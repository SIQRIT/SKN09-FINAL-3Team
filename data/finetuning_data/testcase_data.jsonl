{"context": "", "input": "【기술명】\n인공지능 모델을 이용한 육류 등급 판단 방법 및 시스템\n\n【기술 설명】\n본 발명은 인공지능 모델을 활용하여 육류의 등급을 판단하는 혁신적인 방법 및 장치를 제안합니다. 이 기술은 고해상도 육류 이미지를 분석하여, 마블링, 육색, 조직감 등의 다양한 특성을 평가함으로써 육류의 품질을 객관적으로 판별합니다. 인공지능 모델은 대량의 학습 데이터 세트를 기반으로 훈련되어, 입력된 육류 이미지에 대한 신뢰성 높은 등급을 자동으로 산출합니다. 이를 통해 육류의 품질에 대한 전문적인 판단이 필요 없는 일반 소비자들도 쉽게 육류를 선택할 수 있는 환경을 조성합니다.\n\n【해결 문제】\n육류 소비가 증가함에 따라, 소비자들은 품질에 대한 더욱 높은 기대를 가지고 있습니다. 그러나 육류 등급 평가에는 주관적인 요소가 많아 전문가의 평가 결과가 엇갈리는 경우가 빈번합니다. 이러한 문제는 소비자에게 혼란을 초래하고, 육류 구매 결정에 부정적인 영향을 미칠 수 있습니다. 본 발명은 인공지능을 통해 객관적이고 일관된 육류 등급 평가를 제공하여 이러한 문제를 해결할 수 있으며, 신뢰할 수 있는 정보로 소비자 선택의 정확성을 높이고 시장의 투명성을 증대시킵니다.\n\n【기술 차별성】\n기존의 육류 등급 판단 방식은 주로 전문가의 주관적인 평가에 의존하고 있으며, 이는 평가의 일관성과 신뢰성을 저하시킬 수 있습니다. 본 발명은 인공지능 모델을 통해 대량의 육류 이미지를 학습하고 이를 기반으로 평가를 수행함으로써 기존 기술과 차별화된 객관성과 신뢰성을 제공합니다. 또한, 국가별로 동일한 기준으로 육류를 평가할 수 있는 기능을 통해 글로벌 시장에서도 적용 가능성을 높이며, 비용 절감과 평가 속도 향상이라는 추가적인 이점을 제공합니다. 이와 같은 혁신적인 접근은 육류 산업의 미래를 변화시킬 잠재력을 지니고 있습니다.\n\n【활용 분야】\n본 발명은 식품 산업에서 특히 육류 생산 및 유통 분야에 혁신적인 변화를 가져올 수 있습니다. 고기 품질 평가의 정확성을 높임으로써, 도축장, 가공업체, 유통업체 및 소매점에서 효율적인 품질 관리를 가능하게 합니다. 또한, 인공지능 기반의 육류 등급 판단 시스템은 소비자 신뢰도를 향상시키고, 육류의 가격 책정 및 마케팅 전략 수립에 중요한 역할을 수행할 수 있습니다. 이 기술은 또한 국가별로 서로 다른 가이드라인을 준수하여 글로벌 시장에서도 경쟁력을 강화할 수 있는 기회를 제공합니다.\n\n【구성 요소 및 기능】\n본 시스템은 세 가지 주요 구성 요소로 이루어져 있습니다. 첫 번째 구성 요소는 **학습 데이터 세트 생성 모듈**로, 이는 한돈, 한우 및 육우와 같은 다양한 육류의 이미지와 해당 이미지에 매칭되는 등급 정보를 수집하여 학습용 데이터 세트를 생성합니다. 두 번째 구성 요소는 **인공지능 모델 훈련 모듈**로, 이 모듈은 수집된 데이터 세트를 바탕으로 육류 이미지의 등급을 판단할 수 있도록 인공지능 모델을 훈련시킵니다. 마지막으로, **육류 등급 판단 모듈**은 입력된 육류 이미지를 분석하여 실시간으로 육류의 등급을 평가하며, 이를 통해 신속하고 일관된 품질 평가를 제공합니다.\n\n【구현 방식 예】\n이 시스템의 구현은 두 가지 주요 단계로 구분됩니다. 첫 번째 단계는 **데이터 수집 및 전처리**로, 다양한 육류 이미지와 해당 등급 정보를 수집하고, 이를 인공지능 모델이 이해할 수 있는 형태로 전처리합니다. 두 번째 단계는 **모델 훈련 및 평가**로, 전처리된 데이터를 사용하여 인공지능 모델을 훈련시킨 후, 새로운 육류 이미지를 입력하여 실시간으로 등급을 판단할 수 있도록 시스템을 최적화합니다. 이러한 방법론은 반복적인 피드백과 개선 과정을 통해 모델의 정확도를 지속적으로 향상시킬 수 있는 기회를 제공합니다.", "output": "【발명의 명칭】\n인공지능 모델을 이용한 육류 등급 판단 방법 및 장치\n【기술분야】\n본 발명은 인공지능 모델을 이용한 육류 등급 판단 방법 및 장치에 관한 것으로서, 보다 상세하게는, 인공지능 모델을 이용하여 육류 이미지를 분석하고, 이미지에 포함된 육류의 등급을 판단하는 기술에 관한 것이다.\n【배경기술】\n전 세계적으로 육류소비는 지속적으로 증가되는 추세이다. 2021년 기준 전 세계 육류 소비량 1위는 닭고기이고, 돼지고기, 소고기가 그 뒤를 이어 자리하고 있다. 2021년 돼지고기 소비량은 32.3kg이고, 국내 소고기 소비량은 1인당 12.4kg이다. 최근의 소비자들은 여러가지 매체를 통해 육류에 관한 정보를 얻을 수 있고, 이를 종합하여 보다 더 좋은 육류를 구매하고자 한다. 이는 육 류의 등급에 따라 맛과 가격의 차이가 크기 때문이다. 하지만, 육류에 대한 등급은 전문가들이 아니면 판단하기 쉽지 않고, 전문가마다 등급에 대한 평가가 엇갈릴 수 있다. 이는 육류 등급을 평가하는데 주요 항목인 마블링, 육색, 조직감, 기호도 등의 기준이 평가하는 전문가마 다 다르고, 국가별로 다르기 때문이다. 이와 같이 평가 결과를 뒷받침할 수 있는 부분에 대한 객관화된 자료가 없는 것이 육류 등급 평가에 대한 신뢰 도가 하락하는 가장 큰 원인이다. 이에 따라 등급별로 다수의 육류 사진을 학습한 인공지능이 보유한 데이터를 기초로 어느 하나의 육류 사진을 분석하여 등급을 판단하는 인공지능을 이용한 육류 등급 판단 방법 및 장치에 대한 필요성이 증대되고 있다.\n【해결하려는 과제】\n본 발명은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 이미지에 포함된 육류를 미리 학습된 인공지 능이 분석하여 등급을 판단하는 인공지능을 이용한 육류 등급 판단 방법 및 장치에 관한 것이다. 다만, 본 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제로 한정되지 않으며, 또 다른 기 술적 과제들이 존재할 수 있다.\n【과제의 해결 수단】\n상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제 1 측면에 따르는 실시예는, 인공지능 모 델을 이용한 육류 등급 판단 방법을 제공한다. 본 방법은, 한돈, 한우 및 육우 중 적어도 하나 이상에 대한 학 습용 육류 이미지와 상기 학습용 육류 이미지에 매칭되는 등급 정보를 포함하는 학습 데이터 세트를 생성하는 단계; 및 상기 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류의 등급을 판단하도록 훈련된 인 공지능 모델을 생성하는 단계를 포함한다. 또한, 본 개시의 제 2 측면에 따른 실시예는, 육류 등급 판단 장치를 제공한다. 본 장치는 통신 모듈, 적어도 하나의 프로세서 및 상기 프로세서와 전기적으로 연결되고, 상기 프로세서에서 수행되는 적어도 하나의 코드 (code)가 저장되는 메모리를 포함하고, 상기 메모리는 상기 프로세서를 통해 실행될 때 상기 프로세서가, 한돈, 한우 및 육우 중 적어도 하나 이상에 대한 학습용 육류 이미지와 상기 학습용 육류 이미지에 매칭되는 등급 정 보를 포함하는 학습 데이터 세트를 생성하고, 상기 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류의 등급을 판단하도록 훈련된 인공지능 모델을 생성하도록 야기하는 코드를 저장한다.\n【발명의 효과】\n본 발명은 등급별로 구분된 육류 이미지를 학습한 인공지능에 의해 일관되고, 정확성이 높은 육류 등급 평가를 제공할 수 있다. 그리고 인공지능에 의해 수행되어 비용이 절감되고, 평가 속도를 향상시킬 수 있다. 또한, 국가별로 동일한 기준으로 평가하여 해당 국가의 등급에 맞는 육류 등급 평가를 제공할 수 있다. 또한, 육류 등급 평가 기준을 명확하게 하여 등급을 평가하는데 결정적인 역할을 한 항목이 어떤 부분인지 근거 를 제공할 수 있다.\n【발명을실시하기위한구체적인내용】\n이하에서는 첨부한 도면을 참조하여 본 개시를 상세히 설명하기로 한다. 다만, 본 개시는 여러 가지 상이한 형 태로 구현될 수 있으며, 여기에서 설명하는 실시예들로 한정되는 것은 아니다. 또한, 첨부된 도면은 본 명세서 에 개시된 실시예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않는다. 여기에 사용되는 기술용어 및 과학용어를 포함하는 모든 용어들은 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자가 일반적으로 이해하는 의미로 해석되어야 한다. 사전에 정의된 용어들은 관련기술문헌과 현재 개시된 내용에 부합하는 의미를 추가적으로 갖는 것으로 해석되어야 하며, 별도로 정의되 지 않는 한 매우 이상적이거나 제한적인 의미로 해석되지 않는다. 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 도면에 나타난 각 구성요 소의 크기, 형태, 형상은 다양하게 변형될 수 있다. 명세서 전체에 대하여 동일/유사한 부분에 대해서는 동일/ 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결(접속, 접촉 또는 결합)\"되어 있다고 할 때, 이는 \"직접적으로 연결(접속, 접촉 또는 결합)\"되어 있는 경우뿐만 아니라, 그 중간에 다른 부재를 사이에 두고 \"간접적으로 연결 (접속, 접촉 또는 결합)\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함(구비 또는 마 련)\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소 를 더 \"포함(구비 또는 마련)\"할 수 있다는 것을 의미한다. 본 명세서에 있어서 '부(部)'란, 하드웨어에 의해 실현되는 유닛(unit), 소프트웨어에 의해 실현되는 유닛, 양 방을 이용하여 실현되는 유닛을 포함한다. 또한, 1 개의 유닛이 2 개 이상의 하드웨어를 이용하여 실현되어도 되고, 2 개 이상의 유닛이 1 개의 하드웨어에 의해 실현되어도 된다. 한편, '~부'는 소프트웨어 또는 하드웨어 에 한정되는 의미는 아니며, '~부'는 어드레싱 할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객체 지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수 들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 '~부'들 안에 서 제공되는 기능은 더 작은 수의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분 리될 수 있다. 뿐만 아니라, 구성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 CPU들을 재생시키도록 구현될 수도 있다. 이하의 설명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\" 등은 명세서 작성의 용이함만이 고려되어 부 여되거나 혼용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요 지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략하였다. 본 명세서에서 사용되는 제1, 제2 등과 같이 서수를 나타내는 용어들은 하나의 구성 요소를 다른 구성요소로부 터 구별하는 목적으로만 사용되며, 구성 요소들의 순서나 관계를 제한하지 않는다. 예를 들어, 본 개시의 제1구 성요소는 제2구성요소로 명명될 수 있고, 유사하게 제2구성요소도 제1구성 요소로 명명될 수 있다. 본 명세서에 서 사용되는 단수 표현의 형태들은 명백히 반대의 의미를 나타내지 않는 한 복수 표현의 형태들도 포함하는 것으로 해석되어야 한다. 이하에서 언급되는 \"사용자 단말\"은 네트워크를 통해 서버나 타 단말에 접속할 수 있는 컴퓨터나 휴대용 단말기 로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱 (desktop), 랩톱(laptop), VR HMD(예를 들어, HTC VIVE, Oculus Rift, GearVR, DayDream, PSVR 등)등을 포함할 수 있다. 여기서, VR HMD는 PC용 (예를 들어, HTC VIVE, Oculus Rift, FOVE, Deepon 등)과 모바일용(예를 들어, GearVR, DayDream, 폭풍마경, 구글 카드보드 등) 그리고 콘솔용(PSVR)과 독립적으로 구현되는 Stand Alone 모델(예를 들어, Deepon, PICO 등) 등을 모두 포함한다. 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, 스마트폰(smart phone), 태블릿 PC, 웨어러블 디바이스뿐만 아니라, 블루투스(BLE, Bluetooth Low Energy), NFC, RFID, 초음파(Ultrasonic), 적외선, 와이파이(WiFi), 라이파이(LiFi) 등의 통신 모듈을 탑재한 각종 디바이스를 포함할 수 있다. 또한, \"네트워크\"는 단말들 및 서버들과 같은 각각의 노 드 상호 간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 근거리 통신망(LAN: Local Area Network), 광 역 통신망(WAN: Wide Area Network), 인터넷 (WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통신망 등을 포함한다. 무선 데이터 통신망의 일례에는 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와 이파이(Wi-Fi), 블루투스 통신, 적외선 통신, 초음파 통신, 가시광 통신(VLC: Visible Light Communication), 라이파이(LiFi) 등이 포함되나 이에 한정되지는 않는다. 도 1은 본 발명의 일 실시예에 따른 육류 등급 판단 장치 및 이와 통신 연결된 단말을 나타낸 도면이다. 도 1을 참조하면 육류 등급 판단 장치와 단말은 통신 네트워크를 통해 통신 연결될 수 있다. 이하에 서 육류 등급 판단 장치는 서버로 칭할 수 있다. 서버는 SaaS (Software as a Service), PaaS (Platform as a Service) 또는 IaaS (Infrastructure as a Service)와 같은 클라우드 컴퓨팅 서버로 형성될 수 있다. 또 한, 서버는 사설(private) 클라우드, 공용(public) 클라우드 또는 하이브리드(hybrid) 클라우드 시스템과 같은 형태로 구축될 수도 있으나, 본 발명의 범위가 이에 제한되는 것은 아니다. 또한, 육류 등급 판단 장치는 인공지능 모델을 이용하여 구동될 수 있다. 육류 등급 판단 장치는 적어도 하나 이상에 대한 학습용 육류 이미지와 상기 학습용 육류 이미지에 매칭되 는 등급 정보를 포함하는 학습 데이터 세트를 생성한다. 육류 등급 판단 장치는 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류의 등급을 판단하 도록 훈련된 인공지능 모델을 생성한다. 단말은 육류 등급 판단 장치로 이미지를 전송할 수 있다. 그리고 육류 등급 판단 장치로부터 육 류 등급을 시각화 자료와 함께 수신할 수 있다. 도 2는 도 1에서 육류 등급 판단 장치를 상세하게 나타낸 도면이다. 도 2를 참조하면 육류 등급 판단 장치는 통신 모듈, 프로세서 및 메모리를 포함할 수 있다. 통신 모듈은 다른 네트워크 장치와 유무선 연결을 통해 제어 신호 또는 데이터 신호와 같은 신호를 송수신 하기 위해 필요한 하드웨어 및 소프트웨어를 포함하는 장치를 포함할 수 있다. 통신 모듈은 단말로부터 육류 이미지를 수신할 수 있다. 또한, 통신 모듈은 단말로 육류 등급을 이미지, 그래프 및 테이블(표)을 포함하는 시각화 자료로 제공할 수 있다. 다만, 이에 한정되는 것은 아 니며, 필요에 따라 통신 모듈은 단말이 아닌 외부 장치 및 데이터베이스에 이미지 또는 영상을 수신 할 수 있다. 프로세서는 데이터를 제어 및 처리하는 다양한 종류의 장치들을 포함할 수 있다. 프로세서는 프로그 램 내에 포함된 코드 또는 명령으로 표현된 기능을 수행하기 위해 물리적으로 구조화된 회로를 갖는, 하드웨어 에 내장된 데이터 처리 장치를 의미할 수 있다. 일 예에서, 프로세서는 마이크로프로세서(microprocessor), 중앙처리장치(central processing unit: CPU), 프로세서 코어(processor core), 멀티프로세서(multiprocessor), ASIC(application-specific integrated circuit), FPGA(field programmable gate array) 등의 형태로 구현될 수 있으나, 본 발명의 범위가 이에 한정 되는 것은 아니다. 프로세서는 메모리에 저장된 코드에 따라 동작을 수행한다. 메모리는 통신 모듈로 입력되는 정보 및 데이터, 프로세서에 의해 수행되는 기능에 필요한 정보 및 데이터, 프로세서의 실행에 따라 생성된 데이터 중 적어도 어느 하나 이상을 저장할 수 있다. 메모리는 전원이 공급되지 않아도 저장된 정보를 계속 유지하는 비휘발성 저장장치 및 저장된 정보를 유지 하기 위하여 전력을 필요로 하는 휘발성 저장장치를 통칭하는 것으로 해석되어야 한다. 메모리는 저장된 정보를 유지하기 위하여 전력이 필요한 휘발성 저장장치 외에 자기 저장 매체(magnetic storage media) 또는 플 래시 저장 매체(flash storage media)를 포함할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다.메모리는 프로세서와 전기적으로 연결되고, 프로세서에서 수행되는 적어도 하나의 코드가 저장 된다. 메모리는 프로세서를 통해 실행될 때 프로세서가 다음과 같은 기능 및 절차들을 수행하도 록 야기하는 코드가 저장된다. 메모리는 적어도 하나 이상에 대한 학습용 육류 이미지와 상기 학습용 육류 이미지에 매칭되는 등급 정보 를 포함하는 학습 데이터 세트를 생성하도록 야기하는 코드가 저장된다. 예컨대, 등급 정보는 기 설정된 복수개 의 국가별 소고기 등급 또는 돼지고기 등급을 판단하는 기준에 기초하여 설정될 수 있다. 메모리는 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류의 등급을 판단하도록 훈련된 인 공지능 모델을 생성하도록 야기하는 코드가 저장된다. 메모리는 등급 판단 대상이 되는 육류 이미지를 수신하고, 인공지능 모델을 이용하여 육류 이미지에 대한 등급을 판단하도록 야기하는 코드가 저장된다. 예컨대, 육류 이미지에 포함된 육류의 등급은 복수개의 국가별 등급들 중 적어도 하나 이상의 등급을 포함할 수 있다. 메모리는 통신 연결된 단말로부터 특정 국가의 등급 판단 요청을 수신하는 경우, 육류 이미지에 포함 되는 육류를 특정 국가의 등급에 대응하는 기준으로 판단하도록 야기하는 코드가 저장된다. 메모리는 판단된 육류 등급의 근거로서 상기 육류 이미지의 일 영역을 시각화한 자료를 생성하도록 야기하 는 코드가 저장된다. 예컨대, 일 영역은 육류 이미지 내에 포함된 단백질이 일정 부분 이상 포함된 고기 영역일 수 있다. 메모리는 상기 프로세서와 통신 연결된 단말로 등급, 평가 점수, 육류 이미지, QR 코드, 시각화 자료를 포함하는 인터페이스를 제공하도록 야기하는 코드가 저장된다. 도 3은 본 발명의 일 실시예에 따른 등급 예측 과정을 나타낸 도면이다. 도 3을 참조하면, 육류 등급 판단 장치는 단말로부터 육류 이미지를 수신하면 육류에서 평가 대상이 되는 부분을 구역화하여 잘라낸 후 이미지의 크기를 재설정할 수 있다. 이를 통해 정보의 손실을 최소화할 수 있다. 그리고 크기를 재설정한 이미지에 대해서 미리 훈련된 인공지능 모델을 통해 전이 학습을 진행할 수 있다. 그 다음, 인공지능 모델을 이용하여 육류의 등급을 판단할 수 있다. 이 때, 전이 학습에 사용되는 인공지능 모델은 CNN(Convolutional Neural Network) 및 ViT(Vision Transformer)를 이용할 수 있다. CNN은 합성곱 연산을 통해 이미지의 특징을 감지하고, 이를 통해 입력 데이터를 분류하거나 의미 있는 정보를 추출하고 학습하는 딥러닝 모델이다. ViT는 이미지 처리를 위해 어텐션 메커니즘을 사용하는 딥러닝 모델로 이미지를 토큰으로 변환하여 전역적인 정 보를 추출하고 분류하는데 효과가 있다. 보다 상세하게는 이미지 작업을 Transformer 구조 모델에서 구현하는 것으로 Vision 작업에서 CNN을 사용하지 않고, Transformer의 멀티 헤드 어텐션 구조를 사용하여 구현한 것이다. 이를 통해 ViT는 CNN 기반의 다른 모델 과 비교하였을 때 훌륭한 성능을 나타내며, 학습과정에서 계산 자원을 적게 소모할 수 있다. 이 때, Q(Query), K(Key) 및 V(Value) 값을 바탕으로 큰 값이 강조되며, 이는 학습에 핵심이 되는 요소 표현이 다. 위와 같은 인공지능 모델의 학습 관리는 기 설정된 라이브러리를 사용할 수 있다. 라이브러리는 머신러닝 모델 의 실험을 추적하고 모델을 공유할 수 있도록 지원한다. 도 4는 본 발명의 일 실시예에 따른 관능 평가표를 구하는 과정을 나타낸 도면이다. 도 4를 참조하면, 단말로부터 육류 이미지를 수신하고, 해당 등급의 컬러 분포 그래프를 결합하여 나타낼 수 있으며, 이 때, 육류 이미지와 컬러 분포 그래프를 겹치도록 배치하거나, 육류 이미지와 컬러 분포 그래 프를 나란히 배치할 수 있다. 그리고 인공지능 모델을 활용하여 관능 평가표를 구할 수 있다. 관능 평가표에는 마블링, 육색, 조직감, 표면육즙 및 기호도를 포함할 수 있다. 도 5는 본 발명의 일 실시예에 따른 인공지능 모델을 이용한 등급 예측 결과를 시각화하여 나타낸 도면이다. 도 5를 참조하면, 육류의 등급별 기여도를 해당 등급별 컬러 분포 그래프를 이용하여 시각화한 것을 확인할 수 있다. 도 5에서 육류 이미지를 컬러 분포 그래프와 결합하여 컬러 분포 이미지와 같이 나타낼 수 있다.또한 육류의 대상 등급을 1++, 1+등급, 1등급,2등급,및 3등급으로 구분하고 해당하는 육류의 등급별로 Grad-CAM 기술을 적용하여 어느 부분에 많은 기여를 하고 있는지 시각화한 결과를 확인할 수 있고,이는 육류 이 미지에서 적색에 가까울수록, 모델의 예측에 기여를 많이 한 부분이다. 예컨대 도 5에서 1++ 등급 내지 3등급 (54 내지 58) 각각의 육류 이미지에서 적색으로 표시된 부분에 따라서 육류의 등급이 결정되는 것이다. Grad-CAM(Gradient-weighted Class Activation Mapping)은 딥러닝 모델의 예측 결과를 시각화하는 기법으로, 이미지의 특정 부분이 모델의 결정에 얼마나 기여했는지를 강조하여 표시할 수 있다. 이를 통해 모델이 어떤 부 분을 주로 활용하고 있는지를 시각적으로 이해할 수 있으며, 모델의 예측을 해석할 수 있다. 도 6는 본 발명의 일 실시예에 따른 어텐션 맵(Attention Map)을 통한 등급 예측 결과를 나타낸 도면이다. 도 6를 참조하면, 육류 등급 판단 장치가 단말로부터 수신한 육류 이미지를 인공지능 모델인 ViT(Vision Transformer) based model에서 잠재 벡터를 정방으로 만든 후 원본 이미지와 같은 크기로 재조정 (resize)하여 시각화(61 내지 63)하는 기법이다. 예컨대, 도 6에서와 같이 육류 이미지 내에 표현된 파란색에 가까울수록 큰 가중치를 갖는다. 이미지를 시각화 하기 위해서 사용되는 기술은 도 5에서 설명한 Grad-CAM(Gradient-weighted Class Activation Mapping)과 Attention Map을 이용할 수 있다. 도 7은 본 발명의 다른 실시예에 따른 육류 등급 판단 방법의 순서를 도시한 흐름도이다. 이하에서 설명될 승강장 안전문 제어 방법은 앞서 도 1 내지 도 6를 참조하여 설명한 육류 등급 판단 장치(10 0)에 의해 수행될 수 있다. 따라서, 앞서 도 1 내지 도 6를 참조하여 설명한 본 개시의 실시예에 대한 내용은 이하에서 설명될 실시예에도 동일하게 적용될 수 있으며, 이하에서 상술한 설명과 중복되는 내용은 생략하도록 한다. 이하에서 설명되는 단계들은 반드시 순서대로 수행되어야 하는 것은 아니고, 단계들의 순서는 다양하게 설정될 수 있으며, 단계들은 거의 동시에 수행될 수도 있다. 도 7을 참조하면, 육류 등급 판단 방법은 학습 데이터 세트 생성 단계(S100), 인공지능 모델 생성 단계(S200), 육류 이미지에 대한 등급을 판단하는 단계(S300), 시각화한 자료 생성 단계(S400) 및 인터페이스를 제공하는 단 계(S500)를 포함한다. 학습 데이터 세트 생성 단계(S100)는 적어도 하나 이상에 대한 학습용 육류 이미지와 상기 학습용 육류 이미지 에 매칭되는 등급 정보를 포함하는 학습 데이터 세트를 생성하는 단계이다. 인공지능 모델 생성 단계(S200)는 상기 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류의 등급 을 판단하도록 훈련된 인공지능 모델을 생성하는 단계이다. 육류 이미지에 대한 등급을 판단하는 단계(S300)는 등급 판단 대상이 되는 육류 이미지를 수신하고, 상기 인공 지능 모델을 이용하여 상기 육류 이미지에 대한 등급을 판단하는 단계이다. 또는, 프로세서와 통신 연결된 단말 로부터 특정 국가의 등급 판단 요청을 수신하는 경우, 상기 육류 이미지에 포함되는 육류를 상기 특정 국 가의 등급에 대응하는 기준으로 판단하여 제공할 수 있다. 시각화한 자료 생성 단계(S400)는 판단된 육류 등급의 근거로서 상기 육류 이미지의 일 영역을 시각화한 자료를 생성하는 단계이다. 인터페이스를 제공하는 단계(S500)는 상기 프로세서와 통신 연결된 단말로 등급, 평가 점수, 육류 이미지, QR 코드 및 시각화 자료를 포함하는 인터페이스를 제공하는 단계이다. 본 발명의 일 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함 하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독 가능 매체는 컴퓨터 저장 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구 조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비 휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 본 발명의 방법 및 시스템은 특정 실시예와 관련하여 설명되었지만, 그것들의 구성 요소 또는 동작의 일부 또는 전부는 범용 하드웨어 아키텍쳐를 갖는 컴퓨터 시스템을 사용하여 구현될 수 있다.본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 상술한 설명을 기초로 본 개시의 기술적 사상이나 필수 적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러 므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해되어야만 한다. 본 개시의 범위는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개 념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으로 해석되어야 한다. 본원 의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범 위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해석 되어야 한다.\n【요약】본 개시의 일 실시예는, 인공지능 모델을 이용한 육류 등급 판단 방법을 제공한다. 본 방법은, 한돈, 한우 및 육 우 중 적어도 하나 이상에 대한 학습용 육류 이미지와 상기 학습용 육류 이미지에 매칭되는 등급 정보를 포함하 는 학습 데이터 세트를 생성하는 단계; 및 상기 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류 (뒷면에 계속)\n\n【청구항 1】\n프로세서에 의해 수행되는 인공지능 모델을 이용한 육류 등급 판단 방법으로서,a) 적어도 하나 이상에 대한 학습용 육류 이미지와 상기 학습용 육류 이미지에 매칭되는 등급 정보를 포함하는학습 데이터 세트를 생성하는 단계; 및 b) 상기 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류의 등급을 판단하도록 훈련된 인공지능모델을 생성하는 단계를 포함하는 것인, 인공지능 모델을 이용한 육류 등급 판단 방법.\n【청구항 2】\n제1항에 있어서, c) 등급 판단 대상이 되는 육류 이미지를 수신하고, 상기 인공지능 모델을 이용하여 상기 육류 이미지에 대한등급을 판단하는 단계를 더 포함하는 것인, 인공지능 모델을 이용한 육류 등급 판단 방법.\n【청구항 3】\n제1항에 있어서, 상기 등급 정보는 기 설정된 복수개의 국가별 소고기 등급 또는 돼지고기 등급을 판단하는 기준에 기초하여 설정되는 것인, 인공지능 모델을 이용한 육류 등급 판단 방법.\n【청구항 4】\n제 2 항에 있어서,상기 c) 단계에서 판단되는, 상기 육류 이미지에 포함된 육류의 등급은 복수개의 국가별 등급들 중 적어도 하나이상의 등급을 포함하고, 상기 c) 단계는, 상기 프로세서와 통신 연결된 단말로부터 특정 국가의 등급 판단 요청을 수신하는 경우, 상기 육류 이미지에 포함되는 육류를 상기 특정 국가의 등급에 대응하는 기준으로 판단하여 제공하는 것인, 인공지능 모델을 이용한육류 등급 판단 방법.\n【청구항 5】\n제 1 항에 있어서,d) 상기 c)단계에 따라 판단된 육류 등급의 근거로서 상기 육류 이미지의 일 영역을 시각화한 자료를 생성하는단계를 더 포함하는 것인, 인공지능 모델을 이용한 육류 등급 판단 방법.\n【청구항 6】\n제 5 항에 있어서,상기 일 영역은 상기 육류 이미지 내에 포함된 단백질이 일정 부분 이상 포함된 고기 영역인 것인, 인공지능 모델을 이용한 육류 등급 판단 방법.\n【청구항 7】\n제 1 항에 있어서,e) 상기 프로세서와 통신 연결된 단말로 등급, 평가 점수, 육류 이미지, QR 코드 및 시각화 자료를 포함하는 인터페이스를 제공하는 단계를 더 포함하는 것인, 인공지능 모델을 이용한 육류 등급 판단 방법.공개특허 10-2025-0035112-3-청구항 8 통신 모듈;적어도 하나의 프로세서; 및상기 프로세서와 전기적으로 연결되고, 상기 프로세서에서 수행되는 적어도 하나의 코드(code)가 저장되는 메모리를 포함하고,상기 메모리는 상기 프로세서를 통해 실행될 때 상기 프로세서가,적어도 하나 이상에 대한 학습용 육류 이미지와 상기 학습용 육류 이미지에 매칭되는 등급 정보를 포함하는 학습 데이터 세트를 생성하고, 상기 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류의 등급을 판단하도록 훈련된 인공지능 모델을 생성하도록 야기하는 코드를 저장하는 것인, 육류 등급 판단 장치.\n【청구항 9】\n제 8 항에 있어서,상기 메모리는 상기 프로세서를 통해 실행될 때 상기 프로세서가,등급 판단 대상이 되는 육류 이미지를 수신하고, 상기 인공지능 모델을 이용하여 상기 육류 이미지에 대한 등급을 판단하고, 판단된 육류 등급의 근거로서 상기 육류 이미지의 일 영역을 시각화한 자료를 생성하고, 상기 프로세서와 통신 연결된 단말로 등급, 평가 점수, 육류 이미지, QR 코드, 시각화 자료를 포함하는 인터페이스를제공하도록 야기하는 코드를 저장하는 것인, 육류 등급 판단 장치.\n【청구항 10】\n제 8 항에 있어서,상기 등급 정보는 기 설정된 복수개의 국가별 소고기 등급 또는 돼지고기 등급을 판단하는 기준에 기초하여 설정되는 것인, 육류 등급 판단 장치.\n【청구항 11】\n제 9 항에 있어서,상기 육류 이미지에 포함된 육류의 등급은 복수개의 국가별 등급들 중 적어도 하나 이상의 등급을 포함하고, 상기 메모리는 상기 프로세서를 통해 실행될 때 상기 프로세서가,상기 프로세서와 통신 연결된 단말로부터 특정 국가의 등급 판단 요청을 수신하는 경우, 상기 육류 이미지에 포함되는 육류를 상기 특정 국가의 등급에 대응하는 기준으로 판단하여 제공하도록 야기하는 코드를 저장하는 것인, 육류 등급 판단 장치.\n【청구항 12】\n제 9 항에 있어서,상기 일 영역은 상기 육류 이미지 내에 포함된 단백질이 일정 부분 이상 포함된 고기 영역인 것인, 육류 등급판단 장치."}
{"context": "", "input": "【기술명】\n인공지능 모델을 이용한 육류 맛과 연도 측정 방법 및 시스템\n\n【기술 설명】\n본 발명은 인공지능 모델을 활용하여 육류의 맛과 연도를 측정하는 방법 및 장치에 관한 것으로, 육류 이미지를 분석하여 정량적 평가를 제공합니다. 해당 기술은 사전에 학습된 대량의 육류 이미지와 그에 따른 관능 평가 데이터를 기초로 하여, 새로운 육류 이미지를 입력받아 그 맛과 연도를 신속하고 일관되게 판단할 수 있도록 설계되었습니다. 이로 인해 소비자는 전문가의 평가에 의존하지 않고도 고기 선택 시 보다 정확한 정보를 바탕으로 구매 결정을 내릴 수 있습니다.\n\n【해결 문제】\n현재 육류 시장에서는 소비자들이 육류의 맛과 품질을 판단하는 데 있어 전문가의 평가에 의존하고 있으며, 이는 전문가마다 주관적 기준이 다르기 때문에 일관성이 결여되어 있습니다. 본 기술은 인공지능 모델을 통해 이러한 문제를 해결하고, 육류의 맛과 연도를 객관적으로 측정함으로써 소비자에게 신뢰할 수 있는 정보를 제공합니다. 이 기술은 소비자가 보다 나은 선택을 할 수 있도록 도와주며, 육류 구매 과정에서의 불확실성을 줄이는 동시에 시장의 투명성을 높이는 필요성이 있습니다.\n\n【기술 차별성】\n본 발명은 기존의 육류 평가 방법과 비교했을 때, 인공지능을 통해 대량의 데이터를 신속하게 분석하여 일관된 결과를 도출하는 혁신적인 접근 방식을 채택하고 있습니다. 기존 기술에서는 전문가의 주관에 따라 평가가 이루어졌으나, 본 발명은 정확한 데이터 기반 분석을 통해 소비자에게 객관적이고 신뢰할 수 있는 정보를 제공합니다. 또한, 비용 절감 및 측정 속도 향상이라는 추가적인 장점을 통해 육류 평가 분야에서 경쟁력을 확보할 수 있는 기술적 차별성을 지니고 있습니다.\n\n【활용 분야】\n본 발명은 식품 산업, 특히 육류 가공 및 유통 분야에서 광범위하게 활용될 수 있습니다. 고기 품질 평가 및 관리 시스템에 통합하여, 육류의 맛과 연도를 신속하고 정확하게 측정함으로써 소비자에게 최상의 품질을 보장할 수 있습니다. 또한, 식품 안전 및 품질 관련 규제를 준수하기 위한 도구로서, 레스토랑 및 식품 서비스 산업에서도 활용이 가능하여, 고객 만족도를 높이는 데 기여할 수 있습니다.\n\n【구성 요소 및 기능】\n본 발명의 주요 구성 요소는 다음과 같습니다. 첫째, **학습 데이터 세트 생성 모듈**는 다양한 육류 이미지와 이에 매칭되는 관능 평가 테이블을 바탕으로 학습 데이터 세트를 생성하는 기능을 수행합니다. 둘째, **인공지능 모델 생성 모듈**은 수집된 학습 데이터 세트를 기초로 하여 육류의 맛과 연도를 측정하도록 훈련된 인공지능 모델을 개발합니다. 셋째, **측정 및 평가 모듈**은 입력된 육류 이미지를 분석하여, 해당 육류의 맛과 연도를 정확하게 측정하고, 결과를 사용자에게 제공하는 기능을 담당합니다.\n\n【구현 방식 예】\n본 발명의 구현은 다음과 같은 단계로 이루어집니다. 첫째, 다양한 육류 이미지를 수집하고, 이에 대한 관능 평가 데이터를 수집하여 학습용 데이터 세트를 생성합니다. 둘째, 생성된 학습 데이터 세트를 이용해 인공지능 모델을 훈련시키며, 이 과정에서 모델의 정확성을 지속적으로 검증하고 개선합니다. 마지막으로, 훈련된 모델을 통해 실시간으로 육류 이미지를 분석하고, 맛과 연도를 측정하여 사용자에게 제공하는 시스템을 구축합니다. 이러한 단계적 접근은 효율성을 극대화하고, 정확한 결과를 보장하는 데 기여합니다.", "output": "【발명의 명칭】\n인공지능 모델을 이용한 육류 맛과 연도 측정 방법 및 장치\n【기술분야】\n본 발명은 인공지능 모델을 이용한 육류 맛과 연도 측정 방법 및 장치에 관한 것으로서, 보다 상세하게는, 인공 지능 모델을 이용하여 육류 이미지를 분석하고, 이미지에 포함된 육류의 맛과 연도를 측정하는 기술에 관한 것 이다.\n【배경기술】\n전 세계적으로 육류소비는 지속적으로 증가되는 추세이다. 2021년 기준 전 세계 육류 소비량 1위는 닭고기이고, 돼지고기, 소고기가 그 뒤를 이어 자리하고 있다. 2021년 돼지고기 소비량은 32.3kg이고, 국내 소고기 소비량은 1인당 12.4kg이다. 최근의 소비자들은 여러가지 매체를 통해 육류에 관한 정보를 얻을 수 있고, 이를 종합하여 보다 더 좋은 육류를 구매하고자 한다. 이는 육 류의 등급에 따라 맛과 가격의 차이가 크기 때문이다. 소비자가 육류를 구매하는데 있어서 맛은 가격, 원산지 및 등급을 포함하는 고려 요소 중 하나라고 할 수 있다. 고기의 맛을 결정하는 요인으로는 마블링, 육색, 육즙 및 조직감이 포함될 수 있다. 종래에는 육류의 맛과 연도를 전문가들이 측정하고, 소비자는 전문가들이 측정한 맛과 연도를 통해 육류를 구매 하였다. 하지만, 전문가마다 맛과 연도에 대한 평가가 엇갈릴 수 있는데, 이는 육류의 맛과 연도를 측정하는데 주요 항 목인 마블링, 육색, 조직감, 육즙 및 기호도 등의 기준이 평가하는 전문가마다 다르기 때문이다. 이러한 이유로 육류의 맛과 연도에 대한 일관성은 떨어지게 되었다. 이에 따라 맛과 연도별로 다수의 육류 사진을 학습한 인공지능이 보유한 데이터를 기초로 어느 하나의 육류 사 진을 분석하여 신속하고, 일관성 있게 맛과 연도를 측정하는 인공지능을 이용한 육류 맛과 연도 측정 방법 및 장치에 대한 필요성이 증대되고 있다.\n【해결하려는 과제】\n본 발명은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 이미지에 포함된 육류를 미리 학습된 인공지 능이 분석하여 맛과 연도를 측정하는 인공지능을 이용한 육류 등급 판단 방법 및 장치에 관한 것이다. 다만, 본 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제로 한정되지 않으며, 또 다른 기 술적 과제들이 존재할 수 있다.\n【과제의 해결 수단】\n상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제 1 측면에 따르는 실시예는, 인공지능 모 델을 이용한 육류 맛과 연도 측정 방법을 제공한다. 본 방법은, 적어도 하나 이상에 대한 학습용 육류 이미지와 상기 학습용 육류 이미지에 매칭되는 관능 평가 테이블을 포함하는 학습 데이터 세트를 생성하는 단계 및 상기 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류의 맛과 연도를 측정하도록 훈련된 인공지능 모 델을 생성하는 단계를 포함한다. 또한, 본 개시의 제 2 측면에 따른 실시예는, 육류 맛과 연도 측정 장치를 제공한다. 본 장치는 통신 모듈, 적 어도 하나의 프로세서 및 상기 프로세서와 전기적으로 연결되고, 상기 프로세서에서 수행되는 적어도 하나의 코 드(code)가 저장되는 메모리를 포함하고, 상기 메모리는 상기 프로세서를 통해 실행될 때 상기 프로세서가, 적 어도 하나 이상에 대한 학습용 육류 이미지와 상기 학습용 육류 이미지에 매칭되는 관능 평가 테이블을 포함하 는 학습 데이터 세트를 생성하고, 상기 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류의 맛과 연도를 측정하도록 훈련된 인공지능 모델을 생성하도록 야기하는 코드를 저장한다.\n【발명의 효과】\n본 발명은 맛과 연도별로 구분된 육류 이미지를 학습한 인공지능에 의해 일관되고, 정확성이 높은 육류 맛과 연 도 측정을 제공할 수 있다. 그리고 인공지능에 의해 수행되어 비용이 절감되고, 측정 속도를 향상시킬 수 있다. 또한, 측정 기준을 명확하게 하여 육류의 맛과 연도를 평가하는데 결정적인 역할을 한 항목이 어떤 부분인지 시 각화된 자료로서 근거를 제공할 수 있다.\n【발명을실시하기위한구체적인내용】\n이하에서는 첨부한 도면을 참조하여 본 개시를 상세히 설명하기로 한다. 다만, 본 개시는 여러 가지 상이한 형 태로 구현될 수 있으며, 여기에서 설명하는 실시예들로 한정되는 것은 아니다. 또한, 첨부된 도면은 본 명세서 에 개시된 실시예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않는다. 여기에 사용되는 기술용어 및 과학용어를 포함하는 모든 용어들은 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자가 일반적으로 이해하는 의미로 해석되어야 한다. 사전에 정의된 용어들은 관련기술문헌과 현재 개시된 내용에 부합하는 의미를 추가적으로 갖는 것으로 해석되어야 하며, 별도로 정의되 지 않는 한 매우 이상적이거나 제한적인 의미로 해석되지 않는다. 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 도면에 나타난 각 구성요 소의 크기, 형태, 형상은 다양하게 변형될 수 있다. 명세서 전체에 대하여 동일/유사한 부분에 대해서는 동일/ 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결(접속, 접촉 또는 결합)\"되어 있다고 할 때, 이는 \"직접적으로 연결(접속, 접촉 또는 결합)\"되어 있는 경우뿐만 아니라, 그 중간에 다른 부재를 사이에 두고 \"간접적으로 연결 (접속, 접촉 또는 결합)\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함(구비 또는 마 련)\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소 를 더 \"포함(구비 또는 마련)\"할 수 있다는 것을 의미한다. 본 명세서에 있어서 '부(部)'란, 하드웨어에 의해 실현되는 유닛(unit), 소프트웨어에 의해 실현되는 유닛, 양 방을 이용하여 실현되는 유닛을 포함한다. 또한, 1 개의 유닛이 2 개 이상의 하드웨어를 이용하여 실현되어도 되고, 2 개 이상의 유닛이 1 개의 하드웨어에 의해 실현되어도 된다. 한편, '~부'는 소프트웨어 또는 하드웨어 에 한정되는 의미는 아니며, '~부'는 어드레싱 할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객체 지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수 들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 '~부'들 안에 서 제공되는 기능은 더 작은 수의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분 리될 수 있다. 뿐만 아니라, 구성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 CPU들을 재생시키도록 구현될 수도 있다. 이하의 설명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\" 등은 명세서 작성의 용이함만이 고려되어 부 여되거나 혼용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요 지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략하였다.본 명세서에서 사용되는 제1, 제2 등과 같이 서수를 나타내는 용어들은 하나의 구성 요소를 다른 구성요소로부 터 구별하는 목적으로만 사용되며, 구성 요소들의 순서나 관계를 제한하지 않는다. 예를 들어, 본 개시의 제1구 성요소는 제2구성요소로 명명될 수 있고, 유사하게 제2구성요소도 제1구성 요소로 명명될 수 있다. 본 명세서에 서 사용되는 단수 표현의 형태들은 명백히 반대의 의미를 나타내지 않는 한 복수 표현의 형태들도 포함하는 것으로 해석되어야 한다. 이하에서 언급되는 \"사용자 단말\"은 네트워크를 통해 서버나 타 단말에 접속할 수 있는 컴퓨터나 휴대용 단말기 로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱 (desktop), 랩톱(laptop), VR HMD(예를 들어, HTC VIVE, Oculus Rift, GearVR, DayDream, PSVR 등)등을 포함할 수 있다. 여기서, VR HMD는 PC용 (예를 들어, HTC VIVE, Oculus Rift, FOVE, Deepon 등)과 모바일용(예를 들어, GearVR, DayDream, 폭풍마경, 구글 카드보드 등) 그리고 콘솔용(PSVR)과 독립적으로 구현되는 Stand Alone 모델(예를 들어, Deepon, PICO 등) 등을 모두 포함한다. 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, 스마트폰(smart phone), 태블릿 PC, 웨어러블 디바이스뿐만 아니라, 블루투스 (BLE, Bluetooth Low Energy), NFC, RFID, 초음파(Ultrasonic), 적외선, 와이파이(WiFi), 라이파이(LiFi) 등의 통신 모듈을 탑재한 각종 디바이스를 포함할 수 있다. 또한, \"네트워크\"는 단말들 및 서버들과 같은 각각의 노 드 상호 간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 근거리 통신망(LAN: Local Area Network), 광 역 통신망(WAN: Wide Area Network), 인터넷 (WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통신망 등을 포함한다. 무선 데이터 통신망의 일례에는 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와 이파이(Wi-Fi), 블루투스 통신, 적외선 통신, 초음파 통신, 가시광 통신(VLC: Visible Light Communication), 라이파이(LiFi) 등이 포함되나 이에 한정되지는 않는다. 도 1은 본 발명의 일 실시예에 따른 육류 맛과 연도 측정 장치 및 이와 통신 연결된 단말을 나타낸 도면이다. 도 1을 참조하면 육류 맛과 연도 측정 장치와 단말은 통신 네트워크를 통해 통신 연결될 수 있다. 이 하에서 육류 맛과 연도 측정 장치는 서버로 칭할 수 있다. 서버는 SaaS (Software as a Service), PaaS (Platform as a Service) 또는 IaaS (Infrastructure as a Service)와 같은 클라우드 컴퓨팅 서버로 형성될 수 있다. 또한, 서버는 사설(private) 클라우드, 공용(public) 클라우드 또는 하이브리드(hybrid) 클라우드 시스템 과 같은 형태로 구축될 수도 있으나, 본 발명의 범위가 이에 제한되는 것은 아니다. 또한, 육류 맛과 연도 측정 장치는 인공지능 모델을 이용하여 구동될 수 있다. 육류 맛과 연도 측정 장치는 적어도 하나 이상에 대한 학습용 육류 이미지와 학습용 육류 이미지에 매칭되 는 관능 평가 테이블을 포함하는 학습 데이터 세트를 생성한다. 육류 맛과 연도 측정 장치는 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류의 맛과 연도 를 측정하도록 훈련된 인공지능 모델을 생성한다. 여기서 맛은 여러 전문가의 평가값을 기초로 산출되는 정량적 인 마블링 수치, 육색 수치, 수분감 수치, 조직밀도 수치 등을 기초로 결정될 수 있다. 또한, 연도는 육류의 연 한 정도, 부드러운 정도를 의미하는 것으로 맛과 같이 마블링 수치, 육색 수치, 수분감 수치, 조직밀도 수치 등 을 기초로 결정될 수 있다. 이외에도, 본 발명의 실시예에 따라 처리육, 숙성육을 대상으로 마블링 수치, 육색 수치, 수분감 수치, 조직밀도 수치 등을 판단하여 육류의 숙성 연도, 소비 기한, 후처리 기한 등을 측정할 수도 있다. 단말은 육류 맛과 연도 측정 장치로 이미지를 전송할 수 있다. 그리고 육류 맛과 연도 측정 장치 로부터 육류 맛과 연도를 시각화 자료의 형태로 수신할 수 있다. 도 2는 도 1에서 육류 맛과 연도 측정 장치를 상세하게 나타낸 도면이다. 도 2를 참조하면 육류 맛과 연도 측정 장치는 통신 모듈, 프로세서 및 메모리를 포함할 수 있다. 통신 모듈은 다른 네트워크 장치와 유무선 연결을 통해 제어 신호 또는 데이터 신호와 같은 신호를 송수신 하기 위해 필요한 하드웨어 및 소프트웨어를 포함하는 장치를 포함할 수 있다. 통신 모듈은 단말로부터 육류 이미지를 수신할 수 있다. 또한, 통신 모듈은 단말로 육류 맛과 연도를 이미지, 그래프 및 테이블(표)을 포함하는 시각화 자료의 형태로 제공할 수 있다. 다만, 이에 한정 되는 것은 아니며, 필요에 따라 통신 모듈은 단말이 아닌 외부 장치 및 데이터베이스에 이미지 또는영상을 수신할 수 있다. 프로세서는 데이터를 제어 및 처리하는 다양한 종류의 장치들을 포함할 수 있다. 프로세서는 프로그 램 내에 포함된 코드 또는 명령으로 표현된 기능을 수행하기 위해 물리적으로 구조화된 회로를 갖는, 하드웨어 에 내장된 데이터 처리 장치를 의미할 수 있다. 일 예에서, 프로세서는 마이크로프로세서(microprocessor), 중앙처리장치(central processing unit: CPU), 프로세서 코어(processor core), 멀티프로세서(multiprocessor), ASIC(application-specific integrated circuit), FPGA(field programmable gate array) 등의 형태로 구현될 수 있으나, 본 발명의 범위가 이에 한정 되는 것은 아니다. 프로세서는 메모리에 저장된 코드에 따라 동작을 수행한다. 메모리는 통신 모듈로 입력되는 정보 및 데이터, 프로세서에 의해 수행되는 기능에 필요한 정보 및 데이터, 프로세서의 실행에 따라 생성된 데이터 중 적어도 어느 하나 이상을 저장할 수 있다. 메모리는 전원이 공급되지 않아도 저장된 정보를 계속 유지하는 비휘발성 저장장치 및 저장된 정보를 유지 하기 위하여 전력을 필요로 하는 휘발성 저장장치를 통칭하는 것으로 해석되어야 한다. 메모리는 저장된 정보를 유지하기 위하여 전력이 필요한 휘발성 저장장치 외에 자기 저장 매체(magnetic storage media) 또는 플 래시 저장 매체(flash storage media)를 포함할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 메모리는 프로세서와 전기적으로 연결되고, 프로세서에서 수행되는 적어도 하나의 코드가 저장 된다. 메모리는 프로세서를 통해 실행될 때 프로세서가 다음과 같은 기능 및 절차들을 수행하도 록 야기하는 코드가 저장된다. 메모리는 적어도 하나 이상에 대한 학습용 육류 이미지와 학습용 육류 이미지에 매칭되는 관능 평가 테이 블을 포함하는 학습 데이터 세트를 생성하도록 야기하는 코드가 저장된다. 예컨대, 관능 평가 테이블은, 육류 이미지에 포함된 육류에 대한 마블링 평가값, 육색 평가 평가값, 조직감 평가값, 표면 육즙 평가값 및 기호도 평가값을 포함하고, 기 설정된 복수개의 국가별 소고기의 맛과 연도 또는 돼지고기의 맛과 연도를 판단하는 기 준에 기초하여 설정할 수 있다. 이 때, 마블링 평가값은 상기 육류 이미지에 포함된 육류의 지방 분포 형태를 기초로 산출되고, 육색 평가값은 육류의 채도를 기초로 산출되고, 조직감 평가값은 상기 육류의 밀도, 수분 및 변형성을 기초로 산출되고, 육즙 평가값은 상기 육류의 지방 포함량을 기초로 산출되고, 기호도 평가값은 상기 관능 평가 테이블의 작성 주체가 기설정한 값을 기초로 산출될 수 있다. 메모리는 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류의 맛과 연도를 측정하도록 훈련 된 인공지능 모델을 생성하도록 야기하는 코드가 저장된다. 메모리는 맛과 연도 측정 대상이 되는 육류 이미지를 수신하고, 인공지능 모델을 이용하여 육류 이미지에 대한 맛과 연도를 측정하도록 야기하는 코드가 저장된다. 메모리는 측정된 맛과 연도의 근거로서 육류 이미지의 일 영역을 시각화한 자료를 생성하도록 야기하는 코 드가 저장된다. 예컨대, 일 영역은 상기 육류 이미지 내에 포함된 마블링 분포 형태 및 육색이 기 설정된 수치 값 이상 포함된 고기 영역일 수 있다. 메모리는 단말로 육류 이미지, 시각화자료, 마블링 값, 육색 값, 조직감 값, 육즙 값, 총합 및 QR 코 드를 포함하는 인터페이스를 제공하도록 야기하는 코드가 저장된다. 도 3a 및 도 3b는 본 발명의 일 실시예에 따른 육류 이미지 크기 조절 및 관능 평가를 구하는 과정을 나타낸 도 면이다. 도 3a를 참조하면, 육류 맛과 연도 측정 장치가 통신 연결된 단말로부터 육류 이미지를 수신하고, 육 류 이미지에서 고기 주변부분을 구역화하여 잘라낸 후 이미지의 크기를 조절(resize)할 수 있다. 그리고 도 3b에 나타낸 과정을 수행할 수 있다. 보다 상세하게는 크기가 조절된 육류 이미지를 인공지능 모델 로 잠재 벡터화하고, 기 학습된 등급별 마블링, 육색, 조직감, 육즙 및 기호도 평가값을 기초로 맛과 연도를 측정하고, 관능평가표를 생성할 수 있다. 이 때, 인공지능 모델은 학습을 위한 모델로서, CNN(Convolutional Neural Network) 및 ViT(Vision Transformer)를 이용할 수 있다. CNN은 합성곱 연산을 통해 이미지의 특징을 감지하고, 이를 통해 입력 데이터를 분류하거나 의미 있는 정보를 추출하고 학습하는 딥러닝 모델이다. ViT는 이미지 처리를 위해 어텐션 메커니즘을 사용하는 딥러닝 모델로 이미지를 토큰으로 변환하여 전역적인 정 보를 추출하고 분류하는데 효과가 있다. 보다 상세하게는 이미지 작업을 Transformer 구조 모델에서 구현하는 것으로 Vision 작업에서 CNN을 사용하지 않고, Transformer의 멀티 헤드 어텐션 구조를 사용하여 구현한 것이다. 이를 통해 ViT는 CNN 기반의 다른 모델 과 비교하였을 때 훌륭한 성능을 나타내며, 학습과정에서 계산 자원을 적게 소모할 수 있다. 이 때, Q(Query), K(Key) 및 V(Value) 값을 바탕으로 큰 값이 강조되며, 이는 학습에 핵심이 되는 요소 표현이 다. 도 4는 본 발명의 일 실시예에 따른 관능 평가 결과를 나타낸 도면이다. 도 4를 참조하면, 육류 맛과 연도 측정 장치가 통신 연결된 단말로부터 육류 이미지를 수신하고, 해 당 등급의 컬러 분포 그래프를 결합하여 나타낼 수 있으며, 이 때, 육류 이미지와 컬러 분포 그래프를 겹 치도록 배치하거나, 육류 이미지와 컬러 분포 그래프를 나란히 배치할 수 있다. 그리고 인공지능 모델을 활용하여 관능 평가 결과를 구할 수 있다. 이 때, 관능 평가 결과는 마블링, 육색, 조직감, 표면육즙 및 기호도를 포함할 수 있다. 도 5a 및 도 5b는 본 발명의 일 실시예에 따른 관능 평가를 구하는 과정을 나타낸 도면이다. 도 5a를 참조하면, 도 4에서 설명한 것과 같이 육류 맛과 연도 측정 장치가 통신 연결된 단말로부터 육류 이미지를 수신하고, 해당 등급의 컬러 분포 그래프를 결합하여 컬러 분포 육류 이미지를 나타낼 수 있다. 그리고 도 5b와 같이 육류의 맛과 연도를 구분하고 해당하는 육류의 맛과 연도별로 Grad-CAM 기술을 적용하여 어느 부분에 많은 기여를 하고 있는지 시각화한 결과를 확인할 수 있고, 이는 육류 이미지에서 적색에 가까울수록, 모델의 예측에 많은 기여를 한 부분이다. 예컨대 도 5b에서 맛과 연도의 분포 이미지들(504 내지 508) 각각의 육류 이미지에서 적색으로 표시된 부분에 따라서 육류의 맛과 연도가 결정되는 것이다. 이 때, Grad-CAM(Gradient-weighted Class Activation Mapping)은 딥러닝 모델의 예측 결과를 시각화하는 기법 으로, 이미지의 특정 부분이 모델의 결정에 얼마나 기여했는지를 강조하여 표시할 수 있다. 이를 통해 모델이 어떤 부분을 주로 활용하고 있는지를 시각적으로 이해할 수 있으며, 모델의 예측을 해석할 수 있다. Grad-CAM과 함께 어텐션 맵(Attention Map)을 이용할 수 있으며, Attention Map은 인공지능 모델인 ViT(Vision Transformer) based model에서 잠재 벡터를 정방으로 만든 후 원본 이미지와 같은 크기로 재조정(resize)하여 시각화하는 기법이다. 도 6a 및 도6b는 본 발명의 일 실시예에 따른 단말로 제공되는 인터페이스를 나타낸 도면이다. 도 6a를 참조하면, 원육(신선육)에 대한 맛과 연도 평가 결과는 원본 이미지를 기준으로 마블링, 육 색, 조직감, 육즙 및 총합을 제공하고, 인공지능 모델에 의해서 시각화된 이미지을 기준으로 마블링, 육색, 조직감, 육즙, 총합 및 인공지능 등급 번호을 제공할 수 있다. 그리고 QR코드, 관리번호, 등록인 이메일 및 저장 시간을 함께 제공할 수 있다. 도 6b를 참조하면, 처리육에 대한 맛과 연도 평가 결과는 원본 이미지를 기준으로 마블링, 육색 , 조직감, 육즙, 총합, 시퀀스 번호 및 시기를 제공하고, 인공지능 모델에 의 해서 시각화된 이미지을 기준으로 마블링, 육색, 조직감, 육즙, 총합, 시퀀스 번호, 시기 및 인공지능 등급 번호을 제공할 수 있다. 그리고 QR코드, 관리번호, 등록인 이메일 및 저장 시간을 함께 제공할 수 있다. 도 7은 본 발명의 다른 실시예에 따른 육류 맛과 연도 측정 방법의 순서를 도시한 흐름도이다. 이하에서 설명될 승강장 안전문 제어 방법은 앞서 도 1 내지 도 6b를 참조하여 설명한 육류 맛과 연도 측정 장 치에 의해 수행될 수 있다. 따라서, 앞서 도 1 내지 도 6b를 참조하여 설명한 본 개시의 실시예에 대한 내 용은 이하에서 설명될 실시예에도 동일하게 적용될 수 있으며, 이하에서 상술한 설명과 중복되는 내용은 생략하 도록 한다. 이하에서 설명되는 단계들은 반드시 순서대로 수행되어야 하는 것은 아니고, 단계들의 순서는 다양 하게 설정될 수 있으며, 단계들은 거의 동시에 수행될 수도 있다.도 7을 참조하면, 도 7은 육류 맛과 연도 측정 방법은 학습 데이터 세트 생성 단계(S100), 인공지능 모델 생성 단계(S200), 맛과 연도 측정 단계(S300), 시각화 자료 생성 단계(S400) 및 인터페이스 제공 단계(S500)을 포함 한다. 학습 데이터 세트 생성 단계(S100)는 적어도 하나 이상에 대한 학습용 육류 이미지와 상기 학습용 육류 이미지 에 매칭되는 관능 평가 테이블을 포함하는 학습 데이터 세트를 생성하는 단계이다. 인공지능 모델 생성 단계(S200)는 상기 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류의 맛과 연도를 측정하도록 훈련된 인공지능 모델을 생성하는 단계이다. 맛과 연도 측정 단계(S300)는 맛과 연도 측정 대상이 되는 육류 이미지를 수신하고, 상기 인공지능 모델을 이용 하여 상기 육류 이미지에 대한 맛과 연도를 측정하는 단계이다. 시각화 자료 생성 단계(S400)는 측정된 상기 맛과 연도의 근거로서 상기 육류 이미지의 일 영역을 시각화한 자 료를 생성하는 단계이다. 인터페이스 제공 단계(S500)는 단말로 육류 이미지, 시각화자료, 마블링 값, 육색 값, 조직감 값, 육즙 값, 총합 및 QR 코드를 포함하는 인터페이스를 제공하는 단계이다. 본 발명의 일 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함 하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독 가능 매체는 컴퓨터 저장 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구 조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비 휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 본 발명의 방법 및 시스템은 특정 실시예와 관련하여 설명되었지만, 그것들의 구성 요소 또는 동작의 일부 또는 전부는 범용 하드웨어 아키텍쳐를 갖는 컴퓨터 시스템을 사용하여 구현될 수 있다. 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 상술한 설명을 기초로 본 개시의 기술적 사상이나 필수 적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러 므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해되어야만 한다. 본 개시의 범위는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개 념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으로 해석되어야 한다. 본원 의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범 위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해석 되어야 한다.\n【요약】본 개시의 일 실시예는, 인공지능 모델을 이용한 육류 맛과 연도 측정 방법을 제공한다. 본 방법은, 적어도 하나 이상에 대한 학습용 육류 이미지와 상기 학습용 육류 이미지에 매칭되는 관능 평가 테이블을 포함하는 학습 데이 터 세트를 생성하는 단계 및 상기 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류의 맛과 연도 를 측정하도록 훈련된 인공지능 모델을 생성하는 단계를 포함한다. 본 발명은 맛과 연도별로 구분된 육류 이미지를 학습한 인공지능에 의해 일관되고, 정확성이 높은 육류 맛과 연 도 측정을 제공할 수 있다. 그리고 인공지능에 의해 수행되어 비용이 절감되고, 평가 속도를 향상시킬 수 있다. 또한, 육류 등급 평가 기준을 명확하게 하여 등급을 평가하는데 결정적인 역할을 한 항목이 어떤 부분인지 근거 를 제공할 수 있다.\n\n【청구항 1】\n프로세서에 의해 수행되는 인공지능 모델을 이용한 육류 맛과 연도 측정 방법으로서,a) 적어도 하나 이상에 대한 학습용 육류 이미지와 상기 학습용 육류 이미지에 매칭되는 관능 평가 테이블을 포함하는 학습 데이터 세트를 생성하는 단계; 및 b) 상기 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류의 맛과 연도를 측정하도록 훈련된 인공지능 모델을 생성하는 단계를 포함하는 것인, 인공지능 모델을 이용한 육류 맛과 연도 측정 방법.\n【청구항 2】\n제1항에 있어서, c) 맛과 연도 측정 대상이 되는 육류 이미지를 수신하고, 상기 인공지능 모델을 이용하여 상기 육류 이미지에대한 맛과 연도를 측정하는 단계를 더 포함하는 것인, 인공지능 모델을 이용한 육류 맛과 연도 측정 방법.\n【청구항 3】\n제1항에 있어서, 상기 관능 평가 테이블은, 상기 육류 이미지에 포함된 육류에 대한 마블링 평가값, 육색 평가 평가값, 조직감 평가값, 표면 육즙 평가값및 기호도 평가값을 포함하고,기 설정된 복수개의 국가별 소고기의 맛과 연도 또는 돼지고기의 맛과 연도를 판단하는 기준에 기초하여 설정되는 것인, 인공지능 모델을 이용한 육류 맛과 연도 측정 방법.\n【청구항 4】\n제3 항에 있어서, 상기 마블링 평가값은 상기 육류 이미지에 포함된 육류의 지방 분포 형태를 기초로 산출되고, 육색 평가값은 육류의 채도를 기초로 산출되고,조직감 평가값은 상기 육류의 밀도, 수분 및 변형성을 기초로 산출되고,육즙 평가값은 상기 육류의 지방 포함량을 기초로 산출되고,기호도 평가값은 상기 관능 평가 테이블의 작성 주체가 기설정한 값인 것인, 인공지능 모델을 이용한 육류 맛과연도 측정 방법.\n【청구항 5】\n제 1 항에 있어서,d) 상기 c)단계에 따라 측정된 상기 맛과 연도의 근거로서 상기 육류 이미지의 일 영역을 시각화한 자료를 생성하는 단계를 포함하는 것인, 인공지능 모델을 이용한 육류 맛과 연도 측정 방법.\n【청구항 6】\n제 5 항에 있어서,상기 일 영역은 상기 육류 이미지 내에 포함된 마블링 분포 형태, 육색, 조직감 및 육즙이 기 설정된 수치 값이상 포함된 고기 영역인 것인, 인공지능 모델을 이용한 육류 맛과 연도 측정 방법.공개특허 10-2025-0035114-3-청구항 7 제 1 항에 있어서,e) 단말로 육류 이미지, 시각화자료, 마블링 값, 육색 값, 조직감 값, 육즙 값, 총합 및 QR 코드를 포함하는 인터페이스를 제공하는 단계를 포함하는 것인, 인공지능 모델을 이용한 육류 맛과 연도 측정 방법.\n【청구항 8】\n통신 모듈;적어도 하나의 프로세서; 및상기 프로세서와 전기적으로 연결되고, 상기 프로세서에서 수행되는 적어도 하나의 코드(code)가 저장되는 메모리를 포함하고,상기 메모리는 상기 프로세서를 통해 실행될 때 상기 프로세서가,적어도 하나 이상에 대한 학습용 육류 이미지와 상기 학습용 육류 이미지에 매칭되는 관능 평가 테이블을 포함하는 학습 데이터 세트를 생성하고, 상기 학습 데이터 세트를 기초로 입력되는 육류 이미지에 포함된 육류의 맛과 연도를 측정하도록 훈련된 인공지능 모델을 생성하도록 야기하는 코드를 저장하는 것인, 육류 맛과 연도 측정 장치.\n【청구항 9】\n제 8 항에 있어서,상기 메모리는 상기 프로세서를 통해 실행될 때 상기 프로세서가,맛과 연도 측정 대상이 되는 육류 이미지를 수신하고, 상기 인공지능 모델을 이용하여 상기 육류 이미지에 대한맛과 연도를 측정하고, 측정된 상기 맛과 연도의 근거로서 상기 육류 이미지의 일 영역을 시각화한 자료를 생성하고, 단말로 육류 이미지, 시각화자료, 마블링 값, 육색 값, 조직감 값, 육즙 값, 총합 및 QR 코드를 포함하는인터페이스를 제공하도록 야기하는 코드를 저장하는 것인, 육류 맛과 연도 측정 장치.\n【청구항 10】\n제 8 항에 있어서,상기 관능 평가 테이블은, 상기 육류 이미지에 포함된 육류에 대한 마블링 평가값, 육색 평가 평가값, 조직감 평가값, 표면 육즙 평가값및 기호도 평가값을 포함하고,기 설정된 복수개의 국가별 소고기의 맛과 연도 또는 돼지고기의 맛과 연도를 판단하는 기준에 기초하여 설정되는 것인, 육류 맛과 연도 측정 장치.\n【청구항 11】\n제 10 항에 있어서,상기 마블링 평가값은 상기 육류 이미지에 포함된 육류의 지방 분포 형태를 기초로 산출되고, 육색 평가값은 육류의 채도를 기초로 산출되고, 조직감 평가값은 상기 육류의 밀도, 수분 및 변형성을 기초로 산출되고, 육즙 평가값은 상기 육류의 지방 포함량을 기초로 산출되고, 기호도 평가값은 상기 관능 평가 테이블의 작성 주체가 기설정한 값인, 육류 맛과 연도 측정 장치.\n【청구항 12】\n제 9 항에 있어서,상기 일 영역은 상기 육류 이미지 내에 포함된 마블링 분포 형태, 육색, 조직감 및 육즙이 기 설정된 수치 값이상 포함된 고기 영역인 것인, 육류 맛과 연도 측정 장치.공개특허 10-2025-0035114-4-"}
{"context": "", "input": "【기술명】\nPID 제어기를 이용한 인공지능 시스템\n\n【기술 설명】\n본 발명은 PID 제어기를 이용한 인공지능 시스템으로, 기계 학습 과정에서의 예측 및 분류 결과의 정밀도를 극대화하는 기술입니다. 이 시스템은 훈련 데이터를 기반으로 인공지능 모델을 생성하고, 생성된 모델의 예측 및 분류 결과에 대한 오차 정보를 실시간으로 PID 제어기에 입력하여 미세 조정합니다. 이를 통해, 인공지능 모델이 지속적으로 최적의 성능을 유지할 수 있도록 하여, 다양한 응용 분야에서의 실시간 데이터 처리와 의사결정의 신뢰성을 증대시키는 혁신적인 솔루션을 제공합니다.\n\n【해결 문제】\n기존 인공지능 시스템은 예측 및 분류 결과의 오차를 지속적으로 축적하고 이를 바탕으로 재학습을 진행해야 하며, 이 과정에서 과도한 컴퓨팅 자원과 시간, 그리고 사람의 개입이 필요합니다. 이러한 한계로 인해 실시간 시스템에 적용하기 어려운 문제가 존재합니다. 본 발명은 PID 제어기를 통해 예측 결과의 오차를 실시간으로 반영함으로써, 인공지능 모델의 예측 및 분류 결과의 신뢰성을 높이고 자원의 효율성을 극대화하여 신속한 의사결정을 가능하게 합니다.\n\n【기술 차별성】\n본 발명은 기존의 기계 학습 기술과 차별화된 점에서, PID 제어기를 활용하여 오차 정보를 실시간으로 조정하는 혁신적인 접근 방식을 제시합니다. 기존 기술이 의존하던 재학습 방식과 달리, 본 시스템은 동적인 환경에서도 신속하게 반응하여 오차를 수정함으로써, 예측의 정확성을 지속적으로 개선할 수 있습니다. 이러한 기술적 차별성은 인공지능 시스템의 효율성을 높이는 동시에, 다양한 산업 분야에서의 실시간 데이터 처리 및 의사결정 과정에 큰 변화를 가져올 것으로 기대됩니다.\n\n【활용 분야】\n활용 분야  \n본 발명의 PID 제어기를 이용한 인공지능 시스템은 다양한 분야와 산업에서 광범위하게 활용될 수 있습니다. 특히, 제조업의 자동화 시스템, 자율주행차, 스마트 팩토리, 헬스케어 데이터 분석, 금융 서비스 및 예측 모델링 등에서 높은 정밀도와 신뢰성을 요구하는 애플리케이션에 최적화되어 있습니다. 또한, 실시간 데이터 처리와 오차 교정을 통해 AI 모델의 성능을 지속적으로 향상시킬 수 있어, 경쟁력이 중요한 산업에서 그 가치를 더욱 발휘할 것입니다.\n\n【구성 요소 및 기능】\n구성 요소 및 기능  \n1. 학습부: 본 시스템의 학습부는 입력된 훈련 데이터를 정규화하고 특성을 추출하여 학습 데이터를 도출합니다. 이 과정은 AI 모델의 기초를 형성하며, 다양한 데이터 유형에 대한 적응력을 제공합니다.  \n2. 데이터입력부: 실시간 데이터를 처리하기 위한 데이터입력부는 모델이 예측 또는 분류하고자 하는 데이터를 수집하여 시스템에 전달합니다. 이를 통해 사용자는 실시간으로 변화하는 환경에 신속하게 대응할 수 있습니다.  \n3. PID 제어기: PID 제어기는 처리부에서 출력되는 예측 및 분류 데이터의 오차 정보를 기반으로 실시간으로 결과를 미세 조정합니다. 이 기능은 AI 모델의 정확도를 개선시키고, 과도한 컴퓨팅 자원의 사용을 줄여 효율성을 극대화합니다.\n\n【구현 방식 예】\n구현 방식  \n본 시스템은 다음과 같은 단계로 구현됩니다. 첫째, 훈련 데이터를 수집한 후 정규화 및 특성 추출을 통해 학습 데이터를 도출하는 전처리 과정을 수행합니다. 둘째, 도출된 학습 데이터를 기반으로 AI 모델을 학습시켜 예측 및 분류 기능을 강화합니다. 셋째, 실시간 데이터 입력부를 통해 새로운 데이터를 지속적으로 수집하고, 처리부에서 이를 분석하여 예측 및 분류 데이터를 생성합니다. 마지막으로, PID 제어기가 오차 정보를 기반으로 실시간으로 결과를 미세 조정하여 최적의 성능을 유지하도록 합니다. 이러한 구현 방식은 시스템의 유연성과 효율성을 보장합니다.", "output": "【발명의 명칭】\nPID 제어기를 이용한 인공지능 시스템\n【기술분야】\n본 발명은 인공지능 처리 과정에서 PID 제어기를 사용하여 정밀도를 높인 PID 제어기를 이용한 인공지능 시스템 에 관한 것이다.\n【배경기술】\n기계 학습(machine learning)은 인공 지능의 한 분야로 컴퓨터가 학습을 하여 정보를 검출, 분류, 예측할 수 있 도록 하는 기술 분야이다. 이미 여러 분야에서 많이 응용되고 있으며, 특히 예측(prediction)과 분류(classification)를 위한 다양한 분야 에 활용되고 있다. 이러한 기계 학습의 핵심은 일반화(generalization)와 표현(representation)에 있다. 일반화란 아직 알 수 없는 데이터에 대한 처리를 어떠한 특징(feature)을 이용하여 어느 수준으로 스케일링하여 입력 데이터로 이용할 것 인지 이고, 표현이란 출력된 데이터의 평가를 어떻게 나타낼 것인가 이다. 이렇게 적절한 일반화와 표현을 통해 만들어진 입력 데이터는 학습(training)과 오류 분석(error analysis)을 통해 최적의 모델 하나를 찾게 되며, 선정된 모델(model)은 새로운 데이터를 적용하여 분류 또는 예측 결과를 얻을 수 있게 한다.일반적으로는 예측 및 분류 오차를 지속적으로 축적하고 이를 반영하여 재학습을 통해 새로운 모델을 선정하는 방식으로 예측 및 분류 결과를 재조정하는 기법이 있다. 그러나 이는 재학습 시 과도한 컴퓨팅 자원(메모리, CPU, 저장장치 등)을 다시 필요로 하기 때문에 즉각적인 반 영이 어려우며, 학습 과정에 사람의 개입이 필요한 경우에는 실시간 시스템에 적용이 불가능 하다는 문제가 있 다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허공보 제10-1787411호\n【해결하려는 과제】\n상기와 같은 문제점을 해결하기 위하여 제안된 본 발명은 인공지능 모델의 예측 및 분류 결과에 대한 오차 정보 를 과도한 컴퓨팅 자원의 사용과, 사람의 개입 없이 실시간으로 반영하여 인공지능 모델의 예측 및 분류 결과 오차를 줄일 수 있는 PID 제어기를 이용한 인공지능 시스템을 제공하는데 목적이 있다.\n【과제의 해결 수단】\n상기한 목적을 달성하기 위한 본 발명의 실시예에 따른 PID 제어기를 이용한 인공지능 시스템은 훈련 데이터를 학습하여 모델을 생성하고, 생성된 모델을 이용하여 예측 및 분류 결과를 도출하되, 예측 및 분류 결과에 대한 오차 정보를 PID 제어기에 입력하여 예측 및 분류 결과를 실시간으로 미세 조정하도록 구성된다.\n【발명의 효과】\n상술한 바와 같이, 본 발명의 실시예에 따른 PID 제어기를 이용한 인공지능 시스템은 인공지능 모델의 예측 및 분류 결과에 대한 오차 정보를 PID 제어기에 입력하여 예측 및 분류 결과를 실시간으로 미세 조정함으로써, 과 도한 컴퓨팅 자원의 사용과, 사람의 개입 없이 실시간으로 반영하여 인공지능 모델의 예측 및 분류 결과 오차를 개선할 수 있다.\n【발명을실시하기위한구체적인내용】\n본 발명의 이점 및 특징, 그리고 그것들을 달성하는 기술 등은 첨부되는 도면들과 함께 상세하게 후술되어 있는 실시예를 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있다. 본 실시예는 본 발명의 개시가 완전하도록 함과 더불어, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공될 수 있다. 한편, 본 명세서에서 사용된 용어들은 실시예를 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 '포함한다(comprise)' 및/또는 '포함하는(comprising)'은 언급된 구성요소, 단계, 동작 및/또는 소자는 하나 이상의 다 른 구성요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 부가적으로, 각 도면에 걸쳐 표시된 동일 참조 부호는 동일 구성 요소를 지칭하며, 본 발명의 설명된 실시예의 논의를 불필요하게 불명료하도록 하는 것을 피하기 위해 공지된 특징 및 기술의 상세한 설명은 생략될 수 있다. 도 1은 본 발명의 실시예에 따른 PID 제어기를 이용한 인공지능 시스템을 개략적으로 나타낸 도면이고, 도 2는 종래의 인공지능 시스템과 본 발명의 실시예에 따른 PID 제어기를 이용한 인공지능 시스템이 적용된 예측 및 분 류 결과를 비교한 그래프이다. 도 1에 도시된 바와 같이, 본 발명의 실시예에 따른 PID 제어기를 이용한 인공지능 시스템은 학습부, 데이 터입력부, 처리부, 예측 및 분류 데이터 저장부, 오차 데이터 저장부 및 PID 제어기 를 포함한다. 상기 학습부는 입력되는 훈련 데이터를 정규화 및 특성을 추출하는 전처리과정을 수행하여 학습 데이터를 도출하고, 도출된 학습 데이터를 학습하여 모델을 구성한다. 이때, 상기 학습부는 도출된 학습 데이터를 학습할 시 오류를 분석하고 이를 반영하여 모델을 구성할 수 있다. 상기 데이터입력부는 예측 또는 분류하고자 하는 실시간 데이터를 입력할 수 있다. 상기 처리부는 학습부에서 구성된 모델을 이용하여 데이터입력부에서 입력되는 실시간 데이터를 처리하는 것으로, 입력되는 실시간 데이터를 예측 및 분류할 수 있다. 상기 예측 및 분류 데이터 저장부는 처리부에서 출력되는 예측 및 분류 데이터가 저장될 수 있다. 상기 오차 데이터 저장부는 처리부에서 처리된 결과 중에서 오차 정보를 수집하여 저장될 수 있다. 상기 PID 제어기는 처리부에서 출력되는 예측 및 분류 데이터를 실시간으로 미세 조정할 수 있다. 여기서, 상기 PID 제어기는 오차 데이터 저장부에서 수집된 오차정보를 토대로 처리부에서 출력 되는 예측 및 분류 데이터를 실시간으로 미세 조정할 수 있다. 이때, 상기 PID 제어기는 피드백(feedback) 제어기의 형태를 가지고 있으며, 제어하고자 하는 대상의 출력 값(output)을 측정하여 이를 원하고자 하는 참조값(reference value) 혹은 설정값(setpoint)과 비교하여 오차 (error)를 계산하고, 이 오차값을 이용하여 제어에 필요한 제어값을 계산하는 구조로 되어 있다. 상기 PID 제어기는 아래의 수학식1과 같이 세 개의 항을 더하여 제어값(MV:manipulated variable)을 계산 하도록 구성이 되어 있다. 수학식 1 이에 따라, 인공지능 모델의 예측 및 분류 결과에 대한 오차 정보를 PID 제어기에 입력하여 예측 및 분류 결과를 실시간으로 미세 조정함으로써, 과도한 컴퓨팅 자원의 사용과, 사람의 개입 없이 실시간으로 반영하여 인공지능 모델의 예측 및 분류 결과 오차를 개선할 수 있다. 도 2는 종래의 인공지능 시스템과 본 발명의 실시예에 따른 PID 제어기를 이용한 인공지능 시스템이 적용된 예 측 결과를 비교한 그래프이다.이때, 도 2를 참조하면, 검은 실선은 실측 값이며, 종래의 인공지능 시스템에 대한 예측 결과는 빨간 실선이고, 본 발명의 실시예에 따른 PID 제어기를 이용한 인공지능 시스템을 적용한 예측 결과는 파란 실선이다. 도 2를 통해 확인할 수 있는 바와 같이, 파란 실선이 빨간 실선에 비하여 검은 실선의 패턴과 더욱 유사하다는 것을 알 수 있다. 즉, 종래의 인공지능 시스템에 대한 예측 결과에 비하여 본 발명의 실시예에 따른 PID 제어기를 이용 한 인공지능 시스템을 적용한 예측 결과가 실측 값과 더욱 유사하다. 아래의 표 1은 종래 인공지능 시스템과 본 발명에 따른 PID 제어기를 이용한 인공지능 시스템을 적용했을 때의 예측 결과 오차를 비교한 것이다. 표 1 구분 평균 오차 RMS 오차 종래 인공지능 시스템 79.59 283.78 본 발명 39.16 260.40 즉, 표 1를 통해 확인할 수 있는 바와 같이, 본 발명의 실시예에 따른 PID 제어기를 이용한 인공지능 시스템은 종래의 인공지능 시스템에 비하여 평균 오차는 79.59에서 39.16으로 RMS 오차는 283.78에서 260.4로 오차가 개 선되는 것을 알 수 있다. 본 명세서에서 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 아울러 본 명세서에서 사용되는 '포함한다' 또는 '포함하는'으로 언급된 구성요소, 단계, 동작 및 소자는 하나 이상의 다른 구성요소, 단계, 동 작, 소자 및 장치의 존재 또는 추가를 의미한다. 이제까지 본 발명에 대하여 그 바람직한 실시예들을 중심으로 살펴보았다. 본 명세서를 통해 개시된 모든 실시 예들과 조건부 예시들은, 본 발명의 기술 분야에서 통상의 지식을 가진 당업자가 독자가 본 발명의 원리와 개념 을 이해하도록 돕기 위한 의도로 기술된 것으로, 당업자는 본 발명이 본 발명의 본질적인 특성에서 벗어나지 않 는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있을 것이다.그러므로 개시된 실시예들은 한정적인 관 점이 아니라 설명적인 관점에서 고려되어야 한다. 본 발명의 범위는 전술한 설명이 아니라 특허청구범위에 나타 나 있으며,그와 동등한 범위 내에 있는 모든 차이점은 본 발명에 포함된 것으로 해석되어야 할 것이다.도면 도면1 도면2\n【요약】본 발명은 인공지능 처리 과정에서 PID 제어기를 사용하여 정밀도를 높인 PID 제어기를 이용한 인공지능 시스템 에 관한 것이다.\n\n【청구항 1】\n입력되는 훈련 데이터를 정규화 및 특성을 추출하는 전처리과정을 수행하여 학습 데이터를 도출하고, 도출된 학습 데이터를 학습하여 모델을 구성하는 학습부;예측 또는 분류하고자 하는 실시간 데이터가 입력되는 데이터입력부;상기 학습부에서 구성된 모델을 토대로 상기 데이터입력부에서 입력되는 실시간 데이터를 처리하여 예측 및 분류 데이터를 출력하는 처리부; 및상기 처리부에서 처리된 결과 중에서 오차 정보를 수집하여 저장하는 오차 데이터 저장부;상기 처리부에서 출력되는 상기 예측 및 분류 데이터에 상기 오차 정보를 토대로 실시간으로 미세 조정하여 출력하는 PID 제어기; 및상기 PID 제어기에서 출력되는 상기 예측 및 분류 데이터를 저장하는 예측 및 분류 데이터 저장부;를 포함하는 PID 제어기를 이용한 인공지능 시스템.\n【청구항 2】\n제1항에 있어서,상기 학습부는 상기 학습 데이터를 학습할 시 오류를 분석하고, 분석된 오류를 수정한 학습 데이터를 반영하여 모델을 구성하는 PID 제어기를 이용한 인공지능 시스템."}
{"context": "", "input": "【기술명】\n부호형 비트 슬라이스 생성기 및 그 방법과, 부호형 비트 슬라이스 연산기와, 이들을 적용한 시스템\n\n【기술 설명】\n본 발명은 인공지능 신경망을 가속하기 위한 부호형 비트 슬라이스 생성기 및 그 방법, 부호형 비트 슬라이스 연산기로 구성된 기술입니다. 이 기술은 N 비트 정밀도를 가지는 2의 보수 데이터를 M 비트 슬라이스로 나누어 각 비트 슬라이스가 동일 길이의 부호형 비트 슬라이스를 생성하는 장치 및 방법을 포함합니다. 또한, 생성된 부호형 비트 슬라이스를 활용하여 곱셈, 덧셈, 데이터 스키핑 연산을 수행하며, 데이터 압축 및 전력 효율성을 극대화하는 데이터 관리 유닛과 통합된 아키텍처를 제공합니다.\n\n【해결 문제】\n본 기술은 기존의 비트 슬라이스 연산에서 발생하는 부호 연장 문제를 해결하며, 이는 연산기의 면적을 줄이고 효율성을 높이는 데 기여합니다. 또한, 부호형 비트 슬라이스의 LSB에 부호비트를 더하고 인접한 슬라이스의 부호비트에서 빼는 과정을 통해 0값 비트를 증가시킴으로써, 희소 데이터 압축률을 높이고 연산 속도를 향상시킵니다. 이러한 기능은 인공지능 신경망의 연산 성능을 획기적으로 개선할 수 있는 필요성을 충족시키며, 전력 소모를 낮추어 지속 가능한 기술 발전에 기여합니다.\n\n【기술 차별성】\n본 기술의 차별성은 부호형 비트 슬라이스의 생성 및 연산 과정에서 기존의 비트 슬라이스 기술과 비교해 보다 효율적인 데이터 처리 방식을 채택했다는 점입니다. 특히, 양수 및 음수 비트 슬라이스의 수를 대칭적으로 조정하여 추측 오차를 줄임으로써 인공지능 신경망의 정확도를 향상시키는 혁신적인 접근을 구현합니다. 이러한 독창적인 기술은 비트 슬라이스 연산의 성능을 극대화하고, 전력 효율성을 높이며, 인공지능 분야에서의 경쟁력을 강화하는 데 기여합니다.\n\n【활용 분야】\n본 발명은 인공지능 신경망의 성능을 극대화하기 위한 기술로, 머신러닝 및 딥러닝 분야에서 광범위하게 활용될 수 있습니다. 특히, 대규모 데이터 처리 및 실시간 분석이 요구되는 자율주행차, 스마트 팩토리, 의료 진단 시스템, 그리고 금융 데이터 분석과 같은 산업에서 그 효용이 극대화될 것입니다. 이 기술은 입력 데이터의 희소성을 효과적으로 관리하여 연산 속도를 향상시키고, 전력 소모를 줄일 수 있어, 고성능 컴퓨팅 환경에서 경쟁력을 확보하는 데 기여할 것입니다.\n\n【구성 요소 및 기능】\n본 발명은 세 가지 주요 구성 요소로 이루어져 있습니다. 첫째, **부호형 비트 슬라이스 생성유닛**은 N 비트 정밀도를 가진 2의 보수 데이터를 받아들이고, 부호 비트를 제외한 나머지 비트를 소정 개수의 비트 슬라이스로 분할한 후 각 비트 슬라이스에 부호 비트를 추가하여 동일 길이의 부호형 비트 슬라이스를 생성합니다. 둘째, **스키핑 연산 유닛**은 생성된 비트 슬라이스의 곱셈 및 덧셈 연산과 비트 슬라이스 단위의 데이터 스키핑 연산을 수행하여, 연산 속도를 최적화합니다. 셋째, **축적 유닛**은 스키핑 연산 유닛의 결과를 외부 제어 명령에 따라 축적하고 저장하여, 전체 시스템의 연산 효율성을 극대화합니다.\n\n【구현 방식 예】\n본 발명은 다음과 같은 단계로 구현됩니다. 첫째, 입력 데이터를 수집하고, 데이터 관리 유닛을 통해 부호 비트를 제외한 나머지 비트를 소정 개수의 비트 슬라이스로 분할합니다. 둘째, 각 비트 슬라이스에 부호 비트를 추가하고, 최상위 비트 슬라이스의 부호 비트를 입력 데이터의 부호값으로 설정합니다. 셋째, 스키핑 연산 유닛을 통해 부호형 비트 슬라이스의 연산을 수행하며, 이 과정에서 데이터 압축 및 희소 데이터 관리를 통해 연산 속도를 향상시킵니다. 마지막으로, 축적 유닛을 통해 연산 결과를 저장하고, 이를 바탕으로 인공지능 신경망의 정확도를 높이는 과정을 반복적으로 수행하여 최적의 성능을 달성합니다.", "output": "【발명의 명칭】\n부호형 비트 슬라이스 생성기 및 그 방법과, 부호형 비트 슬라이스 연산기와, 이들을 적용한\n【기술분야】\n본 발명은 인공지능 신경망을 가속하기 위한 기술에 관한 것으로서, 보다 상세하게는, 부호형 비트 슬라이스 (Signed Bit-slice)를 생성하는 장치 및 그 방법과, 상기 방법으로 생성된 부호형 비트 슬라이스를 연산하기 위 한 부호형 비트 슬라이스 연산기, 및 이를 적용한 인공지능 신경망 가속장치에 관한 것이다.\n【배경기술】\n발명의 내용\n【해결하려는 과제】\n따라서 본 발명에서는, N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터를 M(이 때, M은 자연수 이고, M < N 임) 비트 슬라이스로 나눌 때, 각 비트 슬라이스가 모두 부호 비트를 가지는 동일 길이의 부호형 비트 슬라이스를 생성함으로써, 비트 슬라이스의 곱셈 및 축적연산(MAC: multiply and accumulate)시 부호 연장 을 하지 않아도 되고, 이로 인해 비트 길이가 연장된 연산기를 사용하지 않음으로써 연산로직의 면적을 줄일 수 있는 장치 및 방법을 제공하고자 한다. 또한, 본 발명은, 전체 길이 데이터의 부호비트 값을, 각 부호형 비트 슬라이스의 LSB에 더한 후 바로 하위에 인접한 부호형 비트 슬라이스의 부호비트에서 빼는 과정을 반복함으로써, 상기 부호형 비트 슬라이스들 각각에 서 0값을 갖는 비트수를 증가시키고, 이로 인해 희소 데이터 압축시 데이터 압축률을 높이고, 희소 데이터 스키 핑 연산시 연산 속도를 향상시킴과 동시에 전력 소모를 낮출 수 있는 장치 및 방법을 제공하고자 한다. 또한, 본 발명은 상기 부호형 비트 슬라이스를 연산함으로써, 2의 보수데이터에서 0값 근처의 양수데이터와 0값 근처의 음수데이터 모두의 희소성을 활용할 수 있고, 이로 인해, 희소 데이터 압축시 데이터 압축률을 높이고, 희소 데이터 스키핑 연산시 연산 속도를 향상시킴과 동시에 전력 소모를 낮출 수 있는 장치 및 방법을 제공하고 자 한다. 또한, 본 발명은 상기 부호형 비트 슬라이스의 값이 대칭이 되도록 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 함으로써, 상위 비트 슬라이스 연산을 통한 출력값 추측 오차를 줄이고, 이로 인해 추측 연산으로 인한 인공지능 신경망의 정확도를 향상시킬 수 있는 부호형 비트 슬라이스 연산기, 및 이를 적용 한 인공지능 신경망 가속장치를 제공하고자 한다. 또한, 본 발명은 희소 입력 스키핑 연산을 통해 상위 비트 슬라이스 연산을 수행하고 그 결과값을 바탕으로 최 종 출력값의 크기를 추측한 후 하위 비트 슬라이스 연산시 추측된 희소 출력 위치에 해당하는 입력값들을 희소 화함으로써, 희소 입력 비트 슬라이스와 희소 출력 데이터 연산을 동시에 스키핑 연산하고, 이로 인해 연산속도 를 향상시킬 수 있는 인공지능 신경망 가속장치를 제공하고자 한다. 또한, 본 발명은 희소 출력 위치에 해당하는 입력값들을 희소화시켜 연산하기 때문에, 희소 입력 비트 슬라이스 압축과 희소 출력 데이터 압축 방식을 통일시킬 수 있고, 이로 인해 연산 속도를 향상시킬 수 있는 인공지능 신 경망 가속장치를 제공하고자 한다. 또한, 본 발명은 동일 개수의 입력 데이터와 가중치 데이터를 불러와 곱셈 및 축적연산을 수행함으로써 입력데 이터와 가중치 데이터 간의 스키핑 전환이 용이하고, 이로 인해 입력 데이터와 가중치 데이터 중 더욱 희소한 데이터를 스키핑하여 인공지능 신경망 연산을 가속화함으로써, 인공지능 신경망 연산 속도를 향상시킬 수 있는 인공지능 신경망 가속장치를 제공하고자 한다.\n【과제의 해결 수단】\n상술한 목적을 달성하기 위해, 본 발명에서 제공하는 인공지능 신경망 가속장치는 N(이 때, N은 자연수 임) 비 트 정밀도를 가지는 2의 보수데이터인 입력데이터로부터 소정개의 부호형 비트 슬라이스를 생성한 후 압축 관리 하는 데이터 관리 유닛(DMU Core); 상기 부호형 비트 슬라이스의 곱셈 및 덧셈 연산과, 비트 슬라이스 단위의 데이터 스키핑 연산을 수행하는 스키핑 연산 유닛(Zero-slice-skip PE); 및 외부 제어 명령에 의해, 상기 스키 핑 연산 유닛(Zero-slice-skip PE)의 연산결과를 축적하여 저장하는 축적유닛(Accumulation Unit)을 포함하는 것을 특징으로 한다. 바람직하게, 상기 데이터 관리 유닛(DMU Core)은 상기 부호형 비트 슬라이스를 생성하는 부호형 비트 슬라이스 생성유닛(SBR Unit); 및 상기 부호형 비트 슬라이스를 압축하는 부호형 비트 슬라이스 압축유닛(RLE Unit)을 포 함하되, 상기 부호형 비트 슬라이스 생성유닛(SBR Unit)은 N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데이터를 분할하되, 상기 입력데이터의 부호비트를 제외한 나머지 비트들을 소정개의 비트 슬 라이스로 분할하는 분할부; 상기 비트 슬라이스 마다 부호비트를 추가하는 부호비트 추가부; 및 상기 비트 슬라 이스들 중 최상위 비트 슬라이스의 부호비트를 상기 입력데이터의 부호값으로 설정하고, 나머지 비트 슬라이스 들의 부호비트를 양의 부호값으로 설정하는 부호값설정부를 포함할 수 있다. 바람직하게, 상기 스키핑 연산 유닛(Zero-slice-skip PE)은 상기 데이터 관리 유닛(DMU Core)으로부터 압축된 부호형 비트 슬라이스인 입력 비트 슬라이스를 전달받아 저장하는 입력버퍼(IBUF); 상기 입력 비트 슬라이스의저장 위치인 압축 인덱스를 저장하는 인덱스버퍼(IDXBUF); 상기 부호형 비트 슬라이스로 구현된 가중치 데이터 를 저장하는 가중치버퍼(WBUF); 상기 압축 인덱스에 의거하여, 가중치 데이터를 불러와야 할 상기 가중치버퍼 (WBUF)의 주소를 계산하는 스키핑부(Zero-skip Unit); 및 다수의 부호형 비트 슬라이스 연산기들을 포함하고, 상기 입력버퍼(IBUF)로부터 입력 비트 슬라이스를 읽어오고, 상기 스키핑부(Zero-skip Unit)에서 계산된 주소 정보에 의해 상기 가중치버퍼(WBUF)로부터 가중치 데이터를 읽어와서 곱셈 및 축적 연산을 수행하는 연산기 어 레이를 포함할 수 있다. 상기 부호형 비트 슬라이스 연산기는 상기 입력 비트 슬라이스와 상기 가중치 데이터에 대하여 순차적으로 곱셈 연산을 수행하는 곱셈연산기; 상기 곱셈연산기의 연산결과를 누적하는 덧셈연산기; 및 상기 덧셈연산기의 연산 결과를 저장하는 레지스터를 포함할 수 있다. 상기 인공지능 신경망 가속장치는 상기 입력 데이터와 상기 가중치 데이터의 희소성을 비교하고 상기 입력 데이 터 보다 상기 가중치 데이터의 희소성이 더 높을 경우, 가중치 스키핑 연산을 수행하도록 상기 데이터 관리 유 닛(DMU Core), 상기 스키핑 연산 유닛(Zero-slice-skip PE), 및 상기 축적유닛(Accumulation Unit)의 동작을 제어하는 가중치 스키핑 연산 컨트롤러를 더 포함할 수 있다. 한편, 본 발명에서 제공하는 비트 슬라이스 생성방법은, 비트 슬라이스 생성기가, N(이 때, N은 자연수 임) 비 트 정밀도를 가지는 2의 보수데이터인 입력데이터를 분할하되, 상기 입력데이터의 부호비트를 제외한 나머지 비 트들을 소정개의 비트 슬라이스로 분할하는 분할단계; 상기 비트 슬라이스 생성기가, 상기 비트 슬라이스마다 부호비트를 추가하는 부호비트추가단계; 상기 비트 슬라이스 생성기가, 상기 비트 슬라이스들 중 최상위 비트 슬라이스의 부호비트를 상기 입력데이터의 부호값으로 설정하고, 나머지 비트 슬라이스들의 부호비트를 양의 부 호값으로 설정하는 부호설정단계; 및 상기 비트 슬라이스 생성기가, 상기 부호형 비트 슬라이스들 각각에 대하 여 희소 데이터 압축을 실시하는 희소데이터 압축단계를 포함하는 것을 특징으로 한다.\n【발명의 효과】\n이상에서 설명한 바와 같이, 본 발명은 N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터를 M(이 때, M은 자연수이고, M < N 임) 비트 슬라이스로 나눌 때, 각 비트 슬라이스가 모두 부호 비트를 가지는 동일 길이의 부호형 비트 슬라이스를 생성함으로써, 비트 슬라이스의 곱셈 및 축적연산(MAC: multiply and accumulate)시 부호 연장을 하지 않아도 되도록 하고, 이로 인해 비트 길이가 연장된 연산기를 사용하지 않음으 로써 연산로직의 면적을 줄일 수 있는 장점이 있다. 또한, 본 발명은, 전체 길이 데이터의 부호비트 값을, 각 부호형 비트 슬라이스의 LSB에 더한 후 바로 하위에 인접한 부호형 비트 슬라이스의 부호비트에서 빼는 과정을 반복함으로써, 상기 부호형 비트 슬라이스들 각각에 서 0값을 갖는 비트수를 증가시키고, 이로 인해 희소 데이터 압축시 데이터 압축률을 높이고, 희소 데이터 스키 핑 연산시 연산 속도를 향상시킴과 동시에 전력 소모를 낮출 수 있는 장점이 있다. 또한, 본 발명은 상기 부호형 비트 슬라이스를 연산함으로써, 2의 보수데이터에서 0값 근처의 양수데이터와 0값 근처의 음수데이터 모두의 희소성을 활용할 수 있고, 이로 인해, 희소 데이터 압축시 데이터 압축률을 높일 수 있으며, 희소 데이터 스키핑 연산시 연산 속도를 향상시킴과 동시에 전력 소모를 낮출 수 있는 장점이 있다. 또한, 본 발명은 상기 부호형 비트 슬라이스의 값이 대칭이 되도록 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 함으로써, 상위 비트 슬라이스 연산을 통한 출력값 추측 오차를 줄이고, 이로 인해 추측 연산으로 인한 인공지능 신경망의 정확도를 향상시킬 수 있는 장점이 있다. 또한, 본 발명은 희소 입력 스키핑 연산을 통해 상위 비트 슬라이스 연산을 수행하고 그 결과값을 바탕으로 최 종 출력값의 크기를 추측한 후 하위 비트 슬라이스 연산시 추측된 희소 출력 위치에 해당하는 입력값들을 희소 화함으로써, 희소 입력 비트 슬라이스와 희소 출력 데이터 연산을 동시에 스키핑 연산하고, 이로 인해 연산속도 를 향상시킬 수 있는 장점이 있다. 또한, 본 발명은 희소 출력 위치에 해당하는 입력값들을 희소화시켜 연산하기 때문에, 희소 입력 비트 슬라이스 압축과 희소 출력 데이터 압축 방식을 통일시킬 수 있고, 이로 인해 연산 속도를 향상시킬 수 있는 장점이 있다. 또한, 본 발명은 동일 개수의 입력 데이터와 가중치 데이터를 불러와 곱셈 및 축적연산을 수행함으로써 입력데 이터와 가중치 데이터 간의 스키핑 전환이 용이하고, 이로 인해 입력 데이터와 가중치 데이터 중 더욱 희소한 데이터를 스키핑하여 인공지능 신경망 연산을 가속화함으로써, 인공지능 신경망 연산 속도를 향상시킬 수 있는장점이 있다.\n【발명을실시하기위한구체적인내용】\n도 5의 ⒟는 상기 과정을 거쳐 생성된 두 개의 비트 슬라이스를 예시하고 있다. 도 5의 ⒟를 참조하면, 상기 두 개의 비트 슬라이스들은 모두 4비트 길이에 부호를 가지게 된다. 특히, 상위 비트 슬라이스의 경우 도 5의 ⒞에 예시된 과정을 거치면서, 1111가 0000로 변환되어 0값 비트 슬라이스(일명, Zero-slice)가 된다. 이와 같이, 상위 비트인 1111 값이 0000값으로 변환되는 부호형 비트 슬라이스의 특성으로 인해, 본 발명은 상 위 비트가 1111 값을 가지는 0값 근처의 음수데이터의 희소성을 활용할 수 있게 되고, 결과적으로 2의 보수데이 터에서 0값 근처의 양수데이터와 0값 근처의 음수데이터 모두의 희소성을 활용할 수 있게 된다. 이를 수학식으로 나타내면 수학식 4에 예시된 바와 같다. 수학식 4 아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시 예에 대하여 설명하되, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 발명을 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 한편 도면에서 본 발명을 명확 하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유 사한 도면 부호를 붙였다. 또한 상세한 설명을 생략하여도 본 기술 분야의 당업자가 쉽게 이해할 수 있는 부분 의 설명은 생략하였다. 명세서 및 청구범위 전체에서, 어떤 부분이 어떤 구성 요소를 포함한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 도 1은 본 발명의 일 실시 예에 따른 인공지능 신경망 가속장치에 대한 개략적인 블록도이다. 도 1을 참조하면, 본 발명의 일 실시 예에 따른 인공지능 신경망 가속장치는 데이터 관리 유닛(DMU Core), 스키핑 연산 유닛 (Zero-slice-skip PE), 및 축적유닛(Accumulation Unit)을 포함한다. 데이터 관리 유닛(DMU Core)은 N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데이 터로부터 소정개의 부호형 비트 슬라이스를 생성한 후 압축 관리한다. 이를 위해, 데이터 관리 유닛(DMU Core)은 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit), 메모리(Global Memory), 및 출 력 바이너리 마스크(Output Binary Mask) 유닛을 포함할 수 있다. 이 때, 상기 부호형 비트 슬라이스(Signed Bit-slice)는 부호비트를 포함하고, 동일한 비트수를 가지는 비트 슬 라이스를 말하며, 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit)은 상기 부호형 비트 슬라이스를 생 성한 후 압축한다. 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit)의 구성이 도 2에 예시되어 있다. 도 2는 본 발명의 일 실시 예에 따른 부호형 비트 슬라이스 생성/압축 유닛에 대한 개략적인 블록도로서, 도 2 를 참조하면, 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit)는 부호형 비트 슬라이스를 생성하는 부 호형 비트 슬라이스 생성유닛(SBR Unit)과 부호형 비트 슬라이스 압축유닛(RLE unit)으로 구성되며, 부 호형 비트 슬라이스 생성유닛(SBR Unit)는 분할부, 부호비트 추가부, 부호값 설정부, 및 부호 비트 연산부를 포함하고, 부호형 비트 슬라이스 압축유닛(RLE unit)는 희소데이터 압축부를 포함할 수 있다. 분할부는 N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데이터를 분할하되, 상기 입력데이터의 부호비트를 제외한 나머지 비트들을 소정개의 비트 슬라이스로 분할한다. 예를 들어, 분할부 는 7비트 정밀도를 가지는 2의 보수데이터의 경우, 부호를 나타내는 MSB 비트를 제외한 6비트를 2개의 3비트 슬 라이스들, 또는 3개의 2비트 슬라이스로 분할할 수 있다.부호비트 추가부는 분할부에서 분할된 비트 슬라이스들 각각에 부호비트를 추가한다. 분할된 비트 슬라 이스들 중 최상위에 위치하는 비트 슬라이스의 경우, 상기 입력데이터의 부호비트가 존재하므로, 부호비트 추가 부는 최상위의 비트 슬라이스를 제외한 나머지 비트 슬라이스들 모두에 부호비트를 추가한다. 상기 예에서, 7비트의 입력데이터를 2개의 3비트 슬라이스로 분할한 경우, 상위 3비트의 비트 슬라이스에는 입력데이터의 부 호비트가 존재하므로 부호비트 추가부는 하위 3비트의 비트 슬라이스에만 부호비트를 추가한다. 이 경우, 4 비트의 비트 슬라이스가 2개 생성될 것이다. 한편, 7비트의 입력데이터를 2개의 3비트 슬라이스로 분할한 경우, 부호비트 추가부는 최상위 2비트의 비트 슬라이스를 제외한 나머지 2개의 2비트 슬라이스 각각에 부호비트 를 추가한다. 이 경우, 3비트의 비트 슬라이스가 3개 생성될 것이다. 부호값 설정부는 부호비트 추가부에서 추가된 부호비트들 각각의 부호값을 설정한다. 이 때, 소정개의 비트 슬라이스들 중 최상위에 위치한 비트 슬라이스의 부호비트에는 입력데이터의 부호값이 이미 저장되어 있으 므로, 부호값 설정부는 나머지 비트 슬라이스들의 부호비트들 각각의 부호값을 설정하되, 최상위 비트 슬라 이스를 제외한 나머지 비트 슬라이스들은 모두 양수를 나타내므로, 부호값 설정부는 나머지 비트 슬라이스 들의 부호비트들 각각의 부호값을 양의 부호값으로 설정할 수 있다. 부호비트 연산부는 전체 길이 데이터의 부호비트 값을 부호형 비트 슬라이스 각각의 LSB에 더하고, 바로 하 위에 인접한 부호형 비트슬라이스의 부호비트에서 빼는 연산과정을 반복한다. 이는, 상기 부호형 비트 슬라이스 들 각각에서 0값을 갖는 비트수를 증가시키기 위한 것으로서, 부호비트 연산부는 상기 연산과정을 비트 슬 라이스의 수 만큼 반복할 수 있다. 이로 인해, 이러한 비트 슬라이스를 이용한 연산, 또는 인공지능 신경망 가 속시 희소 데이터 압축률 상승 효과를 얻을 수 있게 된다. 한편, 부호비트 연산부는 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 하기 위해, 부호형 비트 슬라이스 값이 미리 설정된 특정값인 경우, 상기 연산과정을 스킵할 수 있다. 즉, 부호비트 연산부 는 부호형 비트 슬라이스 값이 '1000' 인 경우, 상기 연산과정을 스킵할 수 있다. 이는 출력추측법 사용시 출력 추측 오차율을 줄이기 위함이다. 이 때, 상기 ‘출력추측법’이란 출력값이 0인 상황처럼 출력을 추측할 수 있는 인공지능 신경망에서 인공지능 신경망 가속장치의 효율을 향상시키기 위해 통상적으로 수행되는 공지의 기술이다. 따라서, 그 구체적인 처리 과정에 대한 설명은 생략한다. 도 3은 본 발명의 일 실시 예에 따른 부호비트 연산부의 동작을 부연 설명하기 위한 도면으로써, 상기 연산과정 스킵에 의해 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 한 경우(b)와 그렇지 않은 경 우(a)에 대한 오차율을 예시하고 있다. 도 3의 (a)는, '1000' 을 스킵하지 않는 경우, 2의 보수 휠(two's complement Wheel)의 좌우측 대칭이 맞지 않고, 이로 인해, 출력 추측 오차율이 19.9% 임을 예시하고, 도 3의 (b)는, '1000' 을 스킵함으로써 2의 보수 휠(two's complement Wheel)의 좌우측이 대칭을 이루고, 이로 인해, 출력 추측 오차율이 5% 미만임을 예시하고 있다. 희소데이터 압축부는 부호형 비트 슬라이스 생성유닛(SBR Unit)에서 생성된 부호형 비트 슬라이스들 각 각에 대하여 희소 데이터 압축을 실시한다. 이를 위해, 희소데이터 압축부는 런렝스 부호화(Run-Length Encoding) 방식을 적용할 수 있다. 한편, 희소데이터 압축부는 상기 희소 데이터 압축 결과로, 0값이 아닌 데이터와 이 데이터의 위치를 나타 내는 인덱스를 생성한 후, 상기 0값이 아닌 데이터는 후술될 입력버퍼(IBUF)에, 상기 인덱스는 후술될 인 덱스버퍼(IDXBUF)에 각각 저장한다. 이와 같이 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit)이 부호형 비트 슬라이스를 생성하기 위한 처리 과정이 도 4에 예시되어 있다. 도 4는 본 발명의 일 실시 예에 따른 부호형 비트 슬라이스를 생성하는 방법에 대한 처리 흐름도로서, 도 2 및 도 4를 참조하여 본 발명의 일 실시 예에 따른 부호형 비트 슬라이스를 생성하는 방법을 설명하면 다음과 같다. 먼저, 단계 S110에서는, 분할부가 N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데 이터를 분할하되, 상기 입력데이터의 부호비트를 제외한 나머지 비트들을 소정개의 비트 슬라이스로 분할한다. 단계 S120에서는, 부호비트 추가부가 상기 비트 슬라이스마다 부호비트를 추가한다. 단계 S130에서는, 부호값 설정부가 상기 비트 슬라이스들 중 최상위 비트 슬라이스의 부호비트를 상기 입력 데이터의 부호값으로 설정하고, 나머지 비트 슬라이스들의 부호비트를 양의 부호값으로 설정한다. 단계 S140에서는, 부호비트 연산부가 전체 길이 데이터의 부호비트 값을 부호형 비트 슬라이스 각각의 LSB 에 더하고, 바로 하위에 인접한 부호형 비트슬라이스의 부호비트에서 빼는 연산과정을 반복한다. 이는, 상기 부 호형 비트 슬라이스들 각각에서 0값을 갖는 비트수를 증가시키기 위함이다. 한편, 단계 S140에서, 부호비트 연산부는 부호형 비트 슬라이스 값이 미리 설정된 특정값(즉, '1000' )인 경우, 상기 연산과정을 스킵할 수 있다. 이는 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일 하게 함으로써, 출력추측법 사용시 출력 추측 오차율을 줄이기 위함이다. 이와 같은 과정을 거쳐서 생성된 부호형 비트 슬라이스들 각각은, 희소데이터 압축부에서, 희소 데이터 압 축(미도시)을 거쳐 인공지능 신경망 가속장치에 적용될 수 있다. 도 4의 설명에 있어서, 도 2의 장치 설명에 언급된 내용에 대하여는 중복설명을 생략하였다. 도 5는 본 발명의 일 실시 예에 따라 부호형 비트 슬라이스를 생성하는 과정을 예로 들어 설명하기 위한 도면으 로서, 7비트의 2의 보수 데이터(A)인 입력데이터를 본 발명의 일 실시 예에 따른 부호형 비트 슬라이 스로 분할하는 과정을 예로 들어 설명하고 있다. 도 5의 ⒜는 상기 입력데이터가 비트 슬라이스로 분할되기 이전의 상태(즉, 로-데이터(raw data))를 예시하고 있다. 이 때, MSB는 상기 입력데이터의 부호를 나타내는 부호비트이다. 이와 같은 입력데이터를 수학식으로 표 현하면 수학식 1에 예시된 바와 같다. 수학식 1 이와 같은 부호형 비트 슬라이스 표현법은 다양한 비트 길이 정밀도에 다양한 비트 슬라이스 길이로 적용될 수 있다. 먼저, 임의의 2의 보수 N-비트 데이터는 수학식 5에 예시된 바와 같이 표현할 수 있다. 수학식 5 이 때, 는 0 또는 1 값을 가지며, 은 부호 비트를 나타낸다. 한편, 임의의 N-비트(이 때, N은 M, M+(M-1), M+2*(M-1), … ) 데이터 A에 M-비트 (이 때, M은 2, 3, 4, … )슬라이스를 취할 경우, 수학식 6에 예시된 바와 같이 표현할 수 있다. 수학식 6 수학식 6에 예시된 바와 같이 표현된 A 데이터를 부호형 M-비트 슬라이스를 만들기 위해, 수학식 7과 같이 (M- 1) 비트를 묶어서 (N-1)/(M-1)개의 그룹으로 정리할 수 있다. 수학식 7 한편, 수학식 7과 같이 표현된 A 데이터에 부호 비트인 을 각각 비트 슬라이스 그룹에 더하고 빼면 수학식 8과 같이 정리할 수 있다. 수학식 8 이로써 각 비트 슬라이스 그룹에 부호 비트가 추가되었고, M-비트의 부호 비트 슬라이스인 A'를 이용하여 상기 수학식 8을 다시 정리하면 수학식 9에 예시된 바와 같다.수학식 9 이와 같은 수학식 9를 이용하면, 본 발명의 부호형 비트 슬라이스 표현법은 임의의 2의 보수 데이터에 적용 가 능하다. 구체적인 예시로, 2의 보수 데이터 A를 4-비트 (M=4) 슬라이스로 분할하는 경우, 상기 2의 보수 데이터 A는 세 비트 값을 묶어서 정리될 수 있으며, 상기 수학식 6은 다음의 수학식 10과 같이 표현할 수 있다. 수학식 10 이 때, N은 4, 7, 10, 13, … 을 나타낸다. 한편, 상기 수학식 10에 부호 비트인 을 각각 비트 슬라이스 그룹에 더하고 빼면 아래의 수학식 11과 같이 정리할 수 있다. 수학식 11 이로써 각 비트 슬라이스 그룹에 부호 비트가 추가되었고, 4-비트의 부호 비트 슬라이스 A'로 상기 수학식 11을 다시 정리하면 수학식 12와 같다.수학식 12 이와 같이, 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit)은 부호형 비트 슬라이스 표현법을 이용하 여 임의의 2의 보수 데이터를 분할하여 표현할 수 있고, 본 발명의 비트 슬라이스 연산기, 및 인공지능 신경망 가속장치는 이러한 부호형 비트 슬라이스를 이용함으로써, 연산로직의 면적을 줄이고, 결과적으로 하드웨어의 크기를 줄일 수 있으며, 연산속도를 향상시킴과 동시에 전력 소모를 줄일 수 있다. 다시 도 1을 참조하면, 메모리(Global Memory)는 인공지능 신경망을 가속하기 위한 로-데이터(raw data) (즉, 비트 슬라이스로 분할되기 전의 데이터들)를 저장하고, 상기 로-데이터를 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit) 으로 전달함으로써, 부호형 비트 슬라이스를 생성할 수 있도록 한다. 출력 바이너리 마스크(Output Binary Mask) 유닛은 후술될 스키핑 연산 유닛(Zero-slice-skip PE)으 로부터 상위 비트 슬라이스에 대한 스키핑 연산 결과를 입력으로 받아 바이너리 마스크를 생성한다. 이를 위해, 출력 바이너리 마스크 유닛은 상기 스키핑 연산 결과값들 간에 비교 연산을 수행하여 이 값 중 최댓값에 해당하는 값은 1로 표현하고 아닌 값(0값)은 0으로 표현하는 맥스 풀링 출력에 해당하는 바이너리 마스크를 생 성한다. 또한, 출력 바이너리 마스크 유닛은 인공지능 신경망 가속장치에서 출력추측법을 적용시 이를 이 용할 수 있도록, 상기 출력 바이너리 마스크를 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit)으로 전달한다. SBR/RLE Unit(특히, 희소데이터 압축부)은 상기 출력 바이너리 마스크(Output Binary Mask)를 이용하 여 희소 입력 데이터를 새롭게 압축한다. 도 6은 출력 바이너리 마스크를 이용한 희소 입력 스키핑 연산 및 희소 출력 스키핑 연산과정을 예시하고 있다. 도 6을 참조하면, 출력 바이너리 마스크 유닛은 스키핑 연산 유닛(Zero-slice-skip PE)으로부터 상위 비트 슬라이스에 대한 희소 입력 스키핑 연산 결과를 입력으로 받아 4비트의 바이너리 마스크를 생성하고, SBR/RLE Unit(특히, 희소데이터 압축부)은 상기 출력 바이너리 마스크(Output Binary Mask)를 이용하여 희소 입력 데이터를 새롭게 압축하고, 스키핑 연산 유닛(Zero-slice-skip PE)은 상기 새롭게 압축된 희소 입력 데이터를 전달받아 스키핑 연산을 수행한다. 스키핑 연산 유닛(Zero-slice-skip PE)은 상기 부호형 비트 슬라이스의 곱셈 및 덧셈 연산과, 비트 슬라이 스 단위의 데이터 스키핑 연산을 수행한다. 이를 위해, 스키핑 연산 유닛(Zero-slice-skip PE)은 입력버퍼(IBUF), 인덱스버퍼(IDXBUF), 가 중치버퍼(WBUF), 스키핑부(Zero-skip Unit), 및 연산기 어레이를 포함한다. 입력버퍼(IBUF)는 데이터 관리 유닛(DMU Core)으로부터, 압축된 부호형 비트 슬라이스인 입력 비트 슬라이스를 전달받아 저장한다. 인덱스버퍼(IDXBUF)는 상기 입력 비트 슬라이스의 저장 위치인 압축 인덱스를 저장한다. 가중치버퍼(WBUF)는 상기 부호형 비트 슬라이스로 구현된 가중치 데이터를 저장한다. 스키핑부(Zero-skip Unit)는 상기 압축 인덱스에 의거하여, 가중치 데이터를 불러와야 할 상기 가중치버퍼 (WBUF)의 주소를 계산한다. 연산기 어레이는 다수의 부호형 비트 슬라이스 연산기들로 구성되며, 입력버퍼(IBUF)로부터 입 력 비트 슬라이스를 읽어오고, 스키핑부(Zero-skip Unit)에서 계산된 주소 정보에 의해 상기 가중치버퍼 (WBUF)로부터 가중치 데이터를 읽어와서 곱셈 및 축적 연산을 수행한다. 부호형 비트 슬라이스 연산기는 상기 입력 비트 슬라이스와 상기 가중치 데이터에 대하여 순차적으로 곱셈 연산을 수행하는 곱셈연산기, 곱셈연산기의 연산결과를 누적하는 덧셈연산기, 및 덧셈연산기의 연산결과를 저장하는 레지스터를 포함한다. 부호형 비트 슬라이스 연산기는 부호형 비트 슬 라이스 생성/압축 유닛(SBR/RLE Unit)에서 생성된 부호형 비트 슬라이스를 연산하되, 상기 부호형 비트 슬 라이스는 각각 부호비트를 포함하는 동일길이의 데이터이다. 따라서, 본 발명의 부호형 비트 슬라이스 연산기 는 부호를 연장하기 위한 별도의 로직을 추가로 필요로 하지 않고, 비트 길이가 최적화된 로직으로 구현될 수 있다. 도 7은 본 발명의 일 실시 예에 따른 부호형 비트 슬라이스 연산기를 종래의 비트 슬라이스 연산기와 비교하여 설명하기 위한 도면으로서, 도 7의 (a)는 종래의 비트 슬라이스 연산기 구조의 예를 도시하고, 도 7의 (b) 및 (c)는 본 발명의 제1 및 제2 실시 예에 따른 부호형 비트 슬라이스 연산기 구조의 예들을 도시하고 있다. 도 7의 (a)를 참조하면, 종래에는, 부호를 포함하는 상위 비트 슬라이스(BS1)와 부호를 가지지 않는 하위 비트 슬라이스(BS2)를 연산하기 위해, 하위 비트 슬라이스(BS2)에 부호를 가지도록 부호 연장로직이 추가로 필요 하다. 따라서, 4비트의 상위 비트 슬라이스(BS1) 및 하위 비트 슬라이스(BS2)가 부호 연장로직을 통해 각각 5비트 데이터로 연장되어 출력되고, 곱셈연산기, 덧셈연산기, 및 레지스터 각각은 이와 같이 연장 된 데이터에 적합한 크기로 구성되어야 한다. 즉, 상기 예에서, 덧셈연산기는 곱셈연산기로부터 10비트 의 연산결과를 전달받아 연산한 후, 그 누적 연산결과를 레지스터에 저장하되, 레지스터는 15비트 크기 로 구현된다. 한편, 도 7의 (b) 및 (c)를 참조하면, 본 발명의 부호형 비트 슬라이스 연산기는 상위 부호형 비트 슬라이스 (S_BS1)와 하위 부호형 비트 슬라이스(S_BS2)가 모두 부호 비트를 가지고 있으므로 부호 연장 로직이 필요 없으 며, 이로 인해 비트 길이가 최적화된 곱셈연산기(510a, 510b), 덧셈연산기(520a, 520b), 및 레지스터(530a, 530b)를 사용한다. 즉, 도 7의 (b)에 예시된 곱셈연산기(510a)는 4비트의 부호형 비트 슬라이스들(S_BS1, S_BS2)에 대하여 부호 연 장없이 바로 곱셈 연산한 후 8비트의 연산결과를 출력하고, 덧셈연산기(520a)는 상기 8비트의 연산결과를 누적 하여 13비트의 레지스터(530a)에 저장한다. 한편, 도 7의 (c)에 예시된 곱셈연산기(510b)는 4비트의 부호형 비트 슬라이스들(S_BS1, S_BS2)에 대하여 부호 연장없이 바로 곱셈 연산한 후 7비트의 연산결과를 출력하고, 덧셈연산기(520b)는 상기 7비트의 연산결과를 누 적하여 12비트의 레지스터(530b)에 저장하는데, 이는, 출력 추측법 사용시 출력 추측 오차를 줄이기 위해, 상기 부호형 비트 슬라이스 생성시, 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 생성하였기 때문이다. 즉, 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 생성한 경우, 도 3에 예시 된 바와 같이, 부호형 비트 슬라이스 값이 '1000' 인 경우가 발생하지 않기 때문에, 7비트로 모든 데이터를 표 현할 수 있기 때문이다. 한편, 스키핑 연산 유닛(Zero-slice-skip PE)은 상기 부호형 비트 슬라이스를 이용하여 비트 슬라이스 단 위의 데이터 스키핑 연산을 수행하되, 연속된 여러 비트 슬라이스 데이터가 모두 0값일 경우 스키핑 연산을 수 행한다. 이 때, 데이터 스키핑 연산을 위한 처리 과정은 공지의 기술을 이용할 수 있으므로, 구체적인 설명은 생략한다. 축적유닛(Accumulation Unit)은 스키핑 연산 유닛(Zero-slice-skip PE)의 연산결과를 축적하여 저장 한다. 이를 위해, 축적유닛(Accumulation Unit)은 축적연산을 위한 덧셈트리(Adder Tree), 비트 슬 라이스들의 연산위치를 결정하기 위해 비트-쉬프트를 수행하는 비트 쉬프터(Bit-shifter), 출력 데이터를 버퍼링하는 출력버퍼(OBUF), 및 쓰기컨트롤러(Write Ctrlr)를 포함하고, 외부 제어명령 (Instruction)에 의해 동작할 수 있다. 예를 들어, 축적유닛(Accumulation Unit)은 탑-콘트롤러(top controller)(미도시)로부터 전달된 제어명령(Instruction)에 의해, 상기 연산결과를 축적하여 저장할 수 있다. 한편, 본 발명의 인공지능 신경망 가속장치는 입력 데이터와 가중치 데이터의 희소성을 비교하고, 상기 입력 데 이터 보다 상기 가중치 데이터의 희소성이 더 높을 경우 가중치 스키핑 연산을 수행하도록 동작할 수 있는데, 이를 위해, 본 발명의 인공지능 신경망 가속장치는, 상기 가중치 스키핑 연산을 제어하는 가중치 스키핑 연산 컨트롤러(미도시)를 더 포함할 수 있다. 상기 가중치 스키핑 연산 컨트롤러는 상기 입력 데이터와 상기 가중치 데이터의 희소성을 비교하여 상기 입력 데이터 보다 상기 가중치 데이터의 희소성이 더 높을 경우, 가중치 스키핑 연산을 수행하도록 상기 데이터 관리 유닛(DMU Core), 상기 스키핑 연산 유닛(Zero-slice-skip PE), 및 상기 축적유닛(Accumulation Unit)의 동작을 제어할 수 있다.즉, 입력 데이터 보다 가중치 데이터의 희소성이 더 높은 경우, 상기 가중치 스키핑 연산 컨트롤러는 상기 가중 치 데이터를 압축하여 압축된 부호형 비트 슬라이스인 가중치 비트 슬라이스를 출력하도록 상기 데이터 관리 유 닛(DMU Core)을 제어하고, 상기 가중치 비트 슬라이스를 입력버퍼(IBUF)에 저장하고, 상기 가중치 비트 슬라이 스의 저장 위치인 압축 인덱스를 인덱스 버퍼에 저장하고, 상기 부호형 비트 슬라이스로 구현된 입력데이터를 가중치 버퍼(WBUF)에 저장하도록 상기 스키핑 연산 유닛(Zero-slice-skip PE)을 제어하고, 상기 스키핑 연산 유 닛(Zero-slice-skip PE)의 출력데이터를 재정렬하여 출력버퍼(OBUF)에 저장하도록 상기 축적유닛(Accumulation Unit)의 동작을 제어할 수 있다. 이 때, 가중치 스키핑 연산 컨트롤러는 ‘부호형 비트 슬라이스로 구현된 입력 데이터(압축전)’와 ‘부호형 비 트 슬라이스로 구현된 가중치 데이터(압축전)’의 희소성을 비교한다. 즉, 가중치 스키핑 연산 컨트롤러는 입력 데이터와 가중치 데이터를 부호형 비트 슬라이스로 표현한 후 이를 압축할 때 상기 희소성 비교에 의해 희소 연 산 대상을 결정할 수 있다. 특히, 가중치 스키핑 연산 컨트롤러는 심층 신경망의 레이어 별로, 입력 데이터 전 체와 가중치 데이터 전체의 희소성을 비교하는 것이 아닌, 데이터 일부만 비교하여 해당 레이어의 희소 연산 대 상을 결정한다. 상기 입력 데이터와 가중치 데이터는 모두 DMU 코어의 메모리(Global Memory)에 저장 되어 있으며, 이 위치는 탑-컨트롤러(top controller)(즉, 중앙처리장치)가 알고 있다. 도 8은 본 발명의 일 실시 예에 따른 가중치 스키핑 연산 과정을 설명하기 위한 도면으로서, 도 8의 (a)는 일반 적인 데이터 스키핑 연산(즉, 입력데이터의 스키핑 연산) 과정을 예시하고, 도 8의 (b)는 가중치 스키핑 연산 과정을 예시한다. 도 8의 (a)를 참조하면, 입력데이터의 스키핑 연산을 위해, 스키핑 연산 유닛(Zero-slice-skip PE)은 입력 데이터(I)를 입력버퍼(IBUF)에, 압축 인덱스를 인덱스버퍼에, 가중치데이터(W)를 가중치버퍼에 각각 저장한 후, 연산기 어레이에서 이들을 연산한다. 그리고, 그 결과를 출력버퍼에 저장한다. 도 8의 (b)를 참조하면, 가중치데이터의 스키핑 연산을 위해, 스키핑 연산 유닛(Zero-slice-skip PE)은 가 중치데이터(W)를 입력버퍼(IBUF)(210a)에, 가중치데이터(W)의 압축인덱스를 인덱스버퍼(220a)에, 입력데이터 (I)를 가중치버퍼(230a)에 각각 저장한 후, 연산기 어레이(250a)에서 이들을 연산한다. 한편, 축적유닛 (Accumulation Unit)의 쓰기 컨트롤러(Write Ctrlr)는 상기 연산결과를 재정렬(260a)한 후 출력버퍼 에 저장한다. 이로 인해, 본 발명은 입력 데이터와 가중치 데이터 중 더욱 희소한 데이터를 스키핑하여 인공지능 신경망 연산 을 가속화함으로써, 인공지능 신경망 연산 속도를 더욱 효율적으로 향상시킬 수 있다. 상기한 바와 같이, 본 발명은 N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터를 M(이 때, M은 자연수이고, M < N 임) 비트 슬라이스로 나눌 때, 각 비트 슬라이스가 모두 부호 비트를 가지는 동일 길이의 부 호형 비트 슬라이스를 생성함으로써, 비트 슬라이스의 곱셈 및 축적연산(MAC: multiply and accumulate)시 부호 연장을 하지 않아도 되도록 하고, 이로 인해 비트 길이가 연장된 연산기를 사용하지 않음으로써 연산로직의 면 적을 줄일 수 있는 특징이 있다. 또한, 본 발명은, 전체 길이 데이터의 부호비트 값을, 각 부호형 비트 슬라이스의 LSB에 더한 후 바로 하위에 인접한 부호형 비트 슬라이스의 부호비트에서 빼는 과정을 반복함으로써, 상기 부호형 비트 슬라이스들 각각에 서 0값을 갖는 비트수를 증가시키고, 이로 인해 희소 데이터 압축시 데이터 압축률을 높이고, 희소 데이터 스키 핑 연산시 연산 속도를 향상시킴과 동시에 전력 소모를 낮출 수 있는 특징이 있다. 또한, 본 발명은 상기 부호형 비트 슬라이스를 연산함으로써, 2의 보수데이터에서 0값 근처의 양수데이터와 0값 근처의 음수데이터 모두의 희소성을 활용할 수 있고, 이로 인해, 희소 데이터 압축시 데이터 압축률을 높일 수 있으며, 희소 데이터 스키핑 연산시 연산 속도를 향상시킴과 동시에 전력 소모를 낮출 수 있는 특징이 있다. 또한, 본 발명은 상기 부호형 비트 슬라이스의 값이 대칭이 되도록 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 함으로써, 상위 비트 슬라이스 연산을 통한 출력값 추측 오차를 줄이고, 이로 인해 추측 연산으로 인한 인공지능 신경망의 정확도를 향상시킬 수 있는 특징이 있다. 또한, 본 발명은 희소 입력 스키핑 연산을 통해 상위 비트 슬라이스 연산을 수행하고 그 결과값을 바탕으로 최 종 출력값의 크기를 추측한 후 하위 비트 슬라이스 연산시 추측된 희소 출력 위치에 해당하는 입력값들을 희소 화함으로써, 희소 입력 비트 슬라이스와 희소 출력 데이터 연산을 동시에 스키핑 연산하고, 이로 인해 연산속도 를 향상시킬 수 있는 특징이 있다. 또한, 본 발명은 희소 출력 위치에 해당하는 입력값들을 희소화시켜 연산하기 때문에, 희소 입력 비트 슬라이스 압축과 희소 출력 데이터 압축 방식을 통일시킬 수 있고, 이로 인해 연산 속도를 향상시킬 수 있는 특징이 있다. 또한, 본 발명은 동일 개수의 입력 데이터와 가중치 데이터를 불러와 곱셈 및 축적연산을 수행함으로써 입력데 이터와 가중치 데이터 간의 스키핑 전환이 용이하고, 이로 인해 입력 데이터와 가중치 데이터 중 더욱 희소한 데이터를 스키핑하여 인공지능 신경망 연산을 가속화함으로써, 인공지능 신경망 연산 속도를 향상시킬 수 있는 특징이 있다. 이상의 설명에서는 본 발명의 바람직한 실시예를 제시하여 설명하였으나, 본 발명이 반드시 이에 한정되는 것은 아니며, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자라면 본 발명의 기술적 사상을 벗어나지 않는 범위 내에서 여러 가지 치환, 변형 및 변경할 수 있음을 쉽게 알 수 있을 것이다.\n【요약】본 발명의 부호형 비트 슬라이스 생성기는 N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입 력데이터를 분할하되, 상기 입력데이터의 부호비트를 제외한 나머지 비트들을 소정개의 비트 슬라이스로 분할하 는 분할부; 상기 비트 슬라이스 마다 부호비트를 추가하는 부호비트 추가부; 상기 비트 슬라이스들 중 최상위 비 (뒷면에 계속)\n\n【청구항 1】\nN(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데이터를 분할하되, 상기 입력데이터의부호비트를 제외한 나머지 비트들을 소정개의 비트 슬라이스로 분할하는 분할부;상기 비트 슬라이스 마다 부호비트를 추가하는 부호비트 추가부;상기 비트 슬라이스들 중 최상위 비트 슬라이스의 부호비트를 상기 입력데이터의 부호값으로 설정하고, 나머지비트 슬라이스들의 부호비트를 양의 부호값으로 설정하는 부호값설정부; 및상기 부호형 비트 슬라이스들 각각에 대하여 희소 데이터 압축을 실시하는 희소데이터 압축부를 포함하는 것을특징으로 하는 부호형 비트 슬라이스 생성기.\n【청구항 2】\n제1항에 있어서, 상기 부호형 비트 슬라이스들 각각에서 0값을 갖는 비트 슬라이스의 수를 증가시키기 위해, 전체 길이 데이터의부호비트 값을, 각 부호형 비트 슬라이스의 LSB에 더하고, 바로 하위에 인접한 부호형 비트슬라이스의 부호비트에서 빼는 연산과정을 반복하는 부호비트 연산부를 더 포함하는 것을 특징으로 하는 부호형 비트 슬라이스 생성기.\n【청구항 3】\n제2항에 있어서, 상기 부호비트 연산부는양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 하기 위해, 부호형 비트 슬라이스 값이 미리 설정된 특정값인 경우, 상기 연산과정을 스킵하는 것을 특징으로 하는 부호형 비트 슬라이스 생성기.\n【청구항 4】\n비트 슬라이스 생성기의 비트 슬라이스 생성방법에 있어서, 상기 비트 슬라이스 생성기가, N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데이터를분할하되, 상기 입력데이터의 부호비트를 제외한 나머지 비트들을 소정개의 비트 슬라이스로 분할하는분할단계;상기 비트 슬라이스 생성기가, 상기 비트 슬라이스마다 부호비트를 추가하는 부호비트추가단계; 상기 비트 슬라이스 생성기가, 상기 비트 슬라이스들 중 최상위 비트 슬라이스의 부호비트를 상기 입력데이터의부호값으로 설정하고, 나머지 비트 슬라이스들의 부호비트를 양의 부호값으로 설정하는 부호설정단계; 및상기 비트 슬라이스 생성기가, 상기 부호형 비트 슬라이스들 각각에 대하여 희소 데이터 압축을 실시하는 희소데이터 압축단계를 포함하는 것을 특징으로 하는 부호형 비트 슬라이스 생성방법.\n【청구항 5】\n제4항에 있어서, 상기 부호형 비트 슬라이스들 각각에서 0값을 갖는 비트 슬라이스의 수를 증가시키기 위해, 전체 길이 데이터의부호비트 값을, 각 부호형 비트 슬라이스의 LSB에 더하고, 바로 하위에 인접한 부호형 비트슬라이스의 부호비트에서 빼는 연산과정을 반복하는 부호비트 연산단계를 더 포함하는 것을 특징으로 하는 부호형 비트 슬라이스 생성방법.\n【청구항 6】\n공개특허 10-2024-0147342-3-제5항에 있어서, 상기 부호비트 연산단계는양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 하기 위해, 부호형 비트 슬라이스 값이 미리 설정된 특정값인 경우, 상기 연산과정을 스킵하는 것을 특징으로 하는 부호형 비트 슬라이스 생성방법.\n【청구항 7】\n비트 슬라이스 연산기에 있어서, 부호비트를 각각 포함하여 그 길이가 동일하게 생성된 복수개의 M비트 부호형 비트슬라이스를 입력으로 받아 곱셈연산하는 곱셈연산기;상기 곱셈연산기의 연산결과를 누적하는 덧셈연산기; 및상기 덧셈연산기의 연산결과를 저장하는 레지스터를 포함하는 것을 특징으로 하는 비트 슬라이스 연산기.\n【청구항 8】\n인공지능 신경망 가속장치에 있어서,N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데이터로부터 소정개의 부호형 비트 슬라이스를 생성한 후 압축 관리하는 데이터 관리 유닛(DMU Core);상기 부호형 비트 슬라이스의 곱셈 및 덧셈 연산과, 비트 슬라이스 단위의 데이터 스키핑 연산을 수행하는 스키핑 연산 유닛(Zero-slice-skip PE); 및외부 제어 명령에 의해, 상기 스키핑 연산 유닛(Zero-slice-skip PE)의 연산결과를 축적하여 저장하는 축적유닛(Accumulation Unit)을 포함하는 것을 특징으로 하는 인공지능 신경망 가속장치.\n【청구항 9】\n제8항에 있어서, 상기 데이터 관리 유닛(DMU Core)은상기 부호형 비트 슬라이스를 생성하는 부호형 비트 슬라이스 생성유닛(SBR Unit); 및상기 부호형 비트 슬라이스를 압축하는 부호형 비트 슬라이스 압축유닛(RLE Unit)을 포함하되,상기 부호형 비트 슬라이스 생성유닛(SBR Unit)은N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데이터를 분할하되, 상기 입력데이터의부호비트를 제외한 나머지 비트들을 소정개의 비트 슬라이스로 분할하는 분할부;상기 비트 슬라이스 마다 부호비트를 추가하는 부호비트 추가부; 및상기 비트 슬라이스들 중 최상위 비트 슬라이스의 부호비트를 상기 입력데이터의 부호값으로 설정하고, 나머지비트 슬라이스들의 부호비트를 양의 부호값으로 설정하는 부호값설정부를 포함하는 것을 특징으로 하는 인공지능 신경망 가속장치.\n【청구항 10】\n제9항에 있어서, 상기 부호형 비트 슬라이스 압축유닛(RLE Unit)은상기 부호형 비트 슬라이스들 각각에 대하여, 희소 입력 데이터를 압축하고, 0값이 아닌 데이터와 이 데이터의위치를 나타내는 인덱스를 생성하는 것을 특징으로 하는 인공지능 신경망 가속장치.\n【청구항 11】\n제10항에 있어서, 상기 부호형 비트 슬라이스 압축유닛(RLE Unit)은상기 스키핑 연산 유닛(Zero-slice-skip PE)의 스키핑 연산 결과 중 최상위의 비트 슬라이스에 대한 스키핑 연산 결과에 대한 맥스 풀링 결과로 얻어진 출력 바이너리 마스크를 이용하여 상기 희소 입력 데이터를 압축하는것을 특징으로 하는 인공지능 신경망 가속장치.\n【청구항 12】\n공개특허 10-2024-0147342-4-제8항에 있어서, 상기 스키핑 연산 유닛(Zero-slice-skip PE)은 상기 데이터 관리 유닛(DMU Core)으로부터 압축된 부호형 비트 슬라이스인 입력 비트 슬라이스를 전달받아 저장하는 입력버퍼(IBUF);상기 입력 비트 슬라이스의 저장 위치인 압축 인덱스를 저장하는 인덱스버퍼(IDXBUF);상기 부호형 비트 슬라이스로 구현된 가중치 데이터를 저장하는 가중치버퍼(WBUF);상기 압축 인덱스에 의거하여, 가중치 데이터를 불러와야 할 상기 가중치버퍼(WBUF)의 주소를 계산하는 스키핑부(Zero-skip Unit); 및다수의 부호형 비트 슬라이스 연산기들을 포함하고, 상기 입력버퍼(IBUF)로부터 입력 비트 슬라이스를읽어오고, 상기 스키핑부(Zero-skip Unit)에서 계산된 주소 정보에 의해 상기 가중치버퍼(WBUF)로부터 가중치데이터를 읽어와서 곱셈 및 축적 연산을 수행하는 연산기 어레이를 포함하는 것을 특징으로 하는 인공지능 신경망 가속장치.\n【청구항 13】\n제12항에 있어서, 상기 부호형 비트 슬라이스 연산기는상기 입력 비트 슬라이스와 상기 가중치 데이터에 대하여 순차적으로 곱셈연산을 수행하는 곱셈연산기;상기 곱셈연산기의 연산결과를 누적하는 덧셈연산기; 및상기 덧셈연산기의 연산결과를 저장하는 레지스터를 포함하는 것을 특징으로 하는 인공지능 신경망 가속장치.\n【청구항 14】\n제12항에 있어서, 상기 입력 데이터와 상기 가중치 데이터의 희소성을 비교하고 상기 입력 데이터 보다 상기 가중치 데이터의 희소성이 더 높을 경우, 가중치 스키핑 연산을 수행하도록 상기 데이터 관리 유닛(DMU Core), 상기 스키핑 연산유닛(Zero-slice-skip PE), 및 상기 축적유닛(Accumulation Unit)의 동작을 제어하는 가중치 스키핑 연산 컨트롤러를 더 포함하고, 가중치 스키핑 연산 컨트롤러는 상기 가중치 데이터를 압축하여 압축된 부호형 비트 슬라이스인 가중치 비트 슬라이스를 출력하도록 상기 데이터 관리 유닛(DMU Core)을 제어하고,상기 가중치 비트 슬라이스를 입력버퍼(IBUF)에 저장하고, 상기 가중치 비트 슬라이스의 저장 위치인 압축 인덱스를 인덱스 버퍼에 저장하고, 상기 부호형 비트 슬라이스로 구현된 입력데이터를 가중치 버퍼(WBUF)에 저장하도록 상기 스키핑 연산 유닛(Zero-slice-skip PE)을 제어하고,상기 스키핑 연산 유닛(Zero-slice-skip PE)의 출력데이터를 재정렬하여 출력버퍼(OBUF)에 저장하도록 상기 축적유닛(Accumulation Unit)의 동작을 제어하는 것을 특징으로 하는 인공지능 신경망 가속장치."}
{"context": "", "input": "【기술명】\n인공지능 기반 열차 판토그래프 실시간 장애 감지 시스템 및 방법\n\n【기술 설명】\n본 발명은 인공지능 기반의 열차 판토그래프 실시간 장애 감지 시스템 및 방법에 관한 것이다. 이 시스템은 열차 상부에 설치된 판토그래프의 작동 상태를 실시간으로 모니터링하기 위해 고성능 카메라를 활용하여 판토그래프의 상승 및 하강 동작을 촬영하고, 이를 분석하는 엣지 디바이스를 포함한다. 엣지 디바이스는 촬영된 영상을 실시간으로 처리하여 판토그래프와 전차선의 이상 여부를 감지하며, 열차 종합 정보 장치와 연동하여 판토그래프의 구동 신호를 바탕으로 정확한 장애 탐지를 가능하게 한다.\n\n【해결 문제】\n전기 철도차량에서 판토그래프는 전기에너지를 공급받기 위한 필수 장치로, 판토그래프의 손상이나 위치 이상은 열차 운행에 심각한 영향을 미친다. 기존의 기술에서는 이러한 장애를 실시간으로 감지하는 방법이 부족하여, 사고 발생 시 대처가 지연되고 안전성이 저하되는 문제가 있었다. 본 발명은 실시간 영상 분석을 통해 판토그래프의 상승 및 하강 후 위치 이상, 전차선의 좌/우 위치 이상을 즉각적으로 감지함으로써, 철도 운영의 안전성을 획기적으로 향상시키고 신뢰성을 높이는 데 기여한다.\n\n【기술 차별성】\n본 발명의 차별성은 기존 기술과 비교하여 실시간 모니터링 및 자동 장애 탐지를 가능하게 하는 인공지능 기반의 분석 시스템을 도입한 점이다. 기존 기술은 수동적인 점검 방식에 의존하여 장애 발생 후에만 대처할 수 있었으나, 본 발명은 엣지 디바이스를 통해 자동화된 실시간 장애 감지를 실현하며, 정확한 위치 분석과 이상 여부 판단을 통해 판토그래프의 안전성을 강화한다. 이러한 혁신적인 접근 방식은 철도 운영의 효율성을 극대화하고, 전반적인 운행 안전성을 높이는 데 중요한 기여를 할 것이다.\n\n【활용 분야】\n본 발명인 인공지능 기반 열차 판토그래프 실시간 장애 감지 시스템은 철도 산업 및 대중교통 분야에 광범위하게 활용될 수 있습니다. 특히, 고속철도 및 도시철도 시스템에서 안전성을 극대화하고 유지보수 비용을 절감하는 데 기여할 수 있습니다. 또한, 이 시스템은 열차 운영 기업, 유지보수 서비스 회사, 그리고 철도 안전 규제 기관에 의해 채택되어, 전체적인 철도 운영의 효율성과 신뢰성을 향상시키는 데 기여할 것입니다.\n\n【구성 요소 및 기능】\n본 시스템은 다음의 세 가지 주요 구성 요소로 이루어져 있습니다. 첫째, 카메라는 열차 상부에 설치되어 판토그래프의 실시간 영상을 촬영합니다. 둘째, 엣지 디바이스는 촬영된 영상을 분석하여 판토그래프와 전차선의 이상 여부를 감지하며, 이를 통해 판토그래프의 상승 및 하강 구동 이상 여부를 판단합니다. 셋째, 열차 종합 정보 장치는 엣지 디바이스로부터 수신된 데이터를 기반으로 판토그래프의 상승 및 하강 신호를 출력하여 시스템 전체의 원활한 운영을 지원합니다.\n\n【구현 방식 예】\n이 시스템의 구현 방식은 단계별로 이루어집니다. 첫째, 열차에 카메라와 엣지 디바이스를 설치하고, 열차 종합 정보 장치와의 연결을 설정합니다. 둘째, 엣지 디바이스는 카메라에서 받은 영상을 실시간으로 분석하여 판토그래프의 동작 상태와 전차선의 위치를 확인합니다. 셋째, 분석 결과에 따라 판토그래프의 이상 여부를 판단하고, 이를 열차 종합 정보 장치로 전송하여 즉각적인 대응 조치를 취할 수 있도록 합니다. 이러한 단계적 접근은 시스템의 신뢰성과 반응성을 극대화합니다.", "output": "【발명의 명칭】\n인공지능 기반 열차 판토그래프 실시간 장애 감지 시스템 및 방법\n【기술분야】\n본 발명은 인공지능 기반 열차 판토그래프 실시간 장애 감지 시스템 및 방법에 관한 것이다.\n【배경기술】\n전기 철도차량은 동력원으로 전기에너지를 이용하고 있다. 전동차로 전기에너지를 공급하기 위해서 철로 옆에 전철주가 있고, 여기에 가동 브래킷이 설치되고 이 가동 브래킷에 조가선이나 전차선 등의 전차선로가 가설되게 된다. 그리고 전동차에는 전차선로와 접촉되는 판토그래프(Pantograph)가 설치되게 된다. 이러한 전차선로와 판토그래프(Pantograph)는 고전압(교류 25kV)의 전기가 흐르고, 가선과의 기계 전기적인 인 터페이스 성능이 차량 시스템과 시설물의 안전성에 지대한 영향을 미치게 되기 때문에 전차선로 또는 판토그래 프(Pantograph)에 대한 안전성과 신뢰성이 절실히 요구되고 있다. 이와 같이 집전장치는 차량의 성능에 직접적으로 영향을 주는 장치이기 때문에 판토그래프(Pantograph) 손상, 아크 발생, 판토그래프 상/하 이동 및 위치 이상, 전차선 좌/우 이동 및 위치 이상 등의 원인에 의해 장애가 발 행하는 경우 전기 공급 차단으로 열차 운행 및 제어에 심각한 문제가 발생할 수 있다. 그러나 종래에는 이와 같은 판토그래프(Pantograph)의 장애를 탐지하기 위한 기술이 제안되지 못한 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-0711737 B1(2007.04.19)\n【해결하려는 과제】\n본 발명은 상기와 같은 종래의 문제점을 해결하기 위하여 안출된 것으로, 본 발명의 목적은 열차 지붕에 설치된 판토그래프(Pantograph) 영상을 실시간으로 분석하여 판토그래프(Pantograph)의 상승 및 하강 후의 위치 이상, 전차선의 좌/우 위치 이상 여부를 탐지할 수 있는 인공지능 기반 열차 판토그래프 실시간 장애 감지 시스템 및그 방법을 제공함에 있다.\n【과제의 해결 수단】\n본 발명은 상기와 같은 목적을 달성하기 위하여 하기와 같은 실시예를 포함할 수 있다. 본 발명의 실시예는 열차 상부에 설치된 판토그래프(Pantograph)를 실시간으로 촬영하는 카메라와, 카메라에서 촬영된 영상을 분석하여 판토그래프(Pantograph) 및 전차선 이상 여부를 감지하는 엣지 디바이스 및 엣지 디바 이스에 판토그래프의 상승(UP) 및 하강(DOWN) 구동 신호를 출력하는 열차 종합 정보 장치를 포함하고, 엣지 디 바이스는 촬영된 영상을 분석하여 열차 종합 정보 장치의 판토그래프 상승(UP) 및 하강(DOWN) 신호에 연동하여 상승 및 하강되는 판토그래프(Pantograph)의 상승 및 하강 구동 이상 여부와, 판토그래프(Pantograph)의 상승 및 하강 동작 후 설정된 위치에 도달되었는지를 확인하여 판토그래프(Pantograph)의 상승 및 하강 위치 이상 여 부와, 전차선의 좌/우 위치 이상 여부 중 적어도 하나를 감지하는 것을 특징으로 하는 인공지능 기반 열차 판토 그래프 실시간 장애 감지 시스템을 제공할 수 있다. 위 실시예에서, 엣지 디바이스는 열차 종합 정보 장치로부터 수신된 판토그래프 상승(UP) 구동 신호와 연동하여 촬영된 영상을 분석하여 설정된 시간 이내에 판토그래프(Pantograph)가 설정된 상승 하한선까지의 도달 여부와, 하강(DOWN) 신호와 연동하여 판토그래프(Pantograph)가 설정된 시간 이내에 설정된 하강 상한선까지의 도달 여 부를 확인하여 판토그래프 상승 및 하강 구동 이상 여부를 판정할 수 있다. 또한, 엣지 디바이스는 촬영 영상을 통해 판토그래프(Pantograph)의 상승 후 판토그래프(Pantograph)의 위치가 설정된 상승 하한선의 초과 여부와, 하강 후 설정된 하강 상한선 초과 여부를 통해 판토그래프(Pantograph) 상 승 및 하강 위치 이상 여부를 감지할 수 있다. 또한, 엣지 디바이스는 판토그래프(Pantograph)에 접촉된 전차선의 위치가 설정시간 동안 동일 위치에 머무는지 여부를 통해 전차선 이상 여부를 판정할 수 있다. 또한, 엣지 디바이스는 판토그래프(Pantograph)의 영상에서 전차선의 위치가 설정된 폭의 초과 범위에 위치하는 지를 확인하여 이상 여부를 판정하는 것을 특징으로 한다. 또한, 엣지 디바이스는 영상 내의 객체 인식 기법을 통하여 판토그래프를 인식하고, 일치율(Confidence) 값을 산출하여 설정 기준 값과 비교하여 판토그래프의 손상 여부를 판정할 수 있다. 본 발명은 다른 실시예로서 a)카메라를 구동시켜 열차 지붕에 설치된 판토그래프(Pantograph)를 실시간 촬영하 고, 열차 종합 정보 장치를 통해 판토그래프(Pantograph)의 상승(UP) 및 하강(DOWN) 구동 신호를 수신하는 단계 와, b)촬영된 영상을 통해 상승 및 하강 신호에 따른 판토그래프(Pantograph)의 상승 및 하강 과정을 분석하여 판토그래프의 상승 및 하강 이상 여부와, 판토그래프(Pantograph)의 상승 및 하강 후 설정된 위치와 감지된 위 치를 감지하여 상승 및 하강 위치 이상 여부 및 전차선의 위치 이상 여부 중 적어도 하나를 감지하는 단계 및 판토그래프(Pantograph) 및 전차선 중 적어도 하나에서 이상 여부가 감지되면 열차 종합 정보 장치로 감지 결과 를 출력하는 단계를 포함하는 인공지능 기반 열차 판토그래프 실시간 장애 감지 방법을 제공할 수 있다.\n【발명의 효과】\n그러므로 본 발명은 열차의 판토그래프(Pantograph)의 장애 발생 여부를 실시간으로 감지할 수 있고, 영상 내의 전차선의 추적 오인 없이 정확하게 전차선의 위치 이상을 감지할 수 있어 안전성과 신뢰성을 높일 수 있었다.\n【발명을실시하기위한구체적인내용】\n본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있지만, 특정 실시예를 도면에 예시하여 상 세하게 설명하고자 한다. 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 서로 다른 방향으 로 연장되는 구조물을 연결 및/또는 고정시키기 위한 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등 물 내지 대체물중 어느 하나에 해당되는 것으로 이해되어야 한다. 본 명세서에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제 하지 않는 것으로 이해되 어야 한다. 본 발명의 실시예는 인공지능 기반 열차 판토그래프 실시간 장애 감지 시스템 및 방법의 바람직한 실시예를 첨 부 도면을 참조하여 상세히 설명한다. 도 1은 본 발명의 개요를 도시한 도면, 도 2는 본 발명의 구성을 도시한 블럭도이다. 도 1 및 도 2를 참조하면, 본 발명은 열차(T)의 지붕에 설치되어 집전하는 판토그래프(P, Pantograph)와, 판토 그래프(P)를 제어하는 열차 종합 정보 장치와, 판토그래프(P)의 장애 여부를 실시간으로 감지하는 엣지 디 바이스와, 판토그래프(P)를 촬영하는 카메라를 포함할 수 있다. 열차 종합 정보 장치는 판토그래프(P)를 상승 또는 하강 시킨다. 이와 같은 열차 종합 정보 장치 및 판토그래프(P)는 일반적으로 공지된 장치임에 따라 그 설명을 생략한다. 카메라는 엣지 디바이스 또는 열차 종합 정보 장치(TCMS, Train Control and Monitoring System)의 제어에 의해 판토그래프(P)를 실시간으로 촬영한다. 엣지 디바이스는 카메라에서 촬영된 판토그래프(P)의 영상 및/또는 이미지를 분석하여 판토그래프 (P)의 이상 여부를 감시하여 열차 종합 정보 장치로 출력한다. 여기서 열차 종합 정보 장치는 판토그 래프(P)의 이상 여부를 감지한 감지신호가 수신되면, 열차(T) 및/또는 차량기지 내 상황실로 관련 정보 및 경보 를 출력한다. 엣지 디바이스는 이와 같이 카메라의 영상을 분석하여 판토그래프(P)의 이상 여부를 감지하기 위하여 정보를 저장하는 저장부와, 영상을 분석하는 영상 분석부와, 카메라를 제어하는 카메라 제어부 와, 열차 종합 정보 장치와 통신을 수행하는 통신부를 포함할 수 있다. 저장부는 카메라에서 촬영된 영상을 저장한다. 여기서 저장된 영상은 위치 와 시간 정보가 포함될 수 있다. 카메라 제어부는 카메라의 온오프를 제어할 수 있다. 이와 같은 카메라 제어부는 열차 종합 정 보 장치 또는 별개의 독립된 장치로 구성됨도 가능하다. 통신부는 열차 종합 정보 장치와 통신을 수행하여 영상 분석부의 영상 분석 결과를 송신하고, 열차 종합 정보 장치로부터 판토그래프(P)의 상승 및 하강(UP/DOWN) 정보를 수신할 수 있다. 영상 분석부는 카메라에서 촬영된 영상을 통해 전차선(C), 판토그래프(P)의 상승 및 하강 구동 이상 과, 상승 및 하강 위치 이상, 전차선의 좌/우 위치 이상 여부를 감지할 수 있다. 이를 위하여 영상 분석부(12 0)는 인공지능 기반의 영상 분석 기법을 적용할 수 있다. 영상 분석부의 상세 구성은 도 3을 참조하여 설명한다. 도 3은 영상 분석부를 도시한 블럭도이다. 도 3을 참조하면, 영상 분석부는 판토그래프(P)의 상승 및 하강 이상 여부를 감지하는 판토그래프 업다운 감시 모듈과, 영상 또는 영상에서 변환된 이미지를 통해 객체를 인식하여 손상 여부를 감시하는 객체 인식모듈과, 영상 내의 전차선(C) 위치를 감시하는 전차선 감시 모듈을 포함할 수 있다. 판토그래프 업다운 감시 모듈은 판토그래프(P)가 상승 또는 하강 과정의 수행 여부 및 상승 및 하강 후 위 치가 설정된 위치를 초과 또는 이하 여부를 확인하여 판토그래프(P)의 구동 이상 및 위치 이상 여부를 판정한다. 예를 들어, 도 5를 참조하면, 판토그래프(P)는 열차 종합 정보 장치를 통해 출력된 구동 명령에 의해 상 승 또는 하강된다. 이때, 판토그래프는 상승 구동 이후 설정된 상승 하한선 이상에 위치되어야 하고, 하강 구동 이후 설정된 하강 상한선 아래에 위치해야 된다. 그러므로 판토그래프 업다운 감시 모듈은 판토그래프(P)가 상승 및 하강 후 촬영 영상에서 판토그래프(P) 의 현재 위치와 설정된 위치(상승 하한선 및 하강 상한선)를 비교하여 이상 여부를 판정한다. 또한, 판토그래프 업다운 감시 모듈은 열차 종합 정보 장치(예를 들면, 차량 기지의 제어 신호를 수 신하여 열차 종합 정보 장치로부터 출력된)의 판토그래프(P) 상승 및 하강 신호와 연동하여 판토그래프의 구동 이상 여부를 판정할 수 있다. 즉, 판토그래프 업다운 감시 모듈은 열차 종합 장치를 통해 판토그래프의 상승(UP) 또는 하강(DOWN) 명령이 수 신되면, 판토그래프가 정상적으로 상승 또는 하강 구동되는 지를 감시한다. 이때, 판토그래프 업다운 감시 모듈은 영상 내의 판토그래프(P)가 설정된 위치까지 상승 되었는지의 여부 및/또 는 도달되기까지의 시간과, 하강 되었는지의 여부 및/또는 도달되기까지의 시간을 비교하여 이상 여부를 판정할 수 있다. 도 6을 참조하면, 판토그래프(P)는 열차 종합 정보 장치의 구동에 의해 상승 되면 설정 시간 이내에 상승 하한선까지 도달되어야 하고, 하강 시 설정된 시간 이내에 하강 상한선 이하에 위치되어야 한다. 따라서 판토그래프 업다운 감시 모듈은 열차 종합 정보 장치의 판토그래프(P) 구동 신호와 연동하여 영상 내의 판토그래프(P) 위치와 설정된 기준선 및 시간을 비교함에 따라 판토그래프(P) 이상 여부를 판정한다. 객체 인식 모듈은 영상 및/또는 변환된 이미지에서 인공지능 기반의 객체인식 기법을 적용하여 판토그래프 (P)의 객체 인식을 통하여 일치율(Confidence) 값을 추출하고, 설정된 기준 값과 비교하여 손상 여부를 판정한 다. 여기서 일치율(Confidence)은 딥러닝 모델에 의해 학습된 객체를 탐지했을 때 일치율을 의미한다. 즉, 객체 인 식 모듈은 판토그래프(P)를 인식할 때, 일치율이 설정 값 이하 (ex 0.7 : 70%)일 경우 판토그래프(P)의 형 상에 이상이 발생함에 따라 손상된 것으로 판단한다. 전차선 감시 모듈은, 도 7 및 도 8을 참조하면, 열차(T) 운행 중 전차선(C)의 위치 이상 여부를 감시할 수 있다. 이를 위해 전차선 감시 모듈은 전차선(C)이 판토그래프(P)의 헤드를 기준으로 전차선(C)이 동일 위 치에 머무르는지의 여부와, 좌우측에 각각 설정된 기준선(도 8 참조)의 초과 여부를 통하여 전차선(C) 이상 여 부를 감시한다. 일반적으로 전차선(C)은 Messenger Line, Catenary Wire, Contact Wire Dropper등이 구성되며, 이중 판토그래 프(P)는 헤드가 Contact Wire(급전선)와 접촉되면서 Sliding Joint를 이루게 된다. 따라서 열차(T)가 운행 중에는 전차선(C)이 판토그래프(P)와의 동일 위치에 계속하여 머무는 것이 아닌 그 위치 가 변경되되, 헤드를 기준으로 설정된 폭 이내에만 위치되는 것이 정상이다. 그러므로 전차선 감시 모듈은 카메라에서 촬영된 영상에서 판토그래프(P)의 헤드(맨 위 상단부분)에 접촉되는 전차선(C)의 위치가 동일 위치에 머무르거나, 설정된 좌우 기준선을 초과하여 전차선(C)이 위치되는 경우(도 8 참조)를 비정상으로 판단한다. 아울러 전차선 감시 모듈은 전차선(C)의 오인선 해결을 영상을 변환 및 분석할 수 있다. 이는 도 9의 예를 참조하여 설명한다. 도 9의 (a)는 촬영된 영상에서 두개의 선이 존재하는 경우이며, (b)는 야간 촬영 영상을 도 시한 것이다. 전차선 감시 모듈은 위와 같은 (a)와 같이 두개의 선이 존재할 때, 두께를 통하여 해당 전차선(C)을 판정 하고, (b)의 경우에는 조도 차이를 통해 해당 전차선(C)을 구분할 수 있다. 예를 들면, 각 전차선(C)은 그 용도 및 목적에 따라 서로 다른 재질의 케이블 및 두께로서 제작되며, 이와 같은 차이는 야간의 조도 차이에 따라 구분될 수 있다. 그러므로 전차선 감시 모듈은 야간의 경우 영상으로부터 변환된 이미지 프레임 내에서 서로 다른 조도를 갖는 와이어 중 조도가 일치된 와이어를 구분하여 두께를 측정 한다. 또한, 도 9의 (c)와 (d)는 Catenary Wire가 Switching 되는 경우를 촬영한 것이다. 전차선 감시 모듈은 (c)와 (d) 같이 다수의 Catenary Wire가 존재하는 경우 그림자를 통해 Wire의 두께를 산출하여 대상 Catenary Wire(예를 들면, Contact Wire)를 구분하는 것을 특징으로 한다. 본 발명은 상기와 같은 구성을 포함하며, 이하에서는 상기의 구성을 통해 달성되는 인공지능 기반 열차 판토그 래프 실시간 장애 감지 방법을 설명한다. 도 4는 본 발명에 따른 인공지능 기반 열차 판토그래프 실시간 장애 감지 방법을 도시한 순서도이다. 도 4를 참조하면, 본 발명은 열차 종합 정보 장치로부터 정보 수신 및 영상을 촬영하는 S100 단계와, 영상 분석하여 판토그래프 및 전차선(C) 객체를 인식하는 S200 단계와, 판토그래프 객체 인식 일치율 값을 산출하는 S300 단계와, 감지 결과 송신 및 저장하는 S400을 포함할 수 있다. 여기서 각 단계들은 설명을 위하여 임의대로 순서 및 부호를 부여한 것으로서 단계들의 순서를 한정하는 것이 아니다. S100 단계는 엣지 디바이스가 열차 종합 정보 장치를 통하여 판토그래프(P)의 상승(UP) 및 하강 (DOWN) 구동 신호를 수신하고, 카메라가 영상을 촬영하는 단계이다. 카메라는 열차 종합 정보 장치 또는 엣지 디바이스의 구동 명령에 따라 판토그래프(P)를 실시간으로 촬영하여 엣지 디바이스 에 영상을 출력한다. S200 단계는 엣지 디바이스가 영상에서 판토그래프(P) 및 전차선(C)을 객체 인식하여 분석하는 단계이다. 이를 위하여 S200 단계에서 엣지 디바이스는 열차 종합 정보 장치로부터 판토그래프(P) 상승/하강 및 위치 이상을 감시하는 S210 단계와, 전차선(C) 위치 이상을 분석하는 S220 단계를 포함할 수 있다. S210 단계는 엣지 디바이스가 열차 종합 정보 장치로부터 수신된 판토그래프(P) 상승(UP) 신호가 수 신된 시간을 기준으로 설정된 상승 하한선 까지 도달되는 시간과, 판토그래프(P) 하강(DOWN) 신호가 수신된 시 간을 기준으로 설정된 하강 상한선까지 도달되는 시간을 확인하여 설정된 기준시간과 비교하여 이상 여부를 판 정한다. 또한, 엣지 디바이스는 판토그래프(P)가 상승 구동 후 판토그래프(P)의 최상측이 설정된 상승 하한선 아래 에 위치하거나, 판토그래프(P)가 하강 구동 후 설정된 하강 상한선 위에 위치하면 비정상으로 판정할 수 있다. S220 단계는 엣지 디바이스에서 전차선(C) 위치 이상 여부를 감지하는 단계이다. 여기서 엣지 디바이스 는 촬영 영상에서 전차선(C)의 위치가 설정된 위치에서 일정 시간 이상 머무는지의 여부와, 좌/우측에 설 정된 기준선의 초과 여부를 통해서 전차선(C) 이상 여부를 판정한다. 아울러, 엣지 디바이스는 전차선(C) 추적 시 오인 여부를 방지할 수 있도록 영상 내의 객체를 분석하여 객 체의 두께, 그림자의 두께, 야간 시 조도차를 이용한 전차선(C)을 추출함에 따라 전차선(C) 추적 오인을 해소할 수 있다. S300 단계는 엣지 디바이스ㅈ가 영상 내에서 객체 인식 기법을 적용하여 판토그래프(P)의 형상 변형을 감 지하는 단계이며, 이를 위해 S310 단계를 포함한다. S310 단계는 엣지 디바이스가 판토그래프(P)의 손상 여부를 판정하기 위하여 객체 인식 기법을 적용하고, 일치율 값을 산출하여 설정된 기준 값을 비교하여 형상 변형 여부를 판정하는 단계이다. 엣지 디바이스는 카메라에서 촬영된 영상에서 객체 인식 기법을 적용하여 판토그래프(P)의 일치율 값 을 산출한다. 엣지 디바이스는 산출된 일치율 값이 설정된 기준 값 이하이며, 판토그래프(P)가 변형된 것으로 판정한다. S400 단계는 엣지 디바이스가 판정 결과를 열차 종합 정보 장치에 출력하는 단계이다. 엣지 디바이스 는 S200 단계 및 S300 단계를 통해 판토그래프(P)의 위치, 상승 및 하강, 전차선(C)의 이상 여부가 감지되 면 실시간으로 열차 종합 정보 장치를 통해 차량 기지로 관련 정보를 출력한다. 따라서 차량 기지 내 관련 담당자는 이를 인지하여 신속한 조치를 취할 수 있다. 본 발명은 상기한 특정의 바람직한 실시 예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗 어남이 없이 당해 발명이 속하는 기술 분야에서 통상의 지식을 가진 자라면 누구든지 다양한 변형 실시가 가능 한 것은 물론이고, 그와 같은 변경은 청구범위 기재의 범위 내에 있게 되는 것임은 자명하다.\n【요약】본 발명은 열차(T)의 상부에 설치된 판토그래프(P)를 실시간으로 촬영하는 카메라; 카메라에서 촬영된 영상을 분석하여 판토그래프(P) 및 전차선(C)의 이상 여부를 감지하는 엣지 디바이스; 및 엣지 디바이스 에 판토그래프(P)의 상승 및 하강 신호를 출력하는 열차 종합 정보 장치; 를 포함하는 인공지능 기반 열차 판토그래프 실시간 장애 감지 시스템을 포함한다.\n\n【청구항 1】\n에 있어서, 엣지 디바이스는영상 내의 객체 인식 기법을 통하여 판토그래프를 인식하고, 일치율(Confidence) 값을 산출하여 설정 기준 값과비교하여 판토그래프의 손상 여부를 판정하는 것; 을 특징으로 하는 인공지능 기반 열차 판토그래프 실시간 장애 감지 시스템.\n【청구항 2】\n청구항 1에 있어서, 엣지 디바이스는열차 종합 정보 장치로부터 수신된 판토그래프 상승(UP) 구동 신호와 연동하여 촬영된 영상을 분석하여 설정된시간 이내에 판토그래프가 설정된 상승 하한선까지의 도달 여부와, 하강(DOWN) 구동 신호와 연동하여 판토그래프가 설정된 시간 이내에 설정된 하강 상한선까지의 도달 여부를 확인하여 판토그래프 상승 및 하강 구동 이상여부를 판정하는 것; 을 특징으로 하는 인공지능 기반 열차 판토그래프 실시간 장애 감지 시스템.\n【청구항 3】\n청구항 1에 있어서, 엣지 디바이스는촬영 영상을 통해 판토그래프의 상승 후 판토그래프의 위치가 설정된 상승 하한선의 초과 여부와, 하강 후 설정된 하강 상한선 초과 여부를 통해 판토그래프 상승 및 하강 위치 이상 여부를 감지하는 것; 을 특징으로 하는인공지능 기반 열차 판토그래프 실시간 장애 감지 시스템.\n【청구항 4】\n청구항 1에 있어서, 엣지 디바이스는 판토그래프에 접촉된 전차선의 위치가 설정시간 동안 동일 위치에 머무는지 여부를 통해 전차선 이상 여부를 판정하는 것; 을 특징으로 하는 인공지능 기반 열차 판토그래프 실시간 장애 감지 시스템.\n【청구항 5】\n청구항 1에 있어서, 엣지 디바이스는판토그래프의 영상에서 전차선의 위치가 설정된 좌우 폭의 초과 범위에 위치하는 지를 확인하여 이상 여부를 판정하는 것; 을 특징으로 하는 인공지능 기반 열차 판토그래프 실시간 장애 감지 시스템. 공개특허 10-2025-0031877-3-청구항 6\n【청구항 7】\na)카메라를 구동시켜 열차 지붕에 설치된 판토그래프를 실시간 촬영하고, 열차 종합 정보 장치를 통해 판토그래프의 상승(UP) 및 하강(DOWN) 신호를 수신하는 단계;b)촬영된 영상을 통해 상승 및 하강 신호에 따른 판토그래프의 상승 및 하강 과정을 분석하여 판토그래프의 상승 및 하강 이상 여부와, 판토그래프의 상승 및 하강 후 설정된 위치와 감지된 위치를 감지하여 상승 및 하강위치 이상 여부 및 전차선의 설정 위치 초과 여부를 통한 전차선의 위치 이상 여부 중 적어도 하나를 감지하는단계; 및c)판토그래프 및 전차선 중 적어도 하나에서 이상 여부가 감지되면 열차 종합 정보 장치로 감지 결과를 출력하는 단계; 를 포함하는 인공지능 기반 열차 판토그래프 실시간 장애 감지 방법."}
{"context": "", "input": "【기술명】\n인공지능 조류충돌 방지시스템\n\n【기술 설명】\n인공지능 조류충돌 방지시스템은 발전 설비 주변의 조류를 감지하고 분석하여 충돌을 방지하기 위한 혁신적인 솔루션입니다. 이 시스템은 복수 개의 카메라를 통해 촬영된 이미지를 인공지능 알고리즘을 사용하여 조류의 종을 분석하고, 미리 설정된 위험 반경 내에 접근하는 조류에 대해 경보음을 발생시켜 충돌을 예방하는 기능을 갖추고 있습니다. 특히, YOLO5 기법을 활용한 실시간 이미지 분석 및 계층적 이미지 라벨링 기법을 통해 조류의 세부 특성을 정확하게 식별함으로써, 효율적인 조류 모니터링을 실현합니다.\n\n【해결 문제】\n우리나라의 해상 풍력 발전단지 건설이 급증함에 따라, 조류 충돌 문제는 환경 보호와 항공 안전을 위한 중요한 과제가 되었습니다. 현재 사용 중인 외국산 조류 감지 장비는 높은 설치 비용과 유지보수의 어려움으로 인해 국내 시장에서의 실용성이 제한적입니다. 본 인공지능 조류충돌 방지시스템은 국산 솔루션으로서, 발전 설비에 천연기념물 등 조류가 접근하는 것을 효과적으로 확인하고 충돌을 방지하기 위한 경보 시스템을 제공함으로써, 환경 연구 및 지속 가능한 에너지 개발에 기여할 수 있습니다.\n\n【기술 차별성】\n기존의 조류 감지 기술은 주로 비싼 레이더 시스템에 의존하고 있으며, 이는 설치와 유지보수의 복잡성을 초래합니다. 반면, 본 발명은 인공지능 기반의 이미지 분석 기술을 적용하여 경제적이고 효율적인 조류 모니터링을 가능하게 합니다. 특히, YOLO5 기법과 계층적 이미지 라벨링을 활용한 조류 분석은 기존 기술 대비 높은 정확성과 신속성을 제공하며, 다양한 조류의 세부 특성까지 고려하여 보다 정밀한 경고 시스템을 구축함으로써, 차세대 조류 충돌 방지 솔루션으로서의 경쟁력을 강화합니다.\n\n【활용 분야】\n본 발명의 인공지능 조류충돌 방지시스템은 주로 재생 가능 에너지 산업, 특히 육상 및 해상 풍력 발전 분야에서 활용될 수 있습니다. 풍력 발전소는 조류와의 충돌 위험이 높은 지역에 위치하는 경우가 많아, 이 시스템은 조류의 접근을 감지하고 적절한 경고를 통해 인명 및 시설 피해를 예방하는 데 기여합니다. 또한, 항공 및 교통 분야에서도 조류 충돌을 방지하기 위한 시스템으로 적용될 수 있으며, 공항 주변에서의 조류 관리 및 안전성을 증대시키는 데 중요한 역할을 할 것입니다.\n\n【구성 요소 및 기능】\n인공지능 조류충돌 방지시스템의 주요 구성 요소는 다음과 같습니다. 첫째, 촬영부는 복수 개의 카메라를 통해 발전 설비 주변의 조류 이미지를 실시간으로 촬영하며, 이는 조류의 접근을 모니터링하는 데 필수적입니다. 둘째, 분석부는 촬영된 이미지를 YOLO5 알고리즘을 활용하여 조류의 종을 분석하고, 이를 기반으로 세부 특성을 파악하는 계층적 이미지 라벨링 기법을 수행합니다. 셋째, 경보 발생부는 분석 결과를 바탕으로 조류가 미리 설정된 위험 반경에 접근할 경우 경고음을 발생시켜 충돌을 예방하며, 이와 동시에 제어부는 경보 발생부와 발전 설비의 동작을 조정, 외부 서버로 분석 데이터를 전송합니다.\n\n【구현 방식 예】\n인공지능 조류충돌 방지시스템의 구현은 다음과 같은 단계로 진행됩니다. 우선, 발전소 주변에 복수 개의 카메라를 설치하여 조류의 실시간 이미지를 수집합니다. 이후, 수집된 이미지는 설치된 인공지능 알고리즘을 통해 분석되어 조류의 종 및 특성이 식별됩니다. 마지막으로, 분석부의 결과에 따라 조류가 위험 반경에 접근할 경우 경고음이 발생하며, 이 정보는 제어부에 의해 외부 운용 서버로 전송되어 데이터 관리 및 추가적인 분석이 이루어집니다. 이러한 단계적 접근은 시스템의 정확성과 신뢰성을 보장합니다.", "output": "【발명의 명칭】\n인공지능 조류충돌 방지시스템\n【기술분야】\n본 발명은 조류가 접근하는 것을 확인하여 충돌을 방지하기 위한 사운드 알람을 울려 충돌을 방지하는 인공지능 조류충돌 방지시스템에 관한 것이다.\n【배경기술】\n우리나라는 2022년 현재 전국 연안에 해상 풍력 발전단지를 활발하게 건설하고 있다. 환경 연구원등 환경부는 해상풍력발전단지를 건설함에 있어 조류 환경영향 평가를 위한 장비의 설치를 강제하고 있으며, 2021년 말 현재, 영상기반의 조류영향평가 장비를 설치하는 조건으로 해상풍력발전단지의 건설을 허가해 주고 있다. 환경연구원 등 정부기관은 국산 장비 개발이 시급함을 인지하고 국내 기업이 실무적용 가능한 평가 장비를 개발 해 주기를 희망하고 있는 실정이다. 에너지사업(육상 및 해상풍력발전, 태양열, 송전선로 등)에 있어 입지문제(조류 서식지 및 도래지) 및 운영 중 의 발전시설-조류 충돌 등으로 조류관측 분야가 한국전력 등에서도 첨예한 관심을 가지고 있는 부분이지만, 국 내 솔루션이 없어서 요르단과 계약한 풍력발전단지 사업에서 외국의 Avian Radar를 구매하여 설치하였다. 국내 에너지관련 사업 관련하여 한국전력은 국산 제품 부재, 유지보수의 어려움 등의 이유로 Avian Radar를 설 치하지 못하고 있으므로 한국 조류 생태계에 적합한 조류관측 시스템의 개발이 시급한 실정이다. 특히, 레이더를 이용한 시스템은 가격이 비싸 설치에 곤란한 점이 많아, 20221년에는 영상기반 장비를 설치하는 것으로 환경부와 건설업자가 협의하고 있다. 환경부 및 국립공원관리공단에서는 국가생물 다양성 전략과 관련하여 한반도에 도래하는 조류의 이동연구를 위 하여 기상청과 함께 기상레이더를 이용한 이동추적 타당성 연구를 수행한 바 있으나, 국내 운영 중인 기상청 레 이더의 고도가 높아 실효성 부분에서는 매우 미흡한 것으로 판명되었다. 따라서, 해상풍력발전단지 (에너지사업) 및 생물 다양성, 항공 안전, 송전선 철탑 등 다양한 분야에서의 영상기 반의 조류추적 시스템의 개발이 시급한 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제10-2022-0095102호 (공개일자: 2022. 07. 06) (특허문헌 0002) 등록특허공보 제10-2200384호 (공고일자: 2021. 01. 08)\n【해결하려는 과제】\n전술한 문제점을 개선하기 위한 본 발명 실시예들의 목적은 육지나 해상 풍력 단지와 같은 발전 설비에 천연기 념물 등 조류가 접근하는 것을 확인하여 충돌을 방지하기 위한 경보음을 울려 충돌을 방지할 수 있는 인공지능 조류충돌 방지시스템을 제공하는 것이다.\n【과제의 해결 수단】\n상기와 같은 목적을 달성하기 위하여, 본 발명의 일 실시예에 의한 인공지능 조류충돌 방지시스템은 복수 개의 카메라를 포함하여 발전 설비 주변의 조류에 대한 이미지를 촬영하는 촬영부; 상기 촬영된 이미지를 미리 설치된 인공지능 알고리즘으로 상기 조류의 종을 분석하는 분석부; 상기 촬영된 이미지를 기초로 상기 조류가 미리 설정된 위험 반경 내에 접근하게 되는 경우 경보를 발생시키는 경보 발생부; 및 상기 분석부의 분석 결과를 기 초로 상기 경보 발생부 및 발전 설비의 동작을 제어하고, 해당 분석 결과를 외부 운용 서버로 전송하는 제어부 를 포함하고, 상기 분석부는 상기 촬영된 이미지를 YOLO5 기법으로 상기 조류의 종을 분석하는 제1 분류부와, 상기 제1 분류부의 분석 결과에 미리 설정된 종의 세부 특성을 이용하는 계층적 이미지 라벨링(Image Labeling) 기법을 수행하여 상기 조류의 종을 확정하는 제2 분류부를 포함하는 것을 특징으로 한다. 상기 제1 분류부는 상기 촬영된 이미지 내의 조류의 모양을 기초로 상기 조류의 종을 분석하고, 상기 제2 분류 부는 상기 계층적 이미지 라벨링(Image Labeling) 기법을 이용하여 상기 촬영된 이미지 내의 조류의 세부 특징 을 추출한 다음, 추출 결과를 이용하여 상기 조류의 종을 확정하는 것을 특징으로 한다. 상기 제2 분류부는 상기 촬영된 이미지 내의 조류를 특징별 분류 기준으로 분류하되, 상기 특징별 분류 기준은 조류별 비행특징, 날개길이, 부리, 다리 및 형태 중 적어도 하나 이상을 포함하는 것을 특징으로 한다. 또한, 본 발명의 일 실시예에 의한 인공지능 조류충돌 방지시스템은 상기 촬영된 이미지 정보, 상기 조류의 위 치 정보 및 고도 정보를 저장 및 관리하되, 상기 저장 및 관리되는 각각의 정보를 이용하여 조류의 탐지 및 추 적 데이터와 일별 및 월별 통계 데이터를 산출하여 저장하는 데이터베이스부를 포함하는 것을 특징으로 한다. 상기 제어부는 상기 조류가 미리 설정된 위험 반경 내에 접근하게 되는 경우 상기 경보 발생부를 통하여 경보음 을 발생시키고, 상기 발전 설비의 동작을 정지시키는 것을 특징으로 한다.\n【발명의 효과】\n본 발명의 일 실시예에 따른 인공지능 조류충돌 방지시스템은 육지나 해상 풍력 단지와 같은 발전 설비에 천연 기념물 등 조류가 접근하는 것을 확인하여 충돌을 방지하기 위한 경보음을 울려 충돌을 방지하고, 이를 위하여 지정된 고도 및 구역에 접근하는 조류에 대한 경보발생 및 퇴치기능을 수행할 수 있다.\n【발명을실시하기위한구체적인내용】\n상기한 바와 같은 본 발명을 첨부된 도면들과 실시예들을 통해 상세히 설명하도록 한다. 본 발명에서 사용되는 기술적 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려 는 의도가 아님을 유의해야 한다. 또한, 본 발명에서 사용되는 기술적 용어는 본 발명에서 특별히 다른 의미로 정의되지 않는 한, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 의미로 해석되어야 하며, 과도하게 포괄적인 의미로 해석되거나, 과도하게 축소된 의미로 해석되지 않아야 한다. 또한, 본 발명에서 사용되는 기술적인 용어가 본 발명의 사상을 정확하게 표현하지 못하는 잘못된 기술적 용어일 때에 는, 당업자가 올바르게 이해할 수 있는 기술적 용어로 대체되어 이해되어야 할 것이다. 또한, 본 발명에서 사용 되는 일반적인 용어는 사전에 정의되어 있는 바에 따라, 또는 전후 문맥상에 따라 해석되어야 하며, 과도하게 축소된 의미로 해석되지 않아야 한다.또한, 본 발명에서 사용되는 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함한다. 본 발명에서, \"구성된다\" 또는 \"포함한다\" 등의 용어는 발명에 기재된 여러 구성 요소들, 또는 여러 단계를 반 드시 모두 포함하는 것으로 해석되지 않아야 하며, 그 중 일부 구성 요소들 또는 일부 단계들은 포함되지 않을 수도 있고, 또는 추가적인 구성 요소 또는 단계들을 더 포함할 수 있는 것으로 해석되어야 한다. 또한, 본 발명에서 사용되는 제 1, 제 2 등과 같이 서수를 포함하는 용어는 구성 요소들을 설명하는데 사용될 수 있지만, 구성 요소들은 용어들에 의해 한정되어서는 안 된다. 용어들은 하나의 구성 요소를 다른 구성 요소 로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제 1 구성 요소는 제 2 구성 요소로 명명될 수 있고, 유사하게 제 2 구성 요소도 제 1 구성 요소로 명명될 수 있다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동 일하거나 유사한 구성 요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 또한, 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 발명의 사상을 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 발명의 사상이 제한되는 것으로 해석되어서는 아니 됨을 유의해야 한다. 도 1a 내지 도 1b는 본 발명의 일 실시예에 따른 인공지능 조류충돌 방지시스템과 메인 화면 구성을 나타내는 도면이고, 도 2는 본 발명의 일 실시예에 따른 인공지능 조류충돌 방지시스템을 개략적으로 나타내는 블록도이 며, 도 3a 내지 3b는 도 2의 제1 분류부와 제2 분류부를 이용하여 갈매기 머리 특징을 2단계로 구분 및 탐지하 는 과정을 설명하기 위한 도면이고, 도 4는 도 2의 제1 분류부와 제2 분류부를 이용하여 검은머리물때새의 종을 확정하는 과정을 설명하기 위한 도면이며, 도 5는 도 2의 데이터베이스부를 이용하여 조류 이미지를 저장하고 이를 기초로 산출된 사후 통계정보의 예를 설명하기 위한 도면이다. 도 1a 내지 도 2를 참조하면, 본 발명의 일 실시예에 따른 인공지능 조류충돌 방지시스템은 육지나 해상 풍력 단지와 같은 발전 설비에 천연기념물 등 조류가 접근하는 것을 확인하여 충돌을 방지하기 위한 경보음을 울려 충돌을 방지하는 시스템으로서, 촬영부, 분석부, 경보 발생부 및 제어부를 포함한다. 이하, 본 발명의 일 실시예에 따른 인공지능 조류충돌 방지시스템은 천연기념물 등 조류가 접근하는 것을 확인 하여 충돌을 방지하기 위한 사운드 알람을 울려 충돌을 방지하는 시스템으로서, 지정된 고도 및 구역에 접근하 는 조류에 대한 경보 발생 및 퇴치 기능을 수행한다. 한편, 도 1a 내지 도 2의 각 구성요소들은 일반적으로 네트워크(network)를 통해 연결된다. 예를 들어, 도 1a에 도시된 바와 같이, 적어도 하나의 촬영부는 네트워크(Ethernet)를 통하여 AP 공유기와 연결될 수 있다. 그 리고, AP 공유기는, 네트워크(Ethernet 또는 인터넷 통신망)를 통하여 경보 발생부, 분석부 및 제어부 와 연결될 수 있다. 또한, 제어부는 네트워크를 통하여 발전 설비나 데이터베이스부와 연결될 수 있다. 여기서, 네트워크는, 복수의 장치 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의 미하는 것으로, 이러한 네트워크의 일 예에는 근거리 통신망(LAN: Local Area Network), 광역 통신망(WAN: Wide Area Network), 인터넷(WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통신망 등을 포함한다. 무선 데이터 통신망의 일례에는 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), 5GPP(5th Generation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와이파이(Wi-Fi), 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), RF(Radio Frequency), 블루투스 (Bluetooth) 네트워크, NFC(Near-Field Communication) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워 크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 하기에서, 적어도 하나의 라는 용어는 단수 및 복수를 포함하는 용어로 정의되고, 적어도 하나의 라는 용어가 존재하지 않더라도 각 구성요소가 단수 또는 복수로 존재할 수 있고, 단수 또는 복수를 의미할 수 있음은 자명 하다 할 것이다. 또한, 각 구성요소가 단수 또는 복수로 구비되는 것은, 실시예에 따라 변경가능하다 할 것이다. 상기 촬영부는 복수 개의 카메라를 포함하여 발전 설비 주변의 조류에 대한 이미지를 촬영하는 장치로서, 실시간으로 발전 설비 주변을 이동하는 조류를 촬영하는 장치이다. 예를 들어, 상기 촬영부는 도 1에 도시된 바와 같이, 주야간 감시 카메라(4대)를 사방위로 설치하여 360도 방향의 조류 접근 감시 및 퇴치 기능을 수 행하도록 설치될 수 있다. 이때, 복수 개의 카메라는 제어부의 제어에 따라 이미지 촬영을 위한 주기 내지 는 횟수가 설정될 수 있다. 또한, AP 공유기는, 복수 개의 카메라를 통하여 입력된 이미지 데이터를 수집할 수 있다. 이때, 이미지 데이터 는 발전 설비 주변에 이동하는 조류를 촬영한 영상일 수 있다 복수 개의 카메라는, 조류 충돌 방지 및 퇴치를 위한 인공지능 기반 영상 분류를 이용한 조류의 종 분석 관련 웹 페이지, 앱 페이지, 프로그램 또는 애플리케이션을 이용하거나 이용하지 않고 조류를 촬영한 영상을 분석부 로 전송하는 장치일 수 있다. 여기서, 복수 개의 카메라는 단순히 촬영만을 해서 전송을 하는 기능뿐만 아 니라, 영상분석결과만을 별도로 전송하는 기능을 더 포함할 수 있다. 이 경우, 영상분석을 수행하는 하드웨어 및 소프트웨어가 복수 개의 카메라에 포함될 수 있고, 분석부에서는 이 기능을 배제하는 방식으로 구현될 수도 있다. 상기 분석부는 촬영부에 의하여 촬영된 이미지를 AP 공유기를 통하여 수신하고, 미리 설치된 인공지능 알고리즘을 이용하여 조류의 종을 분석하는 장치이다. 이때, 상기 분석부는 수집된 이미지 데이터 내에 포 함된 적어도 하나의 조류를 기 저장된 인공지능 알고리즘으로 분류할 수 있다. 이때, 인공지능 알고리즘은 다양 한 알고리즘이 사용될 수 있겠지만, 본 발명의 일 실시예에서는 비정형 데이터의 분류, 특히 이미지 분류에 강 인한 CNN(Convolutional Neural Network) 계열을 이용할 수 있다. CNN은, 다층퍼셉트론(Multi-Layer Perceptron)에 대응하는 피드포워드 신경망(Feedforward Neural Network)이 인접한 층(Layer)의 유닛(Unit)과 서로 모두 연결된(Fully-Connected) 형태를 이루는 전결합층(Fully-Connected Layer)과, 인접층의 기 설정된 유닛만 연결되는 합성곱층(Convolution Layer) 및 풀링층(Pooling Layer)을 포함할 수 있다. 컨볼루션 신경망은 입력의 특징을 추출하는 컨볼루션 계층, 추출된 특징으로 결과를 추론하는 완전결합(Fully Connected) 계층, 컨볼루션 계층의 출력(Feature Map)의 크기를 줄여주는 풀링(Pooling) 계층으로 구성될 수 있 다. 컨볼루션 계층에서는 가중치 필터 행렬과 입력 행렬이 컨볼루션 연산이 된다. 즉, 그 필터 행렬과 상응하는 입력을 곱한 후, 그 값을 더한 결과(Partial Sum)를 출력 행렬에 순차적으로 저장할 수 있다. 컨볼루션 계층은 반복적인 곱셈과 덧셈 연산 때문에, 컨볼루션 신경망의 연산시간의 대부분은 컨볼루션 계층에서 소모된다. 풀링 계층은 컨볼루션 계층에서 생성된 출력 행렬의 크기를 줄이고, 줄어든 출력 행렬은 오버피팅(Over- Fitting) 문제를 줄여줄 수 있다. 출력 행렬을 줄이는 방법은 크기가 2×2 혹은 3×3인 가중치 필터가 2 또는 3 만큼 이동하면서 가중치 필터 행렬과 교차하는 입력 행렬의 값 중에서 가장 큰 값을 출력 행렬에 저장하는 방법 으로 이루어지는데, 완전연결 계층은 신경망의 마지막 부분에 존재하며 컨볼루션 계층을 통해 얻은 특징들을 종 합하여 결과를 추론하게 된다. 가중치 필터 행렬의 크기는 입력과 출력 행렬의 크기에 의해 정해진다. 또는, 기 저장된 인공지능 알고리즘은, 적어도 하나의 입력층(Input Layer)과 출력층(Output Layer) 간 복수의 은닉층(Hidden Layer)으로 이루어진 인공신경망(Artificial Neural Network)인 DNN(Deep Neural Network) 알고 리즘일 수 있다. 물론, RNN(Recurrent Neural Network), RBM(Restricted Boltzmann Machine) 등을 배제하는 것 은 아니다. 이때, 딥러닝의 단층 퍼셉트론(Single-Layer Perceptron)은, 인공신경망의 가장 기본적인 모형으로, 외부 입력 값을 받아 연결하는 입력층과 이를 처리하여 결과를 출력하는 출력층으로 이루어져 있다. 다층 퍼셉트론(Multi- Layer Perceptron)은, 인공신경망의 이론 중 하나로 역전파신경망(Back Propagation Network)과 다층전방향신 경망(Multi-Layer Feedforward Network)이라고도 불린다. 기본적으로 입력층, 은닉층, 출력층으로 구성되며 각 층은 다수의 뉴런(Node)을 가진다. 여기서, 역전파 알고리즘(Back-Propagation Algorithm)은, 입력층의 각 노 드에 입력 패턴에 따라 임의 가중치를 주면, 이 신호는 은닉층까지 전달되고 출력층에 도달하여 출력값과 목표 값을 비교한다. 비교로 도출된 오차를 줄이기 위하여 연결 강도를 조절하며 역진하는데, 이 과정을 반복하며 오 차를 줄이는 것이 역전파 알고리즘이다. 인공신경망 및 딥러닝은 입력층, 은닉층, 출력층을 통하여 출력값을 도출하는 구조를 가지며, 각 층간 연결강도 를 통하여 신경이 전달된다. 적절한 은닉층, 학습률, 소실 함수, 활성화 함수, 모멘텀, 학습과정 최대 횟수, 학 습과정 반복 횟수 등 파라미터를 설정함으로써 기울기 소실, 오버피팅 등의 문제를 예방하고 좋은 성능을 가진 모델을 구축할 수 있다. 본 발명의 일 실시예에서는 적합한 파라미터를 찾기 위하여 하이퍼 파라미터를 이용할 수 있는데, 다른 방법을 이용하는 것을 배제하는 것은 아니다. 하이퍼 파라미터(Hyper-Parameter)는 설정된 다양한 파라미터들을 학습하고 시도하여 최적화된 파라미터를 찾아 내는 것이다. 여기서, 기울기 소실, 학습 수렴 속도, 오버피팅 등을 보완하기 위한 활성화 함수로, ReLU(Rectified Linear Unit), TanH(Hyperbolic Tangent)이 존재하는데, ReLU 함수는 가중치가 양수일 경우, 그대로 나타내고, 가중치가 양수일 때는 은닉층이 다수여도 기울기 소실이 발생하지 않는다. TanH 함수는 Sigmoid와 유사한 형태를 가지지만 확장된 형태라고 할 수 있는데, 0이 아닌 -1까지 확장되었기에 출력범위가 넓어 더 빠르게 수렴할 수 있다. 또한, 조류가 천년기념물에 해당되는 조류인지 아닌지를 판단하기 위해 분석부는 조류의 종류를 분류하는 딥러닝 모델을 더 포함할 수 있다. 그리고, 딥러닝 모델에 이미지를 입력하여 조류가 천년기념물에 해당되는 조 류인지 아닌지 판단할 수 있다. 딥러닝 모델은 사전에 다수의 조류에 대한 이미지를 학습데이터로 활용하여 학 습된 모델로 종래 이미지 분류를 위해 학습된 CNN을 이용할 수 있다. 그리고 조류의 종류 예측에 대한 정확도를 높이기 위해서 소정의 이미지 전처리 과정을 거칠 수 있다. 예컨대, 이미지에 포함된 노이즈를 제거하고 그레이 스케일로 변환하는 과정을 수행할 수 있다. 빠른 속도로 비행하는 조류의 종을 구분하기 위해서는 빠른 속도로 이미지를 탐지(detection)하는 상술한 CNN이 필요하게 된다. 이를 위하여, CNN은 구분(Classification) 기능을 통하여 영상 속의 객체(주로 하나)가 무엇인 지 분류하게 되고, 탐지(Detection) 기능을 통하여 영상 속의 어떤 객체가 있는지 확인하고, 각 객체에 Bounding Box(이를 Localization이라 함)를 치게 된다. 이러한 CNN은 Bounding Box와 클래스 추측을 동시에 하는 1단계 CNN과 따로 하는 2단계 CNN이 있는데, 빠른 속 도로 탐지하는 1단계 CNN으로는 대표적으로 YOLO가 있다. 다만, 1단계 CNN인 YOLO5는 속도가 빠른 대신 정확도가 떨어지기 때문에 본 발명에서는 YOLO5를 사용하되, 세부 특징을 표현할 수 있는 계층구조 라벨링 방법을 적용하여 1단계 종 구분 후, 세부 특성을 사용하여 2단계 종 확 정을 수행하는 2-Phase Yolo5를 구현한다. 즉, 본 발명은 YOLO5의 낮은 정확도를 높이기 위해, 라벨링을 계층화하여, Bounding Box내에 조류의 세부 특징 이 있는지 여부를 확인하는 2단계 Yolo5 (2-Phase Yolo5 이라 함) 알고리즘을 이용하여 정확도를 높였고, 이를 위하여 1차로 비행 중인 새 모양으로 종을 탐지 후 종의 확정을 위해 세부 특징을 잡아내는 2차 종 확정을 수행 한다. 그 결과, 도 3 내지 도 4에 도시된 바와 같이, 2 phasae Yolo5로 탐지된 결과, 비행하는 동체를 감싸는 Bounding Box 내부에 머리 (또는 꼬리, 부리, 날개끝 모양) 세부 특징을 잡은 Sub Bounding Box가 표시된 것을 확인할 수 있다. 한편, 조류 이미지에 대한 딥러닝 모델의 출력 결과에 따라 분석부는 조류가 천년기념물에 해당되는 조류인 지 판단할 수도 있다. 상기 분석부는 맹금류(독수리, 솔개, 부엉이)/철새(왜가리, 두루미, 청둥오리)/바닷새(갈매기) 총 7종(실제 출현하는 주요 조류에 따라 변동가능)으로 분류한 다음, 최종 학습된 웨이트 파일을 ONNX(Open Neural Network Exchange) 형식 파일로 변환하여 인공지능 카메라 소프트 웨어에 통합한다. 예를 들어, 상기 분석부는 YOLO5 인공지능 이미지 분류 기법을 적용하여 영상 내의 조류별 비행특징(전면, 후면, 좌측면, 우측면), 조류별 날개길이(0.75~1m/1~1.5m/1.5m~), 부리, 다리 및 형태(두루미 학/맹금류/부리/ 머리(흰머리독수리)/다리(두루미))를 기준으로 조류의 종을 분류할 수 있다. 또한, 상기 분석부는 조류를 최초 탐지후, 영상을 확대하여 상술한 방법으로 조류의 종을 구분하고, 천연기 념물이 위험반경 내 접근하여 충돌이 예상되면 제어부의 제어에 의하여 발전 설비의 동작을 정지시키도록 할 수 있다. 보다 상세하게는, 상기 분석부는 촬영부에서 촬영된 이미지를 YOLO5 기법으로 조류의 종을 분석하는 제 1 분류부와, 제1 분류부의 분석 결과에 미리 설정된 종의 세부 특성을 이용하는 계층적 이미지 라벨 링(Image Labeling) 기법을 수행하여 조류의 종을 확정하는 제2 분류부를 포함한다. 상기 제1 분류부는 촬영부에서 촬영된 이미지 내의 조류의 모양을 기초로 조류의 종을 분석한다. 상기 제2 분류부는 계층적 이미지 라벨링(Image Labeling) 기법을 이용하여 촬영부에서 촬영된 이미지 내의 조류의 세부 특징을 추출한 다음, 추출 결과를 이용하여 조류의 종을 확정한다. 이를 위하여, 상기 제2 분 류부는 촬영부에서 촬영된 이미지 내의 조류를 특징별 분류 기준으로 분류하게 되는데, 이때 특징별분류 기준은 조류별 비행특징, 날개길이, 부리, 다리 및 형태 중 적어도 하나 이상을 포함한다. 이러한 방식대로 관측 가능한 조류는 맹금류(검독수리, 말똥가리, 뱀독수리, 유럽개구리매, 작은잿빛개구리매, (작은)황조롱이, 흰목대머리수리, 솔개, 붉은솔개 등), 까마귀속(큰까마귀, 송장까마귀, 갈까마귀), 연작류(칼 새, 숲비둘기, 흰턱제비, 해변종다리, 어치, 큰재개구마리, 벌잡이새, 마다직박구리, 검은머리딱새, 까치, 찌르 레기), 물새(오리, 기러기, 백조류)(회색기러기, 캐나다기러기, 큰고니), 가마우지과(민물가마우지), 왜가리과& 황새과(왜가리, 홍부리황새), 가넷&펠리컨/두루미/갈매기과(사다새/두루미속/노란다리갈매기) 등을 포함할 수 있다. 도시되어 있지는 않지만, 상기 분석부는 제3 분류부를 더 포함할 수 있다. 이러한 제3 분류부는, 촬영부 에서 수집된 이미지 데이터 내에 포함된 적어도 하나의 다른 조류 또는 이동체를 기 저장된 인공지능 알고 리즘으로 분류한 후, 분류된 결과의 오류 검증을 위한 인증을 실시하고, 인증의 결과로 분류된 결과의 오류 부 분 및 오류 원인을 파악하며, 파악된 오류 부분 및 오류 원인을 업데이트한 후, 오류의 패턴을 발견하고 분류를 통하여 오류율을 예측하기 위하여, 기 저장된 인공지능 알고리즘의 재학습을 할 수 있다. 이때, 제3 분류부는, 상술한 인공지능 알고리즘이 CNN인 경우, 완전히 학습이 끝난 이미지 데이터를 재학습하는 과정에서는 가지치기 과정을 적용함으로써 불필요한 가중치와 연결을 줄일 수 있도록 구성될 수 있다. 즉, 학습 이 끝난 가중치 필터 행렬에 낮은 차수 근사로 가중치 필터 행렬의 크기를 줄일 수 있는데, 완전 연결 계층에 적용하고 컨볼루션 계층에 적용하지 않는 것을 기본으로 한다. 그 이유는, 컨볼루션 계층에 가지치기를 적용하 는 경우 신경망의 정확도가 크게 낮아지기 때문이다. 따라서, 본 발명의 일 실시예에서는, 컨볼루션 계층에 낮 은 차수 근사를 먼저 적용하여 다수의 가중치들을 소수의 가중치로 값을 집약한 후에, 가지치기를 적용하는 방 법을 이용할 수 있다. 그 결과로 신경망의 크기가 작아져서 가중치의 저장과 연산을 줄이고, 정확도 손실도 최 소화될 수 있다. 이를 위해, 가속화 알고리즘은, 먼저, 학습이 완료된 신경망의 모든 계층에 낮은 차수 근사를 적용하고, 완전 결합 계층은 가중치의 절대값이 0에 가까운 값부터 전체 가중치의 90%를 가지치기를 적용할 수 있다. 다음으로, 각 계층들의 희소성을 조사하는데, 기준값은 첫 번째 컨볼루션 계층에서 가중치의 절대값의 크기가 하위 x%가 되는 값이 될 수 있다. x는 재학습을 진행할 단말 또는 서버의 메모리 크기에 따라 초기값이 변경될 수 있다. 결정된 기준값 이하의 값은 0으로 간주되고, 희소성은 계층의 가중치 중 0이 차지하는 비율을 의미할 수 있다. 기준값에 의해 조사된 각 계층의 희소성을 기준으로 가지치기를 선택된 컨볼루션 계층부터 가지치기를 적용할 수 있다. 다음으로, 낮은 차수 근사와 가지치기 기법들에 의한 Top-1 정확도 손실을 복원하기 위해 재학습을 진 행할 수 있다. 두 번째로 낮은 차수 근사를 시행하는데, 낮은 차수 근사는 Top-1 정확도의 큰 손실 없이 신경망의 크기를 줄여 연산 속도를 향상 시키는 방법이다. 컨볼루션 계층의 가중치 필터 행렬은 작지만, 다수의 가중치 필터 행렬이 존재한다. 따라서 많은 연산이 다층의 컨볼루션 계층에서 발생하고, 완전 연결 계층은 가중치가 집중되어 있어 신경망의 전체적인 크기에 영향을 주기 때문에, 이러한 각 계층들에 낮은 차수 근사 기법을 사용하여 신경망의 크기를 줄일 수 있다. 낮은 차수 근사는 특이값 분해(Singular Value Decomposition)를 통해 행렬을 분해하고 본 행렬과 차이가 적게 나는 작은 차수(Rank)를 구하여 행렬의 크기를 줄일 수 있다. 세 번째로, 가지치기 기법을 이용하는데, 상술한 바와 같이 가지치기 기법은 학습이 끝난 컨볼루션 신경망에서 중요하지 않은 가중치를 제거하는 방법이다. 가지치기 기법에서는 각 계층에서 남겨놓을 가중치 비율이 결정되 면, 0에 가장 근접한 가중치부터 제거될 수 있다. 각 계층이 Top-1 정확도에 미치는 영향이 다르므로, 동일한 가중치 비율로 계층들이 가지치기 기법이 적용된다면, Top-1 정확도가 크게 낮아질 수 있다. 따라서, 본 발명의 일 실시예는, 낮은 차수 근사 후에 각 계층마다 Top-1 정확도에 영향이 작아지도록 다른 비율로 가중치 가지치 기를 한다. 가지치기를 적용하기 위한 기준값은 첫 번째 컨볼루션 계층의 가중치 희소성이 10%가 되는 값으로 설정할 수 있으나 이에 한정되지는 않는다. 첫 번째 컨볼루션 계층의 희소성을 바탕으로 기준값을 설정한 이유는 첫 번째 컨볼루션 계층에서는 입력 영상의 경계(Edge)를 인지하기 때문에, 컨볼루션 계층 중에서 가중치 희소성이 가장 낮다. 계속되는 상위 컨볼루션 계 층을 통해 연산이 진행되면, 경계 부분의 가중치들이 소수의 가중치들로 더 집중된다. 첫 번째 컨볼루션 계층의 가중치 희소성이 20%가 되는 기준값의 경우, 완전 결합 계층에서는 대부분의 가중치를 0에 근접한 값으로 인지 하기 때문에 가지치기 기법을 적용하면 Top-1 정확도가 크게 하락할 수 있다. 반복적인 실험의 결과로 첫 번째 컨볼루션 계층의 희소성이 10% 이내가 되는 기준값으로 설정할 수 있으나 이 역시 고정된 값이 아니다. 다음으 로, 시스템의 메모리 크기에 따라 가지치기를 수행할 컨볼루션 계층을 선택할 수 있다. 그 메모리의 크기가 작다면, 낮은 컨볼루션 계층부터 가지치기를 수행하는 것이 바람직하지만, Top-1 정확도는 낮아지고, 재학습의 시 간이 늘어날 수 있다. 반대로, 그 메모리 크기가 크다면, 높은 컨볼루션 계층부터 가지치기를 수행하는 것이 좋 지만, Top-1 정확도 높아지고, 재학습의 시간은 짧아질 수 있다. 이렇게 재학습을 할 때 컨볼루션 신경망 기반 딥러닝에서 가지치기를 하는 경우, 제한된 컴퓨팅 자원 또는 네트 워킹 자원 내에서 또는 제한된 시간 내에 수행될 수 있으므로 초기 학습 시간보다 줄어들 수 있고 초기에 들었 던 자원보다 훨씬 적은 자원만으로도 재학습이 가능해진다. 본 발명의 가속화 알고리즘은 낮은 차수 근사와 가 중치 가지치기 방법을 적용하여 신경망의 크기를 효율적으로 줄일 수 있기 때문에, 필요한 메모리가 작아지고, 연산량도 줄어들어 추론의 속도가 향상되며, 재학습의 시간도 크게 줄일 수 있어서 인공지능 서비스를 더 빠르 고 신속하게 제공할 수 있게 된다. 물론, 재학습을 수행하는 방법이 상술한 방법으로 한정되지는 않는다. 상기 경보 발생부는 촬영부에서 촬영된 이미지를 기초로, 즉 이미지에 포함된 조류의 위치 정보를 기초 로 조류가 미리 설정된 위험 반경 내에 접근하게 되는 경우 충돌 위험이 있는 조류를 향하여 경보를 발생시키는 장치로서, 스피커와 같은 음향 장치가 사용될 수 있다. 즉, 상기 경보 발생부는 발전 설비 주변을 이동하는 조류가 지정된 고도 및 구역에 접근하거나, 접근이 예 상되는 조류에 대한 경보를 발생시켜 퇴치시키는 기능을 수행할 수 있다. 더 나아가, 상기 경보 발생부는 발전 설비 주변에 핵심 범위 및 완충 범위 내 조류가 접근하는 경우 이에 대한 위협 소리를 발생하거나, 경광등을 작동시키는 등의 단계별 경보 발생 기능을 수행할 수도 있다. 또한, 상기 경보 발생부는 항공기, 발전 설비(풍력기)와의 거리 및 고도를 핵심범위 및 완충범위로 나누어 조류와 충돌을 회피하기 위한 알람을 사람에게 제공할 수도 있다. 상기 제어부는 분석부의 분석 결과를 기초로 경보 발생부 및 발전 설비의 동작을 제어하고, 해당 분석 결과를 외부 운용 서버로 전송하는 장치이다. 이러한 제어부는 충돌 위험이나 잠재적 충돌에 대한 제어기능을 수행할 수 있다. 한편, 상기 제어부는 조류가 미리 설정된 위험 반경 내에 접근하게 되는 경우 경보 발생부를 통하여 경 보음을 발생시키고, 발전 설비의 동작을 비상 정지시키도록 제어할 수도 있다. 또한, 상기 제어부는 발전 설비 주변을 이동하는 조류에 대한 이미지를 수신하여 조류가 천년기념물에 해당 되는 조류인지 판단하고 판단 결과에 따라 해당 조류를 향하여 경보 발생부를 통하여 특정 경보음을 발생시 킴과 동시에, 발전 설비의 동작을 정지시켜 충돌 위험을 최대한 방지할 수 있다. 또한, 상기 제어부는 발전 설비에 구동정보에 상응하는 제어신호를 전송하여 충돌 위험이 있는 조류가 미리 정해진 구역으로 이동하도록 유도할 수 있다. 그리고 상기 제어부는 조류의 움직임에 대한 정보를 데이터베 이스부에 리워드로 제공하여 파라미터를 조절할 수 있다. 상기 제어부는 이러한 과정을 반복하여 데이 터베이스부에 저장되는 인공지능 알고리즘이 조류 충돌 피해를 최소화시키는 방향으로 학습시킬 수 있다. 또한, 상기 제어부는 시스템 구동을 전반적으로 제어함과 동시에 분석 정보를 표시할 수 있는 데, 도 1b에 도시된 바와 같이, 조류 출현 방향, 조류 출현 빈도, 영상 분석 화면 등을 표시하면서 경고 메시지, 카메라 제 어창이나 카메라 선택창을 디스플레이를 통하여 표시할 수 있다. 한편, 상술한 상기 제어부는 컴퓨터에서 실행될 수 있는 실행가능한 알고리즘을 포함하는 프로그램(또는 어 플리케이션)으로 구현될 수도 있다. 상기 프로그램은 일시적 또는 비일시적 판독 가능 매체(nontransitory computer readable medium)에 저장되어 제공될 수 있다. 비일시적 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니 라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상 술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM(read-only memory), PROM (programmable read only memory), EPROM(Erasable PROM, EPROM) 또는 EEPROM(Electrically EPROM) 또는 플래시 메모리 등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있 다. 일시적 판독 가능 매체는 스태틱 램(Static RAM，SRAM), 다이내믹 램(Dynamic RAM，DRAM), 싱크로너스 디램 (Synchronous DRAM，SDRAM), 2배속 SDRAM(Double Data Rate SDRAM，DDR SDRAM), 증강형 SDRAM(Enhanced SDRAM ，ESDRAM), 동기화 DRAM(Synclink DRAM，SLDRAM) 및 직접 램버스 램(Direct Rambus RAM，DRRAM) 과 같은 다양한 RAM을 의미한다. 한편, 본 인공지능 조류충돌 방지시스템은 촬영부에서 촬영된 이미지 정보, 조류의 위치 정보 및 고도 정보 를 저장 및 관리하되, 저장 및 관리되는 각각의 정보를 이용하여 조류의 탐지 및 추적 데이터와 일별 및 월별 통계 데이터를 산출하여 저장하는 데이터베이스부를 더 포함할 수 있다. 상기 데이터베이스부는 조류의 종을 분류 및 확정하고, 발전 설비를 제어하기 위한 구동정보를 출력하는 인 공지능 알고리즘을 저장한다. 상기 데이터베이스부는 인공지능 알고리즘과 별개로 조류의 종류를 예측하는 딥러닝 모델을 더 저장할 수 있다. 상기 데이터베이스부는 이러한 모델들을 저장할 수 있는 용량을 가진 메모리로 구현될 수 있다. 이와 같이, 본 발명에서의 데이터베이스부는 도 5에서와 같이 해상풍력발전단지 조류 환경영향 평가를 위한 이미지 데이터를 저장하고, 저장된 빅 데이터를 기초로 조류종별 활동 통계를 내거나 각 종 데이터 분석에 활용 하게 할 수 있다. 이를 위하여, 상기 데이터베이스부는 저장 통계 분석 SW, 조류 종류 분석 SW, 조류 접근 감시 및 충돌 방지 SW 등을 구비할 수 있고, 감지된 모든 비행의 온라인 비디오 및 사운드 기록을 저장하고 비행 기능을 분석할 수 있다. 또한, 상기 데이터베이스부는 조류가 없는 경우는 녹화를 하지 않고, 조류가 발견되면 이미지 데이터 를 저장하거나, 저장된 데이터는 사후 분석에 사용하며, 장기적으로는 향후 종 분석 등을 위한 빅 데이터로 활 용하게 할 수 있다. 상기와 같이 구성된 본 발명의 일 실시예에 따른 인공지능 조류충돌 방지시스템은 육지나 해상 풍력 단지와 같 은 발전 설비에 천연기념물 등 조류가 접근하는 것을 확인하여 충돌을 방지하기 위한 경보음을 울려 충돌을 방 지하고, 이를 위하여 지정된 고도 및 구역에 접근하는 조류에 대한 경보발생 및 퇴치기능을 수행할 수 있다. 이하에서는, 본 발명에 따른 인공지능 조류충돌 방지시스템의 인공지능 조류 분류 기능, 활용 방안 및 환경적 기대효과를 예를 들어, 설명하기로 한다. 인공지능 조류 분류 기능 1. 파이썬을 이용하여 크롤링 프로그램을 작성하고 이를 이용하여 조류 이미지 다운로드 - 앉아있는 새, 날아다니는 새, 이륙하는 새, 부리의 모습, 다리의 모습 등 특징별로 구분할 수 있는 이미지 10,000장 다운로드, 구시포 부근, 낙동강 하구언, 금강 하구언등 조류가 많이 비행하는 지역을 택해서 조류 동 영상을 촬영함. - 최소 3회 이상 동영상 촬영을 수행, 총 합계 3시간 동영상 클립에서 2만장 학습데이터 추출 2. YOLO5에서 학습이 가능하도록 LabelImg 프로그램을 이용해서 라벨링 수행 3. 조류를 특징별로 분류하여 라벨링 수행 - 조류 비행 특징: 전면, 후면, 좌측면, 우측면 - 새 종류별 특징: 날개길이 75 ~ 1미터, 1~ 1.5미터, 1.5미터 이상 - 부리, 다리 및 형태별 특징: 두루미 학, 맹금류, 부리, 머리(흰머리독수리), 다리(두루미) - 조류의 종류: 맹금류(독수리, 솔개, 부엉이), 철새(왜가리, 두루미, 청둥오리), 바닷새(갈매기) 7종 4. 특징별로 학습데이타를 최소100장에서 500장정도 마련해서 학습수행하고 학습되는지 여부 확인 5. 학습이 잘 되면 최종적으로 전체 특징별 라벨링한 데이터를 모아서 다시 학습 6. 최종 학습된 웨이트 파일을 ONNX 파일로 변환하여 인공지능 카메라 SW에 전달 활용방안 1. 검증된 장비로 조류 환경영향평가를 수행하여 환경 보전 및 원활한 해상 풍력 발전 단지 건설 활성화 2. 외국 장비 도입 필요성이 없어지고, 수입대체 및 수출 효과 발생 3. 인공지능 기술 개발로 해상분야 영상인식 기술 발전에 기여: 자율운항 선박 개발와 활용 4. 육해상풍력발전단지 뿐 아니라. 공항, 한전 송전탑, 고속도로 유리 소음방지막 등 조류가 부딪혀 죽는 모든 곳에 레이다에 비교하여 상대적으로 저렴하게 조류 보호 장치로 활용 가능하여 환경보전에 기여 5. 풍력발전단지 환경 영향 평가, 공항 조류 퇴치 등을 위한 장비 설치 활성화로 신규 시장 창출 및 고용 창출 환경적 기대효과 1. 천연기념물 조류 보호, 멸종 방지, 조류조사 방식을 개선하여, 조류 활동 분석에 활용 2. 공항, 송전탑 부근에 설치하여 조류 보호 3. 항공기 조류 충돌 방지로 환경 보호 및 사고 발생 저감 한편, 상기 촬영부의 외표면에는 내오염성을 향상시키기 위해 오염 방지 도포용 조성물로 이루어진 내오염 성 도포층이 도포될 수 있다. 상기 내오염성 도포용 조성물은 설포라우레이트 및 코카미도프로필 베타인이 1:0.01 ~ 1:2 몰비로 포함되어 있 고, 설포라우레이트 및 코카미도프로필 베타인의 총 함량은 전체 수용액에 대해 1 ~10 중량%이다. 상기 설포라우레이트 및 코카미도프로필 베타인은 몰비로서 1:0.01 ~ 1:2가 바람직한 바, 몰비가 상기 범위를 벗어나는 경우에는 내오염성 도포층의 도포성이 저하되거나 도포 후에 표면의 수분흡착이 증가하여 도포막이 제 거되는 문제점이 있다. 상기 설포라우레이트 및 코카미도프로필 베타인은 전체 조성물 수용액 중 1 ~ 10 중량%가 바람직한 바, 1 중량% 미만이면 내오염성 도포층의 도포성이 저하되는 문제점이 있고, 10 중량%를 초과하면 도포막 두께의 증가로 인 한 결정석출이 발생하기 쉽다. 한편, 본 내오염성 도포용 조성물을 촬영부의 외표면 상에 도포하는 방법으로는 스프레이법에 의해 도포하 는 것이 바람직하다. 또한, 상기 촬영부의 외표면 상의 최종 도포막 두께는 900 ~ 2300Å이 바람직하다. 상 기 도포막의 두께가 900Å미만이면 고온 열처리의 경우에 열화되는 문제점이 있고, 2300Å을 초과하면 도포 표 면의 결정석출이 발생하기 쉬운 단점이 있다. 또한, 본 내오염성 도포용 조성물은 설포라우레이트0.1 몰 및 코카미도프로필 베타인0.05몰을 증류수 1000 ㎖에 첨가한 다음 교반하여 제조될 수 있다. 상기 구성 성분의 비율 및 도포막 두께를 상기와 같이 수치 한정한 이유는, 본 발명자가 수차례 실패를 거듭하 면서 시험결과를 통해 분석한 결과, 상기 비율에서 최적의 오염방지 도포 효과를 나타내었다. 상기 분석부에는 흡음층을 구성할 수 있다. 상기 흡음층으로는 천연섬유 부직포가 사용될 수 있다. 상기 흡음층의 두께는 0.7 ~ 16㎜인 것이 바람직하다. 상기 흡음층의 두께가 0.7㎜ 미만에서는 충분한 흡음 효 과가 얻어지지 않고, 16㎜를 초과하면 분석부와의 공간이 충분히 확보되지 않으므로 분석부의 온도를 높일 수 있는 단점이 되므로 바람직하지 않다. 상기 흡음층의 단위 무게는 15 ~ 700g/m2 로 하는 것이 바람직하다. 15g/m2 미만에서는 충분한 흡음효과가 얻어 지지 않고, 또한 700g/m2를 넘으면 분석부의 경량성 등을 확보할 수 없으므로 바람직하지 않다. 상기 흡음층을 구성하는 섬유의 섬도는 0.7 ~ 23데시텍스의 범위인 것이 바람직하다. 0.7데시텍스 미만에서는 저주파 소음의 흡수가 어렵고 쿠션성도 저하되므로 바람직하지 않으며, 23데시텍스를 넘으면 고주파 소음의 흡 수가 어려우므로 바람직하지 않다. 상기 흡음층의 부직포의 인장강도는 9Kgf/㎠으로 형성되고, 소음감소계수(NRC)는 0,670으로 형성된다. 이러한 상기 흡음층이 분석부에 구비되므로 분석부의 소음을 저감시킬 수 있다. 흡음층을 구성하는 부직포, 두께, 무게, 섬도 등의 구성 성분을 한정하고 구성비율의 수치를 한정한 이유는, 본 발명자가 수차례 실패를 거듭하면서 시험 결과를 통해 분석한 결과, 상기 구성 성분 및 수치 한정 비율에서 최 적의 흡음 효과를 나타내었다. 상기 제어부의 표면에는 살균기능 및 작업자의 스트레스 완화 등에 도움이 되는 기능성 오일이 혼합된 환경 용 방향제 물질이 코팅될 수 있다. 방향제 물질과 기능성 오일의 혼합 비율은 상기 방향제 물질 95~97중량%에 상기 기능성 오일 3~5중량%가 혼합되 며, 기능성 오일은 스티락스오일(Styrax oil) 55중량%, 세이지오일(Sage oil)45중량%로 이루어진다. 여기서 기능성 오일은 방향제 물질에 대해 3~5중량%가 혼합되는 것이 바람직하다. 기능성 오일의 혼합비율이 3 중량% 미만이면, 그 효과가 미미하며, 기능성 오일의 혼합비율이 3~5중량%를 초과하면 그 효과가 크게 향상되지 않는 반면에 경제성이 떨어진다. 스티락스오일(Styrax oil)은 발삼향으로 심리적으로 마음을 정화하고 두통, 우 울증 등에 작용효과가 있으며, 세이지오일(Sage oil)은 살균, 방충, 스트레스 완화 등에 좋은 효과가 있다. 따 라서, 이러한 기능성 오일이 혼합된 방향제 물질이 제어부의 표면에 코팅됨에 따라, 제어부의 표면을 살균 처리하고 작업자의 스트레스 등을 경감시키는 등의 효과를 얻을 수 있다. 환경용 방향제 물질 및 기능성 오일에 대해 구성 성분을 한정하고 혼합 비율의 수치를 한정한 이유는, 본 발명 자가 수차례 실패를 거듭하면서 시험 결과를 통해 분석한 결과, 상기 구성 성분 및 수치 한정 비율에서 최적의 효과를 나타내었다. 이상에서는 본 발명에 따른 바람직한 실시예들에 대하여 도시하고 또한 설명하였다. 그러나 본 발명은 상술한 실시예에 한정되지 아니하며, 특허 청구의 범위에서 첨부하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속 하는 기술 분야에서 통상의 지식을 가진 자라면 누구든지 다양한 변형 실시가 가능할 것이다.\n【요약】본 발명은 복수 개의 카메라를 포함하여 발전 설비 주변의 조류에 대한 이미지를 촬영하는 촬영부; 상기 촬영된 이미지를 미리 설치된 인공지능 알고리즘으로 상기 조류의 종을 분석하는 분석부; 상기 촬영된 이미지를 기초로 상기 조류가 미리 설정된 위험 반경 내에 접근하게 되는 경우 경보를 발생시키는 경보 발생부; 및 상기 분석부의 (뒷면에 계속)\n\n【청구항 1】\n복수 개의 카메라를 포함하여 발전 설비 주변의 조류에 대한 이미지를 촬영하는 촬영부;상기 촬영된 이미지를 미리 설치된 인공지능 알고리즘으로 상기 조류의 종을 분석하는 분석부;상기 촬영된 이미지를 기초로 상기 조류가 미리 설정된 위험 반경 내에 접근하게 되는 경우 경보를 발생시키는경보 발생부; 및상기 분석부의 분석 결과를 기초로 상기 경보 발생부 및 발전 설비의 동작을 제어하고, 해당 분석 결과를 외부운용 서버로 전송하는 제어부를 포함하고,상기 분석부는 상기 촬영된 이미지를 YOLO5 기법으로 상기 조류의 종을 분석하는 제1 분류부와, 상기 제1 분류부의 분석 결과에 미리 설정된 종의 세부 특성을 이용하는 계층적 이미지 라벨링(Image Labeling) 기법을 수행하여 상기 조류의 종을 확정하는 제2 분류부를 포함하는 것을 특징으로 하는 인공지능 조류충돌 방지시스템.\n【청구항 2】\n제1항에 있어서,상기 제1 분류부는 상기 촬영된 이미지 내의 조류의 모양을 기초로 상기 조류의 종을 분석하고,상기 제2 분류부는 상기 계층적 이미지 라벨링(Image Labeling) 기법을 이용하여 상기 촬영된 이미지 내의 조류의 세부 특징을 추출한 다음, 추출 결과를 이용하여 상기 조류의 종을 확정하는 것을 특징으로 하는 인공지능조류충돌 방지시스템.\n【청구항 3】\n제2항에 있어서,상기 제2 분류부는 상기 촬영된 이미지 내의 조류를 특징별 분류 기준으로 분류하되, 상기 특징별 분류 기준은조류별 비행특징, 날개길이, 부리, 다리 및 형태 중 적어도 하나 이상을 포함하는 것을 특징으로 하는 인공지능조류충돌 방지시스템.\n【청구항 4】\n제2항에 있어서,상기 촬영된 이미지 정보, 상기 조류의 위치 정보 및 고도 정보를 저장 및 관리하되, 상기 저장 및 관리되는 각각의 정보를 이용하여 조류의 탐지 및 추적 데이터와 일별 및 월별 통계 데이터를 산출하여 저장하는 데이터베이스부를 포함하는 것을 특징으로 하는 인공지능 조류충돌 방지시스템.\n【청구항 5】\n제1항에 있어서,상기 제어부는 상기 조류가 미리 설정된 위험 반경 내에 접근하게 되는 경우 상기 경보 발생부를 통하여 경보음을 발생시키고, 상기 발전 설비의 동작을 정지시키는 것을 특징으로 하는 인공지능 조류충돌 방지시스템.공개특허 10-2024-0065914-3-"}
{"context": "", "input": "【기술명】\n인공지능 시스템\n\n【기술 설명】\n본 발명은 인공지능 기반의 환경센서를 활용하여 실내 및 인접 실외의 환경 데이터를 실시간으로 측정하고 분석하는 시스템입니다. 이 시스템은 다수의 환경센서를 통해 수집된 온도, 습도, 공기질 등의 데이터를 AI 서버에서 학습 모델로 처리하여, 환경 상황을 인지하고 사용자에게 적절한 행동고지를 추천합니다. 이를 통해 사용자는 보다 건강한 환경을 유지할 수 있도록 지원받으며, 실내 공기질 관리의 효율성을 극대화할 수 있습니다.\n\n【해결 문제】\n본 기술은 주거환경에서의 공기질 악화 문제를 해결합니다. WHO의 보고서에 따르면 실내 공기질은 인간의 건강에 큰 영향을 미치며, 포스트 코로나 시대에 실내 거주 시간이 증가함에 따라 이 문제의 심각성은 더욱 부각되고 있습니다. 본 발명을 통해 사용자는 실시간으로 공기질을 모니터링하고, AI의 추천에 따라 효율적으로 환경을 개선할 수 있는 솔루션을 제공받아 건강을 보호하고 삶의 질을 향상시킬 수 있습니다.\n\n【기술 차별성】\n본 발명은 기존의 단순한 공기질 모니터링 시스템과 차별화된 점이 있습니다. 기존 시스템은 주로 실내 공기질만을 모니터링하는 데 그쳤으나, 본 시스템은 실내와 실외의 데이터를 통합하여 분석함으로써 보다 정확한 환경 판단을 가능하게 합니다. 또한, 사용자의 행동 패턴과 주거형태를 기반으로 AI가 자동으로 공기질을 조절할 수 있도록 설계되어, 사용자의 직접적인 개입 없이도 효율적인 환경 관리가 이루어지는 혁신적인 접근방식을 제공합니다.\n\n【활용 분야】\n본 발명은 스마트 홈, 건축물 관리, 환경 모니터링, 도시 계획 및 건강 관리와 같은 분야와 산업에 폭넓게 활용될 수 있습니다. 특히, 실내 공기질이 중요한 요인이 되는 주거 환경 및 상업 공간에서의 효율적인 공기질 관리와 최적화된 환경을 제공하여 거주자의 건강과 삶의 질을 향상시킬 수 있습니다. 또한, 이 시스템은 환경 데이터 분석을 통해 정책 입안자나 도시 관리자에게 실시간 정보를 제공하여 환경 개선 및 정책 수립에 기여할 수 있습니다.\n\n【구성 요소 및 기능】\n1. **환경 센서**: 다수의 환경 센서는 실내 및 실외의 다양한 환경 데이터를 실시간으로 측정합니다. 온도, 습도, 미세먼지, CO2 농도와 같은 데이터를 수집하여, 실내 공기질을 종합적으로 분석할 수 있는 기초 데이터를 제공합니다.  \n2. **서비스 서버**: 이 서버는 환경 센서로부터 수집된 데이터를 통합하여 저장하고, AI 서버와의 연결을 통해 분석된 정보를 제공합니다. 사용자 선호도 및 주거형태와 결합하여 개인 맞춤형 공기질 관리 솔루션을 생성하는 역할을 합니다.  \n3. **AI 서버**: AI 서버는 수집된 데이터를 기반으로 학습 모델을 구축하여 실내 환경의 상황을 인지하고, 사용자의 행동 패턴에 맞춰 최적의 행동 고지를 추천합니다. 이를 통해 사용자는 실내 공기질을 보다 효율적으로 관리할 수 있게 됩니다.\n\n【구현 방식 예】\n본 발명의 구현은 다음 단계로 이루어집니다. 첫 번째 단계는 다양한 환경 센서를 설치하여 실내 및 실외의 환경 데이터를 측정하는 것입니다. 두 번째 단계에서는 수집된 데이터를 서비스 서버에 전송하고, 이 서버가 데이터를 통합 및 저장하여 AI 서버와의 연결을 준비합니다. 마지막 단계에서는 AI 서버가 데이터를 분석하여 실내 환경의 상황을 인지하고, 사용자에게 적합한 행동 고지를 제공하는 애플리케이션을 통해 이를 전달함으로써 효율적인 공기질 관리 시스템을 구축하게 됩니다. 이러한 단계적 접근은 시스템의 신뢰성과 정확성을 보장합니다.", "output": "【발명의 명칭】\n인공지능\n【기술분야】\n본 발명은 다수의 환경센서를 이용하여 측정된 환경 센싱값을 학습 모델에 기반하여 실내 오염의 상황을 인지하 고 그에 적합한 행동 고지를 추천하는, 인공지능(AI) 기반의 환경센서를 이용한 환경 상황인지 및 행동고지 시 스템 및 방법에 관한 것이다.\n【배경기술】\n본 발명은 서울특별시 서울산업진흥원 2020년도 포스트 코로나 특화 인공지능 기술사업화 지원사업(CY201023)의 \"환경감지 IoT 융합센서 시스템을 이용한 상황인지 A·I 학습 고도화\" 과제를 통해 개발된 기술이다. 2014년 WHO 보고서에 따르면, 주거환경에서 공기의 질(IAQ: Indoor Air Quality)은 인간의 건강에 막대한 영향 을 미치는 것으로 알려져 있다. 특히, 외부의 공기 보다도 실내의 공기질이 인간의 건강에 큰 영향을 미치며, 포스트 코로나 시대에 실내 거주시간이 많아짐에 따라, 그 영향도는 더욱 증가할 것으로 사료된다. 이에 따라, 실내의 공기질 측정 및 각 플랫폼에서 측정한 데이터를 전송하는 사물 인터넷(IoT) 기반 기술과 데 이터 분석 기술이 다양하게 연구되고 있다. 플랫폼은 수집된 공기질 데이터를 분석하여 사용자에게 분석 결과를 제공하는 것에 중점을 두고 있으며, 센서의 정확도가 조금 부족하더라도 사용자에게 실시간으로 현재 공기질에 대한 알림을 제공하여 환기 및 대처를 유도하고 있다.실내 공기질(IAQ)에 대한 관심이 증가하는 것에 부가하여, 사물 인터넷 및 센서 기술의 발전은 소형의 실내 공 기질 모니터링 시스템의 발전을 가능하게 하였다. 이들 시스템들은 실시간으로 다양한 실내 공기 오염 물 질을 모니터링할 수 있어서, 사람들이 실시간으로 현재의 공기질을 식별함으로써 배출 또는 공기 청정 시스템을 사용 하여 실내 공기를 정화할 수 있다. 하지만, 대부분의 실내 공기질 모니터링 시스템들은 오염 물질의 센싱값을 수치로만 제시하기 때문에, 전문가뿐만 아니라 일반 사용자들은 공기가 얼마나 오염되었는지 또는 각 오염 물질 의 오염 기준이 무엇인지를 식별하기가 어렵다. 또한, 기존에는 센서가 설치된 실내 공간 내부의 센싱 데이터로는 외부 환경 요인에 의한 상황인지 오류 발생 여지가 있었으며, 센서가 설치된 실내 공간에서 특정 활동 없이도 외부 환기를 통해 오염이 증가할 수 있는 문 제가 있었다. 또한, 공기질 모니터링 시스템은 주로 새로 지어지는 아파트를 중심으로 공급되고 있는데, 서울 시민들의 대다 수가 살고 있는 주거환경인 구 아파트, 연립주택, 다세대, 빌라 등의 주거환경에는 적용되지 못하고 있다. 관련 선행기술문헌으로는 등록특허공보 제10-2199915호(발명의 명칭: 인공지능 카메라를 이용한 인공지능 IoT 환경 센서의 재실 상황 추론 학습 방법, 공고일자: 2021년 01월 08일) 및 등록특허공보 제10-2197035호(발명의 명칭: 영상 및 IoT 센서 기반 다기능 환경감시 및 제어장치, 공고일자: 2020년 12월 30일) 등이 있다.\n【해결하려는 과제】\n본 발명은 상기의 문제점을 해결하기 위한 것으로서, 실내 및 실내와 인접한 실외의 환경 데이터를 각각 수집하 고 이를 학습시킨 인공지능(AI)을 통해 실제 실내 환경 데이터에 대한 상황을 인지하고 그에 적합한 행동고지를 추천하는, 인공지능(AI) 기반의 환경센서를 이용한 환경 상황인지 및 행동고지 시스템 및 방법을 제공하는 데 본 발명의 목적이 있다. 본 발명의 다른 목적은, 사용자가 직접 제어하지 않아도 사용자의 패턴과 환경요인에 따라 효율적으로 실내 공 기질을 제어하도록 하는 데 있다. 또한, 본 발명의 다른 목적은, 외부 대기 기준으로 하여 생활공간 내부에 대한 환경을 비교하여 판단할 수 있는 알고리즘을 제공함으로써 정확한 생활 환경 공기질 분석이 가능하도록 하는 데 있다. 또한, 본 발명의 또 다른 목적은, 서울 시민들의 대다수가 살고 있는 주거환경인 구 아파트, 연립주택, 다세대, 빌라 등 기존 주거환경에서도 공기질 모니터링을 저비용으로 쉽고 정확하게 적용할 수 있는 시스템을 마련하고 자 하는 데 있다.\n【과제의 해결 수단】\n이를 위하여 본 발명의 실시예에 따른 인공지능 기반의 환경센서를 이용한 환경 상황인지 및 행동고지 시스템은, 실내 또는 상기 실내와 인접한 위치의 실외에 대하여 환경 데이터를 측정하는 다수의 환경센서; 상기 실내에 설치되고 상기 실내의 온도, 습도, 환기를 제어하기 위한 디바이스; 상기 다수의 환경센서를 통해 측정 된 실내 및 실외 환경 데이터를 수집하는 서비스 서버; 상기 서비스 서버로부터 수집된 실내 환경 데이터와 실 외 환경 데이터, 사용자의 선호도, 주거형태에 관한 주거 데이터, 행동 데이터에 기반하여 학습 모델을 구축하 고 상기 학습 모델을 통해 상기 환경 데이터에 대한 실내의 상황을 인지하고 그에 적합한 행동고지를 추천하는 AI 서버를 포함한다. 바람직하게, 상기 서비스 서버는, 상기 AI 서버로부터 추천받은 행동고지에 따라 실내의 온도, 습도, 환기 중 적어도 하나 이상을 제어하기 위한 제어신호를 상기 디바이스로 전달할 수 있다. 바람직하게, 본 발명의 실시예에 따른 인공지능 기반의 환경센서를 이용한 환경 상황인지 및 행동고지 시스템은, 상기 디바이스에 설치되고 상기 AI 서버에 의해 추천받은 행동고지를 상기 서비스 서버로부터 제공받 아 사용자에게 알려주는 사용자 애플리케이션;을 더 포함할 수 있다. 바람직하게, 상기 AI 서버는, 상기 사용자 애플리케이션을 통해 사용자의 생활 패턴에 따라 미리 입력해둔 스케 줄러에 의해 상기 행동 데이터를 수집할 수 있다. 바람직하게, 상기 AI 서버는, 각각의 환경센서를 통해 측정된 환경 데이터가 정상적인 수치범위를 벗어난 경우 상기 사용자 애플리케이션을 통해 사용자에게 알리고, 상기 사용자로 하여금 해당 상황을 입력하도록 유도하여 상기 행동 데이터를 수집할 수 있다. 바람직하게, 상기 다수의 환경센서는, 온도 센서, 습도센서, 미세 먼지 센서, CO2 센서 중 어느 하나 이상을 포 함하는 융합센서이고, 실외에 구축되는 경우 공공 API를 통해 상기 서비스 서버로 환경 데이터를 제공할 수 있 다. 바람직하게, 상기 사용자 애플리케이션은, 상기 서비스 서버에 네트워크 접속하여 상기 디바이스를 원격 제어할 수 있다. 본 발명의 실시예에 따른 인공지능 기반의 환경센서를 이용한 환경 상황인지 및 행동고지 방법은, 서비스 서버 가 다수의 환경센서를 통해 센싱된 실내 또는 상기 실내와 인접한 위치의 실외에 대하여 환경 데이터를 수집하 는 단계; AI 서버가 상기 서비스 서버로부터 수집된 실내 환경 데이터와 실외 환경 데이터, 사용자의 선호도, 주거형태에 관한 주거 데이터, 행동 데이터에 의거 학습시킨 인공지능을 통해 상기 환경 데이터에 대한 실내의 상황을 인지하는 단계; 및 상기 AI 서버가 상기 상황인지에 따른 행동고지를 추천하는 단계를 포함한다.\n【발명의 효과】\n이러한 본 발명에 따르면, 다수의 환경센서를 이용하여 실내 공간에 대한 공기질 데이터뿐만 아니라 실내와 인 접한 실외의 공기질 데이터까지 수집이 가능하며, 이를 토대로 학습시킨 인공지능 기능을 통해 실제 실내 환경 데이터에 대한 상황을 인지하고 그에 적합한 행동고지를 추천함으로써 정확한 생활 환경 공기질 분석이 가능한 효과가 있다. 또한, 본 발명에 따르면, 외부 대기 기준으로 하여 생활공간 내부에 대한 환경을 비교하여 판단할 수 있으므로 보다 정확한 공기질 분석이 가능한 현저한 효과가 있다. 또한, 본 발명에 따르면, 사용자의 행동 데이터에 기초한 인공지능 기능을 기반으로 공기질 분석을 수행함으로 써, 사용자가 직접 제어하지 않아도 사용자의 패턴과 환경요인에 따라 효율적으로 실내 공기질을 제어할 수 있 는 효과가 있다. 또한, 본 발명에 따르면, 새로운 주거단지는 물론, 구 아파트, 연립주택, 다세대, 빌라 등 기존 주거환경에서도 공기질 모니터링을 저비용으로 쉽게 정확하게 적용할 수 있어 그 활용 범위를 확대할 수 있는 효과가 있다. 또한, 본 발명에 따르면 서울 시내의 잦은 리모델링 등 주거 개선사업으로 인한 이웃 주거환경 악화 상황 모니 터링용으로도 매우 적합할 수 있다.\n【발명을실시하기위한구체적인내용】\n본 발명과 본 발명의 동작상의 이점 및 본 발명의 실시에 의하여 달성되는 목적을 충분히 이해하기 위해서는 본 발명의 바람직한 실시예를 예시하는 첨부 도면 및 첨부 도면에 기재된 내용을 참조하여야만 한다. 이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예를 설명함으로써, 본 발명을 상세히 설명한다. 다만, 본 발명을 설명함에 있어서 이미 공지된 기능 혹은 구성에 대한 설명은, 본 발명의 요지를 명료하게 하기 위하 여 생략하기로 한다. 도 1은 본 발명의 실시예에 따른 인공지능 기반의 환경센서를 이용한 실내 상황인지 및 행동고지 시스템(이하, 시스템이라 칭함)을 개략적으로 나타낸 개념도이다. 본 발명의 실시예에 따른 시스템은 다수의 환경센서와, 서비스 서버, AI 서버, 디바이스를 포함한다. 다수의 환경센서는 실내 공간뿐만 아니라, 공장이나 실내주차장 등과 같은 실외의 공기질을 측정한다. 여 기서, 실내 또는 실내 공간은 주택, 상가, 공장, 어린이집, 학교 등의 건물 내부의 공간을 의미할 수 있으며, 나아가 차량, 열차 등의 이동 수간의 내부 공간을 의미할 수 있다. 즉, 실내는 외부와의 구분이 가능하면서 사 람이 생활 가능한 내부의 공간을 포괄하는 개념으로 이해될 수 있다. 다수의 환경센서는 온도, 습도, 가스, 미세먼지(PM-10, PM-25), 이산화질소(NO2), 일산화탄소(CO), 아황산 가스(SO2) 등 대표적인 5가지 오염 물질을 감지한 환경데이터(또는 환경 센싱값)를 출력할 수 있다. 서비스 서버 및 AI 서버는 다수의 환경센서로부터 측정된 환경 센싱값을 전달받아 데이터 분석 을 하고, 특히 AI 서버는 사용자의 지능과 가깝게 학습시킨 모델을 통해 환경 센싱값에 대한 실내 오염의 상황을 인지하고 그에 적합한 행동고지를 추천한다. 그러면, 서비스 서버는 행동고지의 추천에 따라 실내 공간의 온도, 습도 등을 제어하는 제어신호를 디바이 스로 전달하고 이를 전달받은 디바이스는 제어신호에 따라 동작하여 실내 공간의 온도, 습도, 또는 환기를 제어한다. 또는 실내 공간의 IoT 기기를 제어할 수 있다. 이렇게 동작하는 본 발명의 실시예에 따른 시스템은 일반 아파트, 빌라, 주택 등의 주거환경, 일반사무직 사무 실 환경, 학교, 학원, 대학교 강의실 캠퍼스, 불특정 다수가 사용하는 음식점, 카페, 쇼핑몰, 백화점, 도심 주 변의 제조업 공장의 환경, 신축건물/리모델링/인테리어 등 다양한 공사 현장, 지하철 역사, 실내 외 주차장 환 경 등 다양하게 적용할 수 있다. 이를 적용하기 위한 구체적인 구성은 다음과 같다. 도 2는 본 발명의 실시예에 따른 인공지능 기반의 환경센서를 이용한 환경 상황인지 및 행동고지 시스템의 세부 구성을 나타낸 구성도이다. 본 발명의 실시예에 따른 환경 상황인지 및 행동고지 시스템은, 다수의 환경센서(도 1의 100)로서 다수의 측정 소와 다수의 센서를 포함하고, 서비스 서버에는 API 서버, 디바이스 서버, 데이터베 이스(230, 240)를 포함한다. 그리고, 이러한 서비스 서버와 연동되는 AI 서버, 디바이스, 사용 자 애플리케이션을 포함한다. 다수의 측정소는 실외의 공기질을 측정한다. 즉, 실내 공간과 가장 인접한 위치의 실외에 설치되며, 각 측 정소에서 측정된 실외 환경 데이터는 공공 API를 통해 서비스 서버로 전송된다. 필요에 따라 실외 측정소 는 국가 기관에 의해 운영되며 공공 API를 통해 데이터를 무료로 제공받을 수 있다. 다수의 센서는 실내의 공기질을 측정한다. 이때, 다수의 측정소 및 다수의 센서는 온/습도 센서, 가스 센서 어레이, 미세먼지 처리칩, 다채널 아날로그 신호처리 회로, 다채널 ADC(Analog Digital Converter), 및 MCU(Micro Controller Unit)를 포함하는 환경감지 융합센서 모듈로 구성될 수 있다. 서비스 서버는 API 서버에서 공공 API를 통해 측정소로부터 센싱된 실외 환경 데이터를 수집하 고, 디바이스 서버에서 다수의 센서로부터 측정된 실내 환경 데이터를 수집한다. 수집된 실외 환경 데이터 및 실내 환경 데이터는 데이터베이스(230, 240)에 저장된다. 또한, 서비스 서버에서 API 서버는 AI 서버와 연결되어 수집된 실외 환경 데이터와 실내 환경 데이터를 AI 서버로 전달하고, AI 서버로부터 환경 데이터에 대한 행동고지 결과값을 추천받는다. 또한, 서비스 서버는 디바이스 서버를 통해 디바이스와 연동되어 AI 서버로부터 추천받은 행동고지에 따라 사용자의 실내의 온도, 습도, 환기 등을 제어한다. AI 서버는 서비스 서버에서 수집된 실내 환경 데이터 및 실외 환경 데이터와 사용자의 기호, 주거 데 이터, 온도 제어 데이터, 행동 데이터 등에 기반하여 학습 모델을 구축한다. 이러한 AI 서버는 학습 모델 을 통해 실제 실내 환경 데이터에 대한 상황을 인지하고, 상황에 따른 적합한 행동 고지 결과값을 서비스 서버 로 추천한다. 여기서, 행동 고지 결과값이라 함은 대피, 환기, 온도 조절, 공기 청정기 가동 등을 고지하 는 데이터를 의미한다. 사용자의 주거 데이터는 사용자가 거주하는 실내 공간에 대한 정보로서, 예컨대 주거 유형(아파트, 빌라 등), 층수, 세대원수 등을 포함한다. 행동 데이터는 사용자가 주로 실내 공간에서 행하는 행동에 관한 정보로서, 예 컨대 요리하기, 고기굽기, 먼지털기 등을 포함할 수 있다. 본 발명의 실시예에서, 행동 데이터는 사용자의 생활 패턴에 따라 애플리케이션 등을 통해 미리 설정해둔 스케 줄러에 의해 수집될 수 있다. 예컨대, 월요일부터 금요일까지의 사용자의 생활 패턴을 수집하여 사용자가 실내 공간에서 주로 생활하던 행동 패턴을 데이터화한다. 또한, 행동 데이터는 각각의 센서가 정상적인 수치범위를 벗어난 경우 사용자에게 알림하고 이에 사용자로 하여 금 해당 상황을 입력하도록 유도함으로써 수집될 수 있다. 예를 들어, 사용자가 실내에서 고기를 구웠을 때 CO2 센서 등에 의해 감지되는 수치가 급격히 상승하는데, 이러 한 경우 서비스 서버는 사용자에게 이를 알리고 이에 사용자는 현재 집에서 고기를 구웠다는 내용의 해당 선택 하거나 직접 입력할 수 있다. 이때의 입력은 애플리케이션을 통해 수행될 수 있다. 디바이스는 사용자의 실내(집이나 사무실의 실내 공간)에 설치되는데, 실내의 온도, 습도, 환기를 제어하 기 위한 컨트롤러의 기능을 수행한다. 일 예로, 디바이스는 도 3에 도시한 바와 같다. 디바이스는 AI 서버로부터 추천받은 행동고지에 따라 실내의 온도, 습도, 환기 등을 제어하기 위한 제어신호를 서비스 서버의 디바이스 서버를 통해 전달받는다. 디바이스에는 온도 센서는 물론 미세먼지 센서, CO2 센서 등의 다양한 환경 센서가 내장될 수 있지만, 이 에 한정하는 것은 아니며 물리적으로 디바이스와 분리되어 별도의 위치에 설치될 수도 있다. 사용자 애플리케이션은 디바이스 내에 설치되며, AI 서버에 의해 추천받은 행동고지를 서비스 서버로부터 제공받아 사용자에게 알려주는 기능을 수행한다. 또한, 사용자 애플리케이션은 원격으로 서비스 서버에 접속하여 사용자의 실내에 설치된 디바이스 를 제어할 수 있다. 또한, 사용자 애플리케이션은 AI 서버로 사용자의 행동 데이터를 수집하여 제공할 수 있다. 즉, 사용 자 애플리케이션은 사용자에 의해 설정된 기간동안 사용자의 생활 패턴을 수집하도록 스케줄러 기능을 제 공할 수 있다. 또한, 사용자 애플리케이션은 서비스 서버로부터 수신한 환경 데이터가 정상적인 수치 범위가 아닌 경우에 해당 상황을 입력하도록 유도할 수 있다. 이를 위한 사용자 애플리케이션은 사용자의 조작이 용이한 인터페이스 화면을 제공하는데, 하기의 도 4 내 지 도 10과 같다. 도 4는 회원가입 및 설정 단계를 거친 후 일반적으로 제공되는 기본 홈 화면이다. 도시된 홈 화면에서, 도면부호 440은 모든 메뉴를 펼쳐보기 식으로 열람할 수 있는 메뉴버튼을 나타내고, 441은 상태 새로고침 메뉴버튼을 나타내고 있다. 도면부호 442는 나의 위치와 인접한 실외의 위치(예컨대, 강남대로) 및 실외의 대기상태(예컨대, 미세먼지 34, 초미세먼지 24)를 보여주는 상태 표시 영역이다. 상태 표시 영역 하 단에는 '나의 기기' 표시 영역으로 사용자의 실내 공간에 설치된 디바이스에 대한 정보를 표시한다. 즉, 도시된 443은 등록된 나의 디바이스(기기)를 삭제할 수 있는 삭제버튼, 445는 등록된 디바이스에 대하여 사용자의 활동 기록 사항, 446은 나의 디바이스에 대한 상태를 제공한다. 도 5는 도 4의 홈 화면에서 사용자의 활동 기록에 대한 입력 화면이다. 이의 상세 화면은 도 4에 도시된 사용자의 활동 기록 사항이 선택되어지면 표시되는 화면으로, 현재 하고 있는 활동을 태그하여 기록하도록 제공한다. 예를 들어, 일상, 운동, 요리, 청소 중 어느 하나의 활동을태그하여 저장할 수 있다. 이러한 활동 기록을 입력하는 과정을 통해, 사용자의 활동 데이터를 수집하는 것이 가능해질 것이다. 도 6은 도 4의 홈 화면에서 모든 메뉴보기에 대한 상세 화면이다. 즉, 도 4에 도시된 모든 메뉴 펼쳐보기가 선택되어지면 도 6의 461과 같이 다양한 메뉴 탭이 표시되고, 메 뉴 탭에서 원하는 메뉴가 선택되어지면 해당 기능을 수행하기 위한 인터페이스 화면이 표시된다. 다양한 메뉴에 서, 기기등록은 사용자의 실내 공간에 설치된 디바이스를 등록하기 위한 것이고, 활동 이력은 사용자의 활동 이 력을 표시한다. 활동 스케줄은 고정된 스케줄을 등록하기 위한 기능이며, 설정 탭은 사용자 주거 환경 데이터를 설정하는 기능이다. 도 7 내지 도 10은 이상에서 설명한 각 메뉴에 대한 상세 화면을 보여주고 있다. 도 7은 도 6에서의 활동 이력 메뉴에 대한 상세 인터페이스 화면을 보여주고 있다. 활동 이력 메뉴가 선택되어 지면, 화면에는 날짜, 시간별로 지정하여 활동 이력을 검색하는 검색 영역, 검색 결과 지정된 일정에 수행 되었던 활동 이력 목록이 표시되는 활동 이력 표시 영역이 제공된다. 도 8 및 도 9는 도 6에서의 활동 스케줄 메뉴에 대한 상세 인터페이스 화면이다. 도 8의 인터페이스 화면은 활 동 스케줄을 설정하기 위한 화면으로서, 활동 스케줄을 지정할 요일을 선택하는 영역, 스케줄 시간대를 설 정하는 영역, 스케줄을 적용할 기기 즉, 디바이스를 선택 지정하는 영역, 해당 스케줄로 지정할 활동 을 선택하는 영역이 제공될 수 있다. 도면부호 481은 홈 화면 또는 이전 화면을 되돌아가기 메뉴를 나타내 고 있다. 한편, 도 9의 인터페이스 화면에는 등록된 활동 스케줄의 목록을 보여주고 있다. 도면부호 492는 등록된 활동 스케줄을 삭제하기 위한 메뉴이다. 한편, 도 10은 도 6에서의 설정 메뉴에 대한 상세 인터페이스 화면이다. 여기서, 설정 메뉴는 사용자 주거 환경 데이터를 설정하는 기능으로, 주거 환경 데이터를 입력하는 화면이 제공 된다. 이를 테면, 개인 선호 온도를 지정하는 입력란, 주거 유형을 지정하는 입력란, 주거 층수를 지정하는 입력란, 공동 주거 세대원수를 지정하는 입력란을 포함하여 제공될 수 있다. 미설명부호 411은 홈 화 면 또는 이전 화면을 되돌아가기 메뉴이다. 이하, 도 11을 참조하여 본 발명의 실시예에 따른 인공지능 기반의 환경센서를 이용한 실내 상황인지 및 행동고 지 방법을 설명한다. 먼저 S100 단계에서, 서비스 서버가 다수의 환경센서를 통해 센싱된 실내 및 실외의 환경 데이터를 수집한다. 이때, 실외의 환경 데이터는 실내 공간과 인접한 위치의 실외로 한정할 수 있다. 따라서, 본 발명의 실시예에서 는 실외의 외부 대기를 기준으로 하여 실내 공간에 대한 공기질을 비교하여 판단할 수 있는 알고리즘을 제공하 고자 하기 위함이다. 다음 S200 단계에서, AI 서버가 서비스 서버로부터 수집된 실내 환경 데이터와 실외 환경 데이터, 사용자의 선 호도, 주거형태에 관한 주거 데이터, 행동 데이터에 의거 학습시킨 인공지능을 통해 환경 데이터에 대한 실내의 상황을 인지한다. 즉, 사용자의 생활 패턴에 근거하여 실내 공기질에 대한 현재 상황을 인지한다. 예를 들어, 실내 공기질이 상대적으로 높은 상황에 사용자의 활동 이력에 따르면 현재 청소 중이라고 상황을 판단할 수 있 다. 다음 S300 단계에서, AI 서버가 상황인지에 따른 행동고지를 추천할 수 있다. 전자의 예를 들자면, AI 서버는 청소 중이라는 상황 인지에 따라 창문을 열어라 또는 공기청정기를 가동시키는 행동 고지를 추천할 수 있을 것 이다. 다음 S400 단계에서, 서비스 서버가 AI 서버의 추천에 따라 사용자 애플리케이션을 통해 사용자에게 해당 행동 고지를 알릴 수 있다. 다음 S500 단계에서, 서비스 서버가 AI 서버로부터 추천받은 행동고지에 따라 실내의 온도, 습도, 환기 중 적어 도 하나 이상을 제어하기 위한 제어신호를 디바이스로 전달할 수 있다. 이상의 설명은 본 발명을 예시적으로 설명한 것에 불과하며, 본 발명이 속하는 기술 분야에서 통상의 지식을 가 진 자에 의해 본 발명의 기술적 사상에서 벗어나지 않는 범위에서 다양한 변형이 가능할 것이다. 따라서 본 발 명의 명세서에 개시된 실시예들은 본 발명을 한정하는 것이 아니다. 본 발명의 범위는 아래의 특허청구범위에 의해 해석되어야 하며, 본 출원 시점에 있어서 이들을 대체할 수 있는 다양한 균등물과 변형 예들은 본 발명의 범위에 포함되는 것으로 해석해야 할 것이다.\n【요약】본 발명은 서울특별시 서울산업진흥원 2020년도 포스트 코로나 특화 인공지능 기술사업화 지원사업(CY201023)의 \"환경감지 IoT 융합센서 시스템을 이용한 상황인지 A·I 학습 고도화\" 과제를 통해 개발된 기술이다. 본 발명은 다수의 환경센서를 이용하여 측정된 환경 센싱값을 학습 모델에 기반하여 실내 오염의 상황을 인지하 (뒷면에 계속)\n\n【청구항 1】\n실내 또는 상기 실내와 인접한 위치의 실외에 대하여 환경 데이터를 측정하는 다수의 환경센서;상기 실내에 설치되고 상기 실내의 온도, 습도, 환기를 제어하기 위한 디바이스;상기 다수의 환경센서를 통해 측정된 실내 및 실외 환경 데이터를 수집하는 서비스 서버;상기 서비스 서버로부터 수집된 실내 환경 데이터와 실외 환경 데이터, 사용자의 선호도, 주거형태에 관한 주거데이터, 행동 데이터에 기반하여 학습 모델을 구축하고 상기 학습 모델을 통해 상기 환경 데이터에 대한 실내의상황을 인지하고 그에 적합한 행동고지를 추천하는 AI 서버;를 포함하는 것을 특징으로 하는 을 특징으로 하는 인공지능 기반의 환경센서를 이용한 환경 상황인지 및 행동고지 시스템.\n【청구항 2】\n제1항에 있어서,상기 서비스 서버는, 상기 AI 서버로부터 추천받은 행동고지에 따라 실내의 온도, 습도, 환기 중 적어도 하나이상을 제어하기 위한 제어신호를 상기 디바이스로 전달하는 것을 특징으로 하는 인공지능 기반의 환경센서를이용한 환경 상황인지 및 행동고지 시스템.\n【청구항 3】\n제1항에 있어서,상기 디바이스에 설치되고 상기 AI 서버에 의해 추천받은 행동고지를 상기 서비스 서버로부터 제공받아 사용자에게 알려주는 사용자 애플리케이션;을 더 포함하는 것을 특징으로 하는 인공지능 기반의 환경센서를 이용한 환경 상황인지 및 행동고지 시스템.\n【청구항 4】\n제3항에 있어서,상기 AI 서버는,상기 사용자 애플리케이션을 통해 사용자의 생활 패턴에 따라 미리 입력해둔 스케줄러에 의해 상기 행동 데이터를 수집하는 것을 특징으로 하는 인공지능 기반의 환경센서를 이용한 환경 상황인지 및 행동고지 시스템.\n【청구항 5】\n제3항에 있어서,상기 AI 서버는,각각의 환경센서를 통해 측정된 환경 데이터가 정상적인 수치범위를 벗어난 경우 상기 사용자 애플리케이션을통해 사용자에게 알리고, 상기 사용자로 하여금 해당 상황을 입력하도록 유도하여 상기 행동 데이터를 수집하는것을 특징으로 하는 인공지능 기반의 환경센서를 이용한 환경 상황인지 및 행동고지 시스템.공개특허 10-2023-0065028-3-청구항 6 제1항에 있어서, 상기 다수의 환경센서는, 온도 센서, 습도센서, 미세 먼지 센서, CO2 센서 중 어느 하나 이상을 포함하는 융합센서이고,실외에 구축되는 경우 공공 API를 통해 상기 서비스 서버로 환경 데이터를 제공하는 것을 특징으로 하는 인공지능 기반의 환경센서를 이용한 환경 상황인지 및 행동고지 시스템.\n【청구항 7】\n제3항에 있어서, 상기 사용자 애플리케이션은, 상기 서비스 서버에 네트워크 접속하여 상기 디바이스를 원격 제어할 수 있는 것을 특징으로 하는 인공지능 기반의 환경센서를 이용한 환경 상황인지 및 행동고지 시스템.\n【청구항 8】\n서비스 서버가 다수의 환경센서를 통해 센싱된 실내 또는 상기 실내와 인접한 위치의 실외에 대하여 환경 데이터를 수집하는 단계;AI 서버가 상기 서비스 서버로부터 수집된 실내 환경 데이터와 실외 환경 데이터, 사용자의 선호도, 주거형태에관한 주거 데이터, 행동 데이터에 의거 학습시킨 인공지능을 통해 상기 환경 데이터에 대한 실내의 상황을 인지하는 단계; 및상기 AI 서버가 상기 상황인지에 따른 행동고지를 추천하는 단계;를 포함하는 인공지능 기반의 환경센서를 이용한 환경 상황인지 및 행동고지 방법."}
{"context": "", "input": "【기술명】\n인공지능 기반 스토리 생성 시스템의 인터페이스 제공 방법\n\n【기술 설명】\n본 발명은 인공지능 기반 스토리 생성 시스템의 인터페이스 제공 방법에 관한 것으로, 문서 작성자가 인공지능과 자연어로 상호작용할 수 있는 대화형 인터페이스를 구현합니다. 이 시스템은 두 가지 주요 요소로 구성되며, 첫 번째는 현재 작성 중인 문서를 표시하는 '문서 뷰'이고, 두 번째는 문장 생성 모듈과의 대화형 상호작용을 위한 '대화 뷰'입니다. 이 두 요소는 디스플레이 화면에서 상이한 영역으로 제공되며, 문서 작성자의 조작 형태에 따라 문장 생성 모듈의 스토리 생성 모드를 자동으로 선택적으로 활성화합니다. 이를 통해, 문서 작성자는 보다 직관적이고 효율적인 방식으로 스토리 생성 과정을 진행할 수 있습니다.\n\n【해결 문제】\n기존의 인공지능 기반 스토리 생성 시스템은 문서 작성자가 인공지능과 상호작용하는 방식이 제한적이었으며, 주로 '다음 문장 추천' 또는 '재작성' 모드에 의존했습니다. 이러한 제한적인 인터페이스는 문서 작성자의 의도를 충분히 전달하지 못하고, 결과적으로 생성된 스토리의 품질이 저하될 수 있는 문제를 초래하였습니다. 본 발명은 문서 뷰와 대화 뷰를 통합하여 문서 작성자가 인공지능과의 상호작용을 보다 직관적으로 수행할 수 있도록 하고, 이를 통해 스토리 작성 과정에서의 사용자 편의성과 작업 생산성을 개선합니다. 궁극적으로, 이는 문서 작성자가 보다 풍부하고 정교한 스토리를 생성할 수 있는 환경을 제공합니다.\n\n【기술 차별성】\n본 발명의 혁신성은 사용자 인터페이스의 양방향성이며, 문서 작성자가 자연어로 인공지능과 실시간으로 상호작용할 수 있도록 설계된 점에서 기존 기술과 확연히 차별화됩니다. 기존의 스토리 생성 시스템은 주로 정해진 형식에 따라 작동하여 사용자의 입력을 제한했으나, 본 발명은 사용자 조작에 따라 스토리 생성 모드를 유연하게 전환함으로써 맞춤형 상호작용을 제공합니다. 이러한 차별화된 접근 방식은 인공지능의 대응력을 극대화하고, 결과적으로 생성되는 스토리의 품질을 획기적으로 향상시키는 데 기여합니다. 따라서, 본 발명은 인공지능 기반 스토리 생성의 새로운 패러다임을 제시하며, 시장에서의 경쟁력을 높일 수 있는 강력한 기술적 우위를 제공합니다.\n\n【활용 분야】\n본 발명은 문서 작성 및 콘텐츠 생성이 필요한 다양한 분야와 산업에 광범위하게 활용될 수 있습니다. 특히 출판업, 영화 및 게임 시나리오 작성, 교육 및 학습 자료 개발 등에서 인공지능 기반 스토리 생성 시스템은 창작자의 작업 효율성을 극대화하고, 창의적인 콘텐츠 생산을 지원합니다. 또한, 마케팅 및 광고 분야에서도 고객 맞춤형 콘텐츠를 자동으로 생성하는 데에 활용될 수 있어, 기업의 브랜드 메시지를 효과적으로 전달하는 데 기여할 것입니다.\n\n【구성 요소 및 기능】\n본 발명의 핵심 구성 요소는 다음과 같습니다. 첫째, 문서 뷰는 현재 작성 중인 콘텐츠를 시각적으로 표시하여 문서 작성자가 자신이 작업 중인 내용을 즉시 확인할 수 있도록 합니다. 둘째, 대화 뷰는 인공지능 기반 문장 생성 모듈과의 자연어 상호작용을 통해 사용자가 직관적으로 명령을 입력하고 피드백을 받을 수 있는 인터페이스를 제공합니다. 셋째, 스토리 생성 모드 선택 기능은 사용자가 문서 뷰에서의 조작에 따라 자동으로 다음문장 추천 모드와 재작성 모드 중 하나를 활성화하여, 보다 적합한 문장을 생성할 수 있도록 지원합니다.\n\n【구현 방식 예】\n본 발명은 다음과 같은 단계로 구현됩니다. 첫째, 컴퓨터 장치는 사용자에게 문서 뷰와 대화 뷰를 각각의 화면 영역에 표시하여, 두 가지 인터페이스 요소를 제공합니다. 둘째, 문서 작성자가 문서 뷰에서 수행하는 조작을 감지하여, 자동으로 스토리 생성 모드를 선택적으로 활성화합니다. 셋째, 활성화된 모드에 따라 인공지능 문장 생성 모듈이 사용자의 요청에 최적화된 문장을 추천하거나 재작성하여, 최종적으로 사용자가 만족할 수 있는 품질의 콘텐츠를 생성할 수 있도록 합니다. 이러한 구현 방식은 직관적이면서도 효율적인 사용자 경험을 보장합니다.", "output": "【발명의 명칭】\n인공지능 기반 스토리 생성 시스템의 인터페이스 제공 방법\n【기술분야】\n본 발명은 일반적으로 인공지능 기반 스토리 생성을 위한 인터페이스 제공 기술에 관한 것이다. 특히, 본 발명은 현재 작성중인 문서를 표시하는 영역인 문서 뷰와 문장 생성 모듈(SGM)과의 대화형 상호작용을 제공하는 영역인 대화 뷰를 구비한 대화형 인터페이스를 제공하여 문서 작성자가 인공지능 기반 문장 생성 모듈 (SGM)과 자연어로 상호작용할 수 있도록 인터페이스를 구성하고 문서 뷰에서의 문서 작성자의 조작 형태에 대응 하여 문장 생성 모듈(SGM)의 스토리 생성 모드(다음문장 추천 모드, 재작성 모드)를 선택적으로 활성화하며 그 활성화된 스토리 생성 모드에 따라 대화 뷰의 구성 및 상호작용을 상이하게 구성하는 인공지능 기반 스토리 생 성 시스템의 인터페이스 제공 기술에 관한 것이다.\n【배경기술】\n일반적으로 '스토리 자동 생성(automatic story generating)'이란 컴퓨터 장치가 수행하는 컴퓨터 프로그램을 이용한 자동 글쓰기(automatic writing)를 의미한다. 종래로 스토리 자동 생성을 위한 다양한 기술이 제안되었 으며, 최근에는 인공지능(AI) 기술을 도입하려는 시도가 활발하게 이루어지고 있다. 종래의 인공지능 기반 스토리 생성 시스템의 인터페이스 방식은 문서 생성 목적에 따라 두 가지로 나뉜다. 첫 번째는 주어진 텍스트의 다음에 올 문장을 추천하는 \"다음문장 추천\" 방식이고, 두 번째는 주어진 텍스트의 전 부 또는 일부를 인공지능이 재작성하는 \"재작성\" 방식이다. [도 1]과 [도 2]는 종래기술의 인공지능 기반 스토 리 생성 시스템에서 사용하는 인터페이스의 예를 나타내는 도면이다. [도 1]은 종래기술의 다음문장 추천 인터 페이스이고, [도 2]는 종래기술의 재작성 인터페이스이다. 종래기술에서 첫 번째 방식인 \"다음문장 추천\"하는 예로는 Write With Transformer와 Gmail을 들 수 있다. [도 1]은 Write With Transformer의 다음문장 추천 인터페이스를 나타내는 도면이다. 메인 윈도우에는 문서 작성자 가 입력한 텍스트가 표시되는데, 문서 작성자가 단축키 또는 특정 버튼을 누르면 현재 텍스트에 이어서 확률적 으로 나올 가능성이 높은 다음 문장을 추천해준다. 이때, [도 1]의 좌측 하단에는 다음문장 추천 기능에 관한 설정 메뉴가 있다. 종래기술에서 두 번째 방식인 \"텍스트의 전부 또는 일부를 인공지능이 재작성\"하는 예로는 Shedko , Gabriel et al.의 Inkwell , 그리고 Gero와 Chilton의 단어 임베딩 기반 유의어 사전인 Metaphoria 를 들 수 있다. 이들 기술은 텍스트의 선택된 부분(예: 단어, 문장)이나 텍스트 전체를 미리 정해진 변환 형식에 따라 재작성하여 문서 작성자에게 제공한다. [도 2]는 재작성 인터페이스인 Metaphoria의 유의어 추천 인터페이스를 나타내는 도면이다. 하나의 단어가 선택되면 그와 관련된 의미가 있는 연상 키워드를 추천한다. 종래기술의 문제점은 인공지능 기반의 문장 생성 모듈(Sentence Generation Module: SGM)에 문서 작성자의 입력 을 전달하는 인터페이스 구성에 있다. 종래기술은 SGM이 새로운 문장을 생성하거나 기존 문장을 변환하는 과정 에서 문서 작성자가 SGM에 전달할 수 있는 입력(지시)의 형태가 제한적이다. 구체적으로, [도 1]에서 살펴본 종래기술의 다음문장 추천 인터페이스는 버튼과 슬라이더 메뉴를 통해 SGM의 파 라미터를 직접 조작해야 하는 번거로움이 있다. [도 2]에서 살펴본 종래기술의 재작성 인터페이스는 미리 정해 진 인터페이스의 틀 안에서 SGM의 동작을 조작해야 한다. 예를 들어, [도 2]에서 Metaphoria는 주어진 추천 단 어 중에서 하나를 선택해야 하며, 그 외에는 SGM에 별다른 입력을 전달할 수 없다.\n【해결하려는 과제】\n본 발명의 목적은 일반적으로 인공지능 기반 스토리 생성을 위한 인터페이스 제공 기술을 제공하는 것이다. 특히, 본 발명의 목적은 현재 작성중인 문서를 표시하는 영역인 문서 뷰와 문장 생성 모듈(SGM)과의 대화형 상 호작용을 제공하는 영역인 대화 뷰를 구비한 대화형 인터페이스를 제공하여 문서 작성자가 인공지능 기반 문장 생성 모듈(SGM)과 자연어로 상호작용할 수 있도록 인터페이스를 구성하고 문서 뷰에서의 문서 작성자의 조작 형 태에 대응하여 문장 생성 모듈(SGM)의 스토리 생성 모드(다음문장 추천 모드, 재작성 모드)를 선택적으로 활성 화하며 그 활성화된 스토리 생성 모드에 따라 대화 뷰의 구성 및 상호작용을 상이하게 구성하는 인공지능 기반 스토리 생성 시스템의 인터페이스 제공 기술을 제공하는 것이다. 한편, 본 발명의 해결 과제는 이들 사항에 제한되지 않으며 본 명세서의 기재로부터 다른 해결 과제가 이해될 수 있다.\n【과제의 해결 수단】\n상기의 목적을 달성하기 위하여 본 발명은 컴퓨터 장치가 컴퓨터 화면을 통해 문서 작성자와 인공지능 기반 스 토리 생성 시스템 간에 스토리 자동 생성을 위한 인터페이스를 제공하는 방법을 제공한다. 본 발명에 따른 인공지능 기반 스토리 생성 시스템의 인터페이스 제공 방법은, 현재 작성중인 문서를 표시하는 문서 뷰(document view; DCV)를 문서 작성자를 위한 제 1 인터페이스 요소로 제공하는 제 1 단계; 인공지능 기 반 문장 생성 모듈(SGM)과 문서 작성자 간의 대화형 상호작용을 제공하기 위한 대화 뷰(interaction view; IR V)를 문서 작성자를 위한 제 2 인터페이스 요소로 제공하는 제 2 단계-- 문서 뷰(DCV)와 대화 뷰(IRV)는 디스플 레이 화면에 상이한 영역으로 제공됨 --; 문서 작성자가 문서 뷰(DCV)에서 수행하는 조작 형태에 기초하여 자동 적으로 다음문장 추천 모드와 재작성 모드의 두 가지 스토리 생성 모드 중에서 한 가지를 선택적으로 활성화하 는 제 3 단계; 다음문장 추천 모드가 활성화된 경우, 문서 뷰(DCV)에서 윈도우 커서가 가리키는 문서 위치에 대 한 다음문장 추천을 문장 생성 모듈(SGM)에 지시하는 제 4 단계; 재작성 모드가 활성화된 경우, 문서 뷰(DCV)에 서 문서 작성자가 선택한 텍스트 부분(이하, '선택 텍스트'라 함)에 대한 재작성을 문장 생성 모듈(SGM)에 지시 하는 제 5 단계; 그 활성화된 스토리 생성 모드에 따라 다음문장 추천 또는 선택 텍스트 재작성에 관련된 자연 어 형식의 지시사항을 설정하여 문장 생성 모듈(SGM)로 전달하는 제 6 단계; 그 활성화된 스토리 생성 모드에 대응하여 문장 생성 모듈(SGM)이 생성한 추천 문장을 문장 생성 모듈(SGM)로부터 제공받아 대화 뷰(IRV)에 표시 하는 제 7 단계; 대화 뷰(IRV) 상에 이루어지는 문서 작성자의 선택에 따라 그 활성화된 스토리 생성 모드에 대 응하여 추천 문장을 문서 뷰(DCV)에 반영하는 제 8 단계;를 포함하여 구성될 수 있다. 또한, 제 3 단계는, 문서 뷰(DCV)에서 윈도우 커서가 현재 작성 중인 문서의 어느 한 지점에 멈추면 다음문장 추천 모드를 활성화하는 단계; 문서 뷰(DCV)에서 현재 작성 중인 문서에서 문장이나 단어에 대한 선택이 감지되 면 재작성 모드를 활성화하는 단계;를 포함하여 구성될 수 있다. 또한, 제 8 단계는, 다음문장 추천 모드가 활성화된 경우에 문서 뷰(DCV)에서 윈도우 커서가 가리키는 문서 위 치에 추천 문장을 삽입하는 단계; 재작성 모드가 활성화된 경우에 문서 뷰(DCV)에서 선택 텍스트를 추천 문장으 로 대체하는 단계;를 포함하여 구성될 수 있다. 또한, 제 2 단계는, 문장 생성 모듈(SGM)과 문서 작성자 간의 대화형 상호작용을 제공하기 위한 대화 뷰(IRV)를 문서 작성자를 위한 제 2 인터페이스 요소로 제공하는 단계; 문서 작성자의 지시 사항과 문장 생성 모듈(SGM)의 응답이 쌍(pair)을 이루어 구성된 대화 내역을 저장 표시하기 위한 대화내역 창(interaction history window; IHW)을 대화 뷰(IRV)의 표시 영역 내에 제 1 인터페이스 요소로 제공하는 단계; 문서 작성자가 문장 생성 모듈 (SGM)에 지시 사항을 입력하기 위한 지시 창(command window; CMW)을 대화 뷰(IRV)의 표시 영역 내에 제 2 인터페이스 요소로 제공하는 단계-- 대화내역 창(IHW)과 지시 창(CMW)은 대화 뷰(IRV)의 표시 영역 내에 상이한 영역으로 제공됨 --;를 포함하여 구성될 수 있다. 이때, 제 6 단계는, 다음문장 추천 모드가 활성화된 경우에 지시 창(CMW)을 통해 윈도우 커서가 놓여진 위치에 문서 작성자가 표현하려는 내용을 담은 자연어 형식의 테스 트 문장을 지시사항으로 입력받아 문장 생성 모듈(SGM)로 전달하는 단계; 재작성 모드가 활성화된 경우에 문서 뷰(DCV)에서 식별한 자연어 형식의 선택 텍스트를 지시사항으로 설정하여 문장 생성 모듈(SGM)로 전달하는 단계;를 포함하여 구성될 수 있다. 이때, 제 7 단계는, 그 활성화된 스토리 생성 모드에 대응하여 문장 생성 모 듈(SGM)이 생성한 추천 문장을 문장 생성 모듈(SGM)로부터 제공받아 대화내역 창(IHW)에 표시하는 단계;를 포함 하여 구성될 수 있다. 또한, 제 7 단계는, 추천 문장과 연계하여 복수의 선택사항을 대화내역 창(IHW)에 표시하는 단계; 대화내역 창 (IHW)에서 문서 작성자에 의한 제 1 사항의 선택이 식별되면, 다음문장 추천 모드가 활성화된 경우에 문서 뷰 (DCV)의 현재 작성 중인 문서에서 윈도우 커서가 표시된 부분에 추천 문장을 삽입 처리하고, 재작성 모드가 활 성화된 경우에 문서 뷰(DCV)의 현재 작성 중인 문서에서 추천 문장에 의해 선택 텍스트를 대체 처리하는 단계; 대화내역 창(IHW)에서 문서 작성자에 의한 제 2 사항의 선택이 식별되면, 추천 문장을 버림 처리하는 단계;를 포함하여 구성될 수 있다. 또한, 본 발명에 따른 인공지능 기반 스토리 생성 시스템의 인터페이스 제공 방법은, 제 7 단계 이후에 수행되 는, 인공지능 기반 문장 생성 모듈(SGM)의 스토리 자동 생성에 관한 인공지능 학습을 위해 대화내역 창(IHW)에 서 복수의 선택사항 중 문서 작성자에 의한 선택 결과를 문장 생성 모듈(SGM)로 전달하는 단계;를 더 포함하여 구성될 수 있다. 한편, 본 발명에 따른 컴퓨터프로그램은 컴퓨터에 이상과 같은 인공지능 기반 스토리 생성 시스템의 인터페이스 제공 방법을 실행시키기 위하여 비휘발성 저장매체에 저장된 것이다.\n【발명의 효과】\n본 발명에 따르면 문서 작성자가 문장 생성 모듈(SGM)과 자연어로 상호작용하는 것이 가능하여 문서 작성자의 의도를 정확하고 구체적이고 풍부하게 문장 생성 모듈로 전달할 수 있으며, 그에 따라 인공지능 기반으로 자동 생성된 스토리의 품질을 높일 수 있는 장점이 있다. 또한, 본 발명에 따르면 문서 작성자가 문장 생성 모듈(SGM)에 지시 사항을 입력하는 데에 필요한 조작을 간소 화할 수 있어 스토리 작성 과정에 사용자의 편의를 대폭 개선할 수 있으며, 그에 따라 문서 작성에 관한 작업 생산성을 개선할 수 있는 장점이 있다.\n【발명을실시하기위한구체적인내용】\n이하에서는 도면을 참조하여 본 발명을 상세하게 설명한다. 인공지능 기반으로 스토리를 생성할 때에 문서 작성자가 어떤 문장이 생성되어야할지 문장 생성 모듈(SGM)에 정 확하고 구체적이며 풍부하게 지시를 내릴 수 있는 방식은 자연어를 입력하는 것이다. 예를 들어, \"이 문장을 하 드보일드 문체로 재작성하라\"를 들 수 있다. 종래기술의 인터페이스 방식에서는 SGM에 자연어 형태의 명령을 내 릴 수 없었다. 본 발명에서는 인공지능 기반 스토리 생성 시스템에서 자연어를 통해 SGM과 상호작용 가능한 대화형 인터페이스 를 제시한다. [도 3] 내지 [도 6]은 본 발명에서 대화형 인터페이스의 일 예를 나타낸다. [도 3]과 [도 4]는 \" 다음문장 추천\" 모드의 대화형 인터페이스이고 [도 5]와 [도 6]은 \"재작성\" 모드의 대화형 인터페이스이다. 본 발명에서 컴퓨터 화면을 통해 이루어지는 문서 작성자와 인공지능 기반 스토리 생성 시스템 간의 대화형 인 터페이스는 두 가지 인터페이스 요소를 갖는데, 본 명세서에서는 이를 편의상 문서 뷰(document view; DCV)와 대화 뷰(interaction view; IRV)라고 부른다. 문서 뷰는 현재 작성중인 문서를 표시하는 영역이고, 대화 뷰는 인공지능 기반 문장 생성 모듈(SGM)과 문서 작성자 간의 대화형 상호작용을 제공하는 영역이다. [도 3] 내지 [도 6]에서 좌측 윈도우는 문서 뷰이고 우측 윈도우는 대화 뷰이다. [도 3] 내지 [도 6]에 나타낸 바와 같이 다 음문장 추천 모드와 재작성 모드 모두 문서 뷰와 대화 뷰의 인터페이스 요소를 갖는다. 문서 뷰(DCV)는 문서 작성자가 현재 작성중인 문서를 표시하는 영역이다. 문서 뷰 상에서 문서를 작성하고 있는 중일 수도 있고, 다른 문서작성기(예: MS Word)에서 작성한 문서를 읽어들여와 수정하는 중일 수도 있다. 문서 작성자가 문서 뷰(DCV)에서 수행하는 조작 형태에 기초하여 두 가지 종류의 스토리 생성 모드(다음문장 추 천 모드, 재작성 모드) 중에서 한 가지가 선택적으로 활성화된다. 이때, 스토리 생성 모드의 선택적인 활성화는 문서 작성자가 어떠한 모드 설정 조작을 하는 것이 아니라 문서 뷰(DCV) 상에서 이루어지는 문서 작성자의 조작 형태에 기초하여 자동적으로 수행된다. 문서 뷰에서 윈도우 커서가 현재 작성 중인 문서의 어느 한 지점에 멈추 면, [도 3] 및 [도 4]와 같이 다음문장 추천 모드가 활성화된다. 다음문장 추천 모드에서는 문서 뷰에서 윈도우 커서가 가리키는 문서 위치에 대한 다음 문장을 추천해야 한다는 것을 문장 생성 모듈(SGM)에 지시한다. 한편, 문서 뷰에서 현재 작성 중인 문서의 일부분(문장이나 단어)에 대한 선택이 감지되면, [도 5] 및 [도 6]과 같이 재작성 모드가 활성화된다. 재작성 모드에서는 문서 뷰에서 문서 작성자가 선택한 텍스트 부분(문장, 단어), 즉 '선택 텍스트'에 대한 재작성을 문장 생성 모듈(SGM)에 지시한다. 대화 뷰(IRV)는 문서 작성자가 인공지능 SGM에 다음문장 추천이나 재작성에 관련된 지시사항(command)을 자연어 로 입력하기 위한 공간이다. 본 발명에 따른 대화형 인터페이스는 이 지시사항을 입력받아 인공지능 SGM으로 전 달한다. 이때, 대화 뷰의 입력 인터페이스는 그 활성화된 스토리 생성 모드에 따라서 상이하게 설정된다. [도 3]과 [도 4]는 다음문장 추천 모드가 활성화된 모습이고, [도 5]와 [도 6]은 재작성 모드가 활성화된 모습이다. 본 발명에서 대화 뷰(IRV)는 두 가지 인터페이스 요소를 갖는데, 본 명세서에서는 이를 편의상 대화내역 창 (interaction history window; IHW)과 지시 창(command window; CMW)이라고 부른다. [도 3] 내지 [도 6]에서 대화내역 창은 우측 상단에 표시되고 지시 창은 우측 하단에 표시된다. 대화내역 창과 지시 창에서 우측의 녹색 은 문서 작성자가 타이핑 입력한 텍스트이고 좌측의 파란색은 인공지능 SGM이 생성한 텍스트이다. 대화내역 창(IHW)은 인공지능 SGM과 문서 작성자의 1대1 메신저 대화와 같이 문서 작성자의 지시 사항과 인공지 능 SGM의 응답이 쌍(pair)을 이루어 구성된 대화 내역을 저장 표시한다. 지시 창(CMW)은 문서 작성자가 인공지능 SGM에 지시 사항을 입력하는 인터페이스 요소이다. 지시 창에는 그 선 택된 스토리 생성 모드에 대응하는 레이블(label)이 표시될 수 있다. [도 3]을 참조하면, 다음문장 추천 모드에 서는 \"I would like a suggestion. (이 위치에 적합한 문장을 추천하시오)\"라는 레이블이 표시되어 있다. [도 5]를 참조하면, 재작성 모드에서는 \"Please rewrite this text. (이 텍스트를 재작성하시오)\"라는 레이블이 표 시되어 있다. [도 3]과 [도 4]를 참조하면, 문서 뷰(DCV)에서 윈도우 커서가 현재 작성 중인 문서의 어느 한 지점에 멈추어져 있기에 스토리 생성 모드는 자동적으로 다음문장 추천 모드가 활성화되어 있고 대화 뷰(IRV)도 다음문장 추천 모드에 맞게 설정된다. 다음문장 추천 모드에서 문서 작성자는 그 윈도우 커서가 놓여진 위치에 자신이 표현하 려는 내용을 담은 테스트 문장을 지시 창(CMW)에 입력하고 \"Send\" 버튼을 누른다. 인공지능 SGM은 그 테스트 문 장의 내용을 참고하여 문서 뷰에서 윈도우 커서가 가리키는 문서 위치에 대한 다음 문장을 추천한다. [도 3]에서 문서 작성자는 윈도우 커서가 놓여진 지점에 자신이 표현하려는 내용으로서 \"The house doesn't interact with other people while conversing with Lily. The narrator is forced to do things like turning on the TV manually.\"라는 테스트 문장을 지시 창(CMW)에 입력하고 \"Send\" 버튼을 눌렀다. 이 테스트 문장은 인공지능 SGM에 다음문장의 생성에 관한 지시사항이다. 이처럼 본 발명에서는 지시사항을 자연어 형식으 로 제공할 수 있다. 그에 대응하여, [도 4]에서 인공지능 SGM이 추천한 문장 \"Of couser, during those hours that she spent connecting, the house would steadfastly refuse to connect with me. I would have to demote myself to the tedious task of turning on the television by hand. Once I even had to turn off the living room lights myself.\"가 대화내역 창(IHW)에 표시되었다. 그리고, 대화내역 창(IHW)에는 이 추천 문장과 연계하여 두 가지 선택사항이 표시되어 있다. 문장 작성자가 첫번째 사항을 선택하면 문장 작성자가 그 추천 문장이 맘에 들 었다는 것을 의미하므로, 문서 뷰(DCV)에 표시된 현재 작성 중인 문서에서 윈도우 커서가 표시된 부분에 그 추천 문장이 삽입된다. 만일 문장 작성자가 두번째 사항을 선택하면 문장 작성자가 그 추천 문장이 맘에 들지 않 았다는 것을 의미하므로 그 추천 문장은 버려진다. 본 발명에서 인공지능 SGM은 대화내역 창(IHW)에서 추천 문 장에 대한 문장 작성자의 선택에 기초하여 스토리 자동 생성에 관한 학습을 수행하는 것이 바람직하다. [도 5]와 [도 6]을 참조하면, 문서 뷰(DCV)에서 현재 작성 중인 문서의 일부분 \"Then she would converse for hours, and I would never hear a response.\"에 대한 선택을 식별함에 따라, 스토리 생성 모드는 자동적으로 재작성 모드가 활성화되어 있고 대화 뷰(IRV)도 재작성 모드에 맞게 설정된다. 이때, 선택 텍스트는 인공지능 SGM에 대체문장 재작성에 관한 지시사항이다. 이처럼 본 발명에서는 지시사항을 자연어 형식으로 제공할 수 있 다. [도 5]에서 인공지능 SGM은 선택 텍스트를 재작성하여 \"They talked mysteriously for house but I could never pick up who was talking on the other side.\"를 추천하였으며, 그 히스토리가 대화내역 창(IHW)에 표시 되어 있다. 그리고, 문서 작성자가 첫번째 사항을 선택하면 문서 뷰(DCV)에 표시된 현재 작성 중인 문서에서 그 추천 문장이 선택 텍스트를 대체한다. [도 6]에서 문서 뷰(DCV)는 문서 작성자가 첫번째 사항을 선택하여 위 추 천 문장이 선택 텍스트를 대체한 결과를 나타낸다. 반대로 문서 작성자가 두번째 사항을 선택하면 그 추천 문장 은 버려진다. 재작성 모드에서도 대화내역 창(IHW)에서 추천 문장에 대한 문장 작성자의 선택에 기초하여 인공 지능 SGM의 스토리 자동 생성에 관한 인공지능 학습을 수행하는 것이 바람직하다. 한편, 문서 작성자가 지시 창에 아무런 내용을 작성하지 않고 \"Send\" 버튼을 누르는 경우, 인공지능 SGM은 별도 의 맥락 없이 그 선택된 타겟 텍스트와 그 선택된 스토리 생성 모드에 따라 문장을 생성하고 그 생성된 문장을 추천해서 대화내역 창에 표시한다. 또한, 문서 작성자는 그 선택된 스토리 생성 모드가 어떤 문장을 생성할지를 자연어로 표현하여 지시 창에 입력할 수 있다. 예를 들어, \"하드보일드 문체를 사용하여\", \"격정적인 표현을 활 용하여\", \"최대한 간결하게\" 등을 들 수 있다. 그러면, 그 입력된 지시 내용은 인공지능 기반의 SGM에 스토리 생성에 관한 맥락 정보(context information)로 추가된다. 인공지능 기반의 문장 생성 모듈(SGM)으로 종래 제시된 기술로는 Generative Pre-trained Transformer 3(GPT- 3)를 들 수 있다. GPT-3는 딥러닝을 이용해 인간스러운 텍스트를 만들어내는 자기회귀 언어 모델로서 OpenAI사 가 개발한 GPT-n 시리즈의 3세대 언어 예측 모델이다. GPT-3에 의하면 각종 언어 관련 문제풀이, 랜덤 글짓기, 간단한 사칙연산, 번역, 주어진 문장에 따른 간단한 웹 코딩이 가능하다. GPT-3와 같은 Transformer 기반 SGM은 문서 형태로 작성된 스크립트를 입력으로 받고 그에 따라 나올 확률이 높 은 텍스트를 생성한다. 따라서 본 발명은 인터페이스 상에 문서 작성자가 입력한 텍스트를 스크립트로 변환하는 템플릿을 구비한다. 문서 작성자가 \"Send\" 버튼을 누를 때마다 [도 7] 및 [도 8]에서 \"<>\"로 표기된 부분이 모 두 문서 작성자가 입력한 텍스트로 변환되어 작성된 스크립트가 SGM에 입력된다. [도 7]과 [도 8]은 본 발명에서 인공지능 기반 SGM의 스크립트 템플릿의 예를 나타내는 도면이다. [도 7]은 다 음문장 추천 모드에서 인공지능 기반 SGM의 스크립트 템플릿을 나타내고, [도 8]은 재작성 모드에서 인공지능 기반 SGM의 스크립트 템플릿을 나타낸다. SGM이 성공적으로 \"응답:\" 이후에 따라오는 출력 텍스트를 작성하면 그 출력이 대화내역 창에 표시된다. 대화내 역 창에서 문서 작성자가 체크박스를 선택하면 출력 텍스트의 내용이 문서 뷰로 옮겨간다. 다음문장 추천 모드 에서는 출력 텍스트가 커서 위치에 추가되고, 재작성 모드에서는 출력 텍스트가 선택 텍스트를 대체한다. 본 발명에서는 문서 뷰의 커서 위치나 텍스트 선택 여부에 따라 스토리 생성 시스템의 두 모드를 전환하는 기능 이 채택되었다. 이로 인해, 문서 작성자가 SGM에 지시 사항을 입력하는 데에 필요한 조작을 1회의 마우스 클릭 또는 1회의 드래그 입력 정도로 줄여준다. 즉, 본 발명에서는 다음문장 추천 또는 재작성을 원하는 타겟 텍스트 의 위치를 별도로 대화 뷰에 입력할 필요가 없다. 또한, 스토리 생성 과정에서 가장 많이 사용되는 두 가지 모 드, 즉 다음문장 추천 모드와 재작성 모드를 전환하기 위한 별도의 입력이 필요하지 않다. 본 발명에 따르면 스 토리 작성 과정에 사용자의 편의를 대폭 개선할 수 있는 장점이 있다. 문서 작성은 인지 부하가 큰 창의적 작업이다. 따라서 복잡한 메뉴 선택을 없애고 적은 조작으로 타겟 텍스트를 선택하고 스토리 생성 모드를 설정할 수 있는 것은 작업 생산성에 직접적인 도움을 준다. 인터페이스를 통해 지 시사항을 자연어 형식으로 SGM에 전달함으로써 문서 작성자는 인공지능 기반의 SGM이 어떤 문장을 생성해야 하 는지에 관한 자신의 의도를 정확하고 풍부하게 표현할 수 있다. 한편, 본 발명은 컴퓨터가 읽을 수 있는 비휘발성 기록매체에 컴퓨터가 읽을 수 있는 코드의 형태로 구현되는 것이 가능하다. 이러한 비휘발성 기록매체로는 다양한 형태의 스토리지 장치가 존재하는데 예컨대 하드디스크,SSD, CD-ROM, NAS, 자기테이프, 웹디스크, 클라우드 디스크 등이 있고 네트워크로 연결된 다수의 스토리지 장치 에 코드가 분산 저장되고 실행되는 형태도 구현될 수 있다. 또한, 본 발명은 하드웨어와 결합되어 특정의 절차 를 실행시키기 위하여 매체에 저장된 컴퓨터프로그램의 형태로 구현될 수도 있다.\n【요약】본 발명은 현재 작성중인 문서를 표시하는 영역인 문서 뷰와 문장 생성 모듈(SGM)과의 대화형 상호작용을 제공하 는 영역인 대화 뷰를 구비한 대화형 인터페이스를 제공하여 문서 작성자가 인공지능 기반 문장 생성 모듈(SGM)과 자연어로 상호작용할 수 있도록 인터페이스를 구성하고 문서 뷰에서의 문서 작성자의 조작 형태에 대응하여 문장 (뒷면에 계속)\n\n【청구항 1】\n컴퓨터 장치가 컴퓨터 화면을 통해 문서 작성자와 인공지능 기반 스토리 생성 시스템 간에 스토리 자동 생성을위한 인터페이스를 제공하는 방법으로서, 현재 작성중인 문서를 표시하는 문서 뷰(document view; DCV)를 문서 작성자를 위한 제 1 인터페이스 요소로 제공하는 제 1 단계; 인공지능 기반 문장 생성 모듈(SGM)과 문서 작성자 간의 대화형 상호작용을 제공하기 위한 대화 뷰(interactionview; IRV)를 문서 작성자를 위한 제 2 인터페이스 요소로 제공하는 제 2 단계-- 상기 문서 뷰(DCV)와 상기 대화 뷰(IRV)는 디스플레이 화면에 상이한 영역으로 제공됨 --; 문서 작성자가 상기 문서 뷰(DCV)에서 수행하는 조작 형태에 기초하여 자동적으로 다음문장 추천 모드와 재작성모드의 두 가지 스토리 생성 모드 중에서 한 가지를 선택적으로 활성화하는 제 3 단계; 다음문장 추천 모드가 활성화된 경우, 상기 문서 뷰(DCV)에서 윈도우 커서가 가리키는 문서 위치에 대한 다음문장 추천을 문장 생성 모듈(SGM)에 지시하는 제 4 단계; 재작성 모드가 활성화된 경우, 상기 문서 뷰(DCV)에서 문서 작성자가 선택한 텍스트 부분(이하, '선택 텍스트'라 함)에 대한 재작성을 문장 생성 모듈(SGM)에 지시하는 제 5 단계; 상기 활성화된 스토리 생성 모드에 따라 다음문장 추천 또는 선택 텍스트 재작성에 관련된 자연어 형식의 지시사항을 설정하여 문장 생성 모듈(SGM)로 전달하는 제 6 단계; 상기 활성화된 스토리 생성 모드에 대응하여 문장 생성 모듈(SGM)이 생성한 추천 문장을 문장 생성 모듈(SGM)로부터 제공받아 상기 대화 뷰(IRV)에 표시하는 제 7 단계; 상기 대화 뷰(IRV) 상에 이루어지는 문서 작성자의 선택에 따라 상기 활성화된 스토리 생성 모드에 대응하여 상기 추천 문장을 상기 문서 뷰(DCV)에 반영하는 제 8 단계; 를 포함하여 구성되는 인공지능 기반 스토리 생성 시스템의 인터페이스 제공 방법.\n【청구항 2】\n청구항 1에 있어서,상기 제 3 단계는, 상기 문서 뷰(DCV)에서 윈도우 커서가 현재 작성 중인 문서의 어느 한 지점에 멈추면 다음문장 추천 모드를 활성화하는 단계; 상기 문서 뷰(DCV)에서 현재 작성 중인 문서에서 문장이나 단어에 대한 선택이 감지되면 재작성 모드를 활성화하는 단계;를 포함하여 구성되는 것을 특징으로 하는 인공지능 기반 스토리 생성 시스템의 인터페이스 제공 방법.\n【청구항 3】\n청구항 2에 있어서, 상기 제 8 단계는, 다음문장 추천 모드가 활성화된 경우에 상기 문서 뷰(DCV)에서 윈도우 커서가 가리키는 문서 위치에 상기 추천공개특허 10-2023-0066710-3-문장을 삽입하는 단계;재작성 모드가 활성화된 경우에 상기 문서 뷰(DCV)에서 상기 선택 텍스트를 상기 추천 문장으로 대체하는 단계;를 포함하여 구성되는 것을 특징으로 하는 인공지능 기반 스토리 생성 시스템의 인터페이스 제공 방법.\n【청구항 4】\n청구항 3에 있어서, 상기 제 2 단계는, 문장 생성 모듈(SGM)과 문서 작성자 간의 대화형 상호작용을 제공하기 위한 대화 뷰(IRV)를 문서 작성자를 위한제 2 인터페이스 요소로 제공하는 단계;문서 작성자의 지시 사항과 문장 생성 모듈(SGM)의 응답이 쌍(pair)을 이루어 구성된 대화 내역을 저장 표시하기 위한 대화내역 창(interaction history window; IHW)을 상기 대화 뷰(IRV)의 표시 영역 내에 제 1 인터페이스 요소로 제공하는 단계; 문서 작성자가 문장 생성 모듈(SGM)에 지시 사항을 입력하기 위한 지시 창(command window; CMW)을 상기 대화뷰(IRV)의 표시 영역 내에 제 2 인터페이스 요소로 제공하는 단계-- 상기 대화내역 창(IHW)과 상기 지시 창(CMW)은 상기 대화 뷰(IRV)의 표시 영역 내에 상이한 영역으로 제공됨 --; 를 포함하여 구성되고, 상기 제 6 단계는, 다음문장 추천 모드가 활성화된 경우에 상기 지시 창(CMW)을 통해 윈도우 커서가 놓여진 위치에 문서 작성자가표현하려는 내용을 담은 자연어 형식의 테스트 문장을 지시사항으로 입력받아 문장 생성 모듈(SGM)로 전달하는단계; 재작성 모드가 활성화된 경우에 상기 문서 뷰(DCV)에서 식별한 자연어 형식의 상기 선택 텍스트를 지시사항으로설정하여 문장 생성 모듈(SGM)로 전달하는 단계; 를 포함하여 구성되고, 상기 제 7 단계는, 상기 활성화된 스토리 생성 모드에 대응하여 문장 생성 모듈(SGM)이 생성한 추천 문장을 문장 생성 모듈(SGM)로부터 제공받아 상기 대화내역 창(IHW)에 표시하는 단계; 를 포함하여 구성되는 것을 특징으로 하는 인공지능 기반 스토리 생성 시스템의 인터페이스 제공 방법.\n【청구항 5】\n청구항 4에 있어서, 상기 제 7 단계는, 상기 추천 문장과 연계하여 복수의 선택사항을 상기 대화내역 창(IHW)에 표시하는 단계; 상기 대화내역 창(IHW)에서 문서 작성자에 의한 제 1 사항의 선택이 식별되면, 다음문장 추천 모드가 활성화된경우에 상기 문서 뷰(DCV)의 현재 작성 중인 문서에서 윈도우 커서가 표시된 부분에 상기 추천 문장을 삽입 처리하고, 재작성 모드가 활성화된 경우에 상기 문서 뷰(DCV)의 현재 작성 중인 문서에서 상기 추천 문장에 의해상기 선택 텍스트를 대체 처리하는 단계; 상기 대화내역 창(IHW)에서 문서 작성자에 의한 제 2 사항의 선택이 식별되면, 상기 추천 문장을 버림 처리하는단계; 공개특허 10-2023-0066710-4-를 포함하여 구성되는 것을 특징으로 하는 인공지능 기반 스토리 생성 시스템의 인터페이스 제공 방법.\n【청구항 6】\n청구항 5에 있어서, 상기 제 7 단계 이후에 수행되는, 인공지능 기반 문장 생성 모듈(SGM)의 스토리 자동 생성에 관한 인공지능 학습을 위해 상기 대화내역 창(IHW)에서 상기 복수의 선택사항 중 문서 작성자에 의한 선택 결과를 문장 생성 모듈(SGM)로 전달하는 단계; 를 더 포함하여 구성되는 인공지능 기반 스토리 생성 시스템의 인터페이스 제공 방법.\n【청구항 7】\n컴퓨터에 청구항 1 내지 6 중 어느 하나의 항에 따른 인공지능 기반 스토리 생성 시스템의 인터페이스 제공 방법을 실행시키기 위하여 저장매체에 저장된 컴퓨터프로그램."}
{"context": "", "input": "【기술명】\n인공지능 기반 ＮＦＴ 생성 서비스 제공 시스템\n\n【기술 설명】\n본 발명은 사용자가 입력한 텍스트나 이미지를 기반으로 인공지능(AI)을 활용하여 고유한 이미지, 3D 객체 및 동영상을 생성하고, 이를 통해 NFT(Non-Fungible Token)를 발행할 수 있는 종합적인 서비스 제공 시스템입니다. 이 시스템은 사용자 단말로부터 입력된 데이터를 분석하고, 적어도 하나의 인공지능 알고리즘을 통해 결과물을 생성합니다. 생성된 콘텐츠는 NFT의 형태로 발행되어 거래될 수 있으며, 이 과정에서 위변조 방지 및 창작물의 진위 확인까지 포함하여 안전하고 투명한 거래 환경을 제공합니다.\n\n【해결 문제】\n현재 NFT 시장은 창작물의 위변조 및 불법 복제 문제로 인한 신뢰성 저하가 심각한 상황입니다. 본 발명은 사용자 단말로부터 입력된 텍스트 및 이미지를 활용하여 독창적인 콘텐츠를 생성함으로써, NFT 발행 요청 시 신뢰할 수 있는 결과물을 제공합니다. 또한, NFT의 소유권 증명을 통해 위변조된 NFT의 유통을 방지하며, 창작물의 진위 확인을 통해 불법 복제 문제를 해결하여, 안전하고 투명한 NFT 거래 시장을 형성할 필요성을 충족합니다.\n\n【기술 차별성】\n본 발명은 기존의 AI 기반 미술품 생성 기술과는 달리, 단순한 이미지 생성뿐만 아니라 동영상 및 3D 데이터 생성까지 아우르는 포괄적인 기능을 제공합니다. 더욱이, NFT 발행 및 거래 중개 기능을 통합하여, 사용자에게 실시간으로 NFT의 트렌드를 분석 및 예측하는 정보를 제공함으로써, 기존 기술 대비 뛰어난 사용자 경험을 창출합니다. 이러한 혁신적인 접근은 NFT 시장의 신뢰성을 높이고, 사용자 참여를 극대화하는 데 기여하며, 경쟁 기술과의 명확한 차별성을 나타냅니다.\n\n【활용 분야】\n본 인공지능 기반 NFT 생성 서비스 제공 시스템은 디지털 아트, 게임, 패션, 음악 및 미디어 산업 등 다양한 분야에서 활용될 수 있습니다. 특히, 디지털 아트 시장에서는 작가와 소비자 간의 직접적인 거래를 가능하게 하여 창작물의 가치를 극대화할 수 있습니다. 게임 산업에서는 캐릭터 및 아이템의 NFT화를 통해 사용자 경험을 향상시키고, 패션 산업에서는 한정판 아이템의 디지털 소유권을 제공하여 브랜드 가치를 높일 수 있습니다. 또한, 음악 및 미디어 콘텐츠의 경우, 아티스트가 직접 NFT를 통해 수익을 창출할 수 있는 기회를 제공합니다.\n\n【구성 요소 및 기능】\n본 시스템의 주요 구성 요소는 다음과 같습니다. 첫째, **인공지능 알고리즘**은 입력된 텍스트나 이미지를 기반으로 다양한 형태의 디지털 콘텐츠(이미지, 3D 모델, 동영상)를 생성하는 기능을 수행합니다. 둘째, **사용자 단말**은 최종 사용자가 텍스트를 입력하고 생성된 콘텐츠를 확인하는 인터페이스 역할을 하며, NFT 발행 요청을 손쉽게 진행할 수 있도록 지원합니다. 셋째, **생성 서비스 제공 서버**는 사용자 단말과 인공지능 알고리즘 간의 데이터 전송을 관리하고, 사용자 요청에 따라 NFT를 발행하는 기능을 수행하여 거래의 안전성과 효율성을 보장합니다.\n\n【구현 방식 예】\n본 시스템의 구현 방식은 단계별로 진행됩니다. 첫 번째 단계는 **인공지능 알고리즘 구축**으로, 텍스트 입력을 통해 다양한 형태의 디지털 콘텐츠를 생성할 수 있도록 학습된 모델을 개발합니다. 두 번째 단계는 **사용자 단말 설계**로, 사용자 친화적인 인터페이스를 구축하여 사용자가 손쉽게 텍스트를 입력하고 결과물을 확인할 수 있도록 합니다. 마지막으로, **서버 통합 및 테스트**를 통해 사용자 단말과 인공지능 알고리즘 간의 원활한 데이터 통신을 보장하며, NFT 발행 기능을 포함한 시스템의 안정성과 신뢰성을 검증하여 실제 운영 환경에 배포합니다.", "output": "【발명의 명칭】\n인공지능 기반 ＮＦＴ 생성 서비스 제공 시스템\n【기술분야】\n본 발명은 인공지능 기반 NFT 생성 서비스 제공 시스템에 관한 것으로, 텍스트나 이미지를 입력하면 인공지능 기반으로 이미지, 3D 및 동영상을 생성해주고, 이에 기하여 NFT를 발행할 수 있는 시스템을 제공한다.\n【배경기술】\n인공지능은 발전에 발전을 거듭하면서 미술품을 만드는 도구를 넘어서 스스로 미술품을 만들어내는 단계에까지 이르고 있다. 인공지능은 미술품을 창작하는 방법에 따라 분류하는 경우, 완성물 출력형과 직접 제작형으로 나 눌 수 있는데, 전자는 프린터나 화면으로 최종 결과물을 출력해내는 방법이고, 후자는 인공지능이 직접 화폭에 미술품을 그려내는 방법이다. 또, 미술품을 창작하는데 있어서 인공지능의 역할에 따라 도구형과 독립형으로 나눌 수 있는데, 도구형 인공지능은 인간이 입력하는 사진이나 명령에 따라 알고리즘을 운영하여 결과물을 창작 하는 것으로 딥 드림(Deep Dream), 넥스트 렘브란트(The Next Rembrandt)가 이에 해당한다. 독립형 인공지능은 인간은 창작에 어떠한 관여도 하지 않고 단지 인공지능의 시작버튼만을 조작하는 등의 행위만 있을 뿐이고, 실 제로 창작에 필요한 것은 인공지능이 모두 수행하는 것으로 마리오 클링게만(Mario Klingemann)의 AI, 오비어스 (Obvious)의 AI, 페이스북의 AI CAN, 아론(Aaron)과 바울(Paul)이 있다. 이때, 텍스트를 입력하면 인공지능을 이용하여 이미지나 동영상으로 변환하는 방법이 연구 및 개발되었는데, 이 와 관련하여, 선행기술인 한국공개특허 제2020-0032614호(2020년03월26일 공개) 및 한국공개특허 제2022- 0017068호(2022년02월11일 공개)에는, 머신러닝으로 소설, 대본 및 희곡과 같은 텍스트를 이해하고 이에 매칭되 는 영상 객체를 이용하여 동영상을 생성하거나, 텍스트에 대하여 자연어처리를 이용하여 메타데이터를 추출한 후 동적 콘텐츠를 생성하거나 변형하는 구성이 각각 개시되어 있다. 다만, 상술한 구성은 사용자가 원하는 텍스트를 입력하면 이에 따라 그림을 그려주는 구성이 아니고, 미리 학습 된 텍스트를 입력하면 이에 대응하는 그림을 찾아주는 구성에 불과하다. 최근 NFT 시장에서 다수의 창작물에 대하여 NFT가 발행되고는 있지만, 창작물을 창작할 수 있도록 훈련되고 경험을 쌓은 전문가가 아닌 이상 NFT를 발행할 수 있는 창작물을 만들어내기란 쉽지 않은 일이다. 이에, NFT를 발행하고 싶지만 창작물을 그려내는 기 술이 부족한 일반인을 위하여 인공지능 기반으로 텍스트를 이미지로, 이미지를 동영상이나 3D로 생성한 후 창작 물에 기하여 NFT를 발행할 수 있는 플랫폼의 연구 및 개발이 요구된다.\n【해결하려는 과제】\n본 발명의 일 실시예는, 사용자 단말로부터 입력된 텍스트나 이미지를 이용하여 이미지, 동영상 및 3D 데이터를 생성할 수 있도록 하고, 사용자 단말에서 NFT의 발행을 요청하는 경우 이미지, 동영상 및 3D 데이터 중 어느 하 나에 기하여 NFT를 생성하여 거래를 중개하며, 사용자 단말로부터 기 보유한 NFT가 업로드되는 경우 기 보유한 NFT의 소유권증명을 통하여 위변조 NFT가 시장에 유통되는 것을 방지하고, 창작자 단말로부터 창작물이 업로드 되는 경우 창작물이 불법복제물은 아닌지에 대한 진위확인을 통하여 투명한 거래시장을 형성하며, NFT의 트렌드 를 분석 및 예측하여 사용자에게 정보를 제공할 수 있는, 인공지능 기반 NFT 생성 서비스 제공 시스템을 제공할 수 있다. 다만, 본 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다.\n【과제의 해결 수단】\n상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 발명의 일 실시예는, 입력된 텍스트를 이용하여 생 성된 이미지를 출력하고, 이미지에 기하여 NFT의 발행을 요청하는 사용자 단말 및 텍스트가 입력되면 이미지를 출력하는 적어도 하나의 인공지능 알고리즘을 구축하는 구축부, 사용자 단말에서 텍스트가 입력되는 경우 적어 도 하나의 인공지능 알고리즘에 텍스트를 입력하는 입력부, 적어도 하나의 인공지능 알고리즘에서 출력된 이미 지를 사용자 단말로 전송하는 전송부, 사용자 단말의 발행 요청이 수신되는 경우 이미지에 기하여 NFT를 발행하는 발행부를 포함하는 생성 서비스 제공 서버를 포함한다.\n【발명의 효과】\n전술한 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 사용자 단말로부터 입력된 텍스트나 이미지를 이용하 여 이미지, 동영상 및 3D 데이터를 생성할 수 있도록 하고, 사용자 단말에서 NFT의 발행을 요청하는 경우 이미 지, 동영상 및 3D 데이터 중 어느 하나에 기하여 NFT를 생성하여 거래를 중개하며, 사용자 단말로부터 기 보유 한 NFT가 업로드되는 경우 기 보유한 NFT의 소유권증명을 통하여 위변조 NFT가 시장에 유통되는 것을 방지하고, 창작자 단말로부터 창작물이 업로드되는 경우 창작물이 불법복제물은 아닌지에 대한 진위확인을 통하여 투명한 거래시장을 형성하며, NFT의 트렌드를 분석 및 예측하여 사용자에게 정보를 제공할 수 있다.\n【발명을실시하기위한구체적인내용】\n아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미하며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해 되어야 한다. 명세서 전체에서 사용되는 정도의 용어 \"약\", \"실질적으로\" 등은 언급된 의미에 고유한 제조 및 물질 허용오차 가 제시될 때 그 수치에서 또는 그 수치에 근접한 의미로 사용되고, 본 발명의 이해를 돕기 위해 정확하거나 절 대적인 수치가 언급된 개시 내용을 비양심적인 침해자가 부당하게 이용하는 것을 방지하기 위해 사용된다. 본 발명의 명세서 전체에서 사용되는 정도의 용어 \"~(하는) 단계\" 또는 \"~의 단계\"는 \"~ 를 위한 단계\"를 의미하지 않는다. 본 명세서에 있어서 '부(部)'란, 하드웨어에 의해 실현되는 유닛(unit), 소프트웨어에 의해 실현되는 유닛, 양 방을 이용하여 실현되는 유닛을 포함한다. 또한, 1 개의 유닛이 2 개 이상의 하드웨어를 이용하여 실현되어도 되고, 2 개 이상의 유닛이 1 개의 하드웨어에 의해 실현되어도 된다. 한편, '~부'는 소프트웨어 또는 하드웨어 에 한정되는 의미는 아니며, '~부'는 어드레싱 할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객 체 지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회 로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또 는 그 이상의 CPU들을 재생시키도록 구현될 수도 있다. 본 명세서에 있어서 단말, 장치 또는 디바이스가 수행하는 것으로 기술된 동작이나 기능 중 일부는 해당 단말, 장치 또는 디바이스와 연결된 서버에서 대신 수행될 수도 있다. 이와 마찬가지로, 서버가 수행하는 것으로 기술된 동작이나 기능 중 일부도 해당 서버와 연결된 단말, 장치 또는 디바이스에서 수행될 수도 있다. 본 명세서에서 있어서, 단말과 매핑(Mapping) 또는 매칭(Matching)으로 기술된 동작이나 기능 중 일부는, 단말 의 식별 정보(Identifying Data)인 단말기의 고유번호나 개인의 식별정보를 매핑 또는 매칭한다는 의미로 해석 될 수 있다. 이하 첨부된 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 인공지능 기반 NFT 생성 서비스 제공 시스템을 설명하기 위한 도면이다. 도 1을 참조하면, 인공지능 기반 NFT 생성 서비스 제공 시스템은, 적어도 하나의 사용자 단말, 생성 서 비스 제공 서버, 적어도 하나의 창작자 단말을 포함할 수 있다. 다만, 이러한 도 1의 인공지능 기반 NFT 생성 서비스 제공 시스템은, 본 발명의 일 실시예에 불과하므로, 도 1을 통하여 본 발명이 한정 해석되 는 것은 아니다. 이때, 도 1의 각 구성요소들은 일반적으로 네트워크(Network, 200)를 통해 연결된다. 예를 들어, 도 1에 도시 된 바와 같이, 적어도 하나의 사용자 단말은 네트워크를 통하여 생성 서비스 제공 서버와 연결 될 수 있다. 그리고, 생성 서비스 제공 서버는, 네트워크를 통하여 적어도 하나의 사용자 단말 , 적어도 하나의 창작자 단말과 연결될 수 있다. 또한, 적어도 하나의 창작자 단말은, 네트워 크를 통하여 생성 서비스 제공 서버와 연결될 수 있다. 여기서, 네트워크는, 복수의 단말 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의 미하는 것으로, 이러한 네트워크의 일 예에는 근거리 통신망(LAN: Local Area Network), 광역 통신망(WAN: Wide Area Network), 인터넷(WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통신망 등을 포함한다. 무선 데이터 통신망의 일례에는 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), 5GPP(5th Generation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와이파이(Wi-Fi), 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), RF(Radio Frequency), 블루투스 (Bluetooth) 네트워크, NFC(Near-Field Communication) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워 크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 하기에서, 적어도 하나의 라는 용어는 단수 및 복수를 포함하는 용어로 정의되고, 적어도 하나의 라는 용어가 존재하지 않더라도 각 구성요소가 단수 또는 복수로 존재할 수 있고, 단수 또는 복수를 의미할 수 있음은 자명 하다 할 것이다. 또한, 각 구성요소가 단수 또는 복수로 구비되는 것은, 실시예에 따라 변경가능하다 할 것이다. 적어도 하나의 사용자 단말은, 인공지능 기반 NFT 생성 서비스 관련 웹 페이지, 앱 페이지, 프로그램 또는 애플리케이션을 이용하여 텍스트를 입력하여 이미지, 동영상 및 3D 등을 생성하거나, 이미지를 입력하여 동영상 이나 3D 등을 생성하는 사용자의 단말일 수 있다. 사용자 단말은 생성된 이미지, 동영상 및 3D 등을 이용 하여 NFT의 발행을 요청할 수 있고, NFT가 발행되는 경우 사용자 계정에 등록될 수 있다. 사용자 단말은 NFT를 거래소에 업로드하여 판매할 수 있고, 창작자 단말의 NFT를 구매할 수도 있는 단말일 수 있다. 그 리고, 사용자 단말은, NFT를 구매할 때 NFT의 소유권증명 또는 진위확인 등을 수행할 수 있고, 트렌드에 따른 NFT를 추천받는 단말일 수 있다. 여기서, 적어도 하나의 사용자 단말은, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터 로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데 스크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 이때, 적어도 하나의 사용자 단말은, 네트워크를 통해 원격지의 서버나 단말에 접속할 수 있는 단말로 구현될 수 있다. 적어도 하나의 사용자 단말은, 예 를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트폰(Smartphone), 스마트 패드(Smartpad), 타블렛 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 생성 서비스 제공 서버는, 인공지능 기반 NFT 생성 서비스 웹 페이지, 앱 페이지, 프로그램 또는 애플리케 이션을 제공하는 서버일 수 있다. 그리고, 생성 서비스 제공 서버는, 적어도 하나의 인공지능 알고리즘을이용하여 텍스트를 입력하면 이미지, 동영상 또는 3D를 출력하거나, 이미지를 입력하면 동영상 또는 3D 등으로 출력해주는 기능을 제공하는 서버일 수 있다. 또, 생성 서비스 제공 서버는, 창작자 단말에서 창작 물을 업로드하면 진위확인을 통하여 NFT의 발급 전 검증을 하는 서버일 수 있고, NFT의 거래이전에 소유권증명 을 수행하는 서버일 수 있다. 생성 서비스 제공 서버는, 적어도 하나의 NFT에 대한 기사, 이슈, 소셜미디 어 게시물 등을 수집한 후 분석하여 트렌드를 분석한 결과를 제공하는 서버일 수 있다. 여기서, 생성 서비스 제공 서버는, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스 크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 적어도 하나의 창작자 단말은, 인공지능 기반 NFT 생성 서비스 관련 웹 페이지, 앱 페이지, 프로그램 또는 애플리케이션을 이용하여 창작물을 업로드하고, 창착물에 기하여 NFT의 발행을 요청하는 창작자의 단말일 수 있 다. 여기서, 적어도 하나의 창작자 단말은, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터 로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데 스크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 이때, 적어도 하나의 창작자 단말은, 네트워크를 통해 원격지의 서버나 단말에 접속할 수 있는 단말로 구현될 수 있다. 적어도 하나의 창작자 단말은, 예 를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트폰(Smartphone), 스마트 패드(Smartpad), 타블렛 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 도 2는 도 1의 시스템에 포함된 생성 서비스 제공 서버를 설명하기 위한 블록 구성도이고, 도 3 및 도 4는 본 발명의 일 실시예에 따른 인공지능 기반 NFT 생성 서비스가 구현된 일 실시예를 설명하기 위한 도면이다. 도 2를 참조하면, 생성 서비스 제공 서버는, 구축부, 입력부, 전송부, 발행부, 동영 상부, 3D부, 소유권증명부, 권리확인부, 진위확인부, 랭킹부, 트렌드분석부 , 추천부 및 채굴권제공부를 포함할 수 있다. 본 발명의 일 실시예에 따른 생성 서비스 제공 서버나 연동되어 동작하는 다른 서버(미도시)가 적어도 하 나의 사용자 단말 및 적어도 하나의 창작자 단말로 인공지능 기반 NFT 생성 서비스 애플리케이션, 프 로그램, 앱 페이지, 웹 페이지 등을 전송하는 경우, 적어도 하나의 사용자 단말 및 적어도 하나의 창작자 단말은 인공지능 기반 NFT 생성 서비스 애플리케이션, 프로그램, 앱 페이지, 웹 페이지 등을 설치하거나 열 수 있다. 또한, 웹 브라우저에서 실행되는 스크립트를 이용하여 서비스 프로그램이 적어도 하나의 사용자 단말 및 적어도 하나의 창작자 단말에서 구동될 수도 있다. 여기서, 웹 브라우저는 웹(WWW: World Wide Web) 서비스를 이용할 수 있게 하는 프로그램으로 HTML(Hyper Text Mark-up Language)로 서술된 하이퍼 텍스트를 받아서 보여주는 프로그램을 의미하며, 예를 들어 넷스케이프(Netscape), 익스플로러(Explorer), 크롬 (Chrome) 등을 포함한다. 또한, 애플리케이션은 단말 상의 응용 프로그램(Application)을 의미하며, 예를 들어, 모바일 단말(스마트폰)에서 실행되는 앱(App)을 포함한다. 도 2를 참조하면, 구축부는, 텍스트가 입력되면 이미지를 출력하는 적어도 하나의 인공지능 알고리즘을 구 축할 수 있다. 이때, 인공지능 알고리즘은, 예를 들어, Stable Diffusion, MidJourney, GPT-2/3, DALL-E 등의 툴을 이용할 수도 있고 본 발명의 플랫폼에서 직접 인공지능 알고리즘을 모델링한 후 이를 세팅하여 이용할 수 도 있다. Stable Diffusion은, 자연어인 텍스트로부터 이미지를 생성하는 딥러닝 인공지능으로, 텍스트 투 이 미지(Text-to-Image) 태스크를 위한 모델인데, 컴퓨터 비전 분야와 자연어처리(Natural Language Processing) 분야가 결합된 모델이다. 텍스트 투 이미지는 VAE(Variational AutoEncoder) 기반, GAN(Generative Adversarial Neural Networks) 기반, 디퓨전(Diffusion) 기반 등 다양한 방법이 존재한다. <GAN> GAN 기반의 방법은 생성자(Generator)와 분류자(Discriminator)로 구성되어, 마치 인간 예술가가 그림을 그리고, 그 그림을 스스로 평가하는 과정을 반복하면서 그림을 완성해 나가듯이, 이 두 생성자와 분류자는 서로 평가하고, 경쟁하고 보완하는 일을 한다. 생성자는 이름 그대로 이미지를 만들어내고, 분류자는 생성자 신경망이 만들어낸 이미지가 새로운 이미지인지, 아니면 기존에 존재하던 이미지인지 분류해낸다. 이렇게 분류한 이 미지의 결과는 생성자로 다시 피드백으로 전달된다. 두 생성자와 분류자 간 경쟁을 통해 생성자는 점점 더 새 로운 이미지를 만들어내는 방향으로, 분류자는 기존에 존재하던 이미지와 생성자의 이미지를 더 잘 분류하는 뱡 향으로 발전해나간다. 창의적 GAN(Creative Adversarial Neural Networks)도 GAN과 동일하게 두 생성자와 분류자가 서로 경쟁하게끔 만들어져있다. 하지만 여기에 추가로 창의성이 부여된다. 여기서 창의성이 있다는 것은, 인간의 예술작품을 학습하여 이미 존재하는 인간의 예술작품이 아닌 새로운 스타일의 예술작품을 만들어 낸다는 것을 의미한다. 이러한 창의적 GAN은 인간에게 없던 새로운 그림을 만들어내게 하는 기술이다. 창의적 GAN에서 분류자는 자신 에게 들어온 그림이 생성자가이 만든 그림인지 아니면 인간이 그린 그림인지 분류한다. 이에 덧붙여 그 그림이 기존의 예술 스타일 중 어떤 것에 속하는지도 분류한다. 반대로 생성자는 분류자를 속이기 위해 인간의 예술작 품과 구분되지 않을 수준의 그림을 그려낸다. 나아가 이 그림을 분류자가 인간 예술 스타일 중 하나로 구분하 지 못하도록 기존에 없던 새로운 스타일로 만들어내려 노력한다. 그 결과 창의적 GAN의 생산물은 분류자 신경 망이 인간의 그림인지 인공지능의 그림인지 쉽게 구분하지 못하도록 인간이 만든 예술작품과 비슷하게 보이면서 도, 동시에 인간 예술 스타일 중 하나로 분류하지 못하게 하기 위해 인간 예술에 존재하지 않던 새로운 스타일 의 그림을 만들어낸다. 인공지능이 그린 그림에 대하여 저작권성을 부여할 수 있는지에 대한 다툼이 있는 것은 별론으로 하고, 본 발명의 일 실시예에서는 이렇게 만든 그림에 대한 최종적 권한은 사용자에게 있다는 것을 전 제로 NFT의 발행을 허용할 수 있다. 입력부는, 사용자 단말에서 텍스트가 입력되는 경우 적어도 하나의 인공지능 알고리즘에 텍스트를 입 력할 수 있다. 텍스트-투-이미지의 경우, 간단히 설명하면, [텍스트-이미지]가 매핑되어 있고, 각 이미지 내 구성요소별로 캡셔닝(Captioning)이 라벨링(Labelling)되어 있다. 이에, 단어, 문장 등을 입력하는 경우, NLP (자연어처리)가 각 단어 및 문장을 토큰화(Tokenization)한 후, 각 토큰에 대응하는 이미지를 찾고, 각 이미지 를 합성하여 출력하는 형태가 될 수 있다. 예를 들어, 사용자가 \"강아지가 춤을 추는 그림\"이라고 입력하는 경 우, NLP는 강아지, 춤을 추출하고, 강아지 및 춤에 대응하는 이미지를 찾아낸다. 그리고, NLP에서 주어에 대응 하는 강아지에 액션에 대응하는 춤을 대입하여, 강아지의 뼈 구조인 스켈레톤을 추출하여 춤추는 액션으로 생성 하는 방식으로 이미지를 출력하는 방식일 수 있다. 이때, 텍스트를 문자 단위로 쪼개 상술한 GAN의 입력으로 이용하는 경우, 이미지만 그럴듯하게 생성하는데 그칠 수 있다. 또, StackGAN 및 StackGAN++을 이용할 수도 있는데, 고해상도 이미지 생성을 목표로 어려운 문제를 보다 쉽게 풀기 위해 하위 문제로 분해하는 방법이다. 예를 들어 StackGAN은 먼저 두 단계로 나누어 64×64 크 기의 이미지를 생성하고 생성된 이미지를 조건으로 하여 결과적으로 256×256 크기의 이미지를 생성한다. StackGAN++는 여기서 보다 안정적인 훈련을 위해 트리 구조와 유사한 중간 단계를 추가한 방식이다. Attn(Attention)GAN은 어텐션 매커니즘을 활용하여 텍스트에서 단어 수준의 정보를 반영한다. 이는 문장 수준 의 정보 이전에 이미지로 더 자세한 구현이 가능하다. 먼저, AttnGAN은 텍스트와 이미지 사이의 유사성을 학습 하기 위해 DAMSM(Deep Attentional Multi-modal Similarity Model, DAMSM)을 학습한다. 여기서 텍스트 인코더 는 양방향 LSTM(Long Short Term Memory)를 이용할 수 있고, 이미지 인코더는 Inception-v3를 이용한다. 사전 학습된 DAMSM을 통해 각각 64, 128, 256 크기로 세 장의 이미지를 생성할 수 있다. 다만, 텍스트-투-이미지 GAN의 발전이 지속적으로 이루어졌음에도 불구하고 생성되는 이미지는 여전히 객체 왜곡, 논리적이지 않은 객체 배치 또는 배경의 부자연스러움 등의 문제가 있다. 이를 해결하기 위해 DALL-E는 텍스트와 이미지 토큰을 단일 데이터 스트림으로 자동 회귀 모델을 사용하여 트랜스포머(Transformer) 구조를 이용하고, 본 발명의 일 실시예 에서는 상술한 DALL-E를 이용할 수 있다. 전송부는, 적어도 하나의 인공지능 알고리즘에서 출력된 이미지를 사용자 단말로 전송할 수 있다. 사용자 단말은, 입력된 텍스트를 이용하여 생성된 이미지를 출력할 수 있다. 발행부는, 사용자 단말의 발행 요청이 수신되는 경우 이미지에 기하여 NFT를 발행할 수 있다. 사용 자 단말은, 이미지에 기하여 NFT의 발행을 요청할 수 있다. NFT는 블록체인 네트워크의 계정에 의해 발급 된다. NFT를 발급하는 생성자 계정은 토큰을 발급하는 트랜잭션에 디지털 서명을 한다. 이때, 디지털 서명은 블록체인 기술의 측면에서 계정의 소유자가 개인키를 활용하여 트랜잭션에 서명하였는지를 확인할 수 있음을 의 미한다. 이렇게 디지털 서명된 트랜잭션은 서명에 사용된 암호화 알고리즘 덕분에 조작하기가 매우 어렵다. 이후 발급된 토큰의 소유주가 이전된다면 트랜잭션은 이전된 소유자의 계정으로 다시 서명된다. 모든 과정은 블록체인 네트워크에서 동작하므로 토큰에 대한 과거 소유권의 기록을 모두 추적할 수 있다. 토큰으로 발급하 고자 하는 자산의 원본에 대한 특징은 JSON 형식의 메타데이터이다. 즉, NFT의 발급 과정은, 자산 그 자체에대한 것보다 자산에 대한 정보를 메타데이터로 저장하는 트랜잭션을 발생시키고, 블록체인에 기록함으로써 신뢰 성과 무결성이 보장된 토큰이 계정에 전송돼 소유권을 보장받는 방식이다. 동영상부는, 사용자 단말에서 텍스트를 입력하면 동영상을 생성하거나, 이미지 또는 사용자 단말 에서 업로드한 이미지로 동영상을 생성하는 적어도 하나의 인공지능 알고리즘을 구축할 수 있다. 텍스트 를 동영상을 변환하는 것은, 상술한 텍스트를 이미지로 변환하는 과정과 유사하다. 즉, NLP에서 텍스트를 해석 하고, NLP에서 텍스트를 해석하면, 해석된 결과에 대응하는 이미지, 영상 및 음원을 딥러닝에서 검색하고, 이를 텍스트의 내용에 맞게끔(Contextual) 병합하고 검수를 마친 후 출력된다. 물론, 메타(Meta, Facebook)에서 공 개한 메이크어비디오(Make-A-Video)와 같은 기술을 이용할 수도 있다. 메타의 경우 보간 처리(Interpolation) 를 결합해 짧고 반복되는 GIF 영상을 제작할 수 있다. 그 외에도 이하의 방법으로 애니메이션과 같은 효과를 주는 동영상을 제작할 수 있다. <이미지→동영상> 이미지를 동영상으로 생성하기 위해서는, 영상인식기술을 이용하여 사용자가 그린 그림이나 글씨의 백그라운드 영역을 제거하고, 나머지 영역의 외곽선 검출(Edge Detection)을 통해 객체 영역을 추출할 수 있다. 입력영상 에서 백그라운드 영역을 제거하기 위해 영상의 모든 픽셀에 대해 RGB 색공간에서 HSV 색공간으로 전환하고, 이 진화를 통하여 외곽선을 검출할 수 있다. 추출한 객체 영역에서 들로네 삼각분할(Delaunay Triangulation)을 통해 객체 메쉬(Mesh)를 생성할 수 있다. 들로네 삼각분할은 임의의 점을 연결하여 삼각형의 집합을 만드는데 각 삼각형이 정삼각형에 가깝게 만들어주는 알고리즘이다. 객체 영역에 임의의 점(Vertex)을 삽입한 후, 들로 네 삼각분할을 이용하여 삼각형 폴리곤 단위의 메쉬를 만들 수 있다. 이 과정을 통하여 객체를 메쉬 기반 모델 로 추출할 수 있고, 추출된 모델은 애니메이션 효과를 주기 위한 시스템의 입력값으로 적용한다. <자동 애니메이션 생성> 객체의 메쉬화를 통해 모델링을 한 후, 자동 애니메이션을 적용하기 위해 스켈레톤(Skeleton)을 추출해야 한다. 다만, 일반적인 글씨나 그림 내 객체가 무생물인 경우에는 스켈레톤이 없다. 이 경우에는 스켈레톤에 대응하는 점을 선정하여 움직이도록 할 수도 있다. 스켈레톤은 객체 영역에서 추출한 이진영상을 세선화 알고리즘 (Thining Algorithm)을 적용하여 추출할 수 있다. 또 스켈레톤 라인 내에서 본(Bone)에 대응하는 특징점을 추 출할 수 있다. 특징점을 통해 애니메이션의 본을 만들어야 하는데, 세분화(Segmentation) 과정을 통해 애니메 이션 본을 생성할 수 있다. 세분화 과정은 점과 점 사이를 잇는 라인을 분할하여 세분화된 스켈레톤 라인을 얻 는 과정을 말한다. 그 다음 메쉬 스키닝을 수행하는데, 스키닝은 메쉬의 버텍스마다 어떠한 본을 따라 움직일 것인지에 대해 가중 치(Weight)를 적용하는 작업이다. 만약, 무생물이 아닌 생물이라면 관절의 가동범위가 존재하는데, 이를 기준 으로 가중치를 줄 수 있다. 객체가 생물인데 관절의 가동범위를 벗어난다면 좀비영화를 보는 것과 같은 공포감 을 줄 수 있기 때문이다. 스키닝이 완료된 메쉬는 본의 움직임에 따라 애니메이션을 구성할 수 있다. 이때, 추출된 본의 계층구조(Hierarchy)를 설정하고, 움직임을 제어하여 자동으로 애니메이션을 생성할 수 있다. 계 층구조를 설정하기 위해서는 본을 추출할 때 사용한 스켈레톤 라인과 본을 구성하는 각 점을 이용할 수 있다. 기본이 되는 계층구조는 각각의 끝 점을 피봇(Pivot) 점으로 하여 설정한다. 피봇점은 스켈레톤 라인을 따라 이동하며 분할점을 만나면 부모로 설정한다. 부모로 설정한 점을 다시 피봇점으로 하여 반복하다가 관절점을 만나거나 라인이 끝나게 되면 멈춘다. 모든 끝 점들에 대해 이 과정을 반복하게 되면 핵심적인 애니메이션을 구성하는 가지들이 추출된다. 이후에 각각의 관절점에 대해서 연결된 모든 라인에 대해 과정을 반복하면 관절 들을 잇는 계층구조가 설정된다. 이때 관절점과 관절점이 이어지는 경우 보다 원점에 가까운 점이 부모가 된다. 이 과정을 통해 만들어진 계층구조는 트리 형태의 구조를 지닌다. 이렇게 만들어진 객체를 회전했을 때 하위 본이 계층구조에 따라 회전하는 것을 이용하여 스키닝된 메쉬 객체를 움직일 수 있다. 3D부는, 이미지 또는 사용자 단말에서 업로드한 이미지로 3D 이미지를 생성하는 적어도 하나의 인공 지능 알고리즘을 구축할 수 있다. 3D로 생성하는 것은 2D를 3D로 생성한다는 의미일 수도 있고 상술한 바와 같 이 움직이는 형태로 만든다는 의미일 수도 있다. 2D의 이미지를 3D로 렌더링하기 위해서는, 2D에는 XY 좌표는 있지만 Z가 없어 깊이(Depth)가 없으므로 깊이감을 주어야 하는데, 사용자가 그린 그림의 객체는 사용자만 알기 때문에 이러한 깊이감을 잘 못 주는 경우 볼륨감이나 깊이감이 어색해 3D로 변환하면 사용자의 의도와 같은 결 과물이 나오지 않을 수 있다. 이때, 엔비디아(NVDIA)에서 개발한 GANverse3D를 이용하는 경우, 3D 뉴럴 렌더러(Neural Renderer)를 이용하여 객체를 추출한 후 볼륨감 및 깊이감을 줄 수 있고, 배경도 바꿔볼 수 있다. 이 때, 엔비디아 RTX 그래픽처리장치(GPU)로 실행하면 모든 형태의 2D 이미지를 3D로 재현할 수 있다. 물론, 엔비 디아 외에도 다양한 툴이나 방법을 이용할 수 있다. 소유권증명부는, 사용자 단말에서 사용자 단말에서 기 소유한 NFT에 대한 등록요청을 하는 경우, 사용자 단말로 기 소유한 NFT의 창작물을 창작한 창작자 및 창작물을 소유한 소유자에 대한 계약서 를 업로드하도록 하고, 계약서에 따라 발생된 트랜잭션(Transaction)을 NFT의 메타데이터에 추가할 수 있다. 예를 들어, 창작자 단말에서 창작을 한 후, 사용자가 창작물을 구매한 경우, 사용자는 대금을, 창작자는 창작물을 사용자에게 전달하게 되는데, 이러한 트랜잭션을 확인하고 추적할 수 있다. 이때, 창작자 단말 로 사용자에게 판매를 했는지에 대하여 다시 한 번 검증할 수 있고, 창작자 및 사용자의 이체 내역 등을 확인하 여 검증을 실시할 수도 있다. 권리확인부는, 사용자 단말에서 창작물에 기하여 NFT의 발행을 요청하 는 경우, NFT의 메타데이터에 필드(Field)를 추가하여 계약서 및 트랜잭션을 기록할 수 있다. 진위확인부는, 적어도 하나의 NFT 마켓으로부터 NFT 데이터를 수집하여 업로드할 때, NFT 데이터 내 NFT 이미지에 대한 진위확인을 수행할 수 있다. 예를 들어, 소유권증명부에서는 A라는 NFT가 B라는 사용자의 것이 맞는지를 확인하는 것이고, 진위확인부에서는 A라는 NFT가 위변조된 불법복제물이 아닌지를 확인하는 것이다. 디지털 데이터의 특성상 Ctrl C 및 V만 이용하면 복사가 간단히 가능하기 때문에 원본인지의 여부를 파악하는 것이 중요하다. 우선, NFT에 등록되는 창작물의 이미지를 기준으로 동일한 이미지가 NFT 마켓에 등록 되어 있는지를 확인하고, 동일한 이미지의 경우 상술한 메타데이터를 이용하여 창작자(작가), 소유주를 확인한 후, 정당소유자가 업로드한 정당이미지인 경우 NFT를 수집하여 본 발명의 플랫폼에 업로드한다. 하지만, 동일 한 이미지인데 창작자, 소유주 등이 서로 다른 경우에는 NFT를 업로드하지 않을 수 있다. 랭킹부는, 적어도 하나의 소셜미디어 및 커뮤니티의 오피니언 데이터를 수집하여 NFT의 랭킹을 리스트업할 수 있다. 랭킹부에서는 판매되는 판매량과 사람들에 의한 평가를 종합하여 오피니언 마이닝을 수행할 수 있는데, 오피니언 마이닝은, 자연어처리 및 텍스트 마이닝 등을 이용하여 정서적인 상태와 주관적인 정보를 체 계적으로 식별하고 추출 및 정량화를 연구하는 기술이다. 오피니언 마이닝은 특정 주제나 상황에 따라 감성에 따라 반영해야 하기 때문에 사용자가 어떤 의도를 갖고 있는지 분석하여 처리하는 것이 중요하다. 오피니언 마 이닝 과정은 3단계로 분류하여 진행된다. 첫 번째는 웹 크롤링을 통한 데이터 수집, 두 번째는 수집된 데이터 내에 저장되어 있는 텍스트 내에 평가요소와 긍정 및 부정을 가리키는 오피니언 관계가 있는 문장을 인식하고 불필요한 특수문자와 감성과 관계없는 품사를 제외한다. 마지막으로 두 과정을 통해 긍정, 부정을 의미하는 단 어들이 담긴 특정 주제에 관한 텍스트 데이터를 요약을 통해 분석과 평가한다. 오피니언 마이닝 과정을 통해서 사용자가 NFT에 대해 평가한 오피니언 정보를 판단할 수 있다. 또한, 오피니언 마이닝을 통해 분석된 객관적인 자료로 인하여 제품의 신뢰성을 향상시키고 호감도를 판단해 NFT의 구매 판단 여부를 확인할 수 있다. 트렌드분석부는, 적어도 하나의 NFT에 대한 데이터를 수집하여 트렌드를 분석할 수 있다. 이때, 트렌드를 분석하기 위해, 예를 들어, 미래신호 예측 방법론을 이용할 수 있다. 이때, 미래신호는 약신호로, 임박한 충격 적인 사건에 대한 미약한 초기 징후로 정의된다. 처음에는 모호하고 감지하기 어렵다가 시간이 지남에 따라 더 강력하고 명확해지는 신호로, 약신호는 미래에 가능한 변화의 징후이며, 시간이 흐르면서 강신호(Strong Signal)로, 다시 강신호는 트렌드(Trend)나 메가트렌드(Mega Trend)로 발전될 수 있다. 이때, 단어빈도(Term- Frequncy)나 문서빈도(Document Frequency)를 이용할 수 있는데, 시간에 따른 단어 및 문서빈도의 증가율을 고 려하여 신호를 분류하기 위하여 DoV(Degree of Visibility) 또는 DoD(Degree of Diffusion) 값을 도출하여 키 워드 그래프를 작성할 수 있다. 이 외에도 토픽모델링이나 시계열성을 반영하는 LSTM을 이용할 수도 있다. 추천부는, 사용자 단말의 명시적 피드백 및 암시적 피드백에 기초하여 적어도 하나의 NFT를 추출하여 추천할 수 있다. 이때, 사용자 단말에서 상술한 GAN을 이용하여 자신이 원하는 NFT를 검색할 수도 있다. 예를 들어, 사용자가 원하는 NFT가 없다면 자신이 그림을 그리거나 찾아서 이미지 검색을 이용할 수도 있지만, 이미지 검색의 경우 완전히 동일한 것만 찾아줄 뿐, 사용자가 원하는 스타일이나 패턴 등을 찾기는 쉽지 않다. 또, 사용자가 원하는 시각정보가 존재하지 않거나 적절하지 않은 이미지가 존재하는 경우 GAN을 이용하면 사용 자가 원하는 스타일 등을 그림으로 표현해줄 수 있으므로, 사용자가 입력한 텍스트와 GAN이 생성한 이미지 중 사용자가 선택한 이미지를 모두 이용하여 사용자의 선호도를 파악하고 추천 목록을 추출해줄 수 있다. 이때, 추천부는, 사용자의 특성을 고려하여 항목에 대한 정보인 잠재(Latent)특성과 시각정보 중 어느 정 보에 가중치를 두고 선호도를 예측할지 정하는 것이 바람직하다. 이에 잠재특성과 시각정보 간의 가중치를 정 할 때 사용자와 항목에 대하여 주어진 모든 정보를 가지고 결정할 수 있도록 학습하는 인공 신경망 구조를 설계하여 선호도를 예측하는 추천 알고리즘을 이용할 수 있다. 이는 시각(Visual)정보 가중치를 적응적(Adaptive) 으로 학습하는 BPR(Bayesian Personalized Ranking)이라는 의미로 AVBPR이라 한다. AVBPR에서 시각정보는 VBPR과 같이 추출하며 선호도는 이하 수학식 1과 같이 계산된다. 수학식 1 이는 VBPR에서 사용한 선호도 예측 수식에서 잠재특성 벡터와 시각정보 벡터에 시각정보 가중치 ρ를 곱하여 사 용한다. 시각정보 가중치 ρ는 수학식 2를 통하여 산출할 수 있다. 수학식 2 사용자 u(User)의 잠재특성 벡터 γu, 항목 i(Item)의 잠재특성 벡터 γi, 사용자 u의 시각정보 θu, 항목 i의 시각정보 θi를 연결(Concatenate)한 후 적응적 학습 가중치 WA와 편향(Bias) bA로 구성된 선형 계층을 통과시 키고 마지막으로 활성함수 σ를 통과시킨다. 적응적 학습 알고리즘 다음으로 이미지가 존재하지 않거나 적절하지 않는 등의 현실 상황에 대처하기 위해, 상 술한 텍스트 투 이미지 GAN을 이용하여 사용자가 입력한 텍스트를 입력으로 하여 이미지를 생성한다. 이때 얻 은 이미지를 시각정보로 이용하여 추천을 수행할 수 있다. 우선, 텍스트 투 이미지 GAN을 사전학습(Pre- Training)하기 위해 AttnGAN 구조를 이용하여 진행한다. 사전학습을 위해서는 NFT의 상세설명이 담긴 텍스트와, NFT 이미지를 모두 가진 데이터셋이 필요하다. 그 다음으로는, 텍스트와 이미지 간의 유사도를 구하 기 위해 텍스트 인코더와 이미지 인코더를 학습하고, 학습된 인코더를 통해 텍스트를 입력으로 하는 이미지를 생성할 수 있다. 먼저, VBPR 알고리즘과 같은 방식으로 텍스트정보를 사용하여 항목 i에 대한 사용자 u의 선호 도를 계산하는 TBPR(Textual BPR)을 수학식 3과 같이 정의한다. 수학식 3 여기서 μ는 사전 학습된 Sentence-BERT(Bidirectional Encoder Representations from Transformers)를 통해 얻어진 NFT의 텍스트정보이며, μu는사용자 u와 항목 i의 텍스트정보가 담긴 잠재특성 벡터이다. 이때, 멀티모 달 BPR(Multi-Modal BPR, MMBPR)을 이용하는데, 이는 이전에 등장한 NFT의 시각정보와 텍스트정보를 모두 사용 하며, 선호도를 수학식 4와 같이 구할 수 있다. 수학식 4 시각정보와 텍스트정보를 모두 사용할 때 효과적인 성능을 보여주는 특징 융합 방식을 찾기 위해 이하의 방법을 이용하고 또 비교한 후 정확도가 가장 높게 나오는 방법을 본 발명의 플랫폼의 추천 방법으로 세팅할 수 있다. 첫 번째 방법은, 선호도 계산에 사용된 항목의 모든 정보를 다 더하여 곱 연산을 진행행하는 방법이고, 두 번째 방법은, 선호도 계산에 사용된 항목의 모든 정보를 이어 붙여 곱 연산을 진행하는 방법이고, 세 번째 방법은, Low-Rank Bilinear Pooling 방식을 사용하여 항목의 정보를 합성하는 방법인데, 잠재벡터는 그대로 사용하고 시 각정보와 텍스트정보를 Low-Rank Bilinear Pooling을 통과한다. 네 번째 방법은, 사용자와 항목의 특징정보를 각각 곱 연산하여 더해주는 방법인데, 모든 정보에 대하여 개별적으로 최적화를 진행할 수 있다. 물론, 상술한방법 외에도 다양한 방법으로 사용자에게 추천을 진행할 수 있으며 상술한 방법에 한정되지 않는다. 채굴권제공부는, 사용자 단말에서 프리미엄 계정으로 가입하는 경우, 사용자 단말로 블록체인에 서 채굴(Mining)을 위해 적어도 하나의 자원에 엑세스하는 엑세스권을 부여할 수 있다. 가상화폐는 사용자간 거래를 체결하고 새로운 화폐를 발행하기 위해 컴퓨터 자원을 사용한다. 이 과정에서 CPU와 GPU 같은 컴퓨터 자원을 제공하는 사용자는 보상으로 거래 수수료의 일부나 가상화폐를 발급받게 되는데 이를 채굴이라 한다. 예를 들어, 가맹점과 사용자 간 거래(Transaction)가 발생하기 위해서는, 가맹점은 상품을 팔고, 사용자는 화폐, 예를 들어 가상화폐를 지불해야 하는데, 사용자가 가상화폐를 전자지갑(Wallet)에 얼마를 가지고 있으며, 상품을 살 정도의 가상화폐를 가지고 있는지, 또 그 가상화폐는 유효한지 등을 검증한 후, 그 거래, 즉 사용자- 가맹점 간 거래를 기록하는 블록(Block)을 생성하여 기존 블록에 체인 형태로 새로운 블록을 연결해야 하고 분 산저장해야 한다. 이렇게 블록을 생성하여 거래내용을 기록하는 것에 CPU 및 GPU와 같은 컴퓨터 자원과 전기 에너지가 이용되는데, 이러한 자원을 제공해주는 노드(Node)에게 그 보상으로 가상화폐를 지급하는 것이다. 이 에 따라, 사용자가 프리미엄 계정에 가입한 경우, 본 발명의 플랫폼의 자원, 예를 들어, 채굴기를 IaaS 등의 클 라우드로 임대할 수 있도록 하고, 임대한 채굴기를 이용하여 채굴을 할 수 있는 권한을 부여할 수 있다. 이는 시간을 정해둘 수도 있고, 가용가능한 자원, 예를 들어, 더 좋은 모델의 채굴기를 이용할 수 있는 권한을 나누 거나 하는 방식으로 권한을 부여할 수도 있다. 이하, 상술한 도 2의 생성 서비스 제공 서버의 구성에 따른 동작 과정을 도 3 및 도 4를 예로 들어 상세히 설명 하기로 한다. 다만, 실시예는 본 발명의 다양한 실시예 중 어느 하나일 뿐, 이에 한정되지 않음은 자명하다 할 것이다. 도 3a를 참조하면 본 발명의 일 실시예에 따른 플랫폼(TIDUP)은, 도 3b와 같이 전 세계 모든 NFT 마켓에 있는 NFT를 TIDUP 안에서 검색, 구매, 결제 및 민팅 등을 수행할 수 있도록 구글, 다나와, 네이버 등과 같은 통합검 색엔진을 제공하며, 트렌드를 분석하고 NFT를 위한 콘텐츠를 생성해줄 수 있다. 도 3c와 같이 NFT를 발행, 검 사, 트렌트 검색, NFT 검색, NFT 결제 게이트웨이, 통합 커뮤니티를 제공하며, 도 3d 및 도 3e와 같이 NFT의 기 본이 되는 그림을 생성하거나, NFT를 도 3f와 같이 찾아줄 수 있다. 도 3f와 같이 가짜 NFT를 구별해주는 검사 시스템을 구축하여 진품 여부를 파악하고, 도 3h와 같이 아웃 링크로 결제를 하는 것이 아니라 본 발명의 플랫 폼에서 본 발명의 일 실시예에 따른 결제 프로세스로 결제를 수행할 수 있도록 한다. 또 도 3i와 같이 NFT 트 렌드를 분석해 안내해주고 어디에 투자를 해야할지에 대한 가이드를 제시해줄 수 있으며, 도 3j와 같은 커뮤니 티를 통합해줄 수 있다. 도 3k 및 도 3l와 같이 이 모든 것을 본 발명의 일 실시예에 따른 플랫폼에 통합하여 제공하며, 도 3m과 같은 모델을 이용하여 서비스를 제공하고 수익구조를 가질 수 있다. 도 4a는 본 발명의 일 실시예에 따른 플랫폼의 데모버전이고, 도 4b와 같이 P2E나 M2E로 확장할 수 있고, 도 4 와 같은 미션을 가질 수 있다. 도 4d는 현재 공개된 페이지(https://tidup.io/)의 메인화면인데, 돋보기 형상 옆에 원하는 NFT를 검색하면 통합검색으로 전 세계의 NFT를 검색할 수 있다. 도 4e와 같이 탑 아이템을 소개해 줄 수도 있고, 도 4f와 같이 어떠한 커뮤니티가 존재하는지도 리스트업해줄 수 있다. 도 4g와 같이 판매자의 랭크를 제공할 수도 있고, 카테고리 내 트렌드도 제공할 수 있으며, 이를 태그로 분류하여 카테고리화할 수도 있다. 도 4h와 같이 각 전자지갑을 연계할 수도 있다. 또 도 4i와 같이 어느 한 아티스트의 주소로 들어가면 판매하는 NFT 리스트를 볼 수 있고, 도 4j와 같이 어느 하나의 NFT를 선택하면, 가격과 최근 가격 추이를 도 4k 와 같이 보여줄 수 있다. 또 선택한 NFT를 통하여 협업 필터링 등으로 큐레이션된 추천(Recommendation) 상품 을 도 4l과 같이 나열할 수 있다. 이와 같은 도 2 내지 도 4의 인공지능 기반 NFT 생성 서비스 제공 방법에 대해서 설명되지 아니한 사항은 앞서 도 1을 통해 인공지능 기반 NFT 생성 서비스 제공 방법에 대하여 설명된 내용과 동일하거나 설명된 내용으로부 터 용이하게 유추 가능하므로 이하 설명을 생략하도록 한다. 도 5는 본 발명의 일 실시예에 따른 도 1의 인공지능 기반 NFT 생성 서비스 제공 시스템에 포함된 각 구성들 상 호 간에 데이터가 송수신되는 과정을 나타낸 도면이다. 이하, 도 5를 통해 각 구성들 상호간에 데이터가 송수 신되는 과정의 일 예를 설명할 것이나, 이와 같은 실시예로 본원이 한정 해석되는 것은 아니며, 앞서 설명한 다 양한 실시예들에 따라 도 5에 도시된 데이터가 송수신되는 과정이 변경될 수 있음은 기술분야에 속하는 당업자 에게 자명하다. 도 5를 참조하면, 생성 서비스 제공 서버는, 텍스트가 입력되면 이미지를 출력하는 적어도 하나의 인공지능 알 고리즘을 구축한다(S5100).그리고, 생성 서비스 제공 서버는, 사용자 단말에서 텍스트가 입력되는 경우 적어도 하나의 인공지능 알고리즘 에 텍스트를 입력하고(S5200), 적어도 하나의 인공지능 알고리즘에서 출력된 이미지를 사용자 단말로 전송한다 (S5300). 또, 생성 서비스 제공 서버는, 사용자 단말의 발행 요청이 수신되는 경우 이미지에 기하여 NFT를 발행한다 (S5400). 상술한 단계들(S5100~S5400)간의 순서는 예시일 뿐, 이에 한정되지 않는다. 즉, 상술한 단계들(S5100~S5400)간 의 순서는 상호 변동될 수 있으며, 이중 일부 단계들은 동시에 실행되거나 삭제될 수도 있다. 이와 같은 도 5의 인공지능 기반 NFT 생성 서비스 제공 방법에 대해서 설명되지 아니한 사항은 앞서 도 1 내지 도 4를 통해 인공지능 기반 NFT 생성 서비스 제공 방법에 대하여 설명된 내용과 동일하거나 설명된 내용으로부 터 용이하게 유추 가능하므로 이하 설명을 생략하도록 한다. 도 5를 통해 설명된 일 실시예에 따른 인공지능 기반 NFT 생성 서비스 제공 방법은, 컴퓨터에 의해 실행되는 애 플리케이션이나 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함하는 기록 매체의 형태로도 구현 될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매 체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기 타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리 형 매체를 모두 포함한다. 전술한 본 발명의 일 실시예에 따른 인공지능 기반 NFT 생성 서비스 제공 방법은, 단말기에 기본적으로 설치된 애플리케이션(이는 단말기에 기본적으로 탑재된 플랫폼이나 운영체제 등에 포함된 프로그램을 포함할 수 있음) 에 의해 실행될 수 있고, 사용자가 애플리케이션 스토어 서버, 애플리케이션 또는 해당 서비스와 관련된 웹 서 버 등의 애플리케이션 제공 서버를 통해 마스터 단말기에 직접 설치한 애플리케이션(즉, 프로그램)에 의해 실행 될 수도 있다. 이러한 의미에서, 전술한 본 발명의 일 실시예에 따른 인공지능 기반 NFT 생성 서비스 제공 방 법은 단말기에 기본적으로 설치되거나 사용자에 의해 직접 설치된 애플리케이션(즉, 프로그램)으로 구현되고 단 말기에 등의 컴퓨터로 읽을 수 있는 기록매체에 기록될 수 있다. 전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3a 도면3b 도면3c 도면3d 도면3e 도면3f 도면3g 도면3h 도면3i 도면3j 도면3k 도면3l 도면3m 도면4a 도면4b 도면4c 도면4d 도면4e 도면4f 도면4g 도면4h 도면4i 도면4j 도면4k 도면4l 도면5\n【요약】인공지능 기반 NFT 생성 서비스 제공 시스템이 제공되며, 입력된 텍스트를 이용하여 생성된 이미지를 출력하고, 이미지에 기하여 NFT의 발행을 요청하는 사용자 단말 및 텍스트가 입력되면 이미지를 출력하는 적어도 하나의 인 공지능 알고리즘을 구축하는 구축부, 사용자 단말에서 텍스트가 입력되는 경우 적어도 하나의 인공지능 알고리즘 에 텍스트를 입력하는 입력부, 적어도 하나의 인공지능 알고리즘에서 출력된 이미지를 사용자 단말로 전송하는 전송부, 사용자 단말의 발행 요청이 수신되는 경우 이미지에 기하여 NFT를 발행하는 발행부를 포함하는 생성 서 비스 제공 서버를 포함한다.\n\n【청구항 1】\n입력된 텍스트를 이용하여 생성된 이미지를 출력하고, 상기 이미지에 기하여 NFT의 발행을 요청하는 사용자 단말; 및텍스트가 입력되면 이미지를 출력하는 적어도 하나의 인공지능 알고리즘을 구축하는 구축부, 상기 사용자 단말에서 텍스트가 입력되는 경우 상기 적어도 하나의 인공지능 알고리즘에 상기 텍스트를 입력하는 입력부, 상기적어도 하나의 인공지능 알고리즘에서 출력된 이미지를 상기 사용자 단말로 전송하는 전송부, 상기 사용자 단말의 발행 요청이 수신되는 경우 상기 이미지에 기하여 NFT를 발행하는 발행부를 포함하는 생성 서비스 제공서버;를 포함하는 인공지능 기반 NFT 생성 서비스 제공 시스템.\n【청구항 2】\n제 1 항에 있어서,상기 생성 서비스 제공 서버는,상기 사용자 단말에서 텍스트를 입력하면 동영상을 생성하거나, 상기 이미지 또는 상기 사용자 단말에서 업로드한 이미지로 동영상을 생성하는 적어도 하나의 인공지능 알고리즘을 구축하는 동영상부;를 더 포함하는 것을 특징으로 하는 인공지능 기반 NFT 생성 서비스 제공 시스템.\n【청구항 3】\n제 1 항에 있어서,상기 생성 서비스 제공 서버는,상기 이미지 또는 상기 사용자 단말에서 업로드한 이미지로 3D 이미지를 생성하는 적어도 하나의 인공지능 알고리즘을 구축하는 3D부;를 더 포함하는 것을 특징으로 하는 인공지능 기반 NFT 생성 서비스 제공 시스템.\n【청구항 4】\n제 1 항에 있어서,상기 생성 서비스 제공 서버는,상기 사용자 단말에서 상기 사용자 단말에서 기 소유한 NFT에 대한 등록요청을 하는 경우, 상기 사용자 단말로상기 기 소유한 NFT의 창작물을 창작한 창작자 및 상기 창작물을 소유한 소유자에 대한 계약서를 업로드하도록하고, 상기 계약서에 따라 발생된 트랜잭션(Transaction)을 상기 NFT의 메타데이터에 추가하는 소유권증명부;를 더 포함하는 것을 특징으로 하는 인공지능 기반 NFT 생성 서비스 제공 시스템.\n【청구항 5】\n제 4 항에 있어서,공개특허 10-2024-0083776-3-상기 생성 서비스 제공 서버는,상기 사용자 단말에서 상기 창작물에 기하여 NFT의 발행을 요청하는 경우, 상기 NFT의 메타데이터에 필드(Field)를 추가하여 상기 계약서 및 트랜잭션을 기록하는 권리확인부;를 더 포함하는 것을 특징으로 하는 인공지능 기반 NFT 생성 서비스 제공 시스템.\n【청구항 6】\n제 1 항에 있어서,상기 생성 서비스 제공 서버는,적어도 하나의 NFT 마켓으로부터 NFT 데이터를 수집하여 업로드할 때, 상기 NFT 데이터 내 NFT 이미지에 대한진위확인을 수행하는 진위확인부;를 더 포함하는 것을 특징으로 하는 인공지능 기반 NFT 생성 서비스 제공 시스템.\n【청구항 7】\n제 1 항에 있어서,상기 생성 서비스 제공 서버는,적어도 하나의 소셜미디어 및 커뮤니티의 오피니언 데이터를 수집하여 NFT의 랭킹을 리스트업하는 랭킹부;를 더 포함하는 것을 특징으로 하는 인공지능 기반 NFT 생성 서비스 제공 시스템.\n【청구항 8】\n제 7 항에 있어서,상기 생성 서비스 제공 서버는,적어도 하나의 NFT에 대한 데이터를 수집하여 트렌드를 분석하는 트렌드분석부;를 더 포함하는 것을 특징으로 하는 인공지능 기반 NFT 생성 서비스 제공 시스템.\n【청구항 9】\n제 8 항에 있어서,상기 생성 서비스 제공 서버는,상기 사용자 단말의 명시적 피드백 및 암시적 피드백에 기초하여 상기 적어도 하나의 NFT를 추출하여 추천하는추천부;를 더 포함하는 것을 특징으로 하는 인공지능 기반 NFT 생성 서비스 제공 시스템.\n【청구항 10】\n제 1 항에 있어서,상기 생성 서비스 제공 서버는,상기 사용자 단말에서 프리미엄 계정으로 가입하는 경우, 상기 사용자 단말로 블록체인에서 채굴(Mining)을 위해 적어도 하나의 자원에 엑세스하는 엑세스권을 부여하는 채굴권제공부;공개특허 10-2024-0083776-4-를 더 포함하는 것을 특징으로 하는 인공지능 기반 NFT 생성 서비스 제공 시스템."}
{"context": "", "input": "【기술명】\n자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템 및 방법\n\n【기술 설명】\n본 발명은 자동차 도장작업장에서의 대기오염물질 배출을 효과적으로 관리하기 위한 인공지능 기반 시스템 및 방법에 관한 것입니다. 이 시스템은 고급 센서 모듈을 통해 실시간으로 미세먼지 및 휘발성 유기화합물(VOC)의 농도를 측정하며, 이를 바탕으로 인공지능 알고리즘이 제품 부품의 이상 상태를 판단하고 조치를 취합니다. 또한, 잔여 수명을 예측하고, 필요한 경우 교체 또는 수리를 권장하며, 유지보수 활동 및 일정을 최적화하여 효율적인 운영을 가능하게 합니다. 이러한 시스템은 대기환경을 개선하고, 자동차 도장작업장의 지속 가능성을 높이는 데 크게 기여할 것입니다.\n\n【해결 문제】\n자동차 도장작업장은 화학물질을 사용하여 대기오염물질을 방출하며, 이는 심각한 환경문제를 초래합니다. 특히, 미세먼지와 VOC는 인체 건강에 해로운 영향을 미치며, 이에 대한 규제가 점점 강화되고 있습니다. 기존의 관리 시스템은 실시간 데이터 수집과 예측 기능이 부족하여, 적시에 필요한 조치를 취하기 어렵습니다. 본 발명은 이러한 문제를 해결하여, 대기오염물질의 배출을 최소화하고, 사용자에게 정확한 유지보수 정보를 제공함으로써 보다 안전하고 건강한 작업 환경을 조성하는 것을 목표로 합니다.\n\n【기술 차별성】\n본 발명은 기존 대기오염물질 관리 시스템과는 차별화된 점이 있습니다. 기존 시스템들은 대기오염물질 농도를 측정하는 데 그치지만, 본 발명은 인공지능을 통해 실시간으로 부품의 상태를 분석하고 예측하여, 사전 예방적 조치를 취하는 혁신적인 기능을 포함합니다. 또한, 사용자가 필요로 하는 교체 시기를 반영한 비용 산출 및 알림 기능을 제공함으로써, 사용자 맞춤형 서비스를 구현합니다. 이러한 기술적 차별성과 혁신성은 자동차 도장작업장의 운영 효율성을 극대화하고, 환경 보호에 기여하는 중요한 요소로 작용할 것입니다.\n\n【활용 분야】\n본 발명은 자동차 도장작업장에 특화된 대기오염물질 배출관리 시스템으로, 제조업, 환경관리, 스마트 팩토리 등 다양한 산업 분야에서 활용될 수 있습니다. 특히, 자동차 산업 내 도장 공정에서 발생하는 대기오염물질을 효과적으로 관리함으로써, 기업의 지속 가능한 생산성을 높이고 환경 규제를 준수하도록 돕습니다. 또한, 이 시스템은 인공지능 기반의 예측 및 유지보수 기능을 통해 운영 효율성을 강화하며, 향후 전 세계적으로 확산되는 친환경 제조 트렌드에 기여할 수 있는 잠재력을 가지고 있습니다.\n\n【구성 요소 및 기능】\n1. 센서모듈: 이 모듈은 굴뚝 내부에 설치되어 미세먼지와 휘발성 유기 화합물(VOC)의 농도를 실시간으로 측정합니다. 이를 통해 대기오염물질 배출 상황을 정확히 파악하고, 적절한 조치를 취할 수 있는 데이터를 제공합니다.  \n2. 관리서버: 관리서버는 센서모듈에서 수집된 데이터를 보정하여 인공지능 제어부가 이상 상태를 판단하도록 돕습니다. 또한, 잔존 수명 예측 및 유지보수 추천을 통해 운영 효율성을 극대화합니다.  \n3. 원격측정장치: 이 장치는 센서와 전력량측정계로부터 수집된 데이터를 통신하여 관리서버에 전송합니다. 이를 통해 사용자단말에 실시간으로 정보를 제공하고, 필요한 경우 경고 및 알람 기능을 수행하여 신속한 대응을 가능하게 합니다.\n\n【구현 방식 예】\n시스템 구현은 단계별로 진행됩니다. 첫째, 인프라 구축 단계에서 센서모듈과 원격측정장치를 자동차 도장작업장에 설치하고, 관리서버와 사용자단말 간의 통신 네트워크를 설정합니다. 둘째, 데이터 수집 및 처리 단계에서 센서모듈이 실시간으로 대기오염물질 데이터를 측정하고, 이를 원격측정장치가 관리서버에 전송합니다. 마지막으로, 인공지능 제어부가 수집된 데이터를 분석하여 유지보수 일정 및 교체 권고를 자동으로 생성하며, 이를 사용자단말에 전달하여 효율적인 운영을 지원합니다.", "output": "【발명의 명칭】\n자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템 및 방법\n【기술분야】\n본 발명은 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템 및 방법에 관한 것으로, 더욱 상세하 게는 인공지능을 이용하여 제품의 각 부품의 이상 상태를 판단하여 조치하며, 잔존 수명을 예측하고, 교체 또는 수리를 권고하고, 제한된 자원으로 유지보수 활동 및 일정 계획까지 생성하여 제공하는, 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템 및 방법에 관한 것이다.\n【배경기술】\n일반적으로 산업화는 인류의 경제발전을 이끌었지만, 반대로 대기오염, 수질오염, 토양오염, 온난화, 오존층파 괴 등 환경문제를 야기하였다. 특히 도시에 인구가 밀집하면서 주거난방 및 교통수단의 밀집으로 인한 대기오염 이 주요한 환경문제로 대두되고 있다. 최근에는 미세먼지가 국가적인 재난으로 여겨질 정도로 문제되고 있다. 최근 자동차를 보유한 사람들이 많아지고, 자동차가 단순히 이동수단이 아닌 소장품으로 여기는 경우도 늘고 있 다. 자동차의 내구성과 외관을 유지하기 위해, 자동차 스크래치를 복원하는 도장작업도 증가하고 있다. 자동차 도장작업은 페인트, 용제 등의 화학약품을 사용하므로, 배기가스 중에 대기오염물질인 미세먼지, 휘발성 유기화 합물(Volatiile Organic Compounds; VOC) 등을 배출하게 된다. 소규모 자동차 수리업체의 경우, 도장시설을 주택가에 설치하여 운영하는 경우도 많다. 자동차 부분도장 시설중 총 부피가 5m3 이하, 동력 3hp 이하는 대기배출방지시설 신고대상에서 제외되고 있으며, 이로 인한 소규모의 도 장시설의 대기오염도가 심각한 실정이다. 한편 대기환경 관련 법규에 따라 운영기록부를 기록하여야 하는데, 소 규모 업체의 경우 매일 점검하지 못하는 것이 현실이다. 등록특허공보 제10-0419567호 \"인터넷을 이용한 실시간 대기배출시설 종합관리 시스템\"에는 굴뚝에서 대기오염 물질 배출농도를 연속적으로 측정하는 원격 계측 시스템과 인터넷망을 이용하여 연속적으로 기상요소를 제공하 는 인터넷 실시간 기상자료 전송시스템을 대기확산모델에 접목하여 굴뚝주변 대기환경을 종합적으로 관리하는 인터넷을 이용한 실시간 대기배출시설 종합관리시스템이 개시되어 있다. 시시각각으로 변화하는 주변기상의 영 향을 고려해 줄 수 있어 굴뚝 주변의 오염물질의 확산을 현재기상을 고려하여 정확히 예측할 수 있다는 장점이 있으나, 필터교체 등에 대해서는 개시되고 있지 않다. 등록특허공보 제10-1828970호 \"자동차 도장부스의 멀티형 배기장치\"에서는 자동차 도장부스 내부에서 도장 및 열처리 작업을 할 때 발생되는 오염물질(분진 및 악취voc)을 필터로 제거하는 작업과 배기필터의 재생이 동시에 이루어지도록 하여 별도의 소제 없이도 반영구적으로 사용할 수 있도록 한 자동차 도장부스의 멀티형 배기장치 가 개시된다. 필터구조체의 배기가스 통과공간을 폐쇄한 상태에서 상기 에어공급관으로부터 유입된 압축공기 또는 가열공기를 통해 상기 필터구조체의 각 필터를 재생할 수 있는 효과가 있으나, 고온의 가열공기가 필요하고 재포집된 오염물질을 별도의 공해방지시설에서 처리해야 한다. 이러한 문제를 해결하기 위하여 본 출원인에 의해 10-2249411호가 등록되어 있다. 이러한 선행기술은 도장작업장에서 발생하는 대기환경오염을 방지하며, 부패취를 예방하고, 악취로 인한 민원을 사전 예방할 수 있는 자동차 도장작업장의 대기오염물질 배출관리 시스템 및 방법을 제공한다. 그러나, 이에 한발 더 나아가 제품의 각 부품의 이상 상태를 판단하여 조치하며, 잔존 수명을 예측하고, 교체 또는 수리를 권고하고, 제한된 자원으로 유지보수 활동 및 일정 계획까지 생성하여 제공할 필요가 있다.\n【해결하려는 과제】\n본 발명이 이루고자 하는 기술적 과제는 종래의 불편한 점을 개선하고자 하는 것으로, 인공지능을 이용하여 제 품의 각 부품의 이상 상태를 판단하여 조치하며, 잔존 수명을 예측하고, 교체 또는 수리를 권고하고, 제한된 자 원으로 유지보수 활동 및 일정 계획까지 생성하는, 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스 템 및 방법을 제공하는 것이다. 또한, 본 발명이 이루고자 하는 기술적 과제는 종래의 불편한 점을 개선하고자 하는 것으로, 제품의 각 부품의 수리 또는 교체시의 기간별 소요비용을 산출하여 제공하고, 제품 교체 시기를 반영하여 수리 또는 교체를 추천 하며, 부품의 고장시기를 학습하여 예측하고, 예측된 고장시기 전에 미리 사용자 또는 점검자에게 알람하는, 자 동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템 및 방법을 제공하는 것이다.\n【과제의 해결 수단】\n이러한 과제를 해결하기 위한 본 발명의 특징에 따른 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시 스템은, 센서모듈, 전력량측정계, 원격측정장치, 관리서버, 사용자단말을 포함한다. 상기 센서모듈은 상기 굴뚝의 내부에 설치되고, 상기 굴뚝을 통해 배출되는 가스의 미세먼지를 측정하는 미세먼 지센서; 및 상기 굴뚝을 통해 배출되는 가스의 휘발성 유기 화합물(VOC)의 양을 측정하는 VOC센서;를 포함한다. 상기 전력량측정계는 상기 굴뚝을 통해 대기오염물질을 배출시키는 송풍팬에서 소모되는 전력량을 측정한다. 상기 원격측정장치는, 상기 센서모듈의 센서들과 상기 전력량측정계로부터 각각의 측정데이터를 입력받는 센서 통신모듈; 상기 측정데이터를 상기 관리서버로 전송하는 서버통신모듈; 출력장치로 상기 데이터를 송신하는 출 력모듈; 및 상기 송풍팬의 가동을 제어하는 제어모듈;을 포함한다. 상기 관리서버는, 상기 측정데이터의 보정에 사용하는 기준데이터를 수신하는 외부서버통신부; 상기 기준데이터 를 이용하여 상기 측정데이터로부터 보정데이터를 구하고, 제품의 각 부품의 이상 상태를 판단하여 조치하며, 잔존 수명을 예측하고, 교체 또는 수리를 권고하는 인공지능 제어부; 상기 인공지능 제어부의 제어에 따라 데이 터를 저장장치에 기록하는 기록관리부; 상기 사용자단말로 상기 데이터와 필터정보를 송신하는 단말통신부; 및 상기 원격측정장치로부터 상기 측정데이터를 수신하는 측정장치통신부;를 포함할 수 있다. 상기 데이터를 저장장치에는 제품정보, 제품을 구성하는 부품정보, 부품의 수명정보, 부품의 가격정보, 유지관리 정보, 기간별 소요비용 예 상 정보를 저장하고, 상기 인공지능 제어부는, 상기 데이터 저장장치를 참조하여 상기 부품의 이상시에 상기 부품의 수명정보 및 상 기 부품의 가격정보를 참조하여 기간별 소요비용 예상 정보를 계산하여 제공한다. 상기 인공지능 제어부는, 상기 데이터 저장장치를 참조하여 상기 부품의 이상시에 상기 부품의 수명정보 및 상기 부품의 가격정보를 참조 하여 기간별 소요비용 예상 정보를 계산하는 비용 예측부; 상기 데이터 저장장치의 상기 부품의 수명 및 고장 이력을 참조하여 부품의 고장 시기를 계산하는 고장 예측부 ;상기 사용자 단말기로부터 제품의 이상이 접수되면, 점검자에게 출동을 알리는 메시지를 송신하고, 상기 부품의 고장이 예상되는 시기가 다가오면 미리 사용자 단말기로 알람을 하는 정보제공부를 포함한다. 상기 정보 제공부는 사용자 단말기의 요청에 따라 제품정보, 제품의 부품정보, 부품의 가격정보, 부품의 수명정 보, 부품의 유지관리정보 및 제품의 교체예정 정보를 제공한다. 상기 인공지능 대기오염물질 배출관리 시스템은, 상기 굴뚝의 배출구에 결합하고 상기 센서통신모듈의 신호에 의해 개폐되는 덮개;를 더 포함할 수 있다. 상기 덮개는 상기 배출구를 개폐하기 위하여 상하로 이동하는 개폐가이드;를 포함할 수 있다. 상기 덮개는, 상기 굴뚝을 통해 배출되는 대기오염물질이 상기 센서모듈에서 검출되도록 상기 굴뚝을 통해 배출 되는 가스가 회전하며 배출되도록 유도하는 스크류형 배출가이드;를 포함할 수 있다. 이러한 과제를 해결하기 위한 본 발명의 특징에 따른 자동차 도장작업장의 인공지능 대기오염물질 배출관리 방 법은, 적어도 하나의 제품의 사용자 단말기 또는 점검자 단말기와 통신하며, 상기 제품의 이상시에 수리 또는 교체되 는 부품에 대하여 유지 관리를 하는, 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템의 자동차 도 장작업장의 인공지능 대기오염물질 배출관리 방법으로서, 상기 사용자 단말기로부터 제품 또는 부품의 이상 정보를 수신하는 단계; 상기 부품의 이상시에 상기 부품의 수명정보 및 상기 부품의 가격정보를 참조하여 기간별 소요비용 예상 정보를 계산하여 상기 사용자 단말기 또는 점검자 단말기에 제공하는 단계; 상기 부품의 수명 및 고장 이력을 참조하여 부품의 고장 시기를 계산하여 상기 사용자 단말기 또는 점검자 단말 기에 제공하는 단계; 상기 부품의 고장이 예상되는 시기가 다가오면 미리 사용자 단말기 또는 점검자 단말기로 알람을 하는 단계; 사용자 단말기 또는 점검자 단말기의 요청에 따라 제품정보, 제품의 부품정보, 부품의 가격정보, 부품의 수명정 보, 부품의 유지관리정보 및 제품의 교체예정 정보를 제공하는 단계를 포함한다. 상기 점검자 단말기는 유지관리정보중 제품 및 부품 매뉴얼 정보를 수신하여 표시하여 점검자가 부품 점검 또는 수리 또는 교체 시에 편리함을 제공한다. 상기 사용자 단말기로부터 제품의 이상이 접수되면, 상기 점검자 단말기로 출동을 알리는 메시지를 송신한다.\n【발명의 효과】\n본 발명의 실시예에서는, 인공지능을 이용하여 제품의 각 부품의 이상 상태를 판단하여 조치하며, 잔존 수명을 예측하고, 교체 또는 수리를 권고하고, 제한된 자원으로 유지보수 활동 및 일정 계획까지 생성하는, 자동차 도 장작업장의 인공지능 대기오염물질 배출관리 시스템 및 방법을 제공할 수 있다. 또한, 본 발명의 실시예에서는, 인공지능을 이용하여 제품의 각 부품의 수리 또는 교체시의 기간별 소요비용을 산출하여 제공하고, 제품 교체 시기를 반영하여 수리 또는 교체를 추천하며, 부품의 고장시기를 학습하여 예측 하고, 예측된 고장시기 전에 미리 사용자 또는 점검자에게 알람하는, 자동차 도장작업장의 인공지능 대기오염물 질 배출관리 시스템 및 방법을 제공할 수 있다.\n【발명을실시하기위한구체적인내용】\n아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위 해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 도 1은 본 발명의 실시예에 따른 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템의 구성도이다. 도 1을 참조하면, 본 발명의 실시예에 따른 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템에서, 자동차 도장작업장의 도장부스에서 발생하는 대기오염물질은 송풍팬을 이용하여 굴뚝을 통해 배 출된다. 배출가스 중의 대기오염물질을 관리하기 위하여 본 발명의 일 실시예에 따른 자동차 도장작업장의 인공 지능 대기오염물질 배출관리 시스템은, 원격측정장치, 관리서버, 사용자단말을 포함한다. 굴뚝에는 배출되는 배기가스 중에 대기오염물질의 양을 측정하는 센서들이 설치된다. 원격측정장치는 굴뚝에 있는 센서들과 통신할 수 있도록 연결된다. 센서들로부터 측정된 대기오염물질에 대한 측정데이터를 원 격측정장치로 전송되고, 원격측정장치는 측정데이터를 관리서버로 전송할 수 있다. 관리서버는 측정데이터를 보정할 필요가 있는지 판단하고, 보정할 필요가 있는 경우 보정을 실시한다. 관 리서버는 보정된 측정데이터인 보정데이터를 저장장치로 저장할 수 있다. 보정데이터는 원격측정장치(13 0)로 전송되어 출력장치로 표시할 수 있다. 관리서버는 사용자단말과 통신할 수 있는 수단을 구비하여, 필터교체 정보를 사용자단말로 전송할 수 있다. 사용자단말로부터 대기오염물질의 배출 데이터를 요청받는 경우, 관리서버는 저장장치에 기록 되어 있는 보정데이터를 사용자단말로 전송할 수 있다. 대기오염물질 측정 센서들을 일체화시켜 센서모듈로 구현할 수 있다. 도 6을 참조하면, 굴뚝의 내부에 센서모듈을 설치할 수 있다. 센서모듈은 미세먼지센서와 VOC 센서를 포함한다. 미세먼지센서는 굴뚝을 통해 배출되는 가스 중의 미세먼지 농도를 측정한다. 환경부에서는 미세먼지를 입 자의 지름이 10 μm 이하인 미세먼지(PM10)와 입자의 지름이 2.5 μm 이하인 초미세먼지(PM2.5)로 구분한다. 미 세먼지(PM10)는 연간 평균치를 50 μg/m3 이하로, 24시간 평균치를 100 μg/m3 이하로 관리하고, 입자 지름이 더작아 인체에 더욱 유해한 초미세먼지(PM2.5)는 연간 평균치를 15 μg/m3 이하로, 24시간 평균치를 35 μg/m3 이하로 관리한다. 미세먼지(PM10)는 베타선흡수법으로 측정하고, 초미세먼지(PM2.5)는 중량농도법으로 측정하는 것이 원칙이다.VOC센서는 굴뚝을 통해 배출되는 가스 중에 휘발성 유기화합물(Volatiile Organic Compounds; VOC)의 양 을 측정할 수 있다. 송풍팬에는 전력량측정계를 연결하여, 송풍팬에서 소모되는 전력량을 측정할 수 있다. 전력량측정계 는 원격측정장치와 통신할 수 있도록 설치되어, 측정된 전력데이터를 원격측정장치로 전송할 수 있다. 원 격측정장치는 수신된 전력데이터를 관리서버로 전송하고, 관리서버는 전력데이터를 저장장치에 기록할 수 있다. 도 2는 본 발명의 일 실시예에 따른 자동차 도장작업장의 대기오염물질 배출관리 시스템 중 원격측정장치의 개 략적인 구성을 나타내는 구성도이다. 원격측정장치는 센서통신모듈, 제어모듈, 서버통신모듈, 출력모듈을 포함한다. 추가 로 출력장치를 포함할 수 있다. 센서통신모듈은 센서모듈의 센서들과 송풍팬에 연결된 전력량측정계로부터 각각의 측정데이터를 입력받는다. 센서통신모듈은 송풍팬의 가동을 제어하는 신호를 송풍팬으로 송신할 수 있다. 도 6을 참조하면, 굴뚝의 배출구에 덮개를 설치할 수 있다. 센서통신모듈은 덮개의 개폐를 제어하는 신호를 송신할 수 있다. 서버통신모듈은 센서통신모듈을 통해 수신된 각각의 측정데이터를 관리서버로 전송하고, 관리서버 로부터 측정데이터를 보정한 보정데이터를 수신한다. 관리서버로부터 필터정보를 수신할 수 있다. 출력모듈은 보정데이터 및 필터정보를 출력장치로 송신할 수 있다. 출력장치는 전송된 정보를 출력한다. 출력장치로는 모니터, 터치패널 등을 사용할 수 있다. 제어모듈은 사용자로부터 작업여부에 대한 입력을 수신한다. 사용자의 입력은 키보드, 터치패드 등을 통하 여 입력받을 수 있다. 사용자로부터 작업 가동 신호를 입력받은 경우, 배출구 덮개를 개방하고 송풍팬의 가동을 개시한다. 사용자로부터 작업 중지 신호를 입력받는 경우, 송풍팬의 가동을 중지하고 배출구 덮개를 폐 쇄한다. 제어모듈의 신호는 센서통신모듈을 통해 배출구 덮개와 송풍팬으로 전달할 수 있다. 도 3은 본 발명의 일 실시예에 따른 자동차 도장작업장의 대기오염물질 배출관리 시스템 중 원격측정장치의 출 력장치 화면을 나타내는 사진이다. 출력장치는 출력모듈을 통해 전달된 각종 정보를 출력할 수 있다. 센서모듈을 통해서 측정된 미세먼 지농도, VOC측정량 뿐만 아니라 전력량측정계로부터 전달된 송풍팬의 전력소모량과 누적전 력소모량을 표시한다. 그밖에 당일 가동시간과 현재전압 등도 출력할 수 있다. 센서 또는 외부 서버로부터 입수된 온도, 습도 등의 환경데이터도 표시할 수 있다. 도 3에서 출력장치는 원격측정장치와 일체로 구성하였다. 출력장치를 터치스크린으로 구성하면, 사용자의 입력을 입력받아 제어모듈로 전달할 수 있다. 사진 하부에는 원격측정장치의 센서통신모듈 에 연결되어 있는 케이블이 있어서, 외부의 센서모듈로부터 측정데이터를 수신할 수 있다. 도 4는 본 발명의 일 실시예에 따른 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템 중 관리서버 의 개략적인 구성을 나타내는 구성도이다. 관리서버는 단말통신부, 외부서버통신부, 제어부, 단말통신부, 기록관리부를 포 함한다. 추가로 저장장치를 포함할 수 있다. 측정장치통신부는 원격측정장치로부터 측정데이터를 수신한다. 제어부에서 측정데이터를 보정한 보정 데이터를 원격측정장치로 송신할 수 있다. 외부서버통신부는 측정데이터의 보정에 사용하기 위하여 기준데이터를 외부의 서버로부터 수신한다. 기준 데이터로는 측정지역의 온도, 습도 등의 외부환경데이터 뿐만 아니라, 미세먼지농도, 오존농도, 이산화질소, 이 산화탄소, 아황산가스 등 대기오염물질의 농도를 수신할 수 있다. 인공지능 제어부는 기준데이터를 이용하여 보정여부를 판단하고, 측정데이터로부터 보정데이터를 구한다. 제어부는 필터교체 시기가 되었는지 여부도 판단한다. 보정데이터가 법적으로 허용되는 허용기준치인 미세먼지 50 ppm과, VOC 200 ppm 를 초과하는 경우에 관리서버는 사용자단말로 필터교체 알람을 송신한다. 미세먼지와 VOC가 법적기준치 이내인 경우라도, 주간 누적전력량이 임계전력량보다 커지는 경우에 사용자단말로 미리 필터를 교체하도록 알림을 전송할 수 있다. 이때 임계전력량은 필터교체후 최초 1주간 전력량의 1.8배로 설정할 수 있다. 기록관리부는 보정데이터를 저장장치에 기록한다. 단말통신부는 사용자단말로 필터교체 정보를 송신한다. 필터교체 정보는 푸시 서비스를 이용하여 제 공할 수 있다. 사용자단말로부터 보정데이터 요청을 전달받는 경우, 단말통신부는 유무선 통신수단을 통해 서 보정데이터를 사용자단말로 송신할 수 있다. 도 6을 참조하면, 굴뚝을 통해 배출되는 배기가스는 필터를 통과하므로 대기오염물질 농도가 급격하 게 변하지 않는다. 그러나 최근 문제가 많이 되고 있는 미세먼지의 경우 배기가스의 배출 통로를 역류하여 들어 올 수 있으며, 이러한 경우 측정데이터에 오류가 발생할 수 있다. 예를 들어, 매 1분 간격으로 측정한 측정데이터가 10분전에 측정한 측정데이터보다 30% 이상의 변화가 있거나, 외부 서버로부터 입수한 미세먼지(PM10) 기준데이터가 80 μg/m3 이상인 경우, 외부 미세먼지에 의한 영향을 보 정할 필요가 있는 것으로 판단한다. 미세먼지에 의한 보정을 하는 방법으로는, 최근 측정데이터(R1)와 10분전 측정데이터(R10)의 시간당 상승률(기 울기)인 (R10 - R1) / 10 을 이용하여, T분 경과된 이후의 보정데이터(VR)를 VR = R1 + (R10 - R1) / 10 * T식 으로 구할 수 있다. 외부서버로부터 수신한 미세먼지(PM10) 기준데이터가 80 μg/m3 이하가 되는 경우 보정을 중지한다. 도 5를 참조하면, 인공지능 제어부는 상기 저장장치를 참조하여 필터 등을 포함한 부품의 이상시에 상기 부품의 수명정보 및 상기 부품의 가격 정보를 참조하여 기간별 소요비용 예상 정보를 계산하는 비용 예측부; 상기 저장장치의 상기 부품의 수명 및 고장 이력을 참조하여 부품의 고장 시기를 계산하는 고장 예측부 ; 상기 사용자 단말기로부터 제품의 이상이 접수되면, 상기 점검자 단말기로 출동을 알리는 메시지를 송신하 고, 상기 부품의 고장이 예상되는 시기가 다가오면 미리 사용자 단말기 또는 점검자 단말기로 알람을 하는 정 보제공부를 포함한다. 상기 정보제공부는 사용자 단말기 또는 점검자 단말기의 요청에 따라 제품정보, 제품의 부품정보, 부 품의 가격정보, 부품의 수명정보, 부품의 유지관리정보 및 제품의 교체예정 정보를 제공한다. 상기 정보제공부는 사용자 단말기 또는 점검자 단말기의 입력에 따라 변동되는 부품가격 또는 제품의 정보로 상기 데이터베이스부를 업데이트한다. 상기 점검자 단말기는 유지관리정보중 제품 및 부품 매뉴얼 정보를 수신하여 표시하여 점검자가 부품 점검 또는 수리 또는 교체 시에 편리함을 제공한다. 도 6은 본 발명의 일 실시예에 따른 자동차 도장작업장의 대기오염물질 배출관리 시스템 중 굴뚝의 개략적인 구 성을 나타내는 구성도이다. 굴뚝에서 배기가스가 진입하는 부분에는 필터를 설치하여 배기가스의 대기오염물질을 제거한다. 필터 를 거친 배기가스는 센서모듈을 통과하고, 센서모듈 내의 미세먼지(PM10)센서, 휘발성 유기화합물(VOC)센 서등에 의하여 대기오염물질의 농도가 측정된다. 배기가스는 굴뚝의 배출구을 통하여 외부 대기로 방출된 다. 미세먼지 포집 및 원활한 배기를 위해서 부직포 또는 유리섬유 재질의 필터를 사용할 수 있다. 휘발성 유기화합 물을 흡착하기 위해서는 주로 활성탄을 포함한 필터가 사용된다. 필터는 용도에 맞추어 복수로 사용하는 것이 바람직하다. 작업을 하지 않는 경우에 외부로부터 굴뚝으로 대기오염물질이 역류하여 들어오는 것을 방지하기 위하여, 굴뚝 의 배출구에 덮개를 결합할 수 있다. 덮개는 센서통신모듈의 신호에 의해 개폐될 수 있다. 송풍팬의 가동 전에 덮개를 열고, 송풍팬의 가동이 중지하는 경우에 덮개를 덮는 것이 바람직하다. 덮개는 굴뚝의 배출구를 개폐하기 위하여 상하로 이동하는 개폐가이드를 포함할 수 있다. 개폐 가이드에 랙기어를 형성하면, 모터로 동작하는 피니언 기어에 의해 손쉽게 덮개를 상하이동 시킬 수 있다. 한편, 굴뚝에는 스크류형 배출가이드를 포함할 수 있다. 스크류형 배출가이드는 굴뚝을 통 해 배출되는 가스가 회전하며 배출되도록 유도할 수 있어서, 굴뚝을 통해 배출되는 대기오염물질이 센서모 듈에서 용이하게 검출할 수 있다. 또한 스크류형 배출가이드는 외부 대기가 역류하는 것을 효과적으 로 방지할 수 있어서, 미세먼지 등의 외부 대기오염물질이 센서모듈로 직접 닿는 것을 방지하여 정확한 측 정에 도움을 줄 수 있다. 스크류형 배출가이드의 중앙에는 고정축을 구비할 수 있다. 고정축은 배출구의 덮개에 나 사 등으로 중앙부에 결합할 수 있어서, 기존의 굴뚝 배출구에 덮개를 설치할 때, 스크류형 배출가이드도 함께 설치할 수 있다. 도 7은 본 발명의 일 실시예에 따른 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템에서 수행되는 자동차 도장작업장의 대기오염물질 배출관리 방법을 나타내는 흐름도이다. 도 7을 참조하여, 자동차 도장작업장의 대기오염물질 배출관리 방법을 개략적으로 설명하면 다음과 같다. 먼저 원격측정장치는 센서 등이 정상적으로 동작하는지 확인하는 장치 초기화 작업을 실시한다(S710). 관 리서버는 배출기준을 미리 설정한다(S715). 작업개시 신호가 원격측정장치로 입력되면(S720), 원격측정장치는 배출구를 개방하고(S725) 송풍팬을 가동시킨 다. 센서모듈로부터 대기오염물질의 농도에 대한 측정데이터를 입력받고, 전력량측정계로부터 송풍팬(11 4)의 전력소모량에 대한 측정데이터를 입력받는다(S730). 측정데이터는 관리서버로 전송되고(S735), 관리서버는 외부 서버로부터 수신한 기준데이터를(S740) 이용하여 측 정데이터를 보정한다(S745). 보정된 데이터는 원격측정장치로 전송되어(S750) 출력장치로 출력된다(S755). 관리서버는 보정데이터를 저장장치에 저장하여(S757), 사용자단말로부터 요청이 있는 경우(S790), 요청된 데이 터를 검색하여(S795) 사용자단말로 해당 데이터를 전송할 수 있다(S797). 관리서버는 필터상태를 확인하여(S760), 필터상태에 이상이 있다고 판단하면 사용자단말로 필터상태에 대한 알 림을 전송한다(S765). 관리서버는 원격측정장치로 필터상태에 대하여 전송할 수 있고(S770), 원격측정장치는 필터상태를 출력장치를 이용하여 출력할 수 있다(S775). 작업종료 신호가 원격측정장치로 입력되면(S780), 원격측정장치는 송풍팬을 정지시키고, 배출구를 폐쇄한다 (S785). 도 8은 본 발명의 일 실시예에 따른 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템에서 원격측정 장치가 동작하는 방법을 나타내는 순서도이다. 원격측정장치는 기동하면 우선 장치를 초기화하고 정상동작을 하는지 확인한다(S810). 사용자로부터 작업 개시 신호를 입력받으면, 굴뚝의 배출구 덮개를 개방한다(S820). 그리고 송풍팬의 가동을 시작하고 전력량 측정데이터를 수신한다(S825). 원격측정장치는 센서모듈로부터 대기오염물질에 대한 측정데이터를 수신한다(S830). 수신된 대기오염 물질 및 전력량에 대한 측정데이터를 관리서버로 송신하면(S840), 관리서버에서 측정데이터를 보정한 보정 데이터를 송신하고, 원격측정장치가 보정데이터를 수신한다(S850). 원격측정장치는 보정데이터를 출력장치(29 0)로 보내고, 출력장치는 사용자에게 보정데이터를 보여준다(S860). 원격측정장치는 관리서버로부터 전력량 데이터 또는 필터상태에 대하여 수신하는 경우(S870), 필터상태를 출력장치로 보내서 출력한다(S880). 원격측정장치가 사용자로부터 작업종료 신호를 입력받는 경우(S890), 송풍팬의 가동을 정지하고 (S890), 굴뚝의 배출구 덮개를 폐쇄한다(S895). 도 9는 본 발명의 일 실시예에 따른 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템에서 관리서버 가 동작하는 방법을 나타내는 순서도이다. 관리서버는 배기가스 중 대기오염물질의 배출기준을 설정하고(S910), 원격측정장치로부터 대기오염물 질 농도, 전력량 등의 측정데이터를 수신한다(S920). 관리서버는 외부서버(미도시)로부터 보정에 활용하는 기준데이터를 수신하고(S930), 보정이 필요한 경우 (S940) 측정데이터를 보정하여 보정데이터를 구하고(S945), 보정데이터를 저장장치에 저장하고(S950), 원 격측정장치로 보정데이터를 송신한다(S960). 관리서버는 필터상태를 확인하여(S970), 필터상태가 이상인 것으로 판단한 경우 원격측정장치로 필터상태 에 대하여 송신할 수 있고, 사용자단말로 필터상태에 대하여 알림을 송신할 수 있다(S975). 사용자단말로부터 데이터 요청이 있는 경우(S980), 데이터를 검색하여 사용자단말로 송신할 수 있다(S985). 관리서버가 보정데이터를 구하기 위해 먼저 기준데이터가 측정데이터를 보정할 만한 수준지 파악한다 (S940). 예를 들어, 매 1분 간격으로 데이터를 측정하고, 최근 측정데이터(R1)가 10분전에 측정한 측정데이터 (R10)보다 30% 이상의 변화가 있거나, 외부 서버로부터 입수한 미세먼지(PM10) 기준데이터가 80 μg/m3 이상인 경우, 외부 미세먼지에 의한 영향을 보정할 필요가 있는 것으로 판단한다. 관리서버가 보정데이터를 구하는(S945) 방법의 예로는, 최근 측정데이터(R1)와 10분전 측정데이터(R10)의 시간당 상승률(기울기)인 (R10 - R1) / 10 을 이용하여, T분 경과된 이후의 보정데이터(VR)를 VR = R1 + (R10- R1) / 10 * T 식으로 구할 수 있다. 외부서버로부터 수신한 미세먼지(PM10) 기준데이터가 80 μg/m3 이하가 되 는 경우 보정을 중지한다. 필터상태를 확인하기(S970) 위해서, 보정데이터를 법적으로 허용되는 허용기준치와 비교한다. 법적인 허용기준 치는 미세먼지 50 ppm 과, VOC 200 ppm 이며, 이를 초과하는 경우에 관리서버는 사용자단말로 필터교체 알람을 송신한다. 필터상태를 확인하기(S970) 위해서, 전력량측정계를 이용하여 필터교환 이후 주간 누적전력량을 측정할 수 있다. 미세먼지와 VOC가 법적기준치 이내인 경우라도, 주간 누적전력량이 임계전력량보다 커지는 경우에 사용자 단말로 미리 필터를 교체하도록 알림을 전송할 수 있다. 이때 임계전력량은 필터교체후 최초 1주간 전력량의 1.8배로 설정할 수 있다. 이하에서 본 발명의 특징에 따른 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템의 동작에 대하여 상세히 설명하면 다음과 같다. 도 10은 본 발명의 실시예에 따른 자동차 도장작업장의 인공지능 대기오염물질 배출관리 방법을 나타낸 흐름도 이다. 도 10을 참조하면, 먼저 사용자 또는 점검자 등의 담당자는 필터 또는 기타 부품의 이상시에 서버에 접속 하여 이상을 신고할 수 있다. 그러면 서버의 정보제공부는 담당자 정보 DB를 참조하여 상기 사용자 단말기 또는 점검자 단말기로부터 제품 또는 필터 또는 기타부품의 이상 정보를 수신한다(S110). 다음, 서버의 비용 예측부는 상기 필터를 포함한 부품의 이상시에 상기 부품의 수명정보 및 상기 부 품의 가격정보를 참조하여 기간별 소요비용 예상 정보를 계산하여 상기 사용자 단말기 또는 점검자 단말기 에 제공하는 단계(S320)를 수행하고 계산된 기간별 소요비용 예상 정보를 저장장치에 저장한다. 예를 들어, 서버의 비용 예측부는 필터를 포함한 특정 부품의 이상시에 교체를 할 경우 4년 사용이 예상되고, 교체비용은 4만원이라면, 1년~4년은 교체비용 4만원,5~8년은 교체비용 8만원, 9년 이상은 교체비용 12만원으로 계산하며, 이와 같이 교체시의 기간별 소요비용 예상 정보를 계산한다. 한편, 서버의 비용 예측부는 특정 부품의 이상시에 수리를 할 경우 2년 사용이 예상되고, 교체비용은 3만원이라면, 1년~2년은 수리비용 3만원, 3~4년은 수리비용 6만원, 5~6은 수리비용 9만원, 7~8년은 수리비용 12 만원으로 계산하며, 이와 같이 수리시의 기간별 소요비용 예상 정보를 계산한다. 따라서 사용자 또는 점검자를 이를 참조하여 교체 또는 수리를 결정할 수 있다. 한편, 제품의 교체시기가 정해진 경우 이를 추가로 반영하여 안내할 수 있다. 즉, 제품교체시기가 1년 이내라 면 가급적 수리가 용이할 수 있다. 여기서 필터는 교체 또는 리페어에서 리페어는 필터청소비용으로 계산할 수 있다. 그리고 부품은 센서류나, 도 6의 굴뚝 관련 부품등 다양한 부품이 해당된다. 또한, 서버의 고장 예측부는 상기 부품의 수명 및 고장 이력을 참조하여 부품의 고장 시기를 계산하 여 상기 사용자 단말기 또는 점검자 단말기에 제공하는 단계(S330)를 수행하고, 계산된 부품의 고장 시기 를 저장장치에 저장한다. 예를 들어 특정 제품의 A부품이 평균적으로 1년만에 고장난 경우, 해당 부품의 고장시기를 사용일로부터 1년후 로 한다. 한편, 해당 부품의 고장정보가 없는 경우에는 제조사에서 제공한 유효수명을 고장 또는 교체시기로 제공한다. 필요에 따라 상기 부품의 수명정보는 제조사에서 제공한 수명정보를 이용할 수 있다. 이와 같이 서버의 고장 예측부는 실제 환경에서 취득한 누적된 고장정보를 이용하여 고장시기를 예측 함으로써 더욱더 고장시기 예측의 정확도를 높일 수 있다. 다음, 서버의 정보제공부는 상기 부품의 고장이 예상되는 시기가 다가오면 미리 사용자 단말기 또는 점검자 단말기로 알람을 하는 단계(S340)를 수행한다. 예를 들어 특정 제품의 A부품이 평균적으로 1년만에 고장난 경우, 11개월이 되면, 서버의 정보제공부(11 3)는 해당 제품을 사용하는 사용자 및 점검자에게 해당 제품의 고장이 예상되는 날짜를 미리 한달전쯤에 알려준 다. 그리고 정보제공부는 사용자 단말기 또는 점검자 단말기의 요청에 따라 제품정보, 제품의 부품정보, 부품의 가격정보, 부품의 수명정보, 부품의 유지관리정보 및 제품의 교체예정 정보를 제공하는 단계(S150)를 수 행한다. 즉, 저장장치를 참조하여 사용자 또는 점검자가 원하는 정보를 상기 사용자 단말기 또는 점 검자 단말기로 제공한다. 이에 따라 사용자 또는 점검자는 필요시에 제품정보, 제품의 부품정보, 부품의 가격정보, 부품의 수명정보, 부 품의 유지관리정보 및 제품의 교체예정 정보를 조회 가능하다. 한편, 필요에 따라 점검자가 제품 또는 부품을 점검할 때, 상기 점검자 단말기는 정보제공부로부터 유지관 리정보중 제품 및 부품 매뉴얼 정보를 수신하여 표시하여 점검자가 부품 점검 또는 수리 또는 교체 시에 편리함 을 제공한다. 또한, 서버 정보제공부는 상기 사용자 단말기로부터 제품의 이상이 접수되면, 해당 제품의 유지 보수를 담당하는 점검자의 점검자 단말기로 출동을 알리는 메시지를 송신한다. 또한, 서버는 제품의 각 부품의 이상 상태를 판단하여 조치하며, 잔존 수명을 예측하고, 교체 또는 수리를 권고하고, 제한된 자원으로 유지보수 활동 및 일정 계획까지 생성할 수 있다. 예를 들어, 서버는 유지 보수 활동 인원이 한명인 경우, 한명이 다른 필수 업무를 제외하고 유지 보수 활 동에 투입할 수 있는 시간이 하루에 2시간 이라면, 이에 대응하여 일정 계획을 생성한다. 즉, 12월 1일에서 5일 까지 5개의 부품을 점검해야 한다면 매일 한개씩 점검을 하도록 일정계획을 생성한다. 상기 과정에서 인공지능 제어부는 필요에 따라 도 7 내지 도 10의 제어를 모두 할 수도 있고, 도 10의 제 어만 수행할 수도 있다. 이와 같이, 본 발명의 실시예에서는, 제품의 각 부품의 이상 상태를 판단하여 조치하며, 잔존 수명을 예측하고, 교체 또는 수리를 권고하고, 제한된 자원으로 유지보수 활동 및 일정 계획까지 생성할 수 있다. 또한, 본 발명의 실시예에서는, 제품의 각 부품의 수리 또는 교체시의 기간별 소요비용을 산출하여 제공하고, 제품 교체 시기를 반영하여 수리 또는 교체를 추천하며, 부품의 고장시기를 학습하여 예측하고, 예측된 고장시 기 전에 미리 사용자 또는 점검자에게 알람할 수 있다. 이상에서 설명한 본 발명의 실시예는 장치 및 방법을 통해서만 구현이 되는 것은 아니며, 본 발명의 실시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있으며, 이러한 구현은 앞서 설명한 실시예의 기재로부터 본 발명이 속하는 기술분야의 전문가라면 쉽게 구현할 수 있는 것이다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10\n【요약】본 발명에서는 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템 및 방법이 개시된다. 자동차 도장작 업장의 인공지능 대기오염물질 배출관리 시스템은, 센서모듈, 전력량측정계, 원격측정장치, 관리서버, 사용자단 말을 포함하고, 상기 관리서버는, 상기 측정데이터의 보정에 사용하는 기준데이터를 수신하는 외부서버통신부; (뒷면에 계속)\n\n【청구항 1】\n센서모듈, 전력량측정계, 원격측정장치, 관리서버, 사용자단말을 포함하고,상기 센서모듈은 상기 굴뚝의 내부에 설치되고, 상기 굴뚝을 통해 배출되는 가스의 미세먼지를 측정하는 미세먼지센서; 및 상기 굴뚝을 통해 배출되는 가스의 휘발성 유기 화합물(VOC)의 양을 측정하는 VOC센서;를 포함하고,상기 관리서버는, 상기 측정데이터의 보정에 사용하는 기준데이터를 수신하는 외부서버통신부; 상기 기준데이터를 이용하여 상기 측정데이터로부터 보정데이터를 구하는 제어부; 상기 제어부의 제어에 따라 데이터를 저장장치에 기록하는 기록관리부; 상기 사용자단말로 상기 데이터와 필터정보를 송신하는 단말통신부; 및 상기 원격측정장치로부터 상기 측정데이터를 수신하는 측정장치통신부;를 포함하는 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템.\n【청구항 2】\n제1항에 있어서, 상기 데이터를 저장장치에는 제품정보, 제품을 구성하는 부품정보, 부품의 수명정보, 부품의 가격정보, 유지관리 정보, 기간별 소요비용 예상 정보를 저장하고,상기 인공지능 제어부는, 상기 데이터 저장장치를 참조하여 상기 부품의 이상시에 상기 부품의 수명정보 및 상기 부품의 가격정보를 참조하여 기간별 소요비용 예상 정보를 계산하여 제공하는 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템.\n【청구항 3】\n제2항에 있어서, 상기 인공지능 제어부는,상기 데이터 저장장치를 참조하여 상기 부품의 이상시에 상기 부품의 수명정보 및 상기 부품의 가격정보를 참조하여 기간별 소요비용 예상 정보를 계산하는 비용 예측부(431);상기 데이터 저장장치의 상기 부품의 수명 및 고장 이력을 참조하여 부품의 고장 시기를 계산하는 고장 예측부(432);상기 사용자 단말기로부터 제품의 이상이 접수되면, 점검자에게 출동을 알리는 메시지를 송신하고, 상기 부품의고장이 예상되는 시기가 다가오면 미리 사용자 단말기로 알람을 하는 정보제공부(433)를 포함하는 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템.\n【청구항 4】\n적어도 하나의 제품의 사용자 단말기 또는 점검자 단말기와 통신하며, 상기 제품의 이상시에 수리 또는 교체되는 부품에 대하여 유지 관리를 하는, 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템의 자동차 도장작업장의 인공지능 대기오염물질 배출관리 방법으로서,상기 사용자 단말기로부터 제품 또는 부품의 이상 정보를 수신하는 단계;상기 부품의 이상시에 상기 부품의 수명정보 및 상기 부품의 가격정보를 참조하여 기간별 소요비용 예상 정보를공개특허 10-2024-0146850-3-계산하여 상기 사용자 단말기 또는 점검자 단말기에 제공하는 단계;상기 부품의 수명 및 고장 이력을 참조하여 부품의 고장 시기를 계산하여 상기 사용자 단말기 또는 점검자 단말기에 제공하는 단계;상기 부품의 고장이 예상되는 시기가 다가오면 미리 사용자 단말기 또는 점검자 단말기로 알람을 하는 단계;사용자 단말기 또는 점검자 단말기의 요청에 따라 제품정보, 제품의 부품정보, 부품의 가격정보, 부품의 수명정보, 부품의 유지관리정보 및 제품의 교체예정 정보를 제공하는 단계를 포함하는 자동차 도장작업장의 인공지능대기오염물질 배출관리 방법.\n【청구항 5】\n제4항에 있어서, 상기 점검자 단말기는 유지관리정보중 제품 및 부품 매뉴얼 정보를 수신하여 표시하여 점검자가 부품 점검 또는수리 또는 교체 시에 편리함을 제공하는 자동차 도장작업장의 인공지능 대기오염물질 배출관리 시스템."}
{"context": "", "input": "【기술명】\n인공지능을 이용한 시퀀스 기반의 키오스크 작동 방법 시스템\n\n【기술 설명】\n본 발명은 인공지능(AI)을 활용한 시퀀스 기반의 키오스크 작동 방법에 관한 기술로, 사용자가 키오스크를 보다 효율적으로 이용할 수 있도록 지원합니다. 이 기술은 키오스크 장치가 사용자 인터랙션과 관련된 데이터를 수집하여, 이를 시퀀스 형태로 변환하고, 특정한 주문 절차를 통해 사용자의 경험을 최적화합니다. 인공지능 예측 모델은 수집된 데이터를 기반으로 학습하여, 각 주문 단계에서의 최적의 경로를 제시함으로써, 사용자가 직면할 수 있는 혼란을 최소화하고, 보다 원활한 주문 과정을 제공하는 것을 목표로 합니다.\n\n【해결 문제】\n현재 많은 사용자들이 키오스크를 이용할 때, 복잡한 절차로 인해 불편함을 겪고 있습니다. 본 발명은 이러한 문제를 해결하기 위해, 키오스크 사용성에 관련된 데이터를 수집하고 이를 기반으로 사용자 맞춤형 추천 단계를 제공함으로써, 불필요한 단계를 줄이고 주문 시간을 단축하는 데 중점을 두고 있습니다. 이는 사용자에게 보다 직관적이고 효율적인 주문 경험을 제공하며, 키오스크의 활용도를 극대화하는 필수적인 기술입니다.\n\n【기술 차별성】\n본 발명은 기존의 키오스크 작동 방식과 비교하여, 인공지능 기반의 데이터 분석 및 예측 기능을 통합함으로써 혁신성을 더하고 있습니다. 기존 기술들은 주로 고정된 절차를 따르거나 단순한 사용자 인터페이스를 제공하는 데 그쳤으나, 본 발명은 실시간으로 사용자 데이터를 수집하고 이를 바탕으로 최적의 주문 경로를 제시하는 점에서 차별성을 지닙니다. 이러한 접근법은 키오스크 사용자의 만족도를 높이는 동시에, 운영자의 효율성을 향상시키는 기회를 창출합니다.\n\n【활용 분야】\n본 발명은 주로 소매업, 음식 서비스, 공공 기관 및 자판기와 같은 다양한 산업 분야에서 활용될 수 있다. 이러한 분야에서는 고객과의 상호작용을 통해 주문 및 결제를 효율적으로 처리해야 하며, 키오스크의 사용성 개선은 고객 만족도와 운영 효율성을 동시에 증대시킬 수 있다. 특히 패스트푸드점, 카페, 대형마트 및 공항과 같은 장소에서 고객의 대기 시간을 줄이고, 사용자 경험을 개인화하여 재방문율을 높이는 데 기여할 수 있다.\n\n【구성 요소 및 기능】\n1. **사용자 감지 데이터 수집 모듈**: 이 모듈은 고객의 행동 패턴 및 상호작용 데이터를 실시간으로 수집하여, 키오스크의 사용성을 분석하는 데 필요한 기초 정보를 제공합니다. 이를 통해 고객의 선호도와 행동을 이해하고, 사용자 맞춤형 추천을 위한 기초 자료로 활용됩니다.  \n2. **주문 절차 시퀀스 변환 모듈**: 이 모듈은 수집된 주문 절차 데이터를 노드와 흐름 링크 형태로 변환하여, 사용자의 주문 과정을 시각적으로 표현합니다. 이를 통해 고객은 각 단계에서의 진행 상황을 명확히 인지할 수 있으며, 다음 단계로의 이동을 보다 직관적으로 이해할 수 있습니다.  \n3. **하이브리드 LSTM 모델**: 이 인공지능 모델은 사용자 감지 데이터와 주문 절차 데이터에 기초하여 머신러닝 학습을 수행하고, 고객의 주문 진행 상황에 대한 예측 및 추천을 생성합니다. 이 모델은 고객의 의도를 파악하고 최적의 다음 단계를 추천함으로써, 키오스크 사용자의 경험을 향상시키는 핵심 기능을 수행합니다.\n\n【구현 방식 예】\n본 발명의 구현은 총 여섯 단계로 구성됩니다. 첫 번째 단계에서는 키오스크 장치가 사용자와의 상호작용을 통해 발생하는 데이터를 수집합니다. 두 번째 단계에서는 수집된 주문 절차 데이터를 노드와 흐름 링크로 변환하여 시퀀스를 구성합니다. 세 번째 단계에서는 사용자 감지 데이터와 주문 절차 데이터를 기반으로 노드 특성 정보를 생성하여 노드 특성 테이블을 구축합니다. 네 번째 단계에서는 이 데이터를 하이브리드 LSTM 모델에 입력하여 머신러닝 학습을 수행합니다. 다섯 번째 단계에서는 해당 모델을 통해 고객의 다음 주문 단계를 예측하고, 마지막으로 여섯 번째 단계에서는 이 예측된 정보를 화면에 시각적으로 표시하여 고객이 보다 쉽게 다음 단계를 진행할 수 있도록 지원합니다. 이러한 단계적인 접근 방식은 키오스크의 사용자 경험을 혁신적으로 개선하는 데 기여합니다.", "output": "【발명의 명칭】\n인공지능을 이용한 시퀀스 기반의 키오스크 작동 방법\n【기술분야】\n본 발명은 일반적으로 인공지능을 이용하여 키오스크 작동 과정을 시퀀스 기반으로 판단함으로써 키오스크의 사 용성을 개선하는 기술에 관한 것이다. 특히, 본 발명은 키오스크 장치가 키오스크 사용성에 관련된 데이터를 수집하여 시퀀스 형태로 변환하고 키오스 크 사용 절차를 단축하기 위한 인공지능 예측 모델을 그 수집한 키오스크 사용성 데이터로 학습하고 그 결과에 의해 키오스크의 절차 단축 방안을 도출하여 키오스크 사용성을 개선하는 인공지능을 이용한 시퀀스 기반의 키 오스크 작동 기술에 관한 것이다.\n【배경기술】\n서비스 방법\" 발명의 내용\n【해결하려는 과제】\n본 발명의 목적은 일반적으로 인공지능을 이용하여 키오스크 작동 과정을 시퀀스 기반으로 판단함으로써 키오스 크의 사용성을 개선하는 기술을 제공하는 것이다. 특히, 본 발명의 목적은 키오스크 장치가 키오스크 사용성에 관련된 데이터를 수집하여 시퀀스 형태로 변환하고 키오스크 사용 절차를 단축하기 위한 인공지능 예측 모델을 그 수집한 키오스크 사용성 데이터로 학습하고 그 결과에 의해 키오스크의 절차 단축 방안을 도출하여 키오스크 사용성을 개선하는 인공지능을 이용한 시퀀스 기 반의 키오스크 작동 기술을 제공하는 것이다. 본 발명의 해결 과제는 이 사항에 제한되지 않으며 본 명세서의 기재로부터 다른 해결 과제가 이해될 수 있다.\n【과제의 해결 수단】\n상기의 목적을 달성하기 위하여 본 발명은 키오스크 사용성 개선을 위하여 인공지능 응용 소프트웨어가 설치된 컴퓨터 하드웨어가 수행하는 인공지능을 이용한 시퀀스 기반의 키오스크 작동 방법을 제시한다. 본 발명에 따른 인공지능을 이용한 시퀀스 기반의 키오스크 작동 방법은, 키오스크 장치가 사용자 인터랙션과 관련하여 발생되는 사용자 감지 데이터와 주문 절차 데이터를 다수 수집하는 제 1 단계; 주문 절차 데이터를 노 드와 흐름 링크를 구비한 주문 절차 시퀀스로 변환하는 제 2 단계; 사용자 감지 데이터와 주문 절차 데이터에 기초하여 주문 절차 시퀀스의 각 노드에서의 특성 정보를 요소 값으로 채움으로써 노드 특성 테이블을 생성하는 제 3 단계; 주문 절차 데이터와 노드 특성 테이블을 입력으로 제공하여 하이브리드 LSTM 모델에 대한 머신러닝 학습을 수행하는 제 4 단계; 키오스크 장치에 대한 사용자 주문 과정을 하이브리드 LSTM 모델에 입력하여 해당 사용자의 주문 과정을 위한 다음 추천 단계를 획득하는 제 5 단계; 다음 추천 단계를 키오스크 장치 상에 화면 표시하는 제 6 단계;를 포함하여 구성된다. 본 발명에서 주문 절차 데이터는 주문 시작, 메인 메뉴 주문, 단품메뉴 또는 세트메뉴 선택, 디저트 주문, 음료 주문, 매장식사 또는 포장주문 선택, 결제수단 선택, 주문 종료의 적어도 하나이상을 포함할 수 있다. 또한, 사 용자 감지 데이터는 키오스크 사용자에 대한 성별, 연령대, 주문시 감정 정보의 적어도 하나이상을 포함할 수 있다. 본 발명에서 제 2 단계는, 주문 절차 데이터의 각 절차 항목을 노드로 설정하는 단계; 주문 절차 데이터의 주문 과정 진행을 노드 간을 연결하는 흐름 링크로 설정하는 단계;를 포함하여 구성될 수 있다. 본 발명에서 제 5 단계는, 키오스크 장치에 대한 특정 사용자의 주문 과정을 모니터링하는 단계; 특정 사용자의 주문 과정에 대하여 주문 절차 데이터와 노드 특성 테이블을 획득하는 단계; 특정 사용자의 주문 과정에 대한 주문 절차 데이터와 노드 특성 테이블을 하이브리드 LSTM 모델에 입력하는 단계; 하이브리드 LSTM 모델의 출력 으로부터 해당 사용자의 주문 과정을 위한 다음 추천 단계를 획득하는 단계;를 포함하여 구성될 수 있다. 한편, 본 발명에 따른 컴퓨터프로그램은 컴퓨터에 이상과 같은 인공지능을 이용한 시퀀스 기반의 키오스크 작동 방법을 실행시키기 위하여 비휘발성 저장매체에 저장된 것이다.\n【발명의 효과】\n본 발명에 따르면 키오스크 장치의 사용성을 개선할 수 있는 장점이 있다. 특히, 본 발명에 따르면 키오스크 장치 내에서 자동적으로 사용자가 키오스크를 사용하면서 해당 단계로의 이동 에 대한 추천 정보를 제공해 줄 수 있어 키오스크 사용자는 불필요한 단계를 거치지 않고 다음 주문 단계로 이 동할 수 있는 장점이 있다.\n【발명을실시하기위한구체적인내용】\n이하에서는 도면을 참조하여 본 발명을 상세하게 설명한다. 본 발명을 설명함에 있어서 종래기술과 중복되는 부분에 대해서는 자세한 설명을 생략할 수 있다. [도 1]은 본 발명에 따른 인공지능을 이용한 시퀀스 기반의 키오스크 작동 프로세스의 순서도이다. 본 발명에서는 키오스크 장치가 사용자와의 인터랙션 과정을 통해 키오스크 사용성에 관련된 데이터(이하, '키 오스크 사용성 데이터'라 함)를 스스로 수집하고, 키오스크 사용 절차를 단축시키기 위한 절차축소 예측 모델을 키오스크 사용성 데이터(수집 데이터)를 이용하여 인공지능 학습시킨다. 이때, LSTM 기반 딥러닝 모델을 활용할 수 있다. 그리고 나서, 그 인공지능 학습이 이루어진 절차축소 예측 모델을 활용하여 키오스크의 주문 절차를 단축하는 방안을 스스로 도출한다. [도 1]은 키오스크 사용성 데이터(사용자 감지 데이터, 주문 절차 데이터)를 수집하여 이를 시퀀스 형태의 데이 터로 변환하고 키오스크 사용 단계 사이의 연결성을 추론하여 다음의 키오스크 사용 절차를 추천해주는 시퀀스 기반의 인공지능 모델을 학습 후 이를 활용하여 키오스크를 사용하여 고객 주문 시 메인 화면 옆에 다음 추천 단계를 출력하는 과정을 나타내었다. 이하에서는 [도 1]을 참조하여 본 발명에 따른 인공지능을 이용한 시퀀스 기반의 키오스크 작동 프로세스를 단 계 별로 살펴본다. 본 발명에 따른 키오스크 작동 프로세스는 인공지능 응용 소프트웨어가 설치된 컴퓨터 하드 웨어, 예컨대 인공지능 기반의 키오스크 작동 프로그램이 설치된 키오스크 장치가 수행한다. 단계 (S110) : 키오스크 장치가 사용자 인터랙션과 관련하여 발생되는 사용자 감지 데이터와 주문 절차 데이터 를 수집한다. 본 명세서에서는 주문 절차 데이터와 사용자 감지 데이터를 총칭하여 '키오스크 사용성 데이터'라 고 부른다. 키오스크 장치는 키오스크 주문자로부터 주문(order)을 입력받고 주문을 처리하는 과정에서 이들 정 보를 획득한다. 주문 절차 데이터는 키오스크가 각 사용자로부터 주문을 입력받는 일련의 과정을 나타내는 정보이다. 예를 들어 주문 시작, 메인 메뉴 주문, 단품메뉴 또는 세트메뉴 선택, 디저트 주문, 음료 주문, 매장식사 또는 포장주문 선택, 결제수단 선택, 주문 종료의 적어도 하나이상을 포함할 수 있다. 사용자 감지 데이터는 키오스크가 사용자에 대해 획득하는 데이터이다. 키오스크 장치에 설치된 카메라 등을 이 용하여 키오스크 사용자의 얼굴을 촬영한 후에 이미지 분석을 통해 사용자 감지 데이터를 얻을 수 있다. 키오스 크 장치에 설치된 카메라로 사용자의 얼굴을 촬영하면 사용자에 대해 많은 정보를 추출할 수 있는데, 사용자의 성별이나 연령대는 기본적으로 식별할 수 있으며, 어펙티바(Affectiva)의 감정인식 소프트웨어를 통해 주문 당 시의 사용자 감정도 식별할 수 있다. 예를 들어 키오스크 사용자의 성별, 연령대, 주문시 감정의 적어도 하나이 상을 포함할 수 있다. 키오스크 사용성 데이터를 효과적으로 수집할 수 있도록 키오스크 장치는 멀티모달 장치(multi-modal device)인 것이 바람직하다. '멀티모달(multi-modal)'은 사람과 기계 사이의 커뮤니케이션을 위해 여러가지 형태와 의미로 컴퓨터와 대화하는 휴먼 인터페이스 환경을 말한다. 예를 들어, 멀티모달 키오스크는 카메라, 음성, 터치 디스 플레이와 같은 복수의 장치를 사용하여 키오스크와 사람 사이의 커뮤니케이션을 수행하고, 이를 통해 키오스크 사용성 데이터(사용자 감지 데이터, 주문 절차 데이터)를 수집한다. 단계 (S120) : 다음으로, 주문 절차 데이터를 시퀀스 형태로 변환한다. 이를 본 명세서에서는 편의상 '주문 절 차 시퀀스'라고 부르는데, 주문 절차 시퀀스는 노드(데이터 포인트)와 흐름 링크를 구비한다. [도 2]는 본 발명에서 키오스크 장치의 주문 절차 시퀀스의 개념도이다. 주문 절차 데이터에서 각 절차 항목(주 문 시작, 메인 메뉴 주문, 단품메뉴 또는 세트메뉴 선택, 디저트 주문, 음료 주문, 매장식사 또는 포장주문 선 택, 결제수단 선택, 주문 종료)은 노드(데이터 포인트)로 설정된다. 그리고, 주문 과정의 진행은 이들 노드 간 을 연결하는 흐름 링크로 설정된다. 키오스크 사용자마다 주문 절차는 조금씩 상이할 수 있다. [도 2]를 참조하면, 일련의 절차를 모두 거쳐서 진행 할 수도 있지만, 사용자에 따라서는 단품메뉴 또는 세트메뉴를 선택한 후에 디저트 주문을 건너뛰고 음료 주문으로 진행하거나 혹은 아예 매장식사 또는 포장주문 선택으로 진행할 수도 있다. 또한, 어떤 사용자는 음료 주 문을 건너뛰고 주문 확인으로 진행할 수도 있고 혹은 디저트 주문과 음료 주문을 모두 건너뛰고 주문 확인으로 진행할 수도 있다. 단계 (S120)에서는 사용자의 주문 과정에서 얻은 각각의 주문 절차 데이터를 주문 절차 시퀀스로 변환한다. [도 3]은 사용자의 주문 절차를 시퀀스 형태로 변환한 3가지 예시도이다. 이처럼 사용자마다 주문 절차의 패턴이 상이한데, 인공지능 기반으로 현재의 사용자가 향후 진행할 주문 절차 과정을 미리 예측하고 그에 대응하여 불필요한 절차를 생략해준다면 사용성이 개선될 것이다. 단계 (S130) : 다음으로, 사용자 감지 데이터와 주문 절차 데이터로부터 주문 절차 시퀀스의 노드 특성 테이블 을 생성한다. 이때, 노드 특성 테이블의 구조(행과 열 구조)는 미리 정해져 있으며, 주문 절차 시퀀스의 각 노 드에서의 특성 정보가 노드 특성 테이블의 요소 값으로 입력된다. [도 2]를 참조하면, 주문 절차 시퀀스의 첫번째 노드, 즉 '주문 시작' 노드에는 사용자 감지 데이터가 노드 특 성 테이블에 입력된다. 그리고, 주문 절차 시퀀스의 두번째 이후의 노드, 즉 '메인 메뉴 주문' 내지 '주문 종료' 노드에서는 해당 절차 에서 생성되는 주문 절차 데이터가 노드 특성 테이블 형태로 변환된다. 예를 들어, '메인 메뉴 주문' 노드의 경 우에는 메인 메뉴의 종류, 선택 버튼의 종류, 메뉴 선택시의 주문자 행동 등이 노드 특성 테이블에 입력된다. 이때, 각 노드의 특성 구조는 모두 같아야 하기에 주문 절차 데이터에서 발생하는 특성을 각 열로 설정하고 해 당 열에 해당하는 값들을 채워서 노드 특성 테이블을 완성한다. 이상의 단계(S120, S130)는 사용자 감지 데이터와 주문 절차 데이터로부터 인공지능 신경망 학습을 위한 훈련 데이터를 생성하는 과정이다. 단계 (S140) : 다음으로, 주문 절차 데이터와 노드 특성 테이블을 입력으로 제공하여 하이브리드 LSTM 모델에 대한 머신러닝 학습을 수행한다. 이 과정에서는 키오스크 장치가 수집한 키오스크 사용성 데이터를 이용하여 절차축소 예측 모델을 학슴한다. 인 공지능 신경망 모델 학습 방법은 다양하게 존재하는데, 본 발명에서는 LSTM 기반의 딥러닝 방식을 사용하는 것 이 바람직하다. LSTM(Long Short-Term Memory)은 RNN(순환신경망, Recurrent Neural Network)이 가지고 있는 장기 의존성 문제 (long term dependency)를 해결하기 위해 1997년 Hochreiter & Schmidhuber에 의해 제안된 신경망 모델 이다. LTSM은 학습해야하는 정보의 맥락이 긴 경우에 양호한 학습 능력을 나타낸다. [도 4]는 일반적인 RNN 모델과 LSTM 신경망 모델의 개념도이다. [도 4] (a)는 표준 RNN 모델의 구성을 나타내고, [도 4] (b)는 LSTM 신경망 모델의 구성을 나타낸다. [도 4] (c)는 이들 신경망 모델에 사용된 기호를 나타낸다. 이러한 LSTM 방식은 과거와 현재의 데이터로 미래에 등장할 값이나 카테고리를 예측할 수 있는 특성을 갖는다. 하지만 LSTM 구조만으로는 멀티모달 키오스크에서 수집하는 다양한 정보를 신경망 모델에 학습시키기에 부족하 다는 한계가 있다. 그에 따라, 본 발명에서는 각각의 주문 절차에서 발생하는 데이터들을 동일 모양의 테이블로 변환한 데이터, 즉 노드 특성 테이블을 추가 입력으로 활용한다. 다시말해, 본 발명의 인공지능 신경망 학습 모델에서는 주문 절차 데이터뿐만 아니라, 주문 절차 시퀀스의 각 노드(주문 단계)에 대한 노드 특성 테이블 두 가지를 입력으로 사용하는 하이브리드 LSTM 모델을 사용한다. [도 5]는 본 발명에서 하이브리드 LSTM 기반의 키오스크 데이터 분석 모델의 구조도이다. 본 발명에서는 주문 절차 데이터와 노드 특성 테이블의 두 가지 데이터를 모델 입력으로 활용하는 하이브리드 LSTM 모델을 사용함으 로써 일반적인 LSTM 모델과는 달리 노드 특성 테이블에 대한 학습도 동시에 진행한다. 이들 두 가지 데이터(주문 절차 데이터, 노드 특성 테이블)는 각각의 LSTM 레이어를 거쳐 데이터가 임베딩된다. 그리고, 각각의 LSTM 레이어를 거친 결과를 취합하는 연결 레이어(concatenate layer)를 통해 두 가지 정보의 학습 결과들이 융합된다. 그 융합된 결과를 활용하여 최종 출력 전에 활용되는 다중 퍼셉트론 레이어(Multi- Layer Perceptron, MLP)를 거쳐 최종 출력인 현재 사용자(주문자)에게 맞는 다음의 주문 절차 단계를 예측한다. 여기서 MLP 레이어는 완전 연결 레이어라고도 불린다. 단계 (S150, S160) : 다음으로, 키오스크 장치에 대한 사용자 주문 과정을 하이브리드 LSTM 모델에 입력하여 해 당 사용자의 주문 과정을 위한 다음 추천 단계를 획득한다. [도 5]의 하이브리드 LSTM 모델에 의하면 사용자(주문자)가 특정의 주문 단계에 있을 때에 그 주문 단계 이후에 나타날 노드의 결과를 예측할 수 있게 된다. 다른 말로 표현하면, 사용자의 현재까지 주문 절차를 알고 있을 때 그 사용자에게 다음에 나타날 주문 절차를 예측할 수 있다는 것을 의미한다. 그에 따라, 키오스크 장치에 어느 사용자가 주문을 입력하고 있을 때, 하이브리드 LSTM 모델에 그 주문 과정의 주문 절차 데이터와 노드 특성 테이블을 입력하면, 하이브리드 LSTM 모델의 출력으로부터 해당 사용자의 주문 과정을 위한 다음 추천 단계를 얻을 수 있다. 키오스크 장치는 그 다음 추천 단계를 그 사용자에게 화면 표시함 으로써 사용자의 주문 절차를 단축시킬 수 있다. 한편, 본 발명은 컴퓨터가 읽을 수 있는 비휘발성 기록매체에 컴퓨터가 읽을 수 있는 코드의 형태로 구현되는 것이 가능하다. 이러한 비휘발성 기록매체로는 다양한 형태의 스토리지 장치가 존재하는데 예컨대 하드디스크, SSD, CD-ROM, NAS, 자기테이프, 웹디스크, 클라우드 디스크 등이 있다. 또한, 본 발명은 네트워크로 연결된 다 수의 스토리지 장치에 코드가 분산 저장되고 실행되는 형태로도 구현될 수 있다. 또한, 본 발명은 하드웨어와 결합되어 특정의 절차를 실행시키기 위하여 매체에 저장된 컴퓨터프로그램의 형태로 구현될 수도 있다.\n【요약】본 발명은 일반적으로 인공지능을 이용하여 키오스크 작동 과정을 시퀀스 기반으로 판단함으로써 키오스크의 사 용성을 개선하는 기술에 관한 것이다. 특히, 본 발명은 키오스크 장치가 키오스크 사용성에 관련된 데이터를 수 집하여 시퀀스 형태로 변환하고 키오스크 사용 절차를 단축하기 위한 인공지능 예측 모델을 그 수집한 키오스크 사용성 데이터로 학습하고 그 결과에 의해 키오스크의 절차 단축 방안을 도출하여 키오스크 사용성을 개선하는 인공지능을 이용한 시퀀스 기반의 키오스크 작동 기술에 관한 것이다. 본 발명에 따르면 키오스크 장치의 사용성 을 개선할 수 있는 장점이 있다. 특히, 본 발명에 따르면 키오스크 장치 내에서 자동적으로 사용자가 키오스크를 사용하면서 해당 단계로의 이동에 대한 추천 정보를 제공해 줄 수 있어 키오스크 사용자는 불필요한 단계를 거치 지 않고 다음 주문 단계로 이동할 수 있는 장점이 있다.\n\n【청구항 1】\n키오스크 사용성 개선을 위하여 인공지능 응용 소프트웨어가 설치된 컴퓨터 하드웨어가 수행하는 인공지능을 이용한 시퀀스 기반의 키오스크 작동 방법으로서, 키오스크 장치가 사용자 인터랙션과 관련하여 발생되는 사용자 감지 데이터와 주문 절차 데이터를 다수 수집하는 제 1 단계; 상기 주문 절차 데이터를 노드와 흐름 링크를 구비한 주문 절차 시퀀스로 변환하는 제 2 단계; 상기 사용자 감지 데이터와 상기 주문 절차 데이터에 기초하여 상기 주문 절차 시퀀스의 각 노드에서의 특성 정보를 요소 값으로 채움으로써 노드 특성 테이블을 생성하는 제 3 단계; 상기 주문 절차 데이터와 상기 노드 특성 테이블을 입력으로 제공하여 하이브리드 LSTM 모델에 대한 머신러닝학습을 수행하는 제 4 단계; 키오스크 장치에 대한 사용자 주문 과정을 상기 하이브리드 LSTM 모델에 입력하여 해당 사용자의 주문 과정을위한 다음 추천 단계를 획득하는 제 5 단계; 상기 다음 추천 단계를 키오스크 장치 상에 화면 표시하는 제 6 단계; 를 포함하여 구성되는 인공지능을 이용한 시퀀스 기반의 키오스크 작동 방법.\n【청구항 2】\n청구항 1에 있어서, 상기 주문 절차 데이터는 주문 시작, 메인 메뉴 주문, 단품메뉴 또는 세트메뉴 선택, 디저트 주문, 음료 주문,매장식사 또는 포장주문 선택, 결제수단 선택, 주문 종료의 적어도 하나이상을 포함하고, 상기 사용자 감지 데이터는 키오스크 사용자에 대한 성별, 연령대, 주문시 감정 정보의 적어도 하나이상을 포함하는 것을 특징으로 하는 인공지능을 이용한 시퀀스 기반의 키오스크 작동 방법.\n【청구항 3】\n청구항 1에 있어서, 상기 제 2 단계는, 상기 주문 절차 데이터의 각 절차 항목을 노드로 설정하는 단계; 상기 주문 절차 데이터의 주문 과정 진행을 상기 노드 간을 연결하는 흐름 링크로 설정하는 단계; 를 포함하여 구성되는 것을 특징으로 하는 인공지능을 이용한 시퀀스 기반의 키오스크 작동 방법.\n【청구항 4】\n청구항 3에 있어서, 상기 제 5 단계는, 키오스크 장치에 대한 특정 사용자의 주문 과정을 모니터링하는 단계; 공개특허 10-2024-0076882-3-상기 특정 사용자의 주문 과정에 대하여 주문 절차 데이터와 노드 특성 테이블을 획득하는 단계; 상기 특정 사용자의 주문 과정에 대한 상기 주문 절차 데이터와 상기 노드 특성 테이블을 상기 하이브리드 LSTM모델에 입력하는 단계; 상기 하이브리드 LSTM 모델의 출력으로부터 해당 사용자의 주문 과정을 위한 다음 추천 단계를 획득하는 단계; 를 포함하여 구성되는 것을 특징으로 하는 인공지능을 이용한 시퀀스 기반의 키오스크 작동 방법.\n【청구항 5】\n컴퓨터에 청구항 1 내지 4 중 어느 하나의 항에 따른 인공지능을 이용한 시퀀스 기반의 키오스크 작동 방법을실행시키기 위하여 저장매체에 저장된 컴퓨터프로그램."}
{"context": "", "input": "【기술명】\n심층 신경망을 이용한 심볼릭 인공지능 그래프 생성 방법 시스템\n\n【기술 설명】\n본 발명은 딥러닝을 통해 학습된 심층 신경망을 해석 가능한 심볼릭 인공지능 그래프로 변환하는 혁신적인 방법에 관한 것입니다. 이 기술은 심층 신경망을 여러 블록으로 구획화하고, 각 블록에 대응되는 액티베이션 값을 추출하여 이를 바탕으로 변환 단어를 생성하는 과정을 포함합니다. 마지막으로, 동일한 값의 변환 단어를 병합하여 이해 가능한 심볼릭 인공지능 그래프를 생성함으로써, 복잡한 딥러닝 모델의 해석 가능성을 높입니다.\n\n【해결 문제】\n현재 딥러닝 기술은 높은 성능을 자랑하지만, 그 해석 불가능성으로 인해 실용적 응용에 한계가 존재합니다. 특히 고위험 분야나 표준화가 요구되는 작업에서 딥러닝의 블랙 박스 특성은 신뢰성을 저해합니다. 본 기술은 이러한 문제를 해결하여, 심층 신경망의 해석 가능한 구조를 제시함으로써, 다양한 산업에서의 적용 가능성을 높이고, 데이터 부족이나 환경 변화에 능동적으로 대응할 수 있는 시스템을 제공합니다.\n\n【기술 차별성】\n본 발명은 기존의 딥러닝 모델과는 차별화된 접근방식을 취합니다. 기존 기술이 해석 불가능한 블랙 박스 모델에 의존하는 반면, 본 발명은 심층 신경망의 각 블록을 분리하고, 이를 해석 가능한 심볼릭 그래프로 전환함으로써, 사용자가 이해할 수 있는 형태로 정보를 제공합니다. 이 혁신적인 접근은 심볼릭 인공지능의 장점을 결합하여 데이터 의존성을 감소시키고, 전문가의 직관 없이도 신뢰성 높은 인공지능 모델을 구현할 수 있는 토대를 마련합니다.\n\n【활용 분야】\n본 발명의 심볼릭 인공지능 그래프 생성 방법은 인공지능, 데이터 분석, 로봇 공학, 자율주행차 및 의료 진단 등 다양한 산업 분야에서 활용될 수 있습니다. 특히, 복잡한 데이터 세트를 해석 가능한 형태로 변환하여 의사결정 과정을 지원하는 데 기여할 수 있습니다. 예를 들어, 의료 분야에서는 환자의 진단 데이터를 심볼릭 그래프로 변환하여 의사가 보다 쉽게 이해하고 진단할 수 있도록 도와줄 수 있습니다. 또한, 자율주행차에서는 실시간 데이터 분석을 통해 안전하고 효율적인 주행 경로를 도출하는 데 활용될 수 있습니다.\n\n【구성 요소 및 기능】\n본 발명의 구성 요소는 크게 네 가지로 나눌 수 있습니다. 첫째, **신경망 구획부**는 심층 신경망을 복수의 블록으로 구획화하여 데이터의 구조를 명확히 정의하는 역할을 합니다. 둘째, **결과 추출부**는 구획화된 블록에 대응되는 복수의 액티베이션 값을 추출하여, 각 블록의 활성화 상태를 수집합니다. 마지막으로, **결과 변환부**는 추출된 액티베이션 값을 기반으로 복수의 변환 단어를 생성하여, 의미 있는 정보를 도출하는 데 기여합니다. 이외에도 **단어 병합부**는 동일한 값을 가진 변환 단어들을 병합하여 보다 간결하고 유용한 데이터 표현을 제공합니다.\n\n【구현 방식 예】\n구현 방식은 크게 네 단계로 나눌 수 있습니다. 첫 단계는 심층 신경망을 복수의 블록으로 구획화하는 과정으로, 이는 신경망의 구조를 명확히 하고 각 블록의 의미를 정의하는 데 중점을 둡니다. 두 번째 단계에서는 구획화된 블록에 대응하는 액티베이션 값을 추출하여, 신경망의 작동 상태를 분석합니다. 세 번째 단계에서는 이 액티베이션 값을 기반으로 변환 단어를 생성하는데, 이는 데이터를 의미 있는 형식으로 변환하는 중요한 과정입니다. 마지막으로, 병합 단계에서는 생성된 변환 단어 중 값이 동일한 것들을 병합하여, 최종적으로 해석 가능한 심볼릭 인공지능 그래프를 형성합니다. 이 모든 과정은 컴퓨터로 판독 가능한 기록 매체에 저장된 프로그램을 통해 자동으로 수행될 수 있습니다.", "output": "【발명의 명칭】\n심층 신경망을 이용한 심볼릭 인공지능 그래프 생성 방법\n【기술분야】\n본 발명은 심볼릭 인공지능 그래프 생성 방법에 관한 것으로, 보다 상세하게는, 딥러닝을 통해 학습된 심층 신 경망을 해석 가능한 심볼릭 인공지능 그래프로 변환하는 방법에 관한 것이다.\n【배경기술】\n딥러닝은 역전파(backpropagation)를 통해 심층 신경망을 지도 학습의 경우는 학습 데이터에 최적화하고, 강화 학습의 경우는 리워드(reward) 제도 및 환경에 최적화시킬 수 있다. 딥러닝은 적절한 신경망 아키텍처와 충분한 데이터가 보장된다면 높은 최적화 성능을 보이며, 풀고 있는 문제와 환경에 무관한 높은 최적화 성능은 사람이 만든 인공지능 모델의 필요성을 줄일 수 있다. 사람이 만든 인공지능 모델의 경우 해당 문제에 대한 사람의 이 해를 활용하여 예측 모델이 생성되기 때문에, 데이터를 기계에 대입하지 않고도 성능을 낼 수 있는 장점이 있다. 그러나, 딥러닝 및 사람이 만든 인공지능 모델의 경우, 아래와 같은 한계가 존재한다. 먼저, 딥러닝은 블랙 박 스(black box)의 성격을 가지고 있어, 해석이 어려운 문제가 존재한다. 해석이 어렵기 때문에, 표준화와 같은 높은 일치도가 필요한 작업이나 고위험이 따르는 사용처에는 딥러닝 사용에 제약이 존재한다. 또한, 딥러닝은 데이터에 의존하기 때문에, 데이터가 부족하면 성능 보장이 어려우며 데이터나 환경이 변하는 상황에 쉽게 대응 하기 어렵다. 사람이 만든 인공지능 모델은 고비용의 전문가 직관이 요구되며, 딥러닝처럼 많은 데이터에 대한 성능 보장이 어렵다는 문제가 있다. 따라서, 사람이 만든 인공지능 모델의 한계와 딥러닝의 해석 불가(black box) 특징을 보완하여 실용 시스템에서 의 신뢰성 높은 사용을 가능케하고, 사용하는 환경에 맞추어 심층 신경망 변경을 변경할 수 있도록, 심층 신경 망의 해석 그래프가 필요하다.\n【해결하려는 과제】\n본 발명의 일 과제는 딥러닝을 통해 학습된 심층 신경망을 해석 가능한 심볼릭 인공지능 그래프로 변환하는 방 법에 관한 것이다.\n【과제의 해결 수단】\n일 실시예에 따른 심볼릭 인공지능 그래프 생성 방법은 적어도 하나 이상의 프로세서에 의해 수행되는 심볼릭 인공지능 그래프 생성 방법에 있어서, 심층 신경망을 복수의 블록으로 구획화하는 단계; 상기 복수의 블록에 대 응되는 복수의 액티베이션(activation) 값들을 추출하는 단계; 상기 복수의 액티베이션 값들에 기초하여 복수의 변환 단어들을 생성하는 단계; 및 상기 복수의 변환 단어들 중 적어도 일부의 변환 단어들을 병합하는 단계를 포함할 수 있다. 여기서, 상기 복수의 변환 단어들을 생성하는 단계는 액티베이션 값의 각 자리수의 숫자가 0이 아닌 경우 1로 변환하는 단계일 수 있다.여기서, 상기 적어도 일부의 변환 단어들을 병합하는 단계는 상기 복수의 변환 단어들 중 값이 동일한 변환 단 어들을 병합하는 단계일 수 있다. 여기서, 추출한 상기 복수의 액티베이션 값들에 대응되는 복수의 노드를 생성하는 단계; 및 상기 복수의 액티베 이션 값들의 상관 관계에 기초하여 상기 복수의 노드를 연결하는 엣지를 생성하는 단계를 더 포함할 수 있다. 여기서, 상기 적어도 일부의 변환 단어들을 병합하는 단계는 상기 적어도 일부의 변환 단어들에 대응되는 적어 도 일부의 노드를 병합하는 단계일 수 있다. 여기서, 상기 적어도 일부의 변환 단어를 병합하는 단계는, 제1 변환 단어에 대응되는 제1 노드와 연결된 제2 노드 및 제3 노드를 확인하는 단계; 및 상기 제2 노드에 대응되는 제2 변환 단어 및 상기 제3 노드에 대응되는 제3 변환 단어를 병합하는 단계를 포함하고, 상기 제1 변환 단어는 제1 블록의 출력값인 제1 액티베이션 값이 변환된 값이고, 상기 제2 변환 단어 및 상기 제3 변환 단어는 각각 상기 제1 블록의 입력값인 제2 액티베이션 값 및 제3 액티베이션 값이 변환된 값일 수 있다. 여기서, 각 블록의 출력값에 대응되는 변환 단어에 대한 확률을 산출하는 단계를 더 포함하고, 상기 확률을 산 출하는 단계는 각 블록의 입력값에 대응되는 노드와 연결된 노드의 개수 및 각 블록의 출력값에 대응되는 노드 와 연결된 노드의 개수에 기초하여 출력값의 생성과 관련된 확률을 산출하는 단계일 수 있다. 여기서, 상기 심층 신경망의 출력값에 기초하여 상기 복수의 블록 중 하위 블록의 출력값에 대응되는 노드를 삭 제 또는 변경하는 단계를 더 포함할 수 있다. 여기서, 상기 노드를 삭제 또는 변경하는 단계는, 상기 하위 블록의 출력값에 대응되는 노드들 중 제4 노드와 다른 노드들 사이의 유사도를 산출하는 단계; 및 상기 제4 노드를 삭제하고 상기 제4 노드와 연결된 엣지를 상 기 제4 노드와 유사도가 가장 높은 제5 노드에 연결시키는 단계를 포함할 수 있다. 여기서, 상기 심볼릭 인공지능 그래프 생성 방법을 실행시키도록 컴퓨터로 판독 가능한 기록 매체에 저장된 컴 퓨터 프로그램이 제공될 수 있다. 일 실시예에 따른 심볼릭 인공지능 그래프 생성 시스템은 심층 신경망을 복수의 블록으로 구획화하는 신경망 구 획부; 상기 복수의 블록에 대응되는 복수의 액티베이션(activation) 값들을 추출하는 결과 추출부; 상기 복수의 액티베이션 값들에 기초하여 복수의 변환 단어를 생성하는 결과 변환부; 및 상기 복수의 변환 단어들 중 적어도 일부의 변환 단어들을 병합하는 단어 병합부를 포함할 수 있다.\n【발명의 효과】\n본 발명의 일 실시예에 따르면 딥러닝을 통해 학습된 심층 신경망을 해석 가능한 심볼릭 인공지능 그래프로 변 환하는 방법이 제공될 수 있다.\n【발명을실시하기위한구체적인내용】\n본 명세서에 기재된 실시예는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 본 발명의 사상을 명 확히 설명하기 위한 것이므로, 본 발명이 본 명세서에 기재된 실시예에 한정되는 것은 아니며, 본 발명의 범위 는 본 발명의 사상을 벗어나지 아니하는 수정예 또는 변형예를 포함하는 것으로 해석되어야 한다. 본 명세서에서 사용되는 용어는 본 발명에서의 기능을 고려하여 가능한 현재 널리 사용되고 있는 일반적인 용어 를 선택하였으나 이는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자의 의도, 판례 또는 새로운 기술 의 출현 등에 따라 달라질 수 있다. 다만, 이와 달리 특정한 용어를 임의의 의미로 정의하여 사용하는 경우에는 그 용어의 의미에 관하여 별도로 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌 그 용어가 가진 실질적인 의미와 본 명세서의 전반에 걸친 내용을 토대로 해석되어야 한다. 본 명세서에 첨부된 도면은 본 발명을 용이하게 설명하기 위한 것으로 도면에 도시된 형상은 본 발명의 이해를 돕기 위하여 필요에 따라 과장되어 표시된 것일 수 있으므로 본 발명이 도면에 의해 한정되는 것은 아니다. 본 명세서에서 본 발명에 관련된 공지의 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있 다고 판단되는 경우에 이에 관한 자세한 설명은 필요에 따라 생략하기로 한다. 딥러닝의 발전에 따라 딥러닝에 사용되는 파라미터도 많아지고 있다. 파라미터가 많아질수록 데이터 처리에 대 한 로드도 증가될 수 있다. 그러나, 스마트폰과 같은 휴대용 사용자 단말기의 경우, 고기능의 딥러닝을 실행할 수 있는 자원 및 에너지가 충분하지 않을 수 있다. 이를 위해 빔포밍 등 외부 네트워크 자원을 사용하는 방법도 있으나, 외부 네트워크 자원도 추가적으로 소모되고, 빠르게 처리할 수 없다는 단점이 존재한다. 또한, 신경망의 입력과 출력 사이의 인과 관계를 알 수 있으면, 이를 이용하여 신뢰성 및 정확성을 향상시킬 수 있으나, 딥러닝의 경우 입력과 출력 간의 인과 관계를 파악할 수 없다. 이에, 딥러닝이 새로운 환경에 놓였을 때 처음부터 새롭게 학습해야 하는 문제가 존재한다. 따라서, 사용되는 파라미터의 구분 및 정리와 입력 데이터 및 출력 데이터 사이의 인과 관계를 파악할 수 있는 심볼릭 인공지능 그래프가 필요하다. 이에, 본원 발명에서는 심층 신경망을 해석 가능한 심볼릭 인공지능 그래 프로 변환하는 방법에 대해 제안한다. 도 1은 일 실시예에 따른 심볼릭 인공지능 그래프 생성 시스템의 블록도이다. 도 1을 참조하면, 일 실시예에 따른 심볼릭 인공지능 그래프 생성 시스템(1000, 이하 '시스템')은 신경망 구획 부, 결과 추출부, 결과 변환부 및 단어 병합부를 포함할 수 있다. 도 1은 시스템 에 포함되는 네 가지 구성 요소를 도시하고 있으나, 도시된 구성 요소들이 필수적인 것은 아니고, 시스템 은 그보다 많은 구성 요소를 갖거나 그보다 적은 구성 요소를 가질 수 있다. 또한, 시스템의 각 구성 요소는 물리적으로 하나의 서버에 포함될 수도 있고, 각각의 기능 별로 분산된 분산 서버일 수 있다. 또는 시스템의 각 구성 요소의 기능은 물리적으로 하나의 프로세서에 의해 수행될 수도 있고, 각각의 기능 별로 분산된 복수의 프로세서에 의해 수행될 수도 있다. 시스템은 시스템의 동작을 총괄하는 제어 프로세서를 포함할 수 있다. 구체적으로, 제어 프로세서 는 신경망 구획부, 결과 추출부, 결과 변환부 및 단어 병합부에 제어 명령을 보내 각 부서의 동작을 실행할 수 있다. 이하에서 특별한 언급이 없는 경우에는, 시스템의 동작은 제어 프로세서의 제어에 의해 수행되는 것으로 해석될 수 있다. 신경망 구획부는 심층 신경망을 복수의 블록으로 구획화할 수 있다. 구체적으로, 신경망 구획부는 특정 태스크 또는 환경에 최적화되어 학습된 심층 신경망을 유의미한 모듈들로 구획화할 수 있다. 신경망 구획 부는 심층 신경망을 복수의 블록으로 구획화함으로써 신경망 기반 표준 모델(NPM: Neural Protocol Model)을 생성할 수 있다. 신경망 구획부가 심층 신경망을 구획화하는 기준은 신경망이 적용되는 어플리케이션의 목적, 최적화된 환 경, 모델의 기 구획화된 블록 정보를 포함할 수 있다. 예를 들어, 신경망 구획부는 단순한 다층 퍼셉트론 (MLP: Multi-layer Perceptron) 신경망에 대해 특정 히든 레이어들을 기준으로 구획화할 수 있으나, 이에 한정되지 않는다. 결과 추출부는 신경망 구획부가 구획화한 복수의 블록에 대응되는 복수의 액티베이션(activation) 값들을 추출할 수 있다. 액티베이션(activation) 값은 심층 신경망에 사용되는 입출력 값과 관련된 것으로, 단 어로도 명칭될 수 있다. 결과 추출부는 신경망 구획부가 생성한 신경망 기반 표준 모델(NPM)을 시 뮬레이터로 사용하여 유의미한 레이어에서 단어들을 추출할 수 있다. 구체적으로, 복수의 블록의 입력값 및 출 력값에 대응되는 액티베이션 값을 추출할 수 있다. 결과 추출부는 추출한 액티베이션 값들에 대응되는 복수의 노드를 생성할 수 있다. 또한, 결과 추출부 는 각 액티베이션 값들의 상관 관계 또는 논리적 관계에 기초하여 노드들을 연결하는 엣지를 생성할 수 있다. 결과 추출부는 복수의 노드 및 엣지를 이용하여 심볼릭 인공지능 그래프를 생성할 수 있다. 결과 변환부는 결과 추출부가 추출한 복수의 액티베이션 값들에 기초하여 복수의 변환 단어를 생성 할 수 있다. 구체적으로, 결과 변환부는 액티베이션 값의 각 자리수의 수치에 기초하여 액티베이션 값을 변환하여 변환 단어를 생성할 수 있다. 이때, 결과 변환부는 액티베이션 값의 각 자리수가 0이 아닌 경우 1로 변환할 수 있다. 예를 들어, 액티베이션 값이 0, 0, 0.2, 1인 경우, 결과 변환부는 이를 0, 0, 1, 1로 변환할 수 있다. 또 한 예를 들어, 액티베이션 값이 0, 0.1, 0.3, 0.8인 경우, 결과 변환부는 이를 0, 1, 1, 1로 변환할 수 있다. 액티베이션 값이 변환된 값은 변환 단어로 명칭될 수 있다. 단어 병합부는 결과 변환부가 생성한 복수의 변환 단어들 중 적어도 일부의 변환 단어를 병합할 수 있다. 구체적으로, 단어 병합부는 심볼릭 인공지능 그래프에 포함된 복수의 노드들 중 적어도 일부의 노 드를 병합할 수 있다. 일 실시예에 따르면, 단어 병합부는 값이 동일한 변환 단어를 병합하고, 이에 대응되는 노드들을 병합할 수 있다. 예를 들어, 제1 변환 단어가 0, 0, 1, 1이고 제2 변환 단어가 0, 0, 1, 1인 경우, 단어 병합부(140 0)는 제1 변환 단어 및 제2 변환 단어를 병합할 수 있다. 또한, 단어 병합부는 제1 변환 단어에 대응되는 제1 노드와 제2 변환 단어에 대응되는 제2 노드를 병합할 수 있다. 다른 일 실시예에 따르면, 단어 병합부는 동일한 출력을 생성하는 입력값들을 병합할 수 있다. 구체적으 로, 하나의 블록 내에서 제1 입력 액티베이션 값과 제2 입력 액티베이션 값이 모두 제1 출력 액티베이션 값을 생성하는 경우, 단어 병합부는 제1 입력 액티베이션 값에 대응되는 변환 단어 또는 노드와 제2 입력 액티 베이션 값에 대응되는 변환 단어 또는 노드를 병합할 수 있다. 예를 들어, 단어 병합부는 심볼릭 인공지능 그래프 내에서 제1 블록의 출력값인 제1 액티베이션 값이 변 환된 제1 변환 단어에 대응되는 제1 노드를 기준으로 할 수 있다. 단어 병합부는 제1 노드와 엣지를 통해 연결된 제2 노드 및 제3 노드를 확인할 수 있다. 제2 노드와 제3 노드는 입력 노드로서 모두 제1 노드에 대응되 는 출력값을 생성하기 때문에, 병합될 수 있다. 이에, 단어 병합부는 제2 노드 및 제3 노드를 병합할 수 있다. 또한, 단어 병합부는 제2 노드에 대응되는 제2 변환 단어 및 제3 노드에 대응되는 제3 변환 단어를 병합할 수 있다. 이때, 제2 변환 단어 및 제3 변환 단어는 상기 제1 블록의 입력값인 제2 액티베이션 값 및 제3 액티베이션 값이 각각 변환된 값일 수 있다. 시스템은 위 네 가지 구성 요소 외에도 데이터베이스부를 포함할 수 있다. 데이터베이스부는 시스템 이 동작하는데 필요한 각종 데이터 및 프로그램을 저장할 수 있다. 데이터베이스부는 시스템이 획 득하는 정보 및 처리하는 정보 모두를 저장할 수 있다. 예를 들어, 데이터베이스부는 신경망 구획부가 구획화한 복수의 블록에 대한 정보를 포함할 수 있다. 또 한 예를 들어, 데이터베이스부는 시스템이 생성한 심볼릭 인공지능 그래프를 저장할 수 있다. 또한 예를 들어, 데이터베이스부는 결과 변환부가 생성한 변환 단어들을 저장할 수 있다. 데이터베이스부는 데이터를 임시적으로 또는 반영구적으로 저장할 수 있다. 예를 들어, 데이터베이스부는 하드 디스크(HDD: Hard Disk Drive), SSD(Solid State Drive), 플래쉬 메모리(flash memory), 롬(ROM: Read-Only Memory), 램(RAM: Random Access Memory) 또는 클라우드 스토리지(Cloud Storage) 등일 수 있으나, 이에 한정 되지 않고 데이터를 저장하기 위한 다양한 모듈로 구현될 수 있다.도 2는 일 실시예에 따른 심볼릭 인공지능 그래프 생성 방법의 순서도이다. 도 2를 참조하면, 일 실시예에 따른 심볼릭 인공지능 그래프 생성 방법은 심층 신경망을 구획화하는 단계 (S100), 액티베이션 값을 추출하고 노드와 엣지를 생성하는 단계(S200), 액티베이션 값을 변환하는 단계(S300), 변환된 값 또는 노드를 병합하는 단계(S400), 변환된 값에 대한 확률을 산출하는 단계(S500) 및 노드를 삭제 또 는 변경하는 단계(S600)를 포함할 수 있다. 도 2에는 단계 S100 내지 단계 S600이 순서대로 수행되는 것이 도시 되었으나, 이에 한정되지 않고 각 단계의 순서는 변경될 수 있다. 또는 각 단계가 다른 단계와 병합되거나 생략 될 수도 있다. 일 실시예에 따른 심볼릭 인공지능 그래프 생성 방법에 대한 설명은 도 3 내지 도 9를 함께 참조하여 이하에서 설명한다. 도 3은 딥러닝 실행 환경을 설명하기 위한 예시 도면이다. 도 3을 참조하면, 복수의 단말(UE1, UE2)과 기지국의 통신 환경을 알 수 있다. 복수의 단말과 기지국 사이의 원 활한 통신을 위해 복수의 단말이 기지국에 보내는 데이터 사이의 충돌을 방지하기 위해, 스케줄링 기술이 적용 될 수 있다. 본원 발명에서는 데이터 충돌을 방지하기 위한 스케줄링 환경에서 사용되는 심층 신경망을 예시로 하여 이하에서 심볼릭 인공지능 그래프 생성 방법에 대해 설명한다. 심층 신경망을 구획화하는 단계(S100)는 신경망 구획부가 심층 신경망을 복수의 블록으로 구획화하는 단 계일 수 있다. 도 4를 참조하면, 신경망 구획부는 도 3의 환경에서 사용되는 심층 신경망을 복수의 블록 (UEs-UE1, UEs-UE2, BS-UCM1, BS-UCM2, UEs 등)으로 구획화할 수 있다. 이때, 신경망 구획부는 어플리케 이션의 목적, 최적화된 환경, 모델의 기 구획화된 블록 정보를 포함하는 기준에 의해 심층 신경망을 구획화할 수 있다. 액티베이션 값을 추출하고 노드와 엣지를 생성하는 단계(S200)는 결과 추출부가 각 블록의 입력값과 관련 된 액티베이션 값 및 출력값과 관련된 액티베이션 값들을 추출하는 단계일 수 있다. 또한, 단계 S200에서, 결과 추출부는 각 액티베이션 값에 대응되는 노드들을 생성할 수 있다. 또한, 결과 추출부는 액티베이션 값들의 논리적인 상관 관계에 기초하여 노드들을 연결하는 엣지를 생성할 수 있다. 이에, 결과 추출부는 복수의 노드 및 엣지를 포함하는 심볼릭 인공지능 그래프를 생성할 수 있다. 생성된 그래프는 이하의 단계에서 병합, 삭제 및 수정의 과정을 거쳐 간소화될 수 있다. 도 5를 참조하면, 심볼릭 인공지능 그래프는 제1 블록, 제2 블록 및 제3 블록을 포함할 수 있다. 결과 추출부는 각 블록의 입력값 및 출력값에 대응되는 액티베이션 값을 추출할 수 있다. 예를 들 어, 결과 추출부는 제1 블록의 입력값에 대응되는 액티베이션 값을 추출하여 노드를 생성하고, 출력값에 대응되는 액티베이션 값을 추출하여 노드를 생성할 수 있다. 또한, 결과 추출부는 제2 블 록 및 제3 블록에 대해서도 노드(210, 220, 310, 320)들을 생성할 수 있다. 이때, 상위 블록의 출력 은 하위 블록의 입력이 될 수 있다. 결과 추출부는 생성된 노드들 간의 상관 관계에 기초하여, 노드들을 연결시키는 엣지를 생성할 수 있다. 엣지는 화살표 형태로서, 입력과 출력 간의 관계를 나타낼 수 있다. 또한 하나의 입력값에서 복수의 출력값이 생성될 수 있으므로, 하나의 노드는 여러 엣지를 가질 수 있다. 액티베이션 값을 변환하는 단계(S300)는 결과 변환부가 액티베이션 값의 자리수 숫자들에 기초하여 액티 베이션 값을 변환함으로써 변환 단어를 생성하는 단계일 수 있다. 결과 변환부는 액티베이션 값의 각 자 리수에 대응되는 숫자를 확인할 수 있다. 이때, 액티베이션 값의 각 자리수의 개수는 액티베이션 값을 출력하는 블록의 하위 노드의 개수와 동일할 수 있다. 예를 들어, 도 5의 제1 블록의 하위 노드(출력과 관련된 노드)의 개수는 3개 이므로, 제1 블록의 출력 액티베이션 값의 자리수는 3일 수 있다. 예를 들어, 제1 블 록의 출력 액티베이션 값은 0, 0.1, 0.5일 수 있다. 결과 변환부는 각 자리수의 숫자가 0이 아닌 경우, 1로 변환함으로써 변환 단어를 생성할 수 있다. 위 예 시의 경우, 결과 변환부는 0, 1, 1의 변환 단어를 생성할 수 있다. 이에 따라, 심볼릭 인공지능 그래프에 포함 된 노드 내의 값이 액티베이션 값에서 변환 단어로 변경될 수 있다. 변환된 값 또는 노드를 병합하는 단계(S400)는 단계 S300에서 생성된 변환 단어의 수치에 기초하여 단어 병합부 가 변환 단어에 대응되는 노드를 병합하는 단계일 수 있다. 단어 병합부는 변환 단어의 값이 동일 한 노드들을 병합할 수 있다. 단어 병합부는 노드들을 병합함으로써, 심볼릭 인공지능 그래프를 간소화할수 있다. 단어 병합부는 노드들을 병합함으로써, 딥러닝에 사용되는 파라미터를 축소시킬 수 있다. 도 6을 참조하면, 제2 블록에서 UE1의 입력 노드 3개가 병합되어 하나의 입력 노드가 남게 되고, UE1의 출 력 노드 9개 중 일부가 병합되어 2개의 출력 노드가 남게 되는 것을 확인할 수 있다. UE2의 경우에도, 제2 블록 에서 입력 노드 3개 중 일부가 병합되어 2개의 입력 노드가 남게 되고, 출력 노드 9개가 모두 병합되어 1 개의 출력 노드가 남게 되는 것을 확인할 수 있다. 변환된 값에 대한 확률을 산출하는 단계(S500)는 출력값에 대응되는 변환 단어들이 입력값으로부터 생성될 확률 을 산출하는 단계일 수 있다. 심볼릭 인공지능 그래프는 논리적 관계를 나타내므로, 하나의 노드의 발생 사실을 알게되면, 해당 노드로 인해 논리적으로 유추해낼 수 있는 다른 노드들이 생길 수 있다. 이때, 하나의 노드의 결과값이 복수개일 수 있다. 이러한 상황을 위해, 단계 S500에서 확률을 산출함으로써 확률적 논리 그래프를 생 성할 수 있다. 단계 S500은 시스템의 제어부 또는 산출 기능을 수행하는 별도의 프로세서에 의해 수행될 수 있다. 단계 S500은 각 블록의 입력값에 대응되는 노드와 연결된 노드의 개수 및 각 블록의 출력값에 대응되는 노드와 연결된 노드의 개수에 기초하여 출력값의 생성과 관련된 확률을 산출하는 단계일 수 있다. 구체적으로, 특정 노 드에서 하위 노드로 귀결되었던 경우의 수를 계산함으로써 확률이 산출될 수 있다. 예를 들어, 도 6의 제2 블록 의 특정 노드가 생성되기 위한 경우의 수를 특정 노드와 연결된 제2 블록의 입력 노드의 개수를 이용 하여 산출할 수 있다. 노드를 삭제 또는 변경하는 단계(S600)는 딥러닝의 실행 환경에서 발생할 수 있는 논리적 충돌이나 오류를 수정 하기 위해 노드를 삭제 또는 변경하는 단계일 수 있다. 단계 S600은 시스템의 제어부 또는 분석/수정 기 능을 수행하는 별도의 프로세서에 의해 수행될 수 있다. 도 2와 같은 통신 환경에서, 단계 S100 내지 단계 S500에 의해 생성된 심볼릭 인공지능 그래프에 따른 딥러닝을 사용하면 특정 논리적 연결이 충돌을 일으킬 수 있다. 이때, 충돌을 줄이기 위해, 송수신 결정을 일으키는 최종 논리 연결 관계를 수정할 수 있다. 단계 S600에서 충돌을 일으킬 수 있는 노드를 수정하는 과정은 다른 노드나 엣지에 영향을 주지 않기 때문에, 성능에 피해를 주지 않고 원하는 방향으로 프로토콜이 작동하도록 유도할 수 있다. 시스템은 충돌을 줄이기 위해 그래프 분석을 수행하여 복수의 블록 중 하위 블록의 출력값과 관련되는 노 드들 중 제1 노드 수정과 관련된 결과를 확인할 수 있다. 단계 S600에서, 시스템은 상기 제1 노드와 하위 블록의 다른 출력값과 관련되는 노드들 사이의 유사도를 산출할 수 있다. 시스템은 상기 제1 노드를 삭제 하고, 상기 제1 노드와 연결된 엣지를 유사도가 가장 높은 제2 노드에 연결시킬 수 있다. 시스템은 제1 노드 대신 제2 노드로 대체함에 따라 환경에서 발생할 수 있는 오류를 방지할 수 있다. 도 7은 노드 병합을 구체적으로 설명하기 위한 예시 도면이다. 도 7을 참조하면, 시스템은 추출한 액티베이션 값을 변환함으로써 변환 단어를 생성할 수 있다. 변환 단 어에 기초하여 생성된 그래프는 심볼릭 인공지능 기반 표준 모델(SPM: Semantic/symbolic Protocol Model)로 명칭될 수 있다. 심볼릭 인공지능 기반 표준 모델(SPM)은 활성화 패턴 기준 단어 병합(Activation Pattern- Aware Merging) 방식으로 변환 단어들이 병합될 수 있다. 활성화 패턴 기준 단어 병합은 변환 단어들의 값이 동 일한 단어들을 병합하는 방식으로, 전술한 내용과 중복되므로 자세한 설명은 생략한다. 시스템은 활성화 패턴 기준 단어 병합 방식에 의해 변경된 심볼릭 인공지능 그래프를 논리 연결 패턴 기 준 단어 병합(Connection-aware merging)추가적으로 더 간소화할 수 있다. 논리 연결 패턴 기준 단어 병합은 동 일한 출력값을 내는 입력값들을 병합하는 방식으로, 전술한 내용과 중복될 수 있어 자세한 설명은 생략한다. 도 8은 단어의 유사도를 설명하기 위한 도면이다. 도 8을 참조하면, 단어들의 유사도를 분석하는 방법인 T-SNE(T-distributed stochastic neighborhood embedding)에 의해 분석된 유사도 분포를 확인할 수 있다. 도 8과 같이, 변환 단어들이 동일한 값들 또는 동일 한 출력을 생성하는 값들은 분포도에서 유사한 위치에 설정되는 것을 확인할 수 있다. 단어들의 의미적 상관 관 계를 확인할 수 있는 T-SNE를 통해 확인된 병합될 단어들은 유사한 위치를 가지기 때문에, 그래프 간소화 및 파라미터 축소를 위해 병합될 수 있다. 도 9는 노드를 수정하는 방법을 설명하기 위한 예시 도면이다. 도 9를 참조하면, 시스템은 하위 블록의 출력값과 관련된 특정 노드가 오류를 발생할 가능성이 있는 것을 확인할 수 있다. 시스템은 특정 노드와 유사도가 가장 높은 대체 노드를 이용하여 특정 노 드를 대체 노드로 대체할 수 있다. 이에, 논리적 연결이 충돌되지 않고 원하는 방향으로 프로토콜이 작 동된 것을 확인할 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD- ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다 이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9\n【요약】본 발명의 심볼릭 인공지능 그래프 생성 방법은 심층 신경망을 복수의 블록으로 구획화하는 단계; 상기 복수의 블록에 대응되는 복수의 액티베이션(activation) 값들을 추출하는 단계; 상기 복수의 액티베이션 값들에 기초하 여 복수의 변환 단어들을 생성하는 단계; 및 상기 복수의 변환 단어들 중 적어도 일부의 변환 단어들을 병합하는 단계를 포함할 수 있다.\n\n【청구항 1】\n적어도 하나 이상의 프로세서에 의해 수행되는 심볼릭 인공지능 그래프 생성 방법에 있어서,심층 신경망을 복수의 블록으로 구획화하는 단계;상기 복수의 블록에 대응되는 복수의 액티베이션(activation) 값들을 추출하는 단계;상기 복수의 액티베이션 값들에 기초하여 복수의 변환 단어들을 생성하는 단계; 및상기 복수의 변환 단어들 중 적어도 일부의 변환 단어들을 병합하는 단계를 포함하는심볼릭 인공지능 그래프 생성 방법.\n【청구항 2】\n제1항에 있어서,상기 복수의 변환 단어들을 생성하는 단계는 액티베이션 값의 각 자리수의 숫자가 0이 아닌 경우 1로 변환하는단계인심볼릭 인공지능 그래프 생성 방법.\n【청구항 3】\n제2항에 있어서,상기 적어도 일부의 변환 단어들을 병합하는 단계는 상기 복수의 변환 단어들 중 값이 동일한 변환 단어들을 병합하는 단계인심볼릭 인공지능 그래프 생성 방법.\n【청구항 4】\n제1항에 있어서,추출한 상기 복수의 액티베이션 값들에 대응되는 복수의 노드를 생성하는 단계; 및상기 복수의 액티베이션 값들의 상관 관계에 기초하여 상기 복수의 노드를 연결하는 엣지를 생성하는 단계를 더포함하는심볼릭 인공지능 그래프 생성 방법.\n【청구항 5】\n제4항에 있어서,상기 적어도 일부의 변환 단어들을 병합하는 단계는 상기 적어도 일부의 변환 단어들에 대응되는 적어도 일부의노드를 병합하는 단계인공개특허 10-2024-0104375-3-심볼릭 인공지능 그래프 생성 방법.\n【청구항 6】\n제1항에 있어서,상기 적어도 일부의 변환 단어를 병합하는 단계는,제1 변환 단어에 대응되는 제1 노드와 연결된 제2 노드 및 제3 노드를 확인하는 단계; 및상기 제2 노드에 대응되는 제2 변환 단어 및 상기 제3 노드에 대응되는 제3 변환 단어를 병합하는 단계를 포함하고,상기 제1 변환 단어는 제1 블록의 출력값인 제1 액티베이션 값이 변환된 값이고,상기 제2 변환 단어 및 상기 제3 변환 단어는 각각 상기 제1 블록의 입력값인 제2 액티베이션 값 및 제3 액티베이션 값이 변환된 값인심볼릭 인공지능 그래프 생성 방법.\n【청구항 7】\n제1항에 있어서,각 블록의 출력값에 대응되는 변환 단어에 대한 확률을 산출하는 단계를 더 포함하고,상기 확률을 산출하는 단계는 각 블록의 입력값에 대응되는 노드와 연결된 노드의 개수 및 각 블록의 출력값에대응되는 노드와 연결된 노드의 개수에 기초하여 출력값의 생성과 관련된 확률을 산출하는 단계인심볼릭 인공지능 그래프 생성 방법.\n【청구항 8】\n제4항에 있어서,상기 심층 신경망의 출력값에 기초하여 상기 복수의 블록 중 하위 블록의 출력값에 대응되는 노드를 삭제 또는변경하는 단계를 더 포함하는심볼릭 인공지능 그래프 생성 방법.\n【청구항 9】\n제8항에 있어서,상기 노드를 삭제 또는 변경하는 단계는,상기 하위 블록의 출력값에 대응되는 노드들 중 제4 노드와 다른 노드들 사이의 유사도를 산출하는 단계; 및상기 제4 노드를 삭제하고 상기 제4 노드와 연결된 엣지를 상기 제4 노드와 유사도가 가장 높은 제5 노드에 연결시키는 단계를 포함하는심볼릭 인공지능 그래프 생성 방법.\n【청구항 10】\n제1항 내지 제9항 중 어느 한 항에 기재된 심볼릭 인공지능 그래프 생성 방법을 실행시키도록 컴퓨터로 판독 가공개특허 10-2024-0104375-4-능한 기록 매체에 저장된 컴퓨터 프로그램.\n【청구항 11】\n심층 신경망을 복수의 블록으로 구획화하는 신경망 구획부;상기 복수의 블록에 대응되는 복수의 액티베이션(activation) 값들을 추출하는 결과 추출부;상기 복수의 액티베이션 값들에 기초하여 복수의 변환 단어를 생성하는 결과 변환부; 및상기 복수의 변환 단어들 중 적어도 일부의 변환 단어들을 병합하는 단어 병합부를 포함하는심볼릭 인공지능 그래프 생성 시스템."}
{"context": "", "input": "【기술명】\n친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능 기술기반 부분 방전 진단 방법 및 이 시스템\n\n【기술 설명】\n본 발명은 친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능 기술 기반의 부분 방전 진단 방법에 관한 것입니다. 이 기술은 가스절연개폐장치의 안전성을 높이고 유지보수 비용을 절감하기 위해 설계되었습니다. UHF 센서로부터 수집한 전자파 신호를 분석하여 부분 방전의 크기를 정량적으로 판단하고, 이를 통해 결함 원인을 도출하는 인공지능 알고리즘을 적용합니다. 이러한 접근은 전력 설비의 신뢰성을 높이는 동시에 환경적 지속 가능성을 고려한 혁신적인 솔루션을 제공합니다.\n\n【해결 문제】\n가스절연개폐장치는 전력공급의 안전성을 담보하는 필수 설비로, 고장 시 신속한 차단이 필요합니다. 그러나 기존의 절연가스는 환경 문제를 야기할 수 있으며, 특히 육불화황 가스 사용에 따른 지구온난화 지수가 문제로 지적되고 있습니다. 본 발명은 이러한 문제를 해결하기 위해 친환경 절연가스를 활용하여, 부분 방전 진단을 통해 설비의 결함을 조기에 발견하고, 이에 따른 유지보수 작업을 효율적으로 수행할 수 있도록 합니다. 이는 전력 시스템의 안정성과 환경적 지속 가능성을 동시에 보장하는 필수적인 기술입니다.\n\n【기술 차별성】\n본 발명의 차별성은 기존 기술과 비교했을 때, UHF 센서를 통해 실시간으로 전자파 신호를 수집하고 이를 인공지능 기술로 분석하여 결함 원인을 자동으로 도출하는 점에 있습니다. 기존의 진단 방법은 수동적이거나 경험에 의존하는 경우가 많았으나, 본 발명은 뉴럴 네트워크 기반의 역전파 알고리즘을 적용하여 데이터 기반의 정량적 진단을 가능하게 합니다. 이로 인해 신뢰성과 정확성을 높이며, 설비의 유지보수 비용을 절감할 수 있는 혁신적인 기술로 자리 잡을 것입니다.\n\n【활용 분야】\n본 발명은 전력 산업, 특히 전력 변환 및 분배 시스템에서 사용되는 가스절연개폐장치에 적용될 수 있습니다. 이러한 장치들은 고전압 및 고전류 환경에서 안정적인 작동을 유지해야 하며, 부분 방전 진단 기술의 도입을 통해 장비의 신뢰성을 향상시킬 수 있습니다. 또한, 친환경 절연가스를 사용함으로써 환경 보호 및 지속 가능한 에너지 관리에 기여할 수 있으며, 전력 설비의 유지보수 비용 절감과 안전성을 동시에 확보할 수 있습니다.\n\n【구성 요소 및 기능】\n본 발명은 세 가지 주요 구성 요소로 이루어져 있습니다. 첫 번째 구성 요소는 UHF 센서로, 이는 가스절연개폐장치에서 발생하는 전자파 신호를 실시간으로 측정하여 수집하는 역할을 합니다. 두 번째 구성 요소는 프로세서로, 이 프로세서는 수집된 전자파 신호의 전압을 인가 전하량의 단위로 환산하는 기능을 수행하며, 이를 통해 부분 방전의 크기를 정확하게 판단할 수 있도록 합니다. 마지막으로, 뉴럴 네트워크 기반의 알고리즘을 적용하여 다수의 파라미터를 분석하고 결함 원인을 출력하는 기능을 수행하는 인공지능 모듈이 있습니다. 이 모듈은 고도의 데이터 분석을 통해 장비의 상태를 예측하고, 사전 예방적 유지보수를 가능하게 합니다.\n\n【구현 방식 예】\n본 발명의 구현 방식은 다음과 같은 단계로 구성됩니다. 첫 번째 단계는 UHF 센서를 통해 전자파 신호를 실시간으로 획득하는 것으로, 이 신호는 가스절연개폐장치의 성능을 모니터링하는 데 필수적입니다. 두 번째 단계에서는 수집된 신호의 전압을 환산식에 따라 인가 전하량의 단위로 변환하여, 부분 방전의 크기를 정확히 판단할 수 있도록 합니다. 마지막으로, 프로세서에 의해 처리된 다수의 파라미터를 뉴럴 네트워크 알고리즘에 입력하여 결함 원인을 분석하고 이를 출력함으로써, 체계적인 유지보수 및 관리가 가능하도록 합니다. 이 과정은 자동화된 진단 시스템을 통해 효율적이며 신속하게 이루어집니다.", "output": "【발명의 명칭】\n친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능 기술기반 부분 방전 진단 방법 및 이\n【기술분야】\n본 발명은 친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능 기술기반 부분 방전 진단 방법 및 이를 수행 하는 프로그램이 기록된 컴퓨터 판독이 가능한 기록매체 에 관한 것이다.\n【배경기술】\n가스절연개폐장치(Gas insulated switchgear; GIS)는 안정적인 전력공급을 위한 중요한 설비 중 하나로 부하전 류 개폐뿐만 아니라 계통에 사고 발생 시 고장전류를 신속하게 차단하여 선로에 접속된 전력설비를 보호하는 기 기이다. 가스절연개폐장치(GIS)는 부싱, 차단기, 단로기, 접지개폐기, 계기용 변압기 및 변류기로 구성되어 있 다. 특히 밀폐된 탱크 내부에 절연 성능과 아크소호능력이 우수한 육불화황(SF6) 가스를 충전하여 고장률이 낮고 유지보수 비용이 적은 장점이 있다. 육불화황(SF6) 가스는 가스 안정도가 높은 불활성 기체로 상온에서 무색, 무취, 무해 및 불연성 가스이다. 특 히 공기에 비해 절연강도가 3배 높고 절연회복이 빨라 가스절연개폐장치의 절연매체로 많이 사용하고 있다. 그 러나 최근 지구온난화 문제로 온실가스 저감을 위한 국제적인 노력이 지속되고 있으며, 전력분야에서도 절연매 질인 육불화황(SF6) 가스를 대체할 수 있는 친환경 절연가스를 개발 및 적용 중이다. 예컨대, N2, CO2, 및 Dry air와 같은 친환경 절연가스와 육불화황(SF6) 가스 비율을 조절하여 사용하는 혼합가스에 대한 절연특성 연구가 진행되었지만, 순수 친환경 절연가스 보다 절연내력은 높지만 비율에 따라 지구온난화 지수가 여전히 높기 때문 에 환경적인 문제에서 완전히 벗어날 수 없는 기술적 한계가 있다. 다음으로, 부분 방전은 절연물 표면 오손 또는 내부 보이드와 같은 결함이 존재할 때 전기적인 스트레스에 의한 국부적인 전계 집중으로 발생하며, 일반적으로 빛, 열, 전자파, 소리 등의 다양한 현상이 수반된다. 이러한 부 분 방전 펄스는 1 s보다 짧은 형태로 크기도 매우 미소하다. 그러나 부분 방전이 지속될 경우 절연물이 열화되 어 결국 절연파괴에 이르게 된다. 따라서 친환경 절연가스를 사용하는 절연구조 및 해당 절연구조의 부분 방전진단을 위한 기술이 본 기술 분야에 서 절실한 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허공보 제10-1006019호 (특허문헌 0002) 대한민국 공개특허공보 제10-2021-0154015호\n【해결하려는 과제】\n본 발명은 상기와 같은 문제점을 해결하기 위한 것으로 친환경 절연가스를 사용하는 절연구조를 갖는 가스절연 개폐장치(GIS)에서 발생하는 부분 방전을 용이하게 파악할 수 있도록 UHF 센서로부터 측정된 전자파 신호 내 출 력전압의 단위가 인가 전하량의 단위로 환산되어 부분 방전의 크기가 연산되고, 전자파 신호 내 다수 개의 파라 미터가 뉴럴 네트워크를 적용한 역전파 알고리즘에 입력됨으로써 결함원인이 출력되는 친환경 절연가스 구조에 서 UHF 센서를 이용한 인공지능 기술기반 부분 방전 진단 방법 및 이를 수행하는 프로그램이 기록된 컴퓨터 판 독이 가능한 기록매체를 얻고자 하는 것을 목적으로 한다.본 발명이 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 본 발명의 기재로부터 당해 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있다.\n【과제의 해결 수단】\n상기 목적을 달성하기 위하여, 친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능 기술기반 부분 방전 진단 방법은 적어도 하나의 프로세서에 의하여, 친환경 절연가스 구조를 갖는 가스절연개폐장치(Gas-Insulated Switch Gear; GIS) 일측에 설치된 UHF(Ultra High Frequency) 센서로부터 측정된 전자파 신호가 획득되는 전자 파 신호 획득단계; 상기 적어도 하나의 프로세서에 의하여, 부분 방전의 크기가 판단될 수 있도록 기 저장된 환 산식이 이용되어 전자파 신호 내 출력전압의 단위가 인가 전하량의 단위로 환산되는 단위 환산단계; 상기 적어 도 하나의 프로세서에 의하여, 상기 전자파 신호로부터 기 선정된 다수 개의 파라미터가 획득되는 파라미터 획 득단계; 및 상기 적어도 하나의 프로세서에 의하여, 다수 개의 파라미터가 뉴럴 네트워크를 적용한 역전파 알고 리즘에 입력됨으로써, 결함원인이 출력되는 결함원인 출력단계;를 제공한다. 상기 목적을 달성하기 위하여, 본 발명은 친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능 기술기반 부분 방전 진단 방법을 수행하는 프로그램이 기록된 컴퓨터 판독이 가능한 기록매체를 제공한다.\n【발명의 효과】\n본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 상세한 설명 및 청구범위의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다.\n【발명을실시하기위한구체적인내용】\n본 명세서에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들 을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상 세히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가 지는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 다르게 정의되지 않는 한 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속 하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일반 적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 이하, 본 발명에 따른 실시예를 첨부한 도면을 참조하여 상세히 설명하기로 한다. 도 1은 친환경 절연가스 구조 에서 UHF 센서를 이용한 인공지능 기술기반 부분 방전 진단 방법 흐름도이다. 도 2는 본 발명의 일실시예에 따 른 친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능 기술기반 부분 방전 진단 방법 세부흐름도이다. 도 3 은 본 발명의 일실시예에 따른 뉴럴 네트워크를 적용한 역전파 알고리즘을 표시한 도면이다. 도 4는 본 발명의 일실시예에 따른 Labview 기반의 역전파 알고리즘으르 표시한 도면이다. 도 5는 본 발명의 일실시예에 따른 자유입자(FP)를 도시한 도면이다. 도 6은 본 발명의 일실시예에 따른 외함돌 출(POE)을 표시한 도면이다. 도 7은 본 발명의 일실시예에 따른 보이드(Void)를 표시한 도면이다. 도 8은 본 발명의 일실시예에 따른 크기 연산단계로부터 이용되는 자유입자(Free particle) 결함원인에 대한 환 산식을 표시한 도면이다. 도 9는 본 발명의 일실시예에 따른 크기 연산단계로부터 이용되는 도체돌출 (Protrusion on conductor) 결함원인에 대한 환산식을 표시한 도면이다. 도 10은 본 발명의 일실시예에 따른 크 기 연산단계로부터 이용되는 외함돌출(Protrusion on enclosure) 결함원인에 대한 환산식을 표시한 도면이다. 도 11은 본 발명의 일실시예에 따른 크기 연산단계로부터 이용되는 보이드(Void) 결함원인에 대한 환산식을 표 시한 도면이다. 도 12는 본 발명의 일실시예에 따른 단위 환산단계로부터 이용되는 환산식을 표시한 도면이다. 우선, 본 발명은 친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능 기술기반 부분 방전 진단 방법을 수행 하는 프로그램을 기록한 컴퓨터 장치로 읽을 수 있는 기록매체를 포함한다. 상기 기록매체는 예 컨대, CD, DVD, 하드디스크, 블루레이 디스크, USB, 메모리 카드, ROM 등일 수 있다. 그리고 친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능 기술기반 부분 방전 진단 방법은 컴퓨터 장치 내 적어도 하나의 프 로세서가 상기 기록매체를 읽음으로써 구현될 수 있다. 일반적으로 가스절연개폐장치(GIS)의 부분 방전은 절연물 표면 오손 또는 내부 보이드와 같은 결함이 존재할 때 전기적인 스트레스에 의한 국부적인 전계 집중으로 발생하며, 빛, 열, 전자파, 소리 등의 다양한 현상이 수반된 다. 이러한 부분 방전펄스는 1 s보다 짧은 형태로 크기도 매우 미소하나, 부분 방전이 지속될 경우 절연물이 열 화되어 결국 절연파괴에 이르게 된다. 종래 UHF 검출법은 UHF 센서를 사용하여 부분 방전을 검출할 수 있지만, 센서의 설치 위치, 부분 방전에 의해 발생된 전자파의 전파경로, 센서 타입 등 현장 상황에서 고려해야할 변수 가 많아 부분 방전 크기를 pC 단위로 교정할 수 없는 단점이 있다. 도 1을 보면, 친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능 기술기반 부분 방전 진단 방법은 pC 단위 의 부분 방전의 크기와 결함원인을 판별하기 위해서 전자파 신호 획득단계(S100), 단위 환산단계(S200), 파라미 터 획득단계(S300) 및 결함원인 출력단계(S400)를 포함한다. 우선, 상기 전자파 신호 획득단계(S100)는 적어도 하나의 프로세서에 의하여, 친환경 절연가스 구조를 갖 는 가스절연개폐장치(Gas-Insulated Switch Gear; GIS) 일측에 설치된 UHF(Ultra High Frequency) 센서로 부터 측정된 전자파 신호가 획득된다. 가스절연개폐장치(GIS) 내부 부분 방전 발생에 의해 방사된 300MHz-3GHz의 주파수 대역을 가지는 전자파가 가스절연개폐장치(GIS)의 외함을 따라 전파되며, 가스절연개폐장치(GIS)의 점검창 내부에 설치되는내장형 UHF 센서 또는 스페이서 외부에 설치되는 외장형 UHF 센서이 전파된 전자파 신호를 측정할 수 있다. 내장형 또는 외장형으로 설치된 UHF 센서은 설비에 인가된 높은 전압에 영향을 받지 않기 때문에 가 스절연개폐장치(GIS)의 상태를 실시간으로 감시할 수 있는 장점이 있다. 가장 바람직하게, 상기 전자파 신호 획득단계(S100)는 상기 UHF 센서로부터 실시간으로 상기 전자파 신호 가 획득될 수 있다. 상기 전자파 신호는 파형을 갖는 출력전압(mV)을 포함하거나, 파형을 갖는 출력전압(mV) 그 자체일 수 있다. 도 2의 일실시예를 보면, 상기 전자파 신호 획득단계(S100)는 상기 전자파 신호가 기 설정된 노이즈 레벨과 비 교되고, 기 설정된 노이즈 레벨이상인지 여부가 판단되는 노이즈 레벨 비교단계(S110)를 포함할 수 있다. 상기 노이즈 레벨 비교단계(S110)는 상기 전자파 신호가 노이즈 레벨보다 작다면 실제로 부분 방전이 발생한 것이 아 닌, 불특정한 원인으로 발생한 단순 노이즈인 것으로 판단되어 다음단계로 진행되지 않을 수 있다. 그리고 상기 전자파 신호 획득단계(S100)는 UHF 센서로부터 다시 상기 전자파 신호가 획득될 수 있다. 다음으로, 상기 단위 환산단계(S200)는 상기 적어도 하나의 프로세서에 의하여, 부분 방전의 크기가 판단 될 수 있도록 기 저장된 환산식이 이용되어 전자파 신호 내 출력전압 단위가 인가 전하량의 단위로 환산된다. 본 발명에서 언급하는 기 저장된 환산식은 mV-pC 환산식이다. 보다 구체적으로, 상기 단위 환산단계(S200)는 건 조 공기(Dry Air)와 g3 가스를 포함하는 친환경 절연가스를 대상으로 하기 [수학식 1]을 통해서 출력전압 단위가 인가 전하량의 단위로 환산되는 것을 특징으로 한다. 기 저장된 환산식은 도 12의 일실시예와 같이 UHF 센서로부터 측정된 출력전압과 IEC 60270법에서 측정된 방전 전하량의 관계로부터 도출된 수식이다. 전체 결함에 대한 환산식은 선형적이고 하기 [수학식 1]과 같다. 수학식 1 여기서, pC는 인가 전하량이고, mV는 출력전압이다. 상기 전자파 신호 획득단계(S100)로부터 획득된 전자파 신호만으로는 부분 방전 발생시키는 결함원인을 파악할 수 없다. 상기 기 저장된 환산식은 건조 공기(Dry Air)와 g3 가스를 포함하는 친환경 절연가스가 충전된 가스절 연개폐장치(GIS)에서 결함원인을 파악하지 못하더라도 상기 전자파 신호 내 출력전압의 단위가 인가 전하 량의 단위로 환산될 수 있는 식이다. 따라서 pC 단위의 인가 전하량이 용이하게 파악될 수 있는 현저한 효과가 있다. 도 2의 일실시예를 보면, 상기 단위 환산단계(S200)는 환산된 인가 전하량이 기 설정된 수치 이상인지 여부가 판단되는 인가 전하량 판단단계(S210)를 포함할 수 있다. 상기 인가 전하량 판단단계(S210)는 환산된 인가 전하 량이 기 설정된 수치, 예컨대 5pC 보다 크다면 실제로 부분 방전이 발생한 것으로 판단되어 다음단계로 진행될 수 있다. 반면에, 상기 인가 전하량 판단단계(S210)는 환산된 인가 전하량이 기 설정된 수치, 예컨대, 5pC 보다 작거나 같다면 앞서 전자파 신호가 노이즈 레벨 이상이지만 부분 방전이 발생하지 않고 단순한 노이즈가 발생한 것으로 판단될 수 있다. 향후 알림 제공단계(S600)로부터 지속적인 모니터링을 수행하라는 알림이 제공될 수 있 다. 다음으로, 상기 파라미터 획득단계(S300)는 상기 적어도 하나의 프로세서에 의하여, 상기 전자파 신호로부 터 기 선정된 다수 개의 파라미터가 획득될 수 있다. 상기 친환경 절연가스는 건조 공기(Dry Air)와 g3 가스를 포함할 수 있고, 상기 다수 개의 파라미터는 상승시간, 하강시간, 펄스폭, 주파수대역, 출력전압, 펄스수, 구간별 분포율을 포함하는 것을 특징으로 한다. 상기 전자파 신호는 출력 전압 파형을 갖는다. 따라서 본 발명에서 언급하는 상승시간은 ns 단위일 수 있고, 출 력 전압 파형에서 일정한 정상 상태의 값의 작은 비율에서 큰 비율로 상승하여 도달할 때까지 소요되는 시간이 다. 하강시간은 ns 단위일 수 있고, 출력 전압 파형에서 일정한 정상 상태의 값의 큰 비율에서 작은 비율로 하 강하여 도달할 때까지 소요되는 시간이다. 상기 펄스폭은 ns 단위일 수 있고, 상승 시간과 하강 시간에서 진폭이 1/2이 되는 시간의 간격이다. 상승시간과 펄스폭은 반비례 관계이다. 상기 상승시간이 길어짐에 따라 펄스폭은 좁아지고, 상기 상승시간이 짧아짐에 따라 펄스폭은 넓어질 수 있다. 상기 주파수대역은 MHz 단위일 수 있고, 상기 전자파 신호의 대역일 수 있다. 상기 출력전압은 mV 단위일 수 있 고, UHF(Ultra High Frequency) 센서로부터 출력되는 교류 전압이고, 상기 펄스수는 출력 전압 파형에서 볼 수 있는 전원 주파수의 상수배로 반복되는 진폭 변화 사이클 수이다. 상기 구간별 분포율은 0도 내지 360도가 30도 씩 분할된 구간에서 펄스수의 분포율을 일컫는다. 즉, 상기 파라미터 획득단계(S300)는 상기 전자파 신호로부터 출력할 수 있는 수많은 파라미터 중에서 기 선정 된 다수 개의 파라미터만이 획득되도록 한다. 이에 따라, 상기 파라미터 획득단계(S300)로부터 무분별한 파라미 터가 획득되지 않으므로 기록매체의 저장 공간이 확보될 수 있고, 신속한 처리가 가능한 현저한 효과가 있 다. 다음으로, 상기 결함원인 출력단계(S400)는 상기 적어도 하나의 프로세서에 의하여, 다수 개의 파라미터가 뉴럴 네트워크를 적용한 역전파 알고리즘에 입력됨으로써, 결함원인이 출력된다. 도 3의 일실시예를 보면, 상기 뉴럴 네트워크를 적용한 역전파 알고리즘은 입력층, 은닉층 및 츨력층 구조를 갖 는 뉴럴 네트워크를 포함할 수 있다. 상기 입력층은 다수 개의 파라미터(x1...xn), 은닉층은 다수 개의 뉴런 (z1...zn), 출력층은 다수 개의 결함원인(y1..yn)을 포함할 수 있다. 또한, 상기 뉴럴 네트워크를 적용한 역전파 알고리즘은 입력층, 은닉층 및 출력층 각 층의 뉴런의 활성화 여부 를 제어하고자 각 층에 바이어스가 연결되는 것을 특징으로 한다. 도 4의 일실시예를 보면, 상기 뉴럴 네트워크를 적용한 역전파 알고리즘은 적어도 하나의 프로세서에 의하 여, 그래픽 기반 프로그램밍 툴 중 하나인 랩뷰(Labview) 기반으로 구현될 수 있다. 한편, 본 발명은 적어도 하나의 프로세서에 의하여, 상기 뉴럴 네트워크를 적용한 역전파 알고리즘이 학습 되기 위해서 학습 단계(S700)를 더 포함할 수 있다. 상기 학습 단계(S700)는 친환경 절연가스가 건조 공기(Dry Air)와 g3 가스 중 하나로 구분되는 친환경 절연가스 구분단계(S710), 결함원인별 다수 개의 파라미터를 포함하 는 데이터셋이 배치되는 데이터셋 배치단계(S720), 데이터셋이 이용되어 결함원인(PD characteristics)별 특징 이 추출(Extraction)되는 특징 추출단계(S730) 및 뉴럴 네트워크 내 은닉층에 뉴런(Neuron)이 생성 (Generation)되는 뉴런 생성단계(S740)를 포함할 수 있다. 따라서 상기 학습 단계(S700)는 결함원인별 특징이 뉴럴 네트워크에 학습될 수 있고, 기 학습된 뉴럴 네트워크를 적용한 역전파 알고리즘이 생성될 수 있다. 상기 결함원인 출력단계(S400)는 기 학습된 뉴럴 네트워크를 적용한 역전파 알고리즘에 기 선정된 다수 개의 파 리미터가 입력되면 해당하는 결함원인에 대한 출력이 ‘1’, 해당하지 않는 결함원인에 대한 출력이 ‘0’으로 출력될 수 있다. 다시 도 3의 일실시예를 보면, 상기 다수 개의 파라미터(x1...xn)는 상승시간(x1), 하강시간(x2), 펄스폭(x3), 주파수대역(x4), 출력전압(x5), 펄스수(x6), 1도-30도 구간의 분포율(x7), 31도 내지 60도 구간의 분포율(x8), 61도 내지 90도 구간의 분포율(x9), 91도 내지 120도 구간의 분포율(x10), 121도 내지 150도 구간의 분포율 (x11), 151도 내지 180도 구간의 분포율(x12), 181도 내지 210도 구간의 분포율(x13), 211도 내지 240도 구간 의 분포율(x14), 241도 내지 270도 구간의 분포율(x15), 271도 내지 300도 구간의 분포율(x16), 301도 내지 330도 구간의 분포율(x17) 및 331도 내지 360도 구간의 분포율(x18)을 포함할 수 있다. 또한, 상기 다수 개의 뉴런(z1...zn)은 20개의 뉴런(z1...z20)일 수 있다. 상기 다수 개의 결함원인(y1..yn)은 자유입자(Free Particle; FP), 도체돌출(Protrusion On Conductor; POC), 외함돌출(Protrusion On Enclosure; POE) 및 보이드(Void)를 포함할 수 있다. 도 5의 일실시예를 보면, 상기 자유입자(Free Particle; FP)는 가스절연개폐장치(GIS)의 생산, 조립, 운송 과 스위칭 개폐동작 시 도전성 이물질이 가스절연개폐장치(GIS) 내부로 혼입되거나 내부의 금속입자가 분 리되어 발생하는 결함으로 입자의 크기, 모양, 위치에 따라서 유도되는 전하 분포가 결정될 수 있다. 입자 주변 에 높은 전계가 가해지면 전계의 영향 아래 입자는 가스절연개폐장치(GIS)의 외함을 따라 움직이기 시작하 며, 고압 도체에 도달할 경우 절연파괴가 발생할 수 있다. 다음으로, 도체돌출(Protrusion On Conductor; POC)은 가스절연개폐장치(GIS) 동작 중 전기적, 열적 스트 레스에 의해 내부 고압 도체의 변형이나 혼입된 입자가 부착되어 첨예한 형상을 가진 도체가 되고 그 부위에 전 계가 집중되면 코로나 방전이 발생된다. 도 6의 일실시예를 보면, 외함돌출(Protrusion On Enclosure; POE)은 도체돌출과 동일한 원인으로 발생되는 돌 출부 결함 원인 중 하나로, 가스절연개폐장치(GIS) 내부 외함에 첨예한 부위에 전계가 집중되어 부분 방전 이 발생할 수 있다. 외함돌출은 고압 도체에서 발생하는 도체 돌출과 비교하여 방전 발생 위치가 다르기 때문에 부분 방전 특성이 반대로 나타날 수 있다. 도 7의 일실시예를 보면, 가스절연개폐장치(GIS)에서 사용되는 스페이서는 도체를 지지하거나 내부 가스 구획을 구분하기 위해 설치되는 장치이다. 보이드(Void)는 스페이서를 제조하는 과정 중 절연물인 에폭시를 경 화하는 동안에 공기가 삽입되어 발생하는 결함이다. 오랜 기간 동안 스페이서 내 보이드가 존재하는 경우, 전기 적 트리가 나타나고 결국 절연파괴가 발생하게 된다. 한편, 상기 결함원인 출력단계(S400)는 뉴럴 네트워크를 적용한 역전파 알고리즘을 통해서 자유입자(FP), 도체 돌출(POC), 외함돌출(POE) 및 보이드(Void) 중 하나로 결함원인이 출력되지 않는다면 정의가 불가능한 결함원인 으로 판단될 수 있다. 그리고 본 발명의 알림 제공단계(S600)를 통해서 관리자로부터 지속적인 모니터링이 가능 하도록 관리자 단말에 알림이 제공될 수 있다. 다음으로, 친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능 기술기반 부분 방전 진단 방법은 상기 적어도 하나의 프로세서에 의하여, 상기 결함원인 출력단계(S400)로부터 결함원인이 출력되면 기 저장된 결함원인 별 환산식이 이용되어 부분 방전 크기가 연산되는 부분 방전 크기 연산단계(S500) 및 상기 적어도 하나의 프로 세서에 의하여, 상기 결함원인 및 부분 방전 크기를 포함하는 알림이 관리자 단말에 제공되는 알림 제공단 계(S600)를 더 포함하는 것을 특징으로 한다. 상기 크기 연산단계(S500)는 상기 결함원인 출력단계(S400)로부터 결함원인이 자유입자(FP)로 출력된다면, 기 저장된 자유입자(FP) 환산식이 이용되어 부분 방전 크기가 연산될 수 있다. 환산식은 도 8의 일실시예와 같이 UHF 센서로부터 측정된 출력전압과 IEC 60270법에서 측정된 방전 전하량의 관계로부터 도출된 수식이다. 자유입자(FP)에 의한 결함은 방전 크기가 40-80pC에서 가장 많이 분포하고, 이때, UHF 센서에서는 약 300- 500mV의 출력을 가지는 것이 확인되었다. 기 저장된 자유입자(FP) 환산식은 선형적이고 하기 [수학식 2]와 같다. 수학식 2 여기서, 여기서, pC는 인가 전하량이고, mV는 출력전압이다. 또한, 상기 크기 연산단계(S500)는 상기 결함원인 출력단계(S400)로부터 결함원인이 도체돌출(POC)로 출력된다 면, 기 저장된 도체돌출(POC) 환산식이 이용되어 부분 방전 크기가 연산될 수 있다. 환산식은 도 9의 일실시예 와 같이 UHF 센서로부터 측정된 출력전압과 IEC 60270법에서 측정된 방전 전하량의 관계로부터 도출된 수 식이다. 도체돌출(POC)에 의한 결함은 방전 크기가 10-40pC에서 가장 많이 분포하고, 이때, UHF 센서에서 는 약 25-70mV의 출력을 가지는 것이 확인되었다. 기 저장된 도체돌출(POC) 환산식은 선형적이고 하기 [수학식 3]과 같다. 수학식 3 여기서, 여기서, pC는 인가 전하량이고, mV는 출력전압이다. 또한, 상기 크기 연산단계(S500)는 상기 결함원인 출력단계(S400)로부터 결함원인이 외함돌출(POE)로 출력된다 면, 기 저장된 외함돌출(POE) 환산식이 이용되어 부분 방전 크기가 연산될 수 있다. 환산식은 도 10의 일실시예와 같이 UHF 센서로부터 측정된 출력전압과 IEC 60270법에서 측정된 방전 전하량의 관계로부터 도출된 수 식이다. 외함돌출(POE)에 의한 결함은 방전 크기가 30-60pC에서 가장 많이 분포하고, 이때, UHF 센서에서 는 약 25-60mV의 출력을 가지는 것이 확인되었다. 기 저장된 외함돌출(POE) 환산식은 선형적이고 하기 [수학식 4]와 같다. 수학식 4 여기서, 여기서, pC는 인가 전하량이고, mV는 출력전압이다. 또한, 상기 크기 연산단계(S500)는 상기 결함원인 출력단계(S400)로부터 결함원인이 보이드(Void)로 출력된다면, 기 저장된 보이드(Void) 환산식이 이용되어 부분 방전 크기가 연산될 수 있다. 환산식은 도 11의 일실시예와 같이 UHF 센서로부터 측정된 출력전압과 IEC 60270법에서 측정된 방전 전하량의 관계로부터 도 출된 수식이다. 보이드(Void)에 의한 결함은 방전 크기가 60-100pC에서 가장 많이 분포하고, 이때, UHF 센서 에서는 약 170-320mV의 출력을 가지는 것이 확인되었다. 기 저장된 보이드(Void) 환산식은 선형적이고 하 기 [수학식 5]와 같다. 수학식 5 여기서, 여기서, pC는 인가 전하량이고, mV는 출력전압이다. 다음으로, 상기 알림 제공단계(S600)는 상기 결함원인 및 부분 방전 크기를 포함하는 알림이 관리자 단말에 제 공될 수 있다. 상기 결함원인 출력단계(S400)로부터 자유입자(FP), 도체돌출(POC), 외함돌출(POE) 및 보이드 (Void) 중 하나로 결함원인이 도출된다면, 상기 알림 제공단계(S600)는 관리자에게 가스절연개폐장치(GIS)(20 0)의 내부검사 또는 유지보수를 권장 및 경고하는 알림이 관리자 단말에 시각적 또는 청각적으로 제공될 수 있 다. 또한, 앞서 언급한 것과 같이 상기 단위 환산단계(S200)로부터 환산된 인가전하량이 기 설정된 수치 미만이 라면, 상기 알림 제공단계(S600)는 관리자에게 노이즈에 대한 지속적인 모니터링을 권유하는 알림이 관리자 단 말에 시각적 또는 청각적으로 제공될 수 있다. 또한, 앞서 언급한 것과 같이 상기 결함원인 출력단계(S400)로부 터 결함원인 중 어떠한 결함원인에도 해당되지 않아 정의가 불가능한 것으로 출력된다면, 상기 알림제공단계 (S600)는 관리자에게 정의 불가능한 결함원인이 존재하고 있으므로 지속적인 모니터링을 권유하는 알림이 고나 리자 단말에 시각적 또는 청각적으로 제공될 수 있다. 따라서 본 발명에 의하면, 인공지능 기술기반으로 UHF 센서로부터 획득된 전자파 신호를 분석함으로써, 친 환경 절연가스 구조를 갖는 가스절연개폐장치(GIS)에서 발생하는 부분 방전의 결함원인을 용이하게 파악할 수 있는 현저한 효과가 있다. 또한, 본 발명은 출력전압과 인가 전하량 간의 상관관계를 갖는 환산식을 구비함으로써, 친환경 절연가스 구조 를 갖는 가스절연개폐장치(GIS)에서 발생하는 부분 방전의 크기를 pC 단위로 용이하게 파악할 수 있는 현 저한 효과가 있다. 또한, 본 발명은 관리자 단말에 결함원인별 알림이 제공될 수 있으므로, 가스절연개폐장치(GIS)에 절연파 괴가 발생하기 전에 유지보수가 가능하여 2차적인 사고를 예방할 수 있는 현저한 효과가 있다. 실시예들은 하드웨어, 소프트웨어, 펌웨어, 미들웨어, 마이크로코드, 하드웨어 기술 언어, 또는 이들의 임의의 조합에 의해 구현될 수 있다. 소프트웨어, 펌웨어, 미들웨어 또는 마이크로코드로 구현되는 경우, 필요한 작업 을 수행하는 프로그램 코드 또는 코드 세그먼트들은 컴퓨터 판독 가능 저장 매체에 저장되고 하나 이상의 프로 세서에 의해 실행될 수 있다. 그리고 본 명세서에 설명된 주제의 양태들은 컴퓨터에 의해 실행되는 프로그램 모듈 또는 컴포넌트와 같은 컴퓨 터 실행 가능 명령어들의 일반적인 맥락에서 설명될 수 있다. 일반적으로, 프로그램 모듈 또는 컴포넌트들은 특 정 작업을 수행하거나 특정 데이터 형식을 구현하는 루틴, 프로그램, 객체, 데이터 구조를 포함한다. 본 명세서 에 설명된 주제의 양태들은 통신 네트워크를 통해 링크되는 원격 처리 디바이스들에 의해 작업들이 수행되는 분 산 컴퓨팅 환경들에서 실시될 수도 있다. 분산 컴퓨팅 환경에서, 프로그램 모듈들은 메모리 저장 디바이스들을 포함하는 로컬 및 원격 컴퓨터 저장 매체에 둘 다에 위치할 수 있다. 이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 으로 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달 성될 수 있다. 그러므로 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.\n【요약】본 발명은 친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능 기술기반 부분 방전 진단 방법 및 이를 수행하 는 프로그램이 기록된 컴퓨터 판독이 가능한 기록매체에 관한 것으로, 보다 구체적으로, 친환경 절연가스 구조를 갖는 가스절연개폐장치(Gas-Insulated Switch Gear; GIS) 일측에 설치된 UHF(Ultra High Frequency) 센서로부터 (뒷면에 계속)\n\n【청구항 1】\n적어도 하나의 프로세서에 의하여, 친환경 절연가스 구조를 갖는 가스절연개폐장치(Gas-Insulated Switch Gear;GIS) 일측에 설치된 UHF(Ultra High Frequency) 센서로부터 측정된 전자파 신호가 획득되는 전자파 신호 획득단계;상기 적어도 하나의 프로세서에 의하여, 부분 방전의 크기가 판단될 수 있도록 기 저장된 환산식이 이용되어 전자파 신호 내 출력전압의 단위가 인가 전하량의 단위로 환산되는 단위 환산단계;상기 적어도 하나의 프로세서에 의하여, 상기 전자파 신호로부터 기 선정된 다수 개의 파라미터가 획득되는 파라미터 획득단계; 및상기 적어도 하나의 프로세서에 의하여, 다수 개의 파라미터가 뉴럴 네트워크를 적용한 역전파 알고리즘에 입력됨으로써, 결함원인이 출력되는 결함원인 출력단계;를 포함하는 친환경 절연가스 구조에서 UHF 센서를 이용한인공지능 기술기반 부분 방전 진단 방법.\n【청구항 2】\n제1 항에 있어서,상기 단위 환산단계는,건조 공기(Dry Air)와 g3 가스를 포함하는 친환경 절연가스를 대상으로 하기 [수학식 1]을 통해서 출력전압 단위가 인가 전하량의 단위로 환산되는 것을 특징으로 하는 친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능기술기반 부분 방전 진단 방법.[수학식 1]여기서, pC는 인가 전하량이고, mV는 출력전압이다.\n【청구항 3】\n제1 항에 있어서,상기 적어도 하나의 프로세서에 의하여, 상기 결함원인 출력단계로부터 결함원인이 출력되면 기 저장된 결함원인별 환산식이 이용되어 부분 방전 크기가 연산되는 부분 방전 크기 연산단계; 및상기 적어도 하나의 프로세서에 의하여, 상기 결함원인 및 부분 방전 크기를 포함하는 알림이 관리자 단말에 제공되는 알림 제공단계;를 더 포함하는 것을 특징으로 하는 친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능 기술기반 부분 방전 진단 방법.\n【청구항 4】\n제1 항에 있어서,상기 친환경 절연가스는,건조 공기(Dry Air)와 g3 가스를 포함하고, 상기 다수 개의 파라미터는,상승시간, 하강시간, 펄스폭, 주파수대역, 출력전압, 펄스수 및 구간별 분포율을 포함하는 것을 특징으로 하는친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능 기술기반 부분 방전 진단 방법.공개특허 10-2024-0120778-3-청구항 5 제1항 내지 제4항 중 어느 한 항의 친환경 절연가스 구조에서 UHF 센서를 이용한 인공지능 기술기반 부분 방전진단 방법을 수행하는 프로그램을 기록한 컴퓨터 장치로 읽을 수 있는 기록매체."}
{"context": "", "input": "【기술명】\n표적 객체의 형상을 식별하는 방법 및 이를 수행하는 인공지능 기반 가스 누출 탐지 시스템\n\n【기술 설명】\n본 발명은 인공지능 기반의 가스 누출 탐지 시스템으로, 전자 장치와 카메라를 활용하여 연기 및 가스와 같은 표적 객체의 형상을 실시간으로 식별하는 방법을 제안합니다. 이 시스템은 제1 타입 및 제2 타입의 다양한 카메라 영상을 동시에 수집하고, 수집된 영상 데이터를 인공지능 알고리즘에 입력하여 객체 인식을 수행합니다. 이를 통해 가스 및 연기의 형상 정보를 정확하게 식별하고, 누출 원점을 효과적으로 탐지할 수 있는 기능을 갖추고 있습니다.\n\n【해결 문제】\n가스 누출은 산업 현장 및 일상 생활에서 인체에 치명적일 수 있는 위험 요소로, 신속하고 정확한 탐지가 필수적입니다. 기존의 가스 탐지 기술은 센서 및 카메라를 활용하나, 그로 인한 정확도 및 실시간 모니터링의 한계로 인해 안전사고 발생 가능성이 존재합니다. 본 발명은 이러한 문제를 해결하기 위해 인공지능 기술을 적용하여, 보다 정밀하고 신뢰할 수 있는 가스 누출 탐지를 제공함으로써 유해 가스의 누출로 인한 안전사고를 예방하는 데 기여합니다.\n\n【기술 차별성】\n본 발명의 차별성은 기존 기술들이 단순한 센서 기반의 탐지 시스템에 의존하는 반면, 인공지능 기반의 복합적인 영상 분석을 통해 표적 객체의 형상을 실시간으로 식별할 수 있다는 점에 있습니다. 특히, 제1 타입과 제2 타입의 카메라를 동시에 활용하여 다양한 각도와 조건에서 수집된 영상을 종합적으로 분석함으로써, 가스 및 연기의 탐지 정확성을 획기적으로 향상시킵니다. 이러한 혁신적인 접근 방식은 가스 누출 탐지 분야에서의 기술적 진보를 이루어내며, 안전사고 예방에 있어 필수적인 역할을 수행할 것입니다.\n\n【활용 분야】\n본 발명은 인공지능 기반 가스 누출 탐지 시스템으로, 산업 안전, 환경 보호 및 스마트 빌딩 관리 분야에서 광범위하게 활용될 수 있습니다. 특히, 화학 공장, 정유소, 발전소와 같은 고위험 산업에서는 가스 누출로 인한 사고를 예방하고 신속하게 대응할 수 있는 필수적인 시스템으로 자리 잡을 것입니다. 또한, 상업용 및 주거용 건물의 스마트 모니터링 시스템과 결합하여 실시간으로 가스 누출을 감지하고 이에 따른 경고를 제공함으로써 안전성을 크게 향상시킬 수 있습니다.\n\n【구성 요소 및 기능】\n본 발명은 세 가지 주요 구성 요소로 이루어져 있습니다. 첫째, 제1 타입 카메라는 모니터링 대상 공간을 고해상도로 촬영하여 영상 정보를 수집하며, 이는 가스 및 연기 같은 표적 객체의 초기 탐지에 기여합니다. 둘째, 제2 타입 카메라는 적외선이나 열 감지를 통해 가스 누출의 형상을 더욱 정교하게 분석할 수 있으며, 이로 인해 가스의 종류와 성질을 식별하는 데 도움을 줍니다. 셋째, 객체 인식 모델은 수집된 제1 및 제2 타입 영상을 분석하여 표적 객체가 검출되는지를 판단하며, 이를 통해 가스 누출의 원점 및 확산 경로를 실시간으로 추적할 수 있는 기능을 제공합니다.\n\n【구현 방식 예】\n본 발명을 구현하기 위한 단계는 다음과 같습니다. 우선, 적어도 하나의 제1 타입 카메라를 설치하여 모니터링 대상 공간의 영상을 획득합니다. 이후, 제2 타입 카메라를 통해 추가적인 영상 정보를 수집하며, 이 두 영상 데이터는 인공지능 기반 객체 인식 모델에 입력됩니다. 모델은 입력된 영상을 분석하여 표적 객체의 존재 여부를 판단하고, 이를 바탕으로 가스 누출 위치를 정확하게 식별합니다. 최종적으로, 이러한 정보는 사용자에게 경고 및 알림 형태로 전달되어 즉각적인 대응을 가능하게 합니다.", "output": "【발명의 명칭】\n표적 객체의 형상을 식별하는 방법 및 이를 수행하는 인공지능 기반 가스 누출 탐지 장치\n【기술분야】\n본 개시는 인공지능 기반 가스 누출 탐지를 위한 전자 장치 및 상기 전자 장치가 연기, 가스와 같은 표적 객체 의 형상을 식별하는 방법에 관한 것이다. 보다 상세하게는, 인공지능 기반 가스 누출 탐지를 위한 전자 장치가 인공지능 기반 유해가스를 실시간으로 영상화하고 탐지하기 위해 연기, 가스 객체를 형상화하는 방법에 관한 것 이다.\n【배경기술】\n산업현장이나 생활 주변에서 사용되는 여러 종류의 가스 중 인체에 치명적이거나 폭발성을 띄는 가스누출의 탐 지는 매우 중요하며, 2차적인 안전사고로 확대되는 것을 방지하기 위해 실시간 모니터링이 필요하다. 특히, 저 탄장에서 발생하는 매탄, 암모니아 저장탱크 또는 가스 배관에서 발생하는 암모니아와 같은 가스의 경우 시각적 으로 확인하기가 어렵기 때문에 이러한 가스의 누출을 사전에 탐지하여 안전 사고를 예방할 필요가 있다. 그러나, 종래 가스 경보 및 탐지를 위한 기술의 경우 가스 센서, 비디오 카메라를 활용하는 일부 기술들을 개시 하나, 가스의 탐지 및 추적의 정확도에 한계가 있으며, 경보장치와 연동되어 현장 내부의 가스 누출을 모니터링하고 누출 원점을 탐지하는데 인력을 활용하는 경우가 많아 사고 대처에 미흡한 한계가 있다. 따라서, 미리 설 정된 가스, 연기 및 불꽃과 같은 표적 객체를 효과적으로 탐지하고 관리하기 위한 기술 개발이 요구되고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-2355884호\n【해결하려는 과제】\n일 실시 예에 의하면, 인공지능 기반 유해 가스 실시간 영상화 탐지 시스템 및 이의 동작 방법이 제공될 수 있 다. 보다 상세하게는, 상기 시스템에 사용될 수 있는 인공지능 기반 가스 누출을 탐지하는 전자 장치 및 상기 인공 지능 기반 가스 누출을 탐지하는 전자 장치가 표적 객체의 형상을 식별하는 방법이 제공될 수 있다.\n【과제의 해결 수단】\n상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하 는 전자 장치가 표적 객체의 형상을 식별하는 방법은 상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메 라로부터 모니터링 대상 공간에 대한 제1 타입 영상들을 획득하는 단계; 상기 전자 장치와 연결된 적어도 하나 의 제2 타입의 카메라로부터 상기 모니터링 대상 공간에 대한 제2 타입 영상들을 획득하는 단계; 및 상기 제1 타입 영상들 및 상기 제2 타입 영상들이 입력되면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 표적 객 체가 검출되는지 여부를 식별하는 객체 인식 모델에, 상기 제1 타입 영상들 및 상기 제2 타입 영상들을 입력함 으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체 검출 여부를 식별하는 단계; 를 포 함할 수 있고, 상기 표적 객체는 연기 객체, 가스 객체 또는 불꽃 객체 중 적어도 하나를 포함할 수 있다. 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 또 다른 실시 예에 의하면, 인공지능 기반 가스 누출 을 탐지를 위해, 표적 객체의 형상을 식별하는 전자 장치에 있어서, 네트워크 인터페이스; 하나 이상의 인스트 럭션을 저장하는 메모리; 및 상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서; 를 포함하고, 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간에 대한 제1 타입 영상들을 획득하고, 상기 전자 장치와 연 결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간에 대한 제2 타입 영상들을 획득하고, 상 기 제1 타입 영상들 및 상기 제2 타입 영상들이 입력되면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 표적 객체가 검출되는지 여부를 식별하는 객체 인식 모델에, 상기 제1 타입 영상들 및 상기 제2 타입 영상들을 입력함으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체 검출 여부를 식별하고, 상기 표적 객체는 연기 객체, 가스 객체 또는 불꽃 객체 중 적어도 하나를 포함하는 것을 특징으로 하는, 전자 장치 가 제공될 수 있다. 또한, 상술한 기술적 과제를 달성하기 위한 기술적 수다능로서, 또 다른 실시 예에 의하면, 인공지능 기반 가스 누출을 탐지하는 전자 장치가 표적 객체의 형상을 식별하는 방법에 있어서, 상기 전자 장치와 연결된 적어도 하 나의 제1 타입의 카메라로부터 모니터링 대상 공간에 대한 제1 타입 영상들을 획득하는 단계; 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간에 대한 제2 타입 영상들을 획득하는 단계; 및 상기 제1 타입 영상들 및 상기 제2 타입 영상들이 입력되면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 표적 객체가 검출되는지 여부를 식별하는 객체 인식 모델에, 상기 제1 타입 영상들 및 상기 제2 타입 영상들을 입력함으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체 검출 여부를 식별하 는 단계; 를 포함하고, 상기 표적 객체는 연기 객체, 가스 객체 또는 불꽃 객체 중 적어도 하나를 포함하는 것 을 특징으로 하는, 방법을 수행하도록 하는 프로그램이 저장된 컴퓨터로 읽을 수 있는 기록 매체가 제공될 수있다.\n【발명의 효과】\n일 실시 예에 의하면 가스 객체의 형상을 정확하게 식별할 수 있다. 일 실시 예에 의하면 가스 객체의 형상 정보를 식별하고, 식별된 형상 정보에 기초하여 가스 객체의 누출 원점 을 효과적으로 탐지할 수 있다.\n【발명을실시하기위한구체적인내용】\n본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해 서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치 및 상기 인공지능 기반 가스 누출을 탐지하는 전자 장치를 포함하는 인공지능 기반 가스 누출 탐지 시스템의 동작 과정을 개략적으로 설명하기 위한 도면이다. 일 실시 예에 의하면 인공지능 기반 가스 누출을 탐지하는 전자 장치(이하에서는 '전자 장치'로 명명)는 적어도 하나의 타입의 카메라 및 레이저 측정기를 포함하는 카메라 설치셋으로부터 모니터링 대상 공간에 대한 영상 정보들을 획득하고, 획득된 영상들을 인공지능 모델에 입력함으로써, 획득된 영상들 내에 연기, 가스 또는 불꽃 중 적어도 하나를 포함하는 표적 객체가 있는지 여부를 결정할 수 있다. 일 실시 예에 의하면 전자 장치는 적어도 하나의 타입의 카메라들로부터 적어도 하나의 타입에 따른 복수의 영상들을 인공지능 모델에 입력하고, 인공 지능 모델의 출력 값에 기초하여, 가스 객체, 연기 객체 또는 불꽃 객체 중 적어도 하나 를 포함하는 표적 객체가 검출되는 경우, 표적 객체의 형상 정보를 추출하고, 추출된 형상 정보에 기초하여 표 적 객체를 모델링 및 추적할 수 있다. 본 명세서에서 인공지능 기반 가스 누출 탐지 시스템 또는 전자 장치가 탐지하는 표적 객체는 가스 객체, 가스가 공기 중에서 기체상태로 유동함에 따라 가스 입자 및 공기 입자가 일체가 된 상태의 연기 객체, 가스가 연소함에 따라 생성되는 불꽃 객체 중 적어도 하나를 포함할 수 있다. 일 실시 예에 따른 가스 객체, 연 기 객체, 불꽃 객체는 가시광선 또는 상기 가시광선과 다른 파장 대의 전자기파(예컨대 적외선 등)를 통해 감지 될 수 있다. 일 실시 예에 의하면, 전자 장치가 카메라 설치셋으로부터 획득하는 영상 정보는 저탄장, 암모니아 배관이 설치된 작업 현장을 EO 카메라 또는 OGI 카메라 중 적어도 하나를 이용하여 촬영함으로써 획득되는 가시 광선 영상 또는 적외선 영상들일 수 있다. 또한, 가시광선 영상 및 적외선 영상들은 미리 설정된 프레임 간격을 가지는 복수의 가시광선 프레임 이미지들 및 복수의 적외선 프레임 이미지들을 포함할 수 있다. 일 실시 예에 의하면, 전자 장치는 영상 정보들을 분석한 결과, 표적 객체가 검출되는 것으로 식별 되는 경우, 경보 장치가 시각적 또는 청각적 컨텐츠를 출력하도록 하는 제어 신호를 전송함으로써 가스 누 출과 같은 위험한 상황이 발생하였다는 사실을 작업자들에게 효과적으로 전달할 수 있다. 일 실시 예에 의하면, 전자 장치는 모니터링 대상 공간에 인접하게 설치되는 관제 단말과 연결될 수도 있다. 일 실시 예에 의하면, 전자 장치는 관제 단말로 영상 정보 및 레이저 측정값들을 전달하거나, 전자 장치 (10000가 인공 지능 모델을 이용하여 영상 정보를 분석한 결과(예컨대 표적 객체 검출 여부, 표적 객체에 대한 형상 정보, 누출 원점, 가스 누출 여부, 가스 종류에 대한 정보)를 관제 단말로 전송할 수도 있다. 일 실시 예에 의하면, 관제 단말은 카메라 설치셋과 직접 연결될 수도 있으며, 전자 장치 또는 카메라 설치셋으로부터 획득되는 영상 정보들을 직접 저장함과 함께, 획득된 영상 정보들을 출력할 수 있 다. 또한, 관제 단말은 전자 장치에 포함된 메모리, 프로세서 및 네트워크 인터페이스에 대응되는 구성들을 포함하고, 획득된 영상 정보들을 가스 누출 탐지를 위한 인공지능 모델에 입력함으로써, 표적 객체가 식별되는지 여부, 가스 누출과 같은 이벤트가 탐지되었는지 여부, 표적 객체의 형상 정보들을 결정할 수 있고, 표적 객체 검출과 같은 이벤트가 발생되는 경우 경보 장치로 직접 경고 컨텐츠 출력을 위한 제어 신호를 전송하거나, 표적 객체에 대한 정보들을 디스플레이 장치(예컨대 관제 단말용 모니터)를 통해 직접 출력할 수도 있다. 일 실시 예에 의하면 관제 단말은 인공지능 기반 가스 영상 서버, 경보/제어 서버 및 쿨링 시스템을 포함할 수 있으나, 이에 한정되는 것은 아니며, 작업 현장 내 연산이 필요한 자산에 대한 효율적 처리를 위한 MEC(Multi Access Edge Computing) 서버를 더 포함할 수도 있다. 또한, 관제 단말은 멀티 이더넷 장치를 통해 외부의 여러 장비들과 실시간으로 연결될 수도 있다. 일 실시 예에 의하면, 관제 서버는 카메라 설치셋, 전자 장치, 관제 단말 또는 경보 장치 중 적어도 하나와 연결됨으로써 가스 누출 탐지 시스템내 구성들의 동작을 제어할 수 있다. 예를 들어, 관제 서버는 전자 장치로부터 모니터링 대상 공간에 대한 영상 정보들, 표적 객체 검출 에 따른 표적 객체에 대한 정보(예컨대 종류, 누출 원점, 실제 카메라 설치셋으로부터의 물리적 위치 정보) 및 합성 영상을 획득하고, 획득된 영상 정보들, 표적 객체에 대한 정보 및 합성 영상을 디스플레이상에 출력할 수 있다. 관제 서버는 수집된 데이터들을 통합 관리함으로써 모니터링 대상 공간에 대한 관리를 용이하게 할 수 있다. 또한, 일 실시 예에 의하면, 관제 서버는 모니터링 대상 공간에 대한 영상 정보들, 합성 영상 및 표적 객 체에 관한 정보를 출력함과 함께, 가스 누출 탐지 및 관리를 위한 사용자 인터페이스를 화면상에 출력할 수 있 다. 관제 서버는 출력된 사용자 인터페이스에 대한 관제자들의 사용자 입력에 기초하여 가스 누출 탐지 시 스템내 장치들의 동작을 제어함으로써, 가스 누출 시 해당 가스 누출 원점에 대한 모니터링이 지속되도록할 수 있다. 또한, 일 실시 예에 의하면, 전자 장치는 레이저 측정값과 카메라 설치셋의 팬틸트 정보에 기초하여, 추적된 표적 객체에 대해 생성되는 누출 영상의 파노라마 영상에 대한 좌표를 결정하고, 결정된 좌표 에 기초하여 표적 객체에 관한 누출 영상을 파노라마 영상에 합성함으로써 합성 영상을 생성하며, 원 영상 정보, 누출 원점, 좌표 정보, 누출 영상 및 합성 영상에 대한 정보를 관제 단말 또는 관제 서버 중 적어도 하나로 전송함으로써, 관제자로 하여금 누출된 표적 가스에 대한 모니터링이 용이하도록 할 수 있다. 또한, 일 실시 예에 의하면, 전자 장치는 영상 정보를 분석한 결과, 표적 객체에 관한 누출 영상의 파노 라마 영상에 대한 영상 상에서의 위치 뿐만 아니라, 실제 누출 원점에 대한 물리적 공간에 대한 위치 정보를 관 제 단말, 관제 서버로 더 전송할 수도 있다. 예를 들어, 전자 장치는 카메라 설치셋의 레 이저 측정기로부터 레이저 측정값을 획득하고, 획득된 레이저 측정값과 미리 결정된 카메라 설치셋의 위치 정보에 기초하여 카메라 설치셋으로부터 실제 표적 객체가 발생한 물리적 거리 및 상기 실제 표적 객체가 발생한 물리적 공간상에서의 위치를 식별하고, 식별된 물리적 거리 및 위치에 대한 정보를 관제 서버로 제 공함으로써 관제자로 하여금 표적 객체가 누출된 위치를 정확하게 인지하도록 할 수 있다. 또한, 일 실시 예에 의하면 인공지능 기반 가스 누출을 탐지하는 전자 장치는 카메라 설치셋으로부 터 획득된 영상 정보들을 인공 지능 모델에 입력함으로써 분석한 결과, 표적 객체가 검출되는 것으로 식별되는 경우, 소정의 이벤트가 발생한 것으로 결정하고, 경보 장치로 제어 신호를 전송함으로써 시각적 또는 청각 적 경고 컨텐츠들이 출력되도록 할 수 있다. 일 실시 예에 의하면, 전자 장치는 가스 누출 탐지를 위해 필요한 소프트웨어 모듈들(예컨대 가스 누출 탐지를 위한 하나 이상의 인스트럭션 집합들)을 저장할 수 있고, 프로세서는 상기 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써 가스 누출 탐지 프로세스를 수행할 수 있다. 또한, 네트워크 인터페이 스는 전자 장치와 연결된 다른 전자 장치들로부터 데이터를 획득하건, 전송하는 기능을 수행할 수 있다. 일 실시 예에 의하면, 도 1에 도시된 가스 누출 탐지 시스템은 카메라 설치셋, 전자 장치, 경보 장치, 관제 단말 및 관제 서버를 포함할 수 있으며, 가스 누출 탐지를 위한 기타 장치를 더 포 함할 수도 있다. 또한, 일 실시 예에 따른 가스 누출 탐지 시스템 내 장치들은 적어도 하나의 네트워크를 통해 서로 연결될 수 있다. 일 실시 예에 따른 가스 누출 탐지 시스템내 장치들 사이의 데이터 전송 시 미 리 설정된 데이터 손실률(예컨대 5% 미만) 및 미리 설정된 데이터 전송 주기(예컨대 1초 미만)에 따라 데이터들 이 전송될 수 있으나, 이에 한정되는 것은 아니다. 일 실시 예에 의하면 적어도 하나의 네트워크는 근거리 통신망(Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 부가가치 통신망(Value Added Network; VAN), 이동 통신망(mobile radio communication network), 위성 통신망, 각 네트워크 구성 주체들이 통신을 할 수 있도록 하는 포괄적 의미의 데이터 통신망 및 이들의 상호 조합을 포함할 수 있다. 본 개시에 따른 가스 누출 탐지 시스템 및 전자 장치는 광범위한 저탄장 모니터링 시스템에 사용되거 나, 대량의 암모니아 저장 탱크/가스배관이 설치된 공간의 모니터링 시스템에 사용될 수 있으나, 이에 한정되는 것은 아니며, 가스 객체, 연기 객체 또는 불꽃 객체 중 적어도 하나를 포함하는 표적 객체들의 추적 및 모니터 링이 필요한 작업 현장에 사용될 수 있다. 도 2는 또 다른 실시 예에 따른 인공지능 기반 가스 누출 탐지 시스템의 동작 과정을 나타내는 도면이다. 도 2를 참조하여 또 다른 실시 예에 따른 인공지능 기반 가스 누출 탐지 시스템의 동작 과정을 설명하기로 한다. 일 실시 예에 의하면 인공지능 기반 가스 누출 탐지 시스템은 카메라 설치셋, AI 가스영상 탐지 서버, 경보/제어 서버, 가스 누출 알람 및 경보 장치 및 관제 단말기, 상황실 영상 시스템 을 포함할 수 있다. 일 실시 예에 의하면 카메라 설치셋은 가스 이미징 카메라(예컨대 Optical Gas Imaging, OGI 카메라), EO 카메라(예컨대 Electro-Optical, EO) 및 레이저 측정기를 포함할 수 있다. 일 실시 예에 의하면 가스 이미징 카메라는 물체에서 방출되는 적외선 복사 에너지를 전자적으로 센싱함으 로써, 눈에 보이지 않는 가스 객체들에 대한 이미지 또는 미리 설정된 프레임 간격의 복수의 이미지들을 포함하 는 적외선 영상을 생성하는 카메라일 수 있다. 또한, 일 실시 예에 의하면, EO 카메라는 물체에서 반사되는 가시 광선을 이미지 센서를 통해 센싱함으로써 가시 광선 이미지 또는 미리 설정된 프레임 간격의 복수의 가시광 선 이미지들을 포함하는 가시광선 영상을 생성하는 카메라일 수 있다. 일 실시 예에 의하면 레이저 측정기는 레이저를 방출하고, 방출된 레이저가 대상 객체에 반사됨에 따른 시 간을 측정함으로써 레이저 측정기 또는 카메라 설치셋으로부터 대상 객체까지의 거리 값을 나타내는 레이저 측정 값을 획득할 수 있다. 카메라 설치셋은 적외선 영상들, 가시광선 영상들 및 레이저 측정 값을 가스 누출 탐지 시스템내 적어도 하나의 장치들로 전송할 수 있다. 일 실시 예에 의하면, 가스 이미징 카메 라 및 EO 카메라의 촬영 화각, 촬영 주기는 서로 다르게 설정될 수 있으며, 가스 이미징 카메라 및 EO 카메라가 적외선 영상들 및 가시광선 영상들을 전송하는 동작 조건은 사용자 입력 조건에 따라 미리 설정될 수 있다. 일 실시 예에 의하면, AI 가스 영상 탐지 서버는 카메라 설치셋으로부터 획득된 영상들에 나타나는 표적 객체를 탐지하고, 탐지된 표적 객체의 누출 원점을 식별하며, 표적 객체에 대한 누출 영상을 파노라마 영 상에 합성함으로써 시각화하는 기능을 수행할 수 있다. 일 실시 예에 의하면, 경보/제어 서버는 표적 객체 검출에 따른 이벤트 발생이 탐지되면 가스누출 알람 및 경보 신호를 경보 장치로 전송할 수 있다. 또한, 경보/ 제어 서버는 카메라 설치셋에서 획득되는 영상 정보들, 상기 표적 객체에 관한 누출 영상 및 합성 영 상들을 저장할 수 있다. 또한, 경보/제어 서버는 사용자 입력에 기초하여 저장된 영상들에 대한 검색 기능, 가스 누출 탐지 시스템 내 장치 동작 환경을 설정하기 위한 환경설정 기능, 가스 누출 탐지 시스템내 장치들의 동작 제어를 위 한 동작 제어 기능을 제공할 수도 있다. 일 실시 예에 의하면 경보/제어 서버는 TCP/IP를 통해 이벤트 발 생 신호 데이터를 경보 장치 또는 상황실 영상 시스템으로 송수신할 수 있다. 관제 단말기의 동작은 도 1에 도시된 관제 단말의 동작에 대응될 수 있으므로 구체적인 설명은 생략 하기로 한다. 상황실 영상 시스템은 도 2에 도시된 바와 같이, 표적 객체가 검출되는 경우, 표적 객체에 대한 누출 영상을 파노라마 영상에 합성함으로써 생성되는 합성 영상을 출력할 수 있다. 상황실 영상 시스템 의 동작은 도 1에 도시된 관제 서버의 동작에 대응될 수 있으므로 구체적인 설명은 생략하기로 한다. 도 3은 일 실시 예에 따른 인공지능 기반 가스 누출 탐지 시스템의 동작 방법을 나타내는 흐름도이다. 도 3을 참조하여 일 실시 예에 따른 인공지능 기반 가스 누출 탐지 시스템의 동작 방법을 설명하기로 한다. 도 3에 도시된 인공지능 기반 가스 누출 탐지 시스템의 동작은 도 1에 도시된 전자 장치에 의해서도 수행될 수도 있음은 물론이다. S302에서, 가스 누출 탐지 시스템은 EO 영상 및 OGI 영상을 획득할 수 있다. 예를 들어, 가스 누출 탐지 시 스템은 적어도 하나의 EO 카메라 및 적어도 하나의 OGI 카메라로부터 복수의 EO 영상들 및 OGI 영상들을 획 득할 수 있다. S304에서, 가스 누출 탐지 시스템은 S304에서 획득된 영상들을 객체 인식 모델에 입력 할 수 있다. 예를 들어, 가스 누출 탐지 시스템은 적어도 하나의 EO 카메라로부터 획득된 EO 영상 및 적어 도 하나의 OGI 카메라로부터 획득된 OGI 영상들을 객체 인식 모델에 입력할 수 있다. 도 3에는 도시되지 않았지만, 일 실시 예에 의하면 가스 누출 탐지 시스템은 EO 영상 및 OGI 영상을 획득하 고, 획득된 EO 영상 및 OGI 영상에 대한 이진화, 리사이징, 노멀라이즈(Normalize), 데이터 증강(Data Augmentation) 와 같은 전처리 과정을 수행할 수 있다. 가스 누출 탐지 시스템은 전처리된 EO 영상 및 OGI 영상들을 객체 인식 모델에 입력함으로써 객체 인식 정확도를 향상시킬 수 있다. S306에서, 가스 누출 탐지 시스템은 S302에서 객체 인식 모델의 출력 값에 기초하여 영상들로부터 표적 객 체가 검출되는지 여부를 식별할 수 있다. 일 실시 예에 의하면, 객체 인식 모델은 카메라 영상들이 입력되 면 가스 객체, 연기 객체 또는 불꽃 객체 중 적어도 하나에 관한 표적 객체 또는 상기 표적 객체를 적어도 일부 에 포함하는 객체 후보 영역을 출력하도록 미리 학습되는 인공지능 모델일 수 있다. 일 실시 예에 의하면, 객체 인식 모델은 손실(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 수정 및 갱신되 는 신경망 모델일 수 있다. 예를 들어, 객체 인식 모델은 가스 객체, 불꽃 객체 또는 연기 객체에 대한 이미지 또는 영상 학습 데이터에 기 초하여 학습됨으로써, 영상 또는 이미지 내 가스 객체, 불꽃 객체 또는 연기 객체를 적어도 일부에 포함하는 객 체 후보 영역을 출력함과 함께, 객체 후보 영역 내 표적 객체에 대한 픽셀 정보, 객체 후보 영역의 이미지상에서의 좌표 정보를 함께 출력하도록 마련될 수 있다. 예를 들어, 객체 인식 모델은 CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네 트워크 (Deep Q-Networks) 일 수 있으나, 이에 한정되는 것은 아니다. 또한, 객체 인식 모델은 EO 영상들 또는 OGI 영상들 내 픽셀 값에 기초하여, 소정의 객체 후보 영역이 표적 객체에 대응될 확률 값을 결정하고, 결 정된 확률 값에 기초하여 소정의 우선 순위에 따른 객체 후보 영역을 출력하도록 학습되는 YOLO, R-CNN, SSD 와 같은 객체 컴퓨터 비전 모델일 수 있다. S308에서, 가스 누출 탐지 시스템은 객체 인식 모델을 이용하여 EO 영상들 및 OGI 영상들로부터 표적 객체 가 검출되지 않는 것으로 식별되는 경우, OGI 영상을 주파수 변환함으로써 변환 영상 정보를 생성할 수 있다. 예를 들어, 가스 누출 탐지 시스템은 객체 인식 모델을 이용하여 표적 객체가 검출되지 않는 것으로 1차적 으로 식별되는 경우, 적외선 영상인 OGI 영상에 DFT 이산 푸리에 변환을 적용함으로써 주파수 도메인의 변환 영 상 정보를 생성할 수 있다. 일 실시 예에 의하면 변환 영상 정보는 주파수 별 크기 및 위상 정보를 포함하는 주 파수 패턴을 포함할 수 있다. S310에서, 가스 누출 탐지 시스템은 변환 영상 정보가 입력되면 표적 객체에 따른 주파수 패턴이 존재하는 지 여부를 식별하는 우도비 검정 모델에 변환 영상 정보를 입력함으로써 표적 객체에 따른 주파수 패턴을 분석할 수 있다. S312에서, 가스 누출 탐지 시스템은 우도비 검정 모델을 변환 영상 정보에 적용함에 따라 우도비 검정 모델의 출력 값에 기초하여, 표적 객체에 따른 주파수 패턴이 식별되는지 여부를 결정할 수 있다. S314에서, 가스 누출 탐지 시스템은 우도비 검정 모델을 이옹한 결과 변환 영상 정보로부터 표적 객체에 따 른 주파수 패턴이 식별되지 않는 경우, SVM 모델(예컨대 서포트 벡터 머신 모델, Support Vector Machine)을 변환 영상 정보에 적용함으로써, 변환 영상 정보 내 표적 객체에 따른 주파수 패턴을 재 분석한다. S316에서, 가스 누출 탐지 시스템은 SVM 모델의 출력 값에 기초하여 변환 영상 정보 내 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별할 수 있다. S322에서, 가스 누출 탐지 시스템은 S306에서 객체 인식 모델에 EO 영상들 및 OGI 영상들을 입력한 결과 표 적 객체가 검출되는 것으로 결정되는 경우, 표적 객체가 검출된 EO 영상들 또는 표적 객체가 검출된 OGI 영상들 내 표적 객체를 배경과 분리할 수 있다. 예를 들어, 가스 누출 탐지 시스템은 검출된 표적 객체 정보에 기 초하여 마스킹 데이터를 생성하고, 생성된 마스킹 데이터를 EO 영상들 및 OGI 영상들에 적용함으로써 표적 객체 영역들을 분리할 수 있다. S324에서, 가스 누출 탐지 시스템은 분리된 표적 객체 영역으로부터 객체의 형상을 검출할 수 있다. 예를 들어, 가스 누출 탐지 시스템은 표적 객체 영역 내 외곽선 정보, 중심점 정보, 방향 벡터를 표적의 객체 형 상 정보로 출력할 수 있다. S326에서, 가스 누출 탐지 시스템은 표적 객체 영역들에 나타나는 형상 정보에 기초하여 표적 객체가 생성된 위치에 관한 누출 원점 및 상기 표적 객체의 흐름 방향과 속도에 관한 흐름 벡터 를 결정할 수 있다. S328에서, 가스 누출 탐지 시스템은 누출 원점 및 흐름 벡터에 기초하여 거리좌표 및 구면 좌표를 식별하고, 식별된 좌표에 따라 결정되는 위치 정보들을 변환할 수 있다. 구체적으로, 가스 누출 탐지 시스템 은 누출 원점 및 흐름 벡터에 기초하여 영상에서 표적 객체가 식별되는 것으로 결정된 위치에 레이저를 송 수신함으로써 레이저 측정 값을 획득하고, 획득된 레이저 측정값에 기초하여 카메라 설치셋으로부터 누출 원점 까지의 거리를 획득할 수 있다. 또한, 가스 누출 탐지 시스템은 해당 누출 원점을 모니터링하는 카메라 설 치셋의 팬틸트 정보를 획득할 수 있다. 본 개시에 따른 가스 누출 탐지 시스템은 카메라 설치셋으로부터 누출 원점까지의 거리 및 카메라 팬틸트 정보에 기초하여 구면 좌표계에서의 제1 좌표 값을 결정할 수 있다. 가스 누출 탐지 시스템은 결정된 구면 좌표계에서 제1 좌표 값을 직교 좌표계의 제2 좌표 값으로 변환하고, 직교 좌표계로 변환된 제2 좌표 값에 카메 라 왜곡 값을 반영함으로써 제3 좌표 값을 생성할 수 있다. 가스 누출 탐지 시스템은 제 3 좌표 값에 기초 하여, 표적 객체가 발생한 누출 영상의 파노라마 영상에 대한 기준 위치를 식별하고, 식별된 기준 위치에 따라 누출 영상을 파노라마 영상에 합성할 수 있다. S330에서, 가스 누출 탐지 시스템은 제3 좌표 값에 기초하여, 파노라마 영상에 누출 영상을 합성함으로써 합성 영상을 생성할 수 있다. S332에서, 가스 누출 탐지 시스템은 합성 영상을 저장하고, 저장된 합성 영상을 가스 누출 탐지 시스템에 대한 사용자 입력에 기초하여 출력할 수 있다. 일 실시 예에 의하면 가스 누출 탐지 시스템은 저장된 합성 영상에 액세스하는 사용자 입력에 기초하여 저장된 합성 영상의 적어도 일부를 검색 및 검색된 합성 영상의 일부를 재생할 수 있다. 도 4는 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 표적 객체 검출 여부를 식별하는 방법의 흐름도이다. S410에서, 전자 장치는 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간 에 대한 제1 타입 영상들을 획득할 수 있다. 예를 들어, 제1 타입의 카메라는 EO 카메라를 포함하고, 제1 타입 영상들은 미리 설정된 프레임 간격을 가지는 가시광선 영상들일 수 있다. S420에서, 전자 장치는 전자 장 치와 연결된 적어도 하나의 제2 타입의 카메라로부터 모니터링 대상 공간에 대한 제2 타입 영상들을 획득할 수 있다. 예를 들어, 제2 타입의 카메라는 OGI 카메라이고, 제2 타입 영상들은 미리 설정된 프레임 간격의 복수의 적외선 이미지들을 포함하는 적외선 영상일 수 있다. 일 실시 예에 의하면, 전자 장치가 연결되는 제1 타 입의 카메라 및 제2 타입의 카메라의 모니터링 대상 공간에 대한 화각, 이미지 획득 주기와 같은 촬영 파라미터 는 서로 다르게 마련될 수 있다. S430에서, 전자 장치는 제1 타입 영상들 및 상기 제2 타입 영상들이 입력되면, 제1 타입 영상들 및 상기 제2 타입 영상들 내 표적 객체가 검출되는지 여부를 식별하는 객체 인식 모델에 제1 타입 영상들 및 제2 타입 영상들을 입력함으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 표적 객체 검출 여부를 식별할 수 있다. 일 실시 예에 의하면, 객체 인식 모델은 가시 광선 영상들 및 적외선 영상들 각각으로부터 가스 객체, 연 기 객체 또는 불꽃 객체 중 적어도 하나에 관한 표적 객체를 적어도 일부에 포함하는 객체 후보 영역을 출력하 도록 미리 학습되는 인공지능 모델일 수 있다. 객체 인식 모델은 공지의 손실함수를 이용하여 손실(loss) 값 또 는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 수정 및 갱신되는 신경망 모델로 표적 객체를 포함하는 객체 후보 영역을 구성하는 픽셀의 이미지상 좌표 정보, 외곽선 정보, 객체 후보 영역의 바운더리를 나타내는 경계 정보, 인식된 표적 객체의 종류 정보를 출력할 수 있다. 일 실시 예에 의하면, 전자 장치의 영상 정보들에 대한 객체 인식 정확도는 70% 이상일 수 있으나, 이에 한정되는 것은 아니며, 후술하는 적어도 하나의 인공 지능 모델을 이용한 가스 누출의 인식 정확도는 99% 이상 일 수 있으나, 역시 이에 한정되는 것은 아니다. 또한, 도 4에는 도시되지 않았지만, 전자 장치는 적어도 하나의 인공 지능 모델을 통해 제1 타입 영상들 및 제2 타입 영상들에서 표적 객체가 검출되는지 여부를 식별하 고, 식별된 표적 객체를 미리 설정된 해상도 및 영상 속도로 추적 및 모니터링할 수 있다. 도 4에는 도시되지 않았지만, 일 실시 예에 따른 전자 장치는 제1 타입 영상들 및 제2 타입 영상들 중 적 어도 하나로부터 표적 객체가 검출되는 것으로 식별되는 경우, 표적 객체가 검출된 타입의 영상들로부터 표적 객체의 형상 정보를 추출할 수 있다. 전자 장치가 표적 객체의 형상 정보를 추출하는 구체적인 방법은 후 술하는 도 7 내지 도 9를 참조하여 구체적으로 설명하기로 한다. 도 5는 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 주파수 패턴에 따라 식별되는 표적 객체의 형상 정보를 추출하는 과정을 나타내는 도면이다. S510에서, 전자 장치는 객체 인식 모델의 출력 값에 기초하여, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체가 검출되지 않는 것으로 식별되는 경우, 제2 타입 영상들을 푸리에 변환함으로써 주 파수 도메인상의 변환 영상 정보를 생성할 수 있다. 예를 들어, 전자 장치는 객체 인식 모델을 이용하여 1차적으로 제1 타입 영상들 및 제2 타입 영상들로부터 표적 객체가 검출되지 않는 것으로 식별되는 경우, 적외 선 영상들인 제2 타입 영상들을 이산 푸리에 변환(discrete Fourier transform, DFT)함으로써 주파수 도메인 상의 변환 영상 정보를 생성할 수 있다. 도 5에는 도시되지 않았지만, 또 다른 실시 예에 의하면, 전자 장치 는 제2 타입 영상들을 전처리하고 전처리된 제2 타입 영상들을 푸리에 변환함으로써 주파수 도메인상의 변환 영상 정보들을 생성할 수도 있다. S520에서, 전자 장치는 변환 영상 정보로부터 표적 객체 및 표적 객체 주변의 배경 간섭 물질 각각에 대 한 스펙트럼 정보를 추출할 수 있다. 예를 들어, 변환 영상 정보는 주파수 도메인상에서 특정 파장 영역대에 기 초하여 표적 객체를 나타내는 스펙트럼 정보를 포함할 수 있다. 일 실시 예에 의하면, 스펙트럼 정보는 주파수 별 크기(Magnitude) 및 위상(Phase) 정보를 포함할 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 변환 영상 정보 내 표적 객체와 표적 객체 주변의 배경 간섭물질 각각에 대한 스펙트럼 정보를 추출할 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 표적 객체 및 배경 간섭물질을 구분하지 않고, 변환 영상 정보로 부터 주파수 별 크기 및 위상에 대한 스펙트럼 정보를 추출할 수 있다. S530에서, 전자 장치는 추출된 스펙트럼 정보가 입력되면 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 출력하는 우도비 검정 모델에, 상기 추출된 스펙트럼 정보를 입력함으로써, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별할 수 있다. 예를 들어, 전자 장치는 표적 객체의 주파수 패턴을 분류하는 우도비 검정 모델을 미리 학습시키고, 학습된 우도비 검정 모델을 소정의 조건 에서 변환 영상 정보에 적용함으로써 객체 인식 모델과 함께 표적 객체를 효과적으로 검출할 수 있다. 본 개시에 따른 전자 장치는 객체 인식 모델로부터 표적 객체가 검출되는 것으로 식별되지 않는 경우, 적 외선 영상으로부터 나타나는 스펙트럼 정보의 주파수 패턴을 우도비 검정 모델을 이용하여 제1 타입 영상들 및 제2 타입 영상들 내 표적 객체가 검출되는지 여부를 재 식별함으로써 표적 객체 검출 정확도를 향상시킬 수 있 다. 도 5에는 도시되지 않았지만, 전자 장치는 우도비 검정 모델을 이용하여 재 식별 결과 표적 객체가 검출되는 것으로 식별되는 경우 우도비 검정 모델의 출력 값에 따라 표적 객체가 검출된 영상들에서 표적 객체 영역을 분리하기 위한 마스킹 데이터 생성과정을 수행하게 된다. S540에서, 전자 장치는 표적 객체에 따른 주파수 패턴이 식별되는 경우, 우도비 검정 모델의 출력 값에 기초하여 제2 타입 영상들로부터 표적 객체의 형상 정보를 추출할 수 있다. 예를 들어, 전자 장치는 우도 비 검정 모델의 출력 값에 기초하여 표적 객체에 따른 주파수 패턴이 변환 영상 정보 내에서 식별되는 경우, 표 적 객체가 검출된 것으로 결정하고, 제2 타입 영상들로부터 표적 객체의 형상에 관한 형상 정보를 추출하게 된 다. 전자 장치가 형상 정보를 추출하는 방법은 후술하는 도 7 내지 9를 참조하여 설명하기로 한다. 도 6은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 주파수 패턴에 따라 식별되는 표적 객체의 형상 정보를 추출하는 과정을 나타내는 도면이다. S610에서, 전자 장치는 우도비 검정 모델의 출력 값에 기초하여 상기 표적 객체에 따른 주파수 패턴이 식 별되지 않는 경우, 상기 추출된 스펙트럼 정보를, 상기 추출된 스펙트럼 정보가 입력되면 상기 표적 객체에 따 른 주파수 패턴이 있는지 여부를 출력하는 서포트 벡터 머신 모델에 입력함으로써, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별할 수 있다. 즉, 본 개시에 따른 전자 장치는 객체 인식 모델을 이용한 결과 제1 타입 영상들 및 제2 타입 영상들에서 표적 객체가 검출되지 않는 경우, 우도비 검정 모델 및 서포트 벡터 머신 모델을 이용하여 표적 객체가 검출되 는지 여부를 재식별함으로써 표적 객체의 검출 정확도를 향상시킬 수 있다. 전자 장치는 서포트 벡터 머 신 모델을 이용한 결과 표적 객체에 따른 주파수 패턴이 식별되는 것으로 결정되는 경우, 서포트 벡터 머신 모 델의 출력 값에 따라 표적 객체가 검출된 영상들에서 표적 객체 영역을 분리하기 위한 마스킹 데이터 생성과정 을 수행하게 된다. 본 개시에 따른 전자 장치는 변환 영상 정보로부터 추출된 스펙트럼 정보가 입력되면, 표적 객체의 주파 수 패턴을 분류하는 서포트 벡터 머신 모델을 미리 학습시키고, 학습된 서포트 벡터 머신 모델을 소정의 조건에 서 변환 영상 정보에 적용함으로써, 객체 인식 모델 및 우도비 검정 모델과 함께 표적 객체를 정확하게 검출할 수 있다. S620에서, 전자 장치는 표적 객체에 따른 주파수 패턴이 식별되는 경우, 상기 서포트 벡터 머신 모델의 출력 값에 기초하여, 상기 제2 타입 영상들로부터 상기 표적 객체의 형상 정보를 추출할 수 있다. 전자 장치 가 형상 정보를 추출하는 방법은 후술하는 도 7 내지 9를 참조하여 구체적으로 설명하기로 한다. 상술한 도 4 내지 도 6에서 상술한 바와 같이, 전자 장치는 객체 인식 모델, 우도비 검정 모델 또는 서포트 벡터 머신 모델 중 적어도 하나를 이용하여 적어도 하나의 타입의 영상들을 분석함으로써 표적 객체가 검출되는지 여 부를 정확하게 식별할 수 있을 뿐만 아니라, 적외선 영상을 주파수 도메인 상의 변환 영상 정보로 생성하고, 변 환 영상 정보에서 나타나는 소정의 주파수 별 주파수 패턴에 기초하여, 검출된 표적 객체의 종류(예컨대 메탄인 지, 암모니아인지, 일반 연기인지, 불꽃 인지)를 함께 식별할 수 있다. 도 7은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 표적 객체의 형상 정보를 추출하는 구체적인 방법의 흐름도이다. S710에서, 전자 장치는 표적 객체가 검출된 타입의 영상들을 전처리할 수 있다. 예를 들어, 전자 장치 는 도 3 내지 6에서 상술한 바와 같이, 객체 인식 모델과 변환 영상 정보에 대한 우도비 검정 모델 또는 서포트 벡터 머신 모델을 미리 설정된 조건에 따라 이용함으로써 제1 타입 영상들 및 제2 타입 영상들 중 적어 도 하나로부터 표적 객체가 검출되는지 여부를 식별하고, 표적 객체가 검출되는 것으로 식별되는 경우, 표적 객 체가 검출되는 타입의 영상들을 전처리(예컨대 이진화, 노멀라이즈, Augmentation 등)한다. S720에서, 전자 장치는 기 설정된 표적 객체 정보에 기초하여 마스킹 데이터를 생성할 수 있다. 예를 들 어, 전자 장치는 표적 객체에 대한 정보를 미리 저장할 수 있다. 일 실시 예에 의하면, 표적 객체에 대한 정보는 가스 객체, 연기 객체 또는 불꽃 객체들이 영상들 내 프레임 이미지들 사이에서 이동하는 정도에 관한 이동 평균 값들을 미리 저장할 수 있으며, 표적 객체에 대한 정보에 기초하여 마스킹 데이터를 생성할 수 있다. 구체적으로 도 7에는 도시되지 않았지만, 전자 장치는 표적 객체가 검출된 타입의 영상들의 현재 프레임 이미지 이전의 프레임 이미지들에 대한 이동 평균 값을 결정하고, 결정된 이동 평균 값에 기초하여 마스킹 데이 터를 생성할 수 있다. 예를 들어, 전자 장치는 표적 객체가 검출된 타입의 영상들의 현재 프레임 이전의 프레임 이미지들 세트에 대해 이동 평균값을 결정하고, 결정된 이동 평균값에 기초하여 배경 모델을 생성하며, 생성된 배경 모델을 현재 프레임 이미지에서 제거(예컨대 빼기)하기 위한 마스킹 데이터를 생성한다. 본 개시의 일 실시 예에 따른 전자 장치는 Running average background subtraction 기법을 이용하여 마스킹 데이 터를 생성할 수 있다. S730에서, 전자 장치는 표적 객체가 검출된 타입의 영상들에 마스킹 데이터를 적용함으로써 생성되는 표 적 객체 영역들을, 전처리된 영상들로부터 분리할 수 있다. 전자 장치는 새로운 프레임 이미지들이 획득 될 때마다 모든 프레임 이미지들의 이동 평균값을 지속적으로 수정 및 갱신하며, 수정 및 갱신된 이동 평균값에 기초하여 생성된 마스킹 데이터를 현재 프레임 이미지에 적용함으로써 표적 객체 영역들을 전처리된 영상들로부 터 분리할 수 있다. S740에서, 전자 장치는 분리된 표적 객체 영역들로부터 표적 객체의 형상 정보를 추 출한다. 전자 장치가 형상 정보를 추출하는 과정은 후술하는 도 8 내지 도 9를 더 참조하여 추가 설명하 기로 한다. 도 8은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 표적 객체의 형상을 식별하고 이를 추적하는 과정을 설명하기 위한 도면이다. 도 8을 참조하여 전자 장치가 형상 정보를 추출하는 방법을 더 구체적으로 설명하기로 한다. 그림 을 참조하면, 전자 장치가 도 7에서 상술한 방법에 따라 표적 객체가 검출된 타입의 영상들을 구성하는 전체 프레임 이미지들 또는 현재 프레임 이미지들 이전의 모든 프레임 이미지들로부터 이동 평균 값을 결 정하고, 결정된 이동 평균 값에 기초하여 결정된 마스킹 데이터를 현재 프레임 이미지에 적용함으로 써 현재 프레임 이미지로부터 표적 객체 영역을 분리하는 과정이 도시된다. 전자 장치는 분리된 표적 객체 영역 내 표적 객체에 관한 외곽선 정보를 식별하고, 외곽선 정보에 기초하 여 상기 표적 객체의 중심점 정보를 식별할 수 있으며, 식별된 중심점 정보 및 상기 외곽선 정보에 기초하여 표 적 객체 영역의 방향 벡터를 식별할 수 있다. 본 개시에 따른 전자 장치는 표적 객체가 검출된 타입의 영 상을 구성하는 프레임 이미지마다 상기 외곽선 정보, 중심점 정보 및 방향 벡터를 상기 표적 객체의 형상 정보 로 추출할 수 있다. 본 개시에 따른 전자 장치는 표적 객체가 검출된 타입의 영상들 내 인접하는 프레임 이미지들에서 분리된 표적 객체의 형상 정보에 기초하여 모션 벡터를 결정할 수 있다. 전자 장치는 그림 에 도시된 바와 같이, 표적 객체가 검출된 타입 내 영상들로부터 결정되는 모션 벡터를 이용하여, 표적 객체가 검출된 타입의 영상들 내 표적 객체 영역들을 모델링할 수 있다. 전자 장치는 그림 에 도시된 바와 같이, 표 적 객체를 모델링하는데 사용된 모션 벡터들의 합벡터를 식별할 수 있고, 상기 합벡터의 크기 및 방향에 기초하 여 표적 객체가 생성된 위치에 관한 누출 원점 및 표적 객체의 흐름 방향과 속도에 관한 흐름 벡터를 결정할 수 있다. 도 9는 또 다른 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 표적 객체의 형상 정보를 추 출하는 방법의 흐름도이다. S910에서, 전자 장치는 분리된 표적 객체 영역 내 표적 객체에 관한 외곽선 정보를 식별할 수 있다. 예를 들어, 전자 장치는 마스킹 데이터를 적용함에 따라 분리된 표적 객체 영역을 구성하는 픽셀들의 좌표를 식별할 수 있고, 식별된 픽셀들의 좌표 값에 기초하여 최외곽 픽셀들의 좌표세트를 결정할 수 있다. 전자 장치 는 최외곽 픽셀들의 좌표세트에 기초하여 표적 객체에 관한 외곽선 정보를 식별할 수 있다. S920에서, 전자 장치는 외곽선 정보에 기초하여 표적 객체의 중심점 정보를 식별할 수 있다. 예를 들어, 전자 장치는 외곽선 정보에 기초하여 결정되는 표적 객체의 경계 내부의 픽셀 값들에 Mean Shift 알고리 즘을 적용하거나, 기타 이동하는 표적 객체의 중심점을 찾기 위한 객체 추적 알고리즘을 적용함으로써 표적 객 체의 중심점 정보를 식별할 수 있다. S930에서, 전자 장치는 중심점 정보 및 외곽선 정보에 기초하여 표 적 객체 영역의 방향 벡터를 식별할 수 있다. 예를 들어, 전자 장치는 표적 객체가 검출된 타입의 영상들 내 각 프레임 이미지마다 표적 객체 영역을 분리하고, 분리된 표적 객체 영역으로부터 추출된 형상 정보들 중, 인접한 프레임 이미지들(예컨대 연속한 2개의 프레임 번호를 가지는 이미지들)에서 추출된 형상 정보들에 기초 하여 모션 벡터를 결정할 수 있다. 전자 장치는 표적 객체가 검출된 타입 내 영상들 중, 인접한 프레임 번호를 가지는 프레임 이미지들 사이 에서 결정되는 모션 벡터를 이용하여 표적 객체를 모델링할 수 있으며, 표적 객체를 모델링하는데 사용된 모션 벡터의 합벡터의 방향과 동일한 방향의 방향 벡터를 식별할 수 있다. S940에서, 전자 장치는 상술한 과정 에서 결정된 외곽선 정보, 중심점 정보 및 방향 벡터를 표적 객체의 형상 정보로 추출할 수 있다. 도 10은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 표적 객체의 누출 원점 및 흐름 벡터를 결정하는 구체적인 방법의 흐름도이다. S1010에서, 전자 장치는 분리된 표적 객체 영역들의 형상 정보에 기초하여, 표적 객체가 검출된 타입의 영상들 내 인접하는 표적 객체 영역들 사이의 모션 벡터를 결정할 수 있다. 예를 들어, 도 9에서 상술한 바와 같이, 전자 장치는 표적 객체가 검출된 타입의 영상들 내 인접하는 프레임 이미지들(예컨대 연속하는 프 레임 번호를 가지는 2개의 프레임 이미지들) 사이에서 각 이미지들의 분리된 표적 객체의 형상 정보에 기초하여 모션 벡터를 결정할 수 있다. S1020에서, 전자 장치는 모션 벡터에 기초하여 분리된 표적 객체 영역들을 모델링할 수 있다. S1030에서, 전자 장치는 모델링된 표적 객체 영역들을 나타내는 모션 벡터들의 합벡터를 결정할 수 있다. 예를 들어, 전자 장치는 영상들로부터 상기 표적 객체에 관하여 나타나는 모션 벡터들에 대해 기하학적 벡터합을 수 행함으로써 합벡터를 결정할 수 있다. S1040에서, 전자 장치는 상기 결정된 합벡터의 크기 및 방향에 기초하여, 표적 객체가 검출된 영상들에서, 표적 객체가 생성된 위치에 관한 누출 원점 및 상기 표적 객체의 흐름 방향과 속도에 관한 흐름 벡 터를 결정할 수 있다. 예를 들어, 전자 장치는 상기 합벡터의 시작점을 누출원점으로 결정하고, 상기 시 작점으로부터 종점까지 상기 합벡터가 나타내는 방향을 흐름 벡터의 방향으로 결정할 수 있다. 또한, 전자 장치 는 시작점으로부터 종점까지의 거리를 표적 객체의 속도의 크기를 흐름 벡터의 크기로 결정할 수 있다. 전자 장치는 상술한 방법으로 결정된 크기 및 방향을 가지는 흐름 벡터를 결정할 수 있다. 도 11은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 가스 누출의 탐지를 위한 합성 영 상을 생성하는 방법의 흐름도이다. S1110에서, 전자 장치는 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간 에 대한 제1 타입 영상들 및 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간에 대한 제2 타입의 영상들을 획득할 수 있다. 일 실시 예에 의하면, 상기 제1 타입의 카메라 및 상기 제2 타입의 카메라는 각각 EO(Electro-Optical) 카메라 및 OGI(Optical Gas Imaging) 카메라를 포함하고, 상기 제1 타입 영상들 및 상기 제2 타입 영상들은 각각 가시광선 영상들 및 적외선 영상들을 포함할 수 있다. S1110 은 도 4의 S410 내지 S420에 대응될 수 있으므로 구체적인 설명은 생략하기로 한다. S1120에서, 전자 장치는 제1 타입 영상들 또는 상기 제2 타입 영상들 중 적어도 하나로부터 표적 객체가 검출되는 것으로 식별되는 경우, 상기 검출된 표적 객체에 관한 제1 타입 영상들 및 상기 검출된 표적 객체에관한 상기 제1 타입 영상들에 대응되는 제2 타입 영상들을 합성함으로써 누출 영상을 생성할 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 제1 타입 영상들 또는 상기 제2 타입 영상들 중 표적 객체가 검출된 하나 의 타입의 영상들을 누출 영상으로 생성할 수도 있다. S1130에서, 전자 장치는 누출 영상의 미리 획득된 파노라마 영상에 대한 좌표에 기초하여 누출 영상을 파 노라마 영상에 합성함으로써 합성 영상을 생성할 수 있다. 예를 들어, 전자 장치는 모델링된 표적 객체의 모션 벡터들의 합벡터에 기초하여 누출원점을 결정하고, 결정된 누출 원점에 대한 레이저 측정값 및 카메라 설 치셋의 팬틸트 정보에 기초하여 상기 누출 원점의 파노라마 영상에 대한 좌표를 결정할 수 있다. 전자 장치 는 상기 좌표 값에 기초하여 누출 영상을 파노라마 영상에 합성함으로써 합성 영상을 생성할 수 있다. 도 12는 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 생성한 누출 영상 및 상기 누출 영상을 파노라마 영상에 합성하는 과정을 설명하기 위한 도면이다. 전자 장치는 모니터링 대상 공간을 촬영함으로써 적어도 하나의 EO 카메라 및 적어도 하나의 OGI 카메라 와 연결될 수 있다. 전자 장치는 그림 에 도시된 바와 같이, 획득된 제1 타입 영상들 및 제2 타입 영상들을 합성함으로써 누출 영상을 생성할 수 있다. 예를 들어, 누출 영상은 모니터링 대상 공간에 대한 영상으로 검출된 표적 객체(예컨대 가스 객체, 연기 객체 또는 불꽃 객체) 영역 및 배경 영역을 포함 할 수 있다. 전자 장치는 그림 에 도시된 바와 같이, 누출 영상의 파노라마 영상에 대한 좌표를 결정하고, 결정된 좌표 값에 기초하여 누출 영상을 파노라마 영상에 합성함으로써 합성 영상을 생성할 수 있다. 전자 장치는 생성된 합성 영상을 직접 출력하거나, 전자 장치와 연결된 관제 단말 또는 관제 서버 로 전송함으로써 모니터링 대상 공간을 관리하는 관제자가 표적 객체 검출 용이하게 인식하도록 할 수 있다. 도 13은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 누출 영상을 생성하는 방법의 흐 름도이다. S1310에서, 전자 장치는 검출된 표적 객체에 관한 제1 타입 영상들 및 제1 타입 영상들에 대응되는 제2 타입 영상들을 식별할 수 있다. 그러나 또 다른 실시 예에 의하면, 전자 장치는 제1 타입 영상들 및 제2 타입 영상들 중, 표적 객체가 검출된 하나의 타입의 영상들을 누출 영상으로 생성할 수도 있다. 예를 들어, 전 자 장치는 객체 인식 모델, 우도비 검정 모델 또는 서포트 벡터 머신 모델 중 적어도 하나를 소정의 조건 에 따라 이용함으로써 표적 객체를 검출하고, 표적 객체가 검출된 영상의 타입을 결정할 수 있다. 또한, 전자 장치는 표적 객체가 검출된 영상의 타입에 대응되는 동일한 물리적 공간을 촬영함으로써 획득되는 다른 타입의 영상들을 식별할 수 있다. S1320에서, 전자 장치는 제1 타입 영상들 및 상기 제1 타입 영상들에 대응되는 제2 타입 영상들을 기하학 적으로 매칭할 수 있다. 일 실시 예에 의하면, 전자 장치는 제1 타입 영상들(예컨대 일반 카메라 영상들) 및 상기 제1 타입 영상들에 대응되는 제2 타입 영상들(OGI 영상들)을 호모그래피 매칭 기법 또는 H matrix correspondence method 기법 중 적어도 하나에 기초하여 기하학적으로 매칭할 수 있다. 그러나 또 다른 실시예 에 따르면 전자 장치는 일반 템플릿 매칭 방식을 이용하여 제1 타입 영상들 및 제2 타입 영상들을 기하학 적으로 매칭할 수도 있다. S1330에서, 전자 장치는 기하학적으로 매칭된 제1 타입 영상들 및 상기 제1 타입 영상들에 대응되는 제2 타입 영상들의 매칭 에러를 보정함으로써 누출 영상을 생성할 수 있다. 예를 들어, 전자 장치는 두 대응 되는 타입의 영상들 사이에 투시 변환(Perspective transform)을 수행하기 위한 투시 변환 행렬을 이용하여 제1 타입 영상들 및 제2 타입 영상들을 기하학적으로 매칭한 후, 호모그래피 함수를 이용한 호모그래피 매칭 과정에 서 잘못 매칭된 매칭 에러를 결정할 수 있다. 전자 장치는 후술하는 도 14에서와 같이, 각 타입의 영상들 에서 특징점들을 추출한 후, 추출된 특징점들을 기준으로 매칭 에러를 보정함으로써 누출 영상을 생성할 수 있 다. 도 14는 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 누출 영상을 생성하는 구체적인 방법의 흐름도이다. S1410에서, 전자 장치는 객체 인식 모델, 우도비 검정 모델 또는 서포트 벡터 머신 모델 중 적어도 하나 에 기초하여 표적 객체가 검출되는 경우, 검출된 표적 객체에 관한 제1 타입 영상들 및 제2 타입 영상들로부터 특징점을 추출할 수 있다. 일 실시 예에 의하면, 전자 장치는 SIFT, SURF 또는 ORB 와 같은 특징점 추출 기법을 이용하여 검출된 표적 객체에 관한 제1 타입 영상들 및 제2 타입 영상들 각각으로부터 특징점을 추출할 수 있다. S1420에서, 전자 장치는 제1 타입 영상들에서 추출된 특징점들에 매칭되는 제2 타입 영상들의 특징점을 식별할 수 있다. 일 실시 예에 의하면, 전자 장치는 Brute Force 매칭 기법, 평슌 해시 매칭, 템플릿 매 칭 기법과 같은 다양한 특징점 매칭 기법에 기초하여 제1 타입 영상들에서 추출된 특징점들에 매칭되는 제2 타 입 영상들의 특징점들을 식별할 수 있다. S1430에서, 전자 장치는 제1 타입 영상들에서 추출된 특징점들 및 상기 제2 타입 영상들에서 추출된 특징점들 사이의 평균 변위 값에 기초하여, 제1 타입 영상들 및 상기 제1 타입 영상들에 대응되는 제2 타입 영상들의 매칭 위치를 변경함으로써 매칭 에러를 보정할 수 있다. 예를 들어, 전자 장치는 제1 타입 영상들에서 추출된 특징점들의 좌표 값과 이에 매칭되는 제2 타입 영상 들에서 추출된 특징점들의 좌표 값의 차이에 기초하여 변위값을 결정할 수 있고, 각 타입의 영상들에서 추출된 특징점들의 평균 변위 값을 식별할 수 있다. 전자 장치는 평균 변위 값에 기초하여, 기하학적으로 매칭된 제1 타입의 영상들 및 제2 타입의 영상들의 매칭 위치를 변경함으로써 매칭 에러를 보정한다. S1440에서, 전자 장치는 변경된 매칭 위치에 따라 기하학적으로 매칭된 상태의 제1 타입 영상들 및 제2 타입 영상들을 누 출 영상으로 생성할 수 있다. 도 15는 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 합성 영상을 생성하는 방법의 흐 름도이다. S1510에서, 전자 장치는 상기 제1 타입 영상들 또는 상기 제2 타입 영상들 중 적어도 하나로부터 표적 객 체가 검출되는 것으로 식별되는 경우, 상기 표적 객체가 검출된 타입의 영상들로부터 상기 표적 객체의 형상 정 보를 추출할 수 있다. 전자 장치가 표적 객체의 형상 정보를 추출하는 과정은 도 7 내지 도 9에서 상술한 과정에 대응될 수 있다. S1520에서, 전자 장치는 형상 정보에 기초하여 생성된 누출 영상의 미리 획득된 파노라마 영상에 대한 좌 표를 결정할 수 있다. 예를 들어, 전자 장치는 모니터링 대상 공간에 대한 파노라마 영상을 미리 저장할 수 있다. 일 실시 예에 의하면, 전자 장치는 적어도 하나의 EO 카메라로부터 획득되는 가시광선 영상들을 이용하여 하나의 파노라마 영상으로 변환하고, 변환된 파노라마 영상을 미리 저장할 수 있다. 전자 장치는 표적 객체가 검출된 타입의 영상들 내 인접하는 프레임 이미지들에서 추출된 형상 정보에 기 초하여 모션 벡터를 결정하며, 결정된 모션 벡터에 기초하여 합벡터를 결정하고, 합벡터의 크기 및 방향에 기초 하여 누출 원점 및 흐름 벡터를 결정하며, 결정된 누출 원점 및 흐름 벡터에 기초하여 누출 영상의 파노라마 영 상에 대한 좌표를 결정한다. S1530에서, 전자 장치는 상기 결정된 좌표에 기초하여 누출 영상을 파노라마 영상에 합성함으로써 합성 영상을 생성할 수 있다. 일 실시 예에 의하면, 전자 장치는 누출 영상을 파노 라마 영상에 중첩하여 표시함과 함께, 표적 객체의 종류, 표적 객체가 발생한 누출 원점에 대한 위치 정보를 더 중첩하여 표시할 수도 있다. 도 16은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 파노라마 영상에 대한 누출 영상 의 좌표를 결정하는 방법의 흐름도이다. S1610에서, 전자 장치는 분리된 표적 객체 영역들의 형상 정보에 기초하여, 표적 객체가 생성된 위치에 관한 누출 원점 및 표적 객체의 흐름 방향과 속도에 관한 흐름 벡터를 결정할 수 있다. 예를 들어, 전자 장치 는 표적 객체가 검출된 타입의 영상들 내 인접하는 프레임 이미지들에서 추출된 형상 정보에 기초하여 모 션 벡터를 결정하며, 모션 벡터들에 기초하여 표적 객체를 모델링하고, 상기 표적 객체를 모델링하는데 사용된 모션 벡터들의 합벡터의 크기 및 방향에 기초하여 누출 원점 및 상기 흐름 벡터를 결정할 수 있다. S1620에서, 전자 장치는 누출 원점 및 흐름 벡터에 기초하여 누출 영상의 파노라마 영상에 대한 좌표를 결정할 수 있다. 일 실시 예에 의하면, 전자 장치는 상기 합벡터의 시작점을 누출원점으로 결정하고, 상 기 시작점으로부터 종점까지 상기 합벡터가 나타내는 방향을 흐름 벡터의 방향으로 결정할 수 있다. 또한, 전자 장치는 시작점으로부터 종점까지의 거리를 표적 객체의 속도의 크기를 흐름 벡터의 크기로 결정할 수 있다. 일 실시 예에 의하면, 전자 장치는 상기 합벡터에 따라 결정되는 누출 원점 및 흐름 벡터가 나타내는 방 향에 기초하여, 레이저 측정기로부터, 상기 누출 원점에 대응되는 물리적 공간으로부터 반사되는 레이저 측정값 을 획득하고, 획득된 레이저 측정값에 기초하여 물리적 공간 까지의 거리를 식별할 수 있다. 또한, 전자 장치 는 상기 누출 원점에 대한 카메라 설치셋의 팬틸트 정보를 획득할 수 있다. 전자 장치는 누출 원점, 흐름 벡터, 표적 객체가 발생한 물리적 공간 까지의 거리 및 팬틸트 정보에 기초하여 구면 좌표계에서의 제1 좌표 값을 결정할 수 있다. 전자 장치는 제1 좌표 값을 직교 좌표계의 제2 좌표 값으로 변환하고, 표 적 객체가 검출된 영상들을 전송한 타입의 카메라에 대해 미리 설정되는 렌즈 왜곡 값을 제2 좌표 값에 반영함 으로써 제3 좌표 값을 획득할 수 있다. 전자 장치는 상술한 방법에 따라 결정된 제3 좌표 값을 누출 영상 의 파노라마 영상에 대한 좌표로 결정할 수 있다. 도 17은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 레이저 측정 값 및 카메라의 팬틸 트 정보에 기초하여 누출 원점에 대한 좌표 변환하는 과정을 나타내는 도면이다. S1710에서, 전자 장치는 누출 원점 및 흐름 벡터를 획득할 수 있다. S1710에서, 전자 장치가 표적 객체를 모델링하는데 사용된 모션 벡터에 기초하여 누출 원점 및 흐름 벡터를 결정하는 과정은 도 16에서 상술 한 과정에 대응될 수 있으므로 생략하기로 한다. S1720에서, 전자 장치는 누출 원점 및 흐름 벡터의 방향 에 따른 제어 신호를 레이저 거리 측정기로 송신할 수 있다. S1730에서, 전자 장치는 레이저 측정기로부 터 상기 누출 원점에 대응되는 물리적 공간의 한 지점으로부터 반사되는 레이저 측정값을 획득할 수 있다. S1740에서, 전자 장치는 상기 누출 원점에 대한 카메라 설치셋의 카메라 팬틸트 정보를 획득할 수 있다. S1750에서, 전자 장치는 상기 누출 원점, 흐름 벡터, 표적 객체가 발생한 물리적 공간까지의 거리 및 팬 틸트 정보에 기초하여 구면 좌표계에서의 제1 좌표 값을 결정할 수 있다. S1760에서, 전자 장치는 상기 결정된 제1 좌표 값을 직교 좌표계에서의 제2 좌표 값으로 변환할 수 있다. S1770에서, 전자 장치는 제1 타입의 카메라 또는 제2 타입의 카메라 중 표적 객체가 검출된 영상들을 전송한 타입의 카메라에 대해 미리 설 정되는 렌즈 왜곡 값을 제2 좌표 값에 반영함으로써 제2 좌표 값을 제3 좌표 값으로 변경할 수 있다. 전자 장치 는 상기 결정된 제3 좌표 값에 기초하여 누출 영상을 파노라마 영상에 합성함으로써 합성 영상을 생성할 수 있다. 도 18은 또 다른 실시 예에 따른 인공지능 기반 가스 누출 탐지 시스템의 동작 과정을 나타내는 도면이다. 도 18을 참조하면, 가스 누출 탐지 시스템이 상술한 도 11 내지 16에 기재된 방법에 따라 전자 장치가 생성 한 합성 영상을 이용하는 과정이 도시된다. 그러나 또 다른 실시 예에 의하면, 도 18에 기재된 각 동작들은 가 스 누출 탐지 시스템뿐만 아니라, 전자 장치에 의해서도 수행될 수 있음은 물론이다. 예를 들어, 전 자 장치는 S330에서 도 11 내지 16에 상술한 방법에 따라 누출 영상을 파노라마 영상에 합성함으로써 합 성 영상을 생성할 수 있다. S332에서, 전자 장치는 합성 영상을 저장 및 전송할 수 있다. 일 실시 예에 의하면, 전자 장치는 제한된 데이터 내에서 효율적 설계를 위해 RDBMS (Relative Database Management System)구조에 따라 영 상 데이터들을 관리할 수 있다. 일 실시 예에 의하면, 전자 장치는 저장된 영상 데이터를 검색하기 위한 전자 장치에 대한 사용자 입력에 기초하여, 소정의 영상들을 출력할 수도 있다. 일 실시 예에 의하면, 전 자 장치는 DB SELECT를 이용하여 키워드 일부 및 단어 조합에 기초하여 소정의 저장된 영상 데이터를 출 력할 수 있다. 또한, 일 실시 예에 의하면, 전자 장치는 RDBMS의 효율적 탐색을 위해 SQL을 기반으로 시 스템을 구성하고, 고성능화와 사용자 경험 최적화를 위해 다중 조건 내에서 조건을 제한 문자열을 배열하는 구 조를 SELECT문으로 기본 설계할 수 있다. S334에서, 전자 장치는 객체 인식 모델, 우도비 검정 모델 또는 서포트 벡터 머신 모델 중 적어도 하나를 이용함으로써 표적 객체가 검출되는 것으로 식별되는 경우, 검출된 표적 객체의 형상 정보에 기초하여 누출 원 점 및 표적 객체의 종류를 결정하고, 누출 원점 및 표적 객체의 종류에 대한 정보를 포함 경보 및 알림 컨텐츠 를 생성할 수 있다. 또한, 전자 장치는 경보 장치들을 동작시키기 위한 소정의 제어 신호를 함께 생성할 수 있다.S336에서, 전자 장치는 경보 장치를 제어하기 위한 제어 신호를 경보 장치로 전송함으로써 경광등의 동작 을 제어함으로써 발광을 시키거나, 스피커 장치를 제어함으로써 소정의 음향 신호가 출력되도록 할 수 있다. 일 실시 예에 의하면, 전자 장치는 작업 현장에 설치된 관제 단말을 통하여 소정의 경보 장치를 제어할 수도 있음은 물론이다. S338에서, 전자 장치는 S334에서 생성된 컨텐츠를 출력할 수 있다. 예를 들어, 전자 장치는 S334에 서 생성된 컨텐츠를 전자 장치의 디스플레이 상에 출력할 수도 있지만, 전자 장치와 연결된 관제 단말의 디스플레이 또는 관제 서버를 통하여 연결되는 상황실 시스템의 디스플레이 장치로 컨텐츠를 전송할 수도 있다. 일 실시 예에 의하면, 전자 장치가 전송하는 컨텐츠들은 RDBMS에 실시간으로 저장될 수 있으며, 전 자 장치, 관제 단말, 또는 상황실 시스템에 대한 관제자의 사용자 입력에 기초하여 호출됨으로써, 소정의 디스플레이 상에 출력될 수도 있다. S340에서, 전자 장치는 카메라 설치셋, 레이저 거리 측정기, EO 및 OGI 카메라를 제어하 기 위한 제어 신호를 생성할 수 있다. 일 실시 예에 의하면, 전자 장치는 전자 장치, 관제 단말 또는 상 황실 시스템에 대한 관제자의 사용자 입력에 기초하여 카메라 설치셋, 레이저 거리 측정기, EO 및 OGI 카메라를 제어하기 위한 제어 신호를 생성하고, 모니터링 대상 공간 내 특정 지점을 구체적으로 모니 터링되도록 할 수 있다. 도 19는 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 인공지능 모델을 이용하여 가스 누출을 탐지하는 방법의 흐름도이다. S1910에서, 전자 장치는 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간 에 대한 제1 타입 학습 영상들, 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터 링 대상 공간에 대한 제2 타입 학습 영상들을 획득할 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 전자 장치와 연결된 외부 디바이스로부터 표적 객체를 포함하는 가시광선 영상들 및 적외선 영상들을 제1 타입 학습 영상들 및 제2 타입 학습 영상들로 획득할 수 있다. 일 실시 예에 의하면, 제1 타입 학습 영상들은 및 제2 타입 학습 영상들은 가시광선 영상들 및 적외선 영상들일 수 있다. S1920에서, 전자 장치는 제1 타입 학습 영상들 및 상기 제2 타입 학습 영상들에 기초하여 학습 데이터 및 검증 데이터를 생성할 수 있다. 예를 들어, 전자 장치는 상기 제1 타입 학습 영상들 중 미리 설정된 비율 에 따라 학습 데이터 및 검증 데이터를 생성할 수 있다. 또한, 전자 장치는 제2 타입 학습 영상들 중 미 리 설정된 비율에 따라 학습 데이터 및 검증 데이터를 생성할 수 있다. S1930에서, 전자 장치는 생성된 학습 데이터에 기초하여, 상기 제1 타입의 카메라로부터 획득되는 제1 타 입 영상들 및 상기 제2 타입의 카메라로부터 획득되는 제2 타입 영상들이 입력되면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 표적 객체가 검출되는지 여부를 식별하는 객체 인식 모델을 학습시킬 수 있다. 일 실 시 예에 의하면, 전자 장치는 제1 타입 학습 영상들에 기초하여, 제1 타입 영상들이 입력되면 제1 타입 영상들 내 표적 객체가 검출되는지 여부를 식별하는 제1 객체 인식 모델을 학습시키고, 제2 타입 학습 영상들에 기초하여, 제2 타입 영상들이 입력되면 제2 타입 영상들 내 표적 객체가 검출되는지 여부를 식별하는 제2 객체 인식 모델을 학습 시킨 후, 제1 객체 인식 모델 및 제2 객체 인식 모델을 이용하여 하나의 객체 인식 모델을 생 성할 수도 있다. S1940에서, 전자 장치는 학습된 객체 인식 모델에 상기 제1 타입 영상들 및 상기 제2 타입 영상들을 입력 함으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체의 검출 여부를 식별할 수 있다. 도 19에 도시되지 않았지만, 전자 장치는 표적 객체가 검출되는 것으로 식별되는 경우, 표적 객체가 검출 된 타입의 영상들로부터 표적 객체의 형상 정보를 추출하게 된다. 도 20은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 객체 인식 모델을 학습시키고, 학 습된 객체 인식 모델을 활용하는 과정을 나타내는 도면이다. S2002에서 전자 장치는 인공지능 모델 학습을 위한 영상 데이터를 획득하고, 획득된 영상 데이터를 분석 할 수 있다. S2004에서, 전자 장치는 획득된 영상 데이터를 전처리할 수 있다. S2006에서, 전자 장치 는 획득된 영상 데이터 중에서 미리 설정된 비율에 따라 일부를 학습 데이터로 나머지 일부를 검증 데이터로 분리할 수 있다. S2008에서, 전자 장치는 표적 객체 인식을 위해 사용될 인공지능 알고리즘 및 모델을 결정할 수 있다. S2010에서, 전자 장치는 결정된 알고리즘 및 모델 사항에 따라, 상기 영상 데이터 중 일부의 영상 데이터 인 학습 데이터에 기초하여 인공지능 모델을 학습시킬 수 있다. S2012에서, 전자 장치는 검증 데이터에 기초하여 학습된 인공지능 모델의 성능을 검증할 수 있다. S2014에서, 전자 장치는 인공지능 모델의 성능 을 검증한 결과, 인공지능 모델의 성능이 소정의 조건을 만족하지 못하는 것으로 결정되는 경우, 인공지능 모델 의 파라미터를 파인 튜닝할 수 있다. 그러나, S2016에서, 전자 장치는 인공지능 모델의 성능을 검증한 결 과, 인공 지능 모델의 성능이 소정의 조건을 만족하는 것으로 결정되는 경우, 해당 인공지능 모델의 파라미터를 추출할 수 있다. S2018에서, 전자 장치는 인공지능 모델의 파라미터를 파인 튜닝한 결과에 기초하여, 인공지능 알고리즘 및 모델을 변경할 필요가 있는지 여부를 결정할 수 있다. 전자 장치는 인공지능 알고리즘 및 모델을 변경 할 필요가 있는 경우, 새로운 인공지능 알고리즘 및 모델을 선정하게 되며, 인공지능 알고리즘 및 모델을 변경 할 필요가 없는 경우, 해당 알고리즘 및 모델을 다시 학습시키고, 학습된 모델의 성능 만족 여부를 평가할 수 있다. S2020에서, 전자 장치는 표적 객체 인식을 위한 입력 영상을 획득하고, 획득된 입력 영상을 전처리할 수 있다. S2022에서, 전자 장치는 S2016에서 결정된 인공지능 모델의 파라미터에 기초하여 실제 활용 인공 지능 모델의 파라미터를 수정 및 갱신함으로써 인공지능 모델을 학습시킬 수 있다. S2024에서, 전자 장치(100 0)는 학습된 인공 지능 모델에, 전처리된 입력 영상을 입력한 결과에 기초하여 표적 객체가 검출되는지 여부를 식별하고, 표적 객체가 검출되는 것으로 식별되는 경우, 해당 표적 객체에 대한 정보를 저장 및 반환할 수 있다. 도 21은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 우도비 검정 모델 및 서포트 벡터 모신 모델을 학습과정을 나타내는 흐름도이다. S2110에서, 전자 장치는 제2 타입 학습 영상들 또는 상기 제2 타입 학습 영상들로부터 추출되는 스펙트럼 학습 정보에 기초하여, 상기 제2 타입 영상들 또는 상기 제2 타입 영상들로부터 추출되는 스펙트럼 정보가 입력 되면, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별하는 우도비 검 정 모델을 학습시킬 수 있다. S2120에서, 전자 장치는 제2 타입 학습 영상들 또는 상기 제2 타입 학습 영상들로부터 추출되는 스펙트럼 학습 정보에 기초하여, 상기 제2 타입 영상들 또는 상기 제2 타입 영상들로부터 추출되는 스펙트럼 정보가 입력 되면, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별하는 서포트 벡 터 머신 모델을 학습시킬 수 있다. 전자 장치가 우도비 검정 모델 및 서포트 벡터 모신 모델을 학습하는 구체적인 과정은 후술하는 도 22를 참조하여 구체적으로 설명하기로 한다. 도 22은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 우도비 검정 모델 및 서포트 벡터 모신 모델을 학습하는 과정을 설명하기 위한 도면이다. S2202에서, 전자 장치는 우도비 검정 모델 학습을 위한 주파수 데이터를 획득하고, 획득된 주파수 데이터 를 분석한다. 일 실시 예에 의하면, 주파수 데이터는 제2 타입 학습 영상들을 주파수 도메인으로 변환함으로써 생성되는 영상 데이터일 수 있다. S2204에서, 전자 장치는 주파수 데이터를 전처리할 수 있다. S2206에서, 전자 장치는 전처리된 주파수 데이터 중 일부를 학습 데이터, 나머지 일부를 검증 데이터로 설정할 수 있다. S2208에서, 전자 장치는 표적 객체에 따른 주파수 패턴을 분류하기 위한 알고리즘을 선정할 수 있다. 일 실시 예에 의하면 전자 장치는 적외선 영상으로부터 획득된 스펙트럼 정보를 분류하기 위한 알고리즘으로 우도비 검정 알고리즘을 사용할 수 있다. S2210에서, 전자 장치는 학습 데이터에 기초하여 선정된 알고리 즘 및 상기 알고리즘에 따른 모델을 학습시킬 수 있다. S2212에서, 전자 장치는 학습된 모델의 성능이 소정의 목표치를 만족하는지 여부를 검증할 수 있다. S2214에서, 전자 장치는 학습된 모델의 성능이 소정의 목표치를 만족하지 않는 것으로 식별되는 경우, 해당 모델에 대한 파인 튜닝(Fine Tunning)을 수행할 수 있다. S2216에서, 전자 장치는 S2212에서 학습된 모델의 성능이 소정의 목표치를 만족하는 것으로 식별되는 경우, 학습된 모델의 파라미터를 추출할 수 있다. S2218에서, 전자 장치는 학습된 모델에 입력하기 위해, 표적 객체 검출 대상이 되는 적외선 영상을 획득 하고, 획득된 적외선 영상을 푸리에 변환함으로써 획득되는 주파수 데이터에 대해 전처리를 수행할 수 있다. S2220에서, 전자 장치는 전처리된 주파수 데이터 또는 상기 주파수 데이터에서 획득되는 스펙트럼 정보를 학습된 인공지능 학습 모델(예컨대 우도비 검정 모델)에 입력함으로써 표적 객체에 따른 주파수 패턴이 식별되 는지 여부를 확인할 수 있다. 또한, 일 실시 예에 의하면, 전자 장치는 표적 객체에 따른 주파수 패턴을 검출하기 위해 또 다른 패턴 분류 알고리즘 및 이에 기초하여 학습되는 모델을 더 이용할 수도 있다. 예를 들어, 전자 장치는 서포트 벡터 머신 모델을 학습시키고, 학습된 서포트 벡터 머신 모델을 소정의 조건에서 우도비 검정 모델과 함께 이용 함으로써 표적 객체에 따른 주파수 패턴을 정확하게 추출할 수 있다. S2230 내지 S2250에 도시된 동작은 S2202 내지 S2220에 대응될 수 있으므로 구체적인 설명은 생략하기로 한다. 도 23은 또 다른 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 복수의 소프트웨어 모듈을 이용하여 가스 누출을 탐지하는 과정을 설명하기 위한 도면이다. 도 12에 도시된 각 모듈은 가스 누출 탐지를 위해 전자 장치의 프로세서에 의해 실행될 수 있는, 메모리 내 저장된 하나 이상의 인스트럭션 집합일 수 있다. 일 실시 예에 의하면, 전자 장치는 AI 가스 영상 및 연기 탐지 모듈, 원점 탐지 모듈, 시각화 모듈, 경보 및 제어 모듈로 구분되는 하나 이상의 인스트럭션을 메모리에 저장하고, 저장된 인스트럭션들을 실행함으로써 모니터링 대상 공간에 대한 표적 객체를 탐지할 수 있다. 일 실시 예에 의하면, S2322 내지 S2328에서 전자 장치가 이용하는 S/W들은 AI 가스 영 상 및 연기 탐지 모듈에 포함될 수 있다. 예를 들어, S2322에서, 전자 장치는 EO 카메라, OGI 카메라 및 레이저 측정기를 포함 하는 카메라 설치셋으로부터 가시광선 영상들(예컨대 EO 영상들) 및 적외선 영상들(예컨대 OGI 영상들)을 획득할 수 있다. S2323에서, 전자 장치는 객체 인식 기술 S/W를 실행함으로써, 표적 객체가 가시광선 영 상들 및 적외선 영상들로부터 1차적으로 검출되지 않는 것으로 식별되는 경우, 적외선 영상 주파수 변환 S/W를 실행함으로써 시공간 도메인에 따른 적외선 영상 정보를 주파수 도메인의 변환 영상 정보로 변환할 수 있다. 전 자 장치는 주파수 도메인의 변환 영상 정보에서 스펙트럼을 추출할 수 있다. S2324에서, 전자 장치는 우도비 검정모델 및 SVM 모델 학습을 위한 S/W를 실행함으로써 표적 객체에 따른 주파수 패턴을 식별하기 위한 우도비 검정 모델 및 SVM 모델을 학습시킬 수 있다. S2325에서, 전자 장치 는 주파수별 패턴 분석 S/W를 실행함으로써 우도비 검정 모델 또는 SVM 모델 중 적어도 하나를 이용하여 적외선 영상 내 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별할 수 있다. S2326에서, 전자 장치는 객체 인식 기술 S/W를 실행함으로써 표적 객체가 인식되거나 적외선 영상으로부 터 표적 객체에 따른 주파수 패턴이 식별되는 경우, 연기/배경 분리 S/W를 실행함으로써 표적 객체 영역을 분리 할 수 있다. S2327에서, 전자 장치는 연기 형상 검출 S/W를 실행함으로써 마스킹 데이터를 이용하여, 표 적 객체가 검출된 타입의 영상들에서 표적 객체 영역을 분리하고, 분리된 표적 객체 영역들의 형상 정보를 추출 할 수 있다. S2328에서, 전자 장치는 연기 원점/흐름 검출 S/W를 실행함으로써, 표적 객체가 검출된 타입 의 영상들 내 인접한 프레임 이미지 각각에서 추출된 형상 정보에 기초하여, 분리된 표적 객체 영역들에 대한 모션 벡터를 결정하고, 결정된 모션 벡터들의 합벡터에 기초하여 누출 원점 및 흐름 벡터를 결정할 수 있다. 일 실시 예에 의하면, 전자 장치가 이용하는 원점 탐지 모듈은 거리 구면 좌표 인식 S/W 및 위치 정보 변환 S/W를 포함할 수 있다. 예를 들어, S2329에서, 거리 구면 좌표 인식 S/W를 실행함으로써, 누출 원점 에 대응되는 표적 객체가 발생한 물리적 공간까지의 거리를 획득하고, 획득된 누출 원점에 대한 카메라의 팬틸 트 정보를 획득하며, 상기 누출 원점, 흐름 벡터, 표적 객체가 발생한 물리적 공간까지의 거리 및 팬틸트 정보 에 기초하여 구면 좌표계에서의 좌표를 결정할 수 있다. S2330에서, 전자 장치는 위치 정보 변환 S/W를 실행함으로써 상기 결정된 구면 좌표계에서의 좌표를 직교 좌표계 또는 카메라의 왜곡 정보 보정에 따른 좌표 값으로 변환할 수 있다. S2340에서, 전자 장치는 영상 합성 S/W를 실행함으로써 S2330에서 결정된 좌표 값에 기초하여, 누출 영상 을 파노라마 영상에 대해 합성함으로써 합성 영상을 생성할 수 있다. 일 실시 예에 의하면 시각화 모듈은영상 합성 S/W를 포함할 수 있다. 또한, 일 실시 예에 의하면 경보/제어 모듈은 환경 설정 S/W, 제어 기 능 S/W, 저장 기능 S/W, 검색 기능 S/W, 경보 기능 S/W를 포함할 수 있다. S2352에서, 전자 장치는 환경 설정 S/W를 실행함으로써 모니터링 대상 공간에 대한 카메라 설치셋 의 동작 환경을 조정할 수 있다. S2354에서, 전자 장치는 제어 기능 S/W를 실행함으로써 카메라 설치셋 내 카메라 장치 및 레이저 측정기의 동작을 세부적으로 제어할 수 있다. S2356에서, 전자 장치는 저장기능 S/W를 실행함으로써 S2340에서 획득된 합성 영상을 메모리에 저장할 수 있다. S2357에서, 전자 장치 는 검색 기능 S/W를 실행함으로써 저장된 합성 영상에 접근하려는 사용자 입력에 기초하여 소정의 영상을 검색하고 출력하는 기능을 수행할 수 있다. 일 실시 예에 의하면, 전자 장치는 시간 별, 카메라별, 위치 별로 EO 영상 및 OGI 영상들을 저장해놓고, 시간 별 검색 조건에 따른 소정의 영상들을 검색할 수 있을 뿐만 아 니라, 표적 객체 탐지에 따른 이벤트 기록을 저장하고, 이벤트 별 기록들을 사용자 요청에 의해 출력할 수도 있 다. S2358에서, 전자 장치는 경보기능 S/W를 실행함으로써 영상 내 표적 객체가 검출되는 것으로 식별되는 경 우 소정의 경보 컨텐츠 및 제어 신호를 생성하고, 생성된 경보 컨텐츠를 출력부의 영상 디스플레이에 전 송하거나, 생성된 제어 신호를 출력부의 경광등으로 전송함으로써 발광 동작을 수행하도록 제어할 수 있 다. 도 24는 또 다른 실시 예에 따라, 측정 장치, 인공지능 기반 가스 누출 탐지 서버, 경보/제어 서버 및 관제 장 치가 서로 연동함으로써 가스 누출을 탐지하는 과정을 설명하기 위한 도면이다. 일 실시 예에 의하면 도 1 내지 23에 상술한 가스 누출 탐지 과정들은 가스 누출 탐지 시스템 또는 전자 장 치에 의해서 수행될 수 있다. 일 실시 예에 의하면 가스 누출 탐지 시스템은 측정 장치, 인공 지능 기반 가스 누출 탐지 서버, 경보 및 제어 서버 및 관제 장치를 포함할 수 있다. 도 24 를 참조하여 측정 장치, 인공지능 기반 가스 누출 탐지 서버, 경보 및 제어 서버 및 관제 장 치가 서로 연동함으로써 가스 누출을 탐지하는 과정을 설명하기로 한다. S2402에서, 측정 장치는 영상 정보 및 레이저 측정 값을 획득할 수 있다. 또 다른 실시 예에 의하면, 측 정 장치는 영상 정보를 먼저 획득하고, 경보 및 제어 서버의 제어에 의해, 누출 원점이 탐지되면, 해당 누출 원점에 대한 레이저 측정 값을 추후에 획득할 수도 있다. S2404에서, 측정 장치는 영상 정보 및 레이저 측정 값을 인공지능 기반 가스 누출 탐지 서버로 전송할 수 있다. S2406에서, 인공지능 기반 가스 누출 탐지 서버는 영상 정보 및 레이저 측정 값을 경보 및 제어 서버 로 전달할 수 있다. 그러나, 상술한 과정은 수행되지 않을 수 있으며, 인공지능 기반 가스 누출 탐지 서 버는 영상 정보 및 레이저 측정 값을 자체 서버 장치 내에서만 분석할 수도 있다. S2408에서, 인공지능 기반 가스 누출 탐지 서버는 적어도 하나의 인공지능 모델을 이용하여 획득된 영상 정보 내 표적 객체가 검출되는지 여부를 식별할 수 있다. S2410에서, 인공지능 기반 가스 누출 탐지 서버는 표적 객체가 검출되는 것으로 식별되는 경우, 해당 표 적 객체의 형상 정보에 기초하여 누출 원점 및 흐름 벡터를 결정할 수 있다. S2412에서, 인공지능 기반 가스 누 출 탐지 서버는 누출 원점 및 흐름 벡터에 기초하여 거리 구면 좌표를 결정하고, 결정된 거리 구면 좌표 를 변환함으로써 누출 영상의 파노라마 영상에 대한 좌표를 결정할 수 있다. S2414에서, 인공지능 기반 가스 누 출 탐지 서버는 누출 영상을 파노라마 영상에 합성함으로써 합성 영상을 생성할 수 있다. S2416에서, 인공지능 기반 가스 누출 탐지 서버는 이벤트 탐지 결과, 영상 정보, 레이저 측정값, 합성 영 상 및 인공지능 모델의 분석 결과를 경보 및 제어 서버로 전달할 수 있다. S2418에서, 경보 및 제어 서버 는 이벤트 탐지 결과, 영상 정보, 레이저 측정 값, 합성 영상, 인공 지능 모델의 분석 결과를 관제 장치 로 전달할 수 있다. S2420에서, 관제 장치는 관제 디스플레이를 통해 합성 영상을 포함한 관제 영 상을 표시하고, 소정의 경고 컨텐츠를 생성하며, 생성된 경고 컨텐츠를 관제 영상과 함께 중첩하여 표시할 수 있다. S2422에서, 관제 장치는 카메라 제어 신호, 레이저 측정기 제어 신호를 측정 장치로 전달할 수 있 다. 일 실시 예에 의하면 관제 장치는 복수 타입의 카메라들로 제어 신호를 전송함으로써, 복수 타입 영 상들 사이의 전환 기능을 수행할 수도 있다. 또 다른 실시 예에 의하면, 관제 장치은 제어 신호를 경보 및 제어 서버를 통해 측정 장치로 전달할 수도 있다. 예를 들어, S2424에서, 관제 장치는 관제 장치에 대한 관제자의 사용자 입력에 기초하여 제어 신호를 생성하고, 생성된 제어 신호를 경보 및 제 어 서버로 전달할 수 있다. S2426에서, 측정 장치는 제어 신호에 따라 동작 및 새로운 정보를 획득 할 수 있다. 도 25는 또 다른 실시 예에 따라, 전자 장치, 경보 장치 및 서버가 서로 연동함으로써 가스 누출을 탐지하는 과 정을 설명하기 위한 도면이다. 본 개시의 또 다른 실시 예에 의하면 가스 누출 탐지 시스템은 전자 장치, 경보 장치 및 서버 를 포함할 수도 있다. 도 25에 도시된 과정들은 가스 누출 탐지 시스템에 의해 수행될 수도 있으나, 전자 장치에 의해서도 수행될 수 있음은 물론이다. S2502에서, 전자 장치는 영상 정보, 레이저 측정 값을 획득할 수 있다. S2504에서, 전자 장치는 획득된 영상 정보, 레이저 측정 값을 서버로 전달할 수 있다. S2506에서, 전자 장치는 인공지능 모 델을 이용하여 영상 정보 내 표적 객체가 탐지되는지 및 표적 객체의 종류를 분석할 수 있다. S2508에서, 전자 장치는 인공지능 모델을 이용한 객체 탐지 결과를 서버로 전송할 수 있다. 도 25에는 도시되지 않 았지만, 서버는 전자 장치에서 전송된 영상 정보, 레이저 측정 값, 객체 탐지 결과를 실시간으로 관제 장치의 디스플레이로 출력할 수 있다. S2510에서, 전자 장치는 인공지능 모델을 이용하여 영상 정보 내 표적 객체가 탐지되는지 여부에 기초하 여 소정의 경고 이벤트가 발생하였는지 여부를 결정할 수 있다. S2512에서, 전자 장치는 이벤트가 탐지되 는 경우 경보 정보를 경보 장치로 전송할 수 있다. 또한, 전자 장치는 S2514에서, 경보 정보 및 탐 지 결과를 서버로 전송할 수 있다. 일 실시 예에 의하면, S2516에서, 서버는 전자 장치와 별 도의 경보 정보를 경보 장치로 더 전송함으로써, 복수 루트로 경보 장치의 동작 신뢰를 확보할 수 있다. S2518에서, 전자 장치는 객체 탐지시 누출 원점 및 좌표 정보를 결정할 수 있다. S2520에서, 전자 장치 는 표적 객체에 관한 누출 영상을 생성하고, 생성된 누출 영상을 파노라마 영상에 합성함으로써 합성 영 상을 생성할 수 있다. S2524에서, 서버는 합성 영상 정보 및 탐지 결과를 출력할 수 있다. S2526에서, 서 버는 경보 장치 내 다양한 구성 장치들을 제어하기 위한 제어 신호를 경보 장치로 전송할 수 있다. S2528에서, 서버는 카메라 설치셋 내 구성 장치들을 제어하기 위한 제어 신호를 전자 장치로 전송 할 수 있다. 도 26은 일 실시 예에 따른 전자 장치의 블록도이다. 도 27은 또 다른 실시 예에 따른 전자 장치의 블록도이다. 도 26에 도시된 바와 같이, 일 실시 예에 따른 전자 장치는 프로세서, 네트워크 인터페이스 및 메모리를 포함할 수 있다. 그러나, 도시된 구성 요소가 모두 필수구성요소인 것은 아니다. 도시된 구 성 요소보다 많은 구성 요소에 의해 전자 장치가 구현될 수도 있고, 그 보다 적은 구성 요소에 의해서도 전자 장치는 구현될 수도 있다. 예를 들어, 도 27에 도시된 바와 같이, 전자 장치는 프로세서, 네트워크 인터페이스 및 메모 리외에, 사용자 입력 인터페이스, 출력부, 센싱부, 네트워크 인터페이스, A/V 입력부 및 메모리를 더 포함할 수도 있다. 사용자 입력 인터페이스는, 사용자가 전자 장치를 제어하기 위한 데이터를 입력하는 수단을 의미한 다. 예를 들어, 사용자 입력 인터페이스에는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접 촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠, 조그 스위치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 사용자 입력 인터페이스는, 카메라 설치셋을 제어하거나, 영상 내 특정 영역을 확대 또는 축소하기 위한 사용자 입력을 수신할 수 있다. 또 다른 실시 예에 의하면 사용자 입력 인터페이스는 저장된 합성 영상 중 특정 시간 및 장소에 대한 영상에 접근하기 위한 사용자 입력을 획득할 수도 있음은 물론이다. 출력부(120 0)는, 오디오 신호 또는 비디오 신호 또는 진동 신호를 출력할 수 있으며, 출력부는 디스플레이부, 음향 출력부, 및 진동 모터를 포함할 수 있다.디스플레이부는 전자 장치에서 처리되는 정보를 표시 출력하기 위한 화면을 포함한다. 또한, 화면 은 카메라 설치셋에서 획득된 복수 타입 영상들, 누출 영상, 파노라마 영상 및 합성 영상을 디스플레이 할 수 있다. 예를 들면, 화면의 적어도 일부는 모니터링 대상 공간에 대한 합성 영상, 상기 합성 영상에서 나타나는 표적 객체를 세밀하게 모니터링하기 위해, 카메라 설치셋등을 제어하기 위한 사용자 인터페이스 등을 함께 출력 할 수 있다. 음향 출력부는 네트워크 인터페이스로부터 수신되거나 메모리에 저장된 오디오 데이터를 출 력한다. 또한, 음향 출력부는 전자 장치에서 수행되는 기능(예를 들어, 호신호 수신음, 메시지 수 신음, 알림음)과 관련된 음향 신호를 출력한다. 프로세서는 통상적으로 전자 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 메 모리에 저장된 프로그램들을 실행함으로써, 사용자 입력 인터페이스, 출력부, 센싱부, 네트워크 인터페이스, A/V 입력부 등을 전반적으로 제어할 수 있다. 또한, 프로세서는 메모 리에 저장된 프로그램들을 실행함으로써, 도 1 내지 도 25에 기재된 전자 장치의 기능을 수행할 수 있다. 일 실시 예에 의하면, 프로세서는 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함 으로써, 상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간에 대한 제1 타입 영상들을 획득하고, 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간 에 대한 제2 타입 영상들을 획득하고, 상기 제1 타입 영상들 및 상기 제2 타입 영상들이 입력되면, 상기 제1 타 입 영상들 및 상기 제2 타입 영상들 내 표적 객체가 검출되는지 여부를 식별하는 객체 인식 모델에, 상기 제1 타입 영상들 및 상기 제2 타입 영상들을 입력함으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체 검출 여부를 식별할 수 있다. 일 실시 예에 의하면, 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 전자 장치와 연결 된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간에 대한 제1 타입 영상들 및 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간에 대한 제2 타입의 영상들을 획득하고, 상기 제1 타입 영상들 또는 상기 제2 타입 영상들 중 적어도 하나로부터 표적 객체가 검출되는 것으 로 식별되는 경우, 상기 검출된 표적 객체에 관한 제1 타입 영상들 및 상기 검출된 표적 객체에 관한 상기 제1 타입 영상들에 대응되는 제2 타입 영상들을 합성함으로써 누출 영상을 생성하고, 상기 생성된 누출 영상의 미리 획득된 파노라마 영상에 대한 좌표에 기초하여, 상기 누출 영상을 상기 파노라마 영상에 합성함으로써 합성 영 상을 생성할 수 있다. 일 실시 예에 의하면, 프로세서는 상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니 터링 대상 공간에 대한 제1 타입 학습 영상들, 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부 터 상기 모니터링 대상 공간에 대한 제2 타입 학습 영상들을 획득하고, 상기 제1 타입 학습 영상들 및 상기 제2 타입 학습 영상들에 기초하여 학습 데이터 및 검증 데이터를 생성하고, 상기 생성된 학습 데이터에 기초하여, 상기 제1 타입의 카메라로부터 획득되는 제1 타입 영상들 및 상기 제2 타입의 카메라로부터 획득되는 제2 타입 영상들이 입력되면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 표적 객체가 검출되는지 여부를 식별하 는 객체 인식 모델을 학습시키고, 상기 학습된 객체 인식 모델에 상기 제1 타입 영상들 및 상기 제2 타입 영상 들을 입력함으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체의 검출 여부를 식별할 수 있다. 또한, 일 실시 예에 의하면, 프로세서는 하나 이상의 인스트럭션을 실행함으로써 표적 객체가 검출되는 경우, 표적 객체가 발생한 누출 원점, 상기 누출 원점에 대한 물리적 공간상의 위치 정보, 상기 표적 객체의 종 류 중 적어도 하나에 관한 정보를 합성 영상과 함께 화면상에 출력할 수도 있다. 센싱부는, 전자 장치의 상태 또는 전자 장치 주변의 상태를 감지하고, 감지된 정보를 프로세 서로 전달할 수 있다. 센싱부는 전자 장치의 사양 정보, 모니터링 대상 공간에 대한 온도, 습도, 기압 정보 등을 센싱할 수 있다. 예를 들어, 센싱부는, 지자기 센서(Magnetic sensor), 가속도 센서(Acceleration sensor), 온/습도 센서, 적외선 센서, 자이로스코프 센서, 위치 센서(예컨대, GPS), 기압 센서 , 근접 센서, 및 RGB 센서(illuminance sensor) 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 각 센서들의 기능은 그 명칭으로부터 당업자가 직관적으로 추론할 수 있으므로, 구체적인 설명은 생략하기로 한다. 네트워크 인터페이스는 전자 장치가 다른 장치(미도시) 및 서버와 통신을 하게 하는 하나 이 상의 구성요소를 포함할 수 있다. 다른 장치(미도시)는 전자 장치와 같은 컴퓨팅 장치이거나, 센싱 장치 일 수 있으나, 이에 제한되지 않는다. 예를 들어, 네트워크 인터페이스는, 무선 통신 인터페이스 , 유선 통신 인터페이스 , 이동 통신부를 포함할 수 있다. 무선 통신 인터페이스는 근거리 통 신부(short-range wireless communication unit), 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, 근거 리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 지그비(Zigbee) 통신부, 적외선 (IrDA, infrared Data Association) 통신부, WFD(Wi-Fi Direct) 통신부, UWB(ultra wideband) 통신부 등을 포 함할 수 있으나, 이에 한정되는 것은 아니다. 유선 통신 인터페이스는 유선 통신을 통해 전자 장치와 연결된 외부 디바이스와 데이터를 주고받기 위한 적어도 하나의 유선 인터페이스를 포함할 수 있다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한다. 여기에서, 무선 신호는, 음성 호 신호, 화상 통화 호 신 호 또는 문자/멀티미디어 메시지 송수신에 따른 다양한 형태의 데이터를 포함할 수 있다. A/V(Audio/Video) 입력부는 오디오 신호 또는 비디오 신호 입력을 위한 것으로, 이에는 카메라와 마이크로폰 등이 포함될 수 있다. 카메라는 화상 통화모드 또는 촬영 모드에서 이미지 센서를 통해 정지영상 또는 동영상 등의 화상 프레임을 얻을 수 있다. 이미지 센서를 통해 캡쳐된 이미지는 프로세서 또는 별도의 이미지 처리부(미도시)를 통해 처리될 수 있다. 일 실시 예에 의하면 카메라 모듈은 전면부 에 소정의 필터가 부착됨으로써 적외선 영상을 통해 가스 또는 연기를 시각화하는 OGI 카메라 및 가시광선 영상 을 획득하는 EO 카메라를 포함할 수 있다. 마이크로폰은, 외부의 음향 신호를 입력 받아 전기적인 음성 데이터로 처리한다. 예를 들어, 마이크로폰 은 외부 디바이스 또는 사용자로부터 음향 신호를 수신할 수 있다. 마이크로폰은 사용자의 음성 입 력을 수신할 수 있다. 마이크로폰은 외부의 음향 신호를 입력 받는 과정에서 발생 되는 잡음(noise)을 제 거하기 위한 다양한 잡음 제거 알고리즘을 이용할 수 있다. 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 전자 장치로 입력되 거나 전자 장치로부터 출력되는 데이터를 저장할 수도 있다. 또한, 메모리는 전자 장치가 이용하는 적어도 하나의 인공지능 모델, 전자 장치가 획득한 모니터링 대상 공간에 대한 영상 정보, 레이저 측 정값, 합성 영상, 누출 영상, 인공지능 모델의 분석 결과에 대한 정보를 저장할 수 있다. 또한, 메모리는 전자 장치가 이용하는 적어도 하나의 신경망 모델에 대한 정보를 저장할 수 있다. 예를 들어, 메모리는 적어도 하나의 신경망 모델 내 레이어들, 노드들, 상기 레이어들의 연결 강도에 관 한 가중치 값들을 저장할 수 있다. 또한, 전자 장치는 신경망 모델을 학습하기 위해 전자 장치가 생성한 학습 데이터를 더 저장할 수도 있다. 또한, 메모리는 전자 장치와 연결된 카메라들 또는 서버의 동작 환경에 대한 정보들을 더 저장할 수도 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 메모리에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있는데, 예를 들어, UI 모 듈, 터치 스크린 모듈, 알림 모듈 등으로 분류될 수 있다. UI 모듈은, 가스 누출 탐지를 위한 애플리케이션 별로 전자 장치와 연동되는 특화된 UI, GUI 등을 제공할 수 있다. 터치 스크린 모듈은 사용자의 터치 스크린 상의 터치 제스처를 감지하고, 터치 제스처에 관한 정보를 프로세서로 전달할 수 있다. 일부 실시예에 따른 터치 스크린 모듈은 터치 코드를 인 식하고 분석할 수 있다. 터치 스크린 모듈은 컨트롤러를 포함하는 별도의 하드웨어로 구성될 수도 있다. 알림 모듈은 전자 장치의 이벤트 발생을 알리기 위한 신호를 발생할 수 있다. 예를 들어, 전자 장 치가 가스 누출에 따른 표적 객체가 검출되었음을 식별하고, 이에 따른 경고 컨텐츠를 출력할 수 있다. 일 실시 예에 따른 이벤트의 예로는 호 신호 수신, 메시지 수신, 키 신호 입력, 일정 알림 등이 있다. 알림 모 듈은 디스플레이부를 통해 비디오 신호 형태로 알림 신호를 출력할 수도 있고, 음향 출력부를 통해 오디오 신호 형태로 알림 신호를 출력할 수도 있고, 진동 모터를 통해 진동 신호 형태로 알림 신 호를 출력할 수도 있다. 도 28은 또 다른 실시 예에 따른 가스 누출 탐지 시스템의 장치 구성을 설명하기 위한 도면이다. 일 실시 예에 의하면, 가스 누출 탐지 시스템은 카메라 설치셋, 카메라셋 및 관제 단말기 를 포함할 수 있다. 일 실시 예에 의하면 카메라 설치셋은 카메라 하우징, 팬틸트 , 엘리베이션 폴대를 포함할 수 있다. 가스 누출 탐지 시스템은 카메라 설치셋에 대한 제어 신호 를 전송함으로써, 원격으로 카메라의 팬틸트 값을 변경하거나, 폴대의 엘리베이션 값을 변경함으로써, 원하는 모니터링 대상 공간에 대한 영상 정보 및 레이저 측정값을 획득할 수 있다. 일 실시 예에 의하면, 엘리베이션 폴대는 미리 설정된 높이 값(예컨대 20m)이상 연장될 수 있으며, 팬틸 트는 Pan 360도, tilt는 -30도 내지 30도까지 제어될 수 있으나, 이에 한정되는 것은 아니다. 또한, 일 실시 예에 의하면 카메라 하우징은 30KG 이상의 무게를 지지하도록 마련될 수 있으며, 본 개시에 따른 관 제 단말과 연결되는 경보 장치의 경보음은 90Db/1m 이상의 성능 조건을 만족하도록 마련될 수 있다. 일 실시 예 에 의하면 카메라 하우징 내부에는 카메라 셋이 마련될 수 있다. 일 실시 예에 의하면, 카메라 셋 은 OGI 가스 이미징 카메라, 레이저 측정기 및 EO 카메라를 포함할 수 있다. 일 실시 예에 의하면 카메라의 구성들은 모두 카메라 설치셋으로 포함될 수 있음은 물론이다. 관제 단말기 는 복수의 컴퓨터 조립체 서버 장치와 컴퓨터 조립체 전용 모니터 장치를 포함할 수 있다. 도 29는 일 실시 예에 따른 서버의 블록도이다. 일 실시 예에 의하면, 서버는 네트워크 인터페이스, 데이터 베이스 및 프로세서를 포 함할 수 있다. 도 29에 도시된 서버의 구성은 도 24에 도시된 인공지능 기반 가스 누출 탐지 서버, 경보 및 제어 서버에 대응될 수 있으며, 도 1의 관제 서버의 구성에 대응될 수 있다. 네트워크 인터페이스는 상술한 전자 장치의 네트워크 인터페이스(미도시)에 대응될 수 있다. 예를 들어, 네트워크 인터페이스는 전자 장치로부터 복수 타입의 영상 정보, 인공지능 모델의 분석 결과, 누출 원점, 흐름 벡터, 누출 영상, 합성 영상에 대한 정보를 획득할 수 있다. 또 다른 실시 예에 의하면, 네트워크 인터페이스는 전자 장치가 학습된 인공지능 모델에 대한 정보, 또는 신경망 모델에 대한 정보 (예컨대 레이어들 및 레이어들 사이의 연결 강도에 관한 가중치 값)를 수신할 수 있다. 또 다른 실시 예에 의하 면, 네트워크 인터페이스는 서버가 학습시킨 인공지능 모델에 대한 정보로, 인공 신경망의 레이어들 및 레이어들에 포함된 노드에 관한 정보 또는 신경망 내 레이어들의 연결 강도에 관한 가중치 값들을 전자 장치 로 전송할 수도 있다. 또한, 일 실시 예에 의하면 데이터 베이스는 도 26 내지 도 27에서 상술한 메모리에 대응될 수 있다. 예 를 들어, 데이터 베이스는 전자 장치로부터 획득되는 영상 정보들, 레이저 측정 값, 인공지능 모델 의 분석 결과, 합성 영상, 인공지능 모델 자체에 대한 정보 등을 저장할 수 있다. 일 실시 예에 의하면 데이터 베이스는 키워드 일부와 단어 조합만으로 데이터 베이스 정보 조회가 가능하도록 설계되며, 날짜, 시간 및 카메라 위치 별 소정의 영상 데이터가 검색 및 조회가 가능하도록 설계될 수 있다. 또한, 일 실시 예에 의하면 데이터 베이스는 일반 영상과 표적 객체 검출에 따른 이벤트 발생 시 해당 표 적 객체에 관한 영상에 대한 정보를 제공할 수 있으며, 효율적인 용량 관리를 위해 별도의 동영상 저장 포맷을 이용하여 데이터를 저장할 수 있다. 또한, 데이터 베이스는 기존 저장되어 있는 영상 데이터와 이벤트 발 생 여부 데이터를 join을 이용해 새로운 테이블로 관리할 수 있고, 데이터 무결성 등 데이터 베이스 설계 원칙 을 지키기 위해 테이블 접근 시 view 형식으로 접근 및 원본 테이블 접근을 제한할 수 있다. 또한, 일 실시 예 에 의하면 데이터 베이스는 유지/보수가 용이하게 코드를 procedure 형식으로 관리할 수 있으며, 데이터 베이스 조회 시 최적화를 위해 explain 명령어에 기초하여 데이터를 처리할 수 있으며, 데이터 삭제 내역 관리 를 위한 트리거를 적용할 수 있다. 일 실시 예에 의하면, 프로세서는 서버의 전반적인 동작을 제어할 수 있다. 예를 들어, 프로세서 는 네트워크 인터페이스 및 데이터 베이스를 제어함으로써, 도 1 내지 28에서 기재된 전자장치 또는 가스 누출 탐지 시스템이 수행하는 동작의 전부 또는 적어도 일부를 함께 수행할 수 있다. 도 30은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 제공하는 사용자 인터페이스 화면 을 나타내는 도면이다. 도 30을 참조하면 전자 장치가 제공하는 사용자 인터페이스 화면의 일 예가 도시된다. 도 30에 도시된 사용자 인터페이스 화면은 전자 장치뿐만 아니라, 관제 단말 또는 전자 장치와 연결된 관제 서버에 의해 통제되 는 상황실 시스템의 디스플레이 상에 출력될 수도 있다. 일 실시 예에 의하면, 전자 장치는 카메라 설치 셋 내 복수 타입의 카메라 및 레이저 측정기의 동작을 제어하기 위한 컨트롤 인터페이스, 전자 장치 가 처리하는 영상 정보들을 저장, 관리 및 호출하기 위한 영상 제어 인터페이스를 출력할 수 있다. 전자 장치는 영상 제어 인터페이스를 통해 획득되는 관제자의 사용자 입력에 기초하여 특정 영상에 액세스하거나, 액세스된 특정 영상을 화면상에 출력할 수 있다. 일 실시 예에 의하면, 전자 장치는 컨트롤 인터페이스를 선택하는 사용자 입력에 기초하여, 확대 인터페이스, 포커스 인터페이스 및 센서 인터페이스를 화면상에 추가적으로 제공할 수도 있 다. 일 실시 예에 의하면, 전자 장치는 확대 인터페이스에 대한 사용자 입력에 기초하여, 모니터링 대상 공간 내 특정 영역에 대한 확대 영상을 획득할 수 있다. 또한, 전자 장치는 포커스 인터페이스 에 대한 사용자 입력에 기초하여 미리 지정된 영역에 대한 초점을 자동으로 매칭시키는 포커싱 기능을 수 행할 수 있다. 일 실시 예에 의하면, 전자 장치는 모니터링 대상 공간 내 특정 영역에 대하여 미리 오토 포커싱 영역을 설정해둘 수도 있다. 일 실시 예에 의하면, 전자 장치는 센터 인터페이스에 대한 사 용자 입력에 기초하여, 모니터링 대상 공간 내 위치하는 센서의 동작 환경(셔터 주기, 정보 획득 주기 등)을 변 경할 수 있다. 도 31은 또 다른 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 제공하는 사용자 인터페이스 화면을 나타내는 도면이다. 도 31을 참조하면 전자 장치가 제공하는 사용자 인터페이스 화면의 일 예가 도시된다. 일 실시 예에 의하면, 전 자 장치는 영상 정보들을 저장, 관리 및 호출하기 위한 영상 제어 인터페이스를 제공할 수 있고, 상기 제공된 영상 제어 인터페이스는 비디오 인터페이스를 포함할 수 있다. 예를 들어, 전자 장치 는 비디오 인터페이스를 선택하는 사용자 입력에 기초하여 이미지 인터페이스, 인핸스먼트 인터페이스, 자동 조절 인터페이스 및 설정한 조건들을 저장하기 위한 설정 저장 인터페이스(311 0)를 출력할 수 있다. 일 실시 예에 의하면, 이미지 인터페이스는 현재 표시되는 영상 내 디지털 줌을 통한 영상 확대, 영상의 밝기 값 조절, 명암 값 조절을 위한 사용자 인터페이스를 포함할 수 있다. 일 실시 예에 의하면, 인핸스먼트 인 터페이스는 영상 내 소음 제거, 노이즈 제거와 같은 비디오 데이터의 품질 향상을 위한 편집 인터페이스 들을 포함할 수 있다. 일 실시 예에 의하면 자동 조절 인터페이스은 비디오 클립을 편집하기 위한 인터페 이스를 포함할 수 있고, 설정 저장 인터페이스는 비디오 인터페이스를 통해 변경된 값들을 저장하 기 위한 기능을 제공할 수 있다. 본 개시에 따른 가스 누출 탐지 방법, 가스 누출 탐지를 위한 합성 영상 생성 방법 및 표적 객체의 형상을 식별 하는 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매 체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행 하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같 은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속한다.\n【요약】본 개시는 인공지능 기반 가스 누출을 탐지하는 전자 장치 및 상기 전자 장치가 표적 객체의 형상을 식별하는 방 법에 관한 것이다. 일 실시 예에 의하면, 인공지능 기반 가스 누출을 탐지하는 전자 장치가 표적 객체의 형상을 식별하는 방법은 상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간에 대한 (뒷면에 계속)\n\n【청구항 1】\n인공지능 기반 가스 누출을 탐지하는 전자 장치가 표적 객체의 형상을 식별하는 방법에 있어서,상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간에 대한 제1 타입 영상들을 획득하는 단계;상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간에 대한 제2 타입 영상들을 획득하는 단계; 및상기 제1 타입 영상들 및 상기 제2 타입 영상들이 입력되면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내표적 객체가 검출되는지 여부를 식별하는 객체 인식 모델에, 상기 제1 타입 영상들 및 상기 제2 타입 영상들을입력함으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체 검출 여부를 식별하는 단계;를 포함하고,상기 표적 객체는 연기 객체, 가스 객체 또는 불꽃 객체 중 적어도 하나를 포함하는 것을 특징으로 하는, 방법.\n【청구항 2】\n제1항에 있어서, 상기 방법은상기 제1 타입 영상들 또는 상기 제2 타입 영상들 중 적어도 하나로부터 상기 표적 객체가 검출되는 것으로 식별되는 경우, 상기 표적 객체가 검출된 타입의 영상들로부터 상기 표적 객체의 형상 정보를 추출하는 단계; 를더 포함하는, 방법.\n【청구항 3】\n제2항에 있어서,상기 제1 타입의 카메라 및 상기 제2 타입의 카메라는 각각 EO 카메라 및 OGI 카메라이고, 상기 제1 타입 영상들 및 상기 제2 타입 영상들은 각각 가시광선 영상들 및 적외선 영상들인 것을 특징으로 하는, 방법.\n【청구항 4】\n제3항에 있어서, 상기 방법은상기 객체 인식 모델의 출력 값에 기초하여, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체가 검출되지 않는 것으로 식별되는 경우, 상기 제2 타입 영상들을 푸리에 변환함으로써 주파수 도메인상의 변환영상 정보를 생성하는 단계;상기 변환 영상 정보로부터 상기 표적 객체 및 상기 표적 객체 주변의 배경 간섭물질 각각에 대한 스펙트럼 정보를 추출하는 단계;상기 추출된 스펙트럼 정보가 입력되면 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 출력하는 우도비검정 모델에, 상기 추출된 스펙트럼 정보를 입력함으로써, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별하는 단계; 및상기 표적 객체에 따른 주파수 패턴이 식별되는 경우, 상기 우도비 검정 모델의 출력 값에 기초하여, 상기 제2타입 영상들로부터 상기 표적 객체의 형상 정보를 추출하는 단계; 를 더 포함하는, 방법.공개특허 10-2023-0168242-3-청구항 5 제4항에 있어서, 상기 방법은상기 우도비 검정 모델의 출력 값에 기초하여 상기 표적 객체에 따른 주파수 패턴이 식별되지 않는 경우, 상기추출된 스펙트럼 정보를, 상기 추출된 스펙트럼 정보가 입력되면 상기 표적 객체에 따른 주파수 패턴이 있는지여부를 출력하는 서포트 벡터 머신 모델에 입력함으로써, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른주파수 패턴이 있는지 여부를 식별하는 단계; 및상기 표적 객체에 따른 주파수 패턴이 식별되는 경우, 상기 서포트 벡터 머신 모델의 출력 값에 기초하여, 상기제2 타입 영상들로부터 상기 표적 객체의 형상 정보를 추출하는 단계; 를 더 포함하는, 방법.\n【청구항 6】\n제3항에 있어서, 상기 형상 정보를 추출하는 단계는상기 표적 객체가 검출된 타입의 영상들을 전처리 하는 단계;기 설정된 표적 객체 정보에 기초하여 마스킹 데이터를 생성하는 단계;상기 표적 객체가 검출된 타입의 영상들에 상기 마스킹 데이터를 적용함으로써 생성되는 표적 객체 영역들을,상기 전처리된 영상들로부터 분리하는 단계; 및상기 분리된 표적 객체 영역들로부터 상기 표적 객체의 형상 정보를 추출하는 단계; 를 포함하는, 방법.\n【청구항 7】\n제6항에 있어서, 상기 분리된 표적 객체 영역들로부터 상기 표적 객체의 형상 정보를 추출하는 단계는상기 분리된 표적 객체 영역 내 상기 표적 객체에 관한 외곽선 정보를 식별하는 단계;상기 식별된 상기 외곽선 정보에 기초하여 표적 객체의 중심점 정보를 식별하는 단계;상기 식별된 중심점 정보 및 상기 외곽선 정보에 기초하여 상기 표적 객체 영역의 방향 벡터를 식별하는 단계;및상기 식별된 외곽선 정보, 중심점 정보 및 상기 방향 벡터를 상기 표적 객체의 형상 정보로 추출하는 단계; 를포함하는, 방법.\n【청구항 8】\n제6항에 있어서, 상기 마스킹 데이터를 생성하는 단계는상기 표적 객체가 검출된 타입의 영상들의 현재 프레임 이전의 프레임 이미지들 또는 상기 현재 프레임 이미지들을 포함한 모든 프레임 이미지들에 대한 이동 평균 값을 결정하는 단계; 및상기 결정된 이동 평균 값에 기초하여 상기 마스킹 데이터를 생성하는 단계; 를 포함하는, 방법.\n【청구항 9】\n제8항에 있어서, 상기 방법은 상기 분리된 표적 객체 영역들의 형상 정보에 기초하여, 상기 표적 객체가 검출된 타입의 영상들 내 인접하는표적 객체 영역들 사이의 모션 벡터를 결정하는 단계;상기 결정된 모션 벡터에 기초하여, 상기 분리된 표적 객체 영역들을 모델링하는 단계;공개특허 10-2023-0168242-4-상기 모델링된 표적 객체 영역들을 나타내는 모션 벡터의 합벡터를 결정하는 단계; 및상기 결정된 합벡터에 크기 및 방향에 기초하여, 상기 표적 객체가 검출된 영상들에서, 상기 표적 객체가 생성된 위치에 관한 누출 원점 및 상기 표적 객체의 흐름 방향과 속도에 관한 흐름 벡터를 결정하는 단계; 를 더 포함하는, 방법.\n【청구항 10】\n인공지능 기반 가스 누출을 탐지를 위해, 표적 객체의 형상을 식별하는 전자 장치에 있어서,네트워크 인터페이스;하나 이상의 인스트럭션을 저장하는 메모리; 및상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서; 를 포함하고,상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간에 대한 제1 타입 영상들을 획득하고,상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간에 대한 제2 타입 영상들을 획득하고,상기 제1 타입 영상들 및 상기 제2 타입 영상들이 입력되면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내표적 객체가 검출되는지 여부를 식별하는 객체 인식 모델에, 상기 제1 타입 영상들 및 상기 제2 타입 영상들을입력함으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체 검출 여부를 식별하고,상기 표적 객체는 연기 객체, 가스 객체 또는 불꽃 객체 중 적어도 하나를 포함하는 것을 특징으로 하는, 전자장치.\n【청구항 11】\n제10항에 있어서, 상기 적어도 하나의 프로세서는상기 제1 타입 영상들 또는 상기 제2 타입 영상들 중 적어도 하나로부터 상기 표적 객체가 검출되는 것으로 식별되는 경우, 상기 표적 객체가 검출된 타입의 영상들로부터 상기 표적 객체의 형상 정보를 추출하는, 전자 장치.\n【청구항 12】\n제11항에 있어서,상기 제1 타입의 카메라 및 상기 제2 타입의 카메라는 각각 EO 카메라 및 OGI 카메라이고, 상기 제1 타입 영상들 및 상기 제2 타입 영상들은 각각 가시광선 영상들 및 적외선 영상들인 것을 특징으로 하는, 전자 장치.\n【청구항 13】\n제12항에 있어서, 상기 적어도 하나의 프로세서는상기 객체 인식 모델의 출력 값에 기초하여, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체가 검출되지 않는 것으로 식별되는 경우, 상기 제2 타입 영상들을 푸리에 변환함으로써 주파수 도메인상의 변환영상 정보를 생성하고,상기 변환 영상 정보로부터 상기 표적 객체 및 상기 표적 객체 주변의 배경 간섭물질 각각에 대한 스펙트럼 정보를 추출하고,공개특허 10-2023-0168242-5-상기 추출된 스펙트럼 정보가 입력되면 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 출력하는 우도비검정 모델에, 상기 추출된 스펙트럼 정보를 입력함으로써, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별하고,상기 표적 객체에 따른 주파수 패턴이 식별되는 경우, 상기 우도비 검정 모델의 출력 값에 기초하여, 상기 제2타입 영상들로부터 상기 표적 객체의 형상 정보를 추출하는, 전자 장치.\n【청구항 14】\n제13항에 있어서, 상기 적어도 하나의 프로세서는상기 우도비 검정 모델의 출력 값에 기초하여 상기 표적 객체에 따른 주파수 패턴이 식별되지 않는 경우, 상기추출된 스펙트럼 정보를, 상기 추출된 스펙트럼 정보가 입력되면 상기 표적 객체에 따른 주파수 패턴이 있는지여부를 출력하는 서포트 벡터 머신 모델에 입력함으로써, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른주파수 패턴이 있는지 여부를 식별하고,상기 표적 객체에 따른 주파수 패턴이 식별되는 경우, 상기 서포트 벡터 머신 모델의 출력 값에 기초하여, 상기제2 타입 영상들로부터 상기 표적 객체의 형상 정보를 추출하는, 전자 장치.\n【청구항 15】\n인공지능 기반 가스 누출을 탐지하는 전자 장치가 표적 객체의 형상을 식별하는 방법에 있어서,상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간에 대한 제1 타입 영상들을 획득하는 단계;상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간에 대한 제2 타입 영상들을 획득하는 단계; 및상기 제1 타입 영상들 및 상기 제2 타입 영상들이 입력되면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내표적 객체가 검출되는지 여부를 식별하는 객체 인식 모델에, 상기 제1 타입 영상들 및 상기 제2 타입 영상들을입력함으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체 검출 여부를 식별하는 단계;를 포함하고,상기 표적 객체는 연기 객체, 가스 객체 또는 불꽃 객체 중 적어도 하나를 포함하는 것을 특징으로 하는, 방법을 수행하도록 하는 프로그램이 저장된 컴퓨터로 읽을 수 있는 기록 매체."}
{"context": "", "input": "【기술명】\n나노버블화된 브라운가스의 인공지능 공급 버너장치 시스템\n\n【기술 설명】\n본 발명은 나노버블화된 브라운가스를 인공지능으로 공급하는 버너 장치에 관한 기술로, HHO(수소-산소 혼합가스)를 연료에 직접 혼합함으로써 보일러의 연소 효율성을 극대화하는 혁신적인 시스템입니다. 이 장치는 브라운가스를 연소시키기 위해 설계된 버너와, 브라운가스가 유입되는 유입관, 냉각 기능을 갖춘 본체 및 커넥터로 구성되어 있습니다. 특히, HHO의 혼합 방식은 고객의 기존 보일러를 개조할 필요 없이 간편하게 적용할 수 있도록 하여, 연료 공급 방식의 혁신을 가져옵니다.\n\n【해결 문제】\n기존의 브라운가스 시스템은 연소 시 역화 위험이 존재하며, 이를 방지하기 위한 별도의 장치가 필요했습니다. 본 발명은 HHO를 연료에 직접 혼합하여 공급하므로 이러한 역화 위험을 원천적으로 차단할 수 있습니다. 또한, 브라운가스를 사용함으로써 얻는 에너지 절약 효과와 함께, 환경 친화적인 무공해 연료 사용이 가능하여, 산업계에서 더욱 청정한 에너지 솔루션을 요구하는 필요성을 충족합니다.\n\n【기술 차별성】\n본 발명은 기존 브라운가스 연소 기술과 비교하여, HHO 가스를 직접 혼합하여 공급하는 혁신적인 접근 방식을 채택하고 있습니다. 이로 인해 고객사의 보일러를 개조할 필요가 없으며, 설치 및 운영의 용이성을 극대화하였습니다. 뿐만 아니라, 나노버블화된 브라운가스를 활용함으로써 연소 효율성을 높이고 역화 위험을 제거하는 점에서 독창성을 갖추고 있어, 기존 기술 대비 월등한 성능을 제공합니다.\n\n【활용 분야】\n나노버블화된 브라운가스의 인공지능 공급 버너장치는 에너지 산업, 특히 보일러 및 난방 시스템 분야에서 혁신적인 응용 가능성을 지니고 있습니다. 이 기술은 산업용 및 상업용 보일러의 효율성을 극대화하고, 연료 절약을 통해 운영 비용을 절감할 수 있도록 설계되었습니다. 또한, 가정용 난방 시스템에서도 사용 가능하여, 에너지 소비를 최적화하고 지속 가능한 에너지 솔루션을 제공하는 데 기여할 수 있습니다.\n\n【구성 요소 및 기능】\n1) 브라운가스 버너: 이 핵심 구성 요소는 내부로 유입된 브라운가스를 연소시켜 불꽃을 형성합니다. 이 과정에서 발생하는 열은 보일러의 난방 시스템에 직접 전달되어 에너지 효율성을 높입니다.  \n2) 냉각유로: 이 구조는 가스유로의 외측에 위치하여, 브라운가스의 온도를 효과적으로 제어합니다. 수냉식 또는 공냉식으로 설계되어 있어, 연소 과정에서 발생하는 과열을 방지하고 장치의 내구성을 향상시킵니다.  \n3) 가스배출관: 이 구성 요소는 브라운가스를 안전하게 배출하는 경로를 제공합니다. 가스배출관의 설계는 역화 위험을 최소화하며, 연소 효율성을 극대화하여 안정적인 작동을 보장합니다.\n\n【구현 방식 예】\n이 기술의 구현은 여러 단계로 나뉘어 진행됩니다. 첫째, 고객사의 기존 보일러 시스템에 나노버블화된 브라운가스를 간편하게 연결할 수 있도록 설계된 유입관 및 본체를 설치합니다. 둘째, 브라운가스를 혼합하고 공급하는 시스템을 설정하여 HHO 가스와의 결합을 최적화합니다. 셋째, 냉각유로와 가스배출관을 통해 발생하는 열과 가스를 효과적으로 관리하여, 연소 후의 잔여 물질을 안전하게 배출하는 과정을 완성합니다. 이러한 단계별 접근 방식은 고객에게 기술적 안정성과 효율성을 동시에 제공합니다.", "output": "【발명의 명칭】\n나노버블화된 브라운가스의 인공지능 공급 버너장치\n【기술분야】\n본 발명은 브라운가스 시스템에 관한 것으로, 보다 상세하게는 보일러에 투입되는 연료에 HHO를 직접 혼합 후, 공급하는 방식을 구현하여 고객사의 보일러를 개조할 필요가 없도록 하며, HHO 가스를 연료에 직접 혼합함으로 써, 역화 위험을 원천 차단할 수 있도록 하는 나노버블화된 브라운가스의 인공지능 공급 버너장치에 관한 것이다.\n【배경기술】\n일반적으로, 브라운가스란 물의 전기분해 방식에 의해 생산되는 수소와 산소가 2:1의 혼합비로 혼합된 혼합가스 를 말하 며, 브라운가스만의 4대특성 즉 완전무공해 특성, 완전연소 특성, 임플로젼(Implosion) 특성, 열핵반응 특 성 등을 가지고 있는 아주 이상적인 연료로서 새시대 청정 연료로 각광을 받고있다. 이와 같은 브라운가스는 수소와 산소가 화학당량비 2:1의 완전연소 조건을 갖추고 있으므로 종래의 연소방 법처 럼 산소 공급을 위한 별도의 공기 공급장치와 굴뚝이 필요없다. 브라운가스를 난방에 사용하는 경우, 특별히 환기를 하지 않아도 되므로 에 너지 절약 효과가 크고, 브라 운가 스는 연소후 수증기 상태로 환원됨으로 가습효과도 있어 쾌적한 난방을 할 수 있다. 그러나, 종래에는 브라운가스를 연소시키는 마땅한 방법을 찾지 못하여 경제성을 확보할 수 없었으므로 브 라운 가스를 연료로 사용하지 못한 것이 사실이다. 그 이유로 브라운가스는 연소속도가 빠른 기체이므로 역화(Back- fire) 현상이 일어날 가능성이 많았기 때 문이다. 이에 최근에 이러한 브라운가스의 특성을 극복하여 브라운가스 발생기에서 대량으로 생산되는 브라운가스 를 가 열로, 보일러 등의 산업용 연료로 사용할때 버너측으로부터 역진하는 화염을 차단하기 위한 브라운가 스 역화방 지 장치(대한민국 공개특허공보 제2001-37336호)가 개발되었다. 전기에 언급된 종래 기술은 수개의 브라운가스 발생기에서 생성되는 브라운가스를 포집하는 커스 커플러와; 상 기 가스 커플러에 포집된 브라운가스를 통과시키기 위한 후렛쉬 백 어레스터와; 후렛쉬 백 어 레스터에서 이송 되는 가스중에 함유되어 있는 수분을 제거하기 위한 드레인 캣취와; 상기 드레인 켓취를 통과한 가스를 선택적 으로 공급받아 이에 적당량의 핵산을 가스에 혼입하여 버너로 공급하기 위한 2대의 프레임 모디파이어 및 프레 임 모디파이어에서 공급되는 가스를 연소시키는 버너와 상기의 각 구성에 의한 가스의 공급돠 브라운가스 발생 기의 가동과 중단을 프레숴 콘트롤 루프에 의해 통합 제어하기 위한 시스템 으로 구성되어 있다. 상기와 같은 구성을 갖는 종래 기술은 브라운가스를 연소도중에 역화되는 화염을 유기적으로 작동하는 제 1, 제 2의 프레임 모디파이어에 핵산을 사용하여 화염 의 역화속도를 현저하게 지연시켜 역화를 방지하게 되며, 이 프 레임 모디파이어에 의해 차단되지 않은 화염은 후렛쉬 백 어레스터에서 재차 차단하는 구성으 로 이루어져 있어 역류되는 화염을 효과적으로 차단하게 됨으로 브라운가스를 안전하게 사용할 수 있었다. 그러나, 종래 기술은 브라운발생기와 버너 사이에 제1, 제2의 프레임 모디파이어와 후렛쉬 백 어레스터등 의 역화방지 수단을 별도로 구비함에 따라 가정 뿐만 아니라 산업상에서 브라운가스를 실제로 적용하기에 는 경제적 부담이 크게 초래하게 되는 문제점이 있었다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허 10-2003-0035718\n【해결하려는 과제】\n본 발명의 목적은, 이러한 문제점을 해결하기 위한 것으로, 보일러에 투입되는 연료에 HHO를 직접 혼합 후, 공 급하는 방식을 구현하여 고객사의 보일러를 개조할 필요가 없도록 하며, HHO 가스를 연료에 직접 혼합함으로써, 역화 위험을 원천 차단할 수 있도록 하는 나노버블화된 브라운가스의 인공지능 공급 버너장치를 제공하는데 있 다.\n【과제의 해결 수단】\n상기 과제를 달성하기 위한 본 발명의 실시예에 따른 나노버블화된 브라운가스의 인공지능 공급 버너장치는, 내 부로 유입된 브라운가스를 연소시켜 불꽃을 형성하는 브라운가스 버너에 있어서, 브라운가스가 유입되는 유입관; 전단부에 삽입홈이 형성된 하우징과, 상기 하우징의 중앙에 길이 방향을 따라 형성되고 상기 유입관으 로부터 유 입된 브라운가스가 통과하여 선단측의 가스유출구를 통해 유출되는 가스유로와, 상기 가스유로의 외 측에 길이 방향을 따라 형성된 수냉식 또는 공냉식의 냉각유로를 포함하는 본체; 상기 유입관과 본체를 용접에 의해 연결하되, 상기 냉각유로와 연결된, 냉각을 위한 물 또는 공기가 유입되는 유입공 및 냉각에 사용된 물 또 는 공기가 외부로 배출되는 배출공을 구비한 커넥터; 및 상기 삽입홈에 삽입 결합되어 상기 본체의 선단부를 커 버하되, 상기 가스유출구보다 작은 직경의 내경을 가지면 서 브라운가스가 배출되는 가스배출로가 형성된 가스 배출관과, 상기 가스배출관의 후단부에 연결되어 상기 삽입 홈의 내주면에 고정되고 내부홀에 상기 가스유로의 선단부가 삽입 연결되는 고정편과, 상기 가스배출관의 전단 부에 연결되고 외측으로 확개 형성된 림부와, 상기림부의 내측에 요입 형성되고 내벽면이 오목하게 라운드지도 록 형성된 화구를 포함하는 캡;을 포함하여 이루어 질 수 있다. 또한, 상기 화구가 상기 림부의 내측에 후단측으로 요입 형성되도록 하고, 내측 벽면이 외측으로 오목하게 라운 드지도 록 형성되어 상기 화구가 소정의 곡률반경을 갖도록 오목하게 라운드지도록 형성됨으로써, 긴 불꽃의 형 태를 갖 는 핀포인트 화염과 화구의 내측 벽면이 직접 접촉되지 않게 되므로 상기 캡이 녹아서 용융되거나 손상 되지 않 아 내구성이 우수하여 연속 사용이 가능할 수 있다. 또한, 상기 고정편은 후단부가 전방의 중앙부를 향해 경사지게 형성되어 용접 공간이 추가로 형성되고, 상기 고 정편의 후단부와 상기 가스유로의 선단부의 둘레에 대하여 겹치기 용접을 하여 용접부를 형성할 수 있다.\n【발명의 효과】\n본 발명의 일 실시예에 따르면, 나노버블화된 브라운가스의 인공지능 공급 버너장치에 있어서, 보일러에 투입되 는 연료에 HHO를 직접 혼합 후, 공급하는 방식을 구현하여 고객사의 보일러를 개조할 필요가 없도록 하며, HHO 가스를 연료에 직접 혼합함으로써, 역화 위험을 원천 차단할 수 있도록 한다. 상술한 효과와 더불어 본 발명의 구체적인 효과는 이하\n【발명을실시하기위한구체적인내용】\n이하, 첨부된 도면을 참조하여 본 발명의 동작 원리를 상세히 설명한다. 하기에서 본 발명을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 도 1은 본 발명의 나노버블화된 브라운가스의 인공지능 공급 버너장치의 구성도이다. 도 2는 본 발명의 나노버블화된 브라운가스의 인공지능 공급 버너장치의 단면도이다. 도 3은 본 발명의 나노버블화된 브라운가스의 인공지능 공급 버너장치의 제품 예시도이다. 도 4는 나노버블화된 브라운가스의 인공지능 공급 버너장치의 종류별 버너 제품 예시도이다. 본 발명에 따른 역화 방지를 위한 캡을 구비한 브라운가스 버너는 내부로 유입된 브라운가스를 연소시켜 불꽃을 형성하는 브라운가스 버너에 관한 것으로, 유입관, 본체, 커넥터 및 캡을 포함하여 이루어 진다. 상기 유입관은 브라운가스 발생 장치에 의해 생성된 브라운가스가 유입되는 관으로, 도 2a 및 도 2b와 같 이 지그재그로 복수 회 절곡 형성된 절곡부를 포함할 수 있다. 이는 본체의 내부로 유입되는 대용량 의 브라운가스가 일정한 속도를 유지하면서 유입되게 하는 것인데, 브라운가스의 유입 속도가 높은 경우 브라운 가스가 상기 유입관을 통과하는 거리 및 마찰 증가로 인하여 그 속도가 감소하여 일정한 속도가 유지되면 서 본체의 내부로 유입되는 효과가 더욱 증가하게 되는 것이다. 도 2a 및 도 2b에 도시된 바와 같이, 상기 본체는 하우징, 가스유로, 냉각유로를 포함하여 이루어진다. 상기 하우징은 길이 방향으로 길게 연장 형성되되, 후단부에는 상기 유입관이 삽입되어 용접 결합되 는 커넥터가 연결 설치되고, 전단부에는 삽입홈이 요입 형성된다.상기 삽입홈은 나팔관의 형상을 갖는 캡이 삽입 결합될 수 있는 형상으로 이루어지고, 삽입홈의 선단부는 외측으로 점점 확개되는 형상을 갖는다. 더불어, 상기 삽입홈의 외측 가장자리에는 링 형상의 단 부턱이 형성되고, 상기 삽입홈의 내주면에는 복수 개의 내주홈이 형성된다. 상기 가스유로는 상기 하우징의 중앙에 길이 방향을 따라 형성되고, 상기 유입관으로부터 유입 된 브라운가스가 통과하여 선단의 가스유출구를 통해 유출된다. 상기 냉각유로는 상기 가스유로의 외측에 길이 방향을 따라 형성되고, 상기 커넥터의 유입공 을 통해 냉각유로로 유입된 물 또는 공기가 수냉식 또는 공냉식으로 상기 가스유로를 냉각시키 고, 냉각에 사용된 물 또는 공기는 상기 커넥터의 배출공을 통해 배출된다. 도 4a 및 도 4b에 도시된 바와 같이 상기 커넥터는 상기 유입관과 본체를 용접에 의해 연결하되, 후단부에는 상기 유입관이 삽입되어 용접 결합되고, 전단부에는 상기 본체가 삽입되어 용 접 결합된다. 그리고, 상기 커넥터는 일측에 형성되어 냉각을 위한 물 또는 공기가 유입되는 유입공과, 타측에 형 성되고 냉각에 사용된 물 또는 공기가 외부로 배출되는 배출공을 구비한다. 도 3(a) 및 도 3(b)에 도시된 바와 같이, 상기 캡은 상기 삽입홈에 삽입 결합되어 상기 본체의 선단부를 커버하는 기능을 하고, 가스배출관, 고정편, 림부, 화구를 포함하여 이루어진다. 상기 가스배출관은 상기 가스유출구보다 더 작은 직경의 내경을 가지면서 브라운가스가 외부로 배출 되는 가스배출로가 형성되어 브라운가스가 고속으로 배출되는 곳이고, 이는 베르누이 정리(Bernoulli's theorem)에 의하여 유체가 면적이 넓은 곳에서 좁은 곳으로 이동하게 되면 그 속도가 빨라지는 성질을 이용한 것이다. 상기 고정편은 상기 가스배출관의 후단부에 연장되어 연결되고, 내측에 구비된 내부홀에 상기 가스유로의 선단부가 삽입 연결되며, 상기 삽입홈의 내주면과 상기 가스유로의 선단부의 둘레의 사이에 장착되어 결합된다. 이때, 상기 고정편은 후단부가 전방의 중앙부를 향해 비스듬히 경사지게 형성되어 용접 공간이 추가로 형 성되고, 상기 고정편의 후단부와 상기 가스유로의 선단부의 둘레에 대하여 겹치기 용접을 하여 용접 부(W)를 형성함으로써, 용접되는 면적이 넓어지고 견고한 용접 결합을 이룰 수 있다. 상기 림부는 화구의 가장자리를 형성하는 것으로, 상기 가스배출관의 전단부에 연장되게 연결되 어 외측으로 점점 확개되도록 형성되며, 상기 삽입홈의 내주면을 따라 결합된다. 여기서, 상기 림부는 그 가장자리에 외측으로 돌출된 돌출편이 링 형상으로 형성되고, 상기 돌출편 은 상기 하우징의 선단부, 즉 상기 삽입홈의 외측 가장자리에 형성된 링 형상의 단부턱에 걸림되어 결합된다. 더불어, 상기 림부는 외주면에 복수 개의 지지돌기가 돌출 형성되어 상기 삽입홈의 내주면에 형 성된 복수 개의 내주홈과 결합되어 캡을 지지함으로써 캡이 삽입홈에서 유동되지 않고 견 고한 장착을 유지하고, 분리되는 것을 방지할 수 있다. 아울러, 브라운가스는 일반 가스와는 달리 연소시 응폭(implosion) 현상을 유발하는 성질이 있는데, 이는 연소 시 불꽃이 내부로 모여들면서 초점을 형성하고 주변을 진공화한다. 브라운가스의 불꽃은 응폭 상태가 계속되고 있는 것이며, 이에 따라 브라운가스 불꽃은 핀포인트 화염을 형성하여 불꽃의 형태가 길게 형성되고, 축열은 적 으나 핀포인트 부분에서는 내열재인 세라믹 내화벽돌도 용융시키는 화염 드릴링을 할 수 있을 정도의 막강한 화 력을 과시한다. 따라서, 본 발명에 따른 브라운가스 버너에서는 화구가 상기 림부의 내측에 후단측으로 요입 형성되 도록 하고, 내측 벽면이 외측으로 오목하게 라운드지게 형성되어 상기 화구가 소정의 곡률반경을 갖도록 오목하게 라운드지도록 형성됨으로써, 긴 불꽃의 형태를 갖는 강력한 핀포인트 화염과 화구의 내측 벽면이 직접 접촉되지 않게 되므로, 상기 캡이 녹아서 용융되거나 손상되지 않아 내구성이 우수하여 연속으로 사 용이 가능하게 된다. 이때, 상기 화구는 반구 형상을 갖도록 형성되어 화염(F)의 접촉 가능성을 더욱 감소시킬 수 있다. 이와 같이, 본 발명에 따른 역화 방지를 위한 캡을 구비한 브라운가스 버너는 버너의 선단에 상술한 구성을 갖 는 캡이 구비되어 가스유출구를 보호하고, 캡의 내측에 오목한 형상의 화구를 구비하여 화 염원 이 캡의 외부가 아닌 내부에 형성된다. 따라서, 도 5에 도시된 바와 같이 캡의 화구가 화염(F)을 적당히 감싸 안으면서 내부로부터 화염(F) 의 열과 압력이 외부로 발산되므로, 화염원이 보호되어 외부 간섭에 의해 화염(F)이 소멸됨없이 버너를 연속적 으로 사용할 수 있고, 로 내부에서 비산하는 각종 비산물질(E)과 융융 과정에서 튀어 오른 용융물(M)과 같은 이 물질 및 버너의 외주면을 따라 발생된 수증기(H)가 캡 쪽으로 근접하게 되더라도 화염의 열과 압력에 의하 여 밀려서 이물질과 수증기 잔류물이 가스유출구나 가스배출로를 막거나 버너 내부로 침투되는 것이 방지되며, 이로써 화염(F)이 버너 내부로 역행하여 타 들어가 폭발 및 화재 등 중대 재해의 발생이 방지되어 설 비를 보존하고 안전한 작업환경을 제공할 수 있는 것이다. 또한, 화구가 소정의 곡률반경을 갖도록 오목하게 라운드지도록 형성되어 화염(F)이 화구의 내측 벽 면이 직접 접촉되지 않으므로 캡이 녹아서 용융되거나 손상되지 않고, 캡이 본체에 견고하게 결 합되어 이탈이 방지되므로, 내구성이 우수하고 중간에 작업을 중단함 없이 지속적으로 작업할 수 있어 작업 시 간 및 비용이 절감될 수 있다. 따라서 본 발명의 브라운가스 슈팅버너는 상기 압축공기 노즐의 파이프 나사부(120b)에 압축공기 라 인을 연결하고 반대편에 브라운가스 노즐을 조립하며 상기 브라운가스 인입공에는 후렛쉬백 아 레스터에서 바로 나오는 제1 브라운가스 라인을 연결하고 제1 브라운가스 라인의 일측에 후레임 모디파이어를 거쳐 나오는 제2 브라운가스 라인을 연결한 것이다. 본 발명의 브라운가스 버닝시스템은 압축공기 라인에는 NO.1 솔레노이드 밸브를 설치하고 제1 브라운가스 라인에는 NO.2 솔레노이드 밸브를 설치하여 NO.1과 NO.2가 동시에 열리고 닫히도록 하며 제2 브라운가스 라인에는 NO.3와 NO.4 솔레노이드 밸브(153, 154)를 설치하여 NO.3와 NO.4가 동시에 열리 고 닫히도록 구성한 것이다. 또, 상기 후렛쉬백 아레스터와 후레임 모디파이어의 유니트 전면의 상단에 컨트롤박스를 형성하 여 상기 NO.1 NO.2 NO.3 NO.4 솔레노이드 밸브(151, 152, 153, 154) 전부를 내장시키고 컨트롤박스 전면 에는 버너 점화버튼과 소화버튼이 형성된 것이다. 또, 제2 브라운가스 라인의 NO.3 솔레노이드 밸브와 제1 브라운가스 라인의 NO.2 솔레노이드 밸 브의 사이에 타이머를 설치하여 타이머에 설정된 시간(점화기간)이 지나면 제2 브라운가스 라인의 NO.3 NO.4 솔레노이드 밸브가 닫히고 동시에 압축공기 라인의 NO.1 솔레노이드 밸브와 제1 브라운가 스 라인의 NO.2 솔레노이드 밸브가 열리도록 구성한 것이다. 따라서 본 발명은 점화 버튼을 누르면 제2 브라운가스 라인의 NO.3 NO.4 솔레노이드 밸브가 열리면서 브 라운가스 노즐팁에 설치된 이그나이터(점화기)에 의해 바로 착화되도록 하고 점화기간이 지나면 제2 브라운가스 라인의 NO.3 NO.4 솔레노이드 밸브가 닫히고 압축공기 라인의 NO.1 솔레노이드 밸브와 제1 브 라운가스 라인의 NO.2 솔레노이드 밸브가 동시에 열리면서 버너팁에 불이 붙지 않는 상태로 브라운가 스가 열분해실의 소각물쪽으로 슈팅 되도록 구성한 것이다. 상술한 바와 같이, 본 발명의 일 실시예에 따르면, 나노버블화된 브라운가스의 인공지능 공급 버너장치에 있어 서, 보일러에 투입되는 연료에 HHO를 직접 혼합 후, 공급하는 방식을 구현하여 고객사의 보일러를 개조할 필요 가 없도록 하며, HHO 가스를 연료에 직접 혼합함으로써, 역화 위험을 원천 차단할 수 있도록 한다. 이상과 같이 본 발명에 대해서 예시한 도면을 참조로 하여 설명하였으나, 본 명세서에 개시된 실시 예와 도면에 의해 본 발명이 한정되는 것은 아니며, 본 발명의 기술사상의 범위 내에서 통상의 기술자에 의해 다양한 변형이 이루어질 수 있음은 자명하다. 아울러 앞서 본 발명의 실시 예를 설명하면서 본 발명의 구성에 따른 작용 효과 를 명시적으로 기재하여 설명하지 않았을 지라도, 해당 구성에 의해 예측 가능한 효과 또한 인정되어야 함은 당 연하다.\n【요약】본 발명의 일 실시예에 따르면, 나노버블화된 브라운가스의 인공지능 공급 버너장치에 있어서, 보일러에 투입되 는 연료에 HHO를 직접 혼합 후, 공급하는 방식을 구현하여 고객사의 보일러를 개조할 필요가 없도록 하며, HHO 가스를 연료에 직접 혼합함으로써, 역화 위험을 원천 차단할 수 있도록 한다.\n\n【청구항 1】\n나노버블화된 브라운가스의 인공지능 공급 버너장치로서,내부로 유입된 브라운가스를 연소시켜 불꽃을 형성하는 브라운가스 버너에 있어서, 브라운가스가 유입되는 유입관;전단부에 삽입홈이 형성된 하우징과, 상기 하우징의 중앙에 길이 방향을 따라 형성되고 상기 유입관으로부터 유입된 브라운가스가 통과하여 선단측의 가스유출구를 통해 유출되는 가스유로와, 상기 가스유로의 외측에 길이방향을 따라 형성된 수냉식 또는 공냉식의 냉각유로를 포함하는 본체;상기 유입관과 본체를 용접에 의해 연결하되, 상기 냉각유로와 연결된, 냉각을 위한 물 또는 공기가 유입되는유입공 및 냉각에 사용된 물 또는 공기가 외부로 배출되는 배출공을 구비한 커넥터; 및상기 삽입홈에 삽입 결합되어 상기 본체의 선단부를 커버하되, 상기 가스유출구보다 작은 직경의 내경을 가지면서 브라운가스가 배출되는 가스배출로가 형성된 가스배출관과, 상기 가스배출관의 후단부에 연결되어 상기 삽입홈의 내주면에 고정되고 내부홀에 상기 가스유로의 선단부가 삽입 연결되는 고정편과, 상기 가스배출관의 전단부에 연결되고 외측으로 확개 형성된 림부와, 상기 림부의 내측에 요입 형성되고 내벽면이 오목하게 라운드지도록 형성된 화구를 포함하는 캡;을 포함하여 이루어지는 나노버블화된 브라운가스의 인공지능 공급 버너장치.\n【청구항 2】\n제 1 항에 있어서,상기 화구가 상기 림부의 내측에 후단측으로 요입 형성되도록 하고, 내측 벽면이 외측으로 오목하게 라운드지도록 형성되어 상기 화구가 소정의 곡률반경을 갖도록 오목하게 라운드지도록 형성됨으로써, 긴 불꽃의 형태를 갖는 핀포인트 화염과 화구의 내측 벽면이 직접 접촉되지 않게 되므로 상기 캡이 녹아서 용융되거나 손상되지 않아 내구성이 우수하여 연속 사용이 가능한 것을 특징으로 하는 나노버블화된 브라운가스의 인공지능 공급 버너장치.\n【청구항 3】\n제 1 항에 있어서,상기 고정편은 후단부가 전방의 중앙부를 향해 경사지게 형성되어 용접 공간이 추가로 형성되고, 상기 고정편의후단부와 상기 가스유로의 선단부의 둘레에 대하여 겹치기 용접을 하여 용접부를 형성한 것을 특징으로 하는 나노버블화된 브라운가스의 인공지능 공급 버너장치."}
{"context": "", "input": "【기술명】\n인공지능 모델을 위한 학습 데이터를 증강하기 위한 방법 및 시스템\n\n【기술 설명】\n본 발명은 인공지능 모델을 위한 학습 데이터를 증강하기 위한 혁신적인 방법 및 장치에 관한 것입니다. 이 기술은 의료 분야에서의 인공지능 알고리즘의 효율성을 극대화하기 위해 설계되었습니다. 특히, 대량의 의료 데이터를 활용하여 인공지능 모델의 학습 과정을 개선하고 데이터의 다양성을 증가시키는 데 중점을 둡니다. 이를 통해 인공지능 모델은 보다 정확한 진단 및 예측을 수행할 수 있도록 돕습니다.\n\n【해결 문제】\n현재 의료 분야에서는 인공지능 알고리즘의 성능이 데이터의 양과 질에 크게 의존하고 있습니다. 그러나 고품질의 학습 데이터 확보는 시간과 비용이 많이 소요되는 과정으로, 이는 인공지능 모델의 발전을 저해하는 요인으로 작용합니다. 본 발명은 이러한 문제를 해결하기 위해 데이터 증강 기술을 통해 기존 데이터의 다양성을 확보하고, 인공지능 모델의 학습 능력을 향상시키는 데 기여합니다. 이는 궁극적으로 더 나은 의료 서비스를 제공하고, 질병 진단 및 치료의 정확성을 높이는 데 필수적입니다.\n\n【기술 차별성】\n본 발명은 기존의 데이터 수집 및 처리 방식과 차별화된 접근 방식을 제시합니다. 기존 기술들은 주로 정형화된 데이터에 의존하는 반면, 본 발명은 비정형 데이터와 다양한 데이터 소스를 통합하여 학습 데이터를 증강합니다. 또한, 이 방법은 인공지능 모델의 학습 효율성을 높이는 동시에, 의료 데이터의 불균형 문제를 해결하는 혁신적인 솔루션을 제공합니다. 이러한 기술적 차별성은 인공지능 기반 의료 진단 및 치료의 정확성을 크게 향상시키며, 산업 전반에 긍정적인 영향을 미칠 것입니다.\n\n【활용 분야】\n본 발명은 인공지능 모델의 학습 데이터를 증강하기 위한 방법 및 장치로, 주로 의료 영상 진단, 자율주행 차량, 제조업의 품질 관리, 그리고 소셜 미디어 콘텐츠 분석 등 다양한 분야와 산업에 활용될 수 있습니다. 의료 분야에서는 CT 및 MRI 이미지의 잡음 제거와 데이터 증강을 통해 진단의 정확성을 높일 수 있으며, 자율주행 차량에서는 센서 데이터의 품질을 개선하여 안전성을 강화할 수 있습니다. 제조업에서는 품질 검사에 필요한 AI 모델의 성능을 향상시켜 생산성을 극대화하고, 소셜 미디어에서는 사용자 생성 콘텐츠의 분석 정확도를 높이는 데 기여할 수 있습니다.\n\n【구성 요소 및 기능】\n본 발명은 세 가지 주요 구성 요소로 이루어져 있습니다. 첫째, **잡음 필터**는 복수의 잡음 영상에서 스패클 패턴을 분석하여 불필요한 잡음을 효과적으로 제거하는 기능을 수행합니다. 둘째, **데이터 증강 모듈**은 필터링된 데이터를 기반으로 다양한 변형(회전, 이동, 확대 등)을 생성하여 학습 데이터의 다양성을 증대시키고 모델의 일반화 능력을 향상시킵니다. 셋째, **학습 최적화 알고리즘**은 증강된 데이터를 활용하여 인공지능 모델의 학습 과정을 최적화하며, 학습 속도 및 정확도를 극대화하는 기능을 제공합니다.\n\n【구현 방식 예】\n구현 방식은 다음과 같은 단계로 진행됩니다. 첫 번째 단계는 **데이터 수집**으로, 다양한 출처에서 잡음이 포함된 학습 데이터를 수집합니다. 두 번째 단계는 **잡음 필터링**으로, 수집된 데이터에서 잡음 필터를 적용하여 스패클 패턴을 분석하고 불필요한 잡음을 제거합니다. 세 번째 단계는 **데이터 증강**으로, 필터링된 데이터를 활용하여 다양한 변형 데이터를 생성하며, 마지막으로 네 번째 단계는 **모델 학습**으로, 생성된 증강 데이터를 통해 인공지능 모델을 학습시켜 성능을 극대화합니다. 이 모든 과정은 자동화된 시스템으로 구축되어 효율성을 극대화합니다.", "output": "【발명의 명칭】\n인공지능 모델을 위한 학습 데이터를 증강하기 위한 방법 및 장치\n【기술분야】\n본 발명은 인공지능(artificial intelligence, AI) 모델에 대한 것으로, 특히, 인공지능 모델을 위한 학습 데이 터를 증강(augmentation)하기 위한 방법 및 장치에 대한 것이다.\n【배경기술】\n질병은 인간의 심신에 장애를 일으켜서 정상적인 기능을 저해하는 상태를 의미하는 것으로, 질병에 따라 인간은 고통을 받고 심지어 생을 유지하지 못할 수 있다. 따라서, 질병을 진단하고, 치료하고 나아가 예방하기 위한 다 양한 사회적 시스템 및 기술들이 인류의 역사와 함께 발전해왔다. 질병의 진단 및 치료에 있어서, 기술의 눈부 신 발전에 따라 다양한 도구들 및 방식들이 개발되어 왔지만, 아직까지, 종국적으로는 의사의 판단에 의존하고 있는 현실이다. 한편, 최근 인공지능(artificial intelligence, AI) 기술이 크게 발전하면서 다양한 분야에서 주목되고 있다. 특히, 방대한 양의 누적된 의료 데이터와, 영상 위주의 진단 데이터 등의 환경으로 인해, 의료 분야에 인공지능 알고리즘을 접목하려는 다양한 시도와 연구가 진행 중이다. 구체적으로, 질병을 진단, 예측하는 등 종래의 임상 적 판단에 머물러 있던 작업들을 인공지능 알고리즘을 이용하여 해결하려는 다양한 연구가 이루어지고 있다. 또 한, 진단 등을 위한 중간 과정으로서 의료 데이터를 처리하고 분석하는 작업을 인공지능 알고리즘을 이용하여 해결하려는 다양한 연구가 이루어지고 있다. 선행기술문헌 미국공개특허 US 2019/0261945 (2019.08.29) 유럽공개특허 EP 3804624 (2021.04.14)\n【해결하려는 과제】\n또 다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다.\n【과제의 해결 수단】\n본 발명에 대하여 위에서 간략하게 요약된 특징들은 후술하는 본 발명의 상세한 설명의 예시적인 양상일 뿐이며, 본 발명의 범위를 제한하는 것은 아니다.\n【발명의 효과】\n아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다.\n【발명을실시하기위한구체적인내용】\n이하에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나, 본 발명은 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 본 발명의 실시예를 설명함에 있어서 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그에 대한 상세한 설명은 생략한다. 그리고, 도면에서 본 발명에 대한 설명과 관계없 는 부분은 생략하였으며, 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 본 발명의 일 실시예에 따른 시스템을 도시한다. 도 1을 참고하면, 시스템은 서비스 서버, 데이터 서버, 적어도 하나의 클라이언트 장치를 포함 한다. 서비스 서버는 인공지능 모델 기반의 서비스를 제공한다. 즉, 서비스 서버는 인공지능 모델을 이용하 여 학습 및 예측 동작을 수행한다. 서비스 서버는 네트워크를 통해 데이터 서버 또는 적어도 하나의 클라이언트 장치와 통신을 수행할 수 있다. 예를 들어, 서비스 서버는 데이터 서버로부터 인공 지능 모델을 훈련하기 위한 학습 데이터를 수신하고, 훈련을 수행할 수 있다. 서비스 서버는 적어도 하나 의 클라이언트 장치로부터 학습 및 예측(prediction) 동작에 필요한 데이터를 수신할 수 있다. 또한, 서비 스 서버는 적어도 하나의 클라이언트 장치에게 예측 결과에 대한 정보를 송신할 수 있다. 데이터 서버는 서비스 서버에 저장된 인공지능 모델의 훈련을 위한 학습 데이터를 제공한다. 다양한 실시예들에 따라, 데이터 서버는 누구나 접근 가능한 공공 데이터를 제공하거나 또는 허가를 필요로 하는 데이터를 제공할 수 있다. 필요에 따라, 학습 데이터는 데이터 서버에 의해 또는 서비스 서버에 의해 전처리할 수 있다. 다른 실시예에 따라, 데이터 서버는 생략될 수 있다. 이 경우, 서비스 서버는 외 부에서 훈련된 인공지능 모델을 사용하거나 또는 서비스 서버에 오프라인으로 학습 데이터가 제공될 수 있 다. 적어도 하나의 클라이언트 장치는 서비스 서버에 의해 운용되는 인공지능 모델에 관련된 데이터를 서 비스 서버와 송신 및 수신한다. 적어도 하나의 클라이언트 장치는 사용자에 의해 사용되는 장비이며, 사용자에 의해 입력되는 정보를 서비스 서버에게 송신하고, 서비스 서버로부터 수신되는 정보를 저장 하거나 사용자에게 제공(예: 표시)할 수 있다. 경우에 따라, 어느 하나의 클라이언트로부터 송신된 데이터에 기 반하여 예측 동작이 수행되고, 예측의 결과에 관련된 정보가 다른 클라이언트에게 제공될 수 있다. 적어도 하나 의 클라이언트 장치는 데스크탑 컴퓨터, 랩탑 컴퓨터, 스마트폰, 타블렛, 웨어러블 기기 등 다양한 형태의 컴퓨팅 장치일 수 있다. 도 1에 도시되지 아니하였으나, 시스템은 서비스 서버를 관리하기 위한 관리 장치를 더 포함할 수 있다. 관리 장치는 서비스를 관리하는 주체에 의해 사용되는 장치로서, 서비스 서버의 상태를 모니터링하거나, 서비스 서버의 설정을 제어한다. 관리 장치는 네트워크를 통해 서비스 서버에 접속하거나 또는 케이 블 연결을 통해 직접 연결될 수 있다. 관리 장치의 제어에 따라, 서비스 서버는 동작을 위한 파라미터를 설정할 수 있다. 도 1을 참고하여 설명한 바와 같이, 서비스 서버, 데이터 서버, 적어도 하나의 클라이언트 장치 , 관리 장치 등이 네트워크를 통해 연결되고, 상호작용할 수 있다. 여기서, 네트워크는 유선 네트워크 및 무선 네트워크 중 적어도 하나를 포함할 수 있고, 셀룰러 네트워크, 근거리 네트워크, 광역 네트워크 중 어느 하나 또는 둘 이상의 조합으로 이루어질 수 있다. 예를 들어, 네트워크는 LAN(local area network), WLAN(wireless LAN), 블루투스(bluetooth), LTE(long term evolution), LTE-A(LTE-advanced), 5G(5th generation) 중 적어도 하나에 기반하여 구현될 수 있다. 도 2는 본 발명의 일 실시예에 따른 장치의 구조를 도시한다. 도 2에 예시된 구조는 도 1의 서비스 서버, 데이터 서버, 적어도 하나의 클라이언트 장치의 구조로 이해될 수 있다. 도 2를 참고하면, 장치는, 통신부, 저장부, 제어부를 포함한다. 통신부는 네트워크에 접속하고, 다른 장치와 통신을 수행하기 위한 기능을 수행한다. 통신부는 유선 통신 및 무선 통신 중 적어도 하나를 지원할 수 있다. 통신을 위해, 통신부는 RF(radio frequency) 처리 회로, 디지털 데이터 처리 회로 중 적어도 하나를 포함할 수 있다. 경우에 따라, 통신부는 케이블을 연결 하기 위한 단자를 포함하는 구성요소로 이해될 수 있다. 통신부는 데이터, 신호를 송신 및 수신하기 위한 구성요소이므로, '송수신부(transceiver)'라 지칭될 수 있다. 저장부는 장치의 동작을 위해 필요한 데이터, 프로그램, 마이크로 코드, 명령어 집합, 어플리케이션 등을 저장한다. 저장부는 일시적 또는 비일시적 저장 매체로 구현될 수 있다. 또한, 저장부는 장치에 고정 되어 있거나, 또는 분리 가능한 형태로 구현될 수 있다. 예를 들어, 저장부는 콤팩트 플래시(compact flash, CF) 카드, SD(secure digital) 카드, 메모리 스틱(memory stick), 솔리드 스테이트 드라이브(solid- state drive; SSD) 및 마이크로(micro) SD 카드 등과 같은 낸드 플래시 메모리(NAND flash memory), 하드 디스 크 드라이브(hard disk drive; HDD) 등과 같은 마그네틱 컴퓨터 기억 장치 중 적어도 하나로 구현될 수 있다. 제어부는 장치의 전반적인 동작을 제어한다. 이를 위해, 제어부는 적어도 하나의 프로세서, 적어도 하나의 마이크로 프로세서 등을 포함할 수 있다. 제어부는 저장부에 저장된 프로그램을 실행하고, 통 신부를 통해 네트워크에 접속할 수 있다. 특히, 제어부는 후술하는 다양한 실시예들에 따른 알고리즘 들을 수행하고, 후술하는 실시예들에 따라 장치가 동작하도록 제어할 수 있다. 도 1 및 도 2를 참고하여 설명한 구조에 기반하여, 본 발명의 다양한 실시예들에 따른 인공지능 알고리즘 기반 의 서비스가 제공될 수 있다. 여기서, 인공지능 알고리즘을 구현하기 위해 인공 신경망으로 이루어진 인공지능 모델이 사용될 수 있다. 인공 신경망의 구성 단위인 퍼셉트론(perceptron) 및 인공 신경망의 개념은 다음과 같 다. 퍼셉트론은 생물의 신경 세포를 모델링한 것으로서, 다수의 신호들을 입력으로 삼아 하나의 신호를 출력하는 구 조를 가진다. 도 3은 본 발명에 적용 가능한 인공지능 모델을 구성하는 퍼셉트론의 예를 도시한다. 도 3을 참고 하면, 퍼셉트론은 입력 값들(예: x1, x2, x3, …, xn) 각각 대하여 가중치들(302-1 내지 302-n)(예: w1j, w2j, w3j, …, wnj)을 곱한 후, 가중치 곱해진(weighted) 입력 값들을 변환 함수(transfer function)을 이용하여 합산한다. 합산 과정에서, 바이어스(bias) 값(예: bk)이 더해질 수 있다. 퍼셉트론은 변환 함수의 출력인 네트(net) 입력 값(예: netj)에 대하여 활성 함수(activation function)을 적용함으로써, 출력 값(예: o j)를 생성한다. 경우에 따라, 활성 함수은 임계치(예: θj)에 기반하여 동작할 수 있다. 활성 함수는 다양 하게 정의될 수 있다. 본 발명이 이에 제한되는 것은 아니나, 예를 들어, 활성 함수로서, 스텝 함수(step function), 시그모이드(sigmoid), Relu, Tanh 등이 사용될 수 있다. 도 3와 같은 퍼셉트론들이 나열되고, 레이어를 이룸으로써 인공 신경망이 설계될 수 있다. 도 4는 본 발명에 적 용 가능한 인공지능 모델을 구성하는 인공 신경망의 예를 도시한다. 도 4에서, 원으로 표현된 각 노드는 도 3의 퍼셉트론으로 이해될 수 있다. 도 4를 참고하면, 인공 신경망은 입력 레이어(input layer), 복수의 은닉 레이어(hidden layer)들(404a, 404b), 출력 레이어(output layer)를 포함한다. 예측을 수행하는 경우, 입력 레이어의 각 노드로 입력 데이터가 제공되면, 입력 데이터는 입력 레이어 , 은닉 레이어들(404a, 404b)을 이루는 퍼셉트론들에 의한 가중치 적용, 변환 함수 연산 및 활성 함수 연 산 등을 거쳐 출력 레이어까지 순전파(forward propagation)된다. 반대로, 훈련을 수행하는 경우, 출력 레 이어로부터 입력 레이어를 향한 역전파(backward propagation)를 통해 오차가 계산되고, 계산된 오차 에 따라 각 퍼셉트론에 정의된 가중치 값들이 갱신될 수 있다. 심층 학습은 의료 영상에 관련된 다양한 작업들, 예를 들어, 분류, 세그먼테이션, 사물 인식 등에 있어서 매우 강력한 수단이 되었다. 그러나, 오버피팅(overfitting)을 방지하기 위해, 매우 큰 양의 데이터를 필요로 하는데, 의료 영상을 획득하고, 레이블링하는 것은 큰 비용을 요구한다. 데이터 증강(augmentation)은 주어진 데이터세트의 양(amount) 및 다양성(diversity) 모두를 증가시키는데 효과적인 기술이다. 데이터 증강은 학습 데이터를 부풀리는 것(inflating)으로, 가장 일반적인 방식으로서 플립(flip), 변환(translation), 색상 조절 (clolor transformation) 등이 사용된다. 본 발명은 영상에서 나타나는 스패클 잡음(speckle noise)을 이용한 데이터 증강 기술을 제안한다. 제안되는 기 술은 영상에서 발생하는 스패클 잡음의 특징을 효과적으로 반영할 수 있다. 스패클 잡음은 증식력 있는 (multiplicative) 잡음으로도 알려져 있다. 스패클 잡음의 특징들 중 하나는 감쇄(attenuation)로서, 이는 영상 을 더 어둡게 만든다. 스패클 잡음은 주로 초음파 영상에서 관찰되기도 한다. 스패클 잡음의 패턴(pattern)은 초음파 파라미터 설정에 크게 의존한다. 예를 들어, 공간 해상도(spatial resolution)를 조절하는 주파수는 SNR(signal to noise ratio)에 영향을 주고, 높은 어코스틱 주파수(high acoustic frequencies)는 낮은 SNR로부터 악영향을 받는다. 다이나믹 레인지(dynamic range)는 이미지의 대비(contrast) 및 픽셀 강도(pixel intensities)에 영향을 준다. 초음파 장비의 운용자는 TGC(time gain compensation), 주파수, 다이나믹 레인지 등의 파라미터를 영상 품질을 높이기 위해 수동으로 조절한다. 높은 주파수의 초음파로 인해 감쇄가 나타나면, 숙련된 운용자는 신호 이득을 증가시키기 위해 TGC를 조절할 것이다. 이와 같이, 영상 품질이 운용자의 숙련도(proficiency)에 크게 의존하므 로, 초음파 영상은 높은 내부적-외부적(inter-intra) 변동성(variability)에 영향을 받는 것으로 알려져 있다. 따라서, 본 발명은 원본 영상을 재구성함으로써 덜 숙련된 운용자에 의해 생성된 영상과 같은 저품질 영상을 생 성하는 실시예들을 제안한다. 영상의 다양한 품질들을 통해, 학습 데이터의 증강이 이루어질 수 있고, 이를 활 용하여 인공지능 모델에 대한 훈련이 효과적으로 수행될 수 있을 것이다. 이하 본 발명은 심장 초음파 영상을 예로 들어 다양한 실시예들을 설명하나, 후술되는 다양한 실시예들은 다른 대상에 대한 또는 다른 종류의 영상 들에도 적용될 수 있음은 자명하다. 도 5는 본 발명의 일 실시예에 따른 데이터 증강(augmentation)의 예를 도시한다. 도 5는 원본 영상 및 목 표 영상을 예시한다. 원본 영상은 제1 초음파 촬영 장비를 이용하여 촬영된 영상이고, 목표 영상 은 제2 초음파 촬영 장비를 이용하여 촬영된 영상이다. 즉, 원본 영상에 대한 증강은 제2 초음파 촬 영 장비를 이용하여 촬영된 것과 같은 특성을 가지는 영상을 생성하기 위해 수행될 수 있다. 예를 들어, 제2 초 음파 촬영 장비에 의해 촬영된 의료 영상을 인공지능 모델(예: 도 4와 같은 구조를 포함하는 인공지능 모델)을 이용하여 분석하고자 하는 경우, 제2 초음파 촬영 장비에 의해 촬영된 복수의 영상들이 학습 데이터로서 필요할 것이다. 하지만, 제2 초음파 촬영 장비에 의해 촬영된 영상이 충분하지 아니한 경우, 제1 초음파 촬영 장비에 의해 촬영된 영상들을 이용하여 제2 초음파 촬영 장비에 의해 촬영된 것과 같은 영상들을 합성함으로써 데이터 를 증강하는 것이 가능하다. 도 5에 예시된 영상들(510, 520)을 참고하면, 제2 초음파 촬영 장비에 의해 촬영된 목표 영상은, 제1 초음 파 촬영 장비에 의해 촬영된 원본 영상에 비하여, 낮은 선명도를 가지는 것으로 보여진다. 여기서, 낮은 선명도를 잡음의 존재의 부가에 의한 것으로 해석될 수 있다. 이러한 해석에 근거하여, 본 발명의 다양한 실시 예들에 따라, 원본 영상에 잡음 필터를 적용함으로써 목표 영상과 유사한 특성을 가지는 합성된 영상 이 생성될 수 있다. 이때, 하나 또는 그 이상의 잡음 필터가 적용될 수 있으며, 적용되는 잡음 필터는 훈련된 인공지능 모델에 입력되는 영상을 촬영하기 위해 사용될 초음파 촬영 장비(이하 '대상 장비')에 기반하여 정의 될 수 있다. 적용 가능한 잡음 필터의 예들은 이하 도 6a 내지 도 6l와 같다. 도 6a 내지 도 6l은 본 발명의 일 실시예에 따 른 데이터 증강을 위해 사용되는 잡음 필터의 예들을 도시한다. 일 실시예에 따라, 잡음의 속성을 수학적으로 모델링함으로써 잡음 필터들이 생성될 수 있다. 다른 실시예에 따라, 도 6a 내지 도 6l의 예들과 같이, 대상 장 비를 이용하여 빈 공간을 촬영함으로써 잡음 필터들이 생성될 수 있다. 잡음 필터들은 대상 장비의 설정 파라미 터의 값들의 조합에 따라 도 6a 내지 도 6l와 같은 다양하게 도출될 수 있다. 즉, 본 발명의 다양한 실시예들에 따라 증강을 위해 사용되는 잡음은 랜덤화된 잡음이 아닌 의도적으로 설계된 잡음으로 이해될 수 있다. 예를 들어, 설정 파라미터들은 다이나믹 레인지(dynamic range, DR), 이득(gain), 깊이(depth), TGC(time gain control), 하모닉스(hamonics×3), 포커스(focus) 중 적어도 하나를 포함할 수 있다. 여기서, 다이나믹 레인지 는 이미지의 대조(contrast)를 조절하는 기능, 이득은 이미지의 전체적인 밝기를 조절하는 기능, 깊이는 관심있 는 구조물 (region of interest) 가장 잘 보이는 깊이를 조절할수 있는 기능, TGC는 영상의 깊이에 따라 밝기를 조절하는 기능, 하모닉스는 초음파가 몸으로부터 반사되어 나왔을때 나오는 첫번째 기본파가 아닌 이차 하모닉 음파를 사용하는 기능, 포커스는 초음파 빔(beam)의 폭을 조절하는 기능에 관련된다. 이때, 선택 가능한 설정 파라미터 값들의 조합의 개수가 지나치게 증가하는 것을 방지하기 위해, 일 실시예에 따라, 각 설정 파라미터들 각각에 대하여 10개의 값들만이 허용될 수 있다. 예를 들어, 하모닉스의 경우, 3개의 값들이 허용될 수 있다.이 경우, 전술한 5개의 파라미터들이 사용되면, 잡음 필터들에 적용될 수 있는 파라미터 값들의 조합들은 104×3 개일 수 있다. 또한, 일 실시예에 따라, 본 발명은 찌그러트림(shear), 노출제어(solarize), 밝기조절 (brightness) 등의 증강 기법을 전술한 초음파 노이즈 증강 방식에 더하여 추가적으로 적용하는 증강 정책이 수 있다. 또한, 일 실시예에 따라, 랜드어그멘테이션(randaugmentation) 등의 정책 검색(policy search) 알고리즘 이 적용될 수 있다. 다른 증강(augmentation) 정책 검색(policy search) 알고리즘이 프록시 태스크(proxy task)를 두어 최적의 증 강 정책을 찾는 것과 달리, 랜드어그멘테이션은 검색 공간을 줄임으로써 간단한 그리드 탐색(grid search)만으 로도 최적의 정책을 탐색할 수 있다. 랜드어그멘테이션의 검색 공간은 데이터 증강 방식의 강도를 정해주는 파 라미터 M, 학습 기간 동안 적용할 증강 기법의 갯수 N을 포함할 수 있다. 따라서, 증강 정책은 N 및 M에 대한 함수가 된다. 여기서, 증강 방식의 강도는 증강의 정도를 의미하며, 예를 들어, 회전의 각도, 쉬프트의 거리, 밝기의 변화량 등으로 이해될 수 있다. 랜드어그멘테이션의 정책 검색은 그리드 탐색에 기반하며, 다음 [표 1] 과 같이 수행될 수 있다. 표 1 단계 내용 A데이터 증강 방식의 강도를 정해주는 파라미터 M 설정한다. B학습 기간동안 적용할 증강 기법의 갯수 N 설정한다. 이때, 가능한 모든 증강 기법은 다 음과 같다: Brightness, Rotate, Sharpeness, Shear, Solarize, translateXabs, translateYabs, Dynamic range, Gain, Depth, TGC, Harmonics, Focus (K=13) CHarmonics를 제외한 증강 기법의 강도를 열개로 나눈다. Harmonics는 세 개로 나누어진 다. D스페클 노이즈의 패턴을 결정하는 에코 파라미터들(예: Dynamic range, Gain, Depth, TGC, Harmonics, Focus)은 기계에서 노이즈 획득 시 세팅을 열개로 나누어, 강도를 조절 한다. E학습 시에는 1/K의 균등한(uniform) 확률로 N개의 증강 기법을 선택하여 M의 강도로 데 이터 증강을 수행한다. F최적의 N과 M을 grid-search를 통해 찾게 되며, 가장 높은 검증 정확도(validation accuracy)를 가지는 N 및 M이 최적의 데이터 증강 정책이 된다. [표 1]의 단계 E에서, 검증 정확도는 훈련(train)/검증(validation)/테스트(test) 세트 중 검증 세트에 포함되 는 학습 데이터를 이용해서 지도 학습 태스크(supervised learning task)(예: 세그먼테이션, 분류)를 수행할 때 의 성능(performance)(예: 예측 정확도, 평균 다이스 계수(mean Dice coefficient) 값, 평균 정확도(mean accuracy))을 의미한다. 도 7은 본 발명의 일 실시예에 따라 증강된 데이터를 이용하여 인공지능 모델에 대한 훈련을 수행하는 절차의 예를 도시한다. 도 7은 연산 능력을 가진 장치(예: 도 1의 서비스 서버)의 동작 방법을 예시한다. 도 7을 참고하면, S701 단계에서, 장치는 잡음 필터들 및 증강 방식들을 샘플링한다. 즉, 장치는 설정된 개수 만큼의 잡음 필터들 및 증강 방식들을 샘플링할 수 있다. 여기서, 잡음 필터들의 개수 및 증강 방식들의 개수는 고정된 값이거나, 상황에 따라 적응적으로 조절될 수 있다. 일 실시예에 따라, 잡음 필터들 및 증강 방식의 개 수는 하이퍼 파라미터 M 및 N에 기반하여 결정될 수 있다. 예를 들어, 장치는 1/K 확률로 M의 강도를 가진 N개 증강 방식들을 샘플링할 수 있다. 다른 실시예에 따라, 잡음 필터들 및 증강 방식의 개수는 목표로 하는 학습 데이터의 양에 따라 결정될 수 있다. 또 다른 실시예에 따라, 잡음 필터들 및 증강 방식의 개수는 과거 증강된 학습 데이터를 이용하여 훈련된 모델의 성능에 기반하여 결정될 수 있다. S703 단계에서, 장치는 기초 영상에 선택된 필터들을 적용함으로써 학습 데이터를 생성한다. 이때, 장치는 선택 된 증강 방식들을 적용한다. 즉, 장치는 샘플링된 증강 방식들 및 필터들을 이용하여 학습 데이터를 증강한다. 기초 영상은 대상 장비와 다른 장비에 의해 촬영된 영상으로서, 잡음 필터의 적용을 받는 영상을 의미한다. 일 실시예에 따라, 필터의 적용은 원본 영상 및 잡음 필터의 행렬 곱의 형식으로 수행될 수 있다. 추가적으로, 다 른 실시예에 따라, 행렬 곱 이후에 잡음이 더 부가될 수 있다. 예를 들어, 부가되는 잡음의 크기는 요구되는 학 습 데이터의 양에 따라 다양하게 설정될 수 있다. 다른 예로, 부가되는 잡음의 크기는 사전에 설정된 하이퍼 파 라미터 M에 기반하여 결정될 수 있다.S705 단계에서, 장치는 생성된 학습 데이터 이용하여 훈련을 수행한다. 다시 말해, 장치는 증강된 학습 데이터 를 이용하여 인공지능 모델에 대한 훈련을 수행한다. 이때, 증강을 통해 생성된 영상들은 기초 영상의 레이블과 동일한 값으로 레이블링될 수 있다. 전술한 바와 같이, 증강된 학습 데이터를 이용하여 훈련이 수행될 수 있다. 이때, 학습 데이터의 증강을 위해 적어도 하나의 필터가 사용된다. 필터는 사전에 미리 생성되거나 또는 증강에 앞서 생성될 수 있다. 일 실시예 에 따라, 장치는 대상 장비에 의해 촬영된 잡음 영상들을 분류하고, 분류된 잡음 영상들을 이용하여 필터를 생 성할 수 있다. 잡음 영상들은 대상 장비를 이용하여 빈 공간을 촬영함으로써 생성된 영상들을 포함한다. 잡음 영상들은 서로 다른 조합의 설정 파라미터 값들이 적용된 상태에서 촬영된 영상들일 수 있다. 따라서, 장치는 설정 파라미터 값들의 조합에 따라 복수의 그룹들로 잡음 영상들을 분류할 수 있다. 그리고, 장치는 각 그룹에 속하는 영상들을 기반하여 해당 그룹에 대응하는 잡음 필터를 생성할 수 있다. 일 실시예에 따라, 장치는 해당 그룹에 속하는 영상들을 결합함으로써 잡음 필터를 생성할 수 있다. 다른 실시예에 따라, 장치는 해당 그룹에 속하는 영상들에 포함된 스패클(speckle)의 패턴을 분석하고, 분석된 스패클의 패턴에 기반하여 잡음 필터를 생 성할 수 있다. 여기서, 스패클의 패턴은 스패클의 모양, 크기, 배치 등을 포함할 수 있다. 도 8은 본 발명의 일 실시예에 따라 증강 정책에 기반하여 학습 데이터를 증강하는 절차의 예를 도시한다. 도 8 은 연산 능력을 가진 장치(예: 도 1의 서비스 서버)의 동작 방법을 예시한다. 도 8을 참고하면, S801 단계에서, 장치는 증강 정책을 결정한다. 장치는 잡음 필터를 이용한 증강에 부가적으로 2차 증강을 수행하기 위한 증강 정책을 결정한다. 증강 정책을 결정함은 부가적으로 수행될 증강 기법을 선택하 는 것을 의미한다. 일 실시예에 따라, 장치는 [표 1]에 설명된 과정에 따라 증강 기법을 선택할 수 있다. S803 단계에서, 장치는 결정된 증강 정책에 따라 추가 증강을 수행한다. 장치는 증강 정책에 의해 지시되는 적 어도 하나의 증강 기법을 이용하여 추가 증강을 수행한다. 예를 들어, 적어도 하나의 증강 기법은 찌그러트림 (shear), 노출제어(solarize), 반전(invert) 중 적어도 하나를 포함할 수 있다. 다양한 실시예들에 따라, 추가 증강은 기초 영상 및 잡음 필터의 결합 이후, 또는 결합 중간에 수행될 수 있다. 도 9는 본 발명의 일 실시예에 따른 원본 영상 및 증강된 영상들의 예를 도시한다. 도 9는 기초 영상에 7 가지 잡음 필터들을 적용한 결과들을 예시한다. 도 9를 참고하면, 7개의 잡음 필터들을 적용함에 의해, 7개의 증강된 영상들(920a 내지 920g)이 생성된다. 도 9와 같이, 적용되는 필터에 따라 증강된 영상이 가지는 특성도 달라짐이 확인된다. 도 10a 내지 도 10h는 본 발명의 다른 실시예에 따른 원본 영상 및 증강된 영상들의 예를 도시한다. 도 10a는 원본(original) 영상을 예시하고, 도 10b 내지 도 10h는 도 10a에 예시된 원본 영상으로부터 증강된 영상들을 예시한다. 구체적으로, 도 10b는 밝기조절, 도 10c는 회전(rotate), 도 10d는 선명도조절(sharpness), 도 10e 는 찌그러트림(shear), 도 10f는 노출제어(solarize), 도 10g는 X축 이동(translate in a X axis)(예: TranslateXabs), 도 10h는 Y축 이동(translate in a Y axis)(예: TranslateYabs)의 결과를 예시한다. 여기서, TranslateXabs는 영상을 X축 방향으로 일정 거리 쉬프트(shift)하는 연산, TranslateYabs는 영상을 Y축 방향으 로 일정 거리 쉬프트(shift)하는 연산을 의미한다. 전술한 다양한 실시예들에 따라, 잡음 필터를 이용하여 학습 데이터가 증강될 수 있다. 잡음 필터를 적용함으로 써, 촬영 장비의 특성 차이 또는 촬영 장비의 설정에 따른 특성 차이를 보상한 학습 데이터가 생성될 수 있다. 추가적으로, 촬영 앵글, 촬영 범위의 차이를 보상하기 위한 추가적인 연산이 수행될 수 있다. 예를 들어, 도 5 를 참고하면, 목표 영상은 원본 영상에 비하여 좁은 촬영 범위를 가진다. 따라서, 일 실시예에 따라, 촬영 범위의 차이를 보상하기 위해, 모델 학습시 랜덤 크롭(random crop)이 수행될 수 있다. 랜덤 크롭은 무작 위로 이미지를 크롭하는 연산을 의미한다. 다른 실시예에 따라, 장치는 목표 영상 및 원본 영상 각각 에 대한 촬영 범위를 확인한 후, 촬영 범위의 차이를 보상하는 동작을 더 수행할 수 있다. 예를 들어, 촬영 범 위의 차이에 따라 원본 영상을 확대할 수 있다.본 발명의 예시적인 방법들은 설명의 명확성을 위해서 동작의 시리즈로 표현되어 있지만, 이는 단계가 수행되는 순서를 제한하기 위한 것은 아니며, 필요한 경우에는 각각의 단계가 동시에 또는 상이한 순서로 수행될 수도 있 다. 본 발명에 따른 방법을 구현하기 위해서, 예시하는 단계에 추가적으로 다른 단계를 포함하거나, 일부의 단 계를 제외하고 나머지 단계를 포함하거나, 또는 일부의 단계를 제외하고 추가적인 다른 단계를 포함할 수도 있 다. 본 발명의 다양한 실시예는 모든 가능한 조합을 나열한 것이 아니고 본 발명의 대표적인 양상을 설명하기 위한 것이며, 다양한 실시예에서 설명하는 사항들은 독립적으로 적용되거나 또는 둘 이상의 조합으로 적용될 수도 있 다. 또한, 본 발명의 다양한 실시예는 하드웨어, 펌웨어(firmware), 소프트웨어, 또는 그들의 결합 등에 의해 구현 될 수 있다. 하드웨어에 의한 구현의 경우, 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 범용 프로세서(general processor), 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 본 발명의 범위는 다양한 실시예의 방법에 따른 동작이 장치 또는 컴퓨터 상에서 실행되도록 하는 소프트웨어 또는 머신-실행가능한 명령들(예를 들어, 운영체제, 애플리케이션, 펌웨어(firmware), 프로그램 등), 및 이러한 소프트웨어 또는 명령 등이 저장되어 장치 또는 컴퓨터 상에서 실행 가능한 비-일시적 컴퓨터-판독가능 매체 (non-transitory computer-readable medium)를 포함한다.\n【요약】본 발명은 인공지능(artificial intelligence, AI) 모델을 위한 학습 데이터를 증강(augmentation)하기 위한 것으로, 학습 데이터를 증강(augmentation)하기 위한 방법은, 적어도 하나의 잡음 필터 및 적어도 하나의 증강 방 식을 선택하는 단계, 적어도 하나의 기초 영상에 선택된 적어도 하나의 잡음 필터 및 적어도 하나의 증강 방식을 적용함으로써 학습 데이터를 생성하는 단계, 및 상기 생성된 학습 데이터 이용하여 상기 인공지능 모델에 대한 훈련을 수행하는 단계를 포함할 수 있다.\n\n【청구항 1】\n에 있어서,상기 적어도 하나의 잡음 필터는, 복수의 잡음 영상들에 포함되는 스패클(speckle)의 패턴에 기반하여 생성되는방법.\n【청구항 2】\n청구항 1에 있어서,상기 적어도 하나의 잡음 필터의 개수 및 상기 적어도 하나의 증강 방식의 개수는, 증강 정책에 기반하여 결정되며,상기 증강 정책은, 증강 방식의 강도(strength)를 지시하는 제1 파라미터 및 적용할 증강 기법의 개수를 지시하는 제2 파라미터에 의해 정의되는 방법.\n【청구항 3】\n청구항 1에 있어서,대상 장비에 의해 촬영된 잡음 영상들을 분류하는 단계;상기 분류된 잡음 영상들을 이용하여 적어도 하나의 잡음 필터를 생성하는 단계를 더 포함하는 방법.\n【청구항 4】\n청구항 1에 있어서,상기 잡음 영상들은, 상기 대상 장비를 이용하여 빈 공간을 촬영함으로써 생성된 영상들을 포함하는 방법.\n【청구항 5】\n청구항 1에 있어서,상기 잡음 영상들은, 서로 다른 조합의 설정 파라미터 값들이 적용된 상태에서 촬영된 영상들을 포함하는 방법.\n【청구항 6】\n청구항 1에 있어서,상기 적어도 하나의 잡음 필터는, 복수의 잡음 영상들을 결합함으로써 생성되는 방법.공개특허 10-2024-0059187-3-청구항 7\n【청구항 8】\n청구항 1에 있어서,상기 학습 데이터는, 상기 적어도 하나의 기초 영상 및 상기 적어도 하나의 잡음 필터의 곱에 기반하여 생성되는 방법.\n【청구항 9】\n청구항 1에 있어서,상기 학습 데이터에 적용되는 증강 정책을 결정하는 단계; 및상기 증강 정책에 따라 추가적인 증강을 수행하는 단계를 더 포함하는 방법.\n【청구항 10】\n청구항 9에 있어서,상기 증강 정책은, 적어도 하나의 증강 기법을 지정하며,상기 적어도 하나의 증강 기법은, 밝기 조절(brightness), 회전(rotate), 선명도조절(sharpness), 찌그러트림(shear), 노출제어(solarize), X축 이동(translate in a X axis), Y축 이동(translate in a Y axis) 중 적어도하나를 포함하는 방법.\n【청구항 11】\n의료 영상에서 정보를 획득하기 위한 장치에 있어서,상기 장치의 동작을 위한 명령어 집합을 저장하는 저장부; 및상기 저장부와 연결된 적어도 하나의 프로세서를 포함하며,상기 적어도 하나의 프로세서는, 적어도 하나의 잡음 필터 및 적어도 하나의 증강 방식을 선택하고,적어도 하나의 기초 영상에 선택된 적어도 하나의 잡음 필터 및 적어도 하나의 증강 방식을 적용함으로써 학습데이터를 생성하고,상기 생성된 학습 데이터 이용하여 상기 인공지능 모델에 대한 훈련을 수행하도록 제어하는 장치.\n【청구항 12】\n프로세서에 의해 동작되면 제1항 내지 제10항 중의 어느 한 항에 따른 방법을 실행하기 위해 매체에 저장된 프로그램."}
{"context": "", "input": "【기술명】\n인공지능 캐릭터의 구독 방법 및 그 시스템\n\n【기술 설명】\n**항목 1:**  \n본 발명은 인공지능 캐릭터의 구독 방법 및 시스템을 제안하는 것으로, 사용자가 일정 금액의 구독 수수료를 지불하여 원하는 인공지능 캐릭터를 구독하고, 해당 캐릭터의 기능을 제어할 수 있는 기술이다. 이 시스템은 사용자가 직접 입력한 정보를 기반으로 캐릭터를 생성하며, 구독자는 다른 사용자가 소유한 인공지능 캐릭터의 서비스를 활용할 수 있다. 또한, 구독한 캐릭터의 기능 서비스는 사용자가 제어할 수 있는 점에서, 개인화된 사용자 경험을 제공하는 혁신적인 접근 방식이다.\n\n【해결 문제】\n**항목 2:**  \n현재 시장에서는 다양한 유형의 인공지능 캐릭터와 그 기능이 존재하지만, 사용자들이 원하는 캐릭터를 선택하고, 그 기능을 원활하게 제어하는 데에 어려움을 겪고 있다. 본 발명은 이러한 문제를 해결하기 위해, 사용자가 직접 생성한 캐릭터와 다른 사용자가 소유한 캐릭터를 구독하고, 그 기능을 제어하는 시스템을 제공함으로써 개인의 취향과 필요에 맞는 맞춤형 서비스를 가능하게 한다. 이로 인해 사용자는 보다 풍부하고 개인화된 경험을 누릴 수 있으며, 인공지능 캐릭터의 활용도를 높일 수 있다.\n\n【기술 차별성】\n**항목 3:**  \n본 발명은 기존의 인공지능 캐릭터 서비스와의 차별점으로, 사용자가 직접 캐릭터를 생성하고, 타 사용자와의 상호작용을 통해 구독 서비스를 제공받을 수 있는 점을 강조한다. 기존 기술들은 일반적으로 제공되는 캐릭터의 기능을 수동적으로 사용하는 방식이었으나, 본 발명은 사용자가 직접 참여하여 캐릭터의 기능을 제어 및 커스터마이즈할 수 있도록 함으로써 혁신적인 사용자 경험을 창출한다. 또한, 구독 서비스 내에서 대화 파티 및 특별한 기능을 제공함으로써, 인공지능 캐릭터 간의 상호작용을 증대시키고, 사용자 간의 커뮤니티를 강화하는 데 기여한다.\n\n【활용 분야】\n본 발명인 인공지능 캐릭터의 구독 방법 및 시스템은 게임, 교육, 엔터테인먼트, 소셜 미디어와 같은 다양한 분야에서 활용될 수 있습니다. 특히, 사용자 맞춤형 인공지능 캐릭터가 필요한 산업에서 큰 잠재력을 지니고 있습니다. 예를 들어, 교육 분야에서는 학습자의 스타일에 맞춘 인공지능 튜터가 개발될 수 있으며, 게임 산업에서는 플레이어가 구독한 캐릭터를 통해 더욱 몰입감 있는 경험을 제공받을 수 있습니다. 또한, 소셜 미디어 플랫폼에서 사용자 간의 상호작용을 증진시키기 위해 인공지능 캐릭터를 활용한 새로운 형태의 콘텐츠 생성 및 소비 모델이 가능해집니다.\n\n【구성 요소 및 기능】\n본 발명의 주요 구성 요소는 다음과 같습니다. 첫 번째는 '캐릭터 생성부'로, 이는 제1 크리에이터의 입력을 기반으로 제1 인공지능 캐릭터를 생성하는 기능을 수행합니다. 두 번째는 '구독부'로, 제1 크리에이터가 제2 크리에이터에게 구독 수수료를 지불하여 제2 인공지능 캐릭터를 구독하게 하며, 이를 통해 수익 모델을 형성합니다. 세 번째는 '제어부'로, 이는 제1 크리에이터가 구독한 제2 인공지능 캐릭터의 기능 서비스를 제어하는 기능을 제공하여 개인화된 사용자 경험을 증진시킵니다.\n\n【구현 방식 예】\n본 발명의 구현 방식은 다음 단계로 구성됩니다. 첫째, 제1 크리에이터가 자신의 요구사항을 입력하여 제1 인공지능 캐릭터를 생성하는 단계가 있습니다. 둘째, 제1 크리에이터는 제2 크리에이터가 보유한 제2 인공지능 캐릭터에 대한 구독 수수료를 지불하여 해당 캐릭터를 구독합니다. 셋째, 제1 크리에이터는 제2 인공지능 캐릭터의 기능을 제어하며, 추가적으로 해당 캐릭터와 관련된 대화 서비스 및 대화 파티 서비스에 접근하는 방식으로 구현됩니다. 이러한 단계는 사용자 경험을 극대화하고, 캐릭터 간의 상호작용을 통해 새로운 가치 창출을 가능하게 합니다.", "output": "【발명의 명칭】\n인공지능 캐릭터의 구독 방법 및 그 시스템\n【기술분야】\n본 발명은 인공지능 캐릭터의 구독 방법 및 시스템에 관한 것으로서, 보다 상세하게는 구독한 인공지능 캐릭터 의 기능 서비스의 제어 가능한 기술에 관한 것이다.\n【배경기술】\n발명의 내용\n【해결하려는 과제】\n본 발명의 목적은 일정 금액의 구독 수수료를 지불하여 인공지능 캐릭터를 구독하고, 구독한 인공지능 캐릭터의 기능 서비스를 제어하고자 한다. 다만, 본 발명이 해결하고자 하는 기술적 과제들은 상기 과제로 한정되는 것은 아니며, 본 발명의 기술적 사상 및 영역으로부터 벗어나지 않은 범위에서 다양하게 확장될 수 있다.\n【과제의 해결 수단】\n본 발명의 실시예에 따른 인공지능 캐릭터의 구독 방법은 제1 크리에이터의 입력에 기초하여 제1 인공지능 캐릭 터를 생성하는 단계, 상기 제1 크리에이터가 제2 인공지능 캐릭터를 소유한 제2 크리에이터에게 구독 수수료를 지불하여 상기 제2 인공지능 캐릭터를 구독하는 단계 및 상기 제1 크리에이터에 의해 상기 제2 인공지능 캐릭터 의 기능 서비스를 제어하는 단계를 포함한다. 또한, 본 발명의 실시예에 따른 인공지능 캐릭터의 구독 방법은 상기 제2 인공지능 캐릭터와 상기 제2 인공지능 캐릭터를 팔로잉하는 팔로워 간의 대화 서비스 시, 상기 제2 인공지능 캐릭터를 구독한 구독자들의 인공지능 캐 릭터를 상단에 노출하는 단계를 더 포함할 수 있다. 또한, 본 발명의 실시예에 따른 인공지능 캐릭터의 구독 방법은 상기 제2 인공지능 캐릭터와, 상기 제2 인공지 능 캐릭터를 구독한 인공지능 캐릭터들만 입장이 가능한 대화 파티 서비스를 제공하는 단계를 더 포함할 수 있 다. 본 발명의 실시예에 따른 인공지능 캐릭터의 구독 시스템은 제1 크리에이터의 입력에 기초하여 제1 인공지능 캐 릭터를 생성하는 캐릭터 생성부, 상기 제1 크리에이터가 제2 인공지능 캐릭터를 소유한 제2 크리에이터에게 구 독 수수료를 지불하여 상기 제2 인공지능 캐릭터를 구독하는 구독부 및 상기 제1 크리에이터에 의해 상기 제2 인공지능 캐릭터의 기능 서비스를 제어하는 제어부를 포함한다.\n【발명의 효과】\n다만, 본 발명의 효과는 상기 효과들로 한정되는 것은 아니며, 본 발명의 기술적 사상 및 영역으로부터 벗어나 지 않는 범위에서 다양하게 확장될 수 있다.\n【발명을실시하기위한구체적인내용】\n본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서 로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하 는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명 은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며, 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소, 단계, 동작 및/또는 소자는 하나 이상의 다 른 구성요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적 으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하 게 해석되지 않는다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예들을 보다 상세하게 설명하고자 한다. 도면 상의 동일한 구성요소에 대해서는 동일한 참조 부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 본 발명의 실시예에 따른 인공지능 캐릭터의 구독 방법, 및 그 시스템은, 구독한 인공지능 캐릭터의 기능 서비 스의 제어가 가능한 것을 그 요지로 한다. 본 발명의 온라인 채팅 서버는 모바일 애플리케이션(Application)의 형태로 인공지능 캐릭터의 생성, 생성된 인 공지능 캐릭터와 인공지능 캐릭터를 팔로잉하는 팔로워 간의 대화 서비스를 제공하며, 자유로운 대화 중에서 기 설정된 학습 정도의 충족 여부에 따른 학습량에 기초하여 인공지능 캐릭터의 레벨을 평가할 수 있다. 이에, 크 리에이터(또는 사용자)는 소지하는 단말기에 설치된 애플리케이션을 통해 나만의 인공지능 캐릭터를 생성하고, 생성한 인공지능 캐릭터를 이용하여 팔로워들과 자유로운 소통을 하거나, 자동응답 기능을 통해 기 학습된 대화 엔진을 기반으로 하는 인공지능 캐릭터로 팔로워들과 자동 대화를 할 수 있다. 여기서, 상기 팔로워는 인공지 능 캐릭터를 팔로잉하는 인공지능 캐릭터 또는 크리에이터일 수 있다. 크리에이터(또는 사용자)는 소지하는 스마트폰, 데스크탑 PC, 모바일 단말, PDA, 노트북 및 태블릿 PC 중 적어 도 어느 하나의 단말기(또는 전자 기기)를 통해 대화 서비스를 수행할 수 있다. 이때, 본 발명은 사용자가 소 지하는 단말기 내 애플리케이션(Application)을 통해 사용자의 선택 입력에 따른 정보를 수신할 수 있으며, 상 기 단말기는 터치-감지 영역을 포함하는 스크린을 통해 소정의 기능 집합의 동작을 수행할 수 있는 터치 스크린 형태의 디스플레이를 포함하는 것일 수 있고, 하나 이상의 물리적 버튼 또는 가상의 버튼을 포함하는 기기일 수 있으므로 종류 및 형태는 이에 한정되지 않는다. 이하에서는 도 1 내지 도 6을 참조하여 본 발명에 대해 상세히 설명한다. 도 1은 본 발명의 일 실시예에 따른 네트워크 환경을 설명하기 위한 일 예시도를 도시한 것으로, 도 1의 네트워 크 환경은 복수의 전자 기기들(110, 120, 130, 140), 복수의 서버들(150, 160) 및 네트워크를 포함하는 예를 나타내고 있다. 이러한 도 1은 발명의 설명을 위한 일례로 전자 기기의 수나 서버의 수가 도 1과 같이 한 정되는 것은 아니다. 복수의 전자 기기들(110, 120, 130, 140)은 컴퓨터 장치로 구현되는 이동형 단말일 수 있다. 복수의 전자 기기 들(110, 120, 130, 140)의 예를 들면, 스마트폰(smart phone), 휴대폰, 태블릿 PC, 내비게이션, 컴퓨터, 노트 북, 디지털방송용 단말, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 사용자 착용 장치(웨어러블 디바이스) 등이 있다. 일례로 제1 전자 기기는 무선 또는 유선 통신 방식을 이용하여 네트 워크를 통해 다른 전자 기기들(120, 130, 140) 및/또는 서버(150, 160)와 통신할 수 있다. 통신 방식은 제한되지 않으며, 네트워크가 포함할 수 있는 통신망(일례로, 이동통신망, 유선 인터넷, 무선 인터넷, 방송망)을 활용하는 통신 방식뿐만 아니라 기기들간의 근거리 무선 통신 역시 포함될 수 있다. 예를 들어, 네트워크는, PAN(personal area network), LAN(local area network), CAN(campus area network), MAN(metropolitan area network), WAN(wide area network), BBN(broadband network), 인터넷 등의 네트워크 중 하나 이상의 임의의 네트워크를 포함할 수 있다. 또한, 네트워크는 버스 네트워크, 스타 네트워크, 링 네트워크, 메쉬 네트워크, 스타-버스 네트워크, 트리 또는 계층적(hierarchical) 네트워크 등을 포함하는 네트 워크 토폴로지 중 임의의 하나 이상을 포함할 수 있으나, 이에 제한되지 않는다. 서버(150, 160) 각각은 복수의 전자 기기들(110, 120, 130, 140)과 네트워크를 통해 통신하여 명령, 코드, 파일, 콘텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구현될 수 있다.일례로, 서버는 네트워크를 통해 접속한 제1 전자 기기로 애플리케이션의 설치를 위한 파일을 제공할 수 있다. 이 경우 제1 전자 기기는 서버로부터 제공된 파일을 이용하여 애플리케이션을 설치 할 수 있다. 또한, 제1 전자 기기가 포함하는 운영체제(Operating System, OS)나 적어도 하나의 프로그램 (일례로 브라우저나 상기 설치된 애플리케이션)의 제어에 따라 서버에 접속하여 서버가 제공하는 서 비스나 콘텐츠를 제공받을 수 있다. 예를 들어, 제1 전자 기기가 애플리케이션의 제어에 따라 네트워크 를 통해 서비스 요청 메시지를 서버로 전송하면, 서버는 서비스 요청 메시지에 대응하는 코드를 제1 전자 기기로 전송할 수 있고, 제1 전자 기기는 애플리케이션의 제어에 따라 코드에 따른 화면을 구성하여 표시함으로써 사용자에게 콘텐츠를 제공할 수 있다. 도 2는 도 1에 도시된 전자 기기 및 서버의 내부 구성을 설명하기 위한 일 예시도를 도시한 것으로, 도 2에서는 사용자가 소지한 단말인 하나의 전자 기기에 대한 예로서 제1 전자 기기, 그리고 사용자의 단말과 통신하 는 하나의 서버에 대한 예로서 서버의 내부 구성을 설명한다. 이에, 이하 제1 전자 기기는 사용자의 단말을 의미하며, 서버는 사용자의 단말과 통신하는 서버를 의미한다. 다른 전자 기기들(120, 130, 140) 이나 서버 역시 동일한 또는 유사한 내부 구성을 가질 수 있다. 제1 전자 기기와 서버는 메모리(211, 221), 프로세서(212, 222), 통신 모듈(213, 223) 그리고 입출 력 인터페이스(214, 224)를 포함할 수 있다. 메모리(211, 221)는 컴퓨터에서 판독 가능한 기록 매체로서, RAM(random access memory), ROM(read only memory) 및 디스크 드라이브와 같은 비소멸성 대용량 기록장치 (permanent mass storage device)를 포함할 수 있다. 또한, 메모리(211, 221)에는 운영체제나 적어도 하나의 프로그램 코드(일례로 제1 전자 기기에 설치되어 구동되는 애플리케이션 등을 위한 코드)가 저장될 수 있 다. 이러한 소프트웨어 구성요소들은 메모리(211, 221)와는 별도의 컴퓨터에서 판독 가능한 기록 매체로부터 로딩될 수 있다. 이러한 별도의 컴퓨터에서 판독 가능한 기록 매체는 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨터에서 판독 가능한 기록 매체를 포함할 수 있다. 다른 실시예에 서 소프트웨어 구성요소들은 컴퓨터에서 판독 가능한 기록 매체가 아닌 통신 모듈(213, 223)을 통해 메모리 (211, 221)에 로딩될 수도 있다. 예를 들어, 적어도 하나의 프로그램은 개발자들 또는 애플리케이션의 설치 파 일을 배포하는 파일 배포 시스템(일례로 상술한 서버)이 네트워크를 통해 제공하는 파일들에 의해 설 치되는 프로그램(일례로 상술한 애플리케이션)에 기반하여 메모리(211, 221)에 로딩될 수 있다. 프로세서(212, 222)는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하 도록 구성될 수 있다. 명령은 메모리(211, 221) 또는 통신 모듈(213, 223)에 의해 프로세서(212, 222)로 제공 될 수 있다. 예를 들어 프로세서(212, 222)는 메모리(211, 221)와 같은 기록 장치에 저장된 프로그램 코드에 따라 수신되는 명령을 실행하도록 구성될 수 있다. 통신 모듈(213, 223)은 네트워크를 통해 제1 전자 기기와 서버가 서로 통신하기 위한 기능을 제 공할 수 있으며, 다른 전자 기기(일례로 제2 전자 기기) 또는 다른 서버(일례로 서버)와 통신하기 위 한 기능을 제공할 수 있다. 일례로, 제1 전자 기기의 프로세서가 메모리와 같은 기록 장치에 저 장된 프로그램 코드에 따라 생성한 요청(일례로 검색 요청)이 통신 모듈의 제어에 따라 네트워크를 통해 서버로 전달될 수 있다. 역으로, 서버의 프로세서의 제어에 따라 제공되는 제어 신호나 명령, 콘텐츠, 파일 등이 통신 모듈과 네트워크를 거쳐 제1 전자 기기의 통신 모듈을 통해 제1 전자 기기로 수신될 수 있다. 예를 들어 통신 모듈을 통해 수신된 서버의 제어 신호나 명 령 등은 프로세서나 메모리로 전달될 수 있고, 콘텐츠나 파일 등은 제1 전자 기기가 더 포함할 수 있는 저장 매체로 저장될 수 있다. 입출력 인터페이스는 입출력 장치와의 인터페이스를 위한 수단일 수 있다. 예를 들어, 입력 장치는 키보드 또는 마우스 등의 장치를, 그리고 출력 장치는 애플리케이션의 통신 세션을 표시하기 위한 디스플레이와 같은 장치를 포함할 수 있다. 다른 예로 입출력 인터페이스는 터치스크린과 같이 입력과 출력을 위한 기 능이 하나로 통합된 장치와의 인터페이스를 위한 수단일 수도 있다. 보다 구체적인 예로, 제1 전자 기기 의 프로세서는 메모리에 로딩된 컴퓨터 프로그램의 명령을 처리함에 있어서 서버나 제2 전자 기 기가 제공하는 데이터를 이용하여 구성되는 서비스 화면이나 콘텐츠가 입출력 인터페이스를 통해 디 스플레이에 표시될 수 있다. 입출력 인터페이스 또한 마찬가지로 서버의 프로세서가 메모리 에 로딩된 컴퓨터 프로그램의 명령을 처리함에 있어 서버가 제공하는 데이터를 이용하여 구성되는 정 보를 출력할 수 있다.또한, 다른 실시예들에서 제1 전자 기기 및 서버는 도 2의 구성요소들보다 더 많은 구성요소들을 포 함할 수도 있다. 그러나, 대부분의 종래기술적 구성요소들을 명확하게 도시할 필요성은 없다. 예를 들어, 제1 전자 기기는 상술한 입출력 장치 중 적어도 일부를 포함하도록 구현되거나 또는 트랜시버 (transceiver), GPS(Global Positioning System) 모듈, 카메라, 각종 센서, 데이터베이스 등과 같은 다른 구성 요소들을 더 포함할 수도 있다. 보다 구체적인 예로, 제1 전자 기기가 스마트폰인 경우, 일반적으로 스마 트폰이 포함하고 있는 방위 센서, 가속도 센서나 자이로 센서, 카메라, 각종 물리적인 버튼, 터치패널을 이용한 버튼, 입출력 포트, 진동을 위한 진동기 등의 다양한 구성요소들이 제1 전자 기기에 더 포함되도록 구현될 수 있음을 알 수 있다. 이하에서는 본 발명의 실시예에 따른 인공지능 캐릭터의 구독 방법, 그 시스템의 구체적인 실시예를 설명하기로 한다. 도 3은 본 발명의 실시예에 따른 인공지능 캐릭터의 구독 방법의 동작 흐름도를 도시한 것으로, 도 3의 방법은 도 4에 도시된 본 발명의 실시예에 따른 인공지능 캐릭터의 구독 시스템 또는 서버에서의 동작 흐름도를 나타낸 것이다. 또한, 도 4는 본 발명의 실시예에 따른 구독 여부를 제공하는 단계의 동작 흐름도를 도시한 것이고, 도 5는 본 발명의 실시예에 따른 대화 파티 서비스를 제공하는 단계의 동작 흐름도를 도시한 것이다. 도 3을 참조하면, 단계 S310에서, 제1 크리에이터의 입력에 기초하여 제1 인공지능 캐릭터를 생성한다. 단계 S310은 크리에이터가 본 발명의 시스템에서 제공하는 인공지능 캐릭터를 생성하는 기능을 통해 생성할 수 있다. 예를 들어, 단계 S310은 크리에이터인 사용자에 의해 얼굴 이미지, 말투, 성격, 관심 대화 분야(또는 관 심 대화 내용), 이름, 성별, 캐릭터 소개 내용 등이 설정됨으로써, 미리 설정된 기본 대화 엔진이 학습되어 인 공지능 캐릭터를 생성할 수 있다. 이때, 단계 S310에서 생성되는 인공지능 캐릭터는 크리에이터인 사용자에 의 해 설정된 말투와 관심 대화 내용으로 해당 인공지능 캐릭터를 팔로잉하는 사람들인 팔로워(인공지능 캐릭터 또 는 크리에이터)와 대화를 주고 받을 수 있다. 본 발명의 실시예에 따른 인공지능 캐릭터의 구독 방법은 생성된 인공지능 캐릭터가 대화 엔진을 이용하여 팔로 워들과 대화하는데 있어서, 팔로워들에게 대화하는 답변 방식 또는 답변 내용 등을 크리에이터가 원하는 답변 방식 또는 답변 내용으로 대화할 수 있도록 인공지능 캐릭터의 대화 엔진을 학습시킬 수 있다. 즉, 본 발명은 크리에이터의 요청에 따라 대화를 통해 이미 생성된 인공지능 캐릭터의 대화 엔진을 조금씩 발전시켜 나가는 것으로, 인공지능 캐릭터의 대화 엔진을 완성시킬 때까지 반복적으로 수행될 수 있다. 또한, 단계 S310에서 생성된 인공지능 캐릭터에는 크리에이터에 의해 생성된 인공지능 캐릭터를 다른 사용자들 이 대화 관심 분야 등의 키워드를 통해 검색할 수 있도록, 크리에이터에 의해 설정된 적어도 하나 이상의 해시 태그가 부여될 수 있다. 예를 들어, 크리에이터에 의해 인공지능 캐릭터의 해시태그가 ‘#골프’, ‘#스포츠’ 로 설정되어 있다면, 해당 인공지능 캐릭터는 골프와 스포츠로 검색 가능하고, 골프와 스포츠에 대한 대화를 할 수 있는 인공지능 캐릭터로 분류될 수 있다. 전술한 바와 같이 인공지능 캐릭터가 생성되면, 단계 S310에서 인공지능 캐릭터와 인공지능 캐릭터를 팔로잉하 는 팔로워 간의 대화 서비스를 제공할 수 있다. 크리에이터에 의해 인공지능 캐릭터가 생성된 후, 해당 인공지능 캐릭터를 팔로잉하는 팔로워들이 생기면, 단계 S310에 의해 인공지능 캐릭터와 팔로워 간의 대화방에서 대화 서비스를 제공할 수 있다. 이때, 팔로워는 인공 지능 캐릭터일 수 있으며, 인공지능 캐릭터를 생성한 크리에이터일 수 있다. 일 예로, 인공지능 캐릭터와 인공 지능 캐릭터의 팔로워가 대화하는 경우, 자동응답 기능이 온(ON)되어 크리에이터의 개입 없이 기 학습된 대화 엔진을 기반으로 대화를 주고받을 수 있다. 다른 예로, 크리에이터와 인공지능 캐릭터, 인공지능 캐릭터와 크 리에이터, 또는 크리에이터와 크리에이터 즉, 적어도 한 명의 사람이 포함되어 대화하는 경우, 자동응답 기능이 오프(OFF)되어 크리에이터가 참여하여 자유롭게 대화를 주고받을 수 있다. 전술한 바에 따라, 단계 S310은 채팅방에 크리에이터의 참여 여부에 따라 자동응답 기능을 온(ON)/오프(OFF) 상 태의 대화 서비스를 제공할 수 있으나, 크리에이터가 채팅방에 참여하지 않더라도 특정 채팅방의 자동응답 기능 을 온(ON) 또는 오프(OFF) 상태로 유지시킬 수도 있다. 단계 S320에서, 제1 크리에이터가 제2 인공지능 캐릭터를 소유한 제2 크리에이터에게 구독 수수료를 지불하여 제2 인공지능 캐릭터를 구독한다.단계 S320은 제2 인공지능 캐릭터를 소유한 제2 크리에이터에게 기 설정된 기간 동안의 구독을 위한 구독 수수 료를 지불하고, 지불된 구독 수수료에 따라 기 설정된 기간 동안의 제2 인공지능 캐릭터에 대한 구독을 승인할 수 있다. 예를 들면, 제1 크리에이터는 한달에 5만원의 구독 수수료를 지불하여 제2 인공지능 캐릭터에 대한 구독을 요청할 수 있다. 이에, 단계 S320은 제1 크리에이터로부터 지급된 구독 수수료를 제2 크리에이터에게 제공하며, 제2 크리에이터의 동의에 따라 제1 크리에이터에 의한 제2 인공지능 캐릭터에 대한 구독을 승인할 수 있다. 이때, 구독 기간은 주별, 월별, 분기별 또는 연별로 지정될 수 있으며, 구독 수수료는 전술한 바에 한정 하지 않는다. 이후에, 단계 S320은 제1 크리에이터가 구독한 적어도 하나 이상의 인공지능 캐릭터의 실시간 활동 이력을 제1 인공지능 캐릭터에게 제공할 수 있다. 예를 들면, 제1 크리에이터가 구독한 제2 인공지능 캐릭터의 접속 여부, 실시간 채팅 여부, 라이브 방송 여부, 제2 크리에이터의 접속 시간 및 대화 파티 서비스 관련 정보 중 적어도 어느 하나 이상의 실시간 활동 이력을 제1 인공지능 캐릭터에게 제공함으로써, 제1 크리에이터는 실시간으로 구 독한 제2 인공지능 캐릭터에 대한 활동을 확인할 수 있다. 이때, 단계 S320은 제2 인공지능 캐릭터에 관한 활 동 이력을 알림 팝업창을 통해 제1 크리에이터에게 제공할 수 있다. 또한, 단계 S320은 구독 수수료, 구독 기간 또는 구독 횟수에 따라 제2 인공지능 캐릭터를 구독하는 제1 크리에 이터의 구독 등급을 설정할 수 있다. 예를 들면, 구독 기간이 일주일이고, 구독 수수료는 지정된 금액을 지불 하며, 특정 크리에이터에 대해 1회 내지 3회 정도 구독한 경우에, 단계 S320은 제1 구독 등급을 설정할 수 있다. 또한, 구독 기간이 3개월이고, 구독 수수료는 지정된 금액을 지불하며, 특정 크리에이터에 대해 3회 내 지 10회 정도 구독한 경우에, 단계 S320은 제2 구독 등급을 설정할 수 있다. 또한, 구독 기간이 6개월 또는 1 년이고, 구독 수수료는 프리미엄을 추가하여 지불하며, 특정 크리에이터에 대해 최소 10회 이상 구독한 경우에, 단계 S320은 제3 구독 등급을 설정할 수 있다. 즉, 단계 S320은 구독 수수료, 구독 기간 및 구독 횟수에 따라 구독 등급을 단계별로 설정할 수 있다. 다만, 구독 등급을 분류하는 기준은 전술한 바에 한정하지 않음은 당연 하다. 단계 S330에서, 제1 크리에이터에 의해 제2 인공지능 캐릭터의 기능 서비스를 제어한다. 단계 S330은 제1 크리에이터의 선택에 따라 제2 인공지능 캐릭터를 뮤트(MUTE)할 수 있다. 이에, 단계 S330은 제2 인공지능 캐릭터를 구독한 제1 크리에이터의 선택에 따라 제2 인공지능 캐릭터가 아닌 제2 인공지능 캐릭터 를 소유한 제2 크리에이터와의 대화 서비스를 제공할 수 있다. 예를 들면, 제1 크리에이터가 A 가수(크리에이 터)의 인공지능 캐릭터를 구독하는 경우, A 가수의 인공지능 캐릭터를 뮤트함으로써, 기 학습된 대화 엔진으로 대화하는 A 가수의 인공지능 캐릭터와 대화를 주고받는 것이 아닌, A 가수와 직접 대화를 주고받을 수 있게 된 다. 또한, 단계 S330은 구독 등급에 따라서 제1 크리에이터에게 부가 서비스를 제공할 수도 있다. 예를 들면, 제1 구독 등급인 크리에이터는 구독한 인공지능 캐릭터를 최대 2회만 뮤트할 수 있는 반면에, 제3 구독 등급인 크리 에이터는 구독한 인공지능 캐릭터를 최대 5회까지 뮤트할 수 있으며, 구독한 크리에이터와의 대화 서비스 횟수 또한 제1 구독 등급인 크리에이터에 비해 많이 지급될 수 있다. 도 4를 참조하면, 본 발명의 실시예에 따른 인공지능 캐릭터의 구독 방법은 제2 인공지능 캐릭터와 제2 인공지 능 캐릭터를 팔로잉하는 팔로워 간의 대화 시, 제2 인공지능 캐릭터를 구독한 구독자들의 인공지능 캐릭터를 상 단에 노출하는 단계 S410을 더 포함할 수 있다. 보다 상세하게, 제1 크리에이터가 일정 금액의 수수료를 지불하고, 제2 인공지능 캐릭터를 구독한다고 가정한 경우에, 단계 S410은 제2 인공지능 캐릭터가 제1 인공지능 캐릭터가 아니더라도 적어도 하나 이상의 팔로워와 대화를 주고받는 대화방 상단에 제2 인공지능 캐릭터를 구독한 적어도 하나 이상의 구독자들의 인공지능 캐릭터 를 노출할 수 있다. 이에, 제2 인공지능 캐릭터는 팔로워와 대화하는 대화방의 상단에 노출되는 구독자들을 확 인할 수 있다. 예를 들면, A 가수의 인공지능 캐릭터(제2 인공지능 캐릭터)는 적어도 하나 이상의 팔로워 즉, 구독에 상관없이 본인을 팔로워한 팔로워들과 대화 엔진을 기반으로 대화를 주고받을 수 있다. 이때, A 가수의 인공지능 캐릭터가 팔로워들과 대화를 주고받는 대화방의 상단에 A 가수를 구독하는 팬 각각의 인공지능 캐릭터 가 제공될 수 있다. 여기서, 제1 팬(제1 크리에이터)이 A 가수(크리에이터)의 인공지능 캐릭터를 구독한다고 가정하며, A 가수를 구독하는 팬이 제1 팬뿐 아니라, 제2 팬, 제3 팬, …, 제N 팬 등을 포함할 수 있다. 본 발 명에서 A 가수를 구독한 팬들 각각의 인공지능 캐릭터는 A 가수(크리에이터 또는 인공지능 캐릭터)가 활동하는 페이지 상단에 제공되는 것을 특징으로 한다. 다만, 실시예에 따라서, 제2 인공지능 캐릭터를 구독한 구독자들의 인공지능 캐릭터들은 제2 크리에이터가 본 발명의 시스템에서 제공되는 애플리케이션(Application)에 접속하는 동시에, 모든 페이지 상단에 위치할 수도 있으며, 메인 페이지, 개인 페이지, 대화방 및 팔로워 리스트 중 적어도 어느 하나 이상의 공간에 노출될 수도 있다. 도 5를 참조하면, 본 발명의 실시예에 따른 인공지능 캐릭터의 구독 방법은 제2 인공지능 캐릭터와 제2 인공지 능 캐릭터를 구독한 인공지능 캐릭터들만 입장이 가능한 대화 파티 서비스를 제공하는 단계 S510을 더 포함할 수 있다. 보다 상세하게, 단계 S510은 적어도 하나 이상의 구독자를 갖는 제2 인공지능 캐릭터 또는 제2 크리에이터와 구 독자들만이 입장 가능하여 자유롭게 대화를 주고받을 수 있는 대화 파티 서비스를 제공할 수 있다. 이때, 단계 S510은 구독자들만을 위한 제2 크리에이터의 라이브 방송, 제2 크리에이터와의 실제 대화 서비스, 사진 또는 동 영상 제공과 같은 다양한 파티 서비스를 제공할 수도 있다. 이에, 적어도 하나 이상의 구독자를 갖는 제2 인공 지능 캐릭터는 본인인 제2 인공지능 캐릭터 또는 제2 크리에이터와 적어도 하나 이상의 구독자들만이 입장 가능 한 대화 파티 서비스에 참여할 수 있다. 예를 들면, A 가수는 A 가수를 구독하는 제1 팬뿐 아니라, 제2 팬, 제 3 팬, …, 제N 팬들만 입장이 가능한 대화 파티 서비스를 오픈(open)할 수 있으며, 대화 파티 서비스에서는 A 가수의 인공지능 캐릭터가 아닌 A 가수가 직접 참여하여 라이브 방송, 실제 대화 시간, 사진 또는 동영상 제공 과 같은 사적인 대화를 주고받을 수 있다. 이에, 본 발명에서는 A 가수가 A 가수를 구독한 팬들과 보다 친밀하 고 사적인 대화를 나눌 수 있도록 대화 파티 서비스를 제공하는 것을 특징으로 한다. 도 6은 본 발명의 실시예에 따른 인공지능 캐릭터의 구독 시스템에 대한 구성을 도시한 것으로, 인공지능 캐릭 터의 구독 방법을 수행하는 서버 또는 시스템에 대한 개념적인 구성을 나타낸 것이다. 도 6을 참조하면, 본 발명의 실시예에 따른 인공지능 캐릭터의 구독 시스템은 캐릭터 제공부, 구독부 , 제어부 및 DB를 포함한다. DB(DataBase; 데이터베이스, 640)는 본 발명과 관련된 정보를 저장하는 수단으로, 인공지능 캐릭터에 관한 정보, 학습 정도에 따른 학습량과 구독 여부, 구독 관련 정보(구독 기간, 구독 수수료 및 구독 횟수 등)를 저장 및 관리할 수 있다. 물론, DB는 상술한 데이터로 한정되지 않으며, 본 발명의 모든 데이터를 저장할 수 있다. 캐릭터 제공부는 제1 크리에이터의 입력에 기초하여 제1 인공지능 캐릭터를 생성한다. 캐릭터 제공부는 크리에이터가 본 발명의 시스템에서 제공하는 인공지능 캐릭터를 생성하는 기능을 통해 생성할 수 있다. 예를 들어, 캐릭터 제공부는 크리에이터인 사용자에 의해 얼굴 이미지, 말투, 성격, 관 심 대화 분야(또는 관심 대화 내용), 이름, 성별, 캐릭터 소개 내용 등이 설정됨으로써, 미리 설정된 기본 대화 엔진이 학습되어 인공지능 캐릭터를 생성할 수 있다. 이때, 캐릭터 제공부에서 생성되는 인공지능 캐릭터 는 크리에이터인 사용자에 의해 설정된 말투와 관심 대화 내용으로 해당 인공지능 캐릭터를 팔로잉하는 사람들 인 팔로워(인공지능 캐릭터 또는 크리에이터)와 대화를 주고 받을 수 있다. 본 발명의 실시예에 따른 인공지능 캐릭터의 구독 시스템은 생성된 인공지능 캐릭터가 대화 엔진을 이용하 여 팔로워들과 대화하는데 있어서, 팔로워들에게 대화하는 답변 방식 또는 답변 내용 등을 크리에이터가 원하는 답변 방식 또는 답변 내용으로 대화할 수 있도록 인공지능 캐릭터의 대화 엔진을 학습시킬 수 있다. 즉, 본 발 명은 크리에이터의 요청에 따라 대화를 통해 이미 생성된 인공지능 캐릭터의 대화 엔진을 조금씩 발전시켜 나가 는 것으로, 인공지능 캐릭터의 대화 엔진을 완성시킬 때까지 반복적으로 수행될 수 있다. 또한, 캐릭터 제공부에서 생성된 인공지능 캐릭터에는 크리에이터에 의해 생성된 인공지능 캐릭터를 다른 사용자들이 대화 관심 분야 등의 키워드를 통해 검색할 수 있도록, 크리에이터에 의해 설정된 적어도 하나 이상 의 해시태그가 부여될 수 있다. 예를 들어, 크리에이터에 의해 인공지능 캐릭터의 해시태그가 ‘#골프’, ‘# 스포츠’로 설정되어 있다면, 해당 인공지능 캐릭터는 골프와 스포츠로 검색 가능하고, 골프와 스포츠에 대한 대화를 할 수 있는 인공지능 캐릭터로 분류될 수 있다. 전술한 바와 같이 인공지능 캐릭터가 생성되면, 캐릭터 제공부에서 인공지능 캐릭터와 인공지능 캐릭터를 팔로잉하는 팔로워 간의 대화 서비스를 제공할 수 있다. 크리에이터에 의해 인공지능 캐릭터가 생성된 후, 해당 인공지능 캐릭터를 팔로잉하는 팔로워들이 생기면, 캐릭 터 제공부에 의해 인공지능 캐릭터와 팔로워 간의 대화방에서 대화 서비스를 제공할 수 있다. 이때, 팔로 워는 인공지능 캐릭터일 수 있으며, 인공지능 캐릭터를 생성한 크리에이터일 수 있다. 일 예로, 인공지능 캐릭 터와 인공지능 캐릭터의 팔로워가 대화하는 경우, 자동응답 기능이 온(ON)되어 크리에이터의 개입 없이 기 학습 된 대화 엔진을 기반으로 대화를 주고받을 수 있다. 다른 예로, 크리에이터와 인공지능 캐릭터, 인공지능 캐릭 터와 크리에이터, 또는 크리에이터와 크리에이터 즉, 적어도 한 명의 사람이 포함되어 대화하는 경우, 자동응답 기능이 오프(OFF)되어 크리에이터가 참여하여 자유롭게 대화를 주고받을 수 있다. 구독부는 제1 크리에이터가 제2 인공지능 캐릭터를 소유한 제2 크리에이터에게 구독 수수료를 지불하여 제 2 인공지능 캐릭터를 구독한다. 구독부는 제2 인공지능 캐릭터를 소유한 제2 크리에이터에게 기 설정된 기간 동안의 구독을 위한 구독 수 수료를 지불하고, 지불된 구독 수수료에 따라 기 설정된 기간 동안의 제2 인공지능 캐릭터에 대한 구독을 승인 할 수 있다. 예를 들면, 제1 크리에이터는 한달에 5만원의 구독 수수료를 지불하여 제2 인공지능 캐릭터에 대 한 구독을 요청할 수 있다. 이에, 구독부는 제1 크리에이터로부터 지급된 구독 수수료를 제2 크리에이터 에게 제공하며, 제2 크리에이터의 동의에 따라 제1 크리에이터에 의한 제2 인공지능 캐릭터에 대한 구독을 승인 할 수 있다. 이때, 구독 기간은 주별, 월별, 분기별 또는 연별로 지정될 수 있으며, 구독 수수료는 전술한 바 에 한정하지 않는다. 이후에, 구독부는 제1 크리에이터가 구독한 적어도 하나 이상의 인공지능 캐릭터의 실시간 활동 이력을 제 1 인공지능 캐릭터에게 제공할 수 있다. 예를 들면, 제1 크리에이터가 구독한 제2 인공지능 캐릭터의 접속 여 부, 실시간 채팅 여부, 라이브 방송 여부, 제2 크리에이터의 접속 시간 및 대화 파티 서비스 관련 정보 중 적어 도 어느 하나 이상의 실시간 활동 이력을 제1 인공지능 캐릭터에게 제공함으로써, 제1 크리에이터는 실시간으로 구독한 제2 인공지능 캐릭터에 대한 활동을 확인할 수 있다. 이때, 구독부는 제2 인공지능 캐릭터에 관한 활동 이력을 알림 팝업창을 통해 제1 크리에이터에게 제공할 수 있다. 또한, 구독부는 구독 수수료, 구독 기간 또는 구독 횟수에 따라 제2 인공지능 캐릭터를 구독하는 제1 크리 에이터의 구독 등급을 설정할 수 있다. 예를 들면, 구독 기간이 일주일이고, 구독 수수료는 지정된 금액을 지 불하며, 특정 크리에이터에 대해 1회 내지 3회 정도 구독한 경우에, 구독부는 제1 구독 등급을 설정할 수 있다. 또한, 구독 기간이 3개월이고, 구독 수수료는 지정된 금액을 지불하며, 특정 크리에이터에 대해 3회 내 지 10회 정도 구독한 경우에, 구독부는 제2 구독 등급을 설정할 수 있다. 또한, 구독 기간이 6개월 또는 1년이고, 구독 수수료는 프리미엄을 추가하여 지불하며, 특정 크리에이터에 대해 최소 10회 이상 구독한 경우에, 구독부는 제3 구독 등급을 설정할 수 있다. 즉, 구독부는 구독 수수료, 구독 기간 및 구독 횟수에 따라 구독 등급을 단계별로 설정할 수 있다. 다만, 구독 등급을 분류하는 기준은 전술한 바에 한정하지 않음은 당연하다. 제어부는 제1 크리에이터에 의해 제2 인공지능 캐릭터의 기능 서비스를 제어한다. 제어부는 제1 크리에이터의 선택에 따라 제2 인공지능 캐릭터를 뮤트(MUTE)할 수 있다. 이에, 제어부 는 제2 인공지능 캐릭터를 구독한 제1 크리에이터의 선택에 따라 제2 인공지능 캐릭터가 아닌 제2 인공지 능 캐릭터를 소유한 제2 크리에이터와의 대화 서비스를 제공할 수 있다. 예를 들면, 제1 크리에이터가 A 가수 (크리에이터)의 인공지능 캐릭터를 구독하는 경우, A 가수의 인공지능 캐릭터를 뮤트함으로써, 기 학습된 대화 엔진으로 대화하는 A 가수의 인공지능 캐릭터와 대화를 주고받는 것이 아닌, A 가수와 직접 대화를 주고받을 수 있게 된다. 또한, 제어부는 구독 등급에 따라서 제1 크리에이터에게 부가 서비스를 제공할 수도 있다. 예를 들면, 제 1 구독 등급인 크리에이터는 구독한 인공지능 캐릭터를 최대 2회만 뮤트할 수 있는 반면에, 제3 구독 등급인 크 리에이터는 구독한 인공지능 캐릭터를 최대 5회까지 뮤트할 수 있으며, 구독한 크리에이터와의 대화 서비스 횟 수 또한 제1 구독 등급인 크리에이터에 비해 많이 지급될 수 있다. 본 발명의 실시예에 따른 인공지능 캐릭터의 구독 시스템에서 제어부는 제2 인공지능 캐릭터와 제2 인공지능 캐릭터를 팔로잉하는 팔로워 간의 대화 시, 제2 인공지능 캐릭터를 구독한 구독자들의 인공지능 캐릭 터를 상단에 제공할 수 있다. 예를 들면, 제1 크리에이터가 일정 금액의 수수료를 지불하고, 제2 인공지능 캐릭터를 구독한다고 가정한 경우 에, 제어부는 제2 인공지능 캐릭터가 제1 인공지능 캐릭터가 아니더라도 적어도 하나 이상의 팔로워와 대 화를 주고받는 대화방 상단에 제2 인공지능 캐릭터를 구독한 적어도 하나 이상의 구독자들의 인공지능 캐릭터를제공할 수 있다. 이에, 제2 인공지능 캐릭터는 팔로워와 대화하는 대화방의 상단에 제공되는 구독자들을 확인 할 수 있다. 다만, 실시예에 따라서, 제2 인공지능 캐릭터를 구독한 구독자들의 인공지능 캐릭터들은 제2 크리 에이터가 본 발명의 시스템에서 제공되는 애플리케이션(Application)에 접속하는 동시에, 모든 페이지 상단에 위치할 수도 있으며, 메인 페이지, 개인 페이지, 대화방 및 팔로워 리스트 중 적어도 어느 하나 이상의 공간에 제공될 수도 있다. 또한, 본 발명의 실시예에 따른 인공지능 캐릭터의 구독 시스템에서 제어부는 제2 인공지능 캐릭터와 제2 인공지능 캐릭터를 구독한 인공지능 캐릭터들만 입장이 가능한 대화 파티 서비스를 제공할 수 있다. 보다 상세하게, 제어부는 적어도 하나 이상의 구독자를 갖는 제2 인공지능 캐릭터 또는 제2 크리에이터와 구독자들만이 입장 가능하여 자유롭게 대화를 주고받을 수 있는 대화 파티 서비스를 제공할 수 있다. 이때, 제 어부는 구독자들만을 위한 제2 크리에이터의 라이브 방송, 제2 크리에이터와의 실제 대화 서비스, 사진 또 는 동영상 제공과 같은 다양한 파티 서비스를 제공할 수도 있다. 이에, 적어도 하나 이상의 구독자를 갖는 제2 인공지능 캐릭터는 본인인 제2 인공지능 캐릭터 또는 제2 크리에이터와 적어도 하나 이상의 구독자들만이 입장 가능한 대화 파티 서비스에 참여할 수 있다. 비록, 도 6의 시스템에서 그 설명이 생략되었더라도, 도 6을 구성하는 각 구성 수단은 도 1 내지 도 5에서 설명 한 모든 내용을 포함할 수 있으며, 이는 이 기술 분야에 종사하는 당업자에게 있어서 자명하다. 이상에서 설명된 시스템 또는 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(Field Programmable Gate Array), PLU(programmable logic unit), 마이크로프로세서, 또 는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특 수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다. 이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.\n【요약】본 발명은 구독한 인공지능 캐릭터의 기능 서비스의 제어 가능한 인공지능 캐릭터의 구독 방법 및 시스템에 관한 것으로서, 제1 크리에이터의 입력에 기초하여 제1 인공지능 캐릭터를 생성하는 단계, 상기 제1 크리에이터가 제2 인공지능 캐릭터를 소유한 제2 크리에이터에게 구독 수수료를 지불하여 상기 제2 인공지능 캐릭터를 구독하는 단 계 및 상기 제1 크리에이터에 의해 상기 제2 인공지능 캐릭터의 기능 서비스를 제어하는 단계를 포함한다.\n\n【청구항 1】\n제1 크리에이터의 입력에 기초하여 제1 인공지능 캐릭터를 생성하는 단계;상기 제1 크리에이터가 제2 인공지능 캐릭터를 소유한 제2 크리에이터에게 구독 수수료를 지불하여 상기 제2 인공지능 캐릭터를 구독하는 단계; 및상기 제1 크리에이터에 의해 상기 제2 인공지능 캐릭터의 기능 서비스를 제어하는 단계를 포함하는 인공지능 캐릭터의 구독 방법.\n【청구항 2】\n제1항에 있어서,상기 구독하는 단계는상기 제2 인공지능 캐릭터를 소유한 상기 제2 크리에이터에게 기 설정된 기간 동안의 구독을 위한 구독 수수료를 지불하는 단계; 및상기 지불된 구독 수수료에 따라 기 설정된 기간 동안의 상기 제2 인공지능 캐릭터에 대한 구독을 승인하는 단계를 포함하는 인공지능 캐릭터의 구독 방법.\n【청구항 3】\n제2항에 있어서,상기 구독하는 단계는상기 제1 크리에이터가 구독한 적어도 하나 이상의 인공지능 캐릭터의 실시간 활동 이력을 상기 제1 인공지능캐릭터에게 제공하는 단계를 포함하는 인공지능 캐릭터의 구독 방법.\n【청구항 4】\n제2항에 있어서,상기 구독하는 단계는구독 수수료, 구독 기간 또는 구독 횟수에 따라 상기 제2 인공지능 캐릭터를 구독하는 상기 제1 크리에이터의구독 등급을 설정하는 것을 특징으로 하는, 인공지능 캐릭터의 구독 방법.\n【청구항 5】\n제1항에 있어서,상기 제어하는 단계는 상기 제1 크리에이터의 선택에 따라 상기 제2 인공지능 캐릭터를 뮤트(MUTE)하는 것을 특징으로 하는, 인공지능캐릭터의 구독 방법.\n【청구항 6】\n제5항에 있어서,상기 제어하는 단계는 상기 제2 인공지능 캐릭터를 구독한 상기 제1 크리에이터의 선택에 따라 상기 제2 인공지능 캐릭터가 아닌 상기공개특허 10-2023-0119284-3-제2 인공지능 캐릭터를 소유한 상기 제2 크리에이터와의 대화 서비스를 제공하는 것을 특징으로 하는, 인공지능캐릭터의 구독 방법.\n【청구항 7】\n제1항에 있어서,상기 제2 인공지능 캐릭터와 상기 제2 인공지능 캐릭터를 팔로잉하는 팔로워 간의 대화 서비스 시, 상기 제2 인공지능 캐릭터를 구독한 구독자들의 인공지능 캐릭터를 상단에 노출하는 단계를 더 포함하는 인공지능 캐릭터의 구독 방법.\n【청구항 8】\n제1항에 있어서,상기 제2 인공지능 캐릭터와, 상기 제2 인공지능 캐릭터를 구독한 인공지능 캐릭터들만 입장이 가능한 대화 파티 서비스를 제공하는 단계를 더 포함하는 인공지능 캐릭터의 구독 방법.\n【청구항 9】\n제1 크리에이터의 입력에 기초하여 제1 인공지능 캐릭터를 생성하는 캐릭터 생성부;상기 제1 크리에이터가 제2 인공지능 캐릭터를 소유한 제2 크리에이터에게 구독 수수료를 지불하여 상기 제2 인공지능 캐릭터를 구독하는 구독부; 및상기 제1 크리에이터에 의해 상기 제2 인공지능 캐릭터의 기능 서비스를 제어하는 제어부를 포함하는 인공지능 캐릭터의 구독 시스템.\n【청구항 10】\n제9항에 있어서,상기 구독부는 상기 제2 인공지능 캐릭터를 소유한 상기 제2 크리에이터에게 기 설정된 기간 동안의 구독을 위한 구독 수수료를 지불하고, 상기 지불된 구독 수수료에 따라 기 설정된 기간 동안의 상기 제2 인공지능 캐릭터에 대한 구독을승인하는, 인공지능 캐릭터의 구독 시스템.\n【청구항 11】\n제10항에 있어서,상기 구독부는상기 제1 크리에이터가 구독한 적어도 하나 이상의 인공지능 캐릭터의 실시간 활동 이력을 상기 제1 인공지능캐릭터에게 제공하는, 인공지능 캐릭터의 구독 시스템.\n【청구항 12】\n제10항에 있어서,상기 구독부는구독 수수료, 구독 기간 또는 구독 횟수에 따라 상기 제2 인공지능 캐릭터를 구독하는 상기 제1 크리에이터의구독 등급을 설정하는 것을 특징으로 하는, 인공지능 캐릭터의 구독 시스템.\n【청구항 13】\n제9항에 있어서,상기 제어부는공개특허 10-2023-0119284-4-상기 제1 크리에이터의 선택에 따라 상기 제2 인공지능 캐릭터를 뮤트(MUTE)하는 것을 특징으로 하는, 인공지능캐릭터의 구독 시스템.\n【청구항 14】\n제13항에 있어서,상기 제어부는상기 제2 인공지능 캐릭터를 구독한 상기 제1 크리에이터의 선택에 따라 상기 제2 인공지능 캐릭터가 아닌 상기제2 인공지능 캐릭터를 소유한 상기 제2 크리에이터와의 대화 서비스를 제공하는 것을 특징으로 하는, 인공지능캐릭터의 구독 시스템.\n【청구항 15】\n제9항에 있어서,상기 제어부는상기 제2 인공지능 캐릭터와 상기 제2 인공지능 캐릭터를 팔로잉하는 팔로워 간의 대화 서비스 시, 상기 제2 인공지능 캐릭터를 구독한 구독자들의 인공지능 캐릭터를 상단에 노출하는, 인공지능 캐릭터의 구독 방법.\n【청구항 16】\n제9항에 있어서,상기 제어부는상기 제2 인공지능 캐릭터와, 상기 제2 인공지능 캐릭터를 구독한 인공지능 캐릭터들만 입장이 가능한 대화 파티 서비스를 제공하는, 인공지능 캐릭터의 구독 방법."}
{"context": "", "input": "【기술명】\n가스 누출을 탐지하는 방법 및 이를 수행하는 인공지능 기반 가스 누출을 탐지하는 시스템\n\n【기술 설명】\n**항목 1:**  \n이 기술은 인공지능 기반의 가스 누출 탐지 시스템으로, 다양한 유형의 카메라를 활용하여 실시간으로 가스 누출을 모니터링하고 탐지하는 전자 장치에 관한 것입니다. 시스템은 제1 타입 및 제2 타입의 학습 영상을 수집하여 인공지능 모델을 학습시키고, 이를 통해 가스 객체의 누출 여부를 정밀하게 분석합니다. 이 기술은 고급 분석 알고리즘을 통해 가스 누출을 시각적으로 확인하기 어려운 환경에서도 즉각적으로 대응할 수 있는 능력을 제공합니다.\n\n【해결 문제】\n**항목 2:**  \n산업현장 및 일상생활에서 가스 누출은 인체에 치명적이거나 폭발성을 띌 수 있는 매우 위험한 상황을 초래할 수 있습니다. 기존의 가스 탐지 기술은 종종 한계가 있어, 가스의 누출을 신속하고 정확하게 탐지하는 데 어려움이 있습니다. 따라서 이 기술은 실시간 모니터링을 통해 가스 누출을 조기에 감지하고, 2차 사고를 예방하기 위한 필수적인 솔루션으로 자리매김할 필요성이 큽니다.\n\n【기술 차별성】\n**항목 3:**  \n본 기술은 기존의 가스 탐지 시스템과 비교하여 두 가지 주요 차별점을 가지고 있습니다. 첫째, 복수의 카메라 타입을 활용하여 다양한 환경에서의 가스 누출 탐지를 가능하게 하며, 둘째, 인공지능 모델을 통해 학습된 데이터 기반으로 실시간 분석을 수행하여 탐지의 정확도를 극대화합니다. 이러한 혁신성은 가스 누출 사고를 예방하고, 신속한 대처를 가능하게 하여 안전성을 높이는 데 기여합니다.\n\n【활용 분야】\n본 인공지능 기반 가스 누출 탐지 장치는 다양한 산업 분야에서 활용될 수 있습니다. 특히, 화학 공장, 정유소, 가스 배급소와 같은 위험물질을 다루는 산업에서 필수적인 안전 시스템으로 자리잡을 수 있습니다. 또한, 주택 및 건물의 안전 관리 시스템, 스마트 시티 개발, 환경 모니터링 등 여러 분야에서도 응용 가능하여, 가스 누출로 인한 사고를 예방하고 인명 및 재산 피해를 최소화하는 데 기여할 것입니다.\n\n【구성 요소 및 기능】\n본 장치는 세 가지 주요 구성 요소로 이루어져 있습니다. 첫째, 제1 타입의 카메라는 고해상도 영상을 촬영하여 모니터링 대상 공간의 시각적 데이터를 수집합니다. 둘째, 제2 타입의 카메라는 열 감지 기능을 갖추고 있어 가스 누출 시 발생할 수 있는 열적 변화를 감지합니다. 셋째, 인공지능 모델은 수집된 영상 데이터를 분석하여 가스, 연기, 불꽃과 같은 표적 객체를 인식하고 누출 여부를 판단하는 기능을 수행합니다. 이러한 구성 요소들은 상호 연동되어 가스 누출을 실시간으로 감지하고 경고하는 역할을 합니다.\n\n【구현 방식 예】\n본 기술의 구현은 단계적으로 이루어집니다. 첫 번째 단계에서는 제1 타입 및 제2 타입 카메라를 통해 모니터링 대상 공간의 다양한 학습 영상을 수집합니다. 두 번째 단계에서는 수집된 영상 데이터를 기반으로 학습 데이터와 검증 데이터를 생성하여 인공지능 모델을 학습시킵니다. 세 번째 단계에서는 학습된 모델을 활용하여 실시간으로 입력되는 영상 데이터에서 표적 객체의 존재 여부를 인식하고, 이를 통해 가스 누출을 탐지합니다. 이와 같은 체계적인 접근 방식은 높은 정확도와 신뢰성으로 가스 누출을 효과적으로 감지하도록 설계되었습니다.", "output": "【발명의 명칭】\n가스 누출을 탐지하는 방법 및 이를 수행하는 인공지능 기반 가스 누출을 탐지하는 장치\n【기술분야】\n본 개시는 가스 누출을 탐지하는 방법 및 이를 수행하는 인공지능 기반 가스 누출 탐지를 위한 전자 장치에 관 한 것이다. 보다 상세하게는 적어도 하나의 인공 지능 모델을 이용하여 가스 누출을 탐지하는 방법 및 이를 수 행하는 전자 장치에 관한 것이다.\n【배경기술】\n산업현장이나 생활 주변에서 사용되는 여러 종류의 가스 중 인체에 치명적이거나 폭발성을 띄는 가스누출의 탐 지는 매우 중요하며, 2차적인 안전사고로 확대되는 것을 방지하기 위해 실시간 모니터링이 필요하다. 특히, 저 탄장에서 발생하는 매탄, 암모니아 저장탱크 또는 가스 배관에서 발생하는 암모니아와 같은 가스의 경우 시각적 으로 확인하기가 어렵기 때문에 이러한 가스의 누출을 사전에 탐지하여 안전 사고를 예방할 필요가 있다. 그러나, 종래 가스 경보 및 탐지를 위한 기술의 경우 가스 센서, 비디오 카메라를 활용하는 일부 기술들을 개시 하나, 가스의 탐지 및 추적의 정확도에 한계가 있으며, 경보장치와 연동되어 현장 내부의 가스 누출을 모니터링 하고 누출 원점을 탐지하는데 인력을 활용하는 경우가 많아 사고 대처에 미흡한 한계가 있다. 따라서, 미리 설 정된 가스, 연기 및 불꽃과 같은 표적 객체를 효과적으로 탐지하고 관리하기 위한 기술 개발이 요구되고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-2355884호\n【해결하려는 과제】\n일 실시 예에 의하면, 인공지능 기반 유해 가스 실시간 영상화 탐지 시스템 및 이의 동작 방법이 제공될 수 있 다. 보다 상세하게는, 상기 시스템에 사용될 수 있는 인공지능 기반 가스 누출을 탐지하는 전자 장치 및 상기 전자 장치가 가스 누출을 탐지하는 방법이 제공될 수 있다.\n【과제의 해결 수단】\n상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하 는 전자 장치가 상기 가스 누출을 탐지하는 방법은 상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라 로부터 모니터링 대상 공간에 대한 제1 타입 학습 영상들, 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간에 대한 제2 타입 학습 영상들을 획득하는 단계; 상기 제1 타입 학습 영 상들 및 상기 제2 타입 학습 영상들에 기초하여 학습 데이터 및 검증 데이터를 생성하는 단계; 상기 생성된 학 습 데이터에 기초하여, 상기 제1 타입의 카메라로부터 획득되는 제1 타입 영상들 및 상기 제2 타입의 카메라로 부터 획득되는 제2 타입 영상들이 입력되면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 표적 객체가 검 출되는지 여부를 식별하는 객체 인식 모델을 학습시키는 단계; 및 상기 학습된 객체 인식 모델에 상기 제1 타입 영상들 및 상기 제2 타입 영상들을 입력함으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체의 검출 여부를 식별하는 단계; 를 포함하고, 상기 표적 객체는 연기 객체, 가스 객체 또는 불꽃 객체 중 적어도 하나를 포함할 수 있다. 상술한 기술적 과제를 달성하기 위한 또 다른 실시 예에 의하면, 인공지능 기반 가스 누출을 탐지하는 전자 장 치에 있어서, 네트워크 인터페이스; 하나 이상의 인스트럭션을 저장하는 메모리; 및 상기 하나 이상의 인스트럭 션을 실행하는 적어도 하나의 프로세서; 를 포함하고, 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트 럭션을 실행함으로써, 상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간에 대한 제1 타입 학습 영상들, 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간에 대한 제2 타입 학습 영상들을 획득하고, 상기 제1 타입 학습 영상들 및 상기 제2 타입 학습 영상들 에 기초하여 학습 데이터 및 검증 데이터를 생성하고, 상기 생성된 학습 데이터에 기초하여, 상기 제1 타입의 카메라로부터 획득되는 제1 타입 영상들 및 상기 제2 타입의 카메라로부터 획득되는 제2 타입 영상들이 입력되 면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 표적 객체가 검출되는지 여부를 식별하는 객체 인식 모 델을 학습시키고, 상기 학습된 객체 인식 모델에 상기 제1 타입 영상들 및 상기 제2 타입 영상들을 입력함으로 써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체의 검출 여부를 식별하고, 상기 표적 객 체는 연기 객체, 가스 객체 또는 불꽃 객체 중 적어도 하나를 포함하는 것을 특징으로 하는, 전자 장치가 제공 될 수 있다. 상술한 기술적 과제를 달성하기 위한 또 다른 실시 예에 의하면, 인공지능 기반 가스 누출을 탐지하는 전자 장 치가 상기 가스 누출을 탐지하는 방법에 있어서, 상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로 부터 모니터링 대상 공간에 대한 제1 타입 학습 영상들, 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카 메라로부터 상기 모니터링 대상 공간에 대한 제2 타입 학습 영상들을 획득하는 단계; 상기 제1 타입 학습 영상 들 및 상기 제2 타입 학습 영상들에 기초하여 학습 데이터 및 검증 데이터를 생성하는 단계; 상기 생성된 학습 데이터에 기초하여, 상기 제1 타입의 카메라로부터 획득되는 제1 타입 영상들 및 상기 제2 타입의 카메라로부터 획득되는 제2 타입 영상들이 입력되면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 표적 객체가 검출되 는지 여부를 식별하는 객체 인식 모델을 학습시키는 단계; 및 상기 학습된 객체 인식 모델에 상기 제1 타입 영 상들 및 상기 제2 타입 영상들을 입력함으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체의 검출 여부를 식별하는 단계; 를 포함하고, 상기 표적 객체는 연기 객체, 가스 객체 또는 불꽃 객체 중 적어도 하나를 포함하는 것을 특징으로 하는, 방법을 수행하도록 하는 프로그램이 저장된 컴퓨터로 읽을 수 있 는 기록 매체가 제공될 수 있다.\n【발명의 효과】\n일 실시 예에 의하면 적어도 하나의 인공 지능 모델을 이용하여 가스 객체의 누출을 효과적으로 탐지할 수 있다. 일 실시 예에 의하면, 복수 타입의 영상 데이터에 기초하여 적어도 하나의 인공 지능 모델을 학습시키고, 학습 된 적어도 하나의 인공 지능 모델을 이용하여 가스 누출을 탐지할 수 있다.\n【발명을실시하기위한구체적인내용】\n본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해 서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치 및 상기 인공지능 기반 가스 누출을 탐지하는 전자 장치를 포함하는 인공지능 기반 가스 누출 탐지 시스템의 동작 과정을 개략적으로 설명하기 위한 도면이다. 일 실시 예에 의하면 인공지능 기반 가스 누출을 탐지하는 전자 장치(이하에서는 '전자 장치'로 명명)는 적어도 하나의 타입의 카메라 및 레이저 측정기를 포함하는 카메라 설치셋으로부터 모니터링 대상 공간에 대한 영상 정보들을 획득하고, 획득된 영상들을 인공지능 모델에 입력함으로써, 획득된 영상들 내에 연기, 가스 또는 불꽃 중 적어도 하나를 포함하는 표적 객체가 있는지 여부를 결정할 수 있다. 일 실시 예에 의하면 전자 장치는 적어도 하나의 타입의 카메라들로부터 적어도 하나의 타입에 따른 복수의 영상들을 인공지능 모델에 입력하고, 인공 지능 모델의 출력 값에 기초하여, 가스 객체, 연기 객체 또는 불꽃 객체 중 적어도 하나 를 포함하는 표적 객체가 검출되는 경우, 표적 객체의 형상 정보를 추출하고, 추출된 형상 정보에 기초하여 표 적 객체를 모델링 및 추적할 수 있다. 본 명세서에서 인공지능 기반 가스 누출 탐지 시스템 또는 전자 장치가 탐지하는 표적 객체는 가스 객체, 가스가 공기 중에서 기체상태로 유동함에 따라 가스 입자 및 공기 입자가 일체가 된 상태의 연기 객체,가스가 연소함에 따라 생성되는 불꽃 객체 중 적어도 하나를 포함할 수 있다. 일 실시 예에 따른 가스 객체, 연 기 객체, 불꽃 객체는 가시광선 또는 상기 가시광선과 다른 파장 대의 전자기파(예컨대 적외선 등)를 통해 감지 될 수 있다. 일 실시 예에 의하면, 전자 장치가 카메라 설치셋으로부터 획득하는 영상 정보는 저탄장, 암모니아 배관이 설치된 작업 현장을 EO 카메라 또는 OGI 카메라 중 적어도 하나를 이용하여 촬영함으로써 획득되는 가시 광선 영상 또는 적외선 영상들일 수 있다. 또한, 가시광선 영상 및 적외선 영상들은 미리 설정된 프레임 간격을 가지는 복수의 가시광선 프레임 이미지들 및 복수의 적외선 프레임 이미지들을 포함할 수 있다. 일 실시 예에 의하면, 전자 장치는 영상 정보들을 분석한 결과, 표적 객체가 검출되는 것으로 식별 되는 경우, 경보 장치가 시각적 또는 청각적 컨텐츠를 출력하도록 하는 제어 신호를 전송함으로써 가스 누 출과 같은 위험한 상황이 발생하였다는 사실을 작업자들에게 효과적으로 전달할 수 있다. 일 실시 예에 의하면, 전자 장치는 모니터링 대상 공간에 인접하게 설치되는 관제 단말과 연결될 수도 있다. 일 실시 예에 의하면, 전자 장치는 관제 단말로 영상 정보 및 레이저 측정값들을 전달하거나, 전자 장치 (10000가 인공 지능 모델을 이용하여 영상 정보를 분석한 결과(예컨대 표적 객체 검출 여부, 표적 객체에 대한 형상 정보, 누출 원점, 가스 누출 여부, 가스 종류에 대한 정보)를 관제 단말로 전송할 수도 있다. 일 실시 예에 의하면, 관제 단말은 카메라 설치셋과 직접 연결될 수도 있으며, 전자 장치 또는 카메라 설치셋으로부터 획득되는 영상 정보들을 직접 저장함과 함께, 획득된 영상 정보들을 출력할 수 있 다. 또한, 관제 단말은 전자 장치에 포함된 메모리, 프로세서 및 네트워크 인터페이스에 대응되는 구성들을 포함하고, 획득된 영상 정보들을 가스 누출 탐지를 위한 인공지능 모델에 입력함으로써, 표적 객체가 식별되는지 여부, 가스 누출과 같은 이벤트가 탐지되었는지 여부, 표적 객체의 형상 정보들을 결정할 수 있고, 표적 객체 검출과 같은 이벤트가 발생되는 경우 경보 장치로 직접 경고 컨텐츠 출력을 위한 제어 신호를 전송하거나, 표적 객체에 대한 정보들을 디스플레이 장치(예컨대 관제 단말용 모니터)를 통해 직접 출력할 수도 있다. 일 실시 예에 의하면 관제 단말은 인공지능 기반 가스 영상 서버, 경보/제어 서버 및 쿨링 시스템을 포함할 수 있으나, 이에 한정되는 것은 아니며, 작업 현장 내 연산이 필요한 자산에 대한 효율적 처리를 위한 MEC(Multi Access Edge Computing) 서버를 더 포함할 수도 있다. 또한, 관제 단말은 멀티 이더넷 장치를 통해 외부의 여러 장비들과 실시간으로 연결될 수도 있다. 일 실시 예에 의하면, 관제 서버는 카메라 설치셋, 전자 장치, 관제 단말 또는 경보 장치 중 적어도 하나와 연결됨으로써 가스 누출 탐지 시스템내 구성들의 동작을 제어할 수 있다. 예를 들어, 관제 서버는 전자 장치로부터 모니터링 대상 공간에 대한 영상 정보들, 표적 객체 검출 에 따른 표적 객체에 대한 정보(예컨대 종류, 누출 원점, 실제 카메라 설치셋으로부터의 물리적 위치 정보) 및 합성 영상을 획득하고, 획득된 영상 정보들, 표적 객체에 대한 정보 및 합성 영상을 디스플레이상에 출력할 수 있다. 관제 서버는 수집된 데이터들을 통합 관리함으로써 모니터링 대상 공간에 대한 관리를 용이하게 할 수 있다. 또한, 일 실시 예에 의하면, 관제 서버는 모니터링 대상 공간에 대한 영상 정보들, 합성 영상 및 표적 객 체에 관한 정보를 출력함과 함께, 가스 누출 탐지 및 관리를 위한 사용자 인터페이스를 화면상에 출력할 수 있 다. 관제 서버는 출력된 사용자 인터페이스에 대한 관제자들의 사용자 입력에 기초하여 가스 누출 탐지 시 스템내 장치들의 동작을 제어함으로써, 가스 누출 시 해당 가스 누출 원점에 대한 모니터링이 지속되도록 할 수 있다. 또한, 일 실시 예에 의하면, 전자 장치는 레이저 측정값과 카메라 설치셋의 팬틸트 정보에 기초하여, 추적된 표적 객체에 대해 생성되는 누출 영상의 파노라마 영상에 대한 좌표를 결정하고, 결정된 좌표 에 기초하여 표적 객체에 관한 누출 영상을 파노라마 영상에 합성함으로써 합성 영상을 생성하며, 원 영상 정보, 누출 원점, 좌표 정보, 누출 영상 및 합성 영상에 대한 정보를 관제 단말 또는 관제 서버 중 적어도 하나로 전송함으로써, 관제자로 하여금 누출된 표적 가스에 대한 모니터링이 용이하도록 할 수 있다. 또한, 일 실시 예에 의하면, 전자 장치는 영상 정보를 분석한 결과, 표적 객체에 관한 누출 영상의 파노 라마 영상에 대한 영상 상에서의 위치 뿐만 아니라, 실제 누출 원점에 대한 물리적 공간에 대한 위치 정보를 관 제 단말, 관제 서버로 더 전송할 수도 있다. 예를 들어, 전자 장치는 카메라 설치셋의 레 이저 측정기로부터 레이저 측정값을 획득하고, 획득된 레이저 측정값과 미리 결정된 카메라 설치셋의 위치 정보에 기초하여 카메라 설치셋으로부터 실제 표적 객체가 발생한 물리적 거리 및 상기 실제 표적 객체가 발생한 물리적 공간상에서의 위치를 식별하고, 식별된 물리적 거리 및 위치에 대한 정보를 관제 서버로 제공함으로써 관제자로 하여금 표적 객체가 누출된 위치를 정확하게 인지하도록 할 수 있다. 또한, 일 실시 예에 의하면 인공지능 기반 가스 누출을 탐지하는 전자 장치는 카메라 설치셋으로부 터 획득된 영상 정보들을 인공 지능 모델에 입력함으로써 분석한 결과, 표적 객체가 검출되는 것으로 식별되는 경우, 소정의 이벤트가 발생한 것으로 결정하고, 경보 장치로 제어 신호를 전송함으로써 시각적 또는 청각 적 경고 컨텐츠들이 출력되도록 할 수 있다. 일 실시 예에 의하면, 전자 장치는 가스 누출 탐지를 위해 필요한 소프트웨어 모듈들(예컨대 가스 누출 탐지를 위한 하나 이상의 인스트럭션 집합들)을 저장할 수 있고, 프로세서는 상기 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써 가스 누출 탐지 프로세스를 수행할 수 있다. 또한, 네트워크 인터페이 스는 전자 장치와 연결된 다른 전자 장치들로부터 데이터를 획득하건, 전송하는 기능을 수행할 수 있다. 일 실시 예에 의하면, 도 1에 도시된 가스 누출 탐지 시스템은 카메라 설치셋, 전자 장치, 경보 장치, 관제 단말 및 관제 서버를 포함할 수 있으며, 가스 누출 탐지를 위한 기타 장치를 더 포 함할 수도 있다. 또한, 일 실시 예에 따른 가스 누출 탐지 시스템 내 장치들은 적어도 하나의 네트워크를 통해 서로 연결될 수 있다. 일 실시 예에 따른 가스 누출 탐지 시스템내 장치들 사이의 데이터 전송 시 미 리 설정된 데이터 손실률(예컨대 5% 미만) 및 미리 설정된 데이터 전송 주기(예컨대 1초 미만)에 따라 데이터들 이 전송될 수 있으나, 이에 한정되는 것은 아니다. 일 실시 예에 의하면 적어도 하나의 네트워크는 근거리 통신망(Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 부가가치 통신망(Value Added Network; VAN), 이동 통신망(mobile radio communication network), 위성 통신망, 각 네트워크 구성 주체들이 통신을 할 수 있도록 하는 포괄적 의미의 데이터 통신망 및 이들의 상호 조합을 포함할 수 있다. 본 개시에 따른 가스 누출 탐지 시스템 및 전자 장치는 광범위한 저탄장 모니터링 시스템에 사용되거 나, 대량의 암모니아 저장 탱크/가스배관이 설치된 공간의 모니터링 시스템에 사용될 수 있으나, 이에 한정되는 것은 아니며, 가스 객체, 연기 객체 또는 불꽃 객체 중 적어도 하나를 포함하는 표적 객체들의 추적 및 모니터 링이 필요한 작업 현장에 사용될 수 있다. 도 2는 또 다른 실시 예에 따른 인공지능 기반 가스 누출 탐지 시스템의 동작 과정을 나타내는 도면이다. 도 2를 참조하여 또 다른 실시 예에 따른 인공지능 기반 가스 누출 탐지 시스템의 동작 과정을 설명하기로 한다. 일 실시 예에 의하면 인공지능 기반 가스 누출 탐지 시스템은 카메라 설치셋, AI 가스영상 탐지 서버, 경보/제어 서버, 가스 누출 알람 및 경보 장치 및 관제 단말기, 상황실 영상 시스템 을 포함할 수 있다. 일 실시 예에 의하면 카메라 설치셋은 가스 이미징 카메라(예컨대 Optical Gas Imaging, OGI 카메라), EO 카메라(예컨대 Electro-Optical, EO) 및 레이저 측정기를 포함할 수 있다. 일 실시 예에 의하면 가스 이미징 카메라는 물체에서 방출되는 적외선 복사 에너지를 전자적으로 센싱함으 로써, 눈에 보이지 않는 가스 객체들에 대한 이미지 또는 미리 설정된 프레임 간격의 복수의 이미지들을 포함하 는 적외선 영상을 생성하는 카메라일 수 있다. 또한, 일 실시 예에 의하면, EO 카메라는 물체에서 반사되는 가 시 광선을 이미지 센서를 통해 센싱함으로써 가시 광선 이미지 또는 미리 설정된 프레임 간격의 복수의 가시광 선 이미지들을 포함하는 가시광선 영상을 생성하는 카메라일 수 있다. 일 실시 예에 의하면 레이저 측정기는 레이저를 방출하고, 방출된 레이저가 대상 객체에 반사됨에 따른 시 간을 측정함으로써 레이저 측정기 또는 카메라 설치셋으로부터 대상 객체까지의 거리 값을 나타내는 레이저 측정 값을 획득할 수 있다. 카메라 설치셋은 적외선 영상들, 가시광선 영상들 및 레이저 측정 값을 가스 누출 탐지 시스템내 적어도 하나의 장치들로 전송할 수 있다. 일 실시 예에 의하면, 가스 이미징 카메 라 및 EO 카메라의 촬영 화각, 촬영 주기는 서로 다르게 설정될 수 있으며, 가스 이미징 카메라 및 EO 카메라가 적외선 영상들 및 가시광선 영상들을 전송하는 동작 조건은 사용자 입력 조건에 따라 미리 설정될 수 있다. 일 실시 예에 의하면, AI 가스 영상 탐지 서버는 카메라 설치셋으로부터 획득된 영상들에 나타나는 표적 객체를 탐지하고, 탐지된 표적 객체의 누출 원점을 식별하며, 표적 객체에 대한 누출 영상을 파노라마 영 상에 합성함으로써 시각화하는 기능을 수행할 수 있다. 일 실시 예에 의하면, 경보/제어 서버는 표적 객체검출에 따른 이벤트 발생이 탐지되면 가스누출 알람 및 경보 신호를 경보 장치로 전송할 수 있다. 또한, 경보/ 제어 서버는 카메라 설치셋에서 획득되는 영상 정보들, 상기 표적 객체에 관한 누출 영상 및 합성 영 상들을 저장할 수 있다. 또한, 경보/제어 서버는 사용자 입력에 기초하여 저장된 영상들에 대한 검색 기능, 가스 누출 탐지 시스템 내 장치 동작 환경을 설정하기 위한 환경설정 기능, 가스 누출 탐지 시스템내 장치들의 동작 제어를 위 한 동작 제어 기능을 제공할 수도 있다. 일 실시 예에 의하면 경보/제어 서버는 TCP/IP를 통해 이벤트 발 생 신호 데이터를 경보 장치 또는 상황실 영상 시스템으로 송수신할 수 있다. 관제 단말기의 동작은 도 1에 도시된 관제 단말의 동작에 대응될 수 있으므로 구체적인 설명은 생략 하기로 한다. 상황실 영상 시스템은 도 2에 도시된 바와 같이, 표적 객체가 검출되는 경우, 표적 객체에 대한 누출 영상을 파노라마 영상에 합성함으로써 생성되는 합성 영상을 출력할 수 있다. 상황실 영상 시스템 의 동작은 도 1에 도시된 관제 서버의 동작에 대응될 수 있으므로 구체적인 설명은 생략하기로 한다. 도 3은 일 실시 예에 따른 인공지능 기반 가스 누출 탐지 시스템의 동작 방법을 나타내는 흐름도이다. 도 3을 참조하여 일 실시 예에 따른 인공지능 기반 가스 누출 탐지 시스템의 동작 방법을 설명하기로 한다. 도 3에 도시된 인공지능 기반 가스 누출 탐지 시스템의 동작은 도 1에 도시된 전자 장치에 의해서도 수행될 수도 있음은 물론이다. S302에서, 가스 누출 탐지 시스템은 EO 영상 및 OGI 영상을 획득할 수 있다. 예를 들어, 가스 누출 탐지 시 스템은 적어도 하나의 EO 카메라 및 적어도 하나의 OGI 카메라로부터 복수의 EO 영상들 및 OGI 영상들을 획 득할 수 있다. S304에서, 가스 누출 탐지 시스템은 S304에서 획득된 영상들을 객체 인식 모델에 입력 할 수 있다. 예를 들어, 가스 누출 탐지 시스템은 적어도 하나의 EO 카메라로부터 획득된 EO 영상 및 적어 도 하나의 OGI 카메라로부터 획득된 OGI 영상들을 객체 인식 모델에 입력할 수 있다. 도 3에는 도시되지 않았지만, 일 실시 예에 의하면 가스 누출 탐지 시스템은 EO 영상 및 OGI 영상을 획득하 고, 획득된 EO 영상 및 OGI 영상에 대한 이진화, 리사이징, 노멀라이즈(Normalize), 데이터 증강(Data Augmentation) 와 같은 전처리 과정을 수행할 수 있다. 가스 누출 탐지 시스템은 전처리된 EO 영상 및 OGI 영상들을 객체 인식 모델에 입력함으로써 객체 인식 정확도를 향상시킬 수 있다. S306에서, 가스 누출 탐지 시스템은 S302에서 객체 인식 모델의 출력 값에 기초하여 영상들로부터 표적 객 체가 검출되는지 여부를 식별할 수 있다. 일 실시 예에 의하면, 객체 인식 모델은 카메라 영상들이 입력되 면 가스 객체, 연기 객체 또는 불꽃 객체 중 적어도 하나에 관한 표적 객체 또는 상기 표적 객체를 적어도 일부 에 포함하는 객체 후보 영역을 출력하도록 미리 학습되는 인공지능 모델일 수 있다. 일 실시 예에 의하면, 객체 인식 모델은 손실(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 수정 및 갱신되 는 신경망 모델일 수 있다. 예를 들어, 객체 인식 모델은 가스 객체, 불꽃 객체 또는 연기 객체에 대한 이미지 또는 영상 학습 데이터에 기 초하여 학습됨으로써, 영상 또는 이미지 내 가스 객체, 불꽃 객체 또는 연기 객체를 적어도 일부에 포함하는 객 체 후보 영역을 출력함과 함께, 객체 후보 영역 내 표적 객체에 대한 픽셀 정보, 객체 후보 영역의 이미지상에 서의 좌표 정보를 함께 출력하도록 마련될 수 있다. 예를 들어, 객체 인식 모델은 CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네 트워크 (Deep Q-Networks) 일 수 있으나, 이에 한정되는 것은 아니다. 또한, 객체 인식 모델은 EO 영상들 또는 OGI 영상들 내 픽셀 값에 기초하여, 소정의 객체 후보 영역이 표적 객체에 대응될 확률 값을 결정하고, 결 정된 확률 값에 기초하여 소정의 우선 순위에 따른 객체 후보 영역을 출력하도록 학습되는 YOLO, R-CNN, SSD 와 같은 객체 컴퓨터 비전 모델일 수 있다. S308에서, 가스 누출 탐지 시스템은 객체 인식 모델을 이용하여 EO 영상들 및 OGI 영상들로부터 표적 객체 가 검출되지 않는 것으로 식별되는 경우, OGI 영상을 주파수 변환함으로써 변환 영상 정보를 생성할 수 있다. 예를 들어, 가스 누출 탐지 시스템은 객체 인식 모델을 이용하여 표적 객체가 검출되지 않는 것으로 1차적 으로 식별되는 경우, 적외선 영상인 OGI 영상에 DFT 이산 푸리에 변환을 적용함으로써 주파수 도메인의 변환 영 상 정보를 생성할 수 있다. 일 실시 예에 의하면 변환 영상 정보는 주파수 별 크기 및 위상 정보를 포함하는 주파수 패턴을 포함할 수 있다. S310에서, 가스 누출 탐지 시스템은 변환 영상 정보가 입력되면 표적 객체에 따른 주파수 패턴이 존재하는 지 여부를 식별하는 우도비 검정 모델에 변환 영상 정보를 입력함으로써 표적 객체에 따른 주파수 패턴을 분석할 수 있다. S312에서, 가스 누출 탐지 시스템은 우도비 검정 모델을 변환 영상 정보에 적용함에 따라 우도비 검정 모델의 출력 값에 기초하여, 표적 객체에 따른 주파수 패턴이 식별되는지 여부를 결정할 수 있다. S314에서, 가스 누출 탐지 시스템은 우도비 검정 모델을 이옹한 결과 변환 영상 정보로부터 표적 객체에 따 른 주파수 패턴이 식별되지 않는 경우, SVM 모델(예컨대 서포트 벡터 머신 모델, Support Vector Machine)을 변환 영상 정보에 적용함으로써, 변환 영상 정보 내 표적 객체에 따른 주파수 패턴을 재 분석한다. S316에서, 가스 누출 탐지 시스템은 SVM 모델의 출력 값에 기초하여 변환 영상 정보 내 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별할 수 있다. S322에서, 가스 누출 탐지 시스템은 S306에서 객체 인식 모델에 EO 영상들 및 OGI 영상들을 입력한 결과 표 적 객체가 검출되는 것으로 결정되는 경우, 표적 객체가 검출된 EO 영상들 또는 표적 객체가 검출된 OGI 영상들 내 표적 객체를 배경과 분리할 수 있다. 예를 들어, 가스 누출 탐지 시스템은 검출된 표적 객체 정보에 기 초하여 마스킹 데이터를 생성하고, 생성된 마스킹 데이터를 EO 영상들 및 OGI 영상들에 적용함으로써 표적 객체 영역들을 분리할 수 있다. S324에서, 가스 누출 탐지 시스템은 분리된 표적 객체 영역으로부터 객체의 형상을 검출할 수 있다. 예를 들어, 가스 누출 탐지 시스템은 표적 객체 영역 내 외곽선 정보, 중심점 정보, 방향 벡터를 표적의 객체 형 상 정보로 출력할 수 있다. S326에서, 가스 누출 탐지 시스템은 표적 객체 영역들에 나타나는 형상 정보에 기초하여 표적 객체가 생성된 위치에 관한 누출 원점 및 상기 표적 객체의 흐름 방향과 속도에 관한 흐름 벡터 를 결정할 수 있다. S328에서, 가스 누출 탐지 시스템은 누출 원점 및 흐름 벡터에 기초하여 거리좌표 및 구면 좌표를 식별하고, 식별된 좌표에 따라 결정되는 위치 정보들을 변환할 수 있다. 구체적으로, 가스 누출 탐지 시스템 은 누출 원점 및 흐름 벡터에 기초하여 영상에서 표적 객체가 식별되는 것으로 결정된 위치에 레이저를 송 수신함으로써 레이저 측정 값을 획득하고, 획득된 레이저 측정값에 기초하여 카메라 설치셋으로부터 누출 원점 까지의 거리를 획득할 수 있다. 또한, 가스 누출 탐지 시스템은 해당 누출 원점을 모니터링하는 카메라 설 치셋의 팬틸트 정보를 획득할 수 있다. 본 개시에 따른 가스 누출 탐지 시스템은 카메라 설치셋으로부터 누출 원점까지의 거리 및 카메라 팬틸트 정보에 기초하여 구면 좌표계에서의 제1 좌표 값을 결정할 수 있다. 가스 누출 탐지 시스템은 결정된 구면 좌표계에서 제1 좌표 값을 직교 좌표계의 제2 좌표 값으로 변환하고, 직교 좌표계로 변환된 제2 좌표 값에 카메 라 왜곡 값을 반영함으로써 제3 좌표 값을 생성할 수 있다. 가스 누출 탐지 시스템은 제 3 좌표 값에 기초 하여, 표적 객체가 발생한 누출 영상의 파노라마 영상에 대한 기준 위치를 식별하고, 식별된 기준 위치에 따라 누출 영상을 파노라마 영상에 합성할 수 있다. S330에서, 가스 누출 탐지 시스템은 제3 좌표 값에 기초하여, 파노라마 영상에 누출 영상을 합성함으로써 합성 영상을 생성할 수 있다. S332에서, 가스 누출 탐지 시스템은 합성 영상을 저장하고, 저장된 합성 영상 을 가스 누출 탐지 시스템에 대한 사용자 입력에 기초하여 출력할 수 있다. 일 실시 예에 의하면 가스 누출 탐지 시스템은 저장된 합성 영상에 액세스하는 사용자 입력에 기초하여 저장된 합성 영상의 적어도 일부를 검색 및 검색된 합성 영상의 일부를 재생할 수 있다. 도 4는 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 표적 객체 검출 여부를 식별하는 방법의 흐름도이다. S410에서, 전자 장치는 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간 에 대한 제1 타입 영상들을 획득할 수 있다. 예를 들어, 제1 타입의 카메라는 EO 카메라를 포함하고, 제1 타입 영상들은 미리 설정된 프레임 간격을 가지는 가시광선 영상들일 수 있다. S420에서, 전자 장치는 전자 장 치와 연결된 적어도 하나의 제2 타입의 카메라로부터 모니터링 대상 공간에 대한 제2 타입 영상들을 획득할 수 있다. 예를 들어, 제2 타입의 카메라는 OGI 카메라이고, 제2 타입 영상들은 미리 설정된 프레임 간격의 복수의 적외선 이미지들을 포함하는 적외선 영상일 수 있다. 일 실시 예에 의하면, 전자 장치가 연결되는 제1 타입의 카메라 및 제2 타입의 카메라의 모니터링 대상 공간에 대한 화각, 이미지 획득 주기와 같은 촬영 파라미터 는 서로 다르게 마련될 수 있다. S430에서, 전자 장치는 제1 타입 영상들 및 상기 제2 타입 영상들이 입력되면, 제1 타입 영상들 및 상기 제2 타입 영상들 내 표적 객체가 검출되는지 여부를 식별하는 객체 인식 모델에 제1 타입 영상들 및 제2 타입 영상들을 입력함으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 표적 객체 검출 여부를 식별할 수 있다. 일 실시 예에 의하면, 객체 인식 모델은 가시 광선 영상들 및 적외선 영상들 각각으로부터 가스 객체, 연 기 객체 또는 불꽃 객체 중 적어도 하나에 관한 표적 객체를 적어도 일부에 포함하는 객체 후보 영역을 출력하 도록 미리 학습되는 인공지능 모델일 수 있다. 객체 인식 모델은 공지의 손실함수를 이용하여 손실(loss) 값 또 는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 수정 및 갱신되는 신경망 모델로 표적 객체를 포함하는 객체 후보 영역을 구성하는 픽셀의 이미지상 좌표 정보, 외곽선 정보, 객체 후보 영역의 바운더리를 나타내는 경계 정보, 인식된 표적 객체의 종류 정보를 출력할 수 있다. 일 실시 예에 의하면, 전자 장치의 영상 정보들에 대한 객체 인식 정확도는 70% 이상일 수 있으나, 이에 한정되는 것은 아니며, 후술하는 적어도 하나의 인공 지능 모델을 이용한 가스 누출의 인식 정확도는 99% 이상 일 수 있으나, 역시 이에 한정되는 것은 아니다. 또한, 도 4에는 도시되지 않았지만, 전자 장치는 적어도 하나의 인공 지능 모델을 통해 제1 타입 영상들 및 제2 타입 영상들에서 표적 객체가 검출되는지 여부를 식별하 고, 식별된 표적 객체를 미리 설정된 해상도 및 영상 속도로 추적 및 모니터링할 수 있다. 도 4에는 도시되지 않았지만, 일 실시 예에 따른 전자 장치는 제1 타입 영상들 및 제2 타입 영상들 중 적 어도 하나로부터 표적 객체가 검출되는 것으로 식별되는 경우, 표적 객체가 검출된 타입의 영상들로부터 표적 객체의 형상 정보를 추출할 수 있다. 전자 장치가 표적 객체의 형상 정보를 추출하는 구체적인 방법은 후 술하는 도 7 내지 도 9를 참조하여 구체적으로 설명하기로 한다. 도 5는 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 주파수 패턴에 따라 식별되는 표적 객체의 형상 정보를 추출하는 과정을 나타내는 도면이다. S510에서, 전자 장치는 객체 인식 모델의 출력 값에 기초하여, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체가 검출되지 않는 것으로 식별되는 경우, 제2 타입 영상들을 푸리에 변환함으로써 주 파수 도메인상의 변환 영상 정보를 생성할 수 있다. 예를 들어, 전자 장치는 객체 인식 모델을 이용하여 1차적으로 제1 타입 영상들 및 제2 타입 영상들로부터 표적 객체가 검출되지 않는 것으로 식별되는 경우, 적외 선 영상들인 제2 타입 영상들을 이산 푸리에 변환(discrete Fourier transform, DFT)함으로써 주파수 도메인 상의 변환 영상 정보를 생성할 수 있다. 도 5에는 도시되지 않았지만, 또 다른 실시 예에 의하면, 전자 장치 는 제2 타입 영상들을 전처리하고 전처리된 제2 타입 영상들을 푸리에 변환함으로써 주파수 도메인상의 변환 영상 정보들을 생성할 수도 있다. S520에서, 전자 장치는 변환 영상 정보로부터 표적 객체 및 표적 객체 주변의 배경 간섭 물질 각각에 대 한 스펙트럼 정보를 추출할 수 있다. 예를 들어, 변환 영상 정보는 주파수 도메인상에서 특정 파장 영역대에 기 초하여 표적 객체를 나타내는 스펙트럼 정보를 포함할 수 있다. 일 실시 예에 의하면, 스펙트럼 정보는 주파수 별 크기(Magnitude) 및 위상(Phase) 정보를 포함할 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 변 환 영상 정보 내 표적 객체와 표적 객체 주변의 배경 간섭물질 각각에 대한 스펙트럼 정보를 추출할 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 표적 객체 및 배경 간섭물질을 구분하지 않고, 변환 영상 정보로 부터 주파수 별 크기 및 위상에 대한 스펙트럼 정보를 추출할 수 있다. S530에서, 전자 장치는 추출된 스펙트럼 정보가 입력되면 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 출력하는 우도비 검정 모델에, 상기 추출된 스펙트럼 정보를 입력함으로써, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별할 수 있다. 예를 들어, 전자 장치는 표적 객체의 주파수 패턴을 분류하는 우도비 검정 모델을 미리 학습시키고, 학습된 우도비 검정 모델을 소정의 조건 에서 변환 영상 정보에 적용함으로써 객체 인식 모델과 함께 표적 객체를 효과적으로 검출할 수 있다. 본 개시에 따른 전자 장치는 객체 인식 모델로부터 표적 객체가 검출되는 것으로 식별되지 않는 경우, 적 외선 영상으로부터 나타나는 스펙트럼 정보의 주파수 패턴을 우도비 검정 모델을 이용하여 제1 타입 영상들 및 제2 타입 영상들 내 표적 객체가 검출되는지 여부를 재 식별함으로써 표적 객체 검출 정확도를 향상시킬 수 있 다. 도 5에는 도시되지 않았지만, 전자 장치는 우도비 검정 모델을 이용하여 재 식별 결과 표적 객체가검출되는 것으로 식별되는 경우 우도비 검정 모델의 출력 값에 따라 표적 객체가 검출된 영상들에서 표적 객체 영역을 분리하기 위한 마스킹 데이터 생성과정을 수행하게 된다. S540에서, 전자 장치는 표적 객체에 따른 주파수 패턴이 식별되는 경우, 우도비 검정 모델의 출력 값에 기초하여 제2 타입 영상들로부터 표적 객체의 형상 정보를 추출할 수 있다. 예를 들어, 전자 장치는 우도 비 검정 모델의 출력 값에 기초하여 표적 객체에 따른 주파수 패턴이 변환 영상 정보 내에서 식별되는 경우, 표 적 객체가 검출된 것으로 결정하고, 제2 타입 영상들로부터 표적 객체의 형상에 관한 형상 정보를 추출하게 된 다. 전자 장치가 형상 정보를 추출하는 방법은 후술하는 도 7 내지 9를 참조하여 설명하기로 한다. 도 6은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 주파수 패턴에 따라 식별되는 표적 객체의 형상 정보를 추출하는 과정을 나타내는 도면이다. S610에서, 전자 장치는 우도비 검정 모델의 출력 값에 기초하여 상기 표적 객체에 따른 주파수 패턴이 식 별되지 않는 경우, 상기 추출된 스펙트럼 정보를, 상기 추출된 스펙트럼 정보가 입력되면 상기 표적 객체에 따 른 주파수 패턴이 있는지 여부를 출력하는 서포트 벡터 머신 모델에 입력함으로써, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별할 수 있다. 즉, 본 개시에 따른 전자 장치는 객체 인식 모델을 이용한 결과 제1 타입 영상들 및 제2 타입 영상들에서 표적 객체가 검출되지 않는 경우, 우도비 검정 모델 및 서포트 벡터 머신 모델을 이용하여 표적 객체가 검출되 는지 여부를 재식별함으로써 표적 객체의 검출 정확도를 향상시킬 수 있다. 전자 장치는 서포트 벡터 머 신 모델을 이용한 결과 표적 객체에 따른 주파수 패턴이 식별되는 것으로 결정되는 경우, 서포트 벡터 머신 모 델의 출력 값에 따라 표적 객체가 검출된 영상들에서 표적 객체 영역을 분리하기 위한 마스킹 데이터 생성과정 을 수행하게 된다. 본 개시에 따른 전자 장치는 변환 영상 정보로부터 추출된 스펙트럼 정보가 입력되면, 표적 객체의 주파 수 패턴을 분류하는 서포트 벡터 머신 모델을 미리 학습시키고, 학습된 서포트 벡터 머신 모델을 소정의 조건에 서 변환 영상 정보에 적용함으로써, 객체 인식 모델 및 우도비 검정 모델과 함께 표적 객체를 정확하게 검출할 수 있다. S620에서, 전자 장치는 표적 객체에 따른 주파수 패턴이 식별되는 경우, 상기 서포트 벡터 머신 모델의 출력 값에 기초하여, 상기 제2 타입 영상들로부터 상기 표적 객체의 형상 정보를 추출할 수 있다. 전자 장치 가 형상 정보를 추출하는 방법은 후술하는 도 7 내지 9를 참조하여 구체적으로 설명하기로 한다. 상술한 도 4 내지 도 6에서 상술한 바와 같이, 전자 장치는 객체 인식 모델, 우도비 검정 모델 또는 서포트 벡터 머신 모델 중 적어도 하나를 이용하여 적어도 하나의 타입의 영상들을 분석함으로써 표적 객체가 검출되는지 여 부를 정확하게 식별할 수 있을 뿐만 아니라, 적외선 영상을 주파수 도메인 상의 변환 영상 정보로 생성하고, 변 환 영상 정보에서 나타나는 소정의 주파수 별 주파수 패턴에 기초하여, 검출된 표적 객체의 종류(예컨대 메탄인 지, 암모니아인지, 일반 연기인지, 불꽃 인지)를 함께 식별할 수 있다. 도 7은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 표적 객체의 형상 정보를 추출하는 구체적인 방법의 흐름도이다. S710에서, 전자 장치는 표적 객체가 검출된 타입의 영상들을 전처리할 수 있다. 예를 들어, 전자 장치 는 도 3 내지 6에서 상술한 바와 같이, 객체 인식 모델과 변환 영상 정보에 대한 우도비 검정 모델 또는 서포트 벡터 머신 모델을 미리 설정된 조건에 따라 이용함으로써 제1 타입 영상들 및 제2 타입 영상들 중 적어 도 하나로부터 표적 객체가 검출되는지 여부를 식별하고, 표적 객체가 검출되는 것으로 식별되는 경우, 표적 객 체가 검출되는 타입의 영상들을 전처리(예컨대 이진화, 노멀라이즈, Augmentation 등)한다. S720에서, 전자 장치는 기 설정된 표적 객체 정보에 기초하여 마스킹 데이터를 생성할 수 있다. 예를 들 어, 전자 장치는 표적 객체에 대한 정보를 미리 저장할 수 있다. 일 실시 예에 의하면, 표적 객체에 대한 정보는 가스 객체, 연기 객체 또는 불꽃 객체들이 영상들 내 프레임 이미지들 사이에서 이동하는 정도에 관한 이동 평균 값들을 미리 저장할 수 있으며, 표적 객체에 대한 정보에 기초하여 마스킹 데이터를 생성할 수 있다. 구체적으로 도 7에는 도시되지 않았지만, 전자 장치는 표적 객체가 검출된 타입의 영상들의 현재 프레임 이미지 이전의 프레임 이미지들에 대한 이동 평균 값을 결정하고, 결정된 이동 평균 값에 기초하여 마스킹 데이터를 생성할 수 있다. 예를 들어, 전자 장치는 표적 객체가 검출된 타입의 영상들의 현재 프레임 이전의 프레임 이미지들 세트에 대해 이동 평균값을 결정하고, 결정된 이동 평균값에 기초하여 배경 모델을 생성하며, 생성된 배경 모델을 현재 프레임 이미지에서 제거(예컨대 빼기)하기 위한 마스킹 데이터를 생성한다. 본 개시의 일 실시 예에 따른 전자 장치는 Running average background subtraction 기법을 이용하여 마스킹 데이 터를 생성할 수 있다. S730에서, 전자 장치는 표적 객체가 검출된 타입의 영상들에 마스킹 데이터를 적용함으로써 생성되는 표 적 객체 영역들을, 전처리된 영상들로부터 분리할 수 있다. 전자 장치는 새로운 프레임 이미지들이 획득 될 때마다 모든 프레임 이미지들의 이동 평균값을 지속적으로 수정 및 갱신하며, 수정 및 갱신된 이동 평균값에 기초하여 생성된 마스킹 데이터를 현재 프레임 이미지에 적용함으로써 표적 객체 영역들을 전처리된 영상들로부 터 분리할 수 있다. S740에서, 전자 장치는 분리된 표적 객체 영역들로부터 표적 객체의 형상 정보를 추 출한다. 전자 장치가 형상 정보를 추출하는 과정은 후술하는 도 8 내지 도 9를 더 참조하여 추가 설명하 기로 한다. 도 8은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 표적 객체의 형상을 식별하고 이를 추적하는 과정을 설명하기 위한 도면이다. 도 8을 참조하여 전자 장치가 형상 정보를 추출하는 방법을 더 구체적으로 설명하기로 한다. 그림 을 참조하면, 전자 장치가 도 7에서 상술한 방법에 따라 표적 객체가 검출된 타입의 영상들을 구성하는 전체 프레임 이미지들 또는 현재 프레임 이미지들 이전의 모든 프레임 이미지들로부터 이동 평균 값을 결 정하고, 결정된 이동 평균 값에 기초하여 결정된 마스킹 데이터를 현재 프레임 이미지에 적용함으로 써 현재 프레임 이미지로부터 표적 객체 영역을 분리하는 과정이 도시된다. 전자 장치는 분리된 표적 객체 영역 내 표적 객체에 관한 외곽선 정보를 식별하고, 외곽선 정보에 기초하 여 상기 표적 객체의 중심점 정보를 식별할 수 있으며, 식별된 중심점 정보 및 상기 외곽선 정보에 기초하여 표 적 객체 영역의 방향 벡터를 식별할 수 있다. 본 개시에 따른 전자 장치는 표적 객체가 검출된 타입의 영 상을 구성하는 프레임 이미지마다 상기 외곽선 정보, 중심점 정보 및 방향 벡터를 상기 표적 객체의 형상 정보 로 추출할 수 있다. 본 개시에 따른 전자 장치는 표적 객체가 검출된 타입의 영상들 내 인접하는 프레임 이미지들에서 분리된 표적 객체의 형상 정보에 기초하여 모션 벡터를 결정할 수 있다. 전자 장치는 그림 에 도시된 바와 같이, 표적 객체가 검출된 타입 내 영상들로부터 결정되는 모션 벡터를 이용하여, 표적 객체가 검출된 타입의 영상들 내 표적 객체 영역들을 모델링할 수 있다. 전자 장치는 그림 에 도시된 바와 같이, 표 적 객체를 모델링하는데 사용된 모션 벡터들의 합벡터를 식별할 수 있고, 상기 합벡터의 크기 및 방향에 기초하 여 표적 객체가 생성된 위치에 관한 누출 원점 및 표적 객체의 흐름 방향과 속도에 관한 흐름 벡터를 결정할 수 있다. 도 9는 또 다른 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 표적 객체의 형상 정보를 추 출하는 방법의 흐름도이다. S910에서, 전자 장치는 분리된 표적 객체 영역 내 표적 객체에 관한 외곽선 정보를 식별할 수 있다. 예를 들어, 전자 장치는 마스킹 데이터를 적용함에 따라 분리된 표적 객체 영역을 구성하는 픽셀들의 좌표를 식별할 수 있고, 식별된 픽셀들의 좌표 값에 기초하여 최외곽 픽셀들의 좌표세트를 결정할 수 있다. 전자 장치 는 최외곽 픽셀들의 좌표세트에 기초하여 표적 객체에 관한 외곽선 정보를 식별할 수 있다. S920에서, 전자 장치는 외곽선 정보에 기초하여 표적 객체의 중심점 정보를 식별할 수 있다. 예를 들어, 전자 장치는 외곽선 정보에 기초하여 결정되는 표적 객체의 경계 내부의 픽셀 값들에 Mean Shift 알고리 즘을 적용하거나, 기타 이동하는 표적 객체의 중심점을 찾기 위한 객체 추적 알고리즘을 적용함으로써 표적 객 체의 중심점 정보를 식별할 수 있다. S930에서, 전자 장치는 중심점 정보 및 외곽선 정보에 기초하여 표 적 객체 영역의 방향 벡터를 식별할 수 있다. 예를 들어, 전자 장치는 표적 객체가 검출된 타입의 영상들 내 각 프레임 이미지마다 표적 객체 영역을 분리하고, 분리된 표적 객체 영역으로부터 추출된 형상 정보들 중, 인접한 프레임 이미지들(예컨대 연속한 2개의 프레임 번호를 가지는 이미지들)에서 추출된 형상 정보들에 기초하여 모션 벡터를 결정할 수 있다. 전자 장치는 표적 객체가 검출된 타입 내 영상들 중, 인접한 프레임 번호를 가지는 프레임 이미지들 사이 에서 결정되는 모션 벡터를 이용하여 표적 객체를 모델링할 수 있으며, 표적 객체를 모델링하는데 사용된 모션 벡터의 합벡터의 방향과 동일한 방향의 방향 벡터를 식별할 수 있다. S940에서, 전자 장치는 상술한 과정 에서 결정된 외곽선 정보, 중심점 정보 및 방향 벡터를 표적 객체의 형상 정보로 추출할 수 있다. 도 10은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 표적 객체의 누출 원점 및 흐름 벡터를 결정하는 구체적인 방법의 흐름도이다. S1010에서, 전자 장치는 분리된 표적 객체 영역들의 형상 정보에 기초하여, 표적 객체가 검출된 타입의 영상들 내 인접하는 표적 객체 영역들 사이의 모션 벡터를 결정할 수 있다. 예를 들어, 도 9에서 상술한 바와 같이, 전자 장치는 표적 객체가 검출된 타입의 영상들 내 인접하는 프레임 이미지들(예컨대 연속하는 프 레임 번호를 가지는 2개의 프레임 이미지들) 사이에서 각 이미지들의 분리된 표적 객체의 형상 정보에 기초하여 모션 벡터를 결정할 수 있다. S1020에서, 전자 장치는 모션 벡터에 기초하여 분리된 표적 객체 영역들을 모델링할 수 있다. S1030에서, 전자 장치는 모델링된 표적 객체 영역들을 나타내는 모션 벡터들의 합벡터를 결정할 수 있다. 예를 들어, 전자 장치는 영상들로부터 상기 표적 객체에 관하여 나타나는 모션 벡터들에 대해 기하학적 벡터합을 수 행함으로써 합벡터를 결정할 수 있다. S1040에서, 전자 장치는 상기 결정된 합벡터의 크기 및 방향에 기초하여, 표적 객체가 검출된 영상들에서, 표적 객체가 생성된 위치에 관한 누출 원점 및 상기 표적 객체의 흐름 방향과 속도에 관한 흐름 벡 터를 결정할 수 있다. 예를 들어, 전자 장치는 상기 합벡터의 시작점을 누출원점으로 결정하고, 상기 시 작점으로부터 종점까지 상기 합벡터가 나타내는 방향을 흐름 벡터의 방향으로 결정할 수 있다. 또한, 전자 장치 는 시작점으로부터 종점까지의 거리를 표적 객체의 속도의 크기를 흐름 벡터의 크기로 결정할 수 있다. 전자 장치는 상술한 방법으로 결정된 크기 및 방향을 가지는 흐름 벡터를 결정할 수 있다. 도 11은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 가스 누출의 탐지를 위한 합성 영 상을 생성하는 방법의 흐름도이다. S1110에서, 전자 장치는 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간 에 대한 제1 타입 영상들 및 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간에 대한 제2 타입의 영상들을 획득할 수 있다. 일 실시 예에 의하면, 상기 제1 타입의 카메라 및 상기 제2 타입의 카메라는 각각 EO(Electro-Optical) 카메라 및 OGI(Optical Gas Imaging) 카메라를 포함하고, 상기 제1 타입 영상들 및 상기 제2 타입 영상들은 각각 가시광선 영상들 및 적외선 영상들을 포함할 수 있다. S1110 은 도 4의 S410 내지 S420에 대응될 수 있으므로 구체적인 설명은 생략하기로 한다. S1120에서, 전자 장치는 제1 타입 영상들 또는 상기 제2 타입 영상들 중 적어도 하나로부터 표적 객체가 검출되는 것으로 식별되는 경우, 상기 검출된 표적 객체에 관한 제1 타입 영상들 및 상기 검출된 표적 객체에 관한 상기 제1 타입 영상들에 대응되는 제2 타입 영상들을 합성함으로써 누출 영상을 생성할 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 제1 타입 영상들 또는 상기 제2 타입 영상들 중 표적 객체가 검출된 하나 의 타입의 영상들을 누출 영상으로 생성할 수도 있다. S1130에서, 전자 장치는 누출 영상의 미리 획득된 파노라마 영상에 대한 좌표에 기초하여 누출 영상을 파 노라마 영상에 합성함으로써 합성 영상을 생성할 수 있다. 예를 들어, 전자 장치는 모델링된 표적 객체의 모션 벡터들의 합벡터에 기초하여 누출원점을 결정하고, 결정된 누출 원점에 대한 레이저 측정값 및 카메라 설 치셋의 팬틸트 정보에 기초하여 상기 누출 원점의 파노라마 영상에 대한 좌표를 결정할 수 있다. 전자 장치 는 상기 좌표 값에 기초하여 누출 영상을 파노라마 영상에 합성함으로써 합성 영상을 생성할 수 있다. 도 12는 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 생성한 누출 영상 및 상기 누출 영상을 파노라마 영상에 합성하는 과정을 설명하기 위한 도면이다.전자 장치는 모니터링 대상 공간을 촬영함으로써 적어도 하나의 EO 카메라 및 적어도 하나의 OGI 카메라 와 연결될 수 있다. 전자 장치는 그림 에 도시된 바와 같이, 획득된 제1 타입 영상들 및 제2 타입 영상들을 합성함으로써 누출 영상을 생성할 수 있다. 예를 들어, 누출 영상은 모니터링 대상 공간에 대한 영상으로 검출된 표적 객체(예컨대 가스 객체, 연기 객체 또는 불꽃 객체) 영역 및 배경 영역을 포함 할 수 있다. 전자 장치는 그림 에 도시된 바와 같이, 누출 영상의 파노라마 영상에 대한 좌표를 결정하고, 결정된 좌표 값에 기초하여 누출 영상을 파노라마 영상에 합성함으로써 합성 영상을 생성할 수 있다. 전자 장치는 생성된 합성 영상을 직접 출력하거나, 전자 장치와 연결된 관제 단말 또는 관제 서버 로 전송함으로써 모니터링 대상 공간을 관리하는 관제자가 표적 객체 검출 용이하게 인식하도록 할 수 있다. 도 13은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 누출 영상을 생성하는 방법의 흐 름도이다. S1310에서, 전자 장치는 검출된 표적 객체에 관한 제1 타입 영상들 및 제1 타입 영상들에 대응되는 제2 타입 영상들을 식별할 수 있다. 그러나 또 다른 실시 예에 의하면, 전자 장치는 제1 타입 영상들 및 제2 타입 영상들 중, 표적 객체가 검출된 하나의 타입의 영상들을 누출 영상으로 생성할 수도 있다. 예를 들어, 전 자 장치는 객체 인식 모델, 우도비 검정 모델 또는 서포트 벡터 머신 모델 중 적어도 하나를 소정의 조건 에 따라 이용함으로써 표적 객체를 검출하고, 표적 객체가 검출된 영상의 타입을 결정할 수 있다. 또한, 전자 장치는 표적 객체가 검출된 영상의 타입에 대응되는 동일한 물리적 공간을 촬영함으로써 획득되는 다른 타입의 영상들을 식별할 수 있다. S1320에서, 전자 장치는 제1 타입 영상들 및 상기 제1 타입 영상들에 대응되는 제2 타입 영상들을 기하학 적으로 매칭할 수 있다. 일 실시 예에 의하면, 전자 장치는 제1 타입 영상들(예컨대 일반 카메라 영상들) 및 상기 제1 타입 영상들에 대응되는 제2 타입 영상들(OGI 영상들)을 호모그래피 매칭 기법 또는 H matrix correspondence method 기법 중 적어도 하나에 기초하여 기하학적으로 매칭할 수 있다. 그러나 또 다른 실시예 에 따르면 전자 장치는 일반 템플릿 매칭 방식을 이용하여 제1 타입 영상들 및 제2 타입 영상들을 기하학 적으로 매칭할 수도 있다. S1330에서, 전자 장치는 기하학적으로 매칭된 제1 타입 영상들 및 상기 제1 타입 영상들에 대응되는 제2 타입 영상들의 매칭 에러를 보정함으로써 누출 영상을 생성할 수 있다. 예를 들어, 전자 장치는 두 대응 되는 타입의 영상들 사이에 투시 변환(Perspective transform)을 수행하기 위한 투시 변환 행렬을 이용하여 제1 타입 영상들 및 제2 타입 영상들을 기하학적으로 매칭한 후, 호모그래피 함수를 이용한 호모그래피 매칭 과정에 서 잘못 매칭된 매칭 에러를 결정할 수 있다. 전자 장치는 후술하는 도 14에서와 같이, 각 타입의 영상들 에서 특징점들을 추출한 후, 추출된 특징점들을 기준으로 매칭 에러를 보정함으로써 누출 영상을 생성할 수 있 다. 도 14는 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 누출 영상을 생성하는 구체적인 방법의 흐름도이다. S1410에서, 전자 장치는 객체 인식 모델, 우도비 검정 모델 또는 서포트 벡터 머신 모델 중 적어도 하나 에 기초하여 표적 객체가 검출되는 경우, 검출된 표적 객체에 관한 제1 타입 영상들 및 제2 타입 영상들로부터 특징점을 추출할 수 있다. 일 실시 예에 의하면, 전자 장치는 SIFT, SURF 또는 ORB 와 같은 특징점 추출 기법을 이용하여 검출된 표적 객체에 관한 제1 타입 영상들 및 제2 타입 영상들 각각으로부터 특징점을 추출할 수 있다. S1420에서, 전자 장치는 제1 타입 영상들에서 추출된 특징점들에 매칭되는 제2 타입 영상들의 특징점을 식별할 수 있다. 일 실시 예에 의하면, 전자 장치는 Brute Force 매칭 기법, 평슌 해시 매칭, 템플릿 매 칭 기법과 같은 다양한 특징점 매칭 기법에 기초하여 제1 타입 영상들에서 추출된 특징점들에 매칭되는 제2 타 입 영상들의 특징점들을 식별할 수 있다. S1430에서, 전자 장치는 제1 타입 영상들에서 추출된 특징점들 및 상기 제2 타입 영상들에서 추출된 특징점들 사이의 평균 변위 값에 기초하여, 제1 타입 영상들 및 상기 제1 타입 영상들에 대응되는 제2 타입 영상들의 매칭 위치를 변경함으로써 매칭 에러를 보정할 수 있다. 예를 들어, 전자 장치는 제1 타입 영상들에서 추출된 특징점들의 좌표 값과 이에 매칭되는 제2 타입 영상 들에서 추출된 특징점들의 좌표 값의 차이에 기초하여 변위값을 결정할 수 있고, 각 타입의 영상들에서 추출된 특징점들의 평균 변위 값을 식별할 수 있다. 전자 장치는 평균 변위 값에 기초하여, 기하학적으로 매칭된 제1 타입의 영상들 및 제2 타입의 영상들의 매칭 위치를 변경함으로써 매칭 에러를 보정한다. S1440에서, 전자 장치는 변경된 매칭 위치에 따라 기하학적으로 매칭된 상태의 제1 타입 영상들 및 제2 타입 영상들을 누 출 영상으로 생성할 수 있다. 도 15는 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 합성 영상을 생성하는 방법의 흐 름도이다. S1510에서, 전자 장치는 상기 제1 타입 영상들 또는 상기 제2 타입 영상들 중 적어도 하나로부터 표적 객 체가 검출되는 것으로 식별되는 경우, 상기 표적 객체가 검출된 타입의 영상들로부터 상기 표적 객체의 형상 정 보를 추출할 수 있다. 전자 장치가 표적 객체의 형상 정보를 추출하는 과정은 도 7 내지 도 9에서 상술한 과정에 대응될 수 있다. S1520에서, 전자 장치는 형상 정보에 기초하여 생성된 누출 영상의 미리 획득된 파노라마 영상에 대한 좌 표를 결정할 수 있다. 예를 들어, 전자 장치는 모니터링 대상 공간에 대한 파노라마 영상을 미리 저장할 수 있다. 일 실시 예에 의하면, 전자 장치는 적어도 하나의 EO 카메라로부터 획득되는 가시광선 영상들을 이용하여 하나의 파노라마 영상으로 변환하고, 변환된 파노라마 영상을 미리 저장할 수 있다. 전자 장치는 표적 객체가 검출된 타입의 영상들 내 인접하는 프레임 이미지들에서 추출된 형상 정보에 기 초하여 모션 벡터를 결정하며, 결정된 모션 벡터에 기초하여 합벡터를 결정하고, 합벡터의 크기 및 방향에 기초 하여 누출 원점 및 흐름 벡터를 결정하며, 결정된 누출 원점 및 흐름 벡터에 기초하여 누출 영상의 파노라마 영 상에 대한 좌표를 결정한다. S1530에서, 전자 장치는 상기 결정된 좌표에 기초하여 누출 영상을 파노라마 영상에 합성함으로써 합성 영상을 생성할 수 있다. 일 실시 예에 의하면, 전자 장치는 누출 영상을 파노 라마 영상에 중첩하여 표시함과 함께, 표적 객체의 종류, 표적 객체가 발생한 누출 원점에 대한 위치 정보를 더 중첩하여 표시할 수도 있다. 도 16은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 파노라마 영상에 대한 누출 영상 의 좌표를 결정하는 방법의 흐름도이다. S1610에서, 전자 장치는 분리된 표적 객체 영역들의 형상 정보에 기초하여, 표적 객체가 생성된 위치에 관한 누출 원점 및 표적 객체의 흐름 방향과 속도에 관한 흐름 벡터를 결정할 수 있다. 예를 들어, 전자 장치 는 표적 객체가 검출된 타입의 영상들 내 인접하는 프레임 이미지들에서 추출된 형상 정보에 기초하여 모 션 벡터를 결정하며, 모션 벡터들에 기초하여 표적 객체를 모델링하고, 상기 표적 객체를 모델링하는데 사용된 모션 벡터들의 합벡터의 크기 및 방향에 기초하여 누출 원점 및 상기 흐름 벡터를 결정할 수 있다. S1620에서, 전자 장치는 누출 원점 및 흐름 벡터에 기초하여 누출 영상의 파노라마 영상에 대한 좌표를 결정할 수 있다. 일 실시 예에 의하면, 전자 장치는 상기 합벡터의 시작점을 누출원점으로 결정하고, 상 기 시작점으로부터 종점까지 상기 합벡터가 나타내는 방향을 흐름 벡터의 방향으로 결정할 수 있다. 또한, 전자 장치는 시작점으로부터 종점까지의 거리를 표적 객체의 속도의 크기를 흐름 벡터의 크기로 결정할 수 있 다. 일 실시 예에 의하면, 전자 장치는 상기 합벡터에 따라 결정되는 누출 원점 및 흐름 벡터가 나타내는 방 향에 기초하여, 레이저 측정기로부터, 상기 누출 원점에 대응되는 물리적 공간으로부터 반사되는 레이저 측정값 을 획득하고, 획득된 레이저 측정값에 기초하여 물리적 공간 까지의 거리를 식별할 수 있다. 또한, 전자 장치 는 상기 누출 원점에 대한 카메라 설치셋의 팬틸트 정보를 획득할 수 있다. 전자 장치는 누출 원점, 흐름 벡터, 표적 객체가 발생한 물리적 공간 까지의 거리 및 팬틸트 정보에 기초하여 구면 좌표계에서의 제1 좌표 값을 결정할 수 있다. 전자 장치는 제1 좌표 값을 직교 좌표계의 제2 좌표 값으로 변환하고, 표 적 객체가 검출된 영상들을 전송한 타입의 카메라에 대해 미리 설정되는 렌즈 왜곡 값을 제2 좌표 값에 반영함 으로써 제3 좌표 값을 획득할 수 있다. 전자 장치는 상술한 방법에 따라 결정된 제3 좌표 값을 누출 영상 의 파노라마 영상에 대한 좌표로 결정할 수 있다.도 17은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 레이저 측정 값 및 카메라의 팬틸 트 정보에 기초하여 누출 원점에 대한 좌표 변환하는 과정을 나타내는 도면이다. S1710에서, 전자 장치는 누출 원점 및 흐름 벡터를 획득할 수 있다. S1710에서, 전자 장치가 표적 객체를 모델링하는데 사용된 모션 벡터에 기초하여 누출 원점 및 흐름 벡터를 결정하는 과정은 도 16에서 상술 한 과정에 대응될 수 있으므로 생략하기로 한다. S1720에서, 전자 장치는 누출 원점 및 흐름 벡터의 방향 에 따른 제어 신호를 레이저 거리 측정기로 송신할 수 있다. S1730에서, 전자 장치는 레이저 측정기로부 터 상기 누출 원점에 대응되는 물리적 공간의 한 지점으로부터 반사되는 레이저 측정값을 획득할 수 있다. S1740에서, 전자 장치는 상기 누출 원점에 대한 카메라 설치셋의 카메라 팬틸트 정보를 획득할 수 있다. S1750에서, 전자 장치는 상기 누출 원점, 흐름 벡터, 표적 객체가 발생한 물리적 공간까지의 거리 및 팬 틸트 정보에 기초하여 구면 좌표계에서의 제1 좌표 값을 결정할 수 있다. S1760에서, 전자 장치는 상기 결정된 제1 좌표 값을 직교 좌표계에서의 제2 좌표 값으로 변환할 수 있다. S1770에서, 전자 장치는 제1 타입의 카메라 또는 제2 타입의 카메라 중 표적 객체가 검출된 영상들을 전송한 타입의 카메라에 대해 미리 설 정되는 렌즈 왜곡 값을 제2 좌표 값에 반영함으로써 제2 좌표 값을 제3 좌표 값으로 변경할 수 있다. 전자 장치 는 상기 결정된 제3 좌표 값에 기초하여 누출 영상을 파노라마 영상에 합성함으로써 합성 영상을 생성할 수 있다. 도 18은 또 다른 실시 예에 따른 인공지능 기반 가스 누출 탐지 시스템의 동작 과정을 나타내는 도면이다. 도 18을 참조하면, 가스 누출 탐지 시스템이 상술한 도 11 내지 16에 기재된 방법에 따라 전자 장치가 생성 한 합성 영상을 이용하는 과정이 도시된다. 그러나 또 다른 실시 예에 의하면, 도 18에 기재된 각 동작들은 가 스 누출 탐지 시스템뿐만 아니라, 전자 장치에 의해서도 수행될 수 있음은 물론이다. 예를 들어, 전 자 장치는 S330에서 도 11 내지 16에 상술한 방법에 따라 누출 영상을 파노라마 영상에 합성함으로써 합 성 영상을 생성할 수 있다. S332에서, 전자 장치는 합성 영상을 저장 및 전송할 수 있다. 일 실시 예에 의하면, 전자 장치는 제한된 데이터 내에서 효율적 설계를 위해 RDBMS (Relative Database Management System)구조에 따라 영 상 데이터들을 관리할 수 있다. 일 실시 예에 의하면, 전자 장치는 저장된 영상 데이터를 검색하기 위한 전자 장치에 대한 사용자 입력에 기초하여, 소정의 영상들을 출력할 수도 있다. 일 실시 예에 의하면, 전 자 장치는 DB SELECT를 이용하여 키워드 일부 및 단어 조합에 기초하여 소정의 저장된 영상 데이터를 출 력할 수 있다. 또한, 일 실시 예에 의하면, 전자 장치는 RDBMS의 효율적 탐색을 위해 SQL을 기반으로 시 스템을 구성하고, 고성능화와 사용자 경험 최적화를 위해 다중 조건 내에서 조건을 제한 문자열을 배열하는 구 조를 SELECT문으로 기본 설계할 수 있다. S334에서, 전자 장치는 객체 인식 모델, 우도비 검정 모델 또는 서포트 벡터 머신 모델 중 적어도 하나를 이용함으로써 표적 객체가 검출되는 것으로 식별되는 경우, 검출된 표적 객체의 형상 정보에 기초하여 누출 원 점 및 표적 객체의 종류를 결정하고, 누출 원점 및 표적 객체의 종류에 대한 정보를 포함 경보 및 알림 컨텐츠 를 생성할 수 있다. 또한, 전자 장치는 경보 장치들을 동작시키기 위한 소정의 제어 신호를 함께 생성할 수 있다. S336에서, 전자 장치는 경보 장치를 제어하기 위한 제어 신호를 경보 장치로 전송함으로써 경광등의 동작 을 제어함으로써 발광을 시키거나, 스피커 장치를 제어함으로써 소정의 음향 신호가 출력되도록 할 수 있다. 일 실시 예에 의하면, 전자 장치는 작업 현장에 설치된 관제 단말을 통하여 소정의 경보 장치를 제어할 수도 있음은 물론이다. S338에서, 전자 장치는 S334에서 생성된 컨텐츠를 출력할 수 있다. 예를 들어, 전자 장치는 S334에 서 생성된 컨텐츠를 전자 장치의 디스플레이 상에 출력할 수도 있지만, 전자 장치와 연결된 관제 단말의 디스플레이 또는 관제 서버를 통하여 연결되는 상황실 시스템의 디스플레이 장치로 컨텐츠를 전송할 수도 있다. 일 실시 예에 의하면, 전자 장치가 전송하는 컨텐츠들은 RDBMS에 실시간으로 저장될 수 있으며, 전 자 장치, 관제 단말, 또는 상황실 시스템에 대한 관제자의 사용자 입력에 기초하여 호출됨으로써, 소정의 디스플레이 상에 출력될 수도 있다. S340에서, 전자 장치는 카메라 설치셋, 레이저 거리 측정기, EO 및 OGI 카메라를 제어하 기 위한 제어 신호를 생성할 수 있다. 일 실시 예에 의하면, 전자 장치는 전자 장치, 관제 단말 또는 상 황실 시스템에 대한 관제자의 사용자 입력에 기초하여 카메라 설치셋, 레이저 거리 측정기, EO 및 OGI 카메라를 제어하기 위한 제어 신호를 생성하고, 모니터링 대상 공간 내 특정 지점을 구체적으로 모니 터링되도록 할 수 있다. 도 19는 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 인공지능 모델을 이용하여 가스 누출을 탐지하는 방법의 흐름도이다. S1910에서, 전자 장치는 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간 에 대한 제1 타입 학습 영상들, 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터 링 대상 공간에 대한 제2 타입 학습 영상들을 획득할 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 전자 장치와 연결된 외부 디바이스로부터 표적 객체를 포함하는 가시광선 영상들 및 적외선 영상들을 제1 타입 학습 영상들 및 제2 타입 학습 영상들로 획득할 수 있다. 일 실시 예에 의하면, 제1 타입 학습 영상들은 및 제2 타입 학습 영상들은 가시광선 영상들 및 적외선 영상들일 수 있다. S1920에서, 전자 장치는 제1 타입 학습 영상들 및 상기 제2 타입 학습 영상들에 기초하여 학습 데이터 및 검증 데이터를 생성할 수 있다. 예를 들어, 전자 장치는 상기 제1 타입 학습 영상들 중 미리 설정된 비율 에 따라 학습 데이터 및 검증 데이터를 생성할 수 있다. 또한, 전자 장치는 제2 타입 학습 영상들 중 미 리 설정된 비율에 따라 학습 데이터 및 검증 데이터를 생성할 수 있다. S1930에서, 전자 장치는 생성된 학습 데이터에 기초하여, 상기 제1 타입의 카메라로부터 획득되는 제1 타 입 영상들 및 상기 제2 타입의 카메라로부터 획득되는 제2 타입 영상들이 입력되면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 표적 객체가 검출되는지 여부를 식별하는 객체 인식 모델을 학습시킬 수 있다. 일 실 시 예에 의하면, 전자 장치는 제1 타입 학습 영상들에 기초하여, 제1 타입 영상들이 입력되면 제1 타입 영상들 내 표적 객체가 검출되는지 여부를 식별하는 제1 객체 인식 모델을 학습시키고, 제2 타입 학습 영상들에 기초하여, 제2 타입 영상들이 입력되면 제2 타입 영상들 내 표적 객체가 검출되는지 여부를 식별하는 제2 객체 인식 모델을 학습 시킨 후, 제1 객체 인식 모델 및 제2 객체 인식 모델을 이용하여 하나의 객체 인식 모델을 생 성할 수도 있다. S1940에서, 전자 장치는 학습된 객체 인식 모델에 상기 제1 타입 영상들 및 상기 제2 타입 영상들을 입력 함으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체의 검출 여부를 식별할 수 있다. 도 19에 도시되지 않았지만, 전자 장치는 표적 객체가 검출되는 것으로 식별되는 경우, 표적 객체가 검출 된 타입의 영상들로부터 표적 객체의 형상 정보를 추출하게 된다. 도 20은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 객체 인식 모델을 학습시키고, 학 습된 객체 인식 모델을 활용하는 과정을 나타내는 도면이다. S2002에서 전자 장치는 인공지능 모델 학습을 위한 영상 데이터를 획득하고, 획득된 영상 데이터를 분석 할 수 있다. S2004에서, 전자 장치는 획득된 영상 데이터를 전처리할 수 있다. S2006에서, 전자 장치 는 획득된 영상 데이터 중에서 미리 설정된 비율에 따라 일부를 학습 데이터로 나머지 일부를 검증 데이 터로 분리할 수 있다. S2008에서, 전자 장치는 표적 객체 인식을 위해 사용될 인공지능 알고리즘 및 모델을 결정할 수 있다. S2010에서, 전자 장치는 결정된 알고리즘 및 모델 사항에 따라, 상기 영상 데이터 중 일부의 영상 데이터 인 학습 데이터에 기초하여 인공지능 모델을 학습시킬 수 있다. S2012에서, 전자 장치는 검증 데이터에 기초하여 학습된 인공지능 모델의 성능을 검증할 수 있다. S2014에서, 전자 장치는 인공지능 모델의 성능 을 검증한 결과, 인공지능 모델의 성능이 소정의 조건을 만족하지 못하는 것으로 결정되는 경우, 인공지능 모델 의 파라미터를 파인 튜닝할 수 있다. 그러나, S2016에서, 전자 장치는 인공지능 모델의 성능을 검증한 결 과, 인공 지능 모델의 성능이 소정의 조건을 만족하는 것으로 결정되는 경우, 해당 인공지능 모델의 파라미터를 추출할 수 있다. S2018에서, 전자 장치는 인공지능 모델의 파라미터를 파인 튜닝한 결과에 기초하여, 인공지능 알고리즘 및 모델을 변경할 필요가 있는지 여부를 결정할 수 있다. 전자 장치는 인공지능 알고리즘 및 모델을 변경할 필요가 있는 경우, 새로운 인공지능 알고리즘 및 모델을 선정하게 되며, 인공지능 알고리즘 및 모델을 변경 할 필요가 없는 경우, 해당 알고리즘 및 모델을 다시 학습시키고, 학습된 모델의 성능 만족 여부를 평가할 수 있다. S2020에서, 전자 장치는 표적 객체 인식을 위한 입력 영상을 획득하고, 획득된 입력 영상을 전처리할 수 있다. S2022에서, 전자 장치는 S2016에서 결정된 인공지능 모델의 파라미터에 기초하여 실제 활용 인공 지능 모델의 파라미터를 수정 및 갱신함으로써 인공지능 모델을 학습시킬 수 있다. S2024에서, 전자 장치(100 0)는 학습된 인공 지능 모델에, 전처리된 입력 영상을 입력한 결과에 기초하여 표적 객체가 검출되는지 여부를 식별하고, 표적 객체가 검출되는 것으로 식별되는 경우, 해당 표적 객체에 대한 정보를 저장 및 반환할 수 있다. 도 21은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 우도비 검정 모델 및 서포트 벡터 모신 모델을 학습과정을 나타내는 흐름도이다. S2110에서, 전자 장치는 제2 타입 학습 영상들 또는 상기 제2 타입 학습 영상들로부터 추출되는 스펙트럼 학습 정보에 기초하여, 상기 제2 타입 영상들 또는 상기 제2 타입 영상들로부터 추출되는 스펙트럼 정보가 입력 되면, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별하는 우도비 검 정 모델을 학습시킬 수 있다. S2120에서, 전자 장치는 제2 타입 학습 영상들 또는 상기 제2 타입 학습 영상들로부터 추출되는 스펙트럼 학습 정보에 기초하여, 상기 제2 타입 영상들 또는 상기 제2 타입 영상들로부터 추출되는 스펙트럼 정보가 입력 되면, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별하는 서포트 벡 터 머신 모델을 학습시킬 수 있다. 전자 장치가 우도비 검정 모델 및 서포트 벡터 모신 모델을 학습하는 구체적인 과정은 후술하는 도 22를 참조하여 구체적으로 설명하기로 한다. 도 22은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 우도비 검정 모델 및 서포트 벡터 모신 모델을 학습하는 과정을 설명하기 위한 도면이다. S2202에서, 전자 장치는 우도비 검정 모델 학습을 위한 주파수 데이터를 획득하고, 획득된 주파수 데이터 를 분석한다. 일 실시 예에 의하면, 주파수 데이터는 제2 타입 학습 영상들을 주파수 도메인으로 변환함으로써 생성되는 영상 데이터일 수 있다. S2204에서, 전자 장치는 주파수 데이터를 전처리할 수 있다. S2206에서, 전자 장치는 전처리된 주파수 데이터 중 일부를 학습 데이터, 나머지 일부를 검증 데이터로 설정할 수 있다. S2208에서, 전자 장치는 표적 객체에 따른 주파수 패턴을 분류하기 위한 알고리즘을 선정할 수 있다. 일 실시 예에 의하면 전자 장치는 적외선 영상으로부터 획득된 스펙트럼 정보를 분류하기 위한 알고리즘으로 우도비 검정 알고리즘을 사용할 수 있다. S2210에서, 전자 장치는 학습 데이터에 기초하여 선정된 알고리 즘 및 상기 알고리즘에 따른 모델을 학습시킬 수 있다. S2212에서, 전자 장치는 학습된 모델의 성능이 소정의 목표치를 만족하는지 여부를 검증할 수 있다. S2214에서, 전자 장치는 학습된 모델의 성능이 소정의 목표치를 만족하지 않는 것으로 식별되는 경우, 해 당 모델에 대한 파인 튜닝(Fine Tunning)을 수행할 수 있다. S2216에서, 전자 장치는 S2212에서 학습된 모델의 성능이 소정의 목표치를 만족하는 것으로 식별되는 경우, 학습된 모델의 파라미터를 추출할 수 있다. S2218에서, 전자 장치는 학습된 모델에 입력하기 위해, 표적 객체 검출 대상이 되는 적외선 영상을 획득 하고, 획득된 적외선 영상을 푸리에 변환함으로써 획득되는 주파수 데이터에 대해 전처리를 수행할 수 있다. S2220에서, 전자 장치는 전처리된 주파수 데이터 또는 상기 주파수 데이터에서 획득되는 스펙트럼 정보를 학습된 인공지능 학습 모델(예컨대 우도비 검정 모델)에 입력함으로써 표적 객체에 따른 주파수 패턴이 식별되 는지 여부를 확인할 수 있다. 또한, 일 실시 예에 의하면, 전자 장치는 표적 객체에 따른 주파수 패턴을 검출하기 위해 또 다른 패턴 분류 알고리즘 및 이에 기초하여 학습되는 모델을 더 이용할 수도 있다. 예를 들어, 전자 장치는 서포트 벡터 머신 모델을 학습시키고, 학습된 서포트 벡터 머신 모델을 소정의 조건에서 우도비 검정 모델과 함께 이용 함으로써 표적 객체에 따른 주파수 패턴을 정확하게 추출할 수 있다. S2230 내지 S2250에 도시된 동작은 S2202내지 S2220에 대응될 수 있으므로 구체적인 설명은 생략하기로 한다. 도 23은 또 다른 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 복수의 소프트웨어 모듈을 이용하여 가스 누출을 탐지하는 과정을 설명하기 위한 도면이다. 도 12에 도시된 각 모듈은 가스 누출 탐지를 위해 전자 장치의 프로세서에 의해 실행될 수 있는, 메모리 내 저장된 하나 이상의 인스트럭션 집합일 수 있다. 일 실시 예에 의하면, 전자 장치는 AI 가스 영상 및 연기 탐지 모듈, 원점 탐지 모듈, 시각화 모듈, 경보 및 제어 모듈로 구분되는 하나 이상의 인스트럭션을 메모리에 저장하고, 저장된 인스트럭션들을 실행함으로써 모니터링 대상 공간에 대한 표적 객체를 탐지할 수 있다. 일 실시 예에 의하면, S2322 내지 S2328에서 전자 장치가 이용하는 S/W들은 AI 가스 영 상 및 연기 탐지 모듈에 포함될 수 있다. 예를 들어, S2322에서, 전자 장치는 EO 카메라, OGI 카메라 및 레이저 측정기를 포함 하는 카메라 설치셋으로부터 가시광선 영상들(예컨대 EO 영상들) 및 적외선 영상들(예컨대 OGI 영상들)을 획득할 수 있다. S2323에서, 전자 장치는 객체 인식 기술 S/W를 실행함으로써, 표적 객체가 가시광선 영 상들 및 적외선 영상들로부터 1차적으로 검출되지 않는 것으로 식별되는 경우, 적외선 영상 주파수 변환 S/W를 실행함으로써 시공간 도메인에 따른 적외선 영상 정보를 주파수 도메인의 변환 영상 정보로 변환할 수 있다. 전 자 장치는 주파수 도메인의 변환 영상 정보에서 스펙트럼을 추출할 수 있다. S2324에서, 전자 장치는 우도비 검정모델 및 SVM 모델 학습을 위한 S/W를 실행함으로써 표적 객체에 따른 주파수 패턴을 식별하기 위한 우도비 검정 모델 및 SVM 모델을 학습시킬 수 있다. S2325에서, 전자 장치 는 주파수별 패턴 분석 S/W를 실행함으로써 우도비 검정 모델 또는 SVM 모델 중 적어도 하나를 이용하여 적외선 영상 내 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별할 수 있다. S2326에서, 전자 장치는 객체 인식 기술 S/W를 실행함으로써 표적 객체가 인식되거나 적외선 영상으로부 터 표적 객체에 따른 주파수 패턴이 식별되는 경우, 연기/배경 분리 S/W를 실행함으로써 표적 객체 영역을 분리 할 수 있다. S2327에서, 전자 장치는 연기 형상 검출 S/W를 실행함으로써 마스킹 데이터를 이용하여, 표 적 객체가 검출된 타입의 영상들에서 표적 객체 영역을 분리하고, 분리된 표적 객체 영역들의 형상 정보를 추출 할 수 있다. S2328에서, 전자 장치는 연기 원점/흐름 검출 S/W를 실행함으로써, 표적 객체가 검출된 타입 의 영상들 내 인접한 프레임 이미지 각각에서 추출된 형상 정보에 기초하여, 분리된 표적 객체 영역들에 대한 모션 벡터를 결정하고, 결정된 모션 벡터들의 합벡터에 기초하여 누출 원점 및 흐름 벡터를 결정할 수 있다. 일 실시 예에 의하면, 전자 장치가 이용하는 원점 탐지 모듈은 거리 구면 좌표 인식 S/W 및 위치 정보 변환 S/W를 포함할 수 있다. 예를 들어, S2329에서, 거리 구면 좌표 인식 S/W를 실행함으로써, 누출 원점 에 대응되는 표적 객체가 발생한 물리적 공간까지의 거리를 획득하고, 획득된 누출 원점에 대한 카메라의 팬틸 트 정보를 획득하며, 상기 누출 원점, 흐름 벡터, 표적 객체가 발생한 물리적 공간까지의 거리 및 팬틸트 정보 에 기초하여 구면 좌표계에서의 좌표를 결정할 수 있다. S2330에서, 전자 장치는 위치 정보 변환 S/W를 실행함으로써 상기 결정된 구면 좌표계에서의 좌표를 직교 좌표계 또는 카메라의 왜곡 정보 보정에 따른 좌표 값으로 변환할 수 있다. S2340에서, 전자 장치는 영상 합성 S/W를 실행함으로써 S2330에서 결정된 좌표 값에 기초하여, 누출 영상 을 파노라마 영상에 대해 합성함으로써 합성 영상을 생성할 수 있다. 일 실시 예에 의하면 시각화 모듈은 영상 합성 S/W를 포함할 수 있다. 또한, 일 실시 예에 의하면 경보/제어 모듈은 환경 설정 S/W, 제어 기 능 S/W, 저장 기능 S/W, 검색 기능 S/W, 경보 기능 S/W를 포함할 수 있다. S2352에서, 전자 장치는 환경 설정 S/W를 실행함으로써 모니터링 대상 공간에 대한 카메라 설치셋 의 동작 환경을 조정할 수 있다. S2354에서, 전자 장치는 제어 기능 S/W를 실행함으로써 카메라 설치셋 내 카메라 장치 및 레이저 측정기의 동작을 세부적으로 제어할 수 있다. S2356에서, 전자 장치는 저장기능 S/W를 실행함으로써 S2340에서 획득된 합성 영상을 메모리에 저장할 수 있다. S2357에서, 전자 장치 는 검색 기능 S/W를 실행함으로써 저장된 합성 영상에 접근하려는 사용자 입력에 기초하여 소정의 영상을 검색하고 출력하는 기능을 수행할 수 있다. 일 실시 예에 의하면, 전자 장치는 시간 별, 카메라별, 위치 별로 EO 영상 및 OGI 영상들을 저장해놓고, 시간 별 검색 조건에 따른 소정의 영상들을 검색할 수 있을 뿐만 아 니라, 표적 객체 탐지에 따른 이벤트 기록을 저장하고, 이벤트 별 기록들을 사용자 요청에 의해 출력할 수도 있 다.S2358에서, 전자 장치는 경보기능 S/W를 실행함으로써 영상 내 표적 객체가 검출되는 것으로 식별되는 경 우 소정의 경보 컨텐츠 및 제어 신호를 생성하고, 생성된 경보 컨텐츠를 출력부의 영상 디스플레이에 전 송하거나, 생성된 제어 신호를 출력부의 경광등으로 전송함으로써 발광 동작을 수행하도록 제어할 수 있 다. 도 24는 또 다른 실시 예에 따라, 측정 장치, 인공지능 기반 가스 누출 탐지 서버, 경보/제어 서버 및 관제 장 치가 서로 연동함으로써 가스 누출을 탐지하는 과정을 설명하기 위한 도면이다. 일 실시 예에 의하면 도 1 내지 23에 상술한 가스 누출 탐지 과정들은 가스 누출 탐지 시스템 또는 전자 장 치에 의해서 수행될 수 있다. 일 실시 예에 의하면 가스 누출 탐지 시스템은 측정 장치, 인공 지능 기반 가스 누출 탐지 서버, 경보 및 제어 서버 및 관제 장치를 포함할 수 있다. 도 24 를 참조하여 측정 장치, 인공지능 기반 가스 누출 탐지 서버, 경보 및 제어 서버 및 관제 장 치가 서로 연동함으로써 가스 누출을 탐지하는 과정을 설명하기로 한다. S2402에서, 측정 장치는 영상 정보 및 레이저 측정 값을 획득할 수 있다. 또 다른 실시 예에 의하면, 측 정 장치는 영상 정보를 먼저 획득하고, 경보 및 제어 서버의 제어에 의해, 누출 원점이 탐지되면, 해당 누출 원점에 대한 레이저 측정 값을 추후에 획득할 수도 있다. S2404에서, 측정 장치는 영상 정보 및 레이저 측정 값을 인공지능 기반 가스 누출 탐지 서버로 전송할 수 있다. S2406에서, 인공지능 기반 가스 누출 탐지 서버는 영상 정보 및 레이저 측정 값을 경보 및 제어 서버 로 전달할 수 있다. 그러나, 상술한 과정은 수행되지 않을 수 있으며, 인공지능 기반 가스 누출 탐지 서 버는 영상 정보 및 레이저 측정 값을 자체 서버 장치 내에서만 분석할 수도 있다. S2408에서, 인공지능 기반 가스 누출 탐지 서버는 적어도 하나의 인공지능 모델을 이용하여 획득된 영상 정보 내 표적 객체가 검출되는지 여부를 식별할 수 있다. S2410에서, 인공지능 기반 가스 누출 탐지 서버는 표적 객체가 검출되는 것으로 식별되는 경우, 해당 표 적 객체의 형상 정보에 기초하여 누출 원점 및 흐름 벡터를 결정할 수 있다. S2412에서, 인공지능 기반 가스 누 출 탐지 서버는 누출 원점 및 흐름 벡터에 기초하여 거리 구면 좌표를 결정하고, 결정된 거리 구면 좌표 를 변환함으로써 누출 영상의 파노라마 영상에 대한 좌표를 결정할 수 있다. S2414에서, 인공지능 기반 가스 누 출 탐지 서버는 누출 영상을 파노라마 영상에 합성함으로써 합성 영상을 생성할 수 있다. S2416에서, 인공지능 기반 가스 누출 탐지 서버는 이벤트 탐지 결과, 영상 정보, 레이저 측정값, 합성 영 상 및 인공지능 모델의 분석 결과를 경보 및 제어 서버로 전달할 수 있다. S2418에서, 경보 및 제어 서버 는 이벤트 탐지 결과, 영상 정보, 레이저 측정 값, 합성 영상, 인공 지능 모델의 분석 결과를 관제 장치 로 전달할 수 있다. S2420에서, 관제 장치는 관제 디스플레이를 통해 합성 영상을 포함한 관제 영 상을 표시하고, 소정의 경고 컨텐츠를 생성하며, 생성된 경고 컨텐츠를 관제 영상과 함께 중첩하여 표시할 수 있다. S2422에서, 관제 장치는 카메라 제어 신호, 레이저 측정기 제어 신호를 측정 장치로 전달할 수 있 다. 일 실시 예에 의하면 관제 장치는 복수 타입의 카메라들로 제어 신호를 전송함으로써, 복수 타입 영 상들 사이의 전환 기능을 수행할 수도 있다. 또 다른 실시 예에 의하면, 관제 장치는 제어 신호를 경보 및 제어 서버를 통해 측정 장치로 전달할 수도 있다. 예를 들어, S2424에서, 관제 장치는 관 제 장치에 대한 관제자의 사용자 입력에 기초하여 제어 신호를 생성하고, 생성된 제어 신호를 경보 및 제 어 서버로 전달할 수 있다. S2426에서, 측정 장치는 제어 신호에 따라 동작 및 새로운 정보를 획득 할 수 있다. 도 25는 또 다른 실시 예에 따라, 전자 장치, 경보 장치 및 서버가 서로 연동함으로써 가스 누출을 탐지하는 과 정을 설명하기 위한 도면이다. 본 개시의 또 다른 실시 예에 의하면 가스 누출 탐지 시스템은 전자 장치, 경보 장치 및 서버 를 포함할 수도 있다. 도 25에 도시된 과정들은 가스 누출 탐지 시스템에 의해 수행될 수도 있으나, 전자 장치에 의해서도 수행될 수 있음은 물론이다. S2502에서, 전자 장치는 영상 정보, 레이저 측정 값을 획득할 수 있다. S2504에서, 전자 장치는 획득된 영상 정보, 레이저 측정 값을 서버로 전달할 수 있다. S2506에서, 전자 장치는 인공지능 모 델을 이용하여 영상 정보 내 표적 객체가 탐지되는지 및 표적 객체의 종류를 분석할 수 있다. S2508에서, 전자 장치는 인공지능 모델을 이용한 객체 탐지 결과를 서버로 전송할 수 있다. 도 25에는 도시되지 않 았지만, 서버는 전자 장치에서 전송된 영상 정보, 레이저 측정 값, 객체 탐지 결과를 실시간으로 관제 장치의 디스플레이로 출력할 수 있다. S2510에서, 전자 장치는 인공지능 모델을 이용하여 영상 정보 내 표적 객체가 탐지되는지 여부에 기초하 여 소정의 경고 이벤트가 발생하였는지 여부를 결정할 수 있다. S2512에서, 전자 장치는 이벤트가 탐지되 는 경우 경보 정보를 경보 장치로 전송할 수 있다. 또한, 전자 장치는 S2514에서, 경보 정보 및 탐 지 결과를 서버로 전송할 수 있다. 일 실시 예에 의하면, S2516에서, 서버는 전자 장치와 별 도의 경보 정보를 경보 장치로 더 전송함으로써, 복수 루트로 경보 장치의 동작 신뢰를 확보할 수 있다. S2518에서, 전자 장치는 객체 탐지시 누출 원점 및 좌표 정보를 결정할 수 있다. S2520에서, 전자 장치 는 표적 객체에 관한 누출 영상을 생성하고, 생성된 누출 영상을 파노라마 영상에 합성함으로써 합성 영 상을 생성할 수 있다. S2524에서, 서버는 합성 영상 정보 및 탐지 결과를 출력할 수 있다. S2526에서, 서 버는 경보 장치 내 다양한 구성 장치들을 제어하기 위한 제어 신호를 경보 장치로 전송할 수 있다. S2528에서, 서버는 카메라 설치셋 내 구성 장치들을 제어하기 위한 제어 신호를 전자 장치로 전송 할 수 있다. 도 26은 일 실시 예에 따른 전자 장치의 블록도이다. 도 27은 또 다른 실시 예에 따른 전자 장치의 블록도이다. 도 26에 도시된 바와 같이, 일 실시 예에 따른 전자 장치는 프로세서, 네트워크 인터페이스 및 메모리를 포함할 수 있다. 그러나, 도시된 구성 요소가 모두 필수구성요소인 것은 아니다. 도시된 구 성 요소보다 많은 구성 요소에 의해 전자 장치가 구현될 수도 있고, 그 보다 적은 구성 요소에 의해서도 전자 장치는 구현될 수도 있다. 예를 들어, 도 27에 도시된 바와 같이, 전자 장치는 프로세서, 네트워크 인터페이스 및 메모 리외에, 사용자 입력 인터페이스, 출력부, 센싱부, 네트워크 인터페이스, A/V 입력부 및 메모리를 더 포함할 수도 있다. 사용자 입력 인터페이스는, 사용자가 전자 장치를 제어하기 위한 데이터를 입력하는 수단을 의미한 다. 예를 들어, 사용자 입력 인터페이스에는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접 촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠, 조그 스위치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 사용자 입력 인터페이스는, 카메라 설치셋을 제어하거나, 영상 내 특정 영역을 확대 또는 축소하기 위한 사용자 입력을 수신할 수 있다. 또 다른 실시 예에 의하면 사용자 입력 인터페이스는 저장된 합성 영상 중 특정 시간 및 장소에 대한 영상에 접근하기 위한 사용자 입력을 획득할 수도 있음은 물론이다. 출력부(120 0)는, 오디오 신호 또는 비디오 신호 또는 진동 신호를 출력할 수 있으며, 출력부는 디스플레이부, 음향 출력부, 및 진동 모터를 포함할 수 있다. 디스플레이부는 전자 장치에서 처리되는 정보를 표시 출력하기 위한 화면을 포함한다. 또한, 화면 은 카메라 설치셋에서 획득된 복수 타입 영상들, 누출 영상, 파노라마 영상 및 합성 영상을 디스플레이 할 수 있다. 예를 들면, 화면의 적어도 일부는 모니터링 대상 공간에 대한 합성 영상, 상기 합성 영상에서 나타나는 표적 객체를 세밀하게 모니터링하기 위해, 카메라 설치셋등을 제어하기 위한 사용자 인터페이스 등을 함께 출력 할 수 있다. 음향 출력부는 네트워크 인터페이스로부터 수신되거나 메모리에 저장된 오디오 데이터를 출 력한다. 또한, 음향 출력부는 전자 장치에서 수행되는 기능(예를 들어, 호신호 수신음, 메시지 수 신음, 알림음)과 관련된 음향 신호를 출력한다. 프로세서는 통상적으로 전자 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 메 모리에 저장된 프로그램들을 실행함으로써, 사용자 입력 인터페이스, 출력부, 센싱부, 네트워크 인터페이스, A/V 입력부 등을 전반적으로 제어할 수 있다. 또한, 프로세서는 메모리에 저장된 프로그램들을 실행함으로써, 도 1 내지 도 25에 기재된 전자 장치의 기능을 수행할 수 있다. 일 실시 예에 의하면, 프로세서는 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함 으로써, 상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간에 대한 제1 타입 영상들을 획득하고, 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간 에 대한 제2 타입 영상들을 획득하고, 상기 제1 타입 영상들 및 상기 제2 타입 영상들이 입력되면, 상기 제1 타 입 영상들 및 상기 제2 타입 영상들 내 표적 객체가 검출되는지 여부를 식별하는 객체 인식 모델에, 상기 제1 타입 영상들 및 상기 제2 타입 영상들을 입력함으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체 검출 여부를 식별할 수 있다. 일 실시 예에 의하면, 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 전자 장치와 연결 된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간에 대한 제1 타입 영상들 및 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간에 대한 제2 타입의 영상들을 획득하고, 상기 제1 타입 영상들 또는 상기 제2 타입 영상들 중 적어도 하나로부터 표적 객체가 검출되는 것으 로 식별되는 경우, 상기 검출된 표적 객체에 관한 제1 타입 영상들 및 상기 검출된 표적 객체에 관한 상기 제1 타입 영상들에 대응되는 제2 타입 영상들을 합성함으로써 누출 영상을 생성하고, 상기 생성된 누출 영상의 미리 획득된 파노라마 영상에 대한 좌표에 기초하여, 상기 누출 영상을 상기 파노라마 영상에 합성함으로써 합성 영 상을 생성할 수 있다. 일 실시 예에 의하면, 프로세서는 상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니 터링 대상 공간에 대한 제1 타입 학습 영상들, 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부 터 상기 모니터링 대상 공간에 대한 제2 타입 학습 영상들을 획득하고, 상기 제1 타입 학습 영상들 및 상기 제2 타입 학습 영상들에 기초하여 학습 데이터 및 검증 데이터를 생성하고, 상기 생성된 학습 데이터에 기초하여, 상기 제1 타입의 카메라로부터 획득되는 제1 타입 영상들 및 상기 제2 타입의 카메라로부터 획득되는 제2 타입 영상들이 입력되면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 표적 객체가 검출되는지 여부를 식별하 는 객체 인식 모델을 학습시키고, 상기 학습된 객체 인식 모델에 상기 제1 타입 영상들 및 상기 제2 타입 영상 들을 입력함으로써, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체의 검출 여부를 식별할 수 있다. 또한, 일 실시 예에 의하면, 프로세서는 하나 이상의 인스트럭션을 실행함으로써 표적 객체가 검출되는 경우, 표적 객체가 발생한 누출 원점, 상기 누출 원점에 대한 물리적 공간상의 위치 정보, 상기 표적 객체의 종 류 중 적어도 하나에 관한 정보를 합성 영상과 함께 화면상에 출력할 수도 있다. 센싱부는, 전자 장치의 상태 또는 전자 장치 주변의 상태를 감지하고, 감지된 정보를 프로세 서로 전달할 수 있다. 센싱부는 전자 장치의 사양 정보, 모니터링 대상 공간에 대한 온도, 습도, 기압 정보 등을 센싱할 수 있다. 예를 들어, 센싱부는, 지자기 센서(Magnetic sensor), 가속도 센서(Acceleration sensor), 온/습도 센서, 적외선 센서, 자이로스코프 센서, 위치 센서(예컨대, GPS), 기압 센서 , 근접 센서, 및 RGB 센서(illuminance sensor) 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 각 센서들의 기능은 그 명칭으로부터 당업자가 직관적으로 추론할 수 있으므로, 구체적 인 설명은 생략하기로 한다. 네트워크 인터페이스는 전자 장치가 다른 장치(미도시) 및 서버와 통신을 하게 하는 하나 이 상의 구성요소를 포함할 수 있다. 다른 장치(미도시)는 전자 장치와 같은 컴퓨팅 장치이거나, 센싱 장치 일 수 있으나, 이에 제한되지 않는다. 예를 들어, 네트워크 인터페이스는, 무선 통신 인터페이스 , 유선 통신 인터페이스 , 이동 통신부를 포함할 수 있다. 무선 통신 인터페이스는 근거리 통 신부(short-range wireless communication unit), 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, 근거 리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 지그비(Zigbee) 통신부, 적외선 (IrDA, infrared Data Association) 통신부, WFD(Wi-Fi Direct) 통신부, UWB(ultra wideband) 통신부 등을 포 함할 수 있으나, 이에 한정되는 것은 아니다. 유선 통신 인터페이스는 유선 통신을 통해 전자 장치와 연결된 외부 디바이스와 데이터를 주고받기 위한 적어도 하나의 유선 인터페이스를 포함할 수 있다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의단말, 서버 중 적어도 하나와 무선 신호를 송수신한다. 여기에서, 무선 신호는, 음성 호 신호, 화상 통화 호 신 호 또는 문자/멀티미디어 메시지 송수신에 따른 다양한 형태의 데이터를 포함할 수 있다. A/V(Audio/Video) 입력부는 오디오 신호 또는 비디오 신호 입력을 위한 것으로, 이에는 카메라와 마이크로폰 등이 포함될 수 있다. 카메라는 화상 통화모드 또는 촬영 모드에서 이미지 센서를 통해 정지영상 또는 동영상 등의 화상 프레임을 얻을 수 있다. 이미지 센서를 통해 캡쳐된 이미지는 프로세서 또는 별도의 이미지 처리부(미도시)를 통해 처리될 수 있다. 일 실시 예에 의하면 카메라 모듈은 전면부 에 소정의 필터가 부착됨으로써 적외선 영상을 통해 가스 또는 연기를 시각화하는 OGI 카메라 및 가시광선 영상 을 획득하는 EO 카메라를 포함할 수 있다. 마이크로폰은, 외부의 음향 신호를 입력 받아 전기적인 음성 데이터로 처리한다. 예를 들어, 마이크로폰 은 외부 디바이스 또는 사용자로부터 음향 신호를 수신할 수 있다. 마이크로폰은 사용자의 음성 입 력을 수신할 수 있다. 마이크로폰은 외부의 음향 신호를 입력 받는 과정에서 발생 되는 잡음(noise)을 제 거하기 위한 다양한 잡음 제거 알고리즘을 이용할 수 있다. 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 전자 장치로 입력되 거나 전자 장치로부터 출력되는 데이터를 저장할 수도 있다. 또한, 메모리는 전자 장치가 이용하는 적어도 하나의 인공지능 모델, 전자 장치가 획득한 모니터링 대상 공간에 대한 영상 정보, 레이저 측 정값, 합성 영상, 누출 영상, 인공지능 모델의 분석 결과에 대한 정보를 저장할 수 있다. 또한, 메모리는 전자 장치가 이용하는 적어도 하나의 신경망 모델에 대한 정보를 저장할 수 있다. 예를 들어, 메모리는 적어도 하나의 신경망 모델 내 레이어들, 노드들, 상기 레이어들의 연결 강도에 관 한 가중치 값들을 저장할 수 있다. 또한, 전자 장치는 신경망 모델을 학습하기 위해 전자 장치가 생성한 학습 데이터를 더 저장할 수도 있다. 또한, 메모리는 전자 장치와 연결된 카메라들 또는 서버의 동작 환경에 대한 정보들을 더 저장할 수도 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 메모리에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있는데, 예를 들어, UI 모 듈, 터치 스크린 모듈, 알림 모듈 등으로 분류될 수 있다. UI 모듈은, 가스 누출 탐지를 위한 애플리케이션 별로 전자 장치와 연동되는 특화된 UI, GUI 등을 제공할 수 있다. 터치 스크린 모듈은 사용자의 터치 스크린 상의 터치 제스처를 감지하고, 터치 제스처에 관한 정보를 프로세서로 전달할 수 있다. 일부 실시예에 따른 터치 스크린 모듈은 터치 코드를 인 식하고 분석할 수 있다. 터치 스크린 모듈은 컨트롤러를 포함하는 별도의 하드웨어로 구성될 수도 있다. 알림 모듈은 전자 장치의 이벤트 발생을 알리기 위한 신호를 발생할 수 있다. 예를 들어, 전자 장 치가 가스 누출에 따른 표적 객체가 검출되었음을 식별하고, 이에 따른 경고 컨텐츠를 출력할 수 있다. 일 실시 예에 따른 이벤트의 예로는 호 신호 수신, 메시지 수신, 키 신호 입력, 일정 알림 등이 있다. 알림 모 듈은 디스플레이부를 통해 비디오 신호 형태로 알림 신호를 출력할 수도 있고, 음향 출력부 를 통해 오디오 신호 형태로 알림 신호를 출력할 수도 있고, 진동 모터를 통해 진동 신호 형태로 알림 신 호를 출력할 수도 있다. 도 28은 또 다른 실시 예에 따른 가스 누출 탐지 시스템의 장치 구성을 설명하기 위한 도면이다. 일 실시 예에 의하면, 가스 누출 탐지 시스템은 카메라 설치셋, 카메라셋 및 관제 단말기 를 포함할 수 있다. 일 실시 예에 의하면 카메라 설치셋은 카메라 하우징, 팬틸트 , 엘리베이션 폴대를 포함할 수 있다. 가스 누출 탐지 시스템은 카메라 설치셋에 대한 제어 신호 를 전송함으로써, 원격으로 카메라의 팬틸트 값을 변경하거나, 폴대의 엘리베이션 값을 변경함으로써, 원하는 모니터링 대상 공간에 대한 영상 정보 및 레이저 측정값을 획득할 수 있다. 일 실시 예에 의하면, 엘리베이션 폴대는 미리 설정된 높이 값(예컨대 20m)이상 연장될 수 있으며, 팬틸 트는 Pan 360도, tilt는 -30도 내지 30도까지 제어될 수 있으나, 이에 한정되는 것은 아니다. 또한, 일 실시 예에 의하면 카메라 하우징은 30KG 이상의 무게를 지지하도록 마련될 수 있으며, 본 개시에 따른 관 제 단말과 연결되는 경보 장치의 경보음은 90Db/1m 이상의 성능 조건을 만족하도록 마련될 수 있다. 일 실시 예 에 의하면 카메라 하우징 내부에는 카메라 셋이 마련될 수 있다. 일 실시 예에 의하면, 카메라 셋 은 OGI 가스 이미징 카메라, 레이저 측정기 및 EO 카메라를 포함할 수 있다. 일 실시 예에 의하면 카메라의 구성들은 모두 카메라 설치셋으로 포함될 수 있음은 물론이다. 관제 단말기 는 복수의 컴퓨터 조립체 서버 장치와 컴퓨터 조립체 전용 모니터 장치를 포함할 수 있다. 도 29는 일 실시 예에 따른 서버의 블록도이다. 일 실시 예에 의하면, 서버는 네트워크 인터페이스, 데이터 베이스 및 프로세서를 포 함할 수 있다. 도 29에 도시된 서버의 구성은 도 24에 도시된 인공지능 기반 가스 누출 탐지 서버, 경보 및 제어 서버에 대응될 수 있으며, 도 1의 관제 서버의 구성에 대응될 수 있다. 네트워크 인터페이스는 상술한 전자 장치의 네트워크 인터페이스(미도시)에 대응될 수 있다. 예를 들어, 네트워크 인터페이스는 전자 장치로부터 복수 타입의 영상 정보, 인공지능 모델의 분석 결과, 누출 원점, 흐름 벡터, 누출 영상, 합성 영상에 대한 정보를 획득할 수 있다. 또 다른 실시 예에 의하면, 네트워크 인터페이스는 전자 장치가 학습된 인공지능 모델에 대한 정보, 또는 신경망 모델에 대한 정보 (예컨대 레이어들 및 레이어들 사이의 연결 강도에 관한 가중치 값)를 수신할 수 있다. 또 다른 실시 예에 의하 면, 네트워크 인터페이스는 서버가 학습시킨 인공지능 모델에 대한 정보로, 인공 신경망의 레이어들 및 레이어들에 포함된 노드에 관한 정보 또는 신경망 내 레이어들의 연결 강도에 관한 가중치 값들을 전자 장치 로 전송할 수도 있다. 또한, 일 실시 예에 의하면 데이터 베이스는 도 26 내지 도 27에서 상술한 메모리에 대응될 수 있다. 예 를 들어, 데이터 베이스는 전자 장치로부터 획득되는 영상 정보들, 레이저 측정 값, 인공지능 모델 의 분석 결과, 합성 영상, 인공지능 모델 자체에 대한 정보 등을 저장할 수 있다. 일 실시 예에 의하면 데이터 베이스는 키워드 일부와 단어 조합만으로 데이터 베이스 정보 조회가 가능하도록 설계되며, 날짜, 시간 및 카메라 위치 별 소정의 영상 데이터가 검색 및 조회가 가능하도록 설계될 수 있다. 또한, 일 실시 예에 의하면 데이터 베이스는 일반 영상과 표적 객체 검출에 따른 이벤트 발생 시 해당 표 적 객체에 관한 영상에 대한 정보를 제공할 수 있으며, 효율적인 용량 관리를 위해 별도의 동영상 저장 포맷을 이용하여 데이터를 저장할 수 있다. 또한, 데이터 베이스는 기존 저장되어 있는 영상 데이터와 이벤트 발 생 여부 데이터를 join을 이용해 새로운 테이블로 관리할 수 있고, 데이터 무결성 등 데이터 베이스 설계 원칙 을 지키기 위해 테이블 접근 시 view 형식으로 접근 및 원본 테이블 접근을 제한할 수 있다. 또한, 일 실시 예 에 의하면 데이터 베이스는 유지/보수가 용이하게 코드를 procedure 형식으로 관리할 수 있으며, 데이터 베이스 조회 시 최적화를 위해 explain 명령어에 기초하여 데이터를 처리할 수 있으며, 데이터 삭제 내역 관리 를 위한 트리거를 적용할 수 있다. 일 실시 예에 의하면, 프로세서는 서버의 전반적인 동작을 제어할 수 있다. 예를 들어, 프로세서 는 네트워크 인터페이스 및 데이터 베이스를 제어함으로써, 도 1 내지 28에서 기재된 전자 장치 또는 가스 누출 탐지 시스템이 수행하는 동작의 전부 또는 적어도 일부를 함께 수행할 수 있다. 도 30은 일 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 제공하는 사용자 인터페이스 화면 을 나타내는 도면이다. 도 30을 참조하면 전자 장치가 제공하는 사용자 인터페이스 화면의 일 예가 도시된다. 도 30에 도시된 사용자 인터페이스 화면은 전자 장치뿐만 아니라, 관제 단말 또는 전자 장치와 연결된 관제 서버에 의해 통제되 는 상황실 시스템의 디스플레이 상에 출력될 수도 있다. 일 실시 예에 의하면, 전자 장치는 카메라 설치 셋 내 복수 타입의 카메라 및 레이저 측정기의 동작을 제어하기 위한 컨트롤 인터페이스, 전자 장치 가 처리하는 영상 정보들을 저장, 관리 및 호출하기 위한 영상 제어 인터페이스를 출력할 수 있다. 전자 장치는 영상 제어 인터페이스를 통해 획득되는 관제자의 사용자 입력에 기초하여 특정 영상에액세스하거나, 액세스된 특정 영상을 화면상에 출력할 수 있다. 일 실시 예에 의하면, 전자 장치는 컨트롤 인터페이스를 선택하는 사용자 입력에 기초하여, 확대 인터페이스, 포커스 인터페이스 및 센서 인터페이스를 화면상에 추가적으로 제공할 수도 있 다. 일 실시 예에 의하면, 전자 장치는 확대 인터페이스에 대한 사용자 입력에 기초하여, 모니터링 대상 공간 내 특정 영역에 대한 확대 영상을 획득할 수 있다. 또한, 전자 장치는 포커스 인터페이스 에 대한 사용자 입력에 기초하여 미리 지정된 영역에 대한 초점을 자동으로 매칭시키는 포커싱 기능을 수 행할 수 있다. 일 실시 예에 의하면, 전자 장치는 모니터링 대상 공간 내 특정 영역에 대하여 미리 오토 포커싱 영역을 설정해둘 수도 있다. 일 실시 예에 의하면, 전자 장치는 센터 인터페이스에 대한 사 용자 입력에 기초하여, 모니터링 대상 공간 내 위치하는 센서의 동작 환경(셔터 주기, 정보 획득 주기 등)을 변 경할 수 있다. 도 31은 또 다른 실시 예에 따른 인공지능 기반 가스 누출을 탐지하는 전자 장치가 제공하는 사용자 인터페이스 화면을 나타내는 도면이다. 도 31을 참조하면 전자 장치가 제공하는 사용자 인터페이스 화면의 일 예가 도시된다. 일 실시 예에 의하면, 전 자 장치는 영상 정보들을 저장, 관리 및 호출하기 위한 영상 제어 인터페이스를 제공할 수 있고, 상기 제공된 영상 제어 인터페이스는 비디오 인터페이스를 포함할 수 있다. 예를 들어, 전자 장치 는 비디오 인터페이스를 선택하는 사용자 입력에 기초하여 이미지 인터페이스, 인핸스먼트 인터페이스, 자동 조절 인터페이스 및 설정한 조건들을 저장하기 위한 설정 저장 인터페이스(311 0)를 출력할 수 있다. 일 실시 예에 의하면, 이미지 인터페이스는 현재 표시되는 영상 내 디지털 줌을 통한 영상 확대, 영상의 밝기 값 조절, 명암 값 조절을 위한 사용자 인터페이스를 포함할 수 있다. 일 실시 예에 의하면, 인핸스먼트 인 터페이스는 영상 내 소음 제거, 노이즈 제거와 같은 비디오 데이터의 품질 향상을 위한 편집 인터페이스 들을 포함할 수 있다. 일 실시 예에 의하면 자동 조절 인터페이스는 비디오 클립을 편집하기 위한 인터페 이스를 포함할 수 있고, 설정 저장 인터페이스는 비디오 인터페이스를 통해 변경된 값들을 저장하 기 위한 기능을 제공할 수 있다. 본 개시에 따른 가스 누출 탐지 방법, 가스 누출 탐지를 위한 합성 영상 생성 방법 및 표적 객체의 형상을 식별 하는 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매 체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행 하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같 은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함 한다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21 도면22 도면23 도면24 도면25 도면26 도면27 도면28 도면29 도면30 도면31\n【요약】본 개시는 인공지능 기반 가스 누출을 탐지하는 전자 장치 및 상기 전자 장치가 가스 누출을 탐지하는 방법에 관 한 것이다. 일 실시 예에 의하면, 인공지능 기반 가스 누출을 탐지하는 전자 장치가 가스 누출을 탐지하는 방법 은 상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간에 대한 제1 타입 학습 (뒷면에 계속)\n\n【청구항 1】\n인공지능 기반 가스 누출을 탐지하는 전자 장치가 상기 가스 누출을 탐지하는 방법에 있어서,상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간에 대한 제1 타입 학습 영상들, 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간에 대한 제2타입 학습 영상들을 획득하는 단계;상기 제1 타입 학습 영상들 및 상기 제2 타입 학습 영상들에 기초하여 학습 데이터 및 검증 데이터를 생성하는단계;상기 생성된 학습 데이터에 기초하여, 상기 제1 타입의 카메라로부터 획득되는 제1 타입 영상들 및 상기 제2 타입의 카메라로부터 획득되는 제2 타입 영상들이 입력되면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내표적 객체가 검출되는지 여부를 식별하는 객체 인식 모델을 학습시키는 단계; 및상기 학습된 객체 인식 모델에 상기 제1 타입 영상들 및 상기 제2 타입 영상들을 입력함으로써, 상기 제1 타입영상들 및 상기 제2 타입 영상들 내 상기 표적 객체의 검출 여부를 식별하는 단계; 를 포함하고,상기 표적 객체는 연기 객체, 가스 객체 또는 불꽃 객체 중 적어도 하나를 포함하는 것을 특징으로 하는, 방법.\n【청구항 2】\n제1항에 있어서, 상기 방법은상기 제1 타입 영상들 또는 상기 제2 타입 영상들 중 적어도 하나로부터 상기 표적 객체가 검출되는 것으로 식별되는 경우, 상기 표적 객체가 검출된 타입의 영상들로부터 상기 표적 객체의 형상 정보를 추출하는 단계; 를더 포함하는, 방법.\n【청구항 3】\n제2항에 있어서,상기 제1 타입의 카메라 및 상기 제2 타입의 카메라는 각각 EO 카메라 및 OGI 카메라이고, 상기 제1 타입 학습영상들 및 상기 제1 타입 영상들은 가시광선 영상들이고, 상기 제2 타입 학습 영상들 및 상기 제2 타입 영상들은 적외선 영상들인 것을 특징으로 하는, 방법.\n【청구항 4】\n제3항에 있어서, 상기 방법은상기 제2 타입 학습 영상들 또는 상기 제2 타입 학습 영상들로부터 추출되는 스펙트럼 학습 정보에 기초하여,상기 제2 타입 영상들 또는 상기 제2 타입 영상들로부터 추출되는 스펙트럼 정보가 입력되면, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별하는 우도비 검정 모델을 학습시키는 단계; 및상기 제2 타입 학습 영상들 또는 상기 제2 타입 학습 영상들로부터 추출되는 스펙트럼 학습 정보에 기초하여,상기 제2 타입 영상들 또는 상기 제2 타입 영상들로부터 추출되는 스펙트럼 정보가 입력되면, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별하는 서포트 벡터 머신 모델을 학습시키는 단계; 를 더 포함하는, 방법.공개특허 10-2023-0168244-3-청구항 5 제4항에 있어서, 상기 방법은상기 객체 인식 모델의 출력 값에 기초하여, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내 상기 표적 객체가 검출되지 않는 것으로 식별되는 경우, 상기 제2 타입 영상들을 푸리에 변환함으로써 주파수 도메인상의 변환영상 정보를 생성하는 단계;상기 변환 영상 정보로부터 상기 표적 객체 및 상기 표적 객체 주변의 배경 간섭물질 각각에 대한 스펙트럼 정보를 추출하는 단계;상기 추출된 스펙트럼 정보를 상기 학습된 우도비 검정 모델에 입력함으로써, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별하는 단계; 및상기 표적 객체에 따른 주파수 패턴이 식별되는 경우, 상기 우도비 검정 모델의 출력 값에 기초하여, 상기 제2타입 영상들로부터 상기 표적 객체의 형상 정보를 추출하는 단계; 를 더 포함하는, 방법.\n【청구항 6】\n제5항에 있어서, 상기 방법은상기 우도비 검정 모델의 출력 값에 기초하여 상기 표적 객체에 따른 주파수 패턴이 식별되지 않는 경우, 상기추출된 스펙트럼 정보를, 상기 학습된 서포트 벡터 머신 모델에 입력함으로써, 상기 추출된 스펙트럼 정보 내상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별하는 단계; 및상기 표적 객체에 따른 주파수 패턴이 식별되는 경우, 상기 서포트 벡터 머신 모델의 출력 값에 기초하여, 상기제2 타입 영상들로부터 상기 표적 객체의 형상 정보를 추출하는 단계; 를 더 포함하는, 방법.\n【청구항 7】\n제2항에 있어서, 상기 형상 정보를 추출하는 단계는상기 표적 객체가 검출된 타입의 영상들을 전처리 하는 단계;기 설정된 표적 객체 정보에 기초하여 마스킹 데이터를 생성하는 단계;상기 표적 객체가 검출된 타입의 영상들에 상기 마스킹 데이터를 적용함으로써 생성되는 표적 객체 영역들을,상기 전처리된 영상들로부터 분리하는 단계; 및상기 분리된 표적 객체 영역들로부터 상기 표적 객체의 형상 정보를 추출하는 단계; 를 포함하는, 방법.\n【청구항 8】\n제7항에 있어서, 상기 분리된 표적 객체 영역들로부터 상기 표적 객체의 형상 정보를 추출하는 단계는상기 분리된 표적 객체 영역 내 상기 표적 객체에 관한 외곽선 정보를 식별하는 단계;상기 식별된 상기 외곽선 정보에 기초하여 표적 객체의 중심점 정보를 식별하는 단계;상기 식별된 중심점 정보 및 상기 외곽선 정보에 기초하여 상기 표적 객체 영역의 방향 벡터를 식별하는 단계;및상기 식별된 외곽선 정보, 중심점 정보 및 상기 방향 벡터를 상기 표적 객체의 형상 정보로 추출하는 단계; 를포함하는, 방법.공개특허 10-2023-0168244-4-청구항 9 제7항에 있어서, 상기 마스킹 데이터를 생성하는 단계는상기 표적 객체가 검출된 타입의 영상들의 현재 프레임 이전의 프레임 이미지들에 대한 이동 평균 값을 결정하는 단계; 및상기 결정된 이동 평균 값에 기초하여 상기 마스킹 데이터를 생성하는 단계; 를 포함하는, 방법.\n【청구항 10】\n제9항에 있어서, 상기 방법은상기 분리된 표적 객체 영역들의 형상 정보에 기초하여, 상기 표적 객체가 검출된 타입의 영상들 내 인접하는표적 객체 영역들 사이의 모션 벡터를 결정하는 단계;상기 결정된 모션 벡터에 기초하여, 상기 분리된 표적 객체 영역들을 모델링하는 단계;상기 모델링된 표적 객체 영역들을 나타내는 모션 벡터의 합벡터를 결정하는 단계; 및상기 결정된 합벡터의 크기 및 방향에 기초하여, 상기 표적 객체가 검출된 영상들에서, 상기 표적 객체가 생성된 위치에 관한 누출 원점 및 상기 표적 객체의 흐름 방향과 속도에 관한 흐름 벡터를 결정하는 단계; 를 더 포함하는, 방법.\n【청구항 11】\n제10항에 있어서, 상기 방법은상기 전자 장치와 연결된 레이저 측정기로부터 획득되는 레이저 측정 값에 기초하여, 상기 제1 타입의 카메라또는 상기 제2 타입의 카메라 중, 상기 표적 객체가 검출된 영상들을 전송한 타입의 카메라로부터 상기 누출 원점에 대응되는 상기 표적 객체가 발생한 물리적 공간까지의 거리를 결정하는 단계;상기 표적 객체가 검출된 영상들을 전송한 타입의 카메라의 팬틸트 정보를 획득하는 단계; 및상기 획득된 누출 원점, 흐름 벡터, 상기 표적 객체가 발생한 물리적 공간까지의 거리 및 상기 팬틸트 정보에기초하여, 구면 좌표계에서의 제1 좌표 값을 결정하는 단계; 를 더 포함하는, 방법.\n【청구항 12】\n제10항에 있어서, 상기 방법은상기 결정된 제1 좌표 값을 직교 좌표계의 제2 좌표 값으로 변경하는 단계;상기 제1 타입의 카메라 또는 상기 제2 타입의 카메라 중 상기 표적 객체가 검출된 영상들을 전송한 타입의 카메라에 대해 미리 설정되는 렌즈 왜곡 값을 상기 제2 좌표 값에 반영함으로써 상기 제2 좌표 값을 제3 좌표 값으로 변경하는 단계; 및상기 변경된 제3 좌표 값에 기초하여, 상기 검출된 표적 객체에 관한 제1 타입 영상들 및 상기 검출된 표적 객체에 관한 제2 타입 영상들을 합성함에 따라 생성되는 누출 영상을 미리 획득된 파노라마 영상에 합성함으로써합성 영상을 생성하는 단계; 를 포함하는, 방법.\n【청구항 13】\n인공지능 기반 가스 누출을 탐지하는 전자 장치에 있어서,네트워크 인터페이스;공개특허 10-2023-0168244-5-하나 이상의 인스트럭션을 저장하는 메모리; 및상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서; 를 포함하고,상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간에 대한 제1 타입 학습 영상들, 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간에 대한 제2타입 학습 영상들을 획득하고,상기 제1 타입 학습 영상들 및 상기 제2 타입 학습 영상들에 기초하여 학습 데이터 및 검증 데이터를 생성하고,상기 생성된 학습 데이터에 기초하여, 상기 제1 타입의 카메라로부터 획득되는 제1 타입 영상들 및 상기 제2 타입의 카메라로부터 획득되는 제2 타입 영상들이 입력되면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내표적 객체가 검출되는지 여부를 식별하는 객체 인식 모델을 학습시키고,상기 학습된 객체 인식 모델에 상기 제1 타입 영상들 및 상기 제2 타입 영상들을 입력함으로써, 상기 제1 타입영상들 및 상기 제2 타입 영상들 내 상기 표적 객체의 검출 여부를 식별하고,상기 표적 객체는 연기 객체, 가스 객체 또는 불꽃 객체 중 적어도 하나를 포함하는 것을 특징으로 하는, 전자장치.\n【청구항 14】\n제13항에 있어서, 상기 적어도 하나의 프로세서는상기 제1 타입 영상들 또는 상기 제2 타입 영상들 중 적어도 하나로부터 상기 표적 객체가 검출되는 것으로 식별되는 경우, 상기 표적 객체가 검출된 타입의 영상들로부터 상기 표적 객체의 형상 정보를 추출하는, 전자 장치.\n【청구항 15】\n제14항에 있어서, 상기 제1 타입의 카메라 및 상기 제2 타입의 카메라는 각각 EO 카메라 및 OGI 카메라이고, 상기 제1 타입 학습 영상들 및 상기 제1 타입 영상들은 가시광선 영상들이고, 상기 제2 타입 학습 영상들 및 상기제2 타입 영상들은 적외선 영상들인 것을 특징으로 하는, 전자 장치.\n【청구항 16】\n제15항에 있어서, 상기 적어도 하나의 프로세서는상기 제2 타입 학습 영상들 또는 상기 제2 타입 학습 영상들로부터 추출되는 스펙트럼 학습 정보에 기초하여,상기 제2 타입 영상들 또는 상기 제2 타입 영상들로부터 추출되는 스펙트럼 정보가 입력되면, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별하는 우도비 검정 모델을 학습시키고,상기 제2 타입 학습 영상들 또는 상기 제2 타입 학습 영상들로부터 추출되는 스펙트럼 학습 정보에 기초하여,상기 제2 타입 영상들 또는 상기 제2 타입 영상들로부터 추출되는 스펙트럼 정보가 입력되면, 상기 추출된 스펙트럼 정보 내 상기 표적 객체에 따른 주파수 패턴이 있는지 여부를 식별하는 서포트 벡터 머신 모델을 학습시키는, 전자 장치.\n【청구항 17】\n인공지능 기반 가스 누출을 탐지하는 전자 장치가 상기 가스 누출을 탐지하는 방법에 있어서,상기 전자 장치와 연결된 적어도 하나의 제1 타입의 카메라로부터 모니터링 대상 공간에 대한 제1 타입 학습 영상들, 상기 전자 장치와 연결된 적어도 하나의 제2 타입의 카메라로부터 상기 모니터링 대상 공간에 대한 제2공개특허 10-2023-0168244-6-타입 학습 영상들을 획득하는 단계;상기 제1 타입 학습 영상들 및 상기 제2 타입 학습 영상들에 기초하여 학습 데이터 및 검증 데이터를 생성하는단계;상기 생성된 학습 데이터에 기초하여, 상기 제1 타입의 카메라로부터 획득되는 제1 타입 영상들 및 상기 제2 타입의 카메라로부터 획득되는 제2 타입 영상들이 입력되면, 상기 제1 타입 영상들 및 상기 제2 타입 영상들 내표적 객체가 검출되는지 여부를 식별하는 객체 인식 모델을 학습시키는 단계; 및상기 학습된 객체 인식 모델에 상기 제1 타입 영상들 및 상기 제2 타입 영상들을 입력함으로써, 상기 제1 타입영상들 및 상기 제2 타입 영상들 내 상기 표적 객체의 검출 여부를 식별하는 단계; 를 포함하고,상기 표적 객체는 연기 객체, 가스 객체 또는 불꽃 객체 중 적어도 하나를 포함하는 것을 특징으로 하는, 방법을 수행하도록 하는 프로그램이 저장된 컴퓨터로 읽을 수 있는 기록 매체."}
{"context": "", "input": "【기술명】\n인공지능 기반의 포장용기 재고 처리 시스템\n\n【기술 설명】\n본 발명은 인공지능 기반의 포장용기 재고 처리 장치로, 포스(Point of Sale) 데이터를 수집하여 이를 인공지능 처리용으로 전처리하고, 포장용기 재고 예측 모델에 입력함으로써 생산자에게 정확한 포장용기 재고 소진 정보를 제공하는 기술입니다. 이 시스템은 사용자 주문 데이터를 기반으로 포장용기의 종류와 수량을 결정하고, 이를 활용하여 재고량을 산출합니다. 결과적으로, 관리자는 실시간으로 포장용기 재고 상태를 파악할 수 있으며, 지속적인 데이터 수집을 통해 예측 모델의 정확성을 향상시킬 수 있습니다.\n\n【해결 문제】\n현재 많은 기업들이 포장용기 재고 관리에 어려움을 겪고 있으며, 이는 생산성과 수익성에 심각한 영향을 미칩니다. 주문 데이터와 재고 데이터의 비효율적인 처리로 인해 재고 소진 예측이 부정확해지며, 이로 인해 불필요한 재고 과잉 또는 부족 현상이 발생합니다. 본 기술은 이러한 문제를 해결하기 위해 포스 데이터를 효율적으로 전처리하고, 인공지능을 활용하여 재고 소진 정보를 정확하게 예측함으로써 기업의 운영 효율성을 극대화할 수 있습니다.\n\n【기술 차별성】\n본 발명의 차별성은 기존의 재고 관리 시스템과 달리 인공지능을 활용하여 포스 데이터를 효과적으로 전처리하고, 포장용기 재고 예측 모델을 생성하는 점에 있습니다. 기존 시스템들은 수동으로 재고 데이터를 입력하고 분석하는 방식이었던 반면, 본 기술은 자동화된 데이터 수집 및 분석 과정을 통해 실시간으로 정확한 재고 소진 정보를 제공합니다. 이러한 혁신적인 접근 방식은 기업이 시장 변화에 민첩하게 대응할 수 있도록 지원하며, 재고 관리의 효율성을 크게 향상시킵니다.\n\n【활용 분야】\n본 발명의 인공지능 기반의 포장용기 재고 처리 장치는 식품 및 음료, 화장품, 제약, 전자상거래 등 다양한 산업 분야에서 활용될 수 있습니다. 특히, 신속한 소비재(CPG) 시장에서 재고 관리의 효율성을 높이는 데 기여할 수 있으며, 매장 내 포장용기 소진 예측을 통해 고객 서비스 향상 및 비용 절감 효과를 기대할 수 있습니다. 또한, 온라인 쇼핑몰과 통합하여 자동화된 재고 관리 시스템을 구현함으로써 공급망의 효율성을 극대화할 수 있습니다.\n\n【구성 요소 및 기능】\n본 장치는 크게 네 가지 주요 구성 요소로 이루어져 있습니다. 첫째, 포스 데이터 수신부는 사용자 주문 발생 시 포스 시스템으로부터 주문 데이터와 포장용기 재고 데이터를 수집합니다. 둘째, 학습 데이터 생성부는 수집된 포스 데이터를 전처리하여 인공지능 처리용 주문 데이터를 생성하며, 사용자 주문에 따른 포장용기의 종류와 수량을 결정합니다. 셋째, 포장용기 재고 소진 처리부는 기존 데이터 기반으로 요일별, 시간별 재고 변화율을 분석하여 포장용기 재고 소진 정보를 도출합니다. 마지막으로, 포장용기 재고 소진 정보 제공부는 이 정보를 관리자 단말에 실시간으로 전달하여 신속한 의사결정을 지원합니다.\n\n【구현 방식 예】\n이 기술의 구현은 단계별 접근 방식으로 진행됩니다. 첫째, 포스 시스템과의 통합을 통해 실시간으로 데이터 수집을 위한 인터페이스를 구축합니다. 둘째, 수집된 데이터의 전처리를 통해 인공지능 모델에 적합한 형식으로 변환하는 프로세스를 개발합니다. 셋째, 기계 학습 알고리즘을 활용하여 포장용기 재고 예측 모델을 훈련시키고, 이를 기반으로 실시간 재고 소진 정보를 생성합니다. 마지막으로, 관리자 단말과의 연동을 통해 실시간 알림 시스템을 구축하여 포장용기 재고 소진 정보를 효율적으로 전달하는 시스템을 완성합니다.", "output": "【발명의 명칭】\n인공지능 기반의 포장용기 재고 처리 장치\n【기술분야】\n본 발명은 인공지능 기반의 포장용기 재고 처리 장치에 관한 것으로, 보다 상세하게는, 포스(POS : Point of Sales) 데이터를 수집하고 이를 인공지능 처리용 주문데이터로 전처리하고 포장용기 재고 예측 모델에 입력하여 생산자에게 포장용기 재고 소진 정보를 제공할 수 있는 인공지능 기반의 포장용기 재고 처리 장치에 관한 것이다.\n【배경기술】\n(특허문헌 0001) 등록특허 제 10-1629191호(2016.06.03)호 발명의 내용\n【해결하려는 과제】\n본 발명의 일 실시예는 포스 데이터를 전처리하여 인공지능이 처리하게 쉽도록 하는 인공지능 기반의 포장용기 재고 처리 장치를 제공하고자 한다. 본 발명의 일 실시예는 포장용기 재고 예측 모델을 기반으로 포장용기 재고 소진 정보를 생성할 수 있는 인공지 능 기반의 포장용기 재고 처리 장치를 제공하고자 한다.\n【과제의 해결 수단】\n실시예들 중에서, 포스(POS: Point of Sales)를 통한 사용자 주문이 발생되면 상기 포스로부터 사용자 주문 데 이터와 포장용기 재고 데이터를 포함하는 포스 데이터를 수집하는 포스 데이터 수신부, 상기 포스 데이터를 전 처리하여 인공지능 처리용 주문 데이터를 생성하는 학습 데이터 생성부, 상기 인공지능 처리용 주문 데이터를 포장용기 재고 예측 모델에 입력하여 포장용기 재고 소진 정보를 결정하는 포장용기 재고 소진 처리부 및 상기 포스와 연관된 관리자 단말에 상기 포장용기 재고 소진 정보를 제공하는 포장용기 재고 소진 정보 제공부를 포 함할 수 있다. 상기 학습 데이터 생성부는 상기 사용자 주문 데이터를 기초로 사용자 주문에 따른 포장용기의 종류와 수량을 결정할 수 있다. 상기 학습 데이터 생성부는 상기 포장용기의 종류와 수량이 결정되면 상기 포장용기의 재고량을 산출하여 상기 인공지능 처리용 주문 데이터를 생성할 수 있다. 상기 포장용기 재고 소진 처리부는 기존에 수집된 인공지능 처리용 주문 데이터를 통해 요일별 시간별 재고 수 량 변화율을 기계학습하여 상기 포장용기 재고 예측 모델을 생성할 수 있다. 상기 포장용기 재고 소진 처리부는 상기 포장용기 재고 예측 모델 및 조달기간을 고려하여 발주시점을 같이 제 공하는 상기 포장용기 재고 소진 정보를 결정할 수 있다. 상기 포장용기 재고 소진 정보를 제공할 때, 포장용기 소진 전에 제작 가능한 업체를 검색하고 포장용기 제작업 체를 리스트로 결정할 수 있다. 상기 포장용기 재고 소진 정보 제공부는 검색된 포장용기 제조 업체 중 상기 관리자 단말에 의해 선택된 포장용 기 제조 업체에 예상 배송일 및 예상 단가를 요청하여 상기 예상 배송일이 상기 포장용기 소진 예상일보다 늦지 않은 경우에는 상기 관리자 단말의 승인하에 상기 포장용기 제조 업체에 포장용기 배송 주문을 신청할 수 있다. 상기 포장용기 재고 소진 정보 제공부는 상기 포장용기 재고 예측 모델을 통해 상기 포장용기와 연관되게 이용 되는 포장용기를 결정하고 상기 저장 용기 제조 업체에 주문 가능 여부를 질의하여 가능한 경우 상기 연관되게 이용되는 포장용기를 함께 주문할 수 있다.\n【발명의 효과】\n개시된 기술은 다음의 효과를 가질 수 있다. 다만, 특정 실시예가 다음의 효과를 전부 포함하여야 한다거나 다 음의 효과만을 포함하여야 한다는 의미는 아니므로, 개시된 기술의 권리범위는 이에 의하여 제한되는 것으로 이 해되어서는 아니 될 것이다. 본 발명의 일 실시예에 따른 인공지능 기반의 포장용기 재고 처리 장치는 포스 데이터를 인공지능이 처리하기 쉽도록 전처리 할 수 있다. 본 발명의 일 실시예에 따른 인공지능 기반의 포장용기 재고 처리 장치는 포장용기 재고 예측 모델을 기반으로 포장용기 재고 소진 정보를 생성하여 관리자 단말에 제공할 수 있다.\n【발명을실시하기위한구체적인내용】\n본 발명에 관한 설명은 구조적 내지 기능적 설명을 위한 실시예에 불과하므로, 본 발명의 권리범위는 본문에 설 명된 실시예에 의하여 제한되는 것으로 해석되어서는 아니 된다. 즉, 실시예는 다양한 변경이 가능하고 여러 가 지 형태를 가질 수 있으므로 본 발명의 권리범위는 기술적 사상을 실현할 수 있는 균등물들을 포함하는 것으로 이해되어야 한다. 또한, 본 발명에서 제시된 목적 또는 효과는 특정 실시예가 이를 전부 포함하여야 한다 거나 그러한 효과만을 포함하여야 한다는 의미는 아니므로, 본 발명의 권리범위는 이에 의하여 제한되는 것으로 이해 되어서는 아니 될 것이다. 한편, 본 출원에서 서술되는 용어의 의미는 다음과 같이 이해되어야 할 것이다. \"제1\", \"제2\" 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위한 것으로, 이들 용어들에 의해 권리범위가 한정되어서는 아니 된다. 예를 들어, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\"있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결될 수 도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\"있다고 언급된 때에는 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 한편, 구성요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃 하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함하는 것으로 이해되어야 하고, \"포함 하다\"또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 각 단계들에 있어 식별부호(예를 들어, a, b, c 등)는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단 계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순 서와 다르게 일어날 수 있다. 즉, 각 단계들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수 행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 본 발명은 컴퓨터가 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 코드로서 구현될 수 있고, 컴퓨터가 읽을 수 있는 기록 매체는 컴퓨터 시스템에 의하여 읽힐 수 있는 데이터가 저장되는 모든 종류의 기록 장치를 포함한 다. 컴퓨터가 읽을 수 있는 기록 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저 장 장치 등이 있다. 또한, 컴퓨터가 읽을 수 있는 기록 매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 여기서 사용되는 모든 용어들은 다르게 정의되지 않는 한, 본 발명이 속하는 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 용어들은 관 련 기술의 문맥상 가지는 의미와 일치하는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한 이 상적이거나 과도하게 형식적인 의미를 지니는 것으로 해석될 수 없다.도 1은 본 발명의 일 실시예에 따른 인공지능 기반의 포장용기 재고 처리 시스템를 설명하는 도면이다. 도 1을 참조하면, 인공지능 기반의 포장용기 재고 처리 시스템은 포스, 관리자 단말, 인공지능 기반의 포장용기 재고 처리 장치 및 데이터 베이스를 포함할 수 있다. 포스는 인공지능 기반의 포장용기 재고 처리 장치와 네트워크를 통해 연결될 수 있고 사용자 주문을 인식할 수 있는 컴퓨팅 장치에 해당할 수 있다. 예를 들어, 포스는 사용자가 피자를 주문하는 경우 사용자 주문 데이터와 포장용기 재고 데이터를 포함하는 포스 데이터를 인공지능 기반의 포장용기 재고 처리 장치(13 0)에 전송할 수 있다. 관리자 단말은 인공지능 기반의 포장용기 재고 처리 장치와 네트워크를 통해 연결될 수 있고 포장용 기 재고를 확인하고 관리하는 컴퓨팅 장치에 해당할 수 있고, 일 실시예에서, 관리자 단말은 포장용기 재 고 소진 정보 제공부를 통해 제공된 포장용기 재고 소진 정보에 대해 생산자에게 제공하기 위해 시각화 시 킬 수 있다. 관리자 단말은 반드시 이에 한정되지 않지만, 스마트폰, 노트북, 태블릿 PC 또는 컴퓨터로 구 현될 수 있다. 인공지능 기반의 포장용기 재고 처리 장치는 컴퓨팅 서버로 구현될 수 있고, 포스 및 관리자 단말 과 연동하여 인공지능 기반의 포장용기 재고 처리 장치에서 생성된 데이터를 포스 및 관리자 단 말에 전송할 수 있다. 또한, 인공지능 기반의 포장용기 재고 처리 장치는 인공지능 기반의 포장용기 재고 처리 장치에서 생성된 데이터를 데이터 베이스에 저장하여 데이터를 백업하거나 데이터를 클라 우드화 시킬 수 있다. 예를 들어, 인공지능 기반의 포장용기 재고 처리 장치는 포스를 통한 지속적인 사용자 주문의 발생에 따라 변동되는 포장용기 재고 소진 정보를 갱신하여 사용자의 제어 없이도 자동으로 데이 터를 데이터 베이스를 갱신할 수 있다. 인공지능 기반의 포장용기 재고 처리 장치는 프로세서, 메모리, 관리자 입출력부 및 네트 워크 입출력부를 포함할 수 있으며, 이에 대해서는 도 2에서 보다 자세히 설명한다. 데이터베이스는 논리적으로 연관된 하나 이상의 자료의 모음으로, 독립적으로 운용되어 단일 혹은 복수의 데이터베이스를 구성할 수 있고 여러 사람이 공유하여 사용할 목적으로 통합 또는 관리할 수 있다. 일 실시예에 서, 관리자는 데이터베이스에 저장되어 있는 포장용기 재고 소진 정보를 생산자에게 제공할 수 있다. 데이터베이스는 포장용기를 생산하는 업체의 리스트 정보를 저장할 수 있다. 예를 들어, 데이터베이스 는 특정 포장용기를 판매하는 업체의 리스트와 해당 업체의 특정 포장용기 예상 단가, 예상 발주 기간 및 생산능력을 저장할 수 있다. 다른 예를 들어, 데이터베이스는 네트워크를 통해 특정 포장용기를 판매하는 업체로부터 포장용기 생산 단가, 발주 기간 및 생산능력에 대한 정보를 입력 받아 갱신할 수 있다. 또한, 데이 터베이스는 인공지능 기반의 포장용기 재고 처리 장치의 요청 및 일정한 주기에 따라 포장용기를 판 매하는 업체의 정보를 인공지능 기반의 포장용기 재고 처리 장치에 제공할 수 있다. 도 2는 도 1에 있는 인공지능 기반의 포장용기 재고 처리 장치의 물리적 구성을 설명하는 블록도이다. 도 2를 참조하면, 인공지능 기반의 포장용기 재고 처리 장치는 프로세서, 메모리, 관리자 입출 력부 및 네트워크 입출력부를 포함한다. 프로세서는 관리자의 제어를 기초로 포장용기 재고 소진 정보를 결정하는 과정에서의 각 프로시저를 실행 할 수 있고, 그 과정 전반에서 읽혀지거나 작성되는 메모리를 관리할 수 있으며, 메모리에 있는 휘발 성 메모리와 비휘발성 메모리 간의 동기화 시간을 스케줄 할 수 있다. 프로세서는 인공지능 기반의 포장용 기 재고 처리 장치의 동작 전반을 제어할 수 있고, 메모리, 관리자 입출력부 및 네트워크 입출 력부와 전기적으로 연결되어 이들 간의 데이터 흐름을 제어할 수 있다. 프로세서는 인공지능 기반의 포장용기 재고 처리 장치의 CPU(Central Processing Unit)로 구현될 수 있다. 메모리는 SSD(Solid State Disk) 또는 HDD(Hard Disk Drive)와 같은 비휘발성 메모리로 구현되어 인공지 능 기반의 포장용기 재고 처리 장치에 필요한 데이터 전반을 저장하는데 사용되는 보조기억장치를 포함할 수 있고, RAM(Random Access Memory)과 같은 휘발성 메모리로 구현된 주기억장치를 포함할 수 있다. 관리자 입출력부는 관리자 입력을 수신하기 위한 환경 및 관리자에게 특정 정보를 출력하기 위한 환경을 포함할 수 있다. 예를 들어, 관리자 입출력부는 터치 패드, 터치 스크린, 화상 키보드 또는 포인팅 장치와같은 어댑터를 포함하는 입력장치 및 모니터 또는 터치스크린과 같은 어댑터를 포함하는 출력장치를 포함할 수 있다. 일 실시예에서, 관리자 입출력부는 원격 접속을 통해 접속되는 컴퓨팅 장치에 해당할 수 있고, 그러 한 경우, 관리자 단말은 서버로서 수행될 수 있다. 네트워크 입출력부은 네트워크를 통해 외부 장치 또는 시스템과 연결하기 위한 환경을 포함하고, 예를 들 어, LAN(Local Area Network), MAN(Metropolitan Area Network), WAN(Wide Area Network) 및 VAN(Value Added Network) 등의 통신을 위한 어댑터를 포함할 수 있다. 도 3은 도 1에 있는 인공지능 기반의 포장용기 재고 처리 장치의 기능적 구성을 설명하는 블록도이다. 도 3을 참조하면, 인공지능 기반의 포장용기 재고 처리 장치는 포스 데이터 수신부, 학습 데이터 생 성부, 포장용기 재고 소진 처리부, 포장용기 재고 소진 정보 제공부 및 제어부를 포함할 수 있다. 포스 데이터 수신부는 포스(POS: Point of Sales)를 통한 사용자 주문이 발생되면 포스로부터 사용자 주문 데이터와 포장용기 재고 데이터를 포함하는 포스 데이터를 수집할 수 있다. 예를 들어, 포스 데이터 수신부 는 사용자 주문에 따라서 사용자 주문에 필요한 포장용기의 종류 및 개수를 결정하고 주문이 발생한 시간, 장소 및 날씨에 대한 정보를 포스 데이터로 수집할 수 있다. 일 실시예에서, 포스 데이터 수신부는 포스 데이터를 전송이 가능한 형태의 파일로 변환하여 클라우드에 저장할 수 있다. 클라우드는 인공지능 기반의 포장용기 재고 처리 장치가 아닌 네트워크를 통해 연결된 다 른 장치로 데이터를 저장하거나 처리할 수 있다. 예를 들어, 포스 데이터 수신부는 포스 데이터를 클라우 드에 저장하여, 장소에 구애받지 않고 관리자 단말을 통해 포스 데이터에 대해서 접근 및 관리할 수 있다. 다른 예를 들어, 포스 데이터 수신부는 포스 데이터를 클라우드에 저장하는 과정에서, 가용 클라우드 자원 에 배치 작업을 실행할 수 있고 가용 클라우드 자원을 선별하는 과정에서 가용 클라우드 자원 간의 최소 비용 매칭으로 포스 데이터를 클라우드에 배치할 수 있다. 좀 더 구체적으로 최소 비용 매칭은 포스 데이터의 모든 태스크를 처리하고 배치하는데 소요되는 비용의 총 합이 최소가 될 수 있는 매칭 조합을 통해 결정될 수 있다. 학습 데이터 생성부는 포스 데이터를 전처리하여 인공지능 처리용 주문 데이터를 생성할 수 있다. 예를 들 어, 학습 데이터 생성부는 포스 데이터에 저장되어 있는 포장용기의 종류, 수량, 소진 시간, 소진된 장소 및 날씨에 따라서 헤더 테이블을 작성하고 그에 따른 전위 트리를 생성하여 포스 데이터를 전처리 할 수 있다. 이에 대한 자세한 설명은 도 6에서 한다. 일 실시예에서, 학습 데이터 생성부는 사용자 주문 데이터를 기초로 사용자 주문에 따른 포장용기의 종류 와 수량을 결정할 수 있다. 예를 들어, 학습 데이터 생성부는 사용자가 부대찌개를 주문하는 경우 부대찌 개 메뉴와 대응하는 국용기 1개, 반찬 용기 3개 및 공기밥 용기 1개를 결정할 수 있다. 이에 대한 자세한 설명 은 도 5에서 한다. 일 실시예에서, 학습 데이터 생성부는 포장용기의 종류와 수량이 결정되면 포장용기의 재고량을 산출하여 인공지능 처리용 주문 데이터를 생성할 수 있다. 예를 들어, 학습 데이터 생성부는 소모되는 포장용기의 종류와 수량에 따라 영세업체에 남아 있는 포장용기 재고량을 산출할 수 있다. 포장용기 재고 소진 처리부는 인공지능 처리용 주문 데이터를 포장용기 재고 예측 모델에 입력하여 포장용 기 재고 소진 정보를 결정할 수 있다. 예를 들어, 포장용기 재고 소진 처리부는 전처리된 인공지능 처리용 주문 데이터를 생산자에게 제공하기 위한 메타데이터를 생성하기위해 포장용기 재고 예측모델에 입력하여 예측 된 포장용기 재고 소진 정보를 결정할 수 있다. 일 실시예에서, 포장용기 재고 소진 처리부는 기존에 수집된 인공지능 처리용 주문 데이터를 통해 요일별 시간별 재고 수량 변화율을 기계학습하여 포장용기 재고 예측 모델을 생성할 수 있다. 예를 들어, 포장용기 재 고 소진 처리부는 수집된 인공지능 처리용 주문 데이터에서 일요일에 짜장면 용기가 많이 소모되는 경우, 반복된 인공지능 처리용 주문 데이터의 기계학습을 통해 포장용기 재고 예측 모델을 생성하고 기계학습을 통행 생성된 포장용기 재고 예측 모델을 기반으로 포장용기 재고 소진 정보를 결정할 수 있다. 일 실시예에서, 포장용기 재고 소진 처리부는 포장용기 재고 예측 모델 및 조달기간을 고려하여 발주시점 을 같이 제공하는 포장용기 재고 소진 정보를 결정할 수 있다. 포장용기 재고 소진 처리부는 포장용기 재 고 예측 모델에서 결정된 재고 소진 정보에 더해 포장용기 제조업체에서 영세업체까지의 조달기간을 고려하여한계 발주시점을 계산하여 이러한 한계 발주시점을 포함하는 포장용기 재고 소진 정보를 결정할 수 있다. 예를 들어, 포장용기 재고 소진 처리부는 특정 포장용기에 대한 조달기간이 3일이고 재고 소진 정보에 의한 재 고 소진일이 2020.8.19(수)인 경우, 주말을 제외한 2020.8.14(금)을 한계 발주시점으로 결정할 수 있다. 일 실시예에서, 포장용기 재고 소진 처리부는 포장용기 재고 소진 정보를 제공할 때, 포장용기 소진 전에 제작 가능한 업체를 검색하고 포장용기 제작업체를 리스트로 결정할 수 있다. 예를 들어, 포장용기 재고 소진 처리부는 포장용기 재고 소진 정보에 기초하여 A1용기가 부족할 것으로 예상되는 경우 해당 A1용기를 생산 하는 업체를 리스트로 결정할 수 있다. 일 실시예에서, 포장용기 재고 소진 처리부는 검색된 포장용기 제조 업체 중 관리자 단말에 의해 선택된 포장용기 제조 업체에 예상 배송일 및 예상 단가를 요청하여 예상 배송일이 포장용기 소진 예상일보다 늦지 않 은 경우에는 관리자 단말의 승인하에 포장용기 제조 업체에 포장용기 배송 주문을 신청할 수 있다. 예를 들어, 포장용기 재고 소진 처리부는 제조 업체로부터 예상 배송일 및 예상 단가를 요청하여 얻은 정보를 제조 업 체에 다시 배포하여 역경매 방식으로 다시 배송일 및 예상 단가를 요청할 수 있다. 일 실시예에서, 포장용기 재고 소진 처리부는 포장용기 재고 예측 모델을 통해 포장용기와 연관되게 이용 되는 포장용기를 결정하고 저장 용기 제조 업체에 주문 가능 여부를 질의하여 가능한 경우 연관되게 이용되는 포장용기를 함께 주문할 수 있다. 예를 들어, 포장용기 재고 소진 처리부는 배송 단가를 낮추기 위해 포장 용기 재고 예측 모델을 통해 결정된 포장용기와 연관되게 이용되는 포장용기를 같이 생산 및 발주할 수 있도록 연관 포장용기를 결정할 수 있다. 제어부는 인공지능 기반의 포장용기 재고 처리 장치의 전체적인 동작을 제어하고, 포스 데이터 수신 부, 학습 데이터 생성부, 포장용기 재고 소진 처리부 및 포장용기 재고 소진 정보 제공부 간의 제어 흐름 또는 데이터 흐름을 관리할 수 있다. 도 4는 도 1에 있는 인공지능 기반의 포장용기 재고 처리 장치에서 수행되는 발주과정을 설명하는 순서도 이다. 도 4에서, 인공지능 기반의 포장용기 재고 처리 과정은 단계들 S410 내지 S470을 포함한다. 인공지능 기반의 포장용기 재고 처리 장치는 포스 데이터 수신부를 통해 포스(POS: Point of Sale s)를 통한 사용자 주문이 발생되면 포스로부터 사용자 주문 데이터와 포장용기 재고 데이터를 포함하는 포스 데 이터를 수집할 수 있다(S410). 인공지능 기반의 포장용기 재고 처리 장치는 학습 데이터 생성부를 통해 포스 데이터를 전처리하여 인공지능 처리용 주문 데이터를 생성할 수 있다(S430). 인공지능 기반의 포장용기 재고 처리 장치는 포장용기 재고 소진 처리부를 통해 인공지능 처리용 주 문 데이터를 포장용기 재고 예측 모델에 입력하여 포장용기 재고 소진 정보를 결정할 수 있다(S450). 인공지능 기반의 포장용기 재고 처리 장치는 포장용기 재고 소진 정보 제공부를 통해 포스와 연관된 관리자 단말에 포장용기 재고 소진 정보를 제공할 수 있다(S470). 도 5는 본 발명의 일 실시예에 따른 포장상품의 식별코드에 따른 특정 포장용기의 종류 및 수량을 결정하 는 과정을 설명하는 도면이다. 도 5는 포스, 포장상품에 대응하는 특정용기 집합 테이블, 특정용기 집합 테이블 및 포장용기 재고를 포함한다. 포스는 사용자의 포장상품 주문을 입력 받고 포장상품 주문에 따른 특정용기를 대응시키는 역할을 수행한 다. 포장상품과 특정용기의 대응관계는 특정용기 집합 테이블 및 특정용기 집합 테이블에 따라 정해 진다. 포장상품에 대응하는 특정용기 집합 테이블은 포장상품의 주문에 따라 특정용기 집합을 대응관계를 나타낸 다. 예를 들어, 포장상품에 대응하는 특정용기 집합 테이블은 1번 테이블을 통해 A1 특정용기 집합과 주문 A간의 대응관계를 나타낼 수 있다. 일 실시예에서, 포스 데이터 수신부는 포장상품의 변경 또는 새로운 메뉴 개발에 따라 포장상품에 대응하는 특정용기 집합 테이블을 수정할 수 있다. 예를 들어, 포스 데이터 수 신부는 포장상품에 대응하는 특정용기 집합 테이블이 A(김치찌게)의 주문에 대해서 기존의 A1 포장용 기 집합(김치찌개 통, 공기밥 통 및 반찬통 3개)이 대응되었으나 메뉴의 변경에 따라 반찬을 5개 제공하는 경우, 포장상품에 대응하는 특정용기 집합 테이블을 A(김치찌개)의 주문에 대해서 A2 포장용기 집합(김치 찌개 통, 공기밥 통 및 반찬통 5개)을 제공하는 것으로 대응관계를 변경할 수 있다. 특정용기 집합 테이블은 각각의 특정용기 집합에 따른 특정용기의 종류 및 수량을 나타낸다. 예를 들어, 특정용기 집합 테이블은 A1 특정용기 집합과 그에 필요한 특정용기(70파이 3개, 105파이 2개, 70호 2개, 84호 1개, 젓가락 4개 및 비닐 1개)의 대응관계를 나타낼 수 있다. 일 실시예에서, 포스 데이터 수신부는 기존메뉴 변경에 따라서 포장용기 집합 A1의 구성을 변경할 수 있고, 새로운 메뉴 생성에 따라서 새로운 포장용기 집합 C1 등을 생성할 수 있다. 도 6은 데이터를 전처리 하는 과정에서 일 실시예에 따른 데이터를 헤더 테이블 및 전위 트리에 배치하는 것 을 설명하는 도면이다. 도 6를 참조하면 데이터를 헤더 테이블 및 전위 트리에 배치하는 것은 헤더 테이블 및 전위 트리 를 포함한다. 헤더 테이블는 포장 용기에 대한 정보를 저장하는 엔트리로 구성되며, 각 엔트리는 포장용기의 이름, 소진 수량, 소진시간, 소진장소, 날씨 및 링크로 구성된다. 링크는 포장 용기의 전위 트리에서의 노드 위치를 나타낸다. 전위 트리는 적어도 하나의 노드로 구성된다. 일 실시예에서, 전위 트리는 포장용기의 종류에 따라 정해질 수 있다. 예를 들어, 학습 데이터 생성부는 전위 트리에서 국그릇 집단은 B용기 집단의 구성 용기인 B1, B2 용기를 B용기 집단의 자식 노드에 위치시킬 수 있다. 상기에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특 허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다.\n【요약】본 발명은 인공지능 기반의 포장용기 재고 처리 장치에 관한 것으로, 실시예들 중에서, 포스(POS: Point of Sales)를 통한 사용자 주문이 발생되면 포스로부터 사용자 주문 데이터와 포장용기 재고 데이터를 포함하는 포스 데이터를 수집하는 포스 데이터 수신부, 포스 데이터를 전처리하여 인공지능 처리용 주문 데이터를 생성하는 학 습 데이터 생성부, 인공지능 처리용 주문 데이터를 포장용기 재고 예측 모델에 입력하여 포장용기 재고 소진 정 보를 결정하는 포장용기 재고 소진 처리부 및 포스와 연관된 관리자 단말에 포장용기 재고 소진 정보를 제공하는 포장용기 재고 소진 정보 제공부를 포함한다.\n\n【청구항 1】\n포스(POS: Point of Sales)를 통한 사용자 주문이 발생되면 상기 포스로부터 사용자 주문 데이터와 포장용기 재고 데이터를 포함하는 포스 데이터를 수집하는 포스 데이터 수신부;상기 포스 데이터를 전처리하여 인공지능 처리용 주문 데이터를 생성하는 학습 데이터 생성부;상기 인공지능 처리용 주문 데이터를 포장용기 재고 예측 모델에 입력하여 포장용기 재고 소진 정보를 결정하는포장용기 재고 소진 처리부; 및상기 포스와 연관된 관리자 단말에 상기 포장용기 재고 소진 정보를 제공하는 포장용기 재고 소진 정보 제공부를 포함하는 인공지능 기반의 포장용기 재고 처리 장치.\n【청구항 2】\n제1항에 있어서, 상기 학습 데이터 생성부는상기 사용자 주문 데이터를 기초로 사용자 주문에 따른 포장용기의 종류와 수량을 결정하는 것을 특징으로 하는인공지능 기반의 포장용기 재고 처리 장치.\n【청구항 3】\n제2항에 있어서, 상기 학습 데이터 생성부는상기 포장용기의 종류와 수량이 결정되면 상기 포장용기의 재고량을 산출하여 상기 인공지능 처리용 주문 데이터를 생성하는 것을 특징으로 하는 인공지능 기반의 포장용기 재고 처리 장치.\n【청구항 4】\n제1항에 있어서, 상기 포장용기 재고 소진 처리부는기존에 수집된 인공지능 처리용 주문 데이터를 통해 요일별 시간별 재고 수량 변화율을 기계학습하여 상기 포장용기 재고 예측 모델을 생성하는 것을 특징으로 하는 인공지능 기반의 포장용기 재고 처리 장치.\n【청구항 5】\n제4항에 있어서, 상기 포장용기 재고 소진 처리부는상기 포장용기 재고 예측 모델 및 조달기간을 고려하여 발주시점을 같이 제공하는 상기 포장용기 재고 소진 정보를 결정하는 것을 특징으로 하는 인공지능 기반의 포장용기 재고 처리 장치.\n【청구항 6】\n제5항에 있어서, 상기 포장용기 재고 소진 정보 제공부는상기 포장용기 재고 소진 정보를 제공할 때, 포장용기 소진 전에 제작 가능한 업체를 검색하고 포장용기 제작업체를 리스트로 결정하는 것을 특징으로 하는 인공지능 기반의 포장용기 재고 처리 장치.공개특허 10-2021-0036086-3-청구항 7 제6항에 있어서, 상기 포장용기 재고 소진 정보 제공부는검색된 포장용기 제조 업체 중 상기 관리자 단말에 의해 선택된 포장용기 제조 업체에 예상 배송일 및 예상 단가를 요청하여 상기 예상 배송일이 상기 포장용기 소진 예상일보다 늦지 않은 경우에는 상기 관리자 단말의 승인하에 상기 포장용기 제조 업체에 포장용기 배송 주문을 신청하는 것을 특징으로 하는 인공지능 기반의 포장용기 재고 처리 장치.\n【청구항 8】\n제7항에 있어서, 상기 포장용기 재고 소진 정보 제공부는상기 포장용기 재고 예측 모델을 통해 상기 포장용기와 연관되게 이용되는 포장용기를 결정하고 상기 저장 용기제조 업체에 주문 가능 여부를 질의하여 가능한 경우 상기 연관되게 이용되는 포장용기를 함께 주문하는 것을특징으로 하는 인공지능 기반의 포장용기 재고 처리 장치."}
{"context": "", "input": "【기술명】\n공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 시스템 및 방법\n\n【기술 설명】\n본 발명은 공간 빅데이터를 효율적으로 처리하고 활용하기 위한 분산 처리 기반 인공지능 모델 훈련 시스템 및 방법에 관한 것이다. 이 시스템은 분산 파일 시스템을 통해 대규모 공간 데이터를 저장하고 관리하며, 로컬 캐시를 활용하여 자주 사용하는 데이터를 신속하게 접근할 수 있게 설계되어 있다. 클라이언트는 특정 공간적 범위에 대한 데이터를 요청하면, 빅데이터 로더가 해당 데이터를 적재하고 이를 바탕으로 인공지능 모델 훈련을 진행한다. 이러한 구조는 대규모 데이터 처리의 효율성을 극대화하고, 사용자 맞춤형 훈련 환경을 제공한다.\n\n【해결 문제】\n최근 교통, 도시계획 등 다양한 분야에서 공간 데이터의 활용이 증가하고 있으며, 이로 인해 대량의 공간 빅데이터가 형성되고 있다. 그러나 기존의 데이터 처리 방법은 이러한 대규모 데이터를 효과적으로 관리하고 활용하는 데 한계가 있다. 본 발명은 대규모 공간 데이터를 효율적으로 탐색하고 분산 처리하여 인공지능 모델 훈련에 필요한 형태로 변환함으로써, 데이터 접근성과 처리 속도를 개선하는 것을 목표로 한다. 이는 궁극적으로 보다 정확하고 신뢰성 있는 인공지능 모델 개발을 가능하게 하여, 다양한 산업 분야의 혁신을 촉진할 수 있다.\n\n【기술 차별성】\n본 발명의 기술적 차별성은 기존의 중앙 집중형 데이터 처리 방식에서 벗어나, 공간 빅데이터를 분산 처리하여 효율성을 극대화한 데 있다. 기존 기술들은 주로 단일 파일 시스템에서 데이터를 처리하며, 대규모 데이터가 증가함에 따라 성능 저하 문제가 발생하였다. 반면, 본 발명은 분산 파일 시스템과 로컬 캐시를 조합하여 공간 데이터를 효과적으로 관리하고, 클라이언트 맞춤형 데이터 요청에 신속하게 대응할 수 있는 혁신적인 접근 방식을 제공한다. 특히, 자주 사용하는 공간 데이터를 로컬 캐시에 저장함으로써, 데이터 접근 속도를 크게 향상시켜 인공지능 모델 훈련의 효율성을 높인다.\n\n【활용 분야】\n본 발명은 공간 빅데이터를 활용하는 다양한 산업 분야에서 활용될 수 있습니다. 특히, 스마트 시티 구축, 자율 주행 차량, 환경 모니터링, 농업 및 물류 관리와 같은 분야에서 인공지능 모델 훈련에 필수적인 공간 데이터를 효율적으로 처리하고 분석하는 데 기여할 수 있습니다. 이러한 시스템은 대규모 데이터 처리 및 모델 훈련의 필요성이 증가하고 있는 현대 비즈니스 환경에서 경쟁력을 갖춘 솔루션을 제공합니다. 결국, 본 발명은 데이터 기반 의사결정을 지원하여 기업의 혁신을 가속화하는 데 중요한 역할을 할 것입니다.\n\n【구성 요소 및 기능】\n본 발명의 주요 구성 요소는 다음과 같습니다. 첫째, 분산 파일 시스템은 대규모 공간 빅데이터를 저장하고 관리하는 역할을 하며, 데이터의 확장성과 접근성을 보장합니다. 둘째, 로컬 캐시는 자주 사용되는 공간 데이터를 저장하여 빠른 데이터 접근을 가능하게 하며, 데이터 처리를 최적화합니다. 셋째, 빅데이터 로더는 클라이언트의 요청에 따라 적절한 공간 데이터를 탐색하고 제공하여 인공지능 모델 훈련의 효율성을 극대화합니다. 이러한 구성 요소들은 상호 연동하여 공간 빅데이터의 효과적인 활용을 지원합니다.\n\n【구현 방식 예】\n본 발명의 구현 방식은 여러 단계로 구성됩니다. 첫째, 분산 파일 시스템에 대규모 공간 데이터를 저장하고, 해당 데이터를 로컬 캐시에 필요한 만큼 적재하는 단계가 있습니다. 둘째, 클라이언트가 공간 빅데이터 학습 모델 요청을 보내면, 빅데이터 로더가 요청된 공간적 범위를 기반으로 로컬 캐시 또는 분산 파일 시스템에서 데이터를 탐색하여 적재합니다. 셋째, 클라이언트는 적재된 공간 데이터를 이용하여 인공지능 모델을 생성하고 훈련하며, 이 과정에서 사용자 정의 레이어 구조 및 하이퍼 파라미터를 적용하여 최적의 모델을 개발합니다. 이러한 단계적 접근 방식은 시스템의 유연성과 효율성을 보장합니다.", "output": "【발명의 명칭】\n공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 시스템 및 방법\n【기술분야】\n본 발명은 공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 시스템 및 방법에 관한 것이다.\n【배경기술】\n최근 들어 교통, 도시계획 등 다양한 분야에서 공간 데이터를 활용하여 도로 객체 검출, 지형 변화 감지 등을 위한 다양한 인공지능 모델(artificial intelligence model)을 개발하고 있다. 앞으로 공간 데이터가 축적되어 테라바이트(TB), 페타바이트(PB) 크기의 빅데이터가 형성된다면 파일 시스템에 서 데이터를 불러와 인공지능 모델을 훈련하는데 한계가 있다. 따라서 공간 빅데이터 환경에서 데이터를 효율적으로 탐색하고, 분산 처리하여 학습에 필요한 형태로 데이터를 변환한 뒤 이를 인공지능 모델 훈련에 적용할 수 있는 시스템이 요구되고 있다.\n【해결하려는 과제】\n따라서 본 발명이 해결하고자 하는 과제는 공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 시스템 및 방법을 제공하는 것이다.\n【과제의 해결 수단】\n상기한 기술적 과제를 해결하기 위한 본 발명에 따른 공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 시스템 은 공간 빅데이터를 저장하는 분산 파일 시스템, 상기 분산 파일 시스템에 저장된 공간 빅데이터 중 일부를 저 장하는 로컬 캐시, 및 클라이언트로부터 공간 빅데이터 학습 모델 요청에 기초하여 결정되는 공간적 범위에 해 당하는 공간 데이터를 상기 분산 파일 시스템 또는 상기 로컬 캐시에서 탐색하여 적재한 후 상기 클라이언트에 제공하는 빅데이터 로더를 포함한다. 상기 클라이언트는 상기 빅데이터 로더에서 제공된 공간 데이터를 이용하여 상기 공간 빅데이터 학습 모델에 대 한 훈련을 진행한다. 상기 빅데이터 로더는, 상기 공간적 범위에 해당하는 공간 인덱스를 구하고, 상기 공간 인덱스를 가진 공간 데 이터가 상기 로컬 캐시에 저장되어 있으면, 상기 로컬 캐시로부터 상기 공간 데이터를 적재하며, 상기 공간 인 덱스를 가진 공간 데이터가 상기 로컬 캐시에 저장되어 있지 않으면, 상기 분산 파일 시스템으로부터 상기 공간 데이터를 탐색하여 적재할 수 있다. 상기 빅데이터 로더는, 상기 적재된 공간 데이터를 상기 클라이언트의 메모리 크기로 분할한 복수 개의 공간 데 이터 셋을 생성하고, 상기 생성된 복수 개의 공간 데이터 셋을 상기 클라이언트에 순차적으로 제공할 수 있다. 상기 클라이언트는, 사용자로부터 입력된 레이어 구조 및 하이퍼 파라미터를 포함하는 모델 구성 정보에 따른 인공지능 모델을 생성하는 모델 생성부, 및 상기 인공지능 모델을 상기 빅데이터 로더로부터 순차적으로 제공받 은 공간 데이터를 이용하여 훈련하는 모델 훈련부를 포함할 수 있다. 상기한 기술적 과제를 해결하기 위한 본 발명에 따른 공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 방법은, 클라이언트로부터 공간 빅데이터 학습 모델 요청에 기초하여 공간 빅데이터 학습 모델의 학습에 이용되 는 공간 데이터의 공간적 범위에 해당하는 공간 데이터를 분산 파일 시스템 또는 로컬 캐시에서 탐색하여 적재 하는 단계, 상기 적재된 공간 데이터를 상기 클라이언트에 제공하는 단계, 및 상기 클라이언트에서 상기 공간 데이터를 이용하여 상기 공간 빅데이터 학습 모델에 대한 훈련을 진행하는 단계를 포함한다.상기 공간 데이터를 탐색하여 적재하는 단계는, 상기 공간적 범위에 해당하는 공간 인덱스를 구하는 단계, 상기 공간 인덱스를 가진 공간 데이터가 상기 로컬 캐시에 저장되어 있으면, 상기 로컬 캐시로부터 상기 공간 데이터 를 적재하는 단계, 및 상기 공간 인덱스를 가진 공간 데이터가 상기 로컬 캐시에 저장되어 있지 않으면, 상기 분산 파일 시스템으로부터 상기 공간 데이터를 탐색하여 적재하는 단계를 포함할 수 있다. 상기 적재된 공간 데이터를 상기 클라이언트에 제공하는 단계는, 상기 적재된 공간 데이터를 상기 클라이언트의 메모리 크기로 분할한 복수 개의 공간 데이터 셋을 생성하고, 상기 생성된 복수 개의 공간 데이터 셋을 상기 클 라이언트에 순차적으로 제공할 수 있다. 상기 공간 빅데이터 학습 모델에 대한 학습을 진행하는 단계는, 상기 클라이언트에서 사용자로부터 입력된 레이 어 구조 및 하이퍼 파라미터을 포함하는 모델 구성 정보에 따른 인공지능 모델을 생성하는 단계, 및 상기 클라 이언트에서 상기 인공지능 모델을 상기 순차적으로 제공되는 공간 데이터를 이용하여 훈련하는 단계를 포함할 수 있다. 상기한 기술적 과제를 해결하기 위한 본 발명에 따른 컴퓨터로 읽을 수 있는 기록매체는, 컴퓨터에 상기 방법을 실행시키기 위한 프로그램을 기록할 수 있다.\n【발명의 효과】\n본 발명에 의하면 대규모 공간 데이터를 분산 처리 방법을 이용하여 효율적으로 분산 파일 시스템에서 가져와 인공지능 모델의 훈련에 적용할 수 있다. 특히 사용자의 학습 환경(CPU/Memory)에 맞게 공간 데이터를 분할하 고 이를 순차적으로 호출하여 인공지능 모델의 훈련 입력 값으로 활용할 수 있다. 또한 자주 쓰는 공간 데이터 들을 로컬 캐시(local cache)에 파일 형태로 보관하고, 관리할 수 있다.\n【발명을실시하기위한구체적인내용】\n그러면 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 도 1은 본 발명의 일 실시예에 따른 공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 시스템의 구성도이다. 도 1을 참고하면, 본 발명의 일 실시예에 따른 공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 시스템 은 분산 파일 시스템, 로컬 캐시, 빅데이터 로더 및 클라이언트를 포함할 수 있다. 분산 파일 시스템, 로컬 캐시, 빅데이터 로더 및 클라이언트는 통신망을 통해 각종 정보 및 데이터를 교환할 수 있다. 통신망은 구내 정보 통신망(Local Area Network, LAN), 도시권 통신망(Metropolitan Area Network, MAN), 광역 통신망(Wide Area Network, WAN), 인터넷(internet), 3G(generation), 4G, 5G 이동통신망, 와이파이(Wi-Fi), WIBRO(Wireless Broadband Internet) 등을 포함하는 각종 데이터 통신망이나, 공중전화망(public switched telephone network)을 포함할 수 있다. 네트워크는 유선과 무선을 가리지 않으며 어떠한 통신 방식을 사용 하더라도 상관없다. 분산 파일 시스템은 공간 빅데이터를 저장한다. 분산 파일 시스템은 대용량 파일을 저장하고 처리하 기 위해서 개발된 HDFS(Hadoop Distributed File System) 같은 시스템으로 구현할 수 있다. 로컬 캐시는 분산 파일 시스템에 저장된 공간 빅데이터 중 일부를 저장하는 기능을 수행한다. 빅데이터 로더는 클라이언트로부터 공간 빅데이터 학습 모델 요청에 기초하여 결정되는 공간적 범위 에 해당하는 공간 데이터를 분산 파일 시스템 또는 로컬 캐시에서 탐색하여 적재한 후 클라이언트 에 제공한다. 예를 들어 서울시에 대한 공간 빅데이터 학습 모델을 생성하려고 하는 경우, 공간적 범위는 서울시 전체로 결정될 수 있다. 실시예에 따라서 로컬 캐시와 빅데이터 로더는 하나의 서버 장치에 구축될 수 있다. 클라이언트는 빅데이터 로더에서 제공된 공간 데이터를 이용하여 공간 빅데이터 학습 모델에 대한 훈 련을 진행하고, 훈련된 공간 빅데이터 학습 모델을 생성할 수 있다. 클라이언트는 데스크탑 컴퓨터, 노트 북 등과 같은 컴퓨팅 장치로 구현할 수 있다. 빅데이터 로더는 공간적 범위에 해당하는 공간 인덱스를 구하고, 공간 인덱스를 가진 공간 데이터가 로컬 캐시에 저장되어 있으면, 로컬 캐시로부터 해당하는 공간 데이터를 적재할 수 있다. 또한 빅데이터 로더는 공간 인덱스를 공간 데이터가 로컬 캐시에 저장되어 있지 않으면, 분산 파일 시스템으로 부터 공간 데이터를 탐색하여 적재할 수 있다. 보다 자세하게는 빅데이터 로더는 자주 사용하는 공간 데이터를 로컬 캐시에 미리 일정량 만큼 저장 관리하고, 로컬 캐시에 공간 인데스를 가진 데이터가 존재하면 캐시된 데이터를적재한다. 만약 로컬 캐시 에 없는 공간 인덱스에 해당하는 데이터들은 미리 분산 파일 시스템에서 탐색을 실행하기 위해 최적 화된 디렉토리에서 데이터 적재를 수행할 수 있다. 한편 빅데이터 로더는 적재된 공간 데이터를 클라이언트의 학습 환경, 예컨대 클라이언트의 CPU, 메모리에 맞게 분할하여, 클라이언트에서 공간 빅데이터 학습 모델에 대한 훈련이 원활하게 이루어지 도록 순차 제공할 수 있다. 예를 들어 빅데이터 로더는 클라이언트의 메모리 크기로 분할한 복수 개 의 공간 데이터 셋을 생성하고, 상기 생성된 복수 개의 공간 데이터 셋을 클라이언트에 순차적으로 제공할 수 있다. 클라이언트는 모델 생성부 및 모델 훈련부를 포함할 수 있다. 모델 생성부는 사용자로부터 입력된 레이어 구조 및 하이퍼 파라미터를 포함하는 모델 구성 정보에 따른 인공지능 모델을 생성할 수 있다. 보다 자세하게는 모델 구성 정보는 레이어 세부 사항, 활성화 함수, 레이어 수, 하이퍼 파라미터, DNN, CNN, RNN 등의 레이어 구조 정보 등을 포함할 수 있다. 모델 훈련부는 모델 생성부에서 생성된 인공지능 모델을 빅데이터 로더로부터 제공받은 공간 데 이터를 이용하여 훈련할 수 있다. 그리고 공간 데이터의 크기가 커서 순차적으로 분할 제공되는 경우, 모델 훈 련부는 분할 제공된 공간 데이터를 순차적으로 인공지능 모델을 훈련시킬 수 있다. 클라이언트는 훈련된 인공지능 모델, 즉 공간 빅데이터 학습 모델 및 훈련 정보를 사용자에게 보고할 수 있다. 도 2는 본 발명의 일 실시예에 따른 공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 방법의 흐름도이다. 먼저 빅데이터 로더는 클라이언트로부터 공간 빅데이터 학습 모델 요청에 기초하여 공간 빅데이터 학 습 모델의 학습에 이용되는 공간 데이터의 공간적 범위에 해당하는 공간 데이터를 분산 파일 시스템 또는 로컬 캐시에서 탐색하여 적재할 수 있다(S210). 단계(S210)를 보다 자세히 설명하면, 빅데이터 로더는 공간 빅데이터 학습 모델에 이용되는 공간적 범위에 해당하는 공간 인덱스를 구한다. 다음으로 빅데이터 로더는 공간 인덱스를 가진 공간 데이터가 로컬 캐시 에 저장되어 있으면, 로컬 캐시로부터 공간 데이터를 적재할 수 있다. 한편 빅데이터 로더는 공 간 인덱스를 가진 공간 데이터가 로컬 캐시에 저장되어 있지 않으면, 분산 파일 시스템으로부터 공간 데이터를 탐색하여 적재할 수 있다. 도 3은 본 발명의 일 실시예에 따른 공간 데이터 탐색을 설명하기 위한 도면이다. 도 3을 참고하면, 예를들어 서울시 전체를 학습 모델에 적용하는 경우, 빅데이터 로더는 서울시 전체를 커 버하는 공간적 범위의 좌하단 좌표(36.4, 127.2)와 우상단 좌표(37.2, 128.3)를 공간 인덱스(121, 446)로 변환 하고, 조건문에 공간 인덱스가 121과 446 사이에 존재하는 모든 공간 데이터를 분산 파일 시스템 또는 로 컬 캐시에서 탐색하여 적재할 수 있다. 로컬 캐시에서 먼저 탐색하여 적재하되 로컬 캐시에 해당 공간 데이터가 없는 경우 분산 파일 시스템에서 탐색하여 적재할 수 있다. 다시 도 2를 참고하면, 빅데이터 로더는 적재된 공간 데이터를 클라이언트에 제공할 수 있다(S220). 빅데이터 로더는 적재된 공간 데이터를 클라이언트의 메모리 크기로 분할한 복수 개의 공간 데이터 셋을 생성하고, 생성된 복수 개의 공간 데이터 셋을 클라이언트에 순차적으로 제공할 수 있다. 도 4는 본 발명의 일 실시예에 따른 공간 데이터 분할을 설명하기 위한 도면이다. 도 4를 참고하면, 적재된 공간 데이터의 크기가 40GB이고, 클라이언트의 메모리 크기가 4GB이면, 빅데이터 로더는 적재된 공간 데이터를 10개 이상으로 분할하여 순차적으로 클라이언트에 제공할 수 있다. 다시 도 2를 참고하면, 클라이언트에서 공간 데이터를 이용하여 공간 빅데이터 학습 모델에 대한 훈련을 진행할 수 있다(S230). 먼저 클라이언트는 사용자로부터 입력된 레이어 구조 및 하이퍼 파라미터를 포함하는 모델 구성 정보에 따 른 인공지능 모델을 생성할 수 있다. 이후 클라이언트는 생성된 인공지능 모델을 빅데이터 로더로부 터 제공받은 공간 데이터를 이용하여 훈련할 수 있다. 그리고 공간 데이터의 크기가 커서 순차적으로 분할 제공 되는 경우, 모델 훈련부는 분할 제공된 공간 데이터를 순차적으로 인공지능 모델을 훈련시킬 수 있다. 다시 도 2를 참고하면, 마지막으로 클라이언트는 훈련된 인공지능 모델, 즉 공간 빅데이터 학습 모델 및 훈련 정보를 사용자에게 보고할 수 있다(S240). 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터 를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매 체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD- ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다.이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다.\n【요약】본 발명은 공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 시스템 및 방법에 관한 것으로, 본 발명에 따른 시 스템은 공간 빅데이터를 저장하는 분산 파일 시스템, 분산 파일 시스템에 저장된 공간 빅데이터 중 일부를 저장 하는 로컬 캐시, 및 클라이언트로부터 공간 빅데이터 학습 모델 요청에 기초하여 결정되는 공간적 범위에 해당하 (뒷면에 계속)\n\n【청구항 1】\n공간 빅데이터를 저장하는 분산 파일 시스템,상기 분산 파일 시스템에 저장된 공간 빅데이터 중 일부를 저장하는 로컬 캐시, 및클라이언트로부터 공간 빅데이터 학습 모델 요청에 기초하여 결정되는 공간적 범위에 해당하는 공간 데이터를상기 분산 파일 시스템 또는 상기 로컬 캐시에서 탐색하여 적재한 후 상기 클라이언트에 제공하는 빅데이터 로더를 포함하고,상기 클라이언트는 상기 빅데이터 로더에서 제공된 공간 데이터를 이용하여 상기 공간 빅데이터 학습 모델에 대한 훈련을 진행하는 공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 시스템.\n【청구항 2】\n제 1 항에서,상기 빅데이터 로더는,상기 공간적 범위에 해당하는 공간 인덱스를 구하고, 상기 공간 인덱스를 가진 공간 데이터가 상기 로컬 캐시에 저장되어 있으면, 상기 로컬 캐시로부터 상기 공간데이터를 적재하며,상기 공간 인덱스를 가진 공간 데이터가 상기 로컬 캐시에 저장되어 있지 않으면, 상기 분산 파일 시스템으로부터 상기 공간 데이터를 탐색하여 적재하는 공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 시스템.\n【청구항 3】\n제 2 항에서,상기 빅데이터 로더는,상기 적재된 공간 데이터를 상기 클라이언트의 메모리 크기로 분할한 복수 개의 공간 데이터 셋을 생성하고, 상기 생성된 복수 개의 공간 데이터 셋을 상기 클라이언트에 순차적으로 제공하는 공간 빅데이터 분산 처리 기반인공지능 모델 훈련 시스템.\n【청구항 4】\n제 3 항에서,상기 클라이언트는,사용자로부터 입력된 레이어 구조 및 하이퍼 파라미터를 포함하는 모델 구성 정보에 따른 인공지능 모델을 생성하는 모델 생성부, 및상기 인공지능 모델을 상기 빅데이터 로더로부터 순차적으로 제공받은 공간 데이터를 이용하여 훈련하는 모델훈련부공개특허 10-2023-0055758-3-를 포함하는 공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 시스템.\n【청구항 5】\n클라이언트로부터 공간 빅데이터 학습 모델 요청에 기초하여 공간 빅데이터 학습 모델의 학습에 이용되는 공간데이터의 공간적 범위에 해당하는 공간 데이터를 분산 파일 시스템 또는 로컬 캐시에서 탐색하여 적재하는단계,상기 적재된 공간 데이터를 상기 클라이언트에 제공하는 단계, 및상기 클라이언트에서 상기 공간 데이터를 이용하여 상기 공간 빅데이터 학습 모델에 대한 훈련을 진행하는 단계를 포함하는 공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 방법.\n【청구항 6】\n제 5 항에서,상기 공간 데이터를 탐색하여 적재하는 단계는,상기 공간적 범위에 해당하는 공간 인덱스를 구하는 단계,상기 공간 인덱스를 가진 공간 데이터가 상기 로컬 캐시에 저장되어 있으면, 상기 로컬 캐시로부터 상기 공간데이터를 적재하는 단계, 및상기 공간 인덱스를 가진 공간 데이터가 상기 로컬 캐시에 저장되어 있지 않으면, 상기 분산 파일 시스템으로부터 상기 공간 데이터를 탐색하여 적재하는 단계를 포함하는 공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 방법.\n【청구항 7】\n제 6 항에서,상기 적재된 공간 데이터를 상기 클라이언트에 제공하는 단계는,상기 적재된 공간 데이터를 상기 클라이언트의 메모리 크기로 분할한 복수 개의 공간 데이터 셋을 생성하고, 상기 생성된 복수 개의 공간 데이터 셋을 상기 클라이언트에 순차적으로 제공하는 공간 빅데이터 분산 처리 기반인공지능 모델 훈련 방법.\n【청구항 8】\n제 7 항에서,상기 공간 빅데이터 학습 모델에 대한 학습을 진행하는 단계는,상기 클라이언트에서 사용자로부터 입력된 레이어 구조 및 하이퍼 파라미터을 포함하는 모델 구성 정보에 따른인공지능 모델을 생성하는 단계, 및상기 클라이언트에서 상기 인공지능 모델을 상기 순차적으로 제공되는 공간 데이터를 이용하여 훈련하는 단계를 포함하는 공간 빅데이터 분산 처리 기반 인공지능 모델 훈련 방법.\n【청구항 9】\n컴퓨터에 제5항 내지 제8항 중 어느 한 방법을 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록공개특허 10-2023-0055758-4-매체."}
{"context": "", "input": "【기술명】\n설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고서 자동 시스템\n\n【기술 설명】\n본 발명은 설명가능 인공지능(XAI) 기반의 SaaS 플랫폼을 통해 댐시설물의 결함을 자동으로 검출, 정량화, 캡셔닝, 도면화 및 상태평가 보고서를 생성하는 혁신적인 기술입니다. 해당 플랫폼은 댐시설물의 균열 및 결함 정보를 영상으로 수집하여 인공지능 알고리즘을 이용해 정밀하게 분석합니다. 이를 통해 사용자는 웹 브라우저를 통해 별도의 소프트웨어 설치 없이 손쉽게 댐시설물 상태를 점검하고, 신뢰할 수 있는 데이터 기반의 결함 정보를 얻을 수 있습니다.\n\n【해결 문제】\n기존의 댐시설물 결함 검출 방식은 주관적인 육안검사, 낮은 성능의 룰베이스 알고리즘, 그리고 블랙박스형 딥러닝 알고리즘에 의존하여 신뢰성 부족 및 검출 성능 저하라는 문제를 안고 있었습니다. 본 발명은 이러한 문제를 해결하기 위해 설계되었으며, 설명가능 인공지능을 활용하여 댐시설물의 결함을 명확히 검출하고 정량화함으로써 사용자에게 투명한 결과를 제공합니다. 이 기술은 댐시설물의 안전성을 높이고, 조기 발견을 통한 사고 예방 및 유지보수 비용 절감을 가능하게 합니다.\n\n【기술 차별성】\n본 발명의 차별점은 설명가능 인공지능을 활용하여 결함 검출의 근거를 명확히 제공하는 것입니다. 기존 기술들이 블랙박스처럼 작동하여 결과 해석이 불가능한 반면, 본 기술은 인공지능 모델의 추론 과정 및 이유를 사용자에게 설명할 수 있는 기능을 갖추고 있습니다. 또한, UAV 촬영을 통해 수집된 3차원 포인트 클라우드 데이터를 활용하여 더욱 깊이 있는 결함을 검출하며, 트랜스퍼 러닝 기법을 통해 지속적으로 성능을 향상시킬 수 있는 혁신성을 보유하고 있습니다. 이러한 점에서 본 발명은 댐시설물 결함 검출 분야에서 획기적인 발전을 이루고 있습니다.\n\n【활용 분야】\n본 발명은 댐시설물 안전 점검 및 유지 관리 분야에 특히 유용하게 활용될 수 있다. 수력 발전소, 농업용 저수지, 도시 수자원 관리 시스템 등 다양한 분야에서 댐의 구조적 안전성을 평가하는 데 필요한 기술적 솔루션을 제공한다. 또한, 환경 보호 및 재해 예방을 위한 공공 안전 관리 시스템에서도 필수적인 요소로 작용하며, 기업의 운영 효율성을 높이고 인명 피해를 최소화하는 데 기여할 수 있다.\n\n【구성 요소 및 기능】\n본 발명의 주요 구성 요소는 다음과 같다:  \n1. **설명가능 인공지능 모듈**: 이 모듈은 댐시설물의 균열 및 결함 정보를 영상으로 획득하고, 인공지능 알고리즘을 통해 이를 검출 및 정량화한다. 이를 통해 사용자는 결함의 위치와 심각성을 정확히 이해할 수 있다.  \n2. **SaaS 플랫폼**: 웹 기반의 솔루션으로, 사용자는 별도의 소프트웨어 설치 없이 웹 브라우저를 통해 시스템에 접근할 수 있다. 이 플랫폼은 촬영된 영상을 업로드하고, 인공지능 모델의 처리 결과를 다운로드하며, 사용자 친화적인 인터페이스를 통해 결과를 시각화한다.  \n3. **데이터 시각화 및 보고서 생성 모듈**: 이 모듈은 인공지능 처리 결과를 히트맵 및 캡셔닝 형태로 시각화하여, 사용자가 결함의 특성과 강도를 한눈에 파악할 수 있도록 돕는다. 또한, 상태 평가 보고서를 자동으로 생성하여 효율적인 관리 및 의사 결정을 지원한다.\n\n【구현 방식 예】\n본 발명의 구현은 다음 단계로 이루어진다:  \n1. **데이터 수집**: UAV(무인 항공기)를 통해 댐시설물의 표면을 촬영하고, 겹침 촬영을 통해 3차원 포인트 클라우드 데이터를 생성한다.  \n2. **영상 처리 및 분석**: 수집된 데이터를 설명가능 인공지능 모듈에 입력하여 균열 및 결함을 검출하고 정량화하는 과정을 거친다. 이 과정에서 인공지능 모델은 트랜스퍼 러닝을 통해 지속적으로 성능을 개선한다.  \n3. **결과 시각화 및 보고서 작성**: 처리된 결과는 히트맵 형태로 시각화되며, 사용자는 이를 기반으로 상태 평가 보고서를 자동으로 생성할 수 있다. 이러한 결과는 온라인으로 다운로드 가능하여, 실시간으로 의사 결정을 지원한다.", "output": "【발명의 명칭】\n설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고서 자동\n【기술분야】\n본 발명은 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고서 자동 작성을 위한 SaaS(Software as a Service) 플랫폼 장치에 관한 것이다.\n【배경기술】\n종래 기술에 따르면, 댐시설물의 결함을 검출하기 위해 주관적인 육안검사 방법, 성능이 낮은 룰베이스 알고리 즘 기반 방법, 추론이유를 설명하지 못하는 블랙박스와 같은 딥러닝 알고리즘 기반 방법을 이용하였으나, 이들은 검출 성능이 부족하거나 검출 결과에 대해 신뢰하기 어려운 문제점이 있다.\n【해결하려는 과제】\n본 발명은 전술한 문제점을 해결하기 위해 제안된 것으로, 댐시설물의 균열, 결함을 포함한 영상을 이용하여 설 명가능 인공지능 알고리즘을 학습시킨 후, 균열/결함 검출 및 정량화 성능을 높이고, 웹 서비스(Web Service) 기반의 SaaS플랫폼을 제공하는데 그 목적이 있다.\n【과제의 해결 수단】\n본 발명에 따른 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고서 자동 작성을 위한 SaaS 플랫폼 장치는 설명가능 인공지능 및 SaaS 플랫폼 기반 댐시설물 안전점검 프로그램이 저장된 메모리 및 프로그램을 실행시키는 프로세서를 포함하되, 프로세서는 댐시설물의 균열 및 결함 정보를 영상을 통 해 획득하고, 이를 인공지능 기반으로 검출하고 정량화하고, 온라인을 통해 댐시설물 촬영영상을 플랫폼에 업로 드하고, 인공지능 모델에 의한 영상처리 결과를 온라인으로 다운로드한다. 상기 프로세서는 별도 소프트웨어 설치 없이 웹 브라우저를 통해 솔루션을 사용한다. 상기 결함 정보는 박리, 박락, 파손, 누수, 백태, 철근노출, 재료분리 중 적어도 어느 하나를 포함한다. 상기 프로세서는 UAV로 댐시설물의 표면을 겹침 촬영한 후 이동식 스테레오 이미징 알고리즘 기반으로 획득한 3 차원 포인트 클라우드 및 영상을 이용하여 박락, 철근노출 중 적어도 어느 하나를 포함하는 깊이가 있는 결함의 검출을 수행한다. 상기 프로세서는 상기 인공지능 모델에 의한 영상처리 결과의 추론 과정 및 이유를 기설정된 언어의 문장으로 제공하고, 특징의 강도를 기설정 색깔로 구성된 등고선 지도로 시각화하는 히트맵을 출력하여, 설명가능 인공지 능 기반으로 상기 균열 및 결함의 검출을 수행한다. 상기 프로세서는 상기 균열 및 결함 정보의 위치, 형상, 크기를 시각화하고, 댐시설물의 부재별로 도면화한다. 상기 프로세서는 댐시설물의 대표적인 균열 및 결함과 관련된 벤치마크 데이터셋으로 객체에 대한 히트맵 및 캡 셔닝 성능을 향상시킨다. 상기 프로세서는 트랜스퍼 러닝을 통해 다른 인공지능 모델에 가중치 행렬을 이전시킨다. 상기 프로세서는 댐시설물 표면에 매칭되는 인공지능 필터를 이용하여, 오염된 댐시설물 표면에 포함된 균열 및 결함 정보의 검출을 수행하고, 정밀도를 향상시킨다.\n【발명의 효과】\n본 발명의 효과는 이상에서 언급한 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다.\n【발명을실시하기위한구체적인내용】\n본 발명의 전술한 목적 및 그 이외의 목적과 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있 으며, 단지 이하의 실시예들은 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 목적, 구성 및 효과를 용이하게 알려주기 위해 제공되는 것일 뿐으로서, 본 발명의 권리범위는 청구항의 기재에 의해 정의 된다. 한편, 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한 다(comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성소자, 단계, 동작 및/또는 소자가 하나 이상의 다른 구성소자, 단계, 동작 및/또는 소자의 존재 또는 추가됨을 배제하지 않는다. 댐시설물에 발생하는 입체적인 결함은 균열, 백태, 누수, 재료분리 등 표면 결함과는 달리 결함 부위와 배경의 색상 차이가 없고, 경계가 뚜렷하지 않아 영상 및 2D 기반 인공지능 알고리즘으로 해당 결함을 검출하기가 매우어렵다. 본 발명의 실시예에 따르면, 강재의 박리, 박락, 철근노출, 파손 등 표면결함과 구분되고 입체적으로 표현할 수 있는 결함에 대해 두 장의 영상을 겹쳐 촬영해 겹침 영역의 특징을 추출하고 이 특징 기반으로 두 장의 영상을 매칭한 후 SfM(Structure from Motion) 알고리즘 기반으로 포인트클라우드로 입체화하는 스테레오 이미징 기법 을 적용한다. 미세한 변형 등 결함의 정도가 크지 않아 입체화가 어려운 경우 2D 기반 인공지능 알고리즘의 검출결과와 합성 히여 정확도를 향상시키는 것이 가능하다. 본 발명의 실시예에 따르면, 기존 딥러닝 알고리즘의 문제점을 해결하기 위하여 제안된 것으로, XAI, 포인트 클 라우드 기반으로 댐시설물의 균열 및 결함 검출을 수행함으로써, 2D 기반 딥 뉴럴 네트워크의 단점인 성능향상 의 한계, 추론이유 설명불가, 결함의 입체화 불가, 긴 연산시간 문제를 해결하는 것이 가능하다. 도 1은 본 발명의 실시예에 따른 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화를 위한 인공지능 모델 구 성도이고, 도 2는 본 발명의 실시예에 따른 설명가능 인공지능 기반 댐시설물 결함 검출 결과의 예를 도시하고, 도 3은 본 발명의 실시예에 따른 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화를 위한 인공지능 모델의 플로우차트를 도시하고, 도 4는 본 발명의 실시예에 따른 설명가능 인공지능 기반 댐시설물 히트맵 및 캡셔닝 결과의 예를 도시하고, 도 5는 본 발명의 실시예에 따른 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 자동 작성을 위한 SaaS 플랫폼 장치의 구성을 도시한다. 도 6은 본 발명의 실시예에 따른 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평 가 자동 작성을 위한 SaaS 플랫폼의 초기 화면을 도시하고, 도 7은 본 발명의 실시예에 따른 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 자동 작성을 위한 SaaS 플랫폼의 프리프로세싱 화 면을 도시하고, 도 8은 본 발명의 실시예에 따른 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 자동 작성을 위한 SaaS 플랫폼의 파노라마 생성 화면을 도시하고, 도 9는 본 발명의 실시예에 따른 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 자동 작성을 위한 SaaS 플랫폼의 결함검출 화면을 도시하고, 도 10은 본 발명의 실시예에 따른 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 자동 작성을 위한 SaaS 플랫폼의 댐시설물 정보 입력을 위한 설정 화 면을 도시하고, 도 11은 본 발명의 실시예에 따른 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 자동 작성을 위한 SaaS 플랫폼의 외관조사망도 작성 화면을 도시하고, 도 12는 본 발 명의 실시예에 따른 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 자동 작성 을 위한 SaaS 플랫폼의 히트맵 출력 화면을 도시한다. 도 13은 본 발명의 실시예에 따른 방법을 구현하기 위한 컴퓨터 시스템을 나타낸 블록도이다. 본 발명의 실시예에 따른 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고 서 자동 작성을 위한 SaaS 플랫폼 장치는 설명가능 인공지능 및 SaaS 플랫폼 기반 댐시설물 안전점검 프로그램 이 저장된 메모리 및 프로그램을 실행시키는 프로세서를 포함하되, 프로세서는 댐시설물의 균열 및 결함 정보를 영상을 통해 획득하고, 이를 인공지능 기반으로 검출하고 정량화하고, 온라인을 통해 비대 면으로 댐시설물 촬영영상을 플랫폼에 업로드하고, 인공지능 모델에 의한 영상처리 결과를 온라인으로 다운로드 한다. 프로세서는 별도 소프트웨어 설치 없이 웹 브라우저를 통해 솔루션을 사용한다. 결함 정보는 박리, 박락, 파손, 누수, 백태, 철근노출, 재료분리 중 적어도 어느 하나를 포함한다. 프로세서는 UAV로 댐시설물의 표면을 겹침 촬영한 후 이동식 스테레오 이미징 알고리즘 기반으로 획득한 3차원 포인트 클라우드 및 영상을 이용하여 박락, 철근노출 중 적어도 어느 하나를 포함하는 깊이가 있는 결함 의 검출을 수행한다. UAV는 댐시설물의 표면을 50% 이상 겹침(중복) 촬영한다. 프로세서는 인공지능 모델에 의한 영상처리 결과의 추론 과정 및 이유를 기설정된 언어(예: 국어, 영어) 의 문장으로 출력하는 캡셔닝 기능을 이용해 제시하고, 특징의 강도를 기설정 색깔(붉은 색, 파란색)로 구성된 등고선 지도로 시각화하는 히트맵을 출력하여, 설명가능 인공지능 기반으로 균열 및 결함의 검출을 수행한다. 프로세서는 사용자가 이해할 수 있도록, 균열 및 결함 정보의 위치, 형상, 크기를 시각화하고, 댐시설물 의 부재별(상류면, 하류면, 댐마루 등)로 도면화한다. 프로세서는 댐시설물의 대표적인 균열 및 결함과 관련된 벤치마크 데이터셋으로 객체에 대한 히트맵 및 캡셔닝 성능을 향상시킨다. 프로세서는 트랜스퍼 러닝을 통해 다른 인공지능 모델에 가중치 행렬을 이전시킨다. 전이 학습이란 '한 분야의 문제를 해결하기 위해서 얻은 지식과 정보를 다른 문제를 푸는데 사용하는 방식'으로, 이를 딥러닝의 분 야에서는 '이미지 분류' 문제를 해결하는데 사용했던 네트워크(DNN;Deep Neural Network)를 다른 데이터셋 혹은 다른 문제(task)에 적용시켜 푸는 것을 의미한다. 기계의 시각적 이해를 목표로 하는 컴퓨터 비전의 영역에서 전이 학습으로 수행된 모델들이 높은 성능을 보이고 있어 가장 많이 사용되는 방법 중에 하나이다. 전이학습을 수행하지 않은 모델들보다 비교적 빠르고 정확한 정확도를 달성할 수 있다. 이것이 가능한 이유는 바로 네트워 크가 다양한 이미지의 보편적인 특징 또는 피처(Feature)들을 학습했기 때문이다. 일반적으로 네트워크가 깊어 질수록 서로 다른 종류의 피처들을 학습한다고 알려져 있는데, 낮은 층에서 학습되는 피처를 low-level features, 깊은 층에서 학습되는 피처들은 high level features라고 부른다. low-level feature의 예로는 이미 지의 색이나 경계(edge) 등을 말할 수 있고 high level features는 이보다 더 심화된 객체의 패턴이나 형태를 의미한다. 프로세서는 댐시설물 표면에 매칭되는 인공지능 필터를 이용하여, 오염된 댐시설물 표면에 포함된 균열 및 결함 정보의 검출을 수행하고, 검출 성능 중 정밀도(Precision)를 향상시킨다. 도 13을 참조하면, 컴퓨터 시스템은, 버스를 통해 통신하는 프로세서, 메모리, 입력 인터페이스 장치, 출력 인터페이스 장치, 및 저장 장치 중 적어도 하나를 포함할 수 있다. 컴퓨터 시스템은 또한 네트워크에 결합된 통신 장치를 포함할 수 있다. 프로세서는 중앙 처 리 장치(central processing unit, CPU)이거나, 또는 메모리 또는 저장 장치에 저장된 명령을 실 행하는 반도체 장치일 수 있다. 메모리 및 저장 장치는 다양한 형태의 휘발성 또는 비휘발성 저장 매체를 포함할 수 있다. 예를 들어, 메모리는 ROM(read only memory) 및 RAM(random access memory)를 포함할 수 있다. 본 기재의 실시예에서 메모리는 프로세서의 내부 또는 외부에 위치할 수 있고, 메모리는 이미 알려진 다양한 수단을 통해 프로세서와 연결될 수 있다. 메모리는 다양한 형태의 휘발성 또는 비휘발성 저장 매체이며, 예를 들어, 메모리는 읽기 전용 메모리(read-only memory, ROM) 또는 랜덤 액세스 메모리(random access memory, RAM)를 포함할 수 있다. 따라서, 본 발명의 실시예는 컴퓨터에 구현된 방법으로서 구현되거나, 컴퓨터 실행 가능 명령이 저장된 비일시 적 컴퓨터 판독 가능 매체로서 구현될 수 있다. 한 실시예에서, 프로세서에 의해 실행될 때, 컴퓨터 판독 가능 명령은 본 기재의 적어도 하나의 양상에 따른 방법을 수행할 수 있다. 통신 장치는 유선 신호 또는 무선 신호를 송신 또는 수신할 수 있다. 또한, 본 발명의 실시예에 따른 방법은 다양한 컴퓨터 수단을 통해 수행될 수 있는 프로그램 명령 형태로 구현 되어, 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판독 가능 매체에 기록되는 프로그램 명령은, 본 발명의 실시예를 위해 특별히 설계되어 구성된 것이거나, 컴퓨터 소프트웨어 분야의 통상의 기술자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체는 프로그램 명령을 저장하고 수행하도록 구성된 하드웨어 장치를 포함할 수 있다. 예를 들 어, 컴퓨터 판독 가능 기록 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광 기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 롬(ROM), 램(RAM), 플래시 메모리 등일 수 있다. 프로그램 명령은 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라, 인터프리터 등을 통해 컴퓨터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13\n【요약】본 발명은 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고서 자동 작성을 위한 SaaS(Software as a Service) 플랫폼 장치에 관한 것이다. 본 발명에 따른 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고서 자동 작 성을 위한 SaaS 플랫폼 장치는 설명가능 인공지능 및 SaaS 플랫폼 기반 댐시설물 안전점검 프로그램이 저장된 메 모리 및 프로그램을 실행시키는 프로세서를 포함하되, 프로세서는 댐시설물의 균열 및 결함 정보를 영상을 통해 획득하고, 이를 인공지능 기반으로 검출하고 정량화하고, 온라인을 통해 댐시설물 촬영영상을 플랫폼에 업로드하 고, 인공지능 모델에 의한 영상처리 결과를 온라인으로 다운로드한다.\n\n【청구항 1】\n설명가능 인공지능 및 SaaS 플랫폼 기반 댐시설물 안전점검 프로그램이 저장된 메모리; 및상기 프로그램을 실행시키는 프로세서를 포함하되,상기 프로세서는 댐시설물의 균열 및 결함 정보를 영상을 통해 획득하고, 이를 인공지능 기반으로 검출하고 정량화하고, 온라인을 통해 댐시설물 촬영영상을 플랫폼에 업로드하고, 인공지능 모델에 의한 영상처리 결과를 온라인으로 다운로드하는 것인 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고서 자동 작성을 위한SaaS 플랫폼 장치.\n【청구항 2】\n제1항에 있어서, 상기 프로세서는 별도 소프트웨어 설치 없이 웹 브라우저를 통해 솔루션을 사용하는 것인 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고서 자동 작성을 위한SaaS 플랫폼 장치.\n【청구항 3】\n제1항에 있어서, 상기 결함 정보는 박리, 박락, 파손, 누수, 백태, 철근노출, 재료분리 중 적어도 어느 하나를 포함하는 것인 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고서 자동 작성을 위한SaaS 플랫폼 장치.\n【청구항 4】\n제1항에 있어서, 상기 프로세서는 UAV로 댐시설물의 표면을 겹침 촬영한 후 이동식 스테레오 이미징 알고리즘 기반으로 획득한 3차원 포인트 클라우드 및 영상을 이용하여 박락, 철근노출 중 적어도 어느 하나를 포함하는 깊이가 있는 결함의검출을 수행하는 것인 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고서 자동 작성을 위한SaaS 플랫폼 장치.\n【청구항 5】\n제1항에 있어서, 상기 프로세서는 상기 인공지능 모델에 의한 영상처리 결과의 추론 과정 및 이유를 기설정된 언어의 문장으로제공하고, 특징의 강도를 기설정 색깔로 구성된 등고선 지도로 시각화하는 히트맵을 출력하여, 설명가능 인공지능 기반으로 상기 균열 및 결함의 검출을 수행하는 것공개특허 10-2023-0065188-3-인 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고서 자동 작성을 위한SaaS 플랫폼 장치.\n【청구항 6】\n제1항에 있어서, 상기 프로세서는 상기 균열 및 결함 정보의 위치, 형상, 크기를 시각화하고, 댐시설물의 부재별로 도면화하는것인 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고서 자동 작성을 위한SaaS 플랫폼 장치.\n【청구항 7】\n제1항에 있어서, 상기 프로세서는 댐시설물의 대표적인 균열 및 결함과 관련된 벤치마크 데이터셋으로 객체에 대한 히트맵 및 캡셔닝 성능을 향상시키는 것인 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고서 자동 작성을 위한SaaS 플랫폼 장치.\n【청구항 8】\n제7항에 있어서, 상기 프로세서는 트랜스퍼 러닝을 통해 다른 인공지능 모델에 가중치 행렬을 이전시키는 것인 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고서 자동 작성을 위한SaaS 플랫폼 장치.\n【청구항 9】\n제1항에 있어서, 상기 프로세서는 댐시설물 표면에 매칭되는 인공지능 필터를 이용하여, 오염된 댐시설물 표면에 포함된 균열 및결함 정보의 검출을 수행하고, 정밀도를 향상시키는 것인 설명가능 인공지능 기반 댐시설물 결함 검출, 정량화, 캡셔닝, 도면화, 상태평가 보고서 자동 작성을 위한SaaS 플랫폼 장치."}
{"context": "", "input": "【기술명】\n빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 시스템\n\n【기술 설명】\n본 발명은 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치로, 사용자의 위치코드를 기반으로 실시간으로 위험지역을 식별하고 이를 등급화하여 사용자에게 제공하는 시스템입니다. 이 장치는 트래커 신호를 수집하여 사용자 위치를 추적하고, 해당 위치 주변의 위험지역 정보를 분석하여 사용자에게 맞춤형 경고를 전달합니다. 또한, 위험지역의 등급화 과정에서는 사용자 유형에 따라 위험성을 세분화하여 보다 정밀한 정보를 제공합니다.\n\n【해결 문제】\n최근 사회에서 증가하는 범죄율은 시민들에게 심각한 불안감을 조성하고 있으며, 이로 인해 사회적 결속력이 약화되고 있습니다. 본 발명은 사용자 맞춤형 위험지역 정보를 제공함으로써 개인의 안전을 사전 예방적으로 강화하고, 범죄에 대한 두려움을 경감할 필요성이 있습니다. 이는 범죄 예방을 위한 경제적 비용을 절감하고, 사회 구성원 간의 신뢰를 회복하는 데 기여할 수 있습니다.\n\n【기술 차별성】\n본 발명의 기술은 기존의 범죄 정보 제공 시스템과 비교했을 때, 사용자 위치를 실시간으로 추적하고 빅데이터 분석을 통해 위험지역을 동적으로 등급화하는 점에서 혁신적입니다. 특히, 사용자 유형별로 위험지역을 세분화하여 제공함으로써 더욱 개인화된 안전 정보를 제공할 수 있습니다. 이러한 차별성은 사용자에게 실질적인 안전 정보를 제공하여, 사회 전반의 범죄 예방 및 안전성을 높이는 데 기여할 것입니다.\n\n【활용 분야】\n본 발명은 스마트폰 및 IoT 기기가 널리 사용되는 도시 환경에서의 안전 및 보안 분야에서 활용될 수 있습니다. 특히, 개인 안전, 재난 관리, 범죄 예방, 관광 및 지역 사회 안전에 기여할 수 있는 잠재력을 가지고 있습니다. 예를 들어, 여행객이나 어린이와 같은 특정 사용자 그룹을 위한 맞춤형 위험 정보 제공 서비스는 이 시스템의 주요 응용 분야가 될 수 있으며, 이를 통해 사용자는 보다 안전한 경로를 선택하고 위험 요소를 사전에 인지하여 피해를 최소화할 수 있습니다.\n\n【구성 요소 및 기능】\n본 발명은 세 가지 주요 구성 요소로 이루어져 있습니다. 첫째, '트래커 신호 수집부'는 수신된 트래커 신호에서 사용자 위치코드를 추출하고, 이를 바탕으로 위험지역을 분석하여 트래커 데이터베이스에 저장하는 기능을 수행합니다. 둘째, '위험지역 등급화부'는 저장된 위험지역 정보를 분석하여 위험도를 평가하고 등급화함으로써, 사용자에게 제공할 정보의 신뢰성을 높이는 역할을 합니다. 셋째, '위험지역 처리부'는 사용자 단말의 위치를 실시간으로 추적하여 특정 거리 내의 위험지역 등급 정보를 제공하며, 이동 방향을 예측하여 고위험 지역에 접근할 때 사용자 센서를 활성화하여 응급 신호의 검출을 용이하게 합니다.\n\n【구현 방식 예】\n본 발명의 구현은 다음 단계로 진행됩니다. 우선, 사용자의 단말기에서 발생하는 트래커 신호를 수집하고, 이를 통해 사용자 위치코드를 검출합니다. 이후, 수집된 위치코드를 바탕으로 위험지역을 결정하고 이를 트래커 데이터베이스에 저장합니다. 다음으로, 위험지역 등급화부에서 저장된 데이터를 분석하여 위험도를 평가하고, 위험지역을 등급화한 후, 이를 사용자 단말에 전달합니다. 마지막으로, 위험지역 처리부는 사용자의 이동 경로를 실시간으로 추적하고, 특정 위험지역에 접근할 경우 사용자 센서를 활성화하여 응급 상황에 신속하게 대처할 수 있는 시스템을 구현합니다. 이러한 단계들은 각 구성 요소 간의 원활한 상호작용을 통해 최적화됩니다.", "output": "【발명의 명칭】\n빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치\n【기술분야】\n본 발명은 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치에 관한 것으로, 보다 상 세하게는 사용자 위치코드를 기초로 위험지역을 결정하여 트래커 데이터베이스에 저장하고 분석하여 위험지역을 등급화 하는 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치에 관한 것이다.\n【배경기술】\n강남역 살인사건, 인천 초등생 살인사건, 오원춘 사건 등 흉폭한 강력범죄의 증가와 함께, 양적으로 증가하는 범죄발생은 심각한 사회적 문제이다. 특히 SNS(Social Network Service), 인터넷 등의 발달로 인해 시민들이 범 죄에 대한 정보를 빠르게 접할 수 있어 간접경험으로 범죄 피해를 겪지 않더라도 범죄에 노출될 수 있다는 두려 움이 시민들의 삶을 위협하고 있다. 간접경험으로 접한 범죄 두려움의 사회적 증가는 사회 구성원 간의 불신을 유발하며, 전체적으로는 유대감, 신 뢰 등에 기반한 사회 결속력의 감소를 초래한다. 이러한 부정적 영향의 확산을 방지하기 위해 사전에 범죄를 예 방하기 위한 예방정책을 수립하고 있지만, 막대한 경제적인 비용과 시간이 소요되며 대부분의 비용은 사회 구성 원이 부담하게 된다. 대부분의 범죄는 무작위적인 분포로 발생하지 않고 일정한 장소적 패턴을 보이며 발생하기 때문에, 특정 범죄의 발생 지역에 대한 분석을 통해 범죄 취약지역을 구분하고, 시민에게 범죄 취약지역에 대한 정보를 제공하여 범 죄예방과 생활안전을 위한 대책을 마련하는 것이 중요해지고 있다. 한국 등록특허 제2015-0016898호는 위험정보 수집 및 제공 시스템에 관한 것으로, 위험정보 수집 및 제공용 단 말기, 위험정보 데이터베이스를 가지는 정보통합센터, 위험정보 수집 및 제공용 단말기와 정보통합센터를 연결 하는 통신 네트워크를 포함하며, 단말기는 위치파악을 가능하게 하는 위치정보센서 및 통신부를 구비하여 통신 네트워크를 통해 위치정보를 송신할 수 있고, 위험정보와 관련하여 정보통합센터에 입력 사항을 전달할 수 있는 가의 여부에 따라 복수 모드로 분리하여 모드를 바꾸어가면서 사용될 수 있고, 복수 모드 가운데에서 정보제공 이나 긴급신고를 위해 단말기 사용자가 위험정보를 영상정보, 텍스트정보, 버튼선택정보 가운데 적어도 하나의 형태로 입력하고 전송하면 단말기가 입력된 정보를 단말기의 위치정보와 함께 통신 네트워크를 통해 정보통합센 터로 전달하며, 정보통합센터는 단말기 위치정보를 인식하여 단말기에 단말기가 위치한 영역과 관련된 위험정보 를 제공할 수 있도록 이루어진 것을 특징으로 하는 위험정보 수집 및 제공 시스템을 개시한다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 등록특허 제2015-0016898호 (2015.02.03)\n【해결하려는 과제】\n본 발명의 일 실시예는 사용자 위치코드를 기초로 위험지역을 결정하여 트래커 데이터베이스에 저장하고 분석하 여 위험지역을 등급화 하는 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치를 제공 하고자 한다. 본 발명의 일 실시예는 사용자 단말의 추적을 통해 해당 사용자의 위치를 검출하고 위치를 중심으로 특정 거리 내에 있는 위험지역의 등급정보를 제공하는 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서 비스 장치를 제공하고자 한다.\n【과제의 해결 수단】\n본 발명의 일 실시예에 따른 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치는 트 래커 신호가 수신되면 상기 트래커 신호에 있는 사용자 위치코드를 검출하고, 상기 사용자 위치코드를 기초로 위험지역을 결정하여 트래커 데이터베이스에 저장하는 트래커 신호 수집부, 상기 트래커 데이터베이스를 분석하 여 상기 위험지역을 등급화 하는 위험지역 등급화부 및 사용자 단말의 추적을 통해 해당 사용자의 위치를 검출 하고 상기 위치를 중심으로 특정 거리 내에 있는 위험지역의 등급정보를 제공하는 위험지역 처리부를 포함한다. 상기 트래커 신호 수집부는 상기 사용자 위치코드를 중심으로 특정 시간 이내에 이동 가능한 길을 디지털 지도 상에서 특정하여 상기 위험지역을 결정할 수 있다. 상기 트래커 신호 수집부는 상기 길의 말단을 연결한 폐영역 을 생성하여 상기 위험지역을 결정할 수 있다. 상기 트래커 신호 수집부는 상기 트래커 신호에 있는 사용자 식별코드를 통해 사용자 유형을 결정하고 상기 위 험지역을 사용자 유형별 위험지역으로 세분화할 수 있다. 상기 위험지역 등급화부는 상기 위험지역의 등급화 과정에서 복수의 위험지역들 사이에 있는 비-위험지역을 결 정하고 상기 비-위험지역의 위험성을 예측하여 상기 위험지역을 등급화 할 수 있다. 상기 위험지역 처리부는 상기 사용자 단말의 이동 방향을 예측하여 특정 위험지역 등급 이상을 가지는 고위험지 역을 결정하고 상기 사용자 단말이 상기 고위험지역을 지나가는 동안에는 상기 사용자 단말의 센서를 활성화하 여 사용자 응급신호의 검출을 용이하게 할 수 있다.\n【발명의 효과】\n개시된 기술은 다음의 효과를 가질 수 있다. 다만, 특정 실시예가 다음의 효과를 전부 포함하여야 한다거나 다 음의 효과만을 포함하여야 한다는 의미는 아니므로, 개시된 기술의 권리범위는 이에 의하여 제한되는 것으로 이 해되어서는 아니 될 것이다. 본 발명의 일 실시예에 따른 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치는 사 용자 위치코드를 기초로 위험지역을 결정하여 트래커 데이터베이스에 저장하고 분석하여 위험지역을 등급화 할 수 있다. 본 발명의 일 실시예에 따른 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치는 사 용자 단말의 추적을 통해 해당 사용자의 위치를 검출하고 위치를 중심으로 특정 거리 내에 있는 위험지역의 등 급정보를 제공할 수 있다.\n【발명을실시하기위한구체적인내용】\n본 발명에 관한 설명은 구조적 내지 기능적 설명을 위한 실시예에 불과하므로, 본 발명의 권리범위는 본문에 설 명된 실시예에 의하여 제한되는 것으로 해석되어서는 아니 된다. 즉, 실시예는 다양한 변경이 가능하고 여러 가 지 형태를 가질 수 있으므로 본 발명의 권리범위는 기술적 사상을 실현할 수 있는 균등물들을 포함하는 것으로 이해되어야 한다. 또한, 본 발명에서 제시된 목적 또는 효과는 특정 실시예가 이를 전부 포함하여야 한다거나 그러한 효과만을 포함하여야 한다는 의미는 아니므로, 본 발명의 권리범위는 이에 의하여 제한되는 것으로 이해 되어서는 아니 될 것이다. 한편, 본 출원에서 서술되는 용어의 의미는 다음과 같이 이해되어야 할 것이다. \"제1\", \"제2\" 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위한 것으로, 이들 용어들에 의해 권리범위가 한정되어서는 아니 된다. 예를 들어, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\"있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결될 수 도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\"있다고 언급된 때에는 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 한편, 구성요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃 하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함하는 것으로 이해되어야 하고, \"포함 하다\"또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 각 단계들에 있어 식별부호(예를 들어, a, b, c 등)는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단 계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순 서와 다르게 일어날 수 있다. 즉, 각 단계들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수 행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 여기서 사용되는 모든 용어들은 다르게 정의되지 않는 한, 본 발명이 속하는 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 용어들은 관 련 기술의 문맥상 가지는 의미와 일치하는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한 이 상적이거나 과도하게 형식적인 의미를 지니는 것으로 해석될 수 없다. 도 1은 본 발명의 일 실시예에 따른 빅데이터 기반 위험지역 정보제공 서비스 시스템을 도시한 도면이다. 도 1을 참조하면, 빅데이터 기반 위험지역 정보제공 서비스 시스템은 사용자 단말, 빅데이터 분석 기 반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치 및 트래커 데이터베이스를 포함할 수 있 다. 사용자 단말은 위험 상황에 대하여 사용자의 제어 또는 자동적인 위험 감지에 따라 트래커 신호를 제공할 수 있고, 트래커 신호는 위치코드 및 사용자 유형을 포함할 수 있다. 사용자 단말은 GPS(Global Positioning System)를 장착하거나 또는 네트워크 기반의 위치 검출이 가능한 스마트폰, 노트북 또는 휴대용 컴 퓨터로 구현될 수 있으며, 반드시 이에 한정되지 않고, 웨어러블 등 다양한 디바이스로도 구현될 수 있다. 사용 자 단말은 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치와 네트워크를 통해 연결될 수 있으며, 사용자 단말은 트래커 신호를 생성 및 전송할 수 있는 전용 프로그램 또는 어플리 케이션을 설치하여 실행할 수 있다. 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치는 사용자 위치코드를 기초로 위험지역을 결정하고 위험지역을 등급화할 수 있고 사용자의 요청에 따라 위험지역의 등급정보를 제공할 수 있 는 컴퓨터 또는 서버로 구현될 수 있다. 보다 구체적으로, 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지 역 정보제공 서비스 장치는 위험지역을 결정하는 과정, 위험지역을 등급화하는 과정, 위험지역의 정보를 제공하는 과정을 수행하여 사용자에게 위험지역을 알려줘서 사전에 위험에 대응할 수 있는 서비스를 제공할 수있다. 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치는 사용자 단말과 유선 네트워크 또는 블루투스, WiFi 등과 같은 무선 네트워크로 연결될 수 있고, 네트워크를 통해 사용자 단말 과 데이터를 송수신할 수 있다. 트래커 데이터베이스는 위험지역에 관한 영역 데이터, 등급 데이터, 위험의 종류 데이터 및 위험요인 데이 터를 저장할 수 있고, 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치의 지속 적인 관리를 통해 위험지역의 영역 갱신 및 등급 갱신을 수행할 수 있다. 트래커 데이터베이스는 위험의 종류 데이터를 통해 위엄지역에서 발생될 수 있는 위험 종류를 제공하고 위험요인 데이터를 통해 위엄지역에 있 는 위험시설 및 위험인물에 관한 정보를 제공함으로써 사용자 맞춤형 위험 알림 서비스를 지원할 수 있다. 트래커 데이터베이스는 사용자 유형별 위험지역 데이터를 저장할 수 있고, 트래커 신호에 있는 사용자 유 형을 확인하고 위험의 종류 및 위험요인을 분석하여 사용자 유형별 위험지역 데이터를 갱신할 수 있다. 예를 들 어, 사용자 유형이 성인 여성, 아동, 청소년 등으로 분류될 수 있고, 사용자별 위험지역은 사용자에 따라 상대 적으로 더 주의할 위험지역으로 세분화될 수 있다. 도 2는 도 1의 빅데이터 기반 위험지역 정보제공 서비스 시스템 구성을 설명하는 도면이다. 도 2를 참조하면, 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치는 프로세서 , 메모리, 사용자 입출력부 및 네트워크 입출력부를 포함할 수 있다. 프로세서는 본 발명의 실시예에 따른 빅데이터 기반 위험지역 정보제공 서비스 프로시저를 실행할 수 있고, 이러한 과정에서 읽혀지거나 작성되는 메모리를 관리할 수 있으며, 메모리에 있는 휘발성 메모 리와 비휘발성 메모리 간의 동기화 시간을 스케줄 할 수 있다. 프로세서는 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치의 동작 전반을 제어할 수 있고, 메모리, 사용자 입출력 부 및 네트워크 입출력부와 전기적으로 연결되어 이들 간의 데이터 흐름을 제어할 수 있다. 프로세서 는 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치의 CPU(Central Processing Unit)로 구현될 수 있다. 메모리는 SSD(Solid State Disk) 또는 HDD(Hard Disk Drive)와 같은 비휘발성 메모리로 구현되어 빅데이 터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치에 필요한 데이터 전반을 저장하는데 사용되는 보조기억장치를 포함할 수 있고, RAM(Random Access Memory)과 같은 휘발성 메모리로 구현된 주기억장 치를 포함할 수 있다. 또한, 메모리는 전기적으로 연결된 프로세서에 의해 실행됨으로써 본 발명에 따른 학습 데이터베이스 구축 방법을 실행하는 명령들의 집합을 저장할 수 있다. 사용자 입출력부은 사용자 입력을 수신하기 위한 환경 및 사용자에게 특정 정보를 출력하기 위한 환경을 포함하고, 예를 들어, 터치 패드, 터치 스크린, 화상 키보드 또는 포인팅 장치와 같은 어댑터를 포함하는 입력 장치 및 모니터 또는 터치 스크린과 같은 어댑터를 포함하는 출력장치를 포함할 수 있다. 일 실시예에서, 사용 자 입출력부은 원격 접속을 통해 접속되는 컴퓨팅 장치에 해당할 수 있고, 그러한 경우, 빅데이터 분석 기 반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치는 독립적인 서버로서 수행될 수 있다. 네트워크 입출력부은 네트워크를 통해 사용자 단말과 연결되기 위한 통신 환경을 제공하고, 예를 들 어, LAN(Local Area Network), MAN(Metropolitan Area Network), WAN(Wide Area Network) 및 VAN(Value Added Network) 등의 통신을 위한 어댑터를 포함할 수 있다. 또한, 네트워크 입출력부는 학습 데이터의 무선 전 송을 위해 WiFi, 블루투스 등의 근거리 통신 기능이나 4G 이상의 무선 통신 기능을 제공하도록 구현될 수 있다. 도 3은 도 1의 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치의 기능적 구성을 설 명하는 도면이다. 도 3을 참조하면, 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치는 트래커 신호 수집부, 위험지역 등급화부, 위험지역 처리부 및 제어부를 포함할 수 있다. 트래커 신호 수집부는 사용자 단말로부터 트래커 신호를 수신하고 트래커 신호에 있는 사용자 위치코 드를 검출한다. 예를 들어, 사용자 위치코드는 GPS 신호를 기초로 생성될 수 있다. 다른 예를 들어, 사용자 위치코드는 네트워크 기반의 위치신호를 기초로 생성될 수 있다. 트래커 신호는 사용자 단말에 의해 사용자 의 위험을 알리기 위한 신호로서, 1차적으로 위험 상황에서 사용자 위치코드를 포함하고, 2차적으로, 비위험 상 황에서(즉, 위험 상황을 벗어난 일정 시간 후의 상황에서) 위험의 종류 및 위험요인(예를 들어, 자동차 사고, 성추행 등)을 포함하도록 할 수 있다. 즉, 트래커 신호는 일정 시간의 경과에 따라 완성되는 데이터에 해당할 수 있다. 트래커 신호 수집부는 사용자 위치코드를 기초로 위험지역을 결정하여 트래커 데이터베이스에 저장한 다. 즉, 트래커 신호 수집부는 트래커 신호가 수신되면 사용자 위치코드를 1차적으로 트래커 데이터베이스 에 저장하고, 일정한 시간이 경과되면, 사용자 단말을 통해 위험의 종류 및 위험요인을 2차적으로 트 래커 데이터베이스에 저장한다. 최종적으로, 트래커 신호 수집부는 위엄지역의 등급을 산출하여 트래 커 데이터베이스를 갱신한다. 일 실시예에서, 트래커 신호 수집부는 사용자 위치코드를 중심으로 특정 시간 이내에 이동 가능한 길을 디 지털 지도 상에서 특정하여 위험지역을 결정할 수 있다. 이동 가능한 길은 위험요인이 성인에게만 특정될 수 있 는 경우에는 상대적으로 길게 결정될 수 있고, 위험요인이 청소년에게만 특정될 수 있는 상대적으로 짧게 결정 될 수 있다. 보다 구체적으로, 트래커 신호 수집부는 길의 말단을 연결한 폐영역을 생성하여 위험지역을 결정할 수 있 다. 즉, 트래커 신호 수집부는 이동 가능한 길을 사용자 단말의 위치를 기준으로 전체 영역(예를 들 어, 원형)으로 결정할 수 있고, 이러한 전체 영역에서 이동한 길로 구성된 폐영역을 최종적으로 결정할 수 있다. 일 실시예에서, 트래커 신호 수집부는 트래커 신호에 있는 사용자 식별코드를 통해 사용자 유형을 결정하 고 위험지역을 사용자 유형별 위험지역으로 세분화할 수 있다. 위험지역 등급화부는 트래커 데이터베이스를 분석하여 위험지역을 등급화 할 수 있다. 예를 들어, 위 험지역 등급화부는 트래커 신호가 자주 수신되는 경우에는 위험지역의 등급을 최상위로 설정할 수 있고, 트래커 신호가 야간에 주로 수신되는 경우에는 위험지역의 등급을 높음으로 설정할 수 있으며, 트래커 신호가 거의 수신되지 않은 경우에는 위험지역의 등급을 낮음으로 설정할 수 있다. 일 실시예에서, 위험지역 등급화부는 위험지역의 등급화 과정에서 복수의 위험지역들 사이에 있는 비-위험 지역을 결정하고 비-위험지역의 위험성을 예측하여 위험지역을 등급화 할 수 있다. 즉, 위험지역 등급화부(32 0)는 복수의 위험지역들의 위험성들을 보간(interpolation)하여 그 사이에 있는 비-위험지역의 위험성을 등급화 할 수 있다. 위험지역 처리부는 사용자 단말의 추적을 통해 해당 사용자의 위치를 검출하고 위치를 중심으로 특정 거리 내에 있는 위험지역의 등급정보를 제공한다. 일 실시예에서, 위험지역 처리부는 사용자 단말의 위치를 실시간 추적하여 이동에 따른 위험지역의 등급정보를 사용자에게 알려줌으로써 향후 발생할 수 있는 위 험의 정도를 서비스 제공할 수 있다. 일 실시예에서, 위험지역 처리부는 사용자 단말의 이동 방향을 예측할 수 있고, 예측에 기반하여 특 정 위험지역 등급 이상을 가지는 고위험지역을 결정할 수 있다. 위험지역 처리부는 사용자 단말이 고 위험지역을 지나가는 동안에는 사용자 단말의 센서를 활성화하여 사용자 응급신호의 검출을 용이하게 할 수 있다. 예를 들어, 위험지역 처리부는 사용자 단말의 마이크 및 스피커를 활성화 하여 센싱 감도를 최대로 설정할 수 있다. 또한, 위험지역 처리부는 사용자 단말의 화면에 있는 락(lock)을 해제하고 긴급 전화를 전면에 활성화하여 사용자의 즉각적인 구조요청을 수신할 수 있다. 다만, 지속적으로 락이 해제된 경우에는 문제가 발생될 수 있으므로, 위험지역 처리부는 사용자 단말이 위험지역을 벗어나는 것을 확인하여 다시 락을 설정할 수 있다. 제어부는 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치의 전체적인 동 작을 제어하고, 헬퍼 트래커 신호 수집부, 위험지역 등급화부 및 위험지역 처리부 간의 제어 흐 름 또는 데이터 흐름을 관리할 수 있다. 도 4는 도 1의 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치의 기능 구성을 설명 하는 흐름도이다.도 4에서, 트래커 신호 수집부는 트래커 신호가 수신되면 트래커 신호에 있는 사용자 위치코드를 검출하고 사용자 위치코드를 기초로 위험지역을 결정하여 트래커 데이터베이스에 저장한다(단계 S410). 위험지역 등급화부는 트래커 데이터베이스를 분석하여 위험지역을 등급화 할 수 있다(단계 S420). 위 험지역 처리부는 사용자 단말의 추적을 통해 해당 사용자의 위치를 검출하고 위치를 중심으로 특정 거리 내에 있는 위험지역의 등급정보를 제공한다(단계 S430). 상기에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특 허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다.\n【요약】빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치는 트래커 신호가 수신되면 상기 트 래커 신호에 있는 사용자 위치코드를 검출하고, 상기 사용자 위치코드를 기초로 위험지역을 결정하여 트래커 데 이터베이스에 저장하는 트래커 신호 수집부, 상기 트래커 데이터베이스를 분석하여 상기 위험지역을 등급화 하는 위험지역 등급화부 및 사용자 단말의 추적을 통해 해당 사용자의 위치를 검출하고 상기 위치를 중심으로 특정 거 리 내에 있는 위험지역의 등급정보를 제공하는 위험지역 처리부를 포함한다.\n\n【청구항 1】\n트래커 신호가 수신되면 상기 트래커 신호에 있는 사용자 위치코드를 검출하고, 상기 사용자 위치코드를 기초로위험지역을 결정하여 트래커 데이터베이스에 저장하는 트래커 신호 수집부;상기 트래커 데이터베이스를 분석하여 상기 위험지역을 등급화 하는 위험지역 등급화부; 및사용자 단말의 추적을 통해 해당 사용자의 위치를 검출하고 상기 위치를 중심으로 특정 거리 내에 있는 위험지역의 등급정보를 제공하는 위험지역 처리부를 포함하는 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역정보제공 서비스 장치.\n【청구항 2】\n제1항에 있어서, 상기 트래커 신호 수집부는상기 사용자 위치코드를 중심으로 특정 시간 이내에 이동 가능한 길을 디지털 지도 상에서 특정하여 상기 위험지역을 결정하는 것을 특징으로 하는 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치.\n【청구항 3】\n제2항에 있어서, 상기 트래커 신호 수집부는상기 길의 말단을 연결한 폐영역을 생성하여 상기 위험지역을 결정하는 것을 특징으로 하는 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치.\n【청구항 4】\n제1항에 있어서, 상기 트래커 신호 수집부는상기 트래커 신호에 있는 사용자 식별코드를 통해 사용자 유형을 결정하고 상기 위험지역을 사용자 유형별 위험지역으로 세분화하는 것을 특징으로 하는 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치.\n【청구항 5】\n제1항에 있어서, 상기 위험지역 등급화부는상기 위험지역의 등급화 과정에서 복수의 위험지역들 사이에 있는 비-위험지역을 결정하고 상기 비-위험지역의위험성을 예측하여 상기 위험지역을 등급화 하는 것을 특징으로 하는 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스 장치.\n【청구항 6】\n제1항에 있어서, 상기 위험지역 처리부는상기 사용자 단말의 이동 방향을 예측하여 특정 위험지역 등급 이상을 가지는 고위험지역을 결정하고 상기 사용공개특허 10-2023-0084827-3-자 단말이 상기 고위험지역을 지나가는 동안에는 상기 사용자 단말의 센서를 활성화하여 사용자 응급신호의 검출을 용이하게 하는 것을 특징으로 하는 빅데이터 분석 기반의 인공지능 고객 맞춤형 위험지역 정보제공 서비스장치."}
{"context": "", "input": "【기술명】\n모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 시스템\n\n【기술 설명】\n본 발명은 모바일 카메라와 인공지능 기술을 결합하여 혈류의 양을 측정하고 욕창을 진단하는 혁신적인 장치 및 시스템입니다. 이 장치는 서로 다른 두 파장의 광을 신체 부위에 조사하고, 그 반사광을 모바일 카메라로 촬영하여 산소포화도 및 혈류량 분포도를 생성합니다. 이러한 데이터를 바탕으로 인공지능 모델이 욕창의 진행 정도를 진단하여, 의료진이 보다 정확하고 신속하게 욕창을 평가할 수 있도록 지원합니다.\n\n【해결 문제】\n욕창은 장기적인 압박으로 인해 발생하며, 환자의 삶의 질을 심각하게 저해하는 문제입니다. 기존의 진단 방법은 주로 의사의 육안에 의존하고 있어, 주관적인 판단으로 인해 오진의 위험성이 존재합니다. 본 발명은 혈류량과 산소포화도를 정량적으로 분석하여 욕창을 객관적으로 진단할 수 있는 시스템을 제공함으로써, 조기 발견 및 적절한 치료를 가능하게 하여 환자의 건강을 보호하고 의료비용을 절감하는 데 기여합니다.\n\n【기술 차별성】\n본 발명은 기존의 욕창 진단 기술과 비교하여 여러 가지 차별점과 혁신성을 갖추고 있습니다. 첫째, 두 개의 파장을 이용한 광 조사 기술을 통해 혈류를 시각화함으로써, 기존의 육안 검사보다 훨씬 더 정밀한 진단이 가능합니다. 둘째, 인공지능 모델을 활용하여 혈류량 맵에서 욕창의 진행 등급을 자동으로 판별함으로써, 진단의 일관성과 정확성을 높였습니다. 이러한 접근 방식은 욕창 진단의 표준화를 가능하게 하여 의료 현장에서의 효율성을 극대화합니다.\n\n【활용 분야】\n본 발명은 의료 분야, 특히 피부과 및 재활의학 분야에서 활용될 수 있는 혁신적인 기술입니다. 욕창 진단 장치는 병원, 요양원, 가정에서의 환자 관리에 적용 가능하여, 장기 immobilization 환자들의 피부 상태를 지속적으로 모니터링하고 조기에 욕창을 예방하는 데 기여할 수 있습니다. 또한, 모바일 카메라 기반의 접근 방식은 기존의 비침습적 진단 방법에 비해 비용 효율성과 접근성을 높여, 전 세계적으로 의료 서비스의 질 개선에 이바지할 수 있습니다.\n\n【구성 요소 및 기능】\n1. 광 조사부: 이 구성 요소는 서로 다른 두 개의 파장을 가진 광을 신체 부위에 조사하여, 산화 헤모글로빈과 헤모글로빈의 광 흡수 차이를 통해 혈류를 측정합니다. 이를 통해 피부의 혈류 상태를 실시간으로 평가할 수 있습니다.  \n2. 카메라부: 조사된 광이 반사되어 돌아오는 반사광을 측정하는 역할을 합니다. 이 카메라부는 모바일 기기에 통합되어 있어, 사용자에게 편리한 사용성을 제공하며, 정확한 데이터 수집이 가능합니다.  \n3. 욕창 진단부: 학습 완료된 인공지능 모델을 활용해 혈류량 맵을 분석하고 욕창 진행 등급을 판별합니다. 이 기능은 의료진이 신속하고 정확한 진단을 내릴 수 있도록 지원하며, 환자의 피부 상태에 대한 데이터 기반의 의사결정을 가능하게 합니다.\n\n【구현 방식 예】\n구현 방식은 단계별로 체계적으로 진행됩니다. 첫 번째 단계는 광 조사부와 카메라부의 설계를 통해 서로 다른 파장의 광원을 최적화하고, 반사광을 정밀하게 측정할 수 있는 카메라 시스템을 구축합니다. 두 번째 단계는 산소포화도 분석부와 혈류량 분석부의 알고리즘 개발로, 실제 데이터를 수집하여 인공지능 모델을 학습시키는 과정입니다. 마지막으로, 이러한 구성 요소들을 통합하여 사용자 친화적인 인터페이스를 갖춘 모바일 애플리케이션으로 구현하여, 현장에서 즉시 사용할 수 있도록 합니다. 이를 통해 최종 사용자는 손쉽게 욕창 진단을 수행하고, 필요한 의료적 조치를 취할 수 있습니다.", "output": "【발명의 명칭】\n모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치\n【기술분야】\n본 발명은 욕창 진단 장치 및 시스템에 관한 것으로서, 보다 구체적으로는 모바일 카메라로 혈류의 양을 측정하 여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치 및 시스템에 관한 것이다.\n【배경기술】\n욕창(Pressure Ulcer, Pressure Sore, 압박궤양)이란, 오랫동안의 부동자세로 인해 신체 한 부위에 압력을 지속 해서 받으면 그 부위에 혈액순환 장애가 오고 산소와 영양공급이 부족하여 압력을 받는 부위의 피부, 피하지방, 근육의 허혈로 인하여 발생하는 피부 손상을 의미한다. 대개 중증 환자가 오래 병상에 누워있을 때 바닥에 직 접 닿는 부위에 생기는 압박 괴사이다. 오랫동안 움직임이 없는 경우, 뼈가 튀어나온 부위의 피부가 눌려 혈액 순환이 되지 않아 산소 부족으로 인해 피부가 죽고, 썩어서 욕창이 생기게 된다. 욕창은 어느 부위에서나 발생할 수 있으나 주로 엉치뼈, 넓적다리뼈의 큰 돌기, 무릎뼈, 발꿈치, 정강이뼈 등의 뼈 돌출부와 같이 압박이 많이 가해지는 부위에서 자주 발생한다. 욕창의 초기에는 압력을 받는 부위의 피부가 붉어지고, 이어서 그 부위의 피부에 오려낸 듯한 궤양이 생기며, 더 나아가 피부의 괴사가 진행되게 된다. 도 1은 단계별 분류에 따른 욕창을 도시한 도면이다. 도 1에 도시된 바와 같이 욕창은 4단계의 과정을 거친다. 욕창 1단계에서는, 피부 손상은 관찰되지 않으나 피부가 따듯하고 단단하다. 압력을 제거한 후 5분이 지나도 계속 피부가 붉은색을 띠게 된다. 압력이 완화되면 원래 상태로 회복되며 체위 변경으로 회복될 수 있다. 욕 창 2단계에서는, 피부가 파열되어 찰과상과 물집 등이 나타난다. 부종이 심하고 지방층까지 침범하면 통증이 발생한다. 이 경우 압력이 완화되면 1~2주 이내에 회복될 수 있다. 욕창 3단계에서는 피하조직까지 괴사가 일 어나 악취를 동반한 삼출물이 나타난다. 통증은 없으나 부종이 심하고 괴사조직이 관찰되며, 이 괴사조직을 제 거하고 회복하는 데 수개월이 걸리게 된다. 욕창 4단계에서는, 근육, 뼈, 지지조직(건, 관절) 등의 광범위한 조직 괴사가 일어난다. 괴사조직을 볼 수 있으며 수술적인 치료(피부이식, 피판술 등)가 필요하다. 욕창은 전체 환부가 일정한 손상을 입기보다는 부분적으로 욕창의 정도가 다르게 나타난다. 즉, 동일한 환부라 도 부위에 따라 1단계에서 4단계까지의 다양한 형태를 보인다. 따라서, 동일한 환부라도 적절한 처치와 치료 방법이 요구된다. 특히, 욕창은 환부의 크기와 정도가 다양하게 나타나므로, 이에 대한 정확한 진단과 그에 맞 는 치료의 적용이 필요하다. 이같이 욕창 단계의 진단에는 명확한 기준이 있지만, 진단의 대부분이 의사의 육안에 의한 위험평가시스템에 따 른 확인으로 결정되고 있다. 이는 경험에 의한 진단으로 진단자에 따라 상이한 진단 내용을 나타낼 수 있다. 진단자의 경험에 의존하는 종래의 방법은 오진의 확률을 가지고 있어 욕창의 등급에 대한 표준화된 데이터 기반 의 진단 시스템이 필요하다. 본 발명과 관련된 선행특허로, 공개특허 제10-2012-0072701호(발명의 명칭: 욕창 관리 장치 및 방법, 공개일자: 2012년 07월 04일) 등이 개시된 바 있다.\n【해결하려는 과제】\n본 발명은 기존에 제안된 방법들의 상기와 같은 문제점들을 해결하기 위해 제안된 것으로서, 서로 다른 2개의 파장을 갖는 광을 신체 부위에 조사하고, 신체 부위에서 반사되는 광을 모바일 카메라로 촬영하여 산소포화도 분포도 및 혈류량 맵을 작성해 욕창을 진단함으로써, 산화 헤모글로빈과 헤모글로빈의 광 흡수 파장 차이를 이 용해 혈류를 시각화하여 욕창 발생으로 인한 피부 이상을 객관적으로 감지할 수 있으며, 표준화된 데이터를 기 반으로 욕창을 진단할 수 있는, 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반욕창 진단 장치 및 시스템을 제공하는 것을 그 목적으로 한다.\n【과제의 해결 수단】\n상기한 목적을 달성하기 위한 본 발명의 특징에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치는, 욕창 진단 장치로서, 산화 헤모글로빈과 헤모글로빈의 광 흡수 파장 차이를 이용하기 위해 서로 다른 2개의 파장을 갖는 광을 신체 부위에 조사하는 광 조사부; 상기 광 조사부에서 조사된 광이 표피에서 반사되는 반사광을 측정하는 카메라부; 상기 카메라부에서 측정된 반사광을 이용해 상기 신체 부위의 산소포화도를 측정하고, 상기 신체 부위의 산소포 화도 분포도를 작성하는 산소포화도 분석부; 상기 산소포화도 분포도를 기반으로 상기 신체 부위의 표피의 혈류량 맵을 작성하는 혈류량 분석부; 및 학습 완료된 인공지능 모델을 사용해 상기 혈류량 맵으로부터 욕창을 진단하는 욕창 진단부를 포함하는 것을 그 구성상의 특징으로 한다. 바람직하게는, 상기 광 조사부는, 서로 다른 파장의 광을 조사하는 2종류의 광원부; 상기 2종류의 광원부가 번갈아 배치되는 몸체부; 및 상기 2종류의 광원부의 광 조사를 제어하는 제어부를 포함할 수 있다. 더욱 바람직하게는, 상기 몸체부는, 둘 이상의 동심원상에 상기 2종류의 광원부가 번갈아 배치될 수 있다. 더더욱 바람직하게는, 상기 몸체부는, 상기 2종류의 광원부가 배치된 동심원의 중심 부분에 상기 카메라부의 렌즈가 위치하도록 홀이 형성될 수 있다. 더더더욱 바람직하게는, 상기 광 조사부는, 상기 몸체부에 형성된 홀에 상기 카메라부의 렌즈가 위치하여 상기 신체 부위의 촬영이 가능하도록 모바일 카메 라에 결합되는 결합부를 더 포함할 수 있다. 더욱더 바람직하게는, 상기 결합부는, 상기 모바일 카메라에 탈착 가능하도록 탈착식으로 구성될 수 있다. 더욱 바람직하게는, 상기 산소포화도 분석부는, 상기 2종류의 광원부에서 조사된 광이 표피에서 흡수 후 반사되는 반사광의 차이를 이용해 산소포화도를 측정할 수 있다. 바람직하게는, 상기 욕창 진단부는, 혈류량 맵을 입력 정보로 하고 욕창 진행 등급을 출력 정보로 하는 상기 학습 완료된 인공지능 모델을 사용하며, 상기 혈류량 맵으로부터 상기 욕창 진행 등급을 판정할 수 있다. 상기한 목적을 달성하기 위한 본 발명의 특징에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 시스템은, 욕창 진단 시스템으로서, 산화 헤모글로빈과 헤모글로빈의 광 흡수 파장 차이를 이용하기 위해 서로 다른 2개의 파장을 갖는 광을 신체 부위에 조사하는 광 조사 장치; 상기 광 조사 장치에서 조사된 광이 표피에서 반사되는 반사광을 측정하는 모바일 카메라; 및 상기 모바일 카메라에서 측정된 반사광을 이용해 상기 신체 부위의 산소포화도 및 혈류량을 분석하고, 욕창을 진단하여 출력하는 사용자 장치를 포함하며, 상기 사용자 장치는, 상기 모바일 카메라에서 측정된 반사광을 이용해 상기 신체 부위의 산소포화도를 측정하고, 상기 신체 부위의 산소포화도 분포도를 작성하는 산소포화도 분석부; 상기 산소포화도 분포도를 기반으로 상기 신체 부위의 표피의 혈류량 맵을 작성하는 혈류량 분석부; 및 학습 완료된 인공지능 모델을 사용해 상기 혈류량 맵으로부터 욕창 진행 등급을 판정하는 욕창 진단부를 포함하 는 것을 그 구성상의 특징으로 한다. 바람직하게는, 상기 광 조사 장치는, 서로 다른 파장의 광을 조사하는 2종류의 광원부; 상기 2종류의 광원부가 번갈아 배치되는 몸체부; 및 상기 2종류의 광원부의 광 조사를 제어하는 제어부를 포함할 수 있다. 더욱 바람직하게는, 상기 몸체부는, 둘 이상의 동심원상에 상기 2종류의 광원부가 번갈아 배치될 수 있다. 더더욱 바람직하게는, 상기 몸체부는, 상기 2종류의 광원부가 배치된 동심원의 중심 부분에 상기 모바일 카메라의 렌즈가 위치하도록 홀이 형성될 수 있다. 더더더욱 바람직하게는, 상기 광 조사 장치는, 상기 몸체부에 형성된 홀에 상기 모바일 카메라의 렌즈가 위치하여 상기 신체 부위의 촬영이 가능하도록 결합되 는 결합부를 더 포함할 수 있다. 더욱더 바람직하게는, 상기 결합부는, 상기 모바일 카메라에 탈착 가능하도록 탈착식으로 구성될 수 있다. 더욱 바람직하게는, 상기 산소포화도 분석부는, 상기 2종류의 광원부에서 조사된 광이 표피에서 흡수 후 반사되는 반사광의 차이를 이용해 산소포화도를 측정할 수 있다. 바람직하게는, 상기 욕창 진단부는, 혈류량 맵을 입력 정보로 하고 욕창 진행 등급을 출력 정보로 하는 상기 학습 완료된 인공지능 모델을 사용하며, 상기 혈류량 맵으로부터 상기 욕창 진행 등급을 판정할 수 있다.\n【발명의 효과】\n본 발명에서 제안하고 있는 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치 및 시스템에 따르면, 서로 다른 2개의 파장을 갖는 광을 신체 부위에 조사하고, 신체 부위에서 반사 되는 광을 모바일 카메라로 촬영하여 산소포화도 분포도 및 혈류량 맵을 작성해 욕창을 진단함으로써, 산화 헤 모글로빈과 헤모글로빈의 광 흡수 파장 차이를 이용해 혈류를 시각화하여 욕창 발생으로 인한 피부 이상을 객관 적으로 감지할 수 있으며, 표준화된 데이터를 기반으로 욕창을 진단할 수 있다.\n【발명을실시하기위한구체적인내용】\n이하, 첨부된 도면을 참조하여 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명을 용이하게 실 시할 수 있도록 바람직한 실시예를 상세히 설명한다. 다만, 본 발명의 바람직한 실시예를 상세하게 설명함에 있어, 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단 되는 경우에는 그 상세한 설명을 생략한다. 또한, 유사한 기능 및 작용을 하는 부분에 대해서는 도면 전체에 걸쳐 동일한 부호를 사용한다. 덧붙여, 명세서 전체에서, 어떤 부분이 다른 부분과 ‘연결’ 되어 있다고 할 때, 이는 ‘직접적으로 연결’ 되 어 있는 경우뿐만 아니라, 그 중간에 다른 소자를 사이에 두고 ‘간접적으로 연결’ 되어 있는 경우도포함한다. 또한, 어떤 구성요소를 ‘포함’ 한다는 것은, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제 외하는 것이 아니라 다른 구성요소를 더 포함할 수 있다는 것을 의미한다. 도 2는 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치의 구성을 도시한 도면이다. 도 2에 도시된 바와 같이, 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치는, 산화 헤모글로빈 과 헤모글로빈의 광 흡수 파장 차이를 이용하기 위해 서로 다른 2개의 파장을 갖는 광을 신체 부위에 조사하는 광 조사부, 광 조사부에서 조사된 광이 표피에서 반사되는 반사광을 측정하는 카메라부, 카메라 부에서 측정된 반사광을 이용해 신체 부위의 산소포화도를 측정하고, 신체 부위의 산소포화도 분포도를 작 성하는 산소포화도 분석부, 산소포화도 분포도를 기반으로 신체 부위의 표피의 혈류량 맵을 작성하는 혈류 량 분석부, 및 학습 완료된 인공지능 모델을 사용해 혈류량 맵으로부터 욕창을 진단하는 욕창 진단부(50 0)를 포함하여 구성될 수 있다. 도 3은 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 시스템의 구성을 도시한 도면이다. 도 3에 도시된 바와 같이, 본 발명의 일실시예에 따른 모바 일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 시스템은, 산화 헤모글 로빈과 헤모글로빈의 광 흡수 파장 차이를 이용하기 위해 서로 다른 2개의 파장을 갖는 광을 신체 부위에 조사 하는 광 조사 장치; 광 조사 장치에서 조사된 광이 표피에서 반사되는 반사광을 측정하는 모바일 카메 라; 및 모바일 카메라에서 측정된 반사광을 이용해 신체 부위의 산소포화도 및 혈류량을 분석하고, 욕 창을 진단하여 출력하는 사용자 장치를 포함하여 구성될 수 있다. 즉, 광 조사 장치와 모바일 카메라가 결합하여 환자의 신체 부위에 광을 조사하고 반사광을 측정할 수 있으며, 모바일 카메라는 측정한 데이터를 사용자 장치와 네트워크를 통해 송신할 수 있다. 사용자 장 치는 수신한 데이터를 분석해 산소포화도 분포도 및 혈류량 맵을 작성하고, 학습 완료된 인공지능 모델을 사용해 욕창 진행 등급을 판정할 수 있다. 즉, 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기 반 욕창 진단 시스템의 광 조사 장치와 모바일 카메라는, 본 발명의 일실시예에 따른 모바일 카메라 로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치의 광 조사부 및 카메 라부의 기능을 할 수 있고, 사용자 장치는 산소포화도 분석부, 혈류량 분석부 및 욕창 진단 부의 기능을 할 수 있다. 여기서, 사용자 장치는 환자를 관리하고 욕창을 치료하는 의료진이 사용하는 전자 장치일 수 있다. 전자 장치는 스마트폰, 태블릿(tablet) PC(personal computer), 이동 전화기, 영상 전화기, 전자책 리더기, 데스크탑 (desktop) PC, 랩탑(laptop) PC, 넷북(netbook) 컴퓨터, 워크스테이션(workstation), 서버(server), PDA(personal digital assistant), 미디어 박스, 게임 콘솔, 전자사전 또는 웨어러블 장치(wearable device) 중 적어도 하나를 포함할 수 있으며, 웨어러블 장치는 액세서리형(예: 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트렌즈, 또는 머리착용형 장치(HMD, head-mounted-device), 직물 또는 의류 일체형(예: 전자 의복), 신체 부착형(예: 스킨 패드(skin pad) 또는 문신), 또는 생체 이식형 회로(implantable circuit) 중 적어도 하나를 포함할 수 있다. 다양한 실시예들에서, 전자 장치는 전술한 기기들에 한정되지는 않으며, 전술한 다양한 장치 중 둘 이상의 조합일 수 있다. 이하에서는, 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인 공지능 기반 욕창 진단 장치의 세부적인 구성에 대해 상세히 살펴보도록 한다.광 조사부는, 산화 헤모글로빈과 헤모글로빈의 광 흡수 파장 차이를 이용하기 위해 서로 다른 2개의 파장 을 갖는 광을 신체 부위에 조사할 수 있다. 욕창이 발생하면 피부조직의 괴사가 일어나며, 이는 발생 부위뿐만 아니라 인근 분위의 혈류량과 산소포화도 이상을 야기한다. 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치는, 이러한 혈류량 및 산소포화도 이상을 관측하여 욕창 부위 및 욕창 진행 등급을 진단할 수 있다. 이를 위해 광 조사부는 산화 헤모글로 빈과 헤모글로빈의 광 흡수 파장 차이를 사용해 표피 내 혈류량을 측정하고 혈류량 이상을 감지하기 위해, 서로 다른 2개의 파장을 갖는 광을 조사하도록 구성될 수 있다. 도 4는 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치에서, 광 조사부의 세부적인 구성을 도시한 도면이고, 도 5는 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치에서, 광 조사부의 정면을 예를 들어 도시한 도면이고, 도 6은 본 발명의 일실시예에 따른 모바일 카메라로 혈 류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치에서, 광 조사부의 측면을 예를 들어 도시한 도면이다. 도 4 내지 도 6에 도시된 바와 같이, 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치의 광 조사부는, 광원부, 몸체부 및 제어부를 포함하여 구성될 수 있으며, 결합부를 더 포함하여 구성될 수 있다. 광원부는, 서로 다른 파장의 광을 조사하는 2종류의 광원으로 구성될 수 있다. 예를 들어, 광원부는 765㎚의 광과 880㎚의 광을 조사하는 2종류의 광원을 포함하며, 각 광원은 복수일 수 있다. 몸체부는, 2종류의 광원부가 번갈아 배치될 수 있다. 보다 구체적으로, 몸체부는, 둘 이상의 동심원상에 2종류의 광원부가 번갈아 배치될 수 있다. 즉, 도 5에 도시된 바와 같이, 몸체부 위의 지름이 서로 다른 두 개의 동심원상에 2종류의 광원부를 번갈아 배치하여, 신체 부위에 2종류의 광이 균일 하게 조사되도록 구성할 수 있다. 또한, 몸체부는, 2종류의 광원부가 배치된 동심원의 중심 부분에 카메라부의 렌즈가 위치하도록 홀이 형성될 수 있다. 중심의 홀로는 카메라부의 렌즈가 삽입되어 한 쪽으로 치우침 없이 반사광이 측정되도록 할 수 있다. 제어부는, 2종류의 광원부의 광 조사를 제어할 수 있다. 보다 구체적으로, 제어부는, 광원부 에서 조사되는 광의 전원, 파장, 세기 등을 제어할 수 있다. 여기서, 제어부는 광 조사 장치의 외면에 구비된 입력부(미도시)나 사용자 장치를 통해 사용자의 제어 신호를 수신하고, 제어 신호에 따라 2 종류의 광원부를 제어할 수 있다. 결합부는, 몸체부에 형성된 홀에 카메라부의 렌즈가 위치하여 신체 부위의 촬영이 가능하도록 모바일 카메라에 결합할 수 있다. 즉, 도 5 및 도 6에 도시된 바와 같이, 몸체부의 중심에 형성된 홀 안쪽으로 결합부가 구성되어, 홀 내부로 삽입된 모바일 카메라의 렌즈를 고정해 결합할 수 있다. 도 7은 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치에서, 광 조사부와 카메라부가 결합한 측면 모습을 예를 들어 도시한 도면이다. 도 7에 도시된 바와 같이, 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단 할 수 있는 인공지능 기반 욕창 진단 장치의 결합부는, 홀에 삽입된 카메라부가 고정되도록 잡아줄 수 있다. 이때, 결합부는, 모바일 카메라에 탈착 가능하도록 탈착식으로 구성될 수 있다. 예를 들어, 결합부는 몸체부의 내부로 스프링을 구비해 스프링의 힘에 의해 모바일 카메라가 고정되도 록 할 수 있다. 카메라부는, 광 조사부에서 조사된 광이 표피에서 반사되는 반사광을 측정할 수 있다. 카메라부 는 일반적인 가시광선 카메라 외에도, 열 영상 카메라, 뎁스 카메라, 적외선 카메라 등 다양한 종류의 카 메라로 구현될 수 있다. 또한, 카메라부는 모바일 카메라로 구현될 수 있으며, 모바일 카메라에 도 5 및 도 6에 도시된 바와 같은 광 조사 장치를 결합해, 간편하게 손에 들고 욕창 환자의 신체 부위에 광 을 조사하고 반사광을 측정함으로써, 움직임이 불편한 환자의 욕창을 진단할 수 있다. 도 8은 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치를 사용해 욕창을 진단하는 모습을 예를 들어 도시한 도면이다. 도 8에 도시된 바와 같이, 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치에서는, 광 조사부에서 조사된 2종류의 광이 신체 부위에서 각각 반사된 반사광을 광 조사 부의 중심에 삽입된 카메라부의 렌즈가 수광하여 측정할 수 있다. 산소포화도 분석부는, 카메라부에서 측정된 반사광을 이용해 신체 부위의 산소포화도를 측정하고, 신 체 부위의 산소포화도 분포도를 작성할 수 있다. 보다 구체적으로는, 산소포화도 분석부는, 2종류의 광원 부에서 조사된 광이 표피에서 흡수 후 반사되는 반사광의 차이를 이용해 산소포화도를 측정할 수 있다. 예를 들어, 도 8에 도시된 바와 같은 예에서, 765㎚ 파장의 광에서는 산화 헤모글로빈의 흡광도가 헤모글로빈의 흡광도보다 작고, 880㎚ 파장의 광에서는 산화 헤모글로빈의 흡광도가 헤모글로빈의 흡광도보다 크다. 산소포 화도 분석부는, 이러한 파장에 따른 흡광도 차이를 사용해 산소포화도를 측정하고, 카메라부에서 촬 영된 신체 부위의 표피에서의 산소포화도 분포도를 작성할 수 있다. 혈류량 분석부는, 산소포화도 분포도를 기반으로 신체 부위의 표피의 혈류량 맵을 작성할 수 있다. 욕창 이 발생하면 발생 부위와 인근 부위에서 혈류 이상을 야기되는데, 혈관 내 헤모글로빈과 산화 헤모글로빈에 의 해 측정된 산소포화도는 혈류에 의해 변화되므로, 신체 부위 표피의 산소포화도 분포도를 기반으로 혈류량 맵을 작성할 수 있다. 도 9는 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치의 혈류량 분석부에서 작성한 혈류량 맵을 예를 들어 도시한 도면이다. 도 9에 도시 된 바와 같이, 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치의 혈류량 분석부는, 산소포화도 분포도로부터 2차원의 표피 혈류량 맵을 도 출할 수 있다. 욕창 진단부는, 학습 완료된 인공지능 모델을 사용해 혈류량 맵으로부터 욕창을 진단할 수 있다. 여기서, 학습 완료된 인공지능 모델은, 2차원 혈류량 맵을 입력 데이터로 하고 욕창 진행 등급을 출력 데이터로 하여 대 량의 학습 데이터로 인공지능 알고리즘을 학습하여 생성된 모델로, 혈류량 맵과 같은 2차원 이미지를 복수의 클 래스로 분류하는 분류기 모델일 수 있다. 예를 들어, CNN(Convolutional neural network), 랜덤 포레스트 (Random Forest), 비전 트랜스포머(Vision Transformer) 등의 인공지능 알고리즘을 혈류량 맵과 욕창 진행 등 급 데이터로 학습해 생성된 모델일 수 있다. 도 10은 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지 능 기반 욕창 진단 장치의 욕창 진단부의 진단 과정을 설명하기 위해 도시한 도면이다. 도 10에 도시된 바와 같이, 본 발명의 일실시예에 따른 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공 지능 기반 욕창 진단 장치의 욕창 진단부는, 혈류량 맵을 입력 정보로 하고 욕창 진행 등급을 출력 정보로 하는 학습 완료된 인공지능 모델을 사용하며, 혈류량 맵으로부터 욕창 진행 등급을 판정할 수 있다. 이때, 욕 창 진행 등급은, 욕창 아님, 욕창 1단계, 2단계, 3단계 및 4단계의 총 5개의 클래스로 분류될 수 있다.한편, 욕창 진단부는, 혈류량 맵을 미리 정해진 개수로 분할하고, 분할된 맵 각각을 학습 완료된 인공지능 모델에 입력해 분할된 맵마다 욕창 등급을 출력할 수도 있다. 욕창 진단부는 각 분할된 맵별로 출력된 욕 창 등급을 혈류량 맵에 매핑하여 사용자 장치로 출력할 수 있다. 따라서, 전체 신체 부위 중에서도 개별 영역마다 서로 다를 수 있는 욕창 등급을 세밀하게 진단하고, 각 부분에 대해 적절한 치료가 이루어지도록 할 수 있다. 전술한 바와 같이, 본 발명에서 제안하고 있는 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있 는 인공지능 기반 욕창 진단 장치 및 시스템에 따르면, 서로 다른 2개의 파장을 갖는 광을 신체 부위에 조사하 고, 신체 부위에서 반사되는 광을 모바일 카메라로 촬영하여 산소포화도 분포도 및 혈류량 맵을 작성해 욕 창을 진단함으로써, 산화 헤모글로빈과 헤모글로빈의 광 흡수 파장 차이를 이용해 혈류를 시각화하여 욕창 발생 으로 인한 피부 이상을 객관적으로 감지할 수 있으며, 표준화된 데이터를 기반으로 욕창을 진단할 수 있다. 한편, 본 발명은 다양한 통신 단말기로 구현되는 동작을 수행하기 위한 프로그램 명령을 포함하는 컴퓨터에서 판독 가능한 매체를 포함할 수 있다. 예를 들어, 컴퓨터에서 판독 가능한 매체는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD_ROM, DVD와 같은 광기록 매체(optical media), 플롭티 컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media) 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 이와 같은 컴퓨터에서 판독 가능한 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합 하여 포함할 수 있다. 이때, 컴퓨터에서 판독 가능한 매체에 기록되는 프로그램 명령은 본 발명을 구현하기 위 하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 예를 들어, 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 이상 설명한 본 발명은 본 발명이 속한 기술분야에서 통상의 지식을 가진 자에 의하여 다양한 변형이나 응용이 가능하며, 본 발명에 따른 기술적 사상의 범위는 아래의 특허청구범위에 의하여 정해져야 할 것이다.\n【요약】본 발명은 모바일 카메라로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치에 관한 것으로서, 보다 구체적으로는 욕창 진단 장치로서, 산화 헤모글로빈과 헤모글로빈의 광 흡수 파장 차이를 이용하 기 위해 서로 다른 2개의 파장을 갖는 광을 신체 부위에 조사하는 광 조사부; 상기 광 조사부에서 조사된 광이 (뒷면에 계속)\n\n【청구항 1】\n욕창 진단 장치로서,산화 헤모글로빈과 헤모글로빈의 광 흡수 파장 차이를 이용하기 위해 서로 다른 2개의 파장을 갖는 광을 신체부위에 조사하는 광 조사부(100);상기 광 조사부(100)에서 조사된 광이 표피에서 반사되는 반사광을 측정하는 카메라부(200);상기 카메라부(200)에서 측정된 반사광을 이용해 상기 신체 부위의 산소포화도를 측정하고, 상기 신체 부위의산소포화도 분포도를 작성하는 산소포화도 분석부(300);상기 산소포화도 분포도를 기반으로 상기 신체 부위의 표피의 혈류량 맵을 작성하는 혈류량 분석부(400); 및학습 완료된 인공지능 모델을 사용해 상기 혈류량 맵으로부터 욕창을 진단하는 욕창 진단부(500)를 포함하는 것을 특징으로 하는, 모바일 카메라(20)로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단장치.\n【청구항 2】\n제1항에 있어서, 상기 광 조사부(100)는,서로 다른 파장의 광을 조사하는 2종류의 광원부(110);상기 2종류의 광원부(110)가 번갈아 배치되는 몸체부(120); 및상기 2종류의 광원부(110)의 광 조사를 제어하는 제어부(130)를 포함하는 것을 특징으로 하는, 모바일 카메라(20)로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치.\n【청구항 3】\n제2항에 있어서, 상기 몸체부(120)는,둘 이상의 동심원상에 상기 2종류의 광원부(110)가 번갈아 배치되는 것을 특징으로 하는, 모바일 카메라(20)로혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치.\n【청구항 4】\n제3항에 있어서, 상기 몸체부(120)는,상기 2종류의 광원부(110)가 배치된 동심원의 중심 부분에 상기 카메라부(200)의 렌즈가 위치하도록 홀이 형성된 것을 특징으로 하는, 모바일 카메라(20)로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창진단 장치.\n【청구항 5】\n제4항에 있어서, 상기 광 조사부(100)는,상기 몸체부(120)에 형성된 홀에 상기 카메라부(200)의 렌즈가 위치하여 상기 신체 부위의 촬영이 가능하도록모바일 카메라(20)에 결합되는 결합부(140)를 더 포함하는 것을 특징으로 하는, 모바일 카메라(20)로 혈류의 양공개특허 10-2024-0002096-3-을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치.\n【청구항 6】\n제5항에 있어서, 상기 결합부(140)는,상기 모바일 카메라(20)에 탈착 가능하도록 탈착식으로 구성되는 것을 특징으로 하는, 모바일 카메라(20)로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치.\n【청구항 7】\n제3항에 있어서, 상기 산소포화도 분석부(300)는,상기 2종류의 광원부(110)에서 조사된 광이 표피에서 흡수 후 반사되는 반사광의 차이를 이용해 산소포화도를측정하는 것을 특징으로 하는, 모바일 카메라(20)로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치.\n【청구항 8】\n제1항에 있어서, 상기 욕창 진단부(500)는,혈류량 맵을 입력 정보로 하고 욕창 진행 등급을 출력 정보로 하는 상기 학습 완료된 인공지능 모델을사용하며, 상기 혈류량 맵으로부터 상기 욕창 진행 등급을 판정하는 것을 특징으로 하는, 모바일 카메라(20)로혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 장치.\n【청구항 9】\n욕창 진단 시스템으로서,산화 헤모글로빈과 헤모글로빈의 광 흡수 파장 차이를 이용하기 위해 서로 다른 2개의 파장을 갖는 광을 신체부위에 조사하는 광 조사 장치(10);상기 광 조사 장치(10)에서 조사된 광이 표피에서 반사되는 반사광을 측정하는 모바일 카메라(20); 및상기 모바일 카메라(20)에서 측정된 반사광을 이용해 상기 신체 부위의 산소포화도 및 혈류량을 분석하고, 욕창을 진단하여 출력하는 사용자 장치(30)를 포함하며,상기 사용자 장치(30)는,상기 모바일 카메라(20)에서 측정된 반사광을 이용해 상기 신체 부위의 산소포화도를 측정하고, 상기 신체 부위의 산소포화도 분포도를 작성하는 산소포화도 분석부(300);상기 산소포화도 분포도를 기반으로 상기 신체 부위의 표피의 혈류량 맵을 작성하는 혈류량 분석부(400); 및학습 완료된 인공지능 모델을 사용해 상기 혈류량 맵으로부터 욕창 진행 등급을 판정하는 욕창 진단부(500)를포함하는 것을 특징으로 하는, 모바일 카메라(20)로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 시스템.\n【청구항 10】\n제9항에 있어서, 상기 광 조사 장치(10)는,서로 다른 파장의 광을 조사하는 2종류의 광원부(110);상기 2종류의 광원부(110)가 번갈아 배치되는 몸체부(120); 및공개특허 10-2024-0002096-4-상기 2종류의 광원부(110)의 광 조사를 제어하는 제어부(130)를 포함하는 것을 특징으로 하는, 모바일 카메라(20)로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 시스템.\n【청구항 11】\n제10항에 있어서, 상기 몸체부(120)는,둘 이상의 동심원상에 상기 2종류의 광원부(110)가 번갈아 배치되는 것을 특징으로 하는, 모바일 카메라(20)로혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 시스템.\n【청구항 12】\n제11항에 있어서, 상기 몸체부(120)는,상기 2종류의 광원부(110)가 배치된 동심원의 중심 부분에 상기 모바일 카메라(20)의 렌즈가 위치하도록 홀이형성된 것을 특징으로 하는, 모바일 카메라(20)로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반욕창 진단 시스템.\n【청구항 13】\n제12항에 있어서, 상기 광 조사 장치(10)는,상기 몸체부(120)에 형성된 홀에 상기 모바일 카메라(20)의 렌즈가 위치하여 상기 신체 부위의 촬영이 가능하도록 결합되는 결합부(140)를 더 포함하는 것을 특징으로 하는, 모바일 카메라(20)로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 시스템.\n【청구항 14】\n제13항에 있어서, 상기 결합부(140)는,상기 모바일 카메라(20)에 탈착 가능하도록 탈착식으로 구성되는 것을 특징으로 하는, 모바일 카메라(20)로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 시스템.\n【청구항 15】\n제10항에 있어서, 상기 산소포화도 분석부(300)는,상기 2종류의 광원부(110)에서 조사된 광이 표피에서 흡수 후 반사되는 반사광의 차이를 이용해 산소포화도를측정하는 것을 특징으로 하는, 모바일 카메라(20)로 혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 시스템.\n【청구항 16】\n제9항에 있어서, 상기 욕창 진단부(500)는,혈류량 맵을 입력 정보로 하고 욕창 진행 등급을 출력 정보로 하는 상기 학습 완료된 인공지능 모델을사용하며, 상기 혈류량 맵으로부터 상기 욕창 진행 등급을 판정하는 것을 특징으로 하는, 모바일 카메라(20)로혈류의 양을 측정하여 욕창을 진단할 수 있는 인공지능 기반 욕창 진단 시스템."}
{"context": "", "input": "【기술명】\n공유자원을 이용한 인공지능 공동연구 시스템\n\n【기술 설명】\n본 발명은 인공지능 공동연구 시스템으로, 여러 연구자들이 공유자원을 통해 효율적으로 연구환경을 제공받고 분석 및 학습을 수행할 수 있는 혁신적인 플랫폼입니다. 이 시스템은 외부 데이터를 수집하고 가공하여 저장하며, 표준화된 연구환경을 생성 및 관리하는 기능을 포함합니다. 연구자들은 실시간으로 데이터를 모니터링하고 공유할 수 있으며, 이를 통해 협업의 효율성을 극대화합니다. 이 시스템은 데이터관리유닛, 표준환경관리유닛, 연구환경관리유닛 및 자원관리유닛으로 구성되어, 연구자들이 상호작용하고 공동으로 작업할 수 있는 통합된 환경을 제공합니다.\n\n【해결 문제】\n기존의 인공지능 연구 환경에서는 각 연구자가 개별적으로 서버를 구축하고 데이터 공유를 비효율적인 방법으로 처리해야 했습니다. 이는 연구 결과의 신속한 공유를 방해하고, 데이터 형식의 불일치로 인해 협업의 장애가 발생했습니다. 본 발명은 이러한 문제를 해결하기 위해, 데이터의 일관성을 유지하고 실시간으로 공유할 수 있는 시스템을 제공합니다. 이를 통해 연구자들은 보다 효율적으로 협업할 수 있으며, 제한된 자원에서도 최적의 연구 결과를 도출할 수 있는 환경을 조성합니다.\n\n【기술 차별성】\n본 발명은 기존의 분산 서버 기반 연구 접근 방식과 차별화된 점이 있습니다. 각 연구자가 필요한 연구환경을 자동으로 생성하고, 표준화된 데이터를 관리하여 형식의 불일치를 예방하며, 실시간 모니터링 및 데이터 공유 기능을 통해 협업을 강화합니다. 특히, 데이터 수집 및 가공 과정의 자동화를 통해 시간과 자원을 절약할 수 있으며, 연구자들이 개별적으로 구축해야 했던 환경을 통합하여 제공함으로써 혁신적인 효율성을 제공합니다. 이러한 기술적 진보는 인공지능 연구 분야에서의 협업을 한 단계 끌어올리는 중요한 기회를 제공합니다.\n\n【활용 분야】\n본 발명인 인공지능 공동연구 시스템은 의료, 생명과학, 환경과학, 데이터 과학, 제조업 등 다양한 산업 분야에 활용될 수 있습니다. 특히, 인공지능 모델을 기반으로 한 연구 및 개발이 필요한 분야에서 연구자들이 협력하여 데이터를 분석하고 학습할 수 있는 환경을 제공함으로써, 신약 개발, 환경 모니터링, 스마트 제조 등의 혁신을 가속화할 수 있습니다. 또한, 학계와 산업계의 공동 연구를 통해 지식의 경계를 허물고, 연구의 효율성을 극대화하는 데 기여할 것입니다.\n\n【구성 요소 및 기능】\n1. 데이터관리유닛: 이 유닛은 외부 데이터를 수집하여 일정 형태로 가공하고 저장하는 역할을 수행합니다. 데이터수집부는 다양한 소스에서 데이터를 수집하고, 데이터저장부는 수집된 데이터를 그룹데이터로 저장하여 메타데이터를 통해 접근할 수 있도록 합니다. 데이터관리부는 저장된 데이터를 탐색, 삭제 및 수정하는 기능을 제공하여 데이터 관리의 유연성을 높입니다.  \n2. 표준환경관리유닛: 이 유닛은 연구환경의 기반이 되는 표준환경을 저장하고 관리합니다. 연구자들은 이 유닛을 통해 표준환경의 생성, 삭제 및 조회를 수행할 수 있으며, 이를 통해 연구환경의 일관성을 유지하고 필요한 연구 조건을 손쉽게 설정할 수 있습니다.  \n3. 연구환경관리유닛: 이 유닛은 연구환경을 생성하고 인공지능 연산을 요청하는 기능을 담당합니다. 연구환경 생성을 위한 자원을 할당받고, 선택한 표준환경의 정보를 기반으로 연구환경을 생성하며, 데이터관리유닛으로부터 데이터를 전송받아 인공지능 연산을 요청하는 과정을 관리합니다. 이를 통해 연구자들은 실시간으로 협업할 수 있는 최적의 연구 환경을 마련할 수 있습니다.\n\n【구현 방식 예】\n인공지능 공동연구 시스템의 구현 방식은 단계별로 세분화되어 있습니다. 첫째, 외부 데이터 수집 및 가공 단계에서는 다양한 데이터 소스에서 정보를 수집하고, 이를 데이터관리유닛의 데이터수집부에서 적절한 형태로 가공합니다. 둘째, 표준환경의 설정 단계에서는 표준환경관리유닛을 통해 연구자들이 요구하는 연구 환경을 설정하고, 이를 기반으로 연구환경을 생성합니다. 마지막으로, 연구환경에서의 인공지능 연산 단계에서는 연구환경관리유닛이 데이터관리유닛으로부터 데이터를 수신하여 인공지능 연산을 요청하고, 자원관리유닛이 이를 처리하여 연구자들이 실시간으로 결과를 공유하고 분석할 수 있도록 하는 방식으로 진행됩니다. 이러한 단계적 접근은 시스템의 효율성과 협업의 원활함을 보장합니다.", "output": "【발명의 명칭】\n공유자원을 이용한 인공지능 공동연구 시스템\n【기술분야】\n본 발명은 인공지능 공동연구 시스템에 관한 것으로서, 상세하게는 인공지능 모델을 이용한 연구에 있어서, 여 러 연구자들이 공유자원으로부터 연구환경을 제공받아 분석 및 학습을 진행하고, 실시간으로 모니터링 및 공유 가 가능하게 하는 공동연구 시스템과 관련된다.\n【배경기술】\n일반적으로 인공지능을 이용하여 공동연구를 수행할 때 각 연구기관 혹은 연구자들은 분산된 서버에서 연구를 진행한다. 이때 각 연구자들은 연구에 필요한 컴퓨팅 자원 및 환경을 구축해야 하고, 공동연구를 하면서 필요한 연구 데이 터, 연구결과 및 의견의 공유는 메일 또는 메신저를 통해 이루어진다. 또한 여러 연구자의 병렬적인 연구를 위 해 자원 스케줄링 메커니즘 혹은 자원 운용 규칙을 갖추어야 할 필요가 있다. 하지만 운용 가능한 자원이 한정적인 연구기관의 경우 이를 갖추는 것은 쉽지 않다. 또한 연구환경과 데이터의 형식이 연구자마다 다를 수 있고 이에 따라 특정 연구자가 연구한 환경에 맞춰 다른 연구자도 동일한 환경을 구 축하거나 데이터 형식을 일치시키기 위한 작업이 필요할 수 있다. 또한 연구결과와 의견의 공유를 메일이나 메신저를 사용하여 하게 되면 적기에 결과나 의견의 공유가 어려워 비 효율적인 측면이 있으며, 분석 대상이 되는 데이터를 수집하는 측면에 있어서도 개별적인 데이터 수집 및 가공 프로세스를 사용하게 되므로 데이터 수집에 시간이 들고 형식의 불일치가 발생할 수도 있어 다른 연구자가 데이터를 사용하는 데에 어려움이 있을 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 제10-2109044호 (2020.05.04)\n【해결하려는 과제】\n그 외 본 발명의 세부적인 목적은 이하에 기재되는 구체적인 내용을 통하여 이 기술분야의 전문가나 연구자에게 자명하게 파악되고 이해될 것이다.\n【과제의 해결 수단】\n위 과제를 해결하기 위하여 본 발명은 실시예로, 외부 데이터를 수집하고, 일정 형태로 가공하여 저장하며, 삭 제, 조회, 변경이 가능하도록 관리하는 데이터관리유닛, 연구환경의 기반이 되는 표준환경을 저장하고 상기 표 준환경의 생성, 삭제, 조회가 가능하도록 관리하는 표준환경관리유닛, 연구환경 생성을 위한 자원을 할당받고, 상기 표준환경관리유닛으로부터 선택한 표준환경의 정보를 전송받아 연구환경을 생성하며, 생성된 상기 연구환 경에서 상기 데이터관리유닛으로부터 데이터를 전송받아 인공지능 연산을 요청하도록 관리하는 연구환경관리유 닛 및 공유자원을 관리하고 상기 연구환경관리유닛에 연구환경의 생성을 위한 자원을 할당하는 한편 상기 연구 환경관리유닛으로부터 연산요청이 있을 때 상기 공유자원을 통해 인공지능 연산을 수행하도록 관리하는 자원관 리유닛을 포함하는 인공지능 공동연구 시스템을 제시한다. 여기에서 상기 데이터관리유닛은, 외부 데이터를 전송받아 데이터를 일정 형태로 가공하는 데이터수집부, 상기 데이터수집부에서 수집하여 가공한 데이터를 특징에 따른 항목들과 해당 항목들의 구체적인 데이터를 포함하는 그룹데이터로 저장하는 한편 상기 그룹데이터에 접근할 수 있도록 그룹데이터의 항목들로 이루어진 메타데이터 를 저장하는 데이터저장부 및 상기 데이터저장부에 저장된 메타데이터를 활용하여 저장된 데이터를 탐색, 삭제 및 수정하는 기능을 수행하는 데이터관리부를 포함할 수 있다. 이때 상기 데이터수집부는 시계열 데이터를 수집하고, 다양한 형태의 시계열 데이터를 입력받아 표준화된 형태 의 데이터로 만들고 시간 순서에 따라 정렬하는 데이터수집모듈, 상기 데이터수집모듈에서 수집하여 정렬한 데 이터에서 시간 관련 정보를 표준화된 데이트타임 형태로 변환하는 데이터형변환모듈, 상기 데이터형변환모듈에 서 변환된 시계열 데이터가 시간 순서대로 정렬되었는지와 누락된 날짜는 없는지 검증하는 데이터검증모듈 및 상기 데이터검증모듈에서 검증에 이상이 있는 경우 시간 순서대로 정렬하거나 누락된 날짜의 데이터를 보충함으 로써 데이터를 보정하는 데이터정제모듈을 포함할 수 있다. 한편 상기 데이터저장부에서 저장되는 그룹데이터는 복수로 이루어질 수 있다. 한편 상기 데이터관리부는 상기 데이터저장부에 저장된 메타데이터를 통해 상기 그룹데이터를 삭제, 조회 및 수 정할 수 있다. 또한 상기 표준환경관리유닛은, 인공지능 연구에 필요한 기본적인 설정을 포함한 가상환경인 표준환경을 저장하 는 표준환경저장부 및 상기 표준환경저장부에 표준환경을 생성하거나 삭제하거나 조회하는 기능을 수행하는 표 준환경관리부를 포함할 수 있다. 이때 상기 표준환경은, 인공지능 연구에 필요한 프로그래밍 언어, 하드웨어 및 라이브러리가 구축된 가상환경일 수 있다. 또한 상기 연구환경관리유닛은, 상기 표준환경관리유닛에 저장된 표준환경 중 사용하고자 하는 표준환경을 선택 하고 상기 자원관리유닛으로부터 해당 표준환경을 사용할 가용자원을 할당받아 연구를 수행할 수 있는 연구환경 을 생성하는 연구환경생성부, 상기 연구환경생성부에 의해 생성된 연구환경을 저장하는 연구환경저장부, 상기 연구환경저장부에 저장된 연구환경을 활성 또는 비활성화하거나 삭제하는 관리를 수행하는 연구환경관리부, 상 기 연구환경관리부에 의해 활성화된 연구환경에 대해 사용자들이 접근할 수 있도록 연결해 주는 연구환경연결부, 상기 연구환경연결부를 통해 상기 연구환경에 접근한 사용자들이 인공지능 연산을 수행하고자 할 때 상기 자원관리유닛에 공유자원을 통한 인공지능 연산을 요청하는 연산요청부 및 특정 연구환경에 대해 특 정 사용자의 접근 가능 여부를 설정하고 해당 연구환경의 연구 진행 내용과 결과물을 접근 가능한 사용자들에게 제공하는 연구환경공유부를 포함할 수 있다. 이때 상기 연구환경은, 상기 표준환경관리유닛으로부터 제공된 표준환경을 기반으로 생성된 연구표준환경, 상기 데이터관리유닛으로부터 데이터를 불러오거나 상기 데이터관리유닛에 데이터를 저장하도록 연결해 주는 데이터 연결모듈 및 상기 데이터연결모듈을 통해 상기 데이터관리유닛으로부터 불러온 데이터로 상기 연구표준환경을 이용하여 인공지능 연산을 수행하는 연구모듈을 포함할 수 있다. 한편 상기 연구환경관리유닛은, 상기 연구환경생성부에 의해 생성된 연구환경과 동일한 연구환경을 새롭게 생성 하여 상기 연구환경저장부에 저장하는 연구환경재활용부를 더 포함할 수 있다. 또한 상기 자원관리유닛은, 상기 연구환경관리유닛에서 연구환경을 생성할 때 상기 연구환경의 운용을 위한 기 본적인 자원을 할당하는 기본자원할당부 및 공유자원의 사용을 모니터링 및 관리하고 상기 연구환경관리유닛에 서 연산요청이 있는 경우 상기 공유자원을 통해 수행하도록 관리하는 자원관리부를 포함할 수 있다. 이때 상기 자원관리부는, 상기 공유자원 사용을 모니터링하면서 상기 연구환경관리유닛으로부터 받은 연산요청 을 스케줄링하여 사용 가능한 공유자원 중 연산을 담당하는 연산자원에서 처리하도록 하고, 상기 연산자원을 통 해 얻은 연산 결과를 상기 연구환경관리유닛으로 전달할 수 있다.\n【발명의 효과】\n그 외 본 발명의 효과들은 이하에 기재되는 구체적인 내용을 통하여, 또는 본 발명을 실시하는 과정 중에 이 기 술분야의 전문가나 연구자에게 자명하게 파악되고 이해될 것이다.\n【발명을실시하기위한구체적인내용】\n상술한 본 발명의 특징 및 효과는 첨부된 도면과 관련한 다음의 상세한 설명을 통하여 보다 분명해 질 것이며, 그에 따라 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 발명의 기술적 사상을 용이하게 실시할 수 있을 것이다. 본 발명은 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있는 바, 특정 실시 예들을도면에 예시하고 본문에 상세하게 설명하고자 한다. 그러나 이는 본 발명을 특정한 개시형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해 되어야 한다. 본 출원에서 사용한 용어는 단지 특정한 실시 예들을 설명하기 위해 사용된 것으로, 본 발명을 한 정하려는 의도가 아니다. 이하, 본 발명의 일 실시예에 따른 인공지능 공동연구 시스템에 대해 도면을 참조하여 상세하게 설명한다. 본 명세서에서는 서로 다른 실시예라도 동일유사한 구성에 대해서는 동일유사한 참조번호를 부여하고, 그 설명 은 처음 설명으로 갈음한다. 본 발명의 실시예에 따른 인공지능 공동연구 시스템은, 데이터관리유닛, 표준환경관리유닛, 연구환 경관리유닛 및 자원관리유닛을 포함하여 이루어진다. 데이터관리유닛은, 외부 데이터를 수집하고, 일정 형태로 가공하여 저장하며, 데이터의 삭제, 조회, 변경이 가능하도록 관리한다. 한편 표준환경관리유닛은, 연구환경의 기반이 되는 표준환경을 저장하고 표준환경의 생성, 삭제, 조회 가 가능하도록 관리한다. 연구환경관리유닛은, 연구환경 생성을 위한 자원을 할당받고, 표준환경관리유닛으로부터 선택한 표 준환경의 정보를 전송받아 연구환경을 생성하며, 생성된 연구환경에서 데이터관리유닛으로부터 데 이터를 전송받아 연산을 요청하도록 관리한다. 자원관리유닛은, 공유자원을 관리하고 연구환경관리유닛에 연구환경의 생성을 위한 자원을 할당 하는 한편 연구환경관리유닛부터 연산요청이 있을 때 공유자원을 통해 연산을 수행하도록 관리한다. 이와 같은 구성을 통해, 인공지능을 이용한 공동연구를 할 때 여러 연구자들이 표준화된 데이터와 표준화된 연 구환경에서 작업이 가능하다. 이에 따라 연구자 상호간의 연구결과의 공유가 손쉽게 이루어질 수 있다. 또한 공 유자원의 이용을 통해 소규모의 연구기관에서도 필요한 만큼 자원을 할당받아 충실한 연구가 가능하다. 이하 각 구성에 대해 도면을 참조하여 상세하게 설명한다. 도 1은 본 발명의 실시예에 따른 인공지능 공동연구 시스템을 나타내는 블럭도이고, 도 2는 이러한 인공지능 공 동연구 시스템에 채용된 데이터관리유닛을 나타내는 블록도이다. 데이터관리유닛은, 외부 데이터를 수집하여 일정 형태로 가공하여 저장하며, 저장된 데이터를 관리하는 구성 으로서, 데이터수집부, 데이터저장부 및 데이터관리부를 포함한다. 데이터수집부는 외부 데이터를 전송받고 전송된 데이터의 형변환, 검증 및 정제의 과정을 거쳐 연구 목적에 맞는 데이터로 가공한다. 예를 들어 연구 목적이 시간에 따른 변동 추이를 알아보는 것에 있을 때 외부 데이터로서 시간 정보를 포함한 데이터를 전송받고, 전송받은 데이터를 시계열적 형태로 가공할 수 있다. 이때 데이터를 시계열적 형태로 가공 한다는 것은 시간을 첫번째 칼럼으로 하여 각 데이터를 시간 순서대로 나열되도록 하는 것이 될 수 있다. 이러한 기능을 수행하기 위하여 데이터수집부는, 데이터수집모듈, 데이터형변환모듈, 데이터검증 모듈 및 데이터정제모듈을 포함하여 이루어질 수 있다. 데이터수집모듈은, 외부테이터소스로부터 다양한 형태의 외부 데이터를 입력받아 표준화된 형태의 데 이터로 만들고 정해진 형태로 정렬한다. 외부 데이터는 다양한 형태를 가질 수 있는데(예를 들어 csv파일, parquet파일), 데이터수집모듈은 이를 표준화된 형식의 데이터(예를 들어 dataframe)로 만든다. 데이터형변환모듈은, 데이터수집모듈에서 수집하여 정렬한 데이터에서 데이터에 포함된 각 정보를 표 준화된 형식으로 변환한다. 이러한 과정을 통해 수집된 외부 데이터에서 형태에 따라 다르게 되어 있는 정보들의 형식을 표준화된 형태로 변환할 수 있다. 예를 들어 시간 정보의 경우 정해진 형식(yyyy-MM-dd)의 데이트-타임(datetime) 형태로 변환할 수 있다. 한편 입력받은 외부 데이터가 시간 정보를 포함한 데이터(이하 시계열 데이터라고 함)인 경우 시간 정보를 데이트-타 임 형태로 변환한 후 시간 순서에 따라 정렬할 수 있다. 이와 같이 수집되어 변환된 데이터의 예가 도 3에 도시되어 있다. 데이터검증모듈은, 데이터형변환모듈에서 변환된 데이터가 이상이 있는지 검증한다. 먼저 데이터검증모듈은 각 항목별 일관성이 유지되는지 검증한다. 또한 항목별 특성을 고려하여 결측치 및 이상치가 없는지 검증한다. 특히 데이터가 시계열 데이터인 경우 항목별 데이터가 시간순으로 정렬되었는지, 누 락된 날짜는 없는지 검증한다. 데이터정제모듈은, 데이터검증모듈에서 수행하는 검증에 이상이 있는 경우 데이터를 보정한다. 이때 시간 순서대로 데이터를 정렬하거나 누락된 날짜의 데이터를 보충함으로써 데이터를 보정할 수 있다. 상세하게는 데이터검증모듈에서 데이터 검증을 할 때, 결측치나 이상치가 발생하는 경우에는 데이터검증모 듈은 데이터정제모듈에 보정을 요청하고 데이터정제모듈에서는 중심 경향 값(평균값, 중앙값, 최빈값)이나 보간법을 통해 결측치나 이상치를 보정할 수 있다. 예를 들어 변이 바이러스 비율을 일자별 데이터로 만들려고 하는 경우 도 3에 도시된 바와 같이 항목(Country, VariantofConcern 칼럼)에 해당하는 데이터들을 일자(tDate 칼럼)를 기준으로 하여 순서대로 정렬하게 되는데 이때 일자별 데이터로 만든 후 빈 날짜는 선형보간법을 통해 값을 채울 수 있다. 이와 같이 외부 데이터로부터 데이터의 형변환, 검증, 정제의 과정을 거쳐 연구 목적에 맞는 데이터 수집을 완 료할 수 있다. 상술한 데이터수집부는 수집을 진행하는 데이터 엔지니어가 프로그래밍을 통해 구성할 수 있다. 이때, 데이 터수집부를 거친 데이터는 분석 혹은 학습에 바로 쓰일 수 있게 가공이 완료된 상태이다. 데이터저장부는 데이터수집부에서 수집하여 가공한 데이터를 특징에 따른 항목들 및 해당 항목들의 구 체적인 데이터를 포함하는 그룹데이터로 저장하는 한편 이 그룹데이터에 접근할 수 있도록 그룹데이 터의 항목들로 이루어진 메타데이터를 저장한다. 이때 그룹데이터는 특징 그룹(feature group)에 따라 복수로 이루어질 수 있고, 특징 그룹이란 기본항목인 특징키(feature key)를 포함하여 특징 항목들을 여러 형태로 조합하는 것이며 복수로 존재할 수 있다. 이때 특징키와 특징들로 이루어진 항목 데이터에 대한 정보는 메타데이터(meta data)로 저장되며, 데이터 관리부에서 메타데이터를 조회하여 해당 항목에 저장되어 있는 데이터들을 탐색할 수 있다. 도 4는 데이터관리유닛에서 생성된 그룹데이터의 예를 나타낸다. 도 4는 국가별 변이바이러스 비율을 나타내는 그룹데이터이고 일자(tDate), 국가(Country), 변이(VariantofConcern)가 특징키가 되며, 토탈시 퀀스(total_sequences), 클러스터시퀀스(cluster_sequences), 비율(proportion)이 특징이 된다. 이외에도 국가 별 확진자 사망자 수, 국가별 백신접종율 등 필요한 그룹데이터를 저장할 수 있다. 한편 도 5에는 국가별 확진자 사망자 수, 국가별 백신접종율 및 국가별 변이바이러스 비율에 대한 메타데이터 의 예가 도시되어 있다. 이러한 메타데이터를 통해 원하는 그룹데이터로 빠르게 접근할 수 있다. 데이터관리부는 데이터저장부의 메타데이터를 활용하여 저장된 데이터를 탐색, 삭제 및 수정하는 기능을 수행한다. 예를 들어 국가별 백신접종률 데이터를 조회하고자 할 때, 국가별 백신접종율에 대한 그룹데이터를 불러오 고, 특징키를 지정하여 나머지 특징들을 불러올 수 있다. 예를 들면 국가별 백신접종율에 대한 그룹데이터를 불 러온 후 2020-05-30~2022-08-30의 기간(tDate)과 한국(Country)으로 특징키를 지정하면 해당 기간 한국의 백신 접종율(VaccinatedRate)을 조회할 수 있다. 한편 데이터관리부는 데이터저장부를 필요에 따라 이중화 또는 다중화하여 안정성을 관리하고, 장애 및 재해에 대비할 수 있다. 이와 같이 데이터관리유닛을 통해 데이터를 수집 및 정제하고, 표준화하여 저장함으로써 표준화된 공유 데이 터 저장소를 제공할 수 있고, 공동연구 시 동질의 데이터 확보 및 공유를 수월하게 할 수 있다. 또한 확보된 데 이터에 대해 재사용성을 높여 불필요한 수집 및 전처리 프로세스를 줄일 수 있으므로 효율적인 연구가 가능하게 된다. 표준환경관리유닛은 연구환경의 기반이 되는 표준환경을 생성 및 저장하고, 삭제, 조회가 가능하도록 관리하는 구성으로서, 인공지능 연구에 있어 필요한 환경들을 표준화하여 구성해 놓은 표준환경저장부와 이 를 관리하는 표준환경관리부를 포함하여 구성될 수 있다. 표준환경저장부는 인공지능 연구에 필요한 기본적인 설정을 포함한 가상환경인 표준환경이 저장된다. 여기 에서 표준환경이란 인공지능 연구에 필요한 기본적인 프로그래밍 언어, 자원 활용 및 자원 가속화 라이브러리, 데이터 전처리, 시각화, ML 프레임워크 등이 구축된 가상환경일 수 있다. 이때 사용자의 필요에 따라 다양한 구 성이 존재할 수 있기 때문에 다양한 표준환경을 구축하여 표준환경저장부에 저장해 두는 것이 바람직하다. 한편 표준환경관리부는 표준환경저장부에 표준환경을 생성하거나 삭제하거나 조회하는 기능을 수행한다. 도 6은 표준환경관리유닛을 나타내는 블럭도로서 표준환경의 예들이 제시되어 있다. 도면을 참조하면 표준환경 1은 파이썬(Python) 기반에서 GPU 자원을 사용할 수 있는 가상환경을 나타내고, 표준 환경 2는 R기반에서 CPU 자원을 사용할 수 있는 가상환경을 나타낸다. 이와 같이 다양한 환경으로 표준환경을 구축할 수 있다. 한편 표준환경관리부는 생성한 표준환경 1, 표준환경 2에 추가하여 새로운 표준환경을 추가하거나 기존 표 준환경을 삭제할 수 있다. 이와 같이 표준환경관리유닛을 통해 연구환경을 위한 표준환경이 생성되므로 연구환경을 연구자가 직접 구축하지 않아도 되고 표준환경을 불러와 연구환경에서 사용할 수 있다. 또한 사용자들이 동일한 연 구환경을 기반으로 연구를 할 수 있게 되므로 연구환경을 동일하게 하기 위한 시간과 비용을 절약할 수 있다. 도 7은 연구환경관리유닛을 나타내는 블럭도이다. 연구환경관리유닛은 자원을 할당받고, 표준환경관리유닛으로부터 표준환경 정보를 받아 연구환경을 생성하며, 생성된 연구환경에서 데이터관리유닛으로부터 데이터를 전송받아 연산을 요청하도록 관리하 는 구성으로서, 연구환경생성부, 연구환경저장부, 연구환경관리부, 연구환경연결부, 연산요청 부 및 연구환경공유부을 포함한다. 연구환경생성부는, 표준환경관리유닛에 저장된 표준환경 중 사용하고자 하는 표준환경을 선택하고 자원 관리유닛으로부터 해당 표준환경을 사용할 가용자원을 할당받아 연구를 수행할 수 있는 연구환경을 생 성한다. 이때 생성되는 연구환경은 인공지능을 이용한 연산(이하 인공지능 연산이라 함)을 수반하는 연구환경(32 1)일 수 있다. 또한 사용자는 추가적으로 라이브러리를 설치하여 연구환경을 업데이트할 수 있다. 한편 자원관리유닛에서 할당받은 자원은 연구를 진행하기 위한 자원이 아닌 환경을 운용하기 위한 기본적인 자원에 해당한다. 이는 후술하는 기본자원할당부로부터 할당받게 되고 연산 등을 수행하기 위해 고성능의 자원을 사용해야 할 때에는 후술하는 연산요청부를 활용한다. 연구환경저장부는 연구환경생성부에 의해 생성된 연구환경을 저장한다. 연구환경저장부에 저 장되는 연구환경은 표준환경관리유닛으로부터 제공된 표준환경을 기반으로 생성된 연구표준환경(321a) 과, 데이터연결모듈(321b) 및 연구모듈(321c)을 포함하여 구성될 수 있다. 데이터연결모듈(321b)은 데이터저장부로부터 데이터를 불러오거나 데이터저장부에 데이터를 저장하는데 활용된다. 이때 연구환경저장부에는 데이터연결모듈(321b)을 통해 불러온 데이터와 연구환경에서 진행 한 연구 산출물이 저장될 수 있다. 연구환경관리부는, 연구환경저장부에 저장된 연구환경을 활성화 또는 비활성화하거나 삭제하는 관 리를 수행한다. 여기에서 비활성화는 연구환경은 유지하되 할당받은 자원을 반납하는 것을 의미하고 삭제는 자원 할당을 해제하고 연구환경 자체를 연구환경저장부에서 삭제하는 것을 의미한다. 한편 활성화는 비활성화된 연 구환경에 다시 자원을 할당하여 사용할 수 있게 하는 것이다. 한편 연구환경관리부에서는 사용자 별로 연구환경에 대한 접근 및 생성/삭제에 대한 권한을 관리할 수 있다. 이는 관리자 자격의 사용자가 수행할 수 있다.연구환경연결부는, 연구환경관리부에서 활성화된 연구환경에 대해 사용자들이 접근할 수 있도록 연결해 준다. 연구환경연결부에 의해, 활성화된 연구환경의 연구모듈(321c)에는 사용자들이 접속할 수 있고 연구모듈(321c)을 사용할 수 있다. 연산요청부는 연구환경연결부를 통해 연구환경에 접근한 사용자들이 연산을 수행하고자 할 때 자 원관리유닛에 공유자원을 통한 연산을 요청한다. 연산요청부를 구비함에 따라, 사용자가 연산을 하고자 할 때 공유자원을 이용한 연산이 가능하다. 연산 요청부는 예를 들면 API형태로 이루어질 수 있고, 실행 코드 내에 선언을 함으로써 코드의 실행 시 연산에 대한 요청이 자원관리유닛으로 송신될 수 있다. 연산 요청이 있으면, 자원관리유닛의 자원관리부에서는 요청받은 연산들을 스케줄링하여 공유자원에 서 수행할 수 있게 한다. 연산 결과는 다시 연산요청부를 통해 연구환경에 전달된다. 연구환경공유부는 특정 연구환경에 대해 특정 사용자의 접근 가능 여부를 설정하고 해당 연구환경 의 연구 진행 내용과 결과물을 접근 가능한 사용자들에게 제공한다. 이와 같이 연구환경공유부을 통해 연구환경의 정보 자체나 연구 진행 내용 및 결과물들을 공유할 수 있다. 공유된 내용은 대시보드 형태로 표출될 수 있고, 사용자가 표출되는 요소를 설정할 수 있다. 한편 공유 대상 내 용은 모든 사용자가 볼 수 있는 퍼블릭(public)으로 설정하거나 본인만 확인할 수 있는 프라이빗(private)으로 설정할 수 있다. 이에 따라 다른 사람들과 연구 내용을 실시간으로 공유할 수 있고, 본인의 연구 진행 상황을 모니터링할 수 있 다. 한편 연구환경관리유닛은 연구환경생성부에 의해 생성된 연구환경과 동일한 연구환경을 새롭 게 생성하여 연구환경저장부에 저장하는 연구환경재활용부을 더 포함할 수 있다. 이에 따라 기존에 사용하고 있는 연구환경에서 분기하여 연구를 진행하고 싶을 때 연구환경재활용부을 통해 연구환경을 복제하여 연구를 진행할 수 있다. 또한 복제된 연구환경에서도 기존 연구환경 에 추가적인 라이브러리를 설치하여 환경을 업데이트할 수 있다. 이하에서는 연구환경관리유닛이 작동되는 형태에 대하여 설명한다. 도 7을 참조하면 연구환경생성부를 통해 표준환경저장부에서 표준환경을 선택하고 기본자원할당부 에서 자원을 할당받아 두 종류의 연구환경을 생성한 상태가 도시되어 있다. 이때 연구환경 A는 표준환경 2를 기반으로 CPU를 사용하는 ARIMA(Autoregressive Integrated Moving Average) 알고리즘 개발 환경을 선택한 상태이고, 연구환경 B는 표준환경 1을 기반으로 GPU를 사용하는 GP(Gaussian Process) 알고리즘 개발 환경을 선택한 상태이다. 연구환경저장부는 이와 같이 생성된 각 연구환경을 저장한다. 한편 연구환경재활용부을 통해 기존 연구환경을 복제할 수 있다. 예를 들어 연구환경 A의 ARIMA 알고리즘에 변수를 추가하여 기존 알고리즘 결과와 비교하고 싶을 때 연구환경재활용부을 사용하여 연구환 경 A를 복제한 연구환경 A’를 생성할 수 있다. 연구환경 A’에서 변수를 추가한 실험을 진행하고 연구환경 A의 결과와 비교할 수 있다. 또한 ARIMA를 연구하는 연구자와 GP를 연구하는 연구자가 다르다고 할 때, 관리자는 연구환경관리부을 통해 각 연구자가 다른 연구자의 연구환경을 접근 및 변경하지 못하도록 권한 설정을 할 수 있다. 또한 사용자는 연 구환경관리부을 통해 자신의 연구환경을 활성화/비활성화/삭제 등을 할 수 있다. 사용자는 연구환경연결부를 통해 활성화된 연구환경의 연구모듈(321c)에 접속할 수 있다. 연구환경 A 의 경우, 연구환경이 활성화된 후 R 스튜디오(R studio)를 통해 연구를 진행할 수 있다. 한편 사용자가 GP 알고리즘 코드에 연산요청부에 연산을 요청하는 명령을 선언한 경우, 코드 실행 시 연산 요청부가 GP 알고리즘에 대한 GPU 연산을 자원관리부에 요청한다. 연산 결과는 다시 연산요청부를 통해 해당 연구환경으로 전달된다.추가로 사용자는 연구환경공유부을 통해 연구 진행 내용을 대시보드로 표출할 수 있다. 대시보드에 표출되 는 요소는 예를 들면 사용한 데이터, 연구 내용, 연구결과(그래프, 이미지 등), 학습 시간, 정확도(accuracy), 손실(Loss), MSE, MPE 등이 있으며, 이는 연구자가 직접 세팅할 수 있다. 예를 들어 상술한 시계열 데이터(예를 들면 국가별 확진자 사망자 수 데이터, 국가별 백신접종율 데이터, 국가 별 변이바이러스 비율 데이터)를 전송받아 연구환경에서 인공지능 연산을 통해 확진자, 중증자, 사망자 예 측 결과의 연구결과를 얻을 수 있고 이를 그래프로 표출할 수 있다. 이에 대한 그래프가 도 8에 도시되어 있다. 이와 같이 연구환경관리유닛을 통해 실시간으로 원격 공동연구가 가능하다. 각 연구환경을 사용하는 사 용자들은 거리에 구애받지 않고 원격 커널상에서 연구 진행이 가능하고 각 연구환경에서는 다수의 연구자 가 연구환경을 공유하면서 실시간 공동연구가 가능하다. 또한 연구환경의 저장 및 재활용이 가능하고, 연구환경에 대한 버전 관리를 할 수 있으며 동일한 환경을 기반으로 연구를 진행할 때 따로 환 경을 구축할 필요가 없다. 도 9는 본 발명의 실시예에 따른 인공지능 공동연구 시스템에 채용된 자원관리유닛을 나타내는 블럭도이다. 자원관리유닛은 공유자원을 관리하고 연구환경관리유닛에 자원을 할당하는 한편 연구환경관리유닛 부터 연산요청이 있을 때 공유자원을 통해 수행하도록 관리하는 구성으로서, 기본자원할당부, 자원 관리부 및 공유자원을 포함한다. 기본자원할당부는 연구환경관리유닛에서 연구환경을 생성할 때 연구환경의 운용을 위한 기본 적인 자원을 할당한다. 이와 같이 기본자원할당부에서는 연구환경의 생성시 공유자원의 가용자원 중 연구환경 운용 을 위한 최소한의 자원을 할당한다. 한편 비활성화된 연구환경을 다시 활성화할 때도 기본자원할당부 를 통해 다시 자원을 할당받는다. 예를 들면 기본자원할당부는 연구환경 A의 생성 시 기본 자원으로 CPU 1코어, RAM 2기가를 할당할 수 있고, 연구환경 A가 비활성화 후 재활성화 될 때에도 다시 CPU 1코어, RAM 2기가를 할당할 수 있다. 한편 자원관리부는 공유자원의 사용을 모니터링 및 관리하고 연구환경관리유닛에서 연산요청이 있는 경우 공유자원을 통해 수행하도록 관리한다. 이와 같이 자원관리부는 공유자원의 사용을 모니터링하면서 연산요청부를 통해 받은 작업들을 스케 줄링하여 사용 가능한 공유자원 중 연산을 수행하는 연산자원에서 효율적인 처리가 가능하도록 한다. 이때 연산자원을 통해 얻은 연산 결과는 다시 자원관리부에서 연산요청부로 전달된다. 예를 들면 자원관리부는 연구환경 A, 연구환경 A’ 에서 동시에 프로세스를 요청한 경우, 요청한 프로세스 를 작업(task) 단위(예 : iterator, epoch)로 나누어 클러스터링 된 연산자원에 분배하기 위해 대기 큐에 넣는 다. 이때, 대기 큐에는 작업들이 라운드로빈 스케줄링으로 들어오며 비어있는 연산자원에 순차적으로 부여된다. 이와 같이 자원관리부에서 요청된 연산을 처리하는 과정의 예가 도 10에 도시되어 있다. 이와 같은 인공지능 공동연구 시스템은, 데이터 확보와 처리 형식을 표준화하여 데이터 확보와 환경 구축 에 들어가는 시간과 비용을 크게 절감할 수 있다. 또한 자원관리유닛을 통해 연산 자원을 확보하여 별도의 인프라 구축이 필요 없는 공동연구 인프라를 제공할 수 있고, 대규모 클러스터를 기반으로 한 공유자원의 구축과 공유자원의 스케줄링을 구현할 수 있다. 이에 따라 사용자들은 대규모 클러스터 서버의 공유자원을 서버리스 형태로 사용할 수 있고 자원 스케줄링을 통해 개별적 으로 연산자원을 확보해야 하는 문제를 해결할 수 있다. 또한 실시간 원격 공동연구가 가능하여 각 연구환경을 사용하는 사용자들은 거리에 구애받지 않고 원격 커 널 상에서 연구 진행이 가능하고, 각 연구환경에서는 다수의 사용자가 동일한 연구환경을 기반으로 실시간 공동연구가 가능하며, 연구환경 및 내용 공유를 통해 실시간으로 다른 연구에 대해 확인하면서 피 드백을 주고받을 수 있다. 상기와 같이 인공지능 공동연구 시스템은 상기 설명된 실시예들의 구성과 방법이 한정되게 적용될 수 있는 것이 아니라, 상기 실시예들은 다양한 변형이 이루어질 수 있도록 각 실시예들의 전부 또는 일부가 선택적으로 조합 되어 구성될 수도 있다.앞서 설명한 본 발명의 상세한 설명에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술분야 의 숙련된 당업자 또는 해당 기술분야에 통상의 지식을 갖는 자라면 후술될 특허청구범위에 기재된 본 발명의 사상 및 기술 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다.\n【요약】본 발명은 인공지능 공동연구 시스템과 관련된다. 본 발명은 실시예로 외부 데이터를 수집하고, 일정 형태로 가 공하여 저장하며, 삭제, 조회, 변경이 가능하도록 관리하는 데이터관리유닛, 연구환경의 기반이 되는 표준환경을 저장하고 상기 표준환경의 생성, 삭제, 조회가 가능하도록 관리하는 표준환경관리유닛, 연구환경의 생성을 위한 자원을 할당받고, 상기 표준환경관리유닛으로부터 선택한 표준환경의 정보를 전송받아 연구환경을 생성하며, 생 성된 상기 연구환경에서 상기 데이터관리유닛으로부터 데이터를 전송받아 연산을 요청하도록 관리하는 연구환경 관리유닛 및 공유자원을 관리하고 상기 연구환경관리유닛에 연구환경의 생성을 위한 자원을 할당하는 한편 상기 연구환경관리유닛으로부터 연산요청이 있을 때 상기 공유자원을 통해 연산을 수행하도록 관리하는 자원관리유닛 을 포함하는 인공지능 공동연구 시스템을 제시한다.\n\n【청구항 1】\n외부 데이터를 수집하고, 일정 형태로 가공하여 저장하며, 삭제, 조회, 변경이 가능하도록 관리하는 데이터관리유닛,연구환경의 기반이 되는 표준환경을 저장하고 상기 표준환경의 생성, 삭제, 조회가 가능하도록 관리하는 표준환경관리유닛,연구환경 생성을 위한 자원을 할당받고, 상기 표준환경관리유닛으로부터 선택한 표준환경의 정보를 전송받아 연구환경을 생성하며, 생성된 상기 연구환경에서 상기 데이터관리유닛으로부터 데이터를 전송받아 인공지능 연산을 요청하도록 관리하는 연구환경관리유닛 및공유자원을 관리하고 상기 연구환경관리유닛에 연구환경의 생성을 위한 자원을 할당하는 한편 상기 연구환경관리유닛으로부터 연산요청이 있을 때 상기 공유자원을 통해 인공지능 연산을 수행하도록 관리하는 자원관리유닛을 포함하는 인공지능 공동연구 시스템.\n【청구항 2】\n제1항에 있어서,상기 데이터관리유닛은,외부 데이터를 전송받아 데이터를 일정 형태로 가공하는 데이터수집부,상기 데이터수집부에서 수집하여 가공한 데이터를 특징에 따른 항목들과 해당 항목들의 구체적인 데이터를 포함하는 그룹데이터로 저장하는 한편 상기 그룹데이터에 접근할 수 있도록 그룹데이터의 항목들로 이루어진 메타데이터를 저장하는 데이터저장부 및상기 데이터저장부에 저장된 메타데이터를 활용하여 저장된 데이터를 탐색, 삭제 및 수정하는 기능을 수행하는데이터관리부를 포함하는 인공지능 공동연구 시스템.\n【청구항 3】\n제2항에 있어서,상기 데이터수집부는 시계열 데이터를 수집하고,다양한 형태의 시계열 데이터를 입력받아 표준화된 형태의 데이터로 만들고 시간 순서에 따라 정렬하는 데이터수집모듈,상기 데이터수집모듈에서 수집하여 정렬한 데이터에서 시간 관련 정보를 표준화된 데이트타임 형태로 변환하는데이터형변환모듈,상기 데이터형변환모듈에서 변환된 시계열 데이터가 시간 순서대로 정렬되었는지와 누락된 날짜는 없는지 검증하는 데이터검증모듈 및상기 데이터검증모듈에서 검증에 이상이 있는 경우 시간 순서대로 정렬하거나 누락된 날짜의 데이터를 보충함으로써 데이터를 보정하는 데이터정제모듈을 포함하는 인공지능 공동연구 시스템.\n【청구항 4】\n제2항에 있어서,공개특허 10-2024-0070890-3-상기 데이터저장부에서 저장되는 그룹데이터는 복수로 이루어지는 인공지능을 이용한 공동연구 시스템.\n【청구항 5】\n제2항에 있어서,상기 데이터관리부는 상기 데이터저장부에 저장된 메타데이터를 통해 상기 그룹데이터를 삭제, 조회 및 수정하는 인공지능 공동연구 시스템.\n【청구항 6】\n제1항에 있어서,상기 표준환경관리유닛은,인공지능 연구에 필요한 기본적인 설정을 포함한 가상환경인 표준환경을 저장하는 표준환경저장부 및상기 표준환경저장부에 표준환경을 생성하거나 삭제하거나 조회하는 기능을 수행하는 표준환경관리부를 포함하는 인공지능 공동연구 시스템.\n【청구항 7】\n제6항에 있어서,상기 표준환경은, 인공지능 연구에 필요한 프로그래밍 언어, 하드웨어 및 라이브러리가 구축된 가상환경인 인공지능 공동연구 시스템.\n【청구항 8】\n제1항에 있어서,상기 연구환경관리유닛은,상기 표준환경관리유닛에 저장된 표준환경 중 사용하고자 하는 표준환경을 선택하고 상기 자원관리유닛으로부터해당 표준환경을 사용할 가용자원을 할당받아 연구를 수행할 수 있는 연구환경을 생성하는 연구환경생성부,상기 연구환경생성부에 의해 생성된 연구환경을 저장하는 연구환경저장부,상기 연구환경저장부에 저장된 연구환경을 활성 또는 비활성화하거나 삭제하는 관리를 수행하는연구환경관리부,상기 연구환경관리부에 의해 활성화된 연구환경에 대해 사용자들이 접근할 수 있도록 연결해 주는 연구환경연결부,상기 연구환경연결부를 통해 상기 연구환경에 접근한 사용자들이 인공지능 연산을 수행하고자 할 때 상기 자원관리유닛에 공유자원을 통한 인공지능 연산을 요청하는 연산요청부 및특정 연구환경에 대해 특정 사용자의 접근 가능 여부를 설정하고 해당 연구환경의 연구 진행 내용과 결과물을접근 가능한 사용자들에게 제공하는 연구환경공유부를 포함하는 인공지능 공동연구 시스템.\n【청구항 9】\n제8항에 있어서,상기 연구환경은,상기 표준환경관리유닛으로부터 제공된 표준환경을 기반으로 생성된 연구표준환경,상기 데이터관리유닛으로부터 데이터를 불러오거나 상기 데이터관리유닛에 데이터를 저장하도록 연결해 주는 데이터연결모듈 및상기 데이터연결모듈을 통해 상기 데이터관리유닛으로부터 불러온 데이터로 상기 연구표준환경을 이용하여 인공공개특허 10-2024-0070890-4-지능 연산을 수행하는 연구모듈을 포함하는 인공지능 공동연구 시스템.\n【청구항 10】\n제8항에 있어서,상기 연구환경관리유닛은,상기 연구환경생성부에 의해 생성된 연구환경과 동일한 연구환경을 새롭게 생성하여 상기 연구환경저장부에 저장하는 연구환경재활용부를 더 포함하는 인공지능 공동연구 시스템.\n【청구항 11】\n제1항에 있어서,상기 자원관리유닛은,상기 연구환경관리유닛에서 연구환경을 생성할 때 상기 연구환경의 운용을 위한 기본적인 자원을 할당하는 기본자원할당부 및공유자원의 사용을 모니터링 및 관리하고 상기 연구환경관리유닛에서 연산요청이 있는 경우 상기 공유자원을 통해 수행하도록 관리하는 자원관리부를 포함하는 인공지능 공동연구 시스템.\n【청구항 12】\n제11항에 있어서,상기 자원관리부는,상기 공유자원 사용을 모니터링하면서 상기 연구환경관리유닛으로부터 받은 연산요청을 스케줄링하여 사용 가능한 공유자원 중 연산을 담당하는 연산자원에서 처리하도록 하고,상기 연산자원을 통해 얻은 연산 결과를 상기 연구환경관리유닛으로 전달하는 인공지능 공동연구 시스템."}
{"context": "", "input": "【기술명】\n로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법 및 시스템\n\n【기술 설명】\n본 발명은 로그 분석을 통해 수집된 데이터를 활용하여 인공지능 기반의 마케팅 서비스를 제공하는 방법 및 장치에 관한 것입니다. 이 기술은 서버와 온라인 마켓에 접속한 사용자 단말에서 발생하는 다양한 로그 정보를 수집하고, 이를 분석하여 고객 분석, 유입경로 분석, 코호트 리포트 및 실적 분석을 제공합니다. 최종적으로, 사용자들이 쉽게 이해할 수 있는 형태로 마케팅 리포트를 생성하여 판매자에게 제공하는 것이 핵심입니다. 이러한 방식은 판매자가 실시간으로 마케팅 성과를 확인하고, 즉각적인 전략 수립을 가능하게 합니다.\n\n【해결 문제】\n현재 전자상거래 시장에서는 수많은 판매자가 존재하며, 이들은 고객의 행동 데이터를 효과적으로 분석하여 마케팅 전략을 개선할 필요가 있습니다. 하지만 기존의 온라인 마케팅 플랫폼은 복잡한 데이터 시각화로 인해 판매자가 중요한 정보를 쉽게 이해하지 못하게 합니다. 본 발명은 이러한 문제를 해결하기 위해 사용자 행동 데이터를 명확하고 직관적인 그래프 및 표 형태로 제공함으로써, 마케팅 전략의 효과성과 효율성을 높이는 데 기여합니다. 즉, 판매자는 실질적인 인사이트를 바탕으로 소비자에게 더 효과적으로 접근할 수 있게 됩니다.\n\n【기술 차별성】\n본 발명의 차별성은 복잡한 데이터 분석 과정을 단순화하고, 인공지능을 통해 보다 정교한 마케팅 서비스를 제공하는 데 있습니다. 기존 기술들은 주로 데이터의 양적 분석에 치중하는 반면, 본 발명은 정량적 데이터뿐만 아니라 정성적 인사이트를 제공하여 판매자가 보다 효과적인 결정을 내릴 수 있도록 돕습니다. 또한, 사용자 인터페이스에 미니맵과 같은 직관적인 시각적 요소를 포함하여, 판매자가 현재 페이지의 경로를 쉽게 파악할 수 있도록 설계된 점에서 혁신성을 갖습니다. 이러한 요소들은 판매자의 마케팅 활동을 보다 스마트하고 효율적으로 전환시킬 수 있는 기반이 됩니다.\n\n【활용 분야】\n본 발명은 전자상거래 및 온라인 마케팅 산업에 광범위하게 활용될 수 있습니다. 특히, 온라인 쇼핑몰, 디지털 광고 플랫폼, 고객 관계 관리(CRM) 시스템 등에서 로그 분석을 통해 수집된 데이터를 기반으로 고객 행동을 예측하고 분석하는 데 기여할 수 있습니다. 이 기술은 기업이 효율적인 타겟 마케팅 전략을 수립하고, 고객 맞춤형 서비스를 제공하여 수익성을 극대화하는 데 필수적인 역할을 할 것입니다. 또한, 데이터 기반 의사결정을 통해 경쟁력을 강화하고, 고객 경험을 향상시킬 수 있는 혁신적인 솔루션을 제공합니다.\n\n【구성 요소 및 기능】\n본 발명의 주요 구성 요소는 다음과 같습니다. 첫째, 로그 수집 모듈은 온라인 쇼핑몰 또는 고객 서버에 접속한 사용자의 로그 정보를 실시간으로 수집하는 기능을 수행합니다. 둘째, 분석 리포트 생성 모듈은 수집된 로그 데이터를 바탕으로 유입 경로, 사용자 행동 패턴, 코호트 분석 등을 포함한 다양한 분석 리포트를 생성하여 시각적으로 표현하는 기능을 제공합니다. 셋째, 사용자 리포트 인터페이스는 고객 단말에 접속한 사용자들의 접속 현황과 행동 데이터를 분석하여 사용자가 이해하기 쉬운 형태로 정보를 제공하는 기능을 갖추고 있습니다. 이러한 구성 요소들은 서로 연계되어 통합된 마케팅 솔루션을 구현합니다.\n\n【구현 방식 예】\n본 발명의 구현 방식은 다음과 같은 단계로 진행됩니다. 첫째, 소정 기간 동안 특정 전자상거래 서비스를 운영하는 온라인 쇼핑몰 또는 고객 서버에 접속한 사용자들의 로그 정보를 수집하는 단계가 포함됩니다. 둘째, 수집된 로그 데이터를 분석하여 사용자의 유입 경로 및 행동 패턴을 시각적으로 표현하는 제 1 분석 리포트 인터페이스를 생성합니다. 셋째, 고객 단말에서 사용자 리포트 인터페이스를 통해 접속 현황을 분석하여 미니맵과 그래프 형태로 제공합니다. 이 과정에서 고급 데이터 분석 기법과 인공지능 알고리즘을 활용하여 더욱 정교한 마케팅 전략 수립을 지원합니다. 이러한 구현 방식은 기술적 효율성을 극대화하고, 사용자 경험을 향상시키기 위한 최적의 솔루션을 제공합니다.", "output": "【발명의 명칭】\n로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법 및 장치\n【기술분야】\n본 발명은 로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법 및 장치에 관한 것으로서, 보다 상세하게는, 서버, 온라인 마켓 등에 접속한 사용자 단말과 관련된 다양한 로그 정보를 수집 및 분석한 후 이를 이용하여 고객 분석, 유입경로 분석, 코호트 리포트, 실적 분석 등을 포함하는 인공지능 기반 의 마케팅 서비스를 제공하는 방법 및 장치에 관한 것이다.\n【배경기술】\n최근 국내 전자상거래(이커머스, 온라인 쇼핑) 서비스는 비약적으로 발전하고 있으며, 전자상거래의 급격한 성 장에 따라 온라인 상에서 제품을 판매하는 판매자의 수 또한 비례하여 증가하고 있다. 위와 같은 판매자들은 상품을 판매하는 과정에서 사용자 즉, 고객에게 흥미를 줄 수 있는 다양한 마케팅을 진행 하게 되는데, 이러한 마케팅은 소비자에게 제품에 대한 흥미를 유발시키고 구매까지 유도하는 기능을 수행하기 때문에, 소비자에게 상품을 유통, 판매 등을 할 때 마케팅은 가장 중요한 활동 중 하나라고 볼 수 있다. 따라서, 판매자들은 효과적이며 효율적인 마케팅 방법을 지속적으로 고민하고 있는 실정이나, 여러가지 관련 데 이터들을 분석하며 마케팅을 진행하지 않는 이상 마케팅에 대한 효과 및 효율성은 개선해나가는 것이 쉽지 않다. 이를 위해, 위와 같은 판매자들은 자신이 운영하는 웹사이트 또는 인터넷 쇼핑몰을 통해 제품을 구매하는 사용 자가 상기 웹사이트 또는 인터넷 쇼핑몰에 접속하는 과정 혹은 접속한 이후에 수행하는 일련의 행동들에 대해다양한 데이터를 수집하고 분석하기를 원한다. 현재 대부분의 온라인 마케팅 플랫폼(EX: 구글 애널리틱스)은 고객이 마케팅에 대한 결과를 한 눈에 알아볼 수 없도록 복잡하게 구성되어 있으며, 그로인해 복잡하게 구성된 도표, 서식 및 그래프를 판매자가 한 눈에 이해하 기가 쉽지 않은 실정이다. 이에 판매자들은 온라인 마케팅 플랫폼에서 보여지는 도표, 서식 및 그래프를 알기 쉽게 해석해주는 업무를 다시금 외부 업체 등에 맡기는 경우까지도 발생하고 있는 실정이다. 따라서, 로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스를 제공 하는 방법이 구체적으 로 요구되고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허공보 제10-2008-0050736호 (공개일: 2009년12월03일)\n【해결하려는 과제】\n본 발명은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 서버가 웹사이트 또는 인터넷 쇼핑몰 등에 접 속한 사용자들의 행동 데이터를 수집하여 매출정보, 세션정보, 사용자들의 페이지 조회수 정보(페이지뷰), 주문 횟수 정보, 잠재매출 정보, 사용자들의 쿠폰 사용량 정보 등이 포함된 마케팅 리포트를 고객이 쉽게 확인할 수 있도록 그래프 및 표가 포함된 어느 하나의 형태로 제공하는 것을 목적으로 한다.\n【과제의 해결 수단】\n상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 발명인 로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법은 (a) 소정 기간 동안 특정 전자상거래 서비스를 운영하는 온라인 쇼핑 몰 또는 고객서버에 접속한 사용자들의 로그 정보를 수집하는 단계, (b) 상기 온라인 쇼핑몰 또는 고객서버로 상기 사용자들이 유입된 경로를 분석한 제 1 분석리포트 인터페이스를 제공하는 단계, (c) 상기 고객 단말로 사 용자들의 접속현황을 분석한 사용자리포트 인터페이스를 제공하는 단계를 포함하되, 상기 제 1 분석리포트 인터 페이스 및 사용자리포트 인터페이스는 현재 페이지의 경로를 확인할 수 있는 미니맵을 포함할 수 있다. 본 발명인 로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법은, 상기 제 1분석 인터페이스는 매체 리포트, 매체 및 소스 리포트, 캠페인 리포트 중 적어도 하나에 대한 분석결과를 포함하는 리포트를 제공하고, 상기 고객 단말이 상기 매체 리포트, 매체 및 소스 리포트, 캠페인 리포트 중 어느 하나에 대한 입력을 송신하면 대응하는 복수의 그래프를 제공할 수 있다. 본 발명인 로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법은, 상기 매체 리 포트 내의 상기 복수의 그래프는 매체 기준의 최초 유입된 세션수 및 비율 그래프, 일간 선택한 시점의 매체 기 준의 최초 유입된 세션수 및 사용자수 그래프, 시간별 매체 기준의 최초 유입된 세션수 및 사용자 수 그래프 및 매체 기준의 최초 유입된 세션수 및 사용자수 표를 포함할 수 있다. 본 발명인 로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법은, 상기 매체 및 소스 리포트 내의 상기 복수의 그래프는 매체 및 소스 기준의 최초 유입된 세션수 및 비율 그래프, 일간 선택한 시점의 매체&소스 기준의 최초 유입된 세션수 및 사용자수 그래프, 시간별 매체&소스 기준의 최초 유입된 세션 수 및 사용자수 그래프 및 매체 및 소스 기준의 최초 유입된 세션수 및 사용자수 표를 포함할 수 있다. 본 발명인 로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법은, 상기 캠페인 리포트 내의 상기 복수의 그래프는 캠페인 기준의 최초 유입된 세션수 및 비율 그래프, 일별 선택한 시점의 캠 페인 기준의 최초 유입된 세션수 및 사용자수 그래프, 시간별 캠페인 기준의 최초 유입된 세션수 및 사용자수 그래프 및 캠페인 기준의 최초 유입된 세션수 및 사용자수 표를 포함할 수 있다. 본 발명인 로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법에 있어서, 상기 사용자리포트 인터페이스는 시간별 사용자수 그래프 및 요일별 사용자수 그래프를 장치 별로 제공 가능한 일정기간 동안 접속한 장치별 사용자수 그래프 및 일별 평균 활성 시간 그래프 및 요일별 평균 활성 시간 그래프를 장치 별로 제공 가능한 장치별 전체 및 평균 활성 시간 그래프를 포함할 수 있다. 본 발명의 일실시예에 따른 로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 장치 는, 전자상거래 서비스의 사용자 행동데이터 분석리포트를 제공하기 위한 프로그램이 저장된 메모리 및 상기 프 로그램을 실행하기 위한 프로세서를 포함하며, 상기 프로세서는 상기 프로그램의 실행에 따라 상기 방법을 수행 하고, 상기 방법은, (a) 소정 기간 동안 특정 전자상거래 서비스를 운영하는 온라인 쇼핑몰 또는 고객서버에 접 속한 사용자들의 로그 정보를 수집하는 단계, (b) 상기 온라인 쇼핑몰 또는 고객서버로 상기 사용자들이 유입된 경로를 분석한 제 1 분석리포트 인터페이스를 제공하는 단계 및 (c) 상기 고객 단말로 사용자들의 접속현황을 분석한 사용자리포트 인터페이스를 제공하는 단계를 포함하되, 상기 제 1 분석리포트 인터페이스 및 사용자리포 트 인터페이스는 현재 페이지의 경로를 확인할 수 있는 미니맵을 포함할 수 있다.\n【발명의 효과】\n본 발명에 따르면 아래와 같은 효과들이 제공될 수 있으나, 이에 제한되지는 않는다. 본 발명의 일실시예에 따르면, 사용자들이 전자상거래 서비스를 이용하여 수행하는 행동데이터를 수집하여 시간 별, 일별에 따른 장치별로 접속한 사용자수와 평균 활성시간을 그래프의 형태로 제공할 수 있는 효과가 있다.\n【발명을실시하기위한구체적인내용】\n아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다.본 명세서에 있어서 '부(部)'란, 하드웨어에 의해 실현되는 유닛(unit), 소프트웨어에 의해 실현되는 유닛, 양 방을 이용하여 실현되는 유닛을 포함한다. 또한, 1 개의 유닛이 2 개 이상의 하드웨어를 이용하여 실현되어도 되고, 2 개 이상의 유닛이 1 개의 하드웨어에 의해 실현되어도 된다. 한편, '~부'는 소프트웨어 또는 하드웨어 에 한정되는 의미는 아니며, '~부'는 어드레싱 할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객체 지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수 들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 '~부'들 안에 서 제공되는 기능은 더 작은 수의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분 리될 수 있다. 뿐만 아니라, 구성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 CPU들을 재생시키도록 구현될 수도 있다. 이하에서 언급되는 \"사용자 단말\"은 네트워크를 통해 서버나 타 단말에 접속할 수 있는 컴퓨터나 휴대용 단말기 로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱 (desktop), 랩톱(laptop), VR HMD(예를 들어, HTC VIVE, Oculus Rift, GearVR, DayDream, PSVR 등)등을 포함할 수 있다. 여기서, VR HMD 는 PC용 (예를 들어, HTC VIVE, Oculus Rift, FOVE, Deepon 등)과 모바일용(예를 들 어, GearVR, DayDream, 폭풍마경, 구글 카드보드 등) 그리고 콘솔용(PSVR)과 독립적으로 구현되는 Stand Alone 모델(예를 들어, Deepon, PICO 등) 등을 모두 포함한다. 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되 는 무선 통신 장치로서, 스마트폰(smart phone), 태블릿 PC, 웨어러블 디바이스뿐만 아니라, 블루투스(BLE, Bluetooth Low Energy), NFC, RFID, 초음파(Ultrasonic), 적외선, 와이파이(WiFi), 라이파이(LiFi) 등의 통신 모듈을 탑재한 각종 디바이스를 포함할 수 있다. 또한, “네트워크”는 단말들 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 근거리 통신망(LAN: Local Area Network), 광역 통신망(WAN: Wide Area Network), 인터넷 (WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레 비전 통신망 등을 포함한다. 무선 데이터 통신망의 일례에는 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와이파이(Wi- Fi), 블루투스 통신, 적외선 통신, 초음파 통신, 가시광 통신(VLC: Visible Light Communication), 라이파이 (LiFi) 등이 포함되나 이에 한정되지는 않는다. 먼저, 도 1을 참조하여 본 발명의 일 실시예에 따른 로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법의 구조를 설명하도록 한다. 본 방법은 사용자 단말, 서버 및 고객 단말로 구성된다. 하나의 서버에 복수개의 사용자 단말 및 고객 단말이 연결될 수 있다. 본 발명은 드릴다운 기법을 사용할 수도 있는데 이는 하나의 상위요소에 관련된 여러 하위요소를 세분화하여 분석하는 기법이다. 본 발명에서는 드릴다운 기법을 사용하여 사용자 단말의 행동데이터를 고객 단말(12 0)이 선택한 정렬 기준에 맞는 여러 가지 그래프를 제공할 수 있다. 사용자 단말은 네트워크가 연결되어 배너광고 또는 키워드 검색광고 등의 방법을 통해 서버에 접속하 여 고객 단말에서 운영하는 전자상거래 사이트에 로그인, 카테고리별 제품의 검색, 쿠폰사용, 구매, 단순 방문 등의 활동을 한다. 서버는 네트워크를 통해 유입되는 사용자 단말의 유입 경로 및 사용자 단말의 서버내에서 행동을 분석하고, 고객 단말이 요청하는 기준에 맞는 사용자의 유입 경로 및 행동에 대한 그래프를 고객 단말로 전송한다. 고객 단말은 서버에 네트워크로 연결되어 사용자 단말이 고객 단말의 전자상거래 사이트의 유입되는 경로와 전자상거래 사이트내에서 수행한 행동을 서버로부터 그래프의 형태로 전송 받는다. 이하 도 2를 참조하여 본 발명의 일실시예에 따른 로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마 케팅 서비스 제공 방법에 대하여 상세히 설명하도록 한다. 서버가 고객단말로 제 1 분석리포트 인터페이스를 제공한다.(S110) 먼저 서버는 사용자 단말이 배너광고 또는 키워드 검색광고 등의 방법을 통해 고객 단말의 전자상거래 사이트에 접속하면 사용자 단말 의 유입 경로 및 전자상거래 사이트 내에서 수행하는 행동데이터를 수집한다. 그리고 고객 단말이 서 버에 접속하면 유입된 경로 분석 후 제 1분석리포트 인터페이스를 고객 단말로 제공한다.제 1분석리포트 인터페이스는 이하 도 4a를 참조하여 설명하도록 한다. 제 1분석리포트 인터페이스는 사용자 행 동데이터를 제공할 수 있는 복수개의 패널이 병렬적으로 나열되어 있는 형태로 구성된다. 화면은 크게 메인 행동데이터 패널, 서브 행동데이터 패널, 정렬기준 패널 및 선택 카테고리 패 널로 구성된다. 메인 행동데이터 패널은 매출정보, 잠재매출 정보, 사용자들의 쿠폰 사용량 정보, 전 환율 정보, 구매전환 정보, 접속전환정보, 순 방문자 정보, 로그인 시도 횟수 정보가 포함된 복수개의 상세 행 동데이터 패널로 구성된다. 서브 행동데이터 패널은 세션정보, 매출정보, 사용자들의 페이지 조회수 정보(페이지뷰), 주문 횟수 정보로 구성된다. 정렬기준 패널은 일간, 주간 및 월간을 기준으로 구성되어 고객 단말이 선택한 기준에 맞는 행동데이터를 정렬 할 수 있다. 마지막으로 선택 카테고리 패널은 세션정보, 매출정보, 사용자들의 페이지 조회수 정보 및 구매전환 정보 중 고객 단말이 선택한 정보에 해 당하는 카테고리의 순위를 제공한다. 위 패널들 중 어느 하나의 패널에 대한 고객 단말의 입력(클릭)이 발생될 경우, 제 2 분석리포트 인터페이 스를 제공한다.(S120) 고객 단말이 제 1 분석리포트 인터페이스 내의 메인 행동데이터 패널의 복 수 개의 상세 행동데이터 패널에서 어느 한가지를 입력하면 제 2 분석리포트 인터페이스를 제공한다. 제 2 분석리포트 인터페이스는 이하 도 4b를 참조하여 설명하도록 한다. 제2 분석리포트 인터페이스는 매체 리 포트, 매체&소스 리포트 및 캠페인 리포트로 구성된다. 매체 리포트는 사용자 단말의 첫 유입 시점 기준의 미디어 소스에 대한 리포트이다. 매체&소스 리포트는 사용자 단말의 첫 유입 시 점 기준의 미디어와 소스 조합에 대한 리포트이다. 마지막으로 캠페인 리포트는 사용자 단말의 첫 유 입 시점 기준의 캠페인 소스에 대한 리포트이다. 여기서, 매체란 사용자를 상기 고객서버의 전자상거래 사이트 로 유입하도록 유인한 시스템이고,매체 및 소스란 사용자가 고객서버의 전자상거래 사이트로 유입하게 직전에 머문 도메인이고, 캠페인이란 배너광고 또는 키워드 검색광고를 의미한다. 위 패널들 중 어느 하나의 패널에 대한 고객 단말의 입력(클릭)이 발생될 경우, 제 3 분석리포트 인터페이 스를 제공한다.(S130) 고객 단말이 제 2 분석리포트 인터페이스 내에서 매체 리포트, 매체 및 소스 리포트 및 캠페인 리포트 중 하나를 입력하면 그래프로 표현되는 제 3 분석리포트 인터페이스를 제공 한다. 이하 도 4c를 참조하면 제 3 분석리포트는 그래프의 형태로 제공되는 것을 알 수 있다. 제 3 분석리포트 는 좌측 일영역에 분석된 수치를 보여주는 그래프가 구성되고, 우측 상단 일영역에 정렬기준 패널이 구성 되며, 좌측하단 일영역에 구매여부, 운영체제 및 장치 중 어느 하나의 조건을 선택할 수 있는 조건 선택 패널로 구성된다. 이 때, 조건 선택 패널은 일 실시예이며, 선택 카테고리 패널이 제공될 수도 있다. 제 3 분석리포트의 그래프 종류는 이하 도5a내지 도9b를 참조하여 설명하도록 한다. 도 5a는 매체 기준의 최초 유입된 세션수 및 비율 그래프이다. 도 5a의 상단 그래프에서 가로축은 날짜, 세로축은 각 매체별로 접속한 세 션수를 의미하며, 하단 그래프에서 가로축은 날짜, 세로축은 접속한 매체의 비율을 의미한다. 도 5b는 선택한 시점의 매체 기준의 최초 유입된 사용자수 그래프이다. 그래프의 가로축은 시간, 세로축은 각 매체별로 접속한 사용자수를 의미한다. 접속하는 매체는 추천검색(referral), 자연검색(organic), 유료검색(cpc) 및 제휴 (affiliate)가 있다. 도 6a는 매체&소스 기준의 최초 유입된 세션수 및 비율 그래프이다. 도 6a의 상단 그래프에서 가로축은 날짜, 세로축은 매체와 소스 기준으로 유입된 세션수를 의미하며, 하단 그래프에서 가로축은 날짜, 세로축은 유입된 매체와 소스의 비율이다. 도 6b는 매체&소스 기준의 최초 유입된 사용자수 그래프이다. 그래프의 가로축은 시간, 세로축은 각 매체&소스별로 접속한 사용자수를 의미한다. 접속하는 매체&소스는 검색엔진(EX: Google, 네 이버) 또는 도 6a의 그래프 범례에 표시되어 있는 기 설정된 종류의 제품 검색을 제공하는 사이트이다. 도 7a는 캠페인 기준의 최초 유입된 세션수 및 비율 그래프이다. 도 7a의 상단 그래프에서 가로축은 날짜, 세로 축은 각 캠페인 별로 유입된 세션수를 의미하며, 하단 그래프에서 가로축은 날짜, 세로축은 유입된 캠페인의 비 율을 의미한다. 도 7b는 캠페인 기준의 최초 유입된 세션수 및 사용자수 표이다. 도 7b의 표는 날짜, 순위, 캠 페인, 페이지위치, 세션수 및 사용자수를 기준으로 정렬이 가능한 표를 나타낸다. 접속하는 캠페인의 종류는 자 연접속(organic), 프로모션(Data share promotion), 직접접속(direct) 및 제휴접속(referral)이 있다. 이하 도 3을 참조하여 본 발명의 일 실시예에 따르는 드릴다운 기법을 통해 마케팅리포트를 제공하는 방법의 버 퍼페이지 및 사용자리포트 인터페이스에 대하여 상세히 설명하도록 한다. 서버가 고객 단말로 버퍼페이지를 제공한다.(S210) 서버는 고객 단말이 접속하면 버퍼페이지를 제공 한다. 이는 본 발명의 일 실시예이며, 버퍼페이지를 제공하지 않고, 사용자리포트 인터페이스를 제공할 수도 있다. 고객 단말이 입력하는 설정 기준에 맞는 사용자리포트 인터페이스를 제공한다.(S220) 고객 단말은 제공받 는 사용자리포트 인터페이스에서 일간, 주간 및 월간 중에 기간을 선택할 수 있고, 선택한 기간에 따른 장치 별 활성시간 그래프를 제공 받을 수 있다. 이와 관련하여 이하 도 8 내지 도 9b를 참조하여 설명하도록 한다. 도 8은 기간별 발생한 사용자수, 활성 세션의 체류 시간의 합을 꺾은선 그래프와 막대그래프의 합성 그래프로 나타낸 것이다. 도 8의 그래프에서 가로축은 날짜, 세로축은 사용자수, 보조축은 시간(초)을 의미한다. 도 8에 서 막대그래프는 사용자수이고, 꺾은선 그래프는 사용자당 평균 활성 시간이다. 도 9a 내지 도 9b는 기간동안 접속한 사용자ID 기준의 접속 장치 구분별 사용자수 및 비율 그래프이다. 도 9a의 상단 그래프에서 가로축은 날짜, 세로축은 사용자 ID 기준의 접속 장치 구분별 접속 사용자수를 의미하며, 하단 그래프에서 가로축은 날짜, 세로축은 날짜, 세로축은 사용자 ID 기준의 접속 장치 구분별 접속 사용자 비율을 의미한다. 도 9b의 좌측 그래프에서 가로축은 시간, 세로축은 사용자 ID 기준의 접속 장치 구분별 접속 사용자 수를 의미하며, 우측 그래프에서 가로축은 시간, 세로축은 날짜, 세로축은 사용자 ID 기준의 접속 장치 구분별 접속 사용자 비율을 의미한다. 도 9a 내지 9b에서 접속 장치의 종류는 PC 및 모바일이고, 중복 접속하는 장치의 수 및 비율도 제공 할 수 있다. 본 발명의 추가 실시예에 따르는 모든 기준(EX: 일별, 시간별, 월별)에 대한 그래프를 하나의 화면에 개별로 제 공할 수도 있다. 본 발명의 추가 실시예에 따르는 고객 단말이 설정한 기준에 맞는 복수개의 그래프를 하나의 화면에 제공할 수 도 있다. 이하 본 발명의 일 실시예에 따르는 도 10a 내지 도 10b를 참조하여 본 발명의 일실시예에 따르는 미니맵에 대 하여 설명하도록 한다. 미니맵은 고객 단말을 통해 데이터를 제공받는 중 빠르고, 쉽게 원하는 단계의 분석리포 트를 제공받기 위해서 사용한다. 이하 도 10a를 참조하면 미니맵은 제 3 분석리포트 인터페이스의 상단 일영역에 위치한다. 미니맵에서 현재까지 탐색한 시나리오 히스토리 및 전체 맵의 확인이 가능하다. 전체 맵의 구성은 이하 도 10b를 참 조하여 설명하도록 한다. 도 10b를 참조하면 전체맵은 메인페이지, 분기페이지, 제 1 분석리포트 페이지, 제 2분석리포트 페이지 및 제 3 분석리포트 페이지로 구성된다. 시나리오 히스토리는 현재까지 탐색한 시나리오를 직렬의 형태로 나열하여 보여주고, 전체맵은 병렬 의 형태로 보여줄 수 있다. 본 발명의 일 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함 하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독 가능 매체는 컴퓨터 저장 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구 조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비 휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 본 발명의 방법 및 시스템은 특정 실시예와 관련하여 설명되었지만, 그것들의 구성 요소 또는 동작의 일부 또는 전부는 범용 하드웨어 아키텍쳐를 갖는 컴퓨터 시스템을 사용하여 구현될 수 있다. 전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다. 산업상 이용가능성 본 발명인 로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법은 다양한 인공지 능 기반 마케팅 서비스 제공 방법에 이용할 수 있다.\n【요약】본 발명인 로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법은, (a) 소정 기간 동안 특정 전자상거래 서비스를 운영하는 온라인 쇼핑몰 또는 고객서버에 접속한 사용자들의 로그 정보를 수집하 는 단계, (b) 상기 온라인 쇼핑몰 또는 고객서버로 상기 사용자들이 유입된 경로를 분석한 제 1 분석리포트 인터 페이스를 제공하는 단계, (c) 상기 고객 단말로 사용자들의 접속현황을 분석한 사용자리포트 인터페이스를 제공 하는 단계를 포함하되, 상기 제 1 분석리포트 인터페이스 및 사용자리포트 인터페이스는 현재 페이지의 경로를 확인할 수 있는 미니맵을 포함할 수 있다.\n\n【청구항 1】\n로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법에 있어서,(a) 소정 기간 동안 특정 전자상거래 서비스를 운영하는 온라인 쇼핑몰 또는 고객서버에 접속한 사용자들의 로그 정보를 수집하는 단계;(b) 상기 온라인 쇼핑몰 또는 고객서버로 상기 사용자들이 유입된 경로를 분석한 제 1 분석리포트 인터페이스를제공하는 단계;(c) 상기 고객 단말로 사용자들의 접속현황을 분석한 사용자리포트 인터페이스를 제공하는 단계; 를 포함하되,상기 제 1 분석리포트 인터페이스 및 사용자리포트 인터페이스는 현재 페이지의 경로를 확인할 수 있는 미니맵을 포함하는 것인,로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법.\n【청구항 2】\n제 1항에 있어서,상기 제 1분석인터페이스는 매체 리포트, 매체 및 소스 리포트, 캠페인 리포트 중 적어도 하나에 대한 분석결과를 포함하는 리포트를 제공하고,상기 고객 단말이 상기 매체 리포트, 매체 및 소스 리포트, 캠페인 리포트 중 어느 하나에 대한 입력을 송신하면 대응하는 복수의 그래프를 제공하는 것인,로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법.\n【청구항 3】\n제 2항에 있어서,상기 매체 리포트 내의 상기 복수의 그래프는 매체 기준의 최초 유입된 세션수 및 비율 그래프, 일간 선택한 시점의 매체 기준의 최초 유입된 세션수 및 사용자수 그래프, 시간별 매체 기준의 최초 유입된 세션수 및 사용자수 그래프 및 매체 기준의 최초 유입된 세션수 및 사용자수 표를 포함하는 것인,로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법.\n【청구항 4】\n제 2항에 있어서,상기 매체 및 소스 리포트 내의 상기 복수의 그래프는 매체 및 소스 기준의 최초 유입된 세션수 및 비율그래프, 일간 선택한 시점의 매체&소스 기준의 최초 유입된 세션수 및 사용자수 그래프, 시간별 매체&소스 기준의 최초 유입된 세션수 및 사용자수 그래프 및 매체 및 소스 기준의 최초 유입된 세션수 및 사용자수 표를 포함하는 것인,로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법.\n【청구항 5】\n제 2항에 있어서,상기 캠페인 리포트 내의 상기 복수의 그래프는 캠페인 기준의 최초 유입된 세션수 및 비율 그래프, 일별 선택한 시점의 캠페인 기준의 최초 유입된 세션수 및 사용자수 그래프, 시간별 캠페인 기준의 최초 유입된 세션수및 사용자수 그래프 및 캠페인 기준의 최초 유입된 세션수 및 사용자수 표를 포함하는 것인,공개특허 10-2025-0036592-3-로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법.\n【청구항 6】\n제 1항에 있어서상기 사용자리포트 인터페이스는시간별 사용자수 그래프 및 요일별 사용자수 그래프를 장치 별로 제공 가능한 일정기간 동안 접속한 장치별 사용자수 그래프 및 일별 평균 활성 시간 그래프 및 요일별 평균 활성 시간 그래프를 장치 별로 제공 가능한 장치별 전체 및 평균 활성 시간 그래프를 포함하는 것인,로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 방법.\n【청구항 7】\n로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 장치에 있어서,전자상거래 서비스의 사용자 행동데이터 분석리포트를 제공하기 위한 프로그램이 저장된 메모리; 및 상기 프로그램을 실행하기 위한 프로세서를 포함하며,상기 프로세서는 상기 프로그램의 실행에 따라 상기 방법을 수행하고, 상기 방법은,(a) 소정 기간 동안 특정 전자상거래 서비스를 운영하는 온라인 쇼핑몰 또는 고객서버에 접속한 사용자들의 로그 정보를 수집하는 단계;(b) 상기 온라인 쇼핑몰 또는 고객서버로 상기 사용자들이 유입된 경로를 분석한 제 1 분석리포트 인터페이스를제공하는 단계; 및(c) 상기 고객 단말로 사용자들의 접속현황을 분석한 사용자리포트 인터페이스를 제공하는 단계;를 포함하되,상기 제 1 분석리포트 인터페이스 및 사용자리포트 인터페이스는 현재 페이지의 경로를 확인할 수 있는 미니맵을 포함하는 것인,로그 분석을 통해 수집된 데이터를 이용한 인공지능 기반 마케팅 서비스 제공 장치."}
{"context": "", "input": "【기술명】\n영상정보 및 센서정보를 기반으로 한 인공지능을 활용한 무인매장 시스템의 구성 방법 및 이\n\n【기술 설명】\n본 발명은 인공지능 기반의 무인매장 시스템을 구성하는 방법에 관한 것으로, 고객의 본인 인증 정보를 활용하여 매장에 출입하는 고객을 실시간으로 식별하고 행동을 추적하는 기술입니다. 시스템은 카메라와 센서를 통해 수집된 영상 및 이미지 데이터를 분석하여 고객의 매장 내 동선을 파악하고, 판매대에서의 행동 정보를 분석합니다. 이러한 정보를 인공지능 알고리즘을 활용하여 정제하고, 고객이 선택한 상품에 대해 자동 결제까지의 전 과정을 원활하게 처리할 수 있도록 설계되었습니다.\n\n【해결 문제】\n현재의 소매 환경에서는 고객의 언택트 경험과 효율적인 매장 운영이 중요한 과제로 대두되고 있습니다. 본 발명은 고객이 매장에 들어서자마자 자동으로 식별되고, 상품을 선택한 후 대기 없이 결제할 수 있는 혁신적인 솔루션을 제공합니다. 이는 고객의 구매 편의성을 극대화하는 동시에, 인건비 및 운영 비용 절감에 기여하여 매장 운영의 효율성을 높이는 데 필수적입니다.\n\n【기술 차별성】\n본 발명의 기술은 기존의 셀프 결제 시스템과는 차별화된 점이 있습니다. 기존 시스템은 고객이 직접 결제를 수행해야 하는 반면, 본 발명은 고객의 행동을 실시간으로 분석하고 인공지능을 통해 자동으로 결제를 처리함으로써 고객의 개입을 최소화합니다. 또한, 매장 운영의 무인화를 통해 시간과 장소에 구애받지 않고 24시간 안전하게 운영될 수 있다는 점에서 혁신성을 갖추고 있으며, 이는 고객 경험을 새롭게 정의하는 중요한 기술적 진전을 나타냅니다.\n\n【활용 분야】\n이 본 발명은 소매업, 특히 무인 매장 운영 분야에 광범위하게 활용될 수 있습니다. 전통적인 소매업체는 고객 경험 향상과 운영 비용 절감을 동시에 추구하고 있으며, 본 발명은 이러한 필요를 충족시킬 수 있는 혁신적인 솔루션을 제공합니다. 또한, 이 시스템은 다양한 산업 분야에서 고객 행동 분석 및 맞춤형 마케팅 전략 수립에도 기여할 수 있어, 유통업체뿐만 아니라 데이터 분석 및 인공지능을 활용한 서비스 제공업체에게도 중요한 활용처가 될 것입니다.\n\n【구성 요소 및 기능】\n본 발명의 주요 구성 요소는 다음과 같습니다. 첫째, **영상처리부**는 매장 내에 설치된 카메라를 통해 고객의 영상정보를 실시간으로 수집하고 처리하여 고객을 식별하는 기능을 수행합니다. 둘째, **센서처리부**는 판매대에 설치된 IoT 센서를 통해 고객의 행동 데이터를 수집하고, 이를 기반으로 고객의 구매 경로를 분석하여 실시간으로 정보를 처리합니다. 셋째, **인공지능 프로세스부**는 영상처리부와 센서처리부에서 수집된 데이터를 통합하여 고객의 행동을 예측하고 최종 결제 정보를 확정하는 알고리즘을 구현하여, 자동 결제 시스템을 운영하는 핵심 기능을 담당합니다.\n\n【구현 방식 예】\n본 발명의 구현 방식은 다단계 접근법을 통해 진행됩니다. 첫째, 고객이 매장에 입장할 때, 본인 인증된 식별정보와 함께 출입부를 통과하여 고객 정보를 수집합니다. 둘째, 고객이 매장 내에서 행동할 때, 영상처리부와 센서처리부가 실시간으로 데이터를 수집하고, 이 데이터를 데이터처리부에서 전처리하여 가공처리부로 전달합니다. 마지막으로, 인공지능 프로세스부는 가공된 데이터를 기반으로 고객의 행동을 분석하고, 구매할 상품을 예측한 후 결제처리부를 통해 자동 결제를 완료하는 방식으로 고객에게 원활한 쇼핑 경험을 제공합니다.", "output": "【발명의 명칭】\n영상정보 및 센서정보를 기반으로 한 인공지능을 활용한 무인매장 시스템의 구성 방법 및 이\n【기술분야】\n매장에서 고객을 인식하고 행동을 추적하여 상품 구매까지의 일련의 과정을 영상 및 센서 정보를 이용하여 인공 지능 기반으로 운영하기 위한 무인매장 시스템의 구성 방법 및 이를 제어하기 위한 방법에 관한 것이다. 구체적 으로, 본 발명은 본인 인증이 완료된 식별정보(QR코드, 안면, 지문, 홍채 등의 생체정보, 신용카드정보 등)와 카메라를 활용한 영상정보를 이용하여 매장의 입구에서 고객을 식별하고, 해당 고객의 매장내 동선을 추적하고, 판매대에서의 고객의 행동 정보를 분석하고, 센서 정보(RFID, 중량센서, 적외선센서 등) 등 취합된 정보들을 인 공지능을 활용하여 정제한 후 최종 결제에 이르기까지의 무인매장 시스템의 구성 방법과 이를 제어하는 방법에 관한 것이다.\n【배경기술】\n최근에는 미래형 매장, 언텍트(untact) 매장 등과 같은 미래형 공간 실험에 나선 매장이 등장하고 있다. 업종에 따라 시도하는 형태도 다르고, 다양한 고객 수요에 맞춰 기능을 더하거나, 경영 효율을 높일 목적으로 영업에 필요한 핵심 기능만을 남기고 서비스를 제공하고 있다. 또한, 서비스를 제공받은 고객이 체험을 거쳐 물건을 자 연스럽게 구매하도록 유도하는 점도 특징이며, 데이터를 활용해 비용을 낮추고 매출을 올리는 것을 기본으로 하 고 있다. 그 예로, 직원이 직접 결제처리를 하는 것에서 고객이 셀프 결제를 하는 셀프 매장, 여기서 더 나아가 직원없이 영상이나 센서 정보를 활용한 무인 매장까지 확대되고 있는 상황이다. 이에 따라, 무인 매장에서 고객을 식별, 행동을 추적, 분석하여 최종 결제까지 처리되기 위해 영상, 이미지, 센 서 등의 정보를 인공지능을 활용한 시스템이 필요한 상황이고, 정확한 식별 및 결제 등을 제어하기 위한 방법 및 기술이 필요하다.\n【해결하려는 과제】\n본 발명은 실시간으로 무인 매장에서 사용자를 식별, 인식, 추적하고 상품의 구매, 결제 등의 전과정을 제어하 기 위한 시스템의 구성 방법과 이를 제어하기 위ㅎ나 방법을 제공하고자 한다.\n【과제의 해결 수단】\n본 발명의 일 실시 예는 고객을 식별하기 위해 본인 인증이 완료된 식별 정보(QR코드, 안면, 지문, 홍채 등의 생체정보, 신용카드정보 등)와 매장내 출입시 객체의 영상 또는 이미지 데이터를 매핑하는 일련의 시스템을 제 공한다. 또한, 본 발명의 일 실시 예는 매핑되어 식별된 고객이 매장내에서의 행동에 대한 영상 또는 이미지 데이터와 판매대에 설치된 센서 정보(RFID, 중량센서, 적외선센서 등)를 결합하여 인공지능 알고리즘을 이용하여 고객과 상품을 매칭하는 일련의 시스템을 제공한다. 또한, 본 발명의 일 실시 예는 고객과 매칭된 구매한 상품을 결제하는 일련의 시스템을 제공한다.\n【발명의 효과】\n본 발명의 실시 예에 따르면, 고객은 본인의 식별정보과 결제정보를 사전에 등록한 상황에서 매장에 출입하여 구매하고자 하는 상품을 들고 나가기만 하면 자동으로 구매가 되므로써 결제를 위한 대기가 불필요하고 새로운 고객 경험을 얻을 수 있다. 또한, 본 발명의 실시 예에 따르면, 식별 정보와 영상 또는 이미지 정보의 매핑, 매장내에서의 행동 분석, 인공 지능을 활용한 고객과 상품 매핑, 자동 결제가 되는 시스템을 제공함으로써, 주문 결제 등을 자동으로 수행하기 때문에 인건비로 인한 매장 운영 비용을 줄일 수 있다. 또한, 본 발명의 실시 예에 따르면, 매장 운영에 있어 시간과 상관없이 매장을 무인으로 운영할 수 있어, 새벽 시간과 같은 기피 시간 대의 인력 확보 어려움을 해소할 수 있는 이점도 있다. 또한, 본 발명의 실시 예에 따르면, 매장내 카메라 등을 이용한 영상 또는 이미지 정보로 인해 24시간, 사람이 없는 경우에도 안전하게 운영되고 있음을 확인할 수 있는 이점이 있다.\n【발명을실시하기위한구체적인내용】\n이하, 본 발명에 따른 실시 예들은 첨부된 도면을 참조하여 상세하게 설명한다. 그러나 본 발명이 실시 예에 제 한되거나 한정되는 것은 아니며, 본 발명이 속한 기술 분야에서 기본 지식을 가진 자에게 효율적으로 설명하기 위한 수단일 뿐이다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등 물 내지 대체물을 포함하는 것으로 이해되어야 한다. 그리고, 각 도면에 제시된 동일한 참조 부호는 동일한 부 재를 나타낸다. 또한, 본 명세서에 사용되는 용어는 본 발명에 대한 실시 예를 표현하기 위해 사용된 용어들로, 사용자, 운용자 의 의도 또는 관례 등에 따라 달라질 수 있다. 따라서, 본 용어들에 대한 정의는 본 명세서 전반에 걸친 내용을 토대로 해석되어야 한다. 이하에서는, 인공지능을 활용한 무인매장 시스템의 구성방법 및 이의 제어 방법을 설명한다. 도 1은 본 발명의 일 실시예에 따른 무인 매장 시스템에 대한 개념도 및 구성요소를 도식화한 것이고, 도2는 인공지능 프로세스부 에 대한 개념도 및 구성요소를 도식화한 것이고, 도3은 무인 매장 시스템의 프로세스를 나타낸 흐름도이다. 본 발명의 도 1를 참고하면, 무인 매장 시스템은 고객 인식, 추적, 행동 분석 등 영상을 촬영 및 전송하기 위한 영상장치, 매장에 출입 및 퇴실을 위한 출입부, 매장내 거리, 중량 등의 정보를 전달하기 위한 IoT장 치, 영상장치와 출입부로 부터 영상을 받아 처리하는 영상처리부, 출입부와 IoT장치 로 부터 센서 정보를 받아 처리하는 센서처리부, 영상처리부와 센서처리부의 데이터를 취 합받아 데이터를 처리하는 데이터처리부, 처리된 데이터를 인공지능 분석을 위해 가공하는 가공처리부 , 영상처리부의 데이터와 센서처리부의 데이터를 저장하는 데이터저장부, 센서처리부로부터 이 벤트 정보를 저장하는 이벤트저장부, 데이터저장부와 이벤트저장부의 저장된 데이터로 인공지능 분석을 하는 인공지능 프로세스부, 인공지능 프로세스부로 부터 최종 결과를 수신받아 처리하는 결제처리 로 구성될 수 있다. 영상장치는 카메라, 라즈베리파이, 보드 등이 활용될 수 있으며, 통신모듈은 유무선 통신 기술을 이용하여, 외부 장치, 센서, 사용자 입력, 제어신호 등을 송수신할 수 있다. 여기서 통신모듈에서 사용하는 기 술은 Internet, WIFI, BLE, RFID, IDA, Zigbee, NPC, 5G, LTE, CDMA, GSM, Wide-LAN, LoRa 등이 있다. 출입부는 본인이 식별된 스마트폰, 테블릿 등 모바일 기기를 이용한 어플리케이션을 이용하여 QR코드, 바 코드, 안면인식 등의 수단을 이용하여 식별되는 자동문, SpeedGate 등이 있다. IoT장치는 매장내 상품의 무게 정보, 매대 위치 정보, 고객의 매대 위치 정보나 정보를 제공하는 Display 또는 전자가격표시기 조작을 위한 정보를 얻기 위해 사용되며, IoT 장치는 온도 센서, 압력 센터, 유량 센 서, 중량 센서, 자기 센서, 광 센서, 음향 센서, 미각 센터, 후각 센서, 자이로 센서, 가속도 센서, 조도 센서, 거리 센서, RGB 센서, IR 센서, 지문 인식 센서, 초음파 센서, 광 센서, 레이져 센서, 적외선 센서 등이 있다 . 영상처리부은 영상장비로부터 취합되는 영상 및 이미지 정보와 출입부로부터 취합되는 고객 식 별 정보를 이용하여 데이터처리부에서 처리가 가능하도록 영상 및 이미지의 Frame을 나누고 전송 처리한다. 센서처리부은 출입부로부터 전송되는 고객 식별 정보를 바탕으로 IoT장치을 이용하여 출입부 을 개폐하고, IoT장치로 부터 전송되는 정보를 처리하여 고객 식별 정보 등은 데이터저장부에 저장하고, IoT(장치)로부터 발생된 이벤트 정보는 이벤트저장부에 저장한다.데이터처리부은 영상처리부에서 전송된 영상 및 이미지의 Frame을 이용하여 이미지 좌표 생성, 센서 처리부에서 전송된 데이터와의 매칭 등의 데이터에 대한 전처리 작업을 수행한다. 가공처리부은 데이터처리부으로부터 넘어온 전처리된 데이터를 바탕으로 인공지능프로세스부에 서 처리가 가능하도록 데이터모델링 및 라벨링 등 가공처리 작업을 수행하여 데이터저장부에 저장한다. 데이터저장부는 센서처리부로부터 출입부과 IoT장치에서 생성된 고객 식별 정보, IoT 센서 정보 등을 저장하고, 영상처리부에서 처리된 영상 및 이미지 Frame 정보를 저장하고, 가공처리부에서 처리된 정보를 저정한다. 이벤트저장부는 센서처리부로부터 IoT장치에서부터 발생한 데이터를 이벤트를 기반으로 저장한 다. 이 때 저장되는 이벤트는 상품별, 발생 이벤트별, 상품별, 고객별 이벤트 등으로 구분하여 세분화 저장된다. 인공지능프로세스부는 데이터저장부와 이벤트저장부에 저장된 정보를 바탕으로 이벤트를 체크 하고, 고객을 식별하고, 행동을 추측하는 등 인공지능 알고리즘을 바탕으로 최종 결제처리를 위한 고객과 구매 정보를 확정한다. 결제처리은 인공지능프로세스부로부터 전송받은 정보를 바탕으로 결제처리한다. 결제처리은 출입부에서 활용된 본인 식별 정보와 결제 정보를 활용하여 처리된다. 처리되는 기기는 스마트폰, 테블릿 등의 모바일 어플리케이션 등이 있다. 이하에서, 도 2는 본 발명의 일 실시 예에 따른 인공지능 프로세스부를 나타낸다. 도 2를 참조하면, 인공지능 프로세스부는 이벤트를 체크하는 Check Event(1000-1), 사람, 고객을 식별, 인식하는 Detect Persono(1000-2), 행동을 추측하는 Pose Estimate(1000-3), 사람, 고객을 재식별 및 재인식하 는 Person Reid(1000-4), 구매한 상품을 찾는 Find Product(1000-5)으로 구성될 수 있다. Check Event(1000-1)은 이벤트저장부에 저장된 정보에서 영상정보와 센서정보 데이터를 이용하여 변동되는 데이터를 체크한다. Detect Person(1000-2)은 데이터저장부에 저장된 정보에서 사람, 고객을 식별, 인식한다. Pose Estimate(1000-3)은 데이터저장부에서 사람, 고객의 행동을 분석하여 상품을 들거나 다시 놓거나, 사 람, 고객의 손이 어느 매대에 위치하고 있는지 등을 분석한다. Person Reid(1000-4)는 Check Event(1000-1), Detect Person(1000-2), Pose Estimate(1000-3) 정보를 매핑하 여 사람, 고객, 상품 등의 정보의 정확성을 높이기 위해 사람, 고객의 매칭 여부를 재확인한다. Find Product(1000-5)은 Person Reid(1000-4)로 부터 전송된 데이터를 기반으로 이벤트저장부에서 구매한 상품, 반납한 상품을 최종 검색하여 확정한다. 도 3은 본 발명의 무인 매장 시스템을 이용하는 방법을 나타낸 흐름도를 도식화한 것이다. 도 3에 도시된 방법은 도1과 도2에 도시된 본 발명의 실시예에 따른 인공지능을 활용한 무인 매장 시스템에 의 해 수행될 수 잇다. 도 3를 참조하면, 단계 S100에서 고객 입장시 고객의 식별 정보와 이미지 정보를 획득한다. 단계 S200에서는 매장내 고객의 이동 정보를 획득하고, S100 단계에서 얻은 고객의 식별 정보와 매칭하여 동선 을 추적한다. 단계 S300에서는 매장내 매대앞에서의 고객의 행위 정보를 획득한다. 단계 S400에서는 단계 S200와 동일하여 매장내 고객의 이동 정보를 획득하고, S100단계에서 얻은 고객의 식별 정보와 매칭하여 동선을 추적한다. 단계 S500에서는 고객의 퇴장을 인식하여 단계 S200, 단계 S300에서 얻은 정보를 바탕으로 인공지능 프로세스를 이용하여 단계 S100에서의 본인 식별 정보를 이용하여 구매가 자동으로 이루어진다. 부호의 설명100 : 영상장치 200 : 출입부 300 : IoT 장치 400 : 영상처리부 500 : 센서처리부 600 : 데이터처리부 700 : 가공처리부 800 : 데이터저장부 900 : 이벤트저장부 1000 : 인공지능프로세스부 1000-1 : Check Event 1000-2 : Detect Person 1000-3 : Pose Estimate 1000-4 : Person Reid 1000-5 : Find Product 1100 : 결제처리\n【요약】본 발명은 무인 매장 시스템을 구성함에 있어 영상장치, 출입부, IoT 장치 등을 이용한 영상 및 센서 정보를 발 생시키고, 영상처리부, 센서처리부를 통해 발생한 데이터를 처리하고, 영상처리부와 센서처리부에서 발생한 정보 를 전처리하는 데이터처리부, 처리된 데이터를 데이터 모델링, 라벨링 등의 인공지능을 위한 데이터로 가공하는 가공처리부, 생성되는 데이터를 저장하는 데이터저장부, 이벤트저장부, 생성되고 가공된 데이터를 처리하는 인공 지능프로세스부, 그리고 최종 결제를 처리하는 결제처리의 영상정보 및 센서정보를 기반으로 한 인공지능을 활용 한 무인매장 시스템의 구성 방법 및 이의 제어 방법에 관한 것이다.\n\n【청구항 1】\n매장에서 고객의 식별정보(QR코드, 안면, 지문, 홍채 등의 생체정보, 신용카드 정보 등)으로 입장하기 위한 출입부;매장내에 설치되는 하나 이상의 카메라;상기 카메라를 통해 실시간으로 전송되는 영상정보 또는 이미지정보를 처리하는 영상처리부;판매대에 설치되는 하나 이상의 IoT센서(RFID, 중량센서, 적외선 센서 등);상기 IoT센서를 통해 실시간으로 전송되는 데이터정보 처리 및 상기 출입부 제어를 처리하는 센서처리부;상기 영상처리부에서 전송된 영상 및 이미지와 상기 센서처리부에서 전송된 데이터와의 매칭 등 데이터에 대한전처리 작업을 수행하는 데이터처리부;상기 데이터처리부에서 전달된 전처리된 데이터를 바탕으로 데이터모델링 및 라벨링 등 가공처리 작업을 수행하는 가공처리부;상기 영상처리부, 센서처리부, 가공처리부에서 처리된 정보를 저장하는 데이터저장부;상기 센서처리부에서 발생된 이벤트 정보를 저장하는 이벤트저장부;상기 데이터저장부와 이벤트저장부의 데이터를 기반으로 고객 식별, 행동 추측 등의 인공지능 알고리즘을 바탕으로 결제처리를 위한 고객과 구매정보를 확정하는 인공지능 프로세스부;상기 인공지능 프로세스부로부터 전송받은 데이터를 기반으로 결제를 처리하는 결체처리부;상기 인공지능 프로세스부에서 고객과 구매정보를 확정하기 위해 수행되는 절차 및 방법;\n【청구항 2】\n제1항에 있어서, 상기 출입부는,매장에 출입시 본인이 식별된 스마트폰, 테블릿 등 모바일 기기를 이용한 어플리케이션을 이용하여 QR코드, 바코드 등을 생성하고, 이를 인증하거나, 안면, 홍채, 지문 등을 등록하고 이를 이용하여 인증하여 출입을 허용하는 자동문, SpeedGate 등의 방법 및 장치.\n【청구항 3】\n제1항에 있어서, 상기 영상처리부는,상기 카메라로부터 획득한 획득한 영상 및 이미지 정보와 상기 출입부로부터 획득한 고객 이용하여 영상 및 이미지를 Frame으로 나누어 데이터처리부로 전송하는 것을 특징으로 하는 방법.\n【청구항 4】\n제1항에 있어서, 상기 센서처리부는,상기 출입부로부터 획득한 고객 식별 정보를 바탕으로 상기 IoT센서를 이용하여 출입부를 개폐하며 획득한 고객식별 정보는 데이터저장부에 전송하고, 상기 판매대에 설치된 IoT센서를 통해 획득한 정보를 이벤트저장부에 전송하며, 상기 영상처리부와의 매핑을 위해 데이터처리부로 데이터를 전송하는 것을 특징으로 하는 방법.공개특허 10-2022-0035617-3-청구항 5 제1항에 있어서,상기 데이터처리부는,상기 영상처리부에서 전송된 Frame을 이용하여 영상 및 이미지 좌표를 생성하고, 상기 센서처리부에서 전송된데이터와의 매칭하여 데이터에 대한 전처리 작업을 수행하는 것을 특징으로 하는 방법.\n【청구항 6】\n제1항에 있어서, 상기 가공처리부는,상기 데이터처리부에서 전달된 전처리된 데이터를 바탕으로 상기 인공지능 프로세스부에서 처리가 가능하도록데이터모델링 및 라벨링 등의 가공처리 작업하여 데이터저장부에 저장하는 것을 특징으로 하는 방법.\n【청구항 7】\n제1항에 있어서, 상기 데이터저장부는,상기 센서처리부, 영상처리부, 가공처리부에서 처리된 정보를 저장하는 것을 특징으로 하는 방법 및 장치.\n【청구항 8】\n제1항에 있어서,상기 이벤트저장부는,상기 센서처리부로부터 데이터를 저장하는 것을 특징으로 하는 방법 및 장치.\n【청구항 9】\n제1항에 있어서,상기 인공지능 프로세스부는,상기 데이터저장부와 상기 이벤트저장부의 데이터를 기반으로 이벤트, 고객 식별, 행동을 추측하여 결제가 이루어지는 고객과 구매 정보를 확정하는 것을 특징으로 하는 방법.\n【청구항 10】\n제1항에 있어서,상기 결제처리는,상기 인공지능 프로세스부로부터 전달된 정보를 기반으로 출입시 정의된 방법을 이용하여 결제를 처리하는 것을특징으로 하는 방법.\n【청구항 11】\n제1항에 있어서,상기 인공지능 프로세스부에서 고객과 구매정보를 확정하기 위해 수행되는 절차 및 방법은,이벤트 체크, 사람을 식별하고 인식, 행동 추측, 사람 재식별, 사람 재인식, 구매 상품 검색 등의 일련의 방법과 장치를 특징으로 하는 절차 및 방법;"}
{"context": "", "input": "【기술명】\n인공지능 학습 모델을 이용한 가상 얼굴 편집 방법 및 시스템\n\n【기술 설명】\n본 발명은 인공지능 학습 모델을 활용한 가상 얼굴 편집 방법 및 장치에 관한 것입니다. 이 기술은 실제 인간 얼굴을 인식하고, 이를 기반으로 가상 환경에서의 얼굴 모델을 생성 및 편집하는 과정을 포함합니다. 사용자는 얼굴 핀치 조작을 통해 간편하게 조정 가능한 키포인트를 선택하고, 이를 통해 실제 얼굴의 특성을 반영한 가상 얼굴 모델을 직관적으로 수정할 수 있습니다. 결과적으로, 이 기술은 사용자에게 보다 매끄럽고 자연스러운 가상 얼굴 편집 경험을 제공합니다.\n\n【해결 문제】\n현재의 가상 이미지 소셜 애플리케이션은 얼굴 조정 과정이 복잡하고 번거로워 사용자 만족도를 저하시킬 수 있습니다. 기존의 방법은 수동으로 얼굴의 키포인트를 클릭하고 조정하는 방식으로, 시간이 소모되고 직관적이지 않은 점이 문제로 지적되었습니다. 본 발명은 인공지능 학습 모델을 통해 이러한 불편함을 해소하고, 사용자가 보다 빠르고 손쉽게 얼굴 편집을 수행할 수 있도록 지원함으로써, 가상 얼굴 편집의 필요성과 효율성을 크게 향상시킵니다.\n\n【기술 차별성】\n본 발명의 차별점은 인공지능 학습 모델을 통한 자동화된 얼굴 인식 및 조정 과정에 있습니다. 기존 기술은 사용자가 직접 조작해야 하는 번거로운 절차를 요구하는 반면, 본 기술은 얼굴 핀치 조작을 인식하여 자동으로 필요한 조정 키포인트를 결정합니다. 이 혁신적인 접근방식은 사용자 경험을 극대화하며, 기존의 비효율적인 편집 방법을 대체할 수 있는 잠재력을 가지고 있습니다. 따라서 본 발명은 가상 얼굴 편집 분야에서의 기술적 진보를 이끌어낼 것으로 기대됩니다.\n\n【활용 분야】\n본 발명은 인공지능 학습 모델을 활용한 가상 얼굴 편집 기술로, 주로 디지털 콘텐츠 제작, 게임 개발, 가상 현실(VR) 및 증강 현실(AR) 산업에 적용될 수 있습니다. 특히, 소셜 미디어 플랫폼 및 온라인 커뮤니케이션 도구에서 사용자들이 자신의 얼굴을 실시간으로 편집하고 변형할 수 있는 기능을 제공함으로써, 개인화된 경험을 선사할 수 있습니다. 또한, 영화 및 광고 산업에서도 배우의 얼굴을 가상으로 변형하거나 재구성하여 새로운 비주얼 콘텐츠를 창출하는 데 기여할 수 있습니다.\n\n【구성 요소 및 기능】\n본 발명의 주요 구성 요소는 다음과 같습니다:  \n1. **얼굴 인식 모듈**: 현실 장면에서 실제 인간 얼굴을 인식하는 기능을 담당하며, 고도화된 이미지 처리 알고리즘을 통해 얼굴의 특징점을 정확히 식별합니다. 이를 통해 가상 환경에서의 얼굴 모델링을 위한 기초 데이터를 제공합니다.  \n2. **핀치 조작 인식 모듈**: 사용자가 얼굴에 작용하는 핀치 조작을 감지하는 기능을 수행합니다. 이 모듈은 사용자의 손 동작을 실시간으로 분석하여, 조정할 키포인트와 그 조정 방식을 결정함으로써 직관적인 사용자 인터페이스를 제공합니다.  \n3. **가상 얼굴 모델 조정 모듈**: 인식된 얼굴 모델과 결정된 조정 방식을 바탕으로 제1 가상 얼굴 모델을 제2 가상 얼굴 모델로 변형하는 기능을 수행합니다. 이 모듈은 인공지능 알고리즘을 통해 자연스러운 변형을 구현하여 사용자에게 매끄러운 편집 경험을 제공합니다.\n\n【구현 방식 예】\n본 발명의 구현 방식은 다음과 같은 단계로 구성됩니다: 첫째, 현실 장면에서 카메라를 통해 실제 인간 얼굴을 인식하고, 이를 기반으로 제1 가상 얼굴 모델을 생성합니다. 둘째, 사용자가 얼굴에 대해 핀치 조작을 수행하면, 핀치 조작 인식 모듈이 이를 감지하고 조정할 키포인트 및 그 조정 방식을 결정합니다. 마지막으로, 가상 얼굴 모델 조정 모듈이 이 정보를 활용하여 제1 가상 얼굴 모델을 제2 가상 얼굴 모델로 조정하며, 이 과정은 실시간으로 이루어져 사용자에게 즉각적인 피드백을 제공합니다. 이러한 단계들은 고급 인공지능 기술을 바탕으로 하여, 사용자가 원하는 스타일과 효과를 쉽게 구현할 수 있도록 돕습니다.", "output": "【발명의 명칭】\n인공지능 학습 모델을 이용한 가상 얼굴 편집 방법 및 장치\n【기술분야】\n본 발명은 인공지능 학습 모델을 이용한 가상 얼굴 편집 장치 및 방법에 관한 것이다.\n【배경기술】\n이하에 기술되는 내용은 단순히 본 발명에 따른 일 실시예와 관련되는 배경 정보만을 제공할 뿐 종래기술을 구 성하는 것은 아니다. 인터넷 프로세스의 가속 발전에 따라 이동 단말기의 성능이 빠르게 향상되어 점점 더 많은 애플리케이션의 생성 및 개발을 위한 강력한 기술 지원을 제공한다. 여기서 가상 이미지 소셜 애플리케이션은 인기 있는 커뮤니케이 션 및 엔터테인먼트 방식이 되고 있다. 현재 가상 이미지 소셜 애플리케이션은, 가상 인물 이미지 오관 및 얼굴형을 커스터마이즈 편집할 때, 종종 단 말기 인터페이스에서의 얼굴의 키포인트를 클릭하고, 상하좌우 방향으로 당기는 것을 통해 오관 및 얼굴형의 수 정 및 조정을 완료하는데, 전반 조작 단계가 복잡하고 번거로우므로 사용자의 사용 만족도에 영향을 미친다.\n【해결하려는 과제】\n본 발명은 인공지능 학습 모델을 이용한 가상 얼굴 편집 방법을 제공하는 것을 목적으로 한다.\n【과제의 해결 수단】\n상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 인공지능 학습 모델을 이용한 가상 얼굴 편집 방법은 현실 장면에서의 실제 인간 얼굴을 인식하여, 가상 장면에서의 상기 실제 인간 얼굴의 제1 가상 얼굴 모델을 획 득하는 단계, 상기 실제 인간 얼굴에 작용하는 얼굴 핀치 조작에 응답하여, 상기 얼굴 핀치 조작을 인식하여, 상기 제1 가상 얼굴 모델 중의 조정할 키포인트 및 상기 조정할 키포인트의 조정 방식을 결정하는 단계 및 상기 조정할 키포인트의 조정 방식에 기반하여 상기 제1 가상 얼굴 모델을 제2 가상 얼굴모델로 조정하는 단계를 포함할 수 있다.\n【발명의 효과】\n본 발명에 따르면, 인공지능 학습 모델을 이용한 가상 얼굴 편집 방법을 제공할 수 있다.\n【발명을실시하기위한구체적인내용】\n본 발명을 첨부된 도면을 참조하여 상세히 설명하면 다음과 같다. 여기서, 반복되는 설명, 본 발명의 요지를 불 필요하게 흐릴 수 있는 공지 기능, 및 구성에 대한 상세한 설명은 생략한다. 본 발명의 실시형태는 당 업계에서 평균적인 지식을 가진 자에게 본 발명을 보다 완전하게 설명하기 위해서 제공되는 것이다. 따라서, 도면에서의 요소들의 형상 및 크기 등은 보다 명확한 설명을 위해 과장될 수 있다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성 요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 이하, 본 발명에 따른 바람직한 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 도 1은 본 발명의 일 실시예에 따른 인공지능 학습 모델을 이용한 가상 얼굴 편집 방법을 나타낸 동작 흐름도이 다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 인공지능 학습 모델을 이용한 가상 얼굴 편집 방법은 먼저, 현실 장면에서의 실제 인간 얼굴을 인식하여, 가상 장면에서의 상기 실제 인간 얼굴의 제1 가상 얼굴 모델을 획득할 수 있다(S110). 다음으로, 상기 실제 인간 얼굴에 작용하는 얼굴 핀치 조작에 응답하여, 상기 얼굴 핀치 조작을 인식하여, 상기 제1 가상 얼굴 모델 중의 조정할 키포인트 및 상기 조정할 키포인트의 조정 방식을 결정할 수 있다(S120). 다음으로, 상기 조정할 키포인트의 조정 방식에 기반하여 상기 제1 가상 얼굴 모델을 제2 가상 얼굴모델로 조정 할 수 있다(S130). 일 실시예에 따르면, 상기 얼굴 핀치 조작을 인식하여, 상기 제1 가상 얼굴 모델 중의 상기 조정할 키포인트를 결정하는 단계는 상기 얼굴 핀치 조작을 인식하여, 상기 얼굴 핀치 조작의 작용 대상을 결정하되, 상기 작용 대 상은 상기 실제 인간 얼굴의 오관, 및 상기 실제 인간 얼굴의 얼굴형 중의 적어도 하나를 포함하는 단계 및 상 기 작용 대상에 기반하여 상기 제1 가상 얼굴 모델에 포함된 복수개의 키포인트로부터 상기 조정할 키포인트를 선택하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 얼굴 핀치 조작을 인식하여, 상기 조정할 키포인트의 조정 방식을 결정하는 단계는 상기 얼굴 핀치 조작을 인식하여, 상기 얼굴 핀치 조작으로 인한 작용 대상의 변형을 결정하는 단계 및 상기 작 용 대상의 변형에 기반하여 상기 조정할 키포인트의 조정 방식을 결정하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 작용 대상의 변형에 기반하여 상기 조정할 키포인트의 조정 방식을 결정하는 단계는 상기 작용 대상의 변형 방향에 기반하여 상기 조정할 키포인트의 이동 방향을 결정하되, 상기 변형 방향과 상기 이동 방향은 거울 대칭인 단계 및 상기 작용 대상의 변형 정도에 기반하여 상기 조정할 키포인트의 이동 거리를 결정하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 조정할 키포인트의 조정 방식에 기반하여 상기 제1 가상 얼굴 모델을 제2 가상 얼굴 모델로 조정하는 단계는 상기 제1 가상 얼굴 모델에서의 상기 조정할 키포인트의 초기 위치를 획득하는 단계, 상기 초기 위치, 이동 방향 및 이동 거리를 이용하여 상기 조정할 키포인트의 타깃 위치를 결정하는 단계 및 상 기 타깃 위치에 기반하여 상기 제1 가상 얼굴 모델을 제2 가상 얼굴 모델로 조정하는 단계를 포함할 수 있다. 일 실시예에 따르면, 기 설정 표시 방식에 따라 상기 제1 가상 얼굴 모델에 상기 조정할 키포인트를 표시하는 단계를 더 포함하고, 상기 기 설정 표시 방식은 표시 크기, 표시 색상, 표시 밝기, 표시 특수 효과 중 적어도 하나의 파라미터에 의해 결정될 수 있다.일 실시예에 따르면, 인공지능 학습 모델을 이용한 가상 얼굴 편집 장치는 현실 장면에서의 실제 인간 얼굴을 인식하여, 가상 장면에서의 상기 실제 인간 얼굴의 제1 가상 얼굴 모델을 획득하기 위한 제1 인식 모듈, 상기 실제 인간 얼굴에 작용하는 얼굴 핀치 조작에 응답하여, 상기 얼굴 핀치 조작을 인식하여, 상기 제1 가상 얼굴 모델 중의 조정할 키포인트 및 상기 조정할 키포인트의 조정 방식을 결정하기 위한 제2 인식 모듈 및 상기 조정 할 키포인트의 조정 방식에 기반하여 상기 제1 가상 얼굴 모델을 제2 가상 얼굴 모델로 조정하기 위한 조정 모 듈을 포함할 수 있다. 도 1에 도시된 바와 같이, 컴퓨터 단말기는 판독 전용 메모리(ROM)에 저장된 컴퓨터 프로그램 또는 저장 유닛으로부터 랜덤 액세스 메모리(RAM)에 로딩된 컴퓨터 프로그램에 따라 각 적절한 동작 및 처 리를 수행할 수 있는 컴퓨팅 유닛을 포함한다. RAM에서, 컴퓨터 단말기의 조작에 필요한 다양한 프로그램과 데이터를 더 저장할 수 있다. 컴퓨팅 유닛, ROM 및 RAM은 버스를 통해 서로 연 결된다. 입력/출력(I/O) 인터페이스도 버스에 연결된다. 키보드, 마우스 등과 같은 입력 유닛; 다양한 유형의 디스플레이, 스피커 등과 같은 출력 유닛; 자기 디스크, 광 디스크 등과 같은 저장 유닛; 및 네트워크 카드, 모뎀, 무선 통신 트랜시버 등과 같은 통신 유 닛을 포함하는 컴퓨터 단말기의 복수의 부재는 I/O 인터페이스에 연결된다. 통신 유닛은 컴퓨터 단말기가 인터넷과 같은 컴퓨터 네트워크 및/또는 다양한 통신 네트워크를 통해 다른 기기와 정보/ 데이터를 교환하도록 허용한다. 컴퓨팅 유닛은 처리 및 컴퓨팅 기능을 갖는 다양한 범용 및/또는 전용 처리 컴포넌트일 수 있다. 컴퓨팅 유닛의 일부 예시는 중앙 처리 유닛(CPU), 그래픽 처리 유닛(GPU), 다양한 전용 인공지능(AI) 컴퓨팅 칩, 기계 학습 모델 알고리즘을 실행하는 다양한 컴퓨팅 유닛, 디지털 신호 프로세서(DSP), 및 임의의 적절한 프로 세서, 컨트롤러, 마이크로 컨트롤러 등을 포함하지만 이에 제한되는 것은 아니다. 컴퓨팅 유닛은 본문에 설명된 가상 얼굴 모델의 조정 방법을 구현한다. 예를 들어, 일부 실시예에서, 가상 얼굴 모델의 조정 방법은 저장 유닛과 같은 기계 판독 가능 매체에 유형적으로 포함되는 컴퓨터 소프트웨어 프로그램으로 구현될 수 있다. 일부 실시예에서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및/또는 통신 유닛을 통해 컴퓨터 단말기에 로딩 및/또는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되어 컴퓨팅 유닛에 의해 실행될 경우, 본문에 설명된 가상 얼굴 모델의 조정 방법의 하나 이상의 단계를 수행할 수 있다. 대안적으로, 다른 실시예에서, 컴퓨팅 유닛은 다른 임의의 적절한 방식을 통해(예를 들어, 펌웨어에 의해) 가상 얼굴 모델의 조정 방법을 구현하도록 구성될 수 있다. 본문에 설명된 시스템 및 기술의 다양한 실시형태는 디지털 전자 회로 시스템, 집적 회로 시스템, 필드 프로그 래머블 어레이(FPGA), 전용 집적 회로(ASIC), 전용 표준 제품(ASSP), 시스텝 온 칩(SOC), 복합 프로그램 가능 논리 소자(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어, 및/또는 이들의 조합에서 구현될 수 있다. 이러한 다 양한 실시형태는, 하나 이상의 컴퓨터 프로그램에서 구현되는 것을 포함할 수 있고, 상기 하나 이상의 컴퓨터 프로그램은 적어도 하나의 프로그램 가능 프로세서를 포함하는 프로그램 가능 시스템에서 실행 및/또는 해석될 수 있으며, 상기 프로그램 가능 프로세서는 전용 또는 범용 프로그램 가능 프로세서일 수 있고, 저장 시스템, 적어도 하나의 입력 장치, 및 적어도 하나의 출력 장치로부터 데이터와 명령을 수신하며, 데이터와 명령을 상기 저장 시스템, 상기 적어도 하나의 입력 장치, 및 상기 적어도 하나의 출력 장치로 전송할 수 있다. 여기서 설명해야 할 것은, 일부 바람직한 실시예에서, 도 1에 도시된 상기 전자 장치는 하드웨어 소자(회로를 포함함), 소프트웨어 소자(컴퓨터 판독 가능 매체에 저장된 컴퓨터 코드를 포함함), 또는 하드웨어 소자 및 소 프트웨어 소자의 조합을 포함할 수 있다. 도 1은 특정 구체적인 구현예의 하나의 구현예일 뿐이며, 상기 전자 기기에 존재할 수 있는 부재의 유형을 예시하기 위한 것이다. 상술한 실행 환경에서, 본 발명은 도 2에 도시된 가상 얼굴 모델의 조정 방법을 제공하고, 상기 방법은 도 1에 도시된 컴퓨터 단말기 또는 유사한 전자 기기에 의해 구현될 수 있다. 도 2는 본 발명의 실시예에 따라 제공되 는 가상 얼굴 모델의 조정 방법의 흐름도이다. 도 2에 도시된 바와 같이, 상기 방법은 다음과 같은 단계를 포함 한다. 단계 S21에서, 현실 장면에서의 실제 인간 얼굴을 인식하여, 가상 장면에서의 실제 인간 얼굴의 제1 가상 얼굴 모델을 획득한다. 상기 현실 장면은 사용자가 현재 위치한 실제 장면일 수 있다. 상기 가상 장면은 가상 이미지 애플리케이션 중의 장면일 수 있고, 애플리케이션 기본 크드에 의해 사전 설정될 수 있다. 바람직하게는, 사용자의 장면 선택 조작에 응답하여 가상 장면 전환을 수행하고, 예를 들어, 기설정된 가상 장 면은 해변 장면, 설산 장면, 사막 장면 및 도시 장면을 포함할 수 있으며, 사용자는 그래픽 사용자 인터페이스 에서의 장면 전환 컨트롤을 클릭하여 가상 장면 전환을 수행할 수 있고, 예를 들어 현재 가상 장면이 해변 장면 이고, 전환할 장면이 설산 장면이면, 설산 장면에 대응되는 장면 전환 컨트롤을 클릭하여 해변 장면을 설산 장 면으로 전환할 수 있다. 상기 제1 가상 얼굴 모델은 실제 인간 얼굴에 대응되는 얼굴 모델이고, 제1 가상 얼굴 모델은 2차원 모델 또는 3차원 모델일 수 있다. 구체적으로, 현실 장면에서의 실제 인간 얼굴을 인식하여, 가상 장면에서의 실제 인간 얼굴의 제1 가상 얼굴 모 델을 획득하는 구현 프로세스는 기존의 임의의 인간 얼굴 인식 모델링 해결 수단을 참조할 수 있고, 반복하여 설명하지 않는다. 단계 S22에서, 실제 인간 얼굴에 작용하는 얼굴 핀치 조작에 응답하여, 얼굴 핀치 조작을 인식하여, 제1 가상 얼굴 모델 중의 조정할 키포인트 및 조정할 키포인트의 조정 방식을 결정한다. 상기 실제 인간 얼굴에 작용하는 얼굴 핀치 조작은 실제 인간 얼굴의 키포인트에 대응되는 변형이 발생하도록 하여, 실제 인간 얼굴에 대응되는 제1 가상 얼굴 모델 중의 조정할 키포인트가 상응하게 변경될 수 있다. 바람직하게는, 얼굴 핀치 조작을 인식하는 것은 사용자의 얼굴 핀치 제스처를 인식하는 것 및 사용자의 실제 인 간 얼굴을 인식하는 것을 포함한다. 구체적으로, 얼굴 핀치 제스처가 실제 인간 얼굴에 작용하는 위치를 인식하 는 것을 통해 실제 인간 얼굴의 변형의 키포인트 및 이러한 키포인트에 대한 조정 방법을 결정하고, 실제 인간 얼굴을 추가로 인식하여 제1 가상 얼굴 모델 중의 조정할 키포인트 및 조정할 키포인트의 조정 방식을 결정한다. 구체적으로, 실제 인간 얼굴에 작용하는 얼굴 핀치 조작에 응답하여, 얼굴 핀치 조작을 인식하여, 제1 가상 얼 굴 모델 중의 조정할 키포인트 및 조정할 키포인트의 조정 방식을 결정하는 구현 프로세스는 본 발명의 실시예 에 대한 추가 소개를 참조할 수 있다. 단계 S23에서, 조정할 키포인트의 조정 방식에 기반하여 제1 가상 얼굴 모델을 제2 가상 얼굴 모델로 조정한다. 상기 제2 가상 얼굴 모델은 가상 장면 중 조정된 후의 가상 얼굴 모델로서, 사용자의 요구사항에 더 부합된다. 구체적으로, 조정할 키포인트의 조정 방식에 기반하여 제1 가상 얼굴 모델을 제2 가상 얼굴 모델로 조정하는 구 현 프로세스는 본 발명의 실시예에 대한 추가 소개를 참조할 수 있다. 본 발명의 상기 단계 S21 내지 단계 S23에 따르면, 현실 장면에서의 실제 인간 얼굴을 인식하여, 가상 장면에서 의 실제 인간 얼굴의 제1 가상 얼굴 모델을 획득하고; 실제 인간 얼굴에 작용하는 얼굴 핀치 조작에 응답하여, 얼굴 핀치 조작을 인식하여, 제1 가상 얼굴 모델 중의 조정할 키포인트 및 조정할 키포인트의 조정 방식을 결정 하며; 조정할 키포인트의 조정 방식에 기반하여 제1 가상 얼굴 모델을 제2 가상 얼굴 모델로 조정하는 것을 통 해, 가상 이미지를 지능적으로 조정하는 목적을 달성하고, 가상 이미지를 조정하는 조작 단계를 단순화하며, 사 용자 경험 효과를 향상시킴으로써, 종래의 해결 수단에서 가상 이미지를 조정하는 조작 단계가 번거롭고, 사용 만족도가 좋지 않은 기술적 과제를 해결한다. 본 발명에서 설명하는 특정 실행들은 일 실시예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아 니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어 시스템들, 소프트웨어, 상기 시스템들의 다른 기 능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재들 은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가 능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, \"필 수적인\", \"중요하게\" 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요소가 아닐 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한 다고 할 것이다.도면 도면1\n【요약】인공지능 학습 모델을 이용한 가상 얼굴 편집 방법 및 장치가 개시된다. 본 발명의 일 실시예에 따른 인공지능 학습 모델을 이용한 가상 얼굴 편집 방법은 현실 장면에서의 실제 인간 얼굴을 인식하여, 가상 장면에서의 상기 실제 인간 얼굴의 제1 가상 얼굴 모델을 획득하는 단계, 상기 실제 인간 얼굴에 작용하는 얼굴 핀치 조작에 응답 하여, 상기 얼굴 핀치 조작을 인식하여, 상기 제1 가상 얼굴 모델 중의 조정할 키포인트 및 상기 조정할 키포인 트의 조정 방식을 결정하는 단계 및 상기 조정할 키포인트의 조정 방식에 기반하여 상기 제1 가상 얼굴 모델을 제2 가상 얼굴모델로 조정하는 단계를 포함할 수 있다.\n\n【청구항 1】\n현실 장면에서의 실제 인간 얼굴을 인식하여, 가상 장면에서의 상기 실제 인간 얼굴의 제1 가상 얼굴 모델을 획득하는 단계;상기 실제 인간 얼굴에 작용하는 얼굴 핀치 조작에 응답하여, 상기 얼굴 핀치 조작을 인식하여, 상기 제1 가상얼굴 모델 중의 조정할 키포인트 및 상기 조정할 키포인트의 조정 방식을 결정하는 단계; 및상기 조정할 키포인트의 조정 방식에 기반하여 상기 제1 가상 얼굴 모델을 제2 가상 얼굴모델로 조정하는 단계를 포함하는, 인공지능 학습 모델을 이용한 가상 얼굴 편집 방법.\n【청구항 2】\n제1 항에 있어서,상기 얼굴 핀치 조작을 인식하여, 상기 제1 가상 얼굴 모델 중의 상기 조정할 키포인트를 결정하는 단계는,상기 얼굴 핀치 조작을 인식하여, 상기 얼굴 핀치 조작의 작용 대상을 결정하되, 상기 작용 대상은 상기 실제인간 얼굴의 오관, 및 상기 실제 인간 얼굴의 얼굴형 중의 적어도 하나를 포함하는 단계; 및상기 작용 대상에 기반하여 상기 제1 가상 얼굴 모델에 포함된 복수개의 키포인트로부터 상기 조정할 키포인트를 선택하는 단계를 포함하는, 인공지능 학습 모델을 이용한 가상 얼굴 편집 방법.\n【청구항 3】\n제1 항에 있어서,상기 얼굴 핀치 조작을 인식하여, 상기 조정할 키포인트의 조정 방식을 결정하는 단계는,상기 얼굴 핀치 조작을 인식하여, 상기 얼굴 핀치 조작으로 인한 작용 대상의 변형을 결정하는 단계; 및상기 작용 대상의 변형에 기반하여 상기 조정할 키포인트의 조정 방식을 결정하는 단계를 포함하는, 인공지능 학습 모델을 이용한 가상 얼굴 편집 방법.\n【청구항 4】\n제3 항에 있어서,상기 작용 대상의 변형에 기반하여 상기 조정할 키포인트의 조정 방식을 결정하는 단계는,상기 작용 대상의 변형 방향에 기반하여 상기 조정할 키포인트의 이동 방향을 결정하되, 상기 변형 방향과 상기이동 방향은 거울 대칭인 단계; 및상기 작용 대상의 변형 정도에 기반하여 상기 조정할 키포인트의 이동 거리를 결정하는 단계를 포함하는, 인공지능 학습 모델을 이용한 가상 얼굴 편집 방법.\n【청구항 5】\n제1 항에 있어서,상기 조정할 키포인트의 조정 방식에 기반하여 상기 제1 가상 얼굴 모델을 제2 가상 얼굴 모델로 조정하는 단계는,상기 제1 가상 얼굴 모델에서의 상기 조정할 키포인트의 초기 위치를 획득하는 단계;공개특허 10-2024-0159211-3-상기 초기 위치, 이동 방향 및 이동 거리를 이용하여 상기 조정할 키포인트의 타깃 위치를 결정하는 단계; 및상기 타깃 위치에 기반하여 상기 제1 가상 얼굴 모델을 제2 가상 얼굴 모델로 조정하는 단계를 포함하는, 인공지능 학습 모델을 이용한 가상 얼굴 편집 방법.\n【청구항 6】\n제1 항에 있어서,기 설정 표시 방식에 따라 상기 제1 가상 얼굴 모델에 상기 조정할 키포인트를 표시하는 단계를 더 포함하고,상기 기 설정 표시 방식은 표시 크기, 표시 색상, 표시 밝기, 표시 특수 효과 중 적어도 하나의 파라미터에 의해 결정되는, 인공지능 학습 모델을 이용한 가상 얼굴 편집 방법.\n【청구항 7】\n현실 장면에서의 실제 인간 얼굴을 인식하여, 가상 장면에서의 상기 실제 인간 얼굴의 제1 가상 얼굴 모델을 획득하기 위한 제1 인식 모듈;상기 실제 인간 얼굴에 작용하는 얼굴 핀치 조작에 응답하여, 상기 얼굴 핀치 조작을 인식하여, 상기 제1 가상얼굴 모델 중의 조정할 키포인트 및 상기 조정할 키포인트의 조정 방식을 결정하기 위한 제2 인식 모듈; 및상기 조정할 키포인트의 조정 방식에 기반하여 상기 제1 가상 얼굴 모델을 제2 가상 얼굴 모델로 조정하기 위한조정 모듈을 포함하는, 인공지능 학습 모델을 이용한 가상 얼굴 편집 장치."}
