{"patent_id": "10-2021-0178639", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0089889", "출원번호": "10-2021-0178639", "발명의 명칭": "내시경 증강현실 정밀도 향상 및 심부 병변 오차 감소를 위한 의료 영상 정합 장치 및 그 방", "출원인": "가톨릭관동대학교산학협력단", "발명자": "최안렬"}}
{"patent_id": "10-2021-0178639", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "내시경 증강현실 정밀도 향상 및 심부 병변 오차 감소를 위하여 환자 공간의 영상 데이터와 의료 영상 데이터를정밀 정합하는 의료 영상 정합 장치에 있어서, 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 수신하는 입력부;상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 기반으로 정밀 정합을 위한 회전 및 병진 변환 행렬값을 추정하는 인공 지능 모델이 저장된 인공 지능 모델 저장부; 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 정밀 정합하는 정합부; 및 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터의 정합 결과물을 출력하는 출력부;를 포함하며상기 정합부는 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 개략적으로 정합하여 제1정합 좌표점을 생성하는 제1정합부;상기 제1정합 좌표점과 상기 의료 영상 데이터의 표면 좌표점을 정합하여 제2 정합 좌표점을 생성하는 제2정합부; 및상기 제2정합 좌표점을 상기 인공 지능 모델의 입력으로 하여 추정된 상기 회전 및 병진 변환 행렬값을 기반으로 정밀 정합하는 제3정합부를 포함하는 것인 의료 영상 정합 장치."}
{"patent_id": "10-2021-0178639", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인공 지능 모델의 입력 정보 특징점은 상기 환자 공간의 얼굴 표면 좌표점과 상기 환자 공간의 얼굴 표면좌표점에 대응되는 상기 의료 영상 데이터의 표면 좌표점을 포함하며, 6개의 차원(dimension)으로 설정되는 것인 의료 영상 정합 장치."}
{"patent_id": "10-2021-0178639", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 인공 지능 모델은 팬텀의 병변 위치 좌표점를 기반으로한 데이터 세트를 더 확보하여 인공 지능 모델의 입력 특징점을 설정하고,상기 병변 위치 좌표점을 기반으로한 인공 지능 모델의 입력 특징점은 가상의 병변 구조물에 임의로 지정한 병변 후보군의 위치 좌표점과 상기 병변 구조물을 촬영한 영상 데이터에서 상기 병변 후보군의 위치 정보와 대응되는 위치 좌표점을 포함하며, 6개의 차원(dimension)으로 설정되는 것인 의료 영상 정합 장치."}
{"patent_id": "10-2021-0178639", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 인공 지능 모델은 Bi-LSTM(Bidirectional LSTM) 아키텍처를 포함하며,회귀 레이어 (Regression layer)를 이용하여 회전 및 병진 변환 행렬을 3X3 차원인 회전 변환 행렬과 3X1차원인병진 변환 행렬으로 출력하는 것인 의료 영상 정합 장치.공개특허 10-2023-0089889-3-청구항 5 제1항에 있어서,상기 제2정합부, 상기 인공 지능 모델 및 상기 제3정합부는 ICP(iterative closest point) 알고리즘을 이용하여정합하는 것인 의료 영상 정합 장치."}
{"patent_id": "10-2021-0178639", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "내시경 증강현실 정밀도 향상 및 심부 병변 오차 감소를 위하여 환자 공간의 영상 데이터와 의료 영상 데이터를정밀 정합 하는 의료 영상 정합 방법에 있어서, a) 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 획득하는 단계;b) 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터로부터 개략적으로 좌표점을 추출하여 정합하고, 개략적인 회전 및 병진 변환 행렬을 추출하는 단계c) 상기 개략적으로 정합된 좌표점과 상기 환자 공간의 영상 데이터로부터 추출된 얼굴 표면 좌표점을 추출된상기 개략적인 회전 및 병진 변환 행렬을 이용하여 제1정합하고 제1정합 좌표점을 생성하는 단계;d) 상기 제1정합 데이터를 증강시키고, 증강된 제 1정합 좌표점을 상기 의료 영상 데이터로부터 추출된 표면 좌표점과 정합하여 제2정합 좌표점을 생성하는 단계;및e) 상기 제2정합 좌표점을 상기 인공 지능 모델의 입력으로 하여 추정된 상기 회전 및 병진 변환 행렬값을 기반으로 정밀 정합하는 단계;를 포함하는 것인 의료 영상 정합 방법."}
{"patent_id": "10-2021-0178639", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 인공 지능 모델의 입력 정보 특징점은 상기 환자 공간의 얼굴 표면 좌표점과 상기 환자 공간의 얼굴 표면좌표점에 대응되는 상기 의료 영상 데이터의 표면 좌표점을 포함하며, 6개의 차원(dimension)으로 설정되는 것인 의료 영상 정합 방법."}
{"patent_id": "10-2021-0178639", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제2항에 있어서, 상기 인공 지능 모델은 팬텀의 병변 위치 좌표점를 기반으로한 데이터 세트를 더 확보하여 인공 지능 모델의 입력 특징점을 설정하고,상기 병변 위치 좌표점을 기반으로한 인공 지능 모델의 입력 특징점은 가상의 병변 구조물에 임의로 지정한 병변 후보군의 위치 좌표점과 상기 병변 구조물을 촬영한 영상 데이터에서 상기 병변 후보군의 위치 정보와 대응되는 위치 좌표점을 포함하며, 6개의 차원(dimension)으로 설정되는 것인 의료 영상 정합 방법."}
{"patent_id": "10-2021-0178639", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 인공 지능 모델은 Bi-LSTM(Bidirectional LSTM) 아키텍처를 포함하며,회귀 레이어 (Regression layer)를 이용하여 회전 및 병진 변환 행렬을 3X3 차원인 회전 변환 행렬과 3X1차원인병진 변환 행렬으로 출력하는 것인 의료 영상 정합 방법.공개특허 10-2023-0089889-4-청구항 10 제6항에 있어서,상기 d) 단계 및 상기e) 단계는 ICP(iterative closest point) 알고리즘을 이용하여 정합하는 것인 의료 영상정합 방법."}
{"patent_id": "10-2021-0178639", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제6항에 있어서,상기 d) 단계는 1회의 증강 시마다 상기 제1정합 좌표점을 5% 증강시키며, 상기 증강을 복수회 실시하는 것인 의료 영상 정합 방법."}
{"patent_id": "10-2021-0178639", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 d) 단계는 상기 1회의 증강이 끝날 때마다 표면 정합 오차를 분석하는 단계를 포함하며, 상기 표면 정합 오차 분석값이 기 설정된 종료 조건을 만족할 때 증강을 중단하는 것인 의료 영상 정합 방법."}
{"patent_id": "10-2021-0178639", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시예에 따른 영상 의료 영상 정합 장치는, 내시경 증강현실 정밀도 향상 및 심부 병변 오차 감소를 위하여 환자 공간의 영상 데이터와 의료 영상 데이터를 수신하는 입력부; 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 기반으로 정밀 정합을 위한 회전 및 병진 변환 행렬 값을 추정하는 인공 지능 모델이 저장된 (뒷면에 계속)"}
{"patent_id": "10-2021-0178639", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 의료 영상 정합 장치에 관한 것으로, 상세하게는 내시경의 증강 현실의 정밀도를 향상시키고 심부 병 변 오차를 최소화하여 의료 영상 데이터의 데이터와 환자 공간의 데이터를 정밀 정합을 할 수 있는 의료 영상 정합 장치 및 그 방법에 관한 것이다. 더욱 상세하게는, 본 발명은 인공 신경망을 이용하여 환자 공간의 데이터 및 팬텀의 병변 위치 정보를 기반으로 회전 및 병진 변환 행렬값을 추정하고여, 의료 영상 데이터의 데이터와 환자 공간의 데이터를 정밀 정합을 할 수 있는 의료 영상 정합 장치 및 그 방법에 관한 것이다."}
{"patent_id": "10-2021-0178639", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상 유도 수술 시스템은 수술 도구의 3차원 위치를 수술 전 촬영한 환자의 의료 영상에 가시화하여 병변 및 주 변의 위치를 실시간으로 제공하는 의료 시스템이다. 영상 유도 수술 시스템은 수술 전 환자의 의료 영상을 획득하고, 수술 중 공간 정합을 수행한 후, 수술 도구의 좌표 변환을 통한 가상의 수술 도구를 의료 영상 내에 겹쳐서 표시한다. 여기서, 공간 정합은 수술 전 촬영한 의료 영상의 좌표와 수술 중 획득한 환자 공간 좌표를 동일한 공간으로 정렬시키는 과정을 의미한다. 두 좌표의 정합이 정확하게 수행되지 않으면 실제 수술도구의 위치와 가상의 수술도구의 위치간 이격이 발생할 수 있다. 따라서 준비된 의료 영상과 환자 공간의 영상을 정확하게 정합하는 기술이 필요하다. 한편, 이와 같은 공간 정합은 점 정합과 표면 정합으로 구분된다. 먼저, 점 정합은 의료 영상 및 환자 공간에서 하나의 직선 위에 존재하지 않는 최소 3개의 표식자 마커 좌표를 획득한다. 또한, 각 의료 영상 및 환자 공간의 지역 좌표계를 기초로하여 두 공간의 정렬이 일치될 수 있도록 좌표계간 회전과 선형 변환을 수행한다. 따라서, 점 정합을 수행하기 위해서는 미리 환자 얼굴에 표식자 마커를 부착해야 하며, 추가적으로 CT(computed tomography) 촬영을 해야하는 번거로움이 발생한다. 또한, 환자 얼굴에 부착된 표식자 마커에 의해 신체의 국부 가 부어오르는 종착이 발생할 가능성이 높으며, 이로 인해 표식자 마커가 움직일 경우 정확도가 저하된다는 한 계가 존재한다. 한편, 도1은 종래의 표면 정합을 설명하기 위한 도면이다. 도 1에 도시된 바와 같이 환자(P)의 표면에 대한 정보는 프로브를 통해 획득될 수 있다. 일 예로, 집도의는 프로브가 환자(P)의 신체에 인접한 상태에서 프로브를 천천히 이동시키게 되며, 수 술용 내비게이션 장치는 환자(P)의 표면에 대한 정보를 반영하는 프로브 좌표 데이터(C)들을 획득하게 된다. 그리고, 수술용 내비게이션 장치는 획득한 프로브 좌표 데이터(C)들을 회전 또는 이동시켜 기 촬영한 환자(P)의 의료 영상으로부터 획득한 표면 좌표 데이터들과 정합하고 정합한 결과물을 단일의 공간에 위치시키게 된다. 한편, 표면 좌표 데이터들은 의료영상 장비를 통해 획득한 고해상도의 영상 정보를 기반으로 하기 때문에 수천 에서 수십만개의 좌표 데이터로 구성될 수 있다. 따라서, 표면 정합은 환자 공간과 의료 영상간 지정된 표식자 마커 없이 각 공간의 좌표 군집으로 변환 행렬을 찾아낸다. 또한, 표면 정합은 추가적인 CT 촬영을 진행하지 않으며 임상의의 편의성이 있다. 그러나, 표면 정합은 환자 공간 좌표 군집을 획득하는 지역인 얼굴 표면에서 환부가 멀어지면서 증가되는 병변 오차 문제가 발생된다. 일 예로, 얼굴 표면에서 약간의 회전 오차가 발생한 경우, 얼굴 표면에서 멀리 떨어진 심부 병변 측에서는 증폭된다. 즉, 표면 정합은 얼굴 표면의 좌표만으로 정합을 수행하기 때문에 심부 병변 측 에서 오차가 발생하여 타 병변으로 오인될 수 있다는 한계가 있다."}
{"patent_id": "10-2021-0178639", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적 과제는 본 발명은 의료 영상 정합 장치에 관한 것으로, 더욱 상세하게는 환자 공간의 데이터 및 팬텀의 병변 위치 정보를 기반으로 회전 및 병진 변환 행렬값을 추정하고, 심부 병변 오차를 최소화하여 의료 영상 데이터의 데이터와 환자 공간의 데이터를 정밀 정합을 할 수 있는 의료 영상 정합 장치를 제공하는 것이다. 본 발명이 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다 른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0178639", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 달성하기 위하여, 본 발명의 일 실시예에 따른 내시경 증강현실 정밀도 향상 및 심부 병변 오차 감소를 위하여 환자 공간의 영상 데이터와 의료 영상 데이터를 정밀 정합하는 의료 영상 정합 장치에 있어 서, 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 수신하는 입력부, 상기 환자 공간의 영상 데이터 와 상기 의료 영상 데이터를 기반으로 정밀 정합을 위한 회전 및 병진 변환 행렬 값을 추정하는 인공 지능 모델 이 저장된 인공 지능 모델 저장부, 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 정밀 정합하는 정 합부 및 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터의 정합 결과물을 출력하는 출력부를 포함할 수 있다. 또한, 상기 정합부는 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 개략적으로 정합하여 제1정합 좌표점을 생성하는 제1정합부, 상기 제1정합 좌표점과 상기 의료 영상 데이터의 표면 좌표점을 정합하여 제2 정 합 좌표점을 생성하는 제2정합부 및 상기 제2정합 좌표점을 상기 인공 지능 모델의 입력으로 하여 추정된 상기 회전 및 병진 변환 행렬값을 기반으로 정밀 정합하는 제3정합부를 포함할 수 있다. 상기 인공 지능 모델의 입력 정보 특징점은 상기 환자 공간의 얼굴 표면 좌표점과 상기 환자 공간의 얼굴 표면 좌표점에 대응되는 상기 의료 영상 데이터의 표면 좌표점을 포함하며, 6개의 차원(dimension)으로 설정될 수 있 다. 상기 인공 지능 모델은 팬텀의 병변 위치 좌표점를 기반으로한 데이터 세트를 더 확보하여 인공 지능 모델의 입 력 특징점을 설정하고, 상기 병변 위치 좌표점을 기반으로한 인공 지능 모델의 입력 특징점은 가상의 병변 구조 물에 임의로 지정한 병변 후보군의 위치 좌표점과 상기 병변 구조물을 촬영한 영상 데이터에서 상기 병변 후보 군의 위치 정보와 대응되는 위치 좌표점을 포함하며, 6개의 차원(dimension)으로 설정될 수 있다. 상기 인공 지능 모델은 Bi-LSTM(Bidirectional LSTM) 아키텍처를 포함하며, 회귀 레이어 (Regression layer) 를 이용하여 회전 및 병진 변환 행렬을 3X3 차원인 회전 변환 행렬과 3X1차원인 병진 변환 행렬로 출력할 수 있다. 상기 제2정합부, 상기 인공 지능 모델 및 상기 제3정합부는 ICP(iterative closest point) 알고리즘을 이용하여 정합할 수 있다. 또한, 본 발명의 일 실시예에 따른 내시경 증강현실 정밀도 향상 및 심부 병변 오차 감소를 위하여 환자 공간의 영상 데이터와 의료 영상 데이터를 정밀 정합 하는 의료 영상 정밀 정합 방법에 있어서, a) 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 획득하는 단계, b) 상기 환자 공간의 영상 데이터와 상기 의료 영상 데 이터로부터 개략적으로 좌표점을 추출하여 정합하고, 개략적인 회전 및 병진 변환 행렬을 추출하는 단계, c) 상 기 개략적으로 정합된 좌표점과 상기 환자 공간의 영상 데이터로부터 추출된 얼굴 표면 좌표점을 추출된 상기 개략적인 회전 및 병진 변환 행렬을 이용하여 제1정합하고 제1정합 좌표점을 생성하는 단계, d) 상기 제1정합 데이터를 증강시키고, 증강된 제 1정합 좌표점을 상기 의료 영상 데이터로부터 추출된 표면 좌표점과 정합하여 제2정합 좌표점을 생성하는 단계 및 e) 상기 제2정합 좌표점을 상기 인공 지능 모델의 입력으로 하여 추정된 상 기 회전 및 병진 변환 행렬값을 기반으로 정밀 정합하는 단계를 포함할 수 있다. 상기 d) 단계 및 상기e) 단계는 ICP(iterative closest point) 알고리즘을 이용하여 정합할 수 있다. 상기 d) 단계는 1회의 증강 시마다 상기 제1정합 좌표점을 5% 증강시키며, 상기 증강을 복수회 실시할 수 있다. 상기 d) 단계는 상기 1회의 증강이 끝날 때마다 표면 정합 오차를 분석하는 단계를 포함하며, 상기 표면 정합 오차 분석값이 기 설정된 종료 조건을 만족할 때 증강을 중단할 수 있다."}
{"patent_id": "10-2021-0178639", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 환자 공간의 영상 데이터와 의료 영상 데이터를 인공 지능 모델을 기반으로 추출된 회전 및 병진 변환 행렬을 이용하여 정합을 진행하기 때문에, 표면 정합 시 발생하는 심부 병변 오차를 최소화 할 수 있다. 또한, 본 발명의 실시예에 따르면, 환자 공간의 영상 데이터와 의료 영상 데이터로부터 대략적으로 좌표점을 추 출하여 코스 정합을 먼저 수행함으로써 정합 정확도를 향상시킬 수 있다. 또한, 본 발명의 실시예에 따르면, 가상의 병변 구조물의 병변 위치 좌표점을 포함한 데이터 세트를 확보하고, 이를 기반으로 인공 지능 모델 입력 정보의 특징점을 설정하여 학습을 수행하므로, 얼굴 표면에서 멀리 떨어진 심부 병변 측에서도 최적화된 회전 및 병진 변환 행렬을 추정할 수 있다. 또한, 본 발명의 실시예에 따르면, 사용자는 심부 병변 측의 오차가 최소화된 의료 영상 데이터와 환자 공간의 영상 데이터 정합 결과물을 인지할 수 있다. 이로써, 사용자는 정확하게 심부 병변을 파악할 수 있으며, 효율 적으로 심부 병변의 수술을 진행할 수 있다."}
{"patent_id": "10-2021-0178639", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 상기한 효과로 한정되는 것은 아니며, 본 발명의 상세한 설명 또는 특허청구범위에 기재된 발 명의 구성으로부터 추론 가능한 모든 효과를 포함하는 것으로 이해되어야 한다."}
{"patent_id": "10-2021-0178639", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참조하여 본 발명을 설명하기로 한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며, 따라서 여기에서 설명하는 실시예로 한정되는 것은 아니다. 그리고 도면에서 본 발명을 명확 하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유 사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결(접속, 접촉, 결합)\"되어 있다고 할 때, 이는 \"직접적으로 연 결\"되어 있는 경우뿐 아니라, 그 중간에 다른 부재를 사이에 두고 \"간접적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 구비할 수 있다는 것을 의미한다. 본 명세서에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들 을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요 소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 이하 첨부된 도면을 참고하여 본 발명의 실시예를 상세히 설명하기로 한다. 도2는 본 발명의 실시예에 따른 의료 영상 정합 장치를 도시하는 도면이다. 도2에 도시된 바와 같이, 본 발명의 실시예에 따른 의료 영상 정합 장치는 입력부, 좌표점 생성부 , 증강부, 인공 지능 모델 저장부, 정합부 및 출력부를 포함할 수 있다. 먼저, 입력부는 환자 공간의 영상 데이터와 의료 영상 데이터를 수신한다. 환자 공간은 환자가 위치한 공 간이며, 수술 시 환자 공간으로부터 획득될 수 있다. 또한, 환자 공간의 영상 데이터와 의료 영상 데이터는 3차 원 형태일 수 있다. 일 예로, 입력부는 프로브(미도시)를 포함할 수 있다. 프로브는 환자 공간의 영상 데이터를 획득할 수 있 다. 프로브는 막대 형상의 의료도구일 수 있으며, 단부가 환자의 신체 표면과 접촉되거나 인접하게 배치된 상태 로 사용될 수 있다. 프로브는 환자의 신체 표면을 따라 이동하며 환자 공간의 신체 표면에 대한 영상데이터를 획득한다. 프로브는 환자의 신체를 향한 일측에 배치되는 센서를 포함할 수 있다. 센서는 광학식 센서일 수 있 다. 한편, 의료 영상 데이터는 수술 전에 획득된 환자의 영상으로 CT, MRI 또는 초음파 등을 통해 촬영된 것일 수 있다. 또한, 좌표점 생성부는 제1좌표점 생성부 및 제2좌표점 생성부를 포함할 수 있다. 제1좌표점 생성부는 의료 영상 데이터로부터 표면 좌표점 세트를 획득할 수 있다. 또한, 제1좌표점 생성부 는 획득한 표면 좌표점 세트를 기초로 하여 코스 정합(Coarse matching)을 위한 기준 좌표점인 제1좌표점 생성을 할 수 있다. 여기서, 제1좌표점은 대략적인 정합을 위하여 추출된 의료 영상 데이터의 표면 좌표점이다. 제2좌표점 생성부는 프로브로부터 입력된 환자의 신체 표면에 대한 좌표점을 획득하여 코스 정합을 위한 기준 좌표점인 제2좌표점을 생성할 수 있다. 여기서, 제2좌표점은 프로브가 환자 얼굴의 표면을 접촉할 시, 획 득된 환자 얼굴 표면 좌표점을 포함할 수 있다. 일 예로, 제2좌표점은 프로브가 환자의 이마, 코끝, 눈끝 및 이 마 등을 접촉할 시 환자 공간의 얼굴 표면 좌표점을 포함할 수 있다. 증강부는 제1정합된 표면 좌표점을 증강시킨다. 후술하겠지만, 증강부는 보간법을 이용하여 제1정합 좌표점을 증강시킬 수 있다. 여기서, 제1정합 좌표점을 증강시킨다는 것은 제1 정합 좌표점을들의 수를 증가시 키는 것으로 이해될 수 있다. 구체적으로, 증강부는 구간적 3차 에르미트 보간 다항식(Piecewise Cubic Hermite Interpolating Polynomial)을 이용하여 제1정합 좌표점을 증강시킬 수 있다. 구간적 3차 에르미트 보 간 다항식은 각 점들의 값과 1차 미분값을 대응시켜 보간하는 특징을 가진다. 구간적 3차 에르미트 보간 다항식 은 다음의 [수학식 1]으로 설명될 수 있다.[수학식 1]"}
{"patent_id": "10-2021-0178639", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "[수학식 2]"}
{"patent_id": "10-2021-0178639", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "구간적 3차 에르미트 보간법은 k번째 데이터를 , 데이터 값을 , 기울기 값을 , k번째 데이터의 구간 을 , 라 하고, 의 범위에서 [수학식 2]를 만족하는 [수학식 1]의 3차 다항식 를 계산하는 것을 의미한다. 구간적 3차 에르미트 보간법을 이용하여 좌표점을 증강시키면, 데이터가 과도하게 상승하는 오버슈트 (overshoot) 현상이 방지될 수 있다. 따라서 신체 표면의 평탄 영역을 정확하게 연결할 수 있다. 또한, 증강부는 제1정합 좌표점을 5%씩 증강시킬 수 있다. 제1정합 좌표점을 5% 증강시키는 과정을 1회의 스텝으로 가정하면, 증강부는 1회 이상의 스텝을 반복 실시할 수 있다. 증강부는 제한된 시간 내에서 획득된 제1정합 좌표점의 좌표점 수를 증강시키므로 정합 정확도를 높일 수 있다. 인공 지능 모델 저장부는 의료 영상 데이터 및 환자 공간의 영상 데이터를 수신할 수 있으며, 수신한 의료 영상 데이터 및 환자 공간의 영상 데이터를 이용하여 회전 및 병진 변환 행렬 값을 추정할 수 있다. 구체적으로, 인공 지능 모델 저장부에 인공 지능 모델을 저장할 수 있으며, 인공 지능 모델은 의료 영상 데이터 및 환자 공간의 영상 데이터를 입력으로 하여 정밀 정합을 위한 회전 및 병진 변환 행렬 값을 추정할 수 있다. 인공 지능 모델은 특징적인 값을 시간에 따라 스스로 학습하고 상호 연관성이 있는 시계열 데이터에 따라 예측하는 인공 지능 모델 LSTM(Long Short Term Memory)로 구현될 수 있다. 또한, 인공 지능 모델은 정확도를 향상시키기 위하여 LSTM을 순방향뿐만 아니라 역방향의 결과까지 함께 이용하는 Bi-LSTM(Bidirectional LSTM) 를 포함할 수 있다. 한편, 정합부는 제1정합부, 제2정합부 및 제3정합부을 포함할 수 있다. 제1정합부는 개략적으로 제1좌표점과 제2좌표점을 정합할 수 있다. 정합은 각자의 공간에 위치한 좌표점 세트들을 하나의 좌표계에 배치하는 것을 의미한다. 즉, 제1정합부는 정합된 결과물을 하나의 공간 좌표계 에 배치할 수 있다. 이 때, 제1정합부는 코스 정합을 하는 경우의 회전 및 병진 변환 행렬 값을 추출할 수 있다. 또한, 제1정합부는 추출된 회전 및 병진 변환 행렬값을 이용하여 환자 공간의 얼굴 표면 좌표점을 코스 정 합된 좌표점과 정합할 수 있다. 제1정합부는 환자 공간의 얼굴 표면 좌표점을 이동시키거나 회전시켜 코스 정합된 좌표점과 정합을 구현할 수 있다. 또한, 제1정합부는 코스 정합된 좌표점을 이동시키거나 회전시켜 환자 공간의 얼굴 표면 좌표점과 코스 정합할 수 있다. 그리고, 이 때, 환자 공간의 얼굴 표면 좌표점은 입력부 에서 프로브의 이동 경로에 따라 입력된 환자의 신체 표면에 대한 좌표점들을 포함할 수 있다. 그리고, 제 1정합부는 정합 결과물인 코스 정합된 표면 좌표점을 제1정합 좌표점으로 하여 하나의 공간 좌표계에 배치 할 수 있다. 제2정합부는 증강부에서 증강된 제1정합 좌표점과 의료 영상 데이터의 표면 좌표점을 정합할 수 있다. 일 예로, 제2정합부는 ICP(iterative closest point) 알고리즘을 이용하여 정합할 수 있다. ICP 알고리즘은 두 공간의 좌표간 위치의 평균 차이가 최소가 될 수 있는 회전 및 이동 행렬을 계산하여 매칭하 는 방법이다. ICP 알고리즘은 다음의 수학식 3으로 정의된다.[수학식 3] 초기에 개략적으로"}
{"patent_id": "10-2021-0178639", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 3에서, R과 t는 두개의 좌표점 세트의 위치 오차를 최소화할 수 있는 회전 행렬과 이동 행렬을 의미하며, 와 는 각각 환자 공간의 얼굴 표면 좌표점 세트인 증강된 제1정합 좌표점 세트와 의료 영상의 표면 좌표점 세트를 의미한다. 한편, 제2정합부는 정합 결과물에 대한 정확도를 분석할 수 있다. 제2정합부는 표면 정합 오차 (Surface registration error; SRE) 분석을 통해 정합 오차나 정합 정확도를 분석할 수 있다. 표면 정합 오차 는 하나의 표면 좌표점 세트와 다른 표면 좌표점 세트 간 거리를 계산하고 이를 평균하여 획득된다. 표면 정합 오차는 아래의 수학식 4에 의해 계산될 수 있다. [수학식 4]"}
{"patent_id": "10-2021-0178639", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "[수학식 4]에서 는 i번째 의료 영상의 표면 좌표점을 의미하고 는 ICP 알고리즘을 통 해 획득된 변환행렬이 적용된 i번째 환자 공간의 얼굴 표면 좌표점을 의미한다. 이 때, 환자 공간의 얼굴 표면 좌표점은 i 번째 증강된 제1정합 좌표점을 포함한다. 제2정합부는 계산된 표면 정합 오차가 종료 조건 만족 여부를 판단할 수 있다. 제2정합부는 표면 정 합 오차가 종료 조건을 만족하는 경우, 환자 공간의 얼굴 표면 좌표점에 대응되는 의료 영상의 표면 좌표점과 최종 증강된 환자 공간의 얼굴 표면 좌표점을 추출할 수 있다. 또한, 제2정합부는 표면 정합 오차가 종료 조건을 만족하지 않는 경우, 제1정합 좌표점을 증강부에서 스텝을 반복하여 증강시킬 수 있다. 제3정합부는 저장된 인공 지능 모델을 기반으로 정합을 진행할 수 있다. 이 때, 인공 지능 모델은 추가적 으로 팬텀의 팬텀 병변 위치 좌표점을 포함하여 ICP를 이용한 최적화된 정합을 할 수 있다. 여기서 팬텀은 얼굴 모양 모형으로, 가상의 병변 구조물이 구비될 수 있다. 이 때, 팬텀의 병변 위치 좌표점은 가상의 병변 구조물 에 임의로 지정된 병변 후보군을 의미한다. 따라서, 제3정합부는 팬텀 병변 위치 좌표점을 추가적으로 포 함하여 추출된 이동 및 병진 변환 행렬값을 기초로 ICP정합이 구현되기 때문에 심부 병변 오차 증폭을 감소시킬 수 있다. 마찬가지로, 제3정합부는 결과물을 하나의 공간 좌표계에 배치할 수 있다. 일 예로, 제3정합부는 실 시간 의료 영상 좌표계에 정합된 좌표점을 배치할 수 있다. 출력부는 제3정합부에서 배치된 결과물을 출력한다. 출력부는 정합 결과물을 디스플레이 장치를 통해 영상으로 표시할 수 있다. 도3은 본 발명의 실시예에 따른 의료 영상 데이터의 표면 데이터와 환자 공간의 얼굴 표면 데이터를 정합하는 방법을 도시하는 도면이다. 도3을 참조하면, 단계(S110)에서 의료 영상 정합 장치는 의료 영상 데이터 및 환자 공간의 영상 데이터를 수신 할 수 있다. 의료 영상 정합 장치는 의료 영상 데이터로부터 환자를 촬영한 의료 영상 데이터의 표면 좌표점을 추출하여 획득할 수 있다. 일 예로, 의료 영상 데이터의 표면 좌표점을 환자의 신체 표면에 대한 좌표점들을 포 함한다. 한편, 의료 영상 정합 장치는 환자 공간의 영상 데이터로부터 프로브가 센싱한 환자 공간의 얼굴 표면 좌표점을 추출하여 획득할 수 있다. 의료 영상 정합 장치는 프로브를 이용하여 프로브의 위치 정보를 나타내는 환자 공간 의 영상 데이터를 수집한다. 다음으로, 단계(S120)에서, 의료 영상 정합 장치는 획득된 의료 영상 데이터의 표면 좌표점과 환자 의료 영상 공간의 얼굴 표면 좌표점의 코스 정합용 좌표점을 추출할 수 있다. 일 예로, 의료 영상 정합 장치는 의료 영상 의 공간의 표면 좌표점으로부터 개략적인 정합인 코스 정합을 위해 제1좌표점을 추출할 수 있다. 또한, 의료 영 상 정합 장치는 환자 공간의 얼굴 표면 좌표점으로부터 코스 정합용 제2좌표점을 추출할 수 있다. 여기서, 제2 좌표점은 프로브가 환자의 이마, 코끝, 눈끝 및 이마 등을 접촉할 시 환자 공간의 얼굴 표면 좌표점을 포함할 수 있다. 이 때, 의료 영상 정합 장치는 추출된 제1좌표점 및 제2좌표점을 코스 정합하여 코스 정합된 좌표점을 획득할 수 있다. 또한, 의료 영상 정합 장치는 코스 정합을 하는 경우의 회전 및 병진 변환 행렬값을 추출할 수 있다. 또한, 의료 영상 정합 장치는 추출된 회전 및 병진 변환 행렬값을 이용하여 환자 공간의 얼굴 표면 좌표점을 코 스 정합된 좌표점과 정합할 수 있다. 이 때, 환자 공간의 얼굴 표면 좌표점은 프로브의 이동 경로에 따라 입력 된 환자의 신체 표면에 대한 좌표점들을 포함할 수 있다. 그리고, 의료 영상 정합 장치는 정합 결과물인 코스 정합된 표면 좌표점을 제1정합 좌표점으로 하여 하나의 공간 좌표계에 배치할 수 있다. 단계(S130)에서, 의료 영상 정합 장치는 제1정합 좌표점을 증강할 수 있다. 제1정합 좌표점을 증강하는 단계는 복수 회 반복 실시될 수 있다. 일 예로, 제1정합 좌표점은 5%씩 증강될 수 있다. 제1정합 좌표점을 5% 증강시키 는 과정을 1회의 스텝으로 가정하면, 의료 영상 정합 장치는1회 이상의 스텝을 반복 실시할 수 있다. 의료 영상 정합 장치는 제한된 시간 내에서 획득된 제1정합 좌표점의 좌표점 수를 증강시키므로 정합 정확도를 높일 수 있 다. 또한, 의료 영상 정합 장치는 증강된 제1 정합 좌표점을 의료 영상 데이터의 표면 좌표점과 정합할 수 있다. 일 예로, 의료 영상 정합 장치는 ICP(iterative closest point) 알고리즘을 이용하여 정합할 수 있다. ICP 알고리 즘은 두 공간의 좌표간 위치의 평균 차이가 최소가 될 수 있는 회전 및 이동 행렬을 계산하여 매칭하는 방법이 다. 한편, 의료 영상 정합 장치는 표면 정합 오차 분석을 통해 정합 오차나 정합 정확도를 분석할 수 있다. 표면 정 합 오차는 하나의 표면 좌표점 세트와 다른 표면 좌표점 세트 간 거리를 계산하고 이를 평균하여 획득된다. 또한, 의료 영상 정합 장치는 계산된 표면 정합 오차가 종료 조건 만족 여부를 판단할 수 있다. 의료 영상 정합 장치는 표면 정합 오차가 종료 조건을 만족하는 경우, 환자 공간의 얼굴 표면 좌표점에 대응되는 의료 영상 데 이터의 표면 좌표점과 최종 증강된 환자 공간의 얼굴 표면 좌표점을 추출할 수 있다. 추출된 결과물은 제2정합 좌표점을 의미한다. 그리고, 의료 영상 정합 장치는 표면 정합 오차가 종료 조건을 만족하지 않는 경우, 스텝을 반복하여 제1정합 좌표점을 증강시킬 수 있다. 단계(S140)에서, 의료 영상 정합 장치는 인공 지능 모델을 기반으로 정합을 진행할 수 있다. 이 때, 의료 영상 정합 장치는 제2정합 좌표점과 팬텀 병변 위치 좌표점을 인공 지능 모델의 입력으로하여 추출된 회전 및 병진 변환 행렬값을 기반으로 최적화된 정합을 할 수 있다. 일 예로, 의료 영상 정합 장치는 ICP를 활용하여 최적화 된 정합을 진행할 수 있다. 따라서, 의료 영상 정합 장치는 팬텀 병변 위치 좌표점이 반영된 회전 및 병진 변환 행렬값을 이용하여 최적화된 정합을 구현하기 때문에 심부 병변 오차 증폭을 감소시킬 수 있다. 단계(S150)에서 의료 영상 정합 장치는 최종 정합된 결과물을 하나의 공간 좌표계에 배치하여 출력할 수 있다. 일 예로, 의료 영상 정합 장치는 실시간 의료 영상 데이터 좌표계에 제3정합 좌표점을 배치하고, 디스플레이 장 치를 통해 영상으로 표시할 수 있다. 도4는 본 발명의 실시예에 따른 의료 영상 정합 장치가 제1정합 및 제2정합을 진행하는 방법을 구체적으로 도시 하는 도면이다. 도4에 도시된 바와 같이, 단계(S210)에서 의료 영상 정합 장치는 의료 영상 데이터로부터 표면 좌표 데이터인 표면 좌표점 세트를 획득할 수 있다. 일 예로, 의료 영상 데이터는 수술 전에 획득된 환자의 영상으로 CT, MRI 또는 초음파 등을 통해 촬영된 것일 수 있다. 또한, 의료 영상 정합 장치는 획득된 표면 좌표점 세트로부터 코스 정합을 위한 제1좌표점을 생성할 수 있다. 즉, 의료 영상 정합 장치는 정확도를 향상시키기 위하여 표면 좌표점 세트로부터 대략적으로 좌표점을추출한다. 단계(S220)에서, 의료 영상 정합 장치는 환자 공간의 영상 데이터로부터 얼굴 표면 데이터를 추출할 수 있다. 구체적으로, 의료 영상 정합 장치는 코스 정합을 하기 위하여 환자 공간의 영상 데이터로부터 프로브가 센싱한 환자 공간의 얼굴 표면 좌표점을 추출하여 획득할 수 있다. 의료 영상 정합 장치는 프로브를 이용하여 프로브의 위치 정보를 나타내는 표면 좌표점을 획득할 수 있다. 의료 영상 정합 장치는 프로브가 접촉하거나 인접한 환자 얼굴 표면 일부의 표면 좌표점을 획득할 수 있다. 또한, 의료 영상 정합 장치는 획득한 표면 좌표점을 제2좌표 점으로 생성할 수 있다. 일 예로, 제2좌표점은 환자의 이마, 코끝, 눈끝 및 이마 등을 접촉할 시 환자 공간의 얼굴 표면 좌표점을 포함할 수 있다. 단계(S230)에서, 의료 영상 정합 장치는 제1좌표점을 제2좌표점과 코스 정합하여 코스 정합 좌표점을 생성할 수 있다. 또한, 의료 영상 정합 장치는 코스 정합을 하는 경우의 회전 및 병진 변환 행렬을 추출할 수 있다. 의료 영상 정합 장치는 초기에 코스 정합을 수행하므로 정확도를 향상시킬 수 있다. 단계(S240)에서, 의료 영상 정합 장치는 환자 공간의 얼굴 표면 좌표점을 코스 정합된 표면 좌표점으로 변환할 수 있다. 의료 영상 정합 장치는 추출된 회전 및 병진 변환 행렬을 이용하여 제1정합 좌표점을 생성할 수 있다. 여기서 환자 공간의 얼굴 표면 좌표점은 프로브의 위치 정보를 나타낸다. 프로브는 10초 내외의 시간동안 환자 의 피부 표면을 따라 접촉 또는 근접한 상태로 이동하며 환자의 신체 표면에 대한 데이터를 수집한다. 일례로, 프로브는 10초 내지 20초의 시간 동안 데이터를 수집할 수 있다. 의료 영상 정합 장치는 추출된 코스 정합을 하는 경우의 회전 및 병진 변환 행렬을 기반으로 환자 공간의 얼굴 표면 좌표점과 코스 정합된 좌표점을 정합한다. 그리고, 의료 영상 정합 장치는 정합 결과물인 표면 좌표점을 제1정합 좌표점으로 하여 하나의 공간 좌표계에 배치할 수 있다. 단계(S250)에서, 의료 영상 정합 장치는 제1정합 좌표점을 증강할 수 있다. 제1정합 좌표점을 증강하는 단계는 복수 회 반복 실시될 수 있다. 제1정합 좌표점은 5%씩 증강될 수 있다. 제1정합 좌표점을 5% 증강시키는 과정을 1회의 스텝으로 가정하면, 의료 영상 정합 장치는1회 이상의 스텝을 반복 실시할 수 있다. 의료 영상 정합 장치 는 제한된 시간 내에서 획득된 제1정합 좌표점의 좌표점 수를 증강시키므로 정합 정확도를 높일 수 있다. 또한, 의료 영상 정합 장치는 증강된 제1정합 좌표점을 의료 영상 데이터의 표면 좌표점과 정합할 수 있다. 이 때, 의료 영상 정합 장치는 ICP알고리즘을 이용하여 정합할 수 있다. 또한, 의료 영상 정합 장치는 제 2정합을 진행하는 경우의 회전 및 병진 변환 행렬을 도출할 수 있다. 단계(S260)에서, 의료 영상 정합 장치는 표면 정합 오차 분석을 통해 정합 오차나 정합 정확도를 분석할 수 있 다. 표면 정합 오차는 하나의 표면 좌표점 세트와 다른 표면 좌표점 세트 간 거리를 계산하고 이를 평균하여 획 득된다. 또한, 의료 영상 정합 장치는 분석된 표면 정합 오차가 기 설정된 종료 조건 만족 여부를 판단할 수 있다. 이 때, 의료 영상 정합 장치는 표면 정합 오차가 종료 조건을 만족하지 않을 시, 단계(S250) 및 단계(S260)을 반복 실시할 수 있다. 즉, 의료 영상 정합 장치는 제1정합 좌표점을 재증강시키고 정합하는 단계 및 표면 정합 오차 판단 단계를 반복 실시할 수 있다. 단계(S270)에서, 의료 영상 정합 장치는 표면 정합 오차가 기설정된 종료 조건을 만족하는 경우, 정합 결과로부 터 환자 공간의 얼굴 표면 좌표점에 대응되는 의료 영상 데이터의 표면 좌표점과 최종 증강된 환자 공간의 얼굴 표면 좌표점을 추출할 수 있다. 추출된 결과물은 제2정합 좌표점을 의미한다. 도5는 본 발명의 실시예에 따른 인공 지능 모델을 구축하는 방법을 도시하는 도면이다. 먼저, 단계(S310)에서, 인공 지능 모델은 팬텀의 병변 위치 좌표점 및 환자 공간의 얼굴 표면 좌표점을 기반으 로한 데이터 세트를 확보할 수 있다. 팬텀은 얼굴 모양 모형으로, 가상의 병변 구조물이 구비될 수 있다. 이 때, 팬텀의 병변 위치 좌표점은 가상의 병변 구조물에 임의로 지정된 병변 후보군을 의미한다. 일 예로, 팬텀의 병변 위치 좌표점은 팬텀을 촬영한 CT영상에서 추출된 좌표점을 포함할 수 있다. 또한, 인공 지능 모델은 프로 브로부터 반복적인 실험으로 추출된 환자 공간의 얼굴 표면 좌표점을 획득할 수 있다. 후술하겠지만, 의료 영상 정합 장치는 인공 지능 모델이 팬텀의 병변 위치 좌표점을 추가적으로 포함함으로써 최적화된 정합을 구현할 수 있다. 단계(S320)에서, 인공 지능 모델의 입력 및 출력이 설정될 수 있다. 일 예로, 입력 정보의 특징점은 환자 공간 의 얼굴 표면 좌표점과 그 좌표점에 대응되는 의료 영상 데이터의 표면 좌표점으로 설정될 수 있다. 이 때, 좌표점은 3차원 좌표점으로, (x, y, z) 형태로 표시될 수 있다. 또한, 인공 지능 모델 입력 정보의 특징점은 추가적으로 팬텀 내부에 있는 병변의 위치 정보인 병변 위치 좌표 점이 포함될 수 있다. 여기서, 병변 위치 좌표점은 임의로 지정된 병변 후보군의 위치 좌표점과 팬텀을 촬영한 영상에서 병변 후보군에 대응되는 위치의 위치 좌표점을 포함할 수 있다. 이 때, 병변 위치 좌표점이 인공 지능 모델 입력 정보의 특징점으로 사용된다. 한편, 인공 지능 모델의 출력 정보는 ICP 정합을 통하여 추출된 회전 및 병진 변환 행렬로 설정될 수 있다. 단계(S330)에서, 인공 지능 모델은 학습과 테스트를 위하여 확보된 데이터 세트를 분할한다. 여기서, 학습 데이 터 세트와 검증 데이터 세트를 분할함으로써 학습 데이터에서만 높은 예측력을 보이는 과적합(overfitting)을 방지할 수 있다. 또한, 단계(S330)는 인공 지능 모델의 학습 성능을 높이기 위하여 충분한 학습 데이터를 확보하도록 수행될 수 있다. 일 예로, 인공 지능 모델은 랜덤 노이즈를 추가하는 지터링(Jittering)과 데이터 세트의 데이터 분포가 일정하도록 변경하는 스케일(Scaling) 기법을 활용하여, 학습 데이터를 증강할 수 있다. 단계(S340)에서, 인공 지능 모델은 추출된 특징점을 학습하여 회전 및 병진 변환 행렬을 추정할 수 있다. 예를 들어, 인공 지능 모델은 회전 및 병진 변환 행렬을 추정하기 위하여 데이터의 특징을 추출하여 학습하는 머신 러닝 모델을 사용할 수 있다. 이 때, 머신 러닝 모델은 LSTM(Long Short Term Memory)로 구현될 수 있다. LSTM 은 특징적인 값을 시간에 따라 스스로 학습하고 상호 연관성이 있는 시계열 데이터에 따라 예측하는 인공 지능 모델이다. 여기서, 인공 지능 모델은 정확도를 향상시키기 위하여 순방향뿐만 아니라 역방향의 결과까지 이용할 수 있는 Bi-LSTM(Bidirectional LSTM)으로 구현될 수 있다. 단계(S350)에서, 학습된 인공 지능 모델을 테스트할 수 있다. 학습 데이터 세트로 학습된 인공 지능 모델을 검 증 데이터 세트를 이용하여 평가할 수 있다. 일 예로, 인공 지능 모델은 교차 검증(Cross validation)으로 테스 트될 수 있다. 교차 검증은 과적합(Over fitting)을 방지하기 위하여 최적의 매개 변수를 찾기 위한 검증 방법 이다. 인공 지능 모델이 교차 검증으로 테스트되는 경우, 학습 데이터 세트 중 일부를 검증 데이터 세트로 분할 할 수 있다. 인공 지능 모델은 학습 데이터 세트 및 검증 데이터 세트를 부분적으로 번갈아 바꿔가며 여러 개의 학습 데이터 세트와 검증 데이터 세트를 만들고, 이로 인해 만들어진 각각의 데이터 세트에 대한 결과를 출력하 여 인공 지능 모델을 검증하는 것에 활용할 수 있다. 또한, 인공 지능 모델은 분할된 검증 데이터 세트를 이용 하여 최적화된 파라미터를 추정하고, 인공 지능 모델의 오차가 감소되도록 인공 지능 모델을 수정할 수 있다. 또한, 최종적으로 인공 지능 모델이 형성될 시, 인공 지능 모델은 테스트 데이터 세트를 활용하여 인공 지능 모 델을 평가할 수 있다. 도6은 본 발명의 실시예에 따른 인공 지능 모델의 학습을 위한 입력 정보를 도시하는 도면이다. 도6에 도시된 바와 같이, 환자 공간의 얼굴 표면 좌표점은 (x, y, z) 좌표로 설정되고, 이에 대응되는 의료 영 상 데이터의 표면 좌표점은 (x', y', z')로 설정될 수 있다. 즉, 입력 정보의 특징점은6개의 차원(dimension)으 로 설정될 수 있다. 이 때, 의료 영상 데이터의 표면 좌표점의 길이가 150일 시, 입력 정보의 사이즈는 6 by 150으로 설정될 수 있다. 또한, 추가적으로 팬텀의 병변 위치 좌표점을 팬텀을 촬영한 영상에서 추출할 수 있다. 여기서, 팬텀의 병변 위 치 좌표점은 임의로 지정한 병변 후보군의 위치 좌표점과 팬텀을 촬영한 영상에서 병변 후보군에 대응되는 위치 의 위치 좌표점을 포함할 수 있다. 이 때, 병변 위치 좌표점이 인공 지능 모델 입력 정보의 특징점으로 사용된 다. 추출된 팬텀의 병변 위치 좌표점은 6개의 차원으로 구성되어 입력 정보에 추가될 수 있다. 마찬가지로 의료 영 상 데이터의 표면 좌표점의 길이가 150일 시, 팬텀을 활용한 입력 정보의 사이즈는 6 by 150으로 설정될 수 있 다. 따라서, 최종적으로 입력 정보의 사이즈는 6 by 300으로 설정될 수 있다. 도7은 본 발명의 실시예에 따른 인공 지능 모델의 Bi-LSTM 아키텍처를 도시하는 도면이다. 먼저, LSTM은 RNN(순환 신경망, Recurrent neural network) 인공 지능 모델의 하나로, 연속적인 시계열 데이터 에 적합하다. LSTM 아키텍처는 상호 연관성이 있는 시계열 데이터를 예측하는 인공 지능 모델로서, 데이터를 순 차적으로 처리하는 순환 신경망 모델의 하나이다. 단기 기억 레이어(Shor term, hidden state)와 장기 기억을 담당하는 레이어(Long term, cell state)가 존재하여 시계열 데이터 예측에 높은 정확도를 갖는다. 또한, LSTM아키텍처는 일반적으로 일 실시예에서, 표1은 LSTM 아키텍처의 학습 옵션 테이블이다. 표1및 도7에 도시된 바와 같이, 인공 지능 모델 은 복수의 LSTM으로 Stacked LSTM을 구성할 수 있다. 또한, 인공 지능 모델은 정확도를 향상시키기 위하여 순방 향뿐만 아니라 역방향의 결과까지 이용할 수 있는 Bi-LSTM(Bidirectional LSTM)으로 구현될 수 있다. Bi-LSTM 의 레이어 1은 Bi-LSTM#1로 정의되고, Bi-LSTM의 레이어 2는 Bi-LSTM#2로 정의된다. 한편, 인공 지능 모델에 팬텀의 병변 위치 좌표점 및 환자 공간의 얼굴 표면 좌표점을 기반으로한 데이터 세트 를 입력할 수 있다. 일 예로, 환자 공간의 얼굴 표면 좌표점은 (x, y, z) 좌표로 설정되고, 이에 대응되는 의료 영상 데이터의 표면 좌표점은 (x', y', z')로 설정될 수 있다. 즉, 입력 정보는 6개의 차원(dimension)으로 설 정될 수 있다. 또한, 인공 지능 모델의 Bi-LSTM#1와 Bi-LSTM#2에서 양방향 학습이 구현될 수 있다. 각 Bi-LSTM 레이어에서 출 력된 결과값들은 연결 레이어(Concatenate layer)에서 합쳐질 수 있다. 또한, 연결 레이어에서 합쳐진 결과값들은 완전 연결 레이어(Fully connected layer)로 입력될 수 있다. 완전 연결 레이어는 1차원 배열의 형태로 평탄화된 행렬을 통해 분류를 결정하는 레이어이다. 즉, 완전 연결 레이어 에 입력된 결과값 중에 일부 결과값을 추출할 수 있다. 여기서, 완전 연결 레이어는 과적합(Over fitting)을 방 지하기 위하여 드롭 아웃(Drop out) 형태로 구현될 수 있다. 이 때, 드롭 아웃 비율은 0.2으로 진행될 수 있으 며, 드롭 아웃 비율에 따라 다른 특정 결과값이 출력될 수 있다. 또한, 인공 지능 모델이 복잡할 경우 드롭 아 웃 비율을 늘리고, 단순할 경우 드롭 아웃 비율을 낮추면서 조절할 수 있다. 그리고, 회귀 레이어(Regression layer)를 통해 회전 및 병진 변환 행렬값을 출력할 수 있다. 회귀 레이어는 종 속 변수와 독립 변수간의 상관 관계를 예측하는 것이다. 또한, 회전 및 병진 변환 행렬값의 회전 행렬은 3 by 3(R) 차원이고 병진 행렬은 3 by 1 (T) 차원으로 출력될 수 있다. 따라서, 인공 지능 모델을 통해 출력되는 회 전 및 병진 변환 행렬 값은 12개의 차원을 포함할 수 있다. 인공 지능 모델은 팬텀의 병변 위치 정보를 포함하여 최적화하기 때문에 출력된 회전 및 병진 변환 행렬이 심부 병변 오차의 증폭을 줄일 수 있는 방법으로 학습할 수 있다. 표 1 LSTM 아키텍처의 학습 옵션 테이블 No. Type of parameters Range of parameters Range of parameters 1 Number of hidden units [200,100] [100,50] 2 Maximum epochs 100 100 3 Mini-batch size 64 32 4 Weight initializer function Glorot Glorot 5 Solver Adam Adam 6 Drop out rate 0.2 0.2 7 Initial learning rate 0.01 0.01 8 Gradient threshold 2 2 9 Gradient threshold method Global-l2norm Global-l2norm 10 L2Regularization 1e^-5 1e^-6 11 Sequence padding shortest longest 12 Sequence output mode sequence sequence"}
{"patent_id": "10-2021-0178639", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다.본 발명의 범위는 후술하는 청 구범위에 의하여 나타내어지며, 청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또 는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다.부호의 설명 110. 입력부 120. 좌표점 생성부 130. 증강부 140. 인공 지능 모델 저장부 150. 정합부 160. 출력부"}
{"patent_id": "10-2021-0178639", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도1은 종래의 표면 정합을 설명하기 위한 도면이다. 도2는 본 발명의 실시예에 따른 의료 영상 정합 장치를 도시하는 도면이다. 도3은 본 발명의 실시예에 따른 의료 영상 데이터의 표면 데이터와 환자 공간의 얼굴 표면 데이터를 정합하는 방법을 도시하는 도면이다. 도4는 본 발명의 실시예에 따른 의료 영상 정합 장치가 제1정합 및 제2정합을 진행하는 방법을 구체적으로 도시 하는 도면이다. 도5는 본 발명의 실시예에 따른 인공 지능 모델을 구축하는 방법을 도시하는 도면이다. 도6은 본 발명의 실시예에 따른 인공 지능 모델의 학습을 위한 입력 정보를 도시하는 도면이다. 도7은 본 발명의 실시예에 따른 인공 지능 모델의 Bi-LSTM 아키텍처를 도시하는 도면이다."}
