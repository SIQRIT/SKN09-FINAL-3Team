{"patent_id": "10-2023-0096497", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0015270", "출원번호": "10-2023-0096497", "발명의 명칭": "인공지능 기반의 자동 지적 분할 시스템 및 방법", "출원인": "주식회사 오션라이트에이아이", "발명자": "박해광"}}
{"patent_id": "10-2023-0096497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "에 있어서,상기 지적 분할부는, 설정된 윤곽선 검출 알고리즘을 통해 상기 정사 이미지 내 상기 영역에 대한 윤곽선을 추출하고, 상기 윤곽선에 따라 분할된 각 영역 내 픽셀에 대응되는 클래스의 개수를 상기 각 영역별로카운팅하며, 상기 각 영역별로 가장 많은 개수로 카운팅된 클래스를 상기 각 영역별 클래스로 결정하고, 상기각 영역별 클래스에 따라 상기 정사 이미지 내 영역을 분할하는, 인공지능 기반의 자동 지적 분할 시스템."}
{"patent_id": "10-2023-0096497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 지적 분할부는, 상기 학습 데이터가 각각 학습된 복수 개의 상기 이미지 세그멘테이션 모델이 결합되어 형성되는 앙상블 모델을 구비하며, 상기 앙상블 모델 내 각 이미지 세그멘테이션 모델에서 추론되는 각 픽셀별 클래스의 확률값을 기반으로 상기 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론하는, 인공지능 기반의자동 지적 분할 시스템."}
{"patent_id": "10-2023-0096497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 지적 분할부는, 상기 각 이미지 세그멘테이션 모델에서 추론되는 각 픽셀별 클래스의 확률값을 획득하고,상기 각 이미지 세그멘테이션 모델별 확률값에 대한 평균치가 가장 높게 나타나는 클래스를 상기 각 픽셀별 클래스로 추론하는, 인공지능 기반의 자동 지적 분할 시스템."}
{"patent_id": "10-2023-0096497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 각 이미지 세그멘테이션 모델은, FCN(Fully Convolution Network), U-Net 및 DeepLab 모델이며,상기 각 픽셀별 클래스(Each segmented pixel class)는, 아래 수학식 1에 따라 계산되는, 인공지능 기반의 자동지적 분할 시스템.[수학식 1](여기서, M1Px는 모델 1을 통해 추론된 각 픽셀의 클래스 x의 확률값이며, M2Px는 모델 2를 통해 추론된 각 픽셀의 클래스 x의 확률값이며, M3Px는 모델 3을 통해 추론된 각 픽셀의 클래스 x의 확률값이며, 모델 1 내지 3은 각각 FCN, U-Net 및 DeepLab 모델을 나타냄. 또한, arg max f(x)는 f(x)를 최대로 만드는 x를 의미함)공개특허 10-2025-0015270-3-청구항 5"}
{"patent_id": "10-2023-0096497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "촬영 이미지 획득부에서, 위성 또는 무인 항공기로부터 촬영된 대상지역의 촬영 이미지를 획득하는 단계;정사 이미지 생성부에서, 상기 촬영 이미지의 특징점을 추출하는 단계;상기 정사 이미지 생성부에서, 추출된 상기 특징점을 이용하여 상기 대상지역에 대한 정사 이미지를 생성하는단계;지적 분할부에서, 기 학습된 학습 데이터와 복수 개의 이미지 세그멘테이션 모델을 이용하여 상기 정사 이미지내 각 픽셀들의 지적에 대한 클래스를 추론하는 단계;상기 지적 분할부에서, 추론된 상기 각 픽셀별 클래스를 기반으로 상기 정사 이미지 내 영역을 분할하는 단계;및후처리부에서, 상기 클래스별로 영역이 분할된 상기 정사 이미지에 상기 대상지역에 대한 3차원 정보를 매핑시키는 단계를 포함하는, 인공지능 기반의 자동 지적 분할 방법."}
{"patent_id": "10-2023-0096497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,상기 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론하는 단계는, 상기 학습 데이터가 각각 학습된 복수 개의 상기 이미지 세그멘테이션 모델이 결합되어 형성되는 앙상블 모델을 구비하며, 상기 앙상블 모델 내 각이미지 세그멘테이션 모델에서 추론되는 각 픽셀별 클래스의 확률값을 기반으로 상기 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론하는, 인공지능 기반의 자동 지적 분할 방법."}
{"patent_id": "10-2023-0096497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서,상기 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론하는 단계는, 상기 각 이미지 세그멘테이션 모델에서 추론되는 각 픽셀별 클래스의 확률값을 획득하고, 상기 각 이미지 세그멘테이션 모델별 확률값에 대한 평균치가 가장 높게 나타나는 클래스를 상기 각 픽셀별 클래스로 추론하는, 인공지능 기반의 자동 지적 분할 방법."}
{"patent_id": "10-2023-0096497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서,상기 각 이미지 세그멘테이션 모델은, FCN(Fully Convolution Network), U-Net 및 DeepLab 모델이며,상기 각 픽셀별 클래스(Each segmented pixel class)는, 아래 수학식 1에 따라 계산되는, 인공지능 기반의 자동지적 분할 방법.공개특허 10-2025-0015270-4-[수학식 1](여기서, M1Px는 모델 1을 통해 추론된 각 픽셀의 클래스 x의 확률값이며, M2Px는 모델 2를 통해 추론된 각 픽셀의 클래스 x의 확률값이며, M3Px는 모델 3을 통해 추론된 각 픽셀의 클래스 x의 확률값이며, 모델 1 내지 3은 각각 FCN, U-Net 및 DeepLab 모델을 나타냄. 또한, arg max f(x)는 f(x)를 최대로 만드는 x를 의미함)"}
{"patent_id": "10-2023-0096497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 6에 있어서,상기 정사 이미지 내 영역을 분할하는 단계는, 설정된 윤곽선 검출 알고리즘을 통해 상기 정사 이미지 내 상기영역에 대한 윤곽선을 추출하고, 상기 윤곽선에 따라 분할된 각 영역 내 픽셀에 대응되는 클래스의 개수를 상기각 영역별로 카운팅하며, 상기 각 영역별로 가장 많은 개수로 카운팅된 클래스를 상기 각 영역별 클래스로 결정하고, 상기 각 영역별 클래스에 따라 상기 정사 이미지 내 영역을 분할하는, 인공지능 기반의 자동 지적 분할방법."}
{"patent_id": "10-2023-0096497", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 기반의 자동 지적 분할 시스템 및 방법이 제공된다. 본 발명의 일 실시예에 따른 인공지능 기반의 자동 지적 분할 시스템은, 위성 또는 무인 항공기로부터 촬영된 대상지역의 촬영 이미지를 획득하는 촬영 이미지 획득 부; 상기 촬영 이미지의 특징점을 추출하고, 추출된 상기 특징점을 이용하여 상기 대상지역에 대한 정사 이미지 (orthophotograph)를 생성하는 정사 이미지 생성부; 기 학습된 학습 데이터와 복수 개의 이미지 세그멘테이션 모 델(Image Segmentation Model)을 이용하여 상기 정사 이미지 내 각 픽셀들의 지적(地籍)에 대한 클래스(class) 를 추론하고, 추론된 상기 각 픽셀별 클래스를 기반으로 상기 정사 이미지 내 영역을 분할하는 지적 분할부; 및 상기 클래스별로 영역이 분할된 상기 정사 이미지에 상기 대상지역에 대한 3차원 정보를 매핑시키는 후처리부를 포함한다."}
{"patent_id": "10-2023-0096497", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 위성 또는 무인 항공기로부터 촬영된 촬영 이미지를 기반으로 대상지역의 지적(地籍)을 자동으로 분 할하는 기술에 관한 것으로, 보다 구체적으로는 인공지능을 이용하여 대상지역의 지적을 시간적, 공간적 제약 없이 빠르고 정확하게 분할하는 기술과 관련된다."}
{"patent_id": "10-2023-0096497", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 지적도는 토지의 소재, 지번, 지목, 경계 등을 나타내기 위해 국가에서 만든 평면 지도를 의미한다. 이러한 지적도는 행정, 건설, 토목 분야에서 다양하게 활용되고 있으며, 지적도 제작을 위해 위성사 진, 항공사진 등이 활용된다. 그러나, 종래의 지적도 제작방식은 작업자들의 육안 관측에 의한 수작업에 의존하였으며, 이에 따라 많은 인력 이 투입되는 문제점이 있었다. 또한, 지적도 제작을 위한 단순 반복적인 업무로 인해 작업자들의 업무 기피현상 이 심화되었으며, 이에 따라 작업자들의 인건비가 상승하고 지적도 제작의 원가가 과도하게 상승하는 문제점이 있었다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허공보 제10-2482775호(2022.12.26)"}
{"patent_id": "10-2023-0096497", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예들은 인공지능 기반의 자동 지적 분할 기술을 통해 정사 이미지를 생성하고, 상기 정사 이미지 를 기반으로 정사 이미지 내 각 픽셀들의 클래스(class)를 자동으로 추론한 후 이를 바탕으로 정사 이미지 내 각 영역을 자동으로 분할하기 위한 것이다."}
{"patent_id": "10-2023-0096497", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "예시적인 실시예에 따르면, 위성 또는 무인 항공기로부터 촬영된 대상지역의 촬영 이미지를 획득하는 촬영 이미 지 획득부; 상기 촬영 이미지의 특징점을 추출하고, 추출된 상기 특징점을 이용하여 상기 대상지역에 대한 정사 이미지(orthophotograph)를 생성하는 정사 이미지 생성부; 기 학습된 학습 데이터와 복수 개의 이미지 세그멘테 이션 모델(Image Segmentation Model)을 이용하여 상기 정사 이미지 내 각 픽셀들의 지적(地籍)에 대한 클래스 (class)를 추론하고, 추론된 상기 각 픽셀별 클래스를 기반으로 상기 정사 이미지 내 영역을 분할하는 지적 분 할부; 및 상기 클래스별로 영역이 분할된 상기 정사 이미지에 상기 대상지역에 대한 3차원 정보를 매핑시키는 후처리부를 포함하는, 인공지능 기반의 자동 지적 분할 시스템이 제공된다. 상기 지적 분할부는, 상기 학습 데이터가 각각 학습된 복수 개의 상기 이미지 세그멘테이션 모델이 결합되어 형 성되는 앙상블 모델을 구비하며, 상기 앙상블 모델 내 각 이미지 세그멘테이션 모델에서 추론되는 각 픽셀별 클 래스의 확률값을 기반으로 상기 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론할 수 있다. 상기 지적 분할부는, 상기 각 이미지 세그멘테이션 모델에서 추론되는 각 픽셀별 클래스의 확률값을 획득하고, 상기 각 이미지 세그멘테이션 모델별 확률값에 대한 평균치가 가장 높게 나타나는 클래스를 상기 각 픽셀별 클 래스로 추론할 수 있다. 상기 각 이미지 세그멘테이션 모델은, FCN(Fully Convolution Network), U-Net 및 DeepLab 모델이며, 상기 각 픽셀별 클래스(Each segmented pixel class)는, 아래 수학식 1에 따라 계산될 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0096497", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "(여기서, M1Px는 모델 1을 통해 추론된 각 픽셀의 클래스 x의 확률값이며, M2Px는 모델 2를 통해 추론된 각 픽셀 의 클래스 x의 확률값이며, M3Px는 모델 3을 통해 추론된 각 픽셀의 클래스 x의 확률값이며, 모델 1 내지 3은 각 각 FCN, U-Net 및 DeepLab 모델을 나타냄. 또한, arg max f(x)는 f(x)를 최대로 만드는 x를 의미함) 상기 지적 분할부는, 설정된 윤곽선 검출 알고리즘을 통해 상기 정사 이미지 내 상기 영역에 대한 윤곽선을 추 출하고, 상기 윤곽선에 따라 분할된 각 영역 내 픽셀에 대응되는 클래스의 개수를 상기 각 영역별로 카운팅하며, 상기 각 영역별로 가장 많은 개수로 카운팅된 클래스를 상기 각 영역별 클래스로 결정하고, 상기 각 영역별 클래스에 따라 상기 정사 이미지 내 영역을 분할할 수 있다. 다른 예시적인 실시예에 따르면, 촬영 이미지 획득부에서, 위성 또는 무인 항공기로부터 촬영된 대상지역의 촬 영 이미지를 획득하는 단계; 정사 이미지 생성부에서, 상기 촬영 이미지의 특징점을 추출하는 단계; 상기 정사 이미지 생성부에서, 추출된 상기 특징점을 이용하여 상기 대상지역에 대한 정사 이미지를 생성하는 단계; 지적 분할부에서, 기 학습된 학습 데이터와 복수 개의 이미지 세그멘테이션 모델을 이용하여 상기 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론하는 단계; 상기 지적 분할부에서, 추론된 상기 각 픽셀별 클래스를 기반으 로 상기 정사 이미지 내 영역을 분할하는 단계; 및 후처리부에서, 상기 클래스별로 영역이 분할된 상기 정사 이 미지에 상기 대상지역에 대한 3차원 정보를 매핑시키는 단계를 포함하는, 인공지능 기반의 자동 지적 분할 방법 이 제공된다. 상기 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론하는 단계는, 상기 학습 데이터가 각각 학습된 복 수 개의 상기 이미지 세그멘테이션 모델이 결합되어 형성되는 앙상블 모델을 구비하며, 상기 앙상블 모델 내 각 이미지 세그멘테이션 모델에서 추론되는 각 픽셀별 클래스의 확률값을 기반으로 상기 정사 이미지 내 각 픽셀들 의 지적에 대한 클래스를 추론할 수 있다. 상기 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론하는 단계는, 상기 각 이미지 세그멘테이션 모델에 서 추론되는 각 픽셀별 클래스의 확률값을 획득하고, 상기 각 이미지 세그멘테이션 모델별 확률값에 대한 평균 치가 가장 높게 나타나는 클래스를 상기 각 픽셀별 클래스로 추론할 수 있다. 상기 각 이미지 세그멘테이션 모델은, FCN(Fully Convolution Network), U-Net 및 DeepLab 모델이며, 상기 각 픽셀별 클래스(Each segmented pixel class)는, 아래 수학식 1에 따라 계산될 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0096497", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "(여기서, M1Px는 모델 1을 통해 추론된 각 픽셀의 클래스 x의 확률값이며, M2Px는 모델 2를 통해 추론된 각 픽셀 의 클래스 x의 확률값이며, M3Px는 모델 3을 통해 추론된 각 픽셀의 클래스 x의 확률값이며, 모델 1 내지 3은 각 각 FCN, U-Net 및 DeepLab 모델을 나타냄. 또한, arg max f(x)는 f(x)를 최대로 만드는 x를 의미함) 상기 정사 이미지 내 영역을 분할하는 단계는, 설정된 윤곽선 검출 알고리즘을 통해 상기 정사 이미지 내 상기 영역에 대한 윤곽선을 추출하고, 상기 윤곽선에 따라 분할된 각 영역 내 픽셀에 대응되는 클래스의 개수를 상기 각 영역별로 카운팅하며, 상기 각 영역별로 가장 많은 개수로 카운팅된 클래스를 상기 각 영역별 클래스로 결정 하고, 상기 각 영역별 클래스에 따라 상기 정사 이미지 내 영역을 분할할 수 있다."}
{"patent_id": "10-2023-0096497", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들에 따르면, 기 학습된 학습 데이터와 복수 개의 이미지 세그멘테이션 모델을 이용하여 대상 지역에 대한 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론하고, 추론된 각 픽셀별 클래스를 기반으로 정사 이미지 내 영역을 자동으로 분할하도록 함으로써, 대상지역의 지적을 시간적, 공간적 제약 없이 빠르고 정 확하게 분할할 수 있다. 이에 따라, 기존 작업자들의 업무 비효율성을 해결할 수 있으며, 건설 및 토목 산업에 서의 혁신적인 패러다임 구축과 더불어 작업자들의 인력 감소에 대한 문제를 해결할 수 있다."}
{"patent_id": "10-2023-0096497", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 구체적인 실시형태를 설명하기로 한다. 이하의 상세한 설명은 본 명세서에서 기술된 방법, 장치 및/또는 시스템에 대한 포괄적인 이해를 돕기 위해 제공된다. 그러나 이는 예시에 불과하며 본 발명은 이에 제한되지 않는다. 본 발명의 실시예들을 설명함에 있어서, 본 발명과 관련된 공지기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하기로 한다. 그리고, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 상세한 설명에서 사용되 는 용어는 단지 본 발명의 실시예들을 기술하기 위한 것이며, 결코 제한적이어서는 안 된다. 명확하게 달리 사 용되지 않는 한, 단수 형태의 표현은 복수 형태의 의미를 포함한다. 본 설명에서, \"포함\" 또는 \"구비\"와 같은 표현은 어떤 특성들, 숫자들, 단계들, 동작들, 요소들, 이들의 일부 또는 조합을 가리키기 위한 것이며, 기술된 것 이외에 하나 또는 그 이상의 다른 특성, 숫자, 단계, 동작, 요소, 이들의 일부 또는 조합의 존재 또는 가능 성을 배제하도록 해석되어서는 안 된다. 도 1은 본 발명의 일 실시예에 따른 자동 지적 분할 시스템의 상세 구성을 나타낸 블록도이다. 도 1에 도 시된 바와 같이, 도 1은 본 발명의 일 실시예에 따른 자동 지적 분할 시스템은 촬영 이미지 획득부, 정사 이미지 생성부, 지적 분할부, 학습부, 데이터베이스, 후처리부 및 시각화부 를 포함한다. 본 실시예들에 있어서, 자동 지적 분할 시스템은 클라우드 환경에서 Saas(Software as a Service) 형태의 플랫폼으로 구축되며, 예를 들어 클라우드 서버의 일 구성으로 존재할 수 있다. 촬영 이미지 획득부는 위성 또는 무인 항공기로부터 촬영된 대상지역의 촬영 이미지를 획득한다. 본 실시 예들에 있어서, 대상지역은 지적 분할 대상이 되는 지역으로서, 예를 들어 도로, 농지, 건물 등이 포함된 지표 공간을 의미한다. 또한, 무인 항공기(UAV : Unmanned Aerial Vehicle)는 고정익 항공기, 회전익 항공기 등을 모 두 포함하는 넓은 의미로 사용되며, RGB 카메라, 멀티 스펙트럴(Multi-spectral) 카메라 등과 같은 광학장비를 구비할 수 있다. 촬영 이미지 획득부는 예를 들어, 사용자 단말(미도시)로부터 대상지역의 촬영 이미지를 다량으로 수집할 수 있다. 사용자는 자신이 소지하는 사용자 단말을 통해 대상지역의 촬영 이미지를 복수 개 업로드할 수 있다. 이때, 촬영 이미지 획득부에서 수집되는 촬영 이미지는 하나의 대상지역에 대해 서로 다른 위치 또는 각도 에서 촬영된 이미지일 수 있으며, RGB 픽셀정보, 촬영시간, 고도 등과 같은 메타 데이터를 포함하고 있을 수 있 다. 정사 이미지 생성부는 상기 촬영 이미지의 특징점을 추출하고, 추출된 상기 특징점을 이용하여 상기 대상 지역에 대한 정사 이미지(orthophotograph)를 생성한다. 정사 이미지란 지표면의 비고(比高)에 의하여 발생하는 사진 상의 각 점의 왜곡을 보정하여 동일 축척이 되도록 지도처럼 만든 이미지로서, 중앙 투영이 직교 투영으로 변환된 지형의 이미지이다. 정사 이미지 생성부는 각 촬영 이미지의 특징점을 추출한 후 특징점 매칭 알고 리즘을 통해 하나의 정사 이미지를 생성할 수 있다. 즉, 정사 이미지 생성부는 각 촬영 이미지 내 동일 지 점에 대한 특징점을 상호 매칭시켜 단일의 정사 이미지를 생성할 수 있다. 도 2는 본 발명의 일 실시예에 따른 2차원 정사 이미지 및 3차원 정사 이미지의 예시이다. 도 2의 (a)는 본 발 명의 일 실시예에 따른 2차원 정사 이미지를 나타내며, 도 2의 (b)는 본 발명의 일 실시예에 따른 3차원 정사 이미지를 나타낸다. 지적 분할부는 기 학습된 학습 데이터와 복수 개의 이미지 세그멘테이션 모델(Image Segmentation Model) 을 이용하여 상기 정사 이미지 내 각 픽셀들의 지적(地籍)에 대한 클래스(class)를 추론하고, 추론된 각 픽셀별 클래스를 기반으로 정사 이미지 내 영역을 분할한다. 이를 위해, 지적 분할부는 학습부와 연동하여 상기 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론할 수 있다. 여기서, 클래스는 대상지역 내 동일한 속성을 갖는 객체의 집합으로서, 예를 들어, 도로, 농지, 건물 등이 될 수 있다. 학습부는 네트워크(미도시)를 통해 지적 분할부와 연결되거나, 지적 분할부의 일 구성으로 존재 하여 후술할 앙상블 모델을 학습시킬 수 있다. 학습부는 다양한 예찰 지점에 대한 다량의 촬영 이미지를 학습 데이터로 확보하고, 상기 학습 데이터와 복수 개의 이미지 세그멘테이션 모델을 기반으로 앙상블 모델을 학습할 수 있다. 여기서, 이미지 세그멘테이션 모델은 예를 들어, FCN(Fully Convolution Network), U-Net 및 DeepLab 모델 등이 될 수 있다. 도 3은 본 발명의 일 실시예에 따른 학습부의 상세 구성을 나타낸 블록도이다. 도 3에 도시된 바와 같이, 본 발명의 일 실시예에 따른 학습부는 학습 데이터 수집 모듈, 학습 데이터 전처리 모듈, 학습 모듈 및 저장 모듈을 포함한다. 학습 데이터 수신 모듈은 앙상블 모델의 학습을 위한 다량의 학습 데이터를 수집한다. 여기서, 학습 데이 터는 위성 또는 무인 항공기로부터 촬영된 예찰 지점의 촬영 이미지, 및 상기 촬영 이미지 내 각 픽셀에 대한 클래스를 포함할 수 있다. 학습 데이터 수신 모듈은 다수의 사용자 단말로부터 다량의 촬영 이미지를 수집하고, 작업자로부터 상기 촬영 이미지 내 각 픽셀에 대한 클래스(즉, 라벨값)를 입력 받을 수 있다. 학습 데이터 전처리 모듈은 학습 데이터의 전처리를 수행한다. 여기서, 학습 데이터의 전처리는 예를 들어, 학습 데이터 내 촬영 이미지의 크기, 해상도, 색상, 명암 등을 조정하거나, 노이즈(noise) 또는 이상치 (outlier)를 제거하는 등의 작업일 수 있다. 또한, 학습 데이터 전처리 모듈은 학습 데이터 내 촬영 이미 지의 특징점을 추출하고, 추출된 특징점을 이용하여 촬영 이미지를 정사 이미지로 변환할 수 있다. 이 외에도, 학습 데이터 전처리 모듈은 기 알려진 다양한 전처리 알고리즘에 따라 학습 데이터의 전처리를 수행할 수 있다. 학습 모듈은 학습 데이터를 이용하여 앙상블 모델을 학습시킨다. 본 실시예들에 있어서, 앙상블 모델은 복 수 개의 이미지 세그멘테이션 모델이 결합된 모델로서, 각 이미지 세그멘테이션 모델에서 추론되는 각 픽셀별 클래스의 확률값을 기반으로 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론하도록 구성될 수 있다. 이 미지 세그멘테이션 모델은 예를 들어, 모델 1(예를 들어, FCN 모델), 모델 2(예를 들어, U-Net 모델) 및 모델 3(예를 들어, DeepLab 모델) 등이 될 수 있으며, 앙상블 모델은 모델 1 내지 모델 3이 결합된 모델일 수 있다. 이를 위해, 학습 모델은 상기 학습 데이터, 즉 촬영 이미지 및 상기 촬영 이미지 내 각 픽셀에 대한 클래 스를 앙상블 모델에 입력할 수 있다. 일 예시로서, 학습 모델은 상기 학습 데이터, 즉 촬영 이미지 및 상 기 촬영 이미지 내 각 픽셀에 대한 클래스를 모델 1 내지 모델 3에 각각 입력할 수 있다. 각 이미지 세그멘테이 션 모델에 입력되는 학습 데이터는 활성화 함수를 거친 후 라벨링된 결과에 대한 손실 함수(loss function)의 최적화 알고리즘을 거치게 된다. 이에 따라, 각 이미지 세그멘테이션 모델은 지적 분할의 기준이 되는 특징점 (feature)에 대한 가중치(weight)를 저장하게 된다. 이러한 최적의 가중치 도출을 위해 사용되는 최적화 알고리 즘은 예를 들어, 경사하강법(gradient descent)일 수 있다. 경사하강법은 예측값과 정답값 간의 차이인 손실 함 수의 크기를 최소화시키는 파라미터를 찾는 방식의 최적화 알고리즘으로서, 각 노드별 활성화 함수 내 가중치 또는 편향(bias)을 최적화시킬 수 있다. 이러한 최적화 과정은 에폭(epoch) 수만큼 반복 수행되며, 학습이 완료 되면 모델의 구조(graph), 학습된 가중치, 편향 등이 데이터베이스에 저장될 수 있다. 또한, 필요시 기 학 습된 각 이미지 세그멘테이션 모델에서 프루닝(pruning), 양자화(quantization), 증류(distillation) 등과 같 은 다양한 방법을 적용하여 경량화 가능하다. 저장 모듈은 수집된 학습 데이터, 즉 촬영 이미지와 라벨값을 데이터베이스에 저장한다. 또한, 저장 모듈은 학습된 각 이미지 세그멘테이션 모델의 구조, 가중치, 편향 등을 데이터베이스에 저장할 수 있다. 도 4는 본 발명의 일 실시예에 따른 지적 분할부의 상세 구성을 나타낸 블록도이다. 도 4에 도시된 바와 같이, 본 발명의 일 실시예에 따른 지적 분할부는 이미지 입력 모듈, 이미지 전처리 모듈, 추론 모듈, 분할 모듈 및 송신 모듈을 포함한다. 이미지 입력 모듈은 정사 이미지 생성부로부터 대상지역에 대한 정사 이미지를 입력 받는다. 상술한 바와 같이, 정사 이미지 생성부는 촬영 이미지의 특징점을 추출하고, 추출된 특징점을 이용하여 상기 대상 지역에 대한 정사 이미지를 생성할 수 있다. 정사 이미지 생성부는 이와 같이 생성된 정사 이미지를 이미 지 입력 모듈에 전달할 수 있다. 이미지 전처리 모듈은 입력된 정사 이미지를 전처리한다. 이미지 전처리 모듈은 예를 들어, 정사 이 미지의 크기, 해상도, 색상, 명암 등을 조정하거나, 노이즈 또는 이상치를 제거하는 등의 방식으로 정사 이미지 의 전처리를 수행할 수 있다. 추론 모듈은 학습 데이터와 복수 개의 이미지 세그멘테이션 모델을 이용하여 상기 정사 이미지 내 각 픽셀 들의 지적(地籍)에 대한 클래스를 추론한다. 추론 모듈은 상술한 학습부에서 학습된 앙상블 모델을 이용하여 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론할 수 있다. 구체적으로, 추론 모듈은 앙상블 모델 내 각 이미지 세그멘테이션 모델에서 추론되는 각 픽셀별 클래스의 확률값을 기반으로 상기 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론할 수 있다. 추론 모듈은 각 이미지 세그멘테이션 모델에서 추론되는 각 픽셀별 클래스의 확률값을 획득하고, 상기 각 이미지 세그멘테이 션 모델별 확률값에 대한 평균치가 가장 높게 나타나는 클래스를 상기 각 픽셀별 클래스로 추론할 수 있다. 상 술한 바와 같이, 각 이미지 세그멘테이션 모델은 예를 들어, 모델 1(예를 들어, FCN 모델), 모델 2(예를 들어, U-Net 모델) 및 모델 3(예를 들어, DeepLab 모델)일 수 있다. 일 예시로서, 추론 모듈은 모델 1 내지 모델 3에서 추론되는 각 픽셀별 클래스의 확률값을 획득하고, 각 모델별 확률값에 대한 평균치가 가장 높게 나타나는클래스를 각 픽셀별 클래스로 추론할 수 있다. 이러한 각 픽셀별 클래스(Each segmented pixel class)는, 아래 수학식 1에 따라 계산될 수 있다. 수학식 1"}
{"patent_id": "10-2023-0096497", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "(여기서, M1Px는 모델 1을 통해 추론된 각 픽셀의 클래스 x의 확률값이며, M2Px는 모델 2를 통해 추론된 각 픽셀 의 클래스 x의 확률값이며, M3Px는 모델 3을 통해 추론된 각 픽셀의 클래스 x의 확률값이며, 모델 1 내지 3은 각 각 FCN, U-Net 및 DeepLab 모델을 나타냄. 또한, arg max f(x)는 f(x)를 최대로 만드는 x를 의미함) 즉, 추론 모듈은 일 픽셀에서 (M1Px + M2Px + M3Px)/3 이 가장 높게 나타나는 x(예를 들어, 도로)를 해당 픽 셀의 클래스로 추론할 수 있다. 추론 모듈은 정사 이미지 내 각 픽셀에 대해 수학식 1을 계산할 수 있으며, 이에 따라 정사 이미지 내 각 픽셀별로 클래스를 아래 표 1과 같이 추론할 수 있다. 표 1 픽셀 추론된 클래스(x) 픽셀 1 도로 픽셀 2 농지 픽셀 3 건물 … … 분할 모듈은 추론된 각 픽셀별 클래스를 기반으로 정사 이미지 내 영역을 분할한다. 이를 위해, 분할 모듈 은 설정된 윤곽선 검출 알고리즘을 통해 정사 이미지 내 영역에 대한 윤곽선을 추출할 수 있다. 본 실시예 들에 있어서, 윤곽선 검출 알고리즘(Edge Detection Algorithm)은 예를 들어, Sobel, Prewitt, Canny, Roberts 알고리즘 등이 될 수 있다. 분할 모듈은 각종 윤곽선 검출 알고리즘을 이용하여 정사 이미지 내 영역에 대 한 윤곽선을 추출하고, 상기 윤곽선에 따라 분할된 각 영역 내 픽셀에 대응되는 클래스의 개수를 각 영역별로 카운팅할 수 있다. 각 영역별로 카운팅된 클래스의 개수를 나타내면 아래 표 2와 같다. 여기서, 윤곽선에 따라 분할된 영역 A, 영역 B, 영역 C는 각각 200개의 픽셀을 포함하는 것으로 가정한다. 표 2 영역 카운팅된 클래스의 개수 영역 A 도로 188번 / 농지 12번 영역 B 건물 194번 / 도로 6번 영역 C 농지 188번 /도로 2번 / 건물 10번 … … 이후, 분할 모듈은 각 영역별로 가장 많은 개수로 카운팅된 클래스를 각 영역별 클래스로 결정하고, 상기 각 영역별 클래스에 따라 정사 이미지 내 영역을 분할할 수 있다. 위 표 2의 예시에서, 분할 모듈은 영역 A의 클래스를 도로(188번)로 결정하고, 영역 B의 클래스를 건물(194번)로 결정하고, 영역 C의 클래스를 농지 (188번)로 결정할 수 있다. 이에 따라, 분할 모듈은 영역 A, 영역 B, 영역 C의 클래스에 따라 정사 이미지 를 영역 A, 영역 B, 영역 C 로 각각 분할할 수 있다. 송신 모듈은 이와 같이 추론된 각 픽셀별 클래스와 분할된 각 영역별 클래스에 관한 정보를 후처리부(11 2)로 전달한다. 도 5는 본 발명의 일 실시예에 따른 지적 분할부에서 각 픽셀별 클래스를 추론하고 이를 기반으로 정사 이 미지 내 영역을 분할하는 과정을 나타낸 도면이다. 도 5를 참조하면, 지적 분할부는 기 학습된 학습 데이터와 복수 개의 이미지 세그멘테이션 모델(모델 1, 모델 2, 모델 3)을 이용하여 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론하고, 추론된 각 픽셀별 클 래스를 기반으로 정사 이미지 내 영역을 분할할 수 있다. 상술한 바와 같이, 지적 분할부는 앙상블 모델 내 각 이미지 세그멘테이션 모델에서 추론되는 각 픽셀별 클래스의 확률값을 획득하고, 각 이미지 세그멘테이션 모델별 확률값에 대한 평균치가 가장 높게 나타나는 클래스를 각 픽셀별 클래스로 추론할 수 있다. 한편, 여기 서는 각 이미지 세그멘테이션 모델이 FCN, U-Net 및 DeepLab 모델인 것으로 가정하여 설명하였으나 이는 예시에 불과하며, 각 이미지 세그멘테이션의 종류 및 개수가 이에 한정되는 것은 아니다. 또한, 지적 분할부는 설정된 윤곽선 검출 알고리즘을 통해 정사 이미지 내 상기 영역에 대한 윤곽선을 추 출하고, 상기 윤곽선에 따라 분할된 각 영역 내 픽셀에 대응되는 클래스의 개수를 상기 각 영역별로 카운팅하며, 각 영역별로 가장 많은 개수로 카운팅된 클래스를 상기 각 영역별 클래스로 결정하고, 각 영역별 클래스에 따라 상기 정사 이미지 내 영역을 분할할 수 있다. 다시 도 1로 돌아오면, 후처리부는 클래스별로 영역이 분할된 정사 이미지에 대상지역에 대한 3차원 정보 를 매핑시킨다. 후처리부는 지적 분할부에서 도출된 정사 이미지에 대상지역에 대한 3차원 정보를 매 핑시킬 수 있다. 여기서, 대상지역에 대한 3차원 정보는 예를 들어, 대상지역의 3차원 DEM(Digital Elevation Models)일 수 있다. 후처리부는 GIS(Geographic Information System) 정보, GSD(Ground Sample Distance) 등을 기반으로 클래스별로 영역이 분할된 정사 이미지에 대상지역에 대한 3차원 정보를 매핑시킬 수 있다. 이때, 후처리부는 위경도 좌표를 기준으로 정사 이미지와 3차원 정보 간의 얼라인먼트를 맞춘 후, GSD를 기준으로 이를 수정, 변경할 수 있다. 시각화부는 대상지역의 촬영 이미지, 대상지역의 정사 이미지, 지적 분할부에서 클래스별로 영역이 분할된 정사 이미지, 후처리부에서 대상지역에 대한 3차원 정보가 매핑된 정사 이미지 등을 시각화하여 화 면에 표시한다. 시각화부는 관리자 또는 사용자의 요청에 따라 대상지역의 촬영 이미지, 대상지역의 정사 이미지, 지적 분할부에서 클래스별로 영역이 분할된 정사 이미지, 후처리부에서 대상지역에 대한 3차 원 정보가 매핑된 정사 이미지 중 적어도 하나를 시각화하여 관리자 단말 또는 사용자 단말에 제공할 수 있다. 도 6은 본 발명의 일 실시예에 따른 지적 분할부에 입력되기 전의 정사 이미지의 예시이며, 도 7은 본 발 명의 일 실시예에 따른 학습 데이터의 예시이고, 도 8은 본 발명의 일 실시예에 따른 지적 분할부에서 출 력되는 지적 분할 결과 이미지의 예시이다. 도 6을 참조하면, 지적 분할부에 입력되기 전의 정사 이미지는 도로, 농지, 임야 등으로 이루어져 있음을 확인할 수 있다. 도 7을 참조하면, 학습부에 입력되는 학습 데이터, 즉 라벨링된 데이터에는 도로, 농지, 임야 등이 서로 다른 색상(예를 들어, 검은색/짙은 회색/옅은 회색 등) 또는 명암으로 구분되어 있음을 확인할 수 있다. 도 8을 참조하면, 지적 분할부에서 출력되는 지적 분할 결과 이미지, 즉 클래스별로 영역이 분할된 정사 이미지에는 학습 데이터와 마찬가지로 도로, 농지, 임야 등이 서로 다른 색상 또는 명암으로 구분되어 있음을 확인할 수 있다. 이와 같이, 지적 분할부는 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론하고, 추론된 각 픽셀별 클래스를 기반으로 정사 이미지 내 영역을 분할할 후 서로 다른 색상 또는 명암으로 구분지을 수 있다. 도 9는 본 발명의 일 실시예에 따른 자동 지적 분할 방법을 설명하기 위한 흐름도이다. 도시된 흐름도에서는 상 기 방법을 복수 개의 단계로 나누어 기재하였으나, 적어도 일부의 단계들은 순서를 바꾸어 수행되거나, 다른 단 계와 결합되어 함께 수행되거나, 생략되거나, 세부 단계들로 나뉘어 수행되거나, 또는 도시되지 않은 하나 이상 의 단계가 부가되어 수행될 수 있다. S102 단계에서, 촬영 이미지 획득부는 위성 또는 무인 항공기로부터 촬영된 대상지역의 촬영 이미지를 획 득한다. S104 단계에서, 정사 이미지 생성부는 촬영 이미지의 특징점을 추출하고, 추출된 특징점을 이용하여 대상 지역에 대한 정사 이미지를 생성한다. S106 단계에서, 지적 분할부는 기 학습된 학습 데이터와 복수 개의 이미지 세그멘테이션 모델을 이용하여 정사 이미지 내 각 픽셀들의 지적에 대한 클래스를 추론한다. S108 단계에서, 지적 분할부는 추론된 각 픽셀별 클래스를 기반으로 정사 이미지 내 영역을 분할한다. S110 단계에서, 후처리부는 클래스별로 영역이 분할된 정사 이미지에 대상지역에 대한 3차원 정보를 매핑 시킨다. S112 단계에서, 시각화부는 대상지역의 촬영 이미지, 대상지역의 정사 이미지, 지적 분할부에서 클래 스별로 영역이 분할된 정사 이미지, 후처리부에서 대상지역에 대한 3차원 정보가 매핑된 정사 이미지 등을 시각화하여 화면에 표시한다. 도 10은 예시적인 실시예들에서 사용되기에 적합한 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하기 위한 블록도이다. 도시된 실시예에서, 각 컴포넌트들은 이하에 기술된 것 이외에 상이한 기능 및 능력을 가질 수 있고, 이하에 기술되지 않은 것 이외에도 추가적인 컴포넌트를 포함할 수 있다. 도시된 컴퓨팅 환경은 컴퓨팅 장치를 포함한다. 일 실시예에서, 컴퓨팅 장치는 자동 지적 분할 시 스템, 또는 자동 지적 분할 시스템에 포함되는 하나 이상의 컴포넌트일 수 있다. 컴퓨팅 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함한다. 프로세서는 컴퓨팅 장치로 하여금 앞서 언급된 예시적인 실시예에 따라 동작하도록 할 수 있 다. 예컨대, 프로세서는 컴퓨터 판독 가능 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있 다. 상기 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터 실 행 가능 명령어는 프로세서에 의해 실행되는 경우 컴퓨팅 장치로 하여금 예시적인 실시예에 따른 동작 들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다 른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능 저장 매체에 저장된 프로그램은 프로 세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시예에서, 컴퓨터 판독 가능 저장 매체는 메 모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이상의 자 기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 장치 에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능 저장 매체를 포함하여 컴퓨팅 장치의 다른 다양한 컴 포넌트들을 상호 연결한다. 컴퓨팅 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인터 페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 네트워 크 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치는 입출력 인터페이스를 통해 컴퓨팅 장치의 다른 컴포넌트들에 연결될 수 있다. 예시적인 입출력 장치는 포인팅 장치(마우스 또는 트랙패드 등), 키보드, 터치 입력 장치(터치패드 또는 터치스크린 등), 음성 또는 소리 입력 장치, 다양한 종류의 센서 장치 및/또는 촬영 장치와 같은 입력 장치, 및/또는 디스플레이 장치, 프린터, 스피커 및/또는 네트워크 카드와 같은 출력 장치를 포함할 수 있다. 예시적인 입출력 장치는 컴퓨팅 장치를 구성하는 일 컴포넌트로서 컴퓨팅 장치의 내부에 포함될 수도 있고, 컴퓨팅 장치와는 구별되는 별개의 장치로 컴퓨팅 장치와 연결될 수도 있다."}
{"patent_id": "10-2023-0096497", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상에서 대표적인 실시예를 통하여 본 발명에 대하여 상세하게 설명하였으나, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자는 전술한 실시예에 대하여 본 발명의 범주에서 벗어나지 않는 한도 내에서 다양한 변형 이 가능함을 이해할 것이다. 그러므로 본 발명의 권리범위는 설명된 실시예에 국한되어 정해져서는 안 되며, 후 술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 것들에 의해 정해져야 한다. 부호의 설명 100 : 자동 지적 분할 시스템 102 : 촬영 이미지 획득부 104 : 정사 이미지 생성부 106 : 지적 분할부 108 : 학습부 110 : 데이터베이스 112 : 후처리부 114 : 시각화부 202 : 학습 데이터 수집 모듈 204 : 학습 데이터 전처리 모듈 206 : 학습 모듈 208 : 저장 모듈 302 : 이미지 입력 모듈 304 : 이미지 전처리 모듈 306 : 추론 모듈 308 : 분할 모듈 310 : 송신 모듈"}
{"patent_id": "10-2023-0096497", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 자동 지적 분할 시스템의 상세 구성을 나타낸 블록도 도 2는 본 발명의 일 실시예에 따른 2차원 정사 이미지 및 3차원 정사 이미지의 예시 도 3은 본 발명의 일 실시예에 따른 학습부의 상세 구성을 나타낸 블록도 도 4는 본 발명의 일 실시예에 따른 지적 분할부의 상세 구성을 나타낸 블록도 도 5는 본 발명의 일 실시예에 따른 지적 분할부에서 각 픽셀별 클래스를 추론하고 이를 기반으로 정사 이미지 내 영역을 분할하는 과정을 나타낸 도면 도 6은 본 발명의 일 실시예에 따른 지적 분할부에 입력되기 전의 정사 이미지의 예시 도 7은 본 발명의 일 실시예에 따른 학습 데이터의 예시 도 8은 본 발명의 일 실시예에 따른 지적 분할부에서 출력되는 지적 분할 결과 이미지의 예시 도 9는 본 발명의 일 실시예에 따른 자동 지적 분할 방법을 설명하기 위한 흐름도 도 10은 예시적인 실시예들에서 사용되기에 적합한 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하기 위한 블록도"}
