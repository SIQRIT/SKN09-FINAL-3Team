{"patent_id": "10-2021-0043725", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0138512", "출원번호": "10-2021-0043725", "발명의 명칭": "모바일 기기에서의 음성 태깅을 이용한 영상 학습 및 인식 방법", "출원인": "이피엘코딩 주식회사", "발명자": "김영준"}}
{"patent_id": "10-2021-0043725", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라 영상 획득부가, 사용자로 부터 카메라 영상을 획득하는 단계;영상 특징벡터 추출부가, 상기 획득된 영상으로 부터 영상 특징벡터를 추출하는 단계;음성 획득부가, 사용자로 부터 음성을 수신하여 획득하는 단계;음성 특징벡터 추출부가, 상기 수신된 음성 데이터로 부터 음성 특징벡터를 추출하는 단계;음성 특징모델 사전 구성부가, 상기 추출된 음성 특징벡터로 부터 음성 특징모델 사전을 구성하는 단계;음성모델 식별자 추출부가, 상기 구성된 음성 특징모델 사전으로 부터 음성모델 식별자를 추출하는 단계;영상 지도 학습부가, 상기 음성모델 식별자 정보를 지도 레이블 정보로 활용하여 영상 특징벡터를 사전에 정의된 영상 지도 학습 방법으로 학습시키는 단계;를 포함하는 것을 특징으로 하는 영상 학습 방법."}
{"patent_id": "10-2021-0043725", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,음성 녹음 저장부가, 상기 추출된 음성모델 식별자를 식별정보로 하여 사용자의 음성 녹음 데이터를 사전에 정의된 저장소에 저장하는 단계;를 더 포함하는 것을 특징으로 하는 영상 학습 방법."}
{"patent_id": "10-2021-0043725", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "카메라 영상 획득부가, 사용자로 부터 카메라 영상을 획득하는 단계;영상 특징벡터 추출부가, 상기 획득된 영상으로 부터 영상 특징벡터를 추출하는 단계;영상 인식부가, 사전에 정의된 영상 지도 학습 및 인식 방법으로 상기 영상 특징벡터의 영상인식 결과를 추출하는 단계;음성 녹음 데이터 로드부가, 상기 영상인식 결과를 식별자로 하여 사용자의 음성 녹음 데이터를 사전에 정의된저장소로 부터 불러오는 단계;인식결과 재생부가, 불러온 상기 음성 녹음 데이터를 인식 결과로 재생하는 단계;를 포함하는 것을 특징으로 하는 영상 인식 방법."}
{"patent_id": "10-2021-0043725", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 모바일 기기에서의 영상 인식을 위한 학습 방법과 인식 방법에 관한 것으로 보다 상세하게는 음성 태 깅을 학습과 인식 단계에 사용하는 영상 학습 및 인식 방법에 관한 것이다. 본 발명은 모바일 기기에서의 음성 태깅을 이용하여 영상 학습 및 인식 단계에서 사용자가 화면상에 키보드 입력 (뒷면에 계속)"}
{"patent_id": "10-2021-0043725", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 모바일 기기에서의 영상 인식을 위한 학습 방법과 인식 방법에 관한 것으로 보다 상세하게는 음성 태 깅을 학습과 인식 단계에 사용하는 영상 학습 및 인식 방법에 관한 것이다."}
{"patent_id": "10-2021-0043725", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상인식은 서포트벡터 머신(SVM)이나 딥러닝 기술 등을 통해 많은 분야에서 횔용되고 있다. 최근에서는 글로벌 기업인 구글에서 티처블 머신(Teachable machine)과 같이 초보자도 바로 활용할 수 있는 영상인식용 프로그램을 배포하고 있는 상황이다. 특히 최근 들어 인공지능에 대한 관심이 늘면서 일선 초중고 교육기관에서도 인공지능 교육에 대한 관심이 늘고 있으며, 구글에서 배포하고 있는 초보자용 인공지능 SW를 초등학교에서도 수업에 적용하고 있다. 이러한 초보자용 인공지능 교육용 SW는 웹기반 기술로 되어 있으며, 텐서플로우와 같은 기존의 전문적인 툴에 비해 상당히 쉬워진 것은 사실이나, 학습 단계에서 PC 없이 모바일 기기를 활용하여 초보자가 간단한 체험활동 으로 하기에는 학습에 필요한 데이터를 손이나 키보드로 입력해야 하는 번거로움이 있어서, 사전 지식이 없는 초보자를 위한 체험 교육용으로 활용하기에는 현실적으로 많은 어려움이 따르고 있다. 또한 모바일 기기를 활용하는데 있어서 초보자가 모바일 기기의 카메라로 학습용 영상을 촬영하는 행위를 진행 함에 있어 영상 촬영과 키입력을 통한 데이터 입력 행위가 분리되고, 키보드 입력 행위를 통해 학습 데이터 정 보 입력시 사전에 촬용된 사진 데이터를 다시 선택해야 하는 등의 번거로운 과정을 필요로 하게 된다."}
{"patent_id": "10-2021-0043725", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "선행기술문헌 특허문헌 (특허문헌 0001) 한국 공개특허 제10-2015-0056160호(2015.05.26.공개) (특허문헌 0002) 한국 공개특허 제10-2013-0090012호(2013.08.13.공개) (특허문헌 0003) 한국 공개특허 제10-2017-0111161호(2017.10.12.공개) (특허문헌 0004) 한국 공개특허 제10-2015-0092390호(2015.08.13.공개) 비특허문헌"}
{"patent_id": "10-2021-0043725", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 위와 같은 문제점을 해결하기 위한 발명으로, 발명에서 해결하고자 하는 과제는 모바일 기기에서의 음성 태깅을 이용하여 영상 학습 및 인식 단계에서 사용자가 화면상에 키보드 입력을 통해 값을 입력하는 과정 을 없애고 카메라 촬영과 음성만으로 영상 학습을 수행하고 인식 단계에서 이를 활용하는 방법을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2021-0043725", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "위와 같은 문제를 해결하기 위한 본 발명에 따른 영상 학습 및 인식 방법은, 카메라 영상 획득부가, 사용자로 부터 카메라 영상을 획득하는 단계, 영상 특징벡터 추출부가, 상기 획득된 영상으로 부터 영상 특징벡터를 추출 하는 단계, 음성 획득부가, 사용자로 부터 음성을 수신하여 획득하는 단계, 음성 특징벡터 추출부가, 상기 수신 된 음성 데이터로 부터 음성 특징벡터를 추출하는 단계, 음성 특징모델 사전 구성부가, 상기 추출된 음성 특징 벡터로 부터 음성 특징모델 사전을 구성하는 단계, 음성모델 식별자 추출부가, 상기 구성된 음성 특징모델 사전 으로 부터 음성모델 식별자를 추출하는 단계, 영상 지도 학습부가, 상기 음성모델 식별자 정보를 지도 레이블 정보로 활용하여 영상 특징벡터를 사전에 정의된 영상 지도 학습 방법으로 학습시키는 단계를 포함하는 것에 기 술적 특징이 있다. 또한 본 발명에 따른 영상 학습 및 인식 방법은, 상기 기술한 과정에 추가적으로, 음성 녹음 저장부가, 상기 추 출된 음성모델 식별자를 식별정보로 하여 사용자의 음성 녹음 데이터를 사전에 정의된 저장소에 저장하는 단계 를 더 포함할 수 있다. 또한 본 발명에 따른 영상 학습 및 인식 방법은, 카메라 영상 획득부가, 사용자로 부터 카메라 영상을 획득하는 단계, 영상 특징벡터 추출부가, 상기 획득된 영상으로 부터 영상 특징벡터를 추출하는 단계, 사전에 정의된 영 상 지도 학습 및 인식 방법으로 상기 영상 특징벡터의 영상인식 결과를 추출하는 단계, 상기 영상인식 결과를 식별자로 하여 사용자의 음성 녹음 데이터를 사전에 정의된 저장소로 부터 불러오는 단계, 불러온 상기 음성 녹 음 데이터를 인식 결과로 재생하는 단계를 포함하는 것에 기술적 특징이 있다."}
{"patent_id": "10-2021-0043725", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 음성 태깅을 이용한 영상 학습 및 인식 방법은 키보드 입력이 불편한 모바일 기기에서 사용자가 모바일 기기의 카메라 촬영 행위를 유지하면서 음성 태깅으로 학습에 필요한 데이터를 제공하여, 영상 인식의 과정을 촬영과 동시에 간단하고 쉽게 끝낼 수 있도록 지원함으로써 초보자가 영상인식 기술을 쉽고 편리하게 이 용할 수 있도록 한다."}
{"patent_id": "10-2021-0043725", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명 의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 각 도면을 설명하면서 유사한 참조부호를 유사한 구성요소에 대해 사용하였다. 본 발명을 설명함에 있어서 관련 된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략 한다. 제1, 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용 된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하 게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목 을 포함한다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 영상 학습 및 인식 방법에 대해 구체적으로 살펴본다. 도 1은 본 발명에 따른 음성 태깅 정보를 활용하는 영상 학습 방법의 순서도이다. 도 1을 참조하면 본 발명의 일 실시예에 따른 음성 태깅 정보를 활용하는 영상 학습 방법은 카메라 영상 획득부 가, 사용자로 부터 카메라 영상을 획득하는 단계(S100); 영상 특징벡터 추출부가, 상기 획득된 영상으로 부터 영상 특징벡터를 추출하는 단계(S200); 음성 획득부가, 사용자로 부터 음성을 수신하여 획득하는 단계(S300); 음성 특징벡터 추출부가, 상기 수신된 음성 데이터로 부터 음성 특징벡터를 추출하는 단계(S400); 음성 특징모 델 사전 구성부가, 상기 추출된 음성 특징벡터로 부터 음성 특징모델 사전을 구성하는 단계(S500); 음성모델 식 별자 추출부가, 상기 구성된 음성 특징모델 사전으로 부터 음성모델 식별자를 추출하는 단계(S600); 영상 지도 학습부가, 상기 음성모델 식별자 정보를 지도 레이블 정보로 활용하여 영상 특징벡터를 사전에 정의된 영상 지 도 학습 방법으로 학습시키는 단계(S700);를 포함하여 구성될 수 있다. 사용자는 카메라가 부착된 모바일 기기를 이용하여 영상인식을 위한 학습 과정을 시작하면, 카메라의 촬영 영상 이 화면에 표시되며, 화면 터치 또는 화면에 제시되는 화면 캡처 버튼을 이용해 학습에 필요한 영상을 획득하는 단계(S100)를 시작하게 된다. 영상이 획득되면, SIFT(Scale Invariant Feature Transform) 또는 ORB(Oriented FAST and Rotated BIRIEF) 등 통상적으로 영상 인식에서 활용되는 키포인트 특징 추출과 디스크립터(Descriptor) 알고리즘을 이용하여 영상 특징 벡터를 추출한다(S200). 사용자는 캡처된 영상에 대해 식별정보를 음성으로 전달하게 되며, 사용자로 부터 음성을 수신하여 음성 데이터 를 획득하는 과정을 수행한다(S300). 예를 들어 사용자는 사과을 촬영하면서 캡처 버튼을 클릭한 후, \"사과\" 라는 단어를 음성으로 말하고, 음성 획 득부가 이 데이터를 수신하여 획득한다. 수신된 음성 데이터로 부터 MFCC(Mel-Frequency Cepstral Coefficient)등 통상적으로 음성인식에서 사용되는 특징벡터 추출 알고리즘을 이용하여 음성 특징벡터를 추출한다(S400). 상기 단계를 통해 추출된 음성 특징벡터 값은 동일한 객체의 영상에 대해서도 미세한 차이가 있으므로, 클러스 터링 과정을 거처 음성 특징 모델 사전으로 구축한다(S500). 구축된 음성 특징 모델은 모델을 대표하는 식별자 또는 식별키를 가지며, 이때 추출된 식별자 (ㄴ600) 또는 식 별키를 영상 인식 과정에서 비도 학습용 레이블 값으로 활용한다(S700) 통상적으로 영상인식용 지도 학습을 진행할 경우에는 영상 정보에 영상이 어떠한 객체인지를 알려주는 레이블 정보를 제시한 후, 해당 레이블 정보에 영상이 매칭되도록 학습을 시키는데, 본 발명에서는 이러한 레이블 정보 를 사용자의 음성 파일에서 추출한 음성 특징벡터의 식별자 값으로 활용하는 것이 특징이다. 도 2를 참조하여 본 발명의 일 실시예에 따른 음성 태깅 정보를 활용하는 영상 학습 방법에서, 도 1에 표기된 과정에, 상기 추출된 음성모델 식별자를 식별정보로 하여 사용자의 음성 녹음 데이터를 사전에 정의된 저장소에 저장하는 단계;를 더 포함할 수 있다. 사용자의 음성 녹음 파일을 음성모델 식별자와 함께 같이 저장하는 이유는 추후 영상 인식 단계에서 인식 결과 를 사용자가 녹음한 음성 파일을 재생시키기 위함이다. 도 3은 본 발명에 따른 음성 태깅 정보를 활용하는 영상 인식 방법의 순서도이다. 도 3을 참조하면 본 발명의 일 실시예에 따른 음성 태깅 정보를 활용하는 영상 인식 방법은 카메라 영상 획득부 가, 사용자로 부터 카메라 영상을 획득하는 단계(S100); 영상 특징벡터 추출부가, 상기 획득된 영상으로 부터 영상 특징벡터를 추출하는 단계(S200); 영상 인식부가, 사전에 정의된 영상 지도 학습 및 인식 방법으로 상기 영상 특징벡터의 영상인식 결과를 추출하는 단계(S800); 음성 녹음 데이터 로드부가, 상기 영상인식 결과를 식 별자로 하여 사용자의 음성 녹음 데이터를 사전에 정의된 저장소로 부터 불러오는 단계(S850); 인식결과 재생부 가, 불러온 상기 음성 녹음 데이터를 인식 결과로 재생하는 단계(S900);를 포함하여 구성될 수 있다. 영상 학습 단계가 끝난 후, 영상 인식 단계에서는 SVM(Support Vector Machine) 딥러닝 등의 통상적으로 많이 사용되는 영상인식 방법을 통해 영상인식을 수행한다(S800).영상의 인식 결과로서 사용자의 음성 특징벡터에 대한 모델 식별자 값을 알 수 있으며, 이 식별자를 이용하여 사전에 정의된 저장소 저장된 녹음 파일을 로드한다(S850). 인식 결과를 사용자에게 제시하는데 있어서, 사용자가 학습에 사용하였던 녹음 파일 재생시켜 (S900) 사용자가 직관적으로 영상의 학습과 인식의 결과를 확인할 수 있도록 한다."}
{"patent_id": "10-2021-0043725", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 음성 태깅 정보를 활용하는 영상 학습 방법의 순서도 도 2는 본 발명에 따라 음성 녹음 파일의 저장 단계가 추가된 영상 학습 방법의 순서도 도 3은 본 발명에 따라 영상 인식을 수행한 후, 인식된 결과로 사용자의 녹음 음성을 재생하는 영상 인식 방법 의 순서도"}
