{"patent_id": "10-2022-7038781", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0164573", "출원번호": "10-2022-7038781", "발명의 명칭": "딥 러닝 가속기 및 랜덤 액세스 메모리를 구비한 칩 상의 시스템", "출원인": "마이크론 테크놀로지, 인크.", "발명자": "케일, 푸르나"}}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디바이스에 있어서,기판을 포함하고 상기 디바이스를 포함하는 집적 회로 패키지;상기 기판 상에 구성된 중앙 처리 유닛;상기 기판 상에 구성되고 행렬 피연산자들을 갖는 명령어들을 실행시키도록 구성된 적어도 하나의 처리 유닛;상기 기판을 통해 상기 적어도 하나의 처리 유닛 및 상기 중앙 처리 유닛에 결합되고,인공 신경망의 행렬들;상기 인공 신경망을 구현하기 위해 상기 적어도 하나의 처리 유닛에 의해 실행 가능한 명령어들; 및상기 중앙 처리 유닛에 의한 실행을 위해 프로그래밍된 적어도 하나의 애플리케이션을 저장하도록 구성된 랜덤액세스 메모리; 및상기 기판을 통해 상기 중앙 처리 유닛 및 상기 랜덤 액세스 메모리에 결합되고 상기 디바이스 외부에 있는 버스에 결합 가능한 인터페이스를 포함하는, 디바이스."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 기판에 부착된 인터포저(interposer)를 더 포함하며, 상기 중앙 처리 유닛은 상기 인터포저를 통해, 상기적어도 하나의 처리 유닛 또는 상기 랜덤 액세스 메모리 또는 둘 모두에 결합되는, 디바이스."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 적어도 하나의 처리 유닛은 상기 애플리케이션으로의 입력으로서 상기 인공 신경망으로부터의 출력을 상기 랜덤 액세스 메모리에 저장하도록 구성되고; 상기 중앙 처리 유닛은 상기 애플리케이션의 실행 동안 할당된 논리적 메모리를 상기 랜덤 액세스 메모리의 물리적 메모리에 매핑하도록 구성된 메모리 제어기를 포함하는, 디바이스."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 메모리 제어기는, 상기 중앙 처리 유닛과 상기 랜덤 액세스 메모리 사이의 제1 연결부를통해, 상기 적어도 하나의 처리 유닛에 의한 실행을 위해 랜덤 액세스 메모리로부터 제1 명령어들을 로드하도록구성되는, 디바이스."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 적어도 하나의 처리 유닛은, 제2 연결부를 통해 상기 랜덤 액세스 메모리에, 상기 랜덤액세스 메모리로부터의 행렬 피연산자들을 로드하도록 구성되는, 디바이스."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서, 상기 중앙 처리 유닛은 적어도 하나의 산술 로직 유닛(ALU)을 포함하고; 상기 메모리제어기는, 상기 중앙 처리 유닛과 상기 랜덤 액세스 메모리 사이의 상기 제1 연결부를 통해, 상기 적어도 하나의 ALU에 의한 실행을 위해 랜덤 액세스 메모리로부터 제2 명령어들을 로드하도록 구성되는, 디바이스."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,공개특허 10-2022-0164573-3-상기 적어도 하나의 처리 유닛, 제어 유닛, 행렬 피연산자들을 저장하도록 구성된 로컬 메모리, 및 상기 랜덤액세스 메모리에 대한 메모리 인터페이스를 갖는 딥 러닝 가속기가 구성된 제1 집적 회로 다이; 및상기 랜덤 액세스 메모리가 구성된 적어도 하나의 제2 집적 회로 다이를 더 포함하는, 디바이스."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 중앙 처리 유닛이 구성된 제3 집적 회로 다이를 더 포함하며,상기 메모리 인터페이스는 실리콘 관통 비아들(TSV들)에 의해 상기 적어도 하나의 제2 집적 회로 다이의 상기랜덤 액세스 메모리에 연결되고;상기 중앙 처리 유닛은 상기 실리콘 관통 비아들(TSV들)에 의해 상기 적어도 하나의 제2 집적 회로 다이의 상기랜덤 액세스 메모리에 연결되고;상기 적어도 하나의 제2 집적 회로 다이는 상기 제1 집적 회로 다이와 상기 제2 집적 회로 다이 사이에 적층되는, 디바이스."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 중앙 처리 유닛은 상기 제1 집적 회로 상에 구성되고; 상기 중앙 처리 유닛 및 상기 딥러닝 가속기는 상기 랜덤 액세스 메모리에 대한 인터페이스를 공유하는, 디바이스."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 중앙 처리 유닛 및 상기 딥 러닝 가속기는 상기 랜덤 액세스 메모리로부터 명령어들을 로딩하기 위한 로직 회로를 더 공유하는, 디바이스."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,와이어들이 구성된 제4 집적 회로 다이를 더 포함하며,상기 제1 집적 회로 다이의 상기 딥 러닝 가속기 및 상기 적어도 제2 집적 회로 다이의 상기 랜덤 액세스 메모리는 상기 제4 집적 회로 다이의 상기 와이어들 및 상기 제4 집적 회로 다이로부터의 실리콘 관통비아들(TSV들)을 사용하여 연결되는, 디바이스."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 중앙 처리 유닛이 구성된 제3 집적 회로 다이를 더 포함하며,상기 제1 집적 회로 다이, 상기 적어도 제2 집적 회로 다이 및 상기 제3 집적 회로 다이는 상기 제4 집적 회로다이 상에 적층되고 별도의 실리콘 관통 비아(TSV) 세트를 사용하여 상기 제4 집적 회로에 연결되는, 디바이스."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 인터페이스의 회로는 상기 버스에 대한 신호들을 처리하기 위해 상기 제4 집적 회로 다이 상에 구성되고; 상기 버스는 범용 직렬 버스(USB), 직렬 고급 기술 결합(SATA) 버스 또는 주변 컴포넌트 상호접속 익스프레스(PCIe)의 프로토콜에 따르는, 디바이스."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제7항에 있어서, 상기 적어도 하나의 처리 유닛은 명령어의 두 개의 행렬 피연산자들을 동작시키도록 구성된 행렬-행렬 유닛을 포함하며,상기 행렬-행렬 유닛은 병렬로 동작하도록 구성된 복수의 행렬-벡터 유닛들을 포함하고;상기 복수의 행렬-벡터 유닛들 각각은 병렬로 동작하도록 구성된 복수의 벡터-벡터 유닛들을 포함하고;공개특허 10-2022-0164573-4-상기 복수의 벡터-벡터 유닛들 각각은 병렬로 동작하도록 구성된 복수의 곱셈 누산 유닛들을 포함하는, 디바이스."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "방법에 있어서,집적 회로 디바이스에 구현된 랜덤 액세스 메모리에,인공 신경망의 행렬들,상기 행렬들을 사용하여 상기 인공 신경망을 구현하기 위해 상기 집적 회로 디바이스 내에 포함된 적어도 하나의 처리 유닛에 의해 실행 가능한 제1 명령어들, 및상기 집적 회로 디바이스 내에 포함된 중앙 처리 유닛에 의한 실행을 위해 프로그래밍된 적어도 하나의 애플리케이션의 제2 명령어들을 저장하는 단계;상기 집적 회로 디바이스 외부에 있는 버스에 결합 가능한 상기 집적 회로 디바이스의 인터페이스를 통해, 상기인공 신경망으로의 입력으로 상기 랜덤 액세스 메모리에 센서 데이터를 로딩하는 단계;상기 적어도 하나의 처리 유닛에 의해, 상기 입력에 기초하여 상기 인공 신경망으로부터의 출력을 생성하도록하는 상기 제1 명령어들을 실행시키는 단계;상기 랜덤 액세스 메모리에, 상기 인공 신경망으로부터의 상기 출력을 저장하는 단계; 및상기 중앙 처리 유닛에 의해, 상기 인공 신경망으로부터의 출력을 사용하는 상기 적어도 하나의 애플리케이션의상기 제2 명령어들을 실행시키는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 집적 회로 디바이스는 집적 회로 패키지 내에 포함되고 처리 유닛들, 제어 유닛 및 로컬메모리를 구비한 딥 러닝 가속기를 가지며; 상기 처리 유닛들은 두 개의 행렬 피연산자들을 갖는 명령어를 실행하도록 구성된 적어도 행렬-행렬 유닛을 포함하고; 상기 행렬-행렬 유닛은 병렬로 동작하도록 구성된 복수의 행렬-벡터 유닛들을 포함하고; 상기 행렬-벡터 유닛들 각각은 병렬로 동작하도록 구성된 복수의 벡터-벡터 유닛들을 포함하고; 상기 벡터-벡터 유닛들 각각은 병렬로 동작하도록 구성된 복수의 곱셈 누산 유닛들을 포함하는,방법."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 딥 러닝 가속기는 상기 중앙 처리 유닛이 상기 제2 명령어들을 실행하는 것과 병렬로 상기 제1 명령어들을 실행시키는, 방법."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서, 상기 딥 러닝 가속기에 의한 상기 제1 명령어들의 실행은 상기 중앙 처리 유닛에서 실행된 루틴에 대한 호출을 포함하는, 방법."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "장치에 있어서,랜덤 액세스 메모리;적어도 하나의 산술 로직 유닛(ALU)을 갖는 중앙 처리 유닛;딥 러닝 가속기에 실행 가능한 명령어의 두 개의 행렬 피연산자들에서 동작하도록 구성된 적어도 하나의 처리유닛을 갖는 상기 딥 러닝 가속기;주변 버스에 연결되도록 구성된 인터페이스를 포함하며,상기 장치는 상기 인터페이스를 사용하여 상기 주변 버스로부터 센서 데이터를 수신하고, 상기 센서 데이터를상기 딥 러닝 가속기에서 실행된 제1 명령어들에 대한 입력으로서 저장하고, 상기 제1 명령어의 실행으로부터생성된 출력을 상기 중앙 처리 유닛에서 실행된 애플리케이션으로의 입력으로서 상기 랜덤 액세스 메모리에 저공개특허 10-2022-0164573-5-장하도록 구성되는, 장치."}
{"patent_id": "10-2022-7038781", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 랜덤 액세스 메모리는 인공 신경망의 모델 데이터를 저장하도록 구성된 비휘발성 메모리를 포함하고; 상기 모델 데이터는 상기 딥 러닝 가속기에 의해 실행 가능한 상기 제1 명령어들을 포함하고; 상기 중앙 처리 유닛 및 상기 딥 러닝 가속기는 병렬로 동작하도록 구성되는, 장치."}
{"patent_id": "10-2022-7038781", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "딥 러닝 가속기 및 메모리와 관련된 시스템들, 디바이스들 및 방법들이 설명된다. 집적 회로는 중앙 처리 유닛, 행렬 피연산자들을 갖는 명령어들을 실행시키도록 구성된 딥 러닝 가속기; 상기 딥 러닝 가속기에 의해 실행 가 능한 인공 신경망의 제1 명령어들 및 중앙 처리 유닛에 의해 실행 가능한 애플리케이션의 제2 명령어들을 저장하 도록 구성된 랜덤 액세스 메모리; 랜덤 액세스 메모리 사이의 하나 이상의 연결부들, 딥 러닝 가속기 및 중앙 처 리 유닛; 및 외부 주변 버스에 대한 입/출력 인터페이스로 구성될 수 있다. 딥 러닝 가속기가 인공 신경망에 따 른 센서 데이터를 추론 결과들로 변환하도록 하는 제1 명령어들을 실행시키는 동안, 중앙 처리 장치는 인공 신경 망으로부터의 추론 결과들을 사용하는 애플리케이션을 실행시킬 수 있다."}
{"patent_id": "10-2022-7038781", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원 본 출원은 2020년 4월 9일자로 출원되고 \"SYSTEM ON A CHIP WITH DEEP LEARNING ACCELERATOR AND RANDOM ACCESS MEMORY\"이라는 명칭의 미국 특허 출원 일련 번호 제16/845,002호에 대한 우선권을 주장하며, 그 전체 개 시 내용은 본원에 참조로서 통합된다."}
{"patent_id": "10-2022-7038781", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "기술분야 본원에 개시된 적어도 일부 실시예들은 일반적으로 집적 회로 디바이스들에 관한 것으로, 보다 구체적으로는, 이에 제한되는 것은 아니나, 기계 학습 및/또는 딥 러닝을 통해 구성된 ANN들과 같은 인공 신경망(Artificial Neural Network; ANN)용 가속기들을 갖는 집적 회로 디바이스들에 관한 것이다."}
{"patent_id": "10-2022-7038781", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 신경망(ANN)은 뉴런들의 네트워크를 사용하여 네트워크로의 입력들을 처리하고 네트워크로부터의 출력들을 생성한다. 예를 들어, 네트워크의 각 뉴런은 입력 세트를 수신한다. 뉴런으로의 입력들 중 일부는 네트워크에 있는 특정 뉴런들의 출력들일 수 있으며; 뉴런으로의 입력들 중 일부는 신경망에 제공된 입력들일 수 있다. 네트워크의 뉴 런들 간의 입/출력 관계는 네트워크의 뉴런 연결성을 나타낸다. 예를 들어, 각 뉴런은 입력들에 대한 바이어스, 활성화 함수 및 시냅스 가중치 세트를 각각 가질 수 있다. 활성 화 함수는 계단 함수, 선형 함수, 로그-시그모이드(log-sigmoid) 함수 등의 형태일 수 있다. 네트워크의 다른 뉴런들은 다른 활성화 함수들을 가질 수 있다. 예를 들어, 각 뉴런은 입력들과 바이어스의 가중 합을 생성한 다음 뉴런의 활성화 함수를 사용하여 계산된 가중 합의 함수인 출력을 생성할 수 있다. 일반적으로 ANN의 입력(들)과 출력(들) 사이의 관계는 각 뉴런의 바이어스, 활성화 함수 및 시냅스 가중치들뿐 만 아니라 네트워크의 뉴런들의 연결성을 나타내는 데이터를 포함하는 ANN 모델에 의해 정의된다. 주어진 ANN 모델에 기초하여, 컴퓨팅 디바이스는 네트워크로의 주어진 입력 세트로부터 네트워크의 출력(들)을 계산하도록 구성될 수 있다. 예를 들어, ANN 네트워크로의 입력들은 카메라 입력들에 기초하여 생성될 수 있으며; ANN 네트워크로부터의 출 력들은 이벤트 또는 객체와 같은 아이템(item)의 식별일 수 있다. 일반적으로, ANN은 ANN의 파라미터들이 각각의 입력들과 관련되거나 그 결과로 인해 발생하는 알려진 출력들과 입력들을 ANN에 적용하여 생성된 계산된 출력들 사이의 에러를 최소화하거나 줄이기 위해 조정되는 지도 방법 (supervised method)을 사용하여 훈련될 수 있다. 지도 학습/훈련 방법들의 예들은 강화 학습 및 에러 정정이 있는 학습을 포함한다. 대안적으로 또는 조합하여, ANN은 훈련이 완료되기 전에 주어진 입력 세트에서 나온 정확한 출력들이 알려지지 않은 비지도 방법(unsupervised method)을 사용하여 훈련될 수 있다. ANN은 아이템을 복수의 카테고리들로 분류 하거나, 데이터 지점들을 클러스터들로 분류하도록 훈련될 수 있다. 정교한 기계 학습/훈련 패러다임을 위해 다수의 훈련 알고리즘들이 사용될 수 있다. 딥 러닝은 다층의 기계 학습을 사용하여 입력 데이터에서 특징들을 점진적으로 추출한다. 예를 들어, 하위 레이 어들은 이미지의 에지들을 식별하도록 구성할 수 있으며; 상위 레이어들은 하위 레이어들을 사용하여 검출된 에 지들에 기초하여 얼굴, 객체, 이벤트 등과 같은 이미지에서 캡처된 아이템들을 식별하도록 구성될 수 있다. 딥 러닝은 심층 신경망, 심층 신념 네트워크, 순환 신경망 및/또는 컨볼루션 신경망과 같은 인공 신경망들(ANN들) 을 통해 구현될 수 있다. 딥 러닝은 컴퓨터 비전, 음성/음성 인식, 자연어 처리, 기계 번역, 생물 정보학, 약물 설계, 의료 영상 처리, 게임 등과 같은 많은 응용 분야에 적용되었다."}
{"patent_id": "10-2022-7038781", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본원에 개시된 적어도 일부 실시예들은 감소된 에너지 소비 및 계산 시간으로 인공 신경망들(ANN들)의 계산들을 수행하도록 구성된 범용 집적 회로 디바이스를 제공한다. 집적 회로 디바이스는 딥 러닝 가속기(Deep Learning Accelerator; DLA) 및 랜덤 액세스 메모리를 포함한다. 집적 회로 디바이스는 랜덤 액세스 메모리에 대한 동시 액세스를 위해 별도의 연결부들로 구성될 수 있다. 집적 회로 디바이스는 집적 회로 디바이스에 구현된 인공 신 경망(ANN)으로의 입력으로서 하나 이상의 카메라들로부터 직접 이미지 데이터를 수신하도록 구성된 카메라 인터 페이스를 가질 수 있다. 또한, 집적 회로 디바이스는 칩 상에 시스템을 형성하기 위해 중앙 처리 유닛을 포함할 수 있다. 딥 러닝 가속기(DLA)는 이에 제한되는 것은 아니나 벡터 및/또는 행렬의 곱셈 및 누산을 포함하는, 병렬 벡터 및/또는 행렬 계산들을 수행하도록 특화 및/또는 최적화된 범용 프로그래밍 가능한 하드웨어 컴퓨팅 로직 세트 를 포함한다. 또한 딥 러닝 가속기(DLA)는 정수 이진수에 대한 산술 및 비트단위 연산들을 수행하기 위해 하나 이상의 산술- 로직 유닛(Arithmetic-Logic Unit; ALU)들을 포함할 수 있다. 딥 러닝 가속기(DLA)는 인공 신경망(ANN)의 계산들을 수행하기 위한 일련의 명령어 세트를 통해 프로그래밍할 수 있다. 벡터들 및 행렬들에서 동작하는 딥 러닝 가속기(DLA)의 세분성(granularity)은 딥 러닝 가속기(DLA)에 의해 하 나의 명령어를 실행하는 동안 동작될 수 있는 벡터들/행렬들의 가장 큰 단위에 해당한다. 벡터/행렬 피연산자들 에 대한 사전 정의된 연산에 대한 명령어를 실행하는 동안, 벡터/행렬 피연산자들의 요소들은 딥 러닝 가속기 (DLA)에 의해 병렬로 동작되어 메모리/데이터 액세스와 관련된 실행 시간 및/또는 에너지 소비를 줄일 수 있다.딥 러닝 가속기(DLA)의 세분성의 벡터/행렬 피연산자들에 대한 연산들은 더 큰 크기의 벡터들/행렬들에 대한 계 산들을 구현하기 위한 빌딩 블록들로 사용될 수 있다. 일반적인/실용적인 인공 신경망(ANN)의 구현은 딥 러닝 가속기(DLA)의 연산 세분성보다 더 큰 크기들을 갖는 벡 터/행렬 피연산자들을 포함한다. 딥 러닝 가속기(DLA)를 사용하여 이러한 인공 신경망(ANN)을 구현하기 위해, 큰 크기의 벡터/행렬 피연산자들을 포함하는 계산들은 딥 러닝 가속기(DLA)의 세분성의 벡터/행렬 피연산자들의 계산들로 나눌 수 있다. 딥 러닝 가속기(DLA)는 명령어들을 통해 프로그래밍되어 큰 벡터/행렬 피연산자들을 포 함하는 계산들을 수행할 수 있다. 예를 들어, 명령어들에 대한 응답으로 딥 러닝 가속기(DLA)의 세분성의 벡터 들 및 행렬들을 조작 시 딥 러닝 가속기(DLA)의 원자 계산 능력들은 인공 신경망(ANN)에서 계산들을 구현하도록 프로그래밍될 수 있다. 일부 구현들에서, 딥 러닝 가속기(DLA)는 일반적인 중앙 처리 유닛(CPU)의 일부 로직 연산 능력들이 부족하다. 그러나 딥 러닝 가속기(DLA)는 인공 신경망(ANN)에 제공되는 입력 데이터를 처리하고 딥 러닝 가속기(DLA)에 대 해 생성된 명령어 세트에 따라 인공 신경망(ANN)의 출력을 생성하기에 충분한 로직 유닛들로 구성될 수 있다. 따라서, 딥 러닝 가속기(DLA)는 중앙 처리 유닛(CPU) 또는 다른 프로세서로부터의 도움을 거의 받지 않거나 전 혀 받지 않고 인공 신경망(ANN)의 계산을 수행할 수 있다. 선택적으로, 기존 범용 프로세서는 또한 딥 러닝 가 속기(DLA)의 일부로 구성되어 딥 러닝 가속기(DLA)의 벡터/행렬 처리 유닛들을 사용하여 효율적으로 구현될 수 없고/없거나 딥 러닝 가속기(DLA)의 벡터/행렬 처리 유닛들에 의해 수행될 수 없는 연산들을 수행할 수 있다. 일반적인 인공 신경망(ANN)은 표준 형식(예를 들어, ONNX(Open Neural Network Exchange))으로 기술/지정될 수 있다. 컴파일러는 인공 신경망(ANN)의 설명을 딥 러닝 가속기(DLA)가 인공 신경망(ANN)의 계산들을 수행하는 명 령어 세트로 변환하는 데 사용될 수 있다. 컴파일러는 인공 신경망(ANN) 구현 시 딥 러닝 가속기(DLA)의 성능을 개선하기 위해 명령어 세트를 최적화할 수 있다. 딥 러닝 가속기(DLA)는 벡터/행렬 피연산자들과 벡터/행렬 연산들의 결과들을 저장하도록 구성된 레지스터들, 버퍼들 및/또는 캐시들과 같은 로컬 메모리를 가질 수 있다. 레지스터들의 중간 결과들은 딥 러닝 가속기(DLA) 에서 후속 벡터/행렬 연산들을 위한 피연산자들로 파이프라이닝/시프팅되어 메모리/데이터에 액세스 시 시간과 에너지 소비를 줄이며 따라서 전형적인 인공 신경망(ANN) 구현 시 벡터/행렬 연산들의 일반적인 패턴들의 속도 를 높일 수 있다. 딥 러닝 가속기(DLA)의 레지스터들, 버퍼들 및/또는 캐시들의 용량은 일반적으로 전형적인 인 공 신경망(ANN)의 계산을 구현하기 위한 전체 데이터 세트를 보유하기에 충분하지 않다. 따라서 딥 러닝 가속기 (DLA)에 결합된 랜덤 액세스 메모리는 전형적인 인공 신경망(ANN)을 구현하기 위한 향상된 데이터 저장 능력을 제공하도록 구성된다. 예를 들어, 딥 러닝 가속기(DLA)는 랜덤 액세스 메모리로부터 데이터 및 명령어들을 로드 하고 결과들을 다시 랜덤 액세스 메모리에 저장한다. 딥 러닝 가속기(DLA)와 랜덤 액세스 메모리 사이의 통신 대역폭은 딥 러닝 가속기(DLA)의 계산 능력의 활용을 최적화하거나 최대화하도록 구성된다. 예를 들어, 딥 러닝 가속기(DLA)와 랜덤 액세스 메모리 사이에 높은 통신 대역폭이 제공되어 딥 러닝 가속기(DLA)가 벡터/행렬 피연산자들에 대한 계산들을 수행하는 시간과 거의 동일한 시간 기간에 벡터/행렬 피연산자들이 랜덤 액세스 메모리로부터 딥 러닝 가속기(DLA)로 로드되고 결과들을 다시 랜덤 액세스 메모리에 저장될 수 있다. 딥 러닝 가속기(DLA)의 세분성은 딥 러닝 가속기(DLA)에 의해 수행되는 계산들의 양과 벡터/행렬 피연산자들의 크기 사이의 비율을 증가시키도록 구성되어 딥 러닝 가속기(DLA)와 랜덤 액세스 메모리 사이의 데이터 액세스 트래픽이 감소될 수 있도록 하고, 이는 딥 러닝 가속기(DLA)와 랜덤 액세 스 메모리 사이의 통신 대역폭에 대한 요구사항을 줄일 수 있다. 따라서 데이터/메모리 액세스의 병목 현상이 줄어들거나 제거될 수 있다. 적어도 일부 실시예들에서, 다수의 디바이스들이 다른 목적을 위해 병렬로 랜덤 액세스 메모리에 액세스할 수 있도록 다수의 연결부들이 제공된다. 예를 들어, 랜덤 액세스 메모리는 인공 신경망(ANN)으로의 입력을 저장하 도록 구성된 부분 및 인공 신경망(ANN)으로부터의 출력을 저장하도록 구성된 다른 부분을 포함할 수 있다. 랜덤 액세스 메모리에 대한 하나의 연결부는 중앙 처리 유닛(CPU) 또는 다른 프로세서에 의해 인공 신경망(ANN)으로 부터의 출력에 액세스하는 데 사용될 수 있으며, 동시에 랜덤 액세스 메모리에 대한 다른 연결부는 직접 메모리 액세스(Direct Memory Access; DMA) 제어기에 의해 인공 신경망(ANN)에 대한 입력 데이터를 랜덤 액세스 메모리 에 저장하는 데 사용될 수 있다. 예를 들어, 중앙 처리 유닛(CPU)은 집적 메모리 액세스(DMA) 제어기를 설정하여 인공 신경망(ANN)에 의해 처리 될 입력 데이터를 랜덤 액세스 메모리의 입력 영역에 기록할 수 있다. 입력 세트를 입력 영역에 기록하는 집적 메모리 액세스(DMA) 제어기의 완료는 딥 러닝 가속기(DLA)가 인공 신경망(ANN)을 구현하기 위한 명령어들을 실행하는 것을 트리거할 수 있다. 명령어들의 실행은 입력과 인공 신경망(ANN)의 행렬들이 결합되어 출력이 생성 한다. 출력은 중앙 처리 유닛(CPU)에 대한 랜덤 액세스 메모리의 다른 영역에 저장되도록 구성된다. 선택적으로, 인공 신경망(ANN)의 모델 데이터는 랜덤 액세스 메모리의 추가 영역에 저장될 수 있다. 모델 데이 터는 인공 신경망(ANN)에서 인공 뉴런들의 신경 연결성 및 시냅스 가중치, 인공 뉴런들의 상태들 및/또는 속성 들을 식별하는 행렬들을 포함할 수 있다. 모델 데이터는 인공 신경망(ANN)의 계산을 구현하기 위한 딥 러닝 가 속기(DLA)에 대한 명령어들을 더 포함할 수 있다. 예를 들어, 컴파일러는 인공 신경망(ANN)에 대한 설명을 랜덤 액세스 메모리에 저장된 모델 데이터로 변환할 수 있다. 모델 데이터가 랜덤 액세스 메모리에 저장되고 직접 메모리 액세스(DMA) 제어기가 입력 데이터를 랜덤 액세스 메모리에 기록하도록 구성된 후, 딥 러닝 가속기(DLA) 및 직접 메모리 액세스(DMA) 제어기는 중앙 처리 유닛 (CPU)으로부터의 도움 없이 인공 신경망(ANN)을 사용하여 입력 데이터를 처리할 수 있다. 인공 신경망(ANN)의 출력은 랜덤 액세스 메모리에 자동으로 저장된다. 중앙 처리 유닛(CPU)은 딥 러닝 가속기(DLA)에 입력 데이터를 제공하는 직접 메모리 액세스(DMA) 제어기와 동시에 별도의 연결부를 통해 랜덤 액세스 메모리에 액세스할 수 있다. 예를 들어, 인공 신경망(ANN)으로의 입력 데이터의 스트림은 일련의 입력 데이터 세트들의 형태로 구성될 수 있 다. 각 입력 데이터 세트는 시간 슬롯 동안 인공 신경망(ANN)으로의 입력 세트를 위한 것이다. 딥 러닝 가속기 (DLA)가 현재 입력 세트의 출력을 계산하는 동안, 직접 메모리 액세스(DMA) 제어기는 다음 입력 세트를 랜덤 액 세스 메모리에 저장할 수 있으며; 중앙 처리 유닛(CPU)은 랜덤 액세스 메모리로부터 이전 입력 세트에 대해 생 성된 출력을 동시에 검색할 수 있다. 따라서, 인공 신경망(ANN)으로의 입력 데이터의 준비 및 처리의 태스크는 중앙 처리 유닛(CPU)으로부터 오프로 드될 수 있다. 딥 러닝 가속기(DLA), 랜덤 액세스 메모리 및 직접 메모리 액세스(DMA) 제어기의 조합은 인공 신 경망(ANN)으로부터 중앙 처리 유닛(CPU)으로 결과들을 독립적인 공급자로서 기능할 수 있다. 중앙 처리 유닛 (CPU)은 출력이 필요한 시간에 출력 세트를 검색할 수 있다. 중앙 처리 유닛(CPU)은 인공 신경망(ANN)으로부터 의 출력이 필요하지 않을 때 인공 신경망(ANN)에 입력을 공급 시 그 동작들을 일시 중지하도록 직접 메모리 액 세스(DMA) 제어기에 지시할 수 있다. 이후, 인공 신경망(ANN)으로부터의 출력이 필요할 때, 중앙 처리 유닛 (CPU)은 입력 데이터를 랜덤 액세스 메모리에 로드하는 그 동작들을 재개하도록 직접 메모리 액세스(DMA) 제어 기에 지시할 수 있다. 인공 신경망들(ANN들)은 이미지들과 같은 센서 데이터를 처리하는 데 사용할 수 있다. 예를 들어, 디지털 카메 라들은 컴퓨터 비전 및/또는 자율 주행, 비행, 네비게이션 등을 위한 이미지들을 생성하는 데 사용될 수 있다. 예를 들어, 일부 센서 데이터는 인공 신경망(ANN)에 의해 처리하기 위해 이미지 형태로 변환될 수 있다. 예를 들어, 레이더, 라이다, 초음파 스캐너, 의료 영상 장비 등은 특징들, 객체들, 질병들 등을 인식 및/또는 분류하 기 위해 인공 신경망들(ANN들)에 의해 분석할 이미지들을 생성할 수 있다. 딥 러닝 가속기 및 랜덤 액세스 메모리를 갖는 집적 회로 디바이스는 집적 회로 디바이스에 구현된 인공 신경망 (ANN)으로의 입력으로서 이미지 데이터를 획득하기 위한 카메라 인터페이스를 포함하도록 구성될 수 있다. 예를 들어, 카메라 인터페이스는 이미지 센서, 카메라 또는 레이더, 라이다, 초음파 스캐너, 의료 영상 장비와 같은 이미지들을 생성할 수 있는 다른 디바이스로부터 이미지 데이터를 수신하기 위해 모바일 산업 프로세서 인 터페이스(Mobile Industry Processor Interface; MIPI) 프로토콜에 따라 구현될 수 있다. 예를 들어, 모바일 산업 프로세서 인터페이스(MIPI) 프로토콜은 카메라 또는 이미징 디바이스의 동작을 제어하기 위한 카메라 커맨 드 인터페이스의 지원을 포함할 수 있다. 카메라 인터페이스는 딥 러닝 가속기와 랜덤 액세스 메모리를 갖는 집 적 회로 디바이스가 인공 신경망(ANN)에 의한 처리를 위한 입력으로 이미지 데이터의 수신을 제어할 수 있게 한 다. 카메라 또는 이미지 센서/생성기는 랜덤 액세스 메모리의 입력 영역으로 입력 데이터를 이미지들로 스트리 밍할 수 있다. 집적 회로 디바이스는 인공 신경망(ANN)에 따라 입력 데이터를 자동으로 변환하고 인공 신경망 (ANN)으로부터의 출력을 랜덤 액세스 메모리에 저장한다. 집적 회로 디바이스는 이미지 데이터를 심리스하게 (seamlessly) 획득하여 인공 신경망(ANN) 출력들로 변환하므로, 중앙 처리 유닛으로의 데이터 트래픽은 크게 감 소될 수 있다. 카메라 인터페이스는 집적 회로 디바이스가 랜덤 액세스 메모리에 인공 신경망(ANN)의 지능형 결과들을 자동으 로 공급하는 스마트 센서 유닛으로서 이미지 생성기와 결합되게 한다. 중앙 처리 유닛이 집적 회로 디바이스가 동작하도록 구성하면, 입력 데이터를 획득하고 인공 신경망(ANN)과 관련된 계산을 수행하는 계산 태스크들을 중앙 처리 유닛(CPU)으로부터 오프로드될 수 있다. 선택적으로, 원시 센서/이미지 데이터는 주기적 방식으로 일정 기간 동안 랜덤 액세스 메모리에 버퍼링될 수 있 으므로 필요한 경우 중앙 처리 유닛(CPU)도 일정 기간 내에 원시 센서 데이터에 액세스할 수 있다. 중앙 처리 유닛(CPU)의 로직 회로는 또한 딥 러닝 가속기(DLP) 및 랜덤 액세스 메모리가 있는 집적 회로 디바이 스에 통합될 수 있다. 중앙 처리 유닛(CPU) 및 딥 러닝 가속기(DLP)는 집적 회로 디바이스에서 랜덤 액세스 메 모리를 공유하도록 구성될 수 있다. 집적 회로 디바이스는 중앙 처리 유닛(CPU)과 랜덤 액세스 메모리를 가지고 있기 때문에, 집적 회로 디바이스는 시스템 온 칩(system on chip)을 형성할 수 있고 외부 메모리 버스에 대한 인터페이스 없이 구성될 수 있다. 예를 들어, 중앙 처리 유닛(CPU)을 갖는 이러한 집적 회로 디바이스에서, 애플리케이션들은 중앙 처리 유닛 (CPU)에서 실행되도록 프로그래밍될 수 있으며, 여기서 애플리케이션의 실행 인스턴스에서 사용되는 논리적 메 모리 어드레스들은 중앙 처리 유닛의 메모리 제어기를 통해 랜덤 액세스 메모리에 액세스하기 위한 물리적 메모 리 어드레스에 매핑될 수 있다. 딥 러닝 가속기(DLP)는 인공 신경망(ANN)과 관련된 계산들 중 일부 또는 전체를 수행할 수 있으며 인공 신경망(ANN)의 출력을 중앙 처리 유닛(CPU)에서 실행되는 애플리케이션(들)으로의 입력 으로 제공할 수 있다. 따라서, 집적 회로 디바이스는 감시 카메라와 같은 저가의 지능형 사물 인터넷들(IoT들) 을 구현하는 데 사용될 수 있다. 예를 들어, 하나 이상의 센서들은 집적 회로 디바이스의 입/출력 인터페이스에 연결되어 추론 결과들을 생성하 도록 훈련된 인공 신경망(ANN)으로의 입력으로서 센서 데이터를 제공할 수 있다. 훈련된 인공 신경망(ANN)에 대 한 설명은 컴파일러를 사용하여 일련의 명령어들 및 행렬 데이터로 변환될 수 있다. 명령어들과 행렬 데이터를 랜덤 액세스 메모리에 저장한 후, 딥 러닝 가속기(DLP)는 명령어들을 실행하여 중앙 처리 유닛에 대한 고 레벨 입력으로 인공 신경망(ANN)의 센서 데이터와 행렬 데이터를 결합할 수 있다. 선택적으로, 딥 러닝 가속기(DLP) 에 의해 실행되는 명령어들은 중앙 처리 유닛에서 실행되는 하나 이상의 루틴들에 대한 호출들을 포함할 수 있 다. 신호 라인들은 호출들을 용이하게 하기 위해 집적 회로 디바이스 내에서 구현될 수 있다. 따라서, 집적 회 로 디바이스의 중앙 처리 유닛은 인공 신경망(ANN)을 구현 시 딥 러닝 가속기(DLP)에 서비스들을 선택적으로 제 공할 수 있다. 중앙 처리 유닛에 의해 실행될 애플리케이션은 인공 신경망(ANN)에 의해 생성된 추론 결과들을, 랜덤 액세스 메 모리로부터, 입력으로 판독하도록 프로그래밍될 수 있다. 따라서, 인공 신경망(ANN)을 사용하여 센서 데이터를 처리하는 세부 사항들은 애플리케이션의 프로그래밍으로부터 차폐될 수 있다. 도 1은 일 실시예에 따라 구성된 딥 러닝 가속기 및 랜덤 액세스 메모리를 갖는 집적 회로 디바이스 를 도시한다. 도 1의 딥 러닝 가속기는 처리 유닛들, 제어 유닛 및 로컬 메모리를 포함한다. 벡터 및 행 렬 피연산자들이 로컬 메모리에 있을 때, 제어기 유닛은 처리 유닛들을 사용하여 명령어들에 따 라 벡터 및 행렬 연산들을 수행할 수 있다. 또한, 제어기 유닛은 메모리 인터페이스 및 고속/대역폭 연결부를 통해 랜덤 액세스 메모리로부터 명령어들 및 피연산자들을 로드할 수 있다. 집적 회로 디바이스는 메모리 제어기 인터페이스를 위한 핀(pin)들 또는 콘택(contact)들을 갖는 집 적 회로 패키지 내에 포함되도록 구성된다. 메모리 제어기 인터페이스는 딥 러닝 가속기(DLA)가 없는 기존의 랜덤 액세스 메모리 디바이스와 동 일한 방식으로 집적 회로 디바이스가 전형적인 메모리 제어기에 나타나도록 표준 메모리 액세스 프로토콜 을 지원하도록 구성된다. 예를 들어, 집적 회로 디바이스 외부의 메모리 제어기는 메모리 제어기 인터페이 스를 통해 표준 메모리 액세스 프로토콜을 사용하여 집적 회로 디바이스의 랜덤 액세스 메모리 에 액세스할 수 있다. 집적 회로 디바이스는 집적 회로 디바이스 내에 포함된 랜덤 액세스 메모리와 딥 러닝 가속기 (DLA) 사이의 고대역폭 연결부로 구성된다. 연결부의 대역폭은 랜덤 액세스 메모리와 메모 리 제어기 인터페이스 사이의 연결부의 대역폭보다 높다. 일 실시예에서, 메모리 제어기 인터페이스 및 메모리 인터페이스 모두는 동일한 버스 또는 와이어 세 트를 통해 랜덤 액세스 메모리에 액세스하도록 구성된다. 따라서, 랜덤 액세스 메모리에 액세스하기 위한 대역폭은 메모리 인터페이스와 메모리 제어기 인터페이스 사이에서 공유된다. 대안적으로, 메모리 제어기 인터페이스 및 메모리 인터페이스는 별도의 버스 또는 와이어 세트를 통해 랜덤 액세스 메 모리에 액세스하도록 구성된다. 선택적으로, 랜덤 액세스 메모리는 연결부를 통해 동시에 액세 스될 수 있는 다수의 섹션들을 포함할 수 있다. 예를 들어, 메모리 인터페이스가 랜덤 액세스 메모리(10 5)의 섹션에 액세스할 경우, 메모리 제어 인터페이스는 랜덤 액세스 메모리의 다른 섹션에 동시에 액 세스할 수 있다. 예를 들어, 다른 섹션들은 메모리 셀들의 다른 집적 회로 다이들 및/또는 다른 평면들/뱅크들 상에 구성될 수 있으며; 랜덤 액세스 메모리에 액세스 시 처리량을 증가시키기 위해 다른 섹션들이 병렬로 액세스될 수 있다. 예를 들어, 메모리 제어기 인터페이스는 한 번에 미리 결정된 크기의 하나의 데이터 유 닛에 액세스하도록 구성되며; 메모리 인터페이스는 동일한 미리 결정된 크기 각각인 다수의 데이터 유닛들 을 한 번에 액세스하도록 구성된다. 일 실시예에서, 랜덤 액세스 메모리 및 집적 회로 디바이스는 동일한 집적 회로 패키지 내에 구성된 상이한 집적 회로 다이들 상에 구성된다. 또한, 랜덤 액세스 메모리는 다수의 데이터 요소들의 병렬 액세 스를 동시에 허용하는 하나 이상의 집적 회로 다이들 상에 구성될 수 있다. 일부 구현들에서, 연결부를 통해 병렬로 액세스될 수 있는 벡터 또는 행렬의 데이터 요소들의 수는 벡터들 또는 행렬들에서 동작하는 딥 러닝 가속기(DLA)의 세분성에 해당한다. 예를 들어, 처리 유닛들이 다수의 벡터/행렬 요소들에 대해 병렬로 동작될 수 있을 경우, 연결부는 연결부를 통해 요소들의 동일한 수 또는 수의 배수를 병렬로 로드하거나 저장하도록 구성된다. 선택적으로, 연결부의 데이터 액세스 속도는 딥 러닝 가속기(DLA)의 처리 속도에 기초하여 구성될 수 있다. 예를 들어, 일정량의 데이터 및 명령어들이 로컬 메모리에 로드된 후, 제어 유닛은 처리 유닛 들을 사용하여 데이터에 대해 동작하도록 하는 명령어를 실행하여 출력을 생성할 수 있다. 출력을 생성하 기 위한 처리의 시간 기간 내에서, 연결부의 액세스 대역폭은 다음 동작을 위해 동일한 양의 데이터 및 명 령어들이 로컬 메모리에 로드되도록 하고 동일한 양의 출력이 랜덤 액세스 메모리에 다시 저장되게 한다. 예를 들어, 제어 유닛이 데이터를 처리하고 출력을 생성하기 위해 로컬 메모리의 일부를 사용 하는 동안, 메모리 인터페이스는 이전 동작의 출력을 로컬 메모리의 다른 부분으로부터 랜덤 액세스 메모리로 오프로드할 수 있고, 피연산자 데이터 및 명령어들을 로컬 메모리의 다른 부분으로 로드할 수 있다. 따라서 딥 러닝 가속기(DLA)의 활용과 성능은 연결부의 대역폭에 의해 제한되거나 감소되지 않는 다. 랜덤 액세스 메모리는 인공 신경망(ANN)의 모델 데이터를 저장하고 인공 신경망(ANN)에 대한 입력 데이터 를 버퍼링하는 데 사용될 수 있다. 모델 데이터는 자주 변경되지 않는다. 모델 데이터는 인공 신경망(ANN)을 구 현하기 위한 딥 러닝 가속기(DLA)에 대한 컴파일러에 의해 생성된 출력을 포함할 수 있다. 모델 데이터는 일반 적으로 인공 신경망(ANN)의 설명에 사용되는 행렬들 및 딥 러닝 가속기(DLA)의 세분성의 벡터/행렬 연산들 에 기초하여 인공 신경망(ANN)의 벡터/행렬 연산들을 수행하기 위해 딥 러닝 가속기(DLA)에 대해 생성된 명령어들을 포함한다. 명령어들은 인공 신경망(ANN)의 벡터/행렬 연산들뿐만 아니라 인공 신경망(ANN)의 입력 데이터에서도 동작한다. 일 실시예에서, 입력 데이터가 랜덤 액세스 메모리에 로드되거나 업데이트될 경우, 딥 러닝 가속기 (DLA)의 제어 유닛은 인공 신경망(ANN)에 대한 명령어들을 자동으로 실행하여 인공 신경망(ANN)의 출 력을 생성할 수 있다. 출력은 랜덤 액세스 메모리의 미리 정의된 영역에 저장된다. 딥 러닝 가속기 (DLA)는 중앙 처리 유닛(CPU)으로부터의 도움 없이 명령어들이 실행될 수 있다. 따라서, 딥 러닝 가속기 (DLA)와 집적 회로 디바이스 외부의 프로세서(예를 들어, 중앙 처리 유닛(CPU)) 사이의 조정을 위한 통신이 감소되거나 제거될 수 있다. 선택적으로, 딥 러닝 가속기(DLA)의 로직 회로는 상보적 금속 산화 반도체(Complementary Metal Oxide Semiconductor; CMOS)를 통해 구현될 수 있다. 예를 들어, 랜덤 액세스 메모리의 메모리 셀들의 CUA(CMOS Under the Array) 기술은 처리 유닛들 및 제어 유닛을 포함하는 딥 러닝 가속기(DLA)의 로직 회로를 구현하는 데 사용될 수 있다. 대안적으로, 랜덤 액세스 메모리의 메모리 셀 어레이의 CMOS 기술은 딥 러닝 가속기(DLA)의 로직 회로를 구현하는 데 사용될 수 있다. 일부 구현들에서, 딥 러닝 가속기(DLA)와 랜덤 액세스 메모리는 별도의 집적 회로 다이들 상에 구현 될 수 있으며 딥 러닝 가속기(DLA)와 랜덤 액세스 메모리 사이의 데이터 대역폭 증가를 위해 실리콘 관통 비아(Through-Silicon Vias; TSV)를 사용하여 연결될 수 있다. 예를 들어, 딥 러닝 가속기(DLA)는 필드 프로그래머블 게이트 어레이(Field-Programmable Gate Array; FPGA) 또는 애플리케이션별 집적 회로(Application Specific Integrated Circuit; ASIC)의 집적 회로 다이 상에 형성될 수 있다. 대안적으로, 딥 러닝 가속기(DLA) 및 랜덤 액세스 메모리는 별도의 집적 회로 패키지들로 구성될 수 있으며 병렬 통신을 위해 인쇄 회로 기판(printed circuit board; PCB)에서 다수의 점대점 연결부들을 통해 연 결되고 따라서 데이터 전송 대역폭이 증가될 수 있다. 랜덤 액세스 메모리는 휘발성 메모리 또는 비휘발성 메모리, 또는 휘발성 메모리와 비휘발성 메모리의 조 합일 수 있다. 비휘발성 메모리의 예들은 플래시 메모리, 네거티브 앤드(negative-and; NAND) 로직 게이트들, 네거티브 오어(negative-or; NOR) 로직 게이트들, 상변화 메모리(Phase-Change Memory; PCM), 자기 메모리 (magnetic memory; MRAM), 저항성 랜덤 액세스 메모리, 크로스 포인트 스토리지 및 메모리 디바이스들에 기초하 여 형성된 메모리 셀들을 포함한다. 크로스 포인트 메모리 디바이스는 트랜지스터가 없는 메모리 요소들을 사용 할 수 있으며, 그 각각은 열(column)로 함께 적층되는 메모리 셀 및 선택기를 갖는다. 메모리 요소 열들은 수직 방향들로 이어지는 두 개의 와이어 레이(lay)들을 통해 연결되며, 여기서 한 레이의 와이어들은 메모리 요소 열 들 위에 위치된 레이어에서 한 방향으로 이어지고, 다른 레이의 와이어들은 다른 방향으로 이어져 메모리 요소 열들 아래에 위치된다. 각 메모리 요소는 두 레이어 각각에 있는 한 와이어의 크로스 포인트에서 개별적으로 선 택될 수 있다. 크로스 포인트 메모리 디바이스들은 빠르고 비휘발성이며 처리 및 저장을 위한 통합 메모리 풀 (pool)로 사용될 수 있다. 비휘발성 메모리의 추가의 예들은 읽기 전용 메모리(Read-Only Memory; ROM), 프로그 램 가능 읽기 전용 메모리(Programmable Read-Only Memory; PROM), 소거 가능한 프로그램 가능 읽기 전용 메모 리(Erasable Programmable Read-Only Memory; EPROM) 및 전기적으로 소거 가능한 프로그램 가능 읽기 전용 메 모리(Electronically Erasable Programmable Read-Only Memory; EEPROM) 메모리 등을 포함한다. 휘발성 메모리 의 예들은 동적 랜덤 액세스 메모리(Dynamic Random-Access Memory; DRAM) 및 정적 랜덤 액세스 메모리(Static Random-Access Memory; SRAM)를 포함한다. 예를 들어, 비휘발성 메모리는 랜덤 액세스 메모리의 적어도 일부를 구현하도록 구성될 수 있다. 랜덤 액 세스 메모리의 비휘발성 메모리는 인공 신경망(ANN)의 모델 데이터를 저장하는 데 사용될 수 있다. 따라서, 집적 회로 디바이스의 전원을 끄고 다시 시작한 후, 인공 신경망(ANN)의 모델 데이터를 집적 회로 디바이스에 다시 로드할 필요가 없다. 또한, 비휘발성 메모리는 프로그래밍 가능/재기록 가능할 수 있다. 따라서, 집적 회로 디바이스에서 인공 신경망(ANN)의 모델 데이터는 업데이트 인공 신경망(ANN) 또는 다른 인공 신경망(ANN)을 구현하기 위해 업데이트되거나 대체될 수 있다. 딥 러닝 가속기(DLA)의 처리 유닛들은 벡터-벡터 유닛들, 행렬-벡터 유닛들, 및/또는 행렬-행렬 유닛 들을 포함할 수 있다. 벡터-벡터 연산들, 행렬-벡터 연산들, 및 행렬-행렬 연산들을 위해 수행하도록 구성된 유 닛들의 예들은 도 2 내지 4와 관련하여 아래에서 논의된다. 도 2는 일 실시예에 따라 행렬-행렬 연산들을 수행하도록 구성된 처리 유닛을 도시한다. 예를 들어, 도 2 의 행렬-행렬 유닛은 도 1의 딥 러닝 가속기(DLA)의 처리 유닛들 중 하나로 사용될 수 있다. 도 2에서, 행렬-행렬 유닛은 다수의 커널 버퍼들(131 내지 133) 및 다수의 맵 뱅크들(151 내지 153)을 포 함한다. 맵 뱅크들(151 내지 153) 각각은 맵 뱅크들(151 내지 153)에 각각 저장된 다수의 벡터들을 갖는 행렬 피연산자의 하나의 벡터를 저장하고; 커널 버퍼들(131 내지 133) 각각은 커널 버퍼들(131 내지 133)에 각각 저 장된 다수의 벡터들을 갖는 다른 행렬 피연산자의 하나의 벡터를 저장한다. 행렬-행렬 유닛은 병렬로 동작 하는 다수의 행렬-벡터 유닛들(141 내지 143)을 사용하여 두 개의 행렬 피연산자들의 요소들에 대한 곱셈 및 누 산 연산들을 수행하도록 구성된다. 크로스 바(cross bar)는 맵 뱅크들(151 내지 153)을 행렬-벡터 유닛들(141 내지 143)에 연결한다. 맵 뱅 크(151 내지 153)에 저장된 동일한 행렬 피연산자는 크로스 바를 통해 행렬-벡터 유닛들(141 내지 143) 각 각에 제공되고; 행렬-벡터 유닛들(141 내지 143)은 병렬로 맵 뱅크들(151 내지 153)로부터 데이터 요소들을 수 신한다. 커널 버퍼들(131 내지 133) 각각은 행렬-벡터 유닛들(141 내지 143) 내의 각각의 것에 연결되고 각각의 행렬-벡터 유닛에 벡터 피연산자를 제공한다. 행렬-벡터 유닛들(141 내지 143)은 커널 버퍼들(131 내지 133)에 저장된 해당 벡터들을 곱한 맵 뱅크들(151 내지 153)에 저장된 동일한 행렬 피연산자의 연산을 계산하기 위해 동시에 동작한다. 예를 들어, 행렬-벡터 유닛은 맵 뱅크들(151 내지 153)에 저장된 행렬 피연산자와 커널 버퍼에 저장된 벡터 피연산자에 대해 곱셈 연산을 수행하는 반면, 행렬-벡터 유닛은 동시에 맵 뱅크 들(151 내지 153)에 저장된 행렬 피연산자와 커널 버퍼에 저장된 벡터 피연산자에 대해 곱셈 연산을 수행 한다.도 2의 행렬-벡터 유닛들(141 내지 143) 각각은 도 3에 예시된 방식으로 구현될 수 있다. 도 3은 일 실시예에 따라 행렬-벡터 연산들을 수행하도록 구성된 처리 유닛을 도시한다. 예를 들어, 도 3 의 행렬-벡터 유닛은 도 2의 행렬-행렬 유닛의 행렬-벡터 유닛들 중 어느 하나로 사용될 수 있다. 도 3에서, 맵 뱅크들(151 내지 153) 각각은, 도 2의 맵 뱅크들(151 내지 153)과 유사한 방식으로, 맵 뱅크들 (151 내지 153)에 각각 저장된 다수의 벡터들을 갖는 행렬 피연산자의 하나의 벡터를 저장한다. 도 3의 크로스 바는 맵 뱅크들로부터의 벡터들을 벡터-벡터 유닛들(161 내지 163)에 각각 제공한다. 커널 버퍼(13 1)에 저장된 동일한 벡터는 벡터-벡터 유닛들(161 내지 163)에 제공된다. 벡터-벡터 유닛들(161 내지 163)은 커널 버퍼에 저장된 동일한 백터 연산자를 곱한 맵 뱅크들(151 내지 153)에 각각 저장된 해당 벡터 피연산자들의 연산을 계산하기 위해 동시에 동작한다. 예를 들어, 벡터-벡터 유 닛은 맵 뱅크에 저장된 벡터 피연산자와 커널 버퍼에 저장된 벡터 피연산자에 대해 곱셈 연산을 수행하는 반면, 벡터-벡터 유닛은 동시에 맵 뱅크에 저장된 벡터 피연산자와 커널 버퍼에 저장 된 벡터 피연산자에 대해 곱셈 연산을 수행한다. 도 3의 행렬-벡터 유닛은 도 2의 행렬-행렬 유닛에서 구현될 경우, 행렬-벡터 유닛은 행렬-행렬 유닛의 맵 뱅크들(151 내지 153), 크로스바 및 커널 버퍼를 사용할 수 있다. 도 3의 벡터-벡터 유닛들(161 내지 163) 각각은 도 4에 예시된 방식으로 구현될 수 있다. 도 4는 일 실시예에 따라 벡터-벡터 연산들을 수행하도록 구성된 처리 유닛을 도시한다. 예를 들어, 도 4 의 벡터-벡터 유닛은 도 3의 행렬-벡터 유닛의 벡터-벡터 유닛들 중 어느 하나로 사용될 수 있다. 도 4에서, 벡터-벡터 유닛은 다수의 곱셈 누산(multiply-accumulate; MAC) 유닛들(171 내지 173)을 갖는 다. 곱셈 누산(MAC) 유닛들(171 내지 173) 각각은 두 개의 숫자들을 피연산자들로 수신하고, 두 숫자의 곱셈을 수행하고, 곱셈 누산(MAC) 유닛에서 유지되는 합에 곱셈의 결과를 더할 수 있다. 벡터 버퍼들(181 및 183) 각각은 숫자들의 목록(list)을 저장한다. 각각이 벡터 버퍼들(181 및 183) 중 하나로 부터 비롯되는 숫자 쌍이 곱셈 누산(MAC) 유닛들(171 내지 173) 각각에 입력으로 제공될 수 있다. 곱셈 누산 (MAC) 유닛들(171 내지 173)은 벡터 버퍼들(181 및 183)로부터 다수의 숫자 쌍들을 병렬로 수신하고 곱셈 누산 (MAC) 연산들을 병렬로 수행할 수 있다. 곱셈 누산(MAC) 유닛들(171 내지 173)로부터의 출력들은 시프트 레지스 터에 저장되고; 누산기는 시프트 레지스터에서 결과들의 합을 계산한다. 도 4의 벡터-벡터 유닛이 도 3의 행렬-벡터 유닛으로 구현될 경우, 벡터-벡터 유닛은 하나의 벡 터 버퍼로서 맵 뱅크(예를 들어, 151 또는 153)를 사용할 수 있고, 행렬-벡터 유닛의 커널 버퍼(13 1)는 다른 벡터 버퍼로서 사용할 수 있다. 벡터 버퍼들(181 및 183)은 동일한 수/카운트의 데이터 요소들을 저장하기 위해 동일한 길이를 가질 수 있다. 길이는 벡터-벡터 유닛에서 곱셈 누산(MAC) 유닛들(171 내지 173)의 카운트와 같거나 그 배수일 수 있다. 벡터 버퍼들(181 및 183)의 길이가 곱셈 누산(MAC) 유닛들(171 내지 173)의 카운트의 배수일 경우, 곱셈 누산 (MAC) 유닛들(171 내지 173)의 카운트와 같은 입력 쌍들의 수는 벡터 버퍼들(181 및 183)로부터 각 반복 시 곱 셈 누산(MAC) 유닛들(171 내지 173)로의 입력들로 제공될 수 있으며; 벡터 버퍼들(181 및 183)은 다수의 반복들 을 통해 그들의 요소들을 곱셈 누산(MAC) 유닛들(171 내지 173)에 공급한다. 일 실시예에서, 딥 러닝 가속기(DLA)와 랜덤 액세스 메모리 사이의 연결부의 통신 대역폭은 행 렬-행렬 유닛이 랜덤 액세스 메모리의 일부들을 맵 뱅크들(151 내지 153) 및 커널 버퍼들(131 내지 133)로 사용하기에 충분하다. 다른 실시예에서, 맵 뱅크들(151 내지 153) 및 커널 버퍼들(131 내지 133)은 딥 러닝 가속기(DLA)의 로컬 메모리의 일부에 구현된다. 딥 러닝 가속기(DLA)와 랜덤 액세스 메모리 사이의 연결부의 통신 대역폭은 로컬 메모리의 다른 부분에 행렬-행렬 유닛의 다음 연산 주기의 행렬 피연산자들을 로 드하기에 충분한 반면, 행렬-행렬 유닛은 딥 러닝 가속기(DLA)의 로컬 메모리의 다른 부분에 구현된 맵 뱅크들(151 내지 153) 및 커널 버퍼들(131 내지 133)을 사용하여 현재 연산 주기에서 계산을 수행한다. 도 5는 일 실시예에 따른 훈련된 인공 신경망에 입력들을 자율적으로 적용하도록 구성된 딥 러닝 가속기 및 랜 덤 액세스 메모리를 도시한다. 기계 학습(예를 들어, 딥 러닝)을 통해 훈련된 인공 신경망(ANN)은 표준 형식(예를 들어, 개방형 신경망 교환(Open Neural Network Exchange; ONNX))으로 설명될 수 있다. 표준 형식의 훈련된 ANN에 대한 설명은 인공 뉴런들의 속성들과 연결성을 식별한다. 도 5에서, 딥 러닝 가속기(DLA) 컴파일러는 인공 뉴런들의 속성들 및 연결성에 해당하는 딥 러닝 가속기 (DLA) 및 행렬들에 대한 명령어들을 생성하여 훈련된 ANN을 변환한다. 훈련된 ANN으 로부터 DLA 컴파일러에 의해 생성된 명령어들 및 행렬들은 딥 러닝 가속기(DLA)를 위한 랜 덤 액세스 메모리에 저장될 수 있다. 예를 들어, 랜덤 액세스 메모리 및 딥 러닝 가속기(DLA)는 도 1의 집적 회로 디바이스에서와 같 은 방식으로 고대역폭 연결부를 통해 연결될 수 있다. 명령어들 및 행렬들에 기초한 도 5의 자 율 계산은 도 1의 집적 회로 디바이스에서 구현될 수 있다. 대안적으로, 랜덤 액세스 메모리 및 딥 러닝 가속기(DLA)는 연결부를 구현하기 위해 다수의 지점 간 직렬 버스들이 병렬로 실행되는 인쇄 회 로 기판에 구성될 수 있다. 도 5에서, DLA 컴파일러의 결과들이 랜덤 액세스 메모리에 저장된 후, 훈련된 ANN의 해당 출력 을 생성하기 위해 훈련된 ANN으로의 입력을 처리하기 위한 훈련된 ANN의 적용은 랜덤 액세 스 메모리에서 입력 또는 랜덤 액세스 메모리에 제공된 다른 표시의 존재에 의해 트리거될 수 있다. 이에 응답하여, 딥 러닝 가속기(DLA)는 명령어들을 실행하여 입력과 행렬들을 결합한다. 명령어들의 실행은 딥 러닝 가속기(DLA)의 하나 이상의 행렬-행렬 유닛들(예를 들어, 121)의 맵 뱅크 들(151 내지 153)에 대한 맵 행렬들의 생성을 포함할 수 있다. 일부 실시예들에서, ANN으로의 입력들은 초기 맵 행렬의 형태이다. 초기 맵 행렬의 부분들은 행렬-행렬 유 닛의 맵 뱅크들(151 내지 153)에 저장된 행렬 피연산자로서 랜덤 액세스 메모리로부터 검색될 수 있 다. 대안적으로, DLA 명령어들은 또한 입력으로부터 초기 맵 행렬을 생성하기 위한 딥 러닝 가속기 (DLA)에 대한 명령어들을 포함한다. DLA 명령어들에 따르면, 딥 러닝 가속기(DLA)는 행렬 피연산자들을 커널 버퍼들(131 내지 133)에 로 드하고 행렬-행렬 유닛의 뱅크들(151 내지 153)을 매핑한다. 행렬-행렬 유닛은 행렬 피연산자들에 대 한 행렬 계산을 수행한다. 예를 들어, DLA 명령어들은 딥 러닝 가속기(DLA)의 계산 세분성(예를 들어, 행렬-행렬 유닛에서 행렬 피연산자들로 로드된 행렬들의 크기들/차원들)에 따라 훈련된 ANN의 행렬 계산들을 분해하고 입력 특징 맵들을 인공 뉴런들의 레이어의 커널에 적용하여 인공 뉴런들의 다음 레이어 에 대한 입력으로서 출력을 생성한다. 명령어들에 따라 수행된 훈련된 ANN의 계산이 완료되면, 딥 러닝 가속기(DLA)는 계산을 트리거 하기 위해 ANN의 출력을 랜덤 액세스 메모리의 미리 정의된 위치에 또는 랜덤 액세스 메모리 에 제공된 표시에 지정된 위치에 저장한다. 도 5의 기술이 도 1의 집적 회로 디바이스에서 구현되는 경우, 메모리 제어기 인터페이스에 연결된 외부 디바이스는 입력을 랜덤 액세스 메모리에 기록하고 딥 러닝 가속기(DLA)에 의해 입력(21 1)을 훈련된 ANN에 적용하는 자율 계산을 트리거할 수 있다. 일정 시간 기간 후, 출력은 랜덤 액세스 메모리에서 사용 가능하며; 외부 디바이스는 집적 회로 디바이스의 메모리 제어기 인터페이스를 통해 출력을 판독할 수 있다. 예를 들어, 랜덤 액세스 메모리의 미리 정의된 위치는 딥 러닝 가속기(DLA)에 의해 명령어들의 자율 실행을 트리거하는 표시를 저장하도록 구성될 수 있다. 표시는 랜덤 액세스 메모리 내의 입력의 위치를 선택적으로 포함할 수 있다. 따라서, 입력을 처리하기 위한 명령어들의 자동 실행 동안, 외부 디바이스는 명령어들의 이전 실행 동안 생성된 출력을 검색하고/하거나 명령어들의 다음 실행을 위한 다른 입력 세트를 저장할 수 있다. 선택적으로, 랜덤 액세스 메모리의 추가의 미리 정의된 위치는 명령어들의 현재 실행의 진행 상태의 표시를 저장하도록 구성될 수 있다. 또한, 표시는 명령어들의 현재 실행의 완료 시간의 예측(예를 들어, 명령어들의 이전 실행에 기초하여 추정됨)을 포함할 수 있다. 따라서 외부 디바이스는 출력을 검색하 기 위해 적절한 시간 창에서 완료 상태를 확인할 수 있다. 일부 실시예들에서, 랜덤 액세스 메모리는 다수의 입력(예를 들어, 211) 및 출력(예를 들어, 213) 세트를 저장하기에 충분한 용량으로 구성된다. 각 세트는 랜덤 액세스 메모리에서 미리 결정된 슬롯/영역에 구성 될 수 있다. 딥 러닝 가속기(DLA)는 집적 회로 디바이스 외부에 위치된 프로세서 또는 디바이스로부터의 도움 없 이 랜덤 액세스 메모리에 저장된 행렬들에 따라 입력으로부터 출력을 생성하기 위해 명령 어들을 자율적으로 실행할 수 있다. 하나의 실시예에 따른 방법에서, 컴퓨팅 디바이스(예를 들어, 101)의 랜덤 액세스 메모리는 메모리 제어기 에 대한 컴퓨팅 디바이스(예를 들어, 101)의 인터페이스를 사용하여 액세스될 수 있다. 컴퓨팅 디바이스 (예를 들어, 101)는 맵 뱅크들(151 내지 153)에 저장된 행렬 피연산자 및 커널 버퍼들(131 내지 133)에 저장된 행렬 피연산자와 같은, 행렬 피연산자들에 대한 적어도 계산들을 수행하도록 구성된 처리 유닛들(예를 들어, 111)을 가질 수 있다. 예를 들어, 컴퓨팅 디바이스(예를 들어, 101)는 집적 회로 패키지 내에 포함될 수 있고; 연결부 세트는 인터페 이스를 집적 회로 패키지의 외부에 위치된 메모리 제어기에 연결할 수 있다. 처리 유닛들(예를 들어, 111)에 의해 실행 가능한 명령어들은 인터페이스를 통해 랜덤 액세스 메모리 에 기록될 수 있다. 인공 신경망의 행렬들은 인터페이스를 통해 랜덤 액세스 메모리에 기록될 수 있다. 행렬들 은 인공 신경망의 속성 및/또는 상태를 식별한다. 선택적으로, 랜덤 액세스 메모리의 적어도 일부는 비휘발성이고 인공 신경망의 명령어들 및 행 렬들을 저장하도록 구성된다. 인공 신경망으로의 제1 입력은 인터페이스를 통해 랜덤 액세스 메모리에 기록될 수 있다. 처리 유닛들이 명령어들의 실행을 시작하게 하는 표시가 랜덤 액세스 메모리에 제공된다. 표시 에 응답하여, 처리 유닛들은 제1 입력을 인공 신경망의 행렬들과 결합하기 위한 명령어들 을 실행하여 인공 신경망으로부터 제1 출력을 생성하고 제1 출력을 랜덤 액세스 메모리에 저장한다. 예를 들어, 표시는 랜덤 액세스 메모리의 제1 입력의 어드레스일 수 있고; 표시는 랜덤 액세스 메모 리의 미리 결정된 위치에 저장되어 어드레스에 의해 식별된 입력에 대한 명령어들의 실행의 시 작을 유발할 수 있다. 선택적으로, 표시는 또한 출력을 저장하기 위한 어드레스를 포함할 수 있다. 제1 출력은 인터페이스를 통해 랜덤 액세스 메모리로부터 판독될 수 있다. 예를 들어, 컴퓨팅 디바이스(예를 들어, 101)는 제1 집적 회로 다이 상에 형성된 딥 러닝 가속기 및 하나 이상의 제2 집적 회로 다이 상에 형성된 랜덤 액세스 메모리를 가질 수 있다. 제1 집적 회로 다이와 하나 이상의 제2 집적 회로 다이들 사이의 연결부는 메모리 액세스를 위한 고대역폭을 제공하기 위해 실리콘 관 통 비아들(TSV들)을 포함할 수 있다. 예를 들어, 인공 신경망의 설명은 컴파일러를 사용하여 명령어들 및 행렬들로 변환될 수 있다. 랜덤 액세스 메모리 및 딥 러닝 가속기에 저장된 명령어들 및 행렬들의 조합은 인공 신경망으로의 입력을 그 출력으로 자동으로 변환할 수 있는 인공 신경망의 자율 구현을 제 공한다. 예를 들어, 딥 러닝 가속기가 인공 신경망의 행렬들에 따라 제1 입력으로부터 제1 출력 을 생성하기 위한 명령어들을 실행하는 시간 기간 동안, 인공 신경망으로의 제2 입력은 대체 위 치에서 인터페이스를 통해 랜덤 액세스 메모리에 기록될 수 있다. 제1 출력이 랜덤 액세스 메모 리에 저장된 후, 딥 러닝 가속기가 명령어들의 실행을 다시 시작하게 하고 제2 입력으로부터 제2 출 력을 생성하게 하는 랜덤 액세스 메모리에 표시가 제공될 수 있다. 딥 러닝 가속기가 인공 신경망의 행렬들에 따라 제2 입력으로부터 제2 출력을 생성하기 위한 명 령어들을 실행하는 시간 기간 동안, 제1 출력은 인터페이스를 통해 랜덤 액세스 메모리로 부터 판독될 수 있고; 추가 입력은 제1 입력을 대체하기 위해 랜덤 액세스 메모리에 기록되거나 다른 위치 에 기록될 수 있다. 일련의 입력들에 대해 프로세스가 반복될 수 있다.딥 러닝 가속기는 두 개의 행렬 피연산자들에 대한 명령어를 실행할 수 있는 적어도 하나의 행렬-행렬 유 닛을 포함할 수 있다. 두 개의 행렬 피연산자들은 제1 행렬 및 제2 행렬일 수 있다. 두 개의 행렬들 각각 은 복수의 벡터들을 갖는다. 행렬-행렬 유닛은 병렬로 동작하도록 구성된 복수의 행렬-벡터 유닛들(141 내 지 143)을 포함할 수 있다. 행렬-벡터 유닛들(141 내지 143) 각각은, 다른 행렬-벡터 유닛들과 병렬로, 제1 행 렬 및 제2 행렬로부터의 하나의 벡터에 대해 동작하도록 구성된다. 또한, 행렬-벡터 유닛들(141 내지 143) 각각 은 병렬로 동작하도록 구성된 복수의 벡터-벡터 유닛들(161 내지 163)을 가질 수 있다. 벡터-벡터 유닛들(161 내지 163) 각각은, 다른 벡터-벡터 유닛들과 병렬로, 제1 행렬로부터의 벡터 및 해당 행렬-벡터 유닛의 공통 벡 터 피연산자에 대해 동작하도록 구성된다. 또한, 벡터-벡터 유닛들(161 내지 163) 각각은 병렬로 동작하도록 구 성된 복수의 곱셈 누산 유닛들(171 내지 173)을 가질 수 있다. 딥 러닝 가속기는 처리 유닛들 외에 로컬 메모리 및 제어 유닛을 가질 수 있다. 제어 유닛 은 처리 유닛들에 의한 실행을 위해 랜덤 액세스 메모리로부터 명령어들 및 행렬 피연산자 들(예를 들어, 207)를 로드할 수 있다. 로컬 메모리는 행렬-행렬 유닛에 의해 사용되는 행렬 피연산자들을 캐시 할 수 있다. 연결부는 행렬-행렬 유닛이 두 개의 다른 행렬 피연산자들에 대한 연산을 수행하는 시간 기간 동안 랜덤 액세스 메모리에서 로컬 메모리로 행렬 피연산자 세트를 로드하기에 충분한 대역폭으로 구 성될 수 있다. 또한, 시간 기간 동안, 대역폭은 이전 명령어 실행에서 행렬-행렬 유닛에 의해 생성된 결과 를 로컬 메모리에서 랜덤 액세스 메모리로 저장하기에 충분하다. 도 6은 일 실시예에 따라 별도의 메모리 액세스 연결부들로 구성된 딥 러닝 가속기 및 랜덤 액세스 메모리 를 갖는 집적 회로 디바이스를 도시한다. 예를 들어, 도 6의 집적 회로 디바이스의 딥 러닝 가속기, 랜덤 액세스 메모리, 및 연결부(11 9)는 도 1 및/또는 도 5에 예시된 것들과 유사한 방식으로 구성될 수 있다. 도 6의 집적 회로 디바이스는 랜덤 액세스 메모리에 동시에 액세스하는 데 사용될 수 있는 두 개의 외부 인터페이스들(106 및 107)을 갖는다. 예를 들어, 랜덤 액세스 메모리는 다른 것에 도달하지 않고 동시에 그리고 독립적으로 액세스될 수 있는 적어도 두 개의 부분들을 가질 수 있다. 이러한 부분들은 개별 집적 회로 다이들 상에 구성될 수 있거나, 동일 한 집적 회로 다이 상에 형성되는 메모리 셀들의 개별 평면들 또는 블록들에 구성될 수 있다. 한 부분은 인공 신경망(ANN)으로의 입력을 저장하도록 구성되며; 다른 부분은 인공 신경망(ANN)으로부터의 출력 을 저장하도록 구성된다. 두 개의 외부 인터페이스들(106 및 107)은 각각 입력 및 출력에 대한 부분들에 대한 개별 연결부들(108 및 109)로 구성된다. 따라서, 집적 회로 외부의 다른 디바이스들은 집적 회로 디바이스의 개별 외부 인터페이스들(106 및 107)을 사용하여 랜덤 액세스 메모리에 동시에 액세 스할 수 있다. 예를 들어, 중앙 처리 유닛(CPU)의 메모리 제어기는 CPU 메모리 인터페이스에 연결되어 인공 신경망 (ANN)으로부터의 이전 출력을 판독할 수 있는 반면, 직접 메모리 액세스(DMA) 제어기는 동시에 DMA 제어기 인터페이스에 연결되어 인공 신경망(ANN)에 다음 입력을 기록할 수 있다. 일 실시예에서, 연결부들(108 및 109)은 별도의 버스 세트 또는 와이어 세트를 갖는다. 따라서, 외부 인터페이 스들(106 및 107)은 입력 및 출력을 위해 랜덤 액세스 메모리의 다른 부분들에 액세스 시 버스 들 또는 와이어들을 공유하지 않는다. 대안적으로, 액세스 제어기는 인터페이스들(106 및 107)에 대해 별도의 버퍼들을 사용하고 고대역폭 연결부를 사용하여 랜덤 액세스 메모리와 인터페이스들(106 및 107)에 대한 버퍼들 사이에서 데이터를 전송하도록 구성되어 인터페이스들(106 및 107)이 기록 및 판독 요청들을 동시 에 서비스할 수 있도록 한다. 연결부의 대역폭은 집적 회로 디바이스의 외부 인터페이스들(106 및 107)에 대한 연결부들(108 및 109)에 의해 사용되는 대역폭보다 실질적으로 높기 때문에, 대역폭의 작은 부분이 연결부들(108 및 109)에 할당된다. 예를 들어, 인터페이스들(106 및 107)은 딥 러닝 가속기(DLA)의 메모리 인터페이스에 연결되어 연결부를 통해 랜덤 액세스 메모리에 액세스할 수 있다. 선택적으로, 딥 러닝 가속기(DLA)의 메모리 인터페이스, 중앙 처리 유닛(CPU)의 메모리 제어기에 대 한 인터페이스, 및 인터페이스는 랜덤 액세스 메모리에 동시에 액세스하도록 구성될 수 있다. 예를 들어, 랜덤 액세스 메모리는 다수의 입/출력 메모리 세트들로 구성될 수 있다. 각 세트는 메모리 인 터페이스를 서비스하거나 외부 인터페이스들(106 및 107)을 서비스하도록 선택적으로 구성될 수 있다. 메 모리 인터페이스를 서비스하기 위해 입/출력 메모리 세트가 선택되는 경우, 연결부는 딥 러닝 가속기(DLA)가 세트에 저장된 입력(예를 들어, 211)에 액세스하게 하고 인공 신경망(ANN)으로부터 세트로 출력(예를 들어, 213)을 저장하게 한다. 입/출력 메모리 세트가 외부 인터페이스들(106 및 107)을 서비스하기 위해 선택되는 경우, 서로 다른 메모리 영역들의 입력(예를 들어, 211) 및 출력(예를 들어, 213)은 별도의 외부 인터페이스들(106 및 107)에 의해 동시에 액세스될 수 있다. 한 입/출력 메모리 세트가 딥 러닝 가속기 (DLA)에 할당되어 입력 세트(예를 들어, 211)를 처리하고 해당 출력 세트(예를 들어, 213)를 생성하는 동 안, 하나 이상의 입/출력 메모리 세트들은 외부 인터페이스들(106 및 107)에 동시에 액세스가 가능하도록 할 수 있다. 일 실시예에 따른 방법에서, 집적 회로 디바이스는 인공 신경망의 행렬들 및 명령어들을 저장한다. 명령어들은 행렬들을 사용하여 인공 신경망을 구현하기 위해 집적 회로 디바이스 내에 포함된 적어도 하나의 처리 유닛에 의해 실행 가능하다. 집적 회로 디바이스, 또는 인쇄 회로 기판 상의 대안적으로 패키징된 컴퓨팅 디바이스는 랜덤 액세스 메모리를 갖는다. 집적 회로 디바이스 내에 포함된 랜덤 액세스 메모리는 인공 신경망으로의 제1 입력을 저장하고; 적어도 하나의 처리 유닛은 랜덤 액세스 메모리에 저장된 제1 입력으로부터 제1 출력을 생 성 시 명령어들을 실행하는 데 사용되거나 이를 실행하도록 유발된다. 제1 출력은 랜덤 액세스 메모리 에 저장된다. 이후, 집적 회로 디바이스 내에 포함된 랜덤 액세스 메모리는 인공 신경망으로의 제2 입력을 더 저장하고; 적어도 하나의 처리 유닛은 랜덤 액세스 메모리에 저장된 제2 입력으로부터 제2 출력을 생 성 시 명령어들을 실행하는 데 사용되거나 이를 실행하도록 유발된다. 적어도 하나의 처리 유닛이 제2 입력으로부터 제2 출력을 생성하기 위한 명령어들을 실행하는 동안, 외부 디바이스(예를 들어, 직접 메모리 액세스 제어기)는, 집적 회로 디바이스의 제1 인터페이스를 통해, 인공 신경망으로의 제3 입력을 집적 회로 디바이스의 랜덤 액세스 메모리에 기록한다. 동 시에, 다른 외부 디바이스(예를 들어, 중앙 처리 유닛)는 집적 회로 디바이스의 제2 인터페이스를 통 해, 제3 입력의 기록과 동시에 랜덤 액세스 메모리로부터 제1 출력을 판독한다. 예를 들어, 제3 입력의 기록은 직접 메모리 액세스 제어기에 연결된 제1 인터페이스를 통해 수행될 수 있 으며; 제1 출력의 판독은 중앙 처리 유닛에 연결된 제2 인터페이스를 통해 수행될 수 있다. 예를 들어, 집적 회로 디바이스는 집적 회로 패키지 내에 포함될 수 있고 처리 유닛들, 제어 유닛 및 로컬 메모리를 구비한 딥 러닝 가속기를 갖는다. 처리 유닛들은 두 개의 행렬 피연산 자들을 갖는 명령어들을 실행하도록 구성된 적어도 행렬-행렬 유닛을 포함한다. 행렬-행렬 유닛은 병 렬로 동작하도록 구성된 복수의 행렬-벡터 유닛들(141 내지 143)을 포함한다. 행렬-벡터 유닛들(141 내지 143) 각각은 병렬로 동작하도록 구성된 복수의 벡터-벡터 유닛들(161 내지 163)을 포함한다. 벡터-벡터 유닛들(161 내지 163) 각각은 병렬로 동작하도록 구성된 복수의 곱셈 누산 유닛들(171 내지 173)을 포함한다. 예를 들어, 컴파일러는 인공 신경망의 설명을 명령어들 및 행렬들로 변환하여 딥 러닝 가 속기를 사용하여 인공 신경망을 구현하는 데 사용될 수 있다. 일 구현에서, 제2 인터페이스를 통한 제1 출력의 판독, 제1 인터페이스를 통한 제3 입력의 기록, 딥 러닝 가속기가 제2 입력의 일부를 판독하는 것, 딥 러닝 가속기가 제2 출력의 일부를 랜덤 액세스 메 모리에 기록하는 것은 병렬로 동시에 수행될 수 있다. 예를 들어, 랜덤 액세스 메모리는 동시에 그리고 서로 독립적으로 사용될 수 있는 다수의 부분들을 가질 수 있다. 제1 부분은 인공 신경망으로부터의 제1 출력을 저장하도록 구성되고; 제2 부분은 인공 신경망 으로부터의 제3 입력을 저장하도록 구성되고; 제3 부분은 인공 신경망으로부터의 제2 출력을 저장하 도록 구성되고; 제4 부분은 인공 신경망으로부터의 제2 입력을 저장하도록 구성된다. 제3 및 제4 부분들이 명령어들의 실행 시 딥 러닝 가속기에 의해 사용될 때, 제1 인터페이스 및 제2 인터페이스는 각각 제 1 부분 및 제2 부분에 동시에 연결될 수 있다. 예를 들어, 다른 부분들은 병렬로 서로 독립적으로 동작할 수 있는 별도의 집적 회로 다이들(또는 평면들 또는 블록들)에 구성될 수 있다. 제1 인터페이스 및 제2 인터페이스는 제1 부분 및 제2 부분에 대한 연결부들을 공유 할 수 없다. 집적 회로 디바이스는 제1 인터페이스를 직접 메모리 액세스 제어기에 결합하도록 구성된 커넥터의 제1 커넥터 세트 및 제2 인터페이스를 중앙 처리 유닛에 결합하도록 구성된 제2 커넥터 세트를 갖는, 단일 집적 회로 패키지 내에 포함될 수 있다. 일부 구현들에서, 딥 러닝 가속기는 랜덤 액세스 메모리에 대한 고대역폭 연결부를 갖는 메모리 인터페이스를 가지며; 제1 인터페이스 및 제2 인터페이스는 딥 러닝 가속기의 메모리 인터 페이스를 통해 랜덤 액세스 메모리에 연결된다. 도 7은 일 실시예에 따른 카메라 인터페이스를 갖는 딥 러닝 가속기 및 랜덤 액세스 메모리를 갖는 집적 회로 디바이스를 도시한다. 예를 들어, 도 7의 집적 회로 디바이스의 딥 러닝 가속기, 랜덤 액세스 메모리, 및 연결부(11 9)는 도 1, 도 5 및/또는 도 6에 예시된 것들과 유사한 방식으로 구성될 수 있다. 도 7의 집적 회로 디바이스는 CPU 메모리 인터페이스 및 카메라 인터페이스를 포함하여, 동시에 사용될 수 있는 적어도 두 개의 외부 인터페이스들(221 및 107)을 갖는다. 도 7의 집적 회로 디바이스의 CPU 메모리 인터페이스는, 도 6의 집적 회로 디바이스의 CPU 메모 리 인터페이스와 유사한, 중앙 처리 유닛(CPU)의 메모리 제어기에 대한 연결부를 제공하도 록 구성된다. 도 7에서, CPU 메모리 인터페이스는 딥 러닝 가속기에 구현된다. 예를 들어, CPU 메모리 인터페이스 의 로직 회로는 딥 러닝 가속기의 집적 회로 다이 상에 형성될 수 있고; CPU 메모리 인터페이스(10 7)는 딥 러닝 가속기의 메모리 인터페이스를 사용하여 랜덤 액세스 메모리에 액세스한다. 대안적으로, CPU 메모리 인터페이스는 딥 러닝 가속기와 분리되고 도 6에 예시된 바와 같은 방식으로 구현될 수 있다. 예를 들어, 도 6에 예시된 바와 같이, CPU 메모리 인터페이스는 딥 러닝 가속기와 랜덤 액세스 메모리 사이의 연결부와 별도의 연결부를 사용하여 랜덤 액세스 메모리에 액 세스하도록 구성될 수 있다. 도 6의 집적 회로 디바이스는 도 7의 딥 러닝 가속기에 구현되는 CPU 메 모리 인터페이스와 유사한 방식으로, 딥 러닝 가속기(DLA)에 구현된 CPU 메모리 인터페이스 및/ 또는 DMA 제어기 인터페이스의 로직 회로를 갖도록 수정될 수도 있다. 도 7의 집적 회로 디바이스의 카메라 인터페이스는 카메라, 레이더, 라이더, 의료 영상 장비 등 과 같은 이미지 센서들 또는 이미지 생성기들을 포함하거나 사용하는 하나 이상의 디바이스들에 대한 연결부 를 제공하도록 구성된다. 예를 들어, 카메라에 대한 연결부는 MIPI 카메라 직렬 인터페이스(Camera Serial Interface; CSI) 프로토콜을 포함하는, 모바일 산업 프로세서 인터페이스(Mobile Industry Processor Interface; MIPI) 프로토 콜에 대한 표준에 따라 구현될 수 있다. 연결부는 카메라(또는 다른 이미지 생성기)의 이미징 동작들 을 제어하고 인공 신경망으로의 입력으로서 카메라(또는 다른 이미지 생성기)로부터 이미지 데 이터를 얻는 데 사용될 수 있다. 일 실시예에서, 연결부는 1080p, 4K, 8K 이상의 비디오 및 고해상도 사진 을 포함한, 고성능 애플리케이션들을 지원하는 MIPI CSI-2 표준에 따른 직렬 버스이다. 카메라 인터페이스는 이미지 데이터를 생성 시 카메라의 동작들을 제어하는데 사용될 수 있다. 예를 들어, 카메라 인터페이스는 카메라에 의해 제공되는 이미지 데이터의 해상도를 조정하기 위해 카메라 에 커맨드들을 전송하는데 사용될 수 있다. 예를 들어, 카메라 인터페이스를 통해 카메라로 전 송된 커맨드들은 카메라에 의해 제공되는 이미지 데이터의 프레임 레이트 및/또는 노출 시간을 조정할 수 있다. 예를 들어, 딥 러닝 가속기(DLA)는 카메라 인터페이스를 사용하여 이미지들을 캡처 및/또는 전 송 시 카메라의 동작들을 시작하거나 중지할 수 있다. 일부 구현들에서, 카메라 인터페이스는 관심 영역을 디지털 방식으로 주밍(zoom)하는 커맨드들을 선택적으 로 발행하고 따라서 연결부를 통해 전송될 데이터의 양과 카메라로부터 수신된 이미지 데이터에 대한 집적 회로 디바이스에 의해 수행될 계산의 양을 줄이는 데 사용될 수 있다. 일부 구현들에서, 카메라 인터페이스는 카메라의 뷰 포인트 및/또는 시야를 조정하기 위한 커맨드들 을 선택적으로 발행하는 데 사용될 수 있다. 도 7은 카메라 인터페이스가 딥 러닝 가속기에 구성된 일 구현을 예시한다. 예를 들어, 카메라 인터 페이스의 로직 회로의 적어도 일부는 딥 러닝 가속기의 집적 회로 다이 상에 형성되고; 카메라 인터페이스는 딥 러닝 가속기의 메모리 인터페이스를 사용하여 랜덤 액세스 메모리에 액세스할 수 있다. 예를 들어, 카메라 인터페이스는 연결부를 통해 카메라로부터 이미지를 수신할 수 있고 인공 신 경망으로의 입력으로서 랜덤 액세스 메모리에서 이미지 데이터를 버퍼링할 수 있다. 집적 회로 디바이스가 입력으로서 이미지 데이터 세트를 획득하면, 딥 러닝 가속기는 도 1, 도 5 및/또는 도 6의 디바이스와 유사한 방식으로, 명령어들을 실행하여 출력을 생성할 수 있다. 명령어들은 제어 유닛이 카메라 인터페이스를 동작시키고 인공 신경망으로의 입력으 로서 카메라 인터페이스를 통해 연결부를 통해 카메라로부터 이미지 데이터를 획득하기 위한 명 령어들을 선택적으로 포함할 수 있다. 도 7에서, 카메라 인터페이스는 딥 러닝 가속기에 구성된다. 대안적으로, 카메라 인터페이스는 도 6의 딥 러닝 가속기로부터 분리된 DMA 제어기 인터페이스와 유사한 방식으로, 딥 러닝 가속기 와 분리될 수 있고 딥 러닝 가속기와 랜덤 액세스 메모리 사이의 연결부와 분리된 연결부 를 사용하여 랜덤 액세스 메모리에 액세스하도록 구성될 수 있다. 도 6 및 7의 집적 회로 디바이스들은 CPU 메모리 인터페이스, DMA 제어기 인터페이스 및 카메라 인터페이스의 세 가지 외부 인터페이스들을 갖도록 수정될 수 있다. 선택적으로, 카메라 인터페이스 는 예를 들어 랜덤 액세스 메모리 로부터 출력(예를 들어, 213)을 검색하는 중앙 처리 유닛과 병렬로, 카메라로부터 랜덤 액세스 메모리로 이미지 데이터를 로드하기 위한 직접 메모리 액세스 제 어기를 포함할 수 있다. 카메라 인터페이스 및 DMA 제어기 인터페이스는 선택적으로 직접 메모리 액 세스 제어기들의 동작들을 지원하기 위한 로직 회로의 일부를 공유할 수 있다. 일 실시예에 따른 방법에서, 집적 회로 디바이스는 인공 신경망의 행렬들 및 명령어들을 저장한다. 명령어들은 행렬들을 사용하여 인공 신경망의 계산들을 구현하기 위해 집적 회로 디 바이스 내에 포함된 적어도 하나의 처리 유닛에 의해 실행 가능하다. 집적 회로 디바이스는 메 모리 제어기에 연결되도록 구성된 제1 인터페이스 및 카메라, 레이더, 라이더, 초음파 스캐너 또는 의료 영상 장비와 같은 이미지 생성기에 연결되도록 구성된 제2 인터페이스를 갖는다. 예를 들어, 제2 인터페이스는 카메라 커맨드 인터페이스 프로토콜 및/또는 모바일 산업 프로세서 인터페이 스(MIPI) 프로토콜을 구현한다. 예를 들어, 제2 인터페이스는 모바일 산업 프로세서 인터페이스(MIPI) 카 메라 직렬 인터페이스(CSI) 프로토콜에 따라 직렬 버스 연결부를 통해 카메라에 연결되도록 구성된다. 집적 회로 디바이스는 인공 신경망으로의 입력으로서 이미지 데이터를 수신하기 위해 제2 인터 페이스를 통해 이미지 생성기(예를 들어, 223)와 통신한다. 집적 회로 디바이스는 명령어들을 실행하여 입력에 따라 인공 신경망으로부터 출력을 생성한다. 집적 회로 디바이스는 인공 신경망으로부터의 출력을 집적 회로 디바이스 내에 포함된 랜 덤 액세스 메모리에 저장한다. 집적 회로 디바이스는 제1 인터페이스를 통해 메모리 제어기를 제어하는 중앙 처리 유닛에 출력을 제공한다. 예를 들어, 집적 회로 디바이스는, 이미지 생성기(예를 들어, 223)로부터의 이전 이미지 데이터 세트에 따 라 인공 신경망으로부터 이전에 생성된 출력을 버퍼링하는 것과 동시에 이를 제1 인터페이스를 통해 랜덤 액세스 메모리로부터 동시에 제공하는 동안, 제2 인터페이스를 통해 랜덤 액세스 메모리에 서 인공 신경망으로의 입력으로서 이미지 생성기(예를 들어, 223)로부터의 다음 이미지 데이터 세트를 버 퍼링할 수 있다. 예를 들어, 집적 회로 디바이스는 집적 회로 패키지 내에 포함될 수 있다. 집적 회로 디바이스는 처 리 유닛들, 제어 유닛 및 로컬 메모리를 갖는 딥 러닝 가속기를 갖는다. 처리 유닛들(11 1)은 적어도 두 개의 행렬 피연산자들을 갖는 명령어를 실행하도록 구성된 적어도 행렬-행렬 유닛을 포함 하고; 행렬-행렬 유닛은 병렬로 동작하도록 구성된 복수의 행렬-벡터 유닛들(141 내지 143)을 포함하고; 행렬-벡터 유닛들 각각은 병렬로 동작하도록 구성된 복수의 벡터-벡터 유닛들(161 내지 163)을 포함하고; 벡터-벡터 유닛들 각각은 병렬로 동작하도록 구성된 복수의 곱셈 누산 유닛들(171 내지 173)을 포함한다. 예를 들어, 집적 회로 디바이스는 제2 인터페이스를 통해 이미지 생성기(예를 들어, 223)에 커맨드를 전송할 수 있으며, 여기서 커맨드는 이미지 생성기(예를 들어, 223)에 의해 생성된 이미지 데이터의 해상도 또 는 프레임 레이트를 조정하도록 이미지 생성기(예를 들어, 223)에 지시한다. 예를 들어, 집적 회로 디바이스는, 제2 인터페이스를 통해, 이미지 생성기(예를 들어, 223)에 의해 생성된 이미지 데이터의 관심 영역, 시점 또는 시야를 조정하도록 이미지 생성기(예를 들어, 223)에 지시하는 다른 커맨드를 이미지 생성기(예를 들어, 223)에 전송할 수 있다. 도 8은 일 실시예에 따른 칩 상의 시스템을 도시한다. 도 8의 시스템은 집적 회로 디바이스에 패키징된다. 도 8의 집적 회로 디바이스는, 도 1, 도 5, 도 6 및/또는 도 7에 예시된 것들과 유사한 방식으로 구성될 수 있는, 딥 러닝 가속기, 랜덤 액세스 메모리 및 딥 러닝 가속기와 랜덤 액세스 메모리 사이의 연결부를 갖는다. 도 8의 집적 회로 디바이스는 중앙 처리 유닛(CPU)을 더 포함한다. 중앙 처리 유닛(CPU)은 하나 이상의 처리 코어들을 가질 수 있다. 중앙 처리 유닛(CPU)이 하나 이상의 처리 코어들을 가질 때, 중앙 처 리 유닛(CPU)의 다수의 처리 코어들은 서로 독립적으로 동작하고 병렬로 동작할 수 있다. 중앙 처리 유닛은 메모리 제어기를 갖는다. 연결부는 메모리 제어기와 랜덤 액세스 메모리 사이의 집적 회로 디바이스에 제공된다. 예를 들어, 디바이스의 집적 회로 패키지는 그 안에 포함된 집적 회로 다이들을 지지하기 위한 기판을 포함할 수 있다. 기판은 중앙 처리 유닛, 랜덤 액세스 메모리, 딥 러닝 가속기, 및/또는 입/출력 인터페이스와 같은 집적 회로 디바이스 내의 컴 포넌트들 사이에 연결부들(239, 238, 119)을 제공할 수 있다. 예를 들어, 집적 회로 디바이스의 연결부들 (예를 들어, 239, 238, 119) 및/또는 커넥터들(예를 들어, 핀들 또는 솔더 볼들)에 대한 연결부들을 제공하기 위해 인터포저(interposer)가 기판에 부착될 수 있다. 랜덤 액세스 메모리의 일부는 중앙 처리 유닛에 의해 사용하기 위해 예약될 수 있고 따라서 딥 러닝 가속기에 의해 사용되지 않는다. 이러한 부분은 중앙 처리 유닛에 의해 실행되도록 프로그래밍되는 애플리케이션 및/또는 운영 체제의 명령어들을 저장하는 데 사용될 수 있다. 애플리케이션의 실행 동 안 할당되고 사용되는 논리적 메모리는 메모리 제어기 및/또는 중앙 처리 유닛에 의해 실행되는 운영 체제에 의해 중앙 처리 유닛을 위해 예약된 랜덤 액세스 메모리의 부분의 물리적 메모리에 매핑될 수 있다. 랜덤 액세스 메모리의 다른 부분은 중앙 처리 유닛와 딥 러닝 가속기 사이에서 공유될 수 있다. 딥 러닝 가속기는 인공 신경망으로부터의 출력을 공유 부분에 기록할 수 있으며; 중앙 처리 유 닛은 중앙 처리 유닛에서 실시/실행되는 애플리케이션으로의 입력으로서 공유 부분으로부터 출 력을 판독할 수 있다. 예를 들어, 출력에 대해 구성된 공유 부분은 중앙 처리 유닛에 대해 판독 만될 수 있고 딥 러닝 가속기에 대해 기록만 될 수 있다. 랜덤 액세스 메모리의 추가 부분은 DLA 명령어들 및 행렬들에 의해 표현 및/또는 구현되는 인공 신경망으로의 입력을 버퍼링하는 데 사용될 수 있다. 집적 회로 디바이스는 이미지 센서, 마이크로폰 등과 같은 하나 이상의 센서들로부터 센서 데이터를 수신 하는 데 사용될 수 있는 입/출력 인터페이스를 갖는다. 수신된 센서 데이터는 인공 신경망으로의 입 력으로서 랜덤 액세스 메모리의 버퍼 부분에 저장될 수 있다. 예를 들어, 입/출력 인터페이스는 범용 직렬 버스(Universal Serial Bus; USB), 직렬 고급 기술 결합 (Serial Advanced Technology Attachment; SATA) 버스, 주변 컴포넌트 상호접속 익스프레스(Peripheral Component Interconnect Express; PCIe) 버스, 소형 컴퓨터 시스템 인터페이스(Small Computer System Interface; SCSI) 버스, 파이버 채널, 직렬 결합 SCSI(Serial Attached SCSI; SAS) 버스 또는 임의의 기타 버 스와 같은 주변 기기 버스에 대한 인터페이스일 수 있다. 예를 들어, 입/출력 인터페이스는 예를 들어 도 7에 예시된 바와 같이 그리고 카메라 또는 이미지 생성기 로부터 이미지 데이터를 수신하도록 구성된 카메라 인터페이스일 수 있다. 예를 들어, 입/출력 인터페이스는 예를 들어, 도 6에 예시된 바와 같이 그리고 직접 메모리 액세스 제어기 로부터 센서 데이터를 수신하도록 구성된 직접 메모리 액세스 제어기 인터페이스일 수 있다. 중앙 처리 유닛 및/또는 딥 러닝 가속기는 입/출력 인터페이스를 사용하여 버스에 구성된 센서 의 동작을 제어하고 센서로부터 센서 데이터를 수신할 수 있다. 추가 외부 디바이스들은 입/출력 인터페이스에 액세스할 수 있는 버스에 연결될 수 있다. 이러한 디바이스 들은 유선 또는 무선 근거리 통신망, 무선 개인 통신망, 무선 광역 통신망, 셀룰러 통신망 및/또는 인터넷과 같 은 유선 또는 무선 컴퓨터 연결부를 통해 통신하도록 구성된 통신 디바이스를 포함할 수 있다. 이러한 디바이스 들은 또한 디스플레이 디바이스, 모니터, 터치 스크린, 스피커, 키보드, 마우스, 터치 패드 및/또는 트랙 볼 등 을 포함하여 애플리케이션의 사용자 인터페이스를 표시할 수 있다. 입/출력 인터페이스를 통해, 중앙 처리 유닛에서 실행되는 애플리케이션은 버스에 연결된 디바이스들에 접근할 수 있다. 입/출력 인터페이스는 랜덤 액세스 메모리의 입력 부분에 대한 연결부를 갖는다. 연결부는 출력을 판독 시 및/또는 애플리케이션을 실행 시 (예를 들어, 센서 디바이스로부터) 랜덤 액세스 메 모리에 액세스하는 중앙 처리 유닛과 병렬로 랜덤 액세스 메모리로 입력을 로드하는 데 사 용될 수 있다. 중앙 처리 유닛 및 딥 러닝 가속기는 별도의 집적 회로 다이들에 형성될 수 있다. 예를 들어, 딥 러 닝 가속기는 랜덤 액세스 메모리의 하나 이상의 집적 회로 다이들 위에 적층된 집적 회로 다이 상에 형성될 수 있고; 중앙 처리 유닛은 랜덤 액세스 메모리의 하나 이상의 집적 회로 다이들 아래에 적층 된 추가 집적 회로 다이 상에 형성될 수 있다. 선택적으로, 중앙 처리 유닛을 위해 예약된 랜덤 액세스 메 모리의 일부는 중앙 처리 유닛 아래에 적층된 추가의 집적 회로 다이에 구성될 수 있다. 집적 회로 다이들은 실리콘 관통 비아를 사용하여 연결되어 연결부들(119 및 239)을 제공할 수 있다. 대안적으로, 중앙 처리 유닛 및 딥 러닝 가속기의 집적 회로 다이들이 랜덤 액세스 메모리의 집 적 회로 다이보다 크기가 더 작은 경우, 중앙 처리 유닛 및 딥 러닝 가속기 모두는 랜덤 액세스 메모 리의 집적 회로 다이 위(또는 아래)에 적층될 수 있다. 대안적으로, 집적 회로 다이는 연결부들을 제공하기 위해 와이어들로 구성되며; 와이어들이 있는 집적 회로 다 이는 중앙 처리 유닛, 딥 러닝 가속기 및 랜덤 액세스 메모리의 집적 회로 다이들을 지원하는 기판으로 사용된다. 기판 집적 회로 다이로부터 그 위에(및/또는 그 아래에) 적층된 다른 집적 회로 다이들까지 의 실리콘 관통 비아들(TSV들)은 연결부들(119, 239, 및/또는 238)을 제공하는 데 사용될 수 있다. 선택적으로, 입/출력 인터페이스의 신호 처리 회로는 기판 집적 회로 다이에 구성된다. 일부 구현들에서, 랜덤 액세스 메모리는 인공 신경망의 행렬들 및 딥 러닝 가속기에 대한 명령어들을 저장하도록 구성된 비휘발성 메모리를 포함한다. 예를 들어, 이러한 비휘발성 메모리는 딥 러 닝 가속기 위에 적층된 집적 회로 다이에 구성될 수 있다. 대안적으로, 딥 러닝 가속기 및 중앙 처리 유닛은 동일한 집적 회로 다이에 구성될 수 있다. 딥 러닝 가속기 및 중앙 처리 유닛은 선택적으로 메모리 인터페이스 및 메모리 제어기에 대한 회로 및 연결부들을 공유할 수 있다. 또한, 딥 러닝 가속기 및 중앙 처리 유닛은 랜덤 액세스 메모리(10 5)로부터 명령어들을 로드하도록 구성된 부분 로직 회로를 공유할 수 있다. 일부 구현들에서, 딥 러닝 가속기 의 행렬/벡터 처리 유닛들은 중앙 처리 유닛의 행렬/벡터 실행 유닛들로 구성된다. 예를 들어, 중앙 처리 유닛은 실행을 위해 랜덤 액세스 메모리로부터 명령어들(예를 들어, 215 및/또 는 205)을 로드하도록 구성된 로직 회로를 가질 수 있다. 행렬/벡터 명령어들은 처리 유닛들로 디스패치되 며; 다른 명령어들은 실행을 위해 중앙 처리 유닛의 산술 로직 유닛들(ALU들)로 디스패치된다. 처리 유닛 들은 랜덤 액세스 메모리로부터 행렬/벡터 피연산자들을 로드하고/하거나 랜덤 액세스 메모리에 결과들을 저장하기 위한 추가 회로들을 가질 수 있다. 따라서, 딥 러닝 가속기 및 중앙 처리 유닛은 인공 신경망의 명령어들을 실행 시 서로 협력될 수 있다. 도 9는 일 실시예에 따른 집적 회로 디바이스에서 구현되는 방법을 도시한다. 예를 들어, 도 9의 방법은 도 8의 집적 회로 디바이스에서 구현될 수 있다. 그러나 도 9의 방법은 도 5에 예시된 것과 유사하지만 인쇄 회로 기판 상에 구현된 대안적으로 패키징된 컴퓨팅 디바이스에서 구현될 수도 있다. 도 9의 방법에서, 딥 러닝 가속기 및 중앙 처리 유닛은 서로 실질적으로 독립적으로 동작할 수 있다. 딥 러닝 가속기는 인공 신경망에 따라 센서 데이터로부터 추론 결과들을 생성하며; 중앙 처리 유닛은인공 신경망으로부터의 추론 결과들을 사용할 수 있는 애플리케이션을 실행시킨다. 추론 결과들은 인입되는 센 서 데이터 스트림에 기초하여 주기적으로 업데이트될 수 있으며; 중앙 처리 유닛을 실행하는 애플리케이션 은 이전에 수신된 센서 데이터로부터 생성된 추론 결과들을 사용할 수 있다. 블록에서, 집적 회로 디바이스는, 그의 랜덤 액세스 메모리에, 인공 신경망의 행렬들 및 행렬들을 사용하여 인공 신경망을 구현하기 위해 집적 회로 디바이스 내에 포함된 적어도 하 나의 처리 유닛에 의해 실행 가능한 제1 명령어들을 저장한다. 블록에서, 집적 회로 디바이스 외부에 있는 버스에 대한 인터페이스를 통해, 센서 데이터는 인 공 신경망으로의 입력으로서 랜덤 액세스 메모리에 로드된다. 블록에서, 적어도 하나의 처리 유닛은 제1 명령어들을 실행하여 입력에 기초하여 인공 신 경망으로부터 출력을 생성한다. 블록에서, 집적 회로 디바이스는 인공 신경망으로부터의 출력을 랜덤 액세스 메모리 에 저장한다. 동작들(303 내지 307)은 서로 다른 시간 창들에서 생성된 센서 데이터에 대응하는 다수의 입력 세트에 대 해 반복될 수 있다. 미리 결정된 수의 출력 세트들이 랜덤 액세스 메모리에 저장된 후, 가장 오래된 세트는 최신 세트를 저장하도록 덮어쓰기될 수 있다. 일부 구현들에서, 다음 센서 데이터 세트를 랜덤 액세스 메모리에 로드하고/하거나 이전 센서 데이터 세트 로부터 생성된 출력을 랜덤 액세스 메모리에 저장하는 것은 현재 센서 데이터 세트로부터 출력을 생성하기 위해 제1 명령어들을 실행하는 것과 병렬로 수행될 수 있다. 블록에서, 집적 회로 디바이스는, 그의 랜덤 액세스 메모리에, 집적 회로 디바이스 내에 포함된 중앙 처리 유닛에 의해 실행되도록 프로그래밍된 적어도 하나의 애플리케이션의 제2 명령어들 을 저장한다. 블록에서, 중앙 처리 유닛은 인공 신경망으로부터의 출력을 사용하는 적어도 하나의 애플 리케이션의 제2 명령어들을 실행한다. 블록에서, 중앙 처리 유닛은, 랜덤 액세스 메모리로부터, 인공 신경망으로부터의 출력 을 판독한다. 블록에서, 중앙 처리 유닛은 적어도 하나의 애플리케이션의 실행 시 출력을 처리한다. 동작들(313 내지 317)은 상이한 시간 창들에서 생성된 센서 데이터에 대응하는 추론 결과들인 다수의 출력 세트에 대해 반복될 수 있다. 선택적으로, 중앙 처리 유닛은 딥 러닝 가속기가 인공 신경망으로부터 새로운 출력 세트의 생성을 시작하거나 중지하게 하는 표시를 제공할 수 있다. 선택적으로, 제1 명령어들의 실행 동안, 딥 러닝 가속기는 중앙 처리 유닛에서 실행될 루틴을 호출할 수 있다. 예를 들어, 이러한 루틴은 중앙 처리 유닛에 의해 실행되는 운영 체제에서 또는 애플리케 이션 또는 다른 애플리케이션에서 제공될 수 있다. 예를 들어, 이러한 루틴은 두 개의 행렬/벡터 피연산자 들을 포함하지 않고/하거나 중앙 처리 유닛의 산술 로직 유닛(ALU)에서 실행하기에 적합한 서비스를 제공 할 수 있다. 이러한 호출들을 용이하게 하기 위해 딥 러닝 가속기와 중앙 처리 유닛 사이에 신호 라 인들이 구성될 수 있다. 일부 구현들에서, 집적 회로 디바이스는 실리콘 관통 비아들(TSV들)을 사용하여 연결되는 다수의 적층형 집적 회로 다이들을 갖는다. 예를 들어, 딥 러닝 가속기는 적어도 하나의 처리 유닛, 제어 유닛, 처리 유닛(들)에 대한 행렬 피연산자들을 저장하도록 구성된 로컬 메모리, 및 랜덤 액세스 메모리에 대한 메모리 인터페이 스를 갖는 제1 집적 회로 다이에 구성될 수 있다. 랜덤 액세스 메모리는 적어도 하나의 제2 집적 회 로 다이 상에 구성될 수 있다. 중앙 처리 유닛은 제3 집적 회로 다이 상에 구성될 수 있다. 랜덤 액세스 메모리의 적어도 하나의 제 2 집적 회로 다이는 제1 집적 회로 다이와 제2 집적 회로 다이 사이에 적층될 수 있다. 딥 러닝 가속기의메모리 인터페이스 및 중앙 처리 유닛의 메모리 제어기는 별도의 실리콘 관통 비아(TSV) 세트들 을 사용하여 랜덤 액세스 메모리의 적어도 하나의 제2 집적 회로 다이에 연결될 수 있다. 대안적으로, 중앙 처리 유닛은 딥 러닝 가속기의 제1 집적 회로에 구성될 수 있으며; 중앙 처리 유닛 의 메모리 제어기 및 딥 러닝 가속기의 메모리 인터페이스는 랜덤 액세스 메모리에 대한 인터페이스를 공유하고/하거나 랜덤 액세스 메모리로부터 명령어들(205 및 215)을 로드하기 위한 로 직 회로를 공유할 수 있다. 일부 구현들에서, 제4 집적 회로 다이는 와이어들로 구성된다. 제1 집적 회로 다이 내의 딥 러닝 가속기, 적어도 제2 집적 회로 다이 내의 랜덤 액세스 메모리, 및/또는 제3 집적 회로 다이 내의(또는 제1 집적 회 로 다이 내의) 중앙 처리 유닛은 제4 집적 회로 다이의 와이어들을 사용하고 제4 집적 회로 다이로부터 다 른 집적 회로 다이들까지의 실리콘 관통 비아들(TSV들)을 사용하여 연결될 수 있다. 별도의 실리콘 관통 비아 (TSV) 세트들은 제1 집적 회로 다이 및 중앙 처리 유닛, 딥 러닝 가속기 및 랜덤 액세스 메모리(10 5)의 각각의 집적 회로 다이들의 와이어들로부터 연결될 수 있다. 선택적으로, 집적 회로 디바이스의 인터페이스의 회로는 또한 버스로 또는 버스로부터의 신호들을 처 리하기 위해 제4 집적 회로 다이 상에 구성된다. 예를 들어, 버스는 카메라, 마이크, 이미지 생성기 등과 같은 하나 이상의 센서 디바이스들에 대한 연결을 위해 범용 직렬 버스(USB), 직렬 고급 기술 결합(SATA) 버스 또는 주변 컴포넌트 상호접속 익스프레스(PCIe)의 프로토콜에 따라 구현될 수 있다. 본 개시는 이러한 방법들을 수행하는 데이터 처리 시스템들, 및 데이터 처리 시스템들 상에서 실행될 때 시스템 들이 이러한 방법들을 수행하게 하는 명령어들을 포함하는 컴퓨터 판독가능 매체를 포함하는, 위에서 설명된 방 법들을 수행하는 방법들 및 장치들을 포함한다. 전형적인 데이터 처리 시스템은 마이크로프로세서(들)와 메모리를 상호 연결하는 상호 연결부(예를 들어, 버스 및 시스템 코어 로직)를 포함할 수 있다. 마이크로프로세서는 전형적으로 캐시 메모리에 결합된다. 상호 연결부들은 마이크로프로세서(들)와 메모리를 함께 상호 연결하고 I/O 제어기(들)를 통해 입/출력(I/O) 디 바이스(들)에 이들을 상호 연결한다. I/O 디바이스들은 디스플레이 디바이스 및/또는 마우스, 키보드, 모뎀, 네 트워크 인터페이스, 프린터, 스캐너, 비디오 카메라 및 당업계에 알려진 기타 디바이스와 같은 주변 디바이스들 을 포함할 수 있다. 일 실시예에서, 데이터 처리 시스템이 서버 시스템인 경우, 프린터, 스캐너, 마우스 및/또 는 키보드와 같은 I/O 디바이스들 중 일부는 선택적이다. 상호 연결부는 다양한 브리지, 제어기 및/또는 어댑터를 통해 서로 연결된 하나 이상의 버스들을 포함할 수 있 다. 일 실시예에서 I/O 제어기들은 USB 주변기기를 제어하기 위한 USB(Universal Serial Bus) 어댑터 및/또는 IEEE-1394 주변기기를 제어하기 위한 IEEE-1394 버스 어댑터를 포함한다. 메모리는 ROM(Read Only Memory), 휘발성 RAM(Random Access Memory) 및 하드 드라이브, 플래시 메모리 등과 같은 비휘발성 메모리 중 하나 이상을 포함할 수 있다. 휘발성 RAM은 일반적으로 메모리의 데이터를 리프레시하거나 유지하기 위해 지속적으로 전원이 필요한 동적 RAM(DRAM)으로 구현된다. 비휘발성 메모리는 일반적으로 자기 하드 드라이브, 자기 광학 드라이브, 광학 드라이 브(예를 들어, DVD RAM) 또는 시스템으로부터 전원이 제거된 후에도 데이터를 유지하는 기타 유형의 메모리 시 스템이다. 비휘발성 메모리는 또한 랜덤 액세스 메모리일 수 있다. 비휘발성 메모리는 데이터 처리 시스템의 나머지 컴포넌트들에 직접 결합된 로컬 디바이스일 수 있다. 모뎀이나 이더넷 인터페이스와 같은 네트워크 인터페이스를 통해 데이터 처리 시스템에 결합된 네트워크 저장 디바이스와 같이 시스템으로부터 멀리 떨어진 비휘발성 메모리도 사용될 수 있다. 본 개시에서, 설명을 단순화하기 위해 일부 기능들 및 동작들은 소프트웨어 코드에 의해 수행되거나 발생되는 것으로 설명된다. 그러나 이러한 표현들은 또한 기능들이 마이크로프로세서와 같은 프로세서에 의한 코드/명령 어들 실행으로부터의 결과임을 명시하는 데 사용된다. 대안적으로 또는 조합하여, 본원에 설명된 기능들 및 동작들은 애플리케이션별 집적 회로(Application-Specific Integrated Circuit; ASIC) 또는 필드 프로그래머블 게이트 어레이(Field-Programmable Gate Array; FPGA)를 사용하는 것과 같이 소프트웨어 명령어들을 사용하든 사용하지 않든 특수 목적 회로부를 사용하여 구현될 수 있 다. 실시예들은 소프트웨어 명령어들 없이 또는 소프트웨어 명령어들과 조합하여 하드와이어링된 회로부를 사용 하여 구현될 수 있다. 따라서 기술들은 하드웨어 회로부와 소프트웨어의 임의의 특정 조합이나 데이터 처리 시스템에 의해 실행되는 명령어들에 대한 임의의 특정 소스로 제한되지 않는다. 일 실시예는 완전히 기능하는 컴퓨터들 및 컴퓨터 시스템들에서 구현될 수 있지만, 다양한 실시예들은 다양한 형태로 컴퓨팅 제품으로서 배포될 수 있고 실제로 배포에 영향을 미치는데 사용되는 특정 유형의 기계 또는 컴 퓨터 판독 가능 매체에 관계없이 적용될 수 있다. 개시된 적어도 일부 양태들은 적어도 부분적으로 소프트웨어로 구현될 수 있다. 즉, 기술들은 마이크로프로세서 와 같은 프로세서가 ROM, 휘발성 RAM, 비휘발성 메모리, 캐시 또는 원격 저장 디바이스와 같은 메모리에 포함된 일련의 명령어들을 실행시키는 것에 응답하여 컴퓨터 시스템 또는 기타 데이터 처리 시스템에서 수행될 수 있다. 실시예들을 구현하기 위해 실행되는 루틴들은 운영 체제 또는 \"컴퓨터 프로그램\"이라고 하는 특정 애플리케이션, 컴포넌트, 프로그램, 객체, 모듈 또는 일련의 명령어들의 일부로 구현될 수 있다. 컴퓨터 프로그 램은 일반적으로 컴퓨터의 다양한 메모리 및 저장 디바이스들에 다양한 시간에 설정된 하나 이상의 명령어들을 포함하며, 컴퓨터의 하나 이상의 프로세서들에 의해 판독 및 실행될 때 컴퓨터가 다양한 양태들과 관련된 요소 들을 실행하는 데 필요한 동작들을 수행하게 한다. 기계 판독 가능 매체는 데이터 처리 시스템에 의해 실행될 때 시스템이 다양한 방법들을 수행하도록 하는 소프 트웨어 및 데이터를 저장하는 데 사용될 수 있다. 실행 가능한 소프트웨어 및 데이터는 예를 들어 ROM, 휘발성 RAM, 비휘발성 메모리 및/또는 캐시를 포함하는 다양한 장소들에 저장될 수 있다. 이 소프트웨어 및/또는 데이 터의 부분들은 이러한 저장 디바이스들 중 어느 하나에 저장될 수 있다. 또한 데이터 및 명령어들은 중앙 집중 식 서버들 또는 피어 투 피어 네트워크들로부터 획득될 수 있다. 데이터 및 명령어들의 서로 다른 부분들은 서 로 다른 시간에 서로 다른 통신 세션들에서 또는 동일한 통신 세션에서 서로 다른 중앙 집중식 서버들 및/또는 피어 투 피어 네트워크들로부터 획득될 수 있다. 데이터 및 명령어들은 애플리케이션들을 실행하기 전에 전체적 으로 획득될 수 있다. 대안적으로, 데이터 및 명령어들의 부분들은 실행에 필요할 때 적시에 동적으로 획득될 수 있다. 따라서, 데이터와 명령어들이 특정 시간에 완전히 기계 판독 가능한 매체에 있을 필요는 없다. 컴퓨터 판독 가능 매체의 예들은, 그중에서도, 이에 제한되는 것은 아니나, 휘발성 및 비휘발성 메모리 디바이 스들, 읽기 전용 메모리(ROM), 랜덤 액세스 메모리(RAM), 플래시 메모리 디바이스, 플로피 및 기타 이동식 디스 크, 자기 디스크 저장 매체, 광 저장 매체(예를 들어, 콤팩트 디스크 읽기 전용 메모리(CD ROM), 디지털 다용도 디스크들(DVD들) 등과 같은 비일시적 기록 가능 및 비-기록 가능 유형의 매체를 포함한다. 컴퓨터 판독가능 매 체는 명령어들을 저장할 수 있다. 명령어들은 또한 반송파, 적외선 신호, 디지털 신호 등과 같은 전파 신호의 전기적, 광학적, 음향적 또는 기타 형태에 대한 디지털 및 아날로그 통신 링크들로 구현될 수 있다. 그러나 반송파, 적외선 신호, 디지털 신호 등 과 같은 전파 신호들은 유형의(tangible) 기계 판독 가능 매체가 아니며 명령어들을 저장하도록 구성되지 않는 다. 일반적으로, 기계 판독 가능 매체는 기계(예를 들어, 컴퓨터, 네트워크 디바이스, 개인 휴대 정보 단말기, 제조 도구, 하나 이상의 프로세서 세트를 갖는 임의의 디바이스 등)에 의해 액세스 할 수 있는 형태로 정보를 제공하 는 임의의 메커니즘을 포함한다. 다양한 실시예들에서, 하드와이어링된 회로부는 기술들을 구현하기 위해 소프트웨어 명령어들과 조합하여 사용 될 수 있다. 따라서 기술들은 하드웨어 회로부와 소프트웨어의 임의의 특정 조합으로 제한되지 않고 데이터 처 리 시스템에 의해 실행되는 명령어들에 대한 임의의 특정 소스로도 제한되지 않는다. 상기 설명 및 도면들은 예시적이며 제한하는 것으로 해석되어서는 안 된다. 철저한 이해를 제공하기 위해 여러 가지 구체적인 세부 사항이 설명된다. 그러나 특정 경우에, 잘 알려져 있거나 일반적인 세부 사항들은 설명을 모호하게 하는 것을 피하기 위해 설명되지 않는다. 본 개시에서 하나 또는 일 실시예에 대한 참조는 반드시 동 일한 실시예에 대한 참조는 아니며; 이러한 참조는 적어도 하나를 의미한다. 전술한 명세서에서, 본 개시는 그 특정 예시적인 실시예들을 참조하여 설명되었다. 하기 청구범위에 기재된 바 와 같은 더 넓은 정신 및 범위를 벗어나지 않고 다양한 수정들이 이루어질 수 있음이 명백할 것이다. 따라서, 본 명세서 및 도면들은 제한적인 의미가 아니라 예시적인 의미로 간주되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2022-7038781", "section": "도면", "subsection": "도면설명", "item": 1, "content": "실시예들은 유사한 참조 부호들이 유사한 요소들을 나타내는 첨부 도면들의 도면들로 제한되는 것이 아니라 예 시의 방식으로 예시된다. 도 1은 일 실시예에 따라 구성된 딥 러닝 가속기 및 랜덤 액세스 메모리를 갖는 집적 회로 디바이스를 도시한다. 도 2는 일 실시예에 따라 행렬-행렬 연산들을 수행하도록 구성된 처리 유닛을 도시한다. 도 3은 일 실시예에 따라 행렬-벡터 연산들을 수행하도록 구성된 처리 유닛을 도시한다. 도 4는 일 실시예에 따라 벡터-벡터 연산들을 수행하도록 구성된 처리 유닛을 도시한다. 도 5는 일 실시예에 따른 훈련된 인공 신경망에 입력들을 자율적으로 적용하도록 구성된 딥 러닝 가속기 및 랜 덤 액세스 메모리를 도시한다. 도 6은 일 실시예에 따른 별도의 메모리 액세스 연결부들로 구성된 딥 러닝 가속기 및 랜덤 액세스 메모리를 갖 는 집적 회로 디바이스를 도시한다. 도 7은 일 실시예에 따른 카메라 인터페이스를 갖는 딥 러닝 가속기 및 랜덤 액세스 메모리를 갖는 집적 회로 디바이스를 도시한다. 도 8은 일 실시예에 따른 칩 상의 시스템을 도시한다. 도 9는 일 실시예에 따른 집적 회로 디바이스에서 구현되는 방법을 도시한다."}
