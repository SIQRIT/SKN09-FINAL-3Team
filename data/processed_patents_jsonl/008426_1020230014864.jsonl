{"patent_id": "10-2023-0014864", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0122105", "출원번호": "10-2023-0014864", "발명의 명칭": "이미지 데이터 내 바운딩 박스에 고유값 할당을 통해 이미지 데이터 내 객체를 인식하는 방법", "출원인": "순천향대학교 산학협력단", "발명자": "남윤영"}}
{"patent_id": "10-2023-0014864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이미지 인식 장치에 의해 수행되는 방법에 있어서, 이미지 데이터를 로딩 하는 단계;이미지 데이터를 전처리 하는 단계; 학습된 딥러닝 모델을 통해 이미지 데이터 내 객체 인식값을 출력하는 단계; 및 딥 러닝 모델에 객체 인식값을 입력하여 딥 러닝 모델을 업데이트 하는 단계; 를 포함하는이미지 데이터 내 바운딩 박스에 고유값 할당을 통해 이미지 데이터 내 객체를 인식하는 방법."}
{"patent_id": "10-2023-0014864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 학습된 딥러닝 모델을 통해 이미지 데이터 내 객체 인식값을 출력하는 단계는 제1 시점에서 이미지 데이터 내바운딩 박스 데이터를 추출하는 단계를 더 포함하는 이미지 데이터 내 바운딩 박스에 고유값 할당을 통해 이미지 데이터 내 객체를 인식하는 방법."}
{"patent_id": "10-2023-0014864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 학습된 딥러닝 모델을 통해 이미지 데이터 내 객체 인식값을 출력하는 단계는 바운딩 박스 데이터 내 특징 맵을추출하고, 이에 대응하는 고유값인 제1 ID를 할당하는 단계를 더 포함하는 이미지 데이터 내 바운딩 박스에 고유값 할당을 통해 이미지 데이터 내 객체를 인식하는 방법."}
{"patent_id": "10-2023-0014864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 학습된 딥러닝 모델을 통해 이미지 데이터 내 객체 인식값을 출력하는 단계는 제2 시점에서 바운딩 박스 데이터내 특징 맵을 추출하는 단계를 더 포함하는 이미지 데이터 내 바운딩 박스에 고유값 할당을 통해 이미지 데이터 내 객체를 인식하는 방법."}
{"patent_id": "10-2023-0014864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 학습된 딥러닝 모델을 통해 이미지 데이터 내 객체 인식값을 출력하는 단계는 복수의 특징 맵에 대해서 유사도를 비교하여 제2 시점에서 바운딩 박스 내 특징 맵에 대응하는 고유값인 제2 ID를 할당하는 단계를 더 포함하는 이미지 데이터 내 바운딩 박스에 고유값 할당을 통해 이미지 데이터 내 객체를 인식하는 방법."}
{"patent_id": "10-2023-0014864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 제1 시점과 제2 시점은 서로 상이한 이미지 데이터 내 바운딩 박스에 고유값 할당을 통해 이미지 데이터 내 객체를 인식하는 방법."}
{"patent_id": "10-2023-0014864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2024-0122105-3-프로세서; 네트워크 인터페이스;메모리; 및 상기 메모리에 로드(Load)되고, 상기 프로세서에 의해 실행되는 컴퓨터 프로그램을 포함하되,상기 프로세서는,이미지 데이터를 로딩 하는 인스트럭션; 이미지 데이터를 전처리 하는 인스트럭션;학습된 딥러닝 모델을 통해 이미지 데이터 내 객체 인식값을 출력하는 인스트럭션; 및 딥 러닝 모델에 객체 인식값을 입력하여 딥 러닝 모델을 업데이트 하는 인스트럭션; 를 포함하여 수행하는이미지 데이터 내 바운딩 박스에 고유값 할당을 통해 이미지 데이터 내 객체를 인식하는 장치."}
{"patent_id": "10-2023-0014864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 딥 러닝 모델에 객체 인식값을 입력하여 딥 러닝 모델을 업데이트 하는 인스트럭션은 제1 시점에서 이미지 데이터 내 바운딩 박스 데이터를 추출하는 인스트럭션을 더 포함하여 수행하는이미지 데이터 내 바운딩 박스에 고유값 할당을 통해 이미지 데이터 내 객체를 인식하는 장치."}
{"patent_id": "10-2023-0014864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 딥 러닝 모델에 객체 인식값을 입력하여 딥 러닝 모델을 업데이트 하는 인스트럭션은 바운딩 박스 데이터 내 특징 맵을 추출하고, 이에 대응하는 고유값인 제1 ID를 할당하는 인스트럭션을 더 포함하여 수행하는이미지 데이터 내 바운딩 박스에 고유값 할당을 통해 이미지 데이터 내 객체를 인식하는 장치."}
{"patent_id": "10-2023-0014864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 딥 러닝 모델에 객체 인식값을 입력하여 딥 러닝 모델을 업데이트 하는 인스트럭션은 제2 시점에서 바운딩 박스데이터 내 특징 맵을 추출하는 인스트럭션을 더 포함하여 수행하는이미지 데이터 내 바운딩 박스에 고유값 할당을 통해 이미지 데이터 내 객체를 인식하는 장치."}
{"patent_id": "10-2023-0014864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 딥 러닝 모델에 객체 인식값을 입력하여 딥 러닝 모델을 업데이트 하는 인스트럭션은 복수의 특징 맵에 대해서유사도를 비교하여 제2 시점에서 바운딩 박스 내 특징 맵에 대응하는 고유값인 제2 ID를 할당하는 인스트럭션을더 포함하여 수행하는 이미지 데이터 내 바운딩 박스에 고유값 할당을 통해 이미지 데이터 내 객체를 인식하는 장치."}
{"patent_id": "10-2023-0014864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 제1 시점과 제2 시점은 서로 상이한 이미지 데이터 내 바운딩 박스에 고유값 할당을 통해 이미지 데이터 내 객체를 인식하는 장치.공개특허 10-2024-0122105-4-"}
{"patent_id": "10-2023-0014864", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 이미지 인식 장치에 의해 수행되는 방법에 있어서, 이미지 데이터를 로딩 하는 단계, 이미지 데이터를 전처리 하는 단계, 학습된 딥러닝 모델을 통해 이미지 데이터 내 객체 인식값을 출력하는 단계 및 딥 러닝 모델 에 객체 인식값을 입력하여 딥 러닝 모델을 업데이트 하는 단계를 포함하는 이미지 데이터 내 바운딩 박스에 고 유값 할당을 통해 이미지 데이터 내 객체를 인식하는 방법 및 그 장치에 관한 것이다."}
{"patent_id": "10-2023-0014864", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이미지 데이터 내 바운딩 박스에 고유값 할당을 통해 이미지 데이터 내 객체를 인식하는 방법 및 그 장치에 관한 것으로서, 보다 구체적으로는 이미지 데이터에서 CNN과 YOLO, 딥 러닝 알고리즘을 활용하여 객체를 보다 효율적으로 인식하는 방법 및 그 장치에 관한 것이다."}
{"patent_id": "10-2023-0014864", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥 러닝 기술은 기계학습의 기술 중 하나로 인간이 사고하는 방식과 유사하게 구조를 설계하여 데이터를 지속적 으로 분석 및 처리하는 기술을 말한다. 90년대 이후 여러 모델이 논의된 이후 하드웨어의 성능과 향상 및 전산 능력 증대로 인해 딥 러닝 기술은 고도화되며 발전하고 있다. 그 중 딥 러닝 기술이 활발히 활용되고 있는 분야는 이미지 인식 및 객체 분류 분야이다. 이 분야에서 딥 러닝 기술은 이미지 내에 객체를 인식하고, 그 객체가 어떠한 객체인 지 분류하는 지를 빠르고 효율적으로 수행하도 록 개발되고 있다. 일 예로, 딥 러닝 모델은 합성곱 신경망인 CNN, You Only looks once, YOLO 모델 등을 포함하고 있으며, 여기서 YOLO는 이미지를 한번 보는 것으로 객체의 위치를 추측할 수 있는 딥 러닝 기반의 알고리즘을 뜻한다. 따라서, 딥 러닝 모델의 가장 기본이라 할 수 있는 합성곱 신경망인 CNN과 YOLO 모델을 활용하여 이미지 데이터 내에 객체를 보다 빠르고 효율적으로 인식 및 분류하는 내용에 대해 구체적인 기술 개발 및 기술 논의가 필요한 실정이다."}
{"patent_id": "10-2023-0014864", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공지된 기술이라 할 수는 없다."}
{"patent_id": "10-2023-0014864", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 개시를 통해 해결하고자 하는 과제는 이미지 데이터 내에서 객체를 인식하고 객체를 분류하는 이미지 인식 방법 및 장치를 제공하는 것에 있다. 또한, 본 발명의 개시를 통해 해결하고자 하는 과제는 이미지 데이터에서 객체를 판단하는 바운딩 박스를 설정 하고, 바운딩 박스의 특징 맵에 대응하는 고유값인 ID를 부여하여 보다 빠르게 객체를 인식하는 방법 및 장치를 제공하는 것에 있다. 또한, 본 발명의 개시를 통해 해결하고자 하는 과제는 시점이 변화함에 따라 기존 바운딩 박스의 특징 맵에 대 응하는 고유값을 새로운 바운딩 박스의 특징 맵에 대응하는 고유값과 유사함을 비교하여, 새로운 고유값을 부여 할 지를 판단하는 방법 및 장치를 제공하는 것에 있다."}
{"patent_id": "10-2023-0014864", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 몇몇 실시예를 통해 해결하고자 하는 과제에 관해 이미지 인식 장치에 의해 수행되는 방법에 있어서, 이미지 데이터를 로딩 하는 단계, 이미지 데이터를 전처리 하는 단계, 학습된 딥러닝 모델을 통해 이미지 데이 터 내 객체 인식값을 출력하는 단계 및 딥 러닝 모델에 객체 인식값을 입력하여 딥 러닝 모델을 업데이트 하는 단계를 포함할 수 있다. 일 실시 예에 있어서, 학습된 딥러닝 모델을 통해 이미지 데이터 내 객체 인식값을 출력하는 단계는 제1 시점에 서 이미지 데이터 내 바운딩 박스 데이터를 추출하는 단계를 더 포함할 수 있다. 일 실시 예에 있어서, 학습된 딥러닝 모델을 통해 이미지 데이터 내 객체 인식값을 출력하는 단계는 바운딩 박 스 데이터 내 특징 맵을 추출하고, 이에 대응하는 고유값인 제1 ID를 할당하는 단계를 더 포함할 수 있다. 일 실시 예에 있어서, 학습된 딥러닝 모델을 통해 이미지 데이터 내 객체 인식값을 출력하는 단계는 제2 시점에 서 바운딩 박스 데이터 내 특징 맵을 추출하는 단계를 더 포함할 수 있다. 일 실시 예에 있어서, 학습된 딥러닝 모델을 통해 이미지 데이터 내 객체 인식값을 출력하는 단계는 복수의 특 징 맵에 대해서 유사도를 비교하여 제2 시점에서 바운딩 박스 내 특징 맵에 대응하는 고유값인 제2 ID를 할당하 는 단계를 더 포함할 수 있다. 일 실시 예에 있어서, 상기 제1 시점과 제2 시점은 서로 상이할 수 있다."}
{"patent_id": "10-2023-0014864", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 과제 해결 수단에 의하면, 이미지 데이터 내에서 객체를 인식하고 객체를 분류하는 이미지 인 식 방법 및 장치를 제공할 수 있다. 또한, 본 발명의 과제 해결 수단에 의하면 이미지 데이터에서 객체를 판단하는 바운딩 박스를 설정하고, 바운딩 박스의 특징 맵에 대응하는 고유값인 ID를 부여하여 보다 빠르게 객체를 인식하는 방법 및 장치를 제공할 수 있 다. 또한, 본 발명의 과제 해결 수단에 의하면 시점이 변화함에 따라 기존 바운딩 박스의 특징 맵에 대응하는 고유 값을 새로운 바운딩 박스의 특징 맵에 대응하는 고유값과 유사함을 비교하여, 새로운 고유값을 부여할 지를 판 단하는 방법 및 장치를 제공할 수 있다."}
{"patent_id": "10-2023-0014864", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 개시의 바람직한 실시예들을 상세 히 설명한다. 본 개시의 이점 및 특징, 그 리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 개시의 기술적 사상은 이하의 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구 현될 수 있으며, 단지 이하의 실시예들은 본 개시의 기술적 사상을 완전하도록 하고, 본 개시가 속하는 기술분 야에서 통상의 지식을 가진 자에게 본 개시의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 개시의 기술 적 사상은 청구항의 범주에 의해 정의될 뿐이다. 각 도면의 구성 요소들에 참조부호를 부가함에 있어서, 동일한 구성 요소들에 대해서는 비록 다른 도면상에 표 시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 개시를 설명함에 있어, 관 련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상 세한 설명은 생략한다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있다. 또 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 개시를 제한하고자 하는 것은 아니 다. 본 명세서에서, 단수형은 문 구에서 특별히 언급하지 않는 한 복수형도 포함한다. 또한, 본 개시의 구성 요소를 설명하는 데 있어서, 제1, 제2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이 러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질 이나 차례 또는 순서 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성 요소에 \"연결\", \"결합\" 또는 \"접속\"된 다고 기재된 경우, 그 구성 요소는 그 다른 구성 요소에 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구 성 요소 사이에 또 다른 구성 요소 가 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다.명세서에서 사용되는 \"포함한다(comprises)\" 및/또는 \"포함하는 (comprising)\"은 언급된 구성 요소, 단계, 동작 및/또는 소자는 하나 이상의 다른 구성 요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 이하, 본 개시의 다양한 실시예들에 대하여 첨부된 도면에 따라 상세하게 설명한다. 또한, 본 발명의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본 질이나 차례 또는 순서 등이 한정되지 않는다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 '포함', '구비' 한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재된 '부', '모듈' 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현 될 수 있다. 도 1에 도시된 이미지 수집 장치 및 이미지 인식 장치가 포함된 시스템을 통해 이미지 인식 장치 는 이미지가 입력되면 이미지 내 객체를 인식하고, 이를 적어도 하나 이상의 분류 기준에 따라 분류할 수 있다. 이러한 과정은 이미지 인식 장치가 지도학습 알고리즘인 딥 러닝 알고리즘을 기반으로 라벨링 데이 터를 포함하는 학습 데이터를 통해 기 학습되고, 학습의 결과로 이러한 동작을 수행할 수 있다. 이하에서는 상술한 시스템을 통해 제공되는 이미지가 입력되면 이를 인식하고 분류하는 동작과 관련된 도 1에 도시된 구성 요소들의 동작들에 대해 보다 구체적으로 설명하기로 한다. 도 1은 이미지 수집 장치와 이미지 인식 장치가 네트워크를 통해 연결된 예를 도시하고 있으나, 이는 이해의 편의를 제공하기 위한 것일 뿐이고, 네트워크에 연결될 수 있는 장치의 개수는 얼마든지 달라질 수 있다. 한편, 도 1은 본 개시의 목적을 달성하기 위한 바람직한 실시예를 도시하고 있을 뿐이며, 필요에 따라 일부 구 성 요소가 추가되거나 삭제될 수 있다. 이하, 도 1에 도시된 구성 요소들에 대해 보다 구체적으로 설명하기로 한다. 이미지 인식 장치는 이미지 수집 장치에서 입력되는 적어도 하나 이상의 이미지 데이터에서 객체를 인식하고, 이를 객체 분류 기준에 따라 분류할 수 있다. 이미지 수집 장치는 이미지 데이터가 저장되어 있는 장치일 수 있다. 이미지 수집 장치는 네트워크를 통해 통신할 수 있다. 상기 네트워크는 근거리 통신망 (Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 이동 통신망 (mobile radio communication network), Wibro(Wireless Broadband Internet) 등 과 같은 모든 종류의 유/무선 네트워크로 구현될 수 있다. 이미지 수집 장치은 네트워크를 통해 이미지 데 이터를 지속적으로 획득할 수 있으며, 이러한 이미지 데이터는 이미지 수집 장치에 저장되고 이미지 인식 장치로 송신될 수 있다. 이미지 인식 장치는 수집된 다양한 이미지 데이터를 기초로 딥 러닝 알고리즘을 활용하여 이미지 내 객체 를 인식하고, 이를 분류할 수 있다. 중복된 설명을 배제하기 위해, 이미지 인식 장치가 수행하는 다양한 동작들에 대해서는 추후 도 2 이하의 도면을 참조하여 보다 상세히 설명하도록 한다. 한편, 이미지 인식 장치는 하나 이상의 컴퓨팅 장치로 구현될 수 있다. 예를 들어, 이미지 인식 장치(20 0)의 모든 기능은 단일 컴퓨팅 장치에서 구현될 수 있다. 다른 예로써, 이미지 인식 장치의 제1 기능은 제 1 컴퓨팅 장 치에서 구현되고, 제2 기능은 제2 컴퓨팅 장치에서 구현될 수도 있다. 여기서, 컴퓨팅 장치는, 노 트북, 데스크톱(desktop), 랩탑(laptop) 등이 될 수 있으나, 이에 국한되는 것은 아니며 컴퓨팅 기능이 구비된 모든 종류의 장치를 포함할 수 있다. 다만, 이미지 인식 장치는 고성능의 서버급 컴퓨팅 장치로 구현되는 것이 바람직할 수 있다. 컴퓨팅 장치의 일례에 대해서는 도 6를 참조하여 설명하기로 한다. 나아가, 이미지 수 집 장치 역시 하나 이상의 컴퓨팅 장치로 구현될 수 있음은 당연하다. 몇몇 실시예에서, 이미지 인식 장치가 적용된 환경에 포함된 구성 요소들은 네트워크를 통해 통신할 수 있 다. 상기 네트워크는 근거리 통신망 (Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 이동 통신망 (mobile radio communication network), Wibro(Wireless Broadband Internet) 등과 같은 모든 종류의유/무선 네트워크로 구현될 수 있다. 한편, 도 1에 도시된 환경은 이미지 수집 장치와 이미지 인식 장치 를 경유하여 네트워크를 통해 연 결된 것을 도시하고 있으나, 본 개시의 범위가 이에 한정되는 것은 아니고, 이미지 수집 장치들이 P2P(Peer to Peer)로 연결될 수도 있음을 유의해야 한다. 지금까지 도 1을 참조하여, 본 개시의 몇몇 실시예에 따른 이미지 인식 장치가 적용될 수 있는 예시적인 환경을 설명하였다. 이하, 도 2 이하의 도면들을 참조하여, 본 개시의 다양한 실시예에 따른 방법들에 대하여 상세하게 설명하기로 한다. 후술될 방법들의 각 단계는 컴퓨팅 장치에 의해 수행될 수 있다. 다시 말하면, 방법들의 각 단계는 컴퓨팅 장치 의 프로세서에 의해 실행되는 하나 이 상의 인스트럭션들로 구현될 수 있다. 이러한 방법들에 포함되는 모든 단 계는 하나의 물리적인 컴퓨팅 장치에 의하여 실행될 수도 있을 것이나, 방법의 제1 단계들은 제1 컴퓨팅 장치에 의하여 수행되고, 방법의 제2 단계들은 제2 컴퓨팅 장치에 의하여 수행될 수도 있다. 이하 도 2에서는, 방법들의 각 단계가 도 1에 예시된 이미지 인식 장치에 의해 수행되는 것을 가정하여 설 명을 이어가도록 한다. 다만, 설명의 편의상, 방법들에 포함되는 각 단계의 동작 주체는 그 기재가 생략될 수도 있다. 또한, 본 발명에서 기계학습, 딥러닝, 인공지능, AI 알고리즘은 모두 동일하게 사용될 수 있는 용어이며, 범용 적으로는 통상의 기술자가 이해할 수 있는 범위에서 기계학습 알고리즘을 모두 통칭할 수 있음에 유의해야 한다. 도 2는 본 개시의 몇몇 실시예에 따라 이미지 인식 장치에서 수행될 수 있는 이미지 데이터 내에서 객체를 인식 하는 방법에 관한 순서도이다. 단계 S100에서, 이미지 인식 장치는 이미지 데이터를 이미지 수집 장치로부터 로딩할 수 있다. 이미 지 인식 장치는 이미지 데이터를 획득할 수 있다. 이미지 인식 장치는 이미지 수집 장치를 통해 이미지 데이터를 수신 받을 수 있고, 이미지 인식 장치는 상기 이미지 데이터를 딥 러닝 모델을 학습하는 데 활용할 수 있다. 상기 이미지 데이터는 이미지 내 객체가 포함되어 있는 2D 이미지, 3D 이미지 일 수 있으며, 그 저장 형태는 일 예에 국한되지 않는다. 따라서 이미지 데이터는 .jpg, .png, .jpeg, .mov 등 다양한 형태의 저장 형식으로 저장 된 이미지 데이터일 수 있다. 또한, 이미지 데이터는 이미지 데이터 내 적어도 하나 이상의 객체를 포함하거나 객체를 포함하지 않은 이미지 데이터일 수 있다. 따라서, 본 발명에서의 이미지 데이터는 통상의 기술자가 획득할 수 있는 그림, 사진 등에 관한 이미지 데이터 일 수 있으며, 특정 이미지에 국한되어 해석되지 않음에 유의해야 한다. 단계 S200에서, 이미지 인식 장치는 이미지 데이터를 전처리할 수 있다. 상기 전처리 과정은 딥 러닝 모델 을 학습하기 위해 획득된 이미지 데이터에 대해서 라벨링을 과정을 수행하는 것을 포함할 수 있다. 이미지 인식 장치는 학습된 딥 러닝 모델을 통해 이미지 데이터 내 객체 인식값을 출력할 수 있다. 또는, 일 예에 따라 이미지 수집 장치에서 이미지 인식 장치로 이미지 데이터가 로딩하는 시점에서 이미 라 벨링 과정이 수행되어 생성된 데이터일 수 있다. 따라서 전처리 과정이 필요하지 않은 데이터가 로딩되는 경우 에는 상기 단계 S200 과정이 생략될 수도 있다. 여기서 라벨링 과정이란, 딥 러닝 모델을 학습하기 위한 데이터를 생성하는 과정으로서, 이미지 데이터 내 객체 가 위치하고 있는 영역의 바운딩 박스가 표시되어 있고, 상기 바운딩 박스의 상기 객체에 관한 정보가 라벨링 되어 있는 데이터를 생성하는 과정을 의미한다. 예를 들어, 이미지 데이터 내 개 또는 고양이가 포함되어 있는 경우, 라벨링 데이터는 개 또는 고양이가 이미지 내 위치하고 있는 영역의 적어도 하나 이상의 바운딩 박스가 표시되어 있고, 상기 적어도 하나 이상의 바운딩 박스의 각각 개 또는 고양이가 기재되어 있는 데이터를 생성하 는 과정을 의미할 수 있다. 이러한 과정을 통해 이미지 인식 장치는 이미지 데이터를 딥 러닝 모델에 입력하기 전, 전처리 과정을 통 해 딥 러닝 모델을 학습하는 과정을 수행할 수 있다. 단계 S300에서, 이미지 인식 장치는 학습된 딥러닝 모델을 통해 이미지 데이터를 딥 러닝 모델에 입력하고, 객체 인식값을 출력할 수 있다. 이미지 인식 장치는 학습된 딥 러닝 모델에 이미지 데이터를 입 력하고, 이미지 데이터 내 포함하는 객체에 관한 인식값을 출력할 수 있으며, 상기 인식값은 확률값으로 표현된 값일 수 있다. 이 때, 상기 인식값은 상기 이미지 데이터 내의 객체가 어떠한 객체인 지 분류하여, 상기 객체에 해당하는 확률에 대한 값을 표현한 값일 수 있다. 따라서, 이러한 객체 인식값은 딥 러닝 모델에서 이미지 인식 과 관련하여 딥 러닝 모델이 출력하는 출력값을 의미할 수 있다. 단계 S400에서, 이미지 인식 장치는 딥 러닝 모델에 객체 인식값을 입력하여 딥 러닝 모델을 업데이트 할 수 있다. 이 때, 동적으로 딥 러닝 모델을 학습하는 과정을 수행하고, 이미지 인식 장치에서 딥 러닝 모델 로 입력하는 이미지 데이터는 이미지 인식 장치에서 수집한 이미지 데이터 중 raw data일 수 있다. 보다 구체적으로, 딥 러닝 모델로 입력하여 객체 인식값을 출력하는 이미지 데이터는 단계 S200을 거치지 않은, 순수 이미지 데이터일 수 있으며, 상기 순수 이미지 데이터는 객체를 포함하거나 포함하지 않을 수 있다. 본 발명의 개시에서 활성 모델은 CNN 모델일 수 있다. 상기 CNN 모델은 합성곱 신경망 모델로서, Convolutional layer, pooling layer, fully connected layer, activating function layer을 포함할 수 있다. Convolutional layer는 적어도 하나 이상의 Filter를 포함하고 있으며, 적어도 하나 이상의 Filter는 각각 특정 모양에 대한 특징을 갖을 수 있다. 예를 들어, 물체의 윤곽을 알아내기 위한 edge Filter의 경우 이미지를 커버 할 수 있는 선과 같은 특정 모양에 대한 특징을 갖을 수 있다. edge Filter를 이미지에 적용시키는 경우, edge Filter에 부합하는 특징 정보를 얻을 수 있다. Convolutional layer에 포함된 적어도 하나 이상의 Filter를 통 해 특징 맵을 추출할 수 있다. Pooling layer는 Convolutional layer의 사이 사이에 구조적으로 위치할 수 있다. 또는 복수의 Convolutional layer가 계층적으로 위치한 후, Pooling layer가 위치할 수도 있다. Pooling layer는 Convolutional layer를 통해 추출된 특징 맵에서 특정 영역에 대한 특정 값을 추출하는 기능을 수행한다. Pooling layer는 여러 가지 종류를 가지고 있으며, 일 예로는 Max Pooling layer, Median Pooling layer 등이 있을 수 있다. Fully Connected Layer는 적어도 하나 이상의 Convolutional Layer와 Pooling Layer를 통해 추출된 특징 맵에 대해서 이미지 분류 기능을 수행할 수 있다. 일 예로 Fully Connected Layer는 특징 맵을 일렬의 형태로 위치한 후 hidden layer를 거쳐 이미지를 분류할 수 있다. Activation Function layer는 활성화 함수 층으로서 특징 맵에 적용될 수 있다. Activation Function layer는 Fully Connected Layer 이후 정량적 값에 대해, 특징 정보를 포함하고 있는 여부에 관한 결과로 바꿔 주는 기능 을 수행할 수 있다. 본 발명에서는 Activation Function layer를 Softmax function layer로 설정할 수 있다. 또한, 본 발명에서는 Max Pooling layer, 적어도 하나 이상의 Convolutional layer, Fully Connected Layer, Softmax layer로 이루어질 수 있으며 이는 일 예에 해당할 뿐, 이에 국한되어 해석되는 것은 아님에 유의해야 한다. 또한, 앞서 단계 S200에서 상술한, 딥 러닝 모델의 학습 과정은 이미지 데이터 중 전처리 과정을 거친 이미지 데이터를 통해 학습할 수 있다. 전처리 과정을 거친 이미지 데이터는 객체를 포함하는 이미지일 수 있다. 상기 전처리 과정을 거친 이미지 데이 터는 객체가 있을 것이라 판단되는 영역에 바운딩 박스가 그려져 있고, 이에 객체가 어떠한 객체인지를 포함하 는 정보인 라벨링 정보를 포함하는 이미지 데이터일 수 있다. 예를 들어, 전처리 과정을 거친 이미지 데이터는 이미지 데이터 내에 강아지가 있는 경우, 이미지 데이터에서 강아지가 차지하는 영역을 바운딩 박스가 표시되어 있고, 그 바운딩 박스에 라벨링 정보인 “강아지”, “개”, “dog” 등으로 정보를 포함하는 데이터일 수 있다. 딥 러닝 모델은 전처리 과정을 거친 이미지 데이터를 입력 받고, 출력값을 출력할 수 있으며, 상기 전처 리 과정을 거친 이미지 데이터와 출력값을 비교하여 학습할 수 있다. 일 예에 따르면, 출력값은 전처리 과정을 거친 이미지 데이터가 라벨링 데이터를 포함하는 경우, 라벨링 데이터에 관한 확률값을 포함하는 값일 수 있다. 딥 러닝 모델은 오차 역전파 방법으로 학습할 수 있다. 오차 역전파 방법은 전처리 과정을 거친 이미지 데이터 와 출력값의 오차를 딥 러닝 모델이 포함하는 노드에 다시 반영하여 학습하는 방법일 수 있다. 딥 러닝 모델은 전처리 과정을 거친 이미지 데이터와 출력값의 오차를 최소화하는 방향으로 학습할 수 있다.이하에서는 도 3을 통해 딥 러닝 모델에서 객체 인식값을 출력하는 단계에 관한 구체적인 설명을 하도록 한다. 도 3은 본 개시의 몇몇 실시예에 따라 딥 러닝 모델에서 객체를 인식하고 객체 인식값을 출력하는 단계에 대한 구체적인 설명을 위한 순서도이다. 단계 S310에서, 이미지 인식 장치는 제1 시점에서 이미지 데이터 내에 바운딩 박스 데이터를 추출할 수 있 다. 예를 들어, 이미지 인식 장치는 YOLO 모델을 활용하여 이미지 데이터 내에 객체가 위치할 것이라 판단 되는 영역에 바운딩 박스 데이터를 추출할 수 있다. 여기서 YOLO 모델은 딥 러닝 모델 중 하나로서, You Only Look Once,의 줄임말에 해당하는 알고리즘을 말한다. YOLO 모델은 이미지 데이터를 입력하면, Single Convolutional network(1x1 컨볼루션 레이어)를 실행하고, 입 력된 이미지 데이터의 출력값은 객체가 위치할 것이라 예상되는 확률값으로서, 이 때, 확률값에 대해 임계값 미 만의 바운딩 박스는 무시하고, 임계값 이상의 바운딩 박스 데이터만 출력할 수 있다. 보다 구체적으로 설명하면, YOLO 모델은 입력되는 이미지 사이즈를 resize하고, 바운딩 박스를 랜덤으로 복수 개 형성하여 resize 된 이미지 데이터에 바운딩 박스를 형성, Single Convolutional network(1x1 컨볼루션 레이어)를 실행 하여, 그 중 특징을 가지는 픽셀 단위의 값의 합산을 출력값으로 활용할 수 있다. 이 때, 특징을 가지는 픽셀 단위의 값이 높을수록, 그 픽셀 단위를 포함하고 있는 바운딩 박스가 객체가 있을 것이라 예견되는 영역일 수 있다. 따라서, 이미지 인식 장치는 YOLO 모델을 활용하여 바운딩 박스 데이터를 추출할 수 있고, 상기 바운딩 박 스 데이터는 이미지 데이터 내에서 객체가 존재할 수 있을 것이라 예견되는 영역을 바운딩 박스로 표시한 데이 터일 수 있다. 이 때, 바운딩 박스 데이터는 복수개가 형성될 수 있으며, 서로 간의 픽셀 단위가 겹치면서 형성 될 수 있음은 당연하다. 단계 S320에서, 이미지 인식 장치는 바운딩 박스 데이터 내 특징 맵을 추출하고, 이에 대응하는 고유값인 제1 ID를 할당할 수 있다. 이미지 인식 장치는 바운딩 박스 데이터가 추출되면, 바운딩 박스 내 적어도 하 나 이상의 픽셀의 관한 특징 맵을 추출할 수 있다. 특징 맵은 CNN이 포함하는 이미지 필터를 거쳐 나온 이미지 맵을 의미하고, 이미지 필터 크기와 필터링 간격에 따라 추출되는 특징 맵의 크기가 상이할 수 있다. 이 때, 추 출된 특징 맵에 대해서 이미지 인식 장치는 이에 대응하는 고유값인 제1 ID를 할당할 수 있으며, 상기 제1 ID는 서로 다른 특징 맵을 구분하기 위한 값의 형태일 수 있다. 따라서, 그 형태 및 형식에 국한되어 해석되는 것은 아니하며, 서로 다른 특징맵을 서로 구분할 수 있을 정도로 고유값이 형성될 수 있다. 단계 S330에서, 이미지 인식 장치는 제2 시점에서 바운딩 박스 데이터를 추출하고, 이에 바운딩 박스 데이 터 내 특징 맵을 추출할 수 있다. 이미지 인식 장치는 제1 시점과 상이한 제2 시점에 대해서도 바운딩 박 스 데이터 내 특징 맵을 추출할 수 있다. 따라서, 이미지 인식 장치는 서로 다른 복수 개의 시점에서 바운 딩 박스 데이터 내 특징 맵을 추출할 수 있다. 따라서, 서로 다른 시점에서 입력되는 이미지 데이터 프레임에 대해서 YOLO 모델을 통해 적어도 하나 이상의 바운딩 박스 데이터가 표시되고, 이에 대응하여 이미지 인식 장치 는 바운딩 박스 내 특징 맵을 추출하여, 적어도 하나 이상의 시점에 대응하는 특징 맵을 추출할 수 있다. 단계 S340에서, 이미지 인식 장치는 제1 시점의 바운딩 박스 데이터 내 특징 맵과 제2 시점에서 바운딩 박 스 내 특징 맵의 유사도를 비교하여 이에 대응하는 고유값인 제2 ID 부여 여부를 판단 및 할당할 수 있다. 이미 지 인식 장치는 추출된 적어도 하나 이상의 특징 맵들에 대해서 가장 근접한 시점에서 추출된 특징 맵들 간의 유사도를 추출하고, 상기 유사도를 기초로 다음 시점에서 추출된 특징 맵에 대해 고유값인 제2 ID를 할당 할 지 여부를 판단할 수 있다. 보다 구체적으로, 제1 시점에서 특징 맵에 대응하는 제1 ID가 부여된 경우, 이미지 인식 장치는 제1 시점 보다 일정 시간 이후인, 제2 시점에 대해서 추출된 특징 맵에 제1 ID를 그대로 부여하거나, 또는 제1 ID와 상이 하여, 구별될 수 있는 제2 ID를 부여할 수 있다. 이 때, 특징 맵 간의 유사도를 산출하여 제1 ID를 그대로 부여 할 지, 제2 ID를 부여할 지 판단할 수 있다. 상기 유사도는 각 특징 맵이 포함하고 있는 적어도 하나 이상의 픽 셀 단위의 값을 1:1 대응하여 유사한지 여부에 대한 정도를 의미할 수 있다. 따라서, 이미지 인식 장치는 유사도가 임계값이 넘는 경우에는 제1 ID를 그대로 부여하고, 임계값을 넘지 않은 경우, 제2 ID를 부여하여, 각 시점에 대한 특징 맵을 구분할 수 있다. 이러한 과정을 통해 이미지 인식 장치는 제1, 제2, … ID가 부여된 특징 맵을 기초로 하여, 객체를 인식하 는 과정을 수행할 수 있다. 따라서, 이미지 인식 장치는 합성곱신경망인 CNN만 활용하여 객체를 인식하고, 분류하는 것에 국한되는 것이 아니라 YOLO 모델을 통해 바운딩 박스 데이터와 특징 맵 유사도 비교를 통해, 이 미지 데이터 내 객체 인식에 관해 보다 정확한 결과를 도출할 수 있다. 이하에서는 본 발명에서 활용될 수 있는 CNN 딥 러닝 모델 아키텍쳐의 한 예시를 설명하도록 한다. 도 4는 본 개시의 몇몇 실시예에 따른 딥 러닝 모델 아키텍쳐를 설명하기 위한 예시적인 도면이다. 본 발명에서 상술하는 합성곱신경망인 CNN은 적어도 5개의 CNN layer, 적어도 3개의 Max pooling layer, Softmax activated layer를 포함할 수 있다. 도 4에서 각 layer가 설정된 부분을 도시화하였으며, 이미지 데이 터가 입력되면 순차적으로 도 4에 도시된 layer를 통과하여 출력값이 출력될 수 있다. 이 때, 첫번째 convolutional layer는 3x3 필터 크기를 가질 수 있고, 필터의 이동의 해당하는 stride가 1 또는 2의 값을 수 있으며, Batch Normalization 과정과 Leaky ReLU 함수를 활용할 수 있다. 두번째 convolutional layer는 3x3 필터를 가지며, 필터의 이동의 해당하는 stride가 1 또는 4의 값을 가질 수 있고, Batch Normalization 과정과 Leaky ReLU 함수를 활용할 수 있다. 세번째 convolutional layer 역시 3x3 필터 크기를 가지고, 필터의 이동의 해당하는 stride가 1 또는 8일 수 있으며, Batch Normalization 과정과 Leaky ReLU 함수를 활용할 수 있다. 네 번째 convolutional layer 역시 3x3 필터 크기를 가지고, 필터의 이동의 해당하는 stride가 1 또는 16일 수 있 으며, Batch Normalization 과정과 Leaky ReLU 함수를 활용할 수 있다. 다섯번째 convolutional layer도 3x3 필터 크기와 필터의 이동의 해당하는 stride가 1 또는 16일 수 있으며, 이후 Softmax activated function layer를 활용할 수 있다. 또한, 본 발명에서 활용하는 합성곱신경망에서 Max pooling layer는 2x2 크기를 가질 수 있다. 이하에서는 도 5를 통해 본 발명의 개시가 구현될 수 있는 예시적인 컴퓨팅 장치를 설명하도록 한다. 도 5는 본 개시의 다양한 실시예에 따른 장치 및/또는 시스템을 구현할 수 있는 예시적인 컴퓨팅 장치 도면이다. 컴퓨팅 장치는 하나 이상의 프로세서, 버스, 통신 인터페이스, 프로세서에 의하 여 수행되는 컴퓨터 프로그램을 로드(load)하는 메모리와, 컴퓨터 프로그램을 저장하는 스토 리지 를 포함할 수 있다. 다만, 도 5에는 본 개시의 실시예와 관련 있는 구성 요소들 만이 도시되어"}
{"patent_id": "10-2023-0014864", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "있다. 따라서, 본 개시가 속한 기술분야의 통상의 기술자라면 도 5에 도시된 구성 요소들 외에 다른 범용적인 구성 요소들이 더 포함될 수 있음을 알 수 있다. 프로세서는 컴퓨팅 장치의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 개시의 기술 분야에 잘 알려진 임의의 형태의 프로세서를 포함하여 구성될 수 있다. 또한, 프로세서 는 본 개시의 실시예들에 따른 방법을 실행하기 위한 적어도 하나의 애플리케이션 또는 프로그램에 대한 연산을 수행할 수 있다. 컴퓨팅 장치 는 하나 이상의 프로세서를 구비할 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모 리는 본 개시의 실시예들에 따른 방법 을 실행하기 위하여 스토리지로부터 하나 이상의 프로그램을 로드할 수 있다. 메모리는 RAM 과 같은 휘발성 메모리로 구현될 수 있을 것이나, 본 개시의 기술적 범위가 이에 한정되는 것은 아니다. 버스는 컴퓨팅 장치의 구성 요소 간 통신 기능을 제공한다. 버스는 주소 버스(Address Bus), 데이터 버스(Data Bus) 및 제어 버스 (Control Bus) 등 다양한 형태의 버스로 구현될 수 있다. 통신 인터페이스는 컴퓨팅 장치의 유무선 인터넷 통신을 지원한다. 또한, 통신 인터페이스는 인터넷 통신 외의 다양한 통신 방식을 지원할 수도 있다. 이를 위해, 통신 인터페이스는 본 개시의 기술 분야에 잘 알려진 통신 모듈을 포함하여 구성될 수 있다. 몇몇 실시예들에 따르면, 통신 인터페이스는 생략될 수도 있다. 스토리지는 상기 하나 이상의 프로그램과 각종 데이터를 비임시적으로 저장할 수 있다. 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메 모리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 개시가 속 하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 컴퓨터 프로그램은 메모리에 로드 될 때 프로세서로 하여금 본 개시의 다양한 실시예에 따른 방법/동작을 수행하도록 하는 하나 이상의 인스트럭션들을 포함할 수 있다. 즉, 프로세서는 상기 하나 이 상의 인스트럭션들을 실행함으로써, 본 개시의 다양한 실시예에 따른 방법/동작들을 수행할 수 있다. 지금까지 도 1 내지 도 5를 참조하여 본 개시의 다양한 실시예들 및 그 실시예들에 따른 효과들을 언급하였다. 본 개시의 기술적 사상에 따른 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효 과들은 명세서의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다. 지금까지 도 1 내지 도 5을 참조하여 설명된 본 개시의 기술적 사상은 컴퓨터가 읽을 수 있는 매체 상에 컴퓨터 가 읽을 수 있는 코드로 구현될 수 있다. 상기 컴퓨터로 읽을 수 있는 기록 매체는, 예를 들어 이동형 기록 매 체(CD, DVD, 블루레이 디스크, USB 저장 장치, 이동식 하드 디스크)이거나, 고정식 기록 매체(ROM, RAM, 컴퓨터 구비 형 하드 디스크)일 수 있다. 상기 컴퓨터로 읽을 수 있는 기록 매체에 기록된 상기 컴퓨터 프로그램은 인 터넷 등의 네트워크를 통하여 다른 컴퓨팅 장치에 전송되어 상기 다른 컴퓨팅 장치에 설치될 수 있고, 이로써 상 기 다른 컴퓨팅 장치에서 사용될 수 있다. 이상에서, 본 개시의 실시예를 구성하는 모든 구성 요소들이 하나로 결합되거나 결합되어 동작하는 것으로 설명 되었다고 해서, 본 개시의 기술적 사상이 반드시 이러한 실시예에 한정되는 것은 아니다. 즉, 본 개시의 목적 범위 안에 서라면, 그 모든 구성 요소들이 하나 이상으로 선택적으로 결합하여 동작할 수도 있다. 도면에서 동작들이 특정한 순서로 도시되어 있지만, 반드시 동작들이 도시된 특정한 순서로 또는 순차적 순서로 실행되어야만 하거나 또는 모든 도시 된 동작들이 실행되어야만 원하는 결과를 얻을 수 있는 것으로 이해되어서 는 안 된다. 특정 상황에서는, 멀티태스킹 및 병렬 처리가 유리할 수도 있다. 더욱이, 위에 설명한 실시예들에 서 다양한 구성들의 분리는 그러한 분리가 반드시 필요한 것으로 이해되어서는 안 되고, 설명된 프로그램 컴포 넌트들 및 시스템들은 일반적으로 단일 소프트웨어 제품으로 함께 통합되거나 다수의 소프트웨어 제품으로 패키 지 될 수 있음을 이해하여야 한다."}
{"patent_id": "10-2023-0014864", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상 첨부된 도면을 참조하여 본 개시의 실시예들을 설명하였지만, 본 개시가 속하는 기술분야에서 통상의 지식 을 가진 자는 그 기술적 사상이나 필수 적인 특징을 변경하지 않고서 본 개시가 다른 구체적인 형태로도 실시될 수 있다는 것을 이해할 수 있다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로 이해해야만 한다. 본 개시의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 개시에 의해 정의되는 기술적 사상의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0014864", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 몇몇 실시예에 따른 이미지 인식 장치가 적용될 수 있는 예시적인 환경을 도시한다. 도 2는 본 개시의 몇몇 실시예에 따라 이미지 인식 장치에서 수행될 수 있는 이미지 데이터 내에서 객체를 인식 하는 방법에 관한 순서도이다. 도 3은 본 개시의 몇몇 실시예에 따라 딥 러닝 모델에서 객체를 인식하고 객체 인식값을 출력하는 단계에 대한 구체적인 설명을 위한 순서도이다. 도 4는 본 개시의 몇몇 실시예에 따른 딥 러닝 모델 아키텍쳐를 설명하기 위한 예시적인 도면이다. 도 5는 본 개시의 다양한 실시예에 따른 장치 및/또는 시스템을 구현할 수 있는 예시적인 컴퓨팅 장치 도면이다."}
