{"patent_id": "10-2022-0003940", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0108490", "출원번호": "10-2022-0003940", "발명의 명칭": "상담 서비스 제공 방법 및 장치", "출원인": "주식회사 케이티", "발명자": "류지연"}}
{"patent_id": "10-2022-0003940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 장치에 의해 수행되는 상담 서비스 제공 방법으로서, 피상담자 단말로부터 얼굴을 포함하는 영상을 수신하는 단계, 상기 영상 내의 얼굴 영역에 아바타 그래픽을 합성하여, 아바타 영상을 생성하는 단계, 상기 영상으로부터 추론된 상기 피상담자의 심리 상태에 관한 정보를 시각화하여, 상태 정보 영상을 생성하는단계, 및상기 아바타 영상과 상기 상태 정보 영상 중 적어도 일부를 포함하는 상담용 영상을 상담자 단말로 출력하는 단계를 포함하는, 상담 서비스 제공 방법."}
{"patent_id": "10-2022-0003940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에서,상기 아바타 영상을 생성하는 단계는,상기 얼굴 영역으로부터 하나 이상의 특징점들을 추출하는 단계, 및상기 하나 이상의 특징점들에 기초하여 상기 아바타 그래픽을 합성하는 단계를 포함하는,상담 서비스 제공 방법."}
{"patent_id": "10-2022-0003940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에서,상기 아바타 영상은,상기 영상보다 작은 용량을 가지도록 생성되는,상담 서비스 제공 방법."}
{"patent_id": "10-2022-0003940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에서,상기 피상담자의 심리 상태에 관한 정보는, 상기 얼굴 영역으로부터 추론된 제 1 심리 상태 정보, 그리고 상기 영상 내에서 상기 얼굴 영역을 제외한 영역중 적어도 일부인 환경 영역으로부터 추론된 제 2 심리 상태 정보를 포함하는,상담 서비스 제공 방법."}
{"patent_id": "10-2022-0003940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에서,공개특허 10-2023-0108490-3-상기 상담용 영상을 생성하는 단계는,입력된 영상에 포함되는 하나 이상의 요소로부터 심리 상태를 추론하도록 기 학습된 적어도 하나의 인공지능 모델에 상기 영상을 입력하여, 상기 피상담자의 심리 상태에 관한 정보를 획득하는 단계를 포함하는,상담 서비스 제공 방법."}
{"patent_id": "10-2022-0003940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5항에서,상기 방법은,상기 상담용 영상에 대응하여 상기 상담자 단말로부터 진료 정보를 수신하는 단계, 상기 영상 및 상기 영상과 대응되는 상기 진료 정보를 매칭한 데이터셋(dataset)을 누적 저장하는 단계, 및상기 데이터셋에 기초하여 상기 적어도 하나의 인공지능 모델을 재학습시키는 단계를 포함하는,상담 서비스 제공 방법."}
{"patent_id": "10-2022-0003940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항에서,상기 방법은,상기 영상과 함께 음성을 수신하는 단계를 더 포함하고, 상기 피상담자의 심리 상태에 관한 정보는,상기 음성으로부터 추론된 제 3 심리 상태 정보를 더 포함하는,상담 서비스 제공 방법."}
{"patent_id": "10-2022-0003940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "컴퓨팅 장치에 의해 수행되는 상담 서비스 제공 방법으로서, 영상 내에서 얼굴 영역과 환경 영역을 구분하여 식별하는 단계, 기 학습된 인공지능 모델을 기반으로, 상기 얼굴 영역과 대응되는 제 1 심리 상태 정보 및 상기 환경 영역과 대응되는 제 2 심리 상태 정보를 각각 획득하는 단계, 및상기 영상의 상기 얼굴 영역에 아바타 그래픽을 합성하여 생성되는 아바타 영상, 상기 제 1 심리 상태 정보, 및상기 제 2 심리 상태 정보 중 적어도 하나를 출력하는 단계를 포함하는,상담 서비스 제공 방법."}
{"patent_id": "10-2022-0003940", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 일 실시예에 따라, 컴퓨팅 장치에 의해 수행되는 상담 서비스 제공 방법으로서, 상기 방법은, 피상담 자 단말로부터 얼굴을 포함하는 영상을 수신하는 단계, 상기 영상 내의 얼굴 영역에 아바타 그래픽을 합성하여, 아바타 영상을 생성하는 단계, 상기 영상으로부터 추론된 상기 피상담자의 심리 상태에 관한 정보를 시각화하여, 상태 정보 영상을 생성하는 단계, 및 상기 아바타 영상과 상기 상태 정보 영상 중 적어도 일부를 포함하는 상담 용 영상을 상담자 단말로 출력하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0003940", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 상담 서비스 제공 방법 및 장치에 관한 것으로, 구체적으로 비대면 심리 상담을 제공하는 방법 및 장 치에 관한 것이다."}
{"patent_id": "10-2022-0003940", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정신 건강 의학과를 방문하는 피상담자의 수가 날로 늘어가고 있다. 심리상담은 주로 상담실에서 면대면으로 행 해지는 전통적인 상담 방식으로 이루어져 왔는데, 상담자와 직접 마주해야 하는 면대면 상담 및 심리치료가 부 담되거나 꺼려져 심리치료가 지속되지 못하고 중단되기도 한다. 이에 따라 면대면 상담의 대안으로 최근에는 온 라인 상에서 심리를 상담하고 치료하는 방식이 제시되고 있다. 이러한 영상통화나 원격진료 등의 온라인 심리 상담에 있어서, 상담자는 피상담자의 상태에 관한 정보를 얻기 위해 피상담자의 얼굴 화면을 실시간으로 제공받는 것이 일반적이다. 그러나 피상담자에 따라서는, 자신의 얼굴 이 보여지는 상황에 대해 부담감을 느낄 수 있다. 한편 피상담자의 얼굴에 대한 실사 영상을 실시간으로 상담자 에게 전송하는 것은, 경우에 따라 시스템에 부하를 발생시킬 수 있다. 이에, 상담자에게 피상담자의 심리 상태에 관한 충분한 정보를 제공하면서도 피상담자의 심리적 부담감을 낮추 고, 한편 경량화된 데이터 전송만으로 비대면 심리 상담 서비스를 제공할 수 있는 기술에 대한 당업계의 요구가 존재한다."}
{"patent_id": "10-2022-0003940", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "해결하고자 하는 과제는, 피상담자 영상을 분석 및 처리하여, 피상담자의 얼굴 노출이 없이도 피상담자의 심리 상태에 관한 충분한 정보를 제공할 수 있는 심리 상담 서비스를 제공하는 것이다. 상기 과제 이외에도 구체적으 로 언급되지 않은 다른 과제를 달성하는 데 사용될 수 있다."}
{"patent_id": "10-2022-0003940", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 몇몇 실시예에 따른 컴퓨팅 장치에 의해 수행되는 상담 서비스 제공 방법으로서, 상기 방법은, 피상 담자 단말로부터 얼굴을 포함하는 영상을 수신하는 단계, 상기 영상 내의 얼굴 영역에 아바타 그래픽을 합성하 여, 아바타 영상을 생성하는 단계, 상기 영상으로부터 추론된 상기 피상담자의 심리 상태에 관한 정보를 시각화 하여, 상태 정보 영상을 생성하는 단계, 및 상기 아바타 영상과 상기 상태 정보 영상 중 적어도 일부를 포함하 는 상담용 영상을 상담자 단말로 출력하는 단계를 포함할 수 있다. 상기 아바타 영상을 생성하는 단계는, 상기 얼굴 영역으로부터 하나 이상의 특징점들을 추출하는 단계, 및 상기 하나 이상의 특징점들에 기초하여 상기 아바타 그래픽을 합성하는 단계를 포함할 수 있다. 상기 아바타 영상은, 상기 영상보다 작은 용량을 가지도록 생성될 수 있다. 상기 피상담자의 심리 상태에 관한 정보는, 상기 얼굴 영역으로부터 추론된 제 1 심리 상태 정보, 그리고 상기 영상 내에서 상기 얼굴 영역을 제외한 영역 중 적어도 일부인 환경 영역으로부터 추론된 제 2 심리 상태 정보를 포함할 수 있다. 상기 상담용 영상을 생성하는 단계는, 입력된 영상에 포함되는 하나 이상의 요소로부터 심리 상태를 추론하도록 기 학습된 적어도 하나의 인공지능 모델에 상기 영상을 입력하여, 상기 피상담자의 심리 상태에 관한 정보를 획 득하는 단계를 포함할 수 있다. 상기 방법은, 상기 상담용 영상에 대응하여 상기 상담자 단말로부터 진료 정보를 수신하는 단계, 상기 영상 및 상기 영상과 대응되는 상기 진료 정보를 매칭한 데이터셋(dataset)을 누적 저장하는 단계, 및 상기 데이터셋에 기초하여 상기 적어도 하나의 인공지능 모델을 재학습시키는 단계를 포함할 수 있다. 상기 방법은, 상기 영상과 함께 음성을 수신하는 단계를 더 포함하고, 상기 피상담자의 심리 상태에 관한 정보 는, 상기 음성으로부터 추론된 제 3 심리 상태 정보를 더 포함할 수 있다. 본 개시의 몇몇 실시예에 따른 컴퓨팅 장치에 의해 수행되는 상담 서비스 제공 방법으로서, 영상 내에서 얼굴 영역과 환경 영역을 구분하여 식별하는 단계, 기 학습된 인공지능 모델을 기반으로, 상기 얼굴 영역과 대응되는 제 1 심리 상태 정보 및 상기 환경 영역과 대응되는 제 2 심리 상태 정보를 각각 획득하는 단계, 및 상기 영상 의 상기 얼굴 영역에 아바타 그래픽을 합성하여 생성되는 아바타 영상, 상기 제 1 심리 상태 정보, 및 상기 제 2 심리 상태 정보 중 적어도 하나를 출력하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0003940", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 몇몇 실시예에 따르면, 피상담자의 얼굴이 노출되지 않도록 피상담자 영상을 처리한 후 상담자에게 제공함으로써, 피상담자의 심리적 부담감을 낮출 수 있다. 본 개시의 몇몇 실시예에 따르면, 인공지능 기반의 피상담자 영상 분석을 통해, 피상담자의 얼굴이 노출되지 않 는 상황에서도 상담자에게 심리 상담을 위한 충분한 보조 정보를 제공할 수 있다. 본 개시의 몇몇 실시예에 따르면, 피상담자 영상의 적어도 일부분을 그래픽으로 재구성하여 전송함으로써, 전송 되는 데이터를 경량화하고 시스템 부하를 낮출 수 있다."}
{"patent_id": "10-2022-0003940", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위 해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구 성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 네트워크를 구성하는 장치 들은 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 도 1은 본 개시의 몇몇 실시예에 따른 상담 서비스 제공 장치를 나타낸 블록도이다. 도 1을 참조하면, 본 개시에 따른 상담 서비스 제공 장치는 데이터 수신부, 아바타 생성부, 상 태 분석부, 및 영상 출력부를 포함할 수 있다. 또한 본 개시에 따른 상담 서비스 제공 장치는 하나 이상의 피상담자 단말 및/또는 하나 이상의 상담자 단말과 네트워크를 통해 연결될 수 있다. 본 개시에 따른 상담 서비스 제공 장치의 데이터 수신부는, 피상담자 단말로부터 피상담자의 얼 굴을 포함하는 영상을 수신할 수 있다. 다만 이에 한정되지 않으며, 데이터 수신부는 영상과 함께 피상담자의 음성을 추가로 수신할 수 있고, 그 리고/또는 영상과 함께 피상담자의 뇌파, 맥박, 혈압 등 다양한 반응 정보를 수신할 수 있다. 이를 위해 피상담자 단말은, 피상담자를 촬영하기 위한 하나 이상의 카메라, 피상담자의 음성을 수집하기 위한 하나 이상의 마이크, 및/또는 피상담자의 반응 정보를 수집하기 위한 하나 이상의 센서를 포함하거나, 또 는 이들에 통신적으로 연결될 수 있다. 데이터 수신부가 수신하는 영상은, 피상담자의 얼굴 외에 피상담자의 주변 환경을 포함할 수 있다. 가령 피상담자가 자신의 방에서 상담을 진행하고 있는 경우, 피상담자 단말로부터 수신되는 영상은 피상담자의 얼굴 외에도 피상담자의 방 안에 놓여있는 가구 등의 객체 요소, 및/또는 피상담자의 방 내부의 조도 등의 환경 요소를 더 포함할 수 있다. 데이터 수신부는 피상담자와 상담자 간 실시간 상담을 진행할 수 있도록, 피상담자 단말로부터 실시 간으로 영상을 수신할 수 있다. 한편 데이터 수신부가 수신한 영상은 후술할 아바타 생성부로 전달되 어 아바타 영상을 생성하기 위해 사용될 수 있으며, 그리고/또는 후술할 상태 분석부로 전달되어 피상담자 의 심리 상태에 관한 정보를 추론하기 위해 사용될 수 있다. 본 개시에 따른 상담 서비스 제공 장치의 아바타 생성부는, 영상 내의 얼굴 영역에 아바타 그래픽을 합성하여 아바타 영상을 생성할 수 있다. 아바타 그래픽은, 임의의 형상의 2D 또는 3D 그래픽일 수 있으며, 예컨대 동물이나 애니메이션 등의 캐릭터 그 래픽이거나, 적어도 하나의 색상으로만 이루어진 색상 그래픽일 수도 있다. 아바타 생성부는, 영상 내의 얼굴 영역으로부터 하나 이상의 특징점들을 추출하고, 추출된 특징점들에 기 초하여 아바타 그래픽을 영상 내의 얼굴 영역에 합성할 수 있다. 영상 내 얼굴 영역으로부터 추출되는 특징점들은, 영상 내의 얼굴 영역에 포함된 형상, 패턴, 색상 또는 이들의 조합을 검출하여 추출되는 3차원 안면 좌표 정보일 수 있다. 가령 3차원 안면 좌표 정보는, 얼굴 영역 내의 눈 영역, 코 영역, 입 영역, 턱 영역, 이마 영역 중 하나 이상의 영역과 대응되는 좌표 정보를 포함할 수 있다. 한편 아바타 그래픽은, 영상 내 얼굴 영역에 합성되기 위한 3차원 안면 좌표 정보를 포함할 수 있다. 아바타 생 성부는 아바타 그래픽의 3차원 안면 좌표 정보 및 영상 내 얼굴 영역으로부터 추출된 3차원 안면 좌표 정 보를 맵핑(mapping)하여, 아바타 그래픽을 영상 내 얼굴 영역에 합성한 아바타 영상을 생성할 수 있다. 이와 같이 본 개시의 상담 서비스 제공 방법은, 피상담자의 얼굴이 노출되지 않도록 영상 내 얼굴 영역에 아바 타를 합성한 후 상담자에게 제공함으로써, 피상담자의 심리적 부담감을 낮출 수 있다. 특히 본 개시에서 아바타 영상은, 피상담자 단말로부터 수신된 원본 영상보다 작은 용량을 가지도록 생성 될 수 있다. 즉 피상담자 단말로부터 실시간으로 수신되는 영상에서 피상담자에 대응되는 영역을 저용량의 아바타로 대체함으로써, 상담 중 시스템에 대한 전송 부하를 낮출 수 있다. 본 개시에 따른 상담 서비스 제공 장치의 상태 분석부는, 영상으로부터 피상담자의 심리 상태를 추론 하고, 추론된 피상담자의 심리 상태에 관한 정보를 시각화하여 상태 정보 영상을 생성할 수 있다. 피상담자의 심리 상태를 추론하기 위해, 상태 분석부는 먼저 피상담자 단말로부터 수신한 영상에서 얼굴 영역과 환경 영역을 구분하여 식별할 수 있다. 여기서 환경 영역은 영상 내에서 얼굴 영역을 제외한 영역 중 적어도 일부일 수 있다. 구체적으로 환경 영역은, 영상 내에서 피상담자의 주변 환경을 포함하는 영역일 수 있으며, 전술한 바와 같이 피상담자가 상담을 진행하 고 있는 공간 안에 놓여있는 가구나 물건 등의 객체 요소, 및/또는 피상담자가 상담을 진행하고 있는 공간의 조 도 등의 환경 요소를 포함할 수 있다. 그리고 상태 분석부는, 기 학습된 하나 이상의 인공지능 모델을 통해, 얼굴 영역으로부터 추론되는 피상담 자의 심리 상태에 관한 정보(이하, “제 1 심리 상태 정보”) 및 환경 영역으로부터 추론되는 피상담자의 심리 상태에 관한 정보(이하, “제 2 심리 상태 정보”)를 각각 획득할 수 있다. 제 1 심리 상태 정보를 획득하기 위한 인공지능 모델은, 얼굴 영역에 대한 영상을 분석하여 피상담자의 심리 상 태를 추론하도록 기 학습된 모델일 수 있으며, 예컨대 얼굴 영역으로부터 특징점들의 변위 정보, 또는 눈동자 추적 정보 등을 추출하여 심리 상태를 결정하는 하나 이상의 알고리즘을 포함할 수 있다. 예컨대 상태 분석부는, 인공지능 모델을 통해 영상 내 얼굴 영역에서 각 프레임 별로 특징점들을 추출하고, 추출된 특징점들의 위치를 기 저장된 다양한 심리 상태에서의 얼굴 이미지와 비교하여, 각 심리 상태 에 대한 영상 내 얼굴 영역의 일치도에 기초하여 제 1 심리 상태 정보를 획득할 수 있다. 다만 이에 한정되는 것은 아니며, 제 1 심리 상태 정보를 획득하기 위한 인공지능 모델은 얼굴 영역 이미지로부 터 즉각적으로 감정을 추론하도록 학습된 딥 러닝 모델일 수 있다. 한편 제 2 심리 상태 정보를 획득하기 위한 인공지능 모델은, 환경 영역에 대한 영상을 분석하여 피상담자의 심 리 상태를 추론하도록 기 학습된 모델일 수 있으며, 예컨대 환경 영역으로부터 하나 이상의 객체 인식 정보 또 는 조도 정보 등의 환경 정보를 추출하여 심리 상태를 결정하는 하나 이상의 알고리즘을 포함할 수 있다. 구체적으로 상태 분석부는, 인공지능 모델을 통해 영상 내 환경 영역에서, 피상담자가 상담을 진행하고 있 는 공간의 정돈 상태를 나타내는 하나 이상의 객체(예를 들어, 책상 위 물건들의 분포와 양, 침대 위 이불의 상 태, 빨래 바구니 내 또는 빨래 건조대 상의 빨래의 분포와 양 등)를 인식할 수 있다. 일반적으로 주요 정신장애는 주변 정리정돈 상태와 연관되는 증상을 동반하는 것이 알려져 있다. 가령 우울 장 애의 경우 정리정돈을 어려워할 수 있고, 반대로 강박 장애의 경우 정리정돈에 집착하는 증상을 동반할 수 있다. 이에 따라, 정리정돈 상태에 관한 영상 내 환경 영역의 객체 인식 결과에 기초하여, 제 2 심리 상태 정보 를 획득할 수 있다. 또는 상태 분석부는, 인공지능 모델을 통해 영상 내 환경 영역의 조도 상태를 인식할 수 있다. 예컨대 상 태 분석부는 영상 내 적어도 일부 프레임들에 포함된 픽셀들 각각의 밝기 값의 평균을 임계 값과 비교하여 피상담자가 상담을 진행하고 있는 공간의 조도가 충분한 지 여부를 이진(binary) 판단할 수 있다. 또는 피상담 자의 영상을 촬영하는 이미지 장치의 노출 값이 조도에 따라 자동으로 결정되는 경우, 상태 분석부는 촬영 된 영상의 노출 값에 기초하여 피상담자가 상담을 진행하고 있는 공간의 조도를 결정할 수도 있다. 일반적으로 실내 조도는 해당 공간에 머무르는 사람의 심리에 영향을 미치는 것이 알려져 있는 바, 영상 내 환 경 영역으로부터의 조도 인식 결과에 기초하여 제 2 심리 상태 정보를 획득할 수도 있다. 한편 상태 분석부는, 피상담자 단말로부터 영상과 함께 음성이 추가적으로 수신되는 경우, 음성으로 부터 추론되는 피상담자의 심리 상태에 관한 정보(이하, “제 3 심리 상태 정보”)를 더 획득할 수 있다. 제 3 심리 상태 정보를 획득하기 위한 인공지능 모델은, 음성을 분석하여 피상담자의 심리 상태를 추론하도록 기 학습된 모델일 수 있다. 상기 인공지능 모델은 예컨대 수신한 음성으로부터 파형 정보, 속도 정보 등의 특징 을 추출하여 심리 상태를 결정하는 하나 이상의 알고리즘을 포함할 수 있다. 또는 예컨대, 음성 인식을 통해 음 성에 포함된 하나 이상의 어휘들의 사용 빈도, 사용 비중 등의 어휘 정보를 추출하여 심리 상태를 결정하는 하 나 이상의 알고리즘을 포함할 수도 있다. 구체적으로 상태 분석부는, 인공지능 모델을 통해 음성으로부터 파형, 고저, 강약, 속도 등의 특징을 추출 하고, 추출된 특징들 각각을 기 저장된 다양한 심리 상태에서의 음성과 비교하여, 각 심리 상태에 대한 피상담 자의 음성의 일치도에 기초하여 제 3 심리 상태 정보를 획득할 수 있다. 또는 상태 분석부는, 인공지능 모델을 통해 음성으로부터 하나 이상의 어휘들을 인식하고, 인식된 어휘들 을 기 저장된 어휘 데이터베이스와 비교하여 하나 이상의 유형(예를 들어, 긍정적 어휘 유형과 부정적 어휘 유 형 등)에 따라 분류할 수 있다. 그리고 상태 분석부는, 각 유형 별 어휘들의 사용 빈도, 각 유형 별 어휘 들이 포함된 문장의 개수 등과 같은 통계치에 기초하여 제 3 심리 상태 정보를 획득할 수 있다. 가령 음성 내에 서 긍정적 어휘 및 부정적 어휘 각각의 사용 통계치에 따라, 피상담자의 심리 상태가 긍정적인지 또는 부정적인 지에 관한 정보를 포함하는 제 3 심리 상태 정보를 획득할 수 있다. 다만 이에 한정되는 것은 아니며, 제 3 심리 상태 정보를 획득하기 위한 인공지능 모델은 음성으로부터 즉각적 으로 감정을 추론하도록 학습된 딥 러닝 모델일 수 있으며, 이 경우 모델은 CNN(Convolutional Neural Network; CNN), LSTM(Long Short-Term Memory), 또는 이들의 결합 모델 등 음성 기반 감정인식에 사용 가능한 임의의 알고리즘 및/또는 뉴럴 네트워크 구조를 사용하여 구현될 수 있다. 본 개시에 따른 상담 서비스 제공 장치의 영상 출력부는, 아바타 영상과 상태 정보 영상 중 적어도 일부를 포함하는 상담용 영상을 상담자 단말로 출력할 수 있다. 가령 아바타 영상, 상태 정보 영상, 및/또 는 상담용 영상을 상담자 단말로 전송하거나, 또는 상담 서비스 제공 장치가 상담자 단말과 동 일한 장치로 구현되는 경우에는 상담용 영상을 상담자 단말의 출력부(미도시)를 통해 곧바로 출력할 수도 있다. 영상 출력부는, 아바타 영상과 상태 정보 영상을 합성하여 상담용 영상을 생성할 수 있다. 또는 영상 출력 부는, 아바타 영상 상에 상태 정보 영상을 오버레이(overlay)하여 상담용 영상을 생성할 수 있다. 이 경우 상태 정보 영상은 아바타 영상 상의 적어도 일 부분에 중첩하여 출력될 수 있다. 가령 상태 정보 영상에 표시되 는 피상담자의 심리 상태에 관한 정보가 피상담자의 얼굴 영역에 대응되는 아바타 그래픽을를 가리지 않도록, 아바타 영상 상의 엣지(edge) 영역에 중첩하여 출력될 수 있다. 다만 이에 한정되는 것은 아니다. 상술한 구성은 본 개시에 따른 상담 서비스 제공 장치를 구현하는 데 필수적인 것은 아니어서, 상담 서비 스 제공 장치는 열거된 구성보다 많거나 적은 구성들로 구현될 수 있다. 가령 상담 서비스 제공 장치(10 0)는 영상, 영상으로부터 추론된 피상담자의 심리 상태에 관한 정보, 또는 영상과 대응되는 진료 정보 등을 저 장하기 위한 저장부(미도시)를 더 포함할 수 있다. 이 경우 본 개시에 따른 상담 서비스 제공 장치의 저장부는, 본 개시의 상담 서비스 제공 장치로부터 획득된 피상담자의 심리 상태에 관한 정보를 해당 피상담자의 식별 정보와 매칭하여 저장할 수 있고, 이로써 피 상담자의 지속적인 상담을 위한 상담 이력 정보를 생성 및 관리할 수 있다. 또는 본 개시에 따른 상담 서비스 제공 장치는 상담용 영상의 제공에 대응하여 상담자 단말로부터 상 담자 소견을 포함하는 진료 정보를 수신할 수 있다. 이 경우 상담 서비스 제공 장치의 저장부는, 해당 진 료 정보를 피상담자의 식별 정보와 매칭하여 저장함으로써 상담 이력 정보를 생성 및 관리할 수도 있다. 또는 본 개시에 따른 상담 서비스 제공 장치의 저장부는, 상담자 단말로부터 수신된 상기 진료 정보 를 대응되는 영상과 매칭한 데이터셋(dataset)을 누적하여 저장할 수 있다. 상담자 단말로부터 수신된 진 료 정보는 피상담자의 영상에 대한 상담자의 소견인 바, 피상담자의 심리 상태에 관한 정보의 그라운드 트루스 (ground truth) 값으로 볼 수 있다. 이에, 저장부는 진료 정보를 대응하는 영상과 매칭한 데이터셋을 저장하고, 상담 서비스 제공 장치는 해당 데이터셋에 기초하여 상술한 적어도 하나의 인공지능 모델을 지속적으로 학 습시켜 성능을 향상시킬 수 있다. 한편 도 1에서는 설명의 편의상 상담 서비스 제공 장치와 피상담자 단말 및 상담자 단말을 구분 하여 도시하였으나, 이에 한정되는 것은 아니다. 가령 상담 서비스 제공 장치는 피상담자 단말과 동 일한 장치로서 구현되거나, 또는 상담 서비스 제공 장치는 상담자 단말과 동일한 장치로서 구현될 수 도 있다. 도 2는 본 개시의 몇몇 실시예에 따른 상담 서비스 제공 방법을 도시한 순서도이다. 도 2를 참조하면, 본 개시에 따른 상담 서비스 제공 장치의 데이터 수신부는, 피상담자 단말로 부터 얼굴을 포함하는 영상을 실시간으로 수신할 수 있다(S110). 다만 이에 한정되지 않으며, 데이터 수신부는 영상과 함께 피상담자의 음성을 추가로 수신할 수 있고, 그 리고/또는 영상과 함께 피상담자의 뇌파, 맥박, 혈압 등 다양한 반응 정보를 수신할 수 있다. 이를 위해 피상담자 단말은, 피상담자를 촬영하기 위한 하나 이상의 카메라, 피상담자의 음성을 수집하기 위한 하나 이상의 마이크, 및/또는 피상담자의 반응 정보를 수집하기 위한 하나 이상의 센서를 포함하거나, 또 는 이들에 통신적으로 연결될 수 있다. 데이터 수신부가 수신하는 영상은, 피상담자의 얼굴 외에 피상담자의 주변 환경을 포함할 수 있다. 가령 피상담자가 자신의 방에서 상담을 진행하고 있는 경우, 피상담자 단말로부터 수신되는 영상은 피상담자의 얼굴 외에도 피상담자의 방 안에 놓여있는 가구 등의 객체 요소, 및/또는 피상담자의 방 내부의 조도 등의 환경 요소를 더 포함할 수 있다. 다음으로 본 개시에 따른 상담 서비스 제공 장치의 아바타 생성부는, 영상 내의 얼굴 영역에 아바타 그래픽을 합성하여, 아바타 영상을 생성할 수 있다(S120). 아바타 그래픽은, 임의의 형상의 2D 또는 3D 그래픽일 수 있으며, 예컨대 동물이나 애니메이션 등의 캐릭터 그 래픽이거나, 적어도 하나의 색상으로만 이루어진 색상 그래픽일 수도 있다. 일 예시에서 상담 서비스 제공 장치는, 피상담자 단말로 가능한 아바타 그래픽의 목록을 제공할 수 있다. 피상담자로부터 특정한 아바타 그래픽에 대한 선택을 수신하는 경우, 피상담자 단말는 상담 서비스 제공 장치의 아바타 생성부로 하여금 해당 아바타 그래픽을 기초로 아바타 영상을 생성하게끔 할 수 있다. 다만 이에 한정되는 것은 아니다. 아바타 생성부는, 영상 내의 얼굴 영역으로부터 하나 이상의 특징점들을 추출하고, 추출된 특징점들에 기 초하여 아바타 그래픽을 영상 내의 얼굴 영역에 합성할 수 있다. 영상 내 얼굴 영역으로부터 추출되는 특징점들은, 영상 내의 얼굴 영역에 포함된 형상, 패턴, 색상 또는 이들의 조합을 검출하여 추출되는 3차원 안면 좌표 정보일 수 있다. 가령 3차원 안면 좌표 정보는, 얼굴 영역 내의 눈 영역, 코 영역, 입 영역, 턱 영역, 이마 영역 중 하나 이상의 영역과 대응되는 좌표 정보를 포함할 수 있다. 안 면 좌표 정보 추출을 위해 HOG(Histogram of Oriented Gradient), Haar-like feature, SIFT(Scale Invariant Feature Transform), LBP(Local Binary Pattern), 또는 그 밖에 임의의 다양한 영상 처리 알고리즘들이 사용될 수 있다. 한편 아바타 그래픽은, 영상 내 얼굴 영역에 합성되기 위한 3차원 안면 좌표 정보를 포함할 수 있다. 아바타 생 성부는 아바타 그래픽의 3차원 안면 좌표 정보 및 영상 내 얼굴 영역으로부터 추출된 3차원 안면 좌표 정 보를 맵핑(mapping)하여, 아바타 그래픽을 영상 내 얼굴 영역에 합성한 아바타 영상을 생성할 수 있다. 이와 같이 본 개시의 상담 서비스 제공 방법은, 피상담자의 얼굴이 노출되지 않도록 영상 내 얼굴 영역에 아바 타를 합성한 후 상담자에게 제공함으로써, 피상담자의 심리적 부담감을 낮출 수 있다. 특히 본 개시에서 아바타 영상은, 피상담자 단말로부터 수신된 원본 영상보다 작은 용량을 가지도록 생성 될 수 있다. 즉 피상담자 단말로부터 실시간으로 수신되는 영상에서 피상담자에 대응되는 영역을 저용량의아바타로 대체함으로써, 상담 중 시스템에 대한 전송 부하를 낮출 수 있다. 다음으로 본 개시에 따른 상담 서비스 제공 장치의 상태 분석부는, 영상으로부터 추론된 피상담자의 심리 상태에 관한 정보를 시각화하여 상태 정보 영상을 생성하고(S130), 영상 출력부는 아바타 영상과 상 태 정보 영상 중 적어도 일부를 포함하는 상담용 영상을 상담자 단말로 출력할 수 있다(S140). 피상담자의 심리 상태에 관한 정보를 추론하는 방법에 관하여 도 3을 통해 보다 자세히 후술한다. 도 3은 본 개시의 다른 몇몇 실시예에 따른 상담 서비스 제공 방법을 도시한 순서도이다. 도 3을 참조하면, 본 개시에 따른 상담 서비스 제공 장치는 먼저 영상 내에서 얼굴 영역과 환경 영역을 구 분하여 식별할 수 있다(S210). 여기서 환경 영역은 영상 내에서 얼굴 영역을 제외한 영역 중 적어도 일부일 수 있다. 구체적으로 환경 영역은, 영상 내에서 피상담자의 주변 환경을 포함하는 영역일 수 있으며, 전술한 바와 같이 피상담자가 상담을 진행하 고 있는 공간 안에 놓여있는 가구나 물건 등의 객체 요소, 및/또는 피상담자가 상담을 진행하고 있는 공간의 조 도 등의 환경 요소를 포함할 수 있다. 다음으로 본 개시에 따른 상담 서비스 제공 장치는, 기 학습된 인공지능 모델을 기반으로, 얼굴 영역과 대 응되는 제 1 심리 상태 정보 및 환경 영역과 대응되는 제 2 심리 상태 정보를 각각 획득할 수 있다(S220). 제 1 심리 상태 정보를 획득하기 위한 인공지능 모델은, 얼굴 영역에 대한 영상을 분석하여 피상담자의 심리 상 태를 추론하도록 기 학습된 모델일 수 있으며, 예컨대 얼굴 영역으로부터 특징점들의 변위 정보, 또는 눈동자 추적 정보 등을 추출하여 심리 상태를 결정하는 하나 이상의 알고리즘을 포함할 수 있다. 예컨대 상태 분석부는, 인공지능 모델을 통해 영상 내 얼굴 영역에서 각 프레임 별로 특징점들을 추출하고, 추출된 특징점들의 위치를 기 저장된 다양한 심리 상태에서의 얼굴 이미지와 비교하여, 각 심리 상태 에 대한 영상 내 얼굴 영역의 일치도에 기초하여 제 1 심리 상태 정보를 획득할 수 있다. 다만 이에 한정되는 것은 아니며, 제 1 심리 상태 정보를 획득하기 위한 인공지능 모델은 얼굴 영역 이미지로부 터 즉각적으로 감정을 추론하도록 학습된 딥 러닝 모델일 수 있고, 가령 모델은 CNN(Convolutional Neural Network; CNN), RNN(Recurrent Neural Network), LSTM(Long Short-Term Memory), 오토인코더(Autoencoder), DRN(Deep Residual Network) 등 영상 처리에 사용 가능한 임의의 알고리즘 및/또는 뉴럴 네트워크 구조를 사용 하여 구현될 수 있다. 한편 제 2 심리 상태 정보를 획득하기 위한 인공지능 모델은, 환경 영역에 대한 영상을 분석하여 피상담자의 심 리 상태를 추론하도록 기 학습된 모델일 수 있으며, 예컨대 환경 영역으로부터 하나 이상의 객체 인식 정보 또 는 조도 정보 등의 환경 정보를 추출하여 심리 상태를 결정하는 하나 이상의 알고리즘을 포함할 수 있다. 구체적으로 상태 분석부는, 인공지능 모델을 통해 영상 내 환경 영역에서, 피상담자가 상담을 진행하고 있 는 공간의 정돈 상태를 나타내는 하나 이상의 객체(예를 들어, 책상 위 물건들의 분포와 양, 침대 위 이불의 상 태, 빨래 바구니 내 또는 빨래 건조대 상의 빨래의 분포와 양 등)를 인식할 수 있다. 객체 인식을 위한 다양한 알고리즘들이 알려져 있으며, 환경 영역으로부터 객체를 인식하기 위한 상기 인공지능 모델은 가령 CNN(Convolutional Neural Network) 기반의 AlexNet, ZFNet, VGG, GoogLeNet, 또는 ResNet 중 하나 이상의 알 고리즘을 사용하여 구현될 수 있다. 일반적으로 주요 정신장애는 주변 정리정돈 상태와 연관되는 증상을 동반하는 것이 알려져 있다. 가령 우울 장 애의 경우 정리정돈을 어려워할 수 있고, 반대로 강박 장애의 경우 정리정돈에 집착하는 증상을 동반할 수 있다. 이에 따라, 정리정돈 상태에 관한 영상 내 환경 영역의 객체 인식 결과에 기초하여, 제 2 심리 상태 정보 를 획득할 수 있다. 또는 상태 분석부는, 인공지능 모델을 통해 영상 내 환경 영역의 조도 상태를 인식할 수 있다. 예컨대 상 태 분석부는 영상 내 적어도 일부 프레임들에 포함된 픽셀들 각각의 밝기 값의 평균을 임계 값과 비교하여 피상담자가 상담을 진행하고 있는 공간의 조도가 충분한 지 여부를 이진(binary) 판단할 수 있다. 또는 피상담 자의 영상을 촬영하는 이미지 장치의 노출 값이 조도에 따라 자동으로 결정되는 경우, 상태 분석부는 촬영 된 영상의 노출 값에 기초하여 피상담자가 상담을 진행하고 있는 공간의 조도를 결정할 수도 있다. 일반적으로 실내 조도는 해당 공간에 머무르는 사람의 심리에 영향을 미치는 것이 알려져 있는 바, 영상 내 환 경 영역으로부터의 조도 인식 결과에 기초하여 제 2 심리 상태 정보를 획득할 수도 있다. 다음으로 본 개시에 따른 상담 서비스 제공 장치는, 영상의 얼굴 영역에 아바타 그래픽을 합성하여 생성되 는 아바타 영상, 제 1 심리 상태 정보, 및 제 2 심리 상태 정보 중 적어도 하나를 출력할 수 있다(S230). 가령 상담 서비스 제공 장치는 아바타 영상, 상태 정보 영상, 및/또는 상담용 영상을 상담자 단말로 전송하거나, 또는 상담 서비스 제공 장치가 상담자 단말과 동일한 장치로 구현되는 경우에는 상담용 영상을 상담자 단말의 출력부(미도시)를 통해 곧바로 출력할 수도 있다. 영상 출력부는, 아바타 영상과 상태 정보 영상을 합성하여 상담용 영상을 생성할 수 있다. 또는 영상 출력 부는, 아바타 영상 상에 상태 정보 영상을 오버레이(overlay)하여 상담용 영상을 생성할 수 있다. 이 경우 상태 정보 영상은 아바타 영상 상의 적어도 일 부분에 중첩하여 출력될 수 있다. 가령 상태 정보 영상에 표시되 는 피상담자의 심리 상태에 관한 정보가 피상담자의 얼굴 영역에 대응되는 아바타 그래픽을를 가리지 않도록, 아바타 영상 상의 엣지(edge) 영역에 중첩하여 출력될 수 있다. 다만 이에 한정되는 것은 아니다. 도 4는 본 개시의 몇몇 실시예에 따른 상담 서비스 제공 방법을 제공하기 위한 컴퓨팅 장치를 나타낸 블록도이 다. 여기서 상담 서비스 제공 방법을 제공하는 컴퓨팅 장치는, 전술한 상담 서비스 제공 장치이거나, 또는 상담 서비스에 참여하기 위해 상담 서비스 제공 장치와 통신적으로 연결되는 피상담자 단말이나 상담 자 단말일 수 있다. 다만 이에 한정되는 것은 아니다. 도 4를 참조하면, 본 개시에 따른 컴퓨팅 장치는 하나 이상의 프로세서, 프로세서에 의하여 수행되 는 프로그램을 로드하는 메모리, 프로그램 및 각종 데이터를 저장하는 스토리지, 및 통신 인터페이스 를 포함할 수 있다. 다만, 상술한 구성 요소들은 본 개시에 따른 컴퓨팅 장치를 구현하는데 있어서 필 수적인 것은 아니어서, 컴퓨팅 장치는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가 질 수 있다. 예컨대 컴퓨팅 장치는 출력부 및/또는 입력부(미도시)를 더 포함하거나, 또는 스토리지가 생략될 수도 있다. 프로그램은 메모리에 로드될 때 프로세서로 하여금 본 개시의 다양한 실시예에 따른 방법/동작을 수행 하게끔 하는 명령어들(instructions)을 포함할 수 있다. 즉, 프로세서는 명령어들을 실행함으로써, 본 개시 의 다양한 실시예에 따른 방법/동작들을 수행할 수 있다. 프로그램은 기능을 기준으로 묶인 일련의 컴퓨터 판독 가능 명령어들로 구성되고, 프로세서에 의해 실행되는 것을 가리킨다. 프로세서는 컴퓨팅 장치의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 개시의 기술 분야에 잘 알려진 임의의 형태의 프로세서 중 적어도 하나를 포함하여 구성될 수 있다. 또 한, 프로세서는 본 개시의 다양한 실시예들에 따른 방법/동작을 실행하기 위한 적어도 하나의 애플리케이션 또는 프로그램에 대한 연산을 수행할 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리는 본 개시의 다양한 실시예들에 따른 방 법/동작을 실행하기 위하여 스토리지로부터 하나 이상의 프로그램을 로드할 수 있다. 메모리는 RAM과 같은 휘발성 메모리로 구현될 수 있을 것이나, 본 개시의 기술적 범위는 이에 한정되지 않는다. 스토리지는 프로그램을 비임시적으로 저장할 수 있다. 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 개시가 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 통신 인터페이스는 유/무선 통신 모 듈일 수 있다. 이상에서 설명한 본 개시의 실시예는 장치 및 방법을 통해서만 구현이 되는 것은 아니며, 본 개시의 실시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있다. 이상에서 본 개시의 실시예에 대하여 상세하게 설명하였지만 본 개시의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 개시의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 개시의 권리범위에 속하는 것이다.도면 도면1 도면2 도면3 도면4"}
{"patent_id": "10-2022-0003940", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 몇몇 실시예에 따른 상담 서비스 제공 장치를 나타낸 블록도이다. 도 2는 본 개시의 몇몇 실시예에 따른 상담 서비스 제공 방법을 도시한 순서도이다. 도 3은 본 개시의 몇몇 실시예에 따른 상담 서비스 제공 방법을 도시한 순서도이다. 도 4는 본 개시의 몇몇 실시예에 따른 상담 서비스 제공 방법을 제공하기 위한 컴퓨팅 장치를 나타낸 블록도이 다."}
