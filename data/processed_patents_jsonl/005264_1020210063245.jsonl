{"patent_id": "10-2021-0063245", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0155700", "출원번호": "10-2021-0063245", "발명의 명칭": "인공지능을 이용한 군중 계수 장치 및 방법", "출원인": "(주)케이아이오티", "발명자": "이재준"}}
{"patent_id": "10-2021-0063245", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라 모듈(Camera Module)이 주변 영상을 촬영하는 촬영단계; 및상기 카메라 모듈이 촬영한 대상 영상(Target Image)을 분석하여 상기 대상 영상에 포함된 객체의 수를 검출하는 검출단계;를 포함하는 것을 특징으로 하는 인공지능을 이용한 군중 계수 방법."}
{"patent_id": "10-2021-0063245", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 카메라 모듈은제 1 카메라부(First Camera Part)와 제 2 카메라(Second Camera Part)를 포함하고,상기 제 1 카메라부와 상기 제 2 카메라부의 촬영 영역은 적어도 일부가 서로 다른 것을 특징으로 하는 인공지능을 이용한 군중 계수 방법."}
{"patent_id": "10-2021-0063245", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 카메라 모듈의 촬영 영역에 대한 위치 정보를 판별하여 저장하는 단계;상기 카메라 모듈의 설치 위치에 대한 정보를 판별하여 저장하는 단계; 및상기 대상 영상에서 적어도 하나의 상기 객체를 판별하는 단계;를 더 포함하고,상기 검출단계에서는상기 대상 영상에서 객체의 위치 정보 및 상기 객체의 위치에서의 상기 객체의 기준 정보를 근거로 하여 상기객체의 수를 검출하는 것을 특징으로 하는 인공지능을 이용한 군중 계수 방법."}
{"patent_id": "10-2021-0063245", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 카메라 모듈이 주변의 비교 영상(Comparison Image)을 촬영하여 저장하는 단계; 및상기 비교 영상에 대해 객체의 수를 검출하는 단계;를 더 포함하고,상기 검출단계에서는상기 대상 영상을 적어도 하나의 상기 비교 영상과 비교하여 상기 객체의 수를 검출하는 것을 특징으로 하는 인공지능을 이용한 군중 계수 방법."}
{"patent_id": "10-2021-0063245", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "주변 영상을 촬영하는 카메라 모듈(Camera Module); 및상기 카메라 모듈이 촬영한 대상 영상(Target Image)을 분석하여 상기 대상 영상에 포함된 객체의 수를 검출하는 검출부;를 포함하는 것을 특징으로 하는 인공지능을 이용한 군중 계수 장치.공개특허 10-2022-0155700-3-"}
{"patent_id": "10-2021-0063245", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 군중 계수 장치 및 방법에 관한 것이다. 보다 자세하게는, 본 발명은 군중이 위치 하는 부분의 패턴을 이용하여 신속하고 정확하게 군중의 수를 검출하는 인공지능을 이용한 군중 계수 장치 및 방 법에 관한 것이다. 본 발명에 따른 인공지능을 이용한 군중 계수 방법은 카메라 모듈(Camera Module)이 주변 영상을 촬영하는 촬영 단계 및 상기 카메라 모듈이 촬영한 대상 영상(Target Image)을 분석하여 상기 대상 영상에 포함된 객체의 수를 검출하는 검출단계를 포함할 수 있다."}
{"patent_id": "10-2021-0063245", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 군중 계수 장치 및 방법에 관한 것이다. 보다 자세하게는, 본 발명은 군중이 위 치하는 부분의 패턴을 이용하여 신속하고 정확하게 군중의 수를 검출하는 인공지능을 이용한 군중 계수 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0063245", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 들어 뮤직 콘서트 또는 경기장에서의 스포츠 경기뿐만 아니라 특정 장소에서의 다양한 군중 집회, 모임이 증가하고 있다. 그 모임을 주최하거나 그 모임에 대한 정보를 수집하고 분석하는 언론기관 등에서는 그 군중 집회에 모인 인원 수를 정확하게 파악할 필요가 있다. 종래에는 인력이 직접 계수하거나, 운집한 군중들에서 샘플을 추출해서 그 샘플의 인원수를 카운팅해서 전체 인 원수를 유추하는 통계적 방법을 이용하였다. 이러한 방법은 인력을 이용할 경우 적지 않은 인건비가 필요하고, 군중의 수를 검출하는데 과도하게 긴 시간이 필요하다는 문제점이 있다. 이러한 문제점을 해결하기 위한 종래기술로서 대한민국 공개특허공보 제10-2013-0065234호(발명의 명칭 : 객체 자동 카운팅 방법, 2013.06.19.)(문헌 1)에서는 촬영한 영상에서 객체의 특정한 색상의 픽셀을 추출하고, 추출 한 픽셀의 수를 카운팅하여 객체의 수를 검출하는 기술을 게시하고 있다. 그러나 문헌 1에 따른 기술에서는 객체가 특정한 색상을 갖지 않는 경우에 객체의 수를 정확하게 검출하는 것이 어렵다는 문제점이 있다. 아울러, 문헌 1에 따른 기술에서는 특정 색상의 픽셀을 일일이 카운팅하기 때문에 객체의 수를 검출하는데 상당 한 시간이 소요되며, 계산이 복잡하다는 문제점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) [문헌 1] 대한민국 공개특허공보 제10-2013-0065234호"}
{"patent_id": "10-2021-0063245", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 군중이 위치하는 부분의 패턴을 이용하여 군중의 수를 검출하는 인공지능을 이용한 군중 계수 장치 및 방법을 제공하는데 그 목적이 있다."}
{"patent_id": "10-2021-0063245", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 인공지능을 이용한 군중 계수 방법은 카메라 모듈(Camera Module)이 주변 영상을 촬영하는 촬영 단계 및 상기 카메라 모듈이 촬영한 대상 영상(Target Image)을 분석하여 상기 대상 영상에 포함된 객체의 수를 검출하는 검출단계를 포함할 수 있다. 또한, 상기 카메라 모듈은 제 1 카메라부(First Camera Part)와 제 2 카메라(Second Camera Part)를 포함하고, 상기 제 1 카메라부와 상기 제 2 카메라부의 촬영 영역은 적어도 일부가 서로 다를 수 있다. 또한, 상기 카메라 모듈의 촬영 영역에 대한 위치 정보를 판별하여 저장하는 단계, 상기 카메라 모듈의 설치 위 치에 대한 정보를 판별하여 저장하는 단계 및 상기 대상 영상에서 적어도 하나의 상기 객체를 판별하는 단계를 더 포함하고, 상기 검출단계에서는 상기 대상 영상에서 객체의 위치 정보 및 상기 객체의 위치에서의 상기 객체 의 기준 정보를 근거로 하여 상기 객체의 수를 검출할 수 있다.또한, 상기 카메라 모듈이 주변의 비교 영상(Comparison Image)을 촬영하여 저장하는 단계 및 상기 비교 영상에 대해 객체의 수를 검출하는 단계를 더 포함하고, 상기 검출단계에서는 상기 대상 영상을 적어도 하나의 상기 비 교 영상과 비교하여 상기 객체의 수를 검출할 수 있다. 본 발명에 따른 인공지능을 이용한 군중 계수 장치는 주변 영상을 촬영하는 카메라 모듈(Camera Module) 및 상 기 카메라 모듈이 촬영한 대상 영상(Target Image)을 분석하여 상기 대상 영상에 포함된 객체의 수를 검출하는 검출부를 포함할 수 있다."}
{"patent_id": "10-2021-0063245", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 인공지능을 이용한 군중 계수 장치 및 방법은 군중이 모여 있는 부분의 패턴을 이용하여 군중의 수를 검출하기 때문에 신속한 군중 계수가 가능하다는 효과가 있다."}
{"patent_id": "10-2021-0063245", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명에 따른 인공지능을 이용한 군중 계수 장치 및 방법에 대해 상세히 설명 한다. 본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세한 설명에 상세하게 설명하고자 한다. 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해될 수 있다. 본 발명을 설명함에 있어서 제 1, 제 2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되지 않을 수 있다. 상기 용어들은 하나의 구성요소를 다른 구성요소로 부터 구별하는 목적으로만 사용될 수 있다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제 1 구성요 소는 제 2 구성요소로 명명될 수 있고, 유사하게 제 2 구성요소도 제 1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목 을 포함할 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급되는 경우는, 그 다른 구성요소 에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해될 수 있다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해될 수 있다. 본 문서에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 본 문서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것으로서, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해될 수 있다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석될 수 있으며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않을 수 있다. 아울러, 본 문서에 개시된 실시예는 당 업계에서 평균적인 지식을 가진 자에게 보다 완전하게 설명하기 위해서 제공되는 것으로서, 도면에서의 요소들의 형상 및 크기 등은 보다 명확한 설명을 위해 과장될 수 있다. 본 문서에서 본 발명을 설명함에 있어서, 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지 를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 수 있다. 본 문서에서 설명되는 다양한 실시예들은 소프트웨어, 하드웨어 또는 이들의 조합된 것을 이용하여 컴퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 본 발명의 실시예는 ASICs (application specific integrated circuits), DSPs (digital signal processors), DSPDs (digital signal processing devices), PLDs (programmable logic devices), FPGAs (field programmable gate arrays, 프로세서(processors), 제어기(controllers), 마이크로 컨 트롤러(micro-controllers), 마이크로 프로세서(microprocessors), 기능 수행을 위한 전기적인 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 한편, 소프트웨어적인 구현에 의하면, 본 발명에서 절차나 기능과 같은 실시예들은 적어도 하나의 기능 또는 작 동을 수행하게 하는 별개의 소프트웨어 모듈과 함께 구현될 수 있다. 도 1 내지 도 3은 본 발명에 따른 인공지능을 이용한 군중 계수 장치에 대해 설명하기 위한 도면이다. 도 1을 살펴보면, 본 발명에 따른 인공지능을 이용한 군중 계수 장치(1, 이하 \"계수 장치\"라 칭할 수 있다.)는 카메라 모듈(Camera Module, 10) 및 서버(Server, 20)를 포함할 수 있다. 카메라 모듈은 주변의 영상을 촬영할 수 있다. 여기서, 주변은 카메라 모듈의 촬영이 가능한 영역, 즉 촬영 영역을 의미할 수 있다. 서버는 적어도 하나의 카메라 모듈과 유선 및/또는 무선 방식으로 통신을 수행할 수 있다. 서버는 적어도 하나의 카메라 모듈로부터 카메라 모듈이 촬영한 영상을 전송받고, 전송받은 영상을 분석할 수 있다. 서버는 인공지능을 이용하여 카메라 모듈이 촬영한 영상에서 객체(OB)의 수를 판별할 수 있다. 아울러, 서버는 적어도 하나의 카메라 모듈을 관리할 수 있다. 카메라 모듈이 촬영한 영상은 대상 영상(Target Image), 비교 영상(Comparison Image) 및 샘플 영상 (Sample Image)을 포함할 수 있다. 샘플 영상은 부분 영상(Part Image)이라고도 할 수 있다. 대상 영상은 군중의 수를 검출하기 위해 촬영한 영상일 수 있다. 예를 들어, 20xx년 xx월 xx일 aa시에 AA광장 에 모인 군중의 수를 판별하는 경우, 카메라 모듈이 20xx년 xx월 xx일 aa시에 AA광장을 촬영한 영상이 대상 영상이 될 수 있다. 비교 영상은 대상 영상에서 군중의 수를 신속하고 정확하게 검출하기 위한 목적으로 대상 영상과 비교하는데 사 용하는 영상이라고 할 수 있다. 비교 영상은 비교 패턴 블록(Comparison Pattern Block)을 포함하는 것이 가능하다. 비교 패턴 블록은 대상 영상에서 군중의 수를 신속하고 정확하게 검출하기 위한 목적으로 대상 영상과 비교하는 데 사용하는 영상 블록의 일종이라고 할 수 있다. 이하에서는 비교 패턴 블록을 비교 블록이라고 칭할 수 있다. 서버는 주기적 또는 비주기적으로 적어도 하나의 비교 영상(혹은 비교 블록)을 추가하거나, 변경하거나, 삭 제하는 것이 가능하다. 샘플 영상은 기준 영상을 생성하기 위해 사용되는 영상일 수 있다. 대상 영상, 비교 영상, 샘플 영상, 비교 블록은 이하의 설명을 통해 보다 명확히 설명될 것이다. 도 2를 살펴보면, 카메라 모듈은 제 1 제어부, 제 1 통신부, 제 1 인터페이스부, 메모리부 , 카메라 위치 정보부, 제 1 카메라부, 제 1 조정부, 제 2 카메라부 및 제 2 조정부를 포함할 수 있다. 도 2에 도시된 구성요소들이 필수적인 것은 아니어서, 그보다 많은 구성요소들을 갖거나 그보다 적은 구성요소 들을 갖는 카메라 모듈을 구현하는 것도 가능하다. 제 1 제어부, 제 1 통신부 및 제 1 인터페이스부에 관련해서 \"제 1\"이라는 용어를 사용한 이유 는 이후에 설명할 서버의 구성 부분과 구분하기 위함이다. 예를 들면, 제 1 통신부에서 \"제 1\"이라는 용어를 사용한 이유는 이후에 설명할 서버의 통신부, 즉 제 2 통신부와 구분하기 위함이다. 제 1 제어부는 카메라 모듈의 전반적인 기능 및 동작을 제어할 수 있다. 예를 들면, 제 1 제어부 는 카메라 모듈의 영상 촬영을 제어할 수 있으며, 서버와의 통신을 제어할 수 있다. 제 1 통신부는 제 1 제어부의 제어에 따라 유선 및/또는 무선 방식으로 다른 기기, 예컨대 서버 와 통신을 수행할 수 있다. 제 1 인터페이스부는 제 1 제어부의 제어에 따라 다른 기기와의 연결을 위한 통로를 제공할 수 있다. 메모리부는 제 1 제어부의 제어에 따라 카메라 모듈의 동작 및/또는 기능 구현에 필요한 다양한 프로그램, 데이터 등을 저장할 수 있다. 카메라 위치 정보부는 제 1 제어부의 제어에 따라 카메라 모듈의 위치 정보를 판별할 수 있다. 예를 들면, 카메라 위치 정보부는 카메라 모듈의 GPS 좌표 정보를 판별할 수 있다. 카메라 위치 정보부는, 카메라 모듈이 차량 또는 건물 내부에 설치되는 경우에, 차량 또는 건물 내에 서의 카메라 모듈의 위치에 대한 정보를 판별할 수 있다. 예를 들면, 카메라 모듈이 지하철 등에 사용 되는 전동차 내에 설치되는 경우에, 카메라 위치 정보부는 카메라 모듈이 설치된 전동차의 고유 번호 등의 고유 정보, 전동차 내에서의 카메라 모듈의 위치에 대한 정보 등을 판별할 수 있다. 제 1 카메라부는 제 1 제어부의 제어에 따라 주변의 영상을 촬영할 수 있다. 예를 들면, 제 1 카메라 부는 주변의 영상을 동영상 및/또는 사진 등의 정지 영상 타입으로 촬영할 수 있다. 제 1 조정부는 제 1 제어부의 제어에 따라 제 1 카메라부를 회전시키거나 스윙(Swing)시키는 등 의 방법으로 촬영 각도를 조절할 수 있다. 제 2 카메라부는 제 1 제어부의 제어에 따라 주변의 영상을 촬영할 수 있다. 예를 들면, 제 2 카메라 부는 주변의 영상을 동영상 및/또는 사진 등의 정지 영상 타입으로 촬영할 수 있다. 제 2 조정부는 제 1 제어부의 제어에 따라 제 2 카메라부를 회전시키거나 스윙시키는 등의 방법 으로 촬영 각도를 조절할 수 있다. 도 3을 살펴보면, 서버는 제 2 제어부, 제 2 통신부, 제 2 인터페이스부, 데이터 베이스부 (DB, 230), 촬영 영역 위치 정보부, 기준 정보부, 비교 영상부, 기준 영상부 및 검출부 를 포함할 수 있다. 도 3에 도시된 구성요소들이 필수적인 것은 아니어서, 그보다 많은 구성요소들을 갖거나 그보다 적은 구성요소 들을 갖는 서버를 구현하는 것도 가능하다. 제 2 제어부는 서버의 전반적인 기능 및 동작을 제어할 수 있다. 예를 들면, 제 2 제어부는 군 중 계수를 위한 설정을 제어할 수 있으며, 군중 계수 과정을 제어할 수 있다. 제 2 통신부는 제 2 제어부의 제어에 따라 유선 및/또는 무선 방식으로 다른 기기, 예컨대 카메라 모 듈과 통신을 수행할 수 있다. 제 2 인터페이스부는 제 2 제어부의 제어에 따라 다른 기기와의 연결을 위한 통로를 제공할 수 있다. 데이터 베이스부(DB, 230)는 제 2 제어부의 제어에 따라 서버의 운용에 필요한 다양한 프로그램, 데이 터 등을 저장할 수 있다. 예를 들면, 데이터 베이스부(DB, 230)는 각각의 카메라 모듈의 설치 위치(카메라 모듈의 위치 정보)에 대한 정보 및 카메라 모듈에 대응되는 영역(촬영 영역)에 대한 정보를 저장하고 관리할 수 있다.데이터 베이스부(DB, 230)는 미리 설정한 기준 정보, 비교 영상 및 기준 영상을 저장하고 관리할 수 있다. 아울러, 데이터 베이스부(DB, 230)는 미리 설정된 다양한 영상 패턴, 비교 블록 등에 대한 정보를 저장하고 관 리할 수 있다. 촬영 영역 위치 정보부는 제 2 제어부의 제어에 따라 카메라 모듈에 대응하는 영역, 즉 촬영 영 역의 위치 정보를 판별할 수 있다. 여기서, 촬영 영역은 카메라 모듈이 촬영한 영상에 포함되는 영역이라고 할 수 있다. 또는, 촬영 영역은 카메라 모듈의 촬영 가능 영역이라고도 할 수 있다. 기준 정보부는 제 2 제어부의 제어에 따라 객체를 판별하기 위해 기준이 되는 정보, 즉 기준 정보를 생성 및/또는 판별하고 관리할 수 있다. 여기서, 객체는 군중에 포함되는 사람을 의미할 수 있다. 예를 들면, 객체는 남성, 여성, 성인, 어린이, 유아, 장애인, 노약자 등을 포함할 수 있다. 기준 정보는 객체의 형태에 대한 정보, 객체의 위치에 따른 사이즈(키 등)에 대한 정보 등을 포함할 수 있다. 기준 정보에 대해서는 이하에서 보다 상세히 설명하기로 한다. 비교 영상부는 제 2 제어부의 제어에 따라 비교 영상 및/또는 비교 블록을 생성, 저장, 관리할 수 있 다. 비교 영상은 군중의 수를 판별하기 위해 대상 영상과 비교하는 영상일 수 있다. 비교 블록은 군중의 수를 판별하기 위해 대상 블록과 비교하는 영상으로서, 비교 영상의 일부일 수 있다. 이러한 비교 영상부는 색상 정보부 및 형태 정보부를 포함할 수 있다. 색상 정보부는 비교 영상의 색상에 대한 정보를 생성, 저장, 관리할 수 있다. 예를 들어, 카메라 모듈이 비교 영상을 촬영하는 시간, 계절, 날씨 등에 따라 영상의 색상이 달라질 수 있 다. 색상 정보부는 비교 영상을 촬영하는 시간, 계절, 날씨 등의 변수와 색상에 대한 정보를 매칭시킬 수 있다. 형태 정보부는 비교 영상에 포함되는 군중 그룹 및/또는 객체의 다양한 형태에 대한 정보를 생성, 저장, 관리할 수 있다. 예를 들어, 카메라 모듈이 비교 영상을 촬영하는 각도, 객체의 포즈, 모자 등의 의상, 군중이 모여있는 타 입 등에 따라 객체 또는 군중 그룹의 형태가 달라질 수 있다. 이러한 객체 및/또는 군중 그룹의 형태에 대한 정보를 형태 정보부가 생성, 저장, 관리할 수 있다. 비교 영상에 대해서는 이하에서 보다 상세히 설명하기로 한다. 검출부는 제 2 제어부의 제어에 따라 카메라 모듈이 촬영한 대상 영상을 분석하거나, 대상 영상 과 비교 영상을 비교하는 방법으로 대상 영상에 포함된 객체의 수(군중의 수)를 검출할 수 있다. 이러한 검출부는 객체 검출부, 객체 수 검출부 및 합산부를 포함할 수 있다. 객체 검출부는 카메라 모듈이 촬영한 영상에서 사이즈에 대한 기준 정보 및 형태에 대한 기준 정보를 이용하여 객체(사람)을 검출할 수 있다. 객체 수 검출부는 카메라 모듈이 촬영한 영상에서 객체의 수를 검출할 수 있다. 이를 위해, 객체 수 검출부는 객체 검출부가 검출한 정보를 이용하거나, 비교 영상과 대상 영상을 이용하는 것이 가능하 다. 합산부는 객체 수 검출부가 검출한 정보를 근거로 하여 카메라 모듈이 촬영한 대상 영상에서 객 체의 수의 총 합(군중의 총 수)을 검출할 수 있다. 군중의 수를 검출하는 방법은 이하의 설명을 통해 보다 명확히될 것이다. 도 4 내지 도 7은 기준 정보를 설정하고 이용하는 방법에 대해 설명하기 위한 도면이다. 이하에서는 이상에서 상세히 설명한 부분에 대한 설명은 생략될 수 있다. 도 4에 나타나 있는 바와 같이, 설정 모드(Setting Mode)에서 카메라 모듈이 주변의 영상을 촬영할 수 있다 (S100). 여기서, 설정 모드는 기준 정보, 비교 영상 및/또는 기준 영상 등을 생성하고, 군중 계수를 위해 준비하는 모드 라고 할 수 있다. 카메라 모듈이 촬영한 영상은 제 1 통신부를 통해 서버로 송신될 수 있다. 그러면 서버의 기준 정보부에서는 제 2 제어부의 제어에 따라 카메라 모듈로부터 수신한 영 상을 분석할 수 있다(S200). 기준 정보부는, 분석 결과를 근거로 하여, 촬영 영역의 위치 정보를 판별할 수 있다(S210). 촬영 영역의 위치 정보는 GPS 좌표 정보를 포함할 수 있다. 또는, 촬영 영역의 위치 정보는 카메라 모듈을 기준으로 하는 상대적인 위치 정보를 포함할 수 있다. 예를 들면, 촬영 영역의 제 1 지점은 카메라 모듈로부터 얼마만큼 떨어져 있고, 제 1 지점에 대응하는 카메 라 모듈의 촬영 각도는 어느 정도이고, 카메라 모듈을 기준으로 제 1 지점이 위치하는 방향은 어느 방 향인지에 대한 정보가 촬영 영역의 위치 정보로서 이용될 수 있다. 아울러, 서버는 카메라 모듈의 위치 정보, 측 카메라 모듈이 설치된 지점의 위치 정보를 판별할 수 있다(S220). 여기서, 카메라 모듈의 위치 정보는 카메라 모듈의 GPS 좌표 정보, 카메라 모듈의 수직방향 (Vertical Direction)으로의 위치 정보, 즉 고도 정보(높이 정보)를 포함할 수 있다. 이후, 기준 정보부는 촬영 영역에 대한 위치 정보와 카메라 모듈의 위치 정보를 이용하여 촬영 영역 상의 위치에 따른 기준 사이즈 정보를 판별할 수 있다(S230). 카메라 모듈이 도 5에 나타나 있는 바와 같은 영역(촬영 영역)을 촬영하는 경우를 가정하여 보자. 기준 정보부는 카메라 모듈이 촬영한 영상(도 5의 영상)으로부터 촬영 영역의 제 1 지점(P1), 제 2 지 점(P2), 제 3 지점(P3) 및 제 4 지점(P4)의 위치 정보를 판별할 수 있다. 여기서는, 이해를 돕기 위해 촬영 영역에서 총 4개의 지점에 대한 위치 정보를 판별하고 이를 이용하는 경우를 설명하고 있으나, 본 발명은 이에 한정되지 않을 수 있다. 예를 들면, 본 발명에서는 촬영 영역의 모든 지점에 대한 위치 정보를 판별하고 이를 이용하는 것이 가능하다. 위치 정보는 해당 지점의 GPS 좌표 정보, 카메라 모듈로부터의 거리에 대한 정보, 해당 지점에 대응하는 카 메라 모듈의 촬영 각도에 대한 정보, 카메라 모듈을 기준으로 하는 방향에 대한 정보 등을 포함할 수 있다. 기준 정보부는 판별한 촬영 영역의 위치 정보를 근거로 하여 위치에 따른 기준 정보를 생성 및 판별할 수 있다. 보통 사람의 경우 키가 50cm(유아 등)~200cm(성인 등)인 경우를 가정하여 보자. 이러한 경우, 제 2 지점(P2)에 대응하는 객체(사람)의 키에 대한 기준 정보를 [10m, 0.5cm~2.0cm, 50cm~200c m]로 설정할 수 있다. 예를 들어, 도 6에 나타나 있는 바와 같이, 카메라 모듈이 촬영한 영상에서 카메라 모듈로부터(Pc) 10m 떨어진 제 2 지점(P2)에 위치하는 사람의 키가 0.5cm~2.0cm(L1)로 나타나 있는 경우에, 그 사람의 실제 키는 100배인 50cm~200cm인 것을 의미할 수 있다. 제 2 지점(P2)보다 카메라 모듈로부터 더 멀리 떨어진 제 1 지점(P1)에 대응하는 객체(사람)의 키에 대한 기준 정보는 [50m, 0.1cm~0.4cm, 50cm~200cm]로 설정하는 것이 가능하다. 예를 들어, 도 6에 나타나 있는 바와 같이, 카메라 모듈이 촬영한 영상에서 카메라 모듈로부터(Pc) 50m 떨어진 지점(P1)에 위치하는 사람의 키가 0.1cm~0.4cm(L2)로 나타나 있는 경우에, 그 사람의 실제 키는 500배인50cm~200cm인 것을 의미할 수 있다. 카메라 모듈이 촬영한 영상에서 카메라 모듈로부터 10m떨어진 위치(P2)에 키가 1.8cm인 물체가 검출되 는 위치하는 경우를 가정하여 보자. 이러한 경우에는, 위에서 언급한 객체의 키에 대한 기준 정보를 적용하면 해당 물체의 키는 대략 180cm이고, 이 에 따라 해당 물체의 키는 보통 사람에 대응되는 것으로 판단할 수 있다. 물론, 키가 충분히 작은 영유아 또는 농구 선수 등 키가 유별나게 큰 사람의 경우에는 키에 대한 다른 기준 정 보를 적용하는 것이 가능하다. 이후, 검출된 물체의 형태를 근거로 하여 검출된 물체가 객체(사람)인 것으로 판단하는 것이 가능할 수 있다. 도 7에 나타나 있는 바와 같이, 카메라 모듈이 촬영한 영상에서 제 1 지점(P1)에 과도하게 큰 키, 예컨대 1.8cm의 키를 갖는 물체가 위치하는 경우를 가정하여 보자. 이러한 경우에는 기준 정보를 근거로 판단한 물체의 실제 키는 대략 9m일 수 있다. 사람이 9m의 키를 갖는 경우는 충분히 드물거나 불가능하기 때문에 해당 물체는 객체(사람)가 아닌 동상, 마네 킹, 간판, 벽화 또는 영상 등으로 판단할 수 있다. 이러한 경우에는 해당 물체를 카운팅하지 않을 수 있다. 기준 정보를 생성 및/또는 판별하기 위해 카메라 모듈로부터의 거리 뿐 아니라, 촬영 영역에서 위치에 따른 촬영 각도를 함께 고려하는 것이 가능하다. 예를 들어, 카메라 모듈이 고층 건물 등에 설치되는 경우에 촬영 영상 상의 위치에 따라 촬영 각도는 다를 수 있다. 기준 정보는 객체의 형태 정보를 포함하는 것이 가능하다. 예를 들어, 보통 사람의 경우 머리, 팔, 다리 및 몸통 부분을 갖고, 긴 형태를 갖는 것이 가능하다. 이러한 보 통 사람의 형태 정보가 기준 정보로서 이용될 수 있다. 만약, 카메라 모듈이 촬영한 영상에서 지면을 네 개의 발로 지지하고, 꼬리를 갖는 형태를 갖는 물체가 나 타나 있는 경우에는, 해당 물체는 객체(사람)이 아닌 개, 말 등의 동물일 가능성이 높다. 따라서 이러한 경우에는 카운팅하지 않을 수 있다. 이상에서와 같이, 기준 정보부가 촬영 영역의 위치에 따른 기준 정보를 생성 및/또는 판별하는 경우에는, 촬영 영상의 환경에 무관하게 객체와 객체의 수를 신속하고 정밀하게 판별하는 것이 가능할 수 있다. 예를 들어, 촬영 영역에 대응하여 기준 정보를 각각 설정하지 않고, 모든 카메라 모듈에 대응하여 동일한 기준을 설정한 경우를 가정하여 보자. 이러한 경우에는 촬영 영역의 바닥의 굴곡 또는 경사도, 주변 건물의 배치 등의 주변 환경적 요인으로 인해 객 체 또는 객체의 수의 검출 과정에서 오류가 발생할 가능성이 상대적으로 높을 수 있다. 반면에, 카메라 모듈에 따라 촬영 영역에 대응하여 기준 정보를 판별하고 생성하는 경우에는, 해당 촬영 영 역의 주변 환경적 요인을 고려하여 기준 정보를 생성하기 때문에 보다 정밀하게 신속한 객체 또는 객체의 수의 검출이 가능할 수 있다. 서버는 기준 정보는 주기적 혹은 비주기적으로 갱신하거나, 업데이트 하거나, 추가하거나 삭제하는 것이 가 능하다. 예를 들어, 서버는 카메라 모듈이 촬영한 영상을 분석하여 객체가 아닌 다른 부분, 예컨대 건물, 도로 등 배경이 되는 부분이 변경되는 것으로 판단하는 경우에, 기준 정보를 새롭게 생성 및/또는 판별할 수 있다. 자세하게는, 기준 영상을 변경하는 경우에 기준 정보도 새롭게 생성 및/또는 판별하여 변경하는 것이 가능할 수 있다. 기준 영상을 변경하는 방법은 이하의 도 19에서 상세히 설명하기로 한다. 서버의 기준 정보부는 이상에서 설명한 기준 정보를 이용하여 카메라 모듈이 촬영한 영상에서 객 체(사람)를 판별할 수 있다. 이하에서는 첨부된 도면을 참조하여 비교 영상 및 기준 영상에 대해 설명하기로 한다. 도 8 내지 도 20은 비교 영상 및 기준 영상에 대해 설명하기 위한 도면이다. 이하에서는 이상에서 상세히 설명 한 부분에 대한 설명은 생략될 수 있다. 도 8을 살펴보면, 설정 모드에서 카메라 모듈이 주변 영상을 촬영(S100)하면, 비교 영상부는 촬영한 영상을 비교 영상으로 설정할지의 여부를 판단할 수 있다(S110). S110 단계에서 판단결과, 촬영한 영상을 비교 영상으로 설정하지 않는 경우에는 미리 설정된 제 1 기능(Default 1)을 수행할 수 있다(S120). 제 1 기능은 다음 영상을 비교 영상으로 설정할지의 여부를 판단하는 기능, 비교 영영 설정을 종료하는지의 여 부를 판단하는 기능 등을 예로 들 수 있다. 반면에, S110 단계에서 판단결과, 촬영한 영상을 비교 영상으로 설정하는 경우에는 비교 영상부는 해당 영 상에서 객체의 수를 검출할 수 있다(S130). 이후, 비교 영상부는 해당 영상을 비교 영상으로 저장할 수 있다(S140). 한편, 카메라 모듈이 주변 영상을 촬영(S100)한 이후에 기준 영상을 설정하는 것이 가능하다. 기준 영상에 대한 내용은 도 17 이후에 보다 상세히 설명하기로 한다. 도 9의 (A), (B)에 나타나 있는 바와 같은 영상을 비교 영상으로 설정하는 경우를 가정하여 보자. 도 9의 (A)의 경우에는 카메라 모듈이 촬영한 영상에서 객체(OB)들이 촬영 영역 내에서 단독으로 흩어져 있 는 상태라고 할 수 있다. 이러한 경우에는, 미리 설정된 기준 정보를 근거로 하여 영상에 포함되어 있는 객체의 수, 즉 군중의 수를 검출 할 수 있다. 예를 들면, 도 9의 (A)의 영상에서 객체(OB)의 위치 정보(객체(OB)가 위치한 지점의 위치 정보) 및 객체(OB)의 위치에서의 객체(OB)의 키, 형태 등의 기준 정보를 근거로 하여 객체의 수를 검출할 수 있다. 이는 서버의 검출부의 객체 검출부 및 객체 수 검출부가 기준 정보를 이용하여 수행할 수 있다. 이후, 도 9의 (A)의 영상의 패턴을 저장하고, 도 9의 (A)의 영상에 포함된 객체의 수에 대한 정보를 해당 패턴 에 매칭시켜 저장할 수 있다. 예를 들면, 도 10에 나타나 있는 바와 같이, 도 9의 (A)의 패턴에 대응하는 영상을 제 1 비교 영상으로 설정하 여 저장할 수 있다. 아울러, 제 1 비교 영상에 포함된 객체의 수(인원 수), 제 1 비교 영상을 촬영한 시간, 제 1 비교 영상에 대응 하는 날씨 또는 시야에 대한 정보를 제 1 비교 영상에 매칭시켜 저장할 수 있다. 도 9의 (B)의 경우에는 카메라 모듈이 촬영한 영상에서 객체(OB)들이 촬영 영역 내에서 소정 지점에 무리지 어 모여있는 상태라고 할 수 있다. 이러한 경우에도, 미리 설정된 기준 정보를 근거로 하여 영상에 포함되어 있는 객체의 수, 즉 군중의 수를 검출 할 수 있다. 이후, 도 9의 (B)의 영상의 패턴을 저장하고, 도 9의 (B)의 영상에 포함된 객체의 수에 대한 정보를 해당 패턴 에 매칭시켜 저장할 수 있다. 예를 들면, 도 10에 나타나 있는 바와 같이, 도 9의 (B)의 패턴에 대응하는 영상을 제 2 비교 영상으로 설정하 여 저장할 수 있다. 아울러, 제 2 비교 영상에 포함된 객체의 수(인원 수), 제 2 비교 영상을 촬영한 시간, 제 2 비교 영상에 대응 하는 날씨 또는 시야에 대한 정보를 제 2 비교 영상에 매칭시켜 저장할 수 있다. 비교 영상부는 주기적 및/또는 비주기적으로 비교 영상을 추가하거나, 업데이트하는 것이 가능하다. 비교 영상의 수는 많을수록 정밀한 군중 계수가 가능할 수 있기 때문에 비교 영상부는 미리 설정된 주기마 다 새로운 비교 영상을 추가하는 것이 가능하다. 만약, 추가하려는 비교 영상과 충분히 유사한 경우(유사도가 미리 설정된 임계 유사도보다 더 큰 경우)에는 이 전 영상을 삭제하는 것이 가능하다. 제 1 비교 영상이 저장되어 있는 상태에서 비교 영상부가 새로운 제 10 비교 영상을 생성한 경우를 가정하 여 보자. 여기서, 제 1 비교 영상과 제 10 비교 영상의 유사도가 미리 설정된 임계 유사도보다 더 큰 경우에 제 1 비교 영상을 삭제하고, 제 10 비교 영상을 새롭게 저장할 수 있다. 물론, 보다 정밀한 군중 계수를 위해 유사도가 충분히 높은 제 1 비교 영상과 제 10 비교 영상을 함께 저장하는 것도 가능할 수 있다. 비교 영상의 개수가 많다는 것(비교 블록의 개수가 많다는 것)은 서버의 인공지능의 학습이 더 심화되었음 을 나타낼 수 있다. 아울러, 비교 영상의 개수(비교 블록의 개수)가 많으면 많을수록 보다 정밀한 군중 계수가 가능할 수 있다. 서버의 인공지능의 학습의 심화를 위해 주기적 및/또는 비주기적으로 비교 영역(비교 블록)을 생성, 업데이 트, 추가하는 것이 가능할 수 있다. 군중 계수 모드에서 카메라 모듈이 소정의 제 1 영상을 촬영한 경우를 가정하여 보자. 여기서, 군중 계수 모드는 카메라 모듈이 촬영한 영상에 포함된 객체의 수를 검출하는 모드라고 할 수 있다. 이러한 군중 계 수 모드에서 대해서는 도 21의 이후에 상세히 설명하기로 한다. 카메라 모듈이 제 1 영상을 촬영하여 서버로 전송하면, 서버의 비교 영상부는 전송받은 제 1 영상의 패턴을 분석할 수 있다. 아울러, 비교 영상부는 제 1 영상의 패턴을 미리 저장되어 있는 비교 영상들과 비교하여 유사한 영상 패턴 을 판별할 수 있다. 예를 들어, 제 1 영상의 패턴이 미리 저장된 제 1 비교 영상과 가장 유사하다고 판단한 경우에는 비교 영상부 는 제 1 비교 영상이 제 1 영상의 패턴과 가장 유사하다는 판별결과를 검출부로 전송할 수 있다. 그러면 검출부의 객체 수 검출부는 제 1 비교 영상에 포함된 객체의 수에 대한 정보를 판별하고, 판 별한 정보를 제 1 영상에 포함된 객체의 수로서 검출할 수 있다. 이상에서는 카메라 모듈이 촬영한 영상을 전체적으로 비교 영상으로 설정하는 방법을 설명하였으나, 본 발 명은 이에 한정되지 않을 수 있다. 예를 들면, 카메라 모듈이 촬영한 영상, 즉 비교 영상에서 객체(OB)가 포함된 일부 영역을 추출하고, 추출 한 일부 영역의 객체(OB)에 대응되는 영상의 패턴을 비교 블록으로 설정하는 것이 가능하다. 여기서, 비교 블록은 다른 타입의 비교 영상이라고도 할 수 있다. 이러한 관점에서는, 비교 블록은 앞선 도 9의 (A), (B)에서 설명한 비교 영상과 비교하여 사이즈가 상대적으로 작은 영상이라고 할 수 있다. 이를 고려하여 블록이라는 용어를 사용할 수 있다. 카메라 모듈이 도 11의 (A)와 같은 영상을 촬영하고, 촬영한 영상을 비교 영상부가 비교 영상으로 설 정하는 경우를 가정하여 보자. 비교 영상부는 도 11의 (A)의 영상에서 객체(OB)가 위치하는 영역, 즉 제 1 영역(AR1)과 제 2 영역(AR2)을 각각 관심 영역으로 설정할 수 있다. 이후, 도 11의 (B)에 나타나 있는 바와 같이, 관심 영역에 포함된 객체(OB)들의 외곽을 둘러싸도록 영상 블록을 설정하는 것이 가능하다. 예를 들면, 제 1 영역(AR1)에 포함된 객체(OB)들을 둘러싸도록 영상 블록을 설정하고, 설정한 영상 블록을 제 1 비교 블록(PT1)으로서 설정하여 저장하는 것이 가능하다. 다르게 표현하면, 비교 영상의 일부를 제 1 비교 블 록(PT1)으로 설정하는 것이 가능하다. 제 1 영역(AR1)에서 제 1 비교 블록(PT1)을 설정한 이후에 제 1 비교 블록(PT1)에 포함된 객체의 수를 검출할 수 있다. 예를 들면, 서버의 검출부가 제 1 비교 블록(PT1)에 포함된 객체의 수를 검출할 수 있다. 제 1 비교 블록(PT1)에 복수의 객체(OB)가 겹쳐져서(Overlap) 위치할 수 있다. 이러한 경우에는 검출부는 다른 방식으로 제 1 비교 블록(PT1)에 포함된 객체의 수를 검출할 수 있다. 이에 대해서는 추후에 상세히 설명 하기로 한다. 여기서, 비교 블록은 단수 혹은 복수의 객체(OB)들이 위치하는 부분에 대응될 수 있다. 다른 관점에서 보면, 비교 블록은 단수 혹은 복수의 객체(OB)에 대응되는 영상의 패턴을 의미할 수 있다. 다수의 객체(OB)가 소정 위치에 모여 있는 경우를 가정하자. 이러한 경우에는 객체(OB)의 수를 일일이 카운팅하는 것보다는 다수의 객체(OB)가 모여 있는 패턴을 분석하여 객체의 수를 검출하는 것이 빠를 수 있다. 이러한 비교 블록의 종류는 많을수록 군중 계수의 정밀도가 향상될 수 있다. 비교 영상부는 비교 블록의 패턴 정보를 저장하고, 해당 비교 블록에 대응되는 객체의 수(인원 수)에 대한 정보도 매칭시켜 서버의 데이터 베이스(DB, 230)에 저장할 수 있다. 도 11의 (A)의 제 2 영역(AR2)을 제 1 영역(AR1)과 비교하면, 제 2 영역(AR2)의 사이즈는 상대적으로 작지만, 제 2 영역(AR2)에도 제 1 비교 블록(PT1)이 포함될 수 있다. 아울러, 카메라 모듈과 제 2 영역(AR2) 사이 의 거리(D2)는 카메라 모듈과 제 1 영역(AR1) 사이의 거리(D1)보다 더 클 수 있다. 이는 카메라 모듈이 촬영한 영상에서 제 2 영역(AR2)의 사이즈는 제 1 영역(AR1)의 사이즈보다 작지만, 제 1 영역(AR1)에 포함된 객체의 수와 제 2 영역(AR2)에 포함된 객체의 수는 동일 혹은 유사할 수 있음을 나타낼 수 있다. 이를 고려할 때, 비교 블록에 대한 정보는 비교 블록의 패턴에 대한 정보, 비교 블록에 포함된 객체의 수에 대 한 정보, 비교 블록의 사이즈에 대한 정보, 카메라 모듈과 비교 블록 사이의 거리에 대한 정보, 카메라 모 듈을 기준으로 비교 블록이 위치하는 방향에 대한 정보 등을 포함할 수 있다. 이러한 비교 블록에 대한 정보는 서로 매칭되어 서버의 데이터 베이스에 저장될 수 있다. 도 12의 제 1 영역(AR1)과 제 3 영역(AR3)을 비교하면 제 1 영역(AR1)과 제 3 영역(AR3)의 사이즈는 서로 유사 하고, 제 1 영역(AR1)과 제 3 영역(AR3) 모두 제 1 비교 블록(PT1)을 포함할 수 있다. 아울러, 카메라 모듈 과 제 3 영역(AR3) 사이의 거리(D3)는 카메라 모듈과 제 1 영역(AR1) 사이의 거리(D1)보다 더 클 수 있 다. 이를 고려하면, 카메라 모듈이 촬영한 영상에서 제 3 영역(AR3)의 사이즈는 제 1 영역(AR1)의 사이즈와 유 사 혹은 동일하지만, 제 3 영역(AR3)에 포함된 객체의 수는 제 1 영역(AR1)에 포함된 객체의 수보다 더 많을 수 있음을 나타낼 수 있다. 이를 고려하면, 비교 블록의 패턴 형태와 카메라 모듈로부터의 거리도 군중 계수에 대한 주요 변수라고 할 수 있다. 도 13에 다양한 비교 블록에 대한 정보를 나타내었다. 도 13을 살펴보면, 제 1 비교 블록(PT1)에 관련해서는 기본 객체수(기본 인원수)가 5명이고, 카메라 모듈과 의 거리에 따른 가중치(거리 가중치)가 미터당 1.2이고, 넓이 가중치가 제곱미터당 1.02일 수 있다. 거리 가중치는 제 1 비교 블록(PT1)과 카메라 모듈 사이의 거리가 미리 설정된 기본 거리(예컨대 10m)에서 단위 거리(예컨대 5m) 만큼 증가할 때마다 가중치가 1.2만큼 증가함을 나타낼 수 있다. 넓이 가능치는 제 1 비교 블록(PT1)의 넓이가 기본 넓이(예컨대 2제곱미터)에서 단위 넓이(예컨대 1제곱미터) 만큼 증가할 때마다 가중치가 1.02만큼 증가함을 나타낼 수 있다. 제 1 비교 블록(PT1)의 기본 객체수는 제 1 비교 블록(PT1)의 넓이가 기본 넓이를 갖고, 제 1 비교 블록(PT1)과 카메라 모듈의 사이의 거리가 기본 거리인 경우에 제 1 비교 블록(PT1)에 포함되는 객체의 수를 나타낼 수 있다.예를 들어, 제 1 비교 블록(PT1)의 넓이가 기본 넓이(예컨대 2제곱미터)이고, 제 1 비교 블록(PT1)과 카메라 모 듈 사이의 거리가 기본 거리(예컨대 10m)인 경우에, 제 1 비교 블록(PT1)에 포함되는 객체의 수는 기본 객 체수에 대응되는 5명일 수 있다. 만약, 제 1 비교 블록(PT1)의 넓이가 기본 넓이보다 단위 넓이 만큼 더 넓고(예컨대 3제곱미터), 제 1 비교 블 록(PT1)과 카메라 모듈 사이의 거리가 기본 거리보다 단위 거리 만큼 더 큰 경우(예컨대 15m), 제 1 비교 블록(PT1)에 포함되는 객체의 수는 6.12명(5ㅧ1.2ㅧ1.02)일 수 있다. 여기서는, 거리 가중치를 1.2로 설정하고, 넓이 가중치를 1.02로 설정하는 경우를 설명하였지만, 이는 이해를 돕기 위해 임의로 설정한 것으로서 본 발명이 이에 한정되지 않을 수 있다. 이처럼, 비교 블록의 패턴의 형태 정보, 비교 블록에 포함되는 객체의 수에 대한 정보, 비교 블록의 카메라 모 듈과의 거리에 대한 정보, 비교 블록의 사이즈(넓이)에 대한 정보를 매칭시켜 저장하는 경우에는, 카메라 모듈이 촬영한 영상에서 객체(OB)들을 일일이 카운팅하지 않고, 유사한 비교 블록을 찾아서 그에 대응하는 객체의 수에 대한 정보를 확인하는 방법으로 신속하고 정밀한 군중 계수를 수행할 수 있다. 한편, 비교 블록은 다양한 형태를 가질 수 있다. 예를 들어, 도 14의 (A), (B)와 같이 제 2 비교 블록(PT2)은 중앙이 비어 있는 도넛 형태인 경우도 가능할 수 있다. 복수의 객체(OB)들이 모여 강강술래 놀이 등을 하는 경우에 도 14의 (A)와 같은 타입의 제 2 비교 블록(PT2)이 형성될 수 있다. 도 14의 (B)의 경우는 (A)와 비교하여 동일하게 제 2 비교 블록(PT2)을 형성하지만, 비교 블록에 포함되는 객체 (OB)의 수는 상대적으로 더 많을 수 있다. 복수의 객체(OB)들이 캠프 파이어 등을 하는 경우에 도 14의 (B)와 같은 타입의 제 2 비교 블록(PT2)을 형성될 수 있다. 도 14의 (A)와 (B)의 객체 수의 차이는 앞서 설명한 거리 가중치 및/또는 넓이 가중치를 이용하여 판별할 수 있 다. 이와 같이, 적어도 하나의 객체(OB)를 포함하는 비교 블록에 대응하여 패턴의 형태에 대한 정보, 비교 블록에 포함된 객체의 수에 대한 정보, 거리에 대한 정보, 넓이에 대한 정보 등을 매칭시켜 저장하게 되면, 군중 계수 를 보다 신속하게 정밀하게 수행할 수 있다. 한편, 비교 영상 혹은 비교 블록에서 복수의 객체(OB)가 겹쳐져서 위치하는 경우에는 정밀한 객체의 수의 판별 이 어려울 수 있다. 이러한 경우에는 미리 저장한 동영상 타입의 영상을 역재생하여 충분히 정확한 객체의 수를 판별하는 것이 가능 하다. 복수의 객체(OB)가 중첩되는 영상 패턴을 갖는 비교 블록을 중첩 블록(Overlapping Block)이라고 할 수 있다. 도 15에 나타나 있는 바와 같이, 객체수를 검출하는 과정(S130)에서는 먼저 비교 영상 혹은 비교 블록에 복수의 객체(OB)가 겹쳐져 있는지의 여부를 판단할 수 있다(S131). S131단계에서 판단결과, 복수의 객체(OB)가 겹쳐져 있지 않은 경우에 검출부의 객체 검출부와 객체 수 검출부가 비교 영상 혹은 비교 블록에 포함되어 있는 객체의 수를 카운팅하여 판별할 수 있다(S134). 반면에, S131단계에서 판단결과, 복수의 객체(OB)가 겹쳐져 있는 경우에는 검출부는 미리 저장되어 있는 영상을 역재생할 수 있다(S132). 이를 위해, 서버는 데이터 베이스(DB, 230)에 카메라 모듈이 촬영한 영상을 동영상 형태로 저장하는 것 이 가능하다. 카메라 모듈이 촬영한 영상에서 aaa시점의 영상의 일부의 패턴을 비교 블록으로 저장하는 경우를 가정하여 보자. 이러한 aaa시점의 영상의 일부의 패턴이 비교 블록의 일종인 중첩 블록이라고 할 수 있다. 이러한 경우, 검출부는 카메라 모듈이 촬영한 영상을 aaa시점부터 역재생할 수 있다. 아울러, 영상을 역재생하면서 해당 비교 블록에 포함된 각각의 객체(OB)의 동선을 추적(S133)하고, 추적한 객체 (OB)의 수를 카운팅하여 객체 수를 판별할 수 있다. 예를 들어, 비교 영상부가 도 16의 (A)와 같은 형태를 갖는 패턴을 제 3 비교 블록(PT3)으로 저장하는 경 우를 가정하자. 도 16의 (A)의 비교 블록은 다수의 객체(OB)가 겹쳐진 영상 패턴을 갖는 것으로 볼 수 있다. 도 16의 (A)는 중 첩 블록의 일종이라고 볼 수 있다. 이러한 경우, 검출부는 카메라 모듈이 촬영한 동영상 타입의 영상을 역재생할 수 있다. 그러면, 도 16의 (B), (C)와 같이 카메라 모듈이 촬영한 영상을 거꾸로 재생하는 과정에서 이동하거나 무리 (제 3 비교 블록(PT3))로부터 분리되는 각각의 객체(OB)들의 동선(움직임, 이동)을 추적하고, 객체(OB)의 수를 카운팅할 수 있다. 각각의 객체(OB)들의 움직임을 추적하면 영상의 데이터의 변화가 발생하는데, 이러한 영상 데이터의 변화를 감 지하여 객체(OB)의 수를 검출할 수 있다. 이러한 방법을 사용하면, 다수의 객체(OB)가 겹치듯이 모여있는 비교 블록(제 3 비교 블록(PT3))에서도 객체의 수를 충분히 정밀하게 판별할 수 있다. 서버에서는 제 3 비교 블록(PT3)에 대한 패턴 형태, 사이즈 등의 정보 및 제 3 비교 블록(PT3)에 대응하는 객체(OB)의 수에 대한 정보를 데이터 베이스(DB, 230)에 저장할 수 있다. 한편, 카메라 모듈이 촬영한 영상에서 객체(OB)를 용이하게 검출하기 위해 기준 영상을 설정하고, 설정한 기준 영상을 이용하는 것이 가능하다. 기준 영상은 앞서 설명한 기준 정보의 일종이라고 할 수 있다. 기준 영상은 카메라 모듈에 대응되는 촬영 영역에 객체(OB)가 존재하지 않는 상태의 영상이라고 할 수 있다. 기준 영상을 설정하기 위해, 도 8의 S100단계에서와 같이 카메라 모듈이 주변의 영상을 촬영할 수 있다. 이러한 경우, 카메라 모듈이 촬영한 영상은 일종의 샘플 영상이라고 할 수 있다. 이하에서는 기준 영상을 생성하기 위해 카메라 모듈이 촬영한 영상을 샘플 영상이라고 칭할 수 있다. 아울러, 샘플 영상은 빈 영역(Vacancy Area)(혹은 빈 공간)을 포함하는 영상이라고 할 수 있다. 여기서, 빈 영 역은 카메라 모듈이 촬영한 영상에서 객체(OB)가 위치하지 않아서 촬영 영역의 적어도 일부가 노출된 영역 이라고 할 수 있다. 도 8의 S100단계에서 카메라 모듈이 영상, 즉 샘플 영상을 촬영하면, 촬영한 샘플 영상은 서버로 전송 될 수 있다. 그러면, 서버의 기준 정보부에서는 카메라 모듈로부터 전송받은 샘플 영상을 분석하여 샘플 영상 에 빈 영역이 포함되어 있는지의 여부를 판단할 수 있다(S150). S150단계에서 판단결과, 카메라 모듈로부터 전송받은 영상에 빈 영역이 포함되지 않은 경우에는 미리 설정 된 제 2 기능(Default 2)을 수행할 수 있다. 여기서, 제 2 기능은 해당 영상이 빈 영역을 포함하는 샘플 영상이 아니라는 것을 알리는 기능 등을 예로 들 수 있다. 반면에, S150단계에서 판단결과, 카메라 모듈로부터 전송받은 영상에 빈 영역이 포함된 경우에는 해당 영상 을 샘플 영상으로 설정할 수 있다. 아울러, 샘플 영상에서 검출한 빈 영역에 대한 영상을 조합(S170)하여 기준 영상을 설정하고, 설정한 기준 영상 을 저장할 수 있다(S180). 도 17의 (A)에 나타나 있는 바와 같이, 카메라 모듈이 촬영한 영상에서 촬영 영역의 적어도 일부에 객체 (OB)가 존재하지 않는 영역, 즉 제 1 빈 영역(First Vacancy Area, VA1)이 포함되는 경우를 가정하자. 이러한 경우, 도 17의 (A)와 같은 영상을 제 1 샘플 영상이라고 할 수 있다. 도 17의 (B)의 제 2 샘플 영상은 카메라 모듈을 기준으로 촬영 영상에서 촬영 영역의 좌측 부분에 제 2 빈 영역(Second Vacancy Area, VA2)을 포함할 수 있다.도 17의 (C)의 제 3 샘플 영상은 카메라 모듈을 기준으로 촬영 영상에서 촬영 영역의 상단 부분에 제 3 빈 영역(Third Vacancy Area, VA3)을 포함할 수 있다. 도 17의 (D)의 제 4 샘플 영상은 카메라 모듈을 기준으로 촬영 영상에서 촬영 영역의 좌상단 부분에 제 4 빈 영역(Fourth Vacancy Area, VA4)을 포함할 수 있다. 서버의 기준 정보부에서는 적어도 하나의 샘플 영상, 바람직하게는 복수의 샘플 영상을 분석하여, 각 각의 샘플 영상에서 빈 영역을 검출할 수 있다. 이후, 샘플 영상에서 검출한 빈 영역에 대한 영상을 조합하여 기준 영상을 생성할 수 있다. 기준 영상의 일례가 도 18에 나타나 있다. 도 18의 기준 영상은 도 17의 (A), (B), (C), (D)의 제 1 샘플 영상, 제 2 샘플 영상, 제 3 샘플 영상 및 제 4 샘플 영상의 제 1 빈 영역(VA1), 제 2 빈 영역(VA2), 제 3 빈 영역(VA3) 및 제 4 빈 영역(VA4)의 영상을 조합 한 영상이라고 할 수 있다. 이처럼, 각각의 카메라 모듈에 대응하여 기준 영상을 설정하게 되면, 카메라 모듈의 주변 환경, 설치 환경 등에 관계없이 충분히 정밀한 군중 계수가 가능할 수 있다. 예를 들면, 카메라 모듈의 설치 위치에 따라, 빛의 양, 빛의 각도, 촬영 영역의 바닥의 굴곡 상태, 카메라 모듈의 시야 등이 변할 수 있다. 이를 고려하여 본 발명에서는 카메라 모듈을 설치 이후에 촬영 영역 상에 객체(OB)가 존재하지 않는 기준 영상을 각각의 카메라 모듈에 대응하여 독립적으로 설정할 수 있다. 이러한 경우에는, 각각의 카메라 모듈 의 주변 환경 또는 설치 환경에 대응하여 효과적이고 정밀하게 군중 계수를 수행할 수 있다. 한편, 기준 영상은 주기적 및/또는 비주기적으로 갱신, 추가, 삭제 또는 업데이트되는 것이 가능하다. 자세하 게는, 서버에서 인공지능을 이용하여 주기적 및/또는 비주기적으로 기준 영상을 갱신, 추가, 삭제 또는 업 데이터를 하는 것이 가능할 수 있다. 이에 대해, 첨부된 도 19를 참조하여 살펴보면 아래와 같다. 도 19를 살펴보면, 기준 영상을 설정한 이후에 카메라 모듈은 주변의 영상을 촬영할 수 있다(S300). 여기서, 카메라 모듈이 촬영한 영상은 대상 영상이라고도 할 수 있고, 샘플 영상이라고도 할 수 있다. 이후, 카메라 모듈이 촬영한 영상은 서버로 전송되고, 서버에서는 카메라 모듈로부터 수신한 영상에서 미리 설정된 기준 영상과는 다르게 변화되는 부분이 있는지의 여부를 판단할 수 있다(S310). 자세하게는, 서버는 카메라 모듈이 일정 주기에 따라 연속적으로 촬영한 복수의 영상을 미리 설정되어 저장되어 있는 기준 영상과 비교하여 변화되는 부분이 있는지의 여부를 판단할 수 있다. 여기서, 서버가 기준 영상과 비교하기 위해 사용하는 영상들은 카메라 모듈의 촬영 각도 및 촬영 영역 이 기준 영상과 비교하여 동일한 상태에서 촬영된 영상이라고 할 수 있다. S310단계에서 판단결과 카메라 모듈이 촬영한 영상에서 변화되는 부분이 없는 경우에는 미리 설정된 기준 영상을 변경하지 않고 유지할 수 있다(S350). 반면에, S310단계에서 판단결과 카메라 모듈이 촬영한 영상에서 변화되는 부분이 있는 경우에는 변화된 부 분의 데이터 변화율이 미리 설정된 기준 변화율 이하인지의 여부를 판단할 수 있다(S320). S320단계에서 판단결과 카메라 모듈이 촬영한 영상에서 변화되는 부분의 변화율이 미리 설정된 기준 변화율 보다 더 큰 경우에는 기준 영상을 변경하지 않고 유지할 수 있다(S350). 반면에, S320단계에서 판단결과 카메라 모듈이 촬영한 영상에서 변화되는 부분의 변화율이 미리 설정된 기 준 변화율 이하인 경우에는 변화된 부분이 유지되는 시간이 미리 설정된 기준 시간 이상인지의 여부를 판단할 수 있다(S330). S330단계에서 판단결과 카메라 모듈이 촬영한 영상에서 변화되는 부분의 유지 시간이 미리 설정된 기준 시 간 이상인 경우에는 기준 영상을 변경하지 않고 유지할 수 있다(S350). 반면에, S330단계에서 판단결과 카메라 모듈이 촬영한 영상에서 변화되는 부분의 유지 시간이 미리 설정된 기준 시간 이상인 경우에는 기존의 기준 영상을 새로운 기준 영상으로 변경하여 설정할 수 있다(S340). 새로운 기준 영상을 설정하는 방법은 앞선 도 17 내지 도 18에서 상세히 설명한 바 있다. 도 20의 (A)에 나타나 있는 바와 같이, 카메라 모듈의 촬영 영역에 동상(Statue)이 새롭게 세워지는 경우를 가정하여 보자. 이러한 경우에는, 카메라 모듈이 일정 주기에 따라 연속적으로 촬영한 영상들에는 공통적으로 동상이 포함 될 수 있다. 아울러, 영상에서 동상에 대응하는 데이터의 변화율은 미리 설정된 기준 변화율보다 더 적을 수 있다. 아울러, 영상에서 동상은 미리 설정된 기준 시간 이상 영상에 포함될 수 있다. 이는 동상의 움직임이 거의 없기 때문이 라고 할 수 있다. 이러한 경우, 서버는 해당 동상을 새롭게 추가된 배경 객체(BOB)로 인식할 수 있다. 이후, 서버는 기준 영상에 배경 객체(BOB)가 포함되도록 새로운 기준 영상을 생성 및 설정할 수 있다. 도 20의 (B)에는 도로의 경계석의 새롭게 설치되는 경우의 일례가 나타나 있다. 이러한 경우에도, 서버는 도로의 경계석을 배경 객체(BOB)로 인식하는 것이 가능할 수 있다. 이와 같이, 서버가 주기적 혹은 비주기적으로 기준 영상을 변경하는 경우에는 카메라 모듈에 대응되는 촬영 영역의 환경 변화에 대응하여 보다 효과적이고 정밀하게 군중 계수를 수행할 수 있다. 이상에서 설명한 바와 같이, 서버에서 기준 정보, 기준 영상, 비교 영상 등을 설정한 이후에 군중 계수 모 드를 실행할 수 있다. 군중 계수 모드에 대해 첨부된 도면을 참조하여 살펴보면 아래와 같다. 도 21 내지 도 23은 군준 계수 모드에 대해 설명하기 위한 도면이다. 이하에서는 이상에서 상세히 설명한 부분 에 대한 설명은 생략될 수 있다. 여기서, 군중 계수 모드는 군중 계수를 위한 서버의 설정이 완료된 이후에 소정의 영역에 위치하는 객체 (OB)의 수를 검출하기 위해 카메라 모듈이 촬영한 영상에서 군중의 수를 검출하는 모드라고 할 수 있다. 다른 관점에서 보면, 군중 계수 모드에서는 카메라 모듈이 소정의 촬영 영역의 영상(대상 영상)을 촬영하고, 서버는 카메라 모듈이 촬영한 영상(대상 영상)에서 객체(OB)의 수를 검출할 수 있다. 도 21을 살펴보면, 군중 계수 모드에서는 카메라 모듈이 주변, 즉 촬영 영역에 대응하여 영상을 촬영할 수 있다(S400). 이러한 군중 계수 모드에서 군중 계수를 위해 카메라 모듈이 촬영하는 영상을 타깃 영상 혹은 대상 영상이 라고 할 수 있다. 이하에서는 군중 계수 모드에서 군중 계수를 위해 촬영되는 영상을 대상 영상이라고 칭할 수 있다. 이후, 카메라 모듈은 군중 계수를 위한 영상, 즉 대상 영상을 서버로 전송할 수 있다. 그러면, 서버에는 카메라 모듈로부터 수신한 대상 영상을 미리 설정된 기준 영상과 비교할 수 있다 (S410). 이후, 서버는 대상 영상에서 기준 영상과 다른 부분, 즉 변경 부분이 있는지의 여부를 판단할 수 있다 (S420). S420단계에서 판단결과, 대상 영상에서 기준 영상과 비교하여 다른 부분, 즉 변경된 부분이 없는 경우에는 미리 설정된 제 3 기능(Default 3)을 수행할 수 있다(S430). 여기서, 제 3 기능은 대상 영상에 포함된 객체(OB)의 수가 0임을 알리는 기능, 즉 대상 영상에 객체(OB)가 포함 되지 않음을 알리는 기능, 대상 영상을 다시 촬영하라는 것을 알리는 기능 등을 예로 들 수 있다. 반면에, S420단계에서 판단결과 대상 영상에서 기준 영상과 비교하여 다른 부분, 즉 변경된 부분이 있는 경우에 는 서버는 대상 영상에서 변경된 부분을 검출할 수 있다(S440). 이후, 서버는 검출한 변경된 부분에서 객체를 판별할 수 있다(S450). 이후, 서버는 검출한 변경된 부분을 객체에 대응하여 미리 설정된 적어도 하나의 비교 영상(혹은 비교 블록)과 비교하고(S460), 비교한 결과에 따라 검출한 변경된 부분에서 객체(OB)의 수를 판별할 수 있다(S470). 이후, 판별한 객체(OB)의 수를 합산하여 최종적인 결과값으로 출력하는 것이 가능하다. 여기서, 상황에 따라 최종적인 결과값에는 소정의 오차가 설정될 수 있다. 예를 들어, 카메라 모듈이 도 22에 나타나 있는 바와 같은 영상을 촬영하였다고 가정하자. 카메라 모듈은 도 22의 영상에 포함된 객체(OB)의 수를 검출하기 위해 도 22의 영상을 서버로 전송할 수 있다. 이러한 경우, 도 22의 영상을 대상 영상이라고 할 수 있다. 그러면, 서버는 도 22의 영상을 대상 영상으로 설정하고, 대상 영상을 미리 설정된 기준 영상과 비교할 수 있다. 기준 영상의 일례가 앞선 도 18에 나타나 있다. 예를 들면, 서버는 도 18과 같은 기준 영상과 도 22와 같은 대상 영상을 비교할 수 있다. 아울러, 서버는 비교의 결과로서 대상 영상에서 기준 영상과 다른 부분, 즉 변경된 부분을 검출할 수 있다. 도 22에서는 변경된 부분을 제 4 영역(AR4), 제 5 영역(AR5), 제 6 영역(AR6), 제 7 영역(AR7), 제 8 영역 (AR8) 및 제 9 영역(AR9)으로 표시하였다. 이러한 변경된 부분을 관심영역이라고 할 수 있다. 서버는 검출한 변경된 부분(관심 영역)에서 각각 객체(OB)를 검출할 수 있다. 객체(OB)를 검출하는 과정에 서는 서버는 미리 설정된 기준 정보를 이용할 수 있다. 예를 들면, 서버는 촬영 영역에 대응하는 위치 정보, 카메라 모듈의 위치 정보, 촬영 영역의 각 위치와 카메라 모듈 사이의 거리 정보, 객체(OB)의 형태 및 키 등의 정보 등의 다양한 기준 정보를 이용하여 변경 된 부분에서 객체(OB)를 검출할 수 있다. 기준 정보를 이용한 객체(OB) 검출 방법은 앞서 상세히 설명한 바 있다. 여기서, 객체(OB)가 검출되지 않은 관심 영역(변경된 부분)은 제외하고, 객체(OB)가 검출된 각각의 관심 영역 (변경된 부분)에서 객체(OB)들의 외곽을 둘러싸도록 영상 블록을 설정할 수 있다. 대상 영상의 관심 영역에서 설정한 영상 블록을 대상 블록(Target Block)이라고 칭할 수 있다. 예를 들면, 도 22에 나타나 있는 바와 같이, 제 4 영역(AR4)에서는 제 1 대상 블록(TB1)을 설정하고, 제 5 영역 (AR5)에서는 제 2 대상 블록(TB2)을 설정하고, 제 6 영역(AR6)에서는 제 3 대상 블록(TB3)을 설정하는 것이 가 능하다. 이후, 서버의 비교 영상부는 제 1 대상 블록(TB1)의 영상 패턴을 미리 저장되어 있는 적어도 하나의 비교 블록과 비교하여 유사 비율이 미리 설정된 임계 비율보다 더 높은 적어도 하나의 비교 블록을 검출할 수 있다. 여기서, 검출한 비교 블록을 후보 비교 블록이라고 할 수 있다. 이후, 검출한 적어도 하나의 후보 비교 블록 중에서 제 1 대상 블록(TB1)의 영상 패턴과 가장 유사한 하나의 비 교 블록을 검출할 수 있다. 여기서, 검출한 비교 블록을 매칭 비교 블록이라고 할 수 있다. 이후, 매칭 비교 블록에 포함된 객체(OB)의 수를 파악하고, 파악한 객체(OB)의 수를 제 1 대상 블록(TB1)에 포 함된 객체(OB)의 수로 판별할 수 있다. 제 1 대상 블록(TB1)에 포함된 객체(OB)의 수는 제 4 영역(AR4)에 포함 된 객체(OB)의 수에 대응될 수 있다. 여기서, 후보 비교 블록 및 매칭 비교 블록은 비교 블록을 일종으로 이해를 돕기 위해 다른 용어를 사용한 것일 수 있다. 이러한 방법으로 제 5 영역(AR5), 제 6 영역(AR5), 제 7 영역(AR7), 제 8 영역(AR8) 및 제 9 영역(AR9)에 포함 된 객체(OB)의 수를 검출하고, 검출한 객체(OB)의 수를 합산하여 대상 영상에 포함된 객체(OB)의 총 수에 대한 정보(최종 결과값)를 검출할 수 있다. 아울러, 대상 영상에 포함된 객체(OB)의 총 수(최종 결과값)에 상황에 따라 오차가 부여될 수 있다. 예를 들어, 대상 영상에 이상 패턴이 포함되는 경우에는 최종 결과값에 미리 설정된 소정의 오차가 부여될 수 있다. 이상 패턴에 대해서는 이하에서 설명하기로 한다. 예를 들면, 100명(최종 결과값)ㅁ5명(오차)과 같이 오차가 부여될 수 있다. 혹은 오차는 비율로서 부여되는 것 이 가능하다. 제 7 영역(AR7), 제 8 영역(AR8) 및 제 9 영역(AR9)에서는 하나의 객체(OB)가 포함될 수 있다. 제 7 영역(AR7), 제 8 영역(AR8) 및 제 9 영역(AR9)에 대응되는 대상 블록은 하나의 객체(OB)에 대응하는 비교 블록에 매칭되는 것이 가능하다. 한편, 객체(OB)들의 이동속도가 상대적으로 빠른 경우에는 대상 영상에 포함된 대상 블록들도 그 형태가 빠르게 변경될 수 있다. 예를 들어, 소정의 제 1 시점에서 도 23의 (A)와 같은 대상 영상을 촬영하였다고 가정하자. 여기서, 제 1 시점 이후의 제 2 시점에서는 도 23의 (B)와 같은 대상 영상이 촬영될 수 있다. 도 23의 (A)와 (B)를 비교하면 객체(OB)들이 이동하여 대상 블록의 영상 패턴이 변경된 것을 확인할 수 있다. 이러한 현상은 객체(OB)들의 이동속도가 빠른 경우에 더욱 심화될 수 있다. 이를 고려하면, 대상 영상의 대상 블록의 영상 패턴이 변경되는 정도에 따라 객체(OB)들의 이동속도를 검출하는 것이 가능하다. 여기서, 객체(OB)들의 이동속도는 일정 영역에서의 유동인구를 파악하는데 사용될 수 있다. 이상에서 상세히 설명한 바와 같이, 객체(OB)의 수를 파악하고자 하는 대상 영상을 미리 설정되어 저장된 비교 영상과 비교하여 유사한 비교 영상을 검출하고, 검출한 비교 영상에 포함된 객체(OB)의 수를 대상 영상에 포함 된 객체(OB)의 수로서 판별할 수 있다. 또는, 객체(OB)의 수를 파악하고자 하는 대상 영상에 포함된 대상 블록을 미리 설정되어 저장된 비교 블록과 비 교하여 유사한 비교 블록을 검출하고, 검출한 비교 블록에 포함된 객체(OB)의 수를 대상 블록에 포함된 객체 (OB)의 수로서 판별할 수 있다. 이후, 대상 영상에 포함된 모든 대상 블록의 객체(OB)의 수를 합산하여 대상 영상에 포함된 객체(OB)의 수로서 판별할 수 있다. 이러한 본 발명에서는 대상 영상에 포함된 객체(OB)의 수를 보다 신속하게 판별할 수 있다. 도 24 내지 도 29는 카메라 모듈에 대해 설명하기 위한 도면이다. 이하에서는 이상에서 상세히 설명한 부분에 대한 설명은 생략될 수 있다. 도 24를 살펴보면, 카메라 모듈은 제 1 카메라부(First Camera Part, 11)와 제 2 카메라(Second Camera Part, 12)를 포함할 수 있다. 여기서, 제 1 카메라부와 제 2 카메라부의 촬영 영역은 적어도 일부가 서로 다를 수 있다. 예를 들면, 제 1 카메라부에 대응하는 촬영 영역은 제 1 비중첩영역(First Non Overlap Area, NOVA1) 및 중첩영역(Overlap Area, OVA)을 포함하고, 제 2 카메라부에 대응하는 촬영 영역은 제 2 비중첩영역(Second Non Overlap Area, NOVA2) 및 중첩영역(OVA)을 포함할 수 있다. 여기서, 중첩영역(OVA)은 제 1 카메라부에 대응하는 촬영 영역과 제 2 카메라부에 대응하는 촬영 영역 이 서로 중첩하는 영역일 수 있다. 제 1 비중첩영역(NOVA1)은 제 1 카메라부에 대응하는 촬영 영역에서 중첩영역(OVA)을 제외한 나머지 영역일 수 있다. 제 2 비중첩영역(NOVA2)은 제 2 카메라부에 대응하는 촬영 영역에서 중첩영역(OVA)을 제외한 나머지 영역일 수 있다. 여기서, 중첩영역(OVA)의 사이즈는 제 1 비중첩영역(NOVA1)의 사이즈와 제 2 비중첩영역(NOVA2)의 사이즈의 합 보다 더 클 수 있다. 자세하게는, 중첩영역(OVA)의 면적은 제 1 비중첩영역(NOVA1)의 면적과 제 2 비중첩영역(NOVA2)의 면적의 합보 다 충분히 더 클 수 있다. 제 1 카메라부에 대응하는 촬영 영역과 제 2 카메라부에 대응하는 촬영 영역이 충분히 중첩되는 경우에 는 제 1 비중첩영역(NOVA1) 및 제 2 비중첩영역(NOVA2)을 무시하는 것이 가능할 수도 있다. 이처럼, 카메라 모듈이 복수의 카메라부를 포함하는 경우에는 객체(OB)의 수를 보다 정밀하게 보다 신속하 게 검출하는 것이 가능할 수 있다. 여기서, 제 1 카메라부 및 제 2 카메라부 중 적어도 하나는 회전, 피봇 또는 이동이 가능할 수 있다. 또는, 제 1 카메라부 및 제 2 카메라부는 각각 소정의 프레임에 고정되는 것이 가능할 수 있다. 카메라 모듈이 제 1 카메라부와 제 2 카메라부를 포함하는 경우에는 서버는 제 1 카메라부(1 1)가 촬영한 대상 영상 및 제 2 카메라부가 촬영한 대상 영상을 각각 분석하여 객체(OB)의 수를 각각 검출 하는 것이 가능하다. 이에 대해 첨부된 도면을 참조하여 살펴보면 아래와 같다. 도 25를 살펴보면, 제 1 카메라부에 대응하여 객체(OB)의 수를 검출(S471)하고, 제 2 카메라부에 대응 하여 객체(OB)의 수를 검출(S472)할 수 있다. 다르게 표현하면, 제 1 카메라부가 촬영한 영상(대상 영상)에서 객체(OB)의 수를 검출하고, 제 2 카메라부 가 촬영한 영상(대상 영상)에서 객체(OB)의 수를 검출할 수 있다. 이하에서는 제 1 카메라부가 촬영한 대상 영상을 제 1 대상 영상이라 하고, 제 2 카메라부가 촬영한 영 상을 제 2 대상 영상이라 칭할 수 있다. 예를 들면, 서버의 제 2 제어부가 카메라 모듈에 촬영 영역에 위치하는 객체(OB)의 수를 검출하라 는 명령을 전송할 수 있다. 이러한 경우에는 군중 계수 모드가 발동된 경우라고 할 수 있다. 군중 계수 모드에 대해서는 앞서 상세히 설명 한 바 있다. 군중 계수 모드에서 카메라 모듈의 제 1 카메라부와 제 2 카메라부가 각각 촬영 영역에 대해 영상 (대상 영상)을 촬영할 수 있다. 제 1 카메라부와 제 2 카메라부가 각각 영상(대상 영상)을 촬영하면 각각의 영상에서 객체(OB)의 수를 각각 검출할 수 있다. 대상 영상에서 객체(OB)의 수를 검출하는 방법에 대해서는 앞선 도 21 및 그에 대응되는 설명에서 상세히 설명 한 바 있다. 제 1 카메라부와 제 2 카메라부의 대상 영상에 대한 촬영 시점은 동일한 것이 가능하다. 예를 들어, 서버가 카메라 모듈로 제 10 시점에서 각각 대응하는 촬영 영역에 대한 대상 영상을 촬영하 라는 명령을 전송할 수 있다. 그러면 카메라 모듈에서는 제 1 카메라부와 제 2 카메라부가 각각 제 10 시점에서 대상 영상을 촬 영할 수 있다. 또는, 제 1 카메라부의 촬영 시점과 제 2 카메라부의 촬영 시점은 서로 다를 수 있다. 예를 들면, 서버가 카메라 모듈로 제 10 시점에서 각각 대응하는 촬영 영역에 대한 대상 영상을 촬영하 라는 명령을 전송할 수 있다. 그러면 카메라 모듈에서는 제 1 카메라부는 제 10 시점에서 대응되는 촬영 영역의 제 1 대상 영상을 촬 영하고, 제 2 카메라부는 제 10+△t 시점에서 대응되는 촬영 영역의 제 2 대상 영상을 촬영할 수 있다. 사람인 객체(OB)는 무생물과 같이 완벽하게 정지한 상태를 유지하는 것은 충분히 어려울 수 있으며, 어느 정도 의 움직임을 가질 수 있다. 예를 들면, △t의 시간 동안 적어도 하나의 객체(OB)는 이동하거나 포즈를 변경하 거나 하는 등의 움직임을 수행할 수 있다. 이를 고려하면, 제 1 카메라부가 촬영한 제 1 대상 영상과 제 2 카메라부가 촬영한 제 2 대상 영상에서 적어도 하나의 객체(OB)의 위치, 포즈, 형태, 사이즈 등이 달라질 수 있다. 혹은, 제 1 카메라부가 촬영한 제 1 대상 영상과 제 2 카메라부가 촬영한 제 2 대상 영상에서 복수의 객체(OB)들이 겹쳐진 패턴이 변경되는 것이 가능하다. 이를 고려하면, 군중 계수 모드에서 제 1 카메라부의 촬영 시점과 제 2 카메라부의 촬영 시점을 다르게 하는 경우에는 촬영 영역에 위치하는 객체(OB)의 수를 보다 정밀하게 검출할 수 있다. 도 25에서 제 1 대상 영상에 대해 객체(OB)의 수를 검출하고 제 2 대상 영상에 대해 객체(OB)의 수를 검출한 이 후에, 검출한 결과값이 동일한지의 여부를 판단할 수 있다(S473). 여기서, 결과값은 제 1 대상 영상에 대해 검출한 객체(OB)의 수에 대한 결과값과 제 2 대상 영상에 대해 검출한 객체(OB)의 수에 대한 결과값을 의미할 수 있다. S473단계에서 판단결과, 결과값이 동일한 경우에는 제 1 카메라부 및 제 2 카메라부 중 어느 하나에 대 응하는 결과값을 객체(OB)의 수에 대한 최종 결과값으로 출력할 수 있다(S474). 예를 들어, 서버에서 제 1 카메라부가 촬영한 제 1 대상 영상을 분석한 결과 제 1 대상 영상에 포함되 어 있는 객체(OB)의 수를 20명이라고 판별할 수 있다. 아울러, 서버에서 제 2 카메라부가 촬영한 제 2 대상 영상을 분석한 결과 제 2 대상 영상에 포함되어 있는 객체(OB)의 수를 20명이라고 판별할 수 있다. 이러한 경우에는, 서버는 카메라 모듈에 대응되는 촬영 영역에 위치하는 객체(OB)의 수를 20명으로 최 종적으로 출력하는 것이 가능하다. 즉, 서버는 제 1 카메라부 및 제 2 카메라부 중 어느 하나에 대응하는 결과값을 최종 결과값으로 출력하는 것이 가능할 수 있다. 한편, S473단계에서 판단결과, 결과값이 동일하지 않고 다른 경우에는 제 1 카메라부 및 제 2 카메라부(1 2)에 대한 신뢰도를 평가할 수 있다(S475). 이후, 제 1 카메라부의 신뢰도 및 제 2 카메라부의 신뢰도가 각각 미리 설정된 임계 신뢰도를 넘는지의 여부를 판단할 수 있다(S476). S476단계에서 판단결과, 제 1 카메라부의 신뢰도 및 제 2 카메라부의 신뢰도가 각각 미리 설정된 임계 신뢰도 이상인 경우에는 서버에서는 제 1 카메라부가 촬영한 제 1 대상 영상과 제 2 카메라부가 촬 영한 제 2 대상 영상에서 각각 객체(OB)의 수를 검출(객체(OB) 카운팅)할 수 있다(S477). 이후, 서버는 제 1 대상 영상에 포함된 객체(OB)의 수와 제 2 대상 영상에 포함된 객체(OB)의 수를 합산하 고, 합산한 값을 카메라부의 개수로 나누어 평균값(중간값)을 구할 수 있다(S478). 이후, 서버는 평균값(중간값)을 최종 결과값으로 출력하는 것이 가능할 수 있다. 예를 들어, 서버에서 제 1 카메라부가 촬영한 제 1 대상 영상을 분석한 결과 제 1 대상 영상에 포함되 어 있는 객체(OB)의 수를 20명이라고 판별하고, 아울러 서버에서 제 2 카메라부가 촬영한 제 2 대상 영 상을 분석한 결과 제 2 대상 영상에 포함되어 있는 객체(OB)의 수를 30명이라고 판별할 수 있다. 여기서, 제 1 카메라부의 신뢰도와 제 2 카메라부의 신뢰도는 각각 임계 신뢰도 이상일 수 있다. 이러한 경우, 서버의 검출부는 카메라 모듈에 대응되는 촬영 영역에 위치하는 객체(OB)의 수를 25 명이라고 판별할 수 있다. 한편, S476단계에서 판단결과, 제 1 카메라부의 신뢰도 및 제 2 카메라부 중 적어도 하나의 신뢰도가 미리 설정된 임계 신뢰도보다 더 낮은 경우에는 서버에서는 제 1 카메라부 및 제 2 카메라부 중 신 뢰도가 더 높은 어느 하나에 대응하는 대상 영상을 선택할 수 있다(S479). 이후, 서버는 선택한 대상 영상에 대응하는 객체(OB)의 수에 대한 정보를 최종적인 결과로서 출력할 수 있 다(S480). 예를 들어, 서버에서 제 1 카메라부가 촬영한 제 1 대상 영상을 분석한 결과 제 1 대상 영상에 포함되 어 있는 객체(OB)의 수를 20명이라고 판별하고, 아울러 서버에서 제 2 카메라부가 촬영한 제 2 대상 영 상을 분석한 결과 제 2 대상 영상에 포함되어 있는 객체(OB)의 수를 30명이라고 판별할 수 있다. 여기서, 제 1 카메라부의 신뢰도는 미리 설정된 임계 신뢰도보다 더 높고, 제 2 카메라부의 신뢰도는 임계 신뢰도보다 더 낮은 경우도 가능할 수 있다. 또는, 제 1 카메라부의 신뢰도 및 제 2 카메라부의 신뢰도는 각각 임계 신뢰도보다 더 낮고, 여기서 제 1 카메라부의 신뢰도는 제 2 카메라부의 신뢰도보다 더 높을 수 있다. 이러한 경우, 서버는 신뢰도가 상대적으로 높은 제 1 카메라부에 대응하는 제 1 대상 영상을 선택하고, 선택한 제 1 대상 영역에 포함된 객체(OB)의 수에 대한 정보(20명)를 최종적인 결과값으로 출력하는 것이 가능하다. 제 1 카메라부와 제 2 카메라부의 신뢰도에 대해 살펴보기로 한다. 도 26의 (A)에 나타나 있는 바와 같이, 4명의 객체(OB1, OB2, OB3, OB4)가 일렬로 나란하게 위치하는 경우를 가 정하여 보자. 여기서, 제 1 객체(OB1)는 서 있는 상태이고, 제 1 객체(OB1)의 후방에 위치하는 제 2 객체(OB2)는 제 1 객체 (OB1)보다 키가 더 작고, 제 2 객체(OB2)의 후방에 위치하는 제 3 객체(OB3)는 의자에 앉아 있는 타입이고, 제 3 객체(OB3)의 후방에 위치하는 제 4 객체(OB4)는 바닥에 앉아 있는 타입일 수 있다. 이러한 경우에, 도 26의 (B)에 나타나 있는 바와 같이, 제 1 객체(OB1), 제 2 객체(OB2), 제 3 객체(OB3) 및 제 4 객체(OB4) 사이의 간격이 각각 충분히 작고, 제 1 객체(OB1), 제 2 객체(OB2), 제 3 객체(OB3) 및 제 4 객체(OB4)가 제 1 카메라부의 정면에 나란히 위치할 수 있다. 그러면 제 1 카메라부의 관점에서는 제 1 객체(OB1), 제 2 객체(OB2), 제 3 객체(OB3) 및 제 4 객체(OB4) 가 겹쳐서 보이게 되고, 이에 따라 객체(OB)의 수를 정밀하게 파악하기 어려울 수 있다. 반면에, 제 2 카메라부의 관점에서는 제 1 객체(OB1), 제 2 객체(OB2), 제 3 객체(OB3) 및 제 4 객체(OB 4)의 측면을 관찰할 수 있어서 제 1 객체(OB1), 제 2 객체(OB2), 제 3 객체(OB3) 및 제 4 객체(OB4)를 상대적 으로 정밀하게 구분할 수 있다. 이를 고려하면, 도 26의 경우에는 제 2 카메라부의 신뢰도는 제 1 카메라부의 신뢰도보다 더 높을 수 있다. 다른 관점에서 보면, 도 26의 경우에는 제 2 카메라부의 신뢰도는 미리 설정된 임계 신뢰도 이상이고, 제 1 카메라부의 신뢰도는 임계 신뢰도보다 더 낮을 수 있다. 도 26과 같은 경우에 제 1 카메라부가 촬영한 대상 영상에는, 제 1 객체(OB1), 제 2 객체(OB2), 제 3 객체 (OB3) 및 제 4 객체(OB4)가 중첩되기 때문에, 객체(OB)들의 외곽을 둘러싸도록 영상 블록을 설정하면 설정한 영 상 블록의 패턴은 하나의 객체(OB)를 포함하는 영상 블록의 패턴과 유사할 수 있다. 그러나 제 1 객체(OB1)의 후방에 위치하는 제 2 객체(OB2), 제 3 객체(OB3) 및 제 4 객체(OB4)가 완전히 제 1 객체(OB1)와 중첩(Fully Overlap)되지 않는 경우에는, 제 1 객체(OB1)를 벗어나서 제 2 객체(OB2), 제 3 객체 (OB3) 및 제 4 객체(OB4) 중 적어도 하나의 적어도 일부가 노출될 수 있다. 예를 들면, 제 1 객체(OB1)의 주변 에 제 2 객체(OB2), 제 3 객체(OB3) 및 제 4 객체(OB4) 중 적어도 하나의 팔, 다리 등이 나타날 수 있다. 이처럼, 적어도 하나의 객체(OB)가 다른 객체(OB)에 충분히 가려지는 경우의 영상 패턴을 이상 패턴이라고 할 수 있다. 자세하게는, 적어도 하나의 객체(OB)가 다른 객체(OB)에 의해 미리 설정된 기준 비율 이상 가려지는 경우에 이상 패턴이라고 할 수 있다. 여기서, 기준 비율은 대략 95~99% 사이에서 정해질 수 있다. 예를 들어, 도 26의 경우에 제 1 카메라부의 관점에서 제 2 객체(OB2)가 제 1 객체(OB1)에 의해 대략 97%의 부분이 가려지는 경우에, 제 1 카메라부가 촬영한 대상 영상에 이상 패턴이 포함되는 것으로 볼 수 있다. 이러한 이상 패턴은 객체(OB)의 수를 충분히 정밀하게 검출하기 어려울 가능성이 상대적으로 높을 수 있다. 따라서 이상 패턴이 포함되는지의 여부를 근거로 하여 신뢰성을 판단하는 것이 가능할 수 있다. 예를 들어, 도 26의 (B)의 경우와 같이, 제 1 카메라부가 촬영한 영상(제 1 대상 영상)에 이상 패턴이 포함 되고, 제 2 카메라부가 촬영한 영상(제 2 대상 영상)에는 이상 패턴이 포함되지 않는 경우에는 제 2 카메라 부의 신뢰도가 제 1 카메라부의 신뢰도보다 더 높은 것으로 판단할 수 있다. 또는, 제 2 카메라부(1 2)의 신뢰도가 미리 설정된 임계 신뢰도 이상이고, 제 1 카메라부의 신뢰도는 이상 패턴으로 인해 임계 신 뢰도보다 더 낮을 수 있다. 또는, 대상 영상에 포함되는 이상 패턴의 개수에 따라 신뢰도를 판단하는 것이 가능할 수 있다. 예를 들면, 제 1 카메라부가 촬영한 영상(제 1 대상 영상)에 미리 설정된 기준 개수(예컨대, 5개)보다 더 많은 개수의 이상 패턴이 포함되고, 제 2 카메라부가 촬영한 영상(제 2 대상 영상)에는 기준 개수보다 더 적은 개수의 이상 패턴이 포함되는 경우에는 제 2 카메라부의 신뢰도가 제 1 카메라부의 신뢰도보다 더 높은 것으로 판단하거나, 제 2 카메라부의 신뢰도가 미리 설정된 임계 신뢰도 이상이고 제 1 카메라부의 신뢰도는 이상 패턴으로 인해 임계 신뢰도보다 더 낮은 것으로 판단할 수 있다. 객체(OB)의 수를 검출하고자 하는 대상인 대상 영상에 적어도 하나의 이상 패턴이 포함되는 경우에도 해당 이상 패턴을 미리 설정된 비교 블록, 바람직하게는 중첩 블록들과 비교하여 이상 패턴에 포함된 객체(OB)의 수를 신 속하게 검출할 수 있다. 중첩 블록에 대해서는 앞선 도 15 내지 도 16에서 상세히 설명한 바 있다. 이상 패턴의 또 다른 예가 도 27에 나타나 있다. 도 27의 (A)에 나타나 있는 바와 같이, 4명의 객체(OB1, OB2, OB3, OB4)가 일렬로 나란하게 충분히 밀착하여 위 치하는 경우를 가정하여 보자. 여기서, 제 1 객체(OB1), 제 2 객체(OB2), 제 3 객체(OB3) 및 제 4 객체(OB4)는 몸이 맞닿는 정도로 밀착된 상 태일 수 있다. 이러한 경우에, 도 27의 (B)에 나타나 있는 바와 같이, 제 1 객체(OB1), 제 2 객체(OB2), 제 3 객체(OB3) 및 제 4 객체(OB4)가 제 1 카메라부의 정면에 나란히 위치할 수 있다. 그러면 제 1 카메라부의 관점에서는 제 1 객체(OB1), 제 2 객체(OB2), 제 3 객체(OB3) 및 제 4 객체(OB4) 가 중첩되어 보일 수 있다. 반면에, 제 2 카메라부의 관점에서는 제 1 객체(OB1), 제 2 객체(OB2), 제 3 객체(OB3) 및 제 4 객체(OB 4)의 측면을 관찰할 수 있어서 제 1 객체(OB1), 제 2 객체(OB2), 제 3 객체(OB3) 및 제 4 객체(OB4)를 상대적 으로 정밀하게 구분할 수 있다. 이를 고려하면, 도 27의 경우에는 제 2 카메라부의 신뢰도는 제 1 카메라부의 신뢰도보다 더 높을 수 있다. 아울러, 제 1 카메라부가 촬영한 영상(대상 영상)에는 이상 패턴이 포함될 수 있다. 한편, 제 1 카메라부와 제 2 카메라부의 신뢰도가 각각 미리 설정된 임계 신뢰도보다 더 높으면서도, 제 1 대상 영상에 대응하는 객체(OB)의 수와 제 2 대상 영상에 대응하는 객체(OB)의 수가 다른 경우를 가정하여 보자. 도 28에 나타나 있는 바와 같이, 제 1 카메라부와 제 2 카메라부가 복수의 객체(OB)가 모여 있는 부분 을 각각 촬영하는 경우를 가정하자. 복수의 객체(OB)가 모여 있는 부분의 영상 패턴은 촬영 각도에 따라 다르게 판단될 수 있다. 예를 들면, 도 28의 경우에, 서버는 제 1 카메라부가 촬영한 영상(제 1 대상 영상)에서 복수의 객체 (OB)가 모여 있는 부분(대상 블록)의 영상 패턴이 미리 설정된 제 1 비교 블록의 영상 패턴과 가장 유사하다고 판단할 수 있다. 반면에, 서버는 제 2 카메라부가 촬영한 영상(제 2 대상 영상)에서 복수의 객체(OB)가 모여 있는 부분 (대상 블록)의 영상 패턴이 미리 설정된 제 2 비교 블록의 영상 패턴과 가장 유사하다고 판단할 수 있다. 이러한 경우에는 서버는 제 1 카메라부에 대응되는 제 1 대상 영상을 분석하여 제 1 대상 영상에 포함 된 객체(OB)의 수에 대한 제 1 결과값을 출력하고, 제 2 카메라부에 대응되는 제 2 대상 영상을 분석하여 제 2 대상 영상에 포함된 객체(OB)의 수를 검출하여 제 2 결과값을 출력할 수 있다. 이후, 서버는 제 1 결과값과 제 2 결과값을 합산하고, 평균하여 최종적인 결과값을 출력할 수 있다. 이러한 경우, 촬영 각도에 따른 오차 발생을 억제하거나 방지할 수 있다. 한편, 제 1 카메라부에 대응하는 촬영 영역과 제 2 카메라부에 대응하는 촬영 영역이 일부 중첩되고, 제 1 카메라부에 대응하는 비중첩영역 및 제 2 카메라부에 대응하는 비중첩영역의 크기가 충분히 큰 경 우에는 중첩영역과 비중첩영역에서 객체(OB)의 수의 카운팅을 다른 방식으로 수행할 수 있다. 이에 대해, 첨부 된 도면을 참조하여 살펴보면 아래와 같다. 중첩 영역 및 비중첩 영역에 대해서는 앞선 도 24에서 상세히 설명한 바 있다. 도 29를 살펴보면, 중첩 영역(OVA)에 대해 객체(OB)의 수를 검출할 수 있다(S490). 중첩 영역(OVA)은 제 1 카메라부에 대응되는 촬영 영역과 제 2 카메라부에 대응되는 촬영 영역이 중첩 되는 영역으로서, 제 1 카메라부와 제 2 카메라부가 모두 촬영을 수행하는 영역이라고 할 수 있다. 제 1 카메라부가 대응하는 촬영 영역을 촬영한 제 1 대상 영상을 서버로 전송하고 제 2 카메라부가 대응하는 촬영 영역을 촬영한 제 2 대상 영상을 서버로 전송하면, 서버에는 제 1 대상 영상과 제 2 대 상 영상에서 각각 중첩 영역(OVA)을 판별할 수 있다. 아울러, 서버는 제 1 대상 영상의 중첩 영역(OVA)에 대해 객체(OB)의 수를 검출하고, 제 2 대상 영상의 중 첩 영역(OVA)에 대해 객체(OB)의 수를 검출할 수 있다. 이후, 서버는 신뢰도를 근거로 하여 제 1 카메라부 및 제 2 카메라부 중 어느 하나에 대응하여 중 첩 영역(OVA)에 대한 객체(OB)의 수의 정보를 선택하거나, 평균값을 연산하는 것이 가능하다. 예를 들어, 제 1 카메라부의 신뢰도가 제 2 카메라부의 신뢰도보다 더 높거나, 제 1 카메라부의 신 뢰도가 미리 설정된 임계 신뢰도보다 더 높은 경우를 가정하여 보자. 이러한 경우, 서버는 제 1 카메라부에 대응하는 제 1 대상 영상에서 중첩 영역(OVA)을 판별하고, 판별 한 제 1 대상 영상의 중첩 영역(OVA)에서 객체(OB)의 수를 검출하고, 검출한 객체(OB)의 수에 대한 정보를 중첩 영역(OVA)에 대응하는 최종적인 결과값으로 판별할 수 있다. 또는, 서버는 제 1 카메라부에 대응하는 제 1 대상 영상에서 중첩 영역(OVA)을 판별하고, 판별한 제 1 대상 영상의 중첩 영역(OVA)에서 객체(OB)의 수(제 1 결과)를 검출할 수 있다. 아울러, 서버는 제 2 카메 라부에 대응하는 제 2 대상 영상에서 중첩 영역(OVA)을 판별하고, 판별한 제 2 대상 영상의 중첩 영역(OV A)에서 객체(OB)의 수(제 2 결과)를 검출할 수 있다. 이후, 서버는 제 1 결과와 제 2 결과를 합산하고 평균하여 중첩 영역(OVA)에 대응하는 최종적인 결과값을 출력할 수 있다. 이에 대한 내용은 앞서 상세히 설명한 내용으로부터 충분히 설명될 수 있음로 중복되는 설명은 생략할 수 있다. 이후, 중첩 영역(OVA)에 대한 최종적인 결과값에 소정의 제 1 오차가 부여될 수 있다(S491). 여기서, 상황에 따라 제 1 오차를 생략하는 것도 가능할 수 있다. 한편, 비중첩 영역에서도 객체(OB)의 수를 검출할 수 있다(S492). 예를 들면, 서버는 제 1 카메라부에 대응하는 제 1 비중첩영역(NOVA1)에 대해 객체(OB)의 수를 검출하 고, 이와 함께 제 2 카메라부에 대응하는 제 2 비중첩영역(NOVA2)에 대해 객체(OB)의 수를 검출할 수 있다. 아울러, 서버는 제 1 비중첩영역(NOVA1)에 대응하는 객체(OB)의 수와 제 2 비중첩영역(NOVA2)에 대응하는 객체(OB)의 수를 합산한 값을 전체 비중첩 영역(NOVA1, NOVA2)에 대응하는 객체(OB)의 수에 대한 최종적인 결과 값으로 판별할 수 있다. 이후, 비중첩 영역(NOVA1, NOVA2)에 대한 최종적인 결과값에 소정의 제 2 오차가 부여될 수 있다(S493). 여기서, 상황에 따라 제 2 오차를 생략하는 것도 가능할 수 있다. 제 1 오차와 제 2 오차가 모두 부여되는 상황에서는 최종 결과값 대비한 오차값의 비율은 제 2 오차가 제 1 오 차보다 더 클 수 있다. 예를 들어, 중첩 영역(OVA)에 대한 최종적인 결과값이 100명이라고 가정하면, 제 1 오차는 100명에 대한 ㅁ3%로 서 ㅁ3명일 수 있다. 반면에, 비중첩 영역(NOVA1, NOVA2)에 대한 최종적인 결과값이 100명이라고 가정하면, 제 2 오차는 100명에 대 한 ㅁ10%로서 ㅁ10명일 수 있다. 이처럼, 비중첩 영역(NOVA1, NOVA2)의 최종 결과값에 대한 오차(제 2 오차)의 비율을 중첩 영역(OVA)의 최종 결 과값에 대한 오차(제 1 오차)의 비율을 더 크게 하는 이유는 비중첩 영역(NOVA1, NOVA2)은 제 1 카메라부 또는 제 2 카메라부가 단독으로 촬영하기 때문에 오류가 발생할 가능성이 상대적으로 더 높기 때문일 수 있 다. 비중첩 영역(NOVA1, NOVA2)과 중첩 영역(OVA)에 대해 각각 최종 결과값과 오차를 판별한 이후에는 두 개의 값을 합산하여 카메라 모듈에 대한 최종적인 결과값을 출력할 수 있다(S494). 예를 들어, 중첩 영역(OVA)에 대한 최종적인 결과값이 100명이고 제 1 오차가 ㅁ3명이고, 비중첩 영역(NOVA1, NOVA2)에 대한 최종적인 결과값이 100명이고 제 2 오차는 ㅁ10명인 경우를 가정하여 보자. 이러한 경우, 전체적인 최종 결과값은 200명, 그리고 오차가 ㅁ13명일 수 있다. 이러한 본 발명에서는 대상 영상(대상 블록)과 비교 영상(비교 블록)을 비교하여 대상 영상에 포함된 객체(OB) 의 수를 판별하기 때문에, 보다 신속하게 객체(OB)의 수를 판별 및 검출할 수 있다. 즉, 보다 신속하게 군중 계수를 수행할 수 있다. 이에 따라, 본 발명은 빠르게 객체(OB)의 수를 판별할 필요가 있는 경우에 적용되는 것이 보다 바람직할 수 있 다. 아울러, 본 발명에서는 저사양의 하드웨어 및 소프트웨어를 이용하더라도 신속하게 객체(OB)의 수를 검출하는 것이 가능하다. 아울러, 본 발명에서는 상대적으로 좁은 공간에 포함된 객체(OB)의 수를 신속하게 판별하는데 더욱 효과적일 수 있다. 예를 들면, 본 발명은 지하철 등의 전동차 내에 위치하는 객체(OB)(승객)의 수를 검출하는데 보다 유용하게 사 용될 수 있다. 지하철 등의 전동차는 상대적으로 공간이 좁고, 승객의 수에 따라 좁은 공간에 다수의 객체(OB)가 위치할 수 있 으며, 승차 및/또는 하차에 대응하여 전동차 내에 위치하는 객체(OB)의 수가 빈번하게 변동될 수 있다. 전동차에 카메라 모듈을 설치하고, 이를 이용하여 전동차 내에 위치하는 객체(OB)의 수, 즉 승객의 수를 검 출하는 방법에 대해 첨부된 도면을 참조하여 살펴보면 아래와 같다. 도 30 내지 도 32는 카메라 모듈을 전동차에 설치하는 경우에 대해 설명하기 위한 도면이다. 이하에서는 이상 에서 상세히 설명한 부분에 대한 설명은 생략될 수 있다. 도 30을 살펴보면, 카메라 모듈이 지하철 등의 전동차의 내부에 설치될 수 있다. 예를 들면, 카메라 모듈은 전동차의 내부의 상부벽에 설치될 수 있다. 이러한 경우, 거리에 따른 오차 발생을 억제하거나 방지하기 위해 전동차의 중앙 부분의 상부벽에 카메라 모듈을 설치하는 것이 가능하다. 이처럼, 카메라 모듈이 전동차의 중앙 부분에 설치되는 경우에는 카메라 모듈의 제 1 카메라부(1 1)와 제 2 카메라부가 서로 다른 방향을 향할 수 있다. 예를 들면, 도 31에 나타나 있는 바와 같이, 카메라 모듈의 제 1 카메라부는 전동차의 좌측 부분을 향해 비스듬하게 기울어지고, 제 2 카메라부는 전동차의 우측 부분을 향해 비스듬하게 기울어질 수 있 다. 아울러, 좁고 긴 형태의 공간을 갖는 전동차의 특성을 고려하면, 제 1 카메라부에 대응하는 촬영 영역 의 제 1 비중첩영역(NOVA1)의 사이즈(면적)은 중첩영역(OVA)의 사이즈(면적)보다 더 크고, 제 2 카메라부에 대응하는 촬영 영역의 제 2 비중첩영역(NOVA2)의 사이즈(면적)은 중첩영역(OVA)의 사이즈(면적)보다 더 클 수 있다. 이처럼, 카메라 모듈이 전동차 내에 설치되고, 서버는 카메라 모듈이 촬영한 영상(대상 영상) 을 이용하여 전동차 내에 위치하는 객체(OB), 즉 승객의 수를 검출할 수 있다. 아울러, 전동차에서는 좁고 긴 형태를 갖는 공간에 객체(OB), 즉 승객이 위치하며, 전동차의 이동 중에 는 객체(OB)들의 이동이 상대적으로 감소할 수 있다. 이를 고려하면, 본 발명에서와 같이 대상 영상(대상 블록)과 비교 영상(비교 블록)을 비교하여 대상 영상(대상 블록)에 포함된 객체(OB)의 수를 신속하게 검출하는 기술이 전동차에 적용되는 것이 보다 바람직할 수 있다. 카메라 모듈이 전동차에 적용되는 경우에서 군주 계수를 수행하는 방법에 대해 첨부된 도면을 참조하여 살펴보면 아래와 같다.전동차에서 군중 계수를 수행하기 위해 서버와 전동차의 운행을 제어하는 전동차 제어부(미도시)는 서로 연동되고 통신을 수행할 수 있다. 도 32를 살펴보면, 먼저 전동차의 문(Door)의 계폐를 확인할 수 있다(S500). 이후, 전동차의 문이 닫혀 있는 상태인지의 여부를 판단할 수 있다(S510). S510단계에서 판단결과 전동차의 문이 닫히지 않은 상태, 즉 문이 열린 상태인 경우에서는 미리 설정된 제 4 기능(Default 4)을 수행할 수 있다(S520). 제 4 기능은 전동차의 문이 닫힐때가지 대기하는 기능 등을 예로 들 수 있다. 반면에, S510단계에서 판단결과 전동차의 문이 닫힌 상태에서는 전동차의 속도를 확인할 수 있다 (S530). 이후, 전동차의 속도가 미리 설정된 임계 속도 이상인지의 여부를 판단할 수 있다(S540). S540단계에서 판단결과, 전동차의 속도가 임계 속도보다 낮은 경우에는 미리 설정된 제 5 기능(Default 5) 을 수행할 수 있다(S550). 제 5 기능은 전동차의 속도가 임계 속도를 넘을 때까지 대기하는 기능 등을 예로 들 수 있다. 반면에, S550단계에서 판단결과 전동차의 속도가 임계 속도를 넘어서는 경우에는 카메라 모듈의 제 1 카메라부 및 제 2 카메라부를 이용하여 촬영 영역의 영상, 즉 대상 영상을 촬영할 수 있다(S400). 여기서, 촬영 영역은 전동차의 내부를 포함할 수 있고, 대상 영상은 전동차의 내부의 영상을 포함할 수 있다. 이후, 카메라 모듈이 촬영한 대상 영상에서 객체(OB), 즉 승객의 수를 검출할 수 있다(S470) 카메라 모듈이 촬영 영역의 대상 영상을 촬영하고, 대상 영상에서 객체(OB)의 수를 검출하는 방법은 앞서 상세히 설명하였으므로 중복되는 설명은 생략하기로 한다. 대상 영상에서 객체(OB)의 수를 검출한 이후에는 군중 계수 모드를 종료할지의 여부를 판단하여(S560), 종료하 는 경우에는 군중 계수 모드를 종료할 수 있다(S570). 반면에 S560단계에서 판단결과, 군중 계수 모드를 종료하지 않는 경우에는 다시 S500단계로 진행할 수 있다. 도 32의 내용을 고려하면, 전동차의 속도가 임계 속도 이하이거나 혹은 전동차의 문이 열려 있는 상태 에서는 카메라 모듈은 촬영을 실시하지 않을 수 있다. 반면에, 전동차의 문이 닫혀 있는 상태에서 전동차의 속도가 임계 속도 이상인 경우에 카메라 모듈(1 0)이 영상을 촬영하고, 촬영한 영상에서 객체(OB)의 수를 검출할 수 있다. 아울러, 이러한 과정을 반복할 수 있다. 다른 관점에서 보면, 지하철의 경우 전동차가 정거장에 정차하여 승객이 승차 혹은 하차하는 과정에서는 카 메라 모듈이 촬영을 실시하지 않을 수 있다. 반면에, 전동차가 정거장을 출발하여 충분한 속도에 도달 한 경우(임계 속도를 넘은 경우)에는 카메라 모듈이 영상을 촬영하고, 촬영한 영상에서 객체(OB)의 수를 검 출할 수 있다. 이러한 과정은 인접하는 두 개의 정거장의 사이에서 적어도 1회 이상 수행될 수 있다. 객체(OB), 즉 승객이 전 동차의 사이를 오가는 경우도 있기 때문에 바람직하게는 인접하는 두 개의 정거장의 사이에서 객체(OB)의 수를 검출하는 과정을 복수회 실시하는 것이 바람직할 수 있다. 아울러, 소정의 정거장을 지나면 객체(OB)의 수를 검출하는 과정을 다시 수행할 수 있다. 위에서 설명한 바와 같이, 전동차 내부에 위치하는 객체(OB), 즉 승객의 수를 검출한 이후에는 검출한 승객 의 수에 대한 정보를 전동차를 관리하는 중앙 서버(미도시)에 전송할 수 있다. 그러면, 중앙 서버에는 소정의 제 1 정거장에 전동차가 도착하기 이전에 해당 전동차에 탑승하고 있는 승객의 수를 제 1 정거장에 승차 대기 중인 고객에게 미리 알릴 수 있다. 그러면, 제 1 정거장에서 대기 중인 고객들은 어느 전동차에 적은 수의 승객이 탑승하고 있는지를 미리 확인할 수 있고, 이에 따라 복수의 전동차에 고르게 승객을 분산시키는 효과를 획득할 수 있다."}
{"patent_id": "10-2021-0063245", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이와 같이, 상술한 본 발명의 기술적 구성은 본 발명이 속하는 기술분야의 당업자가 본 발명의 그 기술적 사상 이나 필수적 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해되어야 하고, 본 발명의 범위는 전술한 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범 위의 의미 및 범위 그리고 그 등가개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함 되는 것으로 해석되어야 한다."}
{"patent_id": "10-2021-0063245", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 내지 도 3은 본 발명에 따른 인공지능을 이용한 군중 계수 장치에 대해 설명하기 위한 도면이다. 도 4 내지 도 7은 기준 정보를 설정하고 이용하는 방법에 대해 설명하기 위한 도면이다. 도 8 내지 도 20은 비교 영상 및 기준 영상에 대해 설명하기 위한 도면이다. 도 21 내지 도 23은 군준 계수 모드에 대해 설명하기 위한 도면이다. 도 24 내지 도 29는 카메라 모듈에 대해 설명하기 위한 도면이다. 도 30 내지 도 32는 카메라 모듈을 전동차에 설치하는 경우에 대해 설명하기 위한 도면이다."}
