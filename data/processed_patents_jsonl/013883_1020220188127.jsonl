{"patent_id": "10-2022-0188127", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0105756", "출원번호": "10-2022-0188127", "발명의 명칭": "텍스처 기반의 영상 데이터 처리 방법 및 이를 이용한 시스템", "출원인": "주식회사 옵트에이아이", "발명자": "이재호"}}
{"patent_id": "10-2022-0188127", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나 이상의 프로세서에 의해 수행되는 텍스처 기반 영상 데이터 처리 방법에 있어서,객체의 구획 정보에 기초하여 입력 데이터를 크롭(crop)하여 복수의 구획 이미지를 생성하는 단계;상기 복수의 구획 이미지에 포함된 각각의 구획 이미지 중 상기 객체의 구획 정보에 대응되는 영역 이외의 영역의 픽셀 값을 제거하여 복수의 객체 이미지를 생성하는 단계; 및상기 복수의 객체 이미지의 속성에 기초하여 상기 복수의 객체 이미지에 대한 업 샘플링 수행 여부를 판단하는단계를 포함하고,상기 객체의 구획 정보는 상기 입력 데이터의 텍스처 정보를 기반으로 텍스처가 상이한 영역을 구분하는 벡터정보를 포함하고,상기 복수의 객체 이미지의 속성은 각 객체 이미지 중 픽셀 값이 존재하는 영역의 비율 및 상기 복수의 객체 이미지의 사이즈 분포를 포함하는텍스처 기반의 데이터 처리 방법."}
{"patent_id": "10-2022-0188127", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,업 샘플링 수행 여부의 판단 결과가 긍정인 경우, 상기 복수의 객체 이미지에 대해 사이즈 비율의 정수배로 확대하는 업 샘플링을 수행하는 단계를 더 포함하는텍스처 기반의 데이터 처리 방법."}
{"patent_id": "10-2022-0188127", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 복수의 객체 이미지에 포함된 각 객체 이미지를 제1 이미지 그룹 및 제2 이미지 그룹으로 분류하는 단계를더 포함하고,상기 제1 이미지 그룹은 인공지능 모델의 입력 데이터 사이즈보다 사이즈가 작은 이미지를 포함하고,상기 제2 이미지 그룹은 상기 인공지능 모델의 입력 데이터 사이즈보다 사이즈가 큰 이미지를 포함하는텍스처 기반의 데이터 처리 방법."}
{"patent_id": "10-2022-0188127", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 인공지능 모델의 입력 데이터 사이즈와 일치하도록, 픽셀 값이 0인 픽셀을 이용하여 상기 제1 이미지 그룹에 포함된 이미지의 사이즈를 변경하는 단계를 더 포함하는텍스처 기반의 데이터 처리 방법.공개특허 10-2024-0105756-3-청구항 5 제4항에 있어서,상기 제1 이미지 그룹에 포함된 이미지의 사이즈를 변경하는 단계는,상기 제1 이미지 그룹에 포함된 이미지를 중심으로 상하에 N개의 픽셀 및 좌우에 M개의 픽셀- 상기 N, M은 정수임 -을 추가하는 단계인텍스처 기반의 데이터 처리 방법."}
{"patent_id": "10-2022-0188127", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 제2 이미지 그룹에 포함된 이미지에 대해 크롭을 수행하는 단계를 더 포함하고,상기 크롭을 수행하는 단계는,상기 제2 이미지 그룹에 포함된 이미지의 제1 엣지를 기준으로 이미지를 상기 인공지능 모델의 입력 데이터 사이즈로 크롭하여 제1 엣지 이미지를 생성하는 단계; 및상기 제2 이미지 그룹에 포함된 이미지의 제2 엣지를 기준으로 이미지를 상기 인공지능 모델의 입력 데이터 사이즈로 크롭하여 제2 엣지 이미지를 생성하는 단계를 포함하고,상기 제1 엣지 이미지 및 상기 제2 엣지 이미지는 적어도 일부가 오버랩되는텍스처 기반의 데이터 처리 방법."}
{"patent_id": "10-2022-0188127", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제1 엣지 이미지를 상기 인공지능 모델에 입력하여 제1 대상에 대한 제1 확률 및 제2 대상에 대한 제2 확률을 획득하는 단계; 및상기 제2 엣지 이미지를 상기 인공지능 모델에 입력하여 상기 제1 대상에 대한 제3 확률 및 상기 제2 대상에 대한 제4 확률을 획득하는 단계를 더 포함하고,상기 제1 대상 및 상기 제2 대상은 상기 제1 엣지 이미지 또는 상기 제2 엣지 이미지에 포함된 객체의 텍스처정보에 기초하여 상기 객체가 분류될 수 있는 항목인텍스처 기반의 데이터 처리 방법."}
{"patent_id": "10-2022-0188127", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제1 확률, 상기 제2 확률, 상기 제3 확률 및 상기 제4 확률에 기초하여 상기 제2 이미지 그룹에 포함된 이미지 내의 객체를 판별하는 단계를 더 포함하고,상기 제2 이미지 그룹에 포함된 이미지 내의 객체를 판별하는 단계는,상기 제1 엣지 이미지 내에서 상기 객체가 존재하는 비율인 제1 비율 및 상기 제2 엣지 이미지 내에서 상기 객체가 존재하는 비율인 제2 비율을 산출하는 단계;상기 제1 확률 및 상기 제2 확률에 상기 제1 비율을 곱하여 각각 제1 가중치 확률 및 제2 가중치 확률을 획득하고, 상기 제3 확률 및 상기 제4 확률에 제2 비율을 곱하여 각각 제3 가중치 확률 및 제4 가중치 확률을 획득하는 단계;공개특허 10-2024-0105756-4-상기 제1 가중치 확률 및 상기 제3 가중치 확률을 더하여 상기 제1 대상에 대한 제1 가중합을 산출하고, 상기제2 가중치 확률 및 상기 제4 가중치 확률을 더하여 상기 제2 대상에 대한 제2 가중합을 산출하는 단계; 및상기 제1 가중합 및 상기 제2 가중합에 기초하여 상기 제2 이미지 그룹에 포함된 이미지의 객체가 상기 제1 대상인지 또는 상기 제2 대상인지 여부를 판단하는 단계를 포함하는텍스처 기반의 데이터 처리 방법."}
{"patent_id": "10-2022-0188127", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제4항에 있어서,사이즈가 변경된 상기 제1 이미지 그룹에 포함된 이미지를 상기 인공지능 모델에 입력하여 제1 대상에 대한 확률 및 제2 대상에 대한 확률을 획득하는 단계; 및상기 제1 대상에 대한 확률 및 상기 제2 대상에 대한 확률에 기초하여 상기 제1 이미지 그룹에 포함된 이미지내의 객체를 판별하는 단계를 더 포함하고,상기 제1 대상 및 상기 제2 대상은 사이즈가 변경된 상기 제1 이미지 그룹에 포함된 이미지 내의 객체의 텍스처정보에 기초하여 상기 객체가 분류될 수 있는 항목인텍스처 기반의 데이터 처리 방법."}
{"patent_id": "10-2022-0188127", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제3항에 있어서,상기 제2 이미지 그룹에 포함된 이미지에 대해 크롭을 수행하는 단계를 더 포함하고,상기 크롭을 수행하는 단계는,상기 제2 이미지 그룹에 포함된 이미지의 가로의 크기가 상기 인공지능 모델의 입력 데이터의 가로 사이즈의 A배- 상기 A는 자연수임 -를 초과하고 A+1배 이하인 경우, 가로에 대해 A+1개의 이미지를 생성하도록 크롭을 수행하는 단계, 및상기 제2 이미지 그룹에 포함된 이미지의 세로의 크기가 상기 인공지능 모델의 입력 데이터의 세로 사이즈의 B배- 상기 B는 자연수임 -를 초과하고 B+1배 이하인 경우, 세로에 대해 B+1개의 이미지를 생성하도록 크롭을 수행하는 단계를 포함하고,상기 A+1개의 이미지 중 인접한 이미지 사이의 오버랩 영역은 모두 동일하고,상기 B+1개의 이미지 중 인접한 이미지 사이의 오버랩 영역은 모두 동일한텍스처 기반의 데이터 처리 방법."}
{"patent_id": "10-2022-0188127", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제10항 중 어느 한 항에 기재된 텍스처 기반의 데이터 처리 방법을 실행시키도록 컴퓨터로 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0188127", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "객체의 구획 정보에 기초하여 입력 데이터를 크롭(crop)하여 복수의 구획 이미지를 생성하는 구획 생성부;상기 복수의 구획 이미지에 포함된 각각의 구획 이미지 중 상기 객체의 구획 정보에 대응되는 영역 이외의 영역의 픽셀 값을 제거하여 복수의 객체 이미지를 생성하는 배경 처리부; 및공개특허 10-2024-0105756-5-상기 복수의 객체 이미지의 속성에 기초하여 상기 복수의 객체 이미지에 대한 업 샘플링 수행 여부를 판단하는업 샘플링부를 포함하고,상기 객체의 구획 정보는 상기 입력 데이터의 텍스처 정보를 기반으로 텍스처가 상이한 영역을 구분하는 벡터정보를 포함하고,상기 복수의 객체 이미지의 속성은 각 객체 이미지 중 픽셀 값이 존재하는 영역의 비율 및 상기 복수의 객체 이미지의 사이즈 분포를 포함하는텍스처 기반의 데이터 처리 시스템."}
{"patent_id": "10-2022-0188127", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 텍스처 기반의 데이터 처리 방법은 객체의 구획 정보에 기초하여 입력 데이터를 크롭(crop)하여 복수 의 구획 이미지를 생성하는 단계; 상기 복수의 구획 이미지에 포함된 각각의 구획 이미지 중 상기 객체의 구획 정보에 대응되는 영역 이외의 영역의 픽셀 값을 제거하여 복수의 객체 이미지를 생성하는 단계; 및 상기 복수의 객체 이미지의 속성에 기초하여 상기 복수의 객체 이미지에 대한 업 샘플링 수행 여부를 판단하는 단계를 포함하 고, 상기 객체의 구획 정보는 상기 입력 데이터의 텍스처 정보를 기반으로 텍스처가 상이한 영역을 구분하는 벡 터 정보를 포함하고, 상기 복수의 객체 이미지의 속성은 각 객체 이미지 중 픽셀 값이 존재하는 영역의 비율 및 상기 복수의 객체 이미지의 사이즈 분포를 포함할 수 있다."}
{"patent_id": "10-2022-0188127", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 텍스처 기반의 영상 데이터 처리 방법에 관한 것으로, 보다 상세하게는, 인공지능 모델을 이용하여 영상 데이터 내의 텍스처 기반의 객체를 분류하기 위한 것으로 인공지능 모델을 사용하기 위한 전처리 과정 및 인공지능 모델의 결과에 대한 후처리 과정에 관한 것이다."}
{"patent_id": "10-2022-0188127", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "농경지에 대한 정보는 국가의 중요한 행정 정보 중 하나이다. 농경지에 대한 정보를 이용하여 농작물 산출량을 예측하여 행정 계획을 세울 수 있고, 농경지에 대한 정보 중 농경지의 크기에 대한 정보를 이용하여 지원금 제 도를 상황에 맞게 수정할 수도 있다. 농경지의 현황은 시기에 따라 매번 달라질 수 있어, 일반적으로 농경지 현황 파악의 주기는 짧다. 농경지 현황 을 파악하는 방법으로는 항공 사진을 이용한 방법이 존재한다. 그러나 종래는 항공 사진을 이용해 사람이 수작 업으로 농경지를 분류하고 이에 대한 정보를 수집하기 때문에 노동력, 비용 및 시간이 많이 소요되는 문제가 존 재했다. 최근 인공지능을 이용한 농경지 정보 획득에 대한 연구가 대두되고 있는데, 이에 따라 인공지능을 이용 하기 위한 데이터 전처리 과정과 인공지능이 출력한 데이터를 처리하는 후처리 과정이 필요하다."}
{"patent_id": "10-2022-0188127", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 과제는 인공지능 모델을 이용하여 영상 데이터 내의 텍스처 기반의 객체를 분류하기 위한 것으로 인공지능 모델을 사용하기 위한 전처리 과정 및 인공지능 모델의 결과에 대한 후처리 과정에 관한 것이다."}
{"patent_id": "10-2022-0188127", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 텍스처 기반의 영상 데이터 처리 방법은 적어도 하나 이상의 프로세서에 의해 수행되는 텍스 처 기반 영상 데이터 처리 방법에 있어서, 객체의 구획 정보에 기초하여 입력 데이터를 크롭(crop)하여 복수의 구획 이미지를 생성하는 단계; 상기 복수의 구획 이미지에 포함된 각각의 구획 이미지 중 상기 객체의 구획 정 보에 대응되는 영역 이외의 영역의 픽셀 값을 제거하여 복수의 객체 이미지를 생성하는 단계; 및 상기 복수의 객체 이미지의 속성에 기초하여 상기 복수의 객체 이미지에 대한 업 샘플링 수행 여부를 판단하는 단계를 포함 하고, 상기 객체의 구획 정보는 상기 입력 데이터의 텍스처 정보를 기반으로 텍스처가 상이한 영역을 구분하는 벡터 정보를 포함하고, 상기 복수의 객체 이미지의 속성은 각 객체 이미지 중 픽셀 값이 존재하는 영역의 비율 및 상기 복수의 객체 이미지의 사이즈 분포를 포함할 수 있다. 여기서, 업 샘플링 수행 여부의 판단 결과가 긍정인 경우, 상기 복수의 객체 이미지에 대해 사이즈 비율의 정수 배로 확대하는 업 샘플링을 수행하는 단계를 더 포함할 수 있다. 여기서, 상기 복수의 객체 이미지에 포함된 각 객체 이미지를 제1 이미지 그룹 및 제2 이미지 그룹으로 분류하 는 단계를 더 포함하고, 상기 제1 이미지 그룹은 인공지능 모델의 입력 데이터 사이즈보다 사이즈가 작은 이미 지를 포함하고, 상기 제2 이미지 그룹은 상기 인공지능 모델의 입력 데이터 사이즈보다 사이즈가 큰 이미지를 포함할 수 있다. 여기서, 상기 인공지능 모델의 입력 데이터 사이즈와 일치하도록, 픽셀 값이 0인 픽셀을 이용하여 상기 제1 이 미지 그룹에 포함된 이미지의 사이즈를 변경하는 단계를 더 포함할 수 있다. 여기서, 상기 제1 이미지 그룹에 포함된 이미지의 사이즈를 변경하는 단계는, 상기 제1 이미지 그룹에 포함된 이미지를 중심으로 상하에 N개의 픽셀 및 좌우에 M개의 픽셀- 상기 N, M은 정수임 -을 추가하는 단계일 수 있다. 여기서, 상기 제2 이미지 그룹에 포함된 이미지에 대해 크롭을 수행하는 단계를 더 포함하고, 상기 크롭을 수행 하는 단계는, 상기 제2 이미지 그룹에 포함된 이미지의 제1 엣지를 기준으로 이미지를 상기 인공지능 모델의 입 력 데이터 사이즈로 크롭하여 제1 엣지 이미지를 생성하는 단계; 및 상기 제2 이미지 그룹에 포함된 이미지의 제2 엣지를 기준으로 이미지를 상기 인공지능 모델의 입력 데이터 사이즈로 크롭하여 제2 엣지 이미지를 생성하 는 단계를 포함하고, 상기 제1 엣지 이미지 및 상기 제2 엣지 이미지는 적어도 일부가 오버랩될 수 있다. 여기서, 상기 제1 엣지 이미지를 상기 인공지능 모델에 입력하여 제1 대상에 대한 제1 확률 및 제2 대상에 대한 제2 확률을 획득하는 단계; 및 상기 제2 엣지 이미지를 상기 인공지능 모델에 입력하여 상기 제1 대상에 대한 제3 확률 및 상기 제2 대상에 대한 제4 확률을 획득하는 단계를 더 포함하고, 상기 제1 대상 및 상기 제2 대상 은 상기 제1 엣지 이미지 또는 상기 제2 엣지 이미지에 포함된 객체의 텍스처 정보에 기초하여 상기 객체가 분 류될 수 있는 항목일 수 있다. 여기서, 상기 제1 확률, 상기 제2 확률, 상기 제3 확률 및 상기 제4 확률에 기초하여 상기 제2 이미지 그룹에 포함된 이미지 내의 객체를 판별하는 단계를 더 포함하고, 상기 제2 이미지 그룹에 포함된 이미지 내의 객체를 판별하는 단계는, 상기 제1 엣지 이미지 내에서 상기 객체가 존재하는 비율인 제1 비율 및 상기 제2 엣지 이미 지 내에서 상기 객체가 존재하는 비율인 제2 비율을 산출하는 단계; 상기 제1 확률 및 상기 제2 확률에 상기 제 1 비율을 곱하여 각각 제1 가중치 확률 및 제2 가중치 확률을 획득하고, 상기 제3 확률 및 상기 제4 확률에 제2 비율을 곱하여 각각 제3 가중치 확률 및 제4 가중치 확률을 획득하는 단계; 상기 제1 가중치 확률 및 상기 제3 가중치 확률을 더하여 상기 제1 대상에 대한 제1 가중합을 산출하고, 상기 제2 가중치 확률 및 상기 제4 가중치 확률을 더하여 상기 제2 대상에 대한 제2 가중합을 산출하는 단계; 및 상기 제1 가중합 및 상기 제2 가중합에 기초하여 상기 제2 이미지 그룹에 포함된 이미지의 객체가 상기 제1 대상인지 또는 상기 제2 대상인지 여부를 판단하는 단계를 포함할 수 있다. 여기서, 사이즈가 변경된 상기 제1 이미지 그룹에 포함된 이미지를 상기 인공지능 모델에 입력하여 제1 대상에 대한 확률 및 제2 대상에 대한 확률을 획득하는 단계; 및 상기 제1 대상에 대한 확률 및 상기 제2 대상에 대한 확률에 기초하여 상기 제1 이미지 그룹에 포함된 이미지 내의 객체를 판별하는 단계를 더 포함하고, 상기 제1 대상 및 상기 제2 대상은 사이즈가 변경된 상기 제1 이미지 그룹에 포함된 이미지 내의 객체의 텍스처 정보에 기초하여 상기 객체가 분류될 수 있는 항목일 수 있다. 여기서, 상기 제2 이미지 그룹에 포함된 이미지에 대해 크롭을 수행하는 단계를 더 포함하고, 상기 크롭을 수행 하는 단계는, 상기 제2 이미지 그룹에 포함된 이미지의 가로의 크기가 상기 인공지능 모델의 입력 데이터의 가 로 사이즈의 A배- 상기 A는 자연수임 -를 초과하고 A+1배 이하인 경우, 가로에 대해 A+1개의 이미지를 생성하도 록 크롭을 수행하는 단계, 및 상기 제2 이미지 그룹에 포함된 이미지의 세로의 크기가 상기 인공지능 모델의 입 력 데이터의 세로 사이즈의 B배- 상기 B는 자연수임 -를 초과하고 B+1배 이하인 경우, 세로에 대해 B+1개의 이 미지를 생성하도록 크롭을 수행하는 단계를 포함하고, 상기 A+1개의 이미지 중 인접한 이미지 사이의 오버랩 영 역은 모두 동일하고, 상기 B+1개의 이미지 중 인접한 이미지 사이의 오버랩 영역은 모두 동일할 수 있다. 여기서, 상기 텍스처 기반의 데이터 처리 방법을 실행시키도록 컴퓨터로 판독 가능한 기록 매체에 저장된 컴퓨 터 프로그램이 제공될 수 있다. 일 실시예에 따른 텍스처 기반의 데이터 처리 시스템은 객체의 구획 정보에 기초하여 입력 데이터를 크롭(cro p)하여 복수의 구획 이미지를 생성하는 구획 생성부; 상기 복수의 구획 이미지에 포함된 각각의 구획 이미지 중 상기 객체의 구획 정보에 대응되는 영역 이외의 영역의 픽셀 값을 제거하여 복수의 객체 이미지를 생성하는 배 경 처리부; 및 상기 복수의 객체 이미지의 속성에 기초하여 상기 복수의 객체 이미지에 대한 업 샘플링 수행 여 부를 판단하는 업 샘플링부를 포함하고, 상기 객체의 구획 정보는 상기 입력 데이터의 텍스처 정보를 기반으로 텍스처가 상이한 영역을 구분하는 벡터 정보를 포함하고, 상기 복수의 객체 이미지의 속성은 각 객체 이미지 중 픽셀 값이 존재하는 영역의 비율 및 상기 복수의 객체 이미지의 사이즈 분포를 포함할 수 있다."}
{"patent_id": "10-2022-0188127", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면 인공지능 모델을 사용하기 위한 전처리 과정 및 인공지능 모델의 결과에 대한 후 처리 과정 제공될 수 있다."}
{"patent_id": "10-2022-0188127", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 기재된 실시예는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 본 발명의 사상을 명 확히 설명하기 위한 것이므로, 본 발명이 본 명세서에 기재된 실시예에 한정되는 것은 아니며, 본 발명의 범위 는 본 발명의 사상을 벗어나지 아니하는 수정예 또는 변형예를 포함하는 것으로 해석되어야 한다. 본 명세서에서 사용되는 용어는 본 발명에서의 기능을 고려하여 가능한 현재 널리 사용되고 있는 일반적인 용어 를 선택하였으나 이는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자의 의도, 판례 또는 새로운 기술 의 출현 등에 따라 달라질 수 있다. 다만, 이와 달리 특정한 용어를 임의의 의미로 정의하여 사용하는 경우에는 그 용어의 의미에 관하여 별도로 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌 그 용어가 가진 실질적인 의미와 본 명세서의 전반에 걸친 내용을 토대로 해석되어야 한다. 본 명세서에 첨부된 도면은 본 발명을 용이하게 설명하기 위한 것으로 도면에 도시된 형상은 본 발명의 이해를 돕기 위하여 필요에 따라 과장되어 표시된 것일 수 있으므로 본 발명이 도면에 의해 한정되는 것은 아니다. 본 명세서에서 본 발명에 관련된 공지의 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있 다고 판단되는 경우에 이에 관한 자세한 설명은 필요에 따라 생략하기로 한다. 도 1은 텍스처 기반의 데이터를 설명하기 위한 도면이다. 도 1(a)는 형태 기반의 데이터의 예시이고, 도 1(b)는 텍스처 기반의 데이터의 예시이다. 도 1(a)를 참조하면, 사람의 손 모양은 형태 데이터 및 텍스처(texture) 데이터로 분류될 수 있다. 사람의 손 모양은 형태 기반의 데이터로서, 텍스처와 상관없이 형태 데이터만으로 사람의 손임을 알 수 있는 데이터이다. 형태 데이터로 형태가 무엇인지 판단이 되며, 추가적으로 텍스처 정보를 통해 손에 대한 인종 및 나이가 판단될 수 있다. 도 1(b)를 참조하면, 농경지 데이터는 도 1(a)와 마찬가지로 형태 데이터 및 텍스처 데이터로 분류될 수 있다. 농경지 데이터는 텍스처 기반의 데이터로서, 형태 데이터만으로 농경지를 논, 밭, 과수 등으로 분류가 불가능한 데이터이다. 즉, 농경지 데이터와 같은 텍스처 기반의 데이터는 형태 데이터보다 텍스처 데이터에 많은 정보가포함되어, 텍스처 데이터에 의존하여 객체 분류가 가능한 데이터를 의미하는 것일 수 있다. 예를 들어, 텍스처 데이터는 농경지 데이터, 도로와 관련된 데이터, 화재 시 발생되는 연기 영상 데이터 등일 수 있다. 도 2 내지 도 6을 참조하면, 텍스처 데이터의 예시를 알 수 있다. 인공지능 모델을 이용한 객체 분류는 많은 분야에 사용되고 있다. 객체 분류에 인공지능 모델을 사용하기 위해 서는, 입력 데이터의 크기를 인공지능 모델의 입력 데이터 크기에 맞추는 전처리 과정이 먼저 선행되어야 한다. 종래는 단순히 크기를 늘리거나 줄이는 리사이징(resizing) 방식을 사용하였다. 형태 기반의 데이터는 리사이징 을 하여 그 모양이 약간 왜곡되더라도, 객체의 분류가 가능할 수 있다. 예를 들어, 도 1(a)의 사람 손 모양의 형태 데이터가 가로의 크기가 약간 늘어난다고 하더라도, 객체가 사람의 손으로 분류될 수 있다. 그러나, 텍스처 데이터에 많은 정보가 포함된 텍스처 기반의 데이터는 리사이징을 통해 그 형태가 왜곡되면 인 식 오류가 발생될 수 있다. 구체적으로, 텍스처 기반의 데이터는 패턴(논, 밭, 과수 등인지를 구분할 수 있는 텍스처)을 포함하고 있는데, 리사이징 과정에서 패턴이 왜곡될 수 있다. 따라서, 텍스처 기반의 데이터는 인공 지능 모델을 이용하기 위한 전처리 과정은 형태 기반의 데이터에서의 전처리 과정과 다르다. 도 2 내지 도 6은 텍스처 기반의 데이터 예시를 설명하기 위한 도면이다. 도 2는 논에 대한 텍스처 기반의 데이터를 나타낸 도면이다. 도 2(a)는 논갈이 상태의 논의 텍스처 데이터를 나 타낸 도면이고, 도 2(b)는 물 댄 상태(모내기를 마친 상태)의 논의 텍스처 데이터를 나타낸 도면이고, 도 2(c) 는 작물 생육 상태의 논의 텍스처 데이터를 나타낸 도면이고, 도 2(d)는 작물 수확 후 상태의 논의 텍스처 데이 터를 나타낸 도면이다. 도 2(a) 내지 도 2(d)를 참조하면, 논에 대한 텍스처 기반의 데이터는 형태 데이터(빨간색 박스) 및 텍스처 데 이터(빨간색 박스 내의 패턴)로 분류될 수 있다. 특히, 도 2(a) 내지 도 2(d)의 텍스터 데이터에 논의 상태를 분류할 수 있는 정보를 가지는 패턴이 포함될 수 있다. 도 3은 밭에 대한 텍스처 기반의 데이터를 나타낸 도면이다. 도 3(a)는 작물이 줄지어 재비되는 상태의 밭의 텍 스처 데이터를 나타낸 도면이고, 도 3(b)는 밭을 갈아 놓은 상태의 밭의 텍스처 데이터를 나타낸 도면이고, 도 3(c)는 작물 위에 비닐이 멀칭된 상태의 밭의 텍스처 데이터를 나타낸 도면이고, 도 3(d)는 조경수/묘포 상태의 밭의 텍스처 데이터를 나타낸 도면이다. 도 3(a) 내지 도 3(d)를 참조하면, 밭에 대한 텍스처 기반의 데이터는 형태 데이터(빨간색 박스) 및 텍스처 데 이터(빨간색 박스 내의 패턴)로 분류될 수 있다. 특히, 도 3(a) 내지 도 3(d)의 텍스터 데이터에 밭의 상태를 분류할 수 있는 정보를 가지는 패턴이 포함될 수 있다. 도 4는 과수에 대한 텍스처 기반의 데이터를 나타낸 도면이다. 도 4(a)는 일반 과수의 텍스처 데이터를 나타낸 도면이고, 도 4(b)는 과수가 포도 나무인 경우의 텍스처 데이터를 나타낸 도면이다. 도 4(a) 및 도 4(b)를 참조하면, 과수에 대한 텍스처 기반의 데이터는 형태 데이터(빨간색 박스) 및 텍스처 데 이터(빨간색 박스 내의 패턴)로 분류될 수 있다. 특히, 도 4(a) 및 도 4(b)의 텍스터 데이터에 과수의 상태를 분류할 수 있는 정보를 가지는 패턴이 포함될 수 있다. 도 5는 시설에 대한 텍스처 기반의 데이터를 나타낸 도면이다. 도 5(a)는 검은색 비닐 하우스의 텍스처 데이터 를 나타낸 도면이고, 도 5(b)는 흰색 비닐 하우스의 텍스처 데이터를 나타낸 도면이고, 도 5(c)는 진청색 비닐 하우스의 텍스처 데이터를 나타낸 도면이고, 도 5(d)는 온실의 텍스처 데이터를 나타낸 도면이다. 도 5(a) 내지 도 5(d)를 참조하면, 시설에 대한 텍스처 기반의 데이터는 형태 데이터(빨간색 박스) 및 텍스처 데이터(빨간색 박스 내의 패턴)로 분류될 수 있다. 특히, 도 5(a) 내지 도 5(d)의 텍스터 데이터에 시설의 상태 를 분류할 수 있는 정보를 가지는 패턴이 포함될 수 있다.도 6은 인삼 재배에 대한 텍스처 기반의 데이터를 나타낸 도면이다. 도 6(a)는 흰색 해 가림막의 텍스처 데이터 를 나타낸 도면이고, 도 6(b)는 파란색 해 가림막의 텍스처 데이터를 나타낸 도면이고, 도 6(c)는 검은색 해 가 림막의 텍스처 데이터를 나타낸 도면이고, 도 6(d)는 한르색 해 가림막의 텍스처 데이터를 나타낸 도면이고, 도 6(e)는 검은색과 흰색의 혼합 해 가림막의 텍스처 데이터를 나타낸 도면이고, 도 6(f)는 검은색 및 파란색의 혼 합 해 가림막의 텍스처 데이터를 나타낸 도면이고, 도 6(g)는 청록색 해 가림막의 텍스처 데이터를 나타낸 도면 이다. 도 6(a) 내지 도 6(g)를 참조하면, 인삼 재배에 대한 텍스처 기반의 데이터는 형태 데이터(빨간색 박스) 및 텍 스처 데이터(빨간색 박스 내의 패턴)로 분류될 수 있다. 특히, 도 6(a) 내지 도 6(g)의 텍스처 데이터에 인삼 재배의 상태를 분류할 수 있는 정보를 가지는 패턴이 포함될 수 있다. 이하에서, 본원 발명의 텍스처 기반 데이터를 인공지능 모델에 입력하기 위한 전처리 과정과 이에 대한 후처리 과정에 대해 설명한다. 도 7은 일 실시예에 따른 텍스처 기반의 영상 데이터 처리 시스템의 블록도이다. 도 7을 참조하면, 일 실시예에 따른 텍스처 기반의 영상 데이터 처리 시스템(1000, 이하 '시스템')은 구획 생성 부, 배경 처리부, 업 샘플링부, 제로 패딩부, 오버랩 크롭부, 결과 산출부 및 데이터베이스부를 포함할 수 있다. 도 1은 시스템에 포함되는 일곱 가지 구성 요소를 도 시하고 있으나, 도시된 구성 요소들이 필수적인 것은 아니고, 시스템은 그보다 많은 구성 요소를 갖거나 그보다 적은 구성 요소를 가질 수 있다. 또한, 시스템의 각 구성 요소는 물리적으로 하나의 서버에 포함 될 수도 있고, 각각의 기능 별로 분산된 분산 서버일 수 있다. 시스템은 시스템의 동작을 총괄하는 제어 프로세서를 포함할 수 있다. 구체적으로, 제어 프로세서 는 구획 생성부, 배경 처리부, 업 샘플링부, 제로 패딩부, 오버랩 크롭부, 결 과 산출부 및 데이터베이스부에 제어 명령을 보내 각 부서의 동작을 실행할 수 있다. 이하에서 특별한 언급이 없는 경우에는, 시스템의 동작은 제어 프로세서의 제어에 의해 수행되는 것으로 해석될 수 있다. 구획 생성부는 입력 데이터를 크롭하여 복수의 구획 이미지를 생성할 수 있다. 구체적으로, 구획 생성부 는 입력 데이터인 항공 영상 데이터를 농경지 중심으로 크롭하여 복수의 구획 이미지를 생성할 수 있다. 예를 들어, 구획 생성부는 나주의 어느 지역에 대한 항공 영상 데이터를 입력 데이터로 획득하고, 상기 지역의 제1 농경지를 중심으로 입력 데이터를 크롭하여 제1 구획 이미지를 생성하고, 상기 지역의 또 다른 농경 지인 제2 농경지를 중심으로 입력 데이터를 크롭하여 제2 구획 이미지를 생성할 수 있다. 배경 처리부는 구획 생성부에 의해 생성된 복수의 구획 이미지의 배경을 제거하여 복수의 객체 이 미지를 생성할 수 있다. 구체적으로, 배경 처리부는 구획 이미지 중 객체의 구획 정보에 대응되는 영역 이외의 영역의 픽셀 값을 제거하여(0으로 하여) 객체가 아닌 부분을 배경 처리할 수 있다. 이때, 객체의 구획 정보는 기 설정된 정보로서, 사용자의 입력에 정해지는 것일 수도 있고, 엣지 디텍션(edge detection) 또는 분 할(segmentation) 기술에 의해 구획 이미지에서의 객체 경계를 의미하는 것일 수 있다. 예를 들어, 객체의 구획 정보는 구획 입력 데이터(또는 구획 이미지)의 텍스처 정보를 기반으로 텍스처가 상이한 영역을 구분하는 벡터 정보를 포함할 수 있다. 구획 생성부가 생성하는 구획 이미지 및 배경 처리부가 생성하는 객체 이미지는 도 9를 참조하여 자세히 설명한다. 업 샘플링부는 배경 처리부에 의해 생성된 복수의 객체 이미지에 대한 속성에 기초하여 복수의 객 체 이미지에 대한 업 샘플링 수행 여부를 판단할 수 있다. 판단 결과가 긍정인 겨우, 업 샘플링부는 복수 의 객체 이미지에 대해 업 샘플링을 수행할 수 있다. 업 샘플링(Up-sampling)은 객체의 크기(객체 이미지 자체의 크기가 아닌 객체 이미지에 포함된 객체만의 크기를 의미함)가 인공지능 모델의 입력 데이터 크기보다 매우 작은 경우 발생될 수 있는 인공지능 모델의 열화를 대비 하여, 이미지에 객체에 대한 정보를 늘리는 과정을 의미할 수 있다. 구체적으로, 객체가 너무 작을 경우, 인공 지능 모델의 입력에 대해 정보가 너무 없기 때문에, 인공지능 모델의 정확도가 매우 낮아지는 등 인공지능 모델 의 열화가 발생될 수 있다. 따라서, 이를 방지하기 위해, 업 샘플링부는 이미지에 대해 업 샘플링을 수행할 수 있다. 먼저, 업 샘플링부는 복수의 객체 이미지의 속성을 파악할 수 있다. 이때, 속성은 객체 이미지 중 객체가 차지하는 비율과 관련된 것일 수 있다. 구체적으로, 업 샘플링부는 복수의 객체 이미지 각각에 대해 객체 가 차지하는 비율을 산출할 수 있다. 예를 들어, 객체가 차지하는 비율은 객체 이미지의 픽셀 개수에 대해 픽셀 값이 0이 아닌 픽셀의 개수를 의미하는 것일 수 있으나, 이에 한정되지 않는다. 업 샘플링부 복수의 객체 이미지에 대해 객체가 차지하는 비율이 제1 기준값 이하인 객체 이미지의 개수 를 산출할 수 있다. 이때, 제1 기준값의 수치는 인공지능 모델의 열화 가능성에 의해 설정될 수 있다. 예를 들 어, 인공지능 모델이 작은 정보에도 분류 성능과 정확도가 뛰어난 경우, 제1 기준값은 낮을 수 있다. 그러나, 인공지능 모델의 성능이 높지 않을 경우, 제1 기준값은 높아질 수 있다. 업 샘플링부는 객체가 차지하는 비율이 기준값 이하인 객체 이미지의 개수가 제2 기준값 이상인 경우, 복 수의 객체 이미지 전체에 대해 업 샘플링을 수행할 수 있다. 이때, 제2 기준값은 환경에 따라 설정되는 값일 수 있다. 예를 들어, 제2 기준값은 복수의 객체 이미지 전체 개수의 절반 또는 2/3일 수 있으나, 이에 한정되지 않 는다. 반대로, 업 샘플링부는 객체가 차지하는 비율이 기준값 이하인 객체 이미지의 개수가 상기 제2 기 준값 미만인 경우, 복수의 객체 이미지 전체에 대해 업 샘플링을 수행하지 않을 수 있다. 업 샘플링부는 복수의 객체 이미지에 대해 사이즈 비율의 정수배로 확대하는 업 샘플링을 수행할 수 있다. 예를 들어, 업 샘플링부는 156 X 188 크기를 갖는 객체 이미지를 2배 확대하여 312 X 376 크기를 갖도록 업 샘플링할 수 있다. 업 샘플링은 종래의 리사이징과 유사한 것으로, 약간의 패턴의 왜곡을 야기할 수 있다. 따라서, 업 샘플링부 는 복수의 객체 이미지 중 객체가 차지하는 비율이 제1 기준값 이하인 객체 이미지에 대해서만 업 샘플링 을 수행하는 것이 아니라, 복수의 객체 이미지 전체에 대해서 업 샘플링을 수행하여야 한다. 업 샘플링부(130 0)는 인공지능 모델의 열화 방지와 동시에 분류의 정확도를 위해, 인공지능 모델에 입력되는 데이터 전체에 대 해 일괄적으로 업 샘플링을 수행하여야 한다. 제로 패딩부는 복수의 객체 이미지에 포함된 각 객체 이미지의 크기에 기초하여 제로 패딩(Zero- padding)을 수행할 수 있다. 구체적으로, 제로 패딩부는 객체 이미지의 크기가 인공지능 모델의 입력 데 이터 크기보다 작은 경우, 객체 이미지를 인공지능 모델의 입력 데이터 크기에 맞추는 제로 패딩을 수행할 수 있다. 이때, 제로 패딩부는 픽셀 값이 0인 픽셀을 이용하여 제로 패딩을 수행할 수 있다. 제로 패딩부 가 수행하는 제로 패딩에 대해서는 도 11 및 도 12를 참조하여 이하에서 설명한다. 오버랩 크롭부는 복수의 객체 이미지에 포함된 각 객체 이미지의 크기에 기초하여 오버랩 크롭(overlap crop 또는 overlapped crop)을 수행할 수 있다. 구체적으로, 오버랩 크롭부는 객체 이미지의 크기가 인공 지능 모델의 입력 데이터 크기보다 큰 경우, 객체 이미지를 인공지능 모델의 입력 데이터 크기에 맞도록 크롭하 는 오버랩 크롭을 수행할 수 있다. 이때, 오버랩 크롭부는 크롭된 이미지들의 일부가 오버랩될 수 있도록 객체 이미지를 크롭할 수 있다. 오버랩 크롭부가 수행하는 오버랩 크롭에 대해서는 도 13 내지 도 15를 참조하여 이하에서 설명한다. 결과 산출부는 인공지능 모델에 의해 출력된 결과를 분석하여 객체 이미지 내의 객체의 분류를 결정할 수 있다. 구체적으로, 결과 산출부는 인공지능 모델의 결과인 제1 대상에 대한 확률 및 제2 대상에 대한 확 률과 객체 이미지 내의 객체가 존재하는 비율에 기초하여 객체를 판별할 수 있다. 결과 산출부의 인공지 능 모델의 결과 데이터 후처리는 도 16 및 도 17을 참조하여 이하에서 설명한다. 데이터베이스부는 시스템이 동작하는데 필요한 각종 데이터 및 프로그램을 저장할 수 있다. 데이터 베이스부는 시스템이 획득하는 정보 및 처리하는 정보 모두를 저장할 수 있다. 예를 들어, 데이터베이스부는 구획 생성부에 의해 생성된 복수의 구획 이미지, 배경 처리부 에 의해 생성된 복수의 객체 이미지, 업 샘플링부에 의해 수행된 업 샘플링된 복수의 객체 이미지를 저장 할 수 있다. 또한 예를 들어, 데이터베이스부는 제로 패딩부에 의해 사이즈가 변경된 객체 이미지, 오버랩 크롭부에 의해 크롭된 이미지, 결과 산출부가 이용하는 확률 및 객체가 존재하는 비율 등을 저장할 수 있다. 데이터베이스부는 데이터를 임시적으로 또는 반영구적으로 저장할 수 있다. 예를 들어, 데이터베이스부 는 하드디스크(HDD: Hard Disk Drive), SSD(Solid State Drive), 플래쉬 메모리(flash memory), 롬(ROM:Read-Only Memory), 램(RAM: Random Access Memory) 또는 클라우드 스토리지(Cloud Storage) 등일 수 있으나, 이에 한정되지 않고 데이터를 저장하기 위한 다양한 모듈로 구현될 수 있다. 도 8은 일 실시예에 따른 텍스처 기반의 영상 데이터 처리 방법의 순서도이다. 도 8을 참조하면, 일 실시예에 따른 텍스처 기반의 영상 데이터 처리 방법은 구획 이미지를 생성하는 단계 (S100), 객체 이미지를 생성하는 단계(S200), 업 샘플링 수행 여부를 판단하는 단계(S300), 업 샘플링을 수행하 는 단계(S400), 이미지를 제1 이미지 그룹 및 제2 이미지 그룹으로 분류하는 단계(S500), 이미지가 제1 이미지 그룹에 포함되는지 여부를 판단하는 단계(S600), 제로 패딩을 수행하는 단계(S700) 및 오버랩 크롭을 수행하는 단계(S800)를 포함할 수 있다. 도 8에는 단계 S100 내지 단계 S800이 순서대로 수행되는 것이 도시되었으나, 이 에 한정되지 않고 각 단계의 순서는 변경될 수 있다. 구획 이미지를 생성하는 단계(S100)는 구획 생성부가 객체의 구획 정보에 기초하여 입력 데이터를 크롭함 으로써 복수의 구획 이미지를 생성하는 단계일 수 있다. 구획 생성부는 텍스처가 상이한 영역을 구분하는 벡터 정보를 포함하는 객체의 구획 정보에 기초하여 객체 중심으로 입력 데이터를 크롭할 수 있다. 객체 이미지를 생성하는 단계(S200)는 구획 생성부가 생성한 복수의 구획 이미지를 이용하여 배경 처리부 가 객체의 구획 정보에 대응되는 영역 이외의 영역의 픽셀 값을 제거함으로써 복수의 객체 이미지를 생성 하는 단계일 수 있다. 단계 S200에서 배경 처리부는 인공지능 모델에 이미지를 입력하기 위해, 객체가 아 닌 부분의 정보를 제거할 수 있다. 업 샘플링 수행 여부를 판단하는 단계(S300)는 배경 처리부가 생성한 복수의 객체 이미지의 속성에 기초 하여 업 샘플링부가 복수의 객체 이미지에 대한 업 샘플링 수행 여부를 결정하는 단계일 수 있다. 업 샘 플링 수행 여부가 긍정(Y)인 경우, 업 샘플링부는 단계 S400을 수행할 수 있다. 업 샘플링 수행 여부가 부정(N)인 경우, 업 샘플링부는 복수의 객체 이미지에 대해 업 샘플링을 수행하지 않고, 과정은 단계 S500으로 넘어간다. 업 샘플링부는 복수의 객체 이미지에 포함된 객체 이미지 내의 객체가 존재하는 비율이 제1 기준값 이하 인지 여부와 객체가 존재하는 비율이 제1 기준값 이하인 이미지의 개수가 제2 기준값 이상인지 여부에 기초하여 업 샘플링 여부를 판단할 수 있다. 업 샘플링을 수행하는 단계(S400)는 업 샘플링부가 복수의 객체 이미지를 사이즈의 정수배로 확대하는 단 계일 수 있다. 업 샘플링부는 인공지능 모델의 열화 방지를 위해, 객체에 대한 정보를 늘리는 리사이징을 수행할 수 있다. 이미지를 제1 이미지 그룹 및 제2 이미지 그룹으로 분류하는 단계(S500)는 이미지의 크기가 인공지능 모델의 입 력 데이터 크기보다 작은지 여부에 기초하여 이미지를 제1 이미지 그룹 및 제2 이미지 그룹으로 분류하는 단계 일 수 있다. 구체적으로, 업 샘플링이 수행된 이미지 또는 업 샘플링이 수행되지 않은 이미지 모두 크기가 인공 지능 모델의 입력 데이터 크기보다 작은 경우, 제1 이미지 그룹으로 분류될 수 있다. 또한, 업 샘플링이 수행된 이미지 또는 업 샘플링이 수행되지 않은 이미지 모두 크기가 인공지능 모델의 입력 데이터 크기보다 같거나 큰 경우 제2 이미지 그룹으로 분류될 수 있다. 이때, 이미지의 크기가 작거나 큰 것을 판단하는 기준은 가로 및 세로의 크기 모두가 입력 데이터의 가로 및 세 로의 크기보다 큰지 여부일 수 있다. 예를 들어, 인공지능 모델의 입력 데이터 크기가 224 X 224이고, 제1 객체 이미지가 312 X 376인 경우, 제1 객체 이미지는 제2 이미지 그룹으로 분류될 수 있다. 또한 예를 들어, 인공지 능 모델의 입력 데이터 크기가 224 X 224이고, 제2 객체 이미지가 224 X 376인 경우, 제2 객체 이미지는 제2 이 미지 그룹으로 분류될 수 있다. 또한 예를 들어, 인공지능 모델의 입력 데이터 크기가 224 X 224이고, 제3 객체 이미지가 180 X 224인 경우, 제 3 객체 이미지는 제1 이미지 그룹으로 분류될 수 있다. 또한 예를 들어, 인공지능 모델의 입력 데이터 크기가 224 X 224이고, 제4 객체 이미지가 156 X 188인 경우, 제4 객체 이미지는 제1 이미지 그룹으로 분류될 수 있다. 이미지가 제1 이미지 그룹에 포함되는지 여부를 판단하는 단계(S600)는 인공지능 모델의 입력 데이터 크기에 맞 추기 위해 제로 패딩 또는 오버랩 크롭을 수행하기 전, 이미지의 크기가 인공지능 모델의 입력 데이터 크기보다 작은지 또는 큰지 여부를 판단하는 단계일 수 있다. 이미지가 인공지능 모델의 입력 데이터 크기보다 작아 제1 이미지 그룹에 포함되는 경우, 제로 패딩이 수행될 수 있다. 또는 이미지가 인공지능 모델의 입력 데이터 크기보다 크거나 같아 제2 이미지 그룹에 포함되는 경우, 오버랩 크롭이 수행될 수 있다. 제로 패딩을 수행하는 단계(S700)는 제로 패딩부가 픽셀 값이 0인 픽셀을 이용하여 제1 이미지 그룹에 포 함된 이미지의 사이즈를 변경하는 단계일 수 있다. 이에 대한 자세한 설명은 도 11 및 도 12를 참조하여 설명한 다. 오버랩 크롭을 수행하는 단계(S800)는 오버랩 크롭부가 이미지의 엣지를 기준으로 제2 이미지 그룹에 포 함된 이미지를 인공지능 모델의 입력 데이터 크기에 맞춰 크롭하는 단계일 수 있다. 이에 대한 자세한 설명은 도 13 내지 도 15를 참조하여 설명한다. 도 9는 구획 이미지 및 객체 이미지의 예시를 설명하기 위한 도면이다. 도 9(a)는 입력 데이터인 항공 영상 데이터의 예시이고, 도 9(b)는 도 9(a)로부터 생성된 구획 이미지의 예시이 고, 도 9(c)는 도 9(b)의 구획 이미지로부터 생성된 객체 이미지의 예시이다. 도 9를 참조하면, 구획 생성부는 입력 데이터로부터 복수의 구획 이미지를 생성할 수 있다. 구체적으로, 구획 생성부는 텍스처 정보를 기반으로 텍스처가 상이한 영역을 구분하는 벡터 정보를 포함하는 객체의 구획 정보에 기초하여 객체 중심으로 입력 데이터를 크롭할 수 있다. 도 9(a)를 참조하면, 입력 데이터는 객체의 구획 정보(10, 20)를 포함할 수 있다. 예를 들어, 객체의 구획 정보 는 농경지인 제1 객체에 대한 경계 정보 및 제2 객체에 대한 경계 정보일 수 있으나, 이에 한정되지 않 는다. 구획 생성부는 제1 객체에 대한 구획 정보에 기초하여 제1 객체를 중심으로 이미지를 크롭 하여 제1 구획 이미지를 생성할 수 있다. 마찬가지로 도 9에는 도시되어 있지 않으나, 구획 생성부 는 제2 객체에 대한 구획 정보에 기초하여 제2 객체를 중심으로 이미지를 크롭하여 제2 구획 이미지를 생성할 수 있다. 도 9(b)를 참조하면, 구획 생성부에 의해 생성된 제1 이미지는 제1 객체를 포함할 수 있다. 도 9(c) 를 참조하면, 배경 처리부는 제1 객체에 대한 구획 정보에 기초하여 객체의 구획 정보에 대응되는 영 역 이외의 영역의 픽셀 값을 제거하여 객체 이미지를 생성할 수 있다. 이때, 객체의 구획 정보에 대응되는 영역은 구획 정보에 포함된 경계 내부의 영역이고, 이외의 영역은 경계 외부의 영역일 수 있 다. 이외의 영역의 픽셀 값은 제거된 상태이므로 0값을 가질 수 있다. 배경 처리부에 의해 생성된 복수의 객체 이미지의 속성을 기초로, 복수의 객체 이미지에 대해 업 샘플링 을 수행할지 여부가 판단될 수 있다. 이때, 객체 이미지의 속성은 복수의 객체 이미지에 대해 객체가 차지하는 비율이 제1 기준값 이하인 객체 이미지의 개수일 수 있다. 또한, 객체 이미지의 속성은 객체가 차지하는 비율이 기준값 이하인 객체 이미지의 개수가 제2 기준값 이상인지 여부를 포함할 수 있다. 도 10은 업 샘플링을 수행한 이미지의 예시를 설명하기 위한 도면이다. 도 10(a)는 크기가 작은 객체를 포함하는 객체 이미지의 예시이고, 도 10(b)는 도 10(a)의 이미지를 업 샘플링 한 결과의 예시이다. 도 10(a)를 참조하면, 객체 이미지는 구름 모양의 객체를 포함할 수 있다. 이때, 객체 이미지의 크기에 비해 객체의 크기가 매우 작을 수 있다. 객체 이미지를 인공지능 모델에 입력하게 된다면, 입 력 데이터에 비해 정보가 담긴 객체의 크기가 너무 작기 때문에, 인공지능 모델의 정확도가 매우 감소하는 등 인공지능 모델의 열화가 발생할 수 있다. 구체적으로, 객체 이미지의 대부분의 영역의 픽셀 값이 0이므 로, 정보량이 적을 수 있다. 따라서, 업 샘플링부는 객체 이미지 및 객체 이미지 외에 복수의 객체 이미지에 포함된 모든 객체 이미지에 대해 업 샘플링을 수행할 수 있다. 도 10(b)를 참조하면, 업 샘플링부는 도 10(a)의 객체 이미지에 대해 사이즈의 정수배로 확대하는 업 샘플링을 수행할 수 있다. 따라서, 도 10(b)의 객체 이미지 크기에 비해 객체의 크기가 차지하는 비율이 높아짐을 알 수 있다. 이는 인공지능 모델에 필요한 정보량이 많아짐을 의미하는 것일 수 있다. 도 11은 일 실시예에 따른 제로 패딩 수행 방법의 순서도이다. 도 11을 참조하면, 일 실시예에 따른 제로 패딩 수행 방법은 이미지의 사이즈와 입력 데이터의 사이즈를 비교하 는 단계(S710), 필요한 픽셀 개수를 산출하는 단계(S720) 및 상하와 좌우에 픽셀을 추가하는 단계(S730)를 포함 할 수 있다. 이미지의 사이즈와 입력 데이터의 사이즈를 비교하는 단계(S710)는 제1 이미지 그룹에 포함된 이미지의 사이즈 와 인공지능 모델의 입력 데이터의 사이즈를 비교하는 단계일 수 있다. 구체적으로, 단계 S710에서 제로 패딩부 는 이미지의 사이즈와 인공지능 모델의 입력 데이터의 사이즈의 가로 길이 및 세로 길이를 각각 판단할 수 있다. 필요한 픽셀 개수를 산출하는 단계(S720)는 이미지의 사이즈와 인공지능 모델의 입력 데이터의 사이즈의 차이를 산출하여 가로 및 세로에 각각 필요한 픽셀 개수를 산출하는 단계일 수 있다. 예를 들어, 이미지의 사이즈가 156 X 188이고, 인공지능 모델의 입력 데이터의 사이즈가 224 X 224인 경우, 제로 패딩부는 가로로 68개 의 픽셀 및 세로로 36개의 픽셀이 필요한 것으로 산출할 수 있다. 상하와 좌우에 픽셀을 추가하는 단계(S730)는 제로 패딩부가 단계 S720에서 산출한 필요한 픽셀의 개수를 이미지의 상하와 좌우에 추가하는 단계일 수 있다. 이때, 제로 패딩부가 추가하는 픽셀은 값이 0인 픽셀 일 수 있다. 위 예시에서, 제로 패딩부는 픽셀 값이 0인 픽셀을 이미지의 좌측 및 우측에 34개를 추가하 여, 이미지의 가로 전체의 길이를 68개 픽셀만큼 늘릴 수 있다. 또한, 제로 패딩부는 픽셀 값이 0인 픽셀 을 이미지의 상측 및 하측에 18개를 추가하여, 이미지의 세로 전체의 길이를 36개 픽셀만큼 늘릴 수 있다. 위와 같이, 제로 패딩부는 이미지의 상측 및 하측에 N개의 픽셀을 추가하고, 좌측 및 우측에 M개의 픽셀 을 추가할 수 있다. 제로 패딩부는 상측과 하측, 좌측과 우측에 균일하게 픽셀을 추가함으로써, 중앙에 객체가 위치하도록 이미지에 대해 제로 패딩을 수행할 수 있다. 도 12는 제로 패딩을 수행한 이미지의 예시를 설명하기 위한 도면이다. 도 12(a)는 입력 데이터인 항공 영상 데이터의 예시를 나타내는 도면이고, 도 12(b)는 도 12(a)로부터 생성된 객체 이미지의 예시를 나타내는 도면이고, 도 12(c)는 도 12(b)로부터 제로 패딩이 수행된 결과의 예시를 나타 내는 도면이다. 도 12(a)의 입력 데이터로부터 객체의 구획 정보에 기초하여 구획 이미지가 생성되고, 구획 이미지로부터 배경 이 제거되어 도 12(b)의 객체 이미지가 생성될 수 있다. 도 12(b)의 객체 이미지의 크기는 156 X 188로 인공지 능 모델의 입력 데이터의 크기인 244 X 244보다 작으므로, 도 12(b)의 객체 이미지는 제1 이미지 그룹으로 분류 될 수 있다. 제로 패딩부는 도 12(b)의 객체 이미지에 대해 제로 패딩을 수행할 수 있다. 구체적으로, 제로 패딩부 는 픽셀 값이 0인 픽셀을 객체 이미지의 좌측 및 우측에 34개를 추가하여, 이미지의 가로 전체의 길이를 68개 픽셀만큼 늘릴 수 있다. 또한, 제로 패딩부는 픽셀 값이 0인 픽셀을 이미지의 상측 및 하측에 18개 를 추가하여, 객체 이미지의 세로 전체의 길이를 36개 픽셀만큼 늘릴 수 있다. 도 12(c)를 참조하면, 제로 패딩 이 수행된 객체 이미지는 결국 크기가 224 X 224이 되어 인공지능 모델의 입력 데이터의 크기와 동일해질 수 있 다. 도 13은 일 실시예에 따른 오버랩 크롭 수행 방법의 순서도이다. 도 13을 참조하면, 일 실시예에 따른 오버랩 크롭 수행 방법은 제1 엣지를 기준으로 크롭하여 제1 엣지 이미지 를 생성하는 단계(S810), 제2 엣지를 기준으로 크롭하여 제2 엣지 이미지를 생성하는 단계(S820), 제3 엣지를 기준으로 크롭하여 제3 엣지 이미지를 생성하는 단계(S830) 및 제4 엣지를 기준으로 크롭하여 제4 엣지 이미지 를 생성하는 단계(S840)를 포함할 수 있다. 도 14 및 도 15를 같이 참조하여 오버랩 크롭 수행 방법을 설명한다. 도 14는 오버랩 크롭을 수행한 이미지의 예시를 설명하기 위한 도면이다. 도 14(a)는 입력 데이터인 항공 영상 데이터의 예시를 나타내는 도면이고, 도 14(b)는 도 14(a)로부터 생성된 객체 이미지를 크롭하는 방법을 설명하기 위한 도면이고, 도 14(c)는 도 14(b)의 객체 이미지가 크롭된 결과의 예시를 나타내는 도면이다. 도 14(a)의 입력 데이터로부터 객체의 구획 정보에 기초하여 구획 이미지가 생성되고, 구획 이미지로부터 배경 이 제거되어 도 14(b)의 객체 이미지가 생성될 수 있다. 도 14(b)의 객체 이미지의 크기는 312 X 376로 인공지 능 모델의 입력 데이터의 크기인 244 X 244보다 크므로, 도 14(b)의 객체 이미지는 제2 이미지 그룹으로 분류될 수 있다. 오버랩 크롭부는 도 14(b)의 객체 이미지에 대해 오버랩 크롭을 수행할 수 있다. 구체적으로, 오버랩 크 롭부는 제1 엣지를 기준으로 객체 이미지를 크롭하여 제1 엣지 이미지를 생성할 수 있다. 이때, 엣지를 기준으로 크롭한다는 것은, 왼쪽 상부 엣지인 제1 엣지가 제1 엣지 이미지의 왼쪽 상부 엣지가 되도록 인공지능 모델의 입력 데이터의 크기를 맞춰 객체 이미지를 크롭한다는 것을 의미할 수 있다. 즉, 이는 객체 이미지의 엣지와 엣지 이미지의 엣지가 대응되도록 크롭한다는 것을 의미할 수 있다. 오버랩 크롭부는 제2 엣지를 기준으로 객체 이미지를 크롭하여 제2 엣지 이미지를 생성하고, 제 3 엣지를 기준으로 객체 이미지를 크롭하여 제3 엣지 이미지를 생성하고, 제4 엣지를 기준으로 객 체 이미지를 크롭하여 제4 엣지 이미지를 생성할 수 있다. 이때, 엣지를 기준으로 크롭된 제1 내지 제4 엣 지 이미지는 서로 적어도 일부가 오버랩될 수 있다. 즉, 제1 내지 제4 엣지 이미지에 적어도 일부 공통되는 부 분이 생길 수 있다. 종래 리사이징의 경우 이미지를 일부러 인공지능 모델의 입력 데이터의 크기에 맞추도록 이미지의 크기를 변경 시켰고, 추가적으로 크롭을 수행하는 경우도 있었다. 그러나, 텍스처 기반의 데이터의 경우 리사이징을 하면 텍 스터 데이터에 포함된 패턴이 왜곡되는 현상이 발생하게 된다. 이에, 본원 발명은 텍스처 기반의 객체에 대한 패턴을 유지할 수 있는 크롭 방식에 대한 기술을 제안한다. 도 15는 오버랩 크롭을 수행한 이미지의 예시를 설명하기 위한 도면이다. 도 15(a)는 객체 이미지를 크롭하는 방법을 설명하기 위한 도면이고, 도 15(b)는 도 15(a)의 객체 이미지가 크롭된 결과의 예시를 나타내는 도면이 다. 오버랩 크롭부는 도 15(a)의 객체 이미지에 대해 오버랩 크롭을 수행할 수 있다. 구체적으로, 오버랩 크 롭부는 객체 이미지의 제1 엣지, 제2 엣지 및 제3 엣지를 기준으로 객체 이미지를 크롭하여 제1 엣지 이미지, 제2 엣지 이미지 및 제3 엣지 이미지를 생성할 수 있다. 이때, 객체 이미지의 엣지는 객체 이미지의 모서리뿐만 아니라 객체 이미지의 경계를 포함할 수 있다. 구체적으로, 엣지는 객체 이미 지의 모서리, 상하부 경계 및 좌우 경계를 포함할 수 있다. 오버랩 크롭부는 객체 이미지의 엣지에 기초하여 오버랩 크롭을 수행함으로써 복수의 엣지 이미지를 생성 할 수 있다. 이때, 복수의 엣지 이미지 중 적어도 일부는 서로 오버랩될 수 있다. 구체적으로, 복수의 엣지 이 미지 중 인접한 엣지 이미지들은 적어도 일부가 서로 오버랩될 수 있다. 또한, 오버랩 크롭부는 객체 이미지의 크기와 인공지능 모델의 입력 데이터 사이즈를 비교하여, 크롭의 횟수를 설정할 수 있다. 구체적으로, 오버랩 크롭부는 가로 및 세로에 대해 객체 이미지의 크기가 입력 데이터 사이즈의 A 정수배를 초과하며 A+1 정수배 이하인 경우, 오버랩 크롭부는 가로 및 세로에 대해 A+1개의 엣지 이미지를 생성하도록 크롭을 수행할 수 있다. 예를 들어, 입력 데이터 사이즈가 100 X 100인 경우를 가정한다. 객체 이미지의 크기가 250 X 340인 경우, 오버 랩 크롭부는 가로 및 세로 각각에 대하여 크롭의 횟수를 설정할 수 있다. 구체적으로, 가로의 크기가 250 으로 입력 데이터의 가로 사이즈인 100보다 2배 초과하고 3배 이하이므로, 오버랩 크롭부는 가로에 대해 3부분의 엣지 이미지를 형성하도록 가로에 대해 크롭을 수행할 수 있다. 또한, 세로의 크기가 340으로 입력 데 이터의 세로 사이즈인 100보다 3배 초과하고 4배 이하이므로, 오버랩 크롭부는 세로에 대해 4부분의 엣지 이미지를 형성하도록 세로에 대해 크롭을 수행할 수 있다. 위 예시에 따라, 오버랩 크롭부는 가로 2번 세로 3번의 크롭을 수행하여 총 12개의 엣지 이미지를 형성할 수 있다. 이때, 오버랩 크롭부는 가로 및 세로 각각에 대해 크롭을 수행할 때, 크롭 이후 인접한 이미지 들의 오버랩 영역이 모두 동일하도록 크롭 위치를 설정할 수 있다. 위 예시를 참조하면, 가로 250에 대해 오버랩 크롭부는 크롭을 수행하여 0 내지 100의 가로 좌표를 갖는 제1 이미지, 75 내지 175의 가로 좌표를 갖는 제2 이미지 및 150 내지 250의 가로 좌표를 갖는 제3 이미지를 생성할 수 있다. 이때, 제1 이미지와 제2 이미지가 오버랩되는 부분 및 제2 이미지와 제3 이미지가 오버랩되는 부 분은 모두 25로 동일할 수 있다. 또한, 세로 340에 대해 오버랩 크롭부는 크롭을 수행하여 0 내지 100의 세로 좌표를 갖는 제4 이미지, 80 내지 180의 세로 좌표를 갖는 제5 이미지, 160 내지 260의 세로 좌표를 갖는 제6 이미지 및 240 내지 340의 세 로 좌표를 갖는 제7 이미지를 생성할 수 있다. 이때, 제4 이미지와 제5 이미지가 오버랩되는 부분, 제5 이미지 와 제6 이미지가 오버랩되는 부분 및 제6 이미지와 제7 이미지가 오버랩되는 부분은 모두 20으로 동일할 수 있 다. 도 16은 일 실시예에 따른 이미지 내의 객체를 판별하는 방법의 순서도이다. 구체적으로, 도 16은 제로 패딩되 었거나 오버랩 크롭된 이미지를 인공지능 모델에 입력한 이후, 인공지능 모델의 결과 후처리에 대한 방법의 순 서도를 나타낸다. 도 16을 참조하면, 일 실시예에 따른 이미지 내의 객체를 판별하는 방법은 제1 엣지 이미지를 이용하여 제1 확 률 및 제2 확률을 획득하는 단계(S910), 제2 엣지 이미지를 이용하여 제3 확률 및 제4 확률을 획득하는 단계 (S920), 제1 엣지 이미지를 이용하여 제1 비율을 획득하는 단계(S930), 제2 엣지 이미지를 이용하여 제2 비율을 획득하는 단계(S940), 제1 가중치 확률 내지 제4 가중치 확률을 획득하는 단계(S950), 제1 가중합 및 제2 가중 합을 산출하는 단계(S960) 및 객체가 제1 대상인지 제2 대상인지 여부를 판단하는 단계(S970)를 포함할 수 있다. 이들은 모두 결과 산출부에 의해 수행될 수 있다. 도 16은 단계 S910 내지 단계 S970이 순서대로 수행되는 것을 도시하였으나, 이에 한정되지 않고 각 단계의 순 서는 변경될 수 있다. 예를 들어, 단계 S910 및 단계 S920은 동시에 수행될 수 있다. 또는, 단계 S910, S920, S930 및 S940은 동시에 수행될 수 있다. 또는 단계 S910 및 단계 S920보다 단계 S930 및 단계 S940이 먼저 수행 될 수도 있다. 도 17을 같이 참조하여 오버랩 크롭 수행 방법을 설명한다. 도 17은 이미지 내의 객체 판별 방법의 예시를 설명하기 위한 도면이다. 도 17을 같이 참조하면, 제1 엣지 이미지를 이용하여 제1 확률 및 제2 확률을 획득하는 단계(S910)는 결과 산출 부가 제1 엣지 이미지를 인공지능 모델에 입력하여 제1 대상에 대한 제1 확률 및 제2 대상에 대한 제2 확률을 획득하는 단계일 수 있다. 도 17에서는 제1 대상을 논, 제2 대상을 밭으로 하는 예시를 도시하였으 나, 대상은 이에 한정되지 않는다. 구체적으로, 대상은 이미지에 의해 객체가 분류될 수 있는 항목을 의미하는 것일 수 있다. 제2 엣지 이미지를 이용하여 제3 확률 및 제4 확률을 획득하는 단계(S920)는 결과 산출부가 제2 엣지 이 미지를 인공지능 모델에 입력하여 제1 대상에 대한 제3 확률 및 제2 대상에 대한 제4 확률을 획득하는 단계일 수 있다. 또한, 결과 산출부는 제3 엣지 이미지 및 제4 엣지 이미지를 인공지능 모델에 입력하 여 각각 제1 대상에 대한 확률 및 제2 대상에 대한 확률을 획득할 수 있다. 제1 엣지 이미지를 이용하여 제1 비율을 획득하는 단계(S930)는 결과 산출부가 제1 엣지 이미지 내 에 객체가 존재하는 비율인 제1 비율을 획득하는 단계일 수 있다. 이때, 결과 산출부는 제1 엣지 이미지 에 존재하는 픽셀의 개수 대비 픽셀 값이 0이 아닌 픽셀의 개수를 이용하여 제1 비율을 산출할 수 있다. 제2 엣지 이미지를 이용하여 제2 비율을 획득하는 단계(S940)는 결과 산출부가 제2 엣지 이미지 내 에 객체가 존재하는 비율인 제2 비율을 획득하는 단계일 수 있다. 이때, 결과 산출부는 제2 엣지 이미지 에 존재하는 픽셀의 개수 대비 픽셀 값이 0이 아닌 픽셀의 개수를 이용하여 제2 비율을 산출할 수 있다. 마찬가지로 결과 산출부는 제3 엣지 이미지 및 제4 엣지 이미지를 이용하여 각 이미지에 객체 가 존재하는 비율을 산출할 수 있다. 제1 가중치 확률 내지 제4 가중치 확률을 획득하는 단계(S950)는 결과 산출부가 제1 내지 제4 확률 및 제 1 비율 내지 제2 비율을 이용하여 가중치 확률을 산출하는 단계일 수 있다. 구체적으로, 결과 산출부는 제1 엣지 이미지 내의 객체 존재 비율인 제1 비율에 제1 엣지 이미지를 이용하여 산출된 제1 대상에 대한 제1 확률을 곱하여 제1 가중치 확률을 획득할 수 있다. 마찬가지로, 결과 산출부는 제1 비율에 제2확률을 곱하여 제2 가중치 확률을 획득할 수 있다. 제1 가중치 확률 및 제2 가중치 확률은 제1 엣지 이미지 의 객체 존재 비율(제1 비율)을 이용하여 산출된 제1 대상에 대한 가중치 확률 및 제2 대상에 대한 가중치 확률을 의미할 수 있다. 또한, 결과 산출부는 제2 비율에 제3 확률을 곱하여 제3 가중치 확률을 획득하고, 제2 비율에 제4 확률을 곱하여 제4 가중치 확률을 획득할 수 있다. 제3 가중치 확률 및 제4 가중치 확률은 제2 엣지 이미지의 객 체 존재 비율(제2 비율)을 이용하여 산출된 제1 대상에 대한 가중치 확률 및 제2 대상에 대한 가중치 확률을 의 미할 수 있다. 마찬가지로 결과 산출부는 제3 엣지 이미지 및 제4 엣지 이미지를 이용하여 이 에 대한 가중치 확률을 각각 구할 수 있다. 제1 가중합 및 제2 가중합을 산출하는 단계(S960)는 결과 산출부가 단계 S950에서 획득한 가중치 확률을 각 대상별로 합하는 단계일 수 있다. 구체적으로, 결과 산출부는 제1 대상에 대한 가중치 확률인 제1 가 중치 확률 및 제3 가중치 확률을 더할 수 있다. 또한, 결과 산출부는 제3 엣지 이미지 및 제4 엣지 이미지로부터 산출된 제1 대상에 대한 가중치 확률을 더할 수 있다. 결과 산출부는 결과적으로 제1 대상에 대한 최종 확률인 제1 가중합을 산출할 수 있다. 또한, 결과 산출부는 제2 대상에 대한 가중치 확률인 제2 가중치 확률 및 제4 가중치 확률을 더할 수 있 다. 또한, 결과 산출부는 제3 엣지 이미지 및 제4 엣지 이미지로부터 산출된 제2 대상에 대한 가중치 확률을 더할 수 있다. 결과 산출부는 결과적으로 제2 대상에 대한 최종 확률인 제2 가중합을 산출 할 수 있다. 객체가 제1 대상인지 제2 대상인지 여부를 판단하는 단계(S970)는 결과 산출부가 단계 S960에서 산출된 제1 가중합 및 제2 가중합 중 더 큰 값을 이용하여 객체를 판단하는 단계일 수 있다. 도 17의 예시를 참조하면, 논에 대한 가중합이 78%이고, 밭에 대한 가중합이 8%이므로, 결과 산출부는 객체 이미지 내의 객체가 논 인 것으로 판단할 수 있다. 위와 같이, 결과 산출부는 오버랩 크롭된 객체 이미지들 중 객체가 차지하는 비율과 인공지능 모델의 분 류 결과를 이용하여 객체 이미지 내의 객체를 최종적으로 분류할 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD- ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다"}
{"patent_id": "10-2022-0188127", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17"}
{"patent_id": "10-2022-0188127", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 텍스처 기반의 데이터를 설명하기 위한 도면이다. 도 2 내지 도 6은 텍스처 기반의 데이터 예시를 설명하기 위한 도면이다. 도 7은 일 실시예에 따른 텍스처 기반의 영상 데이터 처리 시스템의 블록도이다. 도 8은 일 실시예에 따른 텍스처 기반의 영상 데이터 처리 방법의 순서도이다. 도 9는 구획 이미지 및 객체 이미지의 예시를 설명하기 위한 도면이다. 도 10은 업 샘플링을 수행한 이미지의 예시를 설명하기 위한 도면이다. 도 11은 일 실시예에 따른 제로 패딩 수행 방법의 순서도이다. 도 12는 제로 패딩을 수행한 이미지의 예시를 설명하기 위한 도면이다. 도 13은 일 실시예에 따른 오버랩 크롭 수행 방법의 순서도이다. 도 14 및 도 15는 일 실시예에 따른 오버랩 크롭을 수행한 이미지의 예시를 설명하기 위한 도면이다. 도 16은 일 실시예에 따른 이미지 내의 객체를 판별하는 방법의 순서도이다. 도 17은 이미지 내의 객체 판별 방법의 예시를 설명하기 위한 도면이다."}
