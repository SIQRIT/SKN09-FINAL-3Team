{"patent_id": "10-2021-0108177", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0026137", "출원번호": "10-2021-0108177", "발명의 명칭": "분산 학습용 서버 및 분산 학습 방법", "출원인": "삼성전자주식회사", "발명자": "김태정"}}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "서버가 분산 학습을 수행하는 방법에 있어서,복수의 노드들 중에서 분산 학습을 수행할 작업자 노드들을 선택하여 컴퓨터 클러스터를 구축하며, 상기 컴퓨터클러스터 내 노드들은, 마스터 노드인 상기 서버와 상기 작업자 노드들을 포함하는, 단계;데이터 서브셋들의 각각이 상기 컴퓨터 클러스터 내 노드들의 각각에 대응하도록 훈련 데이터셋을분할함으로써, 상기 데이터 서브셋들을 결정하는 단계; 상기 데이터 서브셋들의 각각에 기초하여 상기 컴퓨터 클러스터 내 노드들의 각각에 저장된 각 인공지능 모델을훈련시킴으로써, 상기 컴퓨터 클러스터 내 노드들로부터 훈련 결과들을 획득하는 단계;상기 훈련 결과들에 기초하여 상기 서버에 저장된 인공지능 모델의 가중치들을 업데이트하는 단계;상기 컴퓨터 클러스터 내 노드들의 각각에 대하여, 상기 컴퓨터 클러스터 내 노드들의 각각이 훈련을 수행하는데 소요된 연산 시간을 식별하는 단계; 및상기 컴퓨터 클러스터 내 노드들 각각의 연산 시간에 기초하여, 상기 데이터 서브셋들의 각각에 포함되는 데이터 수를 조정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 컴퓨터 클러스터 내 노드들로부터 훈련 결과들을 획득하는 단계는,상기 작업자 노드들 중에서 제1 작업자 노드가 상기 제1 작업자 노드에 대응되는 제1 데이터 서브셋을 이용하여상기 제1 작업자 노드 내 저장된 인공지능 모델을 훈련시킴으로써 생성된 제1 훈련 결과를, 상기 제1 작업자 노드로부터 획득하는 단계; 및상기 작업자 노드들 중에서 제2 작업자 노드가 상기 제2 작업자 노드에 대응되는 제2 데이터 서브셋을 이용하여상기 제2 작업자 노드 내 저장된 인공지능 모델을 훈련시킴으로써 생성된 제2 훈련 결과를, 상기 제2 작업자 노드로부터 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 방법은,상기 컴퓨터 클러스터 내 노드들의 각각을 이용하여 상기 컴퓨터 클러스터 내 노드들의 각각에 저장된 각 인공지능 모델의 다음 훈련을 수행하되, 상기 컴퓨터 클러스터 내 노드들은, 상기 데이터 수가 조정된 데이터 서브셋들을 이용하여 상기 다음 훈련을 수행하는 것인, 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 컴퓨터 클러스터 내 노드들이 상기 다음 훈련을 수행하는 경우, 상기 컴퓨터 클러스터 내 노드들의 각각에대하여 설정된 배치 사이즈는 유지되는 것인, 방법. 공개특허 10-2023-0026137-3-청구항 5 제1항에 있어서,상기 컴퓨터 클러스터 내 노드들의 평균 연산 시간을 계산하는 단계를 더 포함하고,상기 데이터 서브셋들의 각각에 포함되는 데이터 수를 조정하는 단계는,상기 컴퓨터 클러스터 내 노드들의 평균 연산 시간을 상기 컴퓨터 클러스터 내 노드들 각각의 각 연산 시간과비교하는 단계; 및상기 비교 결과에 기초하여, 상기 데이터 서브셋들의 각각에 포함되는 데이터 수를 조정하는 단계를 포함하는,방법."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 비교 결과에 기초하여, 상기 컴퓨터 클러스터 내 노드들 각각에 대응되는 데이터 서브셋들의 각각에 포함되는 데이터 수를 조정하는 단계는,상기 비교 결과가 임계값 이상인 경우, 상기 데이터 서브셋들의 각각에 포함되는 데이터 수를 조정하는 단계를포함하는, 방법."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서,상기 데이터 서브셋들의 각각에 포함되는 데이터 수를 조정하는 단계는,상기 평균 연산 시간보다 연산 시간이 긴 노드에 대응되는 데이터 서브셋의 일부 데이터를 상기 평균 연산 시간보다 연산 시간이 짧은 노드에 대응되는 데이터 서브셋에 포함되도록 조정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 데이터 서브셋들을 결정하는 단계는,상기 마스터 노드에 대응되는 데이터 서브셋의 데이터 수가 상기 작업자 노드들에 대응되는 데이터 서브셋들 각각의 데이터 수보다 작도록 상기 훈련 데이터셋을 분할하는 것인, 방법."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 데이터 서브셋들의 각각에 포함되는 데이터 수를 조정하는 단계는,상기 컴퓨터 클러스터 내 노드들 중에서 연산 시간이 가장 긴 노드에 대응되는 데이터 서브셋의 일부 데이터를상기 컴퓨터 클러스터 내 다른 노드들에 대응되는 데이터 서브셋들에 포함되도록 조정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2023-0026137-4-제1항에 있어서,상기 컴퓨터 클러스터 내 노드들 각각의 연산 시간에 기초하여, 상기 컴퓨터 클러스터 내 노드들 중에서 하나이상의 작업자 노드를 선택하는 단계; 및상기 선택된 하나 이상의 작업자 노드를 상기 컴퓨터 클러스터로부터 제거하고, 하나 이상의 다른 노드를 작업자 노드로써 상기 컴퓨터 클러스터에 편입시키는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "분산 학습을 수행하는 서버에 있어서,통신 인터페이스;하나 이상의 명령어들(instructions)을 저장하는 메모리; 및상기 메모리에 저장된 하나 이상의 명령어들을 실행하는 적어도 하나의 프로세서를 포함하며,상기 적어도 하나의 프로세서는,복수의 노드들 중에서 분산 학습을 수행할 작업자 노드들을 선택하여 컴퓨터 클러스터를 구축하되, 상기 컴퓨터클러스터 내 노드들은, 마스터 노드인 상기 서버와 상기 작업자 노드들을 포함하고,데이터 서브셋들의 각각이 상기 컴퓨터 클러스터 내 노드들의 각각에 대응하도록 훈련 데이터셋을분할함으로써, 상기 데이터 서브셋들을 결정하고,상기 데이터 서브셋들의 각각에 기초하여 상기 컴퓨터 클러스터 내 노드들의 각각에 저장된 각 인공지능 모델을훈련시킴으로써, 상기 컴퓨터 클러스터 내 노드들로부터 훈련 결과들을 획득하고,상기 훈련 결과들에 기초하여 상기 서버에 저장된 인공지능 모델의 가중치들을 업데이트하고,상기 컴퓨터 클러스터 내 노드들의 각각에 대하여, 상기 컴퓨터 클러스터 내 노드들의 각각이 훈련을 수행하는데 소요된 연산 시간을 식별하고,상기 컴퓨터 클러스터 내 노드들 각각의 연산 시간에 기초하여, 상기 데이터 서브셋들의 각각에 포함되는 데이터 수를 조정하는, 서버."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는,상기 작업자 노드들 중에서 제1 작업자 노드가 상기 제1 작업자 노드에 대응되는 제1 데이터 서브셋을 이용하여상기 제1 작업자 노드 내 저장된 인공지능 모델을 훈련시킴으로써 생성된 제1 훈련 결과를, 상기 제1 작업자 노드로부터 획득하고,상기 작업자 노드들 중에서 제2 작업자 노드가 상기 제2 작업자 노드에 대응되는 제2 데이터 서브셋을 이용하여상기 제2 작업자 노드 내 저장된 인공지능 모델을 훈련시킴으로써 생성된 제2 훈련 결과를, 상기 제2 작업자 노드로부터 획득하는, 서버."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는,상기 컴퓨터 클러스터 내 노드들의 각각을 이용하여 상기 컴퓨터 클러스터 내 노드들의 각각에 저장된 각 인공지능 모델의 다음 훈련을 수행하되, 상기 컴퓨터 클러스터 내 노드들은, 상기 데이터 수가 조정된 데이터 서브공개특허 10-2023-0026137-5-셋들을 이용하여 상기 다음 훈련을 수행하는 것인, 서버."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 컴퓨터 클러스터 내 노드들이 상기 다음 훈련을 수행하는 경우, 상기 컴퓨터 클러스터 내 노드들의 각각에대하여 설정된 배치 사이즈는 유지되는 것인, 서버."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는,상기 컴퓨터 클러스터 내 노드들의 평균 연산 시간을 계산하고,상기 컴퓨터 클러스터 내 노드들의 평균 연산 시간을 상기 컴퓨터 클러스터 내 노드들 각각의 각 연산 시간과비교하고,상기 비교 결과에 기초하여, 상기 데이터 서브셋들의 각각에 포함되는 데이터 수를 조정하는, 서버."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 적어도 하나의 프로세서는,상기 비교 결과가 임계값 이상인 경우, 상기 데이터 서브셋들의 각각에 포함되는 데이터 수를 조정하는, 서버."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,상기 적어도 하나의 프로세서는,상기 평균 연산 시간보다 연산 시간이 긴 노드에 대응되는 데이터 서브셋의 일부 데이터를 상기 평균 연산 시간보다 연산 시간이 짧은 노드에 대응되는 데이터 서브셋에 포함되도록 조정하는, 서버."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는,상기 마스터 노드에 대응되는 데이터 서브셋의 데이터 수가 상기 작업자 노드들에 대응되는 데이터 서브셋들 각각의 데이터 수보다 작도록 상기 훈련 데이터셋을 분할하는, 서버."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는,상기 컴퓨터 클러스터 내 노드들 중에서 연산 시간이 가장 긴 노드에 대응되는 데이터 서브셋의 일부 데이터를공개특허 10-2023-0026137-6-상기 컴퓨터 클러스터 내 다른 노드들에 대응되는 데이터 서브셋들에 포함되도록 조정하는, 서버."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는,상기 컴퓨터 클러스터 내 노드들 각각의 연산 시간에 기초하여, 상기 컴퓨터 클러스터 내 노드들 중에서 하나이상의 작업자 노드를 선택하고,상기 선택된 하나 이상의 작업자 노드를 상기 컴퓨터 클러스터로부터 제거하고, 하나 이상의 다른 노드를 작업자 노드로써 상기 컴퓨터 클러스터에 편입시키는, 서버."}
{"patent_id": "10-2021-0108177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2021-0108177", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "복수의 노드들 중에서 분산 학습을 수행할 작업자 노드들을 선택하여 컴퓨터 클러스터를 구축하며, 상기 컴퓨터 클러스터 내 노드들은, 마스터 노드인 상기 서버와 상기 작업자 노드들을 포함하는, 단계; 데이터 서브셋들의 각 각이 상기 컴퓨터 클러스터 내 노드들의 각각에 대응하도록 훈련 데이터셋을 분할함으로써, 상기 데이터 서브셋 (뒷면에 계속)"}
{"patent_id": "10-2021-0108177", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "컴퓨터 클러스터 내 복수의 노드들을 이용하여 분산 학습을 수행하는, 분산 학습용 서버 및 분산 학습 방법이 제공된다."}
{"patent_id": "10-2021-0108177", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 모델을 훈련시키는 방법으로써, 컴퓨터 클러스터를 이용하여 인공지능 모델을 분산 컴퓨팅을 통해 훈 련시키는, 분산 학습이 활용되고 있다. 컴퓨터 클러스터를 이용하여 분산 학습을 수행하는 경우, 컴퓨터 클러스 터의 마스터 노드는 각각의 노드들로부터 훈련 결과를 취합하여 인공지능 모델을 훈련시킬 수 있다. 그러나 클 러스터 내 포함되는 노드들의 컴퓨팅 성능의 차이 또는, 네트워크 속도의 차이 등으로 인하여, 컴퓨터 클러스터 내 일부 노드로부터 처리된 연산 결과의 획득이 지연되면, 전체 분산 학습의 과정에 지연이 발생할 수 있다. 컴퓨터 클러스터를 이용하여 분산 학습을 수행하는 방법에 있어서, 컴퓨터 클러스터 내 노드들의 연산 시간들을 조절함으로써, 분산 학습 속도를 개선하는 방법을 제시하고자 한다."}
{"patent_id": "10-2021-0108177", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시된 실시예들은, 전술한 문제를 해결하기 위한 것으로써, 컴퓨터 클러스터 내 복수의 노드들을 이용하여 분 산 학습을 수행하는 분산 학습용 서버, 및 분산 학습 방법을 제공하기 위한 것이다."}
{"patent_id": "10-2021-0108177", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 서버가 분산 학습을 수행하는 방법에 있어서, 복수의 노드들 중에서 분산 학습을 수행할 작업자 노드들을 선택하여 컴퓨터 클러스터를 구축하 며, 상기 컴퓨터 클러스터 내 노드들은, 마스터 노드인 상기 서버와 상기 작업자 노드들을 포함하는, 단계; 데 이터 서브셋들의 각각이 상기 컴퓨터 클러스터 내 노드들의 각각에 대응하도록 훈련 데이터셋을 분할함으로써, 상기 데이터 서브셋들을 결정하는 단계; 상기 데이터 서브셋들의 각각에 기초하여 상기 컴퓨터 클러스터 내 노 드들의 각각에 저장된 각 인공지능 모델을 훈련시킴으로써, 상기 컴퓨터 클러스터 내 노드들로부터 훈련 결과들 을 획득하는 단계; 상기 훈련 결과들에 기초하여 상기 서버에 저장된 인공지능 모델의 가중치들을 업데이트하는 단계; 상기 컴퓨터 클러스터 내 노드들의 각각에 대하여, 상기 컴퓨터 클러스터 내 노드들의 각각이 훈련을 수행하는데 소요된 연산 시간을 식별하는 단계; 및 상기 컴퓨터 클러스터 내 노드들 각각의 연산 시간에 기초하여, 상기 데이터 서브셋들의 각각에 포함되는 데이터 수를 조정하는 단계를 포함하는, 방법을 제공할 수 있다. 또한, 본 개시의 제2 측면은, 분산 학습을 수행하는 서버에 있어서, 통신 인터페이스; 하나 이상의 명령어들 (instructions)을 저장하는 메모리; 및 상기 메모리에 저장된 하나 이상의 명령어들을 실행하는 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는, 복수의 노드들 중에서 분산 학습을 수행할 작업자 노드 들을 선택하여 컴퓨터 클러스터를 구축하되, 상기 컴퓨터 클러스터 내 노드들은, 마스터 노드인 상기 서버와 상 기 작업자 노드들을 포함하고, 데이터 서브셋들의 각각이 상기 컴퓨터 클러스터 내 노드들의 각각에 대응하도록 훈련 데이터셋을 분할함으로써, 상기 데이터 서브셋들을 결정하고, 상기 데이터 서브셋들의 각각에 기초하여 상 기 컴퓨터 클러스터 내 노드들의 각각에 저장된 각 인공지능 모델을 훈련시킴으로써, 상기 컴퓨터 클러스터 내 노드들로부터 훈련 결과들을 획득하고, 상기 훈련 결과들에 기초하여 상기 서버에 저장된 인공지능 모델의 가중 치들을 업데이트하고, 상기 컴퓨터 클러스터 내 노드들의 각각에 대하여, 상기 컴퓨터 클러스터 내 노드들의 각 각이 훈련을 수행하는데 소요된 연산 시간을 식별하고, 상기 컴퓨터 클러스터 내 노드들 각각의 연산 시간에 기 초하여, 상기 데이터 서브셋들의 각각에 포함되는 데이터 수를 조정하는, 서버를 제공할 수 있다. 또한, 본 개시의 제3 측면은, 제1 측면의 방법을 수행하도록 하는 프로그램이 저장된 기록매체를 제공할 수 있 다."}
{"patent_id": "10-2021-0108177", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 발명에 대해 구체적으로 설명하기로 한다. 본 발명에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 또한, 본 명세서에서 사용되는 '제1' 또는 '제2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만 사용된다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소 프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 일 실시예에 따른 서버를 마스터노드로하는 컴퓨터 클러스터를 설명하기 위한 도면이다. 개시된 실시예에서, 컴퓨터 클러스터는 여러 대의 컴퓨터들이 연결되어 하나의 시스템처럼 동작하는, 서 버 노드(이하, 노드)들의 집합을 말한다. 컴퓨터 클러스터는, 마스터 노드인 서버와 프로세싱 자원 을 제공하는 작업자 노드들로 구성된다. 일 실시예에 따른 서버는, 마스터노드로써 각각의 노드 작업자 노드들에 데이터를 분배하고, 데이터 처리량을 관리할 수 있다. 서버는 서버 및 컴퓨터 클러스터 내 작업자 노드들을 이용하여 서버 내 저장된 인공지능 모델(10 4)의 분산 학습을 수행할 수 있다. 서버는 훈련 데이터셋에 기초하여 인공지능 모델을 훈련시 킬 수 있다. 서버는 데이터 병렬화(data parallelism)의 방식을 이용하여 분산 학습을 수행할 수 있다. 일 실시예에서, 컴퓨터 클러스터는 마스터 노드인 서버, 작업자 노드 1, 작업자 노드 2로 구성될 수 있다. 서버는 인공지능 모델의 분산 학습을 수행하기 위하여, 인공지능 모델 복사하 여, 복제 인공지능 모델을 생성할 수 있다. 예를 들어, 서버는 인공지능 모델을 복사하여, 복제 인 공지능 모델 1을 작업자 노드 1에 제공하고, 복제 인공지능 모델 2를 작업자 노드 2에 제 공할 수 있다. 일 실시예에서, 서버는 분산 학습을 수행하기 위해 훈련 데이터셋을 분할할 수 있다. 예를 들어, 서 버는 훈련 데이터셋을 데이터 서브셋 0, 데이터 서브셋 1, 데이터 서브셋 2로 분할 할 수 있다. 서버는 데이터 서브셋 1을 작업자 노드 1에 제공하고, 데이터 서브셋 2를 작 업자 노드 2에 제공할 수 있다. 데이터 서브셋 0은 서버가 서버 내 저장된 인공지능 모델을 훈 련시키는 데 이용될 수 있다. 일 실시예에서, 서버는 훈련 코드를 실행함으로써, 서버 작업자 노드 1 및 작업자 노드 2 각각에서 독립적으로 노드 내 저장된 인공지능 모델이 훈련되도록 할 수 있다. 예를 들어, 서버는 데이터 서브셋 0에 기초하여 인공지능 모델을 훈련시키고, 작업자 노드 1은 데이터 서브셋 1에 기초하여 복제 인공지능 모델 1을 훈련시키고, 작업자 노드 2는 데이터 서브셋 2에 기 초하여 복제 인공지능 모델 2를 훈련시킬 수 있다.서버는 서버의 훈련 결과 및 작업자 노드 1 및 작업자 노드 2의 훈련 결과들을 획득하여, 서버에 저장된 인공지능 모델의 가중치들을 업데이트 할 수 있다. 또한, 서버는 업 데이트 된 인공지능 모델과 복제 인공지능 모델 1 및 복제 인공지능 모델 2을 동기화하여, 복제 인공지능 모델 1 및 복제 인공지능 모델 2를 업데이트할 수 있다. 도 2는 본 개시의 일 실시예에 따른 서버가 컴퓨터 클러스터를 구축하여 분산 학습을 수행하는 방법을 설명하기 위한 흐름도이다. 단계 S210에서, 일 실시예에 따른 서버는 복수의 노드들 중에서 분산 학습을 수행할 작업자 노드들을 선 택하여 컴퓨터 클러스터를 구축할 수 있다. 서버는 후술하는 실시예들에 따른 데이터 병렬화(data parallelism)의 방식으로, 인공지능 모델의 분산 학습을 수행할 수 있다. 일 실시예에서, 서버는 복수의 노드들 중에서, 분산 학습에 이용 가능한 노드들을 식별할 수 있다. 이용 가능한 노드는, 다른 작업을 수행 중이지 않은 유휴 노드이거나, 분산 학습을 수행할 수 있는 여유 컴퓨팅 자원 이 있는 노드일 수 있다. 서버는 이용 가능한 노드들 중에서, 분산 학습을 수행할 작업자 노드들을 선택 하여 컴퓨터 클러스터를 구축할 수 있다. 예를 들어, 서버는 이용 가능한 노드들 모두를 선택하여, 컴퓨 터 클러스터를 구축할 수 있다. 또는, 서버는 이용 가능한 노드들 중 일부를 선택하여, 컴퓨터 클러스터 를 구축할 수 있다. 일 실시예에서, 서버는 컴퓨터 클러스터의 마스터 노드로 동작한다. 서버는 컴퓨터 클러스터 내 포 함되는 다른 작업자 노드들을 제어하거나, 컴퓨터 클러스터 내 포함되는 다른 작업자 노드들로 작업 명령을 전 달할 수 있다. 단계 S220에서, 일 실시예에 따른 서버는 데이터 서브셋들의 각각이 컴퓨터 클러스터 내 노드들의 각각에 대응하도록 훈련 데이터셋을 분할함으로써, 데이터 서브셋들을 결정할 수 있다. 일 실시예에서, 서버는 컴퓨터 클러스터 내 노드 수에 기초하여, 데이터 서브셋들을 결정할 수 있다. 서 버는 마스터 노드 및 작업자 노드들의 수에 기초하여, 훈련 데이터셋을 분할하여 복수의 데이터 서브셋들 을 결정할 수 있다. 이 경우, 하나의 데이터 서브셋이 하나의 노드에 각각 대응될 수 있다. 서버는 훈련 데이터셋 내 훈련 데이터들을 인덱싱하고, 인덱스 번호에 기초하여 데이터 서브셋들이 구별 되도록 함으로써 데이터 서브셋들을 결정할 수 있다. 예를 들어, 제1 데이터 서브셋에는 인덱스 번호 1 내지 25 의 훈련 데이터가 포함되고, 제2 데이터 서브셋에는 인덱스 번호 26 내지 50의 훈련 데이터가 포함될 수 있다. 동일한 인덱스 번호를 갖는 데이터는 복수개일 수 있다. 구체적으로, 동일한 인덱스 번호를 갖는 데이터가 복수 개라 함은, 서버가 배치(batch) 사이즈를 기준으로 복수의 훈련 데이터들을 동일한 인덱스 번호로 인덱싱 하는 것을 말한다. 서버는, 노드가 인공지능 모델을 훈련시킬 때 입력되는 단위인, 데이터들의 그룹인 배 치(batch)를 기준으로, 복수의 훈련 데이터들을 동일한 인덱스 번호로 인덱싱할 수 있다. 예를 들어, 배치 사이 즈가 10인 경우, 서버는 훈련 데이터셋 내 훈련 데이터 10개를 인덱스 번호 1로 인덱싱하고, 훈련 데이터 셋 내 다른 훈련 데이터 10개를 인덱스 번호 2로 인덱싱할 수 있다. 전술한 예시와 같이, 제1 데이터 서브셋에는 인덱스 번호 1 내지 25의 훈련 데이터가 포함되고, 각각의 인덱스 번호마다 10개의 훈련 데이터가 있으므로, 제1 데이터 서브셋에는 총 250개의 훈련 데이터가 포함될 수 있다. 단계 S230에서, 일 실시예에 따른 서버는 데이터 서브셋들의 각각에 기초하여 컴퓨터 클러스터 내 노드들 의 각각에 저장된 각 인공지능 모델을 훈련시킴으로써, 컴퓨터 클러스터 내 노드들로부터 훈련 결과들을 획득할 수 있다. 일 실시예에서, 서버는 서버 내 저장된 인공지능 모델을 복사하여, 복제 인공지능 모델들을 작업자 노드들에 전달할 수 있다. 서버는 분산 학습을 수행하기 위한 훈련 코드를 실행함으로써, 컴퓨터 클러스 터 내 노드들이 노드들 내 저장된 인공지능 모델을 훈련하도록 할 수 있다. 서버는 컴퓨터 클러스터 내 노드들로부터 훈련 결과들을 획득할 수 있다. 예를 들어, 서버는 작업자 노드들 중에서 제1 작업자 노드가 제1 데이터 서브셋을 이용하여 제1 작업자 노드 내 저장된 인공지능 모델을 훈련시킴으로써 생성된 제1 훈련 결과를, 제1 작업자 노드로부터 획득할 수 있 다. 또한, 서버는 작업자 노드들 중에서 제2 작업자 노드가 제2 데이터 서브셋을 이용하여 제2 작업자 노 드 내 저장된 인공지능 모델을 훈련시킴으로써 생성된 제2 훈련 결과를, 제2 작업자 노드로부터 획득할 수 있다. 또한, 서버도 마스터 노드로써 분산 학습을 수행하므로, 서버에 대응되는 데이터 서브셋을이용하여 서버 내 저장된 인공지능 모델을 훈련시킴으로써 생성된 마스터 노드의 훈련 결과를 획득할 수 있다. 단계 S240에서, 일 실시예에 따른 서버는 훈련 결과들에 기초하여 서버에 저장된 인공지능 모델의 가중치들을 업데이트할 수 있다. 서버는 컴퓨터 클러스터 내 노드들이 각각 연산을 통해 획득한 그래디언트(gradient)들에 기초하여, 서버 에 저장된 인공지능 모델의 가중치들을 업데이트할 수 있다. 또한 서버는, 서버에 저장된 인 공지능 모델 및 작업자 노드들에 저장된 인공지능 모델들을 동기화할 수 있다. 단계 S250에서, 일 실시예에 따른 서버는 컴퓨터 클러스터 내 노드들의 각각에 대하여, 컴퓨터 클러스터 내 노드들의 각각이 훈련을 수행하는데 소요된 연산 시간을 식별할 수 있다. 일 실시예에서, 컴퓨터 클러스터 내 노드들의 훈련 속도는 각각 상이할 수 있다. 서버는 단계 S240에서 전술한 것과 같이, 클러스터 내 노드들로부터 훈련 결과를 획득하여 서버에 저장된 인공지능 모델의 가중 치를 갱신하므로, 훈련 속도가 가장 느린 노드의 훈련이 끝난 후에 서버에 저장된 인공지능 모델을 업데 이트 할 수 있다. 서버는 컴퓨터 클러스터 내 노드들 중에서, 다른 노드들보다 훈련 속도가 소정 기준 이 상 느린 노드들의 훈련 데이터 수를 감소시키기 위해, 컴퓨터 클러스터 내 노드들의 각각이 훈련을 수행하는데 소요된 연산 시간을 식별할 수 있다. 단계 S260에서, 일 실시예에 따른 서버는 컴퓨터 클러스터 내 노드들 각각의 연산 시간에 기초하여, 데이 터 서브셋들의 각각에 포함되는 데이터 수를 조정할 수 있다. 예를 들어, 제1 작업자 노드의 연산 시간은 제2 작업자 노드의 연산 시간보다 소정 기준 이상 짧은 경우, 서버 는 제1 작업자 노드의 제1 데이터 서브셋에 포함되는 데이터 수와 제2 작업자 노드의 제2 데이터 서브셋 에 포함되는 데이터 수를 조정할 수 있다. 구체적으로, 단계 S220에서 전술한 것과 같이, 제1 데이터 서브셋에 는 인덱스 번호 1 내지 25의 훈련 데이터가 포함되고, 제2 데이터 서브셋에는 인덱스 번호 26 내지 50의 훈련 데이터가 포함될 수 있다. 서버는 제1 데이터 서브셋에 인덱스 번호 1 내지 26의 훈련 데이터가 포함되고, 제2 데이터 서브셋에는 인덱스 번호 27 내지 50의 훈련 데이터가 포함되도록 데이터 서브셋들 간의 데이터 수를 조정함으로써, 제1 작업자 노드가 더 많은 훈련 데이터의 연산을 수행하도록 할 수 있다. 도 3은 일 실시예에 따른 서버가 복수의 노드들 중에서 작업자 노드들을 선택하여, 컴퓨터 클러스터를 구축하는 방법을 설명하기 위한 도면이다. 일 실시예에서, 서버는 복수의 노드들 중에서, 분산 학습에 이용 가능한 노드들을 식별할 수 있다. 이용 가능한 노드는, 다른 작업을 수행 중이지 않은 유휴 노드이거나, 분산 학습을 수행할 수 있는 여유 컴퓨팅 자원이 있는 노드일 수 있다. 서버는 이용 가능한 노드들을 식별하고, 이용 가능한 노드들 의 리스트를 생성할 수 있다. 서버는 복수의 노드들의 각각의 노드가 작업 수행 중인지 여부에 따라, 이용 가능한 노드를 다시 식별하고, 이용 가능한 노드들의 리스트를 갱신할 수 있다. 일 실시예에서, 서버는 이용 가능한 노드들 중에서, 분산 학습을 수행할 작업자 노드들을 선택 할 수 있다. 예를 들어, 서버는 이용 가능한 노드들 모두를 작업자 노드들로 선택할 수 있다. 다른 예에서, 서버는 이용 가능한 노드들 중 일부를 작업자 노드들로 선택할 수 있다. 서버 는 이용 가능한 노드들 중에서 적어도 일부의 작업자 노드들을 선택함으로써, 서버를 마 스터 노드로 하는 컴퓨터 클러스터를 구축할 수 있다. 서버가 컴퓨터 클러스터를 구축한 경우, 선택된 작업자 노드들은 이용 가능한 노드들의 리스트에서 제외될 수 있다. 서버는 컴퓨터 클 러스터 내 작업자 노드들 중에서, 적어도 일부의 작업자 노드를 컴퓨터 클러스터로부터 제거하 고, 이용 가능한 노드들 중에서, 적어도 일부의 노드를 작업자 노드로써 컴퓨터 클러스터에 편입시킴 으로써, 컴퓨터 클러스터를 재구축할 수 있다. 도 4는 일 실시예에 따른 서버가 훈련 데이터셋을 분할함으로써 데이터 서브셋들을 결정하는 방법을 설명하기 위한 도면이다. 일 실시예에서, 서버는 인공지능 모델을 훈련시키기 위한 훈련 데이터셋을 분할함으로써, 복수의 데 이터 서브셋들을 결정할 수 있다. 서버는 컴퓨터 클러스터 내 노드 수에 기초하여, 훈련 데이터셋을 분할하여 생성할 데이터 서브셋들의 개수를 결정할 수 있다. 구체적으로, 서버는 컴퓨터 클러스터 내 노 드 수만큼 데이터 서브셋들을 생성할 수 있다.이하에서는, 설명의 편의를 위하여, 컴퓨터 클러스터 내 노드들은 마스터 노드인 서버와, 제1 작업자 노 드, 제2 작업자 노드, 제3 작업자 노드 총 4개의 노드인 경우를 예시로 설명하기로 한다. 다만, 컴퓨터 클러스 터 내 노드들의 수는 이에 한정되는 것은 아니다. 일 실시예에서, 서버는 훈련 데이터셋을 분할하여, 컴퓨터 클러스터 내 노드들의 개수에 대응하도록 데이터 서브셋들을 생성할 수 있다. 예를 들어, 서버는 훈련 데이터셋을 분할하여, 제1 데이터 서브 셋, 제2 데이터 서브셋, 제3 데이터 서브셋 및 제4 데이터 서브셋을 생성할 수 있다. 이 경우, 데이터 서브셋들의 각각은, 컴퓨터 클러스터 내 노드들의 각각에 대응될 수 있다. 예를 들어, 제1 데 이터 서브셋은 제1 작업자 노드에 대응되고, 제2 데이터 서브셋은 제2 작업자 노드에 대응되고, 제3 데이터 서브셋은 제3 작업자 노드에 대응되고, 제4 데이터 서브셋은 서버에 대응될 수 있다. 컴퓨터 클러스터 내 노드들의 각각은, 대응되는 데이터 서브셋을 이용하여 노드 내 저장된 인공지능 모델을 훈 련시킬 수 있다. 서버가 컴퓨터 클러스터 내 노드들의 각각에 대응하도록 훈련 데이터셋을 분할하는 경우, 서버 는 훈련 데이터셋 내 훈련 데이터들을 인덱싱하고, 각각의 데이터 서브셋들에 포함될 인덱스 번호를 결정함으로써 데이터 서브셋들을 생성할 수 있다. 서버가 데이터의 인덱스를 이용하여 데이터 서브셋을 구별한 구체적인 예시는 도 5에서 더 서술하기로 한다. 도 5는 일 실시예에 따른 데이터 서브셋의 데이터 구성을 설명하기 위한 도면이다. 도 5를 참조하면, 일 실시예에 따른 서버는 훈련 데이터셋 내 훈련 데이터들을 인덱싱하고, 각각의 데이 터 서브셋들에 포함될 인덱스 번호를 결정함으로써 데이터 서브셋들을 생성할 수 있다. 일 실시예에서, 서버가 생성한 복수의 데이터 서브셋들 중 어느 하나인 데이터 서브셋은, N개의 데 이터 배치(batch)를 포함할 수 있다. 데이터 배치는, 노드가 인공지능 모델을 훈련시킬 때 입력되는 일 단위인, 데이터들의 그룹을 말한다. 데이터 서브셋에 포함되는 데이터 배치들은, 서버에 의해 부여된 인덱스 번호를 가질 수 있다. 서버는 데이터 서브셋에 포함될 인덱스 번호를 결정할 수 있다. 예를 들어, 서버는 데이터 서 브셋에 포함될 인덱스 번호를 인덱스 번호 1 내지 N으로 결정하여, 데이터 서브셋을 생성할 수 있다. 이 경우, 데이터 서브셋은 인덱스 번호 1의 데이터 배치인 데이터 #1, 인덱스 번호 2의 데이터 배치 인 데이터 #2, 인덱스 번호 3의 데이터 배치인 데이터 #3, 인덱스 번호 4의 데이터 배치인 데이터 #4, ..., 인덱스 번호 N의 데이터 배치인 데이터 #N으로 구성될 수 있다. 전술한 예시와 같이, 하나의 데이터 배치에 포함되어 동일한 인덱스 번호를 갖는 데이터는 복수개일 수 있다. 즉, 동일한 인덱스 번호를 갖는 서로 다른 복수의 데이터들이 하나의 데이터 배치에 포함될 수 있다. 예를 들어, 데이터 #1에는, 복수의 데이터들이 포함될 수 있다. 데이터 배치 내의 복수의 데이터들의 개수는, 배치 사이즈로 지칭될 수 있다. 일 실시예에서, 컴퓨터 클러스터 내 노드(예를 들어, 마스터 노드 또는 작업자 노드)는, 데이터 서브셋 에 포함되는 데이터 배치들에 기초하여, 노드 내 저장된 인공지능 모델을 훈련시킬 수 있다. 노드 는 데이터 서브셋 내 모든 훈련 데이터들에 대하여 연산을 수행하고 가중치들을 갱신하는 훈련 단위 인, 에폭(epoch)을 수행할 수 있다. 노드는 데이터 배치를 노드 내 저장된 인공지능 모델에 입력하여, 손실(loss)을 출력할 수 있다. 도 5를 참조하면, 데이터 서브셋에 포함되는 데이터 배치의 개수 는 N개이므로, 노드는 각각의 데이터 배치마다 연산을 수행하고 손실을 출력하는 과정인, 반복(iteratio n)을 N회 수행함으로써, 반복(iteration)이 N회 수행됨으로써 데이터 서브셋 내 모든 훈련 데이터들에 대 하여 연산이 수행되면, 노드 내 저장된 인공지능 모델에 대한 훈련의 에폭이 1회 수행되었다고 할 수 있다. 일 실시예에 따른 서버가 데이터 서브셋들의 데이터 배치 수를 조정할 때, 서버는 데이터 배치의 배치 사이즈는 유지하면서, 데이터 서브셋의 데이터 배치 수만을 조정할 수 있다. 도 6은 일 실시예에 따른 컴퓨터 클러스터 내 노드들이 데이터 서브셋들을 이용하여 분산 학습을 수행하는 것을 나타낸 도면이다. 도 6을 설명함에 있어서, 컴퓨터 클러스터 내 노드들은 마스터 노드인 서버와, 제1 작업자 노드, 제 2 작업자 노드 및 제3 작업자 노드 총 4개의 노드인 경우를 예시로 설명하기로 한다. 다만, 컴퓨터클러스터 내 노드들의 수는 이에 한정되는 것은 아니다. 일 실시예에서, 서버는 데이터 서브셋들의 각각이 컴퓨터 클러스터 내 노드들의 각각에 대응하도록 훈련 데이터셋을 분할함으로써, 데이터 서브셋들을 결정할 수 있다. 이는, 도 4 내지 도 5에 대한 설명에서 서술하였 으므로, 동일한 설명은 생략한다. 일 실시예에서, 서버는 훈련 코드를 실행함으로써, 서버 및 작업자 노드들이 분산 학습을 수행하도 록 할 수 있다. 훈련 코드가 실행되는 경우, 서버 및 작업자 노드들(610, 620, 630)로 구성되는 컴퓨터 클러스터에서, 인 공지능 모델의 분산 학습이 수행될 수 있다. 서버에서 훈련 코드가 실행되면, 서버로부터 제1 작업자 노드로 훈련 명령이 전달되고, 제1 작업자 노드는 제1 데이터 서브셋을 이용하여 제1 작업자 노드 내 저장된 인공지능 모델을 훈련 시킬 수 있다. 서버는 제1 작업자 노드로부터, 제1 훈련 결과를 획득할 수 있다. 또한, 서버에서 훈련 코드가 실행되면, 서버로부터 제2 작업자 노드로 훈련 명령이 전달되고, 제2 작업자 노드는 제2 데이터 서브셋을 이용하여 제2 작업자 노드 내 저장된 인공지능 모델을 훈련시킬 수 있다. 서버는 제2 작업자 노드로부터, 제2 훈련 결과를 획득할 수 있다. 또한, 서버에서 훈련 코드가 실행되면, 서버로부터 제3 작업자 노드로 훈련 명령이 전달되고, 제3 작업자 노드는 제3 데이터 서브셋을 이용하여 제3 작업자 노드 내 저장된 인공지능 모델을 훈련시킬 수 있다. 서버는 제3 작업자 노드로부터, 제3 훈련 결과를 획득할 수 있다. 또한, 서버에서 훈련 코드가 실행되면, 서버는 제4 데이터 서브셋을 이용하여 서버 내 저장된 인공지능 모델을 훈련시킬 수 있다. 서버는 서버의 훈련 결과 및 작업자 노드들(610, 620, 630)의 훈련 결과들을 취합하고, 취합된 훈 련 결과들에 기초하여 상기 서버에 저장된 인공지능 모델의 가중치들을 업데이트할 수 있다. 도 7은 일 실시예에 따른 서버가 컴퓨터 클러스터를 운용하여 분산 학습을 수행하는 방법을 설명하기 위한 흐름 도이다. 단계 S710에서, 일 실시예에 따른 서버는 복수의 노드들 중에서 분산 학습을 수행할 작업자 노드들을 선 택하여 컴퓨터 클러스터를 구축할 수 있다. 이는, 도 2의 단계 S210에 대응되므로, 동일한 설명은 생략하기로 한다. 단계 S720에서, 일 실시예에 따른 서버는 데이터 서브셋들의 각각이 컴퓨터 클러스터 내 노드들의 각각에 대응하도록 훈련 데이터셋을 분할함으로써, 데이터 서브셋들을 결정할 수 있다. 이는, 도 2의 단계 S220에 대응 되므로, 동일한 설명은 생략하기로 한다. 단계 S730에서, 일 실시예에 따른 서버는 컴퓨터 클러스터 내 노드들에게, 데이터 서브셋에 포함되는 데 이터 배치들의 데이터 인덱스를 전달 후, 훈련 코드를 실행할 수 있다. 서버에서 훈련 코드가 실행되면, 서버 및 작업자 노드들 각각은, 각 노드에 대응하는 데이터 서브셋을 이용하여 각 노드 내 저장된 인공지 능 모델의 훈련을 수행할 수 있다. 단계 S740에서, 일 실시예에 따른 서버는 컴퓨터 클러스터 내 노드들로부터, 소정의 에폭(epoch)마다 출 력된 훈련 결과들을 획득할 수 있다. 예를 들어, 서버는 컴퓨터 클러스터 내 노드들의 각각에서 1회의 에 폭이 수행될 때마다, 컴퓨터 클러스터 내 노드들 각각에 저장된 인공지능 모델의 훈련 결과를 획득할 수 있다. 다른 예에서, 서버는 컴퓨터 클러스터 내 노드들의 각각에서 복수회의 에폭이 수행될 때마다, 컴퓨터 클 러스터 내 노드들 각각에 저장된 인공지능 모델의 훈련 결과를 획득할 수 있다. 단계 S730 내지 단계 S740은, 도 2의 단계 S230에 대응될 수 있다. 단계 S750에서, 일 실시예에 따른 서버는 컴퓨터 클러스터 내 노드들의 훈련 결과들을 취합하여, 서버 내 저장된 인공지능 모델의 가중치들을 업데이트할 수 있다. 서버는 서버 내 저장된 인공지능 모 델의 가중치들을 업데이트하고, 작업자 노드들 내 저장된 인공지능 모델들을 서버 내 저장된 인공지능 모델과 동기화할 수 있다. 단계 S760에서, 일 실시예에 따른 서버는 컴퓨터 클러스터 내 노드들의 데이터 처리량 및 연산 속도를 식 별하여, 각 노드에 대응하는 데이터 서브셋에 포함되는 데이터 배치 인덱스 값을 변경할 수 있다. 일 실시예에서, 서버는 컴퓨터 클러스터 내 노드들의 평균 연산 시간을 계산할 수 있다. 서버는 컴 퓨터 클러스터 내 노드들의 평균 연산 시간을 컴퓨터 클러스터 내 노드들 각각의 각 연산 시간과 비교할 수 있 다. 서버는 비교 결과에 기초하여, 각 노드에 대응하는 데이터 서브셋에 포함되는 데이터 배치 인덱스 값 을 변경할 수 있다. 예를 들어, 제1 작업자 노드의 연산 시간이 컴퓨터 클러스터 내 노드들의 평균 연산 시간보다 긴 경우, 서버 는 제1 작업자 노드의 연산 시간을 감소시키기 위하여, 제1 작업자 노드에 대응되는 제1 데이터 서브셋의 데이터 배치 수가 감소하도록 조정할 수 있다. 즉, 서버는 연산 속도가 느린 제1 작업자 노드의 데이터 처리량을 감소시킴으로써, 제1 작업자 노드의 연산 시간을 감소시킬 수 있다. 구체적으로, 서버는 제1 데 이터 서브셋에 포함되는 데이터 배치 인덱스가 인덱스 번호 1 내지 25인 경우, 서버는 제1 데이터 서브셋 에 포함되는 데이터 배치 인덱스를 인덱스 번호 1 내지 24로 변경함으로써, 제1 작업자 노드가 데이터 배 치 수가 감소된 제1 데이터 서브셋을 이용하여 에폭을 수행하도록 할 수 있다. 이 경우, 서버는 제1 데이 터 서브셋에서 제외된 인덱스 번호 25의 데이터 배치를, 다른 데이터 서브셋(예를 들어, 연산 속도가 빠른 노드 에 대응되는 데이터 서브셋)에 포함되도록 조정할 수 있다. 단계 S770에서, 일 실시예에 따른 서버는 데이터 서브셋의 업데이트된 데이터 배치 인덱스를 컴퓨터 클러 스터 내 노드들에게 전달 후, 다음 에폭을 실행할 수 있다. 각각의 데이터 서브셋들에 포함되는 데이터 배치 인 덱스가 변경되면, 각각의 노드들은 업데이트된 데이터 배치 인덱스에 기초하여 훈련 데이터를 로드하고, 각각의 노드들 내 저장된 인공지능 모델을 훈련시킬 수 있다. 예를 들어, 제1 데이터 서브셋에 포함되는 데이터 배치 인덱스가 인덱스 번호 1 내지 인덱스 번호 25에서, 인덱 스 번호 1 내지 인덱스 번호 24로 변경되면, 제1 작업자 노드는 제1 데이터 서브셋에 포함되는 인덱스 번호 1 내지 인덱스 번호 24의 훈련 데이터들을 로드하고, 제1 작업자 노드 내 저장된 인공지능 모델을 훈련시킬 수 있 다. 일 실시예에서, 서버가 서버 내 저장된 인공지능 모델을 서버 및 작업자 노드들을 이용하여 분산 학습을 수행하는 과정은, 기 설정된 수의 복수의 에폭으로 구성될 수 있다. 서버는 한 번 이상의 에폭을 수행한 후, 훈련 데이터 서브셋들 간의 데이터 배치 수를 조정할 수 있다. 서버는 분산 학습 과정이 종료 될 때까지, 단계 S740 내지 S770을 반복하여 수행할 수 있다. 또한, 서버는 에폭 횟수가 기 설정된 값에 도달하여 마지막 에폭을 수행하는 경우, 단계 S760 내지 S770을 생략할 수 있다. 서버가 분산 학습 과정의 일부인 에폭을 수행하면서, 데이터 서브셋들 간 데이터 배치 수를 조정하는 방 법은, 도 8 내지 도 11에 대한 설명에서 더 서술하기로 한다. 도 8은 분산 학습 과정의 일부인 에폭이 수행됨에 따라, 일 실시예에 따른 서버가 데이터 서브셋들의 각각에 포 함되는 데이터 배치 수를 조정하는 방법을 설명하기 위한 도면이다. 도 8을 설명함에 있어서, 컴퓨터 클러스터 내 노드들은 마스터 노드인 서버와, 제1 작업자 노드, 제2 작 업자 노드, 제3 작업자 노드 총 4개의 노드인 경우를 예시로 설명하기로 한다. 다만, 컴퓨터 클러스터 내 노드 들의 수는 이에 한정되는 것은 아니다. 일 실시예에서, 서버는 분산 학습을 수행하기 위한 훈련 코드를 실행함으로써, 컴퓨터 클러스터 내 노드 들이 노드들 내 저장된 인공지능 모델을 훈련하도록 할 수 있다. 서버는 컴퓨터 클러스터 내 노드들로부 터 훈련 결과들을 획득할 수 있다. 서버는 컴퓨터 클러스터 내 노드들로부터 획득한 훈련 결과들에 기초 하여 서버에 저장된 인공지능 모델의 가중치들을 업데이트할 수 있다. 일 실시예에서, 컴퓨터 클러스터 내 노드들의 훈련 속도는 각각 상이할 수 있다. 서버는 컴퓨터 클러스터 내 노드들의 각각에 대하여, 컴퓨터 클러스터 내 노드들의 각각이 훈련을 수행하는데 소요된 연산 시간을 식별 할 수 있다. 서버는 컴퓨터 클러스터 내 노드들 각각의 연산 시간에 기초하여, 데이터 서브셋들의 각각에 포함되는 데이터 배치 수를 조정할 수 있다. 구체적으로, 서버는 컴퓨터 클러스터 내 노드들의 각각에서, 노드 내 저장된 인공지능 모델의 훈련 과정인 에폭이 수행된 후, 컴퓨터 클러스터 내 노드들의 각각이 다음 에 폭을 수행하기 위한 데이터 서브셋의 데이터 배치 수를 조정할 수 있다. 서버는, 컴퓨터 클러스터 내 노 드들에 대응하는 데이터 서브셋에 포함되는 데이터 배치 수를 계산할 수 있다. 이 경우, 컴퓨터 클러스터 내 어 느 한 노드 K에 대응되는 데이터 서브셋의 데이터 배치 수는, 아래의 수학식 1로 표현될 수 있다.[수학식 1]"}
{"patent_id": "10-2021-0108177", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 는 노드 k가 다음 에폭을 수행할 때 노드 k에 할당될 데이터 배치 수(노드 k에 대응되는 데 이터 서브셋의 다음 데이터 배치 수), 는 노드 k가 현재 에폭을 수행할 때 할당된 데이터 배치 수(노드 k에 대응되는 데이터 서브셋의 현재 데이터 배치 수), 는 컴퓨터 클러스터 내 노드들의 평균 연산 시간, 는 노드 k가 현재 에폭을 수행할 때 소요된 연산 시간, 는 현재 에폭의 전체 훈련 데이터 수, 는 다음 에폭의 전체 훈련 데이터 수를 말한다. 일 실시예에서, 서버는 훈련 코드를 실행함으로써, 서버 및 작업자 노드들이 분산 학습을 수행하도 록 할 수 있다. 에폭 1에서, 서버 및 제1 작업자 노드, 제2 작업자 노드, 제3 작업자 노드는 각각 독립적으로 노드 내 저장된 인공지능 모델을 훈련시킬 수 있다. 예를 들어, 서버는 서버의 데이터 서브셋(데이터 배 치 수:25개)을 이용하여 서버 내 저장된 인공지능 모델을 훈련시키고, 제1 작업자 노드는 제1 작업자 노 드의 데이터 서브셋(데이터 배치 수:25개)을 이용하여 제1 작업자 노드 내 저장된 인공지능 모델을 훈련시키고, 제2 작업자 노드는 제2 작업자 노드의 데이터 서브셋(데이터 배치 수:25개)을 이용하여 제2 작업자 노드 내 저 장된 인공지능 모델을 훈련시키고, 제3 작업자 노드는 제3 작업자 노드의 데이터 서브셋(데이터 배치 수:25개) 을 이용하여 제3 작업자 노드 내 저장된 인공지능 모델을 훈련시킬 수 있다. 서버는, 서버 및 작업자 노드들의 각각이 에폭 1을 수행하는데 소요된 연산 시간을 식별할 수 있다. 예를 들어 서버는, 서버가 에폭 1을 수행하는 데 소요된 연산 시간은 100초, 제1 작업 자 노드가 에폭 1을 수행하는 데 소요된 연산 시간은 120초, 제2 작업자 노드가 에폭 1을 수행하는 데 소요된 연산 시간은 130초, 제3 작업자 노드가 에폭 1을 수행하는 데 소요된 연산 시간은 190초임을 식 별할 수 있다. 서버는, 컴퓨터 클러스터 내 노드들의 평균 연산 시간을 계산할 수 있다. 예를 들어 서버는, 서버 및 작업자 노드들의 각각이 에폭 1을 수행하는데 소요된 연산 시간의 평균이 135초임을 계산할 수 있다. 서버는 컴퓨터 클러스터 내 노드들의 평균 연산 시간을 컴퓨터 클러스터 내 노드들 각각의 각 연산 시간 과 비교할 수 있다. 예를 들어 서버는, 서버, 제1 작업자 노드 및 제2 작업자 노드의 연산 시간은 평균 연산 시간 보다 짧고, 제3 작업자 노드의 연산 시간은 평균 연산 시간 보다 김을 식별할 수 있다. 서버는 비교 결과에 기초하여, 데이터 서브셋들의 각각에 포함되는 데이터 배치 수를 조정할 수 있다. 예 를 들어, 서버는 평균 연산 시간보다 연산 시간이 긴 노드에 대응되는 데이터 서브셋의 일부 데이터 배치 를 평균 연산 시간보다 연산 시간이 짧은 노드에 대응되는 데이터 서브셋에 포함되도록 조정할 수 있다. 이 경 우, 서버는 평균 연산 시간과 각 노드의 연산 시간의 비교 결과를 임계 값과 비교하고, 비교 결과가 임계 값 이상인 경우에만 데이터 서브셋들의 각각에 포함되는 데이터 배치 수를 조정할 수 있다. 구체적으로, 서버는 수학식 1을 이용하여 데이터 서브셋들의 각각에 포함되는 데이터 배치 수를 조정할 수 있다. 서버는 서버의 데이터 서브셋에 포함되는 데이터 배치 수는 33개, 제1 작업자 노드의 데 이터 서브셋에 포함되는 데이터 배치 수는 28개, 제2 작업자 노드의 데이터 서브셋에 포함되는 데이터 배치 수 는 25개, 제3 작업자 노드의 데이터 서브셋에 포함되는 데이터 배치 수는 14개로 조정할 수 있다. 일 실시예에서, 이전 에폭 대비 다음 에폭에서 사용되는 훈련 데이터셋의 데이터 배치 개수가 변경되는 경우, 서버는 에폭의 전체 데이터 수 대비 다음 에폭의 전체 데이터 수의 비율을 적용하여, 데이터 서브셋에 포 함되는 데이터 배치 수를 결정할 수 있다. 에폭 2에서, 서버 및 제1 작업자 노드, 제2 작업자 노드, 제3 작업자 노드는 각각 데이터 배치 수가 조정된 데이터 서브셋을 이용하여 에폭 2를 수행할 수 있다. 서버는 서버의 데이터 서브셋(데이터 배치 수:33개)을 이용하여 서버 내 저장된 인공지능 모델을 훈련시키고, 제1 작업자 노드는 제1 작업자 노드의 데이터 서브셋(데이터 배치 수:28개)을 이용하여 제1 작업자 노드 내 저장된 인공지능 모델을 훈련시키고, 제2 작업자 노드는 제2 작업자 노드의 데이터 서브셋(데이터 배치 수:25개)을 이용하여 제2 작업자 노드 내 저장된인공지능 모델을 훈련시키고, 제3 작업자 노드는 제3 작업자 노드의 데이터 서브셋(데이터 배치 수:14개)을 이 용하여 제3 작업자 노드 내 저장된 인공지능 모델을 훈련시킬 수 있다. 서버는 에폭 2을 수행한 후에, 서버 및 작업자 노드들의 각각이 에폭 2를 수행하는데 소 요된 연산 시간을 식별할 수 있다. 또한, 서버는 서버 및 작업자 노드들의 각각이 에폭 2를 수행하는데 소요된 연산 시간의 평균을 계산할 수 있다. 서버는 컴퓨터 클러스터 내 노드들의 평균 연산 시간을 컴퓨터 클러스터 내 노드들 각각의 각 연산 시간과 비교하고, 비교 결과에 기초하여 데이터 서브셋들의 각각에 포함되는 데이터 배치 수를 조정할 수 있다. 서버 및 작업자 노드들은 데이터 배치 수가 조정된 데이터 서브셋들을 이용하여 에폭 3을 수행하고, 전술한 실시예들에 따라 데이터 서브셋들 각각에 포함되는 데이터 배치 수를 조정할 수 있다. 에폭 3이 수행된 후에, 서버는 전술한 실시예들에 따라 데이터 서브셋들 각각에 포함되는 데이터 배 치 수를 조정하고, 에폭 4를 수행할 수 있다. 서버는 분산 학습 과정이 종료될 때까지, 데이터 서브 셋들 각각에 포함되는 데이터 배치 수를 조정하고 다음 에폭을 수행하는 동작을 반복할 수 있다. 일 실시예에 따른 서버가 수행하는 분산 학습 과정의 일부인, 에폭 1 및 에폭 2의 실행을 나타 내는 블록 850은 도 9에서 더 설명하기로 한다. 또한, 일 실시예에 따른 서버가 분산 학습을 수행할 때, 제1 작업자 노드의 의한 에폭 1 내지 에폭 4의 실행을 나타내는 블록 860은 도 10에서 더 설명하기로 한다. 도 9는 도 8을 더 설명하기 위한 도면으로, 분산 학습 과정의 일부인, 컴퓨터 클러스터 내 노드들의 에폭 1 및 에폭 2의 실행을 나타내는 도면이다. 도 9를 참조하면, 도 9의 에폭 1 및 에폭 2는 도 8의 에폭 1 및 에폭 2의 실행을 나타내는 블록 850 에 대응될 수 있다. 일 실시예에 따른 서버는, 에폭 1을 수행한 후, 각각의 노드들로부터 각각의 노드 내 저장된 인공지능 모 델을 훈련시킨 결과들을 취합하여, 서버 내 저장된 인공지능 모델의 가중치들을 업데이트할 수 있다. 서 버는 서버 내 저장된 인공지능 모델의 가중치들을 업데이트하고, 작업자 노드들 내 저장된 인공지능 모델 들을 서버 내 저장된 인공지능 모델과 동기화할 수 있다. 일 실시예에서, 서버의 데이터 서브셋은 인덱스 번호 1 내지 인덱스 번호 25의 데이터 배치들로 구 성될 수 있다. 서버는 서버의 데이터 서브셋을 이용하여, 서버 내 저장된 인공지능 모 델을 훈련시킬 수 있다. 서버는 서버의 데이터 서브셋 내 모든 데이터 배치들에 대한 연산을 수행하는, 에폭 1을 수행할 수 있다. 일 실시예에서, 제1 작업자 노드의 데이터 서브셋(이하, 제1 데이터 서브셋)은 인덱스 번호 26 내지 인덱스 번호 50의 데이터 배치들로 구성될 수 있다. 제1 작업자 노드는 제1 데이터 서브셋을 이용하 여, 제1 작업자 노드 내 저장된 인공지능 모델을 훈련시킬 수 있다. 제1 작업자 노드는 제1 데이터 서브셋 내 모든 데이터 배치들에 대한 연산을 수행하는, 에폭 1을 수행할 수 있다. 일 실시예에서, 제2 작업자 노드의 데이터 서브셋(이하, 제2 데이터 서브셋)은 인덱스 번호 51 내지 인덱스 번호 75의 데이터 배치들로 구성될 수 있다. 제2 작업자 노드는 제2 데이터 서브셋을 이용하 여, 제2 작업자 노드 내 저장된 인공지능 모델을 훈련시킬 수 있다. 제2 작업자 노드는 제2 데이터 서브셋 내 모든 데이터 배치들에 대한 연산을 수행하는, 에폭 1을 수행할 수 있다. 일 실시예에서, 제3 작업자 노드의 데이터 서브셋(이하, 제3 데이터 서브셋)은 인덱스 번호 76 내지 인덱스 번호 100의 데이터 배치들로 구성될 수 있다. 제3 작업자 노드는 제3 데이터 서브셋을 이용하 여, 제3 작업자 노드 내 저장된 인공지능 모델을 훈련시킬 수 있다. 제3 작업자 노드는 제3 데이터 서브셋 내 모든 데이터 배치들에 대한 연산을 수행하는, 에폭 1을 수행할 수 있다. 서버는 에폭 1을 수행한 후, 각각의 노드들의 데이터 처리량 및 연산 속도를 식별하여, 각 노드에 대응하 는 데이터 서브셋에 포함되는 데이터 배치 인덱스 값을 변경할 수 있다. 예를 들어, 데이터 서브셋들에 포함되는 데이터 배치가 조정된 결과, 업데이트된 서버의 데이터 서브셋 은 인덱스 번호 1 내지 인덱스 번호 33의 데이터 배치들로 구성되고, 업데이트된 제1 데이터 서브셋 은 인덱스 번호 34 내지 인덱스 번호 61의 데이터 배치들로 구성되고, 업데이트된 제2 데이터 서브셋은 인덱스 번호 62 내지 인덱스 번호 86의 데이터 배치들로 구성되고, 업데이트된 제3 데이터 서브셋은 인덱스 번호 87 내지 인덱스 번호 100의 데이터 배치들로 구성될 수 있다. 일 실시예에 따른 서버는, 서버 및 작업자 노드들이 데이터 배치 수가 조정된 데이터 서브셋을 이 용하여 에폭 2를 수행하도록 할 수 있다. 이 경우, 서버는 업데이트된 서버의 데이터 서브셋을 이용 하여 서버 내 인공지능 모델을 훈련시킬 수 있다. 또한, 제1 작업자 노드는 업데이트된 제1 데이터 서브셋을 이용하여 제1 작업자 노드 내 인공지능 모델을 훈련시킬 수 있다. 또한, 제2 작업자 노드 는 업데이트된 제2 데이터 서브셋을 이용하여 제2 작업자 노드 내 인공지능 모델을 훈련시킬 수 있다. 또한, 제3 작업자 노드는 업데이트된 제3 데이터 서브셋을 이용하여 제3 작업자 노드 내 인공지능 모델을 훈련시킬 수 있다. 서버는, 에폭 2을 수행한 후, 각각의 노드들로부터 각각의 노드 내 저장된 인공지능 모델을 훈련시킨 결 과들을 취합하여, 서버 내 저장된 인공지능 모델의 가중치들을 업데이트할 수 있다. 서버는 서버 내 저장된 인공지능 모델의 가중치들을 업데이트하고, 작업자 노드들 내 저장된 인공지능 모델들을 서버 내 저 장된 인공지능 모델과 동기화할 수 있다. 도 10은 도 8을 더 설명하기 위한 도면으로, 분산 학습 과정의 일부인, 제1 작업자 노드에 의한 에폭 1 내지 에 폭 4의 실행을 나타내는 도면이다. 도 10을 참조하면, 도 10의 제1 작업자 노드의 에폭 1 내지 에폭 4는 도 8의 제1 작업자 노드의 의한 에 폭 1 내지 에폭 4의 실행을 나타내는 블록 860에 대응될 수 있다. 에폭 1에서, 제1 작업자 노드는 제1 작업자 노드의 데이터 서브셋에 포함되는, 인덱스 번호 1 내지 인덱스 번호 25의 데이터 배치들에 대하여 연산을 수행할 수 있다. 제1 작업자 노드는 인덱스 번호 1 내 지 인덱스 번호 25의 데이터 배치들을 훈련시킨 에폭 1의 결과를 서버로 전송할 수 있다. 서버 는 제1 작업자 노드의 에폭 1의 연산 속도를 식별하고, 전술한 실시예들에 따라 제1 작업자 노드의 데이터 서브셋에 포함되는 데이터 배치 수를 조정할 수 있다. 예를 들어, 에폭 1 수행 결과, 제1 작업자 노드의 연산 속도는 컴퓨터 클러스터 내 노드들의 평균 연산 속도보다 빠를 수 있다. 이 경우, 서버는 제1 작업자 노드가 다른 노드들에 비해 더 많은 데이터를 처리하도록, 제1 작업자 노드의 데이터 서브셋에 포함되는 데이터 배치 수를 증가시킬 수 있다. 에폭 2에서, 제1 작업자 노드는 에폭 1의 결과에 기초하여 업데이트된 제1 작업자 노드의 데 이터 서브셋에 포함되는, 인덱스 번호 1 내지 인덱스 번호 28의 데이터 배치들에 대하여 연산을 수행할 수 있다. 제1 작업자 노드는 인덱스 번호 1 내지 인덱스 번호 28의 데이터 배치들을 훈련시킨 에폭 2 의 결과를 서버로 전송할 수 있다. 서버는 제1 작업자 노드의 에폭 2의 연산 속도를 식별하고, 전술한 실시예들에 따라 제1 작업자 노드의 데이터 서브셋에 포함되는 데이터 배치 수를 조정 할 수 있다. 예를 들어, 에폭 2 수행 결과, 제1 작업자 노드의 연산 속도는 컴퓨터 클러스터 내 노 드들의 평균 연산 속도보다 느릴 수 있다. 이 경우, 서버는 제1 작업자 노드가 다른 노드들에 비해 더 적은 데이터를 처리하도록, 제1 작업자 노드의 데이터 서브셋에 포함되는 데이터 배치 수를 감소시킬 수 있다. 에폭 3에서, 제1 작업자 노드는 에폭 2의 결과에 기초하여 업데이트된 제1 작업자 노드의 데 이터 서브셋에 포함되는, 인덱스 번호 1 내지 인덱스 번호 27의 데이터 배치들에 대하여 연산을 수행할 수 있다. 제1 작업자 노드는 인덱스 번호 1 내지 인덱스 번호 27의 데이터 배치들을 훈련시킨 에폭 3 의 결과를 서버로 전송할 수 있다. 서버는 제1 작업자 노드의 에폭 3의 연산 속도를 식별하고, 전술한 실시예들에 따라 제1 작업자 노드의 데이터 서브셋에 포함되는 데이터 배치 수를 조정 할 수 있다. 에폭 4에서, 제1 작업자 노드는 에폭 3의 결과에 기초하여 업데이트된 제1 작업자 노드 의 데이터 서브셋에 포함되는, 인덱스 번호 1 내지 인덱스 번호 27의 데이터 배치들에 대하여 연산을 수 행할 수 있다. 제1 작업자 노드는 인덱스 번호 1 내지 인덱스 번호 27의 데이터 배치들을 훈련시킨 에폭 4의 결과를 서버로 전송할 수 있다. 서버는 제1 작업자 노드의 에폭 4의 연산 속도를 식별하고, 전술한 실시예들에 따라 제1 작업자 노드의 데이터 서브셋에 포함되는 데이터 배치 수 를 조정할 수 있다. 일 실시예에서, 데이터 서브셋에 포함되며, 인덱스 번호로 구별되는 데이터 배치는, 전술한 것과 같이 복수개의 훈련 데이터들을 포함할 수 있다. 예를 들어, 배치 사이즈가 10인 경우, 인덱스 번호 1의 데이터 배치는, 10개 의 훈련 데이터들로 구성될 수 있다. 서버는 클러스터 내 노드들을 이용하여 분산 학습을 수행할 때, 클 러스터 내 노드들의 각각에 대하여 설정된 배치 사이즈는 유지하면서, 데이터 배치의 개수를 조정함으로써, 노 드들 간 연산 속도를 평준화하여, 분산 학습의 속도를 증가시킬 수 있다. 도 11은 분산 학습 과정의 일부인 에폭이 수행됨에 따라, 일 실시예에 따른 서버가 데이터 서브셋들의 각각에 포함되는 데이터 배치 수를 조정하는 다른 방법을 설명하기 위한 도면이다. 일 실시예에서, 서버는 컴퓨터 클러스터 내 노드들 중에서, 연산 시간이 가장 긴 노드를 식별할 수 있다. 서버는 연산 시간이 가장 긴 노드에 대응되는 데이터 서브셋의 일부 데이터를 컴퓨터 클러스터 내 다른 노드들에 대응되는 데이터 서브셋들에 포함되도록 조정할 수 있다. 일 실시예에서, 서버는 훈련 코드를 실행함으로써, 서버 및 작업자 노드들이 분산 학습을 수행하도 록 할 수 있다. 에폭 1에서, 서버 및 제1 작업자 노드, 제2 작업자 노드, 제3 작업자 노드는 각각 독립적으로 노드 내 저장된 인공지능 모델을 훈련시킬 수 있다. 예를 들어, 에폭 1이 수행될 때, 서버는 서버(200 0)의 데이터 서브셋(데이터 배치 수:25개)을 이용하여 서버 내 저장된 인공지능 모델을 훈련시키고, 제1 작업자 노드는 제1 작업자 노드의 데이터 서브셋(데이터 배치 수:25개)을 이용하여 제1 작업자 노드 내 저장된 인공지능 모델을 훈련시키고, 제2 작업자 노드는 제2 작업자 노드의 데이터 서브셋(데이터 배치 수:25개)을 이 용하여 제2 작업자 노드 내 저장된 인공지능 모델을 훈련시키고, 제3 작업자 노드는 제3 작업자 노드의 데이터 서브셋(데이터 배치 수:25개)을 이용하여 제3 작업자 노드 내 저장된 인공지능 모델을 훈련시킬 수 있다. 서버는, 서버 및 작업자 노드들의 각각이 에폭 1을 수행하는데 소요된 연산 시간을 식별하고, 연산 시간이 가장 긴 노드를 식별할 수 있다. 예를 들어, 에폭 1 수행 결과, 서버는 연산 시간이 가장 긴 제3 작업자 노드를 식별할 수 있다. 서버는 연산 시간이 가장 긴 제3 작업자 노드의 데이터셋에 포함되는 데이터 배치 일부를 다른 노드들의 데이터 서브셋들에 포함되도록 조정할 수 있다. 예를 들어, 서버는, 제3 작업자 노드의 데이터 서브셋에 포함되는 데이터 수를 22개로 감소시키고, 서버 의 데이터 서브셋에 포함되는 데이터 배치 수를 26개, 제1 작업자 노드의 데이터 서브셋에 포함되는 데이 터 배치 수를 26개, 제2 작업자 노드의 데이터 서브셋에 포함되는 데이터 배치 수를 26개로 증가시킬 수 있다. 이 경우, 서버는 각 노드에 대응하는 데이터 서브셋에 포함되는 데이터 배치 인덱스 값을 변경함으로써 데이터 배치 수를 조정할 수 있다. 예를 들어 서버는, 서버의 데이터 서브셋은 인덱스 번호 1 내지 인덱스 번호 26의 데이터 배치들로 구성하고, 제1 작업자 노드의 데이터 서브셋은 인덱스 번호 27 내지 인덱스 번호 52의 데이터 배치들로 구성하고, 제2 작업자 노드의 데이터 서브셋은 인덱스 번호 53 내지 인덱스 번호 78 의 데이터 배치들로 구성하고, 제3 작업자 노드의 데이터 서브셋은 인덱스 번호 79 내지 인덱스 번호 100의 데 이터 배치들로 구성할 수 있다. 일 실시예에 따른 서버는, 서버 및 작업자 노드들이 데이터 배치 수가 조정된 데이터 서브셋을 이 용하여 에폭 2를 수행하도록 할 수 있다. 예를 들어, 에폭 2가 수행될 때, 서버는 업데이트된 서버의 데이터 서브셋(데이터 배치 수:26개)을 이용하여 서버 내 저장된 인공지능 모델을 훈련시키고, 제1 작업자 노드는 업데이트된 제1 작 업자 노드의 데이터 서브셋(데이터 배치 수:26개)을 이용하여 제1 작업자 노드 내 저장된 인공지능 모델을 훈련 시키고, 제2 작업자 노드는 업데이트된 제2 작업자 노드의 데이터 서브셋(데이터 배치 수:26개)을 이용하여 제2 작업자 노드 내 저장된 인공지능 모델을 훈련시키고, 제3 작업자 노드는 업데이트된 제3 작업자 노드의 데이터 서브셋(데이터 배치 수:22개)을 이용하여 제3 작업자 노드 내 저장된 인공지능 모델을 훈련시킬 수 있다. 일 실시예에 따른 서버는, 전술한 방법들을 이용하여, 에폭이 수행될 때마다 연산 시간이 가장 긴 노드를 식별할 수 있다. 서버는 에폭이 수행될 때마다 연산 시간이 가장 긴 노드에 대응되는 데이터 서브셋의 일 부 데이터를 컴퓨터 클러스터 내 다른 노드들에 대응되는 데이터 서브셋들에 포함되도록 조정함으로써, 에폭 3, 에폭 4, 에폭 5을 수행할 수 있다. 도 12는 일 실시예에 서버가 따른 훈련 데이터셋을 분할함으로써 데이터 서브셋들을 결정하는 다른 방법을 설명 하기 위한 도면이다. 일 실시예에서, 서버는 컴퓨터 클러스터의 마스터 노드의 역할을 수행하므로, 서버 내 저장된 인공지능 모델을 훈련시키는 것 외에, 컴퓨터 클러스터에 포함되는 작업자 노드들의 관리를 위한 다른 작업들을 수행할 수 있다. 따라서, 서버는 서버에 대응되는 데이터 서브셋의 데이터 수를 더 적게 할당할 수 있다. 일 실시예에서, 서버는 훈련 데이터셋을 분할하여, 컴퓨터 클러스터 내 노드들의 개수에 대응하도 록 데이터 서브셋들을 생성할 수 있다. 예를 들어, 서버는 훈련 데이터셋을 분할하여, 제1 데이터 서브셋, 제2 데이터 서브셋, 제3 데이터 서브셋 및 제4 데이터 서브셋을 생성할 수 있 다. 데이터 서브셋들의 각각은, 컴퓨터 클러스터 내 노드들의 각각에 대응될 수 있다. 예를 들어, 제1 데이터 서브셋은 제1 작업자 노드에 대응되고, 제2 데이터 서브셋은 제2 작업자 노드에 대응 되고, 제3 데이터 서브셋은 제3 작업자 노드에 대응되고, 제4 데이터 서브셋은 서버에 대응될 수 있다. 일 실시예에 따른 서버는 제4 데이터 서브셋에 포함되는 데이터 배치 수가 다른 제1 데이터 서브셋 내지 제3 데이터 서브셋(1210, 1220, 1230)에 포함되는 데이터 배치 수보다 적도록, 훈련 데이터 셋을 분 할할 수 있다. 서버가 훈련 데이터셋을 분할하여 데이터 서브셋들을 생성하는 구체적인 방법들은 전술하였으므로, 동일한 설명은 생략한다. 도 13은 일 실시예에 따른 서버가 컴퓨터 클러스터를 운용하여 분산 학습을 수행하는 다른 방법을 설명하기 위 한 흐름도이다. 도 13을 설명함에 있어서, 컴퓨터 클러스터 내 노드들은 마스터 노드인 서버와, 제1 작업자 노드 , 제2 작업자 노드, 제3 작업자 노드 총 4개의 노드인 경우를 예시로 설명하기로 한다. 다만, 컴퓨터 클러스터 내 노드들의 수는 이에 한정되는 것은 아니다. 일 실시예에 따른 서버는, 컴퓨터 클러스터 내 노드들의 연산 속도를 식별할 수 있다. 서버 는 컴퓨터 클러스터 내 노드들 각각의 연산 시간에 기초하여, 컴퓨터 클러스터 내 노드들 중에서 하나 이상의 작업자 노드를 선택할 수 있다. 예를 들어, 서버는 컴퓨터 클러스터 내 노드들 중에서, 연산 시간이 가장 긴 노드를 선택할 수 있 다. 구체적으로, 제1 작업자 노드의 연산 시간이 가장 긴 경우, 서버는 연산 시간이 가장 긴 노드 인 제1 작업자 노드를 선택할 수 있다. 일 실시예에 따른 서버는 선택된 하나 이상의 작업자 노드를 컴퓨터 클러스터로부터 제거하고, 하 나 이상의 다른 노드를 작업자 노드로써 컴퓨터 클러스터에 편입시킬 수 있다. 서버는 이용 가능한 노드들의 리스트에서 이용 가능한 노드를 작업자 노드로 선택하여, 컴퓨터 클러스터에 편입시킬 수 있다. 예를 들어, 서버는 이용 가능한 노드들의 리스트에서 이용 가능한 다른 노드인 제9 작업자 노드를 선택하여, 제9 작업자 노드를 컴퓨터 클러스터로 편입시킬 수 있다. 일 실시예에 따른 서버는 분산 학습 과정의 일부인 에폭이 소정 횟수(예를 들어, 1회 또는 2회) 이상 수 행될 때마다, 컴퓨터 클러스터 내 노드들 중에서 하나 이상의 작업자 노드를 선택할 수 있다. 서버(200 0)는 선택된 하나 이상의 작업자 노드를 컴퓨터 클러스터에서 제외시키고, 이용 가능한 하나 이상의 다른 노드를 작업자 노드로써 컴퓨터 클러스터에 편입시킬 수 있다. 개시된 실시예들에서, 서버가 컴퓨터 클러스터를 이용하여 분산 학습을 수행함에 있어서, 서버는 데이터 서브셋의 데이터 수를 조정하거나, 작업자 노드를 교체하면서 분산 학습의 속도를 증가시킬 수 있다. 서 버는 분산 학습 과정의 에폭이 소정 횟수 수행될 때마다, 데이터 서브셋의 데이터 수를 조정하거나, 작업 자 노드를 교체하거나, 데이터 서브셋의 데이터 수 조정 및 작업자 노드의 교체를 조합하여 분산 학습을 수행할 수 있다. 도 14는 일 실시예에 따른 서버의 구성을 나타낸 블록도이다. 도 14를 참조하면, 일 실시예에 따른 서버는 통신 인터페이스, 메모리 및 프로세서를 포함할 수 있다. 통신 인터페이스는 프로세서의 제어에 의해 컴퓨터 클러스터의 다른 노드들과 데이터 통신을 수행 할 수 있다. 또한, 통신 인터페이스는 컴퓨터 클러스터의 다른 노드들 뿐 아니라, 다른 주변 전자 장치들 과도 데이터 통신을 수행할 수 있다. 통신 인터페이스는 예를 들어, 유선 랜, 무선 랜(Wireless LAN), 와이파이(Wi-Fi), 블루투스 (Bluetooth), 지그비(zigbee), WFD(Wi-Fi Direct), 적외선 통신(IrDA, infrared Data Association), BLE (Bluetooth Low Energy), NFC(Near Field Communication), 와이브로(Wireless Broadband Internet, Wibro), 와이맥스(World Interoperability for Microwave Access, WiMAX), SWAP(Shared Wireless Access Protocol), 와이기그(Wireless Gigabit Allicance, WiGig) 및 RF 통신을 포함하는 데이터 통신 방식 중 적어도 하나를 이 용하여 컴퓨터 클러스터 내 다른 노드들 또는 다른 주변 전자 장치들과 데이터 통신을 수행할 수 있다. 일 실시예에 따른 통신 인터페이스는 분산 학습을 수행하기 위한 명령을 컴퓨터 클러스터 내 노드들에게 전달하고, 컴퓨터 클러스터 내 노드들로부터 분산 학습 결과를 수신할 수 있다. 통신 인터페이스는 컴퓨 터 클러스터 내 노드들의 각각에 저장된 인공지능 모델을 동기화하기 위한 데이터를 컴퓨터 클러스터 내 노드들 로 전송할 수 있다. 메모리는 프로세서가 판독할 수 있는 명령어들, 데이터 구조, 및 프로그램 코드(program code)가 저장될 수 있다. 개시된 실시예들에서, 프로세서가 수행하는 동작들은 메모리에 저장된 프로그램의 명령어들 또는 코드들을 실행함으로써 구현될 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나를 포함하는 비휘발성 메모리 및 램(RAM, Random Access Memory) 또는 SRAM(Static Random Access Memory)과 같은 휘발성 메모리를 포함할 수 있다. 일 실시 예에 따른 메모리는 컴퓨터 클러스터가 분산 학습을 수행하는데 이용될 수 있는 다양한 종류의 데이터를 저장할 수 있다. 예를 들어, 메모리에는 분산 학습 모듈, 작업자 노드 관리 모듈, 훈련 데이터 관리 모듈, 인공지능 모델, 훈련 데이터셋이 저장될 수 있다. 프로세서는 서버의 전반적인 동작들을 제어할 수 있다. 예를 들어, 프로세서는 메모리(220 0)에 저장된 프로그램의 하나 이상의 명령어들(instructions)을 실행함으로써, 서버가 컴퓨터 클러스터를 이용하여 분산 학습을 수행하기 위한 전반적인 동작을 제어할 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서(microprocessor), 그래픽 프로세서(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), AP(Application Processor), 뉴럴 프로세서(Neural Processing Unit) 또는 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계된 인공지능 전용 프로세서 중 적 어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 일 실시예에서, 프로세서는 분산 학습 모듈을 이용하여, 인공지능 모델을 훈련시킬 수 있다. 분산 학습 모듈은 분산 학습을 위한 훈련 코드를 실행시킴으로써, 컴퓨터 클러스터 내 노드들이 각각 독 립적으로 훈련을 수행하도록 할 수 있다. 이 경우, 분산 학습 모듈은 컴퓨터 클러스터 내 노드들에서 각 각 독립적으로 훈련을 수행하기 위해, 인공지능 모델을 복사하여 복제 인공지능 모델들을 생성할 수 있다. 분산 학습 모듈은 컴퓨터 클러스터 내 노드들로부터 노드들의 각각에 저장된 복제 인공지능 모델들 을 훈련시킨 결과인, 훈련 결과들을 획득하고, 인공지능 모델의 가중치들을 업데이트할 수 있다. 분산 학 습 모듈은 컴퓨터 클러스터 내 노드들의 각각에 저장된 복제 인공지능 모델들을 인공지능 모델과 동기화할 수 있다. 일 실시예에서, 프로세서는 작업자 노드 관리 모듈을 이용하여, 컴퓨터 클러스터 내 작업자 노드들 을 관리할 수 있다. 작업자 노드 관리 모듈은 복수의 노드들 중에서, 분산 학습에 이용 가능한 노드들을 식별할 수 있다. 이용 가능한 노드는, 다른 작업을 수행 중이지 않은 유휴 노드이거나, 분산 학습을 수행할 수 있는 여유 컴퓨팅 자원이 있는 노드일 수 있다. 작업자 노드 관리 모듈은 이용 가능한 노드들 중에서, 분 산 학습을 수행할 작업자 노드들을 선택하여 컴퓨터 클러스터를 구축할 수 있다. 작업자 노드 관리 모듈 은 이용 가능한 노드들을 식별하고, 이용 가능한 노드들의 리스트를 생성할 수 있다. 작업자 노드 관리 모듈 은 복수의 노드들의 각각의 노드가 작업 수행 중인지 여부에 따라, 이용 가능한 노드를 다시 식별하고, 이용 가능한 노드들의 리스트를 갱신할 수 있다. 작업자 노드 관리 모듈은 작업자 노드가 작업자 노드 내 저장된 인공지능 모델을 훈련시키는데 소요되는 연산 시간을 식별할 수 있다. 작업자 노드 관리 모듈은컴퓨터 클러스터 내 작업자 노드들의 연산 시간 식별 결과에 기초하여, 컴퓨터 클러스터 내 작업자 노드들 중에 서, 적어도 일부의 작업자 노드를 컴퓨터 클러스터로부터 제거하고, 이용 가능한 노드들 중에서, 적어도 일부의 노드를 작업자 노드로써 컴퓨터 클러스터에 편입시킴으로써, 컴퓨터 클러스터를 재구축할 수 있다. 일 실시예에서, 프로세서는 훈련 데이터 관리 모듈을 이용하여, 훈련 데이터를 관리할 수 있다. 훈 련 데이터 관리 모듈은 인공지능 모델을 훈련시키기 위한 훈련 데이터셋을 분할함으로써, 복수의 데이터 서브셋들을 결정할 수 있다. 훈련 데이터 관리 모듈은 컴퓨터 클러스터 내 노드 수에 기초하여, 훈련 데이터셋을 분할하여 생성할 데이터 서브셋들의 개수를 결정할 수 있다. 구체적으로, 훈련 데이터 관리 모듈은 컴퓨터 클러스터 내 노드 수만큼 데이터 서브셋들을 생성할 수 있다. 이 경우, 데이터 서브 셋들의 각각은, 컴퓨터 클러스터 내 노드들의 각각에 대응될 수 있다. 훈련 데이터 관리 모듈은 훈련 데 이터셋 내 훈련 데이터들을 인덱싱하고, 각각의 데이터 서브셋들에 포함될 인덱스 번호를 결정함으로써 데이터 서브셋들을 생성할 수 있다. 또한, 훈련 데이터 관리 모듈은 작업자 노드들의 각각에 대응되는 데 이터 서브셋에 포함되는 데이터 수를 조정하기 위하여, 각 노드에 대응하는 데이터 서브셋에 포함되는 데이터 배치 인덱스 값을 변경할 수 있다. 한편, 도 14에 도시된 서버의 블록도는, 일 실시예를 위한 블록도이다. 블록도의 각 구성요소는 실제 구 현되는 각 장치의 사양에 따라 통합, 추가 또는 생략될 수 있다. 즉 필요에 따라 2 이상의 구성요소가 하나의 구성요소로 합쳐지거나, 혹은 하나의 구성요소가 2 이상의 구성요소로 세분되어 구성될 수 있다. 또한, 각 블록 에서 수행하는 기능은 실시예들을 설명하기 위한 것이며, 그 구체적인 동작이나 장치는 본 발명의 권리범위를 제한하지 아니한다. 일 실시예에 따른 서버의 동작 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현 되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데 이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위 하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행 하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같 은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함 한다. 컴퓨터 판독 가능 매체는, 비일시적(non-transitory) 기록매체의 형태로 제공될 수 있다. 여기서, 비일시 적 기록매체는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐 이며, 이 용어는 데이터가 기록매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않 는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 또한, 개시된 실시예들에 따른 전자 장치의 동작 방법은 컴퓨터 프로그램 제품(computer program product)에 포 함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 S/W 프로그램, S/W 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체를 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 전자 장치의 제조사 또는 전자 마켓(예, 구글 플레이 스토어, 앱 스 토어)을 통해 전자적으로 배포되는 S/W 프로그램 형태의 상품(예, 다운로더블 앱)을 포함할 수 있다. 전자적 배 포를 위하여, S/W 프로그램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저 장 매체는 제조사의 서버, 전자 마켓의 서버, 또는 SW 프로그램을 임시적으로 저장하는 중계 서버의 저장매체가 될 수 있다. 컴퓨터 프로그램 제품은, 서버 및 전자 장치로 구성되는 시스템에서, 서버의 저장매체 또는 전자 장치의 저장매 체를 포함할 수 있다. 또는, 서버 또는 전자 장치와 통신 연결되는 제3 장치(예, 스마트폰)가 존재하는 경우, 컴퓨터 프로그램 제품은 제3 장치의 저장매체를 포함할 수 있다. 또는, 컴퓨터 프로그램 제품은 서버로부터 전 자 장치 또는 제3 장치로 전송되거나, 제3 장치로부터 전자 장치로 전송되는 S/W 프로그램 자체를 포함할 수 있 다. 이 경우, 서버, 전자 장치 및 제3 장치 중 하나가 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방 법을 수행할 수 있다. 또는, 서버, 전자 장치 및 제3 장치 중 둘 이상이 컴퓨터 프로그램 제품을 실행하여 개시 된 실시예들에 따른 방법을 분산하여 실시할 수 있다.예를 들면, 서버가 서버에 저장된 컴퓨터 프로그램 제품을 실행하여, 서버와 통신 연결된 전자 장치가 개시된 실시예들에 따른 방법을 수행하도록 제어할 수 있다. 이상에서 실시예들에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속한다."}
{"patent_id": "10-2021-0108177", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 서버를 마스터노드로하는 컴퓨터 클러스터를 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시예에 따른 서버가 컴퓨터 클러스터를 구축하여 분산 학습을 수행하는 방법을 설명하기 위한 흐름도이다. 도 3은 일 실시예에 따른 서버가 복수의 노드들 중에서 작업자 노드들을 선택하여, 컴퓨터 클러스터를 구축하는 방법을 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 서버가 훈련 데이터셋을 분할함으로써 데이터 서브셋들을 결정하는 방법을 설명하기 위한 도면이다. 도 5는 일 실시예에 따른 데이터 서브셋의 데이터 구성을 설명하기 위한 도면이다. 도 6은 일 실시예에 따른 컴퓨터 클러스터 내 노드들이 데이터 서브셋들을 이용하여 분산 학습을 수행하는 것을 나타낸 도면이다. 도 7은 일 실시예에 따른 서버가 컴퓨터 클러스터를 운용하여 분산 학습을 수행하는 방법을 설명하기 위한 흐름 도이다. 도 8은 분산 학습 과정의 일부인 에폭이 수행됨에 따라, 일 실시예에 따른 서버가 데이터 서브셋들의 각각에 포 함되는 데이터 배치 수를 조정하는 방법을 설명하기 위한 도면이다. 도 9는 도 8을 더 설명하기 위한 도면으로, 분산 학습 과정의 일부인, 컴퓨터 클러스터 내 노드들의 에폭 1 및 에폭 2의 실행을 나타내는 도면이다. 도 10은 도 8을 더 설명하기 위한 도면으로, 분산 학습 과정의 일부인, 제1 작업자 노드에 의한 에폭 1 내지 에 폭 4의 실행을 나타내는 도면이다. 도 11은 분산 학습 과정의 일부인 에폭이 수행됨에 따라, 일 실시예에 따른 서버가 데이터 서브셋들의 각각에 포함되는 데이터 배치 수를 조정하는 다른 방법을 설명하기 위한 도면이다. 도 12는 일 실시예에 서버가 따른 훈련 데이터셋을 분할함으로써 데이터 서브셋들을 결정하는 다른 방법을 설명 하기 위한 도면이다. 도 13은 일 실시예에 따른 서버가 컴퓨터 클러스터를 운용하여 분산 학습을 수행하는 다른 방법을 설명하기 위 한 흐름도이다. 도 14는 일 실시예에 따른 서버의 구성을 나타낸 블록도이다."}
