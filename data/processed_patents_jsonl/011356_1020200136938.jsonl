{"patent_id": "10-2020-0136938", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0123065", "출원번호": "10-2020-0136938", "발명의 명칭": "이미지를 처리하는 전자장치 및 방법", "출원인": "삼성전자주식회사", "발명자": "백우현"}}
{"patent_id": "10-2020-0136938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,제1 이미지 데이터를 생성하는 제1 이미지 센서;제2 이미지 데이터를 생성하는 제2 이미지 센서;이미지를 디스플레이하는 디스플레이; 및하나 이상의 프로세서를 포함하고, 상기 하나 이상의 프로세서는,상기 제1 이미지 데이터를 처리하여 프리뷰 이미지를 생성하고,상기 프리뷰 이미지를 상기 디스플레이 상에 디스플레이 하고,캡처 이벤트의 발생에 응답하여, 상기 제1 이미지 데이터 및 상기 제2 이미지 데이터를 이용하여 썸네일 데이터를 생성하는, 전자 장치."}
{"patent_id": "10-2020-0136938", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시 예는 전자 장치에서 이미지를 처리하기 위한 장치 및 방법에 관한 것이다. 전자 장치는, 제 1 이 미지 데이터를 생성하는 제 1 이미지 센서와 제 2 이미지 데이터를 생성하는 제 2 이미지 센서와 상기 제 1 이미 지 데이터 또는 상기 제 2 이미지 데이터 중 하나 또는 그 이상의 이미지 데이터를 처리하는 하나 또는 그 이상 의 이미지 처리부와 상기 하나 또는 그 이상의 이미지 처리부에 의해 처리된 제 1 이미지 데이터와 제 2 이미지 데이터 중 하나 또는 그 이상의 이미지 데이터를 표시하는 표시부, 및 상기 하나 또는 그 이상의 이미지 처리부 에 의해 처리된 제 1 이미지 데이터와 제 2 이미지 데이터 중 하나 또는 그 이상의 이미지 데이터를 이용하여 섬 네일 데이터를 생성하는 섬네일 생성부를 포함할 수 있으며, 다양한 다른 실시 예들도 가능할 수 있다."}
{"patent_id": "10-2020-0136938", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 다양한 실시 예는 전자 장치에서 이미지를 처리하기 위한 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2020-0136938", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보통신 기술 및 반도체 기술의 발전으로 각종 전자장치들이 다양한 멀티미디어 서비스를 제공하는 멀티미디어 장치로 발전하고 있다. 예를 들어, 휴대용 전자장치는 방송 서비스, 무선 인터넷 서비스 및 음악 재생 서비스 등의 다양한 멀티미디어 서비스를 제공할 수 있다. 전자장치는 이미지 센서들을 통해 획득한 하나 이상의 이미지를 이용하여 다양한 서비스를 제공할 수 있다. 예 를 들어, 전자 장치는 이미지 처리부(ISP: Image Signal Processor)를 이용하여 이미지 센서를 통해 획득한 이 미지 데이터에 대한 레벨 조정, 잡음 제거, 감마 보정, 색상 공간 변환 등과 같은 이미지 처리를 수행하여 다양 한 서비스를 제공할 수 있다."}
{"patent_id": "10-2020-0136938", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "하지만, 전자 장치는 하나의 이미지 처리부를 이용하여 다양한 이미지 처리들을 수행하여 이미지 데이터에 대한 처리 속도가 저하되는 문제가 발생할 수 있다. 본 발명의 실시 예는 전자 장치에서 하나 이상의 이미지 센서를 통해 획득한 이미지 데이터를 효율적으로 처리 하기 위한 장치 및 방법을 제공할 수 있다. 본 발명의 실시 예는 전자 장치에서 하나 이상의 이미지 센서를 통해 획득한 이미지 데이터의 처리 지연을 줄이 기 위한 장치 및 방법을 제공할 수 있다. 본 발명의 실시 예는 전자 장치에서 캡쳐 이미지 데이터에 대한 섬네일 데이터를 효율적으로 생성하기 위한 장 치 및 방법을 제공할 수 있다. 본 발명의 실시 예는 전자 장치에서 이미지 처리부(ISP)와 다른 프로세서를 이용하여 캡쳐 이미지 데이터에 대 한 섬네일 데이터를 생성하기 위한 장치 및 방법을 제공할 수 있다. 본 발명의 실시 예는 전자 장치의 다른 프로세서에서 이미지 처리부(ISP)에서 생성한 하나 이상의 데이터를 이 용하여 캡쳐 이미지 데이터에 대한 섬네일 데이터를 생성하기 위한 장치 및 방법을 제공할 수 있다. 본 발명의 실시 예는 전자 장치에서 이미지 처리부(ISP)와 다른 프로세서를 이용하여 생성한 섬네일 데이터와 캡쳐 이미지 데이터를 연동하여 저장하기 위한 장치 및 방법을 제공할 수 있다. 본 발명의 실시 예는 전자 장치의 다른 프로세서에서 이미지 처리부(ISP)에서 생성한 메타(meta) 데이터를 이용 하여 캡쳐 이미지 데이터와 섬네일 데이터를 연동하여 저장하기 위한 장치 및 방법을 제공할 수 있다."}
{"patent_id": "10-2020-0136938", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따르면, 전자 장치는, 제 1 이미지 데이터를 생성하는 제 1 이미지 센서와, 제 2 이미지 데이터를 생성하는 제 2 이미지 센서와 상기 제 1 이미지 데이터 또는 상기 제 2 이미지 데이터 중 하나 또는 그 이상의 이미지 데이터를 처리하는 하나 또는 그 이상의 이미지 처리부와 상기 하나 또는 그 이상의 이미지 처리부에 의해 처리된 제 1 이미지 데이터와 제 2 이미지 데이터 중 하나 또는 그 이상의 이미지 데이터를 표시 하는 표시부 및 상기 하나 또는 그 이상의 이미지 처리부에 의해 처리된 제 1 이미지 데이터와 제 2 이미지 데 이터 중 하나 또는 그 이상의 이미지 데이터를 이용하여 섬네일 데이터를 생성하는 섬네일 생성부를 포함할 수 있다. 본 발명의 실시 예에 따르면, 전자 장치는, 이미지 데이터를 수신하고, 상기 이미지 데이터를 처리하여, 프리뷰 이미지를 생성하는 하나 또는 그 이상의 프로세서와 상기 하나 또는 그 이상의 프로세서에 의해 생성된 프리뷰 이미지를 표시하는 표시부를 포함하며, 상기 하나 또는 그 이상의 프로세서는, 캡쳐 명령에 대응하는 신호에 응 답하여, 상기 프리뷰 이미지의 적어도 일부를 이용하여 상기 프리뷰 이미지보다 크기가 같거나 작은 이미지를 생성할 수 있다. 본 발명의 실시 예에 따르면, 전자 장치에서 동작 방법은, 다수 개의 이미지 센서들을 이용하여 다수 개의 이미 지 데이터들을 생성하는 과정과, 하나 또는 그 이상의 이미지 처리부를 통해 상기 다수 개의 이미지 데이터들을 표시부에 표시 가능한 포맷으로 변환하는 과정, 및 상기 이미지 처리부와 별도의 다른 모듈에서 상기 이미지 처 리부에서 변환한 상기 표시 가능한 포맷의 이미지 데이터들을 이용하여 섬네일 데이터를 생성하는 과정을 포함 할 수 있다. 본 발명의 실시 예에 따르면, 전자 장치의 동작 방법은, 하나 또는 그 이상의 이미지 데이터를 저장하는 과정과 하나 또는 그 이상의 프로세서를 통해 상기 하나 또는 그 이상의 이미지 데이터 중 하나 또는 그 이상의 이미지 데이터를 프리뷰 이미지로 변환하는 과정과 캡쳐 명령을 나타내는 신호에 응답하여, 상기 프로세서를 통해 상기 프리뷰 이미지의 적어도 일부를 이용하여, 상기 프리뷰 이미지보다 크기가 작은 이미지를 생성하는 과정을 포함 할 수 있다. 본 발명의 실시 예에 따르면, 전자 장치는 이미지 데이터를 생성하는 하나 또는 그 이상의 이미지 센서와 상기 하나 또는 그 이상의 이미지 센서에서 생성된 이미지 데이터를 처리하는 인터페이스를 포함하며, 상기 인터페이 스는, 상기 이미지 데이터를 하나 또는 그 이상의 모듈로 전송하고, 상기 하나 또는 그 이상의 모듈, 해당 모듈 의 이미지 데이터 처리 방식에 기반하여 이미지 데이터의 형식을 변경할 수 있다."}
{"patent_id": "10-2020-0136938", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이 전자 장치에서 이미지 처리부(ISP)와 다른 프로세서를 이용하여 생성한 섬네일 데이터와 캡쳐 데이터를 연동하여 저장함으로써, 이미지 처리부의 이미지 처리 속도를 향상시킬 수 있다. 전자 장치의 다른 프로세서에서 이미지 처리부에서 생성한 메타 데이터를 이용하여 섬네일 데이터를 생성함으로 써, 섬네일 데이터에 대한 처리 속도를 향상시킬 수 있다. 여기서, 메타 데이터는 이미지 데이터의 프레임 식별 자(frame ID), 이미지 획득 시점(time stamp), 초점 정보(Auto Focus 정보), 이미지 설정 정보(EXIF: Exchangeable Image File Format), 플래쉬 정보 등을 포함할 수 있다."}
{"patent_id": "10-2020-0136938", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명(present disclosure)을 설명할 수 있다. 본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시 예를 가질 수 있는 바, 특정 실시 예들이 도면에 예시되고 관련된 상세한 설명이 기재 되어 있다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경 및/또는 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관 련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용되었다. 본 발명 가운데 사용될 수 있는 \"포함한다\" 또는 \"포함할 수 있다\" 등의 표현은 개시된 해당 기능, 동작 또는 구성요소 등의 존재를 가리키며, 추가적인 하나 이상의 기능, 동작 또는 구성요소 등을 제한하지 않는다. 또한, 본 발명에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 본 발명에서 \"또는\" 등의 표현은 함께 나열된 단어들의 어떠한, 그리고 모든 조합을 포함한다. 예를 들어, \"A 또는 B\"는, A를 포함할 수도, B를 포함할 수도, 또는 A 와 B 모두를 포함할 수도 있다. 본 발명 가운데 \"제 1\", \"제 2\", \"첫째\" 또는 \"둘째\" 등의 표현들이 본 발명의 다양한 구성요소들을 수식할 수 있지만, 해당 구성요소들을 한정하지 않는다. 예를 들어, 상기 표현들은 해당 구성요소들의 순서 및/또는 중요 도 등을 한정하지 않는다. 상기 표현들은 한 구성요소를 다른 구성요소와 구분 짓기 위해 사용될 수 있다. 예를 들어, 제1 사용자 기기와 제 2 사용자 기기는 모두 사용자 기기이며, 서로 다른 사용자 기기를 나타낸다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제 1 구성요소는 제 2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제 1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해될 수 있어야 할 것이다. 본 발명에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 발명에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 본 발명의 실시 예에 따른 전자 장치는 카메라 기능을 포함하는 장치일 수 있다. 예를 들면, 전자 장치는 스마 트 폰(smartphone), 태블릿 PC(tablet personal computer), 이동전화기(mobile phone), 화상전화기, 전자북 리 더기(e-book reader), 데스크탑 PC(desktop personal computer), 랩탑 PC(laptop personal computer), 넷북 컴 퓨터(netbook computer), PDA(personal digital assistant), PMP(portable multimedia player), MP3 플레이어, 모바일 의료기기, 카메라(camera), 또는 웨어러블 장치(wearable device)(예: 전자 안경과 같은 head-mounted-device(HMD), 전자 의복, 전자 팔찌, 전자 목걸이, 전자 앱세서리(appcessory), 전자 문신, 또는 스마트 와치(smartwatch))중 적어도 하나를 포함할 수 있다. 어떤 실시 예들에 따르면, 전자 장치는 카메라 기능을 갖춘 스마트 가전 제품(smart home appliance)일 수 있다. 예를 들자면, 스마트 가전 제품은 텔레비전, DVD(digital video disk) 플레이어, 오디오, 냉장고, 에어컨, 청소기, 오븐, 전자레인지, 세탁기, 공기 청정기, 셋톱 박스(set-top box), TV 박스(예를 들면, 삼성 HomeSyncTM, 애플TVTM, 또는 구글 TVTM), 게임 콘솔(game consoles), 전자 사전, 전자 키, 캠코더(camcorder), 또는 전자 액자 중 적어도 하나를 포함할 수 있다. 어떤 실시 예들에 따르면, 전자 장치는 각종 의료기기(예: MRA(magnetic resonance angiography), MRI(magnetic resonance imaging), CT(computed tomography), 촬영기, 초음파기 등), 네비게이션(navigation) 장치, GPS 수신기(global positioning system receiver), EDR(event data recorder), FDR(flight data recorder), 자동차 인포테인먼트(infotainment) 장치, 선박용 전자 장비(예: 선박용 항법 장치 및 자이로 콤파 스 등), 항공 전자기기(avionics), 보안 기기, 또는 산업용 또는 가정용 로봇 중 적어도 하나를 포함할 수 있다. 어떤 실시 예들에 따르면, 전자 장치는 카메라 기능을 갖춘 가구(furniture) 또는 건물/구조물의 일부, 전자 보 드(electronic board), 전자 사인 입력장치(electronic signature receiving device), 프로젝터(projector) 또 는 각종 계측기기(예: 수도, 전기, 가스, 또는 전파 계측 기기 등) 중 적어도 하나를 포함할 수 있다. 본 발명 에 따른 전자 장치는 전술한 다양한 장치들 중 하나 또는 그 이상의 조합일 수 있다. 또한, 본 발명에 따른 전 자 장치는 전술한 기기들에 한정되지 않음은 당업자에게 자명하다. 이하 첨부된 도면을 참조하여 다양한 실시 예에 따른 전자 장치에 대해서 살펴본다. 다양한 실시 예에서 이용되 는 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전자 장치)를 지칭할 수 있다. 이하 본 발명의 실시 예는 전자 장치에서 다수 개의 이미지 센서들을 통해 획득한 이미지 데이터들을 처리하기 위한 기술에 대해 설명한다. 도 1a는 본 발명의 실시 예에 따른 전자 장치를 포함하는 네트워크 환경을 도시하고 있다. 도 1a를 참조하면 전자 장치는 버스, 프로세서, 메모리, 입출력 인터페이스, 디스플 레이, 통신 인터페이스, 이미지 처리 모듈 및 이미지 센서 모듈을 포함할 수 있다. 버스는 전술한 구성요소들을 서로 연결하고, 전술한 구성요소들 간의 통신 신호(예: 제어 메시지)를 전달 하는 회로일 수 있다. 프로세서는, 예를 들면, 버스를 통해 전술한 다른 구성요소들(예: 메모리, 입출력 인터페이스 , 디스플레이, 통신 인터페이스, 이미지 처리 모듈 또는 이미지 센서 모듈)로부터 명 령을 수신하여, 수신된 명령을 해독하고, 해독된 명령에 따른 연산이나 데이터 처리를 실행할 수 있다. 메모리는 프로세서 또는 다른 구성요소들(예: 입출력 인터페이스, 디스플레이, 통신 인터 페이스, 이미지 처리 모듈, 이미지 센서 모듈 등)로부터 수신되거나 프로세서 또는 다른 구성요소들에 의해 생성된 명령 또는 데이터를 저장할 수 있다. 메모리는, 예를 들면, 커널, 미들웨 어, 어플리케이션 프로그래밍 인터페이스(API: application programming interface) 또는 어플리케 이션 등의 프로그래밍 모듈들을 포함할 수 있다. 전술한 각각의 프로그래밍 모듈들은 소프트웨어, 펌웨어, 하드웨어 또는 이들 중 적어도 둘 이상의 조합으로 구성될 수 있다. 커널은 나머지 다른 프로그래밍 모듈들, 예를 들면, 미들웨어, API 또는 어플리케이션에 구현된 동작 또는 기능을 실행하는 데 사용되는 시스템 리소스들(예: 버스, 프로세서 또는 메모리 등)을 제어 또는 관리할 수 있다. 또한, 커널은 미들웨어, API 또는 어플리케이션이전자 장치의 개별 구성요소에 접근하여 제어 또는 관리할 수 있는 인터페이스를 제공할 수 있다. 미들웨어는 API 또는 어플리케이션이 커널과 통신하여 데이터를 주고받을 수 있도록 중개 역할을 수행할 수 있다. 또한, 미들웨어는 어플리케이션로부터 수신된 작업 요청들과 관련하여, 예를 들면, 어플리케이션 중 적어도 하나의 어플리케이션에 전자 장치의 시스템 리소스(예: 버스, 프 로세서 또는 메모리 등)를 사용할 수 있는 우선 순위를 배정하는 등의 방법을 이용하여 작업 요청에 대한 제어(예: 스케쥴링 또는 로드 밸런싱)을 수행할 수 있다. API는 어플리케이션이 커널 또는 미들웨어에서 제공되는 기능을 제어하기 위한 인터페이 스로, 예를 들면, 파일 제어, 창 제어, 화상 처리 또는 문자 제어 등을 위한 적어도 하나의 인터페이스 또는 함 수(예: 명령어)를 포함할 수 있다. 다양한 실시예에 따르면, 어플리케이션은 SMS/MMS 어플리케이션, 이메일 어플리케이션, 달력 어플리케이션, 알람 어플리케이션, 건강 관리(health care) 어플리케이션(예: 운동량 또는 혈당 등을 측정하는 어플리케이션) 또는 환경 정보 어플리케이션(예: 기압, 습도 또는 온도 정보 등을 제공하는 어플리케이션) 등을 포함할 수 있다. 추가적으로 또는 대체적으로, 어플리케이션은 전자 장치와 외부 전자 장치(예: 전자 장치 102 또는 전자 장치 104) 사이의 정보 교환과 관련된 어플리케이션일 수 있다. 정보 교환과 관련된 어플리 케이션은, 예를 들어, 외부 전자 장치에 특정 정보를 전달하기 위한 알림 전달(notification relay) 어플리케이 션, 또는 외부 전자 장치를 관리하기 위한 장치 관리(device management) 어플리케이션을 포함할 수 있다. 예를 들면, 알림 전달 어플리케이션은 전자 장치의 다른 어플리케이션(예: SMS/MMS 어플리케이션, 이메일 어플리케이션, 건강 관리 어플리케이션 또는 환경 정보 어플리케이션 등)에서 발생한 알림 정보를 외부 전자 장 치(예: 전자 장치 또는 전자 장치)로 전달하는 기능을 포함할 수 있다. 추가적으로 또는 대체적으로, 알림 전달 어플리케이션은, 예를 들면, 외부 전자 장치(예: 전자 장치 또는 전자 장치)로부터 알림 정보를 수신하여 사용자에게 제공할 수 있다. 장치 관리 어플리케이션은, 예를 들면, 전자 장치와 통신하 는 외부 전자 장치(예: 전자 장치 또는 전자 장치)의 적어도 일부에 대한 기능(예: 외부 전자 장치 자체(또는, 일부 구성 부품)의 턴 온(turn on)/턴 오프(turn off) 또는 디스플레이의 밝기(또는, 해상도) 조 절), 외부 전자 장치에서 동작하는 어플리케이션 또는 외부 전자 장치에서 제공되는 서비스(예: 통화 서비스 또 는 메시지 서비스)을 관리(예: 설치, 삭제 또는 업데이트)할 수 있다. 다양한 실시예에 따르면, 어플리케이션은 외부 전자 장치(예: 전자 장치 또는 전자 장치)의 속 성(예: 전자 장치의 종류)에 따라 지정된 어플리케이션을 포함할 수 있다. 예를 들어, 외부 전자 장치가 MP3 플 레이어인 경우, 어플리케이션은 음악 재생과 관련된 어플리케이션을 포함할 수 있다. 유사하게, 외부 전자 장치가 모바일 의료기기인 경우, 어플리케이션은 건강 관리와 관련된 어플리케이션을 포함할 수 있다. 한 실시예에 따르면, 어플리케이션은 전자 장치에 지정된 어플리케이션 또는 외부 전자 장치(예: 서버 , 전자 장치 또는 전자 장치)로부터 수신된 어플리케이션 중 적어도 하나를 포함할 수 있다. 입출력 인터페이스는, 센서(예: 가속도 센서, 자이로 센서) 또는 입력 장치(예: 키보드 또는 터치 스크린)를 통하여 사용자로부터 입력된 명령 또는 데이터를, 예를 들면, 버스를 통해 프로세서, 메모 리, 통신 인터페이스, 또는 이미지 처리 모듈에 전달할 수 있다. 예를 들면, 입출력 인터페이스 는 터치 스크린을 통하여 입력된 사용자의 터치에 대한 데이터를 프로세서로 제공할 수 있다. 또한, 입출력 인터페이스는, 예를 들면, 버스을 통해 프로세서, 메모리, 통신 인터페이스, 또는 이미지 처리 모듈로부터 수신된 명령 또는 데이터를 출력 장치(예: 스피커 또는 디스플레이)를 통하 여 출력할 수 있다. 예를 들면, 입출력 인터페이스는 프로세서를 통하여 처리된 음성 데이터를 스피 커를 통하여 사용자에게 출력할 수 있다. 디스플레이는 사용자에게 각종 정보(예: 멀티미디어 데이터 또는 텍스트 데이터 등)을 표시할 수 있다. 통신 인터페이스는 전자 장치와 외부 장치(예: 전자 장치, 전자 장치, 또는 서버) 간의 통신을 연결할 수 있다. 예를 들면, 통신 인터페이스은 네트워크 통신(예: 인터넷(Internet), LAN(local area network), WAN(wire area network), telecommunication network, cellular network, satellite network 또는 POTS(plain old telephone service) 등), 근거리 통신 164(예: wifi(wireless fidelity), BT(Bluetooth), NFC(near field communication), 또는 유선 통신(예: USB(universal serial bus), HDMI(high definition multimedia interface), RS-232(recommended standard 232) 또는 POTS(plain old telephone service) 등)을 지원할 수 있다. 한 실시예에 따르면, 전자 장치와 외부 장치 간의 통신을 위한프로토콜(예: 근거리 통신 프로토콜, 네트워크 통신 프로토콜 또는 유선 통신 프로토콜)은 API 또는 미들 웨어 중 적어도 하나에서 지원될 수 있다. 전자 장치(102, 104) 각각은 전자 장치와 동일한(예: 같은 타입의) 장치이거나 또는 다른(예: 다른 타입의) 장치일 수 있다. 이미지 센서 모듈은 피사체에 대한 촬영을 통해 획득한 이미지 데이터를 이미지 처리 모듈로 제공할 수 있다. 이때, 이미지 센서 모듈은 전자 장치에 기능적으로 연결된 적어도 하나의 이미지 센서 모듈 을 포함할 수 있다. 이미지 처리 모듈은 이미지 센서 모듈 또는 외부 전자 장치(102, 104)로부터 제공받은 이미지 데이터 에 대한 이미지 처리를 수행할 수 있다. 예를 들어, 이미지 처리 모듈은 이미지 데이터에 대한 레벨 조정 (level adjustment), 잡음 제거(noise reduction), 감마 보정(gamma correction), 표시부에 표시 가능한 포맷으로 변환 중 하나 또는 그 이상의 이미지 처리를 수행할 수 있다. 이미지 처리 모듈은 이미지 처리한 이미지 데이터들 메모리에 저장하거나 디스플레이 에 표시하도록 제어할 수 있다. 예컨대, 이미지 처 리 모듈은 디스플레이 에 표시되는 이미지 데이터(예: YUV 데이터) 및 해당 이미지 데이터에 대한 메 타 데이터를 메모리로 전송할 수 있다. 여기서, 디스플레이에 표시 가능한 포맷으로 변환하는 이미지 처리는 색상 공간 변환(color space conversion)을 포함할 수 있다. 이미지 처리 모듈은 적어도 하나의 이미지 센서 모듈을 통해 획득한 이미지 데이터들 중 적어도 두 개의 이미지 데이터들을 선택하여 합성할 수 있다. 예컨대, 이미지 처리 모듈은 이미지 데이터들에 대응하 는 이미지 획득 시점(time stamp) 또는 이미지 처리 지연 시간 및 이미지 획득 시점을 이용하여 적어도 두 개의 이미지 데이터들을 선택하여 합성할 수 있다. 다른 예를 들어, 캡쳐 이벤트가 발생한 경우, 이미지 처리 모듈은 메모리에 저장된 이미지 데이터들 (예: 프리뷰 이미지) 및 각각의 이미지 데이터에 대한 메타 데이터를 이용하여 캡쳐 이미지 데이터에 대한 섬네 일(thumbnail) 데이터를 생성할 수 있다. 예컨대, 이미지 처리 모듈은 이미지 센서 모듈로부터 제공 받은 이미지 데이터들에 대한 이미지 처리를 수행하는 모듈과 논리적 또는 물리적으로 분리된 다른 모듈을 이용 하여 캡쳐 이미지 데이터에 대한 섬네일 데이터를 생성할 수 있다. 섬네일 데이트는 이미지의 검색을 용이하게 하거나 해당 이미지를 사용자가 쉽게 인지할 수 있도록 해당 이미지의 축소한 이미지 데이터를 나타낼 수 있다. 도 1b는 본 발명의 실시 예에 따른 전자 장치의 블록도를 도시하고 있다. 도 1b를 참조하면, 전자 장치는 프로세서, 메모리, 이미지 센서들(180-1 내지 180-N), 입력부 (입력 인터페이스), 표시부(디스플레이)를 포함할 수 있다. 여기서, 프로세서는 응용프로그램 프로세서(AP: Application Processor)를 포함할 수 있다. 프로세서는 전자장치가 다양한 서비스를 제공하도록 제어할 수 있다. 프로세서는 전자장치에 포함되는 하나 이상의 다른 구성요소(예: 메모리, 이미지 센서들(180-1 내지 180-N), 표시부, 입력부)로부터 수신된 명령을 해독하고, 해독된 명령에 따른 연산이나 데이터 처리를 실행할 수 있다. 예를 들어, 프로세서는 이미지 센서들(180-1 내지 180-N)로부터 제공받은 이미지 데이터들에 대한 레벨 조정(level adjustment), 잡음 제거(noise reduction), 감마 보정(gamma correction), 표시부에 표시 가능한 포맷으로 변환 중 하나 또는 그 이상의 이미지 처리를 수행할 수 있다. 프로세서 는 이미지 처리한 이미지 데이터들 메모리에 저장하거나 표시부에 표시하도록 제어할 수 있다. 예컨대, 프로세서는 표시부에 표시되는 이미지 데이터(예: YUV 데이터) 및 해당 이미지 데이터에 대 한 메타 데이터를 메모리로 전송할 수 있다. 여기서, 표시부에 표시 가능한 포맷으로 변환하는 이미 지 처리는 색상 공간 변환(color space conversion)을 포함할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 프로그램을 실행하여 전자장치가 다양한 멀티미디어 서비스를 제공하도록 제어할 수 있다. 예를 들어, 프로세서는 메모리에 저장된 프로그램을 실행하여 이미지 센서들(180-1 내지 180-N)을 통해 획득한 이미지 데이터들 중 적어도 두 개의 이미지 데이터들을 선택하 여 합성할 수 있다. 예컨대, 프로세서는 이미지 데이터들에 대응하는 이미지 획득 시점(time stamp) 또는 이미지 처리 지연 시간 및 이미지 획득 시점을 이용하여 적어도 두 개의 이미지 데이터들을 선택하여 합성할 수 있다. 다른 예를 들어, 캡쳐 이벤트가 발생한 경우, 프로세서는 메모리에 저장된 이미지 처리된 이미지 데 이터들(예: 프리뷰 이미지) 및 각각의 이미지 데이터에 대한 메타 데이터를 이용하여 캡쳐 이미지 데이터에 대 한 섬네일(thumbnail) 데이터를 생성할 수 있다. 예컨대, 프로세서는 이미지 센서들(180-1 내지 180-N)로부터 제공받은 이미지 데이터들에 대한 이미지 처리를 수행하는 모듈(예: ISP(Image Signal Processor))과 논리 적 또는 물리적으로 분리된 다른 모듈을 이용하여 캡쳐 이미지 데이터에 대한 섬네일 데이터를 생성할 수 있다. 메모리는 전자장치에 포함되는 하나 이상의 구성 요소로부터 수신되거나 하나 이상의 구성 요소에 의 해 생성된 명령 또는 데이터를 저장할 수 있다. 예를 들어, 메모리는 내장 메모리 또는 외장 메모리를 포 함할 수 있다. 내장 메모리는, 예를 들면, 휘발성 메모리(예를 들면, DRAM(dynamic RAM), SRAM(static RAM), SDRAM(synchronous dynamic RAM) 등) 또는 비휘발성 메모리(non-volatile Memory), 예를 들면, OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, NAND flash memory, NOR flash memory 등) 중 적어도 하나를 포함할 수 있다. 외장 메모리는 flash drive, 예를 들면, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital) 또는 Memory Stick 중 적어도 하나를 포함할 수 있다. 외장 메모리는 다양한 인터페이스를 통하여 전자 장치 과 기능적으로 연결될 수 있다. 이미지 센서들(180-1 내지 180-N)은 피사체에 대한 촬영을 통해 획득한 이미지 데이터를 프로세서로 제공 할 수 있다. 이때, 이미지 센서들(180-1 내지 180-N)은 MIPI(Mobile Industry Processor Interface), MDDI(Mobile Display Digital Interface)와 같은 직렬 인터페이스와 병렬 버스(parallel bus)와 같은 병렬 인 터페이스를 통해 프로세서로 이미지 데이터를 전송할 수 있다. 여기서, 제 1 이미지 센서(180-1)는 전자장 치의 전면에 위치하고, 제 N 이미지 센서(180-N)는 전자장치의 후면에 위치할 수 있다. 입력부는 사용자에 의해 입력되는 명령 또는 데이터를 프로세서 또는 메모리에 전송할 수 있다. 예를 들어, 입력부는 터치 입력부, 펜 센서(pen sensor), 키(key) 또는 초음파 입력 장치(ultrasonic)를 포함할 수 있다. 표시부는 전자장치의 상태 정보, 정지 영상, 동영상 또는 데이터와 같이 그래픽으로 사용자 인터페이 스를 제공할 수 있다. 예를 들어, 표시부는 프로세서로부터 제공받은 하나 이상의 이미지를 표시할 수 있다. 다른 예를 들어, 표시부는 프로세서에서 이미지 획득 시점 또는 이미지 획득 시점 및 이미 지 처리 지연 시간에 기반하여 선택한 적어도 하나의 이미지를 표시할 수 있다. 미 도시되었지만, 전자장치는 음성 통신 또는 데이터 통신을 통해 다른 전자장치 또는 서버와 통신을 연결 할 수 있는 통신부를 더 포함할 수 있다. 여기서, 통신부는 서로 다른 통신 네트워크를 지원하는 다수 개의 통 신 서브 모듈들로 구분될 수도 있다. 상술한 실시 예에서 전자 장치는 다수 개의 이미지 센서들(180-1 내지 180-N)을 포함할 수 있다. 이때, 다 수 개의 이미지 센서들(180-1 내지 180-N) 중 하나 또는 그 이상의 이미지 센서는 전자 장치에 선택적으로 연결될 수 있다. 예를 들어, 다수 개의 이미지 센서들(180-1 내지 180-N) 중 하나 또는 그 이상의 이미지 센서 는 유선 인터페이스를 통해 전자 장치에 선택적으로 연결될 수 있다. 다른 예를 들어, 다수 개의 이미지 센서들(180-1 내지 180-N) 중 하나 또는 그 이상의 이미지 센서는 블루투스, 무선랜과 같은 무선 인터페이스를 통해 전자 장치와 선택적으로 연결될 수 있다. 도 2는 본 발명의 실시 예에 따른 프로세서의 상세 블록도를 도시하고 있다. 도 2를 참조하면, 프로세서는 이미지 처리부(ISP: Image Signal Processor), 표시 제어부, 이 미지 생성 제어부, 섬네일 생성부 및 동영상 생성부를 포함할 수 있다. 이미지 처리부는 각각의 이미지 센서(180-1 또는 180-N)로부터 제공받은 이미지 데이터에 대한 레벨 조정, 잡음 제거, 감마 보정, 색상 공간 변환 중 하나 또는 그 이상의 이미지 처리를 수행할 수 있다. 이미지 처리부 는 이미지 처리한 이미지 데이터들을 메모리 또는 표시 제어부 중 하나 이상으로 전송할 수 있 다. 예를 들어, 이미지 처리부는 표시부에 표시되는 이미지 데이터(예: YUV 데이터) 및 해당 이미지 데이터에 대한 메타 데이터를 메모리로 전송할 수 있다. 표시 제어부는 표시부를 통해 그래픽으로 사용자 인터페이스를 제공하도록 제어할 수 있다. 예를 들 어, 표시 제어부는 이미지 처리부 또는 메모리로부터 제공받은 이미지 데이터(예: 프리뷰 이미 지)를 표시부에 표시하도록 제어할 수 있다. 예컨대, 표시 제어부는 이미지 처리부를 통해 이미 지 센서들(180-1 내지 180-N)로부터 제공받은 이미지 데이터들을 표시부에 함께 표시하도록 제어할 수 있 다. 이미지 생성 제어부는 이미지 센서들(180-1 내지 180-N)을 통해 획득한 이미지 데이터들 중 적어도 두 개 의 이미지 데이터들을 선택하여 합성할 수 있다. 예를 들어, 캡쳐 이벤트가 발생한 경우, 이미지 생성 제어부 는 메모리에 저장된 이미지 데이터들의 이미지 획득 시점 또는 이미지 처리 지연 시간 및 이미지 획 득 시점을 이용하여 적어도 두 개의 이미지 데이터들을 선택하여 합성할 수 있다. 섬네일 생성부는 메모리에 저장된 이미지 처리된 이미지 데이터들(예: 프리뷰 이미지) 및 각각의 이 미지 데이터에 대한 메타 데이터를 이용하여 섬네일(thumbnail) 데이터를 생성할 수 있다. 예를 들어, 캡쳐 이 벤트가 발생한 경우, 섬네일 생성부는 메모리에 저장된 이미지 데이터의 YUV 데이터 및 해당 이미지 데이터에 대한 메타 데이터를 이용하여 섬네일(thumbnail) 데이터를 생성할 수 있다. 예컨대, 다수 개의 이미지 센서들(180-1 내지 180-N)을 통해 획득한 적어도 두 개의 이미지 데이터들을 합성하여 캡쳐 이미지 데이터를 생 성하는 경우, 섬네일 생성부는 각 이미지 데이터의 처리 지연 시간에 기반하여 이미지 데이터들을 동기화 하여 섬네일 데이터를 생성할 수 있다. 이때, 섬네일 생성부는 메타 데이터에 포함된 이미지 획득 시점 또 는 프레임 식별 정보를 이용하여 캡쳐 이미지 데이터와 섬네일 데이터를 연동하여 메모리에 저장할 수 있 다. 동영상 생성부는 메모리에 저장된 이미지 처리된 이미지 데이터들을 부호화(encoding)하여 동영상 데 이터를 생성할 수 있다. 예를 들어, 동영상 생성부는 비디오 선 처리부와 비디오 부호화부를 포함할 수 있 다. 비디오 선 처리부는 메모리에 저장된 이미지 처리된 이미지 데이터들에 대한 줌(zoom), 회전(rotate), 색상 공간 변환 및 플립(flip)과 같은 선처리를 수행하여 메모리에 저장할 수 있다. 비디오 부호화부는 기 설정된 부호화 방식에 따라 비디오 선 처리부에 의해 선처리되어 메모리에 저장된 이미지 데이터를 부호화 하여 동영상 데이터를 생성할 수 있다. 미 도시되었지만, 프로세서는 이미지 센서들(180-1 내지 180-N) 로부터 제공받은 하나 또는 그 이상의 이 미지 데이터에 이미지 획득 시점(time stamp)을 설정할 수 있는 시간 설정부를 더 포함할 수 있다. 예를 들어, 시간 설정부는 이미지 센서들(180-1 내지 180-N) 로부터 제공받은 각각의 이미지 데이터와 대응되는 시간을 매 프레임 단위로 해당 이미지 데이터의 메타 데이터에 기록할 수 있다. 다른 예를 들어, 이미지 센서들(180-1 내 지 180-N) 중 전자 장치에 선택적으로 연결될 수 있는 하나 또는 그 이상의 이미지 센서가 존재하는 경우, 시간 설정부는 전자 장치에 연결된 하나 또는 그 이상의 이미지 센서로부터 제공받은 하나 또는 그 이상의 이미지 데이터의 메타 데이터에 이미지 획득 시점을 설정할 수 있다. 이때, 전자 장치에 선택적으로 연결 될 수 있는 하나 또는 그 이상의 이미지 센서를 통해 획득한 이미지는 각각의 이미지 센서에 포함된 별도의 모 듈에 의해 이미지 획득 시점이 설정될 수 있다. 상술한 실시 예에서 프로세서는 하나의 이미지 처리부를 통해 이미지 센서들(180-1 내지 180-N)로부 터 제공받은 이미지 데이터들을 처리할 수 있다. 다른 실시 예에서 프로세서는 다수 개의 이미지 처리부들을 포함하여 각각의 이미지 센서(180-1 또는 180- N)로부터 제공받은 이미지 데이터를 처리할 수 있다. 도 3은 본 발명의 실시 예에 따른 전자 장치의 블록도를 도시하고 있다. 도 3을 참조하면 전자 장치는 프로세서, 메모리, 이미지 센서들(330-1 내지 330-N), 외부 이미 지 처리부들(340-1 내지 340-(N-1)), 입력부, 표시부를 포함할 수 있다. 여기서, 프로세서는 응용프로그램 프로세서(AP)를 포함할 수 있다. 프로세서는 전자장치가 다양한 서비스를 제공하도록 제어할 수 있다. 프로세서는 전자장치에 포함되는 하나 이상의 다른 구성요소(예: 메모리, 제 1 이미지 센서 (330-1), 외부 이미지 처리부들(340-1 내지 340-(N-1)), 입력부, 표시부)로부터 수신된 명령을 해독 하고, 해독된 명령에 따른 연산이나 데이터 처리를 실행할 수 있다. 예를 들어, 프로세서는 제 1 이미지 센서(330-1)로부터 제공받은 이미지 데이터에 대한 레벨 조정, 잡음 제거, 감마 보정, 표시부에 표시 가능 한 포맷으로 변환 중 하나 또는 그 이상의 이미지 처리를 수행할 수 있다. 프로세서는 이미지 처리한 이미 지 데이터를 메모리에 저장하거나, 표시부에 표시하도록 제어할 수 있다. 예컨대, 프로세서는 표시부에 표시되는 이미지 데이터(예: YUV 데이터) 및 해당 이미지 데이터에 대한 메타 데이터를 메모리 로 전송할 수 있다. 다른 예를 들어, 프로세서는 외부 이미지 처리부들(340-1 내지 340-(N-1))을 통 해 메모리에 저장된 이미지들을 표시부에 표시 가능한 포맷으로 변환하여 표시부에 표시하도록 제어할 수 있다. 여기서, 표시부에 표시 가능한 포맷으로 변환하는 이미지 처리는 색상 공간 변환을 포함할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 프로그램을 실행하여 전자장치가 다양한 멀티미디어 서비스를 제공하도록 제어할 수 있다. 예를 들어, 프로세서는 메모리에 저장된 프로그램을 실행하여 이미지 센서들(330-1 내지 330-N)을 통해 획득한 이미지 데이터들 중 적어도 두 개의 이미지 데이터들을 선택하 여 합성할 수 있다. 예컨대, 프로세서는 이미지 데이터들에 대응하는 이미지 획득 시점 또는 이미지 처리 지연 시간 및 이미지 획득 시점을 이용하여 적어도 두 개의 이미지 데이터들을 선택하여 합성할 수 있다. 다른 예를 들어, 캡쳐 이벤트가 발생한 경우, 프로세서는 메모리에 저장된 이미지 처리된 이미지 데 이터들(예: 프리뷰 이미지) 및 각각의 이미지 데이터에 대한 메타 데이터를 이용하여 캡쳐 이미지 데이터에 대 한 섬네일 데이터를 생성할 수 있다. 예컨대, 프로세서는 제 1 이미지 센서(330-1)로부터 제공받은 이미지 데이터들에 대한 이미지 처리를 수행하는 프로세서의 내부 모듈(예: ISP)과 논리적 또는 물리적으로 구분 되는 다른 모듈을 이용하여 캡쳐 이미지 데이터에 대한 섬네일 데이터를 생성할 수 있다. 이때, 다른 모듈은 프 로세서의 내부에서 이미지를 처리하는 내부 모듈과 논리적 또는 물리적으로 구분되거나, 프로세서와 물리적으로 구분될 수 있다. 메모리는 전자장치에 포함되는 하나 이상의 구성 요소로부터 수신되거나 하나 이상의 구성 요소에 의 해 생성된 명령 또는 데이터를 저장할 수 있다. 이미지 센서들(330-1 내지 330-N)은 피사체에 대한 촬영을 통해 획득한 수집 이미지를 프로세서로 제공할 수 있다. 이때, 이미지 센서들(330-1 내지 330-N)은 MIPI, MDDI와 같은 직렬 인터페이스와 병렬 버스와 같은 병 렬 인터페이스를 통해 프로세서 또는 외부 이미지 처리부(340-1 내지 340-(N-1))로 이미지를 전송할 수 있 다. 여기서, 제 1 이미지 센서(330-1)는 전자장치의 전면에 위치하고, 제 N 이미지 센서(330-N)는 전자장 치의 후면에 위치할 수 있다. 외부 이미지 처리부들(340-1 내지 340-(N-1))은 이미지 센서들(330-2 내지 330-N)로부터 제공받은 이미지에 대 한 레벨 조정, 잡음 제거, 감마 보정과 같은 이미지 처리하여 프로세서를 통해 메모리에 저장하도록 제어할 수 있다. 여기서, 외부 이미지 처리부들(340-1 내지 340-(N-1))은 이미지 센서들(330-2 내지 330-N)로부 터 제공받은 이미지에 대한 이미지 데이터에 이미지 획득 시점(time stamp)을 설정할 수 있는 시간 설정부를 더 포함할 수 있다. 예를 들어, 시간 설정부는 이미지 센서들(330-2 내지 330-N)로부터 제공받은 각각의 이미지 데 이터와 대응되는 시간을 매 프레임 단위로 해당 이미지 데이터의 메타 데이터에 기록할 수 있다. 입력부는 사용자에 의해 입력되는 명령 또는 데이터를 프로세서 또는 메모리에 전송할 수 있다. 예를 들어, 입력부는 터치 입력부, 펜 센서, 키 또는 초음파 입력 장치를 포함할 수 있다. 표시부는 전자장치의 상태 정보, 정지 영상, 동영상 또는 데이터와 같은 그래픽으로 사용자 인터페이 스를 제공할 수 있다. 예를 들어, 표시부는 프로세서로부터 제공받은 하나 이상의 이미지 데이터를 표시할 수 있다. 다른 예를 들어, 표시부는 프로세서에서 이미지 획득 시점 또는 이미지 획득 시점 및 이미지 처리 지연 시간에 기반하여 선택한 적어도 두 개의 이미지 데이터들을 표시할 수 있다. 미 도시되었지만, 전자장치는 음성 통신 또는 데이터 통신을 통해 다른 전자장치 또는 서버와 통신을 연결 할 수 있는 통신부를 더 포함할 수 있다. 여기서, 통신부는 서로 다른 통신 네트워크를 지원하는 다수 개의 통 신 서브 모듈들로 구분될 수도 있다. 상술한 실시 예에서 전자 장치는 다수 개의 이미지 센서들(330-1 내지 330-N)을 포함할 수 있다. 이때, 다 수 개의 이미지 센서들(330-1 내지 330-N) 중 하나 또는 그 이상의 이미지 센서는 전자 장치에 선택적으로 연결될 수 있다. 예를 들어, 다수 개의 이미지 센서들(330-1 내지 330-N) 중 하나 또는 그 이상의 이미지 센서 는 유선 인터페이스를 통해 전자 장치에 선택적으로 연결될 수 있다. 이 경우, 전자 장치에 선택적으 로 연결될 수 있는 하나 또는 그 이상의 이미지 센서에 연결되는 외부 이미지 처리부는 전자 장치에 실장 되거나, 이미지 센서와 함께 전자 장치에 선택적으로 연결될 수 있다. 다른 예를 들어, 다수 개의 이미지 센서들(330-1 내지 330-N) 중 하나 또는 그 이상의 이미지 센서는 블루투스, 무선랜과 같은 무선 인터페이스를 통해 전자 장치와 선택적으로 연결될 수 있다. 이 경우, 전자 장치(30 0)에 선택적으로 연결될 수 있는 하나 또는 그 이상의 이미지 센서에 연결되는 외부 이미지 처리부는 전자 장치 에 연결되거나, 이미지 센서와 함께 전자 장치에 선택적으로 연결될 수 있다. 도 4는 본 발명의 실시 예에 따른 프로세서의 상세 블록도를 도시하고 있다. 도 4를 참조하면 프로세서는 이미지 처리부(ISP), 내부 인터페이스, 포맷 변경부, 표시 제 어부, 이미지 생성 제어부, 섬네일 생성부 및 동영상 생성부를 포함할 수 있다. 이미지 처리부는 제 1 이미지 센서(330-1)로부터 제공받은 이미지 데이터에 대한 레벨 조정, 잡음 제거, 감마 보정, 색상 공간 변환 중 하나 또는 그 이상의 이미지 처리를 수행할 수 있다. 이미지 처리부는 이미 지 처리한 이미지 데이터를 메모리 또는 표시 제어부 중 하나 이상으로 전송할 수 있다. 예를 들어, 이미지 처리부는 표시부에 표시되는 이미지 데이터(예: YUV 데이터) 및 해당 이미지 데이터에 대한 메타 데이터를 메모리로 전송할 수 있다. 내부 인터페이스는 각각의 외부 이미지 처리부(340-1 또는 340-(N-1))로부터 제공받은 이미지 데이터를 메 모리로 전송할 수 있다. 예를 들어, 내부 인터페이스는 MIFI(Mobile Industry Processor Interface), CAMIF(Camera Interface) 중 하나 이상을 포함할 수 있다. 포맷 변경부는 메모리에 저장된 외부 이미지 처리부(340-1 또는 340-(N-1))로부터 제공받은 이미지 데이터를 표시부에 표시 가능한 데이터의 포맷으로 변경할 수 있다. 예를 들어, 포맷 변경부는 메모 리로부터 제공받은 이미지 데이터를 색상 공간 변환하여 표시 제어부로 전송할 수 있다. 예컨대, 포 맷 변경부는 표시부에 표시 가능한 데이터의 포맷으로 변경한 외부 이미지 처리부(340-1 또는 340- (N-1))로부터 제공받은 이미지 데이터를 메모리에 저장하도록 제어할 수 있다. 표시 제어부는 표시부를 통해 그래픽으로 사용자 인터페이스를 제공하도록 제어할 수 있다. 예를 들 어, 표시 제어부는 이미지 처리부 또는 포맷 변경부 중 하나 이상으로부터 제공받은 이미지들을 표시부에 표시하도록 제어할 수 있다. 예컨대, 표시 제어부는 이미지 처리부를 통해 제공받은 제 1 이미지 센서(330-1)의 이미지 데이터와 포맷 변경부를 통해 제공받은 제 N 이미지 센서(330-N)의 이 미지 데이터를 표시부에 함께 표시하도록 제어할 수 있다. 이미지 생성 제어부는 이미지 센서들(330-1 내지 330-N)을 통해 획득한 이미지 데이터들 중 적어도 두 개 의 이미지 데이터들을 선택하여 합성할 수 있다. 예를 들어, 캡쳐 이벤트가 발생한 경우, 이미지 생성 제어부 는 메모리에 저장된 이미지들의 이미지 획득 시점 또는 이미지 처리 지연 시간 및 이미지 획득 시점 을 이용하여 적어도 두 개의 이미지 데이터들을 선택하여 합성할 수 있다. 섬네일 생성부는 메모리에 저장된 이미지 처리된 이미지 데이터들 및 각각의 이미지 데이터에 대한 메타 데이터를 이용하여 섬네일(thumbnail) 데이터를 생성할 수 있다. 예를 들어, 캡쳐 이벤트가 발생한 경우, 섬네일 생성부는 메모리에 저장된 각각의 이미지 데이터의 YUV 데이터 및 해당 이미지 데이터에 대한 메타 데이터를 이용하여 섬네일 데이터를 생성할 수 있다. 예컨대, 다수 개의 이미지 센서들(330-1 내지 330- N)을 통해 획득한 적어도 두 개의 이미지 데이터들을 합성하여 캡쳐 이미지 데이터를 생성하는 경우, 섬네일 생 성부는 각 이미지 데이터의 처리 지연 시간에 기반하여 이미지 데이터들을 동기화하여 섬네일 데이터를 생 성할 수 있다. 이때, 섬네일 생성부는 메타 데이터에 포함된 이미지 획득 시점 또는 프레임 식별 정보를 이용하여 캡쳐 이미지 데이터와 섬네일 데이터를 연동하여 메모리에 저장할 수 있다. 동영상 생성부는 메모리에 저장된 이미지 처리된 이미지 데이터들을 부호화(encoding)하여 동영상 데 이터를 생성할 수 있다. 예를 들어, 동영상 생성부는 비디오 선 처리부와 비디오 부호화부를 포함할 수 있 다. 비디오 선 처리부는 메모리에 저장된 이미지 처리된 이미지 데이터들에 대한 줌(zoom), 회전(rotate), 색상 공간 변환 및 플립(flip)과 같은 선처리를 수행하여 메모리에 저장할 수 있다. 비디오 부호화부는 기 설정된 부호화 방식에 따라 비디오 선 처리부에 의해 선처리되어 메모리에 저장된 이미지 데이터를 부호화 하여 동영상 데이터를 생성할 수 있다. 미 도시되었지만, 프로세서는 제 1 이미지 센서(330-1) 또는 제 1 이미지 센서(330-1) 및 외부 이미지 처 리부들(340-1 내지 340-(N-1))로부터 제공받은 이미지 데이터들에 이미지 획득 시점(time stamp)을 설정할 수 있는 시간 설정부를 더 포함할 수 있다. 예를 들어, 시간 설정부는 제 1 이미지 센서(330-1) 로부터 제공받은 이미지 데이터와 대응되는 시간을 매 프레임 단위로 해당 이미지 데이터의 메타 데이터에 기록할 수 있다. 이때, 제 2 이미지 센서(330-2) 내지 제 N 이미지 센서(330-N)를 통해 획득한 이미지 데이터는 각각의 이미지 센서에 연결된 외부 이미지 처리부에 의해 이미지 획득 시점이 설정될 수 있다. 상술한 실시 예에서 프로세서는 외부 이미지 처리부(340-1 또는 340-(N-1))로부터 제공받은 이미지 데이터 를 표시부에 표시 가능한 데이터의 포맷으로 변경하는 포맷 변경부를 포함할 수 있다.다른 실시 예에서 외부 이미지 처리부(340-1 또는 340-(N-1))에서 이미지 데이터를 표시부에 표시 가능한 데이터의 포맷으로 변경 가능한 경우, 프로세서는 포맷 변경부를 포함하지 않도록 구성될 수 있다. 도 5는 본 발명의 실시 예에 따른 전자 장치의 블록도를 도시하고 있다. 도 5를 참조하면 전자 장치는 프로세서, 메모리들(520, 550), 이미지 센서들(530-1 내지 530-N), 외 부 이미지 처리부들(540-1 내지 540-(N-1)), 표시부, 입력부를 포함할 수 있다. 여기서, 프로세서 는 응용프로그램 프로세서(AP: Application Processor)를 포함할 수 있다. 프로세서는 전자장치가 다양한 서비스를 제공하도록 제어할 수 있다. 프로세서는 전자장치에 포함되는 하나 이상의 다른 구성요소로부터 수신된 명령을 해독하고, 해독된 명령에 따른 연산이나 데이터 처리를 실행할 수 있다. 예를 들어, 프로세서는 제 1 이미지 센서(530-1)로 부터 제공받은 이미지 데이터에 대한 레벨 조정, 잡음 제거, 감마 보정, 표시부에 표시 가능한 포맷으로 변환 중 하나 또는 그 이상의 이미지 처리를 수행할 수 있다. 프로세서는 이미지 처리한 이미지 데이터를 제 1 메모리에 저장하거나, 표시부에 표시하도록 제어할 수 있다. 예컨대, 프로세서는 표시부 에 표시되는 이미지 데이터(예: YUV 데이터) 및 해당 이미지 데이터에 대한 메타 데이터를 제 1 메모리 로 전송할 수 있다. 여기서, 표시부에 표시 가능한 포맷으로 변환하는 이미지 처리는 색상 공간 변환 을 포함할 수 있다. 프로세서는 제 1 메모리에 저장된 하나 이상의 프로그램을 실행하여 전자장치가 다양한 멀티미 디어 서비스를 제공하도록 제어할 수 있다. 예를 들어, 프로세서는 메모리에 저장된 프로그램을 실행 하여 이미지 센서들(530-1 내지 530-N)을 통해 획득한 이미지 데이터들 중 적어도 두 개의 이미지 데이터들을 선택하여 합성할 수 있다. 예컨대, 프로세서는 이미지 데이터들에 대응하는 이미지 획득 시점 또는 이미지 처리 지연 시간 및 이미지 획득 시점을 이용하여 적어도 두 개의 이미지 데이터들을 선택하여 합성할 수 있다. 다른 예를 들어, 캡쳐 이벤트가 발생한 경우, 프로세서는 제 1 메모리에 저장된 이미지 처리된 이미 지 데이터들(예: 프리뷰 이미지) 및 각각의 이미지 데이터에 대한 메타 데이터를 이용하여 캡쳐 이미지 데이터 에 대한 섬네일 데이터를 생성할 수 있다. 예컨대, 프로세서는 제 1 이미지 센서(530-1)로부터 제공받은 이미지 데이터들에 대한 이미지 처리를 수행하는 모듈(예: ISP)과 별도의 다른 모듈을 이용하여 캡쳐 이미지 데 이터에 대한 섬네일 데이터를 생성할 수 있다. 제 1 메모리는 전자장치에 포함되는 하나 이상의 구성 요소로부터 수신되거나 하나 이상의 구성 요소 에 의해 생성된 명령 또는 데이터를 저장할 수 있다. 이미지 센서들(530-1 내지 530-N)은 피사체에 대한 촬영을 통해 획득한 이미지를 프로세서로 제공할 수 있 다. 이때, 이미지 센서들(530-1 내지 530-N)은 MIPI, MDDI와 같은 직렬 인터페이스와 병렬 버스와 같은 병렬 인 터페이스를 통해 프로세서 또는 외부 이미지 처리부(540-1 내지 540-(N-1))로 이미지를 전송할 수 있다. 여기서, 제 1 이미지 센서(530-1)는 전자장치의 전면에 위치하고, 제 N 이미지 센서(530-N)는 전자장치 의 후면에 위치할 수 있다. 외부 이미지 처리부들(540-1 내지 540-(N-1))은 이미지 센서들(530-2 내지 530-N)로부터 제공받은 이미지 데이 터에 대한 레벨 조정, 잡음 제거, 감마 보정, 색상 공간 변환과 같은 이미지 처리하여 제 1 메모리에 저장 하도록 제어할 수 있다. 또한, 외부 이미지 처리부들(540-1 내지 540-(N-1))은 이미지 센서들(530-2 내지 530- N)로부터 제공받은 이미지 데이터에 시간 정보를 설정하여 제 2 메모리에 저장하도록 제어할 수 있다. 예 컨대, 외부 이미지 처리부들(540-1 내지 540-(N-1))은 해당 이미지 데이터의 메타 데이터에 시간 정보를 설정할 수 있다. 제 2 메모리는 외부 이미지 처리부들(540-1 내지 540-(N-1))로부터 제공받은 이미지 처리되지 않은 이미지 데이터를 저장할 수 있다. 예를 들어, 제 2 메모리는 외부 이미지 처리부들(540-1 내지 540-(N-1))로부터 제공받은 로우 이미지 데이터(raw image data)를 저장할 수 있다. 이때, 제 2 메모리는 각각의 외부 이미 지 처리부(540-1 또는 540-(N-1)) 별로 존재할 수 있다. 표시부는 전자장치의 상태 정보, 정지 영상, 동영상 또는 데이터와 같은 그래픽으로 사용자 인터페이 스를 제공할 수 있다. 예를 들어, 표시부는 프로세서로부터 제공받은 하나 이상의 이미지 데이터를 표시할 수 있다. 다른 예를 들어, 표시부는 프로세서에서 이미지 획득 시점 또는 이미지 획득 시점 및 이미지 처리 지연 시간에 기반하여 선택한 적어도 두 개의 이미지 데이터들을 표시할 수 있다.입력부는 사용자에 의해 입력되는 명령 또는 데이터를 프로세서 또는 제 1 메모리에 전송할 수 있다. 예를 들어, 입력부는 터치 입력부, 펜 센서, 키 또는 초음파 입력 장치를 포함할 수 있다. 미 도시되었지만, 전자장치는 음성 통신 또는 데이터 통신을 통해 다른 전자장치 또는 서버와 통신을 연결 할 수 있는 통신부를 더 포함할 수 있다. 여기서, 통신부는 서로 다른 통신 네트워크를 지원하는 다수 개의 통 신 서브 모듈들로 구분될 수도 있다. 상술한 실시 예에서 전자 장치는 다수 개의 이미지 센서들(530-1 내지 530-N)을 포함할 수 있다. 이때, 다 수 개의 이미지 센서들(530-1 내지 530-N) 중 하나 또는 그 이상의 이미지 센서는 전자 장치에 선택적으로 연결될 수 있다. 예를 들어, 다수 개의 이미지 센서들(530-1 내지 530-N) 중 하나 또는 그 이상의 이미지 센서 는 유선 인터페이스를 통해 전자 장치에 선택적으로 연결될 수 있다. 이 경우, 전자 장치에 선택적으 로 연결될 수 있는 하나 또는 그 이상의 이미지 센서에 연결되는 외부 이미지 처리부는 전자 장치에 실장 되거나, 이미지 센서와 함께 전자 장치에 선택적으로 연결될 수 있다. 다른 예를 들어, 다수 개의 이미지 센서들(530-1 내지 530-N) 중 하나 또는 그 이상의 이미지 센서는 블루투스, 무선랜과 같은 무선 인터페이스를 통해 전자 장치와 선택적으로 연결될 수 있다. 이 경우, 전자 장치(50 0)에 선택적으로 연결될 수 있는 하나 또는 그 이상의 이미지 센서에 연결되는 외부 이미지 처리부는 전자 장치 에 연결되거나, 이미지 센서와 함께 전자 장치에 선택적으로 연결될 수 있다. 도 6은 본 발명의 실시 예에 따른 프로세서의 상세 블록도를 도시하고 있다. 도 6을 참조하면 프로세서는 이미지 처리부(ISP), 내부 인터페이스, 표시 제어부, 이미지 생성 제어부, 동영상 생성부 및 섬네일 생성부를 포함할 수 있다. 이미지 처리부는 제 1 이미지 센서(530-1)로부터 제공받은 이미지 데이터에 대한 레벨 조정, 잡음 제거, 감마 보정, 색상 공간 변환 중 하나 또는 그 이상의 이미지 처리를 수행할 수 있다. 이미지 처리부는 이미 지 처리한 이미지 데이터를 제 1 메모리 또는 표시 제어부 중 하나 이상으로 전송할 수 있다. 예를 들어, 이미지 처리부는 표시부에 표시되는 이미지 데이터(예: YUV 데이터) 및 해당 이미지 데이터에 대한 메타 데이터를 제 1 메모리로 전송할 수 있다. 내부 인터페이스는 각각의 외부 이미지 처리부(540-1 또는 540-(N-1))로부터 제공받은 이미지를 제 1 메모 리로 전송할 수 있다. 예를 들어, 내부 인터페이스는 MIFI(Mobile Industry Processor Interface), CAMIF(Camera Interface) 중 하나 이상과 외부 이미지 처리부(540-1 또는 540-(N-1))에서 표시부에 표시 가능한 포맷으로 변경한 이미지를 전송하기 위한 RDI(Raw Data dumping Interface) 포함할 수 있다. 표시 제어부는 표시부를 통해 그래픽으로 사용자 인터페이스를 제공하도록 제어할 수 있다. 예를 들 어, 표시 제어부는 이미지 처리부 또는 제 1 메모리 중 하나 이상으로부터 제공받은 이미지 데 이터를 표시부에 표시하도록 제어할 수 있다. 예컨대, 표시 제어부는 이미지 처리부를 통해 제 공받은 제 1 이미지 센서(630-1)의 이미지 데이터와 제 1 메모리로부터 획득한 제 N 이미지 센서(530-N)의 이미지 데이터를 표시부에 함께 표시하도록 제어할 수 있다. 이미지 생성 제어부는 이미지 센서들(530-1 내지 530-N)을 통해 획득한 이미지 데이터들 중 적어도 두 개 의 이미지 데이터들을 선택하여 합성할 수 있다. 예를 들어, 캡쳐 이벤트가 발생한 경우, 이미지 생성 제어부 는 제 1 메모리와 제 2 메모리에 저장된 이미지 데이터들의 이미지 획득 시점 또는 이미지 처리 지연 시간 및 이미지 획득 시점을 이용하여 적어도 두 개의 이미지 데이터들을 선택하여 합성할 수 있다. 동영상 생성부는 제 1 메모리와 제 2 메모리에 저장된 이미지 데이터들을 부호화(encoding)하여 동영상 데이터를 생성할 수 있다. 예를 들어, 동영상 생성부는 비디오 선 처리부와 비디오 부호화부를 포 함할 수 있다. 비디오 선 처리부는 제 1 메모리와 제 2 메모리에 저장된 이미지 데이터들에 대한 줌 (zoom), 회전(rotate), 색상 공간 변환 및 플립(flip)과 같은 선처리를 수행하여 제 1 메모리 및 제 2 메 모리 중 하나 이상에 저장할 수 있다. 비디오 부호화부는 기 설정된 부호화 방식에 따라 비디오 선 처리부 에 의해 선처리되어 제 1 메모리 및 제 2 메모리 중 하나 이상에 저장된 이미지 데이터를 부호화하여 동영상 데이터를 생성할 수 있다. 섬네일 생성부는 제 1 메모리에 저장된 이미지 처리된 이미지 데이터들(예: 프리뷰 이미지) 및 각각 의 이미지 데이터에 대한 메타 데이터를 이용하여 섬네일(thumbnail) 데이터를 생성할 수 있다. 예를 들어, 캡 쳐 이벤트가 발생한 경우, 섬네일 생성부는 제 1 메모리에 저장된 각각의 이미지 데이터의 YUV 데이터 및 해당 이미지 데이터에 대한 메타 데이터를 이용하여 섬네일 데이터를 생성할 수 있다. 예컨대, 다수 개의 이미지 센서들(530-1 내지 530-N)을 통해 획득한 적어도 두 개의 이미지 데이터들을 합성하여 캡쳐 이미지 데이 터를 생성하는 경우, 섬네일 생성부는 각 이미지 데이터의 처리 지연 시간에 기반하여 이미지 데이터들을 동기화하여 섬네일 데이터를 생성할 수 있다. 이때, 섬네일 생성부는 메타 데이터에 포함된 이미지 획득 시점 또는 프레임 식별 정보를 이용하여 캡쳐 이미지 데이터와 섬네일 데이터를 연동하여 제 1 메모리에 저장할 수 있다. 미 도시되었지만, 프로세서는 제 1 이미지 센서(530-1) 또는 제 1 이미지 센서(530-1) 및 외부 이미지 처 리부들(540-1 내지 540-(N-1))로부터 제공받은 이미지 데이터에 이미지 획득 시점(time stamp)을 설정할 수 있 는 시간 설정부를 더 포함할 수 있다. 예를 들어, 시간 설정부는 제 1 이미지 센서(530-1)로부터 제공받은 이미 지 데이터와 대응되는 시간을 매 프레임 단위로 해당 이미지 데이터의 메타 데이터에 기록할 수 있다. 이때, 제 2 이미지 센서(530-2) 내지 제 N 이미지 센서(530-N)를 통해 획득한 이미지는 각각의 이미지 센서에 연결된 외 부 이미지 처리부에 의해 이미지 획득 시점이 설정될 수 있다. 다른 예를 들어, 시간 설정부는 외부 이미지 처 리부540-(N-1)로부터 제공받은 이미지 데이터와 대응되는 시간을 매 프레임 단위로 해당 이미지 데이터의 메타 데이터에 기록할 수 있다. 이 경우, 이미지 생성 제어부는 제 1 메모리에 저장된 이미지들의 이미지 획득 시점에 기반하여 합성하기 위한 적어도 두 개의 이미지들을 선택하여 합성할 수 있다. 도 7은 본 발명의 실시 예에 따른 외부 이미지 처리부의 상세 블록도를 도시하고 있다. 도 7을 참조하면 외부 이미지 처리부는 이미지 처리 제어부 및 시간 설정부를 포함할 수 있다. 이미지 처리 제어부는 이미지 센서(530-2 또는 530-N)로부터 제공받은 이미지 데이터를 레벨 조정, 잡음 제거, 감마 보정 및 표시부에 표시 가능한 포맷으로 변환 중 하나 또는 그 이상의 이미지 처리를 수행할 수 있다. 예를 들어, 이미지 처리 제어부는 표시부에 표시 가능한 포맷으로 변환시키기 위해 이미지 센서(530-2 또는 530-N)로부터 제공받은 YUV422의 이미지 데이터를 YUV420의 이미지 데이터로 색상 공간 변환할 수 있다. 이미지 처리 제어부는 제 2 메모리에 저장된 하나 이상의 이미지 데이터를 표시부에 표시 가능 한 포맷으로 변환하여 이미지 생성 제어부로 전송할 수 있다. 예를 들어, 이미지 처리 제어부는 도 6 의 이미지 생성 제어부의 제어에 따라 제 2 메모리에서 이미지 합성을 위해 선택된 이미지 데이터를 제공받아 표시부에 표시 가능한 포맷으로 변환하여 이미지 생성 제어부로 전송할 수 있다. 다른 예를 들어, 캡쳐 이벤트가 발생한 경우, 제 2 메모리에 저장된 이미지들 중 하나 이상의 이미지 데이터를 표시 부에 표시 가능한 포맷으로 변환하여 이미지 생성 제어부로 전송할 수도 있다. 시간 설정부는 이미지 센서(530-2 또는 530-N)로부터 제공받은 이미지 데이터에 이미지 획득 시점(time stamp)을 설정할 수 있다. 예를 들어, 시간 설정부는 시간 삽입부(time stamp block)와 프레임 설정부(frame count block)를 포함하여 이미지 센서(530-2 또는 530-N)로부터 제공받은 이미지 데이터와 대응되는 시간을 매 프레임 단위로 기록할 수 있다. 상술한 실시 예에서 외부 이미지 처리부는 이미지 처리 제어부와 시간 설정부를 포함할 수 있다. 다 른 실시 예에서 시간 설정부는 외부 이미지 처리부의 외부에 위치할 수도 있다. 도 8은 본 발명의 실시 예에 따른 메모리의 상세 블록 구성을 도시하고 있다. 도 8을 참조하면 제 1 메모리는 논리적 또는 물리적으로 다수 개의 블록들(800, 810, 820)로 나뉘어 데이 터를 저장할 수 있다. 예를 들어, 프로세서의 이미지 처리부로부터 제공받은 이미지 데이터는 제 1 메모리의 세 번째 블록에 저장될 수 있다. 외부 이미지 처리부(540-1 또는 540-(N-1))로부터 제공받은 이미지 데이터는 제 1 메모리의 첫 번째 블록 에 저장될 수 있다. 이때, 이미지 데이터는 Y 데이터, UV 데이터, 메타 데이터로 구분되어 첫 번째 블록 에 내부 블록들(802, 804, 806)에 저장될 수 있다. 여기서, 메타 데이터는 이미지 데이터의 프레임 식별자 (frame ID), 이미지 획득 시점(time stamp), 초점 정보(Auto Focus 정보), 이미지 설정 정보(EXIF: Exchangeable Image File Format) 중 하나 이상을 포함할 수 있다. 캡쳐 이벤트가 발생한 경우, 제 2 메모리에 저장되었더니 이미지 데이터는 외부 이미지 처리부(540-1 또는 540-(N-1))를 통해 제 1 메모리의 세 번째 블록에 저장될 수 있다. 상술한 실시 예에서 전자 장치는 직렬 인터페이스와 병렬 인터페이스를 이용하여 이미지 센서를 통해 생성한 이 미지 데이터를 각각의 모듈로 전송할 수 있다. 예를 들어, 전자 장치는 하기 도 9와 같이 구성되는 MIPI 인터페 이스를 이용하여 이미지 센서를 통해 생성한 이미지 데이터를 각각의 모듈로 전송할 수 있다. 도 9는 본 발명의 실시 예에 따른 인터페이스의 블록도를 도시하고 있다. 도 9를 참조하면 MIPI 인터페이스는 데이터의 형태에 따른 다수 개의 레인(Lane)들을 포함할 수 있다. 예 를 들어, MIPI 인터페이스는 전송하는 데이터 용량에 따라 MIPI 4-Lane PHY, MIPI 2-Lane PHY 및 MIPI 1-Lane PHY로 구성될 수 있다. MIPI 인터페이스는 각각의 레인에 대응되는 직렬 인터페이스(예: CSI: Camera Serial Interface)를 해당 모듈로 이미지 데이터를 전송할 수 있다. 예를 들어, MIPI 4-Lane PHY는 MIPI CSI_0를 통해 하나 이 상의 모듈로 이미지 데이터를 전송하고, MIPI 2-Lane PHY는 MIPI CSI_1을 통해 하나 이상의 모듈로 이미지 데이 터를 전송하며, MIPI 1-Lane PHY는 MIPI CSI_2를 통해 하나 이상의 모듈로 이미지 데이터를 전송할 수 있다. MIPI 인터페이스를 통해 이미지 데이터를 제공받은 모듈은 각 모듈의 특성에 따라 이미지 데이터의 형태를 가공 하거나 처리(processing)할 수 있다. 예를 들어, VPE(Video Pre-processing Engine) 모듈은 MIPI 인터페이스를 통해 제공받은 이미지 데이터를 줌, 회전, 색상 공간 변환 및 플립(flip)과 같은 이미지 처리를 수행할 수 있다. JPEG DCD(decoding) 모듈은 MIPI 인터페이스를 통해 제공받은 JPEG 형태의 이미지 데이터를 복호하는데 필요한 하드웨어적인 가속 기능을 지원할 수 있다. VFE(Video Front-end Engine) 모듈은 MIPI 인터페이스를 통 해 제공받은 이미지 데이터에 색상 변화와 같은 다양한 효과를 적용할 수 있다. Offline JPEG 모듈은 MIPI 인터 페이스를 통해 제공받은 JPEG 형태의 이미지 데이터를 부호화하는데 필요한 하드웨어적인 가속 기능을 지원할 수 있다. 상술한 바와 같이 구성되는 MIPI 인터페이스를 통해 이미지 데이터를 전송하는 경우, 전자 장치는 메모리 및 MIPI 인터페이스의 전송량의 한계로 인해 이미지 데이터를 나눠서 전송하는 분할 전송 방식을 사용할 수 있다. 예를 들어, 11MB의 이미지 데이터를 전송하는 경우, 전자 장치는 도 12a와 같이 11MB의 이미지 데이터를 8MB 데 이터와 3MB의 데이터로 분할하여 MIPI 인터페이스를 통해 전송할 수 있다. 예컨대, 전자 장치는 11MB의 이미지 데이터를 도 12a와 같이 8MB 데이터와 3MB의 데이터로 분할하여 저장하고, 분할된 데이터(1200, 1210)를 PIPE 방식을 통해 전송할 수 있다. MIPI 인터페이스를 통해 분할된 데이터(1200, 1210)를 수신한 전자 장치의 메모리는 하나의 데이터로 취합하거나 분할된 형태로 저장할 수 있다. 전자 장치는 도 12b 와 같이 메모리의 크기(예: 분할된 데이터의 크기) 및 데이터의 분할 개수를 유동적으로 설정할 수 있다. 다른 예를 들어, MIPI 인터페이스를 통해 한번에 11MB의 데이터를 전송할 수 있는 경우, 전자 장치는 도 12b와 같이 11MB 중 기 설정된 데이터양(예: 3MB)을 프리뷰 이미지를 위해 사용하고, 나머지 데이터양(예: 8MB)을 이용하여 로우 이미지(raw image) 데이터를 전송할 수 있다. 이 경우, 전자 장치는 로우 이미지 데이터의 크기에 기반하 여 로우 이미지 데이터를 한번에 또는 분할하여 MIPI 인터페이스를 통해 전송할 수 있다. 예컨대, 로우 이미지 데이터가 7MB인 경우, 전자 장치는 프리뷰 이미지를 위한 3MB와 로우 이미지 데이터를 위한 7MB를 MIPI를 통해 한번에 전송할 수 있다. 로우 이미지 데이터가 15MB인 경우, 전자 장치는 3MB를 프리뷰 이미지를 위한 고정적으 로 사용하고, 로우 이미지 데이터를 위한 8MB 및 7MB로 분할하여 두 번에 걸쳐 MIPI를 통해 한번에 전송할 수 있다. 로우 이미지 데이터를 분할하여 전송한 경우, 전자 장치는 메타 데이터를 이용하여 분할된 로우 이미지 데이터들을 하나의 이미지로 결합할 수 있다. 도 10은 본 발명의 실시 예에 따른 전자 장치에서 섬네일 데이터를 생성하기 위한 흐름도를 도시하고 있다. 도 10을 참조하면 전자 장치는 1001 단계에서 다수 개의 이미지 센서들을 이용하여 이미지 데이터들을 생성할 수 있다. 예를 들어, 전자 장치는 전자 장치의 전면에 위치하는 제 1 이미지 센서와 전자 장치의 후면에 위치하 는 제 2 이미지 센서를 이용하여 이미지 데이터들을 생성할 수 있다. 이미지 데이터들을 생성한 경우, 전자 장치는 1003 단계에서 이미지 데이터들을 표시부에 표시 가능한 프리뷰 포맷으로 변환할 수 있다. 예컨대, 전자 장치는 하나 이상의 이미지 처리부(ISP)를 이용하여 이미지 데이터들을 표시부에 표시 가능한 프리뷰 포맷으로 변환할 수 있다. 예를 들어, 도 2를 참조하는 경우, 전자 장치는 이미지 처리부를 이용하여 이미지 센서들(130-1 내지 130-N)을 통해 생성한 이미지 데이터들을 표시부 에 표시 가능한 프리뷰 포맷(예: YUV 데이터)으로 변환할 수 있다. 이때, 이미지 처리부는 표시부 에 표시 가능한 프리뷰 포맷으로 변환하는 이미지 데이터에 대한 메타 데이터를 함께 생성하여 메모리 에 저장할 수 있다. 다른 예를 들어, 도 5 및 도 6을 참조하는 경우, 전자 장치는 이미지 처리부 를 이용하여 제 1 이미지 센서(530-1)를 통해 생성한 이미지 데이터를 표시부에 표시 가능한 프리뷰포맷(예: YUV 데이터)으로 변환하고, 외부 이미지 처리부들(540-1 내지 540-(N-1))을 이용하여 제 2 이미지 센 서(530-2) 내지 제 N 이미지 센서(530-N)를 통해 생성한 이미지 데이터들을 표시부에 표시 가능한 프리뷰 포맷으로 변환할 수 있다. 이때, 이미지 처리부와 외부 이미지 처리부들(540-1 내지 540-(N-1))은 표시부 에 표시 가능한 프리뷰 포맷으로 변환하는 이미지 데이터에 대한 메타 데이터를 함께 생성하여 제 1 메모 리 및 제 2 메모리 중 하나 이상의 메모리에 저장할 수 있다. 여기서, 메타 데이터는 해당 이미지 데 이터의 프레임 식별자(frame ID), 이미지 획득 시점(time stamp) 및 이미지 설정 정보(EXIF) 중 하나 이상을 포 함할 수 있다. 이미지 데이터들을 표시부에 표시 가능한 프리뷰 포맷으로 변환한 경우, 전자 장치는 1005단계에서 프리뷰 포맷 의 데이터를 이용하여 캡쳐 이미지 데이터에 대한 섬네일 데이터를 생성할 수 있다. 예컨대, 전자 장치는 이미 지 처리부와 별도의 다른 모듈을 이용하여 섬네일 데이터를 생성할 수 있다. 예를 들어, 도 2를 참조하는 경우, 전자 장치의 섬네일 생성부는 메모리에 저장된 프리뷰 포맷의 이미지 데이터 및 해당 이미지 데 이터의 메타 데이터를 이용하여 캡쳐 이미지 데이터에 대한 섬네일 데이터를 생성할 수 있다. 다른 예를 들어, 도 5와 도 6을 참조하는 경우, 전자 장치의 섬네일 생성부는 제 1 메모리 및 제 2 메모리 중 하나 이상의 메모리에 저장된 프리뷰 포맷의 이미지 데이터 및 해당 이미지 데이터의 메타 데이터를 이용하 여 캡쳐 이미지 데이터에 대한 섬네일 데이터를 생성할 수 있다. 도 11은 본 발명의 실시 예에 따른 전자 장치에서 섬네일 데이터와 캡쳐 이미지 데이터를 연동하여 저장하기 위 한 흐름도를 도시하고 있다. 도 11을 참조하면 전자 장치는 1101 단계에서 다수 개의 이미지 센서들을 이용하여 이미지 데이터들을 생성할 수 있다. 예를 들어, 전자 장치는 전자 장치의 전면에 위치하는 제 1 이미지 센서와 전자 장치의 후면에 위치하 는 제 2 이미지 센서를 이용하여 이미지 데이터들을 생성할 수 있다. 이미지 데이터들을 생성한 경우, 전자 장치는 1103 단계에서 이미지 데이터들을 표시부에 표시 가능한 프리뷰 포맷으로 변환할 수 있다. 예를 들어, 전자 장치는 하나 이상의 이미지 처리부(ISP)를 이용하여 이미지 데이터 들을 표시부에 표시 가능한 프리뷰 포맷으로 변환할 수 있다. 이때, 전자 장치는 하나 이상의 이미지 처리부에 서 프리뷰 포맷으로 변환하는 이미지 데이터 및 해당 이미지 데이터에 대한 메타 데이터를 메모리에 저장할 수 있다. 여기서, 메타 데이터는 해당 이미지 데이터의 프레임 식별자, 이미지 획득 시점 및 이미지 설정 정보 중 하나 이상을 포함할 수 있다. 이미지 데이터들을 표시부에 표시 가능한 프리뷰 포맷으로 변환한 경우, 전자 장치는 1105 단계에서 프리뷰 포 맷의 이미지 데이터를 표시부에 표시할 수 있다. 전자 장치는 1107 단계에서 캡쳐 이벤트가 발생하는지 확인할 수 있다. 예를 들어, 전자 장치는 캡쳐 이벤트에 대응하는 하드웨어 버튼의 입력이 감지되는지 확인할 수 있다. 다른 예를 들어, 전자 장치는 캡쳐 이벤트에 대 응하는 아이콘의 선택이 감지되는지 확인할 수 있다. 또 다른 예를 들어, 전자 장치는 캡쳐 이벤트에 대응하는 사용자의 제스쳐가 감지되는지 확인할 수 있다. 1107단계에서 캡쳐 이벤트가 발생하지 않는 경우, 전자 장치는 1101 단계에서 다수 개의 이미지 센서들을 이용 하여 이미지 데이터들을 생성할 수 있다. 1107단계에서 캡쳐 이벤트가 발생한 경우, 전자 장치는 1109 단계에서 프리뷰 포맷의 이미지 데이터를 이용하여 캡쳐 이미지 데이터에 대한 섬네일 데이터를 생성할 수 있다. 예를 들어, 전자 장치의 전면에 저 용량의 제 1 이미지 센서가 위치하고 후면에 고 용량의 제 2 이미지 센서가 위치하는 경우, 전자 장치는 제 1 이미지 센서를 통해 생성한 저 용량의 이미지 데이터를 표시부에 표시 가능한 프리뷰 이미지 데이터로 사용할 수 있다. 전자 장치는 제 2 이미지 센서를 통해 생성한 고 용량의 이미지 데이터를 프리뷰 포맷으로 변환하여 프리뷰 이미지 데이터를 생성할 수 있다. 이에 따라, 고 용량의 이미지 데이터에 대한 처리 지연 시간에 의해 캡쳐 이벤트 발 생 시, 전자 장치는 캡쳐 이벤트 발생 시점에 표시부에 표시된 프리뷰 이미지 데이터에 대응하는 저 용량의 이 미지 데이터와 캡쳐 이벤트 발생 시점에 대응되는 이미지 획득 시점을 포함하는 고 용량의 이미지 데이터를 캡 쳐 이미지 데이터로 인식하여 합성할 수 있다. 캡쳐 이벤트에 따라 섬 네일 데이터 생성 시, 전자 장치는 캡쳐 이벤트 발생 시점에 표시부에 표시된 저 용량 이미지 데이터의 프리뷰 이미지 데이터와 캡쳐 이벤트 발생 시점 에 대응되는 이미지 획득 시점을 포함하는 고 용량의 이미지 데이터에 대한 프리뷰 이미지를 합성하여 섬네일 데이터를 생성할 수 있다. 예컨대, 전자 장치는 이미지 처리부와 별도의 다른 모듈을 이용하여 섬네일 데이터를 생성할 수 있다. 섬네일 데이터를 생성한 경우, 전자 장치는 1111단계에서 섬네일 데이터의 메타 데이터를 이용하여 섬네일 데이 터와 캡쳐 이미지 데이터를 연동하여 저장할 수 있다. 예를 들어, 전자 장치는 섬네일 데이터를 생성하는데 사 용한 메타 데이터에 포함되는 이미지 획득 시점 또는 프레임 식별 정보를 이용하여 캡쳐 이미지 데이터와 섬네 일 데이터를 연동하여 메모리에 저장할 수 있다. 도 13은 본 발명의 또 다른 실시 예에 따른 전자 장치의 블록도를 도시하고 있다. 이하 설명에서 전자 장치 는, 예를 들면, 도 1에 도시된 전자 장치의 전체 또는 일부를 구성할 수 있다. 도 13을 참조하면, 전자 장치는 하나 이상의 프로세서, SIM(subscriber identification module) 카드, 메모리, 통신 모듈, 센서 모듈, 입력 모듈, 디스플레이, 인터페이 스, 오디오 모듈, 카메라 모듈, 전력관리 모듈, 배터리, 인디케이터 또 는 모터를 포함할 수 있다. 프로세서(예: 프로세서)는 하나 이상의 어플리케이션 프로세서(AP: application processor) 또는 하나 이상의 커뮤니케이션 프로세서(CP: communication processor)를 포함할 수 있다. 도 13에서 AP 및 CP가 프로세서 내에 포함된 것으로 도시되었으나, AP 와 CP는 서로 다른 IC 패키지들 내에 각각 포함될 수 있다. 한 실시 예에 따르면, AP 및 CP는 하나의 IC 패키지 내에 포함될 수 있다. AP는 운영체제 또는 응용 프로그램을 구동하여 AP에 연결된 다수의 하드웨어 또는 소프트웨어 구성 요소들을 제어할 수 있고, 멀티미디어 데이터를 포함한 각종 데이터 처리 및 연산을 수행할 수 있다. AP 는, 예를 들면, SoC(system on chip) 로 구현될 수 있다. 한 실시예에 따르면, 프로세서는 GPU(graphic processing unit, 미도시)를 더 포함할 수 있다. CP는 전자 장치(예: 전자 장치)와 네트워크로 연결된 다른 전자 장치들(예: 전자 장치, 전자 장치, 또는 서버) 간의 통신에서 데이터 링크를 관리하고 통신 프로토콜을 변환하는 기능을 수 행할 수 있다. CP는, 예를 들면, SoC로 구현될 수 있다. 한 실시예에 따르면, CP는 멀티미디어 제 어 기능의 적어도 일부를 수행할 수 있다. CP는, 예를 들면, 가입자 식별 모듈(예: SIM 카드)을 이 용하여 통신 네트워크 내에서 전자 장치의 구별 및 인증을 수행할 수 있다. 또한, CP는 사용자에게 음성 통화, 영상 통화, 문자 메시지 또는 패킷 데이터(packet data) 등의 서비스들을 제공할 수 있다. 또한, CP는 통신 모듈의 데이터 송수신을 제어할 수 있다. 도 13에서는, CP, 전력관리 모듈 또는 메모리 등의 구성요소들이 AP와 별개의 구성요소로 도시되어 있으나, 한 실시예에 따 르면, AP가 전술한 구성요소들의 적어도 일부(예: CP)를 포함하도록 구현될 수 있다. 한 실시예에 따르면, AP 또는 CP는 각각에 연결된 비휘발성 메모리 또는 다른 구성요소 중 적어도 하나로부터 수신한 명령 또는 데이터를 휘발성 메모리에 로드(load)하여 처리할 수 있다. 또한, AP 또는 CP는 다른 구성요소 중 적어도 하나로부터 수신하거나 다른 구성요소 중 적어도 하나에 의해 생성된 데이 터를 비휘발성 메모리에 저장(store)할 수 있다. SIM 카드는 가입자 식별 모듈을 포함하는 카드일 수 있으며, 전자 장치의 특정 위치에 형성된 슬롯에 삽 입될 수 있다. SIM 카드는 고유한 식별 정보(예: ICCID(integrated circuit card identifier)) 또는 가 입자 정보(예: IMSI(international mobile subscriber identity))를 포함할 수 있다. 메모리(예: 메모리)는 내장 메모리 또는 외장 메모리를 포함할 수 있다. 내장 메모리 는, 예를 들면, 휘발성 메모리(예를 들면, DRAM(dynamic RAM), SRAM(static RAM), SDRAM(synchronous dynamic RAM) 등) 또는 비휘발성 메모리(non-volatile Memory, 예를 들면, OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, NAND flash memory, NOR flash memory 등) 중 적어도 하나를 포함할 수 있다. 한 실시예에 따르면, 내장 메모리 822는 Solid State Drive (SSD)일 수 있다. 외장 메모리는 flash drive, 예를 들면, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini- SD(mini secure digital), xD(extreme digital) 또는 Memory Stick 등을 더 포함할 수 있다. 외장 메모리 는 다양한 인터페이스를 통하여 전자 장치과 기능적으로 연결될 수 있다. 한 실시예에 따르면, 전 자 장치는 하드 드라이브와 같은 저장 장치(또는 저장 매체)를 더 포함할 수 있다. 통신 모듈(예: 통신 인터페이스)은 무선 통신 모듈 또는 RF 모듈을 포함할 수 있다. 무 선 통신 모듈은, 예를 들면, WiFi, BT(bluetooth) , GPS 또는 NFC(near field communication) 를 포함할 수 있다. 예를 들면, 무선 통신 모듈은 무선 주파수를 이용하여 무선 통 신 기능을 제공할 수 있다. 추가적으로 또는 대체적으로, 무선 통신 모듈은 전자 장치를 네트워크 (예: Internet, LAN(local area network), WAN(wire area network), telecommunication network, cellular network, satellite network 또는 POTS(plain old telephone service) 등)와 연결시키기 위한 네트워크 인터페 이스(예: LAN card) 또는 모뎀 등을 포함할 수 있다. RF 모듈은 데이터의 송수신, 예를 들면, RF 신호의 송수신을 담당할 수 있다. RF 모듈은, 도시되지 는 않았으나, 예를 들면, 트랜시버(transceiver), PAM(power amp module), 주파수 필터(frequency filter) 또 는 LNA(low noise amplifier) 등을 포함할 수 있다. 또한, RF 모듈은 무선 통신에서 자유 공간상의 전자 파를 송수신하기 위한 부품, 예를 들면, 도체 또는 도선 등을 더 포함할 수 있다. 센서 모듈은 물리량을 계측하거나 전자 장치의 작동 상태를 감지하여, 계측 또는 감지된 정보를 전 기 신호로 변환할 수 있다. 센서 모듈은, 예를 들면, 제스처 센서(1340-A), 자이로 센서(1340-B), 기압 센서(1340-C), 마그네틱 센서(1340-D), 가속도 센서(1340-E), 그립 센서(1340-F), 근접 센서(1340-G), color 센서(1340-H)(예: RGB(red, green, blue) 센서), 생체 센서(1340-I), 온/습도 센서(1340-J), 조도 센서(1340- K) 또는 UV(ultra violet) 센서(1340-M)중의 적어도 하나를 포함할 수 있다. 추가적으로 또는 대체적으로, 센서 모듈은, 예를 들면, 후각 센서(E-nose sensor, 미도시), EMG 센서(electromyography sensor, 미도시), EEG 센서(electroencephalogram sensor, 미도시), ECG 센서(electrocardiogram sensor, 미도시), IR(infra red) 센서(미도시), 홍채 센서(미도시) 또는 지문 센서(미도시) 등을 포함할 수 있다. 센서 모듈은 그 안 에 속한 적어도 하나 이상의 센서들을 제어하기 위한 제어 회로를 더 포함할 수 있다. 입력 모듈은 터치 패널(touch panel), (디지털) 펜 센서(pen sensor), 키(key) 또는 초음파(ultrasonic) 입력 장치를 포함할 수 있다. 터치 패널은, 예를 들면, 정전식, 감압식, 적외 선 방식 또는 초음파 방식 중 적어도 하나의 방식으로 터치 입력을 인식할 수 있다. 또한, 터치 패널은 제어 회로를 더 포함할 수도 있다. 정전식의 경우, 물리적 접촉 또는 근접 인식이 가능하다. 터치 패널은 택타일 레이어(tactile layer)를 더 포함할 수도 있다. 이 경우, 터치 패널은 사용자에게 촉각 반응을 제 공할 수 있다. (디지털) 펜 센서는, 예를 들면, 사용자의 터치 입력을 받는 것과 동일 또는 유사한 방법 또는 별도의 인 식용 쉬트(sheet)를 이용하여 구현될 수 있다. 키는, 예를 들면, 물리적인 버튼, 광학식 키, 키패드, 또 는 터치키를 포함할 수 있다. 초음파(ultrasonic) 입력 장치는 초음파 신호를 발생하는 입력 도구를 통해, 전자 장치에서 마이크(예: 마이크)로 음파를 감지하여 데이터를 확인할 수 있는 장치로서, 무선 인 식이 가능하다. 한 실시예에 따르면, 전자 장치는 통신 모듈를 이용하여 이와 연결된 외부 장치(예: 네트워크, 컴퓨터 또는 서버)로부터 사용자 입력을 수신할 수도 있다. 디스플레이(예: 디스플레이)은 패널, 홀로그램, 또는 프로젝터을 포함할 수 있다. 패널은, 예를 들면, LCD(liquid-crystal display) 또는 AM-OLED(active-matrix organic light- emitting diode) 등일 수 있다. 패널은, 예를 들면, 유연하게(flexible), 투명하게(transparent) 또는 착용할 수 있게(wearable) 구현될 수 있다. 패널은 터치 패널과 하나의 모듈로 구성될 수도 있다. 홀로그램은 빛의 간섭을 이용하여 입체 영상을 허공에 보여줄 수 있다. 프로젝터는 스크린에 빛을 투사하여 영상을 표시할 수 있다. 스크린은, 예를 들면, 전자 장치의 내부 또는 외부에 위치할 수 있다. 한 실시예에 따르면, 디스플레이은 패널, 홀로그램, 또는 프로젝터를 제어하기 위한 제어 회로를 더 포함할 수 있다. 인터페이스는, 예를 들면, HDMI(high-definition multimedia interface), USB(universal serial bus), 광통신(optical communication) 단자 또는 D-sub(D-subminiature) 878를 포함할 수 있다. 인터페이스는, 예를 들면, 도 1에 도시된 통신 인터페이스에 포함될 수 있다. 추가적으로 또는 대체 적으로, 인터페이스는, 예를 들면, MHL(mobile high-definition link(미도시)), SD(secure Digital)/MMC(multi-media card)(미도시) 또는 IrDA(infrared data association, 미도시)를 포함할 수 있다. 오디오 모듈은 소리(sound)와 전기신호를 쌍방향으로 변환시킬 수 있다. 오디오 모듈의 적어도 일 부 구성요소는, 예를 들면, 도 1 에 도시된 입출력 인터페이스에 포함될 수 있다. 오디오 모듈은, 예를 들면, 스피커, 리시버, 이어폰 또는 마이크 등을 통해 입력 또는 출력되는 소리 정보를 처리할 수 있다. 카메라 모듈은 정지 영상 및 동영상을 촬영할 수 있는 장치로서, 한 실시예에 따르면, 하나 이상의 이미 지 센서(예: 전면 센서 또는 후면 센서), 렌즈(미도시), ISP(image signal processor, 미도시) 또는 플래쉬 (flash, 미도시)(예: LED 또는 xenon lamp)를 포함할 수 있다. 전력 관리 모듈은 전자 장치(1300의 전력을 관리할 수 있다. 도시하지는 않았으나, 전력 관리 모듈 은, 예를 들면, PMIC(power management integrated circuit), 충전 IC(charger integrated circuit) 또 는 배터리 또는 연료 게이지(battery or fuel gauge)를 포함할 수 있다. PMIC는, 예를 들면, 집적회로 또는 SoC 반도체 내에 탑재될 수 있다. 충전 방식은 유선과 무선으로 구분될 수 있다. 충전 IC는 배터리를 충전시킬 수 있으며, 충전기로부터의 과전압 또는 과전류 유입을 방지할 수 있다. 한 실시예에 따르면, 충전 IC는 유선 충전 방식 또는 무선 충전 방식 중 적어도 하나를 위한 충전 IC를 포함할 수 있다. 무선 충전 방식으로는, 예를 들면, 자기공명 방식, 자기유도 방식 또는 전자기파 방식 등이 있으며, 무선 충전을 위한 부가적인 회로, 예를 들면, 코일 루프, 공진 회로 또는 정류기 등의 회로가 추가될 수 있다. 배터리 게이지는, 예를 들면, 배터리의 잔량, 충전 중 전압, 전류 또는 온도를 측정할 수 있다. 배터리 는 전기를 저장 또는 생성할 수 있고, 그 저장 또는 생성된 전기를 이용하여 전자 장치에 전원을 공급할 수 있다. 배터리는, 예를 들면, 충전식 전지(rechargeable battery), 또는 태양 전자(solar battery)를 포함할 수 있다. 인디케이터는 전자 장치 혹은 그 일부(예: AP)의 특정 상태, 예를 들면, 부팅 상태, 메시지 상태 또는 충전 상태 등을 표시할 수 있다. 모터는 전기적 신호를 기계적 진동으로 변환할 수 있다. 도 시되지는 않았으나, 전자 장치는 모바일 TV 지원을 위한 처리 장치(예: GPU)를 포함할 수 있다. 모바일 TV지원을 위한 처리 장치는, 예를 들면, DMB(digital multimedia broadcasting), DVB(digital video broadcasting) 또는 미디어플로우(media flow) 등의 규격에 따른 미디어 데이터를 처리할 수 있다. 본 발명의 실시 예에 따른 전자 장치의 전술한 구성요소들 각각은 하나 또는 그 이상의 부품(component)으로 구 성될 수 있으며, 해당 구성 요소의 명칭은 전자 장치의 종류에 따라서 달라질 수 있다. 본 개시에 따른 전자 장치는 전술한 구성요소 중 적어도 하나를 포함하여 구성될 수 있으며, 일부 구성요소가 생략되거나 또는 추가 적인 다른 구성요소를 더 포함할 수 있다. 또한, 본 개시에 따른 전자 장치의 구성 요소들 중 일부가 결합되어 하나의 개체(entity)로 구성됨으로써, 결합되기 이전의 해당 구성 요소들의 기능을 동일하게 수행할 수 있다. 한편 본 발명의 상세한 설명에서는 구체적인 실시 예에 관해 설명하였으나, 본 발명의 범위에서 벗어나지 않는 한도 내에서 전자장치의 동작 순서가 변경 또는 병합되거나 재사용 가능하며 생략 등과 같이 여러 가지 변형이 가능하다. 그러므로 본 발명의 범위는 설명된 실시 예에 국한되어 정해져서는 아니 되며 후술하는 특허청구의 범위뿐만 아니라 이 특허청구의 범위와 균등한 것들에 의해 정해져야 한다. 도면 도면1a 도면1b 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12a 도면12b 도면13"}
{"patent_id": "10-2020-0136938", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 본 발명의 실시 예에 따른 전자 장치를 포함하는 네트워크 환경을 도시한다. 도 1b는 본 발명의 실시 예에 따른 전자 장치의 블록도를 도시한다. 도 2는 본 발명의 실시 예에 따른 프로세서의 상세 블록도를 도시한다.도 3은 본 발명의 다른 실시 예에 따른 전자 장치의 블록도를 도시한다. 도 4는 본 발명의 다른 실시 예에 따른 프로세서의 상세 블록도를 도시한다. 도 5는 본 발명의 또 다른 실시 예에 따른 전자 장치의 블록도를 도시한다. 도 6은 본 발명의 또 다른 실시 예에 따른 프로세서의 상세 블록도를 도시한다. 도 7은 본 발명의 실시 예에 따른 외부 이미지 처리부의 상세 블록도를 도시한다. 도 8은 본 발명의 실시 예에 따른 메모리의 상세 블록도를 도시한다. 도 9는 본 발명의 실시 예에 따른 인터페이스의 블록도를 도시한다. 도 10은 본 발명의 실시 예에 따른 전자 장치에서 섬네일 데이터를 생성하기 위한 흐름도를 도시한다. 및 도 11은 본 발명의 실시 예에 따른 전자 장치에서 섬네일 데이터와 캡쳐 이미지 데이터를 연동하여 저장하기 위 한 흐름도를 도시한다. 도 12a 내지 도 12b는 본 발명의 실시 예에 따른 분할되어 저장된 이미지 데이터의 구조를 도시한다. 도 13은 본 발명의 또 다른 실시 예에 따른 전자 장치의 블록도를 도시한다."}
