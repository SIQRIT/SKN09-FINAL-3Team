{"patent_id": "10-2021-0036917", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0131778", "출원번호": "10-2021-0036917", "발명의 명칭": "애니메이션 생성 방법 및 애니메이션 생성 장치", "출원인": "주식회사 케이티", "발명자": "최형기"}}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "동영상에서, 스틸 이미지 내 인물이 등장하는 구간을 검색하는 단계;상기 검색된 구간 내 복수의 프레임 각각에서 상기 인물의 모션 정보를 추출하는 단계;상기 복수의 프레임 각각에서 추출된 상기 모션 정보를 상기 스틸 이미지에서 추출된 인물 영상에 적용하여 복수의 모션 프레임을 생성하는 단계; 및상기 복수의 모션 프레임을 연결하여 애니메이션을 생성하는 단계;를 포함하는애니메이션 생성 방법."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 모션 정보는,상기 복수의 프레임 각각에서 추출되는, 상기 인물의 특징점의 좌표인애니메이션 생성 방법."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 복수의 모션 프레임을 생성하는 단계는,상기 복수의 프레임 중 제1 프레임에서의 특징점의 좌표 및 상기 인물 영상을 인공지능 모델에 제공하는 단계;상기 인공지능 모델이, 상기 인물 영상의 특징 점이 상기 제1 프레임에서의 특징점의 좌표에 대응하여 표시되는제1 모션 영상을 생성하는 단계;상기 복수의 프레임 중 제2 프레임에서의 특징점의 좌표 및 상기 인물 영상을 상기 인공지능 모델에 제공하는단계; 및상기 인공지능 모델이, 상기 인물 영상의 특징 점이 상기 제2 프레임에서의 특징점의 좌표에 대응하여 표시되는제2 모션 영상을 생성하는 단계;를 포함하는애니메이션 생성 방법."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 복수의 모션 프레임을 생성하는 단계는,상기 제1 모션 영상에 배경 이미지를 합성하여 제1 모션 프레임을 생성하는 단계; 및상기 제2 모션 영상에 상기 배경 이미지를 합성하여 제2 모션 프레임을 생성하는 단계;를 더 포함하고,상기 배경 이미지는, 상기 스틸 이미지에서 추출되는애니메이션 생성 방법."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,공개특허 10-2022-0131778-3-상기 복수의 모션 프레임을 연결하여 애니메이션을 생성하는 단계는,상기 복수의 프레임의 순서에 대응하도록, 상기 복수의 모션 프레임을 연결하는 단계;를 포함하는애니메이션 생성 방법."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,상기 애니메이션을 생성하는 단계는,상기 검색된 구간과 동일한 길이를 가지는 상기 애니메이션을 생성하는애니메이션 생성 방법."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서,상기 검색된 구간 내 오디오을 추출하여 저장하는 단계; 및상기 생성된 애니메이션에 상기 저장된 오디오를 추가하여 오디오 합성 애니메이션을 생성하는 단계;를 더 포함하는애니메이션 생성 방법."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1항에 있어서,상기 검색된 구간은, 상기 인물이 일정 시간 이상 연속으로 등장하는 구간인애니메이션 생성 방법."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "메모리; 및동영상에서 스틸 이미지 내 인물이 등장하는 구간을 검색하여 상기 메모리에 저장하고, 상기 검색된 구간 내 복수의 프레임 각각에서 상기 인물의 모션 정보를 추출하고, 상기 복수의 프레임 각각에서 추출된 상기 모션 정보를 상기 스틸 이미지에서 추출된 인물 영상에 적용하여 복수의 모션 프레임을 생성하고, 상기 복수의 모션 프레임을 연결하여 애니메이션을 생성하는 제어부;를 포함하는애니메이션 생성 장치."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,상기 모션 정보는,상기 복수의 프레임 각각에서 추출되는, 상기 인물의 특징점의 좌표인애니메이션 생성 장치."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 9항에 있어서,상기 제어부는,상기 복수의 프레임 중 제1 프레임에서의 특징점의 좌표 및 상기 인물 영상을 인공지능 모델에 제공하고,상기 복수의 프레임 중 제2 프레임에서의 특징점의 좌표 및 상기 인물 영상을 상기 인공지능 모델에 제공하고,상기 인공지능 모델은, 공개특허 10-2022-0131778-4-상기 제1 프레임에서의 특징점의 좌표의 입력에 대응하여, 상기 인물 영상의 특징 점이 상기 제1 프레임에서의특징점의 좌표에 대응하여 표시되는 제1 모션 영상을 생성하고,상기 제2 프레임에서의 특징점의 좌표의 입력에 대응하여, 상기 인물 영상의 특징 점이 상기 제2 프레임에서의특징점의 좌표에 대응하여 표시되는 제2 모션 영상을 생성하는애니메이션 생성 장치."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 제어부는,상기 제1 모션 영상에 배경 이미지를 합성하여 제1 모션 프레임을 생성하고,상기 제2 모션 영상에 상기 배경 이미지를 합성하여 제2 모션 프레임을 생성하고,상기 배경 이미지는, 상기 스틸 이미지에서 추출되는애니메이션 생성 장치."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 9항에 있어서,상기 제어부는,상기 복수의 프레임의 순서에 대응하도록, 상기 복수의 모션 프레임을 연결하는애니메이션 생성 장치."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 9항에 있어서,상기 제어부는,상기 검색된 구간과 동일한 길이를 가지는 상기 애니메이션을 생성하는애니메이션 생성 장치."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14항에 있어서,상기 제어부는,상기 검색된 구간 내 오디오을 추출하여 저장하고,상기 생성된 애니메이션에 상기 저장된 오디오를 추가하여 오디오 합성 애니메이션을 생성하는애니메이션 생성 장치."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 9항에 있어서,상기 검색된 구간은, 상기 인물이 일정 시간 이상 연속으로 등장하는 구간인애니메이션 생성 장치."}
{"patent_id": "10-2021-0036917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "동영상에서, 스틸 이미지 내 인물이 등장하는 구간을 검색하는 단계;상기 검색된 구간 내 복수의 프레임 각각에서 상기 인물의 모션 정보를 추출하는 단계;공개특허 10-2022-0131778-5-상기 복수의 프레임 각각에서 추출된 상기 모션 정보를 상기 스틸 이미지에서 추출된 인물 영상에 적용하여 복수의 모션 프레임을 생성하는 단계; 및상기 복수의 모션 프레임을 연결하여 애니메이션을 생성하는 단계;를 포함하는 애니메이션 생성 방법을 수행하기 위하여 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2021-0036917", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "애니메이션 생성 방법이 개시된다. 본 발명에 따른 애니메이션 생성 방법은, 동영상에서, 스틸 이미지 내 인물이 등장하는 구간을 검색하는 단계, 상기 검색된 구간 내 복수의 프레임 각각에서 상기 인물의 모션 정보를 추출하 는 단계, 상기 복수의 프레임 각각에서 추출된 상기 모션 정보를 상기 스틸 이미지에서 추출된 인물 영상에 적용 하여 복수의 모션 프레임을 생성하는 단계, 및, 상기 복수의 모션 프레임을 연결하여 애니메이션을 생성하는 단 계를 포함한다."}
{"patent_id": "10-2021-0036917", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은, 스틸 이미지 내 인물이 등장하는 구간을 동영상에서 검색하고 검색된 구간에서의 인물의 모션을 스 틸 이미지에 적용함으로써, 동영상을 대표하는 애니메이션을 생성할 수 있는, 애니메이션 생성 방법 및 애니메 이션 생성 장치에 관한 것이다."}
{"patent_id": "10-2021-0036917", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 IPTV나 각종 OTT(Over The Top) 서비스를 통하여, 영화나 방송 프로그램 등의 동영상을 시청자에게 제공하 는 기술이 발달하고 있다. 그리고 동영상의 홍보나 시청자의 동영상의 선택을 돕기 위하여, 서비스 제공자는 동영상을 함축적으로 나타내 는 홍보 콘텐츠를 제공한다. 영화의 홍보 또는 안내를 위한 영화 포스터가 그 대표적인 예이다. 한편 홍보 콘텐츠는 주로 스틸 이미지(still image)의 형태로 제공되고 있다. 이에 따라 생동감 있는 홍보 콘텐 츠를 제공할 수 없는 문제가 있었다. 또한 영화 포스터 등의 홍보 콘텐츠는, 홍보의 대상이 되는 동영상의 내용을 함축적으로 표현하거나 시청자들에 게 강렬한 인상을 전달할 수 있도록 제작되어야 한다. 홍보 콘텐츠의 특성을 그대로 보유하면서 생동감 있는 홍 보 콘텐츠를 제공할 필요가 있다."}
{"patent_id": "10-2021-0036917", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 해결하기 위한 것으로, 본 발명의 목적은 스틸 이미지 내 인물이 등장하는 구간을 동영상에서 검색하고 검색된 구간에서의 인물의 모션을 스틸 이미지에 적용함으로써, 동영상을 대표하는 애니메 이션을 생성할 수 있는, 애니메이션 생성 방법 및 애니메이션 생성 장치를 제공하기 위함이다."}
{"patent_id": "10-2021-0036917", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 애니메이션 생성 방법은, 동영상에서, 스틸 이미지 내 인물이 등장하는 구간을 검색하는 단계, 상기 검색된 구간 내 복수의 프레임 각각에서 상기 인물의 모션 정보를 추출하는 단계, 상기 복수의 프레임 각 각에서 추출된 상기 모션 정보를 상기 스틸 이미지에서 추출된 인물 영상에 적용하여 복수의 모션 프레임을 생 성하는 단계, 및, 상기 복수의 모션 프레임을 연결하여 애니메이션을 생성하는 단계를 포함한다. 이 경우 상기 모션 정보는, 상기 복수의 프레임 각각에서 추출되는, 상기 인물의 특징점의 좌표일 수 있다. 한편 상기 복수의 모션 프레임을 생성하는 단계는, 상기 복수의 프레임 중 제1 프레임에서의 특징점의 좌표 및 상기 인물 영상을 인공지능 모델에 제공하는 단계, 상기 인공지능 모델이, 상기 인물 영상의 특징 점이 상기 제 1 프레임에서의 특징점의 좌표에 대응하여 표시되는 제1 모션 영상을 생성하는 단계, 상기 복수의 프레임 중 제 2 프레임에서의 특징점의 좌표 및 상기 인물 영상을 상기 인공지능 모델에 제공하는 단계, 및, 상기 인공지능 모델이, 상기 인물 영상의 특징 점이 상기 제2 프레임에서의 특징점의 좌표에 대응하여 표시되는 제2 모션 영상 을 생성하는 단계를 포함할 수 있다. 이 경우 상기 복수의 모션 프레임을 생성하는 단계는, 상기 제1 모션 영상에 배경 이미지를 합성하여 제1 모션 프레임을 생성하는 단계, 및, 상기 제2 모션 영상에 상기 배경 이미지를 합성하여 제2 모션 프레임을 생성하는 단계를 더 포함하고, 상기 배경 이미지는, 상기 스틸 이미지에서 추출될 수 있다. 한편 상기 복수의 모션 프레임을 연결하여 애니메이션을 생성하는 단계는, 상기 복수의 프레임의 순서에 대응하 도록, 상기 복수의 모션 프레임을 연결하는 단계를 포함할 수 있다.한편 상기 애니메이션을 생성하는 단계는, 상기 검색된 구간과 동일한 길이를 가지는 상기 애니메이션을 생성할 수 있다. 이 경우 상기 검색된 구간 내 오디오을 추출하여 저장하는 단계, 및, 상기 생성된 애니메이션에 상기 저장된 오 디오를 추가하여 오디오 합성 애니메이션을 생성하는 단계를 더 포함할 수 있다. 한편 상기 검색된 구간은, 상기 인물이 일정 시간 이상 연속으로 등장하는 구간일 수 있다. 한편 본 발명에 따른 애니메이션 생성 장치는, 메모리, 및, 동영상에서 스틸 이미지 내 인물이 등장하는 구간을 검색하여 상기 메모리에 저장하고, 상기 검색된 구간 내 복수의 프레임 각각에서 상기 인물의 모션 정보를 추출 하고, 상기 복수의 프레임 각각에서 추출된 상기 모션 정보를 상기 스틸 이미지에서 추출된 인물 영상에 적용하 여 복수의 모션 프레임을 생성하고, 상기 복수의 모션 프레임을 연결하여 애니메이션을 생성하는 제어부를 포함 한다. 이 경우 상기 모션 정보는, 상기 복수의 프레임 각각에서 추출되는, 상기 인물의 특징점의 좌표일 수 있다. 한편 상기 제어부는, 상기 복수의 프레임 중 제1 프레임에서의 특징점의 좌표 및 상기 인물 영상을 인공지능 모 델에 제공하고, 상기 복수의 프레임 중 제2 프레임에서의 특징점의 좌표 및 상기 인물 영상을 상기 인공지능 모 델에 제공하고, 상기 인공지능 모델은, 상기 제1 프레임에서의 특징점의 좌표의 입력에 대응하여, 상기 인물 영 상의 특징 점이 상기 제1 프레임에서의 특징점의 좌표에 대응하여 표시되는 제1 모션 영상을 생성하고, 상기 제 2 프레임에서의 특징점의 좌표의 입력에 대응하여, 상기 인물 영상의 특징 점이 상기 제2 프레임에서의 특징점 의 좌표에 대응하여 표시되는 제2 모션 영상을 생성할 수 있다. 이 경우 상기 제어부는, 상기 제1 모션 영상에 배경 이미지를 합성하여 제1 모션 프레임을 생성하고, 상기 제2 모션 영상에 상기 배경 이미지를 합성하여 제2 모션 프레임을 생성하고, 상기 배경 이미지는, 상기 스틸 이미지 에서 추출될 수 있다. 한편 상기 제어부는, 상기 복수의 프레임의 순서에 대응하도록, 상기 복수의 모션 프레임을 연결할 수 있다. 한편 상기 제어부는, 상기 검색된 구간과 동일한 길이를 가지는 상기 애니메이션을 생성할 수 있다. 이 경우 상기 제어부는, 상기 검색된 구간 내 오디오을 추출하여 저장하고, 상기 생성된 애니메이션에 상기 저 장된 오디오를 추가하여 오디오 합성 애니메이션을 생성할 수 있다. 한편 상기 검색된 구간은, 상기 인물이 일정 시간 이상 연속으로 등장하는 구간일 수 있다. 한편 본 발명에 따른, 애니메이션 생성 방법을 수행하기 위하여 매체에 저장된 컴퓨터 프로그램은, 동영상에서, 스틸 이미지 내 인물이 등장하는 구간을 검색하는 단계, 상기 검색된 구간 내 복수의 프레임 각각에서 상기 인 물의 모션 정보를 추출하는 단계, 상기 복수의 프레임 각각에서 추출된 상기 모션 정보를 상기 스틸 이미지에서 추출된 인물 영상에 적용하여 복수의 모션 프레임을 생성하는 단계, 및, 상기 복수의 모션 프레임을 연결하여 애니메이션을 생성하는 단계를 포함한다."}
{"patent_id": "10-2021-0036917", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 홍보 콘텐츠를 애니메이션의 형식으로 손쉽게 생성할 수 있는 장점이 있다. 예를 들어 종래 에는 홍보 콘텐츠를 애니메이션의 형식으로 생성하기 위하여 홍보 콘텐츠용 애니메이션을 별도로 제작해야 하는 문제가 있었으며, 이에 따라 일률적이고 제한적인 수의 애니메이션이 제작될 수 밖에 없었다. 다만 본 발명에 따르면, 영화 포스터 등의 스틸 이미지 하나만 있으면, 매우 다양한 애니메이션을 손쉽게 제작할 수 있는 장점 이 있다. 또한 본 발명에 따르면, 홍보의 대상이 되는 동영상 내 인물의 모션 및 오디오를 반영하여 홍보 콘텐츠를 제작 하기 때문에, 직관적이고 생동감 있는 홍보가 가능한 장점이 있다. 또한 본 발명에 따르면, 스틸 이미지(영화 포스터 등) 내 인물의 모습(머리 스타일, 화장, 옷차림, 액세서리, 피부 톤, 밝기, 얼굴의 윤곽, 주름 등)과 스틸 이미지의 배경을 그대로 유지하면서 동영상 내 인물의 모션이나 오디오를 전달한다. 즉 본 발명에 따르면, 동영상의 내용을 함축적으로 표현하거나 시청자들에게 강렬한 인상을 전달해야 하는 홍보 콘텐츠의 특성을 그대로 유지하면서, 동영상 내 모션이나 오디오를 이용한 생동감 있는 홍 보가 가능한 장점이 있다. 또한 기존의 애니메이션은 복수의 프레임을 연결하는 것에 불과하여 오디오가 누락된다는 단점이 있었다. 다만 본 발명에 따르면 동영상 내 모션과 오디오를 함께 시청자에게 전달함으로써, 실감나는 홍보 콘텐츠의 제공이 가능한 장점이 있다. 또한 본 발명에 따르면, 검색된 구간의 길이, 애니메이션의 길이 및 애니메이션에 합성되는 오디오의 길이가 모 두 동일하다. 따라서 동영상 내에서 인물의 모션(예를 들어 발화하는 입 모양)과 오디오(발화음)의 싱크가 일치 하는 것과 마찬가지로, 애니메이션 상에서의 인물의 모션과 오디오의 싱크도 일치하게 된다. 이에 따라서 매우 자연스러운 홍보 콘텐츠를 사용자에게 제공할 수 있는 장점이 있다."}
{"patent_id": "10-2021-0036917", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또 는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘어져서 구현될 수도 있다. 도 1은 본 발명에 따른, 애니메이션 생성 장치를 설명하기 위한 블록도이다. 도 1에서 설명하는 이동 단말기의 구성요소들은 본 발명에 따른 동작을 구현하는데 필수적인 것은 아니어서, 구 성 요소들 중 일부는 생략될 수 있다. 애니메이션 생성 장치는, IPTV 서비스, OTT 서비스 등을 제공하는 주체의 서버일 수 있으나 이에 한정되지 는 않는다.애니메이션 생성 장치는, 통신부, 제어부 및 메모리를 포함할 수 있다. 통신부는 유/무선 통신 기술을 이용하여 외부 장치와 통신하기 위한 통신 회로 또는 통신 모듈을 포함하고, 외부 장치와 데이터를 송/수신할 수 있다. 한편 통신부는 콘텐츠 출력 장치와 통신할 수 있다. 여기서 콘텐츠 출력 장치란, 셋탑 박스, TV 등 콘텐츠 의 영상 및 오디오를 출력할 수 있는 장치일 수 있다. 한편 통신부는 이후에 설명하는 애니메이션 및 동영 상을 콘텐츠 출력 장치에 전송할 수 있다. 또한 통신부는 외부 장치로부터 스틸 이미지 및 동영상을 수신할 수 있다. 용어 “제어부”는, “마이크로 프로세서”, “컨트롤러”, “마이크로 컨트롤러”, “프로세서” 등의 용어와 혼용되어 사용될 수 있다. 제어부는 애니메이션 생성 장치의 전반적인 동작을 제어할 수 있다. 메모리는 애니메이션 생성 장치의 구동을 위한 프로그램 및 기타 데이터를 저장할 수 있다. 또한 메모리는 동영상, 동영상에서 검색된 구간의 영상, 검색된 구간의 오디오 등을 저장할 수 있다. 한편 애니메이션 생성 장치는 입력부(미도시)를 더 포함할 수 있다. 이 경우 입력부(미도시)는, 애니메이 션 생성 장치의 동작을 제어하기 위한 사용자 입력을 수신할 수 있다. 또한 애니메이션 생성 장치는 출력부(미도시)를 더 포함할 수 있다. 이 경우 출력부는 디스플레이부 또는 스피커를 포함하고, 애니메이션 또는 동영상을 직접 출력할 수도 있다. 도 2는 본 발명에 따른 애니메이션 생성 방법을 설명하기 위한 순서도이다. 도 2에 따르면, 애니메이션 생성 방법은, 동영상에서 스틸 이미지 내 인물이 등장하는 구간을 검색하는 단 계(S210), 검색된 구간 내 복수의 프레임 각각에서 인물의 모션 정보를 추출하는 단계(S220), 복수의 프레임 각 각에서 추출된 모션 정보를 스틸 이미지에서 추출된 인물 영상에 적용하여 복수의 모션 프레임을 생성하는 단계 (S230), 복수의 모션 프레임을 연결하여 애니메이션을 생성하는 단계(S240), 및, 생성된 애니메이션에, 검색된 구간 내 오디오를 추가하여 오디오 합성 애니메이션을 생성하는 단계(S250)를 포함할 수 있다. 먼저 동영상에서 스틸 이미지 내 인물이 등장하는 구간을 검색하는 단계(S210)와 관련하여 도 3을 참고하여 설 명한다. 도 3은 본 발명에 따른, 동영상에서 스틸 이미지 내 인물이 등장하는 구간을 추출하는 방법을 설명하기 위한 도 면이다. 여기서 스틸 이미지(still image)는, 정지된 영상, 더욱 구체적으로는 정지된 한 프레임의 영상을 의미할 수 있다. 또한 스틸 이미지는 동영상에 등장하는 인물이 포함된 이미지일 수 있다. 예를 들어 동영상에 인물 A와 인 물 B가 등장하는 경우, 스틸 이미지는 인물 A를 포함하는 이미지일 수 있다. 한편 동영상은, 영화, 방송 프로그램 등, 시청자에게 움직이는 영상으로 제공되는 다양한 콘텐츠를 의미할 수 있다. 한편 제어부는 동영상을 VOD의 형식으로 시청자에게 제공할 수 있다. 한편 특정 스틸 이미지는 특정 동영상에 대응할 수 있다. 여기서 특정 스틸 이미지가 특정 동영상에 대응한 다는 것은, 특정 스틸 이미지가 특정 동영상을 대표하거나 안내하거나 홍보하는 등, 시청자로 하여 금 특정 스틸 이미지를 보고 특정 동영상을 떠올릴 수 있게 하는 것을 의미한다. 예를 들어 스틸 이미지는 영화 A의 포스터이고, 스틸 이미지에 대응하는 동영상은 영화 A일 수 있다. 다른 예를 들어 스틸 이미지는 드라마 B의 썸네일이고, 스틸 이미지에 대응하는 동영상은 드라마 B일 수 있다. 한편 제어부는 스틸 이미지 내 인물을 인식할 수 있다(S311). 일 례로, 제어부는 오브젝트 인식 기술을 이용하여 스틸 이미지내 오브젝트를 인식하고, 인식된 오브 젝트에 상응하는 인물을 검색함으로써 스틸 이미지 내 인물을 인식할 수 있다. 다른 예로, 제어부는 인물 인식 인공지능 모델을 이용하여 스틸 이미지내 인물을 인식할 수 있다. 이와 관련하여 인공지능 모델에 대하여 먼저 설명하면, 인공신경망(뉴럴 네트워크)은 생물학적 뉴런의 동작원리 와 뉴런간의 연결 관계를 모델링한 것으로 노드(node) 또는 처리 요소(processing element)라고 하는 다수의 뉴 런들이 레이어(layer) 구조의 형태로 연결된 정보처리 시스템이다. 인공 신경망은 훈련 데이터(training data)를 이용하여 학습(training)될 수 있다. 여기서 학습이란, 입력 데이 터를 분류(classification)하거나 회귀분석(regression)하거나 군집화(clustering)하는 등의 목적을 달성하기 위하여, 학습 데이터를 이용하여 인공 신경망의 파라미터(parameter)를 결정하는 과정을 의미할 수 있다. 인공 신경망의 파라미터의 대표적인 예시로써, 시냅스에 부여되는 가중치(weight)나 뉴런에 적용되는 편향(bias)을 들 수 있다. 훈련 데이터를 이용하여 학습된 인공 신경망을, 본 명세서에서는 인공지능 모델이라 명칭 할 수 있다. 인공 신경망의 학습 방법 중 지도 학습은, 훈련 데이터로부터 하나의 함수를 유추해내기 위한 기계 학습의 한 방법이다. 그리고 이렇게 유추되는 함수 중, 입력 벡터의 클래스(class)를 예측하여 출력하는 것을 분류 (Classification)라고 할 수 있다. 지도 학습에서는, 훈련 데이터에 대한 레이블(label)이 주어진 상태에서 인공 신경망을 학습시킨다. 여기서 레 이블이란, 훈련 데이터가 인공 신경망에 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과 값)을 의미할 수 있다. 본 명세서에서는 훈련 데이터가 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과값)을 레이블링 데이터(labeling data)이라 명칭 한다. 한편 제어부 또는 기타 학습 장치는, 인물이 포함된 영상 및 인물의 식별 정보(예를 들어 인물 ID)를 이용 하여 인물 인식 인공지능 모델을 트레이닝 할 수 있다, 구체적으로 제어부 또는 기타 학습 장치는, 인물이 포함된 영상을 입력 데이터로써, 인물에 대응하는 식별 정보를 레이블링 데이터로써 인물 인식 인공지능 모델에 제공하여 인물 인식 인공지능 모델을 트레이닝 할 수 있다. 즉 인물의 식별 정보는, 인물 인식 인공지능 모델을 구성하는 인공 신경망이 인물이 포함된 영상을 이용 하여 추론해야 하는 정답 값일 수 있다. 그리고 제어부 또는 기타 학습 장치는 다양한 인물이 포함된 영상들 및 영상들에 대응하는 식별 정보를 훈 련 데이터로 이용하여 인물 인식 인공지능 모델을 트레이닝 할 수 있다. 구체적으로 제어부는 인물 인식 인공지능 모델이 영상에 기반하여 출력한 출력 값과 레이블링 데이터 간의 차이가 작아지도록, 인공지능 모델의 파라미터(가중치, 편향 등)을 조절할 수 있다. 한편 제어부는 스틸 이미지를 트레이닝이 완료된 인물 인식 인공지능 모델에 입력할 수 있다. 이 경 우 인물 인식 인공지능 모델은 자신의 파라미터에 기반하여 스틸 이미지 내 인물의 식별 정보(인물 ID)를 출력할 수 있다. 한편 메모리 또는 외부 데이터베이스에는, 복수의 동영상이 저장될 수 있다. 이 경우 제어부는 스틸 이미지에 대응하는 동영상을 검색할 수 있다. 구체적으로 스틸 이미지에 는 스틸 이미지에 대응하는 동영상의 식별 정보(예를 들어 VOD ID)가 할당될 수 있다. 이 경우 제어부 는, 동영상의 식별 정보를 이용하여, 메모리 또는 외부 데이터베이스로부터 스틸 이미지에 대응 하는 동영상을 검색할 수 있다. 한편 제어부는 동영상에서, 스틸 이미지 내 인물이 등장하는 구간을 검색할 수 있다(S312). 구체적으로 동영상에는 메타 데이터가 첨부될 수 있으며, 메타 데이터는 동영상에 등장하는 인물의 인물 ID 및 등장 시간에 대한 정보를 포함할 수 있다. 이 경우 제어부는 동영상에 첨부된 메타 데이 터를 이용하여, 스틸 이미지 내 인물이 등장하는 구간을 검색할 수 있다. 다만 이것은 스틸 이미지 내 인물이 등장하는 구간을 검색하는 일 방법에 불과한 것으로, 이 외에도 인물이 등장하는 구간을 검색하는 다 양한 방법이 사용될 수 있다. 이 경우 제어부는 동영상에서, 스틸 이미지 내 인물이 등장하는 구간을 추출하여, 메모리 에 저장할 수 있다(S312). 한편 본 발명은 스틸 이미지내 인물이 자연스럽게 움직이는 애니메이션을 생성하는 것을 목적으로 하며, 또한 애니메이션의 길이가 너무 짧아서는 안된다. 따라서 제어부는 스틸 이미지 내 인물이 일정 시간 이상 연속으로 등장하는 구간을 추출할 수 있다. 예를 들어 제어부는 스틸 이미지 내 인물이 7초 이 상 연속으로 등장하는 구간을 추출할 수 있다. 한편 동영상에서 검색된 구간은 시계열적인 복수의 프레임(411, 412, 413)을 포함할 수 있다. 이하에서는 검색된 구간 내 세개의 프레임이 존재하는 것으로 가정하여 설명하나 이에 한정되지 않는다. 한편 제어부는 검색된 구간에서 오디오를 추출하여 메모리에 저장할 수 있다(S312). 다음은 검색된 구간 내 복수의 프레임 각각에서 인물의 모션 정보를 추출하는 단계(S220), 복수의 프레임 각각 에서 추출된 모션 정보를 스틸 이미지에서 추출된 인물 영상에 적용하여 복수의 모션 프레임을 생성하는 단계 (S230), 복수의 모션 프레임을 연결하여 애니메이션을 생성하는 단계(S240)에 대하여 도 4 및 도 5를 참고하여 설명한다. 도 4는 복수의 프레임으로부터 모션 정보를 추출하고, 스틸 이미지와 모션 정보를 이용하여 모션 영상을 생성하 는 방법을 설명하기 위한 도면이다. 먼저 모션 영상의 생성을 위한 인공지능 모델의 트레이닝 방법에 대해서 설명한다. 제어부 또는 기타 학습 장치는 인공지능 모델의 트레이닝에 사용되는 데이터를 획득할 수 있다. 이 경우 제어부 또는 기타 학습 장치는, 도 3에서 설명한 방식으로 데이터를 획득할 수 있다. 예를 들어 제어부 또는 기타 학습 장치는, 동영상으로부터 스틸 이미지 내 인물이 등장하는 구간을 추출할 수 있다. 한편 제어부 또는 기타 학습 장치는, 획득된 데이터를 전 처리하여 트레이닝 데이터를 획득할 수 있다. 구 체적으로 제어부는 구간 내 프레임 에서 특징점의 좌표를 추출할 수 있다. 이 경우 제어부 또는 기타 학습 장치는, 스틸 이미지에서 추출된 인물 영상 및 프레임에서 추출된 특징점 의 좌표를 트레이닝 데이터로 이용하여 인공지능 모델을 트레이닝 할 수 있다. 이 경우 인공지능 모델은, 생성적 적대 신경망(Generative Adversarial Network, GAN)으로 구성될 수 있다. 구체적으로 제어부 또는 기타 학습 장치는, 스틸 이미지에서 추출된 인물 영상 및 프레임에서 추출된 특징 점의 좌표를 인공지능 모델에 제공할 수 있다. 이 경우 생성적 적대 신경망의 생성자(generator)는 자신의 파라미터에 기반하여, 스틸 이미지에서 추출된 인물 영상이 특징점의 좌표에 대응하여 표시되는 영상을 출력할 수 있다. 한편 생성자는 자신이 출력한 영상, 즉 가짜 영상을 판별자(discriminator)에 제공할 수 있다. 또한 제어부 는 진짜 영상을 판별자에 제공할 수 있다. 이 경우 판별자는 생성자가 출력한 영상이 가짜인지, 그리고 제어부가 제공한 영상이 진짜인지를 판별할 수 있다. 또한 제어부는 판별자의 판별 결과를 이용하여 로스 값을 산출하고, 산출된 로스 값을 이용하여 생성자 및 판별자의 파라미터를 업데이트 할 수 있다. 한편 트레이닝이 완료되면, 생성자는 새로운 인물 영상 및 특징점의 좌표를 이용하여 인물 영상을 생성할 수 있 다. 도 4에서는 트레이닝이 완료되고 생성자를 포함하는 인공지능 모델이 도시되었다. 한편 생성적 적대 신경망을 이용한 트레이닝 과정을 설명하였으나 이에 한정되지 않으며, 인공지능 모델은 다양한 학습 방법에 의해 트레이닝 될 수 있다. 트레이닝 이후로 다시 돌아와서, 제어부는 검색된 구간 내 복수의 프레임(411, 412, 413) 각각에서, 인물 의 모션 정보를 추출할 수 있다(S221). 여기서 인물의 모션 정보는, 인물의 행동, 표정, 또는 기타 움직임을 나 타낼 수 있는 정보일 수 있다. 이 경우 모션 정보는 복수의 프레임 각각에서 추출되는, 인물의 특징점의 좌표일 수 있다. 구체적으로 눈, 코, 입 꼬리, 눈썹, 손, 무릎, 발, 어깨, 등 인물의 모션을 파악할 수 있는 지점들이 특징점으 로 사용될 수 있다. 그리고 제어부는 검색된 구간 내 복수의 프레임(411, 412, 413) 각각에서, 인물의 모션 정보를 추출할 수 있다. 구체적으로 제어부는 제1 프레임으로부터 하나 이상의 특징점(x1, x2, x3, x4, x5)의 좌표를 추출할 수 있다. 또한 제어부는 제2 프레임으로부터 하나 이상의 특징점의 좌표를 추출할 수 있다. 또한 제 어부는 제3 프레임으로부터 하나 이상의 특징점의 좌표를 추출할 수 있다. 한편 제어부는 스틸 이미지로부터 인물 영상을 추출할 수 있다(S231). 구체적으로 제어부 는 스틸 이미지로부터 배경 이미지를 제거함으로써 인물 영상을 추출할 수 있다(S222). 이 경우 제어부는 인물의 일부 영역을 추출하여 인물 영상을 생성할 수도 있다. 예를 들어 제어부 는 인물의 전체 영역 중 머리와 목의 영역만을 추출하여 인물 영상을 생성할 수도 있다. 한편 제어부는 복수의 프레임 각각에서 추출된 모션 정보를 스틸 이미지에서 추출된 인물 영상에 적용하여 복수의 모션 프레임을 생성할 수 있다(S230). 구체적으로 제어부는, 복수의 프레임(411, 412, 413) 중 제1 프레임에서의 특징점(X1={x1, x2, x3, x4, x5})의 좌표 및 인물 영상을 인공지능 모델에 제공할 수 있다. 이 경우 인공지능 모델은, 자신의 파라미터에 기반하여, 인물 영상의 특징 점이 제1 프레임에서 의 특징점(X1)의 좌표에 대응하여 표시되는 제1 모션 영상을 생성할 수 있다. 구체적으로, 인공지능 모델은 인물 영상으로부터 특징점을 추출할 수 있다. 또한 인공지능 모델(41 0)은 인물 영상으로부터 추출된 특징점이 제1 프레임에서의 상응하는 특징점의 좌표 상에 표시되는, 제1 모션 영상을 생성할 수 있다. 예를 들어 인물 영상에서 제1 특징점은 우측 입꼬리로서, 인물 영상에서 우측 입꼬리는 내려가 있는 상태라고 가정한다. 그리고 제1 프레임에서의 상응하는 제1 특징점(x1)은 우측 입꼬리로서, 제1 프레 임에서 우측 입꼬리는 올라간 상태일 수 있다. 이 경우 제1 프레임에서의 제1 특징점(x1)의 좌표는 올라간 입꼬리의 좌표를 나타낼 수 있다. 이 경우 인공지능 모델은 인물 영상의 제1 특징점이, 제1 프레임에서의 제1 특징점(x1)의 좌표에 표시되는, 제1 모션 영상을 생성할 수 있다. 즉 제1 모션 영상 내 인물의 모습(머리 스타일, 화장, 옷차림, 액세서리, 피부 톤, 밝기, 얼굴의 윤곽, 주름 등)은 인물 영상 내 인물의 모습이나, 제1 모 션 영상 내 인물의 모션(인물의 행동, 표정, 눈 깜빡임, 발화하는 입의 움직임 등)은 제1 프레임 내 의 인물의 모션일 수 있다. 한편 같은 방법으로, 제2 모션 영상 및 제3 모션 영상이 생성될 수 있다. 예를 들어 제어부는, 복수의 프레임(411, 412, 413) 중 제2 프레임에서의 특징점(X2)의 좌표 및 인물 영상을 인공지능 모델에 제공할 수 있다. 이 경우 인공지능 모델은, 자신의 파라미터에 기반하 여, 인물 영상의 특징 점이 제2 프레임에서의 특징점(X2)의 좌표에 대응하여 표시되는 제2 모션 영상 을 생성할 수 있다. 도 5는 모션 프레임을 생성하는 방법을 설명하기 위한 도면이다. 제어부는 스틸 이미지로부터 배경 이미지를 추출할 수 있다. 구체적으로 제어부는 스틸 이 미지로부터 앞서 설명한 인물 영상을 제외한 배경 이미지를 추출할 수 있다(S231). 이 경우 제어부는 인페인팅 기술을 적용하여 스틸 이미지에서 인물 영상을 자연스럽게 제거한 배경 이미지를 획득할 수도 있다. 그리고 제어부는 복수의 모션 영상(421, 422, 423)에 배경 이미지를 합성하여 복수의 모션 프레임을 생성할 수 있다(S232). 구체적으로 제어부는 복수의 모션 영상(421, 422, 423) 중 제1 모션 영상에 배경 이미지를 합성 하여 제1 모션 프레임을 생성할 수 있다. 또한 제어부는 복수의 모션 영상(421, 422, 423) 중 제2 모션 영상에 배경 이미지를 합성하여 제2 모션 프레임을 생성할 수 있다. 또한 제어부는 복수의 모션 영상(421, 422, 423) 중 제3 모션 영상 에 배경 이미지를 합성하여 제3 모션 프레임을 생성할 수 있다. 한편 제어부는 복수의 모션 프레임에 대하여 화질 향상을 위한 영상 처리를 수행할 수 있다. 예를 들어 제 어부는 복수의 모션 프레임에 대하여 슈퍼 레졸루션 기술을 적용하여 화질을 향상시킬 수 있다. 한편 제어부는 복수의 모션 프레임을 연결하여 애니메이션을 생성할 수 있다. 이 경우 제어부는 앞서 설명한 복수의 프레임(411, 412, 413)의 순서에 대응하도록, 복수의 모션 프레임을 연결할 수 있다. 구체적으로 복수의 프레임(411, 412, 413)은 시계열적인 프레임으로, 시간적인 순서는 제1 프레임, 제2 프 레임 및 제3 프레임 순이다. 또한 제1 모션 프레임은 제1 프레임에서의 특징 점의 좌표를 이용하여, 제2 모션 프레임은 제2 프레임 에서의 특징 점의 좌표를 이용하여, 제3 모션 프레임은 제3 프레임에서의 특징 점의 좌표를 이용하여 생성되었다. 따라서 제어부는 복수의 모션 프레임을, 제1 모션 프레임, 제2 모션 프레임 및 제3 모션 프레임의 순서로 연결하여 애니메이션을 생성할 수 있다. 도 6은 애니메이션 및 오디오를 이용하여 오디오 합성 애니메이션을 생성하는 방법을 설명하기 위한 도면이다. 메모리에는 검색된 구간의 오디오가 저장된 상태이다. 한편 제어부는 검색된 구간의 길이와 동일한 길이를 가지는 애니메이션을 생성할 수 있다. 예를 들어 검색된 구간의 길이가 7초인 경우, 제어부는 애니메이션의 길이 역시 7초가 되도록 복수의 모션 프레임을 연결할 수 있다. 일 실시 예로, 제어부는 검색된 구간 내 복수의 프레임의 프레임 레이트와, 애니메이션 내 복수의 모션 프 레임의 프레임 레이트가 동일한 값을 가지도록, 애니메이션을 생성할 수 있다. 구체적으로 제1 모션 프레임은 인물 영상 및 제1 프레임의 모션 정보를 이용하여 생성되고, 제2 모션 프레 임은 인물 영상 및 제2 프레임의 모션 정보를 이용하여 생성되고, 제3 모션 프레임은 인물 영상 및 제3 프레임의 모션 정보를 이용하여 생성될 수 있다. 즉 검색된 구간 내 복수의 프레임의 개수와, 애니메이션을 구성하는 복수의 모션 프레임의 개수는 동일할 수 있다. 또한 제어부는 검색된 구간 내 복수의 프레임의 프레임 레이트를 그대로 적용하여 복수의 모션 프레임을 연결할 수 있다. 이에 따라 검색된 구간의 길이와 애니메이션의 길이는 동일해질 수 있다. 이 경우 제어부는 애니메이션에 오디오를 추가하여 오디오 합성 애니메이션을 생성할 수 있다. 즉 검색된 구간에서 추출된 오디오 역시 7초의 길이를 가질 수 있다. 따라서 애니메이션에 검색된 구간에서 추출한 오디오를 합성하는 경우, 애니메이션의 길이와 오디오의 길이는 동일할 수 있 다. 한편 앞서 도 4에서는, 모션 영상을 생성하는 인공지능 모델을 설명하였다. 그리고 모션 영상을 생성하는 인공지능 모델은 복수개 존재할 수 있다. 구체적으로 복수의 인공지능 모델은 서로 다른 영역을 타겟팅 하여 모션 영상을 생성할 수 있다. 예를 들어 제1 인공지능 모델은 인물의 얼굴을 타겟팅 하여 모션 영상을 생성할 수 있으며, 제2 인공지능 모델은 인물의 전신 을 타겟팅하여 모션 영상을 생성할 수 있다. 이 경우 제1 인공지능 모델 및 제2 인공지능 모델은 서로 다른 데이터를 이용하여 트레이닝 될 수 있다. 예를 들어 제1 인공지능 모델은 얼굴 영상 및 얼굴의 특징점(입꼬리, 눈, 코 등)의 좌표에 기반하여 트레이닝 될 수 있고, 제2 인공지능 모델은 전신 영상 및 전신의 특징점(머리, 목, 어깨, 손, 팔꿈치, 무릎, 발 등)의 좌표에 기반하여 트레이닝 될 수 있다. 한편 스틸 이미지가 입력되면, 제어부는 복수의 인공지능 모델 중 어느 인공지능 모델을 이용하여 모션 영 상을 생성할지 결정할 수 있다. 예를 들어 스틸 이미지에 인물의 전신이 나타나는 경우, 제어부는 제2 인공지능 모델을 이용하여 모션 영 상을 생성할 것으로 결정할 수 있다. 이 경우 제어부는 스틸 이미지로부터 인물 영상(전신 영상)을 추출하 고, 추출된 인물 영상(전신 영상)을 제2 인공지능 모델에 제공할 수 있다. 또한 제어부는 검색된 구간의 복수의 프레임으로부터 전신의 특징점의 좌표를 추출하여 제2 인공지능 모델에 제공할 수 있다.다른 예를 들어 스틸 이미지에 인물의 전신이 나타나지 않거나 인물의 머리 영역의 비중이 임계값 이상인 경우, 제어부는 제1 인공지능 모델을 이용하여 모션 영상을 생성할 것으로 결정할 수 있다. 이 경우 제어부(12 0)는 스틸 이미지로부터 얼굴 및 얼굴의 주변 영역만을 추출하여 제1 인공지능 모델에 제공할 수 있다. 또한 제 어부는 검색된 구간의 복수의 프레임으로부터 얼굴의 특징점의 좌표를 추출하여 제1 인공지능 모델에 제공 할 수 있다. 한편 제어부는, 통신부를 통하여, 애니메이션을 외부 장치로 전송할 수 있다. 구체적으로 애니메이션 생성 장치가 IPTV 서비스 또는 OTT 서비스 등의 제공자인 경우, 제어부는 애니메이션을 시청자 측 단 말로 전송할 수 있다. 그리고 시청자 측 단말로부터 애니메이션을 선택하는 입력이 수신되면, 제어부는 애니메이션의 홍보 대상 인 동영상을 시청자 측 단말로 전송할 수 있다. 한편 제어부는 동영상 내에서 인물이 일정 시간 연속으로 등장하는 구간이 복수 개 존재할 수 있다. 이 경우 제어부는 복수 개의 구간에 각각 대응하는 복수의 애니메이션을 생성할 수 있다. 이 경우 제어부는 복수의 애니메이션을 순차적으로 외부 장치에 전송할 수 있다. 예를 들어 제어부는 복수의 구간 중 제1 구간에 대응하는 제1 애니메이션(즉 인물이 스틸 이미지의 모습을 나타내면서 제1 구간의 모션을 취하는 애니메이션)을 시청자 측 단말에 전송할 수 있다. 그리고 나서 제어부는 복수의 구간 중 제 2 구간에 대응하는 제2 애니메이션(즉 인물이 스틸 이미지의 모습을 나타내면서 제2 구간의 모션을 취하는 애니 메이션)을 시청자 측 단말에 전송할 수 있다. 이와 같이 본 발명에 따르면, 홍보 콘텐츠를 애니메이션의 형식으로 손쉽게 생성할 수 있는 장점이 있다. 예를 들어 종래에는 홍보 콘텐츠를 애니메이션의 형식으로 생성하기 위하여 홍보 콘텐츠용 애니메이션을 별도로 제작 해야 하는 문제가 있었으며, 이에 따라 일률적이고 제한적인 수의 애니메이션이 제작될 수 밖에 없었다. 다만 본 발명에 따르면, 영화 포스터 등의 스틸 이미지 하나만 있으면, 매우 다양한 애니메이션을 손쉽게 제작할 수 있는 장점이 있다. 또한 본 발명에 따르면, 홍보의 대상이 되는 동영상 내 인물의 모션 및 오디오를 반영하여 홍보 콘텐츠를 제작 하기 때문에, 직관적이고 생동감 있는 홍보가 가능한 장점이 있다. 또한 본 발명에 따르면, 스틸 이미지(영화 포스터 등) 내 인물의 모습(머리 스타일, 화장, 옷차림, 액세서리, 피부 톤, 밝기, 얼굴의 윤곽, 주름 등)과 스틸 이미지의 배경을 그대로 유지하면서 동영상 내 인물의 모션이나 오디오를 전달한다. 즉 본 발명에 따르면, 동영상의 내용을 함축적으로 표현하거나 시청자들에게 강렬한 인상을 전달해야 하는 홍보 콘텐츠의 특성을 그대로 유지하면서, 동영상 내 모션이나 오디오를 이용한 생동감 있는 홍 보가 가능한 장점이 있다. 또한 기존의 애니메이션은 복수의 프레임을 연결하는 것에 불과하여 오디오가 누락된다는 단점이 있었다. 다만 본 발명에 따르면 동영상 내 모션과 오디오를 함께 시청자에게 전달함으로써, 실감나는 홍보 콘텐츠의 제공이 가능한 장점이 있다. 또한 본 발명에 따르면, 검색된 구간의 길이, 애니메이션의 길이 및 애니메이션에 합성되는 오디오의 길이가 모 두 동일하다. 따라서 동영상 내에서 인물의 모션(예를 들어 발화하는 입 모양)과 오디오(발화음)의 싱크가 일치 하는 것과 마찬가지로, 애니메이션 상에서의 인물의 모션과 오디오의 싱크도 일치하게 된다. 이에 따라서 매우 자연스러운 홍보 콘텐츠를 사용자에게 제공할 수 있는 장점이 있다. 한편 본 발명의 도면에서 사용된 포스터 이미지의 배급사는 ㈜미로스페이스, ㈜태왕엔터웍스이며, 영화명은 세 인트 주디이다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 상기 컴 퓨터는 제어부를 포함할 수도 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니 되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하 고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다.부호의 설명 100: 애니메이션 생성 장치 110: 통신부 120: 제어부 130: 메모리"}
{"patent_id": "10-2021-0036917", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른, 애니메이션 생성 장치를 설명하기 위한 블록도이다. 도 2는 본 발명에 따른 애니메이션 생성 방법을 설명하기 위한 순서도이다. 도 3은 본 발명에 따른, 동영상에서 스틸 이미지 내 인물이 등장하는 구간을 추출하는 방법을 설명하기 위한 도 면이다. 도 4는 복수의 프레임으로부터 모션 정보를 추출하고, 스틸 이미지와 모션 정보를 이용하여 모션 영상을 생성하 는 방법을 설명하기 위한 도면이다. 도 5는 모션 프레임을 생성하는 방법을 설명하기 위한 도면이다. 도 6은 애니메이션 및 오디오를 이용하여 오디오 합성 애니메이션을 생성하는 방법을 설명하기 위한 도면이다."}
