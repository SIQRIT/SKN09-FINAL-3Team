{"patent_id": "10-2022-0108652", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0114686", "출원번호": "10-2022-0108652", "발명의 명칭": "비디오에서 사용자의 손을 결정하는 방법 및 전자 장치", "출원인": "삼성전자주식회사", "발명자": "야키신 예브헨니"}}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 비디오 내에서 사용자의 손을 결정하는 방법에 있어서,카메라를 이용하여 복수의 프레임들을 포함하는 비디오를 획득하는 단계(S210);상기 비디오의 프레임들을 이용하여 상기 카메라의 시야(Field of View; FoV)의 이동을 나타내는 시야 궤적을추정하는 단계(S220);상기 비디오의 프레임들 각각 내에서, 하나 이상의 객체의 특징점들을 검출하는 단계(S230);상기 하나 이상의 객체의 특징점들에 기초하여, 상기 하나 이상의 객체의 이동을 나타내는 객체 궤적을 추정하는 단계(S240);상기 카메라의 시야 궤적 및 상기 객체 궤적에 기초하여, 상기 하나 이상의 객체 중에서 사용자의 손 후보를 결정하는 단계(S250);상기 사용자의 머리의 움직임을 나타내는 머리 움직임 궤적을 획득하는 단계(S260);상기 사용자의 손 후보에 대응하는 상기 객체 궤적 및 상기 머리 움직임 궤적에 기초하여, 사용자의 손을 결정하는 단계(S270); 및상기 비디오 내에서 상기 결정된 사용자의 손을 추적하고 제스처를 인식하는 단계(S280)를 포함하는, 방법."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 방법은,상기 비디오의 프레임들 각각에 대하여 전경 객체를 추출함으로써, 전경 프레임들 및 배경 프레임들을 획득하는단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 카메라의 시야 궤적을 추정하는 단계는,상기 배경 프레임들 내 픽셀들을 비교하여 상기 카메라의 시야의 이동과 관련된, 시야 이동 정보를 획득하는 단계; 및상기 시야 이동 정보에 기초하여 상기 카메라의 시야 궤적을 결정하는 단계를 포함하고,상기 하나 이상의 객체의 특징점들을 검출하는 단계는,상기 전경 프레임들 내 상기 전경 객체로부터 상기 하나 이상의 객체의 특징점들을 추출하는 단계를 포함하는,방법."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,상기 머리 움직임 궤적을 획득하는 단계는,상기 사용자의 머리에 위치한 제1 센서로부터 제1 센서 데이터를 획득하는 단계; 및상기 제1 센서 데이터에 기초하여, 상기 머리 움직임 궤적을 생성하는 단계를 포함하는, 방법.공개특허 10-2023-0114686-3-청구항 5 제1항 내지 제4항 중 어느 한 항에 있어서,상기 방법은,상기 사용자의 손에 위치한 제2 전자 장치의 제2 센서로부터 제2 센서 데이터를 획득하는 단계; 및상기 제2 센서 데이터에 기초하여, 상기 사용자의 손의 움직임을 나타내는 손 움직임 궤적을 생성하는 단계를더 포함하는, 방법."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항 중 어느 한 항에 있어서,상기 사용자의 손을 결정하는 단계는,상기 제2 센서 데이터에 기초한 상기 손 움직임 궤적이 생성된 것에 기초하여, 상기 머리 움직임 궤적 및 상기손 움직임 궤적을 비교함으로써 상기 사용자의 손을 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서,상기 사용자의 손을 결정하는 단계는, 상기 사용자의 손 후보에 대응하는 상기 객체 궤적 및 상기 머리 움직임 궤적 간의 상관 계수를 계산하는 단계;및상기 상관 계수가 기 설정된 값 이상인 것에 기초하여, 상기 사용자의 손 후보를 상기 사용자의 손으로 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제3항 내지 제7항 중 어느 한 항에 있어서,상기 하나 이상의 객체의 특징점들을 검출하는 단계는,상기 전경 프레임들 내 복수의 전경 객체들로부터, 복수의 사용자들의 얼굴 특징점들 및 손 특징점들을 검출하는 단계를 포함하고,상기 머리 움직임 궤적을 획득하는 단계는,상기 복수의 사용자들의 얼굴 특징점들에 기초하여 상기 복수의 사용자들의 머리 움직임 궤적들을 획득하는 단계를 포함하고,상기 사용자의 손을 결정하는 단계는,상기 복수의 사용자들 각각에 대하여, 상기 복수의 사용자들의 손 후보들을 상기 복수의 사용자들의 얼굴들과연관시킴으로써 상기 복수의 사용자들의 손을 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서,상기 사용자의 손을 결정하는 단계는,상기 사용자의 손이 왼손인지 오른손인지 여부를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항 내지 제9항 중 어느 한 항에 있어서,상기 방법은,공개특허 10-2023-0114686-4-제스처 인식에 기초하여 상기 전자 장치를 제어하기 위한 제어 명령을 실행하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "비디오 내에서 사용자의 손을 결정하는 전자 장치(2000)에 있어서,적어도 하나의 카메라(2200);하나 이상의 인스트럭션을 저장하도록 구성된 메모리(2300); 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서(2400)를 포함하고,상기 적어도 하나의 프로세서(2400)는, 상기 하나 이상의 인스트럭션을 실행함으로써,적어도 하나의 카메라를 이용하여 복수의 프레임들을 포함하는 비디오를 획득하고,상기 비디오의 프레임들을 이용하여 상기 적어도 하나의 카메라의 시야(Field of View; FoV)의 이동을 나타내는시야 궤적을 추정하고,상기 비디오의 프레임들 각각 내에서, 하나 이상의 객체의 특징점들을 검출하고,상기 하나 이상의 객체의 특징점들에 기초하여, 상기 하나 이상의 객체의 이동을 나타내는 객체 궤적을 추정하고,상기 카메라의 시야 궤적 및 상기 객체 궤적에 기초하여, 상기 하나 이상의 객체 중에서 사용자의 손 후보를 결정하고,상기 사용자의 머리의 움직임을 나타내는 머리 움직임 궤적을 획득하고,상기 사용자의 손 후보에 대응하는 상기 객체 궤적 및 상기 머리 움직임 궤적에 기초하여, 사용자의 손을 결정하고,상기 비디오 내에서 상기 결정된 사용자의 손을 추적하고 제스처를 인식하는, 전자 장치."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 비디오의 프레임들 각각에 대하여 전경 객체를 추출함으로써, 전경 프레임들 및 배경 프레임들을획득하는, 전자 장치."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 배경 프레임들 내 픽셀들을 비교하여 상기 적어도 하나의 카메라의 시야의 이동과 관련된, 시야 이동 정보를 획득하고,상기 시야 이동 정보에 기초하여 상기 카메라의 시야 궤적을 결정하고,상기 전경 프레임들 내 상기 전경 객체로부터 상기 하나 이상의 객체의 특징점들을 추출하는, 전자 장치."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항 내지 제13항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 머리에 위치한 제1 센서로부터 제1 센서 데이터를 획득하고,상기 제1 센서 데이터에 기초하여, 상기 머리 움직임 궤적을 생성하는, 전자 장치.공개특허 10-2023-0114686-5-청구항 15 제11항 내지 제14항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 사용자의 손에 위치한 제2 전자 장치의 제2 센서로부터 제2 센서 데이터를 획득하고,상기 제2 센서 데이터에 기초하여, 상기 사용자의 손의 움직임을 나타내는 손 움직임 궤적을 생성하는, 전자 장치."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항 내지 제15항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 제2 센서 데이터에 기초한 상기 손 움직임 궤적이 생성된 것에 기초하여, 상기 머리 움직임 궤적 및 상기손 움직임 궤적을 비교함으로써 상기 사용자의 손을 결정하는, 전자 장치."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항 내지 제16항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 사용자의 손 후보에 대응하는 상기 객체 궤적 및 상기 머리 움직임 궤적 간의 상관 계수를 계산하고,상기 상관 계수가 기 설정된 값 이상인 것에 기초하여, 상기 사용자의 손 후보를 상기 사용자의 손으로 결정하는, 전자 장치."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항 내지 제17항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 전경 프레임들 내 복수의 전경 객체들로부터, 복수의 사용자들의 얼굴 특징점들 및 손 특징점들을 검출하고,상기 복수의 사용자들의 얼굴 특징점들에 기초하여 상기 복수의 사용자들의 머리 움직임 궤적들을 획득하고,상기 복수의 사용자들 각각에 대하여, 상기 복수의 사용자들의 손 후보들을 상기 복수의 사용자들의 얼굴들과연관시킴으로써 상기 복수의 사용자들의 손을 결정하는, 전자 장치."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항 내지 제18항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 사용자의 손이 왼손인지 오른손인지 여부를 결정하는, 전자 장치."}
{"patent_id": "10-2022-0108652", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2022-0108652", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 비디오 내에서 사용자의 손을 결정하는 방법이 제공된다. 상기 방법은, 카메라를 이용하여 복수의 프레임들을 포함하는 비디오를 획득하는 단계; 상기 비디오의 프레임들을 이용하여 상기 카메라의 시야(Field of View; FoV)의 이동을 나타내는 시야 궤적을 추정하는 단계; 상기 비디오의 프레임들 각각 내에서, 하나 이상의 (뒷면에 계속)"}
{"patent_id": "10-2022-0108652", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "비디오 내에서 사용자의 손을 결정하여 제스처를 인식하는, 전자 장치 및 그 동작 방법이 제공된다."}
{"patent_id": "10-2022-0108652", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자 장치의 조작을 위한 인터랙션의 일 방법으로써, 제스처 인식을 이용한 제어 기능이 제공되고 있다. 전자 장치는 이미지 및/또는 비디오 내에서 손을 추적하고, 제스처를 인식하며, 인식된 제스처에 대응하는 제어 동작 을 수행한다. 전자 장치가 제스처 인식을 수행하는 경우, 전자 장치를 제어하고자 하는 사용자 외에 다른 사람 의 손에 의한 제스처가 인식되는 경우가 발생할 수 있다. 제스처 인식을 통한 사용자 인터랙션 제공 방법에 있어서, 이미지 및/또는 비디오 내에 존재하는 다른 사람의 손에 영향을 받지 않고, 사용자의 손을 정확하게 결정하여 제스처 인식을 수행하기 위한 방법을 제시하고자 한 다. 본 개시에서 이루고자 하는 기술적 과제는, 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른"}
{"patent_id": "10-2022-0108652", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해 될 수 있을 것이다."}
{"patent_id": "10-2022-0108652", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 따르면, 전자 장치가 비디오 내에서 사용자의 손을 결정하는 방법이 제공될 수 있다. 상기 방법은, 카메라를 이용하여 복수의 프레임들을 포함하는 비디오를 획득하는 단계를 포함할 수 있다. 상기 방법 은, 비디오의 프레임들을 이용하여 상기 카메라의 시야(Field of View; FoV)의 이동을 나타내는 시야 궤적을 추 정하는 단계를 포함할 수 있다. 상기 방법은, 상기 비디오의 프레임들 각각 내에서, 하나 이상의 객체의 특징점 들을 검출하는 단계를 포함할 수 있다. 상기 방법은, 상기 하나 이상의 객체의 특징점들에 기초하여, 상기 하나 이상의 객체의 이동을 나타내는 객체 궤적을 추정하는 단계를 포함할 수 있다. 상기 방법은, 상기 카메라의 시 야 궤적 및 상기 객체 궤적에 기초하여, 상기 하나 이상의 객체 중에서 사용자의 손 후보를 결정하는 단계를 포 함할 수 있다. 상기 방법은, 상기 사용자의 머리의 움직임을 나타내는 머리 움직임 궤적을 획득하는 단계를 포 함할 수 있다. 상기 방법은, 상기 사용자의 손 후보에 대응하는 상기 객체 궤적 및 상기 머리 움직임 궤적에 기 초하여, 사용자의 손을 결정하는 단계를 포함할 수 있다. 상기 방법은, 상기 비디오 내에서 상기 결정된 사용자 의 손을 추적하고 제스처를 인식하는 단계를 포함할 수 있다. 본 개시의 일 측면에 따르면, 비디오 내에서 사용자의 손을 결정하는 전자 장치가 제공될 수 있다. 상기 전자 장치는, 통신 인터페이스, 카메라, 하나 이상의 인스트럭션을 저장하도록 구성된 메모리, 및 상기 메모리에 저 장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함할 수 있다. 프로세서는, 상기 하나 이상의 인스 트럭션이 실행될 시, 카메라를 이용하여 복수의 프레임들을 포함하는 비디오를 획득하도록 설정될 수 있다. 프 로세서는, 상기 하나 이상의 인스트럭션이 실행될 시, 상기 비디오의 프레임들을 이용하여 상기 카메라의 시야 (Field of View; FoV) 궤적을 추정하도록 설정될 수 있다. 프로세서는, 상기 하나 이상의 인스트럭션이 실행될 시, 상기 비디오의 프레임들 각각 내에서, 하나 이상의 객체의 특징점들을 검출하도록 설정될 수 있다. 프로세 서는, 상기 하나 이상의 인스트럭션이 실행될 시, 상기 하나 이상의 객체의 특징점들에 기초하여, 객체 궤적을 추정하도록 설정될 수 있다. 프로세서는, 상기 하나 이상의 인스트럭션이 실행될 시, 상기 카메라의 시야 궤적 및 상기 객체 궤적에 기초하여, 상기 하나 이상의 객체 중에서 사용자의 손 후보를 결정하도록 설정될 수 있다. 프로세서는, 상기 하나 이상의 인스트럭션이 실행될 시, 상기 사용자의 머리 움직임 궤적을 획득하도록 설정될 수 있다. 프로세서는, 상기 하나 이상의 인스트럭션이 실행될 시, 상기 사용자의 손 후보에 대응하는 상기 객체 궤적 및 상기 사용자의 머리 움직임 궤적에 기초하여, 사용자의 손을 결정하도록 설정될 수 있다. 프로세서는, 상기 하나 이상의 인스트럭션이 실행될 시, 상기 비디오 내에서 상기 결정된 사용자의 손을 추적하고 제스처를 인식하도록 설정될 수 있다. 본 개시의 일 측면에 따르면, 전자 장치가 사용자의 손을 결정하는, 전술 및 후술하는 방법들 중 어느 하나를 실행시키기 위한 프로그램이 기록된 컴퓨터 판독 가능 기록매체를 제공할 수 있다."}
{"patent_id": "10-2022-0108652", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에서, \"a, b 또는 c 중 적어도 하나\" 표현은 \" a\", \" b\", \" c\", \"a 및 b\", \"a 및 c\", \"b 및 c\", \"a, b 및 c 모두\", 혹은 그 변형들을 지칭할 수 있다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의 미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 또한, 본 명세서에서 사용되는 '제1' 또는 '제2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만 사용된다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소 프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 결정하는 동작을 개략적으로 설명하기 위한 도 면이다. 일 실시예에서, 전자 장치는 사용자의 머리에 착용 가능한 헤드 마운티드 디스플레이(Head Mounted Display; HMD) 또는 AR Glasses일 수 있다. 전자 장치는 사용자의 손을 인식하고, 사용자의 에어 제스처 (air gestures)를 인식하여 동작하는 사용자 인터페이스를 제공할 수 있다. 전자 장치가 제스처 인터랙션을 제공하는 경우, 전자 장치는 제어 권한을 가진 사용자 및/또는 전 자 장치의 사용자의 손을 추적하고 제스처를 인식할 수 있다. 이 경우, 전자 장치는 제스처 인식의 대상이 되는 사용자의 손을 결정할 수 있다. 도 1에 도시된 카메라 시야를 참조하면, 일 실시예에 따른 전자 장치의 카메라 시야에는 다양한 객체들, 즉 손들이 등장할 수 있다. 예를 들어, 전자 장치의 카메라 시야에는 다른 사람의 손들(102, 108, 110) 및 사용자의 손들(104, 106)이 포함될 수 있다. 일 실시예에서, 전자 장치가 카메라 시야에 포함되는 다른 사람의 손들(102, 108, 110)을 인식하여 다른 사람의 손들(102, 108, 110)의 제스처에 의하여 제어된다면, 전자 장치의 사용자가 전자 장치를 원 활하게 사용할 수 없게 된다. 전자 장치는 사용자의 제스처에 의해 전자 장치가 제어될 수 있도록, 카메라의 시야 내에서 사용자의 손들(104, 106)을 결정하고, 사용자의 손들(104, 106)만을 추적하여 제스처를 인식할 수 있다. 이 경우, 전자 장치는 각각의 인식된 제스처 유형에 따라 대응하는 제어 명령을 실행할 수 있다. 전자 장치는, 다른 사람의 손을 사용자의 손으로 인식하지 않으므로, 사용자 외 다른 사람이 전자 장치 를 제어하기 위한 손 제스처를 취하더라도, 제어 명령을 실행하지 않을 수 있다. 예를 들어, 전자 장치 는 다른 사람의 손들(102, 108, 110)의 제스처에 의해서는 제어되지 않을 수 있다. 전자 장치가 사용자의 손을 결정하는 구체적인 동작들에 대해서는, 후술하는 도면들과 그에 대한 상세한 설명에서 더 상세하게 기술하기로 한다. 한편, 도 1 및 후술하는 도면들에서는, 전자 장치가 사용자의 머리에 착용 가능한 디바이스임을 예시로 설명하였다. 즉, 사용자의 자기 중심적인 시야를 기준으로 전자 장치가 사용자의 손을 결정하는 예시들이 주로 설명될 것이다. 다만, 본 개시는 이에 한정되는 것은 아니다. 구체적으로, 전자 장치는 스마트폰, TV, 로봇 등, 카메라를 포함하고 제스처에 의해 제어 가능한 다른 유형의 전자 장치들을 포함할 수 있다. 전자 장치가 사용자의 머리에 착용 가능한 디바이스가 아닌 다른 유형의 디바이스인 경우, 전자 장치는 측면 뷰에서 사용자를 카메라로 촬영하며, 개시된 실시예들에 따라 비디오에 포함되는 사용자 및 그 사용자의 손을 결정할 수 있다. 전자 장치는 사용자의 손을 결정하면, 사용자의 손을 추적하여 제스처를 인식하고 제어 동작을 수행할 수 있다.도 2는 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 결정하는 방법을 설명하기 위한 흐름도이다. 단계 S210에서, 전자 장치는 카메라를 이용하여 복수의 프레임들을 포함하는 비디오를 획득한다. 전자 장 치는 카메라를 이용하여 비디오를 촬영하면서, 실시간으로 획득되는 비디오의 프레임들을 분석할 수 있다. 일 실시예에서, 전자 장치에 포함되는 카메라는 하나 이상일 수 있다. 전자 장치는 예를 들어, RGB 카메라, 깊이 카메라 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 단계 S220에서, 전자 장치는 비디오의 프레임들을 이용하여 카메라의 시야(Field of View; FoV)의 이동을 나타내는 시야 궤적을 추정한다. 일 실시예에서, 전자 장치는 비디오에 포함되는 프레임들 각각에 대하여, 전경 및 배경을 분리할 수 있다. 전자 장치가 프레임으로부터 전경과 배경을 분리하는 방법에는, 다양한 알고리즘이 이용될 수 있다. 예를 들어, 전자 장치는 비디오의 프레임들로부터 전경 객체를 추출하여, 전경 객체를 포함하는 전 경 프레임들 및 전경 객체를 제외한 배경 프레임들을 획득할 수 있다. 전자 장치는 획득된 배경 프레임들 을 이용하여 카메라의 시야 궤적을 추정할 수 있다. 예를 들어, 전자 장치는 배경 프레임들 내 픽셀들을 비교할 수 있다. 이 경우, 배경 프레임들은 시간순으로 정렬된 프레임들일 수 있다. 전자 장치는 배경 프 레임들 내 픽셀들을 비교함으로써, 카메라의 촬영 시야의 이동을 나타내는 시야 이동 정보를 획득할 수 있다. 전자 장치는 시야 이동 정보에 기초하여, 전자 장치의 카메라의 시야 궤적을 결정할 수 있다. 일 실시예에서, 전자 장치는 비디오에 포함되는 프레임들 중에서, 전경 및 배경을 분리할 프레임들을 선 택할 수 있다. 예를 들어, 전자 장치는 시간순으로 나열된 프레임들 중에서, 기 설정된 간격으로 일부의 프레임들만을 추출하여, 전경 및 배경 분리 처리를 수행할 수 있다. 일 실시예에서, 전자 장치는 전자 장치에 포함되는 하나 이상의 센서를 이용하여, 카메라의 시야 궤적을 추정할 수 있다. 예를 들어, 전자 장치는 IMU(Inertial Measurement Unit) 센서를 이용하여, 카 메라의 이동 정보 및 회전 정보를 획득할 수 있다. IMU 센서는, 가속도 센서, 자이로 센서 및 지자기 센서 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 전자 장치의 이동 정보 및 회전 정보 에 기초하여 전자 장치의 카메라의 시야 궤적을 결정할 수 있다. 단계 S230에서, 전자 장치는 비디오의 프레임들 각각 내에서, 하나 이상의 객체의 특징점들을 검출한다. 일 실시예에서, 전자 장치는 단계 S220에서 획득한 전경 프레임들을 이용하여, 비디오 내 하나 이상의 전 경 객체의 특징점들을 검출할 수 있다. 예를 들어, 비디오 내에 손이 있어서 전경 객체로 식별된 경우, 전자 장 치는 손의 특징점들인 손가락 마디, 손바닥, 손목 등을 검출할 수 있다. 다만, 객체 '손'의 전술한 특징 점들은 예시일 뿐이며, '손'에 대하여 다른 특징점들이 검출될 수 있다. 또한, '손' 외에 다른 종류의 객체(예 를 들어, 머리, 얼굴 등)에 대하여, 각각의 객체에 대하여 정의된 특징점들이 검출될 수도 있다. 일 실시예에서, 전자 장치는 객체의 특징점들을 검출하기 위한 인공지능 모델을 이용할 수 있다. 이 경우, 객체의 특징점들을 검출하기 위한 인공지능 모델은, 여러 객체의 카테고리 별로 객체의 특징점들이 주석 (annotation)된 훈련 데이터셋을 이용하여 훈련된 것일 수 있다. 일 실시예에서, 전자 장치는 객체의 특 징점들을 검출할 때, 객체의 카테고리를 먼저 식별하고, 식별된 카테고리에 대응하는 특징점들을 검출할 수 있 다. 예를 들어, 전자 장치는 전경 프레임들 내에서 객체 '손'을 식별하고, '손'의 특징점들을 검출할 수 있다. 단계 S240에서, 전자 장치는 하나 이상의 객체의 특징점들에 기초하여, 객체의 이동을 나타내는 객체 궤 적을 추정한다. 전자 장치는 비디오에 촬영된 하나 이상의 객체들의 특징점들의 이동 정보를 획득할 수 있다. 예를 들어, 전자 장치는 하나의 객체에서 검출된 특징점들에 기초하여 전경 프레임들 내에서 객체 (또는 객체의 특징점들)의 이동 정보를 획득할 수 있다. 예를 들어, 전자 장치는 하나의 객체에서 검출된 특징점들의 집합 및/또는 특징점들의 무게중심 등을 이용하여, 객체의 이동 정보를 생성할 수 있다. 전자 장치 는 객체의 이동 정보에 기초하여, 객체의 궤적을 결정할 수 있다. 단계 S250에서, 전자 장치는 카메라의 시야 궤적 및 객체 궤적에 기초하여, 하나 이상의 객체 중에서 사 용자의 손 후보를 결정한다. 일 실시예에서, 비디오 내 복수의 객체들이 있는 경우, 전술한 실시예들에 따라 복수의 객체들에 각각 대응하는 객체 궤적들이 획득될 수 있다. 예를 들어, 비디오 내 사용자의 손 및 전자 장치의 사용자가 아닌 다른사람들의 손이 포함될 수 있다. 전자 장치는 다른 사람들의 손을 인식하지 않고 사용자의 손만을 인식하 기 위해, 사용자의 손 후보를 결정할 수 있다. 사용자의 손 후보는 예를 들어, 실제 사용자의 손, 다른 사람들 의 손 등을 포함할 수 있다. 전자 장치는 사용자의 손 후보 중에서 실제 사용자의 손이 무엇인지를 결정 할 수 있다. 전자 장치는 객체 궤적들 중에서, 사용자의 손의 움직임을 나타내는 궤적으로 추정되는 객체 궤적을 결정 할 수 있다. 예를 들어, 전자 장치가 사용자의 머리에 착용 가능한 HMD인 경우, 사용자의 머리 움직임에 따른 카메라의 시야 궤적과 사용자의 손 움직임에 따른 손의 궤적은 상관 계수가 높게 나타날 수 있다. 전자 장 치는 비디오 내 하나 이상의 객체 중에서, 사용자의 손 후보를 결정하기 위해 카메라의 시야 궤적 및 객 체 궤적 간의 상관 계수를 계산할 수 있다. 전자 장치가 궤적 간 상관 계수를 계산하는 방법은, 다양한 알고리즘이 사용될 수 있다. 일 실시예에서, 전자 장치는 상관 계수 계산을 위한 신호 처리를 수행할 수 있다. 이러한 신호 처리에는 예를 들어, 동적 시간 워핑(Dynamic Time Warping; DTW) 등이 이용될 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 카메라의 시야 궤적 및 객체 궤적 간의 상관 계수가 기 설정된 값 이상인 것에 기초하여, 하 나 이상의 객체들 중에서 사용자의 손 후보를 결정할 수 있다. 전자 장치는 후술되는 동작들을 더 수행하 여, 사용자의 손 후보 중에서 어떤 객체가 사용자의 손인지를 결정할 수 있다. 단계 S260에서, 전자 장치는 사용자의 머리의 움직임을 나타내는 머리 움직임 궤적을 획득한다. 일 실시예에서, 전자 장치는 전자 장치에 포함되는 하나 이상의 센서를 이용하여, 사용자의 머리 움직임 궤적을 획득할 수 있다. 예를 들어, 전자 장치가 사용자의 머리에 착용 가능한 HMD인 경우, 전자 장치는 IMU(Inertial Measurement Unit) 센서를 이용하여 사용자의 머리 움직임 정보를 획득할 수 있다. 전자 장치는 사용자의 머리 움직임을 나타내는 머리 움직임 정보에 기초하여, 전자 장치를 머리에 착용한 사용자의 머리 움직임 궤적을 결정할 수 있다. 일 실시예에서, 전자 장치는 비디오에 포함되는 프레임들을 이용하여, 사용자의 머리 움직임 궤적을 획득 할 수 있다. 예를 들어, 전자 장치는 카메라를 포함하여 사용자를 촬영 가능한 디바이스일 수 있다. 전자 장치는 사용자를 촬영하여 실시간으로 비디오 프레임들을 획득하고, 비디오 프레임들 중에서, 전경 및 배 경을 분리하고, 전경 객체들 중에서 사람의 머리 특징점들을 검출할 수 있다. 전자 장치는 머리 특징점들 에 기초하여, 전경 프레임들 내에서 사용자의 머리 움직임 정보를 획득할 수 있다. 전자 장치는 사용자의 머리 움직임 정보에 기초하여, 사용자의 머리 움직임 궤적을 결정할 수 있다. 단계 S270에서, 전자 장치는 사용자의 손 후보에 대응하는 객체 궤적 및 머리 움직임 궤적에 기초하여, 사용자의 손을 결정한다. 일 실시예에서, 전자 장치는 단계 S250에서 결정된 손 후보에 대응하는 객체 궤적을 획득할 수 있다. 전 자 장치는 사용자의 손 후보에 대응하는 객체 궤적 및 사용자의 머리 움직임 궤적을 비교할 수 있다. 예 를 들어, 전자 장치는 사용자의 손 후보에 대응하는 객체 궤적과 사용자의 머리 움직임 궤적 간 상관 계 수를 계산할 수 있다. 전자 장치가 궤적 간 상관 계수를 계산하는 방법에는, 다양한 알고리즘이 사용될 수 있다. 예를 들어, 동적 시간 워핑(Dynamic Time Warping; DTW) 등이 이용될 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 사용자의 손 후보에 대응하는 객체 궤적 및 사용자의 머리 움직임 궤적 간의 상관 계수가 기 설정된 값 이상인 것에 기초하여, 사용자의 손 후보들 중에서 사용자의 손을 결정할 수 있다. 단계 S280에서, 전자 장치는 비디오 내에서 결정된 사용자의 손을 추적하고 제스처를 인식한다. 전자 장치는 전자 장치를 사용하는 사용자의 손만을 인식하여, 사용자의 손을 추적하고, 사용자의 손이 나타내는 제스처를 인식할 수 있다. 일 실시예에서, 사용자의 손 제스처 유형 각각에는, 기 설정된 전자 장치에 대한 제어 명령이 저장되어 있을 수 있다. 전자 장치는 사용자의 손에 대한 제스처 인식에 기초하여, 전자 장치를 제어하기 위한 제어 명령을 실행할 수 있다. 이 경우, 전자 장치의 사용자 외 다른 사람이 전자 장치를 제어하기 위한 손 제스처를 취하더라도, 전자 장치는 다른 사람의 손 을 사용자의 손으로 인식하지 않으므로, 제어 명령을 실행하지 않을 수 있다. 도 3은 본 개시의 일 실시예에 따른 전자 장치의 사용자의 몸 움직임을 설명하기 위한 도면이다. 도 3을 설명함에 있어서, 전자 장치는 머리에 착용 가능한 HMD인 경우를 예시로 설명한다. 일 실시예에서, 사용자가 전자 장치를 머리에 착용하여 사용하는 경우, 예를 들어, 가상 현실, 증강 현실, 휴먼-컴퓨터 인터랙션 등, 다양한 경우에, 사용자는 제스처를 조작을 통해 전자 장치를 제어할 수 있다. 사용자가 제스처 조작을 하는 동안, 사용자의 몸 부분들(예를 들어, 손, 머리, 몸통 등)은 부분적으로 동 기화되어 움직인다. 예를 들어, 전자 장치는 카메라를 이용하여 사용자의 시야를 촬영하여 획득한 비디오를 참조하여 설명한 다. 비디오는 복수의 프레임들(제1 프레임, 제2 프레임, 제3 프레임)을 포함한다. 다만, 설명의 편의를 위해 3개의 프레임들만을 도시하였을 뿐, 비디오에는 더 많은 프레임들이 포함될 수 있다. 제1 프레임은, 사용자의 시야가 왼쪽을 바라보고 있을 때를 촬영한 프레임이다. 제2 프레임은, 사용자의 시야가 정면을 바라보고 있을 때를 촬영한 프레임이다. 제3 프레임은, 사용자의 시야가 오 른쪽을 바라보고 있을 때를 촬영한 프레임이다. 전자 장치의 사용자는 손을 왼쪽에서 오른쪽으로 움직이는 제스처를 취할 수 있다. 제1 프레임, 제2 프레임 및 제3 프레임을 참조하면, 사용자가 왼쪽을 바라보다가, 정면을 바라보고, 오른쪽 을 바라보면서, 손을 왼쪽에서 오른쪽으로 이동시키고 있음을 알 수 있다. 이와 같이, 사용자가 제스처를 통하여 전자 장치를 제어할 때, 사용자의 몸 부분들(예를 들어, 손, 머리, 몸통 등)은 부분적으로 동기화 되어 움직인다. 본 개시는 이러한 사용자의 몸 부분들의 부분적으로 동기화되는 특징에 기초하여, 사용자의 몸 부분들의 궤적 분석을 통해 사용자의 손을 사용자 외 다른 사람들의 손과 구별할 수 있다. 도 4는 본 개시의 일 실시예에 따른 전자 장치가 카메라의 시야 궤적을 획득하는 동작을 설명하기 위한 흐름도 이다. 단계 S410은 내지 단계 S430은, 도 2의 단계 S220에 대응될 수 있다. 단계 S410에서, 전자 장치는 비디오의 프레임들 각각에 대하여 전경 객체를 추출함으로써, 전경 프레임들 및 배경 프레임들을 획득한다. 일 실시예에서, 전자 장치는 비디오의 프레임 내에서 객체를 검출하기 위한 인공지능 모델(이하, 객체 검 출 모델)을 이용하여 객체를 검출할 수 있다. 객체 검출 모델은, 이미지를 입력 받아, 객체를 검출(예를 들어, 손, 얼굴 등)한 결과를 출력하는 인공지능 모델일 수 있다. 객체 검출 모델은 객체를 검출하기 위해 객체에 관 련된 정보(예를 들어, 객체의 카테고리 등)가 주석된(annotated) 훈련 데이터셋을 이용하여 훈련된 인공지능 모 델일 수 있다. 전자 장치는 비디오의 프레임 내에서 객체를 검출하고, 객체의 엣지 영역을 식별한 뒤, 프 레임 내에서 검출된 객체 영역을 분리하여 전경 프레임을 생성할 수 있다. 전자 장치는 프레임 내에서 검 출된 객체를 제외한 나머지 영역을 분리하여 배경 프레임을 생성할 수 있다. 일 실시예에서, 전자 장치는 알려진 전경/배경 분리 알고리즘을 이용하여 전경 프레임들 및 배경 프레임 들을 생성할 수 있다. 이러한 방식은 해당 기술 분야의 통상의 기술자에게 용이하게 도출 가능하므로, 설명을 생략한다. 한편 단계 S410에서, 프레임 및 객체를 단수로 표현하여 설명하였으나, 이는 설명의 편의를 위한 예시일 뿐이다. 비디오에 포함되는 프레임은 하나 이상이며, 각각의 프레임들에 포함되는 객체 또한 하나 이상일 수 있 다. 프레임 및/또는 객체가 하나 이상인 경우에도, 전술한 실시예가 동일하게 적용될 수 있다. 단계 S420에서, 전자 장치는 배경 프레임들 내 픽셀들을 비교하여 카메라의 시야 이동을 나타내는 시야 이동 정보를 획득한다. 시야 이동 정보는 카메라의 이동, 회전을 포함하는 3차원 이동에 관련된 정보를 포함할 수 있다. 일 실시예에서, 전자 장치는 비디오에 포함되는 프레임들을 이용하여 배경 프레임들을 획득한다. 전자 장 치는 인접한 배경 프레임 간의 픽셀을 비교하여, 전자 장치의 카메라의 시야 이동 정보를 획득할 수 있다. 예를 들어, 전자 장치는, 인접한 프레임 간에 중복(동일 또는 유사한 값을 갖는 픽셀)되는 픽셀 값 외에, 차이가 있는 픽셀들이 어느 방향인지에 기초하여, 카메라의 시야가 어느 방향으로 이동하였는지를 나 타내는 시야 이동 정보를 획득할 수 있다. 일 실시예에서, 전자 장치의 카메라의 시야 이동 정보는, 전자 장치에 포함되는 센서로부터 획득되 는 센서 데이터를 이용하여 생성될 수도 있다. 예를 들어, 전자 장치는 IMU(Inertial Measurement Unit)센서를 이용하여, 카메라의 이동 정보 및 회전 정보를 획득할 수 있다. IMU 센서는, 가속도 센서, 자이로 센서 및 지자기 센서 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 전자 장치의 이 동 정보 및 회전 정보에 기초하여 전자 장치의 카메라의 시야 이동 정보를 생성할 수 있다. 단계 S430에서, 전자 장치는 시야 이동 정보에 기초하여 카메라의 시야 궤적을 결정한다. 전자 장치는 시야 이동 정보에 기초하여, 전자 장치의 카메라의 3차원 공간 상에서의 시야 궤적을 생성할 수 있다. 카메라의 시야 궤적은, 전술한 HMD를 예로 들면, 사용자가 HMD를 착용하고 머리를 회전시키거 나, 사용자가 3차원 공간 내에서 이동하면서 바라본 시야의 궤적을 의미할 수 있다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 객체의 특징점을 추출하는 동작을 설명하기 위한 흐름도이다. 단계 S510 내지 S520은, 도 2의 단계 S230에 대응될 수 있다. 단계 S510에서, 전자 장치는 비디오의 프레임들 각각에 대하여 전경 객체를 추출함으로써, 전경 프레임들 및 배경 프레임들을 획득한다. 전자 장치가 전경 프레임들을 생성하는 동작에 대해서는, 도 4의 단계 S410에 대한 설명에서 이미 서술하였으므로, 동일한 설명은 생략한다. 단계 S520에서, 전자 장치는 전경 프레임들 내 전경 객체로부터 하나 이상의 객체의 특징점들을 추출한다. 일 실시예에서, 전자 장치는 객체의 특징점들을 검출하기 위한 인공지능 모델(이하, 객체 특징 검출 모델)을 이용할 수 있다. 이 경우, 객체의 특징점들을 검출하기 위한 인공지능 모델은, 여러 객체의 카테고리 별로 객체의 특징점들이 주석(annotation)된 훈련 데이터셋을 이용하여 훈련된 것일 수 있다. 예를 들어, 전자 장치는 전경 프레임의 전경 객체인 '손'의 특징점들인 손가락 마디, 손바닥, 손목 등을 검출할 수 있다. 다만, 객체 '손'의 전술한 특징점들은 예시일 뿐이며, '손'에 대하여 다른 특징점들이 검출 될 수 있다. 또한, '손' 외에 다른 종류의 객체(예를 들어, 머리, 얼굴 등)에 대하여, 각각의 객체에 대하 여 정의된 특징점들이 검출될 수도 있다. 도 6은 본 개시의 일 실시예에 따른 전자 장치가 이용하는, 궤적을 설명하기 위한 도면이다. 일 실시예에서, 궤적들은 다양한 데이터를 이용하여 생성될 수 있다. 예를 들어, 전자 장치는 IMU(Inertial Measurement Unit) 센서를 이용하여, 센서 기반 데이터를 획득할 수 있다. 센서 기반 데이 터는 시간 순으로 센싱된 데이터일 수 있다. 또는, 전자 장치는 비디오 프레임들(제1, 제2, 제3 프레임 등)로부터 이미지 기반 데이터를 획득할 수 있다. 일 실시예에서, 전자 장치는 센서 기반 데이터에 기초하여 궤적들을 생성할 수 있다. 예를 들어, 전자 장치는 사용자의 머리에 위치한 센서(예를 들어, IMU 센서 등)로부터, 센서 기반 데이터 를 획득하고, 사용자의 머리 움직임 궤적(즉, 궤적들)을 생성할 수 있다. 이 경우, 사용자의 머리에 위치한 센서는 전자 장치가 HMD인 경우 HMD에 포함되는 센서일 수 있으나, 이에 한정되는 것은 아니며, 별도의 센서가 사용자의 머리에 위치하여 전자 장치로 센서 기반 데이터를 제공할 수 있다. 또는, 전자 장치는 사용자의 손에 위치한 센서(예를 들어, IMU 센서 등)로부터, 센서 기반 데이터를 획득하고, 사용자의 손 움직임 궤적(즉, 궤적들)을 생성할 수 있다. 이 경우, 사용자의 손에 위치한 센서 는 전자 장치와 유선/무선 통신 연결된 웨어러블 디바이스(예를 들어, 스마트 워치 등)일 수 있으나, 이 에 한정되는 것은 아니며, 별도의 센서가 사용자의 손에 위치하여 전자 장치로 센서 기반 데이터를 제공할 수 있다. 또는, 전자 장치는 전자 장치의 카메라에 인접하여 위치한 센서(예를 들어, IMU 센서 등)로부터, 센서 기반 데이터를 획득하고, 카메라의 시야 이동 궤적(즉, 궤적들)을 생성할 수 있다. 이는, 전술 하였으므로, 동일한 설명은 생략한다. 일 실시예에서, 전자 장치는 이미지 기반 데이터에 기초하여 궤적들을 생성할 수 있다. 예를 들어, 전자 장치는 비디오 프레임들(제1, 제2, 제3 프레임 등)로부터 생성되는 이미지 기반 데이터 를 이용하여, 카메라의 시야 이동 궤적(즉, 궤적들)을 생성할 수 있다. 이 경우, 이미지 기반 데이터 는 전술한 배경 프레임들로부터 획득된 시야 이동 정보를 포함할 수 있다. 이는, 전술하였으므로, 동일한 설명은 생략한다.또는, 전자 장치는 비디오 프레임들(제1, 제2, 제3 프레임 등)로부터 생성되는 이미지 기반 데이터 를 이용하여, 객체 궤적(즉, 궤적들)을 생성할 수 있다. 이 경우, 이미지 기반 데이터는 전술한 전경 프레임들로부터 획득된 객체 특징점 정보를 포함할 수 있다. 한편, 객체 특징점 정보는 사용자의 머리, 얼굴, 손 등의 특징점일 수 있으며, 각각의 경우의 궤적은 머리(얼굴) 움직임 궤적, 손 움직임 궤적이 될 수 있다. 이 는, 전술하였으므로, 동일한 설명은 생략한다. 도 7a 내지 도 7b는 일 실시예에 따른 전자 장치가 센서 데이터로부터 궤적을 생성되하 동작을 더 설명하기 위 한 도면이다. 도 7a는 본 개시의 일 실시예에 따른 전자 장치가 센서 데이터를 획득하는 동작을 설명하기 위한 도면이다. 일 실시예에 따른 전자 장치는 사용자의 머리에 위치한 제1 센서 로부터 제1 센서 데이터를 획 득할 수 있다. 제1 센서는, 전자 장치가 HMD인 경우 HMD에 포함되는 센서일 수 있으나, 이에 한정되 는 것은 아니며, 별도의 제1 센서가 사용자의 머리에 위치하여 전자 장치로 제1 센서 데이터를 제공할 수 있다. 제1 센서 데이터는 시간에 따른 x축, y축, z축으로의 이동 정보 및/또는 회전 정보 등을 포함할 수 있다. 전자 장치는 사용자의 머리에 위치한 제1 센서로부터 획득되는 제1 센서 데이터 에 기초하여, 사용자의 머리 움직임 궤적을 생성할 수 있다. 이는, 도 7b를 참조하여 더 설명한다. 일 실시예에 따른 전자 장치는 사용자의 손에 위치한 제2 센서로부터 제2 센서 데이터를 획득 할 수 있다. 제2 센서는, 전자 장치와 유선/무선 통신 연결된 웨어러블 디바이스(예를 들어, 스마트 워치 등)일 수 있으나, 이에 한정되는 것은 아니며, 별도의 센서가 사용자의 손에 위치하여 전자 장치로 제2 센서 데이터를 제공할 수 있다. 제2 센서 데이터는 시간에 따른 x축, y축, z축으로의 이동 정보 및/또는 회전 정보 등을 포함할 수 있다. 전자 장치는 사용자의 손에 위치한 제2 센서로부터 획득되 는 제2 센서 데이터에 기초하여, 사용자의 손 움직임 궤적을 생성할 수 있다. 이는, 도 7b를 참조하여 더 설명한다. 도 7b는 본 개시의 일 실시예에 따른 전자 장치가 센서 데이터에 기초하여 궤적을 생성하는 동작을 설명하기 위 한 도면이다. 일 실시예에 따른 전자 장치가 도 7a의 제1 센서 데이터 및 제2 센서 데이터로부터 손/머리 움 직임 궤적을 생성하는 원리는 동일하므로, 설명의 편의를 위해 제1 센서 데이터에 대하여만 서술한다. 일 실시예에서, 제1 센서 데이터는 시간 단계별로 각각 x축 이동 정도, y축 이동 정도, z축 이동 정도를 나타내는 정보를 포함할 수 있다. 일 실시예에서, 전자 장치는 제1 센서 데이터에 기초하여, 움직임 궤적을 생성할 수 있다. 전술한 예시에 따르면, 제1 센서 데이터는 사용자의 머리에 위치한 제1 센서 로부터 획득되는 데이터이므로, 움직임 궤적은 사용자의 머리 움직임 궤적일 수 있다. 일 실시예에서, 전자 장치는 궤적을 x축, y축, z축의 3차원 정보를 포함하는 3차원 궤적으로 저장할 수 있다. 전자 장치는 또는, 전자 장치는 3차원 궤적을 간소화하여 2차원 궤적으로 저장할 수 있다. 전자 장치는 후술하는 궤적 상관 계수 계산에 있어서 3차원 궤적 및/또는 2차원 궤적을 이용할 수 있다. 한편, 도 7b에서는 제1 센서 데이터를 예시로 하여 사용자의 머리 움직임 궤적을 생성하는 예시를 설명하 였으나, 이와 유사하게, 전자 장치는 제2 센서 데이터를 이용하여 사용자의 손 움직임 궤적을 생성 할 수 있다. 도 8은 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손 후보를 결정하는 동작을 설명하기 위한 도면이다. 단계 S810에서, 전자 장치는 전자 장치의 카메라의 시야 궤적을 획득한다. 전자 장치는 이미 지 기반 데이터 및/또는 센서 기반 데이터에 기초하여, 카메라의 시야 궤적을 생성할 수 있다. 전자 장치(200 0)가 카메라의 시야 궤적을 획득하는 구체적인 동작들은 전술하였으므로, 동일한 설명은 생략한다. 단계 S820에서, 전자 장치는 하나 이상의 객체 궤적을 획득한다. 전자 장치는 비디오의 프레임 내 에서 객체를 검출하고, 객체의 특징점들을 검출할 수 있다. 전자 장치는 검출된 객체 및/또는 객체의 특 징점들에 기초하여 하나 이상의 객체 궤적을 생성할 수 있다. 전자 장치가 객체 궤적을 획득하는 구체적 인 동작들은 전술하였으므로, 동일한 설명은 생략한다. 단계 S830에서, 전자 장치는 카메라의 시야 궤적 및 객체 궤적 간 상관 계수를 계산한다. 전자 장치 는 상관 관계를 찾기 위한 다양한 알고리즘을 이용할 수 있다. 전자 장치는 상관 계수 계산을 위한 신호 처리를 수행할 수 있다. 이러한 신호 처리는 예를 들어, 동적 시간 워핑(Dynamic Time Warping; DTW) 등이 이용될 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에 따른 전자 장치는 비디오에 포함되는 객체 중에서, 카메라의 시야 궤적 과 상관 관계가 높은 객체의 궤적들만을 필터링할 수 있다. 단계 S840에서, 전자 장치는 상관 계수가 기 설정된 값 이상인 것에 기초하여, 사용자의 손 후보를 결정한다. 전술한 예시에 따르면, 사용자의 몸 부분들(예를 들어, 손, 머리, 몸통 등)은 부분적으로 동기화되어 움직이므로, 사용자가 HMD를 착용하여 제스처 조작을 수행하는 경우, 카메라의 시야 궤적과 사용자의 손 움직임 궤적은 유사하다. 전자 장치는 상관 계수에 기초하여, 객체의 궤적과 카메라의 시야 궤적의 상관 계 수가 기 설정된 값(예를 들어, 0.54) 이상인 것에 기초하여, 해당 궤적을 갖는 객체를 사용자의 손 후보로 결정할 수 있다. 도 9a는 본 개시의 일 실시예에 따른 전자 장치가 카메라의 시야 궤적과 사용자의 손 움직임 궤적을 비교하는 동작을 설명하기 위한 도면이다. 도 9a를 설명함에 있어서, 비디오 내의 객체가 '손' 이므로, 전술한 실시예들에 따라 획득된 객체 궤적은 '손 움직임 궤적'을 예시로 설명한다. 도 9a의 이미지는, 사용자가 HMD 유형의 전자 장치를 착용하고, 제스처를 이용하여 전자 장치(200 0)를 제어하는 것을 설명하기 위한 이미지이다. 일 실시예에서, 전자 장치의 사용자는, 전자 장치를 제어하기 위해서 제스처를 입력할 수 있다. 예 를 들어, 도 9a 의 이미지에 표현된 것과 같이, 전자 장치의 사용자는 왼손의 좌우 이동을 반복하는 제스처를 입력할 수 있다. 전자 장치는 사용자의 제스처를 인식하고, 제스처에 대응하는 제어 명령을 실 행한다. 예를 들어, 전자 장치는 사용자의 손이 '왼손'이고, 제스처가 '좌우 이동'임을 인식하여, 해당 제스처에 대응하는 제어 명령을 실행할 수 있다. 일 실시예에 따른 전자 장치는, 사용자의 손 움직임 궤적과 카메라의 시야 궤적을 비교하고, 손 움직임 궤적과 카메라의 시야 궤적 간의 상관 계수를 계산할 수 있다. 도 9a에 도시된 것과 같이, 전자 장치가 손 특징점들에 기초하여 추정한 손 움직임 궤적(즉, 전술한 실시예들에 따른, 객체의 특징점 들에 기초하여 추정한 객체 궤적)은, 복수개일 수 있다. 일 실시예에 따른 전자 장치는, 상관 계수가 기 설정된 값 이상인 것에 기초하여, 사용자의 손 후보를 결정한다. 이 경우, 결정된 사용자의 손 후보에 대응하는 손 움직임 궤적이 이용된다. 일 실시예에서, 전자 장치는 상관 계수 계산을 위해 사전에 수행되는 신호 처리를 수행할 수 있다. 예를 들어, 전자 장치는 동적 시간 워핑(Dynamic Time Warping; DTW) 알고리즘을 이용할 수 있다. 동적 시간 워핑은, 1차원 시계열의 신호에서, 두개의 다른 속도의 시간축의 파장의 유사성을 측정하는 알고리즘이며, 두 시퀀스인 S1, S2 사이에 대응하는 샘플 포인트 사이의 거리를 계산함함으로써, 두 시퀀스 간의 유사도를 계산할 수 있다. 또는, 전자 장치는 순차적인 데이터인 궤적을 처리하기 위해, 은닉 마르코프 모델(Hidden Markov Model; HMM)을 이용할 수 있으나, 전자 장치가 사용하는 신호 처리 알고리즘은 이에 한정되는 것 은 아니다. 도 9b는 본 개시의 일 실시예에 따른 전자 장치가 카메라의 시야 궤적과 사용자의 손 움직임 궤적을 비교하는 동작을 설명하기 위한 도면이다. 도 9b는, 비디오에 포함되는 제1 프레임 및 제2 프레임을 도시한 것이다. 제2 프레임은 제1 프 레임 이후의 프레임이며, 제1 프레임 및 제2 프레임 사이에는 복수의 프레임들이 더 포함될 수 있으나, 설명의 편의를 위해 생략되었다. 제1 프레임 이전의 다른 프레임들로부터 제1 프레임까지의 프레임들에 기초하여 생성된 궤적들 을 참조하면, 카메라의 시야 궤적은 왼쪽에서 오른쪽 방향으로 이동한 궤적이 생성되었고, 사용자의 왼손 움직 임 궤적은 왼쪽에서 오른쪽 방향으로 이동한 궤적이 생성되었으며, 사용자의 오른손 움직임 궤적은 오른쪽에서 왼쪽 방향으로 이동한 궤적이 생성되었다. 또한, 제1 프레임 이후의 프레임들로부터 제2 프레임까지의 프레임들에 기초하여 생성된 궤적들(92 2)을 참조하면, 카메라의 시야 궤적 및 사용자의 왼손 움직임 궤적은 오른쪽 방향으로 더 이동한 궤적이 생성되 었고, 사용자의 오른손 움직임 궤적은 왼쪽 방향으로 더 이동한 궤적이 생성되었다.도 9c를 이용하여, 전자 장치가 제2 프레임 이후의 다른 프레임들을 이용하는 동작을 더 설명한다. 도 9c는 본 개시의 일 실시예에 따른 전자 장치가 카메라의 시야 궤적과 사용자의 손 움직임 궤적을 비교하는 동작을 설명하기 위한 도면이다. 도 9c는, 비디오에 포함되는 제3 프레임 및 제4 프레임을 도시한 것이다. 제3 프레임은 제2 프 레임 이후의 프레임이며, 제2 프레임 및 제3 프레임 사이에는 복수의 프레임들이 더 포함될 수 있다. 또한, 제3 프레임 및 제4 프레임 사이에는 복수의 프레임들이 더 포함될 수 있다. 제2 프레임 이후의 프레임들로부터 제3 프레임까지의 프레임들에 기초하여 생성된 궤적들을 참 조하면, 카메라 및 객체들의 이동 방향이 전환됨에 따라 추가로 궤적들이 생성되었다. 예를 들어, 카메라의 시 야 궤적은 오른쪽에서 왼쪽 방향으로 이동한 궤적이 추가로 생성되었고, 사용자의 왼손 움직임 궤적 또한 오른 쪽에서 왼쪽 방향으로 이동한 궤적이 추가로 생성되었으며, 사용자의 오른손 움직임 궤적은 왼쪽에서 오른쪽 방 향으로 이동한 궤적이 추가로 생성되었다. 또한, 제3 프레임 이후의 프레임들로부터 제4 프레임까지의 프레임들에 기초하여 생성된 궤적들 을 참조하면, 카메라의 시야 궤적 및 사용자의 왼손 움직임 궤적은 왼쪽 방향으로 더 이동한 궤적이 생성 되었고, 사용자의 오른손 움직임 궤적은 오른손 방향으로 더 이동한 궤적이 생성되었다. 일 실시예에 따른 전자 장치는, 카메라의 시야 궤적 및 비디오의 프레임들을 이용하여 검출된 객체들의 궤적에 기초하여, 사용자의 손 후보를 결정할 수 있다. 구체적으로, 전자 장치는 카메라의 시야 이동 궤 적과 기 설정된 값 이상의 상관 계수를 갖는 객체 궤적을 식별하고, 식별된 객체를 사용자의 손 후보로 결정한 다. 도 9b 및 도 9c의 예시에서, 사용자의 왼손 움직임은 카메라의 움직임과 유사하게 움직이므로, 전술한 실시 예들에 따라 궤적 간 상관 관계가 있는 것으로 식별될 수 있고, 따라서 사용자의 손 후보로 결정될 수 있다. 또 한, 사용자의 오른손 움직임은 카메라의 움직임과 반대로 움직이지만, 전술한 실시예들에 따라 궤적 간 상관 관 계가 있는 것으로 식별될 수 있으며, 사용자의 손 후보로 결정될 수 있다. 전자 장치가 궤적들을 비교하 는 동작들은 전술하였으므로, 동일한 설명은 생략한다. 도 10은 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 결정하는 동작을 설명하기 위한 도면이다. 전자 장치는 머리 움직임 궤적을 획득할 수 있다. 머리 움직임 궤적은 센서 기반 데이터 및/ 또는 이미지 기반 데이터에 기초하여, 사용자의 머리 움직임 궤적을 생성할 수 있다. 이는, 전술하였으므 로, 동일한 설명은 생략한다. 전자 장치는 손 후보 궤적을 획득할 수 있다. 손 후보 궤적이란, 전술한 실시예들에 따라, 객체의 궤적 및/또는 카메라의 시야 이동 궤적에 기초하여, 비디오의 프레임들 내에서 식별된 하나 이상의 객체 들 중에서 사용자의 손 후보로 결정된 객체의 궤적을 말한다. 즉, 결정된 사용자의 손 후보에 대응하는 객체 궤 적을 말한다. 이는, 전술하였으므로, 동일한 설명은 생략한다. 전자 장치는 머리 움직임 궤적 및 손 후보 궤적을 모아 궤적 클러스터를 생성할 수 있 다. 전자 장치는 궤적 매칭 작업을 통해, 사용자의 손 후보들 중에서 사용자의 손을 결정할 수 있 다. 예를 들어, 전자 장치는 머리 움직임 궤적 및 손 후보 궤적 간의 상관 계수를 계산할 수 있다. 전자 장치는 상관 관계를 찾기 위한 다양한 알고리즘을 이용할 수 있다. 또한, 전자 장치는 상관 계수 계산을 위한 신호 처리를 수행할 수 있다. 이러한 신호 처리는 예를 들어, 동적 시간 워핑(Dynamic Time Warping; DTW) 등이 이용될 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에 따른 전자 장치는 사용자의 손 후보에 대응하는 객체 궤적인 손 후보 궤적들 중에서, 머리 움직임 궤적과 상관 관계가 높은 궤적을 식별하고, 식별된 궤적에 대응하는 객체를 사용자의 손으로 결정할 수 있다. 이 경우, 결정된 손에 대응하는 객체 궤적은 손 움직임 궤적으로 지칭될 수 있다. 일 실시예에서, 전자 장치는 결정된 사용자의 손이 왼손인지 오른손인지 여부를 결정할 수 있다. 전자 장 치는 인공지능 모델을 이용한 객체(손) 인식 결과 및/또는 객체(손)의 특징점, 객체(손)의 포즈 추정 결 과, 손 움직임 궤적 중 적어도 하나에 기초하여 사용자의 손이 왼손인지 오른손인지 여부를 결정할 수 있 다. 일 실시예에 따른 전자 장치는 사용자의 손 움직임 궤적을 추적하고, 제스처 인식할 수 있다. 전자 장치는 제스처 인식에 기초하여 사용자의 제스처에 따른 제어 명령을 실행할 수 있다.도 11a는 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 인식하기 위한 아키텍처를 개괄적으로 도시한 도면이다. 도 11a는 전술한 실시예들의 연결 관계를 전반적으로 설명하기 위한 도면이므로, 전술한 것과 동일한 내용들의 설명은 생략될 것이다. 일 실시예에서, 전자 장치는 머리에 착용 가능한 HMD일 수 있다. 전자 장치는 센서 및 카메 라를 포함할 수 있으나, 이에 한정되는 것은 아니며, 센서 및 카메라는 전자 장치의 외부에 위치하여 전자 장치로 데이터를 제공할 수 있다. 일 실시예에서, 전자 장치는 센서를 이용하여 획득된 센서 데이터에 기초하여, 사용자의 머리 움직 임 궤적을 생성할 수 있다. 일 실시예에서, 전자 장치는 카메라를 이용하여 획득된 비디오의 이미지 프레임들로부터, 비 디오 내에 존재하는 하나 이상의 객체에 대하여 객체 특징 추출 작업을 수행할 수 있다. 예를 들어, 비디 오의 이미지 프레임들 내에는, 제1 객체 및 제2 객체가 포함될 수 있다. 전자 장치가 객체 특징 추출을 한 결과, 이미지 프레임 내에서 특징점(들) 이 식별될 수 있다. 설명의 편의를 위해 또다른 특징점들에 대한 식별번호는 생략한다. 일 실시예에서, 전자 장치는 객체 특징 추출 작업을 수행한 이후에, 객체 특징점(들) 을 이 용하여, 궤적 추정 및 손 후보 결정 작업을 수행할 수 있다. 예를 들어, 궤적 추정 작업은 전자 장치 가 카메라의 시야 궤적을 생성하고, 객체 궤적을 생성하는 것을 포함할 수 있다. 전자 장치는 비디 오의 이미지 프레임들을 이용하여 카메라의 시야 궤적을 추정하고, 객체 특징점(들)을 이용하여 객 체 궤적을 추정할 수 있다. 또한, 손 후보 결정 작업은 카메라의 시야 궤적 및 객체 궤적 간 상관관계를 분석하 여, 비디오의 이미지 프레임들 내 존재하는 객체 중에서 사용자의 손일 가능성이 있는 객체를 선택하여, 손 후보를 결정하는 것을 포함할 수 있다. 전자 장치는 손 후보에 대응하는 객체 궤적(이하, 손 움직임 궤적)을 식별할 수 있다. 일 실시예에서, 전자 장치는 머리 움직임 궤적 및 손 움직임 궤적의 매칭 작업을 수행 할 수 있다. 전자 장치는 머리 움직임 궤적 및 손 움직임 궤적 간 상관관계를 분석하여, 손 후보 중에서 사용자의 손을 결정할 수 있다. 예를 들어, 전자 장치가 사용자의 손을 결정한 결과, 이미지 프레임들 내의 제1 객체는 전자 장치의 사용자가 아닌 다른 사람의 손으로 결정되고, 제2 객 체는 전자 장치의 사용자의 손으로 결정될 수 있다. 일 실시예에서, 전자 장치는 결정된 사용자의 손을 추적하면서, 제스처 인식 작업을 수행할 수 있 다. 전자 장치에는 각각의 제스처마다 대응하는 제어 명령이 저장되어 있을 수 있다. 일 실시예에 따른 전자 장치는 다른 사람의 것으로 결정된 손의 제스처에 대해서는 제어 명령을 실행하지 않고, 전자 장치 의 사용자의 것으로 결정된 손의 제스처에 대해서만 제어 명령을 실행할 수 있다. 도 11b는 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 인식하기 위한, 또다른 아키텍처를 개괄적으 로 도시한 도면이다. 도 11b를 설명함에 있어서, 도 11a에서 설명한 것과 동일한 내용은 생략한다. 일 실시예에서, 전자 장치는 사용자의 손에 위치한 제2 전자 장치인 웨어러블 디바이스로부터 데이 터를 수신할 수 있다. 웨어러블 디바이스는 센서(예를 들어, IMU 센서 등)를 포함할 수 있다. 전자 장치 는 웨어러블 디바이스로부터 수신되는 센서 데이터에 기초하여, 사용자의 손 움직임 궤적을 생성할 수 있다. 다만, 이에 한정되는 것은 아니며, 웨어러블 디바이스로부터 사용자의 손 움직임 궤적 이 생성되어 전자 장치로 제공될 수도 있다. 일 실시예에서, 전자 장치는 도 11a에서 전술한 것과 같이, 궤적 추정 및 손 후보 결정 작업을 수 행할 수 있다. 전자 장치는 웨어러블 디바이스로부터 수신된 센서 데이터에 기초한 손 움직임 궤적 이 생성된 것에 기초하여, 해당 손 움직임 궤적에 대응하는 객체는 카메라 시야 궤적과의 상관관계 계산을 생략하고 바로 손 후보로 결정할 수 있다. 예를 들어, 전자 장치는 비디오의 이미지 프레임들 내의 제3 객체 손 후보로 결정할 수 있다. 또한, 전자 장치는 도 11a에서 전술한 것과 같이, 머리 움직임 궤적 및 손 움직임 궤적의 매칭 작업을 수행할 수 있다. 이 경우, 전자 장치는 웨어러블 디바이스로부터 수신된 센서 데이터에 기초한 손 움직임 궤적을 머리 움직임 궤적과 비교함으로써 상관계수를 계산하고, 계산 결과에 기초하여 해당 객체를 사용자의 손으로 결정 할 수 있다. 예를 들어, 전자 장치는 상관계수가 기 설정된 값 이상인 것에 기초하여, 비디오의 이미지 프레임들 내의 제3 객체를 사용자의 손으로 결정할 수 있다. 한편, 일 실시예에서, 전자 장치는 웨어러블 디바이스가 착용된 손에 대하여 다른 방식으로 사용자 의 손을 결정할 수도 있다. 예를 들어, 전자 장치는 이미지 프레임들 내에서 웨어러블 디바이스 를 식별(예를 들어, 객체 인식 인공지능 모델 등을 이용)하고, 웨어러블 디바이스로부터 수신되는 식별 정보에 기초하여, 사용자의 손을 결정할 수 있다. 다른 예에서, 전자 장치는 웨어러블 디바이스 로부터 수신된 센서 데이터에 기초한 손 움직임 궤적에 대해서는, 손 후보로 결정하는 단계를 생략 하고, 바로 사용자의 손으로 결정할 수도 있다. 일 실시예에서, 비디오의 이미지 프레임들 내의 제2 객체는, 웨어러블 디바이스를 착용하지 않은 사용자의 손이므로, 전자 장치는 도 11a에서 설명한 동작들에 기초하여 제2 객체를 사용자의 손으로 결정할 수 있다. 또한, 비디오의 이미지 프레임들 내의 제3 객체는 웨어러블 디바이스 를 착용한 사용자의 손이므로, 전자 장치는 도 11b에서 설명한 동작들에 기초하여 제3 객체 를 사용자의 손으로 결정할 수 있다. 한편, 일 실시예에서, 전자 장치는 결정된 사용자의 손이 왼손인지 오른손인지 여부를 결정할 수 있다. 예를 들어, 전자 장치는 제2 객체는 오른손이고, 제3 객체는 왼손임을 결정할 수 있다. 도 12는 본 개시의 일 실시예에 따른 전자 장치가 복수의 사용자들 및 그들의 손을 구별하는 동작을 설명 하기 위한 도면이다. 일 실시예에서, 전자 장치는 복수의 사용자들(제1 사용자, 제2 사용자, 제3 사용자)를 촬영한 비디오를 획득할 수 있다. 전자 장치는 전자 장치에 포함되는 카메라를 이용하여 비 디오를 획득하거나, 또는, 전자 장치의 외부에 있는 카메라로부터 촬영된 비디오를 제공받을 수 있 다. 일 실시예에서, 전자 장치는 비디오에 포함되는 이미지 프레임들을 분석할 수 있다. 전자 장치는 머리/얼굴 인식 작업을 수행할 수 있다. 전자 장치는 이미지 프레임들을 전경 프레임들 및 배경 프레임들로 분리하고, 전경 프레임들 내의 복수의 전경 객체들로부터, 복수의 사용자들 (제1 사용자, 제2 사용자, 제3 사용자)의 얼굴 특징점들을 검출할 수 있다. 일 실시예에서, 전자 장치는 객체 특징 검출 모델을 이용하여 얼굴 특징점들을 검출할 수 있다. 전자 장 치는 복수의 사용자들(제1 사용자, 제2 사용자, 제3 사용자)의 얼굴 특징점들에 기초 하여, 복수의 사용자들(제1 사용자, 제2 사용자, 제3 사용자)의 머리 움직임 궤적을 획득할 수 있다. 구체적인 예를 들면, 전자 장치는 제1 사용자의 머리(1201-1), 제2 사용자의 머리(1202- 1) 및 제3 사용자의 머리(1203-1)를 각각 식별하고, 제1 사용자의 머리 움직임 궤적(1232-1), 제2 사용자의 머 리 움직임 궤적(1232-2) 및 제3 사용자의 머리 움직임 궤적(1232-3)을 획득할 수 있다. 전자 장치가 머리 움직임 궤적을 획득하는 구체적인 동작은 전술한 실시예들에서 이미 설명하였으므로, 동일한 설명은 생략한다. 한편, 후술되는 것과 같이, 각각의 머리가 어느 사용자의 머리인지 및 해당 사용자의 손은 무엇인지를 식별하는 것은, 움직임 패턴 매칭 작업을 통해 수행될 수 있다. 전자 장치는 손 인식 작업을 수행할 수 있다. 전자 장치는 이미지 프레임들을 전경 프 레임들 및 배경 프레임들로 분리하고, 전경 프레임들 내의 복수의 전경 객체들로부터, 복수의 사용자들(제1 사 용자, 제2 사용자, 제3 사용자)의 손 특징점들을 검출할 수 있다. 일 실시예에서, 전자 장치는 객체 특징 검출 모델을 이용하여 손 특징점들을 검출할 수 있다. 전자 장치 는 복수의 사용자들(제1 사용자, 제2 사용자, 제3 사용자)의의 손 특징점들에 기초하 여, 복수의 사용자들(제1 사용자, 제2 사용자, 제3 사용자)의 손 움직임 궤적을 획득 할 수 있다. 구체적인 예를 들면, 전자 장치는 제1 사용자의 오른손(1201-2), 제2 사용자의 오른손(1202- 2), 제2 사용자의 왼손(1202-3) 및 제3 사용자의 오른손(1203-2)을 각각 식별하고, 제1 사용자의 오른손 움직임 궤적(1242-1), 제2 사용자의 오른손 움직임 궤적, 제2 사용자의 왼손 움직임 궤적 및 제3 사용자의 오른손 움직 임 궤적(1242-2)을 식별할 수 있다. 도 12에서, 제2 사용자의 왼손 움직임 궤적 및 오른손 움직임 궤적은 생략되었다. 전자 장치가 손 움직임 궤적을 획득하는 구체적인 동작은 전술한 실시예들에서 이미 설명하였으므로, 동일한 설명은 생략한다. 한편, 후술되는 것과 같이, 각각의 머리가 어느 사용자의 머리인지 및 해당 사용자의 손은 무엇인지를 식별하는 것은, 움직임 패턴 매칭 작업을 통해 수행될 수 있다. 전자 장치는 골격 기반 손 및 얼굴 연결 작업을 수행할 수 있다. 전자 장치는 객체 특징 검 출 모델 및/또는 특징 추출 알고리즘을 이용하여, 이미지 프레임들 내에서 복수의 사용자들(제1 사용자 , 제2 사용자, 제3 사용자)의 머리, 손 등의 특징점들을 검출함으로써, 신체 주요 특징점들 을 연결한 골격 데이터를 생성할 수 있다. 전자 장치 골격 데이터를 움직임 패턴 매칭 작업에서 사 용자의 손 및 얼굴을 연결하는 데 보조적인 데이터로써 활용할 수 있다. 일 실시예에서, 골격 기반 손 및 얼굴 연결 작업은 생략될 수 있다. 전자 장치는 움직임 패턴 매칭 작업을 수행할 수 있다. 전자 장치는 사용자의 머리 움직임 궤적 및 손 움직임 궤적을 비교하여, 머리 움직임 궤적과 손 움직임 궤적을 매칭할 수 있다. 여기서, 궤적을 매 칭한다는 것은, 머리 움직임 궤적과 손 움직임 궤적이 유사하여 상관 계수가 높은 것으로 식별되는 것일 수 있 으나, 이에 한정되는 것은 아니며, 궤적이 유사하지 않더라도 하나의 사용자의 머리 움직임 및 손 움직임으로 식별되는 경우도 포함할 수 있다. 일 실시예에서, 전자 장치는 움직임 패턴 매칭 작업을 수행할 때, 전술한 골격 데이터를 더 이용할 수 있다. 전자 장치는 복수의 사용자들(제1 사용자, 제2 사용자, 제3 사용자)의 손 후 보들을 결정하고, 움직임 패턴 매칭 작업을 수행함으로써, 복수의 사용자들(제1 사용자, 제2 사용 자, 제3 사용자)의 손 후보들을 복수의 사용자들(제1 사용자, 제2 사용자, 제3 사용자 )의 얼굴과 연관시킴으로써, 복수의 사용자들의 손을 결정할 수 있다. 일 실시예에 따른 전자 장치는 사용자별로 매칭된 얼굴 및 손에 기초하여, 전자 장치의 제어 동작 을 수행할 수 있다. 예를 들어, 제2 사용자만이 전자 장치의 제어 권한을 가진 사용자인 경우, 전 자 장치는 제2 사용자의 제스처만을 제어 명령으로 인식하여 제어 동작을 수행할 수 있다. 일 실시 예에서, 전자 장치는 제1 사용자, 제2 사용자 및 제3 사용자의 각각의 제스처를 별개 로 인식하고, 각각의 사용자의 제스처로부터 제어 명령을 인식하여 제어 동작을 수행할 수 있다. 일 실시예에서, 복수의 사용자들(제1 사용자, 제2 사용자, 제3 사용자) 각각에는, 서로 다른 제어 권한이 설정되어 있을 수 있다. 전자 장치는 전자 장치의 제어를 위한 제스처가 어느 사용자 의 손인지 식별하고, 식별된 사용자의 제어 권한 레벨을 식별하며, 그에 따른 제어 동작을 수행할 지 여부를 결 정할 수 있다. 도 13은 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 인식하는 예시적인 상황을 설명하기 위한 도면 이다. 일 실시예에서, 전자 장치는 머리에 착용가능한 HMD(예를 들어, AR Glass 등)일 수 있다. 전자 장치 는 전술한 실시예들에 따라 사용자의 손을 결정하고, 결정된 사용자의 손을 추적하여 제스처를 인식할 수 있다. 전자 장치는 인식된 제스처에 기초하여 제어 동작을 수행할 수 있다. 예를 들어, 전자 장치가 증강 현실을 제공하는 AR Glass인 경우, 전자 장치는 실제 현실 장면에 증 강 객체 등을 사용자에게 제공할 수 있다. 이 경우, 전자 장치의 카메라 시야에는, 사용자의 손 및 다른 사람의 손이 포함될 수 있다. 그러나, 전자 장치가 사용자의 손을 결정하지 않으면, 전자 장치는 다른 사람의 손의 제스처에 의해서도 제어될 수 있다. 이에 따라, 전자 장치 의 사용자가 의도하지 않은 제어 동작이 수행될 수 있다. 따라서, 전자 장치는 카메라 시야 내에서 사용자의 손이 무엇인지를 결정할 필요가 있다. 전자 장치는 전술한 실시예들에서 서술한 동작들을 통해, 카메라 시야 내에서 다른 사람의 손 및 사용자의 손을 구별하고, 사용자의 손만을 인식할 수 있다. 도 14는 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 인식하는 예시적인 상황을 설명하기 위한 도면 이다. 도 14의 예시적인 상황은, 전자 장치가 사용자들로부터 이격된 제3 위치에 위치하여, 사용자들의 제스처 를 인식하고 인터랙션 하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 디스플레이 및 카메라를 포함하는 장치(예를 들어, TV 등)일 수 있다. 전자 장치는 전술한 실시예들에 따라 사용자의 손을 결정하고, 결정된 사용자의 손을 추적하여 제스처를 인식 할 수 있다. 전자 장치는 인식된 제스처에 기초하여 제어 동작을 수행할 수 있다. 일 실시예에서, 복수의 사용자들(제1 사용자, 제2 사용자 및 제3 사용자)이 전자 장치(200 0)를 시청하는 경우, 전자 장치는 복수의 사용자들 각각의 손을 결정할 수 있다. 전자 장치가 복수의 사용자들(제1 사용자, 제2 사용자 및 제3 사용자) 각각에 대하여 각각의 사용자의 손을 결정한 결과를 예시로 설명하면, 전자 장치는 제1 사용자에 대하여 제1 사용 자의 머리와 제1 사용자의 손을 매칭하고, 제2 사용자에 대하여 제2 사용자의 머리와 제2 사용자의 손을 매칭하고, 제3 사용자에 대하여 제3 사용자의 머리와 제3 사용자의 손 을 매칭할 수 있다. 전자 장치가 복수의 사용자들(제1 사용자, 제2 사용자 및 제3 사 용자)의 손을 결정하는 동작은 도 12에 대한 설명에서 전술하였으므로, 동일한 설명은 생략한다. 일 실시예에 따른 전자 장치는 사용자별로 매칭된 얼굴 및 손에 기초하여, 전자 장치의 제어 동작 을 수행할 수 있다. 예를 들어, 제1 사용자만이 전자 장치의 제어 권한을 가진 사용자인 경우, 전 자 장치는 제1 사용자의 제스처만을 제어 명령으로 인식하여 제어 동작을 수행할 수 있다. 일 실시 예에서, 전자 장치는 제1 사용자, 제2 사용자 및 제3 사용자의 각각의 제스처를 별개 로 인식하고, 각각의 사용자의 제스처로부터 제어 명령을 인식하여 제어 동작을 수행할 수 있다. 일 실시예에서, 복수의 사용자들(제1 사용자, 제2 사용자, 제3 사용자) 각각에는, 서로 다른 제어 권한이 설정되어 있을 수 있다. 전자 장치는 전자 장치의 제어를 위한 제스처가 어느 사용자 의 손인지 식별하고, 식별된 사용자의 제어 권한 레벨을 식별하며, 그에 따른 제어 동작을 수행할 지 여부를 결 정할 수 있다. 도 15는 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 인식하는 예시적인 상황을 설명하기 위한 도면 이다. 도 15의 예시적인 상황은, 도 14와 같이 전자 장치가 사용자들로부터 이격된 제3 위치에 위치하여, 사용 자들의 제스처를 인식하고 인터랙션 하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 로봇일 수 있다. 전자 장치는 전술한 실시예들에 따라 사용자의 손을 결정하고, 결정된 사용자의 손을 추적하여 제스처를 인식할 수 있다. 전자 장치는 인식된 제스처에 기초 하여 제어 동작을 수행할 수 있다. 예를 들어, 전자 장치는 제1 사용자에 대하여 제1 사용자의 머 리와 제1 사용자의 손을 매칭하고, 제2 사용자에 대하여 제2 사용자의 머리와 제2 사 용자의 손을 매칭할 수 있다. 전자 장치가 복수의 사용자들 손을 결정하는 동작은 도 12에 대한 설 명에서 전술하였으므로, 동일한 설명은 생략한다. 일 실시예에 따른 전자 장치는 서로 다른 사용자들로부터 식별된 제스처 등을 기반으로 사용자별로 제어 동작을 분리하여 제어 동작을 수행할 수 있다. 도 16은 본 개시의 일 실시예에 따른 전자 장치의 구성을 도시한 블록도이다. 일 실시예에 따른 전자 장치는 통신 인터페이스, 카메라, 메모리 및 프로세서를 포함할 수 있다. 통신 인터페이스는 프로세서의 제어에 의해 다른 전자 장치들과 데이터 통신을 수행할 수 있다. 통신 인터페이스는 통신 회로를 포함할 수 있다. 통신 인터페이스는 예를 들어, 유선 랜, 무선 랜 (Wireless LAN), 와이파이(Wi-Fi), 블루투스(Bluetooth), 지그비(ZigBee), WFD(Wi-Fi Direct), 적외선 통신 (IrDA, infrared Data Association), BLE (Bluetooth Low Energy), NFC(Near Field Communication), 와이브로 (Wireless Broadband Internet, Wibro), 와이맥스(World Interoperability for Microwave Access, WiMAX), SWAP(Shared Wireless Access Protocol), 와이기그(Wireless Gigabit Alliances, WiGig) 및 RF 통신을 포함하 는 데이터 통신 방식 중 적어도 하나를 이용하여, 전자 장치와 다른 디바이스들 간의 데이터 통신을 수행 할 수 있는, 통신 회로를 포함할 수 있다. 일 실시예에 따른 통신 인터페이스는 전자 장치의 사용자의 손 움직임 궤적 및 머리 움직임 궤적 등을 생성하기 위한 데이터를 외부 전자 장치와 송수신할 수 있다. 예를 들어, 통신 인터페이스는 전자 장치의 사용자의 머리에 위치한 센서로부터 센서 데이터를 획득할 수 있다. 또한, 전자 장치는 사용자의 손에 위치한 센서로부터 센서 데이터를 획득할 수 있다. 사용자의 머리 및/또는 손에 위치한 센서는, 통 신 기능 지원하는 별개의 센서로 존재하거나, 전자 장치와 별개의 전자 장치(예를 들어, 웨어러블 디바이 스 등) 등에 포함될 수 있다. 또는, 전자 장치는 외부 전자 장치로부터 비디오 및/또는 이미지를 획득할 수 있다. 카메라는 객체를 촬영하여 비디오 및/또는 이미지를 획득할 수 있다. 카메라는 하나 이상일 수 있 다. 카메라는 예를 들어, RGB 카메라, 깊이 카메라, 적외선 카메라 등을 포함할 수 있으나, 이에 한정되 는 것은 아니다. 카메라는 복수의 프레임들을 포함하는 비디오를 획득할 수 있다. 카메라의 구체적 인 종류 및 세부 기능은 통상의 기술자가 명확하게 추론할 수 있으므로, 설명을 생략한다. 메모리는 프로세서가 판독할 수 있는 명령어들, 데이터 구조, 및 프로그램 코드(program code)가 저장될 수 있다. 메모리는 하나 이상일 수 있다. 개시된 실시예들에서, 프로세서가 수행하는 동작 들은 메모리에 저장된 프로그램의 명령어들 또는 코드들을 실행함으로써 구현될 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등)를 포함할 수 있으며, 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나를 포함하는 비 휘 발성 메모리 및 램(RAM, Random Access Memory) 또는 SRAM(Static Random Access Memory)과 같은 휘발성 메모 리를 포함할 수 있다. 일 실시예에 따른 메모리는 전자 장치가 사용자의 손을 결정하기 위해 동작하도록 하는 하나 이상 의 인스트럭션 및/또는 프로그램을 저장할 수 있다. 예를 들어, 메모리에는 비디오 처리 모듈, 객 체 분석 모듈, 궤적 추정 모듈 및 손 결정 모듈이 저장될 수 있다. 프로세서는 전자 장치의 전반적인 동작들을 제어할 수 있다. 예를 들어, 프로세서는 메모리 에 저장된 프로그램의 하나 이상의 명령어들(instructions)을 실행함으로써, 전자 장치가 비디오 및/또는 이미지에서 사용자의 손을 결정하기 위한 전반적인 동작들을 제어할 수 있다. 프로세서는 하나 이상일 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서(microprocessor), 그래픽 처리 장치(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 애플리케이션 프로세서(Application Processor), 신경망 처리 장치(Neural Processing Unit) 또는 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계된 인공지능 전 용 프로세서 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 프로세서는 비디오 처리 모듈을 실행하여, 비디오에 포함되는 하나 이상의 프레임들을 처리할 수 있다. 프로세서는 비디오의 프레임들로부터 전경 객체를 추출하여, 전경 객체를 포함하는 전경 프레임들 및 전경 객체를 제외한 배경 프레임들을 획득할 수 있다. 일 실시예에서, 프로세서는 비디오에 포함되는 프레임들 중에서, 전경 및 배경을 분리할 프레임들을 선택할 수 있다. 예를 들어, 프로세서는 시간순으로 나열된 프레임들 중에서, 기 설정된 간격으로 일부의 프레임들만을 추출하여, 전경 및 배경 분리 처리를 수행할 수 있다. 프로세서는 객체 분석 모듈을 실행하여, 이미지 내 프레임들에 포함되는 객체를 분석할 수 있다. 객체 분석 모듈은 객체 검출 모델 및/또는 객체 특징점 검출 모델을 포함할 수 있다. 객체 검출 모델은, 이미지 를 입력 받아, 객체를 검출(예를 들어, 손, 얼굴 등)한 결과를 출력하는 인공지능 모델일 수 있다. 객체 검출 모델은 객체를 검출하기 위해 객체에 관련된 정보(예를 들어, 객체의 카테고리 등)가 주석된 훈련 데이터셋을 이용하여 훈련된 인공지능 모델일 수 있다. 객체 특징 검출 모델은, 이미지를 입력 받아, 객체의 특징점을 검출 (예를 들어, 손 특징점, 얼굴 특징 점)한 결과를 출력하는 인공지능 모델일 수 있다. 객체 특징 검출 모델은 여 러 객체의 카테고리 별로 객체의 특징점들이 주석(annotation)된 훈련 데이터셋을 이용하여 훈련된 것일 수 있 다. 일 실시예에서, 프로세서는 객체의 특징점들을 검출할 때, 객체의 카테고리를 먼저 식별하고, 식별된 카테고리에 대응하는 특징점들을 검출할 수 있다. 예를 들어, 프로세서는 전경 프레임들 내에서 객체 '손'을 식별하고, '손'의 특징점들을 검출할 수 있다. 프로세서는 궤적 추정 모듈을 실행하여, 사용자의 손을 결정하기 위해 이용되는 궤적들을 추정/생 성할 수 있다. 프로세서는 비디오 처리 모듈로부터 생성된 배경 프레임들을 이용하여 카메라의 시야 궤적을 추정 할 수 있다. 프로세서는 배경 프레임들 내 픽셀들을 비교할 수 있다. 이 경우, 배경 프레임들은 시간순으로 정렬된 프 레임들일 수 있다. 프로세서는 배경 프레임들 내 픽셀들을 비교함으로써, 카메라의 촬영 시야 이동을 나 타내는 시야 이동 정보를 획득할 수 있다. 프로세서는 시야 이동 정보에 기초하여, 전자 장치의 카 메라의 시야 궤적을 결정할 수 있다. 프로세서는 사용자의 머리에 위치한 센서로부터 카메라의 이동 정보 및 회전 정보를 획득할 수 있다. 프 로세서는 이동 정보 및 회전 정보에 기초하여 전자 장치의 카메라의 시야 궤적을 결정할 수 있다. 프로세서는 비디오 처리 모듈로부터 생성된 전경 프레임들 및 객체 분석 모듈로부터 생성된 객체 특징점들에 기초하여, 객체 궤적을 추정할 수 있다. 프로세서는 하나의 객체에서 검출된 특징점들에 기초하여 전경 프레임들 내에서 객체(또는 객체의 특징점들)의 이동 정보를 획득할 수 있다. 프로세서는 객체의 이동 정보에 기초하여, 객체의 궤적을 결정할 수 있다. 구체적 예를 들면, 프레임 내 객체가 손, 머리/ 얼굴 등인 경우, 프로세서는 손, 머리/얼굴의 이동 정보를 획득하고, 손 움직임 궤적, 머리/얼굴 움직임 궤적을 결정할 수 있다. 프로세서는 사용자의 머리에 위치한 센서로부터 사용자의 머리 움직임 정보를 획득할 수 있다. 프로세서 는 사용자의 머리 움직임 정보에 기초하여 머리 움직임 궤적을 결정할 수 있다. 프로세서는 사용자의 손에 위치한 센서로부터 사용자의 손 움직임 정보를 획득할 수 있다. 프로세서 는 사용자의 손 움직임 정보에 기초하여 손 움직임 궤적을 결정할 수 있다. 프로세서는 손 결정 모듈을 실행하여 사용자의 손을 결정할 수 있다. 프로세서는 카메라의 시야 궤적 및 객체 궤적에 기초하여, 비디오 내에 포함되는 하나 이상의 객체 중에 서 사용자의 손 후보를 결정한다. 일 실시예에서, 프로세서는 카메라의 시야 궤적 및 객체 궤적 간의 상 관 계수가 기 설정된 값 이상인 것에 기초하여, 하나 이상의 객체들 중에서 사용자의 손 후보를 결정할 수 있다. 프로세서는 사용자의 손 후보의 손 움직임 궤적(객체 궤적) 및 사용자의 머리 움직임 궤적에 기초하여, 사용자의 손을 결정할 수 있다. 예를 들어, 프로세서는 손 움직임 궤적이 생성된 것에 기초하여, 머리 움 직임 궤적 및 손 움직임 궤적을 비교함으로써 사용자의 손을 결정할 수 있다. 프로세서는 사용자의 손 후 보에 대응하는 객체 궤적 및 사용자의 머리 움직임 궤적 간의 상관 계수가 기 설정된 값 이상인 것에 기초하여, 사용자의 손 후보들 중에서 사용자의 손을 결정할 수 있다. 프로세서는 사용자의 손이 왼손인지 오른손인 지 여부를 결정하할 수 있다. 한편, 전술한 메모리에 저장된 모듈들은, 설명의 편의를 위한 것이며 반드시 이에 한정되는 것은 아니다. 전술한 실시예들을 구현하기 위해 다른 모듈이 추가될 수 있으며, 전술한 모듈들 중 일부의 모듈들은 하나의 모 듈로 구현될 수도 있다. 일 실시예에 따른 전자 장치는 프로세서 및 메모리에 저장된 모듈들 을 이용하여, 전자 장치를 사용하는 사용자의 손만을 인식한다. 전자 장치가 사용자의 손이 무엇인 지 결정하면, 전자 장치는 사용자의 손을 추적하고 제스처를 인식할 수 있다. 일 실시예에서, 사용자의 손 제스처 유형 각각에는, 기 설정된 전자 장치에 대한 제어 명령이 저장되어 있을 수 있다. 전자 장치 는 사용자의 손에 대한 제스처 인식에 기초하여, 전자 장치를 제어하기 위한 제어 명령을 실행할 수 있다. 이 경우, 전자 장치의 사용자 외 다른 사람이 전자 장치를 제어하기 위한 손 제스처를 취 하더라도, 전자 장치는 다른 사람의 손을 사용자의 손으로 인식하지 않으므로, 제어 명령을 실행하지 않 을 수 있다. 제스처 인식을 통한 사용자 인터랙션 제공 방법에 있어서, 이미지 및/또는 비디오 내에 존재하는 다른 사람의 손에 영향을 받지 않고, 사용자의 손을 정확하게 결정하여 제스처 인식을 수행하기 위한 방법을 제시하고자 한 다. 본 개시에서 이루고자 하는 기술적 과제는, 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른"}
{"patent_id": "10-2022-0108652", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다. 본 개시의 일 측면에 따르면, 전자 장치가 비디오 내에서 사용자의 손을 결정하는 방법이 제공될 수 있다. 상기 방법은, 카메라를 이용하여 복수의 프레임들을 포함하는 비디오를 획득하는 단계를 포함할 수 있다. 상기 방법 은, 비디오의 프레임들을 이용하여 상기 카메라의 시야(Field of View; FoV)의 이동을 나타내는 시야 궤적을 추 정하는 단계를 포함할 수 있다. 상기 방법은, 상기 비디오의 프레임들 각각 내에서, 하나 이상의 객체의 특징점 들을 검출하는 단계를 포함할 수 있다. 상기 방법은, 상기 하나 이상의 객체의 특징점들에 기초하여, 상기 하나 이상의 객체의 이동을 나타내는 객체 궤적을 추정하는 단계를 포함할 수 있다. 상기 방법은, 상기 카메라의 시 야 궤적 및 상기 객체 궤적에 기초하여, 상기 하나 이상의 객체 중에서 사용자의 손 후보를 결정하는 단계를 포 함할 수 있다. 상기 방법은, 상기 사용자의 머리의 움직임을 나타내는 머리 움직임 궤적을 획득하는 단계를 포 함할 수 있다. 상기 방법은, 상기 사용자의 손 후보에 대응하는 상기 객체 궤적 및 상기 머리 움직임 궤적에 기 초하여, 사용자의 손을 결정하는 단계를 포함할 수 있다. 상기 방법은, 상기 비디오 내에서 상기 결정된 사용자 의 손을 추적하고 제스처를 인식하는 단계를 포함할 수 있다. 상기 방법은, 상기 비디오의 프레임들 각각에 대하여 전경 객체를 추출함으로써, 전경 프레임들 및 배경 프레임 들을 획득하는 단계를 더 포함할 수 있다. 상기 카메라의 시야 궤적을 추정하는 단계는, 상기 배경 프레임들 내 픽셀들을 비교하여 상기 카메라 시야의 이 동과 관련된, 시야 이동 정보를 획득하는 단계 및 상기 시야 이동 정보에 기초하여 상기 카메라의 시야 궤적을 결정하는 단계를 포함할 수 있다. 상기 하나 이상의 객체의 특징점들을 검출하는 단계는, 상기 전경 프레임들 내 상기 전경 객체로부터 상기 하나 이상의 객체의 특징점들을 추출하는 단계를 포함할 수 있다. 상기 머리 움직임 궤적을 획득하는 단계는, 상기 사용자의 머리에 위치한 제1 센서로부터 제1 센서 데이터를 획 득하는 단계 및 상기 제1 센서 데이터에 기초하여, 상기 머리 움직임 궤적을 생성하는 단계를 포함할 수 있다. 상기 방법은, 상기 사용자의 손에 위치한 제2 전자 장치의 제2 센서로부터 제2 센서 데이터를 획득하는 단계 및 상기 제2 센서 데이터에 기초하여, 상기 사용자의 손의 움직임을 나타내는 손 움직임 궤적을 생성하는 단계를 더 포함할 수 있다. 상기 사용자의 손을 결정하는 단계는, 상기 제2 센서 데이터에 기초한 상기 손 움직임 궤적이 생성된 것에 기초 하여, 상기 머리 움직임 궤적 및 상기 손 움직임 궤적을 비교함으로써 상기 사용자의 손을 결정하는 단계를 포 함할 수 있다. 상기 사용자의 손을 결정하는 단계는, 상기 사용자의 손 후보에 대응하는 상기 객체 궤적 및 상기 머리 움직임 궤적 간의 상관 계수를 계산하는 단계 및 상기 상관 계수가 기 설정된 값 이상인 것에 기초하여, 상기 사용자의 손 후보를 상기 사용자의 손으로 결정하는 단계를 포함할 수 있다. 상기 하나 이상의 객체의 특징점들을 검출하는 단계는, 상기 전경 프레임들 내 복수의 전경 객체들로부터, 복수 의 사용자들의 얼굴 특징점들 및 손 특징점들을 검출하는 단계를 포함할 수 있다. 상기 머리 움직임 궤적을 획 득하는 단계는, 상기 복수의 사용자들의 얼굴 특징점들에 기초하여 상기 복수의 사용자들의 머리 움직임 궤적들 을 획득하는 단계를 포함할 수 있다. 상기 사용자의 손을 결정하는 단계는, 상기 복수의 사용자들 각각에 대하 여, 상기 복수의 사용자들의 손 후보들을 상기 복수의 사용자들의 얼굴들과 연관시킴으로써 상기 복수의 사용자 들의 손을 결정하는 단계를 포함할 수 있다. 상기 사용자의 손을 결정하는 단계는, 상기 사용자의 손이 왼손인지 오른손인지 여부를 결정하는 단계를 포함할 수 있다. 상기 방법은, 제스처 인식에 기초하여 상기 전자 장치를 제어하기 위한 제어 명령을 실행하는 단계를 더 포함할 수 있다. 한편, 본 개시의 실시예들은 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어 를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스 될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨 터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구 현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독 가 능 명령어, 데이터 구조, 또는 프로그램 모듈과 같은 변조된 데이터 신호의 기타 데이터를 포함할 수 있다.또한, 컴퓨터에 의해 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다 는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경 우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2022-0108652", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7a 도면7b 도면8 도면9a 도면9b 도면9c 도면10 도면11a 도면11b 도면12 도면13 도면14 도면15 도면16"}
{"patent_id": "10-2022-0108652", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 결정하는 동작을 개략적으로 설명하기 위한 도 면이다. 도 2는 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 결정하는 방법을 설명하기 위한 흐름도이다. 도 3은 본 개시의 일 실시예에 따른 전자 장치의 사용자의 몸 움직임을 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시예에 따른 전자 장치가 카메라의 시야 궤적을 획득하는 동작을 설명하기 위한 흐름도 이다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 객체의 특징점을 추출하는 동작을 설명하기 위한 흐름도이다. 도 6은 본 개시의 일 실시예에 따른 전자 장치가 이용하는, 궤적을 설명하기 위한 도면이다. 도 7a는 본 개시의 일 실시예에 따른 전자 장치가 센서 데이터를 획득하는 동작을 설명하기 위한 도면이다. 도 7b는 본 개시의 일 실시예에 따른 전자 장치가 센서 데이터에 기초하여 궤적을 생성하는 동작을 설명하기 위 한 도면이다. 도 8은 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손 후보를 결정하는 동작을 설명하기 위한 도면이다. 도 9a는 본 개시의 일 실시예에 따른 전자 장치가 카메라의 시야 궤적과 사용자의 손 움직임 궤적을 비교하는 동작을 설명하기 위한 도면이다. 도 9b는 본 개시의 일 실시예에 따른 전자 장치가 카메라의 시야 궤적과 사용자의 손 움직임 궤적을 비교하는 동작을 설명하기 위한 도면이다. 도 9c는 본 개시의 일 실시예에 따른 전자 장치가 카메라의 시야 궤적과 사용자의 손 움직임 궤적을 비교하는 동작을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 결정하는 동작을 설명하기 위한 도면이다. 도 11a는 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 인식하기 위한 아키텍처를 개괄적으로 도시한 도면이다. 도 11b는 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 인식하기 위한, 또다른 아키텍처를 개괄적으 로 도시한 도면이다. 도 12는 본 개시의 일 실시예에 따른 전자 장치가 복수의 사용자들 및 그들의 손을 구별하는 동작을 설명 하기 위한 도면이다. 도 13은 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 인식하는 예시적인 상황을 설명하기 위한 도면 이다. 도 14는 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 인식하는 예시적인 상황을 설명하기 위한 도면 이다. 도 15는 본 개시의 일 실시예에 따른 전자 장치가 사용자의 손을 인식하는 예시적인 상황을 설명하기 위한 도면 이다. 도 16은 본 개시의 일 실시예에 따른 전자 장치의 구성을 도시한 블록도이다."}
