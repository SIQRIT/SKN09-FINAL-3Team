{"patent_id": "10-2023-0039826", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0145229", "출원번호": "10-2023-0039826", "발명의 명칭": "입체 이미지 생성 장치 및 그 방법", "출원인": "주식회사 케이티", "발명자": "박시완"}}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "입체 이미지 생성 장치에 있어서,원본 이미지를 수신하는 이미지 수신부;상기 원본 이미지를 객체 이미지 및 배경 이미지로 분리 생성하는 이미지 분리부;상기 객체 이미지의 깊이 정보에 기초하여 상기 객체 이미지를 그레이스케일(grayscale) 이미지로 변환하는 그레이스케일 이미지 생성부;상기 그레이스케일 이미지를 깊이별로 슬라이싱하여 복수의 그레이스케일 마스킹 이미지를 생성하는 마스킹 이미지 생성부;상기 복수의 그레이스케일 마스킹 이미지를 이용하여 상기 원본 이미지를 깊이별로 슬라이싱하여 복수의 깊이이미지를 생성하는 깊이 이미지 생성부; 및상기 복수의 깊이 이미지와 상기 배경 이미지를 이용하여 입체 이미지를 생성하는 입체 이미지 생성부를 포함하는, 입체 이미지 생성 장치."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 이미지 분리부는,미리 학습된 제1 딥러닝 모델에 상기 원본 이미지를 입력하여 상기 원본 이미지 내의 객체를 추출하는, 입체 이미지 생성 장치."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제1 딥러닝 모델은 U2Net 기반의 딥러닝 모델인, 입체 이미지 생성 장치."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 이미지 분리부는,상기 원본 이미지에서 상기 객체를 선택 추출하여 상기 객체 이미지를 생성하고, 상기 원본 이미지에서 상기 객체를 선택 제거하여 상기 배경 이미지를 생성하는, 입체 이미지 생성 장치."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 이미지 분리부는,미리 학습된 제2 딥러닝 모델을 통해 상기 선택 제거된 영역을 인페인팅(inpainting)하여 상기 배경 이미지를공개특허 10-2024-0145229-3-생성하는, 입체 이미지 생성 장치."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 제2 딥러닝 모델은 LaMa 기반의 딥러닝 모델인, 입체 이미지 생성 장치."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 그레이스케일 이미지 생성부는,미리 학습된 제3 딥러닝 모델에 상기 객체 이미지를 입력하여 상기 객체 이미지의 깊이 정보를 획득하는, 입체이미지 생성 장치."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제3 딥러닝 모델은 MiDas 기반의 딥러닝 모델인, 입체 이미지 생성 장치."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 마스킹 이미지 생성부는,상기 객체 이미지의 RGB 색상 정보를 기반으로 상기 그레이스케일 이미지를 슬라이싱하여 상기 복수의 그레이스케일 마스킹 이미지를 생성하는, 입체 이미지 생성 장치."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 깊이 이미지 생성부는,상기 원본 이미지에서 각 깊이별 그레이스케일 마스킹 이미지에 대응하는 깊이 이미지를 추출하여 상기 복수의깊이 이미지를 생성하는, 입체 이미지 생성 장치."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "입체 이미지 생성 방법에 있어서,원본 이미지를 수신하는 동작;상기 원본 이미지를 객체 이미지 및 배경 이미지로 분리 생성하는 동작;상기 객체 이미지의 깊이 정보에 기초하여 상기 객체 이미지를 그레이스케일(grayscale) 이미지로 변환하는 동작;상기 객체 이미지의 깊이 정보에 기초하여 상기 그레이스케일 이미지를 깊이별로 슬라이싱하여 복수의 그레이스케일 마스킹 이미지를 생성하는 동작;공개특허 10-2024-0145229-4-상기 복수의 그레이스케일 마스킹 이미지를 이용하여 상기 원본 이미지를 깊이별로 슬라이싱하여 복수의 깊이이미지를 생성하는 동작; 및상기 복수의 깊이 이미지와 상기 배경 이미지를 이용하여 입체 이미지를 생성하는 동작을 포함하는, 방법."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 원본 이미지를 객체 이미지 및 배경 이미지로 분리 생성하는 동작은,미리 학습된 제1 딥러닝 모델에 상기 원본 이미지를 입력하여 상기 원본 이미지 내의 객체를 추출하는 동작;상기 원본 이미지에서 상기 객체를 선택 추출하여 상기 객체 이미지를 생성하는 동작; 및상기 원본 이미지에서 상기 객체를 선택 제거하여 상기 배경 이미지를 생성하는 동작을 포함하는, 방법."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 제1 딥러닝 모델은 U2Net 기반의 딥러닝 모델인, 방법."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 배경 이미지를 생성하는 동작은,미리 학습된 제2 딥러닝 모델을 통해 상기 선택 제거된 영역을 인페인팅(inpainting)하여 상기 배경 이미지를생성하는 동작을 포함하는, 방법."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 제2 딥러닝 모델은 LaMa 기반의 딥러닝 모델인, 방법."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,미리 학습된 제3 딥러닝 모델에 상기 객체 이미지를 입력하여 상기 객체 이미지의 깊이 정보를 획득하는 동작을더 포함하는, 방법."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 제3 딥러닝 모델은 MiDas 기반의 딥러닝 모델인, 방법."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "공개특허 10-2024-0145229-5-제11항에 있어서,상기 복수의 그레이스케일 마스킹 이미지를 생성하는 동작은,상기 객체 이미지의 RGB 색상 정보를 기반으로 상기 그레이스케일 이미지를 슬리이싱하여 상기 복수의 그레이스케일 마스킹 이미지를 생성하는 동작을 포함하는, 방법."}
{"patent_id": "10-2023-0039826", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 복수의 깊이 이미지를 생성하는 동작은,상기 원본 이미지에서 각 깊이별 그레이스케일 마스킹 이미지에 대응하는 복수의 깊이 이미지를 추출하여 상기복수의 깊이 이미지를 생성하는 동작을 포함하는, 방법."}
{"patent_id": "10-2023-0039826", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 입체 이미지 생성 장치는, 원본 이미지를 수신하는 이미지 수신부; 상기 원본 이미 지를 객체 이미지 및 배경 이미지로 분리 생성하는 이미지 분리부; 상기 객체 이미지의 깊이 정보에 기초하여 상 기 객체 이미지를 그레이스케일(grayscale) 이미지로 변환하는 그레이스케일 이미지 생성부; 상기 그레이스케일 이미지를 깊이별로 슬라이싱하여 복수의 그레이스케일 마스킹 이미지를 생성하는 마스킹 이미지 생성부; 상기 복 수의 그레이스케일 마스킹 이미지를 이용하여 상기 원본 이미지를 깊이별로 슬라이싱하여 복수의 깊이 이미지를 생성하는 깊이 이미지 생성부; 및 상기 복수의 깊이 이미지와 상기 배경 이미지를 이용하여 입체 이미지를 생성 하는 입체 이미지 생성부를 포함할 수 있다."}
{"patent_id": "10-2023-0039826", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 입체 이미지 생성 장치 및 그 방법에 관한 것으로, 보다 구체적으로는 원본 이미지 내의 객체에 대해 모션 효과(motion effect)를 적용하여 콘텐츠의 몰입감을 높일 수 있도록 하는 입체 이미지 생성 장치 및 그 방 법에 관한 것이다."}
{"patent_id": "10-2023-0039826", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "다양한 애니메이션 기술이 당 업계에 공지되어 있지만, 정적인 이미지의 경우, 2차원 이미지만을 표현하므로 동 적인 이미지(예를 들어, 동영상)에서 나타나는 것과 같은 생동감이나 현장감을 표현하는데 한계가 존재한다. 이를 해결하기 위해, 복수의 정적 이미지들을 생성한한 후 복수의 정적 이미지들을 합성하여 동적 이미지와 유 사하게 인식되도록 하는 콘텐츠 생성 방법이 제안되었다. 그러나, 종래 제안된 방법에 의하면, 복수의 정적 이미지를 촬영 또는 생성하는 것은 매우 번거롭고, 업무에 있 어 효율적이지 않다는 문제가 존재한다. 이에, 정적 이미지에 기반하여 생동감이나 현장감을 갖는 입체 이미지를 효율적으로 생성할 수 있는 장치 및 방 법에 대한 필요가 대두되고 있다. 한편, 인간의 뇌를 모방하는 뉴럴 네트워크(neural network)가 고안되어 컴퓨터 스스로 외부 데이터를 조합, 분 석하여 학습하는 딥러닝(deep learning) 기술이 발전함에 따라 AI(Artificial Intelligence, 인공지능)가 획기 적으로 도약하였다. 이와 같은 시대적 흐름에 따라, 뉴럴 네트워크가 이미지에 접목된 이미지 딥러닝(image deep learning) 기술이 함께 발전하고 있다."}
{"patent_id": "10-2023-0039826", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 바와 같은 기술적 배경에서 안출된 것으로, 원본 이미지 내의 객체에 대해 모션 효과(motion effect)를 적용하여 콘텐츠의 몰입감을 높일 수 있도록 하는 입체 이미지 생성 장치 및 그 방법을 제공하고자 한다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0039826", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 해결하기 위한 본 발명의 일 실시 예에 따른 입체 이미지 생성 장치는, 원본 이미지를 수 신하는 이미지 수신부; 상기 원본 이미지를 객체 이미지 및 배경 이미지로 분리 생성하는 이미지 분리부; 상기객체 이미지의 깊이 정보에 기초하여 상기 객체 이미지를 그레이스케일(grayscale) 이미지로 변환하는 그레이스 케일 이미지 생성부; 상기 그레이스케일 이미지를 깊이별로 슬라이싱하여 복수의 그레이스케일 마스킹 이미지를 생성하는 마스킹 이미지 생성부; 상기 복수의 그레이스케일 마스킹 이미지를 이용하여 상기 원본 이미지를 깊이 별로 슬라이싱하여 복수의 깊이 이미지를 생성하는 깊이 이미지 생성부; 및 상기 복수의 깊이 이미지와 상기 배 경 이미지를 이용하여 입체 이미지를 생성하는 입체 이미지 생성부를 포함할 수 있다. 또한, 일 실시 예에 따르면, 상기 이미지 분리부는, 미리 학습된 제1 딥러닝 모델에 상기 원본 이미지를 입력하 여 상기 원본 이미지 내의 객체를 추출할 수 있다. 또한, 일 실시 예에 따르면, 상기 제1 딥러닝 모델은 U2Net 기반의 딥러닝 모델일 수 있다. 또한, 일 실시 예에 따르면, 상기 이미지 분리부는, 상기 원본 이미지에서 상기 객체를 선택 추출하여 상기 객 체 이미지를 생성하고, 상기 원본 이미지에서 상기 객체를 선택 제거하여 상기 배경 이미지를 생성할 수 있다. 또한, 일 실시 예에 따르면, 상기 이미지 분리부는, 미리 학습된 제2 딥러닝 모델을 통해 상기 선택 제거된 영 역을 인페인팅(inpainting)하여 상기 배경 이미지를 생성할 수 있다. 또한, 일 실시 예에 따르면, 상기 제2 딥러닝 모델은 LaMa 기반의 딥러닝 모델일 수 있다. 또한, 일 실시 예에 따르면, 상기 그레이스케일 이미지 생성부는, 미리 학습된 제3 딥러닝 모델에 상기 객체 이 미지를 입력하여 상기 객체 이미지의 깊이 정보를 획득할 수 있다. 또한, 일 실시 예에 따르면, 상기 제3 딥러닝 모델은 MiDas 기반의 딥러닝 모델일 수 있다. 또한, 일 실시 예에 따르면, 상기 마스킹 이미지 생성부는, 상기 객체 이미지의 RGB 색상 정보를 기반으로 상기 그레이스케일 이미지를 슬라이싱하여 상기 복수의 그레이스케일 마스킹 이미지를 생성할 수 있다. 또한, 일 실시 예에 따르면, 상기 깊이 이미지 생성부는, 상기 원본 이미지에서 각 깊이별 그레이스케일 마스킹 이미지에 대응하는 깊이 이미지를 추출하여 상기 복수의 깊이 이미지를 생성할 수 있다. 추가로, 상기의 기술적 과제를 해결하기 위한 본 발명의 다른 실시 예에 따른 입체 이미지 생성 방법은, 원본 이미지를 수신하는 동작; 상기 원본 이미지를 객체 이미지 및 배경 이미지로 분리 생성하는 동작; 상기 객체 이 미지의 깊이 정보에 기초하여 상기 객체 이미지를 그레이스케일(grayscale) 이미지로 변환하는 동작; 상기 객체 이미지의 깊이 정보에 기초하여 상기 그레이스케일 이미지를 깊이별로 슬라이싱하여 복수의 그레이스케일 마스 킹 이미지를 생성하는 동작; 상기 복수의 그레이스케일 마스킹 이미지를 이용하여 상기 원본 이미지를 깊이별로 슬라이싱하여 복수의 깊이 이미지를 생성하는 동작; 및 상기 복수의 깊이 이미지와 상기 배경 이미지를 이용하 여 입체 이미지를 생성하는 동작을 포함할 수 있다. 또한, 다른 일 실시 예에 따르면, 상기 원본 이미지를 객체 이미지 및 배경 이미지로 분리 생성하는 동작은, 미 리 학습된 제1 딥러닝 모델에 상기 원본 이미지를 입력하여 상기 원본 이미지 내의 객체를 추출하는 동작; 상기 원본 이미지에서 상기 객체를 선택 추출하여 상기 객체 이미지를 생성하는 동작; 및 상기 원본 이미지에서 상기 객체를 선택 제거하여 상기 배경 이미지를 생성하는 동작을 포함할 수 있다. 또한, 다른 일 실시 예에 따르면, 상기 제1 딥러닝 모델은 U2Net 기반의 딥러닝 모델일 수 있다. 또한, 다른 일 실시 예에 따르면, 상기 배경 이미지를 생성하는 동작은, 미리 학습된 제2 딥러닝 모델을 통해 상기 선택 제거된 영역을 인페인팅(inpainting)하여 상기 배경 이미지를 생성하는 동작을 포함할 수 있다. 또한, 다른 일 실시 예에 따르면, 상기 제2 딥러닝 모델은 LaMa 기반의 딥러닝 모델일 수 있다. 또한, 다른 일 실시 예에 따르면, 미리 학습된 제3 딥러닝 모델에 상기 객체 이미지를 입력하여 상기 객체 이미 지의 깊이 정보를 획득하는 동작을 더 포함할 수 있다. 또한, 다른 일 실시 예에 따르면, 상기 제3 딥러닝 모델은 MiDas 기반의 딥러닝 모델일 수 있다. 또한, 다른 일 실시 예에 따르면, 상기 복수의 그레이스케일 마스킹 이미지를 생성하는 동작은, 상기 객체 이미 지의 RGB 색상 정보를 기반으로 상기 그레이스케일 이미지를 슬리이싱하여 상기 복수의 그레이스케일 마스킹 이 미지를 생성하는 동작을 포함할 수 있다. 또한, 다른 일 실시 예에 따르면, 상기 복수의 깊이 이미지를 생성하는 동작은, 상기 원본 이미지에서 각 깊이 별 그레이스케일 마스킹 이미지에 대응하는 복수의 깊이 이미지를 추출하여 상기 복수의 깊이 이미지를 생성하는 동작을 포함할 수 있다."}
{"patent_id": "10-2023-0039826", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 입체 이미지 생성 장치 및 그 방법에 의하면, 원본 이미지 내의 객체에 대해 모션 효과(motion effect)를 적용하여 콘텐츠에 대한 몰입감을 높일 수 있다. 또한, 본 발명에 의하면, 원본 이미지 내의 객체와 배경을 분리하여 각각의 이미지를 생성하고, 이를 이용해 현 장감과 생동감이 극대화된 동적인 입체 이미지를 생성할 수 있는 효과가 있다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0039826", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명에 따른 실시예들은 첨부된 도면들을 참조하여 설명한다. 각 도면의 구성요소들에 참조부호를 부 가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가지 도록 하고 있음에 유의해야 한다. 또한, 본 발명의 실시예를 설명함에 있어, 관련된 공지 구성 또는 기능에 대 한 구체적인 설명이 본 발명의 실시예에 대한 이해를 방해한다고 판단되는 경우에는 그 상세한 설명은 생략한다. 또한, 이하에서 본 발명의 실시예들을 설명할 것이나, 본 발명의 기술적 사상은 이에 한정되거나 제 한되지 않고 당업자에 의해 변형되어 다양하게 실시될 수 있다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"간접적으로 연결\"되어 있는 경우도 포함한다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외 하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 본 발명의 실시예의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질이나 차례 또는 순서 등이 한 정되지 않는다. 도 1은 본 발명의 일 실시 예에 따른 입체 이미지 생성 장치의 기능적 블록도를 나타내는 도면이고, 도 2 는 본 발명의 일 실시 예에 따른 입체 이미지 생성 방법(S200)을 설명하기 위한 순서도를 나타내는 도면이다. 구체적 설명에 앞서, 이하의 본 발명의 입체 이미지 생성 장치는 정적인 원본 이미지를 동적인 입체 이미 지로 변환하여 제공하는 장치일 수 있다. 예를 들어, 입체 이미지 생성 장치는 원본 이미지에 포함된 객체 와 배경 간의 깊이(depth) 정보를 이용하여 콘텐츠의 몰입감을 주는 입체 이미지를 생성하는 장치일 수 있다. 일 실시 예에 따르면, 입체 이미지 생성 장치는 휴대폰, 스마트 폰(smart phone), 노트북 컴퓨터(laptop computer), 디지털방송용 단말기, PDA(personal digital assistants), PMP(portable multimedia player), 네비 게이션, 슬레이트 PC(slate PC), 태블릿 PC(tablet PC), 울트라북(ultrabook), 웨어러블 디바이스(wearable device, 예를 들어, 워치형 단말기(smart watch), 글래스형 단말기(smart glass), HMD(head mounted display)) 등을 포함하는 정보통신기기와 멀티미디어기기 및 그에 대한 응용 기기에 적용될 수 있음은 자명할 것이다. 또한, 일 실시 예에 따르면, 입체 이미지 생성 장치는 머신 러닝 중에서 딥러닝(deep learning)이라는 방 법을 통해 만들어진 인공지능 기반의 모델을 이용하여 입체 이미지를 생성하는 장치일 수 있다. 따라서, 이하에 서 설명하는 적어도 하나의 딥러닝 모델은 객체를 포함하는 다수의 학습 원본 이미지 데이터를 이용하여 생성되 는 입체 이미지를 학습 데이터로 반복 학습할 수 있다. 이하 본 발명의 입체 이미지 생성 장치는 본 발명의 일 실시 예에 따른 입체 이미지 생성 방법을 구성하는 각 단계들을 실행하도록 구성될 수 있으며, 예를 들어, 도 2에 도시되는 바와 같이, 입체 이미지 생성 방법 (S200)의 각 단계들을 실행하도록 구성될 수 있다. 도 1 및 도 2를 참조하면, 본 발명의 일 실시 예에 따른 입체 이미지 생성 장치는 이미지 수신부, 이 미지 분리부, 그레이스케일 이미지 생성부, 마스킹 이미지 생성부, 깊이 이미지 생성부 및 입체 이미지 생성부를 포함할 수 있다. 이미지 수신부는 메모리 등의 저장 수단에 미리 저장되거나 또는 PC, 카메라 등의 외부 단말로부터 전송되 는 2차원의 원본 이미지를 수신할 수 있다(S210). 일 실시 예에 따라, 원본 이미지는 적어도 하나의 객체 (object)와 배경(background)을 포함할 수 있다. 적어도 하나의 객체는, 예를 들어, 원본 이미지 내의 인물, 사 물, 동물 등을 의미하고, 배경은 원본 이미지 내의 객체를 제외한 나머지 영역을 의미할 수 있다. 이미지 분리부는 이미지 수신부를 통해 수신된 원본 이미지를 객체 이미지와 배경 이미지로 각각 분 리하여 생성할 수 있다(S220). 예를 들어, 이미지 분리부는 미리 학습된 제1 딥러닝 모델에 원본 이미지를 입력하여 원본 이미지 내의 적어도 하나의 객체를 추출할 수 있다. 제1 딥러닝 모델은, 예를 들어, 원본 이미지 내에서 중요한 특징을 갖는 객체를 검출하는 U2Net 기반의 딥러닝 모델일 수 있다. 일 실시 예에 따라, 이미지 분리부는 원본 이미지에서 객체가 검출된 영역에 대해서는 이미지의 식별자가 1을 갖도록 마스킹(masking) 처리하고, 객체를 제외한 영역에 대해서는 이미지의 식별자가 0을 갖도록 마스킹 처리할 수 있다. 그리고, 이미지 분리부는 원본 이미지에서 식별자 1을 갖는 영역을 선택 추출하여 객체 이미지를 생성하고, 동시에 원본 이미지에서 식별자 1을 갖는 영역을 선택 제거하여 배경 이미지를 생성할 수 있다. 다시 말해, 이미지 분리부는 원본 이미지에서 객체가 검출된 영역을 선택 추출하여 객체 이미지를 생성하고, 원본 이미지에서 객체가 검출된 영역을 선택 제거하여 배경 이미지를 생성할 수 있다. 이 경우, 이미지 분리부는 미리 학습된 제2 딥러닝 모델을 이용해 원본 이미지에서 객체가 검출된 영역, 즉 선택 제거된 영역을 인페인팅(inpainting)하여 배경 이미지를 생성할 수 있다. 제2 딥러닝 모델은 원본 이미 지에서 선택 제거된 영역에 대한 이미지 복원을 수행하는 LaMa 기반의 딥러닝 모델일 수 있다. 그레이스케일 이미지 생성부는 이미지 분리부를 통해 생성되는 객체 이미지를 그레이스케일 (grayscale) 이미지로 변환할 수 있다(S230). 예를 들어, 그레이스케일 이미지 생성부는 객체 이미지를 미 리 학습된 제3 딥러닝 모델에 입력하여 객체 이미지의 깊이 정보를 획득하고, 획득한 깊이 정보에 따라 컬러의 객체 이미지를 그레이스케일 이미지로 변환할 수 있다. 그레이스케일 이미지는 객체 이미지 내 각 픽셀에 대응하는 깊이에 관한 값을 그레이스케일로 변환한 이미지일 수 있다. 이 경우, 제3 딥러닝 모델은, 예를 들어, 객체 이미지 내 객체의 깊이 정보를 추정하기 위한 MiDas 기 반의 딥러닝 모델일 수 있다. 마스킹 이미지 생성부는 그레이스케일 이미지 생성부를 통해 획득한 깊이 정보에 따라 그레이스케일 이미지를 깊이별로 슬라이싱(slicing)하여 복수의 그레이스케일 마스킹 이미지를 생성할 수 있다(S240). 일 실시 예에 따라, 마스킹 이미지 생성부는 객체 이미지 내 픽셀의 깊이 정보를 바탕으로 입체 이미지를 출력하는 시점과 수직인 방향, 예를 들어, Z축 방향으로 이미지 슬라이싱을 수행할 수 있다. 이 경우, 마스킹 이미지 생성부는 설계자 또는 사용자에 의해 기 설정된 깊이 범위에 따라 이미지 슬라이싱 정도를 조절할 수 있다. 또한, 일 실시 예에 따라, 마스킹 이미지 생성부는 객체 이미지의 RGB 색상 정보를 기반으로 그레이스케일 이미지를 슬라이싱하여 복수의 그레이스케일 마스킹 이미지를 생성할 수 있다. 깊이 이미지 생성부는 복수의 그레이스케일 마스킹 이미지에 대응하여 원본 이미지를 깊이별로 슬라이싱하 여 복수의 깊이 이미지를 생성할 수 있다(S250). 예를 들어, 깊이 이미지 생성부는 원본 이미지와 각각의 그레이스케일 마스킹 이미지의 공통 영역을 원본 이미지에서 추출하여 복수의 깊이 이미지를 생성할 수 있다. 입체 이미지 생성부는 복수의 깊이 이미지와 배경 이미지를 합성하여 모션 효과(motion effect)를 갖는 입 체 이미지를 생성할 수 있다(S260). 일 실시 예에 따라, 입체 이미지 생성부는 입체 이미지 내에서 객체의 위치, 각도, 배경과 객체의 조합 여부 등을 고려하여 복수의 깊이 이미지와 배경 이미지를 랜더링할 수 있다. 이하에서는, 원본 이미지를 이용하여 입체 이미지를 생성하는 구체적인 과정에 대해 보다 상술하기로 한다. 도 3 내지 도 8은 본 발명의 일 실시 예에 따른 입체 이미지를 생성하는 과정을 설명하기 위한 일 예를 나타내 는 도면이다. 먼저, 도 3 및 도 5는 원본 이미지를 이용해 객체 이미지와 배경 이미지를 생성하는 과정을 각 각 나타낸다. 도 3 및 도 5를 참조하면, 입체 이미지 생성 장치의 이미지 분리부는 원본 이미지를 미리 학습 된 제1 딥러닝 모델에 입력하여 원본 이미지 내의 주요 특징을 가진 객체를 추출하고, 추출된 객체의 경계 를 기준으로 마스킹 처리된 이미지를 생성할 수 있다. 일 실시 예에 따라, 이미지 분리부는 원본 이미지에서 객체가 검출된 영역에 대해서는 이미지의 식별 자가 1을 갖도록 마스킹 처리하고, 객체를 제외한 영역에 대해서는 이미지의 식별자가 0을 갖도록 마스킹 처리 하여 마스킹 처리된 이미지를 생성할 수 있다. 예를 들어, 마스킹 처리된 이미지는, 도 3 및 도 4에 도시되는 바와 같이, 식별자가 1을 갖도록 마스킹 처리된 영역은 white으로 변환되고, 식별자가 0을 갖도록 마 스킹 처리된 영역을 black으로 변환된 이미지일 수 있다. 그리고, 이미지 분리부는 원본 이미지에서 마스킹 처리된 이미지에서 객체가 검출된 영역을 선 택 추출하여 객체 이미지를 생성하고(예를 들어, 도 4 참조), 원본 이미지에서 마스킹 처리된 이미지 에서 객체가 검출된 영역을 선택 제거하여 제1 배경 이미지를 생성할 수 있다(예를 들어, 도 5 참 조). 일 실시 예에 따라, 이미지 분리부는 제1 배경 이미지를 미리 학습된 제2 딥러닝 모델에 입력하여 선 택 제거된 영역을 인페인팅함으로써, 제2 배경 이미지를 생성할 수 있다. 제2 배경 이미지는 입체 이 미지 생성을 위해 이용되는 배경 이미지를 의미할 수 있다. 다음으로, 도 6을 참조하면, 입체 이미지 생성 장치의 그레이스케일 이미지 생성부는 이미지 분리부 에 의해 생성된 객체 이미지를 그레이스케일 이미지로 변환할 수 있다. 예를 들어, 그레이스케 일 이미지 생성부를 객체 이미지의 깊이 정보를 바탕으로 객체 이미지 내 각 픽셀에 대응하는 깊이에 관한 값을 그레이스케일로 변환함으로써, 그레이스케일 이미지를 생성할 수 있다. 다음으로, 도 7을 참조하면, 입체 이미지 생성 장치의 마스킹 이미지 생성부는 그레이스케일 이미지 를 깊이별로 슬라이싱하여 복수의 그레이스케일 마스킹 이미지를 생성할 수 있다. 예를 들어, 마스킹 이미지 생성부는 객체 이미지의 깊이 정보를 바탕으로 Z축 방향으로 이미지 슬라이싱을 수행하여 복 수의 그레이스케일 마스킹 이미지를 생성할 수 있다. 일 실시 예에 따라, 마스킹 이미지 생성부는 객체 이미지의 RGB 색상 정보를 기반으로 그레이스케일 이미지를 슬라이싱하여 복수의 그레이스케일 마스킹 이미지를 생성할 수도 있다. 다음으로, 도 8을 참조하면, 입체 이미지 생성 장치의 깊이 이미지 생성부는 원본 이미지를 복 수의 그레이스케일 마스킹 이미지에 대응하여 깊이별로 슬라이싱하여 복수의 깊이 이미지를 생성할 수 있다. 예를 들어, 깊이 이미지 생성부는 원본 이미지와 그레이스케일 마스킹 이미지 각각의 공통 영역을 원본 이미지에서 추출하여 복수의 깊이 이미지를 생성할 수 있다. 다음으로, 입체 이미지 생성 장치의 입체 이미지 생성부는 복수의 깊이 이미지와 배경 이미지 를 합성하여 입체 이미지를 생성할 수 있다. 일 실시 예에 따라, 입체 이미지 생성부는 입체 이미지의 장르 정보에 기초하여 입체 이미지에 적합한 적 어도 하나의 레이어(layer)를 생성 및/또는 추출할 수 있다. 즉, 이미지 생성부는 상기 적어도 하나의 레 이어를 입체 이미지에 합성함으로써, 보다 생동감있고, 시선집중효과가 있는 입체 이미지를 제공할 수 있다. 상술한 바와 같이, 본 발명의 일 실시 예에 따른 입체 이미지 생성 장치 및 그 방법에 의하면, 원본 이미지 내 의 객체에 대해 모션 효과(motion effect)를 적용하여 콘텐츠에 대한 몰입감을 높일 수 있다. 또한, 본 발명에 의하면, 원본 이미지 내의 객체와 배경을 분리하여 각각의 이미지를 생성하고, 이를 이용해 현 장감과 생동감이 극대화된 동적인 입체 이미지를 생성할 수 있는 효과가 있다. 한편, 본 명세서에 기재된 다양한 실시예들은 하드웨어, 미들웨어, 마이크로코드, 소프트웨어 및/또는 이들의 조합에 의해 구현될 수 있다. 예를 들어, 다양한 실시예들은 하나 이상의 주문형 반도체(ASIC)들, 디지털 신호 프로세서(DSP)들, 디지털 신호 프로세싱 디바이스(DSPD)들, 프로그램어블 논리 디바이스(PLD)들, 필드 프로그램 어블 게이트 어레이(FPGA)들, 프로세서들, 컨트롤러들, 마이크로컨트롤러들, 마이크로프로세서들, 여기서 제시되는 기능들을 수행하도록 설계되는 다른 전자 유닛들 또는 이들의 조합 내에서 구현될 수 있다. 또한, 예를 들어, 다양한 실시예들은 명령들을 포함하는 컴퓨터-판독가능한 매체에 수록되거나 인코딩될 수 있 다. 컴퓨터-판독가능한 매체에 수록 또는 인코딩된 명령들은 프로그램 가능한 프로세서 또는 다른 프로세서로 하여금 예컨대, 명령들이 실행될 때 방법을 수행하게끔 할 수 있다. 컴퓨터-판독가능한 매체는 컴퓨터 저장 매 체를 포함하며, 컴퓨터 저장 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수도 있다. 예를 들어, 이러한 컴퓨터-판독가능한 매체는 RAM, ROM, EEPROM, CD-ROM 또는 기타 광학 디스크 저장 매체, 자기 디 스크 저장 매체 또는 기타 자기 저장 디바이스를 포함할 수 있다. 이러한 하드웨어, 소프트웨어, 펌웨어 등은 본 명세서에 기술된 다양한 동작들 및 기능들을 지원하도록 동일한 디바이스 내에서 또는 개별 디바이스들 내에서 구현될 수 있다. 추가적으로, 본 발명에서 \"~부\"로 기재된 구성 요소들, 유닛들, 모듈들, 컴포넌트들 등은 함께 또는 개별적이지만 상호 운용가능한 로직 디바이스들로서 개별 적으로 구현될 수 있다. 모듈들, 유닛들 등에 대한 서로 다른 특징들의 묘사는 서로 다른 기능적 실시예들을 강 조하기 위해 의도된 것이며, 이들이 개별 하드웨어 또는 소프트웨어 컴포넌트들에 의해 실현되어야만 함을 필수 적으로 의미하지 않는다. 오히려, 하나 이상의 모듈들 또는 유닛들과 관련된 기능은 개별 하드웨어 또는 소프트 웨어 컴포넌트들에 의해 수행되거나 또는 공통의 또는 개별의 하드웨어 또는 소프트웨어 컴포넌트들 내에 통합 될 수 있다. 특정한 순서로 동작들이 도면에 도시되어 있지만, 이러한 동작들이 원하는 결과를 달성하기 위해 도시된 특정한 순서, 또는 순차적인 순서로 수행되거나, 또는 모든 도시된 동작이 수행되어야 할 필요가 있는 것으로 이해되지 말아야 한다. 임의의 환경에서는, 멀티태스킹 및 병렬 프로세싱이 유리할 수 있다. 더욱이, 상술한 실시예에서 다양한 구성요소들의 구분은 모든 실시예에서 이러한 구분을 필요로 하는 것으로 이해되어서는 안되며, 기술된 구성요소들이 일반적으로 단일 소프트웨어 제품으로 함께 통합되거나 다수의 소프트웨어 제품으로 패키징될 수 있다는 것이 이해되어야 한다. 이상에서와 같이 도면과 명세서에서 최적 실시예가 개시되었다. 여기서 특정한 용어들이 사용되었으나, 이는 단 지 본 발명을 설명하기 위한 목적에서 사용된 것이지 의미한정이나 특허청구범위에 기재된 본 발명의 범위를 제 한하기 위하여 사용된 것은 아니다. 그러므로 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이해할 것이다. 따라서 본 발명의 진정한 기술적 보호범위는 첨부된 특 허청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2023-0039826", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 입체 이미지 생성 장치의 기능적 블록도를 나타내는 도면이다. 도 2는 본 발명의 일 실시 예에 따른 입체 이미지 생성 방법을 설명하기 위한 순서도를 나타내는 도면이다. 도 3 내지 도 8은 본 발명의 일 실시 예에 따른 입체 이미지를 생성하는 과정을 설명하기 위한 일 예를 나타내 는 도면이다."}
