{"patent_id": "10-2018-0153820", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0071837", "출원번호": "10-2018-0153820", "발명의 명칭": "인공지능을 이용한 반려동물 감성봇 장치 및 이를 이용한 교감 방법", "출원인": "정진해", "발명자": "정진해"}}
{"patent_id": "10-2018-0153820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자 모바일 기기;반려동물에 착용되고, 반려동물의 감정상태를 센싱하는 센서부와, 제1무선통신부를 포함하는 반려동물 웨어러블기기 및;상기 제1무선통신부 및 상기 사용자 모바일 기기와 통신하는 통신부, 반려동물의 사진을 캐릭터로 변환하는 영상부, 상기 센서부에서 센싱된 반려동물의 감정상태 정보를 분석하여 분석정보를 생성하는 분석부, 상기 분석정보를 영상부의 캐릭터에 반영시켜 리얼캐릭터를 생성시키는 영상반영부 및, 데이터베이스를 포함하는 서버;를포함하여 구성되는 것을 특징으로 하는 인공지능을 이용한 반려동물 감성봇 시스템."}
{"patent_id": "10-2018-0153820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 분석부는,상기 반려동물의 감정상태 정보와 외부 정보를 분석하여 분석정보를 생성하도록 구성되고,상기 서버는,메시지 생성부를 더 포함하여 구성되고,상기 메시지 생성부는,상기 분석부의 분석정보를 이용하여 반려동물의 감정상태를 메시지로 생성시키도록 구성되는 것을 특징으로 하는 인공지능을 이용한 반려동물 감성봇 시스템."}
{"patent_id": "10-2018-0153820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "사용자 모바일 기기에서 촬영된 반려동물의 사진을 영상부에서 캐릭터로 변환시키는 캐릭터 변환단계;반려동물 웨어러블기기의 센서부에서 센싱된 후 서버의 분석부로 전달된 반려동물의 감정상태 정보를 분석하여분석정보를 생성시키는 감정분석단계;상기 캐릭터 변환단계에서 생성된 캐릭터에 상기 분석정보를 반영하여, 반려동물의 감정이 반영된 리얼캐릭터를생성시키는 리얼캐릭터 생성단계;상기 리얼캐릭터를 사용자 모바일 기기로 전달하여 구현시키는 구현단계;를 포함하여 구성되는 것을 특징으로하는 반려동물 감성봇 시스템을 이용한 반려동물과의 교감방법."}
{"patent_id": "10-2018-0153820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 분석부는,상기 반려동물의 감정상태 정보와 외부 정보를 분석하여 분석정보를 생성하도록 구성되고,상기 서버는,메시지 생성부를 더 포함하여 구성되고,공개특허 10-2020-0071837-3-상기 메시지 생성부는,상기 감정분석단계의 분석정보를 이용하여 반려동물의 감정상태를 메시지로 생성시키는 메시지 생성단계를 더수행하도록 구성되며,상기 메시지는 사용자 모바일 기기에서 구현되도록 구성되는 것을 특징으로 하는 반려동물 감성봇 시스템을 이용한 반려동물과의 교감방법."}
{"patent_id": "10-2018-0153820", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 반려동물 감성봇 장치 및 이를 이용한 교감 방법에 관한 것으로, 더욱 상세하게는, 실제 반려동물을 캐릭터화하여, 상기 캐릭터에 실제 반려동물의 감정 또는 외부 정보를 반영하여, 실제 반려동물 과 동일한 환경 및 신체, 감정 조건을 가지는 캐릭터와 대화 가능한 반려동물 감성봇 장치 및 이를 이용한 교감 방법에 관한 것이다."}
{"patent_id": "10-2018-0153820", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 반려동물 감성봇 장치 및 이를 이용한 교감 방법에 관한 것으로, 더욱 상세하게는, 실제 반려동물을 캐릭터화하여, 상기 캐릭터에 실제 반려동물의 감정 또는 외부 정보를 반영하여, 캐릭터와 교감 가능한 반려동물 감성봇 장치 및 이를 이용한 교감 방법에 관한 것이다."}
{"patent_id": "10-2018-0153820", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "반려동물은 1인가구가 증가함에 따라, 점점 가정에서 많이 키우고 있으며, 반려동물 1,000만 시대가 도래하고 있다. 그리고, 과거에는 반려동물이 사람들의 즐거움 또는 필요에 의한 수단이었다면, 현재는 반려동물이 친구 또는 가족의 일원으로 인식이 많이 바뀌고 있는 추세이다. 따라서, 최근 들어 반려동물의 건강에 관심을 갖는 사람들 이 많이 늘고 있다. 반려동물이 가족의 일원이 되었지만, 말을 하지 못하기 때문에 직접적은 소통은 어려우며, 반려동물이 아프더라 도 그 증상을 쉽게 알아차리기가 힘들어 많은 불편함을 갖고 있다. 또한, 반려동물의 감정 또는 건강상태를 알 수 없어 답답한 사용자가 늘고 있다. 최근 웨어러블 업계에서 반려동물을 위한 펫 웨어러블(Pet Wearable)의 존재감이 점차 부각되고 있으며, 미국 샌프란시스코에 위치한 휘슬 랩(Whistle Lab)은 애완견을 위한 활동 추적 단말기인 '휘슬 활동 모니터(Whistle Activity Monitor, 이하 휘슬)'를 제작해 판매하고 있다. 그러나, 반려동물의 심박, 체온, 움직임, 위치정보 등의 정보를 웨어러블 센서를 통해 실시간으로 수집하고, 이 를 융,복합 빅 데이터 방법론에 의해 빅 데이터 의사결정 시스템을 제공함으로 반려동물과 사람과의 더 깊고 의 미 있는 교감이 가능한 빅 데이터 인텔리전스 정보 기술을 제공하도록 하기 위한 시스템을 구현하여 애완동물을 관리하지 못하고 있다. 또한, 반려동물 멀티모달 센싱 기술, 반려동물 데이터수집을 위한 모바일 디바이스 응용SW기술, 반려동물 신체 적, 감성정 상황 분석을 위한 빅 데이터 분석 및 의사결정 응용SW기술, 반려동물 데이터 통합분석 및 관리시스 템 기술 구현으로 고착화 되어가는 반려 동물의 주인에게 크나큰 경제적 부담은 물론, 공동 생활환경에서의 사 회적 문제를 해결하기 위한 방안으로 부각되고 있다. 즉, 종래 반려동물과의 교감 시스템은 단순히 반려동물의 신체 상태 정보, 활동량 또는 식사량 등만이 반려동물 주인에게 일방적으로 제공하는 것에 그치는 문제가 발생하였고, 또한 반려동물 주인은 반려동물과 계속적으로 함께하지 않는 이상 반려동물의 감정 상태를 쉽게 파악할 수 없는 문제가 발생하였다."}
{"patent_id": "10-2018-0153820", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 해결하기 위해 안출된 것으로, 반려동물의 감정을 빅데이터 시스템을 통해 제공하는 것이 아닌, 실제 반려동물의 감정을 파악하여 전달하여 실제 소통 환경을 제공하는 환경으로 해결하고자 한다. 또한, 반려동물과의 교감 시스템이 단순히 반려동물의 신체 상태 정보, 활동량 또는 식사량 등만이 반려동물 주 인에게 일방적으로 제공하는 것에 그치는 문제와, 반려동물 주인은 반려동물과 계속적으로 함께하지 않는 이상 반려동물의 감정 상태를 쉽게 파악할 수 없는 문제를 해결하고자 한다."}
{"patent_id": "10-2018-0153820", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "사용자 모바일 기기, 반려동물에 착용되고, 반려동물의 감정상태를 센싱하는 센서부와, 제1무선통신부를 포함하 는 반려동물 웨어러블기기 및 상기 제1무선통신부 및 상기 사용자 모바일 기기와 통신하는 통신부, 반려동물의 사진을 캐릭터로 변환하는 영상부, 상기 센서부에서 센싱된 반려동물의 감정상태 정보를 분석하여 분석정보를 생성하는 분석부, 상기 분석정보를 영상부의 캐릭터에 반영시켜 리얼캐릭터를 생성시키는 영상반영부 및, 데이 터베이스를 포함하는 서버를 포함하여 구성되는 것을 특징으로 한다. 상기 분석부는, 상기 반려동물의 감정상태 정보와 외부 정보를 분석하여 분석정보를 생성하도록 구성되고, 상기 서버는, 메시지 생성부를 더 포함하여 구성되고, 상기 메시지 생성부는, 상기 분석부의 분석정보를 이용하여 반 려동물의 감정상태를 메시지로 생성시키도록 구성되는 것을 특징으로 한다. 사용자 모바일 기기에서 촬영된 반려동물의 사진을 영상부에서 캐릭터로 변환시키는 캐릭터 변환단계, 반려동물 웨어러블기기의 센서부에서 센싱된 후 서버의 분석부로 전달된 반려동물의 감정상태 정보를 분석하여 분석정보 를 생성시키는 감정분석단계, 상기 캐릭터 변환단계에서 생성된 캐릭터에 상기 분석정보를 반영하여, 반려동물 의 감정이 반영된 리얼캐릭터를 생성시키는 리얼캐릭터 생성단계, 상기 리얼캐릭터를 사용자 모바일 기기로 전 달하여 구현시키는 구현단계를 포함하여 구성되는 것을 특징으로 한다. 상기 분석부는, 상기 반려동물의 감정상태 정보와 외부 정보를 분석하여 분석정보를 생성하도록 구성되고, 상기 서버는, 메시지 생성부를 더 포함하여 구성되고, 상기 메시지 생성부는, 상기 감정분석단계의 분석정보를 이용 하여 반려동물의 감정상태를 메시지로 생성시키는 메시지 생성단계를 더 수행하도록 구성되며, 상기 메시지는 사용자 모바일 기기에서 구현되도록 구성되는 것을 특징으로 한다."}
{"patent_id": "10-2018-0153820", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같이 본 발명은 반려동물의 감정을 직접 센서를 통해 파악하기 때문에, 실시간으로 반려 동물의 감정을 파악할 수 있다. 즉, 본 발명은 반려동물의 감정을 직접 센서 분석을 통해 파악하고, 반려동물의 감정을 실시간으로 캐릭터화하 여 반려동물 주인에게 전달 가능한 효과를 얻을 수 있고, 그 결과, 반려동물 주인은 캐릭터화된 반려동물의 감 정정보를 이용하여, 반려동물과 산책, 놀이, 먹이주기 등과 같은 대응을 통한 교감을 실현시킬 수 있고, 사용자 의 대응 및 교감 정도에 따라 반려동물의 캐릭터가 성장하여, 사용자와 반려동물과의 친밀도를 높일 수 있는 효 과가 있다. 또한, 사용자 모바일 기기의 앱 내에 설치되어 대화형식으로 소통하므로, 실제 대화를 하고 있다는 느낌을 받을 수 있고, 언제 어디서나 반려동물과 교감할 수 있다."}
{"patent_id": "10-2018-0153820", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 실시예들에 대한 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후 술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하"}
{"patent_id": "10-2018-0153820", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "고, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되 는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다.본 발명의 실시예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명의 실시예에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 도 1은 본 발명의 일 실시예에 따른 감성봇 장치의 구성을 나타낸 도면이다. 도 1을 참조하면, 본 발명의 일 실 시예에 따른 감성봇 장치 및 그를 이용한 교감 방법은, 사용자에게 메시지를 전달하는 장치로서, 사용자 모바일 기기, 반려동물 웨어러블기기, 통신부, 영상부, 분석부, 영상반영부 및 서버로 구성되어 있다. 상기 감성봇 장치는, 사용자 모바일 기기 및 반려동물 웨어러블기기를 포함하며, 사용자가 직접 사용가능한 모 바일 기기 및 반려동물에 착용되는 웨어러블기기로 이루어져 있다. 상기 반려동물 웨어러블 기기는, 반려동물에 착용되고, 반려동물의 감정상태를 센싱하는 센서부와, 제1무선통신 부를 포함한다. 또한, 상기 통신부는 상기 제1무선통신부 및 상기 사용자 모바일 기기와 통신하기 위해 구비되어 있으며, 상기 영상부는 반려동물의 사진을 캐릭터로 변환하기 위해 구비되어 있다. 또한, 상기 분석부는 상기 센서부에서 센 싱된 반려동물의 감정상태 정보를 분석하여 분석정보를 생성하기 위해 구비되어 있으며, 상기 영상반영부는 상 기 분석정보를 영상부의 캐릭터에 반영시켜 리얼캐릭터를 생성시키기 위해 구비되어 있다. 또한, 상기 감성봇 시스템은 데이터베이스를 포함하는 서버를 더 구비하고 있다. 이때, 상기 분석부는, 상기 반려동물의 감정상태 정보와 외부 정보를 분석하여 분석정보를 생성하도록 구성되고, 상기 서버는, 메시지 생성부를 더 포함하여 구성되고, 상기 메시지 생성부는, 상기 분석부의 분석정 보를 이용하여 반려동물의 감정상태를 메시지로 생성시키도록 구성된다. 상기 메시지 생성부에서 생성되는 메시지는, 문자, 음성, 이모티콘 또는 영상 중 어느 하나 이상의 것이 될 수 있다. 또한, 상기 메시지는 사용자 모바일 기기로 전송되어, 상기 캐릭터와 함께 구현된다. 이때, 상기 외부 정보는, 반려동물의 위치정보, 외부 날씨정보, 실내 온도정보, 외부 온도정보, 실내 습도정보, 외부 습도정보, 계절정보, 시간정보 또는 기념일정보 중 어느 하나의 정보로 구성되고, 상기 반려동물의 위치정 보, 실내 온도정보 및 실내 습도정보는 센서부에서 센싱되도록 구성되며, 상기 외부 날씨정보, 외부 온도정보, 외부 습도정보, 계절정보, 시간정보 및 기념일정보는 외부서버에서 상기 서버로 취득되도록 구성되는 것을 특징 으로 한다. 또한, 상기 영상반영부에서 생성된 리얼캐릭터는, 반려동물에 대한 사용자의 교감에 따라 달라지는 반려동물의 감정상태 정보의 변화를 이용하여, 사용자와 반려동물 간의 교감이 증가할수록 리얼캐릭터가 성장하도록 구성되 는 것을 특징으로 한다. 또한, 상기 리얼캐릭터는, 성장에 따라 크기 또는 형태 중 어느 하나 이상의 것이 변화 가능하도록 구성된다. 또한, 상기 영상반영부에서 생성된 리얼캐릭터는, 반려동물에 대한 사용자의 교감에 따라 달라지는 반려동물의 감정상태 정보의 변화를 이용하여, 사용자와 반려동물 간의 교감이 증가할수록 리얼캐릭터가 성장하도록 구성되 고, 상기 리얼캐릭터는, 성장에 따라 메시지의 대화수준이 진화되도록 구성된다. 즉, 리얼캐릭터의 성장은 사용 자와 반려동물 간의 교감에 따라 변화하므로, 사용자와 반려동물 간의 교감이 감소하면, 상기 리얼캐릭터 또한 퇴화될 수 있다. 이하, 첨부된 도면을 참조하여 사용자에게 메시지를 보내는 반려동물 감성봇 장치를 이용한 방법에 대한 실시예 를 설명하기로 한다. 도 2는 본 발명의 일 실시예에 따른 반려동물 감성봇 장치를 이용한 교감 방법을 나타낸 도면이다. 사용자 모바일 기기에서 촬영된 반려동물의 사진을 영상부에서 캐릭터로 변환시키는 캐릭터 변환단계를 거치게 된다. 상기 반려동물의 사진 또는 영상을 캐릭터화 하기 위해, 반려동물의 사진 또는 영상을 합성, 캐리커쳐화 등의 방법을 통해 캐릭터화 하게 된다. 상기 캐릭터는 반려동물 캐릭터로 캐릭터 데이터베이스에 저장되게 되고, 변환되기 전 사진 또는 영상은 반려동물 데이터베이스에 저장되게 된다. 반려동물 웨어러블기기의 센서부에서 센싱된 후 서버의 분석부로 전달된 반려동물의 감정상태 정보를 분석하여 분석정보를 생성시키는 감정분석단계를 거치게 된다. 또한, 상기 캐릭터 변환단계에서 생성된 캐릭터에 상기 분석정보를 반영하여, 반려동물의 감정이 반영된 리얼캐 릭터를 생성시키는 리얼캐릭터 생성단계를 거쳐 상기 리얼캐릭터를 사용자 모바일 기기로 전달하여 구현시키는 구현단계를 거친다. 이때, 상기 분석부는, 상기 반려동물의 감정상태 정보와 외부 정보를 분석하여 분석정보를 생성하도록 구성되고, 상기 서버는, 메시지 생성부를 더 포함하여 구성되고, 상기 메시지 생성부는, 상기 감정분석단계의 분석정보를 이용하여 반려동물의 감정상태를 메시지로 생성시키는 메시지 생성단계를 더 수행하도록 구성되며, 상기 메시지는 사용자 모바일 기기에서 구현되도록 구성된다. 상기 외부 정보는, 반려동물의 위치정보, 외부 날씨정보, 실내 온도정보, 외부 온도정보, 실내 습도정보, 외부 습도정보, 계절정보, 시간정보 또는 기념일정보 중 어느 하나의 정보로 구성되고, 상기 반려동물의 위치정보, 실내 온도정보 및 실내 습도정보는 센서부에서 센싱되도록 구성되며, 상기 외부 날씨정보, 외부 온도정보, 외부 습도정보, 계절정보, 시간정보 및 기념일정보는 외부서버에서 상기 서버로 취득되도록 구성되는 것을 특징으로 한다. 또한, 상기 리얼캐릭터는, 반려동물에 대한 사용자의 교감에 따라 달라지는 반려동물의 감정상태 정보의 변화를 이용하여, 사용자와 반려동물 간의 교감이 증가할수록 캐릭터가 성장하도록 구성되는 것을 특징으로 한다. 이때, 상기 리얼 캐릭터는, 성장에 따라 크기 또는 형태 중 어느 하나 이상의 것이 변화 가능하도록 구성된다. 즉, 상기 리얼캐릭터는, 반려동물에 대한 사용자의 교감에 따라 달라지는 반려동물의 감정상태 정보의 변화를 이용하여, 사용자와 반려동물 간의 교감이 증가할수록 리얼캐릭터가 성장하도록 구성되고, 상기 리얼캐릭터는, 성장에 따라 메시지의 대화수준이 진화되도록 구성된다. 또한, 본 발명의 일 실시예에 따른 감성봇 장치는, 상기 캐릭터와 실제 반려동물의 사진 또는 영상은 서로 매칭 되어 저장되어, 각 캐릭터마다 고유의 정보를 가지게 된다. 예를 들어, 반려동물 A의 사진을 캐릭터화하여 저장 시, 캐릭터 데이터베이스에 A의 캐릭터가 저장되게 되고, 반려동물 데이터베이스에는 A의 사진 및 A의 생일, 성 격, 접종날짜, 성장조건 등과 같은 정보가 저장되게 된다. 상기 정보는 사용자의 입력을 통해 이루어질 수 있다. 그 다음, 센서부에서 센싱된 반려동물의 감정상태를 분석하고, 분석된 감정상태와 외부 정보를 결합하여 서버부 로 전송하는 단계를 거치게 된다. 상기 센서부는 상기 반려동물의 생체신호를 센싱하게 된다. 이때, 상기 센서정보는 반려동물의 짖음 등과 같은 청각적 신호 또는 음성일 수도 있고, 반려동물의 체온 등과 같은 촉각적 센서일 수 있고, 피부상태 등과 같은 시각적 센서 또는 영상일 수도 있다. 또한, 상기 센서부는 상기 반려동물의 생체신호 뿐만 아니라 외부 신호 또 한 센성 가능하다. 위치, 외부 날씨, 습도, 온도 등과 같은 외부 신호를 센싱하여 상기 반려동물의 생체신호와 함께 서버부에 전송되게 된다. 이때, 상기 청각적 신호를 감지하기 위하여 청각센서를 더 포함할 수 있고, 상기 청각센서는 반려동물의 음성을 센싱하기 위해 구비될 수 있다. 그 다음, 상기 서버부에 전송된 감정상태 및 외부 정보를 바탕으로 대화형 메시지를 생성하는 단계를 거치게 된 다. 상기 반려동물의 생체신호를 시각적, 청각적, 촉각적 센서를 통해 수집된 정보와 위치, 날씨, 습도 등의 다 양한 정보를 결합하여 대화형 메시지를 생성할 수 있다. 상기 대화형 메시지는 상기 캐릭터의 성장 단계에 따라 대화의 단계가 조절되거나 또는 캐릭터의 상태가 전달될 수 있다. 즉, 상기 정보들을 바탕으로 형성된 대화형 메시지를 사용자에게 전달하고, 사용자가 입력한 메시지를 분석하여 그에 대응하는 대화형 메시지를 생성할 수 있다. 이때, 생성된 메시지는 캐릭터에 나타내는 단계를 더 거치게 된다. 이때, 상기 캐릭터는, 텍스트 형태로 메시지를 나타낼 수 있고, 또는 스피커를 통해 음성의 형태로 나타낼 수도 있다. 상기 캐릭터는, 사용자와 반려동물과의 교감 정도에 따라 다양하게 진화하는 육성형 캐릭터일 수 있다. 즉, 사 용자와 반려동물의 교감이 많아질수록 캐릭터의 성장 속도가 빨라지고 대화의 수준도 진화할 수 있다. 즉, 반려동물과의 교감에 있어, 사용자가 선택한 캐릭터 또는 반려동물의 사진을 합성한 캐릭터는, 사료, 물, 조도, 이산화탄소 농도 등과 같은 정보를 입력받아 관리 될 수 있으며, 쓰다듬어주기, 안아주기, 산책하기, 목 욕시켜주기, 운동하기, 터그놀이하기 등과 같은 행동을 센서로 인식할 수 있으며, 인식된 센서값에 따라 반려동 물의 상태 또는 감정을 파악할 수 있다.이때, 상기 캐릭터는 적어도 하나 이상 저장가능하며, 사용자의 필요에 따라 선택 가능하도록 형성된다. 즉, 다 수개의 캐릭터를 저장하여 사용자와 1:1, 1:N, N:1 또는 N:N으로 대화 가능하다. 도 3은 본 발명의 다른 실시예에 따른 사용자 캐릭터 감성봇 장치를 이용한 교감 방법을 나타낸 도면이다. 다른 실시예로서, 반려동물의 영상 대신 사람의 영상을 이용하여 촬영하고, 사람을 캐릭터화 하여 이용할 수 있다. 상기 반려동물 대신 사람의 사진 또는 영상을 촬영하여 캐릭터화 하고, 사용자의 정보를 입력받게 된다. 이때, 상기 캐릭터 및 사용자 정보는 캐릭터 데이터베이스 또는 사용자 데이터베이스에 저장되게 된다. 또한, 상기 사용자에 부착된 센서를 통해 상기 사용자의 생체신호를 파악할 수 있으며, 센서를 통해 수집된 정 보, 음성 및 영상을 통해 감정, 상태, 위치 등과 같은 정보를 파악할 수 있다. 상기와 같은 센서 정보를 통해 대화형 메시지를 생성하게 되는데, 이때, 사용자 데이터베이스에 저장된 사용자의 정보를 이용할 수 있다. 상기 사용자의 정보는 사용자의 취향, 대화수준, 이전대화내용, 직업, 성별, 나이 등과 같은 정보일 수 있다. 도 4는 본 발명의 일 실시예에 따른 감성봇 장치의 작동모습을 나타낸 도면이다. 도 4를 참조하면, 상기 감성봇 장치는 전술한 방법으로 반려동물 또는 사용자가 하나의 캐릭터로 형성되게 된다. 이때, 상기 캐릭터는 상태 또 는 상황정보에 따라 상기 캐릭터의 형태를 변형할 수 있다. 상기 상태 또는 상황정보는, 일 예로, 날씨, 계절, 시간, 위치, 특정일 등과 같이 다양한 정보 및 상황일 수 있다. 도 5는 본 발명의 일 실시예에 따른 센서부의 작동모습을 나타낸 도면이다. 도 5를 참조하여, 상기 센서부에 대 해 상세히 설명한다. 전술한바와 같이, 상기 센서부는 반려동물의 감정상태를 센싱하기 위해 구비되어 있으며, 반려동물의 생체신호를 인식하여, 상기 생체신호를 바탕으로 감정상태를 파악하게 된다. 상기 센서는, PPG, ECG(심전도센서), EMG(근전도 센서), EDA, EEG(뇌파 측정 센서), IMU(관성 측정센서), TEMP(온도측정센서), CDS(조도 센서), CO2(이산화탄소 측정 센서) 등과 같은 센서일 수 있으며, 상기와 같은 센서를 통해 수집된 정 보는 데이터통신(INS)을 통해 서버부로 전송될 수 있다. 또한, 별도의 영상 또는 음성을 통해 인식된 감정상태 또한, 서버부로 전송되어, 슬픔, 기쁨, 분노 등과 같은 실제 감정상태를 나타낼 수 있다. 또한, 전술한 바와 같이, 상기 캐릭터는, 사용자와 반려동물과의 교감 정도에 따라 다양하게 진화하는 육성형 캐릭터일 수 있는데, 이에 따라 대화의 수준도 진화할 수 있다. 도 6은 본 발명의 일 실시예에 따른 대화 단계 조절 모습을 나타낸 도면이다. 도 6에 도시된 바와 같이, 일예로, 대화의 수준을 레벨 1에서 9까지로 보았을 때, 레벨1의 단계에서는 ㅇㅇ, ㅎ ㅎ 등과 같은 대화의 수준을 나타낼 수 있으며, 레벨 2의 단계에서는 맞춤법이 올바르지 못한 대화를 표한할 수 있다. 레벨이 높아질수록 일반 사용자와 유사한 대화를 제공할 수 있으며, 레벨 9의 단계에서는 일반 사용자와 대화하는 환경을 제공 할 수 있다. 레벨 1 이 레벨 9까지 진화하기 위해서는 각 단계별 이동 조건을 충족할 경우, 이동 가능하도록 설정 할 수 있 다. 즉, 사용자와 반려동물 캐릭터와의 대화시간 또는 기간에 따라 레벨 이동을 가능하도록 설정할 수 있다. 위 치정보 분석을 통한 반려동물의 예방접종 여부, 미용여부, 산책여부, 운동여부 등을 파악할 수 있고, 이에 따라 단계를 이동가능하다. 본 발명의 일 실시예에 따른 감성봇 장치 및 그를 이용한 교감 방법은, 모니터링부를 더 구비할 수 있다. 별도 의 모니터링부를 더 구비함으로써, 반려 동물의 상태를 실시간으로 모니터링 할 수 있다. 또한, 본 발명의 일 실시예에 따른 감성봇 장치 및 그를 이용한 교감 방법은 사용자의 모바일 기기에서 적용 될 수 있다. 또한, 캐릭터가 사용자의 음성 또는 문자 입력을 이해하는 데에는 인공지능이 사용될 수 있다. 구체적으로 사용 자의 음성의 패턴을 분석하여 사용자의 감정패턴(슬픔, 화남, 행복함 등)을 예측하는 데 인공지능이 사용될 수 있다. 더 구체적으로 사용자가 입력한 대화내용을 분석하여 사용자의 감정을 예측하는 데 인공지능이 사용될 수 있다. 해당 인공지능은 딥뉴런 네트워크를 사용할 수 있는데, 여러 방식(CNN 등)을 사용할 수 있으며, 머신 러 닝 알고리즘을 사용할 수 있다. 상술한 머신 러닝 알고리즘의 경우 심층 신경망(DNN)을 사용하거나 합성곱신경망(CNN) 또는 순환신경망(RNN) 방 식과 같이 여러가지 방식의 머신 러닝 알고리즘을 사용할 수 있다. 하지만 본 발명에서와 같이 캐릭터가 사용자의 음성 또는 문자 입력을 이해하기 위해서는, 사용자의 특정 행동 패턴에 대해 정확하게 구분할 수 있어야 하는데. 상기 구분은 예측기법에서는 후술하는 SVM(Support VectorMachine) 기법을 사용할 수 있다. SVM이란 클래시피케이션(classification), 리그레션(regression), 특이점 판별(outliers detection) 등에 주로 사용되는 지도 학습(Supervised Learning) 머신 러닝 방법 중 하나이다. 예를 들어, 두 그룹의 데이터를 구분하 는 여러 가지 방법 중에 각 그룹의 최대 거리에 있는 중간지점을 정확하게 구분할 수 있는 것이 분류정확도를 높일 수 있는 최적의 방법이라고 할 수 있다. 또한, 센서들로부터 획득된 데이터에 상술한 것과 같은 SVM 기법을 적용할 때, 장착된 센서의 수가 증가하고 센 서들로부터 전송된 데이터들이 점점 더 축적될수록 머신러닝의 트레이닝 횟수가 증대되고, 결과적으로 트레이닝 을 통해 획득한 모델링의 정확도가 점점 높아지게 된다. 이러한 특징은 특정한 수학이나 통계적 모델링을 통한 분석기법이 항상 일정한 정도의 예측오류율을 가지는 데에 비해, 트레이닝의 횟수가 늘수록 예측오류율이 점점 더 개선될 수 있다는 점은 머신 러닝 기법을 통한 모델링의 큰 장점이다. 결과적으로, 상술한 SVM 기법을 활용하여 상술했던 행렬을 분석하고 예측하게 되면, 사용자의 음성 또는 문자 입력의 행동패턴을 예측할 수 있다. 이 때 상술한 사용자의 음성 또는 문자 입력의 예측된 행동은 예를 들어, 사용자가 화가 났을 경우 나타나는 음성의 높낮이 등과 같은 행동을 의미한다. 또한, 두번째 실시예로는 후술하는 다른 이미지 분석 방식을 사용할 수 있다. 먼저, 사용자는 기본 이미지와 웃 고 있는 모습의 이미지 세트를 확보한다. 이때 이미지 세트는 트레이닝에 사용될 데이터와 평가(evaluation)에 사용될 데이터로 각각 분리한다. 평가에 사용될 데이터는 사용자가 이미 기본 이미지와 웃고 있는 모습의 이미 지에 대한 판단이 끝난 데이터 셋이라고 볼 수 있다. 이후 해당 이미지 세트를 머신 러닝 학습 기법 중 하나인 바이너리 클래시피케이션(Binary Classification)을 적용하여 트레이닝시키고, 이를 통해 모델을 획득한다. 이후 학습된 모델의 정확도(accuracy)를 평가 데이터셋 과 비교하여 확인한다. 이미지 세트가 늘어나고 이를 리트레이닝 시키는 횟수가 증대할수록 학습 모델의 판단 정확도는 점점 높아지게 된다. 결과적으로 목표로 하는 정확도(예를 들어 95%)를 달성한 캐릭터를 실행시키게 되면, 복수의 센서 또는 촬영수 단으로부터 인식된 또는 촬영된 이미지를 입력데이터로 활용하여, 감정상태를 판별할 수 있게 된다. 이 때, 사용되는 머신 러닝 방식은 인공지능 분야에서 활용되고 있는 심층 신경망(DNN)을 사용하거나 합성곱신 경망(CNN) 또는 순환신경망(RNN) 방식을 사용할 수 있다. 특히 좀더 구체적으로는 이미지 분석에 뛰어난 CNN 모 델링 방식이 본 발명에 적합하다고 할 수 있다. 이러한 방식은 초기에는 학습된 모델의 정확도가 높지 않아 적용이 상대적으로 어려울 수 있고, 상술했던 첫번 째 방식에 비해 컴퓨팅 파워가 많이 필요로 하는 단점이 있다. 반면, 이러한 방식은 이미지 세트가 계속 확보되 고 트레이닝 수가 늘어날수록 점차 정확도가 높아지며, 새로운 이미지나 형태에 대해서도 사용자나 작업자가 정 의할 필요 없이 적응적으로 적용될 수 있다는 장점을 갖는다. 또한 학습을 시키는 서버를 한정하지 않고 다양한 곳에서 학습 가능하다는 장점이 있다. 이상의 설명에서는 본 발명의 다양한 실시예들을 제시하여 설명하였으나 본 발명이 반드시 이에 한정되는 것은"}
{"patent_id": "10-2018-0153820", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "아니며, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자라면 본 발명의 기술적 사상을 벗어나지 않는 범 위 내에서 여러 가지 치환, 변형 및 변경이 가능함을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2018-0153820", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 감성봇 장치의 구성을 나타낸 도면. 도 2는 본 발명의 일 실시예에 따른 반려동물 감성봇 장치를 이용한 교감 방법을 나타낸 도면. 도 3은 본 발명의 다른 실시예에 따른 사용자 캐릭터 감성봇 장치를 이용한 교감 방법을 나타낸 도면. 도 4는 본 발명의 일 실시예에 따른 감성봇 장치의 작동모습을 나타낸 도면. 도 5는 본 발명의 일 실시예에 따른 센서부의 작동모습을 나타낸 도면. 도 6은 본 발명의 일 실시예에 따른 대화 단계 조절 모습을 나타낸 도면."}
