{"patent_id": "10-2017-0104313", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0092797", "출원번호": "10-2017-0104313", "발명의 명칭": "의료 영상에 기반하여 상태를 진단하는 장치 및 방법", "출원인": "연세대학교 산학협력단", "발명자": "이영한"}}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "의료영상을 진단하는 방법에 있어서, 의료 영상에서 진단부위를 추출하기 위한 의료 학습모델들을 구비하며, 상기 의료 영상을 입력하는 단계;입력된 상기 의료 영상 및 상기 의료 학습 모델에 기반하는 딥러닝 알고리즘을 수행하여 상기 의료 영상에서 진단 부위 영역을 추출하는 단계;추출된 상기 진단부위 영역에서 설정된 위치의 간격을 측정하는 단계; 및측정된 상기 진단부위 간격을 설정된 기준값과 비교 분석하여 상기 의료 영상 진단 결과를 생성 및 표시하는 단계를 포함하는 방법."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 의료 영상을 진단할 때 입력되는 의료 영상에서 진단 영역을 추출할 수 있는 상기 의료 학습 모델을 생성하는 단계를 더 포함하며,상기 의료 학습 모델을 생성하는 단계는,의료 영상을 입력하는 단계;의사에 의해 상기 의료 영상에 표시된 진단 부위 영상을 입력하는 단계;상기 의료 영상 및 진단부위 영상에 기반하는 딥러닝 알고리즘을 수행하여 상기 의료 학습 모델을 생성하는 단계를 포함하는 의료영상 학습 단계를 포함하는 방법."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서상기 진단 부위 영역을 추출하는 단계는상기 딥러닝 알고리즘의 수행 결과에 기반하여 의료 영상에서 진단 영역을 추출하는 단계; 및상기 추출된 진단영역에서 경계선들을 추출하고, 경계선들 중에서 진단할 방향의 경계선들을 선택하여 제1 및제2 진단라인을 추출하는 단계를 포함하는 방법.상기 진단부위 간격을 측정하는 단계는상기 제1 진단라인과 제2 진단라인의 간격을 측정하는 것을 포함하는 방법."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "의료 영상 진단 장치에 있어서,의료 영상에서 진단부위를 추출하기 위한 의료 학습모델을 구비하며, 입력되는 상기 의료 영상 및 상기 의료 학습 모델에 기반하는 딥러닝 알고리즘을 수행하여 상기 의료 영상에서 진단 부위를 추출하는 진단부위 추출부;추출된 상기 진단부위 영역의 설정된 진단 위치에서 상기 진단부위의 간격을 측정하는 측정부; 및 공개특허 10-2018-0092797-3-측정된 상기 진단부위 간격을 설정된 기준값들과 비교 분석하여 의료 영상의 병리 진단 결과를 생성하여 출력하는 진단부를 포함하는 장치."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 학습 모듈을 더 포함하며,상기 학습모듈은 의료 영상을 입력하고, 의사에 의해 상기 의료 영상에 표시된 진단 부위 영상을 입력하며, 상기 의료 영상 및 진단부위 영상에 기반하는 딥러닝 알고리즘을 수행하여 상기 의료 학습 모델을 생성하는 것을 포함하며, 상기 의료 학습 모델은 의료 영상을 진단할 때 입력되는 의료 영상에서 상기 진단 부위를 추출할 수 있는 것을특징으로 하는 장치."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 진단부위 추출부는상기 딥러닝 알고리즘의 수행 결과에 기반하여 의료 영상에서 진단 영역을 추출하는 진단영역 추출부; 및, 상기 추출된 진단영역에서 경계선들을 추출하고, 경계선들 중에서 제1 및 제2 진단라인을 추출하는 진단라인 추출부를 포함하며,상기 측정부는상기 제1 진단라인과 제2 진단라인의 간격을 측정하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "경추 영상을 진단하는 방법에 있어서, 경추 영상에서 경추 연조직(prevertebral stripe) 영역을 추출하기 위한 의료 학습 모델들을 구비하며, 상기 경추 영상을 입력하는 단계;입력된 상기 경추 영상 및 상기 의료 학습 모델에 기반하는 딥러닝 알고리즘을 수행하여 상기 의료 영상에서 경추 연조직 영역을 추출하는 단계;추출된 상기 경추 연조직 영역에서 설정된 위치의 경추 연조직의 간격을 측정하는 단계; 및측정된 상기 경추 연조직 간격을 설정된 기준값들과 비교 분석하여 의료 영상의 경추 연조직 진단 결과를 생성하여 표시하는 단계를 포함하는 방법."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 경추 영상을 진단할 때 입력되는 경추 영상에서 상기 경추 연조직 영역을 추출할 수 있는 상기 의료 학습모델을 생성하는 단계를 더 포함하며,공개특허 10-2018-0092797-4-상기 의료 학습 모델을 생성하는 단계는,상기 경추 영상을 입력하는 단계;의사에 의해 상기 의료 영상에 표시되는 제1 진단라인(prevertebral line) 및 제2 진단라인(anteriorvertebral line) 영상을 입력하는 단계;상기 제1 진단라인 및 제2 진단라인에 기반하여 진단영역을 생성하는 단계; 및상기 의료 영상 및 진단영역에 기반하는 딥러닝 알고리즘을 수행하여 상기 의료 학습 모델을 생성하는 단계를포함하는 의료영상 학습 단계를 포함하는 방법."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 경추 연조직 영역을 추출하는 단계는상기 딥러닝 알고리즘의 수행 결과에 기반하여 의료 영상에서 상기 진단 영역을 추출하는 단계; 및상기 추출된 진단영역에서 상기 제1 및 제2 진단라인을 추출하는 단계를 포함하는 방법."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 경추 연조직의 간격을 측정하는 단계는상기 제1 및/또는 제2 진단라인의 기울기를 측정하는 단계;측정된 상기 기울기에 기반하여 상기 제1 및 제2 진단라인의 중요 측정 위치를 결정하는 단계; 및상기 결정된 위치에서 상기 제1 진단라인과 제2 진단라인의 사이의 간격을 측정하는 단계를 포함하는 방법."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서상기 중요 측정 위치는 상기 경추의 C2-C3 및/또는 C6-C7 위치의 경추 연조직인 것을 특징으로 하는 장치."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서상기 경추 연조직 진단 결과를 생성하여 표시하는 단계는상기 제1 진단라인과 제2 진단라인의 간격과 기준값을 비교 분석하여 비정상 확률을 진단하는 단계;상기 경추 영상에 상기 제1 및 제2 진단라인을 오버레이하여 표시하며, 상기 제1 및/또는 제2 진단라인의 간격및 비정상 확률을 표시하는 단계를 포함하는 방법."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "경추 영상 진단 장치에 있어서, 상기 경추 영상에서 경추 연조직(prevertebral stripe) 영역을 추출하기 위한 의료 학습 모델들을 구비하며, 입력된 상기 경추 영상 및 상기 의료 학습 모델에 기반하는 딥러닝 알고리즘을 수행하여 상기 의료 영상에서 경공개특허 10-2018-0092797-5-추 연조직 영역을 추출하는 경추 연조직 영역 추출부;추출된 상기 경추 연조직 영역에서 설정된 위치의 경추 연조직의 간격을 측정하는 측정부; 및 측정된 상기 경추 연조직 간격을 설정된 기준값들과 비교 분석하여 의료 영상의 경추 연조직 진단 결과를 생성하여 출력하는 진단부를 포함하는 장치."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,학습 모듈을 더 구비하며,상기 학습 모듈은 상기 경추 영상을 입력하며, 의사에 의해 상기 의료 영상에 표시되는 제1 진단라인(prevertebral line) 및 제2 진단라인(anteriorvertebral line) 영상을 입력하며, 상기 제1 진단라인 및 제2 진단라인 영상에 기반하는 진단영역을 생성하며, 상기 의료 영상 및 진단영역에 기반하는 딥러닝 알고리즘을 수행하여 상기 의료 학습 모델을 생성하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 경추 연조직 추출부는상기 딥러닝 알고리즘의 수행 결과에 기반하여 의료 영상에서 상기 진단 영역을 추출하는 진단영역 추출부; 및상기 추출된 진단영역에서 상기 제1 및 제2 진단라인을 추출하는 진단라인 추출부를 포함하는 방법."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 측정부는상기 제1 및/또는 제2 진단라인의 기울기를 측정하는 기울기 측정부; 및측정된 상기 기울기에 기반하여 상기 제1 및 제2 진단라인의 중요 측정 위치를 결정하고, 상기 결정된 위치에서상기 제1 진단라인과 제2 진단라인의 사이의 간격을 측정하는 간격 측정부를 포함하는 장치."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서상기 중요 측정 위치는 상기 경추의 C2-C3 및/또는 C6-C7 위치의 경추 연조직인 것을 특징으로 하는 장치."}
{"patent_id": "10-2017-0104313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서상기 진단부는공개특허 10-2018-0092797-6-상기 제1 진단라인과 제2 진단라인의 간격과 기준값을 비교 분석하여 비정상 확률을 생성하며, 상기 경추 영상에 상기 제1 및 제2 진단라인을 오버레이하여 표시되고, 상기 제1 및 제2 진단라인의 간격 및 비정상 확률이 표시되도록 표시부에 출력하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2017-0104313", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 다양한 실시예들에 따른 경추 영상 진단 장치는, 상기 경추 영상에서 경추 연조직(prevertebral stripe) 영역을 추출하기 위한 의료 학습 모델들을 구비하며, 입력된 상기 경추 영상 및 상기 의료 학습 모델에 기반하는 딥러닝 알고리즘을 수행하여 상기 의료 영상에서 경추 연조직 영역을 추출하는 경추 연조직 영역 추출 부와, 추출된 상기 경추 연조직 영역에서 설정된 위치의 경추 연조직의 간격을 측정하는 측정부 및 측정된 상기 경추 연조직 간격을 설정된 기준값들과 비교 분석하여 의료 영상의 경추 연조직 진단 결과를 생성하여 출력하는 진단부를 포함할 수 있다."}
{"patent_id": "10-2017-0104313", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 의료 영상을 분석하여 환자의 상태를 진단할 수 있는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2017-0104313", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 알고리즘들은 의료 분야에 있어서도 활발하게 적용되고 있다. 향후 사물인터넷(Internet of Things: loT) 기반 생체 정보의 수집이 보편화되면 일상 생활에서 건강 상태를 모니터링하고 이상 유무를 확인하는데 인 공지능 알고리즘들이 다양하게 적용될 것으로 예상된다. 또한, 실제 의료 현장에서는 국내외 영상의학 및 방사 선 의학과를 중심으로 의료 영상에서 인공지능 알고리즘들을 활용하려는 움직임이 있다. 방사선 단순촬영(Radiography or X-ray), 초음파(ultrasonography), 컴퓨터단층촬영(Computed Tomography: CT), 자기공명영상(Magnetic Resonance Imaging: MRI), 양전자단층촬영(Positron Emission Tomography: PET) 등 다양한 의료 진단 기기로부터 획득된 의료 영상을 의사가 판독함으로써 과거에 비해 질병의 조기 진단 및 치 료가 가능해지고, 그 결과 인간 수명 연장이 실현되고 있다. 그러나 다양한 진단 기기를 이용하는 환자 수의 증 가에 비해 의료진 수의 부족, 인간의 부정확한 판독 및 의사 간 혹은 동일 의사 내에서의 판독 편차 등으로 인 한 오진의 가능성도 문제로 대두되고 있다. 따라서, 의료 영상에서는 인공지능 알고리즘 기반 진단 시스템을 도 입함으로써 이러한 문제점들을 보완하고자 하는 다양한 시도가 나타나고 있다. 즉, 의사에 의한 의료 영상의 판 독에 더해 인공 지능을 이용한 진단 소견을 보완함(second-opinion 또는 double-reading으로 활용)으로써 보다 정확한 진단을 목적으로 하는 연구 등이 활발히 진행되고 있다."}
{"patent_id": "10-2017-0104313", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "다양한 실시예들은 의료 영상 진단 장치에서 획득된 의료 영상에서 설정된 진단 부위의 상태(medical condition)를 인식하여 이상 여부를 진단할 수 있는 장치 및 방법을 제공할 수 있다. 다양한 실시예들은 의료 영상 진단 장치에서 의료 영상 및 의료 영상의 진단 영역을 딥러닝에 기반하여 학습하 여 입력되는 의료 영상에서 진단할 부위를 자동으로 설정할 수 있는 장치 및 방법을 제공할 수 있다. 다양한 실시예들은 의료 영상 진단 장치에서 입력되는 의료 영상을 학습된 딥러닝 결과를 적용하여 진단 부위를 자동으로 설정하고, 설정된 진단 부위의 상태를 분석하여 의료 영상의 상태를 진단할 수 있는 장치 및 방법을 제공할 수 있다. 다양한 실시예들은 의료 영상 진단 장치가 학습 모듈 및 진단모듈을 포함하고, 학습 모듈은 의료 영상에 적어도 2개의 진단라인들을 표시하고, 진단 라인들에 기반하여 진단 영역을 설정하며, 의료 영상 및 해당하는 진단영역 을 딥러닝 알고리즘에 의해 학습하여 딥러닝 학습 모델들을 생성하며, 진단 모듈은 입력되는 의료 영상에 학습 된 딥러닝 학습 모델을 적용하여 의료 영상에서 진단 영역을 추출하고, 추출된 진단 영역으로 진단 라인을 생성 한 후 진단 라인 사이의 간격을 측정하여 의료 영상의 상태를 진단할 수 있는 장치 및 방법을 제공할 수 있다. 다양한 실시예들은 의료 영상 진단 장치에서 외상 환자의 경추 의료 영상(C spine lateral view)에서 경추 연조 직(prevertebral soft tissue)의 두께 판독하기 위한 딥러닝 학습 모델을 구비하며, 경추 의료 영상이 입력되면 학습된 딥러닝 학습 모델을 적용하여 경추 의료 영상에서 진단 부위를 자동으로 설정하고, 설정된 진단 부위의 상태를 판독하여 경추 연조직의 상태를 진단할 수 있는 장치 및 방법을 제공할 수 있다. 다양한 실시예들은, 의료 영상 진단 장치에서 외상 환자의 경추 의료 영상(C spine lateral view)에서 경추 연 조직(prevertebral soft tissue)의 두께 판독하기 위한 딥러닝 학습 모델을 구비하며, 경추 의료 영상이 입력되 면 학습된 딥러닝 학습 모델을 적용하여 경추 의료 영상에서 진단 부위를 자동으로 설정하고, 설정된 진단 부위의 상태를 판독하여 경추 연조직의 상태를 진단할 수 있는 컴퓨터 판독 가능한 기록매체를 제공할 수 있다."}
{"patent_id": "10-2017-0104313", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "다양한 실시예들에 따른 의료영상을 진단하는 방법은, 의료 영상에서 진단부위를 추출하기 위한 의료 학습모델 들을 구비하며, 상기 의료 영상을 입력하는 단계와, 입력된 상기 의료 영상 및 상기 의료 학습 모델에 기반하는 딥러닝 알고리즘을 수행하여 상기 의료 영상에서 진단 부위 영역을 추출하는 단계와, 추출된 상기 진단부위 영 역에서 설정된 위치의 간격을 측정하는 단계 및 측정된 상기 진단부위 간격을 설정된 기준값과 비교 분석하여 상기 의료 영상의 병리 진단 결과를 생성 및 표시하는 단계를 포함할 수 있다. 다양한 실시예들에 따른 의료 영상 진단 장치는, 의료 영상에서 진단부위를 추출하기 위한 의료 학습모델을 구 비하며, 입력되는 상기 의료 영상 및 상기 의료 학습 모델에 기반하는 딥러닝 알고리즘을 수행하여 상기 의료 영상에서 진단 부위를 추출하는 진단부위 추출부와, 추출된 상기 진단부위 영역의 설정된 진단 위치에서 상기 진단부위의 간격을 측정하는 측정부 및 측정된 상기 진단부위 간격을 설정된 기준값들과 비교 분석하여 의료 영 상의 병리 진단 결과를 생성하여 출력하는 진단부를 포함할수 있다. 다양한 실시예들에 따른 경추 영상을 진단하는 방법은, 경추 영상에서 경추 연조직(prevertebral stripe) 영역 을 추출하기 위한 의료 학습 모델들을 구비하며, 상기 경추 영상을 입력하는 단계와, 입력된 상기 경추 영상 및 상기 의료 학습 모델에 기반하는 딥러닝 알고리즘을 수행하여 상기 의료 영상에서 경추 연조직 영역을 추출하는 단계와, 추출된 상기 경추 연조직 영역에서 설정된 위치의 경추 연조직의 간격을 측정하는 단계 및 측정된 상기 경추 연조직 간격을 설정된 기준값들과 비교 분석하여 의료 영상의 경추 연조직 진단 결과를 생성하여 표시하는 단계를 포함할 수 있다. 다양한 실시예들에 따른 경추 영상 진단 장치는, 상기 경추 영상에서 경추 연조직(prevertebral stripe) 영역을 추출하기 위한 의료 학습 모델들을 구비하며, 입력된 상기 경추 영상 및 상기 의료 학습 모델에 기반하는 딥러 닝 알고리즘을 수행하여 상기 의료 영상에서 경추 연조직 영역을 추출하는 경추 연조직 영역 추출부와, 추출된 상기 경추 연조직 영역에서 설정된 위치의 경추 연조직의 간격을 측정하는 측정부와, 측정된 상기 경추 연조직 간격을 설정된 기준값들과 비교 분석하여 의료 영상의 경추 연조직 진단 결과를 생성하여 출력하는 진단부를 포 함할 수 있다."}
{"patent_id": "10-2017-0104313", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 본 발명의 합성곱 신경망 딥 러닝 기반 경추 연조직의 측정 방법은 외상 환자의 C spine lateral view에서 경추 연조직 영역(prvertebral soft tissue, prvertebral stripe)의 두께 판독시 의사에 의 한 의료 영상의 판독에 더해 인공 지능을 이용하여 의산의 진단 소견을 보완할 수 있다. 딥 러닝 알고리즘에 기반하여 의료 영상의 경추 연조직 영역을 추출하고, 추출된 경추 연조직 영역(prvertebral soft tissue, prvertebral stripe)의 의 간격을 측정할 수 있다. 딥 러닝 기반 경추 연조직의 측정 방법은 외 상 환자의 C spine lateral view에서 경추 연조직의 두께 판독시 의사에 의한 의료 영상의 판독에 더해 인공 지 능을 이용하여 진단 소견을 보완할 수 있다."}
{"patent_id": "10-2017-0104313", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 상세한 설명에 앞서, 이하에서 설명되는 본 명세서 및 청구범위에 사용된 용어나 단어는 통상적이거 나 사전적인 의미로 한정해서 해석되어서는 아니 되며, 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명 하기 위해 용어의 개념으로 적절하게 정의할 수 있다는 원칙에 입각하여 본 발명의 기술적 사상에 부합하는 의 미와 개념으로 해석되어야만 한다. 따라서 본 명세서에 기재된 실시예와 도면에 도시된 구성은 본 발명의 가장 바람직한 실시예에 불과할 뿐, 본 발명의 기술적 사상을 모두 대변하는 것은 아니므로, 본 출원시점에 있어서 이들을 대체할 수 있는 다양한 균등물과 변형 예들이 있을 수 있음을 이해하여야 한다. 이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예들을 상세히 설명한다. 이때, 첨부된 도면에서 동일한 구성 요소는 가능한 동일한 부호로 나타내고 있음을 유의해야 한다. 또한, 본 발명의 요지를 흐리게 할 수 있는 공지 기능 및 구성에 대한 상세한 설명은 생략할 것이다. 마찬가지의 이유로 첨부 도면에 있어서 일부 구성요소 는 과장되거나 생략되거나 또는 개략적으로 도시되었으며, 각 구성요소의 크기는 실제 크기를 전적으로 반영하 는 것이 아니다. 도 1은 다양한 실시예들에 따른 병원 정보 시스템(HIS, hospital information system)의 구성을 도시하는 도면 이다. 도 1을 참조하면, 병원 정보 시스템은 진료 장치, 진료 지원 장치, 관리 장치, 의료 정보 장치를 포함할 수 있다. 병원 정보 시스템은 인터넷 망을 통해 외부 장치와 연결될 수 있 다. 병원 정보 시스템은 처방 진단 시스템(OCS, (order communication system) 및 의료 정보 장치를 포함 할 수 있다. 처방 진단 시스템은 진단장치, 진료 지원 장치, 관리 장치를 포함할 수 있다. 처방 진단 시스템(OCS는 환자에게 발생하는 처방을 중심으로 진료 장치, 진료 지원 장치 및 관리 장 치들 간에 정보 전달을 전산화한 시스템을 의미할 수 있다. 병원 정보 시스템 내의 각 장치(진료, 진료 지 원, 관리)들은 환자의 처방에 관련된 정보들을 처방 진단 시스템을 통해 해당하는 장치들에 전송할 수 있다. 처방 진단 시스템은 EMR(electronic medical record) 기능을 제공할 수 있다. EMR은 환자의 정보기록에 이용하 던 종이 차트 대신 컴퓨터를 이용하여 컴퓨터에 직접 환자의 정보를 기록(paperless, chartless system)할 수 있다. 진료 장치는 외래 처방, 병동 처방, 병동 간호, 수술실에 관련된 업무를 처리하는 장치가 될 수 있다. 진 료 장치의 진료과는 외과계((general surgery, neuro surgery, chest surgery, orthopedic surgery, plastic surgery 등), 내과계(internal medicine; pulmonology, gastroenterology, endocrinology, rheumatology, hematology, oncology, nephrology, infectious diseases, allergy and clinical Immunology 등), 산부인과(obstetrics and gynecology), 이비인후과(ear, nose, throat), 안과(ophthalmology, eye), 피부 과(dermatology), 비뇨기과(urology), 소아청소년과(pediatrics), 치과(dentistry), 신경과 (neurology), 정신 건강의학과(psychiatry), 정신의학과(psychology), 마취과(anesthetics), 진단검사의학과(clinical pathology), 영상의학과(radiology), 방사선종양학과(radiation oncology) 등이 있다. 진료 지원 장치는 각종 검사실, 진단 방사선/핵의학, 약국, 영양/급식 등을 처리하는 장치가 될 수 있다. 진료 지원 장치는 검체 검사, 기능 검사 및 환자의 의료 영상 획득 등의 기능을 수행할 수 있다. 진료 지 원 장치에서 획득할 수 있는 의료 영상은 X-선, 감마선, 초음파, 자기장 등을 이용하여 획득할 수 있다. 먼저 인체를 통과하는 X-선 이용하는 방법은, X-ray(X선영상 기술, radiography)을 이용하여 인체의 각 부위 조직의 투과된 X선의 감쇄 특성을 이용하여 평면형광판이나 필름에 생체 내부 구조를 영상화하는 방법 및 CT(전산 화 단층 촬영 기술, Computed Tomography)을 이용하여 인체의 단면 주위를 돌면서 X-선을 투사하고 X-선이 인체 를 통과하면서 감소되는 양을 측정하여 내부 구조를 영상화하는 방법을 포함할 수 있다. 두 번째로 인체 내에 주입된 감마선을 이용 하는 방법은 PET(양전자 방출 단층 촬영기술, Positron Emission Tomography) 방법이 될 수 있다. 세 번째로 인체 내에서 반사된 초음파 이용하는 방법은 Ultrasound(초음파영상 진단 기술)를 이용하여 송신된 초음파에 대해 생체 조직에서 반사된 초음파를 수신하여 반사되어온 초음파를 증폭, 검출하여 모니터에 영상화하는 방법이 될 수 있다. 네 번째로 인체 내 주입된 자기장 이용하는 방법은 MRI(자기공명영상 진단 기술, Magnetic Resonance Imaging)를 이용하여 자력에 의하여 발생하는 자기장을 이용하여 생체 임의의 단층 영상을 획득할 수 있는 방법이 될 수 있다. 예를들면, 진료 지원 장치의 의료 영상은 X-ray, MRI(magnetic resonance imaging), fMRI, MRI/DTI(diffusion tensor imaging), CT(computed tomography), SPECT(single- photon emission computed tomography), PET(positron emission tomography), MEG(magnetoencephalography), EEG(electroencephalography), EIT(extreme ultraviolet imaging telescope) 또는 이들의 조합으로 후처리 (image post-processing) 혹은 영상 정합(fusion image)에 의해 획득될 수 있다. 관리 장치는 외래 원무, 입원 원무, 응급실 원무 등을 처리하는 장치가 될 수 있다. 의료 정보 장치는 진료 장치, 진료 지원 장치 및 관리 장치에서 생성 또는 획득되는 의료 정보들 및/또는 의료 영상들을 저장할 수 있으며, 진료 장치 등에 의해 저장된 의료 정보 및/또는 의료 영 상들이 조회될 수 있다. 의료 정보 장치는 의료 영상을 처리하는 의학 영상 정보 시스템((PACS; Picture Archiving and Communication System) 및 의료 정보를 처리하는 의료 정보 시스템(예를들면, RIS(Radiological Information System), LIS(Laboratory Information System) 등) 등을 포함할 수 있다. PACS는 진단 지원 장치 에서 획득되는 의료 영상을 네트워크(예를들면, DICOM(digital Imaging and communication in medicine) 네트워크)를 통해 수신하여 저장하고, 진료 장치의 진료과의 임상 의사가 네트워크를 통해 조회하여 해당 환자를 진료할 수 있는 포괄적인 디지털 이미지관리 및 전송시스템이 될 수 있다. PACS는 진료 지원 장치 의 다양한 검사(촬영)장치들로부터 획득된 의료 영상들을 등록된 의료 정보(예를들면, 환자 정보 및 검사 정 보)와 정합시킬 수 있다. 예를들면, 의료 정보는 RIS에 저장될 수 있다. 이런 경우, PACS는 RIS로부터 관련정보 를 가져올 수 있으며, 바람직하기는 진료 지원 장치의 의료 영상 획득 장치에서 환자정보를 입력시킬 당시 에 RIS의 정보를 이용할 수도 있다. 관리장치, 진료 장치, 진료 지원 장치 및/또는 의료 정보 장치는 네트워크로 연결될 수 있 다. 네트워크는 컴퓨터 네트워크(computer network)(예: LAN 또는 WAN)가 될 수 있다. 예를들면, 진료 장치 및 진료 지원 장치와 의료 정보 장치는 네트워크를 통해 DICOM(digital Imaging and communication in medicine) 프로토콜 방식으로 의료 정보 및 의료 영상을 통신할 수 있다. DICOM 프로토콜은 의료영상의 표준적 처리를 위해 국제적으로 공인된 프로토콜로서, 병원에서 의료 영상과 정보들을 전송하는 표 준 프로토콜로 PACS의 프로토콜로 사용될 수 있다. 병원에 사용하는 영상 검사 및 진료 장비들은 서로 다른 기 종의 영상 진단 장비이며, 이로인해 이종 장치들 간에 서로 데이터를 교환하고 전송하기 위한 표준안으로 DICOM 프로토콜을 사용할 수 있다. 또한 병원 정보 시스템은 네트워크를 통해 다른 장치들과 연결되어 의료 정보 및 영상들을 통신 할 수 있다. 네트워크는 통신 네트워크(telecommunications network), 예를 들면, 컴퓨터 네트워크(computer network)(예: LAN 또는 WAN), 인터넷, 또는 전화 네트워크(telephone network) 중 적어도 하나를 포함할 수 있 다. 다른 장치는 산하 의료 기관, 타 의료 기관, 의료 보헙 업체, 은행 등이 될 수 있다. 예를들면, 진료 장치는 인터넷 망을 통해 타 의료기관에 진료 회송 또는 이송을 할 수 있으며, 검사 의뢰 등을 할 수 있다. 도 1과 같은 병원 정보 시스템에서, 환자가 병원에 내원하여 진료를 받는 경우, 먼저 관리 장치에서 외래 원무 기능을 수행하고, 진료 장치에서 1차 진료 기능이 수행될 수 있다. 이때 의료 영상이 필요한 경우, 진료 장치의 해당하는 의료 영상의 촬영 처방을 발생할 수 있으며, 진료 지원 장치는 촬영 처방에 대 응되는 의료 영상을 촬영하여 의료 정보 장치에 저장할 수 있다. 그러면 진료 장치는 의료 정보 장치 에 저장된 의료 영상에 기반하여 환자를 진료할 수 있다. 도 2는 다양한 실시예들에 따른 병원 시스템의 의료 영상 진단 장치의 구성을 도시하는 도면이다. 도 2를 참조하면, 의료 영상 진단 장치는 프로세서, 저장부, 통신부, 입력부 및 표시부 을 포함할 수 있다. 의료 영상 진단 장치는 도 1의 진료장치 또는 진료 지원장치이 될 수 있다.의료 진단 장치는 전자장치가 될 수 있다. 전자 장치는 스마트폰(smartphone), 태블릿 PC(tablet personal computer), 데스크탑 PC(desktop personal computer), 랩탑 PC(laptop personal computer), 넷북 컴 퓨터(netbook computer), 워크테이션(workstation), 서버, PDA(personal digital assistant), PMP(portable multimedia player), 또는 웨어러블 디바이스(wearable device) 중 적어도 하나를 포함할 수 있다. 통신부는 네트워크(예를들면 도 1의 네트워크)을 통해 병원 시스템의 다른 장치(예를들면, 도 1의 의 료 영상 정보장치) 및/또는 다른 장치(예를들면 도 1의 외부장치)로부터 의료 영상을 수신할 수 있다. 의료 영상은 DICOM 프로토콜 방식의 이미지일 수 있다. 통신부는 무선 통신 모듈 및/또는 유선 통신 모듈을 포함할 수 있으며, 무선 통신 모듈은 셀룰러 통신 모듈 및/또는 근거리 통신 모듈을 포함할 수 있다. . 근거리 통신 모듈은 WiFi(wireless fidelity), 블루투스, 블루투스 저전력(BLE), 지그비(Zigbee), NFC(near field communication), 자력 시큐어 트랜스미션(Magnetic Secure Transmission), 라디오 프리퀀시(RF), 또는 보디 에어리어 네트워크(BAN) 중 적어도 하나를 포함할 수 있다. 공중 통신 모듈은 LTE(long term evolution), LTE-A(LTE Advance), CDMA(code division multiple access), WCDMA(wideband CDMA), UMTS(universal mobile telecommunications system), 또는 GSM(Global System for Mobile Communications) 등 중 적어도 하나를 사용 하는 셀룰러 통신을 포함할 수 있다. 유선 통신 모듈은, 예를 들면, USB(universal serial bus), HDMI(high definition multimedia interface), RS-232(recommended standard 232), 또는 POTS(plain old telephone service) 등 중 적어도 하나를 포함할 수 있다. 입력부는 사용자에 의해 발생되는 입력신호들을 수신할 수 있다. 입력부는 데이터 또는 의료 진단 장 치의 동작을 제어하기 위한 커맨드 등을 입력할 수 있다. 다양한 실시예들에 따른 입력부는 학습 중에 사 용자(예를들면 의사)에 의해 의료 영상 위에 입력되는 진단 라인들을 감지하여 입력신호로 생성할 수 있다. 표시부는 액정 디스플레이(LCD, liquid crystal display), 발광 다이오드(LED, light emitting diode) 디 스플레이, 유기 발광 다이오드(OLED, organic light emitting diode) 디스플레이, 또는 전자종이(electronic paper) 디스플레이를 포함할 수 있다. 표시부는 사용자에게 각종 콘텐츠(예: 텍스트, 이미지, 비디오, 아 이콘, 및/또는 심볼 등)을 표시할 수 있다. 다양한 실시예들에 따른 표시부는 의료 영상, 학습 및 진단 과 정에서 수행되는 진단라인 및 진단 영역 등을 표시할 수 있다. 다양한 실시예들에 따른 입력부 및 표시부는 터치 스크린(touch-screen)으로 구성될 수 있다. 이런 경우 입력부는 터치 센서들을 포함할 수 있다. 터치스크린은 예를 들면, 전자 펜 또는 사용자의 신체의 일 부를 이용한 터치, 제스쳐, 근접, 또는 호버링 입력을 수신할 수 있다. 예를들면, 터치스크린은 표시부에 표시되는 의료 영상 위에 펜으로 터치 입력되는 입력들을 감지하여 진단라인의 신호들로 생성할 수 있다. 프로세서은 중앙처리장치(CPU, central processing unit), 어플리케이션 프로세서(AP, application processor), 또는 커뮤니케이션 프로세서(CP, communication processor(CP)) 중 적어도 하나를 포함할 수 있다. 프로세서는, 의료 영상 진단 장치의 적어도 하나의 다른 구성요소들의 제어 및/또는 통신에 관한 연 산이나 데이터 처리를 실행할 수 있다. 메모리는 휘발성 및/또는 비휘발성 메모리를 포함할 수 있다. 메모리는, 의료 영상 진단 장치의 적어도 하나의 다른 구성요소에 관계된 명령 또는 데이터를 저장할 수 있다. 다양한 실시예에 따른 메모리(21 0)은 소프트웨어 및/또는 프로그램을 저장할 수 있다. 다양한 실시예에들에 따른 프로세서는 학습 모듈 및 진단 모듈을 포함할 수 있다. 학습 모듈은 진단 모듈에서 의료 영상을 진단할 때 의료 영상의 진단 영역이 자동으로 설정되도록 의료 영상을 학습하는 기능을 수행할 수 있다. 학습 모듈은 통신부을 통해 의료 영상과 입력부을 통해 진단 라인 정보들을 입력할 수 있다. 의료 영상은 의료 영상 정보장치에 전송되는 의료 영상이 될 수 있다. 진단라인 정보들은 의사가 표시부 에 표시되는 의료 영상에서 의료 상태를 진단하기 위한 부위를 표시하는 정보가 될 수 있다. 예를들면, 의 사는 표시부에 표시되는 의료 영상에서 진단 부위를 설정하기 위해 적어도 2개의 진단 라인을 표시(예를들 면 펜으로 표시부 상에서 라인을 그어 진단 위치를 설정)할 수 있다. 학습모듈은 의료 이미지 및 적어도 두개의 진단라인들을 입력하고, 진단라인들 사이에 화소를 채워 진단영역으로 변환할 수 있다. 이후 학습 모듈은 의료 이미지 및 진단영역을 딥러닝 알고리듬에 기반하여 학습하여 의료 이미지에서 진단영역을 추출하기 위한 딥러닝 학습 모델을 생성하여 메모리에 저장할 수 있다. 딥러닝 알고리즘은 합성 신경망 알고리즘(CNN, convolutional neural network algorithm)이 될 수 있다. 진단 모듈은 진단할 의료 영상이 통신부을 통해 입력되면, 학습된 딥러닝 학습 모델에 기반하여 의료 영상 을 딥러닝 알고리즘에 적용할 수 있다. 딥러닝 알고리즘을 수행하면, 의료 영상에서 진단 영역을 추출할 수 있 으며, 추출된 진단 영역에서 적어도 두개의 진단라인들을 추출할 수 있다. 이후 진단 모듈은 추출된 적어도 두 개의 진단라인들 사이의 간격을 측정하고, 측정된 거리 정보를 설정된 기준값과 비교하여 진단 결과 정보를 생 성할 수 있다. 또한 진단 모듈은 추출된 진단라인들을 의료 영상에 오버레이시켜 표시부에 표시할 수 있으 며, 진단 결과 정보도 표시부에 함께 표시할 수 있다. 도 3은 다양한 실시예들에 따른 의료 진단 장치의 학습 모듈 구조를 도시하는 도면이다. 도 3을 참조하면, 의료 영상은 특정 위치에 진단 부위를 포함하는 영상이 될 수 있다. 예를들면, 사람의 뼈는 피부로 감싸져 있으며, 특정 뼈에 인접되는 피부는 일정한 두께를 가질 수 있다. 예를들면, 경추(cervical vertebral)의 앞에 위치되는 경추 연조직(prevertebral soft tissue, prevertebral stripe)는 정상 경우 일정 두께를 가질 수 있다. 그러나 경추 또는 경추 연조직 영역에 이상이 발생되면 경추 연조직의 두께가 변경될 수 있다. 따라서 특정 뼈에 인접되는 피부 영역을 진단 부위로 설정하고, 진단 부위의 변화를 측정하면 해당하는 뼈 또는 피부 조직의 이상 또는 정상 여부를 진단할 수 있다. 의료 영상은 진단하고자 뼈 및 해당하는 뼈 에 인접되는 피부의 진단부위 영역을 포함하는 영상이 될 수 있다. 의사는 의료 영상에서 진단부위의 영역 을 설정할 수 있다. 진단 부위 영역의 시작 위치에 제1 진단라인을 표시하고, 진단부위 영역의 종료 위치에 제2 진단 라인을 표시하여 진단 영역을 설정할 수 있다. 의료 영상이 입력되면, 의사는 의료 영상에 진단 부위를 표시하기 위한 적어도 두 개의 진단라인들을 표시되는 진단 부위 영상을 생성할 수 있다. 예를들면, 의료 영상은 엑스레이 이미지가 될 수 있으며, 의사는 영상 의학과 및/또는 방사선과 의사가 될 수 있다. 의료 영상은 학습(training)에 사용할 이미지가 될 수 있으며, 진단 부위 영상은 의사가 의료 영상에 표시한 진단 라인들이 될 수 있다. 의 료 영상은 통신부(예를들면 도 2의 통신부)을 통해 수신되는 DICOM 의료 영상이 될 수 있으며, 의료 영상은 표시부(예를들면 도 2의 표시부)에 표시될 수 있다. 그리고 의사는 표시부에 표시되는 의료 영상에서 진단 부위 영역을 설정하기 위한 제1 진단라인 및 제2 진단라인을 표시할 수 있다. 제1 진단라인 은 진단 부위 영역의 시작 위치에 표시될 수 있으며, 제2 진단라인은 진단 부위 영역의 종료 위치에 표시될 수 있다. 의사가 제1 및 제2 진단라인을 설정하면, 입력부(예를들면 도 2의 입력부)는 의사에 의해 입력되는 제1 진단라인 및 제2 진단라인을 감지하여 프로세서(예를들면 도 2의 프로세서)에 전달할 수 있다. 프로세 서는 입력되는 제1 진단라인 및 제2 진단라인에 기반하여 의료 영상의 진단 영역을 생성할 수 있다. 진단 영역 변환부는 제1 진단라인과 제2 진단라인 사이에서 화소들을 채워넣어 면적으로 변환할 수 있다. 예를들면, 진단영역 변환부는 진단 라인들 사이에 수평 방향(X 축 방향)으로 화소(pixel)들을 채워 넣어 진단 영역을 생성할 수 있다. 진단영역을 생성한 후, 딥러닝 실행부는 의료 영상과 해당하는 의료 영상의 진단영역을 딥러닝 알고리즘으로 학습하여 딥러닝 학습 모델을 생성할 수 있다. 다양한 실시예들에 따르면 딥러닝 알고리즘은 합성 신경망(convolutional neural network, CNN) 알고리즘을 사용할 수 있다. 딥러닝 실행부에서 생성되는 딥 러닝 학습 모델(CNN 학습 모델)은 진단 모듈에서 입력되는 의료 영상에 진단 영역을 설정하는 동작을 수행할 수 있다. 딥러닝 학습모델(예를들면 CNN 학습 모델)은 의료 학습 모델이 될 수 있다. 다양한 실시예들에 따른 의료 학습 모델은 의료 영상 및 진단 부위 영역에 기반하여 생성되는 모델로서, 의료 영상을 진단할 때 입력되는 의 료 영상의 진단 부위 영역을 추출할 수 있는 의료 학습 모델이 될 수 있다. 도 4는 다양한 실시예들에 따른 의료 진단 장치의 진단 모듈 구조를 도시하는 도면이다. 도 4를 참조하면, 의료 영상은 통신부(도 2의 통신부)를 통해 수신되는 의료 영상이 될 수 있다. 의 료 진단 장치는 입력되는 의료 영상에서 진단부위 영역을 추출할 수 있다. 다양한 실시예들에 따르면, 진단부위 추출부는 입력되는 의료 영상에서 진단 영역을 추출하고, 추출된 진단영역에서 제1 및 제2 진단라인을 추출할 수 있다. 딥러닝 실행부는 의료 영상과 의료 학습 모델에 기반하여 의료 영상에서 진단 영역을 추출할 수 있다. 딥러닝 실행부는 진단영역 추출부의 기능을 수행할 수 있다. 딥러닝 실행부는 의료 영상 에서 진단 영역을 추출하기 위해 특화된 CNN 학습 모델이 될 수 있다. 의료 영상에서 진단 영역이 추출되 면, 진단라인 추출부는 진단 영역의 경계를 추출하여 진단라인들을 추출할 수 있다. 딥러닝 실행부 및 진단라인 추출부는 진단부위 추출부가 될 수 있다. 병리 진단부는 기울기 측정부, 간격 측정부 및 진단부을 포함할 수 있다. 기울기 측정부 는 진단 라인들의 기울기를 측정하고, 간격 측정부은 측정된 기울기에 기반하여 중요한 위치(병리 진단할 주요 위치)에서 진단 라인들 사이의 간격을 측정할 수 있다. 기울기 측정부 및 간격 측정부는 추출된 진단부위 영역의 설정된 진단 위치에서 진단부위의 간격을 측정하는 측정부가 될 수 있다. 진단부 는 측정된 진단 라인들 사이의 간격을 기준 값과 비교 분석하여 병리 진단 결과를 생성할 수 있다. 이때 병리 진단 결과는 측정된 주요 위치의 측정 결과 값 및 비정상 확률(또는 정상 확률) 값이 될 수 있다. 또한 진단라 인 추출부에서 진단라인들이 추출되면, 의료 영상에 진단 라인들을 오버레이하여 의료 영상에 진단 부위를 표시할 수 있다. 프로세서의 진단 모듈은 진단부에서 출력되는 병리 진단 결과 및 진단부위가 표시 되는 의료 영상을 표시부에 표시할 수 있다. 의료 영상은 경추 영상이 될 수 있다. 경추의 앞에 위치되는 경추 연조직(prevertebral soft tissue in cervical spine)은 일정 두께(간격)를 가질 수 있다. 외상 환자의 C spine lateral view에서 경추 연조직의 두 께를 판독할 때, 의사에 의한 의료 영상의 판독에 더해 인공 지능을 이용하여 진단 소견을 보완하거나 의사 판 독 이전에 미리 인지하여 고위험 영상으로 미리 분류할 수 있다. 예를들면, 응급실 의료 환경은 빠른 의학적 판 단이 요구되고 영상의학과 의사의 24시간 판독을 기대할 수 없는 의료 환경이 될 수 있다. 따라서 의료 영상을 촬영함과 동시에, 주의를 기울여야할 위험도 높은 상황을 미리 알려준다면 응급 진료의 수준을 한 단계 더 올릴 수 있어 국민건강향상에 이바지 할 수 있다. 도 5는 경추 구성(C spine lateral view)을 모식적으로 도시한 도면이다. 도 5를 참조하면, 경추는 C1-C7을 포함할 수 있으며, 경추 라인은 anterior vertebral line, posterior vertebral line, spino-lamina line, posterior spinous line을 포함할 수 있다. 그리고 anterior vertebral line의 앞에 prevertebral line이 있으며, prevertebral line과 anterior vertebral line 사이에 경추 연조직이 위치된다. 경추 연조직은 임상학적으로 의미가 크다. 경추 연조직은 정상인의 경우, 간격이 C2와 C3 사이의 영역의 두께는 7 mm 정도이며, C6과 C7 사이의 영역 두께는 21 mm 정도가 될 수 있다. 그리고 prevertebral space인 경추 연조직에 fluid (출혈, 농양 등)가 발생되면, 경추 연조직은 두꺼워질 수 있다. 합성곱 신경망 딥 러닝 기반 경추 연조직 의 측정 방법은 prevertebral line 및 anterior vertebral line을 인식하여 경추 연조직 (prevertebral soft tissue, prevertebral stripe)의 두께를 측정하여 진단하는 경우, 영상의학과 전문의에 의 한 측정과 97% 이상의 일치도를 보임을 확인할 수 있다. 이하의 설명에서 의료 영상은 경추 의료 영상(C spine lateral view)을 예로들어 설명될 것이다. 경추 의료 영 상에서 진단 영역은 경추 연조직(prevertebral stripe) 영역이 될 수 있으며, 제1 진단라인은 prevertebral line이 될 수 있으며, 제2 진단라인은 anterior vertebral line이 될 수 있다. 따라서 진단 영역은 제1 진단라 인과 제2 진단라인 사이에 위치되는 경추 연조직(prevertebral stripe) 영역이 될 수 있다. 의료 영상이 경추 영상인 경우, 진단 부위 추출부(예를들면, 딥러닝 실행부 및 진단라인 추출부는 경 추 연조직 추출부가 될 수 있다. 딥러닝 실행부는 경추 연조직 영역을 추출하며, 진단라인 추출부 는 경추 연조직에서 제1 진단라인 및 제2 진단라인을 추출할 수 있다. 또한 기울기 측정부는 제1 진단라인 및/또는 제2 진단라인의 기울기를 측정할 수 있으며, 간격 측정부는 중요 부위 위치(예를들면, C2-C3 및/또는 C6-C7)를 추출하여 제1 라인과 제2 라인의 간격을 측정 할 수 있다. 측정부는 기울기 측정부 및 간격 측정부을 포함할 수 있다. 도 6은 다양한 실시예들에 따른 의료 진단 동작을 도시하는 도면이다. 도 6을 참조하면, 의료 진단 장치는 의료 영상이 입력되면 의료 영상의 진단 부위를 자동으로 설정하여 진단 동 작을 수행할 수 있다. 이를 위하여, 다양한 실시예들에 따른 의료 영상 진단 장치는 의료 영상의 진단부위를 학 습하여 의료 학습 모델(예를들면 딥러닝 학습 모델)을 생성할 수 있다. 의료 학습 모델은 학습용 의료 영상 및 학습용 진단 부위 이미지에 기반하여 생성될 수 있다. 예를들면, 의사는 학습용 의료 영상에 진단 부위를 표시 하고, 의료 영상 진단 장치는 의료 영상 및 진단부위 영상을 학습하여 의료 영상의 진단부위를 설정하기 위한 의료 학습 모델을 생성할 수 있다. 의사에 의해 표시되는 진단부위 이미지는 라인으로 표시될 수 있으며, 또는 면적으로 표시될 수 있다. 다양한 실시예들에서, 의사는 의료 영상에 진단부위를 라인(이하 진단라인이라 칭함)으로 표시하고, 의료 영상 진단 장치는 진단라인에 기반하여 진단 영역을 생성하고, 의료 영상과 진단영역 영상에 기반하여 의료 학습 모 델을 학습하는 것으로 설명될 것이다. 그러나 의료 영상 진단 장치는 의료 영상과 진단라인 영상에 기반하여 의 료 학습 모델을 생성할 수도 있다.다양한 실시예들에서, 의료 영상은 통신부(예를들면 도 2의 통신부를 통해 입력될 수 있으며, 또는 입력부 (예를들면 도 2의 입력부의 스캐너)를 통해 입력될 수 있다. 다양한 실시예들에서 진단 부위 이미지는 입 력부를 통해 입력될 수 있으며, 또는 통신부를 통해 입력될 수 있다. 이하의 설명에서, 의료 영상 진단 장치는 통신부를 통해 의료 영상을 입력하고, 입력부를 통해 진단부위를 입력 하는 것을 예로들어 설명하기로 한다. 또한 진단부위 이미지는 진단라인이며, 의료 영상 진단 장치는 진단라인 영상에 기반하여 진단 영역을 설정하고, 의료 영상과 진단영역에 기반하여 의료 학습 모델을 생성하는 것으로 설명될 것이다. 611 단계에서 통신부를 통해 학습용 의료 영상이 입력되면, 의료 영상 진단 장치는 613단계에서 입력된 의료 영 상 이미지를 표시부(예를들면 도 2의 표시부)에 표시하고, 의사는 표시되는 의료 영상에 진단라인을 표시 할 수 있다. 예를들면, 의료 영상이 경추 영상이면, 의사에 의해 표시되는 진단라인은 prevertebral line(제1 진단라인, 도 5의 511) 및 anterior vertebral line(제2 진단라인, 도 5의 513)이 될 수 있다. 의료 영상 진단 장치는 613단계에서 입력부를 통해 의료 영상에 연관된 진단 부위 이미지를 수신할 수 있으며, 615단계에서 진 단라인 이미지에서 진단라인들 사이를 화소를 채워넣어 진단영역을 생성할 수 있다. 예를들면, 진단영역은 prevertebral line과 anterior vertebral line 사이의 경추 연조직(prevertebral stripe, 도 5의 550)이 될 수 있다. 의료 영상 진단 장치는 617단계에서 의료 영상과 진단 영역 영상에 대하여 딥러닝 알고리즘을 수행할 수 있으며, 619단계에서 딥러닝 학습 결과에 기반하는 의료 학습 모델을 생성할 수 있다. 딥러닝 알고리즘은 CNN 알고리즘이 될 수 있다. 의료 영상을 학습하는 과정에서, 의료 영상은 다양한 상태로 입력될 수 있으며, 진단부위 이미지는 입력되는 의 료 영상의 상태에 기반하여 그려질 수 있다. 예를들면, 의료 영상은 15도 좌측 방향으로 기울어질 수 있으며, 우측 방향으로 20도 기울어질 수 있으며, 180도 회전되어 입력될 수도 있다. 이런 경우, 의사는 입력되는 의료 영상의 상태에 따라 진단 라인들을 표시할 수 있으며, 의료 영상 진단 장치는 입력되는 의료영상의 상태에 기반 하여 의료 학습 모델을 생성할 수 있다. 따라서 의료 영상 진단 장치는 의료 영상의 입력 상태(예를들면, 회전, 기울어짐 등)에 대응되는 의료 학습 모델을 생성할 수 있다. 의료 영상 진단 장치는 생성된 의료 학습 모델에 기반하여 입력되는 의료 영상의 진단 부위를 설정할 수 있다. 651단계에서 의료 영상이 입력됨을 인식하면, 의료 영상 진단 장치는 653단계에서 입력된 의료 영상과 다양한 상태로 생성된 의료 학습 모델들에 기반하는 딥러닝 알고리즘을 수행할 수 있다. 의료 학습 모델은 다양한 의료 영상들 및 이들 각각 대응되는 진단 영역들에 대하여 딥러닝 알고리즘에 의해 생성된 모델들이 될 수 있다. 의 료 영상 진단 장치는 653단계에서 딥러닝 알고리즘이 실행하면, 655단계에서 입력된 의료 영상의 진단부위에 대 응되는 진단 영역 영상을 추출할 수 있으며, 657단계에서 진단영역 이미지의 경계선들을 추출하여 진단라인을 추출할 수 있다. 진단라인을 추출하면, 의료 영상 진단 장치는 659단계에서 추출된 진단 라인을 입력된 의료 영 상에 오버레이시켜 표시부에 의료 영상의 진단 부위를 표시할 수 있다. 의료 영상 진단 장치는 657단계에서 진단라인 이미지를 추출할 후, 661단계에서 추출된 진단라인의 기울기를 추 정하고, 추정된 기울기에 기반하여 진단 라인들의 간격을 측정할 수 있다. 의료 영상 진단 장치는 진단 라인들 에서 병리 진단을 수행할 수 있는 중요 부위 위치에서 진단라인들 간의 간격을 측정한 후, 663단계에서 측정된 간격들을 분석하여 의료 진단 동작을 수행할 수 있다. 예를들면, 중요 부위 위치는 경추 영상에서 C2와 C3 및/ 또는 C6과 C7의 위치가 될 수 있으며, 의료 영상 진단 장치는 중요 부위 위치에서 prevertebral line(제1 진단 라인) 및 anterior vertebral line(제2 진단라인) 사이의 간격을 측정할 수 있다. 의료 영상 진단 장치는 의료 진단 동작을 수행한 후, 665단계에서 병리 진단 결과를 표시부에 표시할 수 있다. 의료 영상 진단 장치는 665 단계에서 병리 진단 결과를 표시할 때, 진단 라인들이 오버레이 표시되는 의료 영상을 함께 표시할 수도 있다. 또한 의료 영상 진단 장치는 661단계에서 진단라인의 기울기 및 중요 부위가 설정되면, 진단라인이 표시되는 의 료 영상에서 표시되는 진단라인에서 설정된 중요 부위 위치를 표시할 수 있다. 의사는 표시부에 표시되는 의료 영상 및 진단 라인을 육안으로 확인하고, 의료 영상에 진단라인이 정확하게 설 정된 경우, 의료 진단 결과에 기반하여 의료 영상을 2차적으로 분석할 수 있다. 도 7은 다양한 실시예들에 따라 의료 학습 모델을 생성하는 절차를 도시하는 흐름도이다. 도 8a - 도 8e는 의료 학습 모델을 생성하는 동작을 설명하기 화면의 예들을 표시하는 도면이다. 도 9a - 도 9d는 의료 영상의 입력 상태에서 그려지는 진단 라인의 표시 예를 도시하는 도면이다. 도 7을 참조하면, 도 8a와 같은 경추 영상이 입력되면, 의료 영상 진단 장치는 711단계에서 이를 인식하고, 입 력된 경추 영상을 표시할 수 있다. 의사는 도 8b와 같이 표시되는 경추 영상에 진단부위를 설정하기 위한 prevertebral line 및 anterior vertebral line을 표시할 수 있다. 경추 영상에 prevertebral line 및 anterior vertebral line이 표시되면, 의료 영상 진단 장치는 713 단계에서 의사에 의해 표 시되는 prevertebral line 및 anterior vertebral line을 인식하여 도 8c와 같이 제1 진단라인 및 제2 진단라인을 추출할 수 있다. 제1 진단라인은 prevertebral line이 될 수 있으며, 제2 진단라 인은 anterior vertebral line이 될 수 있다. 제1 및 제2 진단라인(831, 833)을 추출한 후, 의료 영상 진 단 장치는 715 단계에서 제1 및 제2 진단라인(831, 833) 사이를 화소로 채워 도 8d와 같이 진단 영역을 생 성할 수 있다. 진단 영역은 도 8b에서의 경추 연조직 영역이 될 수 있다. 진단영역을 생성한 후, 의료 영상 진단 장치는 717 단계에서 도 8a와 같은 경추 영상 및 도 8d와 같은 진 단 영역에 기반하여 딥러닝 알고리즘을 수행할 수 있으며, 719 단계에서 딥러닝 학습 결과에 따른 의료 학 습 모델을 생성할 수 있다. 719단계에서 생성되는 의료 학습 모델은 도 8a와 같은 의료 영상이 입력될 때 도 8e 와 같이 의료 영상에서 진단 영역을 자동으로 설정하기 위한 모델이 될 수 있다. 711단계에서 의료 영상 진단 장치에 입력되는 의료 영상(경추 영상)은 고해상도 이미지일 수 있다. 고해상도 이 미지를 학습하는 경우 많은 연산 횟수 및 시간을 시간이 소모될 수 있다. 따라서 의료 영상을 적절한 크기로 미 리 처리(pre-processing)된 크기로 재구성할 수 있다. 의료영상을 dicom 형식일 수 있으며, 영상의 크기(pixel size) 정보는 dicom header에서 얻을 수 있다. 예를들면, dicom 영상은 2k x 3k의 크기를 가질 수 있다. 다양 한 실시예들에서 의료 영상(경추 영상) 효과적인 학습(deep learning)을 위해서 256 x 256으로 다운 스케일 (downscale)할 수 있다. 예를들면, 의료 영상 진단 장치는 의료 영상의 학습 동작을 수행하기 전에 2k x 3k 의 크기를 가지는 경추 영상의 좌상단 시작점, 우하단 끝점을 클릭(click)하고, 이를 기준으로 256 x 256 크기를 가지는 의료영상으로 resize and crop 하여 traning set을 위한 영상을 재구성할 수 있다. 앞서 얻은 pixel size도 같은 비율로 계산하면 resize and crop 영상에서도 길이를 측정할 수 있다. 효율적인 의료 학습 모델 (training set)을 생성하기 위한 바이나리(binary file) 형식으로, 점(Point)들을 잇는 진단라인을 통해 진단영 역 마스크(mask)를 생성하고, 의료 영상과 진단영역 영상을 [256 x 256 x 2] 어레이(array)로 저장할 수 있다. 즉, 의료 영상 진단장치는 911단계에서 위와 같이 재구성된 의료 영상(경추 영상)을 입력할 수 있으며, 의사는 재구성된 경추 영상에서 경추 연조직을 추출하기 위한 진단 라인들을 그려 넣을 수 있다. 의료 영상 진단장치에 입력되는 경추 영상은 기울어진 형태로 획득될 수 있다. 예를들면, 경추 영상은 좌측 또 는 우측으로 기울어진 상태로 획득될 수 있다. 이때 의사는 기울어진 경추 영상에 진단라인들을 그려 넣을 수 있다. 그러면 의료 영상 진단장치는 기울어진 경추 영상에 따른 진단영역을 생성하고, 이를 학습하여 의료 학습 모델을 생성할 수 있다. 따라서 의료 영상 진단장치는 입력되는 의료 영상에 대응되는 각도로 진단 영역을 설정 할 수 있으며, 설정된 진단 영역을 기반하여 의료 영상의 딥러닝 알고리즘을 수행할 수 있다. 도 9는 다양한 실시예들에 따라 의료 영상 진단장치에서 입력되는 의료 영상을 분석하여 진단하는 동작 절차를 도시하는 흐름도이다. 도 10a - 도 10d는 다양한 실시예들에 따른 의료 진단 동작의 화면들을 예시하는 도면이 다. 도 9를 참조하면, 의료 영상 진단 장치는 911단계에서 도 10a와 같은 경추 영상을 수신할 수 있다. 경추 영상이 수신되면, 의료 영상 진단 장치는 경추 영상과 학습된 의료 학습 모델들에 기반하여 딥러닝 알고리즘을 수행할 수 있다. 의료 학습 모델은 상기 도 7과 같은 방법으로 생성될 수 있으며, 경추 영상의 진단 영역을 학습하여 생성된 마스크 모델이 될 수 있다. 의료 영상 진단 장치는 경추 영상과 의료 학습 모델을 입력으로 하여 딥러닝 알고리즘을 수행할 수 있으며, 딥러닝 학습이 종료되면 도 10b와 같은 진단 영역 이미지를 생성할 수 있다. 의 료 진단장치는 진단할 의료 영상이 수신되면, 913단계에서 수신된 의료 영상과 의료 학습 모델들을 입력으로 하 는 딥러닝 알고리즘을 수행하며, 915단계에서 딥러닝 알고리즘의 수행에 기반하여 도 10b와 같이 수신된 의료 영상의 진단영역을 추출할 수 있다. 도 10b와 같이 추출되는 진단영역은 경추 연조직 영역이 될 수 있댜. 의료 영상 진단 장치는 917 단계에서 도 10b와 같이 추출된 진단영역에서 경계선들을 추출하여 도 10c와 같은 제1 및 제2 진단 라인(1031, 1033)들을 추출할 수 있다. 제1 진단라인은 진단영역의 좌측 경계선으로 prevertebral line이 될 수 있으며, 제2 진단라인은 진단영역의 우측 경계선으로 anterior vertebral line이 될 수 있다. 도 10c와 같이 제1 진단라인 및 제2 진단라인을 추출한 후, 의료 영상 진단장치는 919단계에서 의 료 진단 동작을 수행할 수 있다. 의료 진단 동작을 수행하는 동작은 951 단계 - 955 단계를 포함할 수 있다. 의 료 영상 진단 장치는 951 단계에서 추출된 제1 진단라인 및 제2 진단라인의 기울기를 측정하고, 953 단계에서측정된 기울기에 기반하여 간격을 측정할 중요 부위를 설정하며, 설정된 중요 부위의 간격을 측정할 수 있다. 경추 영상인 경우, 도 10c와 같이 제1 중요 부위는 C2-C3 위치가 될 수 있으며, 제2 중요 부위는 C6-C7 위치가 될 수 있다. 의료 영상 진단 장치는 953 단계에서 제1 중요 부위 및/또는 제2 중요 부위 의 간격(두께)을 측정할 수 있다. 의료 진단 장치는 C2-C3의 두께를 측정할 수 있으며, 또는 C6-C7의 두 께를 측정할 수 있으며 또는 C2-C3 및 C6-C7의 두께를 모두 측정할 수 있다. C2-C3 및/또는 C6-C7 위치의 경추 연조직 두께를 측정한 후, 의료 영상 진단장치는 955단계에서 해당 부위의 두께 측정값을 해당 부위의 기준값 (정상 수치를 가지는 기준값)과 비교 분석하여 경추 연조직의 상태를 진단할 수 있다. 경추 연조직의 두께를 진단한 후, 의료 영상 진단장치는 921단계에서 진단 결과 값을 표시부에 표시할 수 있다. 도 10d는 표시부에 표시되는 경추 영상 및 진단 결과값의 표시 예를 도시하는 도면이 될 수 있다. 도 10d에서 1061은 입력되는 경추 영상이 될 수 있으며, 1063은 입력된 경추 영상에 추출된 진단라인이 오버레이되어 표시 되는 경추 영상이 될 수 있으며, 1065는 경추 영상의 경추 연조직의 표시 화면의 예가 될 수 있다. 경추 영상 화면은 917 단계에서 제1 진단라인 및 제2 진단라인이 경추 영상에 오버레이된 화면이 될 수 있다. 955단계에서 생성되는 진단 결과 값은 경추 C2-C3의 두께인 dist1과 경추 C6-C7의 두께인 dist2의 값을 표시할 수 있으며, 측정된 두께들과 정상인 기준값들을 비교 분석하여 정상(normal) 확률 및 비정상(abnormal) 의 확률로 표시할 수 있다. 예를들면, 경추 C2-C3의 두께 dist1이 7 mm로 측정되고, 경추 C6-C7의 dist 값이 21mm로 측정된 경우, 의료 영상 진단 장치는 normal 확률을 100%로 표시하고, abnormal 확률을 0%로 표시할 수 있다. 그리고 dist1 및/또는 dist2의 측정 값이 각각 대응되는 기준값(dist1이 7mm, dist2는 21mm) 보다 작거 나 큰 값으로 측정되면, 의료 영상 진단 장치는 기준값과 측정 값들의 비율을 측정하여 정상 및 비정상 확률로 표시할 수 있다. 도 11은 다양한 실시예들에 따른 의료 영상 진단 장치가 경추 영상의 진단 절차를 도시하는 흐름도이다. 도 12a - 도 12h는 다양한 실시예에 따른 의료 영상 진단 장치가 경추 영상에서 진단 부위를 추출하여 병리 진단 결과 를 표시하는 화면들의 예를 도시하는 도면이다. 도 11을 참조하면, 의료 영상 진단 장치는 경추 영상이 입력되면 입력된 경추 영상에서 진단 부위를 자동으로 설정하여 진단 결과 영상 및 병리 진단 결과를 표시할 수 있다. 경추 영상이 입력되면, 의료 영상 진단 장치는 1111 단계에서 입력 경추 영상과 의료 학습 모델에 기반하는 딥러닝 알고리즘을 수행하여 도 12a와 같이 입력된 경추 영상의 진단 영역 영상을 추출할 수 있다. 의료 영상 진단장치는 추출된 진단영역 영상으로부터 진단라인 영상들을 추출할 수 있다. 의료 영상 진단장치는 도 12a와 같은 진단 영역을 추출하면, 1113 단계에서 추출된 진단영역 영상의 경계 영상들을 추출하여 도 12b와 같은 진단 영역의 경계 영상을 추출할 수 있다. 도 12b와 같 은 경계 영상에서 경추의 제1 진단라인(prevertebral line)과 제2 진단라인(anterior vertebral line)을 추출 하기 위하여, 의료 영상 진단 장치는 1115 단계에서 도 12c와 같이 경계 영상의 상측의 행 라인 및 하측의 행 라인을 제거할 수 있다. 의료 영상 진단 장치는 1117 단계에서 도 12c와 같은 영상에 X 축 방향으로 왼쪽 끝 포 인트와 오른쪽 큰 포인트를 제어한 나머지 부분을 제거하여 도 12d와 같은 진단라인들을 추출할 수 있다. 도 12d에서 제1 진단라인은 prevertebral line이 될 수 있으며, 제2 진단라인은 anterior vertebral line이 될 수 있다. 그리고 제1 진단라인과 제2 진단라인의 사이 영역는 경추 연조직 영역이 될 수 있다. 도 12d와 같이 진단라인들이 추출되면, 의료 영상 진단 장치는 도 12h와 입력된 경추 영상에 추출 된 진단라인을 오버레이하여 표시할 수 있다. 그리고 의사는 표시되는 진단라인의 위치를 확인하여 경추 영상에 서 진단라인이 정확하게 추출되었는지 육안으로 확인할 수 있다. 도 11에서 1113단계 - 1117 단계는 도 9의 진 단라인 추출하는 917 단계의 동작이 될 수 있다. 입력된 경추 영상에서 진단 라인을 추출한 후, 의료 영상 진단장치는 1119 단계에서 추출된 진단라인의 기울기 를 측정할 수 있다. 의료 영상 진단 장치는 도 12e와 같이 진단라인(예를들면 제2 진단라인의 기울기에 기반하여 수선의 발(foot of perpendicular)을 측정할 수 있다. 수선(perpendicular)은 일정한 직선이나 평면과 직각을 이루는 직선을 의미할 수 있으며, 수선의 발은 수선과 일정한 직선이나 평면이 만나는 점이 될 수 있다. 또한 한점에서 직선이나 평면에 수선을 그었을 때 생기는 교점. 직선과 직선, 직선과 평면이 수직으로 만나 생기는 교점들도 수선의 발이 될 수 있다. 예를들면, 도 12e에 도시된 바와 같이, 의료 영상 진단장치는 우측 진단라인의 기울기에 기반하여 수선의 발을 측정할 수 있으며, 우측 출발지점의 상 2픽셀과 하 2픽셀을 포함한 기울기를 측정할 수 있다. 의료 영상 진단 장치는 도 12e와 같이 진단라인의 기울기를 측정 한 후, 1121 단계에서 출발점과 수선의 발 사이의 거리(간격)를 측정할 수 있다. 도 12f에서 X축은 출발점(단위 pixel)이 될 수 있으며, Y축은 측정된 거리(단위 pixel)이 될 수 있다. 의료 영상 진단장치는 출발 점에서 수선의 발 사이에 거리를 측정하여 기울기 기반의 간격을 화소 값으로 설정할 수 있다. 도 11에서 1119단계 및 1121 단계는 도 9의 951 단계의 동작이 될 수 있다. 기울기 간격을 측정한 후, 의료 영상 진단 장치는 중요 부위 간격을 추출할 수 있다. 의료 영상 진단장치는 기 울기 간격 기반의 간격을 측정한 후 1123 단계에서 분산 값을 측정할 수 있다. 예를들면, 도 12g와 같이 최대값 을 가지는 3개의 포인트들과 최소 값을 가지는 3개 포인트들을 제외한 포인트들의 분산을 측정할 수 있다. 분산 측정 방법은 좌측 및 우측의 2 픽셀들을 포함 5개의 픽셀들에 대한 분산을 측정할 수 있다. 의료 영상 진단장치 는 1125 단계에서 최대 분산을 가지는 포인트로부터 전반부와 후반부를 구분하고, 1127 단계에서 전반부 및 후 반부의 전후 5 픽셀을 제외한 부분에 대한 중간 값을 각각 C2-C3 및 C6-C7의 위치로 설정할 수 있다. 의료 영상 진단장치는 1129 단계에서 중요 부위인 C2-C3 및/또는 C6-C7의 위치에서 제1 진단라인(prevertebral line)과 제2 진단라인(anterior vertebral line) 사이의 두께를 측정할 수 있다. 경추 영상에서 C2-C3 및/또는 C6-C7의 위치의 prevertebral line과 anterior vertebral line 사이의 두께 dist1 및 dist2를 측정한 후, 의료 영상 진단장치는 1131 단계에서 dist1 및 dist2를 각각 대응되는 기준값과 비교 분석하여 진단 결과를 표시할 수 있다. 이때 표시되는 진단 결과는 도 10d에 도시된 바와 같이 dist1 및 dist2의 측정 값 및 측정값에 기반하는 정상 및/또는 비정상 확률로 표시할 수 있다. 또한 의료 영상 진단장치 는 1117 단계에서 추출된 prevertebral line과 anterior vertebral line을 경추 영상에 오버레이하여 표시할 수 있다. 도 13은 다앙한 실시예들에 따른 의료 영상 진단장치가 진단 영역을 추출하는 동작을 도시하는 흐름도이다. 도 14a - 도 14e는 다양한 실시예들에 따라 경추 영상에서 진단영역을 추출하는 동작의 화면 예를 도시하는 도면이 다. 도 13을 참조하면, 딥러닝 알고리즘(CNN algorithm)을 수행하면 경추 영상에서 도 12a와 같이 하나의 진단영역 영상을 추출할 수 있다. 그러나 진단영역 영상을 추출할 때 도 14a와 같이 분리된 영상들을 가지는 진단영역 영 상을 추출할 수 있다. 도 14a는 1411-1417과 같은 2개의 분리 영역들을 가지는 상태로 진단영역이 추출된 예를 도시하고 있다. 진단영역이 도 14a와 같이 복수의 영역들로 추출되면 의료 영상 진단장치는 1311 단계에서 이를 인식하고, 1313 단계에서 도 14b와 같이 분리된 영역 1411- 1417들에 참조번호 1440과 같은 식별자들을 이용하 여 영역 별로 번호를 부여할 수 있다. 의료 영상 진단 장치는 1315 단계에서 X 축 방향(수평 방향)으로 분리된 영역 1411 - 1417들을 연결하여 겹치는 영역들을 추출할 수 있다. 예를들면, 도 14c에서 수평 방향으로 영역 1411과 1417이 겹쳐질 수 있으며, 영역 1413과 1415가 겹칠 수 있다. 의료 영상 진단 장치는 1415 및 1413과 같 이 수평방향으로 겹치는 1411 및 1417과 1413 및 1415 영역들을 인식할 수 있다. 의료 영상 진단 장치는 1317 단계에서 도 14d와 같이 겹치는 영역(1411 및 1417, 1413 및 1415)들 중에서 작은 크기를 가지는 영역들(1417, 1415)을 제거한 후, 도 14e와 같이 수정된 진단영역을 설정할 수 있다. 의료 진단장치는 딥러닝 알고리즘을 수 행하여 입력된 경추 영상의 진단 영역을 추출할 때, 추출된 진단영역이 복수의 영역들로 추출되면 수평 방향으 로 겹치는 영역들 중에서 작은 크기를 가지는 영역들을 제거하여 진단영역을 추출할 수 있다. 이상 본 발명을 몇 가지 바람직한 실시예를 사용하여 설명하였으나, 이들 실시예는 예시적인 것이며 한정적인"}
{"patent_id": "10-2017-0104313", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "것이 아니다. 이와 같이, 본 발명이 속하는 기술분야에서 통상의 지식을 지닌 자라면 본 발명의 사상과 첨부된 특허청구범위에 제시된 권리범위에서 벗어나지 않으면서 균등론에 따라 다양한 변화와 수정을 가할 수 있음을 이해할 것이다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8a 도면8b 도면8c 도면8d 도면8e 도면9 도면10a 도면10b 도면10c 도면10d 도면11 도면12a 도면12b 도면12c 도면12d 도면12e 도면12f 도면12g 도면12h 도면13 도면14a 도면14b 도면14c 도면14d 도면14e"}
{"patent_id": "10-2017-0104313", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 다양한 실시예들에 따른 병원 정보 시스템(HIS, hospital information system)의 구성을 도시하는 도면 이다. 도 2는 다양한 실시예들에 따른 병원 시스템의 의료 영상 진단 장치의 구성을 도시하는 도면이다. 도 3은 다양한 실시예들에 따른 의료 진단 장치의 학습 모듈 구조를 도시하는 도면이다. 도 4는 다양한 실시예들에 따른 의료 진단 장치의 진단 모듈 구조를 도시하는 도면이다. 도 5는 경추 구성(C spine lateral view)을 모식적으로 도시한 도면이다. 도 6은 다양한 실시예들에 따른 의료 진단 동작을 도시하는 도면이다. 도 7은 다양한 실시예들에 따라 의료 학습 모델을 생성하는 절차를 도시하는 흐름도이다. 도 8a - 도 8e는 의료 학습 모델을 생성하는 동작을 설명하기 화면의 예들을 표시하는 도면이다. 도 9는 다양한 실시예들에 따라 의료 영상 진단장치에서 입력되는 의료 영상을 분석하여 진단하는 동작 절차를 도시하는 흐름도이다. 도 10a - 도 10d는 다양한 실시예들에 따른 의료 진단 동작의 화면들을 예시하는 도면이다. 도 11은 다양한 실시예들에 따른 의료 영상 진단 장치가 경추 영상의 진단 절차를 도시하는 흐름도이다. 도 12a - 도 12h는 다양한 실시예에 따른 의료 영상 진단 장치가 경추 영상에서 진단 부위를 추출하여 병리 진 단 결과를 표시하는 화면들의 예를 도시하는 도면이다. 도 13은 다앙한 실시예들에 따른 의료 영상 진단장치가 진단 영역을 추출하는 동작을 도시하는 흐름도이다. 도 14a - 도 14e는 다양한 실시예들에 따라 경추 영상에서 진단영역을 추출하는 동작의 화면 예를 도시하는 도 면이다."}
