{"patent_id": "10-2022-0174504", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0091510", "출원번호": "10-2022-0174504", "발명의 명칭": "연합 앙상블 학습 방법 및 장치", "출원인": "성균관대학교산학협력단", "발명자": "이지형"}}
{"patent_id": "10-2022-0174504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "클라이언트가 수행하는 연합학습 방법에 있어서,서버로부터 글로벌 학습 모델을 수신하는 단계;상기 글로벌 학습 모델 및 랭크-1(rank-1) 행렬을 기초로 로컬 학습 모델을 생성하는 단계;로컬 학습 데이터를 기초로 상기 로컬 학습 모델에 학습을 수행하여 클라이언트 학습 모델을 생성하는 단계; 및상기 서버에 상기 클라이언트 학습 모델을 전송하는 단계를 포함하는, 연합학습 방법."}
{"patent_id": "10-2022-0174504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 글로벌 학습 모델 및 랭크-1(rank-1) 행렬을 기초로 로컬 학습 모델을 생성하는 단계는,하기 수학식을 기초로 상기 로컬 학습 모델을 생성하는 단계를 포함하고,상기 Wnew는 상기 로컬 학습 모델이고, 상기 W는 상기 글로벌 학습 모델이고, 상기 는 상기 랭크-1 행렬이고, 상기 r은 제1 벡터이고, 그리고, 상기 sT는 제2 벡터인, 연합학습 방법."}
{"patent_id": "10-2022-0174504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 클라이언트 학습 모델을 생성하는 단계는,하기 수학식을 기초로 상기 로컬 학습 데이터를 기초로 상기 로컬 학습 모델에 대한 학습을 수행하는 단계를 포함하고,상기 는 손실 함수이고, 상기 는 y번째 차원 벡터이고, 상기 는 j번째 차원 벡터이고, 그리고, 상기 j:클래스 수인, 연합 학습 방법."}
{"patent_id": "10-2022-0174504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 서버에 상기 랭크-1 행렬을 전송하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-0174504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "적어도 하나의 송수신기;적어도 하나의 명령이 저장된 적어도 하나의 메모리; 및상기 적어도 하나의 명령을 수행하는 적어도 하나의 프로세서를 포함하고,공개특허 10-2024-0091510-3-상기 적어도 하나의 명령은,서버로부터 글로벌 학습 모델을 수신하는 단계;상기 글로벌 학습 모델 및 랭크-1(rank-1) 행렬을 기초로 로컬 학습 모델을 생성하는 단계;로컬 학습 데이터를 기초로 상기 로컬 학습 모델에 학습을 수행하여 클라이언트 학습 모델을 생성하는 단계; 및상기 서버에 상기 클라이언트 학습 모델을 전송하는 단계를 포함하는, 클라이언트."}
{"patent_id": "10-2022-0174504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 글로벌 학습 모델 및 랭크-1(rank-1) 행렬을 기초로 로컬 학습 모델을 생성하는 단계는,하기 수학식을 기초로 상기 로컬 학습 모델을 생성하는 단계를 포함하고,상기 Wnew는 상기 로컬 학습 모델이고, 상기 W는 상기 글로벌 학습 모델이고, 상기 는 상기 랭크-1 행렬이고, 상기 r은 제1 벡터이고, 그리고, 상기 sT는 제2 벡터인, 클라이언트."}
{"patent_id": "10-2022-0174504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 클라이언트 학습 모델을 생성하는 단계는,하기 수학식을 기초로 상기 로컬 학습 데이터를 기초로 상기 로컬 학습 모델에 대한 학습을 수행하는 단계를 포함하고,상기 는 손실 함수이고, 상기 는 y번째 차원 벡터이고, 상기 는 j번째 차원 벡터이고, 그리고, 상기 j:클래스 수인, 클라이언트."}
{"patent_id": "10-2022-0174504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 적어도 하나의 명령은,상기 서버에 상기 랭크-1 행렬을 전송하는 단계를 더 포함하는, 클라이언트."}
{"patent_id": "10-2022-0174504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "서버가 수행하는 연합학습 방법에 있어서,글로벌 학습 데이터를 기초로 제1 글로벌 학습 모델을 생성하는 단계;복수의 클라이언트에 상기 제1 글로벌 학습 모델을 전송하는 단계;상기 복수의 클라이언트 각각으로부터 클라이언트 학습 모델을 수신하는 단계; 및상기 복수의 클라이언트 학습 모델을 기초로 제2 글로벌 학습 모델을 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0174504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2024-0091510-4-제9항에 있어서,상기 복수의 클라이언트 학습 모델을 기초로 제2 글로벌 학습 모델을 생성하는 단계는,상기 복수의 클라이언트 학습 모델의 평균을 연산하여 상기 제2 글로벅 학습 모델을 생성하는 단계를 포함하는,방법."}
{"patent_id": "10-2022-0174504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 복수의 클라이언트로부터 랭크-1(rank-1) 행렬을 수신하는 단계; 및상기 랭크-1 행렬을 기초로 상기 제2 글로벌 학습 모델에 대한 추론을 수행하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-0174504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "적어도 하나의 송수신기;적어도 하나의 명령이 저장된 적어도 하나의 메모리; 및상기 적어도 하나의 명령을 수행하는 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 명령은,글로벌 학습 데이터를 기초로 제1 글로벌 학습 모델을 생성하는 단계;복수의 클라이언트에 상기 제1 글로벌 학습 모델을 전송하는 단계;상기 복수의 클라이언트 각각으로부터 클라이언트 학습 모델을 수신하는 단계; 및상기 복수의 클라이언트 학습 모델을 기초로 제2 글로벌 학습 모델을 생성하는 단계를 포함하는, 서버."}
{"patent_id": "10-2022-0174504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 복수의 클라이언트 학습 모델을 기초로 제2 글로벌 학습 모델을 생성하는 단계는,상기 복수의 클라이언트 학습 모델의 평균을 연산하여 상기 제2 글로벌 학습 모델을 생성하는 단계를 포함하는,서버."}
{"patent_id": "10-2022-0174504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 적어도 하나의 명령은,상기 복수의 클라이언트로부터 랭크-1(rank-1) 행렬을 수신하는 단계; 및상기 랭크-1 행렬을 기초로 상기 제2 글로벌 학습 모델에 대한 추론을 수행하는 단계를 더 포함하는, 서버."}
{"patent_id": "10-2022-0174504", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 연합 앙상블 학습 방법 및 장치에 관한 것으로, 본 발명은 연합 앙상블 학습 방법은 서버로부터 글로 벌 학습 모델을 수신하는 단계, 기 글로벌 학습 모델 및 랭크-1(rank-1) 행렬을 기초로 로컬 학습 모델을 생성하 는 단계, 로컬 학습 데이터를 기초로 상기 로컬 학습 모델에 학습을 수행하여 클라이언트 학습 모델을 생성하는 단계 및 상기 서버에 상기 클라이언트 학습 모델을 전송하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0174504", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 연합 앙상블 학습 방법 및 장치에 과한 것으로, 특히 랭크-1(rank-1) 행렬을 이용한 연합 앙상블 학 습 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0174504", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "연합 학습(federated learning)은 개인정보를 포함한 예민한 정보를 보호할 목적으로 개발된 딥러닝 방법이다. 연합 학습 네트워크에 참여한 클라이언트(participant, client, party, edge device, node, user 등으로도 지칭) 각각의 로컬 모델들을 바탕으로 전체를 아우르는 글로벌 모델을 생성하는 방식을 이용한다. 좀 더 구체적으로, 각각의 클라이언트는 데이터를 수집하여 로컬 모델을 학습하고, 서버에 학습한 로컬 모델의 정보를 업로드한다. 서버는 로컬 모델 정보를 취합하여 글로벌 모델을 업데이트하고, 클라이언트에 업데이트한 글로벌 모델의 정보를 전송한다. 클라이언트는 서버로부터 받은 글로벌 모델의 정보로 로컬 모델을 업데이트한 다. 그러나 종래의 연합학습 방법은 분산 환경의 발달로 다양한 데이터를 사용할 수 있게 되었고, 데이터 분포가 비 독립적 동일 분포(Non-IID)가 되며 연합 앙상블 방법 시 성능이 기존의 FedAvg보다 떨어지는 것을 볼 수 있다. 또한 앙상블 방법은 엣지 디바이스(edge device)에서는 사용하기 힘들 정도로 모델이 커져, 비용이 증가하는 문 제점이 있을 수 있다."}
{"patent_id": "10-2022-0174504", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 상기와 같은 문제점을 해결하기 위한 것으로, 통신 및 비용을 감소할 수 있는 연합 앙상블 학 습 방법 및 장치를 제공하는 데 있다."}
{"patent_id": "10-2022-0174504", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 연합 학습 방법은 클라이언트가 수행하는 연합학습 방법에 있어서, 서버로부터 글 로벌 학습 모델을 수신하는 단계, 상기 글로벌 학습 모델 및 랭크-1(rank-1) 행렬을 기초로 로컬 학습 모델을 생성하는 단계, 로컬 학습 데이터를 기초로 상기 로컬 학습 모델에 학습을 수행하여 클라이언트 학습 모델을 생 성하는 단계 및 상기 서버에 상기 클라이언트 학습 모델을 전송하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 따른 클라이언트는 적어도 하나의 송수신기, 적어도 하나의 명령이 저장된 적어도 하나 의 메모리 및 상기 적어도 하나의 명령을 수행하는 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 명 령은, 서버로부터 글로벌 학습 모델을 수신하는 단계, 상기 글로벌 학습 모델 및 랭크-1(rank-1) 행렬을 기초로 로컬 학습 모델을 생성하는 단계, 로컬 학습 데이터를 기초로 상기 로컬 학습 모델에 학습을 수행하여 클라이언 트 학습 모델을 생성하는 단계 및 상기 서버에 상기 클라이언트 학습 모델을 전송하는 단계를 포함할 수 dLT다 본 발명의 일 실시예에 따른 연합 학습 방법은 서버가 수행하는 연합학습 방법에 있어서, 글로벌 학습 데이터를 기초로 제1 글로벌 학습 모델을 생성하는 단계, 복수의 클라이언트에 상기 제1 글로벌 학습 모델을 전송하는 단 계, 상기 복수의 클라이언트 각각으로부터 클라이언트 학습 모델을 수신하는 단계 및 상기 복수의 클라이언트 학습 모델을 기초로 제2 글로벌 학습 모델을 생성하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 따른 서버는 적어도 하나의 송수신기, 적어도 하나의 명령이 저장된 적어도 하나의 메모 리 및 상기 적어도 하나의 명령을 수행하는 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 명령은, 글로벌 학습 데이터를 기초로 제1 글로벌 학습 모델을 생성하는 단계, 복수의 클라이언트에 상기 제1 글로벌 학 습 모델을 전송하는 단계, 상기 복수의 클라이언트 각각으로부터 클라이언트 학습 모델을 수신하는 단계 및 상 기 복수의 클라이언트 학습 모델을 기초로 제2 글로벌 학습 모델을 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0174504", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, Non-IID 환경에서도 강한 연합 앙상블 학습 방법 및 장치를 제공할 수 있다. 본 발명에 따르면, 연합 앙상블 학습 방법에서 비용문제를 효과적으로 감소시킬 수 있다."}
{"patent_id": "10-2022-0174504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 명세서의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"전기적으로 연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 전기적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 전기적으로 연결되 어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어 야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 도 1은 본 발명의 일 실시예에 따른 연합 학습 시스템의 블록도이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 연합 학습 시스템은 서버 및 복수의 클라이언트를 포함할 수 있다. 도면에는 3개의 클라이언트만을 도시하였으나 이는 일 예시이며 이에 한정하지 아니한다. 일 실시예에서, 연합 학습 시스템은 VGG-9 기반의 모델을 포함할 수 있다. 여기에서, 연합학습(Federated Learning)은 인공지능 모델 학습 방법으로서, 중앙 서버에 있는 데이터를 활용하여 학습하는 방식이 아닌, 각 로컬 클라이언트에서 학습된 인공지능 모델의 파라미터 만을 사용하여 중앙 서버의 인공지능 모델을 학습하는 방법일 수 있다. 로컬 클라이언트 별 보유 데이터의 분포에 따라 데이터 분산 환경은 독립 동일 분포(IID, Independent Identically Distributed) 환경과 비독립 동일 분포(Non-IID, Not Independent and Identically Distributed) 환경으로 구분된다. 독립 동일 분포(IID)는 각 로컬 클라이언트 별 보유 데이터의 분포가 비슷한 경우, 다시 말 하면, 데이터 양과 레이블이 비슷하게 분포된 경우를 의미하고, 비독립 동일 분포(Non-IID)는 각 로컬 클라이언 트 별 보유 데이터의 분포가 다른 경우, 다시 말하면, 데이터 양과 레이블이 비슷하지 않고 서로 다르게 분포된 경우를 의미할 수 있다. 서버는 글로벌 학습 모델 및 글로벌 학습 데이터를 포함할 수 있다. 서버는 여기에서, 글로벌 학습 모델은 글로벌 학습 데이터를 기초로 생성된 학습 모델일 수 있다. 서버는 글로벌 학습 모델을 복수의 클 라이언트 각각에 전송할 수 있다. 복수의 클라이언트는 각각 글로벌 학습 모델을 수신할 수 있다. 복수의 클라이언트는 각각 랭크- 1(RANK-1) 행렬 및 로컬 학습 데이터를 포함할 수 있다. 복수의 클라이언트는 글로벌 학습 모델 및 랭크-1 행렬을 기초로 로컬 학습 모델을 생성할 수 있다. 복수의 클라이언트는 수학식 1을 기초로 로컬 학습 모델 을 생성할 수 있다.수학식 1"}
{"patent_id": "10-2022-0174504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서, Wnew는 로컬 학습 모델일 수 있고, W는 글로벌 학습 모델일 수 있고, 는 랭크-1 행렬일 수 있고, r은 제1 벡터일 수 일 수 있고, sT는 제2 벡터일 수 있다. 복수의 클라이언트는 로컬 학습 데이터를 기초로 로컬 학습 모델 학습을 수행하여 클라이언트 학습 모델을 생성할 수 있다. 복수의 클라이언트는 수학식 2의 손실함수를 최소화하는 방식으로 로컬 학습 모델에 대한 학습을 수행할 수 있다. 수학식 2"}
{"patent_id": "10-2022-0174504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2에서, LCE는 손실함수일 수 있고, 는 y번째 차원 벡터일 수 있고 는 j번째 차원 벡터일 수 있으며 j는 클래스 일 수 있다. 복수의 클라이언트는 글로벌 학습 모델 및 랭크-1 행렬을 서버에 전송할 수 있다. 도 2는 본 발명의 일 실시예에 따른 연합 학습 방법의 순서도이다. 도 2를 참조하면, 서버는 제1 글로벌 학습 모델을 생성할 수 있다(S210). 서버(예를 들어, 도 1의 서버)는 글로벌 학습 데이터를 기초로 제1 글로벌 학습 모델을 생성할 수 있다. 서버는 제1 글로벌 학습 모델을 복수의 클라이언트 각각에 전송할 수 있다(S220). 복수의 클라이언트는 제1 글로벌 학습 모델을 서버로부터 수신할 수 있다(S220). 복수의 클라이언트(예를 들어, 도 1의 복수의 클라이언트) 각각은 글로벌 공유 모델을 기초로 로컬 학습 모델을 생성할 수 있다(S230). 복수의 클라이언트는 글로벌 공유 모델 및 랭크-1 행렬을 기초로 로컬 학습 모델을 생성할 수 있다. 예를 들어, 복수의 클라이언트 각각은 수학식 1을 기초로 로컬 학습 모델을 생성할 수 있다. 복수의 클라이언트는 로 컬 학습 모델을 기초로 클라이언트 학습 모델을 생성할 수 있다(S240). 복수의 클라이언트는 로컬 학습 데이터 를 기초로 로컬 학습 모델에 대한 학습을 수행하는 방식으로 클라이언트 학습 모델을 생성할 수 있다. 복수의 클라이언트는 클라이언트 학습 모델을 서버에 전송할 수 있다(S250). 서버는 클라이언트 학습 모델을 복수의 클라이언트로부터 수신할 수 있다(S250). 서버는 클라이언트 학습 모델 을 기초로 제2 글로벌 학습 모델을 생성할 수 있다(S260). 서버는 복수의 클라이언트 학습 모델의 평균을 연산 하는 방식으로 제2 글로벌 학습 모델을 생성할 수 있다. 서버는 제2 글로벌 학습 모델에 대한 학습을 수행할 수 있다(S270). 예를 들어, 서버는 글로벌 학습 데이터를 기초로 제2 글로벌 학습 모델에 대한 학습을 수행할 수 있다. 서버는 랭크-1 행렬을 전송할 것을 복수의 클라이언트에게 요청할 수 있다(S280). 복수의 클라이언트는 서버로 부터 랭크-1 행렬의 전송 요청을 수신할 수 있다(S280). 복수의 클라이언트는 랭크-1 행렬을 서버에 전송할 수 있다(S290). 서버는 랭크-1 행렬을 복수의 클라이언트로부터 수신할 수 있다(S290). 서버는 복수의 랭크-1 행렬 을 기초로 추론(inference)을 수행할 수 있다(S300). 도 3은 본 발명의 일 실시예에 따른 연합 학습 방법의 효과를 설명하기 위한 그래프이다. 도 4 내지 5는 본 발 명의 일 실시예에 따른 연합 학습 방법의 효과를 설명하기 위한 표이다.도 3 내지 4에서 실험 데이터셋은 CIFAR-10을 사용하였으며, 모델은 VGG-9 신경망을 사용하였다. 학습에 사용된 클라이언트 수는 10개, 라운드는 100회, Non-IID는 Dirichlet α=0.1로 설정하였다. 도 3 내지 도 4를 참조하면, 기존의 연합 앙상블 모델은 클라이언트 모델의 전체를 사용하기에 글로벌 학습 모델이 크게 증가하는 것을 볼 수 있으나 본 발명의 일 실시예에 따른 연합 학습 모델의 경우 글로벌 학습 모델이 Rank-1 행렬들과 공 유 모델로 이루어져 있기에, 앙상블 모델이 크기가 작은 것을 확인할 수 있다. 도 5에서 실험 데이터셋은 SVHN 및 CIFAR를 사용하였으며, IID 상황 및 Non-IID 상황에서의 연합학습 방법으로 FedRE, FedAvg 및 FedEnsemble을 시용하는 경우 이미지 분류 성능을 비교한 것이다. 여기에서, FedRE는 본 발명 의 일 실시예에 따른 연합 학습 방법일 수 있다. 도 5를 참조하면, 본 발명의 일 실시예에 따른 연합학습 방법 (FedRE)은 IID 상황에서는 기존 성능에 비해 5% 정도 향상이 된 것을 알 수 있고, Non-IID 상황에서는 50% 정도 향상된 것을 확인할 수 있다. 도 6은 본 발명의 일 실시예에 따른 장치의 블록도이다. 도 6의 장치는 도 1의 서버 및 클라이언트와 동일할 수 있다. 장치는 적어도 하나의 프로 세서, 메모리 및 네트워크와 연결되어 통신을 수행하는 송수신 장치를 포함할 수 있다. 또한, 장치는 입력 인터페이스 장치, 출력 인터페이스 장치, 저장 장치 등을 더 포함할 수 있다. 장치에 포함된 각각의 구성 요소들은 버스(bus, 670)에 의해 연결되어 서로 통신을 수행할 수 있다. 다만, 장치에 포함된 각각의 구성요소들은 공통 버스가 아니라, 프로세서를 중심으로 개별 인터페이스 또는 개별 버스를 통하여 연결될 수도 있다. 예를 들어, 프로세서는 메모리, 송수신 장치, 입력 인터페이스 장치, 출력 인터페이스 장치 및 저장 장치 중에서 적어도 하나와 전용 인터페이스를 통하여 연결될 수도 있다. 프로세서는 메모리 및 저장 장치 중에서 적어도 하나에 저장된 프로그램 명령(program comman d)을 실행할 수 있다. 프로세서는 중앙 처리 장치(central processing unit, CPU), 그래픽 처리 장치 (graphics processing unit, GPU), 또는 본 발명의 실시예들에 따른 방법들이 수행되는 전용의 프로세서를 의미 할 수 있다. 메모리 및 저장 장치 각각은 휘발성 저장 매체 및 비휘발성 저장 매체 중에서 적어도 하 나로 구성될 수 있다. 예를 들어, 메모리는 읽기 전용 메모리(read only memory, ROM) 및 랜덤 액세스 메 모리(random access memory, RAM) 중에서 적어도 하나로 구성될 수 있다. 본 발명에서 사용되는 대부분의 용어는 해당 분야에서 널리 사용되는 일반적인 것들에서 선택되지만, 일부 용어 는 출원인에 의해 임의로 선택되며 그 의미는 필요에 따라 다음 설명에서 자세히 서술한다. 따라서 본 발명은 용어의 단순한 명칭이나 의미가 아닌 용어의 의도된 의미에 근거하여 이해되어야 한다. 본 발명은 본 발명의 필수적 특징을 벗어나지 않는 범위에서 다른 특정한 형태로 구체화될 수 있음은 당업자에 게 자명하다. 따라서, 상술한 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니 되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2022-0174504", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명에 대해 더욱 이해하기 위해 포함되며 본 출원에 포함되고 그 일부를 구성하는 첨부된 도면은 본 발명의 원리를 설명하는 상세한 설명과 함께 본 발명의 실시예를 나타낸다. 도 1은 본 발명의 일 실시예에 따른 연합 학습 시스템의 블록도이다. 도 2는 본 발명의 일 실시예에 따른 연합 학습 방법의 순서도이다. 도 3은 본 발명의 일 실시예에 따른 연합 학습 방법의 효과를 설명하기 위한 그래프이다.도 4 내지 5는 본 발명의 일 실시예에 따른 연합 학습 방법의 효과를 설명하기 위한 표이다. 도 6은 본 발명의 일 실시예에 따른 장치의 블록도이다."}
