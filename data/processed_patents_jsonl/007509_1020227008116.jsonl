{"patent_id": "10-2022-7008116", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0078566", "출원번호": "10-2022-7008116", "발명의 명칭": "메모리기반 프로세서", "출원인": "뉴로블레이드, 리미티드.", "발명자": "시티, 엘라드"}}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "기판; 상기 기판 상에 배치되고 복수의 이산 메모리 뱅크를 포함하는 메모리 어레이; 상기 기판 상에 배치되고 상기 복수의 이산 메모리 뱅크 중의 하나 이상의 이산 메모리 뱅크와 각각 연관되는복수의 프로세서 서브유닛을 포함하는 프로세싱 어레이; 및 컨트롤러를 포함하는 집적회로에 있어서, 상기 컨트롤러는 상기 동작에 대한 적어도 하나의 보안 조치를 이행하도록 구성된 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 컨트롤러는 상기 적어도 하나의 보안 조치가 촉발되는 경우에 하나 이상의 해결책을 취하도록 구성된 것을특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 컨트롤러는 적어도 하나의 메모리 위치에 적어도 하나의 보안 조치를 이행하도록 구성된 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 데이터는 신경망 모델의 가중치 데이터(weight data)를 포함하는 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 컨트롤러는 입력 데이터 또는 출력 데이터 동작에 사용되지 않는 상기 메모리 어레이의 하나 이상의 메모리 부분에 대한 접근 차단을 포함하는 적어도 하나의 보안 조치를 이행하도록 구성된 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 컨트롤러는 상기 메모리 어레이의 서브세트(subset)만의 차단을 포함하는 적어도 하나의 보안 조치를 이행하도록 구성된 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 메모리 어레이의 상기 서브세트는 특정 메모리 주소에 의해 지정되는 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서, 공개특허 10-2022-0078566-3-상기 메모리 어레이의 상기 서브세트는 설정 가능한 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 컨트롤러는 상기 집적회로로 가는 트래픽 또는 상기 집적회로에서 오는 트래픽의 제어를 포함하는 적어도하나의 보안 조치를 이행하도록 구성된 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 컨트롤러는 변경 가능한 데이터, 코드, 또는 고정된 데이터의 업로딩을 포함하는 적어도 하나의 보안 조치를 이행하도록 구성된 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 변경 가능한 데이터, 코드, 또는 고정된 데이터의 업로딩은 부팅 프로세스 중에 일어나는 것을 특징으로하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 컨트롤러는 부팅 프로세스가 완료되면 차단될 상기 메모리 어레이의 적어도 일부에 대한 특정 메모리 주소를 식별하는 설정 파일을 상기 부팅 프로세스 동안에 업로드하는 것을 포함하는 적어도 하나의 보안 조치를 이행하도록 구성된 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서, 상기 컨트롤러는 하나 이상의 메모리 주소와 연관된 상기 메모리 어레이의 메모리 부분에 대한 접근을 차단 해제하기 위한 암호를 요구하도록 더 구성된 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항에 있어서, 상기 적어도 하나의 보안 조치는 적어도 하나의 차단된 메모리 주소로의 접근 시도가 검출되면 촉발되는 것을특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항에 있어서,상기 컨트롤러는 상기 메모리 어레이의 적어도 일부분에 대하여 계산된 검사 합계(checksum), 해시(hash),CRC(cyclic redundancy check, 순환 중복 검사), 패리티(parity)를 계산하고, 상기 계산된 검사 합계, 해시,CRC, 또는 패리티를 소정의 값과 비교하는 것을 포함하는 적어도 하나의 보안 조치를 이행하도록 구성된 것을특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 컨트롤러는, 상기 적어도 하나의 보안 조치의 일환으로, 상기 계산된 검사 합계, 해시, CRC, 또는 패리티가 상기 소정의 값과 일치하는지 여부를 판단하도록 구성된 것을 특징으로 하는 집적회로. 공개특허 10-2022-0078566-4-청구항 17 제1항에 있어서, 상기 적어도 하나의 보안 조치는 적어도 2개의 상이한 메모리 부분에 프로그램 코드의 복제를 포함하는 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 적어도 하나의 보안 조치는 상기 적어도 2개의 상이한 메모리 부분의 상기 프로그램 코드의 실행으로부터의 출력 결과가 서로 상이한지 여부의 판단을 포함하는 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 출력 결과는 중간 출력 결과 또는 최종 출력 결과를 포함하는 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17항에 있어서, 상기 적어도 2개의 상이한 메모리 부분은 상기 집적회로 내에 포함되는 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제1항에 있어서, 상기 적어도 하나의 보안 조치는 동작 패턴이 하나 이상의 소정의 동작 패턴과 상이한지 여부의 판단을 포함하는 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제2항에 있어서, 상기 하나 이상의 해결책은 동작의 실행의 중단을 포함하는 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "위조로부터 집적회로를 보호하는 방법에 있어서, 상기 방법은 상기 집적회로의 동작에 대한 적어도 하나의 보안 조치를 상기 집적회로와 연관된 컨트롤러를 사용하여 이행하는 단계를 포함하고, 상기 집적회로는: 기판; 상기 기판 상에 배치되고 복수의 이산 메모리 뱅크를 포함하는 메모리 어레이; 상기 기판 상에 배치되고 상기 복수의 이산 메모리 뱅크 중의 하나 이상의 이산 메모리 뱅크와 각각 연관되는복수의 프로세서 서브유닛을 포함하는 프로세싱 어레이를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 상기 적어도 하나의 보안 조치가 촉발되는 경우에 하나 이상의 해결책을 취하는 단계를 더 포함하는 방법. 공개특허 10-2022-0078566-5-청구항 25 기판; 상기 기판 상에 배치되고 복수의 이산 메모리 뱅크를 포함하는 메모리 어레이; 상기 기판 상에 배치되고 상기 복수의 이산 메모리 뱅크 중의 하나 이상의 이산 메모리 뱅크와 각각 연관되는복수의 프로세서 서브유닛을 포함하는 프로세싱 어레이; 및 컨트롤러를 포함하는 집적회로에 있어서, 상기 컨트롤러는 상기 집적회로의 동작에 대한 적어도 하나의 보안 조치를 이행하도록 구성되고, 상기 적어도하나의 보안 조치는 적어도 2개의 상이한 메모리 부분에 프로그램 코드를 복제하는 것을 포함하는 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "기판; 상기 기판 상에 배치되고 복수의 이산 메모리 뱅크를 포함하는 메모리 어레이; 상기 기판 상에 배치되고 상기 복수의 이산 메모리 뱅크 중의 하나 이상의 이산 메모리 뱅크와 각각 연관되는복수의 프로세서 서브유닛을 포함하는 프로세싱 어레이; 및 집적회로의 동작에 대한 적어도 하나의 보안 조치를 이행하도록 구성된 컨트롤러를 포함하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제26항에 있어서, 상기 컨트롤러는 상기 적어도 하나의 보안 조치가 촉발되는 경우에 하나 이상의 해결책을 취하도록 더 구성된것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "기판; 상기 기판 상에 배치되고 복수의 이산 메모리 뱅크를 포함하는 메모리 어레이; 상기 기판 상에 배치되고 상기 복수의 이산 메모리 뱅크 중의 하나 이상의 이산 메모리 뱅크와 각각 연관되는복수의 프로세서 서브유닛을 포함하는 프로세싱 어레이; 및 분산 프로세서 메모리 칩과, 다른 분산 프로세서 메모리 칩이 아닌, 외부 엔티티 사이의 통신 연결을 구축하도록 구성된 제1 통신 포트; 및 상기 분산 프로세서 메모리 칩과 제1 추가 분산 프로세서 메모리 칩 사이의 통신 연결을 구축하도록 구성된 제2통신 포트를 포함하는 분산 프로세스 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제28항에 있어서, 상기 분산 프로세서 메모리 칩과 제2 추가 분산 프로세시 메모리 칩 사이의 통신 연결을 구축하도록 구성된 제3통신 포트를 더 포함하는 분산 프로세서 메모리 칩. 공개특허 10-2022-0078566-6-청구항 30 제29항에 있어서, 상기 제1 통신 포트, 상기 제2 통신 포트, 상기 제3 통신 포트 중의 적어도 하나를 통하여 통신을 제어하도록구성된 컨트롤러를 더 포함하는 분산 프로세서 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제29항에 있어서, 상기 제1 통신 포트, 상기 제2 통신 포트, 상기 제3 통신 포트는 각각 상응하는 버스와 연관되는 것을 특징으로하는 분산 프로세서 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제31항에 있어서, 상기 상응하는 버스는 상기 제1 통신 포트, 상기 제2 통신 포트, 상기 제3 통신 포트의 각각에 공통인 버스인것을 특징으로 하는 분산 프로세서 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "제31항에 있어서, 상기 제1 통신 포트, 상기 제2 통신 포트, 상기 제3 통신 포트의 각각과 연관된 상기 상응하는 버스는 모두 상기 복수의 분산 메모리 뱅크에 연결되는 것을 특징으로 하는 분산 프로세서 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제31항에 있어서, 상기 제1 통신 포트, 상기 제2 통신 포트, 상기 제3 통신 포트와 연관된 적어도 하나의 버스는 단방향성(unidirectional)인 것을 특징으로 하는 분산 프로세서 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "제31항에 있어서, 상기 제1 통신 포트, 상기 제2 통신 포트, 상기 제3 통신 포트와 연관된 적어도 하나의 버스는 양방향성(bidirectional)인 것을 특징으로 하는 분산 프로세서 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "제30항에 있어서,상기 컨트롤러는 상기 분산 프로세서 메모리 칩과 상기 제1 추가 분산 프로세서 메모리 칩 사이의 데이터 전송을 예정하여, 상기 데이터 전송에 의거하고 상기 데이터 전송이 수신되는 시간 주기 동안에 상기 제1 추가 분산프로세서 메모리 칩의 수신 프로세서 서브유닛이 그와 연관된 프로그램 코드를 실행하게 하도록 구성된 것을 특징으로 하는 분산 프로세서 메모리 칩. 공개특허 10-2022-0078566-7-청구항 37 제30항에 있어서, 상기 컨트롤러는 상기 분산 프로세서 메모리 칩의 상기 복수의 프로세서 서브유닛의 적어도 하나의 프로세서 서브유닛으로 클럭 인에이블 신호(clock enable signal)를 전송하여 상기 복수의 프로세서 서브유닛의 상기 적어도 하나의 프로세서 서브유닛의 하나 이상의 동작 양상을 제어하도록 구성된 것을 특징으로 하는 분산 프로세서메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_38", "content": "제37항에 있어서, 상기 컨트롤러는 상기 복수의 프로세서 서브유닛의 상기 적어도 하나의 프로세서 서브유닛으로 전송된 상기 클럭 인에이블 신호를 제어하여 상기 복수의 프로세서 서브유닛의 상기 적어도 하나의 프로세서 서브유닛과 연관된 하나 이상의 통신 명령의 타이밍을 제어하도록 구성된 것을 특징으로 하는 분산 프로세서 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_39", "content": "제30항에 있어서, 상기 컨트롤러는 상기 분산 프로세서 메모리 칩의 상기 복수의 프로세서 서브유닛의 하나 이상의 프로세서 서브유닛에 의한 프로그램 코드의 실행을 선택적으로 시작하도록 구성된 것을 특징으로 하는 분산 프로세서 메모리칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_40", "content": "제30항에 있어서, 상기 컨트롤러는 클럭 인에이블 신호를 활용하여 상기 복수의 프로세서 서브유닛의 하나 이상의 프로세서 서브유닛으로부터 상기 제2 통신 포트 및 상기 제3 통신 포트의 적어도 하나로의 데이터 전송의 타이밍을 제어하도록 구성된 것을 특징으로 하는 분산 프로세서 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_41", "content": "제28항에 있어서, 상기 제1 통신 포트와 연관된 통신 속도는 상기 제2 통신 포트와 연관된 통신 속도보다 낮은 것을 특징으로 하는 분산 프로세서 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_42", "content": "제30항에 있어서,상기 컨트롤러는 상기 복수의 프로세서 서브유닛 중의 제1 프로세서 서브유닛이 상기 제1 추가 분산 프로세서메모리 칩에 포함된 제2 프로세서 서브유닛으로 데이터를 전송할 준비가 되었는지 여부를 판단하고 상기 제1 프로세서 서브유닛이 상기 데이터를 상기 제2 프로세서 서브유닛으로 전송할 준비가 되었다고 판단한 이후에 클럭인에이블 신호를 활용하여 상기 제1 프로세서 서브유닛으로부터 상기 제2 프로세서 서브유닛으로의 데이터의 전송을 개시하도록 구성된 것을 특징으로 하는 분산 프로세서 메모리 칩. 공개특허 10-2022-0078566-8-청구항 43 제42항에 있어서,상기 컨트롤러는 상기 제2 프로세서 서브유닛이 상기 데이터를 수신할 준비가 되었는지 여부를 판단하고 상기제2 프로세서 서브유닛이 상기 데이터를 수신할 준비가 되었다고 판단한 이후에 상기 클럭 인에이블 신호를 활용하여 상기 제1 프로세서 서브유닛으로부터 상기 제2 프로세서 서브유닛으로의 상기 데이터의 상기 전송을 개시하도록 더 구성된 것을 특징으로 하는 분산 프로세서 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_44", "content": "제42항에 있어서, 상기 컨트롤러는 상기 제2 프로세서 서브유닛이 상기 데이터를 수신할 준비가 되었는지 여부를 판단하고 상기제1 추가 분산 프로세서 메모리 칩의 상기 제2 프로세서 서브유닛이 상기 데이터를 수신할 준비가 되었다는 판단 이후까지 상기 전송에 포함된 상기 데이터를 버퍼(buffer)하도록 더 구성된 것을 특징으로 하는 분산 프로세서 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_45", "content": "제1 분산 프로세서 메모리 칩과 제2 분산 프로세서 메모리 칩 사이에 데이터를 전송하는 방법에 있어서, 상기 제1 분산 프로세서 메모리 칩 상에 배치된 복수의 프로세서 서브유닛 중의 제1 프로세서 서브유닛이 상기제2 분산 프로세서 메모리 칩에 포함된 제2 프로세서 서브유닛으로 데이터를 전송할 준비가 되었는지 여부를 상기 제1 분산 프로세서 메모리 칩과 상기 제2 분산 프로세서 메모리 칩 중의 적어도 하나와 연관된 컨트롤러를사용하여 판단하는 단계; 및 상기 제1 프로세서 서브유닛이 상기 제2 프로세서 서브유닛으로 상기 데이터를 전송할 준비가 되었다는 판단을한 후에 상기 컨트롤러에 의해 제어되는 클럭 인에이블 신호를 활용하여 상기 제1 프로세서 서브유닛에서 상기제2 프로세서 서브유닛으로 상기 데이터의 전송을 개시하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_46", "content": "제45항에 있어서,상기 제2 프로세서 서브유닛이 상기 데이터를 수신할 준비가 되었는지 여부를 상기 컨트롤러를 활용하여 판단하는 단계; 및 상기 제2 프로세서 서브유닛이 상기 데이터를 수신할 준비가 되었다고 판단한 이후에 상기 클럭 인에이블 신호를 활용하여 상기 제1 프로세서 서브유닛으로부터 상기 제2 프로세서 서브유닛으로의 상기 데이터의 상기 전송을 개시하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_47", "content": "제45항에 있어서, 상기 제2 프로세서 서브유닛이 상기 데이터를 수신할 준비가 되었는지 여부를 판단하고 상기 제1 추가 분산 프로세서 메모리 칩의 상기 제2 프로세서 서브유닛이 상기 데이터를 수신할 준비가 되었다는 판단 이후까지 상기전송에 포함된 상기 데이터를 버퍼(buffer)하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_48", "content": "공개특허 10-2022-0078566-9-기판; 상기 기판 상에 배치되고 복수의 이산 메모리 뱅크를 포함하는 메모리 어레이; 메모리 칩과, 다른 메모리 칩이 아닌, 외부 엔티티 사이의 통신 연결을 구축하도록 구성된 제1 통신 포트; 및 상기 메모리 칩과 제1 추가 메모리 칩 사이의 통신 연결을 구축하도록 구성된 제2 통신 포트를 포함하는 메모리칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_49", "content": "제48항에 있어서, 상기 제1 통신 포트는 상기 메모리 칩 내부의 메인 버스 및 상기 메모리 칩에 포함된 적어도 하나의 프로세서서브유닛 중의 적어도 하나로 연결되는 것을 특징으로 하는 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_50", "content": "제48항에 있어서,상기 제2 통신 포트는 상기 메모리 칩 내부의 메인 버스 및 상기 메모리 칩에 포함된 적어도 하나의 프로세서서브유닛 중의 적어도 하나로 연결되는 것을 특징으로 하는 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_51", "content": "복수의 메모리 뱅크를 포함하는 메모리 어레이; 상기 복수의 메모리 뱅크에 대한 읽기 동작의 적어도 일 양상을 제어하도록 구성된 적어도 하나의 컨트롤러; 및 상기 복수의 메모리 뱅크의 특정 주소에 저장된 데이터와 연관된 다중 비트 0값을 검출하도록 구성된 적어도 하나의 0값 검출 논리부를 포함하고, 상기 적어도 하나의 컨트롤러는 상기 적어도 하나의 0값 검출 논리부에 의한 0값 검출에 응답하여 0값 지시자를하나 이상의 회로로 보내도록 구성된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_52", "content": "제51항에 있어서, 상기 0값 지시자가 보내지는 상기 하나 이상의 회로는 상기 메모리 유닛의 외부에 있는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_53", "content": "제51항에 있어서, 상기 0값 지시자가 보내지는 상기 하나 이상의 회로는 상기 메모리 유닛의 내부에 있는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_54", "content": "제51항에 있어서, 상기 적어도 하나의 0값 검출 논리부가 상기 특정 주소와 연관된 0값을 검출하는 경우에 상기 특정 주소와 연관공개특허 10-2022-0078566-10-된 읽기 명령을 중단시키도록 구성된 적어도 하나의 읽기 비활성 요소를 더 포함하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_55", "content": "제51항에 있어서, 상기 적어도 하나의 컨트롤러는 상기 특정 주소에 저장된 상기 0값 데이터를 전송하는 대신에 상기 0값 지시자를 상기 하나 이상의 회로에 전송하도록 구성된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_56", "content": "제51항에 있어서,상기 0값 지시자의 사이즈는 상기 0값 데이터의 사이즈보다 작은 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_57", "content": "제51항에 있어서,(a) 상기 0값의 검출, (b) 상기 0값 지시자의 생성, 및 (c) 상기 하나 이상의 회로로 상기 0값 지시자의 전송을포함하는 제1 프로세스에 의해 소비되는 에너지는 상기 0값 데이터를 상기 하나 이상의 회로로 전송하여 소비되는 에너지보다 작은 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_58", "content": "제57항에 있어서, 상기 제1 프로세스에 의해 소비된 상기 에너지는 상기 하나 이상의 회로로 상기 0값 데이터를전송하여 소비된 상기 에너지의 절반보다 작은 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_59", "content": "제51항에 있어서, 상기 적어도 하나의 0값 검출 논리부에 의한 0값 검출 이후에 상기 복수의 메모리 뱅크의 적어도 하나의 메모리뱅크의 활성화를 배제하도록 구성된 적어도 하나의 센스 증폭기를 더 포함하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_60", "content": "제59항에 있어서, 상기 적어도 하나의 센스 증폭기는 상기 복수의 메모리 뱅크로부터 저전력 신호를 감지하고, 상기 복수의 메모리 뱅크에 저장된 데이터가 상기 적어도 하나의 컨트롤러에 의해 해석될 수 있도록 작은 전압 스윙을 높은 전압레벨로 증폭하도록 구성된 복수의 트랜지스터를 포함하는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_61", "content": "제51항에 있어서, 상기 복수의 메모리 뱅크의 각 메모리 뱅크는 서브뱅크로 더 정리되고, 상기 적어도 하나의 컨트롤러는 서브뱅크 컨트롤러를 포함하고, 상기 적어도 하나의 0값 검출 논리부는 상기 서브뱅크와 연관된 0값 검출 로직을 포함하는 것을 특징으로 하는 메모리 유닛. 공개특허 10-2022-0078566-11-청구항 62 제61항에 있어서, 상기 서브뱅크의 각각에 연관된 센스 증폭기를 포함하는 적어도 하나의 읽기 비활성 요소를 더 포함하는 메모리유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_63", "content": "제51항에 있어서, 상기 메모리 유닛 내에 공간적으로 분산된 복수의 프로세서 서브유닛을 더 포함하고, 상기 복수의 프로세서 서브유닛의 각 프로세서 서브유닛은 상기 복수의 메모리 뱅크의 전용의 적어도 하나의 메모리 뱅크와 연관되고,상기 복수의 프로세서 서브유닛의 각 프로세서 서브유닛은 상응하는 메모리 뱅크에 저장된 데이터에 접근하고운용하도록 구성된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_64", "content": "제63항에 있어서, 상기 하나 이상의 회로는 상기 프로세서 서브유닛의 하나 이상을 포함하는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_65", "content": "제63항에 있어서, 상기 복수의 프로세서 서브유닛의 각 프로세서 서브유닛은 하나 이상의 버스에 의해 상기 복수의 프로세서 서브유닛의 둘 이상의 다른 프로세서 서브유닛으로 연결되는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_66", "content": "제51항에 있어서, 복수의 버스를 더 포함하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_67", "content": "제66항에 있어서, 상기 복수의 버스는 상기 복수의 메모리 뱅크 사이에 데이터를 전송하도록 구성된 것을 특징으로 하는 메모리유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_68", "content": "제67항에 있어서,상기 복수의 버스의 적어도 하나는 상기 하나의 회로로 상기 0값 지시자를 전송하도록 구성된 것을 특징으로 하는 메모리 유닛. 공개특허 10-2022-0078566-12-청구항 69 복수의 메모리 뱅크의 주소에 저장된 데이터의 읽기 요청을 메모리 유닛 외부의 회로로부터 수신하는 단계; 상기 수신된 요청에 응답하여 0값 검출 논리부를 활성화하여, 상기 수신된 주소에서 컨트롤러가 0값을 검출하는단계; 및 상기 0값 검출 논리부에 의한 상기 0값 검출에 응답하여 상기 컨트롤러가 0값 지시자를 상기 회로로 전송하는단계를 포함하는, 복수의 메모리 뱅크의 특정 주소에서 0값을 검출하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_70", "content": "제69항에 있어서,상기 0값 검출 논리부가 상기 요청된 주소와 연관된 0값을 검출하는 경우에, 상기 컨트롤러가 상기 요청된 주소와 연관된 읽기 명령을 중단시키도록 읽기 비활성 요소를 구성하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_71", "content": "제69항에 있어서, 상기 0값 검출 논리부가 0값을 검출하는 경우에, 상기 컨트롤러가 상기 복수의 메모리 뱅크의 적어도 하나의 메모리 뱅크의 활성화를 배제시키도록 센스 증폭기를 구성하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_72", "content": "메모리 유닛이 복수의 메모리 뱅크의 특정 주소에서 0값을 검출하게 유발하도록 상기 메모리 유닛의 컨트롤러에의해 실행 가능한 지시의 세트를 저장하는 비일시적 컴퓨터 판독가능 매체에 있어서, 상기 방법은: 복수의 메모리 뱅크의 주소에 저장된 데이터의 읽기 요청을 메모리 유닛 외부의 회로로부터 수신하는 단계; 상기 수신된 요청에 응답하여 0값 검출 논리부를 활성화하여, 상기 수신된 주소에서 컨트롤러가 0값을 검출하는단계; 및 상기 0값 검출 논리부에 의한 상기 0값 검출에 응답하여 상기 컨트롤러가 0값 지시자를 상기 회로로 전송하는단계를 포함하는 것을 특징으로 하는, 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_73", "content": "제72항에 있어서, 상기 방법은 상기 0값 검출 논리부가 상기 요청된 주소와 연관된 0값을 검출하는 경우에, 상기 컨트롤러가 상기요청된 주소와 연관된 읽기 명령을 중단시키도록 읽기 비활성 요소를 구성하는 단계를 더 포함하는 것을 특징으로 하는 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_74", "content": "제72항에 있어서, 상기 방법은 상기 0값 검출 논리부가 0값을 검출하는 경우에, 상기 컨트롤러가 상기 복수의 메모리 뱅크의 적어도 하나의 메모리 뱅크의 활성화를 배제시키도록 센스 증폭기를 구성하는 단계를 더 포함하는 것을 특징으로 하는 비일시적 컴퓨터 판독가능 매체. 공개특허 10-2022-0078566-13-청구항 75 복수의 메모리 뱅크, 상기 복수의 메모리 뱅크에 대한 읽기 동작의 적어도 일 양상을 제어하도록 구성된 적어도하나의 컨트롤러, 및 상기 복수의 메모리 뱅크의 특정 주소에 저장된 데이터와 연관된 다중 비트 0값을 검출하도록 구성된 적어도 하나의 0값 검출 논리부를 포함하는 메모리 유닛; 및상기 메모리 뱅크로부터 데이터를 읽을 읽기 요청을 상기 메모리 유닛으로 전송하도록 구성된 프로세싱 유닛을포함하고, 상기 적어도 하나의 컨트롤러와 적어도 하나의 0값 검출 논리부는 상기 적어도 하나의 0값 검출 논리부에 의한0값 검출에 응답하여 0값 지시자를 하나 이상의 회로로 보내도록 구성된 것을 특징으로 하는 집적회로."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_76", "content": "복수의 메모리 뱅크를 포함하는 메모리 어레이; 상기 복수의 메모리 뱅크에 대한 읽기 동작의 적어도 일 양상을 제어하도록 구성된 적어도 하나의 컨트롤러; 및 상기 복수의 메모리 뱅크의 특정 주소에 저장된 데이터와 연관된 소정의 다중 비트 값을 검출하도록 구성된 적어도 하나의 검출 논리부를 포함하고, 상기 적어도 하나의 컨트롤러는 상기 적어도 하나의 검출 논리부에 의한 상기 소정의 다중 비트 값의 검출에 응답하여 값 지시자를 하나 이상의 회로로 보내도록 구성된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_77", "content": "제76항에 있어서,상기 소정의 다중 비트 값은 사용자에 의해 선택 가능한 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_78", "content": "복수의 메모리 뱅크를 포함하는 메모리 어레이; 상기 복수의 메모리 뱅크에 대한 쓰기 동작의 적어도 일 양상을 제어하도록 구성된 적어도 하나의 컨트롤러; 및 상기 복수의 메모리 뱅크의 특정 주소에 기록될 데이터와 연관된 소정의 다중 비트 값을 검출하도록 구성된 적어도 하나의 검출 논리부를 포함하고, 상기 적어도 하나의 컨트롤러는 상기 적어도 하나의 검출 논리부에 의한 상기 소정의 다중 비트 값의 검출에 응답하여 값 지시자를 하나 이상의 회로로 보내도록 구성된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_79", "content": "기판; 상기 기판에 배치된 복수의 메모리 뱅크를 포함하는 메모리 어레이; 상기 기판에 배치된 복수의 프로세서 서브유닛; 상기 복수의 메모리 뱅크에 대한 읽기 동작의 적어도 일 양상을 제어하도록 구성된 적어도 하나의 컨트롤러; 및 상기 복수의 메모리 뱅크의 특정 주소에 저장된 데이터와 연관된 소정의 다중 비트 값을 검출하도록 구성된 적어도 하나의 검출 논리부를 포함하고, 상기 적어도 하나의 컨트롤러는 상기 적어도 하나의 검출 논리부에 의한 상기 소정의 다중 비트 값의 검출에 응답하여 값 지시자를 상기 복수의 프로세서 서브유닛의 하나 이상으로 보내도록 구성된 것을 특징으로 하는 분산공개특허 10-2022-0078566-14-프로세서 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_80", "content": "하나 이상의 메모리 뱅크; 뱅크 컨트롤러; 및 어드레스 생성기를 포함하고, 상기 어드레스 생성기는: 상기 하나 이상의 메모리 뱅크의 연관된 메모리 뱅크 내에서 접근될 현재 행의 현재 주소를 상기 뱅크 컨트롤러로 제공하고; 상기 연관된 메모리 뱅크 내에서 접근될 다음 행의 예측 주소를 판단하고; 상기 현재 어드레스와 연관된 상기 현재 행에 대한 동작이 완료되기 전에 상기 뱅크 컨트롤러로 상기 예측 주소를 제공하도록 구성된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_81", "content": "제80항에 있어서, 상기 현재 어드레스와 연관된 상기 현재 행에 대한 상기 동작은 읽기 동작 또는 쓰기 동작인 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_82", "content": "제80항에 있어서, 상기 현재 행과 상기 다음 행은 동일한 메모리 뱅크에 있는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_83", "content": "제82항에 있어서, 상기 동일한 메모리 뱅크는 상기 현재 행이 접근되는 동안에 상기 다음 행이 접근되도록 하는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_84", "content": "제80항에 있어서, 상기 현재 행과 상기 다음 행은 서로 상이한 메모리 뱅크에 있는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_85", "content": "제80항에 있어서,분산 프로세서를 더 포함하고, 상기 분산 프로세서는 상기 메모리 어레이의 복수의 이산 메모리 뱅크 중에 공간적으로 분산된 프로세싱 어레이의 복수의 프로세서 서브유닛을 포함하는 것을 특징으로 하는 메모리 유닛.공개특허 10-2022-0078566-15-청구항 86 제80항에 있어서,상기 뱅크 컨트롤러는 상기 현재 행에 접근하고 상기 현재 행에 대한 상기 동작의 완료 이전에 상기 다음 행을활성화하도록 구성된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_87", "content": "제80항에 있어서,상기 하나 이상의 메모리 뱅크는 각각 적어도 제1 서브 뱅크 및 제2 서브 뱅크를 포함하고, 상기 하나 이상의메모리 뱅크의 각각과 연관된 상기 뱅크 컨트롤러는 상기 제1 서브뱅크와 연관된 제1 서브뱅크 컨트롤러 및 상기 제2 서브뱅크와 연관된 제2 서브뱅크 컨트롤러를 포함하는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_88", "content": "제87항에 있어서,상기 제1 서브뱅크 컨트롤러는 상기 제2 서브뱅크 컨트롤러가 상기 제2 서브뱅크에서 다음 행을 활성화하는 동안에 상기 제1 서브뱅크의 현재 행에 포함된 데이터의 접근을 가능하게 하도록 구성된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_89", "content": "제88항에 있어서,제2 서브뱅크의 상기 활성화된 다음 행은 데이터가 접근되고 있는 상기 제1 서브뱅크의 상기 현재 행으로부터적어도 2행만큼 이격된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_90", "content": "제87항에 있어서,상기 제2 서브뱅크 컨트롤러는 상기 제1 서브뱅크 컨트롤러가 상기 제1 서브뱅크의 다음 행을 활성화하는 동안에 상기 제2 서브뱅크의 현재 행에 포함된 데이터로의 접근을 유발하도록 구성된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_91", "content": "제90항에 있어서,제1 서브뱅크의 상기 활성화된 다음 행은 데이터가 접근되고 있는 상기 제2 서브뱅크의 상기 현재 행으로부터적어도 2행만큼 이격된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_92", "content": "제80항에 있어서,공개특허 10-2022-0078566-16-상기 예측 주소는 학습 신경망을 활용하여 판단되는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_93", "content": "제80항에 있어서,상기 예측 주소는 판단된 라인 접근 패턴에 기초하여 판단되는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_94", "content": "제80항에 있어서,상기 어드레스 생성기는 상기 현재 주소를 생성하도록 구성된 제1 어드레스 생성기 및 상기 예측 주소를 생성하도록 구성된 제2 어드레스 생성기를 포함하는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_95", "content": "제94항에 있어서,상기 제2 어드레스 생성기는 상기 제1 어드레스 생성기가 상기 현재 주소를 생성한 이후에 소정의 시간 주기 이내에 상기 예측 주소를 계산하도록 구성된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_96", "content": "제95항에 있어서,상기 소정의 시간 주기는 조정 가능한 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_97", "content": "제96항에 있어서,상기 소정의 시간 주기는 상기 메모리 유닛과 연관된 적어도 하나의 동작 파라미터의 값에 의거하여 조정되는것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_98", "content": "제97항에 있어서,상기 적어도 하나의 동작 파라미터는 상기 메모리 유닛의 온도를 포함하는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_99", "content": "제80항에 있어서,상기 어드레스 생성기는 상기 예측 주소와 연관된 신뢰 수준을 생성하고 상기 신뢰 수준의 소정의 임계값 아래로 떨어지는 경우에 상기 뱅크 컨트롤러로 하여금 상기 예측 주소에 있는 상기 다음 행의 접근을 포기하게 유발하도록 더 구성된 것을 특징으로 하는 메모리 유닛. 공개특허 10-2022-0078566-17-청구항 100 제80항에 있어서,상기 예측 주소는 지연 생성되는 상기 주소를 샘플링 하는 일련의 플립플롭(chain of flip flops)에 의해 생성되는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_101", "content": "제100항에 있어서,상기 지연은 상기 샘플링 된 주소를 저장하는 플립플롭 간의 선택을 하는 멀티플렉서를 통해 설정 가능한 것을특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_102", "content": "제80항에 있어서,상기 뱅크 컨트롤러는 상기 메모리 유닛의 리셋 이후의 소정의 주기 동안에 상기 어드레스 생성기로부터 수신된예측 주소를 무시하도록 구성된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_103", "content": "제80항에 있어서,상기 어드레스 생성기는 상기 연관된 메모리 뱅크에 관련된 행 접근에서 무작위 패턴을 검출한 후에 상기 뱅크컨트롤러로 상기 예측 주소를 제공하는 것을 포기하도록 구성된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_104", "content": "하나 이상의 메모리 뱅크를 포함하고, 상기 하나 이상의 메모리 뱅크의 각 메모리 뱅크는: 복수의 행; 상기 복수의 행의 제1 서브세트를 제어하도록 구성된 제1 행 컨트롤러; 상기 복수의 행의 제2 서브세트를 제어하도록 구성된 제2 행 컨트롤러; 상기 복수의 행에 저장될 데이터를 수신하기 위한 단일 데이터 입력; 및 상기 복수의 행으로부터 가져온 데이터를 제공하기 위한 단일 데이터 출력을 포함하는 것을 특징으로 하는 메모리 뱅크."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_105", "content": "제104항에 있어서,상기 메모리 유닛은 프로세싱을 위한 제1 주소와 소정의 시간에 활성화 및 접근을 하기 위한 제2 주소를 수신하도록 구성된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_106", "content": "제104항에 있어서,공개특허 10-2022-0078566-18-상기 복수의 행의 상기 제1 서브세트는 짝수 번호의 행들로 구성된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_107", "content": "제106항에 있어서,상기 짝수 번호의 행들은 상기 하나 이상의 메모리 뱅크의 절반에 배치된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_108", "content": "제106항에 있어서,홀수 번호의 행들은 상기 하나 이상의 메모리 뱅크의 절반에 배치된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_109", "content": "제104항에 있어서,상기 복수의 행의 상기 제2 서브세트는 홀수 번호의 행들로 구성된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_110", "content": "제104항에 있어서,상기 복수의 행의 상기 제1 서브세트는 상기 복수의 행의 제2 서브세트를 포함하는 메모리 뱅크의 제2 서브뱅크에 인접한 상기 메모리 뱅크의 제1 서브뱅크에 포함되는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_111", "content": "제104항에 있어서,상기 제1 행 컨트롤러는 상기 제2 행 컨트롤러가 상기 복수의 행의 상기 제2 서브세트 중의 행을 활성화하는 동안에 상기 복수의 행의 상기 제1 서브세트 중의 행에 포함된 데이터의 접근을 유발하도록 구성된 것을 특징으로하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_112", "content": "제111항에 있어서,상기 복수의 행의 상기 제2 서브세트 중의 상기 활성화된 행은 데이터가 접근되고 있는 상기 복수의 행의 상기제1 서브세트의 상기 행으로부터 적어도 2행만큼 이격된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_113", "content": "제104항에 있어서,상기 제2 행 컨트롤러는 상기 제1 행 컨트롤러가 상기 복수의 행의 상기 제2 서브세트 중의 행을 활성화하는 동안에 상기 복수의 행의 상기 제2 서브세트 중의 행에 포함된 데이터의 접근을 유발하도록 구성된 것을 특징으로하는 메모리 유닛. 공개특허 10-2022-0078566-19-청구항 114 제113항에 있어서,상기 복수의 행의 상기 제1 서브세트 중의 상기 활성화된 행은 데이터가 접근되고 있는 상기 복수의 행의 상기제2 서브세트의 상기 행으로부터 적어도 2행만큼 이격된 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_115", "content": "제104항에 있어서,상기 하나 이상의 메모리 뱅크의 각 메모리 뱅크는 접근될 행의 부분을 지시하는 열 식별자를 수신하기 위한 열입력을 포함하는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_116", "content": "제104항에 있어서,한 라인의 가외 중복 매트가 각각의 두 매트 라인 사이에 배치되어 활성화를 허용하기 위한 거리를 형성하는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_117", "content": "제104항에 있어서,서로 근접한 라인들은 동시에 활성화되지 않는 것을 특징으로 하는 메모리 유닛."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_118", "content": "기판; 상기 기판 상에 배치되고 복수의 이산 메모리 뱅크를 포함하는 메모리 어레이; 상기 기판 상에 배치되고 상기 복수의 이산 메모리 뱅크 중에서 상응하는 전용 이산 메모리 뱅크와 각각 연관되는 복수의 프로세서 서브유닛을 포함하는 프로세싱 어레이; 및 상기 기판 상에 배치되고 상기 복수의 프로세서 서브유닛의 하나 이상의 프로세서 서브유닛에 대한 레지스터 파일의 적어도 하나의 레지스터 역할을 하도록 구성된 적어도 하나의 메모리 매트를 포함하는 메모리 칩 상의 분산 프로세서."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_119", "content": "제118항에 있어서, 상기 적어도 하나의 메모리 매트는 상기 프로세싱 어레이의 상기 복수의 프로세서 서브유닛의 적어도 하나의 프로세서 서브유닛에 포함된 것을 특징으로 하는 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_120", "content": "제118항에 있어서, 공개특허 10-2022-0078566-20-상기 레지스터 파일은 데이터 레지스터 파일로서 구성된 것을 특징으로 하는 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_121", "content": "제118항에 있어서, 상기 레지스터 파일은 어드레스 레지스터 파일로서 구성된 것을 특징으로 하는 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_122", "content": "제118항에 있어서, 상기 적어도 하나의 메모리 매트는 상기 복수의 프로세서 서브유닛의 하나 이상의 프로세서 서브유닛에 의해 접근될 데이터를 저장할 상기 복수의 프로세서 서브유닛의 하나 이상의 프로세서 서브유닛에 대한 레지스터 파일의 적어도 하나의 레지스터를 제공하도록 구성된 것을 특징으로 하는 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_123", "content": "제118항에 있어서, 상기 적어도 하나의 메모리 매트는 상기 복수의 프로세서 서브유닛의 하나 이상의 프로세서 서브유닛에 대한 레지스터 파일의 적어도 하나의 레지스터를 제공하도록 구성되고, 상기 레지스터 파일의 상기 적어도 하나의 레지스터는 상기 복수의 프로세서 서브유닛에 의한 컨볼루션 가속기 동작(convolution accelerator operations)의실행 동안에 상기 복수의 프로세서 서브유닛에 의해 사용되는 계수를 저장하도록 구성된 것을 특징으로 하는 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_124", "content": "제118항에 있어서, 상기 적어도 하나의 메모리 매트는 DRAM 메모리 매트인 것을 특징으로 하는 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_125", "content": "제118항에 있어서, 상기 적어도 하나의 메모리 매트는 일방향 접근을 통해 통신하도록 구성된 것을 특징으로 하는 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_126", "content": "제118항에 있어서, 상기 적어도 하나의 메모리 매트는 양방향 접근을 허용하는 것을 특징으로 하는 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_127", "content": "제118항에 있어서, 상기 기판 상에 배치된 적어도 하나의 중복 메모리 매트를 더 포함하고, 상기 적어도 하나의 중복 메모리 매트는 상기 복수의 프로세서 서브유닛의 하나 이상의 프로세서 서브유닛에 대해 적어도 하나의 중복 레지스터를 제공하도록 구성된 것을 특징으로 하는 메모리 칩.공개특허 10-2022-0078566-21-청구항 128 제118항에 있어서, 상기 기판 상에 배치된 적어도 하나의 중복 메모리 매트를 더 포함하고, 상기 적어도 하나의 중복 메모리 매트는 상기 복수의 프로세서 서브유닛의 하나 이상의 프로세서 서브유닛에 대한 적어도 하나의 중복 레지스터를 제공하도록 구성된 적어도 하나의 중복 메모리 비트를 포함하는 것을 특징으로 하는 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_129", "content": "제118항에 있어서, 각각 상기 복수의 프로세서 서브유닛의 한 프로세서 서브유닛을 그에 상응하는 전용 메모리 뱅크에 연결하는 제1 복수의 버스; 및 각각 상기 복수의 프로세서 서브유닛의 한 프로세서 서브유닛을 상기 복수의 프로세서 서브유닛의 다른 프로세서 서브유닛에 연결하는 제2 복수의 버스를 더 포함하는 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_130", "content": "제118항에 있어서, 상기 복수의 프로세서 서브유닛의 적어도 하나의 프로세서 서브유닛은 소정의 숫자로부터 거꾸로 세도록 구성된카운터를 포함하고, 상기 카운터가 0값에 도달하면 상기 복수의 프로세서 서브유닛의 상기 적어도 하나의 프로세서 서브유닛은 현재 작업을 중단하고 메모리 리프레시 동작을 촉발하도록 구성된 것을 특징으로 하는 메모리칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_131", "content": "제118항에 있어서, 상기 복수의 프로세서 서브유닛의 적어도 하나의 프로세서 서브유닛은 현재 작업을 중단하고 특정 시간에 메모리 리프레시 동작을 촉발하여 상기 메모리 매트를 리프레시하는 메커니즘을 포함하는 것을 특징으로 하는 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_132", "content": "제118항에 있어서, 상기 레지스터 파일은 캐시로서 사용되도록 구성된 것을 특징으로 하는 메모리 칩."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_133", "content": "분산 프로세서 메모리 칩의 메모리 어레이에서 하나 이상의 데이터 값을 가져오는 단계; 상기 하나 이상의 데이터 값을 상기 분산 프로세서 메모리 칩의 메모리 매트에 형성된 레지스터에 저장하는 단계; 및 프로세서 요소에 의해 실행된 적어도 하나의 명령에 따라, 상기 레지스터에 저장된 상기 하나 이상의 데이터 값에 접근하는 단계를 포함하고, 상기 메모리 어레이는 기판 상에 배치된 복수의 이산 메모리 뱅크를 포함하고, 공개특허 10-2022-0078566-22-상기 프로세서 요소는 상기 기판 상에 배치된 프로세싱 어레이에 포함된 복수의 프로세서 서브유닛 중의 프로세서 서브유닛이고, 상기 프로세서 서브 유닛 각각은 상기 복수의 이산 메모리 뱅크의 상응하는 전용 이산 메모리뱅크와 연관되고, 상기 레지스터는 상기 기판 상에 배치된 메모리 매트에 의해 제공되는 것을 특징으로 하는, 분산 프로세서 메모리 칩의 적어도 하나의 명령을 실행하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_134", "content": "제133항에 있어서, 상기 프로세서 요소는 가속기로서 기능하도록 구성되는 것을 특징으로 하고, 상기 레지스터에 저장된 제1 데이터에 접근하는 단계: 상기 메모리 어레이로부터 제2 데이터에 접근하는 단계; 및 상기 제1 데이터 및 상기 제2 데이터에 연산을 수행하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_135", "content": "제133항에 있어서, 상기 적어도 하나의 메모리 매트는 복수의 워드라인과 비트라인을 포함하는 것을 특징으로 하고, 상기 메모리 매트의 사이즈에 따라 상기 워드라인과 상기 비트라인을 로드하는 타이밍을 판단하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_136", "content": "제133항에 있어서, 상기 레지스터를 주기적으로 리프레시하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_137", "content": "제133항에 있어서, 상기 메모리 매트는 DRAM 메모리 매트를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_138", "content": "제133항에 있어서, 상기 메모리 매트는 상기 메모리 어레이의 상기 복수의 이산 메모리 뱅크에 포함된 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_139", "content": "기판; 상기 기판 상에 배치된 프로세싱 유닛; 및 상기 기판 상에 배치된 메모리 유닛을 포함하고, 상기 메모리 유닛은 상기 프로세싱 유닛에 의해 접근될 데이터를 저장하도록 구성되고, 공개특허 10-2022-0078566-23-상기 프로세싱 유닛은 상기 프로세싱 유닛에 대한 캐시 역할을 하도록 구성된 메모리 매트를 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_140", "content": "적어도 하나의 정보 스트림의 분산 프로세싱을 위한 방법에 있어서, 상기 방법은: 하나 이상의 메모리 프로세싱 집적회로가 적어도 하나의 정보 스트림을 제1 통신 채널을 통해 수신하는 단계―여기서, 각 메모리 프로세싱 집적회로는 컨트롤러, 다중 프로세서 서브유닛, 및 다중 메모리 유닛을 포함함; 상기 하나 이상의 메모리 프로세싱 집적회로가 상기 적어도 하나의 정보 스트림을 버퍼링 하는 단계; 상기 하나 이상의 메모리 프로세싱 집적회로가 상기 적어도 하나의 정보 스트림에 대한 1차 처리 동작을 수행하여 1차 처리 결과를 제공하는 단계; 상기 1차 처리 결과를 프로세싱 집적회로로 전송하는 단계; 및 상기 하나 이상의 메모리 프로세싱 집적회로가 상기 1차 처리 결과에 대한 2차 처리 동작을 수행하여 2차 처리결과를 제공하는 단계를 포함하고, 상기 하나 이상의 메모리 프로세싱 집적회로의 로직 셀의 사이즈는 상기 프로세싱 집적회로의 로직 셀의 사이즈보다 작은 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_141", "content": "제140항에 있어서, 상기 다중 메모리 유닛의 각각은 상기 다중 프로세서 서브유닛의 적어도 하나에 결합되는 것을 특징으로 하는방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_142", "content": "제140항에 있어서, 특정 기간의 시간 동안에 수신된 상기 적어도 하나의 정보 스트림의 정보 단위의 총 사이즈는 상기 특정 기간의시간 동안에 출력된 1차 처리 결과의 총 사이즈보다 큰 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_143", "content": "제140항에 있어서, 상기 적어도 하나의 정보 스트림의 총 사이즈는 상기 1차 처리 결과의 총 사이즈보다 작은 것을 특징으로 하는방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_144", "content": "제140항에 있어서, 상기 메모리 가미 제조 프로세스는 DRAM 제조 프로세스인 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_145", "content": "제140항에 있어서, 공개특허 10-2022-0078566-24-상기 프로세싱 집적회로는 메모리 가미 제조 프로세스에 의해 제조되고, 상기 프로세싱 집적회로는 로직 가미 제조 프로세스에 의해 제조되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_146", "content": "제140항에 있어서, 상기 하나 이상의 메모리 프로세싱 집적회로의 로직 셀의 사이즈는 상기 프로세싱 집적 회로의 상응하는 로직셀의 사이즈의 적어도 2배인 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_147", "content": "제140항에 있어서, 상기 하나 이상의 메모리 프로세싱 집적회로의 로직 셀의 임계 치수는 상기 프로세싱 집적 회로의 상응하는 로직 셀의 임계 치수의 적어도 2배인 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_148", "content": "제140항에 있어서, 상기 하나 이상의 메모리 프로세싱 집적회로의 메모리 셀의 임계 치수는 상기 프로세싱 집적 회로의 상응하는로직 셀의 임계 치수의 적어도 2배인 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_149", "content": "제140항에 있어서, 상기 프로세싱 집적회로가 상기 1차 처리 동작을 수행하도록 상기 하나 이상의 메모리 프로세싱 집적회로에 요청하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_150", "content": "제140항에 있어서, 상기 프로세싱 집적회로가 상기 1차 처리 동작을 수행하도록 상기 하나 이상의 메모리 프로세싱 집적회로에 지시하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_151", "content": "제140항에 있어서, 상기 프로세싱 집적회로가 상기 1차 처리 동작을 수행하도록 상기 하나 이상의 메모리 프로세싱 집적회로를 구성하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_152", "content": "제140항에 있어서, 상기 하나 이상의 메모리 프로세싱 집적회로가 상기 프로세싱 집적회로의 개입 없이 상기 1차 처리 동작을 실행공개특허 10-2022-0078566-25-하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_153", "content": "제140항에 있어서, 상기 1차 처리 동작은 상기 2차 처리 동작보다 덜 메모리 집약적인 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_154", "content": "제140항에 있어서, 상기 1차 처리 동작의 총 스루풋(throughput)은 상기 2차 처리 동작의 총 스루풋보다 큰 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_155", "content": "제140항에 있어서, 상기 적어도 하나의 정보 스트림은 하나 이상의 프리프로세싱된(preprocessed) 정보 스트림을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_156", "content": "제155항에 있어서, 상기 하나 이상의 프리프로세싱된 정보 스트림은 네트워크 컨베이드 유닛들(network conveyed units)로부터 추출된 데이터인 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_157", "content": "제140항에 있어서, 상기 1차 처리 동작의 일 부분은 상기 다중 프로세서 서브유닛의 상기 하나의 프로세서 서브유닛에 의해 실행되고, 상기 1차 처리 동작의 다른 부분은 상기 다중 프로세서 서브유닛의 다른 프로세서 서브유닛에 의해 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_158", "content": "제140항에 있어서, 상기 1차 처리 동작과 상기 2차 처리 동작은 이동통신망 프로세싱 동작을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_159", "content": "제140항에 있어서, 상기 1차 처리 동작과 상기 2차 처리 동작은 데이터베이스 프로세싱 동작을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_160", "content": "제140항에 있어서, 상기 1차 처리 동작과 상기 2차 처리 동작은 데이터베이스 분석 프로세싱 동작을 포함하는 것을 특징으로 하는방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_161", "content": "제140항에 있어서, 상기 1차 처리 동작과 상기 2차 처리 동작은 인공지능 프로세싱 동작을 포함하는 것을 특징으로 하는 방법. 공개특허 10-2022-0078566-26-청구항 162 하나 이상의 스토리지 서브시스템으로부터 분리되어 있는 하나 이상의 컴퓨팅 서브시스템을 포함하는 분리된 시스템의 하나 이상의 메모리 프로세싱 집적회로가 정보 단위를 수신하는 단계―여기서, 상기 하나 이상의 메모리프로세싱 집적회로의 각각은 컨트롤러, 다중 프로세서 서브유닛, 및 다중 메모리 유닛을 포함하고, 상기 하나이상의 컴퓨팅 서브시스템은 다중 프로세싱 집적회로를 포함하고, 상기 하나 이상의 메모리 프로세싱 집적회로의 로직 셀의 사이즈는 상기 다중 프로세싱 집적회로의 상응하는 로직 셀의 사이즈의 적어도 2배임; 상기 하나 이상의 메모리 프로세싱 집적회로가 상기 정보 단위에 프로세싱 동작을 수행하여 프로세싱 결과를 제공하는 단계; 및 상기 하나 이상의 메모리 프로세싱 집적회로로부터 상기 프로세싱 결과를 출력하는 단계를 포함하는 분산 프로세싱을 위한 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_163", "content": "제162항에 있어서, 상기 분리된 시스템의 상기 하나 이상의 컴퓨팅 서브시스템으로 상기 프로세싱 결과를 출력하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_164", "content": "제162항에 있어서, 상기 분리된 시스템의 상기 하나 이상의 스토리지 서브시스템으로 상기 정보 단위를 수신하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_165", "content": "제162항에 있어서, 상기 분리된 시스템의 상기 하나 이상의 스토리지 서브시스템으로 상기 프로세싱 결과를 출력하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_166", "content": "제162항에 있어서, 상기 분리된 시스템의 상기 하나 이상의 컴퓨팅 서브시스템으로 상기 정보 단위를 수신하는 단계를 더 포함하는방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_167", "content": "제166항에 있어서, 상기 다중 프로세싱 집적회로의 상이한 그룹의 프로세싱 유닛으로부터 전송된 정보 단위는 상기 다중 프로세싱집적회로에 의해 실행되는 프로세스의 중간 결과의 상이한 부분들을 포함하고, 프로세싱 유닛의 그룹은 적어도하나의 프로세싱 집적회로를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_168", "content": "공개특허 10-2022-0078566-27-제167항에 있어서, 하나 이상의 메모리 프로세싱 집적회로가 전체 프로세스의 결과를 출력하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_169", "content": "제168항에 있어서, 상기 전체 프로세스의 상기 결과를 상기 다중 프로세싱 집적회로의 각각으로 전송하는 단계를 더 포함하는방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_170", "content": "제168항에 있어서, 상기 중간 결과의 상기 상이한 부분들은 업데이트 된 신경망 모델의 상이한 부분들이고, 상기 전체 프로세스의상기 결과는 상기 업데이트 된 신경망 모델인 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_171", "content": "제168항에 있어서, 상기 업데이트 된 신경망 모델을 상기 다중 프로세싱 집적회로의 각각으로 전송하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_172", "content": "제162항에 있어서, 상기 분리된 시스템의 스위칭 서브유닛을 활용하여 상기 프로세싱 결과를 출력하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_173", "content": "제162항에 있어서, 상기 하나 이상의 메모리 프로세싱 집적회로는 상기 분리된 시스템의 메모리 프로세싱 서브유닛에 포함되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_174", "content": "제162항에 있어서, 상기 하나 이상의 메모리 프로세싱 집적회로의 적어도 하나는 상기 분리된 시스템의 하나 이상의 컴퓨팅 서브시스템에 포함되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_175", "content": "제162항에 있어서, 상기 하나 이상의 메모리 프로세싱 집적회로의 적어도 하나는 상기 분리된 시스템의 하나 이상의 메모리 서브시스템에 포함되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_176", "content": "제162항에 있어서, (a) 상기 정보 단위는 상기 다중 프로세싱 집적회로의 적어도 하나로부터 수신됨 및 (b) 상기 프로세싱 결과는공개특허 10-2022-0078566-28-상기 다중 프로세싱 집적회로의 하나 이상의 메모리 프로세싱 집적회로로 전송됨 중의 적어도 하나는 사실인 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_177", "content": "제176항에 있어서, 상기 하나 이상의 메모리 프로세싱 집적회로의 로직 셀의 임계 치수는 상기 다중 프로세싱 집적 회로의 상응하는 로직 셀의 임계 치수의 적어도 2배인 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_178", "content": "제176항에 있어서, 상기 하나 이상의 메모리 프로세싱 집적회로의 메모리 셀의 임계 치수는 상기 다중 프로세싱 집적 회로의 상응하는 로직 셀의 임계 치수의 적어도 2배인 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_179", "content": "제162항에 있어서, 상기 정보 단위는 프리프로세싱된(preprocessed) 정보 단위를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_180", "content": "제179항에 있어서, 상기 다중 프로세싱 집적회로가 상기 프리프로세싱된 정보 단위를 제공하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_181", "content": "제162항에 있어서, 상기 정보 단위는 신경망의 모델의 부분들을 전달하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_182", "content": "제162항에 있어서, 상기 정보 단위는 적어도 하나의 데이터베이스 쿼리의 부분 결과를 전달하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_183", "content": "제162항에 있어서, 상기 정보 단위는 적어도 하나의 총 데이터베이스 쿼리의 부분 결과를 전달하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_184", "content": "데이터베이스 쿼리와 관련 있는 데이터베이스의 데이터베이스 엔트리를 나타내는 적어도 하나의 관련성 기준을공개특허 10-2022-0078566-29-포함하는 상기 데이터베이스 쿼리를 메모리 프로세싱 집적회로가 수신하는 단계―여기서, 상기 메모리 프로세싱집적회로는 컨트롤러, 다중 프로세서 서브유닛, 및 다중 메모리 유닛을 포함함; 상기 메모리 프로세싱 집적회로에 저장된 한 그룹의 관련 있는 데이터베이스 엔트리를 상기 메모리 프로세싱 집적회로가 상기 적어도 하나의 관련성 기준에 의거하여 판단하는 단계; 및 상기 메모리 프로세싱 집적회로에 저장된 관련 없는 데이터베이스 엔트리를 하나 이상의 프로세싱 엔티티로 실질적으로 전송하지 않고 프로세싱을 계속하기 위해 상기 그룹의 관련 있는 데이터베이스 엔트리를 상기 하나 이상의 프로세싱 엔티티로 전송하는 단계―여기서, 상기 관련 없는 데이터베이스 엔트리는 상기 관련 있는 데이터베이스 엔트리와 상이함―를 포함하는 데이터베이스 분석 가속을 위한 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_185", "content": "제184항에 있어서, 상기 하나 이상의 프로세싱 엔티티는 상기 메모리 프로세싱 집적회로의 상기 다중 프로세서 서브유닛에 포함되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_186", "content": "제185항에 있어서, 상기 메모리 프로세싱 집적회로가 상기 그룹의 관련 있는 데이터베이스 엔트리를 더 처리하여 상기 데이터베이스 쿼리에 대한 응답을 완료하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_187", "content": "제186항에 있어서, 상기 데이터베이스 쿼리에 대한 상기 응답을 상기 메모리 프로세싱 집적회로로부터 출력하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_188", "content": "제187항에 있어서, 상기 출력하는 단계는 흐름 제어 프로세를 적용하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_189", "content": "제188항에 있어서, 상기 흐름 제어 프로세스를 적용하는 단계는 상기 하나 이상의 프로세싱 엔티티로부터 출력되고 상기 그룹의 하나 이상의 데이터베이스 엔트리의 처리의 완료에 관한 지시자에 대응하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_190", "content": "제185항에 있어서, 상기 메모리 프로세싱 집적회로가 상기 그룹의 관련 있는 데이터베이스 엔트리를 더 처리하여 상기 데이터베이스 쿼리에 대한 중간 응답을 제공하는 단계를 더 포함하는 방법. 공개특허 10-2022-0078566-30-청구항 191 제190항에 있어서, 상기 데이터베이스 쿼리에 대한 상기 중간 응답을 상기 메모리 프로세싱 집적회로로부터 출력하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_192", "content": "제191항에 있어서, 상기 출력하는 단계는 흐름 제어 프로세를 적용하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_193", "content": "제192항에 있어서, 상기 흐름 제어 프로세스를 적용하는 단계는 상기 하나 이상의 프로세싱 엔티티로부터 출력되고 상기 그룹의 데이터베이스 엔트리의 부분 처리의 완료에 관한 지시자에 대응하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_194", "content": "제185항에 있어서, 상기 하나 이상의 프로세싱 엔티티가 상기 그룹의 관련 있는 데이터베이스 엔트리의 추가적인 프로세싱의 진행을 나타내는 프로세싱 상태 지시자를 생성하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_195", "content": "제185항에 있어서, 상기 메모리 프로세싱 집적회로를 활용하여 상기 그룹의 관련 있는 데이터베이스 엔트리를 더 처리하는 단계를더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_196", "content": "제195항에 있어서, 상기 처리하는 단계는 상기 다중 프로셋서 서브유닛에 의해 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_197", "content": "제195항에 있어서, 상기 처리하는 단계는 상기 다중 프로세싱 서브유닛의 한 프로세싱 서브유닛이 중간 결과를 계산하는 단계, 상기 중간 결과를 상기 다중 프로세싱 서브유닛의 다른 프로세싱 서브유닛으로 전송하는 단계, 및 상기 다른 프로세싱 서브유닛이 추가적인 계산을 수행하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_198", "content": "공개특허 10-2022-0078566-31-제195항에 있어서, 상기 처리하는 단계는 상기 컨트롤러에 의해 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_199", "content": "제195항에 있어서, 상기 처리하는 단계는 상기 다중 프로세서 서브유닛 및 상기 컨트롤러에 의해 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_200", "content": "제184항에 있어서, 상기 하나 이상의 프로세싱 엔티티는 상기 메모리 프로세싱 집적회로의 외부에 위치하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_201", "content": "제200항에 있어서, 상기 메모리 프로세싱 집적회로로부터 상기 그룹의 관련 있는 데이터베이스 엔트리를 출력하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_202", "content": "제201항에 있어서, 상기 출력하는 단계는 흐름 제어 프로세를 적용하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_203", "content": "제202항에 있어서, 상기 흐름 제어 프로세스를 적용하는 단계는 상기 하나 이상의 프로세싱 엔티티로부터 출력되고 상기 하나 이상의 프로세싱 엔티티와 연관된 데이터베이스 엔트리의 관련성에 관한 지시자에 대응하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_204", "content": "제184항에 있어서, 상기 다중 프로세서 서브유닛은 완전 산술논리부(full arithmetic logic units)를 포함하는 것을 특징으로 하는방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_205", "content": "제184항에 있어서, 상기 다중 프로세서 서브유닛은 부분 산술논리부(partial arithmetic logic units)를 포함하는 것을 특징으로공개특허 10-2022-0078566-32-하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_206", "content": "제184항에 있어서, 상기 다중 프로세서 서브유닛은 메모리 컨트롤러를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_207", "content": "제184항에 있어서, 상기 다중 프로세서 서브유닛은 부분 메모리 컨트롤러를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_208", "content": "제184항에 있어서, (i) 상기 그룹의 관련 있는 데이터베이스 엔트리, (ii) 상기 데이터베이스 쿼리에 대한 응답, 및 (iii) 상기 데이터베이스 쿼리에 대한 중간 응답 중의 적어도 하나를 출력하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_209", "content": "제212항에 있어서, 상기 출력하는 단계는 트래픽 성형을 적용하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_210", "content": "제212항에 있어서, 상기 출력하는 단계는 상기 메모리 프로세싱 집적회로를 리퀘스터 유닛(requester unit)에 결합시키는 링크를통해, 상기 출력하는 단계 동안에 사용된 대역폭을 최대 허용 대역폭에 일치시키려고 시도하는 단계를 포함하는것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_211", "content": "제212항에 있어서, 상기 출력을 출력하는 단계는 출력 트래픽 속도의 변동을 임계값 이하로 유지하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_212", "content": "제184항에 있어서, 상기 하나 이상의 프로세싱 엔티티는 다중 프로세싱 엔티티를 포함하고, 상기 다중 프로세싱 엔티티의 적어도하나의 프로세싱 엔티티는 상기 메모리 프로세싱 집적회로에 속하고 상기 다중 프로세싱 엔티티의 적어도 다른하나의 프로세싱 엔티티는 상기 메모리 프로세싱 집적회로에 속하지 않는 것을 특징으로 하는 방법. 공개특허 10-2022-0078566-33-청구항 213 제184항에 있어서, 상기 하나 이상의 프로세싱 엔티티는 다른 메모리 프로세싱 집적회로에 속하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_214", "content": "데이터베이스 쿼리와 관련 있는 데이터베이스의 데이터베이스 엔트리를 나타내는 적어도 하나의 관련성 기준을포함하는 상기 데이터베이스 쿼리를 다중 메모리 프로세싱 집적회로가 수신하는 단계―여기서, 상기 다중 메모리 프로세싱 집적회로는 각각 컨트롤러, 다중 프로세서 서브유닛, 및 다중 메모리 유닛을 포함함; 상기 메모리 프로세싱 집적회로에 저장된 한 그룹의 관련 있는 데이터베이스 엔트리를 상기 다중 메모리 프로세싱 집적회로 각각이 상기 적어도 하나의 관련성 기준에 의거하여 판단하는 단계; 및 상기 메모리 프로세싱 집적회로에 저장된 관련 없는 데이터베이스 엔트리를 하나 이상의 프로세싱 엔티티로 실질적으로 전송하지 않고 프로세싱을 계속하기 위해 상기 다중 메모리 프로세싱 집적회로의 각각이 상기 메모리프로세싱 집적회로에 저장된 상기 그룹의 관련 있는 데이터베이스 엔트리를 상기 하나 이상의 프로세싱 엔티티로 전송하는 단계―여기서, 상기 관련 없는 데이터베이스 엔트리는 상기 관련 있는 데이터베이스 엔트리와 상이함―를 포함하는 데이터베이스 분석 가속을 위한 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_215", "content": "데이터베이스 쿼리와 관련 있는 데이터베이스의 데이터베이스 엔트리를 나타내는 적어도 하나의 관련성 기준을포함하는 상기 데이터베이스 쿼리를 집적회로가 수신하는 단계―여기서, 상기 집적회로는 컨트롤러, 필터링 유닛, 및 다중 메모리 유닛을 포함함; 상기 집적회로에 저장된 한 그룹의 관련 있는 데이터베이스 엔트리를 상기 필터링 유닛이 상기 적어도 하나의관련성 기준에 의거하여 판단하는 단계; 및 상기 집적회로에 저장된 관련 없는 데이터 엔트리를 하나 이상의 프로세싱 엔티티로 실질적으로 전송하지 않고프로세싱을 계속하기 위해 상기 집적회로 외부에 위치한 상기 하나 이상의 프로세싱 엔티티로 상기 그룹의 관련있는 데이터베이스 엔트리를 전송하는 단계를 포함하는 데이터베이스 분석 가속을 위한 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_216", "content": "데이터베이스 쿼리와 관련 있는 데이터베이스의 데이터베이스 엔트리를 나타내는 적어도 하나의 관련성 기준을포함하는 상기 데이터베이스 쿼리를 집적회로가 수신하는 단계―여기서, 상기 집적회로는 컨트롤러, 프로세싱유닛, 및 다중 메모리 유닛을 포함함; 상기 집적회로에 저장된 한 그룹의 관련 있는 데이터베이스 엔트리를 상기 프로세싱 유닛이 상기 적어도 하나의관련성 기준에 의거하여 판단하는 단계; 상기 집적회로에 저장된 관련 없는 데이터 엔트리를 상기 집적회로가 처리하지 않고 상기 그룹의 관련 있는 데이터베이스 엔트리를 상기 프로세싱 유닛이 처리하여 프로세싱 결과를 제공하는 단계―여기서, 여기서, 상기 관련 없는 데이터베이스 엔트리는 상기 관련 있는 데이터베이스 엔트리와 상이함; 및 상기 프로세싱 결과를 집적회로로부터 출력하는 단계를 포함하는 데이터베이스 분석 가속을 위한 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_217", "content": "다중 문장 세그먼트에 매핑된 다중 요청된 특징 벡터의 검색을 위한 검색 정보를 메모리 프로세싱 집적회로가수신하는 단계―여기서, 상기 메모리 프로세싱 집적회로는 컨트롤러, 다중 프로세서 서브유닛, 및 다중 메모리공개특허 10-2022-0078566-34-유닛을 포함하고, 메모리 유닛의 각각은 프로세서 서브유닛에 결합됨; 상기 다중 요청된 특징 벡터를 상기 다중 메모리 유닛의 적어도 일부 메모리 유닛으로부터 검색하는 단계―여기서, 상기 검색하는 단계는 둘 이상의 메모리 유닛으로부터 상기 둘 이상의 메모리 유닛에 저장된 요청된 특징벡터를 동시에 요청하는 단계를 포함함; 및 (a) 상기 요청된 특징 벡터 및 (b) 상기 요청된 특징 벡터의 프로세싱의 결과 중의 적어도 하나를 포함하는 출력을 상기 메모리 프로세싱 집적회로로부터 출력하는 단계를 포함하는 특징 벡터 관련 정보의 검색을 위한방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_218", "content": "제217항에 있어서, 상기 출력은 상기 요청된 특징 벡터를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_219", "content": "제217항에 있어서, 상기 출력은 상기 요청된 특징 벡터의 상기 프로세싱의 상기 결과를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_220", "content": "제219항에 있어서, 상기 프로세싱은 상기 다중 프로세서 서브유닛에 의해 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_221", "content": "제220항에 있어서, 상기 프로세싱은 요청된 특징 벡터를 한 프로세싱 서브유닛으로부터 다른 프로세싱 서브유닛으로의 전송을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_222", "content": "제220항에 있어서, 상기 프로세싱은 한 프로세싱 서브유닛에 의하 중간 결과의 계산, 다른 프로세싱 서브유닛으로 상기 중간 결과의 전송, 및 상기 다른 프로세싱 서브유닛에 의한 다른 중간 결과 또는 프로세싱 결과의 계산을 포함하는 것을특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_223", "content": "제219항에 있어서, 상기 프로세싱은 상기 컨트롤러에 의해 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_224", "content": "공개특허 10-2022-0078566-35-제219항에 있어서, 상기 프로세싱은 상기 다중 프로세서 서브유닛 및 상기 컨트롤러에 의해 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_225", "content": "제219항에 있어서, 상기 프로세싱은 상기 메모리 프로세싱 집적회로의 벡터 프로세서에 의해 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_226", "content": "제217항에 있어서, 상기 컨트롤러는 문장 세그먼트와 상기 문장 세그먼트에 매핑된 특징 벡터의 위치 사이의 알려진 매핑에 의거하여 상기 요청된 특징 벡터를 동시에 요청하도록 구성된 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_227", "content": "제11항에 있어서, 상기 매핑은 상기 메모리 프로세싱 집적회로의 부팅 과정 중에 업로드되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_228", "content": "제217항에 있어서, 상기 컨트롤러는 상기 다중 요청된 특징 벡터의 검색을 관리하도록 구성된 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_229", "content": "제217항에 있어서, 상기 다중 문장 세그먼트는 특정 순서이고, 상기 요청된 특징 벡터의 상기 출력은 상기 특정 순서에 따라 수행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_230", "content": "제229항에 있어서, 상기 다중 요청된 특징 벡터의 상기 검색은 상기 특정 순서에 따라 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_231", "content": "제229항에 있어서, 상기 다중 요청된 특징 벡터의 상기 검색은 적어도 부분적으로는 순서에 상관없이 실행되고, 상기 검색은 상기다중 요청된 특징 벡터의 순서의 재배열을 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_232", "content": "공개특허 10-2022-0078566-36-제217항에 있어서, 상기 다중 요청된 특징 벡터의 상기 검색은 상기 다중 요청된 특징 벡터가 상기 컨트롤러에 의해 읽히기 전에상기 다중 요청된 특징 벡터의 버퍼링을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_233", "content": "제232항에 있어서, 상기 다중 요청된 특징 벡터의 상기 검색은 상기 다중 메모리 유닛과 연관된 하나 이상의 버퍼가 하나 이상의요청된 특징 벡터를 저장하는 때를 나타내는 버퍼 상태 지시자의 생성을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_234", "content": "제233항에 있어서, 전용 컨트롤 라인을 통해 상기 버퍼 상태 지시자를 전달하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_235", "content": "제234항에 있어서, 상기 전용 컨트롤 라인은 메모리 유닛별로 하나가 할당되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_236", "content": "제234항에 있어서, 상기 버퍼 상태 지시자는 하나 이상의 상기 버퍼에 저장된 하나 이상의 상태 비트를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_237", "content": "제234항에 있어서, 하나 이상의 공유 컨트롤 라인을 통해 상기 버퍼 상태 지시자를 전달하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_238", "content": "제217항에 있어서, 상기 검색 정보는 특정 수의 비트를 나타내는 제1 해상도의 하나 이상의 검색 명령에 포함되는 것을 특징으로하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_239", "content": "제238항에 있어서, 상기 특정 수의 비트보다 작은 수의 비트를 나타내는 더 높은 해상도에서 상기 컨트롤러를 통해 상기 검색을 관리하는 단계를 더 포함하는 방법. 공개특허 10-2022-0078566-37-청구항 240 제238항에 있어서, 상기 컨트롤러는 특징 벡터 해상도 상의 상기 검색을 관리하도록 구성된 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_241", "content": "제238항에 있어서, 상기 컨트롤러가 상기 검색을 독립적으로 관리하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_242", "content": "제217항에 있어서, 상기 다중 프로세서 서브유닛은 완전 산술논리부(full arithmetic logic units)를 포함하는 것을 특징으로 하는방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_243", "content": "제217항에 있어서, 상기 다중 프로세서 서브유닛은 부분 산술논리부(partial arithmetic logic units)를 포함하는 것을 특징으로하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_244", "content": "제217항에 있어서, 상기 다중 프로세서 서브유닛은 메모리 컨트롤러를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_245", "content": "제217항에 있어서, 상기 다중 프로세서 서브유닛은 부분 메모리 컨트롤러를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_246", "content": "제217항에 있어서, 상기 출력을 출력하는 단계는 상기 출력에 트래픽 성형을 적용하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_247", "content": "제217항에 있어서, 상기 출력을 출력하는 단계는 상기 메모리 프로세싱 집적회로를 리퀘스터 유닛(requester unit)에 결합시키는링크를 통해, 상기 출력하는 단계 동안에 사용된 대역폭을 최대 허용 대역폭에 일치시키는 단계를 포함하는 것을 특징으로 하는 방법. 공개특허 10-2022-0078566-38-청구항 248 제217항에 있어서, 상기 출력을 출력하는 단계는 출력 트래픽 속도의 변동을 임계값 이하로 유지하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_249", "content": "제217항에 있어서, 상기 검색하는 단계는 단일 메모리 유닛에 저장된 한 세트의 요청된 특징 벡터로부터 상기 요청된 특징 벡터의적어도 일부 요청된 특징 벡터의 예측 검색을 적용하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_250", "content": "제217항에 있어서, 상기 요청된 특징 벡터는 상기 메모리 유닛 사이에 분산되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_251", "content": "제217항에 있어서, 상기 요청된 특징 벡터는 예상되는 검색 패턴에 의거하여 상기 메모리 유닛 사이에 분산되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_252", "content": "베이스 다이, 적어도 하나의 제2 다이와 연관된 제1 메모리 리소스, 및 적어도 하나의 제3 다이와 연관된 제2메모리 리소스를 포함하는 하이브리드 장치에 포함된 다중 프로세서가 프로세싱 동작을 수행하는 단계―여기서,상기 베이스 다이와 상기 적어도 하나의 제2 다이는 웨이퍼 투 웨이퍼 접합(wafer to wafer bond)에 의해 서로연결됨; 상기 제1 메모리 리소스에 저장된 정보를 상기 다중 프로세서를 활용하여 검색하는 단계; 및 상기 제2 메모리 리소스에서 상기 제1 메모리 리소스로 추가 정보를 전송하는 단계―여기서, 상기 베이스 다이와 상기 적어도 하나의 제2 다이 사이의 제1 경로의 전반적인 대역폭은 상기 적어도 하나의 제2 다이와 상기 적어도 하나의 제3 다이 사이의 제2 경로의 전반적인 대역폭보다 크고, 상기 제1 메모리 리소스의 저장 용량은 상기 제2 메모리 리소스의 저장 용량보다 작음―를 포함하는 메모리 집약적 프로세싱을 위한 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_253", "content": "제252항에 있어서, 상기 제2 메모리 리소스는 고대역폭 메모리(HBM) 리소스를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_254", "content": "제252항에 있어서, 공개특허 10-2022-0078566-39-상기 적어도 하나의 제3 다이는 고대역폭 메모리(HBM) 칩의 적층을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_255", "content": "제252항에 있어서, 상기 제2 메모리 리소스의 적어도 일부는 웨이퍼 투 웨이퍼 접합 없이 상기 베이스 다이로 연결되는 적어도 하나의 제3 다이의 한 제3 다이에 속하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_256", "content": "제252항에 있어서, 상기 제2 메모리 리소스의 적어도 일부는 웨이퍼 투 웨이퍼 접합 없이 상기 적어도 하나의 제2 다이의 한 제2다이로 연결되는 적어도 하나의 제3 다이의 한 제3 다이에 속하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_257", "content": "제252항에 있어서, 상기 제1 메모리 리소스와 상기 제2 메모리 리소스는 서로 상이한 레벨의 캐시 메모리를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_258", "content": "제252항에 있어서, 상기 제1 메모리 리소스는 상기 베이스 다이와 상기 제2 메모리 리소스 사이에 위치하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_259", "content": "제252항에 있어서, 상기 제1 메모리 리소스는 상기 제2 메모리 리소스 위에 위치하지 않는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_260", "content": "제252항에 있어서, 복수의 프로세서 서브유닛과 상기 제1 메모리 리소스를 포함하는 적어도 하나의 제2 다이의 한 제2 다이가 추가적인 프로세싱을 수행하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_261", "content": "제260항에 있어서, 적어도 하나의 프로세서 서브유닛이 상기 프로세서 서브유닛에 할당된 상기 제1 메모리 리소스의 전용 부분에결합되는 것을 특징으로 하는 방법. 공개특허 10-2022-0078566-40-청구항 262 제261항에 있어서, 상기 제1 메모리 리소스의 상기 전용 부분은 적어도 하나의 메모리 뱅크를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_263", "content": "제252항에 있어서, 상기 다중 프로세서는 상기 제1 메모리 리소스도 포함하는 메모리 프로세싱 칩에 속하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_264", "content": "제252항에 있어서, 상기 베이스 다이는 상기 다중 프로세서를 포함하고, 상기 다중 프로세서는 웨이퍼 투 웨이퍼 접합으로 형성된컨덕터를 통해 상기 제1 메모리 리소스로 결합되는 복수의 프로세서 서브유닛을 포함하는 것을 특징으로 하는방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_265", "content": "제264항에 있어서, 각 프로세서 서브유닛이 상기 프로세서 서브유닛에 할당된 상기 제1 메모리 리소스의 전용 부분에 결합되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_266", "content": "베이스 다이; 다중 프로세서; 적어도 하나의 제2 다이의 제1 메모리 리소스; 및적어도 하나의 제3 다이의 제2 메모리 리소스를 포함하고, 상기 베이스 다이와 상기 적어도 하나의 제2 다이는 웨이퍼 투 웨이퍼 접합에 의해 서로 연결되고, 상기 다중 프로세서는 프로세싱 동작을 수행하고 상기 제1 메모리 리소스에 저장된 정보를 검색하도록구성되고, 상기 제2 메모리 리소스는 상기 제2 메모리 리소스에서 상기 제1 메모리 리소스로 추가 정보를 전송하도록 구성되고, 상기 베이스 다이와 상기 적어도 하나의 제2 다이 사이의 제1 경로의 전반적인 대역폭은 상기 적어도 하나의 제2 다이와 상기 적어도 하나의 제3 다이 사이의 제2 경로의 전반적인 대역폭보다 크고, 상기 제1 메모리 리소스의 저장 용량은 상기 제2 메모리 리소스의 저장 용량보다 작은 것을 특징으로 하는 메모리 집약적 프로세싱을 위한 하이브리드 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_267", "content": "제266항에 있어서, 공개특허 10-2022-0078566-41-상기 제2 메모리 리소스는 고대역폭 메모리(HBM) 리소스를 포함하는 것을 특징으로 하는 하이브리드 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_268", "content": "제266항에 있어서, 상기 적어도 하나의 제3 다이는 HBM 메모리 칩의 적층인 것을 특징으로 하는 하이브리드 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_269", "content": "제266항에 있어서, 상기 제2 메모리 리소스의 적어도 일부는 웨이퍼 투 웨이퍼 접합 없이 상기 베이스 다이로 연결되는 상기 적어도 하나의 제3 다이의 한 제3 다이에 속하는 것을 특징으로 하는 하이브리드 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_270", "content": "제266항에 있어서, 상기 제2 메모리 리소스의 적어도 일부는 웨이퍼 투 웨이퍼 접합 없이 상기 적어도 하나의 제2 다이의 한 제2다이로 연결되는 상기 적어도 하나의 제3 다이의 한 제3 다이에 속하는 것을 특징으로 하는 하이브리드 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_271", "content": "제266항에 있어서, 상기 제1 메모리 리소스와 상기 제2 메모리 리소스는 서로 상이한 레벨의 캐시 메모리를 포함하는 것을 특징으로 하는 하이브리드 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_272", "content": "제266항에 있어서, 상기 제1 메모리 리소스는 상기 베이스 다이와 상기 제2 메모리 리소스 사이에 위치하는 것을 특징으로 하는 하이브리드 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_273", "content": "제266항에 있어서, 상기 제1 메모리 리소스는 상기 제2 메모리 리소스의 옆에 위치하는 것을 특징으로 하는 하이브리드 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_274", "content": "제266항에 있어서, 상기 적어도 하나의 제2 다이의 한 제2 다이는 추가적인 프로세싱을 수행하도록 구성되고, 상기 제2 다이는 복수의 프로세서 서브유닛과 상기 제1 메모리 리소스를 포함하는 것을 특징으로 하는 하이브리드 장치. 공개특허 10-2022-0078566-42-청구항 275 제274항에 있어서, 각 프로세서 서브유닛이 상기 프로세서 서브유닛에 할당된 상기 제1 메모리 리소스의 전용 부분에 결합되는 것을 특징으로 하는 하이브리드 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_276", "content": "제275항에 있어서, 상기 제1 메모리 리소스의 상기 전용 부분은 적어도 하나의 메모리 뱅크를 포함하는 것을 특징으로 하는 하이브리드 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_277", "content": "제266항에 있어서, 상기 다중 프로세서는 상기 제1 메모리 리소스도 포함하는 메모리 프로세싱 칩의 복수의 프로세서 서브유닛을포함하는 것을 특징으로 하는 하이브리드 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_278", "content": "제266항에 있어서, 상기 베이스 다이는 상기 다중 프로세서를 포함하고, 상기 다중 프로세서는 웨이퍼 투 웨이퍼 접합으로 형성된컨덕터를 통해 상기 제1 메모리 리소스로 결합되는 복수의 프로세서 서브유닛을 포함하는 것을 특징으로 하는하이브리드 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_279", "content": "제278항에 있어서, 각 프로세서 서브유닛이 상기 프로세서 서브유닛에 할당된 상기 제1 메모리 리소스의 전용 부분에 결합되는 것을 특징으로 하는 하이브리드 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_280", "content": "데이터베이스 가속 집적회로의 네트워크 통신 인터페이스가 스토리지 유닛으로부터 한 양의 정보를 검색하는 단계; 상기 양의 정보를 1차 처리하여 1차 처리된 정보를 제공하는 단계; 상기 데이터베이스 가속 집적회로의 메모리 컨트롤러를 활용하고 인터페이스를 통해, 상기 1차 처리된 정보를다중 메모리 프로세싱 집적회로로 전송하는 단계―여기서, 각 메모리 프로세싱 집적회로는 컨트롤러, 다중 프로세서 서브유닛, 및 다중 메모리 유닛을 포함함; 상기 다중 메모리 프로세싱 집적회로를 활용하여 상기 1차 처리된 정보의 적어도 일부를 2차 처리하여 2차 처리된 정보를 제공하는 단계; 상기 데이터베이스 가속 집적회로의 상기 메모리 컨트롤러가 상기 다중 메모리 프로세싱 집적회로로부터 검색된정보를 검색하는 단계―여기서, 상기 검색된 정보는 (a) 상기 1차 처리된 정보의 적어도 일부분 및 (b) 상기 2차 처리된 정보의 적어도 일부분 중의 적어도 하나를 포함함; 공개특허 10-2022-0078566-43-상기 데이터베이스 가속 집적회로의 데이터베이스 가속 유닛을 활용하여, 상기 검색된 정보에 데이터베이스 프로세싱 동작을 수행하여 데이터베이스 가속 결과를 제공하는 단계; 및 상기 데이터베이스 가속 결과를 출력하는 단계를 포함하는 데이터베이스 가속을 위한 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_281", "content": "제280항에 있어서, 상기 데이터베이스 가속 집적회로의 관리 유닛을 활용하여, 상기 검색하는 단계, 상기 1차 처리하는 단계, 및상기 처리하는 단계 중의 적어도 하나를 관리하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_282", "content": "제281항에 있어서, 상기 관리하는 단계는 상기 데이터베이스 가속 집적회로의 상기 관리 유닛에 의해 생성되는 실행 계획에 의거하여 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_283", "content": "제281항에 있어서, 상기 관리하는 단계는 상기 데이터베이스 가속 집적회로의 상기 관리 유닛에 의해 생성되지 않고 수신되는 실행계획에 의거하여 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_284", "content": "제281항에 있어서, 상기 관리하는 단계는 (a) 네트워크 통신 네트워크 인터페이스 리소스, (b) 압축해제 유닛 리소스, (c) 메모리컨트롤러 리소스, (d) 다중 메모리 프로세싱 집적회로 리소스, 및 (e) 데이터 가속 유닛 리소스 중의 적어도 하나를 할당하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_285", "content": "제280항에 있어서, 상기 네트워크 통신 인터페이스는 둘 이상의 상이한 유형의 네트워크 통신 포트를 포함하는 것을 특징으로 하는방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_286", "content": "제285항에 있어서, 상기 둘 이상의 상이한 유형의 네트워크 통신 포트는 스토리지 인터페이스 프로토콜 포트 및 일반 네트워크를통한 스토리지 인터페이스 프로토콜 포트를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_287", "content": "제285항에 있어서, 공개특허 10-2022-0078566-44-상기 둘 이상의 상이한 유형의 네트워크 통신 포트는 스토리지 인터페이스 프로토콜 포트 및 이더넷을 통한 스토리지 인터페이스 프로토콜 포트를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_288", "content": "제285항에 있어서, 상기 둘 이상의 상이한 유형의 네트워크 통신 포트는 스토리지 인터페이스 프로토콜 포트 및 PCIe 포트를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_289", "content": "제280항에 있어서, 컴퓨트 시스템의 컴퓨트 노드를 포함하고 상기 컴퓨트 시스템의 매니저에 의해 제어되는 관리 유닛을 포함하는것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_290", "content": "제280항에 있어서, 컴퓨트 시스템의 컴퓨트 노드가 상기 검색하는 단계, 상기 1차 처리하는 단계, 상기 전송하는 단계, 및 상기 3차 처리하는 단계의 적어도 하나를 제어하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_291", "content": "제280항에 있어서, 상기 데이터베이스 가속 집적회로를 활용하여 다중 작업을 동시에 실행하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_292", "content": "제280항에 있어서, 상기 데이터베이스 가속 집적회로의 외부에 위치한 관리 유닛을 활용하여, 상기 검색하는 단계, 상기 1차 처리하는 단계, 상기 전송하는 단계, 및 상기 3차 처리하는 단계의 적어도 하나를 관리하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_293", "content": "제280항에 있어서, 상기 데이터베이스 가속 집적회로는 컴퓨트 시스템에 속하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_294", "content": "제280항에 있어서, 상기 데이터베이스 가속 집적회로는 컴퓨트 시스템에 속하지 않는 것을 특징으로 하는 방법. 공개특허 10-2022-0078566-45-청구항 295 제280항에 있어서, 컴퓨트 시스템의 컴퓨트 노드에 의해 상기 데이터베이스 가속 집적회로로 전송된 실행 계획에 의거하여 상기 검색하는 단계, 상기 1차 처리하는 단계, 상기 전송하는 단계, 및 상기 3차 처리하는 단계의 적어도 하나를 실행하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_296", "content": "제280항에 있어서, 상기 데이터베이스 프로세싱 동작을 수행하는 단계는 데이터베이스 프로세싱 서브유닛이 데이터베이스 프로세싱지시를 동시에 수행하는 단계를 포함하고, 상기 데이터베이스 가속 유닛은 공유 메모리 유닛을 공유하는 한 그룹의 데이터베이스 가속기 서브유닛을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_297", "content": "제296항에 있어서, 각 데이터베이스 서브유닛은 특정 유형의 데이터베이스 프로세싱 지시를 실행하도록 구성된 것을 특징으로 하는방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_298", "content": "제297항에 있어서, 데이터베이스 프로세싱 서브유닛들을 동적으로 연결하여 다중 지시를 포함하는 데이터베이스 프로세싱 동작을실행하는 데에 필요한 실행 파이프라인을 제공하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_299", "content": "제280항에 있어서, 상기 데이터베이스 프로세싱 동작을 수행하는 단계는 시간 I/O 대역폭에 따라 상기 데이터베이스 가속 집적회로의 리소스를 할당하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_300", "content": "제280항에 있어서, 상기 데이터베이스 가속 결과를 로컬 스토리지로 출력하는 단계와 상기 로컬 스토리지에서 상기 데이터베이스가속 결과를 검색하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_301", "content": "제280항에 있어서, 상기 네트워크 통신 인터페이스는 RDMA 유닛을 포함하는 것을 특징으로 하는 방법. 공개특허 10-2022-0078566-46-청구항 302 제280항에 있어서, 하나 이상의 그룹의 데이터베이스 가속 집적회로의 데이터베이스 가속 집적회로들 사이에 정보를 교환하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_303", "content": "제280항에 있어서, 하나 이상의 그룹의 데이터베이스 가속 집적회로의 데이터베이스 가속 집적회로들 사이에 데이터베이스 가속 결과를 교환하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_304", "content": "제280항에 있어서, 하나 이상의 그룹의 데이터베이스 가속 집적회로의 데이터베이스 가속 집적회로들 사이에 (a) 정보 및 (b) 데이터베이스 가속 결과 중의 적어도 하나를 교환하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_305", "content": "제304항에 있어서, 한 그룹의 데이터베이스 가속 집적회로들은 공통 인쇄회로기판에 연결되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_306", "content": "제304항에 있어서, 한 그룹의 데이터베이스 가속 집적회로들은 전산 시스템의 모듈형 유닛에 속하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_307", "content": "제304항에 있어서, 상이한 그룹의 데이터베이스 가속 집적회로들은 상이한 인쇄회로기판에 연결되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_308", "content": "제304항에 있어서, 상이한 그룹의 데이터베이스 가속 집적회로들은 전산 시스템의 모듈형 유닛에 속하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_309", "content": "제304항에 있어서, 상기 하나 이상의 그룹의 데이터베이스 가속 집적회로가 분산 프로세싱을 실행하는 단계를 더 포함하는 방법. 공개특허 10-2022-0078566-47-청구항 310 제304항에 있어서, 상기 교환하는 단계는 하나 이상의 그룹의 상기 데이터베이스 가속 집적회로의 네트워크 통신 인터페이스를 활용하여 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_311", "content": "제304항에 있어서, 상기 교환하는 단계는 스타 결선(star-connection)에 의해 서로 연결되는 다중 그룹에 걸쳐 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_312", "content": "제304항에 있어서, 상기 하나 이상의 그룹의 상이한 그룹의 데이터베이스 가속 집적회로들 사이에 (a) 정보 및 (b) 데이터베이스가속 결과 중의 적어도 하나를 교환하기 위해 적어도 하나의 스위치를 사용하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_313", "content": "제304항에 있어서, 상기 하나 이상의 그룹의 데이터베이스 가속 집적회로들의 적어도 일부가 분산 프로세싱을 실행하는 단계를 더포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_314", "content": "제304항에 있어서, 제1 데이터 구조와 제2 데이터 구조의 분산 프로세싱을 수행하는 단계를 더 포함하고, 상기 제1 데이터 구조와상기 제2 데이터 구조의 총 사이즈는 상기 다중 메모리 프로세싱 집적회로의 스토리지 용량보다 큰 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_315", "content": "제314항에 있어서, 상기 분산 프로세싱을 수행하는 단계는 (a) 상이한 쌍의 제1 데이터 구조 부분과 제2 데이터 구조 부분을 상이한 데이터베이스 가속 집적회로에 새롭게 할당 및 (b) 상기 상이한 쌍의 처리를 여러 번 반복 수행하는 단계를포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_316", "content": "제315항에 있어서, 상기 분산 프로세싱을 수행하는 단계는 데이터베이스 조인(join) 동작을 포함하는 것을 특징으로 하는 방법. 공개특허 10-2022-0078566-48-청구항 317 제315항에 있어서, 상기 분산 프로세싱을 수행하는 단계는: 상이한 제1 데이터 구조 부분들을 상기 하나 이상의 그룹의 상이한 데이터베이스 가속 집적회로로 할당하는 단계; 및 상이한 제2 데이터 구조 부분들을 상기 하나 이상의 그룹의 상이한 데이터베이스 가속 집적회로로 새로 할당하는 단계와 상기 데이터베이스 가속 집적회로가 상기 제1 데이터 구조 부분들과 상기 제2 데이터 구조 부분들을처리하는 단계를 여러 번 반복 수행하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_318", "content": "제317항에 있어서, 다음 반복의 상기 새로 할당하는 단계는 현재 반복의 처리와 적어도 부분적으로 시간 중첩되는 방식으로 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_319", "content": "제317항에 있어서, 상기 새로 할당하는 단계는 상기 상이한 데이터베이스 가속 집적회로들 사이에 제2 데이터 구조 부분들을 교환하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_320", "content": "제319항에 있어서, 상기 교환하는 단계는 상기 처리하는 단계와 적어도 부분적으로 시간 중첩되는 방식으로 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_321", "content": "제317항에 있어서, 상기 새로 할당하는 단계는 한 그룹의 상기 상이한 데이터베이스 가속 집적회로 사이에 제2 데이터 구조 부분을교환하는 단계 및 상기 교환하는 단계가 완료되면 상이한 그룹의 데이터베이스 가속 집적회로 사이의 제2 데이터 구조 부분을 교환하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_322", "content": "제280항에 있어서, 상기 데이터베이스 가속 집적회로는 다중 데이터베이스 가속 집적회로, 하나 이상의 비휘발성 메모리 유닛, 이더넷 스위치, PCIe 스위치 및 이더넷 스위치, 및 상기 다중 메모리 프로세싱 집적회로를 포함하는 블레이드(blade)에 포함되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_323", "content": "공개특허 10-2022-0078566-49-데이터베이스 가속 집적회로; 및 각 메모리 프로세싱 집적회로는 컨트롤러, 다중 프로세서 서브유닛, 및 다중 메모리 유닛을 포함하는 다중 메모리 프로세싱 집적회로를 포함하고, 상기 데이터베이스 가속 집적회로의 네트워크 통신 인터페이스는 스토리지 유닛으로부터 정보를 수신하도록 구성되고,상기 데이터베이스 가속 집적회로는 상기 양의 정보를 1차 처리하여 1차 처리된 정보를 제공하도록 구성되고, 상기 데이터베이스 가속 집적회로의 메모리 컨트롤러는 상기 1차 처리된 정보를 인터페이스를 통해 상기 다중메모리 프로세싱 집적회로로 전송하도록 구성되고, 상기 다중 메모리 프로세싱 집적회로는 상기 1차 처리된 정보의 적어도 부분들을 2차 처리하여 2차 처리된 정보를 제공하도록 구성되고, 상기 데이터베이스 가속 집적회로의 상기 메모리 컨트롤러는 상기 다중 메모리 프로세싱 집적회로에서 정보를검색하도록 구성되고, 상기 검색된 정보는 (a)상기 1차 처리된 정보의 적어도 일 부분 및 (b)상기 2차 처리된정보의 적어도 일 부분의 적어도 하나를 포함하고, 상기 데이터베이스 가속 집적회로의 데이터베이스 가속 유닛은 상기 검색된 정보에 데이터베이스 프로세스 동작을 수행하여 데이터베이스 가속 결과를 제공하도록 구성되고, 상기 데이터베이스 가속 집적회로는 상기 데이터베이스 가속 결과를 출력하도록 구성된 것을 특징으로 하는 데이터베이스 가속을 위한 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_324", "content": "제323항에 있어서, 상기 데이터베이스 가속 집적회로의 관리 유닛을 활용하여 상기 검색된 정보의 상기 검색, 상기 1차 처리, 및상기 2차 처리 중의 적어도 하나를 관리하도록 구성된 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_325", "content": "제324항에 있어서, 상기 관리 유닛은 상기 데이터베이스 가속 집적회로의 상기 관리 유닛에 의해 생성되는 실행 계획에 의거하여관리하도록 구성된 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_326", "content": "제324항에 있어서, 상기 관리 유닛은 상기 데이터베이스 가속 집적회로의 상기 관리 유닛에 의해 생성되지 않고 수신되는 실행 계획에 의거하여 관리하도록 구성된 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_327", "content": "제324항에 있어서, 상기 관리 유닛은 (a) 네트워크 통신 네트워크 인터페이스 리소스, (b) 압축해제 유닛 리소스, (c) 메모리 컨트롤러 리소스, (d) 다중 메모리 프로세싱 집적회로 리소스, 및 (e) 데이터 가속 유닛 리소스 중의 하나 이상을할당하여 관리하도록 구성된 것을 특징으로 하는 장치. 공개특허 10-2022-0078566-50-청구항 328 제323항에 있어서, 상기 네트워크 통신 인터페이스는 상이한 유형의 네트워크 통신 포트를 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_329", "content": "제328항에 있어서, 상기 상이한 유형의 네트워크 통신 포트는 스토리지 인터페이스 프로토콜 포트 및 일반 네트워크를 통한 스토리지 인터페이스 프로토콜 포트를 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_330", "content": "제328항에 있어서, 상기 상이한 유형의 네트워크 통신 포트는 스토리지 인터페이스 프로토콜 포트 및 이더넷을 통한 스토리지 인터페이스 프로토콜 포트를 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_331", "content": "제328항에 있어서, 상기 상이한 유형의 네트워크 통신 포트는 스토리지 인터페이스 프로토콜 포트 및 PCIe 포트를 포함하는 것을특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_332", "content": "제323항에 있어서, 상기 장치는 컴퓨트 시스템의 컴퓨트 노드를 포함하고 상기 컴퓨트 시스템의 매니저에 의해 제어되는 관리 유닛에 결합되는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_333", "content": "제323항에 있어서, 컴퓨트 시스템의 컴퓨트 노드에 의해 제어되도록 구성된 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_334", "content": "제323항에 있어서, 상기 데이터베이스 가속 집적회로에 의해 동시에 다중 작업을 실행하도록 구성된 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_335", "content": "제323항에 있어서, 상기 데이터베이스 가속 집적 회로는 컴퓨팅 시스템에 속하는 장치.공개특허 10-2022-0078566-51-청구항 336 제323항에 있어서, 상기 데이터베이스 가속 집적회로는 컴퓨팅 시스템에 속하지 않는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_337", "content": "제323항에 있어서, 컴퓨터 시스템의 컴퓨트 노드에 의해 상기 데이터베이스 가속 집적회로로 전송된 실행 계획에 의거하여 상기 검색, 1차 처리, 전송, 및 3차 처리 중의 적어도 하나를 실행하도록 구성된 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_338", "content": "제323항에 있어서, 상기 데이터베이스 가속 유닛은 데이터베이스 프로세싱 서브유닛에 의한 데이터베이스 프로세스 지시를 동시에수행하도록 구성되고, 상기 데이터베이스 가속 유닛은 공유 메모리 유닛을 공유하는 한 그룹의 데이터베이스 가속기 서브유닛을 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_339", "content": "제338항에 있어서, 각 데이터베이스 프로세싱 서브유닛은 특정 유형의 데이터베이스 프로세스 지시를 실행하도록 구성된 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_340", "content": "제329항에 있어서, 상기 장치는 데이터베이스 프로세싱 서브유닛들을 동적으로 연결하여 다중 지시를 포함하는 데이터베이스 프로세스 동작을 실행하는 데에 필요한 실행 파이프라인을 제공하도록 구성된 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_341", "content": "제323항에 있어서, 상기 장치는 시간 I/O 대역폭에 따라 상기 데이터베이스 가속 집적회로의 리소스를 할당하도록 구성된 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_342", "content": "제323항에 있어서, 상기 장치는 상기 데이터베이스 가속 집적회로에 의해 접근 가능한 로컬 스토리지를 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_343", "content": "제323항에 있어서, 상기 네트워크 통신 네트워크 인터페이스는 RDMA 유닛을 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_344", "content": "공개특허 10-2022-0078566-52-제323항에 있어서, 상기 장치는 하나 이상의 그룹의 데이터베이스 가속 집적회로들의 데이터베이스 가속 집적회로들 사이에 정보를교환하도록 구성된 상기 하나 이상의 그룹의 데이터베이스 가속 집적회로들을 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_345", "content": "제323항에 있어서, 상기 장치는 하나 이상의 그룹의 데이터베이스 가속 집적회로들의 데이터베이스 가속 집적회로들 사이에 가속결과를 교환하도록 구성된 상기 하나 이상의 그룹의 데이터베이스 가속 집적회로들을 포함하는 것을 특징으로하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_346", "content": "제323항에 있어서, 상기 장치는 하나 이상의 그룹의 데이터베이스 가속 집적회로들의 데이터베이스 가속 집적회로들 사이에 (a) 정보 및 (b) 데이터베이스 가속 결과 중의 적어도 하나를 실행하도록 구성된 상기 하나 이상의 그룹의 데이터베이스 가속 집적회로들을 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_347", "content": "제346항에 있어서, 한 그룹의 데이터베이스 가속 집적회로들은 동일 인쇄회로기판에 연결되는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_348", "content": "제346항에 있어서, 한 그룹의 데이터베이스 가속 집적회로들은 전산 시스템의 모듈형 유닛에 속하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_349", "content": "제346항에 있어서, 상이한 그룹의 데이터베이스 가속 집적회로들은 상이한 인쇄회로기판에 연결되는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_350", "content": "제346항에 있어서, 상이한 그룹의 데이터베이스 가속 집적회로들은 전산 시스템의 모듈형 유닛에 속하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_351", "content": "제346항에 있어서, 상기 교환은 하나 이상의 그룹의 상기 데이터베이스 가속 집적회로의 네트워크 통신 인터페이스를 활용하여 실행되는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_352", "content": "제346항에 있어서, 상기 교환은 스타 결선(star-connection)에 의해 서로 연결되는 다중 그룹에 걸쳐 실행되는 것을 특징으로 하는장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_353", "content": "제346항에 있어서, 공개특허 10-2022-0078566-53-상기 장치는 상기 하나 이상의 그룹의 상이한 그룹의 데이터베이스 가속 집적회로들 사이에 (a) 정보 및 (b) 데이터베이스 가속 결과 중의 적어도 하나를 교환하기 위해 적어도 하나의 스위치를 사용하도록 구성된 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_354", "content": "제346항에 있어서, 상기 장치는 상기 하나 이상의 그룹의 일부 그룹의 상기 데이터베이스 가속 집적회로들의 일부에 의해 분산 프로세스를 실행하도록 구성된 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_355", "content": "제346항에 있어서, 상기 제1 데이터 구조와 제2 데이터 구조를 활용하여 분산 프로세싱을 수행하도록 구성되고, 상기 제1 데이터구조와 상기 제2 데이터 구조의 총 사이즈는 상기 다중 메모리 프로세싱 집적회로의 스토리지 용량보다 큰 것을특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_356", "content": "제355항에 있어서, 상기 장치는 상기 분산 프로세싱을 (a) 상이한 쌍의 제1 데이터 구조 부분과 제2 데이터 구조 부분을 상이한 데이터베이스 가속 집적회로에 새로 할당의 수행 및 (b) 상기 상이한 쌍의 처리를 여러 번 반복 수행하여 수행하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_357", "content": "제355항에 있어서, 상기 분산 프로세스는 데이터베이스 조인(join) 동작을 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_358", "content": "제355항에 있어서, 상기 장치는: 상이한 제1 데이터 구조 부분들을 상기 하나 이상의 그룹의 상이한 데이터베이스 가속 집적회로로 할당; 및 상이한 제2 데이터 구조 부분들을 상기 하나 이상의 그룹의 상이한 데이터베이스 가속 집적회로로 새로 할당하고 상기 데이터베이스 가속 집적회로에 의해 상기 제1 데이터 구조 부분들과 상기 제2 데이터 구조 부분들을 처리하는 것을 여러 번 반복 수행하여 상기 분산 프로세싱을 수행하도록 구성된 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_359", "content": "제358항에 있어서, 상기 장치는 다음 반복의 새로운 할당을 현재 반복의 처리와 적어도 부분적으로 시간 중첩되는 방식으로 실행하도록 구성된 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_360", "content": "제358항에 있어서, 상기 장치는 상기 상이한 데이터베이스 가속 집적회로 사이에 제2 데이터 구조 부분을 교환함으로써 새로운 할당을 실행하도록 구성된 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_361", "content": "제360항에 있어서, 공개특허 10-2022-0078566-54-상기 교환은 상기 데이터베이스 가속 집적회로에 의한 상기 처리와 적어도 부분적으로 시간 중첩되는 방식으로실행되는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_362", "content": "제358항에 있어서, 상기 장치는 한 그룹의 상기 상이한 데이터베이스 가속 집적회로 사이에 제2 데이터 구조 부분을 교환하고 더이상 교환할 제2 데이터 구조 부분이 없으면 상이한 그룹의 데이터베이스 가속 집적회로 사이의 제2 데이터 구조 부분을 교환함으로써 새로운 할당을 실행하도록 구성된 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_363", "content": "제323항에 있어서, 상기 데이터베이스 가속 집적회로는 다중 데이터베이스 가속 집적회로, 하나 이상의 비휘발성 메모리 유닛, 이더넷 스위치, PCIe 스위치 및 이더넷 스위치, 및 상기 다중 메모리 프로세싱 집적회로를 포함하는 블레이드(blade)에 포함되는 것을 특징으로 하는 장치."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_364", "content": "데이터베이스 가속 집적회로의 네트워크 통신 인터페이스가 스토리지 유닛으로부터 정보를 검색하는 단계; 상기 양의 정보를 1차 처리하여 1차 처리된 정보를 제공하는 단계; 상기 데이터베이스 가속 집적회로의 메모리 컨트롤러가 상기 1차 처리된 정보를 인터페이스를 통해 다중 메모리리소스로 전송하는 단계; 상기 다중 메모리 리소스로부터 정보를 검색하는 단계; 상기 데이터베이스 가속 집적회로의 데이터베이스 가속 유닛이 상기 검색된 정보에 데이터베이스 프로세싱 동작을 수행하여 데이터베이스 가속 결과를 제공하는 단계; 및 상기 데이터베이스 가속 결과를 출력하는 단계를 포함하는 데이터베이스 가속을 위한 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_365", "content": "제364항에 있어서, 상기 1차 처리된 정보를 2차 처리하여 2차 처리된 정보를 제공하는 단계를 더 포함하고, 상기 1차 처리된 정보의 상기 처리는 상기 다중 메모리 리소스를 더 포함하는 하나 이상의 메모리 프로세싱 집적회로 내에 위치한 다중 프로세서에 의해 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_366", "content": "제364항에 있어서, 상기 1차 처리는 데이터베이스 엔트리의 필터링을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_367", "content": "제364항에 있어서, 상기 2차 처리는 데이터베이스 엔트리의 필터링을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_368", "content": "제364항에 있어서, 상기 1차 처리와 상기 2차 처리는 데이터베이스 엔트리의 필터링을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-7008116", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일부 실시예들에서, 집적회로는 기판 및 상기 기판에 배치된 메모리 어레이를 포함할 수 있고, 상기 메모리 어레 이는 복수의 이산 메모리 뱅크를 포함한다. 상기 집적회로는 또한 상기 기판에 배치된 프로세싱 어레이를 포함할 수 있고, 상기 프로세싱 어레이는 복수의 프로세서 서브유닛을 포함하고, 상기 복수의 프로세서 서브유닛의 각 프로세서 서브유닛은 상기 복수의 이산 메모리 뱅크 중의 하나 이상의 이산 메모리 뱅크와 연관된다. 상기 집적 회로는 또한 상기 집적회로의 동작에 대한 적어도 하나의 보안 조치를 이행하고 상기 적어도 하나의 보안 조치가 촉발되는 경우에 하나 이상의 해결책을 취하도록 구성된 컨트롤러를 포함할 수 있다."}
{"patent_id": "10-2022-7008116", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 메모리 집약적 동작을 가능하게 하는 장치에 관한 것이다. 특히, 본 개시는 전용 메모리 뱅크에 연결 된 처리 소자를 포함하는 하드웨어칩에 관한 것이다. 본 개시는 또한 전력 효율과 메모리 칩의 속도를 개선하는 장치에 관한 것이다. 특히, 본 개시는 메모리 칩 상에 리프레시를 부분적으로 하거나 전혀 하지 않는 시스템 및 방법에 관한 것이다. 본 개시는 또한 선택 가능한 용량의 메모리 칩 및 메모리 칩 상의 듀얼 포트 능력에 관한 것이다."}
{"patent_id": "10-2022-7008116", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 출원은 2019년 8월 13일에 출원된 미국 가출원 번호 제62/886,328, 2019년 9월 29일에 출원된 미국 가출원 번호 제62/907,659, 2020년 2월 7일에 출원된 미국 가출원 번호 제62/971,912, 및 2020년 2월 28일에 출원된 미국 가출원 번호 제62/983,174를 우선권으로 주장하며, 그 내용이 사실상 여기에 전부 포함된다. 프로세서 속도와 메모리 용량이 지속적으로 상승함에 따라, 효과적인 처리 속도에 대한 중대한 한계는 폰노이만 병목현상(von Neumann bottleneck)이다. 폰노이만 병목현상은 기존의 컴퓨터 아키텍처의 스루풋(throughput) 한 계에서 기인한다. 특히, 프로세서에 의해 수행되는 실제 계산에 비해 메모리로부터 프로세서로의 데이터 전송에 병목이 생기는 경우가 많다. 이에 따라, 메모리 집약적 처리에서는 메모리에 읽기와 쓰기를 위한 클럭 사이클의 수가 상당히 증가한다. 클럭 사이클이 메모리에 읽기와 쓰기에 소비되고 데이터에 대한 연산을 수행하는데 활용 될 수 없으므로, 그 결과 효과적인 처리 속도에 손실이 발생한다. 또한, 프로세서의 계산 대역폭은 일반적으로 프로세서가 메모리에 접근하기 위해 사용하는 버스의 대역폭보다 크다. 이러한 병목현상은 신경망 및 기타 머신러닝 알고리즘, 데이터베이스 구축, 검색 인덱싱, 및 쿼리 처리와 같은 메모리 집약적 프로세스, 및 데이터 처리 동작보다 많은 읽기와 쓰기 동작을 수반하는 기타 작업에서 더욱 두드 러진다. 또한, 사용 가능한 디지털 데이터의 크기와 입도가 급성장하면서 머신러닝 알고리즘의 구성의 기회가 생겼고 새 로운 기술이 가능해졌다. 그러나 이로 인해 데이터베이스와 병렬 연산의 세계에 번거로운 문제도 생겨났다. 예 를 들어, 소셜미디어와 사물인터넷의 증가로 인해 전례 없는 속도로 디지털 데이터가 생성되고 있다. 이러한 새 로운 데이터는 새로운 광고 방식에서부터 더욱 정교한 산업 공정 제어 방법에 이르기까지 다양한 목적을 위한 알고리즘을 생성하는데 활용될 수 있다. 그러나 새로운 데이터의 저장, 처리, 분석, 및 취급이 쉽지 않았다. 새로운 데이터 소스는 페타바이트 내지 제타바이트 규모로 거대할 수 있다. 또한, 이러한 데이터 소스의 성장 속도는 데이터 처리 능력을 능가할 수 있다. 따라서, 데이터 과학자들은 이러한 문제를 해결하기 위하여 병렬 데이터 처리 방식을 채택해왔다. 계산 능력을 향상하고 거대한 양의 데이터를 취급하려는 노력의 일환으로, 과 학자들은 병렬 집약 계산이 가능한 시스템과 방법을 개발하려고 시도했다. 그러나 기존의 시스템과 방법은 그 방식이 데이터 관리, 분리된 데이터의 통합, 및 분리된 데이터의 분석을 위한 추가적인 리소스의 필요에 의해 제한을 받는 경우가 많기 때문에 데이터 처리의 요구조건을 따라가지 못했다. 대형 데이터 세트의 취급을 가능하게 하기 위하여, 엔지니어들과 과학자들은 이제 데이터 분석에 사용되는 하드 웨어를 향상하려고 노력한다. 예를 들어, 산술적 계산보다는 메모리 운용에 더 적합한 기술로 제조된 단일 기판 내에 메모리 및 처리 기능을 도입함으로써, 새로운 반도체 프로세서 또는 칩(예, 여기에 기재된 프로세서 또는 칩)이 데이터 집약적 작업에 특정하여 설계될 수 있다. 데이터 집약적 작업을 위해 특정 설계된 집적회로가 있 으면, 새로운 데이터 처리 요구조건의 충족이 가능하다. 그럼에도 불구하고, 대형 데이터 세트의 데이터 처리 문제를 해결하기 위한 이러한 접근방식에는 칩 설계와 제조에서 새로운 문제의 해결이 요구된다. 예컨대, 데이 터 집약적 작업을 위해 설계된 새로운 칩이 일반적인 칩에 사용되는 제조 기술과 아키텍처로 제조된다면, 새로 운 칩은 성능 저하 및/또는 수율 저조를 겪게 될 것이다. 또한, 새로운 칩이 기존의 데이터 취급 방법으로 동작 하도록 설계된다면, 새로운 칩이 병렬 연산을 처리할 능력은 기존의 방법에 의해 한계가 있으므로 새로운 칩의 성능은 저하될 것이다."}
{"patent_id": "10-2022-7008116", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 메모리 집약적 동작을 가능하게 하는 장치에 관한 것이다. 특히, 본 개시는 전용 메모리 뱅크에 연결 된 처리 소자를 포함하는 하드웨어칩에 관한 것이다. 본 개시는 또한 전력 효율과 메모리 칩의 속도를 개선하는장치에 관한 것이다. 특히, 본 개시는 메모리 칩 상에 리프레시를 부분적으로 하거나 전혀 하지 않는 시스템 및 방법에 관한 것이다. 본 개시는 또한 선택 가능한 용량의 메모리 칩 및 메모리 칩 상의 듀얼 포트 능력에 관한 것이다."}
{"patent_id": "10-2022-7008116", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일부 실시예들에서, 집적회로는 기판 및 상기 기판 상에 배치된 메모리 어레이를 포함할 수 있고, 상기 메모리 어레이는 복수의 이산 메모리 뱅크를 포함한다. 상기 집적회로는 또한 상기 기판 상에 배치된 프로세싱 어레이 를 포함할 수 있고, 상기 프로세싱 어레이는 상기 복수의 이산 메모리 뱅크 중의 하나 이상의 이산 메모리 뱅크 와 각각 연관되는 복수의 프로세서 서브유닛을 포함한다. 상기 집적회로는 또한, 상기 집적회로의 동작에 대한 적어도 하나의 보안 조치를 이행하고 상기 적어도 하나의 보안 조치가 촉발되는 경우에 하나 이상의 해결책을 취하도록 구성된 컨트롤러를 포함할 수 있다. 개시된 실시예들은 또한, 위조로부터 집적회로를 보호하는 방법을 포함할 수 있고, 상기 방법은 상기 집적회로 의 동작에 대한 적어도 하나의 보안 조치를 상기 집적회로와 연관된 컨트롤러를 사용하여 이행하는 단계 및 상 기 적어도 하나의 보안 조치가 촉발되는 경우에 하나 이상의 해결책을 취하는 단계를 포함하고, 상기 집적회로 는: 기판; 상기 기판 상에 배치되고 복수의 이산 메모리 뱅크를 포함하는 메모리 어레이; 및 상기 기판 상에 배 치되고 상기 복수의 이산 메모리 뱅크 중의 하나 이상의 이산 메모리 뱅크와 각각 연관되는 복수의 프로세서 서 브유닛을 포함하는 프로세싱 어레이를 포함한다. 개시된 실시예들은 집적회로를 포함할 수 있고, 상기 집적회로는: 기판; 상기 기판 상에 배치되고 복수의 이산 메모리 뱅크를 포함하는 메모리 어레이; 상기 기판 상에 배치되고 상기 복수의 이산 메모리 뱅크 중의 하나 이 상의 이산 메모리 뱅크와 각각 연관되는 복수의 프로세서 서브유닛을 포함하는 프로세싱 어레이; 및 상기 집적 회로의 동작에 대한 적어도 하나의 보안 조치를 이행하도록 구성된 컨트롤러를 포함하고, 여기서 상기 적어도 하나의 보안 조치는 적어도 2개의 상이한 메모리 부분에 프로그램 코드를 복제하는 것을 포함한다. 일부 실시예들에서, 기판, 상기 기판 상에 배치된 메모리 어레이, 상기 기판 상에 배치된 프로세싱 어레이, 제1 통신 포트, 및 제2 통신 포트를 포함하는 분산 프로세서 메모리 칩이 제공된다. 상기 메모리 어레이는 복수의 이산 메모리 뱅크를 포함할 수 있다. 상기 프로세싱 어레이는 상기 복수의 이산 메모리 뱅크 중에서 하나 이상 의 이산 메모리 뱅크와 각각 연관되는 복수의 프로세서 서브유닛을 포함할 수 있다. 상기 제1 통신 포트는 상기 분산 프로세서 메모리 칩과, 다른 분산 프로세서 메모리 칩이 아닌, 외부 엔티티 사이의 통신 연결을 구축하도 록 구성될 수 있다. 상기 제2 통신 포트는 상기 분산 프로세서 메모리 칩과 제1 추가 분산 프로세서 메모리 칩 사이의 통신 연결을 구축하도록 구성될 수 있다. 일부 실시예들에서, 제1 분산 프로세서 메모리 칩과 제2 분산 프로세서 메모리 칩 사이에 데이터를 전송하는 방 법은: 상기 제1 분산 프로세서 메모리 칩 상에 배치된 복수의 프로세서 서브유닛 중의 제1 프로세서 서브유닛이 상기 제2 분산 프로세서 메모리 칩에 포함된 제2 프로세서 서브유닛으로 데이터를 전송할 준비가 되었는지 여부 를 상기 제1 분산 프로세서 메모리 칩과 상기 제2 분산 프로세서 메모리 칩 중의 적어도 하나와 연관된 컨트롤 러를 사용하여 판단하는 단계; 및 상기 제1 프로세서 서브유닛이 상기 제2 프로세서 서브유닛으로 상기 데이터 를 전송할 준비가 되어 있다는 판단을 한 후에 상기 컨트롤러에 의해 제어되는 클럭 인에이블 신호를 사용하여 상기 제1 프로세서 서브유닛에서 상기 제2 프로세서 서브유닛으로 상기 데이터의 전송을 개시하는 단계를 포함 할 수 있다. 일부 실시예들에서, 메모리 유닛은: 복수의 메모리 뱅크를 포함하는 메모리 어레이; 상기 복수의 메모리 뱅크에 대한 읽기 동작의 적어도 일 양상을 제어하도록 구성된 적어도 하나의 컨트롤러; 및 상기 복수의 메모리 뱅크의 특정 어드레스에 저장된 다중 비트 0 값을 검출하도록 구성된 적어도 하나의 0 값 검출 논리부를 포함할 수 있 고, 상기 적어도 하나의 컨트롤러와 상기 적어도 하나의 0 값 검출 논리부는 상기 적어도 하나의 0 값 검출 논 리부에 의한 0 값 검출에 응답하여 0 값 지시자를 상기 메모리 유닛 외부의 하나 이상의 회로로 보내도록 구성 된다. 일부 실시예들은 복수의 이산 메모리 뱅크의 특정 어드레스에서 0 값을 검출하는 방법을 포함할 수 있고, 상기 방법은: 복수의 이산 메모리 뱅크의 어드레스에 저장된 데이터의 읽기 요청을 메모리 유닛 외부의 회로로부터 수신하는 단계; 상기 수신된 요청에 응답하여 0 값 검출 논리부를 활성화하여, 수신된 어드레스에서 컨트롤러가 0 값을 검출하는 단계; 및 상기 0 값 검출 논리부에 의한 상기 0 값 검출에 응답하여 상기 컨트롤러가 0 값 지 시자를 상기 회로로 전송하는 단계를 포함한다. 일부 실시예들은 메모리 유닛이 복수의 이산 메모리 뱅크의 특정 어드레스에서 0 값을 검출하게 유발하도록 상 기 메모리 유닛의 컨트롤러에 의해 실행 가능한 일련의 명령을 저장하는 비일시적 컴퓨터 판독가능 매체를 포함 할 수 있고, 상기 방법은: 복수의 이산 메모리 뱅크의 어드레스에 저장된 데이터의 읽기 요청을 메모리 유닛 외 부의 회로로부터 수신하는 단계; 상기 수신된 요청에 응답하여 0 값 검출 논리부를 활성화하여, 수신된 어드레 스에서 컨트롤러가 0 값을 검출하는 단계; 및 상기 0 값 검출 논리부에 의한 상기 0 값 검출에 응답하여 상기 컨트롤러가 0 값 지시자를 상기 회로로 전송하는 단계를 포함한다. 일부 실시예들에서, 메모리 유닛은: 하나 이상의 메모리 뱅크; 뱅크 컨트롤러; 및 어드레스 생성기를 포함할 수 있고, 상기 어드레스 생성기는 연관된 메모리 뱅크 내에서 접근될 현재 행의 현재 어드레스를 상기 뱅크 컨트롤 러로 제공하고, 상기 연관된 메모리 뱅크 내에서 접근될 다음 행의 예측 어드레스를 판단하고, 상기 현재 어드 레스와 연관된 상기 현재 행에 대한 읽기 동작이 완료되기 전에 상기 뱅크 컨트롤러로 상기 예측 어드레스를 제 공하도록 구성된다. 일부 실시예들에서, 메모리 유닛은 하나 이상의 메모리 뱅크를 포함할 수 있고, 상기 하나 이상의 메모리 뱅크 의 각 메모리 뱅크는 복수의 행, 상기 복수의 행의 제1 서브세트를 제어하도록 구성된 제1 행 컨트롤러, 상기 복수의 행에 저장될 데이터를 수신하기 위한 단일 데이터 입력, 및 상기 복수의 행으로부터 가져온 데이터를 제 공하기 위한 단일 데이터 출력을 포함한다. 일부 실시예들에서, 분산 프로세서 메모리 칩은: 기판; 상기 기판 상에 배치되고 복수의 이산 메모리 뱅크를 포 함하는 메모리 어레이; 상기 기판 상에 배치되고 상기 복수의 이산 메모리 뱅크 중의 상응하는 전용 이산 메모 리 뱅크와 각각 연관되는 복수의 프로세서 서브유닛을 포함하는 프로세싱 어레이; 상기 복수의 프로세서 서브유 닛 중의 하나를 그에 상응하는 전용 메모리 뱅크에 각각 연결하는 제1 복수의 버스; 및 상기 복수의 프로세서 서브유닛 중의 하나를 상기 복수의 프로세서 서브유닛의 다른 하나에 각각 연결하는 제2 복수의 버스를 포함할 수 있다. 상기 메모리 뱅크의 적어도 하나는 상기 기판 상에 배치된 적어도 하나의 DRAM 메모리 매트를 포함할 수 있다. 상기 프로세서 서브유닛의 적어도 하나는 상기 적어도 하나의 메모리 매트와 연관되는 하나 이상의 논 리 소자를 포함할 수 있다. 상기 적어도 하나의 메모리 매트와 상기 하나 이상의 논리 소자는 상기 복수의 프로 세서 서브유닛의 하나 이상에 대한 캐시 역할을 하도록 구성될 수 있다. 일부 실시예들에서, 분산 프로세서 메모리 칩의 적어도 하나의 명령을 실행하는 방법은: 상기 분산 프로세서 메 모리 칩의 메모리 어레이에서 하나 이상의 데이터 값을 가져오는 단계; 상기 하나 이상의 데이터 값을 상기 분 산 프로세서 메모리 칩의 메모리 매트에 형성된 레지스터에 저장하는 단계; 및 프로세서 요소에 의해 실행된 적 어도 하나의 명령에 따라, 상기 레지스터에 저장된 상기 하나 이상의 데이터 값에 접근하는 단계를 포함할 수 있고; 상기 메모리 어레이는 상기 기판 상에 배치된 복수의 이산 메모리 뱅크를 포함하고; 상기 프로세서 요소 는 상기 기판 상에 배치된 프로세싱 어레이에 포함된 복수의 프로세서 서브유닛 중의 프로세서 서브유닛이고, 상기 프로세서 서브 유닛 각각은 상기 복수의 이산 메모리 뱅크의 상응하는 전용 이산 메모리 뱅크와 연관되고; 상기 레지스터는 상기 기판 상에 배치된 메모리 매트에 의해 제공된다. 일부 실시예들은 기판; 상기 기판 상에 배치된 처리부; 및 상기 기판 상에 배치된 메모리 유닛을 포함할 수 있 고, 상기 메모리 유닛은 상기 처리부에 의해 접근될 데이터를 저장하도록 구성되고, 상기 처리부는 상기 처리부 에 대한 캐시 역할을 하도록 구성된 메모리 매트를 포함한다. 프로세싱 시스템들은 점점 더 많은 양의 정보를 매우 빠른 속도로 처리할 것으로 기대된다. 예를 들어, 5세대 (5G) 모바일 인터넷 네트워크는 방대한 양의 정보 스트림을 수신하고 이러한 정보 스트림을 더 빠른 속도로 처 리할 것으로 예상된다. 프로세싱 시스템은 하나 이상의 버퍼 및 프로세서를 포함할 수 있다. 프로세서에 의해 적용되는 프로세싱 동작 에는 지연이 있을 수 있고, 이에 따라 방대한 버퍼가 필요할 수 있다. 방대한 버퍼는 비용 및/또는 공간이 많이 필요할 수 있다. 버퍼에서 프로세서로 방대한 양의 정보를 전달하려면 버퍼와 프로세서 사이에 고대역폭 커넥터 및/또는 고대역 폭 버스가 필요할 수 있고, 이 또한 프로세싱 시스템의 비용과 공간을 증가시킬 수 있다. 이에 따라, 효율적인 프로세싱 시스템의 제공에 대한 요구가 증대되고 있다. 분리된 서버는 다중 서브시스템을 포함하고, 각 서브 시스템은 고유의 역할을 가지고 있다. 예를 들어, 분리된 서버는 하나 이상의 스위칭 서브시스템, 하나 이상의 컴퓨팅 서브시스템, 및 하나 이상의 스토리지 서브시스템을 포함할 수 있다. 상기 하나 이상의 컴퓨팅 서브시스템과 상기 하나 이상의 스토리지 서브시스템은 상기 하나 이상의 스위칭 서브 시스템을 통해 서로 결합된다. 컴퓨팅 서브시스템은 다중 컴퓨팅 유닛을 포함할 수 있다. 스위칭 서브시스템은 다중 스위칭 유닛을 포함할 수 있다. 스토리지 서브시스템은 다중 스토리지 유닛을 포함할 수 있다. 이러한 분리된 서버의 병목은 서브시스템 사이의 정보 전달에 필요한 대역폭에 있다. 상이한 컴퓨팅 서브시스템의 모든(또는 상당한 부분의) 컴퓨팅 유닛 사이에 정보 단위를 공유하는데 필요한 분 산 계산을 수행하는 경우에는 특히 그렇다. 공유에 가담하는 N개의 컴퓨팅 유닛이 있고, N은 매우 큰 정수(예를 들어, 적어도 1024)이고, N개의 컴퓨팅 유 닛은 각각 모든 다른 컴퓨팅 유닛으로(또는 모든 다른 컴퓨팅 유닛으로부터) 정보 단위를 전송(또는 수신)해야 한다고 가정하면, 약 N 번의 정보 단위 전송 프로세스를 수행할 필요가 있다. 이러한 많은 수의 전송 프로세스 는 시간과 에너지를 많이 필요로 하고 분리된 서버의 처리량을 극적으로 제한하게 된다. 이에 따라, 효율적인 분리된 서버와 분산 프로세싱의 효율적 수행 방법에 대한 요구가 증대되고 있다. 데이터베이스는 다중 필드를 포함하는 엔트리를 많이 포함한다. 데이터베이스 프로세싱은 하나 이상의 필터링 파라미터(예를 들어, 하나 이상의 관련 필드의 정체 및 값)를 포함하고 실행될 연산의 종류를 판단할 수 있는 하나 이상의 연산 파라미터, 상기 연산을 적용하는 경우에 사용될 변수 또는 정수 등을 포함하는 하나 이상의 쿼리의 실행을 포함하는 것이 일반적이었다. 예를 들어, 데이터베이스 쿼리는 특정 필드가 소정의 범위 이내의 값을 가진(필터링 파라미터) 상기 데이터베이 스의 모든 기록에 대한 통계 연산(연산 파라미터)의 수행을 요청할 수 있다. 다른 예를 들면, 데이터베이스 쿼 리는 임계값보다 작은(필터링 파라미터) 특정 필드를 가진 기록의 삭제(연산 파라미터)를 요청할 수 있다. 양이 큰 데이터베이스는 일반적으로 스토리지 장치에 저장된다. 쿼리에 응답하기 위하여, 상기 데이터베이스는 메모리 유닛으로 전송되며, 일반적으로 데이터베이스 세그먼트별로 차례로 전송된다. 상기 데이터베이스의 상기 엔트리는 상기 메모리 유닛으로부터 상기 메모리 유닛과 동일한 집적회로에 속해 있 지 않은 프로세서로 전송된다. 이어서 상기 엔트리는 상기 프로세서에 의해 처리된다. 상기 메모리 유닛에 저장된 상기 데이터베이스의 각 데이터베이스 세그먼트에 대해, 상기 처리는: (i) 상기 데 이터베이스 세그먼트의 기록을 선택하는 단계; (ii) 상기 기록을 상기 메모리 유닛으로부터 상기 프로세서로 전 송하는 단계; (iii) 상기 프로세서가 상기 기록을 필터링하여 상기 기록이 관련이 있는지 여부를 판단하는 단계; (iv) 상기 관련 기록에 대해 하나 이상의 추가 연산(합산, 기타 수학적 및/또는 통계적 연산의 적용)을 수행하는 단계를 포함한다. 상기 필터링 단계는 상기 기록이 모두 상기 프로세서로 전송되고 상기 프로세서가 어느 기록이 관련이 있는지 판단을 한 후에 중단한다. 데이터 베이스의 상기 관련 엔트리가 상기 프로세서에 저장되어 있지 않은 경우에 이러한 관련 기록을 상기 프 로세서로 전송하여 상기 필터링 단계 이후에 추가적으로 처리(상기 프로세싱에 후속하는 상기 연산을 적용)할 필요가 있다. 다중 프로세싱 연산이 단일 필터링에 후속하는 경우, 각 연산의 결과는 상기 메모리 유닛으로 전송된 후에 다시 상기 프로세서로 전송될 수 있다. 이러한 프로세스에는 대역폭과 시간이 많이 소모된다. 이에 따라, 데이터베이스 프로세싱을 수행하기 위한 효율적인 방식에 대한 요구가 증대되고 있다. 워드 임베딩(word embedding)은 어휘에서 단어 또는 구절이 요소의 벡터로 매핑되는 자연어 처리(natural language processing (NLP))의 언어 모델링 및 특징 학습 방식의 모음에 대한 포괄적인 명칭이다. 개념적으로, 단어당 많은 차원이 있는 공간으로부터 훨씬 적은 차원이 있는 연속적 벡터 공간으로의 수학적 매핑이 개입된다 (www.wikipedia.org 참고). 이러한 매핑을 생성하는 방법에는 신경망, 단어 동시 등장 행렬(word co-occurrence matrix)에 대한 차원 축소 (dimensionality reduction), 설명 가능한 지식 기반 방법, 및 단어가 등장하는 맥락 차원의 명시적 표현이 포 함된다. 단어 및 구절 임베딩은 입력 표현의 근간으로 사용되는 경우에 구문 분석(syntactic parsing) 및 감성 분석 (sentiment analysis)과 같은 NLP 작업에서의 성능을 증가시키는 것으로 나타났다. 문장은 단어 또는 구절로 구분될 수 있고, 각 구간은 벡터로 표현될 수 있다. 문장은 그 문장의 단어 또는 구절 을 표현하는 모든 벡터를 포함하는 행렬로 표현될 수 있다. 단어를 벡터로 매핑하는 어휘는 단어 또는 구절(또는 해당 단어를 나타내는 색인)을 활용하여 접근될 수 있는 메모리 유닛(예, DRAM)에 저장될 수 있다. 액세스는 DRAM의 스루풋을 감소시키는 랜덤 액세스일 수 있다. 또한, 액세스는, 특히 많은 수의 액세스가 DRAM 에 넣어지는 경우, DRAM을 포화시킬 수 있다. 문장에 포함되는 단어들은 일반적으로 매우 무작위적이다. 매핑을 저장하는 DRAM 메모리에 접근하면, DRAM 버스 트(bursts)를 활용하는 경우라고 하더라도, 일반적으로 랜덤 액세스의 성능 저하의 결과를 가져오게 된다. 이는, 일반적으로 버스트 중에 DRAM 메모리 뱅크 엔트리의 작은 부분의 하나만이 특정 문장에 관련이 있는 엔트 리를 저장하게 되기 때문이다. 이에 따라, DRAM 메모리의 스루풋은 낮고 연속적이지 않다. 문장의 각 단어 또는 구절은 DRAM 메모리의 집적회로의 외부에 있는 호스트 컴퓨터의 제어 하에 DRAM 메모리에 서 가져와 지고, 해당 단어의 위치에 대한 지식에 기반하여 각 단어 또는 구간을 나타내는 각 벡터의 검색을 제 어해야 한다. 이는 시간과 리소스가 많이 드는 작업이다. 데이터 센터들과 기타 컴퓨터 시스템들은 매우 빠른 속도로 점점 더 많은 양의 정보를 처리하고 교환해야 할 것으로 기대되고 있다. 점점 더 많은 양의 데이터의 교환은 데이터 센터들과 기타 컴퓨터 시스템들의 병목이 될 수 있고, 이러한 데이 터 센터들과 기타 컴퓨터 시스템들의 역량의 일부만이 활용되는 원인이 될 수 있다. 도 96a는 종래 기술의 데이터베이스와 종래 기술의 마더보드의 일례를 도시한 것이다. 데이터베 이스는 다중 서버를 포함할 수 있고, 각 서버는 다중 서버 마더보드(\"CPU + 메모리 + 네트워크\")를 포함할 수 있다. 각 서버 마더보드는 트래픽을 수신하고 메모리 유닛(RAM) 및 다중 데이터베이스 가속기(DB 가속기)에 연결되는 CPU(INTEL사의 XEON 등)를 포함한다. DB 가속기는 선택 사항이고, DB 가속 동작은 CPU에 의해 수행될 수 있다. 모든 트래픽은 CPU를 통해 흐르고, CPU는 PCIe와 같은 상대적으로 제한적인 대역폭인 링크를 통해 DB 가속기에 결합될 수 있다. 다중 마더보드 간에 정보 단위들을 보내는 데에 많은 양의 리소스가 전용된다. 이에 따라, 효율적인 데이터 센터 및 기타 컴퓨터 시스템의 제공에 대한 요구가 증대되고 있다. 신경망과 같은 인공지능(AI) 응용은 그 크기가 극적으로 증가하고 있다. 증가하는 신경망의 크기에 대처하기 위 하여, 각각 AI 가속 서버(서버 마더보드를 포함함) 역할을 하는 다중 서버가 사용되어 학습 등과 같은 신경망 처리 작업을 수행한다. 상이한 랙에 배치된 다중 AI 가속 서버를 포함하는 시스템의 일례가 도 1에 도시되어 있 다. 전형적인 학습 세션에서, 매우 많은 수의 이미지가 동시에 처리되어 손실과 같은 방대한 수의 값을 제공한다. 방대한 수의 값은 상이한 AI 가속 서버 사이에서 전달되고, 그 결과로 이례적인 양의 트래픽이 발생한다. 예를 들어, 일부 신경망층은 상이한 AI 가속 서버에 위치한 다중 GPU에 걸쳐 계산될 수 있고, 네트워크를 통한 취합 이 필요할 수 있고 이는 많은 대역폭을 필요로 하게 된다. 이례적인 양의 트래픽을 전달하려면 초고대역폭(ultra-high bandwidth)이 필요하고, 이는 실현 가능하지 않거나 비용 효율적이지 못할 수 있다. 도 97a는 서브시스템들을 포함하는 시스템을 도시하고 있다. 여기서, 각 서브시스템은 RAM 메모리(RAM 12056), 중앙처리장치(CPU 12054), 네트워크 인터페이스 카드(NIC 12053)를 포함하는 서버 마더보드가 있는 AI 가속 서버를 연결하는 스위치를 포함하고, 상기 CPU는 (PCIe 버스를 통해) 다중 AI 가속기(예, 그래픽처리장치, AI 칩(AI ASIC), FPGA 등)로 연결된다. NIC는 네트워크에 의해(예, 이 더넷, UDP 링크 등을 사용) 서로 결합(예, 하나 이상의 스위치에 의해 결합)되고, 이러한 NIC는 시스템이 요구 하는 초고대역폭 전달이 가능할 수 있다. 이에 따라, 효율적인 AI 컴퓨팅 시스템에 대한 요구가 증대되고 있다. 기타 개시된 실시예들에 따라, 비일시적 컴퓨터 판독가능 저장 매체는 적어도 하나의 처리 장치에 의해 실행되 고 여기에 기재된 방법 중의 하나 이상을 수행하는 프로그램 명령을 저장할 수 있다. 상기의 일반적인 설명과 하기의 상세한 설명은 예시에 불과하며 본 개시의 청구 범위에 대한 한정이 아니다."}
{"patent_id": "10-2022-7008116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "하기의 상세한 설명은 첨부한 도면을 참조한다. 편의상, 도면과 설명에서 동일 또는 유사한 구성요소에 동일한 참조 번호를 사용한다. 여러 예시적인 실시예를 설명하지만, 다양한 변경, 개조, 구현 등이 가능하다. 예를 들 어, 도면에 예시된 구성요소를 치환, 또는 추가, 변경할 수 있고, 설명에 포함된 방법은 단계를 치환하거나 순 서를 바꾸거나 삭제하거나 추가하여 변경할 수 있다. 따라서, 하기의 상세한 설명은 개시된 실시예와 예시에 국 한되지 않고, 올바른 청구 범위는 첨부된 청구항에 의해 정의된다. 프로세서 아키텍처 본 개시의 전체를 통해, '하드웨어 칩'이라는 용어는 하나 이상의 회로 소자(예, 트랜지스터, 커패시터, 저항기 등)가 형성되는 반도체 웨이퍼(실리콘 등)를 말한다. 회로 소자는 처리 소자 또는 메모리 소자를 형성할 수 있 다. '처리 소자'는 적어도 하나의 논리 함수(예, 산술 함수, 논리 게이트, 기타 불리언(Boolean) 연산 등)을 함 께 수행하는 하나 이상의 회로 소자를 말한다. 처리 소자는 범용 처리 소자(예, 설정 가능한 복수의 트랜지스터) 또는 전용 처리 소자(예, 특정 논리 함수를 수행하도록 설계된 특정 논리 게이트 또는 복수의 회로 소자)일 수 있다. '메모리 소자'는 데이터를 저장하는데 활용될 수 있는 하나 이상의 회로 소자를 말한다. '메 모리 소자'는 또한 '메모리 셀'로 불릴 수도 있다. 메모리 소자는 동적(즉, 데이터 저장을 유지하기 위해 전기 적 리프레쉬가 필요), 정적(즉, 전원이 차단된 이후의 일정 시간 동안 데이터 유지), 또는 비휘발성 메모리일 수 있다. 처리 소자는 서로 접합되어 프로세서 서브유닛(subunit)을 형성할 수 있다. 이에 따라, '프로세서 서브유닛'은 적어도 하나의 작업 또는 명령(예, 프로세서 명령 세트의 작업 또는 명령)을 실행할 수 있는 최소 묶음의 처리 소자를 포함할 수 있다. 예를 들어, 서브유닛은 명령을 함께 실행하도록 구성된 하나 이상의 범용 처리 소자, 하나 이상의 전용 처리 소자와 쌍을 이루어 서로 보완적인 방식으로 명령을 실행하도록 구성된 하나 이상의 범 용 처리 소자 등을 포함할 수 있다. 프로세서 서브유닛은 기판(예, 웨이퍼) 상에 어레이로 배치될 수 있다. '어 레이'는 직사각형상을 포함할 수 있지만, 서브유닛의 어레이 배치는 기판 상에서 기타 모든 형상으로 형성될 수 있다. 메모리 소자는 서로 접합되어 메모리 뱅크를 형성할 수 있다. 예를 들어, 메모리 뱅크는 적어도 하나의 회선(또 는 기타 전도성 연결)을 따라 연결된 하나 이상의 메모리 소자 라인을 포함할 수 있다. 또한, 메모리 소자는 다 른 방향의 적어도 하나의 추가 회선을 따라 연결될 수 있다. 예를 들어, 메모리 소자는 하기에 설명하는 바와 같이 워드라인(wordline)과 비트라인(bitline)을 따라 배치될 수 있다. 메모리 뱅크가 라인을 포함할 수 있지만, 기타 모든 배치를 활용하여 소자를 기판 내에 배치하여 기판 상에 뱅크를 형성할 수 있다. 또한, 하나 이상의 뱅크가 적어도 하나의 메모리 컨트롤러에 전기적으로 접합되어 메모리 어레이를 형성할 수 있다. 메모리 어레이는 장방형 배치의 뱅크를 포함할 수 있지만, 어레이 내의 뱅크의 배치는 기판 상에서 기타 모든 형상으로 형성될 수 있다. 본 개시의 전체를 통해, '버스'는 기판의 소자 사이의 모든 통신 연결을 말한다. 예를 들어, 회선 또는 라인(전 기적 연결 형성), 광섬유(광 연결 형성), 또는 구성 부품 사이의 통신을 하는 기타 모든 연결이 '버스'로 지칭 될 수 있다. 기존의 프로세서에서는 범용 논리 회로와 공유 메모리가 쌍을 이룬다. 공유 메모리는 논리 회로가 실행할 명령 세트뿐만 아니라 명령 세트의 실행에 활용할 데이터와 명령 세트의 실행의 결과로 획득하는 데이터를 모두 저장 할 수 있다. 하기에 설명하는 바와 같이, 일부 기존 프로세서는 캐싱(caching) 시스템을 활용하여 공유 메모리 로부터의 읽기 지연을 줄이지만, 기존의 캐싱 시스템은 공유 상태를 유지하고 있다. 기존 프로세서는 중앙처리 장치(CPU), 그래픽처리장치(GPU), 다양한 주문형반도체(ASIC) 등을 포함한다. 도 1은 CPU의 일례를 도시한 것이 고, 도 2는 GPU의 일례를 도시한 것이다. 도 1에 도시된 바와 같이, CPU는 프로세서 서브유닛(120a)과 프로세서 서브유닛(120b)과 같은 하나 이상의 프로세서 서브유닛을 포함하는 처리부를 포함할 수 있다. 도 1에는 도시되어 있지 않지만, 각 프로세서 서 브유닛은 복수의 처리 소자를 포함할 수 있다. 또한, 처리부는 하나 이상의 단계의 온칩캐시(on-chip cache)를 포함할 수 있다. 이러한 캐시 소자는 프로세서 서브유닛(120a, 120b)과 캐시 소자를 포함하는 기판 내 에 형성된 하나 이상의 버스를 통해 프로세서 서브유닛(120a, 120b)에 연결되기 보다는 대부분 처리부와 동일한 반도체 다이 상에 형성된다. 버스를 통한 연결보다는 동일 다이 상의 직접 배치는 기존 프로세서의 1단 계(L1) 캐시와 2단계(L2) 캐시에 모두 일반적이다. 또는, 구형 프로세서에서, L2 캐시는 프로세서 서브유닛과 L2 캐시 사이의 후면 버스(back-side bus)를 사용하여 프로세서 서브유닛 사이에 공유되었다. 후면 버스는, 하 기에 설명하는 바와 같이, 일반적으로 전면 버스(front-side bus)보다 크다. 이에 따라, 캐시는 다이 상의 모든 프로세서 서브유닛과 공유돼야 하므로, 캐시가 프로세서 서브유닛(120a, 120b)과 동일한 다이 상에 형성되 거나 하나 이상의 후면 버스를 통하여 프로세서 서브유닛(120a, 120b)에 통신 가능하게 결합될 수 있다. 버스가 없는 실시예(예, 캐시가 다이 상에 직접 형성)와 후면 버스를 활용하는 실시예 모두에서, 캐시는 CPU의 프로세 서 서브유닛 간에 공유된다. 또한, 처리부는 공유 메모리(140a) 및 공유 메모리(140b)와 통신한다. 예를 들어, 메모리(140a, 140b)는 공유 DRAM(dynamic random access memory)의 메모리 뱅크를 나타내는 것일 수 있다. 도면에는 두 개의 뱅크가 도시되었지만, 대부분의 기존 메모리 칩은 8개 내지 16개의 메모리 뱅크를 포함한다. 이에 따라, 프로세서 서브 유닛(120a, 120b)은 공유 메모리(140a, 140b)를 활용하여 프로세서 서브유닛(120a, 120b)에 의해 운용될 데이터 를 저장할 수 있다. 그러나 이러한 구성의 결과로, 처리부의 클럭 속도가 버스의 데이터 전송 속도를 초과 하는 경우에, 메모리(140a, 140b)와 처리부 사이의 버스는 병목이 된다. 이는 기존 프로세서에서 일반적이 며, 이에 따라 클럭 속도와 트랜지스터 수에 의거한 처리 속도 사양보다 처리 속도가 떨어지는 결과를 초래한다. 도 2에 도시된 바와 같이, 유사한 문제가 GPU에도 존재한다. GPU는 하나 이상의 프로세서 서브유닛(예, 서 브유닛(220a, 220b, 220c, 220d, 220e, 220f, 220g, 220h, 220i, 220j, 220k, 220l, 220m, 220n, 220o, 220p))을 포함하는 처리부를 포함할 수 있다. 또한, 처리부는 하나 이상의 단계의 온칩캐시 및/또는 레지스터 파일을 포함할 수 있다. 이러한 캐시 소자는 일반적으로 처리부와 동일한 반도체 다이 상에 형성된다. 실제로, 도 2의 예에서, 캐시는 처리부와 동일한 다이 상에 형성되고 모든 프로세서 서브유닛 사이에서 공유되는 반면, 캐시(230a, 230b, 230c, 230d)는 각각 프로세서 서브세트(subset) 상에 형성되고 그 전용이 된다. 또한, 처리부는 공유 메모리(250a, 250b, 250c, 250d)와 통신한다. 예를 들어, 메모리(250a, 250b, 250c, 250d)는 공유 DRAM의 메모리 뱅크를 나타내는 것일 수 있다. 이에 따라, 처리부의 프로세서 서브유닛은 공 유 메모리(250a, 250b, 250c, 250d)를 활용하여 프로세서 서브유닛에 의해 이후에 운용되는 데이터를 저장할 수 있다. 그러나 앞서 CPU에 대한 설명과 유사하게, 이러한 배치의 결과로 메모리(250a, 250b, 250c, 250d)와 처리 부 사이의 버스는 병목이 된다. 개시된 하드웨어 칩의 개요 도 3a는 예시적인 하드웨어 칩의 일 실시예를 개략적으로 도시한 것이다. 하드웨어 칩은 앞서 설명한 CPU, GPU, 및 기타 기존 프로세서에 대한 병목을 완화하도록 설계된 분산 프로세서를 포함할 수 있다. 분산 프 로세서는 단일 기판 상에 공간적으로 분산된 복수의 프로세서 서브유닛을 포함할 수 있다. 또한, 앞서 설명한 바와 같이, 본 개시의 분산 프로세서에서, 상응하는 메모리 뱅크도 기판 상에서 공간적으로 분산되어 있다. 일 부 실시예에서, 분산 프로세서는 명령 세트와 연관되어 있고, 분산 프로세서의 프로세서 서브유닛의 각 서브유 닛은 명령 세트에 포함된 하나 이상의 작업의 수행을 담당할 수 있다. 도 3a에 도시된 바와 같이, 하드웨어 칩은 논리 및 제어 서브유닛(320a, 320b, 320c, 320d, 320e, 320f, 320g, 320h)과 같은 복수의 프로세서 서브유닛을 포함할 수 있다. 도 3a에 더 도시된 바와 같이, 각 프로세서 서브유닛은 전용 메모리 인스턴스(memory instance)를 포함할 수 있다. 예컨대, 논리 및 제어 서브유닛(320a)은 전용 메모리 인스턴스(330a)에 작동적으로 연결되고, 논리 및 제어 서브유닛(320b)은 전용 메모리 인스턴스 (330b)에 작동적으로 연결되고, 논리 및 제어 서브유닛(320c)은 전용 메모리 인스턴스(330c)에 작동적으로 연결 되고, 논리 및 제어 서브유닛(320d)은 전용 메모리 인스턴스(330d)에 작동적으로 연결되고, 논리 및 제어 서브 유닛(320e)은 전용 메모리 인스턴스(330e)에 작동적으로 연결되고, 논리 및 제어 서브유닛(320f)은 전용 메모리 인스턴스(330f)에 작동적으로 연결되고, 논리 및 제어 서브유닛(320g)은 전용 메모리 인스턴스(330g)에 작동적 으로 연결되고, 논리 및 제어 서브유닛(320h)은 전용 메모리 인스턴스(330h)에 작동적으로 연결된다. 도 3a에는 각 메모리 인스턴스가 단일 메모리 뱅크인 것으로 도시되어 있지만, 하드웨어 칩은 하드웨어 칩 상의 프로세서 서브유닛에 대한 전용 메모리 인스턴스로 둘 이상의 메모리 뱅크를 포함할 수 있다. 또한, 도 3a에는 각 프로세서 서브유닛이 각 전용 메모리 뱅크에 대해 논리 소자와 제어를 모두 포함하는 것으로 도시 되어 있지만, 하드웨어 칩은 적어도 부분적으로는 논리 소자와 분리된 제어를 메모리 뱅크에 대해 사용할 수도 있다. 또한, 도 3a에 도시된 바와 같이, 둘 이상의 프로세서 서브유닛과 그에 상응하는 메모리 뱅크가 예 를 들어 프로세싱 그룹(310a, 310b, 310c, 310d)으로 합쳐질 수 있다. '프로세싱 그룹'이란 하드웨어 칩이 형성되는 기판 상의 공간적 구분을 나타내는 것일 수 있다. 이에 따라, 프로세싱 그룹은, 예를 들어 제어(340a, 340b, 340c, 340d)와 같은, 프로세싱 그룹의 메모리 뱅크에 대한 추가적인 제어를 더 포함할 수 있다. 추가적으 로 또는 대안적으로, '프로세싱 그룹'은 하드웨어 칩 상에서 실행할 코드의 컴파일을 위한 논리 묶음을 나 타내는 것일 수 있다. 이에 따라, 하드웨어 칩에 대한 컴파일러(하기에 설명)가 전반적인 명령 세트를 하 드웨어 칩 상의 프로세싱 그룹 간에 분리할 수 있다. 또한, 호스트가 하드웨어 칩으로 명령, 데이터, 및 기타 입력을 제공하고 하드웨어 칩으로부터 출력을 읽을 수 있다. 이에 따라, 명령 세트 전체가 단일 다이, 예를 들어 하드웨어 칩을 호스트하는 다이 상에서 실행될 수 있다. 실제로, 다이 밖에서의 통신은 하드웨어 칩으로의 명령 로딩, 하드웨어 칩으 로의 입력 전송, 및 하드웨어 칩으로부터의 출력 읽기가 전부일 수 있다. 이에 따라, 하드웨어 칩의 프로세서 서브유닛은 하드웨어 칩의 전용 메모리 뱅크와 통신하므로, 모든 계산과 메모리 연산은 다이 상 (하드웨어 칩 상)에서 수행될 수 있다. 도 3b는 다른 예시적인 하드웨어 칩(300')의 실시예를 개략적으로 도시한 것이다. 하드웨어 칩의 대안으로 도시되었지만, 도 3b에 도시된 아키텍처는 적어도 부분적으로는 도 3a에 도시된 아키텍처와 병합될 수 있다. 도 3b에 도시된 바와 같이, 하드웨어 칩(300')은 프로세서 서브유닛(350a, 350b, 350c, 350d)과 같은 복수의 프 로세서 서브유닛을 포함할 수 있다. 도 3b에 더 도시된 바와 같이, 각 프로세서 서브유닛은 복수의 전용 메모리 인스턴스를 포함할 수 있다. 예컨대, 프로세서 서브유닛(350a)은 전용 메모리 인스턴스(330a, 330b)에 연결되고, 프로세서 서브유닛(350b)은 전용 메모리 인스턴스(330c, 330d)에 연결되고, 프로세서 서브유닛(350c)은 전용 메모리 인스턴스(330e, 330f)에 연결되고, 프로세서 서브유닛(350d)은 전용 메모리 인스턴스(330g, 330h)에 연결된다. 또한, 도 3b에 도시된 바와 같이, 프로세서 서브유닛과 그에 상응하는 메모리 뱅크는 예를 들어 프로세싱 그룹(310a, 310b, 310c, 310d)으로 합쳐질 수 있다. 앞서 설명한 바와 같이, '프로세싱 그룹'이 란 하드웨어 칩(300')이 형성되는 기판 상의 공간적 구분 및/또는 하드웨어 칩(300') 상에서 실행할 코드의 컴 파일을 위한 논리 묶음을 나타내는 것일 수 있다. 도 3b에 더 도시된 바와 같이, 프로세서 서브유닛은 버스를 통하여 서로 통신할 수 있다. 예를 들어, 도 3b에 도시된 바와 같이, 프로세서 서브유닛(350a)은 버스(360a)를 통하여 프로세서 서브유닛(350b)과 통신하고, 버스 (360c)를 통하여 프로세서 서브유닛(350c)과 통신하고, 버스(360f)를 통하여 프로세서 서브유닛(350d)과 통신할 수 있다. 마찬가지로, 프로세서 서브유닛(350b)은 버스(360a)를 통하여 프로세서 서브유닛(350a)과 통신하고(상 기에 설명), 버스(360e)를 통하여 프로세서 서브유닛(350c)과 통신하고(상기에 설명), 버스(360d)를 통하여 프 로세서 서브유닛(350d)과 통신할 수 있다. 또한, 프로세서 서브유닛(350c)은 버스(360c)를 통하여 프로세서 서 브유닛(350a)과 통신하고(상기에 설명), 버스(360e)를 통하여 프로세서 서브유닛(350b)과 통신하고(상기에 설명), 버스(360b)를 통하여 프로세서 서브유닛(350d)과 통신할 수 있다. 이에 따라, 프로세서 서브유닛(350d) 은 버스(360f)를 통하여 프로세서 서브유닛(350a)과 통신하고(상기에 설명), 버스(360d)를 통하여 프로세서 서 브유닛(350b)과 통신하고(상기에 설명), 버스(360b)를 통하여 프로세서 서브유닛(350c)과 통신할 수 있다(상기 에 설명). 본 개시의 당업자라면, 도 3b에 도시된 것보다 적은 수의 버스가 사용될 수 있음을 이해할 것이다. 예를 들어, 프로세서 서브유닛(350b)과 프로세서 서브유닛(350c) 사이의 통신이 프로세서 서브유닛(350a) 및/또 는 프로세서 서브유닛(350d)을 통하여 이루어지도록 버스(360e)가 제거될 수 있다. 마찬가지로, 프로세서 서브 유닛(350a)과 프로세서 서브유닛(350d) 사이의 통신이 프로세서 서브유닛(350b) 또는 프로세서 서브유닛(350c) 을 통하여 이루어지도록 버스(360f)가 제거될 수 있다. 또한, 본 개시의 당업자라면, 도 3a와 도 3b에 도시된 것과 다른 아키텍처가 활용될 수 있음을 이해할 것이다. 예를 들어, 각각 단일 프로세서 서브유닛과 메모리 인스턴스를 포함하는 프로세싱 그룹의 어레이가 기판 상에 배치될 수 있다. 프로세서 서브유닛은 상응하는 전용 메모리 뱅크에 대한 컨트롤러의 일부, 상응하는 전용 메모 리 매트(memory mat)에 대한 컨트롤러의 일부 등을 추가적으로 또는 대안적으로 형성할 수 있다. 상기 설명한 아키텍처에 따라, 하드웨어 칩(300, 300')은 메모리 집약적 작업에 대해 기존의 아키텍처에 비해 상당히 증가된 효율을 제공할 수 있다. 예를 들어, 데이터베이스 연산 및 인공지능 알고리즘(예, 신경망)은 기 존의 아키텍처가 하드웨어 칩(300, 300')보다 효율성이 떨어지는 메모리 집약적 작업의 예이다. 이에 따라, 하 드웨어 칩(300, 300')은 데이터베이스 가속기(accelerator) 프로세서 및/또는 인공지능 가속기 프로세서로 불릴 수 있다. 개시된 하드웨어 칩의 설정 상기에 설명한 하드웨어 칩 아키텍처는 코드의 실행을 위해 구성될 수 있다. 예를 들어, 각 프로세서 서브유닛 은 하드웨어 칩 내의 다른 프로세서 서브유닛과 별개로 개별적으로 코드(명령 세트를 정의)를 실행할 수 있다. 이에 따라, 멀티스레딩(multithreading)을 관리하기 위하여 운영체제에 의존하거나 멀티태스킹(병렬성보다는 동 시성)을 활용하기보다, 본 개시의 하드웨어 칩은 프로세서 서브유닛이 완전히 병렬로 동작하게 할 수 있다. 앞서 설명한 완전 병렬 구현 외에도, 각 프로세서 서브유닛에 배정된 명령의 적어도 일부는 중첩할 수 있다. 예 를 들어, 분산 프로세서 상에 배치된 복수의 프로세서 서브유닛은 운영체제 또는 기타 관리 소프트웨어의 구현 등으로서 중복 명령을 실행할 수 있는 반면에, 운영체제 또는 기타 관리 소프트웨어의 컨텍스트 내에서 병렬 작 업을 수행하기 위하여 비중복(non-overlapping) 명령을 실행할 수 있다. 도 4는 프로세싱 그룹으로 일반적인 명령을 실행하는 예시적인 프로세스를 도시한 것이다. 예컨대, 프로세싱 그룹은 본 개시의 하드웨어 칩의 일부를 포함할 수 있다(하드웨어 칩, 하드웨어 칩(300') 등). 도 4에 도시된 바와 같이, 전용 메모리 인스턴스와 쌍을 이룬 프로세서 서브유닛으로 명령이 전송될 수 있다. 외부 호스트(예, 호스트)가 실행을 위해 명령을 프로세싱 그룹으로 전송할 수 있다. 또는, 프로세서 서브유닛이 메모리 인스턴스로부터 명령을 가져오고 가져온 명령을 실행할 수 있도록, 호스 트가 상기 명령을 포함하는 명령 세트를 전송하여 메모리 인스턴스에 저장할 수 있다. 이에 따라, 가 져온 명령을 실행하게 구성될 수 있는 일반적인 처리 소자인 처리 소자에 의해 명령이 실행될 수 있다. 또 한, 프로세싱 그룹은 메모리 인스턴스에 대한 컨트롤을 포함할 수 있다. 도 4에 도시된 바와 같이, 컨트롤은 수신된 명령을 실행할 때 처리 소자에 의해 요구되는 메모리 인스턴스로의 읽기 및/또는 쓰기를 수행할 수 있다. 명령의 실행 후, 프로세싱 그룹은 명령의 결과를 외부 호스트로 또는 동 일 하드웨어 칩 상의 다른 프로세싱 그룹 등으로 출력할 수 있다. 일부 실시예에서, 도 4에 도시된 바와 같이, 프로세서 서브유닛은 어드레스 생성기를 더 포함할 수 있다. '어드레스 생성기'는 읽기와 쓰기를 수행하기 위한 하나 이상의 메모리 뱅크의 어드레스를 판단하도록 구 성된 복수의 처리 소자를 포함할 수 있고, 또한 판단된 어드레스에 위치한 데이터에 연산(예, 덧셈, 뺄셈, 곱셈 등)을 수행할 수 있다. 예를 들어, 어드레스 생성기는 메모리로의 읽기 또는 쓰기를 위한 어드레스를 판단 할 수 있다. 일 실시예에서, 어드레스 생성기는 읽기 값이 더 이상 필요하지 않은 경우에 명령에 의거하여 판단된 새로운 값으로 읽기 값을 덮어씀으로써 효율을 향상할 수 있다. 추가적으로 또는 대안적으로, 어드레스 생성기는 명령 실행의 결과를 저장할 사용 가능한 어드레스를 선택할 수 있다. 이로써, 외부 호스트에게 더 편리한 나중의 클럭 사이클에 대한 결과 읽기를 스케줄 할 수 있게 된다. 다른 예에서, 어드레스 생성기 는 벡터 또는 행렬 곱셈-누적(multiply-accumulate) 계산과 같은 멀티사이클 계산 동안에 읽기 및 쓰기를 할 어드레스를 판단할 수 있다. 이에 따라, 어드레스 생성기는 데이터를 읽고 멀티사이클 계산의 중간 결 과를 쓰기 위한 메모리 어드레스를 유지 또는 계산하여, 프로세서 서브유닛이 이러한 메모리 어드레스를 저장할 필요 없이 계속 처리할 수 있도록 할 수 있다. 도 5는 프로세싱 그룹으로 특수 명령을 실행하기 위한 예시적인 프로세스를 도시한 것이다. 예를 들 어, 프로세싱 그룹은 본 개시의 하드웨어 칩의 일부를 포함할 수 있다(하드웨어 칩, 하드웨어 칩 (300') 등). 도 5에 도시된 바와 같이, 전용 메모리 인스턴스와 쌍을 이룬 처리 소자로 특수 명령(예, 곱셈-누적 명령)이 전송될 수 있다. 외부 호스트(예, 호스트)가 실행을 위해 명령을 처리 소자로 전송할 수 있 다. 이에 따라, 특정 명령(수신된 명령 포함)을 실행하도록 구성된 특수 처리 소자인 처리 소자에 의해 명 령이 호스트로부터의 특정 신호에 실행될 수 있다. 또는, 처리 소자는 실행을 위해 메모리 인스턴스 로부터 명령을 가져올 수 있다. 따라서, 도 5의 예에서, 처리 소자는 외부 호스트로부터 수신된 또는 메모 리 인스턴스로부터 가져온 MAC(multiply-accumulate) 명령을 실행하도록 구성된 MAC 회로이다. 명령을 실 행한 후, 프로세싱 그룹은 명령의 결과를 외부 호스트 또는 동일 하드웨어 칩의 다른 프로세싱 그룹 등으 로 출력할 수 있다. 도면에는 단일 명령과 단일 결과만을 도시하였지만, 복수의 명령이 수신, 검색, 및 실행될 수 있고, 복수의 결과가 출력 이전에 프로세싱 그룹 상에서 병합될 수 있다. 도 5에는 MAC 회로로 도시 되었지만, 프로세싱 그룹에는 추가적인 또는 대안적인 특수 회로가 포함될 수 있다. 예를 들어, MAX-읽기 명령(벡터의 최대값 출력), MAX0-읽기 명령(전체 벡터를 출력하지만 0으로 MAX 하는 정류 기(rectifier)로 불리는 기능) 등이 구현될 수 있다. 도 4의 일반적인 프로세싱 그룹과 도 5의 특수 프로세싱 그룹이 별도의 것으로 도시 되어 있지만, 이 들은 병합될 수 있다. 예를 들어, 일반적인 프로세서 서브유닛이 하나 이상의 특수 프로세서 서브유닛과 결합되 어 프로세서 서브유닛을 형성할 수 있다. 이에 따라, 일반적인 프로세서 서브유닛은 하나 이상의 특수 프로세서 서브유닛에 의해 실행 가능하지 않은 모든 명령에 대해 활용될 수 있다. 본 개시의 당업자라면, 신경망 구현과 기타 메모리 집약적 작업이 특수 논리 회로에 의해 처리될 수 있음을 이 해할 것이다. 예를 들어, 데이터베이스 쿼리, 패킷 검사, 스트링 비교, 및 기타 기능은 여기에 기재된 하드웨어 칩에 의해 실행되는 경우에 효율이 향상될 수 있다. 분산 처리에 대한 메모리 기반 아키텍처 본 개시에 따른 하드웨어 칩 상에서, 전용 버스는 칩 상의 프로세서 서브유닛 사이 및/또는 프로세서 서브유닛 과 그에 상응하는 전용 메모리 뱅크 사이에 데이터를 전송할 수 있다. 전용 버스를 사용하면 상충하는 요구가 불가능하거나 하드웨어가 아닌 소프트웨어를 사용하여 쉽게 회피될 수 있기 때문에 중재 비용을 줄일 수 있다. 도 6은 프로세싱 그룹을 개략적으로 도시한 것이다. 프로세싱 그룹은 하드웨어 칩, 하드웨어 칩 (300') 등과 같은 하드웨어 칩에서 사용하기 위한 것일 수 있다. 프로세서 서브유닛은 버스를 통해 메모리에 연결될 수 있다. 메모리는 프로세서 서브유닛에 의한 실행을 위한 데이터 및 코드를 저장하는 RAM 소자를 포함할 수 있다. 일부 실시예에서, 메모리는 N-웨이 메모리일 수 있다(여기서, N은 인터리브(interleaved) 메모리 내의 세그먼트의 수를 의미하는 1 이상의 수). 프로세서 서브유닛은 버스를 통해 프로세서 서브유닛 전용의 메모리에 결합되므로, N은 실행 성능의 손실 없이도 상대적으로 낮은 수로 유지될 수 있을 것이다. 이는, N이 작으면 실행 성능이 떨어지고 N이 높으면 면적과 파워 손실이 큰 기존의 멀티웨이 레지스터 파일 또는 캐시에 비한 향상을 의미한다. 프로세싱 그룹을 사용하는 시스템의 작업 및 어플리케이션 구현의 요구조건에 맞도록 작업에 연관된 데이 터의 사이즈 등에 따라 메모리의 사이즈, N-웨이의 N의 수, 및 버스의 폭이 조절될 수 있다. 메모리 소자는, 예를 들어, 휘발성 메모리(RAM, DRAM, SRAM, 상변화 RAM (phase-change RAM 또는 PRAM), 강자성 RAM(magnetoresistive RAM 또는 MRAM), 저항성 RAM(resistive RAM 또는 ReRAM) 등) 또는 비휘발성 메모리(플 래시메모리 또는 ROM)와 같은, 본 기술 분야에 알려진 하나 이상의 메모리 유형을 포함할 수 있다. 일부 실시예 에 따라, 메모리 소자의 일부분은 제1 메모리 유형을 포함하고, 다른 부분은 다른 메모리 유형을 포함할 수 있다. 예를 들어, 메모리 소자의 코드 영역은 ROM 소자를 포함하고, 메모리 소자의 데이터 영역은 DRAM 소자를 포함할 수 있다. 이러한 분할의 다른 예로서, 신경망의 무게는 플래시메모리에 저장하는 반면, 계 산을 위한 데이터는 DRAM에 저장할 수 있다. 프로세서 서브유닛은 프로세서를 포함할 수 있는 처리 소자를 포함한다. 프로세서는, 당업자라면 이"}
{"patent_id": "10-2022-7008116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "해하듯이, 파이프라인 되거나 되지 않을 수 있고, 본 기술분야에 알려진 모든 시중의 집적회로(예, ARM, ARC, RISC-V 등) 상에 구현된 맞춤형 RISC(Reduced Instruction Set Computing) 소자 또는 기타 처리 스키마일 수 있다. 처리 소자는 일부 실시예에서 ALU(Arithmetic Logic Unit) 또는 기타 컨트롤러를 포함하는 컨트롤러 를 포함할 수 있다. 일부 실시예에 따라, 수신 또는 저장된 코드를 실행하는 처리 소자는 일반적인 처리 소자를 포함할 수 있 으므로 매우 다양한 처리 연산의 수행이 유연하고 가능하다. 특정 연산의 수행 동안에 소비하는 전력을 비교할 때, 전용이 아닌 회로는 특정 연산 전용 회로보다 많은 전력을 소비한다. 따라서, 특정 복잡 산술 계산을 수행 할 경우, 처리 소자는 전용 하드웨어보다 많은 전력을 소비하고 효율이 떨어질 수 있다. 따라서, 일부 실 시예에 따라, 처리 소자의 컨트롤러는 특정 연산(예, 합산 또는 '이동' 연산)을 수행하도록 설계될 수 있 다. 일례에서, 특정 연산은 하나 이상의 가속기(accelerator, 650)에 의해 수행될 수 있다. 각 가속기는 특정 계산 (예, 곱셈, 부동 소수점 벡터 연산 등)의 수행의 전용으로 프로그램될 수 있다. 가속기를 사용함으로써, 프로세 서 서브유닛 당 계산 별로 소비하는 평균 전력이 감소될 수 있고, 향후 계산 처리량이 증가한다. 가속기는 시스템이 구현(예, 신경망의 실행, 데이터베이스 쿼리의 실행 등)하도록 설계된 어플리케이션에 따라 선택될 수 있다. 가속기는 처리 소자에 의해 설정될 수 있고, 전력 소비의 감소와 계산의 가속을 위해 처리 소 자와 협력하여 작동할 수 있다. 스마트 DMA(direct memory access) 주변기기와 같이, 가속기는 프로세싱 그룹의 메모리와 MUX/DEMUX/입력/출력 포트(예, MUX, DEMUX) 사이에 데이터를 전송하기 위해 추가적으로 또는 대안적으로 사용될 수 있다. 가속기는 다양한 기능을 수행하도록 구성될 수 있다. 예를 들어, 어떤 가속기는 신경망에서 자주 사용되는 16비트 부동 소수점 계산 또는 8비트 정수 계산을 수행하도록 구성될 수 있다. 가속기 기능의 다른 예는 신경망 의 학습 단계에서 자주 사용되는 32비트 부동 소수점 계산이다. 가속기 기능의 또 다른 예는 데이터베이스에서 사용되는 것과 같은 쿼리 처리이다. 일부 실시예에서, 가속기는 이러한 기능을 수행하기 위해 특화된 처리 소자를 포함할 수 있고/있거나 메모리 소자에 저장된 설정 데이터에 따라 설정되어 수정이 가능하도록 할 수 있다. 가속기는 메모리로의/로부터의 또는 기타 가속기 및/또는 입력/출력으로의/으로부터의 데이터의 설정 가능한 기재된 목록의 메모리 이동에서 타임 이동을 추가적으로 또는 대안적으로 구현할 수 있다. 이에 따라, 하기에 더 설명하는 바와 같이, 프로세싱 그룹을 사용하는 하드웨어 칩 내부의 모든 데이터 이동은 하드웨 어 동기화보다는 소프트웨어 동기화를 이용할 수 있다. 예를 들어, 한 프로세싱 그룹(예, 600)의 가속기는 10번 째 사이클마다 데이터를 입력에서 가속기로 전송한 후에 다음 사이클에서 데이터를 출력하여 프로세싱 그룹의 메모리로부터 다른 프로세싱 그룹으로 정보가 이동하게 할 수 있다. 도 6에 더 도시된 바와 같이, 일부 실시예에서, 프로세싱 그룹은 입력 포트에 연결된 적어도 하나의 입력 멀티플렉서(MUX)와 출력 포트에 연결된 적어도 하나의 출력 디멀티플렉서(DEMUX)를 더 포함할 수 있 다. 이러한 MUX/DEMUX는 처리 소자 및/도는 가속기 중의 하나로부터의 제어 신호(미도시)에 의해 제 어되고, 처리 소자에 의해 수행되는 현 지시 및/또는 가속기 중의 한 가속기에 의해 실행되는 연산에 따라 판단될 수 있다. 일부의 경우, 프로세싱 그룹은 (코드 메모리로부터의 미리 정해진 명령에 따라) 입 력 포트로부터 출력 포트로 데이터를 전송하도록 요구될 수 있다. 이에 따라, MUX/DEMUX의 각각이 처리 소자와 가속기에 연결될 뿐만 아니라, 입력 MUX의 하나 이상(예, MUX)이 하나 이상의 버스를 통해 출력 DEMUX(예, DEMUX)로 직접 연결될 수 있다. 도 6의 프로세싱 그룹은 배열되어 도 7a에 도시된 것 등과 같은 분산 프로세서를 형성할 수 있다. 프로세 싱 그룹은 기판에 배치되어 어레이를 형성할 수 있다. 일부 실시예에서, 기판은 실리콘과 같은 반도 체 기판을 포함할 수 있다. 추가적으로 또는 대안적으로, 기판은 연성회로기판과 같은 회로기판을 포함할 수 있다. 도 7a에 도시된 바와 같이, 기판은, 프로세싱 그룹과 같은, 그 위에 배치된 복수의 프로세싱 그룹을 포함할 수 있다. 이에 따라, 기판은 뱅크(720a, 720b, 720c, 720d, 720e, 720f, 720g, 720h)와 같은 복수 의 뱅크를 포함하는 메모리 어레이를 포함한다. 또한, 기판은 서브유닛(730a, 730b, 730c, 730d, 730e, 730f, 730g, 730h)과 같은 복수의 프로세서 서브유닛을 포함할 수 있는 프로세싱 어레이를 포함한다. 또한, 앞서 설명한 바와 같이, 각 프로세싱 그룹은 프로세서 서브유닛과 이 프로세서 서브유닛 전용의 하나 이 상의 상응하는 메모리 뱅크를 포함할 수 있다. 이에 따라, 도 7a에 도시된 바와 같이, 각 서브유닛은 상응하는 전용 메모리 뱅크와 연관된다. 예를 들어, 프로세서 서브유닛(730a)은 메모리 뱅크(720a)와 연관되고, 프로세서 서브유닛(730b)은 메모리 뱅크(720b)와 연관되고, 프로세서 서브유닛(730c)은 메모리 뱅크(720c)와 연관되고, 프로세서 서브유닛(730d)은 메모리 뱅크(720d)와 연관되고, 프로세서 서브유닛(730e)은 메모리 뱅크(720e)와 연 관되고, 프로세서 서브유닛(730f)은 메모리 뱅크(720f)와 연관되고, 프로세서 서브유닛(730g)은 메모리 뱅크 (720g)와 연관되고, 프로세서 서브유닛(730h)은 메모리 뱅크(720h)와 연관된다. 각 프로세서 서브유닛이 상응하는 전용 메모리 뱅크와 통신하도록 하기 위하여, 기판은 프로세서 서브유닛 중의 하나를 그에 상응하는 전용 메모리 뱅크로 연결하는 제1 복수의 버스를 포함할 수 있다. 이에 따라, 버스 (740a)는 프로세서 서브유닛(730a)을 메모리 뱅크(720a)로 연결하고, 버스(740b)는 프로세서 서브유닛(730b)을 메모리 뱅크(720b)로 연결하고, 버스(740c)는 프로세서 서브유닛(730c)을 메모리 뱅크(720c)로 연결하고, 버스 (740d)는 프로세서 서브유닛(730d)을 메모리 뱅크(720d)로 연결하고, 버스(740e)는 프로세서 서브유닛(730e)을 메모리 뱅크(720e)로 연결하고, 버스(740f)는 프로세서 서브유닛(730f)을 메모리 뱅크(720f)로 연결하고, 버스 (740g)는 프로세서 서브유닛(730g)을 메모리 뱅크(720g)로 연결하고, 버스(740h)는 프로세서 서브유닛(730h)을 메모리 뱅크(720h)로 연결한다. 또한, 각 프로세서 서브유닛이 다른 프로세서 서브유닛과 통신하도록 하기 위하 여, 기판은 프로세서 서브유닛 중의 하나를 프로세서 서브유닛 중의 다른 하나로 연결하는 제2 복수의 버 스를 포함할 수 있다. 도 7a의 예에서, 버스(750a)는 프로세서 서브유닛(730a)을 프로세서 서브유닛(750e)으로 연결하고, 버스(750b)는 프로세서 서브유닛(730a)을 프로세서 서브유닛(750b)으로 연결하고, 버스(750c)는 프로 세서 서브유닛(730b)을 프로세서 서브유닛(750f)으로 연결하고, 버스(750d)는 프로세서 서브유닛(730b)을 프로 세서 서브유닛(750c)으로 연결하고, 버스(750e)는 프로세서 서브유닛(730c)을 프로세서 서브유닛(750g)으로 연 결하고, 버스(750f)는 프로세서 서브유닛(730c)을 프로세서 서브유닛(750d)으로 연결하고, 버스(750g)는 프로세 서 서브유닛(730d)을 프로세서 서브유닛(750h)으로 연결하고, 버스(750h)는 프로세서 서브유닛(730h)을 프로세 서 서브유닛(750g)으로 연결하고, 버스(750i)는 프로세서 서브유닛(730g)을 프로세서 서브유닛(750g)으로 연결 하고, 버스(750j)는 프로세서 서브유닛(730f)을 프로세서 서브유닛(750e)으로 연결한다. 이에 따라, 도 7a에 도시된 예시적인 배치에서, 복수의 논리 프로세서 서브유닛은 적어도 하나의 행과 적어도 하나의 열로 배치된다. 제2 복수의 버스는 각 프로세서 서브유닛을 동일한 행의 적어도 하나의 인접 프로세서 서브유닛과 동일한 열의 적어도 하나의 인접 프로세서 서브유닛으로 연결한다. 도 7a는 '부분 타일 연결 (partial tile connection)'로 일컬을 수 있다. 도 7a에 도시된 배치는 수정되어 '완전 타일 연결(full tile connection)'을 형성할 수 있다. 완전 타일 연결은 대각선의 프로세서 서브유닛을 연결하는 추가적인 버스를 포함한다. 예를 들어, 제2 복수의 버스는 프로세서 서 브유닛(730a)과 프로세서 서브유닛(730f) 사이, 프로세서 서브유닛(730b)과 프로세서 서브유닛(730e) 사이, 프 로세서 서브유닛(730b)과 프로세서 서브유닛(730g) 사이, 프로세서 서브유닛(730c)과 프로세서 서브유닛(730f) 사이, 프로세서 서브유닛(730c)과 프로세서 서브유닛(730h) 사이, 및 프로세서 서브유닛(730d)과 프로세서 서브 유닛(730g) 사이에 추가적인 버스를 포함할 수 있다. 완전 타일 연결은, 근처의 프로세서 서브유닛에 저장된 데이터와 결과를 활용하는, 컨볼루션(convolution) 계산 에 이용될 수 있다. 예를 들어, 컨볼루션 이미지 처리 중에, 각 프로세서 서브유닛은 이미지 타일(예, 한 픽셀 또는 픽셀 그룹)을 수신할 수 있다. 컨볼루션 결과를 계산하기 위하여, 각 프로세서 서브유닛은 각각 상응하는 타일을 수신한 8개의 인접 프로세서 서브유닛으로부터 데이터를 확보할 수 있다. 부분 타일 연결에서는, 대각선으로 인접한 프로세서 서브유닛으로부터의 데이터는 해당 프로세서 서브유닛에 연결된 다른 인접 프로세서 서브 유닛을 통해 통과될 수 있다. 이에 따라, 칩 상의 분산 프로세서는 인공지능 가속기 프로세서일 수 있다. 컨볼루션 계산의 구체적인 예에서, N x M 이미지가 복수의 프로세서 서브유닛에 걸쳐 분할될 수 있다. 각 프로 세서 서브유닛은 상응하는 타일에 대해 A x B 필터로 컨볼루션을 수행할 수 있다. 타일 사이의 경계 상의 하나 이상의 픽셀에 대한 필터링을 수행하기 위하여, 각 프로세서 서브유닛은 동일한 경계 상의 픽셀을 포함하는 타 일을 가진 이웃 프로세서 서브유닛으로부터 데이터를 요구할 수 있다. 이에 따라, 각 프로세서 서브유닛에 대해 생성된 코드는 해당 서브유닛이 컨볼루션을 계산하고 인접 서브유닛으로부터 데이터가 필요할 때마다 제2 복수 의 버스 중의 하나로부터 당겨오도록 설정한다. 제2 복수의 버스로 데이터를 출력하기 위한 상응하는 명령이 해 당 서브유닛으로 제공되어 필요한 데이터 전송의 타이밍이 적절하도록 한다. 도 7a의 부분 타일 연결은 N-부분 타일 연결이 되도록 수정될 수 있다. 이러한 수정에서, 제2 복수의 버스는 각 프로세서 서브유닛을 도 7a의 버스가 지나가는 4방향(즉, 상, 하, 좌, 우 방향)의 해당 프로세서 서브유닛의 임 계 거리 이내(예, n 프로세서 서브유닛 이내)에 있는 프로세서 서브유닛으로 더 연결할 수 있다. 완전 타일 연 결에도 유사한 수정이 이루어져(즉, 결과적으로 N-완전 타일 연결이 되어) 제2 복수의 버스가 각 프로세서 서브 유닛을 도 7a의 버스가 지나가는 4방향과 대각선 2 방향의 해당 프로세서 서브유닛의 임계 거리 이내(예, n 프 로세서 서브유닛 이내)에 있는 프로세서 서브유닛으로 더 연결하도록 할 수 있다. 다른 배치도 가능하다. 예를 들어, 도 7b에 도시된 배치에서, 버스(750a)는 프로세서 서브유닛(730a)을 프로세 서 서브유닛(730d)으로 연결하고, 버스(750b)는 프로세서 서브유닛(730a)을 프로세서 서브유닛(730b)으로 연결 하고, 버스(750c)는 프로세서 서브유닛(730b)을 프로세서 서브유닛(730c)으로 연결하고, 버스(750d)는 프로세서 서브유닛(730c)을 프로세서 서브유닛(730d)으로 연결한다. 이에 따라, 도 7b에 도시된 예에서, 복수의 프로세서 서브유닛은 별 무늬로 배치된다. 제2 복수의 버스는 각 프로세서 서브유닛을 별 무늬 이내의 적어도 하나의 인 접 프로세서 서브유닛으로 연결한다. 추가적인 배치(미도시)도 가능하다. 예를 들면, 복수의 프로세서 서브유닛이 하나 이상의 선에 배치되도록(도 7a에 도시된 배치와 유사) 하는 이웃 연결 배치가 사용될 수 있다. 이웃 연결 배치에서, 제2 복수의 버스는 각 프로세서 서브유닛을 동일 선 상의 좌측에 있는 프로세서 서브유닛, 동일 선 상의 우측에 있는 프로세서 서브유 닛, 동일 선 상의 좌우측 모두에 있는 프로세서 서브유닛 등에 연결한다. 다른 예에서, N-선형 연결 배치가 사용될 수 있다. N-선형 연결 배치에서, 제2 복수의 버스는 각 프로세서 서브 유닛을 해당 프로세서 서브유닛의 임계 거리 이내(예, n 프로세서 서브유닛 이내)에 있는 프로세서 서브유닛에 연결한다. N-선형 연결 배치는 라인 어레이(상기 설명 참조), 장방형 어레이(도 7a에 도시), 타원형 어레이(도 7b에 도시), 또는 기타 기하 어레이와 함께 사용될 수 있다. 또 다른 예에서, N-로그 연결 배치가 사용될 수 있다. N-로그 연결 배치에서, 제2 복수의 버스는 각 프로세서 서브유닛을 해당 프로세서 서브유닛의 2의 거듭제곱 임계 거리 이내(예, 2n 프로세서 서브 유닛 이내)에 있는 프 로세서 서브유닛에 연결한다. N-로그 연결 배치는 라인 어레이(상기 설명 참조), 장방형 어레이(도 7a에 도시), 타원형 어레이(도 7b에 도시), 또는 기타 기하 어레이와 함께 사용될 수 있다. 상기에 설명한 연결 스키마의 어느 것이라도 서로 병합하여 동일 하드웨어 칩 상에서 사용될 수 있다. 예를 들 어, 완전 타일 연결이 한 영역에서 사용되고, 부분 타일 연결이 다른 영역에서 사용될 수 있다. 다른 예를 들면, N-선형 연결 배치가 한 영역에서 사용되고, N-완전 타일 연결이 다른 영역에서 사용될 수 있다. 메모리 칩의 프로세서 서브유닛 사이의 전용 버스에 대안적으로 또는 추가적으로, 하나 이상의 공유 버스를 사 용하여 분산 프로세서의 모든 프로세서 서브유닛(또는 모든 프로세서 서브유닛의 서브세트)을 서로 연결할 수 있다. 공유 버스 상의 충돌은 프로세서 서브유닛에 의해 실행되는 코드를 활용하여 공유 버스 상의 데이터 전송 타이밍을 조정함으로써 방지될 수 있으며, 이에 대하여는 하기에 설명한다. 공유 버스에 추가적으로 또는 대안 적으로, 설정형 버스(configurable bus)를 사용하여 프로세서 서브유닛을 동적으로 연결하여 서로 분리된 버스 로 연결되는 프로세서 서브유닛 그룹을 형성할 수 있다. 예를 들어, 설정형 버스는 프로세서 서브유닛에 의해 제어되어 데이터를 선택된 프로세서 서브유닛으로 전송할 수 있는 트랜지스터 또는 기타 메커니즘을 포함할 수 있다. 도 7a와 도 7b에서, 프로세싱 어레이의 복수의 프로세서 서브유닛은 메모리 어레이의 복수의 이산 메모리 뱅크 사이에 공간적으로 분포된다. 다른 대안적인 실시예(미도시)에서, 복수의 프로세서 서브유닛은 기판의 하나 이 상의 영역에서 클러스터링 될 수 있고, 복수의 메모리 뱅크는 기판의 하나 이상의 다른 영역에서 클러스터링 될수 있다. 일부 실시예에서, 공간적 분포와 클러스터링의 조합(미도시)이 사용될 수 있다. 예를 들어, 기판의 일 영역은 프로세서 서브유닛의 클러스터를 포함하고, 기판의 다른 영역은 메모리 뱅크의 클러스터를 포함하고, 기 판의 또 다른 영역은 메모리 뱅크 사이에 분포된 프로세싱 어레이를 포함할 수 있다. 본 개시의 당업자라면, 기판 상에 프로세싱 그룹의 어레이를 형성하는 것은 배타적인 실시예가 아님을 이 해할 것이다. 예를 들어, 각 프로세서 서브유닛은 적어도 두 개의 전용 메모리 뱅크와 연관될 수 있다. 이에 따 라, 도 3b의 프로세싱 그룹(310a, 310b, 310c, 310d)은 프로세싱 그룹을 대신하여 또는 프로세싱 그룹 과 함께 사용되어 프로세싱 어레이와 메모리 어레이를 형성할 수 있다. 셋, 넷, 또는 그 이상 등의 전용 메모리 뱅크(미도시)를 포함하는 다른 프로세싱 그룹도 사용될 수 있다. 복수의 프로세서 서브유닛의 각 프로세서 서브유닛은 특정 어플리케이션과 연관된 소프트웨어 코드를 복수의 프 로세서 서브유닛에 포함된 다른 프로세서 서브유닛에 대해 개별적으로 실행하도록 구성될 수 있다. 예를 들어, 하기에 설명하는 바와 같이, 복수의 서브시리즈(sub-series)의 명령이 머신 코드로 그룹으로 묶이고 각 프로세 서 서브유닛으로 제공되어 실행될 수 있다. 일부 실시예에서, 각 전용 메모리 뱅크는 적어도 하나의 DRAM을 포함한다. 대안적으로, 메모리 뱅크는 SRAM, DRAM, 플래시메모리 등과 같은 메모리 유형의 조합을 포함할 수 있다. 기존의 프로세서에서, 프로세서 서브유닛 사이의 데이터 공유는 일반적으로 공유 메모리로 수행된다. 공유 메모 리는 보통 넓은 부분의 칩 영역을 요구 및/또는 추가적인 하드웨어(예, 아비터(arbiter))에 의해 관리되는 버스 에 의해 수행된다. 버스는 앞서 설명한 바와 같이 병목 현상을 초래한다. 또한, 칩의 외부에 있을 수 있는 공유 메모리는 정확하고 업데이트 된 데이터를 프로세서 서브유닛에 제공하기 위해서 캐시 일관성 메커니즘과 더욱 복잡한 캐시(예, L1 캐시, L2 캐시, 공유 DRAM)를 포함하는 것이 보통이다. 하기에 더 설명하는 바와 같이, 도 7a와 도 7b에 도시된 전용 버스는 하드웨어 관리(예, 아비터)가 필요 없는 하드웨어 칩을 가능하게 한다. 또한, 도 7a와 도 7b에 도시된 것과 같은 전용 메모리를 사용하면 복잡한 캐싱 계층과 일관성 메커니즘이 없어도 된다. 대신에, 각 프로세서 서브유닛이 다른 프로세서 서브유닛에 의해 계산 및/또는 다른 프로세서 서브유닛의 전용 메모리 뱅크에 저장된 데이터에 접근하게 하기 위하여, 각 프로세서 서브유닛에 의해 개별적으로 실행되는 코드 를 활용하여 동적으로 타이밍이 수행되는 버스가 제공된다. 이로써, 기존에 사용되는 버스 관리 하드웨어 대부 분 또는 전부가 없어도 된다. 또한, 복잡한 캐싱 메커니즘을 이러한 버스를 통한 직접 전송으로 대체할 수 있으 므로, 그 결과, 메모리 읽기와 쓰기 동안에 대기 시간을 줄일 수 있다. 메모리 기반 프로세싱 어레이 도 7a와 도 7b에 도시된 바와 같이, 본 개시의 메모리 칩은 개별적으로 동작할 수 있다. 또는, 본 개시의 메모 리 칩은 메모리 장치(예, 하나 이상의 DRAM 뱅크), 시스템 온 칩, FPGA(field-programmable gate array), 또는 기타 프로세싱 및/또는 메모리 칩과 같은 하나 이상의 추가적인 집적회로에 작동적으로 연결될 수 있다. 이러한 실시예에서, 상기 아키텍처에 의해 실행되는 일련의 명령의 작업은 메모리 칩의 프로세서 서브유닛과 추가적인 집적회로의 프로세서 서브유닛 사이에 분할될 수(예, 하기에 설명하는 바와 같이, 컴파일러에 의해) 있다. 예를 들어, 추가적인 집적회로는 명령 및/또는 데이터를 메모리 칩에 입력하고 메모리 칩으로부터 출력을 수신하는 호스트(예, 도 3a의 호스트)를 포함할 수 있다. 본 개시의 메모리 칩과 하나 이상의 추가 집적회로를 서로 연결하기 위하여, 메모리 칩은 JEDEC(Joint Electron Device Engineering Council) 표준 또는 그 개정 표준을 준수하는 메모리 인터페이스와 같은 메모리 인터페이스 를 포함할 수 있다. 상기 하나 이상의 추가 집적회로는 이후 메모리 인터페이스로 연결될 수 있다. 이에 따라, 하나 이상의 추가 집적회로가 본 개시의 복수의 메모리 칩에 연결되는 경우, 데이터가 하나 이상의 추가 집적회 로를 통해 메모리 칩 사이에 공유될 수 있다. 추가적으로 또는 대안적으로, 하나 이상의 추가 집적회로는 본 개 시의 메모리 칩의 버스와 연결하기 위한 버스를 포함하여 상기 하나 이상의 추가 집적회로가 본 개시의 메모리 칩과 협력하여 코드를 실행하도록 할 수 있다. 이러한 실시예에서, 하나 이상의 추가 집적회로는 본 개시의 메 모리 칩과 다른 기판 상에 있더라도 분산 프로세싱을 추가적으로 지원할 수 있다. 또한, 본 개시의 메모리 칩은 분산 프로세서의 어레이를 형성하기 위하여 어레이로 배치될 수 있다. 예를 들어, 도 7c에 도시된 바와 같이, 하나 이상의 버스가 메모리 칩(770a)을 추가 메모리 칩(770b)으로 연결할 수 있다. 도 7c의 예에서, 메모리 칩(770a)은 하나 이상의 상응하는 메모리 뱅크가 각 프로세서 서브유닛의 전용인 프로 세서 서브유닛을 포함한다. 예를 들어, 프로세서 서브유닛(730a)은 메모리 뱅크(720a)와 연관되고, 프로세서 서브유닛(730b)은 메모리 뱅크(720b)와 연관되고, 프로세서 서브유닛(730e)은 메모리 뱅크(720c)와 연관되고, 프 로세서 서브유닛(730f)은 메모리 뱅크(720d)와 연관된다. 버스는 각 프로세서 서브유닛을 그에 상응하는 메모리 뱅크에 연결한다. 이에 따라, 버스(740a)는 프로세서 서브유닛(730a)을 메모리 뱅크(720a)에 연결하고, 버스 (740b)는 프로세서 서브유닛(730b)을 메모리 뱅크(720b)에 연결하고, 버스(740c)는 프로세서 서브유닛(730e)을 메모리 뱅크(720c)에 연결하고, 버스(740d)는 프로세서 서브유닛(730f)을 메모리 뱅크(720d)에 연결한다. 또한, 버스(750a)는 프로세서 서브유닛(730a)을 프로세서 서브유닛(750a)에 연결하고, 버스(750b)는 프로세서 서브유 닛(730a)을 프로세서 서브유닛(750b)에 연결하고, 버스(750c)는 프로세서 서브유닛(730b)을 프로세서 서브유닛 (750f)에 연결하고, 버스(750d)는 프로세서 서브유닛(730e)을 프로세서 서브유닛(750f)에 연결한다. 앞서 설명 한 바와 같이, 메모리 칩(770a)의 다른 배치도 활용될 수 있다. 마찬가지로, 메모리 칩(770b)은 하나 이상의 상응하는 메모리 뱅크가 각 프로세서 서브유닛의 전용인 프로세서 서브유닛을 포함한다. 예를 들어, 프로세서 서브유닛(730c)은 메모리 뱅크(720e)와 연관되고, 프로세서 서브유 닛(730d)은 메모리 뱅크(720f)와 연관되고, 프로세서 서브유닛(730g)은 메모리 뱅크(720g)와 연관되고, 프로세 서 서브유닛(730h)은 메모리 뱅크(720h)와 연관된다. 버스는 각 프로세서 서브유닛을 그에 상응하는 메모리 뱅 크에 연결한다. 이에 따라, 버스(740e)는 프로세서 서브유닛(730c)을 메모리 뱅크(720e)에 연결하고, 버스 (740f)는 프로세서 서브유닛(730d)을 메모리 뱅크(720f)에 연결하고, 버스(740g)는 프로세서 서브유닛(730g)을 메모리 뱅크(720g)에 연결하고, 버스(740h)는 프로세서 서브유닛(730h)을 메모리 뱅크(720h)에 연결한다. 또한, 버스(750g)는 프로세서 서브유닛(730c)을 프로세서 서브유닛(750g)에 연결하고, 버스(750h)는 프로세서 서브유 닛(730d)을 프로세서 서브유닛(750h)에 연결하고, 버스(750i)는 프로세서 서브유닛(730c)을 프로세서 서브유닛 (750d)에 연결하고, 버스(750j)는 프로세서 서브유닛(730g)을 프로세서 서브유닛(750h)에 연결한다. 앞서 설명 한 바와 같이, 메모리 칩(770b)의 다른 배치도 활용될 수 있다. 메모리 칩(770a, 770b)의 프로세서 서브유닛은 하나 이상의 버스를 사용하여 서로 연결될 수 있다. 이에 따라, 도 7c의 예에서, 버스(750e)는 메모리 칩(770a)의 프로세서 서브유닛(730b)과 메모리 칩(770b)의 프로세서 서브 유닛(730c)을 서로 연결할 수 있고, 버스(750f)는 메모리 칩(770a)의 프로세서 서브유닛(730f)과 메모리 칩 (770b)의 프로세서 서브유닛(730c)을 서로 연결할 수 있다. 예를 들어, 버스(750e)는 메모리 칩(770b)으로의 입 력 버스(따라서, 메모리 칩(770a)의 출력 버스) 역할을 할 수 있고, 버스(750f)는 메모리 칩(770a)으로의 입력 버스(따라서, 메모리 칩(770b)의 출력 버스) 역할을, 또는 그 반대의 역할을, 할 수 있다. 또는 버스(750e, 750f)는 모두 메모리 칩(770a, 770b) 사이의 양방향 버스 역할을 할 수 있다. 버스(750e, 750f)는 직접 회선을 포함하거나, 메모리 칩(770a)과 집적회로(770b) 사이의 인터칩 인터페이스 (inter-chip interface)에 사용되는 핀을 줄이기 위해 고속 연결 상에 인터리브 될 수 있다. 또한, 메모리 칩에 사용되는 앞서 설명한 모든 연결 구성이 사용되어 메모리 칩을 하나 이상의 추가 집적회로에 연결할 수 있다. 예를 들어, 메모리 칩(770a, 770b)은 도 7c에 도시된 것과 같은 2개의 버스만을 사용하기보다 완전 타일 연결이 나 부분 타일 연결을 사용하여 연결될 수 있다. 이에 따라, 버스(750e, 750f)를 사용하여 도시되었지만, 아키텍처는 더 적은 수의 버스나 더 많은 수의 버 스를 포함할 수 있다. 예를 들어, 프로세서 서브유닛(730a, 730b) 사이 또는 프로세서 서브유닛(730f, 730c) 사 이에 단일 버스가 사용될 수 있다. 또는, 추가적인 버스가 프로세서 서브유닛(730b, 730d) 사이 또는 프로세서 서브유닛(730f, 730d) 사이 등에 사용될 수 있다. 또한, 단일 메모리 칩과 추가 집적회로를 사용하는 것으로 도시되었지만, 복수의 메모리 칩이 앞서 설명한 바와 같이 연결될 수 있다. 예를 들어, 도 7c에 도시된 바와 같이, 메모리 칩(770a, 770b, 770c, 770d)이 어레이로 연결된다. 각 메모리 칩은 앞서 설명한 메모리 칩과 유사하게 프로세서 서브유닛과 전용 메모리 뱅크를 포함한 다. 이에 따라, 이러한 구성요소에 대한 설명은 여기서 반복하지 않는다. 도 7c의 예에서, 메모리 칩(770a, 770b, 770c, 770d)은 루프로 연결된다. 이에 따라, 버스(750a)는 메모리 칩 (770a, 770d)을 연결하고, 버스(750c)는 메모리 칩(770a, 770b)을 연결하고, 버스(750e)는 메모리 칩(770b, 770c)을 연결하고, 버스(750g)는 메모리 칩(770c, 770d)을 연결한다. 메모리 칩(770a, 770b, 770c, 770d)은 완 전 타일 연결, 부분 타일 연결 또는 기타 연결 구성으로 연결될 수 있지만, 도 7c의 예는 메모리 칩(770a, 770b, 770c, 770d) 사이에 적은 수의 핀 연결을 가능하게 한다. 상대적 대용량 메모리 본 개시의 실시예들은 기존 프로세서의 공유 메모리에 비하여 상대적으로 큰 사이즈의 전용 메모리를 사용할 수 있다. 공유 메모리가 아닌 전용 메모리를 사용하면 메모리 증가로 인한 효율 감소 없이 작업을 진행할 수 있다. 이로써, 공유 메모리의 증가에 따른 효율 향상이 폰노이만 병목현상(von Neumann bottleneck)으로 인해 줄어드 는 기존 프로세서에서 수행되는 것보다 신경망 처리와 데이터베이스 쿼리와 같은 메모리 집약적 작업이 더 효율 적으로 수행될 수 있다. 예를 들어, 본 개시의 분산 프로세서에서, 분산된 프로세서의 기판 상에 배치된 메모리 어레이는 복수의 이산 메모리 뱅크를 포함할 수 있다. 각각의 이산 메모리 뱅크는 1 메가바이트 이상의 용량 및 복수의 프로세서 서브 유닛을 포함하고 기판 상에 배치된 프로세싱 어레이를 포함할 수 있다. 앞서 설명한 바와 같이, 프로세서 서브 유닛의 각 프로세서 서브유닛은 복수의 이산 메모리 뱅크 중에서 상응하는 전용 이산 메모리 뱅크와 연관될 수 있다. 일부 실시예에서, 복수의 프로세서 서브유닛은 메모리 어레이 이내의 복수의 이산 메모리 뱅크 사이에서 공간적으로 분포될 수 있다. 대형 CPU 또는 GPU에 대해 몇 메가바이트의 공유 캐시를 사용하기보다 최소 1메카 바이트의 전용 메모리를 사용함으로써, 본 개시의 분산 프로세서는 CPU와 GPU의 폰노이만 병목현상으로 인해 기 존의 시스템에서 가능하지 않은 효율성을 얻게 된다. 서로 다른 메모리가 전용 메모리로 사용될 수도 있다. 예를 들어, 각 전용 메모리 뱅크는 적어도 하나의 DRAM 뱅크를 포함할 수 있다. 또는, 각 전용 메모리 뱅크는 적어도 하나의 SRAM 뱅크를 포함할 수 있다. 다른 실시예 에서, 서로 다른 유형의 메모리가 단일 하드웨어 칩 상에서 병합될 수 있다. 앞서 설명한 바와 같이, 각 전용 메모리는 최소 1메가바이트일 수 있다. 이에 따라, 각 전용 메모리 뱅크는 동 일 사이즈이거나, 복수의 메모리 뱅크의 적어도 두 메모리 뱅크는 서로 다른 사이즈일 수 있다. 또한, 앞서 설명한 바와 같이, 분산 프로세서는 각각 복수의 프로세서 서브유닛의 한 프로세서 서브유닛을 그에 상응하는 전용 메모리 뱅크에 연결하는 제1 복수의 버스 및 각각 복수의 프로세서 서브유닛의 한 프로세서 서브 유닛을 복수의 프로세서 서브유닛의 다른 프로세서 서브유닛에 연결하는 제2 복수의 버스를 포함할 수 있다. 소프트웨어를 활용한 동기화 앞서 설명한 바와 같이, 본 개시의 하드웨어 칩은 하드웨어가 아닌 소프트웨어를 활용하여 데이터 전송을 관리 할 수 있다. 특히, 버스 상의 전송, 메모리의 읽기와 쓰기, 및 프로세서 서브유닛의 계산의 타이밍이 프로세서 서브유닛에 의해 실행되는 명령의 서브시리즈에 의해 설정되기 때문에, 본 개시의 하드웨어 칩은 코드를 실행하 여 버스 상의 충돌을 방지할 수 있다. 이에 따라, 본 개시의 하드웨어 칩은 종래에 데이터 전송의 관리에 사용 되는 하드웨어 메커니즘(예, 칩 내의 네트워크 컨트롤러, 프로세서 서브유닛 간의 패킷 파서(packet parser) 및 패킷 전송기(packet transferor), 버스 아비터, 중재를 피하기 위한 복수의 버스 등)을 회피할 수 있다. 본 개시의 하드웨어 칩이 종래의 방식으로 데이터를 전송한다면, N 프로세서 서브유닛을 버스에 연결하려면 아 비터에 의해 제어되는 광범위한 MUX 또는 버스 중재가 필요할 것이다. 반면, 앞서 설명한 바와 같이, 본 개시의 실시예는 프로세서 서브유닛 사이에 오직 회선, 광케이블 등인 버스를 사용할 수 있고, 프로세서 서브유닛은 개 별적으로 코드를 실행하여 버스 상의 충돌을 방지할 수 있다. 이에 따라, 본 개시의 실시예는 기판 상의 공간을 보존할 수 있을 뿐만 아니라 (중재에 의한 전력 및 시간 소비로 인한) 재료 비용과 효율 저하를 줄일 수 있다. FIFO(first-in-first-out) 컨트롤로 및/또는 메일박스를 사용하는 다른 아키텍처와 비교하면 효율성과 공간의 이점이 더욱 크다. 또한, 앞서 설명한 바와 같이, 각 프로세서 서브유닛은 하나 이상의 처리 소자 외에도 하나 이상의 가속기를 포 함할 수 있다. 일부 실시예에서, 처리 소자가 아니라 가속기가 버스의 읽기와 쓰기를 할 수 있다. 이러한 실시 예에서, 처리 소자가 하나 이상의 계산을 수행하는 사이클과 동일한 사이클 동안에 가속기가 데이터를 전송하게 함으로써 효율성이 추가적으로 확보될 수 있다. 그러나 이러한 실시예는 가속기에 대한 추가적인 재료를 필요로 한다. 예를 들어, 가속기의 제조를 위해 트랜지스터가 추가적으로 필요할 수 있다. 코드는 또한 프로세서 서브유닛(예, 처리 소자 및/또는 프로세서 서브유닛의 일부를 형성하는 가속기)의 타이밍 과 지연을 포함하는 내부 동작에 대처할 수 있다. 예를 들면, 컴파일러(하기에 설명)는 데이터 전송을 제어하는 명령의 서브시리즈를 생성하는 경우의 타이밍과 지연에 대처하는 프리프로세싱(pre-processing)을 수행할 수 있 다. 일례에서, 복수의 프로세서 서브유닛은 이전 계층의 더 많은 복수의 뉴런에 완전히 연결된 복수의 뉴런을 포함 하는 신경망 계층을 계산하는 작업이 배정될 수 있다. 복수의 프로세서 서브유닛 사이에 이전 계층의 데이터가 균일하게 퍼져있다고 가정할 때, 상기 계산을 수행하는 한가지 방법은 각 프로세서 서브유닛이 이전 계층의 데 이터를 메인 버스로 차례로 전송하도록 설정하는 것일 수 있고, 그러면 각 프로세서 서브유닛은 프로세서 서브유닛이 구현하는 해당 뉴런의 가중치로 이 데이터를 곱할 것이다. 각 프로세서 서브유닛은 하나 이상의 뉴런을 계산하므로, 각 프로세서 서브유닛은 이전 계층의 데이터를 뉴런의 수만큼 전송할 것이다. 따라서, 프로세서 서 브유닛은 서로 다른 시간에 전송하게 될 것이므로, 각 프로세서 서브유닛의 코드는 다른 프로세서 서브유닛의 코드와 동일하지 않다. 일부 실시예에서, 분산 프로세서는 복수의 이산 메모리 뱅크를 포함하는 메모리 어레이가 배치된 기판(예, 실리 콘과 같은 반도체 기판 및/또는 연성회로기판과 같은 회로 기판) 및 상기 기판에 배치되고 도 7a와 도 7b 등에 도시된 것과 같은 복수의 프로세서 서브유닛을 포함하는 프로세싱 어레이를 포함할 수 있다. 앞서 설명한 바와 같이, 각각의 프로세서 서브유닛은 복수의 이산 메모리 뱅크 중에서 상응하는 전용 이산 메모리 뱅크와 연관될 수 있다. 또한, 도 7a와 도 7b 등에 도시된 것과 같이, 분산 프로세서는 각각 복수의 프로세서 서브유닛의 하나 를 복수의 프로세서 서브유닛의 적어도 다른 하나에 연결하는 복수의 버스를 더 포함할 수 있다. 앞서 설명한 바와 같이, 복수의 버스는 소프트웨어로 제어될 수 있다. 이에 따라, 복수의 버스는 타이밍 하드웨 어 로직 요소가 없어서 프로세서 서브유닛 사이의 데이터 전송과 복수의 버스의 상응하는 버스를 통한 데이터 전송은 타이밍 하드웨어 로직 요소에 의해 제어되지 않을 수 있다. 일례에서, 복수의 버스는 버스 아비터가 없 어서 프로세서 서브유닛 사이의 데이터 전송과 복수의 버스의 상응하는 버스를 통한 데이터 전송은 버스 아비터 에 의해 제어되지 않을 수 있다. 일부 실시예에서, 도 7a와 도 7b 등에 도시된 것과 같이, 분산 프로세서는 복수의 프로세서 서브유닛을 상응하 는 전용 메모리 뱅크에 연결하는 제2 복수의 버스를 더 포함할 수 있다. 앞서 설명한 복수의 버스와 유사하게, 제2 복수의 버스는 타이밍 하드웨어 로직 요소가 없어서 프로세서 서브유닛과 상응하는 전용 메모리 뱅크 사이 의 데이터 전송은 타이밍 하드웨어 로직 요소에 의해 제어되지 않을 수 있다. 일례에서, 제2 복수의 버스는 버 스 아비터가 없어서 프로세서 서브유닛과 상응하는 전용 메모리 뱅크 사이의 데이터 전송은 버스 아비터에 의해 제어되지 않을 수 있다. 본 개시에서, '없다.'라는 표현은 타이밍 하드웨어 로직 요소(예, 버스 아비터, 중재 구조, FIFO 컨트롤러, 메 일박스 등)가 절대적으로 없음을 반드시 의미하는 것이 아니다. 이러한 요소는 이러한 요소가 '없다.'라고 설명 된 하드웨어 칩에 여전히 포함되어 있을 수 있다. 오히려, '없다.'라는 표현은 하드웨어 칩의 기능을 말하는 것 이다. 즉, 타이밍 하드웨어 로직 요소가 '없는' 하드웨어 칩은 타이밍 하드웨어 로직 요소를 사용하지 않고 하 드웨어 칩의 데이터 전송의 타이밍을 제어한다. 예를 들어, 하드웨어 칩이 실행 코드의 오류로 인한 충돌로부터 의 보호를 위한 2차 예방책으로 타이밍 하드웨어 로직 요소를 포함하더라도, 하드웨어 칩은 하드웨어 칩의 프로 세서 서브유닛 사이의 데이터 전송을 제어하는 명령의 서브시리즈를 포함하는 코드를 실행한다. 앞서 설명한 바와 같이, 복수의 버스는 복수의 프로세서 서브유닛의 상응하는 프로세서 서브유닛 사이에 회선 및 광섬유의 적어도 하나를 포함할 수 있다. 이에 따라, 일례에서, 타이밍 하드웨어 로직 요소가 없는 분산 프 로세서는 버스 아비터, 중재 구조, FIFO 컨트롤러, 메일박스 등이 없이 회선 또는 광섬유만을 포함할 수 있다. 일부 실시예에서, 복수의 프로세서 서브유닛은 복수의 프로세서 서브유닛에 의해 실행되는 코드에 따라 복수의 버스의 적어도 하나를 통해 데이터를 전송하도록 구성된다. 이에 따라, 앞서 설명한 바와 같이, 컴파일러는 각 각 단일 프로세서 서브유닛에 의해 실행되는 코드를 포함하는 명령의 서브시리즈를 정리할 수 있다. 명령의 서 브시리즈는 프로세서 서브유닛에게 언제 버스 중의 하나로 데이터를 전송할지와 언제 버스로부터 데이터를 가져 올지를 지시할 수 있다. 서브시리즈가 분산 프로세서에 걸쳐 협력하여 실행되는 경우, 프로세서 서브유닛 사이 의 전송의 타이밍은 서브시리즈에 포함된 전송과 회수 명령에 의해 통제될 수 있다. 따라서, 코드는 복수의 버 스의 적어도 하나를 통한 데이터 전송의 타이밍을 통제한다. 컴파일러는 단일 프로세서 서브유닛에 의해 실행될 코드를 생성할 수 있다. 또한, 컴파일러는 프로세서 서브유닛의 그룹에 의해 실행될 코드를 생성할 수 있다. 일 부의 경우, 컴파일러는 모든 프로세서 서브유닛을 마치 하나의 슈퍼프로세서(예, 분산 프로세서)인 것처럼 취급 할 수 있고, 컴파일러는 이렇게 정의된 슈퍼프로세서/분산 프로세서에 의해 실행될 코드를 생성할 수 있다. 앞서 설명하고 도 7a와 도 7b에 도시된 바와 같이, 복수의 프로세서 서브유닛은 메모리 어레이 내의 복수의 이 산 메모리 뱅크 사이에 공간적으로 분포될 수 있다. 또는, 복수의 프로세서 서브유닛은 기판의 하나 이상의 영 역에서 클러스터링 될 수 있고, 복수의 메모리 뱅크는 기판의 하나 이상의 다른 영역에서 클러스터링 될 수 있 다. 일부 실시예에서, 앞서 설명한 바와 같이, 공간적 분포와 클러스터링의 조합이 사용될 수 있다. 일부 실시예에서, 분산 프로세서는 복수의 이산 메모리 뱅크를 포함하는 메모리 어레이가 배치된 기판(예, 실리 콘과 같은 반도체 기판 및/또는 연성회로기판과 같은 회로 기판)을 포함할 수 있다. 프로세싱 어레이는 또한 상기 기판에 배치되고 도 7a와 도 7b 등에 도시된 것과 같은 복수의 프로세서 서브유닛을 포함할 수 있다. 앞서 설명한 바와 같이, 각각의 프로세서 서브유닛은 복수의 이산 메모리 뱅크 중에서 상응하는 전용 이산 메모리 뱅 크와 연관될 수 있다. 또한, 도 7a와 도 7b 등에 도시된 것과 같이, 분산 프로세서는 각각 복수의 프로세서 서 브유닛의 하나를 복수의 이산 메모리 뱅크의 상응하는 전용 이산 메모리 뱅크에 연결하는 복수의 버스를 더 포 함할 수 있다. 앞서 설명한 바와 같이, 복수의 버스는 소프트웨어로 제어될 수 있다. 이에 따라, 복수의 버스는 타이밍 하드웨 어 로직 요소가 없어서 프로세서 서브유닛과 복수의 이산 메모리 뱅크의 상응하는 전용 이산 메모리 뱅크 사이 의 데이터 전송과 복수의 버스의 상응하는 버스를 통한 데이터 전송은 타이밍 하드웨어 로직 요소에 의해 제어 되지 않을 수 있다. 일례에서, 복수의 버스는 버스 아비터가 없어서 프로세서 서브유닛 사이의 데이터 전송과 복수의 버스의 상응하는 버스를 통한 데이터 전송은 버스 아비터에 의해 제어되지 않을 수 있다. 일부 실시예에서, 도 7a와 도 7b 등에 도시된 바와 같이, 분산 프로세서는 복수의 프로세서 서브유닛의 하나를 복수의 프로세서 서브유닛의 적어도 다른 하나에 연결하는 제2 복수의 버스를 더 포함할 수 있다. 앞서 설명한 복수의 버스와 유사하게, 제2 복수의 버스는 타이밍 하드웨어 로직 요소가 없어서 프로세서 서브유닛과 상응하 는 전용 메모리 뱅크 사이의 데이터 전송은 타이밍 하드웨어 로직 요소에 의해 제어되지 않을 수 있다. 일례에 서, 제2 복수의 버스는 버스 아비터가 없어서 프로세서 서브유닛과 상응하는 전용 메모리 뱅크 사이의 데이터 전송은 버스 아비터에 의해 제어되지 않을 수 있다. 일부 실시예에서, 분산 프로세서는 소프트웨어 타이밍 요소와 하드웨어 타이밍 요소의 조합을 사용할 수 있다. 예를 들어, 분산 프로세서는 복수의 이산 메모리 뱅크를 포함하는 메모리 어레이가 배치된 기판(예, 실리콘과 같은 반도체 기판 및/또는 연성회로기판과 같은 회로 기판)을 포함할 수 있다. 프로세싱 어레이는 또한 상기 기 판에 배치되고 도 7a와 도 7b 등에 도시된 것과 같은 복수의 프로세서 서브유닛을 포함할 수 있다. 앞서 설명한 바와 같이, 각각의 프로세서 서브유닛은 복수의 이산 메모리 뱅크 중에서 상응하는 전용 이산 메모리 뱅크와 연 관될 수 있다. 또한, 도 7a와 도 7b 등에 도시된 것과 같이, 분산 프로세서는 각각 복수의 프로세서 서브유닛의 하나를 복수의 프로세서 서브유닛의 적어도 다른 하나에 연결하는 복수의 버스를 더 포함할 수 있다. 또한, 앞 서 설명한 바와 같이, 복수의 프로세서 서브유닛은 복수의 버스를 통한 데이터 전송의 타이밍을 제어하여 복수 의 버스의 적어도 하나 상에서의 데이터 전송의 충돌을 방지하는 소프트웨어를 실행하도록 구성될 수 있다. 이 러한 예에서, 소프트웨어는 데이터 전송의 타이밍을 제어할 수 있지만, 전송 자체는 적어도 부분적으로는 하나 이상의 하드웨어 요소에 의해 제어될 수 있다. 이러한 실시예에서, 분산 프로세서는 복수의 프로세서 서브유닛의 하나를 상응하는 전용 메모리 뱅크에 연결하 는 제2 복수의 버스를 더 포함할 수 있다. 앞서 설명한 복수의 버스와 유사하게, 복수의 프로세서 서브유닛은 제2 복수의 버스를 통한 데이터 전송의 타이밍을 제어하여 제2 복수의 버스의 적어도 하나 상에서의 데이터 전 송의 충돌을 방지하는 소프트웨어를 실행하도록 구성될 수 있다. 이러한 예에서, 앞서 설명한 바와 같이, 소프 트웨어는 데이터 전송의 타이밍을 제어할 수 있지만, 전송 자체는 적어도 부분적으로는 하나 이상의 하드웨어 요소에 의해 제어될 수 있다. 코드의 분할 앞서 설명한 바와 같이, 본 개시의 하드웨어 칩은 하드웨어 칩을 형성하는 기판 상에 포함된 프로세서 서브유닛 전체에서 병렬로 코드를 실행할 수 있다. 또한, 본 개시의 하드웨어 칩은 멀티태스킹을 수행할 수 있다. 예를 들면, 본 개시의 하드웨어 칩은 영역 멀티태스킹을 수행할 수 있다. 즉, 하드웨어 칩의 프로세서 서브유닛의 한 그룹은 한 작업(예, 오디오 프로세싱)을 실행하고, 하드웨어 칩의 프로세서 서브유닛의 다른 그룹은 다른 작업 (예, 이미지 프로세싱)을 실행할 수 있다. 다른 예에서, 본 개시의 하드웨어 칩은 타이밍 멀티태스킹을 수행할 수 있다. 즉, 하드웨어 칩의 하나 이상의 프로세서 서브유닛은 제1 시간 주기 동안에 한 작업을 실행하고 제2 시간 주기 동안에는 다른 작업을 실행할 수 있다. 영역 멀티태스킹과 타이밍 멀티태스킹의 조합도 사용되어 제1 시간 주기 동안에 한 작업이 제1 그룹의 프로세서 서브유닛에 배정되고 제1 시간 주기 동안에 다른 작업이 제2 그룹의 프로세서 서브유닛에 배정된 후에 제2 시간 주기 동안에 제3 작업이 제1 그룹과 제2 그룹에 포함된 프로 세서 서브유닛에 배정될 수 있다. 본 개시의 메모리 칩 상의 실행을 위한 머신 코드를 정리하기 위하여, 머신 코드는 메모리 칩의 프로세서 서브 유닛 사이에서 분할될 수 있다. 예를 들어, 메모리 칩 상의 프로세서는 기판 및 기판 상에 배치된 복수의 프로 세서 서브유닛을 포함할 수 있다. 메모리 칩은 기판 상에 배치된 상응하는 복수의 메모리 뱅크를 더 포함할 수 있고, 여기서, 복수의 프로세서 서브유닛의 각각은 복수의 프로세서 서브유닛의 어느 프로세서 서브유닛에도 공유되지 않는 적어도 하나의 전용 메모리 뱅크에 연결될 수 있다. 메모리 칩 상의 각 프로세서 서브유닛은 다른 프로세서 서브유닛과 별개로 일련의 명령을 실행하도록 구성될 수 있다. 각 일련의 명령은 일련의 명령을 정의 하는 코드에 따라 프로세서 서브유닛의 하나 이상의 일반 처리 소자를 설정 및/또는 일련을 명령을 정의하는 코 드 내에 제공된 시퀀스에 따라 프로세서 서브유닛의 하나 이상의 특별 처리 소자(예, 하나 이상의 가속기)를 활 성화하여 실행될 수 있다. 이에 따라, 각 일련의 명령은 단일 프로세서 서브유닛에 의해 수행될 일련의 작업을 정의할 수 있다. 단일 작업 은 프로세서 서브유닛 내의 하나 이상의 처리 소자의 아키텍처에 의해 정의된 명령 세트 이내의 명령을 포함할 수 있다. 예를 들어, 프로세서 서브유닛은 특정 레지스터(register)를 포함할 수 있고, 단일 작업은 레지스터로 데이터 푸쉬(push), 레지스터로부터 데이터 풀(pull), 레지스터 이내의 데이터에 대한 산술 연산의 수행, 레지 스터 이내의 데이터에 대한 논리 연산의 수행 등을 할 수 있다. 또한, 프로세서 서브유닛은 0-피연산자 (operand) 프로세서 서브유닛('스택 머신(stack machine)'으로도 지칭), 1-피연산자 프로세서 서브유닛(어큐뮬 레이터 머신(accumulator machine)으로도 지칭), 2-연산자 프로세서 서브유닛(RISC 등), 3-연산자 프로세서 서 브유닛(CISC(complex instruction set computer)) 등과 같이 여러 수의 피연산자에 대해 구성될 수 있다. 다른 예에서, 프로세서 서브유닛은 하나 이상의 가속기를 포함할 수 있고, 단일 작업은 가속기를 활성화하여 MAC 함 수, MAX 함수, MAX-0 함수 등과 같은 특정 함수를 수행할 수 있다. 일련의 명령은 메모리 칩의 전용 메모리 뱅크로부터 읽기와 쓰기를 하기 위한 작업을 더 포함할 수 있다. 예를 들어, 작업은 이 작업을 실행하는 프로세서 서브유닛 전용의 메모리 뱅크에 데이터 하나를 쓰는 작업, 이 작업 을 실행하는 프로세서 서브유닛 전용의 메모리 뱅크에서 데이터 하나를 읽는 작업 등을 포함할 수 있다. 일부 실시예에서, 읽기와 쓰기는 메모리 뱅크의 컨트롤러와 협력하여 프로세서 서브유닛에 의해 수행될 수 있다. 예 를 들어, 프로세서 서브유닛은 읽기 또는 쓰기를 수행하라는 제어 신호를 컨트롤러에 전송하여 읽기 또는 쓰기 작업을 실행할 수 있다. 일부 실시예에서, 제어 신호는 읽기와 쓰기에 사용할 특정 어드레스를 포함할 수 있다. 또는 프로세서 서브유닛은 읽기와 쓰기를 위해 사용할 수 있는 어드레스의 선택을 메모리 컨트롤러에 맡길 수 있다. 추가적으로 또는 대안적으로, 읽기와 쓰기는 하나 이상의 가속기가 메모리 뱅크의 컨트롤러와 협력하여 수행될 수 있다. 예를 들어, 가속기는 앞서 설명한 프로세서 서브유닛이 제어 신호를 생성하는 것과 유사하게 메모리 컨트롤러에 대한 제어 신호를 생성할 수 있다. 상기에 설명한 실시예에서, 어드레스 생성기를 사용하여 메모리 뱅크의 특정 어드레스로 읽기와 쓰기를 지시할 수도 있다. 예를 들어, 어드레스 생성기는 읽기와 쓰기를 위한 메모리 어드레스를 생성하도록 구성된 처리 소자 를 포함할 수 있다. 어드레스 생성기는 추후 계산의 결과를 더 이상 필요가 없는 이전 계산의 결과의 어드레스 와 같은 어드레스로 쓰는 등을 통하여 효율성을 향상하기 위하여 어드레스를 생성하도록 구성될 수 있다. 이에 따라, 어드레스 생성기는 프로세서 서브유닛으로부터의(예, 프로세서 서브유닛에 포함된 처리 소자 또는 하나 이상의 가속기로부터의) 명령에 대응하여 또는 프로세서 서브유닛과 협력하여 메모리 컨트롤러에 대한 제어 신 호를 생성할 수 있다. 추가적으로 또는 대안적으로, 어드레스 생성기는, 예를 들어, 특정 패턴에서 메모리 내의 특정 어드레스에 대해 반복하는 중첩 루프(nested loop) 구조를 생성하는 일부 설정 또는 레지스터에 의거하여 어드레스를 생성할 수 있다. 일부 실시예에서, 각 일련의 명령은 상응하는 일련의 작업을 정의하는 머신 코드 세트를 포함할 수 있다. 이에 따라, 상기 일련의 작업은 일련의 명령을 포함하는 머신 코드 내에 압축될 수 있다. 일부 실시예에서, 하기에 도 8을 참조하여 설명하는 바와 같이, 일련의 작업은 복수의 논리 회로 중의 고수준(higher-level)의 일련의 작 업을 복수의 일련의 작업으로 분포하도록 구성된 컴파일러에 의해 정의될 수 있다. 예를 들어, 컴파일러는 고수 준의 일련의 작업에 의거하여 복수의 일련의 작업을 생성하여 각각 상응하는 일련의 작업을 함께 실행하는 프로 세서 서브유닛이 고수준의 일련의 작업이 서술한 것과 같은 함수를 수행할 수 있다. 하기에 설명하는 바와 같이, 고수준의 일련의 작업은 인간-판독 가능 프로그래밍 언어로 된 명령 세트를 포함할 수 있다. 이에 상응하여, 각 프로세서 서브유닛에 대한 일련의 작업은 머신 코드로 된 명령 세트를 각각 포함하 는 저수준(lower-level)의 일련의 작업을 포함할 수 있다. 앞서 도 7a와 도 7b를 참조하여 설명한 바와 같이, 메모리 칩은 복수의 프로세서 서브유닛의 하나를 복수의 프 로세서 서브유닛의 적어도 다른 하나에 각각 연결하는 복수의 버스를 더 포함할 수 있다. 또한, 앞서 설명한 바 와 같이, 복수의 버스 상의 데이터 전송은 소프트웨어를 사용하여 제어될 수 있다. 이에 따라, 복수의 버스의 적어도 하나를 통한 데이터 전송은 복수의 버스의 적어도 하나에 연결된 프로세서 서브유닛에 포함된 일련의 명령에 의해 미리 정해질 수 있다. 따라서, 일련의 명령에 포함된 작업 중의 하나는 버스 중의 하나로 데이터를 출력하는 작업 또는 버스 중의 하나로부터 데이터를 가져오는 작업을 포함할 수 있다. 이러한 작업은 프로세서 서브유닛의 처리 소자 또는 프로세서 서브유닛에 포함된 하나 이상의 가속기에 의해 실행될 수 있다. 후자의 실 시예에서, 프로세서 서브유닛은 가속기가 버스 중의 하나로부터 데이터를 가져오거나 버스 중의 하나로 데이터 를 배치하는 사이클과 같은 사이클에서 계산을 수행하거나 상응하는 메모리 뱅크로 제어 신호를 전송할 수 있다. 일례에서, 복수의 버스의 적어도 하나에 연결된 프로세서 서브유닛에 포함된 일련의 명령은 복수의 버스의 적어 도 하나에 연결된 프로세서 서브유닛이 복수의 버스의 적어도 하나로 데이터를 쓰게 하는 명령을 포함하는 전송 작업을 포함할 수 있다. 추가적으로 또는 대안적으로, 복수의 버스의 적어도 하나에 연결된 프로세서 서브유닛 에 포함된 일련의 명령은 복수의 버스의 적어도 하나에 연결된 프로세서 서브유닛이 복수의 버스의 적어도 하나 로부터 데이터를 읽게 하는 명령을 포함하는 수신 작업을 포함할 수 있다. 프로세서 서브유닛 사이의 코드 분산에 추가적으로 또는 대안적으로, 데이터는 메모리 칩의 메모리 뱅크 사이에 분할될 수 있다. 예를 들어, 앞서 설명한 바와 같이, 메모리 칩 상의 분산 프로세서는 메모리 칩 상에 배치된 복수의 프로세서 서브유닛과 메모리 칩 상에 배치된 복수의 메모리 뱅크를 포함할 수 있다. 복수의 메모리 뱅크 의 각 메모리 뱅크는 복수의 메모리 뱅크의 다른 메모리 뱅크에 저장된 데이터와 별개인 데이터를 저장하도록 구성될 수 있고, 복수의 프로세서 서브유닛의 각 프로세서 서브유닛은 복수의 메모리 뱅크 중에서 적어도 하나 의 전용 메모리 뱅크에 연결될 수 있다. 예를 들어, 각 프로세서 서브유닛은 그 프로세서 서브유닛 전용의 하나 이상의 상응하는 메모리 뱅크의 하나 이상의 메모리 컨트롤러에 접근할 수 있고, 다른 어떤 프로세서 서브유닛 도 이러한 상응하는 하나 이상의 메모리 컨트롤러에 접근할 수 없을 수 있다. 이에 따라, 메모리 뱅크 사이에 공유될 수 있는 메모리 컨트롤러가 없기 때문에 각 메모리 뱅크에 저장된 데이터는 다른 메모리 뱅크에 저장된 메모리와 별개일 수 있다. 일부 실시예에서, 하기에 도 8을 참조하여 설명하는 바와 같이, 복수의 메모리 뱅크 각각에 저장된 데이터는 복 수의 메모리 뱅크 사이에 데이터를 분산하도록 구성된 컴파일러에 의해 정의될 수 있다. 또한, 컴파일러는 상응 하는 프로세서 서브유닛에 분산된 복수의 저수준 작업을 이용하여 고수준의 일련의 작업에서 정의된 데이터를 복수의 메모리 뱅크에 분산하도록 구성될 수 있다. 하기에 더 설명하는 바와 같이, 고수준의 일련의 작업은 인간-판독 가능 프로그래밍 언어로 된 명령 세트를 포 함할 수 있다. 이에 상응하여, 각 프로세서 서브유닛에 대한 일련의 작업은 머신 코드로 된 명령 세트를 각각 포함하는 저수준의 일련의 작업을 포함할 수 있다. 앞서 도 7a와 도 7b를 참조하여 설명한 바와 같이, 메모리 칩은 복수의 프로세서 서브유닛의 하나를 복수의 메 모리 뱅크 중의 하나 이상의 상응하는 전용 메모리 뱅크에 각각 연결하는 복수의 버스를 더 포함할 수 있다. 또 한, 앞서 설명한 바와 같이, 복수의 버스 상의 데이터 전송은 소프트웨어를 활용하여 제어될 수 있다. 이에 따 라, 복수의 버스 중 특정 버스를 통한 데이터 전송은 복수의 버스 중 특정 버스에 연결된 상응하는 프로세서 서 브유닛에 의해 제어될 수 있다. 따라서, 일련의 명령에 포함된 작업의 하나는 버스 중의 하나로 데이터를 출력 하는 작업 또는 버스 중의 하나로부터 데이터를 가져오는 작업을 포함할 수 있다. 앞서 설명한 바와 같이, 이러 한 작업은 (i) 프로세서 서브유닛의 처리 소자 또는 (ii) 프로세서 서브유닛에 포함된 하나 이상의 가속기에 의 해 실행될 수 있다. 후자의 실시예에서, 프로세서 서브유닛은 가속기가 하나 이상의 상응하는 전용 메모리 뱅크 에 연결된 버스 중의 하나로부터 데이터를 가져오거나 하나 이상의 상응하는 전용 메모리 뱅크에 연결된 버스 중의 하나로 데이터를 배치하는 사이클과 같은 사이클에서 계산을 수행하거나 프로세서 서브유닛을 다른 프로세 서 서브유닛에 연결하는 버스를 사용할 수 있다. 따라서, 일례에서, 복수의 버스의 적어도 하나로 연결된 프로세서 서브유닛에 포함된 일련의 명령은 전송 작업 을 포함할 수 있다. 전송 작업은 하나 이상의 상응하는 전용 메모리 뱅크에 저장할 데이터를 복수의 버스의 적 어도 하나에 연결된 프로세서 서브유닛이 복수의 버스의 적어도 하나로 쓰게 하는 명령을 포함할 수 있다. 추가 적으로 또는 대안적으로, 복수의 버스의 적어도 하나로 연결된 프로세서 서브유닛에 포함된 일련의 명령은 수신 작업을 포함할 수 있다. 수신 작업은 하나 이상의 상응하는 전용 메모리 뱅크에 저장할 데이터를 복수의 버스의 적어도 하나에 연결된 프로세서 서브유닛이 복수의 버스의 적어도 하나로부터 읽게 하는 명령을 포함할 수 있다. 이에 따라, 이러한 실시예의 전송 및 수신 작업은 하나 이상의 상응하는 전용 메모리 뱅크의 하나 이상의 메모리 컨트롤러로 복수의 버스의 적어도 하나를 따라 전송되는 제어 신호를 포함할 수 있다. 또한, 전송 및 수 신 작업은 프로세서 서브유닛의 다른 부분(프로세서 서브유닛의 하나 이상의 다른 가속기)에 의해 실행되는 계산 또는 기타 작업과 동시에 프로세서 서브유닛의 일 부분(예, 프로세서 서브유닛의 하나 이상의 가속기)에 의 해 실행될 수 있다. 이러한 동시 실행의 일례에는 수신, 곱셈, 및 전송이 함께 실행되는 MAC-릴레이(relay) 명 령이 포함될 수 있다. 메모리 뱅크 간의 데이터 분산 외에도, 특정 부분의 데이터가 서로 다른 메모리 뱅크에 복제될 수 있다. 예를 들어, 앞서 설명한 바와 같이, 메모리 칩 상의 분산 프로세서는 메모리 칩 상에 배치된 복수의 프로세서 서브유 닛과 메모리 칩 상에 배치된 복수의 메모리 뱅크를 포함할 수 있다. 복수의 프로세서 서브유닛의 각각은 복수의 메모리 뱅크 중의 적어도 하나의 전용 메모리 뱅크로 연결될 수 있고, 복수의 메모리 뱅크의 각 메모리 뱅크는 복수의 메모리 뱅크의 다른 메모리 뱅크에 저장된 데이터와 별개인 데이터를 저장하도록 구성될 수 있다. 또한, 복수의 메모리 뱅크 중의 하나의 특정 메모리 뱅크에 저장된 데이터의 적어도 일부는 복수의 메모리 뱅크의 적 어도 다른 하나의 메모리 뱅크에 저장된 데이터의 복제본을 포함할 수 있다. 예를 들어, 일련의 명령에 사용되 는 데이터의 번호, 문자열, 또는 기타 유형이 한 메모리 뱅크에서 메모리 칩의 다른 프로세서 서브유닛으로 전 송되기보다는 서로 다른 프로세서 서브유닛의 전용인 복수의 메모리 뱅크에 저장될 수 있다. 일례에서, 병렬 문자열 매칭(parallel string matching)은 앞서 설명한 데이터 복제를 활용할 수 있다. 예를 들 어, 복수의 문자열은 동일한 문자열에 비교될 수 있다. 기존의 프로세서는 복수의 문자열의 각 문자열을 동일 스트링과 순차 비교할 것이다. 본 개시의 하드웨어 칩에서는, 동일 문자열이 메모리 뱅크 전반에 걸쳐 복제되어 프로세서 서브유닛이 복수의 문자열의 개별 문자열을 복제된 문자열과 병렬 비교할 수 있도록 할 수 있다. 일부 실시예에서, 하기에 도 8을 참조하여 설명하는 바와 같이, 복수의 메모리 뱅크 중의 하나의 특정 메모리 뱅크 및 복수의 메모리 뱅크의 적어도 다른 하나에 복제된 일부 데이터는 메모리 뱅크에 데이터를 복제하도록 구성된 컴파일러에 의해 정의된다. 또한, 컴파일러는 상응하는 프로세서 서브유닛에 분산된 복수의 저수준 작업 을 이용하여 적어도 일부 데이터를 복제하도록 구성될 수 있다. 데이터의 복제는 데이터의 동일 부분을 다른 계산에 재사용하는 작업에 유용할 수 있다. 데이터의 이런 부분을 복제함으로써, 이러한 계산이 메모리 뱅크의 프로세서 서브유닛에 분산되어 병렬 실행될 수 있는 반면, 각 프로 세서 서브유닛은 (프로세서 서브유닛을 연결하는 버스를 통해 데이터의 이런 부분을 푸쉬 및 풀 하지 않고) 데 이터의 이런 부분을 전용 메모리 뱅크에 저장하고 전용 메모리 뱅크에서 저장된 부분에 접근할 수 있다. 일례에 서, 복수의 메모리 뱅크의 하나의 특정 메모리 뱅크와 복수의 메모리 뱅크의 적어도 하나의 다른 메모리 뱅크에 복제된 일부 데이터는 신경망의 가중치를 포함할 수 있다. 이러한 예에서, 신경망의 각 노드는 복수의 프로세서 서브유닛의 적어도 한 프로세서 서브유닛에 의해 정의될 수 있다. 예를 들어, 각 노드는 이 노드를 정의하는 적 어도 하나의 프로세서 서브유닛에 의해 실행되는 머신 코드를 포함할 수 있다. 이러한 예에서, 가중치를 복제하 면 각 프로세서 서브유닛이 (다른 프로세서 서브유닛과의 데이터 전송을 수행하지 않고) 하나 이상의 전용 메모 리 뱅크에만 접근하면서 머신 코드를 실행하여 상응하는 노드에 적어도 부분적으로 작용할 수 있다. 전용 메모 리에 대한 읽기와 쓰기 타이밍은 다른 프로세서 서브유닛과 별개인 반면에 프로세서 서브유닛 사이의 데이터 전 송은 타이밍 동기화(앞서 설명한 바와 같이 소프트웨어를 활용)가 필요하므로, 메모리의 복제를 통해 프로세서 서브유닛 사이의 데이터 전송을 안 해도 되면 전체적인 실행이 더욱 효율적이 될 수 있다. 앞서 도 7a와 도 7b를 참조하여 설명한 바와 같이, 메모리 칩은 복수의 프로세서 서브유닛의 하나를 복수의 메 모리 뱅크의 하나 이상의 상응하는 전용 메모리 뱅크에 각각 연결하는 복수의 버스를 포함할 수 있다. 또한, 앞 서 설명한 바와 같이, 복수의 버스 상의 데이터 전송은 소프트웨어를 이용하여 제어될 수 있다. 이에 따라, 복 수의 버스의 특정 버스를 통한 데이터 전송은 복수의 버스의 특정 버스에 연결된 상응하는 프로세서 서브유닛에 의해 제어될 수 있다. 따라서, 일련의 명령에 포함된 작업의 하나는 버스 중의 하나로 데이터를 출력하는 작업 또는 버스 중의 하나에서 데이터를 가져오는 작업을 포함할 수 있다. 앞서 설명한 바와 같이, 이러한 작업은 (i) 프로세서 서브유닛의 처리 소자 또는 (ii) 프로세서 서브유닛에 포함된 하나 이상의 가속기에 의해 실행될 수 있다. 앞서 더 설명한 바와 같이, 이러한 작업은 하나 이상의 상응하는 전용 메모리 뱅크의 하나 이상의 메 모리 컨트롤러로 복수의 버스의 적어도 하나를 따라 전송되는 제어 신호를 포함하는 전송 작업 및/또는 수신 작 업을 포함할 수 있다. 도 8은 도 7a와 도 7b에 도시된 것 등과 같은 본 개시의 예시적인 메모리 칩 상에서 실행되기 위한 일련의 명령 을 컴파일하는 방법의 순서도를 도시한 것이다. 방법은 범용 또는 전용의 기존 프로세서에 의해 구현 될 수 있다. 방법은 컴파일러를 형성하는 컴퓨터 프로그램의 일부로 실행될 수 있다. 본 개시에서, '컴파일러'는 고수 준 언어(예, C, FORTRAN, BASIC 등과 같은 절차형 언어; Java, C++, Pascal, Python 등과 같은 객체 지향 언어등)를 저수준 언어(예, 어셈블리 코드, 오브젝트 코드, 머신 코드 등)로 변환하는 모든 컴퓨터 프로그램을 말한 다. 컴파일러는 사람으로 하여금 인간 판독 가능 언어로 일련의 명령을 프로그램할 수 있게 해줄 수 있고, 이러 한 명령은 나중에 머신 실행 가능 언어로 변환된다. 단계 810에서, 프로세서는 일련의 명령과 연관된 작업을 프로세서 서브유닛의 서로 다른 서브유닛에 배정할 수 있다. 예를 들어, 일련의 명령은 프로세서 서브유닛에서 병렬로 실행될 소그룹으로 분할될 수 있다. 일례에서, 신경망은 노드로 분할될 수 있고, 하나 이상의 노드가 서로 다른 프로세서 서브유닛에 배정될 수 있다. 이러한 예에서, 각 소그룹은 서로 다른 계층으로 연결된 복수의 노드를 포함할 수 있다. 따라서, 프로세서 서브유닛은 신경망의 제1 계층으로부터의 노드, 동일 프로세서 서브유닛에 의해 구현된 제1 계층으로부터의 노드에 연결된 제2 계층으로부터의 노드 등을 구현할 수 있다. 각각의 연결에 의거하여 노드를 배정함으로써, 프로세서 서브유 닛 간의 데이터 전송이 적어질 수 있고, 그 결과로 앞서 설명한 바와 같이 효율성이 향상될 수 있다. 앞서 도 7a와 도 7b를 참조하여 설명한 바와 같이, 프로세서 서브유닛은 메모리 칩 상에 배치된 복수의 메모리 뱅크에 공간적으로 분산될 수 있다. 이에 따라, 작업의 배정은 논리적으로 분할될 뿐만 아니라 적어도 부분적으 로는 공간적으로 분할될 수 있다. 단계 820에서, 프로세서는 버스에 의해 각각 연결되는 메모리 칩의 프로세서 서브유닛의 쌍 사이에 데이터를 전 송하는 작업을 생성할 수 있다. 예를 들어, 앞서 설명한 바와 같이, 데이터 전송은 소프트웨어를 활용하여 제어 될 수 있다. 이에 따라, 프로세서 서브유닛은 동기화된 시간에 버스 상에서 데이터를 푸시 및 풀 하도록 구성될 수 있다. 따라서, 생성된 작업은 데이터의 이러한 동기화된 푸쉬 및 풀을 수행하기 위한 작업을 포함할 수 있다. 앞서 설명한 바와 같이, 단계 820은 프로세서 서브유닛의 타이밍과 지연을 포함하는 내부 동작에 대처하기 위한 프리프로세싱을 포함할 수 있다. 예를 들어, 프로세서는 생성된 작업이 동기화되도록 하기 위하여 프로세서 서 브유닛의 알려진 시간과 지연(예, 버스로 데이터를 푸쉬 하는데 드는 시간, 버스로부터 데이터를 풀 하는데 드 는 시간, 계산과 푸쉬 또는 풀 사이의 지연 등)을 활용할 수 있다. 따라서, 하나 이상의 프로세서 서브유닛에 의한 적어도 하나의 푸쉬 및 하나 이상의 프로세서 서브유닛에 의한 적어도 하나의 풀을 포함하는 데이터 전송 은 프로세서 서브유닛 간의 타이밍 차이, 프로세서 서브유닛의 지연 등으로 인한 지연을 발생시키지 않고 동시 에 일어날 수 있다. 단계 830에서, 프로세서는 배정 및 생성된 작업을 복수의 그룹의 서브시리즈 명령으로 분류할 수 있다. 예를 들 어, 서브시리즈 명령은 각각 단일 프로세서 서브유닛에 의해 실행될 일련의 작업을 포함할 수 있다. 따라서, 복 수의 그룹의 서브시리즈 명령의 각각은 복수의 프로세서 서브유닛의 서로 다른 서브유닛에 상응할 수 있다. 이 에 따라, 단계 810, 단계 820, 및 단계 830의 결과로, 일련의 명령이 복수의 그룹의 서브시리즈 명령으로 나누 어질 수 있다. 앞서 설명한 바와 같이, 단계 820은 서로 다른 그룹 사이의 데이터 전송이 모두 동기화 되게 할 수 있다. 단계 840에서, 프로세서는 복수의 그룹의 서브시리즈 명령의 각각에 상응하는 머신 코드를 생성할 수 있다. 예 를 들어, 서브시리즈 명령을 나타내는 고수준 코드는 상응하는 프로세서 서브유닛에 의해 실행 가능한 머신 코 드와 같은 저수준 코드로 변환될 수 있다. 단계 850에서, 프로세서는 복수의 그룹의 서브시리즈 명령의 각각에 상응하는 생성된 머신 코드를 상기 분할에 따라 복수의 프로세서 서브유닛의 상응하는 프로세서 서브유닛에 배정할 수 있다. 예를 들어, 프로세서는 각 서 브시리즈 명령에 상응하는 프로세서 서브유닛의 식별자를 붙일 수 있다. 따라서, 서브시리즈 명령이 실행을 위 해 메모리 칩에 업로드 되는 경우에(예, 도 3a의 호스트에 의해), 각 서브시리즈는 적절한 프로세서 서브 유닛을 설정할 수 있다. 일부 실시예에서, 일련의 명령과 연관된 작업을 프로세서 서브유닛의 서로 다른 프로세서 서브유닛에 배정하는 것은 적어도 부분적으로는 메모리 칩 상의 둘 이상의 프로세서 서브유닛 사이의 공간적 근접성에 의존할 수 있 다. 예를 들어, 앞서 설명한 바와 같이, 프로세서 서브유닛 사이의 데이터 전송의 수를 감소하면 효율성이 향상 될 수 있다. 이에 따라, 프로세서는 둘 이상의 프로세서 서브유닛을 통해 데이터를 이동하는 데이터 전송을 최 소화할 수 있다. 따라서, 프로세서는 인접 전송을 최대화하고(적어도 국부적으로) 이웃하지 않는 프로세서 서브 유닛으로의 전송을 최소화하는(적어도 국부적으로) 방식으로 서브시리즈를 프로세서 서브유닛으로 배정하기 위 하여 메모리 칩의 알려진 레이아웃을 하나 이상의 최적화 알고리즘(예, 그리디 알고리즘(greedy algorithm))과 병합하여 활용할 수 있다.방법은 본 개시의 메모리 칩에 대한 추가적인 최적화를 포함할 수 있다. 예를 들어, 프로세서는 상기 분할 에 의거하여 일련의 명령과 연관된 데이터를 분류하고 이러한 분류에 따라 데이터를 메모리 뱅크에 배정할 수 있다. 이에 따라, 메모리 뱅크는 각 메모리 뱅크의 전용인 각 프로세서 서브유닛에 배정된 서브시리즈 명령에 사용되는 데이터를 보유할 수 있다. 일부 실시예에서, 데이터의 분류는 둘 이상의 메모리 뱅크로 복제될 데이터의 적어도 일부를 판단하는 작업을 포함할 수 있다. 예를 들어, 앞서 설명한 바와 같이, 일부 데이터는 하나 이상의 서브시리즈 명령에서 사용될 수 있다. 이러한 데이터는 서로 다른 서브시리즈 명령이 배정된 복수의 프로세서 서브유닛 전용의 메모리 뱅크 에 복제될 수 있다. 이러한 최적화는 프로세서 서브유닛 간의 데이터 전송을 더 감소시킬 수 있다. 방법의 출력은 실행을 위한 본 개시의 메모리 칩으로의 입력일 수 있다. 예를 들어, 메모리 칩은 적어도 하나의 전용 메모리 뱅크에 각각 연결된 복수의 프로세서 서브유닛과 이에 상응하는 복수의 메모리 뱅크를 포함 할 수 있고, 메모리 칩의 프로세서 서브유닛은 방법에 의해 생성된 머신 코드를 실행하도록 구성될 수 있 다. 도 3a를 참조하여 설명한 바와 같이, 호스트는 방법에 의해 생성된 머신 코드를 프로세서 서브유 닛에 입력하여 실행할 수 있다. 서브뱅크와 서브컨트롤러 기존의 메모리 뱅크에서, 컨트롤러는 뱅크 레벨에서 제공된다. 각 뱅크는 전형적으로 장방형으로 배치되지만 이 외의 기타 모든 기하 형상으로 배치될 수 있는 복수의 매트(mat)를 포함한다. 각 매트는 역시 전형적으로 장방 형으로 배치되지만 이 외의 기타 모든 기하 형상으로 배치될 수 있는 복수의 메모리 셀을 포함한다. 각 셀은 (셀이 고압 또는 저압으로 유지되는지 등에 따라) 단일 비트의 데이터를 저장할 수 있다. 이러한 기존의 아키텍처의 예가 도 9와 도 10에 도시되어 있다. 도 9에 도시된 바와 같이, 뱅크 레벨에서, 복수 의 매트(예, 매트(930-1, 930-2, 940-1, 940-2))가 뱅크를 형성할 수 있다. 기존의 장방형 구조에서, 뱅 크는 글로벌 워드라인(예, 워드라인)과 글로벌 비트라인(예, 비트라인)으로 제어될 수 있다. 이 에 따라, 로우 디코더(row decoder)는 입력되는 제어 신호(예, 어드레스에서 읽기 요청, 어드레스로 쓰기 요청 등)에 의거하여 정확한 워드라인을 선택할 수 있고, 글로벌 센스 증폭기(global sense amplifier, 920)(및 /또는 도 9에는 도시되지 않은 글로벌 컬럼 디코더)는 제어 신호에 의거하여 정확한 비트라인을 선택할 수 있다. 증폭기는 또한 읽기 동작 중에 선택된 뱅크에서 전압 레벨을 증폭할 수 있다. 도면에는 초기 선택을 위해 로우 디코더를 사용하고 열을 따라 증폭을 수행하는 것으로 도시되어 있지만, 뱅크는 추가적으로 또는 대 안적으로 컬럼 디코더(column decoder)를 사용하여 초기 선택을 하고 행을 따라 증폭을 수행할 수 있다. 도 10은 매트의 일례를 도시한 것이다. 예를 들어, 매트는 도 9의 뱅크와 같은 메모리 뱅크의 일부를 형성할 수 있다. 도 10에 도시된 바와 같이, 복수의 셀(예, 1030-1, 1030-2, 1030-3)이 매트를 형성할 수 있다. 각 셀은 커패시터, 트랜지스터, 또는 적어도 1비트의 데이터를 저장하는 기타 회로를 포함할 수 있다. 예를 들어, 셀은 하전되어 '1'을 나타내고 방전되어 '0'을 나타내는 커패시터를 포함하거나 '1'을 나 타내는 제1 상태와 '0'을 나타내는 제2 상태를 포함하는 플립플롭(flip-flop)을 포함할 수 있다. 기존의 매트는 예를 들어 512비트 x 512비트를 포함할 수 있다. 매트가 MRAM, ReRAM 등의 일부를 형성하는 실시예에서, 셀은 트랜지스터, 저항기, 커패시터, 또는 적어도 1비트의 데이터를 저장하는 물질의 이온 또는 일부를 분리하 는 기타 메커니즘을 포함할 수 있다. 예를 들어, 셀은 제1 상태가 '1'을 나타내고 제2 상태가 '0'을 나타내는 전해질 이온, 칼코겐화 유리(chalcogenide glass) 등을 포함할 수 있다. 도 10에 더 도시된 바와 같이, 기존의 장방형 구조에서, 매트는 로컬 워드라인(예, 워드라인)과 로 컬 비트라인(예, 비트라인)에 걸쳐 제어될 수 있다. 이에 따라, 워드라인 드라이버(예, 워드라인 드라이 버(1020-1, 1020-2, . . . , 1020-x))가 선택된 워드라인을 제어하여, 매트가 그 일부를 형성하는 메모 리 뱅크와 연관된 컨트롤러로부터의 제어 신호(예, 어드레스에서 읽기 요청, 어드레스로 쓰기 요청, 리프레쉬 신호 등)에 의거하여 읽기, 쓰기, 또는 리프레쉬를 수행할 수 있다. 또한, 로컬 센스 증폭기(예, 로컬 증폭기 (1010-1, 1010-2, . . . , 1010-x)) 및/또는 로컬 컬럼 디코더(도 10에는 미도시)가 선택된 비트라인을 제어하 여 읽기, 쓰기, 또는 리프레쉬를 수행할 수 있다. 로컬 센스 증폭기는 또한, 선택된 셀의 전압 레벨을 읽기 동 작 동안에 증폭할 수 있다. 도면에는 초기 선택에 워드라인 드라이버를 사용하고 열을 따라 증폭을 수행하는 것으로 도시되어 있지만, 매트는 초기 선택에 비트라인 드라이버를 사용하고 행을 따라 증폭을 수행할 수도 있다. 앞서 설명한 바와 같이, 많은 수의 매트가 복제되어 메모리 뱅크를 형성한다. 메모리 뱅크는 그룹으로 묶여서 메모리 칩을 형성할 수 있다. 예를 들어, 메모리 칩은 8개 내지 32개의 메모리 뱅크를 포함할 수 있다. 이에 따라, 기존의 메모리 칩 상에서 프로세서 서브유닛과 메모리 뱅크를 페어링한 결과로 8 내지 32 프로세서 서브유 닛만이 형성된다. 이에 따라, 본 개시의 실시예는 추가적인 서브뱅크(sub-bank) 체계를 가진 메모리 칩을 포함 할 수 있다. 본 개시의 이러한 메모리 칩은 따라서 프로세서 서브유닛과 페어링 된 전용 메모리 뱅크로 사용되 는 메모리 서브뱅크를 가진 프로세서 서브유닛을 포함할 수 있다. 이에 따라, 더 많은 수의 서브프로세서(sub processor)가 가능하고, 인메모리 계산(in-memory computing)의 병렬 수행과 성능을 향상할 수 있다. 본 개시의 일부 실시예에서, 뱅크의 글로벌 로우 디코더와 글로벌 센스 증폭기는 서브뱅크 컨트롤러로 대 체할 수 있다. 이에 따라, 메모리 뱅크의 글로벌 로우 디코더와 글로벌 센스 증폭기로 제어 신호를 보내지 않고, 메모리 뱅크의 컨트롤러는 제어 신호를 적합한 서브뱅크 컨트롤러로 보낼 수 있다. 제어 신호를 보내는 방향은 동적으로 제어되거나 하드웨어에 내장(예, 하나 이상의 논리 게이트를 통해)될 수 있다. 일부 실시예에 서, 퓨즈를 사용하여 각 서브뱅크 또는 매트의 컨트롤러가 제어 신호를 해당 서브뱅크 또는 매트로 통과시키거 나 차단하도록 지시할 수 있다. 따라서, 이러한 실시예에서, 퓨즈를 사용하여 불량 서브뱅크가 비활성화될 수 있다. 이러한 실시예의 일례에서, 메모리 칩은 복수의 메모리 뱅크를 포함할 수 있고, 각 메모리 뱅크는 뱅크 컨트롤 러와 복수의 메모리 서브뱅크를 포함할 수 있고, 각 메모리 서브뱅크는 메모리 서브뱅크 상의 각 위치로 읽기와 쓰기가 가능하도록 하는 서브뱅크 로우 디코더와 서브뱅크 컬럼 디코더를 포함할 수 있다. 각 서브뱅크는 복수 의 메모리 매트를 포함할 수 있고, 각 메모리 매트는 복수의 메모리 셀을 포함할 수 있고 내부적으로 로컬인 로 우 디코더, 컬럼 디코더, 및/또는 로컬 센스 증폭기를 포함할 수 있다. 서브뱅크 로우 디코더와 서브뱅크 컬럼 디코더는 뱅크 컨트롤러의 읽기 및 쓰기 요청 또는 하기에 설명하는 서브뱅크 메모리 상의 메모리 내 계산에 사 용되는 서브뱅크 프로세서 서브유닛의 읽기 및 쓰기 요청을 처리할 수 있다. 추가적으로, 각 메모리 서브뱅크는 뱅크 컨트롤러의 읽기 요청과 쓰기 요청을 처리할지 여부 및/또는 이러한 요청을 다음 레벨(예, 매트 상의 로우 디코더 및 컬럼 디코더의 레벨)로 송부할지 또는 이러한 요청을 차단할지, 예를 들어, 내부 처리 소자 또는 프 로세서 서브유닛이 메모리에 접근하게 허용할지, 여부를 판단하도록 구성된 컨트롤러를 더 포함할 수 있다. 일 부 실시예에서, 뱅크 컨트롤러는 시스템 클럭(system clock)에 동기화될 수 있다. 그러나 서브뱅크 컨트롤러는 시스템 클럭에 동기화되지 않을 수 있다. 앞서 설명한 바와 같이, 서브뱅크를 사용하면, 프로세서 서브유닛이 기존 칩의 메모리 뱅크와 쌍을 이룬 경우보 다 더 많은 수의 프로세서 서브유닛을 메모리 칩에 포함시킬 수 있다. 이에 따라, 각 서브뱅크는 서브뱅크를 전 용 메모리로 사용하는 프로세서 서브유닛을 더 포함할 수 있다. 앞서 설명한 바와 같이, 프로세서 서브유닛은 RISC, CISC, 또는 기타 범용 프로세서 서브유닛을 포함 및/또는 하나 이상의 가속기를 포함할 수 있다. 또한, 프로세서 서브유닛은 앞서 설명한 바와 같이 어드레스 생성기를 포함할 수 있다. 앞서 설명한 모든 실시예에서, 각 프로세서 서브유닛은 뱅크 컨트롤러를 사용하지 않고 서브뱅크의 로우 디코더와 컬럼 디코더를 사용하여 프 로세서 서브유닛 전용의 서브뱅크에 접근하도록 구성될 수 있다. 서브 뱅크와 연관된 프로세서 서브유닛은 또한 메모리 매트를 취급(하기에 설명하는 디코더 및 메모리 중복 메커니즘 포함) 및/또는 상위 레벨(예, 뱅크 레벨 또는 메모리 레벨)의 읽기 및 쓰기 요청이 이에 부응하여 전송 및 취급되는지 여부를 판단할 수 있다. 일부 실시예에서, 서브뱅크 컨트롤러는 서브뱅크의 상태를 저장하는 레지스터를 더 포함할 수 있다. 이에 따라, 서브뱅크가 사용중인 것으로 레지스터가 나타내는 가운데 서브뱅크 컨트롤러가 메모리 컨트롤러로부터 제어 신 호를 수신하는 경우에, 서브뱅크 컨트롤러는 오류임을 출력할 수 있다. 각 서브뱅크가 프로세서 서브유닛을 더 포함하는 실시예에서, 서브뱅크의 프로세서 서브유닛이 메모리 컨트롤러로부터의 외부 요청에 상충하여 메모리 에 접근하는 경우, 레지스터는 오류임을 나타낼 수 있다. 도 11은 서브뱅크 컨트롤러를 사용하는 메모리 뱅크의 다른 실시예의 일례를 도시한 것이다. 도 11의 예에서, 뱅크는 로우 디코더, 뱅크 디코더, 및 서브뱅크 컨트롤러(예, 컨트롤러(1130a, 1130b, 1130c))가 있는 복수의 메모리 서브뱅크(예, 서브뱅크(1170a, 1170b, 1170c))를 포함한다. 서브뱅크 컨트롤러는 서브뱅크 컨트롤러의 제어를 받는 하나 이상의 서브뱅크로 요청을 전달할지 여부를 판단할 수 있는 어드레스 리 졸버(address reolver; 예, 리졸버(1140a, 1140b, 1140c))를 포함할 수 있다. 서브뱅크 컨트롤러는 하나 이상의 논리 회로(예, 회로(1150a, 1150b, 1150c))를 더 포함할 수 있다. 예를 들어, 하나 이상의 처리 소자를 포함하는 논리 회로는 서브뱅크의 셀을 리프레쉬하는 동작, 서브뱅크의 셀을 비우는 동작 등과 같은 하나 이상의 동작이 뱅크의 외부에서 요청을 처리하지 않고 수행되도록 할 수 있다. 또는, 논리 회로는 앞서 설명한 바와 같은 프로세서 서브유닛을 포함하여 서브뱅크 컨트롤러에 의해 제어되는 모든 서브뱅크가 프로세서 서브유닛의 상응하는 전용 메모리가 되도록 할 수 있다. 도 11의 예에서, 논리(1150a)의 상응하는 전용 메모리는 서브뱅크(1170a)이고, 논리(1150b)의 상응하는 전용 메모리는 서브뱅크 (1170b)이고, 논리(1150c)의 상응하는 전용 메모리는 서브뱅크(1170c)이다. 앞서 설명한 모든 실시예에서, 논리 회로에는 서브뱅크로 연결하는 버스, 예를 들어, 버스(1131a, 1131b, 1131c)가 있다. 도 11에 도시된 바와 같이, 서브뱅크 컨트롤러 각각은 처리 소자 또는 프로세서 서브유닛에 의한 또는 명령을 발생하는 고수준 메모 리 컨트롤러에 의한 메모리 뱅크 상의 위치에 읽기와 쓰기가 가능하게 하는 서브뱅크 로우 디코더와 서브뱅크 컬럼 디코더와 같은 복수의 디코더를 포함할 수 있다. 예를 들어, 서브뱅크 컨트롤러(1130a)는 디코더(1160a, 1160b, 1160c)를 포함하고, 서브뱅크 컨트롤러(1130b)는 디코더(1160d, 1160e, 1160f)를 포함하고, 서브뱅크 컨트롤러(1130c)는 디코더(1160g, 1160h, 1160i)를 포함한다. 뱅크 로우 디코더의 요청에 의거하여, 서브 뱅크 컨트롤러는 서브뱅크 컨트롤러에 포함된 디코더를 사용하여 워드라인을 선택할 수 있다. 여기에 설명한 시 스템은 서브뱅크의 처리 소자 또는 프로세서 서브유닛이 다른 뱅크 및 다른 서브뱅크 마저도 간섭하지 않으면서 메모리에 접근할 수 있게 하고, 이에 따라 각 서브뱅크 프로세서 서브유닛은 다른 서브뱅크 서브유닛과 병렬로 메모리 계산을 할 수 있다. 또한, 각 서브뱅크는 복수의 메모리 셀을 각각 포함하는 복수의 메모리 매트를 포함할 수 있다. 예를 들어, 서 브뱅크(1170a)는 매트(1190a-1, 1190a-2, . . . , 1190a-x)를 포함하고, 서브뱅크(1170b)는 매트(1190b-1, 1190b-2, . . . , 1190b-x)를 포함하고, 서브뱅크(1170c)는 매트(1190c-1, 1190c-2, . . . , 1190c-x)를 포함 한다. 또한, 도 11에 도시된 바와 같이, 각 서브뱅크는 적어도 하나의 디코더를 포함할 수 있다. 예를 들어, 서 브뱅크(1170a)는 디코더(1180a)를 포함하고, 서브뱅크(1170b)는 디코더(1180b)를 포함하고, 서브뱅크(1170c)는 디코더(1180c)를 포함한다. 이에 따라, 뱅크 컬럼 디코더는 외부 요청에 의거하여 글로벌 비트라인(예, 1121a 또는 1121b)을 선택할 수 있는 반면에 뱅크 로우 디코더에 의해 선택된 서브뱅크는 컬럼 디코더를 활용하여 이 서브뱅크가 전용인 논리 회로의 로컬 요청에 의거한 로컬 비트라인(예, 1181a 또는 1181b)을 선택 할 수 있다. 이에 따라, 각 프로세서 서브유닛은 뱅크 로우 디코더와 뱅크 컬럼 디코더를 사용하지 않고 서브 뱅크의 로우 디코더와 컬럼 디코더를 활용하여 프로세서 서브유닛의 전용 서브 뱅크에 접근하도록 구성될 수 있 다. 따라서, 각 프로세서 서브유닛은 다른 서브뱅크를 간섭하지 않으면서 상응하는 서브뱅크에 접근할 수 있다. 또한, 서브뱅크로의 요청이 프로세서 서브유닛의 외부에서 이루어지는 경우에, 서브뱅크 디코더는 접근된 데이 터를 뱅크 디코더에 반영할 수 있다. 또는, 각 서브뱅크에 단일 행의 메모리 뱅크만이 있는 실시예에서, 로컬 비트라인은 서브뱅크의 비트라인이 아닌 매트의 비트라인일 수 있다. 도 11에 도시된 실시예의 서브뱅크 로우 디코더와 서브뱅크 컬럼 디코더를 사용하는 실시예의 조합도 사용될 수 있다. 예를 들어, 뱅크 로우 디코더가 제거되지만 뱅크 컬럼 디코더는 유지하고 로컬 비트라인을 사용할 수 있 다. 도 12는 복수의 매트를 포함하는 메모리 서브뱅크의 실시예의 일례를 도시한 것이다. 예를 들어, 서브뱅 크는 도 11의 서브뱅크의 일부분을 나타내거나 메모리 뱅크가 다르게 구현된 것을 나타내는 것일 수 있다. 도 12의 예에서, 서브뱅크는 복수의 매트(예, 1240a, 1240b)를 포함한다. 또한, 각 매트는 복수 의 셀을 포함할 수 있다. 예를 들어, 매트(1240a)는 셀(1260a-1, 1260a-2, . . . , 1260a-x)을 포함하고, 매트 (1240b)는 셀(1260b-1, 1260b-2, . . . , 1260b-x)을 포함한다. 각 매트에는 매트의 메모리 셀에 배정될 어드레스의 범위가 배정될 수 있다. 이러한 어드레스는 매트가 이리저 리 옮겨질 수 있고 결함이 있는 매트는 비활성화되고 사용되지 않도록(예, 하기에 설명하는 바와 같이, 하나 이 상의 퓨즈 사용) 제조시에 설정될 수 있다. 서브뱅크는 메모리 컨트롤러로부터 읽기와 쓰기 요청을 수신한다. 도 12에는 도시되어 있지 않지만, 메모리 컨트롤러로부터의 요청은 서브뱅크의 컨트롤러를 통해 필터링 되고 어드레스 결정 을 위해 서브뱅크의 적절한 매트로 보내질 수 있다. 대안적으로, 메모리 컨트롤러의 요청의 어드레 스의 적어도 일부분(예, 높은 비트)이 서브뱅크의 모든 매트(예, 1240a, 1240b)로 전송되어 매트의 배정 된 어드레스 범위가 명령에 특정된 어드레스를 포함하는 경우에만 어드레스와 연관된 요청과 전체 어드레스를 처리하도록 할 수 있다. 상기의 서브뱅크 지시와 유사하게, 매트 판단은 동적으로 제어되거나 하드웨어에 내장 될 수 있다. 일부 실시예에서, 퓨즈를 사용하여 각 매트에 대한 어드레스 범위를 판단할 수 있고, 또한 불법 어 드레스 범위를 배정함으로써 불량 매트를 비활성화할 수 있다. 매트는 일반적인 기타 방법이나 퓨즈 연결에 의 해 추가적으로 또는 대안적으로 비활성화 될 수 있다. 앞서 설명한 모든 실시예에서, 서브뱅크의 각 매트는 매트에서 워드라인을 선택하기 위한 로우 디코더(예, 1230a, 1230b)를 포함할 수 있다. 일부 실시예에서, 각 매트는 퓨즈 및 비교기(예, 1220a, 1220b)를 더 포함할수 있다. 앞서 설명한 바와 같이, 비교기는 각 매트가 입력되는 요청을 처리할지 여부를 판단하게 할 수 있고, 퓨즈는 각 매트가 불량인 경우 비활성화 되게 할 수 있다. 대안적으로, 뱅크 및/또는 서브뱅크의 로우 디코더가 각 매트의 로우 디코더 대신에 사용될 수 있다. 또한, 앞서 설명한 모든 실시예에서, 해당 매트에 포함된 컬럼 디코더(예, 1250a, 1250b)는 로컬 비트라인(예, 1251, 1253)을 선택할 수 있다. 로컬 비트라인은 메모리 뱅크의 글로벌 비트라인에 연결될 수 있다. 서브뱅크에 자체의 로컬 비트라인이 있는 실시예에서, 셀의 로컬 비트라인은 서브뱅크의 로컬 비트라인으로 더 연결될 수 있다. 이에 따라, 선택된 셀의 데이터는 셀의 컬럼 디코더(및/또는 센스 증폭기)를 통한 후에 서브뱅크의 컬럼 디코더(및/또는 센스 증폭기)를 통하고(서브뱅크 컬럼 디코더 및/또는 센스 증폭기를 포함하는 실시예에서) 그 후에 뱅크의 컬럼 디코더(및/또는 센스 증폭기)를 통해 읽어질 수 있다. 매트는 복제되고 어레이로 배열되어 메모리 뱅크(또는 메모리 서브뱅크)를 형성할 수 있다. 예를 들어, 본 개시의 메모리 칩은 복수의 메모리 뱅크를 포함할 수 있고, 각 메모리 뱅크에는 복수의 메모리 서브뱅크가 있고, 각 메모리 서브뱅크에는 메모리 서브뱅크 상의 각 위치로 읽기와 쓰기를 처리하기 위한 서브뱅크 컨트롤 러가 있다. 또한, 각 메모리 서브뱅크는 복수의 메모리 매트를 포함할 수 있고, 각 메모리 매트에는 복수의 메 모리 셀과 매트 로우 디코더와 매트 컬럼 디코더(도 12에 도시)가 있다. 매트 로우 디코더와 매트 컬럼 디코더 는 서브뱅크 컨트롤러로부터의 읽기와 쓰기 요청을 처리할 수 있다. 예를 들어, 매트 디코더는 모든 요청을 수 신하고 요청을 처리할지 여부를 각 매트의 알려진 어드레스 범위에 의거하여 판단(예, 비교기를 활용)하거나, 서브뱅크(또는 뱅크) 컨트롤러에 의한 매트 선택에 의거하여 알려진 어드레스 범위 이내의 요청 만을 수신할 수 있다. 컨트롤러 데이터 전송 본 개시의 메모리 칩은 또한 프로세서 서브유닛을 활용하여 데이터를 공유하는 것 외에도 메모리 컨트롤러(또는 서브뱅크 컨트롤러 또는 매트 컨트롤러)를 활용하여 데이터를 공유할 수 있다. 예를 들어, 본 개시의 메모리 칩 은 메모리 뱅크의 각 위치로 읽기와 쓰기가 가능하도록 하는 뱅크 컨트롤러, 로우 디코더, 및 컬럼 디코더를 각 각 포함하는 복수의 메모리 뱅크(예, SRAM 뱅크, DRAM 뱅크 등)와 복수의 뱅크 컨트롤러의 각 컨트롤러를 복수 의 뱅크 컨트롤러의 적어도 하나의 다른 컨트롤러에 연결하는 복수의 버스를 포함할 수 있다. 일부 실시예에서, 복수의 버스는 하나 이상의 프로세서 서브유닛에 연결된 메모리 뱅크의 메인 버스 상의 데이 터 전송의 방해 없이 접근될 수 있다. 이에 따라, 메모리 뱅크(또는 서브뱅크)는 다른 메모리 뱅크(또는 서브뱅 크)와의 데이터 전송 또는 수신과 동일한 클럭 사이클로 상응하는 프로세서 서브유닛과 데이터를 전송 또는 수 신할 수 있다. 각 컨트롤러가 복수의 다른 컨트롤러에 연결된 실시예에서, 컨트롤러는 데이터의 전송 또는 수신 을 위해 복수의 다른 컨트롤러의 하나의 다른 컨트롤러를 선택하도록 구성될 수 있다. 일부 실시예에서, 각 컨 트롤러는 적어도 하나의 이웃하는 컨트롤러에 연결될 수 있다(예, 공간적으로 인접하는 컨트롤러의 쌍들이 서로 연결될 수 있다). 메모리 회로의 리던던트 로직 본 개시는 온칩(on-chip) 데이터 프로세싱을 위한 프라이머리 논리부(primary logic portions)가 있는 메모리 칩에 관한 것이다. 메모리 칩은 불량 프라이머리 논리부를 교체하여 칩의 제조 수율을 증가시킬 수 있는 리던던 트 논리부(redundant logic portions)를 포함할 수 있다. 따라서, 칩은 논리부의 개별 검사에 의거한 메모리 칩 의 로직 블록의 설정을 가능하게 하는 온칩 요소를 포함할 수 있다. 메모리 칩은 논리부 전용의 영역이 클수록 제조 오류의 영향을 더 많이 받기 때문에 칩의 이러한 특징은 수율을 향상할 수 있다. 예를 들어, 리던던트 논 리부가 큰 DRAM 메모리 칩은 수율을 감소시키는 제조 문제의 영향을 많이 받을 수 있다. 그러나 리던던트 논리 부를 구현하면 고도의 병렬성 능력을 유지하면서도 DRAM 메모리 칩의 생산자나 사용자가 전체 논리부를 켜거나 끌 수 있게 해주기 때문에 수율과 신뢰성이 향상되는 결과를 얻을 수 있다. 본 개시에서, 개시된 실시예의 설명 의 편의상 특정 메모리 유형(예, DRAM)의 예를 들 수 있다. 그렇다고 하더라도, 본 개시가 특정된 메모리 유형 으로 한정되는 것은 아니라는 점은 당연하다 할 것이다. 오히려, 본 개시의 일부 부분에서 예로 든 메모리 유형 이 적다고 하더라도, 개시된 실시예와 함께 DRAM, 플래시메모리, SRAM, ReRAM, PRAM, MRAM, ROM, 또는 기타 모 든 메모리와 같은 메모리 유형이 사용될 수 있다. 도 13은 본 개시에 따른 예시적인 메모리 칩의 구성도이다. 메모리 칩은 DRAM 메모리 칩으로 구현 될 수 있다. 메모리 칩은 또한 플래시메모리, SRAM, ReRAM, PRAM, 및/또는 MRAM 등과 같은 모든 유형의 휘발성 또는 비휘발성 메모리로 구현될 수 있다. 메모리 칩은 어드레스 매니저, 복수의 메모리 뱅크(1304(a,a) 내지 1304(z,z))를 포함하는 메모리 어레이, 메모리 로직, 비즈니스 로직, 및 리던던트 비즈니스 로직이 배치된 기판을 포함할 수 있다. 메모리 로직과 비즈니스 로직 은 프라이머리 로직 블록을 구성할 수 있는 반면, 리던던트 비즈니스 로직은 리던던트 블록을 구성 할 수 있다. 또한, 메모리 칩은 비활성화 스위치와 활성화 스위치가 포함될 수 있는 설정 스 위치를 포함할 수 있다. 비활성화 스위치와 활성화 스위치도 기판에 배치될 수 있다. 본 출 원에서, 메모리 로직, 비즈니스 로직, 및 리던던트 비즈니스 로직은 또한 집합적으로 '로직 블록'으로 칭해질 수 있다. 어드레스 매니저는 로우 디코더 및 컬럼 디코더 또는 기타 유형의 메모리 보조장치를 포함할 수 있다. 대 안적으로 또는 추가적으로, 어드레스 매니저는 마이크로컨트롤러 또는 처리부를 포함할 수 있다. 일부 실시예에서, 도 13에 도시된 바와 같이, 메모리 칩은 복수의 메모리 블록을 2차원 어레이로 기판 상에 배치할 수 있는 단일 메모리 어레이를 포함할 수 있다. 그러나 다른 실시예에서, 메모리 칩 은 다수의 메모리 어레이를 포함할 수 있고, 각각의 메모리 어레이는 서로 다른 구성으로 메 모리 블록을 배치할 수 있다. 예를 들어, 메모리 어레이 중의 적어도 한 어레이의 메모리 블록(즉, 메모리 뱅크)이 방사형 분포로 배치되어 어드레스 매니저 또는 메모리 로직으로부터 메모리 블록으로의 라 우팅을 가능하게 할 수 있다. 비즈니스 로직은 메모리 자체의 관리에 사용되는 논리와 무관한 어플리케이션의 인메모리 계산(in-memory computation)을 위해 사용될 수 있다. 예를 들어, 비즈니스 로직은 활성화 함수로 사용되는 플로팅, 정수, 또는 MAC 연산과 같은 AI에 관한 함수를 이행할 수 있다. 또한, 비즈니스 로직은 min, max, sort, count 등과 같은 데이터베이스 관련 함수를 이행할 수 있다. 메모리 로직은 읽기, 쓰기, 리프레쉬 동작 등을 포함하는 메모리 관리에 관한 작업을 수행할 수 있다. 따라서, 비즈니스 로직은 뱅크 레벨, 매트 레벨, 매 트 레벨의 그룹 중의 하나 이상에 추가될 수 있다. 비즈니스 로직에는 하나 이상의 어드레스 출력과 하나 이상의 데이터 입력/출력이 있을 수 있다. 예를 들어, 비즈니스 로직은 로우/컬럼 라인에 의해 어드레스 매니저로 어드레스 할 수 있다. 그러나 일부 실시예에서, 데이터 입력/출력을 통해 로직 블록이 추가적으 로 또는 대안적으로 어드레스 될 수 있다. 리던던트 비즈니스 로직은 비즈니스 로직의 복제일 수 있다. 또한, 리던던트 비즈니스 로직 은 작은 퓨즈/안티퓨즈(anti-fuse)를 포함할 수 있는 비활성화 스위치 및/또는 활성화 스위치에 연 결될 수 있고, 인스턴스 중의 하나(예, 디폴트로 연결되는 인스턴스)를 비활성화 또는 활성화하는 논리에 사용 되고 다른 로직 블록 중의 하나(예, 디폴트로 연결 해제되는 인스턴스)를 활성화할 수 있다. 일부 실시예에서, 하기에 도 15를 참조하여 설명하는 바와 같이, 블록의 중복성은 비즈니스 로직과 같은 로직 블록 이내에 국한될 수 있다. 일부 실시예에서, 메모리 칩의 로직 블록은 전용 버스로 메모리 어레이의 서브세트에 연결될 수 있 다. 예를 들어, 메모리 로직, 비즈니스 로직, 및 리던던트 비즈니스 로직의 세트는 메모리 어레이의 메모리 블록(즉, 1304 (a,a) 내지 1304 (a,z))의 제1행에 연결될 수 있다. 전용 버스는 연관된 로직 블록이 어드레스 매니저 등을 통하여 통신 라인을 개설할 필요없이 메모리 블록으로부터 데이터에 신속히 접근하게 해줄 수 있다. 복수의 프라이머리 로직 블록의 각각은 복수의 메모리 뱅크의 적어도 하나에 연결될 수 있다. 또한, 리던 던트 비즈니스 블록과 같은 리던던트 블록은 메모리 인스턴스(1304(a,a)-(z,z))의 적어도 하나에 연결될 수 있다. 리던던트 블록은 메모리 로직 또는 비즈니스 로직과 같은 복수의 프라이머리 로직 블록의 적어도 하나를 복제할 수 있다. 비활성화 스위치는 복수의 프라이머리 로직 블록의 적어도 하나에 연결될 수 있고, 활성화 스위치는 복수의 리던던트 블록의 적어도 하나에 연결될 수 있다. 이러한 실시예에서, 복수의 프라이머리 로직 블록(메모리 로직 및/또는 비즈니스 로직)의 하나와 연관된 결함이 검출되면, 비활성화 스위치는 복수의 프라이머리 로직 블록의 하나를 비활성화하도록 구성 될 수 있다. 동시에, 활성화 스위치는 복수의 프라이머리 로직 블록의 하나를 복제하는 리던던트 로직 블 록과 같은 복수의 리던던트 블록의 하나를 활성화하도록 구성될 수 있다. 또한, 집합적으로 '설정 스위치'로 불릴 수 있는 활성화 스위치와 비활성화 스위치는 스위치의 상 태를 설정하는 외부 입력을 포함할 수 있다. 예를 들어, 활성화 스위치는 외부 입력의 활성화 신호가 스 위치가 닫힌 상태를 유발하도록 설정될 수 있고, 비활성화 스위치는 외부 입력의 비활성화 신호가 스위치가 열린 상태를 유발하도록 설정될 수 있다. 일부 실시예에서, 메모리 칩의 모든 설정 스위치는 디폴트로 비활성화 상태이고, 검사의 결과가 관련 로직 블록이 기능을 하는 것으로 나타내고 신호가 외부 입력에 주어진 이후에 활성화될 수 있다. 또는, 일부의 경우, 메모리 칩의 모든 설정 스위치는 디폴트로 활성화 상태이 고, 검사의 결과가 관련 로직 블록이 기능을 하지 않는 것으로 나타내고 비활성화 신호가 외부 입력에 주어진 이후에 비활성화될 수 있다. 설정 스위치가 초기에 활성화이거나 비활성화인지 여부와 상관없이, 관련 로직 블록과 연관된 결함이 검출되면, 설정 스위치는 관련 로직 블록을 비활성화할 수 있다. 설정 스위치가 초기에 활성화되어 있는 경우, 설정 스위 치의 상태는 관련 로직 블록을 비활성화하기 위하여 비활성화로 변경될 수 있다. 설정 스위치가 초기에 비활성 화되어 있는 경우, 설정 스위치의 상태는 관련 로직 블록을 비활성화하기 위하여 비활성화 상태로 유지될 수 있 다. 예를 들어, 조작성 검사의 결과, 특정 로직 블록이 작동하지 않는 것으로 나오거나 특정 사양 내에서 작동 하지 않는 것으로 나올 수 있다. 이러한 경우, 로직 블록은 상응하는 설정 스위치를 활성화하지 않음으로써 비 활성화될 수 있다. 일부 실시예에서, 설정 스위치는 둘 이상의 로직 블록에 연결될 수 있고 서로 다른 로직 블록 사이에서 선택하 도록 구성될 수 있다. 예를 들어, 설정 스위치는 비즈니스 로직과 리던던트 로직 블록 모두에 연결 될 수 있다. 설정 스위치는 리던던트 로직 블록을 활성화하는 반면에 비즈니스 로직을 비활성화할 수 있다. 대안적으로 또는 추가적으로, 복수의 프라이머리 로직 블록의 적어도 하나(메모리 로직 및/또는 비즈니스 로직)가 제1 전용 연결로 복수의 메모리 뱅크 또는 메모리 인스턴스의 서브세트에 연결될 수 있다. 이후, 복수의 프라이머리 로직 블록의 적어도 하나를 복제하는 복수의 리던던트 블록의 적어도 하나(예, 리던던 트 비즈니스 블록)가 제2 전용 연결로 동일한 복수의 메모리 뱅크 또는 인스턴스의 서브세트에 연 결될 수 있다. 또한, 메모리 로직에는 비즈니스 로직과 다른 기능과 능력이 있을 수 있다. 예를 들어, 메모리 로 직은 메모리 뱅크에 읽기와 쓰기 동작이 가능하도록 설계될 수 있는 반면, 비즈니스 로직은 인메모리 계산을 수행하도록 설계될 수 있다. 따라서, 비즈니스 로직이 제1 비즈니스 로직 블록을 포함하 고 비즈니스 로직이 제2 비즈니스 로직 블록(예, 리던던트 비즈니스 로직)을 포함하는 경우, 결함 이 있는 비즈니스 블록을 연결 해제하고 능력의 손실 없이 리던던트 비즈니스 로직에 다시 연결하 는 것이 가능하다. 일부 실시예에서, 설정 스위치(비활성화 스위치와 활성화 스위치 포함)는 퓨즈, 안티퓨즈, 또는 프 로그램 가능 장치(일회용 프로그램 가능 장치 포함), 또는 기타 형태의 비휘발성 메모리로 구현될 수 있다. 도 14는 개시된 실시예에 따른 예시적인 리던던트 로직 블록 세트의 구성도이다. 일부 실시예에서, 리던 던트 로직 블록 세트는 기판에 배치될 수 있다. 리던던트 로직 블록 세트는 스위치(1312, 1314)에 각각 연결된 비즈니스 로직과 리던던트 비즈니스 로직 중의 적어도 하나를 포함할 수 있다. 또한, 비즈니스 로직과 리던던트 비즈니스 로직은 어드레스 버스와 데이터 버스(140 4)에 연결될 수 있다. 일부 실시예에서, 도 14에 도시된 바와 같이, 스위치(1312, 1314)는 로직 블록을 클럭 노드에 연결할 수 있다. 이로써, 설정 스위치는 로직 블록을 클럭 신호와 연결 또는 해제할 수 있고, 그 결과로 로직 블록을 활성화 또 는 비활성화 할 수 있다. 그러나 다른 실시예에서, 스위치(1312, 1314)는 로직 블록을 다른 노드에 연결하여 활 성화 또는 비활성화 할 수 있다. 예를 들어, 설정 스위치는 로직 블록을 전압 공급 노드(예, VCC) 또는 접지 노 드(예, GND) 또는 클럭 신호에 연결할 수 있다. 이로써, 설정 스위치는 개방 회로를 만들거나 로직 블록 전원을 차단할 수 있기 때문에 로직 블록은 설정 스위치에 의해 활성화 또는 비활성화 될 수 있다. 일부 실시예에서, 도 14에 도시된 바와 같이, 어드레스 버스와 데이터 버스는 서로 각각의 버스에 병렬로 연결된 로직 블록의 반대편에 있을 수 있다. 이로써, 서로 다른 온칩 요소의 라우팅이 로직 블록 세트 에 의해 가능해질 수 있다. 일부 실시예에서, 복수의 비활성화 스위치의 각각은 복수의 프라이머리 로직 블록의 적어도 하나를 클럭 노드와 결합하고, 복수의 활성화 스위치의 각각은 복수의 리던던트 블록의 적어도 하나를 클럭 노드와 결 합하여 클럭을 단순 활성화/비활성화 메커니즘으로 연결/해제할 수 있게 한다. 리던던트 로직 블록 세트의 리던던트 비즈니스 로직은 설계자가 복제할 가치가 있는 블록을 면적과 라우팅에 의거하여 선택할 수 있게 해준다. 예를 들어, 칩 설계자는 블록의 면적이 클수록 오류가 날 가능성이 높으므로 면적이 큰 블록을 복제하기로 선택할 수 있다. 따라서, 칩 설계자는 면적이 큰 로직 블록을 복제하기 로 결정할 수 있다. 반면, 설계자는 면적이 작은 블록은 공간의 상당한 손실 없이도 쉽게 복제가 되기 때문에 면적이 작은 블록의 복제를 선호할 수도 있다. 또한, 도 14의 구성을 활용하여, 설계자는 면적당 오류의 통계에 따라 로직 블록의 복제를 쉽게 선택할 수도 있다. 도 15는 개시된 실시예에 따른 예시적인 로직 블록의 구성도이다. 로직 블록은 비즈니스 로직 블록 및/또는 리던던트 비즈니스 로직 블록일 수 있다. 그러나 다른 실시예에서, 예시적인 로직 블록은 메모리 로직 또는 메모리 칩의 기타 요소일 수도 있다. 로직 블록은 작은 프로세서 파이프라인 이내에서 로직 중복성이 사용되는 또 다른 실시예를 제시한다. 로 직 블록은 레지스터, 페치(fetch) 회로, 디코더, 및 라이트백(write-back) 회로 를 포함할 수 있다. 또한, 로직 블록은 계산부 및 복제 계산부를 포함할 수 있다. 그 러나 다른 실시예에서, 로직 블록은 컨트롤러 파이프라인을 포함하지 않지만 요구되는 비즈니스 로직이 있는 산발적 처리 소자를 포함하는 기타 요소를 포함할 수 있다. 계산부와 복제 계산부는 디지털 계산의 수행이 가능한 디지털 회로를 포함할 수 있다. 예를 들어, 계산부와 복제 계산부는 이진수에 대한 산술과 비트 연산을 수행하는 산술논리부(arithmetic logic unit, ALU)를 포함할 수 있다. 또는, 계산부와 복제 계산부는 부동소수점수에 대한 연산을 수행하 는 부동소수점부(floating-point unit, FPU)를 포함할 수 있다. 또한, 일부 실시예에서, 계산부와 복제 계산부는 min, max, count, 및 compare 등과 같은 데이터베이스 관련 함수를 이행할 수 있다. 일부 실시예에서, 도 15에 도시된 바와 같이, 계산부와 복제 계산부는 스위칭 회로(1514, 1516)에 연결될 수 있다. 스위칭 회로는 활성화되는 경우에 계산부를 활성화 또는 비활성화 할 수 있다. 로직 블록에서, 복제 계산부는 계산부의 복제일 수 있다. 또한, 일부 실시예에서, 레지스터 , 페치 회로, 디코더, 및 라이트백 회로는(집합적으로 '로컬 논리부'라 칭함) 계산부 보다 크기가 작을 수 있다. 소자의 크기가 클수록 제조 과정에서 문제가 발생할 가능성이 크므로, 설계자 는 크기가 작은 요소(예, 로컬 논리부)보다는 크기가 큰 요소(예, 계산부)를 복제하기로 결정할 수 있다. 그러나 수율과 오류율의 기록에 따라, 설계자는 크기가 큰 요소에 추가적으로 또는 대안적으로 로컬 논리부를 (또는 전체 블록을) 복제하기로 선택할 수도 있다. 예를 들어, 계산부는 레지스터, 페치 회로 , 디코더, 및 라이트백 회로보다 크기가 클 수 있고, 따라서 오류 가능성이 높을 수 있다. 설계자는 로직 블록의 다른 요소보다는 계산부 또는 전체 블록을 복제하기로 선택할 수 있다. 로직 블록은 계산부와 복제 계산부의 적어도 하나에 각각 연결되는 복수의 로컬 설정 스위치 를 포함할 수 있다. 로컬 설정 스위치는 계산부에 결함이 검출되는 경우에 계산부를 비활성화 하고 복제 계산부를 활성화하도록 설정될 수 있다. 도 16은 개시된 실시예에 따른 버스로 연결된 예시적인 로직 블록의 구성도이다. 일부 실시예에서, 로직 블록 (예, 메모리 로직, 비즈니스 로직, 또는 리던던트 비즈니스 로직)은 서로 별개일 수 있고, 버스를 통해 연결될 수 있고, 외부에서 구체적으로 어드레스 함으로써 활성화될 수 있다. 예를 들어, 메 모리 칩은 각각의 ID 번호를 가진 여러 로직 블록을 포함할 수 있다. 그러나 다른 실시예에서, 로직 블록 은 메모리 로직, 비즈니스 로직, 및 리던던트 비즈니스 로직의 하나 이상이 포함된 더 큰 요소를 나타내는 것일 수 있다. 일부 실시예에서, 로직 블록의 각각은 다른 로직 블록과 중복될 수 있다. 모든 블록이 프라이머리 블록 또는 리던던트 블록으로 동작할 수 있는 이러한 완전한 중복성으로 인해 설계자는 칩의 전체적인 기능은 유지하면서 결함이 있는 요소의 연결을 해제할 수 있기 때문에 제조 수율을 향상할 수 있다. 예를 들어, 모든 복제 블록이 동일한 어드레스와 데이터 버스에 연결될 수 있기 때문에 설계자는 오류가 날 가능성이 높은 논리 영역은 비활성화 하면서 유사한 계산 능력을 유지할 능력이 있을 수 있다. 예를 들어, 로직 블록의 초기 수는 목표 능력보다 클 수 있다. 이후, 일부 로직 블록을 비활성화 해도 목표 능력에 영향을 주지 않을 수 있다. 로직 블록에 연결된 버스는 어드레스 버스, 명령 라인, 및 데이터 라인을 포함할 수 있다. 도 16에 도시된 바와 같이, 로직 블록의 각각은 버스의 각 라인과 별개로 연결될 수 있다. 그러나 특정 실시예 에서, 로직 블록은 체계적 구조로 연결되어 라우팅을 가능하게 할 수 있다. 예를 들어, 버스의 각 라인은라인을 다른 로직 블록으로 라우팅하는 멀티플렉서로 연결될 수 있다. 일부 실시예에서, 소자의 활성화/비활성화로 인해 변경될 수 있는 칩의 내부 구조를 몰라도 외부에서의 접근을 가능하게 하기 위하여, 로직 블록의 각각은 퓨즈드(fused) ID와 같은 퓨즈드 ID를 포함할 수 있다. 퓨즈 드 ID는 ID를 판단하고 관리 회로에 연결될 수 있는 스위치(예, 퓨즈)의 어레이를 포함할 수 있다. 예를 들어, 퓨즈드 ID는 어드레스 매니저에 연결될 수 있다. 또는, 퓨즈드 ID는 높은 계층의 메모 리 어드레스 유닛에 연결될 수 있다. 이러한 실시예에서, 퓨즈드 ID는 특정 어드레스로 설정될 수 있다. 예를 들어, 퓨즈드 ID는 관리 회로로부터 수신된 명령에 의거하여 최종 ID를 판단하는 프로그램 가능 비 휘발성 장치를 포함할 수 있다. 메모리 칩 상의 분산 프로세서는 도 16에 도시된 구성으로 설계될 수 있다. 칩 웨이크업(chip wakeup) 또는 공 장 검사 단계에서 BIST로서 실행되는 검사 절차는 검사 프로토콜에 합격하는 복수의 프라이머리 로직 블록(메모 리 로직 및 비즈니스 로직)의 블록에 실행 ID 번호를 배정할 수 있다. 검사 절차는 또한 검사 프로 토콜에 불합격하는 복수의 프라이머리 로직 블록의 블록에 불법 ID 번호를 배정할 수 있다. 검사 절차는 또한 검사 프로토콜에 합격하는 복수의 리던던트 블록(리던던트 로직 블록)의 블록에 실행 ID 번호를 배정할 수 있다. 리던던트 블록이 불합격하는 프라이머리 로직 블록을 대체하기 때문에, 실행 ID 번호가 배정된 복수의 리던던트 블록의 블록은 불법 ID 번호가 배정된 복수의 프라이머리 로직 블록의 블록보다 크거나 같을 수 있고, 이에 따라 블록이 비활성화 된다. 또한, 복수의 프라이머리 로직 블록의 각각과 복수의 리던던트 블록의 각각은 적어도 하나의 퓨즈드 ID를 포함할 수 있다. 또한, 도 16에 도시된 바와 같이, 로직 블록을 연결하 는 버스는 명령 라인, 데이터 라인, 및 어드레스 라인을 포함할 수 있다. 그러나 다른 실시예에서, 버스에 연결된 모든 로직 블록은 비활성화 상태로 ID 번호 없이 시작할 것이다. 하나씩 검사하여, 양호한 각 블록에는 실행 ID가 부여되고, 작동하지 않는 로직 블록에는 불법 ID가 남아있고 비활성화 될 것이다. 이런 식으로, 리던던트 로직 블록은 결함이 있는 것으로 알려진 블록을 검사 과정에서 대 체함으로써 제조 수율을 향상할 수 있다. 어드레스 버스는 관리 회로를 복수의 메모리 뱅크의 각각, 복수의 프라이머리 로직 블록의 각각, 및 복수 의 리던던트 블록의 각각에 결합할 수 있다. 이러한 연결로 인해, 프라이머리 로직 블록과 연관된 결함을 검출 하면, 관리 회로는 유효하지 않은 어드레스를 복수의 프라이머리 로직 블록의 하나에 배정하고 유효한 어드레스 를 복수의 리던던트 블록의 하나에 배정할 수 있다. 예를 들어, 도 16의 A)에 도시된 바와 같이, 불법 ID(예, 어드레스 0xFFF)가 모든 로직 블록(1602(a)-(c))에 설 정될 수 있다. 검사 후에, 로직 블록 1602(a)와 1602(c)는 제대로 기능하는 것으로 확인되고 로직 블록 1602 (b)는 기능에 문제가 있는 것으로 확인된다. 도 16의 A)에서, 음영 처리하지 않은 로직 블록은 기능 검사에 합 격한 로직 블록을 나타내고 음영 처리한 로직 블록은 기능 검사에 불합격한 로직 블록을 나타내는 것일 수 있다. 이후, 검사 절차는 제대로 기능하는 로직 블록에 대한 불법 ID를 합법 ID로 변경하고 기능에 문제가 있는 로직 블록에 대한 불법 ID는 그대로 유지한다. 예를 들면, 도 16의 A)에서, 로직 블록 1602(a)와 1602(c)에 대 한 어드레스는 각각 0xFFF에서 0x001과 0x002로 변경된다. 반면에, 로직 블록 1602(b)에 대한 어드레스는 불법 어드레스 0xFFF로 유지된다. 일부 실시예에서, ID는 상응하는 퓨즈드 ID을 프로그램하여 변경된다. 로직 블록의 검사 결과가 다르면 설정도 다를 수 있다. 예를 들어, 도 16의 B)에 도시된 바와 같이, 어드 레스 매니저는 초기에 모든 로직 블록에 불법 ID(즉, 0xFFF )를 배정할 수 있다. 그러나 검사의 결 과, 로직 블록 1602(a)와 1602(b) 모두 정상적으로 기능하는 것으로 나타날 수 있다. 이 경우, 메모리 칩(130 0)은 두 개의 로직 블록만 있어도 되기 때문에, 로직 블록 1602(c)의 검사는 불필요할 수 있다. 따라서, 검사에 들어가는 리소스를 최소화하기 위하여, 메모리 칩의 제품 정의에 의해 요구되는 기능하는 로직 블록의 최 소 수량에 따라서만 로직 블록이 검사하고 다른 블록은 검사하지 않을 수 있다. 도 16의 B)에서, 음영 처리하지 않은 로직 블록은 기능성 검사에 합격한 로직 블록을 나타내고, 음영 처리한 로직 블록은 검사하지 않은 로직 블록을 나타낸다. 이러한 실시예에서, 생산 테스터(외장 또는 내장, 자동 또는 수동) 또는 스타트업에서 BIST를 실행하는 제어기 는 검사를 통해 기능하는 것으로 판명된 로직 블록에 대해 불법 ID를 실행 ID로 변경하고 검사하지 않은 로직 블록은 불법 ID를 변경하지 않을 수 있다. 예를 들면, 도 16의 B)에서, 로직 블록 1602(a)와 1602(b)의 어드레 스는 각각 0xFFF에서 0x001과 0x002로 변경된다. 반면, 검사하지 않은 로직 블록 1602(c)에 대한 어드레스는 불 법 어드레스 0xFFF를 유지한다.도 17은 개시된 실시예에 따른 직렬로 연결된 예시적인 소자(1702, 1712)의 구성도이다. 도 17은 전체 시스템 또는 칩을 도시한 것일 수 있다. 또는, 도 17은 다른 기능 블록을 포함하는 칩 내부의 블록을 도시한 것일 수 있다. 소자(1702, 1712)는 메모리 로직 및/또는 비즈니스 로직과 같은 복수의 로직 블록을 포함하는 전체 소자를 나타내는 것일 수 있다. 이런 실시예에서, 소자(1702, 1712)는 또한 어드레스 매니저와 같이 동작 을 수행하기 위해 필요한 요소를 포함할 수 있다. 그러나 다른 실시예에서, 소자(1702, 1712)는 비즈니스 로직 또는 리던던트 비즈니스 로직과 같은 논리 소자를 나타내는 것일 수 있다. 도 17은 소자(1702, 1712)가 서로 통신할 필요가 있을 수 있는 실시예를 제시한다. 이런 경우, 소자(1702, 1712)는 직렬로 연결될 수 있다. 그러나 작동하지 않는 소자가 로직 블록 사이의 연결성을 막을 수 있다. 따라 서, 소자 사이의 연결은 소자가 결함으로 인해 비활성화 되어야 할 필요가 있는 경우를 대비하여 우회 옵션을 포함할 수 있다. 우회 옵션은 또한 우회된 소자 자체의 일부일 수 있다. 도 17에서, 소자는 직렬로 연결될 수 있고(예, 1702(a)-(c)), 불합격 소자(예, 1702(b))는 결함 시에 우회될 수 있다. 소자는 스위칭 회로와 병렬도 더 연결될 수 있다. 예를 들어, 일부 실시예에서, 도 17에 도시된 바와 같 이, 소자(1702, 1712)는 스위칭 회로(1722, 1728)와 연결될 수 있다. 도 17에 도시된 예에서, 소자(1702(b))는 결함이 있다. 예를 들어, 소자(1702(b))는 회로 기능 검사에서 불합격이다. 따라서, 소자(1702(b))는 활성화 스 위치(1314; 도 17에 미도시) 등을 활용하여 비활성화 될 수 있고/있거나 스위칭 회로(1722(b))가 활성화되어 소 자(1702(b))를 우회하고 로직 블록 사이의 연결성을 유지할 수 있다. 이에 따라, 복수의 프라이머리 소자가 직렬로 연결된 경우, 복수의 소자의 각각은 병렬 스위치와 병렬로 연결될 수 있다. 복수의 소자의 하나와 연관된 결함이 검출되면, 복수의 소자의 하나와 연결된 병렬 스위치가 활성화되 어 복수의 소자의 두 소자를 서로 연결할 수 있다. 다른 실시예에서, 도 17에 도시된 바와 같이, 스위칭 회로는 사이클을 지연시켜서 소자의 서로 다른 라인 사이의 동기화를 유지하는 하나 이상의 샘플링 포인트를 포함할 수 있다. 어떤 소자가 비활성화 된 경우에, 인 접 로직 블록 사이의 연결을 차단하면 다른 계산과의 동기화 오류가 발생할 수 있다. 예를 들어, 어떤 작업이 A 라인과 B 라인 모두로부터 데이터를 필요로 하고, A 라인과 B 라인은 각각 서로 별개의 일련의 소자에 의해 수 행되는 경우에, 한 소자를 비활성화 하면 A 라인과 B 라인 사이의 비동기화가 발생할 것이고 이에 따라 추가적 인 데이터 관리가 필요할 것이다. 비동기화를 방지하기 위하여, 샘플 회로는 비활성화 된 소자(1712(b)) 에 의해 유발된 지연을 시뮬레이션 할 수 있다. 그러나 일부 실시예에서, 병렬 스위치는 샘플링 회로 대 신에 안티퓨즈를 포함할 수 있다. 도 18은 개시된 실시예에 따른 2차원 어레이로 연결된 예시적인 소자의 구성도이다. 도 18은 전체 시스템 또는 칩을 나타내는 것일 수 있다. 또는, 도 18은 다른 기능 블록을 포함하는 칩 내부의 블록을 도시한 것일 수 있다. 소자는 메모리 로직 및/또는 비즈니스 로직과 같은 복수의 로직 블록을 포함하는 자율 소자 (autonomous unit)를 나타내는 것일 수 있다. 그러나 다른 실시예에서, 소자는 비즈니스 로직과 같 은 논리 소자를 나타내는 것일 수 있다. 설명의 편의상, 도 18의 설명은 앞서 도 13에 설명한 요소(예, 메모리 칩)를 참조할 수 있다. 도 18에 도시된 바와 같이, 소자는 소자(메모리 로직, 비즈니스 로직, 및 리던던트 비즈니스 로직의 하나 이상을 포함하거나 나타낼 수 있음)가 스위칭 박스 및 연결 박스를 통해 서로 연결된 2차원 어레이로 배치될 수 있다. 또한, 2차원 어레이의 설정을 제어하기 위하여, 2차원 어레이는 주변에 I/O 블록을 포함할 수 있다. 연결 박스는 I/O 블록으로부터 입력되는 신호에 대응할 수 있는 프로그램 가능 및 재구성 가능 장 치일 수 있다. 예를 들어, 연결 박스는 소자로부터의 복수의 입력 핀을 포함할 수 있고, 또한 스위칭 박 스로 연결될 수 있다. 또는, 연결 박스는 프로그램 가능 로직 셀의 핀을 라우팅 트랙과 연결하는 한 그룹의 스위치를 포함할 수 있고, 스위칭 박스는 서로 다른 트랙을 연결하는 한 그룹의 스위치를 포함 할 수 있다. 일부 실시예에서, 연결 박스와 스위칭 박스는 스위치(1312, 1314)와 같은 설정 스위치로 구현될 수 있다. 이러한 실시예에서, 연결 박스와 스위칭 박스는 칩 스타트업에 실행되는 BIST 또는 생산 테스터에 의해 설정될 수 있다. 일부 실시예에서, 연결 박스와 스위칭 박스는 소자에 대한 회로 기능 검사 후에 설정될 수 있다. 이런 실시예에서, I/O 블록을 사용하여 검사 신호를 소자에 전송할 수 있다. 검사 결과에 따 라, I/O 블록은 검사 프로토콜에 불합격하는 소자를 비활성화 하고 검사 프로토콜에 합격하는 소자 를 활성화하는 방식으로 연결 박스와 스위칭 박스를 설정하는 프로그래밍 신호를 전송할 수 있다. 이러한 실시예에서, 복수의 프라이머리 로직 블록과 복수의 리던던트 블록은 2차원 그리드(grid)로 기판 상에 배치될 수 있다. 따라서, 복수의 프라이머리 소자의 각 소자와 리던던트 비즈니스 로직과 같은 복 수의 리던던트 블록의 각 블록은 스위칭 박스로 서로 연결될 수 있고, 입력 블록은 2차원 그리드의 각 라 인과 각 열의 주변에 배치될 수 있다. 도 19는 개시된 실시예에 따른 복합 연결된 예시적인 소자의 구성도이다. 도 19는 전체 시스템을 나타내는 것일 수 있다. 또는, 도 19는 다른 기능 블록을 포함하는 칩 내부의 블록을 도시한 것일 수 있다. 도 19의 복합 연결은 소자(1902(a)-(f))와 설정 스위치(1904(a)-(h))를 포함한다. 소자는 메모리 로직 및/또는 비즈니스 로직과 같은 복수의 로직 블록을 포함하는 자율 소자를 나타내는 것일 수 있다. 그러나 다른 실시예에서, 소자는 메모리 로직, 비즈니스 로직, 또는 리던던트 비즈니스 로직 과 같은 로직 소자를 나타내는 것일 수 있다. 설정 스위치는 비활성화 스위치와 활성화 스위 치 중의 하나 이상을 포함할 수 있다. 도 19에 도시된 바와 같이, 복합 연결은 두 면에 있는 소자를 포함할 수 있다. 예를 들어, 복합 연결은 z 축을 따라 이격된 두 개의 개별적인 기판을 포함할 수 있다. 대안적으로 또는 추가적으로, 소자는 기판의 두 면에 배치될 수 있다. 예를 들어, 메모리 칩의 면적을 줄이려는 목적으로, 기판은 중첩하는 두 면에 배치될 수 있고, 3차원으로 배치된 설정 스위치로 연결될 수 있다. 설정 스위치는 비활성화 스위치 및/또는 활성화 스위치를 포함할 수 있다. 기판의 제1 면은 '메인' 소자를 포함할 수 있다. 이 블록은 디폴트로 활성화될 수 있다. 이러한 실시예에 서, 제2면은 '리던던트' 소자를 포함할 수 있다. 이 소자는 디폴트로 비활성화 될 수 있다. 일부실시예에서, 설정 스위치는 안티퓨즈를 포함할 수 있다. 따라서, 소자의 검사 후에, 특정 안티 퓨즈를 '상시 온(always-on)' 상태로 스위칭하고 선택된 소자를 비활성화함으로써 블록이 서로 다른 면에 있더라도 기능 소자의 타일로 연결될 수 있다. 도 19에 도시된 예에서, '메인' 소자의 하나(1902(e))는 고장이 다. 도 19에서, 기능에 문제가 있거나 검사하지 않은 블록은 음영 처리로 표시되고, 검사도 하고 기능에 문제가 없는 블록은 음영 처리하지 않은 상태로 표시될 수 있다. 따라서, 설정 스위치는 서로 다른 면에 있는 로 직 블록의 하나(예, 1902(f))가 활성화되도록 설정될 수 있다. 이로써, 메인 로직 블록의 하나에 결함이 있더라 도, 여분의 논리 소자로 대체함으로써 메모리 칩이 여전히 기능을 한다. 또한, 도 19에서, 메인 로직 블록이 기능을 하기 때문에, 제2면에 있는 소자의 하나(1902(c))가 검사를 받지 않았고 활성화되지 않았다. 예를 들어, 도 19에서, 메인 소자1902(a)와 1902(d)는 모두 기능 검사에 합격 했다. 따라서, 소자(1902(c))는 검사를 받거나 활성화되지 않았다. 따라서, 도 19는 검사 결과에 따라 활성화되 는 로직 블록을 구체적으로 선택하는 능력을 도시한다. 일부 실시예에서, 도 19에 도시된 바와 같이, 제1면에 있는 모든 소자에 상응하는 여분 또는 리던던트 블 록이 있는 것이 아니다. 그러나 다른 실시예에서, 모든 소자가 프라이머리와 리던던트 모두에 해당하는 경우에 모든 소자는 서로에 대해 리던던트가 됨으로써 완벽한 중복성을 가질 수 있다. 또한, 일부에서는 도 19에 도시 된 방사형 네트워크(star network)로 구현되지만, 병렬 연결, 직렬 연결, 및/또는 서로 다른 요소를 설정 스위 치로 병렬 또는 직렬로 연결하는 구현도 가능하다. 도 20은 개시된 실시예에 따른 리던던트 블록 활성화 프로세스를 도시한 예시적인 순서도이다. 활성화 프 로세스는 메모리 칩, 특히 DRAM 메모리 칩에 대해 이행될 수 있다. 일부 실시예에서, 프로세스 는 메모리 칩의 기판 상에 배치된 복수의 로직 블록의 각 블록에 대해 적어도 하나의 회로 기능을 검사하 는 단계, 검사의 결과에 의거하여 복수의 프라이머리 로직 블록에서 결함이 있는 로직 블록을 식별하는 단계, 메모리 칩의 기판 상에 배치된 적어도 하나의 리던던트 또는 추가 로직 블록에 대해 적어도 하나의 회로 기능을 검사하는 단계, 외부 신호를 비활성화 스위치에 인가하여 적어도 하나의 결함이 있는 로직 블록을 비활성화 하 는 단계, 및 외부 신호를 활성화 스위치에 인가하여 적어도 하나의 리던던트 블록을 활성화하는 단계를 포함할수 있다. 여기서, 활성화 스위치는 적어도 하나의 리던던트 블록과 연결될 수 있고, 메모리 칩의 기판 상에 배 치될 수 있다. 하기의 도 20의 설명에서 프로세스의 각 단계에 대해 더 설명한다. 프로세스는 비즈니스 블록과 복수의 리던던트 블록(예, 리던던트 비즈니스 블록)과 같은 복 수의 로직 블록을 검사하는 단계(단계 2002)를 포함할 수 있다. 검사는 온웨이퍼(on-wafer) 검사를 위한 프로빙 스테이션(probing station) 등을 활용한 패키징(packaging) 이전에 수행될 수 있다. 그런, 프로세스는 패키징 이후에 수행될 수도 있다. 단계 2002의 검사는 유한 시퀀스의 검사 신호를 메모리 칩의 모든 로직 블록 또는 메모리 칩의 로 직 블록의 서브세트에 인가하는 단계를 포함할 수 있다. 검사 신호는 0 또는 1을 출력할 것으로 예상되는 계산 을 요청할 수 있다. 다른 실시예에서, 검사 신호는 메모리 뱅크의 특정 어드레스를 읽거나 특정 메모리 뱅크에 쓰기를 요청할 수 있다. 단계 2002의 반복 프로세스 하에서 로직 블록의 반응을 검사하기 위해 검사 방식이 이행될 수 있다. 예를 들어, 메모리 뱅크에 데이터를 쓰도록 하는 명령을 전송한 후에 기록한 데이터의 무결성을 검증하여 로직 블록을 검사 할 수 있다. 다른 실시예에서, 데이터를 역으로 하여 알고리즘을 반복하여 검사할 수 있다. 다른 실시예에서, 단계 2002의 검사는 로직 블록의 모델을 실행하여 검사 명령의 세트에 의거하여 타깃 메모리 이미지를 생성하는 단계를 포함할 수 있다. 이후, 메모리 칩의 로직 블록에 명령의 동일한 시퀀스가 실행되고, 그 결과가 기록될 수 있다. 시뮬레이션의 잔존하는 메모리 이미지는 또한 검사에서 확보된 이미지와 비교될 수 있고, 불일치에는 불합격의 플래그가 붙여질 수 있다. 또는, 단계 2002에서, 검사는 셰도우 모델링(shadow modeling)을 포함할 수 있고, 여기서, 진단은 생성되지만 결과를 반드시 예측하지는 않는다. 오히려, 셰도우 모델링을 활용한 검사는 메모리 칩과 시뮬레이션에서 병렬로 실행될 수 있다. 예를 들어, 메모리 칩의 로직 블록이 명령 또는 작업을 완수하는 경우, 동일한 명령을 실행하 라는 신호를 시뮬레이션에 보낼 수 있다. 메모리 칩의 로직 블록이 명령을 완수하면, 두 모델의 아키텍처 상태 를 비교한다. 여기에 불일치가 있으면, 불합격 플래그가 붙는다. 일부 실시예에서, 단계 2002에서 모든 로직 블록(메모리 로직, 비즈니스 로직, 및 리던던트 비즈니 스 로직의 각각 등을 포함)을 검사할 수 있다. 그러나 다른 실시예에서, 서로 다른 차수의 검사에서 로직 블록의 서브세트만을 검사할 수도 있다. 예를 들어, 1차 검사에서는 메모리 로직과 그 연관 블록만을 검 사할 수 있다. 2차 검사에서는 비즈니스 로직과 그 연관 블록만을 검사할 수 있다. 3차 검사에서는 앞선 2번의 검사의 결과에 따라 리던던트 비즈니스 로직과 연관된 로직 블록을 검사할 수 있다. 프로세스는 단계 2004로 진행할 수 있다. 단계 2004에서, 결함이 있는 로직 블록이 식별되고, 결함이 있 는 리던던트 블록도 식별될 수 있다. 예를 들어, 단계 2002의 검사에 불합격하는 로직 블록이 단계 2004에서 결 함이 있는 블록으로 식별될 수 있다. 그러나 다른 실시예에서, 결함이 있는 특정 블록 만이 초기에 식별될 수 있다. 예를 들어, 일부 실시예에서, 비즈니스 로직과 연관된 로직 블록만이 식별될 수 있고, 리던던트 로 직 블록이 결함이 있는 로직 블록을 대체해야 하는 경우에만 결함이 있는 리던던트 로직 블록이 식별될 수 있다. 또한, 결함이 있는 로직 블록을 식별하는 단계는 식별된 결함이 있는 로직 블록의 식별 정보를 메모리 뱅 크 또는 비휘발성 메모리에 기록하는 단계를 포함할 수 있다. 단계 2006에서, 결함이 있는 로직 블록이 비활성화 될 수 있다. 예를 들어, 설정 회로를 사용하여, 결함이 있는 로직 블록을 클럭, 접지, 및/또는 전원 노드로부터 연결 해제함으로써 결함이 있는 로직 블록이 비활성화 될 수 있다. 또는, 로직 블록을 회피하는 배치로 연결 박스를 설정함으로써 결함이 있는 로직 블록이 비활성화 될 수 있다. 또한, 다른 실시예에서, 어드레스 매니저로부터 불법 어드레스를 수신함으로써 결함이 있는 로직 블록이 비활성화 될 수 있다. 단계 2008에서, 결함이 있는 로직 블록을 복제하는 리던던트 블록이 식별될 수 있다. 일부 로직 블록에 결함이 있더라도 메모리 칩의 능력을 유지하기 위하여, 단계 2008에서, 결함이 있는 로직 블록을 복제할 수 있고 사용 가능한 리던던트 블록을 식별할 수 있다. 예를 들어, 벡터 곱셈을 수행하는 로직 블록이 결함이 있는 것으로 판 단되는 경우, 단계 2008에서, 어드레스 매니저 또는 온칩 컨트롤러는 역시 벡터 곱셈을 수행하는 사용 가 능한 리던던트 로직 블록을 식별할 수 있다. 단계 2010에서, 단계 2008에서 식별된 리던던트 블록이 활성화될 수 있다. 단계 2006의 비활성화 동작에 반하여, 단계 2010에서는, 식별된 리던던트 블록을 클럭, 접지, 및/또는 전원 노드에 연결함으로써 식별된 리던 던트 블록이 활성화될 수 있다. 또는, 식별된 리던던트 블록을 연결하는 배치로 연결 박스를 설정함으로써, 식별된 리던던트 블록이 활성화될 수 있다. 또한, 다른 실시예에서, 검사 절차 실행 타임에 실행 어드레스를 수신 함으로써, 식별된 리던던트 블록이 활성화될 수 있다. 도 21은 개시된 실시예에 따른 어드레스 배정 프로세스를 도시한 예시적인 순서도이다. 어드레스 배정 프 로세스는 메모리 칩, 특히 DRAM 메모리 칩에 대해 이행될 수 있다. 도 16을 참조하여 설명한 바와 같이, 일부 실시예에서, 메모리 칩의 로직 블록은 데이터 버스에 연결될 수 있고 어드레스 ID를 포함할 수 있다. 프로세스는 결함이 있는 로직 블록을 비활성화 하고 검사에 합격하는 로직 블록을 활성화하는 어드레스 배정 방법을 제공한다. 프로세스의 단계들은 칩 스타트업에 실행되는 BIST 또는 생산 테스터에 의해 수행되는 것으로 설명되지만, 메모리 칩의 다른 요소 및/또는 외부 장치도 프로세스의 하나 이상의 단계를 수행할 수 있다. 단계 2102에서, 테스터는 칩 레벨의 각 로직 블록에 불법 ID를 배정함으로써 모든 로직 블록과 리던던트 블록을 비활성화 할 수 있다. 단계 2104에서, 테스터는 로직 블록의 검사 프로토콜을 실행할 수 있다. 예를 들어, 테스터는 메모리 칩 의 로직 블록의 하나 이상에 대해 단계 2002에서 설명한 검사 방법을 실행할 수 있다. 단계 2106에서, 단계 2104의 검사의 결과에 따라, 테스터는 로직 블록에 결함이 있는지 여부를 판단할 수 있다. 로직 블록에 결함이 없는 경우(단계 2106에서 '아니오'), 어드레스 매니저는 단계 2108에서 실행 ID를 검사된 로직 블록에 배정할 수 있다. 로직 블록에 결함이 있는 경우(단계 2106에서 '예'), 어드레스 매니저는 단 계 2110에서 결함이 있는 로직 블록에 불법 ID를 남겨둘 수 있다. 단계 2112에서, 어드레스 매니저는 결함이 있는 로직 블록을 복제하는 리던던트 로직 블록을 선택할 수 있다. 일부 실시예에서, 결함이 있는 로직 블록을 복제하는 리던던트 로직 블록에는 결함이 있는 로직 블록과 동일한 요소 및 연결이 있을 수 있다. 그러나 다른 실시예에서, 리던던트 로직 블록은 결함이 있는 로직 블록과 다른 요소 및/또는 연결을 포함하지만 균등한 동작을 수행할 수 있을 수 있다. 예를 들어, 결함이 있는 로직 블 록이 벡터 곱셈을 수행하도록 설계된 경우, 선택된 리던던트 로직 블록도 결함이 있는 로직 블록과 동일한 아키 텍처가 아니더라도 벡터 곱셈을 수행할 수 있을 수 있다. 단계 2114에서, 어드레스 매니저는 리던던트 블록을 검사할 수 있다. 예를 들어, 테스터는 단계 2104에 적용된 검사 방식을 식별된 리던던트 블록에 적용할 수 있다. 단계 2116에서, 단계 2114의 검사의 결과에 의거하여, 테스터는 리던던트 블록에 결함이 있는지 여부를 판단할 수 있다. 단계 2118에서, 리던던트 블록에 결함이 없는 경우(단계 2116에서 '아니오'), 테스터는 식별된 리던던 트 블록에 실행 ID를 배정할 수 있다. 일부 실시예에서, 프로세스는 단계 2118 이후에 단계 2104로 돌아 가서 메모리 칩의 모든 로직 블록을 검사하는 반복 루프를 구성할 수 있다. 테스터가 리던던트 블록에 결함이 있는 것으로 판단하는 경우(단계 2116에서 '예'), 단계 2120에서, 테스터는 추가 리던던트 블록이 사용 가능한지 여부를 판단할 수 있다. 예를 들어, 테스터는 사용 가능한 리던던트 로직 블록에 관한 정보로 메모리 뱅크에 쿼리를 할 수 있다. 사용 가능한 리던던트 로직 블록이 있는 경우(단계 2120 에서 '예'), 테스터는 단계 2112로 돌아가서 결함이 있는 로직 블록을 복제하는 새로운 리던던트 로직 블록을 식별할 수 있다. 사용 가능한 리던던트 로직 블록이 없는 경우(단계 2120에서 '아니오'), 단계 2122에서, 테스 터는 오류 신호를 생성할 수 있다. 오류 신호는 결함이 있는 로직 블록과 결함이 있는 리던던트 블록의 정보를 포함할 수 있다. 결합된 메모리 뱅크 여기에 개시된 실시예들은 또한, 분산된 고성능 프로세서를 포함한다. 프로세서는 메모리 뱅크와 처리부를 접근 시키는 메모리 컨트롤러를 포함할 수 있다. 프로세서는 데이터가 계산을 위해 처리부에 신속히 전달되도록 구성 될 수 있다. 예를 들어, 작업을 수행하기 위해 처리부가 두 개의 데이터 인스턴스가 필요한 경우, 메모리 컨트 롤러는 통신 라인이 개별적으로 두 데이터 인스턴스로부터의 정보에 대한 접근을 제공할 수 있도록 구성될 수 있다. 개시된 메모리 아키텍처는 복합 캐시 메모리와 복합 레지스터 파일 스키마와 연관된 하드웨어 요구조건을 최소화하고자 한다. 일반적으로, 프로세서 칩은 코어가 레지스터와 직접 작용하도록 하는 캐시 체계를 포함한다. 그러나 캐시 동작은 상당한 다이 면적을 필요로 하고 추가적인 전력을 소비한다. 개시된 메모리 아키 텍처는 메모리에 논리 요소를 추가함으로써 캐시 체계의 사용을 피한다. 개시된 아키텍처는 또한 메모리 뱅크 내에 데이터를 전략적으로(또는 최적화된) 배치할 수 있게 한다. 메모리 뱅크가 단일 포트만을 포함하고 지연이 많은 경우라도, 개시된 메모리 아키텍처는 데이터를 메모리 뱅크의 다른 블록에 전략적으로 배치함으로써 고성능을 가능하게 하고 메모리 병목현상을 방지할 수 있다. 지속적인 데이터 스트림을 처리부로 제공하려는 목적으로, 컴파일 최적화(compilation optimization) 단계는 데이터가 특정 또는 일반 작업에 대해 메모리 뱅크에 저장되어야 하는 방법을 판단할 수 있다. 이후, 처리부와 메모리 뱅크를 접근 시키는 메모리 컨트롤러는 동작을 수행하기 위하여 데이터가 필요한 경우에 특정 처리부에게 접근을 허용하도록 구성될 수 있다. 메모리 칩의 설정은 처리부(예, 설정 매니저) 또는 외부 인터페이스에 의해 수행될 수 있다. 설정은 또한 컴파 일러 또는 기타 소프트웨어 툴에 의해 기록될 수 있다. 또한, 메모리 컨트롤러의 설정은 메모리 뱅크에 사용 가 능한 포트와 메모리 뱅크의 데이터 구조에 의거할 수 있다. 이에 따라, 개시된 아키텍처는 서로 다른 메모리 뱅 크로부터 데이터의 지속적인 흐름 또는 동시 정보를 처리부에 제공할 수 있다. 이로써, 지연 병목현상 또는 캐 시 메모리 요구사항을 회피하여 메모리 이내의 계산 작업이 신속히 처리될 수 있다. 또한, 메모리 칩에 저장된 데이터는 컴파일 최적화 단계에 의거하여 배치될 수 있다. 컴파일은 프로세서가 메모 리 지연이 없는 처리부로 작업을 효율적으로 배정하는 처리 루틴의 구축을 가능하게 할 수 있다. 컴파일은 컴파 일러에 의해 수행되고 기판의 외부 인터페이스와 연결된 호스트로 전송될 수 있다. 일반적으로, 특정 접근 패턴 에 대한 높은 지연 및/또는 적은 수의 포트의 결과는 데이터를 필요로 하는 처리부에 대한 데이터 병목현상이 될 수 있다. 그러나 개시된 컴파일은 불리한 메모리 유형으로도 처리부가 지속적으로 데이터를 수신할 수 있게 메모리 뱅크에 데이터를 배치할 수 있다. 또한, 일부 실시예에서, 설정 매니저는 작업에 요구되는 계산에 의거하여 필요한 처리부에 신호를 보낼 수 있다. 칩의 서로 다른 처리부 또는 로직 블록에는 서로 다른 작업에 대해 특화된 하드웨어 또는 아키텍처가 있 을 수 있다. 따라서, 수행될 작업에 따라, 처리부 또는 처리부의 그룹이 해당 작업을 수행하도록 선택될 수 있 다. 기판 상의 메모리 컨트롤러는 프로세서 서브유닛의 선택에 따라 데이터를 보내거나 접근을 허용하여 데이터 전송 속도를 향상할 수 있다. 예를 들어, 컴파일 최적화와 메모리 아키텍처에 의거하여, 처리부는 작업을 수행 하도록 요구되는 경우에 메모리 뱅크의 접근이 허용될 수 있다. 또한, 칩 아키텍처는 메모리 뱅크의 데이터 접근에 필요한 시간을 단축하여 데이터의 전송을 가능하게 하는 온 칩 요소를 포함할 수 있다. 따라서, 본 개시는 단순한 메모리 인스턴스를 활용하여 특정 또는 일반 작업의 수행 이 가능한 고성능 프로세서에 대한 칩 아키텍처를 컴파일 최적화 단계와 함께 설명한다. 메모리 인스턴스에는 DRAM 장치 또는 기타 메모리 지향 기술에 사용되는 것과 같은 적은 수의 포트 및/또는 높은 지연이 있을 수 있 지만, 개시된 아키텍처는 메모리 뱅크로부터 처리부로의 데이터의 지속적인(또는 거의 지속적인) 흐름을 가능하 게 하여 이러한 단점을 극복할 수 있다. 본 출원에서, 동시 통신이란 클럭 사이클 이내의 통신을 말하는 것일 수 있다. 또는, 동시 통신이란 미리 정해 진 시간 이내에 정보를 전송하는 것을 의미하는 것일 수 있다. 예를 들어, 동시 통신은 몇 나노초(10억분의 몇 초) 이내의 통신을 말하는 것일 수 있다. 도 22는 개시된 실시예에 따른 예시적인 처리 장치에 대한 구성도이다. 도 22의 A)는 메모리 컨트롤러가 멀티플렉서를 활용하여 제1 메모리 블록과 제2 메모리 블록을 연결하는 처리 장치의 제1 실 시예를 도시한 것이다. 메모리 컨트롤러는 또한 적어도 설정 매니저, 로직 블록, 복수의 가 속기(2216(a)-(n))를 연결할 수 있다. 도 22의 B)는 메모리 컨트롤러가 메모리 컨트롤러와 적어도 설정 매니저, 로직 블록, 복수의 가속기(2216(a)-(n))를 연결하는 버스를 활용하여 메모리 블록 (2202, 2204)을 연결하는 처리 장치의 제2 실시예를 도시한 것이다. 또한, 호스트는 외부에 위치할 수 있고 외부 인터페이스 등을 통해 처리 장치에 연결될 수 있다. 메모리 블록(2202, 2204)은 DRAM 매트 또는 매트 그룹, DRAM 뱅크, MRAM\\ PRAM\\ RERAM\\ SRAM 유닛, 플래시 매 트, 또는 기타 메모리 기술을 포함할 수 있다. 메모리 블록(2202, 2204)은 대안적으로 비휘발성 메모리, 플래시 메모리 장치, ReRAM(Resistive Random Access Memory) 장치, 또는 MRAM(Magnetoresistive Random Access Memory) 장치를 포함할 수 있다. 메모리 블록(2202, 2204)은 추가적으로 복수의 워드라인(미도시)과 복수의 비트라인(미도시) 사이에 행과 열로 배치된 복수의 메모리 셀을 포함할 수 있다. 메모리 셀의 각 행의 게이트는 복수의 워드라인 각각에 연결될 수 있다. 메모리 셀의 각 열은 복수의 비트라인 각각에 연결될 수 있다. 다른 실시예에서, 메모리 영역(메모리 블록(2202, 2204) 포함)은 단일 메모리 인스턴스로부터 구성될 수 있다. 본 출원에서, '메모리 인스턴스'라는 용어는 '메모리 블록'과 서로 호환하여 사용될 수 있다. 메모리 인스턴스 (또는 블록)의 특성은 열악할 수 있다. 예를 들어, 메모리에는 포트가 하나밖에 없을 수 있고 랜덤 액세스 지연 이 클 수 있다. 대안적으로 또는 추가적으로, 메모리는 열 및 라인 변경 동안에 접근이 불가능할 수 있고 정정 용량 충전 및/또는 회로 설정 등과 관련된 데이터 접근 문제에 직면할 수 있다. 그러나 도 22에 제시된 아키텍 처는 메모리 인스턴스와 처리부 사이의 전용 연결을 허용하고 블록의 특성을 고려하는 특정 방식으로 데이터를 배치함으로써 메모리 장치의 병렬 처리를 가능하게 한다. 일부 장치 아키텍처에서, 메모리 인스턴스는 여러 포트를 가지고 있어서 병렬 동작이 가능할 수 있다. 그러나 이러한 실시예에서, 칩은 데이터가 칩 아키텍처에 의거하여 컴파일 되고 구성되는 경우에 성능 향상을 이룰 수 있다. 예를 들어, 컴파일러는 단일 포트 메모리를 활용하여도 용이하게 접근될 수 있도록 명령을 제공하여 데이 터 배치를 구성함으로써 메모리 영역의 접근 효율을 향상할 수 있다. 또한, 메모리 블록(2202, 2204)은 단일 칩의 메모리에 대해 다중 유형일 수 있다. 예를 들어, 메모리 블록 (2202, 2204)은 eFlash 및 eDRAM일 수 있다. 또한, 메모리 블록은 ROM의 인스턴스를 가진 DRAM을 포함할 수 있 다. 메모리 컨트롤러는 메모리 접근을 처리하고 그 결과를 나머지 모듈로 전달할 논리 회로를 포함할 수 있다. 예를 들어, 메모리 컨트롤러는 어드레스 매니저 및 멀티플렉서와 같은 선택 장치를 포함하여 데이 터를 메모리 블록과 처리부 사이에 전달하고 메모리 블록으로의 접근을 허용할 수 있다. 대안적으로, 메모리 컨 트롤러는 시스템의 메모리 클럭의 상승 에지(rising edge)와 하강 에지(falling edge)에 데이터가 전송되 는 DDR SDRAM의 구동에 사용되는 DDR(double data rate) 메모리 컨트롤러를 포함할 수 있다. 또한, 메모리 컨트롤러는 듀얼 채널(Dual Channel) 메모리 컨트롤러를 구성할 수 있다. 듀얼 채널 메모리 를 도입하면 메모리 컨트롤러에 의한 병렬 접근의 제어가 가능할 수 있다. 병렬 접근 라인은 다중 라인이 함께 사용되는 경우에 서로 동일한 길이가 데이터의 동기화를 가능하게 하도록 구성될 수 있다. 대안적으로 또 는 추가적으로, 병렬 접근 라인은 메모리 뱅크의 다중 메모리 포트의 접근을 허용할 수 있다. 일부 실시예에서, 처리 장치는 처리부에 연결될 수 있는 하나 이상의 멀티플렉서를 포함할 수 있다. 처리 부는 멀티플렉서에 직접 연결될 수 있는 설정 매니저, 로직 블록, 가속기를 포함할 수 있다. 또한, 메모리 컨트롤러는 복수의 메모리 뱅크 또는 블록으로부터의 적어도 하나의 데이터 입력과 복수의 처리부 각각으로 연결된 적어도 하나의 데이터 출력을 포함할 수 있다. 이러한 구성으로, 메모리 컨트롤 러는 두 개의 데이터 입력을 통하여 메모리 뱅크 또는 블록(2202, 2204)으로부터 동시에 데이터를 수신하 고, 적어도 하나의 선택된 처리부를 통하여 수신된 데이터를 두 개의 데이터 출력을 통하여 동시에 전송할 수 있다. 그러나 일부 실시예에서, 적어도 하나의 데이터 입력과 적어도 하나의 데이터 출력은 읽기 또는 쓰기 동 작만을 허용하는 단일 포트에서 이행될 수 있다. 이러한 실시예에서, 단일 포트는 데이터, 어드레스, 및 명령 라인을 포함하는 데이터 버스로 구현될 수 있다. 메모리 컨트롤러는 복수의 메모리 블록(2202, 2204)의 각각으로 연결될 수 있고, 선택 스위치 등을 통하 여 처리부로도 연결될 수 있다. 또한, 설정 매니저, 로직 블록, 및 가속기를 포함하는 기판 상의 처리부는 메모리 컨트롤러에 개별적으로 연결될 수 있다. 일부 실시예에서, 설정 매니저는 수 행될 작업의 표시를 수신할 수 있고, 이에 대응하여 메모리에 저장되거나 외부에서 제공된 설정에 따라 메모리 컨트롤러, 가속기, 및/또는 로직 블록을 설정할 수 있다. 대안적으로, 메모리 컨트롤러 는 외부 인터페이스에 의해 설정될 수 있다. 작업은 복수의 처리부 중에서 적어도 하나의 처리부를 선택 하는데 사용될 수 있는 적어도 하나의 계산을 필요로 할 수 있다. 대안적으로 또는 추가적으로, 선택은 적어도 하나의 계산을 수행할 수 있는 선택된 처리부의 능력에 적어도 부분적으로의 의거하여 이루어질 수 있다. 이에 대응하여, 메모리 컨트롤러는, 전용 버스를 활용하여 및/또는 파이프라인 된 메모리 접근에서, 메모리 뱅 크에 접근을 허용하거나 적어도 하나의 선택된 처리부와 적어도 두 개의 메모리 뱅크 사이에 데이터를 전달할 수 있다. 일부 실시예에서, 적어도 두 개의 메모리 블록의 제1 메모리 블록은 복수의 처리부의 제1측에 배치될 수 있고, 적어도 두 개의 메모리 블록의 제2 메모리 블록은 제1측의 반대편인 복수의 처리부의 제2측에 배치 될 수 있다. 또한, 작업을 수행할 선택된 처리부, 예를 들어, 가속기(2216(n))는 통신 라인이 제1 메모리 뱅크 또는 제1 메모리 블록에 개방된 클럭 사이클 동안에 제2 메모리 뱅크에 접근하도록 설정될 수 있다. 또는, 선택된 처리부는 통신 라인이 제1 메모리 블록에 개방된 클럭 사이클 동안에 제2 메모리 블 록으로 데이터를 전송하도록 설정될 수 있다.일부 실시예에서, 도 22에 도시된 바와 같이, 메모리 컨트롤러는 개별 요소로 구현될 수 있다. 그러나 다 른 실시예에서, 메모리 컨트롤러는 메모리 영역에 내장되거나 가속기(2216(a)-(n))를 따라 배치될 수 있 다. 처리 장치의 처리 영역은 설정 매니저, 로직 블록 및 가속기(2216(a)-(n))를 포함할 수 있다. 가속기는 기능이 미리 정의된 복수의 처리 회로를 포함할 수 있고 특정 어플리케이션에 의해 정의 될 수 있다. 예를 들어, 가속기는 모듈 사이의 메모리 이동을 취급하는 벡터 MAC 유닛 또는 DMA(Direct Memory Access) 유닛일 수 있다. 가속기는 또한 자체 어드레스를 계산하고 메모리 컨트롤러에 데이터를 요 청하거나 기록할 수 있다. 예를 들어, 설정 매니저는 메모리 뱅크에 접근할 수 있는 가속기의 적어 도 하나에 신호할 수 있다. 이후, 가속기는 메모리 컨트롤러를 설정하여 데이터를 전달하거나 접근 을 허용하도록 할 수 있다. 또한, 가속기는 적어도 하나의 산술 논리부, 적어도 하나의 벡터 처리 논리부, 적어도 하나의 문자열 비교 논리부, 적어도 하나의 레지스터, 및 적어도 하나의 DMA(direct memory access)를 포함할 수 있다. 설정 매니저는 가속기를 설정하고 작업의 실행을 지시하는 디지털 처리 회로를 포함할 수 있다. 예 를 들어, 설정 매니저는 메모리 컨트롤러와 복수의 가속기 각각에 연결될 수 있다. 설정 매 니저에는 가속기의 설정을 저장할 전용 메모리가 있을 수 있다. 설정 매니저는 메모리 뱅크 를 이용하여 메모리 컨트롤러를 통해 명령과 설정을 가져올 수 있다. 또는, 설정 매니저는 외부 인 터페이스를 통하여 프로그램 될 수 있다. 일부 실시예에서, 설정 매니저에는 자체 캐시 체계를 가진 온칩 RISC(reduced instruction set computer) 또는 온칩 복합 CPU가 구현되어 있을 수 있다. 일부 실시예에서, 설 정 매니저가 생략될 수도 있고, 가속기는 외부 인터페이스를 통해 설정될 수 있다. 처리 장치는 또한 외부 인터페이스(미도시)를 포함할 수 있다. 외부 인터페이스는 외부 호스트 또 는 온칩 메인 프로세서로부터 명령을 수신하는 메모리 뱅크 컨트롤러와 같은 상위 레벨로부터 메모리의 접근을 허용하거나 외부 호스트 또는 온칩 메인 프로세서로부터 메모리의 접근을 허용한다. 외부 인터페이스는 나중에 설정 매니저 또는 소자들(2214, 2216)에 의해 사용될 메모리 컨트롤러를 통해 메모리에 설 정 또는 코드를 기록함으로써 설정 매니저와 가속기의 프로그래밍을 허용할 수 있다. 그러나 외부 인터페이스는 또한, 메모리 컨트롤러를 통해 전달되지 않고도 처리부를 직접 프로그램 할 수 있다. 설정 매니저가 마이크로컨트롤러인 경우, 설정 매니저는 외부 인터페이스를 통해 메인 메모리로부터 컨 트롤러 로컬 메모리에 코드의 로딩을 허용할 수 있다. 메모리 컨트롤러는 외부 인터페이스로부터의 요청 수신에 대응하여 작업을 중단하도록 설정될 수 있다. 외부 인터페이스는 처리 장치 상의 다양한 요소에 무접착제 인터페이스를 제공하는 논리 회로와 연관된 복수의 커넥터를 포함할 수 있다. 외부 인터페이스는 데이터 읽기를 위한 데이터 I/O 입력과 데이터 쓰기를 위한 출력, 외부 어드레스 출력, 외부 CE0 칩 선택 핀, 액티브 로우 칩 셀렉터(Active-low chip selectors), 바이트 활성 화 핀, 메모리 사이클 상의 대기 상대에 대한 핀, 쓰기 활성화 핀, 출력 활성화 핀, 및 읽기-쓰기 활성화 핀을 포함할 수 있다. 따라서, 외부 인터페이스에는 프로세스를 제어하고 처리 장치로부터 정보를 확보하는 요청된 입력과 출력이 있다. 예를 들어, 외부 장치는 JEDEC DDR 표준을 준수할 수 있다. 대안적으로 또는 추가적으로, 외부 장치는 SPI\\OSPI 또는 UART와 같은 기타 표준을 준수할 수 있다. 일부 실시예에서, 외부 인터페이스는 칩 기판 상에 배치될 수 있고 외부 호스트와 연결될 수 있다. 외부 호스트는 외부 인터페이스를 통해 메모리 블록(2202, 2204), 메모리 컨트롤러, 및 처리부에 대한 접근을 확보할 수 있다. 추가적으로 또는 대안적으로, 외부 호스트는 메모리에 대한 읽기 및 쓰기를 할 수 있고, 읽기 및 쓰기 명령을 통하여 설정 매니저에게 신호를 보내 프로세스의 개시 및/또는 중단과 같은 동작을 수행하게 할 수 있다. 또한, 외부 호스트는 가속기를 직접 설정할 수 있다. 일부 실시예에서, 외부 호스트는 메모리 블록(2202, 2204) 상에서 직접 읽기/쓰기 동작을 수행할 수 있다. 일부 실시예에서, 설정 매니저와 가속기는 대상 작업에 따라 직접 버스를 사용하여 장치 영역을 메 모리 영역과 연결하도록 설정될 수 있다. 예를 들어, 가속기의 서브세트는 가속기의 서브세트가 작업을 실행하기 위해 필요한 계산을 수행할 능력이 있는 경우에 메모리 인스턴스와 연결할 수 있다. 이러한 분 리를 함으로써, 메모리 블록(2202, 2204)에 필요한 대역폭(BW)이 전용 가속기에 확보되도록 할 수 있다. 또한, 메모리 인스턴스를 메모리 컨트롤러로 연결하면 행 지연 시간이 크더라도 서로 다른 메모리의 데이터에 신속하게 접근할 수 있기 때문에, 전용 버스가 있는 이러한 구성은 용량이 큰 메모리를 작은 인스턴스 또는 블 록으로 나누는 것을 가능하게 할 수 있다. 연결의 병렬화를 하기 위해, 메모리 컨트롤러는 데이터, 어드레스, 및/또는 컨트롤 버스로 메모리 인스턴스의 각각에 연결될 수 있다. 상기에 설명한 바와 같이 메모리 컨트롤러를 포함시키면 처리 장치에 캐시 체계 또는 복합 레지스터 파일 이 없어도 될 수 있다. 캐시 체계를 추가하여 시스템 역량을 강화할 수도 있지만, 처리 장치의 아키텍처 로 인해, 설계자는 처리 동작에 의거하여 충분한 메모리 블록 또는 인스턴스를 추가하고 이에 따라 캐시 체계 없이 인스턴스를 관리할 수 있다. 예를 들어, 처리 장치의 아키텍처로 인해, 파이프라인 된 메모리 접근 을 제거함으로써 캐시 체계가 필요하지 않게 될 수 있다. 파이프라인 된 메모리 접근에서, 처리부는 매 사이클 에 지속적인 데이터 흐름을 수신할 수 있고, 특정 데이터 라인이 개방(또는 활성화)될 수 있는 반면에 다른 데 이터 라인이 데이터를 수신 또는 전송할 수 있다. 개별 통신 라인을 활용한 지속적인 데이터의 흐름으로 인해, 실행 속도는 향상될 수 있고, 라인 변경으로 인한 지연은 최소화될 수 있다. 또한, 도 22의 개시된 아키텍처는 적은 수의 메모리 블록에서 데이터를 구성하고 라인 변경으로 인한 전력 손실 을 줄일 수 있는 파이프라인 된 메모리 접근을 가능하게 한다. 예를 들어, 일부 실시예에서, 컴파일러는 메모리 뱅크의 데이터 구성 또는 데이터 구성 방법을 호스트와 주고받고 주어진 작업 동안에 데이터에 대한 접근 을 가능하게 할 수 있다. 이후, 설정 매니저는 어느 메모리 뱅크가(경우에 따라서는 메모리 뱅크의 어느 포트가) 가속기에 의해 접근될 수 있는지 정의할 수 있다. 메모리 뱅크 내의 데이터 위치와 데이터 접근 방법 사이의 동기화는 데이터를 최소의 지연으로 가속기에 공급함으로써 전산 작업을 개선한다. 예를 들어, 설정 매 니저가 RISC\\CPU를 포함하는 실시예에서, 방법은 오프라인 소프트웨어에서 이행될 수 있고, 이후에 설정 매니저는 상기 방법을 실행하도록 프로그램 될 수 있다. 방법은 RISC\\CPU 컴퓨터에 의해 실행 가능한 모 든 언어로 만들어질 수 있고 모든 플랫폼에서 실행될 수 있다. 방법의 입력은 메모리 컨트롤러 뒤의 메모리의 설정 및 메모리 접근 패턴과 함께 데이터 자체를 포함할 수 있다. 또한, 방법은 해당 실시예에 특정된 언어 또 는 기계어로 구현될 수 있고, 단순히 이진수 또는 문자로 된 일련의 설정값일 수도 있다. 앞서 설명한 바와 같이, 일부 실시예에서, 컴파일러는 파이프라인 된 메모리 접근에 대비하여 데이터를 메모리 블록(2202, 2204)에 구성하기 위해 호스트로 명령을 제공할 수 있다. 파이프라인 된 메모리 접근은 일반 적으로 복수의 메모리 뱅크 또는 메모리 블록(2202, 2204)의 복수의 어드레스를 수신하는 단계, 수신된 어드레 스에 따라 개별 데이터 라인을 사용하여 복수의 메모리 뱅크에 접근하는 단계, 복수의 메모리 뱅크의 제1 메모 리 뱅크 내에 있는 제1 어드레스로부터 제1 통신 라인을 통하여 복수의 처리부의 적어도 하나로 데이터를 공급 하고 복수의 메모리 뱅크의 제2 메모리 뱅크 내에 있는 제2 어드레스로 제2 통신 라인을 개통하는 단계, 및 제2 어드레스로부터 제2 통신 라인을 통하여 복수의 처리부의 적어도 하나로 데이터를 공급하고 제2 클럭 사 이클 이내에 제1 통신 라인의 제1 메모리 뱅크 내의 제3 어드레스로 제3 통신 라인을 개통하는 단계를 포함할 수 있다. 일부 실시예에서, 파이프라인 된 메모리 접근은 단일 포트에 연결된 두 개의 메모리 블록으로 실행될 수 있다. 이러한 실시예에서, 메모리 컨트롤러는 단일 포트 뒤로 메모리 블록을 숨길 수 있지만 파이프라 인 된 메모리 접근 방식으로 처리부에 데이터를 전송할 수 있다. 일부 실시예에서, 컴파일러는 작업을 실행하기 전에 호스트 상에서 실행될 수 있다. 이러한 실시예에서, 컴파일러가 데이터 흐름의 설정을 이미 알고 있을 수 있기 때문에, 컴파일러는 메모리 장치의 아키텍처에 의거 하여 데이터 흐름의 설정을 판단할 수 있을 수 있다. 다른 실시예에서, 오프라인 시간에 메모리 블록(2204, 2202)의 설정을 모르는 경우, 파이프라인 된 방법은 호스 트에서 실행할 수 있고, 호스트는 계산을 시작하기 전에 메모리 블록에 데이터를 배치할 수 있다. 예를 들어, 호스트는 메모리 블록(2204, 2202)에 직접 데이터를 기록할 수 있다. 이러한 실시예에서, 설 정 매니저와 같은 처리부와 메모리 컨트롤러는 필요한 하드웨어에 관한 정보를 런타임까지 모를 수 있다. 이후, 작업의 실행이 시작될 때까지 가속기의 선택을 지연할 필요가 있을 수 있다. 이러한 상황에 서, 처리부 또는 메모리 컨트롤러는 가속기를 무작위로 선택하고, 작업이 실행되면서 수정될 수 있 는 검사 데이터 접근 패턴을 생성할 수 있다. 그러나 작업을 미리 아는 경우, 컴파일러는 데이터와 명령을 메모리 뱅크 내에 배치하여 호스트가 접근 지연을 최소화하는 신호 연결을 설정 매니저와 같은 처리부에 설정하게 할 수 있다. 예를 들어, 일부의 경우, 가속기는 동시에 n 개의 워드를 필요로 할 수 있다. 그러나 각 메모리 인스턴스는 한 번에 m 개의 워드만 가져오는 것을 지원할 수 있다. 여기서, m과 n은 모두 정수이고, m < n 이다. 따라서, 컴파일러는 필 요한 데이터를 서로 다른 메모리 인스턴스 또는 블록에 배치하여 데이터 접근을 가능하게 할 수 있다. 또한, 라 인 누락 지연을 방지하기 위해, 호스트는 처리 장치에 다수의 메모리 인스턴스가 있는 경우에 서로 다른 메모리 인스턴스의 서로 다른 라인에 데이터를 나눌 수 있다. 데이터를 분할하면, 현재의 인스턴스에서 데이터를 계속 사용하면서 다음 인스턴스에 데이터의 다음 라인에 접근하는 것이 가능하다. 예를 들어, 가속기(2216(a))는 두 개의 벡터를 곱하도록 구성될 수 있다. 각 벡터는 메모리 블록(2202, 2204)과 같은 별개의 메모리 블록에 저장될 수 있고, 각 벡터는 다수의 워드를 포함할 수 있다. 따라서, 가속기 (2216(a))에 의한 곱셈을 필요로 하는 작업을 완료하려면, 두 개의 메모리 블록에 접근하고 복수의 워드를 가져 올 필요가 있을 수 있다. 그러나 일부 실시예에서, 메모리 블록은 클럭 사이클 당 하나의 워드만 접근을 허용한 다. 예를 들어, 메모리 블록에는 단일 포트가 있을 수 있다. 이런 경우, 동작 중의 데이터 전송을 빠르게 하기 위해, 컴파일러는 벡터를 구성하는 워드를 서로 다른 메모리 블록에 배치하여 워드의 병렬 및/또는 동시 읽기를 가능하게 할 수 있다. 이런 상황에서, 컴파일러는 전용 라인이 있는 메모리 블록에 워드를 저장할 수 있다. 예 를 들어, 각 벡터가 두 개의 워드를 포함하고 메모리 컨트롤러가 4개의 메모리 블록에 직접 접근이 가능한 경우, 컴파일러는 4개의 메모리 블록에 데이터를 배치하고, 각 메모리 블록은 워드를 전송하고 데이터 전달을 빠르게 할 수 있다. 또한, 메모리 컨트롤러에 각 메모리 블록으로 단일 연결 이상이 있을 수 있는 실시예 에서, 컴파일러는 설정 매니저(또는 다른 처리부)에게 특정 포트로 접근하도록 명령할 수 있다. 이 방법 으로, 처리 장치는 파이프라인 된 메모리 접근을 수행하여, 동시에 일부 라인에서 워드를 로딩하고 다른 라인에서 데이터를 전송함으로써 데이터를 처리부로 지속 제공할 수 있다. 도 23은 개시된 실시예에 따른 예시적인 처리 장치의 구성도이다. 구성도는 MAC 유닛, 설정 매니저 (2304; 설정 매니저와 균등 또는 유사), 메모리 컨트롤러(2306; 메모리 컨트롤러와 균등 또는 유사), 및 복수의 메모리 블록(2308(a)-(d)) 형태의 단일 가속기를 표시하는 단순화된 처리 장치를 도시 한다. 일부 실시예에서, MAC 유닛은 특정 작업을 처리하기 위한 특정 가속기일 수 있다. 예를 들어, 처리 장치 에 2D-컨볼루션 작업이 부여될 수 있다. 이 경우, 설정 매니저는 적절한 하드웨어를 구비한 가속기 에 이 작업과 연관된 계산을 수행하도록 신호를 보낼 수 있다. 예를 들어, MAC 유닛에는 4개의 내부 증가 카운터(internal incrementing counter; 컨볼루션 계산에 필요한 4개의 루프를 관리하기 위한 논리 합산기 (logical adder) 및 레지스터)와 곱셈-누적부(multiply accumulate unit)가 있을 수 있다. 설정 매니저 는 입력되는 데이터를 처리하고 작업을 실행하도록 MAC 유닛에 신호를 보낼 수 있다. 설정 매니저 는 작업을 실행하라는 표시를 MAC 유닛에 전송할 수 있다. 이러한 상황에서, MAC 유닛은 계산된 어 드레스에서 반복하고, 수를 곱하고, 내부 레지스터에 누적할 수 있다. 일부 실시예에서, 메모리 컨트롤러가 전용 버스를 활용하여 블록과 MAC 유닛에 접근을 허용 하는 반면, 설정 매니저는 가속기를 설정할 수 있다. 그러나 다른 실시예에서, 설정 매니저 또는 외부 인터페이스로부터 수신된 명령에 의거하여 메모리 컨트롤러가 직접 가속기를 설정할 수 있다. 대안 적으로 또는 추가적으로, 설정 매니저는 몇 가지 설정을 미리 로드하고 가속기가 서로 다른 크기를 가진 서로 다른 어드레스 상에서 반복적으로 실행하도록 할 수 있다. 이러한 실시예에서, 설정 매니저는 가속 기와 같은 복수의 처리부의 적어도 하나로 명령이 전송되기 전에 명령을 저장하는 캐시 메모리를 포함할 수 있다. 그러나 다른 실시예에서, 설정 매니저는 캐시를 포함하지 않을 수 있다. 일부 실시예에서, 설정 매니저 또는 메모리 컨트롤러는 작업을 위해 접근될 필요가 있는 어드레스 를 수신할 수 있다. 설정 매니저 또는 메모리 컨트롤러는 레지스터를 확인하여 메모리 블록 의 하나에 로드된 라인에 이 어드레스가 이미 있는지 여부를 판단할 수 있다. 이 어드레스가 이미 있는 경우, 메모리 컨트롤러는 메모리 블록으로부터 워드를 읽어서 MAC 유닛으로 전달할 수 있다. 로드 된 라인에 이 어드레스가 없는 경우, 설정 매니저는 메모리 컨트롤러에게 이 라인을 로드하도록 요 청하고 MAC 유닛에게 이 어드레스를 가져올 때까지 대기하라는 신호를 보낼 수 있다. 일부 실시예에서, 도 23에 도시된 바와 같이, 메모리 컨트롤러는 두 개의 개별 어드레스로부터 두 개의 입력을 포함할 수 있다. 그러나 둘 이상의 어드레스에 동시에 접근해야 하고, 이러한 어드레스가 단일 메모리 블록에 있는 경우(예를 들어, 메모리 블록(2308(a))에만 있는 경우), 메모리 컨트롤러 또는 설정 매니저 는 예외를 둘 수 있다. 또는, 설정 매니저는 두 어드레스가 단일 라인을 통해서만 접근 가능한 경 우에 무효 데이터 신호를 출력할 수 있다. 다른 실시예에서, 유닛은 필요한 모든 데이터를 가져올 수 있을 때까 지 프로세스 실행을 지연할 수 있다. 이로 인해, 전체적인 성능이 저하될 수 있다. 그렇지만, 컴파일러는 지연 을 방지할 수 있는 설정과 데이터 배치를 찾을 수 있다. 일부 실시예에서, 컴파일러는 설정 매니저와 메모리 컨트롤러와 가속기가 단일 메모리 블록 으로부터 다중 어드레스가 접근되어야 하지만 메모리 블록에 포트가 하나뿐인 상황을 대응하도록 설정할 수 있는 처리 장치에 대한 설정 또는 명령을 생성할 수 있다. 예를 들어, 컴파일러는 처리부가 메모리 블록 의 여러 라인에 접근할 수 있도록 메모리 블록에 데이터를 재배치할 수 있다. 또한, 메모리 컨트롤러는 하나 이상의 입력에 대해 동시에 작용할 수 있다. 예를 들면, 메모리 컨트롤러 는 한 포트를 통하여 메모리 블록의 하나에 접근을 허용하고 다른 입력에서 다른 메모리 블록의 요 청을 수신하면서 데이터를 공급하는 것을 허용할 수 있다. 따라서, 이러한 동작의 결과로, 해당 메모리 블록과 의 통신의 전용 라인으로부터 데이터를 수신하는 예시적인 2D-컨볼루션 작업이 가속기에 부여될 수 있다. 추가적으로 또는 대안적으로, 메모리 컨트롤러 또는 로직 블록은 각 메모리 블록에 대해 리프레쉬 카운터 를 보유하고 모든 라인의 리프레쉬를 처리할 수 있다. 이런 카운터가 있으면, 메모리 컨트롤러가 장치로 부터의 데드 액세스 타임(dead access times) 사이에 리프레쉬 사이클을 삽입할 수 있다. 또한, 메모리 컨트롤러는 파이프라인 된 메모리 접근을 수행하여 데이터를 공급하기 전에 어드레스를 수 신하고 메모리 블록에 라인을 개통하도록 설정하는 것이 가능할 수 있다. 파이프라인 된 메모리 접근은 중단 또 는 지연된 클럭 사이클 없이 데이터를 처리부로 제공할 수 있다. 예를 들어, 메모리 컨트롤러 또는 로직 블록의 하나가 도 23의 우측 라인으로 데이터에 접근하는 반면, 좌측 라인에서 데이터가 전송될 수 있다. 이 방 법에 대해서는 도 26을 참조하여 상세히 설명하기로 한다. 요구되는 데이터에 대응하여, 처리 장치는 멀티플렉서 및/또는 기타 스위칭 장치를 활용하여 어느 장치가 주어진 작업을 수행할지를 선택할 수 있다. 예를 들어, 설정 매니저는 적어도 두 개의 데이터 라인이 MAC 유닛까지 이어지도록 멀티플렉서를 설정할 수 있다. 이로써, 컨볼루션 중에 곱셈을 필요로 하는 벡터 또 는 워드가 단일 클럭에서 동시에 처리부에 도달할 수 있기 때문에, 2D-컨볼루션과 같이 다중 어드레스로부터의 데이터를 필요로 하는 작업의 수행이 빨라질 수 있다. 이러한 데이터 전송 방법으로 인해, 가속기와 같은 처리부는 결과를 신속하게 출력할 수 있다. 일부 실시예에서, 설정 매니저는 작업의 우선순위에 의거하여 프로세스를 실행하도록 설정하는 것이 가능 할 수 있다. 예를 들어, 설정 매니저는 중단 없이 실행 프로세스를 완료하도록 설정될 수 있다. 이 경우, 설정 매니저는 명령 또는 작업의 설정을 가속기에 제공하고, 중단 없이 실행되도록 하고, 작업이 완료된 경우에만 멀티플렉서를 스위치 할 수 있다. 그러나 다른 실시예에서, 설정 매니저는 외부 인터페 이스의 요청과 같은 우선 작업을 수신하는 경우에 작업을 중단하고 데이터 라우팅을 재설정할 수 있다. 그러나 메모리 블록이 충분히 있으면, 메모리 컨트롤러는 작업이 완료될 때까지 변경되지 않아도 되는 전 용 라인이 있는 처리부로 데이터를 라우팅하거나 접근을 허용하도록 설정될 수 있다. 또한, 일부 실시예에서, 모든 장치는 버스에 의해 설정 매니저의 입구로 연결될 수 있고, 장치는 장치와 버스 사이의 접근을 관리 (예, 멀티플렉서와 동일한 로직을 활용)할 수 있다. 따라서, 메모리 컨트롤러는 복수의 메모리 인스턴스 또는 메모리 블록에 직접 연결될 수 있다. 또는, 메모리 컨트롤러는 메모리 서브인스턴스(sub-instance)에 직접 연결될 수 있다. 일부 실시예에서, 각 메모리 인스턴스 또는 블록은 서브인스턴스로부터 구성될 수 있다(예를 들어, DRAM은 개별적인 데이터 라인 이 다중 서브블록(sub-block)으로 배치된 매트로부터 구성될 수 있다). 또한, 인스턴스는 DRAM 매트, DRAM, 뱅 크, 플래시 매트, SRAM 매트, 또는 기타 유형의 메모리를 포함할 수 있다. 이후, 메모리 컨트롤러는 어드 레스 서브인스턴스로의 전용 라인을 포함하여 파이프라인 된 메모리 접근 중의 지연을 직접 최소화할 수 있다. 일부 실시예에서, 메모리 컨트롤러는 또한 특정 메모리 인스턴스에 필요한 로직(로우/컬럼 디코더, 리프 레쉬 로직 등)을 구비하고, 메모리 블록은 자체 로직을 처리할 수 있다. 따라서, 메모리 블록은 어 드레스를 확보하고 출력/기록 데이터에 대한 명령을 생성할 수 있다. 도 24는 개시된 실시예에 따른 예시적인 메모리 구성도를 도시한다. 일부 실시예에서, 처리 장치에 대한 코드 또는 설정을 생성하는 컴파일러는 데이터를 각 메모리 블록에 사전 배치하여 메모리 블록(2202, 2204)으로 부터 로딩을 설정하는 방법을 수행할 수 있다. 예를 들어, 컴파일러는 작업에 필요한 각 워드가 메모리 인스턴 스 또는 메모리 블록의 라인에 상호 연관되도록 데이터를 사전 배치할 수 있다. 그러나 처리 장치의 사용 가능한 메모리 블록보다 많은 메모리 블록을 필요로 하는 작업에 대해, 컴파일러는 각 메모리 블록의 하나 이상 의 메모리 위치에 데이터를 맞추는 방법을 이행할 수 있다. 컴파일러는 또한 데이터를 시퀀스로 저장하고, 라인 누락 지연을 피하기 위해 각 메모리 블록의 지연을 평가할 수 있다. 일부 실시예에서, 호스트는 설정 매니저 와 같은 처리부의 일부일 수 있지만, 다른 실시예에서, 컴파일러 호스트는 외부 인터페이스를 통해 처리 장치에 연결될 수 있다. 이러한 실시예에서, 호스트는 컴파일러에 대해 설명한 것과 같은 컴파일링 기능을 실행할 수 있다. 일부 실시예에서, 설정 매니저는 CPU 또는 마이크로컨트롤러(uC)일 수 있다. 이러한 실시예에서, 설정 매 니저는 메모리에 접근하여 메모리에 배치된 명령을 가져와야 할 수 있다. 특정 컴파일러는 연속 명령이 동일 메모리 라인과 다수의 메모리 뱅크에 저장되어 가져온 명령에 대한 파이프라인 된 메모리 접근이 허용되도 록 하는 방식으로 코드를 생성하고 메모리에 배치할 수 있다. 이러한 실시예에서, 설정 매니저와 메모리 컨트롤러는 파이프라인 된 메모리 접근을 가능하게 함으로써 선형 실행에서 행 지연을 방지하는 것이 가 능할 수 있다. 프로그램의 선형 실행의 이전 경우의 방법에서는, 컴파일러가 명령을 인지하고 배치하여 파이프라인 된 메모리 실행을 하였다. 그러나 다른 소프트웨어 구조는 더 복잡할 수 있고 컴파일러가 명령을 인지하고 그에 따라 동작 하는 것이 요구될 수 있다. 예를 들어, 작업에 루프와 브랜치(branches)가 필요한 경우, 컴파일러는 모든 루프 코드를 단일 라인 내부에 배치하여 단일 라인이 라인 개통 지연 없이 반복되게 할 수 있다. 이에 따라, 메모리 컨트롤러는 실행 중에 라인을 변경할 필요가 없을 수 있다. 일부 실시예에서, 설정 매니저는 내부 캐싱 또는 소형 메모리를 포함할 수 있다. 내부 캐싱은 설정 매니 저에 의해 실행되는 명령을 저장하여 브랜치와 루프를 처리할 수 있다. 예를 들어, 내부 캐싱 메모리의 명령은 메모리 블록에 접근하기 위해 가속기를 설정하는 명령을 포함할 수 있다. 도 25는 개시된 실시예에 따른 메모리 설정 프로세스를 도시한 예시적인 순서도이다. 메모리 설정 프로세 스 설명의 편의상, 앞서 설명한 도 22에 도시된 구성요소가 참조될 수 있다. 일부 실시예에서, 프로세스 는 외부 인터페이스를 통해 연결된 호스트로 명령을 제공하는 컴파일러에 의해 실행될 수 있다. 다른 실 시예에서, 프로세스는 설정 매니저와 같은 처리 장치의 구성요소에 의해 실행될 수 있다. 일반적으로, 프로세스는 작업의 수행을 위해 동시에 필요한 워드의 수를 판단하는 단계, 복수의 메모리 뱅크 각각으로부터 동시에 접근될 수 있는 워드의 수를 판단하는 단계, 및 동시에 필요한 워드의 수가 동시에 접근될 수 있는 워드의 수보다 큰 경우에 동시에 필요한 워드의 수를 다중 메모리 뱅크 사이에 분할하는 단계를 포함할 수 있다. 또한, 동시에 필요한 워드의 수를 분할하는 단계는 사이클릭(cyclic) 구조의 워드를 실행하는 단계 및 메모리 뱅크 당 한 워드를 순차적으로 배정하는 단계를 포함할 수 있다. 더욱 구체적으로, 프로세스는 컴파일러가 작업 사양을 수신할 수 있는 단계 2502로 시작할 수 있다. 이 사양은 요구되는 계산 및/또는 우선순위 레벨을 포함할 수 있다. 단계 2504에서, 컴파일러는 작업을 수행할 수 있는 가속기 또는 가속기의 그룹을 식별할 수 있다. 또는, 컴파일 러는 작업을 수행할 가속기를 설정 매니저와 같은 처리부가 식별할 수 있도록 명령을 생성할 수 있다. 예 를 들어, 요구되는 계산을 활용하여, 설정 매니저는 가속기의 그룹에서 작업을 수행할 수 있는 가속기를 식별할 수 있다. 단계 2506에서, 컴파일러는 작업을 실행하기 위해 동시에 접근돼야 하는 워드의 수를 판단할 수 있다. 예를 들 어, 두 벡터의 곱셈을 하려면 적어도 두 벡터에 접근해야 하고, 따라서 컴파일러는 연산을 수행하기 위해 벡터 워드가 동시에 접근돼야 한다고 판단할 수 있다. 단계 2508에서, 컴파일러는 작업을 실행하기 위해 필요한 사이클의 수를 판단할 수 있다. 예를 들면, 4개의 부 수곱(by-product)의 컨볼루션 연산이 작업에 필요한 경우, 컴파일러는 작업을 수행하기 위해 적어도 4 사이클이 필요할 것이라고 판단할 수 있다. 단계 2510에서, 컴파일러는 동시에 접근될 필요가 있는 워드를 서로 다른 메모리 뱅크에 배치할 수 있다. 이로 써, 메모리 컨트롤러는, 캐시에 저장된 데이터가 필요 없이, 서로 다른 메모리 인스턴스로 라인을 개통하 고 필요한 메모리 블록에 클럭 사이클 이내에 접근하도록 설정될 수 있다. 단계 2512에서, 컴파일러는 순차적으로 접근되는 워드를 동일한 메모리 뱅크에 배치할 수 있다. 예를 들어, 4 사이클의 연산이 필요한 경우, 컴파일러는 실행 중에 서로 다른 메모리 블록 사이의 라인 변경을 방지하기 위하 여 단일 메모리 블록에 순차적 사이클로 필요한 워드를 쓰도록 하는 명령을 생성할 수 있다. 단계 2514에서, 컴파일러는 설정 매니저와 같은 처리부를 프로그램 하는 명령을 생성할 수 있다. 명령은 스위칭 장치(예, 멀티플렉서)를 작동하거나 데이터 버스를 설정하는 조건을 명시할 수 있다. 이러한 명령으로, 설정 매니저는 메모리 컨트롤러가 작업에 따른 전용 통신 라인을 활용하여 데이터를 메모리 블록에서 처리부로 라우팅하거나 메모리 블록에 대한 접근을 허용하도록 설정할 수 있다. 도 26은 개시된 실시예에 따른 메모리 읽기 프로세스를 도시한 예시적인 순서도이다. 메모리 읽기 프로세 스 설명의 편의상, 앞서 설명한 도 22에 도시된 구성요소가 참조될 수 있다. 일부 실시예에서, 하기에 설 명하는 바와 같이, 프로세스는 메모리 컨트롤러에 의해 이행될 수 있다. 그러나 다른 실시예에서, 프로세스는 설정 매니저와 같은 처리 장치의 다른 구성요소에 의해 이행될 수 있다. 단계 2602에서, 메모리 컨트롤러, 설정 매니저, 또는 기타 처리부는 메모리 뱅크로 데이터를 라우 팅하거나 메모리 뱅크에 대한 접근을 허용하도록 하는 요청을 수신할 수 있다. 이 요청은 어드레스와 메모리 블 록을 명시할 수 있다. 일부 실시예에서, 상기 요청은 라인 2218의 읽기 명령 및 라인 2220의 어드레스를 명시하는 데이터 버스를 통해 수신될 수 있다. 다른 실시예에서, 상기 요청은 메모리 컨트롤러에 연결된 디멀티플렉서를 통해 수신될 수 있다. 단계 2604에서, 설정 매니저, 호스트, 또는 기타 처리부는 내부 레지스터를 쿼리할 수 있다. 내부 레지스 터는 메모리 뱅크로 개통된 라인, 개통된 어드레스, 개통된 메모리 블록, 및/또는 다음 작업에 관한 정보를 포 함할 수 있다. 내부 레지스터에 있는 정보에 의거하여, 메모리 뱅크로 개통된 라인이 있는지 여부 및/또는 메모 리 블록이 단계 2602에서 요청을 수신했는지 여부가 판단될 수 있다. 대안적으로 또는 추가적으로, 메모리 컨트 롤러가 직접 내부 레지스터를 쿼리할 수 있다. 개통된 라인에 메모리 뱅크가 로딩되어 있지 않다고 내부 레지스터가 나타내는 경우(즉, 단계 2606에서 '아니오'), 프로세스는 단계 2616으로 진행하여 수신된 어드레스와 연관된 메모리 뱅크로 라인이 로딩될 수 있다. 또한, 메모리 컨트롤러 또는 설정 매니저와 같은 처리부는 단계 2616에서 메모리 어드레 스로부터 정보를 요청하는 구성요소로 지연 신호를 보낼 수 있다. 예를 들어, 가속기가 이미 사용중인 메 모리 블록에 위치한 메모리 정보를 요청하는 경우, 메모리 컨트롤러는 단계 2618에서 가속기로 지연 신호 를 보낼 수 있다. 단계 2620에서, 설정 매니저 또는 메모리 컨트롤러는 내부 레지스터를 업데이트 하여 새로운 메모리 뱅크 또는 새로운 메모리 블록으로 라인이 개통됐음을 나타낼 수 있다. 개통된 라인에 메모리 뱅크가 로딩되어 있다고 내부 레지스터가 나타내는 경우(즉, 단계 2606에서 '예'), 프로 세스는 단계 2608로 진행할 수 있다. 단계 2608에서, 메모리 뱅크에 로딩된 라인이 다른 어드레스에 사용 되고 있는지 여부가 판단될 수 있다. 라인이 다른 어드레스에 사용되고 있는 경우(즉, 단계 2608에서 '예'), 단 일 블록에 두 인스턴스가 있는 것을 나타내는 것일 수 있으므로, 동시에 접근될 수 없다. 따라서, 단계 2616에 서 메모리 어드레스로부터 정보를 요청하는 구성요소로 오류 또는 면제 신호가 전송될 수 있다. 그러나 라인이 다른 어드레스에 사용되고 있지 않은 경우(즉, 단계 2608에서 '아니오'), 라인이 어드레스에 대해 개통될 수 있 고 타깃 메모리 뱅크로부터 데이터를 가져오고 단계 2614로 진행하여 메모리 어드레스로부터 정보를 요청하는 구성요소로 데이터를 전송할 수 있다. 프로세스를 통해, 처리 장치는 작업을 수행하는데 필요한 정보를 포함하는 메모리 블록 또는 메모 리 인스턴스와 처리부 사이의 직접 연결을 구축할 수 있다. 이러한 데이터의 구성으로 인해, 서로 다른 메모리 인스턴스 내에 구성된 벡터로부터 정보를 읽는 것이 가능할 뿐만 아니라 장치가 복수의 이런 어드레스를 요청하 는 경우에 서로 다른 메모리 블록으로부터 동시에 정보를 가져오는 것이 가능할 수 있다. 도 27은 개시된 실시예에 따른 실행 프로세스를 도시한 예시적인 순서도이다. 실행 프로세스 설명 의 편의상, 앞서 설명한 도 22에 도시된 구성요소가 참조될 수 있다. 단계 2702에서, 컴파일러 또는 설정 매니저와 같은 로컬 유닛은 수행되어야 하는 작업의 요청을 수신할 수 있다. 작업은 단일 연산(예, 곱셈) 또는 복합 연산(예, 행렬 사이의 컨볼루션)을 포함할 수 있다. 작업은 또 한 필요한 계산을 나타낼 수 있다. 단계 2704에서, 컴파일러 또는 설정 매니저는 작업을 수행하기 위해 동시에 요구되는 워드의 수를 판단할 수 있다. 예를 들어, 설정 매니저 또는 컴파일러는 벡터 사이의 곱셈을 수행하기 위해 두 워드가 동시에 필요하 다고 판단할 수 있다. 다른 예로써, 2D 컨볼루션 작업에서, 설정 매니저는 'n'과 'm'이 각각 행렬 차원인 'n' 곱하기 'm'의 워드가 행렬 사이의 컨볼루션을 위해 필요하다고 판단할 수 있다. 단계 2704에서, 설정 매니 저는 또한 작업을 수행하기 위해 필요한 사이클의 수를 판단할 수 있다. 단계 2706에서, 단계 2704의 판단에 따라, 컴파일러는 동시에 접근되어야 하는 워드를 기판 상에 배치된 복수의 메모리 뱅크에 기록할 수 있다. 예를 들어, 복수의 메모리 뱅크로부터 동시에 접근될 수 있는 워드의 수가 동시 에 필요한 워드의 수보다 적은 경우, 컴파일러는 데이터를 다중 메모리 뱅크에 배치하여 필요한 서로 다른 워드 에 클럭 이내에 접근 가능하게 할 수 있다. 또한, 작업을 수행하기 위해 여러 사이클이 필요하다고 설정 매니저 또는 컴파일러가 판단하는 경우, 컴파일러는 필요한 워드를 순차적 사이클로 복수의 메모리 뱅크의 단일 메모리 뱅크에 기록하여 메모리 뱅크 사이의 라인 변경을 방지할 수 있다. 단계 2708에서, 메모리 컨트롤러는 제1 메모리 라인을 이용하여 복수의 메모리 뱅크 또는 블록의 제1 메 모리 뱅크에서 적어도 하나의 제1 워드를 읽거나 적어도 하나의 제1 워드에 대한 접근을 허용하도록 설정될 수 있다. 단계 2170에서, 가속기의 하나와 같은 처리부는 적어도 하나의 제1 워드를 활용하여 작업을 처리할 수 있 다. 단계 2712에서, 메모리 컨트롤러는 제2 메모리 뱅크에 제2 메모리 라인을 개통하도록 설정될 수 있다. 예 를 들어, 작업에 의거하고 파이프라인 된 메모리 접근 방식을 활용하여, 메모리 컨트롤러는 작업에 필요 한 정보가 단계 2706에서 기록된 제2 메모리 블록에 제2 메모리 라인을 개통하도록 설정될 수 있다. 일부 실시 예에서, 제2 메모리 라인은 단계 2170의 작업이 완료되려는 시점에 개통될 수 있다. 예를 들어, 작업에 100 클 럭이 필요한 경우, 제2 메모리 라인은 90번째 클럭에서 개통될 수 있다. 일부 실시예에서, 단계 2708 내지 단계 2712는 하나의 라인 액세스 사이클 이내에 실행될 수 있다. 단계 2714에서, 메모리 컨트롤러는 단계 2710에서 개통된 제2 메모리 라인을 활용하여 제2 메모리 뱅크의 적어도 하나의 제2 워드의 데이터에 대한 접근을 허용하도록 설정될 수 있다. 단계 2176에서, 가속기의 하나와 같은 처리부는 적어도 하나의 제2 워드를 활용하여 작업을 처리할 수 있 다. 단계 2718에서, 메모리 컨트롤러는 제1 메모리 뱅크에 제2 메모리 라인을 개통하도록 설정될 수 있다. 예 를 들어, 작업에 의거하고 파이프라인 된 메모리 접근 방식을 활용하여, 메모리 컨트롤러는 제1 메모리 블록으로의 제2 메모리 라인을 개통하도록 설정될 수 있다. 일부 실시예에서, 제1 블록으로의 제2 메모리 라인 은 단계 2176의 작업이 완료되려는 시점에 개통될 수 있다. 일부 실시예에서, 단계 2714 내지 단계 2718은 하나의 라인 액세스 사이클 이내에 실행될 수 있다. 단계 2720에서, 메모리 컨트롤러는 제1 뱅크의 제2 메모리 라인 또는 제3 뱅크의 제1 라인을 활용하고 다른 메 모리 뱅크로 진행하여 복수의 메모리 뱅크의 제1 메모리 뱅크에서 적어도 하나의 제3 워드를 읽거나 적어도 하 나의 제3 워드에 대한 접근을 허용할 수 있다. 부분 리스페시 DRAM 칩과 같은 일부 메모리 칩은 칩의 커패시터 또는 기타 전기 부품의 전압 쇠퇴로 인해 저장된 데이터(예, 전기용량 활용)가 손실되는 것을 방지하기 위해 리프레시를 활용한다. 예를 들어, DRAM에서, 각 셀은 데이터가 손실되거나 손상되지 않도록 커패시터에 전하를 복원하기 위하여 수시로(특정 프로세스 또는 설계에 의거) 리프 레시 되어야 한다. DRAM 칩의 메모리 용량이 증가함에 따라, 메모리를 리프레시 하는데 상당한 양의 시간이 요 구된다. 특정 라인의 메모리가 리프레시 되고 있는 시한 동안에, 리프레시 되고 있는 라인을 포함하는 뱅크에는 접근이 불가능하다. 이는 성능 저하로 이어질 수 있다. 또한, 리프레시 프로세스와 연관된 전력 또한, 상당해진 다. 종전에는 메모리 리프레시와 연관된 역효과를 줄이기 위해 리프레시가 수행되는 비율을 줄이려고 노력하였 지만, 이러한 노력의 대부분은 DRAM의 물리적 레이어에만 집중하였다. 리프레시 동작은 메모리의 행을 읽고 다시 쓰는 것과 비슷하다. 이 원리를 활용하고 메모리로의 접근 패턴에 집 중하여, 본 개시의 실시예들은 리프레시에 전력을 덜 사용하고 메모리가 리프레시 되는 소요 시간을 줄이기 위 해 소프트웨어 및 하드웨어 방식 및 메모리 칩의 수정을 포함한다. 예를 들어, 개요를 설명하면, 일부 실시에는 하드웨어 및/또는 소프트웨어를 사용하여 라인 액세스 타이밍을 추적하고 리프레시 사이클 이내의(예, 타이밍 임계값에 의거하여) 최근에 접근된 행을 건너뛸 수 있다. 다른 예에서, 일부 실시예는 메모리 칩의 리프레시 컨 트롤러에 의해 실행된 소프트웨어에 의존하여 메모리로의 접근이 무작위 되지 않도록 읽기와 쓰기를 배정할 수 있다. 이에 따라, 소프트웨어는 리프레시를 더욱 정교하게 제어하여 낭비되는 리프레시 사이클 및/또는 라인을 방지할 수 있다. 이러한 방법들은 단독으로 사용되거나 프로세서에 대한 머신 코드와 함께 리프레시 컨트롤러에 대한 명령을 인코딩하는 컴파일러와 함께 사용되어 메모리로의 접근이 역시 무작위 되지 않도록 한다. 하기에상세히 설명하는 이러한 방법 및 구성의 모든 임의의 조합을 활용하여, 개시된 실시예들은 메모리 유닛이 리프 레시 되는 소요 시간을 줄임으로써 메모리 리프레시 전력 요구를 감소 및/또는 시스템 성능을 향상시킬 수 있다. 도 28은 본 개시에 따른 리프레시 컨트롤러를 포함하는 예시적인 메모리 칩을 도시한 것이다. 예를 들어, 메모리 칩은 기판 상에 복수의 메모리 뱅크(예, 메모리 뱅크(2801a) 등)를 포함할 수 있다. 도 28 의 예에서, 기판은 4개의 메모리 뱅크를 포함하고, 각 메모리 뱅크에는 4개의 라인이 있다. 라인은 메모리 칩 의 하나 이상의 메모리 뱅크 내의 워드라인 또는, 메모리 뱅크 또는 메모리 뱅크의 그룹을 따라 있는 행 의 일부 또는 전체와 같은, 메모리 칩 내의 메모리 셀의 모든 임의의 다른 모음을 의미할 수 있다. 다른 실시예에서, 기판은 모든 임의의 수의 메모리 뱅크를 포함할 수 있고, 각 메모리 뱅크는 모든 임의의 수의 라인을 포함할 수 있다. 일부 메모리 뱅크는 동일할 수의 라인을 포함할 수 있는 반면에(예, 도 28의 경우), 다 른 메모리 뱅크는 상이한 수의 라인을 포함할 수 있다. 도 28에 도시된 바와 같이, 메모리 칩은 컨트롤러 를 포함하여 메모리 칩으로 입력을 수신하고 메모리 칩으로부터 출력을 전송할 수 있다(상기 에 '코드의 분할'에서 설명). 일부 실시예에서, 복수의 메모리 뱅크는 DRAM(dynamic random access memory)을 포함할 수 있다. 그러나 복수 의 메모리 뱅크는 주기적인 리프레시를 필요로 하는 데이터를 저장하는 모든 임의의 휘발성 메모리를 포함할 수 있다. 하기에 더 상세히 설명하는 바와 같이, 개시된 실시예들은 카운터 또는 저항-커패시터 회로를 이용하여 리프레 시 사이클의 타이밍을 수행할 수 있다. 예를 들어, 카운터 또는 타이머를 활용하여 마지막 완전 리프레시 사이 클 이후의 시간을 잰 후에 카운터가 목표 값에 도달하는 경우에 다른 카운터를 활용하여 모든 행에 걸쳐 반복할 수 있다. 본 개시의 실시예들은 추가적으로 메모리 칩의 세그먼트로의 접근을 추적하고 필요한 리프레시 전력을 줄일 수 있다. 예를 들면, 도 28에는 도시되어 있지 않지만, 메모리 칩은 복수의 메모리 뱅크의 하나 이상의 세그먼트에 대한 접근 동작을 나타내는 접근 정보를 저장하도록 구성된 데이터 스토리지를 더 포함 할 수 있다. 예컨대, 하나 이상의 세그먼트는 메모리 칩 내의 메모리 셀의 라인, 열, 또는 모든 임의의 다른 그룹의 모든 임의의 부분을 포함할 수 있다. 한 특정 예에서, 하나 이상의 세그먼트는 복수의 메모리 뱅크 내의 메모리 구조의 적어도 한 행을 포함할 수 있다. 리프레시 컨트롤러는 적어도 부분적으로는 저장된 접근 정보에 의거하여 하나 이상의 세그먼트의 리프레시 동작을 수행하도록 구성될 수 있다. 예를 들어, 데이터 스토리지는 메모리 칩의 세그먼트(예, 메모리 칩 내의 메모리 셀의 라인, 열, 또는 모든 임의의 기타 그룹)와 연관된 하나 이상의 레지스터, SRAM 셀 등을 포함할 수 있다. 또한, 데이터 스 토리지는 연관된 세그먼트가 하나 이상의 이전 사이클에서 접근되었는지 여부를 나타내는 비트를 저장하도록 구 성될 수 있다. '비트'는 레지스터, SRAM 셀, 비휘발성 메모리 등과 같은 적어도 하나의 비트를 저장하는 모든 임의의 데이터 구조를 포함할 수 있다. 또한, 비트는 데이터 구조의 상응하는 스위치(또는 트랜지스터와 같은 스위칭 요소)를 ON('1' 또는 'true'와 동등할 수 있음)으로 설정하여 설정될 수 있다. 추가적으로, 또는 대안적 으로, 비트는 데이터 구조에 '1'(또는 비트의 설정을 나타내는 모든 임의의 다른 값)을 쓰기 위하여 데이터 구 조 내의 모든 임의의 다른 성질을 수정(예, 플래시 메모리의 플로팅 게이트를 충전, SRAM 내의 하나 이상의 플 립플롭의 상태를 수정 등)하여 설정될 수 있다. 비트가 메모리 컨트롤러의 리프레시 동작의 일부로 설정된 것으 로 판단되는 경우, 리프레시 컨트롤러는 연관된 세그먼트의 리프레시 사이클을 건너뛰고 해당 부분과 연 관된 레지스터를 비울 수 있다. 다른 예에서, 데이터 스토리지는 메모리 칩의 세그먼트(예, 메모리 칩 내의 메모리 셀의 라인, 열, 또는 모든 임의의 기타 그룹)와 연관된 하나 이상의 비휘발성 메모리(예, 플래시 메모리 등)를 포함할 수 있다. 비휘발성 메모리는 연관된 세그먼트가 하나 이상의 이전 사이클에서 접근되었는지 여부를 나타내는 비트를 저장 하도록 구성될 수 있다. 일부 실시예는, 추가적으로 또는 대안적으로, 라인이 접근된 현재의 리프레시 사이클 내의 마지막 틱(tick)을 가지고 있는 각 행 또는 행의 그룹(또는 메모리 칩의 다른 세그먼트) 상에 타임스탬프 레지스터를 추가할 수 있다. 이는 각 행 접근에서 리프레시 컨트롤러가 행 타임스탬프 레지스터를 업데이트 할 수 있음을 의미한다. 따라서, 다음번에 리프레시가 발생할 때에(예, 리프레시 사이클의 끝), 리프레시 컨트롤러는 저장된 타임스탬프를 비교하고, 연관된 세그먼트가 이전에 특정 시간 주기 이내에(예, 저장된 타임스탬프에 적용된 것 과 같은 특정 임계값 이내에) 접근된 경우, 리프레시 컨트롤러는 다음 세그먼트로 건너뛸 수 있다. 이는 시스템 이 최근에 접근된 세그먼트에 리프레시 전력을 사용하는 것을 방지한다. 또한, 리프레시 컨트롤러는 각 세그먼트가 다음 사이클에서 접근되거나 리프레시 되도록 접근의 추적을 계속할 수 있다. 이에 따라, 또 다른 예에서, 데이터 스토리지는 메모리 칩의 세그먼트(예, 메모리 칩 내의 메모리 셀의 라인, 열, 또는 모든 임의의 기타 그룹)와 연관된 하나 이상의 레지스터 또는 비휘발성 메모리를 포함할 수 있다. 비트를 사용하여 연관 세그먼트가 접근되었는지 여부를 나타내기보다, 레지스터 또는 비휘발성 메모리 는 연관 세그먼트의 가장 최근 접근을 나타내는 타임스탬프 또는 기타 정보를 저장하도록 구성될 수 있다. 이러 한 예에서, 리프레시 컨트롤러는 연관 레지스터 또는 메모리에 저장된 타임스탬프와 현재 시각 사이의 시 간의 양(예, 하기의 도 29a 및 도 29b에 설명하는 바와 같은 타이머로부터의 시간)이 미리 정해진 임계값(예, 8ms, 16ms, 32ms, 64ms 등)을 초과하는지 여부에 의거하여 연관 세그먼트를 리프레시 할지 또는 접근할 지 여부 를 판단할 수 있다. 이에 따라, 미리 정해진 임계값은 연관 세그먼트가 리프레시 사이클마다 적어도 한 번씩 리프레시(접근이 아닌 경우) 되도록 하는 리프레시 사이클에 대한 시간의 양을 포함할 수 있다. 대안적으로, 미리 정해진 임계값은 리 프레시 사이클에 필요한 시간보다 짧은 시간의 양을 포함할 수 있다(예, 모든 임의의 요구되는 리프레시 또는 접근 신호가 리프레시 사이클이 완료되기 전에 연관 세그먼트에 도달하게 하기 위함). 예를 들어, 미리 정해진 시간은 리프레시 주기가 8ms인 메모리 칩에 대해 7ms일 수 있고, 이로써 세그먼트가 7ms 이내에 접근되지 않으 면 리프레시 컨트롤러가 8ms 리프레시 주기의 종료 전에 세그먼트에 도착하는 리프레시 또는 접근 신호를 전송 하게 될 수 있다. 일부 실시예에서, 미리 정해진 임계값은 연관 세그먼트의 크기에 달려있을 수 있다. 예를 들 어, 미리 정해진 임계값은 메모리 칩의 세그먼트가 작을수록 작아질 수 있다. 상기에서는 메모리 칩을 참조하여 설명하였지만, 본 개시의 리프레시 컨트롤러는 앞서 설명하고 본 개시 전반에 걸쳐 설명하는 것과 같은 분산 프로세서 아키텍처에서도 사용될 수 있다. 이러한 아키텍처의 일례가 도 7a에 도 시되어 있다. 이러한 실시예에서, 메모리 칩과 동일한 기판은, 도 7a에 도시된 바와 같은, 그 위에 배치 된 복수의 프로세싱 그룹을 포함할 수 있다. 앞서 도 3a를 참조하여 설명한 바와 같이, '프로세싱 그룹'은 둘 이상의 프로세서 서브유닛 및 이 서브유닛에 상응하는 기판 상의 메모리 뱅크를 의미할 수 있다. 프로세싱 그룹 은 기판 상의 공간적 분산 및/또는 메모리 칩 상의 실행을 위한 코드의 컴파일링 목적의 논리적 그루핑을 나타낼 수 있다. 이에 따라, 기판은 도 28에 도시된 뱅크(2801a)와 기타 뱅크와 같은 복수의 뱅크를 포함하는 메모리 어레이를 포함할 수 있다. 또한, 기판은 복수의 프로세서 서브유닛(예, 도 7a에 도시된 서브유닛(730a, 730b, 730c, 730d, 730e, 730f, 730g, 730h))을 포함할 수 있는 프로세싱 어레이를 포함할 수 있다. 앞서 도 7a를 참조하여 더 설명한 바와 같이, 각 프로세싱 그룹은 프로세서 서브유닛 및 프로세서 서브유닛 전 용의 상응하는 하나 이상의 메모리 뱅크를 포함할 수 있다. 또한, 각 프로세서 서브유닛이 상응하는 전용 메모 리 뱅크와 통신할 수 있게 하기 위하여, 기판은 프로세서 서브유닛 중의 하나를 그에 상응하는 전용 메모리 뱅 크로 연결하는 제1 복수의 버스를 포함할 수 있다. 이러한 실시예에서, 도 7a에 도시된 바와 같이, 기판은 각 프로세서 서브유닛을 적어도 하나의 다른 프로세서 서브유닛(예, 동일 행의 인접 서브유닛, 동일 열의 인접 프로세서 서브유닛, 또는 기판 상의 모든 임의의 다른 프로세서 서브유닛)과 연결하기 위한 제2 복수의 버스를 포함할 수 있다. 앞서 '소프트웨어를 활용한 동기화' 부분에서 설명한 바와 같이, 프로세서 서브유닛 사이와 복수의 버스의 상응하는 버스를 통한 데이터 전달이 타 이밍 하드웨어 로직 요소에 의해 제어되지 않도록 제1 및/또는 제2 복수의 버스에는 타이밍 하드웨어가 없을 수 있다. 메모리 칩과 동일한 기판이 그 위에 배치된 복수의 프로세싱 그룹(예, 도 7a에 도시)을 포함할 수 있는 실시예에서, 프로세서 서브유닛은 어드레스 생성기(예, 도 4에 도시된 어드레스 생성기)를 더 포함할 수 있다. 또한, 각 프로세싱 그룹은 프로세서 서브유닛 및 프로세서 서브유닛 전용의 상응하는 하나 이상의 메모리 뱅크를 포함할 수 있다. 이에 따라, 어드레스 생성기 각각은 복수의 메모리 뱅크의 상응하는 전용 메모리 뱅크 와 연관될 수 있다. 또한, 기판은 복수의 어드레스 생성기 중의 하나를 그에 상응하는 전용 메모리 뱅크로 각각 연결하는 복수의 버스를 포함할 수 있다. 도 29a는 본 개시에 따른 예시적인 리프레시 컨트롤러를 도시한 것이다. 리프레시 컨트롤러는 도 28의 메모리 칩과 같은 본 개시의 메모리 칩에 포함될 수 있다. 도 29a에 도시된 바와 같이, 리프레시 컨 트롤러는 온칩 발진기(on-chip oscillator) 또는 리프레시 컨트롤러를 위한 모든 임의의 기타 타이 밍 회로를 포함할 수 있는 타이머를 포함할 수 있다. 도 29a에 도시된 구성에서, 타이머는 리프레 시 사이클을 주기적으로(예, 8ms, 16ms, 32ms, 64ms 등 마다) 촉발할 수 있다. 리프레시 사이클은 로우 카운터 를 활용하여 상응하는 메모리 칩의 모든 행을 통해 사이클을 하고 합산기를 활성 비트와 함께 활용하여 각 행에 대한 리프레시 신호를 생성할 수 있다. 도 29a에 도시된 바와 같이, 비트는 각 행이 한 사이클 동안에 확실히 리프레시 되도록 하기 위해 1('true')에 고정될 수 있다. 본 개시의 실시예에서, 리프레시 컨트롤러는 데이터 스토리지를 포함할 수 있다. 앞서 설명한 바와 같이, 데이터 스토리지는 메모리 칩의 세그먼트(예, 메모리 칩 내의 메모리 셀의 라인, 열, 또는 모든 임 의의 기타 그룹)와 연관된 하나 이상의 레지스터 또는 비휘발성 메모리를 포함할 수 있다. 레지스터 또는 비휘 발성 메모리는 연관 세그먼트의 가장 최근 접근을 나타내는 타임스탬프 또는 기타 정보를 저장하도록 구성될 수 있다. 리프레시 컨트롤러는 저장된 정보를 활용하여 메모리 칩의 세그먼트에 대한 리프레시를 건너뛸 수 있다. 예를 들어, 어떤 세그먼트가 하나 이상의 이전 리프레시 사이클 동안에 리프레시 되었다고 저장된 정보가 나타내는 경우에 리프레시 컨트롤러는 현 리프레시 사이클에서 해당 세그먼트를 건너뛸 수 있다. 다른 예 에서, 어떤 세그먼트에 대한 저장된 타임스탬프와 현재 시각 사이의 차이가 임계값보다 작은 경우에 리프레시 컨트롤러는 현재 리프레시 사이클에서 해당 세그먼트를 건너뛸 수 있다. 리프레시 컨트롤러는 또한 다중 리프레시 사이클을 통해 메모리 칩의 세그먼트의 접근과 리프레시의 추적을 계속 이어갈 수 있다. 예를 들어, 리프레시 컨트롤러는 타이머를 활용하여 저장된 타임스탬프를 업데이트할 수 있다. 이 러한 실시예에서, 리프레시 컨트롤러는 임계 시간 간격 이후에 데이터 스토리지에 저장된 접근 정보를 비 우는 데에 타이머의 출력을 활용하도록 구성될 수 있다. 예를 들어, 데이터 스토리지가 연관 세그먼트에 대한 가장 최근 접근 또는 리프레시의 타임스탬프를 저장하는 실시예에서, 리프레시 컨트롤러는 접근 명령 또 는 리프레시 신호가 세그먼트로 전송될 때마다 새로운 타임스탬프를 데이터 스토리지에 저장할 수 있다. 데이터 스토리지가 타임스탬프 대신에 비트를 저장하는 경우, 타이머는 임계 시간 주기보다 길게 설정된 비트를 비우도록 구성될 수 있다. 예를 들어, 데이터 스토리지가 연관 세그먼트가 하나 이상의 이전 사이클에서 접근되 었던 것으로 나타내는 비트를 저장하는 실시예에서, 리프레시 컨트롤러는 타이머가 연관 비트에 설 정된 것(예, 1)보다 임계 수의 사이클(예, 1, 2 등) 이후의 새로운 리프레시 사이클을 촉발할 때마다 데이터 스 토리지 내의 비트를 비울(예, 0으로 설정) 수 있다. 리프레시 컨트롤로는 메모리 칩의 다른 하드웨어와 협력하여 메모리 칩의 세그먼트의 접근을 추적할 수 있다. 예를 들면, 메모리 칩은 센스 증폭기를 사용하여 읽기 동작을 수행한다(예, 도 9 및 도 10에 도시). 센스 증폭기는 하나 이상의 메모리 셀에 데이터를 저장하는 메모리 칩의 세그먼트로부터 저전력 신호를 감지하고, 데이터가 앞서 설명한 바와 같은 외부 CPU 또는 GPU 또는 집적 프로세서 서브유닛과 같은 로 직에 의해 해석될 수 있도록 작은 전압 스윙(voltage swing)을 높은 전압 수준으로 증폭하도록 구성된 복수의 트랜지스터를 포함할 수 있다. 도 29a에는 도시되어 있지 않지만, 리프레시 컨트롤러는 또한 하나 이상의 세그먼트에 접근하고 적어도 하나의 비트 레지스터의 상태를 변경하도록 구성된 센스 증폭기와 통신할 수 있다. 예를 들어, 센스 증폭기가 하나 이상의 세그먼트에 접근하는 경우, 연관 세그먼트가 이전 사이클에서 접근되었 음을 나타내는 비트를 설정(예, 1로 설정)할 수 있다. 데이터 스토리지가 연관 세그먼트에 대한 가장 최근 접근 또는 리프레시의 타임스탬프를 저장하는 실시예에서, 센스 증폭기가 하나 이상의 세그먼트에 접근하는 경우, 타 이머로부터 레지스터, 메모리, 또는 데이터 스토리지를 포함하는 기타 요소로 타임스탬프의 기록을 촉발 할 수 있다. 앞서 설명한 모든 실시예에서, 리프레시 컨트롤러는 복수의 메모리 뱅크에 대한 메모리 컨트롤러와 통합 될 수 있다. 예를 들어, 도 3a에 도시된 실시예와 유사하게, 리프레시 컨트롤러는 메모리 칩의 메 모리 뱅크 또는 기타 세그먼트와 연관된 논리 및 제어 서브유닛에 포함될 수 있다. 도 29b는 본 개시에 따른 다른 예시적인 리프레시 컨트롤러(2900')를 도시한 것이다. 리프레시 컨트롤러(290 0')는 도 28의 메모리 칩과 같은 본 개시의 메모리 칩에 포함될 수 있다. 리프레시 컨트롤러와 유 사하게, 리프레시 컨트롤러(2900')는 타이머, 로우 카운터, 활성 비트, 및 합산기를 포함한다. 또한, 리프레시 컨트롤러(2900')는 데이터 스토리지를 포함할 수 있다. 도 29b에 도시된 바와 같이, 데이터 스토리지는 메모리 칩의 세그먼트(예, 메모리 칩 내의 메모리 셀의 라인, 열, 또는 모든 임의의 기타 그룹)와 연관된 하나 이상의 레지스터 또는 비휘발성 메모리를 포함할 수 있고, 데이터 스토리지 내의 상태는 연관되는 하나 이상의 세그먼트에 대응하여 변경되도록(예, 앞서 설명한 바와 같이, 리프 레시 컨트롤러(2900')의 센스 증폭기 또는 기타 요소에 의해) 구성될 수 있다. 이에 따라, 리프레시 컨트롤러 (2900')는 데이터 스토리지 내의 상태에 의거하여 하나 이상의 세그먼트의 리프레시를 건너뛰도록 구성될 수 있 다. 예를 들어, 세그먼트와 연관된 상태가 활성화되어 있으면(예, 스위치를 켜서 1로 설정, '1'을 저장하기 위 하여 성질을 변경 등), 리프레시 컨트롤러(2900')는 연관 세그먼트에 대한 리프레시 사이클을 건너뛰고 해당 부분과 연관된 상태를 비울 수 있다. 상태는 적어도 1비트 레지스터 또는 적어도 1비트의 데이터를 저장하도록 구 성된 모든 임의의 다른 메모리 구조로 저장될 수 있다. 메모리 칩의 세그먼트가 각 리프레시 사이클 동안에 반드시 리프레시 또는 접근되도록 하기 위하여, 리프레시 컨트롤러(2900')는 다음 리프레시 사이클 동안에 리프레시 신호를 촉발하기 위하여 상태를 재설정하거나 비울 수 있다. 일부 실시예에서, 세그먼트를 건너뛴 다음에, 리프레시 컨트롤러(2900')는 해당 세그먼트가 다음 리프 레시 사이클에 반드시 리프레시 되게 하기 위하여 연관 상태를 비울 수 있다. 다른 실시예에서, 리프레시 컨트 롤러(2900')는 임계 시간 간격 이후에 데이터 스토리지 내의 상태를 재설정하도록 구성될 수 있다. 예를 들면, 리프레시 컨트롤러(2900')는 타이머가 연관 상태가 설정된(예, 스위치를 켜서 1로 설정, '1'을 저장하기 위하여 성질을 변경 등) 이후에 임계 시간을 초과할 때마다 데이터 스토리지의 상태를 비울 수(예, 0으로 설정) 있다. 일부 실시예에서, 리프레시 컨트롤러(2900')는 임계 시간 대신에 임계 수의 리프레시 사이클(예, 1, 2 등) 또는 임계 수의 클럭 사이클(예, 2, 4 등)을 사용할 수 있다. 다른 실시예에서, 상태는 연관 세그먼트의 가장 최근 리프레시 또는 접근의 타임스탬프를 포함하여, 타임스탬프 와 현재 시각(예, 도 29a 및 도 29b의 타이머로부터의 시각) 사이의 시간의 양이 미리 정해진 임계값(예, 8ms, 16ms, 32ms, 64ms 등)을 초과하는 경우에 리프레시 컨트롤러(2900')는 연관 세그먼트로 접근 명령 또는 리 프레시 신호를 전송하고 그 부분과 연관된 타임스탬프를 업데이트(예, 타이머를 활용)하도록 할 수 있다. 추가적으로 또는 대안적으로, 리프레시 컨트롤러(2900')는 리프레시 타임 지시자가 미리 정해진 타임 임계값 이 내의 마지막 리프레시 타임을 나타내는 경우에 복수의 메모리 뱅크의 하나 이상의 세그먼트에 대한 리프레시 동 작을 건너뛰도록 구성될 수 있다. 이러한 실시예에서, 하나 이상의 세그먼트에 대한 리프레시 동작을 건너뛴 이 후에, 리프레시 컨트롤러(2900')는 하나 이상의 세그먼트와 연관된 저장된 리프레시 타임 지시자를 변경하여 다 음 동작 사이클 동안에 하나 이상의 세그먼트가 리프레시 되게 하도록 구성될 수 있다. 예를 들어, 앞서 설명한 바와 같이, 리프레시 컨트롤러(2900')는 타이머를 이용하여 저장된 리프레시 타임 지시자를 업데이트할 수 있다. 이에 따라, 데이터 스토리지는 복수의 메모리 뱅크의 하나 이상의 세그먼트가 마지막으로 리프레시 되었던 시간 을 나타내는 리프레시 타임 지시자를 저장하도록 구성된 타임스탬프 레지스터를 포함할 수 있다. 또한, 리프레 시 컨트롤러(2900')는 데이터 스토리지에 저장된 접근 정보를 임계 시간 간격 이후에 비우는데 타이머의 출력을 이용할 수 있다. 앞서 설명한 모든 실시예에서, 하나 이상의 세그먼트로의 접근은 하나 이상의 세그먼트와 연관된 쓰기 동작을 포함할 수 있다. 추가적으로 또는 대안적으로, 하나 이상의 세그먼트로의 접근은 하나 이상의 세그먼트와 연관 된 읽기 동작을 포함할 수 있다. 또한, 도 29b에 도시된 바와 같이, 리프레시 컨트롤러(2900')는 적어도 부분적으로는 데이터 스토리지 내의 상 태에 의거하여 데이터 스토리지의 업데이트를 보조하도록 구성된 합산기 및 로우 카운터를 포함할 수 있다. 데이터 스토리지는 복수의 메모리 뱅크와 연관된 비트 테이블을 포함할 수 있다. 예를 들어, 비트 테이블은 연관 세그먼트에 대한 비트를 가지도록 구성된 스위치(또는 트랜지스터와 같은 스위칭 요 소) 또는 레지스터(예, SRAM 등)의 어레이를 포함할 수 있다. 추가적으로 또는 대안적으로, 데이터 스토리지 는 복수의 메모리 뱅크와 연관된 타임스탬프를 저장할 수 있다. 또한, 리프레시 컨트롤러(2900')는 하나 이상의 세그먼트로의 리프레시가 비트 테이블에 저장된 해당 값에 의거 하여 일어날지 여부를 제어하도록 구성된 리프레시 게이트를 포함할 수 있다. 예를 들어, 리프레시 게이 트는, 연관 세그먼트가 하나 이상의 이전 클럭 사이클 동안에 리프레시 또는 접근되었던 것으로 데이터 스토리지의 상응하는 상태가 나타내는 경우에, 로우 카운터로부터의 리프레시 신호를 무효로 하도 록 구성된 논리 게이트(예, 'and' 게이트)를 포함할 수 있다. 다른 실시예에서, 리프레시 게이트는, 연관 세그먼트가 미리 정해진 임계 시간값 이내에 리프레시 또는 접근되었던 것으로 데이터 스토리지로부터의 해당 타임스탬프가 나타내는 경우에, 로우 카운터로부터의 리프레시 신호를 무효로 하도록 구성된 마이크 로프로세서 또는 기타 회로를 포함할 수 있다. 도 30은 메모리 칩(예, 도 28의 메모리 칩)의 부분 리프레시를 위한 프로세스의 예시적인 순서도이 다. 프로세스는 도 29a의 리프레시 컨트롤러 또는 도 29b의 리프레시 컨트롤러(2900')와 같은 본 개시에 따른 리프레시 컨트롤러에 의해 실행될 수 있다. 단계 3010에서, 리프레시 컨트롤러는 복수의 메모리 뱅크의 하나 이상의 세그먼트에 대한 접근 동작을 나타내는 정보에 접근할 수 있다. 예를 들어, 앞서 도 29a와 도 29b를 참조하여 설명한 바와 같이, 리프레시 컨트롤러는 메모리 칩의 세그먼트(예, 메모리 칩 내의 메모리 셀의 라인, 열, 또는 모든 임의의 기타 그룹)와 연관되고 연관 세그먼트의 가장 최근 접근을 나타내는 타임스탬프 또는 기타 정보를 저장하도록 구성된 데이터 스토리지를 포함할 수 있다. 단계 3020에서, 리프레시 컨트롤러는 적어도 부분적으로는 접근된 정보에 의거하여 리프레시 및/또는 접근 명령 을 생성할 수 있다. 예를 들어, 앞서 도 29a와 도 29b를 참조하여 설명한 바와 같이, 리프레시 컨트롤러는, 접 근된 정보가 미리 정해진 시간 임계값 이내의 마지막 리프레시 또는 접근 시각 및/또는 하나 이상의 이전 클럭 사이클 동안에 발생한 마지막 리프레시 또는 접근을 나타내는 경우에, 복수의 메모리 뱅크의 하나 이상의 세그 먼트에 대한 리프레시 동작을 건너뛸 수 있다. 추가적으로 또는 대안적으로, 리프레시 컨트롤러는, 접근된 정보 가 나타내는 가장 최근 리프레시 또는 접근 시간이 미리 정해진 임계값을 초과하는지 여부에 의거 및/또는 가장 최근 리프레시 또는 접근이 하나 이상의 이전 클럭 사이클 동안에 발생하지 않은 경우에, 연관 세그먼트를 리프 레시 또는 접근하라는 명령을 생성할 수 있다. 단계 3030에서, 리프레시 컨트롤러는 하나 이상의 세그먼트와 연관되어 저장된 리프레시 타임 지시자를 변경하 여 다음 동작 사이클 동안에 하나 이상의 세그먼트가 리프레시 되게 할 수 있다. 예를 들어, 하나 이상의 세그 먼트에 대한 리프레시 동작을 건너뛴 이후에, 리프레시 컨트롤러는 하나 이상의 세그먼트에 대한 접근 동작을 나타내는 정보를 변경하여 다음 클럭 사이클 동안에 하나 이상의 세그먼트가 리프레시 되게 할 수 있다. 이에 따라, 리프레시 컨트롤러는 리프레시 사이클을 건너뛴 이후에 세그먼트에 대한 상태를 비울 수(예, 0으로 설정) 있다. 추가적으로 또는 대안적으로, 리프레시 컨트롤러는 현재 사이클 동안에 리프레시 및/또는 접근되는 세그 먼트에 대한 상태를 설정할 수(예, 1로 설정) 있다. 하나 이상의 세그먼트에 대한 접근 동작을 나타내는 정보가 타임스탬프를 포함하는 실시예에서, 리프레시 컨트롤러는 현재 사이클 동안에 리프레시 및/또는 접근되는 세그 먼트와 연관되어 저장된 모든 임의의 타임스탬프를 업데이트할 수 있다. 방법은 추가적인 단계를 더 포함할 수 있다. 예를 들어, 단계 3030에 대한 추가 또는 대안으로, 센스 증 폭기가 하나 이상의 세그먼트에 접근하고 하나 이상의 세그먼트와 연관된 정보를 변경할 수 있다. 추가적으로 또는 대안적으로, 센스 증폭기는 접근이 발생한 경우에 리프레시 컨트롤러로 신호를 보내서 리프레시 컨트롤러 가 하나 이상의 세그먼트와 연관된 정보를 업데이트하게 할 수 있다. 앞서 설명한 바와 같이, 센스 증폭기는 하 나 이상의 메모리 셀에 데이터를 저장하는 메모리 칩의 세그먼트로부터 저전력 신호를 감지하고, 데이터가 앞서 설명한 바와 같은 외부 CPU 또는 GPU 또는 집적 프로세서 서브유닛과 같은 로직에 의해 해석될 수 있도록 작은 전압 스윙을 높은 전압 수준으로 증폭하도록 구성된 복수의 트랜지스터를 포함할 수 있다. 이러한 예에서, 센스 증폭기가 하나 이상의 세그먼트에 접근할 때마다, 세그먼트와 연관된 비트를 설정하여(예, 1로 설정) 연관 세그 먼트가 이전 사이클에서 접근되었음을 나타낼 수 있다. 하나 이상의 세그먼트에 대한 접근 동작을 나타내는 정 보가 타임스탬프를 포함하는 실시예에서, 센스 증폭기가 하나 이상의 세그먼트에 접근할 때마다, 리프레시 컨트 롤러의 타이머로부터 데이터 스토리지로 타임스탬프의 쓰기를 촉발하여 세그먼트와 연관된 모든 임의의 저장된 타임스탬프를 업데이트할 수 있다. 도 31은 메모리 칩(예 도 28의 메모리 칩)에 대한 리프레시를 판단하는 프로세스의 예시적인 순서 도이다. 프로세스는 본 개시에 따른 컴파일러 내에서 이행될 수 있다. 앞서 설명한 바와 같이, '컴파일러'는 고수준 언어(예, C, FORTRAN, BASIC 등과 같은 절차형 언어; Java, C++, Pascal, Python 등과 같 은 객체 지향 언어 등)를 저수준 언어(예, 어셈블리 코드, 오브젝트 코드, 머신 코드 등)로 변환하는 모든 컴퓨 터 프로그램을 말한다. 컴파일러는 사람으로 하여금 인간 판독 가능 언어로 일련의 명령을 프로그램 할 수 있게 해줄 수 있고, 이러한 명령은 나중에 머신 실행 가능 언어로 변환된다. 컴파일러는 하나 이상의 프로세서에 의 해 실행되는 소프트웨어 명령을 포함할 수 있다. 단계 3110에서, 하나 이상의 프로세서는 고수준 컴퓨터 코드를 수신할 수 있다. 예를 들면, 고수준 컴퓨터 코드 는 메모리(예, 하드디스크 드라이브 등과 같은 비휘발성 메모리, DRAM과 같은 휘발성 메모리 등) 상의 하나 이 상의 파일에 인코딩 되거나 네트워크(예, 인터넷 등)를 통해 수신될 수 있다. 추가적으로 또는 대안적으로, 고 수준 컴퓨터 코드는 사용자로부터 수신될 수 있다(예, 키보드와 같은 입력 장치를 활용). 단계 3120에서, 하나 이상의 프로세서는 고수준 컴퓨터 코드에 의해 접근될 메모리 칩과 연관된 복수의 메모리 뱅크에 분산된 복수의 메모리 세그먼트를 식별할 수 있다. 예를 들어, 하나 이상의 프로세서는 복수의 메모리 뱅크를 한정하는 데이터 구조 및 메모리 칩의 상응하는 구조에 접근할 수 있다. 하나 이상의 프로세서는 메모리 (예, 하드디스크 드라이브 등과 같은 비휘발성 메모리, DRAM과 같은 휘발성 메모리 등)로부터 데이터 구조에 접근하거나 네트워크(예, 인터넷 등)를 통해 데이터 구조를 수신할 수 있다. 이러한 실시예에서, 데이터 구조는 컴파일러에 의해 접근될 수 있는 하나 이상의 라이브러리에 포함되어, 접근될 특정 메모리 칩에 대한 명령을 컴 파일러가 생성하도록 허용할 수 있다. 단계 3130에서, 하나 이상의 프로세서는 고수준 컴퓨터 코드에 접근하여 복수의 메모리 접근 사이클에서 일어날 복수의 메모리 읽기 명령을 식별할 수 있다. 예를 들어, 하나 이상의 프로세서는 메모리로부터의 하나 이상의 읽기 명령 및/또는 메모리로의 하나 이상의 쓰기 명령을 요구하는 고수준 컴퓨터 코드 이내의 각 연산을 식별할 수 있다. 이러한 명령은 변수 초기화, 변수 재할당, 변수의 논리 연산, 입력-출력 연산 등을 포함할 수 있다. 단계 3140에서, 하나 이상의 프로세서는 복수의 메모리 접근 사이클의 각 사이클 동안에 복수의 메모리 세그먼 트의 각 세그먼트가 접근되도록 복수의 메모리 세그먼트의 각 세그먼트를 통해 복수의 메모리 접근 명령과 연관 된 데이터의 분산을 유발할 수 있다. 예를 들어, 하나 이상의 프로세서는 메모리 칩의 구조를 한정하는 데이터 구조로부터 메모리 세그먼트를 식별한 후에 변수를 고수준 코드로부터 메모리 세그먼트의 다양한 세그먼트로 배 정하여 각 메모리 세그먼트가 각 리프레시 사이클(특정 수의 클럭 사이클을 포함할 수 있음) 동안에 적어도 한 번 접근(예, 쓰기 또는 읽기를 통해)되도록 할 수 있다. 이러한 예에서, 하나 이상의 프로세서는 각 메모리 세 그먼트가 특정 수의 클럭 사이클 동안에 적어도 한 번 접근(예, 쓰기 또는 읽기를 통해)되도록 고수준 코드의 라인으로부터 변수를 배정하기 위하여 고수준 코드의 각 라인이 요구하는 클럭 사이클의 수를 나타내는 정보에 접근할 수 있다. 다른 예에서, 하나 이상의 프로세서는 고수준 코드로부터 머신 코드 또는 기타 저수준 코드를 우선 생성할 수 있다. 이후, 하나 이상의 프로세서는 변수를 저수준 코드로부터 메모리 세그먼트의 다양한 세그먼트로 배정하여 각 메모리 세그먼트가 각 리프레시 사이클(특정 수의 클럭 사이클을 포함할 수 있음) 동안에 적어도 한 번 접근 (예, 쓰기 또는 읽기를 통해)되도록 할 수 있다. 이러한 예에서, 저수준 코드의 각 라인은 단일 클럭 사이클을 필요로 할 수 있다. 상기의 모든 실시예에서, 하나 이상의 프로세서는 임시 출력을 사용하는 논리 연산 또는 기타 명령을 메모리 세 그먼트이 다양한 세그먼트에 더 배정할 수 있다. 이러한 임시 출력의 결과는 여전히 읽기 및/또는 쓰기 명령이 되어서 지명된 변수가 해당 메모리 세그먼트에 아직 배정되지 않아도 배정된 메모리 세그먼트가 리프레시 사이 클 동안에 여전히 접근되도록 할 수 있다. 방법은 추가적인 단계를 더 포함할 수 있다. 예를 들어, 컴파일링 이전에 변수가 배정되는 실시예에서, 하나 이상의 프로세서는 고수준 코드로부터 머신 코드 또는 기타 저수준 코드를 생성할 수 있다. 또한, 하나 이 상의 프로세서는 메모리 칩과 상응하는 논리 회로에 의한 실행을 위한 컴파일링 된 코드를 전송할 수 있다. 논 리 회로는 GPU 또는 CPU와 같은 종래의 회로를 포함하거나 도 7a에 도시된 바와 같이 메모리 칩으로서 동일 기 판 상에 프로세싱 그룹을 포함할 수 있다. 이에 따라, 앞서 설명한 바와 같이, 기판은 도 28에 도시된 뱅크 (2801a)와 기타 뱅크와 같은 복수의 뱅크를 포함하는 메모리 어레이를 포함할 수 있다. 또한, 기판은 복수의 프 로세서 서브유닛(예, 도 7a에 도시된 서브유닛(730a, 730b, 730c, 730d, 730e, 730f, 730g, 730h))을 포함하는 프로세싱 어레이를 포함할 수 있다. 도 32는 메모리 칩(예, 도 28의 메모리 칩)에 대한 리프레시를 판단하는 프로세스의 다른 예시적인 순서도이다. 프로세스는 본 개시에 따른 컴파일러 내에서 이행될 수 있다. 프로세스는 컴파일러를 포함하는 소프트웨어 명령을 실행하는 하나 이상의 프로세서에 의해 실행될 수 있다. 프로세스는 도 31의 프로세스와 별도로 또는 함께 이행될 수 있다. 단계 3210에서, 단계 3110과 유사하게, 하나 이상의 프로세서는 고수준 컴퓨터 코드를 수신할 수 있다. 단계 3220에서, 단계 3120과 유사하게, 하나 이상의 프로세서는 고수준 컴퓨터 코드에 의해 접근될 메모리 칩과 연관 된 복수의 메모리 뱅크에 분산된 복수의 메모리 세그먼트를 식별할 수 있다. 단계 3230에서, 하나 이상의 프로세서는 고수준 컴퓨터 코드를 평가하여 복수의 메모리 세그먼트의 하나 이상을 각각 연관시키는 복수의 메모리 읽기 명령을 식별할 수 있다. 예를 들어, 하나 이상의 프로세서는 메모리로부터 의 하나 이상의 읽기 명령 및/또는 메모리로의 하나 이상의 쓰기 명령을 필요로 하는 고수준 컴퓨터 코드 내의 각 연산을 식별할 수 있다. 이러한 명령은 변수 초기화, 변수 재할당, 변수의 논리 연산, 입력-출력 연산 등을 포함할 수 있다. 일부 실시예에서, 하나 이상의 프로세서는 논리 회로 및 복수의 메모리 세그먼트를 활용하여 고수준 코드의 실 행을 시뮬레이션 할 수 있다. 예를 들어, 시뮬레이션은 디버거(debugger) 또는 기타 명령어 집합 시뮬레이터(instruction set simulator 또는 ISS)와 유사하게 고수준 코드의 라인별 스텝스루(line-by-line step- through)를 포함할 수 있다. 디버거(debugger)가 프로세서의 레지스터를 나타내는 내부 변수를 유지하는 것과 유사하게, 시물레이션은 복수의 메모리 세그먼트의 어드레스를 나타내는 내부 변수를 더 유지할 수 있다. 단계 3240에서, 하나 이상의 프로세서는, 메모리 접근 명령의 분석에 의거하고 복수의 메모리 세그먼트의 각 메 모리 세그먼트에 대해, 메모리 세그먼트로의 마지막 접근부터 누적되는 시간의 양을 추적할 수 있다. 예를 들어, 앞서 설명한 시뮬레이션을 활용하여, 하나 이상의 프로세서는 복수의 메모리 세그먼트의 각 세그먼트 이 내의 하나 이상의 어드레스로의 각 접근(예, 읽기 또는 쓰기) 사이의 시간의 길이를 판단할 수 있다. 시간의 길 이는 절대적 시간, 클럭 사이클, 또는 리프레시 사이클(예, 메모리 칩의 알려진 리프레시 속도에 의해 판단)로 측정될 수 있다. 단계 3250에서, 임의의 특정 메모리 세그먼트에 대한 마지막 접근 이후의 시간의 양이 미리 정해진 임계값을 초 과할 것이라는 판단에 대응하여, 하나 이상의 프로세서는 특정 메모리 세그먼트로의 접근을 유발하도록 구성된 메모리 리프레시 명령 및 메모리 접근 명령의 적어도 하나를 고수준 컴퓨터 코드로 도입할 수 있다. 예를 들어, 하나 이상의 프로세서는 리프레시 컨트롤러(예, 도 29a의 리프레시 컨트롤러 또는 도 29b의 리프레시 컨 트롤러(2900'))에 의한 실행을 위한 리프레시 명령을 포함할 수 있다. 논리 회로가 메모리 칩으로서 동일 기판 상에 매립되지 않는 실시예에서, 하나 이상의 프로세서는 메모리 칩으로의 전송을 위한 리프레시 명령을 논리 회로로의 전송을 위한 저수준 코드와 별도로 생성할 수 있다. 추가적으로 또는 대안적으로, 하나 이상의 프로세서는 메모리 컨트롤러(리프레시 컨트롤러와 분리 또는 일체일 수 있음)에 의한 실행을 위한 접근 명령을 포함할 수 있다. 접근 명령은 메모리 세그먼트에 읽기 연산을 촉발하 지만 메모리 세그먼트에 읽기 또는 쓰기가 된 변수에 논리 회로가 더 이상의 연산을 못하게 하도록 구성된 더미 (dummy) 명령을 포함할 수 있다. 일부 실시예에서, 컴파일러는 프로세스와 프로세스의 단계의 조합을 포함할 수 있다. 예를 들면, 컴파일러는 단계 3140에 따른 변수를 배정한 후에 상기에 설명한 시뮬레이션을 실행하여 단계 3250에 따른 모든 임의의 추가적인 메모리 리프레시 명령 또는 메모리 접근 명령을 추가할 수 있다. 이러한 조합으로, 컴파일러는 최대한 많은 메모리 세그먼트로 변수를 분산하고 미리 정해진 임계 시간의 양 이내에 접근될 수 없는 모든 임의 의 메모리 세그먼트에 대한 리프레시 또는 접근 명령을 생성할 수 있다. 다른 조합의 예에서, 컴파일러는 단계 3230에 따른 코드를 시뮬레이션 하고, 미리 정해진 임계 시간의 양 이내에 접근되지 않을 것으로 시뮬레이션에 서 나타난 모든 임의의 세그먼트에 의거하여 단계 3140에 따른 변수를 배정할 수 있다. 일부 실시예에서, 이러 한 조합은 단계 3250을 더 포함하여, 단계 3140에 따른 배정이 완료된 후라도, 미리 정해진 임계 시간의 양 이 내에 접근될 수 없는 메모리 세그먼트에 대한 리프레시 또는 접근 명령을 컴파일러가 생성할 수 있다. 본 개시의 리프레시 컨트롤러로 인해, 논리회로(CPU 및 GPU와 같은 종래의 논리 회로 또는 도 7a에 도시된 바와 같은 메모리 칩으로서 동일 기판 상의 프로세싱 그룹)에 의해 실행되는 소프트웨어는 리프레시 컨트롤러에 의해 실행되는 자동 리프레시를 비활성화 하고, 대신에 실행되는 소프트웨어를 통해 리프레시를 제어할 수 있다. 이 에 따라, 본 개시의 일부 실시예는 공지의 메모리 칩 접근 패턴을 가진 소프트웨어를 제공할 수 있다(예, 컴파 일러가 복수의 메모리 뱅크를 한정하는 데이터 구조 또는 메모리 칩의 상응하는 구조로 접근이 되는 경우). 이 러한 실시예에서, 포스트 컴파일링 옵티마이저(post-compiling optimizer)는 자동 리프레시를 비활성화 하고 임 계 시간의 양 이내에 접근되지 않은 메모리 칩의 세그먼트에 대해서만 수동으로 리프레시 제어를 설정할 수 있 다. 따라서, 앞서 설명한 단계 3250과 유사하지만 컴파일링 이후에, 포스트 컴파일링 옵티마이저는 각 메모리 세그먼트가 반드시 미리 정해진 임계 시간의 양으로 접근 또는 리프레시 되도록 하는 리프레시 명령을 생성할 수 있다. 리프레시 사이클을 감소시키는 다른 예로 메모리 칩으로의 미리 정의된 패턴의 접근을 활용할 수 있다. 예를 들 어, 논리 회로에 의해 실행되는 소프트웨어가 메모리 칩에 대한 접근 패턴을 제어할 수 있는 경우에, 일부 실시 예는 종래의 선형 라인 리프레시 이상의 리프레시를 위한 접근 패턴을 생성할 수 있다. 예를 들면, 컨트롤러의 판단에 논리 회로에 의해 실행되는 소프트웨어가 메모리의 2행마다 정기적으로 접근하는 경우, 본 개시의 리프 레시 컨트롤러는 메모리 칩의 속도를 증가하고 전력 소모를 감소하기 위하여 2 라인마다 리프레시를 하지 않는 접근 패턴을 사용할 수 있다. 이러한 리프레스 컨트롤러의 일례가 도 33에 도시되어 있다. 도 33은 본 개시에 따른 저장된 패턴에 의해 구성 된 예시적인 리프레시 컨트롤러를 도시한 것이다. 리프레시 컨트롤러는 본 개시의 메모리 칩에 포 함될 수 있다. 예를 들어, 복수의 메모리 뱅크와 복수의 메모리 세그먼트가 도 28의 메모리 칩과 같은 복수의 메모리 뱅크의 각각에 포함되게 할 수 있다. 리프레시 컨트롤러는 타이머(도 29a와 도 29b의 타이머와 유사), 로우 카운터(도 29a 와 도 29b의 로우 카운터와 유사), 및 합산기(도 29a와 도 29b의 합산기와 유사)를 포함한다. 또한, 리프레시 컨트롤러는 데이터 스토리지를 포함한다. 도 29b의 데이터 스토리지 와 달리, 데이터 스토리지는 복수의 메모리 뱅크의 각각에 포함된 복수의 메모리 세그먼트의 리프 레시에서 이행될 적어도 하나의 메모리 리프레시 패턴을 포함할 수 있다. 예를 들어, 도 33에 도시된 바와 같이, 데이터 스토리지는 메모리 뱅크의 세그먼트를 행 및/또는 열로 구분하는 Li(예, 도 33의 예에서 L1, L2, L3, L4) 및 Hi(예, 도 33의 예에서 H1, H2, H3, H4)를 포함할 수 있다. 또한, 각 세그먼트는 세그먼트 와 연관된 행이 증가되는 방식(예, 각 행이 접근 또는 리프레시 되는지 여부, 한 항씩 건너서 접근 또는 리프레 시 되는지 여부 등)을 정의하는 Inci 변수(예, 도 33의 예에서 Inc1, Inc2, Inc3, Inc4)와 연관될 수 있다. 따 라서, 도 33에 도시된 바와 같이, 리프레시 패턴은 리프레시 사이클 동안에 리프레시 될 특정 메모리 뱅크 내의 복수의 메모리 세그먼트의 범위 및 리프레시 사이클 동안에 리프레시 되지 않을 특정 메모리 뱅크의 복수의 메 모리 세그먼트의 범위를 식별하게 소프트웨어에 의해 배정되는 복수의 메모리 세그먼트 식별자를 포함하는 테이 블을 포함할 수 있다. 따라서, 데이터 스토리지는 논리 회로(CPU 및 GPU와 같은 종래의 논리 회로 또는 도 7a에 도시된 바와 같 은 메모리 칩으로서 동일 기판 상의 프로세싱 그룹)에 의해 실행되는 소프트웨어가 사용하기로 선택할 수 있는 리프레시 패턴을 정의할 수 있다. 메모리 리프레시 패턴은 리프레시 사이클 동안에 특정 메모리 뱅크 내의 복수 의 메모리 세그먼트 중에서 어느 메모리 세그먼트가 리프레시 될지 및 리프레시 사이클 동안에 특정 메모리 뱅 크의 복수의 메모리 세그먼트 중에서 어느 메모리 세그먼트가 리프레시 되지 않을지를 식별하게 소프트웨어를 활용하여 구성 가능할 수 있다. 따라서, 리프레시 컨트롤러는 Inci에 따라 현재 사이클 동안에 접근되지 않는 정의된 세그먼트 내의 일부 또는 모든 행을 리프레시 할 수 있다. 리프레시 컨트롤러는 현재 사이클 동안에 접근되도록 설정된 정의된 세그먼트의 다른 행을 건너뛸 수 있다. 리프레시 컨트롤러의 데이터 스토리지가 복수의 메모리 리프레시 패턴을 포함하는 실시예에서, 각 메모리 리프레시 패턴은 복수의 메모리 뱅크의 각각에 포함된 복수의 메모리 세그먼트의 리프레시를 위한 상이 한 리프레시 패턴을 나타낼 수 있다. 메모리 리프레시 패턴은 복수의 메모리 세그먼트 상의 사용을 위해 선택 가능할 수 있다. 이에 따라, 리프레시 컨트롤러는 특정 리프레시 사이클 동안에 복수의 메모리 리프레시 패턴 중에서 이행할 메모리 리프레시 패턴의 선택이 가능하도록 구성될 수 있다. 예를 들어, 논리 회로(CPU 및 GPU와 같은 종래의 논리 회로 또는 도 7a에 도시된 바와 같은 메모리 칩으로서 동일 기판 상의 프로세싱 그룹) 에 의해 실행되는 소프트웨어는 하나 이상의 상이한 리프레시 사이클 동안에 사용될 상이한 메모리 리프레시 패 턴을 선택할 수 있다. 대안적으로, 논리 회로에 의해 실행되는 소프트웨어는 상이한 리프레시 사이클의 일부 또 는 전체 동안에 사용할 하나의 메모리 리프레시 패턴을 선택할 수 있다. 메모리 리프레시 패턴은 데이터 스토리지에 저장된 하나 이상의 변수를 활용하여 인코딩 될 수 있다. 예 를 들어, 복수의 메모리 세그먼트가 행으로 배열된 실시예에서, 각 메모리 세그먼트 식별자는 메모리 리프레시 가 시작 또는 종료되어야 하는 메모리의 행 이내의 특정 위치를 식별하도록 구성될 수 있다. 예를 들어, Li와 Hi 외에, 하나 이상의 추가적인 변수가 Li와 Hi에 의해 정의된 행의 어느 부분이 세그먼트 이내인지 정의할 수 있다. 도 34는 메모리 칩(예, 도 28의 메모리 칩)에 대한 리프레시를 판단하기 위한 프로세스의 예시적인 순서도이다. 프로세스는 본 개시에 따른 리프레시 컨트롤러(예, 도 33의 리프레시 컨트롤러) 내의 소프트웨어에 의해 이행될 수 있다. 단계 3410에서, 리프레시 컨트롤러는 복수의 메모리 뱅크의 각각에 포함된 복수의 메모리 세그먼트의 리프레시 에 이행될 적어도 하나의 메모리 리프레시 패턴을 저장할 수 있다. 예를 들어, 앞서 도 33을 참조하여 설명한 바와 같이, 리프레시 패턴은 리프레시 사이클 동안에 리프레시 될 특정 메모리 뱅크 내의 복수의 메모리 세그먼 트의 범위 및 리프레시 사이클 동안에 리프레시 되지 않을 특정 메모리 뱅크의 복수의 메모리 세그먼트의 범위 를 식별하게 소프트웨어에 의해 배정되는 복수의 메모리 세그먼트 식별자를 포함하는 테이블을 포함할 수 있다. 일부 실시예에서, 적어도 하나의 리프레시 패턴은 제조시에 리프레시 컨트롤러 상으로(예, 리프레시 컨트롤러와 연관되거나 리프레시 컨트롤러에 의해 적어도 접근될 수 있는 ROM 상으로) 인코딩 될 수 있다. 이에 따라, 리프 레시 컨트롤러는 적어도 하나의 리프레시 패턴에 접근하지만 이 리프레시 패턴을 저장하지 않을 수 있다.단계 3420과 단계 3430에서, 리프레시 컨트롤러는 소프트웨어를 활용하여 리프레시 사이클 동안에 특정 메모리 뱅크 내의 복수의 메모리 세그먼트 중에서 어느 메모리 세그먼트가 리프레시 될지 및 리프레시 사이클 동안에 특정 메모리 뱅크의 복수의 메모리 세그먼트 중에서 어느 메모리 세그먼트가 리프레시 되지 않을지를 식별할 수 있다. 예를 들면, 앞서 도 33을 참조하여 설명한 바와 같이, 논리 회로(CPU 및 GPU와 같은 종래의 논리 회로 또 는 도 7a에 도시된 바와 같은 메모리 칩으로서 동일 기판 상의 프로세싱 그룹)에 의해 실행되는 소프트웨어는 적어도 하나의 메모리 리프레시 패턴을 선택할 수 있다. 또한, 리프레시 컨트롤러는 선택된 적어도 하나의 메모 리 리프레시 패턴에 접근하여 각 리프레시 사이클 동안에 상응하는 리프레시 신호를 생성할 수 있다. 리프레시 컨트롤러는 적어도 하나의 리프레시 패턴에 따라 현재 리프레시 사이클 동안에 접근되지 않은 정의된 세그먼트 이내의 일부 또는 전체 부분을 리프레시 하고, 현재 사이클 동안에 접근되기로 설정된 정의된 세그먼트의 다른 부분을 건너뛸 수 있다. 단계 3440에서, 리프레시 컨트롤러는 상응하는 리프레시 명령을 생성할 수 있다. 예를 들어, 도 33에 도시된 바 와 같이, 합산기는 데이터 스토리지 내의 적어도 하나의 메모리 리프레시 패턴에 따라 리프레시 되 지 않을 특정 세그먼트에 대한 리프레시 신호를 무효로 하도록 구성된 논리 회로를 포함할 수 있다. 추가적으로 또는 대안적으로, 마이크로프로세서(도 33에는 미도시)가 데이터 스토리지 내의 적어도 하나의 메모리 리 프레시 패턴에 따라 어느 세그먼트가 리프레시 되어야 하는지에 의거하여 특정 리프레시 신호를 생성할 수 있다. 방법은 추가적인 단계를 더 포함할 수 있다. 예를 들어, 적어도 하나의 메모리 리프레시 패턴이 1, 2, 또 는 기타 수의 리프레시 사이클마다 변화하도록(예, 도 33에 도시된 바와 같이 L1, H1, Inc1에서 L2, H2, Inc2로 이동) 구성된 실시예에서, 리프레시 컨트롤러는 단계 3430과 단계 3440에 따른 리프레시 신호의 다음 판단을 위 해 데이터 스토리지의 상이한 부분에 접근할 수 있다. 이와 유사하게, 논리 회로(CPU 및 GPU와 같은 종래의 논 리 회로 또는 도 7a에 도시된 바와 같은 메모리 칩으로서 동일 기판 상의 프로세싱 그룹)에 의해 실행되는 소프 트웨어가 하나 이상의 추후 리프레시 사이클에서의 사용을 위해 데이터 스토리지에서 새로운 메모리 리프레시 패턴을 선택하는 경우, 리프레시 컨트롤러는 단계 3430과 단계 3440에 따른 리프레시 신호의 다음 판단을 위해 데이터 스토리지의 상이한 부분에 접근할 수 있다. 선택적 크기의 메모리 칩 메모리 칩을 설계하고 메모리의 특정 용량을 목표로 하는 경우, 메모리 용량의 증가 또는 축소의 변화를 하려면 제품 및 전체 마스크 세트를 재설계해야 할 수 있다. 종종, 제품 설계와 시장 조사는 동시에 이루어지고, 경우 에 따라 시장 조사가 가능하기 전에 제품 설계가 끝나기도 한다. 따라서, 제품 설계와 시장의 실제 수요 사이에 괴리가 있을 수 있다. 본 개시는 시장 수요에 상응하는 메모리 용량의 메모리 칩을 유연하게 제공하는 방법을 제시한다. 설계 방법은 적절한 인터커넥트(interconnect) 회로와 함께 다이를 설계하여, 단일 웨이퍼로부터 가 변 크기의 메모리 용량의 메모리 칩을 생산하는 기회를 제공하기 위하여, 하나 이상의 다이를 포함할 수 있는 메모리 칩이 웨이퍼로부터 선택적으로 절단되게 할 수 있다. 본 개시는 웨이퍼로부터 메모리 칩을 절단하여 메모리 칩을 제조하는 시스템 및 방법에 관한 것이다. 본 방법은 웨이퍼로부터 선택적 크기의 메모리 칩을 생산하는데 활용될 수 있다. 다이를 포함하는 웨이퍼의 예시적인 실시예가 도 35a에 도시되어 있다. 웨이퍼는 반도체 물질(예, 실리콘(Si), 실리콘 게르마늄 (SiGe), SOI(silicon on insulator), 질화 갈륨(GaN), 질화 알루미늄(AlN), 알루미늄 질화 갈륨(AlGaN), 질화 붕소(BN), 갈륨 비소(GaAs), 갈륨 알루미늄 비소(AlGaAs), 질화 인듐(InN), 및 그 조합 등)로부터 형성될 수 있 다. 다이는 모든 임의의 적합한 반도체, 유전체, 또는 금속 성분을 포함할 수 있는 모든 임의의 적합한 회로 요소(예, 트랜지스터, 커패시터, 저항 등)를 포함할 수 있다. 다이는 웨이퍼의 물질과 동일하 거나 상이할 수 있는 반도체 물질로 형성될 수 있다. 다이 외에도, 웨이퍼는 다른 구조 및/또는 회 로를 포함할 수 있다. 일부 실시예에서, 하나 이상의 결합 회로가 제공될 수 있고 다이 중의 하나 이상을 서로 결합할 수 있다. 예시적인 실시예에서, 이러한 결합 회로는 둘 이상의 다이에 의해 공유되는 버스를 포함 할 수 있다. 추가적으로, 결합 회로는 다이와 연관된 회로를 제어 및/또는 다이로 정보를 제공 및 다이로부터 정보를 가져오도록 설계된 하나 이상의 논리 회로를 포함할 수 있다. 일부 경우에서, 결합 회 로는 메모리 접근 관리 로직을 포함할 수 있다. 이러한 로직은 논리적 메모리 어드레스를 다이와 연관된 물리적 어드레스로 변환할 수 있다. 여기서, '제조'라는 용어는 개시된 웨이터, 다이, 및/또는 칩을 구성하는 모든 단계를 통칭할 수 있다. 예를 들어, 제조는 웨이퍼 상에 포함된 다양한 다이(및 모든 임의의 기타 회로)의 동시 레이아웃과 형성을 의미할 수 있다. 제조는 또한 경우에 따라 하나의 다이 또는 다수의 다이를 포함하도록 웨이퍼로부터 선택적 크기의 메모리 칩을 절단하는 것을 의미할 수 있다. 물론, 제조라는 용어는 이러한 예에제한되지 않으며 개시된 메모리 칩 및 그 중간 구조의 일부 또는 전체의 생성과 연관된 다른 측면을 포함할 수 있다. 메모리 칩의 제조를 위해 다이 또는 한 그룹의 다이를 사용할 수 있다. 메모리 칩은 본 개시의 다른 부분 에서 설명한 바와 같이 분산 프로세서를 포함할 수 있다. 도 35b에 도시된 바와 같이, 다이는 기판 및 기판 상에 배치된 메모리 어레이를 포함할 수 있다. 메모리 어레이는 데이터를 저장하도록 설계된 메모리 뱅 크(3511A-3511D) 등과 같은 하나 이상의 메모리 유닛을 포함할 수 있다. 다양한 실시예에서, 메모리 뱅크는 트 랜지스터, 커패시터 등과 같은 반도체 기반 회로 요소를 포함할 수 있다. 예시적인 일 실시예에서, 메모리 뱅크 는 저장 장치의 다중 행과 열을 포함할 수 있다. 일부의 경우에서, 이러한 메모리 뱅크의 용량은 1 메가바이트 이상일 수 있다. 메모리 뱅크는 DRAM 또는 SRAM을 포함할 수 있다. 다이는 기판 상에 배치된 프로세싱 어레이를 더 포함할 수 있고, 프로세싱 어레이는 도 35b에 도시된 바 와 같이 복수의 프로세서 서브유닛(3515A-3515D)을 포함할 수 있다. 앞서 설명한 바와 같이, 각 메모리 뱅크는 전용 버스에 의해 연결된 전용 프로세서 서브유닛을 포함할 수 있다. 예를 들어, 프로세서 서브유닛(3515A)은 버스 또는 연결을 통해 메모리 뱅크(3511A)와 연관된다. 여기서, 메모리 뱅크(3511A-3511D)와 프로세서 서브유닛(3515A-3515D) 사이에 다양한 연결이 가능하고, 도 35b에는 그 중의 일부 연결만이 도시되어 있음은 당 연하다 할 것이다. 예시적인 일 실시예에서, 프로세서 서브유닛은 연관된 메모리 뱅크에 대해 읽기/쓰기 동작을 수행할 수 있고, 다양한 메모리 뱅크에 저장된 메모리에 관한 리프레시 동작 또는 기타 적절한 동작을 더 수행 할 수 있다. 다이는 프로세서 서브유닛을 상응하는 메모리 뱅크와 연결시키도록 구성된 제1 그룹의 버스를 포함할 수 있다. 예시적인 버스는 전기 요소를 연결하고 각 메모리 뱅크와 그 연관 프로세서 서브유닛 사이에 데이터와 어 드레스의 전송을 허용하는 전선 또는 컨덕터의 집합을 포함할 수 있다. 예시적인 실시예에서, 연결은 프 로세서 서브유닛(3515A)을 메모리 뱅크(3511A)로 연결하기 위한 전용 버스의 역할을 할 수 있다. 다이는 한 그룹의 이러한 버스를 포함할 수 있고, 각 버스는 프로세서 서브유닛을 상응하는 전용 메모리 뱅크로 연결할 수 있다. 또한, 다이는 다른 그룹의 버스를 포함할 수 있고, 각 버스는 프로세서 서브유닛(예, 서브유닛 (3515A-3515D))을 서로 연결할 수 있다. 예를 들어, 이러한 버스는 연결(3516A-3516D)을 포함할 수 있다. 다양 한 실시예에서, 메모리 뱅크(3511A-3511D)를 위한 데이터는 입력-출력 버스를 통해 전달될 수 있다. 예시 적인 일 실시예에셔, 입력-출력 버스는 데이터 관련 정보 및 다이의 메모리 유닛의 동작을 제어하 기 위한 명령 관련 정보를 전달할 수 있다. 데이터 정보는 메모리 뱅크에 저장하기 위한 데이터, 메모리 뱅크에 서 읽은 데이터, 상응하는 메모리 뱅크에 저장된 데이터에 대해 수행된 동작에 의거한 하나 이상의 프로세서 서 브유닛으로부터의 프로세싱 결과, 명령 관련 정보, 다양한 코드 등을 포함할 수 있다. 다양한 경우에서, 입력-출력 버스에 의해 전송된 데이터 및 명령은 입력-출력(IO) 컨트롤러에 의 해 제어될 수 있다. 예시적인 일 실시예에서, IO 컨트롤러는 버스와 프로세서 서브유닛(3515A- 3515D) 사이의 데이터의 흐름을 제어할 수 있다. IO 컨트롤러는 프로세서 서브유닛(3515A-3515D) 중의 어 느 서브유닛에서 정보를 가져올 것인지를 판단할 수 있다. 다양한 실시에에서, IO 컨트롤러는 IO 컨트롤 러를 비활성화 하도록 구성된 퓨즈를 포함할 수 있다. 퓨즈는 다수의 다이를 함께 합쳐서 더 큰 메모리 칩(단일 다이만을 포함하는 단일 다이 메모리 칩에 대한 상대적인 용어로 멀티 다이 메모리 칩으로도 지칭함)을 형성하는 경우에 사용될 수 있다. 이후, 멀티 다이 메모리 칩은 멀티 다이 메모리 칩을 형성하는 다 이 유닛 중의 하나의 IO 컨트롤러의 하나를 사용하고, 다른 IO 컨트롤러에 상응하는 퓨즈를 사용하여 다른 다이 유닛과 연관된 다른 IO 컨트롤러를 비활성화 할 수 있다. 각 메모리 칩 또는 프로세서 다이 또는 다이의 그룹은 상응하는 메모리 뱅크와 연관된 분산 프로세서를 포함할 수 있다. 일부 실시예에서, 이러한 분산 프로세서는 복수의 메모리 뱅크로서 동일 기판 상에 배치된 프로세싱 어레이로 배열될 수 있다. 또한, 프로세싱 어레이는 각각이 어드레스 생성기(어드레스 생성 장치(AGU)로도 지칭)를 포함하는 하나 이상의 논리부를 포함할 수 있다. 일부 경우에서, 어드레스 생성기는 적어도 하나의 프 로세서 서브유닛의 일부일 수 있다. 어드레스 생성기는 메모리 칩과 연관된 하나 이상의 메모리 뱅크로부터 데 이터를 가져오기 위해 필요한 메모리 어드레스를 생성할 수 있다. 어드레스 생성 계산은 덧셈, 뺄셈, 모듈로 연 산, 또는 비트 이동과 같은 정수 산술 연산을 포함할 수 있다. 어드레스 생성기는 한 번에 여러 피연산자를 연 산하도록 구성될 수 있다. 또한, 다중 어드레스 생성기가 동시에 하나 시상의 어드레스 계산 연산을 수행할 수 있다. 다양한 실시예에서, 어드레스 생성기는 상응하는 메모리 뱅크와 연관될 수 있다. 어드레스 생성기는 상응 하는 버스 라인을 통해 상응하는 메모리 뱅크와 연결될 수 있다.다양한 실시예에서, 웨이퍼의 상이한 영역을 선택적으로 절단하여 웨이퍼로부터 선택 가능 사이즈 의 메모리 칩을 형성할 수 있다. 설명한 바와 같이, 웨이퍼는 한 그룹의 다이를 포함할 수 있고, 이 그룹 은 웨이퍼 상에 포함된 둘 이상의 다이(예, 2, 3, 4, 5, 10, 또는 그 이상의 다이)의 그룹을 포함할 수 있다. 하기에 상세히 설명하는 바와 같이, 일부 경우에서, 한 그룹의 다이의 하나의 다이만을 포함하는 웨이퍼의 부분 을 절단하여 단일 메모리 칩이 형성될 수 있다. 이러한 경우, 그 결과의 메모리 칩은 한 다이와 연관된 메모리 칩을 포함할 수 있다. 반면, 다른 경우에서, 선택 가능 사이즈의 메모리 칩이 하나 이상의 다이를 포함하게 형 성될 수 있다. 이러한 메모리 칩은 웨이퍼 상에 포함된 한 그룹의 다이의 둘 이상의 다이를 포함하는 웨이퍼의 영역을 절단하여 형성될 수 있다. 이러한 경우, 다이는 다이를 서로 결합시키는 결합 회로와 함께 멀티 다이 메 모리 칩을 제공한다. 클럭 요소, 데이터 버스, 또는 모든 임의의 적절한 논리 회로와 같은 일부 회로 요소가 또 한 칩 사이에 추가적으로 연결될 수 있다. 일부 경우에서, 다이 그룹과 연관된 적어도 하나의 컨트롤러는 다이 그룹의 동작을 단일 메모리 칩(예, 다중 메 모리 유닛 메모리 칩)으로 제어하도록 구성될 수 있다. 컨트롤러는 메모리 칩과의 데이터 흐름을 관리하는 하나 이상의 회로를 포함할 수 있다. 메모리 컨트롤러는 메모리 칩의 일부이거나 메모리 칩과 직접 연관되지 않는 별 도의 칩의 일부일 수 있다. 예시적인 일 실시예에서, 컨트롤러는 메모리 칩의 분산 프로세서와 연관된 읽기 및 쓰기 요청 또는 기타 명령을 가능하게 하도록 구성될 수 있고, 메모리 칩의 모든 임의의 다른 측면(에, 메모리 칩의 리프레시, 분산 프로세서와의 상호 작용 등)을 제어하도록 구성될 수 있다. 일부 경우에서, 컨트롤러는 다 이의 일부일 수 있고, 다른 경우에서, 컨트롤러는 다이에 인접하여 레이아웃 될 수 있다. 다양한 실시예에서, 컨트롤러는 또한 메모리 칩 상에 포함된 적어도 하나의 메모리 유닛의 적어도 하나의 메모리 컨트 롤러를 포함할 수 있다. 일부 경우에서, 메모리 칩 상의 정보에 접근하기 위해 사용되는 프로토콜은 메모리 칩 상에 존재할 수 있는 복제 로직 및 메모리 유닛(예, 메모리 뱅크)과 무관할 수 있다. 프로토콜은 메모리 칩 상 의 데이터의 적절한 접근을 위해 상이한 ID 또는 어드레스 범위를 가지도록 구성될 수 있다. 이러한 프로토콜을 가진 칩의 예로, 상이한 메모리 뱅크에 상이한 어드레스 범위가 있는 JEDEC(Joint Electron Device Engineering Council) 더블 데이터 레이트(DDR) 컨트롤러, 상이한 메모리 유닛(예, 메모리 뱅크)에 상이한 ID가 있는 SPI(serial peripheral interface) 등을 가진 칩이 있을 수 있다. 다양한 실시예에서, 다중 영역이 웨이퍼에서 절단될 수 있고, 여기서 다양한 영역은 하나 이상의 다이를 포함할 수 있다. 일부 경우에서, 각 별도의 영역은 멀티 다이 메모리 칩의 형성에 사용될 수 있다. 일부 경우에서, 둘 이상의 영역이 동일한 형상일 수 있고, 동일한 수의 다이가 동일한 방식으로 결합 회로에 결합될 수 있다. 대안 적으로, 예시적인 일 실시예에서, 제1 그룹의 영역이 제1 유형의 메모리 칩의 형성에 활용되고, 제2 그룹의 영 역이 제2 유형의 메모리 칩의 형성에 활용될 수 있다. 예를 들어, 도 35c에 도시된 바와 같은 웨이퍼은 단일 다이를 포함할 수 있는 영역을 포함할 수 있고, 제2 영역은 두 개의 다의의 그룹을 포함할 수 있다. 영역 웨이퍼에서 절단되는 경우, 단일 다이 메모리 칩이 제공되게 된다. 영역이 웨이 퍼에서 절단되는 경우, 멀티 다이 메모리 칩이 제공되게 된다. 도 35c에 도시된 그룹들은 예시에 불과하 고, 다양한 다른 영역과 다이 그룹이 웨이퍼에서 절단될 수 있다. 다양한 실시예에서, 다이는 웨이퍼에서 형성되어, 예를 들어 도 35c에 도시된 바와 같이, 다이는 웨이퍼 의 하나 이상의 행을 따라 배열될 수 있다. 다이는 하나 이상의 행에 상응하는 입력-출력 버스를 공유할 수 있다. 예시적인 일 실시예에서, 다이의 그룹은 다양한 절단 형상을 사용하여 웨이퍼에서 절단될 수 있 고, 여기서, 메모리 칩의 형성에 활용될 수 있는 다이의 그룹을 절단하는 경우, 공유 입력-출력 버스의 적어도 일부분은 제외될 수 있다(예, 입력-출력 버스의 일부만이 다이의 그룹을 포함하여 형성되는 메모 리 칩의 일부로 포함될 수 있다). 앞서 설명한 바와 같이, 다수의 다이(예, 도 35c에 도시된 다이(3506A 및 3506B))를 사용하여 메모리 칩 을 형성하는 경우, 다이 중의 하나에 상응하는 하나의 IO 컨트롤러가 활성화되고 다이(3506A 및 3506B)의 모든 프로세서 서브유닛으로의 데이터 흐름을 제어하도록 구성될 수 있다. 예를 들어, 도 35d에는 메모리 뱅크 (3511A-3511H), 프로세서 서브유닛(3515A-3515H), IO 컨트롤러(3521A, 3521B), 및 퓨즈(3554A, 3554B)를 포함 하는 메모리 칩을 형성하기 위해 조합된 다이(3506A 및 3506B)가 도시되어 있다. 여기서, 메모리 칩 은 웨이퍼로부터 메모리 칩을 제거하기 전에 웨이퍼의 영역에 상응한다. 즉, 본 개시에서, 일단 웨이퍼에서 절단된 웨이퍼의 영역(3504, 3505, 3517 등)은 메모리 칩(3504, 3505, 3517 등) 이 되게 된다. 또한, 여기서 퓨즈는 비활성화 요소를 말하기도 한다. 예시적인 일 실시예에서, 퓨즈(3554B)는 IO 컨트롤러(3521B)를 비활성화 하는데 사용될 수 있고, IO 컨트롤러(3521A)는 프로세서 서브유닛(3515A- 3515H)과 데이터를 주고받음으로써 모든 메모리 뱅크(3511A-3511H)로의 데이터 흐름을 제어하는데 사용될 수 있다. 예시적인 일 실시예에서, IO 컨트롤러(3521A)는 모든 임의의 적절한 연결을 활용하여 다양한 프로세서 서브 유닛과 연결될 수 있다. 일부 실시예에서, 하기에 더 설명하는 바와 같이, 프로세서 서브유닛(3515A-3515H)은 상호 연결될 수 있고, IO 컨트롤러(3521A)는 메모리 칩의 프로세싱 로직을 형성하는 프로세서 서브유닛 (3515A-3515H)으로의 데이터 흐름을 제어하도록 구성될 수 있다. 예시적인 일 실시예에서, 컨트롤러(3521A 및 3521B)와 같은 IO 컨트롤러 및 상응하는 퓨즈(3554A 및 3554B)는 메모리 뱅크(3511A-3511H) 및 프로세서 서브유닛(3515A-3515H)의 형성과 함께 웨이퍼 상에 형성될 수 있 다. 다양한 실시예에서, 메모리 칩을 형성할 때에, 단일 칩으로 기능하고 단일 입력-출력 컨트롤러(예, 컨트롤러(3521A))에 의해 제어되는 메모리 칩을 다이(3506A 및 3506B)가 형성하도록 구성되도록 퓨즈 중 의 하나(예, 퓨즈(3554B))가 비활성화 될 수 있다. 예시적인 일 실시예에서, 퓨즈의 활성화는 전류를 인가하여 퓨즈를 촉발하는 것을 포함할 수 있다. 다양한 실시예에서, 메모리 칩의 형성을 위해 하나 이상의 다이가 사용 되는 경우에, 하나의 IO 컨트롤러를 제외한 모든 IO 컨트롤러는 상응하는 퓨즈를 통해 비활성화 될 수 있다. 다양한 실시예에서, 도 35c에 도시된 바와 같이, 다수의 다이가 한 세트의 입력-출력 버스 및/또는 컨트롤 버스 와 함께 웨이퍼 상에 형성된다. 예시적인 입력-출력 버스가 도 35c에 도시되어 있다. 예시적인 일 실시예에서, 입력-출력 버스 중의 하나(예, 입력-출력 버스)가 여러 다이에 연결될 수 있다. 도 35c에는 다이(3506A 및 3506B) 옆을 지나가는 입력-출력 버스의 예시적인 일 실시예가 도시되어 있다. 도 35c에 도시된 바와 같은 다이(3506A 및 3506B) 및 입력-출력 버스의 구성은 예시에 불과하고, 다양한 다른 구성 이 사용될 수도 있다. 예를 들어, 도 35e는 웨이퍼 상에 형성되고 육각형 대형으로 배열된 다이가 도시하고 있다. 예시적인 일 실시예에서, 4개의 다이를 포함하는 메모리 칩이 웨이퍼에서 절 단될 수 있다. 예시적인 일 실시예에서, 메모리 칩은 적절한 버스 라인(예, 도 35e에 도시된 라인(353 3))에 의해 4개의 다이로 연결된 입력-출력 버스의 일부분을 포함할 수 있다. 정보를 메모리 칩의 적절한 메모리 유닛으로 전달하기 위하여, 메모리 칩은 입력-출력 버스에 대한 분기점에 배치된 입 력/출력 컨트롤러(3542A 및 3542B)를 포함할 수 있다. 컨트롤러(3542A 및 3542B)는 입력-출력 버스를 통 해 명령 데이터를 수신하고 적절한 메모리 유닛으로 정보를 전송하기 위한 버스의 분기를 선택할 수 있다. 예를 들면, 명령 데이터가 다이와 연관된 메모리 유닛에서의 읽기/쓰기 정보를 포함하는 경우, 컨 트롤러(3542A)는 명령 요청을 수신하고 데이터를 도 35d에 도시된 버스의 분기(3531A)로 전송하는 반면, 컨트롤러(3542B)는 명령 요청을 수신하고 데이터를 분기(3531B)로 전송할 수 있다. 도 35e에는 파선으로 절단선 을 표현하여 상이한 영역의 다양한 절단이 이루어질 수 있음이 도시되어 있다. 예시적인 일 실시예에서, 한 그룹의 다이 및 상호 연결 회로가 도 36a에 도시된 것과 같은 메모리 칩에 포함되도록 설계될 수 있다. 이러한 실시예는 사로 통신하도록 구성될 수 있는 프로세서 서브유닛을 포함할 수 (인메모리 프로세싱을 위해) 있다. 예를 들어, 메모리 칩에 포함될 각 다이는 메모리 뱅크(3511A-3511D), 프로세서 서브유닛(3515A-3515D), 및 IO 컨트롤러(3521 및 3522)와 같은 다양한 메모리 유닛을 포함할 수 있다. IO 컨트롤러(3521 및 3522)는 입력-출력 버스와 병렬로 연결될 수 있다. IO 컨트롤러에는 버스 가 있을 수 있고, IO 컨트롤러에는 버스가 있을 수 있다. 예시적인 일 실시예에서, 프로세서 서브유닛(3515A-3515D)은 예를 들어 버스를 통해 연결될 수 있다. 일부 경우에서, IO 컨트롤러 중의 하나 는 상응하는 퓨즈를 사용하여 비활성화 될 수 있다. 예를 들어, IO 컨트롤러는 퓨즈를 활용하여 비 활성화 될 수 있고, IO 컨트롤러는 버스를 통해 서로 연결된 프로세서 서브유닛(3515A-3515D)을 통 한 메모리 뱅크(3511A-3511D)로의 데이터 흐름을 제어할 수 있다. 도 36a에 도시된 바와 같은 메모리 유닛의 구성은 예시에 불과하고, 웨이퍼의 상이한 영역을 절단함으로 써 다양한 다른 구성이 형성될 수 있다. 예를 들면, 도 36b에는 메모리 유닛을 포함하고 입력-출력 버스 에 연결된 3개의 영역(3601-3603)을 가진 구성이 도시되어 있다. 예시적인 일 실시예에서, 영역(3601-3603)은 상응하는 퓨즈(3554-3556)에 의해 비활성화 될 수 있는 IO 컨트롤 모듈(3521-3523)을 활용하여 입력-출력 버스 로 연결된다. 메모리 유닛을 포함하는 영역을 배열하는 실시예의 다른 예가 도 36c에 도시되어 있고, 여 기서 3개의 영역(3601, 3602, 3603)이 버스 라인(3611, 3612, 3613)을 활용하여 입력-출력 버스로 연결 된다. 도 36d는 IO 컨트롤러(3521-3524)를 통해 입력-출력 버스(3530A 및 3530B)에 연결된 메모리 칩(3506A- 3506D)의 다른 예시적인 실시예를 도시한 것이다. 예시적인 일 실시예에서, IO 컨트롤러는 도 36d에 도시된 바 와 같이 상응하는 퓨즈를 활용하여 비활성화 될 수 있다. 도 37은 하나 이상의 다이를 포함할 수 있는 그룹 및 그룹과 같은 다이의 다양한 그룹 을 도시하고 있다. 예시적인 일 실시예에서, 웨이퍼 상에 다이를 형성하는 것 외에도, 웨이퍼 는 글루 로직으로 불리는 논리 회로도 포함할 수 있다. 글루 로직은 웨이퍼 상의 공간을 일부 차지함으로써 웨이퍼 당 제조되는 다이의 수가 글루 로직이 없이 제조하는 경우보 다 적어지는 결과를 가져올 수 있다. 그러나 글루 로직이 있음으로써 다수의 다이가 단일 메모리 칩으로 기능하도록 구성되게 할 수 있다. 예컨대, 글루 로직은 구성을 변경하지 않고 다이 내부의 영역을 다이끼리 연 결하기 위해서만 사용되는 회로를 위해 지정하지 않고 다수의 다이를 연결할 수 있다. 다양한 실시예에서, 글루 로직은 다른 메모리 컨트롤러와의 인터페이스를 제공하여 멀티 다이 메모리 칩이 단일 메모리 칩으로 기 능하도록 할 수 있다. 글루 로직은 예를 들어 그룹으로 도시된 다이의 그룹으로 함께 절단될 수 있 다. 또는, 메모리 칩에 대해 하나의 다이만이, 예를 들어 그룹이 필요한 경우, 글루 로직은 절단되지 않 을 수 있다. 예를 들어, 글루 로직은 상이한 다이 사이의 협력을 가능하게 하기 위해 필요하지 않은 경우에 선 택적으로 제거될 수 있다. 도 37에서, 예를 들어, 파선 영역과 같은, 상이한 영역의 다양한 절단이 도시된 바와 같이 이루어질 수 있다. 다양한 실시예에서, 도 37에 도시된 바와 같이, 하나의 글루 로직 요소가 두 개 의 다이마다 웨이퍼 상에 레이아웃 될 수 있다. 일부 경우에서, 하나의 글루 로직 요소는 한 그룹 의 다이를 형성하는 모든 임의의 수의 다이에 대해 사용될 수 있다. 글루 로직은 다이 그룹의 모든 다이에 연결되도록 구성될 수 있다. 다양한 실시예에서, 글루 로직에 연결된 다이는 멀티 다이 메모리 칩 을 형성하도록 구성될 수 있고, 글루 로직에 연결되지 않은 경우에는 별개의 단일 다이 메모리 칩을 형성 하도록 구성될 수 있다. 다양한 실시예에서, 글루 로직에 연결되고 함께 기능하도록 설계된 다이가 그룹 으로 웨이퍼에서 절단될 수 있고, 그룹 등으로 표시된 바와 같이 글루 로직을 포함할 수 있 다. 글루 로직에 연결되지 않은 다이는 그룹 등으로 표시된 바와 같이 글루 로직을 포함하지 않고 웨이퍼에서 절단되어 단일 다이 메모리 칩을 형성할 수 있다. 일부 실시예에서, 웨이퍼에서 멀티 다이 메모리 칩을 제조하는 과정에서, 원하는 멀티 다이 메모리 칩의 세트를 생성하기 위해 하나 이상의 절단 형상(예, 그룹(3713, 3715)을 형성하는 형상)이 결정될 수 있다. 일부 경우에서, 그룹으로 도시된 바와 같이, 절단 형상은 글루 로직을 포함하지 않을 수 있다. 다양한 실시예에서, 글루 로직은 멀티 다이 메모리 칩의 다중 메모리 유닛의 제어를 위한 컨트롤러일 수 있다. 일부 경우에서, 글루 로직은 다양한 다른 컨트롤러에 의해 수정될 수 있는 파라미터를 포함할 수 있다. 예컨대, 멀티 다이 메모리 칩의 결합 회로는 글루 로직의 파라미터 또는 메모리 컨트롤러(예, 도 35b에 도시된 프로세서 서브유닛(subunits 3515A-3515D))의 파라미터를 구성하기 위한 회로를 포함할 수 있다. 글루 로직은 다양한 작업을 수행하도록 구성될 수 있다. 예를 들면, 글루 로직은 어느 다이가 어드 레스 되어야 할지를 판단하도록 구성될 수 있다. 일부 경우에서, 글루 로직은 다중 메모리 유닛을 동기화 하는데 사용될 수 있다. 다양한 실시예에서, 글루 로직은 메모리 유닛들이 단일 칩으로 작동하게 되도록 다양한 메모리 유닛을 제어하도록 구성될 수 있다. 일부 경우에서, 입력-출력 버스(예, 도 35c에 도시된 버스 )와 프로세서 서브유닛(3515A-3515D) 사이에 증폭기가 추가되어 버스로부터의 데이터 신호를 증폭 할 수 있다. 다양한 실시예에서, 웨이퍼에서 복잡한 형상을 절단하는 것은 기술적으로 어려울/비쌀 수 있고, 다이들이 웨이퍼 상에 정렬된다면 더 단순한 절단 방법이 채택될 수 있다. 도 38a는 다이가 정렬되어 직사각 형 격자를 형성하는 것을 도시하고 있다. 예시적인 일 실시예에서, 전체 웨이퍼에 세로 절단과 가 로 절단을 하여 절단된 다이의 그룹을 분리할 수 있다. 예시적인 일 실시예에서, 세로 및 가로 절단 (3803, 3801)으로 선택된 수의 다이를 포함하는 그룹이 만들어질 수 있다. 예컨대, 절단과 절단의 결과로 단일 다이를 포함하는 영역(예, 3811A), 두 개의 다이를 포함하는 영역(예, 3811B), 및 4개의 다이를 포 함하는 영역(예, 3811C)이 형성될 수 있다. 절단과 절단에 의해 형성된 영역들은 예시에 불과하며, 모든 임의의 다른 적절한 영역이 형성될 수 있다. 다양한 실시예에서, 다이의 정렬에 따라, 다양한 절단이 이루 어질 수 있다. 예를 들면, 도 38b에 도시된 바와 같이, 다이들이 삼각형 격자로 정렬되는 경우, 라인(3802, 3804, 3806)과 같은 절단 라인을 활용하여 멀티 다이 메모리 칩을 형성할 수 있다. 예컨대, 일부 영역은 6개의 다이, 5개의 다이, 3개의 다이, 2개의 다이, 1개의 다이, 또는 모든 임의의 기타 적절한 수의 다이를 포함할 수 있다. 도 38c는 버스 라인이 삼각형 격자로 배열되고, 교차하는 버스 라인에 의해 형성된 삼각형의 중앙 에 다이가 정렬된 것을 도시하고 있다. 다이는 버스 라인을 통해 이웃하는 모든 버스라인으 로 연결될 수 있다. 둘 이상의 인접 다이를 포함하는 영역(예, 도 38c에 도시된 영역)을 절단함으로써, 적어도 하나의 버스 라인(예, 라인)이 영역에 남게 되고, 영역을 활용하여 형성된 멀티 다이 메모리 칩으로 데이터 및 명령을 제공하기 위해 버스 라인이 활용될 수 있다. 도 39는 메모리 유닛의 그룹이 단일 메모리 칩으로 기능하도록 하기 위해 프로세서 서브유닛(3515A-3515P) 사이 에 다양한 연결이 형성될 수 있음을 도시하고 있다. 예를 들어, 다양한 메모리 유닛의 그룹은 프로세서 서브유닛(3515B)과 프로세서 서브유닛(3515E) 사이의 연결을 포함할 수 있다. 연결은 메모리 뱅크 (3511E)를 제어하는데 사용될 수 있는 서브유닛(3515B)에서 서브유닛(3515E)로의 데이터 및 명령의 전송을 위한 버스 라인으로 사용될 수 있다. 다양한 실시예에서, 프로세서 서브유닛 사이의 연결은 웨이퍼 상에 다이 를 형성하는 동안에 구현될 수 있다. 일부 경우에서, 여러 다이로부터 형성된 메모리 칩의 패키징 단계에서 추 가적인 연결이 제조될 수 있다. 도 39에 도시된 바와 같이, 프로세서 서브유닛(3515A-3515P)은 다양한 버스(예, 연결)를 활용하여 서로 연결될 수 있다. 연결에는 타이밍 하드웨어 로직 요소가 없어서 프로세서 서브유닛 사이의 데이터 전송과 연결을 통한 데이터 전송은 타이밍 하드웨어 로직 요소에 의해 제어되지 않을 수 있다. 다양한 실시예에 서, 프로세서 서브유닛(3515A-3515P)을 연결하는 버스는 웨이퍼 상에 다양한 회로를 제조하기 전에 웨이 퍼 상에 레이아웃 될 수 있다. 다양한 실시예에서, 프로세서 서브유닛(예, 서브유닛(3515A-3515P))은 상호 연결될 수 있다. 예를 들어, 서브유 닛(3515A-3515P)은 적절한 버스(예, 연결)에 의해 연결될 수 있다. 연결은 서브유닛(3515A-3515P) 중의 하나 이상을 서브유닛(3515A-3515P) 중의 다른 하나 이상과 연결시킬 수 있다. 예시적인 일 실시예에서, 연결된 서브유닛은 동일 다이 상에 있을 수 있고(예, 3515A와 3515B의 경우), 다른 경우에서, 연결된 서브유닛 은 상이한 다이 상에 있을 수 있다(예, 3515B와 3515E의 경우). 연결은 서브유닛을 연결하기 위한 전용 버스를 포함할 수 있고 서브유닛(3515A-3515P) 사이에 데이터를 효율적으로 전송하도록 구성될 수 있다. 본 개시의 다양한 측면은 선택 가능 사이즈의 메모리 칩을 웨이퍼로부터 생산하기 위한 방법에 관한 것이다. 예 시적인 일 실시예에서, 선택 가능 사이즈의 메모리 칩은 아나 이상의 다이로부터 형성될 수 있다. 앞서 설명한 바와 같이, 다이는 예를 들어 도 35c에 도시된 바와 같이 하나 이상의 행을 따라 배열될 수 있다. 일부 경우에 서, 하나 이상의 행에 상응하는 적어도 하나의 공유 입력-출력 버스가 웨이퍼 상에 레이아웃 될 수 있다. 예를 들어, 버스가 도 35c에 도시된 바와 같이 레이아웃 될 수 있다. 다양한 실시예에서, 버스는 적어도 두 개의 다이의 메모리 유닛으로 전기적으로 연결될 수 있고, 연결된 다이는 멀티 다이 메모리 칩의 형 성에 사용될 수 있다. 예시적인 일 실시예에서, 하나 이상의 컨트롤러(예, 도 35b에 도시된 입력-출력 컨트롤러 (3521, 3522))가 멀티 다이 메모리 칩의 형성에 사용되는 적어도 두 개의 다이의 메모리 유닛을 제어하도록 구 성될 수 있다. 다양한 실시예에서, 버스로 연결된 메모리 유닛이 있는 다이는 적어도 하나의 컨트롤러(예, 컨트롤러(3521, 3522))로 정보를 전송하는 공유 입력-출력 버스(예, 도 35b에 도시된 버스(353 0))의 적어도 하나의 상응하는 부분과 함께 웨이퍼에서 절단되어, 연결된 다이의 메모리 유닛을 함께 단일 칩으 로 기능하게 컨트롤러가 제어하도록 구성될 수 있다. 일부 경우에서, 웨이퍼의 영역을 절단하여 메모리 칩을 제조하기 이전에 웨이퍼 상에 위치한 메모 리 유닛을 검사할 수 있다. 검사는 적어도 하나의 공유 입력-출력 버스(예, 도 35c에 도시된 버스)를 사 용하여 수행될 수 있다. 메모리 칩은 메모리 유닛이 검사에 합격하는 경우에 메모리 유닛을 포함하는 다이의 그 룹으로부터 형성될 수 있다. 검사에 불합격하는 메모리 유닛은 폐기되고 메모리 칩의 제소에 사용되지 않을 수 있다. 도 40은 다이의 그룹으로부터 메모리 칩을 구성하는 예시적인 프로세스를 도시한 것이다. 프로세스(400 0)의 단계 4011에서, 다이가 반도체 웨이퍼 상에 레이아웃 될 수 있다. 단계 4015에서, 모든 임의의 적절 한 방식을 활용하여 웨이퍼 상에 다이가 제작될 수 있다. 예를 들어, 다이는 웨이퍼를 식각하고, 다양한 유전층, 금속층, 또는 반도체층을 증착하고, 증착된 층을 더 식각하는 등을 통하여 제작될 수 있다. 예 컨대, 다중 층이 증착되고 식각될 수 있다. 다양한 실시예에서, 층은 모든 임의의 적절한 도핑 요소를 활용하여 n형 도핑 또는 p형 도핑 될 수 있다. 예를 들어, 반도체층은 인(P)으로 n형 도핑 될 수 있고 붕소(B)로 p형 도 핑 될 수 있다. 도 35a에 도시된 바와 같은 다이는 웨이퍼에서 다이를 절단하기 위해 사용될 수 있는 공간에 의해 서로로부터 분리될 수 있다. 예를 들어, 다이는 공간 영역에 의해 서로로부터 이격 될 수 있고, 여기서 공간 영역의 폭은 공간 영역에서 웨이퍼 절단이 가능하도록 선택될 수 있다. 단계 4017에서, 모든 임의의 적절한 방식을 활용하여 웨이퍼로부터 다이가 절단될 수 있다. 예시적 인 일 실시예에서, 다이는 레이저를 활용하여 절단될 수 있다. 예시적인 일 실시예에서, 웨이퍼은 우선 스크라이브(scribe) 된 후에 기계적 절단이 될 수 있다. 또는, 기계적 절단 톱(dicing saw)이 사용될 수 있다. 일부 경우에서, 스텔스다이싱(stealth dicing) 프로세스가 사용될 수 있다. 절단 과정에서, 웨이퍼(350 1)는 다이가 절단된 이후에 다이를 홀드하기 위한 다이싱 테이프 상에 탑재될 수 있다. 다양한 실시예에서, 도38a의 절단(3801 및 3803) 또는 도 38b의 절단(3802, 3804, 및 3806)으로 도시된 바와 같이 대형 절단이 이루 어질 수 있다. 일단 다이가 개별적으로 또는, 도 35c의 그룹과 같이, 그룹으로 절단되면, 다이 는 패키징 될 수 있다. 다이의 패키징은 다이에 컨택트(contacts)를 형성하고, 컨택트에 보호층을 증착하고, 열관리 장치(예, 히트싱크)를 부착하고, 다이를 인캡슐레이션 하는 과정을 포함한다. 다양한 실시예에서, 메모리 칩의 형성에 선택되는 다이의 수에 따라, 컨택트와 버스의 적절한 구성이 사용될 수 있다. 예시적인 일 실시예에서, 메모리 칩을 형성하는 다이 사이의 컨택트의 일부는 메모리 칩 패키징 과정에서 형성 될 수 있다. 도 41a는 다수의 다이를 포함하는 메모리 칩을 제조하기 위한 예시적인 프로세스를 도시한 것이다. 프로 세스의 단계 4011은 프로세스의 단계 4011과 동일할 수 있다. 단계 4111에서, 도 37에 도시된 바와 같은 글루 로직이 웨이퍼 상에 레이아웃 될 수 있다. 글루 로직은 도 37에 도시된 바와 같이 다이의 동작을 제어하기 위한 모든 임의의 적합한 로직일 수 있다. 앞서 설명한 바와 같이, 글루 로직 의 존재로 인해 여러 다이가 단일 메모리 칩으로 기능할 수 있게 된다. 글루 로직은 다수의 다이로 부터 형성된 메모리 칩이 단일 메모리 칩으로 기능할 수 있도록 다른 메모리 컨트롤러와의 인터페이스를 제공할 수 있다. 프로세스의 단계 4113에서, 버스(예, 입력-출력 버스 및 컨트롤 버스)가 웨이퍼 상에 레이아웃 될 수 있다. 버스는 다양한 다이 및 글루 로직과 같은 다양한 논리 회로와 연결되도록 레이아웃 될 수 있다. 일부 경우에서, 버스는 메모리 유닛을 연결할 수 있다. 예를 들어, 버스는 상이한 다이의 프로세서 서브유닛을 연결하도록 구성될 수 있다. 단계 4115에서, 모든 임의의 적합한 방식을 활용하여 다이, 글루 로직, 및 버스가 제작될 수 있다. 예를 들어, 논리 요소는 웨이퍼를 식각하고, 다양한 유전층, 금속층, 또는 반도체층을 증착하고, 증착된 층을 더 식각하는 등을 통하여 제작될 수 있다. 버스는 예를 들어 금속 증착을 활용하여 제작 될 수 있다. 단계 4140에서, 절단 형상을 활용하여 도 37에 도시된 것과 같은 단일 글루 로직에 연결된 다이의 그룹을 절단할 수 있다. 절단 형상은 다수의 다이를 포함하는 메모리 칩에 대한 메모리 요구사항을 활용하여 판 단될 수 있다. 예를 들어, 도 41b는 프로세스의 변형일 수 있는 프로세스를 도시하고 있으며, 여기 서 프로세스의 단계 4140 이전에 단계 4117과 단계 4119가 있을 수 있다. 단계 4117에서, 웨이퍼 절단 시스템은 메모리 칩에 대한 요구사항을 설명하는 명령을 수신할 수 있다. 예를 들면, 요구사항에는 4개의 다이를 포함하는 메모리 칩의 형성을 포함할 수 있다. 일부 경우에서, 단계 4119에서 프로그램 소프트웨 어가 다이의 그룹과 글루 로직에 대한 주기적 패턴을 판단할 수 있다. 예컨대, 주기적 패턴은 2개의 글루 로직 요소와 4개의 다이에서 1개의 글루 로직마다 2개의 다이가 연결된 패턴을 포함할 수 있 다. 또는 단계 4119에서, 패턴은 메모리 칩의 설계자에 의해 제공될 수 있다. 일부 경우에서, 패턴은 웨이퍼로부터 메모리 칩의 수율을 극대화하도록 선택될 수 있다. 예시적인 일 실 시예에서, 다이의 메모리 유닛을 검사하여 불량 메모리 유닛이 있는 다이('불량 다이'라고 지칭)를 식별 하고, 불량 다이의 위치에 의거하여, 검사에 합격한 메모리 유닛을 포함하는 다이의 그룹이 식별되고 적 절한 절단 패턴이 판단될 수 있다. 예를 들어, 웨이퍼의 가장자리에서 많은 수의 다이가 불량인 경 우, 웨이퍼의 가장자리의 다이를 제외하는 절단 패턴이 결정될 수 있다. 단계 4011, 단계 4111, 단계 4113, 단계 4115, 및 단계 4140과 같은 프로세스의 다른 단계들은 프로세스의 동일한 번호의 단계 들과 동일할 수 있다. 도 41c는 프로세스의 변형일 수 있는 예시적인 프로세스를 도시한 것이다. 프로세스의 단계 4011, 단계 4111, 단계 4113, 단계 4115, 및 단계 4140은 프로세스의 동일한 번호의 단계들과 동일할 수 있고, 프로세스의 단계 4131은 프로세스의 단계 4117을 대신할 수 있고, 프로세스의 단계 4133은 프로세스의 단계 4119를 대신할 수 있다. 단계 4131에서, 웨이퍼 절단 시스템은 제1 세트의 메모리 칩과 제2 세트의 메모리 칩에 대한 요구사항을 설명하는 명령을 수신할 수 있다. 예를 들어, 요구사항은 4개의 다이를 포함하는 메모리 칩으로 제1 세트의 메모리 칩을 형성하고 2개의 다이를 포함하는 메 모리 칩으로 제2 세트의 메모리 칩을 형성하는 것을 포함할 수 있다. 일부 경우에서, 웨이퍼에서 2 세트 이상의 메모리 칩이 형성되어야 할 수도 있다. 예컨대, 제3 세트의 메모리 칩은 1개의 다이만을 포함하는 메모리 칩을 포함할 수 있다. 일부의 경우, 단계 4133에서, 각 세트의 메모리 칩에 대한 메모리 칩을 형성하기 위한 다이의 그룹과 글루 로직의 주기적 패턴을 프로그램 소프트웨어가 판단할 수 있다. 예를 들면, 제1 세트의 메모리 칩은 2개의 글루 로직과 4개의 다이에서 1개의 글루 로직마다 2개의 다이가 연결된 패턴을 포함하는 메모리 칩을 포함할 수 있다. 다양한 실시예에서, 동일한 메모리 칩에 대한 글루 로직은 서로 연결되어 단일 글루 로직으로 기능할 수 있다. 예를 들어, 글루 로직의 제작 과정에서, 글 루 로직을 서로 연결하는 버스 라인이 형성될 수 있다. 제2 세트의 메모리 칩은 1개의 글루 로직과 2개의 다이에서 다이가 글루 로직에 연결 된 패턴을 가진 메모리 칩을 포함할 수 있다. 일부 경우에서, 제2 세트의 메모리 칩이 선택되고, 제2 세트의 메 모리 칩은 단일 다이를 포함하는 메모리 칩을 포함하는 경우, 글루 로직이 필요하지 않을 수 있다. 듀얼 포트(dual port) 기능 메모리 칩 또는 칩 내의 메모리 인스턴스를 설계할 때에, 한 가지 중요한 특성은 단일 클럭 사이클 동안에 동시 에 접근될 수 있는 워드의 수이다. 읽기 및/또는 쓰기를 위해 동시에 접근될 수 있는 어드레스(예, 워드 또는 워드라인이라고도 부르는 행 및 비트 또는 비트라인이라고도 부르는 열을 따라 있는 어드레스)가 많을수록, 메 모리 칩은 더 빨라진다. 레지스터 파일, 캐시, 또는 공유 메모리를 구축하는 등의, 동시에 다중 어드레스에 접 근할 수 있게 하는 다중 방향 포트를 포함하는 메모리를 개발하려는 노력이 있어왔지만, 대부분의 인스턴스는 사이즈가 크고 다중 어드레스 접근을 지원하는 메모리 매트를 활용한다. 그러나 DRAM 칩은 각 메모리 셀의 각 커패시터에 연결된 단일 비트라인과 단일 로우라인(row line)을 포함하는 것이 일반적이다. 이에 따라, 본 개시 의 실시예들은 DRAM 어레이의 이러한 종래의 단일 포트 메모리 구조를 변경하지 않고 기존의 DRAM 칩 상에 다중 포트 접근을 제공하고자 한다. 본 개시의 실시예들에서, 메모리 인스턴스 또는 칩의 클럭 속도는 메모리를 사용하는 논리 회로의 속도보다 2배 빠를 수 있다. 따라서, 메모리를 사용하는 모든 임의의 논리 회로는 메모리 및 그 구성요소에 '상응'할 수 있다. 이에 따라, 본 개시의 실시예들은 메모리 어레이 클럭 사이클로 2개의 어드레스에 읽기 또는 쓰기를 할 수 있고, 이는 논리 회로에 대한 단일 프로세싱 클럭 사이클과 맞먹는다. 논리 회로는 컨트롤러, 가속기, GPU, 또는 CPU와 같은 회로를 포함할 수 있거나 도 7a에 도시된 바와 같이 메모리 칩과 동일한 기판 상의 프로세싱 그룹을 포함할 수 있다. 앞서 도 3a를 참조하여 설명한 바와 같이, '프로세싱 그룹'은 둘 이상의 프로세서 서브 유닛과 이에 상응하는 기판 상의 메모리 뱅크를 말하는 것일 수 있다. 그룹은 기판 상의 공간적 분산 및/또는 메모리 칩 상의 실행을 위한 코드의 컴파일링을 위한 논리적 묶음을 나타낼 수 있다. 이에 따라, 앞서 도 7a를 참조하여 설명한 바와 같이, 메모리 칩이 있는 기판은 도 28에 도시된 뱅크(2801a) 및 기타 뱅크와 같은 복수의 뱅크가 있는 메모리 어레이를 포함할 수 있다. 또한, 기판은 복수의 프로세서 서브유닛(예, 도 7a에 도 시된 서브유닛(730a, 730b, 730c, 730d, 730e, 730f, 730g, 730h))을 포함할 수 있는 프로세싱 어레이도 포함 할 수 있다. 이에 따라, 본 개시의 실시예에서, 단일 포트 메모리 어레이가 2 포트 메모리 칩인 것처럼 각 로직 사이클에 대 해 2개의 어드레스를 처리하고 로직에 2개의 결과를 제공하기 위하여, 연속하는 2 메모리 사이클의 각각에서 어 레이로부터 데이터를 읽을 수 있다. 추가적인 클러킹(clocking)을 통해, 본 개시의 메모리 칩은 단일 포트 어레 이가 2 포트 메모리 인스턴스, 3 포트 메모리 인스턴스, 4 포트 메모리 인스턴스, 또는 모든 임의의 기타 다중 포트 메모리 인스턴스처럼 기능할 수 있다. 도 42는 본 개시에 따른 회로가 사용되는 메모리 칩의 열을 따라 듀얼 포트 접근을 제공하는 예시적인 회 로를 도시한 것이다. 도 42에 도시된 실시예는 2개의 컬럼 멀티플렉서('mux')(4205a 및 4205b)가 있는 하 나의 메모리 어레이를 사용하여 논리 회로에 대한 동일 클럭 사이클 동안에 동일 행의 2 워드에 접근할 수 있다. 예를 들어, 메모리 클럭 사이클 동안에, RowAddrA가 로우 디코더에서 사용되고 ColAddrA가 멀티 플렉서(4205a)에서 사용되어 어드레스 (RowAddrA, ColAddrA)를 가진 메모리로부터의 데이터를 버퍼링 한다. 동 일한 메모리 클럭 사이클 동안에, ColAddrB가 멀티플렉서(4205b)에서 사용되어 어드레스 (RowAddrA, ColAddr B)를 가진 메모리로부터의 데이터를 버퍼링 한다. 따라서, 회로는 동일한 행 또는 워드라인을 따라 2개의 상이한 어드레스에서 메모리 셀 상에 저장된 데이터(예, DataA 및 DataB)로의 듀얼 포트 접근을 가능하게 할 수 있다. 따라서, 로우 디코더가 두 읽기에 대한 동일한 워드라인을 활성화하도록 두 어드레스가 행을 공유 할 수 있다. 또한, 도 42에 도시된 예와 같은 실시예들은 동일한 메모리 클럭 사이클 동안에 2 어드레스가 접근 될 수 있도록 컬럼 멀티플렉서를 사용할 수 있다. 이와 유사하게, 도 43은 본 개시에 따른 회로가 사용되는 메모리 칩의 행을 따라 듀얼 포트 접근을 제공 하는 예시적인 회로를 도시한 것이다. 도 43에 도시된 실시예는 로우 디코더가 멀티플렉서('mux') 에 결합된 하나의 메모리 어레이를 사용하여 논리 회로에 대한 동일 클럭 사이클 동안에 동일 열 상의 2 개의 워드에 접근할 수 있다. 예를 들어, 2 메모리 클럭 사이클의 제1 사이클에서, RowAddrA가 로우 디코더 에서 사용되고, ColAddrA가 컬럼 멀티플렉서에서 사용되어 어드레스 (RowAddrA, ColAddrA)를 가진메모리 셀로부터의 데이터를 버퍼링 할 수 있다(예, 도 43의 'Buffered Word' 버퍼로). 2 메모리 클럭 사이클의 제2 사이클에서, RowAddrB가 로우 디코더에서 사용되고, ColAddrA가 컬럼 멀티플렉서에서 사용되어 어드레스 (RowAddrB, ColAddrA)를 가진 메모리 셀로부터의 데이터를 버퍼링 할 수 있다. 따라서, 회로는 동일한 열 또는 비트라인을 따라 2개의 상이한 어드레스에서 메모리 셀 상에 저장된 데이터(예, DataA 및 DataB)로의 듀얼 포트 접근을 가능하게 할 수 있다. 따라서, 컬럼 디코더(도 43에 도시된 바와 같이, 하나 이상 의 컬럼 멀티플렉서와 분리되거나 병합될 수 있음)가 두 읽기에 대한 동일한 비트라인을 활성화하도록 두 어드 레스가 행을 공유할 수 있다. 로우 디코더는 각 워드라인을 활성화하기 위해 하나의 메모리 클럭 사이클 이 필요할 수 있기 때문에 도 43에 도시된 예와 같은 실시예들은 2개의 메모리 클럭 사이클을 사용할 수 있다. 이에 따라, 회로를 사용하는 메모리 칩은 상응하는 논리 회로보다 클럭 속도가 적어도 2배 빠른 경우에 듀얼 포트 메모리로 기능할 수 있다. 이에 따라, 앞서 설명한 바와 같이, 도 43은 상응하는 논리 회로에 대한 클럭 사이클보다 빠른 2개의 메모리 클 럭 사이클 동안에 DataA와 DataB를 읽어올 수 있다. 예컨대, 로우 디코더(예, 도 43의 로우 디코더) 및 컬럼 디코더(도 43에 도시된 바와 같이, 하나 이상의 컬럼 멀티플렉서와 분리되거나 병합될 수 있음)는 2개의 어드레스를 생성하는 상응하는 논리 회로의 속도보다 적어도 2배 빠른 속도로 클러킹 되도록 구성될 수 있다. 예를 들어, 회로에 대한 클럭 회로(도 43에는 미도시)는 2개의 어드레스를 생성하는 상응하는 논리 회로 의 속도보다 적어도 2배 빠른 속도에 따라 회로를 클러킹 할 수 있다. 도 42와 도 43의 실시예는 별개로 또는 함께 사용될 수 있다. 이에 따라, 단일 포트 메모리 어레이 또는 매트 상에 듀얼 포트 기능을 제공하는 회로(예, 회로 또는 회로)는 적어도 하나의 행과 적어도 하나의 열을 따라 배열된 복수의 메모리 뱅크를 포함할 수 있다. 복수의 메모리 뱅크는 도 42에 메모리 어레이로 도시되어 있고 도 43에 메모리 어레이로 도시되어 있다. 본 실시예는 또한 단일 클럭 사이클 동안에 읽기 또는 쓰기를 위한 2개의 어드레스를 수신하도록 구성된 적어도 하나의 로우 멀티플렉서(도 43에 도시) 또는 적 어도 하나의 컬럼 멀티플렉서(도 42에 도시)를 사용할 수 있다. 또한, 본 실시예는 로우 디코더(예, 도 42의 로 우 디코더 및 도 43의 로우 디코더) 및 컬럼 디코더(도 42와 도 43에 도시된 바와 같이, 하나 이상 의 컬럼 멀티플렉서와 분리되거나 병합될 수 있음)를 사용하여 2개의 어드레스에 읽기 또는 쓰기를 할 수 있다. 예를 들어, 로우 디코더와 컬럼 디코더는 제1 사이클 동안에 적어도 하나의 로우 멀티플렉서 또는 적어도 하나 의 컬럼 멀티플렉서로부터 2개의 어드레스 중 제1 어드레스를 읽어오고 제1 어드레스에 상응하는 워드라인 및 비트라인을 디코딩할 수 있다. 또한, 로우 디코더와 컬럼 디코더는 제2 사이클 동안에 적어도 하나의 로우 멀티 플렉서 또는 적어도 하나의 컬럼 멀티플렉서로부터 2개의 어드레스 중 제2 어드레스를 읽어오고 제2 어드레스에 상응하는 워드라인 및 비트라인을 디코딩할 수 있다. 이러한 읽어오기는 각각, 로우 디코더를 사용하여 어드레 스에 상응하는 워드라인을 활성화하고, 컬럼 디코더를 사용하여 이 어드레스에 상응하는 활성화된 워드라인 상 의 비트라인을 활성화하여 이루어질 수 있다. 상기에서는 읽어오기에 대하여 설명하였지만, 도 42와 도 43의 실시예들은 개별적으로 구현되거나 함께 구현되 는 여부와 관계없이, 쓰기 명령을 포함할 수 있다. 예를 들어, 제1 사이클 동안에, 로우 디코더와 컬럼 디코더 는 적어도 하나의 로우 멀티플렉서 또는 적어도 하나의 컬럼 멀티플렉서에서 읽어온 제1 데이터를 2개의 어드레 스 중의 제1 어드레스에 기록할 수 있다. 또한, 제2 사이클 동안에, 로우 디코더와 컬럼 디코더는 적어도 하나 의 로우 멀티플렉서 또는 적어도 하나의 컬럼 멀티플렉서에서 읽어온 제2 데이터를 2개의 어드레스 중의 제2 어 드레스에 기록할 수 있다. 도 42의 예는 제1 및 제2 어드레스가 워드라인 어드레스를 공유하는 경우의 이러한 프로세스를 보여주고, 도 43 의 예는 제1 및 제2 어드레스가 컬럼 어드레스를 공유하는 경우의 이러한 프로세스를 보여준다. 하기에 도 47을 참조하여 설명하는 바와 같이, 제1 및 제2 어드레스가 워드라인 어드레스 또는 컬럼 어드레스를 공유하지 않는 경우에 동일 프로세스가 구현될 수 있다. 이에 따라, 상기의 예는 행 및 열 중의 적어도 하나를 따라 듀얼 포트 접근을 제공하지만, 추가적인 실시예는 행 및 열 모두를 따라 듀얼 포트 접근을 제공할 수 있다. 도 44는 본 개시에 따른 회로가 사용되는 메모 리 칩의 행과 열 모두를 따라 듀얼 포트 접근을 제공하는 예시적인 회로를 도시한 것이다. 이에 따라, 회 로는 도 42의 회로와 도 43의 회로의 조합을 나타내는 것을 수 있다. 도 44에 도시된 실시예는 하나의 메모리 어레이를 멀티플렉서(\"mux\")와 결합된 로우 디코더와 함께 사용하여 논리 회로에 대한 동일한 클럭 사이클 동안에 2개의 행에 접근할 수 있다. 또한, 도 44에 도시된 실시 예는 메모리 어레이를 멀티플렉서(\"mux\")와 결합된 컬럼 디코더(또는 멀티플렉서)와 함께 사용하여동일한 클럭 사이클 동안에 2개의 열에 접근할 수 있다. 예를 들어, 2 메모리 클럭 사이클의 제1 사이클에서, RowAddrA가 로우 디코더에서 사용되고, ColAddrA가 컬럼 멀티플렉서에서 사용되어 어드레스 (RowAddrA, ColAddrA)를 가진 메모리 셀로부터의 데이터를 버퍼링 할 수 있다(예, 도 44의 'Buffered Word' 버 퍼로). 2 메모리 클럭 사이클의 제2 사이클에서, RowAddrB가 로우 디코더에서 사용되고, ColAddrA가 컬럼 멀티플렉서에서 사용되어 어드레스 (RowAddrB, ColAddrA)를 가진 메모리 셀로부터의 데이터를 버퍼링 할 수 있다. 따라서, 회로는 2개의 상이한 어드레스에서 메모리 셀 상에 저장된 데이터(예, DataA 및 Data B)로의 듀얼 포트 접근을 가능하게 할 수 있다. 로우 디코더는 각 워드라인을 활성화하기 위해 하나의 메 모리 클럭 사이클이 필요할 수 있기 때문에 도 44에 도시된 예와 같은 실시예들은 추가적인 버퍼를 사용할 수 있다. 이에 따라, 회로를 사용하는 메모리 칩은 상응하는 논리 회로보다 클럭 속도가 적어도 2배 빠른 경 우에 듀얼 포트 메모리로 기능할 수 있다. 도 44에는 도시되어 있지 않지만, 회로는 행 또는 워드라인을 따라 도 46(하기에 설명)의 추가 회로 및/ 또는 열 또는 비트라인을 따라 유사한 추가 회로를 더 포함할 수 있다. 이에 따라, 회로는 상응하는 회로 를 활성화하여(예, 도 46의 스위칭 요소(4613a, 4613b) 등의 하나 이상과 같은 하나 이상의 스위칭 요소를 개방 하여) 어드레스를 포함하는 단전된 부분을 활성화할 수 있다(예, 단전된 부분에 전압을 연결하거나 전류를 흐르 게 하여). 이에 따라, 회로는 회로의 요소(예, 라인 등)가 어드레스에 의해 식별된 위치를 포함하는 경우 및/또 는 회로의 요소(예, 스위칭 요소)가 어드레스에 의해 식별된 메모리 셀로의 전압의 공급 및/또는 전류의 흐름을 제어하는 경우에 '상응'할 수 있다. 이후, 회로는 로우 디코더와 컬럼 멀티플렉서를 사용하 여 상응하는 워드라인과 비트라인을 디코딩하고, 활성화된 단전 부분에 위치하는 어드레스에 데이터를 읽기 또 는 쓰기 할 수 있다. 도 44에 더 도시된 바와 같이, 회로는 읽기와 쓰기를 위한 두 개의 어드레스를 단일 클럭 사이클 동안에 가져오도록 구성된 적어도 하나의 로우 멀티플렉서(로우 디코더와 분리된 것으로 도시되어 있지만 그 안 에 포함될 수 있음) 및/또는 적어도 하나의 컬럼 멀티플렉서(컬럼 멀티플렉서와 분리된 것으로 도시되어 있지만 그 안에 포함될 수 있음)를 더 사용할 수 있다. 이에 따라, 본 실시예들은 로우 디코더(예, 로우 디코더 )와 컬럼 디코더(컬럼 멀티플렉서와 분리되거나 병합될 수 있음)를 사용하여 두 개의 어드레스에 읽기와 쓰기를 할 수 있다. 예를 들어, 로우 디코더와 컬럼 디코더는 메모리 클럭 사이클 동안에 적어도 하나의 로우 멀티플렉서 또는 적어도 하나의 컬럼 멀티플렉서로부터 2개의 어드레스 중의 제1 어드레스를 가져오고 제1 어드레스에 상응하는 워드라인 및 비트라인을 디코딩할 수 있다. 또한, 로우 디코더와 컬럼 디코더는 동일 메모 리 사이클 동안에 적어도 하나의 로우 멀티플렉서 또는 적어도 하나의 컬럼 멀티플렉서로부터 2개의 어드레스 중의 제2 어드레스를 가져오고 제2 어드레스에 상응하는 워드라인 및 비트라인을 디코딩할 수 있다. 도 45a와 도 45b는 단일 포트 메모리 어레이 또는 매트 상에 듀얼 포트 기능을 제공하기 위한 기존의 복제 방식 을 도시한 것이다. 도 45a에 도시된 바와 같이, 듀얼 포트 읽기는 메모리 어레이 또는 매트 전체에 걸쳐 데이터 의 복제 사본의 동기화 상태를 유지함으로써 제공될 수 있다. 이에 따라, 읽기는 도 45a에 도시된 바와 같이 메 모리 인스턴스의 두 사본 모두에서 수행될 수 있다. 또한, 도 45b에 도시된 바와 같이, 메모리 어레이 또는 매 트 전체에 걸쳐 모든 쓰기를 복제함으로써 듀얼 포트 쓰기가 제공될 수 있다. 예를 들면, 메모리 칩은 메모리 칩을 사용하는 모든 논리 회로가 데이터의 각 복제 사본에 하나씩 쓰기 명령의 복제를 전송할 것을 요구할 수 있다. 또는, 일부 실시예에서, 도 45a에 도시된 바와 같이, 추가 회로를 구비함으로써, 사본의 동기화 상태를 유지하기 위하여 메모리 어레이 또는 매트 전체에 걸쳐 기록된 데이터의 복제 사본을 생성하도록 추가 회로에 의해 자동으로 복제된 단일 쓰기 명령을 메모리 인스턴스를 사용하는 논리 회로가 전송할 수 있다. 도 42, 도 43, 및 도 44의 실시예들은, 멀티플렉서를 사용하여 단일 메모리 클럭 사이클에서 2개의 비트라인에 접근(예, 도 42 참조) 및/또는 메모리의 클럭 속도를 상응하는 논리 회로보다 빠르게 하고(예, 도 43 참조) 모든 데이터 를 메모리에 복제하는 대신에 추가 어드레스를 처리할 추가 멀티플렉서를 제공함으로써, 이러한 기존의 복제 방 식에서 중복성을 감소시킬 수 있다. 상기에 설명한 클럭 속도의 증가 및/또는 추가 멀티플렉서 외에도, 본 개시의 실시예들은 메모리 어레이 내의 어느 지점에서 비트라인 및/또는 워드라인을 단전하는 회로를 사용할 수 있다. 이러한 실시예들에서, 단전 회로 의 동일 부분으로 결합되지 않은 상이한 위치에 로우 디코더 및 컬럼 디코더가 접근하는 한, 어레이로 다중 동 시 접근이 가능하다. 예를 들어, 단전 회로는 로우 디코더 및 컬럼 디코더가 전기적 간섭 없이 상이한 어드레스 에 접근할 수 있게 할 수 있으므로, 상이한 워드라인과 비트라인을 가진 위치가 동시에 접근될 수 있다. 메모리 내의 단전 영역의 입도(granularity)는 메모리 칩의 설계 과정에서 단전 회로에 의해 요구되는 추가 부분과 비 교하여 고려될 수 있다.이러한 동시 접근을 이행하기 위한 아키텍처가 도 46에 도시되어 있다. 구체적으로, 도 46은 단일 포트 메모리 어레이 또는 매트에 듀얼 포트 기능을 제공하는 예시적인 회로를 도시한 것이다. 도 46에 도시된 바와 같 이, 회로는 적어도 하나의 행과 적어도 하나의 열을 따라 배열된 복수의 메모리 매트(예, 4609a, 4609b 등)를 포함할 수 있다. 회로의 레이아웃은 행에 상응하는 워드라인(4611a, 4611b)과 같은 복수의 워드라 인과 열에 상응하는 비트라인(4615a, 4615b)을 더 포함할 수 있다. 도 46의 예는 각각 2개의 라인과 8개의 열이 있는 12개의 메모리 매트를 포함한다. 다른 실시예에서, 기판은 모 든 임의의 수의 메모리 매트를 포함할 수 있고, 각 메모리 매트는 모든 임의의 수의 라인과 모든 임의의 수의 열을 포함할 수 있다. 일부 메모리 매트는 동일 수의 라인과 열(도 46의 예)을 포함할 수 있는 반면에, 다른 메 모리 매트는 상이한 수의 라인 및/또는 열을 포함할 수 있다. 도 46에는 도시되어 있지 않지만, 회로는 읽기와 쓰기를 위한 2개(또는 3개 또는 모든 임의의 복수)의 어 드레스를 단일 클럭 사이클 동안에 수신하도록 구성된 적어도 하나의 로우 멀티플렉서(로우 디코더(4601a 및/또 는 4601b)와 분리 또는 일체) 또는 적어도 하나의 컬럼 멀티플렉서(예, 컬럼 멀티플렉서(4603a 및/또는 4603 b))를 더 사용할 수 있다. 또한, 본 실시예들은 로우 디코더(예, 로우 디코더(4601a 및/또는 4601b) 및 컬럼 멀 티플렉서(4603a 및/또는 4603b)와 분리 또는 일체일 수 있음)를 사용하여 2개(또는 그 이상)의 어드레스에 읽기 또는 쓰기를 할 수 있다. 예를 들어, 로우 디코더와 컬럼 디코더는 메모리 클럭 사이클 동안에 2개의 어드레스 중의 제1 어드레스를 적어도 하나의 로우 멀티플렉서 또는 적어도 하나의 컬럼 멀티플렉서로부터 읽어오고 제1 어드레스에 상응하는 워드라인 또는 비트라인을 디코딩할 수 있다. 또한, 로우 디코더와 컬럼 디코더는 동일한 메모리 사이클 동안에 2개의 어드레스 중의 제2 어드레스를 적어도 하나의 로우 멀티플렉서 또는 적어도 하나의 컬럼 멀티플렉서로부터 읽어오고 제2 어드레스에 상응하는 워드라인 또는 비트라인을 디코딩할 수 있다. 앞서 설명한 바와 같이, 2개의 어드레스가 단전 회로의 동일 부분(예, 4613a, 4613b 등과 같은 스위칭 요소)에 결합 되지 않은 상이한 위치에 있는 한, 접근은 동일 메모리 클럭 사이클 동안에 일어날 수 있다. 또한, 회로 는 제1 메모리 클럭 사이클 동안에 첫 번째 2개의 어드레스에 동시에 접근한 후에 제2 메모리 클럭 사이클 동안 에 두 번째 2개의 어드레스에 동시에 접근할 수 있다. 이러한 실시예에서, 회로를 사용하는 메모리 칩은 상응하는 논리 회로보다 클럭 속도가 적어도 2배 빠른 경우에 4포트 메모리로 기능할 수 있다. 도 46은 스위치로 기능하도록 구성된 적어도 하나의 행 회로 및 적어도 하나의 열 회로를 더 포함한다. 예를 들 어, 4613a, 4613b 등과 같은 상응하는 스위칭 요소는 4613a, 4613b 등과 같은 스위칭 요소에 연결된 워드라인 도는 비트라인으로부터 전류가 흐르도록 또는 흐르지 못하도록 및/또는 전압이 연결되도록 또는 연결되지 못하 도록 구성된 트랜지스터 또는 모든 임의의 다른 전기 요소를 포함할 수 있다. 따라서, 상응하는 스위칭 요소는 회로를 단전된 부분으로 구분할 수 있다. 여기에는 단일 행과 각 행의 16 열을 포함하는 것으로 도시되어 있지만, 회로 내의 단전된 부분은 회로의 설계에 따라 상이한 수준의 입도를 포함할 수 있다. 회로는 앞서 설명한 어드레스 동작 동안에 상응하는 단전된 영역을 활성화하기 위하여 컨트롤러(예, 행 컨트롤)를 사용하여 적어도 하나의 행 회로 및 적어도 하나의 열 회로의 상응하는 회로를 활성화할 수 있 다. 예를 들어, 회로는 스위칭 요소 중의 가까운 상응하는 스위칭 요소(예, 4613a, 4613b 등)로 하나 이 상의 제어 신호를 전송할 수 있다. 스위칭 요소(4613a, 4613b 등)가 트랜지스터를 포함하는 실시예에서, 제어 신호는 트랜지스터를 개방하기 위한 전압을 포함할 수 있다. 어드레스를 포함하는 단전된 영역에 따라, 스위칭 요소 중의 하나 이상이 회로에 의해 활성화될 수 있다. 예를 들어, 도 46의 메모리 매트(4609b) 내의 어드레스에 도달하기 위해, 메모리 매트(4609a)로의 접근을 허용 하는 스위칭 요소는 메모리 매트(4609b)로의 접근을 허용하는 스위칭 요소와 함께 개방되어야 한다. 행 컨트롤 은 회로 내의 특정 어드레스를 읽어오기 위하여 특정 어드레스에 따라 스위칭 요소의 활성화를 결 정할 수 있다. 도 46은 메모리 어레이(예, 메모리 매트(4609a, 4609b 등)를 포함)의 워드라인을 분리하는데 사용되는 회로 의 예를 나타낸 것이다. 그러나 다른 실시예들은 유사한 회로(예, 메모리 칩을 단전 영역으로 분리 하는 스위칭 요소)를 사용하여 메모리 어레이의 비트라인을 분리할 수 있다. 이에 따라, 회로의 아키텍처 는 도 42 또는 도 44에 도시된 것과 같은 듀얼-컬럼 접근에 사용될 수 있을 뿐만 아니라 도 43 또는 도 44에 도 시된 것과 같은 듀얼-로우 접근에 사용될 수 있다. 메모리 어레이 또는 매트로의 멀티 사이클 접근을 위한 프로세스가 도 47a에 도시되어 있다. 구체적으로, 도 47a는 싱글 포트 메모리 어레이 또는 매트(예, 도 43의 회로 또는 도 44의 회로 사용) 상에 듀얼 포트 접근을 제공하기 위한 프로세스의 예시적인 순서도이다. 프로세스는 도 43 또는 도 44의 로우디코더(4303 또는 4304) 및 컬럼 디코더(도 43 또는 도 44의 컬럼 멀티플렉서(4305 또는 4405)와 같은 하나 이 상의 컬럼 멀티플렉서와 분리 또는 일체일 수 있음)와 같은 본 개시에 따른 로우 디코더 및 컬럼 디코더를 사용 하여 실행될 수 있다. 단계 4710에서, 제1 메모리 클럭 사이클 동안에, 회로는 적어도 하나의 로우 멀티플렉서와 적어도 하나의 컬럼 멀티플렉서를 사용하여 2개의 어드레스의 제1 어드레스에 상응하는 워드라인 및 비트라인을 디코딩할 수 있다. 예를 들어, 적어도 하나의 로우 디코더는 워드라인을 활성화할 수 있고, 적어도 하나의 컬럼 멀티플렉서는 활성 화된 워드라인을 따르고 제1 어드레스에 상응하여 메모리 셀로부터의 전압을 증폭할 수 있다. 증폭된 전압은 회 로를 포함하는 메모리 칩을 활용하는 논리 회로로 제공되거나 하기에 설명하는 단계 4720에 따라 버퍼링 될 수 있다. 논리 회로는 GPU나 CPU와 같은 회로를 포함하거나, 예를 들어 도 7a에 도시된 바와 같이 메모리 칩과 동 일한 기판 상에 프로세싱 그룹을 포함할 수 있다. 상기에서는 읽기 동작으로 설명하였지만, 방법은 쓰기 동작도 유사하게 처리할 수 있다. 예를 들면, 적어 도 하나의 로우 디코더는 워드라인을 활성화하고, 적어도 하나의 컬럼 멀티플렉서는 활성화된 워드라인을 따르 고 제1 어드레스에 상응하여 메모리 셀로 전압을 인가하여 새로운 데이터를 메모리 셀에 기록할 수 있다. 일부 실시예에서, 회로는 회로를 포함하는 메모리 칩을 활용하는 논리 회로로 쓰기의 확인을 제공하거나 하기의 단계 4720에 따라 확인을 버퍼링 할 수 있다. 단계 4720에서, 회로는 제1 어드레스의 읽어온 데이터를 버퍼링 할 수 있다. 예를 들어, 도 43과 도 44에 도시 된 바와 같이, 버퍼로 인해 회로는 2개의 어드레스 중의 제2 어드레스를 읽어올 수 있고(하기의 단계 4730에서 설명) 두 읽어오기 모두의 결과를 함께 출력할 수 있다. 버퍼는 레지스터, SRAM, 비휘발성 메모리, 또는 모든 임의의 다른 데이터 스토리지 장치를 포함할 수 있다. 단계 4730에서, 제2 메모리 클럭 사이클 동안에, 회로는 적어도 하나의 로우 멀티플렉서와 적어도 하나의 컬럼 멀티플렉서를 사용하여 2개의 어드레스의 제2 어드레스에 상응하는 워드라인과 비트라인을 디코딩할 수 있다. 예를 들어, 적어도 하나의 로우 디코더는 워드라인을 활성화할 수 있고, 적어도 하나의 컬럼 멀티플렉서는 활성 화된 워드라인을 따르고 제2 어드레스에 상응하여 메모리 셀로부터의 전압을 증폭할 수 있다. 증폭된 전압은 회 로를 포함하는 메모리 칩을 활용하는 논리 회로로, 개별적으로 또는 예를 들어 단계 4720에서 버퍼링된 전압과 함께, 제공될 수 있다. 논리 회로는 GPU나 CPU와 같은 회로를 포함하거나, 예를 들어 도 7a에 도시된 바와 같이 메모리 칩과 동일한 기판 상에 프로세싱 그룹을 포함할 수 있다. 상기에서는 읽기 동작으로 설명하였지만, 방법은 쓰기 동작도 유사하게 처리할 수 있다. 예를 들면, 적어 도 하나의 로우 디코더는 워드라인을 활성화하고, 적어도 하나의 컬럼 멀티플렉서는 활성화된 워드라인을 따르 고 제2 어드레스에 상응하여 메모리 셀로 전압을 인가하여 새로운 데이터를 메모리 셀에 기록할 수 있다. 일부 실시예에서, 회로는 개별적으로 또는 단계 4720 등에서 버퍼링된 전압과 함께 회로를 포함하는 메모리 칩을 활 용하는 논리 회로로 쓰기의 확인을 제공할 수 있다 단계 4740에서, 회로는 버퍼링된 제1 어드레스와 함께 제2 어드레스의 읽어온 데이터를 출력할 수 있다. 예를 들어, 도 43과 도 44에 도시된 바와 같이, 회로는 두 읽어오기(예, 단계 4710과 단계 4730) 모두의 결과를 함께 출력할 수 있다. 회로는 회로를 포함하는 메모리 칩을 활용하는 논리 회로로 결과를 출력할 수 있다. 논리 회로 는 GPU나 CPU와 같은 회로를 포함하거나, 예를 들어 도 7a에 도시된 바와 같이 메모리 칩과 동일한 기판 상에 프로세싱 그룹을 포함할 수 있다. 상기에서는 다중 사이클에 대하여 설명하였지만, 도 42에 도시된 바와 같이 2개의 어드레스가 워드라인을 공유 하는 경우에, 방법은 2개의 어드레스로 단일 사이클 접근도 가능하다. 예를 들어, 다중 컬럼 멀티플렉서 가 동일 메모리 클럭 사이클 동안에 동일 워드라인 상의 상이한 비트라인을 디코딩할 수 있으므로, 단계 4710과 단계 4730은 동일 메모리 클럭 사이클 동안에 수행될 수 있다. 이러한 실시예에서, 버퍼링을 하는 단계 4720은 건너뛸 수 있다. 동시 접근(예, 상기에 설명한 회로를 활용)을 위한 프로세스가 도 47b에 도시되어 있다. 이에 따라, 단계 가 순차적으로 도시되어 있지만, 도 47b의 단계들은 동일 메모리 클럭 사이클 동안에 수행될 수 있고, 적어도 일부 단계들(예, 단계 4760과 4780 또는 단계 4770과 4790)은 동시에 실행될 수 있다. 구체적으로, 도 47b는 단 일 포트 메모리 어레이 또는 매트(예, 도 42의 회로 또는 도 46의 회로 활용) 상에 듀얼 포트 접근 을 제공하기 위한 프로세스의 예시적인 순서도이다. 프로세스는 도 42 또는 도 46의 로우 디코더 (4203 또는 4601a 및 4601b) 및 컬럼 디코더(도 42 또는 도 46의 컬럼 멀티플렉서(4205a 및 4205b 또는 4603a및 4603b)와 같은 하나 이상의 컬럼 멀티플렉서와 분리 또는 일체일 수 있음)와 같은 본 개시에 따른 로우 디코 더 및 컬럼 디코더를 사용하여 실행될 수 있다. 단계 4760에서, 회로는, 메모리 클럭 사이클 동안에, 2개의 어드레스의 제1 어드레스에 의거하여 적어도 하나의 행 회로와 적어도 하나의 열 회로의 상응하는 회로를 활성화할 수 있다. 예를 들어, 회로는 적어도 하나의 행 회로와 적어도 하나의 열 회로를 포함하는 스위칭 요소의 가까운 상응하는 요소로 하나 이상의 제어 신호를 전 송할 수 있다. 이에 따라, 회로는 2개의 어드레스의 제1 어드레스를 포함하는 상응하는 단전 영역에 접근할 수 있다. 단계 4770에서, 메모리 클럭 사이클 동안에, 회로는 적어도 하나의 로우 멀티플렉서와 적어도 하나의 컬럼 멀티 플렉서를 활용하여 제1 어드레스에 상응하는 워드라인과 비트라인을 디코딩할 수 있다. 예를 들면, 적어도 하나 의 로우 디코더는 워드라인을 활성화할 수 있고, 적어도 하나의 컬럼 멀티플렉서는 활성화된 워드라인을 따르고 제1 어드레스에 상응하여 메모리 셀로부터의 전압을 증폭할 수 있다. 증폭된 전압은 회로를 포함하는 메모리 칩 을 활용하는 논리 회로로 제공될 수 있다. 예컨대, 앞서 설명한 바와 같이, 논리 회로는 GPU나 CPU와 같은 회로 를 포함하거나, 예를 들어 도 7a에 도시된 바와 같이 메모리 칩과 동일한 기판 상에 프로세싱 그룹을 포함할 수 있다. 상기에서는 읽기 동작으로 설명하였지만, 방법은 쓰기 동작도 유사하게 처리할 수 있다. 예를 들면, 적어 도 하나의 로우 디코더는 워드라인을 활성화하고, 적어도 하나의 컬럼 멀티플렉서는 활성화된 워드라인을 따르 고 제1 어드레스에 상응하여 메모리 셀로 전압을 인가하여 새로운 데이터를 메모리 셀에 기록할 수 있다. 일부 실시예에서, 회로는 회로를 포함하는 메모리 칩을 활용하는 논리 회로로 쓰기의 확인을 제공할 수 있다. 단계 4780에서, 동일 사이클 동안에, 회로는 2개의 어드레스의 제2 어드레스에 의거하여 적어도 하나의 행 회로 와 적어도 하나의 열 회로의 상응하는 회로를 활성화할 수 있다. 예를 들어, 회로는 적어도 하나의 행 회로와 적어도 하나의 열 회로를 포함하는 스위칭 요소의 가까운 상응하는 요소로 하나 이상의 제어 신호를 전송할 수 있다. 이에 따라, 회로는 2개의 어드레스의 제2 어드레스를 포함하는 상응하는 단전 영역에 접근할 수 있다. 단계 4790에서, 동일 사이클 동안에, 회로는 적어도 하나의 로우 멀티플렉서와 적어도 하나의 컬럼 멀티플렉서 를 사용하여 제2 어드레스에 상응하는 워드라인과 비트라인을 디코딩할 수 있다. 예를 들어, 적어도 하나의 로 우 디코더는 워드라인을 활성화할 수 있고, 적어도 하나의 컬럼 멀티플렉서는 활성화된 워드라인을 따르고 제2 어드레스에 상응하여 메모리 셀로부터의 전압을 증폭할 수 있다. 증폭된 전압은 회로를 포함하는 메모리 칩을 활용하는 논리 회로로 제공될 수 있다. 예를 들어, 앞서 설명한 바와 같이, 논리 회로는 GPU나 CPU와 같은 종래 의 회로를 포함하거나, 도 7a에 도시된 바와 같이 메모리 칩과 동일한 기판 상에 프로세싱 그룹을 포함할 수 있 다. 상기에서는 읽기 동작으로 설명하였지만, 방법은 쓰기 동작도 유사하게 처리할 수 있다. 예를 들면, 적어 도 하나의 로우 디코더는 워드라인을 활성화하고, 적어도 하나의 컬럼 멀티플렉서는 활성화된 워드라인을 따르 고 제2 어드레스에 상응하여 메모리 셀로 전압을 인가하여 새로운 데이터를 메모리 셀에 기록할 수 있다. 일부 실시예에서, 회로는 회로를 포함하는 메모리 칩을 활용하는 논리 회로로 쓰기의 확인을 제공할 수 있다. 상기에서는 단일 사이클을 참조하여 설명하였지만, 2개의 어드레스가 워드라인과 비트라인을 공유하는(또는 적 어도 하나의 행 회로와 적어도 하나의 열 회로에서 스위칭 요소를 공유하는) 단전 영역에 있는 경우, 방법 은 2개의 어드레스로 멀티 사이클 접근을 가능하게 할 수 있다. 예를 들면, 단계 4760과 단계 4770은 제1 로우 디코더와 제1 컬럼 멀티플렉서가 제1 어드레스에 상응하는 워드라인과 비트라인을 디코딩할 수 있는 제1 메모리 클럭 사이클 동안에 수행될 수 있고, 단계 4780과 단계 4790은 제2 로우 디코더와 제2 컬럼 멀티플렉서 가 제2 어드레스에 상응하는 워드라인과 비트라인을 디코딩할 수 있는 제2 메모리 클럭 사이클 동안에 수행될 수 있다. 행과 열을 모두 따라 듀얼 포트 접근을 하는 아키텍처의 다른 예가 도 48에 도시되어 있다. 구체적으로, 도 48 은 다중 로우 디코더를 다중 컬럼 멀티플렉서와 함께 활용하여 행과 열을 모두 따라 듀얼 포트 접근을 제공하는 예시적인 회로를 도시한 것이다. 도 48에서, 로우 디코더(4801a)는 제1 워드라인에 접근할 수 있고, 컬럼 멀티플렉서(4803a)는 제1 워드라인을 따라 하나 이상의 메모리 셀로부터의 데이터를 디코딩할 수 있는 반면, 로 우 디코더(4801b)는 제2 워드라인에 접근할 수 있고, 컬럼 멀티플렉서(4803b)는 제2 워드라인을 따라 하나 이상 의 메모리 셀로부터의 데이터를 디코딩할 수 있다. 도 47b를 참조하여 설명한 바와 같이, 이 접근은 하나의 메모리 클럭 사이클 동안에 동시일 수 있다. 이에 따라, 도 46의 아키텍처와 유사하게, 도 48의 아키텍처(하기의 도 49에서 설명하는 메모리 매트를 포함)는 다중 어드레스가 동일 클럭 사이클에서 접근되도록 할 수 있다. 예를 들어, 도 48의 아키텍처는 모든 임의의 수의 로 우 디코더와 모든 임의의 수의 컬럼 멀티플렉서를 포함하여 로우 디코더와 컬럼 멀티플렉서의 수에 상응하는 수 의 어드레스가 모두 단일 메모리 클럭 사이클 이내에서 접근되도록 할 수 있다. 다른 실시예에서, 이 접근은 두 메모리 클럭 사이클을 따라 순차적일 수 있다. 메모리 칩의 클럭 속도를 상응하는 논리 회로보다 빠르게 함으로써, 두 메모리 클럭 사이클은 메모리를 사용하는 논리 회로에 대한 하나 의 클럭 사이클과 동등할 수 있다. 예를 들어, 앞서 설명한 바와 같이, 논리 회로는 GPU나 CPU와 같은 종래의 회로를 포함하거나, 도 7a에 도시된 바와 같이 메모리 칩과 동일한 기판 상에 프로세싱 그룹을 포함할 수 있다. 다른 실시예들은 동시 접근을 가능하게 할 수 있다. 예를 들어, 도 42를 참조하여 설명한 바와 같이, 다중 컬럼 디코더(도 48에 도시된 4803a 및 4803b와 같은 컬럼 멀티플렉서를 포함할 수 있음)가 단일 메모리 클럭 사이클 동안에 동일 워드라인을 따라 다중 비트라인을 읽을 수 있다. 추가적으로 또는 대안적으로, 도 46을 참조하여 설명한 바와 같이, 회로는 추가적인 회로를 포함하여 이 접근이 동시가 되게 할 수 있다. 예를 들면, 로 우 디코더(4801a)는 제1 워드라인에 접근하고, 컬럼 멀티플렉서(4803a)는 로우 디코더(4801b)가 제2 워드라인에 접근하는 동일 메모리 클럭 사이클 동안에 제1 워드라인을 따라 메모리 셀로부터의 데이터를 디코딩할 수 있고, 컬럼 멀티플렉서(4803b)는 제2 워드라인을 따라 메모리 셀로부터의 데이터를 디코딩할 수 있다. 도 48의 아키텍처는 도 49에 도시된 바와 같은 메모리 뱅크를 형성하는 변형 메모리 매트와 함께 사용될 수 있 다. 도 49에서, 각 메모리 셀(DRAM과 유사하게 커패시터로 도시되었지만 SRAM 또는 임의의 다른 메모리 셀과 유 사한 방식으로 배열된 다수의 트랜지스터를 포함할 수도 있음)에는 2개의 워드라인과 2개의 비트라인이 접근된 다. 이에 따라, 도 49의 메모리 매트는 2개의 상이한 비트를 동시에 접근할 수 있게 하거나 2개의 상이한 논리 회로에 의한 동일 비트의 접근마저 가능하게 한다. 그러나 도 49의 실시예는 상기의 실시예와 같이 단일 포트 접근을 위해 배선되는 표준 DRAM메모리 매트 상의 듀얼 포트 솔루션을 구현하기 보다는 메모리 매트의 변 형을 활용한다. 상기에서는 2개의 포트로 설명하였지만, 상기에 설명한 모든 임의의 실시예들은 2개의 포트 이상으로 확장될 수 있다. 예를 들어, 도 42, 도 46, 도 48, 및 도 49의 실시예들은 각각 추가적인 열 또는 로우 멀티플렉서를 포함 하여 단일 클럭 사이클 동안에 각각 추가적인 열 또는 행으로의 접근을 제공할 수 있다. 다른 예를 들면, 도 43 및 도 44의 실시예들은 추가적인 로우 디코더 및/또는 컬럼 멀티플렉서를 포함하여 단일 클럭 사이클 동안에 각 각 추가적인 행 또는 열로의 접근을 제공할 수 있다. 메모리 내의 가변 워드 길이 접근 이상과 이하에서, '결합'이라는 용어는 직접 연결, 간접 연결, 전기적 연결 등을 포함하는 의미로 사용될 수 있 다. 또한, '제1', '제2' 등의 용어는 이름이나 명칭이 동일하거나 유사한 구성요소 또는 방법 단계 사이의 구분을 위해 사용될 뿐이고, 반드시 공간적 또는 시간적 순서를 나타내는 것이 아니다. 일반적으로, 메모리 칩은 메모리 뱅크를 포함한다. 메모리 뱅크는 읽기나 쓰기를 할 특정 워드(또는 기타 고정 사이즈의 데이터 유닛)를 선택하도록 구성된 로우 디코더 및 컬럼 디코더에 결합될 수 있다. 각 메모리 뱅크는 데이터 유닛을 저장하기 위한 메모리 셀, 로우 디코더 및 컬럼 디코더에 의해 선택된 메모리 셀로부터의 전압을 증폭하기 위한 센스 증폭기, 및 모든 임의의 기타 적절한 회로를 포함할 수 있다. 각 메모리 뱅크는 보통 특정 I/O 폭을 가진다. 예를 들어, I/O 폭은 워드를 포함할 수 있다. 메모리 칩을 사용하는 논리 회로에 의해 실행되는 일부 프로세스는 매우 긴 워드를 사용하는 것이 이점이 있을 수 있는 반면에, 일부 다른 프로세스는 워드의 일부만 필요할 수 있다. 실제로, 인메모리(in-memory) 컴퓨팅 유닛(예, 도 7a에 도시되고 설명된 바와 같은, 메모리 칩과 동일한 기판에 배치된 프로세서 서브유닛)이 워드의 일부만 필요로 하는 메모리 접근 동작을 수행하는 경우가 흔하다. 워드의 일부만이 사용되는 경우에 워드 전체의 접근과 연관된 지연을 줄이기 위하여, 본 개시의 실시예들은 워 드의 하나 이상의 부분만을 가져오는 방법과 시스템을 제공함으로써 워드의 불필요한 부분의 전송과 연관된 데 이터 손실을 감소하고 메모리 장치의 전력 소모를 감소할 수 있다. 또한, 본 개시의 실시예들은 메모리 칩과, 워드의 일부에만 읽기와 쓰기를 하는 메모리 칩에 접근하는 기타 구 성(예, CPU나 GPU와 같이 분리되어 있거나, 도 7a에 도시되고 설명된 프로세서 서브유닛과 같이 메모리 칩과 동 일한 기판 상에 포함된, 논리 회로) 사이의 상호작용의 전력 소모도 감소시킬 수 있다. 메모리 접근 명령(예, 메모리를 사용하는 논리 회로로부터의 명령)은 메모리 내의 어드레스를 포함할 수 있다. 예를 들어, 어드레스는 로우 어드레스와 컬럼 어드레스를 포함하거나 메모리의 메모리 컨트롤러 등에 의해 로우 어드레스 및 컬럼 어드레스로 변환될 수 있다. DRAM과 같은 많은 휘발성 메모리에서, 로우 어드레스는 로우 디코더로 전송되고(예, 논리 회로에 의해 직접 또 는 메모리 컨트롤러를 활용하여), 로우 디코더는 행(워드라인이라고도 지칭) 전체를 활성화하고 당해 행에 포함 된 모든 비트라인을 로딩한다. 컬럼 어드레스는 비트라인을 포함하는 메모리 뱅크 외부와 다음 레벨 회로로 전송되는 활성화된 행 상의 비트라 인을 식별한다. 예를 들면, 다음 레벨 회로는 메모리 칩의 I/O 버스를 포함할 수 있다. 인메모리 프로세싱을 활 용하는 실시예에서, 다음 레벨 회로는 메모리 칩의 프로세서 서브유닛(예, 도 7a에 도시)을 포함할 수 있다. 이에 따라, 아래에 설명하는 메모리 칩은 도 3a, 도 3b, 도 4 내지 도 6, 도 7a 내지 도 7d, 도 11 내지 도 13, 도 16 내지 도 19, 도 22, 및 도 23의 하나 이상에 도시된 바와 같은 메모리 칩에 포함되거나 메모리 칩을 포함 할 수 있다. 메모리 칩은 논리 셀보다는 메모리 셀에 최적화된 제1 제조 프로세스에 의해 제조될 수 있다. 예를 들면, 제1 제조 프로세스에 의해 제조된 메모리 셀은 제1 제조 프로세스에 의해 제조된 논리 회로보다 임계 치수가 작을 (예, 2배, 3배, 4배, 5배, 6배, 7배, 8배, 9배, 10배 등만큼) 수 있다. 예컨대, 제1 제조 프로세스는 아날로그 제조 프로세스, DRAM 제조 프로세스 등을 포함할 수 있다. 이러한 메모리 칩은 메모리 유닛을 포함할 수 있는 집적회로를 포함할 수 있다. 메모리 유닛은 메모리 셀, 출력 포트, 및 읽기 회로를 포함할 수 있다. 일부 실시예에서, 메모리 유닛은 앞서 설명한 프로세서 서브유닛과 같은 처리부를 더 포함할 수 있다. 예를 들어, 읽기 회로는 출력 포트를 통해 제1 수의 비트까지 출력하기 위한 제1 그룹의 메모리 읽기 경로 및 리덕션 유닛을 포함할 수 있다. 출력 포트는 오프칩(off-chip) 논리 회로(예, 가속기, CPU, GPU 등) 또는 앞서 설명한 바와 같은 온칩(on-chip) 프로세서 서브유닛으로 연결될 수 있다. 일부 실시예에서, 처리부는 리덕션 유닛을 포함하거나, 리덕션 유닛의 일부이거나, 리덕션 유닛과 상이하거나, 리덕션 유닛을 포함할 수 있다. 인메모리 읽기 경로는 집적회로에 포함(예를 들어, 메모리 유닛에 포함)되거나, 메모리 셀에 읽기 및/또는 쓰기 를 하도록 구성된 모든 임의의 회로 및/또는 링크를 포함할 수 있다. 예를 들면, 인메모리 읽기 경로는 센스 증 폭기, 메모리 셀에 결합된 컨덕터, 멀티플렉서 등을 포함할 수 있다. 처리부는 메모리 유닛에서 제2 수의 비트를 읽기 위한 읽기 요청을 메모리 유닛으로 전송하도록 구성될 수 있다. 추가적으로 또는 대안적으로, 읽기 요청은 오프칩 논리 회로(예, 가속기, CPU, GPU 등)에서 유래할 수 있 다. 리덕션 유닛은 접근 요청과 관련된 전력 소모의 감소를 보조하도록(예, 여기에 기재된 부분 워드 접근의 하나 이상을 활용) 구성될 수 있다. 리덕션 유닛은 제1 수의 비트와 제2 수의 비트에 의거하여, 읽기 요청에 의해 촉발된 읽기 동작 동안에, 메모리 읽기 경로를 제어하도록 구성될 수 있다. 예를 들어, 리덕션 유닛으로부터의 제어 신호는 읽기 경로의 메모리 소모에 영향을 주어, 요청된 제2 수의 비트와 관련이 없는 메모리 읽기 경로의 에너지 소모를 감소시킬 수 있다. 예컨대, 리덕션 유닛은 제2 수가 제1 수보다 작은 경우에 무관한 메모리 읽기 경로를 제어하도록 구성될 수 있다. 앞서 설명한 바와 같이, 집적회로는 도 3a, 도 3b, 도 4 내지 도 6, 도 7a 내지 도 7d, 도 11 내지 도 13, 도 16 내지 도 19, 도 22, 및 도 23의 하나 이상에 도시된 바와 같은 메모리 칩에 포함되거나 메모리 칩을 포함할 수 있다. 무관한 인메모리 읽기 경로는, 제2 수의 비트에 포함되지 않은 제1 수의 비트의 비트와 같은, 제1 수의 비트의 무관한 비트와 연관될 수 있다.도 50은 메모리 셀 어레이의 메모리 셀(5001-5008), 비트(5021-5028)를 포함하는 출력 포트, 메모 리 읽기 경로(5011-5018)를 포함하는 읽기 회로, 및 리덕션 유닛을 포함하는 예시적인 집적회로 를 도시한 것이다. 제2 수의 비트가 상응하는 메모리 읽기 경로를 활용하여 읽히는 경우, 제1 수의 비트의 무관한 비트는 읽히지 않아야 하는 비트(예, 제2 수의 비트에 포함되지 않는 비트)에 상응할 수 있다. 읽기 동작 동안에, 리덕션 유닛은 활성화된 메모리 읽기 경로가 제2 수의 비트를 전달하도록 구성될 수 있도록 제2 수의 비트에 상응하는 메모리 읽기 경로를 활성화하도록 구성될 수 있다. 이러한 실시예에서, 제2 수의 비트에 상응하는 메모리 읽기 경로만이 활성화될 수 있다. 읽기 동작 동안에, 리덕션 유닛은 각각의 무관한 메모리 읽기 경로의 적어도 일부를 폐쇄하도록 구성될 수 있다. 예컨대, 무관한 메모리 읽기 경로는 제1 수의 비트의 무관한 비트에 상응할 수 있다. 여기서, 무관한 메모리 경로의 적어도 일부분을 폐쇄하는 대신에, 리덕션 유닛은 무관한 경로가 활성화되 지 않도록 할 수 있다. 추가적으로 또는 대안적으로, 읽기 동작 동안에, 리덕션 유닛은 무관한 메모리 읽기 경로를 저전력 모드 로 유지하도록 구성될 수 있다. 예를 들면, 저전력 모드는 무관한 메모리 경로에 정상 동작 전압 또는 전류보다 낮은 전압 또는 전류가 공급되는 모드를 포함할 수 있다. 리덕션 유닛은 무관한 메모리 읽기 경로의 비트라인을 제어하도록 더 구성될 수 있다. 이에 따라, 리덕션 유닛은 관련 있는 메모리 읽기 경로의 비트라인을 로드(load) 하고 무관한 메모리 읽 기 경로의 비트라인을 저전력 모드로 유지하도록 구성될 수 있다. 예를 들면, 관련 있는 메모리 읽기 경로의 비 트라인만이 로드 될 수 있다. 추가적으로 또는 대안적으로, 리덕션 유닛은 무관한 메모리 읽기 경로를 비활성화 상태로 유지하면서 관 련 있는 메모리 읽기 경로의 비트라인을 로드 하도록 구성될 수 있다. 일부 실시예에서, 리덕션 유닛은 읽기 동작 동안에 관련 있는 메모리 읽기 경로의 일부를 활용하고 무관 한 각 메모리 읽기 경로의 일부(비트라인과 다름)를 저전력 모드로 유지하도록 구성될 수 있다. 앞서 설명한 바와 같이, 메모리 칩은 센스 증폭기를 사용하여 내부에 포함된 메모리 셀로부터의 전압을 증폭할 수 있다. 이에 따라, 리덕션 유닛은 읽기 동작 동안에 관련 있는 메모리 읽기 경로의 일부를 활용하고 무 관한 메모리 읽기 경로의 적어도 일부와 연관된 센스 증폭기를 저전력 모드로 유지하도록 구성될 수 있다. 이러한 실시예에서, 리덕션 유닛은 읽기 동작 동안에 관련 있는 메모리 읽기 경로의 일부를 활용하고 관 련 없는 메모리 읽기 경로 모두와 연관된 하나 이상의 센스 증포기를 저전력 모드로 유지하도록 구성될 수 있다. 추가적으로 또는 대안적으로, 리덕션 유닛은 읽기 동작 동안에 관련 있는 메모리 읽기 경로의 일부를 활 용하고 무관한 메모리 읽기 경로와 연관된 하나 이상의 센스 증폭기를 따라가는(예, 공간적으로 및/또는 시간적 으로) 무관한 메모리 읽기 경로의 일부를 저전력 모드로 유지하도록 구성될 수 있다. 상기에 설명한 모든 임의의 실시예에서, 메모리 유닛은 컬럼 멀티플렉서(미도시)를 포함할 수 있다. 이러한 실시예에서, 리덕션 유닛은 컬럼 멀티플렉서와 출력 포트 사이에 결합될 수 있다. 추가적으로 또는 대안적으로, 리덕션 유닛은 컬럼 멀티플렉서에 내장될 수 있다. 추가적으로 또는 대안적으로, 리덕션 유닛은 메모리 셀과 컬럼 멀티플렉서 사이에 결합될 수 있다. 리덕션 유닛은 독립적으로 제어 가능할 수 있는 리덕션 서브유닛을 포함할 수 있다. 예를 들어, 상이한 리덕션 서브유닛은 상이한 메모리 유닛 열과 연관될 수 있다. 상기에서는 읽기 동작과 읽기 회로를 참조하여 설명하였지만, 상기의 실시예들은 쓰기 동작과 쓰기 회로에 대하 여 유사하게 적용될 수 있다. 예를 들어, 본 개시에 따른 집적회로는 메모리 셀, 출력 포트, 및 쓰기 회로를 포함하는 메모리 유닛을 포함할 수 있다. 일부 실시예에서, 메모리 유닛은 앞서 설명한 프로세서 서브유닛과 같은 처리부를 더 포함할 수 있다. 쓰기 회로는 출력 포트를 통하여 제1 수의 비트까지 출력하기 위한 제1 그룹의 메모리 쓰기 경로 및 리덕션 유닛을 포함할 수 있다. 처리부는 메모리 유닛으로부터 제2 수의 비트를 쓰기 위한 쓰기 요청을 메모리 유닛으로 전송하도록 구성될 수 있다. 추가적으로 또는 대안적으로, 쓰기 요청은 오프칩 논리 회로(예, 가속기, CPU, GPU 등)에서 유래할 수 있다. 리덕션 유닛은 제1 수의 비트와 제2 수의 비트에 의거하여, 쓰기 요청에 의해 촉발된 쓰기 동작 동안에, 메모리 쓰기 경로를 제어하도록 구성될 수 있다. 도 51은 로우 어드레스와 컬럼 어드레스를 활용하여(예, 온칩 프로세서 서브유닛 또는 가속기, CPU, GPU 등과 같은 오프칩 논리 회로로부터) 어드레스 된 메모리 셀 어레이를 포함하는 메모리 뱅크를 도시한 것 이다. 도 51에 도시된 바와 같이, 메모리 셀은 비트라인(세로) 및 워드라인(가로―대부분 생략되어 간략히 묘사 됨)으로 연결된다. 또한, 로우 디코더에는 로우 어드레스가 공급(예, 온칩 프로세서 서브유닛, 오프칩 논 리 회로, 또는 도 51에 도시되지 않은 메모리 컨트롤러로부터)될 수 있고, 컬럼 멀티플렉서에는 컬럼 어 드레스가 공급(예, 온칩 프로세서 서브유닛, 오프칩 논리 회로, 또는 도 51에 도시되지 않은 메모리 컨트롤러로 부터)될 수 있고, 컬럼 멀티플렉서는 최대 전체 라인으로부터 출력을 수신하고 출력 버스를 통해 워드까지 출력할 수 있다. 도 51에서, 컬럼 멀티플렉서의 출력 버스는 메인 I/O 버스에 결합 된다. 다른 실시예에서, 출력 버스는 로우 어드레스 및 컬럼 어드레스를 전송하는 메모리 칩의 프로세서 서브유닛(예, 도 7a에 도시)에 결합될 수 있다. 간략한 묘사를 위해, 메모리 뱅크를 메모리 매트로 분할하는 것 은 도시되지 않았다. 도 52는 메모리 뱅크를 도시한 것이다. 도 52에서, 메모리 뱅크는 출력 버스에 입력이 결합된 PIM(processing in memory) 로직도 포함하는 것으로 도시되어 있다. PIM 로직은 어드레스(예, 로 우 어드레스와 컬럼 어드레스를 포함)를 생성하고 PIM 어드레스 버스를 통해 출력하여 메모리 뱅크에 접 근할 수 있다. PIM 로직은 처리부를 포함하는 리덕션 유닛(예, 5030)의 예이다. PIM 로직은 전력의 감소를 보조하는 도 52에 도시되지 않은 다른 회로를 제어할 수 있다. PIM 로직은 또한 메모리 뱅크 를 포함하는 메모리 유닛의 메모리 경로를 포함할 수 있다. 앞서 설명한 바와 같이, 워드 길이(예, 한 번에 전송되는 것으로 선택된 비트라인의 수)는 일부 경우에 클 수 있다. 이러한 경우에서, 읽기 및/또는 쓰기를 위한 각 워드는 아래의 예와 같은 읽기 및/또는 쓰기 동작의 다양한 단 계에서 전력을 소모할 수 있는 메모리 경로와 연관될 수 있다. a. 비트라인 로딩―필요한 값으로 비트라인이 로드 되는 것을(읽기 사이클에서 비트라인 상의 커패시터로부터 또는 쓰기 사이클에서 커패시터로 기록될 새 값으로) 방지하려면, 메모리 어레이의 끝에 위치한 센스 증폭기를 비활성화하고 데이터를 보유하는 커패시터가 방전되거나 충전되지 않도록 할 필요가 있다(그렇지 않으면 저장된 데이터가 파괴된다). b. 센스 증폭기로부터, 비트라인을 선택하는 컬럼 멀티플렉서를 통해, 칩의 나머지 부분으로(칩의 내부로 또는 외부로 데이터를 전송하는 I/O 버스로 또는 메모리와 동일 기판 상의 프로세서 서브유닛과 같은, 데이터를 사용 하는, 내장 로직으로) 데이터 이동. 전력 절약을 활성화하기 위해, 본 개시의 집적회로는 워드의 일부 부분이 무관하다는 판단을 행 활성화 시간에 한 후에 비활성화 신호를 워드의 무관한 부분에 대한 하나 이상의 센스 증폭기로 전송할 수 있다. 도 53은 메모리 셀의 어레이, 로우 디코더, 출력 버스에 결합된 컬럼 멀티플렉서, 및 PIM 로직을 포함하는 메모리 유닛을 도시한 것이다. 메모리 유닛은 또한 컬럼 멀티플렉서로의 비트의 경로를 활성화 또는 비활성화하는 스위치를 포함한다. 스위치는 아날로그 스위치, 스위치 기능하도록 구성된 트랜지스터, 또는 메모리 유닛의 일부로 전압의 공급 및/또는 전류의 흐름을 제어하도록 구성된 모든 임의의 기타 회로를 포함할 수 있다. 센스 증폭기(미도시)는 메모리 셀 어레이의 끝에, 예를 들어 스위치보다 앞에(공간적으로 및/또는 시간적으 로), 위치할 수 있다. 스위치는 PIM 로직으로부터 버스를 통해 전송되는 인에이블 신호(enable signal)에 의해 제 어될 수 있다. 스위치는, 연결이 끊어진 경우에, 메모리 유닛의 센스 증폭기(미도시)의 연결을 끊고 따라 서 센스 증폭기로부터 연결이 끊어진 비트라인을 방전 또는 충전하지 않도록 구성될 수 있다. 스위치와 PIM 로직은 리덕션 유닛(예, 5030)을 구성할 수 있다. 또 다른 예에서, PIM 로직은 인에이블 신호를 스위치로 전송하는 대신에 센스 증폭기로 전송할 수 있다(예, 센스 증폭기에 활성화 입력이 있는 경우). 비트라인은 추가적으로 또는 대안적으로 다른 지점에서, 예를 들어 비트라인의 끝과 센스 증폭기 이후가 아닌 지점에서, 연결이 끊어질 수 있다. 예를 들면, 비트라인은 어레이로 들어가기 이전에 연결이 끊어질 수 있다. 이러한 실시예에서, 센스 증폭기 및 전송 하드웨어(예, 출력 버스)로부터의 데이터 전송에서도 전력이 절 약될 수 있다. 다른 실시예들(전력 절약은 덜하지만 구현이 더 수월한 실시예들)은 컬럼 멀티플렉서의 전력과 컬럼 멀티 플렉서으로부터 다음 레벨 회로로의 전송 손실의 감소에 초점을 맞춘다. 예를 들어, 앞서 설명한 바와 같 이, 다음 레벨 회로는 메모리 칩의 I/O 버스(예, 버스)를 포함할 수 있다. 인메모리 프로세싱을 활용하는 실시예에서, 다음 레벨 회로는 메모리 칩의 프로세서 서브유닛(예, PIM 로직)을 추가적으로 또는 대안적 으로 포함할 수 있다. 도 54a는 세그먼트로 분할된 컬럼 멀티플렉서를 도시한 것이다. 컬럼 멀티플렉서의 각 세그 먼트는 PIM 로직으로부터 버스를 통해 전송된 활성화 및/또는 비활성화 신호에 의해 개별적 으로 활성화 또는 비활성화될 수 있다. 컬럼 멀티플렉서는 또한 어드레스 컬럼 버스에 의해 공급될 수 있다. 도 54a의 실시예는 컬럼 멀티플렉서로부터의 출력의 다른 부분보다 더 나은 제어를 제공할 수 있다. 여기서, 상이한 메모리 경로의 제어는 비트 해상도가 상이할 수 있다. 예를 들어, 비트 해상도는 단일 비트 해 상도에서 다중 비트 해상도까지의 범위일 수 있다. 전자는 전력 감소에 더 효과적일 수 있고, 후자는 구현이 더 단순하고 제어 신호가 덜 필요할 수 있다. 도 54b는 예시적인 방법을 도시한 것이다. 예컨대, 방법은 상기에 도 50, 도 51, 도 52, 도 53, 또는 도 54a를 참조하여 설명한 모든 임의의 메모리 유닛을 활용하여 이행될 수 있다. 방법은 단계 5132와 단계 5134를 포함할 수 있다. 단계 5132에서, 메모리 유닛에서 제2 수의 비트를 읽기 위한 접근 요청을 집적회로의 처리부(예, PIM 로직 )가 집적회로의 메모리 유닛으로 전송할 수 있다. 메모리 유닛은 메모리 셀(예, 어레이의 메모리 셀), 출력 포트(예, 출력 버스), 및 리덕션 유닛(예, 리덕션 유닛)과 출력 포트를 통해 제1 수의 비트까지의 출력 및/또는 입력을 위한 제1 그룹의 메모리 읽기/쓰기 경로를 포함할 수 있는 읽기/쓰기 회로를 포함할 수 있다. 접근 요청은 읽기 요청 및/또는 쓰기 요청을 포함할 수 있다. 메모리 입력/출력 경로는 메모리 읽기 경로, 메모리 쓰기 경로, 및/또는 읽기와 쓰기에 모두 사용되는 경로를 포함할 수 있다. 단계 5134에서, 접근 요청에 대응할 수 있다. 예를 들어, 단계 5134에서, 제1 수의 비트와 제2 수의 비트에 의거하여, 접근 요청에 의해 촉발된 접근 동작 동 안에, 리덕션 유닛(예, 리덕션 유닛)이 메모리 읽기/쓰기 경로를 제어할 수 있다. 또한, 단계 5134에서, 다음 중의 어느 하나 및/또는 다음 중의 하나 이상의 모든 임의의 조합이 수행될 수 있다. 아래에 나열된 모든 임의의 동작은 접근 요청에 대응하는 동안에 실행될 수 있지만 접근 요청에 대한 대 응 이전 및/또는 이후에 실행될 수도 있다. 따라서, 단계 5134는 다음 중의 적어도 하나를 포함할 수 있다. a.제2 수가 제1수보다 작은 경우에 무관한 메모리 읽기 경로를 제어하는 단계― 여기서, 무관한 메모리 읽기 경 로는 제2 수의 비트에 포함되지 않는 제1 수의 비트의 비트와 연관됨; b.읽기 동작 동안에 관련 있는 메모리 읽기 경로를 활성화하는 단계― 여기서, 관련 있는 메모리 읽기 경로는 제2 수의 비트를 전달하도록 구성됨; c.무관한 메모리 읽기 경로 각각의 적어도 일부분을 읽기 동작 동안에 폐쇄하는 단계; d.무관한 메모리 읽기 경로를 읽기 동작 동안에 저전력 모드로 유지하는 단계; e.무관한 메모리 읽기 경로의 비트라인을 제어하는 단계; f.관련 있는 메모리 읽기 경로의 비트라인을 로드하고 무관한 메모리 읽기 경로의 비트라인을 저전력 모드로 유 지하는 단계; g.무관한 메모리 읽기 경로의 비트라인을 비활성화 상태로 유지하는 반면에 관련 있는 메모리 읽기 경로의 비트 라인을 로드하는 단계; h.읽기 동작 동안에 관련 있는 메모리 읽기 경로의 부분들을 활용하고 무관한 메모리 읽기 경로 각각의 일부분 을 저전력 모드로 유지하는 단계―여기서, 상기 일부분은 비트라인과 상이함; i. 읽기 동작 동안에 관련 있는 메모리 읽기 경로의 부분들을 활용하고 적어도 일부 무관한 메모리 읽기 경로에 대한 센스 증폭기를 저전력 모드로 유지하는 단계; j.읽기 동작 동안에 관련 있는 메모리 읽기 경로의 부분들을 활용하고 적어도 무관한 메모리 읽기 경로의 센스 증폭기를 저전력 모드로 유지하는 단계; 및 k.읽기 동작 동안에 관련 있는 메모리 읽기 경로의 부분들을 활용하고 무관한 메모리 읽기 경로의 센스 증폭기 이후의 무관한 메모리 읽기 경로의 부분들을 저전력 모드로 유지하는 단계. 저전력 모드 또는 유휴 모드(idle mode)는 메모리 접근 경로가 접근 동작을 위해 사용되는 경우의 전력 소비보 다 메모리 접근 경로의 전력 소비가 적은 모드를 포함할 수 있다. 일부 실시예에서, 저전력 모드는 메모리 접근 경로를 폐쇄하는 것을 포함할 수도 있다. 저전력 모드는 추가적으로 또는 대안적으로 메모리 접근 경로를 활성 화하지 않는 것을 포함할 수 있다. 여기서, 비트라인 단계 동안에 전력 감소가 일어나려면 메모리 접근 경로의 관련성 또는 무관성을 워드라인 개 방 전에 알고 있어야 할 수 있다. 다른 위치(예, 컬럼 멀티플렉서)에서 일어나는 전력 감소는 각 접근의 메모리 접근 경로의 관련성 또는 무관성의 결정이 가능할 수 있다. 고속 저전력 활성화 및 고속 접근 메모리 DRAM 및 기타 메모리 유형들(SRAM, 플래시메모리 등)은 일반적으로 로우 및 컬럼 접근 스키마를 감안하여 구성 되는 메모리 뱅크로부터 구성되는 경우가 흔하다. 도 55는 다중 메모리 매트와 연관 로직(예, 도 55에 각각 RD 및 COL로 도시된 로우 디코더 및 컬럼 디코더)을 포함하는 메모리 칩의 일례를 도시한 것이다. 도 55의 예에서, 매트는 뱅크로 그룹 지어지고 워드라인과 비트라인이 지나간다. 메모리 뱅크와 연관 로직은 도 55에 5141, 5142, 5143, 5144, 5145, 및 5146으로 표시되 고 적어도 하나의 버스를 공유한다. 메모리 칩은 도 3a, 도 3b, 도 4 내지 도 6, 도 7a 내지 도 7d, 도 11 내지 도 13, 도 16 내지 도 19, 도 22, 및 도 23의 하나 이상에 도시된 바와 같은 메모리 칩에 포함되거나 메모리 칩을 포함할 수 있다. 예컨대, DRAM에는 새 행의 활성화((예, 접근을 위한 새 라인을 준비)와 연관된 오버헤드가 많다. 라인이 활성화 (또는 라인의 개방)되면, 그 행의 데이터는 훨씬 빠른 접근을 위해 사용 가능할 수 있다. DRAM에서, 이러한 접 근은 무작위 방식으로 일어날 수 있다. 새 라인의 활성화와 연관된 두 가지 문제는 전력과 시간이다. c. 라인 상의 모든 커패시터에 한꺼번에 접근하고 라인을 로드해야 함에 따라 유발되는 전류의 빠른 흐름으로 인해 전력이 상승한다(예, 몇 개의 메모리 뱅크만 있는 라인을 개방하는 경우에 전력은 수 암페어에 이를 수 있 다). d. 시간 지연 문제는 대부분 행(워드라인)을 로드한 후에 열(비트라인)을 로드하는데 들어가는 시간과 연관된다. 본 개시의 일부 실시예들은 라인의 활성화 동안에 첨두 전력 소비를 감소하고 라인의 활성화 시간을 감소하는 시스템 및 방법을 포함할 수 있다. 일부 실시예들은 어느 정도까지 완전 무작위 접근을 희생하여 이러한 전력과 시간 비용을 감소시킬 수 있다. 예를 들어, 일 실시예에서, 메모리 유닛은 제1 메모리 매트, 제2 메모리 매트, 및 제2 메모리 매트에 포함된 제 2 그룹의 메모리 셀을 활성화하지 않고 제1 메모리 매트에 포함된 제1 그룹의 메모리 셀을 활성화하도록 구성된활성화부를 포함할 수 있다. 제1 그룹의 메모리 셀과 제2 그룹의 메모리 셀은 모두 메모리 유닛의 단일 행에 속 할 수 있다. 대안적으로, 활성화부는 제1 그룹의 메모리 셀을 활성화하지 않고 제2 메모리 매트에 포함된 제2 그룹의 메모리 셀을 활성화하도록 구성될 수 있다. 일부 실시예에서, 활성화부는 제1 그룹의 메모리 셀의 활성화 이후에 제2 그룹의 메모리 셀을 활성화하도록 구 성될 수 있다. 예를 들면, 활성화부는 제1 그룹의 메모리 셀의 활성화가 완료된 이후에 개시된 지연 기간의 만료에 후속하여 제2 그룹의 메모리 셀을 활성화하도록 구성될 수 있다. 추가적으로 또는 대안적으로, 활성화부는 제1 그룹의 메모리 셀에 결합된 제1 워드라인에 생성된 신호의 값에 의거하여 제2 그룹의 메모리 셀을 활성화하도록 구성될 수 있다. 상기에 설명한 모든 임의의 실시예들에서, 활성화부는 제1 워드라인 세그먼트와 제2 워드라인 세그먼트 사이에 배치된 중간 회로를 포함할 수 있다. 제1 워드라인 세그먼트는 제1 메모리 셀에 결합될 수 있고, 제2 워드라인 세그먼트는 제2 메모리 셀에 결합될 수 있다. 중간 회로의 예로는, 이게 국한되지 않지만, 도 56 내지 도 61에 일부가 도시된 스위치, 플립플롭, 버퍼, 인버터(inverter) 등이 있을 수 있다. 일부 실시예에서, 제2 메모리 셀은 제2 워드라인 세그먼트에 결합될 수 있다. 이러한 실시예에서, 제2 워드라인 세그먼트는 적어도 제1 메모리 매트를 통과하는 바이패스(bypass) 워드라인 경로에 결합될 수 있다. 이러한 바 이패스 경로의 일례가 도 61에 도시되어 있다. 활성화부는 단일 행과 연관된 워드라인으로부터의 활성화 신호에 의거하여 제1 그룹의 메모리 셀과 제2 그룹의 메모리 셀로의 전압의 공급(및/또는 전류의 흐름)을 제어하도록 구성된 제어부를 포함할 수 있다. 다른 예시적인 실시예에서, 메모리 유닛은 제1 메모리 매트, 제2 메모리 매트, 및 제1 메모리 매트의 제1 그룹 의 메모리 셀로 활성화 신호를 공급하고 적어도 제1 그룹의 메모리 셀의 활성화가 완료될 때까지 제2 메모리 매 트의 제2 그룹의 메모리 셀로의 활성화 신호의 공급을 지연하도록 구성된 활성화부를 포함할 수 있다. 제1 그룹 의 메모리 셀과 제2 그룹의 메모리 셀은 메모리 유닛의 단일 행에 속할 수 있다. 예를 들어, 활성화부는 활성화 신호의 공급을 지연하도록 구성된 지연부를 포함할 수 있다. 추가적으로 또는 대안적으로, 활성화부는 입력부에서 활성화 신호를 수신하고 활성화 신호의 적어도 하나의 특 성에 의거하여 지연부를 제어하도록 구성된 비교기(comparator)를 포함할 수 있다. 다른 예시적인 실시예에서, 메모리 매트는 제1 메모리 매트, 제2 메모리 매트, 및 제1 메모리 매트의 제1 메모 리 셀을 제1 메모리 셀이 활성화되는 초기 활성화 기간 동안에 제2 메모리 매트의 제2 메모리 셀로부터 격리하 고 초기 활성화 기간 후에 제1 메모리 셀을 제2 메모리 셀에 결합하도록 구성된 격리부를 포함할 수 있다. 제1 및 제2 메모리 셀은 메모리 유닛의 단일 행에 속할 수 있다. 하기의 예시들에서, 메모리 매트 자체에 대한 수정은 필요 없다. 일부 예에서, 실시예들은 메모리 뱅크에 대한 약간의 수정에 의존할 수 있다. 아래에 설명하는 도면들은 메모리 뱅크에 추가된 워드 신호를 짧게 하여 워드라인을 여러 개의 짧은 부분으로 나누는 메커니즘을 도시한다. 다음의 도면에서, 간략한 설명을 위해 다양한 메모리 뱅크 구성이 생략되었다. 도 56 내지 도 61은 상이한 그룹 내에 그룹으로 된 다중 메모리 매트(5150, 5150, 5150, 5150, 5150, 5150, 5151, 5151, 5151, 5151, 5151, 5151, 5152, 5152, 5152, 5152, 5152, 및 5152)와 로우 디코더를 포함하는 메모리 뱅크의 부분들(각각 5140, 5140, 5140, 5140, 5140, 및 5149로 표시)을 도시한 것이다. 행으로 배열된 메모리 매트는 상이한 그룹을 포함할 수 있다. 도 56 내지 도 59 및 도 61은 각 그룹이 한 쌍의 메모리 매트를 포함하는 9 그룹의 메모리 매트를 도시한다. 각 각 임의의 수의 메모리 매트를 포함하는 임의의 수의 그룹이 사용될 수 있다. 메모리 매트(5150, 5150, 5150, 5150, 5150, 및 5150)는 행으로 배열되고, 다중 메모리 라 인을 공유하며, 3개의 그룹으로 분류된다. 즉, 제1 상부 그룹은 5150과 5150로 표시된 메모리 매트를 포 함하고, 제2 상부 그룹은 5150과 5150로 표시된 메모리 매트를 포함하고, 제3 상부 그룹은 5150와 5150으로 표시된 메모리 매트를 포함한다. 마찬가지로, 메모리 매트(5151, 5151, 5151, 5151, 5151, 및 5151)는 행으로 배열되고, 다 중 메모리 라인을 공유하며, 3개의 그룹으로 분류된다. 즉, 제1 중간 그룹은 5151과 5151로 표시된 메모 리 매트를 포함하고, 제2 중간 그룹은 5151과 5151로 표시된 메모리 매트를 포함하고, 제3 중간 그룹은 5151와 5151으로 표시된 메모리 매트를 포함한다. 또한, 메모리 매트(5152, 5152, 5152, 5152, 5152 및 5152)는 행으로 배열되고, 다중 메모 리 라인을 공유하며, 3개의 그룹으로 분류된다. 즉, 제1 하부 그룹은 5152과 5152로 표시된 메모리 매트 를 포함하고, 제2 하부 그룹은 5152과 5152로 표시된 메모리 매트를 포함하고, 제3 하부 그룹은 5152 와 5152로 표시된 메모리 매트를 포함한다. 모든 임의의 수의 메모리 매트가 행으로 배열되고, 메모리 라인 을 공유하고, 모든 임의의 수의 그룹으로 분류될 수 있다. 예컨대, 각 그룹의 메모리 매트의 수는 1, 2, 또는 그 이상일 수 있다. 앞서 설명한 바와 같이, 활성화 회로는 동일 메모리 라인을 공유하는 다른 그룹의 메모리 매트를 활성화하지 않 고 한 그룹의 메모리 매트를 활성화하도록 구성될 수 있다. 또는, 라인 어드레스가 동일한 상이한 메모리 라인 세그먼트에 적어도 결합될 수 있다. 도 56 내지 도 61은 활성화 회로의 상이한 예를 도시한 것이다. 일부 실시예에서, 활성화 회로의 적어도 일부분 (예, 중간 회로)은 메모리 매트의 그룹 사이에 위치하여 한 그룹의 메모리 매트가 활성화되게 하는 반면에 동일 한 행의 다른 그룹의 메모리 매트는 활성화되지 않게 할 수 있다. 도 56은 제1 상부 그룹의 메모리 매트와 제2 상부 그룹의 메모리 매트의 상이한 라인 사이에 위치한 지연 또는 격리 회로(5153 - 5153)와 같은 중간 회로를 도시하고 있다. 도 56은 또한 제2 상부 그룹의 메모리 매트와 제3 상부 그룹의 메모리 매트의 상이한 라인 사이에 위치한 지연 또는 격리 회로(5154 - 5154)와 같은 중간 회로를 도시하고 있다. 추가적으로, 일부 지연 또는 격리 회로 는 중간 그룹의 메모리 매트로부터 형성된 그룹 사이에 위치한다. 또한, 일부 지연 또는 격리 회로는 하부 그룹 의 메모리 매트로부터 형성된 그룹 사이에 위치한다. 지연 또는 연기 회로는 로우 디코더로부터의 워드라인 신호가 다른 그룹의 행을 따라 전파되는 것을 지연 또는 중지할 수 있다. 도 57은 플립플롭(5155 - 5155 and 5156-5156)을 포함하는 지연 또는 격리 회로와 같은 중간회로 를 도시하고 있다. 활성화 신호가 워드라인으로 주입되는 경우, 제1 그룹의 매트(워드라인에 따라)가 활성화되는 반면에 워드라인 상의 다른 그룹은 비활성화 상태로 유지된다. 다른 그룹은 다음 클럭 사이클에 활성화될 수 있다. 예를 들어, 다른 그룹의 제2 그룹은 다음 클럭 사이클에서 활성화될 수 있고, 다른 그룹의 제3 그룹은 또 다른 클럭 사이클 이후에 활성화될 수 있다. 플립플롭은 D형 플립플롭 또는 모든 임의의 다른 유형의 플립플롭을 포함할 수 있다. D형 플립플롭으로 공급되 는 클럭은 단순화를 위해서 도면에서 생략되었다. 따라서, 제1 그룹으로의 접근은 전력을 사용하여 제1 그룹과 연관된 워드라인의 부분만을 충전할 수 있고, 이는 전체 워드라인을 충전하는 것보다 빠르고 전류도 덜 필요하다. 하나 이상의 플립플롭이 메모리 매트의 그룹 사이에 사용될 수 있으므로, 개방 부분 사이의 지연을 증가시킬 수 있다. 추가적으로 또는 대안적으로, 실시예들은 클럭을 느리게 하여 지연을 증가시킬 수 있다. 또한, 활성화되는 그룹들은 이전에 사용된 라인 값으로부터의 그룹들을 여전히 포함할 수 있다. 예를 들어, 방 법은 이전 라인의 데이터에 여전히 접근하면서 새로운 라인 세그먼트를 활성화하게 할 수 있어서, 새로운 라인 의 활성화와 연관된 페널티를 감소시킬 수 있다. 이에 따라, 일부 실시예들은 활성화된 제1 그룹이 있을 수 있고, 이전에 활성화된 라인의 다른 그룹들을 서로 간섭하지 않는 비트라인의 신호를 가지고 활성화 상태로 유지되도록 할 수 있다.추가적으로, 일부 실시예들은 스위치와 제어 신호를 포함할 수 있다. 제어 신호는 뱅크 컨트롤러에 의해 제어되 거나 제어 신호 사이에 플립플롭을 추가하여(예, 상기에 설명한 메커니즘과 동일한 타이밍 효과를 생성하여) 제 어될 수 있다. 도 58은 스위치(5157 - 5157 및 5158-5158 등)이고 한 그룹과 다른 그룹 사이에 위치하는 지연 또 는 격리 회로와 같은 중간 회로를 도시하고 있다. 그룹 사이에 위치한 한 세트의 스위치는 전용 제어 신호에 의 해 제어될 수 있다. 도 58에서, 제어 신호는 행 제어부(5160)에 의해 전송되고 상이한 세트의 스위치 사이의 하나 이상의 연속된 지연부(예, 5160 및 5160)에 의해 지연될 수 있다. 도 59는 연속된 인버터 게이트 또는 버퍼(예, 159 - 5159 및 5159'1(0 - 5159')이고 메모리 매트의 그룹들 사이에 위치한 지연 또는 격리 회로와 같은 중간 회로를 도시하고 있다. 스위치 대신에, 버퍼는 메모리 매트의 그룹들 사이에 사용될 수 있다. 버퍼는 스위치와 스위치 간에, 단일 트랜 지스터 구조를 사용하는 경우에 때때로 발생하는 효과인, 워드라인을 따른 전압 강하를 방지할 수 있다. 다른 실시예들은 메모리 뱅크에 추가된 영역을 활용함으로써 더욱 무작위한 접근을 허용하면서 매우 낮은 활성 화 전력과 시간을 제공할 수 있다. 메모리 매트에 근접하여 위치한 워드라인(예, 5152 - 5152)을 사용하는 일례가 도 60에 도시되어 있다. 이러한 워드라인들은 메모리 매트를 통과할 수도 또는 통과하지 않을 수도 있고 스위치(예, 5157 - 5157 )와 같은 중간 회로를 통해 메모리 매트 내의 워드라인들에 결합할 수 있다. 스위치는 어느 메모리 매트가 활성화될지를 제어할 수 있고 메모리 컨트롤러가 각 시점에 관련이 있는 라인 부분만 활성화하도록 할 수 있다. 상기에 설명한 라인 부분의 연속 활성화를 사용하는 실시예와 달리, 도 60의 예는 더 강한 제어를 제공할 수 있 다. 로우 파트 인에이블 신호(5170 및 5170)와 같은 인에이블 신호는 도시되지 않은 메모리 컨트롤러와 같은 로직에서 유래할 수 있다. 도 61은 글로벌 워드라인이 메모리 매트를 통과하고, 메모리 매트 외부로 보내질 필요가 없을 수 있는 워 드라인 신호에 대한 바이패스 경로를 형성하는 것을 도시하고 있다. 이에 따라, 도 61에 도시된 실시예는 메모 리 밀도에 약간의 손실을 감수하고 메모리 뱅크의 면적을 줄일 수 있다. 도 61에서, 글로벌 워드라인은 중단 없이 메모리 매트를 통과할 수 있고 메모리 셀에 연결되지 않을 수 있다. 로컬 워드라인 세그먼트는 스위치 중의 하나에 의해 제어되고 메모리 매트 내에서 메모리 셀에 연결될 수 있다. 메모리 매트의 그룹이 워드라인의 상당한 파티션을 제공하는 경우, 메모리 뱅크는 완전한 무작위 접근을 사실상 지원할 수 있다. 일부 배선과 로직을 또한 절약할 수 있고 워드라인을 따라 활성화 신호의 전파 속도를 감소시키는 다른 실시예 는 전용 인에이블 신호 및 인에이블 신호를 전달하는 전용 라인을 사용하지 않고 메모리 매트 사이에 다른 버퍼 링 또는 격리 회로 및/또는 스위치를 사용한다 예를 들어, 비교기를 사용하여 스위치 또는 기타 버퍼링 또는 격리 회로를 제어할 수 있다. 비교기는 비교기에 의해 모니터링 된 워드라인 세그먼트 상의 신호의 레벨이 특정 레벨에 도달하는 경우에 스위치 또는 기타 버퍼 링 또는 격리 회로를 활성화할 수 있다. 예를 들어, 특정 레벨은 이전 워드라인 세그먼트가 완전히 로드되었음 을 나타낼 수 있다. 도 62는 메모리 유닛의 동작을 위한 방법을 도시한 것이다. 예컨대, 방법은 도 56 내지 도 61을 참 조하여 앞서 설명한 메모리 뱅크의 하나 이상을 사용하여 이행될 수 있다. 방법은 단계 5192와 단계 5194를 포함할 수 있다. 단계 5192는 활성화부가 메모리 유닛의 제2 메모리 매트에 포함된 제2 그룹의 메모리 셀을 활성화하지 않고 메 모리 유닛의 제1 메모리 매트에 포함된 제1 그룹의 메모리 셀을 활성화하는 단계를 포함할 수 있다. 제1 그룹의 메모리 셀과 제2 그룹의 메모리 셀은 모두 메모리 유닛의 단일 행에 속할 수 있다. 단계 5194는 활성화부가 단계 5192 이후에 제2 그룹의 메모리 셀을 활성화하는 단계를 포함할 수 있다. 단계 5194는 제1 그룹의 메모리 셀이 활성화되는 동안, 제1 그룹의 메모리 셀의 완전 활성화 이후, 제1 그룹의 메모리 셀의 활성화가 완료된 이후에 개시된 지연 기간의 만료 이후, 제1 그룹의 메모리 셀이 비활성화된 이후등에 실행될 수 있다. 지연 기간은 고정 또는 조정될 수 있다. 예를 들어, 지연 기간의 길이는 메모리 유닛의 예상 접근 패턴에 의거 할 수 있거나 예상 접근 패턴과 무관하게 설정될 수 있다. 지연 기간은 1000분의 1초 내지 1초 이상의 범위일 수 있다. 일부 실시예에서, 단계 5194는 제1 그룹의 메모리 셀에 결합된 제1 워드라인 세그먼트 상에 생성된 신호의 값에 의거하여 개시될 수 있다. 예컨대, 신호의 값이 제1 임계값을 초과하는 경우, 제1 그룹의 메모리 셀이 완전히 활성화되었음을 나타내는 것일 수 있다. 단계 5192와 단계 5194의 하나는 제1 워드라인 세그먼트와 제2 워드라인 세그먼트 사이에 배치된 중간 회로(예, 활성화부의 중간 회로)를 사용할 수 있다. 제1 워드라인 세그먼트는 제1 메모리 셀에 결합될 수 있고, 제2 워드 라인 세그먼트는 제2 메모리 셀에 결합될 수 있다. 중간 회로의 예들은 도 56 내지 도 61에 도시되어 있다. 단계 5192와 단계 5194는 단일 행과 연관된 워드라인으로부터의 활성화 신호의 제1 그룹의 메모리 셀과 제2 그 룹의 메모리 셀로의 인가를 제어부가 제어하는 단계를 더 포함할 수 있다. 검사 시간 단축을 위한 메모리 병렬화(parallelism) 및 벡터를 활용하는 메모리의 검사 로직 본 개시의 일부 실시예들은 인칩 검사부(in chip testing unit)를 활용하여 검사의 속도를 빠르게 할 수 있다. 일반적으로, 메모리 칩의 검사에는 상당한 검사 시간이 필요하다. 검사 시간을 줄이면 생산 비용을 줄일 수 있 고 또한 더 많은 검사가 가능해지므로 제품의 신뢰성이 높아질 수 있다. 도 63과 도 64는 검사기 및 칩(또는 칩의 웨이퍼)을 도시한 것이다. 검사기는 검사를 관리하 는 소프트웨어를 포함할 수 있다. 검사기는 메모리의 전체에 대해 데이터의 상이한 시퀀스를 실행 한 후에 이 시퀀스를 다시 읽어 메모리의 불량 비트가 위치한 장소를 식별할 수 있다. 일단 인지가 되면, 검사기는 비트를 수리하기 위한 명령을 생성하고, 문제가 해결되는 경우에, 검사기는 메모리(521 0)의 검사 합격을 표명할 수 있다. 그렇지 않은 경우에, 일부 칩은 불량으로 표명될 수 있다. 검사기는 검사 시퀀스를 기록한 후에 데이터를 다시 읽어와서 예상 결과와 비교할 수 있다. 도 64는 검사기 및 병렬로 검사되는 칩(예, 5210)의 전체 웨이퍼가 있는 검사 시스템을 도시한 것 이다. 예컨대, 검사기는 배선의 버스로 칩의 각각에 연결될 수 있다. 도 64에 도시된 바와 같이, 검사기는 메모리 칩 모두에 읽기 및 쓰기를 몇 차례 해야 하고, 데이터는 외 부 칩 인터페이스를 통해 통과해야 한다. 또한, 일반적인 I/O 동작을 활용하여 제공될 수 있는 프로그램 가능한 구성 정보 등을 활용하여 집적회로의 로 직과 메모리 뱅크 모두를 검사하는 것이 이로울 수 있다. 또한, 집적회로 이내에 검사부가 있는 것이 검사에 유리할 수 있다. 검사부는 집적회로에 속해 있을 수 있고 검사 결과를 분석하고 로직(예, 도 7a에 도시되고 설명한 프로세서 서 브유닛) 및/또는 메모리(예, 복수의 메모리 뱅크 전체)의 불량 등을 발견할 수 있다. 메모리 검사기는 보통 매우 단순하고 단순 형식에 따라 집적회로와 검사 벡터를 교환한다. 예를 들어, 기록될 메모리 엔트리의 어드레스의 쌍 및 메모리 엔트리에 기록될 값을 포함하는 쓰기 벡터가 있을 수 있다. 또한, 읽 을 메모리 엔트리의 어드레스를 포함하는 읽기 벡터도 있을 수 있다. 쓰기 벡터의 어드레스의 적어도 일부는 읽 기 벡터의 어드레스의 적어도 일부와 동일할 수 있다. 쓰기 벡터의 적어도 일부 다른 어드레스는 읽기 벡터의 적어도 일부 다른 어드레스와 상이할 수 있다. 프로그램이 되면, 메모리 검사기는 또한 읽을 메모리 엔트리의 어드레스와 읽을 예상 값을 포함할 수 있는 예상 결과 벡터를 수신할 수 있다. 메모리 검사기는 읽는 값에 예상 값을 비교할 수 있다. 일 실시예에 따르면, 집적회로(집적회로의 메모리 포함 또는 미포함)의 로직(예, 프로세서 서브유닛)은 동일한 프로토콜/형식을 사용하여 메모리 검사기에 의해 검사될 수 있다. 예를 들어. 쓰기 벡터의 값의 일부는 집적회 로의 로직에 의해 실행될 명령일 수(및 계산 및/또는 메모리 접근을 포함할 수) 있다. 메모리 검사기는 메모리 엔트리 어드레스(적어도 일부는 계산의 예상 값을 저장)를 포함할 수 있는 예산 결과 벡터 및 읽기 벡터로 프로 그램 될 수 있다. 따라서, 메모리 검사기는 로직뿐만 아니라 메모리의 검사에 사용될 수 있다. 메모리 검사기는일반적으로 로직 검사기보다 훨씬 단순하고 저렴하며, 제시된 방법을 통해 단순한 메모리 검사기를 활용하여 복 잡한 로직 검사를 수행할 수 있다. 일부 실시예에서, 메모리 이내의 로직은 벡터(또는 기타 데이터 구조)만을 활용하고 로직 검사에 흔히 사용되는 더욱 복잡한 메커니즘(예, 인터페이스 등을 통해 컨트롤러와 통신하여 어느 회로를 검사할지 로직에 지시)을 활 용하지 않고 메모리 이내의 로직의 검사를 가능하게 한다. 검사부를 사용하는 대신에, 메모리 컨트롤러는 구성 정보에 포함된 메모리 엔트리에 접근하라는 명령을 수신하 고 접근 명령을 실행하고 결과를 출력하도록 구성될 수 있다. 도 65 내지 도 69에 도시된 집적회로의 하나 이상은 검사부가 없이도 또는 검사를 수행할 능력이 없는 검사기가 있어도 검사를 실행할 수 있다. 본 개시의 실시예들은 메모리의 병렬화(parallelism) 및 내부 칩 대역폭을 활용하여 검사 시간을 단축하고 향상 하는 방법 및 시스템을 포함할 수 있다. 방법과 시스템은 메모리 칩이 그 자체를 검사하고(검사기가 검사를 실행하고, 검사 결과를 읽고, 결과를 분석하 는 것이 아닌), 결과를 저장하고, 및 궁극적으로 검사기가 결과를 읽도록 하는(및, 필요한 경우, 메모리 칩을 다시 프로그램하여 중복 메커니즘을 활성화하는 등) 것에 기반할 수 있다. 검사는 메모리의 검사 또는 메모리 뱅크와 로직의 검사(앞서 도 7a를 참조하여 설명한 바와 같은 검사할 기능적 논리부가 있는 계산 메모리의 경우)를 포함할 수 있다. 일 실시예에서, 방법은 외부 대역폭이 검사를 제한하지 않도록 칩 이내에서 데이터를 읽기 및 쓰기 하는 단계를 포함할 수 있다. 메모리 칩이 프로세서 서브유닛을 포함하는 실시예에서, 각 프로세서 서브유닛은 검사 코드 또는 구성으로 프로 그램 될 수 있다. 메모리 칩이 검사 코드를 실행할 수 없는 프로세서 서브유닛을 포함하거나 프로세서 서브유닛이 없지만 메모리 컨트롤러를 포함하는 실시예에서, 메모리 컨트롤러는 패턴을 읽고 쓰고(예, 외부적으로 컨트롤러에 프로그램) 추가적인 분석을 위해 불량의 위치를 표시(예, 메모리 엔트리에 값을 기록하고, 엔트리를 읽고, 기록된 값과 다 른 값을 수신)하도록 구성될 수 있다. 여기서, 메모리의 검사에는 방대한 수의 비트의 검사, 예를 들어, 메모리의 각 비트를 검사하고 검사된 비트가 기능함을 확인하는 것이 필요할 수 있다. 또한, 메모리 검사는 상이한 전압 및 온도 조건 하에서 때때로 반복될 수 있다. 일부 불량에 대해, 하나 이상의 중복 메커니즘이 활성화될 수(예, 플래시 또는 OTP를 프로그램 하거나 퓨즈를 태워서) 있다. 또한, 메모리 칩의 논리 및 아날로그 회로(예, 컨트롤러, 레귤레이터, I/O)의 검사도 필요할 수 있다. 일 실시예에서, 집적회로는 기판, 기판 상에 배치된 메모리 어레이, 기판 상에 배치된 프로세싱 어레이, 및 기 판 상에 배치된 인터페이스를 포함할 수 있다. 여기서 설명하는 집적회로는 도 3a, 도 3b, 도 4 내지 도 6, 도 7a 내지 도 7d, 도 11 내지 도 13, 도 16 내지 도 19, 도 22, 및 도 23의 하나 이상에 도시된 바와 같은 메모리 칩에 포함되거나 메모리 칩을 포함할 수 있다. 도 65 내지 도 69는 다양한 집적회로 및 검사기를 도시하고 있다. 집적회로는 메모리 뱅크, 칩 인터페이스(예, 메모리 뱅크가 공유하는 버스 및 I/O 컨트롤러 ), 및 논리부(이하 \"로직\"으로 칭함)를 포함하는 것으로 도시되어 있다. 도 66은 퓨즈 인터페이스 및 퓨즈 인터페이스와 상이한 메모리 뱅크에 결합된 버스를 도시하고 있다. 도 65 내지 도 70은 또한 다음과 같은 검사 프로세스의 다양한 단계를 도시하고 있다. a. 검사 시퀀스를 쓰는 단계 (도 65, 도 67, 도 68, 도 69); b. 검사 결과를 읽어오는 단계 (도 67, 도 68, 도 69); c. 예상 결과 시퀀스를 쓰는 단계 (도 65); d. 수정할 불량 어드레스를 읽어오는 단계 (도 66); 및 e. 퓨즈를 프로그램 하는 단계 (도 66). 각 메모리 뱅크는 그 자체의 논리부에 결합 및/또는 논리부에 의해 제어될 수 있다. 그러나 앞서 설명한 바와 같이, 논리부로의 모든 임의의 할당이 제공될 수 있다. 따라서, 논리부의 수는 메모리 뱅크의 수와 다를 수 있고, 논리부는 하나 이상의 메모리 뱅크 또는 한 메모리 뱅크의 일부 등을 제어할 수 있 다. 논리부는 하나 이상의 검사부를 포함할 수 있다. 또 65는 논리부 내의 검사부(TU)를 도시하 고 있다. TU는 논리부의 전체 또는 일부에 포함될 수 있다. 여기서, 검사부는 논리부와 분리되어 있거나 논리부와 일체일 수 있다. 도 65는 또한 TU 내의 검사 패턴 생성기(GEN으로 표시)를 도시하고 있다. 검사 패턴 생성기는 검사부의 전체 또는 일부에 포함될 수 있다. 간략한 도시를 위해, 검사 패턴 생성기와 검사 부는 도 66 내지 도 70에는 도시되어 있지 않지만 이러한 실시예들에 포함될 수 있다. 메모리 어레이는 다중 메모리 뱅크를 포함할 수 있다. 또한, 프로세싱 어레이는 복수의 검사부를 포함할 수 있 다. 복수의 검사부는 다중 메모리 뱅크를 검사하여 검사 결과를 제공하도록 구성될 수 있다. 인터페이스는 검사 결과를 나타내는 정보를 집적회로 외부의 장치로 출력하도록 구성될 수 있다. 복수의 검사부는 다중 메모리 뱅크의 하나 이상의 검사에 사용할 적어도 하나의 검사 패턴을 생성하도록 구성된 적어도 하나의 검사 패턴 생성기를 포함할 수 있다. 일부 실시예에서, 앞서 설명한 바와 같이, 복수의 검사부 각각은 복수의 검사부의 특정 검사부에 의해 사용될 검사 패턴을 생성하여 다중 메모리 뱅크의 적어도 하나를 검사하도록 구성된 검사 패턴 생성기를 포함할 수 있다. 앞서 설명한 바와 같이, 도 65는 검사부 내의 검사 패 턴 생성기(GEN)를 도시하고 있다. 하나 이상의 또는 모든 논리부가 검사 패턴 생성기를 포함할 수 있다. 적어도 하나의 검사 패턴 생성기는 적어도 하나의 검사 패턴을 생성하기 위한 명령을 인터페이스로부터 수신하 도록 구성될 수 있다. 검사 패턴은 검사 중에 접근되어야 할(예, 읽기 및/또는 쓰기 할) 메모리 엔트리 및/또는 엔트리에 기록될 값 등을 포함할 수 있다. 인터페이스는 집적회로 외부에 있을 수 있는 외부 장치로부터 적어도 하나의 검사 패턴 생성을 위한 명령을 포 함하는 구성 정보를 수신하도록 구성될 수 있다. 적어도 하나의 검사 패턴 생성기는 메모리 어레이로부터 적어도 하나의 검사 패턴을 생성하기 위한 명령을 포함 하는 구성 정보를 읽어오도록 구성될 수 있다. 일부 실시예에서, 구성 정보는 벡터를 포함할 수 있다. 인터페이스는 적어도 하나의 검사 패턴일 수 있는 명령을 포함하는 구성 정보를 집적회로의 외부에 있을 수 있 는 장치로부터 수신하도록 구성될 수 있다. 예를 들어, 적어도 하나의 검사 패턴은 메모리 어레이의 검사 동안에 접근되어야 할 메모리 어레이 엔트리를 포 함할 수 있다. 적어도 하나의 검사 패턴은 메모리 어레이의 검사 동안에 접근된 메모리 어레이에 기록될 입력 데이터를 더 포 함할 수 있다. 추가적으로 또는 대안적으로, 적어도 하나의 검사 패턴은 메모리 어레이의 검사 동안에 접근된 메모리 어레이 엔트리에 기록될 입력 데이터 및 메모리 어레이의 검사 동안에 접근된 메모리 어레이 엔트리에서 읽어올 출력 데이터의 예상 값을 더 포함할 수 있다. 일부 실시예에서, 복수의 검사부는 복수의 검사부에 의해 실행되면 복수의 검사부가 메모리 어레이를 검사하도 록 유발하는 검사 명령을 메모리 어레이로부터 가져오도록 구성될 수 있다. 예를 들어, 검사 명령은 구성 정보에 포함될 수 있다. 구성 정보는 메모리 어레이 검사의 예상 결과를 포함할 수 있다. 추가적으로 또는 대안적으로, 구성 정보는 메모리 어레이의 검사 동안에 접근된 메모리 어레이 엔트리로부터 읽 어올 출력 데이터의 값을 포함할 수 있다.추가적으로 또는 대안적으로, 구성 정보는 벡터를 포함할 수 있다. 일부 실시예에서, 복수의 검사부는 복수의 검사부에 의해 실행되면 복수의 검사부가 메모리 어레이를 검사하고 프로세싱 어레이를 검사하도록 유발하는 검사 명령을 메모리 어레이로부터 가져오도록 구성될 수 있다. 예를 들어, 검사 명령은 구성 정보에 포함될 수 있다. 구성 정보는 벡터를 포함할 수 있다. 추가적으로 또는 대안적으로, 구성 정보는 메모리 어레이 검사와 프로세싱 어레이 검사의 예상 결과를 포함할 수 있다. 일부 실시예에서, 앞서 설명한 바와 같이, 복수의 검사부는 다중 메모리 뱅크의 검사 동안에 사용되는 검사 패 턴의 생성을 위한 검사 패턴 생성기가 없을 수 있다. 이러한 실시예에서, 복수의 검사부의 적어도 2개의 검사부는 다중 메모리 뱅크의 적어도 2개의 메모리 뱅크를 병렬로 검사하도록 구성될 수 있다. 대안적으로, 복수의 검사부의 적어도 2개의 검사부는 다중 메모리 뱅크의 적어도 2개의 메모리 뱅크를 직렬로 검사하도록 구성될 수 있다. 일부 실시예에서, 검사 결과를 나타내는 정보는 불량 메모리 어레이 엔트리의 식별자를 포함할 수 있다. 일부 실시예에서, 인터페이스는 복수의 검사 회로에 의해 확보된 부분적 검사 결과를 메모리 어레이의 검사 동 안에 여러 회 가져오도록 구성될 수 있다. 일부 실시예에서, 집적회로는 메모리 어레이의 검사 동안에 검출된 적어도 하나의 오류를 수정하도록 구성된 오 류 수정부를 포함할 수 있다. 예를 들어, 오류 수정부는 일부 메모리 워드를 비활성화하고 이러한 워드를 중복 워드로 대체하는 등의 모든 임의의 적절한 방법을 활용하여 메모리 오류를 수정하도록 구성될 수 있다. 상기의 모든 임의의 실시예에서, 집적회로는 메모리 칩일 수 있다. 예컨대, 집적회로는 분산 프로세서를 포함할 수 있고, 여기서 프로세싱 어레이는 도 7a에 도시된 바와 같은 분 산 프로세서의 복수의 서브유닛을 포함할 수 있다. 이러한 실시예에서, 프로세서 서브유닛의 각각은 다중 메모리 뱅크의 상응하는 전용 메모리 뱅크와 연관될 수 있다. 앞서 설명한 모든 임의의 실시예에서, 검사 결과를 나타내는 정보는 적어도 하나의 메모리 뱅크의 상태를 나타 낼 수 있다. 메모리 뱅크의 상태는, 메모리 워드 당, 엔트리 그룹 당, 또는 전체 메모리 뱅크 당의 하나 이상의 입도로 제공될 수 있다. 도 65 내지 도 66은 검사기 검사 단계의 4단계를 도시하고 있다. 제1 단계에서, 검사기는 검사 시퀀스를 기록하고, 메모리 뱅크의 논리부는 데이터를 메모리에 기록한다. 로직은 검사기로부터 명령을 수신하고 자체적으로 검사 시퀀스를 생성(하기에 설명)할 정도로 복잡할 수도 있다. 제2 단계에서, 검사기는 예상 결과를 검사된 메모리에 기록하고, 논리부는 메모리 뱅크에서 읽어온 데이 터에 예상 결과를 비교하여 오류의 목록을 저장한다. 예상 결과를 기록하는 단계는 로직이 자체적으로 예상 결 과의 시퀀스를 생성(하기에 설명)할 수 있을 정도로 복잡한 경우에 단순화될 수 있다. 제3 단계에서, 검사기는 논리부로부터 불량 어드레스를 판독한다. 제4 단계에서, 검사기는 결과에 의거하여 행동하고 오류를 수정할 수 있다. 예를 들면, 특정 인터페이스 에 연결하여 메모리 내에 퓨즈를 프로그램 하지만 메모리 내에 오류 수정 메커니즘을 프로그램 할 수 있게 하는 모든 임의의 다른 메커니즘을 활용할 수도 있다. 이러한 실시예에서, 메모리 검사기는 벡터를 활용하여 메모리를 검사할 수 있다. 예를 들어, 각 벡터는 입력 시리즈와 출력 시리즈로부터 구성될 수 있다. 입력 시리즈는 메모리에 기록할 데이터와 어드레스의 쌍을 포함할 수 있다(많은 실시예에서, 이 시리즈는 논리 부에 의해 실행된 프로그램과 같은 프로그램이 필요한 경우에 생성할 수 있게 하는 공식으로 모델링 될 수 있다). 일부 실시예에서, 검사 패턴 생성기는 이러한 벡터를 생성할 수 있다. 여기서, 벡터가 예시적인 데이터 구조이지만, 다른 실시예들은 다른 데이터 구조를 사용할 수 있다. 데이터 구 조는 집적회로 외부에 위치한 검사기에 의해 생성된 다른 검사 데이터 구조를 준수할 수 있다. 출력 시리즈는 메모리로부터 읽어올 예상 데이터를 포함하는 데이터와 어드레스 쌍을 포함할 수 있다(일부 실시 예에서, 이 시리즈는 런타임(runtime)에 프로그램에 의해, 예를 들면 논리부에 의해, 생성될 수 있다). 메모리 검사는 각각의 벡터가 입력 시리즈에 따라 메모리에 데이터를 쓴 후에 출력 시리즈에 따라 데이터를 읽 어오고 예상 데이터에 비교하는 벡터의 목록을 실행하는 단계를 일반적으로 포함한다. 부조화(mismatch)의 경우, 메모리는 불량으로 분류되거나, 메모리에 중복성에 대한 메커니즘이 있으면 중복 메 커니즘이 활성화되게 하여 활성화된 중복 메커니즘 상에서 벡터가 다시 검사되게 할 수 있다. 메모리가 프로세서 서브유닛(도 7a를 참조하여 설명)을 포함하거나 여러 메모리 컨트롤러를 포함하는 실시예에 서, 전체 검사는 메모리 뱅크의 논리부에 의해 처리될 수 있다. 따라서, 메모리 컨트롤러 또는 프로세서 서브유 닛이 검사를 수행할 수 있다. 메모리 컨트롤러는 검사기로부터 프로그램 될 수 있고, 검사의 결과는 검사기에 의한 추후 판독을 위해 메모리 컨트롤러 자체에 보관될 수 있다. 논리부의 동작을 구성 및 검사하기 위해, 검사기는 논리부를 메모리 접근이 되도록 구성하고 검사 결과가 메모 리 접근에 의해 판독될 수 있음을 확인할 수 있다. 예를 들면, 입력 벡터는 논리부에 대한 프로그래밍 시퀀스를 포함할 수 있고, 출력 벡터는 이러한 검사의 예상 결과를 포함할 수 있다. 예컨대, 프로세서 서브유닛과 같은 논리부가 메모리의 2개의 어드레스 상의 계산을 수 행하도록 구성된 배율기(multiplier) 또는 합산기(adder)를 포함하는 경우, 입력 벡터는 데이터를 메모리에 기 록하는 명령의 세트 및 합산기/배율기 로직으로 기록하는 명령의 세트를 포함할 수 있다. 합산기/배율기 결과가 출력 벡터로 읽어올 수만 있다면, 결과는 검사기로 전송될 수 있다. 검사는 메모리로부터 로직 구성을 로드하고 로직 출력이 메모리로 전송되게 하는 단계를 더 포함할 수 있다. 논리부가 그 구성을 메모리로부터 로드하는 실시예에서(예, 로직이 메모리 컨트롤러인 경우), 논리부는 코드를 메모리 그 자체로부터 실행할 수 있다. 이에 따라, 입력 벡터는 논리부에 대한 프로그램을 포함할 수 있고, 프로그램 그 자체가 논리부의 다양한 회로 를 검사할 수 있다. 따라서, 검사는 외부 검사기가 사용하는 형식으로 벡터를 수신하는 것으로 제한되지 않을 수 있다. 논리부로 로드되는 명령이 논리부에게 메모리 뱅크로 결과를 기록하도록 지시하는 경우, 검사기는 이러한 결과 를 판독하고 예상 출력 시리즈에 비교할 수 있다. 예를 들어, 메모리에 기록된 벡터는 논리부에 대한 검사 프로그램이거나 검사 프로그램(예, 검사는 메모리가 유 효하다는 가정 하에 하지만, 그렇지 않은 경우에도, 기록된 검사 프로그램은 작동하지 않을 것이고, 검사는 실 패할 것이며, 이는 어차피 칩이 유효하지 않으므로 용납될 만한 결과이다) 및/또는 논리부가 코드를 실행하고 결과를 메모리에 기록하는 방법을 포함할 수 있다. 논리부의 모든 검사는 메모리를 통해 수행될 수 있으므로(메 모리에 로직 검사 입력을 기록하고 검사 결과를 기록), 검사기는 입력 시퀀스와 예상 출력 시퀀스로 단순 벡터 검사를 실행할 수 있다. 로직 구성과 결과는 읽기 명령 및/또는 쓰기 명령으로 접근될 수 있다. 도 68은 벡터인 쓰기 검사 시퀀스를 전송하는 검사기를 도시한 것이다. 벡터의 부분들에는 프로세싱 어레이의 로직에 결합된 메모리 뱅크 사이에 나누어진 검사 코드 가 포함된다. 각 로직은 연관된 메모리 뱅크에 저장된 코드를 실행할 수 있고, 이러한 실행은 하나 이상의 메모 리 뱅크에 접근하는 단계, 계산을 수행하는 단계, 및 결과(예, 검사 결과)를 메모리 뱅크에 저장하는 단계를 포함할 수 있다. 검사 결과는 검사기에 의해 반송될 수 있다(예, 결과를 판독). 이로써, 로직은 I/O 컨트롤러에 의해 수신된 명령에 의해 제어될 수 있다. 도 68에서, I/O 컨트롤러는 메모리 뱅크와 로직으로 연결된다. 다른 실시예에서, 로직은 I/O 컨트롤러 와 메모리 뱅크 사이에 연결될 수 있다. 도 70은 메모리 뱅크를 검사하는 방법을 도시한 것이다. 예컨대, 방법은 앞서 도 65 내지 도 69를 참조하여 설명한 메모리 뱅크의 하나 이상을 활용하여 이행될 수 있다. 방법은 단계 5302, 단계 5310, 및 단계 5320을 포함할 수 있다. 단계 5302에서, 집적회로의 메모리 뱅크 를 검사하라는 요청을 수신할 수 있다. 집적회로는 기판, 기판 상에 배치되고 메모리 뱅크를 포함하는 메모리 어레이, 기판 상에 배치된 프로세싱 어레이, 및 기판 상에 배치된 인터페이스를 포함할 수 있다. 프로세싱 어레 이는 앞서 설명한 바와 같이 복수의 검사부를 포함할 수 있다. 일부 실시예에서, 요청은 구성 정보, 하나 이상의 벡터, 명령 등을 포함할 수 있다. 이러한 실시예에서, 구성 정보는 메모리 어레이 검사의 예상 결과, 명령, 데이터, 메모리 어레이의 검사 동안에 접근되는 메모리 어레이 엔트리로부터 판독될 출력 데이터의 값, 검사 패턴 등을 포함할 수 있다. 검사 패턴은 (i) 메모리 어레이의 검사 동안에 접근될 메모리 어레이 엔트리, (ii) 메모리 어레이의 검사 동안 에 접근된 메모리 어레이에 기록될 입력 데이터, 및 (iii) 메모리 어레이의 검사 동안에 접근된 메모리 어레이 엔트리로부터 판독될 출력 데이터의 예상 값 중의 적어도 하나를 포함할 수 있다. 단계 5302는 다음과 같은 단계들의 적어도 하나를 포함하고/하거나 다음과 같은 단계들의 적어도 하나가 후속할 수 있다. a. 적어도 하나의 검사 패턴을 생성하기 위한 명령을 적어도 하나의 검사 패턴 생성기가 인터페이스로부터 수신 하는 단계; b. 적어도 하나의 검사 패턴을 생성하기 위한 명령을 포함하는 구성 정보를 인터페이스가 집적회로 외부의 외부 장치로부터 수신하는 단계; c. 적어도 하나의 검사 패턴을 생성하기 위한 명령을 포함하는 구성 정보를 적어도 하나의 검사 패턴 생성기가 메모리 어레이로부터 읽어오는 단계; d. 적어도 하나의 검사 패턴인 명령을 포함하는 구성 정보를 인터페이스가 집적회로 외부의 외부 장치로부터 수 신하는 단계; e. 복수의 검사부에 의해 실행되면 복수의 검사부가 메모리 어레이를 검사하도록 유발하는 검사 명령을 복수의 검사부가 메모리 어레이로부터 가져오는 단계; 및 f. 복수의 검사부에 의해 실행되면 복수의 검사부가 메모리 어레이를 검사하고 프로세싱 어레이를 검사하도록 유발하는 검사 명령을 복수의 검사부가 메모리 어레이로부터 수신하는 단계. 단계 5302 이후에 단계 5310이 수행될 수 있다. 단계 5310에서, 복수의 검사부가 요청에 대응하여 다중 메모리 뱅크를 검사하고 검사 결과를 제공할 수 있다. 방법은 인터페이스가 복수의 검사부에 의해 확보된 부분적 검사 결과를 메모리 어레이의 검사 동안에 여 러 회 수신하는 단계를 더 포함할 수 있다. 단계 5310은 다음과 같은 단계들의 적어도 하나를 포함하고/하거나 다음과 같은 단계들의 적어도 하나가 후속할 수 있다. a. 하나 이상의 다중 메모리 뱅크의 적어도 하나를 검사하기 위해 검사부에 의해 사용될 검사 패턴을 하나 이상 의 검사 패턴 생성기(예, 복수의 검사부의 하나, 일부, 또는 모두에 포함된 검사 패턴 생성기)가 생성하는 단계; b. 복수의 검사부의 적어도 2개의 검사부가 다중 메모리 뱅크의 적어도 2개의 메모리 뱅크를 병렬로 검사하는 단계; c. 복수의 검사부의 적어도 2개의 검사부가 다중 메모리 뱅크의 적어도 2개의 메모리 뱅크를 직렬로 검사하는 단계; d. 메모리 엔트리에 값을 기록하고, 메모리 엔트리를 판독하고, 결과를 비교하는 단계; 및 e. 메모리 어레이의 검사 도중에 검출된 적어도 하나의 오류를 오류 수정부가 수정하는 단계. 단계 5310 이후에 단계 5320이 수행될 수 있다. 단계 5320에서, 검사 결과를 나타내는 정보를 인터페이스가 집 적회로의 외부로 출력할 수 있다. 검사 결과를 나타내는 정보는 불량 메모리 어레이 엔트리의 식별자를 포함할 수 있다. 이로써, 각 메모리 엔트 리에 관한 읽기 데이터를 전송하지 않음으로써 시간을 절약할 수 있다. 추가적으로 또는 대안적으로, 검사 결과를 나타내는 정보는 적어도 하나의 메모리 뱅크의 상태를 나타낼 수 있 다. 이에 따라, 일부 실시예에서, 검사 결과를 나타내는 정보는 검사 동안에 메모리 뱅크에 기록되거나 메모리 뱅크 로부터 판독된 데이터 유닛의 총 사이즈보다 훨씬 작을 수 있고, 검사부의 도움 없이 메모리를 검사하는 검사기 에서 전송될 수 있는 입력 데이터보다 훨씬 작을 수 있다. 검사된 집적회로는 상기에 설명한 도면의 하나 이상에 도시된 바와 같은 메모리 칩 및/또는 분산 프로세서를 포 함할 수 있다. 예를 들어, 여기서 설명하는 집적회로는 도 3a, 도 3b, 도 4 내지 도 6, 도 7a 내지 도 7d, 도 11 내지 도 13, 도 16 내지 도 19, 도 22, 및 도 23의 하나 이상에 도시된 바와 같은 메모리 칩에 포함되거나 메모리 칩을 포함할 수 있다. 도 71은 집적회로의 메모리 뱅크를 검사하는 방법의 일례를 도시한 것이다. 예컨대, 방법은 앞서 도 65 내지 도 69를 참조하여 설명한 메모리 뱅크의 하나 이상을 활용하여 이행될 수 있다. 방법은 단계 5352, 단계 5355, 및 단계 5358을 포함할 수 있다. 단계 5352에서, 명령을 포함하는 구성 정 보를 집적회로의 인터페이스가 수신할 수 있다. 인터페이스를 포함하는 집적회로는 또한 기판, 메모리 뱅크를 포함하고 기판 상에 배치되는 메모리 어레이, 기판 상에 배치되는 프로세싱 어레이, 및 기판 상에 배치된 인터 페이스를 포함할 수 있다. 구성 정보는 메모리 어레이 검사의 예상 결과, 명령, 데이터, 메모리 어레이의 검사 동안에 접근되는 메모리 어 레이 엔트리로부터 판독될 출력 데이터의 값, 검사 패턴 등을 포함할 수 있다. 추가적으로 또는 대안적으로, 구성 정보는 명령, 명령을 기록할 메모리 엔트리의 어드레스, 입력 데이터를 포함 할 수 있고, 명령의 실행 동안에 계산된 출력 값을 수신하기 위한 메모리 엔트리의 어드레스도 포함할 수 있다. 검사 패턴은 (i) 메모리 어레이의 검사 동안에 접근될 메모리 어레이 엔트리, (ii) 메모리 어레이의 검사 동안 에 접근된 메모리 어레이에 기록될 입력 데이터, 및 (iii) 메모리 어레이의 검사 동안에 접근된 메모리 어레이 엔트리로부터 판독될 출력 데이터의 예상 값 중의 적어도 하나를 포함할 수 있다. 단계 5352 이후에 단계 5355가 수행될 수 있다. 단계 5355에서, 메모리 어레이에 접근하고, 연산 동작을 수행하 고, 결과를 제공하여 프로세싱 어레이가 명령을 실행할 수 있다. 단계 5355 이후에 단계 5358이 수행될 수 있다. 단계 5358에서, 결과를 나타내는 정보를 인터페이스가 집적회로 의 외부로 출력할 수 있다. 사이버 보안 및 위조 검출 방법 메모리 칩 및/또는 프로세서는 악의적 이용자의 타깃이 될 수 있고 다양한 유형의 사이버 공격의 대상이 될 수 있다. 일부 경우에서, 이러한 공격은 하나 이상의 메모리 리소스에 저장된 데이터 및/또는 코드를 변경하려는 시도일 수 있다. 사이버 공격은 메모리에 저장된 상당한 양의 데이터에 의존하는 학습 신경망 또는 기타 유형의 인공지능(AI) 모델에 대하여 특히 문제가 될 수 있다. 저장된 데이터가 조작되거나 심지어 불명확하게 되면, 이 러한 조작은 해로울 수 있다. 예를 들어, 데이터 집약적 AI 모델에 의존하여 다른 차량 또는 보행자 등을 식별 하는 자율주행차 시스템은 의존하는 데이터가 손상되거나 불명확해지면 호스트 차량 주변상황을 잘못 파악할 수 있다. 그 결과, 사고가 발생할 수 있다. AI 모델이 더욱 광범위한 기술 분야에서 적용됨에 따라, 이러한 모델과 연관된 데이터에 대한 사이버 공격은 중대 혼란의 위험이 된다. 다른 경우에서, 사이버 공격은 한 명 이상의 행위자가 프로세서 또는 기타 유형의 집적회로 기반 논리 요소와 연관된 동작 파라미터를 위조하거나 위조하려는 시도를 포함할 수 있다. 예를 들어, 프로세서는 흔히 특정 동작 사양 내에서 동작하도록 설계된다. 위조를 포함하는 사이버 공격은 프로세서, 메모리 유닛, 또는 기타 회로의 동작 파라미터들 중의 하나 이상을 변경함으로써 설계된 동작 사양(예: 클럭 속도, 대역폭 사양, 온도 제한, 동 작 속도 등)을 초과하도록 시도할 수 있다. 이러한 위조는 대상 하드웨어의 고장으로 이어질 수 있다. 사이버 공격에 대한 방어를 위한 기존의 방식들은 프로세서 레벨에서 동작하는 컴퓨터 프로그램(예: 바이러스 방지 소프트웨어, 악성코드 방지 소프트웨어)을 포함할 수 있다. 다른 방식들은 라우터 또는 기타 하드웨어와 연관된 소프트웨어 기반 방화벽의 사용을 포함할 수 있다. 이러한 방식들은 메모리 유닛의 외부에서 실행된 소 프트웨어 프로그램을 이용한 사이버 공격에 대한 대응인 반면에, 메모리 유닛에 저장된 데이터를 효율적으로 보 호하는 추가적인 또는 대안적인 방식이 여전히 필요하고, 이러한 데이터의 정확성과 사용 가능성이 신경망 등과 같은 메모리 집약적 어플리케이션의 동작에 절대적인 경우에 더욱 그렇다. 본 개시의 실시예들은 메모리에 대한 사이버 공격에 강한 메모리를 포함하는 다양한 집적회로 설계를 제공한다. 집적회로에 민감한 정보 및 명령을 안전한 방법으로 가져온(예: 칩/집적회로 외부로의 인터페이스가 아직 활성 화되지 않은 부팅 프로세스 도중) 후에 이러한 민감한 정보 및 명령을 집적회로 외부로 노출시키지 않고 집적회 로 내에 유지하고 집적회로 내에서 연산을 완료하면 민감한 정보 및 명령의 보안을 향상시킬 수 있다. CPU 및 기타 유형의 프로세싱 유닛은, 특히 이러한 CPU 및 프로세싱 유닛이 외부 메모리와 함께 동작하는 경우에, 사이 버 공격에 취약하다. 복수의 메모리 뱅크를 포함하는 메모리 어레이 중의 메모리 칩 상에 배치되는 분산 프로세 서 서브유닛을 포함하는 개시된 실시예들은 사이버 공격과 위조에 덜 취약할 수 있다(예: 프로세싱이 메모리 칩 내에서 이루어지기 때문). 하기에 더 상세히 설명하는 개시된 안전 조치의 임의의 모든 조합은 사이버 공격 및/ 또는 위조에 대한 개시된 실시예들의 취약성을 더 감소시킬 수 있다. 도 72a는 본 개시의 실시예들에 따른 메모리 어레이 및 프로세싱 어레이를 포함하는 집적회로를 도시한 것이다. 예컨대, 집적회로는 앞서 설명하고 본 개시에 전체적으로 설명하는 임의의 모든 분산 프로세서 온 메모리 칩(distributed processor-on-a-memory chip) 아키텍처(및, 기능)를 포함할 수 있다. 메모리 어레이 와 프로세싱 어레이는 동일 기판 상에 형성될 수 있고, 본 개시의 일부 실시예들에서, 집적회로는 메모리 칩을 구성할 수 있다. 예를 들어, 앞서 설명한 바와 같이, 집적회로는 복수의 메모리 뱅크를 포함하는 메 모리 칩과 메모리 칩 상에 공간적으로 분산된 복수의 프로세서 서브유닛을 포함할 수 있고, 여기서 복수의 메모 리 뱅크는 각각 복수의 프로세서 서브유닛의 하나 이상의 전용 서브유닛과 연관된다. 일부 경우에서, 각 프로세 서 서브유닛은 하나 이상의 메모리 뱅크 전용일 수 있다. 일부 실시예들에서, 도 72a에 도시된 바와 같이, 메모리 어레이는 복수의 이산 메모리 뱅크(7210_1, 7210_2, ... 7210_J1, 7210_Jn)를 포함할 수 있다. 본 개시의 실시예들에 따르면, 메모리 어레이는 예컨대 휘발성 메모리(RAM, DRAM, SRAM, 상변화 RAM (PRAM), 자기 저항 RAM (MRAM), 저항 RAM (ReRAM) 등) 또는 비휘발성 메 모리(플래시 메모리 또는 ROM)를 포함하는 하나 이상의 유형의 메모리를 포함할 수 있다. 본 개시의 일부 실시 예들에 따르면, 메모리 뱅크(7210_1 내지7210_Jn)는 복수의 MOS 메모리 구조를 포함할 수 있다. 앞서 언급한 바와 같이, 프로세싱 어레이는 복수의 프로세서 서브유닛(7220_1 내지 7220_K)을 포함할 수 있다. 일부 실시예들에서, 프로세서 서브유닛(7220_1 내지 7220_K)은 각각 복수의 이산 메모리 뱅크(7210_1 내지 7210_Jn) 중에서 하나 이상의 이산 메모리 뱅크와 연관될 수 있다. 도 72a의 예시적인 실시예에는 각 프로세서 서브유닛이 2개의 이산 메모리 뱅크와 연관되어 있는 것으로 도시되어 있지만, 각 프로세서 서브유닛이 임의의 모든 수의 전용 이산 메모리 뱅크와 연관될 수 있음은 당연하다 할 것이다. 또는, 반대로, 각 메모리 뱅 크는 임의의 모든 수의 프로세서 서브유닛과 연관될 수 있다. 본 개시의 실시예들에 따라, 집적회로의 메 모리 어레이에 포함된 이산 메모리 뱅크의 수는 집적회로의 프로세싱 어레이에 포함된 프로세서 서브유닛 의 수와 비교하여 동일하거나, 적거나, 많을 수 있다. 집적회로는 본 개시의 실시예들에 따른(및 앞서 설명한 바와 같은) 복수의 제1 버스를 더 포함할 수 있다. 각 버스는 프로세서 서브유닛(7220_k)을 상응하는 전용 메모리 뱅크(7210_j)로 연결시킬 수 있 다. 본 개시의 일부 실시예들에 따르면, 집적회로는 복수의 제2 버스를 더 포함할 수 있다. 각 버 스는 프로세서 서브유닛(7220_k)을 다른 프로세서 서브유닛(7220_k+1)으로 연결시킬 수 있다. 도 72a에 도시된 바와 같이, 복수의 프로세서 서브유닛(7220_1 내지 7220_K)은 버스를 통해 서로 연결될 수 있다. 도 72a에는 복수의 프로세서 서브유닛(7220_1 내지 7220_K)이 버스를 통해 직렬로 연결되어 루프를 형성 하는 것으로 도시되어 있지만, 프로세서 서브유닛은 임의의 모든 다른 방식으로도 연결될 수 있음은 당연하다 할 것이다. 예를 들면, 일부의 경우에서, 특정 프로세서 서브유닛은 버스를 통해 다른 프로세서 서 브유닛에 연결되지 않을 수 있다. 다른 경우에서, 특정 프로세서 서브유닛은 하나의 다른 프로세서 서브유닛에 만 연결될 수 있고, 또 다른 경우에서, 특정 프로세서 서브유닛은 하나 이상의 버스를 통하여 둘 이상의 다른 프로세서 서브유닛에 연결(예: 직렬 연결, 병렬 연결, 가지(branched) 연결 등)될 수 있다. 여기서, 기재 된 집적회로의 실시예들은 예시일 뿐이다. 일부 경우에서, 집적회로에는 상이한 내부 컴포넌트 및 연결이 있을 수 있고, 다른 경우에서, 하나 이상의 내부 컴포넌트 및 기재된 연결은 생략될 수 있다(예: 특정 적용 분야의 요구에 따라). 도 72a를 다시 참조하면, 집적회로는 집적회로에 대한 적어도 하나의 보안 조치를 이행하기 위한 하나 이상의 구조를 포함할 수 있다. 일부 경우에서, 이러한 구조는 하나 이상의 메모리 뱅크에 저장된 데이터 를 조작 또는 불명확하게 하는(또는 조작 또는 불명확하게 하려 시도하는) 사이버 공경을 검출하도록 구성될 수 있다. 다른 경우에서, 이러한 구조는 집적회로와 연관된 동작 파라미터의 위조 또는 집적회로와 연 관된 하나 이상의 동작에 직접적으로 또는 간접적으로 영향을 미치는 하나 이상의 하드웨어 요소(집적회로 내부에 포함되거나 집적회로 외부의 하드웨어 요소)의 위조를 검출하도록 구성될 수 있다. 일부 경우에서, 컨트롤러가 집적회로에 포함될 수 있다. 컨트롤러는 하나 이상의 버스(725 0)를 통하여 예컨대 프로세서 서브유닛(7220_1 ...7220_k) 중의 하나 이상에 연결될 수 있다. 컨트롤러는 메모리 뱅크(7210_1 ...7210_Jn) 중의 하나 이상에도 연결될 수 있다. 도 72a에는 하나의 컨트롤러가 도 시되어 있지만, 컨트롤러가 다중 프로세서 요소 및/또는 논리 회로를 포함할 수 있음은 당연하다 할 것이다. 개시된 실시예들에서, 컨트롤러는 집적회로의 적어도 하나의 동작에 대한 적어도 하나의 보안 조치를 이행하도록 구성될 수 있다. 나아가, 개시된 실시예들에서, 컨트롤러는 적어도 하나의 보안 조치 가 촉발되는 경우에 하나 이상의 해결책을 취하도록(또는 유발하도록) 구성될 수 있다. 본 개시의 일부 실시예들에 따르면, 적어도 하나의 보안 조치는 집적회로의 특정 양상에 대한 접근을 차 단하기 위해 컨트롤러에 의해 이행되는 프로세스를 포함할 수 있다. 접근 차단에는 칩의 외부로부터 메모리의 특정 영역으로의 접근(읽기 및/또는 쓰기 목적)을 컨트롤러가 방지하도록 하는 것이 포함된다. 접근 통제는 주 소 결정(resolution), 메모리 뱅크의 일부 결정, 메모리 뱅크 결정 등에 적용될 수 있다. 일부 경우에서, 집적 회로와 연관된 메모리의 하나 이상의 물리적 위치(예: 집적회로의 하나 이상의 메모리 뱅크 또는 하나 이상의 메모리 뱅크의 임의의 부분)가 차단될 수 있다. 일부 실시예들에서, 컨트롤러는 인공지능 모 델(또는 기타 유형의 소프트웨어 기반 시스템)의 실행과 연관된 집적회로의 특정부분으로의 접근을 차단 할 수 있다. 예를 들면, 일부 실시예들에서, 컨트롤러는 집적회로와 연관된 메모리에 저장된 신경 망 모델의 가중치로의 접근을 차단할 수 있다. 여기서, 소프트웨어 프로그램(즉, 모델)은 프로그램으로의 입력 데이터, 프로그램의 코드 데이터, 및 프로그램 실행으로부터의 출력 데이터라는 3가지 컴포넌트를 포함할 수 있 다. 이러한 컴포넌트들은 신경망 모델에도 적용될 수 있다. 이러한 모델의 동작 과정에서, 입력 데이터가 생성 되고 모델로 공급될 수 있고, 모델을 실행하면 읽기를 위한 출력 데이터를 생성할 수 있다. 그러나 수신된 입력 데이터를 활용한 모델 실행과 연관된 프로그램 코드 및 데이터 값들은 고정되어 있을 수 있다. 여기에서 사용되는 '차단'이라는 용어는 예컨대 칩/집적회로의 외부에서 개시된 메모리의 특정 영역에 대한 읽 기 또는 쓰기 동작을 허용하지 않는 컨트롤러의 동작을 의미할 수 있다. 칩/집적회로의 I/O가 통과할 수 있는 컨트롤러는 메모리 뱅크 전체를 차단할 수 있지만, 메모리 뱅크 내의 임의의 범위의 메모리 주소를, 예컨대 단 일 메모리 주소 내지 사용 가능한 메모리 뱅크의 주소 전체를 포함하는 임의의 범위의 메모리 주소(또는 그 사 이의 임의의 주소 범위)까지, 차단할 수도 있다. 입력 데이터의 수신 및 출력 데이터의 저장과 연관된 메모리 위치는 변경값 및 집적회로 외부의 컴포넌트 (입력 데이터를 제공하거나 출력 데이터를 수신하는 컴포넌트)와의 상호작용과 연관되므로, 일부의 경우에서 이 러한 메모리 위치로의 접근 차단은 실용적이지 않을 수 있다. 반면, 모델 코드 및 고정 데이터 값과 연관된 메 모리 위치로의 접근 차단은 특정 유형의 사이버 공격에 대해 효과적일 수 있다. 따라서, 일부 실시예들에서, 프 로그램 코드 및 데이터 값과 연관된 메모리(예: 입력 데이터의 쓰기/수신하기 및 출력 데이터의 읽기/제공하기 위해 사용되는 것이 아닌 메모리)는 보안 조치로서 차단될 수 있다. 접근 제한은 특정 프로그램 코드 및/또는 데이터 값(예: 수신된 입력 데이터에 의거한 모델의 실행과 연관된 값)을 변경하지 못하도록 특정 메모리 위치 를 차단하는 것을 포함할 수 있다. 또한, 중간 데이터(예: 모델의 실행 과정에서 생성되는 데이터)와 연관된 메 모리 영역도 외부 접근으로부터 차단될 수 있다. 따라서, 집적회로 상에 있거나 외부에 위치하는지 여부 와 상관없이 다양한 연산 로직이 입력 데이터의 수신 또는 생성된 출력 데이터의 검색과 연관된 메모리 위치로 데이터를 제공하거나 이 메모리 위치로부터 데이터를 수신할 수 있는 반면에, 이러한 연산 로직은 수신된 입력데이터에 기반한 프로그램 실행과 연관된 프로그램 코드 및 데이터 값을 저장하는 메모리 위치에 대한 접근 또 는 수정할 능력이 없게 된다. 보안 조치를 제공하기 위한 집적회로 상의 메모리 위치 차단 외에도, 특정 프로그램 또는 모델과 연관된 코드를 실행하도록 구성된 특정 연산 로직 요소(및 접근되는 메모리 영역)로의 접근을 제한하여 기타 보안 조치 가 이행될 수 있다. 일부 경우에서, 이러한 접근 제한은 집적회로 상에 위치한(예: 연산 메모리(예: 본 개시의 메모리 칩 상의 분산 프로세서와 같은 연산 능력을 보유한 메모리) 등) 연산 로직(및 연관 메모리 영 역)에 대하여 이루어질 수 있다. 집적회로의 차단된 메모리 부분에 저장된 코드의 모든 임의의 실행과 연 관되거나 집적회로의 차단된 메모리 부분에 저장된 데이터 값으로의 모든 임의의 접근과 연관된 연산 로 직(및 연관 메모리 영역)으로의 접근도 해당 연산 로직이 집적회로 상에 위치하는지 여부와 상관없이 차 단/제한될 수 있다. 프로그램/모델의 실행을 담당하는 연산 로직으로의 접근을 제한하면, 수신된 입력 데이터에 따른 동작과 연관된 코드 및 데이터 값이 조작되거나 불명확해지는 등으로부터의 보호가 유지되는 것을 더 보장 할 수 있다. 집적회로의 메모리 어레이의 특정 부분과 연관된 하드웨어 기반 영역으로의 접근에 대한 차단 또는 제한 을 포함하는 컨트롤러에 의해 이행되는 보안 조치는 임의의 모든 적절한 방법으로 이루어질 수 있다. 일부 실시 예들에서, 이러한 차단은 컨트롤러가 특정 메모리 부분을 차단하게 유발하도록 구성된 컨트롤러로 명령을 추가 또는 제공하여 이행될 수 있다. 일부 실시예들에서, 차단될 하드웨어 기반 메모리 부분은 특정 메 모리 주소(예; 메모리 뱅크(7210_1 ... 7210_J2)의 임의의 모든 메모리 요소와 연관된 주소 등)에 의해 지정될 수 있다. 일부 실시예들에서, 메모리의 차단된 영역은 프로그램 또는 모델 실행 동안에 계속 고정될 수 있다. 다른 경우에서, 차단된 영역은 설정 가능할 수 있다. 즉, 일부 경우에서, 컨트롤러에는 차단된 영역이 프 로그램 또는 모델의 실행 동안에 변경될 수 있도록 명령이 제공될 수 있다. 예를 들어, 특정 시간에, 특정 메모 리 위치가 메모리의 차단된 영역에 추가될 수 있다. 또는, 특정 시간에, 특정 메모리 위치(예: 이전에 차단된 메모리 위치)가 메모리의 차단된 영역에서 제외될 수 있다. 특정 메모리 위치의 차단은 임의의 모든 방법으로 이루어질 수 있다. 일부 경우에서, 특정 메모리 요청이 차단 된 메모리 위치와 관련되는지 여부를 컨트롤러가 판단할 수 있도록, 차단된 메모리 위치의 기록(예: 차단 된 메모리 주소를 저장하고 식별하는 파일, 데이터페이스, 데이터 구조 등)이 컨트롤러에 의해 접근 가능 할 수 있다. 일부 경우에서, 컨트롤러는 차단된 주소의 데이터베이스를 유지하여 특정 메모리 위치로의 접근을 제어하는데 사용한다. 다른 경우에서, 차단될 때까지 설정 가능하고 차단할 메모리 위치(예: 칩 외부로 부터의 메모리 접근이 제한되는 메모리 위치)를 식별하는 고정된 소정의 값을 포함할 수 있는 하나 이상의 레지 스터의 표 또는 집합이 컨트롤러에 있을 수 있다. 예를 들면, 메모리 접근이 요청되는 경우, 컨트롤러는 해당 메모리 접근 요청과 연관된 메모리 주소를 차단된 메모리 주소에 비교할 수 있다. 메모리 접근 요청과 연 관된 메모리 주소가 차단된 메모리 주소의 리스트 내에 있는 것으로 판단되는 경우, 메모리 접근 요청(읽기 또 는 쓰기 동작 여부와 무관하게)는 거절될 수 있다. 앞서 설명한 바와 같이, 적어도 하나의 보안 조치는 입력 데이터의 수신 또는 생성된 출력 데이터에 대한 접근 제공에 사용되지 않는 메모리 어레이의 특정 메모리 부분에 대한 접근 차단을 포함할 수 있다. 일부 경우 에서, 차단된 영역 내의 메모리 부분은 조정될 수 있다. 예를 들면, 차단된 메모리 부분이 차단 해제될 수 있고, 차단되지 않은 메모리 부분이 차단될 수 있다. 임의의 모든 적적한 방법이 활용되어 차단된 메모리 부분 을 차단 해제할 수 있다. 예컨대, 보안 조치 이행으로, 차단된 메모리 영역의 하나 이상의 부분을 차단 해제하 기 위한 암호를 요구할 수 있다. 이행된 보안 조치는 이행된 보안 조치에 역행하는 동작이 검출되면 촉발될 수 있다. 예를 들어, 차단된 메모리 부분으로의 접근 시도(읽기 또는 쓰기 요청 여부와 무관)는 보안 조치를 촉발할 수 있다. 또한, 소정의 암호와 일치하지 않는 암호가 입력되면(예: 차단된 메모리 부분의 차단 해제 시도) 보안 조치가 촉발될 수 있다. 일부 경우에서, 허용된 임계 수(예: 1회, 2회, 3회 등)의 암호 입력 시도 이내에 정확한 암호가 입력되지 않으면 보 안 조치가 촉발될 수 있다. 메모리 부분은 임의의 모든 시간에 차단될 수 있다. 예를 들면, 일부 경우에서, 메모리 부분은 프로그램 실행 도중의 다양한 시간에 차단될 수 있다. 다른 경우에서, 메모리 부분은 프로그램/모델 실행 시작시 및/또는 전에 차단될 수 있다. 예를 들어, 차단될 메모리 주소가 프로그램/모델 코드의 프로그래밍과 함께 또는 프로그램/모 델에 의해 접근될 데이터의 생성과 저장이 됨에 따라 결정되고 식별될 수 있다. 이로써, 메모리 어레이 공격에 대한 취약성은 프로그램/모델 실행이 시작되는 시점 동안에 또는 이후에, 프로그램/모델에 의해 사용될데이터가 생성 및 저장된 이후 등에 감소되거나 제거될 수 있다. 차단된 메모리는 임의의 모든 적합한 방법에 의해 또는 임의의 모든 적합한 시간에 차단 해제될 수 있다. 앞서 설명한 바와 같이, 차단된 메모리 부분은 정확한 암호의 수신 이후에 차단 해제될 수 있다. 다른 경우에서, 차 단된 메모리는 전체 메모리 어레이를 재시동(명령에 의해 또는 파워를 껐다 켜서) 하거나 삭제하여 차단 해제될 수 있다. 추가적으로 또는 대안적으로, 해제 명령 시퀀스를 이행하여 하나 이상의 메모리 부분을 차단 해제할 수 있다. 본 개시의 실시예들에 따르면, 또한 앞서 설명한 바와 같이, 컨트롤러는 집적회로와 왕래하는, 특 히 집적회로 외부의 소스로부터의 트래픽을 제어하도록 구성될 수 있다. 예를 들어, 도 72a에 도시된 바 와 같이, 집적회로 외부의 컴포넌트와 집적회로 내부의 컴포넌트(예: 메모리 어레이 또는 프 로세서 서브유닛) 사이의 트래픽은 컨트롤러에 의해 제어될 수 있다. 이러한 트래픽은 컨트롤러 를 통해 또는 컨트롤러에 의해 제어되거나 모니터링 되는 하나 이상의 버스(예: 7250, 7260, 또는 7261)를 통해 통과할 수 있다. 본 개시의 일부 실시예들에 따르면, 집적회로는 부팅 프로세스 동안에 변경 불가능 데이터(예: 모델 가중 치, 계수 등의 고정 데이터) 또는 특정 명령(예: 차단될 메모리 부분을 식별하는 코드)을 수신할 수 있다. 여기 서, 변경 불가능 데이터는 프로그램 또는 모델의 실행 동안에 계속 고정되고 차후의 부팅 프로세스까지 변경되 지 않고 유지되는 데이터를 의미할 수 있다. 프로그램 실행 동안에, 집적회로는 처리될 입력 데이터 및/ 또는 집적회로와 연관된 프로세싱에 의해 생성되는 출력 데이터를 포함할 수 있는 변경 불가능 데이터와 상호작용할 수 있다. 앞서 설명한 바와 같이, 메모리 어레이 또는 프로세싱 어레이로의 접근은 프 로그램 또는 모델 실행 동안에 제한될 수 있다. 예를 들어, 메모리 어레이의 특정 부분으로의 접근 또는 기록될 입력 데이터와의 처리 또는 상호작용 또는 읽어질 생성된 출력 데이터와의 처리 또는 상호작용과 연관된 특정 프로세서 서브유닛으로의 접근이 제한될 수 있다. 프로그램 또는 모델 실행 동안에, 변경 불가능 데이터를 포함하는 메모리 부분은 차단될 수 있고, 이로써 접근 불가능해질 수 있다. 일부 실시예들에서, 변경 불가능 데 이터 및/또는 차단될 메모리 부분과 연관된 명령은 임의의 모든 적절한 데이터 구조에 포함될 수 있다. 예를 들 면, 이러한 데이터 및/또는 명령은 부팅 시퀀스 동안 또는 이후에 접근 가능한 하나 이상의 설정 파일을 통해 컨트롤러가 사용 가능하게 될 수 있다. 도 72a를 다시 참조하면, 집적회로는 통신 포트를 더 포함할 수 있다. 도 72a에 도시된 바와 같이, 컨트롤러는 프로세싱 서브유닛(7220_1 내지 7220_K) 사이에 공유된 버스와 통신 포트 사이에 결합될 수 있다. 일부 실시예들에서, 통신 포트는 비휘발성 메모리 등을 포함할 수 있는 호스트 메모리 와 연관된 호스트 컴퓨터에 직접 또는 간접 결합될 수 있다. 일부 실시예들에서, 호스트 컴퓨터 는 변경 가능 데이터(예: 프로그램 또는 모델의 실행 동안에 사용될 입력 데이터), 변경 불가능 데 이터, 및/또는 명령을 연관된 호스트 메모리로부터 가져올 수 있다. 변경 가능 데이터 , 변경 불가능 데이터, 및 명령은 부팅 절차 동안에 통신 포트를 통하여 호스트 컴퓨 터로부터 컨트롤러로 업로드 될 수 있다. 도 72b는 본 개시의 실시예들에 따른 집적회로 내부의 메모리 영역을 도시한 것이다. 도시된 바와 같이, 도 72b 는 호스트 메모리에 포함된 데이터 구조의 예를 묘사하고 있다. 도 73a에는 본 개시의 실시예들에 따른 집적회로의 다른 예가 도시되어 있다. 도 73a에 도시된 바와 같이, 컨트 롤러는 사이버공격 검출기와 응답 모듈을 포함할 수 있다. 본 개시의 일부 실시예들에서, 컨 트롤러는 접근 제어 규칙을 저장하거나 접근 제어 규칙에 접근하도록 구성될 수 있다. 본 개 시의 일부 실시예들에 따르면, 접근 제어 규칙은 컨트롤러가 접근 가능한 설정 파일에 포함될 수 있다. 일부 실시예들에서, 접근 제어 규칙은 부팅 절차 동안에 컨트롤러로 업로드 될 수 있다. 접 근 제어 규칙은 임의의 모든 변경 가능 데이터, 변경 불가능 데이터, 명령, 및 이들의 상응하는 메모리 위치와 연관된 접근 규칙을 나타내는 정보를 포함할 수 있다. 앞서 설명한 바와 같이, 접근 제 어 규칙 또는 설정 파일은 메모리 어레이 중의 특정 메모리 주소를 식별하는 정보를 포함할 수 있 다. 일부 실시예들에서, 컨트롤러는 메모리 어레이의 다양한 주소, 예를 들어 명령 또는 변경 불가 능 데이터를 저장하기 위한 주소를 차단하는 차단 메커니즘 및/또는 기능을 제공하도록 구성될 수 있다. 컨트롤러는 접근 제어 규칙을 집행하도록, 예를 들어, 허가되지 않은 엔티티가 변경 불가능 데이터 또는 명령을 변경하는 것을 방지하도록 구성될 수 있다. 일부 실시예들에서, 변경 불가능 데이터 또는 명령의 읽기는 접근 제어 규칙에 따라 금지될 수 있다. 본 개시의 일부 실시예들에 따르면, 컨트롤러는 특정 명령 또는 변경 불가능 데이터의 적어도 일부분에 대한 접근 시도가 있는지 여부를 판단하도록 구성될 수 있 다. 컨트롤러(예: 사이버 공격 검출기를 포함)는 접근 요청과 연관된 메모리 주소를 변경 불가능 데이터 및 명령에 대한 메모리 주소에 비교하여 하나 이상의 차단된 메모리 위치에 무단 접근 시도가 있었는지 여부를 검출할 수 있다. 이로써, 예를 들어, 컨트롤러의 사이버 공격 검출기는 의심되는 사이버 공 격이 발생하는지, 예를 들어, 하나 이상의 명령을 변경하거나 하나 이상의 차단된 메모리 부분과 연관된 변경 불가능 데이터를 변경 또는 불명확하게 하려는 요청이 있는지 여부를 판단하도록 구성될 수 있다. 응답 모듈 은 검출된 사이버 공격에 어떻게 대응할지 및/또는 어떻게 대응을 이행할지를 판단하도록 구성될 수 있다. 예컨대, 일부 경우에서, 하나 이상의 차단된 메모리 위치의 데이터 또는 명령에 대해 검출된 공격에 대응 하여, 컨트롤러의 응답 모듈은 검출된 공격과 연관된 메모리 접근 동작과 같은 하나 이상의 동작을 중단하는 등이 포함될 수 있는 대응을 이행하거나 이행되도록 유발할 수 있다. 검출된 공격에 대한 대응은 또한 프로그램 또는 모델의 실행과 연관된 하나 이상의 동작의 중단, 공격 시도의 경고 또는 기타 지시자의 출력, 호 스트에 지시 라인 주장, 또는 전체 메모리의 삭제 등을 포함할 수 있다. 메모리 부분의 차단 외에도, 사이버 공격으로부터 보호하는 다른 방법들이 이행되어 집적회로와 연관된 기재된 보안 조치를 제공할 수 있다. 예를 들면, 일부 실시예들에서, 컨트롤러 는 집적회로와 연관 된 상이한 메모리 위치와 프로세서 서브유닛 내에 프로그램 또는 모델을 복제하도록 구성될 수 있다. 이로써, 프로그램/모델 및 프로그램/모델의 복제는 서로 개별적으로 실행될 수 있고, 개별 프로그램/모델 실행의 결과가 비교될 수 있다. 예를 들어, 프로그램/모델은 2개의 상이한 메모리 뱅크에 복제되고 집적회로 내의 상이한 프로세서 서브유닛에서 실행될 수 있다. 다른 실시예들에서, 프로그램/모델은 2개의 상이한 집적 회로에 복제될 수 있다. 어느 경우이든, 프로그램/모델 실행의 결과가 비교되어 복제 프로그램/모델 실행 사이에 차이가 존재하는지 여부를 판단할 수 있다. 실행 결과(예: 중간 실행 결과, 최종 실행 결과 등)에서 검 출된 차이는 프로그램/모델의 하나 이상의 양상 또는 그와 연관된 데이터를 변경한 사이버 공격의 존재를 나타 내는 것일 수 있다. 일부 실시예들에서, 상이한 메모리 뱅크와 프로세서 서브유닛은 동일한 입력 데이터에 의거하여 2개의 복제된 모델을 실행하도록 설정될 수 있다. 일부 실시예들에서, 동일한 입력 데이터에 의거하여 2개의 복제된 모델을 실행하는 동안에 중간 결과가 비교될 수 있고, 동일한 단계에서 2개의 중간 결과 사이에 불일치가 있으면, 잠재적 해결책으로서 실행이 정지될 수 있다. 동일한 집적회로의 프로세서 서브유닛들 이 2개의 복제된 모델을 실행하는 경우에, 그 집적회로는 또한 결과를 비교할 수 있다. 이는 집적회로 외부의 엔티티에 2개의 복제된 모델의 실행에 관하여 알리지 않고 이루어질 수 있다. 즉, 칩 외부의 엔티티는 집적회로 상에서 복제 모델들이 병렬로 실행되고 있는 것을 인식하지 못한다. 도 73b는 본 개시의 실시예들에 따른 복제 모델을 동시에 실행하기 위한 구성을 도시한 것이다. 사이버 공격의 가능성을 검출을 위한 일례로 단일 프로그램/모델 복제가 기재되지만, 사이버 공격의 가능성을 검출을 위해 임 의의 모든 수의 복제(예: 1, 2, 3, 또는 그 이상)가 사용될 수 있다. 복제의 수와 개별 프로그램/모델 실행이 증가함에 따라, 사이버 공격 검출의 신뢰 수준도 상승할 수 있다. 복제의 수가 증가하면 사이버 공격의 성공 가 능 비율도 또한 감소하는데, 이는 공격자가 다중 프로그램/모델 복제에 영향을 주기 더 어려울 수 있기 때문이 다. 프로그램 또는 모델 복제의 수는 런타임에서 판단되어, 사이버 공격자가 프로그램 또는 모델 실행에 성공적 으로 영향을 미치는 것에 대한 난이도를 더 상승시킬 수 있다. 일부 실시예들에서, 복제된 모델들은 하나 이상의 양상에서 서로 상이할 수 있다. 본 예에서, 2개의 프로그램/ 모델과 연관된 코드는 서로 상이하게 되어 있을 수 있지만, 이러한 프로그램/모델들은 모두 동일한 출력 결과를 내도록 설계될 수 있다. 적어도 이러한 방식에서, 2개의 프로그램/모델은 서로의 복제인 것으로 고려될 수 있다. 예를 들어, 2개의 신경망 모델에는 서로에 대한 층에서 뉴런의 순서가 상이할 수 있다. 그러나 모델 코드 의 이러한 변화에도 불구하고, 동일한 출력 결과를 낼 수 있다. 이러한 방식으로 프로그램/모델을 복제하면, 손 상시킬 프로그램 또는 모델의 이러한 효과적인 복제본을 사이버 공격자가 식별하는 것이 더 어려워질 수 있고, 그 결과, 복제 모델/프로그램은 사이버 공격의 영향을 최소화하는 중복성을 제공하는 방법을 제공할 수 있을 뿐 만 아니라 사이버 공격 검출을 향상시킬 수 있다(예: 사이버 공격자가 한 프로그램/모델 또는 그 데이터를 바꾸 지만 프로그램/모델 복제본은 상응하게 바꾸지 못하는 위조 또는 무단 접근을 하이라이트 함으로써). 많은 경우에서, 복제 프로그램/모델들(특히, 코드 차이를 보이는 복제 프로그램/모델을 포함)은 그 출력들이 완 전히 일치하지는 않지만 정확하고 고정된 값이 아닌 소프트 값(예: 거의 동일한 출력 값)을 구성하도록 설계될 수 있다. 이러한 실시예들에서, 둘 이상의 효과적인 프로그램/모델 복제본으로부터의 출력 결과가 비교되어(예: 전용 모듈 또는 호스트 프로세서를 활용) 출력 결과들(중간 결과 또는 최종 결과) 사이의 차이가 소정의 범위 이내인지 여부를 판단할 수 있다. 소정의 임계값 또는 범위를 초과하지 않는 출력 소프트 값의 차이는 위조, 무단 접근 등이 발생하지 않았다는 증거로 고려될 수 있다. 반면, 출력된 소프트 값의 차이가 소정의 임계값 또는 범위를 초과하는 경우, 이러한 차이는 메모리에 대한 위조, 무단 접근 등의 형태로 사이버 공격이 있었다는 증 거로 고려될 수 있다. 이러한 경우, 복제 프로그램/모델 보안 조치가 촉발될 수 있고, 하나 이상의 해결책(예: 프로그램 또는 모델의 실행을 중단, 집적회로의 하나 이상의 동작을 정지, 기능을 제한하는 안전 모드로 동작 등)이 취해질 수 있다. 집적회로와 연관된 보안 조치는 또한 프로그램 또는 모델의 실행과 연관된 데이터의 정량 분석을 포함할 수 있다. 예를 들어, 일부 실시예들에서, 컨트롤러는 메모리 어레이의 적어도 일부분에 저장된 데 이터에 대한 하나 이상의 검사 합계(checksum)/해시(hash)/순환 중복 검사(CRC)/패리티(parity) 값을 계산하도 록 구성될 수 있다. 계산된 값(들)은 소정의 값(들)과 비교될 수 있다. 비교된 값들 사이에 차이가 있으면, 이 러한 차이는 메모리 어레이의 적어도 일부분에 저장된 데이터에 위조가 있다는 증거로 해석될 수 있다. 일부 실시예들에서, 검사 합계/해시/CRC/패리티 값은 메모리 어레이와 연관된 모든 메모리 위치에 대해 계산되어 데이터의 변경을 식별할 수 있다. 본 예에서, 문제의 전체 메모리(또는 메모리 뱅크)는 검사 합계/해 시/CRC/패리티 값의 계산을 위해 호스트 컴퓨터 또는 집적회로와 연관된 프로세서 등이 읽을 수 있 다. 다른 경우에서, 검사 합계/해시/CRC/패리티 값은 메모리 어레이와 연관된 메모리 위치의 소정의 서브 세트에 대해 계산되어 메모리 위치의 서브세트와 연관된 데이터의 변경을 식별할 수 있다. 일부 실시예들에서, 컨트롤러는 소정의 데이터 경로와 연관된 검사 합계/해시/CRC/패리티 값(예: 메모리 접근 패턴과 연관)을 계산하도록 구성될 수 있고, 계산된 값들은 서로 또는 소정의 값에 비교되어 위조 또는 다른 형태의 사이버 공 격이 있었는지 여부를 판단할 수 있다. 집적회로는 집적회로 내의 또는 집적회로로 접근 가능한 위치의 하나 이상의 소정의 값(예: 예상 검사 합계/해시/CRC/패리티 값, 중간 출력 결과 또는 최종 출력 결과의 예상 차이 값, 특정 값과 연관된 예상 차이 범위 등)을 보호함으로써 사이버 공격에 대한 보안이 더 강화될 수 있다. 예를 들어, 일부 실시예들 에서, 하나 이상의 소정의 값은 메모리 어레이의 레지스터에 저장될 수 있고 모델의 각 런 동안 또는 후 에 중간 또는 최종 출력 값, 검사 합계 등을 평가하는데 활용(예: 집적회로의 컨트롤러에 의해)될 수 있다. 일부 경우에서, 레지스터 값은 \"최종 결과 데이터 저장\" 명령을 활용하여 업데이트 되어 소정의 값의 바로 계산할 수 있고, 계산된 값은 레지스터 또는 다른 메모리 위치에 저장될 수 있다. 이로써, 유효한 출력 값 이 각 프로그램 또는 모델 실행 또는 부분 실행 이후에 비교를 위해 활용되는 소정의 값을 업데이트 하기 위해 활용될 수 있다. 이러한 방법은 사이버 공격 활동을 노출시키기 위해 설계된 하나 이상의 소정의 참조 값을 변 경하거나 위조하려는 사이버 공격자의 시도의 어려움을 증가시킬 수 있다. 동작에서, 메모리 접근을 추적하기 위해 CRC 계산기가 사용될 수 있다. 예를 들어, 이러한 계산 회로는 메모리 뱅크 레벨에, 프로세서 서브유닛에, 또는 컨트롤러에 배치될 수 있고, 이들 각각은 각 메모리 접근마다 CRC 계 산기로 누적하도록 구성될 수 있다. 도 74a는 집적회로의 다른 실시예를 도시한 것이다. 도 74a에 도시된 실시예에서, 컨트롤러는 위조 검출기 및 응답 모듈을 포함할 수 있다. 개시된 다른 실시예들과 유사하게, 위조 검출기는 잠재적 위조 시도의 증거를 검출하도록 구성될 수 있다. 본 개시의 일부 실시예들에 따르면, 예컨대, 집적회로 와 연관되고 컨트롤러에 의해 이행되는 보안 조치는 실제 프로그램/모델 동작 패턴과 소정의/허용 된 동작 패턴의 비교를 포함할 수 있다. 실제 프로그램/모델 동작 패턴이 하나 이상의 양상에서 소정의/허용된 동작 패턴과 다른 경우에 보안 조치가 촉발될 수 있다. 보안 조치가 촉발되면, 컨트롤러의 응답 모듈 이 하나 이상의 해결책을 이행하여 대응하도록 구성될 수 있다. 도 74c는 본 개시의 예시에 따른 칩 내의 다양한 지점에 위치할 수 있는 검출 요소를 도시한 것이다. 앞서 설명 한 바와 같은 사이버 공격과 위조의 검출은 도 74c의 예에 도시된 바와 같은 칩 내의 다양한 지점에 위치한 검 출 요소를 활용하여 수행될 수 있다. 예를 들어, 특정 코드는 특정 시간 주기 이내의 예상 수의 프로세싱 이벤 트와 연관될 수 있다. 도 74c에 도시된 검출기는 특정 시간 주기(타임 카운터로 모니터) 동안에 시스템이 겪는 이벤트의 수(이벤트 카운터로 모니터)를 카운트할 수 있다. 이벤트의 수가 소정의 임계값(예: 소정의 시간 주기 동안에 예상되는 이벤트의 수)을 초과하는 경우, 위조를 나타내는 것일 수 있다. 도 74c에 도시된 바와 같이, 이러한 검출기는 이벤트의 다양한 유형을 모니터하도록 시스템의 다중 지점에 포함될 수 있다. 더욱 구체적으로, 일부 실시예들에서, 컨트롤러는 예산 프로그램/모델 동작 패턴을 저장 또는 접근 하도록 구성될 수 있다. 예를 들어, 일부 경우에서, 동작 패턴은 시간 당 허용된 부하 패턴과 시간 당 금지 또 는 불법 패턴을 나타내는 그래프로 묘사될 수 있다. 위조 시도는 메모리 어레이 또는 프로세싱 어레이가 특정 동작 사양 밖에서 동작하도록 유발할 수 있다. 이는 메모리 어레이 또는 프로세싱 어 레이가 발열하거나 제대로 작동하지 않게 할 수 있고, 메모리 어레이 또는 프로세싱 어레이 와 관련된 데이터 또는 코드가 변경되게 할 수 있다. 이러한 변경의 결과로, 그래프에 도시된 바와 같이, 허용된 동작 패턴 밖의 동작 패턴이 야기될 수 있다. 본 개시의 일부 실시예들에 따르면, 컨트롤러는 메모리 어레이 또는 프로세싱 어레이와 연관 된 동작 패턴을 모니터하도록 구성될 수 있다. 동작 패턴은 접근 요청의 수, 접근 요청의 유형, 접근 요청의 시 간 등과 연관될 수 있다. 컨트롤러는 동작 패턴이 허용 가능한 동작 패턴과 상이한 경우에 위조 공격을 검출하도록 더 구성될 수 있다. 여기서, 개시된 실시예들은 사이버 공격에 대한 보호 외에도 동작에서의 비악성 오류에 대한 보호를 위해 활용 될 수 있다. 예컨대, 개시된 실시예들은 특히 레벨이 집적회로의 동작 사양 밖인 경우의 온도 또는 전압 변화 또는 레벨과 같은 환경 요인에서 기인하는 오류에 대해 집적회로와 같은 시스템의 보호에도 효과적 일 수 있다. 의심되는 사이버 공경의 검출에 대응하여(예: 촉발된 보안 조치에 대한 응답으로) 임의의 모든 적합한 해결책이 이행될 수 있다. 예를 들면, 해결책은 프로그램/모델 실행과 연관된 하나 이상의 동작의 중단, 집적회로 와 연관된 하나 이상의 컴포넌트를 안전 모드로 동작, 집적회로의 하나 이상의 컴포넌트에 추가적인 입력 또는 접근 차단 등을 포함할 수 있다. 도 74b는 개시된 예시적인 실시예들에 따라 위조에 대해 집적회로를 보호하는 방법의 순서도를 도시한 것 이다. 예컨대, 단계 7452에서, 집적회로와 연관된 컨트롤러를 이용하여 집적회로의 동작에 대한 적어도 하나의 보안 조치를 이행할 수 있다. 단계 7454에서, 적어도 하나의 보안 조치가 촉발되는 경우에, 하나 이상의 해결책 이 취해질 수 있다. 집적회로는 기판, 기판 상에 배치되고 복수의 이산 메모리 뱅크를 포함하는 메모리 어레이, 및 기판 상에 배치되고 복수의 프로세서 서브유닛을 포함하는 프로세싱 어레이를 포함할 수 있고, 복수의 프로 세서 서브유닛은 각각 복수의 이산 메모리 뱅크 중의 하나 이상의 이산 메모리 뱅크와 연관될 수 있다. 일부 실시예들에서, 개시된 보안 조치는 다중 메모리 칩에서 이행될 수 있고, 개시된 보안 메커니즘의 적어도 하나 이상은 각 메모리 칩/집적회로에 대해 이행될 수 있다. 일부 경우에서, 각 메모리 칩/집적회로는 동일한 보안 조치를 이행할 수 있지만, 다른 경우에서, 상이한 메모리 칩/집적회로는 상이한 보안조치를 이행할 수 있 다(예: 상이한 보안 조치가 특정 집적회로와 연관된 특정 유형의 동작에 더 적합할 수 있는 경우). 일부 실시예 들에서, 하나 이상의 보안 조치가 집적회로의 특정 컨트롤러에 의해 이행될 수 있다. 예를 들면, 특정 집적회로 는 개시된 보안 조치의 임의의 모든 수 또는 유형을 이행할 수 있다. 또한, 특정 집적회로 컨트롤러는 촉발된 보안 조치에 응답하여 다중의 상이한 해결책을 이행하도록 구성될 수 있다. 여기서, 상기 보안 메커니즘의 둘 이상이 조합되어 사이버 공격 또는 위조 공격에 대한 보안을 강화할 수 있다. 또한, 보안 조치는 상이한 집적회로들에 모두 이행될 수 있고, 이러한 집적회로들은 서로 협조하여 보안 조치를 이행할 수 있다. 예를 들어, 모델 복제가 한 메모리 칩 내에서 수행될 수도 있고 상이한 메모리 칩 모두에서 수 행될 수 있다. 이러한 예에서, 한 메모리 칩에서의 결과 또는 둘 이상의 메모리 칩에서의 결과가 비교되어 사이 버 공격 또는 위조 공격의 가능성을 검출할 수 있다. 일부 실시예들에서, 다중 집적회로 모두에 적용된 복제 보 안 조치는 개시된 접근 차단 메커니즘, 해시 보호 메커니즘, 모델 복제, 프로그램/모델 실행 패턴 분석 중의 하 나 이상, 및 이들의 임의의 모든 조합 또는 다른 개시된 실시예들을 포함할 수 있다. DRAM 내 다중 포트 프로세서 서브유닛 앞서 설명한 바와 같이, 여기에 개시된 실시예들은 프로세서 서브유닛의 어레이와 메모리 뱅크의 어레이를 포함 하는 분산 프로세서 메모리 칩을 포함할 수 있고, 여기서 프로세서 서브유닛의 각각은 메모리 뱅크의 어레이의 적어도 하나에 전용일 수 있다. 아래에 설명하는 바와 같이, 분산 프로세서 메모리 칩은 스케일러블(scalable) 시스템에 대한 근거 역할을 할 수 있다. 즉, 일부 경우에서, 분산 프로세서 메모리 칩은 하나의 분산 프로세서 메모리 칩으로부터 다른 분산 프로세서 메모리 칩으로 데이터를 전송하도록 구성된 하나 이상의 통신 포트를 포 함할 수 있다. 이로써, 임의의 모든 원하는 수의 분산 프로세서 메모리 칩이 서로 연결(예: 직렬, 병렬, 루프, 또는 임의의 모든 조합)되어 분산 프로세서 메모리 칩의 스케일러블 어레이를 형성할 수 있다. 이러한 어레이는 메모리 집약적 동작을 효율적으로 수행하고 메모리 집약적 동작의 수행과 연관된 연산 리소스를 스케일링하기 위한 유연한 해법을 제공할 수 있다. 분산 프로세서 메모리 칩은 타이밍 패턴이 상이한 클럭을 포함할 수 있기 때문에, 여기에 개시된 실시예들은 클럭 타이밍 차이가 있어도 분산 프로세서 메모리 칩 사이의 데이터 전송을정확하게 제어하는 특징을 포함한다. 이러한 실시예들은 상이한 분산 프로세서 메모리 칩들 간의 효율적인 데이 터 공유를 가능하게 할 수 있다. 도 75a는 본 개시의 실시예들에 따른 복수의 분산 프로세서 메모리 칩을 포함하는 스케일러블 프로세서 메모리 시스템을 도시한 것이다. 본 개시의 실시예들에 따르면, 스케일러블 프로세서 메모리 시스템은 제1 분산 프로세 서 메모리 칩, 제2 분산 프로세서 메모리 칩(7500'), 및 제3 분산 프로세서 메모리 칩(7500\")과 같은 복 수의 분산 프로세서 메모리 칩을 포함할 수 있다. 제1 분산 프로세서 메모리 칩, 제2 분산 프로세서 메모 리 칩(7500'), 및 제3 분산 프로세서 메모리 칩(7500\")은 각각 본 개시에 기재된 임의의 모든 실시예들과 연관 된 임의의 모든 구성 및/또는 특징을 포함할 수 있다. 일부 실시예들에서, 제1 분산 프로세서 메모리 칩, 제2 분산 프로세서 메모리 칩(7500'), 및 제3 분산 프 로세서 메모리 칩(7500\")은 각각 도 72a에 도시된 집적회로와 유사하게 구현될 수 있다. 도 75a에 도시된 바와 같이, 제1 분산 프로세서 메모리 칩은 메모리 어레이, 프로세싱 어레이, 및 컨트롤러 를 포함할 수 있다. 메모리 어레이, 프로세싱 어레이, 및 컨트롤러는 도 72a의 메모리 어레이, 프로세싱 어레이, 및 컨트롤러와 유사하게 구성될 수 있다. 본 개시의 실시예들에 따르면, 제1 분산 프로세서 메모리 칩은 제1 통신 포트를 포함할 수 있다. 일부 실시예들에서, 제1 통신 포트는 하나 이상의 외부 엔티티와 통신하도록 구성될 수 있다. 예를 들면, 통신 포트는 분산 프로세서 메모리 칩과 분산 프로세서 메모리 칩(7500', 7500\")과 같은 다른 분산 프로세서 메모리 칩이 아닌 외부 엔티티 사이에 통신 연결을 구축하도록 구성될 수 있다. 예컨대, 통신 포트 는 도 72에 도시된 바와 같이 호스트 컴퓨터, 또는 임의의 모든 다른 컴퓨팅 장치, 통신 모듈 등에 직접 또는 간접 결합될 수 있다. 본 개시의 실시예들에 따르면, 제1 분산 프로세서 메모리 칩은 다른 분산 프로세서 메모리 칩(예: 7500', 7500\")과 통신하도록 구성된 하나 이상의 추가 통신 포트를 더 포함할 수 있다. 일부 실시예들에서, 하나 이상 의 추가 통신 포트는 도 75a에 도시된 바와 같이 제2 통신 포트 및 제3 통신 포트를 포함할 수 있 다. 제2 통신 포트는 제2 분산 프로세서 메모리 칩(7500')과 통신하고 제1 분산 프로세서 메모리 칩 과 제2 분산 프로세서 메모리 칩(7500') 사이에 통신 연결을 구축하도록 구성될 수 있다. 마찬가지로, 제 3 통신 포트는 제3 분산 프로세서 메모리 칩(7500\")과 통신하고 제1 분산 프로세서 메모리 칩과 제 3 분산 프로세서 메모리 칩(7500\") 사이에 통신 연결을 구축하도록 구성될 수 있다. 일부 실시예들에서, 제1 분 산 프로세서 메모리 칩(및 여기에 개시된 임의의 모든 메모리 칩)은 임의의 모든 적절한 수(예: 2개, 3개, 4개, 5개, 6개, 7개, 8개, 9개, 10개, 20개, 50개, 100개, 1000개 등)의 통신 포트를 포함하는 복수의 통 신 포트를 포함할 수 있다. 일부 실시예들에서, 제1 통신 포트, 제2 통신 포트, 및 제3 통신 포트는 상응하는 버스와 연관된다. 상응하는 버스는 제1 통신 포트, 제2 통신 포트, 및 제3 통신 포트 각각에 공통인 버스일 수 있다. 일부 실시예들에서, 제1 통신 포트, 제2 통신 포트, 및 제3 통신 포트 각각과 연관된 상응하는 버스는 모두 복수의 이산 메모리 뱅 크로 연결된다. 일부 실시예들에서, 제1 통신 포트는 메모리 칩 내부의 메인 버스 및 메모리 칩 내부에 포함된 적어도 하나의 프로세서 서브유닛 중의 적어도 하나로 연결된다. 일부 실시예들에서, 제2 통신 포트는 메모리 칩 내부의 메인 버스 및 메모리 칩 내부에 포함된 적어도 하나의 프로세서 서브유닛 중의 적어도 하나로 연결된 다. 개시된 분산 프로세서 메모리 칩의 구성이 제1 분산 프로세서 메모리 칩에 대하여 설명되었지만, 제2 분 산 프로세서 메모리 칩(7500') 및 제3 분산 프로세서 메모리 칩(7500\")도 제1 분산 프로세서 메모리 칩과 유사하게 구성될 수 있다. 예를 들어, 제2 분산 프로세서 메모리 칩(7500')도 메모리 어레이(7510'), 프로세싱 어레이(7520'), 컨트롤러(7540'), 및/또는 포트(7530', 7531', 7532')와 같은 복수의 통신 포트를 포함할 수 있다. 마찬가지로, 제3 분산 프로세서 메모리 칩(7500\")도 메모리 어레이(7510\"), 프로세싱 어레이(7520\"), 컨 트롤러(7540\"), 및/또는 포트(7530\", 7531\", 7532\")와 같은 복수의 통신 포트를 포함할 수 있다. 일부 실시예들 에서, 제2 분산 프로세서 메모리 칩(7500')의 제2 통신 포트(7531')와 제3 통신 포트(7532')는 제3 분산 프로세 서 메모리 칩(7500\") 및 제1 분산 프로세서 메모리 칩과 각각 통신하도록 구성될 수 있다. 이와 유사하게, 제3 분산 프로세서 메모리 칩(7500\")의 제2 통신 포트(7531\")와 제3 통신 포트(7532\")는 제1 분산 프 로세서 메모리 칩 및 제2 분산 프로세서 메모리 칩(7500')과 각각 통신하도록 구성될 수 있다. 분산 프로 세서 메모리 칩들 간의 구성 유사성으로 인해 개시된 분산 프로세서 메모리 칩에 의거한 연산 시스템의 스케일 링이 용이해질 수 있다. 나아가, 각 분산 프로세서 메모리 칩과 연관된 통신 포트의 개시된 구성은 분산 프로세서 메모리 칩의 어레이의 배치(예: 직렬, 병렬, 루프, 별 형상, 그물망 형상 등의 연결)를 유연하게 할 수 있다. 본 개시의 실시예들에 따르면, 제1 내지 제3 분산 프로세서 메모리 칩(7500, 7500', 7500\")과 같은 분산 프로세 서 메모리 칩들은 버스를 통해 서로 통신할 수 있다. 일부 실시예들에 따르면, 버스는 2개의 상이 한 분산 프로세서 메모리 칩의 2개의 통신 포트를 연결할 수 있다. 예를 들어, 제1 프로세서 메모리 칩의 제2 통신 포트는 버스를 통해 제2 프로세서 메모리 칩(7500')의 제3 통신 포트(7532')로 연결될 수 있다. 본 개시의 실시예들에 따르면, 제1 내지 제3 분산 프로세서 메모리 칩(7500, 7500', 7500\")과 같은 분산 프로세서 메모리 칩들은 버스와 같은 버스를 통해 외부 엔티티(예: 호스트 컴퓨터)와 통신할 수 있다. 예 를 들면, 제1 분산 프로세서 메모리 칩의 제1 통신 포트는 버스를 통해 하나 이상의 외부 엔 티티에 연결될 수 있다. 분산 프로세서 메모리 칩들은 다양한 방법으로 서로 연결될 수 있다. 일부 경우에서, 분산 프로세서 메모리 칩들은 각 분산 프로세서 메모리 칩이 한 쌍의 인접한 분산 프로세서 메모리 칩에 연결되 는 직렬 연결성을 나타낼 수 있다. 다른 경우에서, 분산 프로세서 메모리 칩들은 적어도 하나의 분산 프로세서 메모리 칩이 둘 이상의 다른 분산 프로세서 메모리 칩으로 연결되는 더 높은 정도의 연결성을 나타낼 수 있다. 일부 경우에서, 복수의 메모리 칩 내의 모든 분산 프로세서 메모리 칩들은 다른 모든 분산 프로세서 메모리 칩 에 복수로 연결될 수 있다. 도 75a에 도시된 바와 같이, 버스(또는 도 75a의 실시예와 연관된 임의의 모든 기타 버스)는 단방향성 (unidirectional)일 수 있다. 도 75a에는 버스가 단방향성이고 특정 데이터 전송 흐름(도 75a에 화살표로 표시)이 있는 것으로 도시되어 있지만, 버스(또는 도 75a의 임의의 모든 기타 버스)는 양방향성 버스로 구현될 수 있다. 본 개시의 일부 실시예들에 따르면, 2개의 분산 프로세서 메모리 칩 사이에 연결된 버스는 분 산 프로세서 메모리 칩과 외부 엔티티 사이에 연결된 버스보다 통신 속도가 빠르도록 구성될 수 있다. 일부 실 시예들에서, 분산 프로세서 메모리 칩과 외부 엔티티 사이의 통신은 제한된 시간 동안에, 예를 들면 실행 준비 (호스트 컴퓨터로부터 프로그램 코드, 입력 데이터, 가중치 데이터 등의 로딩) 동안에, 신경망 모델의 실행으로 생성된 결과를 호스트 컴퓨터로 출력하는 주기 동안에 일어날 수 있다. 분산 프로세서 메모리 칩(7500, 7500', 7500\")과 연관된 하나 이상의 프로그램의 실행 동안에(예: 인공지능 어플리케이션 등과 연관된 메모리 집약적 동작 동안에) 분산 프로세서 메모리 칩 사이의 통신은 버스(7533, 7533' 등)를 통해 일어날 수 있다. 일부 실시 예들에서, 분산 프로세서 메모리 칩과 외부 엔티티 사이의 통신은 2개의 프로세서 메모리 칩 사이의 통신보다 덜 빈번히 일어날 수 있다. 통신 요구사항과 실시예들에 따르면, 분산 프로세서 메모리 칩과 외부 엔티티 사이 의 버스는 통신 속도가 분산 프로세서 메모리 칩들 사이의 버스의 통신 속도에 비하여 동일하거나, 빠르거나, 느리도록 구성될 수 있다. 일부 실시예들에서, 도 75a에 묘사된 바와 같이, 제1 내지 제3 분산 프로세서 메모리 칩(7500, 7500', 7500\")과 같은 복수의 분산 프로세서 메모리 칩은 서로 통신하도록 구성될 수 있다. 이러한 능력은 스케일러블 분산 프로 세서 메모리 칩 시스템의 조립을 용이하게 할 수 있다. 예를 들면, 제1 내지 제3 분산 프로세서 메모리 칩 (7500, 7500', 7500\")의 메모리 어레이(7510, 7510', 7510\") 및 프로세싱 어레이(7520, 7520', 7520\")은 통신 채널(예: 도 75a에 도시된 버스)에 의해 연결되는 경우에 단일 분산 프로세서 메모리 칩에 사실상 속하는 것으 로 간주될 수 있다. 본 개시의 실시예들에 따르면, 복수의 분산 프로세서 메모리 칩들 사이의 통신 및/또는 분산 프로세서 메모리 칩과 하나 이상의 외부 엔티티 사이의 통신은 임의의 모든 적절한 방법으로 관리될 수 있다. 일부 실시예들에서, 이러한 통신은 분산 프로세서 메모리 칩의 프로세싱 어레이와 같은 프로세싱 리소스 에 의해 관리될 수 있다. 분산 프로세서의 어레이에 의해 제공되는 프로세싱 리소스를 통신 관리에 의한 연산 부하로부터 완화시키기 위하는 등의 일부 다른 실시예들에서, 분산 프로세서 메모리 칩의 컨트롤러(7540, 7540', 7540\")와 같은 컨트롤러는 분산 프로세서 메모리 칩들 사이의 통신 및/또는 분산 프로세서 메모리 칩(들)과 하나 이상의 외부 엔티티 사이의 통신을 관리하도록 구성될 수 있다. 예를 들어, 제1 내지 제3 분산 프로세서 메모리 칩(7500, 7500', 7500\")의 각 컨트롤러(7540, 7540', 7540\")는 그에 상응하는 분산 프로세서 메모리 칩의 다른 분산 프로세서 메모리 칩과 관련된 다른 분산 프로세서 메모리 칩에 대한 통신을 관리하도록 구성될 수 있다. 일부 실시예들에서, 컨트롤러(7540, 7540', 7540\")는 이러한 통신을 포트(7531, 7531', 7531\", 7532, 7532', 7532\") 등과 같은 상응하는 통신 포트를 통해 제어하도록 구성될 수 있다. 컨트롤러(7540, 7540', 7540\")는 또한 분산 프로세서 메모리 칩들 사이에 존재할 수 있는 시간차를 고려하면서 분산 프로세서 메모리 칩들 사이의 통신을 관리하도록 구성될 수 있다. 예를 들면, 분산 프로세서 메모리 칩(예: 7500)은 다른 분산 프로세서 메모리 칩(예: 7500', 7500\")의 클럭과 다를 수 있는(예: 상이한 타이밍 패턴) 내부 클럭에 의해 공급될 수 있다. 따라서, 일부 실시예들에서, 컨트롤러는 분산 프로세서 메모리 칩 들 사이의 상이한 타이밍 패턴을 고려하는 하나 이상의 전략을 이행하고 분산 프로세서 메모리 칩들 사이의 시 간 편차 가능성을 고려하여 분산 프로세서 메모리 칩들 사이의 통신을 관리하도록 구성될 수 있다. 예를 들어, 일부 실시예들에서, 제1 분산 프로세서 메모리 칩의 컨트롤러는 특정 조건 하에서 제1 분산 프로세서 메모리 칩으로부터 제2 분산 프로세서 메모리 칩(7500')으로의 데이터 전송을 가능하게 하 도록 구성될 수 있다. 일부 경우에서, 컨트롤러는 제1 분산 프로세서 메모리 칩의 하나 이상의 프 로세서 서브유닛이 데이터를 전송할 준비가 되어 있지 않은 경우에 데이터 전송을 보류할 수 있다. 대안적으로 또는 추가적으로, 컨트롤러는 제2 분산 프로세서 메모리 칩(7500')의 수신 프로세서 서브유닛이 데이터를 수신할 준비가 되어 있지 않은 경우에 데이터 전송을 보류할 수 있다. 일부 경우에서, 컨트롤러는 전송 프로세서 서브유닛(예: 칩 내부의 서브유닛)이 데이터를 전송할 준비가 되어 있고 수신 프로세서 서브유 닛(예: 칩(7500') 내부의 서브유닛)이 데이터를 수신할 준비가 되어 있는 것을 모두 확인한 후에 전송 프로세서 서브유닛으로부터 수신 프로세서 서브유닛으로의 데이터 전송을 개시할 수 있다. 다른 실시예들에서, 컨트롤러 는 특히 수신 프로세서 서브유닛이 전송된 데이터를 수신할 준비가 될 때까지 데이터가 컨트롤러(예: 7540 또는 7540')에서 버퍼링 될 수 있는 경우에 전송 프로세서 서브유닛이 데이터를 전송할 준비가 되어 있는 지 여부에만 의거하여 데이터 전송을 개시할 수 있다. 본 개시의 실시예들에 따르면, 컨트롤러는 데이터 전송을 가능하게 하기 위하여 하나 이상의 다른 타이밍 제약이 충족되었는지 여부를 판단하도록 구성될 수 있다. 이러한 타이밍 제약은 전송 프로세서 서브유닛의 전송 시간과 수신 프로세서 서브유닛의 수신 시간 사이의 시간차, 외부 엔티티(예: 호스트 컴퓨터)의 처리되는 데이 터 접근 요청, 전송 프로세서 서브유닛 및 수신 프로세서 서브유닛과 연관된 메모리 리소스(예: 메모리 어레이) 상에서 수행되는 리프레시 동작 등에 관련된 것일 수 있다. 도 75e는 본 개시의 실시예들에 따른 타이밍을 예시적으로 도시한 것이다. 도 75e는 하기의 예를 도시한 것이다. 일부 실시예들에서, 컨트롤러 및 분산 프로세서 메모리 칩과 연관된 다른 컨트롤러들은 클럭 인에이블 신 호를 활용하여 칩들 사이의 데이터 전송을 관리하도록 구성될 수 있다. 예를 들면, 프로세싱 어레이는 클 럭에 의해 공급될 수 있다. 일부 실시예들에서, 하나 이상의 프로세서 서브유닛이 공급된 클럭 신호에 응답하는 지 여부는 클럭 인에이블 신호(도 7a에 \"CE\"로 표시됨)를 활용하여 컨트롤러 등에 의해 제어될 수 있다. 각 프로세서 서브유닛(예: 7520_1 내지 7520_K)은 프로그램 코드를 실행할 수 있고, 프로그램 코드는 통신 명령 을 포함할 수 있다. 본 개시의 일부 실시예들에 따르면, 컨트롤러는 프로세서 서브유닛(7520_1 내지 7520_K)으로의 클럭 인에이블 신호를 제어함으로써 통신 명령의 타이밍을 제어할 수 있다. 예를 들어, 전송 프 로세서 서브유닛(예: 제1 분산 프로세서 메모리 칩의 프로세서 서브유닛)이 특정 사이클(예: 1000번째 클 럭 사이클)에 데이터를 전송하도록 프로그램되어있고 수신 프로세서 서브유닛(예: 제2 분산 프로세서 메모리 칩 (7500')의 프로세서 서브유닛)이 특정 사이클(예: 1000번째 클럭 사이클)에 데이터를 수신하도록 프로그램 되어 있는 경우, 제1 분산 프로세서 메모리 칩의 컨트롤러와 제2 분산 프로세서 메모리 칩(7500')의 컨 트롤러(7540')는 전송 프로세서 서브유닛과 수신 프로세서 서브유닛이 모두 데이터 전송을 수행할 준비가 될 때 까지 데이터 전송을 허용하지 않을 수 있다. 예컨대, 컨트롤러는 수신된 클럭 신호에 대응하여 전송 프로 세서 서브유닛이 데이터를 전송하는 것을 방지하는 특정 클럭 인에이블 신호(예: logic low)를 전송 프로세서 서브유닛에 공급함으로써 전송 프로세서 서브유닛으로부터의 데이터 전송을 '대기'시킬 수 있다. 특정 클럭 인 에이블 신호는 분산 프로세서 메모리 칩의 전체 또는 일부를 '동결' 시킬 수 있다. 반면에, 컨트롤러는 전송 프로세서 서브유닛이 수신된 클럭 신호에 대응하도록 유발하는 반대 클럭 인에이블 신호(예: logic high) 를 전송 프로세서 서브유닛에 공급함으로써 전송 프로세서 서브유닛이 데이터 전송을 개시하도록 유발할 수 있 다. 칩(7500')의 수신 프로세서서 서브유닛이 수신을 하거나 수신을 하지 않는 등의 유사한 동작도 컨트롤러 (7540')에서 제공된 클럭 인에이블 신호를 활용하여 제어될 수 있다. 일부 실시예들에서, 클럭 인에이블 신호는 프로세서 메모리 칩(예: 7500) 내의 모든 프로세서 서브 유닛(예: 7520_1 내지 7520_K)으로 보내질 수 있다. 클럭 인에이블 신호는 일반적으로 프로세서 서브유닛이 각 클럭 신호 에 대응하거나 무시하도록 유발하는 효과가 있을 수 있다. 예를 들면, 일부 경우에서, 클럭 인에이블 신호가 하 이(high)인 경우(특정 어플리케이션의 컨벤션에 따라), 프로세서 서브유닛은 클럭 신호에 대응할 수 있고 클럭 신호 타이밍에 따라 하나 이상의 명령을 실행할 수 있다. 반면에, 클럭 신호가 로우(low)인 경우, 프로세서 서 브유닛은 클럭 신호에 대응하는 것이 방지되어 클럭 타이밍에 대응하여 명령을 실행하지 않도록 할 수 있다.즉, 클럭 인에이블 신호가 로우인 경우, 프로세서 서브유닛은 수신된 클럭 신호를 무시할 수 있다. 도 75a를 다시 참조하면, 임의의 컨트롤러(7540, 7540', 7540\")는 해당 어레이의 하나 이상의 프로세서 서브유 닛이 수신된 클럭 신호에 대응하거나 대응하지 않게 유발함으로써 클럭 인에이블 신호를 활용하여 각 분산 프로 세서 메모리 칩의 동작을 제어하도록 구성될 수 있다. 일부 실시예들에서, 컨트롤러(7540, 7540', 7540\")는 코 드 실행을 선택적으로, 예컨대 이러한 코드가 데이터 전송 동작과 그 타이밍에 관한 것이거나 데이터 전송 동작 과 그 타이밍을 포함하는 경우에, 진행하도록 구성될 수 있다. 일부 실시예들에서, 컨트롤러(7540, 7540', 7540\")는 클럭 인에이블 신호를 활용하여 임의의 통신 포트(7531, 7531', 7531\", 7532, 7532', 7532\")를 통하 여 2개의 상이한 분산 프로세서 메모리 칩 사이의 데이터 전송의 타이밍을 제어하도록 구성될 수 있다. 일부 실 시예들에서, 컨트롤러(7540, 7540', 7540\")는 클럭 인에이블 신호를 활용하여 임의의 통신 포트(7531, 7531', 7531\", 7532, 7532', 7532\")를 통하여 2개의 상이한 분산 프로세서 메모리 칩 사이의 데이터 수신의 시간을 제 어하도록 구성될 수 있다. 일부 실시예들에서, 2개의 상이한 분산 프로세서 메모리 칩 사이의 데이터 전송 타이밍은 컴파일 최적화 (compilation optimization) 단계의 의거하여 설정될 수 있다. 컴파일은 2개의 상이한 분산 프로세서 메모리 칩 사이에 연결된 버스를 통한 전송 지연에 영향을 받지 않고 작업이 프로세싱 서브유닛에 효율적으로 배정될 수 있는 프로세싱 루틴을 구축하게 할 수 있다. 컴파일은 호스트 컴퓨터 내의 컴파일러에 의해 수행되거나 호스트 컴퓨터로 전송될 수 있다. 정상적으로, 2개의 상이한 분산 프로세서 메모리 칩 사이의 버스를 통한 전송 지연은 데이터를 필요로 하는 프로세싱 서브유닛에 대한 데이터 병목을 가져올 수 있다. 개시된 컴파일은 버스를 통한 바람직하지 않은 전송 지연이 있어도 프로세싱 유닛이 연속적으로 데이터를 수신할 수 있게 하는 식으로 데이터 전송 일정을 짤 수 있다. 도 75a의 실시예는 분산 프로세서 메모리 칩(7500', 7500'', 7500''') 당 3개의 포트를 포함하고 있지만, 개시 된 실시예에 따른 분산 프로세서 메모리 칩에는 임의의 모든 수의 포트가 포함될 수 있다. 예를 들면, 일부 경 우에서, 분산 프로세서 메모리 칩은 더 많은 수의 또는 더 적은 수의 포트를 포함할 수 있다. 도 75b의 실시예 에서, 각 분산 프로세서 메모리 칩(예: 7500A-7500I)은 다중 포트로 구성될 수 있다. 이러한 포트들은 사실상 서로 동일하거나 상이할 수 있다. 도시된 예에서, 각 분산 프로세서 메모리 칩은 하나의 호스트 통신 포트 와 4개의 칩 포트를 포함하는 5개의 포트를 포함한다. 호스트 통신 포트는 도 75b에 도시된 바와 같은 어레이 내의 임의의 분산 프로세서 메모리 칩과 분산 프로세서 메모리 칩의 어레이에 대해 원격에 위 치한 호스트 컴퓨터 등 사이의 통신(버스 경유)을 하도록 구성될 수 있다. 칩 포트는 버스를 통해 분산 프로세서 메모리 칩들 사이의 통신이 가능하게 하도록 구성될 수 있다. 임의의 모든 수의 분산 프로세서 메모리 칩이 서로 연결될 수 있다. 도 75b에 도시된 예에서, 분산 프로세서 메 모리 칩 당 4개의 칩 포트를 포함함으로써 각 분산 프로세서 메모리 칩이 둘 이상의 다른 분산 프로세서 메모리 칩으로 연결되는 어레이가 가능할 수 있고, 일부 경우에서, 특정 칩은 4개의 다른 분산 프로세서 메모리 칩으로 연결될 수 있다. 분산 프로세서 메모리 칩에 더 많은 칩 포트를 포함시키면 분산 프로세서 메모리 칩 간의 상호 연결성이 더 확대될 수 있다. 또한, 도 75b에는 분산 프로세서 메모리 칩(7500A-7500I)에 2가지의 상이한 유형의 통신 포트(7570, 7572)가 있 는 것으로 도시되어 있지만, 일부 경우에서는 각 분산 프로세서 메모리 칩에 단일 유형의 통신 포트가 포함될 수 있다. 다른 경우에서, 2가지 이상의 유형의 통신 포트가 하나 이상의 분산 프로세서 메모리 칩에 포함될 수 있다. 도 75c의 예에서, 각각의 분산 프로세서 메모리 칩(7500A'-7500C')은 2개(또는 그 이상)의 동일한 유형의 통신 포트를 포함한다. 본 실시예에서, 통신 포트는 버스를 통해 호스트 컴퓨터와 같은 외부 엔티티와 통신하는 것을 가능하게 하도록 구성될 수 있고, 또한 버스를 통해 분산 프로세서 메모리 칩들 (예: 7500B' 및 7500C') 간의 통신을 가능하게 하도록 구성될 수 있다. 일부 실시예들에서, 하나 이상의 분산 프로세서 메모리 칩 상에 제공된 포트들은 하나 이상의 호스트로의 접근 을 제공하는데 사용될 수 있다. 예를 들어, 도 75d에 도시된 실시예에서, 분산 프로세서 메모리 칩은 둘 또는 그 이상의 포트를 포함한다. 포트는 호스트 포트, 칩 포트, 또는 호스트 포트와 칩포트의 조합을 구성할 수 있다. 도시된 실시예에서, 2개의 포트(7570, 7570')는 상이한 2개의 호스트(예: 호스트 컴퓨터 또는 연산 요소, 또는 다른 유형의 논리부)에 버스(7534, 7534')를 통한 분산 프로세서 메모리 칩(7500A)으로의 접근 을 제공할 수 있다. 이러한 실시예는 2개(또는 그 이상)의 상이한 호스트 컴퓨터에 분산 프로세서 메모리 칩 (7500A)으로의 접근을 제공할 수 있다. 그러나 다른 실시예들에서, 예를 들어 호스트 엔티티가 분산 프로세서 메모리 칩(7500A)의 프로세서 서브유닛/메모리 뱅크의 하나 이상으로 추가적인 대역폭 또는 병렬 접근을 요구하는 경우와 같이, 버스(7534, 7534')는 모두 동일한 호스트 엔티티로 연결될 수 있다. 일부 경우에서, 도 75d에 도시된 바와 같이, 분산 프로세서 메모리 칩(7500A)의 분산 프로세서 서브유닛/메모리 뱅크로의 접근을 제어하는 데에 하나 이상의 컨트롤러(7540, 7540')가 사용될 수 있다. 다른 경우에서, 하나 이 상의 외부 호스트 엔티티로부터의 통신을 처리하는 데에 단일 컨트롤러가 사용될 수 있다. 또한, 분산 프로세서 메모리 칩(7500A) 내의 하나 이상의 버스는 분산 프로세서 메모리 칩(7500A)의 분산 프로 세서 서브유닛/메모리 뱅크로의 병렬 접근을 가능하게 할 수 있다. 예컨대, 분산 프로세서 메모리 칩(7500A)은 분산 프로세서 서브유닛(7520_1 내지 7520_6) 및 해당 전용 메모리 뱅크(7510_1 내지 7510_6) 등으로의 병렬 접 근을 가능하게 하는 제1 버스 및 제2 버스(7580')를 포함할 수 있다. 이러한 구성은 분산 프로세서 메모 리 칩(7500A) 내의 2개의 상이한 위치로의 동시 접근을 가능하게 할 수 있다. 또한, 모든 포트가 동시에 사용되 지 않는 경우에서, 분산 프로세서 메모리 칩(7500A) 내의 하드웨어 리소스(예: 공통 버스 및/또는 공통 컨트롤 러)를 공유할 수 있고, 이러한 하드웨어로 멀티플렉스된 IO를 구성할 수 있다. 일부 실시예들에서, 연산 유닛(예: 프로세서 서브유닛(7520_1 내지 7520_6))의 일부는 추가 포트(7570') 또는 컨트롤러로 연결될 수 있는 반면에, 다른 연산 유닛들은 연결되지 않을 수 있다. 그러나 추가 포트(7570')로 연 결되지 않은 연산 유닛으로부터의 데이터는 포트(7570')로 연결된 연산 유닛으로 연결의 내부 그리드를 통해 들 어갈 수 있다. 이로써, 추가 버스를 추가하지 않고도 포트(7570, 7570') 모두에서 통신이 동시에 수행될 수 있 다. 통신 포트(예: 7530 내지 7532)와 컨트롤러(예: 7540)가 서로 별개의 요소인 것으로 도시되어 있지만, 본 개시 의 실시예들에 따르면, 통신 포트와 컨트롤러(또는 임의의 모든 다른 컴포넌트)가 통합된 유닛으로 구현될 수 있음은 당연하다 할 것이다. 도 76은 본 개시의 실시예들에 따른 통합 컨트롤러 및 인터페이스 모듈을 구비한 분산 프로세서 메모리 칩을 도시한 것이다. 도 76에 도시된 바와 같이, 프로세서 메모리 칩은 도 75의 컨트롤러와 통신 포트(7530, 7531, 7532)의 기능을 수행하도록 구성된 통합 컨트롤러 및 인터페이스 모듈을 구비하여 구현될 수 있다. 도 76에 도시된 바와 같이, 컨트롤러 및 인터페이스 모듈은 통신 포트(예: 7530, 7531, 7532)와 유사한 인터페이스(7548_1 내지 7548_N)를 통해 외부 엔티티, 하나 이상의 분산 프로세서 메모리 칩 등과 같은 다중의 상이한 엔티티와 통신하도록 구성될 수 있다. 컨트롤러 및 인터페이스 모 듈은 또한, 분산 프로세서 메모리 칩들 사이 또는 분산 프로세서 메모리 칩과 호스트 컴퓨터와 같 은 외부 엔티티 사이의 통신을 제어하도록 구성될 수 있다. 일부 실시예들에서, 컨트롤러 및 인터페이스 모듈 은 하나 이상의 다른 분산 프로세서 메모리 칩과 병렬 통신 및 호스트 컴퓨터, 통신 모듈 등과 같은 외부 엔티티와 병렬 통신하도록 구성된 통신 인터페이스(7548_1 내지 7548_N)를 포함할 수 있다. 도 77은 본 개시의 실시예들에 따른 도 75a에 도시된 스케일러블 프로세서 메모리 시스템에서 분산 프로세서 메 모리 칩 사이에 데이터를 전송하는 순서도를 도시한 것이다. 도시의 목적상, 데이터 전송의 흐름은 도 75a를 참 조하여 설명하고 데이터가 제1 프로세서 메모리 칩으로부터 제2 프로세서 메모리 칩(7500')으로 전송되는 것으로 간주하기로 한다. 단계 S7710에서, 데이터 전송 요청이 수신될 수 있다. 그러나 여기서, 앞서 설명한 바와 같이, 일부 실시예들에 서, 데이터 전송 요청이 필요하지 않을 수 있다. 예를 들면, 일부 경우에서, 데이터 전송의 시기는 미리 결정될 수 있다(예: 특정 소프트웨어 코드에 의해). 이러한 경우, 데이터 전송은 별도의 데이터 전송 요청 없이 진행될 수 있다. 단계 S7710은 예컨대 컨트롤러에 의해 수행될 수 있다. 일부 실시예들에서, 데이터 전송 요청은 제1 분산 프로세서 메모리 칩의 하나의 프로세서 서브유닛으로부터 제2 분산 프로세서 메모리 칩(7500') 의 다른 프로세서 서브유닛으로의 데이터 전송 요청을 포함할 수 있다. 단계 S7720에서, 데이터 전송 시기가 결정될 수 있다. 설명한 바와 같이, 데이터 전송 시기는 미리 결정될 수 있고 특정 소프트웨어 프로그램의 실행 순서에 따를 수 있다. 단계 S7720은 예컨대 컨트롤러 등에 의해 수행될 수 있다. 일부 실시예들에서, 데이터 전송 시기는 전송하는 프로세서 서브유닛이 데이터를 전송할 준비가 되었는지 여부 및/또는 수신하는 프로세서 서브유닛이 데이터를 수신할 준비가 되었는지 여부를 고 려하여 판단될 수 있다. 본 개시의 실시예들에 따르면, 이러한 데이터 전송을 가능하게 하도록 하나 이상의 다 른 타이밍 제약이 완수되었는지 여부도 고려될 수 있다. 이러한 하나 이상의 타이밍 제약은 전송하는 프로세서 서브유닛으로부터의 전송 시간과 수신하는 프로세서 서브유닛의 수신 시간 사이의 시간차, 외부 엔티티(예: 호 스트 컴퓨터)로부터의 처리되는 데이터로의 접근 요청, 전송 또는 수신하는 프로세서 서브유닛과 연관된 메모리 리소스(예: 메모리 어레이) 상에 수행되는 리프레시 동작 등과 관련될 수 있다. 본 개시의 실시예들에 따르면, 프로세싱 서브유닛은 클럭에 의해 공급될 수 있다. 일부 실시예들에서, 프로세싱 서브유닛에 공급되는 클럭은클럭 인에이블 신호 등을 활용하여 제어될 수 있다. 본 개시의 일부 실시예들에 따르면, 컨트롤러는 프로 세서 서브유닛(7520_1 내지 7520_K)로의 클럭 인에이블 신호를 제어함으로써 통신 명령의 시기를 제어할 수 있 다. 단계 S7703에서, 단계 S7720에서 결정된 데이터 전송 시기에 의거하여 데이터 전송이 수행될 수 있다. 단계 S7730은 컨트롤러 등에 의해 관리될 수 있다. 예를 들어, 제1 분산 프로세서 메모리 칩의 전송 프 로세서 서브유닛은 단계 S7720에서 결정된 데이터 전송 시기에 따라 제2 분산 프로세서 메모리 칩(75000')의 수 신 프로세서 서브유닛으로 데이터를 전송할 수 있다. 개시된 아키텍처는 다양한 응용에 활용될 수 있다. 예를 들어, 일부 경우에서, 상기 아키텍처는 신경망(특히 대 형 신경망)과 연관된 가중치 또는 신경값(neuron values) 또는 부분 신경값과 같은 데이터가 상이한 분산 프로 세서 메모리 칩들 간에 공유되는 것을 용이하게 할 수 있다. 또한, SUM, AVG 등과 같은 특정 연산은 다중의 상 이한 분산 프로세서 메모리 칩들로부터의 데이터를 필요로 할 수 있다. 이러한 경우, 개시된 아키텍처는 이러한 데이터가 다중의 상이한 분산 프로세서 메모리 칩들 간에 공유되는 것을 용이하게 할 수 있다. 나아가, 개시된 아키텍처는 분산 프로세서 메모리 칩들 간에 기록이 공유되는 것을 용이하게 하여 쿼리의 결합 연산 등을 지원 할 수 있다. 또한, 기재된 실시예들은 분산 프로세서 메모리 칩에 대한 것이지만, 분산 프로세서 서브유닛 등을 포함하지 않 는 일반적인 메모리 칩에도 동일한 원리와 방식이 적용될 수 있다. 예를 들어, 일부 경우에서, 다중 메모리 칩 이 다중 포트 메모리 칩으로 서로 결합되어 프로세서 서브유닛의 어레이가 없이도 메모리 칩의 어레이를 형성할 수 있다. 다른 실시예에서, 다중 메모리 칩이 서로 결합되어 연결된 메모리의 어레이를 형성하여 다중 메모리 칩으로 구성된 사실상 하나의 큰 메모리를 호스트에 제공할 수 있다. 포트의 내부 연결은 메인 버스로의 연결 또는 프로세싱 어레이에 포함된 내부 프로세서 서브유닛들 중의 하나로 의 연결일 수 있다. 인메모리 0 값 검출 본 개시의 일부 실시예들은 복수의 메모리 뱅크의 하나 이상의 특정 주소에 저장된 0 값을 검출하기 위한 메모 리 유닛에 관한 것이다. 개시된 메모리 유닛의 0 값 검출 기능은 컴퓨팅 시스템의 전력 소모를 감소시키는데 유 용할 수 있고, 추가적으로 또는 대안적으로, 메모리로부터 0 값을 검색하는데 필요한 프로세싱 시간을 줄일 수 있다. 이 기능은 읽은 데이터에 실제로 0 값이 많은 시스템에서, 또한 메모리로부터의 0 값 검색이 필요 없을 수 있고(예: 0 값을 임의의 모든 다른 값과 곱하면 0이 됨) 연산 회로는 피연산자 중의 하나가 0이고 결과를 더 욱 시간 또는 에너지 효율적으로 계산한다는 사실을 활용할 수 있는 곱셈/덧셈/뺄셈 등의 연산과 같은 계산 동 작에, 특히 관련이 있다. 이러한 경우에, 0 값의 존재 검출은 메모리 접근과 메모리로부터의 0 값 검색을 대신 하여 활용될 수 있다. 본 섹션에서, 개시된 실시예들은 읽기 기능에 관하여 기재한다. 그러나 개시된 아키텍처와 방식이 0 값 쓰기 연 산 및 다른 값들이 더 자주 등장할 가능성이 있는 다른 특정 소정의 비제로(non-zero) 값 연산에도 동일하게 적 용될 수 있음은 당연하다 할 것이다. 개시된 실시예들에서, 메모리에서 0 값을 가져오는 대신에, 이러한 값이 특정 주소에서 검출되는 경우에, 메모 리 유닛은 메모리 유닛 외부의 하나 이상의 회로(예: 메모리 유닛 외부에 위치한 하나 이상의 프로세서, CPU 등)로 0 값 지시자를 내보낼 수 있다. 0 값은 다중 비트 0 값 제로(예: 0 값 바이트, 0 값 워드, 1 바이트 미만, 1 바이트 이상 등인 다중 비트 0 값) 이다. 0 값 지시자는 메모리에 저장된 0 값을 지시하는 1비트 신호 이므로, 1비트 0 값 지시 신호를 전달하는 것이 메모리에 저장된 n 비트의 데이터를 전송하는 것보다 유리하다. 송신된 제로 지시는 전송에 대한 에너지 소비를 1/n만큼 감소시킬 수 있고, 뉴런의 가중치에 의한 입력의 계산, 컨볼루션, 입력 데이터에 커널(kernel)의 적용, 및 학습 신경망, 인공지능과 연관된 계산, 및 광범위한 어레이 의 다른 유형의 계산에 곱셈 연산이 개입되는 경우 등에서 계산의 속도를 높일 수 있다. 이러한 기능성을 제공 하기 위하여, 개시된 메모리 유닛은 메모리의 특정 위치에 있는 0 값의 존재를 검출하고 0 값의 검색(예: 읽기 명령을 통한 검색)을 방지하고 메모리 유닛 외부의 회로망으로 0 값 지시자가 대신 송신(예: 메모리의 하나 이 상의 제어라인, 메모리 유닛과 연관된 하나 이상의 버스 등을 활용)되도록 하는 하나 이상의 0 값 검출 논리부 를 포함할 수 있다. 0 값 검출은 메모리 매트 레벨, 뱅크 레벨, 서브뱅크 레벨, 칩 레벨 등에서 수행될 수 있다. 여기서, 개시된 실시예들은 메모리 칩 외부의 위치로 0 값 지시자를 전달하는 것과 관련하여 설명되어 있지만, 개시된 실시예들과 기능들은 메모리 칩 내부에서 프로세싱이 수행되는 경우에도 상당히 유리할 수 있다. 예를 들어, 여기에 개시된 분산 프로세서 메모리 칩과 같은 실시예들에서, 프로세싱은 해당 프로세스 서브유닛에 의 해 다양한 메모리 뱅크 내의 데이터에 대해 수행될 수 있다. 연관 데이터가 0을 많이 포함할 수 있는 신경망 또 는 데이터 분석의 실행과 같은 많은 경우에서, 개시된 방식은 분산 프로세서 메모리 칩의 프로세서 서브유닛에 의해 수행되는 프로세싱과 연관된 프로세싱의 속도 증가 및/또는 전력 소비 감소를 가져올 수 있다. 도 78a는 본 개시의 실시예들에 따른 칩 레벨에서 메모리 칩 내에 구현된 복수의 메모리 뱅크의 하나 이 상의 특정 주소에 저장된 0 값을 검출하는 시스템을 도시한 것이다. 시스템은 메모리 칩과 호스트를 포함할 수 있다. 메모리 칩은 복수의 제어부를 포함할 수 있고, 각 제어부에는 전용 메모 리 뱅크가 있을 수 있다. 예컨대, 제어부는 전용 메모리 뱅크에 작동적으로 연결될 수 있다. 예컨대, 메모리 뱅크의 어레이 간에 공간적으로 분산된 프로세서 서브유닛을 포함하는 본 개시의 분산 프로세서 메모리 칩과 관련된 일부 경우에서, 메모리 칩 내의 프로세싱에는 메모리 접근(읽기, 쓰기 여부와 무관하게)이 개입될 수 있다. 메모리 칩 내부의 프로세싱의 경우에서도, 읽기 또는 쓰기 명령과 연관된 0 값을 검출하는 개 시된 방식은 내부 프로세서 유닛 또는 서브유닛이 실세 0 값의 전송을 포기하도록 할 수 있다. 대신에, 0 값의 검출과 0 값 지시자의 송신(예: 하나 이상의 내부 프로세싱 서브유닛으로)에 응답하여 분산 프로세서 메모리 칩 은 메모리 칩 내의 0 값의 데이터 송신에 소모되었을 수 있는 에너지를 절약할 수 있다. 다른 예에서, 메모리 칩과 호스트는 각각 메모리 칩과 호스트 사이의 통신을 가능하게 하는 입력/출력(IO)을 포함할 수 있다. 각 IO는 0 값 지시자 라인(7830A)과 버스(7840A)에 결합될 수 있다. 0 값 지시자 라인(7830A)은 0 값 지시자를 메모리 칩으로부터 호스트로 전송할 수 있고, 0 값 지시자 는 호스트에 의해 요청된 메모리 뱅크의 특정 주소에 저장된 0 값을 검출함에 따라 메모리 칩에 의 해 생성된 1비트 신호를 포함할 수 있다. 호스트는 0 값 지시자 라인(7830A)를 통해 0 값 지시자를 수신 하면 0 값 지시자와 연관된 하나 이상의 미리 정의된 동작을 수행할 수 있다. 예를 들어, 호스트가 곱셈 을 위한 피연산자를 검색하도록 메모리 칩에 요청했다면, 피연산자 중의 하나가 0임을 수신된 0 값 지시 자로부터 호스트가 (실제 메모리 값을 수신하지 않고) 확인하게 되므로, 호스트는 곱셈을 더욱 효 율적으로 계산할 수 있다. 호스트는 또한 메모리 칩으로 명령, 데이터, 및 기타 입력을 제공하고 버스를 통해 메모리 칩으로부터 출력을 읽어올 수 있다. 호스트로부터의 통신을 수신하면, 메모리 칩은 수신된 통신과 연관된 데이터를 가져올 수 있고 가져온 데이터를 버스를 통해 호스트 로 전송할 수 있다. 일부 실시예들에서, 호스트는 제로 데이터 값 대신에 0 값 지시자를 메모리 칩으로 보낼 수 있다. 이로써, 메모 리 칩(예: 메모리 칩 상에 배치된 컨트롤러)는제로 데이터 값을 수신할 필요 없이 메모리 내에 0 값을 저장하거 나 리프레시할 수 있다. 이러한 업데이트는 0 값 지시자의 수신(예: 쓰기 명령의 일부)에 의거하여 일어날 수 있다. 도 78b는 본 개시의 실시예들에 따른 메모리 뱅크 레벨에서 복수의 메모리 뱅크(7811A, 7811B)의 하나 이상의 특정 주소에 저장된 0 값을 검출하는 메모리 칩을 도시한 것이다. 메모리 칩은 복수의 메모리 뱅크 (7811A, 7811B)와 IO 버스를 포함할 수 있다. 도 78b에는 메모리 칩에 2개의 메모리 뱅크(7811A, 7811B)가 구현된 것으로 도시하고 있지만, 메모리 칩은 임의의 모든 수의 메모리 뱅크를 포함할 수 있다. IO 버스는 버스(7840B)를 통해 외부 칩(예: 도 78a의 호스트)과 데이터를 송수신하도록 구성될 수 있다. 버스(7840B)는 도 78a의 버스(7840A)와 유사하게 기능할 수 있다. IO 버스는 또한 0 값 지시자 라 인(7830B)을 통해 0 값 지시자를 전송할 수 있고, 0 값 지시자 라인(7830B)은 도 78a의 0 값 지시자 라인 (7830A)과 유사하게 기능할 수 있다. IO 버스는 또한 내부 0 값 지시자 라인과 버스를 통해 메모리 뱅크(7811A, 7811B)와 통신하도록 구성될 수 있다. IO 버스는 수신된 데이터를 외부 칩으로부터 메모리 뱅크(7811A, 7811B)의 하나로 전송할 수 있다. 예컨대, IO 버스는 메모리 뱅크(7811A)의 특정 주 소에 저장된 데이터의 읽기 명령을 포함하는 데이터를 버스를 통해 전송할 수 있다. IO 버스와 메 모리 뱅크(7811A, 7811B) 사이에는 멀티플렉서(mux)가 포함될 수 있고 내부 0 값 지시자 라인과 버스 (7841A)에 의해 연결될 수 있다. 멀티플렉서는 수신된 데이터를 IO 버스로부터 특정 메모리 뱅크로 전송 하도록 구성될 수 있고, 수신된 데이터 또는 수신된 0 값 지시자를 특정 메모리 뱅크로부터 IO 버스로 전 송하도록 더 구성될 수 있다. 일부 경우에서, 호스트 엔티티는 정상적인 데이터 송신만을 수신하도록 구성될 수 있고, 개시된 0 값 지시자에 대한 해석 또는 응답을 하지 못하도록 구성될 수 있다. 이러한 경우에서, 개시된 실시예들(예: 컨트롤러/칩 IO등)은 0 값 지시자 신호 대신에 호스트 IO에 대한 데이터 라인에 대한 0 값을 재생할 수 있고, 이로써 칩의 내 부적으로 데이터 전송 전력을 절약할 수 있다. 메모리 뱅크(7811A, 7811B)는 각각 제어부를 포함한다. 제어부는 메모리 뱅크의 요청된 주소에 저장된 0 값을 검출할 수 있다. 저장된 0 값을 검출하면, 제어부는 0 값 지시자를 생성하고 내부 0 값 지시자 라인을 통 해 IO 버스로 전송할 수 있으며, 이어서 0 값 지시자는 0 값 지시자 라인(7830B)을 통해 외부 칩으로 전 송될 수 있다. 도 79는 본 개시의 실시예들에 따른 메모리 매트 레벨에서 복수의 메모리 매트의 하나 이상의 특정 주소에 저장 된 0 값을 검출하는 메모리 뱅크를 도시한 것이다. 일부 실시예들에서, 메모리 뱅크는 메모리 매트 (7912A, 7912B)로 정리될 수 있고, 각 메모리 매트는 개별적으로 제어되고 접근될 수 있다. 메모리 뱅크 는 0 값 검출 논리부(7914A, 7914B)를 포함할 수 있는 메모리 매트 컨트롤러(7913A, 7913B)를 포함할 수 있다. 메모리 매트 컨트롤러(7913A, 7913B)는 각각 메모리 매트(7912A, 7912B) 상의 위치로 읽기 및 쓰기가 가능하도 록 할 수 있다. 메모리 뱅크는 읽기 비활성 요소, 로컬 센스 증폭기(7915A, 7915B), 및/또는 글로벌 센스 증폭기를 더 포함할 수 있다. 메모리 매트(7912A, 7912B)는 각각 복수의 메모리 셀을 포함할 수 있다. 복수의 메모리 셀은 각각 1비트의 2진 정보를 저장할 수 있다. 예를 들어, 임의의 모든 메모리 셀은 개별적으로 0 값을 저장할 수 있다. 특정 메모리 매트의 모든 메모리 셀이 0 값을 저장하고 있으면, 0 값은 메모리 매트 전체와 연관이 있을 수 있다. 메모리 매트 컨트롤러(7913A, 7913B)는 각각 전용 메모리 매트에 접근하도록 구성될 수 있고, 전용 메모리 매트 에 저장된 데이터를 읽거나 전용 매트에 데이터를 쓸 수 있다. 일부 실시예들에서, 0 값 검출 논리부(7914A 또는 7914B)는 메모리 뱅크 내에 구현될 수 있다. 하나 이상 의 0 값 검출 논리부(7914A, 7914B)가 메모리 뱅크, 메모리 서브뱅크, 메모리 매트, 및 하나 이상의 메모리 셀 의 세트와 연관될 수 있다. 0 값 검출 논리부(7914A 또는 7914B)는 요청된 특정 주소(예: 메모리 매트(7912A 또 는 7912B))가 0 값을 저장하고 있음을 검출할 수 있다. 검출은 여러 방법으로 수행될 수 있다. 제1 방법은 0에 대한 디지털 비교기를 활용하는 것을 포함한다. 디지털 비교기는 2개의 숫자를 2진 형태의 입력 으로 취하고 제1 숫자(수신된 데이터)가 제2 숫자와 동일한지 여부를 판단하도록 구성될 수 있다. 2개의 숫 자가 동일한 것으로 디지털 비교기가 판단하는 경우, 0 값 검출 논리부는 0 값 지시자를 생성할 수 있다. 0 값 지시자는 1비트 신호일 수 있고, 데이터 비트를 다음 레벨(예: 도 78b의 IO 버스)로 전송할 수 있는 증폭 기(예: 로컬 센스 증폭기(7915A, 7915B)), 송신기, 및 버퍼를 비활성화할 수 있다. 0 값 지시자는 0 값 지시자 라인(7931A 또는 7931B)을 통해 글로벌 센스 증폭기로 더 전송될 수 있지만, 일부 경우에서는 글로벌 센 스 증폭기를 바이패스 할 수 있다. 0 값 검출의 제2 방법은 아날로그 비교기를 활용하는 것을 포함할 수 있다. 아날로그 비교기는 비교를 위해 2개 의 아날로그 입력의 전압을 활용하는 것을 제외하고는 디지털 비교기와 유사하게 기능할 수 있다. 예를 들면, 비트가 모두 감지될 수 있고, 비교기는 신호 사이의 논리 OR 함수 역할을 할 수 있다. 0 값 검출의 제3 방법은 로컬 센스 증폭기(7915A, 7915B)로부터 전송된 신호를 글로벌 센스 증폭기 내부 로 활용하는 것을 포함할 수 있고, 글로벌 센스 증폭기는 입력 중에서 하이(비제로)인 것이 있는지 여부 를 감지하고 이 논리 신호를 활용하여 다음 레벨의 증폭기를 제어하도록 구성된다. 로컬 센스 증폭기(7915A, 7915B)와 글로벌 센스 증폭기는 복수의 메모리 뱅크로부터 저전력 신호를 감지하고, 복수의 메모리 뱅크 에 저장된 데이터가 메모리 매트 컨트롤러(7913A 또는 7913B)와 같은 적어도 하나의 컨트롤러에 의해 해석될 수 있도록 작은 전압 스윙을 높은 전압 레벨로 증폭하도록 구성된 복수의 트랜지스터를 포함할 수 있다. 예를 들어, 메모리 셀은 메모리 뱅크 상에 행과 열로 레이아웃 될 수 있다. 각 라인은 행에서 각 메모리 셀에 부착될 수 있다. 행을 따라 있는 라인은 워드라인이라고 하며, 선택적으로 전압을 가하여 활성화된다. 열을 따 라 있는 라인은 비트라인이라고 하며, 2개의 보완적인 비트라인이 메모리 어레이의 가장자리에서 센스 증폭기에 부착될 수 있다. 센스 증폭기의 수는 메모리 뱅크 상의 비트라인(열)의 수에 상응할 수 있다. 특정 메모 리 셀에서 비트를 읽기 위하여, 셀의 행을 따라 있는 워드라인이 온 되어(turned on) 행에 있는 모든 메모리 셀 이 활성화된다. 이어, 각 셀에 저장된 값(0 또는 1)은 특정 셀과 연관된 비트라인에서 사용 가능해진다. 2개의 보완적인 비트라인의 종단에 있는 센스 증폭기는 작은 전압을 정상 논리 레벨로 증폭할 수 있다. 이어, 원하는 셀로부터의 비트는 셀의 센스 증폭기로부터 버퍼로 래치되고(latched) 출력 버스에 놓이게 될 수 있다. 0 값 검출의 제4 방법은 값이 0인 경우에 메모리에 저장되고 쓰기 시간에 저장된 각 워드 당 추가 비트를 활용 하는 것을 포함할 수 있고 데이터를 읽어서 데이터가 0인지 아닌지를 알게 되는 경우에 이러한 추가 비트를 활 용할 수 있다. 이 방법은 메모리에 모든 0을 쓰는 것을 피할 수 있으므로 에너지를 더욱 절약할 수 있다. 앞서 설명하고 본 개시 전반에서 설명하는 바와 같이, 일부 실시예들은 복수의 프로세서 서브유닛을 포함하는 메모리 유닛(예: 메모리 유닛)을 포함할 수 있다. 이러한 프로세서 서브유닛은 단일 기판(예: 메모리 유 닛과 같은 메모리 칩의 기판) 상에 공간적으로 분산될 수 있다. 또한, 복수의 프로세서 서브유닛 각각은 메모리 유닛의 복수의 메모리 뱅크 중의 해당 메모리 뱅크 전용일 수 있다. 또한, 해당 프로세서 서브 유 닛 전용의 이러한 메모리 뱅크도 기판 상에 공간적으로 분산될 수 있다. 일부 실시예들에서, 메모리 유닛(780 0)은 특정 작업(예: 신경망 실행과 연관된 하나 이상의 연산 등)과 연관될 수 있고, 메모리 유닛의 프로 세서 서브유닛 각각은 이러한 작업의 일부분의 수행을 담당할 수 있다. 예를 들어, 각 프로세서 서브유닛에는 데이터 처리 및 메모리 연산, 산술 및 논리 연산 등을 포함할 수 있는 명령이 구비될 수 있다. 일부 경우에서, 0 값 검출 로직은 0 값 지시자를 메모리 유닛 상에 공간적으로 분산된 기재된 프로세서 서브유닛의 하나 이상으로 제공하도록 구성될 수 있다. 도 80은 본 개시의 실시예들에 따른 복수의 메모리 뱅크의 특정 주소에 저장된 0 값을 검출하는 예시적인 방법 의 순서도를 도시한 것이다. 방법은 메모리 칩(예: 도 78b의 메모리 칩)에 의해 수행될 수 있다. 구체적으로, 메모리 유닛의 컨트롤러(예: 도 79의 컨트롤러(7913A) 및 0 값 검출 논리부(예: 0 값 검출 논리부(7914A))가 방법을 수행할 수 있다. 단계 8010에서, 임의의 모든 적합한 방식에 의해 읽기 또는 쓰기 동작이 개시될 수 있다. 일부 경우에서, 컨트 롤러는 복수의 이산 메모리 뱅크(예: 도 78에 도시된 메모리 뱅크)의 특정 주소에 저장된 데이터를 읽어오라는 요청을 수신할 수 있다. 컨트롤러는 복수의 이산 메모리 뱅크에 대한 읽기/쓰기 동작의 적어도 일 양상을 제어 하도록 구성될 수 있다. 단계 8020에서, 하나 이상의 0 값 검출 회로가 사용되어 읽기 또는 쓰기 명령과 연관된 0 값의 존재를 검출할 수 있다. 예를 들면, 0 값 검출 논리부(예: 도 78의 00 값 검출 논리부)가 읽기 또는 쓰기와 연관된 특정 주소와 연관된 0 값을 검출할 수 있다. 단계 8030에서, 컨트롤러는 단계 8020에서 0 값 검출 논리부에 의한 0 값 검출에 응답하여 메모리 유닛 외부의 하나 이상의 회로로 0 값 지시자를 전송할 수 있다. 예를 들어, 0 값 검출 논리부는 요청된 주소가 0 값을 저장 하고 있다고 판단할 수 있고 값이 0이라는 지시를 메모리 칩 외부(또는 메모리 뱅크의 어레이 중에 분산된 프로 세서 서브유닛을 포함하는 개시된 분산 프로세서 메모리 칩의 경우 등에서는 메모리 칩 내부)의 엔티티(예: 하 나 이상의 회로)로 전송할 수 있다. 0 값이 읽기 또는 쓰기 명령과 연관된 것으로 검출되지 않는 경우, 컨트롤 러는 0 값 지시자 대신에 데이터 값을 전송할 수 있다. 일부 실시예들에서, 0 값 지시자가 전송되는 하나 이상 의 회로는 메모리 유닛 내부에 있을 수 있다. 개시된 실시예들은 0 값 검출에 대하여 기재되었지만, 동일한 원리와 방식이 다른 메모리 값(예: 1 등)의 검출 에 적용될 수 있을 것이다. 일부 경우에서, 0 값 지시자 외에도, 검출 로직은 읽기 또는 쓰기 명령과 연관된 다 른 값(예: 1 등)의 하나 이상의 지시자를 전송할 수 있고, 이러한 지시자는 값 지시자에 상응하는 임의의 모든 값이 검출되는 경우에 전송될 수 있다. 일부 경우에서, 값은 사용자에 의해 조정(예: 하나 이상의 레지스터를 업데이트)될 수 있다. 이러한 업데이트는 데이터 세트에 관한 특성이 알려져 있을 수 있는 경우에 특히 유용할 수 있고, 특정 값이 다른 값들보다 데이터 내에 더 많이 있을 수 있다고 이해된다(예: 사용자의 측에서 이해). 이러한 경우, 하나, 둘, 셋, 또는 그 이상의 지시자가 데이터 세트와 연관된 가장 많은 데이터 값과 연관될 수 있다. DRAM 활성화 페널티에 대한 보상 특정 유형의 메모리(예: DRAM)에서, 메모리 셀은 메모리 뱅크 내의 어레이에 배치될 수 있고, 메모리 셀에 포함 된 값들은 한 번에 어레이 내 메모리 셀의 한 라인씩 접근되고 검색(읽기)될 수 있다. 이러한 읽기 프로세스는 우선 메모리 셀의 라인(또는 열)을 오픈(활성화)하여 메모리 셀에 의해 저장된 데이터 값이 사용 가능하게 만드 는 단계를 포함할 수 있다. 다음으로, 오픈된 라인의 메모리 셀 값들이 동시에 감지될 수 있고, 메모리 셀 값들 을 읽기 위하여 열 주소가 사용되어 개별 메모리 셀 값 또는 메모리 셀 값들의 그룹(즉, 워드)을 사이클하고 각 메모리 셀 값을 외부 데이터 버스로 연결할 수 있다. 이러한 프로세스는 시간이 걸린다. 일부 경우에서, 읽기 위한 메모리 라인을 오픈하는 데에 32 사이클의 연산 시간이 필요하고, 오픈된 라인에서 갑들을 읽는 데에 다시 32 사이클이 필요하다. 현재 오픈된 라인의 읽기 동작을 완료한 후에야 읽을 다음 라인을 오픈한다면 심각한 지연이 발생할 수 있다. 본 예에서, 다음 라인을 오픈하는 데에 필요한 32사이클 동안에, 아무 데이터도 읽히지 않으며, 각 라인을 읽는 데에 라인 데이터를 반복하는 데에 걸리는 32사이클이 아니라 결과적으로 총 64사이클 이 필요하게 된다. 기존의 메모리 시스템에서는 제1 라인에 읽기 또는 쓰기가 수행되는 동안에 동일 뱅크의 제2 라인을 오픈할 수 없다. 따라서, 지연을 줄이기 위하여, 오픈할 다음 라인은 하기에 더욱 상세히 설명하는 바와 같이 다른 뱅크에 있거나 듀얼 라인 접근을 위한 특별한 뱅크에 있을 수 있다. 현재 라인은 다음 라인을 오픈하 기 전에 모두 플립플롭 또는 래치로 샘플링 될 수 있고, 다음 라인이 오픈될 수 있는 반면에 모든 프로세싱이 플립플롭/래치 상에서 수행된다. 다음 예상 라인이 동일 뱅크에 있는(및 상기 내용이 하나도 존재하지 않는 경 우) 경우, 지연은 회피할 수 없을 수 있고, 시스템은 기다릴 필요가 있을 수 있다. 이러한 메커니즘은 표준 메 모리 및 특히 메모리 프로세싱 장치 모두에 해당한다. 여기에 개시된 실시예들은 오픈될 다음 메모리 라인을 현재 오픈되어 있는 메모리 라인의 읽기 동작이 완료되기 전에 예측하는 등을 통하여 이러한 지연을 줄일 수 있다. 즉, 오픈될 다음 라인이 예측될 수 있다면, 다음 라인 을 오픈하는 프로세스는 현재 라인의 읽기 동작이 완료되기 전에 시작할 수 있다. 프로세스의 어느 시점에 다음 라인 예측이 이루어지는가에 따라, 다음 라인의 오픈과 연관된 지연은 32 사이클(앞서 설명한 특정 예)에서 32 사이클 미만으로 감소될 수 있다. 일 특정 예에서, 다음 라인 오픈이 20 사이클 먼저 예측된다면, 추가적인 지 연은 12 사이클에 불과하게 된다. 다른 예에서, 다음 라인 오픈이 32 사이클 먼저 예측된다면, 지연은 아예 없 게 된다. 그 결과, 각 행을 직렬적으로 오픈하고 읽기 위하여 총 64 사이클이 필요한 대신에, 현재 행을 읽는 중에 다음 행을 오픈함으로써, 각 행을 읽는 시간이 결과적으로 줄어들 수 있다. 하기의 메커니즘은 현재 라인과 예측 라인이 동일 뱅크에 있어야 하지만, 라인 상에서 활성화와 작동을 동시에 지원할 수 있는 뱅크가 있다면 그러한 뱅크가 활용될 수도 있다. 예측 주소 생성기는 접근된 행을 관찰하고, 접근과 연관된 하나 이상의 패턴(예: 순차적 라인 접근, 모든 짝수 라인으로의 접근, 모든 3의 배수 라인으로의 접근 등)을 식별하고, 관찰된 패턴에 의거하여 접근될 다음 행을 추정하는 패턴 학습 모델을 포함할 수 있다. 다른 예에서, 예측 주소 생성기는 접근될 다음 행을 예측하기 위한 공식/알고리즘을 적용하는 유닛을 포함할 수 있다. 또 다른 실시예들에서, 예측 주소 생성기는 접근되는 현재 주소/행, 접근된 이전 2, 3, 4, 또는 그 이상의 주소/행 등과 같은 입력에 의거하여 접근될 예측 다음 행(예측 행과 연관된 하나 이상의 주소 포함)을 출력하는 학습 신경망을 포함할 수 있다. 임의의 모든 상기 예측 주소 생성기를 활용하여 접근될 다음 메모리 라인을 예측하면 메모리 접근과 연관된 지연을 상당히 감소시킬 수 있다. 기재된 예측 주소/행 생성기는 데이터를 검색하기 위한 메모리로의 접근이 이루어지는 임의의 모든 시스 템에 유용할 수 있다. 일부 경우에서, 기재된 예측 주소/행 생성기 및 다음 메모리 라인 접근을 예측하기 위한 연관 방법들은 인공지능 모델을 실행하는 시스템에 특히 적합할 수 있는데, 이는 AI 모델들은 다음 행 예측을 용이하게 하는 반복적 메모리 접근 패턴과 연관될 수 있기 때문이다. 도 81a는 본 개시의 실시예들에 따른 다음 행 예측에 의거하여 메모리 뱅크와 연관된 다음 행을 활성화하 는 시스템을 도시한 것이다. 시스템은 현재 및 예측 주소 생성기, 뱅크 컨트롤러, 및 메모리 뱅크(8180A, 8180B)를 포함할 수 있다. 주소 생성기는 메모리 뱅크(8180A, 8180B) 내의 접근을 위한 주소를 생 성하는 엔티티일 수 있고, 소프트웨어 프로그램을 실행하는 임의의 모든 논리 회로, 컨트롤러, 또는 마이크로프 로세서에 기반할 수 있다. 뱅크 컨트롤러는 메모리 뱅크(8180A)의 현재 행에 접근하도록(예: 주소 생성기 에 의해 생성된 현재 행 식별기를 활용) 구성될 수 있다. 뱅크 컨트롤러는 또한 주소 생성기(819 2)에 의해 생성된 예측 행 식별자에 의거하여 메모리 뱅크(8180B) 내에서 접근될 예측 다음 행을 활성화하도록 구성될 수 있다. 하기의 예는 2개의 뱅크를 설명한다. 다른 예에서는, 더 많은 뱅크가 사용될 수 있다. 일부 실 시예들에서, 한 번에 둘 이상의 행에 접근하는 것을 허용하는(하기에 설명) 메모리 뱅크가 있을 수 있으므로, 동일 프로세스가 단일 뱅크 상에서 수행될 수 있다. 앞서 설명한 바와 같이, 접근될 예측 다음 행의 활성화는 접근되는 현재 행에 대해 수행된 읽기 동작의 완료 이전에 시작할 수 있다. 따라서, 일부 경우에서, 주소 생성 기는 접근할 다음 행을 예측할 수 있고 예측된 다음 행의 식별자(예: 하나 이상의 주소)를 현재 행으로의 접근이 완료되기 이전 아무 때나 컨트롤러로 보낼 수 있다. 이러한 타이밍으로 인해, 뱅크 컨트롤러는 예 측된 다음 행의 활성화를 현재 행이 접근되는 동안 및 현재 행의 접근이 완료되기 이전의 임의의 시점에 개시할 수 있다. 일부 경우에서, 뱅크 컨트롤러는 접근된 현재 행의 활성화가 완료되는 시점 및/또는 현재 행에 대한 읽기 동작이 시작된 시점의 동일 시간(또는 몇 클럭 사이클 이내)에 메모리 뱅크의 예측된 다음 행 의 활성화를 개시할 수 있다. 일부 실시예들에서, 현재 주소와 연관된 현재 행에 대한 동작은 읽기 또는 쓰기 동작일 수 있다. 일부 실시예들 에서, 현재 행과 다음 행은 동일한 메모리 뱅크 내에 있을 수 있다. 일부 실시예들에서, 동일한 메모리 뱅크는현재 행이 접근되는 동안에 다음 행이 접근되게 할 수 있다. 현재 행과 다음 행은 상이한 메모리 뱅크에 있을 수 있다. 일부 실시예들에서, 메모리 유닛은 현재 주소와 예측 주소를 생성하도록 구성된 프로세서를 포함할 수 있다. 일부 실시예들에서, 메모리 유닛은 분산 프로세서를 포함할 수 있다. 분산 프로세서는 메모리 어레이의 복수의 이산 메모리 뱅크 중에 공간적으로 분산된 프로세싱 어레이의 복수의 프로세서 서브유닛을 포함할 수 있 다. 일부 실시예들에서, 예측 주소는 지연 생성되는 주소를 샘플링 하는 일련의 플립플롭에 의해 생성될 수 있 다. 지연은 샘플링 된 주소를 저장하는 플립플롭 간의 선택을 하는 멀티플렉서를 통해 설정될 수 있다. 여기서, 예측된 다음 행이 실행 소프트웨어가 접근 요청을 하는 실제 다음 행이라는 것이 확인되면(예: 현재 행 에 대한 읽기 동작의 완료 후) 예측된 다음 행은 접근될 현재 행이 될 수 있다. 개시된 실시예들에서, 예측된 다음 행을 활성화하는 프로세스는 현재 행 읽기 동작의 완료 전에 개시될 수 있기 때문에, 예측된 다음 행이 접 근할 다음 행이 맞다는 것이 확인되면, 접근할 다음 행은 이미 완전히 또는 부분적으로 활성화될 수 있다. 이로 써, 라인 활성화와 연관된 지연을 상당히 감소시킬 수 있다. 현재 행의 읽기가 끝나기 전에 또는 끝남과 동시에 활성화가 끝나도록 다음 행이 활성화되는 경우에 전력 감소가 이루어질 수 있다. 현재 및 예측 주소 생성기는 메모리 뱅크 내의 접근될 행을 식별(예: 프로그램 실행에 의거)하고 접근될 다음 행을 예측(예: 행 접근에서 관찰된 패턴에 의거, 소정의 패턴(n+1, n+2)에 의거 등)하도록 구성된 임의의 모든 논리 요소, 연산부, 메모리 유닛, 알고리즘, 학습 모델 등을 포함할 수 있다. 예컨대, 일부 실시예 들에서, 현재 및 예측 주소 생성기는 카운터(8192A), 현재 주소 생성기(8192B), 및 예측 주소 생성기 (8192C)를 포함할 수 있다. 현재 주소 생성기(8192B)는 예컨대 카운터(8192A)의 출력에 의거하거나 연산부로부 터의 요청에 의거하여 메모리 뱅크 내에서 접근될 현재 행의 현재 주소를 생성하도록 구성될 수 있다. 접 근될 현재 행과 연관된 주소는 뱅크 컨트롤러로 제공될 수 있다. 예측 주소 생성기(8192C)는 카운터 (8192A)의 출력에 의거하거나, 소정의 접근 패턴에 의거하거나(예: 카운터(8192A)와 함께), 학습 신경망 또는 관찰된 라인 접근과 연관된 패턴 등에 의거하여 라인 접근을 관찰하고 접근될 다음 라인을 예측하는 기타 유형 의 패턴 예측 알고리즘의 출력에 의거하여, 메모리 뱅크 내에서 접근될 다음 행의 예측 주소를 판단하도 록 구성될 수 있다. 주소 생성기는 예측 주소 생성기(8192C)로부터의 예측된 다음 행 주소를 뱅크 컨트롤 러로 제공할 수 있다. 일부 실시예들에서, 현재 주소 생성기(8192B)와 예측 주소 생성기(8192C)는 시스템의 내부 또는 외부에 구현될 수 있다. 외부 호스트도 시스템의 외부에 구현되고 시스템으로 더 연결될 수 있다. 예를 들 어, 현재 주소 생성기(8192B)는 프로그램을 실행하는 외부 호스트에 있는 소프트웨어일 수 있고, 예측 주소 생 성기(8192C)는 시스템의 내부 또는 외부에 구현될 수 있다. 앞서 설명한 바와 같이, 예측된 다음 행 주소는 이전에 접근된 하나 이상의 행 주소를 포함할 수 있는 입력 (들)에 의거하여 접근할 다음 행을 예측하는 학습 신경망을 활용하여 판단될 수 있다. 학습 신경망 또는 기타 유형의 모델은 예측 주소 생성기(8192C)와 연관된 로직 내에서 작동할 수 있다. 일부 경우에서, 학습 신경망 등 은 예측 주소 생성기(8192C)의 외부에 있지만 예측 주소 생성기(8192C)와 통신하는 하나 이상의 연산부에 의해 실행될 수 있다. 일부 실시예들에서, 예측 주소 생성기(8192C)는 현재 주소 생성기(8192B)의 복제 또는 실질적 복제를 포함할 수 있다. 또한, 현재 주소 생성기(8192B)와 예측 주소 생성기(8192C) 동작 타이밍은 서로에 대해 고정되거나 조정 될 수 있다. 예를 들어, 일부 경우에서, 예측 주소 생성기(8192C)는 접근될 다음 행과 연관된 주소 식별자를 현 재 주소 생성기(8192B)가 생성하는 시점에 대하여 고정된 시간(예: 고정된 수의 클럭 사이클)에 예측된 다음 행 과 연관된 주소 식별자를 출력하도록 구성될 수 있다. 일부 경우에서, 예측된 다음 행 식별자는 접근될 현재 행 의 활성화가 시작되기 전 또는 후, 접근될 현재 행과 연관된 읽기 동작이 시작되기 전 또는 후, 또는 접근되는 현재 행과 연관된 읽기 동작이 완료되기 전의 임의의 시간에 생성될 수 있다. 일부 경우에서, 예측된 다음 행 식별자는 접근될 현재 행의 활성화의 시작과 동시에 또는 접근될 현재 행과 연관된 읽기 동작의 시작과 동시에 생성될 수 있다. 다른 경우에서, 예측된 다음 행 식별자의 생성과 접근될 현재 행의 활성화 또는 현재 행과 연관된 읽기 동작의 개시 사이의 시간은 조정 가능할 수 있다. 예를 들면, 일부 경우에서, 이 시간은 하나 이상의 동작 파라미터와 연관된 값에 의거하여 메모리 유닛의 동작 동안에 연장 또는 단축될 수 있다. 일부 경우에서, 메모리 유 닛 또는 컴퓨팅 시스템의 다른 컴포넌트와 연관된 온도(또는 기타 파라미터 값)는 현재 주소 생성기(8192B)와 예측 주소 생성기(8192C)가 상대적인 동작 시기를 변경하도록 유발할 수 있다. 일부 실시예들에서, 예측 메커니 즘은 논리의 일부일 수 있다. 현재 및 예측 주소 생성기는 접근할 예측된 다음 행 판단과 연관된 신뢰 수준을 생성할 수 있다. 이러한 신뢰 수준(예측 프로세스의 일환으로 예측 주소 생성기(8192C)에 의해 판단될 수 있음)는 현재 행의 읽기 동작 동안에(즉, 현재 행 읽기 동작이 완료되기 이전 및 접근할 다음 행의 식별이 확인되기 이전에) 예측된 다음 행 의 활성화를 개시할지 여부 등을 판단하는데 활용될 수 있다. 예를 들어, 일부 경우에서, 접근할 예측된 다음 행과 연관된 신뢰 수준은 임계 수준과 비교될 수 있다. 예컨대, 신뢰 수준이 임계 수준에 미달하는 경우, 메모 리 유닛은 예측된 다음 행의 활성화를 포기할 수 있다. 반면에, 신뢰 수준이 임계 수준을 초과하는 경우, 메모리 유닛은 메모리 뱅크 내에서 예측된 다음 행의 활성화를 개시할 수 있다. 예측된 다음 행의 임계 수준 대비 신뢰 수준의 검사와 그 이후의 예측된 다음 행의 활성화의 개시 또는 비개시 는 임의의 모든 적합한 방식으로 이루어질 수 있다. 예를 들어, 일부 경우에서, 예측된 다음 행과 연관된 신뢰 수준이 임계 수준에 미달하는 경우, 예측 주소 생성기(8192C)는 예측된 다음 행 결과를 이후의 논리 요소로 출 력하는 것을 포기할 수 있다. 이러한 경우에, 대안적으로, 현재 및 예측 주소 생성기는 예측된 다음 행 식별자를 뱅크 컨트롤러로부터 보류할 수 있거나, 뱅크 컨트롤러(또는 다른 논리부)는 읽어지는 현재 행 과 연관된 읽기 동작이 완료되기 전에 예측된 다음 행의 활성화를 시작할지 여부를 판단하기 위해 예측된 다음 행에서 신뢰 수준을 활용하도록 구성될 수 있다. 예를 들어, 일부 경우에서, 신뢰 수준은 하나 이상의 이전 다음 행 예측이 정확했던 것으로 판명됐는지(예: 과 거 성능 지시자) 여부에 달려있을 수 있다. 신뢰 수준은 또한 알고리즘/모델로의 입력의 하나 이상의 특성에 의 거할 수 있다. 예컨대, 패턴을 따르는 실제 행 접근을 포함하는 입력은 패턴을 덜 따르는 실제 행 접근보다 신 뢰 수준이 높을 수 있다. 또한, 최근 행 접근을 포함하는 입력의 스트림에 대해 무작위성이 검출되는 등의 일부 경우에서, 생성된 신뢰 수준은 낮을 수 있다. 또한, 무작위성이 검출되는 경우에서, 다음 행 예측 프로세스는 일괄 중단되거나, 다음 행 예측이 메모리 유닛의 하나 이상의 컴포넌트에 의해 무시되거나, 예측된 다음 행의 활성화를 포기하기 위한 임의의 모든 다른 동작이 취해질 수 있다. 일부 경우에서, 메모리의 동작에 대하여 피드백 메커니즘이 포함될 수 있다. 예를 들어, 주기적으로 또는 각 다음 행 예측 이후에도, 예측 주소 생성기(8192C)가 접근될 실제 다음 행을 예측하는 정확성이 판단될 수 있 다. 일부 경우에서, 접근할 다음 행의 예측에 오류가 있는 경우(또는 소정의 수의 오류 이후에), 예측 주소 생 성기(8192C)의 다음 행 예측 동작은 정지될 수 있다. 다른 경우에서, 예측 주소 생성기(8192C)는 예측 동작의 하나 이상의 양상이 접근할 다음 행 예측의 정확성에 관해 수신된 피드백에 의거하여 조정될 수 있도록 학습 요 소를 포함할 수 있다. 이러한 능력은 예측 주소 생성기(8192C)의 동작을 개선하여 예측 주소 생성기(8192C)가 변화하는 접근 패턴 등에 적응할 수 있도록 할 수 있다. 일부 실시예들에서, 예측된 다음 행의 생성 및/또는 예측된 다음 행의 활성화의 시기는 메모리 유닛의 전 반적인 동작에 달려있을 수 있다. 예를 들면, 전원을 켠 후 또는 메모리 유닛을 리셋한 후에, 접근할 다 음 행의 예측(또는 예측된 다음 행을 뱅크 컨트롤러로 송부)은 정지될 수 있다(예: 소정의 시간 또는 클 럭 사이클 동안, 소정의 수의 행 접근/읽기가 완료될 때까지, 예측된 다음 행의 신뢰 수준이 소정의 임계 수준 을 초과할 때까지, 또는 임의의 모든 다른 적절한 조건에 의거하여). 도 81b는 개시된 실시예에 따른 메모리 유닛의 다른 구성을 도시한 것이다. 도 81b의 시스템(8100B)에서, 캐시는 뱅크 컨트롤러와 연관될 수 있다. 캐시는, 예컨대, 하나 이상의 행의 데이터가 접근 된 후에 저장되고 다시 활성화할 필요가 없게 하도록 구성될 수 있다. 따라서, 캐시는 뱅크 컨트롤러 가 메모리 뱅크에 접근하는 대신에 캐시로부터 행 데이터에 접근하게 할 수 있다. 예를 들면, 캐시는 마지막 X 행 데이터(또는 임의의 모든 다른 캐시 저장 전략)을 저장할 수 있고, 뱅크 컨트 롤러는 예측된 행에 따라 캐시를 채울 수 있다. 또한, 예측된 행이 이미 캐시에 있는 경우, 예측된 행은 다시 열릴 필요가 없고, 뱅크 컨트롤러(또는 캐시 내에 구현된 캐시 컨트롤러)는 예측된 행 이 스와핑 되는 것으로부터 보호할 수 있다. 캐시는 여러 이점을 제공할 수 있다. 첫째, 캐시는 행 을 캐시에 로딩하고 뱅크 컨트롤러는 캐시에 접근하여 행 데이터를 가져올 수 있으므로, 다음 행 예측을 위한 특별한 뱅크나 하나 이상의 뱅크가 필요하지 않다. 둘째, 뱅크 컨트롤러로부터 캐시까 지의 물리적 거리는 뱅크 컨트롤러로부터 메모리 뱅크까지의 물리적 거리보다 짧으므로 캐시(819 3)로부터의 읽기와 쓰기는 에너지를 절약할 수 있다. 셋째, 캐시는 더 작고 컨트롤러에 더 가까이 있으므로 캐시에 의해 야기된 지연은 메모리 뱅크의 지연보다 낮다. 일부 경우에서, 예컨대, 예측 주소 생성기에 의해 생성된 예측된 다음 행의 식별자는 예측된 다음 행이 뱅크 컨트롤러에 의해 메모리 뱅크 내에서 활성화됨에 따라 캐시에 저장될 수 있다. 프로그램 실행 등에 의거하여, 현재 주소 생 성기(8192B)는 메모리 뱅크 내의 접근할 실제 다음 행을 식별할 수 있다. 접근할 실제 다음 행과 연관된식별자는 캐시에 저장된 예측된 다음 행의 식별자와 비교될 수 있다. 접근할 실제 다음 행과 접근할 예측 된 다음 행이 동일한 경우, 뱅크 컨트롤러는 접근할 다음 행의 활성화가 완료된 후에 이 행에 대한 읽기 동작을 개시할 수 있다(다음 행 예측 프로세스의 결과로 완전히 또는 부분적으로 활성화될 수 있음). 반면에, 접근할 실제 다음 행(현재 주소 생성기(8192B)에 의해 판단)이 캐시에 저장된 예측된 다음 행 식별자와 일치하지 않는 경우, 완전히 또는 부분적으로 활성화된 예측된 다음 행에 대하여 읽기 동작이 개시되지 않게 되 고, 시스템은 접근될 실제 다음 행의 활성화를 시작하게 된다. 듀얼 활성화 뱅크 앞서 설명한 바와 같이, 다른 행들이 처리되는 동안에 한 행을 활성화할 능력이 있는 뱅크를 구축하도록 하는 여러 메커니즘을 설명할 가치가 있다. 다른 행이 접근되는 동안에 추가적이 행을 활성화시키는 뱅크에 대해 여 러 실시예들이 제공될 수 있다. 실시예들에서 2개 행만 활성화되는 것으로 설명하고 있지만, 더 많은 행에도 적 용될 수 있음은 당연하다 할 것이다. 제안된 제1 실시예에서, 메모리 뱅크는 메모리 서브뱅크로 분할될 수 있고, 기재된 실시예들은 한 서브뱅크에서 라인에 대한 읽기 동작을 수행하는 동안에 다른 서브뱅크에서 예측되 거나 필요한 다음 행의 활성화에 활용될 수 있다. 예를 들어, 도 81c에 도시된 바와 같이, 메모리 뱅크는 다중 메모리 서브뱅크를 포함하도록 구성될 수 있다. 메모리 뱅크와 연관된 뱅크 컨트롤러는 복수의 서브뱅크 컨트롤러를 상응하는 서브뱅크와 연관되어 포함할 수 있다. 복수의 서브뱅크 컨트롤러의 제1 서브뱅크 컨트롤러는 복수의 서브뱅크 컨트롤러의 제2 서브뱅크 컨트롤러가 복수의 서브뱅크의 제2 서브뱅크의 다음 행을 활성화할 수 있는 동안에 복수의 서브뱅크의 제1 서브뱅크의 현재 행에 포함된 데이터로의 접근을 가 능하게 하도록 구성될 수 있다. 한 번에 한 서브뱅크의 워드만에 접근하는 경우에 하나의 컬럼 디코더만이 사용 될 수 있다. 2개의 뱅크가 동일한 출력 버스에 묶여 단일 뱅크로 보일 수 있다. 단일 뱅크 입력도 단일 주소 및 새로운 행을 열기 위한 추가 행 주소일 수 있다. 도 81c는 각 메모리 서브뱅크별 제1 및 제2 서브뱅크 행 컨트롤러(8183A, 8183B)를 도시한 것이다. 도 81c에 도시된 바와 같이, 메모리 뱅크는 복수의 서브뱅크를 포함할 수 있다. 또한, 뱅크 컨트롤러 는 상응하는 서브뱅크와 각각 연관된 복수의 서브뱅크 컨트롤러(8183A-B)를 포함할 수 있다. 복수 의 서브뱅크 컨트롤러의 제1 서브뱅크 컨트롤러(8183A)는 제2 서브뱅크 컨트롤러(8183B)가 서브뱅크의 제 2 부분의 다음 행을 활성화할 수 있는 동안에 서브뱅크의 제1 부분의 현재 행에 포함된 데이터로의 접근 을 가능하게 하도록 구성될 수 있다. 접근되고 있는 행에 바로 인접한 행의 활성화는 접근된 행을 왜곡하고/왜곡하거나 접근된 행으로부터 읽히는 데 이터에 오류를 일으킬 수 있기 때문에, 개시된 실시예들은 활성화될 것으로 예측되는 다음 행이 데이터가 접근 되고 있는 제1 서브뱅크의 현재 행으로부터 예를 들어 적어도 2행만큼 이격되게 하도록 구성될 수 있다. 일부 실시예들에서, 활성화될 행들은 적어도 한 매트만큼 이격될 수 있어서 활성화가 서로 상이한 매트들에서 실행될 수 있다. 제2 서브뱅크 컨트롤러는 제1 서브뱅크 컨트롤러가 제1 서브뱅크의 다음 행을 활성화하는 동안에 제2 서브뱅크의 현재 행에 포함된 데이터로의 접근을 유발하도록 구성될 수 있다. 제1 서브뱅크의 활성화된 다음 행 은 데이터가 접근되고 있는 제2 서브뱅크의 현재 행으로부터 적어도 2행만큼 이격될 수 있다. 읽기/접근되고 있는 행들과 활성화되고 있는 행들 사이의 소정의 거리는 하드웨어에 의해 결정될 수 있다. 예를 들어, 메모리 뱅크의 상이한 부분들을 상이한 로우 디코더들에 결합하고, 소프트웨어가 데이터를 손상시키지 않 기 위하여 유지할 수 있다. 현재 행 사이의 간격은 2 이상(예: 3, 4, 5, 또는 그 이상)일 수 있다. 거리는 시간 이 경과하면서, 예를 들어, 저장된 데이터에 일어난 왜곡에 대한 평가에 근거하여, 변경될 수 있다. 왜곡은 다 양한 방식으로 평가될 수 있다. 예를 들어, 신호 대 잡음비, 오류율, 왜곡을 보수하는데 필요한 오류 코드 등을 산출하여 평가될 수 있다. 두 행은 충분히 멀리 떨어져 있고 동일 뱅크 상에서 2개의 뱅크 컨트롤러가 구현되는 경우에 실제로 활성화될 수 있다. 새로운 아키텍처(동일 뱅크 상에 2개의 컨트롤러를 구현)는 동일 매트 내에서 라인이 개방되는 것을 방지할 수 있다. 도 81d는 본 개시의 실시예들에 따른 다음 행 예측을 위한 일 실시예를 도시한 것이다. 본 실시예는 플립플롭의 추가적인 파이프라인(주소 레지스터 A 내지 C)을 포함할 수 있다. 주소 생성기 이후의 활성화 및 지연된 주소와 예측을 활용하기 위해 전체 실행을 지연하는데 필요한 지연은 생성된 새로운 주소(파이프의 시작, 주소 레지스 터 C 아래)가 될 수 있고 현재 주소는 파이프라인의 끝이 됨에 따라, 파이프라인은 임의의 모든 수의 플립플롭 (스테이지)으로 구현될 수 있다. 본 실시예에서, 복제 주소 생성기는 필요하지 않다. 주소 레지스터가 지연을 제공하는 동안에 지연을 구성하도록 셀렉터(도 81d의 멀티플렉서)가 추가될 수 있다. 도 81e는 본 개시의 실시예들에 따른 메모리 뱅크에 대한 일 실시예를 도시한 것이다. 메모리 뱅크는 새로 활성 화된 라인이 현재 라인으로부터 충분히 멀리 떨어져 있는 경우에 새로운 라인의 활성화가 현재 라인에 손상을 입히지 않도록 구현될 수 있다. 도 82e에 도시된 바와 같이, 메모리 뱅크는 2 라인의 매트 사이마다 추가 메모 리 매트(검정색)를 포함할 수 있다. 따라서, 제어부(예: 로우 디코더)는 매트에 의해 이격된 라인들을 활성화할 수 있다. 일부 실시예들에서, 메모리 유닛은 프로세싱을 위한 제1 주소와 소정의 시간에 활성화 및 접근을 하기 위한 제2 주소를 수신하도록 구성될 수 있다. 도 81f는 본 개시의 실시예들에 따른 메모리 뱅크에 대한 다른 실시예를 도시한 것이다. 메모리 뱅크는 새로 활 성화된 라인이 현재 라인으로부터 충분히 멀리 떨어져 있는 경우에 새로운 라인의 활성화가 현재 라인에 손상을 입히지 않도록 구현될 수 있다. 도 81f에 도시된 실시예는 모든 짝수 라인은 메모리 뱅크의 상반부에 구현되고 모든 홀수 라인은 메모리 뱅크의 하반부에 구현되도록 함으로써 로우 디코더가 라인 n과 라인 n+1을 열 수 있도 록 할 수 있다. 이러한 구현으로 항상 충분히 멀리 떨어진 연속적인 라인에 접근하는 것이 가능할 수 있다. 개시된 실시예들에 따른 듀얼 컨트롤 메모리 뱅크는, 듀얼 컨트롤 메모리 뱅크가 한 번에 하나의 데이터 단위만 을 출력하도록 구성된 경우에도, 단일 메모리 뱅크의 상이한 부분들의 접근 및 활성화를 가능하게 할 수 있다. 예를 들면, 설명한 바와 같이, 듀얼 컨트롤은 메모리 뱅크가 제2 행(예: 예측된 다음 행 또는 접근할 소정의 다 음 행)을 활성화하는 동안에 제1 행에 접근하는 것이 가능하게 할 수 있다. 도 82는 본 개시의 실시예들에 따른 메모리 행 활성화 페널티(예: 지연)를 감소시키기 위한 듀얼 컨트롤 메모리 뱅크를 도시한 것이다. 듀얼 컨트롤 메모리 뱅크는 데이터 입력(DIN), 행 주소(ROW), 열 주소(COLUMN), 제1 명령 입력(COMMAND_1), 및 제2 명령 입력(COMMAND_2)을 포함하는 입 력들을 포함할 수 있다. 메모리 뱅크는 데이터 출력(Dout)을 포함할 수 있다. 주소에는 행 주소와 열 주소가 있고 2개의 로우 디코더가 있는 것으로 추정한다. 주소의 다른 구성도 가능하고, 로우 디코더의 수는 2개보다 많을 수 있고, 단일 컬럼 디코더보다 많은 컬럼 디코더가 있을 수 있다. 행 주소(ROW)는 활성 명령과 같은 명령과 연관된 행을 식별할 수 있다. 행 활성화 후에는 행의 읽기 또는 행에 쓰기를 수반하므로, 행이 열려 있는 동안에(활성화 이후) 쓰기를 하거나 열린 행으로부터 읽기를 할 행 주 소를 전송할 필요가 없을 수 있다. 제1 명령 입력(COMMAND_1)은 제1 로우 디코더에 의해 접근된 행으로 명령(활성 명령 등)을 전송하는 데에 사용될 수 있다. 제2 명령 입력(COMMAND_2)은 제2 로우 디코더에 의해 접근된 행으로 명령(활성 명령 등)을 전송하는 데에 사용될 수 있다. 데이터 입력(DIN)은 쓰기 동작을 실행하는 경우에 데이터를 공급하는 데에 사용될 수 있다. 행 전체가 한꺼번에 읽히지 않을 수 있으므로, 단일 행 세그먼트들은 순차적으로 읽힐 수 있고, 열 주소 (COLUMN)는 행의 읽힐 세그먼트(즉, 어느 열)를 나타낼 수 있다. 설명의 편의상, 2Q의 세그먼트가 있고, 열 입력에는 Q 비트가 있고, Q는 1을 초과하는 양의 정수인 것으로 추정한다. 듀얼 컨트롤 메모리 뱅크는 앞서 도 81a 내지 도 81b를 참조하여 설명한 주소 예측과 함께 또는 별도로 작동할 수 있다. 물론, 동작의 지연을 줄이기 위하여, 듀얼 컨트롤 메모리 뱅크는 본 개시에 따른 주소 예측과 함께 동작할 수 있다. 도 83a, 도 83b, 및 도 83c는 메모리 뱅크의 행에 접근 및 활성화하는 예시들을 도시한 것이다. 일례에서, 앞서 언급한 바와 같이, 한 행의 읽기와 활성화에는 32 사이클(세그먼트)이 필요한 것으로 추정한다. 또한, 활성화 페널티(델타로 표시한 길이)를 줄이기 위해, 다음 행이 열려야 하는지를 미리(다음 행에 접근할 필요가 있기 적어도 델타 전에) 아는 것이 유리할 수 있다. 일부 경우에서, 델타는 4 사이클일 수 있다. 도 83a, 도 83b, 및 도 83c에 도시된 각 메모리 뱅크는 일부 실시예에서 한 번에 하나의 행만이 열릴 수 있는 둘 이상의 서브뱅크를 포함할 수 있다. 일부 경우에서, 짝수의 행들은 제1 서브뱅크와 연관될 수 있고, 홀수의 행 들은 제2 서브뱅크와 연관될 수 있다. 이러한 예에서, 개시된 예측 주소 실시예를 활용하면 다른 메모리 서브뱅 크의 행에 대한 읽기 동작의 끝에 도달하기 전에(델타 주기 이전에) 특정 메모리 서브뱅크의 한 행의 활성화 개 시가 가능할 수 있다. 이로써, 순차적 메모리 접근(예: 행 1, 2, 3, 4, 5, 6, 7, 8 ...의 읽기가 수행되어야 하 고, 행 1, 3, 5 등은 제1 메모리 서브뱅크와 연관되고, 행 2, 4, 6 등은 이와 상이한 제2 메모리 서브뱅크와 연 관되는 소정의 메모리 접근 시퀀스)이 매우 효율적인 방식으로 수행될 수 있다. 도 83a는 상이한 메모리 서브뱅크에 포함된 메모리 행에 접근하기 위한 상태를 도시하는 것일 수 있다. 도 83a 에 도시된 상태에서: a.행 A는 제1 로우 디코더에 의해 접근 가능할 수 있다. 제1 세그먼트(가장 좌측의 음영 처리된 세그먼트)는 제 1 로우 디코더가 행 A를 활성화한 이후에 접근될 수 있다. b.행 B는 제2 로우 디코더에 의해 접근 가능할 수 있다. 도 83a에 도시된 상태에서, 행 B는 닫혀 있고 아직 활 성화되지 않았다. 도 83a에 도시된 상태에 앞서 활성화 명령과 행 A의 주소가 제1 로우 디코더로 전송될 수 있다. 도 83b는 행 A에 접근한 이후에 행 B에 접근하기 위한 상태를 도시한 것이다. 본 예에 따르면, 행 A는 제1 로우 디코더에 의해 접근 가능할 수 있다. 도 83b에 도시된 상태에서, 제1 로우 디코더는 행 A를 활성화하였고 가장 우측의 4개의 세그먼트들(음영 처리되지 않은 4개의 세그먼트들)만을 제외하고 모든 세그먼트들에 접근하였다. 델타(행 A에 있는 4개의 흰색 세그먼트들)는 4 사이클이므로, 뱅크 컨트롤러는 제2 로우 디코더가 행 A의 가장 우측의 세그먼트들에 접근하기 전에 행 B를 활성화하도록 할 수 있다. 일부 경우에서, 소정의 접근 패턴(예: 홀 수 행은 제1 서브뱅크에 지정되고 짝수 행은 제2 서브뱅크에 지정되는 순차적 행 접근)에 대응하여 행 B가 활성 화될 수 있다. 다른 경우에서, 앞서 설명한 임의의 모든 행 예측 방법에 대응하여 행 B가 활성화될 수 있다. 행 B가 접근되는 경우에 행 B를 열기 위해 행 B가 활성화될 때까지 기다리는 대신에 행 B가 이미 활성화되어(열려) 있도록, 뱅크 컨트롤러는 제2 로우 디코더가 행 B를 활성화하도록 할 수 있다. 도 83b에 도시된 상태에 앞서 다음과 같은 동작이 일어날 수 있다. a. 제1 로우 디코더에 활성화 명령과 행 A의 주소를 전송 b. 행 A의 첫 28 세그먼트를 읽기 또는 쓰기 c. 행의 28 세그먼트의 읽기 또는 쓰기 동작 후에, 행 B의 주소에 대한 활성화 명령을 제2 로우 디코더로 전송 일부 실시예들에서, 짝수 행들은 하나 이상의 메모리 뱅크의 절반에 위치한다. 일부 실시예들에서, 홀수 행들은 하나 이상의 메모리 뱅크의 절반에 위치한다. 일부 실시예들에서, 한 라인의 가외 중복 매트가 각각의 두 매트 라인 사이에 배치되어 활성화를 허용하기 위한 거리를 형성할 수 있다. 일부 실시예들에서, 서로 근접한 라인들은 동시에 활성화되지 않을 수 있다. 도 83c는 행 A에 접근한 후에 행 C(예: 제1 서브뱅크에 포함된 다음 홀수 행)에 접근하기 위한 상태를 도시한 것일 수 있다. 도 83c에 도시된 바와 같이, 행 B는 제2 로우 디코더에 의해 접근 가능할 수 있다. 도시된 바와 같이, 제2 로우 디코더는 행 B를 활성화하였고 가장 우측의 4개의 세그먼트들(음영 처리되지 않은 4개의 세그먼 트들)만을 제외하고 모든 세그먼트들에 접근하였다. 본 예에서, 델타는 4 사이클이므로, 뱅크 컨트롤러는 제1 로우 디코더가 행 B의 가장 우측의 세그먼트들에 접근하기 전에 행 C를 활성화하도록 할 수 있다. 행 C가 접근 되는 경우에 행 C를 열기 위해 행 C가 활성화될 때까지 기다리는 대신에 행 C가 이미 활성화되어(열려) 있도록, 뱅크 컨트롤러는 제1 로우 디코더가 행 C를 활성화하도록 할 수 있다. 이 방식으로 동작함으로써, 메모리 읽기 동작과 연관된 지연을 감소시키거나 완전히 제거할 수 있다. 레지스터 파일로서의 메모리 매트 컴퓨터 아키텍처에서, 프로세서 레지스터는 컴퓨터의 프로세서(예: CPU)로 빠르게 접근 가능하게 하는 저장소 위치를 구성한다. 레지스터는 일반적으로 프로세서 코어(L0)에 가장 가까운 메모리 유닛을 포함한다. 레지스터 는 특정 유형의 데이터에 접근하는 가장 빠른 방법을 제공할 수 있다. 컴퓨터는 여러 유형의 레지스터를 포함할 수 있고, 각 유형의 레지스터는 저장하는 정보의 유형에 따라 또는 특정 유형의 레지스터의 정보 상에서 운영되 는 명령의 유형에 의거하여 구분될 수 있다. 예를 들면, 컴퓨터는 수치 정보, 피연산자, 중간 결과, 및 설정을 보유하는 데이터 레지스터, 주 메모리에 접근하기 위해 명령에 의해 사용되는 주소 정보를 저장하는 주소 레지 스터, 데이터와 주소 정보를 모두 저장하는 범용 레지스터, 상태 레지스터 등을 포함할 수 있다. 레지스터 파일 은 컴퓨터 처리부에 의해 사용되기 위한 레지스터의 논리 그룹을 포함한다. 많은 경우에서, 컴퓨터의 레지스터 파일은 처리부(예: CPU) 내에 위치하고 논리 트랜지스터에 의해 구현된다. 그러나 개시된 실시예들에서, 연산 처리부는 기존의 CPU에 있지 않을 수 있다. 대신, 이러한 처리 요소들(예: 프로세서 서브유닛)은 메모리 칩 내에 프로세싱 어레이로 공간적으로 분산되어 있을 수 있다(상기 설명 참조). 각 프로세서 서브유닛은 하나 이상의 상응하는 전용 메모리 유닛(예: 메모리 뱅크)와 연관될 수 있다. 이러한 아키텍처를 통해, 각 프로세서 서브유닛은 특정 프로세서 서브유닛이 운영할 데이터를 저장하는 하나 이상의 메모리 요소에 공간적으로 근접하여 위치할 수 있다. 본 개시에서 설명하는 바와 같이, 이러한 아키텍처는 전형적 인 CPU 및 외부 메모리 아키텍처가 겪는 메모리 접근 병목을 제거하는 등을 통해 특정 메모리 집약적 동작의 속 도를 상당히 증가시킬 수 있다. 그러나 여기에 기재된 분산 프로세서 메모리 칩 아키텍처는 상응하는 프로세서 서브유닛 전용의 메모리 요소로 부터 데이터를 운영하는 다양한 유형의 레지스터를 포함하는 레지스터 파일의 이점을 여전히 활용할 수 있다. 그러나 프로세서 서브유닛은 메모리 칩의 메모리 요소들 중에서 분산될 수 있으므로, 주 메모리 저장소 역할을 하기보다는 상응하는 프로세서 서브유닛에 대한 레지스터 파일 또는 캐시로 기능하기 위하여, 상응하는 프로세 서 서브유닛에 하나 이상의 메모리 요소를 추가하는 것이 가능할 수 있다(이는 특정 제조 프로세스의 논리 요소 에 비하여 특정 프로세스로부터의 이점이 될 수 있음). 이러한 아키텍처는 몇 가지 이점을 제공할 수 있다. 예컨대, 레지스터 파일은 상응하는 프로세서 서브유닛의 일 부이므로, 프로세서 서브유닛은 관련 레지스터 파일에 공간적으로 가까이 위치할 수 있다. 이러한 배치는 동작 효율을 상당히 증가시킬 수 있다. 기존의 레지스터 파일은 논리 트랜지스터에 의해 구현된다. 예를 들어, 종래 레지스터 파일의 각 비트는 약 12개의 논리 트랜지스터로 구성되므로, 16비트의 레지스터 파일은 192개의 논리 트랜지스터로 구성된다. 이러한 레지스터 파일은 논리 트랜지스터에 접근하려면 많은 수의 논리 컴포넌트를 필 요로 할 수 있고, 따라서 공간을 많이 차지할 수 있다. 논리 트랜지스터에 의해 구현된 레지스터 파일에 비해, 본 개시의 실시예들의 레지스터 파일은 공간을 상당히 덜 필요로 한다. 이러한 사이즈 감소는 논리 구조의 제조 보다는 메모리 구조의 제조에 최적화된 프로세스에 의해 제조된 메모리 셀을 포함하는 메모리 매트를 활용한 본 개시의 실시예들의 레지스터 파일을 구현하여 실현될 수 있다. 일부 실시예들에서, 분산 프로세서 메모리 칩이 제공될 수 있다. 분산 프로세서 메모리 칩은 기판, 기판 상에 배치되고 복수의 이산 메모리 뱅크를 포함하는 메모리 어레이, 및 기판 상에 배치되고 복수의 프로세서 서브유 닛을 포함하는 프로세싱 어레이를 포함할 수 있다. 각 프로세서 서브유닛은 복수의 이산 메모리 뱅크 중에서 상 응하는 전용 이산 메모리 뱅크와 연관될 수 있다. 분산 프로세서 메모리 칩은 또한 제1 복수의 버스와 제2 복수 의 버스를 포함할 수 있다. 제1 복수의 버스의 각 버스는 복수의 프로세서 서브유닛의 일 프로세서 서브유닛을 그에 상응하는 전용 메모리 뱅크에 연결시킬 수 있다. 제2 복수의 버스의 각 버스는 복수의 프로세서 서브유닛 의 일 프로세서 서브유닛을 복수의 프로세서 서브유닛의 다른 프로세서 서브유닛에 연결시킬 수 있다. 일부 경 우에서, 제2 복수의 버스는 복수의 프로세서 서브유닛의 하나 이상의 프로세서 서브유닛을 복수의 프로세서 서 브유닛 중의 둘 이상의 다른 프로세서 서브유닛으로 연결시킬 수 있다. 복수의 프로세서 서브유닛의 하나 이상 의 프로세서 서브유닛은 또한 기판 상에 배치된 적어도 하나의 메모리 매트를 포함할 수 있다. 적어도 하나의 메모리 매트는 복수의 프로세서 서브유닛의 하나 이상의 프로세서 서브유닛에 대한 레지스터 파일의 적어도 하 나의 레지스터 역할을 하도록 구성될 수 있다. 일부 경우에서, 레지스터 파일은 하나 이상의 논리 컴포넌트와 연관되어 메모리 매트가 레지스터 파일의 하나 이상의 레지스터 기능을 하게 하도록 할 수 있다. 예를 들면, 이러한 논리 컴포넌트에는 스위치, 증폭기, 인버 터, 센스 증폭기 등이 포함될 수 있다. 레지스터 파일이 DRAM 매트에 의해 구현되는 예에서, 리프레시 동작을 수행하여 저장된 데이터의 손실을 방지하도록 하기 위하여 논리 컴포넌트가 포함될 수 있다. 이러한 논리 컴포 넌트는 로우 및 컬럼 멀티플렉서(\"mux\")를 포함할 수 있다. 또한, DRAM 매트에 의해 구현된 레지스터 파일은 수 율 저하에 대응하기 위하여 중복 메커니즘을 포함할 수 있다. 도 84는 CPU 및 외장 메모리를 포함하는 종래의 컴퓨터 아키텍처를 도시한 것이다. 동작 동 안에, 메모리로부터의 값들은 CPU에 포함된 레지스터 파일와 연관된 레지스터 내부로 로딩될 수 있다. 도 85a는 개시된 실시예들에 따른 예시적인 분산 프로세서 메모리 칩(8500a)을 도시한 것이다. 도 84의 아키텍 처와 달리, 분산 프로세서 메모리 칩(8500a)은 동일 기판 상에 배치된 메모리 요소와 프로세서 요소를 포함한다. 즉, 칩(8500a)은 메모리 어레이 및 메모리 어레이에 포함된 하나 이상의 전용 메모리 뱅크와 각각 연 관된 복수의 프로세서 서브유닛을 포함하는 프로세싱 어레이를 포함할 수 있다. 도 85의 아키텍처에서, 프로세 서 서브유닛에 의해 사용되는 레지스터는 메모리 어레이와 프로세싱 어레이가 형성된 동일 기판 상에 배치된 하 나 이상의 메모리 매트에 의해 제공된다. 도 85a에 도시된 바와 같이, 분산 프로세서 메모리 칩(8500a)은 기판 상에 배치된 복수의 프로세싱 그룹 (8510a, 8510b, 8510c)에 의해 형성될 수 있다. 더욱 구체적으로, 분산 프로세서 메모리 칩(8500a)은 기판 상에 배치된 메모리 어레이와 프로세싱 어레이를 포함할 수 있다. 메모리 어레이는메모리 뱅크(8520a, 8520b, 8520c)와 같은 복수의 메모리 뱅크를 포함할 수 있다. 프로세싱 어레이는 프 로세서 서브유닛(8530a, 8530b, 8530c)과 같은 복수의 프로세서 서브유닛을 포함할 수 있다. 또한, 각각의 프로세싱 그룹(8510a, 8510b, 8510c)은 프로세서 서브유닛과 이 프로세서 서브유닛 전용의 하나 이상의 상응하는 메모리 뱅크를 포함할 수 있다. 도 85a에 도시된 실시예에서, 각각의 프로세서 서브유닛 (8530a, 8530b, 8530c)은 상응하는 전용 메모리 뱅크(8520a, 8520b, 8532c)와 연관될 수 있다. 즉, 프로세서 서브유닛(8530a)은 메모리 뱅크(8520a)와 연관될 수 있고, 프로세서 서브유닛(8530b)은 메모리 뱅크(8520b)와 연관될 수 있고, 프로세서 서브유닛(8530c)은 메모리 뱅크(8520c)와 연관될 수 있다. 각 프로세서 서브유닛이 그에 상응하는 전용 메모리 뱅크(들)와 통신할 수 있도록 하기 위하여, 분산 프로세서 메모리 칩(8500a)은 프로세서 서브유닛들 중의 하나를 그에 상응하는 전용 메모리 뱅크(들)와 연결시키는 제1 복수의 버스(8540a, 8540b, 8540c)를 포함할 수 있다. 도 85a에 도시된 실시예에서, 버스(8540a)는 프로세서 서 브유닛(8530a)을 메모리 뱅크(8520a)에 연결시킬 수 있고, 버스(8540b)는 프로세서 서브유닛(8530b)을 메모리 뱅크(8520b)에 연결시킬 수 있고, 버스(8540c)는 프로세서 서브유닛(8530c)을 메모리 뱅크(8520c)에 연결시킬 수 있다. 또한, 각 프로세서 서브유닛이 다른 프로세서 서브유닛들과 통신할 수 있도록 하기 위하여, 분산 프로세서 메모 리 칩(8500a)은 프로세서 서브유닛들 중의 하나를 적어도 하나의 다른 프로세서 서브유닛과 연결시키는 제2 복 수의 버스(8550a, 8550b)를 포함할 수 있다. 도 85a에 도시된 실시예에서, 버스(8550a)는 프로세서 서브유닛 (8530a)을 프로세서 서브유닛(8530b)과 연결시킬 수 있고, 버스(8550b)는 프로세서 서브유닛(8530b)을 프로세서 서브유닛(8530c)과 연결시킬 수 있다. 각각의 이산 메모리 뱅크(8520a, 8520b, 8520c)는 복수의 메모리 매트를 포함할 수 있다. 도 85a에 도시된 실시 예에서, 메모리 뱅크(8520a)는 메모리 매트(8522a, 8524a, 8526a)를 포함할 수 있고, 메모리 뱅크(8520b)는 메 모리 매트(8522b, 8524b, 8526b)를 포함할 수 있고, 메모리 뱅크(8520c)는 메모리 매트(8522c, 8524c, 8526c) 를 포함할 수 있다. 앞서 도 10을 참조하여 설명한 바와 같이, 메모리 매트는 복수의 메모리 셀을 포함할 수 있 고, 각 셀은 커패시터, 트랜지스터, 또는 적어도 1 비트의 데이터를 저장하는 다른 회로를 포함할 수 있다. 종 래의 메모리 매트는 예컨대 512 비트 X 512 비트를 포함할 수 있지만, 여기에 개시된 실시예들은 이에 한정되지 않는다. 프로세서 서브유닛(8530a, 8530b, 8530c)의 적어도 하나는 상응하는 프로세서 서브유닛(8530a, 8530b, 8530c) 에 대한 레지스터 파일 역할을 하도록 구성된 메모리 매트(8532a, 8532b, 8532c)와 같은 적어도 하나의 메모리 매트를 포함할 수 있다. 즉, 적어도 하나의 메모리 매트(8532a, 8532b, 8532c)는 하나 이상의 프로세서 서브유 닛(8530a, 8530b, 8530c)에 의해 사용되는 레지스터 파일의 적어도 하나의 레지스터를 제공한다. 레지스터 파일 은 하나 이사의 레지스터를 포함할 수 있다. 도 85a에 도시된 실시예에서, 프로세서 서브유닛(8530a) 내의 메모 리 매트(8532a)는 프로세서 서브유닛(8530a)(및/또는 분산 프로세서 메모리 칩(8500a)에 포함된 임의의 모든 다 른 프로세서 서브유닛)에 대한 레지스터 파일 역할을 할 수 있고('레지스터 파일(8532a)'로도 지칭), 프로세서 서브유닛(8530b) 내의 메모리 매트(8532b)는 프로세서 서브유닛(8530b)에 대한 레지스터 파일 역할을 할 수 있 고, 프로세서 서브유닛(8530c) 내의 메모리 매트(8532c)는 프로세서 서브유닛(8530c)에 대한 레지스터 파일 역 할을 할 수 있다. 프로세서 서브유닛(8530a, 8530b, 8530c)의 적어도 하나는 또한 논리 컴포넌트(8534a, 8534b, 8534c)와 같은 적어도 하나의 논리 컴포넌트를 포함할 수 있다. 각 논리 컴포넌트(8534a, 8534b, 또는 8534c)는 상응하는 메모 리 매트(8532a, 8532b, 또는 8532c)가 상응하는 프로세서 서브유닛(8530a, 8530b, 또는 8530c)에 대한 레지스 터 파일 역할을 할 수 있게 하도록 구성될 수 있다. 일부 실시예들에서, 적어도 하나의 메모리 매트는 기판 상에 배치될 수 있고, 이러한 적어도 하나의 메모리 매 트는 복수의 프로세서 서브유닛의 하나 이상의 프로세서 서브유닛에 대한 적어도 하나의 중복 레지스터를 제공 하도록 구성된 적어도 하나의 중복 메모리 비트를 포함할 수 있다. 일부 실시예들에서, 적어도 하나의 프로세서 서브유닛은 현재 작업을 중단하고 특정 시간에 메모리 리프레시 동작을 촉발하여 메모리 매트를 리프레시하는 메커니즘을 포함할 수 있다. 도 85b는 개시된 실시예들에 따른 예시적인 분산 프로세서 메모리 칩(8500b)을 도시한 것이다. 도 85b에 도시된 메모리 칩(8500b)은 메모리 매트(8532a, 8532b, 8532c)가 상응하는 프로세서 서브유닛(8530a, 8530b, 8530c)에 포함되지 않는다는 점을 제외하고는 도 85a에 도시된 메모리 칩(8500a)과 사실상 동일하다. 대신에, 도 85b의메모리 매트(8532a, 8532b, 8532c)는 상응하는 프로세서 서브유닛(8530a, 8530b, 8530c)의 외부에 그러나 공간 적으로 인근에 배치된다. 이 방식으로, 메모리 매트(8532a, 8532b, 8532c)는 여전히 상응하는 프로세서 서브유 닛(8530a, 8530b, 8530c)에 대한 레지스터 파일의 역할을 할 수 있다. 도 85c는 개시된 실시예에 따른 장치(8500c)를 도시한 것이다. 장치(8500c)는 기판, 제1 메모리 뱅크 , 제2 메모리 뱅크, 및 프로세싱 유닛을 포함한다. 제1 메모리 뱅크, 제2 메모리 뱅크 , 및 프로세싱 유닛은 기판 상에 배치된다. 프로세싱 유닛은 프로세서 및 메모 리 매트에 의해 구현된 레지스터 파일을 포함한다. 프로세싱 유닛의 동작 동안에, 프로세서 는 레지스터 파일에 접근하여 데이터의 읽기 또는 쓰기를 할 수 있다. 분산 프로세서 메모리 칩(8500a, 8500b) 또는 장치(8500c)는 메모리 매트에 의해 제공된 레지스터로의 프로세서 서브유닛의 접근에 의거하여 다양한 기능을 제공할 수 있다. 예를 들면, 일부 실시예들에서, 분산 프로세서 메 모리 칩(8500a 또는 8500b)은 메모리에 결합되어 더 큰 메모리 대역폭을 활용할 수 있도록 하는 가속기로 기능 하는 프로세서 서브유닛을 포함할 수 있다. 도 85a에 도시된 실시예에서, 프로세서 서브유닛(8530a)이 가속기 ('가속기(8530a)'로도 지칭함)로 기능할 수 있다. 가속기(8530a)는 가속기(8530a) 내에 배치된 메모리 매트 (8532a)를 활용하여 레지스터 파일의 하나 이상의 레지스터를 제공할 수 있다. 대안적으로, 도 85b에 도시된 실 시예에서, 가속기(8530a)는 가속기(8530a) 외부에 배치된 메모리 매트(8532a)를 레지스터 파일로 활용할 수 있 다. 또한, 가속기(8530a)는 메모리 뱅크(8520b) 내의 메모리 매트(8522b, 8524b, 8526b) 중의 임의의 하나 또 는 메모리 뱅크(8520c) 내의 메모리 매트(8522c, 8524c, 8526c) 중의 임의의 하나를 활용하여 하나 이상의 레지 스터를 제공할 수 있다. 개시된 실시예들은 특정 유형의 이미지 처리, 신경망, 데이터베이스 분석, 압축 및 압축해제 등에 특히 유용할 수 있다. 예를 들어, 도 85a 또는 도 85b의 실시예에서, 메모리 매트는 메모리 매트로서 동일한 칩 상에 포함된 하나 이상의 프로세서 서브유닛에 대한 레지스터 파일의 하나 이상의 레지스터를 제공할 수 있다. 하나 이상의 레지스터는 프로세서 서브유닛(들)에 의해 자주 접근되는 데이터의 저장에 활용될 수 있다. 예를 들어, 컨볼루 션 이미지 처리 동안에, 컨볼루션 가속기는 메모리 내에 있는 전체 이미지에 대해 동일한 계수들을 여러 번 반 복적으로 사용할 수 있다. 이러한 컨볼루션 가속기에 대한 제안된 구현은 이러한 계수들을 모두 '인근'의 레지 스터 파일에, 즉, 레지스터 파일 메모리 매트로서 동일 칩 상에 위치한 하나 이상의 프로세서 서브유닛 전용의 메모리 매트 내에 포함된 하나 이상의 레지스터 내에 보관하는 것일 수 있다. 이러한 아키텍처는 레지스터(및 저장된 계수값)를 계수값을 운용하는 프로세서 서브유닛에 가까이 둘 수 있다. 메모리 매트에 의해 구현된 레지 스터 파일은 공간적으로 가까운 효율적인 캐시 기능을 할 수 있기 때문에, 데이터 전송 시의 손실 및 접근 시의 지연을 상당히 감소시킬 수 있다. 다른 예에서, 개시된 실시예들은 메모리 매트에 의해 제공된 레지스터들 안으로 워드들을 입력할 수 있는 가속 기를 포함할 수 있다. 가속기는 레지스터들을 순환 버퍼(cyclic buffer)로 취급하여 단일 사이클에서 벡터를 배 가할 수 있다. 예를 들어, 도 85c에 도시된 장치(8500c)에서, 프로세싱 유닛 내의 프로세서는 메모 리 매트에 의해 구현된 레지스터 파일을 순환 버퍼로 사용하여 데이터(A1, A2, A3, . . . .)를 저장 하는 가속기로 기능한다. 제1 메모리 뱅크는 데이터(A1, A2, A3, . . . .)로 곱해질 데이터(B1, B2, B3, . . . )를 저장한다. 제2 메모리 뱅크는 곱셈 결과(C1, C2, C3, . . . .)를 저장한다. 즉, Ci = Ai Х Bi이다. 프로세싱 유닛에 레지스터 파일이 없다면, 프로세서가 메모리 뱅크(8570 또는 8572)와 같은 외부 메모리 뱅크로부터 데이터(A1, A2, A3, . . . .)와 데이터(B1, B2, B3, . . . )를 모두 읽으려면 메모리 대역폭과 사이클이 더 필요할 것이고, 이는 상당한 지연을 유발할 수 있다. 반면에, 본 실시예에서는, 데이터(A1, A2, A3, . . . .)가 프로세싱 유닛 내에 형성된 레지스터 파일에 저 장된다. 따라서, 프로세서는 외부 메모리 뱅크로부터 데이터(B1, B2, B3, . . . )만 읽어오면 된다. 따라서, 메모리 대역폭은 상당히 줄어들 수 있다. 메모리 프로세스에서, 메모리 매트는 일방향 접근(즉, 단일 접근)만을 허용하는 것이 보통이다. 일방향 접근에 서, 메모리로 하나의 포트가 있다. 그 결과, 특정 시간에 특정 주소로부터의 하나의 접근 동작, 예컨대, 읽기 또는 쓰기만이 수행될 수 있다. 그러나 메모리 매트 자체가 양방향 접근을 허용한다면, 양방향 접근이 당연한 선택이 될 수 있다. 양방향 접근에서, 2개의 상이한 주소가 특정 시간에 접근될 수 있다. 메모리 매트에 접근하 는 방법은 영역 및 요건에 의거하여 판단될 수 있다. 일부 경우에서, 메모리 매트에 의해 구현된 레지스터 파일 은 2개의 소스를 읽어야 하고 하나의 목적지 레지스터(destination register)가 있는 프로세서에 연결된 경우에 4방향 접근을 허용할 수 있다. 일부 경우에서, 레지스터 파일이 DRAM 매트에 의해 구현되어 설정 또는 캐시 데 이터를 저장하는 경우에, 레지스터 파일은 일방향 접근만을 허용할 수 있다. 표준 CPU는 다방향 접근 매트를 포함할 수 있는 반면에, DRAM이 적용되는 경우에는 일방향 접근 매트가 더 바람직할 수 있다. 컨트롤러 또는 가속기가 레지스터로의 단일 접근만을 필요로 하는 방식으로 설계되는 경우에, 메모리 매트로 구 현된 레지스터가 종래의 레지스터 파일 대신에 사용될 수 있다. 단일 접근에서, 한 번에 하나의 워드만이 접근 될 수 있다. 예를 들어, 프로세싱 유닛은 특정 시간에 2개의 레지스터 파일로부터 2개의 워드에 접근할 수 있다. 2개의 레지스터 파일의 각 레지스터 파일은 단일 접근만을 허용하는 메모리 매트(예: DRAM 매트)에 의해 구현될 수 있다. 대부분의 기술에서, 제조사로부터 확보된 닫혀 있는 블록(IP)인 메모리 매트 IP는 행 및 열 접근을 위해 워드라 인과 로우라인과 같은 배선이 구비되어 있다. 그러나 메모리 매트 IP는 주변에 논리 컴포넌트를 포함하지 않는 다. 따라서, 본 실시예들에 개시된 메모리 매트에 의해 구현된 레지스터 파일은 논리 컴포넌트를 포함할 수 있 다. 메모리 매트의 사이즈는 레지스터 파일의 요구 사이즈에 의거하여 선택될 수 있다. 메모리 매트를 활용하여 레지스터 파일의 레지스터를 제공하는 경우에 특정 문제가 발생할 수 있고, 이러한 문 제는 해당 메모리 매트를 형성하는데 활용된 특정 메모리 기술에 따라 다를 수 있다. 예를 들어, 메모리 생산에 서, 제조된 모든 메모리가 생산 후에 반드시 제대로 작동하는 것은 아니다. 이는 알려진 문제이고, 칩 상에 고 밀도의 SRAM이나 DRAM이 있는 경우에는 특히 그렇다. 메모리 기술에서는 이러한 문제의 대응으로, 수율을 적당 한 수준으로 유지하기 위하여 하나 이상의 중복 메커니즘이 활용될 수 있다. 개시된 실시예에서, 레지스터 파일 의 레지스터를 제공하는 데에 사용된 메모리 인스턴스(예: 메모리 뱅크)의 수가 상당히 적기 때문에, 중복 메커 니즘은 일반적인 메모리 응용만큼 중요하지 않을 수 있다. 반면에, 메모리 기능성에 영향을 주는 동일한 생산 문제는 특정 메모리 매트가 하나 이상의 레지스터를 제공하는 데에 적절히 기능하는지 여부에도 영향을 미칠 수 있다. 그 결과, 개시된 실시예들에는 중복 요소들이 포함될 수 있다. 예를 들어, 적어도 하나의 중복 메모리 매 트가 분산 프로세서 메모리 칩의 기판 상에 배치될 수 있다. 적어도 하나의 중복 메모리 매트는 복수의 프로세 서 서브유닛의 하나 이상의 프로세서 서브유닛에 대해 적어도 하나의 중복 레지스터를 제공하도록 구성될 수 있 다. 다른 예에서, 매트는 요구되는 사이즈보다 클 수 있고(예: 512x512가 아닌 620x620), 중복 메커니즘은 512x512 영역 또는 이와 균등한 영역 외부의 메모리 매트의 영역 내부로 구축될 수 있다. 다른 문제는 타이밍과 관련된 것일 수 있다. 일반적으로, 워드라인 및 비트라인의 로딩 타이밍은 메모리의 사이 즈에 의해 결정된다. 레지스터 파일이 상당히 작은 단일 메모리 매트(예: 512 x 512 비트)에 의해 구현될 수 있 으므로, 메모리 매트로부터 워드를 로딩하는 데에 적은 시간이 필요할 수 있고, 로직에 비해 상당히 빠르게 실 행하기에 타이밍이 충분할 수 있다. 리프레시 - DRAM과 같은 일부 메모리 유형은 주기적인 리프레시를 필요로 한다. 리프레시는 프로세서 도는 가속 기를 멈출 때에 수행될 수 있다. 작은 메모리 매트에 대해, 리프레시 하는 시간은 작은 퍼센티지의 시간일 수 있다. 따라서, 시스템이 짧은 시간 동안 정지하더라도, 메모리 매트를 레지스터로 사용하여 얻는 이득은 전체 성능을 감안할 때에 다운타임의 가치가 있을 수 있다. 일 실시예에서, 프로세싱 유닛은 수정의 숫자로부터 거꾸 로 세는 카운터를 포함할 수 있다. 카운터가 '0'에 도달하는 경우, 프로세싱 유닛은 프로세서(예: 가속기)에 의 해 수행되는 현재 작업을 중단하고, 메모리 매트가 라인별로 리프레시 되는 리프레시 동작을 촉발할 수 있다. 리프레시 동작이 종료되면, 프로세서는 작업을 재개할 수 있고, 카운터는 소정의 숫자로부터 거꾸로 세도록 재 설정될 수 있다. 도 86은 개시된 실시예들에 따른 분산 프로세서 메모리 칩에서 적어도 하나의 명령을 실행하는 예시적인 방법의 순서도를 도시한 것이다. 예컨대, 단계 8602에서, 분산 프로세서 메모리 칩의 기판 상의 메모리 어레이로 부터 적어도 하나의 데이터 값이 검색될 수 있다. 단계 8604에서, 검색된 데이터 값은 분산 프로세서 메모리 칩 의 기판 상의 메모리 어레이의 메모리 매트에 의해 제공되는 레지스터에 저장될 수 있다. 단계 8606에서, 분산 프로세서 메모리 칩 상의 분산 프로세서 서브유닛의 하나 이상과 같은 프로세서 요소가 메모리 매트 레지스터로 부터의 저장된 데이터 값을 운용할 수 있다. 본 명세서 전반에 걸쳐, 레지스터 파일은 최하위 레벨 캐시일 수 있으므로, 레지스터 파일에 관한 모든 언급은 캐시에도 동일하게 적용될 수 있음은 당연하다 할 것이다. 프로세싱 병목 '제1', '제2', '제3' 등의 용어는 서로 상이한 용어들 사이의 차이를 나타내는 용도로만 사용된다. 이러한 용어 는 요소의 순서 및/또는 시기 및/또는 중요도를 나타내는 것이 아니다. 예를 들어, 제1 프로세스에 앞서 제2 프 로세스가 있는 등이 가능할 수 있다. '결합'이라는 용어는 직접 및/또는 간접으로 연결됨을 의미할 수 있다. '메모리/프로세싱', '메모리 및 프로세싱', 및 '메모리 프로세싱'은 상호 교환적인 방식으로 사용된다. 메모리/프로세싱 유닛일 수 있는 다중 방법, 컴퓨터 판독가능 매체, 메모리/프로세싱 유닛, 및/또는 시스템이 있을 수 있다. 메모리/프로세싱 유닛은 메모리와 프로세싱 능력이 있는 하드웨어 유닛이다. 메모리/프로세싱 유닛은 메모리 프로세싱 집적회로일 수 있거나, 메모리 프로세싱 집적회로에 포함될 수 있거나, 하나 이상의 메모리 프로세싱 집적회로를 포함할 수 있다. 메모리/프로세싱 유닛은 PCT 특허 출원 공개공보 WO2019025892에 도시된 바와 같은 분산 프로세서일 수 있다. 메모리/프로세싱 유닛은 PCT 특허 출원 공개공보 WO2019025892에 도시된 바와 같은 분산 프로세서를 포함할 수 있다. 메모리/프로세싱 유닛은 PCT 특허 출원 공개공보 WO2019025892에 도시된 바와 같은 분산 프로세서에 속할 수 있 다. 메모리/프로세싱 유닛은 PCT 특허 출원 공개공보 WO2019025892에 도시된 바와 같은 메모리 칩일 수 있다. 메모리/프로세싱 유닛은 PCT 특허 출원 공개공보 WO2019025892에 도시된 바와 같은 메모리 칩을 포함할 수 있다. 메모리/프로세싱 유닛은 PCT 특허 출원 공개공보 WO2019025892에 도시된 바와 같은 메모리 칩에 속할 수 있다. 메모리/프로세싱 유닛은 PCT 특허 출원 번호 PCT/IB2019/001005에 도시된 바와 같은 분산 프로세서일 수 있다. 메모리/프로세싱 유닛은 PCT 특허 출원 번호 PCT/IB2019/001005에 도시된 바와 같은 분산 프로세서를 포함할 수 있다. 메모리/프로세싱 유닛은 PCT 특허 출원 번호 PCT/IB2019/001005에 도시된 바와 같은 분산 프로세서에 속할 수 있다. 메모리/프로세싱 유닛은 PCT 특허 출원 번호 PCT/IB2019/001005에 도시된 바와 같은 메모리 칩일 수 있다. 메모리/프로세싱 유닛은 PCT 특허 출원 번호 PCT/IB2019/001005에 도시된 바와 같은 메모리 칩을 포함할 수 있 다. 메모리/프로세싱 유닛은 PCT 특허 출원 번호 PCT/IB2019/001005에 도시된 바와 같은 메모리 칩에 속할 수 있다. 메모리/프로세싱 유닛은 웨이퍼 대 웨이퍼 접합(wafer to wafer bond) 및 다중 도체(multiple conductors)를 활용하여 서로 연결된 집적회로일 수 있다. 분산 프로세서 메모리 칩, 분산 메모리 프로세싱 집적회로, 메모리 칩, 분산 프로세서에 관한 임의의 모든 내용 은 웨이퍼 대 웨이퍼 접합 및 다중 도체를 활용하여 서로 연결된 한 쌍의 집적회로로서 구현될 수 있다. 메모리/프로세싱 유닛은 로직 셀보다 메모리 셀에 더 적합한 제1 제조 프로세스에 의해 제조될 수 있다. 따라서, 제1 제조 프로세스는 메모리 가미(memory flavored) 제조 프로세스로 여겨질 수 있다. 메모리 셀은 하 나 이상의 트랜지스터를 포함할 수 있다. 로직 셀은 하나 이상의 트랜지스터를 포함할 수 있다. 제1 제조 프로 세스는 메모리 뱅크의 제조에 적용될 수 있다. 로직 셀은 함께 논리 기능을 구현하는 하나 이상의 트랜지스터를 포함할 수 있고 더 큰 논리 회로의 블록의 기본 구성 블록으로 사용될 수 있다. 메모리 셀은 함께 메모리 기능 을 구현하는 하나 이상의 트랜지스터를 포함할 수 있고 더 큰 논리 회로의 블록의 기본 구성 블록으로 사용될 수 있다. 상응하는 로직 셀들은 동일한 논리 기능을 구현할 수 있다. 메모리/프로세싱 유닛은 메모리 셀보다 로직 셀에 더 적합한 제2 제조 프로세스에 의해 제조된 프로세서, 프로 세싱 집적회로, 및/또는 프로세싱 유닛과 다를 수 있다. 따라서, 제2 제조 프로세스는 로직 가미(logic flavored) 제조 프로세스로 여겨질 수 있다. 제2 제조 프로세스는 CPU, GPU 등의 제조에 사용될 수 있다. 메모리/프로세싱 유닛은 프로세서, 프로세싱 집적회로, 및/또는 프로세싱 유닛보다 덜 연산 집약적인 동작의 수 행에 더 적합할 수 있다. 예를 들어, 제1 제조 프로세스에 의해 제조된 메모리 셀은 제1 제조 프로세스에 의해 제조된 논리 회로의 임계 치수를 초과하는, 심지어는 아주 많이 초과하는(예: 2, 3, 4, 5, 9, 7, 8, 9, 10 등을 초과하는 인수만큼) 임계 치수를 보일 수 있다. 제1 제조 프로세스는 아날로그 제조 프로세스, DRAM 제조 프로세스 등일 수 있다. 제1 제조 프로세스에 의해 제조된 로직 셀의 사이즈는 제2 제조 프로세스에 의해 제조된 상응하는 로직 셀의 사 이즈를 적어도 2만큼 초과할 수 있다. 상응하는 로직 셀은 제1 제조 프로세스에 의해 제조된 로직 셀과 동일한 가능성을 가질 수 있다. 제2 제조 프로세스는 디지털 제조 프로세스일 수 있다. 제2 제조 프로세스는 CMOS(complementary metal-oxide-semiconductor), 바이폴라(bipolar), BiCOMS(bipolar- CMOS), DMOS(double-diffused metal-oxide-semiconductor), 산화물 상 실리콘 제조 프로세스 등 중의 임의의 하나일 수 있다. 메모리/프로세싱 유닛은 다중 프로세서 서브유닛을 포함할 수 있다. 하나 이상의 메모리/프로세싱 유닛의 프로세서 서브유닛들은 서로 개별적으로 및/또는 서로 협조하여 동작 및/ 또는 분산 프로세싱을 수행할 수 있다. 분산 프로세싱은 다양한 방식으로, 예컨대, 플랫(flat) 방식 또는 계층 방식으로 실행될 수 있다. 플랫 방식은 프로세서 서브유닛들이 동일한 동작들을 수행하도록(및 그 사이 프로세싱의 결과를 출력하거나 출 력하지 않도록) 한다. 계층 방식은 상이한 계층의 프로세싱 동작의 시퀀스의 실행을 포함할 수 있다. 여기서, 특정 층의 프로세싱 동 작은 또 다른 계층의 프로세싱 동작을 뒤따른다. 프로세서 서브유닛들은 상이한 층에 할당(동적 또는 정적)되고 계층적 프로세싱에 가담할 수 있다. 분산 프로세싱은 또한 다른 유닛들, 예컨대 메모리/프로세싱 유닛의 컨트롤로 및/또는 메모리/프로세싱 유닛에 속하지 않는 유닛들을 포함할 수 있다. 로직/논리 및 프로세서 서브유닛이라는 용어는 서로 상호교환적으로 사용될 수 있다. 본 출원에서 언급된 임의의 모든 프로세싱/처리는 임의의 모든 방식으로(예: 분산 방식, 분산되지 않는 방식 등) 실행될 수 있다. 이하, 다양한 참조 및/또는 참조에 의한 내용은 PCT 특허 출원 공개공보 WO2019025892 및 PCT 특허 출원 번호 PCT/IB2019/001005(2019년 9월 9일)에 기초한다. PCT 특허 출원 공개공보 WO2019025892 및/또는 PCT 특허 출원 번호 PCT/IB2019/001005는 다양한 방법, 시스템, 프로세서, 메모리 칩 등의 예시들을 제공하지만 이에 한정되지 않으며, 다른 방법, 시스템, 프로세서 등이 제공될 수도 있다. 프로세서 전에 하나 이상의 메모리/프로세싱 유닛이 있는 프로세싱 시스템이 제공될 수 있고, 각 메모리 및 프 로세싱 유닛(메모리/프로세싱 유닛)에는 프로세싱 리소스 및 스토리지 리소스가 있다. 프로세서는 하나 이상의 메모리/프로세싱 유닛이 다양한 프로세싱 작업을 수행하도록 요청 또는 지시할 수 있다. 다양한 프로세싱 작업의 실행은 프로세서의 로드를 덜고, 지연을 감소시키고, 일부 경우에서는 하나 이상 의 메모리/프로세싱 유닛과 프로세서 사이의 정보의 총 대역폭을 감소시킨다. 프로세서는 상이한 입도의 지시 및/또는 요청을 제공할 수 있다. 예를 들어, 프로세서는 특정 프로세싱 리소스 를 겨냥한 지시를 보낼 수 있거나 임의의 프로세싱 리소스를 지정하지 않고 메모리/프로세싱 유닛을 겨냥한 더 높은 계층 지시를 보낼 수 있다. 메모리/프로세싱 유닛은 임의의 모든 방식(예: 동적, 정적, 분산, 중앙집중, 오프라인, 온라인 등)으로 그 프로 세싱 및/또는 메모리 리소스를 관리할 수 있다. 리소스의 관리는 프로세서에 의한 설정 등의 후에 프로세서의 제어 하에 자율적으로 실행될 수 있다. 예를 들어, 작업은 하나 이상의 메모리/프로세싱 유닛의 하나 이상의 프로세싱 리소스 및/또는 메모리 리소스에 의한 실행 또는 하나 이상의 지시를 필요로 할 수 있는 서브작업들(sub-tasks)로 분할될 수 있다. 각 프로세싱 리소스는 적어도 하나의 지시를 실행(예: 독립적 또는 비독립적으로)하도록 구성될 수 있다. 예를 들면, PCT 특허 출원 공개공보 WO2019025892의 프로세서 서브유닛과 같은 프로세싱 리소스에 의해 서브시리즈(sub-series)의 지시가 실행된다. 적어도 메모리 리소스의 할당은 또한 하나 이상의 메모리/프로세싱 유닛이 아닌 엔티티, 예를 들면, 하나 이상 의 메모리/프로세싱 유닛에 결합될 수 있는 DMA(direct access memory) 유닛으로 제공될 수 있다. 컴파일러는 메모리/프로세싱 유닛에 의해 실행된 작업의 유형별로 설정 파일을 준비할 수 있다. 설정 파일은 메 모리 할당 및 작업 유형과 연관된 프로세싱 리소스 할당을 포함할 수 있다. 설정 파일은 상이한 프로세싱 리소 스에 의해 실행될 수 있는/있거나 메모리 할당을 정의할 수 있는 지시를 포함할 수 있다. 예를 들어, 행렬 곱셈 작업(행렬 A를 행렬 B로 곱하는 작업, 즉 A*B = C)에 관한 설정 파일은 행렬 A의 요소들 을 어디에 저장할지, 행렬 B의 요소들을 어디에 저장할지, 행렬 C의 요소들을 어디에 저장할지, 행렬 곱셈 중에 생성된 중간 결과를 어디에 저장할지를 지시할 수 있고, 행렬 곱셈에 관한 임의의 모든 수학적 연산의 수행을 위한 프로세싱 리소스를 겨냥한 지시를 포함할 수 있다. 설정 파일은 데이터 구조의 일례이고, 다른 데이터 구 조들이 제공될 수 있다. 행렬 곱셈은 하나 이상의 메모리/프로세싱 유닛에 의해 임의 모든 방식으로 실행될 수 있다. 하나 이상의 메모리/프로세싱 유닛은 행렬 A를 벡터 V로 곱할 수 있다. 이는 임의의 모든 방식으로 수행될 수 있다. 예를 들어, 프로세싱 리소스별로 행렬의 행 또는 열을 유지(상이한 프로세싱 리소스별 열의 상이한 행), 행렬의 행 또는 열과 벡터의 곱셈의 결과를 순환(상이한 프로세싱 리소스 사이에서), 및 이전 곱셈(두 번째부터 가장 최근의 반복까지)의 결과를 순환하는 것을 포함할 수 있다. 행렬 A가 4x4 행렬이고, 벡터 V가 1x4 벡터이고, 4개의 프로세싱 리소스가 있다고 가정 하에, 행렬 A의 제1 행 은 제1 프로세서 서브유닛에 저장되고, 행렬 A의 제2 행은 제2 프로세서 서브유닛에 저장되고, 행렬 A의 제3 행 은 제3 프로세서 서브유닛에 저장되고, 행렬 A의 제4 행은 제4 프로세서 서브유닛에 저장된다. 곱셈은 벡터 V의 제1 내지 제4 요소를 제1 내지 제4 프로세싱 리소스로 보내고 벡터 V의 제1 내지 제4 요소를 A의 상이한 벡터들 로 곱하여 개시되어 제1 중간 결과를 제공한다. 곱셈은 제1 중간 결과를 순환함으로써, 즉, 각 프로세싱 리소스 가 제1 프로세싱 리소스에 의해 계산된 제1 중간 결과를 이웃하는 프로세싱 리소스로 보냄으로써 계속된다. 각 프로세싱 리소스는 제1 중간 결과를 벡터로 곱하여 제2 곱셈 결과를 제공한다. 이는 행렬 A와 벡터 V의 곱셈이 끝날 때까지 여러 번 반복된다. 도 90a는 하나 이상의 메모리/프로세싱 유닛(일괄적으로 10910으로 표시) 및 프로세서를 포함하는 시스 템의 일례이다. 앞서 도시된 바와 같이, 프로세서는 하나 이상의 메모리/프로세싱 유닛으 로 요청 또는 지시를 (링크를 통해) 보낼 수 있고, 하나 이상의 메모리/프로세싱 유닛은 이어서 이러한 요청 및/또는 지시를 수행(또는 선택적으로 수행)하고 결과를 프로세서로 (링크를 통해) 보낼 수 있다. 프로세서는 결과를 더 처리하여 하나 이상의 출력을 (링크를 통해) 제공할 수 있 다. 하나 이상의 메모리/프로세싱 유닛은 J개의 메모리 리소스(10912(1,1) - 10912(1,J))를 포함할 수 있고(J는 양 의 정수), K개의 프로세싱 리소스(10911(1,1) - 10911(1,K))를 포함할 수 있다(K는 양의 정수). J는 K와 동일하거나 상이할 수 있다. 프로세싱 리소스(10911(1,1) - 10911(1,K))는 PCT 특허 출원 공개공보 WO2019025892에 도시된 바와 같은 프로 세싱 그룹 또는 프로세서 서브그룹 등일 수 있다. 메모리 리소스(10912(1,1) - 10912(1,J))는 PCT 특허 출원 공개공보 WO2019025892에 도시된 바와 같은 메모리 인스턴스, 메모리 매트, 메모리 뱅크 등일 수 있다. 하나 이상의 메모리/프로세싱 유닛의 임의의 모든 리소스(메모리 리소스 또는 프로세싱 리소스) 사이에는 임의 의 모든 연결성 및/또는 기능성 관계가 있을 수 있다. 도 90b는 메모리/프로세싱 유닛(10910)의 일례이다. 도 90b에서, K개(K는 양의 정수)의 프로세싱 리소스(10911(1,1) - 10911(1,K))는 서로 직렬로 연결됨(링크 참조)에 따라 루프를 형성한다. 각 프로세싱 리소스는 또한, 상응하는 한 쌍의 전용 메모리 리소스에 결합된다. 예컨대, 프로세싱 리소스(10911)는 메모리 리소스(10912과 10912)에 결합되고, 프로세싱 리 소스(10911(K))는 메모리 리소스(10912(J-1)과10912(J))에 결합된다. 프로세싱 리소스들은 임의의 모든 다른 방식으로 서로 연결될 수 있다. 각 프로세싱 리소스별로 할당된 메모리 리소스의 수는 2개가 아닐 수도 있다. 상 이한 리소스들 사이의 연결성의 예시들은 PCT 특허 출원 공개공보 WO2019025892에 도시되어 있다. 도 90c는 N개(N은 양의 정수)의 메모리/프로세싱 유닛(10910 - 10910(N))과 프로세서를 포함하는 시 스템의 일례이다. 앞서 도시된 바와 같이, 프로세서는 메모리/프로세싱 유닛(10920- 10910(N))으로 요청 또는 지시를 (링크(10931 - 10931(N))를 통해) 보낼 수 있고, 메모리/프로세싱 유닛 (10920- 10910(N))은 이어서 이러한 요청 및/또는 지시를 수행하고 결과를 프로세서로 (링크 (10932-3232(N))를 통해) 보낼 수 있다. 프로세서는 결과를 더 처리하여 하나 이상의 출력을 (링크 를 통해) 제공할 수 있다. 도 90d는 N개(N은 양의 정수)의 메모리/프로세싱 유닛(10910 - 10910(N))과 프로세서를 포함하는 시 스템의 일례이다. 도 90d는 메모리/프로세싱 유닛(10910 - 10910(N))의 앞에 프리프로세서 (preprocessor, 10909)를 도시하고 있다. 프리프로세서는 프레임 추출, 헤더 검출 등과 같은 다양한 프리프로세 싱 동작을 수행할 수 있다. 도 90e는 하나 이상의 메모리/프로세싱 유닛 및 프로세서를 포함하는 시스템의 일례이다. 도 90e는 하나 이상의 메모리/프로세싱 유닛 앞에 있는 프리프로세서 및 DMA 컨트롤러를 도시하고 있다. 도 90f는 적어도 하나의 정보 스트림의 분산 프로세싱 방법을 도시한 것이다. 방법은 하나 이상의 메모리 프로세싱 집적회로가 적어도 하나의 정보 스트림을 제1 통신 채널을 통해 수 신하는 단계 10810으로 시작할 수 있고, 여기서 각 메모리 프로세싱 집적회로는 컨트롤러, 다중 프로세서 서브 유닛, 및 다중 메모리 유닛을 포함한다. 단계 10810 이후에 단계 10820과 단계 10830이 수행될 수 있다. 단계 10820은 하나 이상의 메모리 프로세싱 집적회로가 정보 스트림을 버퍼링하는 단계를 포함할 수 있다. 단계 10830은 하나 이상의 메모리 프로세싱 집적회로가 적어도 하나의 정보 스트림에 대한 제1 프로세싱 동작을 수행하여 제1 프로세싱 결과를 제공하는 단계를 포함할 수 있다. 단계 10830은 압축 또는 압축해제를 포함할 수 있다. 이에 따라, 정보 스트림의 총 사이즈는 제1 프로세싱 결과의 총 사이즈를 초과할 수 있다. 정보 스트림의 총 사 이즈는 특정 기간의 주기 동안에 수신된 정보의 양을 반영하는 것일 수 있다. 제1 프로세싱 결과의 총 사이즈는 동일한 특정 기간의 임의의 주기 동안에 출력된 제1 프로세싱 결과의 양을 반영하는 것일 수 있다. 대안적으로, 정보 스트림(또는 본 명세서에 언급된 임의의 다른 정보 엔티티)의 총 사이즈는 제1 프로세싱 결과 의 총 사이즈보다 작을 수 있다. 이 경우, 압축이 확보된다. 단계 10830 이후에, 제1 프로세싱 결과를 하나 이상의 프로세싱 집적회로로 전송하는 단계 10840이 수행될 수 있다. 하나 이상의 메모리 프로세싱 집적회로는 메모리 가미 제조 프로세스에 의해 제조될 수 있다. 하나 이상의 메모리 프로세싱 집적회로는 로직 가미 제조 프로세스에 의해 제조될 수 있다. 메모리 프로세싱 집적회로에서, 메모리 유닛들은 각각 프로세서 서브유닛에 결합될 수 있다. 단계 10840 이후에, 하나 이상의 프로세싱 집적회로가 제1 프로세싱 결과에 대한 제2 프로세싱 동작을 수행하여 제2 프로세싱 결과를 제공하는 단계 10850이 수행될 수 있다. 단계 10820 및/또는 단계 10830은 하나 이상의 프로세싱 집적회로에 의해 지시되거나, 하나 이상의 프로세싱 집 적회로에 의해 요청되거나, 하나 이상의 프로세싱 집적회로의 설정 이후에 하나 이상의 프로세싱 집적회로에 의 해 실행되거나, 하나 이상의 프로세싱 집적회로의 개입 없이 독립적으로 실행될 수 있다. 제1 프로세싱 동작은 제2 프로세싱 동작보다 덜 연산 집약적일 수 있다. 단계 10830 및/또는 단계 10850은 (a) 이동통신망 프로세싱 동작, (b) 다른 망 관련 프로세싱 동작(이동통신망 과 다른 네트워크의 프로세싱), (c) 데이터베이스 프로세싱 동작, (d) 데이터베이스 분석 프로세싱 동작, (e) 인공지능 프로세싱 동작, 및 임의의 다른 프로세싱 동작 중의 적어도 하나일 수 있다. 분리된 시스템 메모리/프로세싱 유닛 및 분산 프로세싱 방법 분리된(disaggregated) 시스템, 분산 프로세싱 방법, 프로세싱/메모리 유닛, 분리된 시스템의 운용 방법, 프로 세싱/메모리 유닛의 운용 방법, 및 비일시적이고 임의의 상기 방법을 실행하기 위한 지시를 저장하는 컴퓨터 판 독가능 매체가 제공될 수 있다. 분리된 시스템은 상이한 서브시스템(subsystems)이 상이한 기능을 수행하도록 할당한다. 예를 들어, 저장은 하나 이상의 스토리지 서브시스템에 주로 구현될 수 있는 반면에 연산은 하나 이 상의 스토리지 서브시스템에 주로 구현될 수 있다. 분리된 시스템은 하나의 분리된 서버, 하나 이상의 분리된 서버, 하나 이상의 서버와 다른 서버일 수 있다. 분리된 시스템은 하나 이상의 스위칭 서브시스템, 하나 이상의 컴퓨팅 서브시스템, 하나 이상의 스토리지 서브 시스템, 및 하나 이상의 프로세싱/메모리 서브시스템을 포함할 수 있다. 하나 이상의 프로세싱/메모리 서브시스템, 하나 이상의 컴퓨팅 서브시스템, 및 하나 이상의 스토리지 서브시스 템은 하나 이상의 스위칭 서브시스템을 통해 서로 결합될 수 있다. 하나 이상의 프로세싱/메모리 서브시스템은 분리된 시스템의 하나 이상의 서브시스템에 포함될 수 있다. 도 87a는 분리된 시스템의 다양한 예를 도시한 것이다. 임의의 모든 수의 임의의 모든 유형의 서브시스템이 있을 수 있다. 분리된 시스템은 도 87a에 포함되지 않은 유 형의 하나 이상의 추가 서브시스템, 더 적은 수의 유형의 서브시스템 등을 포함할 수 있다. 분리된 시스템은 2개의 스토리지 서브시스템, 컴퓨팅 서브시스템, 스위칭 서브시스템, 및 프로세싱/메모리 서브시스템을 포함한다. 분리된 시스템은 2개의 스토리지 서브시스템, 컴퓨팅 서브시스템, 스위칭 서브시스템, 프로세싱/메모리 서브시스템, 및 가속기 서브시스템을 포함한다. 분리된 시스템은 2개의 스토리지 서브시스템, 컴퓨팅 서브시스템, 프로세싱/메모리 서브시스 템을 포함하는 스위칭 서브시스템을 포함한다. 분리된 시스템은 2개의 스토리지 서브시스템, 컴퓨팅 서브시스템, 프로세싱/메모리 서브시스 템을 포함하는 스위칭 서브시스템, 및 가속기 서브시스템을 포함한다 프로세싱/메모리 서브시스템을 스위칭 서브시스템 내에 포함시킴으로써, 분리된 시스템(7101, 7102) 이내의 트래픽을 감소시키고, 스위칭의 지연을 감소시키는 등이 가능할 수 있다. 분리된 시스템의 상이한 서브시스템들은 다양한 통신 프로토콜을 활용하여 서로 통신할 수 있다. 이더넷을 활용 하거나 심지어 이더넷 통신 프로토콜 상의 RDMA를 활용하면 스루풋을 증가시킬 수 있고 심지어 분리된 시스템의 요소들 사이의 정보 단위의 교환에 관한 다양한 제어 및/또는 저장 동작의 복잡성을 감소시킬 수 있는 것이 발 견되었다. 분리된 시스템은 프로세싱/메모리 서브시스템이 계산에 가담하도록 함으로써, 특히 메모리 집약적 계산을 실행 함으로써 분산 프로세싱을 수행할 수 있다. 예를 들어, N개의 컴퓨팅 단위들이 N개의 컴퓨팅 단위들 간에 정보 단위들을 공유해야 하는(올투올(all to all) 공유) 것으로 가정하면, (a) N개의 정보 단위들이 하나 이상의 프로세싱/메모리 서브시스템의 하나 이상의 프로 세싱/메모리 유닛으로 전송될 수 있고, (b) 하나 이상의 프로세싱/메모리 유닛은 올투올 공유를 필요로 한 계산 을 수행할 수 있고, (c) N개의 업데이트된 정보 단위들이 N개의 컴퓨팅 단위들로 전송될 수 있다. 이는 약 N개 의 전송 동작이 필요하게 된다. 예를 들어, 도 87b는 신경망의 모델(신경망의 노드들로 할당된 가중치를 포함하는 모델)을 업데이트한 분산 프 로세싱을 도시한 것이다. N개의 컴퓨팅 단위들 PU 내지 PU(N)(7120 - 7120(N))의 각 컴퓨팅 단위는 분리된 시스템들(7101, 7102, 7103, 7104) 중의 임의의 분리된 시스템의 컴퓨팅 서브시스템에 속할 수 있다. N개의 컴퓨팅 단위들은 N개의 부분 모델 업데이트(7121 내지 7121(N))(업데이트된 N개의 상이한 부분)를 계 산하고 (스위칭 서브시스템을 통해) 프로세싱/메모리 서브시스템으로 전송한다. 프로세싱/메모리 서브시스템은 업데이트된 모델을 계산하고 (스위칭 서브시스템을 통해) N개 의 컴퓨팅 단위들 PU 내지 PU(N)(7120 내지 7120(N))으로 전송한다. 도 87c, 도 87d, 및 도 87e는 각각 메모리/프로세싱 유닛(7011, 7012, 7013)의 예시를 도시한 것이고, 도 87f 와 도 87g는 메모리/프로세싱 유닛과 이더넷 모듈과 이더넷 모듈 상의 RDMA와 같은 하나 이상의 통 신 모듈을 포함하는 집적회로(7014, 7015)를 도시한 것이다. 메모리/프로세싱 유닛은 컨트롤러, 내부 버스, 다중 쌍의 로직, 및 메모리 뱅크를 포 함한다. 컨트롤러는 통신 모듈로 동작하도록 구성되거나 통신 모듈에 결합될 수 있다. 컨트롤러와 다중 쌍의 로직 및 메모리 뱅크 사이의 연결성은 다른 방식으로 구현될 수 있다. 메모리 뱅크와 로직은 다른 방식(쌍이 아닌)으로 배치될 수 있다. 프로세싱/메모리 서브시스템의 하나 이상의 메모리/프로세싱 유닛은 모델 업데이트를 병렬로 처리 할 수 있고(상이한 로직들을 사용하고 상이한 메모리 뱅크들로부터 모델의 상이한 부분들을 병렬로 검색), 대량 의 메모리 리소스와 메모리 뱅크와 로직 사이의 연결의 매우 높은 대역폭 덕분에 이러한 계산을 매우 효율적인 방식으로 수행할 수 있다. 도 87c 내지 도 87e의 메모리/프로세싱 유닛들(7011, 7012, 7013)과 도 87c 내지 도 87e의 집적회로들(7014, 7015)은 이더넷 모듈(도 87c 내지 도 87g) 및 이더넷 모듈 상의 RDMA(도 87e, 도 87g)와 같은 하나 이상 의 통신 모듈을 포함한다. 이러한 RDMA 및/또는 이더넷 모듈(메모리/프로세싱 유닛 이내 또는 메모리/프로세싱 유닛과 동일한 집적회로 이 내)을 구비하면, 분리된 시스템의 상이한 요소들 사이의 통신이 매우 빨라지고, RDMA의 경우에는 분리된 시스템 의 상이한 요소들 사이의 통신을 상당히 단순하게 한다. 여기서, RDMA 및/또는 이더넷 모듈을 포함하는 메모리/프로세싱 유닛은 다른 환경에서도, 예컨대 메모리/프로세 싱 유닛이 분리된 시스템에 포함되지 않는 경우에도 이점이 있을 수 있다. 또한, RDMA 및/또는 이더넷 모듈은 메모리/프로세싱 유닛의 그룹별로, 예컨대 비용 절감의 이유로, 할당될 수 있다. 메모리/프로세싱 유닛, 메모리/프로세싱 유닛의 그룹, 및 프로세싱/메모리 서브시스템은 다른 통신 포트, 예컨 대, PCIe 통신 포트를 포함할 수 있다. RDMA 및/또는 이더넷 모듈을 활용하면 이더넷 포트가 있을 수 있는 네트워크 집적회로(NIC)에 연결되는 브리지 로 메모리/프로세싱 유닛을 연결할 필요가 없기 때문에 비용 효율적일 수 있다. RDMA 및/또는 이더넷 모듈을 활용하면 이더넷(또는 이더넷 상의 RDMA)이 메모리/프로세싱 유닛 내에 네이티브 (native) 하게 할 수 있다. 여기서, 이더넷은 LAN(local area network) 프로토콜의 일례에 불과하고, PCIe는 이더넷보다 큰 거리에 사용될 수 있는 다른 통신 프로토콜의 일례에 불과하다. 도 87h는 분산 프로세싱을 위한 방법을 도시한 것이다. 방법은 하나 이상의 프로세싱 반복을 포함할 수 있다. 프로세싱 반복은 분리된 시스템의 하나 이상의 메모리 프로세싱 집적회로에 의해 실행될 수 있다. 프로세싱 반복은 분리된 시스템의 하나 이상의 프로세싱 집적회로에 의해 실행될 수 있다. 하나 이상의 프로세싱 집적회로에 의해 실행되는 프로세싱 반복 이후에 하나 이상의 프로세싱 집적회로에 의해 실행되는 프로세싱 반복이 뒤따를 수 있다. 하나 이상의 프로세싱 집적회로에 의해 실행되는 프로세싱 반복 이전에 하나 이상의 프로세싱 집적회로에 의해 실행되는 프로세싱 반복이 선행될 수 있다. 또 다른 프로세싱 반복이 분리된 시스템의 다른 회로들에 의해 실행될 수 있다. 예컨대, 하나 이상의 프리프로 세싱 회로가 하나 이상의 메모리 프로세싱 집적회로에 의한 프로세싱 반복을 위한 정보 단위의 준비 등을 포함 하는 임의의 모든 유형의 프리프로세싱을 수행할 수 있다. 방법은 분리된 시스템의 하나 이상의 메모리 프로세싱 집적회로가 정보 단위를 수신하는 단계 7020을 포 함할 수 있다. 각 메모리 프로세싱 집적회로는 컨트롤러, 다중 프로세서 서브유닛, 및 다중 메모리 유닛을 포함할 수 있다. 하나 이상의 메모리 프로세싱 집적회로는 메모리 가미 제조 프로세스에 의해 제조될 수 있다. 정보 단위는 신경망 모델의 일부를 전달할 수 있다. 정보 단위는 적어도 하나의 데이터베이스 쿼리의 부분 결과를 전달할 수 있다. 정보 단위는 적어도 하나의 총 데이터베이스 쿼리의 부분 결과를 전달할 수 있다. 단계 7020은 분리된 시스템의 하나 이상의 스토리지 서브시스템으로부터 정보 단위를 수신하는 단계를 포함할 수 있다. 단계 7020은 분리된 시스템의 하나 이상의 컴퓨팅 서브시스템으로부터 정보 단위를 수신하는 단계를 포함할 수 있고, 하나 이상의 컴퓨팅 서브시스템은 로직 가미 제조 프로세스에 의해 제조된 다중 프로세싱 집적회로를 포 함할 수 있다. 단계 7020 이후의 단계 7030에서, 하나 이상의 메모리 프로세싱 집적회로는 정보 단위에 프로세싱 동작을 수행 하여 프로세싱 결과를 제공할 수 있다. 정보 단위의 총 사이즈는 프로세싱 결과의 총 사이즈에 비해 크거나, 동일하거나, 작을 수 있다. 단계 7030 이후의 단계 7040에서, 하나 이상의 메모리 프로세싱 집적회로가 프로세싱 결과를 출력한다. 단계 7040은 분리된 시스템의 하나 이상의 컴퓨팅 서브시스템으로 프로세싱 결과를 출력하는 단계를 포함할 수 있고, 하나 이상의 컴퓨팅 서브시스템은 로직 가미 제조 프로세스에 의해 제조된 다중 프로세싱 집적회로를 포 함할 수 있다. 단계 7040은 분리된 시스템의 하나 이상의 스토리지 서브시스템으로 프로세싱 결과를 출력하는 단계를 포함할 수 있다. 정보 단위들은 다중 프로세싱 집적회로의 상이한 그룹의 프로세싱 유닛으로부터 전송될 수 있고 다중 프로세싱 집적회로에 의해 분산 방식으로 실행된 프로세스의 중간 결과의 상이한 부분들일 수 있다. 한 그룹의 프로세싱 유닛은 적어도 하나의 프로세싱 집적회로를 포함할 수 있다. 단계 7030은 정보 단위들을 처리하여 전체 프로세스의 결과를 제공하는 단계를 포함할 수 있다. 단계 7040은 전체 프로세스의 결과를 다중 프로세싱 집적회로의 각각으로 전송하는 단계를 포함할 수 있다. 중간 결과의 상이한 부분들은 업데이트된 신경망 모델의 상이한 부분들일 수 있고, 여기서, 전체 프로세스의 결 과는 업데이트된 신경망 모델이다. 단계 7040은 업데이트된 신경망 모델을 다중 프로세싱 집적회로의 각 프로세싱 집적회로로 전송하는 단계를 포 함할 수 있다. 단계 7040 이후의 단계 7050에서, 다중 프로세싱 집적회로로의 프로세싱 결과에 적어도 부분적으로 의거하여 다 중 프로세싱 집적회로가 다른 프로세싱을 수행할 수 있다. 단계 7040은 분리된 시스템의 스위칭 서브유닛을 활용하여 프로세싱 결과를 출력하는 단계를 포함할 수 있다. 단계 7020은 프리프로세싱된 정보 단위인 정보 단위를 수신하는 단계를 포함할 수 있다. 도 87i는 분산 프로세싱을 위한 방법을 도시하고 있다. 방법은 다중 프로세싱 집적회로가 정보를 프리프로세싱하여 프리프로세싱된 정보 단위를 제공하는 단계 7010을 포함한다는 점에서 방법과 차이가 있다. 단계 7010 이후에 단계 7020, 단계 7030, 및 단계 7040이 수행될 수 있다. 데이터베이스 분석 가속 메모리 유닛과 동일한 집적회로에 속하는 필터링 유닛에 의해 적어도 필터링을 수행하기 위한 장치, 방법 및 지 시를 저장하는 컴퓨터 판독가능 매체가 제공된다. 여기서, 필터는 어느 엔트리가 특정 데이터베이스 쿼리에 관련이 있는지를 나타낸다. 아비터(arbitrator) 또는 임의의 다른 흐름 제어 매니저(flow control manager)는 관 련 엔트리를 프로세서로 전송하거나 관련 없는 엔트리를 프로세서로 전송하지 않음으로써 프로세서로 및 프로세 서로부터의 대부분의 트래픽을 사실상 감소시킬 수 있다. 예를 들어, 도 91a에는 프로세서(CPU 9240) 및 메모리 및 필터링 시스템을 포함하는 집적회로가 도시되어 있다. 메모리 및 필터링 시스템은 메모리 유닛 엔트리 및 관련 엔트리를 프로세서로 전송하는 아비 터와 같은 하나 이상의 아비터에 결합된 필터링 유닛을 포함할 수 있다. 임의의 모든 아비트레이션 (arbitration) 프로세스가 적용될 수 있다. 엔트리의 수, 필터링 유닛의 수, 및 아비터의 수 사이에는 임의의 모든 관계가 있을 수 있다. 아비터는 통신 인터페이스, 플로우 컨트롤러 등과 같이 정보의 흐름을 제어할 수 있는 임의의 모든 유닛으로 대 체될 수 있다. 필터링은 하나 이상의 관련성/필터링 기준에 의거한다. 관련성은 데이터베이스 쿼리별로 설정될 수 있고 임의의 모든 방식으로 나타내어질 수 있다. 예컨대, 어느 엔트 리가 관련이 있는지를 나타내는 관련성 플래그(9224')를 메모리 유닛이 저장할 수 있다. 또한, K개의 데이터베 이스 세그먼트(9220(k))를 저장하는 스토리지 장치가 있고, 여기서 k의 범위는 1 내지 K이다. 여기서, 전 체 데이터베이스가 메모리 유닛에 저장되고 스토리지 장치에 저장되지 않을 수 있다(이러한 솔루션은 휘발성 메 모리 저장 데이터베이스라고도 지칭함). 메모리 유닛 엔트리는 전체 데이터베이스를 저장하기에 너무 작을 수 있으므로 한 번에 한 세그먼트를 수신할 수 있다. 필터링 유닛은 필드의 값을 임계값에 비교하는 동작, 필드의 값을 소정의 값에 비교하는 동작, 필드의 값이 소 정의 범위 이내인지를 판단하는 동작 등과 같은 필터링 동작을 수행할 수 있다. 따라서, 필터링 유닛은 공지의 데이터베이스 필터링 동작을 수행할 수 있고 소형의 저렴한 회로일 수 있다. 필터링 동작의 출력(예: 관련 데이터베이스 엔트리의 내용)은 처리를 위해 CPU로 전송된다. 메모리 및 필터링 시스템은 도 91b에 도시된 바와 같이 메모리 및 프로세싱 시스템으로 대체될 수 있다. 메모리 및 프로세싱 시스템은 메모리 유닛 엔트리에 결합된 프로세싱 유닛을 포함한다. 프로 세싱 유닛은 필터링 동작을 수행할 수 있고 관련 기록에 대한 하나 이상의 추가 동작의 실행에 적어도 부 분적으로 가담할 수 있다. 프로세싱 유닛은 특정 동작을 수행하도록 맞추어지고/지거나 다중 동작을 수행하도록 구성된 프로그램 가능 유 닛일 수 있다. 예를 들면, 프로세싱 유닛은 파이프라인 방식 프로세싱 유닛일 수 있거나, ALU를 포함하거나, 다 중 ALU를 포함하는 등일 수 있다. 프로세싱 유닛은 하나 이상의 추가 동작을 모두 수행할 수 있다. 대안적으로, 하나 이상의 추가 동작의 일부가 프로세싱 유닛에 의해 실행되고, 프로세서(CPU 9240)는 하나 이상 의 추가 동작의 다른 부분을 실행할 수 있다. 프로세싱 동작의 출력(예: 데이터베이스 쿼리에 대한 부분 응답 또는 전체 응답)은 CPU로 전 송된다. 부분 응답은 추가적인 처리를 필요로 한다. 도 92a는 필터링과 추가 프로세싱을 수행하도록 구성된 메모리/프로세싱 유닛을 포함하는 메모리/프로세 싱 시스템)을 도시한 것이다. 메모리/프로세싱 시스템은 메모리/프로세싱 유닛에 의해 도 91의 프로세싱 유닛과 메모리 유닛을 구현한다. 프로세서의 역할은 프로세싱 유닛의 제어, 하나 이상의 추가 동작의 적어도 일부의 실행 등을 포함할 수 있다. 메모리 엔트리와 프로세싱 유닛의 조합은 적어도 부분적으로는 하나 이상의 메모리/프로세싱 유닛에 의해 구현 될 수 있다. 도 92b는 메모리/프로세싱 유닛의 일례를 도시한 것이다. 메모리/프로세싱 유닛은 컨트롤러, 내부 버스, 및 다중 쌍의 로직과 메모리 뱅크 를 포함한다. 컨트롤러는 통신 모듈로서 동작하도록 구성되거나 통신 모듈에 결합될 수 있다. 컨트롤로와 다중 쌍의 로직과 메모리 뱅크 사이의 연결성은 다른 방식으로 구현될 수 있다. 메모리 뱅크와 로직은 다른 방식으로(쌍이 아닌) 배치될 수 있다. 다중 메모리 뱅크는 단일 로직에 결합 및/또 는 단일 로직에 의해 관리될 수 있다. 데이터베이스 쿼리는 인터페이스를 통해 메모리/프로세싱 시스템에 의해 수신된다. 인터페이스 는 버스, 포트, 입력/출력 인터페이스 등일 수 있다. 여기서, 데이터베이스에 대한 응답은 하나 이상의 메모리/프로세싱 시스템, 하나 이상의 메모리 및 프로세싱 시 스템, 하나 이상의 메모리 및 필터링 시스템, 및 이러한 시스템의 외부에 위치한 하나 이상의 프로세서 등 중의 적어도 하나(또는 이들의 조합)에 의해 생성될 수 있다. 여기서, 데이터베이스에 대한 응답은 하나 이상의 필터링 유닛, 하나 이상의 메모리/프로세싱 유닛, 하나 이상 의 프로세싱 유닛, 및 하나 이상의 다른 프로세서(예: 하나 이상의 다른 CPU) 등 중의 적어도 하나(또는 이들의 조합)에 의해 생성될 수 있다. 임의의 모든 프로세스는 관련 데이터베이스 엔트리를 찾는 단계 및 그 후에 관련 데이터베이스 엔트리를 처리하 는 단계를 포함할 수 있다. 처리는 하나 이상의 프로세싱 엔티티에 의해 실행될 수 있다. 프로세싱 엔티티는 메모리 및 프로세싱 시스템의 프로세싱 유닛(예: 메모리 및 프로세싱 시스템의 프로세 싱 유닛), 메모리/프로세싱 유닛의 프로세서 서브유닛(또는 로직)(예: 도 91a, 도 91b, 및 도 74의 CPU) 등 중의 적어도 하나일 수 있다. 데이터베이스 쿼리에 대한 응답의 생성에 포함된 처리는 다음 중의 임의의 하나 또는 그 조합에 의해 생성될 수 있다. a. 메모리 및 프로세싱 시스템의 프로세싱 유닛. b. 상이한 메모리 및 프로세싱 시스템들의 프로세싱 유닛들. c. 메모리/프로세싱 시스템의 하나 이상의 메모리/프로세싱 유닛의 프로세서 서브유닛(또는 로직 ). d. 상이한 메모리/프로세싱 시스템들의 메모리/프로세싱 유닛들의 프로세서 서브유닛들(또는 로직 ). e. 메모리/프로세싱 시스템의 하나 이상의 메모리/프로세싱 유닛들의 컨트롤러들. f. 상이한 메모리/프로세싱 시스템들의 하나 이상의 메모리/프로세싱 유닛들의 컨트롤러들. 따라서, 데이터베이스 쿼리에 대한 응답에 관여된 프로세싱은 (a) 하나 이상의 메모리/프로세싱 유닛들의 하나 이상의 컨트롤러들, (b) 메모리/프로세싱 시스템들의 하나 이상의 프로세싱 유닛들, (c) 하나 이상의 메모리/프 로세싱 유닛들의 하나 이상의 프로세서 서브유닛들, 및 (d) 하나 이상의 다른 프로세서들 등의 임의의 조합 또 는 하부 조합에 의해 실행될 수 있다. 하나보다 많은 프로세싱 엔티티에 의해 실행되는 프로세싱은 분산 프로세싱으로 지칭할 수 있다. 여기서, 필터링은 하나 이상의 필터링 유닛 및/또는 하나 이상의 프로세싱 유닛 및/또는 하나 이상의 프로세싱 서브유닛 중의 필터링 엔티티에 의해 실행될 수 있다. 이러한 차원에서, 필터링 동작을 수행하는 프로세싱 유닛 및/또는 프로세싱 서브유닛은 필터링 유닛으로 지칭될 수 있다. 프로세싱 엔티티는 필터링 엔티티일 수 있거나 필터링 유닛과 다를 수 있다. 프로세싱 엔티티는 다른 필터링 엔티티에 의해 관련 있는 것으로 여겨진 데이터베이스 엔트리의 프로세싱 동작 을 수행할 수 있다. 프로세싱 엔티티는 필터링 동작도 수행할 수 있다. 데이터베이스 쿼리에 대한 응답은 하나 이상의 필터링 엔티티 및 하나 이상의 프로세싱 엔티티를 활용할 수 있 다. 하나 이상의 필터링 엔티티 및 하나 이상의 프로세싱 엔티티는 동일 시스템(예: 메모리/프로세싱 시스템, 메모리 및 프로세싱 시스템, 메모리 및 필터링 시스템)에 속하거나 상이한 시스템에 속할 수 있다. 메모리/프로세싱 유닛은 다중 프로세서 서브유닛을 포함할 수 있다. 프로세서 서브유닛들은 서로로부터 독립적 으로 동작할 수 있고, 서로 부분적으로 협력할 수 있고, 분산 프로세싱에 가담하는 등이 가능할 수 있다. 도 92c는 다중 메모리 및 필터링 시스템, 다른 다중 프로세서(예: CPU), 및 스토리지 장치를 도시한 것이다. 다중 메모리 및 필터링 시스템은 하나 이상의 데이터베이스 쿼리 내의 하나 이상의 필터링 기준에 의거하 여 하나 이상의 데이터베이스 엔트리의 필터링에 가담(동시 또는 비동시)할 수 있다. 도 92d는 다중 메모리 및 프로세싱 시스템, 다른 다중 프로세서(예: CPU), 및 스토리지 장치(921 0)를 도시한 것이다. 다중 메모리 및 프로세싱 시스템은 하나 이상의 데이터베이스 쿼리의 응답에 관여된 필터링과 적어도 부 분적으로는 프로세싱에 가담(동시 또는 비동시)할 수 있다. 도 92e는 다중 메모리/프로세싱 시스템, 다른 다중 프로세서(예: CPU), 및 스토리지 장치를 도시한 것이다. 다중 메모리/프로세싱 시스템은 하나 이상의 데이터베이스 쿼리의 응답에 관여된 필터링과 적어도 부분적 으로는 프로세싱에 가담(동시 또는 비동시)할 수 있다. 도 92f는 데이터베이스 분석 가속 방법을 도시한 것이다. 방법은 데이터베이스 쿼리와 관련 있는 데이터베이스의 데이터베이스 엔트리를 나타내는 적어도 하나의 관련성 기준을 포함하는 데이터베이스 쿼리를 메모리 프로세싱 집적회로가 수신하는 단계 9310으로 시작할 수 있다. 데이터베이스 쿼리와 관련 있는 데이터베이스의 데이터베이스 엔트리는 데이터베이스의 데이터베이스 엔트리의 전부, 일부, 또는 하나일 수 있거나 하나도 아닐 수 있다. 메모리 프로세싱 집적회로는 컨트롤러, 다중 프로세서 서브유닛, 및 다중 메모리 유닛일 수 있다. 단계 9310 이후에, 메모리 프로세싱 집적회로에 저장된 한 그룹의 관련 있는 데이터베이스 엔트리를 메모리 프 로세싱 집적회로가 적어도 하나의 관련성 기준에 의거하여 판단하는 단계 9320이 수행될 수 있다. 단계 9320 이후에, 메모리 프로세싱 집적회로에 저장된 관련 없는 데이터 엔트리를 하나 이상의 프로세싱 엔티 티로 실질적으로 전송하지 않고 프로세싱을 계속하기 위해 상기 그룹의 관련 있는 데이터베이스 엔트리를 상기 하나 이상의 프로세싱 엔티티로 전송하는 단계 9330이 수행될 수 있다. '실질적으로 전송하지 않고'라는 문구는 전혀 전송하지 않거나(데이터베이스 쿼리에 대한 응답 과정에서) 미미 한 수의 관련 없는 엔트리를 전송하는 것을 의미한다. 미미하다는 것은 최대 1, 2, 3, 4, 5, 6, 7, 8, 9, 10%를 의미할 수 있거나 대역폭에 중대한 영향이 없는 양을 전송하는 것을 의미할 수 있다. 단계 9330 이후에, 상기 그룹의 관련 있는 데이터베이스 엔트리를 프로세싱 하여 데이터베이스 쿼리에 대한 응 답을 제공하는 단계 9340이 수행될 수 있다."}
{"patent_id": "10-2022-7008116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "[002] 도 92g는 데이터베이스 분석 가속 방법을 도시한 것이다. 필터링 및 데이터베이스 쿼리에 대한 응답에 필요한 프로세싱 전체가 메모리 프로세싱 집적회로에 의해 실행되 는 것으로 가정한다. 방법은 데이터베이스 쿼리와 관련 있는 데이터베이스의 데이터베이스 엔트리를 나타내는 적어도 하나의 관련성 기준을 포함하는 데이터베이스 쿼리를 메모리 프로세싱 집적회로가 수신하는 단계 9310으로 시작할 수 있다. 단계 9310 이후에, 메모리 프로세싱 집적회로에 저장된 한 그룹의 관련 있는 데이터베이스 엔트리를 메모리 프 로세싱 집적회로가 적어도 하나의 관련성 기준에 의거하여 판단하는 단계 9320이 수행될 수 있다.단계 9320 이후에, 메모리 프로세싱 집적회로에 저장된 관련 없는 데이터 엔트리를 하나 이상의 프로세싱 엔티 티로 실질적으로 전송하지 않고 완전한 프로세싱을 위해 상기 그룹의 관련 있는 데이터베이스 엔트리를 상기 하 나 이상의 프로세싱 엔티티로 전송하는 단계 9331이 수행될 수 있다. 단계 9331 이후에, 상기 그룹의 관련 있는 데이터베이스 엔트리를 완전히 프로세싱 하여 데이터베이스 쿼리에 대한 응답을 제공하는 단계 9341이 수행될 수 있다. 단계 9341 이후에, 데이터베이스 쿼리에 대한 응답을 메모리 프로세싱 집적회로로부터 출력하는 단계 9351이 수 행될 수 있다. 도 92h는 데이터베이스 분석 가속 방법을 도시한 것이다. 필터링 및 데이터베이스 쿼리에 대한 응답에 필요한 프로세싱의 일부만이 메모리 프로세싱 집적회로에 의해 실 행되는 것으로 가정한다. 메모리 프로세싱 집적회로는 메모리 프로세싱 집적회로의 외부에 위치한 하나 이상의 다른 프로세싱 엔티티에 의해 처리될 부분 결과를 출력하게 된다. 방법은 데이터베이스 쿼리와 관련 있는 데이터베이스의 데이터베이스 엔트리를 나타내는 적어도 하나의 관련성 기준을 포함하는 데이터베이스 쿼리를 메모리 프로세싱 집적회로가 수신하는 단계 9310으로 시작할 수 있다. 단계 9310 이후에, 메모리 프로세싱 집적회로에 저장된 한 그룹의 관련 있는 데이터베이스 엔트리를 메모리 프 로세싱 집적회로가 적어도 하나의 관련성 기준에 의거하여 판단하는 단계 9320이 수행될 수 있다. 단계 9320 이후에, 메모리 프로세싱 집적회로에 저장된 관련 없는 데이터 엔트리를 하나 이상의 프로세싱 엔티 티로 실질적으로 전송하지 않고 일부 프로세싱을 위해 상기 그룹의 관련 있는 데이터베이스 엔트리를 상기 하나 이상의 프로세싱 엔티티로 전송하는 단계 9332가 수행될 수 있다. 단계 9332 이후에, 상기 그룹의 관련 있는 데이터베이스 엔트리를 일부 프로세싱하여 데이터베이스 쿼리에 대한 중간 응답을 제공하는 단계 9342가 수행될 수 있다. 단계 9342 이후에, 데이터베이스 쿼리에 대한 중간 응답을 메모리 프로세싱 집적회로로부터 출력하는 단계 9352 가 수행될 수 있다. 단계 9352 이후에, 상기 중간 응답을 계속 프로세싱하여 데이터베이스 쿼리에 대한 응답을 제공하는 단계 9390 이 수행될 수 있다. 도 92i는 데이터베이스 분석 가속 방법을 도시한 것이다. 필터링은 메모리 프로세싱 집적회로에 의해 실행되지만 관련 있는 데이터베이스 엔트리의 처리는 메모리 프로세 싱 집적회로에 의해 실행되지 않는 것으로 가정한다. 메모리 프로세싱 집적회로는 메모리 프로세싱 집적회로의 외부에 위치한 하나 이상의 다른 프로세싱 엔티티에 의해 완전히 처리될 관련 있는 데이터베이스 엔트리 그룹을 출력하게 된다. 방법은 데이터베이스 쿼리와 관련 있는 데이터베이스의 데이터베이스 엔트리를 나타내는 적어도 하나의 관련성 기준을 포함하는 데이터베이스 쿼리를 메모리 프로세싱 집적회로가 수신하는 단계 9310으로 시작할 수 있다. 단계 9310 이후에, 메모리 프로세싱 집적회로에 저장된 한 그룹의 관련 있는 데이터베이스 엔트리를 메모리 프 로세싱 집적회로가 적어도 하나의 관련성 기준에 의거하여 판단하는 단계 9320이 수행될 수 있다. 단계 9320 이후에, 메모리 프로세싱 집적회로에 저장된 관련 없는 데이터 엔트리를 하나 이상의 프로세싱 엔티 티로 실질적으로 전송하지 않고 상기 그룹의 관련 있는 데이터베이스 엔트리를 메모리 프로세싱 집적회로의 외 부에 위치한 하나 이상의 프로세싱 엔티티로 전송하는 단계 9333이 수행될 수 있다. 단계 9333 이후에, 상기 중간 응답을 완전히 프로세싱 하여 데이터베이스 쿼리에 대한 응답을 제공하는 단계 9391이 수행될 수 있다. 도 92j는 데이터베이스 분석 가속 방법을 도시한 것이다. 방법은 데이터베이스 쿼리와 관련이 있는 데이터베이스의 데이터베이스 엔트리를 나타내는 적어도 하나의 관련성 기준을 포함하는 데이터베이스 쿼리를 집적회로가 수신하는 단계 9315로 시작할 수 있고, 집적회로는 컨트롤러, 필터링 유닛, 및 다중 메모리 유닛을 포함한다. 단계 9315 이후에, 집적회로에 저장된 한 그룹의 관련 있는 데이터베이스 엔트리를 필터링 유닛이 적어도 하나 의 관련성 기준에 의거하여 판단하는 단계 9325가 수행될 수 있다. 단계 9325 이후에, 집적회로에 저장된 관련 없는 데이터 엔트리를 하나 이상의 프로세싱 엔티티로 실질적으로 전송하지 않고 프로세싱을 계속하기 위해 상기 그룹의 관련 있는 데이터베이스 엔트리를 집적회로의 외부에 위 치한 하나 이상의 프로세싱 엔티티로 전송하는 단계 9335가 수행될 수 있다. 단계 9335 이후에 단계 9391이 수행될 수 있다. 도 92k는 데이터베이스 분석 가속 방법을 도시한 것이다. 방법은 데이터베이스 쿼리와 관련이 있는 데이터베이스의 데이터베이스 엔트리를 나타내는 적어도 하나의 관련성 기준을 포함하는 데이터베이스 쿼리를 집적회로가 수신하는 단계 9314로 시작할 수 있고, 집적회로는 컨 트롤러, 프로세싱 유닛, 및 다중 메모리 유닛을 포함한다. 단계 9314 이후에, 집적회로에 저장된 한 그룹의 관련 있는 데이터베이스 엔트리를 프로세싱 유닛이 적어도 하 나의 관련성 기준에 의거하여 판단하는 단계 9324가 수행될 수 있다. 단계 9324 이후에, 집적회로에 저장된 관련 없는 데이터 엔트리를 프로세싱 유닛이 처리하지 않고 상기 그룹의 관련 있는 데이터베이스 엔트리를 프로세싱 유닛이 처리하여 프로세싱 결과를 제공하는 단계 9334가 수행될 수 있다. 단계 9334 이후에, 집적회로로부터 프로세싱 결과를 출력하는 단계 9344가 수행될 수 있다. 방법들(9300, 9301, 9302, 9304, 9305) 중의 임의의 방법에서, 메모리 프로세싱 집적회로는 출력을 생성한다. 출력은 관련 있는 데이터베이스 엔트리의 그룹, 하나 이상의 중간 결과, 또는 하나 이상의 (완전) 결과일 수 있 다. 출력 이전에 메모리 프로세싱 집적회로의 필터링 엔티티 및/또는 프로세싱 엔티티로부터 하나 이상의 관련 있는 데이터베이스 엔트리 및/또는 하나 이상의 결과(전체 결과 또는 중간 결과)의 검색이 수행될 수 있다. 검색은 하나 이상의 방식으로 제어될 수 있고 메모리 프로세싱 집적회로의 하나 이상의 컨트롤러 및/또는 아비 터에 의해 제어될 수 있다. 출력 및/또는 검색은 검색 및/또는 출력의 하나 이상의 파라미터의 제어를 포함할 수 있다. 파라미터는 검색 타 이밍, 검색 속도, 검색 소스, 대역폭, 검색 순서, 출력 타이밍, 출력 속도, 출력 소스, 대역폭, 출력 순서, 검 색 방법의 유형, 아비트레이션 방법의 유형 등을 포함할 수 있다. 출력 및/또는 검색은 흐름 제어 프로세스를 수행할 수 있다. 출력 및/또는 검색(예: 흐름 제어 프로세스의 적용)은 하나 이상의 프로세싱 엔티티로부터 출력되고 그룹의 데 이터베이스 엔트리의 처리의 완료에 관한 지시자에 대응하는 것일 수 있다. 지시자는 프로세싱 엔티티로부터 중 간 결과가 검색될 준비가 되었는지 여부를 나타내는 것일 수 있다. 출력은, 메모리 프로세싱 집적회로를 리퀘스터 유닛(requester unit)에 결합시키는 링크를 통해, 출력 과정에서 사용된 대역폭을 최대 허용 대역폭에 일치시키려는 시도를 포함할 수 있다. 이 링크는 메모리 프로세싱 집적회 로의 출력의 수신자로의 링크일 수 있다. 최대 허용 대역폭은 링크의 능력 및/또는 유용성, 출력된 컨텐츠의 수 신자의 능력 및/또는 유용성에 따를 수 있다. 출력은 출력된 컨텐츠를 최선의 또는 차선의 방식으로 출력하려는 시도를 포함할 수 있다. 출력된 컨텐츠의 출력은 출력 트래픽 속도의 변동을 임계값 이하로 유지하려는 시도를 포함할 수 있다. 방법들(9300, 9301, 9302, 9305) 중의 임의의 방법은 하나 이상의 프로세싱 엔티티가 상기 그룹의 관련 있는 데 이터베이스 엔트리의 추가적인 프로세싱의 진행을 나타내는 것일 수 있는 프로세싱 상태 지시자를 생성하는 단 계를 포함할 수 있다. 앞서 설명한 임의의 모든 방법에 포함된 프로세싱은 단일 프로세싱 엔티티 이상에 의해 실행될 수 있다. 이 경 우, 프로세싱은 분산 방식으로 실행되므로 분산 프로세싱으로 여겨질 수 있다. 앞서 나타낸 바와 같이, 프로세싱은 계층 방식 또는 플랫 방식으로 실행될 수 있다. 방법들(9300 내지 9305) 중의 임의의 방법은 다중 데이터베이스 쿼리에 대해 동시에 또는 순차적으로 응답할 수 있는 다중 시스템에 의해 실행될 수 있다. 워드 임베딩 앞서 설명한 바와 같이, 워드 임베딩은 어휘에서 단어 또는 구절이 요소의 벡터로 매핑되는 자연어 처리(NLP)의 언어 모델링 및 특징 학습 방식의 모음에 대한 포괄적인 명칭이다. 개념적으로, 단어당 많은 차원이 있는 공간 으로부터 훨씬 적은 차원이 있는 연속적 벡터 공간으로의 수학적 매핑이 개입된다. 벡터들은 수학적으로 처리될 수 있다. 예를 들면, 행렬에 속하는 벡터들은 합산되어 합산 벡터를 제공할 수 있 다. 다른 예를 들면, (문장의) 행렬의 공분산(covariance)이 계산될 수 있다. 여기에는 행렬과 그 전치행렬 (transposed matrix)의 곱셈이 포함될 수 있다. 메모리/프로세싱 유닛은 어휘를 저장할 수 있다. 특히, 어휘의 부분들은 메모리/프로세싱 유닛의 다중 메모리 뱅크들에 저장될 수 있다. 따라서, 메모리/프로세싱 유닛은 문장의 단어 또는 구절을 나타내게 되는 접근 정보(예: 검색 키)로 접근될 수 있다. 따라서, 문장의 단어 또는 구절을 나타내는 벡터는 메모리/프로세싱 유닛의 메모리 뱅크들의 적어도 일부 로부터 검색되게 된다. 메모리/프로세싱 유닛의 상이한 메모리 뱅크들은 어휘의 상이한 부분들을 저장할 수 있고 (문장의 색인 분포에 따라) 병렬로 접근될 수 있다. 메모리 뱅크의 단일 라인 이상이 순차적으로 접근될 필요가 있는 경우에도 예측 은 페널티를 줄일 수 있다. 메모리/프로세싱 유닛의 상이한 메모리 뱅크들 사이에 어휘의 단어들을 할당하면 문장별로 메모리/프로세싱 유 닛의 상이한 메모리 뱅크들로 병렬 접근이 될 가능성을 향상시킨다는 차원에서 최선이거나 매우 바람직할 수 있 다. 이러한 할당은 사용자별로, 일반 대중별로, 또는 사람들의 그룹별로 학습될 수 있다. 또한, 메모리/프로세싱 유닛은 프로세싱 동작의 적어도 일부를 수행(로직에 의해)하는 데에도 활용될 수 있어서, 메모리/프로세싱 유닛 외부의 버스로부터 요구되는 대역폭을 줄일 수 있고 다중 연산을 효율적인 방식 으로(병렬로도 가능) 계산(메모리/프로세싱 유닛의 다중 프로세서를 병렬로 활용)할 수 있다. 메모리 뱅크는 로직과 연관될 수 있다. 프로세싱 동작의 적어도 일부는 하나 이상의 추가적인 프로세서(예: 벡터 합산기(vector adder) 등을 포함하는 벡터 프로세서)에 의해 실행될 수 있다. 메모리/프로세싱 유닛 메모리 뱅크의 일부 또는 전부로 할당될 수 있는 하나 이상의 추가 프로세서를 포함할 수 있다(로직 쌍). 따라서, 단일 추가 프로세서는 메모리 뱅크의 전부 또는 일부로 할당될 수 있다(로직 쌍). 다른 예를 들면, 추 가 프로세서는 일부 레벨의 추가 프로세서가 그보다 낮은 레벨의 추가 프로세서의 출력을 처리할 수 있도록 계 층 방식으로 배치될 수 있다. 여기서, 프로세싱 동작은 추가 프로세서를 사용하지 않고 메모리/프로세싱 유닛의 로직에 의해 실행될 수 있다. 도 89a, 도 89b, 도 89c, 도 89d, 도 89e, 도 89f, 및 도 89g는 각각 메모리/프로세싱 유닛(9010, 9011, 9012, 9013, 9014, 9015, 9019)의 예를 도시한 것이다. 메모리/프로세싱 유닛은 컨트롤러, 내부 버스 , 및 로직과 메모리 뱅크의 다중 쌍을 포함한다. 여기서, 로직과 메모리 뱅크는 다른 방식으로 컨트롤러에 및/또는 서로 결합될 수 있다. 예컨대, 다중 버스가 컨트롤러와 로직 사이에 제공되거나, 로직이 다중 층으로 배치되거나, 단일 로직이 다중 메모리 뱅 크에 의해 공유되거나(도 89e의 예 참조) 등이 가능할 수 있다. 메모리/프로세싱 유닛 내의 각 메모리 뱅크의 페이지 길이는 임의의 모든 방식으로 정의될 수 있다. 예를 들면, 길이는 충분히 작을 수 있고, 메모리 뱅크의 수는 관련 없는 정보에 많은 비트를 낭비하지 않고 많은 수 의 벡터의 출력이 병렬로 가능하게 할 수 있도록 충분히 클 수 있다. 로직은 완전 ALU, 부분 ALU, 메모리 컨트롤러, 부분 메모리 컨트롤러 등을 포함할 수 있다. 부분 ALU(메 모리 컨트롤러) 유닛은 완전 ALU(메모리 컨트롤러)에 의해 실행 가능한 기능의 일부만을 실행할 능력이 있다. 본 출원에 도시된 임의의 모든 로직 또는 서브프로세서는 완전 ALU, 부분 ALU, 메모리 컨트롤러, 부분 메모리 컨트롤러 등을 포함할 수 있다. 컨트롤러와 다중 쌍의 로직과 메모리 뱅크 사이의 연결성은 다른 방식으로 구현될 수 있다. 메모리 뱅크와 로직은 다른 방식(예: 쌍이 아닌 방식)으로 배치될 수 있다. 메모리/프로세싱 유닛에는 추가 벡터가 없을 수 있고, (메모리 뱅크로부터의) 벡터의 처리는 로직 에 의해 수행된다. 도 89b는 내부 버스에 결합된 벡터 프로세서와 같은 추가 프로세서를 도시한 것이다. 도 89c는 내부 버스에 결합된 벡터 프로세서와 같은 추가 프로세서를 도시한 것이다. 하나 이상의 추가 프로세서가 프로세싱 동작을 실행(단독으로 또는 로직과 함께)한다. 도 89d는 버스를 통해 메모리/프로세싱 유닛에 결합된 호스트를 도시한 것이다. 도 89d는 또한 단어/구절을 벡터에 매핑하는 어휘를 도시하고 있다. 메모리/프로세싱 유닛은 이전에 인지된 단어 또는 구절을 각각 나타내는 검색 키를 활용하여 접근된다. 호스트는 문장을 나 타내는 다중 검색 키를 메모리/프로세싱 유닛으로 전송하고, 메모리/프로세싱 유닛은 벡터 또는 문 장과 관련된 벡터에 의해 적용된 프로세싱 동작의 결과를 출력할 수 있다. 단어/구절은 메모리/프로세싱 유닛 에 저장되지 않는 것이 보통이다. 메모리 뱅크를 제어하기 위한 메모리 컨트롤러 기능은 로직에 포함(완전히 또는 부분적으로), 컨트롤러에 포함(완전히 또는 부분적으로), 및/또는 메모리/프로세싱 유닛 내의 하나 이상의 메모리 컨트롤러(미도시)에 포함(완전히 또는 부분적으로)될 수 있다. 메모리/프로세싱 유닛은 호스트로 전송되는 벡터/결과의 스루풋을 최대화하도록 구성될 수 있거나 내부 메모리/프로세싱 유닛 트래픽을 제어 및/또는 메모리/프로세싱 유닛과 호스트 컴퓨터(또는 메모리/프로세싱 유 닛 외부의 임의의 다른 엔티티) 사이의 트래픽을 제어하기 위한 임의의 모든 프로세스를 적용할 수 있다. 상이한 로직이 메모리/프로세싱 유닛의 메모리 뱅크에 결합되고 벡터에 수학적 연산을 수행(바람직 하게 병렬)하여 처리된 벡터를 생성할 수 있다. 하나의 로직은 다른 로직으로 벡터를 전송할 수 있고(도 89g의 예시 라인 참조), 다른 로직은 수신된 벡터 및 스스로 계산한 벡터에 수학적 연산을 적용할 수 있다. 로직은 계층으로 배치될 수 있고, 특정 레벨의 로직은 이전 레벨의 로직으로부터의 벡터 또는 중간 결과(수학적 연산을 적용을 생성)를 처리할 수 있다. 처리된 벡터의 총 사이즈가 결과의 총 사이즈를 초과하는 경우, 출력 대역폭(메모리/프로세싱 유닛으로부터의 출력 대역폭)의 감소가 확보된다. 예를 들어, 메모리/프로세싱 유닛에 의해 K개의 벡터가 합산되어 단일 출력 벡터를 제공하는 경우, 대역폭의 K:1 감소가 확보된다. 컨트롤러는 접근될 상이한 벡터들의 주소를 방송함으로써 병렬로 다중 메모리 뱅크를 개방하도록 구성될 수 있다. 컨트롤러는 문장의 단어 또는 구절의 순서에 적어도 부분적으로 의거하여 다중 메모리 뱅크로부터(또는 상이한 벡터를 저장하는 임의의 중간 버퍼 또는 스토리지 회로; 도 89d의 버퍼 참조) 상이한 벡터를 검색하는 순 서를 제어하도록 구성될 수 있다. 컨트롤러는 벡터의 메모리/프로세싱 유닛 외부 출력에 관한 하나 이상의 파라미터에 의거하여 상이 한 벡터의 검색을 관리하도록 구성될 수 있다. 예를 들어, 메모리 뱅크로부터의 상이한 벡터의 검색 속도는 메 모리/프로세싱 유닛으로부터 상이한 벡터를 출력하는 허용 속도와 실질적으로 동일하도록 설정될 수 있다. 컨트롤러는 임의의 트래픽 형성 프로세스를 적용하여 메모리/프로세싱 유닛 외부로 상이한 벡터를 출력할 수 있다. 예를 들어, 컨트롤러는 호스트 컴퓨터 또는 메모리/프로세싱 유닛을 호스트 컴퓨터로 결 합시키는 링크에 의해 허용 가능한 최대 속도와 최대한 근접한 속도로 상이한 벡터를 출력하려고 겨냥할 수 있 다. 다른 예를 들면, 컨트롤러는 시간에 따른 트래픽 속도 변동을 최소화 또는 적어도 실질적으로 감소시키면서상이한 벡터를 출력할 수 있다. 컨트롤러는 메모리 뱅크 및 로직과 동일한 집적회로에 속할 수 있고, 따라서 상이한 벡터의 검색 상태(예: 벡터가 준비되었는지 여부, 벡터가 준비되었지만 동일한 메모리 뱅크로부터 다른 벡터가 검색되 고 있거나 검색되기 직전인지 여부 등)에 관한 피드백을 상이한 로직/메모리 뱅크로부터 수월하게 수신할 수 있 다. 피드백은 임의의 모든 방식으로, 예컨대, 전용 컨트롤 라인, 공유 컨트롤 라인 등을 통해, 상태 비트 등을 활용하여, 제공될 수 있다(도 89f의 상태 라인 참조). 컨트롤러는 상이한 벡터의 검색과 출력을 독립적으로 제어할 수 있고, 따라서 호스트 컴퓨터의 개입을 줄 일 수 있다. 대안적으로, 호스트 컴퓨터는 컨트롤러의 관리 능력을 인식하지 못할 수 있고 계속해서 상세 지시 를 전송할 수 있다. 이 경우, 메모리/프로세싱 유닛은 상세 지시를 무시하고 컨트롤러의 관리 능력을 숨 기는 등을 할 수 있다. 앞서 설명한 솔루션은 호스트 컴퓨터에 의해 관리 가능한 프로토콜에 의거하여 사용될 수 있다. 메모리/프로세싱 유닛에서 프로세싱 동작을 수행하는 것은 이러한 동작이 호스트 내의 프로세싱 동작보다 전력 소비가 많은 경우에도, 심지어 이러한 동작이 호스트와 메모리/프로세싱 유닛 사이의 전달 동작보다 전력 소비 가 많은 경우에도, 매우 이점이 있는(에너지 측면에서) 것이 발견되었다. 예를 들어, 벡터가 충분히 크다는 가 정 하에, 예컨대 데이터 단위를 전송하는 에너지 소비는 4pJ이고 데이터 단위의 (호스트에 의한) 처리 동작의 에너지 소비는 0.1pJ이라고 하면, 메모리/프로세싱 유닛에 의한 데이터 단위의 처리는 메모리/프로세싱 유닛에 의한 데이터 단위의 처리의 에너지 소비가 5pJ 미만이었을 때 더 효과적이었다. 각 벡터(문장을 나타내는 행렬의 벡터)는 단어의 시퀀스(또는 다른 다중 비트 세그먼트)로 나타내어질 수 있다. 설명의 편의상, 다중 비트 세그먼트는 단어인 것으로 가정한다. 벡터가 0 값 단어를 포함하는 경우에 추가적인 전력 감소가 확보될 수 있다. 0 값 단어 전체를 출력하는 대신에, 단어보다 짧은(예: 1비트) 0 값 플래그(전용 컨트롤 라인으로 전달되기도 함)가 출력될 수 있다. 플래 그는 다른 값(예: 1값을 가진 단어)에 할당될 수 있다. 도 88a는 임베딩을 위한 방법을 도시한 것으로서, 특징 벡터 관련 정보를 검색하는 방법일 수도 있다. 이 러한 특징 벡터 관련 정보는 특징 벡터 및/또는 이러한 특징 벡터의 처리 결과를 포함할 수 있다. 방법은 다중 문장 세그먼트에 매핑될 수 있는 다중 요청된 특징 벡터의 검색을 위한 검색 정보를 메모리 프로세싱 집적회로가 수신하는 단계 9410으로 시작할 수 있다. 메모리 프로세싱 유닛은 컨트롤러, 다중 프로세서 서브유닛, 및 다중 메모리 유닛을 포함할 수 있다. 각각의 메 모리 유닛은 프로세서 서브유닛에 결합될 수 있다. 단계 9410 이후에, 다중 메모리 유닛의 적어도 일부로부터 다중 요청된 특징 벡터를 검색하는 단계 9420이 수행 될 수 있다. 검색은 둘 이상의 메모리 유닛으로부터 둘 이상의 메모리 유닛에 저장된 요청된 특징 벡터의 요청을 포함할 수 있다. 요청은 문장 세그먼트와 문장 세그먼트에 매핑된 특징 벡터의 위치 사이의 알려진 매핑에 의거하여 실행될 수 있다. 매핑은 메모리 프로세싱 집적회로의 부팅 과정 중에 업로드될 수 있다. 한 번에 최대한 많은 요청된 특징 벡터를 검색하는 것이 유리할 수 있지만, 이는 요청된 특징 벡터가 저장된 위 치와 상이한 메모리 유닛의 수에 달려있다. 하나보다 많은 요청된 특징 벡터가 동일 메모리 뱅크에 저장되어 있는 경우, 예측 검색이 적용되어 메모리 뱅크 로부터의 정보 검색과 연관된 페널티를 줄일 수 있다. 페널티 감소를 위한 다양한 방법이 본 출원의 다양한 부 분에 도시되어 있다. 검색은 단일 메모리 유닛에 저장된 한 세트의 요청된 특징 벡터의 적어도 일부 요청된 특징 벡터의 예측 검색을 적용하는 것이 포함될 수 있다. 요청된 특징 벡터는 최적의 방식으로 메모리 유닛 사이에 분산될 수 있다. 요청된 특징 벡터는 예상되는 검색 패턴에 의거하여 메모리 유닛 사이에 분산될 수 있다. 다중 요청된 특징 벡터의 검색은 특정 순서에 따라, 예를 들면, 하나 이상의 문장의 문장 세그먼트의 순서에 따 라 실행될 수 있다. 다중 요청된 특징 벡터의 검색은 적어도 부분적으로는 순서 없이 실행될 수 있고, 여기서 검색은 다중 요청된 특징 벡터의 순서를 재배열하는 것을 더 포함할 수 있다. 다중 요청된 특징 벡터의 검색은 다중 요청된 특징 벡터가 컨트롤러에 의해 읽히기 전에 다중 요청된 특징 벡터 의 버퍼링을 포함할 수 있다. 다중 요청된 특징 벡터의 검색은 다중 메모리 유닛과 연관된 하나 이상의 버퍼가 하나 이상의 요청된 특징 벡터 를 저장하는 경우를 지시하는 버퍼 상태 지시자의 생성을 포함할 수 있다. 방법은 전용 컨트롤 라인을 통해 버퍼 상태 지시자를 전달하는 단계를 포함할 수 있다. 전용 컨트롤 라인은 메모리 유닛별로 할당될 수 있다. 버퍼 상태 지시자는 하나 이상의 버퍼에 저장된 상태 비트일 수 있다. 방법은 하나 이상의 공유 컨트롤 라인을 통해 버퍼 상태 지시자를 전달하는 단계를 포함할 수 있다. 단계 9420 이후에, 다중 요청된 특징 벡터를 처리하여 프로세싱 결과를 제공하는 단계 9430이 수행될 수 있다. 추가적으로 또는 대안적으로, 단계 9420 이후에, (a) 요청된 특징 벡터 및 (b) 요청된 특징 벡터의 처리 결과 중의 적어도 하나를 포함할 수 있는 출력을 메모리 프로세싱 집적회로로부터 출력하는 단계 9440이 수행될 수 있다. (a) 요청된 특징 벡터 및 (b) 요청된 특징 벡터의 처리 결과 중의 적어도 하나는 특징 벡터 관련 정보로 도 지칭된다. 단계 9430이 실행되는 경우, 단계 9440은 (적어도) 요청된 특징 벡터의 처리 결과를 출력하는 단계를 포함할 수 있다. 단계 9430을 건너뛰는 경우, 단계 9440은 요청된 특징 벡터를 출력하는 단계를 포함하고 요청된 특징 벡터의 처 리 결과를 출력하는 단계를 포함하지 않을 수 있다. 도 88b는 임베딩을 위한 방법을 도시한 것이다. 출력은 요청된 특징 벡터를 포함하지만 요청된 특징 벡터를 처리한 결과는 포함하지 않는 것으로 가정한다. 방법은 다중 문장 세그먼트에 매핑될 수 있는 다중 요청된 특징 벡터의 검색을 위한 검색 정보를 메모리 프로세싱 집적회로가 수신하는 단계 9410으로 시작할 수 있다. 단계 9410 이후에, 다중 메모리 유닛의 적어도 일부로부터 다중 요청된 특징 벡터를 검색하는 단계 9420이 수행 될 수 있다. 단계 9420 이후에, 요청된 특징 벡터를 포함하지만 요청된 특징 벡터를 처리한 결과를 포함하지 않는 출력을 메 모리 프로세싱 집적회로로부터 출력하는 단계 9431이 수행될 수 있다. 도 88c는 임베딩을 위한 방법을 도시한 것이다. 출력은 요청된 특징 벡터를 처리한 결과를 포함하는 것으로 가정한다. 방법은 다중 문장 세그먼트에 매핑될 수 있는 다중 요청된 특징 벡터의 검색을 위한 검색 정보를 메모리 프로세싱 집적회로가 수신하는 단계 9410으로 시작할 수 있다. 단계 9410 이후에, 다중 메모리 유닛의 적어도 일부로부터 다중 요청된 특징 벡터를 검색하는 단계 9420이 수행 될 수 있다. 단계 9420 이후에, 다중 요청된 특징 벡터를 처리하여 프로세싱 결과를 제공하는 단계 9430이 수행될 수 있다. 단계 9430 이후에, 요청된 특징 벡터를 처리한 결과를 포함할 수 있는 출력을 메모리 프로세싱 집적회로로부터 출력하는 단계 9442가 수행될 수 있다. 출력을 출력하는 단계는 출력에 트래픽 성형(traffic shaping)을 적용하는 단계를 포함할 수 있다. 출력을 출력하는 단계는 메모리 프로세싱 집적회로를 리퀘스터 유닛에 결합시키는 링크를 통해, 출력 과정에서 사용된 대역폭을 최대 허용 대역폭에 일치시키려고 시도하는 단계를 포함할 수 있다. 출력을 출력하는 단계는 출력 트래픽 속도의 변동을 임계값 이하로 유지하려고 시도하는 단계를 포함할 수 있다. 검색하는 단계 및 출력하는 단계 중의 임의의 단계는 호스트의 제어 하에 및/또는 컨트롤러에 의해 독립적으로 또는 일부 독립적으로 실행될 수 있다. 호스트는 다중 메모리 유닛 내의 요청된 특징 벡터의 위치와 무관한 일반 검색 정보의 전송부터 다중 메모리 유 닛 내의 요청된 특징 벡터의 위치와 의거한 상세 검색 정보의 전송에 이르는 상이한 입도의 검색 명령을 전송할 수 있다. 호스트는 메모리 프로세싱 집적회로 이내의 상이한 검색 동작의 타이밍을 제어(또는 제어 시도)할 수 있지만 이 러한 타이밍에 대해 개의치 않을 수도 있다. 컨트롤러는 호스트에 의해 다양한 레벨에서 제어될 수 있고, 심지어 호스트의 상세 명령을 무시하고 적어도 검 색 및/또는 출력을 독립적으로 제어할 수도 있다. 요청된 특징 벡터의 처리는 하나 이상의 메모리/프로세싱 유닛 및 하나 이상의 메모리/프로세싱 유닛 외부에 위 치한 하나 이상의 프로세서 등 중의 적어도 하나(또는 이들의 조합)에 의해 실행될 수 있다. 여기서, 요청된 특징 벡터의 처리는 하나 이상의 프로세서 서브유닛, 컨트롤러, 하나 이상의 벡터 프로세서, 및 하나 이상의 메모리/프로세싱 유닛 외부에 위치한 하나 이상의 메모리/프로세싱 유닛 등 중의 적어도 하나(또는 이들의 조합)에 의해 실행될 수 있다. 요청된 특징 벡터의 처리는 다음 중의 임의의 하나 또는 그 조합에 의해 실행되고 생성될 수 있다. a. 메모리/프로세싱 유닛의 프로세서 서브유닛(또는 로직) b. 다중 메모리/프로세싱 유닛의 프로세서 서브유닛(또는 로직) c. 메모리/프로세싱 유닛의 컨트롤러 d. 다중 메모리/프로세싱 유닛의 컨트롤러 e. 메모리/프로세싱 유닛의 하나 이상의 벡터 프로세서 f. 다중 메모리/프로세싱 유닛의 하나 이상의 벡터 프로세서 따라서, 요청된 특징 벡터의 처리는 (a) 하나 이상의 메모리/프로세싱 유닛들의 하나 이상의 컨트롤러들, (b) 하나 이상의 메모리/프로세싱 유닛들의 하나 이상의 프로세서 서브유닛들, (c) 하나 이상의 메모리/프로세싱 유 닛들의 하나 이상의 벡터 프로세서들, 및 (d) 하나 이상의 메모리/프로세싱 유닛들의 외부에 위치한 하나 이상 의 다른 프로세서들 등의 임의의 조합 또는 하부 조합에 의해 실행될 수 있다. 둘 이상의 프로세싱 엔티티들에 의해 실행되는 처리는 분산 프로세싱으로 지칭될 수 있다. 메모리/프로세싱 유닛은 다중 프로세서 서브유닛을 포함할 수 있다. 프로세서 서브유닛들은 서로 독립적으로 동 작, 서로 부분적으로 협력, 분산 프로세싱에 가담 등이 가능하다. 프로세싱은 모든 프로세서 서브유닛이 동일한 동작을 수행하는(및 동작들 사이에 프로세싱의 결과를 출력하거나 출력하지 않을 수 있는) 플랫 방식으로 실행될 수 있다. 프로세싱은 상이한 레벨의 프로세싱 동작의 시퀀스가 포함되는 계층 방식으로 실행될 수 있다. 여기서, 특정 층 의 프로세싱 동작은 다른 레벨의 프로세싱 동작을 뒤따른다. 프로세서 서브유닛들은 상이한 층들에 할당(동적 또는 정적)되고 계층 프로세싱에 가담할 수 있다. 요청된 특징 벡터의 프로세싱은 둘 이상의 프로세싱 엔티티(프로세서 서브유닛, 컨트롤러, 벡터 프로세서, 기타 프로세서)에 의해 실행될 수 있고, 임의의 모든 방식(플랫, 계층, 또는 기타 방식)으로 분산 프로세싱 될 수 있 다. 예를 들어, 프로세서 서브유닛들이 그 처리 결과를 컨트롤러로 출력하고, 컨트롤러는 그 결과를 더 처리할 수 있다. 하나 이상의 메모리/프로세싱 유닛의 외부에 위치한 하나 이상의 다른 프로세서는 메모리 프로세싱 집 적회로의 출력을 더 처리할 수 있다. 여기서, 검색 정보는 문장 세그먼트에 매핑되지 않은 요청된 특징 벡터의 검색을 위한 정보도 포함할 수 있다. 이러한 특징 벡터는 문장 세그먼트에 관련될 수 있는 하나 이상의 사람, 장치, 또는 임의의 다른 엔티티에 매핑 될 수 있다. 예를 들면, 문장 세그먼트를 감지한 장치의 사용자, 문장 세그먼트를 감지한 장치, 문장 세그먼트 의 소스로 식별된 사용자, 문장 생성 당시에 접속된 웹 사이트, 문장이 캡처된 장소 등이 여기에 포함될 수 있 다. 방법(9400, 9401, 9402)은 문장 세그먼트에 매핑되지 않은 요청된 검색 벡터 및/또는 프로세싱에 준용하여 적용 가능하다. 특징 벡터의 프로세싱 예에는 합산, 가중 합산, 평균, 감산, 또는 임의의 모든 다른 수학적 함수의 적용이 포함 될 수 있으며 이에 한정되지 않는다. 하이브리드 장치 프로세서 속도와 메모리 사이즈가 모두 지속적으로 증가함에 따라, 효과적인 처리 속도에 대한 중대한 한계는 폰노이만 병목현상이다. 폰노이만 병목현상은 기존의 컴퓨터 아키텍처의 스루풋 한계에서 기인한다. 특히, 프로 세서에 의해 수행되는 실제 계산에 비해 메모리(즉, 외부 DRAM 메모리와 같은 로직 다이 외부의 메모리)로부터 프로세서로의 데이터 전송에 병목이 생기는 경우가 많다. 이에 따라, 메모리 집약적 처리에서는 메모리에 읽기 와 쓰기를 위한 클럭 사이클의 수가 상당히 증가한다. 클럭 사이클이 메모리에 읽기와 쓰기에 소비되고 데이터 에 대한 연산을 수행하는데 활용될 수 없으므로, 그 결과 효과적인 처리 속도에 손실이 발생한다. 또한, 프로세 서의 계산 대역폭은 일반적으로 프로세서가 메모리에 접근하기 위해 사용하는 버스의 대역폭보다 크다. 이러한 병목현상은 신경망 및 기타 머신러닝 알고리즘과 같은 메모리 집약적 프로세스, 데이터베이스 구성, 색 인 검색, 쿼리 작업, 및 데이터 처리 연산보다 더 많은 읽기와 쓰기 동작을 포함하는 기타 작업에서 특히 확연 하다. 본 개시는 앞서 종래 기술의 다른 문제들 중에서 앞서 나열한 하나 이상의 문제를 완화 또는 극복하기 위한 해 법을 기재한다. 메모리 집약적 프로세싱을 위한 하이브리드 장치가 제공될 수 있고, 하이브리드 장치는 베이스 다이(base die), 다중 프로세서, 적어도 하나의 다른 다이의 제1 메모리 리소스, 및 적어도 하나의 또 다른 다이의 제2 메모리 리소스를 포함할 수 있다. 베이스 다이와 적어도 하나의 다른 다이는 웨이퍼 온 웨이퍼 접합(wafer on wafer bonding)에 의해 서로 연결된 다. 다중 프로세서는 프로세싱 동작을 수행하고 제1 메모리 리소스에 저장된 검색된 정보를 검색하도록 구성된다. 제2 메모리 리소스는 제2 메모리 리소스에서 제1 메모리 리소스로 추가 정보를 전송하도록 구성된다. 베이스 다이와 적어도 하나의 다른 다이 사이의 제1 경로의 전반적인 대역폭은 적어도 하나의 다른 다이와 적어 도 하나의 또 다른 다이 사이의 제2 경로의 대역폭보다 크고, 제1 메모리 리소스의 저장 용량은 제2 메모리 리 소스의 저장 용량보다 몇 배 작다. 제2 메모리 리소스는 고대역폭 메모리(HBM) 리소스이다. 적어도 하나의 또 다른 다이는 고대역폭 메모리(HBM) 칩의 적층이다. 제2 메모리 리소스의 적어도 일부는 웨이퍼 투 웨이퍼 접합과 다른 연결성에 의해 베이스 다이로 연결되는 또 다른 다이에 속할 수 있다. 제2 메모리 리소스의 적어도 일부는 웨이퍼 투 웨이퍼 접합과 다른 연결성에 의해 다른 다이로 연결되는 또 다 른 다이에 속할 수 있다. 제1 메모리 리소스와 제2 메모리 리소스는 서로 상이한 레벨의 캐시 메모리이다. 제1 메모리 리소스는 베이스 다이와 제2 메모리 리소스 사이에 위치한다. 제1 메모리 리소스는 제2 메모리 리소스의 옆에 위치한다. 다른 다이는 추가적인 프로세싱을 수행하도록 구성되고, 다른 다이는 복수의 프로세서 서브유닛과 제1 메모리 리소스를 포함한다. 각 프로세서 서브유닛은 프로세서 서브유닛에 할당된 제1 메모리 리소스의 고유 부분에 결합된다. 제1 메모리 리소스의 고유 부분은 적어도 하나의 메모리 뱅크이다. 다중 프로세서는 제1 메모리 리소스도 포함하는 메모리 프로세싱 칩에 포함된 복수의 프로세서 서브유닛이다. 베이스 다이는 다중 프로세서를 포함하고, 다중 프로세서는 웨이퍼 투 웨이퍼 접합에 형성된 컨덕터를 통해 결 합된 복수의 프로세서 서브유닛이다. 각 프로세서 서브유닛은 프로세서 서브유닛에 할당된 제1 메모리 리소스의 고유 부분에 결합된다. 하나 이상의 또 다른 다이에 포함되고 웨이퍼 온 웨이퍼(WOW) 연결성과 다른 연결성을 활용하여 연결되는 제2 메모리 리소스에 베이스 다이의 적어도 일 부분을 WOW 연결성을 활용하여 결합시킬 수 있는 하이브리드 집적회 로가 제공될 수 있다. 제2 메모리 리소스의 일례는 고대역폭 메모리(HBM) 리소스일 수 있다. 다양한 도면에서, 제2 메모리 리소스는 실리콘관통전극(through silicon via 또는 TSV) 연결성을 활용하여 컨트롤러에 결합될 수 있는 HBM 메모리 유닛의 적층에 포함된다. 컨트롤러는 베이스 다이에 포함되거나 베이스 다이의 적어도 일부에 결합된다(예: 마이크로 범프를 통해). 베이스 다이는 로직 다이일 수 있지만 메모리/프로세싱 유닛일 수도 있다. WOW 연결성은 베이스 다이의 하나 이상의 부분을 메모리 다이 또는 메모리/프로세싱 유닛일 수 있는 다른 다이 (WOW 연결된 다이)의 하나 이상의 부분으로 결합시키는 데에 활용될 수 있다. WOW 연결성은 매우 높은 스루풋 연결성이다. 고대역폭 메모리(HBM) 칩의 적층은 베이스 다이에 결합될 수 있고(직접 또는 WOW 연결된 다이를 통해) 고 스루 풋 연결과 매우 확장된 메모리 리소스를 제공할 수 있다. WOW 연결된 다이는 HBM 칩의 적층과 베이스 다이 사이에 결합되어 TSV 연결성이 있고 하부에 WOW 연결된 다이가 있는 HBM 메모리 칩 적층을 형성할 수 있다. TSV 연결성이 있고 하부에 WOW 연결된 다이가 있는 HBM 칩 적층은 WOW 연결된 다이가 베이스 다이로 접근될 수 있는 하위 레벨 메모리(예: 레벨 3 캐시)로 사용될 수 있는 다층 메모리 계층을 제공할 수 있고, 여기서 고위 레벨 HBM 메모리 적층으로부터의 페치(fetch) 및/또는 프리페치(pre-fetch) 동작이 WOW 연결된 다이를 채운다. HBM 메모리 칩은 HBM DRAM 칩일 수 있지만, 임의의 모든 다른 메모리 기술이 사용될 수 있다. WOW 연결성과 HBM 칩을 조합하여 활용하면 대역폭과 메모리 밀도 사이의 균형을 제공할 수 있는 다중 메모리 층 을 포함할 수 있는 다중 레벨 메모리 구조를 제공할 수 있다. 제시된 솔루션은 종래의 DRAM 메모리/HBM과 로직 다이의 내부 캐시 사이의 추가적이고 완전히 새로운 메모리 계 층의 역할을 할 수 있다. 이는 빠른 방식으로 메모리 읽기를 더 잘 관리하는 DRAM 상의 새로운 메모리 계층을 제공할 수 있다. 도 93a 내지 도 93i는 각각 하이브리드 집적회로(11011'-11019')를 도시한 것이다. 도 93a는 TSV를 활용하여 서로 연결되고 베이스 다이의 제1 메모리 컨트롤러에 연결되는 HDM DRAM 메모리 칩의 적층을 포함하는, TSV 연결성이 있고 최하위 레벨에 마이크로 범프가 있는 HBM DRAM 적층(집합적으로 11030으로 표시)을 도시하고 있다. 도 93a는 또한 하나 이상의 WOW 중간층을 통해 DRAM 웨이퍼에 결합된 베이스 다이의 제2 메모리 컨트롤러를 포함하는, 적어도 메모리 리소스가 있고 WOW 기술을 활용하여 결합되는 웨이퍼(집합 적으로 11040으로 표시)를 도시하고 있다. 하나 이상의 WOW 중간층은 상이한 물질로 구성될 수 있지만 패드 연 결성 및/또는 TSV 연결성과 다를 수 있다. 컨덕터(11022')는 하나 이상의 WOW 중간층을 통과하고 DRAM 다이를 베이스 다이의 컴포넌트에 전기적으로 결합 시킨다. 베이스 다이는 인터포저에 결합되고, 이어서 인터포저는 마이크로 범프를 활용하여 패키 지 기판에 결합된다. 패키지 기판의 하면에는 마이크로 범프의 어레이가 있다. 마이크로 범프는 다른 연결성으로 대체될 수 있다. 인터포저와 패키지 기판은 다른 층으로 대체 될 수 있다. 제1 메모리 컨트롤러 및/또는 제2 메모리 컨트롤러는 베이스 다이의 외부에 (적어도 부분 적으로), 예컨대 DRAM 웨이퍼 내, DRAM 웨이퍼와 베이스 다이 사이, HBM 메모리 유닛의 적층과 베이스 다이 사 이 등에 위치할 수 있다. 제1 메모리 컨트롤러 및 제2 메모리 컨트롤러는 동일 컨트롤러에 속하거나 상이한 컨트롤러에 속 할 수 있다. HBM 메모리 유닛의 하나 이상은 로직은 물론 메모리도 포함할 수 있고, 메모리/프로세싱 유닛일 수 있거나 메모 리/프로세싱 유닛을 포함할 수 있다. 제1 및 제2 메모리 컨트롤러는 제1 메모리 리소스와 제1 메모리 리소스 사이에 정보를 전달하기 위하여 다중 버 스에 의해 서로 결합될 수 있다. 도 93a는 또한, 제2 메모리 컨트롤러로부터 베이스 다이의 컴포넌트(예: 다중 프로세서)로의 버스를 도시하고 있다. 도 93a에는 또한 제1 메모리 컨트롤러로부터 베이스 다이의 컴포넌트(예: 도 93c에 도시된 바와 같은 다중 프로세서)로의 버스가 도시되어 있다. 도 93b는 DRAM 다이 대신에 메모리/프로세싱 유닛(11021')을 구비함으로써 도 93a의 하이브리드 집적회 로와 다른 하이브리드 집적회로를 도시한 것이다. 도 93c는 HBM 메모리 유닛의 적층과 베이스 다이 사이에 DRAM 다이를 포함하는, TSV 연결성이 있 고 하부에 WOW 연결된 다이가 있는 HBM 메모리 칩 적층(집합적으로 11040으로 표시)이 있는 점에서 도 93a의 하 이브리드 집적회로와 차이가 있는 하이브리드 집적회로를 도시한 것이다. DRAM 다이는 WOW 기술을 활용하여(WOW 중간층 참조) 베이스 다이의 제1 메모리 컨트롤러 에 결합된다. HBM 메모리 다이의 하나 이상은 로직과 메모리를 모두 포함할 수 있고 메모리/프로 세싱 유닛이거나 메모리/프로세싱 유닛을 포함할 수 있다. 최하단의 DRAM 다이(도 93c에 DRAM 다이로 도시)는 HBM 메모리 다이이거나 HBM 메모리 다이와 다를 수 있다. 도 93d의 하이브리드 집적회로에 도시된 바와 같이, 최하단의 DRAM 다이(DRAM 다이)는 메 모리/프로세싱 유닛(11021')으로 대체될 수 있다. 도 93e 내지 도 93g는 각각 하이브리드 집적회로(11015, 11016, 11016')를 도시한 것으로서, 베이스 다이 가 TSV 연결성과 최하위 레벨에 마이크로 범프가 있는 HBM DRAM 적층과 적어도 메모리 리소스가 있고 WOW 기술을 활용하여 결합된 웨이퍼의 다중 인스턴스 및/또는 TSV 연결성과 하부에 WOW 연결된 다 이가 있는 HBM 메모리 칩 적층의 다중 인스턴스에 결합된다. 도 93h는 메모리 유닛, 레벨 2 캐시 메모리(L2 캐시) 및 다중 프로세서를 도시함으로써 도 93d의 하이브리드 집적회로와 차이가 있는 하이브리드 집적회로(11014')를 도시한 것이다. 다중 프로세 서는 L2 캐시에 결합되고 메모리 유닛과 L2 캐시에 저장된 계수 및/또는 데이터에 의해 공급될 수 있다. 상기 하이브리드 집적회로의 임의의 하이브리드 집적회로는 대역폭 집약적인 인공지능(AI) 프로세싱에 활용될 수 있다. 도 93d와 도 93h의 메모리/프로세싱 유닛(11021')은 WOW 기술로 메모리 컨트롤러에 결합되는 경우에 AI 계산을 수행할 수 있고 HBM DRAM 적층 및/또는 WOW 연결된 다이로부터 매우 빠른 속도로 데이터와 계수를 모두 수신할 수 있다. 임의의 모든 메모리/프로세싱 유닛은 분산 메모리 어레이 및 프로세서 어레이를 포함할 수 있다. 분산 메모리 어레이 및 프로세서 어레이는 다중 메모리 뱅크와 다중 프로세서를 포함할 수 있다. 다중 프로세서는 프로세싱 어레이를 형성할 수 있다. 도 93c, 도 93d, 및 도 93h를 참조하고, 하이브리드 집적회로(11013, 11014, 또는 11014')가 행렬을 벡터로 곱 하는 계산을 포함하는 GEMV(general matrix-vector multiplications)를 실행하도록 요구된다고 가정하면, 이런 유형의 계산은 검색된 행렬 데이터를 재사용하지 않기 때문에 대역폭 집약적이다. 따라서, 전체 행렬이 검색되 어야 하고 한 번만 사용된다. GEMV는 (i) 제1 행렬(A)을 제1 벡터(V1)로 곱하여 제1 중간 벡터를 제공하고, 제1 중간 벡터에 제1 비선형 연산 (NLO1)을 적용하여 제1 중간 결과를 제공하고, (ii) 제2 행렬(B)을 제1 중간 결과로 곱하여 제2 중간 벡터를 제 공하고, 제2 중간 벡터에 제2 비선형 연산(NLO2)을 적용하여 제2 중간 결과를 제공하는 등(N은 2보다 큰, 제N 중간 결과를 수신할 때까지)을 포함하는 수학적 연산 시퀀스의 일부일 수 있다. 각 행렬이 크다고(예: 1 기가비트) 가정하면, 계산에는 1 테라비트의 연산 파워가 필요하고 1 테라비트의 대역 폭/스루풋이 필요하다. 연산과 계산은 병렬로 실행될 수 있다. GEMV 계산이 N=4를 나타내고 다음의 형태를 가진다고 가정한다: 결과 = NLO4(D*(NLO3(C*(NLO2(B*(NLO1(A*V1))))))). 또한, DRAM 다이(또는 메모리/프로세싱 유닛(11021')은 A, B, C, D를 동시에 저장하기에 메모리가 충분 하지 않은 것으로 가정하면, 이러한 행렬들의 적어도 일부는 HDM DRAM 다이에 저장되게 된다. 베이스 다이는 프로세서, ALU 등과 같은 계산 유닛을 포함하는 로직 다이인 것으로 가정한다. 제1 다이가 A*V1를 계산하는 동안, 제1 메모리 컨트롤러는 다음 계산을 위해 다른 행렬의 빠진 부분들을 하나 이상의 HBM DRAM 다이로부터 검색한다. 도 93h를 참조하고 (a) DRAM 다이는 대역폭이 2 TB이고 용량이 512 Mb이고, (b) HBM DRAM 다이 는 대역폭이 0.2 TB이고 용량이 8 Gb이고, (c) L2 캐시는 대역폭이 6 TB이고 용량이 10 Mb인 SRAM인 것으로 가정한다. 행렬의 곱셈은 데이터의 재사용, 즉, 큰 행렬을 세그먼트 (예: 이중 버퍼 구성에서 사용될 수 있는 L2 캐시에 들어가도록 5 Mb 세그먼트)로 나누고 제1 행렬 세그먼트를 제2 행렬의 세그먼트들(다른 행렬 세그먼트 뒤에 제2 행렬 세그먼트)로 곱하는 것을 포함할 수 있다. 제1 행렬 세그먼트를 제2 행렬 세그먼트로 곱하는 동안, 다른 제2 행렬 세그먼트가 (메모리 프로세싱 유닛 (11021')의) DRAM 다이로부터 L2 캐시로 페치된다. 행렬이 각각 1 Gb인 것으로 가정하면, 페치 동작과 계산이 실행되는 동안에 DRAM 다이 또는 메모리/프로 세싱 유닛(11021')이 HBM DRAM 다이로부터 행렬 세그먼트에 의해 공급된다. DRAM 다이 또는 메모리/프로세싱 유닛(11021')은 행렬 세그먼트를 합하고, 행렬 세그먼트들은 WOW 중간 층을 통해 베이스 다이로 공급된다. 메모리/프로세싱 유닛(11021')은 결과를 제공하도록 계산되는 중간값을 전송하는 대신에 계산을 수행하고 결과 를 전송하여 WOW 중간층을 통해 베이스 다이로 전송되는 정보의 양을 줄일 수 있다. 다중(Q) 중 간값이 처리되어 결과가 제공되는 경우, 압축비는 Q:1이 될 수 있다. 도 93i는 WOW 기술로 구현되는 메모리 프로세싱 유닛(11019')의 일례를 도시한 것이다. 로직 유닛(프로세 서 서브유닛일 수 있음), 컨트롤러, 및 버스가 제1 칩 내에 위치하고 있고, 상이한 로직 유 닛에 할당된 메모리 뱅크가 제2 칩 내에 위치하고 있다. 여기서, 제1 칩과 제2 칩은 하나 이상의 WOW 중간층을 포함할 수 있는 WOW 접합을 통과하는 컨덕터(11012')를 활용하여 서로 연결된다. 도 93j는 메모리 집약적 프로세싱을 위한 방법의 일례이다. 메모리 집약적이란 프로세싱이 높은 대역폭 메모리 소비를 필요로 하거나 높은 대역폭 메모리 소비와 연관됨을 의미한다. 방법은 단계 11110, 단계 11120, 및 단계 11130으로 시작할 수 있다. 단계 11110은 베이스 다이, 적어도 하나의 다른 다이의 제1 메모리 리소스, 및 적어도 하나의 또 다른 다이의 제2 메모리 리소스를 포함하는 하이브리드 장치의 다중 프로세서가 프로세싱 동작을 수행하는 단계를 포함하고, 여기서 베이스 다이와 적어도 하나의 다른 다이는 웨이퍼 온 웨이퍼 접합에 의해 서로 연결된다. 단계 11120은 다중 프로세서가 제1 메모리 리소스에 저장된 검색된 정보를 검색하는 단계를 포함한다. 단계 11130은 제2 메모리 리소스에서 제1 메모리 리소스로 추가 정보를 전송하는 단계를 포함할 수 있고, 여기 서 베이스 다이와 적어도 하나의 다른 다이 사이의 제1 경로의 전반적인 대역폭은 적어도 하나의 다이와 적어도 하나의 또 다른 다이 사이의 제2 경로의 전반적인 대역폭보다 크고, 제1 메모리 리소스의 저장 용량은 제2 메모 리 리소스의 저장 용량보다 몇 배 작다.방법 11100은 복수의 프로세서 서브유닛과 제1 메모리 리소스를 포함하는 다른 다이가 추가적인 프로세싱을 수 행하는 단계 11140을 더 포함할 수 있다. 각 프로세서 서브유닛은 해당 프로세서 서브유닛에 할당된 제1 메모리 리소스의 고유 부분에 결합될 수 있다. 제1 메모리 리소스의 고유 부분은 적어도 하나의 메모리 뱅크이다. 단계 11110, 단계 11120, 단계 11130, 및 단계 11140은 동시, 부분적으로 중첩되는 방식 등으로 실행될 수 있다. 제2 메모리 리소스는 고대역폭 메모리(HBM) 리소스이거나 HBM 메모리 리소스와 다를 수 있다. 적어도 하나의 또 다른 다이는 HBM 메모리 칩의 적층이다. 통신 칩 데이터베이스는 여러 필드를 포함하는 많은 엔트리를 포함한다. 데이터베이스 프로세싱은 하나 이상의 필터링 파라미터(예: 하나 이상의 관련 있는 필드의 식별자 또는 하나 이상의 관련 있는 필드의 값)를 포함하고 또한 실행될 동작의 유형, 동작을 적용할 때에 사용될 변수 또는 상수 등을 판단할 수 있는 하나 이상의 동작 파라미 터를 포함하는 하나 이상의 쿼리의 실행을 포함하는 것이 일반적이다. 데이터 프로세싱은 데이터베이스 분석 또 는 기타 데이터베이스 프로세스를 포함할 수 있다. 예를 들면, 데이터베이스 쿼리는 특정 필드가 소정의 범위 이내의 값을 가진(필터링 파라미터) 데이터베이스의 모든 기록에 통계적 연산을 수행(연산 파라미터)하도록 요청할 수 있다. 다른 예를 들면, 데이터베이스 쿼리는 임계값보다 작은(필터링 파라미터) 특정 필드를 가진 기록을 삭제(연산 파라미터)하도록 요청할 수 있다. 대량의 데이터베이스는 일반적으로 스토리지 장치에 저장된다. 쿼리에 응답하기 위하여, 데이터베이스는, 하나 의 데이터베이스 세그먼트씩, 메모리 유닛으로 전송된다. 데이터베이스 세그먼트의 엔트리는 메모리 유닛으로부터 메모리 유닛과 동일한 집적회로에 속하지 않는 프로세 서로 전송된다. 이후에 엔트리는 프로세서에 의해 처리된다. 메모리 유닛에 저장된 데이터베이스의 각 데이터베이스 세그먼트에 대해, 프로세싱은 다음과 같은 단계를 포함 한다: (i) 데이터베이스 세그먼트의 기록을 선택하는 단계; (ii) 기록을 메모리 유닛에서 프로세서로 전송하는 단계; (iii) 프로세서가 기록을 필터링 하여 관련이 있는 기록인지 여부를 판단하는 단계; 및 (iv) 관련 있는 기록에 하나 이상의 추가 연산(합산, 임의의 기타 수학적 및/또는 통계적 연산의 적용)을 수행하는 단계. 모든 기록이 프로세서로 전송되고 프로세서가 기록이 관련이 있는 것으로 판단하면 필터링 프로세스가 종료된다. 데이터베이스의 관련 있는 엔트리가 프로세서에 저장되어 있지 않은 경우, 필터링 단계 이후에 계속 처리되게 하기 위하여(프로세싱 후속의 연산을 적용) 이러한 관련 있는 기록을 프로세서로 전송할 필요가 있다. 다중 프로세싱 연산이 단일 필터링에 후속하는 경우, 각 연산의 결과는 메모리 유닛으로 전송될 수 있고, 이후 에 다시 프로세서로 전송될 수 있다. 이러한 프로세스는 대역폭과 시간이 많이 든다. 데이터베이스 프로세싱을 수행하는 효율적인 방식을 제공할 필요가 증가하고 있다. 데이터베이스 가속 집적회로를 포함할 수 있는 장치가 제공될 수 있다. 하나 이상의 데이터베이스 가속 집적회로 그룹의 데이터베이스 가속 집적회로들 사이에 정보 및/또는 가속 결과 (데이터베이스 가속 집적회로에 의해 수행된 프로세싱의 결과)를 교환하도록 구성될 수 있는 하나 이상의 데이 터베이스 가속 집적회로 그룹을 포함하는 장치가 제공될 수 있다. 데이터베이스 가속 집적회로 그룹의 데이터베이스 가속 집적회로들은 동일한 인쇄회로기판에 연결될 수 있다. 데이터베이스 가속 집적회로 그룹의 데이터베이스 가속 집적회로들은 전산 시스템의 모듈형 유닛에 속할 수 있 다. 상이한 그룹의 데이터베이스 가속 집적회로들은 상이한 인쇄회로기판에 연결될 수 있다. 상이한 그룹의 데이터베이스 가속 집적회로들은 전산 시스템의 상이한 모듈형 유닛에 속할 수 있다. 장치는 하나 이상의 그룹의 데이터베이스 가속 집적회로들에 의해 분산 프로세스를 실행하도록 구성될 수 있다. 장치는 하나 이상의 그룹의 상이한 그룹의 데이터베이스 가속 집적회로들 사이에 (a) 정보 및 (b) 데이터베이스 가속 결과 중의 적어도 하나를 교환하기 위해 적어도 하나의 스위치를 사용하도록 구성될 수 있다. 장치는 하나 이상의 그룹의 일부 그룹의 데이터베이스 가속 집적회로들의 일부에 의해 분산 프로세스를 실행하 도록 구성될 수 있다. 장치는 제1 데이터 구조 및 제2 데이터 구조의 분산 프로세스를 수행하도록 구성될 수 있고, 여기서 제1 데이터 구조와 제2 데이터 구조의 총 사이즈는 다중 메모리 프로세싱 집적회로의 저장 능력보다 크다. 장치는 (a) 상이한 쌍의 제1 데이터 구조 부분과 제2 데이터 구조 부분을 상이한 데이터베이스 가속 집적회로에 새롭게 할당 및 (b) 상기 상이한 쌍의 처리를 여러 번 반복 수행하여 분산 프로세스를 수행하도록 구성될 수 있 다. 도 94a와 도 94b는 스토리지 시스템, 컴퓨터 시스템, 및 데이터베이스 가속을 위한 하나 이상의 장치의 예시를 도시한 것이다. 데이터베이스 가속을 위한 하나 이상의 장치는 다양한 방식으로, 예컨대 스토리지 시스템과 컴퓨터 시스템 사이에서 탐지하거나 위치함으로써, 스토리지 시스템 과 컴퓨터 시스템 사이의 통신을 모니터 할 수 있다. 스토리지 시스템은 많은(예: 20개 이상, 50개 이상, 100개 이상 등) 스토리지 유닛(예: 디스크)을 포함 할 수 있고 예컨대 100 TB 이상의 정보를 저장할 수 있다. 컴퓨터 시스템은 방대한 컴퓨터 시스템일 수 있고 수십, 수백, 수천 개의 프로세싱 유닛을 포함할 수 있다. 컴퓨터 시스템은 매니저에 의해 제어되는 다중 컴퓨트 노드(compute nodes, 11512)를 포함할 수 있다. 컴퓨트 노드는 데이터베이스 가속을 위한 하나 이상의 장치를 제어하거나 데이터베이스 가속을 위한 하 나 이상의 장치와 상호 작용할 수 있다. 데이터베이스 가속을 위한 하나 이상의 장치는 하나 이상의 데이터베이스 가속 집적회로(예: 도 94a와 도 94b의 데이터베이스 가속 집적회로) 및 메모리 리소스를 포함할 수 있다. 메모리 리소스는 메 모리 전용의 하나 이상의 칩에 속할 수 있지만 메모리/프로세싱 유닛에 속할 수도 있다. 도 94c와 도 94d는 컴퓨터 시스템과 데이터베이스 가속을 위한 하나 이상의 장치의 예를 도시한 것이다. 데이터베이스 가속을 위한 하나 이상의 장치의 하나 이상의 데이터베이스 가속 집적회로는 컴퓨터 시스 템 내에 위치하거나(도 94c 참조) 데이터베이스 가속을 위한 하나 이상의 장치 내에 위치한(도 94d 참조) 관리 유닛에 의해 제어될 수 있다. 도 94e는 데이터베이스 가속 집적회로와 다중 메모리 프로세싱 집적회로를 포함하는 데이터베이 스 가속을 위한 장치를 도시한 것이다. 각 메모리 프로세싱 집적회로는 컨트롤러, 다중 프로세서 서브유 닛, 및 다중 메모리 유닛을 포함할 수 있다. 데이터베이스 가속 집적회로는 네트워크 통신 인터페이스, 제1 프로세싱 유닛, 메모리 컨 트롤러, 데이터베이스 가속 유닛, 인터커넥트, 및 관리 유닛을 포함하는 것으로 도시되어 있다. 네트워크 통신 네트워크는 많은 수의 스토리지 유닛으로부터 방대한 양의 정보를 수신(예: 네트워크 통 신 인터페이스의 제1 포트(11531)를 통해)하도록 구성될 수 있다. 각 스토리지 유닛은 초당 수십 및 수백 메 가바이트의 속도로 정보를 출력할 수 있고, 데이터 전송 속도는 앞으로 계속 증가할 것으로(예: 2-3년마다 2배 씩) 예상된다. 스토리지 유닛의 수는 10개, 50개, 100개, 200개, 또는 그 이상일 수 있다. 방대한 양의 정보는 초당 수십 및 수백 기가바이트 이상일 수 있고, 심지어 초당 테라바이트, 페타바이트 범위일 수 있다. 제1 프로세싱 유닛은 방대한 양의 정보를 1차 처리(프리프로세스)하여 제1 처리 정보를 제공하도록 구성 될 수 있다. 메모리 컨트롤러는 방대 스루풋 인터페이스를 통해 제1 처리 정보를 다중 메모리 프로세싱 집적 회로로 전송하도록 구성될 수 있다. 다중 메모리 프로세싱 집적회로는 다중 메모리 프로세싱 집적회로가 제1 처리 정보의 적어도 일부를 2차 처리(프로세스)하여 제2 처리 정보를 제공하도록 구성될 수 있다. 메모리 컨트롤러는 다중 메모리 프로세싱 집적회로로부터 검색된 정보를 검색하도록 구성될 수 있다. 검 색된 정보는 (a) 제1 처리 정보의 적어도 일부 및 (b) 제2 처리 정보의 적어도 일부 중의 적어도 하나를 포함할 수 있다. 데이터베이스 가속 유닛은 검색된 정보에 데이터프로세스 동작을 수행하여 데이터베이스 가속 결과를 제 공하도록 구성될 수 있다. 데이터베이스 가속 집적회로는 예컨대 네트워크 통신 인터페이스의 하나 이상의 제2 포트(11531)를 통하여 데이터베이스 가속 결과를 출력하도록 구성될 수 있다. 도 94e는 또한 검색된 정보의 검색, 1차 처리(프리프로세스), 2차 처리(프로세스), 및 3차 처리(데이터베이스 프로세싱) 중의 적어도 하나를 관리하도록 구성된 관리 유닛을 도시하고 있다. 관리 유닛은 데이 터베이스 가속 집적회로의 외부에 위치할 수 있다. 관리 유닛은 실행 계획에 의거하여 상기 관리를 수행하도록 구성될 수 있다. 실행 계획은 관리 유닛에 의해 생 성되거나 데이터베이스 가속 집적회로 외부에 위치한 엔티티에 의해 생성될 수 있다. 실행 계획은 (a) 데이터베 이스 가속 집적회로의 다양한 컴포넌트에 의해 실행될 지시, (b) 실행 계획의 이행을 위해 필요한 데이터 및/또 는 계수, 및 (c) 지시 및/또는 데이터의 메모리 할당 중의 적어도 하나를 포함할 수 있다. 관리 유닛은 (a) 네트워크 통신 네트워크 인터페이스 리소스, (b) 압축해제 유닛 리소스, (c) 메모리 컨트롤러 리소스, (d) 다중 메모리 프로세싱 집적회로 리소스, 및 (e) 데이터 가속 유닛 리소스 중의 적어도 일부를 할당 하여 관리를 수행하도록 구성될 수 있다. 도 94e와 도 94g에 도시된 바와 같이, 네트워크 통신 네트워크 인터페이스는 상이한 유형의 네트워크 통신 포트 를 포함할 수 있다. 상이한 유형의 네트워크 통신 포트는 스토리지 인터페이스 프로토콜 포트(예: SATA 포트, ATA 포트, ISCSI 포트, 네트워크 파일 포트, 파이버 채널 포트) 및 일반 네트워크를 통한 스토리지 인터페이스 프로토콜 포트(예: 이더넷을 통한 ATA, 이더넷을 통한 파이버 채널, NVME, Roce 등)를 포함할 수 있다. 상이한 유형의 네트워크 통신 포트는 스토리지 인터페이스 프로토콜 포트 및 PCIe 포트를 포함할 수 있다. 도 94f에는 방대한 정보, 제1 처리 정보, 검색된 정보, 및 데이터베이스 가속 결과의 흐름을 나타내는 점선이 도시되어 있다. 도 94f에는 데이터베이스 가속 집적회로가 다중 메모리 리소스에 결합되는 것으 로 도시되어 있다. 다중 메모리 리소스는 메모리 프로세싱 집적회로에 속하지 않을 수 있다. 데이터베이스 가속을 위한 장치는 데이터베이스 가속 집적회로가 다중 작업을 동시에 실행하도록 구성될 수 있다. 즉, 네트워크 통신 인터페이스가 정보의 다중 스트림을 (동시에) 수신할 수 있음에 따 라, 제1 프로세싱 유닛은 다중 정보 단위에 동시에 1차 처리를 수행할 수 있고, 메모리 컨트롤러(1153 3)는 다중 1차 처리 정보 단위를 동시에 다중 메모리 프로세싱 집적회로로 전송할 수 있고, 데이터베이 스 가속 유닛은 다중 검색된 정보 단위를 동시에 처리할 수 있다. 데이터베이스 가속을 위한 장치는 방대한 컴퓨터 시스템의 컴퓨트 노드에 의해 데이터베이스 가속 집적 회로로 전송된 실행 계획에 의거하여 검색, 1차 처리, 전송, 및 3차 처리 중의 적어도 하나를 실행하도록 구성 될 수 있다. 데이터베이스 가속을 위한 장치는 데이터베이스 가속 집적회로의 활용을 실질적으로 최적화하는 방식으 로 검색, 1차 처리, 전송, 및 3차 처리 중의 적어도 하나를 관리하도록 구성될 수 있다. 최적화는 지연, 스루풋, 및 임의 기타 타이밍, 스토리지, 또는 프로세싱을 고려하고 모든 컴포넌트가 흐름 경로를 따라 쉬지 않 고 병목 현상 없이 유지되도록 시도한다. 데이터베이스 가속 집적회로는, 예컨대 네트워크 통신 인터페이스의 하나 이상의 제2 포트(11531)를 통해, 데이터베이스 가속 결과를 출력하도록 구성될 수 있다. 데이터베이스 가속을 위한 장치는 네트워크 통신 네트워크 인터페이스에 의해 교환되는 트래픽의 대역폭 을 실질적으로 최적화하도록 구성될 수 있다. 데이터베이스 가속을 위한 장치는 데이터베이스 가속 집적회로의 활용을 실질적으로 최적화하는 방식으 로 검색, 1차 처리, 전송, 및 3차 처리 중의 적어도 하나에 병목이 발생하는 것을 실질적으로 방지하도록 구성 될 수 있다. 데이터베이스 가속을 위한 장치는 시간 I/O 대역폭(temporal I/O bandwidth)에 따라 데이터베이스 가속 집적회로의 리소스를 할당하도록 구성될 수 있다. 도 94g는 데이터베이스 가속 집적회로와 다중 메모리 프로세싱 집적회로를 포함하는 데이터베이 스 가속을 위한 장치를 도시한 것이다. 도 94g에는 또한 데이터베이스 가속 집적 회로에 결합된 다양한 유닛들, 예컨대 원격 RAM, 이더넷 메모리 DIMMs, 스토리지 시스템, 로컬 스토리지 유닛, 비휘발성 메모리(NVM)(비휘발성 메모리는 NVME(NVM express unit)일 수 있음) 등이 도시 되어 있다. 데이터베이스 가속 집적회로는 이더넷 포트(11531), RDMA 유닛, 직렬 스케일업 포트 (11531), SATA 컨트롤러, PCIe 포트(11531), 제1 프로세싱 유닛, 메모리 컨트롤러 , 데이터베이스 가속 유닛, 인터커넥트, 관리 유닛, 암호화 연산을 실행하기 위한 암호화 엔진, 및 레벨 2 SRAM(L2 SRAM)을 포함하는 것으로 도시되어 있다. 데이터베이스 가속 유닛은 DMA 엔진, 레벨 3(L3) 메모리, 및 데이터베이스 가속기 서브유닛 을 포함하는 것으로 도시되어 있다. 데이터베이스 가속기 서브유닛은 설정 가능한 유닛일 수 있 다. 이더넷 포트(11531), RDMA 유닛, 직렬 스케일업 포트(11531), SATA 컨트롤러, PCIe 포트 (11531)는 각각 네트워크 통신 인터페이스의 일부인 것으로 간주될 수 있다. 원격 RAM, 이더넷 메모리 DIMMs, 스토리지 시스템은 이더넷 포트(11531)에 결합되고, 이어서 이더넷 포트(11531)는 RDMA 유닛에 결합된다. 로컬 스토리지 유닛은 SATA 컨트롤러에 결합된다. PCIe 포트(11531)는 NVM에 결합된다. PCIe 포트는 예컨대 관리 목적의 명령을 교환하는 데에도 활용 될 수 있다. 도 94h는 데이터베이스 가속 유닛의 일례이다. 데이터베이스 가속 유닛은 데이터베이스 프로세싱 서브유닛이 데이터베이스 프로세스 지시를 동 시에 수행하도록 구성될 수 있고, 여기서 데이터베이스 가속 유닛은 공유 메모리 유닛을 공유하는 데이 터베이스 가속기 서브유닛의 그룹을 포함할 수 있다. 상이한 조합의 데이터베이스 가속 유닛이 동적으로 서로 연결되어(설정 가능한 링크 또는 인터커넥트 를 통해) 다중 지시를 포함할 수 있는 데이터베이스 프로세스 동작을 실행하는 데에 요구되는 실행 파이 프라인을 제공할 수 있다. 각 데이터베이스 프로세서 서브유닛은 특정 유형의 데이터베이스 프로세스 지시(예: 필터, 병합, 누적 등)를 실 행하도록 구성될 수 있다. 도 94h는 또한 캐시에 결합된 개별적인 데이터베이스 프로세싱 유닛을 도시하고 있다. 데이터베 이스 프로세싱 유닛과 캐시는 재구성 가능한 DB 가속기 어레이 대신에 제공되거나 재구성 가능한 DB 가속기 어레이에 추가하여 제공될 수 있다. 장치는 스케일인(scale-in) 및/또는 스케일아웃(scale-out)을 용이하게 하여 다중 데이터베이스 가속 집적회로 (및 연관된 메모리 리소스 또는 다중 메모리 프로세싱 집적회로)가, 예컨대 데이터베이스 동작의 분산 프로세싱에 가담하여, 서로 협력하게 할 수 있다. 도 94i는 2개의 데이터베이스 가속 집적회로(및 그와 연관 메모리 리소스)를 포함하는 블레이드 와 같은 모듈형 유닛을 도시한 것이다. 블레이드는 하나, 둘, 또는 셋 이상의 메모리 프로세싱 집적회로 와 그와 연관된 메모리 리소스를 포함할 수 있다. 블레이드는 또한 하나 이상의 비휘발성 메모리 유닛, 이더넷 스위치, PCIe 스위치, 및 이더넷 스위치를 포함할 수 있다. 다중 블레이드는 임의의 모든 통신 방법, 통신 프로토콜, 및 연결성을 활용하여 서로 통신할 수 있다. 도 94i에는 서로 완전히 연결된 4개의 데이터베이스 가속 집적회로(및 그와 연관된 메모리 리소스 )이 도시되어 있다. 여기서, 각 데이터베이스 가속 집적회로는 나머지 3개의 데이터베이스 가속 집적회로에 모두 연결된다. 이러한 연결성은 예컨대 인터넷을 통한 RDMA 프로토콜 등과 같은 임의의 모 든 통신 프로토콜을 활용하여 확보될 수 있다. 도 94i에는 또한 연관된 메모리 리소스 및 RAM과 이더넷 포트를 포함하는 유닛에 연결된 데이터 베이스 가속 집적회로가 도시되어 있다. 도 94j, 도 94k, 도 94l, 및 도 94m은 4개의 데이터베이스 가속 집적회로 그룹이 도시되어 있고, 각 그 룹은 (서로 완전히 연결된) 4개의 데이터베이스 집적회로 및 그와 연관된 메모리 리소스가 도시 하고 있다. 상이한 그룹들은 스위치를 통해 서로 연결된다. 그룹의 수는 2, 3, 4, 또는 그 이상일 수 있다. 그룹별 데이터베이스 가속 집적회로의 수는 2, 3, 4, 또는 그 이상일 수 있다. 그룹의 수는 그룹별 데이터베이스 가속 집적회로의 수와 동일(또는 상이)할 수 있다. 도 94k는 동시에 효율적으로 서로 조인하기에 너무 큰(예: 1 TB) 2개의 표 A와 B를 도시하고 있다. 이 표들은 사실상 패치로 나누어져 있고, 조인 동작은 표 A의 패치와 표 B의 패치를 포함하는 쌍에 적용된다. 데이터베이스 가속 집적회로 그룹은 다양한 방식으로 패치를 처리할 수 있다. 예를 들어, 장치는 다음과 같은 동작에 의해 분산 프로세싱을 수행하도록 구성될 수 있다: g. 상이한 제1 데이터 구조 부분들(표 A의 패치들, 예컨대 제1 패치(A0) 내지 제16 패치(A15))을 하나 이상의 그룹의 상이한 데이터베이스 가속 집적회로에 할당. h. (i) 하나 이상의 그룹의 상이한 데이터베이스 가속 집적회로에 상이한 제2 데이터 구조 부분들(표 B의 패치 들, 예컨대 제1 패치(B0) 내지 제16 패치(B15))의 새로운 할당, 및 (ii) 데이터베이스 가속 집적회로에 의한 제 1 데이터 구조 부분들과 제2 데이터 구조 부분의 처리를 여러 번 반복 수행. 장치는 다음 반복의 새로운 할당을 현재 반복의 처리와 적어도 부분적으로 시간 중첩되는 방식으로 실행하도록 구성될 수 있다. 장치는 상이한 데이터베이스 가속 집적회로 사이에 제2 데이터 구조 부분을 교환함으로써 새로운 할당을 실행하 도록 구성될 수 있다. 상기 교환은 적어도 부분적으로는 프로세스와 시간 중첩되는 방식으로 실행될 수 있다. 장치는 한 그룹의 상이한 데이터베이스 가속 집적회로 사이에 제2 데이터 구조 부분을 교환하고 더 이상 교환할 제2 데이터 구조 부분이 없으면 상이한 그룹의 데이터베이스 가속 집적회로 사이의 제2 데이터 구조 부분을 교 환함으로써 새로운 할당을 실행하도록 구성될 수 있다. 도 94k에서, 4 사이클의 일부 결합 연산이 도시되어 있다. 예를 들어, 좌측 상단 그룹의 데이터베이스 가속 집 적회로를 참조하면, 4 사이클은 Join(A0, B0), Join(A0, B3), Join(A0, B2), 및 Join(A0, B1)의 계산을 포함한다. 이러한 4 사이클 동안에, A0은 동일한 데이터베이스 가속 집적회로에 유지되는 반면에, 행렬 B의 패치들(B0, B1, B2, B3)은 동일 그룹의 데이터베이스 가속 집적회로의 성분들 사이에서 회전된다. 도 94l에서, 제2 행렬의 패치들이 상이한 그룹 사이에서 회전된다. 즉, (a) 패치 B0, B1, B2 및 B3(좌측 상단의 그룹에 의해 이전에 처리된 패치들)은 좌측 상단의 그룹에서 좌측 하단의 그룹으로 보내지고, (b) 패치 B4, B5, B6 및 B7(좌측 하단 그룹에 의해 이전에 처리된 패치들)은 좌측 하단의 그룹에서 우측 상단의 그룹으로 보내지 고, (c) 패치 B8, B9, B10 및 B11(우측 상단 그룹에서 이전에 처리된 패치들)은 우측 상단의 그룹에서 우측 하 단의 그룹으로 보내지고, (d) 패치 B12, B13, B14 및 B15(우측 하단 그룹에서 이전에 처리된 패치들)는 우측 하 단의 그룹에서 좌측 상단의 그룹으로 보내진다. 도 94n은 다중 블레이드, SATA 컨트롤러, 로컬 스토리지 유닛, NVME, PCIe 스위 치, 이더넷 메모리 DIMMs, 및 이더넷 포트(11531)를 포함하는 시스템의 일례이다. 블레이드는 PCIe 스위치, 이더넷 포트, 및 SATA 컨트롤러의 각각에 결합될 수 있 다. 도 94o에는 2개의 시스템(11621, 11622)이 도시되어 있다. 시스템은 데이터베이스 가속을 위한 하나 이상의 장치, 스위칭 시스템, 스토리지 시스템 , 및 컴퓨트 시스템을 포함할 수 있다. 스위칭 시스템은 데이터베이스 가속을 위한 하나 이상의 장치, 스토리지 시스템, 컴퓨트 시스템 사이의 연결성을 제공한다. 시스템은 스토리지 시스템 및 데이터베이스 가속을 위한 하나 이상의 장치, 스위칭 시스템 , 및 컴퓨트 시스템을 포함할 수 있다. 스위칭 시스템은 스토리지 시스템 및 데이터베이 스 가속을 위한 하나 이상의 장치와 컴퓨트 시스템 사이의 연결성을 제공한다. 도 95a는 데이터베이스 가속을 위한 방법을 도시한 것이다. 방법은 데이터베이스 가속 집적회로의 네트워크 통신 네트워크 인터페이스가 방대한 수의 스토리지 유닛 으로부터 방대한 양의 정보를 검색하는 단계 12100으로 시작할 수 있다. 방대한 수의 스토리지 유닛으로 연결하면(예: 다중의 상이한 버스를 활용) 단일 스토리지 유닛의 스루풋이 한정 되어 있는 경우에도 네트워크 통신 네트워크 인터페이스가 방대한 양의 정보를 수신할 수 있게 한다. 단계 11210 이후에, 방대한 양의 정보를 1차 처리하여 1차 처리된 정보를 제공할 수 있다. 1차 처리는 버퍼링, 페이로드(payloads)로부터의 정보 추출, 헤더 제거, 압축해제, 압축, 해독, 데이터베이스 쿼리 필터링, 또는 임 의의 다른 처리 동작의 수행을 포함할 수 있다. 1차 처리는 또한 버퍼링으로 제한될 수도 있다. 단계 11210 이후에, 데이터베이스 가속 집적회로의 메모리 컨트롤러가 1차 처리된 정보를 방대한 스루풋 인터페 이스를 통해 다중 메모리 프로세싱 집적회로로 전송하는 단계 11220이 수행될 수 있고, 여기서 각 메모리 프로 세싱 집적회로는 컨트롤러, 다중 프로세서 서브유닛, 및 다중 메모리 유닛을 포함할 수 있다. 메모리 프로세싱 집적회로는 본 출원의 다른 부분에서 도시된 바와 같은 메모리/프로세싱 유닛 또는 분산 프로세서 또는 메모리 칩일 수 있다. 단계 11220 이후에, 다중 메모리 프로세싱 집적회로가 1차 처리된 정보의 적어도 일부를 2차 처리하여 2차 처리 된 정보를 제공하는 단계 11230이 수행될 수 있다. 단계 11230에는 데이터베이스 가속 집적회로에 의한 다중 작업의 동시 실행이 포함될 수 있다. 단계 11230은 데이터 프로세싱 서브유닛에 의한 데이터베이스 프로세싱 지시의 동시 수행을 포함할 수 있고, 여 기서 데이터베이스 가속 유닛은 공유 메모리 유닛을 공유하는 데이터베이스 가속기 서브유닛 그룹을 포함할 수 있다. 단계 11230 이후에, 데이터베이스 가속 집적회로의 메모리 컨트롤러가 다중 메모리 프로세싱 집적회로로부터 검 색된 정보를 검색하는 단계 11240이 수행될 수 있고, 여기서 검색된 정보는 (a) 1차 처리된 정보의 적어도 일부 분 및 (b) 2차 처리된 정보의 적어도 일부분 중의 적어도 하나를 포함할 수 있다. 단계 11240 이후에, 데이터베이스 가속 집적회로의 데이터베이스 가속 유닛이 검색된 정보에 데이터베이스 프로 세싱 동작을 수행하여 데이터베이스 가속 결과를 제공하는 단계 11250이 수행될 수 있다. 단계 11250은 시간 I/O 대역폭에 따라 데이터베이스 가속 집적회로의 리소스를 할당하는 단계를 포함할 수 있다. 단계 11250 이후에, 데이터베이스 가속 결과를 출력하는 단계 11260이 수행될 수 있다. 단계 11260은 데이터베이스 프로세싱 서브유닛들을 동적으로 연결하여 다중 지시를 포함할 수 있는 데이터베이 스 프로세싱 동작을 실행하는 데에 필요한 실행 파이프라인을 제공하는 단계를 포함할 수 있다. 단계 11260은 데이터베이스 가속 결과를 로컬 스토리지로 출력하는 단계와 로컬 스토리지에서 데이터베이스 가 속 결과를 검색하는 단계를 포함할 수 있다. 여기서, 단계 11210, 단계 11220, 단계 11230, 단계 11240, 단계 11250, 단계 11260 및 방법의 임의의 다른 단계는 파이프라인 방식으로 실행될 수 있다. 이러한 단계는 동시에 또는 앞서 설명한 순서와 다른 순서로 실행될 수 있다. 예를 들어, 단계 1120 이후에 단계 11250이 수행되어 1차 처리된 정보가 데이터베이스 가속 유닛에 의해 계속 처리되도록 할 수 있다. 다른 예를 들면, 1차 처리된 정보는 다중 메모리 프로세싱 집적회로로 보내지고 이어서 (다중 메모리 프로세싱 집적회로에 의해 처리되지 않고) 데이터베이스 가속 유닛으로 보내질 수 있다. 또 다른 예를 들면, 1차 처리된 정보 및/또는 2차 처리된 정보는 데이터 가속 유닛에서 데이터베이스 처리되지 않고 데이터베이스 가속 집적회로에서 출력될 수 있다. 방법은 방대한 컴퓨트 시스템의 컴퓨트 노드에 의해 데이터베이스 가속 집적회로로 보내진 실행 계획에 의거한 검색, 1차 처리, 전송, 및 3차 처리 중의 적어도 하나의 실행을 포함할 수 있다. 방법은 데이터베이스 가속 집적회로의 활용을 실질적으로 최적화하는 방식으로 검색, 1차 처리, 전송, 및 3차 처리 중의 적어도 하나를 관리하는 단계를 포함할 수 있다. 방법은 네트워크 통신 네트워크 인터페이스에 의해 교환되는 트래픽의 대역폭을 실질적으로 최적화하는 단계를 포함할 수 있다. 방법은 데이터베이스 가속 집적회로의 활용을 실질적으로 최적화하는 방식으로 검색, 1차 처리, 전송, 및 3차 처리 중의 적어도 하나에 병목이 발생하는 것을 실질적으로 방지하는 단계를 포함할 수 있다. 방법은 또한 다음 단계들의 적어도 하나를 포함할 수 있다. 단계 11270은 데이터베이스 가속 집적회로의 관리 유닛이 검색, 1차 처리, 전송, 및 3차 처리 중의 적어도 하나 를 관리하는 단계를 포함할 수 있다. 관리는 데이터베이스 가속 집적회로의 관리 유닛에 의해 생성된 실행 계획에 의거하여 실행될 수 있다. 관리는 데이터베이스 가속 집적회로에 생성되지 않았지만 데이터베이스 가속 집적회로에 의해 수신된 실행 계획 에 의거하여 실행될 수 있다. 관리는 (a) 네트워크 통신 네트워크 인터페이스 리소스, (b) 압축해제 유닛 리소스, (c) 메모리 컨트롤러 리소 스, (d) 다중 메모리 프로세싱 집적회로 리소스, 및 (e) 데이터 가속 유닛 리소스 중의 적어도 일부를 할당하는 단계를 포함할 수 있다. 단계 11271은 방대한 컴퓨트 시스템의 컴퓨트 노드가 검색, 1차 처리, 전송, 및 3차 처리 중의 적어도 하나를 제어하는 단계를 포함할 수 있다. 단계 11272는 데이터베이스 가속 집적회로의 외부에 위치한 관리 유닛이 검색, 1차 처리, 전송, 및 3차 처리 중 의 적어도 하나를 관리하는 단계를 포함할 수 있다. 도 95b는 데이터베이스 가속 집적회로의 그룹을 운영하는 방법을 도시한 것이다. 방법은 데이터베이스 가속 집적회로가 데이터베이스 가속 동작을 수행하는 단계 11310으로 시작할 수 있 다. 단계 11310은 방법의 하나 이상의 단계를 실행하는 단계를 포함할 수 있다. 방법은 또한 하나 이상의 그룹의 데이터베이스 가속 집적회로들의 데이터 가속 집적회로들 사이에 (a) 정보 및 (b) 데이터베이스 가속 결과 중의 적어도 하나를 교환하는 단계 11320을 포함할 수 있다. 단계 11310과 단계 11320의 조합은 하나 이상의 그룹의 데이터베이스 가속 집적회로에 의한 분산 프로세싱의 실 행에 이를 수 있다. 교환은 하나 이상의 그룹의 데이터베이스 가속 집적회로의 네트워크 통신 네트워크 인터페이스를 이용하여 실행 될 수 있다. 교환은 스타 결선(star-connection)에 의해 서로 연결될 수 있는 다중 그룹에 걸쳐 실행될 수 있다. 단계 11320은 하나 이상의 그룹의 상이한 그룹의 데이터베이스 가속 집적회로들 사이에 (a) 정보 및 (b) 데이터 베이스 가속 결과 중의 적어도 하나를 교환하기 위해 적어도 하나의 스위치를 사용하는 단계를 포함할 수 있다. 단계 11310은 하나 이상의 그룹의 일부의 데이터베이스 가속 집적회로의 일부가 분산 프로세싱을 실행하는 단계 11311을 포함할 수 있다. 단계 11311은 제1 데이터 구조 및 제2 데이터 구조의 분산 프로세스를 수행하는 단계를 포함할 수 있고, 여기서 제1 데이터 구조와 제2 데이터 구조의 총 사이즈는 다중 메모리 프로세싱 집적회로의 저장 능력보다 크다. 분산 프로세싱을 수행하는 단계는 (a) 상이한 쌍의 제1 데이터 구조 부분과 제2 데이터 구조 부분을 상이한 데 이터베이스 가속 집적회로에 새롭게 할당 및 (b) 상기 상이한 쌍의 처리를 여러 번 반복 수행하는 단계를 포함 할 수 있다. 분산 프로세싱의 수행은 데이터베이스 조인(join) 동작의 실행을 포함할 수 있다. 단계 11310은 (a) 상이한 제1 데이터 구조 부분들을 하나 이상의 그룹의 상이한 데이터베이스 가속 집적회로로 할당하는 단계 11312 및 (b) 상이한 제2 데이터 구조 부분들을 하나 이상의 그룹의 상이한 데이터베이스 가속 집적회로로 새로 할당하는 단계 11314와 데이터베이스 가속 집적회로가 제1 데이터 구조 부분들과 제2 데이터 구조 부분들을 처리하는 단계 11316을 여러 번 반복 수행하는 단계를 포함할 수 있다. 단계 11314는 현재 반복의 처리와 적어도 부분적으로 시간 중첩되는 방식으로 실행될 수 있다. 단계 11314는 상이한 데이터베이스 가속 집적회로 사이에 제2 데이터 구조 부분을 교환하는 단계를 포함할 수 있다. 단계 11320은 단계 11310과 적어도 부분적으로 시간 중첩되는 방식으로 실행될 수 있다. 단계 11314는 한 그룹의 상이한 데이터베이스 가속 집적회로 사이에 제2 데이터 구조 부분을 교환하고 더 이상 교환할 제2 데이터 구조 부분이 없으면 상이한 그룹의 데이터베이스 가속 집적회로 사이의 제2 데이터 구조 부 분을 교환하는 단계를 포함할 수 있다. 도 95c는 데이터베이스 가속을 위한 방법을 도시한 것이다. 방법은 데이터베이스 가속 집적회로의 네트워크 통신 네트워크 인터페이스가 방대한 수의 스토리지 유닛 으로부터 방대한 양의 정보를 검색하는 단계 11352로 시작할 수 있다. 단계 11352 이후에, 방대한 양의 정보를 1차 처리하여 1차 처리된 정보를 제공하는 단계 11354가 수행될 수 있 다. 단계 11352 이후에, 데이터베이스 가속 집적회로의 메모리 컨트롤러가 1차 처리된 정보를 방대한 스루풋 인터페 이스를 통해 다중 메모리 리소스로 전송하는 단계 11354가 수행될 수 있다. 단계 11354 이후에, 다중 메모리 리소스에서 검색된 정보를 검색하는 단계 11356이 실행될 수 있다. 단계 11356 이후에, 데이터베이스 가속 집적회로의 데이터베이스 가속 유닛이 검색된 정보에 데이터베이스 프로 세싱 동작을 수행하여 데이터베이스 가속 결과를 제공하는 단계 11358이 수행될 수 있다. 단계 11358 이후에, 데이터베이스 가속 결과를 출력하는 단계 11359가 수행될 수 있다. 방법은 또한 1차 처리된 정보를 2차 처리하여 2차 처리된 정보를 제공하는 단계 11355를 포함할 수 있다. 2차 처리는 다중 메모리 리소스를 더 포함하는 하나 이상의 메모리 프로세싱 집적회로 내에 위치한 다중 프로세서에 의해 실행될 수 있다. 단계 11355 이후에, 단계 11354와 단계 11356이 실행된다. 2차 처리된 정보의 총 사이즈는 1차 처리된 정보의 총 사이즈보다 작을 수 있다. 1차 처리된 정보의 총 사이즈는 방대한 양의 정보의 총 사이즈보다 작을 수 있다. 1차 처리는 데이터베이스 엔트리의 필터링을 포함할 수 있다. 따라서, 쿼리에 관련이 없는 데이터베이스 엔트리 를 걸러 냄으로써 추가적인 처리하기 전에 및/또는 관련이 없는 데이터베이스 엔트리를 다중 메모리 리소스에 저장하기 전에 대역폭, 저장 리소스, 및 프로세싱 리소스를 절약할 수 있다. 2차 처리는 데이터베이스 엔트리의 필터링을 포함할 수 있다. 필터링은 필터링 조건이 복잡하고(예: 다중 조건 을 포함) 필터링이 이루어지지 건에 다중 데이터베이스 엔트리 필드를 수신해야 하는 경우에 적용될 수 있다. 예컨대, (a) 특정 나이 이상이고 바나나와 같은 사람 및 (b) 다른 나이 이상이고 사과와 같은 사람을 찾는 경우 가 이에 해당할 수 있다. 데이터베이스 이하의 예들은 데이터베이스에 관한 것이다. 데이터베이스는 데이터 센터일 수 있거나, 데이터 센터의 일부일 수 있거나, 데이터 센터에 속하지 않을 수 있다. 데이터베이스는 하나 이상의 네트워크를 통해 다중 사용자에게 결합될 수 있다. 데이터베이스는 클라우드 데이 터베이스일 수 있다. 하나 이상의 관리 유닛을 포함하는 데이터베이스 및 하나 이상의 메모리/프로세싱 유닛을 포함하는 다중 데이터 베이스 가속기 보드가 제공될 수 있다. 도 96b는 관리 유닛 및 각각 통신/관리 프로세서(프로세서)와 다중 메모리/프로세싱 유닛(1202 6)을 포함하는 다중 DB 가속기 보드를 포함하는 데이터베이스를 도시한 것이다. 프로세서는 PCIe, ROCE 같은 프로토콜 등과 같은 다양한 통신 프로토콜을 지원할 수 있다. 데이터베이스 명령은 메모리/프로세싱 유닛에 의해 실행될 수 있고, 프로세서는 상이한 메모리/프로세싱 유닛들 사이에, 상이한 DB 가속기 보드들 사이에, 및 관리 유닛과 함께 트래픽을 전송할 수 있다. 특히 많은 내부 메모리 뱅크를 포함하는 다중 메모리/프로세싱 유닛을 활용하면 데이터베이스 명령의 실 행을 극적으로 가속시킬 수 있고 통신 병목 현상을 피할 수 있다. 도 96c는 프로세서 및 다중 메모리/프로세싱 유닛을 포함하는 DB 가속기 보드를 도시한 것이다. 프로세서는 메모리/프로세싱 유닛과 통신하기 위한 DDR 컨트롤러와 같은 다중 통 신 전용 컴포넌트, RDMA 엔진, DB 쿼리 데이터베이스 엔진 등을 포함한다. DDR 컨트롤러는 통신 컨트롤러의 예이고, RDMA 엔진은 임의의 통신 엔진의 예이다. 도 96b, 도 96c, 및 도 96d의 시스템의 운영(또는 시스템의 임의 부분의 운영) 방법이 제공될 수 있다. 여기서, 데이터베이스 가속 집적회로는 다중 메모리 프로세싱 집적회로에 포함되지 않는 다중 메모리 리 소스와 연관될 수 있거나 프로세싱 유닛과 연관되지 않을 수 있다. 이러한 경우, 프로세싱은 주로 및 오로지 데 이터베이스 가속 집적회로에 의해서 실행된다. 도 94p는 데이터베이스 가속을 위한 방법을 도시한 것이다. 방법은 데이터베이스 가속 집적회로의 네트워크 통신 인터페이스가 스토리지 유닛으로부터 정보를 검색 하는 단계 11710을 포함할 수 있다. 단계 11710 이후에, 정보의 양을 1차 처리하여 1차 처리된 정보를 제공하는 단계 11720이 수행될 수 있다. 단계 11720 이후에, 데이터베이스 가속 집적회로의 메모리 컨트롤러가 1차 처리된 정보를 스루풋 인터페이스를 통해 다중 메모리 리소스로 전송하는 단계 11730이 수행될 수 있다. 단계 11730 이후에, 다중 메모리 리소스로부터 정보를 검색하는 단계 11740이 수행될 수 있다. 단계 11740 이후에, 데이터베이스 가속 집적회로의 데이터베이스 가속 유닛이 검색된 정보에 데이터베이스 프로 세싱 동작을 수행하여 데이터베이스 가속 결과를 제공하는 단계 11750이 수행될 수 있다. 단계 11750 이후에, 데이터베이스 가속 결과를 출력하는 단계 11760이 수행될 수 있다. 1차 처리 및/또는 2차 처리는 데이터베이스 엔트리의 필터링을 포함하여 계속 처리할 데이터베이스 엔트리를 판 단할 수 있다. 2차 처리는 데이터베이스 엔트리의 필터링을 포함한다. 하이브리드 시스템 메모리/프로세싱 유닛은 메모리 집약적일 수 있는 계산을 실행하는 경우 및/또는 병목 현상이 검색 동작과 관련 되는 경우에 매우 효과적이다. 프로세싱 중심의(및 덜 메모리 중심의) 프로세서 유닛(예: GPU, CPU 등)은 병목 현상이 연산 동작과 관련되는 경우에 더욱 효과적일 수 있다. 하이브리드 시스템은 서로 완전히 또는 부분적으로 연결될 수 있는 하나 이상의 프로세서 유닛과 하나 이상의 메모리/프로세싱 유닛을 모두 포함할 수 있다. 메모리/프로세싱 유닛(MPU)은 로직 셀보다 메모리 셀에 더 적합한 제1 제조 프로세스에 의해 제조될 수 있다. 예를 들어, 제1 제조 프로세스에 의해 제조된 메모리 셀의 임계 치수는 제1 제조 프로세스에 의해 제조된 로직셀의 임계 치수보다 작거나 심지어 매우 작을 수(예: exceeds 2, 3, 4, 5, 6, 7, 8, 9, 10 등을 초과하는 인수 만큼) 있다. 예컨대, 제1 제조 프로세스는 아날로그 제조 프로세스, DRAM 제조 프로세스 등일 수 있다. 프로세서는 로직에 더 적합한 제2 제조 프로세스에 의해 제조될 수 있다. 예를 들면, 제2 제조 프로세스에 의해 제조된 로직 회로의 임계 치수는 제1 제조 프로세스에 의해 제조된 로직 회로의 임계 치수보다 작거나 심지어 매우 작을 수 있다. 다른 예를 들면, 제2 제조 프로세스에 의해 제조된 로직 회로의 임계 치수는 제1 제조 프로 세스에 의해 제조된 메모리 셀의 임계 치수보다 작거나 심지어 매우 작을 수 있다. 예컨대, 제2 제조 프로세스 는 디지털 제조 프로세스, CMOS 제조 프로세스 등일 수 있다. 작업은 각 유닛의 이점 및 유닛들 사이의 데이터 전송에 관련된 페널티를 고려하여 정적 또는 동적 방식으로 상 이한 유닛들 사이에 할당될 수 있다. 예컨대, 메모리 집약적 프로세스는 메모리/프로세싱 유닛에 할당되고 프로세싱 집약적이고 메모리를 많이 쓰지 않는 프로세스는 프로세싱 유닛에 할당될 수 있다. 프로세서는 하나 이상의 메모리/프로세싱 유닛이 다양한 프로세싱 작업을 수행하도록 요청 또는 지시할 수 있다. 다양한 프로세싱 작업의 실행은 프로세스의 로드를 덜고, 지연을 감소시키고, 일부 경우에서는 하나 이상 의 메모리/프로세싱 유닛과 프로세서 사이의 정보의 전반적인 대역폭을 감소시키는 등을 할 수 있다. 프로세서는 상이한 입도의 지시 및/또는 요청을 제공할 수 있다. 예를 들면, 프로세서는 특정 프로세싱 리소스 를 겨냥한 지시를 전송하거나 임의의 프로세싱 리소스를 지정하지 않고 메모리/프로세싱 유닛을 겨냥한 더 높은 레벨의 지시를 전송할 수 있다. 도 96d는 하나 이상의 메모리/프로세싱 유닛(MPU)과 프로세서를 포함하는 하이브리드 시스템 의 일례이다. 도시된 바와 같이, 프로세서는 하나 이상의 MPU로 요청 또는 지시를 전송할 수 있고, 이어서 하나 이상의 MPU는 요청 및/또는 지시를 수행(또는 선택적으로 수행)하고 결과를 프로 세서로 전송할 수 있다. 프로세서는 결과를 더 처리하여 하나 이상의 출력을 제공할 수 있다. 각 MPU는 메모리 리소스, 프로세싱 리소스(예: 콤팩트 마이크로컨트롤러), 및 캐시 메모리를 포 함한다. 마이크로컨트롤러는 한정된 연산 능력이 있을 수 있다(예: 곱셈 누적 유닛을 주로 포함할 수 있음). 마이크로컨트롤러는 인메모리 가속(in-memory acceleration) 목적으로 프로세스를 적용할 수 있고, CPU 또는 완전 DB 프로세싱 엔진 또는 그 서브세트일 수 있다. MPU는 뱅크 간의 빠른 통신을 위해 매시(mesh), 링(ring), 또는 기타 위상배치(topology)로 연결될 수 있는 패킷 프로세싱 유닛 및 마이크로프로세서를 포함할 수 있다. DIMM 간의 빠른 통신을 위해 둘 이상의 DDR 컨트롤러가 있을 수 있다. 인메모리 패킷 프로세서의 목표는 BW, 데이터 이동, 전력 소비를 줄이고 성능을 향상시키는 것이다. 이들을 활 용하면 표준 솔루션보다 성능/TCO를 극적으로 향상시키게 된다. 여기서, 관리 유닛은 선택적이다. 각 MPU는 인공지능(AI) 계산을 수행하고 그 결과만을 프로세서로 전달하여 트래픽의 양을 줄일 수 있고(특히 MPU가 다중 계산에 사용될 신경망 계수를 수신 및 저장하는 경우) 신경망의 일 부분이 사용되어 새로운 데이터 를 처리할 때마다 외부 칩으로부터 계수를 수신하지 않아도 되므로, AI 메모리/프로세싱 유닛으로 동작할 수 있 다. MPU는 계수가 0인 경우를 판단하고 0 값 계수를 포함하는 곱셈을 수행할 필요가 없다고 프로세서에 알릴 수 있 다. 여기서, 1차 처리와 2차 처리는 데이터베이스 엔트리의 필터링을 포함할 수 있다. MPU는 본 명세서, PCT 출원 공개공보 WO2019025862 및 PCT 특허 출원 번호 PCT/IB2019/001005에 도시된 임의의 모든 메모리 프로세싱 유닛일 수 있다. 네트워크 인터페이스 카드가 AI 프로세싱 능력이 있고 다중 AI 가속 서버를 결합시키는 네트워크를 통해 전송될 트래픽의 양을 감소시키기 위해 일부 AI 프로세싱 작업을 수행하도록 구성된 AI 컴퓨팅 시스템(및 이 시스템에의해 실행 가능한 시스템)이 제공될 수 있다. 예를 들면, 일부 추론(inference) 시스템에서, 입력은 네트워크(예: AI 서버에 연결된 IP 카메라의 다중 스트림)이다. 이러한 경우에서, 프로세싱 및 네트워킹 유닛 상에서 RDMA + AI를 활용하면, CPU와 PCIe 버스의 로드를 감소시킬 수 있고, 프로세싱 및 네트워킹 유닛에 포함되지 않은 GPU에 의해서가 아니라 프로세싱 및 네 트워킹 유닛 상에서 프로세싱을 제공할 수 있다. 예를 들면, 초기 결과를 계산하고 타깃 AI 가속 서버(하나 이상의 AI 프로세싱 연산을 적용하는 서버)로 전송하 는 대신에 프로세싱 및 네트워킹 유닛은 타깃 AI 가속 서버로 보내지는 값의 양을 줄이는 프리프로세싱을 수행 할 수 있다. 타깃 AI 컴퓨팅 서버는 다른 AI 가속 서버에 의해 제공된 값에 계산을 수행하도록 할당된 AI 컴퓨 팅 서버이다. 이는 AI 가속 서버들 사이에 교환되는 트래픽의 대역폭을 줄이고 또한 타깃 AI 가속 서버의 로드 를 줄인다. 타깃 AI 가속 서버는 동적 또는 정적인 방식으로, 로드 밸런싱(load balancing) 또는 기타 할당 알고리즘을 활 용하여 할당될 수 있다. 단일 타깃 AI 가속 서버보다 많은 타깃 AI 가속 서버가 있을 수 있다. 예를 들면, 타깃 AI 가속 서버가 다중의 손실을 추가하는 경우, 프로세싱 및 네트워킹 유닛은 AI 가속 서버에 의해 생성된 손실을 추가하고 손실의 합을 타깃 AI 가속 서버로 전송하여 대역폭을 줄일 수 있다. 미분 계산, 종합 등과 같은 프리프로세싱 연산을 수행하는 경우에 동일한 이득이 얻어질 수 있다. 도 97b는 서버 마더보드를 구비한 AI 프로세싱 및 네트워킹 유닛을 서로 연결하기 위한 스위치 를 각각 포함하는 서브시스템을 포함하는 시스템을 도시한 것이다. 서버 마더보드는 네트워크 능 력이 있고 AI 프로세싱 능력이 있는 하나 이상의 AI 프로세싱 및 네트워킹 유닛을 포함한다. AI 프로세 싱 및 네트워킹 유닛은 하나 이상의 NIC, 및 프리프로세싱을 수행하기 위한 ALU 또는 기타 계산 회로를 포함할 수 있다. AI 프로세싱 및 네트워킹 유닛은 칩일 수 있거나 단일 칩 이상을 포함할 수 있다. 단일 칩인 AI 프로세 싱 및 네트워킹 유닛을 구비하는 것이 유리할 수 있다. AI 프로세싱 및 네트워킹 유닛은 (오로지 혹은 주로) 프로세싱 리소스를 포함할 수 있다. AI 프로세싱 및 네트워킹 유닛은 인메모리 컴퓨팅 회로를 포함하거나, 인메모리 컴퓨팅 회로를 포함하지 않거나, 중 요한 인메모리 컴퓨팅 회로를 포함하지 않을 수 있다. AI 프로세싱 및 네트워킹 유닛은 집적회로이거나, 하나 이상의 집적회로를 포함하거나, 집적회로의 일부 등일 수 있다. AI 프로세싱 및 네트워킹 유닛은 AI 프로세싱 및 네트워킹 유닛을 포함하는 AI 가속 서버와 다른 AI 가속 서버 사이에 트래픽을 전달(예: DDR 채널, 네트워크 채널, 및/또는 PCIe 채널을 활용하여) 할 수 있다 (도 97c 참조). AI 프로세싱 및 네트워킹 유닛은 또한 DDR 메모리와 같은 외부 메모리에 결합될 수 있다. 프로세싱 및 네트워킹 유닛은 메모리를 포함 및/또는 메모리/프로세싱 유닛을 포함할 수 있다. 도 97c에서, AI 프로세싱 및 네트워킹 유닛은 로컬 DDR 연결, DDR 채널, AI 가속기, RAM 메모리, 암호화 /해독 엔진, PCIe 스위치, PCIe 인터페이스, 다중 코어 프로세싱 어레이, 고속 네트워킹 연결 등을 포함하는 것으로 도시되어 있다. 도 97b 및 도 97c의 임의의 도면의 시스템을 운영하기 위한(또는 시스템의 임의의 부분을 운영하는) 방법이 제 공될 수 있다. 본 출원에 언급된 임의의 모든 방법의 임의의 모든 단계의 조합이 제공될 수 있다. 본 출원에서 언급된 임의의 모든 유닛, 집적회로, 메모리 리소스, 로직, 프로세싱 서브유닛, 컨트롤러, 컴포넌 트의 임의의 조합이 제공될 수 있다. \"포함\"(\"including\" 및/또는 \"comprising\")에 관한 일체의 언급은 \"포함\"(\"consisting\")과 \"실질적으로 포 함\"(\"substantially consisting\")에 준용하여 적용될 수 있다. 상기의 설명은 예시의 목적으로 제시되었다. 이 설명은 모든 것을 망라한 것이 아니며 개시된 그대로의 형태 또 는 실시예로 제한되는 것이 아니다. 수정 및 응용은 본 명세서를 고려하고 개시된 실시예를 실시함으로써 당업 자에게 당연할 것이다. 또한, 개시된 실시예의 양상들이 메모리에 저장되는 것으로 설명되었지만, 당업자라면이러한 양상들이, 예를 들어, 하드 디스크 또는 CD ROM, 또는 다른 유형의 RAM 또는 ROM, USB 매체, DVD, 블루 레이, UHD 블루레이, 또는 기타 광드라이브 매체 등의 2차 저장장치와 같은 다른 유형의 컴퓨터 판독가능 매체 에 저장될 수도 있음을 이해할 것이다. 개시된 설명과 방법에 기반한 컴퓨터 프로그램은 당업자에게는 당연한 기술이다. 다양한 프로그램 또는 프로그 램 모듈이 당업자에게 공지인 기술을 사용하여 생성되거나 기존의 소프트웨어와 관련되어 설계될 수 있다. 예를 들어, 프로그램 섹션 또는 프로그램 모듈은 .Net Framework, .Net Compact Framework (및 Visual Basic, C 등 과 같은 관련 언어), Java, C++, Objective-C, HTML, HTML/AJAX 조합, XML, 또는 자바 애플릿(Java applet)을 포함하는 HTML로 설계될 수 있다. 또한, 예시된 실시예들을 여기에 설명하였지만, 모든 실시예의 범위는 균등한 구성요소, 수정, 누락, 조합(예, 다양한 실시예에 걸친 양상의 조합), 응용, 및/또는 변경을 가짐은 본 발명의 당업자에게 당연하다. 청구항의 한정은 청구항에 사용된 언어에 근거하여 넓게 해석되어야 하며 본 명세서에서 또는 본 발명의 출원 중에 설명 된 예시에 한정되지 않는다. 예시들은 배타적이지 않은 것으로 이해되어야 한다. 나아가, 개시된 방법의 단계들 은 단계들의 순서를 재배열 및/또는 단계를 삽입 또는 삭제하는 등의 다양한 방법으로 수정될 수 있다. 따라서, 본 명세서와 예시들은 예시의 목적으로만 고려되고, 진정한 범위와 기술적 사상은 하기의 청구항과 그 균등한 범위에 의해 정의된다."}
{"patent_id": "10-2022-7008116", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시에 포함되고 본 개시의 일부를 구성하는 첨부 도면은 개시된 다양한 실시예를 도시한다. 도 1은 중앙처리장치(CPU)를 개략적으로 도시한 것이다. 도 2는 그래픽처리장치(GPU)를 개략적으로 도시한 것이다. 도 3a는 개시된 실시예에 따른 예시적인 하드웨어 칩의 일 실시예를 개략적으로 도시한 것이다. 도 3b는 개시된 실시예에 따른 예시적인 하드웨어 칩의 다른 실시예를 개략적으로 도시한 것이다. 도 4는 개시된 실시예에 따른 예시적인 하드웨어 칩에 의해 실행되는 일반적인 명령을 개략적으로 도시한 것이다. 도 5는 개시된 실시예에 따른 예시적인 하드웨어 칩에 의해 실행되는 특수한 명령을 개략적으로 도시한 것이다. 도 6은 개시된 실시예에 따른 예시적인 하드웨어 칩에서 사용하기 위한 프로세싱 그룹을 개략적으로 도시한 것 이다. 도 7a는 개시된 실시예에 따른 프로세싱 그룹의 장방형 어레이를 개략적으로 도시한 것이다. 도 7b는 개시된 실시예에 따른 프로세싱 그룹의 타원형 어레이를 개략적으로 도시한 것이다. 도 7c는 개시된 실시예에 따른 하드웨어 칩의 어레이를 개략적으로 도시한 것이다. 도 7d는 개시된 실시예에 따른 하드웨어 칩의 다른 어레이를 개략적으로 도시한 것이다. 도 8은 개시된 실시예에 따른 예시적인 하드웨어 칩 상에서의 실행을 위한 일련의 명령을 컴파일하기 위한 예시 적인 방법을 도시한 순서도이다. 도 9는 메모리 뱅크를 개략적으로 도시한 것이다. 도 10은 메모리 뱅크를 개략적으로 도시한 것이다. 도 11은 개시된 실시예에 따른 서브뱅크 컨트롤이 있는 예시적인 메모리 뱅크의 일 실시예를 개략적으로 도시한 것이다. 도 12는 개시된 실시예에 따른 서브뱅크 컨트롤이 있는 예시적인 메모리 뱅크의 다른 실시예를 개략적으로 도시 한 것이다. 도 13은 개시된 실시예에 따른 예시적인 메모리 칩의 구성도이다. 도 14는 개시된 실시예에 따른 예시적인 리던던트 로직 블록 세트의 구성도이다. 도 15는 개시된 실시예에 따른 예시적인 로직 블록의 구성도이다. 도 16은 개시된 실시예에 따른 버스가 연결된 예시적인 로직 블록의 구성도이다. 도 17은 개시된 실시예에 따른 직렬로 연결된 예시적인 로직 블록의 구성도이다. 도 18은 개시된 실시예에 따른 2차원 어레이로 연결된 예시적인 로직 블록의 구성도이다.도 19는 개시된 실시예에 따른 복합 연결된 예시적인 로직 블록에 대한 구성도이다. 도 20은 개시된 실시예에 따른 리던던트 블록 활성화 프로세스를 도시한 예시적인 순서도이다. 도 21은 개시된 실시예에 따른 어드레스 배정 프로세스를 도시한 예시적인 순서도이다. 도 22는 개시된 실시예에 따른 예시적인 처리 장치에 대한 구성도이다. 도 23은 개시된 실시예에 따른 예시적인 처리 장치의 구성도이다. 도 24는 개시된 실시예에 따른 예시적인 메모리 구성도를 포함한다. 도 25는 개시된 실시예에 따른 메모리 설정 프로세스를 도시한 예시적인 순서도이다. 도 26은 개시된 실시예에 따른 메모리 읽기 프로세스를 도시한 예시적인 순서도이다. 도 27은 개시된 실시예에 따른 실행 프로세스를 도시한 예시적인 순서도이다. 도 28은 본 개시에 따른 리프레시 컨트롤러를 포함하는 예시적인 메모리 칩을 도시한 것이다. 도 29a는 본 개시에 따른 예시적인 리프레시 컨트롤러를 도시한 것이다. 도 29b는 본 개시에 따른 다른 예시적인 리프레시 컨트롤러를 도시한 것이다. 도 30은 본 개시에 따른 리프레시 컨트롤러에 의해 실행되는 프로세스의 예시적인 순서도이다. 도 31은 본 개시에 따른 컴파일러에 의해 이행되는 프로세스의 예시적인 순서도이다. 도 32는 본 개시에 따른 컴파일러에 의해 이행되는 프로세스의 다른 예시적인 순서도이다. 도 33은 본 개시에 따른 저장된 패턴에 의해 구성된 예시적인 리프레시 컨트롤러를 도시한 것이다. 도 34는 본 개시에 따른 리프레시 컨트롤러 내의 소프트웨어에 의해 이행되는 프로세스의 예시적인 순서도이다. 도 35a는 본 개시에 따른 다이를 포함하는 예시적인 웨이퍼를 도시한 것이다. 도 35b는 본 개시에 따른 입력/출력 버스에 연결된 예시적인 메모리 칩을 도시한 것이다. 도 35c는 본 개시에 따른 행으로 배열되고 입력-출력 버스에 연결된 메모리 칩을 포함하는 예시적인 웨이퍼를 도시한 것이다. 도 35d는 본 개시에 따른 그룹을 형성하고 입력-출력 버스에 연결된 두 개의 메모리 칩을 도시한 것이다. 도 35e는 본 개시에 따른 육각형 격자로 배치되고 입력-출력 버스에 연결된 다이를 포함하는 예시적인 웨이퍼를 도시한 것이다. 도 36a 내지 도 36d는 본 개시에 따른 입력/출력 버스에 연결된 메모리 칩의 다양한 가능한 구성을 도시한 것이다. 도 37은 본 개시에 따른 글루 로직(glue logic)을 공유하는 다이의 예시적인 그루핑을 도시한 것이다. 도 38a 내지 도 38b는 본 개시에 따른 웨이퍼의 예시적인 절단을 도시한 것이다. 도 38c는 본 개시에 따른 웨이퍼 상의 다이의 예시적인 배열 및 입력-출력 버스의 배열을 도시한 것이다. 도 39는 본 개시에 따른 상호 연결된 프로세서 서브유닛을 포함하는 웨이퍼 상의 예시적인 메모리 칩을 도시한 것이다. 도 40은 본 개시에 따른 웨이퍼로부터 메모리 칩의 그룹을 레이아웃 하는 프로세스의 예시적인 순서도이다. 도 41a는 본 개시에 따른 웨이퍼로부터 메모리 칩의 그룹을 레이아웃 하는 프로세스의 다른 예시적인 순서도이 다. 도 41b 내지 도 41c는 본 개시에 따른 웨이퍼로부터 한 그룹 이상의 메모리 칩을 절단하기 위한 절단 패턴을 판 단하는 프로세스의 예시적인 순서도이다. 도 42는 본 개시에 따른 열을 따라 듀얼 포트 접근을 제공하는 메모리 칩 내의 회로의 예시를 도시한 것이다.도 43은 본 개시에 따른 행을 따라 듀얼 포트 접근을 제공하는 메모리 칩 내의 회로의 예시를 도시한 것이다. 도 44는 본 개시에 따른 행과 열을 따라 듀얼 포트 접근을 제공하는 메모리 칩 내의 회로의 예시를 도시한 것이다. 도 45a는 복제된 메모리 어레이 또는 매트를 활용한 듀얼 읽기를 도시한 것이다. 도 45b는 복제된 메모리 어레이 또는 매트를 활용한 듀얼 쓰기를 도시한 것이다. 도 46은 본 개시에 따른 행을 따라 듀얼 포트 접근을 위한 스위칭 요소를 포함하는 메모리 칩 내의 회로의 예시 를 도시한 것이다. 도 47a는 본 개시에 따른 싱글 포트 메모리 어레이 또는 매트 상에 듀얼 포트 접근을 제공하기 위한 프로세스의 예시적인 순서도이다. 도 47b는 본 개시에 따른 싱글 포트 메모리 어레이 또는 매트 상에 듀얼 포트 접근을 제공하기 위한 다른 프로 세스의 예시적인 순서도이다. 도 48은 본 개시에 따른 행과 열을 따라 듀얼 포트 접근을 제공하는 메모리 칩 내의 회로의 다른 예시를 도시한 것이다. 도 49는 본 개시에 따른 메모리 매트 내의 듀얼 포트 접근을 위한 스위칭 요소의 예시를 도시한 것이다. 도 50은 본 개시에 따른 부분 워드에 접근하도록 구성된 리덕션 유닛을 포함하는 예시적인 집적회로를 도시한 것이다. 도 51은 도 50에 대해 설명된 바와 같은 리덕션 유닛을 활용하기 위한 메모리 뱅크를 도시한 것이다. 도 52는 본 개시에 따른 PIM 로직으로 통합된 리덕션 유닛을 활용하는 메모리 뱅크를 도시한 것이다. 도 53은 본 개시에 따른 PIM 로직을 활용하여 부분 워드에 접근하기 위한 스위치를 활성화하는 메모리 뱅크를 도시한 것이다. 도 54a는 본 개시에 따른 부분 워드 접근을 비활성화하는 분할된 열 멀티플렉스를 포함하는 메모리 뱅크를 도시 한 것이다. 도 54b는 본 개시에 따른 메모리에서 부분 워드 접근을 위한 프로세스의 예시적인 순서도이다. 도 55는 다중 메모리 매트를 포함하는 종래의 메모리 칩을 도시한 것이다. 도 56은 본 개시에 따른 라인의 개통 동안에 전력 소비를 감소하기 위한 활성화 회로를 포함하는 예시적인 메모 리 칩을 도시한 것이다. 도 57은 본 개시에 따른 라인의 개통 동안에 전력 소비를 감소하기 위한 활성화 회로를 포함하는 다른 예시적인 메모리 칩을 도시한 것이다. 도 58은 본 개시에 따른 라인의 개통 동안에 전력 소비를 감소하기 위한 활성화 회로를 포함하는 또 다른 예시 적인 메모리 칩을 도시한 것이다. 도 59는 본 개시에 따른 라인의 개통 동안에 전력 소비를 감소하기 위한 활성화 회로를 포함하는 추가로 예시적 인 메모리 칩을 도시한 것이다. 도 60은 본 개시에 따른 라인의 개통 동안에 전력 소비를 감소하기 위한 글로벌 워드라인과 로컬 워드라인을 포 함하는 예시적인 메모리 칩을 도시한 것이다. 도 61은 본 개시에 따른 라인의 개통 동안에 전력 소비를 감소하기 위한 글로벌 워드라인과 로컬 워드라인을 포 함하는 다른 예시적인 메모리 칩을 도시한 것이다. 도 62는 본 개시에 따른 메모리 내에서 라인의 순차적 개통을 위한 프로세스의 예시적인 순서도이다. 도 63은 메모리 칩에 대한 종래의 검사기를 도시한 것이다. 도 64는 메모리 칩에 대한 다른 종래의 검사기를 도시한 것이다. 도 65는 본 개시에 따른 동일 기판 상의 논리 소자를 메모리로 사용하여 메모리 칩을 검사하는 예시를 도시한것이다. 도 66은 본 개시에 따른 동일 기판 상의 논리 소자를 메모리로 사용하여 메모리 칩을 검사하는 다른 예시를 도 시한 것이다. 도 67은 본 개시에 따른 동일 기판 상의 논리 소자를 메모리로 사용하여 메모리 칩을 검사하는 또 다른 예시를 도시한 것이다. 도 68은 본 개시에 따른 동일 기판 상의 논리 소자를 메모리로 사용하여 메모리 칩을 검사하는 추가적인 예시를 도시한 것이다. 도 69는 본 개시에 따른 동일 기판 상의 논리 소자를 메모리로 사용하여 메모리 칩을 검사하는 다른 추가적인 예시를 도시한 것이다. 도 70은 본 개시에 따른 메모리 칩을 검사하기 위한 프로세스의 예시적인 순서도이다. 도 71은 본 개시에 따른 메모리 칩을 검사하기 위한 다른 프로세스의 예시적인 순서도이다. 도 72a는 본 개시의 실시예들에 따른 메모리 어레이와 프로세싱 어레이를 포함하는 집적회로를 도시한 것이다. 도 72b는 본 개시의 실시예들에 따른 집적회로 내부의 메모리 영역을 도시한 것이다. 도 73a는 본 개시의 실시예들에 따른 컨트롤러가 예시적으로 구성된 집적회로를 도시한 것이다. 도 73b는 본 개시의 실시예들에 따른 복제 모델을 동시에 실행하기 위한 구성을 도시한 것이다. 도 74a는 본 개시의 실시예들에 따른 컨트롤러가 다른 예시적으로 구성된 집적회로를 도시한 것이다. 도 74b는 본 개시의 실시예들에 따른 집적회로를 보호하는 방법의 순서도를 도시한 것이다. 도 74c는 본 개시의 실시예들에 따른 칩 내에 위치한 검출 요소를 도시한 것이다. 도 75a는 본 개시의 실시예들에 따른 복수의 분산 프로세서 메모리 칩을 포함하는 스케일러블 프로세서 메모리 시스템을 도시한 것이다. 도 75b는 본 개시의 실시예들에 따른 복수의 분산 프로세서 메모리 칩을 포함하는 스케일러블 프로세서 메모리 시스템을 도시한 것이다. 도 75c는 본 개시의 실시예들에 따른 복수의 분산 프로세서 메모리 칩을 포함하는 스케일러블 프로세서 메모리 시스템을 도시한 것이다. 도 75d는 본 개시의 실시예들에 따른 듀얼 포트 분산 프로세서 메모리 칩을 도시한 것이다. 도 75e는 본 개시의 실시예들에 따른 타이밍을 예시적으로 도시한 것이다. 도 76은 본 개시의 실시예들에 따른 통합 컨트롤러 및 인터페이스 모듈을 구비하고 스케일러블 프로세서 메모리 시스템을 구성하는 프로세서 메모리 칩을 도시한 것이다. 도 77은 본 개시의 실시예들에 따른 도 75a에 도시된 스케일러블 프로세서 메모리 시스템에서 프로세서 메모리 칩 사이에 데이터를 전송하는 순서도를 도시한 것이다. 도 78a는 본 개시의 실시예들에 따른 칩 레벨에서 메모리 칩 내에 구현된 복수의 메모리 뱅크의 하나 이상의 특 정 주소에 저장된 0 값을 검출하는 시스템을 도시한 것이다. 도 78b는 본 개시의 실시예들에 따른 메모리 뱅크 레벨에서 복수의 메모리 뱅크의 하나 이상의 특정 주소에 저 장된 0 값을 검출하는 메모리 칩을 도시한 것이다. 도 79는 본 개시의 실시예들에 따른 메모리 매트 레벨에서 복수의 메모리 매트의 하나 이상의 특정 주소에 저장 된 0 값을 검출하는 메모리 뱅크를 도시한 것이다. 도 80은 본 개시의 실시예들에 따른 복수의 이산 메모리 뱅크의 특정 주소에서 0 값을 검출하는 예시적인 방법 의 순서도를 도시한 것이다. 도 81a는 본 개시의 실시예들에 따른 다음 행 예측에 의거하여 메모리 뱅크와 연관된 다음 행을 활성화하는 시 스템을 도시한 것이다. 도 81b는 본 개시의 실시예들에 따른 도 81a의 시스템의 다른 실시예를 도시한 것이다. 도 81c는 본 개시의 실시예들에 따른 각 메모리 서브뱅크의 제1 서브뱅크 행 컨트롤러와 제2 서브뱅크 행 컨트 롤러를 도시한 것이다. 도 81d는 본 개시의 실시예들에 따른 다음 행 예측을 위한 일 실시예를 도시한 것이다. 도 81e는 본 개시의 실시예들에 따른 메모리 뱅크에 대한 일 실시예를 도시한 것이다. 도 81f는 본 개시의 실시예들에 따른 메모리 뱅크에 대한 다른 실시예를 도시한 것이다. 도 82는 본 개시의 실시예들에 따른 메모리 행 활성화 페널티를 감소시키기 위한 듀얼 컨트롤 메모리 뱅크를 도 시한 것이다. 도 83a는 메모리 뱅크의 행에 접근 및 활성화하는 제1 예를 도시한 것이다. 도 83b는 메모리 뱅크의 행에 접근 및 활성화하는 제2 예를 도시한 것이다. 도 83c는 메모리 뱅크의 행에 접근 및 활성화하는 제3 예를 도시한 것이다. 도 84는 종래의 CPU/레지스터 파일 및 외부 메모리 아키텍처를 도시한 것이다. 도 85a는 일 실시예에 따른 레지스터 파일 역할을 하는 메모리 매트를 포함하는 예시적인 분산 프로세서 메모리 칩을 도시한 것이다. 도 85b는 다른 실시예에 따른 레지스터 파일 역할을 하도록 구성된 메모리 매트를 포함하는 예시적인 분산 프로 세서 메모리 칩을 도시한 것이다. 도 85c는 다른 실시예에 따른 레지스터 파일 역할을 하는 메모리 매트를 포함하는 예시적인 장치를 도시한 것이다. 도 86은 개시된 실시예들에 따른 분산 프로세서 메모리 칩에서 적어도 하나의 명령을 실행하는 예시적인 방법의 순서도를 도시한 것이다. 도 87a는 분리된 서버의 예를 도시한 것이다. 도 87b는 분산 프로세싱의 예를 도시한 것이다. 도 87c는 메모리/프로세싱 유닛의 예를 도시한 것이다. 도 87d는 메모리/프로세싱 유닛의 예를 도시한 것이다. 도 87e는 메모리/프로세싱 유닛의 예를 도시한 것이다. 도 87f는 메모리/프로세싱 유닛 및 하나 이상의 통신 모듈을 포함하는 집적회로의 예를 도시한 것이다. 도 87g는 메모리/프로세싱 유닛 및 하나 이상의 통신 모듈을 포함하는 집적회로의 예를 도시한 것이다. 도 87h는 방법의 예이다. 도 87i는 방법의 예이다. 도 88a는 방법의 예이다. 도 88b는 방법의 예이다. 도 88c는 방법의 예이다. 도 89a는 메모리/프로세싱 유닛 및 어휘의 예이다. 도 89b는 메모리/프로세싱 유닛의 예이다. 도 89c는 메모리/프로세싱 유닛의 예이다. 도 89d는 메모리/프로세싱 유닛의 예이다. 도 89e는 메모리/프로세싱 유닛의 예이다. 도 89f는 메모리/프로세싱 유닛의 예이다. 도 89g는 메모리/프로세싱 유닛의 예이다. 도 89h는 메모리/프로세싱 유닛의 예이다. 도 90a는 시스템의 예이다. 도 90b는 시스템의 예이다. 도 90c는 시스템의 예이다. 도 90d는 시스템의 예이다. 도 90e는 시스템의 예이다. 도 90f는 방법의 예이다. 도 91a는 메모리 및 필터링 시스템, 스토리지 장치, 및 CPU의 예이다. 도 91b는 메모리 및 프로세싱 시스템, 스토리지 장치, 및 CPU의 예이다. 도 92a는 메모리 및 프로세싱 시스템, 스토리지 장치, 및 CPU의 예이다. 도 92b는 메모리/프로세싱 유닛의 예이다. 도 92c는 메모리 및 필터링 시스템, 스토리지 장치, 및 CPU의 예이다. 도 92d는 메모리 및 프로세싱 시스템, 스토리지 장치, 및 CPU의 예이다. 도 92e는 메모리 및 프로세싱 시스템, 스토리지 장치, 및 CPU의 예이다. 도 92f는 방법의 예이다. 도 92g는 방법의 예이다. 도 92h는 방법의 예이다. 도 92i는 방법의 예이다. 도 92j는 방법의 예이다. 도 92k는 방법의 예이다. 도 93a는 하이브리드 집적회로의 일례의 단면도이다 도 93b는 하이브리드 집적회로의 일례의 단면도이다. 도 93c는 하이브리드 집적회로의 일례의 단면도이다. 도 93d는 하이브리드 집적회로의 일례의 단면도이다. 도 93e는 하이브리드 집적회로의 일례의 평면도이다. 도 93f는 하이브리드 집적회로의 일례의 평면도이다. 도 93g는 하이브리드 집적회로의 일례의 평면도이다. 도 93h는 하이브리드 집적회로의 일례의 단면도이다. 도 93i는 하이브리드 집적회로의 일례의 단면도이다. 도 93j는 방법의 예이다. 도 94a는 스토리지 시스템, 하나 이상의 장치, 및 컴퓨터 시스템의 예이다. 도 94b는 스토리지 시스템, 하나 이상의 장치, 및 컴퓨터 시스템의 예이다. 도 94c는 하나 이상의 장치 및 컴퓨터 시스템의 예이다. 도 94d는 하나 이상의 장치 및 컴퓨터 시스템의 예이다. 도 94e는 데이터베이스 가속 집적회로의 예이다. 도 94f는 데이터베이스 가속 집적회로의 예이다. 도 94g는 데이터베이스 가속 집적회로의 예이다. 도 94h는 데이터베이스 가속 유닛의 예이다. 도 94i는 블레이드 및 데이터베이스 가속 집적회로의 그룹의 예이다. 도 94j는 데이터베이스 가속 집적회로의 그룹들의 예이다. 도 94k는 데이터베이스 가속 집적회로의 그룹들의 예이다. 도 94l은 데이터베이스 가속 집적회로의 그룹들의 예이다. 도 94m은 데이터베이스 가속 집적회로의 그룹들의 예이다. 도 94n은 시스템의 예이다. 도 94o는 시스템의 예이다. 도 94p는 방법의 예이다. 도 95a는 방법의 예이다. 도 95b는 방법의 예이다. 도 95c는 방법의 예이다. 도 96a는 종래 기술 시스템의 예이다. 도 96b는 시스템의 예이다. 도 96c는 데이터베이스 가속기 보드의 예이다. 도 96d는 시스템의 일부의 예이다. 도 97a는 종래 기술 시스템의 예이다. 도 97b는 시스템의 예이다. 도 97c는 AI 네트워크 인터페이스 카드의 예이다."}
