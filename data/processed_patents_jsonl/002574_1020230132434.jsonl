{"patent_id": "10-2023-0132434", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0049693", "출원번호": "10-2023-0132434", "발명의 명칭": "노약자 위급상황 감지 서버, 시스템 및 방법", "출원인": "김원봉", "발명자": "김원봉"}}
{"patent_id": "10-2023-0132434", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "노약자 위급상황 감지 시스템에 있어서,모니터링 영상을 생성하는 카메라; 상기 모니터링 영상을 이진영상으로 변환하는 전처리 TCP서버; 및 상기 변환된 이진영상을 분석하여 객체를 식별하고, 식별된 객체 중 사람으로 추정되는 대상 객체의 수를 파악하고, 상기 대상 객체의 관절을 검출하여, 검출된 관절에 따라 자세를 추정하고, 추정된 자세를 이용하여 위급상황을 판단하는 위급상황 감지 서버; 를 포함하는 위급상황 감지 시스템."}
{"patent_id": "10-2023-0132434", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 위급상황 감지 서버; 는이진영상에서 식별된 객체의 밝기, 색상, 대조를 포함하는 특징정보와 사람 추정을 위해 기설정된 임계값을 비교하고, 상기 특징정보 중 적어도 하나가 임계값을 초과하는 경우, 상기 특징정보를 포함하는 객체를 사람인 대상 객체로 인식하고, 상기 대상 객체의 목, 척추, 오른쪽 다리 및 왼쪽 다리 관절을 포함하는 4관절을 검출하여, 검출된 관절을 상기기진영상에 오버레이(overlay) 하여 출력하고, 상기 이진영상에서 사람으로 추정되는 대상 객체의 수를 출력하는 것을 특징으로 하는 위급상황 감지 시스템."}
{"patent_id": "10-2023-0132434", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 위급상황 감지 서버; 는목, 척추, 왼쪽 다리 및 오른쪽 다리 관절을 포함하는 4관절의 평균 신뢰도를 산출하고, 평균 신뢰도가 임계값을 초과하는 대상객체 중 신뢰도가 가장 높은 대상객체의 자세를 추정하고, 추정된 자세에 대한 4관절의 신뢰도평균을 산출하는 위급상황 감지 시스템."}
{"patent_id": "10-2023-0132434", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 노약자 위급상황 감지 서버; 는대상 객체의 이동 방향이 아래쪽인 경우, 이진영상의 높이 방향 해상도 및 국내 아파트 평균 실내 높이 정보를이용하여 대상 객체의 목관절 이동 속도를 산출하고, 대상 객체의 자세가 누운 자세로 추정된 이후의 누운 자세를 유지하는 경과 시간 및 대상 객체가 일어난 경우일어난 경과 시간을 초기화하고, 신뢰도가 가장 높은 관절인 목과 엉덩이 관절을 기준으로 목 또는 엉덩이 관절 변화가 임계값을 초과하는 경우,대상 객체가 움직인 것으로 판단하고,대상 객체의 마지막 움직임이 인식된 후의 경과 시간을 측정하는 것을 특징으로 하는 위급상황 감지 시스템."}
{"patent_id": "10-2023-0132434", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2025-0049693-3-제4항에 있어서, 상기 노약자 위급상황 감지 서버; 는대상 객체의 목관절 이동속도가 임계값 이상인 경우, 상기 대상 객체가 쓰러진 것으로 판단하고, 대상 객체가쓰러진 후 설정된 시간 동안 대상 객체의 움직임이 감지되지 않는 경우, 위급상황으로 판단하는 것을 특징으로하는 위급상황 감지 시스템."}
{"patent_id": "10-2023-0132434", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "노약자 위급상황 감지 장치에 있어서,적어도 하나의 명령어를 저장하는 메모리; 및프로세서를 포함하며,상기 적어도 하나의 명령어가 상기 프로세서에 의해 실행됨으로써,객체를 모니터링한 이진영상을 수집하고, 상기 이진영상을 분석하여 객체를 식별하고, 식별된 객체 중 사람으로추정되는 대상 객체의 수를 파악하고, 상기 대상 객체의 관절을 검출하여, 검출된 관절에 따라 자세를추정하고, 추정된 자세를 이용하여 위급상황을 판단하는 위급상황 감지 장치."}
{"patent_id": "10-2023-0132434", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 위급상황 감지 장치; 는이진영상에서 식별된 객체의 밝기, 색상, 대조를 포함하는 특징정보와 사람 추정을 위해 기설정된 임계값을 비교하고, 상기 특징정보 중 적어도 하나가 임계값을 초과하는 경우, 상기 특징정보를 포함하는 객체를 사람인 대상 객체로 인식하고, 상기 대상 객체의 목, 척추, 오른쪽 다리 및 왼쪽 다리 관절을 포함하는 4관절을 검출하여, 검출된 관절을 상기기진영상에 오버레이(overlay) 하여 출력하고, 상기 이진영상에서 사람으로 추정되는 대상 객체의 수를 출력하는 것을 특징으로 하는 위급상황 감지 장치."}
{"patent_id": "10-2023-0132434", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서, 상기 위급상황 감지 서버; 는목, 척추, 왼쪽 다리 및 오른쪽 다리 관절을 포함하는 4관절의 평균 신뢰도를 산출하고, 평균 신뢰도가 임계값을 초과하는 대상객체 중 신뢰도가 가장 높은 대상객체의 자세를 추정하고, 추정된 자세에 대한 4관절의 신뢰도평균을 산출하는 위급상황 감지 장치."}
{"patent_id": "10-2023-0132434", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 노약자 위급상황 감지 장치; 는대상 객체의 이동 방향이 아래쪽인 경우, 이진영상의 높이 방향 해상도 및 국내 아파트 평균 실내 높이 정보를이용하여 대상 객체의 목관절 이동 속도를 산출하고, 대상 객체의 자세가 누운 자세로 추정된 이후의 누운 자세를 유지하는 경과 시간 및 대상 객체가 일어난 경우일어난 경과 시간을 초기화하고, 신뢰도가 가장 높은 관절인 목과 엉덩이 관절을 기준으로 목 또는 엉덩이 관절 변화가 임계값을 초과하는 경우,대상 객체가 움직인 것으로 판단하고,공개특허 10-2025-0049693-4-대상 객체의 마지막 움직임이 인식된 후의 경과 시간을 측정하는 것을 특징으로 하는 위급상황 감지 장치."}
{"patent_id": "10-2023-0132434", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 노약자 위급상황 감지 장치; 는대상 객체의 목관절 이동속도가 임계값 이상인 경우, 상기 대상 객체가 쓰러진 것으로 판단하고, 대상 객체가쓰러진 후 설정된 시간 동안 대상 객체의 움직임이 감지되지 않는 경우, 위급상황으로 판단하는 것을 특징으로하는 위급상황 감지 장치."}
{"patent_id": "10-2023-0132434", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시예에 따른 노약자 위급상황 감지, 서버, 시스템 및 방법은 개인 식별이 불가능한 이진 영상을 통해 노약자의 자세를 인식하여 위급상황을 판단함으로써, 사생활 및 개인정보를 보호할 수 있도록 한다. 또한, 실시예서는 비 접촉 장치를 통해 위급상황을 인지할 수 있도록 하여, 웨어러블 센서 착용에 대한 번거로움과 불편함을 해소할 수 있도록 한다. 또한, 실시예에서 자세 식별은 가능하지만, 안면 인지 등 개인 식별이 불가능한 이진 영상을 통 해 응급상황을 감지함으로써, 불필요한 사생활 노출을 막을 수 있도록 한다."}
{"patent_id": "10-2023-0132434", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 위급상황 감지 서버, 시스템 및 방법에 관한 것으로 구체적으로, 노약자의 자세와 자세변화를 인식하 여 위급상황을 인지하는 서버, 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0132434", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 명세서에서 달리 표시되지 않는 한, 이 섹션에 설명되는 내용들은 이 출원의 청구항들에 대한 종래 기술이 아니며, 이 섹션에 포함된다고 하여 종래 기술이라고 인정되는 것은 아니다. 한국의 노인 인구는 현재 600만 명에 달하며, 이들 중에서 약 25%에 해당하는 독거 노인들이 혼자서 생활하고 있다. 독거노인들의 비율은 전반적으로 높아지는 추세를 보이고 있고, 연간 4만 명이 고독사 형태로 사망하는 것으로 조사되어, 그들의 생활과 복지에 대한 관심이 절실한 시점이다. 노인 돌봄을 위해, 자원봉사자로 고독사 지킴이단을 운영하고, 고독사 위험이 있는 노인 돌보고 있다. 또한, 지 자체별로 친구 모임방을 만들어, 사회 활동이 거의 없는 독거 노인 친구 맺어주기 활동을 이어오고 있다. 뿐만 아니라 다양한 세대로 구성된 소셜 패밀리 운영하고, 단체 카톡방을 만들어 연락을 주고받도록 한다. 하지만, 종래의 독거노인 돌봄 활동은 독거노인에게 응급상황이 발생했을 때, 바로 알거나 빠르게 대처할 수 없는 문제 가 있다. 최근에는 노인의 신체나 실내에 모니터링 센서를 부착하여, 신체 및 환경 모니터링 정보를 통해 응급상황을 인 지할 수 있도록 한다. 하지만, 웨어러블 센서는 부착이 번거롭고, CCTV 등의 모니터링 센서는 사생활 정보 보안 에 취약한 문제가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 한국 특허공개 제10-2023-0055572호 (2023.04.26) (특허문헌 0002) 2. 한국 특허등록 제10-2157436호 (2020.09.11)"}
{"patent_id": "10-2023-0132434", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예에 따른 노약자 위급상황 감지 서버, 시스템 및 방법은, 노인의 건강 정보와 주거 생활 정보를 비접촉식 이진영상을 통해 확인할 수 있도록 한다. 실시예에서는 적외선 센서를 이용하는 카메라를 관찰 대상인 노약자와 협의된 장소에 설치하여, 노약자 모니터 링 정보를 비접촉식으로 생성한다. 이후, 모니터링 정보를 통해 쓰러짐, 일정 시간 이상의 부동 등 자세를 인식 하고, 이를 기반으로 위험상황을 판단하여 소방서나 보호자에게 위험상황 발생을 알릴 수 있도록 한다.또한, 실시예에서는 안면 등 개인 식별이 불가능한 이진 영상을 통한 자세를 인식함으로써, 모니터링 영상에 포 함될 수 있는 사생활이나 개인정보 유출을 막을 수 있도록 한다."}
{"patent_id": "10-2023-0132434", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예에 따른 노약자 위급상황 감지 시스템은 모니터링 영상을 생성하는 카메라; 모니터링 영상을 이진영상으 로 변환하는 전처리 TCP서버; 및 변환된 이진영상을 분석하여 객체를 식별하고, 식별된 객체 중 사람으로 추정 되는 대상 객체의 수를 파악하고, 상기 대상 객체의 관절을 검출하여, 검출된 관절에 따라 자세를 추정하고, 추 정된 자세를 이용하여 위급상황을 판단하는 위급상황 감지 서버; 를 포함한다."}
{"patent_id": "10-2023-0132434", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서와 같은 노약자 위급상황 감지, 서버, 시스템 및 방법은 개인 식별이 불가능한 이진 영상을 통해 노약 자의 자세를 인식하여 위급상황을 판단함으로써, 사생활 및 개인정보를 보호할 수 있도록 한다. 또한, 실시예서는 비접촉 장치를 통해 위급상황을 인지할 수 있도록 하여, 웨어러블 센서 착용에 대한 번거로움 과 불편함을 해소할 수 있도록 한다. 또한, 실시예에서 자세 식별은 가능하지만, 안면 인지 등 개인 식별이 불가능한 이진 영상을 통해 응급상황을 감지함으로써, 불필요한 사생활 노출을 막을 수 있도록 한다."}
{"patent_id": "10-2023-0132434", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 상기한 효과로 한정되는 것은 아니며, 본 발명의 상세한 설명 또는 특허청구범위에 기재된 발 명의 구성으로부터 추론 가능한 모든 효과를 포함하는 것으로 이해되어야 한다."}
{"patent_id": "10-2023-0132434", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 본 명세서에 있어서 '부(部)'란, 하드웨어에 의해 실현되는 유닛(unit), 소프트웨어에 의해 실현되는 유닛, 양 방을 이용하여 실현되는 유닛을 포함한다. 또한, 1개의 유닛이 2개 이상의 하드웨어를 이용하여 실현되어도 되 고, 2개 이상의 유닛이 1개의 하드웨어에 의해 실현되어도 된다. 본 명세서에 있어서 단말, 장치 또는 디바이스가 수행하는 것으로 기술된 동작이나 기능 중 일부는 해당 단말, 장치 또는 디바이스와 연결된 서버에서 대신 수행될 수도 있다. 이와 마찬가지로, 서버가 수행하는 것으로 기술 된 동작이나 기능 중 일부도 해당 서버와 연결된 단말, 장치 또는 디바이스에서 수행될 수도 있다. 이하, 첨부된 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 도 1은 실시예에 따른 노약자 위급상황 감지 시스템을 나타낸 도면이다. 도 1을 참조하면, 실시예에 따른 노약자 위급상황 감지 시스템은 카메라, 위급상황 감지 서버 및 전 처리 TCP 서버를 포함하여 구성될 수 있다. 실시예에서 카메라는 관찰 대상인 노약자를 모니터링하여 모니터링 영상을 생성이다. 실시예에서 카메라는 적외선 카메라, 카메라 및 라이다(LiDar)카메라 등을 포 함한다. 실시예에서 카메라는 적외선 라이다 카메라로 구성될 수 있다. 도 2는 적외선 라이다 센서의 획득 영상 (a)과 ToF 센서의 획득 영상(a)을 비교하기 위한 도면이다. 도 2을 참조하면, ToF 센서는 인물과 배경의 거리 차이를 통해 인물 추출하기 때문에, 인물과 배경의 거리 차이가 작은 경우 인물 추출이 불가능 하다. 예컨대, 도 2의 b에 도시된 바와 같이, ToF 센서는 도로에 서있는 사람의 검출은 정확하게 수행할 수 있지만, 방에 누워 있는 사람의 검출은 수행할 수 없다. 이에 따라, 실시예에서는 적외선 라이다 센서를 탑재한 카메라를 통 해 영상을 획득함으로써, 도 3에 도시된 바와 같이, 벽에 붙어 있거나, 바닥에 누워있는 사람을 인식할 수 있도 록 한다. 도 3은 적외선 카메라를 통해 획득한 영상 및 오픈 포즈(OpenPose)를 통한 관절 정보 수집 오버레이 성공 실시예를 나타낸 도면이다. 아울러, 실시예에서는 적외선 라이다 센서를 탑재한 카메라를 통해 조명 에 관계없이 어두운 방안의 사람까지 인식할 수 있도록 한다. 또한, 실시예에서는 적외선 카메라를 통해 안면을 비식별화 할 수 있다. 도 4는 실시예에 따른 적외선 카메라로 256 색의 영상을 8채널로 단순화하여 출력 한 화면이다. 도 4에 도시된 바와 같이, 실시예에서는 적외선 센서로 획득한 이진 영상을 이용하여 대상 객체의 자세는 추정하되 안면 등 개인 식별 정보를 인식할 수 없도록 하여, 모니터링을 통해 사생활이나 개인정보가 노 출되는 것을 막을 수 있도록 한다. 전처리 TCP 서버는 카메라로부터 모니터링 영상을 수집하고, 수집한 모니터링 영상을 이진영상으로 변환한다. 실시예에서는 이미지 처리 기술을 이용하여, 이미지의 각 픽셀을 두 가지 값 중 하나로 표현하여 이 진영상으로 변환할 수 있다. 실시예에서 이진영상은 각 픽셀이 흰색(밝음) 또는 검은색(어둠) 중 하나로 표현되 며, 주로 특정 임계값(threshold)을 기준으로 픽셀 값을 결정할 수 있다. 이를 위해, 전처리 TCP 서버는 컬러 이미지를 흑백 이미지로 변환한다. 이후, 이진영상을 만들기 위해 임계값을 설정한다. 임계값은 이미지의 각 픽셀 값을 분류할 기준 값이다. 실시예에서 임계값 이하의 픽셀은 검은색으로, 임계값 이상의 픽셀은 흰색으 로 할당될 수 있다. 이후, 임계값을 기준으로 픽셀 값을 분류하여 이진화를 적용한다. 임계값보다 낮은 값은 검은색으로, 임계값보다 높거나 같은 값은 흰색으로 설정한다. 위급상황 감지 서버는 전처리 TCP 서버으로부터 수신한 이진영상을 분석하여 객체를 식별하고, 식별 된 객체 중 사람으로 추정되는 대상 객체의 수를 파악하고, 대상 객체의 자세를 추정하고, 추정된 자세에 따라 위급상황을 판단한다. 또한, 실시예에서 위급상황 감지 서버는 자세 및 응급상황 판단을 위한 임계값 설정 파일을 포함하는 학습 데이터 셋을 수집하고 자세 추정모델 및 관절 추정 모델을 통해 대상객체를 식별한다. 실시예에서 위급상황 감 지 서버는 자세 추정 결과와 자세의 유지시간에 따라 위급상황을 판단할 수 있다. 실시예에 따른 노인 위급상황 감지 시스템은 노인의 건강 정보와 주거 생활 정보를 비접촉식 이진영상을 통해 확인할 수 있도록 한다. 또한, 대상 객체인 노약자와 협의된 장소에 설치되어, 비접촉식으로 노약자 모니터링 정보를 생성한다. 이후, 모니터링 정보를 통해 쓰러짐, 일정 시간 이상의 부동 등 위험 자세를 인식하여, 소방 서나 보호자에게 위험상황을 신속하게 알릴 수 있도록 한다. 또한, 실시예에서는 개인 식별이 불가능한 이진 영 상을 통한 자세를 인식하여 개인정보와 사생활 정보를 보호할 수 있도록 한다. 도 5는 실시예에 따른 위급상황 감지 서버의 블록도를 나타낸 도면이다. 실시예에서 서버(Server)는 컴퓨터 네트워크에서 다른 컴퓨터나 장치들에게 서비스를 제공하거나 데이터를 저장 하고 관리하는 컴퓨팅 시스템이다. 서버는 클라이언트(Client)라 불리는 다른 컴퓨터나 장치들로부터 요청 을 받아들이고, 해당 요청에 대한 응답이나 데이터를 제공한다. 도 2에 도시된 서버 구성은 간략화하여 나 타낸 예시일 뿐이다. 통신부는 유선 및 무선 등과 같은 그 통신 양태를 가리지 않고 구성될 수 있으며, 단거리 통신망(PAN: Personal Area Network), 근거리 통신망(WAN: Wide Area Network) 등 다양한 통신망으로 구성될 수 있다. 또한, 통신부는 공지의 월드와이드웹(WWW: World Wide Web) 기반으로 동작할 수 있으며, 적외선(IrDA: Infrared Data Association) 또는 블루투스(Bluetooth)와 같이 단거리 통신에 이용되는 무선 전송 기술을 이용 할 수도 있다. 일례로, 통신부는 본 개시의 일 실시예에 따른 기법을 수행하는데 필요한 데이터에 대한 송 수신을 담당할 수 있다. 메모리는 임의의 타입의 저장 매체를 의미할 수 있다 예를 들어, 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예: SD 또는 XD 메모리 등), RAM(Random Access Memory), SRAM(Static Random Access Memory), ROM(Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매 체를 포함할 수 있다. 이러한 메모리는 도 1에 도시되어 있는 데이터베이스를 구성할 수도 있다. 메모리는 프로세서에 의해 실행될 수 있는 적어도 하나의 명령어를 저장할 수 있다. 또한, 메모리 는 프로세서가 생성하거나 결정한 임의의 형태의 정보 및 서버가 수신한 임의의 형태의 정보를 저장할 수 있다. 예컨대, 메모리는 후술하겠지만 사용자에 따른 RM 데이터 및 RM 프로토콜을 저장한다. 또 한, 메모리는 다양한 종류의 모듈, 명령어 세트 내지 모델을 저장한다. 프로세서는 메모리에 저장된 적어도 하나의 명령어를 실행시킴으로써, 후술될 본 개시내용의 실시예 들에 따른 기술적 특징들을 수행할 수 있다. 일 실시예에서, 프로세서는 적어도 하나의 코어로 구성될 수 있으며, 컴퓨터 장치의 중앙 처리 장치(CPU: central processing unit), 범용 그래픽 처리 장치 (GPGPU: general purpose graphics processing unit), 텐서 처리 장치(TPU: tensor processing unit) 등의 데이터 분석 및/또는 처리를 위한 프로세서를 포함할 수 있다. 도 6은 실시예에 따른 메모리에 저장된 명령어 세트 구성을 나타낸 도면이다. 도 6을 참조하면, 실시예에 따른 명령어 세트는 수집부, 전처리부, 학습부, 분석부 및 출 력부를 포함하여 구성될 수 있다. 포함하여 구성될 수 있다. 본 명세서에서 사용되는 '부' 라는 용어는 용어가 사용된 문맥에 따라서, 소프트웨어, 하드웨어 또는 그 조합을 포함할 수 있는 것으로 해석되어야 한다. 예를 들어, 소프트웨어는 기계어, 펌웨어(firmware), 임베디드코드(embedded code), 및 애플리케이션 소프트웨 어일 수 있다. 또 다른 예로, 하드웨어는 회로, 프로세서, 컴퓨터, 집적 회로, 집적 회로 코어, 센서, 멤스 (MEMS; Micro-Electro-Mechanical System), 수동 디바이스, 또는 그 조합일 수 있다. 수집부는 이진영상 분석에 필요한 일련의 데이터 및 모델의 학습 데이터를 수집한다. 예컨대, 수집부 는 인체 관절 위치 추정 및 자세 인식에 필요한 학습 데이터 셋을 수집한다. 실시예에서 학습 데이터 셋은 사람의 자세와 형태를 추정하기 위한 데이터셋으로, 3D 인체 형상 모델과 이미지 데이터를 포함할 수 있다. 실 시예에서는 학습 데이터셋을 통해 이미지로부터 사람의 2차원 관절 정보를 추정(2D Human Pose Estimation)하고, 3차원 관절 좌표를 추정(3D Human Pose Estimation) 할 수 있도록 한다. 예컨대, 수집부 는 도 14 및 도 15는 실시예에 따른 관절추정을 위한 학습 데이터를 수집하여, 관절정보를 추정할 수 있도 록 한다. 도 14는 Json 구조에 따른 24관절 정보와 관절 정보에 해당하는 신체의 위치를 나타낸 도면이고, 도 15는 관절 그래프를 나타낸 도면이다. 또한, 수집부는 관절 및 자세 추정을 위해, 다양한 학습 데이터를 수집하고 수집된 데이터를 이용하 여 모델 학습 데이터 셋을 생성한다. 도 8 및 도 9은 실시예에 따른 학습 데이터 셋의 구성예를 나타낸 도면이 다. 도 8및 도 9를 참조하면, 실시예에서 학습 데이터셋은 기 공개되어 있는 3D 데이터셋 분석 및 설문 조사를 통하여 총 70종의 동작을 선정하고 이를 성별, 신장, 몸무게에 따라 선별된 24명의 액터들이 수행하도록 한다. 데이터셋 구성은 액터 별 기본 Shape parameter, 3D 스캔 정보와 동작 종류, 촬영 카메라 정보가 기본적으로 포 함되어 있으며 촬영된 액터의 이미지와 2D, 3D 관절 데이터, Point cloud 데이터, 3D shape 데이터로 구성되어 있다. 이미지는 촬영된 동작 별 액터 영상에서 프레임 단위로 이미지를 추출한다. 이렇게 생성된 이미지를 통해 서 2D 및 3D 관절 정보를 추출하며, Point cloud 데이터는 영상 촬영 시 100여대의 Multi view 카메라에서 획득 한다. 실시예에서는 도 16에 도시된 바와 같이, 사물 인식을 위한 학습 데이터도 수집할 수 있다. 도 16의 (a) 는 사물인식을 위한 학습 데이터 셋이고, 도 16의 (b)는 움직임 인식을 위해 수집된 이미지를 정제한 학습 데이 터 셋이다. 도 10은 실시예에 따른 관절 추정을 위한 학습 데이터와 입력 데이터를 나타낸 도면이다. 도 10을 참조하면, 실 시예에서 수집부는 학습 데이터로 이용하기 위해 대상 객체의 인체 자세 판단을 위한 4가지 관절을 추정하 고, 6가지 특징점을 추출한다. 실시예에서 4가지 관절은 목관절, 허리 관절, 오른쪽 무릎관절 및 왼쪽 무릎관절 을 포함할 수 있다. 실시예에서 6가지 특징점은 길이 3종과 각도 3종을 포함한다. 실시예에 따른 특징점을 설명 하기 위한 도 12를 참조하면, 실시예에서 특징점의 길이 3종은 척추 길이, 왼쪽 무릎 길이, 오른쪽 무릎 길이를 포함하고, 각도 3종은 목-오른쪽 무릎 각도, 목 왼쪽 무릎각도 및 양 다리 사이 관절 각도를 포함할 수 있다. 이후, 실시예에서 수집부는 그래디언트 부스팅 회귀트리를 이용하여, 6가지 특징점들 중에 무작위로 조합 한 트리를 500개 생성하여, 약 180만개의 학습데이터를 생성하고, 생성된 학습데이터로 모델을 학습시켜 테스트 정확도를 향상시킬 수 있도록 한다. 또한, 실시예에서 수집부는 인체 자세 분류를 위한 6가지 특징점의 선 정 및 획득을 위해, API, 웹크롤링 등 다양한 데이터 수집 방법을 통해 사람 인체 및 자세 3D 데이터를 수집하 고 이를 이용한다. 전처리부는 수집된 학습 데이터 셋 중 편향성이나 차별성을 가진 데이터를 제거하기 위해, 수집된 학습데 이터를 전처리한다. 또한, 학습 데이터 셋을 정제하여, 학습 파라미터를 생성할 수 있다. 실시예에서 전처리부 는 수집된 트레이닝 데이터 셋을 전처리하여 인공지능 모델 학습에 적합한 형태로 가공한다. 예컨대, 전처 리부는 노이즈 제거, 이상치 제거, 결측치 처리 등의 과정을 수행할 수 있다. 또한, 전처리부는 데이 터 전처리를 통해 데이터를 정규화하거나, 이상치를 제거하거나, 데이터의 배율 조정 등을 수행하여 모델이 불 필요한 패턴을 학습하는 것을 방지할 수 있다. 도 11은 실시예에 따른 전처리된 학습 데이터의 예를 나타낸 도면이다. 도 11을 참조하면, 실시예에서는 전처리부에서 학습 데이터를 전처리하여, 여러 동작을 자세로 구분할 수 있다. 실시예에서 전처리부는 수집된 사람 인체 및 자세 3D 데이터로부터 인물 24명의 모델에서 촬영된 70 가지의 자세 사진과 함께 24개 관절의 좌표 정보를 JSON 형태의 텍스트 파일로 수집한다. 전처리부는 전처 리 과정에서 70가지의 자세를 크게 3가지 자세로 분류하는 전처리를 수행한다. 실시예에서는 선 자세, 앉은 자 세 및 누운 자세로 분류하고, 선자세는 0, 앉은 자세는 1, 누운 자세는 2에 해당하는 정보 코드를 부여할 수 있 다. 기존 데이터에서는 5자세로 대분류 하지만, 실시예에서는 혼합 자세는 제거하고, 엎드린 자세는 누운 자세 에 포함시킨다. 실시예에서 전처리부는 JSON 파일의 관절 좌표 데이터 1,827,282개를 전처리를 한다. 이후, 전처리 단계에서 목관절 좌표, 엉덩이 좌표, 왼쪽 무릎 좌표, 오른쪽 무릎 좌표의 4개 좌표를 1920*1080 해상도 기준으로 로딩한다. 또한, 실시예에서 전처리부는 해상도 정보를 통해 화면 위치에 상관이 없도록 길이 정보와 각도 정보를 계산할 수 있도록 한다. 특히 전처리부는 가까이 있던 멀리 있던 자세 추정에 영 향을 받지 않도록 척추 길이(목-엉덩이)를 1.0의 기준값으로 설정하고, 왼쪽 다리와 오른쪽 다리 길이를 상대적 길이로 나타낸다. 각도는 360도 기준이 아닌 라디안 값으로 구한 다음 최대 값인 2Pi를 1.0으로 하는 상대적인 절대값 크기로 나타낸다. 이렇게 하면 영상에서 대상이 멀리 있던 가까이 있든 왼쪽에 있든 오른쪽에 있든 상관이 없으며, 최대 값을 1.0으로 정규화 했기 때문에 각 특징점이 공평한 중요도로를 가지고 학습에 활용될 수 있 다. 학습부는 딥러닝 뉴럴 네트워크를 수집된 트레이닝 데이터 셋으로 학습시켜 딥러닝 모델을 구현한다. 도 7 은 실시예 따른 학습부에 저장되어 데이터를 학습하는 모델의 예를 나타낸 도면이다. 도 7을 참조하면, 메 모리의 학습부에는 영상분석 모델, 관절 추정 모델 및 자세 추정 모델이 저장될 수 있다. 각각의 모듈 내지 모델은 프로세서에 의해 실행 가능한 어플리케이션의 형태일 수 있다. 영상 분석 모델은 이진영상에 포함된 대상 객체를 추출하기 위한 인공신경망 모델이다. 실시예에서 영상 분 석 모델은 디지털 영상이나 비디오 데이터로부터 의미 있는 정보를 추출하고 해석하는데 사용되는 알고리즘 과 모델이다. 영상 분석 모델은 영상 데이터를 분석하여 객체 인식, 객체 추적, 움직임 감지, 분류, 세그멘 테이션 등을 수행한다. 실시예에서 영상 분석 모델은 객체 인식(Object Recognition)을 통해, 영상 속에서 특정 객체나 물체를 식별하고 분류한다. 실시예에서는 대상 객체인 노약자를 식별하고 분류할 수 있다. 또한, 영상 분석 모델은 대상 객체가 어떻게 움직이는지 추적하고, 다양한 프레임 간에 객체의 위치 및 속성을 유 지하고, 이를 통해 객체의 운동 경로나 동작을 분석한다. 또한, 영상 분석 모델은 영상 내에서 객체의 경계 를 식별하고, 각 객체 영역을 구분한다. 실시예에서는 시맨틱세그멘테이션을 통해 영상 내의 픽셀을 각각의 의 미 있는 클래스로 분류한다. 아울러, 영상 분석 모델은 객체 검출(Object Detection)을 통해, 여러 객체가 포함된 영상에서 객체의 위치와 경계를 추출할 수 있다. 관절 추정 모델는 식별된 대상 객체의 관절 위치와 관절의 종류를 추정하는 인공신경망 모델이다. 실시예에 서 관절 추정 모델은 24개의 관절 학습 데이터를 학습결과를 통해 대상 객체의 관절 위치와 종류를 파악한다. 자세 추정 모델은 관절 추정 결과를 기반으로 대상 객체의 자세를 추정한다. 실시예에서 추정되는 자세는 선 자세, 앉은 자세, 누운 자세를 포함할 수 있다. 실시예에서 자세 추정 모델은 자세 추정 시, 양쪽 무릎 관절을 모두 사용한다. 신뢰도가 높은 한쪽만을 사용 하지 않고 양쪽의 무릎관절을 이용하는 이유는 2차원 영상에서 관절들 간의 비율로 원근감을 나타내기 위함이다. 또한, 실시예에서 자세 추정 모델은 수직으로 인식된 사람의 관절에서 동일 인물에 대한 척추의 길이가 다리 길이에 비해 상대적으로 짧아지면 누워있다고 판단할 수 있다. 또한, 실시예에서는 그래디언트 부 스팅 회귀트리 알고리즘은 임의의 특징점들의 조합을 선택하여 이 특징점들 간의 상관관계를 이용하여 학습을 하게 되는데 180만개의 학습데이터에서 추출된 다양한 조합들에 의해 선 자세, 앉은 자세, 누은 자세를 추정할 수 있도록 한다. 실시예에서 자세 추정 모델은 2차원인 이진 영상에서 3차원인 자세 정보를 획득하기 위해, 신체 부위의 길이 와 기울기를 이용한다. 2차원인 이진 영상에서 서있는 수직으로 배치된 사람이 서있는지 누워있는지 판단 시, 신체 부위의 길이와 기울 기로 판단할 수 없다. 하지만, 실시예에서 자세 추정 모델은 학습 데이터로 추출된 6가지 특징점을 머신러닝 으로 학습하고, 다리 길이와 척추 길이를 쌍으로 선택하고, 선택된 길이의 비율에 의하여 원근감을 학습할 수 있다. 이를 위해, 실시예에서 자세 추정 모델은 인식된 관절 점으로부터 이미지 상에서의 관절 간 거리를 측정한다. 예컨대, 자세 추정 모델은 목과 골반에 해당하는 관절점을 추출하고, 관절점 좌표를 이용하여 픽 셀 단위의 거리를 산출한다. 이후, 자세 추정 모델은 픽셀 거리를 실제 길이로 변환한다. 예컨대, 자세 추정 모델은 이미지 내에 포함된 실제 길이를 대표하는 요소인 스케일바를 이용하여, 이미지의 해상도와 관련된 픽셀 거리를 실제 길이로 변환한다. 이후, 자세 추정 모델은 이미지 상의 픽셀 거리와 실제 길이 간의 비례를 활용하여 관절 간 거리를 이미지에서 추정한 길이로 변환한다. 이를 위해 이미지 상의 픽셀 거리를 이미지 전체 길이로 나누어 비율을 구하고, 이 비율을 실제 길이에 적용하여 3D 길이를 획득한다. 또한, 실시예에서 자세 추정 모델은 다리길이와 척추길이의 비율에 따라 누운 자세를 추정할 수 있다. 실시 예에서는 목 관절에서 척추 관절 까지의 거리를 척추길이로 산출하고, 척추길이가 일정 수준 이상 증가하거나, 척추길이에 대한 다리길이가 일정 비율이상 감소하는 경우, 해당 대상 객체의 자세를 누운 자세로 판단할 수 있 다. 실시예에서 수집부는 2가지 이상의 특징점이 쌍으로 선택될 수 있도록 그래디언트 부스팅 회귀트리 (Gradient Boosting Regression Tree) 알고리즘을 학습데이터에 적용한다. 그래디언트 부스팅 회귀트리는 여러 개의 결정 트리를 묶어 강력한 모델을 만드는 앙상블 기법 중 하나이다. 그래디언트 부스팅 회귀트리는 랜덤 포 레스트 알고리즘과는 달리 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리 생성하므로 무작위성이 없다. 실시예에서는 학습 시 강력한 사전 가지치기를 사용하여 과대적합을 방지하는데 보통 1내지5 정도의 깊지 않은 트리 사용하므로 빠른 예측이 가능한 반면 적은 메모리를 사용한다. 실시예에서 자세 추정 모델은 그래디언트 부스팅 회귀트리를 이용한 인체 자세 분류할 수 있다. 실시예에서 는 추출된 6개의 특징점에서 최대 결정 트리의 깊이는 5로 설정하였으며, 학습률은 0.1로 설정한다. 또한 생성 될 결정 트리의 개수는 500개로 지정한다. 학습데이터 수는 총 1,827,282개를 이용하였으며, 학습데이터와 테스 트데이터는 7:3으로 나누어, 학습데이터는 총 1,279,097개이며, 테스트데이터는 548,185개를 사용하였다. 학습 의 반복 횟수는 도 13에 도시된 바와 같이, 500회 반복되었으며, 90.5%의 정확도를 보인다. 본 명세서에서의 모델은 네트워크 함수, 인공신경망 및/또는 뉴럴 네트워크에 기반하여 동작하는 임의의 형태의 컴퓨터 프로그램을 의미할 수 있다. 본 명세서에 걸쳐, 모델, 신경망, 네트워크 함수, 뉴럴 네트워크(neural network)는 상호 교환 가능한 의미로 사용될 수 있다. 신경망은 하나 이상의 노드들이 하나 이상의 링크를 통해 상호 연결되어 신경망 내에서 입력 노드 및 출력 노드 관계를 형성한다. 신경망 내에서 노드들과 링크들의 개수 및 노드들과 링크들 사이의 연관관계, 링크들 각각에 부여된 가중치의 값에 따라, 신경망의 특성이 결정될 수 있다. 신경망은 하나 이상의 노드들의 집합으로 구성될 수 있다. 신경망을 구성하는 노드들의 부분 집합은 레이 어(layer)를 구성할 수 있다. 딥 뉴럴 네트워크(DNN: deep neural network, 심층신경망)는 입력 레이어와 출력 레이어 외에 복수개의 히든 레 이어를 포함하는 신경망을 의미할 수 있다. 딥 뉴럴 네트워크는 컨볼루션 뉴럴 네트워크(CNN: convolutional neural network), 리커런트 뉴럴 네트워크(RNN: recurrent neural network), 오토 인코더(auto encoder), GAN(Generative Adversarial Networks), 제한 볼츠만 머신(RBM: restricted boltzmann machine), 심층 신뢰 네 트워크(DBN: deep belief network), Q 네트워크, U 네트워크, 샴 네트워크, 적대적 생성 네트워크(GAN: Generative Adversarial Network), 트랜스포머(transformer) 등을 포함할 수 있다. 전술한 딥 뉴럴 네트워크의 기재는 예시일 뿐이며 본 개시는 이에 제한되지 않는다. 뉴럴 네트워크는 지도학습(supervised learning), 비지도학습(unsupervised learning), 준지도학습(semi supervised learning), 자가학습(self-supervised learning) 또는 강화학습(reinforcement learning) 중 적어 도 하나의 방식으로 학습될 수 있다. 뉴럴 네트워크의 학습은 뉴럴 네트워크가 특정한 동작을 수행하기 위한 지 식을 뉴럴 네트워크에 적용하는 과정일 수 있다. 뉴럴 네트워크는 출력의 오류를 최소화하는 방향으로 학습될 수 있다. 뉴럴 네트워크의 학습에서 반복적으로 학 습 데이터를 뉴럴 네트워크에 입력시키고 학습 데이터에 대한 뉴럴 네트워크의 출력과 타겟의 에러를 계산하고, 에러를 줄이기 위한 방향으로 뉴럴 네트워크의 에러를 뉴럴 네트워크의 출력 레이어에서부터 입력 레이어 방향 으로 역전파(backpropagation)하여 뉴럴 네트워크의 각 노드의 가중치를 업데이트 하는 과정이다. 지도학습의 경우 각각의 학습 데이터에 정답이 라벨링 되어있는 데이터(labelled data)를 사용하며, 비지도학습의 경우는 각각의 학습 데이터에 정답이 라벨링되어 있지 않은 데이터(unlabeled data)를 사용할 수 있다. 업데이트 되는 각 노드의 연결 가중치는 학습률(learning rate)에 따라 변화량이 결정될 수 있다. 입력 데이터에 대한 뉴럴 네 트워크의 계산과 에러의 역전파는 학습 사이클(epoch)을 구성할 수 있다. 학습률은 뉴럴 네트워크의 학습 사이 클의 반복 횟수에 따라 상이하게 적용될 수 있다. 또한, 과적합(overfitting)을 막기 위해서 학습 데이터의 증 가, 레귤러화(regularization), 노드 일부를 비활성화하는 드롭아웃(dropout), 배치 정규화 레이어(batch normalization layer) 등의 방법이 적용될 수 있다. 일 실시예에서, 모델은 트랜스포머의 적어도 일부분을 차용할 수 있다. 트랜스포머는 임베딩된 데이터들을 인코 딩하는 인코더 및 인코딩된 데이터들을 디코딩하는 디코더로 구성될 수 있다. 트랜스포머는 일련의 데이터들을 수신하여, 인코딩 및 디코딩 단계를 거처 상이한 타입의 일련의 데이터들을 출력하는 구조를 지닐 수 있다. 일 실시예에서, 일련의 데이터들은 트랜스포머가 연산가능한 형태로 가공될 수 있다. 일련의 데이터들을 트랜스포 머가 연산가능한 형태로 가공하는 과정은 임베딩 과정을 포함할 수 있다. 데이터 토큰, 임베딩 벡터, 임베딩 토 큰 등과 같은 표현들은, 트랜스포머가 처리할 수 있는 형태로 임베딩된 데이터들을 지칭하는 것일 수 있다. 트랜스포머가 일련의 데이터들을 인코딩 및 디코딩하기 위하여, 트랜스포머 내의 인코더 및 디코더들을 어텐션 (attention) 알고리즘을 활용하여 처리할 수 있다. 어텐션 알고리즘이란 주어진 쿼리(Query)에 대해, 하나 이상 의 키(Key)에 대한 유사도를 구하고, 이렇게 주어진 유사도를, 각각의 키(Key)와 대응하는 값(Value)에 반영한후, 유사도가 반영된 값(Value)들을 가중합하여 어텐션 값을 계산하는 알고리즘을 의미할 수 있다. 쿼리, 키 및 값을 어떻게 설정하느냐에 따라, 다양한 종류의 어텐션 알고리즘이 분류될 수 있다. 예를 들어, 쿼 리, 키 및 값을 모두 동일하게 설정하여 어텐션을 구하는 경우, 이는 셀프-어텐션 알고리즘을 의미할 수 있다. 입력된 일련의 데이터들을 병렬로 처리하기 위해, 임베딩 벡터를 차원을 축소하여, 각 분할된 임베딩 벡터에 대 해 개별적인 어텐션 헤드를 구하여 어텐션을 구하는 경우, 이는 멀티-헤드(multi-head) 어텐션 알고리즘을 의미 할 수 있다. 일 실시예에서, 트랜스포머는 복수개의 멀티-헤드 셀프 어텐션 알고리즘 또는 멀티-헤드 인코더-디코더 알고리 즘을 수행하는 모듈들로 구성될 수 있다. 일 실시예에서, 트랜스포머는 임베딩, 정규화, 소프트맥스(softmax) 등 어텐션 알고리즘이 아닌 부가적인 구성요소들 또한 포함할 수 있다. 어텐션 알고리즘을 이용하여 트랜스포머 를 구성하는 방법은 Vaswani et al., Attention Is All You Need, 2017 NIPS에 개시된 방법을 포함할 수 있으 며, 이는 본 명세서에 참조로 통합된다. 트랜스포머는 임베딩된 자연어, 분할된 이미지 데이터, 오디오 파형 등 다양한 데이터 도메인에 적용하여, 일련 의 입력 데이터를 일련의 출력 데이터로 변환할 수 있다. 다양한 데이터 도메인을 가진 데이터들을 트랜스포머 에 입력가능한 일련의 데이터들로 변환하기 위해, 트랜스포머는 데이터들을 임베딩할 수 있다. 트랜스포머는 일 련의 입력 데이터 사이의 상대적 위치관계 또는 위상관계를 표현하는 추가적인 데이터를 처리할 수 있다. 또는 일련의 입력 데이터에 입력 데이터들 사이의 상대적인 위치관계 또는 위상관계를 표현하는 벡터들이 추가적으로 반영되어 일련의 입력 데이터가 임베딩될 수 있다. 일 예에서, 일련의 입력 데이터 사이의 상대적 위치관계는, 자연어 문장 내에서의 어순, 각각의 분할된 이미지의 상대적 위치 관계, 분할된 오디오 파형의 시간 순서 등을 포함할 수 있으나, 이에 제한되지 않는다. 일련의 입력 데이터들 사이의 상대적인 위치관계 또는 위상관계를 표 현하는 정보를 추가하는 과정은 위치 인코딩(positional encoding)으로 지칭될 수 있다. 일 실시예에서, 모델은 RNN(Recurrent Neural Network), LSTM(Long Short Term Memory) 네트워크, DNN(Deep Neural Network), CNN(Convolutional Neural Network) 및 BRDNN(Bidirectional Recurrent Deep Neural Network) 중 적어도 하나를 포함할 수 있고 이에 한정하지 않는다. 일 실시예에서, 모델은 전이학습(transfer learning) 방식으로 학습된 모델일 수 있다. 여기서, 전이학습은 대 용량의 라벨링되어 있지 않은 학습용 데이터를 준지도학습 또는 자가학습 방식으로 사전 학습(pre-training)하 여 제1 태스크를 갖는 사전 학습된(pre-trained) 모델을 얻고, 사전 학습된 모델을 제2 태스크에 적합하도록 fine-tuning하여 라벨링된 학습용 데이터를 지도학습 방식으로 학습해 타겟으로 하는 모델을 구현하는 학습 방 식을 나타낸다. 다시 도 6을 참조하면, 분석부는 영상 분석 모델을 통해 이진영상을 분석하여 대상 객체를 추출한다. 이후, 추출된 객체 중 사람으로 추정되는 대상 객체의 수를 파악한다. 실시예에서 분석부는 객체의 경계를 찾거나 객체의 특징을 추출하여 대상 객체를 식별할 수 있다. 객체 추 출은 주로 객체 인식 및 세그멘테이션 기술을 활용하여 수행된다. 또한, 분석부는 추출된 대상 객체 중에 서 사람으로 추정되는 대상 객체를 식별한다. 실시예에서는 대상 객체에 관절 수를 검출하여 검출된 관절 수에 따라 사람으로 추정되는 객체를 식별하거나 객체인식 모델을 통해, 사람으로 추정되는 객체를 식별할 수 있다. 또한, 분석부는 이진영상에서 식별된 객체의 특징 정보를 통해, 대상 객체를 인식한다. 실시예에서 대상 객체는 노약자 등 사람으로 추정되는 객체이다. 실시예에서 특징 정보는 객체의 종류를 나타내는 정보로서, 밝 기, 색상, 대조 등을 포함할 수 있다. 실시예에서 분석부는 특징정보 중 적어도 하나가 설정된 임계값을 초과하는 객체를 사람인 대상 객체로 인식한다. 실시예에서는 사람으로 추정하는 대상 객체를 인식하기 위한 임 계값을 미리 설정할 수 있다. 이를 위해, 분석부는 이진 영상에서 식별된 객체들을 분할하여, 객체의 경계를 찾거나 중심점을 확인한다. 이후, 각 객체에 대해 이미지의 밝기, 색상, 대조를 포함하는 특징정보를 추출한다. 분석부는 추출한 특징 들 중 하나 이상이 설정된 임계값을 초과하는지 확인한다. 예를 들어, 밝기, 색상, 대조 중 하나라도 설정된 임 계값을 초과하는지 검사한다. 이후, 분석부는 객체의 특징들이 설정된 임계값을 초과하는 경우, 분류 모델 을 통해 해당 객체를 사람인 대상 객체로 판별한다. 분석부는 사람으로 추정되는 대상 객체가 식별되면, 이 객체의 수를 파악한다. 객체 수 파악은 일반적으로 객체들 간의 거리, 위치 등을 기반으로 수행될 수 있다. 또한, 사람 객체들 간의 거리가 가까우면 하나의 그룹으로 간주하거나, 개별 객체로 판별하여 카운트할 수 있다. 또한, 실시예에서 분석부는 관절 추정 모델을 통해 이진영상에서 대상객체의 관절을 인식한다. 실시예에서 는 인식된 관절의 신뢰도가 기설정된 임계값을 초과하는 경우 인식된 관절을 이진영상과 오버레이 하여 출력할 수 있도록 한다. 예컨대, 분석부는 목, 허리, 왼쪽 다리 및 오른쪽 다리를 포함하는 4관절을 추정하고, 신 뢰도에 따라 4관절을 이진영상에 오버레이 한다. 이를 위해, 분석부는 관절 추정 모델을 사용하여 이진영상에서 대상 객체의 관절을 인식한다. 분석부(12 4)는 대상 객체의 특징을 기반으로 관절 위치를 예측하고 추정한다. 이후, 관절 추정 결과로 얻어진 인식된 관 절의 신뢰도를 확인하고, 확인된 인식된 관절의 신뢰도를 기설정된 임계값과 비교한다. 실시예에서 분석부(12 4)는 만약 인식된 관절의 신뢰도가 임계값을 초과한다면, 인식된 관절 정보를 출력부로 전달할 수 있다. 실시예에서 분석부는 실제 데이터와 추정 데이터의 비교, 신뢰도 스코어 계산, 동적정보 활용, 불확실성 모델링 방법 중 적어도 하나를 통해 신뢰도를 산출할 수 있다. 예컨대, 분석부는 관절 추정 모델에서 실제 데이터와 추정된 데이터의 일치율을 산출하고 이에 따라 관절 의 신뢰도를 측정할 수 있다. 구체적으로, 분석부는 특정 관절의 추정된 위치가 실제 데이터에 포함된 오 차 범위를 계산하여 관절에 대한 신뢰도를 평가할 수 있다. 또한, 분석부는 모델이 관절을 얼마나 확신하는지를 나타내는 신뢰도 점수를 계산하여 신뢰도를 평가할 수 있다. 예컨대, 분석부는 모델 내부에서 관절 위치의 확률 분포를 기반으로 신뢰도를 산출할 수 있다. 또한, 분석부는 여러 프레임의 연속적인 이미지를 활용하여 관절의 움직임 패턴을 추적하고, 이를 통해 신 뢰도를 측정할 수 있다. 실시예에서는 움직임이 일관되게 추정된 경우 신뢰도를 높게 산출한다. 아울러, 분석부 는 관절 위치의 불확실성을 모델링하여 신뢰도를 산출할 수 있다. 이는 주로 확률적인 방법을 사용하여 관 절 위치의 분포를 추정하고, 이 분포의 폭이 작을수록 높은 신뢰도로 산출하는 방법이다. 또한, 분석부는 4관절의 평균 신뢰도를 산출한다. 4관절은 자세를 결정하는 중요 관절로서, 목, 척추, 왼 쪽 다리 및 오른쪽 다리 관절을 포함한다. 실시예에서 분석부는 관절 추정 모델을 사용하여 이진영상에서 대상 객체의 관절을 인식하고, 각 관절의 위치에 대한 신뢰도를 계산한다. 관절 추정 모델은 주로 딥러닝 네트워크를 사용하며, 이 네트워크는 관절 위치 와 신뢰도를 예측한다. 각 관절의 위치에 대한 신뢰도를 취합하여 관절의 평균 신뢰도를 계산한다. 이를 위해서 는 각 관절의 신뢰도 값을 더하고, 관절의 수로 나누어 평균을 구할 수 있다. 계산된 평균 신뢰도는 대상 객체 의 관절 추정 결과의 신뢰성을 나타내는 지표이다. 실시예에서는 신뢰도가 높을수록 추정된 관절 위치가 실제 객체의 위치와 일치할 가능성이 높다는 것을 의미한다. 실시예에서 분석부는 4관절의 평균 신뢰도가 임계 값을 초과하는 대상 중 신뢰도가 가장 높은 관찰 대상의 자세를 추정한다. 이후, 분석부는 추정된 자세에 대한 4관절의 신뢰도 평균을 산출하고, 이전에 추정된 자세를 신뢰도와 함 께 출력한다. 또한, 분석부는 관찰 대상 식별 후 식별된 대상의 움직임 여부를 판단한다. 분석부는 관찰 대상의 이 동 방향이 아래쪽을 항하는 경우, 관찰 대상의 목관절을 기준으로 이동 속도를 산출할 수 있다. 예컨대, 분석부 는 이진 영상의 높이 방향 해상도 및 국내 아파트 평균 실내 높이를 이용하여 관찰 대상의 목관절의 이동 속도를 산출한다. 이를 위해, 분석부는 이진 영상의 높이 방향 해상도를 확인하고, 대상객체의 목부분을 포함하는 관심 영역 을 정의한다. 이후, 이진 영상에서 관심 영역(예컨대, 목 부분)을 추적하여 프레임 간 이동을 감지한다. 또한, 추적된 데이터를 이용하여 각 프레임에서의 관절 위치 및 이동량을 계산한다. 실시예에서 분석부는 국내 아파트 평균 실내 높이를 획득하여, 관찰 대상의 목 관절 이동량을 프레임 단위로 측정한다. 이후, 목관절 이동 량을 시간에 따른 변화량인 속도(m/s)로 산출한다. 실시예에서 분석부는 목 관절의 이동 거리를 아파트 평 균 실내 높이로 나누어 상대적인 이동 거리를 구한 다음, 시간 간격으로 나누어 목 관절의 이동 속도를 계산할 수 있다. 또한, 실시예에서 분석부는 대상 객체의 자세 유지시간을 카운팅한다. 예컨대, 분석부는 대상 객체의 자세가 누운 자세로 추정된 이후, 경과 시간을 측정하고, 관찰 대상이 일어나는 경우 경과 시간을 초기화한다. 또한, 분석부는 대상 객체가 마지막으로 움직인 이후 경과된 시간을 측정한다. 실시예에서 분석부는 신뢰도가 가장 높은 관절인 목과 엉덩이 관절을 기준으로 관절 변화가 임계값을 초과하는 경우 움직임으로 판단 한다. 또한, 실시예에 분석부는 위험상황 발생을 의미하는 모션 패턴을 설정하고, 설정된 모션 패턴이 인식되는 경우, 위험상황으로 판단할 수 있다. 실시예에서는 위급상황 발생 시 노약자가 직접 입력하는 모션 패턴을 미리 저장한다. 실시예에서 모션 패턴은 손을 좌우로 5번 이상 흔드는 모션, 손으로 가슴을 내리 치는 모션, 손으로 전화기 모양을 만드는 모션 등을 포함할 수 있다. 실시예에서 노약자가 위험상황이 발생되거나 예측되는 시점에 카메라에 해당 모션 패턴을 수행하면 모션 패턴 정보가 서버로 전송한다. 이후, 분석부는 영상 처리 모델 및 자세 추정 모델을 통해 모션 패턴을 인식하는 경우, 바로 위급상황으로 판단하여 이에 대응하는 조치를 취할 수 있도록 한다. 또한, 분석부는 대상 객체의 이동속도가 임계값 이상인 경우, 대상 객체가 쓰러진 것으로 판단하고, 쓰러 진 후 설정된 시간 동안 관찰대상의 움직임이 감지되지 않는 경우, 응급상황으로 판단한다. 출력부는 분석부로부터 전달받은 데이터를 가공하여, 이진영상 분석 결과를 포함하는 정보를 표시한 다. 예컨대, 출력부는 제목 표시창을 통해 버전 정보를 포함하여 시스템 제목을 표시한다. 실시예에서는 버전 정보를 수정해야 하는 경우, 설정 파일(예컨대, conf. json)에서 버전 정보를 변경할 수 있다. 또한, 출력부는 수신 영상 표시창을 통해, TCP 영상 전처리 서버로 부터 수신된 영상을 출력할 수 있다. 실시예에서 영상은 흑백으로 표시되며, 채널을 단순화 한 후의 색의 종류를 2색, 3색, 4색 등으로 설정 파일에 서 설정할 수 있다. 실시예에서 설정파일은 conf.json 등을 포함한다. 또한, 출력부는 이진영상에서 식별 된 객체 중 설정된 임계값을 초과하는 객체인 대상 객체들은 사람으로 인식하여 4관절을 오버레이 하여 표시한 다. 실시예에서 설정된 임계값은 이미지의 밝기, 색상, 대조 등을 포함할 수 있다. 또한, 출력부는 영상에서 사람으로 추정되는 대상객체의 수를 표시한다. 실시예에서 관절을 표시하는 것은 관절들의 평균 임계값이 설정 파일(예컨대, conf.json)에서 설정한 임계값을 초과하는 경우만 출력할 수 있다. 또한, 출력부는 4관절의 평균 신뢰도가 임계값을 넘는 대상에 중에서 가장 신뢰도가 높은 인물에 대해 추 정된 자세를 출력한다. 실시예에서 또한, 출력부는 선 자세, 앉은 자세, 누운 자세로 세 가지로 분류하여 출력할 수 있다. 또한, 출력부는 추정된 자세에 대하여 4가지 관절의 신뢰도의 평균을 산출하여 함께 퍼센 트로 표시할 수 있다. 실시예에서 출력부는 이전 추정 자세를 신뢰도와 함께 표시한다. 또한, 출력부는 관찰 대상의 이동 방향이 아래쪽을 항하는 경우 목관절을 기준으로 산출된 속도를 m/s 단 위로 출력할 수 있다. 또한, 출력부는 대상 객체가 누운 이후 경과 시간을 시, 분, 초 단위로 출력한다. 예컨대, 관찰 대상의 자세가 누운 자세로 추정된 이후 경과된 시간을 초 단위로 표시할 수 있다. 또한, 출력부 는 대상 객체의 최종 움직임 경과 시간을 시, 분, 초 단위로 출력할 수 있다. 실시예에서는 관찰 대상이 마지막으로 움직인 이후 경과된 시간을 초 단위로 측정 후 표시한다. 또한, 출력부는 정상 및 응급상황을 포함하는 상태정보를 출력한다. 실시예에서는 관찰 대상이 임계값 이 상의 속도로 쓰러진 상태에서, 임계값 이상의 시간동안 움직임이 없을 경우 응급상황으로 판단되면, 출력부 는 응급상황에 해당하는 상태정보를 출력한다. 예컨대, 응급 상황인 경우 화면에 \"EMERGENCY\"를 출력할 수 있다. 이상에서와 같은 노약자 위급상황 감지, 서버, 시스템 및 방법은 개인 식별이 불가능한 이진 영상을 통해 노약 자의 자세를 인식하여 위급상황을 판단함으로써, 사생활 및 개인정보를 보호할 수 있도록 한다. 또한, 실시예서는 비접촉 장치를 통해 위급상황을 인지할 수 있도록 하여, 웨어러블 센서 착용에 대한 번거로움 과 불편함을 해소할 수 있도록 한다. 또한, 실시예에서 자세 식별은 가능하지만, 안면 인지 등 개인 식별이 불가능한 이진 영상을 통해 응급상황을 감지함으로써, 불필요한 사생활 노출을 막을 수 있도록 한다."}
{"patent_id": "10-2023-0132434", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "개시된 내용은 예시에 불과하며, 특허청구범위에서 청구하는 청구의 요지를 벗어나지 않고 당해 기술분야에서 통상의 지식을 가진 자에 의하여 다양하게 변경 실시될 수 있으므로, 개시된 내용의 보호범위는 상술한 특정의 실시예에 한정되지 않는다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16"}
{"patent_id": "10-2023-0132434", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 노약자 위급상황 감지 시스템을 나타낸 도면 도 2는 적외선 라이다 센서의 획득 영상(a)과 ToF 센서의 획득 영상(a)을 비교하기 위한 도면 도 3은 적외선 카메라를 통해 획득한 영상 및 오픈 포즈(OpenPose)를 통한 관절 정보 수집 오버레이 성공 실시 예를 나타낸 도면 도 4는 실시예에 따른 적외선 카메라로 256 색의 영상을 8채널로 단순화하여 출력한 화면 도 5는 실시예에 따른 위급상황 감지 서버의 블록도를 나타낸 도면 도 6은 실시예에 따른 메모리에 저장된 명령어 세트 구성을 나타낸 도면 도 7은 실시예 따른 학습부에 저장되어 데이터를 학습하는 모델의 예를 나타낸 도면 도 8 및 도 9은 실시예에 따른 학습 데이터 셋의 구성예를 나타낸 도면 도 10은 실시예에 따른 관절 추정을 위한 학습 데이터와 입력 데이터를 나타낸 도면 도 11은 실시예에 따른 전처리된 학습 데이터의 예를 나타낸 도면 도 12는 실시예에 따른 특징점을 설명하기 위한 도면 도 13은 실시예에 따른 학습 데이터 셋의 정확도를 나타낸 도면 도 14는 Json 구조에 따른 24관절 정보와 관절 정보에 해당하는 신체의 위치를 나타낸 도면이고, 도 15는 관절 그래프를 나타낸 도면 도 16은 실시예에 따른 학습 데이터를 나타낸 도면"}
