{"patent_id": "10-2019-0043052", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0120311", "출원번호": "10-2019-0043052", "발명의 명칭": "의료 영상을 이용한 암의 병기 결정 방법 및 의료 영상 분석 장치", "출원인": "계명대학교 산학협력단", "발명자": "김해원"}}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상분석장치가 사용자에 대한 의료 영상을 입력받는 단계; 및상기 영상분석장치가 상기 의료 영상을 신경망에 입력하여 상기 사용자에 대한 암 병기 정보를 생성하는 단계를포함하되,상기 신경망은 의료 영상에서 원발성 종양 정보, 림프절 전이 정보 및 원격 전이 정보를 기준으로 상기 암 병기정보를 출력하도록 사전에 학습된 모델인 의료 영상을 이용한 암의 병기 결정 방법."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 원발성 종양 정보는 원발성 종양의 존재 여부, 원발성 종양의 크기 및 원발성 종양의 침습 정도 중 적어도하나를 포함하고,상기 림프절 전이 정보는 림프절 전이 여부, 전이된 림프절 위치 및 림프절 전이 정도 중 적어도 하나를 포함하고,상기 원격 전이 정보는 원격 전이 여부, 원격 전이 정도 및 원격 전이 위치 중 적어도 하나를 포함하는 의료 영상을 이용한 암의 병기 결정 방법."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 의료 영상은 CT 영상, PET 영상 및 PET/CT 영상을 포함하는 영상집합 중 적어도 하나의 영상인 의료 영상을 이용한 암의 병기 결정 방법."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 의료 영상은 서로 종류가 다른 제1 영상 및 제2 영상을 포함하고, 상기 신경망은 제1 신경망 및 제2 신경망을 포함하되,상기 제1 신경망은 상기 제1 영상 또는 상기 제2 영상을 입력받아 원발성 종양 영역, 림프절 영역 및 원격 전이영역을 검출하고, 상기 제2 신경망은 상기 제2 영상에서 상기 검출한 영역과 동일한 위치의 영역에 대한 특징 정보를 기준으로 상기 암 병기 정보를 출력하는 의료 영상을 이용한 암의 병기 결정 방법."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 제1 영상은 CT 영상이고, 상기 제2 영상은 PET 영상 또는 PET/CT 영상인 의료 영상을 이용한 암의 병기 결정 방법."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 암 병기 정보는 TNM (tumor-node-metastasis) 기준에 따른 병기 정보인 의료 영상을 이용한 암의 병기 결정 방법.공개특허 10-2020-0120311-3-청구항 7 제1항에 있어서,상기 영상분석장치가 상기 신경망에서 출력되는 특징 정보를 디코더 신경망에 입력하여 상기 암 병기 정보가 포함되는 영상을 생성하는 단계를 더 포함하는 의료 영상을 이용한 암의 병기 결정 방법."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "영상분석장치가 사용자의 의료 영상을 입력받는 단계; 상기 영상분석장치가 상기 의료 영상을 신경망에 입력하여 원발성 종양의 크기, 림프절 전이 정도 및 원격 전이정도를 결정하는 단계; 및상기 영상분석장치가 상기 원발성 종양의 크기, 림프절 전이 정도 및 원격 전이 정도를 기준으로 상기 사용자에대한 암 병기 정보를 생성하는 단계를 포함하되,상기 신경망은 의료 영상에서 원발성 종양 정보, 림프절 전이 정보 및 원격 전이 정보를 출력하도록 사전에 학습된 모델인 의료 영상을 이용한 암의 병기 결정 방법."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 원발성 종양 정보는 원발성 종양의 존재 여부, 원발성 종양의 크기 및 원발성 종양의 침습 정도 중 적어도하나를 포함하고,상기 림프절 전이 정보는 림프절 전이 여부, 전이된 림프절 위치 및 림프절 전이 정도 중 적어도 하나를 포함하고,상기 원격 전이 정보는 원격 전이 여부, 원격 전이 정도 및 원격 전이 위치 중 적어도 하나를 포함하는 의료 영상을 이용한 암의 병기 결정 방법."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 신경망은 제1 신경망, 제2 신경망 및 제3 신경망으로 포함하고,상기 제1 신경망은 의료 영상에서 양성 결절(nodule) 존재 여부, 원발성 종양의 크기 및 원발성 종양의 침습 정도 중 적어도 하나를 출력하고,상기 제2 신경망은 의료 영상에서 림프절 전이 여부, 전이된 림프절 위치 및 림프절 전이 정도 중 적어도 하나를 출력하고,상기 제3 신경망은 의료 영상에서 원격 전이 여부, 원격 전이 정도 및 원격 전이 위치 중 적어도 하나를 출력하는 의료 영상을 이용한 암의 병기 결정 방법."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 의료 영상은 서로 종류가 다른 제1 영상 및 제2 영상을 포함하고, 상기 신경망은 제1 신경망 및 제2 신경망을 포함하되,상기 제1 신경망은 상기 제1 영상 또는 상기 제2 영상을 입력받아 원발성 종양 영역, 림프절 영역 및 원격 전이영역 중 적어도 하나의 영역을 검출하고, 상기 제2 신경망은 상기 제2 영상에서 상기 검출한 영역과 동일한 위치의 영역에 대한 특징 정보를 기준으로 원발성 종양 정보, 림프절 전이 정보 및 원격 전이 정보 중 적어도 하나는 출력하는 의료 영상을 이용한 암의 병기 결정 방법."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2020-0120311-4-제11항에 있어서,상기 제1 영상은 CT 영상이고, 상기 제2 영상은 PET 영상 또는 PET/CT 영상인 의료 영상을 이용한 암의 병기 결정 방법."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서,상기 암 병기 정보는 TNM (tumor-node-metastasis) 기준에 따른 병기 정보인 의료 영상을 이용한 암의 병기 결정 방법."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "사용자의 의료 영상을 입력받는 입력장치;의료 영상에서 원발성 종양 정보, 림프절 전이 정보 및 원격 정보를 기준으로 상기 암 병기 정보를 출력하도록사전에 학습된 신경망을 저장하는 저장장치; 및상기 입력받은 의료 영상을 상기 신경망에 입력하여 상기 사용자에 대한 암 병기 정보를 생성하는 연산장치를포함하는 의료 영상 분석 장치."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 의료 영상은 서로 종류가 다른 제1 영상 및 제2 영상을 포함하고, 상기 신경망은 제1 신경망 및 제2 신경망을 포함하되,상기 제1 신경망은 상기 제1 영상 또는 상기 제2 영상을 입력받아 원발성 종양 영역, 림프절 영역 및 원격 전이영역을 검출하고, 상기 제2 신경망은 상기 제2 영상에서 상기 검출한 영역과 동일한 위치의 영역에 대한 특징 정보를 기준으로 상기 암 병기 정보를 출력하는 의료 영상 분석 장치."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 제1 영상은 CT 영상이고, 상기 제2 영상은 PET 영상 또는 PET/CT 영상인 의료 영상 분석 장치."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,상기 저장 장치는 특징 정보를 입력받아 영상을 생성하는 디코더 신경망을 더 저장하고, 상기 연산 장치는 상기 신경망에서 출력되는 특징 정보를 상기 디코더 신경망에 입력하여 상기 암 병기 정보가포함되는 영상을 생성하는 의료 영상 분석 장치."}
{"patent_id": "10-2019-0043052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14항에 있어서,상기 원발성 종양 정보는 원발성 종양의 존재 여부, 원발성 종양의 크기 및 원발성 종양의 침습 정도 중 적어도하나를 포함하고,상기 림프절 전이 정보는 림프절 전이 여부, 전이된 림프절 위치 및 림프절 전이 정도 중 적어도 하나를 포함하고,상기 원격 전이 정보는 원격 전이 여부, 원격 전이 정도 및 원격 전이 위치 중 적어도 하나를 포함하는 의료 영상 분석 장치.공개특허 10-2020-0120311-5-"}
{"patent_id": "10-2019-0043052", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "의료 영상을 이용한 암의 병기 결정 방법은 영상분석장치가 사용자에 대한 의료 영상을 입력받는 단계 및 상기 영상분석장치가 상기 의료 영상을 신경망에 입력하여 상기 사용자에 대한 암 병기 정보를 생성하는 단계를 포함 한다. 상기 신경망은 의료 영상에서 원발성 종양의 크기, 림프절 전이 정도 및 원격 전이 정도를 기준으로 상기 암 병기 정보를 출력하도록 사전에 학습된 모델이다."}
{"patent_id": "10-2019-0043052", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이하 설명하는 기술은 의료 영상을 이용하여 암의 병기를 결정하는 기법에 관한 것이다."}
{"patent_id": "10-2019-0043052", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "암 환자 진단에 CT(전산화단층촬영), MRI(자기공명영상), PET(양전자단층촬영) 같은 의료 영상이 널리 사용되고 있다. 의료진이 의료 영상을 판독하여 해당 환자를 진단하고, 이 진단결과에 따라 치료한다. 따라서 의료 영상 판독은 반드시 전문가를 통해 수행한다. 한편, 컴퓨터를 이용한 보조 진단(CAD) 기술도 등장하였다. 예컨대, CT 영상에서 폐 결절 부위를 검출하여 표시 하는 방식이다. 의료진은 보조 진단 기술을 활용하여 보다 빠르게 정확하게 의료 영상을 판독할 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-1768812호"}
{"patent_id": "10-2019-0043052", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "의료 영상 판독은 전문가의 주관적인 판단에 따른다. 따라서 영상 판독은 의사의 경험에 따라 영상 해석 능력에 차이 있어 오진발생 가능성의 한계가 있다. 종래 보조 진단 기술은 다양한 병증에 따른 영상 특성을 반영하기 어려웠다. 또 기존의 보조 진단 기술은 특정 부위 검출과 같이 진단을 위한 단순한 보조적 수단에 불과하였다. 이하 설명하는 기술은 의료영상의 AI(인공지능)모델을 이용하여 자동으로 암의 병기(stage)를 결정하는 기법을 제공하고자 한다."}
{"patent_id": "10-2019-0043052", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "의료 영상을 이용한 암의 병기 결정 방법은 영상분석장치가 사용자에 대한 의료 영상을 입력받는 단계 및 상기 영상분석장치가 상기 의료 영상을 신경망에 입력하여 상기 사용자에 대한 암 병기 정보를 생성하는 단계를 포함 한다. 상기 신경망은 의료 영상에서 원발성 종양 정보, 림프절 전이 정보 및 원격 전이 정보를 기준으로 상기 암 병기 정보를 출력하도록 사전에 학습된 모델이다. 의료 영상을 이용한 암의 병기 결정 방법은 영상분석장치가 사용자의 의료 영상을 입력받는 단계, 상기 영상분 석장치가 상기 의료 영상을 신경망에 입력하여 원발성 종양의 크기, 림프절 전이 정도 및 원격 전이 정도를 결 정하는 단계 및 상기 영상분석장치가 상기 원발성 종양의 크기, 림프절 전이 정도 및 원격 전이 정도를 기준으 로 상기 사용자에 대한 암 병기 정보를 생성하는 단계를 포함한다. 상기 신경망은 의료 영상에서 원발성 종양 정보, 림프절 전이 정보 및 원격 전이 정보를 출력하도록 사전에 학습된 모델이다. 의료 영상 분석 장치는 사용자의 의료 영상을 입력받는 입력장치, 의료 영상에서 원발성 종양 정보, 림프절 전 이 정보 및 원격 정보를 기준으로 상기 암 병기 정보를 출력하도록 사전에 학습된 신경망을 저장하는 저장장치 및 상기 입력받은 의료 영상을 상기 신경망에 입력하여 상기 사용자에 대한 암 병기 정보를 생성하는 연산장치 를 포함한다."}
{"patent_id": "10-2019-0043052", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이하 설명하는 기술은 AI(인공지능) 모델을 이용하여 의료 영상에서 암의 병기를 정확하게 결정한다. 따라서 의 료진은 의료 영상만 촬영하면 암 발생 여부뿐만 아니라 암의 병기까지 파악할 수 있다. 따라서, 이하 설명하는 기술은 암의 병기에 따라 즉각적이고 적절한 의료적 조치를 가능하게 한다."}
{"patent_id": "10-2019-0043052", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 설명하는 기술은 다양한 변경을 가할 수 있고 여러 가지 실시례를 가질 수 있는 바, 특정 실시례들을 도면 에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 이하 설명하는 기술을 특정한 실시 형태에 대해 한정하려 는 것이 아니며, 이하 설명하는 기술의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하 는 것으로 이해되어야 한다. 제1, 제2, A, B 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 해당 구성요소들은 상기 용어 들에 의해 한정되지는 않으며, 단지 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예 를 들어, 이하 설명하는 기술의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 본 명세서에서 사용되는 용어에서 단수의 표현은 문맥상 명백하게 다르게 해석되지 않는 한 복수의 표현을 포함 하는 것으로 이해되어야 하고, \"포함한다\" 등의 용어는 설시된 특징, 개수, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 의미하는 것이지, 하나 또는 그 이상의 다른 특징들이나 개수, 단계 동작 구성요 소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 배제하지 않는 것으로 이해되어야 한다. 도면에 대한 상세한 설명을 하기에 앞서, 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기 능 별로 구분한 것에 불과함을 명확히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이 하에서 설명할 구성부 각각은 자신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의 해 전담되어 수행될 수도 있음은 물론이다. 또, 방법 또는 동작 방법을 수행함에 있어서, 상기 방법을 이루는 각 과정들은 문맥상 명백하게 특정 순서를 기 재하지 않은 이상 명기된 순서와 다르게 일어날 수 있다. 즉, 각 과정들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 이하 설명에서 사용하는 정보 내지 용어에 대하여 먼저 설명한다. 의료 영상은 사용자(환자)에 대한 의학적 정보를 포함하는 영상을 의미한다. 의료 영상은 다양한 기법으로 촬영 된 다양한 영상을 포함하는 의미이다. 예컨대, 의료 영상은 X-ray 영상, CT 영상, MRI 영상, PET 영상, PET-CT 영상 등을 의미한다. 이하 설명의 편의를 위해 개별 영상은 CT, PET, PET-CT 등으로 표현한다. CT는 X 선을 이용한 단층촬영 기법이다. PET는 양전자방출단층촬영 기법이다. PET는 체내의 특정 성분에 양전자 를 내는 물질을 정맥 주사한 후 대상자를 촬영한다. PET는 인체에 투입하는 방사성 동위원소 화합물의 종류에 따라 포도당 대사, 아미노산 대사, DNA 합성, 수용체 영상(소마토스타틴 등), 종양에 특이적인 항체, 유전자 영 상 등 다양한 분자 영상을 획득할 수 있다. PET-CT는 양전자방출 단층촬영검사(PET)와 전산화 단층촬영검사(CT)가 결합된 촬영 기법이다. PET-CT는 질환의 형태적 영상(CT)과 기능적 영상(PET)을 동시에 포함한다. 따라서 종래 PET 검사보다 병소 부위를 정확하게 진단 할 수 있다. 이하 설명하는 기술은 암(cancer)의 병기를 결정하는 기법이다. 암의 병기는 암의 진행 정도를 나타내는 정보이 다. 암은 병기에 따라 효과적인 의료적 대처 방법이 있다. 따라서 정확한 병기 정보를 파악하는 것이 매우 중요 하다. 암은 다양한 종류가 있다. 예컨대, 암은 소화기암, 폐암, 유방암, 부인암, 뇌암, 갑상선암, 두경부암, 소아암 등으로 구분할 수 있다. 이하 설명하는 기술은 특정 유형의 암에 대한 병기 결정에 한정되지 않는다. 이하 설명 하는 기술은 다양한 암 중 적어도 하나에 대한 병기를 결정한다. 다만, 이하 설명의 편의를 위하여 폐암에 대한 자료를 중심으로 설명한다. 이하 설명하는 기술은 기계학습(machine learning)모델을 사용하여 의료 영상을 분석한다. 기계학습모델은 널리 알려진 바와 같이 다양한 모델이 있다. 이하 설명하는 기술은 인공신경망(artificial neural network)을 사용하 여 영상을 분석한다고 가정한다. 인공신경망은 딥러닝 네트워크를 사용할 수 있다. 딥러닝 네트워크는 DNN(Deep Neural Network), CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), RBM(Restricted Boltzmann Machine) 등의 모델일 수 있다. 널리 알려진 딥러닝 모델에 대해서는 자세한 설명을 생략한다. 이하 인공신경망을 이용하여 영상을 분석하는 장치를 영상분석장치라고 명명하다. 영상분석장치는 사전에 학습 된 인공신경망을 이용하여 영상을 분석한다. 영상분석장치는 일정한 데이터 처리 내지 신호 처리를 수행할 수 있다. 예컨대, 영상분석장치는 PC, 스마트기기, 서버 등과 같은 장치로 구현될 수 있다. 영상분석장치는 의료 영상을 분석한다. 분석 대상인 영상을 이하 소스 영상이라고 명명한다. 영상분석장치는 인 공신경망에 소스 영상을 입력하여 분석 결과를 도출한다. 사용자는 검사 대상이 되는 사람을 의미한다. 사용자는 환자 내지 환자 후보에 해당한다. 소스 영상은 사용자에 대한 의료 영상이다. 도 1은 의료 영상을 이용한 암 병기 결정 시스템의 예이다. 암 병기 결정 시스템은 의료 영상 스캔 장치 및 영상분석장치(150, 180)를 포함한다. 의료 영상 스캔 장치는 의료 기관에 설치된 영상 장비이다. 의료 영상 스캔 장치는 사용자를 대상으 로 CT, PET, PET/CT 등의 영상을 생성한다. 도 1은 하나의 의료 영상 스캔 장치를 도시하였다. 후술하겠지 만, 암 병기 결정 시스템은 복수의 의료 영상을 사용할 수 있다. 따라서, 도 1과 달리 서로 다른 종류(복 수)의 의료 영상 스캔 장치가 사용될 수 있다. 도 1은 영상분석장치로 분석 서버 및 분석 PC를 예로 도시하였다. 물론 영상분석장치는 다양한 형태 로 구현될 수 있다. 예컨대, 영상분석장치는 휴대 가능한 모바일 기기로 구현될 수도 있다. 암 병기 결정 시스템은 분석 서버 또는 분석 PC 중 어느 하나를 포함할 수 있다. 나아가 암 병 기 결정 시스템은 분석 서버 및 분석 PC를 모두 포함할 수 있다. 분석 서버는 의료 영상 스캔 장치부터 소스 영상을 전달받는다. 분석 서버는 유선 또는 무선 네 트워크를 통해 소스 영상을 수신할 수 있다. 분석 서버는 의료 영상을 분석하고, 분석한 결과를 사용자 에게 전달한다. 사용자는 사용자 단말을 통해 분석 서버의 분석 결과 또는 영상을 확인할 수 있다. 사용자 단말은 PC, 스마트 기기, 디스플레이 장치 등과 같은 장치를 의미한다. 분석 PC는 의료 영상 스캔 장치부터 소스 영상을 전달받는다. 분석 PC는 유선 또는 무선 네트워 크를 통해 소스 영상을 수신할 수 있다. 분석 PC는 의료 영상을 분석하고, 분석한 결과를 사용자에게 전달한다. 사용자는 분석 PC를 통해 분석 결과를 확인할 수 있다. 분석 서버 또는 분석 PC는 딥러닝 모델을 사용하여 의료 영상을 분석할 수 있다. 분석 서버 또 는 분석 PC는 의료 영상을 분석하여 사용자의 암 병기에 대한 정보를 생성할 수 있다. 도 2는 암 병기 결정을 위한 신경망 모델의 예이다. 도 2는 암 병기를 결정하는 영상분석장치에서 사용할 수 있는 신경망 모델에 대한 예이다. 도 2는 하나의 신경망(제1 신경망, 210)을 사용하는 예이다. 예컨대,제1 신경망은 CNN과 같은 모델일 수 있다. 제1 신경망은 의료 영상을 입력받고, 의료 영상의 분석 결 과인 암 병기 정보를 출력한다. 도 1의 하부에는 입력되는 의료 영상에 대한 예와 출력되는 암 병기 정보의 예 를 도시하였다. 의료 영상은 PET/CT 영상을 예로 도시하였다. 암 병기 정보는 \"Stage IIA\"로 표시하였다. 암 병 기 정보는 암의 종류 등에 따라 다른 정보로 식별될 수도 있다. 제1 신경망은 사전에 학습되어야 한다. 제1 신경망은 특정한 유형(CT, PET 또는 PET/CT 중 어느 하나)의 훈련용 영상과 해당 영상의 환자에 대한 정확한 암 병기 정보를 이용하여 훈련될 수 있다. 제1 신경망 은 입력되는 훈련용 영상에 대해 매칭되는 암 병기 정보가 출력되도록 학습된다. 딥러닝 네트워크 학습 과 정에 대해서는 상세한 설명을 생략한다. 제1 신경망은 학습 과정을 통해 신경망 계층의 가중치가 최적화된 다. 물론 제1 신경망은 암 병기를 결정하는 애플리케이션으로 사용되면서, 결과값을 피드백받아 계속 업데 이트될 수도 있다. 딥러닝 네트워크에서 파라미터 (parameter)는 손실함수를 감소시키는 방향으로 학습을 수행 한다. 손실함수는 학습 과정을 통해 신경망의 가중치를 최적화할 수 있다. 예컨대, 가중치 최적화는 경사 하강 법(gradient descent method)을 이용할 수 있다. 도 3은 암 병기 결정을 위한 신경망 모델의 다른 예이다. 도 3은 암 병기를 결정하는 영상분석장치에서 사 용할 수 있는 신경망 모델에 대한 예이다. 도 3은 두 개의 신경망(제1 신경망, 제2 신경망)을 사용하는 예이다. 제1 신경망 및 제2 신경망은 CNN과 같은 모델일 수 있다. 제1 신경망 및 제2 신경망은 서 로 다른 종류의 딥러닝 모델일 수도 있다. 제1 신경망은 의료 영상에서 원하는 객체가 존재하는 관심 영역(ROI)을 검출한다. 예컨대, 제1 신경망 은 CNN과 같은 모델일 수 있다. 제1 신경망은 객체 검출을 위한 것으로 의료 영상의 특징 정보를 기 준으로 특정한 영역을 검출한다. 예컨대, 제1 신경망은 의료 영상에서 원발성 종양, 림프절 영역 및 원격 전이 영역 중 적어도 하나를 검출할 수 있다. 제1 신경망은 사전에 학습되어야 한다. 제1 신경망은 특정한 유형(CT, PET 또는 PET/CT 중 어느 하나)의 훈련용 영상과 해당 영상에 존재하는 관심 영역에 대한 정보 를 이용하여 훈련될 수 있다. 제1 신경망은 훈련용 영상에서 원발성 종양, 림프절 영역 및 원격 전이 영역 중 적어도 하나를 검출하도록 학습된다. 학습되는 모델 형태에 따라 제1 신경망은 원발성 종양, 림프절 영 역 및 원격 전이 영역 중 어느 하나를 검출할 수 있다. 또는 제1 신경망은 원발성 종양, 림프절 영역 및 원격 전이 영역 중 2개 이상을 검출할 수도 있다. 제2 신경망은 입력되는 의료 영상을 이용하여 암 병기 정보를 출력한다. 예컨대, 제2 신경망은 CNN과 같은 모델일 수 있다. 제2 신경망은 제1 신경망에서 검출한 관심 영역을 입력받을 수 있다. 또는 제2 신경망은 의료 영상 전체를 입력받되, 관심 영역의 특징 정보만을 이용하여 영상을 분석할 수 있다. 제2 신경망은 관심 역역의 특징 정보를 기준으로 암 병기 정보를 출력한다. 제2 신경망은 사전에 학습되 어야 한다. 제2 신경망은 특정한 유형(CT, PET 또는 PET/CT 중 어느 하나)의 훈련용 영상 또는 관심 영역 영상과 해당 영상에 매칭되는 암 병기 정보를 이용하여 훈련될 수 있다. 제2 신경망은 제1 신경망에 서 출력하는 영역의 종류(원발성 종양, 림프절 영역 및 원격 전이 영역 중 적어도 하나)에 대응되는 훈련용 영 상을 이용하여 학습된다. 제2 신경망은 훈련용 영상에서 원발성 종양, 림프절 영역 및 원격 전이 영역 중 적어도 하나를 이용하여 암 병기 정보를 출력한다. 도 3의 하부에는 입력되는 의료 영상에 대한 예와 출력되는 암 병기 정보의 예를 도시하였다. 의료 영상은 PET/CT 영상을 예로 도시하였다. 제1 신경망은 의료 영상에서 ROI를 검출한다. 제2 신경망은 제1 신 경망 모델이 출력하는 영상 내지 정보를 입력받아 암 병기 정보를 출력한다. 암 병기 정보는 \"Stage IIA\" 로 표시하였다. 암 병기 정보는 암의 종류 등에 따라 다른 정보로 식별될 수도 있다. 도 4는 암 병기 결정을 위한 신경망 모델의 또 다른 예이다. 도 4는 암 병기를 결정하는 영상분석장치에서 사용할 수 있는 신경망 모델에 대한 예이다. 도 4는 3개의 신경망(제1 신경망, 제2 신경망 및 제3 신경망)을 사 용하는 예이다. 예컨대, 제1 신경망, 제2 신경망 및 제3 신경망은 CNN과 같은 모델일 수 있다. 제1 신경망, 제2 신경망 및 제3 신경망은 서로 다른 유형의 딥러닝 네트워크일 수도 있다. 제1 신경망, 제2 신경망 및 제3 신경망은 각각 암 병기를 결정하기 위한 요소 정보를 출력한다. 제1 신경망은 의료 영상에서 원발성 종양 정보를 출력한다. 원발성 종양 정보는 원발성 종양의 존재, 원발 성 위치 내지 원발성 종양의 크기를 포함한다. 제1 신경망은 의료 영상을 입력받고, 의료 영상의 분석 결과인 원발성 종양 정보를 출력한다. 제1 신경망은 사전에 학습되어야 한다. 제1 신경망은 특정한 유 형(CT, PET 또는 PET/CT 중 어느 하나)의 훈련용 영상과 해당 영상의 환자에 대한 원발성 종양의 존재 내지 원 발성 종양의 크기를 이용하여 훈련될 수 있다. 제1 신경망은 입력되는 훈련용 영상에 대해 매칭되는 원발 성 종양 정보가 출력되도록 학습된다. 제2 신경망은 의료 영상에서 림프절 정보를 출력한다. 림프절 정보는 림프절 전이 여부, 전이된 림프절 위 치 내지 림프절 전이 정도를 포함한다. 제2 신경망은 의료 영상을 입력받고, 의료 영상의 분석 결과인 림 프절 정보를 출력한다. 제2 신경망은 사전에 학습되어야 한다. 제2 신경망은 특정한 유형(CT, PET 또 는 PET/CT 중 어느 하나)의 훈련용 영상과 해당 영상의 환자에 대한 림프절 정보를 이용하여 훈련될 수 있다. 제2 신경망은 입력되는 훈련용 영상에 대해 매칭되는 림프절 정보가 출력되도록 학습된다. 제3 신경망은 의료 영상에서 원격 전이 정보를 출력한다. 원격 전이 정보는 원격 전이 여부, 원격 전이 정 도 및 원격 전이 위치를 포함한다. 제3 신경망은 의료 영상을 입력받고, 의료 영상의 분석 결과인 원격 전 이 정보를 출력한다. 제3 신경망은 사전에 학습되어야 한다. 제3 신경망은 특정한 유형(CT, PET 또는 PET/CT 중 어느 하나)의 훈련용 영상과 해당 영상의 환자에 대한 원격 전이 정보를 이용하여 훈련될 수 있다. 제3 신경망은 입력되는 훈련용 영상에 대해 매칭되는 원격 전이 정보가 출력되도록 학습된다. 영상분석장치는 제1 신경망, 제2 신경망 및 제3 신경망이 출력하는 정보를 기준으로 암 병기를 결정할 수 있다. 영상분석장치는 원발성 종양 정보, 림프절 정보 및 원격 전이 정보를 기준으로 암 병기를 결정 할 수 있다. 도 4는 원발성 종양 정보, 림프절 정보 및 원격 전이 정보 각각에 대하여 하나의 신경망을 사용하는 예를 도시 하였다. 이때 하나의 신경망은 도 3과 유사하게 관심 영역을 검출하는 신경망과 검출한 관심 영역 영역의 특징 정보를 특정 정보를 추출하는 신경망으로 구성될 수 있다. 예컨대, 제1 신경망은 의료 영상에서 원발성 종 양 위치 내지 결절 위치(ROI)를 검출하는 제1 서브 신경망과 검출한 ROI를 대상으로 원발성 종양 정보를 출력하 는 제2 서브 신경망으로 구성될 수 있다. 제2 신경망 및 제3 신경망도 유사하게 두 개의 서브 신경망 으로 구성될 수도 있다. 도 5는 복수의 의료 영상을 이용한 암 병기 결정에 대한 예이다. 영상분석장치는 복수의 의료 영상을 이용하여 암 병기를 결정할 수도 있다. 복수의 의료 영상은 동일 사용자에 대한 서로 다른 유형의 의료 영상으로 구성된 다. 도 5는 도 3의 신경망 모델을 예로 설명한다. 제1 신경망은 CT 영상을 입력받는다. 제1 신경망은 CT 영상에서 ROI를 검출한다. 제2 신경망은 동일 사용자에 대한 PET/CT 영상을 입력받는다. 이때 제2 신경망은 CT 상의 ROI와 동일한 영역을 중심으로 특징 정보를 파악하여 암 병기 정보를 출력할 수 있다. 도 3은 설명의 편의를 위하여 CT, PET/CT를 예로 든 것으로, 다른 종류의 의료 영상을 사용할 수도 있다. 예컨대, 제1 신경망은 CT에서 폐 결절 검출하고, 제2 신경망은 PET/CT 영상에서 폐 결절의 특징 을 추출하여 해당 폐 결절이 정상, 양성 또는 악성인지 여부를 출력할 수 있다. 제1 신경망은 CT에서 림프절을 검출하고, 제2 신경망은 PET/CT 영상에서 림프절의 특징을 추출하여 해당 림프절이 전이성인지 양성인지 여부를 출력할 수 있다. 제1 신경망은 PET/CT에서 원격 전이 영역(후보)을 검출하고, 제2 신 경망은 CT/PET 영상에서 해당 영역이 원격 전이 상태인지 또는 양성 병변인지 여부를 출력할 수 있다. 전술한 바와 같이 신경망 모델은 다양한 모델이 사용될 수 있다. 대표적으로 CNN이 사용될 수 있다. CNN은 다양 한 형태의 계층 구조로 구성될 수 있다. 예컨대, CNN은 5개의 컨볼루션 계층 + Relu 계층, 2개의 최대 풀링 계 층, 2개의 전연결 계층(Fully connected layer) 구조를 가질 수 있다. 또 신경망 훈련을 위한 훈련 데이터 마련도 중요하다. 훈련 데이터는 이용하고자 하는 영상의 종류, 판단에 사 용하는 기준 등에 따라 달라진다. 훈련 데이터 전처리 과정에 대하여 간략하게 설명한다. 예컨대, PET/CT 영상 을 이용한다면, 512 * 512 픽셀의 PET dicom 영상와 CT dicom 영상를 256 * 256 pixel 크기로 자를(crop) 수 있다. 자른 영상에 대한 판별결과를 3차원 one-hot vector로 정의할 수 있다. 예컨대, 폐암 정보를 포함하지 않 는 PET/CT 영상은 [1, 0, 0], 양성 병변을 포함하는 영상은 [0,1, 0], 악성 병변은 [0, 0, 1]으로 정의할 수 있다. 훈련 영상는 랜덤하게 선별하되, 양성 종양, 악성 종양 등 진단하고자 하는 유형별로 충분한 세트를 마련해야 한다. 경우에 따라서, 훈련 영상이 충분하지 않은 경우, 일정한 영상 처리 방식을 이용하여 훈련 영상을 증대할 수도 있다. 도 6은 폐암 병기를 나타내는 테이블의 예이다. 도 6은 암 중에서 폐암에 대한 병기를 결정하는 TNM 기준에 대 한 예이다. T는 원발성 종양(T: Primary Tumor) 상태를 나타내고, N은 국소 림프절(N: Lymph Nodes) 상태를 나 타내고, M은 원격 전이(M: Metastasis) 여부를 나타낸다. 폐암의 병기는 원발성 종양, 림프절 상태, 원격 전이 여부를 기준으로 구분될 수 있다. T(원발성 종양)는 크기, 내부 기관(기관지) 침습 정도, 주변 기관 침습 정도 등에 대한 상태 정보를 나타낸다. N(림프절)은 림프절 상태, 림프절 전이 여부, 림프절 전이 정도 등에 대한 상 태 정보를 나타낸다. M(전이)은 내부 전이 정도, 외부 원격 전이 위치, 원격 전이 정도 등에 대한 상태 정보를 나타낸다. 신경망은 훈련 영상과 훈련 영상의 TNM 기준에 따른 병기를 매칭하는 과정을 반복하면서 학습될 수 있다. 이 경우, 도 2 또는 도 3과 같이 신경망이 암 병기 정보를 출력한다. 또는 신경망은 훈련 영상과 훈련 영 상의 TNM 기준에 대한 상태를 매칭하는 과정을 반복하면서 학습될 수 있다. 이 경우, 도 4와 같이 신경망은 원 발성 종양 정보, 림프절 정보 및 원격 전이 정보를 출력한다. 도 7은 암 병기 정보를 갖는 영상을 생성하는 신경망 모델의 예이다. 도 7은 암 병기를 결정하는 영상분석 장치에서 사용할 수 있는 신경망 모델에 대한 예이다. 도 7은 암 병기에 대한 정보를 포함하는 영상을 생성하는 신경망에 대한 예이다. 입력 영상에서 특징 정보를 추출하고, 추출한 특징 정보를 기반으로 일정한 영상을 생성 하는 모델에 해당한다. 이와 같은 신경망은 대표적으로 오토인코더, 컨볼루셔널 인코더-디코더 등이 있다. 도 7 은 컨볼루셔널 인코더-디코더 구조에 대한 예이다. 신경망 모델은 인코더 및 디코더를 포함한다. 인코더는 소스 영상(의료 영상)을 입력받아 특징 정보 내지 특징 맵을 출력한다. 디코더는 입력받은 특징 정보 내지 특징 맵을 기준으로 특정 영상을 출력한다. 디코더가 출력하는 영상을 출력 영상이라고 명 명한다. 인코더는 소스 영상의 특징 맵을 생성하고, 특징 맵의 크기를 감소시키면서 일부 유효한 특징값만을 추출 한다. 디코더는 인코더가 출력하는 유효한 특징값을 기준으로 특징 맵의 크기를 증가시킨다. 디코더 는 최종적으로 소스 영상과 동일한 크기의 출력 영상을 출력한다. 인코더는 복수의 인코더 단을 포함한다. 도 7은 3개의 인코더 단(encoder 1, encoder 2 및 encoder 3)을 예로 도시하였다. 인코더 단은 복수의 컨볼루셔널 블록과 하나의 풀링 계층으로 구성될 수 있다. 하나의 컨볼루셔널 블록은 컨볼 루셔널 계층, 비선형화 계층 및 표준화 계층을 포함한다. 비선형화 계층은 relu layer를 사용할 수 있다. 표준 화 계층은 배치 표준화 계층을 사용할 수 있다. 각 계층의 동작은 전술한 바와 같다. 풀링 계층은 최대 풀링(max pooling)을 수행할 수 있다. 풀링 계층은 최댓값을 갖는 픽셀 위치를 저장해두고, 대응되는 디코더 단의 업 샘플링 계층에 전달한다(도 3에서 점선 화살표로 표시함). 인코더는 소스 영상에서 암 병기 판단에 사용될 특징 정보를 추출한다. 한편 의료 영상에 특정 영역을 표 시하기 위하여 인코더는 특징 정보 위치 파악이 가능한 모델을 사용할 수도 있다. 디코더는 복수의 디코더 단을 포함한다. 도 7은 3개의 디코더 단(decoder 1, decoder 2 및 decoder 3)을 예로 도시하였다. 전술한 바와 같이 디코더는 인코더에 대칭되는 구조(거울상)를 갖는다. 따라서 디 코더 단은 하나의 업샘플링 계층 및 복수(컨볼루셔널 블록의 개수와 동일한)의 역컨볼루셔널 블록으로 구성될 수 있다. 디코더 단은 인코더 단의 동작을 역으로 수행한다. 업샘플링 계층은 대응되는 인코더 단의 최대 풀링 계층으로부터 전달 받은 최댓값 픽셀 위치에 입력 특징 맵의 값을 출력하고, 최댓값 픽셀 위치 외에는 '0' 의 값을 출력한다. 디코더 단은 대응되는 인코더 단의 컨볼루셔널 블록 및 컨볼루셔널 계층과 필터 개수, 필터 크기 등이 동일하다. 디코더는 입력된 의료 영상과 유사한 영상을 출력할 수 있다. 출력 영상은 특징 정보가 반영된 값을 포함 한다. 다양한 형태로 구현이 가능한데, 출력 영상은 의료 영상에서 양성 병변 영역, 악성 영역, 양성 림프절 영역, 악성 림프절 영역, 원격 전이 영역 등을 나타낼 수 있다. 출력 영상은 특정 색상으로 해당 영역을 표현할 수 있다. 나아가 출력 영상은 암 병기 판단을 위한 서로 다른 기준으로 구별되게 표현할 수도 있다. 출력 영상 은 최종적인 암 병기 정보를 출력 영상에 표시(색상, 텍스트 등)할 수 있다. 출력 영상이 나타내는 정보는 디코 더의 구성 내지 파라미터 설정에 따라 달라질 수 있다. 도 8은 의료 영상을 이용한 암 병기 결정 장치의 구성에 대한 예이다. 암 병기 결정 장치는 전술한 영상처리장치에 해당한다. 암 병기 결정 장치는 도 1의 분석 서버 내지 분석 PC에 해당하기도 한다. 암 병기 결정 장치는 전술한 신경망 모델을 이용하여 소스 영상으로부터 암 병기 정보를 추출할 수 있다. 암 병기 결정 장치는 물리적으로 다양한 형태로 구현될 수 있다. 예컨대, 암 병기 결정 장치는 PC와 같은 컴퓨터 장치, 네트워크의 서버, 영상 처리 전용 칩셋 등의 형태를 가질 수 있다. 컴퓨터 장치는 스마트 기 기 등과 같은 모바일 기기를 포함할 수 있다. 암 병기 결정 장치는 저장 장치, 메모리, 연산장치, 인터페이스 장치 및 통신 장치 를 포함한다. 저장 장치는 영상 처리 내지 분석을 위한 신경망 모델을 저장한다. 예컨대, 저장 장치는 도 2, 도 3, 도 4 및 도 7 중 적어도 하나의 유형에 따른 딥러닝 모델을 저장할 수 있다. 딥러닝 모델은 사전에 학습된 상태 라고 가정한다. 나아가 저장 장치는 영상 처리에 필요한 프로그램 내지 소스 코드 등을 저장할 수 있다. 저장 장치는 입력된 소스 영상 및 생성된 출력 영상을 저장할 수 있다. 메모리는 암 병기 결정 장치가 수신한 소스 영상 및 출력 영상 생성과정에서 생성되는 데이터 및 정 보 등을 저장할 수 있다. 인터페이스 장치는 외부로부터 일정한 명령 및 데이터를 입력받는 장치이다. 인터페이스 장치는 물리 적으로 연결된 입력 장치 또는 외부 저장 장치로부터 소스 영상을 입력받을 수 있다. 인터페이스 장치는 영상 분석을 위한 각종 신경망 모델을 입력받을 수 있다. 인터페이스 장치는 신경망 모델 생성을 위한 학 습데이터, 정보 및 파라미터값을 입력받을 수도 있다. 통신 장치는 유선 또는 무선 네트워크를 통해 일정한 정보를 수신하고 전송하는 구성을 의미한다. 통신 장 치는 외부 객체로부터 소스 영상을 수신할 수 있다. 통신 장치는 각종 신경망 모델 및 모델 학습을 위한 데이터도 수신할 수 있다. 통신 장치는 결정한 암 병기 정보 또는 출력 영상을 외부 객체로 송신할 수 있다. 통신 장치 내지 인터페이스 장치는 외부로부터 일정한 데이터 내지 명령을 전달받는 장치이다. 통신 장치 내지 인터페이스 장치를 입력장치라고 명명할 수 있다. 연산 장치는 저장장치에 저장된 신경망 모델 내지 프로그램을 이용하여 소스 영상으로부터 암 병기 정보 또는 출력 영상을 생성한다. 연산 장치는 주어진 학습 데이터를 이용하여 영상 처리 과정에 사용되는 딥러닝 모델을 학습할 수도 있다. 연산 장치는 전술한 과정을 통해 구축된 딥러닝 모델을 이용하여 소스 영상으로부터 암 병기 정보를 생성할 수 있다. 연산 장치는 데이터를 처리하고, 일정한 연산을 처리하는 프로세서, AP, 프로그램이 임베디드된 칩과 같은 장치일 수 있다. 또한, 상술한 바와 같은 의료 영상 분석 방법 내지 암 병기 결정 방법은 컴퓨터에서 실행될 수 있는 실행가능한 알고리즘을 포함하는 프로그램(또는 어플리케이션)으로 구현될 수 있다. 상기 프로그램은 비일시적 판독 가능 매체(non-transitory computer readable medium)에 저장되어 제공될 수 있다. 비일시적 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니 라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상 술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있다.본 실시례 및 본 명세서에 첨부된 도면은 전술한 기술에 포함되는 기술적 사상의 일부를 명확하게 나타내고 있 는 것에 불과하며, 전술한 기술의 명세서 및 도면에 포함된 기술적 사상의 범위 내에서 당업자가 용이하게 유추 할 수 있는 변형 예와 구체적인 실시례는 모두 전술한 기술의 권리범위에 포함되는 것이 자명하다고 할 것이다."}
{"patent_id": "10-2019-0043052", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 의료 영상을 이용한 암 병기 결정 시스템의 예이다. 도 2는 암 병기 결정을 위한 신경망 모델의 예이다. 도 3은 암 병기 결정을 위한 신경망 모델의 다른 예이다. 도 4는 암 병기 결정을 위한 신경망 모델의 또 다른 예이다. 도 5는 복수의 의료 영상을 이용한 암 병기 결정에 대한 예이다. 도 6은 폐암 병기를 나타내는 테이블의 예이다. 도 7은 암 병기 정보를 갖는 영상을 생성하는 신경망 모델의 예이다. 도 8은 의료 영상을 이용한 암 병기 결정 장치의 구성에 대한 예이다."}
