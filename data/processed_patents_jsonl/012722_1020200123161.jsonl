{"patent_id": "10-2020-0123161", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0040225", "출원번호": "10-2020-0123161", "발명의 명칭": "조리 기기 및 그의 동작 방법", "출원인": "엘지전자 주식회사", "발명자": "박윤식"}}
{"patent_id": "10-2020-0123161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "조리 기기에 있어서,디스플레이부;조리실;상기 조리실의 내부를 가열하는 가열부;상기 조리실을 촬영하는 카메라; 및상기 카메라를 통해 촬영된 이미지로부터, 식재료를 식별하고, 식별된 식재료가 유증기를 발생하는 식품군에 속하는지를 판단하고, 상기 식별된 식재료가 유증기를 발생하는 식품군에 속하는 경우, 상기 식재료의 조리 상태를 나타내는 조리 상태 정보를 획득하고, 획득된 조리 상태 정보에 기초하여, 상기 조리실의 오염도를결정하고, 결정된 오염도에 따라 청소 가이드 정보를 상기 디스플레이부를 통해 표시하거나, 상기 조리실의 청소 모드를 동작시키도록 상기 가열부를 제어하는 프로세서를 포함하는조리 기기."}
{"patent_id": "10-2020-0123161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는상기 오염도가 제1 오염 레벨인 경우, 사용자로 하여금 간이 청소를 수행하도록 하는 제1 청소 가이드 정보를상기 디스플레이부를 통해 표시하고,상기 오염도가 상기 제1 오염 레벨보다 큰 제2 오염 레벨인 경우, 상기 사용자로 하여금 상기 조리실의 내부에물을 분사하도록 하고, 제1 청소 모드로 자동 동작함을 나타내는 제2 청소 가이드 정보를 상기 디스플레이부를통해 표시하는조리 기기."}
{"patent_id": "10-2020-0123161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는상기 오염도가 상기 제2 오염 레벨보다 큰 제3 오염 레벨인 경우, 제2 청소 모드로 자동 동작 함을 나타내는 제3 청소 가이드 정보를 상기 디스플레이부를 통해 표시하고,상기 제2 청소 모드 하에서, 상기 가열부의 가열 온도 및 가열 시간 각각은 상기 제1 청소 모드 하에서 상기 가열부의 가열 온도 및 가열 시간 각각보다 큰조리 기기."}
{"patent_id": "10-2020-0123161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 조리 상태 정보는상기 식재료의 유증기 발생 추정 레벨을 포함하고,상기 조리 기기는 상기 식재료의 식별 정보에 상기 유증기 발생 추정 레벨을 매칭시킨 유증기 발생 추정 테이블공개특허 10-2022-0040225-3-을 저장하는 메모리를 더 포함하고,상기 프로세서는상기 유증기 발생 추정 테이블을 이용하여, 상기 식별된 식재료에 맞는 상기 유증기 발생 추정 레벨을획득하고,획득된 유증기 발생 추정 레벨을 이용하여, 상기 오염도를 결정하는조리 기기."}
{"patent_id": "10-2020-0123161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 조리 상태 정보는상기 식재료의 유증기 발생 추정 레벨을 포함하고,상기 프로세서는상기 식재료의 조리 중, 유증기의 발생 시점을 획득하고, 상기 발생 시점부터, 상기 유증기의 발생 유지 시간에기초하여, 상기 유증기 발생 추정 레벨을 결정하고,결정된 유증기 발생 추정 레벨을 이용하여, 상기 오염도를 결정하는조리 기기."}
{"patent_id": "10-2020-0123161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 프로세서는상기 유증기의 발생 유지 시간이 길어질수록, 상기 유증기 발생 추정 레벨의 값을 증가시키는조리 기기."}
{"patent_id": "10-2020-0123161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 조리실 내에 배치되며, 상기 유증기의 발생을 감지하는 가스 센서를 더 포함하는조리 기기."}
{"patent_id": "10-2020-0123161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 프로세서는상기 조리 상태 정보 및 조리 이력 상태 정보에 기초하여, 상기 오염도를 결정하고,상기 조리 상태 정보는 상기 식재료의 유증기 발생 추정 레벨을 포함하고,상기 조리 이력 상태 정보는 상기 조리실의 조리 횟수를 포함하는조리 기기."}
{"patent_id": "10-2020-0123161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 청소 가이드 정보를 사용자의 이동 단말기에 무선으로 전송하는 통신부를 더 포함하는공개특허 10-2022-0040225-4-조리 기기."}
{"patent_id": "10-2020-0123161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,이미지 데이터로부터 식재료를 식별하는 영상 인식 모델을 저장하는 메모리를 더 포함하고,상기 프로세서는상기 영상 인식 모델을 이용하여, 상기 촬영된 이미지로부터 상기 식재료를 식별하는조리 기기."}
{"patent_id": "10-2020-0123161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 영상 인식 모델은 상기 이미지로부터, 상기 식재료를 포함하는 객체 경계 박스를 획득하는 객체 감지 모델 및상기 객체 경계 박스로부터, 상기 식재료의 식별 정보를 획득하는 객체 식별 모델을 포함하고,상기 객체 감지 모델 및 상기 객체 식별 모델 각각은 딥 러닝 알고리즘 또는 머신 러닝 알고리즘을 통해 학습된인공 신경망 기반의 모델인조리 기기."}
{"patent_id": "10-2020-0123161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 프로세서는상기 식재료의 조리 개시 명령을 수신하고, 상기 조리 개시 명령을 수신한 시점부터, 상기 카메라의 동작을 온시키는조리 기기."}
{"patent_id": "10-2020-0123161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "조리 기기의 동작 방법에 있어서,카메라를 통해 조리실을 촬영하는 단계;촬영된 이미지로부터, 식재료를 식별하는 단계;식별된 식재료가 유증기를 발생하는 식품군에 속하는지를 판단하는 단계;상기 식별된 식재료가 유증기를 발생하는 식품군에 속하는 경우, 상기 식재료의 조리 상태를 나타내는 조리 상태 정보를 획득하는 단계;획득된 조리 상태 정보에 기초하여, 상기 조리실의 오염도를 결정하는 단계; 및결정된 오염도에 따라 청소 가이드 정보를 디스플레이부를 통해 표시하는 단계를 포함하는조리 기기의 동작 방법."}
{"patent_id": "10-2020-0123161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "조리 기기의 동작 방법을 기록한 컴퓨터로 읽을 수 있는 비 활성 기록 매체에 있어서,상기 동작 방법은카메라를 통해 조리실을 촬영하는 단계;공개특허 10-2022-0040225-5-촬영된 이미지로부터, 식재료를 식별하는 단계;식별된 식재료가 유증기를 발생하는 식품군에 속하는지를 판단하는 단계;상기 식별된 식재료가 유증기를 발생하는 식품군에 속하는 경우, 상기 식재료의 조리 상태를 나타내는 조리 상태 정보를 획득하는 단계;획득된 조리 상태 정보에 기초하여, 상기 조리실의 오염도를 결정하는 단계; 및결정된 오염도에 따라 청소 가이드 정보를 디스플레이부를 통해 표시하는 단계를 포함하는비 활성 기록 매체."}
{"patent_id": "10-2020-0123161", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 조리 기기는 카메라를 통해 촬영된 이미지로부터, 식재료를 식별하고, 식별된 식재 료가 유증기를 발생하는 식품군에 속하는지를 판단하고, 상기 식별된 식재료가 유증기를 발생하는 식품군에 속하 는 경우, 상기 식재료의 조리 상태를 나타내는 조리 상태 정보를 획득하고, 획득된 조리 상태 정보에 기초하여, 상기 조리실의 오염도를 결정하고, 결정된 오염도에 따라 청소 가이드 정보를 상기 디스플레이부를 통해 표시하 거나, 상기 조리실의 청소 모드를 동작시키도록 가열부를 제어할 수 있다."}
{"patent_id": "10-2020-0123161", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시(disclosure)는 영상 인식을 통해 조리실의 오염도를 측정하여, 조리실의 청소를 가이드할 수 있는 조리 기기에 관한 것이다."}
{"patent_id": "10-2020-0123161", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "오븐과 같은 열을 이용하는 조리 기기는 일상 생활에 있어서 필수적인 가전 제품이다. 조리 기기는 조리실 내부의 요리물을 가열하여 조리를 하게 된다. 조리실 내부는 요리물의 요리에 따라 오염될 수 있어, 조리실의 청소가 때론 필요하다. 대한민국 공개특허 KR2012-0046756A는 자가진단에 의한 청소안내가 가능한 오븐을 제공하고, 오븐 고 내에 오염 원으로부터 발생되는 암모니아 가스를 측정하고 기준치 이상일 경우, 오븐의 청소에 대한 알림 및 청소 모드를 동작시키는 내용을 개시하고 있다. 그러나, 종래 기술은 오염원의 부폐로 인해 발생되는 암모니아 측정량을 통해 오븐의 청소 유무를 판단한다. 이 경우, 오염물에 의한 유해 가스가 발생하는 수준에서 판단 가능하기 때문에 오염이 이미 진행된 상황일 수 있어, 오븐의 위생/청소에 대한 선제적 가이드가 어려운 문제가 있다. 또한, 오븐 고내의 위생 수준 판단 기준을 암모니아 가스 측정량 만으로 일반화 어려운 문제가 있다."}
{"patent_id": "10-2020-0123161", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 조리 과정에서 발생되는 오염도를 인식하여, 오염도에 맞는 조리실의 청소를 선제적으로 가이드할 수 있는 조리 기기의 제공을 그 목적으로 한다. 본 개시는 조리 과정에서 발생되는 오염도를 인식하여, 오염도에 맞는 조리실의 청소를 선제적으로 자동 수행할 수 있는 조리 기기의 제공을 그 목적으로 한다. 본 개시는 조리실의 오염도에 따라 단계 별 청소 관리를 제공할 수 있는 조리 기기의 제공을 그 목적으로 한다."}
{"patent_id": "10-2020-0123161", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 실시 예에 따른 조리 기기는 카메라를 통해 촬영된 이미지로부터, 식별된 식재료가 유증기를 발생하 는 식품군에 속하는 경우, 상기 식재료의 조리 상태를 나타내는 조리 상태 정보에 기초하여, 상기 조리실의 오 염도를 결정하고, 결정된 오염도에 따라 청소 가이드 정보를 상기 디스플레이부를 통해 표시할 수 있다. 본 개시의 실시 예에 따른 조리 기기는 결정된 오염도에 맞는 청소를 자동 수행하도록 가열부를 제어할 수 있다. 본 개시의 실시 예에 따른 조리 기기는 오염도가 제1 오염 레벨인 경우, 사용자로 하여금 간이 청소를 수행하도 록 하는 제1 청소 가이드 정보를 상기 디스플레이부를 통해 표시하고, 상기 오염도가 상기 제1 오염 레벨보다 큰 제2 오염 레벨인 경우, 상기 사용자로 하여금 상기 조리실의 내부에 물을 분사하도록 하고, 제1 청소 모드로 자동 동작함을 나타내는 제2 청소 가이드 정보를 상기 디스플레이부를 통해 표시하고, 상기 오염도가 상기 제2오염 레벨보다 큰 제3 오염 레벨인 경우, 제2 청소 모드로 자동 동작 함을 나타내는 제3 청소 가이드 정보를 상 기 디스플레이부를 통해 표시할 수 있다."}
{"patent_id": "10-2020-0123161", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시 예에 따르면, 조리실의 오염도가 심각해 지기 전에, 조리실의 청소를 위한 정보가 가이드 되어, 사용자는 오염도에 적합한 조치를 효율적으로 취할 수 있다. 본 개시의 실시 예에 따르면, 조리실의 오염도가 심각해 지기 전에, 조리실의 청소가 자동으로 수행되어, 조리 실의 청결이 유지될 수 있다. 본 개시의 실시 예에 따르면, 사용자에게 추정된 조리실의 오염도에 해당되는 위생/청소 단계를 선택적으로 설 정 가능하도록 제공하여, 사용자의 기호에 맞는 청소 관리가 행해질 수 있다."}
{"patent_id": "10-2020-0123161", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 '모듈' 및 '부'는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 개시의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 '연결되어' 있다거나 '접속되어' 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 '직접 연결되어' 있다거나 '직접 접속되어' 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 도 1은 본 개시의 일 실시 예에 따른 조리 기기를 나타낸 블록도이다. 도 1을 참조하면, 조리 기기는 통신부, 입력부, 러닝 프로세서, 센싱부, 출력부 , 메모리, 프로세서 및 가열부를 포함할 수 있다. 통신부는 유무선 통신 기술을 이용하여 다른 AI 장치나 AI 서버 등의 외부 장치들과 데이터를 송수신할 수 있다. 예컨대, 통신부는 외부 장치들과 센서 정보, 사용자 입력, 학습 모델, 제어 신호 등을 송수신할 수 있다. 이때, 통신부가 이용하는 통신 기술에는 GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), LTE(Long Term Evolution), 5G, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), 블 루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), ZigBee, NFC(Near Field Communication) 등이 있다. 통신부는 통신 모뎀(communication modem) 또는 통신 회로(communication circuit)라고도 칭할 수 있다. 입력부는 다양한 종류의 데이터를 획득할 수 있다. 이때, 입력부는 영상 신호 입력을 위한 카메라, 오디오 신호를 수신하기 위한 마이크로폰, 사용자로부터 정보를 입력 받기 위한 사용자 입력부 등을 포함할 수 있다. 여기서, 카메라나 마이크로폰을 센서로 취급하여, 카메라나 마이크로폰으로부터 획득한 신호를 센싱 데이터 또는 센서 정보라고 할 수도 있다. 입력부는 모델 학습을 위한 학습 데이터 및 학습 모델을 이용하여 출력을 획득할 때 사용될 입력 데이터 등을 획득할 수 있다. 입력부는 가공되지 않은 입력 데이터를 획득할 수도 있으며, 이 경우 프로세서 또는 러닝 프로세서는 입력 데이터에 대하여 전처리로써 입력 특징점(input feature)을 추출할 수 있다. 입력부는 영상 신호 입력을 위한 카메라(Camera, 121), 오디오 신호를 수신하기 위한 마이크로폰 (Microphone, 122), 사용자로부터 정보를 입력 받기 위한 사용자 입력부(User Input Unit, 123)를 포함할 수 있다. 입력부에서 수집한 음성 데이터나 이미지 데이터는 분석되어 사용자의 제어 명령으로 처리될 수 있다. 입력부는 영상 정보(또는 신호), 오디오 정보(또는 신호), 데이터, 또는 사용자로부터 입력되는 정보의 입 력을 위한 것으로서, 영상 정보의 입력을 위하여, 조리 기기는 하나 또는 복수의 카메라들을 구비할 수 있다. 카메라는 화상 통화모드 또는 촬영 모드에서 이미지 센서에 의해 얻어지는 정지영상 또는 동영상 등의 화 상 프레임을 처리한다. 처리된 화상 프레임은 디스플레이부(Display Unit, 151)에 표시되거나 메모리에 저 장될 수 있다. 마이크로폰은 외부의 음향 신호를 전기적인 음성 데이터로 처리한다. 처리된 음성 데이터는 조리 기기 에서 수행 중인 기능(또는 실행 중인 응용 프로그램)에 따라 다양하게 활용될 수 있다. 한편, 마이크로폰 에는 외부의 음향 신호를 입력 받는 과정에서 발생되는 잡음(noise)을 제거하기 위한 다양한 잡음 제거 알 고리즘이 적용될 수 있다. 사용자 입력부는 사용자로부터 정보를 입력 받기 위한 것으로서, 사용자 입력부를 통해 정보가 입력 되면, 프로세서는 입력된 정보에 대응되도록 조리 기기의 동작을 제어할 수 있다. 사용자 입력부는 기계식 (mechanical) 입력수단(또는, 메커니컬 키, 예컨대, 조리 기기의 전/후면 또 는 측면에 위치하는 버튼, 돔 스위치 (dome switch), 조그 휠, 조그 스위치 등) 및 터치식 입력수단을 포함할 수 있다. 일 예로서, 터치식 입력수단은, 소프트웨어적인 처리를 통해 터치스크린에 표시되는 가상 키(virtual key), 소프트 키(soft key) 또는 비주얼 키(visual key)로 이루어지거나, 상기 터치스크린 이외의 부분에 배치 되는 터치 키(touch key)로 이루어질 수 있다. 러닝 프로세서는 학습 데이터를 이용하여 인공 신경망으로 구성된 모델을 학습시킬 수 있다. 여기서, 학습 된 인공 신경망을 학습 모델이라 칭할 수 있다. 학습 모델은 학습 데이터가 아닌 새로운 입력 데이터에 대하여 결과 값을 추론해 내는데 사용될 수 있고, 추론된 값은 어떠한 동작을 수행하기 위한 판단의 기초로 이용될 수 있다. 이때, 러닝 프로세서는 AI 서버의 러닝 프로세서과 함께 AI 프로세싱을 수행할 수 있다. 이때, 러닝 프로세서는 조리 기기에 통합되거나 구현된 메모리를 포함할 수 있다. 또는, 러닝 프로세 서는 메모리, 조리 기기에 직접 결합된 외부 메모리 또는 외부 장치에서 유지되는 메모리를 사 용하여 구현될 수도 있다. 센싱부는 다양한 센서들을 이용하여 조리 기기 내부 정보, 조리 기기의 주변 환경 정보 및 사용 자 정보 중 적어도 하나를 획득할 수 있다. 이때, 센싱부에 포함되는 센서에는 근접 센서, 조도 센서, 가속도 센서, 자기 센서, 자이로 센서, 관성 센 서, RGB 센서, IR 센서, 지문 인식 센서, 초음파 센서, 광 센서, 마이크로폰, 라이다, 레이더 등이 있다. 출력부는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시킬 수 있다. 이때, 출력부에는 시각 정보를 출력하는 디스플레이부, 청각 정보를 출력하는 스피커, 촉각 정보를 출력하 는 햅틱 모듈 등이 포함될 수 있다. 출력부는 디스플레이부(Display Unit, 151), 음향 출력부(Sound Output Unit, 152), 햅틱 모듈(Haptic Module, 153), 광 출력부(Optical Output Unit, 154) 중 적어도 하나를 포함할 수 있다. 디스플레이부는 조리 기기에서 처리되는 정보를 표시(출력)한다. 예컨대, 디스플레이부는 조리 기기에서 구동되는 응용 프로그램의 실행화면 정보, 또는 이러한 실행화면 정보에 따른 UI(User Interface), GUI(Graphic User Interface) 정보를 표시할 수 있다. 디스플레이부는 터치 센서와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써, 터치 스크린을 구현 할 수 있다. 이러한 터치 스크린은, 조리 기기와 사용자 사이의 입력 인터페이스를 제공하는 사용자 입력 부로써 기능함과 동시에, 단말기와 사용자 사이의 출력 인터페이스를 제공할 수 있다. 음향 출력부는 호신호 수신, 통화모드 또는 녹음 모드, 음성인식 모드, 방송수신 모드 등에서 통신부(11 0)로부터 수신되거나 메모리에 저장된 오디오 데이터를 출력할 수 있다. 음향 출력부는 리시버(receiver), 스피커(speaker), 버저(buzzer) 중 적어도 하나 이상을 포함할 수 있다. 햅틱 모듈(haptic module)은 사용자가 느낄 수 있는 다양한 촉각 효과를 발생시킨다. 햅틱 모듈이 발 생시키는 촉각 효과의 대표적인 예로는 진동이 될 수 있다. 광출력부는 조리 기기의 광원의 빛을 이용하여 이벤트 발생을 알리기 위한 신호를 출력한다. 조리 기 기에서 발생 되는 이벤트의 예로는 메시지 수신, 호 신호 수신, 부재중 전화, 알람, 일정 알림, 이메일 수 신, 애플리케이션을 통한 정보 수신 등이 될 수 있다. 메모리는 조리 기기의 다양한 기능을 지원하는 데이터를 저장할 수 있다. 예컨대, 메모리는 입 력부에서 획득한 입력 데이터, 학습 데이터, 학습 모델, 학습 히스토리 등을 저장할 수 있다. 프로세서는 데이터 분석 알고리즘 또는 머신 러닝 알고리즘을 사용하여 결정되거나 생성된 정보에 기초하 여, 조리 기기의 적어도 하나의 실행 가능한 동작을 결정할 수 있다. 그리고, 프로세서는 조리 기기 의 구성 요소들을 제어하여 결정된 동작을 수행할 수 있다. 이를 위해, 프로세서는 러닝 프로세서 또는 메모리의 데이터를 요청, 검색, 수신 또는 활용할 수 있고, 상기 적어도 하나의 실행 가능한 동작 중 예측되는 동작이나, 바람직한 것으로 판단되는 동작을 실행 하도록 조리 기기의 구성 요소들을 제어할 수 있다. 이때, 프로세서는 결정된 동작을 수행하기 위하여 외부 장치의 연계가 필요한 경우, 해당 외부 장치를 제 어하기 위한 제어 신호를 생성하고, 생성한 제어 신호를 해당 외부 장치에 전송할 수 있다. 프로세서는 사용자 입력에 대하여 의도 정보를 획득하고, 획득한 의도 정보에 기초하여 사용자의 요구 사 항을 결정할 수 있다. 이때, 프로세서는 음성 입력을 문자열로 변환하기 위한 STT(Speech To Text) 엔진 또는 자연어의 의도 정 보를 획득하기 위한 자연어 처리(NLP: Natural Language Processing) 엔진 중에서 적어도 하나 이상을 이용하여, 사용자 입력에 상응하는 의도 정보를 획득할 수 있다. 이때, STT 엔진 또는 NLP 엔진 중에서 적어도 하나 이상은 적어도 일부가 머신 러닝 알고리즘에 따라 학습된 인 공 신경망으로 구성될 수 있다. 그리고, STT 엔진 또는 NLP 엔진 중에서 적어도 하나 이상은 러닝 프로세서 에 의해 학습된 것이나, AI 서버의 러닝 프로세서에 의해 학습된 것이거나, 또는 이들의 분산 처리에 의해 학습된 것일 수 있다. 프로세서는 조리 기기의 동작 내용이나 동작에 대한 사용자의 피드백 등을 포함하는 이력 정보를 수 집하여 메모리 또는 러닝 프로세서에 저장하거나, AI 서버 등의 외부 장치에 전송할 수 있다. 수집된 이력 정보는 학습 모델을 갱신하는데 이용될 수 있다. 프로세서는 메모리에 저장된 응용 프로그램을 구동하기 위하여, 조리 기기의 구성 요소들 중 적 어도 일부를 제어할 수 있다. 나아가, 프로세서는 상기 응용 프로그램의 구동을 위하여, 조리 기기에 포함된 구성 요소들 중 둘 이상을 서로 조합하여 동작시킬 수 있다. 가열부는 공급되는 에너지를 이용하여 열을 발생시킬 수 있다. 가열부는 공급되는 전기를 이용하여 열을 발생시키고, 발생시킨 열을 이용하여 조리 기기의 내부를 가열시킬 수 있다. 가열부는 조리실의 내부에 구비될 수 있다. 가열부는 조리실의 측단 또는 하단에 배치될 수 있다. 가열부는 전기 에너지를 열 에너지로 변환하는 회로를 포함할 수 있다. 이하에서, 조리 기기는 인공 지능 조리 기기 또는 인공 지능 오븐(oven)이라 칭할 수도 있다. 또한, 조리 기기가 벽에 부착된 형태로 구비되는 경우, 월 오븐(Wall Oven)이라 명명될 수 있다. 도 2는 본 개시의 일 실시 예에 따른 조리기기의 사시도이고, 도 3은 도 2의 조리기기에서 도어가 열린 상태를 보여주는 사시도이다. 조리 기기는, 내부에 각종 부품을 수용하는 본체를 포함할 수 있다. 본체는, 조리실을 형성하는 내측 프레임과, 내측 프레임의 외측에서 내측 프레임을 둘러싸 는 외측 프레임을 포함할 수 있다. 내측 프레임의 상단부에는 카메라가 구비될 수 있다. 카메라는 조리실을 촬영할 수 있다. 촬 영된 이미지는 조리 중인 식재료를 인식하는데 사용될 수 있다. 내측 프레임의 전단부에는 본체 패널이 구비될 수 있다. 본체 패널은 상기 내측 프레임의 전단부에 결합되거나 전단부와 일체로 형성될 수 있다. 도어는, 본체에 힌지 기구에 의해서 회전 가능하게 연결될 수 있다. 일 예로 도어의 하단에 힌지 기구가 연결될 수 있다. 조리실로 공급된 열에 의한 온도 상승을 최소화하기 위하여, 도어 외부의 공기는 도어 내부로 유동 할 수 있다. 따라서, 도어는 도어 내부를 유동한 공기가 배출되는 도어 공기 출구를 포함하고, 상기 본체는 상기 도어 공기 출구를 통해 배출된 공기가 유입되는 본체 공기 입구를 포함할 수 있다. 본체 공기 입구는 본체 패널에 형성될 수 있다. 또한, 본체 공기 입구를 통해 본체로 유입된 공기는 상기 본체를 유동한 후에 본체 공기 출구 를 통해 본체의 외부로 배출될 수 있다. 본체 공기 출구도 본체 패널에 형성될 수 있다. 도어는 컨트롤 장치를 더 포함할 수 있다. 컨트롤 장치는 제한적이지는 않으나, 도어에서 상측부에 위치되고, 도어가 닫힌 상태에서 본체 패 널 중에서 조리실의 상측에 위치되는 부분과 마주보도록 위치될 수 있다. 컨트롤 장치는, 디스플레이부와 사용자 입력부 중 하나 이상을 포함할 수 있다. 디스플레이부는 터치 입력을 수신할 수 있는 터치 스크린의 형태로 구현될 수 있다. 컨트롤 장치를 통해서 조리 기기의 작동 정보를 표시 및/또는 사용자의 작동 명령을 입력받을 수 있 다. 도 4는 본 개시의 일 실시 예에 따른 조리 기기의 동작 방법을 설명하는 흐름도이다. 특히, 도 4는 조리 상태를 인지하여, 조리 기기의 조리실의 청소 또는 위생에 대해 선제적(Proactiv e)으로 대응할 수 있는 방법을 설명하는 도면이다. 도 4를 참조하면, 조리 기기의 프로세서는 식재료의 조리가 개시된 경우, 카메라를 통해 조리실 을 촬영한 이미지를 획득한다(S401). 프로세서는 사용자 입력부 또는 디스플레이부를 통해 조리 개시 명령을 수신한 경우, 조리 기기 에 탑재된 카메라를 통해 조리실의 내부를 촬영하고, 촬영된 이미지를 획득할 수 있다. 프로세서는 식재료의 조리 개시 명령을 수신하고, 조리 개시 명령을 수신한 시점부터, 카메라의 동작 을 온 시킬 수 있다. 프로세서는 영상 인식 모델을 이용하여, 획득된 이미지로부터 하나 이상의 식재료를 식별한다(S403). 프로세서는 영상 인식 모델를 이용하여, 이미지에 포함된 식재료를 식별할 수 있다. 영상 인식 모델은 딥 러닝 알고리즘 또는 머신 러닝 알고리즘에 의해 학습된 인공 신경만 기반의 모델일 수 있 다. 영상 인식 모델은 이미지 데이터를 기반으로, 이미지 데이터에 포함된 객체가 무엇인지를 추론하는 모델일 수 있다. 객체는 식재료가 될 수 있다. 영상 인식 모델은 인공 지능 서버에 의해 학습되고, 인공 지능 서버로부터 수신되어 조리 기기의 메모리 에 저장된 모델일 수 있다. 프로세서는 메모리에 저장된 영상 인식 모델을 이용하여, 이미지에 상응하는 이미지 데이터로부터 이 미지에 포함된 식재료를 식별할 수 있다. 또 다른 예로, 프로세서는 촬영된 이미지를 통신부를 통해 인공 지능 서버에 전송할 수 있다. 인공 지능 서버는 영상 인식 모델을 이용하여, 이미지로부터 객체 식별 정보를 추출할 수 있고, 추출된 객체 식별 정 보를 조리 기기에 전송할 수 있다. 영상 인식 모델은 객체 감지 모델 및 객체 식별 모델을 포함할 수 있다. 객체 감지 모델은 이미지 데이터로부터 하나 이상의 객체를 감지하는 모델이고, 객체 식별 모델은 감지된 하나 이상의 객체가 무엇인지를 식별하는 모델일 수 있다. 객체 감지 모델을 이용하여, 영상으로부터, 복수의 객체들을 감지하고, 객체 식별 모델을 이용하여, 감지된 객 체를 식별하는 과정을 설명한다. 도 5 및 도 6은 본 개시의 실시 예에 따른 객체 감지 모델의 학습 과정을 설명하는 도면이다. 도 5를 참조하면, 객체 감지 모델은 복수의 영상 데이터들을 포함하는 학습용 영상 데이터 세트를 이 용하여, 각 학습용 영상 데이터로부터, 복수의 객체들을 포함하는 객체 경계 박스 세트를 획득할 수 있다. 객체 경계 박스 세트는 객체를 포함하는 경계 박스들의 집합일 수 있다. 객체 감지 모델은 SSD(Single Shot multibox Detector) MobilenetV2, Faster R-CNN Inception, YOLO(You Only Look Once) 알고리즘을 이용하여, 영상 데이터로부터, 복수의 객체들을 감지할 수 있다. YOLO(You Only Look Once) 알고리즘은 복수의 CNN들로 구성될 수 있다. YOLO(You Only Look Once) 알고리즘은 그리드 분할 과정, 예측 과정, 신뢰도 계산 과정, 객체 선정 과정을 포함 할 수 있다. 그리드 분할 과정은 이미지 데이터를 복수의 그리드들로 나누는 과정일 수 있다. 복수의 그리드들 각각의 크기 는 동일할 수 있다.예측 과정은 각 그리드에 대해 그리드 중앙을 중심으로, 미리 정의된 형태(predefined shape)로 지정된 경계 박 스의 개수를 예측하는 과정일 수 있다. 미리 정의된 형태(predefined shape)로 지정된 경계 박스는 K-평균 알고리즘에 의한 데이터로부터 생성될 수 있 고, 객체의 크기 및 형태에 대한 사전 정보를 담고 있을 수 있다. 각 경계 박스는 각기 다른 크기 및 형태의 객체를 감지하도록 설계될 수 있다. 각 경계 박스는 객체의 형태 또는 경계를 나타낼 수도 있다. 신뢰도 계산 과정은 예측 과정에서, 얻어진 경계 박스들 각각에 객체가 포함되어 있는지, 배경만 단독으로 있는 지 여부에 따라, 경계 박스의 신뢰도를 계산하는 과정일 수 있다. 객체 판단 과정은 신뢰도 계산 과정에 따라 기 설정된 값 이상의 신뢰도를 갖는 경계 박스에 객체가 존재하는 것으로 판단하는 과정일 수 있다. 객체 판단 과정을 통해 이미지 데이터에 포함된 복수의 경계 박스들(601 내지 607)이 추출될 수 있다. 프로세서는 객체 감지 모델을 통해 추출된 복수의 경계 박스들로부터, 각 객체의 식별 정보를 획득할 수 있다. 프로세서는 객체 식별 모델을 이용하여, 각 경계 박스에 해당하는 이미지 데이터로부터, 경계 박스 내에 존재하는 객체를 식별할 수 있다. 객체 식별 모델은 딥 러닝 알고리즘 또는 머신 러닝 알고리즘을 이용하여, 학습된 인공 신경망 기반의 모델일 수 있다. 객체 식별 모델은 지도 학습을 통해 학습된 모델일 수 있다. 객체 식별 모델은 이미지 데이터로부터, 객체의 식별 정보를 추론하는 모델일 수 있다. 객체의 식별 정보는 객 체의 명칭, 객체의 식별자 등 객체를 식별하는 정보일 수 있다. 객체 식별 모델은 학습용 이미지 데이터 및 학습용 이미지 데이터에 레이블된 레이블링 데이터를 포함하는 트레 이닝 데이터 세트를 입력 데이터로 하여, 객체의 식별 정보를 출력하는 모델일 수 있다. 도 7은 본 개시의 일 실시 예에 따른 객체 식별 모델의 학습 과정을 보여준다. 도 7을 참조하면, 객체 식별 모델은 학습용 이미지 데이터 및 이에 레이블된 레이블링 데이터를 포함하는 트레이닝 데이터 세트를 이용하여, 객체 식별 정보를 추론할 수 있다. 레이블링 데이터는 정답 데이터로, 객체 식별 정보일 수 있다. 객체 식별 모델은 레이블링 데이터와 객체 식별 정보 간의 차이에 상응하는 비용 함수를 최소화하도록 학 습될 수 있다. 객체 식별 모델의 비용 함수는 각 이미지 데이터에 상응하는 객체 식별 정보에 대한 라벨과, 각 이미지 데 이터로부터 추론된 객체 식별 정보 간의 차이의 제곱 평균으로 표현될 수 있다. 학습용 이미지 데이터에서 입력 특징 벡터가 추출되어, 입력되면, 객체의 식별 결과가 대상 특징 벡터로서 출력 되고, 객체 식별 모델은 출력된 대상 특징 벡터와 라벨링된 객체 식별 정보의 차이에 상응하는 손실 함수 를 최소화하도록 학습되는 것일 수 있다. 객체 식별 모델은 조리 기기의 러닝 프로세서 또는 AI 서버의 러닝 프로세서에 의해 학습되어, 조리 기기에 탑재될 수 있다. 객체 식별 모델은 도 6에 도시된, 제1 경계 박스에 해당되는 제1 이미지 데이터로부터, 제1 객체 식 별 정보를 결정할 수 있다. 예를 들어, 제1 객체 식별 정보는 스테이크일 수 있다. 객체 식별 모델은 제2 경계 박스에 해당되는 제2 이미지 데이터로부터, 제2 객체 식별 정보를 결정할 수 있다. 예를 들어, 제2 객체 식별 정보는 당근일 수 있다. 이와 같이, 객체 식별 모델을 통해, 이미지 데이터로부터, 객체가 어떤 식품인지가 식별될 수 있다. 다시, 도 4를 설명한다. 프로세서는 식별된 식재료가 유증기를 발생하는 식품군에 속하는지를 판단한다(S405). 프로세서는 유증기 발생 식품군은 유증기를 발생할 수 있는 복수의 식품들을 포함할 수 있다. 유중기 발생 식품군에 대한 정보는 메모리에 저장되어 있을 수 있다. 도 8은 유증기를 발생하는 식품군을 나타내는 도면일 수 있다. 유증기 발생 식품군은 육류, 생선 및 빵을 포함할 수 있다. 조리 기기의 메모리는 유증기 발생 식품군에 속하는 식품들의 명칭을 포함할 수 있다. 프로세서는 식별된 식재료가 유증기 발생 식품군에 속하는지를 판단하고, 판단 결과를 출력할 수 있 다. 다시, 도 4를 설명한다. 프로세서는 식별된 식재료가 유증기를 발생하는 식품군으로 판단된 경우, 식재료의 조리 상태를 나타내는 조리 상태 정보를 획득한다(S407). 조리 상태 정보는 식재료의 조리 시간, 조리 온도, 유증기 발생 정도 중 하나 이상을 포함할 수 있다. 조리 시간은 식재료의 조리 시작 시점부터 조리 종료 시점까지의 시간일 수 있다. 조리 온도는 식재료의 조리 시, 설정된 온도일 수 있다. 유증기 발생 정도는 조리 시간 동안 발생된 유증기의 추정량에 대응될 수 있다. 조리 기기의 센싱부는 가스 센서(미도시)를 포할 수 있다. 가스 센서는 조리실의 내부에 구비될 수 있다. 프로세서는 조리 시간 동안, 가스 센서를 통해 유증기의 발생 유무를 감지하고, 유증기가 발생된 경우, 유 증기의 발생 정도를 예측할 수 있다. 프로세서는 식재료에 따른 유증기 발생 정도를 나타내는 유증기 발생 추정 테이블을 이용하여, 유증기 발 생 정도를 획득할 수 있다. 이에 대해서는, 도 9를 참조하여 설명한다. 도 9는 본 개시의 일 실시 예에 따른 식재료에 따른 유증기 발생 정도를 나타내는 유증기 발생 추정 테이블을 도시한 도면이다. 도 9의 유증기 발생 추정 테이블은 메모리에 저장되어 있을 수 있다. 도 9를 참조하면, 유증기 발생 추정 테이블은 영상 인식 기반을 통해 얻어진 식재료의 식별 정보(카테고리)에 대응하는 유증기 발생 추정 레벨이 매칭되어 있다. 유증기 발생 추정 레벨은 대/중/소 3개의 레벨로 구별될 수 있으나, 이는 예시에 불과하다. 유증기 발생 추정량 이 0~100의 범위를 갖는 경우, 대 레벨은 70이상 100 이하, 중 레벨은 30 이상 70미만, 소 레벨은 0 이상 30 미 만의 값에 대응될 수 있다. 예를 들어, 식별된 식재료가 Beef, Por, Poultry, fish인 경우, 유증기 발생 추정 레벨은 대 레벨이 될 수 있다. 식별된 식재료가 Pizza인 경우, 유증기 발생 추정 레벨은 중 레벨이 될 수 있다. 식별된 식재료가 Dessert(예를 들어, 빵, 케??, 쿠키 등)인 경우, 유증기 발생 추정 레벨은 소 레벨이 될 수 있 다. 유증기 발생 추정 테이블은 유증기 발생 추정 모델에 의해 학습되어 얻어질 테이블일 수 있다. 유증기 발생 추정 모델은 식재료에 따라 발생되는 유증기 발생량을 추정하는 인공 신경망 기반의 학습 모델일 수 있다. 조리 기기의 프로세서는 유증기 발생 추정 테이블을 이용하여, 식별된 식재료에 대응하는 유증 기 발생 추정 레벨을 획득할 수 있다.다시, 도 4를 설명한다. 또 다른 실시 예에 따르면, 프로세서는 유증기가 감지된 시점 및 유증기가 감지된 시점부터, 조리된 기간 동안에 기초하여, 유증기 발생 추정 레벨을 획득할 수 있다. 이에 대해서는, 도 10을 참조하여 설명한다. 도 10은 본 개시의 일 실시 예에 따라 유증기 감지 시점부터, 식재료의 조리 기간에 따라 유증기 발생 추정 레 벨을 결정하는 방법을 설명하는 도면이다. 도 10의 그래프의 가로축은 시간이고, 세로축은 온도를 나타낸다. 프로세서는 조리 개시 후, 조리실에 구비된 가스 센서를 통해 유증기가 감지된 것으로 판단한 경우, 유증기의 발생 시점인 제1 시점(t1)을 획득할 수 있다. 프로세서는 제1 시점(t1)부터, 제2 시점(t2)이하의 기간까지 유증기의 발생이 유지되는 경우, 유증기 발생 추정 레벨을 소 레벨로 결정할 수 있다. 프로세서는 제1 시점(t1)부터, 제3 시점(t3)이하의 기간까지 유증기의 발생이 유지되는 경우, 유증기 발생 추정 레벨을 중 레벨로 결정할 수 있다. 프로세서는 제1 시점(t1)부터, 제4 시점(t4)을 넘는 기간까지 유증기의 발생이 유지되는 경우, 유증기 발 생 추정 레벨을 대 레벨로 결정할 수 있다. 프로세서는 유증기의 발생 유지 시간이 길어질수록, 유증기 발생 추정 레벨의 값을 증가시킬 수 있다. 또 다른 예로, 유증기 발생 추정 레벨은 유증기 발생 유지 기간에 온도가 추가적으로 더 고려되어 결정될 수 있 다. 프로세서는 제1 시점(t1)부터, 제2 시점(t2)이하의 기간까지 유증기의 발생이 유지되고, 조리실의 가 열 온도가 일정 온도(K)이상인 경우, 유증기 발생 추정 레벨을 소 레벨로 결정할 수 있다. 프로세서는 제1 시점(t1)부터, 제3 시점(t3)이하의 기간까지 유증기의 발생이 유지되고, 조리실의 가 열 온도가 일정 온도(K)이상인 경우, 유증기 발생 추정 레벨을 중 레벨로 결정할 수 있다. 프로세서는 제1 시점(t1)부터, 제4 시점(t4)을 넘는 기간까지 유증기의 발생이 유지되고, 조리실의 가 열 온도가 일정 온도(K)이상인 경우, 유증기 발생 추정 레벨을 대 레벨로 결정할 수 있다. 다시, 도 4를 설명한다. 프로세서는 식재료의 조리 종료 후, 획득된 조리 상태 정보에 기초하여, 조리실의 오염도를 결정한다 (S409). 조리실의 오염도는 제1 오염 레벨, 제1 오염 레벨보다 큰 제2 오염 레벨, 제2 오염 레벨보다 큰 제3 오염 레벨로 구분될 수 있다. 일 실시 예에서, 프로세서는 조리 상태 정보에 포함된 유증기 발생 추정 레벨을 이용하여, 조리실의 오염도를 결정할 수 있다. 예를 들어, 프로세서는 유증기 발생 추정 레벨이 대 레벨인 경우, 오염도를 제3 오염 레벨로 결정할 수 있 다. 프로세서는 유증기 발생 추정 레벨이 중 레벨인 경우, 오염도를 제2 오염 레벨로 결정할 수 있다. 프 로세서는 유증기 발생 추정 레벨이 소 레벨인 경우, 오염도를 제1 오염 레벨로 결정할 수 있다. 또 다른 실시 예에서, 프로세서는 조리 상태 정보 및 조리 이력 상태 정보에 기초하여, 조리실의 오염 도를 결정할 수 있다. 조리 이력 상태 정보는 조리실의 마지막 청소 후, 식재료의 조리 횟수를 포함할 수 있다. 여기서, 식재료는 이전 조리에서 사용된 재료와 동일한 식재료일 수 있으나, 이에 한정될 필요는 없다. 프로세서는 조리실의 마지막 청소 후, 도어가 1회 개방 및 1회 폐쇄된 경우, 이를 1회의 조리 횟 수로 결정할 수 있다. 조리 횟수는 조리실의 사용 횟수로 표현될 수도 있다. 프로세서는 유증기 발생 추정 레벨 및 조리 횟수에 기초하여, 조리실의 오염도를 결정할 수 있다. 이에 대해서는, 도 11을 참조하여 설명한다. 도 11은 본 개시의 실시 예에 따른 유증기 발생 추정 레벨 및 식재료의 조리 횟수에 따라 조리실의 오염도를 결 정하는 과정을 설명하는 도면이다. 도 11의 오염도 결정 테이블은 조리 기기의 메모리에 미리 저장되어 있을 수 있다. 예를 들어, 프로세서는 유증기 발생 추정 레벨이 대 레벨 또는 중 레벨이고, 식재료의 조리 횟수가 7회 이 상인 경우, 오염도를 제3 오염 레벨로 결정할 수 있다. 프로세서는 유증기 발생 추정 레벨이 대 레벨 또는 중 레벨이고, 식재료의 조리 횟수가 1회 이상 6회 이하 인 경우, 오염도를 제2 오염 레벨로 결정할 수 있다. 프로세서는 유증기 발생 추정 레벨이 소 레벨이고, 식재료의 조리 횟수가 6회 이상인 경우, 오염도를 제2 오염 레벨로 결정할 수 있다. 프로세서는 유증기 발생 추정 레벨이 소 레벨이고, 식재료의 조리 횟수가 3회 이상 6회 이하인 경우, 오염 도를 제1 오염 레벨로 결정할 수 있다. 프로세서는 결정된 조리실의 오염도에 기초하여, 조리실의 청소를 가이드하는 가이드 정보를 출력 하거나, 조리실의 자동 청소를 개시한다(S411). 가이드 정보는 결정된 오염도에 적합한 조리실의 청소 방법을 가이드하기 위한 정보일 수 있다. 가이드 정 보는 조리실의 청소 방법을 가이드하는 텍스트 또는 이미지 중 하나 이상을 포함할 수 있다. 프로세서는 디스플레이부를 통해 가이드 정보를 표시할 수 있다. 프로세서는 가이드 정보를 통신부를 통해 사용자의 이동 단말기에 전송할 수도 있다. 프로세서는 가이드 정보를 출력하면서, 결정된 오염도에 따라 필요한 경우, 조리실의 자동 청소를 개 시할 수 있다. 예를 들어, 프로세서는 결정된 오염도가 제2 오염 레벨인 경우, 제1 온도로, 일정 시간 동안 조리실을 가열하도록 가열부를 제어할 수 있다. 또 다른 예로, 프로세서는 결정된 오염도가 제3 오염 레벨인 경우, 제2 온도 이상으로, 일정 시간 동안, 조리실을 고온 가열하도록 가열부를 제어할 수 있다. 이에 대해서는 도 12 내지 도 14를 참조하여 설명한다. 도 12 내지 도 14는 결정된 오염도에 따라 조리 기기의 디스플레이부를 통해 가이드 정보를 표시하는 예를 설명 하는 도면이다. 도 12는 결정된 오염도가 제1 오염 레벨인 경우, 표시되는 제1 청소 가이드 정보를 보여주는 도면이다. 프로세서는 오염도가 제1 오염 레벨로 결정된 경우, 제1 청소 가이드 정보를 디스플레이부를 통해 표시할 수 있다. 제1 청소 가이드 정보는 제1 가이드 텍스트 및 제1 가이드 이미지를 포함할 수 있다. 제1 가이드 텍스트는 오염도가 제1 오염 레벨이고, 간이 청소를 수행라는 텍스트를 포함할 수 있다. 간이 청소는 사용자가 수동으로 조리실을 청소하는 것일 수 있다. 제1 가이드 이미지는 간이 청소를 수행하는 방법을 나타내는 이미지일 수 있다. 도 13은 결정된 오염도가 제2 오염 레벨인 경우, 표시되는 제2 청소 가이드 정보를 보여주는 도면이다. 프로세서는 오염도가 제2 오염 레벨로 결정된 경우, 제2 청소 가이드 정보를 디스플레이부를 통해 표시할 수 있다. 제2 청소 가이드 정보는 제2 가이드 텍스트 및 제2 가이드 이미지를 포함할 수 있다. 제2 가이드 텍스트는 오염도가 제2 오염 레벨이고, Easy Clean 모드를 자동으로 동작시킴을 나타내고, 조 리실의 내부에 물의 분사를 유도하는 텍스트를 포함할 수 있다. Easy Clean 모드는 제1 온도로, 일정 시간 동안 조리실을 가열하여, 조리실의 내부를 청소하는 모드일 수 있다. 제2 가이드 이미지는 조리실의 내부에 물을 분사함을 나타내는 이미지일 수 있다. 도 14는 결정된 오염도가 제3 오염 레벨인 경우, 표시되는 제3 청소 가이드 정보를 보여주는 도면이다. 프로세서는 오염도가 제3 오염 레벨로 결정된 경우, 제3 청소 가이드 정보를 디스플레이부를 통해 표시할 수 있다. 제3 청소 가이드 정보는 제3 가이드 텍스트를 포함할 수 있다. 제3 가이드 텍스트는 오염도가 제3 오염 레벨이고, Self-Clean 모드로 자동 동작함을 나타내는 텍스트를 포함할 수 있다. Self-Clean 모드는 제1 온도보다 큰 제2 온도로 일정 시간 동안, 조리실 내부를 고온으로 가열하는 청소 모 드일 수 있다. 이와 같이, 본 개시의 실시 예에 따르면, 조리실의 오염 정도가 자동으로 측정되어, 사용자에게 오염 정도 에 최적화된 조리실의 청소 가이드가 제공될 수 있다. 또한, 조리실의 상태를 파악하여, 청소/위생을 위한 가이드 및 청소 모드로 동작을 통해, 조리실의 오 염에 선제적으로 대응할 수 있는 효과가 있다. 한편, 본 개시의 또 다른 실시 예에 따르면, 오염 레벨은 사용자의 설정에 따라 달라질 수 있다. 오염 레벨이 달라짐에 따라 그에 상응하는 청소 가이드 정보 또한 달라질 수 있다. 즉, 사용자의 기호에 따라 오염 레벨이 달라질 수 있어, 개인화된 청소 가이드가 제공될 수 있다. 본 개시의 일 실시 예에 따르면, 전술한 방법은 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구 현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장 되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14"}
{"patent_id": "10-2020-0123161", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 조리 기기를 나타낸 블록도이다. 도 2는 본 개시의 일 실시 예에 따른 조리기기의 사시도이다. 도 3은 도 2의 조리기기에서 도어가 열린 상태를 보여주는 사시도이다. 도 4는 본 개시의 일 실시 예에 따른 조리 기기의 동작 방법을 설명하는 흐름도이다. 도 5 및 도 6은 본 개시의 실시 예에 따른 객체 감지 모델의 학습 과정을 설명하는 도면이다. 도 7은 본 개시의 일 실시 예에 따른 객체 식별 모델의 학습 과정을 보여준다. 도 8은 유증기를 발생하는 식품군을 나타내는 도면일 수 있다. 도 9는 본 개시의 일 실시 예에 따른 식재료에 따른 유증기 발생 정도를 나타내는 유증기 발생 추정 테이블을 도시한 도면이다. 도 10은 본 개시의 일 실시 예에 따라 유증기 감지 시점부터, 식재료의 조리 기간에 따라 유증기 발생 추정 레 벨을 결정하는 방법을 설명하는 도면이다. 도 11은 본 개시의 실시 예에 따른 유증기 발생 추정 레벨 및 식재료의 조리 횟수에 따라 조리실의 오염도를 결 정하는 과정을 설명하는 도면이다. 도 12 내지 도 14는 결정된 오염도에 따라 조리 기기의 디스플레이부를 통해 가이드 정보를 표시하는 예를 설명 하는 도면이다."}
