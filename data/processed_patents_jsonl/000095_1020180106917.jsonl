{"patent_id": "10-2018-0106917", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0029661", "출원번호": "10-2018-0106917", "발명의 명칭": "뉴럴 프로세싱 시스템", "출원인": "삼성전자주식회사", "발명자": "송진욱"}}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 특징 맵(feature map) 및 제1 가중치를 이용하여 특징 추출 연산을 수행하고 제1 연산 결과 및 제2 연산 결과를 출력하는 제1 프론트엔드 모듈;제2 특징 맵 및 제2 가중치를 이용하여 특징 추출 연산을 수행하고 제3 연산 결과 및 제4 연산 결과를 출력하는제2 프론트엔드 모듈;상기 제1 프론트엔드 모듈로부터 제공되는 제1 연산 결과와, 제2 브릿지(bridge)를 통해 상기 제2 프론트엔드모듈로부터 제공되는 제4 연산 결과를 입력받아 상기 제1 연산 결과 및 상기 제4 연산 결과를 합산 처리하는 제1 백엔드 모듈; 및상기 제2 프론트엔드 모듈로부터 제공되는 제3 연산 결과와, 제1 브릿지를 통해 상기 제1 프론트엔드 모듈로부터 제공되는 제2 연산 결과를 입력받아 상기 제3 연산 결과 및 상기 제2 연산 결과를 합산 처리하는 제2 백엔드모듈을 포함하는 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 프론트엔드 모듈 및 상기 제1 백엔드 모듈은 제1 클럭 신호에 따라 구동되고,상기 제2 프론트엔드 모듈 및 상기 제2 백엔드 모듈은 상기 제1 클럭 신호와 주파수가 다른 제2 클럭 신호에 따라 구동되는 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제1 브릿지 및 상기 제2 브릿지는 비동기식 브릿지(asynchronous bridge)인 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제1 백엔드 모듈은 상기 제1 프론트엔드 모듈에 제1 라이트백 데이터를 제공하고,상기 제2 백엔드 모듈은 상기 제2 프론트엔드 모듈에 제2 라이트백 데이터를 제공하는 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,특징 추출을 수행할 데이터 중 제1 데이터를 상기 제1 프론트엔드 모듈에 할당하고, 상기 데이터 중 제2 데이터를 상기 제2 프론트엔드 모듈에 할당하는 워크로드 관리부를 더 포함하고,상기 제1 프론트엔드 모듈은 상기 제1 특징 맵 및 상기 제1 가중치를 이용하여 상기 제1 데이터에 대한 특징 추출 연산을 수행하고,상기 제2 프론트엔드 모듈은 상기 제2 특징 맵 및 상기 제2 가중치를 이용하여 상기 제2 데이터에 대한 특징 추출 연산을 수행하는 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 제1 데이터의 양(amount)과, 상기 제2 데이터의 양은 서로 다른 뉴럴 프로세싱 시스템.공개특허 10-2020-0029661-2-청구항 7 제5항에 있어서,상기 제1 프론트엔드 모듈 및 상기 제1 백엔드 모듈에 제1 클럭 신호를 제공하고, 상기 제2 프론트엔드 모듈 및상기 제2 백엔드 모듈에 제2 클럭 신호를 제공하는 클럭 관리 유닛을 더 포함하고,상기 클럭 관리 유닛은 상기 제1 클럭 신호 및 상기 제2 클럭 신호 중 적어도 하나의 주파수를 조절하여, 상기워크로드 관리부의 할당 동작에 따라, 상기 제1 프론트엔드 모듈, 상기 제1 백엔드 모듈, 상기 제2 프론트엔드모듈 및 상기 제2 백엔드 모듈 중 적어도 하나에 대한 클럭 게이팅을 수행하는 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 제1 프론트엔드 모듈 및 상기 제1 백엔드 모듈에 제1 파워 게이팅 신호를 제공하고, 상기 제2 프론트엔드모듈 및 상기 제2 백엔드 모듈에 제2 파워 게이팅 신호를 제공하는 전력 관리 유닛을 더 포함하고,상기 전력 관리 유닛은 상기 제1 파워 게이팅 신호 및 상기 제2 파워 게이팅 신호 중 적어도 하나의 값을 제어하여, 상기 워크로드 관리부의 할당 동작에 따라, 상기 제1 프론트엔드 모듈, 상기 제1 백엔드 모듈, 상기 제2프론트엔드 모듈 및 상기 제2 백엔드 모듈 중 적어도 하나에 대한 파워 게이팅을 수행하는 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 프론트엔드 모듈 및 제1 백엔드 모듈을 포함하는 제1 뉴럴 프로세싱 유닛; 및상기 제1 뉴럴 프로세싱 유닛 및, 상기 제1 뉴럴 프로세싱 유닛과 다른 클럭 도메인에서 동작하는 제2 뉴럴 프로세싱 유닛에 전기적으로 접속된 브릿지 유닛을 포함하고,상기 제1 프론트엔드 모듈은, 제1 특징 맵(feature map) 및 제1 가중치를 이용하여 특징 추출 연산을 수행한 제1 연산 결과 중 일부를 상기 제1 백엔드 모듈에 제공하고,상기 브릿지 유닛은, 상기 제2 뉴럴 프로세싱 유닛에서 수행된 제2 연산 결과 중 일부를 상기 제1 백엔드 모듈에 제공하고,상기 제1 백엔드 모듈은, 상기 제1 연산 결과 중 일부와 상기 제2 연산 결과 중 일부를 합산 처리하는 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 브릿지 유닛은, 상기 제1 뉴럴 프로세싱 유닛과 다른 클럭 도메인에서 동작하는 제3 뉴럴 프로세싱 유닛에전기적으로 접속되고,상기 제1 프론트엔드 모듈은 상기 제1 연산 결과 중 다른 일부를 상기 브릿지 유닛에 제공하고,상기 브릿지 유닛은, 상기 제1 연산 결과 중 일부를 상기 제3 뉴럴 프로세싱 유닛에 제공하는 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 브릿지 유닛은 하나 이상의 비동기식 브릿지(asynchronous bridge)를 포함하는 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 제1 백엔드 모듈은 상기 제1 프론트엔드 모듈에 제1 라이트백 데이터를 제공하는 뉴럴 프로세싱 시스템.공개특허 10-2020-0029661-3-청구항 13 제1 프론트엔드 모듈 및 제1 백엔드 모듈을 포함하는 제1 뉴럴 프로세싱 유닛;제2 프론트엔드 모듈 및 제2 백엔드 모듈을 포함하는 제2 뉴럴 프로세싱 유닛; 및특징 추출을 수행할 데이터 중 제1 데이터를 제1 뉴럴 프로세싱 유닛에 할당하고, 상기 데이터 중 제2 데이터를상기 제2 뉴럴 프로세싱 유닛에 할당하는 워크로드 관리부를 포함하고,상기 제1 프론트엔드 모듈은, 제1 특징 맵(feature map) 및 제1 가중치를 이용하여 상기 제1 데이터에 대한 특징 추출 연산을 수행하고 제1 연산 결과 및 제2 연산 결과를 출력하고,상기 제2 프론트엔드 모듈은, 제2 특징 맵 및 제2 가중치를 이용하여 상기 제2 데이터에 대한 특징 추출 연산을수행하고 제3 연산 결과 및 제4 연산 결과를 출력하고,상기 제1 백엔드 모듈은, 상기 제1 연산 결과 및 상기 제4 연산 결과를 합산 처리하고, 상기 제2 백엔드 모듈은상기 제3 연산 결과 및 상기 제2 연산 결과를 합산 처리하는 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 제1 데이터의 양(amount)과, 상기 제2 데이터의 양은 서로 다른 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 제1 프론트엔드 모듈 및 상기 제1 백엔드 모듈에 제1 클럭 신호를 제공하고, 상기 제2 프론트엔드 모듈 및상기 제2 백엔드 모듈에 제2 클럭 신호를 제공하는 클럭 관리 유닛을 더 포함하고,상기 클럭 관리 유닛은 상기 제1 클럭 신호 및 상기 제2 클럭 신호 중 적어도 하나의 주파수를 조절하여, 상기워크로드 관리부의 할당 동작에 따라, 상기 제1 프론트엔드 모듈, 상기 제1 백엔드 모듈, 상기 제2 프론트엔드모듈 및 상기 제2 백엔드 모듈 중 적어도 하나에 대한 클럭 게이팅을 수행하는 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서,상기 제1 프론트엔드 모듈 및 상기 제1 백엔드 모듈에 제1 파워 게이팅 신호를 제공하고, 상기 제2 프론트엔드모듈 및 상기 제2 백엔드 모듈에 제2 파워 게이팅 신호를 제공하는 전력 관리 유닛을 더 포함하고,상기 전력 관리 유닛은 상기 제1 파워 게이팅 신호 및 상기 제2 파워 게이팅 신호 중 적어도 하나의 값을 제어하여, 상기 워크로드 관리부의 할당 동작에 따라, 상기 제1 프론트엔드 모듈, 상기 제1 백엔드 모듈, 상기 제2프론트엔드 모듈 및 상기 제2 백엔드 모듈 중 적어도 하나에 대한 파워 게이팅을 수행하는 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 제1 뉴럴 프로세싱 유닛은 제1 클럭 신호에 따라 구동되고,상기 제2 뉴럴 프로세싱 유닛은 상기 제1 클럭 신호와 주파수가 다른 제2 클럭 신호에 따라 구동되는 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서,상기 제1 백엔드 모듈은 제2 브릿지를 통해 상기 제2 프론트엔드 모듈로부터 상기 제4 연산 결과를 제공받고,상기 제2 백엔드 모듈은 제1 브릿지를 통해 상기 제1 프론트엔드 모듈로부터 상기 제2 연산 결과를 제공받는 뉴공개특허 10-2020-0029661-4-럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 제1 브릿지 및 상기 제2 브릿지는 비동기식 브릿지(asynchronous bridge)인 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제13항에 있어서,상기 제1 백엔드 모듈은 상기 제1 프론트엔드 모듈에 제1 라이트백 데이터를 제공하고,상기 제2 백엔드 모듈은 상기 제2 프론트엔드 모듈에 제2 라이트백 데이터를 제공하는 뉴럴 프로세싱 시스템."}
{"patent_id": "10-2018-0106917", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "뉴럴 프로세싱 시스템(neural processing system)이 제공된다. 뉴럴 프로세싱 시스템은, 제1 특징 맵(feature map) 및 제1 가중치를 이용하여 특징 추출 연산을 수행하고 제1 연산 결과 및 제2 연산 결과를 출력하는 제1 프 론트엔드 모듈; 제2 특징 맵 및 제2 가중치를 이용하여 특징 추출 연산을 수행하고 제3 연산 결과 및 제4 연산 결과를 출력하는 제2 프론트엔드 모듈; 상기 제1 프론트엔드 모듈로부터 제공되는 제1 연산 결과와, 제2 브릿지 (bridge)를 통해 상기 제2 프론트엔드 모듈로부터 제공되는 제4 연산 결과를 입력받아 상기 제1 연산 결과 및 상 기 제4 연산 결과를 합산 처리하는 제1 백엔드 모듈; 및 상기 제2 프론트엔드 모듈로부터 제공되는 제3 연산 결 과와, 제1 브릿지를 통해 상기 제1 프론트엔드 모듈로부터 제공되는 제2 연산 결과를 입력받아 상기 제3 연산 결 과 및 상기 제2 연산 결과를 합산 처리하는 제2 백엔드 모듈을 포함한다."}
{"patent_id": "10-2018-0106917", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 뉴럴 프로세싱 시스템에 관한 것이다."}
{"patent_id": "10-2018-0106917", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥 러닝(deep learning)은 다중 처리 계층을 갖는 심화 그래프(deep graph)를 이용하여 입력 데이터에서 높은 레벨의 추상화를 모델링하려는 알고리즘 집합에 기초한 연산 아키텍처를 말한다. 일반적으로 딥 러닝 아키텍처 에는 다수의 뉴런 계층과 파라미터들을 포함할 수 있다. 딥 러닝 아키텍처 중 CNN(Convolutional Neural Network)은 이미지 분류, 이미지 캡션 생성, 시각적 질문 응답 및 자동 운전 차량과 같은, 많은 인공 지능 및 머신 러닝 어플리케이션에서 널리 사용되고 있다. CNN 시스템은 예컨대 이미지의 분류를 위해 수많은 파라미터를 포함하고 수많은 연산을 필요로 하기 때문에 높 은 복잡도를 가진다. 이에 따라 CNN 시스템을 구현하기 위해서는 하드웨어 리소스에 대한 비용이 문제가 되고, 하드웨어 리소스가 소모하는 전력의 양 역시 문제가 된다. 특히 최근 모바일 시스템에 구현되는 CNN의 경우 비 용 및 전력 소모가 낮으면서도 인공 지능을 구현할 수 있는 아키텍처가 요구된다."}
{"patent_id": "10-2018-0106917", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 기술적 과제는, 비용 및 전력 소모가 낮으면서도 인공 지능을 구현할 수 있는 뉴럴 네트워크 시스템을 제공하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재로부터 해당 기술 분야의 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2018-0106917", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 달성하기 위한 본 발명의 일 실시예에 따른 뉴럴 프로세싱 시스템은, 제1 특징 맵(feature map) 및 제1 가중치를 이용하여 특징 추출 연산을 수행하고 제1 연산 결과 및 제2 연산 결과를 출력하는 제1 프 론트엔드 모듈; 제2 특징 맵 및 제2 가중치를 이용하여 특징 추출 연산을 수행하고 제3 연산 결과 및 제4 연산 결과를 출력하는 제2 프론트엔드 모듈; 제1 프론트엔드 모듈로부터 제공되는 제1 연산 결과와, 제2 브릿지 (bridge)를 통해 제2 프론트엔드 모듈로부터 제공되는 제4 연산 결과를 입력받아 제1 연산 결과 및 제4 연산 결 과를 합산 처리하는 제1 백엔드 모듈; 및 제2 프론트엔드 모듈로부터 제공되는 제3 연산 결과와, 제1 브릿지를 통해 제1 프론트엔드 모듈로부터 제공되는 제2 연산 결과를 입력받아 제3 연산 결과 및 제2 연산 결과를 합산 처리하는 제2 백엔드 모듈을 포함한다. 상기 기술적 과제를 달성하기 위한 본 발명의 다른 실시예에 따른 뉴럴 프로세싱 시스템은, 제1 프론트엔드 모 듈 및 제1 백엔드 모듈을 포함하는 제1 뉴럴 프로세싱 유닛; 및 제1 뉴럴 프로세싱 유닛 및, 제1 뉴럴 프로세싱 유닛과 다른 클럭 도메인에서 동작하는 제2 뉴럴 프로세싱 유닛에 전기적으로 접속된 브릿지 유닛을 포함하고, 제1 프론트엔드 모듈은, 제1 특징 맵 및 제1 가중치를 이용하여 특징 추출 연산을 수행한 제1 연산 결과 중 일부를 제1 백엔드 모듈에 제공하고, 브릿지 유닛은, 제2 뉴럴 프로세싱 유닛에서 수행된 제2 연산 결과 중 일부 를 제1 백엔드 모듈에 제공하고, 제1 백엔드 모듈은, 제1 연산 결과 중 일부와 제2 연산 결과 중 일부를 합산 처리한다. 상기 기술적 과제를 달성하기 위한 본 발명의 또 다른 실시예에 따른 뉴럴 프로세싱 시스템은, 제1 프론트엔드 모듈 및 제1 백엔드 모듈을 포함하는 제1 뉴럴 프로세싱 유닛; 제2 프론트엔드 모듈 및 제2 백엔드 모듈을 포함 하는 제2 뉴럴 프로세싱 유닛; 및 특징 추출을 수행할 데이터 중 제1 데이터를 제1 뉴럴 프로세싱 유닛에 할당 하고, 데이터 중 제2 데이터를 제2 뉴럴 프로세싱 유닛에 할당하는 워크로드 관리부를 포함하고, 제1 프론트엔 드 모듈은, 제1 특징 맵 및 제1 가중치를 이용하여 제1 데이터에 대한 특징 추출 연산을 수행하고 제1 연산 결 과 및 제2 연산 결과를 출력하고, 제2 프론트엔드 모듈은, 제2 특징 맵 및 제2 가중치를 이용하여 제2 데이터에 대한 특징 추출 연산을 수행하고 제3 연산 결과 및 제4 연산 결과를 출력하고, 제1 백엔드 모듈은, 제1 연산 결 과 및 제4 연산 결과를 합산 처리하고, 제2 백엔드 모듈은 제3 연산 결과 및 제2 연산 결과를 합산 처리한다. 기타 실시예들의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2018-0106917", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 컴퓨팅 시스템을 설명하기 위한 개략도이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 컴퓨팅 시스템은 뉴럴 프로세싱 시스템(neural processing system), 클럭 관리 유닛(clock management unit, CMU), 프로세서 및 메모리를 포함한다. 뉴 럴 프로세싱 시스템, 프로세서 및 메모리는 버스를 통해 데이터를 주고 받을 수 있다. 뉴럴 프로세싱 시스템은 CNN(Convolutional Neural Network)을 구현하거나 실행할 수 있는 뉴럴 네트워크 프로세서이다. 그러나 본 발명이 이에 제한되는 것은 아니다. 즉, 뉴럴 프로세싱 시스템은 임의의 벡터 연 산, 매트릭스 연산 등을 처리하는 프로세서로 대체 구현될 수 있다. 본 실시예에서, 뉴럴 프로세싱 시스템은 특징 추출 레이어(feature extraction layer), 특징 분류 레이어 (feature classification layer) 등과 같은 복수의 레이어(layer)를 포함하는 뉴럴 네트워크를 처리할 수 있다. 여기서 특징 추출 레이어는 뉴럴 네트워크의 초기 레이어에 해당하며, 예컨대 입력 이미지로부터 모서리, 변화도(gradient)와 같은 저 레벨의 특징들을 추출하기 위해 사용될 수 있다. 한편 특징 분류 레이어는 뉴럴 네 트워크의 차후 레이어에 해당하며, 예컨대 입력 이미지로부터 얼굴, 눈, 코와 같은 더 복잡하고 높은 레벨의 특징을 추출할 수 있다. 특징 분류 레이어는 완전 연결 레이어(fully-connected layers)에 해당한다. 뉴럴 프로세싱 시스템은, 입력 이미지로부터 특징을 추출하기 위해, 입력 이미지 또는 특징 맵(feature map)을 필터(filter) 또는 커널(kernel)을 이용하여 연산을 수행할 수 있다. 예를 들어, 뉴럴 프로세싱 시스템 은 입력 이미지 또는 특징 맵을 컨볼루션 필터(convolution filter) 또는 컨볼루션 커널(convolution kernel)을 이용하여 컨볼브(convolve) 연산을 수행할 수 있다. 또한, 뉴럴 프로세싱 시스템은 구체적인 구 현 목적에 따라 정해지는, 특징 맵에 대응할 수 있는 가중치(weight)를 상기 연산에 이용할 수 있다. 본 실시예에서, 특히 주목할 점은, 뉴럴 프로세싱 시스템은 복수의 뉴럴 프로세싱 유닛(neural processing unit)(100a, 100b)을 포함한다는 점이다. 설명의 편의를 위해, 본 실시예에서 뉴럴 프로세싱 시스템은 2 개 의 뉴럴 프로세싱 유닛(100a, 100b)을 포함하는 것으로 도시하였으나, 본 발명의 범위가 이에 제한되는 것은 아 니다. 구체적인 구현 목적에 따라 뉴럴 프로세싱 시스템은 n 개(여기서 n은 2 이상의 자연수)의 뉴럴 프로 세싱 유닛을 포함할 수 있다. 클럭 관리 유닛은 뉴럴 프로세싱 시스템을 구동하기 위한 제1 클럭 신호(CLK1) 및 제2 클럭 신호(CLK 2)를 생성하여, 제1 뉴럴 프로세싱 유닛(100a) 및 제2 뉴럴 프로세싱 유닛(100b)에 각각 제공한다. 이에 따라 제1 뉴럴 프로세싱 유닛(100a)은 제1 클럭 신호(CLK1)에 따라 구동되고, 제2 뉴럴 프로세싱 유닛(100b)은 제2 클럭 신호(CLK2)에 따라 구동된다. 본 발명의 몇몇의 실시예에서, 제1 클럭 신호(CLK1)와 제2 클럭 신호(CLK2)의 주파수는 서로 다를 수 있다. 다 시 말해서, 제1 뉴럴 프로세싱 유닛(100a)이 동작하는 클럭 도메인과, 제2 뉴럴 프로세싱 유닛(100b)이 동작하 는 클럭 도메인은 서로 다를 수 있다. 클럭 관리 유닛은 필요에 따라 제1 클럭 신호(CLK1) 및 제2 클럭 신호(CLK2)의 주파수를 각각 제어할 수 있 다. 또한, 클럭 관리 유닛은 필요에 따라 제1 클럭 신호(CLK1) 및 제2 클럭 신호(CLK2)에 대한 클럭 게이팅 (clock gating)을 수행할 수도 있다. 프로세서는, 뉴럴 프로세싱 시스템이 처리하는 인공지능 연산, 벡터 연산, 매트릭스 연산 등과 구별되 는 일반적인 산술 연산을 수행하는 프로세서이다. 프로세서는 예를 들어 CPU(Central Processing Unit), GPU(Graphic Processing Unit) 등을 포함할 수 있으나, 본 발명의 범위가 이에 제한되는 것은 아니다. 본 실시 예에서, 프로세서는 컴퓨팅 시스템을 전반적으로 제어할 수 있다. 메모리는, 프로세서가 어플리케이션을 실행하거나, 컴퓨텅 시스템을 제어하는 동안 사용되는 데이터 가 저장될 수 있다. 메모리는 예를 들어 DRAM(Dynamic Random Access Memory)일 수 있으나, 본 발명의 범 위가 이에 제한되는 것은 아니다. 본 실시예에서, 메모리에는, 예컨대 뉴럴 프로세싱 시스템이 CNN을 이용하여 처리할 이미지 데이터가 저장될 수 있다. 도 2는 본 발명의 일 실시예에 따른 뉴럴 프로세싱 시스템을 설명하기 위한 블록도이다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 뉴럴 프로세싱 시스템은 제1 뉴럴 프로세싱 유닛(100a) 및 제2 뉴럴 프로세싱 유닛(100b)을 포함한다. 제1 뉴럴 프로세싱 유닛(100a) 및 제2 뉴럴 프로세싱 유닛(100b) 사 이에는 브릿지 유닛(bridge unit)이 배치된다. 먼저, 브릿지 유닛은 제1 뉴럴 프로세싱 유닛(100a)의 연산으로 생성된 중간 결과를 제2 뉴럴 프로세싱 유 닛(100b)으로 전달하기 위한 제1 브릿지 및, 제2 뉴럴 프로세싱 유닛(100b)의 연산으로 생성된 중간 결과 를 제1 뉴럴 프로세싱 유닛(100a)으로 전달하기 위한 제2 브릿지를 포함한다. 이를 위해, 제1 뉴럴 프로세싱 유닛(100a)과 제2 뉴럴 프로세싱 유닛(100b)이 서로 다른 클럭 도메인에서 동작 하는 경우, 브릿지 유닛은 제1 뉴럴 프로세싱 유닛(100a) 및, 제1 뉴럴 프로세싱 유닛(100a)과 다른 클럭 도메인에서 동작하는 제2 뉴럴 프로세싱 유닛(100b)에 전기적으로 접속된다. 이에 따라, 제1 뉴럴 프로세싱 유닛(100a)과 제2 뉴럴 프로세싱 유닛(100b)이 서로 다른 클럭 도메인에서 동작 하는 경우, 브릿지 유닛에 포함된 브릿지(111, 112)는 비동기식 브릿지(asynchronous bridge)로 구현되어, 서로 다른 클럭 도메인 사이에서 데이터 전달을 가능하도록 한다. 본 실시예에서, 제1 뉴럴 프로세싱 유닛(100a)은 제1 프론트엔드 모듈(102a) 및 제1 백엔드 모듈(104a)을 포함 하고, 제2 뉴럴 프로세싱 유닛(100b)은 제2 프론트엔드 모듈(102b) 및 제2 백엔드 모듈(104b)을 포함한다. 제1 뉴럴 프로세싱 유닛(100a)은, 뉴럴 프로세싱 시스템이 처리할 데이터 중 제1 데이터(DATA1)를 처리할 수 있고, 제2 뉴럴 프로세싱 유닛(100b)은, 뉴럴 프로세싱 시스템이 처리할 데이터 중 제1 데이터(DATA1)를 처리 할 수 있다. 구체적으로, 제1 프론트엔드 모듈(102a)은 제1 특징 맵 및 제1 가중치를 이용하여 제1 데이터(DATA1)에 대해 특 징 추출 연산을 수행하고, 제1 연산 결과(R11) 및 제2 연산 결과(R12)를 출력한다. 그리고 제2 프론트엔드 모듈 (102b)은 제2 특징 맵 및 제2 가중치를 이용하여 제2 데이터(DATA2)에 대해 특징 추출 연산을 수행하고, 제3 연 산 결과(R21) 및 제4 연산 결과(R22)를 출력한다. 제1 백엔드 모듈(104a)은 제1 프론트엔드 모듈(102a)로부터 제공되는 제1 연산 결과(R11)와, 제2 브릿지를 통해 제2 프론트엔드 모듈(102b)로부터 제공되는 제4 연산 결과(R22)를 입력받아, 제1 연산 결과(R11) 및 제4 연산 결과(R22)를 합산 처리한다. 한편, 제2 백엔드 모듈(104b)은 제2 프론트엔드 모듈(102b)로부터 제공되는 제3 연산 결과(R21)와, 제1 브릿지를 통해 제1 프론트엔드 모듈(102a)로부터 제공되는 제2 연산 결과(R1 2)를 입력받아 제3 연산 결과(R21) 및 제2 연산 결과(R12)를 합산 처리한다. 본 발명의 몇몇의 실시예에서, 제1 프론트엔드 모듈(102a) 및 제1 백엔드 모듈(104a)은 제1 클럭 신호(CLK1)에 따라 구동되고, 제2 프론트엔드 모듈(102b) 및 제2 백엔드 모듈(104b)은 제1 클럭 신호(CLK1)와 주파수가 다른 제2 클럭 신호(CLK2)에 따라 구동될 수 있다. 즉, 제1 프론트엔드 모듈(102a) 및 제1 백엔드 모듈(104a)은 제2 프론트엔드 모듈(102b) 및 제2 백엔드 모듈(104b)과 다른 클럭 도메인에서 동작할 수 있다. 한편, 본 실시예에서, 제1 백엔드 모듈(104a)은 제1 프론트엔드 모듈(102a)에 제1 라이트백 데이터(WB DATA1)를 제공하고, 제2 백엔드 모듈(104b)은 제2 프론트엔드 모듈(102b)에 제2 라이트백 데이터(WB DATA2)를 제공할 수 있다. 제1 라이트백 데이터(WB DATA1) 및 제2 라이트백 데이터(WB DATA2)는 각각 제1 프론트엔드 모듈(102a) 및 제2 프론트엔드 모듈(102b)에 대한 입력이 되어, 특징 추출 연산을 반복할 수 있도록 한다. 이제 도 3을 참조하여, 본 발명의 일 실시예에 따른 뉴럴 프로세싱 시스템의 더욱 상세한 구조를 설명하도 록 한다. 도 3은 본 발명의 일 실시예에 따른 뉴럴 프로세싱 시스템을 설명하기 위한 블록도이다. 도 3을 참조하면, 본 발명의 일 실시예에 따른 뉴럴 프로세싱 시스템의 제1 뉴럴 프로세싱 유닛(100a)에 포 함된 제1 프론트엔드 모듈(102a)은, 복수의 제1 내부 메모리(1021a, 1022a), 복수의 제1 페치(fetch) 유닛 (1023a, 1024a), 복수의 제1 디스패치(dispatch) 유닛(1025a, 1026a) 및 제1 MAC 어레이(multiplication and accumulation array)(1027a)를 포함한다. 복수의 제1 내부 메모리(1021a, 1022a)는 제1 프론트엔드 모듈(102a)이 데이터(DATA11, DATA12)에 대한 특징 추출 연산을 위해 이용하는 제1 특징 맵 및 제1 가중치를 저장할 수 있다. 본 실시예에서, 복수의 제1 내부 메 모리(1021a, 1022a)는 SRAM(Static Random Access Memory)으로 구현될 수 있으나, 본 발명의 범위가 이에 제한 되는 것은 아니다. 복수의 제1 페치 유닛(1023a, 1024a)은 제1 특징 맵 및 제1 가중치를 복수의 제1 내부 메모리(1021a, 1022a) 각각으로부터 페치하여, 복수의 제1 디스패치 유닛(1025a, 1026a)에 전달한다. 복수의 제1 디스패치 유닛(1025a, 1026a)은, 페치된 제1 특징 맵 및 제1 가중치를 채널 별로 제1 MAC 어레이 (1027a)에 전달한다. 예를 들어, 복수의 제1 디스패치 유닛(1025a, 1026a)은, 예컨대 k 개의(여기서 k는 자연수) 채널 별로 가중치와 이에 대응하는 특징 맵을 선정하여 제1 MAC 어레이(1027a)에 전달할 수 있다. 제1 MAC 어레이(1027a)는 복수의 제1 디스패치 유닛(1025a, 1026a)으로부터 전달받은 데이터에 대해 곱셈 누적 연산을 수행한다. 예를 들어, 제1 MAC 어레이(1027a)는 k 개의 채널 별 데이터에 대해 각각 곱셈 누적 연산을 수행한다. 그리고 제1 MAC 어레이(1027a)는 제1 연산 결과(R11) 및 제2 연산 결과(R12)를 출력한다. 그러면, 앞서 설명한 바와 같이, 제1 연산 결과(R11)는 제1 백엔드 모듈(104a)에 제공되고, 제2 연산 결과(R1 2)는 제1 브릿지를 통해 제2 뉴럴 프로세싱 유닛(100b)의 제2 백엔드 모듈(104b)에 제공될 수 있다. 한편, 본 발명의 일 실시예에 따른 뉴럴 프로세싱 시스템의 제1 뉴럴 프로세싱 유닛(100a)에 포함된 제1 백 엔드 모듈(104a)은, 제1 합산 유닛(1041a), 제1 활성 유닛(1043a) 및 제1 라이트백 유닛(1045a)을 포함한다. 제1 합산 유닛(1041a)은 제1 연산 결과(R11) 및 제4 연산 결과(R22)에 대한 합산 연산을 수행한다. 여기서 제4 연산 결과(R22)는 제2 브릿지를 통해 제2 뉴럴 프로세싱 유닛(100b)의 제2 프론트엔드 모듈(102b)로부터 제공될 수 있다.제1 활성 유닛(1043a)은 합산 연산의 수행 결과에 대해 활성 연산(activation)을 수행할 수 있다. 본 발명의 몇 몇의 실시예에서, 활성 연산은 ReLU, Sigmoid, tanh 등의 활성 함수를 이용한 연산을 포함할 수 있으나, 본 발 명의 범위가 이에 제한되는 것은 아니다. 제1 라이트백 유닛(1045a)은 활성 연산의 수행 결과를 제1 프론트엔드 모듈(102a)에 제공하는 라이트백 연산을 수행한다. 구체적으로, 제1 라이트백 유닛(1045a)은 활성 연산의 수행 결과를 복수의 제1 내부 메모리(1021a, 1022a)에 저장할 수 있다. 한편, 본 발명의 일 실시예에 따른 뉴럴 프로세싱 시스템의 제2 뉴럴 프로세싱 유닛(100b)에 포함된 제2 프 론트엔드 모듈(102b)은, 복수의 제1 내부 메모리(1021b, 1022b), 복수의 제2 페치 유닛(1023b, 1024b), 복수의 제2 디스패치 유닛(1025b, 1026b) 및 제2 MAC 어레이(1027b)를 포함한다. 복수의 제2 내부 메모리(1021b, 1022b)는 제2 프론트엔드 모듈(102b)이 데이터(DATA21, DATA22)에 대한 특징 추출 연산을 위해 이용하는 제2 특징 맵 및 제2 가중치를 저장할 수 있다. 본 실시예에서, 복수의 제2 내부 메 모리(1021b, 1022b)는 SRAM으로 구현될 수 있으나, 본 발명의 범위가 이에 제한되는 것은 아니다. 복수의 제2 페치 유닛(1023b, 1024b)은 제2 특징 맵 및 제2 가중치를 복수의 제2 내부 메모리(1021b, 1022b) 각각으로부터 페치하여, 복수의 제2 디스패치 유닛(1025b, 1026b)에 전달한다. 복수의 제2 디스패치 유닛(1025b, 1026b)은, 페치된 제2 특징 맵 및 제2 가중치를 채널 별로 제2 MAC 어레이 (1027b)에 전달한다. 예를 들어, 복수의 제2 디스패치 유닛(1025b, 1026b)은, 예컨대 k 개의(여기서 k는 자연수) 채널 별로 가중치와 이에 대응하는 특징 맵을 선정하여 제2 MAC 어레이(1027b)에 전달할 수 있다. 제2 MAC 어레이(1027b)는 복수의 제2 디스패치 유닛(1025b, 1026b)으로부터 전달받은 데이터에 대해 곱셈 누적 연산을 수행한다. 예를 들어, 제2 MAC 어레이(1027b)는 k 개의 채널 별 데이터에 대해 각각 곱셈 누적 연산을 수행한다. 그리고 제2 MAC 어레이(1027b)는 제3 연산 결과(R21) 및 제4 연산 결과(R22)를 출력한다. 그러면, 앞서 설명한 바와 같이, 제3 연산 결과(R21)는 제2 백엔드 모듈(104b)에 제공되고, 제4 연산 결과(R2 1)는 제2 브릿지를 통해 제1 뉴럴 프로세싱 유닛(100a)의 제1 백엔드 모듈(104a)에 제공될 수 있다. 한편, 본 발명의 일 실시예에 따른 뉴럴 프로세싱 시스템의 제2 뉴럴 프로세싱 유닛(100b)에 포함된 제2 백 엔드 모듈(104b)은, 제2 합산 유닛(1041b), 제2 활성 유닛(1043b) 및 제2 라이트백 유닛(1045b)을 포함한다. 제2 합산 유닛(1041b)은 제3 연산 결과(R21) 및 제2 연산 결과(R12)에 대한 합산 연산을 수행한다. 여기서 제2 연산 결과(R12)는 제1 브릿지를 통해 제1 뉴럴 프로세싱 유닛(100a)의 제1 프론트엔드 모듈(102a)로부터 제공될 수 있다. 제2 활성 유닛(1043b)은 합산 연산의 수행 결과에 대해 활성 연산을 수행할 수 있다. 본 발명의 몇몇의 실시예 에서, 활성 연산은 ReLU, Sigmoid, tanh 등의 활성 함수를 이용한 연산을 포함할 수 있으나, 본 발명의 범위가 이에 제한되는 것은 아니다. 제2 라이트백 유닛(1045b)은 활성 연산의 수행 결과를 제2 프론트엔드 모듈(102b)에 제공하는 라이트백 연산을 수행한다. 구체적으로, 제2 라이트백 유닛(1045b)은 활성 연산의 수행 결과를 복수의 제2 내부 메모리(1021b, 1022b)에 저장할 수 있다. 도 4 및 도 5는 본 발명의 일 실시예에 따른 뉴럴 프로세싱 시스템의 프론트엔드 모듈을 설명하기 위한 블록도 이다. 도 4를 참조하면, 복수의 제1 내부 메모리(1021a, 1022a)는 각각 데이터(DATA11) 및 데이터(DATA12)에 대한 특 징 추출 연산을 위해 이용하는 제1 특징 맵 및 제1 가중치를 저장하고, 제1 페치 유닛(1023a, 1024a)은 제1 특 징 맵 및 제1 가중치를 복수의 제1 내부 메모리(1021a, 1022a) 각각으로부터 페치하여, 복수의 제1 디스패치 유 닛(1025a, 1026a)에 전달한다. 제1 디스패치 유닛(1025a)은 데이터(DATA11)의 6 개의 채널 별로 가중치와 이에 대응하는 특징 맵을 선정하여 제1 MAC 어레이(1027a)에 전달하고, 제1 디스패치 유닛(1026a)은 데이터(DATA12)의 6 개의 채널 별로 가중치와 이에 대응하는 특징 맵을 선정하여 제1 MAC 어레이(1027a)에 전달한다. 제1 MAC 어레이(1027a)는 6 개의 채널 각각에 대해, 복수의 제1 디스패치 유닛(1025a, 1026a)으로부터 전달받은 데이터에 대해 곱셈 누적 연산을 수행한다.본 실시예에서, 제1 MAC 어레이(1027a)로부터 출력되는 연산 결과 중 제1 연산 결과(R11)는 1 번째, 3 번째 및 6 번째 채널에 대한 곱셈 누적 연산 결과에 해당하고, 제2 연산 결과(R12)는 2 번째, 4 번째 및 5 번째 채널에 대한 곱셈 누적 연산 결과에 해당한다. 제1 연산 결과(R11)는 제1 백엔드 모듈(104a)의 제1 합산 유닛(1041a)에 제공되고, 제2 연산 결과(R12)는, 다른 클럭 도메인에서 동작하는 제2 뉴럴 프로세싱 유닛(100b)에 전송하기 위해 제1 브릿지에 제공된다. 한편, 제1 백엔드 모듈(104a)의 제1 합산 유닛(1041a)은, 제2 브릿지를 통해 다른 클럭 도메인에서 동작하는 제2 뉴럴 프로세싱 유닛(100b)의 연산 결과, 예컨대 제4 연산 결과(R22)를 제공받는다. 이어서 도 5를 참조하면, 복수의 제2 내부 메모리(1021b, 1022b)는 각각 데이터(DATA21) 및 데이터(DATA22)에 대한 특징 추출 연산을 위해 이용하는 제2 특징 맵 및 제2 가중치를 저장하고, 제2 페치 유닛(1023b, 1024b)은 제2 특징 맵 및 제2 가중치를 복수의 제2 내부 메모리(1021b, 1022b) 각각으로부터 페치하여, 복수의 제2 디스 패치 유닛(1025b, 1026b)에 전달한다. 제2 디스패치 유닛(1025b)은 데이터(DATA21)의 6 개의 채널 별로 가중치와 이에 대응하는 특징 맵을 선정하여 제2 MAC 어레이(1027b)에 전달하고, 제2 디스패치 유닛(1026b)은 데이터(DATA22)의 6 개의 채널 별로 가중치와 이에 대응하는 특징 맵을 선정하여 제2 MAC 어레이(1027b)에 전달한다. 제2 MAC 어레이(1027b)는 6 개의 채널 각각에 대해, 복수의 제2 디스패치 유닛(1025b, 1026b)으로부터 전달받은 데이터에 대해 곱셈 누적 연산을 수행한다. 본 실시예에서, 제2 MAC 어레이(1027b)로부터 출력되는 연산 결과 중 제3 연산 결과(R21)는 2 번째, 4 번째 및 5 번째 채널에 대한 곱셈 누적 연산 결과에 해당하고, 제4 연산 결과(R22)는 1 번째, 3 번째 및 6 번째 채널에 대한 곱셈 누적 연산 결과에 해당한다. 제3 연산 결과(R21)는 제2 백엔드 모듈(104b)의 제2 합산 유닛(1041b)에 제공되고, 제4 연산 결과(R22)는, 다른 클럭 도메인에서 동작하는 제1 뉴럴 프로세싱 유닛(100a)에 전송하기 위해 제2 브릿지에 제공된다. 한편, 제2 백엔드 모듈(104b)의 제2 합산 유닛(1041b)은, 제1 브릿지를 통해 다른 클럭 도메인에서 동작하는 제1 뉴럴 프로세싱 유닛(100a)의 연산 결과, 예컨대 제2 연산 결과(R12)를 제공받는다. 도 6은 본 발명의 일 실시예에 따른 뉴럴 프로세싱 시스템의 백엔드 모듈을 설명하기 위한 블록도이다. 도 6을 참조하면, 제1 합산 유닛(1041a)은 채널 별로 제1 연산 결과(R11) 및 제4 연산 결과(R22)에 대한 합산 연산을 수행한다. 앞서 도 4 및 도 5에서 총 제1 연산 결과(R11)는 6 개의 채널 중 3 개의 채널에 대한 값을 포 함하고, 제4 연산 결과(R22) 역시 3 개의 채널에 대한 값을 포함하므로, 이들 각각에 대한 합산을 3 가지의 채 널에 대해 수행한다. 이어서 제1 활성 유닛(1043a)은 합산 연산의 수행 결과에 대해 채널 별로 활성 연산을 수행하고, 제1 라이트백 유닛(1045a)은 활성 연산의 수행 결과를 제1 프론트엔드 모듈(102a)에 제공하는 라이트백 연산을 채널 별로 수 행한다. 예를 들어, 제1 라이트백 유닛(1045a)은 활성 연산의 수행 결과 중 1 번째 채널에 대응하는 데이터를 제1 내부 메모리(1021a)에 라이트백하고, 2 번째 및 3 번째 채널에 대응하는 데이터를 제1 내부 메모리(1022a) 에 라이트백할 수 있다. 한편, 제2 합산 유닛(1041b) 역시 채널 별로 제3 연산 결과(R21) 및 제2 연산 결과(R12)에 대한 합산 연산을 수 행한다. 앞서 도 4 및 도 5에서 총 제3 연산 결과(R21)는 6 개의 채널 중 3 개의 채널에 대한 값을 포함하고, 제2 연산 결과(R12) 역시 3 개의 채널에 대한 값을 포함하므로, 이들 각각에 대한 합산을 3 가지의 채널에 대해 수행한다. 이어서 제2 활성 유닛(1043b)은 합산 연산의 수행 결과에 대해 채널 별로 활성 연산을 수행하고, 제2 라이트백 유닛(1045b)은 활성 연산의 수행 결과를 제2 프론트엔드 모듈(102b)에 제공하는 라이트백 연산을 채널 별로 수 행한다. 예를 들어, 제2 라이트백 유닛(1045b)은 활성 연산의 수행 결과 중 1 번째 채널에 대응하는 데이터를 제2 내부 메모리(1021b)에 라이트백하고, 2 번째 및 3 번째 채널에 대응하는 데이터를 제2 내부 메모리(1022b) 에 라이트백할 수 있다. 도 7은 본 발명의 다른 실시예에 따른 컴퓨팅 시스템을 설명하기 위한 개략도이고, 도 8은 본 발명의 다른 실시 예에 따른 뉴럴 프로세싱 시스템을 설명하기 위한 블록도이다. 도 7 및 도 8을 참조하면, 도 1의 실시예와 달리, 본 실시예에 따른 컴퓨팅 시스템의 뉴럴 프로세싱 시스템 은 워크로드 관리부를 더 포함한다. 워크로드 관리부는 특징 추출을 수행할 데이터(DATA) 중 제1 데이터(DATA1)를 제1 뉴럴 프로세싱 유닛 (100a)에 할당하고, 데이터(DATA) 중 제2 데이터(DATA2)를 제2 뉴럴 프로세싱 유닛(100b)에 할당한다. 구체적으 로, 워크로드 관리부는 특징 추출을 수행할 데이터(DATA) 중 제1 데이터(DATA1)를 제1 프론트엔드 모듈 (102a)에 할당하고, 데이터(DATA) 중 제2 데이터(DATA2)를 제2 프론트엔드 모듈(102b)에 할당한다. 이에 따라, 제1 프론트엔드 모듈(102a)은, 제1 특징 맵 및 제1 가중치를 이용하여 제1 데이터(DATA1)에 대한 특 징 추출 연산을 수행하고, 제2 프론트엔드 모듈(102b)은 제2 특징 맵 및 제2 가중치를 이용하여 제2 데이터 (DATA2)에 대한 특징 추출 연산을 수행할 수 있다. 특히, 본 발명의 몇몇의 실시예에서, 제1 데이터(DATA1)의 양(amount)과, 제2 데이터(DATA2)의 양은 서로 다를 수 있다. 클럭 관리 유닛은, 제1 클럭 신호(CLK1) 및 제2 클럭 신호(CLK2) 중 적어도 하나의 주파수를 조절하여, 워 크로드 관리부의 할당 동작에 따라, 제1 뉴럴 프로세싱 유닛(100a) 및 제2 뉴럴 프로세싱 유닛(100b)에 대 한 성능 및 전력 조절을 수행할 수 있다. 예를 들어, 클럭 관리 유닛은, 워크로드 관리부의 할당 동작 에 따라 제1 프론트엔드 모듈(102a), 제1 백엔드 모듈(104a), 제2 프론트엔드 모듈(102b) 및 제2 백엔드 모듈 (104b) 중 적어도 하나에 대한 클럭 게이팅을 수행할 수 있다. 이와 같은 방식으로, 본 발명의 다양한 실시예에 따른 뉴럴 프로세싱 시스템은 그 내부의 복수의 뉴럴 프로 세싱 유닛(100a, 100b)의 클럭 신호를 조절하여, 성능을 조절하거나 소모 전력을 조절할 수 있다. 예를 들어, 제1 뉴럴 프로세싱 유닛(100a)의 성능을 높이고 제2 뉴럴 프로세싱 유닛(100b)의 소모 전력을 낮추기 위해, 클 럭 관리 유닛은 제1 뉴럴 프로세싱 유닛(100a)을 구동하는 제1 클럭 신호(CLK1)의 주파수를 높이고 제2 뉴 럴 프로세싱 유닛(100b)을 구동하는 제2 클럭 신호(CLK2)의 주파수를 낮출 수 있다. 또 다른 예로, 제1 뉴럴 프 로세싱 유닛(100a)만을 사용하고 제2 뉴럴 프로세싱 유닛(100b)을 사용하지 않는 특수한 상황의 경우, 제2 뉴럴 프로세싱 유닛(100b)을 구동하는 제2 클럭 신호(CLK2)를 조절하여 클럭 게이팅을 수행할 수도 있다. 따라서 본 발명의 다양한 실시예에 따른 뉴럴 프로세싱 시스템을 포함하는 컴퓨팅 시스템에 따르면 비용 및 전력 소모 가 낮으면서도 인공 지능을 구현할 수 있게 된다. 도 9는 본 발명의 또 다른 실시예에 따른 컴퓨팅 시스템을 설명하기 위한 개략도이고, 도 10은 본 발명의 또 다 른 실시예에 따른 뉴럴 프로세싱 시스템을 설명하기 위한 블록도이다. 도 9 및 도 10을 참조하면, 도 7 및 도 8의 실시예와 달리, 본 실시예에 따른 컴퓨팅 시스템은 PMU를 더 포함한다. 앞서 설명한 바와 같이, 워크로드 관리부는 특징 추출을 수행할 데이터(DATA) 중 제1 데이터(DATA1)를 제1 프론트엔드 모듈(102a)에 할당하고, 데이터(DATA) 중 제2 데이터(DATA2)를 제2 프론트엔드 모듈(102b)에 할당한 다. 이에 따라, 제1 프론트엔드 모듈(102a)은, 제1 특징 맵 및 제1 가중치를 이용하여 제1 데이터(DATA1)에 대한 특 징 추출 연산을 수행하고, 제2 프론트엔드 모듈(102b)은 제2 특징 맵 및 제2 가중치를 이용하여 제2 데이터 (DATA2)에 대한 특징 추출 연산을 수행할 수 있다. 전력 관리 유닛은, 제1 뉴럴 프로세싱 유닛(100a)에 제1 파워 게이팅 신호(PG1)를 제공하고, 제2 뉴럴 프로 세싱 유닛(100b)에 제2 파워 게이팅 신호(PG2)를 제공한다. 구체적으로, 전력 관리 유닛은, 제1 프론트엔드 모듈(102a) 및 제1 백엔드 모듈(104a)에 제1 파워 게이팅 신호(PG1)를 제공하고, 제2 프론트엔드 모듈(102b) 및 제2 백엔드 모듈(104b)에 제2 파워 게이팅 신호(PG2)를 제공할 수 있다. 전력 관리 유닛은 제1 파워 게이팅 신호(PG1) 및 제2 파워 게이팅 신호(PG2) 중 적어도 하나의 값을 제어하 여, 워크로드 관리부의 할당 동작에 따라, 제1 뉴럴 프로세싱 유닛(100a) 및 제2 뉴럴 프로세싱 유닛 (100b)에 대한 전력 조절을 수행할 수 있다. 예를 들어, 전력 관리 유닛은 제1 프론트엔드 모듈(102a), 제1 백엔드 모듈(104a), 제2 프론트엔드 모듈(102b) 및 제2 백엔드 모듈(104b) 중 적어도 하나에 대한 파워 게이팅 을 수행할 수 있다. 이와 같은 방식으로, 본 발명의 다양한 실시예에 따른 뉴럴 프로세싱 시스템은 필요에 따라 그 내부의 복 수의 뉴럴 프로세싱 유닛(100a, 100b) 중 적어도 일부에 대해 파워 게이팅을 수행하여 뉴럴 프로세싱 시스템 의 소모 전력을 낮출 수 있다. 따라서 본 발명의 다양한 실시예에 따른 뉴럴 프로세싱 시스템을 포함하는 컴퓨팅 시스템에 따르면 비용 및 전력 소모가 낮으면서도 인공 지능을 구현할 수 있게 된다. 도 11은 본 발명의 또 다른 실시예에 따른 컴퓨팅 시스템을 설명하기 위한 개략도이다. 도 11을 참조하면, 본 실시예에 따른 컴퓨팅 시스템은 복수의 뉴럴 프로세싱 유닛(100a, 100b, 100c, 100d) 을 포함한다. 설명의 편의를 위해, 본 실시예에서 뉴럴 프로세싱 시스템은 4 개의 뉴럴 프로세싱 유닛 (100a, 100b, 100c, 100d)을 포함하는 것으로 도시하였으나, 본 발명의 범위가 이에 제한되는 것은 아니다. 클럭 관리 유닛은 뉴럴 프로세싱 시스템을 구동하기 위한 제1 클럭 신호(CLK1) 내지 제4 클럭 신호 (CLK4)를 생성하여, 제1 뉴럴 프로세싱 유닛(100a) 내지 제4 뉴럴 프로세싱 유닛(100d)에 각각 제공한다. 이에 따라 제1 뉴럴 프로세싱 유닛(100a)은 제1 클럭 신호(CLK1)에 따라 구동되고, 제2 뉴럴 프로세싱 유닛(100b)은 제2 클럭 신호(CLK2)에 따라 구동되고, 제3 뉴럴 프로세싱 유닛(100c)은 제3 클럭 신호(CLK3)에 따라 구동되고, 제4 뉴럴 프로세싱 유닛(100d)은 제4 클럭 신호(CLK4)에 따라 구동다. 본 발명의 몇몇의 실시예에서, 제1 클럭 신호(CLK1) 내지 제4 클럭 신호(CLK4)의 주파수는 모두 동일하지 않을 수 있다. 다시 말해서, 제1 뉴럴 프로세싱 유닛(100a) 내지 제4 뉴럴 프로세싱 유닛(100d)이 동작하는 클럭 도 메인들은 모두 동일하지 않을 수 있다. 클럭 관리 유닛은 필요에 따라 제1 클럭 신호(CLK1) 내지 제4 클럭 신호(CLK4)의 주파수를 각각 제어할 수 있다. 또한, 클럭 관리 유닛은 필요에 따라 제1 클럭 신호(CLK1) 내지 제4 클럭 신호(CLK4) 중 적어도 하나 에 대한 클럭 게이팅을 수행할 수도 있다. 도 12 및 도 13은 본 발명의 또 다른 실시예에 따른 뉴럴 프로세싱 시스템을 설명하기 위한 블록도이다. 도 12를 참조하면, 본 실시예에 따른 뉴럴 프로세싱 시스템은 제1 뉴럴 프로세싱 유닛(100a) 내지 제4 뉴럴 프로세싱 유닛(100d)을 포함한다. 제1 뉴럴 프로세싱 유닛(100a) 내지 제4 뉴럴 프로세싱 유닛(100d) 사이에는 하나 이상의 브릿지(1112, 1113, 1114)가 배치된다. 브릿지는 제1 뉴럴 프로세싱 유닛(100a)의 연산으로 생성된 중간 결과(R12)를 제2 뉴럴 프로세싱 유닛 (100b)으로 전달하고, 브릿지는 제1 뉴럴 프로세싱 유닛(100a)의 연산으로 생성된 중간 결과(R13)를 제3 뉴럴 프로세싱 유닛(100c)으로 전달한다. 그리고 브릿지는 제1 뉴럴 프로세싱 유닛(100a)의 연산으로 생 성된 중간 결과(R14)를 제4 뉴럴 프로세싱 유닛(100d)으로 전달한다. 이를 위해, 제1 뉴럴 프로세싱 유닛(100a)과 제2 뉴럴 프로세싱 유닛(100b)이 서로 다른 클럭 도메인에서 동작 하는 경우, 브릿지는 제1 뉴럴 프로세싱 유닛(100a) 및, 제1 뉴럴 프로세싱 유닛(100a)과 다른 클럭 도메 인에서 동작하는 제2 뉴럴 프로세싱 유닛(100b)에 전기적으로 접속된다. 이와 마찬가지로, 브릿지는 제1 뉴럴 프로세싱 유닛(100a) 및, 제1 뉴럴 프로세싱 유닛(100a)과 다른 클럭 도메인에서 동작하는 제3 뉴럴 프로 세싱 유닛(100c)에 전기적으로 접속하고, 브릿지는 제1 뉴럴 프로세싱 유닛(100a) 및, 제1 뉴럴 프로세싱 유닛(100a)과 다른 클럭 도메인에서 동작하는 제4 뉴럴 프로세싱 유닛(100d)에 전기적으로 접속한다. 이에 따라, 브릿지(1112, 1113, 1114)는 비동기식 브릿지로 구현되어, 서로 다른 클럭 도메인 사이에서 데이터 전달을 가능하도록 한다. 이어서 도 13을 참조하면, 제1 뉴럴 프로세싱 유닛(100a) 내지 제4 뉴럴 프로세싱 유닛(100d) 사이에는 하나 이 상의 브릿지(1122, 1123, 1124)가 배치된다. 브릿지는 제2 뉴럴 프로세싱 유닛(100b)의 연산으로 생성된 중간 결과(R22)를 제1 뉴럴 프로세싱 유닛 (100a)으로 전달하고, 브릿지는 제3 뉴럴 프로세싱 유닛(100c)의 연산으로 생성된 중간 결과(R33)를 제1 뉴럴 프로세싱 유닛(100a)으로 전달한다. 그리고 브릿지는 제4 뉴럴 프로세싱 유닛(100d)의 연산으로 생 성된 중간 결과(R44)를 제1 뉴럴 프로세싱 유닛(100a)으로 전달한다. 이를 위해, 제1 뉴럴 프로세싱 유닛(100a)과 제2 뉴럴 프로세싱 유닛(100b)이 서로 다른 클럭 도메인에서 동작 하는 경우, 브릿지는 제1 뉴럴 프로세싱 유닛(100a) 및, 제1 뉴럴 프로세싱 유닛(100a)과 다른 클럭 도메 인에서 동작하는 제2 뉴럴 프로세싱 유닛(100b)에 전기적으로 접속된다. 이와 마찬가지로, 브릿지는 제1 뉴럴 프로세싱 유닛(100a) 및, 제1 뉴럴 프로세싱 유닛(100a)과 다른 클럭 도메인에서 동작하는 제3 뉴럴 프로 세싱 유닛(100c)에 전기적으로 접속하고, 브릿지는 제1 뉴럴 프로세싱 유닛(100a) 및, 제1 뉴럴 프로세싱 유닛(100a)과 다른 클럭 도메인에서 동작하는 제4 뉴럴 프로세싱 유닛(100d)에 전기적으로 접속한다. 이에 따라, 브릿지(1112, 1113, 1114)는 비동기식 브릿지로 구현되어, 서로 다른 클럭 도메인 사이에서 데이터 전달을 가능하도록 한다. 도 12 및 도 13의 실시예에서는, 제1 뉴럴 프로세싱 유닛(100a)과 다른 뉴럴 프로세싱 유닛(100b, 100c, 100d) 사이의 브릿지에 대해 설명하였으나, 본 발명의 범위가 이에 제한되는 것은 아니고, 이와 같은 내용은 제2 뉴럴 프로세싱 유닛(100b)과 다른 뉴럴 프로세싱 유닛(100c, 100d) 사이, 그리고 제3 뉴럴 프로세싱 유닛(100c)과 제 4 뉴럴 프로세싱 유닛(100d) 사이에도 동일하게 적용될 수 있다. 도 14는 본 발명의 또 다른 실시예에 따른 컴퓨팅 시스템을 설명하기 위한 블록도이다. 도 14를 참조하면, 본 실시예에 따른 컴퓨팅 시스템의 뉴럴 프로세싱 시스템은 워크로드 관리부를 더 포함한다. 도 7 및 도 8에서 설명한 바와 유사하게, 워크로드 관리부는 특징 추출을 수행할 데이터 (DATA)를 제1 뉴럴 프로세싱 유닛(100a) 내지 제4 뉴럴 프로세싱 유닛(100d)에 분배 할당할 수 있다. 그리고 각 각의 뉴럴 프로세싱 유닛(100a) 내지 제4 뉴럴 프로세싱 유닛(100d)에 분배되는 데이터의 양은 모두 동일하지 않을 수 있다. 클럭 관리 유닛은, 제1 클럭 신호(CLK1) 내지 제4 클럭 신호(CLK4) 중 적어도 하나의 주파수를 조절하여, 워크로드 관리부의 할당 동작에 따라, 도 7 및 도 8에서 설명한 바와 유사하게, 제1 뉴럴 프로세싱 유닛 (100a) 내지 제4 뉴럴 프로세싱 유닛(100d)에 대한 성능 및 전력 조절을 수행할 수 있다. 이와 같은 방식으로, 본 발명의 다양한 실시예에 따른 뉴럴 프로세싱 시스템은 그 내부의 복수의 뉴럴 프로 세싱 유닛(100a, 100b, 100c, 100d)의 클럭 신호를 조절하여, 성능을 조절하거나 소모 전력을 조절할 수 있다. 예를 들어, 제1 뉴럴 프로세싱 유닛(100a) 내지 제3 뉴럴 프로세싱 유닛(100c)의 성능을 높이고 제4 뉴럴 프로 세싱 유닛(100d)의 소모 전력을 낮추기 위해, 클럭 관리 유닛은 제1 뉴럴 프로세싱 유닛(100a) 내지 제3 뉴 럴 프로세싱 유닛(100c)을 구동하는 제1 클럭 신호(CLK1) 내지 제3 클럭 신호(CLK3)의 주파수를 높이고, 제4 뉴 럴 프로세싱 유닛(100d)을 구동하는 제4 클럭 신호(CLK4)의 주파수를 낮출 수 있다. 또 다른 예로, 제1 뉴럴 프 로세싱 유닛(100a) 및 제2 뉴럴 프로세싱 유닛(100b)만을 사용하고, 제3 뉴럴 프로세싱 유닛(100c) 및 제4 뉴럴 프로세싱 유닛(100d)을 사용하지 않는 경우, 제3 뉴럴 프로세싱 유닛(100c) 및 제4 뉴럴 프로세싱 유닛(100d)을 구동하는 제3 클럭 신호(CLK3) 및 제4 클럭 신호(CLK4)를 조절하여 클럭 게이팅을 수행할 수도 있다. 따라서 본 발명의 다양한 실시예에 따른 뉴럴 프로세싱 시스템을 포함하는 컴퓨팅 시스템에 따르면 비용 및 전력 소모 가 낮으면서도 인공 지능을 구현할 수 있게 된다. 도 15는 본 발명의 또 다른 실시예에 따른 컴퓨팅 시스템을 설명하기 위한 블록도이다. 도 15를 참조하면, 도 14의 실시예와 달리, 본 실시예에 따른 컴퓨팅 시스템의 뉴럴 프로세싱 시스템은 PMU를 더 포함한다. 앞서 설명한 바와 같이, 워크로드 관리부는 특징 추출을 수행할 데이터(DATA)를 제1 뉴럴 프로세싱 유닛 (100a) 내지 제4 뉴럴 프로세싱 유닛(100d)에 분배 할당한다. 전력 관리 유닛은, 제1 뉴럴 프로세싱 유닛(100a) 내지 제4 뉴럴 프로세싱 유닛(100d)에 제1 파워 게이팅 신호(PG1) 내지 제4 파워 게이팅 신호(PG4)를 제공한다. 전력 관리 유닛은 제1 파워 게이팅 신호(PG1) 내지 제4 파워 게이팅 신호(PG4) 중 적어도 하나의 값을 제어 하여, 워크로드 관리부의 할당 동작에 따라, 도 9 및 도 10에서 설명한 바와 유사하게, 제1 뉴럴 프로세싱 유닛(100a) 내지 제4 뉴럴 프로세싱 유닛(100d)에 대한 전력 조절을 수행할 수 있다. 이와 같은 방식으로, 본 발명의 다양한 실시예에 따른 뉴럴 프로세싱 시스템은 필요에 따라 그 내부의 복수 의 뉴럴 프로세싱 유닛(100a, 100b, 100c, 100d) 중 적어도 일부에 대해 파워 게이팅을 수행하여 뉴럴 프로세싱 시스템의 소모 전력을 낮출 수 있다. 따라서 본 발명의 다양한 실시예에 따른 뉴럴 프로세싱 시스템을 포함하는 컴퓨팅 시스템에 따르면 비용 및 전력 소모가 낮으면서도 인공 지능을 구현할 수 있게 된다. 도 16은 본 발명의 또 다른 실시예에 따른 컴퓨팅 시스템을 설명하기 위한 블록도이다. 도 16을 참조하면, 본 실시예에 따른 컴퓨팅 시스템은 뉴럴 프로세싱 시스템, 클럭 관리 유닛, 프로 세서, 메모리, 전력 관리 유닛, 스토리지, 디스플레이 및 카메라를 포함하는 컴퓨팅 시스템일 수 있다. 뉴럴 프로세싱 시스템, 클럭 관리 유닛, 프로세서, 메모리, 전력 관리 유닛 , 스토리지, 디스플레이 및 카메라는 버스를 통해 데이터를 주고 받을 수 있다. 본 발명의 몇몇의 실시예에서, 컴퓨팅 시스템은 모바일 컴퓨팅 시스템일 수 있다. 예를 들어, 컴퓨팅 시스템 은 스마트폰, 태블릿 컴퓨터, 노트북 컴퓨터 등을 비롯한 컴퓨팅 시스템일 수 있다. 물론 본 발명의 범위는 이에 한정되지 않는다. 이제까지 설명한 바와 같은 본 발명의 다양한 실시예에 따른 뉴럴 프로세싱 시스템은 카메라를 통해 생 성한 이미지 데이터 또는 스토리지에 저장된 이미지 데이터에 대해, 저 비용과 저 전력으로 CNN을 이용한 특징 추출 연산을 수행할 수 있다. 이제까지 설명한 바와 같이, 뉴럴 프로세싱 시스템은 개별적으로 클럭 및 전력을 조절할 수 있는 복수의 뉴 럴 프로세싱 유닛을 포함하는 아키텍처를 채택함으로써, 비용 및 전력 소모가 낮으면서도 인공 지능을 충실히 구현 및 실행할 수 있게 된다. 이상 첨부된 도면을 참조하여 본 발명의 실시예들을 설명하였으나, 본 발명은 상기 실시예들에 한정되는 것이"}
{"patent_id": "10-2018-0106917", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "아니라 서로 다른 다양한 형태로 제조될 수 있으며, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자는 본 발명의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이 해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으 로 이해해야만 한다."}
{"patent_id": "10-2018-0106917", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 컴퓨팅 시스템을 설명하기 위한 개략도이다. 도 2는 본 발명의 일 실시예에 따른 뉴럴 프로세싱 시스템을 설명하기 위한 블록도이다. 도 3은 본 발명의 일 실시예에 따른 뉴럴 프로세싱 시스템을 설명하기 위한 블록도이다. 도 4 및 도 5는 본 발명의 일 실시예에 따른 뉴럴 프로세싱 시스템의 프론트엔드 모듈을 설명하기 위한 블록도 이다. 도 6은 본 발명의 일 실시예에 따른 뉴럴 프로세싱 시스템의 백엔드 모듈을 설명하기 위한 블록도이다. 도 7은 본 발명의 다른 실시예에 따른 컴퓨팅 시스템을 설명하기 위한 개략도이다. 도 8은 본 발명의 다른 실시예에 따른 뉴럴 프로세싱 시스템을 설명하기 위한 블록도이다. 도 9는 본 발명의 또 다른 실시예에 따른 컴퓨팅 시스템을 설명하기 위한 개략도이다. 도 10은 본 발명의 또 다른 실시예에 따른 뉴럴 프로세싱 시스템을 설명하기 위한 블록도이다. 도 11은 본 발명의 또 다른 실시예에 따른 컴퓨팅 시스템을 설명하기 위한 개략도이다. 도 12 및 도 13은 본 발명의 또 다른 실시예에 따른 뉴럴 프로세싱 시스템을 설명하기 위한 블록도이다. 도 14는 본 발명의 또 다른 실시예에 따른 컴퓨팅 시스템을 설명하기 위한 블록도이다. 도 15는 본 발명의 또 다른 실시예에 따른 컴퓨팅 시스템을 설명하기 위한 블록도이다. 도 16은 본 발명의 또 다른 실시예에 따른 컴퓨팅 시스템을 설명하기 위한 블록도이다."}
