{"patent_id": "10-2022-0184405", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0102409", "출원번호": "10-2022-0184405", "발명의 명칭": "경량 인공지능 지원 하드웨어의 최적 활용을 위한 앙상블 학습 방법 및 장치", "출원인": "한국전자기술연구원", "발명자": "김병수"}}
{"patent_id": "10-2022-0184405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "각기 다른 구조를 갖는 다수의 경량 뉴럴 네트워크들을 구성하는 앙상블 학습 수행 블럭; 및구성된 경량 뉴럴 네트워크들의 분류 결과들을 기초로 최종 분류 결과를 판정하는 판정 블럭;을 포함하는 것을특징으로 하는 경량 인공지능 지원 하드웨어."}
{"patent_id": "10-2022-0184405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,경량 뉴럴 네트워크들은,각기 다른 하이퍼 파라미터를 갖는 것을 특징으로 하는 경량 인공지능 지원 하드웨어."}
{"patent_id": "10-2022-0184405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,경량 뉴럴 네트워크들은,경량 인공지능 지원 하드웨어의 자원 범위 내에서 최대한의 개수로 생성되는 것을 특징으로 하는 경량 인공지능지원 하드웨어."}
{"patent_id": "10-2022-0184405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,경량 인공지능 지원 하드웨어의 자원은,경량 인공지능 지원 하드웨어에 탑재된 메모리를 포함하는 것을 특징으로 하는 경량 인공지능 지원 하드웨어."}
{"patent_id": "10-2022-0184405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 3에 있어서,경량 뉴럴 네트워크들은,멀티모달 데이터셋으로부터 컨텍스트를 분류하는 것을 특징으로 하는 경량 인공지능 지원 하드웨어."}
{"patent_id": "10-2022-0184405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "에 있어서,판정 블럭은,보팅 알고리즘을 기반으로 최종 분류 결과를 판정하는 것을 특징으로 하는 경량 인공지능 지원 하드웨어."}
{"patent_id": "10-2022-0184405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 6에 있어서,가중치들은,경량 뉴럴 네트워크들의 정확도를 기반으로 변경되는 것을 특징으로 하는 경량 인공지능 지원 하드웨어."}
{"patent_id": "10-2022-0184405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 1에 있어서,앙상블 학습 수행 블럭은,일부 경량 뉴럴 네트워크을 배제하고 새로운 경량 뉴럴 네트워크를 추가할 수 있는 것을 특징으로 하는 경량 인공지능 지원 하드웨어."}
{"patent_id": "10-2022-0184405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "각기 다른 구조를 갖는 다수의 경량 뉴럴 네트워크들을 구성하는 단계;구성된 경량 뉴럴 네트워크들의 분류 결과들을 기초로 최종 분류 결과를 판정하는 단계;를 포함하는 것을 특징으로 하는 경량 인공지능 지원 하드웨어의 구동 방법."}
{"patent_id": "10-2022-0184405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "각기 다른 구조를 갖는 다수의 경량 뉴럴 네트워크들을 구성하는 앙상블 학습 수행 블럭; 및구성된 경량 뉴럴 네트워크들에서 출력되는 컨텍스트 데이터들에 대해, 보팅 알고리즘을 기반으로 최종 분류 결과를 판정하는 판정 블럭;을 포함하는 것을 특징으로 하는 경량 인공지능 지원 하드웨어."}
{"patent_id": "10-2022-0184405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "각기 다른 구조를 갖는 다수의 경량 뉴럴 네트워크들을 구성하는 단계; 및구성된 경량 뉴럴 네트워크들에서 출력되는 컨텍스트 데이터들에 대해, 보팅 알고리즘을 기반으로 최종 분류 결과를 판정하는 단계;를 포함하는 것을 특징으로 하는 경량 인공지능 지원 하드웨어의 구동 방법."}
{"patent_id": "10-2022-0184405", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "경량 인공지능 지원 하드웨어의 최적 활용을 위한 앙상블 학습 방법 및 장치가 제공된다. 본 발명의 실시예에 따 른 경량 인공지능 지원 하드웨어는, 각기 다른 구조를 갖는 다수의 경량 뉴럴 네트워크들을 구성하는 앙상블 학 습 수행 블럭 및 구성된 경량 뉴럴 네트워크들의 분류 결과들을 기초로 최종 분류 결과를 판정하는 판정 블럭을 포함한다. 이에 의해, 제한된 자원을 갖는 경량 인공지능 하드웨어를 최적으로 활용하여 앙상블 뉴럴 네트워크를 구성함으로써, 자원 활용의 극대화에 의한 경량 인공지능 하드웨어의 정확도 향상이 가능해진다."}
{"patent_id": "10-2022-0184405", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 앙상블 학습에 관한 것으로, 더욱 상세하게는 제한된 자원을 갖는 경량 인공지능 하드웨어의 최적 활 용을 위한 앙상블 학습 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0184405", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능 기술은 다양한 환경에서 얻어진 데이터를 기반으로 분류, 인식, 추정 등의 응용에 널리 이용되고 있으며, 성능 측면에서도 과거에 비해 실제 제품화가 진행될 수 있을 정도로 향상되어 많은 분야에서 주목받고 있다. 특히, 각종 센서 기술들이 많이 발달한 현대 환경에서는 여러 분야의 빅데이터를 비교적 쉽게 얻을 수 있 으며, 이는 학습에 있어 많은 데이터를 요구하는 인공지능의 응용 및 기술 발전에 크게 기여하고 있다. 이에 따 라 미래에는 인공지능 기술의 실제 응용 분야가 더욱 확장될 것으로 보인다. 인공지능 기술의 발전은 heavy 한 네트워크 구조를 갖는 deep neural network 기반의 연구 분야에서 뿐만 아니 라, 딥러닝 모델의 크기를 감소시키고, 연산을 간소화하는 경량 인공지능 분야에서도 활발히 이루어지고 있다. 특히, 경량 인공지능은 막강한 프로세서 기반의 인프라가 갖춰지기 힘든 엣지 단에 적용될 수 있으며, 적은 비 용으로 운영이 가능하다는 점에서 드론, 로봇을 포함한 다양한 IoT 기기 활용 분야에서의 관심이 점차 증가하고 있다. 경량 인공지능 기술은 경량 딥러닝 알고리즘 개발 분야와 알고리즘 경량화 분야의 두 축으로 연구가 진행되고 있다. 경량 딥러닝 알고리즘은 모델의 구조적 한계를 극복하고자 하는 연구이며, 모델 구조 변경, 합성곱 필터 변경, 자동 모델 탐색 등의 접근 방법으로 연구가 진행되고 있다. 알고리즘 경량화는 기존 딥러닝 모델의 효율 적인 사용을 위한 연구이며, 모델 압축, 지식 증류, 하드웨어 가속화 등의 접근 방법으로 연구가 진행되고 있다. 경량 인공지능이 적용되는 응용 환경은 적은 비용으로 최대의 성능을 내기 위해 비교적 제한적인 자원이 전제되 며, 특히 하드웨어 환경 측면에서 낮은 메모리 용량, 제한된 노드 수 등 소규모 네트워크 기반의 인공지능 기술 이 적용된다. 그러나 단순한 단일 네트워크 구조로 운영되는 경량 인공지능 적용 환경에서는 제공되는 하드웨어 자원의 일부 만 사용하는 경우가 많으며, 이로 인해 최적의 성능을 얻기가 힘들다는 문제가 있다."}
{"patent_id": "10-2022-0184405", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위하여 안출된 것으로서, 본 발명의 목적은, 경량 인공지능 하드웨어 의 분류 정확도 향상을 위한 방안으로, 제한된 자원을 갖는 경량 인공지능 하드웨어를 최적으로 활용하여 앙상 블 뉴럴 네트워크를 구성하는 방법을 제공함에 있다."}
{"patent_id": "10-2022-0184405", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른 경량 인공지능 지원 하드웨어는 각기 다른 구조를 갖는 다수의 경량 뉴럴 네트워크들을 구성하는 앙상블 학습 수행 블럭; 및 구성된 경량 뉴럴 네트워크들의 분류 결과 들을 기초로 최종 분류 결과를 판정하는 판정 블럭;을 포함한다. 경량 뉴럴 네트워크들은, 각기 다른 하이퍼 파라미터를 가질 수 있다. 경량 뉴럴 네트워크들은, 경량 인공지능 지원 하드웨어의 자원 범위 내에서 최대한의 개수로 생성될 수 있다. 경량 인공지능 지원 하드웨어의 자원은, 경량 인공지능 지원 하드웨어에 탑재된 메모리를 포함할 수 있다. 경량 뉴럴 네트워크들은, 멀티모달 데이터셋으로부터 컨텍스트를 분류할 수 있다. 판정 블럭은, 경량 뉴럴 네트워크들에서 출력되는 컨텍스트 데이터들에 각기 다른 가중치를 부여하고, 가중치가 부여된 컨텍스트 데이터들을 기초로 최종 분류 결과를 판정할 수 있다. 판정 블럭은, 보팅 알고리즘을 기반으로 최종 분류 결과를 판정할 수 있다. 가중치들은, 경량 뉴럴 네트워크들의 정확도를 기반으로 변경될 수 있다. 앙상블 학습 수행 블럭은, 일부 경량 뉴럴 네트워크을 배제하고 새로운 경량 뉴럴 네트워크를 추가할 수 있다. 본 발명의 다른 측면에 따르면, 각기 다른 구조를 갖는 다수의 경량 뉴럴 네트워크들을 구성하는 단계; 구성된 경량 뉴럴 네트워크들의 분류 결과들을 기초로 최종 분류 결과를 판정하는 단계;를 포함하는 것을 특징으로 하 는 경량 인공지능 지원 하드웨어의 구동 방법이 제공된다. 본 발명의 또다른 측면에 따르면, 각기 다른 구조를 갖는 다수의 경량 뉴럴 네트워크들을 구성하는 앙상블 학습 수행 블럭; 및 구성된 경량 뉴럴 네트워크들에서 출력되는 컨텍스트 데이터들에 대해, 보팅 알고리즘을 기반으 로 최종 분류 결과를 판정하는 판정 블럭;을 포함하는 것을 특징으로 하는 경량 인공지능 지원 하드웨어가 제공 된다. 본 발명의 또다른 측면에 따르면, 각기 다른 구조를 갖는 다수의 경량 뉴럴 네트워크들을 구성하는 단계; 및 구 성된 경량 뉴럴 네트워크들에서 출력되는 컨텍스트 데이터들에 대해, 보팅 알고리즘을 기반으로 최종 분류 결과 를 판정하는 단계;를 포함하는 것을 특징으로 하는 경량 인공지능 지원 하드웨어의 구동 방법이 제공된다."}
{"patent_id": "10-2022-0184405", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상 설명한 바와 같이, 본 발명의 실시예들에 따르면, 제한된 자원을 갖는 경량 인공지능 하드웨어를 최적으로 활용하여 앙상블 뉴럴 네트워크를 구성함으로써, 자원 활용의 극대화에 의한 경량 인공지능 하드웨어의 정확도 향상이 가능해진다."}
{"patent_id": "10-2022-0184405", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 발명을 보다 상세하게 설명한다. 본 발명의 실시예에서는 경량 인공지능 지원 하드웨어의 최적 활용을 위한 앙상블 학습 방법 및 장치를 제시한 다. 경량 인공지능 지원 하드웨어의 분류 정확도를 높이기 위한 방안으로, 제한된 자원을 갖는 경량 인공지능 하드웨어의 최적 활용을 위해 멀티모달 데이터셋에 대하여 다양한 앙상블 학습을 진행하고, 각 네트워크에서 제 공되는 컨텍스트 정보를 이용하여 데이터 분류 정확도를 높이는 기술이다. 경량 인공지능 하드웨어의 최적 활용을 위해 데이터셋에 대하여 다양한 네트워크를 적용하는 앙상블 학습 구조 를 채택하였다는 점과 다양한 네트워크들에서 제공하는 컨텍스트 데이터 기반으로 분류 결과를 판정한다는 점에 서, 기존 경량 인공지능 하드웨어와 구별된다. 도 1은 본 발명의 일 실시예에 따른 앙상블 학습 기반 경량 인공지능 지원 하드웨어의 구성을 도시한 도면이다. 본 발명의 실시예에 따른 인공지능 지원 하드웨어는 도시된 바와 같이, 앙상블 학습 수행 블럭 및 결 과 판정 블럭을 포함하여 구성된다. 앙상블 학습 수행 블럭은 다수의 경량 뉴럴 네트워크들을 구성하여 학습시키고 구동시키는 블럭이다. 앙상 블 학습 수행 블럭에 의해 구성되는 경량 뉴럴 네트워크들은 서로 다른 구조를 갖으며 서로 다른 하이퍼 파라미터(Hyper Parameter)를 갖는다. 경량 뉴럴 네트워크들은 경량 인공지능 지원 하드웨어의 자원 범위, 구체적으로 경량 인공지능 지원 하드 웨어에 탑재된 메모리 범위 내에서 최대한의 개수로 생성된다. 도 2에는 앙상블 학습 수행 블럭을 위한 경량 뉴럴 네트워크들(Network #1, Network #2, Network #3, ..., Network #N)의 구성 결과를 예시하였다. 도시된 바와 같이 경량 뉴럴 네트워크들은 인공지능 지원 하드웨 어에서 제공하는 자원을 최적으로 활용할 수 있도록 구성된다. 기존의 단일 네트워크 기반 경량 인공지능 지원 하드웨어의 활용 구조 대비 효율적인 하드웨어 활용 구조로써, 경량 인공지능의 성능 향상에 크게 기여할 수 있는 구조이다. 도 3은 앙상블 학습 수행 블럭의 세부 구조를 도시한 도면이다. 도시된 바와 같이 앙상블 학습 수행 블럭 은 학습용 멀티모달 데이터셋으로 경량 뉴럴 네트워크들(Network #1, Network #2, Network #3, ..., Network #N)을 각각 학습시킨다. 전술한 바와 같이 경량 뉴럴 네트워크들(Network #1, Network #2, Network #3, ..., Network #N)은 서로 다른 구조를 갖으며, 서로 다른 하이퍼 파라미터를 갖능다. 학습이 완료된 경량 뉴럴 네트워크들(Network #1, Network #2, Network #3, ..., Network #N)을 추론용 멀티모 달 데이터셋으로부터 컨텍스트를 분류하여, 분류 결과로 컨텍스트 데이터들을 각각 생성하여 출력한다. 다시 도 1을 참조하여 설명한다. 결과 판정 블럭은 앙상블 학습 수행 블럭에 구성된 경량 뉴럴 네트 워크들(Network #1, Network #2, Network #3, ..., Network #N)의 분류 결과들을 기초로 최종 분류 결과를 판 정한다. 도 4에는 결과 판정 블럭의 세부 구성을 도시하였다. 도시된 바와 같이 결과 판정 블럭은 가중치 적 용 블럭과 보팅&판정 블럭을 포함하여 구성된다. 가중치 적용 블럭은 경량 뉴럴 네트워크들(Network #1, Network #2, Network #3, ..., Network #N)의 분 류 결과들로 출력되는 컨텍스트 데이터들에 가중치를 각각 부여한다. 가중치는 경량 뉴럴 네트워크들의 과거 분류 결과들의 정확도를 기초로 가변될 수 있다. 즉 정확도가 높아지고 있는 경량 뉴럴 네트워크의 가중치는 증가하도록 하고, 정확도가 낮아지고 있는 경량 뉴럴 네트워크의 가중치는 감소하도록 할 수 있다. 보팅&판정 블럭은 가중치가 부여된 컨텍스트 데이터들에 대해 보팅 알고리즘(Voting Algorithm)을 기반으 로 최종 분류 결과를 판정하여 출력한다. 도 5는 경량 인공지능 지원 하드웨어의 최적 활용을 위한 앙상블 학습 방법의 설명에 제공되는 흐름도이다. 도시된 바와 같이, 앙상블 학습 수행 블럭이 먼저 경량 뉴럴 네트워크들(Network #1, Network #2, Network #3, ..., Network #N)을 구성한다(S210). S210단계에서 경량 뉴럴 네트워크들(Network #1, Network #2, Network #3, ..., Network #N)의 구조와 하이퍼 파라미터는 서로 다르게 설정한다. 또한 S210단계에서 경량 뉴럴 네트워크들(Network #1, Network #2, Network #3, ..., Network #N)은 경량 인공 지능 지원 하드웨어의 자원 내에서 가능한 최대 개수로 생성된다. 다음 앙상블 학습 수행 블럭은 S210단계에서 구성된 경량 뉴럴 네트워크들(Network #1, Network #2, Network #3, ..., Network #N)을 학습용 멀티모달 데이터셋들로 각각 학습시킨다(S220). 그리고 학습이 완료된 경량 뉴럴 네트워크들(Network #1, Network #2, Network #3, ..., Network #N)은 추론용 멀티모달 데이터셋 데이터셋을 각각 분석하여 분류 결과로 컨텍스트 데이터들을 각각 생성한다(S230). 그러면 결과 판정 블럭의 가중치 적용 블럭은 S230단계에서 생성되는 경량 뉴럴 네트워크들(Network #1, Network #2, Network #3, ..., Network #N)의 컨텍스트 데이터들에 가중치를 각각 부여한다(S240). 이후 보팅&판정 블럭은 S240단계에 의해 가중치가 부여된 컨텍스트 데이터들에 대해 보팅 알고리즘을 기반 으로 최종 분류 결과를 판정하여 출력한다(S250). 지금까지 경량 인공지능 지원 하드웨어의 최적 활용을 위한 앙상블 학습 방법 및 장치에 대해 바람직한 실시예 를 들어 상세히 설명하였다. 위 실시예에서는 경량 인공지능 지원 하드웨어의 컨텍스트 분류 정확도를 갖도록 하기 위해, 멀티모달 데이터셋 에 대해 앙상블 학습을 적용하되 경량 인공지능 지원 하드웨어의 자원을 최대한 활용하여 앙상블 뉴럴 네트워크들을 구성하도록 하여, 다양한 네트워크 활용으로 기존의 단일 경량 네트워크 학습 기반 결과 판정 기술의 한계 를 극복하였다. 위 실시예에서 경량 뉴럴 네트워크들에 대해서는 변경이 가능한 것으로 구현 가능하다. 이를 테면 앙상블 학습 수행 블럭은 정확도가 떨어지는 경량 뉴럴 네트워크를 배제하고 새로운 경량 뉴럴 네트워크를 추가하는 것 이 가능하다. 또한, 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2022-0184405", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2022-0184405", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 앙상블 학습 기반 경량 인공지능 지원 하드웨어의 구성을 도시한 도면, 도 2는 앙상블 학습 수행 블럭을 위한 경량 뉴럴 네트워크들의 구성 결과 예시, 도 3은 앙상블 학습 수행 블럭의 세부 구조, 도 4는 결과 판정 블럭의 세부 구성, 도 5는 경량 인공지능 지원 하드웨어의 최적 활용을 위한 앙상블 학습 방법의 설명에 제공되는 흐름도이다."}
