{"patent_id": "10-2023-0140801", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0057236", "출원번호": "10-2023-0140801", "발명의 명칭": "부스팅 알고리즘에 기초하여 이상치를 제거하는 방법 및 장치", "출원인": "제노플랜 인크", "발명자": "강병규"}}
{"patent_id": "10-2023-0140801", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "유전자형 정보(Genotype data) 및 표현형 정보(phenotype data)를 포함하는 데이터 세트(data set)에기초하여, 제1 분류 모델을 학습하는 단계;상기 학습에 기초하여, 질병에 관한 케이스(Case)와 컨트롤(Control)의 분류를 수행하는 제2 분류 모델을 획득하는 단계;상기 데이터 세트를 상기 제2 분류 모델에 입력하고, 상기 제2 분류 모델의 출력으로 분류 결과를 출력하는 단계; 및상기 분류 결과에 기초하여, 상기 데이터 세트의 이상치(outlier)를 제거하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2023-0140801", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 학습하는 단계는,부스팅 알고리즘(Boosting Algorithm)에 기초하여, 상기 제1 분류 모델을 학습하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2023-0140801", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,제1 분류 모델은,복수의 약한 분류기들(weak classifiers)를 포함하고,상기 학습하는 단계는,상기 데이터 세트에 기초하여, 상기 복수의 약한 분류기들을 순차적으로 학습하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2023-0140801", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 제1 분류 모델은,1차부터 n차의 순서를 가지는 n 개의 약한 분류기들을 포함하고,상기 학습하는 단계는,상기 데이터 세트를 n-1차 약한 분류기들에 입력함으로써, n-1차 예측 값을 출력하는 단계; 및상기 n-1차 예측 값과 정답 값의 차이에 기초하여, 상기 n차 약한 분류기들을 업데이트하는 단계;를 포함하고,상기 n은, 2 이상의 자연수인, 방법."}
{"patent_id": "10-2023-0140801", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 제2 분류 모델을 결정하는 단계는,상기 데이터 세트를 상기 n차 약한 분류기에 입력함으로써, n차 예측 값을 출력하는 단계; 및상기 n차 예측 값과 정답 값의 비교에 기초하여, 상기 n차 약한 분류기를 상기 제2 분류 모델로 결정하는 단계;를 포함하는, 방법.공개특허 10-2025-0057236-3-청구항 6 제1 항에 있어서,상기 제거하는 단계는,상기 분류 결과와 정답 값의 차이에 기초하여, 상기 데이터 세트의 이상치를 결정하는 단계; 및상기 데이터 세트의 이상치를 상기 데이터 세트로부터 제거하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2023-0140801", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 이상치가 제거된 상기 데이터 세트에 기초하여, 전장 유전체 연관분석 연구(Genome-Wide AssociationStudy, GWAS)를 수행하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2023-0140801", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 전장 유전체 연관분석 연구의 결과에 기초하여, 다유전자 위험점수(Polygenic risk score, PRS)를 산출하는 단계; 및상기 다유전자 위험 점수에 기초하여, 질병을 예측하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2023-0140801", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "적어도 하나의 메모리; 및적어도 하나의 프로세서;를 포함하고,상기 적어도 하나의 프로세서는,유전자형 정보(Genotype data) 및 표현형 정보(phenotype data)를 포함하는 데이터 세트(data set)에기초하여, 제1 분류 모델을 학습하고,상기 학습에 기초하여, 질병에 관한 케이스(Case)와 컨트롤(Control)의 분류를 수행하는 제2 분류 모델을 획득하고,상기 데이터 세트를 상기 제2 분류 모델에 입력하고, 상기 제2 분류 모델의 출력으로 분류 결과를 출력하고,상기 분류 결과에 기초하여, 상기 데이터 세트의 이상치(outlier)를 제거하는, 장치."}
{"patent_id": "10-2023-0140801", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항에 따른 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 부스팅 알고리즘에 기초하여 이상치를 제거하는 방법 및 장치에 관한 것이다. 본 개시의 일 실시 예에 따른 방법은, 유전자형 정보(Genotype data) 및 표현형 정보(phenotype data)를 포함하는 데이터 세트(data set)에 기초하여, 제1 분류 모델을 학습하고, 학습에 기초하여, 질병에 관한 케이스(Case)와 컨트롤(Control)의 분류를 수행하는 제2 분류 모델을 획득하고, 데이터 세트를 제2 분류 모델에 입력하고, 제2 분류 모델의 출력으 로 분류 결과를 출력하고, 분류 결과에 기초하여, 데이터 세트의 이상치(outlier)를 제거할 수 있다."}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 부스팅 알고리즘에 기초하여 이상치를 제거하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전장 유전체 연관분석 연구(Genome-wide association study, GWAS)란, 많은 개인의 유전체(genome)들을 통하여 수백, 수천 또는 수백만 이상의 유전적 다양성들이 유전체적-표현형적 관련이 있는지를 구별하고 검사하는 것으 로 복잡한 질병을 진단할 수 있는 방법이다. 전장 유전체 연관분석 연구는, 질병 발명에 관한 연관성을 밝혀낼 수 있는데, 특히 질병 위험성 분석 시 유용하 게 작용된다는 특징이 있다. 질병을 대상으로 하는 전장 유전체 연관분석 연구는, 케이스(Case)와 컨트롤(Control)의 데이터 세트를 사용하는데, 여기에서 케이스는 질병을 걸린 집단을 의미하고, 컨트롤은 질병에 걸 리지 않았으며 비슷한 종류의 질병에 대한 위험성도 가지고 있지 않은 집단을 의미한다. 한편, 이러한 전장 유전체 연관분석 연구를 진행함에 있어서, 유전적으로 질병의 위험성이 낮음에도 불구하고 케이스로 분류되거나, 유전적으로 질병의 위험성이 높음에도 불구하고 컨트롤로 분류되어 전장 유전체 연관분석 연구의 결과가 적절하지 않은 경우가 발생한다는 문제점이 있다. 이에 따라, 전장 유전체 연관분석을 연구함에 있어서, 케이스 및 컨트롤을 정확히 분류하는 기술에 대한 요구가 늘어나고 있다."}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다."}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 부스팅 알고리즘에 기초하여 이상치를 제거하는 방법 및 장치를 제공하는 데 있다. 또한, 상기 방법 을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체를 제공하는 데 있다. 본 발명이 해결하고자 하는 과제는 이상에서 언급한 과제에 한정되지 않으며, 언급되지 않은 본 발명의 다른 과 제 및 장점들은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시 예에 의해보다 분명하게 이해될 것이다. 또한, 본 발명이 해결하고자 하는 과제 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 알 수 있을 것이다."}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 부스팅 알고리즘에 기초하여 이상치를 제거하는 방법에 있어서, 유전자형 정보(Genotype data) 및 표현형 정보(phenotype data)를 포함하는 데이터 세트(data set)에 기초하여, 제1 분류 모델을 학습하는 단계; 상기 학습에 기초하여, 질병에 관한 케이 스(Case)와 컨트롤(Control)의 분류를 수행하는 제2 분류 모델을 획득하는 단계; 상기 데이터 세트를 상기 제2 분류 모델에 입력하고, 상기 제2 분류 모델의 출력으로 분류 결과를 출력하는 단계; 및 상기 분류 결과에 기초 하여, 상기 데이터 세트의 이상치(outlier)를 제거하는 단계;를 포함하는, 방법을 제공할 수 있다. 본 개시의 제2 측면은, 적어도 하나의 메모리; 및 적어도 하나의 프로세서;를 포함하고, 상기 적어도 하나의 프 로세서는, 유전자형 정보(Genotype data) 및 표현형 정보(phenotype data)를 포함하는 데이터 세트(data set) 에 기초하여, 제1 분류 모델을 학습하고, 상기 학습에 기초하여, 질병에 관한 케이스(Case)와 컨트롤(Control) 의 분류를 수행하는 제2 분류 모델을 획득하고, 상기 데이터 세트를 상기 제2 분류 모델에 입력하고, 상기 제2 분류 모델의 출력으로 분류 결과를 출력하고, 상기 분류 결과에 기초하여, 상기 데이터 세트의 이상치(outlie r)를 제거하는, 장치를 제공할 수 있다. 본 개시의 제3 측면은, 제1 측면에 따른 방법을 컴퓨터에서 실행하기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체를 제공할 수 있다. 이 외에도, 본 발명을 구현하기 위한 다른 방법, 다른 시스템 및 상기 방법을 실행하기 위한 컴퓨터 프로그램이 저장된 컴퓨터로 판독 가능한 기록매체가 더 제공될 수 있다. 전술한 것 외의 다른 측면, 특징, 이점이 이하의 도면, 특허청구범위 및 발명의 상세한 설명으로부터 명확해질 것이다."}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 개시의 과제 해결 수단에 의하면, 본 개시에서는 유전자형 정보(Genotype data) 및 표현형 정보 (phenotype data)를 포함하는 데이터 세트(data set)에 기초하여, 제1 분류 모델을 학습하고, 상기 학습에 기초 하여, 질병에 관한 케이스(Case)와 컨트롤(Control)의 분류를 수행하는 제2 분류 모델을 획득하고, 상기 데이터 세트를 상기 제2 분류 모델에 입력하고, 상기 제2 분류 모델의 출력으로 분류 결과를 출력하고, 상기 분류 결과 에 기초하여, 상기 데이터 세트의 이상치(outlier)를 제거함으로써, 보다 정확하게 케이스와 컨트롤의 집단을 분류할 수 있다.또한, 본 개시에서는 분류된 케이스와 컨트롤의 데이터를 이용하여, 유의미한 전장 유전체 연관분석 연구의 결 과를 도출할 수 있다. 또한, 본 개시에서는 전장 유전체 연관분석 연구의 결과를 이용하여, PRS를 계산함으로써 보다 정확한 질병의 위험도를 예측할 수 있다."}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 다양한 실시예가 첨부된 도면과 연관되어 기재된다. 본 개시의 다양한 실시예는 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는바, 특정 실시예들이 도면에 예시되고 관련된 상세한 설명이 기 재되어 있다. 그러나 이는 본 개시의 다양한 실시예를 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 개 시의 다양한 실시예의 사상 및 기술 범위에 포함되는 모든 변경 및/또는 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용되었다. 본 개시의 다양한 실시예에서 사용될 수 있는 \"포함한다.\" 또는 \"포함할 수 있다.\" 등의 표현은 개시 (disclosure)된 해당 기능, 동작 또는 구성요소 등의 존재를 가리키며, 추가적인 하나 이상의 기능, 동작 또는 구성요소 등을 제한하지 않는다. 또한, 본 개시의 다양한 실시예에서, \"포함하다.\" 또는 \"가지다.\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것 이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존 재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 다양한 실시예에서 \"또는\" 등의 표현은 함께 나열된 단어들의 어떠한, 그리고 모든 조합을 포함한다. 예를 들어, \"A 또는 B\"는, A를 포함할 수도, B를 포함할 수도, 또는 A 와 B 모두를 포함할 수도 있다. 본 개시의 다양한 실시예에서 사용된 \"제1\", \"제2\", \"첫째\", 또는 \"둘째\" 등의 표현들은 다양한 실시예들의 다 양한 구성요소들을 수식할 수 있지만, 해당 구성요소들을 한정하지 않는다. 예를 들어, 상기 표현들은 해당 구 성요소들의 순서 및/또는 중요도 등을 한정하지 않는다. 상기 표현들은 한 구성요소를 다른 구성요소와 구분하 기 위해 사용될 수 있다. 예를 들어, 제1 사용자 기기와 제2 사용자 기기는 모두 사용자 기기이며, 서로 다른사용자 기기를 나타낸다. 예를 들어, 본 개시의 다양한 실시예의 권리 범위를 벗어나지 않으면서 제1 구성요소 는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 본 개시의 실시 예에서 \"모듈\", \"유닛\", \"부(part)\" 등과 같은 용어는 적어도 하나의 기능이나 동작을 수행하는 구성요소를 지칭하기 위한 용어이며, 이러한 구성요소는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\", \"유닛\", \"부(part)\" 등은 각각이 개별적인 특정 한 하드웨어로 구현될 필요가 있는 경우를 제외하고는, 적어도 하나의 모듈이나 칩으로 일체화되어 적어도 하나 의 프로세서로 구현될 수 있다. 본 개시의 다양한 실시예에서 사용한 용어는 단지 특정일 실시예를 설명하기 위해 사용된 것으로, 본 개시의 다 양한 실시예를 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현 을 포함한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 개시의 다양한 실시예가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 개시의 다양한 실시예에서 명백하게 정의되지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하에서, 첨부된 도면을 이용하여 본 발명의 다양한 실시 예들에 대하여 구체적으로 설명한다. 도 1은 일 실시예에 따른 부스팅 알고리즘에 기초하여 이상치를 제거하는 시스템의 일 예를 설명하기 위한 도면 이다. 도 1을 참조하면, 시스템은 사용자 단말 및 서버를 포함한다. 예를 들어, 사용자 단말과 서버 는 유선 또는 무선 통신 방식으로 연결되어 상호 간에 데이터(예를 들어, 유전자형 정보(Genotype data), 표현형 정보(phenotype data), 데이터 세트(data set) 등)를 송수신할 수 있다. 설명의 편의를 위하여, 도 1에는 시스템에 사용자 단말 및 서버가 포함되는 것으로 도시하였으나, 이에 한정되지 않는다. 예를 들어, 시스템에는 다른 외부 디바이스(미도시)가 포함될 수 있으며, 이하에서 설명될 사용자 단말 및 서버의 동작이 단일 디바이스(예를 들어, 사용자 단말 또는 서버) 또는 다수의 디바이스들에 의하여 구현될 수도 있다. 사용자 단말은 디스플레이 장치 및 사용자 입력을 수신하는 장치(예를 들어, 키보드, 마우스 등)를 구비하 고, 메모리와 프로세서를 포함하는 컴퓨팅 장치일 수 있다. 예를 들어, 디스플레이 장치는 터치 스크린으로 구 현되어 사용자 입력을 수신할 수 있다. 예를 들어, 사용자 단말은 노트북(notebook) PC, 데스크탑(desktop) PC, 랩탑(laptop), 테블릿 컴퓨터(tablet computer), 스마트 폰 등이 해당될 수 있으나, 이에 한정되지 않는다. 서버는 사용자 단말을 포함하여 외부 디바이스(미도시)와 통신하는 장치일 수 있다. 일 예로서, 서버 는 유전자형 정보, 표현형 정보 및 데이터 세트를 저장하는 장치일 수 있다. 또는, 서버는 메모리와 프로세서를 포함하고, 자체적인 연산 능력을 갖춘 컴퓨팅 장치일 수 있다. 일 예로 서, 서버는 도 1 내지 도 9를 참조하여 후술할 사용자 단말의 동작들 중 적어도 일부를 수행할 수 있다. 예를 들어, 서버는 클라우드(cloud) 서버일 수도 있으나, 이에 한정되지 않는다. 사용자 단말은 부스팅 알고리즘에 기초하여 유전자형 정보 및 표현형정보를 포함하는 데이터 세트의 이상치 를 제거할 수 있다. 예를 들어, 사용자 단말은 유전자형 정보(Genotype data) 및 표현형 정보(phenotype data)를 포함하는 데이터 세트(data set)에 기초하여, 제1 분류 모델을 학습할 수 있다. 그리고, 사용자 단말 은 학습에 기초하여, 질병에 관한 케이스(Case)와 컨트롤(Control)의 분류를 수행하는 제2 분류 모델을 획 득할 수 있다. 그리고, 사용자 단말은 데이터 세트를 제2 분류 모델에 입력하고, 제2 분류 모델의 출력으로 분류 결과를 출력할 수 있다. 그리고, 사용자 단말은 분류 결과에 기초하여, 상기 데이터 세트의 이상치 (outlier)를 제거할 수 있다. 유전자형 정보는, DNA가 지니는 유전 정보에 의하여 결정되는 형질에 관한 정보를 의미한다. 유전자형 정보는 세포, 생물, 개체 등에서 발현된 유전적 특성을 포함할 수 있다. 예를 들어, 일 실시예에 따른 유전자형 정보는, 다수의 사람들에 대한 유전자형에 관한 정보를 포함할 수 있다.표현형 정보는, 생명체가 유전적인 정보를 이용하여, 세포, 조직 및 개체에 단백질과 당을 통해 생산한 기능적 형질에 관한 정보를 의미한다. 표현형 정보는 생물의 외형에서 드러나는 물리적 특성, 행동에 관한 특성 등을 포함할 수 있다. 예를 들어, 일실시예에 따른 표현형 정보는, 다수의 사람들에 대한 표현형에 관한 정보를 포함 할 수 있다. 데이터 세트는, 유전자형 정보와 표현정 정보를 포함한 세트를 의미한다. 데이터 세트는 트레이닝 세트 (Training Set), 밸리데이션 세트(Validation Set) 및 테스트 세트(Test Set)를 포함할 수 있다. 예를 들어, 사용자 단말는 트레이닝 세트를 이용하여 제1 분류 모델을 학습할 수 있다. 그리고, 사용자 단말는 밸 리데이션 세트를 이용하여 제2 분류 모델을 결정할 수 있다. 그리고, 사용자 단말은 테스트 세트를 이용하 여 질병을 예측할 수 있다. 제1 분류 모델은, 부스팅 알고리즘에 기초하여 학습되는 복수의 약한 분류기들을 포함할 수 있다. 제1 분류 모 델에 포함된 복수의 약한 분류기들은 유전자형 정보 및 표현형 정보를 포함하는 데이터 세트를 이용하여 순차적 으로 학습될 수 있다. 예를 들어, 제1 분류 모델은 1차부터 n차의 순서를 가지는 n개의 약한 분류기들을 포함할 수 있다. 여기에서 약한 분류기들은, 데이터 세트를 1차 약한 분류기부터 입력함으로써 출력되는 예측 값과 정 답 값의 차이를 도출하고, 도출된 차이에 기초하여 그 다음 순차 약한 분류기를 업데이트(예를 들어, 다음 순차 약한 분류기의 가중치를 업데이트)하여 학습될 수 있다. 제2 분류 모델은, 제1 분류 모델의 학습된 결과물로서, 제1 분류 모델에 비해 분류의 정확도가 높은 모델을 의 미한다. 즉, 제1 분류 모델이 학습됨에 따라 획득되는 분류 모델일 수 있다. 예를 들어, 사용자 단말은 제1 분류 모델에 포함된 약한 분류기들을 순차적으로 학습하고, 밸리데이션 세트에 기초하여 정확도가 기 설정된 값 이상인 약한 분류기를 제2 분류 모델로 결정할 수 있다. 이상치는, 유전체 연관분석 연구를 수행함에 있어서 정교하지 못한 베타 값(예를 들면, 연관성(Association)의 정도)이나 적절하지 않은 p-value를 도출시키는 유전자형 정보 및 표현형 정보를 의미한다. 예를 들어, 이상치 는 질병에 대한 유전적 위험도가 낮음에도 불구하고 다른 이유(예를 들면, 질병을 일으키는 병인이 여러가지인 경우, 운동 부족 등의 환경적 요인이 나쁜 경우, Monogenic Variant 등과 같이 GWAS에서 다루지 않는 변수로 인 한 경우 등)에 의하여 케이스로 분류된 것을 포함할 수 있다. 또한, 이상치는 질병에 대한 유전적 위험도가 높 음에도 불구하고 다른 이유(예를 들면, 나이가 상대적으로 적은 경우, 건강한 식습관 등의 환경적 요인이 좋은 경우, Monogenic Variant가 질병의 주요 원인인 경우, 유전적 영향도가 낮은 질병인 경우 등)에 의하여 컨트롤 로 분류된 것을 포함할 수 있다. 한편, 사용자 단말은 이상치가 제거된 데이터 세트에 기초하여, 전장 유전체 연관분석 연구(Genome-Wide Association Study, GWAS)를 수행할 수 있다. 한편, 사용자 단말은 전장 유전체 연관분석 연구의 결과에 기초하여 질병을 예측할 수 있다. 예를 들어, 사 용자 단말은 전장 유전체 연관분석 연구의 결과에 기초하여, 다유전자 위험점수(Polygenic risk score, PRS)를 산출할 수 있다. 그리고, 사용자 단말은 다유전자 위험 점수에 기초하여, 질병을 예측할 수 있다. 한편, 설명의 편의를 위하여, 명세서의 전반에 걸쳐 사용자 단말이 유전자형 정보(Genotype data) 및 표현 형 정보(phenotype data)를 포함하는 데이터 세트(data set)에 기초하여, 제1 분류 모델을 학습하고, 학습에 기 초하여, 질병에 관한 케이스(Case)와 컨트롤(Control)의 분류를 수행하는 제2 분류 모델을 획득하고, 데이터 세 트를 제2 분류 모델에 입력하고, 제2 분류 모델의 출력으로 분류 결과를 출력하고, 분류 결과에 기초하여, 데이 터 세트의 이상치(outlier)를 제거하는 것으로 설명하였으나, 이에 한정되지 않는다. 예를 들어, 사용자 단말 에 의하여 수행되는 동작들의 적어도 일부는 서버에 의하여 수행될 수 있다. 다시 말해, 이하에서 도 1 내지 도 9를 참조하여 설명되는 사용자 단말의 동작들 중 적어도 일부는 서버 에 의하여 수행될 수 있다. 예를 들어, 서버는 유전자형 정보(Genotype data) 및 표현형 정보 (phenotype data)를 포함하는 데이터 세트(data set)에 기초하여, 제1 분류 모델을 학습하고, 학습에 기초하여, 질병에 관한 케이스(Case)와 컨트롤(Control)의 분류를 수행하는 제2 분류 모델을 획득하고, 데이터 세트를 상 기 제2 분류 모델에 입력하고, 제2 분류 모델의 출력으로 분류 결과를 출력하고, 분류 결과에 기초하여, 데이터 세트의 이상치(outlier)를 제거할 수 있다. 그리고, 서버는 이상치가 제거된 데이터 세트에 기초하여, 전장 유전체 연관분석 연구(Genome-Wide Association Study, GWAS)를 수행할 수 있다. 그리고, 서버는 전장 유 전체 연관분석 연구의 결과에 기초하여, 질병을 예측할 수 있다. 도 2a는 일 실시예에 따른 사용자 단말의 일 예를 도시한 구성도이다. 도 2a를 참조하면, 사용자 단말은 프로세서, 메모리, 입출력 인터페이스 및 통신 모듈 을 포함한다. 설명의 편의를 위하여, 도 2a에는 본 발명과 관련된 구성요소들 만이 도시되어 있다. 따라서, 도 2a에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 사용자 단말에 더 포함될 수 있다. 또한, 도 2a에 도시된 프로세서, 메모리, 입출력 인터페이스 및 통신 모듈은 독립된 장치 로 구현될 수도 있음은 본 발명과 관련된 기술 분야에서의 통상의 지식을 가진 자에게 자명하다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리할 수 있 다. 여기에서, 명령은 메모리 또는 외부 장치(예를 들어, 서버 등)로부터 제공될 수 있다. 또한, 프로 세서는 사용자 단말에 포함된 다른 구성요소들의 동작을 전반적으로 제어할 수 있다. 먼저, 프로세서는 유전자형 정보(Genotype data) 및 표현형 정보(phenotype data)를 포함하는 데이터 세 트(data set)에 기초하여, 제1 분류 모델을 학습한다. 예를 들면, 프로세서는 유전자형 정보 및 표현형 정 보를 포함하는 데이터 세트를 제1 분류 모델에 입력하고, 부스팅 알고리즘에 기초하여 제1 분류 모델을 학습할 수 있다. 그리고, 프로세서는 학습에 기초하여, 질병에 관한 케이스(Case)와 컨트롤(Control)의 분류를 수행하는 제 2 분류 모델을 획득한다. 제1 분류 모델 또한 질병에 관한 케이스 및 컨트롤의 분류를 수행할 수 있지만, 분류 의 정확도는 제2 분류 모델에 비해 낮을 수 있다. 프로세서는 학습을 통해 제1 분류 모델의 정확도를 증가 시키고, 제1 분류 모델의 정확도가 기 설정된 임계 값 이상인 경우 해당 제1 분류 모델의 학습을 중단하고 제2 분류 모델로 획득할 수 있다. 그리고, 프로세서는 데이터 세트를 제2 분류 모델에 입력하고, 제2 분류 모델의 출력으로 분류 결과를 출 력한다. 여기에서 출력되는 분류 결과는 케이스 및 컨트롤 중 하나일 수 있다. 여기에서, 제1 분류 모델 및 제2 분류 모델은, 입력된 데이터 세트를 이용하여 학습된 머신러닝 모델일 수 있다. 예를 들어, 제1 분류 모델 및 제2 분류 모델은 인공 신경망을 이용하는 딥러닝 모델일 수 있다. 머신러닝 모델은, 기계학습(Machine Learning) 기술과 인지과학에서 생물학적 신경망의 구조에 기초하여 구현된 통계학적 학습 알고리즘 또는 그 알고리즘을 실행하는 구조를 의미한다. 예를 들어, 머신러닝 모델은 생물학적 신경망 에서와 같이 시냅스의 결합으로 네트워크를 형성한 인공 뉴런인 노드(Node)들이 시냅스의 가중치를 반복적으로 조정하여, 특정 입력에 대응한 올바른 출력과 추론된 출력 사이 의 오차가 감소되도록 학습함으로써, 문제 해결 능력을 가지는 모델을 나타낼 수 있다. 예를 들어, 머신러닝 모 델은 기계학습, 딥러닝 등의 인공지능 학습법에 사용되는 임의의 확률 모델, 뉴럴 네트워크 모델 등을 포함할 수 있다. 예를 들어, 머신러닝 모델은 다층의 노드들과 이들 사이의 연결로 구성된 다층 퍼셉트론(MLP: multilayer perceptron)으로 구현될 수 있다. 본 발명의 일 실시예에 따른 머신러닝 모델은 MLP를 포함하는 다양한 인공신 경망 모델 구조들 중 하나를 이용하여 구현될 수 있다. 예를 들어, 머신러닝 모델은 외부로부터 입력 신호 또는 데이터를 수신하는 입력 레이어, 입력 데이터에 대응한 출력 신호 또는 데이터를 출력하는 출력 레이어, 입력 레이어와 출력 레이어 사이에 위치하며 입력 레이어로부터 신호를 받아 특성을 추출하여 출력 레이어로 전달하 는 하나 이상의 은닉 레이어로 구성될 수 있다. 출력 레이어는 은닉 레이어로부터 신호 또는 데이터를 수신하여 외부로 출력한다. 그리고, 프로세서는 분류 결과에 기초하여, 데이터 세트의 이상치(outlier)를 제거한다. 예를 들면, 프로 세서는 분류 결과와 정답 값의 차이에 기초하여 데이터 세트의 이상치를 결정하고, 데이터 세트의 이상치 를 데이터 세트로부터 제거할 수 있다. 즉, 프로세서는 학습된 모델인 제2 분류 모델의 예측 값과 정답 값의 차이가 생기는 경우, 해당 정답 값에 대응하는 데이터들을 이상치로 결정하여 데이터 세트로부터 해당 이상치를 제거할 수 있다. 학습된 모델인 제2 분류 모델의 예측 값은 정확도가 높은 것으로 신뢰할 수 있는 데이터에 해당한다. 그럼에도 불구하고, 제2 분류 모델의 예측 값과 정답 값의 차이가 기 설정된 임계 값 이상이라면, 해당 정답 값에 대응하는 데이터 세트의 값 들은 유전적 위험도가 낮음에도 다른 이유로 인해 케이스로 분류된 것이거나, 유전적 위험도가 높음에도 다른 이유로 인해 컨트롤로 분류된 것일 수 있다. 따라서, 프로세서는 제2 분류 모델의 예측 값과 정답 값의 차 이가 기 설정된 임계 값 이상인 경우에는 해당되는 정답 값의 샘플들(예를 들면, 데이터 세트에 포함된 유전형 정보 및 표현형 정보)를 이상치로 결정하고, 해당 이상치를 데이터 세트로부터 제거한다. 한편, 프로세서는 이상치가 제거된 데이터 세트에 기초하여, 전장 유전체 연관분석 연구(Genome-Wide Association Study, GWAS)를 수행할 수 있다. 이상치가 제거된 데이터 세트에 기초하여 전체 연관분석 연구를 수행하는 경우, 프로세서는 보다 유의미한 연구 결과를 도출할 수 있다. 한편, 프로세서는 전장 유전체 연관분석 연구의 결과에 기초하여, 다유전자 위험점수(Polygenic risk score, PRS)를 산출하고, 다유전자 위험 점수에 기초하여, 질병을 예측할 수 있다. 일 실시예에 따른 프로세서가 동작하는 구체적인 예들은 도 3 내지 도 9를 참조하여 설명한다. 프로세서는 다수의 논리 게이트들의 어레이로 구현될 수도 있고, 범용적인 마이크로 프로세서와 이 마이크 로 프로세서에서 실행될 수 있는 프로그램이 저장된 메모리의 조합으로 구현될 수도 있다. 예를 들어, 프로세서 는 범용 프로세서, 중앙 처리 장치(CPU), 마이크로프로세서, 디지털 신호 프로세서(DSP), 제어기, 마이크 로제어기, 상태 머신 등을 포함할 수 한다. 일부 환경에서, 프로세서는 주문형 반도체(ASIC), 프로그램 가 능 로직 디바이스(PLD), 필드 프로그램 가능 게이트 어레이(FPGA) 등을 포함할 수도 있다. 예를 들어, 프로세서 는 디지털 신호 프로세서(DSP)와 마이크로프로세서의 조합, 복수의 마이크로프로세서들의 조합, 디지털 신 호 프로세서(DSP) 코어와 결합된 하나 이상의 마이크로프로세서들의 조합, 또는 임의의 다른 그러한 구성들의 조합과 같은 처리 디바이스들의 조합을 지칭할 수도 있다. 메모리는 비-일시적인 임의의 컴퓨터 판독 가능한 기록매체를 포함할 수 있다. 일 예로서, 메모리는 RAM(random access memory), ROM(read only memory), 디스크 드라이브, SSD(solid state drive), 플래시 메모 리(flash memory) 등과 같은 비소멸성 대용량 저장 장치(permanent mass storage device)를 포함할 수 있다. 다른 예로서, ROM, SSD, 플래시 메모리, 디스크 드라이브 등과 같은 비소멸성 대용량 저장 장치는 메모리와는 구분되는 별도의 영구 저장 장치일 수 있다. 또한, 메모리에는 운영체제(OS)와 적어도 하나의 프로그램 코 드(예를 들어, 도 3 내지 도 9를 참조하여 후술할 동작을 프로세서가 수행하기 위한 코드)가 저장될 수 있 다. 이러한 소프트웨어 구성요소들은 메모리와는 별도의 컴퓨터에서 판독 가능한 기록매체로부터 로딩될 수 있 다. 이러한 별도의 컴퓨터에서 판독 가능한 기록매체는 사용자 단말에 직접 연결될 수 있는 기록 매체일 수 있고, 예를 들어, 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨터에서 판 독 가능한 기록매체를 포함할 수 있다. 또는, 소프트웨어 구성요소들은 컴퓨터에서 판독 가능한 기록매체가 아 닌 통신 모듈을 통해 메모리에 로딩될 수도 있다. 예를 들어, 적어도 하나의 프로그램은 개발자들 또 는 어플리케이션의 설치 파일을 배포하는 파일 배포 시스템이 통신 모듈을 통해 제공하는 파일들에 의해 설치되는 컴퓨터 프로그램(예를 들어, 도 3 내지 도 9를 참조하여 후술할 동작을 프로세서가 수행하기 위 한 컴퓨터 프로그램 등)에 기반하여 메모리에 로딩될 수 있다. 입출력 인터페이스는 사용자 단말과 연결되거나 사용자 단말에 포함될 수 있는 입력 또는 출력 을 위한 장치(예를 들어, 키보드, 마우스 등)와의 인터페이스를 위한 수단일 수 있다. 입출력 인터페이스 가 프로세서와 별도로 구성될 수 있으나, 이에 한정되지 않으며, 입출력 인터페이스가 프로세서(11 0)에 포함되도록 구성될 수도 있다. 통신 모듈은 네트워크를 통해 서버와 사용자 단말이 서로 통신하기 위한 구성 또는 기능을 제공 할 수 있다. 또한, 통신 모듈은 사용자 단말이 다른 외부 디바이스와 통신하기 위한 구성 또는 기능 을 제공할 수 있다. 예를 들어, 프로세서의 제어에 따라 제공되는 제어 신호, 명령, 데이터 등이 통신 모 듈과 네트워크를 거쳐 서버 및/또는 외부 디바이스로 전송될 수 있다. 한편, 도 2a에는 도시되지 않았으나, 사용자 단말은 디스플레이 장치를 더 포함할 수 있다. 예를 들어, 디 스플레이 장치는 터치 스크린으로 구현될 수도 있다. 또는, 사용자 단말은 독립적인 디스플레이 장치와 유 선 또는 무선 통신 방식으로 연결되어 상호 간에 데이터를 송수신할 수 있다. 예를 들어, 디스플레이 장치를 통 하여 질병에 관한 케이스(Case)와 컨트롤(Control)의 분류 결과, 전장 유전체 연관분석 연구의 결과, 다유전자 위험점수(Polygenic risk score, PRS), 예측된 질병 등이 제공될 수 있다. 도 2b는 일 실시예에 따른 서버의 일 예를 도시한 구성도이다. 도 2b를 참조하면, 서버는 프로세서, 메모리 및 통신 모듈을 포함한다. 설명의 편의를 위 하여, 도 2b에는 본 발명과 관련된 구성요소들만이 도시되어 있다. 따라서, 도 2b에 도시된 구성요소들 외에 다 른 범용적인 구성요소들이 서버에 더 포함될 수 있다. 또한 도 2b에 도시된 프로세서, 메모리및 통신 모듈은 독립된 장치로 구현될 수 있음은 본 발명과 관련된 기술 분야에서의 통상의 지식을 가진 자에게 자명하다. 프로세서는, 유전자형 정보(Genotype data) 및 표현형 정보(phenotype data)를 포함하는 데이터 세트 (data set)에 기초하여, 제1 분류 모델을 학습할 수 있다. 또한, 프로세서는, 학습에 기초하여, 질병에 관 한 케이스(Case)와 컨트롤(Control)의 분류를 수행하는 제2 분류 모델을 획득할 수 있다. 또한, 프로세서 는, 데이터 세트를 제2 분류 모델에 입력하고, 제2 분류 모델의 출력으로 분류 결과를 출력할 수 있다. 또한, 프로세서는, 분류 결과에 기초하여, 데이터 세트의 이상치(outlier)를 제거할 수 있다. 또한, 프로세서 는 이상치가 제거된 데이터 세트에 기초하여, 전장 유전체 연관분석 연구(Genome-Wide Association Study, GWAS)를 수행할 수 있다. 또한, 프로세서는 전장 유전체 연관분석 연구의 결과에 기초하여, 질병을 예측할 수 있다. 다시 말해, 도 2a를 참조하여 상술한 프로세서의 동작 중 적어도 하나가 프로세서에 의하여 수행될 수 있다. 이 경우, 사용자 단말은 서버로부터 전송된 정보를 디스플레이 장치를 통하여 출력할 수 있 다. 한편, 프로세서의 구현 예는 도 2a를 참조하여 상술한 프로세서의 구현 예와 동일하므로, 구체적인 설명은 생략한다. 메모리에는 프로세서의 동작에 필요한 데이터, 프로세서의 동작에 따라 생성된 데이터 등 다양 한 데이터가 저장될 수 있다. 또한, 메모리에는 운영체제(OS)와 적어도 하나의 프로그램(예를 들어, 프로 세서가 동작하는데 필요한 프로그램 등)이 저장될 수 있다. 한편, 메모리의 구현 예는 도 2a를 참조하여 상술한 메모리의 구현 예와 동일하므로, 구체적인 설명 은 생략한다. 통신 모듈은 네트워크를 통해 서버와 사용자 단말이 서로 통신하기 위한 구성 또는 기능을 제공 할 수 있다. 또한, 통신 모듈은 서버가 다른 외부 디바이스와 통신하기 위한 구성 도는 기능을 제공 할 수 있다. 예를 들어, 프로세서의 제어에 따라 제공되는 제어 신호, 명령, 데이터 등이 통신 모듈 과 네트워크를 거쳐 사용자 단말 및/또는 외부 디바이스로 전송될 수 있다. 도 3은 일 실시예에 따른 부스팅 알고리즘에 기초하여 이상치를 제거하는 방법의 일 예를 설명하기 위한 흐름도 이다. 도 3을 참조하면, 부스팅 알고리즘에 기초하여 이상치를 제거하는 방법은 도 1 및 도 2a에 도시된 사용자 단말 (10, 100) 또는 프로세서에서 시계열적으로 처리되는 단계들로 구성된다. 따라서, 이하에서 생략된 내용이 라고 하더라도 도 1 및 도 2a에 도시된 사용자 단말(10, 100) 또는 프로세서에 관하여 이상에서 기술된 내 용은 도 3의 부스팅 알고리즘에 기초하여 이상치를 제거하는 방법에도 적용될 수 있다. 또한, 도 1 및 도 2b를 참조하여 상술한 바와 같이, 도 3의 부스팅 알고리즘에 기초하여 이상치를 제거하는 방 법의 단계들 중 적어도 하나는 서버(20, 200) 또는 프로세서에서 처리될 수 있다. S310 단계에서, 프로세서는 유전자형 정보(Genotype data) 및 표현형 정보(phenotype data)를 포함하는 데이터 세트(data set)에 기초하여, 제1 분류 모델을 학습한다. 한편, 프로세서는 부스팅 알고리즘에 기초하여 제1 분류 모델을 학습할 수 있다. 부스팅 알고리즘은, AdaBoost(Adaptive Boost), GBM(Gradient Boosting Machine), XGBoost, LightGBM 및 CatBoost 중 적어도 하나 를 포함할 수 있다. 일 예로서, 프로세서는 AdaBoost 알고리즘에 기초하여 제1 분류 모델을 학습할 수 있 다. 다른 예로서, 프로세서는 GBM 알고리즘에 기초하여 제1 분류 모델을 학습할 수 있다. 또 다른 예로서, 프로세서는 XGBoost 알고리즘에 기초하여 제1 분류 모델을 학습할 수 있다. 다만, 제1 분류 모델을 학습하 는 예들은 상술한 바에 한정되지 않는다. 한편, 제1 분류 모델은 Decision Tree를 기반으로 하는 기계학습 알고리즘에 기초하여 학습될 수 있다. Decision Tree는 엔트로피(Entropy)와 같은 정보량을 기준으로 분류에 필요한 기준치를 생성하고, 생성된 기준 치를 기준으로 구획을 나눔으로써 여러 개의 구획을 학습하여 데이터를 예측하는 알고리즘을 포함한다. 한편, 제1 분류 모델은 복수의 약한 분류기들(weak classifiers)을 포함할 수 있다. 약한 분류기들은 제2 분류 모델에 비해 분류의 정확도가 낮은 복수의 모델들로서, 부스팅 알고리즘을 통해 순차적으로 학습되어 분류의 정확도를 개선해나가는 특징을 가진다. 예를 들어, 제1 분류 모델은 1차부터 n차의 순서를 가지는 n 개의 약한 분 류기들을 포함할 수 있다. 프로세서는 Decision Tree를 기반으로 하는 약한 분류기들을 학습하고, 약한 분 류기의 출력인 예측 값과 정답 값의 비교를 통해 오차를 가지는 데이터에 더 높은 가중치를 부여함으로써 약한 분류기들을 업데이트할 수 있다. 프로세서는 이러한 업데이트를 반복하여 오차를 줄여나가면서 보다 정확 한 분류의 결과를 도출하는 모델을 획득할 수 있다. 한편, 프로세서는 데이터 세트에 기초하여, 복수의 약한 분류기들을 순차적으로 학습할 수 있다. 여기에서, 복수의 약한 분류기들은 Decision Tree를 통해 학습하는 모델들일 수 있다. 예를 들어, 프로세서 는 1차부터 n차의 순서를 가지는 n 개의 약한 분류기들에 대하여, 데이터 세트를 1차 약한 분류기에 입력 하여 1차 예측 값을 출력하고, 출력된 1차 예측 값과 정답 값의 차이에 기초하여 2차 약한 분류기를 업데이트할 수 있다. 프로세서는 2차 약한 분류기를 업데이트 함에 있어서, 2차 약한 분류기에 포함된 가중치를 업데 이트할 수 있으며, 가중치는 정답 값과의 차이가 기 설정된 임계 값 이상인 해당 데이터에 대한 가중치일 수 있 다. S320 단계에서, 프로세서는 학습에 기초하여, 질병에 관한 케이스(Case)와 컨트롤(Control)의 분류를 수행 하는 제2 분류 모델을 획득한다. 프로세서는 제1 분류 모델을 학습함으로써, 보다 분류의 정확도가 높은 제2 분류 모델을 획득할 수 있다. 한편, 프로세서는 데이터 세트를 n 차 약한 분류기에 입력하고, n 차 약한 분류기의 출력으로 케이스 및 컨트롤에 대한 n 차 예측 값을 출력할 수 있다. 그리고, 프로세서는 n차 예측 값과 케이스 및 컨트롤에 대 한 분류의 정답 값을 비교하여, n차 약한 분류기를 제2 분류 모델로 결정할 수 있다. 프로세서는 n차 예측 값과 정답 값의 차이가 기 설정된 임계 값 미만인 경우, n차 약한 분류기를 제2 분류 모델로 결정할 수 있다. 다만, 제2 분류 모델을 획득하는 예들은 상술한 바에 한정되지 않는다. 한편, 프로세서는 AdaBoost 알고리즘에 기초하여 제1 분류 모델에 포함된 약한 분류기들을 학습함으로써, 제2 분류 모델을 획득할 수 있다. 예를 들면, 프로세서는 아래의 수학식 1 내지 수학식 3에 따라 Error 값 을 계산하고, alpha로 정의되는 coefficient 값을 통해 Sampel Weight를 업데이트함으로써 약한 분류기들을 학 습할 수 있다. 수학식 1"}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 2"}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 3"}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "먼저, 프로세서는 수학식 1에 따라, j번째 트레이닝 세트에 대한 가중치, j번째 트레이닝 세트에 대한 제 1 분류 모델의 출력에 대한 에러 값(Error)을 산출할 수 있다. 여기에서, i는 약한 분류기들의 인덱스를 의미한 다. 여기에서, n은 트레이닝 샘플의 총 수를 의미한다. 여기에서, Xj는 j번째 트레이닝 세트(유전자형 정보 및 표현형 정보)의 입력 값을 의미한다. 여기에서 Ci(Xj)는 i번째 여기에서, Yj는 j번째 트레이닝 세트의 분류 결과에 관한 정답 값을 의미한다. 여기에서 Wj는 j번째 트레이닝 세트에 대한 가중치를 의미한다. 여기에서, I(x)는 입력된 값이 참인지 거짓인지에 따라 1 또는 0을 출력하는 함수이며, 프로세서는 Wj, Ci(Xj), Yj에 기초하여 i번 째 약한 분류기의 에러 값(Errori)을 산출할 수 있다. 그리고, 프로세서는 수학식 2에 따라, 산출된 에러 값(Errori)을 이용하여, alpha로 정의되는 coefficient 값(αi)을 산출할 수 있다. 그리고, 프로세서는 수학식 3에 따라, 산출된 coefficient 값(αi)을 이용하여, Wj를 업데이트할 수 있다. 한편, 프로세서는 GBM 알고리즘에 기초하여 하기의 수학식 4 내지 수학식 7에 따라 제1 분류 모델에 포함 된 약한 분류기들을 학습함으로써, 제2 분류 모델을 획득할 수 있다. 수학식 4"}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 5"}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 6"}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 7"}
{"patent_id": "10-2023-0140801", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "먼저, 프로세서는 수학식 4에 기초하여 초기 예측 값(F0(x))을 설정할 수 있다. 여기에서, m은 약한 분류 기들의 인덱스이고, n은 데이터 샘플의 인덱스를 의미한다. 여기에서, F0(x)은 프로세서에 의해 설정된 초 기 예측 값이고, Fm(x)은 m번째 약한 분류기의 예측 값을 의미한다. 여기에서, yi는 i번째 입력 데이터(유전자형 정보 및 표현형 정보를 포함하는 데이터 세트)에 대한 분류 결과의 정답 값을 의미한다. 여기에서, 는 손실 함수로, 손실 함수는 Mean Squreared Error에 관한 함수일 수 있다. 예를 들면, 손실 함 수 L은 와 같이 정의될 수 있다. 이 경우, F0(x)는 주어진 타겟 y 값을 기준으로손실이 제일 작아지는 γ 값을 의미한다. 그리고, 프로세서는 수학식 5에 따라 Residual( ) 값을 산출할 수 있다. 한편, 프로세서는 수학식 6에 따라 Residual 값을 추정하도록 약한 분류기들(hm)을 학습할 수 있다. 프로 세서는 약한 분류기들(hm)을 학습함에 있어서, 트레이닝 세트인 을 이용하여 약한 분류기들(hm)을 학습할 수 있으며, 약한 분류기들의 분류 결과에 대한 정확도 향상을 위해 적절한 계수 값을 추정할 수 있다. 그리고, 프로세서는 수학식 7에 따라, 약한 분류기들(hm)을 업데이트할 수 있다. 즉, 프로세서는 제1 분류 모델에 포함되는 약한 분류기들을 계속 생성하여 강한 분류기인 제2 분류 모델을 구축할 수 있다. 이때, 손실 함수를 이용하여 손실 값을 줄여나가는 방향으로 제2 분류 모델을 구축할 수 있다. 여기에서 약한 분류기들은 Decision Tree를 기반으로 할 수 있으며, 약한 분류기에 Residual을 기반으로 추가적 인 약한 분류기를 더함으로써 부스팅 알고리즘을 수행할 수 있다. 이하 도 4를 참조하여, 부스팅 알고리즘에 기초하여 제1 분류 모델을 학습하는 일 예를 설명한다. 도 4는 일 실시예에 따른 프로세서가 부스팅 알고리즘에 기초하여 제1 분류 모델을 학습하는 일 예를 설명하기 위한 도면이다. 도 4를 참조하면, 프로세서는 제1 분류 모델에 포함된 약한 분류기들(41, 42, 43, 44)을 순차적으로 학습 한다. 프로세서는 1차 약한 분류기에 입력 데이터(x, y)을 입력하고 분류의 결과인 1차 예측 값을 출 력한다. 그리고, 프로세서는 출력된 1차 예측 값을 이용하여, 1차 Residual 값을 산출한다. 그리고, 프로 세서는 산출된 1차 Residual 값에 기초하여, 2차 약한 분류기의 분류 결과인 2차 예측 값을 출력한다. 그리고, 다시 프로세서는 출력된 2차 예측 값을 이용하여, 2차 Residual 값을 산출한다. 그리고, 프로세서 는 산출된 2차 Residual 값에 기초하여, 3차 약한 분류기의 분류 결과인 3차 예측 값을 출력한다. 그 리고, 프로세서는 출력된 3차 예측 값에 기초하여 그다음 차수의 약한 분류기의 예측 값을 출력한다. 이렇 게 프로세서는 약한 분류기들의 학습을 순차적으로 진행하여 분류 결과의 정확도를 향상시킨다. 여기에서, 약한 분류기들은 Decision Tree를 기반으로 하는 모델들일 수 있으며, 이전 차수의 약한 분류기에서 분류의 결과를 맞추지 못한 에러 샘플(Error Sample)에 대해 더 높은 가중치를 부여하여, 다음 차수의 약한 분 류기를 통해 분류 결과의 정확도를 향상시킬 수 있다. 프로세서는 이러한 과정들을 반복 수행하여, 에러 샘플들을 줄여나감으로써 제2 분류 모델을 획득할 수 있다. 이하 도 5를 참조하여, 부스팅 알고리즘에 기초하여 제1 분류 모델을 학습하는 다른 예를 확인한다. 도 5는 일 실시예에 따른 프로세서가 부스팅 알고리즘에 기초하여 제1 분류 모델을 학습하는 다른 예를 설명하 기 위한 도면이다. 도 5를 참조하면, 제1 분류 모델에 포함된 약한 분류기의 예측 값(predicition, 52)과 분류 결과의 정답 값 (actual data, 51)이 다른 것을 확인할 수 있다. 프로세서는 이와 같은 경우, 맞추지 못한 에러 샘플의 샘 플 가중치(Sampel weight)를 조정할 수 있다. 학습을 통해 에러 샘플의 샘플 가중치를 조정한 경우, 프로세서는 제1 분류 모델에 포함된 약한 분류기의 예측 값(predicition, 54)을 출력하는 것을 확인할 수 있다. 이하 도 6을 참조하여, 부스팅 알고리즘에 기초하여 제1 분류 모델을 학습하는 또 다른 예를 확인한다. 도 6은 일 실시예에 따른 프로세서가 부스팅 알고리즘에 기초하여 제1 분류 모델을 학습하는 또 다른 예를 설명 하기 위한 도면이다. 도 6을 참조하면, 프로세서는 Ada Boost 알고리즘에 기초하여 제1 분류 모델에 포함된 약한 분류기들 (classifier 1, 2, 3, 4)을 학습한다. 프로세서는 데이터 세트의 분류 결과의 정답 값과 비교하여 순 차적으로 약한 분류기들(classifier 1, 2, 3, 4)를 학습함으로써, 1차 약한 분류기(classifier 1)을 통해 예측 한 결과, 2차 약한 분류기(classifier 2)을 통해 예측한 결과, 3차 약한 분류기(classifier 3)을 통해 예측한 결과 및 4차 약한 분류기(classifier 4)을 통해 예측한 결과를 획득한다. 그리고 프로세서(11 0)는, 약한 분류기들의 예측한 결과들(62, 63, 64, 65)를 종합하여 ensemble 모델인 제2 분류 모델을 획득할 수있다. 다시 도 3을 참조하면, S330 단계에서, 프로세서는 데이터 세트를 제2 분류 모델에 입력하고, 제2 분류 모 델의 출력으로 분류 결과를 출력한다. 이하 도 7을 참조하여, 제2 분류 모델의 일 예를 확인한다. 도 7은 일 실시예에 따른 제2 분류 모델의 일 예를 설명하기 위한 도면이다. 도 7을 참조하면, 프로세서는 유전자형 정보 및 표현형 정보를 포함하는 입력 데이터를 제2 분류 모델 에 입력하고, 제2 분류 모델로부터 입력 데이터에 대한 케이스 및 컨트롤의 분류 결과를 출력 할 수 있다. 이때 제2 분류 모델은 Decision Tree 모델을 포함할 수 있으며, 프로세서는 유전자형 정보 및 표현형 정보를 포함하는 입력 데이터를 Decision Tree 모델에 입력하고, Decision Tree 모델로부터 케이스 및 컨트롤의 분류 결과를 출력할 수 있다. 도 7에서 상술한 바에 따르면, 프로세서는 Decision Tree 모델을 포함하는 제2 분류 모델을 이용하여, 유 전자형 정보 및 표현 정보를 제2 분류 모델에 입력함으로써 케이스 및 컨트롤의 분류 결과를 출력할 수 있다. 다만, 제2 분류 모델의 예는 상술한 바에 한정되지 않는다. 다시 도 3을 참조하면, S340 단계에서, 프로세서는 분류 결과에 기초하여 데이터 세트의 이상치를 제거한 다. 예를 들면, 프로세서는 제2 분류 모델을 통해 출력한 분류 결과와 정답 값을 비교하여, 출력된 분류 결과와 정답 값이 상이한 정도가 기 설정된 임계 값 이상인 경우에는 해당 샘플을 이상치로 결정하고, 결정된 이상치를 데이터 세트로부터 제거할 수 있다. 이하 도 8을 참조하여, 전장 유전체 연관분석 연구를 수행하는 일 예를 설명한다. 도 8은 일 실시예에 따른 프로세서가 전장 유전체 연관분석 연구를 수행하는 일 예를 설명하기 위한 흐름도이다. 도 8을 참조하면, S810 단계 내지 S840 단계 각각은 도 3의 S310 단계 내지 S340 단계에 대응된다. 따라서, 이 하에서 S810 단계 내지 S840 단계 각각에 대해 중복되는 설명은 생략하도록 한다. S850 단계에서, 프로세서는 이상치가 제거된 데이터 세트에 기초하여, 전장 유전체 연관분석 연구를 수행 한다. 이상치가 제거된 데이터 세트에는 이상치가 포함되어 있지 않으므로, 프로세서는 보다 유의미한 전 장 유전체 연관분석 연구의 결과를 도출할 수 있다. 이하 도 9를 참조하여, 전장 유전체 연관 분석 연구의 결과에 기초하여 질병을 예측하는 일 예를 설명한다. 도 9는 일 실시예에 따른 프로세서가 전장 유전체 연관분석 연구의 결과에 기초하여 질병을 예측하는 일 예를 설명하기 위한 흐름도이다. 도 9을 참조하면, S910 단계 내지 S950 단계 각각은 도 8의 S810 단계 내지 S850 단계에 대응된다. 따라서, 이 하에서 S910 단계 내지 S950 단계 각각에 대해 중복되는 설명은 생략하도록 한다. S960 단계에서, 프로세서는 전장 유전체 연관분석 연구의 결과에 기초하여, 다유전자 위험점수(Polygenic risk score, PRS)를 산출한다. 예를 들면, 프로세서는 전장 유전체 연관분석 연구의 결과를 미리 학습된 PRS 모델에 입력하고, PRS 모델의 출력으로 다유전자 위험점수를 획득할 수 있다. PRS 모델은, 전장 유전체 연 관 분석 연구(GWAS)의 결과에서 발견된 변이들의 위험도를 합산하여 다유전자 위험점수를 출력할 수 있다. S970 단계에서, 프로세서는 다유전자 위험 점수에 기초하여 질병을 예측한다. 예를 들면, 프로세서는 다유전자 위험 점수가 기 설정된 임계 값 이상인 경우, 질병에 걸릴 확률이 높을 것으로 예측할 수 있다. 또한, 프로세서는 예측한 다유전자 위험 점수를 의료 종사자에게 제공하여, 임상적인 판단에 도움을 줄 수 있다. 상술한 바에 따르면, 프로세서는 유전자형 정보 및 표현형 정보를 포함하는 데이터 세트에 기초하여, 제1 분류 모델을 학습하여 제2 분류 모델을 획득하고, 획득된 제2 분류 모델을 이용하여 데이터 세트의 이상치를 제 거할 수 있다. 또한, 프로세서는 이상치가 제거된 데이터 세트를 이용하여 유의미한 결과를 도출하는 전장 유전체 연관분석 연구를 수행할 수 있고, 전장 유전체 연관 분석 연구의 결과에 기초하여 보다 정확한 질병 예 측 결과를 도출할 수 있다. 한편, 상술한 방법은 컴퓨터에서 실행될 수 있는 프로그램으로 작성 가능하고, 컴퓨터로 읽을 수 있는 기록매체 를 이용하여 상기 프로그램을 동작시키는 범용 디지털 컴퓨터에서 구현될 수 있다. 또한, 상술한 방법에서 사용 된 데이터의 구조는 컴퓨터로 읽을 수 있는 기록매체에 여러 수단을 통하여 기록될 수 있다. 상기 컴퓨터로 읽 을 수 있는 기록매체는 마그네틱 저장매체(예를 들면, 롬, 램, USB, 플로피 디스크, 하드 디스크 등), 광학적 판독 매체(예를 들면, 시디롬, 디브이디 등)와 같은 저장매체를 포함한다. 한편, 상술한 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽 을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들 간에 직접, 온라인으로 배포(예: 다운로드 또 는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플 리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장 되거나, 임시적으로 생성될 수 있다. 본 실시예와 관련된 기술 분야에서 통상의 지식을 가진 자는 상기된 기재의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있을 것이다. 그러므로 개시된 방법들은 한정적인 관점이 아니라 설명적인 관점에서 고려되어야 하며, 권리 범위는 전술한 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동등한 범위 내에 있는 모든 차이점을 포함하는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0140801", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 부스팅 알고리즘에 기초하여 이상치를 제거하는 시스템의 일 예를 설명하기 위한 도면 이다. 도 2a는 일 실시예에 따른 사용자 단말의 일 예를 도시한 구성도이다. 도 2b는 일 실시예에 따른 서버의 일 예를 도시한 구성도이다. 도 3은 일 실시예에 따른 프로세서가 부스팅 알고리즘에 기초하여 이상치를 제거하는 방법의 일 예를 설명하기 위한 흐름도이다. 도 4는 일 실시예에 따른 프로세서가 부스팅 알고리즘에 기초하여 제1 분류 모델을 학습하는 일 예를 설명하기 위한 도면이다. 도 5는 일 실시예에 따른 프로세서가 부스팅 알고리즘에 기초하여 제1 분류 모델을 학습하는 다른 예를 설명하 기 위한 도면이다. 도 6은 일 실시예에 따른 프로세서가 부스팅 알고리즘에 기초하여 제1 분류 모델을 학습하는 또 다른 예를 설명 하기 위한 도면이다. 도 7은 일 실시예에 따른 제2 분류 모델의 일 예를 설명하기 위한 도면이다. 도 8은 일 실시예에 따른 프로세서가 전장 유전체 연관분석 연구를 수행하는 일 예를 설명하기 위한 흐름도이다. 도 9는 일 실시예에 따른 프로세서가 전장 유전체 연관분석 연구의 결과에 기초하여 질병을 예측하는 일 예를 설명하기 위한 흐름도이다."}
