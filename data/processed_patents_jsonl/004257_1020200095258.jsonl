{"patent_id": "10-2020-0095258", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0015132", "출원번호": "10-2020-0095258", "발명의 명칭": "로봇 작업의 학습 방법 및 로봇 시스템", "출원인": "네이버랩스 주식회사", "발명자": "최근준"}}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "작업을 수행하도록 이루어지며, 상기 작업과 관련된 힘 정보를 검출하는 로봇 장치;상기 로봇 장치를 지도하도록 조작 가능하게 형성되며, 상기 로봇 장치에 대해 상기 작업에 대한 지도가 이루어지는 동안에 상기 힘 정보에 근거하여 햅틱 피드백을 출력하는 인터페이스 장치;상기 햅틱 피드백을 출력하는 상기 인터페이스 장치에 의해 상기 지도가 이루어지는 동안에, 상기 로봇 장치의작업환경과 관련된 제1정보와, 상기 로봇 장치의 구동상태와 관련된 제2정보를 센싱하는 센싱부; 및상기 로봇 장치가 상기 작업에 대한 자율 수행이 가능하도록, 상기 제1정보 및 제2정보를 이용하여, 상기 작업과 관련된 상기 로봇 장치의 동작을 학습하는 학습부를 포함하는 로봇 시스템."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 센싱부는 상기 인터페이스 장치에 의해 상기 지도가 이루어지는 동안에, 상기 로봇 장치에 가해지는 외력을 검출하고,상기 인터페이스 장치는 상기 외력에 근거하여 상기 햅틱 피드백을 출력하는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 힘 정보를 기반으로 상기 로봇 장치를 지도하도록 상기 햅틱 피드백은 상기 인터페이스 장치에서 상기 외력에 해당하는 힘을 사용자에게 전달하는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제1정보 및 제2정보는 상기 힘 정보를 기반으로 상기 로봇 장치를 지도함에 따라 상기 작업환경 및 상기구동상태가 변화되는 정보인 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 로봇 장치는,상기 인터페이스 장치로부터 상기 작업에 대한 지도 명령을 수신하는 하위 제어기;상기 하위 제어기에 의한 제어 하에 상기 지도 명령에 따른 구동을 수행하는 구동부;상기 하위 제어기를 제어하여 상기 구동부를 구동하는 상위 제어기를 포함하는 로봇 시스템."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 하위 제어기는, 상기 인터페이스 장치로부터 상기 지도 명령을 수신하여 상기 구동부를 제어하고, 상기 힘정보를 햅틱 정보로서 상기 인터페이스 장치로 전송하는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2022-0015132-3-제5항에 있어서,상기 학습부는 상기 제1정보 및 제2정보를 이용하여, 상기 작업에 대한 학습을 수행하여 상기 상위 제어기의 적어도 일부를 도출하는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 상위 제어기는, 상기 학습에 근거하여 상기 로봇 장치가 상기 작업을 자율 수행할 수 있도록 상기 하위 제어기에 대한 제어 명령을 생성하는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 상위 제어기는 상기 로봇 장치를 구동하도록 기설정된 제1제어부와, 상기 학습에 의하여 도출되어 상기 제1제어부와 연동하는 제2제어부를 구비하는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제5항에 있어서, 상기 제1정보 및 제2정보는 상기 지도 명령과 함께 시계열 데이터로 데이터베이스에 저장되며,상기 학습부는 상기 시계열 데이터를 이용하여 상기 상위 제어기를 도출하는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제5항에 있어서, 상기 구동부는 Quasi-Direct-Drive 방식으로 구동되는 모터를 구비하는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 센싱부는 상기 모터의 출력단에 걸리는 힘을 입력단의 전기 에너지로 감지함에 따라 상기 힘 정보를 검출하는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서, 상기 제1정보는 촬영 이미지, 오브젝트와의 거리, 작업환경의 온도 중 적어도 하나를 포함하고,상기 제2정보는 모터의 각도, 가속도 및 각속도, 모터에 인가되는 토크 또는 전류 중 적어도 하나를 포함하는로봇 시스템."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "인터페이스 장치를 통하여 작업에 대한 지도가 가능한 로봇 장치에 있어서,상기 로봇 장치는,인터페이스 장치로부터 상기 작업에 대한 지도 명령을 수신하는 제1 제어기;다관절을 구비하며, 상기 제1 제어기에 의한 제어 하에 상기 지도 명령에 따른 구동을 수행하는 구동부;상기 제1 제어기에 의한 제어 하에 상기 구동부가 구동되는 동안에, 상기 로봇 장치의 작업환경과 관련된 제1정보와, 상기 로봇 장치의 구동상태와 관련된 제2정보를 센싱하는 센싱부; 및상기 제1 제어기를 제어하여, 상기 구동부를 구동하는 제2 제어기를 포함하고,공개특허 10-2022-0015132-4-상기 로봇 장치는 상기 제1정보 및 제2정보를 이용하여, 상기 작업에 대한 학습을 수행하고,상기 제2 제어기는, 상기 학습에 근거하여 상기 로봇 장치가 상기 작업을 자율 수행할 수 있도록 상기 제1 제어기에 대한 제어 명령을 생성하는 것을 포함하는 것을 특징으로 하는 로봇 장치."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 제1 제어기는 상기 작업에 대한 지도 명령에 따라 상기 구동부를 제어하는 동안에, 상기 구동부의 외력을햅틱 정보로서 상기 인터페이스 장치로 전달하는 것을 특징으로 하는 로봇 장치."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 제1정보 및 제2정보는 상기 햅틱 정보를 기반으로 상기 로봇 장치를 지도함에 따라 상기 작업환경 및 상기구동상태가 변화되는 정보인 것을 특징으로 하는 로봇 장치."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서, 상기 제2 제어기의 적어도 일부는 상기 제1정보 및 제2정보를 이용하여, 상기 작업에 대한 학습을 수행함에 따라 도출되는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "로봇 작업의 학습 방법에 있어서,인터페이스 장치에 대한 외부조작에 근거하여, 로봇 작업에 대한 지도가 수행되는 단계;상기 인터페이스 장치가 로봇 장치에 상기 조작에 해당하는 구동명령을 전달하고, 상기 로봇 장치로부터 상기로봇 작업에서 발생하는 힘과 관련된 정보를 전송받아 햅틱 피드백을 출력하는 단계;상기 구동명령에 따라 상기 로봇 장치가 상기 로봇 작업을 수행하는 동안에, 상기 로봇 장치의 작업환경과 관련된 제1정보와, 상기 로봇 장치의 구동상태와 관련된 제2정보를 센싱하는 단계; 및상기 제1정보와 제2정보를 이용하여 상기 로봇 작업에 대한 학습을 수행하는 단계를 포함하는 로봇 작업의 학습방법."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 로봇 작업에 대한 학습을 통하여 상기 로봇 장치의 제어기의 적어도 일부가 도출되며, 상기 제어기를 통하여 상기 로봇 장치가 자율적으로 작업을 수행하는 단계를 더 포함하는 로봇 작업의 학습 방법."}
{"patent_id": "10-2020-0095258", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에 있어서, 상기 제어기는 상위 제어기 및 하위 제어기를 구비하고,상기 하위 제어기는 상기 지도가 수행되는 단계에서 상기 구동명령을 전달받아 상기 로봇 장치의 구동부를 제어하고, 상기 상위 제어기는 상기 자율적으로 작업을 수행하는 단계에서 상기 하위 제어기를 제어하며, 상기 로봇 작업에 대한 학습을 통하여 적어도 일부가 도출되는 것을 특징으로 하는 로봇 작업의 학습 방법."}
{"patent_id": "10-2020-0095258", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 로봇 작업의 학습 방법 및 로봇 시스템에 관한 것이다. 본 발명에 따른 로봇 시스템은, 작업을 수행하 도록 이루어지며, 상기 작업과 관련된 힘 정보를 검출하는 로봇 장치와, 상기 로봇 장치를 지도하도록 조작 가능 하게 형성되며, 상기 로봇 장치에 대해 상기 작업에 대한 지도가 이루어지는 동안에 상기 힘 정보에 근거하여 햅 틱 피드백을 출력하는 인터페이스 장치와, 상기 햅틱 피드백을 출력하는 상기 인터페이스 장치에 의해 상기 지도 가 이루어지는 동안에, 상기 로봇 장치의 작업환경과 관련된 제1정보와, 상기 로봇 장치의 구동상태와 관련된 제 2정보를 센싱하는 센싱부, 및 상기 로봇 장치가 상기 작업에 대한 자율 수행이 가능하도록, 상기 제1정보 및 제2 정보를 이용하여, 상기 작업과 관련된 상기 로봇 장치의 동작을 학습하는 학습부를 포함할 수 있다."}
{"patent_id": "10-2020-0095258", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 원격 조종장치를 이용하여 로봇 작업을 학습하는 방법과 및 그 시스템에 관한 것이다."}
{"patent_id": "10-2020-0095258", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전세계적으로 고령화가 진행되고 있으며, 그에 따라 노동인구 감소 및 인건비 상승과 같은 사회적인 문제가 대 두되고 있다. 이러한 문제로 인하여, 산업 전반적으로 자동화의 필요성이 증가하고 있으며, 그 해법으로서, 로 봇을 통한 자동화가 각광받고 있다. 이러한 추세에 맞추어, 최근에는 사회 곳곳에서 인력을 로봇으로 대체하려 는 움직임이 활발해지고 있다. 그러나, 전통적 제조 로봇 시장에서는 단순하고 반복적인 작업을 빠르고 정확하게 수행하는 데에만 로봇 기술이 집중되어 있어 전기전자, 물류 등 신규한 산업 분야에서 로봇을 이용한 자동화 수요에 대해 유연한 대처가 어려 운 실정이다. 예를 들어, 전기전자 부품의 제조는 공정의 표준화가 어렵고, 작업의 난이도가 매우 높으며, 생산 라인의 수명이 매우 짧아, 획일적인 작업을 반복적으로 수행하는 기존의 로봇 기술을 적용하기에 부적절하다. 또한, 물류 서비스 분야는 로봇의 작업을 정형화시킬 수 없으며, 다양한 상황에 대처가 필요하다. 예를 들어, 택배 서비스를 수행하는 로봇은 다양한 무게의 배송물품을 들어올려야 하며, 로봇은 배송물품의 무게에 따라 적 절한 제어를 수행해야 한다. 이와 같이, 서로 다른 작업의 형태는, 작업의 형태에 따라 서로 다른 “힘 정보” 가 요구되며, 로봇은 작업의 형태에 따라 서로 다른 힘 정보가 요구되는 다양한 작업을 수행해야 하는 어려움이 발생하게 된다. 또한, 가사 서비스 분야에서도 다양한 상황이 발생할 수 있으며, 이 경우에도 힘 정보가 필요하게 된다. 구체적 으로, 일상 생활 공간에서 수행되는 많은 작업들은 그 작업을 표현하기 위해서 힘과 관련한 정보가 필요할 수 있다. 예를 들어 '빵에 버터를 펴서 바르는 작업'을 수행하기 위하여 로봇이 버터를 디저트 나이프로 누르며 움 직여야 하는데, 그 누르는 '힘'에 따라서 '빵에 버터를 펴 바르는 작업'의 결과물이 달라지게 된다. 또한 버터 의 단단한 정도, 빵의 단단한 정도 등에 따라서 작업 결과가 달라질 수 있다. 또 다른 예로서, 로봇이 수행해야 할 작업을 표현하는 경우에도 힘 정보가 필요할 수 있다. 구체적으로, '책상 에 붙어 있는 스카치 테이프를 떼어내는 작업' 또는 '수건을 이용하여 책상 위의 얼룩을 지우는 작업' 등에서도 필요한 '힘'의 크기나 방향 등의 정보를 통하여 작업을 보다 정확하게 표현할 수 있게 된다.한편, 최근에는 로 봇에게 작업을 학습시키는 지능형 로봇기술이 크게 주목받고 있다. 현재 활발히 연구되고 있는 로봇에게 작업을 학습시키는 방법으로는, Teaching pendant, Kinesthetic teaching, Teleoperation 및 Hard coding 등이 있다. 하지만, 이러한 방법들은 힘 정보를 필요로 하는 작업을 로봇에게 학습시키기에는 부적절한 방법이다. 보다 구체적으로, Teaching pendant 방법은 위치와 자세의 정보를 저장하는 방식으로, 작업을 학습하는 방법에 대하여 기술하고 있으며, kinesthetic teaching 방법은 사람이 로봇을 직접 잡고 움직이기 때문에 로봇 입장에 서 사람으로부터 전달되어오는 힘이 교시를 위한 힘인지 아니면 작업에 필요한 힘인지를 구별하기가 어려운 문 제가 있다. Teleoperation의 경우 사람의 자세의 정보만이 로봇에게 전달되기 때문에 힘 정보를 작업에 담을 수가 없으며, hard coding의 경우 복잡한 작업에 대한 유연성이 떨어지며, 또한 모든 작업마다 프로그래밍을 해야 하는 문제 가 있다. 따라서, 이러한 문제를 해결할 수 있는 새로운 형태의 로봇 작업의 학습 방법과, 힘 정보를 필요로 하는 작업을 수행할 수 있는 로봇 시스템에 대한 니즈가 여전히 존재한다."}
{"patent_id": "10-2020-0095258", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은, 로봇이 다양하고 복잡한 작업을 효과적으로 학습하여 수행할 수 있는 새로운 학습 모델을 제공하는 것이다. 본 발명은, 힘 정보를 기반으로 로봇 작업을 학습시키는 방법 및 시스템을 제공하는 것이다. 보다 구체적으로, 본 발명은, 로봇 작업시에 발생하는 힘 정보에 기반하여 로봇 작업을 새롭게 정의할 수 있는 방법 및 시스템을 제공하는 것이다. 또한, 본 발명은 자유도가 높은 다관절 로봇에게 보다 효과적으로 학습을 수행하는 방법 및 시스템을 제공한다.본 발명은, 외부환경을 반영하여 작업이 자율 수행되도록, 로봇을 지도하는 사용자 의도를 반영할 수 있는 학습 방법 및 시스템을 제공하는 것이다. 나아가, 본 발명은 작업 지도시에 외부환경을 반영할 수 있는 방법과, 학습데이터를 효과적으로 획득할 수 있는 학습 방법 및 시스템을 제공하는 것이다. 또한, 본 발명은, 산업현장이나 서비스현장에서 변화된 작업환경에 따른 신규 작업지시를 편하게 하기위한 현장 기술을 제공하기 위한 것이다."}
{"patent_id": "10-2020-0095258", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "위에서 살펴본 과제를 해결하기 위하여, 본 발명에 따른 로봇 시스템은 힘을 전달하는 햅틱 조종장치를 이용하 여 전문가가 작업을 시연하고, 이를 학습하는 프로세스를 이용한다. 구체적으로, 상기 로봇 시스템은, 작업을 수행하도록 이루어지며, 상기 작업과 관련된 힘 정보를 검출하는 로봇 장치와, 상기 로봇 장치를 지도하도록 조작 가능하게 형성되며, 상기 로봇 장치에 대해 상기 작업에 대한 지도 가 이루어지는 동안에 상기 힘 정보에 근거하여 햅틱 피드백을 출력하는 인터페이스 장치와, 상기 햅틱 피드백 을 출력하는 상기 인터페이스 장치에 의해 상기 지도가 이루어지는 동안에, 상기 로봇 장치의 작업환경과 관련 된 제1정보와, 상기 로봇 장치의 구동상태와 관련된 제2정보를 센싱하는 센싱부, 및 상기 로봇 장치가 상기 작 업에 대한 자율 수행이 가능하도록, 상기 제1정보 및 제2정보를 이용하여, 상기 작업과 관련된 상기 로봇 장치 의 동작을 학습하는 학습부를 포함한다. 나아가, 본 발명에서, 상기 센싱부는 상기 인터페이스 장치에 의해 상기 지도가 이루어지는 동안에, 상기 로봇 장치에 가해지는 외력을 검출하고, 상기 인터페이스 장치는 상기 외력에 근거하여 상기 햅틱 피드백을 출력한다. 상기 힘 정보를 기반으로 상기 로봇 장치를 지도하도록 상기 햅틱 피드백은 상기 인터페이스 장치에서 상기 외 력에 해당하는 힘을 사용자에게 전달한다. 이 경우에, 상기 제1정보 및 제2정보는 상기 힘 정보를 기반으로 상 기 로봇 장치를 지도함에 따라 상기 작업환경 및 상기 구동상태가 변화되는 정보가 될 수 있다. 본 발명에 따른 로봇 시스템에서, 상기 로봇 장치는, 상기 인터페이스 장치로부터 상기 작업에 대한 지도 명령 을 수신하는 하위 제어기와, 상기 하위 제어기에 의한 제어 하에 상기 지도 명령에 따른 구동을 수행하는 구동 부와, 상기 하위 제어기를 제어하여 상기 구동부를 구동하는 상위 제어기를 포함할 수 있다. 상기 하위 제어기는, 상기 인터페이스 장치로부터 상기 지도 명령을 수신하여 상기 구동부를 제어하고, 상기 힘 정보를 햅틱 정보로서 상기 인터페이스 장치로 전송한다. 상기 학습부는 상기 제1정보 및 제2정보를 이용하여, 상기 작업에 대한 학습을 수행하여 상기 상위 제어기의 적 어도 일부를 도출한다. 이 경우에, 상기 상위 제어기는, 상기 학습에 근거하여 상기 로봇 장치가 상기 작업을 자율 수행할 수 있도록 상기 하위 제어기에 대한 제어 명령을 생성할 수 있다. 또한, 상기 상위 제어기는 상기 로봇 장치를 구동하도록 기설정된 제1제어부와, 상기 학습에 의하여 도출되어 상기 제1제어부와 연동하는 제2제 어부를 구비할 수 있다. 나아가, 본 발명에 따른 로봇 시스템에서, 상기 제1정보 및 제2정보는 상기 지도 명령과 함께 시계열 데이터로 데이터베이스에 저장되며, 상기 학습부는 상기 시계열 데이터를 이용하여 상기 상위 제어기를 도출한다. 상기 구동부는 Quasi-Direct-Drive 방식으로 구동되는 모터를 구비할 수 있다. 또한, 상기 센싱부는 상기 모터 의 출력단에 걸리는 힘을 입력단의 전기 에너지로 감지함에 따라 상기 힘 정보를 검출할 수 있다. 한편, 본 발명에 따른 인터페이스 장치를 통하여 작업에 대한 지도가 가능한 로봇 장치는, 하나의 제어기를 통 하여 작업에 대한 지도가 수행되는 동안에 학습 데이터를 획득하여 다른 제어기를 학습한다.구체적으로, 상기 로봇 장치는, 인터페이스 장치로부터 상기 작업에 대한 지도 명령을 수신하는 제1 제어기와, 다관절을 구비하며, 상기 제1 제어기에 의한 제어 하에 상기 지도 명령에 따른 구동을 수행하는 구동부와, 상기 제1 제어 기에 의한 제어 하에 상기 구동부가 구동되는 동안에, 상기 로봇 장치의 작업환경과 관련된 제1정보와, 상기 로 봇 장치의 구동상태와 관련된 제2정보를 센싱하는 센싱부, 및 상기 제1 제어기를 제어하여, 상기 구동부를 구동 하는 제2 제어기를 포함한다. 이 때에, 상기 로봇 장치는 상기 제1정보 및 제2정보를 이용하여, 상기 작업에 대 한 학습을 수행하고, 상기 제2 제어기는, 상기 학습에 근거하여 상기 로봇 장치가 상기 작업을 자율 수행할 수 있도록 상기 제1 제어기에 대한 제어 명령을 생성한다.또한, 본 발명은 로봇 작업의 학습 방법을 제시한다. 상기 로봇 작업의 학습 방법은, 인터페이스 장치에 대한 외부조작에 근거하여, 로봇 작업에 대한 지도가 수행되는 단계와, 상기 인터페이스 장치가 로봇 장치에 상기 조 작에 해당하는 구동명령을 전달하고, 상기 로봇 장치로부터 상기 로봇 작업에서 발생하는 힘과 관련된 정보를 전송받아 햅틱 피드백을 출력하는 단계와, 상기 구동명령에 따라 상기 로봇 장치가 상기 로봇 작업을 수행하는 동안에, 상기 로봇 장치의 작업환경과 관련된 제1정보와, 상기 로봇 장치의 구동상태와 관련된 제2정보를 센싱 하는 단계, 및 상기 제1정보와 제2정보를 이용하여 상기 로봇 작업에 대한 학습을 수행하는 단계를 포함한다."}
{"patent_id": "10-2020-0095258", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 로봇 작업의 학습 방법 및 로봇 시스템은, 로봇과 외부의 환경 사이의 힘에 대한 정보를 기반으 로 로봇 작업을 정의하여, 로봇이 다양하고 복잡한 작업을 용이하게 학습하도록 한다. 구체적으로, 본 발명은 작업환경의 변화에 보다 유연하게 대처할 수 있는 학습 방법을 구현할 수 있다. 자세와 위치에 대한 정보를 이용하는 로봇 작업에 대한 정의는 외부 환경이 변화하면 새로운 모델링을 도출해야 만 하는 문제가 있으나, 본 발명에서는 힘을 고려한 새로운 형태로 로봇 작업을 정의함에 따라, 이러한 문제를 해소할 수 있게 된다. 또한, 본 발명은, 햅틱 기능을 갖춘 인터페이스 장치를 이용함에 따라, 전문가가 실제 환경에서 로봇에 가해지 는 힘을 피드백 받으면서 로봇 지도를 수행하게 된다. 즉, 다양한 환경에서 힘을 기반으로 한 작업에 대한 지도 가 수행될 수 있다. 이 경우에, 본 발명은 로봇에서 실제 환경에서 작업에 필요한 정보들을 획득하고, 이를 학 습에 활용하며, 따라서 힘 정보를 필요로 하는 작업을 로봇에게 학습시킬 수 있게 된다. 이 경우에, 본 발명은 사람의 physical intelligence 를 로봇의 언어(제1정보, 제2정보)로 변환하여 학습할 수 있으며, 작업 환경 (제1정보)에 따라 사람이 어떻게 행동하지는 지를 지시 단계에서 다양한 정보(제1정보, 제2 정보)를 통해 유추, 학습시킬 수 있다. 또한, 본 발명은 전문가의 작업지시를 로봇에게 학습시킬 수 있어, 다관 절 로봇에게 보다 효과적인 학습을 수행하게 할 수 있다. 한편, 본 발명은, 다관절 로봇의 높은 자유도를 이용 하여 학습을 수행하므로, 다양한 상황에서 여러 작업에 대한 유연한 대처가 가능하게 된다. 이 경우에, 로봇은 과거 수행한 작업에 대한 학습 정보를 새로운 작업에 대한 학습 정보로서 함께 활용함으로써, 새로운 작업에 대 한 학습 속도를 높일 수 있다. 이와 같이, 과거의 학습 데이터와 학습된 결과를 사용하고, 전문가와 햅틱 장치를 통해 로봇이 작업을 직접 수 행하며 얻은 정보를 바탕으로 학습하므로, 본 발명에서는 적은 수의 지도, demonstration, 만으로도 로봇의 학 습이 수행될 수 있다.나아가, 본 발명은 서로 다른 작업마다 로봇을 동작하기 위한 프로그래밍을 수행하지 않고, 햅틱을 이용하여 로봇을 교시를 할 수 있기 때문에, 로봇을 학습시키기 위하여 소요되는 시간과 노력을 줄일 수 있다.또한, 본 발명에서는, 지도 단계에서, 하위 제어기가, 인터페이스 장치와 정보를 송수신하고, 학 습단계에서, 지도 단계에서 획득된 정보를 이용하여 상위 제어기가 도출되므로, 보다 효율적인 학습 및 로봇제 어가 가능하게 된다. 또한, 본 발명에서는 다양한 센서로부터 얻은 데이터를 이용하기 때문에 다양한 상황에서 유연하게 대처 할 수 있는 상위 제어기 학습이 가능하게 된다. 이 경우에, 상위 제어기는 공통 미들웨어로서 구현되어, 서로 다른 로봇에 대한 작업 프로그램으로서 제공될 수 있다. 이를 통하여, 로봇의 대체, 작업계획의 변경이나 로봇의 안전표준 준수가 보다 용이하게 수행될 수 있다."}
{"patent_id": "10-2020-0095258", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소에는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설 명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼 용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실 시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 본 발명은 햅틱 기능이 있는 원격 조종장치(또는 인터페이스 장치)를 이용하여 로봇 작업을 학습하는 방법과 및 그 시스템을 제공하는 것이다. 여기에서, 햅틱(haptic)은, 컴퓨터 촉각기술로서, 구체적으로 사용자의 입력 장치를 통해 촉각과 힘, 운동감 등 을 느끼게 하는 기술을 의미한다. 이 경우, 촉각과 힘, 운동감의 효과는, 진동, 공기 분사, 온도제어 등을 통하 여 구현될 수 있으며, 다른 예로서, 사용자가 손가락이나 팔 등의 근 감각을 통해 느낄 수 있도록 구현할 수 있 다. 또한, 본 명세서에서 설명하는 햅틱 피드백은 입력장치를 통한 피드백을 이용하여 촉각과 힘, 운동감 등을 느끼게 하는 기술을 의미한다. 이와 같이, 본 발명은 로봇의 원격 조종장치에 햅틱 피드백을 출력하여 원격 조종장치의 사용자가 실제의 작업 환경에서 로봇에서 생성되는 힘을 인지하도록 한다. 또한, 본 명세서에서 로봇은 i) 사람과 유사한 기능을 가진 기계, 또는 ii) 하나 또는 복수의 컴퓨터 프로그 램으로 작동할 수 있고(programmable), 자동적으로 복잡한 일련의 작업(comlex series of actions)을 수행하는 기계적 장치를 말한다. 또 다른 예로, 로봇은 형태가 있으며, 자신이 생각할 수 있는 능력을 가진 기계를 의미 할 수 있다. 특히, 본 명세서에서 예시하는 로봇은, 기능적 관점에서 제조공장에서 조립, 용접, 핸들링 등을 수행하는 산업 용 로봇 또는 환경을 인식하고 스스로 판단하는 기능을 가진 지능형 로봇 등이 될 수 있다. 또한, 본 명세서에 서 설명되는 로봇은 한 가지 기능이 아니라, 여러가지 기능을 복합적으로 수행하도록 이루어질 수 있다. 나아가, 본 명세서에서 설명되는 로봇은, 모습과 행동이 인간을 닮은 안드로이드(android) 로봇, 인간과 유사한 신체 구조를 지닌 휴머노이드(humanoid) 로봇, 신체 일부가 기계로 개조된 사이보그(cyborg) 등의 형태로 구현 될 수 있다. 또한, 본 명세서에서 설명되는 로봇은, 용도적 관점에서, 청소로봇, 오락로봇, 교육로봇, 재활로봇 등의 개인 서비스용 로봇 (service robot for personal and private use)과, 안내로봇, 소방로봇, 의료로봇, 배달로봇, 재난구조로봇, 이사로봇, 가사로봇, 주방로봇 등의 전문 서비스용 로봇 (service robot for professional use)과, 용접로봇, 도장로봇, 이송로봇 등의 제조용 로봇 (industrial robot), 전투로봇, 정찰로봇 등의 군사용 로봇(military robot) 등을 포함할 수 있다. 한편, 본 명세서에서 설명되는 로봇은, 전술한 기능이나 용도를 구현하기 위하여, 액추에이터(actuator), 제어 시스템(control system), 엔드 이펙터(end effector), 매니퓰레이터(Manipulator), 센서(sensor) 등을 구비할 수 있다. 한편, 본 발명에 따른 로봇은 다양한 작업을 수행하기 위한 적절한 형태를 갖추기 위하여, 다관절의 매니퓰레이 터를 가지는 다관절 로봇으로 구현될 수 있다. 또한, 본 발명에서는 다관절 로봇에 대한 새로운 형태의 학습 방 법을 제시함에 따라, 로봇이 다양하고 복잡한 작업을 안전하게 수행할 수 있는 새로운 학습 모델을 구현한다. 다만, 본 발명의 실시예에서는 다관절의 구동부와 인터페이스 장치의 구조를 기준으로, 로봇의 새로운 학습 방 법에 대하여 설명하나, 본 발명은 이에 한정되는 것은 아니다. 즉, 이하 설명되는 실시예는 로봇의 구조나 학습 방식이면 타입에 관계없이 적용될 수 있다. 도 1a 및 도 1b는 본 발명에 따른 로봇 작업의 학습 방법 및 작업 실행을 설명하기 위한 개념도들이다. 도 1a에 도시된 것과 같이, 사용자는 로봇에게 특정 작업환경에서 필요한 작업을 지도한다. 여기에서, 작업환경이란, 로봇이 작업을 수행하기 위한 환경으로서, 로봇을 둘러싼 다양한 환경적인 요인을 포 함할 수 있다. 특히, 작업환경은, 로봇이 수행해야 하는 작업과 관련된 재료, 도구, 작업 대상 등을 모두 포함 하는 의미로 이해되어 질 수 있다. 이하에서는, 특정 작업 및 특정 작업환경에 대해 구체적인 예를 들어 본 발명에 대해 살펴보도록 한다. 예를 들어, 특정 작업으로서, “나무에 못을 박는 작업”을 정의한다. 본 발명에서는, 특정 작업을 수행하기 위하여, 사용자에 의해 나무에 못을 박는 작업이 로봇에게 지도될 수 있 다. 사용자는 작업의 전문가 또는 로봇 지도의 전문가일 수 있으며, 인터페이스 장치를 이용하여 상기 로봇을 원격으로 조종할 수 있다. 한편, 본 명세서에서 언급되는 “사용자”는 반드시 전문가에 국한되지 않으며, 인터 페이스 장치를 이용하여 로봇을 조종할 수 있는 주체이면 된다. 본 명세서에서 “지도”는 로봇을 가르쳐 이끈다는 의미이며, 가이드(guiding), 교시(teaching) 등으로 지칭되 는 것도 가능하다. 인터페이스 장치는 사용자의 조작에 따라서, 구동명령을 생성하여 로봇으로 전달할 수 있다. 예를 들어, 인터페 이스 장치는 원격 조종장치로 상기 로봇과 통신을 통하여 구동명령을 전달한다. 도시된 바와 같이, 로봇은 사용자의 조작에 의하여 나무에 못을 박는 작업을 수행하게 되며, 이 경우에 작업환 경(또는 특정 작업환경)은 나무 등의 오브젝트나, 나무의 위치, 나무의 재질, 로봇의 자세에 대한 제약 등이 될 수 있다. 한편, 본 발명에서는 인터페이스 장치로서, 햅틱 장치를 이용하여 힘 정보를 필요로 하는 작업을 힘 제어가 가 능한 로봇에 학습시키는 방법론을 제시한다. 따라서, 상기 인터페이스 장치는 로봇이 못을 박을 때 발생하는 힘을 햅틱 피드백으로서 출력하도록 이루어진다. 이를 위하여, 상기 인터페이스 장치는 햅틱 모듈을 구비할 수 있다. 사용자는 실제로, 작업시 로봇에게 발생하는 힘을 느끼면서, 인터페이스 장치를 이용하여, 로봇에게 못을 박는 작업을 원격 조종으로 지도하게 된다. 구체적으로, 로봇은 실제의 작업을 시연하는 형태로 수행하고, 이 때에 사용자가 인터페이스 장치를 통해 해당 작업에서 발생하는 실제 힘을 느끼는 동시에, 상기 시연을 위하여 인터 페이스 장치를 조종하는 것이다. 이 경우에, 로봇에서는, 작업의 지도에서 학습을 위한 학습 데이터가 센싱되고, 센싱된 학습 데이터를 포함하는 데이터베이스가 구축될 수 있다. 로봇은, 이렇게 구축된 데이터베이스를 이용하여 머신 러닝 등을 통하여 작업 을 학습할 수 있다. 학습을 통하여 제어기, 또는 제어 프로그램이나 작업의 수행정책 등이 도출되며, 로봇은, 사용자에 의한 지도가 없더라도, 학습 결과를 활용하여 자율적으로 과거 수행했던 작업 및 이와 유사한 작업을 수행하게 된다. 이러한 학습의 결과로, 도 1b에 도시된 바와 같이 로봇은 콘크리트 벽에 못을 박는 작업을 수행할 수 있다. 콘 크리트 벽에 못을 박는 경우는 수평방향으로 배치된 나무와 달리 오브젝트가 수직방향으로 배치되는 점과, 못을 박기 위해서 더 큰 힘이 필요한 점 등에서 작업환경이 달라지게 된다. 하지만, 로봇은 사용자의 행위 의도를 작 업의 지도에서 파악했기 때문에 작업의 수행에서 작업환경이 달라지더라도 해당 작업을 자율적으로 수행할 수 있게 된다. 다만, 본 발명은 반드시 본 예시와 동일한 형태의 프로세스에 한정되는 것은 아니다. 본 실시예의 설명은 다른"}
{"patent_id": "10-2020-0095258", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "형태로 실시될 수 있음을 본 기술분야의 당업자라면 쉽게 알 수 있을 것이다. 이러한 예로서, 지도단계에서 수 직방향으로 배치된 나무에 대하여 못을 박는 작업이 지도될 수 있다. 그리고, 실제 작업 과정에서 로봇에게는, 나무가 아닌 콘크리트에 못을 박는 작업이 요구될 수 있다. 이러한 경우, 작업의 대상이 되는 오브젝트는 나무 에서, 콘크리트로 변경되며, 이는 작업환경이 변경됨을 의미한다. 이와 같이, 작업환경이 변경되는 경우, 본 발 명에 따른 로봇은 변경된 작업환경에서의 작업을 위하여, 종래 학습했던 작업 정보(예를 들어, 힘 정보)로부터 변경된 작업환경에서 필요한 작업 정보를 도출할 수 있다. 예를 들어, 위에 경우에는, 나무가 아닌 콘크리트에 못을 박기 위하여, 나무에 못을 박을 때 보다 더 큰 힘이 필요하며, 본 발명에 따른 로봇은 학습에 기반하여, 새롭게 부여된 작업을 위하여 필요한 힘 정보를 도출할 수 있다. 도 1a 및 도 1b에서 설명된 로봇 작업의 학습 방법 및 작업 실행을 구현하기 위하여, 본 발명은 로봇 작업에 대 한 새로운 정의와, 로봇에게 다양한 작업을 학습시킬 수 있는 방법을 제시한다. 이와 같이, 본 발명은, 로봇 작업을 새롭게 정의하고, 다양한 작업을 학습하는 방법론을 제공하는 것으로서, 이 하에서는, 첨부된 도면과 함께, 본 발명에 따른 로봇 작업의 학습 방법 및 로봇 시스템에 대하여 첨부된 도면과 함께 보다 구체적으로 살펴본다. 도 2는 본 발명에 따른 로봇 시스템의 개요를 설명하기 위한 개념도이고, 도 3 은 도 2의 로봇 장치의 구조를 설명하기 위한 블록도이며, 도 4는 본 발명에 따른 로봇 작업의 학습 방법을 대 표적으로 나타내는 흐름도이다. 이하의 설명에서는 “하나의 로봇을 학습시키는 시스템과 학습방법”을 예를 들어 설명하나, 본 발명은, 복수의 로봇을 학습시키는 시스템과 학습방법에 공통적으로 활용될 수 있음은 물론이다. 먼저 도 2를 살펴보면, 본 발명에 따른 로봇 시스템은 로봇 장치, 인터페이스 장치 및 데이터베 이스 중 적어도 하나를 포함할 수 있다. 또한, 이러한 로봇 시스템은 사용자와 작업환경과 조합되 어, 도 4의 학습법을 구현하게 된다. 먼저, 도 4를 참조하면, 본 발명의 학습법은 지도단계(S100), 학습단계(S200) 및 실행단계(S300)의 프로세스로 구성될 수 있다. 상기 지도단계(S100)는 사용자가 인터페이스 장치를 통해 로봇 장치를 조종해서 작업을 수행하면서 로봇 장치를 지도하는 단계가 될 수 있다. 도 2를 참조하면, 사용자는 이러한 지도단계(S100)에서 햅틱 기능이 있는 인터페이스 장치를 이용하여 로봇 장치를 조종해 작업을 수행하며, 전술한 바와 같이 작업의 전문가 또는 로봇 지도의 전문가가 될 수 있다. 작업환경은 작업에 필요한 오브젝트를 포함한 환경으로, 물체, 툴 또는 그 주변 환경을 통틀어서 지칭될 수 있다. 예를 들어, 건물 내에서 택배물품을 수신인에게 운반하는 경우, 작업환경에는 택배물품(물체), 운반 시 보관함(툴) 및 건물내외, 복도, 계단, 엘리베이터 등의 장소(주변 환경)가 포함될 수 있다. 다른 예로서, 전 술한 바와 같이 나무에 못을 박는 경우, 작업환경에는 나무와 못(물체), 툴(망치) 및 나무가 배치된 형태 (주변환경)가 포함될 수 있다. 이 경우에, 로봇 장치도 그 자체로서 작업환경에 포함될 수 있다. 예를 들어, 로봇 장치의 크기 나 이동범위 등도 작업환경이 될 수 있다. 또한, 본 실시예에서 작업은 특정 물체 또는 대상으로 삼는 것들을 원하는 상태(위치, 자세 등)로 만드는 것으 로 정의될 수 있다. 예를 들어, 건물 내에서 택배물품을 수신인에게 운반하는 경우, 작업은 택배물품을 원하는 위치로 운반하여 수신인에게 전달하는 것이 될 수 있다. 다른 예로서, 전술한 바와 같이 나무에 못을 박는 경우, 작업은 못에 수직으로 힘을 가하여 수평으로 바닥에 배치된 나무에 박는 것이 될 수 있다. 인터페이스 장치는 학습 지도 장치로서 햅틱 원격 조종장치가 될 수 있다. 예를 들어, 상기 인터페이스 장 치는 사용자가 로봇 장치를 조종하여 작업을 수행하고, 작업 중에 일어나는 로봇과 작업환경간의 상호작용을 사용자가 인지하기 위한 햅틱 피드백을 주는 장치가 될 수 있다. 이를 위하여, 상기 인터페이스 장치는 상기 로봇 장치를 지도하도록 조작 가능하게 형성되며, 상기 로봇 장치에 대해 상기 작업에 대한 지도가 이루어지는 동안에 상기 힘 정보에 근거하여 햅틱 피드백을 출 력하도록 이루어진다. 이러한, 예로서 상기 인터페이스 장치는 6자유도 이상을 갖는 장치가 될 수 있으며, 각 자유도는 액츄에이 터에 의하여 움직이는 구조가 될 수 있다. 이러한, 조작을 위한 구성에 더하여, 상기 인터페이스 장치에는 햅틱 피드백을 받을 수 있는 장치가 더 구비된다. 예를 들어, 상기 인터페이스 장치는 햅틱 피드백을 출력하는 햅틱 모듈을 구비할 수 있다. 또한, 상기 햅 틱 모듈은 상기 인터페이스 장치에서 햅틱 기능의 조합에 따라 2개 이상이 구비될 수 있다. 한편, 상기 인터페이스 장치는 상기 로봇 장치와의 통신을 위한 무선 통신부와, 로봇으로부터 정보를 받아 사용자에게 전달할 수 있는 출력부를 구비할 수 있다. 상기 무선 통신부는 상기 로봇 장치와의 무선 통신을 위한 모듈들로 구성될 수 있으며, 상기 출력부는 상 기 로봇 장치로부터 전송받은 이미지 정보를 출력하는 디스플레이 기기 등이 될 수 있다. 이 경우에, 상기 디스 플레이 기기는 3D 디스플레이, 혼합현실 디스플레이, VR 기기 등이 될 수 있다. 로봇 장치는 작업을 수행하도록 이루어지며, 상기 작업과 관련된 힘 정보를 검출하도록 형성된다. 상기 로봇 장치는 도 1을 참조하여 설명한 로봇의 여러가지 형태 중 어느 하나가 될 수 있다. 상기 로봇 장치는, 작업환경에 변화를 줄 수 있는 장치(로봇의 구동부)을 포함하며, 작업환경을 인지할 수 있는 장치 (센서 등)를 구비할 수 있다. 이러한 예로서, 도 3을 참조하면, 상기 로봇 장치는 무선통신부, 센싱부, 구동부, 제어부 , 메모리, 인터페이스부 및 전원공급부 등을 구비할 수 있다. 다만, 본 명세서 상에서 설명되는 로봇 장치는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요 소들을 가질 수 있다. 예를 들어 센싱부 및 제어부는 로봇 장치의 내에 존재할 수도 있고 외에 존재할 수도 있다. 즉, 상기 무선통신부, 센싱부, 구동부, 제어부, 메모리, 인터페이 스부 및 전원공급부 중 일부가 로봇 장치로서 구성되고, 일부는 별도의 장치로 구현되는 것도 가능하다. 또한, 무선통신부는 유선통신부로 대체되거나, 상기 로봇 장치와 인터페이스 장치가 별도의 유 선통신부를 구비하는 것도 가능하다. 이 경우에, 유선 및 무선 통신 뿐만 아니라, 하나의 시스템안에서 메모리 를 이용한 통신도 상기 로봇 장치와 인터페이스 장치에 포함될 수 있다. 상기 무선통신부는 로봇 장치와 인터페이스 장치 사이, 로봇 장치와 다른 로봇 장치 사이, 또는 로봇 장치와 외부서버 사이의 무선 통신을 수행한다. 또한, 상기 무선 통신부는, 로봇 장치 를 하나 이상의 네트워크에 연결하는 하나 이상의 모듈을 포함할 수 있다. 이러한 예로서, 상기 무선통신 부는 무선 인터넷 모듈(111a), 근거리 통신 모듈(111b), 위치정보 모듈(111c) 등을 구비할 수 있다. 무선 인터넷 모듈(111a)은 무선 인터넷 접속을 위한 모듈을 말하는 것으로, 로봇 장치에 내장되거나 외장될 수 있다. 무선 인터넷 모듈(111a)은 무선 인터넷 기술들에 따른 통신망에서 무선 신호를 송수신하도록 이루어진다. 근거리 통신 모듈(111b)은 근거리 통신(Short range communication)을 수행하는 모듈을 말하는 것으로, 로봇 장 치의 근거리 통신을 지원할 수 있다. 이러한 근거리 통신은, 예를 들어, 블루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi(Wireless-Fidelity), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나가 될 수 있다. 위치정보 모듈(111c)은 로봇 장치의 위치(또는 현재 위치)를 획득하기 위한 모듈을 말하는 것으로, GPS 기 반 측위나, 네트워크 기반 측위 기술 중 적어도 하나가 될 수 있다. 다만, 상기 위치정보 모듈(111c)은 센싱부 와 조합되어 위치정보를 획득할 수 있다. 이 경우에, 상기 위치정보 모듈(111c)은 광센서 기반, 라이다 기 반, 관성센서 기반, 이미지 기반, 융합 센서 기반의 측위 기술에서 필요한 정보를 수신하는 모듈이 될 수 있다. 상기 센싱부는 작업에서 발생하는 힘 정보, 로봇 장치 내 정보(특히, 로봇의 구동상태), 로봇 장치를 둘러 싼 주변 환경 정보, 로봇 장치의 위치 정보 및 사용자 정보 중 적어도 하나를 센싱하기 위한 하나 이상의 센서 를 포함할 수 있다.상기 작업에서 발생하는 힘 정보는 예를 들어, 상기 로봇 장치에 가해지는 외력이 될 수 있다. 이 경우에, 상기 외력은 힘-토크 센서를 이용하여 측정하거나 모터에 인가되는 전류 등 로봇의 상태를 이용하여 추정하는 방식으로 산출될 수 있다. 상기 로봇의 구동상태는 모터의 각도, 가속도 및 각속도, 모터에 인가되는 토크 또는 전류 등이 될 수 있다. 따 라서, 상기 센싱부는 모터에 인가되는 전류를 센싱하는 전류센서(112a, current sensor), 모터의 각도를 센싱하는 엔코더(112b, encoder)를 구비할 수 있다. 이에 더하여, 상기 센싱부는 가속도 및 각속도를 센싱 하는 IMU 센서, 모터에 인가되는 토크를 센싱하는 토크센서(torque sensor) 등을 구비할 수 있다. 상기 로봇 장치를 둘러싼 주변 환경 정보에는 작업환경이 포함될 수 있다. 이를 위하여, 센싱부 는 오브젝트와의 거리, 작업환경의 온도 등과 같은 데이터를 특정 센서들을 이용하여 측정할 수 있다. 또한, 센 싱부는 비전 processing을 이용하여 정보를 획득하기 위하여, 카메라(112c)를 구비할 수 있다. 이와 같이 작업환경을 감지하는 센서들은 로봇 장치의 내에 존재할 수도 있고 외에 존재할 수도 있다. 예를 들어, 로봇 장치와 함께 주변 상황을 촬영하는 경우에는, 상기 센서들은 로봇 장치의 외부에 구비될 수 있 다. 또 다른 예로서, 상기 센싱부의 구성과 관계없이 상기 지도단계(S100)에서 정보 획득을 위하여, 본 발명의 로봇 시스템에는 이미지 센서, 카메라 등이 로봇 장치의 외부에 별도로 구비될 수 있다. 상기 구동부는 제어부에 의한 제어 하에 상기 사용자의 지도 명령에 따른 구동을 수행하도록 이루어 진다. 이러한 예로서, 상기 구동부은 엔드 이펙터(113a), 매니퓰레이터(113b), 액추에이터(113c) 중 적어 도 하나를 구비할 수 있다. 상기 엔드 이펙터(113a)는 환경과 상호 작용하도록 설계된 로봇 암의 끝단 장치로서, 그리퍼, 핀셀 및 메스 등 이 될 수 있다. 이러한, 엔드 이펙터(113a)는 로봇 장치와 별도로 구비되어 로봇 주변기기나 액세서리 등 이 되는 것도 가능하다. 상기 매니퓰레이터(113b)는 로봇 장치의 본체와 팔에 링크, 조인트 및 기타 구조 요소와 메커니즘을 통합하는 장치가 될 수 있다. 다관절 로봇의 경우, 모터의 회전운동을 하는 여러 개의 관절을 가지는 매니퓰레이터(113 b)를 구비할 수 있다. 이 경우에, 상기 매니풀레이터(113b)와 엔트 이펙터(113a)는 6자유도 이상의 팔과 1자유도 이상의 손을 형성할 수 있다. 또한, 본 발명의 로봇이 양팔 로봇이나 여러 개의 팔을 가지는 로봇으로 구현되기 위하여, 상기 팔과 손은 여러 개의 쌍으로 존재할 수 있다. 또한, 상기 액추에이터(113c)는 전기, 화학 또는 열에너지를 회전 또는 직선 운동으로 변환하는 장치로서, 모터, 공압 실린더, 인공 근육 등이 될 수 있다. 상기 액추에이터(113c)는 QDD (Quasi-Direct-Drive )방식으로 구동되는 모터를 구비할 수 있다. QDD 방식은 출 력단에 걸리는 힘을 입력단의 센서로 감지가 가능하다. 이 경우에, 상기 입력단의 센서는 상기 센싱부에 포함될 수 있다. 즉, 상기 센싱부는 상기 모터의 출 력단에 걸리는 힘을 입력단의 전기 에너지로 감지함에 따라 상기 힘 정보를 검출할 수 있다. 이와 같이, 상기 QDD방식의 모터의 전류 센서에 의해 외력이 감지될 수 있고 모터의 전류를 제어하여 토크가 예 측될 수 있다. 로봇 작업에서 발생하는 외력은 모터에 인가되는 전류 등 로봇의 상태를 이용하여 추정하는 방식 으로 산출될 수 있다. 다만, 본 발명은 반드시 이에 한정되는 것은 아니다. 예를 들어, QDD 방식이 아니더라도, 모터와 함께 관절에 토크를 측정할 수 있는 센서를 활용하여 토크 제어를 구현하는 것도 가능하다. 한편, 본 발명의 로봇 장치는 메모리, 인터페이스부 및 전원공급부를 구비할 수 있다. 메모리는 제어부의 동작을 위한 프로그램을 저장할 수 있고, 입/출력되는 데이터들(예를 들어, 구동 명령 등)을 임시 저장할 수도 있다. 인터페이스부는 상기 로봇 장치를 외부기기와 연결시킬 수 있는 통로로서 구비될 수 있다. 예를 들어, 상기 인터페이스부는 접속단자, 포트, 전원단자 등이 될 수 있다. 전원공급부는 외부의 전원, 내부의 전원을 인가받아 로봇장치에 포함된 각 구성요소들에 전원을 공급 하는 장치가 될 수 있다. 다른 예로서, 상기 전원공급부는 상기 로봇 장치의 내부에서 전기에너지를 생성하여 각 구성요소에 공급하는 장치가 될 수 있다.한편, 제어부는 작업을 수행하는 동작과 더불어, 통상적으로 로봇 장치의 전반적인 동작을 제어한다. 도 3을 참조하면, 상기 제어부는 제1제어기와 제2제어기를 구비할 수 있다. 본 실시예서, 상기 제1제어기는 하위 제어기(114b)가 되고, 상기 제2제어기는 상위 제어기(114a)가 될 수 있다. 다만, 본 발명은 반드시 이에 한정되는 것은 아니다. 예를 들어, 상기 제1제어기는 상위 제어기가 되고, 상기 제2제어기는 하위 제어기가 되는 것도 가능하다. 다른 예로서, 제1제어기와 제2제어기가 상위제어와 하위제어가 적용되지 않고 병렬적으로 구성되는 것도 가능하다. 상기 하위 제어기(114b)는 한 개 또는 복수개의 제어기로 구성될 수 있다. 예를 들어, 상기 하위 제어기(114b) 는 위치 제어기, 속도 제어기, 전류 제어기 중 적어도 하나를 포함할 수 있다. 이 경우에, 상기 구동부는 상기 하위 제어기(114b)에 의한 제어 하에 사용자의 지도 명령에 따른 구동을 수행하게 된다. 예를 들어, 상기 하위 제어기(114b)는 상기 인터페이스 장치로부터 상기 작업에 대한 지도 명령을 수신하 여 상기 구동부를 제어한다. 또한, 상기 하위 제어기(114b)는 상위 제어기(114a)로부터 상기 작업에 대한 구동명령을 수신하여 상기 구동부를 제어할 수 있다. 이 경우에, 상위 제어기(114a)는 상기 하위 제어기 (114b)를 제어하여 상기 구동부를 구동하는 기능을 수행하는 제어기가 될 수 있으며, 상세한 내용은 후술 한다. 구체적으로, 상기 하위 제어기(114b)는 인터페이스 장치 또는 상위 제어기(114a)로부터의 명령을 받고, 센 싱 데이터를 이용하여 모터에 인가할 토크 또는 전류를 계산할 수 있다. 계산된 결과는 위치 제어기, 속도 제어 기, 전류 제어기 등에 의하여 모터 등을 구동하게 되며, 구동명령은 하나 또는 다수의 파라미터에 의하여 결정 될 수 있다. 이 경우에, 상기 구동명령에는 작업에 대한 정보를 담고 있지 않게 된다. 즉, 상기 하위 제어기(114b)는 어떤 모터를 어느 위치로 움직여라, 어떤 모터에 전류를 얼마나 흘려라 등과 같은 명령을 수행하게 된다. 최종적으로, 상기 하위 제어기(114b)는 모터를 통해 외부 환경과 힘 상호작용을 수행하는 제어기로서, 상위 제 어기(114a)나 인터페이스 장치에 의하여 전달된 명령을 이용하여 모터 등의 액추에이터를 제어하는 기능을 하게 된다. 이와 같이, 지도단계(S100)에서는 상기 하위 제어기(114b)가 상기 인터페이스 장치로부 터 구동명령을 전달받아 상기 모터 등의 액추에이터를 제어하게 된다. 다시 도 2를 참조하면, 본 발명의 로봇 시스템은 데이터베이스를 포함할 수 있다. 상기 데이터베이스 에는 지도단계(S100)에서 로봇의 상태, 작업환경 정보를 센싱하고, 인터페이스 장치에서 하위 제어기 (114b)로 들어가는 명령을 검출하여 시계열 데이터로 저장할 수 있다. 한편, 상기 데이터베이스에는 지도단계(S100)의 정보 뿐만 아니라 과거 데이터도 함께 저장될 수 있다. 이 러한 예로서, 과거 학습에 의해서 도출된 정책(방법론)도 함께 저장될 수 있다. 도 3의 학습단계(S200)에서는 학습부(140, 이하 도 6b 참조)가 상기 데이터베이스를 이용하여 학습을 수행 하며, 학습단계(S200)의 결과물로서 상위 제어기(114a)의 적어도 일부가 도출될 수 있다. 이를 위하여, 상기 로 봇 시스템은 학습부를 더 구비할 수 있다. 상기 학습부는 상기 로봇 장치가 상기 작업에 대한 자율 수행이 가능하도록, 상기 데이터베이스(13 0)를 이용하여, 상기 작업과 관련된 상기 로봇 장치의 동작을 학습한다. 예를 들어, 상기 학습부는 상기 로봇 장치와 별도로 구성되거나, 상기 로봇 장치의 내부에 구비될 수 있다. 또한, 상기 학습부 는 상기 데이터베이스와 함께 별도의 서버에 구비되는 것도 가능하다. 학습단계(S200)는 지도단계(S100)에서 생성된 정보 (센싱 데이터 및 로봇의 내부 상태) 등을 데이타베이스(13 0)에 저장하고, 저장된 데이터를 이용해 학습을 하여 대상 작업을 수행하기 위한 정책(예를 들어, 상위 제어 기)을 도출하는 단계가 될 수 있다. 이 때에, 상위 제어기를 도출하는 조건(objective function)은 사용자가 인터페이스 장치를 통해 로봇을 조종해 수행한 작업과 학습되어진 상위 제어기를 이용하여 수행한 작업의 결과물이 같아야 한다는 조건이 될 수 있다. 또한, 이 경우에, 반드시 상기 지도단계(S100)가 완료된 후에 상기 학습단계(S200)가 진행되는 것은 아니다. 본 발명에서는 예를 들어, 상기 지도단계(S100)가 상기 학습단계(S200)에 선행하나, 상기 지도단계(S100)가 상기 학습단계(S200)가 시간흐름을 기준으로 적어도 일부분이 겹쳐져서 진행될 수 있다.도 3을 참조하면, 상기 상위 제어기(114a)는 상기 로봇 장치의 제어부에 구비될 수 있다. 또한, 상기 상위 제어기(114a)는 복수개의 제어기로 나뉠 수 있으며 다양한 형태로 변형되어 구비될 수 있다. 이러한 예로 서, 상기 상위 제어기(114b)는 인공지능(AI, Artificial Intelignece) 기술에서 사용되는 시스템 중 하나로서 구현될 수 있다. 이러한 예로서, 상기 상위 제어기(114a)는 계층적 제어기, 유한상태머신 (finite state machine), 행동 트리 (behavior tree) 중 적어도 하나를 구비할 수 있다. 이러한, 상위 제어기는 프로그래밍용 언어인 겐(Gen),파이 썬(Python), 리스프처리언어(Lisp), 줄리아(Julia), C/C++ 등과, AI 딥러닝 프레임워크 텐서플로(TensorFlow), 파이토치(Pytorch), Theano 등에 의하여 구현될 수 있다.이 경우에, 상기 상위 제어기(114a)는 학습단계(S200) 의 결과물로 데이터로부터 학습된 부분과 학습과 관계없이 기 프로그래밍된 부분을 각각 구비할 수 있다. 도 3의 실행단계(S300)에서, 상기 상위 제어기(114a)는 수행하고자 하는 작업이 무엇인지 입력 받아 현재 상태 의 정보로부터 다음 행위에 대한 정보를 산출하여 하위 제어기(114b)로 전달할 수 있다. 이와 같이, 상기 로봇 장치는 학습된 정책이나 도출된 상위 제어기(114a)를 이용하여 실행단계(S300)에서 자율적으로 작업을 수 행하게 된다. 상기 상위 제어기(114a)는 학습단계(S200)의 결과물로서 하위 제어기(114b)에게 일방향으로 명령을 전달하므로, 상위 제어기(114a)의 주기와 하위 제어기(114b)의 주기는 다르게 설정될 수 있다. 이 경우에, 상기 상위 제어기(114a)는 작업과 관련된 정보를 담고 있으며 모션을 수행하기 위한 일련의 시퀀스 로 표현될 수 있다. 이러한 예로서, 상기 상위 제어기(114a)는 하기와 같이 표현될 수 있다."}
{"patent_id": "10-2020-0095258", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": ": 센서로부터 얻은 데이터 (로봇과 작업환경의 상태) : 행위 (하위 제어기 입장에서는 명령)를 의미 : 1초부터 t초까지의 상태를 의미 여기서, 행위는, 로봇 장치의 엔드 이펙터의 자세나 모터의 토크 (또는 전류)가 될 수도 있다. 또한, 행위는 vector field로 표현된 상태-토크 함수 일 수도 있으며, 하위 제어기를 구성하는 파라미터 셋의 부분 집합일 수 도 있다. 이와 같이, 본 발명은, 햅틱 기능을 갖춘 인터페이스 장치를 이용함에 따라, 전문가가 실제 환경에서 로봇 에 가해지는 힘을 피드백 받으면서 로봇 지도를 수행하게 되고, 이러한 로봇 지도에서 센싱된 여러 정보를 학습 하여 상위 제어기(114a)가 도출된다. 따라서, 햅틱 장치를 이용하여 힘 정보를 필요로 하는 작업을 힘 제어가 가능한 로봇에 학습시키는 방법론이 구현될 수 있다. 이하에서는, 위에서 살펴본 본 발명에 따른 로봇 시스템을 참조하여, 로봇 작업의 학습 방법에 대하여 첨 부된 도면과 함께 보다 구체적으로 살펴본다. 도 5a 및 도 5b는 각각 도 4의 지도단계에 대한 상세 흐름도와 지 도의 개념을 설명하기 위한 개념도이고, 도 6a 및 도 6b는 각각 도 4의 학습단계에 대한 상세 흐름도와 학습의 개념을 설명하기 위한 개념도이며, 도 7a 및 도 7b는 각각 도 4의 실행단계에 대한 상세 흐름도와 실행의 개념 을 설명하기 위한 개념도이다. 본 발명에 따른 로봇 작업의 학습 방법에 의하면, 도 4의 지도단계(S100)는 도 5a와 같이 세분화될 수 있다. 먼저, 인터페이스 장치에 대한 외부조작에 근거하여, 로봇 작업에 대한 지도가 수행된다. 즉, 전문가에 의 하여 로봇 작업의 지도를 위한 조종 장치의 조작이 수행된다(S110). 상기 전문가는 사용자, 작업의 전문가, 로 봇 지도의 전문가, 작업자 등 여러가지 형태가 가능하며, 이하 설명의 편의를 위하여 전문가로 통일하여 지칭한 다. 이 경우, 전문가의 로봇 지도를 위한 사전 준비가 진행될 수 있다. 예를 들어, 로봇 작업이 정해지면, 로봇을 지도 및 학습시키기 위한 세부적인 작업환경 설정이나 지도계획 설정 등이 이루어질 수 있다. 상기 인터페이스 장치는, 도 5b에 도시된 바와 같이 인간의 팔이나 로봇 암과 유사한 크기로, 다관절로 이 루어질 수 있다. 또한, 상기 인터페이스 장치는, 도 1 내지 도 4를 참조하여 전술한 인터페이스 장치의 기능이나 구조를 구비할 수 있다. 다음으로, 전문가가 상기 인터페이스 장치를 잡고 움직여 조작하는 경우에, 상기 인터페이스 장치에 서 구동명령이 생성되어 상기 로봇 장치로 전달된다(S120). 즉, 상기 인터페이스 장치가 상기 로봇 장치에 상기 조작에 해당하는 구동명령을 전달한다. 다만, 본 발명은 반드시 이에 한정되는 것은 아니며, 상기 인터페이스 장치는 상기 움직임에 대한 정보를 상기 로봇 장치로 전달하고, 상기 로봇 장치 에서 구동명령을 생성하는 것도 가능하다. 보다 구체적으로, 상기 움직임에 대한 정보는 상기 인터페이스 장치와 상기 로봇 장치의 무선 통신부 를 이용한 데이터 통신으로 상기 로봇 장치로 전송될 수 있다. 이후에, 상기 움직임에 대한 정보는 상기 로봇 장치의 하위 제어기(114b, 도 2 및 도 3 참조)로 전달된다. 이 경우에, 전문가의 조작이나 움직임을 상기 로봇 장치가 묘사하기 위해서는 상기 인터페이스 장치와 상기 로봇 장치의 기구학 정보를 바탕으로 한 제어기나 알고리즘이 구비될 수 있다. 다음으로, 구동명령에 따라 로봇 장치가 작업을 수행한다(S130). 구체적으로, 상기 로봇 장치의 하위 제어 기(114b)에 동작 수행을 위한 명령이 들어오면, 상기 하위 제어기(114b)가 상기 로봇 장치의 구동부 를 제어하여 작업을 수행하게 된다. 예를 들어, 상기 로봇 장치의 센싱부는 작업환경이나, 모터의 현 재 상태 등을 센싱하고, 상기 하위 제어기(114b)는 상기 작업환경이나, 모터의 현재 상태를 상기 센싱부에 서 전달받아 작업 수행을 위한 동작을 산출하여, 이에 대응하도록 모터를 제어한다. 이 경우에, 상기 모터는 도 1 내지 도4를 참조하여 전술한 바와 같이 QDD 방식의 모터나 또는 다른 방식의 모터가 될 수 있다. 이와 같이, 모터를 통해 하드웨어, 즉 엔드 이펙터(113a, 도 3 참조)와 매니퓰레이터(113b, 도 3 참조)가 움직 이면 작업환경과 힘 상호작용을 통해 작업환경의 변화가 발생하게 된다. 이러한 작업환경의 변화는, 예를 들어 못을 내려쳐서 못이 나무로부터 돌출한 높이가 달라지는 것 등이 될 수 있으며, 이에 대한 상세한 설명은 전술 한 내용으로 갈음한다. 이 때에, 상기 센싱부의 센서들은 발생한 외력을 센싱한다(S140). 나아가, 상기 센 싱부는 작업환경의 상태나 변화를 센싱할 수 있다. 다음으로, 상기 인터페이스 장치가 상기 로봇 장치로부터 상기 로봇 작업에서 발생하는 힘과 관련된 정보를 전송받아 햅틱 피드백을 출력하는 단계가 진행된다. 이와 같이, 상기 센싱부는 상기 인터페이스 장치에 의해 상기 전문가의 지도가 이루어지는 동안에, 상기 로봇 장치에 가해지는 외력을 검출하고, 상기 인터페이스 장치는 상기 외력에 근거하여 상기 햅 틱 피드백을 출력하게 된다. 보다 구체적으로, 센서로부터 들어온 외력과 작업환경의 상태나 변화에 대한 정보는 상기 인터페이스 장치(12 0)를 통하여 상기 전문가에게 전달된다. 먼저, 상기 정보는 상기 인터페이스 장치에 햅틱 정보로 전송될 수 있다(S150). 상기 햅틱 정보는 상기 외력이나 작업환경의 상태나 변화를 알려주는 데이터가 될 수 있다. 이 경우에, 상기 하위 제어기(114b)는 상기 힘 정보를 햅틱 정보로서 상기 인터페이스 장치로 전송할 수 있다. 예를 들어, 도 5b를 참조하면, 로봇 장치가 못을 나무에 박기 위하여, 못을 망치로 내려치면, 반력(F1)이 발생 하여 로봇에게 힘을 가하게 된다. 이러한 반력(F1)의 데이터가 힘 정보로서 상기 인터페이스 장치에 전달될 수 있다. 상기 인터페이스 장치는 전문가가 손으로 잡는 부분에 수직방향으로 상기 반력(F1)에 해당하는 힘(F2)을 가하여, 전문가가 못을 박는 작업에서 상기 반력(F1)을 느낄 수 있게 한다. 다만, 본 명세서는 반력을 예시로서 설명하나, 망치의 무게 등, 작업환경에서는 다양한 형태의 외력, 물체의 재질, 표면의 거칠기 등이 발생할 수 있으며, 이러한 외력들이 상기 힘 정보에 포함될 수 있다. 이와 같이, 상기 힘 정보를 기반으로 상기 로봇 장치 를 지도하도록 상기 햅틱 피드백은 상기 인터페이스 장치에서 상기 외력에 해당하는 힘을 사용자에게 전달하게 된다. 햅틱 피드백을 위하여 햅틱 모듈을 구동하는 구동 명령은 상기 인터페이스 장치에서 생성한다. 다른 예로 서, 상기 햅틱 정보는 상기 데이터로부터 도출한 상기 인터페이스 장치에 대한 제어명령이 될 수 있으며, 이 경우에 상기 제어명령을 이용하여 상기 햅틱 모듈을 구동하게 된다. 상기 햅틱 모듈의 구동에 의하여, 상기 인터페이스 장치는 상기 외력에 대한 햅틱 피드백을 출력하게 된다 (S160). 예를 들어, 상기 햅틱 모듈은 복수의 액추에이터나 장치를 구비할 수 있으며, 상기 인터페이스 장치 는 전문가가 느낄 수 있도록 액추에이터 또는 장치를 통해 힘이나 환경 변화의 데이터를 전달할 수 있다.이와 같이, 햅틱 피드백을 받은 전문가는 힘을 반영하여 로봇 작업의 지도를 위한 조종 장치 조작을 수행하게 된다(S110). 전문가는 이와 같이 지도에 필요한 정보를 상기 인터페이스 장치로부터 받아들일 수도 있고 작업환경을 직 접 보고 느낄 수도 있다. 단, 작업환경과 상호 작용은 로봇을 통해서만 이루어진다. 즉, 환경 변화를 줄 수 있 는 방법은 로봇 장치를 통해서만 가능한 것이다. 상기에서 설명한 지도단계(S100)의 다음으로, 도 4의 학습단계(S200)가 진행된다. 본 발명에 따른 로봇 작업의 학습 방법에 의하면, 학습단계(S200)는 도 6a와 같이 세분화될 수 있다. 도 6a를 참조하면, 상기 학습단계(S200)은 데이터 저장 단계와 정책(policy, 방법론) 학습 단계를 구비할 수 있 다. 먼저, 상기 지도단계(S100)에서 구동명령에 따라 로봇 장치가 작업을 수행하면, 학습 데이터가 센싱된다 (S210). 보다 구체적으로, 상기 인터페이스 장치가 상기 로봇 장치로 전송한 구동명령에 따라 상기 로봇 장치가 상기 로봇 작업을 수행하는 동안에, 상기 로봇 장치의 작업환경과 관련된 제1정보와, 상 기 로봇 장치의 구동상태와 관련된 제2정보가 센싱될 수 있다. 상기 제1 및 제2정보의 센싱은 햅틱 피드백을 출력하는 인터페이스 장치에 의해 상기 로봇 작업의 지도가 이루어지는 동안에, 상기 센싱부에 의하여 수행된다. 다만, 상기 학습데이터는 상기 제1정보와 제2정보를 필수적으로 포함하는 것은 아니며, 어느 하나의 정보만을 포함하는 것도 가능하다. 이렇게 센싱된 제1정보와 제2정보는 전문가의 행위 의도를 파악하기 위해 필요한 데이터로서 수집될 수 있다. 이를 위하여, 상기 제1정보 및 제2정보는 상기 힘 정보를 기반으로 상기 로봇 장치를 지도함에 따라 상기 작업환경 및 상기 구동상태가 변화되는 정보가 될 수 있다. 여기서, 행위 의도는 어느 상황에 어떤 동작을 행해 야 작업을 수행할 수 있는지에 대한 계획을 의미한다. 또한, 상기 행위 의도는 학습을 통하여 도출되는 상위 제 어기(114a)에 의하여 구체화될 수 있다. 도 6b와 함께 도 2를 참조하면, 전문가가 인터페이스 장치를 이용해 로봇 장치를 움직이고, 상기 로 봇 장치가 작업을 수행하면, 이 때에 상기 로봇 장치로 전송되는 구동명령이 데이터베이스에 저 장될 수 있다. 또한, 데이터베이스에는 작업환경과 로봇 장치의 구동상태가 저장될 수 있다. 여 기서, 작업환경이나 구동상태는 도 1 내지 도 4를 참조하여 설명한 내용이 적용될 수 있다. 이러한 예로서, 상기 제1정보는 촬영 이미지, 오브젝트와의 거리, 작업환경의 온도 중 적어도 하나를 포함하고, 상기 제2정보는 모터의 각도, 가속도 및 각속도, 모터에 인가되는 토크 또는 전류 중 적어도 하나를 포함할 수 있다. 또한, 상기 촬영 이미지는 도 6b와 같이 상기 로봇 장치와 별도로 구비되는 카메라 등에 의하여 획득될 수 있다. 다른 예로서, 상기 작업환경의 온도는 상기 로봇 장치와 별도로 구비되는 온도측정장치에 의하여 획 득될 수 있다. 상기에서 설명한 데이터 저장 단계의 다음에는 정책 학습 단계가 진행된다. 다만, 상기 데이터 저장 단계와 정 책 학습 단계는 본 명세서의 예시와 같이 순차적으로 진행될 수도 있지만, 반드시 이에 한정되는 것은 아니다. 예를 들어, 데이터 저장 단계의 진행 중에 정책 학습 단계가 진행되는 것도 가능하다. 구체적으로, 상기 제1정보와 제2정보를 이용하여 상기 로봇 작업에 대한 학습을 수행하는 단계가 진행된다. 즉, 상기 로봇 작업에 대한 학습을 통하여 상기 로봇 장치의 제어부(114, 도 3 참조)의 적어도 일부가 도출된 다. 보다 구체적으로, 상기 학습부는 상기 로봇 장치가 상기 작업에 대한 자율 수행이 가능하도록, 상기 제1정보 및 제2정보를 이용하여, 상기 작업과 관련된 상기 로봇 장치의 동작을 학습한다. 예를 들어, 상기 학습부가 상기 작업에 대한 학습을 수행하여 상기 상위 제어기(114a)의 적어도 일부가 도출될 수 있다. 이 경우에, 상기 제1정보 및 제2정보는 상기 지도 명령과 함께 시계열 데이터로 데이터베이스에 저장되며, 상 기 학습부는 상기 시계열 데이터를 이용하여 상기 상위 제어기(114a)를 도출한다. 이 단계는, 전문가에 의해 수행된 작업을 전문가 없이 상위 제어기(114a)만으로 수행할 수 있도록 상기 상위 제 어기(114a)를 도출해 내는 과정이 될 수 있다. 이 경우에, 상기 상위 제어기(114a)의 일부가 도출되는 것도 가 능하다. 도 3을 참조하여 전술한 바와 같이, 상기 상위 제어기(114a)는 제1제어부 및 제2제어부로 구획될 수 있 다. 상기 제1제어부는 상기 로봇 장치를 구동하도록 기설정된 부분으로서, 상기 학습과 관계없이 기 프로그래밍 된 부분이 될 수 있다. 상기 제2제어부는 상기 학습에 의하여 도출되어 상기 제1제어부와 연동하는 부분이 될수 있다. 즉, 상기 제2제어부는 학습단계의 결과물로 데이터로부터 학습되어 도출되는 부분이 될 수 있다. 학습단계(S200)에서, 다음으로 획득한 학습데이터를 이용하여 학습을 수행하고(S220), 학습을 통하여 작업을 수 행하기 위한 정책이 도출된다(S230). 이 때에, 상기 학습은 최근의 데이터 뿐만 아니라 과거의 정보를 함께 이 용하여 학습을 수행할 수 있다. 이를 위하여, 상기 데이터베이스에는 과거의 데이터 또는 과거 학습에 의 해서 도출된 정책 (방법론)이 함께 저장될 수 있다. 상기 학습은, 다양한 알고리즘에 의해서 수행될 수 있으며, 예를 들어 모방학습(Imitation learning), 메타 러 닝(Meta learning), 강화학습(Reinforcement learning), 역강화학습(Inverse Reinforcement Learning) 중 적 어도 하나에 의하여 수행될 수 있다. 이후에, 상기 상위 제어기(114a)는, 상기 학습에 근거하여 상기 로봇 장치가 상기 작업을 자율 수행할 수 있도록 상기 하위 제어기(114b)에 대한 제어 명령을 생성하게 된다. 예를 들어, 상기에서 설명한 상기 로봇 작업에 대한 학습을 통하여 상기 로봇 장치의 제어부의 적어 도 일부가 도출된 후에, 상기 제어부를 통하여 상기 로봇 장치가 자율적으로 작업을 수행하는 단계가 진행된다. 즉, 상기에서 설명한 학습단계(S200)의 다음으로, 도 4의 실행단계(S300)가 진행된다. 본 발명에 따른 로봇 작 업의 학습 방법에 의하면, 실행단계(S300)는 도 7a와 같이 세분화될 수 있다. 보다 구체적으로, 실행단계(S300)에서는 상기 로봇 장치가 전문가 없이 학습단계(S200)에 의해서 얻어진 상위 제어기(114a)를 이용하여 전문가가 수행한 작업을 수행한다. 특히, 상기 로봇 장치는 전문가의 행위 의도를 파악했기 때문에 실행단계(S300)의 작업환경이 지도단계(S100)의 환경과 다르더라도 작업을 수행할 수 있다. 이러한 예로서, 도 5b와 같이 전문가가 바닥에 놓인 나무에 못을 박는 작업을 지도하면, 도 7b와 같이 로 봇 장치는 콘크리트 벽에 못을 박는 작업을 자율적으로 수행할 수 있다. 다른 예로서, 안전을 위하여 로봇 장치의 머리 위로 택배물품을 들어올려서 운반하는 작업을 지도한다면, 로봇 장치는 더 무거운 택배물품을 더 강한 힘으로 머리 위로 들어올려서 운반할 수 있게 된다. 이하, 이러한 실행단 계(S300)에 대하여 보다 구체적으로 설명한다. 먼저, 학습단계(S200)에서 얻어진 상위 제어기(114a)에서 수행하고 싶은 작업이 지정된다. 이러한 지정은 작업 을 구분하는 무엇이든 가능하다. 예를 들어 자연수들이 해당 작업에 대하여 각각 지정될 수 있다. 구체적으로, 1은 못을 박는 작업이고, 2는 택배물품을 운반하는 작업이 될 수 있다. 이 경우에, 1을 지정하면, 로봇 장치는 못을 박는 작업을 실시하라는 명령을 인식하게 된다. 다음으로, 상기 상위 제어기(114a)는 현재의 로봇 장치와 작업환경의 상태 정보를 이용하여 하위 제어기(114b) 에게 수행해야하는 동작 명령을 전송한다. 예를 들어, 상기 로봇 장치는, 로봇 장치의 상태 정보와 작업환 경의 상태 정보를 획득 (S310)하고, 이러한 정보들을 이용하여 제어기들이 작업에 대한 명령을 생성한다(S320). 보다 구체적으로, 1을 지정하여 못을 박으라는 명령을 인식하면, 상기 로봇 장치가 작업환경의 상태 정보 로서 콘크리트 벽을 인식하게 되고, 상기 로봇 장치의 상태 정보로서 엔드 이펙터(113a)의 위치나 매니퓰 레이터(113b, 도 3 참조)의 현재 자세 등을 인식한다. 이러한 정보 획득은 상기 로봇 장치의 센싱부(112, 도 3 참조)에 의하여 수행될 수 있다. 또한, 상기 상위 제어기(114a)는 작업에 대한 동작명령을 생성하여 상기 하위 제어기(114b)로 전달한다. 이때에, 동작명령은 상기 로봇 장치의 엔드 이펙터(113a)의 목표 위치, 엔드 이펙터(113a)의 자세, 매니퓰 레이터(113b)의 자세, 모터 토크, 모터 전류, 상태-모터 토크 함수 등의 형태로 전달될 수 있다. 또한, 상기 동 작명령은 상기에서 설명한 여러가지 형태 중 하나가 될 수도 있고, 조합으로 표현될 수도 있다. 구체적인 예로 서, 상기 상위 제어기(114a)는 못을 박는 위치를 인식하여 벽에 못을 박기 위한 엔드 이펙터(113a)와 매니퓰레 이터(113b)의 동작을 산출하여, 동작명령을 생성하게 된다. 상기 동작명령을 전달받은 하위 제어기(114b)는 현재 로봇 장치의 상태 정보와 작업환경의 상태 정보 를 이용하여 상기 상위 제어기(114a)로부터 들어온 동작명령을 수행하기 위한 토크를 모터에 인가한다. 이와 같 이 상기 하위 제어기(114b)에 의하여 벽에 못을 박는 동작이 수행된다. 이 때에, 상기 로봇 장치는 외력과 작업환경의 변화를 감지하고(S330), 작업을 자율적으로 수행하게 된다 (S340). 구체적으로, 움직인 모터는 작업환경에 변화를 일으키고 이때 발생한 외력과 작업환경의 변화는 센싱부 에 의해서 인지될 수 있다. 상기 센싱부는 하위 제어기(114b)와 상위 제어기(114a)가 필요로 하는 정보, 예를 들어 오브젝트 인지, 위치나 자세 추정 등으로 가공하여 하위 제어기(114b)와 상위 제어기(114a)로 전 달한다. 예를 들어, 벽에 못을 박는 작업에서 로봇 장치는 나무에 못을 박는 경우보다 동일한 힘에서 못이 덜 박힌다는 것을 인지하게 된다. 따라서, 상기 상위 제어기(114a)는 보다 강한 힘으로 못을 박을 수 있는 모터 의 토크를 하위 제어기(114b)에 동작명령으로 전달하여, 콘크리트 벽에 못을 박는 작업을 자율적으로 수행하게 된다. 나아가, 이 경우에, 도 1b와 도 7b에 각각 도시된 바와 같이, 상기 로봇 장치는 서로 다른 콘크리트 벽들 에 못을 박는 작업을 수행하는 것도 가능하다. 상기 로봇 장치는, 어느 콘크리트 벽(도 1b 참조)에 못을 박는 작업을 한 후에, 다른 콘크리트 벽(도 7b 참조)이 그 전과 유사하다는 것을 인지하여, 유사한 힘을 사용하여 작 업을 수행할 수 있다. 이상에서 설명한 본 발명에 따른 로봇 작업의 학습 방법 및 로봇 시스템은, 로봇과 외부의 환경 사이의 힘에 대 한 정보를 기반으로 로봇 작업을 정의하여, 로봇이 다양하고 복잡한 작업을 용이하게 학습하도록 한다. 따라서, 본 발명은 작업환경의 변화에 따라 로봇의 외력이 변화하는 것에 보다 유연하게 대처하는 학습방법을 구현할 수 있다. 또한, 이상에서 설명된 로봇 작업의 학습 방법 및 로봇 시스템은 여러가지 형태로 변형될 수 있다. 그 예로서, 상기에서 설명된 로봇 작업의 학습 방법 및 로봇 시스템은 1대 N의 학습이나 로봇 작업 제어에 적용될 수 있다. 이하, 도 8 및 도 9를 참조하여 본 발명의 변형예 또는 다른 실시예에 대하여 설명한다. 또한, 이하 설명되는 변형예 또는 실시예에서는 앞선 예와 동일 또는 유사한 구성에 대해서는 동일, 유사한 참조번호가 부여되고, 그 설명은 처음 설명으로 갈음된다. 도 8 및 도 9는 본 발명에 따른 로봇 작업의 학습 방법 및 로봇 시스템의 다른 실시예들을 나타내는 개념도들이 다. 본 도면들을 참조하면, 로봇 시스템은 복수의 로봇 장치(210a, 210b, 210c)를 구비할 수 있다. 먼저, 도 8을 참 조하면, 로봇 시스템은 학습부에 의하여 학습된 정책이 각각의 로봇 장치에서 상위 제어기로서 도출될 수 있다. 예를 들어, 로봇 시스템은, 도 2를 참조하여 설명한 로봇 시스템과 같이, 로봇 장치, 인터페이스 장치 및 데이 터베이스 중 적어도 하나를 포함할 수 있다. 또한, 이러한 로봇 시스템은 사용자와 작업환경과 조합되어, 도 4 내지 도 7a의 학습법을 구현하게 된다. 다만, 본 실시예에서는 상기 로봇 장치가 복수로 구비되며, 이러한 예로서 상기 로봇 시스템은 제1로봇장치 (210a), 제2로봇장치(210b) 및 제3로봇장치(210c)를 구비할 수 있다. 상기 제1로봇장치(210a), 제2로봇장치(210b) 및 제3로봇장치(210c)는 각각, 도 3을 참조하여 설명한 로봇장치의 구성요소들을 구비할 수 있다. 다만, 상기 제1로봇장치(210a), 제2로봇장치(210b) 및 제3로봇장치(210c)는 센싱 부, 상위 제어기, 하위 제어기는 공통으로 구비하나, 나머지 구성요소들은 선택적으로 구비하는 것도 가능하다. 이러한 예로서, 상기 제1로봇장치(210a), 제2로봇장치(210b) 및 제3로봇장치(210c)의 구동부는 서로 다른 구조 를 가질 수 있다. 구체적으로, 로봇장치들은 전문서비스용 로봇으로서, 제1로봇장치(210a)는 안내로봇, 제2로봇 장치(210b)는 소방로봇, 제3로봇장치(210c)는 배달로봇이 될 수 있다. 이 경우에, 본 발명의 지도단계 및 학습단계를 활용하여, 상기 제1로봇장치(210a), 제2로봇장치(210b) 및 제3로 봇장치(210c)가 각각 개별 작업에 적합하도록 학습될 수 있다. 따라서, 상기 제1로봇장치(210a), 제2로봇장치 (210b) 및 제3로봇장치(210c)의 상위 제어기들에는 서로 다른 정책이 탑재될 수 있다. 나아가, 상기 제1로봇장 치(210a), 제2로봇장치(210b) 및 제3로봇장치(210c)의 하위 제어기들도 각각 로봇의 용도에 따라서 적합하도록 구성될 수 있다. 다른 예로서, 도 9를 참조하면, 로봇 시스템은 학습부에 의하여 학습된 정책이 별도의 서버에서 제어기의 일부 로서 도출될 수 있다. 예를 들어, 로봇 시스템은, 도 2를 참조하여 설명한 로봇 시스템과 같이, 로봇 장치, 인터페이스 장치 및 데이 터베이스를 포함할 수 있다. 또한, 이러한 로봇 시스템은 사용자와 작업환경과 조합되어, 도 4 내지 도 7a의 학 습법을 구현하게 된다. 다만, 본 실시예에서는 서버가 복수의 로봇 장치를 제어하도록 이루어진다. 예를 들어, 상기 로봇 시스템 은 서버, 제1로봇장치(310a) 및 제2로봇장치(310b)를 구비할 수 있다. 이 경우에, 상위 제어기는 상위 제1제어기와 상위 제2제어기(314a)를 포함할 수 있다. 상기 상위 제1제어 기는 상기 서버에 위치하는 제어기로서, 도 4 내지 도 7a의 학습법에 의하여 도출될 수 있다. 이에 반해, 상기 상위 제2제어기(314a)는 상기 로봇 장치(310a)에 구비되는 제어기로서, 학습과 관계없이 기 프로그 래밍된 부분이 될 수 있다. 본 실시예에서는, 학습에 의하여 도출되는 정책은 상위 제1제어기로서 서버 에 위치하며, 무선 또는 유선 통신을 통하여 상기 제1로봇장치(310a) 및 제2로봇장치(310b)를 제어한다. 이 경우에, 서버에서 전달되는 작업수행의 명령이 상기 제1로봇장치(310a) 및 제2로봇장치(310b)의 상위 제2제어기(314a)에 전달되고, 상기 상위 제2제어기(314a)가 하위 제어기(314b)에 수행해야하는 동작 명령을 전 송한다. 예를 들어, 제1로봇장치(310a)에게 못을 박으라는 작업이 지정되면, 제1로봇장치(310a)는 로봇 장치의 상태 정 보와 작업환경의 상태 정보를 획득하고, 이러한 정보들을 서버로 전송한다. 상기 서버에서 상위 제1 제어기가 작업에 대한 명령을 생성하여, 상위 제2제어기(314a)로 전송한다. 이후에, 상기 상위 제2제어기 (314a)는 작업에 대한 명령을 상기 제1로봇 장치(310a)의 엔드 이펙터의 목표 위치, 엔드 이펙터의 자세, 매니 퓰레이터의 자세, 모터 토크, 모터 전류, 상태-모터 토크 함수 등 구체적인 형태로 변환하여 상기 하위 제어기 (314b)로 전달한다. 이 때에, 상기 서버는 제1로봇장치(310a)보다 제2로봇장치(310b)가 작업장소와 더 가 깝게 위치하고 있다는 것을 인지하여, 상기 제1로봇장치(310a) 대신에 상기 제2로봇장치(310b)에게 작업에 대한 명령을 전송할 수 있다. 상기 제2로봇장치(310b)는 상기 제1로봇장치를 예시하여 설명한 프로세스를 따라 해당 작업을 수행할 수 있다. 이와 같이, 본 실시예에서는 서버에서 다수의 로봇을 효율적으로 관리하는 것이 가능하 다. 또한, 본 실시예에서는 하나의 로봇 장치를 학습한 결과를 다른 로봇 장치에 복제하는 프로세스에 활용될 수 있 다. 예를 들어, 제1로봇장치를 이용하여 작업을 학습하고, 학습한 결과가 상위 제1제어기로 도출되고, 상기 상 위 제1제어기는 상기 제1로봇장치 및 제2로봇장치에 공통적으로 적용될 수 있다. 본 실시예에서 살펴본 것과 같이, 본 발명에 따른 로봇 작업의 학습 방법 및 로봇 시스템은, 1대 N의 로봇 학습 방법으로 변형이 가능하다. 이상에서 설명한 바와 같이, 본 발명에서는 로봇이 다양하고 복잡한 작업을 안전하게 수행할 수 있는 새로운 학 습 모델이나, 힘 정보를 기반으로 로봇 작업을 학습시키는 새로운 방법 및 시스템을 제공한다. 구체적으로, 본 발명은, 로봇과 외부의 환경 사이의 힘에 대한 정보를 기반으로 로봇 작업을 정의하여, 로봇이 다양하고 복잡한 작업을 용이하게 학습하도록 한다. 또한, 본 발명은 작업환경의 변화에 따라 로봇의 외력이 변 화하는 것에 보다 유연하게 대처하는 학습방법을 구현할 수 있다. 자세와 위치에 대한 정보를 이용하는 로봇 작업에 대한 정의는 외부 환경이 변화하면 새로운 모델링을 도출해야 만 하는 문제가 있으나, 본 발명에서는 힘을 고려한 새로운 형태로 로봇 작업을 정의함에 따라, 이러한 문제를 해소할 수 있게 된다. 또한, 본 발명은, 햅틱 기능을 갖춘 인터페이스 장치를 이용함에 따라, 전문가가 실제 환경에서 로봇에 가해지 는 힘을 피드백 받으면서 로봇 지도를 수행하게 된다. 즉, 다양한 환경에서 힘을 기반으로 한 작업의 지도가 수 행될 수 있다. 이 경우에, 본 발명은 로봇에서 실제 환경에서 작업에 필요한 정보들을 획득하여 학습에 활용하 며, 따라서 힘 정보를 필요로 하는 작업을 로봇에게 학습시킬 수 있게 된다. 또한, 본 발명은 전문가의 작업지시를 로봇에게 학습시킬 수 있어, 다관절 로봇에게 보다 효과적인 학습을 수행 하게 할 수 있다. 이를 통하여, 다관절 로봇의 높은 자유도를 이용하여 여러 작업을 다양한 상황에서 유연하게 대처하는 것이 가능하게 된다. 이 경우에, 로봇은 과거의 학습 정보를 함께 사용하여 새로운 작업을 학습 속도 도 빠르게 할 수 있으며, 나아가 일일이 프로그래밍을 하지 않고 햅틱을 이용하여 교시를 할 수 있기 때문에 학 습에 소요되는 시간과 노력을 줄일 수 있다. 또한, 본 발명에서는, 지도 단계에서 하위 제어기가 인터페이스 장치와 정보를 송수신하고, 학습단계에서 이 때 에 획득된 정보를 이용하여 상위 제어기가 도출되므로, 보다 효율적인 학습 및 로봇제어가 가능하게 된다. 이 경우에, 상위 제어기는 공통 미들웨어로서 구현되어, 서로 다른 로봇에 대한 작업 프로그램으로서 제공될 수 있 다. 이를 통하여, 로봇의 대체, 작업계획의 변경이나 로봇의 안전표준 준수가 보다 용이하게 수행될 수 있다 상기와 같이 설명된 로봇 작업의 학습 방법 및 로봇 시스템은 상기 설명된 실시예들의 구성과 방법이 한정되게 적용될 수 있는 것이 아니라, 상기 실시예들은 다양한 변형이 이루어질 수 있도록 각 실시예들의 전부 또는 일 부가 선택적으로 조합되어 구성될 수도 있다."}
{"patent_id": "10-2020-0095258", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a 및 도 1b는 본 발명에 따른 로봇 작업의 학습 방법 및 작업 실행을 설명하기 위한 개념도들이다. 도 2는 본 발명에 따른 로봇 시스템의 개요를 설명하기 위한 개념도이다. 도 3은 도 2의 로봇 장치의 구조를 설명하기 위한 블록도이다. 도 4는 본 발명에 따른 로봇 작업의 학습 방법을 대표적으로 나타내는 흐름도이다. 도 5a 및 도 5b는 각각 도 4의 지도단계에 대한 상세 흐름도와 지도의 개념을 설명하기 위한 개념도들이다. 도 6a 및 도 6b는 각각 도 4의 학습단계에 대한 상세 흐름도와 학습의 개념을 설명하기 위한 개념도들이다. 도 7a 및 도 7b는 각각 도 4의 실행단계에 대한 상세 흐름도와 실행의 개념을 설명하기 위한 개념도들이다.도 8 및 도 9는 본 발명에 따른 로봇 작업의 학습 방법 및 로봇 시스템의 다른 실시예들을 나타내는 개념도들이 다."}
