{"patent_id": "10-2017-0116178", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0029083", "출원번호": "10-2017-0116178", "발명의 명칭": "신경망 학습 방법 및 이를 적용한 장치", "출원인": "삼성전자주식회사", "발명자": "임태규"}}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "신경망 학습 방법에 있어서,복수의 클래스로 분류된 복수의 템플릿 이미지와 복수의 실제 이미지를 신경망(neural networks)에 입력하는 단계; 상기 복수의 클래스를 바탕으로 상기 복수의 템플릿 이미지에 대응되는 템플릿 특징 벡터와 상기 복수의 실제이미지에 대응되는 실제 특징 벡터가 산출되도록 상기 신경망을 학습하는 단계;를 포함하는 신경망 학습 방법."}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 입력하는 단계는,상기 복수의 템플릿 이미지를 템플릿 도메인에 대응되는 제1 신경망에 입력하고,상기 복수의 실제 이미지를 리얼 도메인에 대응되는 제2 신경망에 입력하는 것을 특징으로 하는 신경망 학습 방법."}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 템플릿 특징 벡터는 상기 제1 신경망에 상기 복수의 템플릿 이미지를 입력하여 획득된 특징 벡터이며,상기 실제 특징 벡터는 상기 제2 신경망에 상기 복수의 실제 이미지를 획득하여 획득된 특징 벡터인 것을 특징으로 하는 신경망 학습 방법."}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 템플릿 특징 벡터와 상기 실제 특징 벡터는 임베디드된 특징 공간(feature space)에 투사(projection)되는것을 특징으로 하는 신경망 학습 방법."}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 학습하는 단계는,상기 복수의 템플릿 특징 벡터가 상기 임베디드된 특징 공간 내에서 서로 멀리 떨어지도록 상기 제1 신경망을학습하는 것을 특징으로 하는 신경망 학습 방법."}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 학습하는 단계는,상기 복수의 실제 특징 벡터가 상기 임베디드된 특징 공간 내에 같은 클래스를 가지는 템플릿 특징 벡터와 가까워지도록 상기 제2 신경망을 학습하는 것을 특징으로 하는 신경망 학습 방법."}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서,공개특허 10-2019-0029083-3-상기 학습하는 단계는,상기 복수의 실제 특징 벡터가 상기 임베디드된 특징 공간 내에 다른 클래스를 가지는 템플릿 특징 벡터와 멀어지도록 상기 제2 신경망을 학습하는 것을 특징으로 하는 신경망 학습 방법."}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,실제 이미지를 획득하는 단계;상기 학습된 신경망에 상기 획득된 실제 이미지를 입력하여 상기 획득된 실제 이미지에 대응되는 특징 벡터를산출하는 단계; 및 상기 산출된 특징 벡터를 분류하여 상기 획득된 실제 이미지의 클래스를 인식하는 단계;를 포함하는 신경망 학습 방법."}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "신경망 학습을 위한 장치에 있어서,적어도 하나의 메모리; 및상기 적어도 하나의 메모리와 연결되어 상기 장치를 제어하는 프로세서;를 더 포함하고,상기 프로세서는,복수의 클래스로 분류된 복수의 템플릿 이미지와 복수의 실제 이미지를 신경망(neural networks)에 입력하고,상기 복수의 클래스를 바탕으로 상기 복수의 템플릿 이미지에 대응되는 템플릿 특징 벡터와 상기 복수의 실제이미지에 대응되는 실제 특징 벡터가 산출되도록 상기 신경망을 학습하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9에 있어서,상기 프로세서는,상기 복수의 템플릿 이미지를 템플릿 도메인에 대응되는 제1 신경망에 입력하고,상기 복수의 실제 이미지를 리얼 도메인에 대응되는 제2 신경망에 입력하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 템플릿 특징 벡터는 상기 제1 신경망에 상기 복수의 템플릿 이미지를 입력하여 획득된 특징 벡터이며,상기 실제 특징 벡터는 상기 제2 신경망에 상기 복수의 실제 이미지를 획득하여 획득된 특징 벡터인 것을 특징으로 하는 장치."}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 템플릿 특징 벡터와 상기 실제 특징 벡터는 임베디드된 특징 공간(feature space)에 투사(projection)되는것을 특징으로 하는 장치."}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 프로세서는,상기 복수의 템플릿 특징 벡터가 상기 임베디드된 특징 공간 내에서 서로 멀리 떨어지도록 상기 제1 신경망을공개특허 10-2019-0029083-4-학습하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 프로세서는,상기 복수의 실제 특징 벡터가 상기 임베디드된 특징 공간 내에 같은 클래스를 가지는 템플릿 특징 벡터와 가까워지도록 상기 제2 신경망을 학습하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 프로세서는,상기 복수의 실제 특징 벡터가 상기 임베디드된 특징 공간 내에 다른 클래스를 가지는 템플릿 특징 벡터와 멀어지도록 상기 제2 신경망을 학습하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2017-0116178", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서,상기 프로세서는,실제 이미지가 획득되면, 상기 학습된 신경망에 상기 획득된 실제 이미지를 입력하여 상기 획득된 실제 이미지에 대응되는 특징 벡터를 산출하고,상기 산출된 특징 벡터를 분류하여 상기 획득된 실제 이미지의 클래스를 인식하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2017-0116178", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 딥러닝 등의 기계 학습 알고리즘을 활용하는 인공지능(AI) 시스템 및 그 응용에 관련된 것이다. 특히, 복수의 클래스로 분류된 복수의 템플릿 이미지와 복수의 실제 이미지를 신경망(neural networks)에 입력하고, 복 수의 클래스를 바탕으로 복수의 템플릿 이미지에 대응되는 템플릿 특징 벡터와 복수의 실제 이미지에 대응되는 실제 특징 벡터가 산출되도록 신경망을 학습할 수 있다."}
{"patent_id": "10-2017-0116178", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 기계 학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 인공 지능(Artificial Intelligence, AI) 시스템 및 그 응용에 관한 것이다. 특히, 본 개시는 템플릿 이미지 및 실제 이미지를 이용하여 실제 이미지를 인식하여 분류하는 신경망을 학습하 는 방법에 관한 것이다."}
{"patent_id": "10-2017-0116178", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 규칙 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용 할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 규칙 기반 스마트 시스템은 점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다. 인공지능 기술은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분 야로 구성된다. 인공지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 시각적 이해 는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술 로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험정보 를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함 한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임을 제어하는 기술로서, 움직임 제어(항법, 충돌, 주행), 조작 제어(행동 제어) 등을 포함한다. 한편, 종래에는 이미지를 검색하기 위한 신경망(neural network)을 학습하기 위하여, 도 1에 도시된 바와 같이, 촬영된 실제 이미지를 학습 데이터로 신경망에 입력하여 신경망을 학습하였다. 이때, 신경망의 인식-분류 알고리즘의 성능을 높이기 위해서는 분류하고자 하는 클래스(혹은 유형)마다 학 습 데이터 양이 많아야 한다. 그러나, 일반적으로 촬영된 실제 이미지에 대한 데이터량에는 한계가 있는 문 제점이 존재한다. 뿐만 아니라, 특정 클래스의 학습 데이터 샘플이 많고, 특정 클래스의 학습 데이터 샘플이 부족할 경우, 신경망 의 인식-분류 알고리즘의 성능이 저하될 수 있다. 즉, 종래에는 특정 클래스의 학습 데이터의 샘플이 많다 고 하더라도 다른 클래스의 학습 데이터 샘플이 특정 수만큼 수집하지 못하는 경우, 신경망의 인식-분류 알 고리즘의 성능을 보정하지 못하는 문제점이 발생한다."}
{"patent_id": "10-2017-0116178", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 문제점을 해결하기 위한 것으로서, 본 개시의 목적은 템플릿 이미지 및 실제 이미지를 이용하 여 신경망을 학습하는 신경망 학습 방법 및 이를 적용한 장치를 제공함에 있다."}
{"patent_id": "10-2017-0116178", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따른, 신경망 학습 방법은 복수의 클래스로 분류된 복수의 템플릿 이미지와 복수의 실 제 이미지를 신경망(neural networks)에 입력하는 단계; 및 상기 복수의 클래스를 바탕으로 상기 복수의 템플릿 이미지에 대응되는 템플릿 특징 벡터와 상기 복수의 실제 이미지에 대응되는 실제 특징 벡터가 산출되도록 상기 신경망을 학습하는 단계;를 포함한다. 그리고, 상기 입력하는 단계는, 상기 복수의 템플릿 이미지를 템플릿 도메인에 대응되는 제1 신경망에 입력하고, 상기 복수의 실제 이미지를 리얼 도메인에 대응되는 제2 신경망에 입력할 수 있다. 또한, 상기 템플릿 특징 벡터는 상기 제1 신경망에 상기 복수의 템플릿 이미지를 입력하여 획득된 특징 벡터이 며, 상기 실제 특징 벡터는 상기 제2 신경망에 상기 복수의 실제 이미지를 획득하여 획득된 특징 벡터일 수 있 다. 그리고, 상기 템플릿 특징 벡터와 상기 실제 특징 벡터는 임베디드된 특징 공간(feature space)에 투사 (projection)될 수 있다. 또한, 상기 학습하는 단계는, 상기 복수의 템플릿 특징 벡터가 상기 임베디드된 특징 공간 내에서 서로 멀리 떨 어지도록 상기 제1 신경망을 학습할 수 있다. 그리고, 상기 학습하는 단계는, 상기 복수의 실제 특징 벡터가 상기 임베디드된 특징 공간 내에 같은 클래스를 가지는 템플릿 특징 벡터와 가까워지도록 상기 제2 신경망을 학습할 수 있다. 또한, 상기 학습하는 단계는, 상기 복수의 실제 특징 벡터가 상기 임베디드된 특징 공간 내에 다른 클래스를 가 지는 템플릿 특징 벡터와 멀어지도록 상기 제2 신경망을 학습할 수 있다. 그리고, 실제 이미지를 획득하는 단계; 상기 학습된 신경망에 상기 획득된 실제 이미지를 입력하여 상기 획득된 실제 이미지에 대응되는 특징 벡터를 산출하는 단계; 및 상기 산출된 특징 벡터를 분류하여 상기 획득된 실제 이미지의 클래스를 인식하는 단계;를 포함할 수 있다. 한편, 본 개시의 일 실시예에 따른, 신경망 학습을 위한 장치는, 적어도 하나의 메모리; 및 상기 적어도 하나의 메모리와 연결되어 상기 장치를 제어하는 프로세서;를 더 포함하고, 상기 프로세서는, 복수의 클래스로 분류된 복수의 템플릿 이미지와 복수의 실제 이미지를 신경망(neural networks)에 입력하고, 상기 복수의 클래스를 바 탕으로 상기 복수의 템플릿 이미지에 대응되는 템플릿 특징 벡터와 상기 복수의 실제 이미지에 대응되는 실제 특징 벡터가 산출되도록 상기 신경망을 학습할 수 있다. 그리고, 상기 프로세서는, 상기 복수의 템플릿 이미지를 템플릿 도메인에 대응되는 제1 신경망에 입력하고, 상 기 복수의 실제 이미지를 리얼 도메인에 대응되는 제2 신경망에 입력할 수 있다.또한, 상기 템플릿 특징 벡터는 상기 제1 신경망에 상기 복수의 템플릿 이미지를 입력하여 획득된 특징 벡터이 며, 상기 실제 특징 벡터는 상기 제2 신경망에 상기 복수의 실제 이미지를 획득하여 획득된 특징 벡터일 수 있 다. 그리고, 상기 템플릿 특징 벡터와 상기 실제 특징 벡터는 임베디드된 특징 공간(feature space)에 투사 (projection)될 수 있다. 또한, 상기 프로세서는, 상기 복수의 템플릿 특징 벡터가 상기 임베디드된 특징 공간 내에서 서로 멀리 떨어지 도록 상기 제1 신경망을 학습할 수 있다. 그리고, 상기 프로세서는, 상기 복수의 실제 특징 벡터가 상기 임베디드된 특징 공간 내에 같은 클래스를 가지 는 템플릿 특징 벡터와 가까워지도록 상기 제2 신경망을 학습할 수 있다. 또한, 상기 프로세서는, 상기 복수의 실제 특징 벡터가 상기 임베디드된 특징 공간 내에 다른 클래스를 가지는 템플릿 특징 벡터와 멀어지도록 상기 제2 신경망을 학습할 수 있다. 그리고, 상기 프로세서는, 실제 이미지가 획득되면, 상기 학습된 신경망에 상기 획득된 실제 이미지를 입력하여 상기 획득된 실제 이미지에 대응되는 특징 벡터를 산출하고, 상기 산출된 특징 벡터를 분류하여 상기 획득된 실 제 이미지의 클래스를 인식할 수 있다."}
{"patent_id": "10-2017-0116178", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같은 다양한 실시예에 의해, 특정 클래스에서 학습 데이터의 양이 적더라도 더욱 좋은 성능의 인식 -분류 알고리즘을 가지는 학습된 신경망을 획득할 수 있게 된다. 또한, 상술한 바와 같은 학습된 신경망을 이용하여 더욱 정확하게 실제 이미지를 인식하고 분류할 수 있게 된다."}
{"patent_id": "10-2017-0116178", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 다양한 실시 예가 첨부된 도면을 참조하여 기재된다. 그러나, 이는 본 개시에 기재된 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 개시의 실시 예의 다양한 변경(modifications), 균등물 (equivalents), 및/또는 대체물(alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 본 개시에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제 3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 부프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 이하에서는 도면을 참조하여 본 개시에 대해 상세히 설명하기로 한다. 도 2는 본 개시의 일 실시예에 따른, 템 플릿 이미지 및 실제 이미지를 이용하여 신경망을 학습하는 방법을 설명하기 위한 도면이다. 특히, 본 개시의 일 실시 우선, 전자 장치는 표지판 이미지를 분류하고 인식하기 위한 인식 알고리즘을 가지는 신경망을 학습할 수 있다. 이때, 여러 클래스(혹은 유형)의 표지판 이미지 중 일부 클래스(seen class)는 도로에서 쉽게 촬영될 수 있으나, 일부 클래스(unseen class)는 도로에서 쉽게 촬영할 수 없어 학습 데이터를 구하는데 한계가 존재한다. 따라서, 본 개시의 일 실시예에 따른, 전자 장치는 표지판 이미지를 분류하고 인식하기 위한 인식 알고리 즘을 가지는 신경망을 학습하기 위해 복수의 클래스로 분류된 템플릿 이미지(templet image) 및 복수의 클래스 에 대응되는 실제 이미지를 신경망에 입력할 수 있다. 이때, 템플릿 이미지는 표지판을 만들기 위해 이용되는 공식 이미지(officail image)로서, 인터넷을 통해 획득된 그림 이미지일 수 있다. 또한, 실제 이미지는 실제 도 메인(real adomain)에 포함된 이미지로서, 여러 사용자에 의해 촬영된 이미지일 수 있다. 특히, 전자 장치는 템플릿 이미지를 기준으로 실제 이미지를 분류하도록 신경망을 학습할 수 있다. 구체적 으로, 전자 장치는 복수의 클래스로 분류된 템플릿 이미지를 제1 신경망에 입력하여 템플릿 특징 벡터를 산출할 수 있다. 그리고, 전자 장치는 복수의 클래스에 대응되는 실제 이미지를 제2 신경망에 입력하여 템 플릿 특징 벡터를 산출할 수 있다. 이때, 제1 신경망 및 제2 신경망을 서로 다를 수 있으나, 이는 일 실시예에 불과할 뿐, 서로 같은 신경망일 수도 있다. 또한, 전자 장치는 복수의 템플릿 이미지 각각에 대응되는 템플릿 특징 벡터와 복수의 실제 이미지 각각에 대응되는 실제 특징 벡터를 임베디드된 특징 공간(embedded feature space)에 매핑할 수 있다. 이때, 임베디드 된 특징 공간은 특징 벡터들이 투사(projection)될 수 있는 N차원의 특징 공간일 수 있다. 그리고, 전자 장치는 복수의 클래스를 바탕으로 복수의 템플릿 이미지에 대응되는 템플릿 특징 벡터와 복 수의 실제 이미지에 대응되는 실제 특징 벡터가 산출되도록 제1 신경망 및 제2 신경망을 학습할 수 있다. 구체적으로, 전자 장치는 복수의 클래스를 가지는 템플릿 이미지 각각에 대응되는 템플릿 특징 벡터가 임 베디드된 특징 공간 내에서 서로 멀리 떨어지도록 제1 신경망을 학습할 수 있다. 또한, 전자 장치는 실제이미지에 대응되는 실제 특징 벡터가 대응되는 클래스를 가지는 템플릿 이미지의 템플릿 특징 벡터와 가까워지 도록 제2 신경망을 학습할 수 있다. 또한, 전자 장치는 실제 이미지들이 다른 클래스를 가지는 템플릿 이 미지의 특징 벡터와 멀어지도록 제2 신경망을 학습할 수 있다. 즉, 전자 장치는 복수의 클래스 템플릿 이미지에 대응되는 템플릿 특징 벡터가 기준점(혹은, anchor ponit)가 되고, 기준점을 기준으로 대응되는 클래스의 실제 특징 벡터가 위치하도록 제1 신경망 및 제2 신경망 을 학습할 수 있다. 그리고, 전자 장치는 학습된 제2 신경망을 이용하여 표지판 이미지를 인식할 수 있다. 구체적으로, 입력 데이터로서 촬영된 실제 이미지가 제2 신경망에 입력된 경우, 전자 장치는 촬영된 실제 이미지에 대응되는 특징 벡터를 산출할 수 있다. 그리고, 전자 장치는 분류기를 이용하여 특징 벡터의 클래스를 분류함으로써, 촬영된 실제 이미지의 클래스를 인식할 수 있게 된다. 상술한 바와 같이, 전자 장치가 클래스별로 특징 공간에 특징 벡터들이 위치하도록 신경망을 학습함으로써, 특정 클래스(예를 들어, unseen class)에서 적은 량의 학습 데이터를 가지더라도 더욱 정확한 인 식 결과를 획득할 수 있도록 신경망을 학습할 수 있다. 도 3은 본 개시의 일 실시예에 따른, 전자 장치의 구성을 나타내는 블럭도이다. 도 3에 도시된 바와 같이, 전자 장치는 프로세서 및 메모리를 포함할 수 있다. 이때, 전자 장치는 신경망을 학습할 수 있 는 컴퓨팅 장치로서, 서버, 데스크탑 PC, 노트북 PC, 태블릿 PC 등과 같은 다양한 전자 장치로 구현될 수 있다. 프로세서는 메모리에 저장된 프로그램을 이용하여 신경망을 학습할 수 있다. 특히, 프로세서는 표지판 이미지를 클래스별로 분류하고 인식하기 위한 신경망을 학습할 수 있다. 이때, 이미지를 인식하기 위한 신경망은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며 인간의 신경망의 뉴런(neuron)을 모의 하는, 가중치를 가지는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 노드들은 뉴런이 시냅스 (synapse)를 통하여 신호를 주고 받는 뉴런의 시냅틱(synaptic) 활동을 모의하도록 각각 연결 관계를 형성할 수 있다. 이때, 신경망은 신경망 모델에서 발전한 딥 러닝 모델을 포함할 수 있다. 딥 러닝 모델에서 복수의 네트 워크 노드들은 서로 다른 깊이(또는, 레이어)에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데이터를 주고 받을 수 있다. 신경망 모델의 예에는 DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 등이 있을 수 있으나 이에 한정되지 않는다. 구체적으로, 프로세서는 복수의 클래스로 분류된 복수의 템플릿 이미지와 복수의 실제 이미지를 신경망에 입력하고, 복수의 클래스를 바탕으로 상기 복수의 템플릿 이미지에 대응되는 템플릿 특징 벡터와 복수의 실제 이미지에 대응되는 실제 특징 벡터가 산출되도록 신경망을 학습할 수 있다. 이 구체적으로, 프로세서는 복수의 템플릿 이미지를 템플릿 도메인에 대응되는 제1 신경망에 입력하여 템플릿 특징 벡터를 획득할 수 있으며, 복수의 실제 이미지를 리얼 도메인에 대응되는 제2 신경망에 입력하여 실제 특 징 벡터를 획득할 수 있다. 이때, 템플릿 특징 벡터와 실제 특징 벡터는 임베디드된 특징 공간(feature space) 에 투사(projection)될 수 있다. 그리고, 프로세서는 복수의 템플릿 특징 벡터가 임베디드된 특징 공간 내에서 서로 멀리 떨어지도록 제1 신경망을 학습할 수 있다. 또한, 프로세서는 복수의 실제 특징 벡터가 임베디드된 특징 공간 내에 같은 클 래스를 가지는 템플릿 특징 벡터와 가까워지도록 제2 신경망을 학습할 수 있다. 또한, 프로세서는 복수의 실제 특징 벡터가 임베디드된 특징 공간 내에 다른 클래스를 가지는 템플릿 특징 벡터와 멀어지도록 제2 신경망 을 학습할 수 있다. 그리고, 실제 이미지가 획득되면, 프로세서는 학습된 신경망(특히, 제2 신경망)에 획득된 실제 이미지를 입력하여 획득된 실제 이미지에 대응되는 특징 벡터를 산출하고, 산출된 특징 벡터를 분류하여 획득된 실제 이 미지의 클래스를 인식할 수 있다. 이때, 프로세서는 산출된 특징 벡터를 분류하기 위하여, support vector machine (SVM)를 이용할 수 있으나, 이는 일 실시예에 불과할 뿐, multi layer perceptron (MLP)와 같은 다른 분류기를 이용할 수 있다. 한편, 상술한 바와 같은 기능을 수행하는 프로세서는 기존의 범용 프로세서(예를 들어, CPU)일 수 있으나, 이는 일 실시예 불과할 뿐, 인공지능 학습을 위한 AI 전용 프로세서(예를 들어, GPU)일 수 있다. 메모리는 전자 장치의 동작에 필요한 각종 프로그램 및 데이터를 저장할 수 있다. 메모리는 비 휘발성 메모리, 휘발성 메모리, 플래시메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 메모리는 프로세서에 의해 액세스되며, 프로세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 본 개시에서 메모리라는 용어는 메모리, 프로세 서 내 롬(미도시), 램(미도시) 또는 전자 장치에 장착되는 메모리 카드(미도시)(예를 들어, micro SD 카드, 메모리 스틱)를 포함할 수 있다. 또한, 메모리에 본 개시의 일 실시예에 따른, 이미지 분류/인식을 위하여 학습 알고리즘을 통해 생성된 신 경망 모델을 저장할 수도 있다. 도 4는 본 개시의 일 실시예에 따른, 전자 장치의 프로세서의 구성을 나타내는 블럭도이다. 도 4에 도시된 바와 같이, 프로세서는 데이터 학습부 및 데이터 인식부를 포함한다. 데이터 학습부는 이미지 분류/인식을 위한 신경망을 학습할 수 있다. 데이터 학습부는 이미지 분류/ 인식을 판단하기 위하여 어떤 학습 데이터를 이용할지, 학습 데이터를 이용하여 이미지를 어떻게 분류/인식할지 에 관한 기준을 학습할 수 있다. 데이터 학습부는 학습에 이용될 학습 데이터를 획득하고, 획득된 학습 데 이터를 후술할 이미지 인식/분류를 위한 신경망 모델에 적용함으로써, 신경망 모델을 학습할 수 있다. 특히, 본 개시의 일 실시예에 따른, 데이터 학습부는 템플릿 이미지 및 실제 이미지를 기반으로 신경망 모델을 학습 할 수 있다. 데이터 인식부는 실제로 촬영된 실제 이미지를 이용하여 이미지(혹은 이미지에 포함된 오브젝트)를 분류하 고 인식할 수 있다. 데이터 인식부는 학습된 신경망 모델을 이용하여, 소정의 실제 이미지로부터 실제 이 미지의 클래스를 분류하고 인식할 수 있다. 데이터 인식부는 학습에 의한 기설정된 기준에 따라 소정의 실 제 이미지를 획득하고, 획득된 실제 이미지를 입력 값으로 하여 신경망 모델을 이용함으로써, 실제 이미지의 클 래스를 분류하고 인식할 수 있다. 또한, 획득된 실제 이미지를 입력 값으로 하여 신경망 모델에 의해 출력된 결 과값은, 신경망 모델을 갱신하는데 이용될 수 있다. 데이터 학습부 및 데이터 인식부 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전 자 장치에 탑재될 수 있다. 예를 들어, 데이터 학습부 및 데이터 인식부 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로 세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각 종 전자 장치에 탑재될 수도 있다. 이 경우, 데이터 학습부 및 데이터 인식부는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별 개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 학습부 및 데이터 인식부 중 하나는 전자 장치에 포함되고, 나머지 하나는 서버에 포함될 수 있다. 또한, 데이터 학습부 및 데이터 인식부 는 유선 또는 무선으로 통하여, 데이터 학습부가 구축한 신경망 모델 정보를 데이터 인식부로 제공할 수도 있고, 데이터 인식부로 입력된 데이터가 추가 학습 데이터로서 데이터 학습부로 제공될 수도 있다. 한편, 데이터 학습부 및 데이터 인식부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 학습부 및 데이터 인식부 중 적어도 하나가 소프트웨어 모듈(또는, 인스터력션(instruction) 포함하 는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가 능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프 트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플 리케이션에 의해 제공될 수 있다. 도 5 및 도 6은 본 개시의 일 실시예에 따른, 데이터 학습부 및 데이터 인식부의 구성을 나타내는 블 럭도이다. 도 5를 참조하면, 일부 실시예에 따른 데이터 학습부는 학습 데이터 획득부(111-1) 및 모델 학습부(111- 4)를 포함할 수 있다. 또한, 데이터 학습부는 학습 데이터 전처리부(111-2), 학습 데이터 선택부(111-3) 및 모델 평가부(111-5) 중 적어도 하나를 선택적으로 더 포함할 수 있다.학습 데이터 획득부(111-1)는 이미지의 클래스를 분류하고 인식하기 위한 신경망 모델에 필요한 학습 데이터를 획득할 수 있다. 특히, 본 개시의 학습 데이터 획득부(111-1)는 학습 데이터로서, 제1 신경망 모델에 입력하기 위한 템플릿 이미지와 제2 신경망 모델에 입력하기 위한 실제 이미지를 획득할 수 있다. 모델 학습부(111-4)는 학습 데이터를 이용하여, 신경망 모델이 소정의 이미지의 클래스를 어떻게 분류할지에 관 한 판단 기준을 갖도록 학습시킬 수 있다. 구체적으로, 모델 학습부(111-4)는 템플릿 이미지를 신경망 모델에 입력하여 획득한 템플릿 특징 벡터를 특징 공간의 기준점으로 설정하고, 실제 이미지를 신경망 모델에 입력하여 획득한 실제 특징 벡터가 클래스별로 특징 공간에 위치하도록 신경망 모델을 학습할 수 있다. 이때, 모델 학습 부(111-4)는 학습 데이터 중 적어도 일부를 판단 기준으로 이용하는 지도 학습(supervised learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 또는, 모델 학습부(111-4)는, 예를 들어, 별다른 지도 없이 학습 데이터를 이 용하여 스스로 학습함으로써, 상황의 판단을 위한 판단 기준을 발견하는 비지도 학습(unsupervised learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 또한, 모델 학습부(111-4)는, 예를 들어, 학습에 따른 상황 판단의 결과가 올바른 지에 대한 피드백을 이용하는 강화 학습(reinforcement learning)을 통하여, 신경망 모델을 학습 시킬 수 있다. 또한, 모델 학습부(111-4)는, 예를 들어, 오류 역전파법(error back-propagation) 또는 경사 하 강법(gradient descent)을 포함하는 학습 알고리즘 등을 이용하여 신경망 모델을 학습시킬 수 있다 신경망 모델이 학습되면, 모델 학습부(111-4)는 학습된 신경망 모델을 저장할 수 있다. 이 경우, 모델 학습부 (111-4)는 학습된 신경망 모델을 전자 장치의 메모리에 저장할 수 있다. 또는, 모델 학습부(111-4)는 학습된 신경망 모델을 전자 장치와 유선 또는 무선 네트워크로 연결되는 서버의 메모리에 저장할 수도 있 다. 데이터 학습부는 인식 모델의 분석 결과를 향상시키거나, 인식 모델의 생성에 필요한 자원 또는 시간을 절 약하기 위하여, 학습 데이터 전처리부(111-2) 및 학습 데이터 선택부(111-3)를 더 포함할 수도 있다. 학습 데이터 전처리부(111-2)는 상황 판단을 위한 학습에 획득된 데이터가 이용될 수 있도록, 획득된 데이터를 전처리할 수 있다. 학습 데이터 전처리부(111-2)는 모델 학습부(111-4)가 이미지 인식을 위한 학습을 위하여 획 득된 학습 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다. 학습 데이터 선택부(111-3)는 학습 데이터 획득부(111-1)에서 획득된 학습 데이터 또는 학습 데이터 전처리부 (111-2)에서 전처리된 학습 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 선택된 학습 데이터는 모 델 학습부(111-4)에 제공될 수 있다. 학습 데이터 선택부(111-3)는 기 설정된 선별 기준에 따라, 획득되거나 전 처리된 데이터 중에서 학습에 필요한 학습 데이터를 선택할 수 있다. 예를 들어, 학습 데이터 선택부(111-3)는 획득된 실제 이미지 중 표지판이 표시된 영역을 검출하여 표지판 영역에 대한 데이터만을 학습 데이터로 선택할 수 있다. 데이터 학습부는 신경망 모델의 분석 결과를 향상시키기 위하여, 모델 평가부(111-5)를 더 포함할 수도 있 다. 모델 평가부(111-5)는 신경망 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 분석 결과가 소정 기준을 만족하지 못하는 경우, 모델 학습부(111-4)로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가 데이 터는 인식 모델을 평가하기 위한 기 정의된 데이터일 수 있다. 예를 들어, 모델 평가부(111-5)는 평가 데이터에 대한 학습된 인식 모델의 분석 결과 중에서, 분석 결과가 정확 하지 않은 평가 데이터의 개수 또는 비율이 미리 설정된 임계치를 초과하는 경우 소정 기준을 만족하지 못한 것으로 평가할 수 있다. 도 6을 참조하면, 일부 실시예에 따른 데이터 인식부는 인식 데이터 획득부(112-1) 및 인식 결과 제공부 (112-4)를 포함할 수 있다. 또한, 데이터 인식부는 인식 데이터 전처리부(112-2), 인식 데이터 선택부(112-3) 및 모델 갱신부(112-5) 중 적어도 하나를 선택적으로 더 포함할 수 있다. 인식 데이터 획득부(112-1)는 이미지의 클래스를 분류하여 이미지를 인식하기 위해 필요한 데이터를 획득할 수 있다. 예를 들어, 인식 데이터 획득부(112-1)는 차량 내에 포함된 카메라를 이용하여 촬영된 이미지 데이터를 획득할 수 있다. 인식 결과 제공부(112-4)는 인식 데이터 획득부(112-1)에서 획득된 이미지를 입력값으로 학습된 신경망 모델에 적용하여 특징 벡터를 획득하고, 획득된 특징 벡터를 바탕으로 이미지의 클래스를 판단하고 이미지를 인식할 수 있다. 인식 결과 제공부(112-4)는 후술할 인식 데이터 전처리부(112-2) 또는 인식 데이터 선택부(112-3)에 의해 선택된 데이터를 입력 값으로 신경망 모델에 적용하여 분석 결과를 획득할 수 있다. 분석 결과는 신경망 모델에 의해 결정될 수 있다. 일 실시예로, 인식 결과 제공부(112-4)는 인식 데이터 획득부(112-1)에서 획득한 표지판을 포함하는 이미지 데 이터를 학습된 신경망 모델 적용하여 표지판의 클래스에 대한 정보를 획득(또는, 추정)할 수 있다. 데이터 인식부는 신경망 모델의 분석 결과를 향상시키거나, 분석 결과의 제공을 위한 자원 또는 시간을 절 약하기 위하여, 인식 데이터 전처리부(112-2) 및 인식 데이터 선택부(112-3)를 더 포함할 수도 있다. 인식 데이터 전처리부(112-2)는 이미지에 포함된 표지판의 클래스를 분류하기 위해 획득된 데이터가 이용될 수 있도록, 획득된 데이터를 전처리할 수 있다. 인식 데이터 전처리부(112-2)는 인식 결과 제공부(112-4)가 이미지 에 포함된 표지판의 클래스를 분류하기 위해 획득된 데이터가 이용될 수 있도록, 획득된 데이터를 기 정의된 포 맷으로 가공할 수 있다. 인식 데이터 선택부(112-3)는 인식 데이터 획득부(112-1)에서 획득된 데이터 또는 인식 데이터 전처리부(112- 2)에서 전처리된 데이터 중에서 이미지의 클래스를 분류하기 위해 필요한 데이터를 선택할 수 있다. 선택된 데 이터는 인식 결과 제공부(112-4)에게 제공될 수 있다. 예를 들어, 인식 데이터 선택부(112-3)는 촬영된 이미지 로부터 표지판 영역을 검출하고, 검출된 표지판 영역에 대한 데이터를 입력 데이터로 선택할 수 있다. 모델 갱신부(112-5)는 인식 결과 제공부(112-4)에 의해 제공되는 분석 결과에 대한 평가에 기초하여, 인식 모델 이 갱신되도록 제어할 수 있다. 예를 들어, 모델 갱신부(112-5)는 인식 결과 제공부(112-4)에 의해 제공되는 분 석 결과를 모델 학습부(112-4)에게 제공함으로써, 모델 학습부(112-4)가 인식 모델을 추가 학습 또는 갱신하도 록 요청할 수 있다. 도 7 및 도 8은 본 개시의 일 실시예에 따른, 템플릿 이미지와 실제 이미지를 이용하여 신경망을 학습하기 위한 쿼드러플 구조를 설명하기 위한 도면이다. 우선, 템플릿 이미지와 실제 이미지를 이용하여 신경망을 학습하기 위하여, 전자 장치는 쿼드러플 구조의 신경망 모델을 이용할 수 있다. 이때, 제1 신경망 모델 및 제2 신경망 모델은 템플릿 도메인의 이미지를 입력받 는 신경망 모델이며, 제3 신경망 모델 및 제4 신경망 모델은 리얼 도메인의 이미지를 입력받는 신경망 모델일 수 있다. 구체적으로, 제1 신경망 모델은 제1 클래스의 템플릿 이미지를 입력받기 위한 신경망 모델이며, 제2 신경망 모델은 제2 클래스의 템플릿 이미지를 입력받기 위한 신경망 모델이며, 제3 신경망 모델은 제1 클래스의 실제 이미지를 입력받기 위한 신경망 모델이며, 제4 신경망 모델은 제2 클래스의 실제 이미지를 입력받기 위한 신경망 모델일 수 있다. 여기서, 템플릿 이미지의 특징과 실제 이미지의 특징 사이에 차이가 존재하므로, 제1 신경망 모델 및 제2 신경 망 모델은 같은 신경망 모델일 수 있으며, 제3 신경망 모델 및 제4 신경망 모델은 같은 신경망 모델일 수 있다. 즉, 템플릿 이미지는 노이즈가 거의 없는 그림 이미지로서, 간단한 신경망 모델을 이용할 수 있으나, 실제 이미 지는 많은 노이즈로 인해 더욱 복잡한 신경망 모델을 이용할 수 있다. 그러나, 템플릿 도메인의 신경망 모델과 리얼 도메인의 신경망 모델이 서로 상이한 것은 일 실시예에 불과할 뿐, 4개의 신경망 모델이 모두 같은 신경망 모델일 수 있다. 한편, 쿼드러플 구조는 두 개의 이미지 데이터 세트를 고려할 수 있다. 템플릿 세트는 일 수 있으며, 이때, 는 대표적인 템플릿 이미지일 수 있고, 는 대응되는 클래스 라 벨일 수 있다. 실제 이미지 데이터 세트는 일 수 있으며, 는 k 클래스의 실제 이미 지 세트일 수 있다. 간단히 말해, 여기서, 는 클래스-k에 라벨링된 샘플을 말할 수 있다. 또한, 가 유클리디안 엠베딩(Euclidean embedding)을 의미할 수 있다. 즉, 는 고차원 벡터 x를 D- 차원의 특징 공간( )에 매핑하는 것을 의미한다. 본 개시는 템플릿 이미지를 통해 획득된 특징 벡터는 특징 공간(feacher space)에서 기준점(또는 anchor point) 역할을 하고, 기준점 주위에 실제 이미지를 통해 획득된 특징 벡터들을 클러스터링하기 위해 템플릿 이미지를 통해 획득된 특징 벡터와 실제 이미지를 통해 획득된 특징 벡터를 같은 특징 공간에 임베디드할 수 있다. 이때, 임베디드된 특징 공간 내에서는 아래와 같은 두 가지 특징을 가질 수 있다. 1) 다른 클래스의 템플릿 이미지를 통해 획득된 특징값이 기준점 역할을 하기 위하여 임베디드된 특징 공간 내 에서는 멀리 떨어져 있다. 2) 실제 이미지를 통해 획득된 특징값은 대응되는 클래스를 가지는 템플릿 이미지를 통해 획득된 특징값 주변에 매핑될 수 있다. 본 개시의 일 실시예로, 서로 다른 클래스를 가지는 두 개의 템플릿 이미지와 두 개의 템플릿 이미지 각각의 클 래스에 대응되는 두 개의 실제 이미지를 포함하는 쿼드러플 엘리먼트(quadruple element)가 정의될 수 있다. 예 를 들어, 두 개의 클래스가 각각 A,B라고 할 때, 쿼드러플 엘리먼트는 (TA,TB,XA,XB)로 정의될 수 있다. 이러한 쿼드러플 엘리먼트를 통해 획득된 특징 벡터들은 아래와 같은 속성을 가지고 있다. 1) 임베디드된 특징 공간에서 TA를 통해 획득된 특징 벡터는 TB를 통해 획득된 특징 벡터와 멀리 떨어져 있다. 2) 임베디드된 특징 공간에서 XA를 통해 획득된 특징 벡터는 XB를 통해 획득된 특징 벡터와 멀리 떨어져 있다. 3) 임베디드된 특징 공간에서 XA(또는 XB)를 통해 획득된 특징 벡터는 TA(또는 TB)를 통해 획득된 특징 벡터와 가까이 있다. 4) 임베디드된 특징 공간에서 TA(또는 TB)를 통해 획득된 특징 벡터는 XB(또는 XA)를 통해 획득된 특징 벡터와 멀리 떨어져 있다. 쿼드러플 구조는 템플릿 이미지에 의해 획득된 특징 벡터와 실제 이미지에 의해 획득된 특징 벡터를 공통의 메 트릭 공간()에 임베딩하도록 학습할 수 있다. 비선형적 매핑을 위하여, 임베딩(f)는 신경망으로서 모델링 되고, 가중치 파라미터의 세트는 를 의미할 수 있다. 여기서, 두 개의 서로 다른 도메인 데이터(템플릿 도 메인, 실제 도메인)가 다루어지기 때문에, 두 개의 신경망이 이용될 수 있다. 이때, 템플릿 도메인을 위한 신경 망은 로 표현될 수 있고, 실제 도메인을 위한 신경망은 로 표현될 수 있다. 즉, 도 7에 도시된 바와 같이, 제1 신경망 모델은 로 표현될 수 있으며, 제2 신경망 모델 은 로 표현될 수 있으며, 제3 신경망 모델은 로 표현될 수 있으며, 제4 신경망 모델은 로 표현될 수 있다. 제안된 쿼드러플 네트워크 Q는 각 쌍 내에서 가중치를 공유하는 두 개의 쌍둥이 네트워크로 구성될 수 있다. 하 나는 템플릿 이미지로부터 특징 벡터를 획득하기 위한 신경망이며, 다른 하나는 실제 이미지로부터 특징 벡터를 획득하기 위한 신경망일 수 있다. 각각의 도메인에 4개의 이미지가 입력되면, 아래와 같은 특징 벡터들의 세트가 산출될 수 있다. 수학식 1"}
{"patent_id": "10-2017-0116178", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "산출된 네 개의 특징 벡터( )는 각각 임베디드된 특징 공간 내에 매핑될 수 있다. 그리고, 전자 장치는 상술한 신경망을 학흡하기 위해 손실 함수(loss function)을 이용할 수 있다. 네 개의 특징 벡터( )가 출력된 경우, 네 개의 특징 벡터들 사이에는 도 8에 도시된 바와 같 이, 6개의 관계가 존재할 수 있으며, 6 개의 관계에 대응되는 유클리디안 특징 거리(Euclidean feature distance) ( )를 산출할 수 있다. 이때, 로서, 두 벡터 사이의 거리를 의미할 수 있다. 그리고, 전자 장치는 앞서 설명한 바와 같이, 같은 라벨의 특징 벡터들(즉, 같은 클래스의 특징 벡터들)이 서로 가까워지도록 손실 함수 ( )를 적용할 수 있고, 다른 라벨의 특징벡터들이 서로 멀어지도록 손실 함수 를 적용할 수 있다. 손실 함수 h는 hinge loss를 적용하고 m은 hinge loss에 적용되는 margin 크기를 의미한다. 이때, 전자 장치는 최대 6개의 손실 함수를 이용할 수 있으나, 최소로 필요한 손실 함수는 3개일 수 있다. 이때, 최종 손실 함수는 아래와 같을 수 있다. 수학식 2"}
{"patent_id": "10-2017-0116178", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "전자 장치는 상술한 손실 함수를 이용하여 앞서 설명한 바와 같이, 신경망 모델을 학습할 수 있다. 상술한 바와 같은 학습 과정을 통해, 전자 장치는 실제 이미지(혹은 실제 이미지에 포함된 오브젝트)의 클 래스를 분류하기 위한 신경망 모델(특히, 제3 및 제4 신경망 모델)을 획득할 수 있다. 그리고, 전자 장치는 학습된 신경망 모델에 입력 데이터로서 촬영된 이미지를 입력하여 특징 벡터를 획득 할 수 있다. 그리고, 전자 장치는 분류기를 이용하여 획득된 특징 벡터의 클래스를 분류하여 촬영된 이미지의 클래스를 분류할 수 있게 된다. 도 9는 본 개시의 일 실시예에 따른, 신경망 학습 방법을 설명하기 위한 흐름도이다. 전자 장치는 복수의 클래스로 분류된 복수의 템플릿 이미지와 복수의 실제 이미지를 신경망에 입력할 수 있다(S910). 이때, 전자 장치는 복수의 템플릿 이미지를 템플릿 도메인에 대응되는 제1 신경망에 입력할 수 있으며, 복수의 실제 이미지를 리얼 도메인에 대응되는 제2 신경망에 입력할 수 있다. 전자 장치는 복수의 클래스를 바탕으로 복수의 템플릿 이미지에 대응되는 템플릿 특징 벡터와 복수의 실제 이미지에 대응되는 실제 특징 벡터가 산출되도록 신경망을 학습할 수 있다(S920). 구체적으로, 전자 장치 는 제1 신경망에 의해 획득된 텝플릿 특징 벡터와 제2 신경망에 의해 획득된 실제 특징 벡터를 임베디드된 특징 공간(feature space)에 투사(projection)할 수 있다. 그리고, 전자 장치는 복수의 템플릿 특징 벡터가 임 베디드된 특징 공간 내에서 서로 멀리 떨어지도록 제1 신경망을 학습할 수 있으며, 복수의 실제 특징 벡터가 임 베디드된 특징 공간 내에 같은 클래스를 가지는 템플릿 특징 벡터와 가까워지도록 제2 신경망을 학습할 수 있으 며, 복수의 실제 특징 벡터가 임베디드된 특징 공간 내에 다른 클래스를 가지는 템플릿 특징 벡터와 멀어지도록 제2 신경망을 학습할 수 있다. 그리고, 전자 장치는 학습된 신경망을 이용하여 실제 이미지를 분류하고 인식할 수 있다. 도 10은 일부 실시예에 따른 전자 장치 및 서버가 서로 연동함으로써 데이터를 학습하고 인식하는 예시를 나타내는 도면이다. 도 10을 참조하면, 전자 장치는 이미지의 클래스를 분류하여 이미지를 인식하도록 신경망을 학습할 수 있 으며, 외부 장치는 전자 장치에 의해 학습된 신경망 모델에 기초하여 획득된 이미지를 인식할 수 있 다. 이때, 전자 장치는 서버일 수 있으며, 외부 장치는 차량에 부착된 컴퓨팅 장치일 수 있으나, 이 에 한정되는 것은 아니다. 이 경우, 전자 장치는 도 5에 도시된 데이터 학습부의 기능을 수행할 수 있다. 전자 장치의 모 델 학습부(111-4)는 이미지를 인식하기 위하여 어떤 데이터를 이용할지, 데이터를 이용하여 이미지를 어떻게 인 식할지에 관한 기준을 학습할 수 있다. 모델 학습부(111-4)는 학습에 이용될 학습 데이터를 획득하고, 획득된 학습 데이터를 신경망 모델에 적용함으로써, 이미지 인식을 위한 기준을 학습할 수 있다. 또한, 외부 장치의 인식 결과 제공부는 인식 데이터 선택부에 의해 선택된 이미지 데이터를 전자 장치에 의해 생성된 신경망 모델에 적용하여 이미지를 인식할 수 있다. 예를 들어, 인식 결과 제공부 는 인식 데이터 선택부에 의해 선택된 이미지 데이터를 전자 장치에게 전송하고, 전자 장치 가 인식 데이터 선택부에 의해 선택된 이미지 데이터를 신경망 모델에 적용하여 이미지를 인식할 수 있다. 또한, 인식 결과 제공부는 전자 장치에 의해 생성된 이미지 인식 결과를 전자 장치로부"}
{"patent_id": "10-2017-0116178", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "터 수신할 수 있다. 또는, 외부 장치의 요약 결과 제공부는 전자 장치에 의해 생성된 신경망 모델을 전자 장치로부터 수신하고, 수신된 신경망 모델을 이용하여 이미지를 인식할 수 있다. 이 경우, 외"}
{"patent_id": "10-2017-0116178", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "부 장치의 요약 결과 제공부는 인식 데이터 선택부에 의해 선택된 이미지 데이터를 전자 장 치로부터 수신된 신경망 모델에 적용하여 이미지를 인식할 수 있다. 본 개시의 다양한 실시예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명령어를 호 출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시예들에 따른 전자 장치(예: 전자 장치(A)) 를 포함할 수 있다. 상기 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 상기 프로세서의 제어하 에 다른 구성요소들을 이용하여 상기 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프리 터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non- transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하지 않 으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 일시예에 따르면, 본 개시에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경 우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다 양한 실시예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차 적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다."}
{"patent_id": "10-2017-0116178", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래의 신경망을 학습하는 방법을 설명하기 위한 도면, 도 2는 본 개시의 일 실시예에 따른, 템플릿 이미지 및 실제 이미지를 이용하여 신경망을 학습하는 방법을 설명 하기 위한 도면, 도 3은 본 개시의 일 실시예에 따른, 전자 장치의 구성을 나타내는 블럭도 도 4는 본 개시의 일 실시예에 따른, 전자 장치의 프로세서의 구성을 나타내는 블럭도, 도 5는 본 개시의 일 실시예에 따른, 학습부의 구성을 나타내는 블럭도, 도 6은 본 개시의 일 실시예에 따른, 인식부의 구성을 나타내는 블럭도, 도 7은 본 개시의 일 실시예에 따른, 템플릿 이미지와 실제 이미지를 이용하여 신경망을 학습하기 위한 쿼드러 플 구조를 설명하기 위한 도면, 도 8은 본 개시의 일 실시예에 따른, 임베디드된 특징 공간 내에서 특징값 매핑을 설명하기 위한 도면, 도 9는 본 개시의 일 실시예에 따른, 신경망 학습 방법을 설명하기 위한 흐름도, 도 10은 본 개시의 일 실시예에 따른, 다양한 실시예에 따른, 학습부 및 인식부를 나타내는 블럭도, 도 11은 본 개시의 다른 실시예에 따른, 인식 모델을 이용하여 이미지를 인식하기 위한 전자 장치의 구성을 나 타내느 블럭도이다."}
