{"patent_id": "10-2023-0071141", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0084449", "출원번호": "10-2023-0071141", "발명의 명칭": "신경 프로세싱 유닛", "출원인": "주식회사 딥엑스", "발명자": "박정부"}}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 모드 또는 제2 모드를 선택하도록 구성된 모드 선택부(mode selector) 및 복수의 PE(Processing Element) 행들 및 복수의 PE 열들을 포함하는 복수의 프로세싱 엘리먼트들을 포함하고,상기 제1 모드에 할당된 제1 PE 행들의 개수는 상기 제2 모드에 할당된 제2 PE 행들의 개수보다 많고, 상기 제1 PE 행들은 상기 제1 모드에 응답하여 제1 합성곱 연산을 수행하도록 구성되고, 상기 제2 PE 행들은 상기 제2 모드에 응답하여 상기 제1 합성곱 연산과 다른 제2 합성곱 연산을 수행하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 합성곱 연산은, 스탠다드(standard) 합성곱 연산 또는 포인트와이즈(point-wise) 합성곱 연산을 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제2 합성곱 연산은, 뎁스와이즈(depth-wise) 합성곱 연산을 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,지연 유닛은 상기 제2 PE 행들의 인접한 2개의 PE 행들의 인접한 2개의 PE들을 연결하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,멀티플렉서는 상기 제2 PE 행들의 인접한 2개의 PE 행들의 인접한 2개의 PE들을 연결하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,지연 유닛을 더 포함하고, 상기 복수의 프로세싱 엘리먼트들 중 하나의 프로세싱 엘리먼트는 브랜치(branch)를 포함하는 제1 입력단, 제2입력단 및 출력단을 포함하고, 상기 브랜치는 상기 지연 유닛과 연결되는, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,멀티플렉서를 더 포함하고, 상기 멀티플렉서는, 상기 모드 선택부로부터 상기 제1 모드 또는 상기 제2 모드를 포함하는 선택 신호를 입력받공개특허 10-2023-0084449-3-도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 모드 또는 제2 모드를 선택하도록 구성된 모드 선택부(mode selector) 및 복수의 PE(Processing Element) 행들 및 복수의 PE 열들을 포함하는 복수의 프로세싱 엘리먼트 어레이를 포함하고,상기 제1 모드에 할당된 상기 프로세싱 엘리먼트 어레이의 제1 영역은, 상기 제2 모드에 할당된 상기 프로세싱엘리먼트 어레이의 제2 영역 보다 크고, 상기 제1 영역과 상기 제2 영역은 서로 중첩(overlap) 되도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 제1 영역의 상기 복수의 PE 행들의 개수는, 상기 제2 영역의 상기 복수의 PE 행들의 개수보다 많은, 신경프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 제1 영역의 상기 복수의 PE 행들은, 상기 제1 모드에 응답하여 제1 합성곱 연산을 수행하도록 구성되고, 상기 제2 영역의 상기 제2 PE 행들은 상기 제2 모드에 응답하여 제2 합성곱 연산을 수행하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 제1 합성곱 연산은 스탠다드(standard) 합성곱 연산 또는 포인트와이즈(point-wise) 합성곱 연산을 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 제2 합성곱 연산은, 뎁스와이즈(depth-wise) 합성곱 연산을 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서,상기 제2 영역에 배치된 복수의 멀티플렉서들을 더 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서,상기 제2 영역에 배치된 복수의 지연 유닛들을 더 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1 모드 또는 제2 모드를 선택하도록 구성된 모드 선택부(mode selector) 및 상기 제1 모드에서 제1 합성곱 연산을 수행하고, 상기 제2 모드에서 제2 합성곱 연산을 수행하도록 구성된 복수의 프로세싱 엘리먼트들을 포함하고, 상기 복수의 프로세싱 엘리먼트들은 상기 제2 합성곱 연산을 위해 가중치 데이터를 재사용하도록 구성되고, 상기 복수의 프로세싱 엘리먼트들은 가중치 커널의 크기에 기초하여 상기 가중치 데이터를 딜레이 하도록 구성공개특허 10-2023-0084449-4-된 딜레이 버퍼를 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 제1 합성곱 연산은, 스탠다드(standard) 합성곱 연산 또는 포인트와이즈(point-wise) 합성곱 연산을 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 제2 합성곱 연산은, 뎁스와이즈(depth-wise) 합성곱 연산을 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서,상기 딜레이 버퍼는, 뎁스와이스 합성곱 연산의 가중치 재사용을 하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항에 있어서, 상기 제1 모드에서 상기 복수의 프로세싱 엘리먼트들은, 가중치 데이터가 입력 및 상기 제1 합성곱 연산에 사용된 특징 맵 데이터가 입력을 수신하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항에 있어서, 상기 제2 모드에서 상기 복수의 프로세싱 엘리먼트들 중 일부 프로세싱 엘리먼트는 상기 제2 합성곱 연산에 사용된 가중치 데이터의 입력을 수신하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0071141", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "신경 프로세싱 유닛이 제공된다. 신경 프로세싱 유닛은 제1 모드 또는 제2 모드를 선택하도록 구성된 모드 선택 부(mode selector) 및 복수의 PE(Processing Element) 행들 및 복수의 PE 열들을 포함하는 복수의 프로세싱 엘 리먼트들을 포함하고, 제1 모드에 할당된 제1 PE 행들의 개수는 제2 모드에 할당된 제2 PE 행들의 개수보다 많고, 제1 PE 행들은 제1 모드에 응답하여 제1 합성곱 연산을 수행하도록 구성되고, 제2 PE 행들은 제2 모드에 응답하여 제1 합성곱 연산과 다른 제2 합성곱 연산을 수행하도록 구성될 수 있다."}
{"patent_id": "10-2023-0071141", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 신경 프로세싱 유닛에 관한 것이다."}
{"patent_id": "10-2023-0071141", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인간은 인식(Recognition), 분류(Classification), 추론(Inference), 예측(Predict), 조작/의사결정 (Control/Decision making) 등을 할 수 있는 지능을 갖추고 있다. 인공지능(artificial intelligence: AI)은 인간의 지능을 인공적으로 모방하는 것을 의미한다. 인간의 뇌는 뉴런(Neuron)이라는 수많은 신경세포로 이루어져 있으며, 각각의 뉴런은 시냅스(Synapse)라고 불리 는 연결부위를 통해 수백에서 수천 개의 다른 뉴런들과 연결되어 있다. 인간의 지능을 모방하기 위하여, 생물학 적 뉴런의 동작원리와 뉴런 간의 연결 관계를 모델링한 것을, 인공신경망(Artificial Neural Network, ANN) 모 델이라고 한다. 즉, 인공신경망은 뉴런들을 모방한 노드들을 레이어(Layer: 계층) 구조로 연결시킨 시스템이다."}
{"patent_id": "10-2023-0071141", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "인공신경망모델(Artificial Neural Network (ANN) 모델)은 레이어 수에 따라 '단층 신경망'과 '다층 신경망'으 로 구분한다. 일반적인 다층신경망은 입력 레이어와 은닉 레이어, 출력 레이어로 구성된다. 입력 레이어 (input layer)는 외부의 자료들을 받아들이는 레이어로서, 입력 레이어의 뉴런 수는 입력되는 변수의 수와 동일 하다. 은닉 레이어(hidden layer)는 입력 레이어와 출력 레이어 사이에 위치하며 입력 레이어로부터 신호를 받아 특징을 추출하여 출력층으로 전달한다. 출력 레이어(output layer)는 은닉 레이어로부터 신호를 받아외부로 출력한다. 뉴런 간의 입력신호는 0에서 1 사이의 값을 갖는 각각의 가중치와 곱해진 후 합산된다. 이 합 이 뉴런의 임계치보다 크면 뉴런이 활성화되어 활성화 함수를 통하여 출력 값으로 구현된다. 한편, 보다 높은 인공 지능을 구현하기 위하여, 인공신경망의 은닉 레이어의 개수를 늘린 것을 심층 신경망 (Deep Neural Network, DNN)이라고 한다. DNN에는 여러 종류가 있으나, 합성곱 신경망(Convolutional Neural Network, CNN)은 입력 데이터의 특징들을 추출하고, 특징들의 패턴을 파악하기에 용이한 것으로 알려져 있다. 합성곱 신경망(CNN)은 각각의 레이어의 뉴런 간의 연산을 매트릭스 형태의 입력 신호와 매트릭스 형태의 가중치 커널의 합성곱으로 구현한 네트워크 구조를 의미한다. 합성곱 신경망은 인간 뇌의 시각 피질에서 영상을 처리하는 것과 유사한 기능을 하는 신경망이다. 합성곱 신경 망은 객체 분류 및 인식(object classification and detection) 에 적합한 것으로 알려져 있다. 합성곱 신경망은 합성곱 연산과 활성화 함수(activation function) 연산과 풀링(pooling) 연산들이 특정 순서로 처리되는 형태로 구성된다(예를 들어, 도 3). 합성곱 신경망에서 대부분의 연산 시간은 합성곱 연산이 차지한다. 합성곱 신경망은 행렬(Matrix) 형태의 커널(kernel)에 의해 각 채널의 영상의 특징을 추출하고, 풀링(Pooling) 에 의해 이동이나 왜곡 등에 대해서 항상성을 제공하는 방식으로 사물을 추론한다. 각 채널에서는 입력 데이터 와 커널의 합성곱으로 특징맵(Feature Map)을 구한 후 활성화 함수를 적용하여 해당 채널의 활성화 맵을 생성한 다. 이후 풀링이 적용될 수 있다. 패턴을 최종적으로 분류하는 레이어는 합성곱 신경망의 후단에 위치하며, 완전 연결 레이어(Fully Connected Layer)가 예시적으로 사용될 수 있다. 합성곱 신경망의 연산 처리에서 대부분의 연산은 합성곱 또는 행렬곱을 통해 수행된다. 이때 필요한 커널들을 메인 메모리로부터 읽어 오는 빈도가 상당히 빈번하다. 이러한 합성곱 신경망 동작의 상 당 부분은 각각의 채널에 대응되는 커널들을 메인 메모리로부터 신경 프로세싱 유닛으로 읽어오는 시간이 차지 한다. 메모리는 메인 메모리, 내부 메모리, 온 칩(On-Chip) 메모리 등으로 나뉘어진다. 각각의 메모리는 복수의 메모 리 셀로 이루어지며, 각각의 메모리 셀은 고유한 메모리 주소를 가진다. 신경 프로세싱 유닛이 메인 메모리에 저장된 가중치 값을 불러오거나 다른 파라미터 값들을 불러올 때마다, 메인 메모리의 주소에 대응되는 메인 메 모리 셀에 접근하기까지 여러 클럭(clock)의 지연시간(latency)이 발생될 수 있다. 이러한 지연시간은 Column Address Strobe(CAS) Latency 및 Row Address Strobe (RAS) Latency를 포함할 수 있다. 인공신경망 연산은 방대한 데이터를 요구한다. 따라서 메인 메모리에서 신경 프로세싱 유닛으로 필요한 파라미 터를 읽어오는데 소모되는 시간과 전력 소모가 상당하다는 문제가 있다. 인공신경망모델의 추론 시, 신경 프로세싱 유닛(NPU)이 빈번하게 인공신경망모델의 특정 레이어의 특징맵 또는 커널을 메인 메모리에서 읽어온다는 사실을 본 개시의 발명자는 인식하였다. 신경 프로세싱 유닛(NPU)이 인공신경망모델의 특징맵 또는 커널을 메인 메모리에서 읽어오는 동작의 처리 속도 가 느리고 에너지를 많이 소비한다는 사실을 본 개시의 발명자는 인식하였다. 메인 메모리에 대한 액세스가 아닌 온칩 메모리나 NPU 내부 메모리에 대한 엑세스가 늘어날 수록 처리 속도가 빨라지고 에너지 소비도 감소한다는 사실을 본 개시의 발명자는 인식하였다. 특정 구조의 프로세싱 엘리먼트 어레이에서는 특정 방식의 합성곱 연산에서 프로세싱 엘리먼트 어레이의 가동률 (PE utilization rate)이 급격히 낮아진다는 사실을 본 개시의 발명자는 인식하였다. 예를 들면, 프로세싱 엘리 먼트 어레이의 프로세싱 엘리먼트가 100개 일 때, 50개의 프로세싱 엘리먼트 들만 동작한다면 프로세싱 엘리먼 트 어레이의 가동율은 50%이다. 특정 프로세싱 엘리먼트 어레이의 구조에서 뎁스와이즈(depth-wise) 합성곱 연산 시 데이터 재사용이 불가하여 프로세싱 엘리먼트 어레이의 가동률이 급격히 하락한다는 사실을 본 개시의 발명자는 인식하였다. 특히, 스탠다드 또는 포인트와이즈 합성곱 대비 프로세싱 엘리먼트 어레이의 가동율이 상대적으로 저하되는 뎁 스와이즈 합성곱의 경우, 뎁스와이즈 합성곱의 연산량이 스탠다드 또는 포인트와이즈(point-wise) 합성곱 연산량 대비 상대적으로 적더라도, 뎁스와이즈 합성곱에 소요되는 리소스, 전력 및 처리 시간 등이 스탠다드 또는 포인트와이즈 합성곱 연산과 실질적으로 비슷해질 정도로 비효율적이 된다는 사실을 본 개시의 발명자는 인식하 였다. 특히, 뎁스와이즈 합성곱의 상대적으로 적은 연산량에도 낮은 프로세싱 엘리먼트 어레이의 가동률에 의해서 신 경 프로세싱 유닛의 성능에 병목현상이 생길 수 있다는 사실을 본 개시의 발명자는 인식하였다. 특히, 뎁스와이즈 합성곱 연산을 수행할 시 가중치를 재사용할 경우 뎁스와이즈 합성곱 연산의 처리 속도를 극 대화하고 에너지 소비도 감소시킬 수 있다는 사실을 본 개시의 발명자는 인식하였다. 이에, 본 개시가 해결하고자 하는 과제는 NPU에서 뎁스와이즈 합성곱 연산 시 가중치를 재사용하여, 메인 메모 리 읽기 동작의 횟수를 저감하고, 소비 전력을 저감할 수 있는 신경 프로세싱 유닛 및 그 동작 방법을 제공하는 것이다. 단 본 개시는 이에 제한되지 않으며, 또 다른 과제들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0071141", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 바와 같은 과제를 해결하기 위하여 본 개시의 일 예시에 따른 신경 프로세싱 유닛이 제공된다. 신경 프로세싱 유닛은 제1 모드 또는 제2 모드를 선택하도록 구성된 모드 선택부(mode selector) 및 복수의 PE(Processing Element) 행들 및 복수의 PE 열들을 포함하는 복수의 프로세싱 엘리먼트들을 포함하고, 제1 모드 에 할당된 제1 PE 행들의 개수는 제2 모드에 할당된 제2 PE 행들의 개수보다 많고, 제1 PE 행들은 제1 모드에 응답하여 제1 합성곱 연산을 수행하도록 구성되고, 제2 PE 행들은 제2 모드에 응답하여 제1 합성곱 연산과 다른 제2 합성곱 연산을 수행하도록 구성될 수 있다. 제1 합성곱 연산은, 스탠다드(standard) 합성곱 연산 또는 포인트와이즈(point-wise) 합성곱 연산을 포함하도록 구성될 수 있다. 제2 합성곱 연산은, 뎁스와이즈(depth-wise) 합성곱 연산을 포함하도록 구성될 수 있다. 지연 유닛은 제2 PE 행들의 인접한 2개의 PE 행들의 인접한 2개의 PE들을 연결하도록 구성될 수 있다. 멀티플렉서는 제2 PE 행들의 인접한 2개의 PE 행들의 인접한 2개의 PE들을 연결하도록 구성될 수 있다. 지연 유닛을 더 포함하고, 복수의 프로세싱 엘리먼트들 중 하나의 프로세싱 엘리먼트는 브랜치(branch)를 포함 하는 제1 입력단, 제2 입력단 및 출력단을 포함하고, 브랜치는 지연 유닛과 연결되도록 구성될 수 있다. 멀티플렉서를 더 포함하고, 멀티플렉서는, 모드 선택부로부터 제1 모드 또는 제2 모드를 포함하는 선택 신호를 입력받도록 구성될 수 있다. 전술한 바와 같은 과제를 해결하기 위하여 본 개시의 다른 예시에 따른 신경 프로세싱 유닛이 제공된다. 신경 프로세싱 유닛은 제1 모드 또는 제2 모드를 선택하도록 구성된 모드 선택부(mode selector) 및 복수의 PE(Processing Element) 행들 및 복수의 PE 열들을 포함하는 복수의 프로세싱 엘리먼트 어레이를 포함하고, 제1 모드에 할당된 프로세싱 엘리먼트 어레이의 제1 영역은, 제2 모드에 할당된 프로세싱 엘리먼트 어레이의 제2 영 역 보다 크고, 제1 영역과 제2 영역은 서로 중첩(overlap)되도록 구성될 수 있다. 제1 영역의 복수의 PE 행들의 개수는, 제2 영역의 복수의 PE 행들의 개수보다 많도록 구성될 수 있다. 제1 영역의 복수의 PE 행들은, 제1 모드에 응답하여 제1 합성곱 연산을 수행하도록 구성되고, 제2 영역의 제2 PE 행들은 제2 모드에 응답하여 제2 합성곱 연산을 수행하도록 구성될 수 있다. 제2 영역에 배치된 복수의 멀티플렉서들을 더 포함하도록 구성될 수 있다. 제2 영역에 배치된 복수의 지연 유닛들을 더 포함하도록 구성될 수 있다. 전술한 바와 같은 과제를 해결하기 위하여 본 개시의 다른 예시에 따른 신경 프로세싱 유닛이 제공된다. 신경 프로세싱 유닛은 제1 모드 또는 제2 모드를 선택하도록 구성된 모드 선택부(mode selector) 및 제1 모드에서 제 1 합성곱 연산을 수행하고, 제2 모드에서 제2 합성곱 연산을 수행하도록 구성된 복수의 프로세싱 엘리먼트들을 포함하고, 복수의 프로세싱 엘리먼트들은 제2 합성곱 연산을 위해 가중치 데이터를 재사용하도록 구성되고, 복수의 프로세싱 엘리먼트들은 가중치 커널의 크기에 기초하여 가중치 데이터를 딜레이 하도록 구성된 딜레이 버 퍼를 포함하도록 구성될 수 있다. 딜레이 버퍼는, 뎁스와이스 합성곱 연산의 가중치 재사용을 하도록 구성될 수 있다. 제1 모드에서 복수의 프로세싱 엘리먼트들은, 가중치 데이터가 입력 및 제1 합성곱 연산에 사용된 특징 맵 데이 터가 입력을 수신하도록 구성될 수 있다. 제2 모드에서 복수의 프로세싱 엘리먼트들 중 일부 프로세싱 엘리먼트는 제2 합성곱 연산에 사용된 가중치 데이 터의 입력을 수신하도록 구성될 수 있다."}
{"patent_id": "10-2023-0071141", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, NPU에서 뎁스와이즈 합성곱 연산 시 가중치를 재사용함으로써, 메인 메모리 읽기 동작의 횟 수를 저감하고, 소비 전력을 저감할 수 있다. 또한, 본 개시에 따르면, 뎁스와이즈 합성곱 연산 시 사용되지 않은 프로세싱 엘리먼트를 비활성화함으로써, 전 력 소모를 최소화할 수 있다. 또한, 본 개시에 따르면, 뎁스와이즈 합성곱 연산 시 가중치를 딜레이하여 재사용함으로써, NPU에서 사용되는 에너지를 절약하고, 프로세싱 엘리먼트 어레이의 효율성 및 처리율이 향상된 신경 프로세싱 유닛을 제공할 수 있다."}
{"patent_id": "10-2023-0071141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서 또는 출원에 개시되어 있는 본 개시의 개념에 따른 실시 예들에 대해서 특정한 구조적 내지 단계적 설명들은 단지 본 개시의 개념에 따른 실시 예를 설명하기 위한 목적으로 예시된 것이다. 본 개시의 개념에 따 른 실시 예들은 다양한 형태로 실시될 수 있으며 본 명세서 또는 출원에 설명된 실시 예들에 한정되는 것으로 해석되어서는 아니 된다. 본 개시의 개념에 따른 실시 예는 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있다. 따라서 특정 실 시 예들을 도면에 예시하고 본 명세서 또는 출원에 상세하게 설명하고자 한다. 그러나, 이는 본 개시의 개념에 따른 실시 예를 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 개시의 사상 및 기술 범위에 포함되는 모 든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1 및/또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만, 예컨대 본 개시의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1 구성요소는 제2 구성요소로 명명 될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관 계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 인접하는\"과 \"~에 직접 인접하는\" 등도 마찬가지로 해석되어야 한다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\" 등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\" 등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 예를 들면, 제1 사용자 기기와 제2 사용자 기기는, 순서 또는 중요도와 무관하게, 서로 다른 사용자 기기를 나타낼 수 있다. 예를 들면, 본 문서에 기재된 권리범위를 벗어나지 않으면서 제1 구성요소는 제 2 구성요소로 명명될 수 있고, 유사하게 제 2 구성요소도 제1 구성요소로 바꾸어 명명될 수 있다. 본 개시에서 사용된 용어들은 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 다른 예시의 범위를 한정하 려는 의도가 아닐 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수"}
{"patent_id": "10-2023-0071141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 문서에 기재된 기술분야에서 통상 의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시에 사용된 용어들 중 일반적인 사전에 정의된 용어들은, 관련 기술의 문맥상 가지는 의미와 동일 또는 유사한 의미로 해석될 수 있으며, 본 문서에서 명백하게 정의되지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 경우에 따라서, 본 문서에서 정의된 용어일지라도 본 문서의 실시 예들을 배제하도록 해 석될 수 없다. 본 개시에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 개시를 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 개시에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 서술된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이존재함을 지정하려는 것이다. 따라서, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미 를 가지는 것으로 해석되어야 하며, 본 개시에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 본 개시의 여러 예시들의 각각 특징들이 부분적으로 또는 전체적으로 서로 결합 또는 조합 가능하다. 따라서 여 러 예시들은 당업자가 충분히 이해할 수 있듯이 기술적으로 다양한 연동 및 구동이 가능하며, 각 예시들이 서로 에 대하여 독립적으로 실시 가능할 수도 있고 연관 관계로 함께 실시 가능할 수도 있다. 실시 예를 설명함에 있어서 본 개시가 속하는 기술 분야에 익히 알려져 있고 본 개시와 직접적으로 관련이 없는 기술 내용에 대해서는 설명을 생략할 수 있다. 이는 불필요한 설명을 생략함으로써 본 개시의 요지를 흐리지 않 고 더욱 명확히 전달하기 위함이다. <용어의 정의> 이하, 본 명세서에서 제시되는 개시들의 이해를 돕고자, 본 명세서에서 사용되는 용어들에 대하여 간략하게 정 리하기로 한다. NPU: 신경 프로세싱 유닛(Neural Processing Unit)의 약어로서, CPU(Central processing unit)과 별개로 인공 신경망모델의 연산을 위해 특화된 프로세서를 의미할 수 있다. ANN: 인공신경망(artificial neural network)의 약어로서, 인간의 지능을 모방하기 위하여, 인간 뇌 속의 뉴런 들(Neurons)이 시냅스(Synapse)를 통하여 연결되는 것을 모방하여, 노드들을 레이어(Layer: 계층) 구조로 연결 시킨, 네트워크를 의미할 수 있다. 인공신경망의 정보: 네트워크의 구조 정보, 레이어의 개수에 대한 정보, 각 레이어의 연결 관계 정보, 각 레이 어의 가중치 정보, 연산 처리 방법에 대한 정보, 활성화 함수 정보 등을 포함하는 정보이다. DNN: 심층 신경망(Deep Neural Network)의 약어로서, 보다 높은 인공 지능을 구현하기 위하여, 인공신경망의 은 닉 레이어의 개수를 늘린 것을 의미할 수 있다. CNN: 합성곱 신경망(Convolutional Neural Network)의 약어로서, 인간 뇌의 시각 피질에서 영상을 처리하는 것 과 유사한 기능을 하는 신경망이다. 합성곱 신경망은 영상처리에 적합한 것으로 알려져 있으며, 입력 데이터의 특징들을 추출하고, 특징들의 패턴을 파악하기에 용이한 것으로 알려져 있다. KERNEL: 합성곱의 N × M 행렬의 가충치를 의미한다. 인공신경망모델의 각각의 레이어는 복수개의 KERNEL을 가 지며, KERNEL의 개수는 채널의 개수 또는 필터의 개수 등으로 지칭될 수 있다. 이하, 첨부한 도면을 참조하여 본 개시의 실시예를 설명한다. 도 1은 본 개시의 일 예시에 따른 신경 프로세싱 유닛이 포함된 장치를 설명하는 개략적인 개념도이다. 도 1을 참조하면 NPU가 포함된 장치(B)는 온칩 영역(A)을 포함한다. 온칩 영역(A) 외부에는 메인 메모리가 포함될 수 있다. 예를 들면, 메인 메모리는 ROM, SRAM, DRAM, Resistive RAM, Magneto-resistive RAM, Phase-change RAM, Ferroelectric RAM, Flash Memory, HBM 등과 같은 메모리 중 하나의 메모리를 포함할 수 있다. 메인 메모 리는 적어도 하나의 메모리 유닛으로 구성될 수 있다. 메인 메모리는 단일(homogeneous) 메모리 유 닛 또는 이종(heterogeneous) 메모리 유닛으로 구성될 수 있다. 신경 프로세싱 유닛(neural processing unit, NPU)은 인공신경망을 위한 동작을 수행하도록 특화된 프로 세서이다. 온칩 영역(A)에는 NPU가 배치된다. NPU는 내부 메모리를 포함할 수 있다. 내부 메모리는 휘발성 메모리 및/또는 비휘발성 메모리를 포함할 수 있다. 예를 들면, 내부 메모리는 ROM, SRAM, DRAM, Resistive RAM, Magneto-resistive RAM, Phase-change RAM, Ferroelectric RAM, Flash Memory, HBM 등과 같은 메모리 중 하나의 메모리를 포함할 수 있다. 내부 메모리 는 적어도 하나의 메모리 유닛으로 구성될 수 있다. 내부 메모리는 단일(homogeneous) 메모리 유닛 또는 이종(heterogeneous) 메모리 유닛으로 구성될 수 있다. 온칩 영역(A)에는 온칩 메모리가 배치될 수 있다. 온칩 메모리는 반도체 다이에 실장된 메모리로 온칩 영역(A)에서 처리되는 데이터를 캐싱하거나 또는 저장하기 위한 메모리일 수 있다. 온칩 메모리는 ROM, SRAM, DRAM, Resistive RAM, Magneto-resistive RAM, Phase-change RAM, Ferroelectric RAM, Flash Memory, HBM 등과 같은 메모리 중 하나의 메모리를 포함할 수 있다. 온칩 메모리는 적어도 하나의 메모리 유닛으로 구성될 수 있다. 온칩 메모리는 단일(homogeneous) 메모리 유닛 또는 이종(heterogeneous) 메 모리 유닛으로 구성될 수 있다. 온칩 영역(A)에는 중앙 프로세싱 유닛(CPU)와 같은 범용 프로세싱 유닛이 배치될 수 있다. CPU는 NPU와 온칩 메모리 그리고 메인 메모리와 동작 가능하게 연결될 수 있다. NPU가 포함된 장치(B)는 전술한 NPU의 내부 메모리, 온칩 메모리, 메인 메모리 중 적어도 하나를 포함할 수 있다. 단, 이에 제한되지 않는다. 이하에서 적어도 하나의 메모리는 내부 메모리, 온칩 메모리, 메인 메모리 중 적어도 하나를 포함하도록 의도된다. 또한, 온칩 메모리의 기재는 NPU의 내부 메모리 또는 NPU의 외부 에 있으나 온칩 영역(A)에 있는 메모리를 포함하도록 의도된다. 이하에서는 인공신경망모델에 대해서 도 20을 참조하여 설명하도록 한다. 도 20은 예시적인 인공신경망모델을 설명하기 위한 개념도이다. 도 20을 참조하면, 예시적인 인공신경망모델은 다층구조의 레이어를 포함하도록 구성될 수 있다. 예를 들면 MobileNet V1.0 모델의 레이어는 28개일 수 있다. 인공신경망은 입력 신호가 들어오면, 입력 신호에 가중치를 적용하고, 선택적으로 활성화 함수를 적용하는 인공 뉴런들로 구성된 네트워크를 의미한다. 이러한 인공신경망은 입력 데이터로부터 추론(inference) 결과를 출력하 는데 사용될 수 있다. NPU는 전기/전자 회로로 구현된 반도체일 수 있다. 상기 전기/전자 회로라 함은 수많은 전자 소자, (예컨 대, 트렌지스터, 커패시터)를 포함하는 것을 의미할 수 있다. NPU는 프로세싱 엘리먼트 어레이(processing element array), 내부 메모리, 컨트롤러, 및 인터페이 스를 포함할 수 있다. 프로세싱 엘리먼트 어레이, 내부 메모리, 컨트롤러, 및 인터페이스 각각은 수많은 트렌지스터들이 연결된 반도체 회로일 수 있다. 따라서, 이들 중 일부는 육안으로는 식별되어 구분되기 어려울 수 있고, 동작에 의해서만 식별될 수 있다. 예를 들어, 임의 회로는 프로세싱 엘리먼트 어레이로 동작하기도 하 고, 혹은 컨트롤러로 동작될 수도 있다. NPU는 프로세싱 엘리먼트 어레이, 프로세싱 엘리먼트 어레이에서 추론될 수 있는 인공신경망모델의 적어 도 일부를 저장하도록 구성된 내부 메모리, 및 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정 보에 기초하여 프로세싱 엘리먼트 어레이 및 내부 메모리를 제어하도록 구성된 스케줄러를 포함할 수 있다. 여기서, 인공신경망모델은 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보를 포함할 수 있 다. 단, 본 개시는 이에 제한되지 않는다. 인공신경망모델은 특정 추론 기능을 수행하도록 학습된 AI 인식모델 을 의미할 수 있다. 예를 들면, 인공신경망모델은 Object Detection, Object Segmentation, Image/Video Reconstruction, Image/Video Enhancement, Object Tracking, Event Recognition, Event Prediction, Anomaly Detection, Density Estimation, Event Search, Measurement 등의 추론을 수행하도록 학습될 모델일 수 있다. 예를 들면, 인공신경망모델은 Bisenet, Shelfnet, Alexnet, Densenet, Efficientnet, EfficientDet, Googlenet, Mnasnet, Mobilenet, Resnet, Shufflenet, Squeezenet, VGG, Yolo, RNN, CNN, DBN, RBM, LSTM 등 의 모델일 수 있다. 단, 본 개시는 이에 제한되지 않으며, NPU에서 동작할 새로운 인공신경망모델이 꾸준히 발 표되고 있다. 프로세싱 엘리먼트 어레이는 인공신경망을 위한 동작을 수행할 수 있다. 예를 들어, 입력 데이터가 입력되었을 때, 프로세싱 엘리먼트 어레이는 인공신경망의 학습을 수행하도록 할 수 있다. 또한 입력 데이터가 입력되었을때, 프로세싱 엘리먼트 어레이는 학습 완료된 인공신경망을 통해 추론 결과를 도출하는 동작을 수행할 수 있다. 예를 들면, NPU는 인터페이스를 통해서 메인 메모리에 저장된 인공신경망모델의 데이터의 적어도 일부를 내부 메모리으로 불러올 수 있다. 컨트롤러는 NPU는 추론 연산을 위한 프로세싱 엘리먼트 어레이의 연산 및 내부 메모리의 읽기 및 쓰 기 순서를 제어하도록 구성된다. 또한 컨트롤러는 입력 데이터에 해당하는 배치 채널의 적어도 일부의 크기를 조정하도록 구성된다. 인공신경망모델의 구조에 의하면, 각 레이어 별 연산은 순차적으로 수행된다. 즉, 인공신경망모델의 구조가 확 정될 경우, 레이어 별 연산순서가 정해질 수 있다. 각 레이어 별 연산은 NPU의 내부 메모리 또는 온 칩 메모리의 크기에 따라서 한번에 처리가 불가한 경우가 발생할 수 있다. 이러한 경우, NPU는 적 절한 크기로 해당 레이어를 타일링(tiling)하여 하나의 연산처리를 복수의 연산처리로 나누어 처리할 수 있다. 이러한 인공신경망모델의 구조 및 NPU의 하드웨어 제약에 따른 연산의 순서 또는 데이터 흐름의 순서를 NPU에서 추론되는 인공신경망모델의 데이터 지역성으로 정의할 수 있다. 즉, 인공신경망모델이 NPU에서 실행되도록 컴파일러가 인공신경망모델을 컴파일 할 경우, 신경 프로세싱 유닛-메모리 레벨에서의 인공신경망모델의 인공신경망 데이터 지역성이 재구성될 수 있다. 예를 들어, 컴파일러 는 CPU에 의해 실행될 수 있다. 또는 컴파일러는 별도의 시스템에서 실행될 수 있다. 즉, 컴파일러, 인공신경망모델에 적용된 알고리즘들, 및 NPU의 동작 특성, 가중치 값들의 크기, 및 특징 맵 또는 채널의 개수에 따라서 내부 메모리에 로딩되는 인공신경망모델 처리에 필요한 데이터의 크기 및 순서가 결정될 수 있다. 예를 들면, 동일한 인공신경망모델의 경우에도 NPU가 해당 인공신경망모델을 연산하는 방식, 예를 들면, 특징맵 타일링(feature map tiling), 프로세싱 엘리먼트의 스테이셔너리(Stationary) 기법 등, NPU의 프 로세싱 엘리먼트 개수, NPU 내 특징맵 및 가중치의 크기, 내부 메모리 용량, NPU내의 메모리 계층 구조, 및 해당 인공신경망모델을 연산 처리하기 위한 NPU의 연산 동작의 순서를 결정해 주는 이와 같이 생성된 출력 특징맵에 활성화 함수가 적용되어 활성화 맵이 최종적으로 출력될 의 알고리즘 특성 등에 따라서 처리하고자 하는 인공신경망모델의 계산 방법이 구성될 수 있다. 왜냐하면, 상술한 요인들에 의해서 동일한 인 공신경망모델을 연산 처리하더라도 NPU가 클럭 단위로 매 순간 필요한 데이터의 순서를 상이하게 결정할 수 있기 때문이다. 이하에서는 도 2를 참조하여 컴파일러에 대해서 구체적으로 설명한다. 도 2는 본 개시에 관련된 컴파일러를 설명하는 개략적인 개념도이다. 도 2를 참조하면, 컴파일러는 프론트엔드(frontend) 및 백엔드(backend)를 가지고, 프로그램 최적화를 위 해 사용되는 IR(Intermediate representation)이 프론트엔드와 백엔드 사이에 존재한다. 예를 들면, 컴파일러 는 ONNX, TensorFlow, PyTorch, mxnet, Keras 등에서 제공하는 딥러닝 프레임워크로 생성된 인공신경망 모델을 입력 받도록 구성될 수 있다. 프론트엔드는 입력되는 인공신경망모델에 대한 하드웨어에 독립적인 변환 및 최적화 작업을 수행하고, IR은 소 스 코드를 나타내기 위해 사용되며, 백엔드는 소스 코드로부터 바이너리 형태의 머신 코드(즉, NPU에서 사용될 수 있는 코드)를 생성한다. 나아가, 컴파일러는 인공신경망모델의 합성곱 방식을 분석하여 NPU가 연산할 모든 연산에 대한 정 보를 포함하는 모드 정보를 생성하고, 생성된 모드 정보를 NPU로 제공할 수 있다. 여기서, 모드 정보는 인공신경망모델의 레이어별, 채널별 또는 타일별 제1 합성곱 연산 및/또는 제2 합성곱 연산에 대한 정보를 포함 한다. 예를 들어, 제1 합성곱 연산은 스탠다드 합성곱 연산(standard convolution) 또는 포인트와이즈 합성곱 연산(point-wise convolution)을 포함하고, 제2 합성곱 연산은 뎁스와이즈 합성곱 연산(depth-wise convolution)을 포함하지만, 이에 한정되지 않는다. 이와 같이 제공된 모드 정보에 기반하여 NPU는 동작 모드를 결정하고, 결정된 동작 모드에 따른 연산 동 작을 수행할 수 있다. 이하에서는 인공신경망 중에서 심층 신경망(DNN)의 한 종류인 합성곱 신경망(CNN)에 대해서 도 3을 참조하여 상 세하게 설명하기로 한다.도 3은 본 개시에 관련된 합성곱 신경망을 설명하는 개략적인 개념도이다. 컨볼루션 신경망은 하나 또는 여러 개의 컨볼루션 레이어(convolutional layer)와 통합 레이어(pooling layer), 완전하게 연결된 레이어(fully connected layer)들의 조합일 수 있다. 컨볼루션 신경망은 2차원 데이터 의 학습 및 추론에 적합한 구조를 가지고 있으며, 역전달(Backpropagation algorithm)을 통해 학습될 수 있다. 본 개시의 예시에서, 컨볼루션 신경망은 채널마다 채널의 입력 영상의 특징을 추출하는 커널이 존재한다. 커널 은 2차원 행렬로 구성될 수 있으며, 입력 데이터를 순회하면서 합성곱 연산 수행한다. 커널의 크기는 임의로 결 정될 수 있으며, 커널이 입력 데이터를 순회하는 간격(stride) 또한 임의로 결정될 수 있다. 커널 하나당 입력 데이터 전체에 대한 합성곱 결과는 특징맵(feature map) 또는 활성화 맵으로 지칭될 수 있다. 이하에서 커널은 일 세트의 가중치 값들 또는 복수의 세트의 가중치 값들을 포함할 수 있다. 각 레이어 별 커널의 개수는 채널의 개수로 지칭될 수 있다. 이처럼 합성곱 연산은 입력 데이터와 커널의 조합으로 이루어진 연산이므로, 이후 비선형성을 추가하기 위한 활 성화 함수가 적용될 수 있다. 합성곱 연산의 결과인 특징맵에 활성화 함수가 적용되면 활성화 맵으로 지칭될 수 있다. 구체적으로 도 3을 참조하면, 컨볼루션 신경망은 적어도 하나의 컨볼루션 레이어, 적어도 하나의 풀링 레이어, 및 적어도 하나의 완전 연결 레이어를 포함한다. 예를 들면, 합성곱(컨볼루션)은, 입력 데이터의 크기(통상적으로 1×1, 3×3 또는 5×5 행렬)와 출력 피처 맵 (Feature Map)의 깊이(커널의 수)와 같은 두 개의 주요 파라미터에 의해 정의될 수 있다. 이러한 주요 파라미터 는 합성곱에 의해 연산될 수 있다. 이들 합성곱은, 깊이 32에서 시작하여, 깊이 64로 계속되며, 깊이 128 또는 256에서 종료될 수 있다. 합성곱 연산은, 입력 데이터인 입력 이미지 행렬 위로 3×3 또는 5×5 크기의 커널 (kernel)을 슬라이딩하여 커널의 각 가중치와 겹쳐지는 입력 이미지 행렬의 각 원소를 곱한 후 이들을 모두 더 하는 연산을 의미할 수 있다. 이와 같이 생성된 출력 특징맵에 활성화 함수가 적용되어 활성화 맵이 최종적으로 출력될 수 있다. 풀링 레이어 는 출력 데이터(즉, 활성화 맵)을 다운 샘플링하여 특징맵의 크기를 줄이는 풀링 연산을 수행할 수 있다. 예를 들어, 풀링 연산은 최대 풀링(max pooling) 및/또는 평균 풀링(average pooling)을 포함할 수 있으나, 이에 한 정되지 않는다. 최대 풀링 연산은 커널을 이용하며, 특징맵과 커널이 슬라이딩되어 커널과 겹쳐지는 특징맵의 영역에서 최대 값 을 출력한다. 평균 풀링 연산은 특징맵과 커널이 슬라이딩되어 커널과 겹쳐지는 특징맵의 영역 내에서 평균값을 출력한다. 이처럼 풀링 연산에 의해 특징맵의 크기가 줄어들기 때문에 특징맵의 파라미터 개수 또한 줄어든다. 완전 연결 레이어는 풀링 레이어를 통해서 출력된 데이터를 복수의 클래스(즉, 추정값)로 분류하고, 분류된 클 래스 및 이에 대한 점수(score)를 출력할 수 있다. 풀링 레이어를 통해서 출력된 데이터는 3차원 특징맵 형태를 이루며, 이러한 3차원 특징맵이 1차원 벡터로 변환되어 완전 연결 레이어로 입력될 수 있다. 이하에서는 도 4를 참조하여 신경망 프로세스 유닛에 대해서 구체적으로 설명하도록 한다. 도 4는 본 개시의 실시예에 따른 신경 프로세싱 유닛을 설명하는 개략적인 개념도이다. 도 4를 참조하면, 신경 프로세싱 유닛(NPU)은 프로세싱 엘리먼트 어레이(PE array), 내부 메모리 및 컨트롤러를 포함한다. 프로세싱 엘리먼트 어레이는 인공신경망의 노드 데이터와 연결망의 가중치 데이터를 연산하도록 구성된 복 수의 프로세싱 엘리먼트들(PE1…)을 포함하도록 구성된다. 각각의 프로세싱 엘리먼트는 MAC (multiply and accumulate) 연산기 및/또는 ALU (Arithmetic Logic Unit) 연산기를 포함할 수 있다. 단, 본 개시에 따른 예시 들은 이에 제한되지 않는다. 또한, 제시된 실시예에서 프로세싱 엘리먼트들(PE1…)은 단지 설명의 편의를 위한 예시이며, 복수의 프로 세싱 엘리먼트들(PE1…)의 개수는 제한되지 않는다. 복수의 프로세싱 엘리먼트들(PE1…)의 개수에 의 해서 프로세싱 엘리먼트 어레이의 크기 또는 개수가 결정될 수 있다. 프로세싱 엘리먼트 어레이의 크기는 N × M 행렬 형태로 구현될 수 있다. 여기서 N 과 M은 0보다 큰 정수이다. 이에, 프로세싱 엘리먼트 어레이는 N × M 개의 프로세싱 엘리먼트를 포함할 수 있다. 프로세싱 엘리먼트 어레이의 크기는 NPU가 작동하는 인공신경망모델의 특성을 고려하여 설계할 수 있다. 부연 설명하면, 프로세싱 엘리먼트의 개수는 작동할 인공신경망모델의 데이터 크기, 요구되는 연산량, 요 구되는 소비 전력 등을 고려하여 결정될 수 있다. 인공신경망모델의 데이터 크기는 인공신경망모델의 레이어 수 와 각각의 레이어의 가중치 데이터 크기에 대응되어 크기가 결정될 수 있다. 따라서, 본 개시의 일 예시에 따른 프로세싱 엘리먼트 어레이의 크기는 제한되지 않는다. 프로세싱 엘리먼 트 어레이의 프로세싱 엘리먼트들(PE1…)의 개수가 증가할수록 작동하는 인공신경망모델의 병렬 연산 능력이 증가되나, NPU의 제조 비용 및 물리적인 칩 크기가 증가될 수 있다. 예를 들면, NPU에서 작동되는 인공신경망모델은 30개의 특정 키워드를 감지하도록 학습된 인공신경망, 즉 AI 키워드 인식모델일 수 있다. 이러한 경우, 프로세싱 엘리먼트 어레이의 크기는 인공신경망모델의 연산 량 특성을 고려하여 4 × 3로 설계될 수 있다. 다르게 설명하면, 프로세싱 엘리먼트 어레이는 12개의 프로 세싱 엘리먼트들을 포함할 수 있다. 단, 이에 제한되지 않으며, 복수의 프로세싱 엘리먼트들(PE1…)의 개 수는 예를 들면, 8개 내지 16,384 범위 내에서 선택되는 것도 가능하다. 즉, 본 개시의 예시들에서 프로세싱 엘 리먼트의 개수는 제한되지 않는다. 프로세싱 엘리먼트 어레이는 인공신경망 연산에 필요한 덧셈, 곱셈, 누산 등의 기능을 수행하도록 구성된 다. 다르게 설명하면, 프로세싱 엘리먼트 어레이는 MAC(multiplication and accumulation) 연산을 수행하 도록 구성될 수 있다. 이하에서는 도 5를 참조하여 프로세싱 엘리먼트 어레이 중 하나의 프로세싱 엘리먼트를 구체적으로 설명하 도록 한다. 도 5는 본 개시에 적용될 수 있는 프로세싱 엘리먼트 어레이 중 하나의 프로세싱 엘리먼트를 설명하는 개략적인 개념도이다. 도 5를 참조하면, 제1 프로세싱 엘리먼트(PE1)는 곱셈기(Multiplier), 가산기(Adder) 및 누산 기(Accumulator)를 포함할 수 있다. 제1 프로세싱 엘리먼트(PE1)는 비트 양자화 유닛(Bit quantization unit)을 선택적으로 포함할 수 있다. 단, 본 개시에 따른 예시들은 이에 제한되지 않으며, 프로세싱 엘리먼트 어레이는 인공신경망의 연 산 특성을 고려하여 다양하게 변형 실시될 수도 있다. 곱셈기는 입력 받은 (N)bit 데이터와 (M)bit 데이터를 곱한다. 곱셈기의 연산 값은 (N+M)bit 데이터 로 출력될 수 있다. 여기서 N과 M은 0보다 큰 정수이다. (N)bit 데이터를 입력 받는 제1 입력부는 변수 같은 특 성을 가지는 값을 입력 받도록 구성될 수 있고, (M)bit 데이터를 입력 받는 제2 입력부는 상수 같은 특성을 가 지는 값을 입력 받도록 구성될 수 있다. 예를 들면, 제1 입력부는 특징맵 데이터를 입력 받을 수 있다. 즉, 특징맵 데이터는 입력 영상, 음성 등의 특징 을 추출한 데이터 일 수 있기 때문에, 실시간으로 센서 등 외부에서 입력되는 데이터 일 수 있다. 프로세싱 엘 리먼트로 입력되는 특징맵 데이터는 입력 특징맵 데이터로 지칭될 수 있다. MAC 연산이 완료되어 프로세싱 엘리 먼트에서 출력되는 특징맵 데이터는 출력 특징맵 데이터로 지칭될 수 있다. NPU는 출력 특징맵 데이터에 배치 정규화, 풀링, 활성화 함수 등의 추가 연산을 선택적으로 더 적용할 수 있다. 예를 들면, 제2 입력부는 가중치, 즉, 커널 데이터를 입력 받을 수 있다. 즉, 인공신경망모델의 가중치 데이터 는 학습이 완료된 경우, 인공신경망모델의 가중치 데이터는 별도의 학습이 진행되지 않는 한 변하지 않을 수 있 다. 즉, 곱셈기는 하나의 변수와 하나의 상수를 입력 받도록 구성될 수 있다. 부연 설명하면, 제1 입력부에 입 력되는 변수 값은 인공신경망모델의 특징맵 데이터일 수 있다. 제2 입력부에 입력되는 상수 값은 인공신경망모 델의 가중치 데이터일 수 있다. 이처럼 컨트롤러가 변수 값과 상수 값의 특성을 구분하여 내부 메모리를 제어할 경우, 컨트롤러(30 0)는 내부 메모리의 메모리 재사용율을 증가시킬 수 있다. 단, 곱셈기의 입력 데이터는 상수 값과 변수 값에 제한되지 않는다. 즉, 본 개시의 예시들에 따르면, 프로 세싱 엘리먼트의 입력 데이터는 상수 값과 변수 값의 특성을 이해하여 동작할 수 있기 때문에, NPU의 연 산 효율을 향상시킬 수 있다. 하지만 NPU의 동작은 입력 데이터의 상수 값 및 변수 값의 특징에 제한되지 않는다. 이를 바탕으로, 컨트롤러는 상수 값의 특성을 고려하여 메모리 재사용율을 향상시키도록 구성될 수 있다. 다시 도 20을 예를 들면, 컨트롤러는 인공신경망모델의 각각의 레이어의 가중치 크기(Kernel size), 입력 특징맵 크기(IFMAP size), 출력 특징맵 크기(OFMAP size)가 서로 상이한 것을 확인할 수 있다. 예를 들면, 내부 메모리의 크기가 결정될 경우, 특정 레이어 또는 특정 레이어의 타일의 입력 특징맵의 크 기와 출력 특징맵의 크기가 내부 메모리보다 작을 경우, 컨트롤러는 특징맵 데이터를 재사용을 하도 록 NPU를 제어할 수 있다. 예를 들면, 내부 메모리의 크기가 결정될 경우, 특정 레이어 또는 특정 레이어의 타일의 가중치의 크기가 상당히 작을 경우, 컨트롤러는 특징맵 데이터를 재사용을 하도록 NPU를 제어할 수 있다. 다시 도 20 을 참조하면, 제1 내지 제8 레이어의 가중치 크기는 상당히 작은 것을 알 수 있다. 따라서 컨트롤러는 상 기 가중치들이 내부 메모리에 일정 기간 상주하여 재사용 되도록 내부 메모리를 제어할 수 있다. 즉, 컨트롤러는 인공신경망모델의 상기 데이터 재사용 정보를 포함하는 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 재사용 가능한 변수 값을 각각 인식하고, 선택적으로 메모리를 재사용 하도록 내부 메모 리를 제어할 수 있다. 즉, 컨트롤러는 인공신경망모델의 상기 데이터 재사용 정보를 포함하는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 재사용될 수 있는 상수 값을 각각 인식하고, 선택적으로 메모리를 재사 용 하도록 내부 메모리를 제어할 수 있다. 상기 동작을 위해서 컴파일러 또는 컨트롤러는 인공 신경망모델의 임계 크기 이하의 가중치를 분류할 수 있다. 즉, 컨트롤러는 인공신경망모델의 상기 데이터 재사용 정보를 포함하는 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 재사용 가능한 변수 값 및 재사용 가능한 상수 값을 각각 인식하고, 선택적으로 메모리를 재사용 하도록 내부 메모리을 제어할 수 있다. 한편, 제1 프로세싱 엘리먼트(PE1)는 곱셈기의 제1 입력부 및 제2 입력부 중 하나의 입력부에 0이 입 력될 때, 연산을 하지 않더라도 연산 결과가 0인 것을 인지하고 있기 때문에, 곱셈기가 연산을 하지 않도 록 동작을 제한할 수 있다. *예를 들면, 곱셈기의 제1 입력부 및 제2 입력부 중 하나의 입력부에 0이 입력될 때, 곱셈기는 제로 스키핑(zero skipping) 방식으로 동작하도록 구성될 수 있다. 곱셈기의 제1 입력부 및 제2 입력부에 입력되는 데이터는 인공신경망모델의 각각의 특징맵 및 가중치의 양 자화에 따라서 비트 폭(bit width)이 결정될 수 있다. 예를 들면, 제1 레이어의 특징맵이 5bit로 양자화 되고 제1 레이어의 가중치가 7bit로 양자화되는 경우 제1 입력부는 5bit-width의 데이터를 입력 받도록 구성되고, 제 2 입력부는 7bit-width의 데이터를 입력 받도록 구성될 수 있다. NPU는 내부 메모리에 저장된 양자화된 데이터가 제1 프로세싱 엘리먼트의 입력부들에 입력될 때 양자화된 비트 폭이 실시간으로 변환되도록 제1 프로세싱 엘리먼트를 제어할 수 있다. 즉, 레이어 마다 양자화 된 비트 폭이 다를 수 있다. 따라서 제1 프로세싱 엘리먼트는 입력되는 데이터의 비트 폭이 변환될 때마다 비트 폭 정보를 NPU에서 제공받고, 제공된 비트 폭 정보에 기반하여 비트 폭을 변환시켜서 입력 데이터를 생성하도록 구성될 수 있다. 가산기는 곱셈기의 연산 값과 누산기의 연산 값을 가산한다. (L)loops가 0일 경우, 누산된 데이 터가 없으므로, 가산기의 연산 값은 곱셈기의 연산 값과 동일할 수 있다. (L)loops가 1일 경우, 곱셈 기의 연산 값과 누산기의 연산 값이 가산된 값이 가산기의 연산 값일 수 있다. 누산기는 가산기의 연산 값과 곱셈기의 연산 값이 (L)loops 횟수만큼 누산되도록 가산기의 출력부에서 출력된 데이터를 임시 저장한다. 구체적으로, 가산기의 출력부에서 출력된 가산기의 연산 값은 누산기의 입력부에 입력되고, 입력된 연산 값은 누산기에 임시 저장되었다가 누산기의 출 력부에서 출력된다. 출력된 연산 값은 루프에 의해 가산기의 입력부에 입력된다. 이때, 가산기의 입 력부에는 곱셈기의 출력부에서 새롭게 출력된 연산 값이 함께 입력된다. 즉, 누산기의 연산 값과 곱 셈기의 새로운 연산 값이 가산기의 입력부에 입력되고, 이 값들이 가산기에서 가산되어 가산기 의 출력부를 통해 출력된다. 가산기의 출력부에서 출력된 데이터, 즉 가산기의 새로운 연산 값 은 누산기의 입력부에 입력되며, 이후 동작들은 상술한 동작들과 실질적으로 동일하게 루프 횟수만큼 수행된다. 이처럼, 누산기는 곱셈기의 연산 값과 가산기의 연산 값을 루프 횟수만큼 누산하기 위해 가산기 의 출력부에서 출력된 데이터를 임시 저장하므로, 누산기의 입력부에 입력되는 데이터 및 출력부에서 출력되는 데이터는 가산기의 출력부에서 출력된 데이터와 같은 (N+M+log2(L))bit의 비트 폭을 가질 수 있 다. 여기서 L은 0보다 큰 정수이다. 누산기는 임시 메모리로 레지스터를 포함하도록 구성될 수 있다. 누산기는 누산이 종료되면, 초기화 신호(initialization reset)를 인가받아서 누산기 내부에 저장된 데이터를 0으로 초기화 할 수 있다. 단, 본 개시에 따른 예시들은 이에 제한되지 않는다. 비트 양자화 유닛은 누산기에서 출력되는 데이터의 비트 폭을 저감하도록 구성될 수 있다. 비트 양자 화 유닛은 컨트롤러에 의해서 제어될 수 있다. 양자화된 데이터의 비트 폭은 (X)bit로 출력될 수 있 다. 여기서 X는 0보다 큰 정수이다. 상술한 구성에 따르면, 제1 프로세싱 엘리먼트 어레이는 MAC 연산을 수행하도록 구성되고 MAC 연산 결과를 양자화해서 출력할 수 있다. 특히 이러한 양자화는 (L)loops가 증가할수 록 소비 전력을 더 절감할 수 있는 효과가 있다. 또한 소비 전력이 저감되면 발열도 저감할 수 있다. 특히 발열 을 저감하면 NPU의 고온에 의한 오동작 발생 가능성을 저감할 수 있다. 비트 양자화 유닛의 출력 데이터(X)bit는 다음 레이어의 노드 데이터 또는 합성곱의 입력 데이터가 될 수 있다. 만약 인공신경망모델이 양자화되었다면, 비트 양자화 유닛은 양자화된 정보를 인공신경망모델에서 제공받도록 구성될 수 있다. 단, 이에 제한되지 않으며, 컨트롤러는 인공신경망모델을 분석하여 양자화된 정보를 추출하도록 구성될 수 있다. 따라서 비트 양자화 유닛은 양자화된 데이터 크기에 대응되도록, 출력 데이터(X)bit를 양자화 된 비트 폭으로 변환하여 출력할 수 있다. 비트 양자화 유닛의 출력 데이터(X)bit 는 양자화된 비트 폭으로 내부 메모리에 저장될 수 있다. 본 개시의 일 예시에 따른 NPU의 제1 프로세싱 엘리먼트는 비트 양자화 유닛에 의해서 누산기 에서 출력되는 (N+M+log2(L))bit의 비트 폭의 데이터를 (X)bit의 비트 폭으로 저감할 수 있다. 이를 위해 컨트롤러는 비트 양자화 유닛을 제어하여 출력 데이터의 비트 폭을 LSB(least significant bit)에서 MSB(most significant bit)까지 소정 비트만큼 저감할 수 있다. 출력 데이터의 비트 폭이 저감되면 NPU의 소비 전력, 연산량, 메모리 사용량이 저감될 수 있다. 하지만 비트 폭이 특정 길이 이하로 저감될 경우, 인공신경망모델의 추론 정확도가 급격히 저하될 수 있는 문제가 발생 될 수 있다. 따라서, 출력 데이터의 비트 폭 저감, 즉, 양자화 수준은 인공신경망모델의 추론 정확도 저감 수준 대비 소비 전력, 연산량, 메모리 사용량 저감 정도를 비교하여 결정될 수 있다. 양자화 수준은 인공신경망모델 의 목표 추론 정확도를 결정하고, 비트 폭을 점진적으로 저감하면서 열화를 테스트하는 방법으로 결정될 수 있 다. 양자화 수준은 각각의 레이어의 연산 값마다 각각 결정될 수 있다. 상술한 제1 프로세싱 엘리먼트(PE1)에 따라 곱셈기의 (N)bit 데이터와 (M)bit 데이터의 비트 폭을 조 절하고, 비트 양자화 유닛에 의해서 연산 값(X)bit의 비트 폭을 저감함으로써, 프로세싱 엘리먼트 어레이 의 MAC 연산 속도를 향상시키면서 소비 전력을 저감할 수 있고, 인공신경망의 합성곱(convolution) 연산을 보다 더 효율적으로 할 수 있다. 이를 바탕으로 하는 NPU의 내부 메모리는 프로세싱 엘리먼트 어레이의 MAC 연산 특성 및 소비 전력 특성을 고려하여 구성된 메모리 시스템일 수 있다. 예를 들면, NPU는, 프로세싱 엘리먼트 어레이의 MAC 연산 특성 및 소비 전력 특성을 고려하여 프로 세싱 엘리먼트 어레이의 연산 값의 비트 폭을 저감하도록 구성될 수 있다. 예를 들면, NPU는 내부 메모리의 특징맵 또는 가중치 재사용을 위해 프로세싱 엘리먼트 어레이(10 0)의 연산 값의 비트 폭을 저감하도록 구성될 수 있다. NPU의 내부 메모리는 NPU의 소비 전력을 최소화하도록 구성될 수 있다. NPU의 내부 메모리는 작동되는 인공신경망모델의 파라미터들의 크기 및 연산 단계를 고려하여 저전 력으로 메모리를 제어하도록 구성된 메모리 시스템일 수 있다. NPU의 내부 메모리는 인공신경망모델의 데이터 크기 및 연산 단계를 고려하여 가중치가 저장된 특정 메모리 어드레스를 재사용하도록 구성된 저전력 메모리 시스템일 수 있다. NPU는 비선형성을 부여하기 위한 여러 가지 활성화 함수를 처리하도록 구성된 연산부를 더 추가하도록 구 성될 수 있다. 예를 들면, 활성화 함수는 입력값에 대한 비선형의 출력값을 도출하는 시그모이드 함수, 하이퍼 볼릭 탄젠트(tanh) 함수, ReLU함수, Leaky ReLU 함수, Maxout 함수 또는 ELU 함수 등을 포함할 수 있으나, 이 에 한정되지 않는다. 이러한 활성화 함수는 MAC 연산 이후에 선택적으로 적용될 수 있다. 활성화 함수가 적용된 연산 값은, 활성화 맵으로 지칭될 수 있다. 다시 도 4를 참조하면, 내부 메모리는 휘발성 메모리로 구성될 수 있다. 휘발성 메모리는 전원이 공급된 경우에만 데이터를 저장하고, 전원 공급이 차단되면 저장된 데이터가 소멸되는 메모리다. 휘발성 메모리는 정적 랜덤 액세스 메모리 (Static Random Access Memory; SRAM), 동적 랜덤 액세스 메모리 (Dynamic Random Access Memory; DRAM) 등을 포함할 수 있다. 내부 메모리는 바람직하게는 SRAM일 수 있으나, 이에 한정되지 않는 다. 내부 메모리의 적어도 일부는 비휘발성 메모리로 구성될 수 있다. 비휘발성 메모리는 전원이 공급되지 않 는 경우에도 데이터를 저장하는 메모리다. 비휘발성 메모리는 롬(Read Only Memory; ROM) 등을 포함할 수 있다. 학습이 완료된 가중치는 비휘발성 메모리에 저장되는 것도 가능하다. 즉, 가중치 저장부 및/또는 휘발성 메모리 또는 비휘발성 메모리를 포함할 수 있다. 내부 메모리는 가중치 저장부 및 특징맵 저장부를 포함한다. 가중치 저장부는 인공신경망 모델의 가중치의 적어도 일부를 저장하고, 특징맵 저장부는 인공신경망모델의 노드 데이터 또는 특징맵의 적어도 일부를 저장한다. 인공신경망모델이 포함할 수 있는 인공신경망의 데이터는 각각의 레이어의 노드 데이터 또는 특징맵, 및 각각의 레이어의 노드를 연결하는 연결망 각각의 가중치 데이터를 포함할 수 있다. 인공신경망의 데이터 또는 파라미터 들 중 적어도 일부는 컨트롤러 내부에 제공되는 메모리 또는 내부 메모리에 저장될 수 있다. 인공신경망의 파라미터들 중 특징맵은 배치 채널로 구성될 수 있다. 여기서 복수의 배치 채널들은 예를 들어 실 질적으로 동일한 기간(예를 들어 10 또는 100 ms 이내)에 복수의 이미지 센서들 또는 카메라들을 통해 촬영된 이미지들일 수 있다. 한편, 컨트롤러는 인공신경망모델의 가중치 값들의 크기, 특징맵의 크기, 및 가중치 값들과 특징맵의 계산 순서 등을 고려하여 프로세싱 엘리먼트 어레이 및 내부 메모리를 제어하도록 구성될 수 있다. 컨트롤러는 모드 선택부와 스케줄러를 포함한다. 모드 선택부는 프로세싱 엘리먼트 어레이에서 계산될 가중치 값들의 크기, 특징맵의 크기, 및 가중치 값들과 특징맵의 계산 순서 등에 따라 프로세싱 엘리먼트 어레이가 제1 모드 또는 제2 모드로 동작할지를 선택할 수 있다. 여기서, 제1 모드는 제1 합성곱 연산을 수행하는 동작 모드로서, 제1 합성곱 연산은 스탠다드 합성곱 연산 또는 포인트와이즈 합성곱 연산일 수 있으나, 이에 한정되지 않는다. 제2 모드는 제2 합성곱 연산을 수행하는 모드로 서, 제2 합성곱 연산은 뎁스와이즈 합성곱 연산일 수 있으나, 이에 한정되지 않는다. 모드 선택부는 제1 모드 또는 제2 모드 중 선택된 동작 모드를 나타내는 선택 신호를 프로세싱 엘리먼트 어레이로 전달하여 프로세싱 엘리먼트 어레이가 제1 모드 또는 제2 모드로 동작하도록 할 수 있다. 다양한 실시예에서 모드 선택부는 컴파일러로부터 제공된 모드 정보에 기반하여 제1 모드 또는 제2 모드로 동작할지를 선택할 수도 있다. 예를 들어, 모드 선택부는 컴파일러로부터 제공된 모드 정보 에 기반하여 제1 모드 또는 제2 모드를 선택하고, 선택된 제1 모드 또는 제2 모드를 나타내는 선택 신호를 프로 세싱 엘리먼트 어레이로 전달할 수 있다. 다음으로, 스케줄러는 선택된 모드에 따라 동작하도록 프로세싱 엘리먼트 어레이 및 내부 메모리 를 제어할 수 있다. 예를 들어, 모드 선택부가 제1 모드를 선택하면 스케줄러는 제1 입력 데이터에 해당하는 가중치 데이 터를 내부 메모리의 가중치 저장부에 로드(load)하고, 제2 입력 데이터에 해당하는 특징맵 데이터를 내부 메모리의 특징맵 저장부에 로드할 수 있다. 스케줄러는 프로세싱 엘리먼트 어레이를 구성하는 복수의 PE 각각에서 제1 합성곱 연산을 통해 가중치 데이터 및 특징맵 데이터를 계산하도록 프로세싱 엘리먼트 어레이를 제어할 수 있다. 모드 선택부가 제2 모드를 선택하면 스케줄러는 앞서 설명한 바와 같이 가중치 데이터를 가중치 저장 부에 로드하고, 특징맵 데이터를 특징맵 저장부에 로드할 수 있다. 컨트롤러는 프로세싱 엘리먼 트 어레이를 구성하는 복수의 PE 각각에서 제2 합성곱 연산을 통해 가중치 데이터 및 특징맵 데이터를 계 산하도록 프로세싱 엘리먼트 어레이를 제어할 수 있다. 내부 메모리가 가중치 저장부 및 특징맵 저장부를 구분하여 포함하는 것으로 도시되었으나, 이 는 예시적일 뿐이고, 메모리 주소 등을 통해 논리적으로 구분되거나 또는 가변적으로 구분되거나 또는 구분되지 않을 수도 있다. 부연 설명하면, 가중치 저장부의 크기와 특징맵 저장부의 크기는 각 레이어별, 각 타일별 상이할 수 있다. 다시 도 20을 참조하면, 각각의 레이어의 특징맵들(IFMAP or OFMAP)의 데이터 크기와 가중치의 데이터 크 기는 레이어별 상이한 것을 알 수 있다. 위에 설명된 예시에서는 인공신경망의 파라미터들이 NPU의 내부 메모리에 저장되는 것으로 설명되었 지만, 이에 제한되지 않고 온칩 메모리 또는 메인 메모리에 저장될 수도 있다. 한편, 일반적인 CPU의 스케줄링은 공평성, 효율성, 안정성, 반응 시간 등을 고려하여, 최상의 효율을 낼 수 있 도록 동작한다. 즉, 우선 순위, 연산 시간 등을 고려해서 동일 시간내에 가장 많은 프로세싱을 수행하도록 스케 줄링 된다. 따라서, 종래의 CPU는 각 프로세싱의 우선 순서, 연산 처리 시간 등의 데이터를 고려하여 작업을 스 케줄링 하는 알고리즘을 사용하였다. 이와 다르게 컨트롤러는 인공신경망모델의 파라미터들의 연산 방식 특히, 프로세싱 엘리먼트 어레이 에서 수행할 합성곱 연산 방식의 특성에 기초하여 동작 모드를 선택하고, 결정된 동작 모드에 따라 합성곱 연산 동작을 수행하도록 프로세싱 엘리먼트 어레이를 제어할 수 있다. 더 나아가면, 컨트롤러는 제1 모드에서 포인트와이즈 합성곱 연산과 같은 제1 합성곱 연산을 수행하고, 제 2 모드에서 뎁스와이즈 합성곱 연산과 같은 제2 합성곱 연산을 수행하도록 프로세싱 엘리먼트 어레이를 제 어할 수 있다. 일반적으로, 포인트와이즈 합성곱 연산은 1 × 1 × M 행렬 형태의 커널 데이터를 이용하여 수행되는 연산이고, 뎁스와이즈 합성곱 연산은 N × M × 1 행렬 형태의 커널 데이터를 이용하여 수행되는 연산이다. 여기서, N, M 은 정수이고, N과 M은 같은 수일 수 있다. 뎁스와이즈 합성곱 연산을 수행할 시 NPU는 복수의 PE 행렬로 구성된 프로세싱 엘리먼트 어레이의 일부 PE 행만을 이용하여 연산을 수행하므로, 연산을 위해 사용되지 않은 PE들이 존재하게 된다. 또한, 일부 PE 행만을 이용하여 뎁스와이즈 합성곱 연산이 이루어지더라도 포인트와이즈 합성곱 연산에 비해 뎁스와이즈 합성 곱 연산을 위해 소요되는 시간이 빠르지 않아 NPU에서의 뎁스와이즈 합성곱 연산이 효율성이 떨어진다. 즉, 프로세싱 엘리먼트 어레이의 가동률이 저하될 수 있다. 이러한 비효율성을 극복하기 위해, 본 개시는 프로세싱 엘리먼트 어레이가 뎁스와이즈 합성곱 연산 시 가 중치 또는 특징맵 데이터를 재사용함으로써, 메인 메모리와 온칩 영역(A) 사이의 데이터 이동을 최소화하 도록 구성된 신경 프로세싱 유닛을 제안한다. 이러한 비효율성을 극복하기 위해, 본 개시는 프로세싱 엘리먼트 어레이가 뎁스와이즈 합성곱 연산 시 가 중치 데이터를 재사용함으로써, 동작하지 않은 PE들의 전원을 오프(off)하도록 구성된 신경 프로세싱 유닛을 제 안한다. 이러한 비효율성을 극복하기 위해, 본 개시는 프로세싱 엘리먼트 어레이가 뎁스와이즈 합성곱 연산 시 가 중치 데이터를 재사용함으로써, 뎁스와이즈 연산을 위해 소요되는 시간 및 전력량을 줄이고, 효율적인 연산 성 능을 갖는 신경 프로세싱 유닛을 제안한다. 이하에서는 신경 프로세싱 유닛이 제1 모드 또는 제2 모드에 따라 프로세싱 엘리먼트 어레이를 운영하여 하드웨 어 리소스 사용 및 전력 소모를 줄이고, 개선된 연산 성능을 갖도록 하기 위한 프로세싱 엘리먼트 어레이를 구 체적으로 설명한다. 도 6은 본 개시의 실시예에 따른 프로세싱 엘리먼트 어레이 중 하나의 프로세싱 엘리먼트를 설명하는 구성도이 다. 제시된 실시예에서 프로세싱 엘리먼트의 동작을 구체적으로 설명하기 위해 도 4를 통해서 설명된 구성 요소(즉, 가중치 저장부, 특징맵 저장부 및 모드 선택부)를 이용하도록 한다.도 6을 참조하면, 복수의 프로세싱 엘리먼트 중 하나인 제1 프로세싱 엘리먼트(PE_00)는 제1 프로세싱 엘 리먼트(PE_00)에 대응하여 레지스터가 구비된다. 레지스터는 레지스터 파일로 지칭될 수 있다. 레지스터는 도 5에 도시된 누산기의 누산 값을 저장하는 임시 메모리에 대응될 수 있다. 제1 프로세싱 엘리먼트(PE_00)는 가중치 저장부와 연결되어 가중치 데이터가 전달되는 신호 라인 (W_in_0)과 연결되고, 특징맵 저장부와 연결되어 특징맵 데이터가 전달되는 신호 라인(F_in_0)과 연결될 수 있다. 제1 프로세싱 엘리먼트(PE_00)는 가중치 저장부로부터 전달된 가중치 데이터 및 특징맵 저장부 로부터 전달된 특징맵 데이터에 대한 연산(예: MAC 연산)을 수행하고, 연산값을 레지스터에 저장할 수 있 다. 여기서, 연산값은 특징맵 데이터에 가중치 데이터가 MAC 연산된 결과를 나타내는 특징맵 데이터일 수 있다. 예를 들면, 제1 프로세싱 엘리먼트(PE_00)가 3 × 3 행렬의 가중치 커널로 합성곱 연산을 하려면 9 클럭이 소요될 수 있다. 9 클럭 동안 누산된 값은 레지스터에 저장될 수 있다. 제1 프로세싱 엘리먼트 (PE_00)에서 연산이 완료되면 연산값을 초기화하는 리셋 신호(Reset_00)가 수신되고, 이로 인해 제1 프로 세싱 엘리먼트(PE_00)의 연산값이 초기화될 수 있다. 제1 프로세싱 엘리먼트(PE_00)는 가동 여부에 따라서 인에이블 신호(Enable, En0)가 인가되어 NPU의 소비 전력을 저감하도록 구성될 수 있다. 또한 각각의 프로세싱 엘리먼트의 가동 여부에 따라서 NPU의 프 로세싱 엘리먼트 어레이의 가동율이 결정될 수 있다. 각각의 프로세싱 엘리먼트의 가동여부는 컨트롤러에 의해서 제어될 수 있다. 컨트롤러는 각각의 프로 세싱 엘리먼트에 대응되는 인에이블 신호를 생성하도록 구성될 수 있다. 레지스터는 도 4를 참조하여 앞서 설명한 레지스터 파일을 의미할 수 있다. 연산값을 특징맵 저장부 로 출력하기 위한 출력 명령 신호가 수신되면 레지스터는 특징맵 저장부와 연결된 출력 신호 라인 (F_out_00)을 통해 연산값을 출력하고, 출력된 연산값은 특징맵 저장부에 저장될 수 있다. 이러한 레지스 터는 선택적으로 구비될 수 있다. 레지스터가 구비되지 않은 경우, 제1 프로세싱 엘리먼트(PE_00)의 연산값은 특징맵 저장부로 바 로 전달되어 저장되도록 구성될 수 있다. 제1 프로세싱 엘리먼트(PE_00)는 MAC 연산이 완료되면 출력 데이터가 전달되는 신호 라인(F_out_00)과 연 결될 수 있다. 상기 신호 라인(F_out_00)은 내부 메모리와 연결되거나 또는 별도의 벡터 프로세싱 유닛(미 도시) 또는 활성화 함수 연산 유닛(미도시)와 연결되도록 구성될 수 있다. 부연 설명하면, 본 개시의 실시예들에 따른 프로세싱 엘리먼트는 입력 받은 가중치 데이터를 다른 프로세싱 엘 리먼트에 전달하도록 구성될 수 있다. 따라서 전달되는 가중치 데이터는 프로세싱 엘리먼트 어레이 내부에서 재 사용될 수 있기 때문에, 상기 가중치 데이터를 내부 메모리, 온칩 메모리 및/또는 메인 메모리 에서 다시 로드 하는 횟수를 저감할 수 있다. 제1 프로세싱 엘리먼트(PE_00)에는 레지스터 이외에 제1 프로세싱 엘리먼트(PE_00)에 대응하여 제1 멀티플렉서(MUX1) 및 딜레이 버퍼(Z-k)가 더 구비될 수 있다. 제1 멀티플렉서(MUX1)는 동작 모드에 따라 딜레이 버퍼(Z-k)로부터 출력된 가중치 데이터 또는 제1 프 로세싱 엘리먼트(PE_00)로부터 출력된 가중치 데이터 중 어느 하나를 인접한 프로세싱 엘리먼트로 전달할 수 있다. 구체적으로, 모드 선택부로부터 제1 모드로 동작하기 위한 선택 신호(SELECT_0)가 수신되면 제1 멀티플렉 서(MUX1)는 제1 모드로 동작한다. 모드 선택부로부터 제2 모드로 동작하기 위한 선택 신호(SELECT_1)가 수신되면 제1 멀티플렉서(MUX1)(13 0)는 제2 모드로 동작한다. 제1 모드에서 제1 멀티플렉서(MUX1)는 제1 프로세싱 엘리먼트(PE_00)의 출력된 가중치 데이터를 인접 한 프로세싱 엘리먼트로 전달한다. 여기서, 가중치 데이터는 제1 프로세싱 엘리먼트(PE_00)와 인접한 적어 도 하나의 프로세싱 엘리먼트로 각각 전달될 수 있다. 단, 인접한 프로세싱 엘리먼트는 본 개시의 설명의 편이 를 위한 것일 뿐이며, 인접한 프로세싱 엘리먼트는 대응되는 프로세싱 엘리먼트로 지칭될 수 있다.제2 모드에서 제1 멀티플렉서(MUX1)는 딜레이 버퍼(Z-k)로부터 출력된 가중치 데이터를 인접한 프로세 싱 엘리먼트로 전달한다. 딜레이 버퍼(Z-k)로부터 출력된 가중치 데이터는 기 설정된 클럭(clock) 만큼 딜 레이된(time delayed) 가중치 데이터일 수 있다. 이와 같이 딜레이된 가중치 데이터가 제1 프로세싱 엘리먼트(PE_00)와 연결된 적어도 하나의 프로세싱 엘 리먼트로 각각 전달될 수 있다. 다양한 실시예에서 딜레이된 가중치 데이터는 제1 프로세싱 엘리먼트 (PE_00)와 연결된 열에 해당하는 적어도 하나의 프로세싱 엘리먼트로 딜레이되며 순차적으로 전달될 수 있 다. 즉, 특정 프로세싱 엘리먼트는 입력 받은 가중치를 매 동작 클럭마다 인접한 다른 프로세싱 엘리먼트로 전달하 거나 또는 딜레이 버퍼로 전달할 수 있다. 상기 동작을 위해서 멀티플렉서가 제공될 수 있다. 즉, 제1 멀티플렉서는 특정 프로세싱 엘리먼트에서 출력하는 가중치 및 딜레이 버퍼에서 출력하는 가중치 를 입력 받도록 구성된다. 즉, 제1 멀티플렉서는 딜레이 버퍼 및 프로세싱 엘리먼트에서 출력하는 가중치 데이터를 입력 받도록 구성될 수 있다. 딜레이 버퍼(Z-k)는 가중치 저장부로부터 전달된 가중치 데이터(W_in_0)를 기 설정된 클럭만큼 임시로 저장한 후 출력한다. 딜레이 버퍼(Z-k)에서 출력된 가중치 데이터(W_in_0)는 멀티플렉서(MUX1)로 입 력된다. 딜레이 버퍼(Z-k)에서 출력된 가중치 데이터(W_in_0)는 앞서 설명한 바와 같이 기 설정된 클럭만큼 딜레이된 가중치 데이터일 수 있다. 딜레이 버퍼(Z-k)는 제1 모드에서 동작하지 않고, 제2 모드에서만 동작 한다. 즉, 제1 멀티플렉서(MUX1)는 제1 모드에서 제1 입력을 선택하고, 제2 모드에서 제2 입력을 선택할 수 있다. 합성곱 연산을 수행할 시 특징맵 데이터 및 특징맵 데이터와 연산되는 커널 데이터(즉, 가중치 데이터) 는 행렬 형태를 갖는다. 본 개시의 실시예들에 따른 프로세싱 엘리먼트 어레이의 딜레이 유닛에 따르면, 프로세싱 엘리먼트 어레이 중 적어도 일부 열에 해당하는 프로세싱 엘리먼트가 딜레이 버퍼(Z-k)를 활용하여 뎁스와이즈 합성곱 연산을 수행하 도록 구성될 수 있다. 즉, 딜레이 버퍼(Z-k)에 의해서, 행렬 형태의 커널 데이터가 행렬 형태의 특징맵 데이터를 기 설정된 간격 만큼 슬라이딩하는 방식으로 특정 프로세싱 엘리먼트에서 합성곱 연산되면, 커널 데이터의 일부가 인접한 다른 프로세싱 엘리먼트의 합성곱 연산을 위해 재사용될 수 있다. 이처럼 재사용되는 커널 데이터의 일부를 가중치 저장부에서 프로세싱 엘리먼트 어레이로 반복하여 로드하지 않고, 딜레이 버퍼(Z-k)를 이용하여 재사용함으로써, 뎁스와이즈 합성곱 연산 성능을 향상시킬 수 있다. 한편, 프로세싱 엘리먼트 어레이에서 제2 모드에서 동작되는 프로세싱 엘리먼트들은 인에이블 신호(En0)에 의해 활성화되고, 동작되지 않은 나머지 프로세싱 엘리먼트는 비활성화됨으로써, NPU의 전력 소모를 저감 시킬 수 있다. 이하에서는 이러한 프로세싱 엘리먼트가 행렬 형태로 구성된 프로세싱 엘리먼트 어레이를 도 7을 참조하여 설명 하도록 한다. 도 7은 본 개시의 실시예에 따른 프로세싱 엘리먼트 어레이의 구조를 나타내는 개략적인 구성도이다. 제시된 실 시예에서는 프로세싱 얼리먼트의 동작을 설명하는데 있어 불필요한 구성은 일부 생략한다. 도 7을 참조하면, 프로세싱 엘리먼트 어레이는 복수의 PE 행 및 복수의 PE 열로 구성된 복수의 PE를 포함 할 수 있다. 프로세싱 엘리먼트 어레이의 복수의 PE 각각은 가중치 저장부와 연결된 W_in 신호 라인들을 통해 가 중치를 입력받도록 구성되고, 특징맵 저장부와 연결된 F_in 신호 라인들과 연결될 수 있다. 프로세싱 엘리먼트 어레이는 모드 선택부의 선택 신호(SELECT_0, SELECT_1)에 의해 제1 모드 또는 제 2 모드로 동작할 수 있다 모드 선택부로부터 제1 모드로 동작하기 위한 선택 신호(SELECT_0)가 수신되면 수신된 선택 신호는 멀티플 렉서(MUX1, MUX2)로 전달되어 멀티플렉서(MUX1, MUX2)가 제1 모드로 동작하도록 한다. 모드 선택부로부터 제2 모드로 동작하기 위한 선택 신호(SELECT_1)가 수신되면 수신된 선택 신호는 멀티플 렉서(MUX1, MUX2)로 전달되어 멀티플렉서(MUX1, MUX2)가 제2 모드로 동작하도록 한다. 여기서, 제1 모드는 스탠다드 합성곱 연산 또는 포인트와이즈 합성곱 연산을 위한 동작 모드를 의미할 수 있다. 여기서, 제2 모드는 뎁스와이즈 합성곱 연산을 위한 동작 모드를 의미할 수 있다. 본 개시에서 멀티플렉서는 선택기 또는 스위치로 지칭되는 것도 가능하다. 각각의 제1 멀티플렉서(MUX1)는 열 방향, 수직 방향, 또는 제1 방향으로, 적어도 (k-stride)개의 PE들의 가중치 데이터의 출력 라인들과 각각 연결될 수 있다. 제1 멀티플렉서(MUX1)의 개수는 (k-stride)개의 PE 행들에 대응 되는 프로세싱 엘리먼트의 개수와 동일할 수 있다. 예를 들어, 하나의 PE 행은 M개의 프로세싱 엘리먼트들을 포 함할 수 있다. 단 본 개시는 이에 제한되지 않는다. 제2 멀티플렉서(MUX2)는 행 방향, 수평 방향, 또는 제2 방향으로 적어도 (k-stride)개의 PE 행에 대한 특징맵 데이터의 입력 라인들과 연결될 수 있다. 제2 멀티플렉서(MUX2)의 개수는 적어도 (k-stride)개일 수 있다. 단 본 개시는 이에 제한되지 않는다. 여기서, k는 가중치 커널의 크기일 수 있다. 예를 들면 커널의 크기가 3 × 3 이면 k=3일 수 있다. 여기서, 간격(stride)은 합성곱의 stride 값을 의미한다. 간격은 예를 들어, 1 이상의 정수 일 수 있다. 예를 들어, k는 '3'이고 stride가 '1'이면 제1 멀티플렉서(MUX1) 각각은 적어도 2개의 PE 행들의 가중치 데이터 출력 라인들과 각각 연결되고, 제2 멀티플렉서(MUX2) 각각은 적어도 2개의 PE 행들의 특징맵 데이터의 입력 라인들과 각각 연결될 수 있다. 여기서 특징맵 데이터의 입력 라인은 M개의 채널로 구성된 신호 버스일 수 있다. 여기서 M은 하나의 PE 행에 배치된 프로세싱 엘리먼트들의 개수를 의미할 수 있다. 단 본 개시는 이에 제한되지 않는다. 다시 말해서, 제1 멀티플렉서(MUX1)는 적어도 (k-stride)개의 PE 행들에 해당하는 복수의 PE의 가중치 데이터의 출력 라인 및 대응되는 딜레이 버퍼(Z-k)의 가중치 데이터의 출력 라인과 연결된다. 다시 말해서, 제2 멀티플렉서(MUX2)는 특징맵 저장부로부터 적어도 (k-stride)개의 PE행들에 해당하는 특 징맵 데이터가 입력되는 입력 라인과 연결될 수 있다. 멀티플렉서(MUX1, MUX2)의 개수는 처리하고자 하는 인공 신경망모델의 커널의 크기를 참고하여 결정될 수 있으나, 이에 한정되지 않는다. 부연 설명하면, 제1 PE 행은 제1 복수의 프로세싱 엘리먼트들(PE_00, PE_01, …)을 지칭할 수 있고, 제2 PE 행 은 제2 복수의 프로세싱 엘리먼트들(PE_10, PE_11, …)을 지칭할 수 있다. 부연 설명하면 제1 PE 열은 제3 복수의 프로세싱 엘리먼트들(PE_00, PE_10, PE_20, PE_30, …)을 지칭할 수 있 고, 제2 PE 열은 제4 복수의 프로세싱 엘리먼트들(PE_01, PE_11, PE_21, PE_31, …)을 지칭할 수 있다. 이하 제1 모드를 예시로 본 개시의 실시예에 따른 프로세싱 엘리먼트 어레이를 설명한다. 제1 모드에서 가중치 저장부로부터 출력된 가중치 데이터는 각 W_in 신호 라인을 통해 복수의 PE 열 각각 으로 입력된다. 예를 들어, 제1 가중치 데이터는 W_in_0 신호 라인에 대응하는 제1 PE 열(PE_00, PE_10, PE_20, PE_30, …)으로 입력된다. 이때, 제1 프로세싱 엘리먼트(PE_00)에 입력된 제1 가중치 데이터가 제1 프로 세싱 엘리먼트(PE_00)로부터 출력되어 제1 프로세싱 엘리먼트(PE_00)에 대응하는 제1 멀티플렉서(MUX1)로 입력 된다. 제1 멀티플렉서(MUX1)는 제1 모드에서 제1 프로세싱 엘리먼트(PE_00)로부터 출력된 가중치 데이터를 다음 클럭에, 인접한 다음 행의 제2 프로세싱 엘리먼트(PE_10)로 전달한다. 이어서 제2 프로세싱 엘리먼트(PE_10)로 입력된 가중치 데이터는 다음 클럭에 제2 프로세싱 엘리먼트(PE_10)로 부터 출력되어 제2 프로세싱 엘리먼트(PE_10)의 출력 신호 라인과 연결된 제1 멀티플렉서(MUX1)로 입력된다. 제 1 멀티플렉서(MUX1) 또한 제1 모드에서 제2 프로세싱 엘리먼트(PE_10)로부터 출력된 가중치 데이터를, 동일한열에서 인접한 다음 행의 제3 프로세싱 엘리먼트(PE_20)로 전달한다. 이어서 제3 프로세싱 엘리먼트(PE_20)로 입력된 가중치 데이터는 제3 프로세싱 엘리먼트(PE_20)로부터 출력되어 동일한 행에서 인접한 다음 열의 제4 프로세싱 엘리먼트(PE_30)로 입력된다. 이러한 동작은 각 행렬의 마지막 프로세싱 엘리먼트까지 계속될 수 있다. 예를 들면, 하나의 가중치 데이터는 W_in_0 신호 라인에 연결된 제1 PE 열(PE_00, PE_10, PE_20, PE_30, …)을 따라서 순차적으로 전달될 수 있다. 즉, 본 개시의 실시예들에 따른 프로세싱 엘리먼트 어레이의 PE 열은 가중치 데이터를 인접한 PE로 전달하 도록 구성된 파이프라인 구조를 가지도록 구성될 수 있다. W_in_1 신호 라인에 대응하는 제2 PE 열 또한 앞서 설명한 바와 같은 동일한 동작이 수행되며, 프로세싱 엘리먼 트 어레이의 복수의 PE 열에 대해서 동일한 동작이 수행될 수 있다. 제1 모드에서 특징맵 저장부로부터 출력된 특징맵 데이터는 각 F_in 신호 라인을 통해 복수의 PE 행 각각 으로 입력된다. 예를 들어, 특징맵 데이터는 F_in_00 신호 라인, F_in_10 신호 라인, F_in_20 신호 라인, F_in_30 신호 라인, …. 에 대응하는 PE 행으로 유니캐스팅(unicasting) 또는 브로드캐스팅(broadcasting) 될 수 있다. 이러한 동작은 각 행렬의 마지막 프로세싱 엘리먼트까지 계속될 수 있다. F_in 신호 라인은 M개의 채널로 구성된 버스일 수 있다. F_in 신호 라인은 1개의 PE 행에 대응되는 개별 신호 라인들을 포함하는 버스 라인일 수 있다. 예를 들어, 제1 PE 행(PE_00, PE_01, …)이 64개의 프로세싱 엘리먼트 를 가지도록 구성되면, F_in_00 신호 라인은 64개의 라인으로 구성된 버스 라인일 수 있다. 그리고, F_in 신호 라인은 PE 행의 각각의 프로세싱 엘리먼트에 개별 특징맵 데이터를 유니캐스트하거나 또는 동일한 특징맵 데이 터를 브로드캐스트 하도록 구성될 수 있다. 이처럼 각 PE에 특징맵 데이터 및 가중치 데이터가 입력되면 각 PE에서 입력된 특징맵 데이터 및 가중치 데이터 에 대한 MAC 연산이 매 클럭마다 수행되고, 연산을 통해 산출된 연산 결과 데이터(즉, 특징맵 데이터)가 각 PE 로부터 출력되어 특징맵 저장부에 저장될 수 있다. 부연 설명하면, 도 7에서는 생략되었으나, 도 6을 다시 참조하면, 각각의 PE는 MAC 연산 값이 저장된 레지스터 에서 MAC 연산 값을 출력하는 F_out 신호 라인을 각각 포함하도록 구성될 수 있다. 단, 이에 제한되지 않으며, F_out 신호 라인은 내부 메모리 또는 추가적인 다른 연산 유닛과 연결되도록 구성될 수 있다. 이하 제2 모드를 예시로 본 개시의 실시예에 따른 프로세싱 엘리먼트 어레이를 설명한다. 모드 선택부로부터 제2 모드로 동작하기 위한 선택 신호(SELECT_1)가 수신되면 수신된 선택 신호는 멀티플 렉서(MUX1, MUX2)로 전달되어 프로세싱 엘리먼트 어레이가 제2 모드로 동작하도록 한다. 여기서, 제2 모드 는 뎁스와이즈 합성곱 연산을 위한 동작 모드를 의미한다. 제2 모드에서 가중치 저장부로부터 출력된 가중치 데이터는 각 W_in 신호 라인을 통해 복수의 PE 열 각각 으로 입력된다. 이러한 경우 복수의 PE 열 중 일부 PE 행(즉, (k-stride) 열)에 대응하여 구비된 딜레이 버퍼 (Z-k)가 가중치 데이터를 재사용하기 위해 이용될 수 있다. 가중치 저장부와 연결된 W_in 신호 라인 각각은 브랜치(Branch)를 가지고, 이러한 브랜치를 통해 W_in 신 호 라인 각각에 대응하는 PE 열의 PE와 딜레이 버퍼(Z-k)가 연결될 수 있다. 이러한 딜레이 버퍼(Z-k)는 k 클럭 만큼 딜레이된 가중치 데이터를 출력한다. 즉, 딜레이 버퍼(Z-k)는 캐스캐이딩(cascading)되어 딜레이 클럭 수를 캐스캐이딩만큼 증가시킬 수 있다. 예를 들면, 제2 모드에서 가중치 저장부에 연결된 W_in_0 신호 라인을 통해 가중치 데이터가 제1 프로세싱 엘리먼트(PE_00)로 입력될 때 브랜치를 통해 해당 가중치 데이터가 제1 프로세싱 엘리먼트(PE_00)에 대응하는 딜레이 버퍼(Z-k)로도 전달된다. 딜레이 버퍼(Z-k)로 전달된 가중치 데이터는 k 클럭만큼 딜레이되어 제1 프로세 싱 엘리먼트(PE_00)에 대응하는 제1 멀티플렉서(MUX1)로 전달된다. 딜레이된 가중치 데이터는 제1 프로세싱 엘 리먼트(PE_00)에 대응하는 제1 멀티플렉서(MUX1)를 통해 다음 행의 제2 프로세싱 엘리먼트(PE_10)로 전달된다. 또한 딜레이 버퍼(Z-k)를 통해서 출력된 딜레이된 가중치 데이터는 다음 열의 제2 프로세싱 엘리먼트(PE_10)에 대응하는 딜레이 버퍼(Z-k)로 전달된다. 제2 프로세싱 엘리먼트(PE_10)에 대응하는 딜레이 버퍼(Z-k)로 전달된 딜레이된 가중치 데이터는 k 클럭만큼 딜 레이되어 제2 프로세싱 엘리먼트(PE_10)에 대응하는 제1 멀티플렉서(MUX1)로 전달된다. 이처럼 딜레이된 가중치 데이터는 제2 프로세싱 엘리먼트(PE_10)에 대응하는 제1 멀티플렉서(MUX1)를 통해 인접한 다음 행의 제3 프로세 싱 엘리먼트(PE_20)로 입력된다. 이러한 동작은 프로세싱 엘리먼트 어레이의 각 PE 열마다 (k-stride)개의 프로세싱 엘리먼트까지 계속될 수 있다. 이와 같이 딜레이 버퍼(Z-k)가 (k-stride)개의 PE 행들에 대응하여 구비되는 구조는 캐스캐이딩되는 구조이므로, 프로세싱 엘리먼트 어레이의 확장 설계가 가능하다. 제2 모드에서 특징맵 저장부에 저장된 특징맵 데이터는 k 개의 브랜치를 가지는 F_in 신호 라인을 통해 복 수의 PE 행으로 브로드캐스팅된다. 예를 들면, F_in 신호 라인의 k 개의 브랜치는 제1 PE 행(PE_00, PE_01, …), 제2 PE행(PE_10, PE_11, …), 제3 PE행(PE_20, PE_21, …)과 연결될 수 있다. 제2 모드에서 이러한 F_in 신호 라인은 k 개의 브랜치를 가지고, 브랜치를 통해 F_in 신호 라인에 대응하는 (k- stride)개의 PE 행의 입력 라인들과 연결될 수 있다. 제2 모드에서 k 개의 브랜치를 통해 입력되는 특징맵 데이터는 제1 PE 행(PE_00, PE_01, …)과 제2 멀티플렉서 (MUX2)와 연결된 제2 PE 행(PE_10, PE_11, …) 및 제3 PE 행(PE_20, PE_21, …)으로 전달된다. 따라서 특징맵 데이터는 제1 PE 행(PE_00, PE_01, …), 제2 PE 행(PE_10, PE_11, …), 제3 PE 행(PE_20, PE_21, …)에 브로드 캐스팅된다. 이처럼 각 PE에 특징맵 데이터(즉, 입력 특징맵 데이터) 및 가중치 데이터가 입력되면 각 PE에서 입력된 특징맵 데이터 및 가중치 데이터에 대한 MAC 연산이 수행된다. 연산을 통해 산출된 연산 결과 데이터(즉, 출력 특징맵 데이터)는 각 PE로부터 출력되어 내부 메모리 또는 특징맵 저장부에 저장될 수 있다. 제2 모드에서 동작하는 K 개의 PE 행들은 인에이블(En) 신호를 통해 활성화되고, 동작하지 않은 나머지 PE 행들 은 NPU의 전력 효율을 위해 비활성화될 수 있다. 제2 모드에서는 특징맵 데이터가 특정 PE 행들에 브로드캐스팅됨에 따라 제1 모드와 비교해서 특징맵 신호가 변 경된다. 따라서 제2 모드에 대해서는 도 8을 참조하여 자세히 후술한다. 이하에서는 제1 모드에서의 프로세싱 엘리먼트 어레이의 동작을 도 8를 참조하여 구체적으로 설명하도록 한다. 도 8은 본 개시의 실시예에 따른 제1 모드에서 동작하는 프로세싱 엘리먼트 어레이의 구조를 나타내는 개략도이 다. 설명의 편의를 위해서 도 7에 도시된 구성 요소들 중 제1 모드에서 실질적으로 동작하지 않는 구성 요소들은 도 8에서 생략하여 설명한다. 제시된 실시예에서 프로세싱 엘리먼트 어레이는 N × M 개의 프로세싱 엘리먼트(PE)를 포함하는 것으로 설명한 다. 여기서, 여기서, N, M은 정수이고, N과 M은 동일한 수일 수 있다. 도 8을 참조하면, 제1 모드에서 프로세싱 엘리먼트 어레이는 Output Stationary Systolic Array 방식으로 구성될 수 있으나, 이에 한정되지 않는다. 제1 모드에서 가중치 저장부로부터 출력된 가중치 데이터는 가중치 저장부의 출력과 연결된 W_in 신 호 라인들(W_in_0, W_in_1, … W_in_M)을 통해 프로세싱 엘리먼트 어레이를 구성하는 각 PE로 전달된다. 예를 들어, 가중치 데이터는 복수의 PE열 중 제1 PE열과 연결되는 W_in_0 신호 라인을 통해 파이프라인화 (pipeline)되어 제1 PE열의 PE_00, PE_10, PE_20, PE_30, …, PE_N0로 캐스캐이딩되고, 복수의 PE열 중 제2 PE 열과 연결되는 W_in_1 신호 라인을 통해 파이프라인화되어 제2열의 PE_01, PE_11, PE_21, PE_31, …, PE_N1로 캐스캐이딩될 수 있다. 제1 모드에서 특징맵 저장부로부터 출력된 특징맵 데이터는 특징맵 저장부의 출력과 연결된 F_in 신 호 라인(F_in_00, F_in_01, … F_in_NM)을 통해 프로세싱 엘리먼트 어레이를 구성하는 각 PE로 전달된다. 예를 들어, 특징맵 데이터는 복수의 PE행 중 제1 PE행과 연결되는 F_in_00, F_in_01, …, F_in_0M 신호 라인을 통해 제1 PE행의 PE_00, PE_01, …, PE_0M으로 공급되고, 복수의 PE행 중 제2 PE행과 연결되는 F_in_10, F_in_11, …, F_in_1M 신호 라인을 통해 제2 PE행의 PE_10, PE_11, …, PE_1M으로 공급될 수 있다. 또한 특징맵 데이터는 복수의 PE행 중 제3 PE행과 연결되는 F_in_20, F_in_21, …, F_in_2M 신호 라인을 통해 제3 PE행의 PE_20, PE_21, …, PE_2M으로 공급되고, 복수의 PE행 중 제4 PE행과 연결되는 F_in_30, F_in_31, …, F_in_3M 신호 라인을 통해 제4 PE행의 PE_30, PE_31, …, PE_3M으로 공급될 수 있다. 이처럼 가중치 데이터 및 특징맵 데이터가 입력되면 각 PE는 가중치 데이터 및 특징맵 데이터에 대한 MAC 연산 을 수행하고, 연산 결과를 특징맵 저장부로 전달한다. 이와 같이 프로세싱 엘리먼트 어레이는 가중치 저장부와 W_in 신호 라인(W_in_0, W_in_1, … W_in_M)을 통해 연결되고, 특징맵 저장부와 F_in 신호 라인(F_in_00, F_01, … F_in_NM)으로 연결될 수 있다. 특히, F_in_00, F_in_01, … F_in_0M이 입력되는 신호 라인은 M-1개의 신호 라인들이 배치된 버스일 수 있다. 각 신호 라인은 프로세싱 엘리먼트 어레이의 각 PE와 연결될 수 있다. 따라서, F_in 신호 라인을 통해서 전달되는 특징맵 데이터는 점대점(point to point) 통신인 유니캐스트(unicast) 통신으로 이루어질 수 있다. 한편, W_in_0이 입력되는 신호 라인은 한 개의 신호 라인이 배치될 수 있다. 해당 신호 라인은 열 방향으로 프 로세싱 엘리먼트 어레이의 각 PE와 연결될 수 있다. 따라서, W_in_0 신호 라인을 통해서 PE(예: PE_00)에 전달된 가중치 데이터는 매 클럭마다 다음 행의 PE(예: PE_10)로 쉬프트(shift), 즉, 전달될 수 있다. 이를 통 해 가중치 데이터가 프로세싱 엘리먼트 어레이 내에서 재사용되어 연산을 위해 사용되는 리소스 소모 및 메모리 사용량을 최소화시킬 수 있다. 이하에서는 제2 모드에서의 프로세싱 엘리먼트 어레이의 동작을 도 9를 참조하여 구체적으로 설명하도록 한다. 도 9는 본 개시의 실시예에 따른 제2 모드에서 동작하는 프로세싱 엘리먼트 어레이의 구조를 나타내는 개략도이 다. 설명의 편의를 위해서 도 7에 도시된 구성 요소들 중 제2 모드에서 실질적으로 동작하지 않는 구성 요소들은 도 9에서 생략하여 설명한다. 프로세싱 엘리먼트 어레이는 N × M 개의 프로세싱 엘리먼트(PE)를 포함하는 것으로 설명한다. 여기서, 여 기서, N, M은 정수이고, N과 M은 동일한 수일 수 있다. 제2 모드에서, 예를 들어 커널의 크기가 3 × 3일 경우, 특징맵 저장부에서 출력된 특징맵 데이터는 F_in 신호 라인들에 해당하는 k 개의 브랜치로 연결된 F_in_00, F_in_01, … F_in_0M 신호 라인들을 통해 k 개의 PE 행들에 브로드캐스팅된다. 예를 들면, 제2 모드에서 k 개의 브랜치와 연결된 제1 PE 열(PE_00, PE_10, PE20)에는 F_in_00 신호가 브로드 캐스팅된다. 예를 들면, 제2 모드에서 k 개의 브랜치와 연결된 제2 PE 열(PE_01, PE_11, PE21)에는 F_in_01 신호가 브로드 캐스팅된다. 제2 모드에서 가중치 저장부로부터 출력된 가중치 데이터는 가중치 저장부의 출력과 연결된 W_in 신 호 라인들(W_in_0, W_in_1, … W_in_M)을 통해 프로세싱 엘리먼트 어레이를 구성하는 각 PE로 전달된다. 해당 가중치 데이터는 각 PE에 대응하는 딜레이 버퍼(Z-k)에 전달되고, 딜레이 버퍼(Z-k)와 연결된 각 행의 다음 PE로 전달될 수 있다. 예를 들어, 가중치 데이터는 복수의 PE열 중 제1 PE열과 연결되는 W_in_0 신호 라인을 통해 PE_00으로 전달되고, 해당 가중치 데이터는 PE_00에서 MAC 연산되고, PE_00에 대응하는 브랜치를 통해 딜레이 버퍼(Z-k)로 전달되어 k 클럭만큼 딜레이될 수 있다. 이처럼 딜레이된 가중치 데이터는 인접한 다음 열의 PE_10으로 전달된 다. 이어서, 딜레이된 가중치 데이터는 PE_10에서 MAC 연산되고, PE_10에 대응하는 브랜치를 통해 딜레이 버퍼(Z- k)로 전달되어 다시 k 클럭만큼 딜레이될 수 있다. 즉, 2k 클럭만큼 딜레이된 가중치 데이터가 제1행에서 인접 한 다음 열의 PE_20으로 전달된다. 딜레이된 가중치 데이터는 PE_20에서 MAC 연산된다. 이러한 동작은 W_in_1, … W_in_M 신호 라인들 각각에 대응 하는 PE 열에 대해서 수행될 수 있다.이처럼 딜레이 버퍼(Z-k)를 통해 딜레이되며 전달된 가중치 데이터는 각 PE 열 방향으로 딜레이 브로드캐스팅 (delayed broadcasting)될 수 있다. 따라서, 가중치 저장부에서 전달된 가중치 데이터는 딜레이 브로드캐 스팅(delayed broadcasting)에 의해 딜레이된 가중치 데이터가 제공되는 각 PE에서 재사용될 수 있다. 제2 모드에서 특징맵 저장부로부터 출력된 특징맵 데이터는 특징맵 저장부의 출력과 연결된 소정의 브랜치를 가지는 F_in 신호 라인들(F_in_00, F_01, … F_in_0M)을 통해 프로세싱 엘리먼트 어레이를 구성 하는 소정의 PE 행들로 브로드캐스팅된다. 제2 모드에서 k 개의 브랜치를 통해 입력되는 특징맵 데이터는 제1 PE 행(PE_00, PE_01 … PE0M)과 제2 PE 행 (PE_10, PE_11, … PE1M) 및 제3 PE 행(PE_20, PE_21, … PE2M)으로 전달된다. 따라서 특징맵 데이터는 제1 PE 행(PE_00, PE_01, …), 제2 PE 행(PE_10, PE_11, …), 제3 PE 행(PE_20, PE_21, …)에 브로드캐스팅된다. 이처럼 각 PE에 특징맵 데이터(즉, 입력 특징맵 데이터) 및 가중치 데이터가 입력되면 각 PE에 입력된 특징맵 데이터 및 가중치 데이터에 대한 MAC 연산이 매 클럭 별 수행된다. 연산을 통해 산출된 연산 결과 데이터(즉, 출력 특징맵 데이터)는 각 PE로부터 출력되어 내부 메모리 또는 특징맵 저장부에 저장될 수 있다. 즉, 각 PE는 가중치 데이터 및 특징맵 데이터를 입력 받아 가중치 데이터 및 특징맵 데이터에 대한 MAC 연산을 수행한다. 즉, 프로세싱 엘리먼트 어레이는 가중치 데이터를 입력받는 PE_00, 가중치 데이터를 입력받고 특정 클럭으로 딜 레이하여 PE_10으로 전달하도록 구성된 딜레이 버퍼(Z-k), 및 PE_00과 PE_10에 특징맵 데이터를 동시에 제공하도 록 구성된 브로드캐스트 신호 라인(F_in_00)을 포함하도록 구성될 수 있다. 따라서, 딜레이 유닛은 가중치 데이 터를 재사용하면서 뎁스와이즈 합성곱을 처리하도록 구성될 수 있다. 즉, 가중치를 전달하는 하나의 딜레이 버퍼, 딜레이 버퍼의 입력과 출력에 대응되는 2개의 프로세싱 엘리먼트, 2개의 프로세싱 엘리먼트에 특징맵을 동시에 입력하는 신호라인을 제공함에 따라 데이터 재사용이 가능한 뎁스 와이즈 합성곱을 구현할 수 있다. 또한, 인공신경망모델의 가중치 커널이 3 × 3일 경우, 가중치를 전달하는 두개의 딜레이 버퍼, 두개의 딜레이 버퍼의 입력과 출력에 대응되는 3개의 프로세싱 엘리먼트, 3개의 프로세싱 엘리먼트에 특징맵을 동시에 입력하 는 신호라인을 제공함에 따라 데이터 재사용이 가능한 뎁스와이즈 합성곱을 구현할 수 있다. 만약 인공신경망모델의 가중치 커널이 3 × 3인 경우, 제1 PE 열(PE_00, PE_10, PE20)은 제1 가중치 커널을 딜 레이 하면서 제1 뎁스와이즈 합성곱을 처리할 수 있다. 또한 제2 PE 열(PE_01, PE_11, PE21)은 제2 가중치 커널 을 딜레이 하면서 제2 뎁스와이즈 합성곱을 처리할 수 있다. 즉, 2개의 딜레이 버퍼, 3개의 프로세싱 엘리먼트, 3 개의 브랜치로 묶인 브로드캐스트 신호라인은 3 × 3 커널 의 뎁스와이즈 합성곱을 처리할 수 있는 하나의 유닛 단위가 될 수 있다. 따라서 상기 유닛 단위를 증가하면, 동시에 처리할 수 있는 뎁스와이즈 합성곱의 개수도 비례하여 증가할 수 있다. 이와 같이 프로세싱 엘리먼트 어레이는 가중치 데이터를 각 PE에 전달할 시 딜레이 버퍼를 이용하여 딜레 이 브로드캐스팅함으로써, 제2 모드 동작 시 NPU에서 소모되는 에너지를 절약하고, 프로세싱 엘리먼트 어레이의 동작 효율성 및 NPU의 스루풋(throughput)이 향상될 수 있다. 또한, 프로세싱 엘리먼트 어레이는 제2 모드 에서 동작하지 않은 구성 요소를 비활성화함으로써, 전력 소모를 최소화할 수 있다. 즉, 도 8과 도9를 비교하면, 제1 모드는 F_in 신호 라인이 각 PE 마다 개별로 동작하도록 구성되고, 제2 모드는 F_in 신호 라인이 각 PE 열의 PE들 중 적어도 일부가 브랜치로 연결되어 각 PE 열의 일부 PE들이 브로드캐스팅 되도록 구성된다. 이하에서는 제1 모드 또는 제2 모드에서 동작하는 각 PE를 그룹화하여 활성화 또는 비활성화함으로써, 저전력 모드로 동작하기 위한 프로세싱 엘리먼트 어레이를 도 10을 참조하여 설명하도록 한다. 도 10은 본 개시의 실시예에 따른 프로세싱 엘리먼트 어레이의 구조를 나타내는 개략적인 구성도이다. 도 10을 참조하면, 프로세싱 엘리먼트 어레이는 제1 모드와 제2 모드에 따라 동작하는 PE를 구분하여 제1 모드에 따라 동작하는 복수의 PE을 그룹화하고, 제2 모드에 따라 동작하는 복수의 PE를 그룹화할 수 있다. 도 7을 참조하면, 제1 그룹 및 제2 그룹에 해당하는 PE들은 제1 모드에서 동작하고, 제1 그룹에 해당하는 PE들은 제2 모드에서만 동작할 수 있다. 모드 선택부로부터 제1 모드로 동작하기 위한 선택 신호가 수신되면 프로세싱 엘리먼트 어레이는 제1 그룹 및 제2 그룹의 PE들을 활성화하기 위해 제1 그룹 및 제2 그룹의 각 PE로 인에이블 신 호를 전달한다. 이로 인해, 제1 그룹 및 제2 그룹의 PE들이 활성화되어 제1 모드의 동작을 수행할 수 있다. 모드 선택부로부터 제2 모드로 동작하기 위한 선택 신호가 수신되면 프로세싱 엘리먼트 어레이는 제2 모드에서 동작하는 제1 그룹의 PE들을 활성화하기 위해 제1 그룹의 각 PE로 인에이블 신호를 전달한 다. 이로 인해, 제1 그룹의 PE들이 활성화되어 제2 모드의 동작을 수행하고, 제2 그룹은 비활성화될 수 있다. 이처럼, 제2 모드에서 미사용되는 PE가 비활성화됨으로써, 프로세싱 엘리먼트 어레이의 저전력 모드 동작이 구현될 수 있다. 다양한 실시예에서 프로세싱 엘리먼트 어레이는 복수의 제1 그룹을 포함하도록 구성될 수 있다. 따라 서 프로세싱 엘리먼트 어레이의 뎁스와이즈 합성곱 연산시 프로세싱 엘리먼트 어레이의 가동률이 증 가될 수 있다. 다양한 실시예에서 프로세싱 엘리먼트 어레이는 적어도 하나일 수 있다. 즉, 프로세싱 엘리먼트 어레이는 복수개 구비되어 인공신경망 모델의 레이어 중 일부를 분할하여 처리하도록 구성될 수 있다. 다양한 실시예에서 프로세싱 엘리먼트 어레이는 인공신경망모델의 각 레이어에 따라 인에이블 신호를 인가 하여 해당하는 PE를 개별로 구동시킬 수 있다. 프로세싱 엘리먼트 어레이는 인공신경망모델의 레이어 구조 를 분석하여 인공신경망모델의 레이어별 연산 시 해당하는 PE를 개별적으로 활성화(on) 또는 비활성화(off)함으 로써, NPU의 소비 전력을 최소화할 수도 있다. 이하에서는 다양한 구조의 딜레이 버퍼가 구비된 프로세싱 엘리먼트 어레이를 도 11을 참조하여 설명하도록 한 다. 입력된 커널 데이터의 원소들(a0, b0, c0, d0, e0, f0, g0, h0, i0)(①) 각각과 MAC 연산이 이루어진다. 이는 도 14에서 설명한 단계 에 해당할 수 있다. 단계 는 단계 대비 3클럭 딜레이된다. 단계 는 도 14의 3 × 3 × m 크기의 커널 데이터의 제1 커널(즉, 'a0', 'b0', 'c0', 'd0', 'e0', 'f0', 'g0', 'h0', 'i0')이 '1' 간격으로 슬라이딩하여 입력 특징맵 데이터의 원소들 중 중첩되는 제2 특징맵(즉, 'F0', 'G0', 'H0', 'K0', 'L0', 'M0', 'P0', 'Q0', 'R0') 과 연산된다. 이때, 단계 는 도 15의 PE_10에서 9클럭 동안 순차적으로 처리된다. 즉, 단계 대비 3클럭 딜레이된 제1 커널과 제2 특징맵의 합성곱 연산을 위해서 PE_10은 9 클럭의 동작이 필요하다. 이때, 단계 는 도 15의 PE_10으로 도 16의 3클럭 딜레이된 제1 커널의 신호인 W_in_0(Z-3)(PE_10) 신호와 제 2 특징맵 영역의 신호인 F_in_00 신호('F0', 'G0', 'H0', 'K0', 'L0', 'M0', 'P0', 'Q0', 'R0')가 9 클럭 동안 입력된다. 즉, 3클럭 딜레이된 제1 커널의 각각의 원소들('a0', 'b0', 'c0', 'd0', 'e0', 'f0', 'g0', 'h0', 'i0')과 제2 특징맵의 각각의 원소들('F0', 'G0', 'H0', 'K0', 'L0', 'M0', 'P0', 'Q0', 'R0')이 순차적으로 PE_10으로 입력된다. 도 14의 단계 에서와 같이 특징맵 데이터 위에서 커널 데이터가 '1' 간격 만큼 슬라이딩되어 연 산이 이루어지므로, 커널 데이터의 원소들(a0, b0, c0, d0, e0, f0, g0, h0, i0)은 3 클럭 이후에 재사 용될 수 있다. 커널 데이터를 재사용하여 연산을 수행하기 위해 가중치 저장부에서 출력된 커널 데이터는 PE_00에 대응하여 구비된 딜레이 버퍼(Z-k)로 전달된다. 딜레이 버퍼(Z-k)로 전달된 커널 데이터는 3 클럭 만큼 딜레이되어 딜레이된 커널 데이터가 PE_00에 대응하는 제1 멀티플렉서(MUX1)를 통해 다음 열의 PE_10으로 전달된다. 도 16에 도시된 바와 같이 PE_10에 입력된 커널 데이터는 3 클럭만큼 딜레이되어(②) 특징맵 데이터의 원소들 중 'F0, G0, H0, K0, L0, M0, P0, Q0, R0'과 MAC 연산이 이루어진다. 이는 도 14에서 설명한 단계 에 해당 할 수 있다.단계 은 단계 대비 3클럭 딜레이된다. 단계 은 도 14의 3 × 3 × m 크기의 커널 데이터의 제1 커널(즉, 'a0', 'b0', 'c0', 'd0', 'e0', 'f0', 'g0', 'h0', 'i0')이 '1' 간격으로 슬라이딩하여 입력 특징맵 데이터의 원소들 중 중첩되는 제3 특징맵(즉, 'K0', 'L0', 'M0', 'P0', 'Q0', 'R0', 'U0', 'V0', 'W0') 과 연산된다. 이때, 단계 은 도 15의 PE_20에서 9클럭 동안 순차적으로 처리된다. 즉, 단계 대비 3클럭 딜레이된 제1 커널과 제3 특징맵의 합성곱 연산을 위해서 PE_20은 9 클럭의 동작이 필요하다. 이때, 단계 은 도 15의 PE_20으로 도 16의 6클럭 딜레이된 제1 커널의 신호인 W_in_0(Z-6)(PE_20) 신호와 제 3 특징맵 영역의 신호인 F_in_00 신호('K0', 'L0', 'M0', 'P0', 'Q0', 'R0', 'U0', 'V0', 'W0')가 9 클럭 동안 입력된다. 즉, 6클럭 딜레이된 제1 커널의 각각의 원소들('a0', 'b0', 'c0', 'd0', 'e0', 'f0', 'g0', 'h0', 'i0')과 제3 특징맵의 각각의 원소들('K0', 'L0', 'M0', 'P0', 'Q0', 'R0', 'U0', 'V0', 'W0')이 순차적으로 PE_20으로 입력된다. 도 14의 단계 에서와 같이 특징맵 데이터 위에서 커널 데이터가 '1' 만큼 슬라이딩되어 연산이 이루어지므로, 커널 데이터의 원소들(a0, b0, c0, d0, e0, f0, g0, h0, i0)은 모두 재사용될 수 있다. 커널 데이터를 재사용하여 연산을 수행하기 위해 가중치 저장부에서 출력된 커널 데이터는 PE_10에 대응하여 구비된 딜레이 버퍼(Z-k)로 전달된다. 딜레이 버퍼(Z-k)로 전달된 커널 데이터는 3 클럭 만큼 더 딜레이되어 딜레이된 커널 데이터가 PE_10에 대응하는 제1 멀티플렉서(MUX1)를 통해 PE_20으로 전달된 다. 도 16에 도시된 바와 같이 PE_20에 입력된 커널 데이터는 6 클럭만큼 딜레이되어(③) 특징맵 데이터의 원소들 중 'K0, L0, M0, P0, Q0, R0, U0, V0, W0'과 MAC 연산이 이루어진다. 이는 도 14에서 설명한 단계 에 해당 할 수 있다. 즉, 단계 부터 9클럭 이후 PE_00의 합성곱이 완료된다. 따라서 PE_00의 누산된 값은 내부 메모리 또는 특징맵 저장부에 저장될 수 있다. 단계 부터 9클럭 이후 PE_10의 합성곱이 완료된다. 따라서 PE_10의 누산된 값은 내부 메모리 또는 특징맵 저장부에 저장될 수 있다. 단계 부터 9클럭 이후 PE_20의 합성곱이 완료된다. 따라서 PE_20의 누산된 값은 내부 메모리 또는 특징맵 저장부에 저장될 수 있다. 다시 도 6을 참조하면, 각 PE의 누산 값은 레지스터에 저장될 수 있다. 그리고 각 PE는 F_out 신호라인을 통해서 특징맵 저장부와 통신할 수 있다. 각 PE 내부에 저장된 누산 값은 MAC 연산이 마무리 된 후 특정 클럭에서 리셋(Reset) 신호를 입력 받아 초기화 될 수 있다. 그리고 초기화된 PE는 새로운 MAC 연산을 수행하도 록 준비가 된 상태일 수 있다. 각 단계가 완료되고, 완료된 결과가 내부 메모리 또는 특징맵 저장부에 저장되면, 각각의 프로세싱 엘리먼트에 저장된 값은 도 6에 도시된 리셋 신호에 의해서 초기화 될 수 있다. 따라서 단계 이 완료된 PE_00은 단계 를 처리할 수 있게 준비된다. 따라서 단계 가 완료된 PE_10은 단계 를 처리할 수 있게 준비된다. 따라서 단계 이 완료된 PE_20은 단계 을 처리할 수 있게 준비된다. 이후 도 14의 단계 , , , … 들도 상술한 바와 같이 가중치 데이터의 재사용에 의한 연산이 이루어질 수 있다. 단계 , , 을 위하여, 신호 라인 F_in_00은 새로운 특징맵 데이터의 원소들 ('B0', 'C0', 'D0', 'G0', 'H0', 'I0', 'L0', 'M0', 'N0', 'Q0', 'R0', 'S0', 'V0', 'W0', 'X0')을 순차적으로 제1 PE 열(PE_00, PE_10, PE_20)에 공급할 수 있다. 단, 본 개시는 이에 제한되지 않으며, 단계 , , 은 또 다른 PE 열 에서 처리되는 것도 가능하다. 또한 단계 , , 과 단계 , , 은 하나의 PE 열에서 순차적으로 처리되거나 또는 서로 다른 PE 열 들에서 병렬로 처리될 수 있다. 즉, 단계 내지 단계 이 완료되면 단계 내지 단계 이 동일한 방식으로 반복될 수 있다. 따라서 제 1 PE 열(PE_00, PE_10, PE20)은 다양한 커널과 다양한 특징맵을 순차적으로 입력받아 다수의 뎁스와이즈 합성곱 연산들을 처리하도록 동작할 수 있다. 이때, 커널 데이터의 적어도 일부는 프로세싱 엘리먼트 어레이 내부에서 딜레이 버퍼(Z-k)를 통해서 재사용될 수 있게 된다. 만약 딜레이 버퍼가 프로세싱 엘리먼트 어레이에 없고, 커널 데이터가 연산을 위해 사용될 때마다 가중치 저장 부에서 프로세싱 엘리먼트 어레이로 불필요하게 로드되면, 커널 데이터의 재사용이 불가능해진다. 하지만, 본 개시의 실시예들에 따른 프로세싱 엘리먼트 어레이는 뎁스와이즈 합성곱 데이터 재사용을 위한 딜레이 버퍼를 이용하여 연산 시 사용되는 리소스 및 메모리 사용량을 저감시킬 수 있다. 따라서 효율적인 뎁스 와이즈 합성곱 연산이 가능하다. 이와 같이 프로세싱 엘리먼트 어레이는 프로세싱 엘리먼트 어레이에 구비된 딜레이 버퍼(Z-k)를 이용 하여 효율적인 뎁스와이즈 합성곱 연산을 수행할 수 있다. 도 16에 도시된 바와 같이 PE_00 및 PE_10에서 6 클럭 동안 커널 데이터의 원소들이 중첩(overlap)되고, PE_10 및 PE_20에서 6 클럭 동안 커널 데이터의 원소들이 중첩된다. 이와 같이 중첩되는 시간 구간에서 연산 속도가 향상될 수 있다. 본 개시의 실시예들에 따르면, 특징맵 저장부에서 출력된 특징맵 데이터는 브랜치를 가지는 F_in 신 호 라인을 통해 복수의 PE 열로 브로드캐스팅될 수 있다. 예를 들면, F_in_00 신호 라인은 제1 PE 열(PE_00, PE_10, PE20)로 특징맵 데이터를 브로드캐스팅한다. F_in_01 신호 라인은 제2 PE 열(PE_01, PE_11, PE21)로 특징맵 데이터를 브로드캐스팅한다. F_in_0M 신호 라인 은 제1 PE 열(PE_0M, PE_1M, PE2M)로 특징맵 데이터를 브로드캐스팅한다. 따라서 본 개시의 실시예들에 따른 NPU는 각각의 PE 열 마다 커널 데이터 재사용이 가능한 뎁스와이즈 합성곱 연산을 각각 수행하도록 구성 될 수 있다. 이하에서는 간격의 크기가 '2'인 경우 뎁스와이즈 합성곱 연산을 수행하는 프로세싱 엘리먼트 어레이의 동작을 도 13, 도 15, 도 17 및 도 18을 참조하여 구체적으로 설명하도록 한다. 도 17은 본 개시의 실시예에 따른 가중치 데이터 및 특징맵 데이터에 대한 뎁스와이즈 합성곱 연산을 설명하기 위한 예시도이다 도 18은 본 개시의 실시예에 따른 딜레이 버퍼에서 시간에 따라 저장되는 가중치 데이터를 설명하기 위한 예시 도이다. 이하 설명의 편의를 위하여 중복되는 설명은 생략할 수 있다. 먼저 도 13을 참조하면, 3 × 3 × m 행렬 형태의 커널 데이터 및 5 × 5 × M 행렬 형태의 입력 특징맵 데이터에 대한 뎁스와이즈 합성곱 연산이 수행된다고 가정한다. 합성곱 연산을 위해 커널 데이터가 입력 특징맵 데이터를 순회하는 간격(stride)은 '2'로 가정한다. 즉, 간격은 '1'에서 '2'로 변경될 수 있 다. 이러한 경우 합성곱 연산은, 5 × 5 × M 크기의 입력 특징맵 데이터 위로 3 × 3 × m 크기의 커널 데이 터가 '2' 간격만큼 슬라이딩하여 커널 데이터의 각 원소와 겹쳐지는 입력 특징맵 데이터의 각 원소를 곱한 후 이들을 모두 더하는 것으로 이루어진다. 도 14와 도 17을 비교하면, 간격이 '1'에서 '2'로 변경됨에 따라 단계 와 단계 가 생략될 수 있다. 따라 서 구체적으로 각 단계들에 대하여 도 17 및 도 18을 참조하여 설명한다. 도 17 및 도 18의 단계 은 도 14 및 도 16의 단계 과 실질적으로 동일하다. 따라서 중복 설명은 생략한다. 3 × 3 × m 크기의 커널 데이터의 제1 커널(즉, 'a0', 'b0', 'c0', 'd0', 'e0', 'f0', 'g0', 'h0', 'i0')이 '1' 간격으로 슬라이딩하여 입력 특징맵 데이터의 원소들 중 중첩되는 제1 특징맵(즉, 'A0', 'B0', 'C0', 'F0', 'G0', 'H0', 'K0', 'L0', 'M0')과 연산된다. 이때, 단계 은 도 18의 PE_00에서 9클럭 동안 순차적으로 처리된다. 즉, 제1 커널과 제1 특징맵의 합성곱 연 산을 위해서 PE_00은 9 클럭의 동작이 필요하다. 도 14 및 도 16의 실시예의 단계 는 도 17 및 도 18의 실시예에서는 실질적으로 수행되지 않는다. 하지만 도 17 및 도 18의 실시예에 따른 NPU는 도 14 및 도 16의 단계 와 실질적으로 동일하게 동작할 수 있다. 다만 도 17 및 도 18의 실시예에서는, stride 2의 경우 단계 가 불필요 하기 때문에 NPU의 컨트롤러 는 단계 를 수행하는 예시적인 PE_10의 MAC 연산 값을 출력하는 F_out 신호 라인을 비활성화 할 수 있 다. 즉, 특정 프로세싱 엘리먼트의 MAC 연산 값을 취하지 않음으로써 다양한 간격(stride)값을 간단하게 조절할 수 있다. 상술한 구성에 따르면, F_out 신호 라인의 출력만 선택적으로 제어함으로 써 간격 값을 용이하게 제어할 수 있는 효과가 있다. 도 17 및 도 18의 단계 은 도 14 및 도 16의 단계 과 실질적으로 동일하다. 따라서 중복 설명은 생략한다. 단계 은 단계 대비 6 클럭 딜레이된다. 단계 은 도 17의 3 × 3 × m 크기의 커널 데이터 의 제1 커널(즉, 'a0', 'b0', 'c0', 'd0', 'e0', 'f0', 'g0', 'h0', 'i0')이 '2' 간격으로 슬라이딩하여 입력 특징맵 데이터의 원소들 중 중첩되는 제3 특징맵(즉, 'K0', 'L0', 'M0', 'P0', 'Q0', 'R0', 'U0', 'V0', 'W0')과 연산된다. 이때, 단계 은 도 15의 PE_20에서 9클럭 동안 순차적으로 처리된다. 즉, 단계 대비 6클럭 딜레이된 제1 커널과 제3 특징맵의 합성곱 연산을 위해서 PE_20은 9 클럭의 동작이 필요하다. 즉, 단계 부터 9클럭 이후 PE_00의 합성곱이 완료된다. 따라서 PE_00의 누산된 값은 내부 메모리 또는 특징맵 저장부에 저장될 수 있다. 상술하였듯이, 단계 부터 9 클럭 이후 PE_10의 합성곱이 완료된다. 하지만 PE_10의 누산된 값은 출력 되지 않을 수 있다. 단계 부터 9클럭 이후 PE_20의 합성곱이 완료된다. 따라서 PE_20의 누산된 값은 내부 메모리 또는 특징 맵 저장부에 저장될 수 있다. 각 단계가 완료되고, 완료된 결과가 내부 메모리 또는 특징맵 저장부에 선택적으로 저장될 수 있다. 따라서 단계 이 완료된 PE_00은 단계 를 처리할 수 있게 준비된다. 따라서 단계 이 완료된 PE_20은 단 계 을 처리할 수 있게 준비된다. 이후 도 14의 단계 , , … 들도 상술한 바와 같이 가중치 데이터의 재사용에 의한 연산이 이루어질 수 있 다. 단계 , 을 위하여, 신호 라인 F_in_00은 새로운 특징맵 데이터의 원소들 ('B0', 'C0', 'D0', 'G0', 'H0', 'I0', 'L0', 'M0', 'N0', 'Q0', 'R0', 'S0', 'V0', 'W0', 'X0')을 순차적으로 제1 PE 열(PE_00, PE_10, PE_20)에 공급할 수 있다. 즉, 단계 및 단계 이 완료되면 단계 및 단계 이 동일한 방식으로 반복될 수 있다. 이때, 커널 데이터의 적어도 일부는 프로세싱 엘리먼트 어레이 내부에서 딜레이 버퍼(Z-k)를 통해서 재사용될 수 있게 된다. 도 18에 도시된 바와 같이 PE_00 및 PE_20에서 3 클럭 동안 커널 데이터의 원소들이 중첩(overlap)된다. 이와 같이 중첩되는 시간 구간에서 연산 속도가 향상될 수 있다. 이하에서는 뎁스와이즈 합성곱 연산 시 특정 커널 크기 및 특정 간격에서 특정 열의 PE들의 연산이 불필요한 경 우 프로세싱 엘리먼트 어레이의 동작을 도 13, 도 15, 도 17 및 도 19를 참조하여 설명하도록 한다. 도 19는 본 개시의 실시예에 따른 딜레이 버퍼에서 시간에 따라 저장되는 가중치 데이터를 설명하기 위한 예시 도이다. 먼저 도 13 및 도 17에서 설명한 바와 같이 특정 커널 크기가 '3 × 3 × m'의 크기이고, 특정 간격을 '2'로 가 정한다. 뎁스와이즈 합성곱 연산을 위해 가중치 저장부에서 출력된 가중치 데이터(즉, 커널 데이터)는 복수 의 PE 행 각각의 제1열에 해당하는 PE들(PE_00, PE_01, …)로 입력되고, 해당 가중치 데이터는 기 설정된 클럭 만큼 딜레이되기 위해 딜레이 버퍼(Z-k)로 입력된다. 다만, 상술한 '3 × 3 × m'의 커널 크기와 '2' 간격으로 뎁스와이즈 합성곱 연산이 이루어지는 경우 특징맵 데이터 위에서 커널 데이터가 '2' 간격만큼 슬 라이딩되기 때문에, 딜레이 버퍼(Z-k)를 통해 k 클럭만큼 딜레이된 가중치 데이터는 제2 PE행(PE_10, PE_11, …)에 대응하여 배치된 딜레이 버퍼(Z-k)로 바이패스(bypass)되어 2k 클럭만큼 딜레이된 후 다음 행인 제3 PE 행 (PE_20, PE_21, …)으로 입력될 수 있다. 이러한 경우 제2 PE 행(PE_10, PE_11, …)은 어떠한 연산 동작을 수행하지 않으므로, 도 15 및 도 19에 도시된 바와 같이 비활성화를 위한 En 신호(En1=Low)를 전달하여 제2 PE 행(PE_10, PE_11, …)을 비활성화시킬 수 있다. 이와 같이 제2 PE행이 비활성화되면 제1 PE행 및 제3 PE행 각각에서만 MAC 연산이 수행될 수 있다. 이처럼 본 개시는 연산 동작을 수행하지 않은 불필요한 PE들을 비활성화함으로써, NPU의 소비 전력을 저감할 수 있 다. 몇몇 실시예에 따르면, NPU는 제1 모드 또는 제2 모드를 선택하도록 구성된 모드 선택부 및 복수의 PE를 포함하 는 PE Array를 포함할 수 있다. NPU는 제1 모드에서, 제1 입력 데이터가 PE Array로 입력되고, 제2 입력 데이터가 PE Array로 입력되도록 구성 되고, 제2 모드에서, 제1 입력 데이터가 PE Array의 PE 열 방향으로 입력되도록 구성되고, 제1 입력 데이터가 특정 클럭(clock) 만큼 딜레이되면서 PE 열 방향으로 전달되도록 구성되고, 제1 입력 데이터가 특정 클럭만큼 딜레이되는 특정 PE 행들에 제2 입력 데이터가 브로드캐스트 되도록 구성될 수 있다. 제1 모드에서, PE Array는 포인트와이즈 합성곱 연산(point-wise convolution)을 수행하도록 구성될 수 있다. 제2 모드에서, PE Array는 뎁스와이즈 합성곱 연산(depth-wise convolution)을 수행하도록 구성될 수 있다. 특정 클럭은, 인공신경망모델의 커널의 크기 또는 합성곱의 간격(stride)에 기초하여 결정될 수 있다. 제1 모드에서, PE Array의 각각의 PE 열의 PE들은 파이프라인(pipeline)화되어 제1 입력 데이터를 전달하도록 구성될 수 있다. 제1 모드에서, 제2 입력 데이터는 PE Array의 복수의 PE 행 각각의 PE들로 유니캐스트 되도록 구성될 수 있다. PE Array는, 제1 입력 데이터를 특정 클럭만큼 딜레이하여 출력하도록 구성된 딜레이 버퍼를 더 포함하도록 구 성될 수 있다. PE Array는, 인공신경망모델의 커널의 크기에 기초하여 특정 클럭을 결정하도록 구성될 수 있다. *제2 모드에서, 제2 입력 데이터는 브랜치를 가지는 신호 라인을 통해 복수의 PE 열로 브로드캐스트 하도록 구 성될 수 있다. 제2 모드에서, 인공신경망모델의 커널의 크기에 기초하여 PE Array의 복수의 PE 행들 중 일부가 활성화되도록 구성되고, 나머지 PE 행들은 비활성화되도록 구성될 수 있다. PE Array는 복수의 PE 행들 중 적어도 일부에 배치된 제1 멀티플렉서, 복수의 PE 행들 중 적어도 일부의 입력단 에 배치된 제2 멀티플렉서, 및 복수의 PE 행들 중 적어도 일부에 배치된 딜레이 버퍼를 포함하도록 구성될 수 있다. 전술한 바와 같은 과제를 해결하기 위하여 본 개시의 다른 예시에 따른 신경 프로세싱 유닛이 제공된다. 신경 프로세싱 유닛은 제1 모드 또는 제2 모드를 선택하도록 구성된 모드 선택부(mode selector) 및 제1 모드에서 제 1 합성곱 연산을 수행하고, 제2 모드에서 제2 합성곱 연산을 수행하도록 구성된 프로세싱 엘리먼트 어레이 (Processing Element Array)를 포함한다. 프로세싱 엘리먼트 어레이는 제2 합성곱 연산을 위해 사용되는 가중치 데이터를 프로세싱 엘리먼트 어레이 내부 에서 재사용하도록 구성될 수 있다. 제1 합성곱 연산은, 스탠다드(standard) 또는 포인트와이즈 합성곱 연산을 포함할 수 있다. 제2 합성곱 연산은, 뎁스와이즈 합성곱 연산을 포함할 수 있다. 프로세싱 엘리먼트 어레이는 뎁스와이즈 합성곱의 가중치 재사용을 하도록 구성된 딜레이 버퍼를 포함하도록 구 성될 수 있다. 제1 모드에서 제1 합성곱 연산을 위해 사용되는 가중치 데이터가 복수의 PE 열들 각각의 PE들로 파이프라인화여 입력되도록 구성되고, 제1 합성곱 연산을 위해 사용되는 특징맵 데이터가 복수의 PE 행들 각각의 PE들로 유니캐 스트 되도록 구성될 수 있다. 프로세싱 엘리먼트 어레이의 복수의 PE 행들 중 적어도 일부에는 딜레이 버퍼가 배치될 수 있다. 제2 모드에서 제2 합성곱 연산을 위해 사용되는 가중치 데이터가 딜레이 버퍼로 입력되고, 딜레이 버퍼를 통해 딜레이된 가중치 데이터가 출력되도록 구성될 수 있다. 프로세싱 엘리먼트 어레이는 기 설정된 클럭만큼 가중치 데이터를 딜레이 되도록 구성된 딜레이 버퍼를 더 포함 할 수 있다.딜레이 버퍼는 인공신경망모델의 커널의 크기에 기초하여 딜레이 되도록 구성될 수 있다. 전술한 바와 같은 과제를 해결하기 위하여 본 개시의 다른 예시에 따른 신경 프로세싱 유닛이 제공된다. 신경 프로세싱 유닛은 합성곱 연산을 위해 사용되는 가중치 데이터를 로드하도록 구성된 가중치 저장부, 합성곱 연산 을 위해 사용되는 특징맵 데이터를 로드하는 특징맵 저장부, 복수의 PE(Processing Element)를 포함하는 프로세 싱 엘리먼트 어레이(PE Array), 및 프로세싱 엘리먼트 어레이의 동작을 제어하는 컨트롤러를 포함하도록 구성될 수 있다. 프로세싱 엘리먼트 어레이는, 복수의 PE 중 적어도 일부의 PE들에 대응하여 배치된 복수의 딜레이 유 닛을 포함하고, 복수의 딜레이 유닛은 대응되는 스위치 유닛에 의해서 선택적으로 가중치 데이터를 딜레이 하도 록 구성될 수 있다. 전술한 바와 같은 과제를 해결하기 위하여 본 개시의 다른 예시에 따른 프로세싱 엘리먼트 어레이가 제공된다. 프로세싱 엘리먼트 어레이는 가중치 데이터를 입력받도록 구성된 제1 프로세싱 엘리먼트, 가중치 데이터를 입력 받고 특정 클럭으로 딜레이하여 제2 프로세싱 엘리먼트로 전달하도록 구성된 딜레이 유닛, 및 제1 프로세싱 엘 리먼트와 제2 프로세싱 엘리먼트에 특징맵 데이터를 동시에 제공하도록 구성된 브로드캐스트 신호 라인을 포함 하도록 구성될 수 있다. 딜레이 유닛은 가중치 데이터를 재사용하여 뎁스와이즈 합성곱을 처리하도록 구성될 수 있다. 본 명세서와 도면에 게시된 본 개시의 예시들은 본 개시의 기술내용을 쉽게 설명하고 본 개시의 이해를 돕기 위 해 특정 예를 제시한 것뿐이며, 본 명의 범위를 한정하고자 하는 것은 아니다. 여기에 게시된 예시들 이외에도 발명의 기술적 사상에 바탕을 둔 다른 변형 예들이 실시 가능하다는 것은 본 개시가 속하는 기술 분야에서 통상 의 지식을 가진 자에게 자명한 것이다."}
{"patent_id": "10-2023-0071141", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 예시에 따른 신경 프로세싱 유닛이 포함된 장치를 설명하는 개략적인 개념도이다. 도 2는 본 개시에 관련된 컴파일러를 설명하는 개략적인 개념도이다. 도 3은 본 개시에 관련된 합성곱 신경망을 설명하는 개략적인 개념도이다. 도 4는 본 개시의 실시예에 따른 신경 프로세싱 유닛을 설명하는 개략적인 개념도이다. 도 5는 본 개시에 관련된 프로세싱 엘리먼트 어레이 중 하나의 프로세싱 엘리먼트를 설명하는 개략적인 개념도 이다. 도 6은 본 개시의 실시예에 따른 프로세싱 엘리먼트 어레이 중 하나의 프로세싱 엘리먼트를 설명하는 구성도이 다. 도 7은 본 개시의 실시예에 따른 프로세싱 엘리먼트 어레이의 구조를 나타내는 개략적인 구성도이다. 도 8은 본 개시의 실시예에 따른 제1 모드에서 동작하는 프로세싱 엘리먼트 어레이의 구조를 나타내는 개략도이 다. 도 9는 본 개시의 실시예에 따른 제2 모드에서 동작하는 프로세싱 엘리먼트 어레이의 구조를 나타내는 개략도이 다. 도 10은 본 개시의 실시예에 따른 프로세싱 엘리먼트 어레이의 구조를 나타내는 개략적인 구성도이다. 도 11은 본 개시의 실시예에 따른 프로세싱 엘리먼트 어레이의 구조를 나타내는 개략적인 구성도이다. 도 12는 본 개시의 실시예에 따른 프로세싱 엘리먼트 어레이의 구조를 나타내는 개략도이다. 도 13은 본 개시의 실시예에 따른 가중치 데이터 및 특징맵 데이터를 설명하기 위한 예시도이다. 도 14는 본 개시의 실시예에 따른 가중치 데이터 및 특징맵 데이터에 대한 뎁스와이즈 합성곱 연산을 설명하기 위한 예시도이다. 도 15는 본 개시의 실시예에 따른 프로세싱 엘리먼트 어레이의 구조를 나타내는 개략도이다. 도 16은 본 개시의 실시예에 따른 딜레이 버퍼에서 시간에 따라 저장되는 가중치 데이터를 설명하기 위한 예시 도이다. 도 17은 본 개시의 실시예에 따른 가중치 데이터 및 특징맵 데이터에 대한 뎁스와이즈 합성곱 연산을 설명하기위한 예시도이다. 도 18은 본 개시의 실시예에 따른 딜레이 버퍼에서 시간에 따라 저장되는 가중치 데이터를 설명하기 위한 예시 도이다. 도 19는 본 개시의 실시예에 따른 딜레이 버퍼에서 시간에 따라 저장되는 가중치 데이터를 설명하기 위한 예시 도이다. 도 20은 예시적인 인공신경망모델을 설명하기 위한 개념도이다."}
