{"patent_id": "10-2023-0125604", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0042454", "출원번호": "10-2023-0125604", "발명의 명칭": "해석가능한 인공지능을 이용한 감염병 대유행 기간의 우울장애 예측 시스템, 우울장애 예측", "출원인": "인제대학교 산학협력단", "발명자": "변해원"}}
{"patent_id": "10-2023-0125604", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "우울 장애 확률을 예측하기 위한 복수의 설명 변수 및 결과 변수에 대한 데이터를 포함하는 샘플 데이터를 수집하는 샘플 데이터 수집부;분석 대상자의 우울 장애 확률을 예측하기 위한 복수의 학습 모델을 구축하고, 샘플 데이터를 이용하여 복수의학습 모델에 대한 학습을 수행하는 학습 수행부; 구축된 복수의 학습 모델로부터 성능 통계에 기초하여 결과 변수에 영향을 미치는 설명 변수의 서브 세트를 구성하고, 각 서브 세트에 대한 복수의 학습 모델의 성능 통계에 기초하여 어느 하나의 설명 변수의 서브 세트를선택하는 변수 선택부; 수집된 샘플 데이터의 선택된 설명 변수 및 결과 변수에 의해 복수의 학습 모델에 대한 학습을 수행하고, 각학습 모델에 대한 성능 통계에 기초하여 분석 대상자의 우울 장애 확률을 예측하기 위한 하나의 학습 모델을 선택하는 학습 모델 선택부; 및 SHAP(SHapley Additive exPlanations)을 이용하여 우울 장애 예측과 관련한 각 설명 변수의 영향도를 제공하는 영향도 산출부 를 포함하는 해석가능한 인공지능을 이용한 우울 장애 예측 시스템."}
{"patent_id": "10-2023-0125604", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,샘플 데이터에서 결측치를 제거하고, SMOTE-ENN 방법에 의해 샘플 데이터를 재조정하는 샘플 데이터 전처리를수행하는 전처리 수행부를 더 포함하는 해석가능한 인공지능을 이용한 우울 장애 예측 시스템."}
{"patent_id": "10-2023-0125604", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,트리 기반 모델에 대하여 BorutaShap 방법에 의해 학습 모델에 사용할 설명 변수를 선택하고, 딥러닝 기반 모델에 대하여 feature_importances 함수에 의해 학습 모델에 사용할 설명 변수를 선택하는 해석가능한 인공지능을이용한 우울 장애 예측 시스템."}
{"patent_id": "10-2023-0125604", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,복수의 학습 모델은 RF, XGBoost, LGBM, CatBoost 및 TabNet 모델을 포함하는 해석가능한 인공지능을 이용한 우울 장애 예측 시스템."}
{"patent_id": "10-2023-0125604", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,복수의 학습 모델 중 RF, XGBoost, LGBM 및 CatBoost 모델에 대하여 BorutaShap 방법에 의해 학습 모델에 사용할 설명 변수를 선택하고, TabNet 모델에 대하여 feature_importances 함수에 의해 학습 모델에 사용할 설명 변수를 선택하는 해석가능한 인공지능을 이용한 우울 장애 예측 시스템."}
{"patent_id": "10-2023-0125604", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,공개특허 10-2025-0042454-3-선택된 설명 변수는 가구원의 최종 학교, 거주하고 있는 주택 점유 형태, 거주 주택 규모, 난방을 위해 사용하는 에너지, 난방비 부담으로 난방을 하지 못한 경험 여부, 주거복지 관련 사업 인지도, 주거복지 관련 사업 이용 여부, 주거복지 관련 사업 도움 정도, 주거복지 관련 사업 향후 이용 의향, 가구원의 경제활동 참여 상태,가구원의 민간의료보험 가입 건수, 식비 부족 경험, 현재 자녀 수, 희망 자녀 수, 일과 가정의 양립을 위해 가장 필요한 지원, 가구 도움 정도, 최근 1년 간 주민 모임 참여 경험, 향후 사회 단체 활동 참여 의사, 향후 선거 및 투표 참여 의사, 향후 기부 의향, 서울형 기초보장제도 인지 여부, 2019년 대비 문화여가 개선 여부, 조사 전일 행복감, 복지정책 방향 및 실현방안, 서울시의 역점 정책분야, 서울시 우선 지원 대상, 노인 복지시설이용 경험 여부, 영유아 복지시설의 가구 도움 정도, 코로나19 이전과 비교하여 현재 감정상태, 서울시 재난긴급생활비의 인지 여부, 긴급재난지원금의 수급액 만족 정도, 긴급재난지원금의 가구 도움 정도, 서울시 재난긴급생활비의 가구 도움 정도 및 가구주 학력 정보를 포함하는 해석가능한 인공지능을 이용한 우울 장애 예측 시스템."}
{"patent_id": "10-2023-0125604", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "우울 장애 확률을 예측하기 위한 복수의 설명 변수 및 결과 변수에 대한 데이터를 포함하는 샘플 데이터를 수집하는 샘플 데이터 수집 단계;분석 대상자의 우울 장애 확률을 예측하기 위한 복수의 학습 모델을 구축하고, 샘플 데이터를 이용하여 복수의학습 모델에 대한 학습을 수행하는 학습 수행 단계; 구축된 복수의 학습 모델로부터 성능 통계에 기초하여 결과 변수에 영향을 미치는 설명 변수의 서브 세트를 구성하고, 각 서브 세트에 대한 복수의 학습 모델의 성능 통계에 기초하여 어느 하나의 설명 변수의 서브 세트를선택하는 변수 선택 단계; 수집된 샘플 데이터의 선택된 설명 변수 및 결과 변수에 의해 복수의 학습 모델에 대한 학습을 수행하고, 각학습 모델에 대한 성능 통계에 기초하여 분석 대상자의 우울 장애 확률을 예측하기 위한 하나의 학습 모델을 선택하는 학습 모델 선택 단계; 및 SHAP(SHapley Additive exPlanations)을 이용하여 우울 장애 예측과 관련한 각 설명 변수의 영향도를 제공하는 영향도 산출 단계 를 포함하는 해석가능한 인공지능을 이용한 우울장애 예측 방법."}
{"patent_id": "10-2023-0125604", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 기재된 해석가능한 인공지능을 이용한 우울 장애 예측 방법을 컴퓨터에 의해 수행시키기 위해 기록 매체에 저장된 프로그램."}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 의하면, 해석가능한 인공지능을 이용한 우울 장애 예측 시스템이 제공될 수 있다. 우울 장애 예측 시스템은, 우울 장애 확률을 예측하기 위한 복수의 설명 변수 및 결과 변수에 대한 데이터를 포함하는 샘플 데이터를 수집하는 샘플 데이터 수집부; 분석 대상자의 우울 장애 확률을 예측하기 위한 복수의 학습 모델 (뒷면에 계속)"}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 우울 장애를 예측하는 기술에 관한 것으로, 보다 상세하게는 해석가능한 인공지능을 이용한 감염병 대유행 기간의 우울 장애 예측 시스템, 우울 장애 예측 방법 및 기록 매체에 저장된 프로그램에 관한 것이다."}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "우울증은 전 세계 인구에 영향을 미치며 글로벌 보건 의제를 지속적으로 괴롭히는 중요한 글로벌 이슈로 부상했 다. 세계보건기구(WHO)는 전 세계 인구의 약 4.4%에 해당하는 3억 5천만 명 이상이 우울증을 앓고 있는 것으로 추산한다. 2030년에는 우울증이 전 세계 주요 건강 문제가 될 것으로 예상한다. 코로나19의 확산으로 사람들이 실내에 머무르고 사회적 상호 작용을 제한하게 되면서 우울증 상황이 더욱 악화되어 문제가 더욱 심각해졌다. 팬데믹 기간 동안 전체 인구의 우울증 유병률은 33%로 추정된다. 코로나19는 신체 건강에 영향을 미칠 뿐만 아 니라 여러 정신 질환을 유발한다. 그러나 이러한 정신 질환은 조기에 발견하고 적절한 치료를 받으면 그 영향을 완화할 수 있다. 따라서 정신 건강을 모니터링할 수 있는 효과적인 방법과 도구의 개발이 시급하다."}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 종래 기술의 문제점을 해결하기 위하여 도출된 것으로서, 본 발명이 해결하기 위한 과제 는, 코로나19 팬데믹 기간 동안의 한국인의 우울 장애를 높은 정확도로 예측하면서도, 의료인이 예측 결과를 이 해할 수 있는 해석가능한 인공지능을 이용한 우울 장애 예측 시스템, 우울 장애 예측 방법 및 프로그램을 제공 하는 것이다."}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 수단으로서, 본 발명의 실시예에 따른 해석가능한 인공지능을 이용한 우울 장애 예측 시스템은, 우울 장애 확률을 예측하기 위한 복수의 설명 변수 및 결과 변수에 대한 데이터를 포함하는 샘 플 데이터를 수집하는 샘플 데이터 수집부; 분석 대상자의 우울 장애 확률을 예측하기 위한 복수의 학습 모델을 구축하고, 샘플 데이터를 이용하여 복수의 학습 모델에 대한 학습을 수행하는 학습 수행부; 구축된 복수의 학 습 모델로부터 성능 통계에 기초하여 결과 변수에 영향을 미치는 설명 변수의 서브 세트를 구성하고, 각 서브 세트에 대한 복수의 학습 모델의 성능 통계에 기초하여 어느 하나의 설명 변수의 서브 세트를 선택하는 변수 선 택부; 수집된 샘플 데이터의 선택된 설명 변수 및 결과 변수에 의해 복수의 학습 모델에 대한 학습을 수행하 고, 각 학습 모델에 대한 성능 통계에 기초하여 분석 대상자의 우울 장애 확률을 예측하기 위한 하나의 학습 모 델을 선택하는 학습 모델 선택부; SHAP(SHapley Additive exPlanations)을 이용하여 우울 장애 예측과 관련한 각 설명 변수의 영향도를 제공하는 영향도 산출부 를 포함할 수 있다. 해석가능한 인공지능을 이용한 우울 장애 예측 시스템은 샘플 데이터에서 결측치를 제거하고, SMOTE-ENN 방법에 의해 샘플 데이터를 재조정하는 샘플 데이터 전처리를 수행하는 전처리 수행부를 더 포함할 수 있다. 트리 기반 모델에 대하여 BorutaShap 방법에 의해 학습 모델에 사용할 설명 변수가 선택되고, 딥러닝 기반 모델 에 대하여 feature_importances 함수에 의해 학습 모델에 사용할 설명 변수가 선택될 수 있다. 복수의 학습 모델은 RF, XGBoost, LGBM, CatBoost 및 TabNet 모델을 포함할 수 있다. 복수의 학습 모델 중 RF, XGBoost, LGBM 및 CatBoost 모델에 대하여 BorutaShap 방법에 의해 학습 모델에 사용 할 설명 변수를 선택하고, TabNet 모델에 대하여 feature_importances 함수에 의해 학습 모델에 사용할 설명 변 수를 선택할 수 있다. 선택된 설명 변수는 가구원의 최종 학교, 거주하고 있는 주택 점유 형태, 거주 주택 규모, 난방을 위해 사용하 는 에너지, 난방비 부담으로 난방을 하지 못한 경험 여부, 주거복지 관련 사업 인지도, 주거복지 관련 사업 이 용 여부, 주거복지 관련 사업 도움 정도, 주거복지 관련 사업 향후 이용 의향, 가구원의 경제활동 참여 상태, 가구원의 민간의료보험 가입 건수, 식비 부족 경험, 현재 자녀 수, 희망 자녀 수, 일과 가정의 양립을 위해 가 장 필요한 지원, 가구 도움 정도, 최근 1년 간 주민 모임 참여 경험, 향후 사회 단체 활동 참여 의사, 향후 선 거 및 투표 참여 의사, 향후 기부 의향, 서울형 기초보장제도 인지 여부, 2019년 대비 문화여가 개선 여부, 조 사 전일 행복감, 복지정책 방향 및 실현방안, 서울시의 역점 정책분야, 서울시 우선 지원 대상, 노인 복지시설 이용 경험 여부, 영유아 복지시설의 가구 도움 정도, 코로나19 이전과 비교하여 현재 감정상태, 서울시 재난긴 급생활비의 인지 여부, 긴급재난지원금의 수급액 만족 정도, 긴급재난지원금의 가구 도움 정도, 서울시 재난긴 급생활비의 가구 도움 정도 및 가구주 학력 정보를 포함할 수 있다. 상술한 과제를 해결하기 위한 다른 수단으로서, 본 발명의 실시예에 따른 해석가능한 인공지능을 이용한 우울장 애 예측 방법은 우울 장애 확률을 예측하기 위한 복수의 설명 변수 및 결과 변수에 대한 데이터를 포함하는 샘 플 데이터를 수집하는 샘플 데이터 수집 단계; 분석 대상자의 우울 장애 확률을 예측하기 위한 복수의 학습 모 델을 구축하고, 샘플 데이터를 이용하여 복수의 학습 모델에 대한 학습을 수행하는 학습 수행 단계; 구축된 복 수의 학습 모델로부터 성능 통계에 기초하여 결과 변수에 영향을 미치는 설명 변수의 서브 세트를 구성하고, 각 서브 세트에 대한 복수의 학습 모델의 성능 통계에 기초하여 어느 하나의 설명 변수의 서브 세트를 선택하는 변 수 선택 단계; 수집된 샘플 데이터의 선택된 설명 변수 및 결과 변수에 의해 복수의 학습 모델에 대한 학습을 수행하고, 각 학습 모델에 대한 성능 통계에 기초하여 분석 대상자의 우울 장애 확률을 예측하기 위한 하나의 학습 모델을 선택하는 학습 모델 선택 단계; SHAP(SHapley Additive exPlanations)을 이용하여 우울 장애 예측 과 관련한 각 설명 변수의 영향도를 제공하는 영향도 산출 단계를 포함할 수 있다. 상술한 과제를 해결하기 위한 다른 수단으로서, 본 발명의 실시예에 따른 프로그램은 상기 해석가능한 인공지능 을 이용한 우울 장애 예측 방법을 컴퓨터에 의해 수행시키기 위해 기록 매체에 저장된 프로그램을 포함할 수 있다."}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 우울 장애 확률을 예측하기 위한 복수의 설명 변수 및 결과 변수에 대한 데이터 를 포함하는 샘플 데이터를 수집하고, 분석 대상자의 우울 장애 확률을 예측하기 위한 복수의 학습 모델을 구축 하고, 샘플 데이터를 이용하여 복수의 학습 모델에 대한 학습을 수행하며, 구축된 복수의 학습 모델로부터 성능 통계에 기초하여 결과 변수에 영향을 미치는 설명 변수의 서브 세트를 구성하고, 각 서브 세트에 대한 복수의 학습 모델의 성능 통계에 기초하여 어느 하나의 설명 변수의 서브 세트를 선택하고, 수집된 샘플 데이터의 선택 된 설명 변수 및 결과 변수에 의해 복수의 학습 모델에 대한 학습을 수행하고, 각 학습 모델에 대한 성능 통계 에 기초하여 분석 대상자의 우울 장애 확률을 예측하기 위한 하나의 학습 모델을 선택하며, SHAP(SHapley Additive exPlanations)을 이용하여 우울 장애 예측과 관련한 각 설명 변수의 영향도를 제공함으로써, 코로나19 팬데믹 기간 동안의 한국인의 우울 장애를 높은 정확도로 예측하면서도, 의료인이 예측 결과를 이해할 수 있는 해석가능한 인공지능을 이용한 우울 장애 예측 시스템, 우울 장애 예측 방법 및 프로그램이 제공될 수 있다."}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예를 상세히 설명하기로 한다. 본 발명의 실시예들은 당해 기술 분야에서 통상의 지식을 가진 자에게 본 발명을 더욱 완전하게 설명하기 위하 여 제공되는 것이며, 하기 실시예는 여러 가지 다른 형태로 변형될 수 있으며, 본 발명의 범위가 하기 실시예에 한정되는 것은 아니다. 오히려, 이들 실시예는 본 개시를 더욱 충실하고 완전하게 하고, 당업자에게 본 발명의 사상을 완전하게 전달하기 위하여 제공되는 것이다. 여기에 설명되는 다양한 실시예는 예를 들어, 소프트웨어, 하드웨어 또는 이들의 조합된 것을 이용하여 컴퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 여기에 설명되는 실시예는 ASICs (application specific integrated circuits), DSPs (digital signal processors), DSPDs (digital signal processing devices), PLDs (programmable logic devices), FPGAs (field programmable gate arrays, 프로세서(processors), 제어기(controllers), 마이크로 컨 트롤러(micro-controllers), 마이크로 프로세서(microprocessors), 기능 수행을 위한 전기적인 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 소프트웨어적인 구현에 의하면, 절차나 기능과 같은 실시예들은 적어도 하나의 기능 또는 작동을 수행하게 하는 별개의 소프트웨어 모듈과 함께 구현될 수 있다. 소프트웨어 코드는 적절한 프로그램 언어로 쓰여진 소프트웨어어플리케이션에 의해 구현될 수 있다. 도 1은 본 발명의 일 실시예에 따른 우울 장애 예측 시스템의 구성을 도시하는 블록도이다. 도 1을 참조하면, 우울 장애 예측 시스템은 샘플 데이터 수집부, 전처리 수행부, 학습 수행부 , 변수 선택부, 학습 모델 선택부 및 영향도 산출부를 포함할 수 있다. 우울 장애 예측 시 스템은 정보 처리 단말기에 탑재된 프로세서 및 메모리에 의해 구현될 수 있다. 또한, 우울 장애 예측 시스 템는 정보 처리 단말기와 네트워크를 통하여 연결된 처리 서버에 의해 구현될 수 있다. 우울 장애 예측 시스템의 구성 요소들을 이하에서 상세히 설명하며, 이러한 구성 요소들은 정보 처리 단말 기에 모듈 형태로 구현되거나, 또는 서버 및 클라이언트에 의해 제공되는 서비스 형태로 구현될 수 있다. 샘플 데이터 수집부는 분석 대상자의 우울장애를 예측하기 위한 복수의 설명 변수 및 결과 변수에 대한 데 이터를 포함하는 샘플 데이터를 수집할 수 있다. 복수의 설명 변수 및 결과 변수에 대한 샘플 데이터는 지방자 체단체 거주 주민에 대한 설문 데이터로부터 취득될 수 있다. 결과 변수인 우울 장애 여부는 우울증 평가를 위 해 사용되는 자가보고 척도인 CESD-R-10 문항에 대한 답변 데이터로부터 결정될 수 있다. 전처리 수행부는 샘플 데이터에서 결측치를 제거하고, SMOTE-ENN 방법에 의해 샘플 데이터를 재조정할 수 있다. 설문 데이터는 선택형 문항을 포함할 수 있고, 선택형 문항에 대한 결측치에 대하여 전처리를 수행할 수 있다. 샘플 데이터에 대하여 과적합을 방지하기 위하여 SMOTE-ENN(Synthetic Minority Oversampling Technique- Edited Nearest Neighbours) 기법을 이용하여 샘플 데이터의 균형화 전처리가 수행될 수 있다. 데이터 클래스의 비율이 너무 차이가 나면 우세한 클래스를 택하는 모델의 정확도가 높아지므로 모델의 성능 판별이 어려워진다. 이러한 경우, 정확도(accuracy)가 높아도 데이터 개수가 적은 클래스의 재현율(recall-rate)이 급격히 작아지는 현상이 발생할 수 있다. 이와 같은 비대칭 데이터 문제를 해결하기 위하여, 오버샘플링과 언더샘플링을 결합한 앙상블 방법이 사용될 수 있다. SMOTE는 소수 클래스에 속하는 데이터를 부트스트래핑 또는 KNN 방법을 이용하여 합성하여 데이터 수를 증폭시키며, ENN(Edited Nearest Neighbours)방법은 KNN을 사용해 다수 클래스 데이터를 축소시키고, 이웃한 데 이터 중 자신과 같은 클래스보다 다른 클래스의 데이터가 많을 경우 해당 데이터는 제외하는 방법이며, SMOTE- ENN 방식은 SMOTE 방식과 ENN 방식을 결합한 앙상블 방법이다. 학습 수행부는 분석 대상자의 우울 장애 확률을 예측하기 위한 복수의 학습 모델을 구축하고, 샘플 데이터 를 이용하여 복수의 학습 모델에 대한 학습을 수행할 수 있다. 복수의 학습 모델은 RF, XGBoost, LGBM, CatBoost 및 TabNet 모델을 포함할 수 있다. 변수 선택부는 구축된 복수의 학습 모델로부터 성능 통계에 기초하여 결과 변수에 영향을 미치는 설명 변 수의 서브 세트를 구성하고, 각 서브 세트에 대한 복수의 학습 모델의 성능 통계에 기초하여 어느 하나의 설명 변수의 서브 세트를 선택할 수 있다. 일 실시예에서, 트리 기반 모델에 대하여 BorutaShap 방법에 의해 학습 모델에 사용할 설명 변수를 선택하고, 딥러닝 기반 모델에 대하여 feature_importances 함수에 의해 학습 모델에 사용할 설명 변수를 선택할 수 있다. 또한, 복수의 학습 모델 중 RF, XGBoost, LGBM 및 CatBoost 모델에 대하여 BorutaShap 방법에 의해 학습 모델 에 사용할 설명 변수를 선택하고, TabNet 모델에 대하여 feature_importances 함수에 의해 학습 모델에 사용할 설명 변수를 선택할 수 있다. 학습 모델에 사용할 설명 변수의 선택은 복수의 설명 변수 세트에 대한 학습 모델의 성능 통계에 기초하여 보팅 방법에 의해 결정될 수 있다. 보팅 방법은, 학습 모델별로 변수 중요도에 따라 학습 모델에 사용할 설명 변수 세트를 결정하는 단계와, 결정된 학습 모델별 설명 변수 서브 세트, 학습 모델별 설명 변수 서브 세트 중 1개의 학습 모델별 설명 변수 서브 세트에 포함되는 설명 변수로 구성되는 제1 보팅 세트, 2개의 학습 모델별 설명 변 수 서브 세트에 포함되는 설명 변수로 구성되는 제2 보팅 세트, 3개의 학습 모델별 설명 변수 서브 세트에 포함 되는 설명 변수로 구성되는 제3 보팅 세트, 4개의 학습 모델별 설명 변수 서브 세트에 포함되는 설명 변수로 구 성되는 제4 보팅 세트, 5개의 학습 모델별 설명 변수 서브 세트에 포함되는 설명 변수로 구성되는 제5 보팅 세 트를 구성하는 단계와, 구성된 복수의 설명 변수 세트에 대한 학습 모델의 성능 통계에 기초하여 하나의 설명 변수의 서브 세트를 선택하는 단계를 포함하는 단계들에 의해 수행될 수 있다. 일 실시예에서, 선택된 설명 변수는 가구원의 최종 학교, 거주하고 있는 주택 점유 형태, 거주 주택 규모, 난방 을 위해 사용하는 에너지, 난방비 부담으로 난방을 하지 못한 경험 여부, 주거복지 관련 사업 인지도, 주거복지 관련 사업 이용 여부, 주거복지 관련 사업 도움 정도, 주거복지 관련 사업 향후 이용 의향, 가구원의 경제활동 참여 상태, 가구원의 민간의료보험 가입 건수, 식비 부족 경험, 현재 자녀 수, 희망 자녀 수, 일과 가정의 양립 을 위해 가장 필요한 지원, 가구 도움 정도, 최근 1년 간 주민 모임 참여 경험, 향후 사회 단체 활동 참여 의사, 향후 선거 및 투표 참여 의사, 향후 기부 의향, 서울형 기초보장제도 인지 여부, 2019년 대비 문화여가 개선 여부, 조사 전일 행복감, 복지정책 방향 및 실현방안, 서울시의 역점 정책분야, 서울시 우선 지원 대상, 노인 복지시설 이용 경험 여부, 영유아 복지시설의 가구 도움 정도, 코로나19 이전과 비교하여 현재 감정상태, 서울시 재난긴급생활비의 인지 여부, 긴급재난지원금의 수급액 만족 정도, 긴급재난지원금의 가구 도움 정도, 서울시 재난긴급생활비의 가구 도움 정도 및 가구주 학력 정보를 포함할 수 있다. 학습 모델 선택부는 수집된 샘플 데이터의 선택된 설명 변수 및 결과 변수에 의해 복수의 학습 모델에 대 한 학습을 수행하고, 각 학습 모델에 대한 성능 통계에 기초하여 분석 대상자의 우울 장애 확률을 예측하기 위 한 하나의 학습 모델을 선택할 수 있다. 분석 대상자의 우울 장애를 예측하기 위하여 구축된 복수의 학습 모델 은 RF, XGBoost, LGBM, CatBoost 및 TabNet 모델을 포함할 수 있고, 선택된 하나의 학습 모델은 TabNet 모델을 포함할 수 있다. 복수의 학습 모델 중에서 예측 성능 통계를 기초로 더 높은 성능 통계를 갖는 하나의 모델이 선택될 수 있다. 예측 성능 통계는 Accuracy, Precision, Recall, F1-score 및 AUC 중 하나 이상을 포함할 수 있다. 영향도 산출부는 SHAP(SHapley Additive exPlanations)을 이용하여 우울 장애 예측과 관련한 각 설명 변 수의 영향도를 제공할 수 있다. SHAP은 협동 게임 이론의 원리를 사용하여 특정 예측을 위해 각 입력 기능에 중요도 점수를 할당한다. 게임 이 론에서 규칙은 플레이어의 상호 작용 방식을 규제하며, 각 플레이어는 전략을 가지고 보상을 받는다. 게임에 대 한 개별 참가자의 기여도는 샤플리 값을 사용하여 결정된다. 모델 설명의 맥락에서 전략은 절차의 결과에, 참가자는 기능에, 보상은 획득한 결과의 품질에 해당한다. 샤플리 값은 전체 예측에 대한 특정 특성의 기여도를 식별하는 데 도움이 된다. 샘플링 절차를 반복하여 한계 기여도 근사치를 향상시킬 수 있다. 궁극적으로 SHAP 값은 가능한 모든 특징 연합에 대한 한계 기여도의 가중 평균으로 정의될 수 있다. 도 2는 본 발명의 일 실시예에 따른 우울 장애 예측 시스템을 컴퓨터에서 구현하는 경우의 구성을 나타내는 도면이다. 우울 장애 예측 시스템 이 구현되는 컴퓨터 장치는 PC, 노트북, 스마트기기 또는 서버 등과 같은 정보 처리 장치를 의미한다. 컴퓨터 장치는 입력장치, 연산장치, 저장장치 및 출력장치를 포함할 수 있다. 입력 장치는 복수의 샘플 데이터와 예측 대상자의 설명 변수에 대한 측정값을 입력 받을 수 있다. 입력 장 치는 데이터 파일 형태로 샘플 데이터를 입력 받거나, 키보드, 마우스 등의 입력 디바이스에 의해 샘플 데 이터를 입력 받을 수 있다. 입력 받은 샘플 데이터와 예측 대상자의 설명 변수에 대한 측정값은 저장 장치(23 0)에 저장될 수 있다. 또한, 입력 장치는 마이크 등의 디바이스를 이용하여 사용자의 음성을 입력 받고, 해당 음성으로부터 변환 된 텍스트를 입력 데이터로 사용할 수 있다. 음성 입력 방식에 의하면, 응급실 등의 긴급한 환경에서 의료 관계 자가 응급 환자의 입력 데이터를 타이핑에 의하지 않고 음성 입력으로부터 변환된 텍스트 데이터가 학습 모델에 사용될 수 있다. 저장 장치은 입력 받은 샘플 데이터와 예측 대상자의 설명 변수에 대한 측정값을 저장할 수 있다. 또한, 저장 장치는 구축된 학습 모델, 예측 모델 및 SHAP 모델을 저장할 수 있다. 연산 장치는 샘플 데이터를 학습하여 우울 장애 확률을 예측하기 위한 학습 모델, 예측 모델 및 SHAP 모델 을 구축할 수 있다. 또한, 연산 장치는 구축된 학습 모델로부터 분석 대상자의 우울 장애 확률 예측값 및 설명 변수별 영향도를 산출할 수 있다. 출력 장치은 우울 장애 확률 예측값 및 설명 변수별 영향도를 일정한 형태로 출력하는 장치이다. 출력장치 는 디스플레이 장치, 문서를 출력하는 출력 장치 및 우울 장애 확률 예측값 및 설명 변수별 영향도를 다른장치에 전달하는 통신 장치 중 적어도 하나를 포함할 수 있다. 도 3은 본 발명의 일 실시예에 따른 우울 장애 예측 시스템을 서버와 클라이언트 단말기에 의해 구현하는 경우의 구성을 나타내는 도면이다. 우울 장애 예측 시스템은 클라이언트 단말, 검사 DB, 처리 서버 및 모델 DB를 포함한 다. 클라이언트 단말은 공공 기관, 의료 기관 또는 환자의 집 등의 장소에 설치될 수 있다. 클라이언트 단말 은 샘플 데이터 또는 예측 대상자의 설명 변수에 대한 측정값을 입력 받을 수 있다. 입력된 샘플 데이터 또는 예측 대상자의 설명 변수에 대한 측정값은 검사 DB에 저장될 수 있다. 검사 DB는 입력 받은 샘플 데이터와 예측 대상자의 설명 변수에 대한 측정값을 저장하는 데이터베이스를 포함할 수 있다. 처리 서버는 샘플 데이터를 학습하여 우울 장애 확률 예측값 및 설명 변수별 영향도를 산출하기 위한 학습 모델을 구축할 수 있다. 또한, 처리 서버는 구축된 학습 모델로부터 예측 대상자의 우울 장애 확률 예측값 및 설명 변수별 영향도를 산출할 수 있다. 모델 DB는 구축된 예측 모델 및 LIME 학습 모델에 관련된 데이터를 포함할 수 있다. 처리 서버는 구 축된 예측 모델 및 LIME 학습 모델을 모델 DB에 저장할 수 있다. 도 3에는 검사 DB, 처리 서버 및 모델 DB를 별개의 구성 요소로 도시하였지만, 검사 DB, 처리 서버 및 모델 DB는 하나의 일체화된 구성 요소로 구성될 수 있다. 도 4는 본 발명의 일 실시예에 따른 우울 장애 예측 시스템에 의해 구현되는 우울 장애 예측 방법의 흐름도 이다. 도 4를 참조하면, 우울 장애 예측 방법은 샘플 데이터 수집 단계(S110), 전처리 수행 단계(S120), 학습 수행 단 계(S130), 변수 선택 단계(S140), 학습 모델 선택 단계(S150) 및 영향도 산출 단계(S160)를 포함할 수 있다. 샘플 데이터 수집 단계(S110)에서, 샘플 데이터 수집부가 우울 장애 확률을 예측하기 위한 복수의 설명 변 수 및 결과 변수에 대한 데이터를 포함하는 샘플 데이터를 수집할 수 있다. 전처리 수행 단계(S120)에서, 전처리 수행부가 샘플 데이터에서 결측치를 제거하고, SMOTE-ENN 방법에 의 해 샘플 데이터를 재조정하는 샘플 데이터 전처리를 수행할 수 있다. 학습 수행 단계(S130)에서, 학습 수행부가 분석 대상자의 우울 장애 확률을 예측하기 위한 복수의 학습 모 델을 구축하고, 샘플 데이터를 이용하여 복수의 학습 모델에 대한 학습을 수행할 수 있다. 변수 선택 단계(S140)에서, 변수 선택부가 구축된 복수의 학습 모델로부터 성능 통계에 기초하여 결과 변 수에 영향을 미치는 설명 변수의 서브 세트를 구성하고, 각 서브 세트에 대한 복수의 학습 모델의 성능 통계에 기초하여 어느 하나의 설명 변수의 서브 세트를 선택할 수 있다. 학습 모델 선택 단계(S150)에서, 학습 모델 선택부가 수집된 샘플 데이터의 선택된 설명 변수 및 결과 변 수에 의해 복수의 학습 모델에 대한 학습을 수행하고, 각 학습 모델에 대한 성능 통계에 기초하여 분석 대상자 의 우울 장애 확률을 예측하기 위한 하나의 학습 모델을 선택할 수 있다. 영향도 산출 단계(S160)에서, 영향도 산출부가 SHAP(SHapley Additive exPlanations)을 이용하여 우울 장 애 예측과 관련한 각 설명 변수의 영향도를 제공할 수 있다. 샘플 데이터 수집 단계(S110), 전처리 수행 단계(S120), 학습 수행 단계(S130), 변수 선택 단계(S140), 학습 모 델 선택 단계(S150) 및 영향도 산출 단계(S160)에 대하여, 샘플 데이터 수집부, 전처리 수행부, 학습 수행부, 변수 선택부, 학습 모델 선택부 및 영향도 산출부의 상술한 설명이 참조될 수 있 다. 이하에서는 해석가능한 인공지능을 이용한 우울 장애 예측 모델의 개발 및 검증 과정의 설명을 통하여 본 발명 에 따른 해석가능한 인공지능을 이용한 우울 장애 예측 시스템 및 예측 방법의 특징에 대하여 설명한다. [자료원 및 전처리] 서울연구원은 서울시민의 복지 현황과 욕구에 대한 자료를 수집하기 위해 서울복지실태조사를 실시한다. 조사의 목적은 서울시의 특성을 대표하고 시 차원의 복지정책을 설계하고 모니터링하기 위한 전제를 제공하기 위한 것 이다. 조사 당시 표본 규모는 서울에 거주하는 3,000가구로 구성되었다. 표본 추출 방식은 통계청의 2018년 인 구주택총조사 표본 추출 층을 활용한 다단계 층화 비례 배분 방식을 사용했다. 이를 위해 다단계 층화 비례 분 포 방식으로 300개의 표본 구를 선정하고, 층화 표본 추출을 통해 각 구당 10가구를 선정했다. 95% 신뢰수준에 서 오차범위를 1.8% 이내로 관리하기 위해 3,000가구를 표본으로 선정했다. 조사는 구조화된 설문지를 이용한 가구 대면 면접 방식으로 진행되었다. 설문조사 방법으로는 컴퓨터 지원 개인 면접(CAPI)이 사용되었지만, 코로 나19 팬데믹 기간 동안 봉쇄와 같은 잠재적인 방역 문제를 해결하기 위해 종이 설문지 또한 사용되었다. 2020년 조사에서는 완료된 가구의 약 68.7%가 CAPI를 사용하여 인터뷰를 진행했으며, 31.3%는 종이 설문지를 사용하여 인터뷰를 진행했다. 총 3,027건의 설문조사가 완료되어 설문 조사 결과가 샘플 데이터에 포함되었다. [데이터 전처리] 데이터는 결측치 처리, 대상 변수 재분류, 데이터 불균형 해결을 위한 전처리 과정을 거쳤다. 서울복지실태조사 는 선택형 문항을 포함하고 있기 때문에 데이터셋에는 전처리가 필요한 결측값이 포함되어 있었다. 설문조사에 는 우울증을 직접적으로 식별하는 문항은 없었지만, 우울증 평가를 위해 널리 사용되는 자가보고 척도인 CESD- R-10 문항이 포함되어 있었다. CESD-R-10에 대한 응답을 바탕으로 '우울증'이라는 목표 변수를 구성했다. 목표 변수를 결정한 후, 최종 전처리 단계에서는 데이터 세트 내의 불균형 문제를 해결하는 것으로 구성되었다. 처음에 데이터 세트는 3,027개의 샘플과 659개의 피처(feature)로 구성되었다. 누락된 값을 처리하기 위해 데이 터 세트에서 50% 이상의 널 값을 가진 열을 제거했다. 그 결과, 결측값을 다시 제거한 후 데이터 세트는 3,027 개의 샘플과 228개의 변수로 축소되었다. CESD-R-10(미국 역학 연구 센터 우울증 척도 개정 10 항목)은 일반 인구의 우울 증상을 평가하는 데 사용되는 자가 보고 척도이다. 이 척도는 지난 일주일 동안 특정 감정을 느꼈거나 특정 행동을 경험한 일수를 4점 리커트 척도로 평가하도록 응답자에게 요청하는 10개의 항목으로 구성되어 있다. 응답 옵션은 0점(거의 또는 전혀 없음)에서 3점(항상 있음)까지 다양하다. 10개 항목의 점수를 합산하여 우울한 신체 증상을 평가하며, 10점 이 상이면 임상적 우울증을 나타낸다. CESD-R-10은 강력한 내적 일관성(크론바흐 α = 0.86)과 높은 검사-재검사 신뢰도(ICC = 0.85)를 입증했다. 서울복지실태조사에는 CESD-R-10 외에도 동일한 4점 리커트 척도를 활용하여 일주일 동안 식욕이 없고 먹기 싫 은 경험에 대한 유사한 문항이 포함되어 있다. 총 11개 항목에 대한 응답을 합산하여 총점을 산출하였으며, CESD-R-10 10개 항목과 추가 문항을 포함하였다. 총점을 기준으로 목표 특징을 생성했으며, 10점 이상을 받은 개인은 우울한 것으로 간주하고(1로 표시), 10점 미만을 받은 개인은 우울하지 않은 것으로 분류했다(0으로 표 시). 대상 기능을 생성한 후, 데이터 세트에서 11개 항목의 열을 제거했다. 그 결과, 데이터 세트는 3,027개의 샘플, 216개의 변수, \"우울증\"으로 명명된 1개의 목표 특징 열로 구성되었다. 목표 특징은 비우울(레이블 0) 샘플과 우울(레이블 1) 샘플의 분포가 2589:438의 비율로 불균형한 것으로 나타 났다. 이 불균형을 해결하기 위해 데이터 세트의 균형을 재조정하기 위해 SMOTE-ENN 기법을 채택했다. SMOTE- ENN 기법은 두 가지 알고리즘을 결합한다: 즉, 합성 소수 과대 샘플링 기법(SMOTE)과 편집된 최인접 이웃(ENN) 을 결합한 것이다. SMOTE는 소수 클래스에 대한 합성 인스턴스(우울 레이블)를 생성하여 대표성을 높이는 반면, ENN은 가장 가까운 이웃에 의해 잘못 분류된 두 클래스의 관측치를 제거한다. SMOTE-ENN 방법을 사용하기 전에 데이터 세트는 훈련 세트와 테스트 세트로 80:20의 비율로 나뉘었다. 훈련 세 트에는 2,421개의 샘플이, 테스트 세트에는 606개의 샘플이 있었다. 테스트 세트의 대표성을 유지하면서 재조정 된 데이터에서 모델이 학습할 수 있도록 훈련 세트에만 SMOTE-ENN 접근법을 적용했다. SMOTE-ENN 방법을 적용한 후 재조정된 훈련 세트는 3,354개의 샘플로 구성되었으며, 비우울(레이블 0) 1,328개와 우울(레이블 1) 2,026개 의 비율로 구성되었다. [특징 선택] 전처리 단계를 거친 데이터 세트는 228개의 변수로 구성되었다. 이 모든 변수가 분류에 반드시 유의미한 것은 아니다. 수많은 변수를 포함하면 계산 시간과 리소스 사용량이 증가하고, 복잡성이 증가하며, 가치 있는 정보를 거의 또는 전혀 추가하지 않아 잠재적으로 성능이 저하될 수도 있다. 따라서 최적의 결과를 얻으려면 특징 (feature)의 수를 줄이는 것이 중요하다다. 본 발명자는 TabNet을 포함한 5개의 모델과 비교를 위해 RF, XGBoost, LGBM, CatBoost 등 4개의 기존 머신러닝 모델을 훈련하였다. TabNet 뿐만 아니라 비교 모델의 성능을 향상시키는 중요한 특징을 식별하는 것이목표였다. 도 5는 본 발명의 일 실시예로서 사용된 특징 선택 방법인 보팅 방법을 나타낸다. 모든 모델은 특징 선택 과정에서 기본 하이퍼파라미터를 활용했다 RF, XGBoost, LGBM, CatBoost는 트리 기반 모델이기 때문에 중요한 특징 선택을 위해 BorutaShap 방법을 사용 하기로 결정했다. BorutaShap은 Boruta 특징 선택 알고리즘을 SHAP과 병합하는 효율적인 Python 기반 래퍼 방법 이다. BorutaShap 방법은 트리 기반 학습자를 기본 모델로만 호환하고 지원한다. TabNet의 딥러닝 아키텍처 특성상 TabNet 분류기의 특징 선택은 별도로 수행했다. 모든 특징의 중요도 점수를 계산하기 위해 TabNet에 내장된 'feature_importances_' 함수를 활용했다. 그 결과 중요도 점수가 0.01 이상인 특징만 선별했다. 각 모델에서 유의미한 특징 집합을 획득한 후, 가장 영향력 있는 특징을 종합적으로 식별하기 위해 보팅 (voting) 방식을 사용했다. 모델은 특정 피처가 모델의 중요 피처 목록에 포함될 경우 해당 피처에 투표 (voting)를 했다. 따라서 각 피처는 다양한 모델에서 그 중요성을 나타내는 투표를 모았으며, 피처에 대한 투표 수는 1(한 모델에서 선택됨을 나타냄)에서 5(5개의 모델 모두에서 선택됨을 나타냄)까지 다양했다. 보팅 메커니즘을 통해 'voting_1'에서 'voting_5'로 표시된 5개의 피처 하위 집합을 도출했다. 'voting_1' 하위 집합은 최소 한 표 이상을 받은 모든 특징으로 구성되었으며, 그 이후의 각 하위 집합('voting_2' ~ 'voting_5')에는 각각 최소 2, 3, 4, 5표를 받은 특징이 포함되어 있습니다. 이러한 특징 하위 집합이 모델 성 능에 미치는 영향을 평가하기 위해 5개의 모델 각각을 'voting_1'부터 'voting_5'까지 각 하위 집합에 대해 순 차적으로 학습시켰다. 이후 최적의 성능을 도출한 특징 하위 집합을 모델 훈련 및 최적화에 사용했다. [TabNet] TabNet은 표 형식의 데이터를 위해 특별히 설계된 딥러닝을 위한 혁신적인 아키텍처로, 높은 성능과 해석 가능 성을 모두 제공한다. TabNet의 AR 아키텍처는 일련의 단계로 구성되며, 각 단계는 D차원 특징 벡터를 처리한다. 각 단계에서 입력은 특징 변환기 블록을 통과한다. 이 블록은 여러 레이어로 구성되며, 모든 의사 결정 단계에 서 공유하거나 단일 단계에 특화될 수 있다. 블록 내에는 완전히 연결된 레이어, 배치 정규화 레이어, GLU(게이 트 선형 유닛) 활성화 기능이 있다. 또한 GLU는 잔여 정규화 연결에 연결되어 네트워크 편차를 줄이는 역할을 한다. 다층 블록은 기능 선택을 용이하게 하고 네트워크의 파라미터 효율성을 향상시킨다. TabNet의 아키텍처는 도 6에 도시된다. 피처 트랜스포머는 이텐티브 트랜스포머와 마스크에 모두 연결되어 모든 단계에서 포괄적인 피처 선택을 오케스 트레이션한다. 이텐티브 트랜스포머는 완전히 연결된 레이어와 배치 정규화 레이어로 구성된 다층 구조이다. 이 텐티브 트랜스포머와 마스킹 프로세스의 공식은 [수학식 1]로 표현할 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 a[i-1]은 이전 단계를 나타내고, P[i-1]은 이전 스케일이며, h_i는 특정 훈련 가능한 함수를 나타낸다. 어텐티브 트랜스포머는 두 가지 중요한 요소, 즉 스파스맥스 활성화 함수와 프라이어(prior)가 특징이다. 스파 스맥스는 특징 벡터에 희소성을 도입한 다음 이러한 특징을 유클리드 공간의 확률적 매핑에 투영하여 차원을 줄 인다. 투영 후 각 특징 벡터는 모델 해석 가능성을 향상시키는 데 도움이 되는 확률과 연관된다. 프라이어 스케 일 항인 P[i]는 이전 단계에 걸친 특징의 두드러짐을 나타내며 [수학식 2]로 나타낼 수 있다. [수학식 2]"}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 γ는 한 결정 단계 또는 여러 단계에 걸친 특징 적용 간의 연관성을 설명한다. γ가 1이면 해당 단계에 서 특징이 적용되고, γ가 0이면 여러 단계에 걸쳐 적용이 이루어진다. 어텐티브 트랜스포머는 가장 눈에 띄는 특징을 선택하여 변환된 특징 벡터를 형성하고 이러한 특징을 훈련 가능 한 마스크인 M[j]로 향하게 한다. 마스크는 해석 가능성을 높이고 어텐티브 트랜스포머의 특징 선택을 더욱 세분화한다. b번째 샘플의 j번째 특징을 정의하는 M_bj[i]가 0이면 해당 단계에서 특징이 아무 값도 기여하지 않 음을 의미한다. 각 단계에서 이러한 마스크를 수집하면 최종 의사 결정 과정에서 각 단계의 중요도를 측정하는 계수가 생성된다. 본 발명자는 TabNet 모델을 구축하기 위해 pytorch_TabNet version 4.0을 활용했다. TabNet 의 하이퍼파라미터 는 Optuna 프레임워크에 의해 미세 조정(fine-tune)되었다. 최적화한 TabNet 모델의 하이퍼파라미터는 다음과 같다: 'n_d': 32, 'n_a': 64, ' gamma': 1.0529025412526656, ' momentum': 0.3777743510901338, 'mask_type': 'entmax', ' patienceScheduler': 8, 'epochs': 218 [머신러닝 모델] 랜덤 포레스트(RF) 알고리즘은 \"백(bagged)\" 트리를 사용하는 머신 러닝 전략이다. RF는 의사 결정 트리의 앙상 블에 의존하며, 각 의사 결정 트리는 훈련 데이터 세트에서 무작위로 선택된 샘플과 예측자를 사용하여 구성된 다. 이러한 샘플은 독립적으로 동일하게 배포된다. 기존의 의사 결정 트리와 달리 RF는 사용 가능한 모든 피처 를 분할에 사용하는 대신 각 반복 중에 임의의 피처 하위 집합만 고려하는 다른 접근 방식을 취한다. 이러한 선 택적 특징 하위 집합 전략을 구현하면 각 예측자가 트리 구조의 구성에 기여할 수 있으므로, 단순히 훈련 샘플 을 배깅하는 것에 비해 예측 분산이 줄어들고 모델 정확도가 향상된다. Optuna가 최적화한 RF 모델의 하이퍼파 라미터는 다음과 같다: 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_features': 0.4, 'min_impurity_decrease': 1e-09, 'min_samples_leaf': 6, 'min_samples_split': 10, 'n_estimators': 300. XGBoost(eXtreme Gradient Boosting)은 부스팅 앙상블 프레임워크 내에서 입력 변수와 출력 간의 비선형 관계를 발견하도록 설계된 매우 효과적인 그라디언트 부스팅 방법의 구현이다. 이 방법은 복잡하고 비선형적인 관계를 정확하게 포착하고 학습하는데 좋은 성능을 보여준다. XGBoost는 부스팅 기법을 사용하여 여러 약한 분류기의 강점을 통합함으로써 앙상블의 예측 능력을 향상시킨다. XGBoost는 다양하고 방대한 데이터 세트를 관리할 수 있는 능력과 메모리 소비와 계산 복잡성을 줄이는 최적화 기법으로 차별화된다. 과적합을 방지하고 일반화 가능 성을 개선하기 위해 다양한 정규화 전략을 사용한다. Optuna를 사용하여 최적화한 XGBoost 모델의 하이퍼파라미 터는 다음과 같습니다: 'objective': 'binary:logistic', 'colsample_bytree': 0.904628, 'learning_rate': 0.112842, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 286, 'reg_alpha': 2.344177, 'reg_lambda': 10.0, 'scale_pos_weight': 50.0, 'subsample': 0.610825. LightGBM(Light Gradient Boosting)은 머신 러닝용 그라디언트 부스팅 알고리즘의 성능과 확장성을 갖춘 구현이 다. 이 알고리즘은 그라디언트 기반 일면(one-side) 및 독점 기능 번들링이라는 두 가지 정교한 방법을 사용한 다. LightGBM은 레벨별 트리 성장이 아닌 리프(leaf) 별 트리 성장을 사용하는데, 이는 XGBoost와 같은 기존의 그라디언트 부스팅 기법과는 대조적이다. 리프 단위 트리 성장에서 LightGBM은 전체 손실 감소에 가장 크게 기 여하는 리프를 확장하는데 집중하여 트리를 수직으로 성장시킨다. 이러한 수직 확장 전략을 통해 LightGBM은 필 수 기능에 우선순위를 부여하고 보다 빠르게 컨버전스를 달성할 수 있다. 이와 대조적으로 대부분의 다른 알고 리즘은 레벨을 연속적으로 추가하여 트리 구조를 수평적으로 확장한다. 도 7은 리프 단위 트리 성장의 이점을 보여준다. Optuna가 최적화한 LGBM 모델의 하이퍼파라미터는 다음과 같다: 'bagging_fraction': 0.69664, 'bagging_freq': 7, 'feature_fraction': 0.882759, 'learning_rate': 0.194762, 'min_child_samples': 100, 'min_split_gain': 0.309977, 'n_estimators': 86, 'num_leaves': 256, 'reg_alpha': 1e-10, 'reg_lambda': 10.0, 'subsample_for_bin': 200000. \"범주형 부스팅(categorical boosting)\"의 약자인 CatBoost는 데이터 세트 내의 범주형 열에 집중하는 머신러닝 알고리즘이다. 범주형 특징을 효과적으로 관리하기 위해 순열 기법, OHMS(one_hot_max_size), 목표 기반 통계를 사용한다. CatBoost는 현재 트리의 모든 분할에서 그리디 방법(greedy method)을 사용하여 범주형 변수로 인한 특징 조합의 기하급수적인 증가를 해결한다. CatBoost는 OHMS 매개변수보다 많은 카테고리를 가진 범주형 특징 에 대해 다음 단계를 따른다. - 레코드를 무작위로 하위 집합으로 나눈다. - 변수의 레이블을 정수 값으로 변환한다. - 범주형 속성을 숫자 형식으로 변환한다. 범주형 특성을 숫자 값으로 변환하려면 [수학식 3]에 따라 각 범주에 대한 평균 목표 값(avrTarget)을 계산해야 한다. [수학식 3]"}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서 count_In_Class는 주어진 범주 특징에 대한 타깃의 양수 인스턴스(ones)를 나타내고, total_Count는 이 전 객체의 수이며, prior는 시작 파라미터에서 지정한 값입니다. Optuna가 최적화한 CatBoost 모델의 하이퍼파 라미터는 다음과 같다: 'DEPTH': 2, 'L2_LEAF_REG': 10, 'RANDOM_STRENGTH': 0.167311, 'N_ESTIMATORS': 163, 'ETA': 0.248041 [평가 지표] 본 발명자는 예측 모델의 성능을 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1 점수(F1-score)를 사용하여 평가하였다. 이러한 지표는 아래 공식을 사용하여 계산하였다."}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "(진음성)은 모델에 의해 '우울'(레이블 1)로 올바르게 분류된 인스턴스의 수이다. (진양성)은 모델에 의해 '우울하지 않음'(레이블 0)으로 올바르게 분류된 인스턴스의 수이다. (위음성)은 모델에 의해 '우울'로 잘못 분류된 인스턴스의 수이다. (위양성)은 모델에 의 해 '우울하지 않음'으로 잘못 분류된 인스턴스의 수이다. 또한 모델을 평가하기 위한 추가 성능 지표로 \"수신기 작동 특성 곡선 아래 면적\"(AUC)을 활용했다. AUC 점수는 분류를 위한 특정 컷오프 값에 의존하지 않기 때문에 신뢰할 수 있는 성능 척도이다. AUC가 높을수록 모델의 예 측 성능이 우수함을 나타낸다. 본 발명자는 AUC가 가장 높은 모델을 가장 우수한 예측 능력을 가진 것으로 간주 했다. 여러 모델이 동일한 AUC 값을 얻은 상황에서는 F1 점수가 가장 높은 모델이 더 우수한 것으로 간주했다. 모든 분석에는 Python 3.11.3이 사용되었으며, 모든 모델의 예측 성능을 평가하기 위해 10배 교차 검증이 사용 되었다. [SHapley Additive exExplanations (SHAP)] 예측의 근본적인 이유를 더 잘 이해하기 위해 최상의 예측 모델로 결정된 모델에 대하여 SHAP을 적용했다. SHAP 은 협동 게임 이론의 원리를 사용하여 특정 예측을 위해 각 입력 기능에 중요도 점수를 할당한다. 게임 이론에 서 규칙은 플레이어의 상호 작용 방식을 규제하며, 각 플레이어는 전략을 가지고 보상을 받는다. 게임에 대한 개별 참가자의 기여도는 샤플리 값을 사용하여 결정된다. 모델 설명의 맥락에서 전략은 절차의 결과에, 참가자 는 기능에, 보상은 획득한 결과의 품질에 해당한다. 샤플리 값은 전체 예측에 대한 특정 특성의 기여도를 식별 하는 데 도움이 된다. 샘플링 절차를 반복하여 한계 기여도 근사치를 향상시킬 수 있다. 궁극적으로 SHAP 값은 가능한 모든 특징 연합에 대한 한계 기여도의 가중 평균으로 정의되며, [수학식 4]와 같이 나타낼 수 있다. [수학식 4]"}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서 는 특징 i를 제외한 모든 연합을 고려할 때 특징 i가 기여하는 가중 평균 샤플리 값을 나타낸다. F는 전체 특징 수를, S는 특징의 부분 집합 또는 연합을, f(x_(S∪i))는 특징 i가 포함되었을 때의 모델 예측을, f(x_S)는 특징 i가 포함되지 않은 모델 예측을 나타낸다.[결과 1: 특징 서브 세트의 평가] BorutaShap를 적용하여 RF, XGBoost, LGBM, CatBoost 모델의 중요 특징을 선별한 결과, 각각 138개, 43개, 58 개, 83개의 중요 특징을 얻을 수 있었다. TabNet 모델의 경우 28개의 주요 특징을 확인했다. 그 후, 특징 선택 을 위해 투표 메커니즘을 활용하여 'voting_1', 'voting_2', 'voting_3', 'voting_4', 'voting_5'로 표시된 5 개의 특징 하위 집합을 생성했다. [표 1]은 각 개별 모델에서 선택한 기능 하위 집합과 투표 메커니즘의 영향을 평가하여 기본 하이퍼파라미터와 함께 모든 모델의 AUC 점수를 표시한다. [표 1]"}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "모든 특징을 사용할 경우 RF, XGBoost, LGBM, CatBoost 및 TabNet의 AUC 점수는 각각 0.9759, 0.9932, 0.9732, 0.9744 및 0.8927이었다. 개별 모델의 기능 하위 집합 중 RF 및 LGBM 모델은 각각 0.9769 및 0.9766의 AUC 점 수로 CatBoost 기능을 사용하여 가장 높은 AUC를 달성했다. XGBoost 모델은 RF 기능을 사용하여 0.9767의 가장 높은 AUC를 획득했다. 반면, CatBoost 및 TabNet 모델은 각각 0.9763점 및 0.9247점으로 XGBoost 기능을 사용 하여 가장 높은 AUC를 달성했다. 보팅_1, 보팅_2, 보팅_3, 보팅_4 기능 하위 집합을 사용할 때 RF, XGBoost, LGBM, CatBoost 모델 간의 AUC 차 이는 0.0001~0.0006으로 비교적 작다. 그러나 보팅_4 하위 집합을 사용할 때 TabNet 모델의 AUC에는 상당한 차 이가 있다. TabNet 모델은 이 하위 집합에 대해 0.9302의 AUC를 달성했으며, 이는 모든 기능을 사용할 때 0.8927의 AUC보다 상당히 높은 수치이다. 또한 탭넷 모델의 다른 기능 하위 집합(투표_1, 투표_2, 투표_3, 투표 _4) 간의 AUC 차이는 0.0039에서 0.0151까지 다양하여 성능에 주목할 만한 변동성이 있음을 나타낸다. 따라서 본 발명자는 예측 모델을 훈련하고 최적화하기 위해 36개의 특징을 포함한 vote_4 하위 집합의 특징을 선택했다. 선택된 36개의 특징에 대한 자세한 내용은 [표 2]에 설명되어 있다.[표 2] [표 2] (계속)"}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "[최적화된 모델 평가] 표 3은 36개의 중요 피처를 사용하여 학습 세트와 테스트 세트에 대한 5개의 최적화된 모델(TabNet, RF, XGBoost, LGBM, CatBoost)의 예측 성능을 보여준다다. TabNet은 훈련 세트에서 다른 모든 모델을 능가하는 0.9957의 가장 높은 AUC 점수를 획득했다. XGBoost, LGBM, CatBoost 및 RF 모델의 AUC 값은 각각 0.9947, 0.9947, 0.9946 및 0.9940이었다. F1 점수, 정밀도, 정확도에서도 TabNet이 F1 점수 0.9752, 정밀도 0.9792, 정확도 0.9702로 다른 모델보다 우 수한 성능을 보였다. 그러나 TabNet은 0.9714점으로 XGBoost와 LGBM에 비해 Recall 점수가 약간 낮았는데, 이는 각각 0.9734점, 0.9719점인 XGBoost와 LGBM에 비해 낮은 점수이다.테스트 세트에서 TabNet은 계속해서 우수한 성능을 보여주었다. AUC 0.9937, 정확도 0.9604, 정밀도 0.9356, 리 콜 0.9450, F1 점수 0.9403을 달성했다. 훈련 세트의 결과와 유사하게, TabNet은 테스트 세트에서도 AUC, 정확 도, 정밀도 및 F1 점수 측면에서 다른 모델보다 우수한 성능을 보였다. 도 8의 혼합 행렬(confusion matrix)은 테스트 세트에서 TabNet의 진양성률이 94%, 진음성률이 97%임을 보여 주며, 이 데이터 세트에서 TabNet 모델의 효과를 더욱 검증한다. [표 3]"}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "[SHAP을 통한 TabNet 해석] TabNet 모델의 전체적인 해석을 위해 도 9의 (a) 및 (b)는 우울증 위험 특성의 중요도 순위와 특성 값이 위험 변화에 어떤 영향을 미치는지 보여준다. 도 9의 (a)는 우울증 예측 결과에 크게 기여하는 특성을 강조하고 있다 다. 기여도가 높은 상위 특성은 코드62('난방비 부담으로 난방을 하지 못한 경험'), 코드574('조사 전날 행복감'), 코드286('향후 참여 의지-선거 투표'), 코드659('세대주'), 코드635('코로나19 이전 대비 현재 정서 상태'), 코드67('주거복지 관련 사업-주택 구입 자금(대출) 지원 인지') 등이 있다. 도 9의 (b)에 따르면, '난방비 부담으로 난방을 하지 못한 경험'은 우울증에 중요한 영향을 미치며, 난방비 부 담으로 난방을 하지 못한 경험이 많을수록 우울증 위험이 높아지는 것으로 나타났다. 반대로 \"조사 전날의 행복 감\"이라는 특성의 값이 클수록 우울증 위험이 감소하는 것으로 나타났다. 이 결과는 행복을 경험하는 개인이 우 울증에 걸릴 가능성이 적다는 개념과 일치하기 때문에 직관적이고 설득력이 있다. 도 10 및 도 11은 글로벌 해석 외에도 SHAP force 플롯에서 도출된 두 가지 국지적 설명 사례를 보여준다. 도 10 및 도 11은 샘플 1과 2에 대한 TabNet 모델의 예측에 대한 설명을 보여준다. 첫 번째 샘플의 경우, 모델은 해당 개인이 우울증 위험이 없다고 예측했다. 실제로 이 참가자는 우울증을 앓고 있지 않아 제안된 모델의 예측 이 맞았음이 확인되었다. 이 사람의 특성은 다음과 같이 설명할 수 있다: - 가구원당 민간의료보험 가입 건수(코드140): 1 - 세대주(코드 659): 고등학교 이하 - 조사 전날 행복감(코드 574): 5단계 - 난방비 때문에 난방을 하지 못한 경험(코드62): 없음 - 코로나19 이전과 비교한 현재 감정 상태 (코드635): 50/100점 - 주거복지 관련 사업 인지도 - 주택구입자금(융자) 지원(코드67): 내용에 대해 어느 정도 알고 있음 - 혜택에 대한 만족도 - 긴급재난지원금 (코드640): 만족 - 가계 도움 정도 - 긴급재난지원금 (코드642): 약간 도움됨 - 인지도 - 서울형 기초보장제도 (코드297): 내용을 어느 정도 알고 있음 - 서울시 재난긴급생활비 사용 여부(코드639): 사용 여부는 잘 모르겠다: 사용 안함 - 서울시가 가장 중점적으로 추진해야 할 정책 분야(1순위) (코드 593) 주거 정책 - 식비 부족 (코드193) - 식비 걱정: 전혀 두 번째 샘플의 경우, 모델은 이 사람이 우울증에 걸릴 위험이 있다고 예측했다. 이 사람은 우울증 환자의 실제 상태와 일치하며, 이는 모델의 예측 결과와 일치한다. 이 개인의 특징은 다음과 같다: - 서울시 재난 긴급생활비(코드639) 사용 여부: 재수령 - 일-가정 양립을 위해 가장 필요한 지원(1순위)(코드262): 출산휴가 및 육아휴직 강화 - 가계 지원 수준 - 서울시 재난 긴급생활비 (코드643): 보통 - 가계 지원 수준 - 긴급재난지원금 (코드642): 보통 - 혜택 만족도 - 긴급재난지원금 (코드640): 보통: 보통 - 향후 기부 의향 (코드288): 없음 - 주거복지 관련 사업 향후 이용 의향 - 주택구입자금(융자) 지원(코드94): 아니요 없음 - 코로나19 이전과 비교한 현재 정서 상태 (코드635): 20/100점 - 주거복지 관련 사업 인지도 - 주택구입자금(융자) 지원(코드67): 들어본 적은 있지만, 무슨 사업인지 모른다"}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "- 향후 참여 의향 - 선거 투표 (코드286): 아니다 - 조사 전날의 행복감 (코드574): 7단계 - 난방비 때문에 난방을 하지 못한 경험 (코드62): 없음 - 현재 자녀 수 (코드225): 3 - 예상 자녀 수 (코드226): 3 TabNet 모델과 SHAP를 결합함으로써 우울증 결과에 대한 해석 가능한 TabNet 딥 러닝 모델의 예측 정확도를 검 증할 수 있다. 결과에 따르면 본 발명에서 제안된 모델은 사회복지 조사에서 도출된 표 형식 데이터에 적용했을 때 RF, XGBoost, LGBM, CatBoost와 같은 기존 기계 학습 모델보다 성능이 우수한 것으로 나타났다. 또한 SHAP와 결합된 TabNet 모델은 데이터 분석에 대한 광범위한 전문 지식을 보유하지 않은 사회 분야 전문가와 심리학자에 게 귀중한 도구를 제공합니다. 이를 통해 AI 모델의 의사결정 과정을 쉽게 이해할 수 있어 현장에서의 실제 적 용 가능성이 높아진다. 이상에서 설명된 단계 또는 프로세스는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합에 의해 실행될 수 있다. 예를 들어, 실시예들에서 설명된 단계 또는 프로세스는, 예를 들어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPA(field programmable array), PLU(programmable logic unit), 마이크 로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 실행될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에 서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가"}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "사용되는 것으로 설명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처 리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세 서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서,분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매 체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계 되고 구성된 것들이거나 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에 는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬 (ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치 가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리 터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예 의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이 다."}
{"patent_id": "10-2023-0125604", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2023-0125604", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 우울 장애 예측 시스템의 구성을 도시하는 블록도이다. 도 2는 본 발명의 일 실시예에 따른 우울 장애 예측 시스템을 컴퓨터에서 구현하는 경우의 구성을 나타내는 도 면이다. 도 3은 본 발명의 일 실시예에 따른 우울 장애 예측 시스템을 서버와 클라이언트 단말기에 의해 구현하는 경우 의 구성을 나타내는 도면이다. 도 4는 본 발명의 일 실시예에 따른 우울 장애 예측 시스템에 의해 구현되는 우울장애 예측 방법의 흐름도이다. 도 5는 본 발명의 일 실시예로서 사용된 특징 선택 방법인 보팅 방법의 개념도이다. 도 6은 TabNet 아키텍처를 도시한다. 도 7은 리프 단위 트리 성장의 이점을 보여주는 개념도이다. 도 8은 본 발명의 일 실시예에 따른 예측 모델의 혼합 행렬(confusion matrix)을 도시한다. 도 9는 본 발명의 일 실시예에 따른 예측 모델의 SHAP 그래프이다. 도 10은 본 발명의 일 실시예에 따른 샘플 1의 SHAP force 플롯을 도시한다. 도 11은 본 발명의 일 실시예에 따른 샘플 2의 SHAP force 플롯을 도시한다."}
