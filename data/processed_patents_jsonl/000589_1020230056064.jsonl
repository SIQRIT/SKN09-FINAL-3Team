{"patent_id": "10-2023-0056064", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0159146", "출원번호": "10-2023-0056064", "발명의 명칭": "인공지능 기반 고속 저전력 3D 렌더링 가속기 및 그 방법", "출원인": "한국과학기술원", "발명자": "유회준"}}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "동일한 물체를 여러 방향에서 촬영한 다수의 2D 사진을 사용하여 DNN의 가중치를 학습시킨 뒤 이를 이용하여 3D렌더링하는 심층신경망(DNN) 기반 3D 렌더링 가속기에 있어서,관찰자의 위치 및 방향에서 3D 렌더링 대상인 물체에 대한 이미지 평면을 생성하고 상기 이미지 평면을 다수의타일 단위로 분할한 후, 분할된 타일단위이미지들을 뇌모방 시각인지하여 3D 렌더링을 위해 필요한 DNN 추론범위를 축소 결정하는 시각인지코어(VPC);입력 희소성에 따라 연산 효율이 서로 다른 복수의 뉴럴엔진(NE)을 구비하고, 상기 축소 결정된 DNN 추론범위에포함된 DNN 추론을 가속하되, 상기 DNN 추론을 위해 연산량이 축소된 태스크들을 상기 복수의 뉴럴엔진(NE)들에분할 할당하여 가속하는 하이브리드 뉴럴엔진(HNE); 및상기 타일단위이미지들 각각의 희소성 비율에 의거하여 상기 복수의 뉴럴엔진(NE)들 중 하나로 상기 태스크들각각을 할당하기 위한 선택정보를 생성하는 동적신경망할당(DNNA) 코어를 포함하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속기."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 시각인지코어(VPC)는관찰자의 위치 변화시, 이전프레임과 현재프레임의 친숙도 평가에 의해 재사용 가능한 이전프레임의 픽셀값인재사용 픽셀값을 결정하고, 상기 재사용 픽셀값을 반영하여 현재프레임의 픽셀들 중 DNN 추론이 필요한 DNN 추론 대상 픽셀을 결정한 후, 상기 DNN 추론 대상 픽셀을 나타내는 바이너리 맵을 생성하는 시간적 친숙도 유닛(TFU); 및상기 물체를 사전에 미리 생성된 저해상도 복셀(voxel)로 표현한 후 관찰자의 시선방향으로 상기 복셀 내부에위치한 좌표만을 DNN 추론 대상인 샘플좌표로 생성하되, 상기 DNN 추론 대상 픽셀에 대응한 복셀 내부의 좌표만을 샘플좌표로 생성하는 공간적 주의 유닛(SAU)을 포함하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D렌더링 가속기."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 시간적 친숙도(TF) 유닛은상기 타일단위이미지를 3D 변환한 후, 상기 관찰자의 위치 및 방향의 변화값을 기준으로, 이전프레임의 픽셀별RGB 값을 회전 및 평행 이동시켜 대응된 현재프레임의 픽셀에 투영하는 3D 변환기; 및이전프레임 및 대응된 현재프레임의 픽셀단위로 색상변화값을 예측하고, 상기 예측된 색상변화값이 미리 설정된허용변화값 미만인 픽셀의 RGB값만을 재사용하도록 결정하는 재사용처리부를 포함하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속기."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 3D 변환기는상대적 주소 기반 버퍼링 기법을 활용하여 상기 이전프레임의 픽셀별 RGB값을 회전 및 평행 이동시키는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속기."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 재사용처리부는하나의 현재프레임 픽셀에 다수의 이전프레임 픽셀이 매칭되는 겹침현상이 발생한 경우, 겹침이 발생한 이전프레임 픽셀들 중 가장 앞에 위치하는 픽셀의 RGB값을 선택하여 타일내 겹침을 해소하고, DNN 추론에 의해 타일간공개특허 10-2024-0159146-3-겹침을 해소하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속기."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서, 상기 공간적 주의(SA) 유닛은외부 메모리로부터 수집된 상기 복셀(voxel)에 대한 정보를 저장하는 복셀캐시(Voxel Cache); 상기 바이너리 맵을 기반으로 광선을 발사하여, 상기 광선상의 좌표들 중 상기 DNN 추론 대상 픽셀에 대응한 복셀 내부의 좌표만을 샘플좌표로 생성하는 샘플좌표생성부; 및상기 샘플좌표 생성결과에 의해 상기 DNN 추론 대상 픽셀 별로 유효한 샘플수를 결정하고, 그 결과를 이용하여상기 타일단위이미지를 밀집타일 또는 희소타일로 분류한 후 상기 종류에 따라 상기 하이브리드 뉴럴엔진(HNE)과의 입/출력을 제어하는 태스크 컨트롤러를 포함하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속기."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 공간적 주의(SA) 유닛은DNN 추론 결과에 의거하여 추론의 지속 여부, 및 상기 샘플좌표생성부의 샘플좌표 생성동작을 제어하는 하향식주의(TDA) 로직을 더 포함하고,상기 하향식 주의(TDA) 로직은상기 하이브리드 뉴럴엔진(HNE)으로부터 임의의 제1 레이어에 대한 중간연산결과를 전달받고, 상기 중간연산결과에 포함된 중간밀도값이 미리 설정된 하향임계값 미만인 경우 상기 제1 레이어의 잔여 DNN 추론 단계의 스킵을 결정하고,상기 하이브리드 뉴럴엔진(HNE)으로부터 3D 렌더링 과정 전체에서 발생한 누적밀도값을 전달받고, 상기 누적밀도값이 미리 설정된 상향임계값을 초과하는 경우 상기 샘플좌표생성부의 샘플좌표 생성동작에 대한 중단을 결정하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속기."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제2항에 있어서, 상기 하이브리드 뉴럴엔진(HNE)은입력 데이터에 0이 있을 때 해당 연산을 스킵하는 1D 뉴럴엔진(NE); 입력 데이터에 0의 존재 여부와 상관없이 데이터를 재사용하는 2D 뉴럴엔진(NE);상기 1D NE, 및 상기 2D NE의 입/출력값을 저장하는 입출력 메모리(IOMEM); 및2차 함수와 모듈로 함수로 구성된 근사수식을 이용하여 정현파를 생성하고, 상기 정현파를 이용하여 위치 인코딩을 수행하는 모듈로 기반 위치 인코딩 유닛(Mod-PEU)을 포함하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속기."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 모듈로 기반 위치 인코딩 유닛(Mod-PEU)은반정밀도 형식의 샘플좌표를 2로 나눈 나머지값을 산출하고, 그에 대한 2의 보수를 취하여 제1 및 제2 파라미터를 생성한 후, 상기 제1 및 제2 파라미터를 하기의 수학식에 적용하여 위치 인코딩에 필요한 다수의 사인파 및코사인파를 생성하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속기.(수학식)"}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2024-0159146-4-제2항에 있어서, 상기 동적신경망할당(DNNA) 코어는상기 타일단위이미지 마다, 상기 DNN 추론 대상 픽셀들 중 일부를 희소성 기준 픽셀로 결정하되, 원심 샘플링방식(CS)으로 상기 희소성 기준 픽셀을 결정하고, 상기 희소성 기준 픽셀들 각각의 출력제로패턴을 추출하는 출력제로패턴 추출부; 상기 희소성 기준 픽셀들 각각의 출력제로패턴을 비트와이즈(Bitwise) OR 연산으로 취합하여 상기 희소성 비율을 나타내는 비트마스크를 생성하는 비트마스크 생성부; 및상기 비트마스크가 가지는 0의 개수에 따라 상기 복수의 뉴럴엔진들 중 하나로 상기 태스크들 각각을 할당하기위한 선택정보를 생성하는 선택정보 생성부를 포함하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속기."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 동적신경망할당(DNNA) 코어는상기 선택정보에 의한 상기 복수의 뉴럴엔진들 각각의 태스크 할당정보를 모니터링하고 상기 복수의 뉴럴엔진들각각의 연산수행시간 점유율 특성에 의해 태스크 오프로딩을 실시하되, 상기 복수의 뉴럴엔진들 중 연산수행시간 점유율이 일정한 하나의 뉴럴엔진의 활용도를 향상시키는 방향으로 오프로딩을 수행하는 오프로딩제어부를더 포함하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속기."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 동적신경망할당(DNNA) 코어는상기 비트마스크에 의거하여 상기 복수의 뉴럴엔진들 각각의 클럭을 제어하는 클럭제어부를 더 포함하는 것을특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속기."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "동일한 물체를 여러 방향에서 촬영한 다수의 2D 사진을 사용하여 DNN의 가중치를 학습시킨 뒤 이를 이용하여 3D렌더링하는 심층신경망(DNN) 기반 3D 렌더링 가속기를 이용한 3D 렌더링 방법에 있어서,관찰자의 위치 및 방향에서 3D 렌더링 대상인 물체에 대한 이미지 평면을 생성하고 상기 이미지 평면을 다수의타일 단위로 분할한 후, 분할된 타일단위이미지들을 뇌모방 시각인지하여 3D 렌더링을 위해 필요한 DNN 추론범위를 축소 결정하는 시각인지단계;상기 타일단위이미지들 각각의 희소성 비율에 의거하여 상기 타일단위이미지들 각각의 DNN 추론 방법을 결정하되, 상기 DNN 추론 범위에 포함된 DNN 추론 연산 태스크들을, 입력 희소성에 따라 연산 효율이 서로 다른 복수의 뉴럴엔진(NE)들에 분할 할당하여 상기 타일단위이미지들 각각의 DNN 추론 방법을 결정하는 동적신경망할당단계; 및상기 동적신경망할당단계에서 결정된 DNN 추론 방법에 의해, 상기 DNN 추론을 가속하는 가속단계를 포함하는 것을 특징으로 하는 인공지능기반 고속 저전력 3D 렌더링 방법."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 시각인지단계는상기 물체를 사전에 미리 생성된 저해상도 복셀(voxel)로 표현한 후 관찰자의 시선방향으로 상기 복셀 내부에위치한 좌표만을 DNN 추론 대상인 샘플좌표로 생성하는 공간적 주의(SA) 단계;관찰자의 위치 변화시 이전프레임과 현재프레임의 친숙도 평가에 의해 재사용 가능한 이전프레임의 픽셀값인 재사용 픽셀값을 결정하고, 상기 재사용 픽셀값을 반영하여 현재프레임의 픽셀들 중 DNN 추론이 필요한 DNN 추론대상 픽셀을 결정하는 시간적 친숙도(TF) 단계; 및상기 DNN 추론 결과에 의거하여, 추론의 지속 여부 및 추가 샘플링 필요성 여부를 판단하는 하향식 주의(TDA)단계를 포함하는 것을 특징으로 하는 인공지능기반 고속 저전력 3D 렌더링 방법."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "공개특허 10-2024-0159146-5-제14항에 있어서, 상기 공간적 주의(SA) 단계는외부 메모리로부터 수집된 상기 복셀(voxel)에 대한 정보를 캐시메모리에 저장하는 캐싱단계;상기 관찰자의 시선방향으로 광선을 발사하여, 상기 광선상의 좌표들 중 상기 DNN 추론 대상 픽셀에 대응한 복셀 내부의 좌표만을 샘플좌표로 생성하는 샘플좌표생성단계; 및상기 타일단위이미지를 밀집타일 또는 희소타일로 분류한 후 상기 분류결과에 의해 상기 하이브리드 뉴럴엔진(HNE)과의 입/출력을 제어하는 태스크 컨트롤단계를 포함하는 것을 특징으로 하는 인공지능기반 고속 저전력 3D렌더링 방법."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서, 상기 시간적 친숙도(TF) 단계는상기 타일단위이미지를 3D 변환한 후, 상기 관찰자의 위치 및 방향의 변화값을 기준으로, 이전프레임의 픽셀별RGB 값을 회전 및 평행 이동시켜 대응된 현재프레임의 픽셀에 투영하는 3D 변환단계; 및 이전프레임 및 대응된 현재프레임의 픽셀단위로 색상변화값을 예측하고, 상기 예측된 색상변화값이 미리 설정된허용변화값 미만인 픽셀의 RGB값만을 재사용하도록 결정하는 재사용처리단계를 포함하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 방법."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 3D 변환단계는상대적 주소 기반 버퍼링 기법을 활용하여 상기 이전프레임의 픽셀별 RGB값을 회전 및 평행 이동시키는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 방법."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서, 상기 재사용처리단계는하나의 현재프레임 픽셀에 다수의 이전프레임 픽셀이 매칭되는 겹침현상이 발생한 경우, 겹침이 발생한 이전프레임 픽셀들 중 가장 앞에 위치하는 픽셀의 RGB값을 선택하여 타일내 겹침을 해소하고, DNN 추론에 의해 타일간겹침을 해소하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속방법."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제14항에 있어서, 상기 하향식 주의(TDA) 단계는상기 하이브리드 뉴럴엔진(HNE)으로부터 3D 렌더링 과정 전체에서 발생한 누적밀도값을 전달받고, 상기 누적밀도값이 미리 설정된 상향임계값을 초과하는 경우 상기 샘플좌표생성부의 샘플좌표 생성동작에 대한 중단을 결정하는 샘플좌표생성 중단단계; 및상기 하이브리드 뉴럴엔진(HNE)으로부터 임의의 제1 레이어에 대한 중간연산결과를 전달받고, 상기 중간연산결과에 포함된 중간밀도값이 미리 설정된 하향임계값 미만인 경우 상기 제1 레이어의 잔여 DNN 추론 단계의 스킵을 결정하는 잔여 DNN 추론 스킵단계를 포함하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속방법."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제14항에 있어서, 상기 동적신경망할당단계는상기 타일단위이미지 마다, 상기 DNN 추론 대상 픽셀들 중 일부를 희소성 기준 픽셀로 결정하되, 원심 샘플링방식(CS)으로 상기 희소성 기준 픽셀을 결정하고, 상기 희소성 기준 픽셀들 각각의 출력제로패턴을 추출하는 출력제로패턴 추출단계;상기 희소성 기준 픽셀들 각각의 출력제로패턴을 비트와이즈(Bitwise) OR 연산으로 취합하여 상기 희소성 비율을 나타내는 비트마스크를 생성하는 비트마스크 생성단계; 및상기 복수의 뉴럴엔진들 중 하나로 상기 DNN 추론을 위한 태스크들 각각을 할당하기 위한 선택정보를 생성하되,공개특허 10-2024-0159146-6-상기 비트마스크가 가지는 0의 개수에 따라 상기 선택정보를 생성하는 선택정보 생성단계를 포함하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속방법."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서, 상기 동적신경망할당단계는상기 선택정보에 의한 상기 복수의 뉴럴엔진들 각각의 태스크 할당정보를 모니터링하고 상기 복수의 뉴럴엔진들각각의 연산수행시간 점유율 특성에 의해 태스크 오프로딩을 실시하되, 상기 복수의 뉴럴엔진들 중 연산수행시간 점유율이 일정한 하나의 뉴럴엔진의 활용도를 향상시키는 방향으로 오프로딩을 수행하는 오프로딩단계를 더포함하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속방법."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제20항에 있어서, 상기 동적신경망할당단계는상기 비트마스크에 의거하여 상기 복수의 뉴럴엔진들 각각의 클럭을 제어하는 클럭제어단계를 더 포함하는 것을특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속방법."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제20항에 있어서, 상기 가속단계는2차 함수와 모듈로 함수로 구성된 근사수식을 이용하여 정현파를 생성하고, 상기 정현파를 이용하여 위치 인코딩을 수행하는 모듈로 기반 위치 인코딩 단계; 및상기 선택정보에 의거하여 상기 태스크들 각각을 추론하되, 입력 데이터에 0이 있을 때 해당 연산을 스킵하는1D 뉴럴엔진(NE), 및 입력 데이터에 0의 존재 여부와 상관없이 데이터를 재사용하는 2D 뉴럴엔진(NE) 중 상기태스크들 각각에 할당된 어느 하나를 이용하여 대응된 태스크들을 DNN 추론하는 추론단계를 포함하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 가속방법."}
{"patent_id": "10-2023-0056064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 상기 모듈로 기반 위치 인코딩 단계는반정밀도 형식의 샘플좌표를 2로 나눈 나머지값을 산출하고, 그에 대한 2의 보수를 취하여 제1 및 제2 파라미터를 생성한 후, 상기 제1 및 제2 파라미터를 하기의 수학식에 적용하여 위치 인코딩에 필요한 다수의 사인파 및코사인파를 생성하는 것을 특징으로 하는 인공지능 기반 고속 저전력 3D 렌더링 방법.(수학식)"}
{"patent_id": "10-2023-0056064", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 인공지능 기반 고속 저전력 3D 렌더링 가속기는 동일한 물체를 여러 방향에서 촬영한 다수의 2D 사진 을 사용하여 DNN의 가중치를 학습시킨 뒤 이를 이용하여 3D 렌더링하는 DNN 기반 3D 렌더링 가속기에 있어서, 관 찰자의 위치 및 방향에서 3D 렌더링 대상인 물체에 대한 이미지 평면을 생성하고 상기 이미지 평면을 다수의 타 (뒷면에 계속)"}
{"patent_id": "10-2023-0056064", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 3D 렌더링 가속기 및 그 방법에 관한 것으로서, 보다 상세하게는, 모바일 기기에서의 메타버스 실현 을 위한 인공지능 기반 고속 저전력 3D 렌더링 가속기 및 그 방법에 관한 것이다."}
{"patent_id": "10-2023-0056064", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기계 학습 기술의 한 가지 종류인 심층신경망은 음성인식, 이미지분석 등의 다양한 분야에 활용되고 있으며, 최 근에는 심층신경망 기술이 고성능 3D 렌더링에도 활용되고 있다. 심층신경망을 기반으로 한 3D 렌더링 방식(예컨대, NeRF(Neural Radiance Fields))은 심층신경망 추론을 통해 RGB 값을 추측하여 3D 렌더링을 가능케 하는 방법으로써, 일반 사용자도 쉽게 3D 컨텐츠를 창조, 재구성할 수있어, 가상공간의 자유도를 높이고, 3D 컨텐츠 공유를 위해 필요한 통신 대역폭도 크게 낮출 수 있는 특징이 있 다. 이러한 심층신경망 기반 3D 렌더링은 적은 메모리 사용량과 그 편의성 덕분에 앞으로 발전 가능성이 높은 알고 리즘이지만, 매우 느린 렌더링 속도가 문제로 부각되고 있다. 예를 들어, NVIDIA사의 V100 서버에서 가속을 하 더라도, 이미지 한 장을 렌더링하는데 30초가 소요되는 등 비현실적인 렌더링 속도로 인해, 현재 3D 렌더링의 주류가 되지 못하고 있다. 특히, 심층신경망 기반 3D 렌더링의 느린 속도는 심층신경망 추론의 연산요구량이 매우 높기 때문이다. 따라서 심층신경망 기반 3D 렌더링을 통한 메타버스 실현을 위해서는, 렌더링 속도를 고속(예컨대, 최소 30 FPS(frames-per-second) 이상)으로 가속하면서도 저전력으로 구현하여 VR/AR(Virtual Reality/Augmented Reality) 헤드셋에서 사용 가능한 렌더링 가속 기술이 필요하다. 선행기술문헌 비특허문헌 (비특허문헌 0001) [1] B. Mildenhall et al., \"NeRF: Representing scenes as neural radiance fields for view synthesis,\" in 16th European Conference on Computer Vision (ECCV), 2020, pp. 405-421. (비특허문헌 0002) [2] MetaVRain: A 133mW Real-time Hyper-realistic-3D-NeRF Processor with 1D-2D Hybrid-Neural-Engines for Metaverse on Mobile Devices, ISSCC 2023 발표"}
{"patent_id": "10-2023-0056064", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기 문제를 해결하기 위해 본 발명에서는, 3D 공간을 저해상도 복셀(voxel)로 미리 표현하고, 샘플링 수행시 복셀 내부에 위치한 샘플만 취함으로써 필요한 샘플의 개수를 최소화시킬 수 있고, 이로 인해, 외부 메모리 접 근량을 최소화함과 동시에 연산량을 크게 줄여 렌더링 속도를 향상시키는 인공지능 기반 고속 저전력 3D 렌더링 가속기 및 그 방법을 제공하고자 한다. 또한 본 발명은, 데이터 희소성을 활용하는 1D NE(Neural Engine)와, 데이터 재사용성을 극대화한 2D NE를 함께 채택하고 연산 대상 이미지의 희소성 비율에 의해, 연산량이 축소된 태스크들 각각을 상기 1D NE 및 2D NE에 분 할 할당함으로써 연산 효율성을 향상시키고, 이로 인해, 렌더링 속도를 향상시키는 인공지능 기반 고속 저전력 3D 렌더링 가속기 및 그 방법을 제공하고자 한다. 또한, 본 발명은, 관찰자의 위치 변화시, 이전프레임과 현재프레임의 유사도에 의해 이전프레임의 픽셀값을 재 사용함으로써, 렌더링에 필요한 픽셀 개수를 효과적으로 줄일 수 있고, 이로 인해, 심층신경망 연산량을 줄여 렌더링 속도를 향상시키는 인공지능 기반 고속 저전력 3D 렌더링 가속기 및 그 방법을 제공하고자 한다. 또한, 본 발명은, 심층신경망 기반 3D 렌더링 연산에서 반드시 필요한 위치 인코딩(positional encoding) 동안 2차함수와 모듈로함수로 구성된 다항식으로 정현파 함수를 근사하여 대체함으로써 회로 복잡도를 최소화할 수 있으며, 한 주기 내에서 여러 위치 인코딩 결과를 생성함으로써 전력 및 면적 소모를 줄일 수 있고, 결과적으로 심층신경망 기반 3D 렌더링을 가속화할 수 있는 인공지능 기반 고속 저전력 3D 렌더링 가속기 및 그 방법을 제 공하고자 한다."}
{"patent_id": "10-2023-0056064", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 목적을 달성하기 위해, 본 발명에서 제공하는 3D 렌더링 가속기는 동일한 물체를 여러 방향에서 촬영한 다수의 2D 사진을 사용하여 심층신경망(Deep Neural Network, 이하 'DNN'이라 칭함)의 가중치를 학습시킨 뒤 이 를 이용하여 3D 렌더링하는 DNN 기반 3D 렌더링 가속기에 있어서, 관찰자의 위치 및 방향에서 3D 렌더링 대상인 물체에 대한 이미지 평면을 생성하고 상기 이미지 평면을 다수의 타일 단위로 분할한 후, 분할된 타일단위이미 지들을 뇌모방 시각인지하여 3D 렌더링을 위해 필요한 DNN 추론범위를 축소 결정하는 시각인지코어(Visual Perception Core, 이하 'VPC'라 칭함); 입력 희소성에 따라 연산 효율이 서로 다른 복수의 뉴럴엔진(NE)을 구비하고, 상기 축소 결정된 DNN 추론범위에 포함된 DNN 추론을 가속하되, 상기 DNN 추론을 위해 연산량이 축소된 태스크들을 상기 복수의 뉴럴엔진(NE)들에 분할 할당하여 가속하는 하이브리드 뉴럴엔진(Hybrid Neural Engine, 이하 'HNE'라 칭함); 및 상기 타일단위이미지들 각각의 희소성 비율에 의거하여 상기 복수의 NE들 중 하나로 상 기 태스크들 각각을 할당하기 위한 선택정보를 생성하는 동적신경망할당(Dynamic Neural Network Allocation, 이하 'DNNA'라 칭함) 코어를 포함하는 것을 특징으로 한다. 바람직하게, 상기 VPC는 관찰자의 위치 변화시, 이전프레임과 현재프레임의 친숙도 평가에 의해 재사용 가능한 이전프레임의 픽셀값인 재사용 픽셀값을 결정하고, 상기 재사용 픽셀값을 반영하여 현재프레임의 픽셀들 중 DNN 추론이 필요한 DNN 추론 대상 픽셀을 결정한 후, 상기 DNN 추론 대상 픽셀을 나타내는 바이너리 맵을 생성하는 시간적 친숙도 유닛(Temporal Familiarity Unit, 이하 'TFU'라 칭함); 및 상기 물체를 사전에 미리 생성된 저 해상도 복셀(voxel)로 표현한 후 관찰자의 시선방향으로 상기 복셀 내부에 위치한 좌표만을 DNN 추론 대상인 샘 플좌표로 생성하되, 상기 DNN 추론 대상 픽셀에 대응한 복셀 내부의 좌표만을 샘플좌표로 생성하는 공간적 주의 유닛(Spatial Attention Unit, 이하 'SAU'라 칭함)을 포함할 수 있다. 바람직하게, 상기 HNE는 입력 데이터에 0이 있을 때 해당 연산을 스킵하는 1D NE; 입력 데이터에 0의 존재 여부 와 상관없이 데이터를 재사용하는 2D NE; 상기 1D NE, 및 상기 2D NE의 입/출력값을 저장하는 입출력 메모리 (Input Output MEMory, 이하 'IOMEM'라 칭함); 및 2차 함수와 모듈로 함수로 구성된 근사수식을 이용하여 정현 파를 생성하고, 상기 정현파를 이용하여 위치 인코딩을 수행하는 모듈로 기반 위치 인코딩 유닛(Modulo-based Positional Encoding Unit, 이하 'Mod-PEU'라 칭함)을 포함할 수 있다. 바람직하게, 상기 DNNA 코어는 상기 타일단위이미지 마다,상기 DNN 추론 대상 픽셀들 중 일부를 희소성 기준 픽 셀로 결정하되, 원심 샘플링 방식(CS)으로 상기 희소성 기준 픽셀을 결정하고, 상기 희소성 기준 픽셀들 각각의 출력제로패턴을 추출하는 출력제로패턴 추출부; 상기 희소성 기준 픽셀들 각각의 출력제로패턴을 비트와이즈 (Bitwise) OR 연산으로 취합하여 상기 희소성 비율을 나타내는 비트마스크(bit mask)를 생성하는 비트마스크 생 성부; 및 상기 비트마스크가 가지는 0의 개수에 따라 상기 복수의 NE 중 하나로 상기 태스크들 각각을 할당하기 위한 선택정보를 생성하는 선택정보 생성부를 포함할 수 있다. 또한, 본 발명에서 제공하는 3D 렌더링 가속방법은, 동일한 물체를 여러 방향에서 촬영한 다수의 2D 사진을 사 용하여 DNN의 가중치를 학습시킨 뒤 이를 이용하여 3D 렌더링하는 DNN 기반 3D 렌더링 가속기를 이용한 3D 렌더 링 방법에 있어서, 관찰자의 위치 및 방향에서 3D 렌더링 대상인 물체에 대한 이미지 평면을 생성하고 상기 이 미지 평면을 다수의 타일 단위로 분할한 후, 분할된 타일단위이미지들을 뇌모방 시각인지하여 3D 렌더링을 위해 필요한 DNN 추론범위를 축소 결정하는 시각인지단계; 상기 타일단위이미지들 각각의 희소성 비율에 의거하여 상 기 타일단위이미지들 각각의 DNN 추론 방법을 결정하되, 상기 DNN 추론 범위에 포함된 DNN 추론 연산 태스크들 을, 입력 희소성에 따라 연산 효율이 서로 다른 복수의 뉴럴엔진(NE)들에 분할 할당하여 상기 타일단위이미지들 각각의 DNN 추론 방법을 결정하는 동적신경망할당단계; 및 상기 동적신경망할당단계에서 결정된 DNN 추론 방법 에 의해, 상기 DNN 추론을 가속하는 가속단계를 포함하는 것을 특징으로 한다. 바람직하게, 상기 시각인지단계는 상기 물체를 사전에 미리 생성된 저해상도 복셀(voxel)로 표현한 후 관찰자의 시선방향으로 상기 복셀 내부에 위치한 좌표만을 DNN 추론 대상인 샘플좌표로 생성하는 공간적 주의(Spatial Attention, 이하 'SA'라 칭함) 단계; 관찰자의 위치 변화시 이전프레임과 현재프레임의 친숙도 평가에 의해 재 사용 가능한 이전프레임의 픽셀값인 재사용 픽셀값을 결정하고, 상기 재사용 픽셀값을 반영하여 현재프레임의 픽셀들 중 DNN 추론이 필요한 DNN 추론 대상 픽셀을 결정하는 시간적 친숙도(Temporal Familiarity, 이하 'T F'라 칭함) 단계; 및 상기 DNN 추론 결과에 의거하여, 추론의 지속 여부 및 추가 샘플링 필요성 여부를 판단하 는 하향식 주의(Top-Down Attention, 이하 'TDA'라 칭함) 단계를 포함할 수 있다. 바람직하게, 상기 동적신경망할당단계는 상기 타일단위이미지 마다, 상기 DNN 추론 대상 픽셀들 중 일부를 희소 성 기준 픽셀로 결정하되, 원심 샘플링 방식(CS)으로 상기 희소성 기준 픽셀을 결정하고, 상기 희소성 기준 픽 셀들 각각의 출력제로패턴을 추출하는 출력제로패턴 추출단계; 상기 희소성 기준 픽셀들 각각의 출력제로패턴을 비트와이즈(Bitwise) OR 연산으로 취합하여 상기 희소성 비율을 나타내는 비트마스크를 생성하는 비트마스크 생 성단계; 및 상기 복수의 뉴럴엔진들 중 하나로 상기 DNN 추론을 위한 태스크들 각각을 할당하기 위한 선택정보 를 생성하되, 상기 비트마스크가 가지는 0의 개수에 따라 상기 선택정보를 생성하는 선택정보 생성단계를 포함 할 수 있다. 바람직하게, 상기 가속단계는 상기 선택정보에 의거하여 상기 태스크들 각각을 추론하되, 입력 데이터에 0이 있 을 때 해당 연산을 스킵하는 1D NE 및 입력 데이터에 0의 존재 여부와 상관없이 데이터를 재사용하는 2D NE 중상기 태스크들 각각에 할당된 어느 하나를 이용하여 대응된 태스크들을 DNN 추론하는 추론단계; 및 2차 함수와 모듈로 함수로 구성된 근사수식을 이용하여 정현파를 생성하고, 상기 정현파를 이용하여 위치 인코딩을 수행하 는 모듈로 기반 위치 인코딩 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0056064", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같은 본 발명의 3D 렌더링 가속기 및 그 방법은 3D 공간을 저해상도 복셀(voxel)로 미리 표현하고, 샘플링 수행시 복셀 내부에 위치한 샘플만 취함으로써 필요한 샘플의 개수를 최소화시킬 수 있고, 이 로 인해, 외부 메모리 접근량을 최소화함과 동시에 연산량을 크게 줄여 렌더링 속도를 향상시킬 수 있는 장점이 있다. 또한 본 발명은, 데이터 희소성을 활용하는 1D NE와, 데이터 재사용성을 극대화한 2D NE를 함께 채택하고 연산 대상 이미지의 희소성 비율에 의해, 연산량이 축소된 태스크들 각각을 상기 1D NE 및 2D NE에 분할 할당함으로 써 연산 효율성을 향상시키고, 이로 인해, 렌더링 속도를 향상시킬 수 있는 장점이 있다. 또한, 본 발명은, 관찰자의 위치 변화시, 이전프레임과 현재프레임의 유사도에 의해 이전프레임의 픽셀값을 재 사용함으로써, 렌더링에 필요한 픽셀 개수를 효과적으로 줄일 수 있고, 이로 인해, 심층신경망 연산량을 줄여 렌더링 속도를 향상시킬 수 있는 장점이 있다. 또한, 본 발명은, 심층신경망 기반 3D 렌더링 연산에서 반드시 필요한 위치 인코딩(positional encoding) 동안 2차함수와 모듈로함수로 구성된 다항식으로 정현파 함수를 근사하여 대체함으로써 회로 복잡도를 최소화할 수 있으며, 한 주기 내에서 여러 위치 인코딩 결과를 생성함으로써 전력 및 면적 소모를 줄일 수 있고, 결과적으로 심층신경망 기반 3D 렌더링을 가속화할 수 있는 장점이 있다."}
{"patent_id": "10-2023-0056064", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시 예에 대하여 설명하되, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 발명을 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 한편 도면에서 본 발명을 명확 하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 또한 상세한 설명을 생략하여도 본 기술 분야의 당업자가 쉽게 이해할 수 있는 부분 의 설명은 생략하였다. 명세서 및 청구범위 전체에서, 어떤 부분이 어떤 구성 요소를 포함한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 도 1은 본 발명의 일 실시 예에 따른 인공지능 기반 고속 저전력 3D 렌더링 가속기에 대한 개략적인 블록도이다. 도 1을 참조하면, 본 발명의 일 실시 예에 따른 3D 렌더링 가속기는 동일한 물체를 여러 방향 에서 촬영한 다수의 2D 사진을 사용하여 DNN의 가중치를 학습시킨 뒤 이를 이용하여 3D 렌더링하는 심층신경망 (DNN) 기반 3D 렌더링하는 장치로서, 시각인지코어(Visual Perception Core, 이하 'VPC'라 칭함), 하이브 리드 뉴럴엔진(Hybrid Neural Engine, 이하 'HNE'라 칭함), 동적신경망할당코어(Dynamic Neural Network Allocation Core, 이하 'DNNA-C'라 칭함), 외부 메모리(Global MEM), 및 탑컨트롤러(Top Ctrlr.)를 포함한다. 또한, 상기 장치들(즉, 시각인지코어(VPC), 하이브리드 뉴럴엔진(HNE) , 동적신경망할당코어(DNNA- C라 칭함), 외부 메모리(Global MEM), 및 탑컨트롤러(Top Ctrlr.)) 각각은 모두 네트워크 온칩 (Network-on-Chip)으로 통신한다. 시각인지코어(VPC)는 뇌모방을 통해 필요한 연산량을 줄이는 장치로서, 관찰자의 위치 및 방향에서 3D 렌 더링 대상인 물체에 대한 이미지 평면을 생성하고 상기 이미지 평면을 다수의 타일 단위로 분할한 후, 분할된 타일단위이미지들을 뇌모방 시각인지하여 3D 렌더링을 위해 필요한 DNN 추론범위를 축소 결정한다. 즉, VPC는 BuFF(Bundle-Frame-Familiarity) 아키텍처 구현시 필요한 외부 메모리 접근량을 최소화하고, HNE가 연산해야 하는 태스크의 양을 크게 줄여 전체 렌더링 속도 향상에 기여한다. 이를 위해, VPC는 시간적 친숙도 유닛(Temporal Familiarity Unit, 이하 'TFU'라 칭함), 및 공간적 주의 유닛(Spatial Attention Unit, 이하 'SAU'라 칭함)을 포함한다. TFU는 시간적 친숙도(Temporal Familiarity, TF)과정을 수행하는 장치로서, 이전의 연산 결과물들에서 현 재 프레임에서 유사한 연산들을 제외하는 처리를 수행한다. 예를 들어, TFU는 이전프레임의 렌더링결과 (RGB-D, 빨강, 초록, 파랑, 깊이)를 현재프레임 렌더링에 재사용함으로써, 렌더링이 필요한 픽셀의 개수를 줄이 고, 이로 인해, 렌더링 속도를 빠르게 하기 위한 처리를 한다. 즉, TFU는 관찰자의 위치 변화시, 이전프레 임과 현재프레임의 친숙도 평가에 의해 재사용 가능한 이전프레임의 픽셀값인 재사용 픽셀값을 결정하고, 상기 재사용 픽셀값을 반영하여 현재프레임의 픽셀들 중 DNN 추론이 필요한 DNN 추론 대상 픽셀을 결정한 후, 상기 DNN 추론 대상 픽셀을 나타내는 바이너리 맵을 생성한다. 이를 위한 TFU의 보다 상세한 구성 및 동작에 대 하여는 도 2, 및 도 4 내지 도 7을 참조하여 후술할 것이다. SAU는 공간집중(Spatial Attention, SA)과정을 수행하는 장치로서, 심층신경망이 학습할 때의 기억을 토대 로, 3D 공간상 물체의 대강의 위치를 기억해내 연산량을 줄이는 처리를 수행한다. 예를 들어, SAU는 복셀 없이 학습된 심층신경망를 통해 3D 공간을 미리 저해상도 복셀로 표현하고, 심층신경망 기반 3D 렌더링 연산 중 샘플링 과정에서 복셀안에 있는 점들만 샘플링해 필요한 샘플의 개수를 최소화시키기 위한 처리를 한다. 즉, SAU는 상기 물체를 사전에 미리 생성된 저해상도 복셀(voxel)로 표현한 후 관찰자의 시선방향으로 상기 복 셀 내부에 위치한 좌표만을 DNN 추론 대상인 샘플좌표로 생성하되, 상기 DNN 추론 대상 픽셀에 대응한 복셀 내 부의 좌표만을 샘플좌표로 생성한다. 이를 위한 SAU의 보다 상세한 구성 및 동작에 대하여는 도 3, 도 8, 및 도 9를 참조하여 후술할 것이다. 하이브리드 뉴럴엔진(HNE)은 VPC에서 필요한 연산량을 최소화한 뒤 남은 연산을 빠르고 효율적으로 가속하기 위한 장치로서, 서로 다른 아키텍처를 차용하여 입력 희소성에 따라 연산 효율이 서로 다른 복수의 뉴 럴엔진(Neural Engine, 이하 'NE'이라 칭함)을 구비하고, 상기 NE들을 이용하여 상기 남은 DNN 추론을 가속하되, 상기 DNN 추론을 위한 태스크들을 상기 복수의 뉴럴엔진(NE)들에 분할 할당하여 가속한다. 특히, HNE는 VPC에서 축소 결정된 DNN 추론범위에 포함된 DNN 추론을 가속한다. 즉, HNE는 VPC 에서 연산을 수행해야 한다고 판단한 태스크들에 대해 DNN 추론을 수행하되, 데이터 희소성을 활용하는 1D NE와, 데이터 재사용성을 극대화한 2D NE를 함께 활용하여 추론을 효율적으로 가속한다. 이와 같이, 1D NE와 2D NE를 동시에 활용함으로써, 본 발명의 HNE는 희소성을 활용하지 않았을 때에 비해 3.7배의 높은 렌더링 속도를 달성할 수 있다. 또한, 본 발명의 HNE는 1D NE 혹은 2D NE 둘 중 하나로만 가 속했을 때에 비해, 최소 2.4배 높은 에너지 효율을 보였다. 이러한 HNE의 보다 상세한 구성 및 동작에 대하여는 도 10 내지 도 16을 참조하여 후술할 것이다. 동적신경망할당코어(DNNA-C)는 HNE를 구성하는 복수의 NE들 중 하나로 상기 태스크들 각각을 할당하 기 위한 장치로서, 상기 타일단위이미지들 각각의 희소성 비율에 의거하여 상기 복수의 NE들 중 하나로 태스크 를 할당하기 위한 선택정보를 생성한다. 즉, DNNA-C는 상기 타일단위이미지들 각각의 희소성 비율에 따라 DNN 채널을 두 그룹으로 분리한다. 이를 위해, DNNA-C는 희소성 비율의 높고 낮음을 결정하기 위한 기준값을 저장하고, VPC에서 출력된 임의의 제1 타일단위이미지의 희소성이 상기 기준값 이상이면 희소성이 높다고 판단하여 상기 제1 타일단위이미 지가 1D NE에서 처리되도록 1D NE로 채널을 할당하고, 상기 제1 타일단위이미지의 희소성이 상기 기준값 미만이 면 희소성이 낮다고 판단하여 상기 제1 타일단위이미지가 2D NE에서 처리되도록 2D NE로 채널을 할당할 수 있다. 이러한 DNNA-C의 보다 상세한 구성 및 동작에 대하여는 도 17 내지 도 22를 참조하여 후술할 것이다. 외부 메모리(Global MEM)는 3D 렌더링 가속기를 동작시키기 위해 미리 결정된 정보들을 저장한다. 특 히, 외부 메모리(Global MEM)는 DNN의 가중치값을 저장한다. 탑컨트롤러(Top Ctrlr.)는 미리 설정된 제어명령, 또는 외부로부터 전달되는 제어명령에 의거하여, 3D 렌 더링 가속기의 동작을 제어한다. 도 2는 본 발명의 일 실시 예에 따른 TFU에 대한 개략적인 블록도이고, 도 3은 본 발명의 일 실시 예에 따 른 SAU에 대한 개략적인 블록도이고. 도 4 내지 도 9는 VPC를 구성하는 매크로 불록레벨 6개의 파이 프라인 단계들의 처리 과정을 예시한 도면들이다. 도 1, 도 2, 및 도 4 내지 도 7을 참조하여, 본 발명의 일 실시 예에 따른 TFU의 구성 및 동작을 설명하면 다음과 같다. TFU는, 도 2에 예시된 바와 같이, 3D 변환기 및 재사용처리부를 포함하여 구성되며, 도 4에 예시 된 매크로 블록레벨 6개의 파이프라인 단계들 중 3D 변환단계(3D Transformation), 시간친숙도 평가단계 (Temporal Familiarity(TF) Evaluation), 및 RGB 겹침문제 해결단계(RGB Overlap Handling)를 수행한다. 특히, 3D 변환기는 상기 3D 변환단계(3D Transformation)를 수행하고, 재사용처리부는 상기 시간친숙도 평가 단계(Temporal Familiarity(TF) Evaluation), 및 상기 RGB 겹침문제 해결단계(RGB Overlap Handling)를 수행한 다. 한편, TFU는, I/O 버퍼 및 TTH(Tile-wise TF Handler)를 더 포함할 수 있다. 먼저, TFU는, 이전프레임의 RGB-D 픽셀을 재사용하여 현재 프레임 픽셀을 채운다. 이를 위해, 3D 변환기 는 상기 타일단위이미지에 대한 3D 변환한 후, 상기 관찰자의 위치 및 방향의 변화값을 기준으로, 이전프레 임의 픽셀별 RGB 값을 회전 및 평행 이동시켜 대응된 현재프레임의 픽셀에 투영한다. 한편, 타일 내의 픽셀은 3D 변환 후에도 비슷한 곳으로 이동하는 특징(즉, 데이터 지역성(Data Locality))을 가 지므로, 3D 변환기는 상대적 주소 기반 버퍼링(Relative Addressing-based Buffering) 기법을 활용할 수 있다. 이 경우, 상대적 주소 기반 버퍼링 기법을 사용하지 않을 때와 대비하여, 필요한 출력 버퍼의 크기를 최 소화하고 외부 메모리 액세스(EMA)를 97.9% 만큼 줄일 수 있다. 이 때, 상기 상대적 주소 기반 버퍼링 기법은 공지의 기술을 이용할 수 있다. 이러한 3D 변환기의 처리 과정이 도 5에 예시되어 있다. 도 5는 상기 6개의 파이프라인 단계들 중, 3D 변환단계(3D Transformation)에 대한 처리 과정을 설명하기 위한 도면으로서, 관찰자 위치가 변화하였을 때(Moving Camera Viewpoint), 변화한 위치를 바탕으로 이전프레임 RGB- D 결과를 회전, 평행 이동시켜, 현재프레임의 픽셀을 채우는 과정을 도시하고 있다. 이와 같이, 3D 변환을 통해 재사용할 수 있는 픽셀의 개수는 매우 많지만, 이를 3D 렌더링에 그대로 활용할 경 우 9.7dB 만큼의 최대 신호 대 잡음비(Peak Signal-to-Noise Ratio, PSNR) 손실이 나타나며, 이로 인해, 렌더 링 퀄리티에 크게 손상을 주는 문제가 있다. 따라서 본 발명에서는, 이를 방지하기 위해, 재사용처리부에서, 시간친숙도 평가단계(TF Evaluation)를 수 행한다. 즉, 재사용처리부는 이전프레임 및 대응된 현재프레임의 픽셀단위로 색상변화값을 예측하고, 상기예측된 색상변화값이 미리 설정된 허용변화값 미만인 픽셀의 RGB값만을 재사용하도록 한다. 이 때, 상기 시간친숙도 평가단계(TF Evaluation)는, 심층신경망의 부분 연산만을 수행해, 재사용하고자 하는 픽셀의 RGB 변화가 클지 작을지 미리 예상하고, 만약 RGB 변화가 크다고 예상하면, 재사용하지 않고 새롭게 RGB 값을 찾도록 유도한다. 즉, 상기 시간친숙도 평가단계(TF Evaluation)는, 심층신경망 추론 결과의 변화를 추정 하여 3D 변환 전후의 색상 차이를 예측하는 기술을 활용한 것으로서, 심층신경망 기반 3D 렌더링에서 심층신경 망 추론의 결과물인 밀도는 관찰자의 위치와 바라보는 방향에 상관없이 일정하게 나타나지만 샘플의 색상은 카 메라 좌표에 따라 달라지는 특징을 이용하여, 카메라 좌표의 영향을 받는 마지막 몇 개의 레이어만 분석하여 색 상 변화를 추정한다. 이를 위해, 재사용처리부는 이전 프레임 계산 단계에서, 카메라 포즈 종속 레이어의 입력 특징 맵을 기억하 고 있다가, 현재 프레임 계산시 나머지 레이어에 대해서만 부분 추론(Partial Inference)을 수행한다. 따라서 본 발명은, 1dB 미만의 PSNR 손실만을 보이면서 심층신경망 추론의 95% 이상을 제외할 수 있는 장점이 있다. 이러한 시간친숙도 평가단계(TF Evaluation)에 대한 처리 과정이 도 6에 예시되어 있다. 도 6은 상기 6개의 파이프라인 단계들 중, 시간친숙도 평가단계(TF Evaluation)에 대한 처리 과정을 설명하기 위한 도면으로서, 심층신경망 기반 3D 렌더링에 사용되는 심층신경망의 일부분만 추론해 이전 프레임의 RGB-D 값을 재사용 할 수 있는지 없는지 판단하는 과정을 도시하고 있다. 도 1, 도 2, 및 도 6을 참조하면, TFU 는 변환 결과를 HNE로 전송하고 부분 INF를 사용하여 친숙도를 계산한다. 한편, 부분 INF의 오버헤드를 최 소화하기 위해 이전 픽셀의 중간 특징 맵을 로드하고 현재 프레임의 업데이트된 보기 방향을 사용하여 색상 값 을 업데이트한다. 이전 INF 결과인 활성화 값을 불러와서 재사용하기 때문에 부분 INF는 전체 INF에 비해 0.72% 의 연산량만을 보인다. 즉, 시간친숙도 평가단계(TF Evaluation)에서는, 이전 프레임의 중간 합 결과를 기억하 고 있다가 부분 심층신경망 추론 때 활용되어 필요한 MAC 연산을 99.3% 감소시킨다. 또한, TFU는 HNE(12 0)의 도움을 받아서, 상기 시간친숙도 평가단계(TF Evaluation)를 수행하고, HNE가 부분 INF를 완료하면 재사용 가능한 픽셀을 나타내는 바이너리 맵(Bmap)을 만든다. 한편, 하나의 현재프레임 픽셀에 다수의 이전프레임 픽셀이 매칭되는 겹침현상이 발생한 경우, 재사용처리부 는 겹침이 발생한 이전프레임 픽셀들 중 가장 앞에 위치하는 픽셀의 RGB값을 선택하여 타일내 겹침을 해소 하고, DNN 추론에 의해 타일간 겹침을 해소하는 RGB 겹침문제 해결단계(RGB Overlap Handling)를 수행한다. 이 러한 RGB 겹침문제 해결단계(RGB Overlap Handling)에 대한 처리 과정이 도 7에 예시되어 있다. 도 7은 상기 6개의 파이프라인 단계들 중, RGB 겹침문제 해결단계(RGB Overlap Handling)에 대한 처리 과정을 설명하기 위한 도면으로서, 도 1, 도 2, 및 도 7을 참조하면, TFU는 타일 내 겹침이 발생했을 때와, 타일 밖 겹침이 발생했을 때 다른 원칙을 가지고 해결한다. 먼저, 타일 내에서 타일 내로 이동하다 겹침이 발생한 경 우, TFU는 현재 관찰자 기준으로 더 가까운 RGB-D를 선택한다. 이를 위해, TFU는 인트라 타일 처리 중에 깊이 비교기를 사용하여 카메라 원점에 가장 가까운 RGB-D 픽셀 하나만 선택한다. 한편, 타일 간 이동으로 겹침이 발생한 경우, TFU는 깊이 비교 없이 새로운 RGB-D 연산을 수행하게 한다. 이를 위해, TFU내의 TTH는 타일 간 처리에서 깊이 비교를 건너뛴다. 대신 비트 단위의 'AND' 연산을 사용하여 겹치는 픽셀을 찾는다. 이렇게 다른 겹침 해결 방식은 모두 깊이 비교로 RGB-D를 선택했을 때에 비해 외부 메모리 엑세스 양을 75% 줄일 수 있다. 또한, 상기 AND 연산으로 생성된 Bmap은 인접한 타일의 변환 결과에 응답하고 최종 누적 Bmap은 새로운 RGB-D 값을 얻기 위해 추론이 필요한지 여부를 나타낸다. 상기한 바와 같이, 본 발명은, 이기종 중첩 처리 덕분에 총 99.5%의 EMA를 줄일 수 있고, 최종적으로 TFU는 이 전 프레임의 RGB-D 픽셀을 재사용할 수 있어 평균 48.6배의 속도 향상 효과를 보인다. 도 1, 도 3, 도 8, 및 도 9를 참조하여, 본 발명의 일 실시 예에 따른 SAU의 구성 및 동작을 설명하면 다 음과 같다. SAU는, 도 3에 예시된 바와 같이, 복셀캐시, 샘플좌표 생성부, 태스크 컨트롤러, 및 TDA 로직 을 포함하여 구성되며, 도 4에 예시된 매크로 블록레벨 6개의 파이프라인 단계들 중 복셀캐싱단계(Voxel Caching), 샘플좌표 생성단계(Sampling Coordinate Gen.), 태스크 할당단계(Task Allocation), 및 하향식주의 단계(Top-Down Attention, TDA)를 수행한다.복셀캐시는 외부 메모리로부터 수집된 상기 복셀(voxel)에 대한 정보를 저장한다. 샘플좌표 생성부는 샘플좌표를 생성하되, 상기 바이너리 맵을 기반으로 광선을 발사하여 상기 광선상의 좌 표들 중 상기 DNN 추론 대상 픽셀에 대응한 복셀 내부의 좌표만을 샘플좌표로 생성한다. 태스크 컨트롤러는 상기 샘플좌표 생성결과에 의해 상기 DNN 추론 대상 픽셀별로 유효한 샘플수를 결정하고, 그 결과를 이용하여 상기 타일단위이미지를 밀집타일 또는 희소타일로 분류한 후 상기 종류에 따라 상기 하이브리드 뉴럴엔진(HNE)과의 입/출력을 제어한다. TDA 로직은 HNE의 DNN 추론 결과에 의거하여 추론의 지속 여부, 및 상기 샘플좌표생성부의 샘플좌표 생성동작을 제어한다. 즉, TDA 로직은 HNE으로부터 임의의 제1 레이어에 대한 중간연산결과를 전달받 고, 상기 중간연산결과에 포함된 중간밀도값이 미리 설정된 하향임계값 미만인 경우 상기 제1 레이어의 잔여 DNN 추론 단계의 스킵을 결정할 수 있다. 또한, TDA 로직은 HNE으로부터 3D 렌더링 과정 전체에서 발 생한 누적밀도값을 전달받고, 상기 누적밀도값이 미리 설정된 상향임계값을 초과하는 경우 상기 샘플좌표생성부 의 샘플좌표 생성동작에 대한 중단을 결정할 수 있다. 도 8은 상기 6개의 파이프라인 단계들 중, 복셀캐싱단계(Voxel Caching), 샘플좌표 생성단계(Sampling Coordinate Gen.), 및 하향식주의단계(Top-Down Attention, TDA)에 대한 처리 과정을 설명하기 위한 도면으로 서, 도 1, 도 3, 및 도 8을 참조하면, SAU는 복셀 안에 존재하는 샘플만 좌표를 형성하기 위해 외부 메모 리로부터 복셀정보를 불러오는데, 이 때, 외부메모리에서 불러온 복셀을 중복해서 불러오는 것을 최소화하기 위 해, 상기 복셀캐싱단계(Voxel Caching)에서는 상기 복셀정보를 복셀캐시에 저장하고, 추후에 복셀캐시 에 저장되지 않은 복셀정보만을 선택적으로 불러올 수 있도록 한다. 한편, 샘플좌표생성부는 샘플이 주의맵(Attention Map) 내부에 있는지 여부를 평가하여 픽셀당 8개 샘플의 좌표를 생성한다. 이 때, 샘플좌표생성부는 처음에는 8개의 샘플 좌표를 생성하고, TDA를 통해 누적된 밀도 가 낮을 경우 해당 픽셀에 대하여 추가로 8개씩 샘플링을 더 진행할 수 있다. 결과적으로, 픽셀별로 샘플링되는 좌표의 개수는 8의 배수가 된다. 또한, TDA 로직에서 누적된 밀도를 수신하여 샘플좌표계산의 지속여부를 결정하는 과정을 예시하고 있다. 이와 같이, TDA 로직을 활용함으로써, SAU는 쓸모없는 샘플의 샘플 생성을 피할 수 있다. 도 9는 상기 6개의 파이프라인 단계들 중, 태스크 할당단계(Task Allocation)에 대한 처리 과정을 설명하기 위 한 도면으로서, 도 1, 도 3, 및 도 9를 참조하면, 태스크 컨트롤러는 상기 복셀캐싱단계(Voxel Caching) 및 샘플좌표 생성단계(Sampling Coordinate Gen.)를 거쳐 생성된 샘플 좌표들을 모아, HNE의 입력으로 넣기 위해 준비하는 태스크 할당단계(Task Allocation)를 수행한다. 이를 위해, 태스크 컨트롤러는 먼저, 상기 단위타일이미지당 계산해야하는 픽셀의 개수(즉, 유효한 샘플의 수)에 의해 상기 단위타일이미지들을 분류하되, 상기 계산해야 하는 픽셀의 개수가 많다면 밀집타일(Dense tile), 적다면 희소타일(Sparse tile)로 분류한다. 그리고, 그 분류결과에 따라, 상기 밀집타일(Dense tile)은 마스킹(Masking)만하여 HNE에 입력으로 넣어주고, 희소타일(Sparse tile)은 연산이 필요한 픽셀만 누적버 퍼(accumulation buffer)에 쌓고, 태스크가 충분히 쌓였을 때만 HNE에게 넘겨 out-of-order 연산을 수행 한다. 즉, 입력 컨트롤러는 밀도가 높은 타일을 HNE에 직접 전달하지만, 희소 타일의 경우 입력 좌표가 버퍼에 충분히 축적될 때까지 기다린다. 이는 하나의 타일에 충분한 샘플이 존재할 때, HNE의 효율이 더욱 향상될 수 있기 때문이다. 한편, 출력 컨트롤러는 마스킹 유닛 또는 재정렬 버퍼(ROB)로 HNE 출력을 디코딩하여 최종 RGB-D 결과를 생성한 다. 즉, 출력 컨트롤러는 HNE로부터 밀집타일(Dense tile)에 대한 연산결과의 경우 마스킹 유닛만 거치고, 희소타일(Sparse tile)에 대한 연산결과의 경우 재정렬 버퍼(ROB)를 활용해 원래 크기의 타일로 출력을 복구한 후, 이를 최종 출력으로 만들어 낸다. 이로 인해, SAU는 TFU에 이어 추가적으로 평균 23.1배 더 높은 처리량을 보여주었으며, 이와 같이, TFU와 SAU가 결합된 VPC는 최종적으로 바닐라 심층신경망 기반 3D 렌더링 가속보다 1120배 더 빠른 렌더링을 달성하는 BuFF를 성공적으로 실현하였다. 도 10은 본 발명의 일 실시 예에 따른 하이브리드 뉴럴엔진(HNE)에 대한 개략적인 블록도이다. 도 1 및 도 10을 참조하면, 본 발명의 일 실시 예에 따른 HNE는 1D NE, 2D NE, 및 PEU를 포함한다. 이 밖 에도, NHE는 1D NE, 및 2D NE의 입/출력값이 저장되는 IOMEM(In Out MEMory), WMEM (WeightMemory), CSMEM (Centrifugal Sampling Memory), PSMEM (Partial-sum Memory) 등이 주변부에 달려 있어, 심층 신경망 가속 연산을 돕는다. 1D NE는 입력 데이터에 0이 있을 때 해당 연산을 스킵함으로써 데이터 희소성이 높은 데이터(즉, Sparse한 입력 데이터)에 최적화된 뉴럴엔진이다. 이를 위해, 1D NE는 8개의 PE 유닛으로 구성되며 각 PE 유닛은 단 일 NZ(nonzero) 입력 활성화 값(Input Activation, IA)을 수신하여 동시에 32개의 출력을 계산할 수 있다. 2D NE는 입력 데이터에 0의 존재 여부와 상관없이 데이터를 재사용하는 특징을 가짐으로써 데이터 희소성 이 낮은 데이터(즉, Dense한 입력 데이터)에 최적화된 뉴럴엔진이다. 따라서, 2D NE는 인코딩 없이 밀집된 IA를 수신한다. 즉, 2D NE는 희소성에 관계없이 입출력 메모리(In-out Memory, IOMEM)에서 32개의 IA를 수신하고 가산기 트리를 사용하여 32개의 출력을 생성할 수 있다. 한편, 모든 중간 부분 합계는 부분 합계 메모리(Partial-sum Memory, PSMEM)에 저장되고 ReLU와 같은 후처리 후 IOMEM으로 전송된다. 부분 합계 집계 단계에서 출력 활성화 값을 재정렬하여 1D NE및 2D NE에 독립적 으로 할당한다. 따라서 각 NE(121 또는 122)는 채널의 일부만 수신하게 되고, 이로 인해 각 NE(121 또는 122)가 DNN의 작은 부분만 가속한다고 착각하게 된다. 1D NE 및 2D NE는 모두 IOMEM 뿐만 아니라 PEU 로부터 IA를 수신하여 위치 인코딩 결과가 필요한 계층을 계산할 수 있다. 도 11은 서로 다른 디자인 철학을 갖는 1D NE와 2D NE를 도시한 도면으로서, 각각의 장단점을 설명하 기 위한 도면이다. 도 10 및 도 11을 참조하면, 입력 희소성이 높으면 1D NE의 효율이 늘어나지만, 입력 희소성이 낮으면 2D NE의 효율이 더 높아지는 것을 알 수 있다. 예를 들어, 1D NE는 희소성 비율이 60% 미만이 되면 상당한 성능 저하를 보이는 반면, 2D NE는 밀도가 높은 입력에 더 유리하다. 따라서 VPC 를 통해 연산량을 제거하고 남은 심층신경망 연산들은 그 데이터의 희소성 비율에 의해 1D NE 및 2D NE에 동적으로 할당된다. PEU는 정현파를 이용하여 위치 인코딩(Positional Encoding)을 수행하되, 3D 렌더링에 반드시 필요한 정현 파의 생성을 빠르고 효율적으로 수행하기 위해, 2차 함수와 모듈로(modulo) 함수로 구성된 근사수식을 이용하여 정현파를 생성하고, 상기 정현파를 이용하여 위치 인코딩(Positional Encoding)을 수행한다. 한편, 이처럼 모듈 로(modulo) 함수를 적용함으로써, PEU를 모듈로 기반 위치 인코딩 유닛(Mod-PEU, Modulo-based PEU)이라 칭한다. 도 12 내지 도 16은 이러한 모듈로 기반 위치 인코딩 유닛(Mod-PEU)의 구성 및 동작을 설명하기 위한 도면으로 서, 모듈로 기반 위치 인코딩의 단계별 동작을 분리하여 설명하고 있다. 도 12 내지 도 16을 참조하여, PEU의 보다 상세한 구성 및 동작을 설명하면 다음과 같다. 도 12는 Mod-PEU(Modulo-PEU)의 개발 동기를 설명하기 위한 도면으로써, 도 12를 참조하면, 기존 심층신경망 기 반 3D 렌더링 연산(Full NeRF)에서 위치 인코딩(Positional Encoding)은 연산의 큰 부분을 차지하지 않고 있었 으나, BuFF 아키텍처의 TF 과정을 수행할 때는 부분 추론만 수행하면서 위치 인코딩(Positional Encoding)이 무 려 94.7%의 연산량을 차지하게 된다. 따라서, 고속 저전력 렌더링을 유지하기 위해서는 빠르고 효율적인 사인파 함수 생성이 반드시 필요하다. 도 13은 2차 함수와 모듈로(modulo) 함수로 구성된 근사수식(즉, 주기 다항식(Periodic Polynomial))을 예시한 도면으로써, 도 13을 참조하면, 본 발명의 PEU는 반정밀도 형식의 샘플좌표를 2로 나눈 나머지값을 산출하 고, 그에 대한 2의 보수를 취하여 제1 및 제2 파라미터를 생성한 후, 상기 제1 및 제2 파라미터를 하기의 (수학 식 1)에 적용하여 위치 인코딩에 필요한 다수의 사인파 및 코사인파를 생성한다. 수학식 1"}
{"patent_id": "10-2023-0056064", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상기 수학식은 Modulo 함수들의 곱을 통해 주기성과 사인함수의 형태를 흉내낸 것으로써, 심층신경망 기반 3D 렌더링 수행시 PSNR 손실이 없는 것을 확인하였으며, 기존 테일러 급수 전개에 비해 단순한 수식을 보이는 것을볼 수 있다. 또한, 상기 수학식에 의하면, 모듈로 계산으로 인해 주기 4로 출력이 반복된다. 이는 제안하는 근 사 방법이 사인파 함수와 동일하게 여전히 미분 가능한 특성을 가지고 있으며, 그래디언트의 방향 역시 기존 사 인파 함수와 거의 동일하기 때문이다. 따라서, 본 발명의 PEU는 위치 인코딩 동안 간단한 주기 다항식으로 정현파 함수를 근사할 수 있다. 도 14는 상기 주기 다항식 기반의 사인파 함수 생성을 위한 Mod-PEU의 기본 연산 유닛을 예시한 도면으로 써, 모듈로회로(Modulo Circuit), 부호계산회로(Sign Calculation Circuit, SCC) 및 크기계산회로(Magnitude Calculation Circuit, MCC)로 구성되는 Mod-PEU 중 모듈로회로(Modulo Circuit)를 예시하고 있다. 도 14를 참조하면, 상기 모듈로회로는 상기 근사수식에 필요한 2개의 모듈로 잔여물인 mod(x,2)와 mod(2-x,2)를 만든다. 이를 위해, 상기 모듈로회로는 IEEE 754 반정밀도 형식(Half-precision, Floating-point 16-bit, FP16)으로 샘플의 좌표를 수신하고 간단한 산술비트시프터(Arithmetic Shifter, ASH)로 mod(x,2)를 얻는다. 이 후 mod(2-x,2)는, mod(-x,2)와 같은 값을 가지므로, 2의 보수유닛(2’Complement Unit)을 거쳐 간단하게 계산 할 수 있다. 도 15는 상기 주기 다항식(Periodic Polynomial)(즉, 근사 수식)의 부호를 결정하는 상기 부호계산회로(SCC)를 설명하기 위한 도면이다. 도 15를 참조하면, 사인(Sin)함수의 부호는 입력의 부호와 비트 시프트 연산 이후 MSB 값들의 XOR 연산 결과를 통해 얻어낼 수 있고, 코사인(Cos)함수의 부호는 비트시프트연산 이후, 2’을 더해 만 들 수 있다. 한편, 위치 인코딩에는 '2의 거듭제곱' 시퀀스가 포함된 여러 인코딩 결과가 필요하다. 따라서 상기 부호계산회 로(SCC)와 후술될 크기계산회로(MCC)는 모두 이러한 특성을 고려하여 30개의 위치 부호화 값을 병렬로 만든다. 도 16은 상기 크기계산회로(MCC)를 설명하기 위한 도면으로, 도 16을 참조하면, 상기 모듈로회로(Modulo Circuit)에 의해 만들어진 Modulo 결과들을 곱하여 30개의 sin, cos함수 값들을 동시 생산하되, 사인 함수의 크 기는 mod(x,2) 및 mod(2-x,2)를 곱하여 산출하고, 코사인 함수는 mod(x+1,2)와 mod(1-x,2)을 곱하여 산출할 수 있다. 그런데, 이 때, MCC를 통한 크기 계산시, 사인 및 코사인 함수 모두 동일한 LSB 곱셈 결과가 필요하며, 2 곱셈의 거듭제곱을 고려할 때, LSB 곱셈은 다중 위치 인코딩 결과를 만들기 위해 재사용될 수 있다. 따라서, 상 기 크기계산회로(MCC)는 LSB part의 결과물은 30개의 output이 공유하도록 함으로써, 회로 복잡도를 최소화 시 켰다. 즉, MCC는 다중 인코딩 결과 생성 중에 LSB 부분 곱셈기를 공유함으로써, 추가로 38.2%의 전력 소비를 줄 였다. 이와 같이 함으로써, 본 발명은 정현파 형성의 오버헤드를 최소화할 수 있다. 즉, Mod-PEU는 기존 LUT 혹 은 CORDIC 방식에 비해, 최대 96% 낮은 전력 소모와 최대 90% 낮은 면적을 요구하였으며, 단일 연산 사이클에 여러 개의 사인파 함수 값을 얻을 수 있어, 고속 연산에도 최적화시켰다. 따라서 본 발명은, Mod-PEU를 적 용함으로써, BuFF 아키텍처를 차용하더라도 큰 성능 저하 없이 TF Evaluation을 포함한 심층신경망 기반 3D 렌 더링을 가속화할 수 있다. 도 17은 본 발명의 일 실시 예에 따른 동적신경망할당(DNNA) 과정에 대한 개념을 설명하기 위한 도면으로서, VPC의 출력을 HNE로 전달할 때 이루어지는 타일단위이미지들에 대한 동적할당과정(Dynamic Neural Network Allocation)을 예시하고 있다. 도 1 및 도 17을 참조하면, 먼저, VPC에서는, 3D 렌더링 대상인 이미지를 여러 개의 타일로 쪼갠 후, 타일 마다 심층신경망 추론을 수행하여 RGB를 얻어낸다. 이 때, 타일별 연산을 수행하는 본 발명의 특징으로 인해, 타일별 RGB 값이 유사하며 중간 심층신경망 추론 부산물들의 분포 및 패턴 역시 비슷한 특징이 있다. 한편, HNE에서는 타일단위의 이미지들을 가속할 때 타일 내에서 같은 출력제로패턴(ReLU 활성화 함수로 인 해 생기는 '0'의 패턴)을 공유하는 특징이 있다. 따라서 동적신경망할당코어(DNNA-C)는 이러한 특징들을 이용하여 매 타일마다 발견되는 출력제로패턴을 도 출한 후, 그 출력제로패턴에 따라 1D NE와 2D NE에 할당할 태스크를 결정할 수 있다. 이를 위한, 동적신경망할당코어(DNNA-C)의 구성 예가 도 18에 예시되어 있다. 도 18은 본 발명의 일 실시 예에 따른 동적신경망할당(DNNA) 코어에 대한 개략적인 블록도로서, 도 18을 참조하 면, 본 발명의 일 실시 예에 따른 동적신경망할당(DNNA) 코어는 출력제로패턴 추출부, 비트마스크 생 성부, 선택정보 생성부, 태스크 할당결과 저장부, 오프로딩처리부, 및 클럭제어부를포함한다. 출력제로패턴 추출부는 VPC에서 출력되는 상기 타일단위이미지마다 상기 DNN 추론 대상 픽셀(즉, 이 전프레임의 RGB 값을 재사용하지 않는 픽셀)들 중 일부를 희소성 기준 픽셀로 결정하고, 상기 희소성 기준 픽셀 들 각각의 출력제로패턴(즉, 희소성)을 추출한다. 한편, 작업 할당은 해당 가중치를 로드하고 IA를 재정렬하는 데 많은 대기 시간이 필요하기 때문에 비실용적이 다. 따라서 본 발명은 가중치 가져오기의 대기 시간을 숨기고 데이터 재정렬 비용을 최소화하기 위해 가능한 한 빨리 적절한 작업 할당 방법을 판단해야 한다. 따라서, 출력제로패턴 추출부는, 이러한 출력제로패턴을 사 전에 최대한 빨리 파악하기 위해, 원심 샘플링 방식(Centrifugal Sampling, CS)을 사용하여 상기 희소성 기준 픽셀을 결정하고, 상기 희소성 기준 픽셀들 각각의 출력제로패턴(즉, 희소성)을 추출한다. 이는 타일마다 일부 픽셀에 대한 신경망 추론을 수행하고, 해당 픽셀에서 나타나는 희소성 패턴을 다른 패턴에도 똑같이 적용함으로 써, 출력 예측을 빠르게 할 수 있도록 하기 위함이다. 즉, 이로 인해, 3D 렌더링 가속기의 연산량을 줄이고 결 과적으로 3D 렌더링 속도를 빠르게 할 수 있다. 도 19는 이러한 원심 샘플링 방식(CS)을 설명하기 위한 도면으로써, 도 19를 참조하면, 출력제로패턴 추출부 는 8x8 타일을 먼저 4x4 타일 네 개로 쪼갠 후, 도 19에 예시된 바와 같이, 각각의 타일마다 미리 정해둔 지그재그(Zigzag) 패턴 순서(즉, 중앙에서 주변방향으로 결정된 지그재그 순서)에 입각해 중앙에서 가장 먼 픽 셀을 선택한다. 이는, 관계가 낮은 4개의 픽셀을 선택하여 예측 정확도를 높이기 위함이다. 이 때, 가장 먼 픽셀을 선택하는 과정은, 도 19에 예시된 바와 같이, AND 게이트와 Not 게이트로만 구성된 빈 픽셀 검색 회로(Empty Pixel Search Circuit)에 의해 수행될 수 있다. 한편, HNE는 이와 같이 선택된 재사용 불가한 4개의 픽셀들 각각에 대해, 8개 샘플의 추론을 수행한 후, NZ(NonZero) 출력을 나타내는 CS-Bmap(일명, 출력제로패턴)을 생성하여, 동적신경망할당코어(DNNA-C)로 전 송한다. 비트마스크 생성부는 상기 CS-Bmap(즉, 출력제로패턴)을 비트와이즈(Bitwise) OR 연산으로 취합하여 희소 성 비율을 나타내는 비트마스크(bitmask)를 생성한다. 이로 인해, 비트마스크 생성부는 제로패턴의 최악의 경우를 판단할 수 있다. 이는 정확도를 향상시키기 위함이다. 선택정보 생성부는 상기 비트마스크가 가지는 0의 개수에 따라 상기 복수의 뉴럴엔진들 중 하나로 태스크 를 할당하기 위한 선택정보를 생성한다. 도 20은 비트마스크 생성부 및 선택정보 생성부에 의한 동적할당과정을 설명하기 위한 도면으로서, 출력제로패턴 추출부에서 선택된 픽셀들에 대한 심층신경망 추론결과가 입력된 이후의 동적할당과정을 예 시하고 있다. 도 18 내지 도 20을 참조하면, 먼저, 비트마스크 생성부는 각각의 픽셀 마다 나온 출력 제로 패턴을 Bitwise OR 연산으로 취합한다. 이 때, 비트마스크 생성부가 Bitwise OR 연산을 수행하는 이유는 픽셀 마 다 발생한 다양한 출력 제로 패턴 중 네 픽셀 모두가 '0' 값을 가질 때만 해당 0 패턴을 다른 잉여 픽셀들에 공 유하기 위함이다. 한편, 상기 Bitwise OR 연산 이후, 그 결과로 생성된 Bit-mask는 동적신경망할당코어(DNNA-C)의 선택정보 생성부로 전달되고, 선택정보 생성부는 상기 bit-mask 가 가지는 0의 개수에 따라, 0이 많다면 1D NE 로, 0이 적다면 2D NE로 해당 채널 (channel)을 할당한다. 여기서 채널 할당은 외부 메모리(Global Memory)에 저장되어 있는 가중치 중 해당 채널에 대한 가중치만 정해진 NE로 전달하는 과정을 의미한다. 이후 1D NE와 2D NE는 출력 제로 패턴이 CS Bit-mask와 같다고 가정하고 나머지 픽셀에 대한 연산을 이어서 수행하며, 할당된 채널에 대한 것만 연산한다. 1D NE는 희소성이 미리 정해진 임계값보다 높은 채 널을 수신하고 나머지 채널은 2D NE에 할당한다. 온-칩(on-chip) 가중치 메모리의 이중 버퍼링 덕분에 이 가중치 프리페치 프로세스는 기본 DNN 계산으로 파이프라인을 구현하여 완전히 숨길 수 있다. 태스크 할당결과 저장부는 의한 태스크 할당정보를 저장한다. 즉, 태스크 할당결과 저장부는 선택정 보 생성부에서 생성된 선택정보에 의한 태스크 할당결과를 저장한다. 오프로딩처리부는 상기 선택정보에 의한 상기 복수의 뉴럴엔진들 각각의 태스크 할당정보를 모니터링하고 상기 복수의 뉴럴엔진들 각각의 연산수행시간 점유율 특성에 의해 태스크 오프로딩을 실시하되, 상기 복수의 뉴 럴엔진들 중 연산수행시간 점유율이 일정한 하나의 뉴럴엔진의 활용도를 향상시키는 방향으로 오프로딩을 수행한다. 이로 인해, HNE의 효율성을 높일 수 있다. 즉, 희소성 비율을 통한 작업 할당은 작업을 NE로 성공적 으로 분할하지만 낮은 코어 사용률 문제로 인해 HNE의 성능이 저하될 수 있는 문제를 이와 같은 오프로딩 에 의해 해결할 수 있는 것이다. 도 21은 이러한 오프로딩처리부의 CS 기반 태스크 오프로딩을 설명하기 위한 도면으로서, 도 21의 좌측 도 면은, 2D NE의 채널이 1개 비었을 경우 1D NE에 할당된 채널 한 개를 2D NE에 넘겨 연산 시간을 최적화 할 수 있는 예를 도시하고, 도 21의 우측 도면은. 2D NE 채널이 1개 밖에 할당이 안 되어 있을 경우, 2D NE에 할당되 었던 해당 채널을 1D NE에 넘겨 2D NE에 해당연산을 수행할 필요 없게 만든 예를 도시한다. 즉, 1D NE는 입력 데이터에 '0'이 있을 때 연산을 건너뛰기 때문에, 희소성과 할당된 채널의 수에 따라 연산 수 행 시간이 크게 바뀌고, 2D NE는 할당된 채널이 적으나 많으나 같은 연산 시간을 필요로 하므로, 2D NE에 할당 된 채널을 최대한 꽉 채워야 연산 시간을 최적화 할 수 있는 특징이 있는데, 도 21은 이러한 특성에 의해, 2D NE의 Under-utilization을 막는 방향으로 1D에서 2D 혹은 2D에서 1D 방향으로 태스크 오프로딩을 수행한 예를 도시하고 있다. 이와 같이, 오프로딩처리부가 2D NE의 미사용을 미리 감지한 다음 1D-to-2D 또는 2D-to-1D 작업 오프로딩 을 수행하고, 2D NE를 전체 코어 사용 상태로 유지함으로써, 본 발명은 최종적으로 평균 14.5%의 처리량 향상 효과를 보인다. 클럭제어부는 비트마스크 생성부에서 생성된 비트마스크에 의거하여 상기 복수의 뉴럴엔진들 각각의 클럭을 제어한다. 이는, CS 기반의 심층신경망 추론 결과, 출력의 제로 패턴을 미리 알 수 있는 특징을 이용한 것으로서, 클럭제어부는 비트마스크로부터 나머지 샘플들, 혹은 픽셀들에서 쓸모없는 계산이 무엇인지를 미리 판단하고, 그 결과에 의해, 클록게이팅(Clock-Gating, CG)을 함으로써, 동적 전력 소비를 줄일 수 있다. 도 22는 이러한 클럭제어부를 설명하기 위한 도면으로서, 도 22를 참조하여 클럭제어부를 설명하면 다음과 같다. 먼저, 클럭제어부는 1D NE 및 2D NE 모두에 배치되며 비트 마스크를 입력 신호로 수신한다. 한편, 비트 로 테이터는 메인 PE 어레이에서 파이프라인 구조의 전력 소비를 관리하기 위해 CG 제어 신호를 만든다. CS 기반 CG는 최종적으로 HNE의 동적 전력 소비를 최대 24.6%까지 줄일 수 있다. 한편, 오프로딩처리부 및 클럭제어부는 HNE의 성능 향상을 위해, HNE 내부 또는, 복수의 NE들 각각에 설치될 수 있다. 이와 같이, HNE는 두 개의 이기종 NE를 활용할 뿐만 아니라 CS-DNNA 코어를 통한 동적 관리 방법을 통해 그 성능을 최적화할 수 있다. 즉, 본 발명의 HNE는 희소성 이용 없이 가속보다 3.7배 더 높은 처리량을 달 성할 수 있으며, 1D NE 또는 2D NE 중 하나만 사용하는 기존 NE보다 최소 2.4배 높은 에너지 효율을 달성할 수 있다. 도 23 내지 도 29는 본 발명의 일 실시 예에 따른 인공지능 기반 고속 저전력 3D 렌더링 가속방법에 대한 처리 흐름도들이고, 도 30 내지 도 32는 본 발명의 일 실시 예에 따른 인공지능 기반 고속 저전력 3D 렌더링 가속방 법을 설명하기 위한 도면들이다. 도 1 내지 도 29를 참조하여, 본 발명의 일 실시 예에 따른 3D 렌더링 가속방법을 설명하면 다음과 같다. 먼저, 단계 S100에서는, 본 발명의 3D 렌더링 가속기가 2D 사진을 학습한다. 즉, 단계 S100에서, 본 발명 의 3D 렌더링 가속기는 동일한 물체를 여러 방향에서 촬영한 다수의 2D 사진을 사용하여 DNN의 가중치를 학습한다. 단계 S200에서는, VPC가 시각인지(Visual Perception, VP)를 수행한다. 즉, 단계 S200에서, VPC는 관찰자의 위치 및 방향에서 3D 렌더링 대상인 물체에 대한 이미지 평면을 생성하고 상기 이미지 평면을 다수의 타일 단위로 분할한 후, 분할된 타일단위이미지들을 뇌모방 시각인지하여 3D 렌더링을 위해 필요한 DNN 추론범 위를 축소 결정한다. 이를 위해, VPC는, 도 24에 예시된 바와 같이, 공간적 주의 단계(S210), 시간적친숙도 단계(S220), 및 하 향식 주의 단계(S230)를 수행한다.먼저, 단계 S210에서는, SAU가 복셀 없이 학습된 심층신경망을 통해 미리 저해상도 복셀을 정의하고, 심층 신경망 기반 3D 렌더링 연산 중 샘플링 과정에서 복셀 안에 있는 점들만 샘플링해 필요한 샘플의 개수를 최소화 한다(공간적주의). 이를 위해, SAU는, 도 25에 예시된 바와 같이, 단계 S211에서 외부 메모리로부터 수집된 복셀(voxel)에 대 한 정보를 캐시메모리에 저장하고(복셀캐싱), 단계 S212에서 샘플좌표를 생성하되, 상기 관찰자의 시선방향으로 광선을 발사하여 상기 광선상의 좌표들 중 상기 DNN 추론 대상 픽셀에 대응한 복셀 내부의 좌표만을 샘플좌표로 생성하고(샘플좌표생성), 단계 S213에서 상기 타일단위이미지를 밀집타일 또는 희소타일로 본류한 후 상기 분류 결과에 의해 HNE와의 입/출력을 제어한다(태스크 컨트롤). 도 30은 이러한 공간적 주의 단계(S210)를 도식화하여 설명한 것으로서, BuFF(Bundle-Frame-Familiarity) 아키 텍처의 SA 과정을 예시하고 있다. 도 30을 참조하면, 본 발명의 공간적 주의(SA) 단계(즉, 단계 S210)는 주의 맵을 활용하여 광선당 샘플 수를 줄인다. 즉, 단계 S210는, 저해상도 복셀을 사용하여 어텐션 맵 내부의 의미 있는 샘플만 수집함으로써, 필요한 샘플의 개수를 최소화시키는 예를 도시하고 있다. 이 때, 상기 복셀은 고밀 도 샘플을 포함하는 하위 공간을 표시하여 사전 훈련 단계에서 얻을 수 있다. 또한, 단계 S220에서는, TFU가 관찰자의 위치 변화시 이전프레임과 현재프레임의 친숙도 평가에 의해 재사 용 가능한 이전프레임의 픽셀값인 재사용 픽셀값을 결정하고, 상기 재사용 픽셀값을 반영하여 현재프레임의 픽 셀들 중 DNN 추론이 필요한 DNN 추론 대상 픽셀을 결정한다(시간적 친숙도). 특히, TFU는 이전 프레임의 심층신경망 중간 연산 결과를 메모리에 저장한 후, 이를 Partial-sum 으로 활용해, 부분추론만을 수행함으로써, 연산량을 최소화한다. 이를 위해, TFU는, 도 26에 예시된 바와 같이, 단계 S221에서 상기 타일단위이미지를 3D 변환한 후, 상기 관찰자의 위치 및 방향의 변화값을 기준으로, 이전프레임의 픽셀별 RGB 값을 회전 및 평행 이동시켜 대응된 현 재프레임의 픽셀에 투영하고(3D 변환), 단계 S222에서 이전프레임 및 대응된 현재프레임의 픽셀단위로 색상변화 값을 예측하고, 상기 예측된 색상변화값이 미리 설정된 허용변화값 미만인 픽셀의 RGB값만을 재사용하도록 결정 한다(재사용 처리). 이 때, 단계 S221에서, 3D 변환기는 상대적 주소 기반 버퍼링 기법을 활용하여 상기 이전프레임의 픽셀별 RGB값을 회전 및 평행 이동시키고, 단계 S222에서는, 재사용 처리부가 하나의 현재프레임 픽셀에 다수의 이 전프레임 픽셀이 매칭되는 겹침현상이 발생한 경우, 겹침이 발생한 이전프레임 픽셀들 중 가장 앞에 위치하는 픽셀의 RGB값을 선택하여 타일내 겹침을 해소하고, DNN 추론에 의해 타일간 겹침을 해소하는 과정을 더 수행한 다. 도 31은 시간적 친숙도 단계(S220)를 도식화하여 설명한 것으로서, BuFF(Bundle-Frame-Familiarity) 아키텍처 의 TF 과정을 예시하고 있다. 도 31을 참조하면, 본 발명의 시간적 친숙도(TF) 단계(즉, 단계 S2250)는 이전 프 레임에서 얻어낸 RGB-D (빨강, 초록, 파랑, 깊이) 정보를 현재 프레임에서도 재사용하여 새롭게 렌더링이 필요 한 픽셀의 개수를 줄이는 역할을 수행한다. 단, 3D 변환을 통해 재사용할 수 있는 픽셀의 개수는 매우 많을 수 있지만, 이를 그대로 활용할 경우 9.7dB 만큼의 PSNR 손실이 나타나며, 렌더링 퀄리티에 크게 손상을 준다. 이 를 방지하기 위해, 본 발명은 TF Evaluation을 도입하였으며, 이는 심층신경망의 부분 연산만을 수행해, 재사용 하고자 하는 픽셀의 RGB 변화가 클지 작을지 미리 예상하고, 만약 RGB 변화가 크다고 예상하면, 재사용하지 않 고 새롭게 RGB 값을 찾도록 유도한다. 단계 S230에서는, TDA 로직이, 상기 DNN 추론 결과에 의거하여, 추론의 지속 여부 및 추가 샘플링 필요성 여부를 판단한다(하향식 주의). 이를 위해, TDA 로직은, 도 27에 예시된 바와 같이, 단계 S231, 및 단계 S232에서, HNE로부터 전달된 3D 렌더링 과정 전체의 누적밀도값과 미리 설정된 상향임계값을 비교하여, 상기 누적밀도값이 미리 설정된 상향 임계값을 초과하는 경우 상기 샘플좌표생성부의 샘플좌표 생성동작에 대한 중단을 결정한다. 한편, 단계 S233 및 단계 S234에서는, TDA 로직이, HNE로부터 전달된 임의의 제1 레이어에 대한 중간연산결과에 포함된 중간밀도값과 미리 설정된 하향임계값을 비교하여, 상기 중간밀도값이 상기 하향임계값 미만인 경우 상기 제1 레이어의 잔여 DNN 추론 단계의 스킵을 결정한다. 도 32는 본 발명의 일 실시 예에 따른 하향식 주의(TDA) 단계를 설명하기 위한 도면으로서, BuFF(Bundle-Frame- Familiarity) 아키텍처의 TF 과정을 예시하고 있다. 도 32를 참조하면, 본 발명의 하향식 주의(TDA) 단계(즉, 단계 S230)는 두 가지 피드백이 함께 적용된다. 첫 번째 피드백은 단기(short-term) 피드백으로 심층신경망의중간 연산 결과물인 밀도 (density)가 크면 나머지 레이어 연산을 이어가고, 밀도가 낮으면 나머지 연산은 바로 스킵하는 방식이다. 두 번째 피드백은 장기(long-term) 피드백으로 지금까지 누적된 밀도 값이 충분히 크다면 샘플링 작업을 멈추고, 반대로 누적된 밀도 값이 아직 작다면 샘플링을 계속 이어서 하는 방식이다. 샘플링은 8 개 단위로 추가로 더 할지, 안할지를 결정한다. 이러한 TDA 단계는 최종적으로 추가 PSNR 손실 없이 총 샘플 수 를 95.7%까지 줄일 수 있다. 이와 같이, 단계 S200을 거쳐 연산량이 최소화된 타일단위이미지가 생성되면, 단계 S300에서는, 동적신경망할당 코어(DNNA-C라 칭함)가, 상기 타일단위이미지들 각각의 희소성 비율에 의거하여 상기 타일단위이미지들 각 각의 DNN 추론 방법을 결정한다. 즉, 단계 S300에서, 동적신경망할당코어(DNNA-C)는, 상기 DNN 추론 범위 에 포함된 DNN 추론 연산 태스크들을, 입력 희소성에 따라 연산 효율이 서로 다른 복수의 뉴럴엔진(NE)들에게 분할 할당하여 상기 타일단위이미지들 각각의 DNN 추론 방법을 결정할 수 있다. 이를 위해, 동적신경망할당코어(DNNA-C라 칭함)는, 도 28에 예시된 바와 같이, 출력제로패턴 추출단계 (S310), 비트마스크 생성단계(S320), 선택정보 생성단계(S330), 오프로딩단계(S340), 및 클럭제어단계(S350)를 수행한다. 먼저, 출력제로패턴 추출단계(S310)에서는, 출력제로패턴 추출부가 상기 타일단위이미지 마다, 상기 DNN 추론 대상 픽셀들 중 일부를 희소성 기준 픽셀로 결정하되, 원심 샘플링 방식(CS)으로 상기 희소성 기준 픽셀을 결정하고, 상기 희소성 기준 픽셀들 각각의 출력제로패턴을 추출한다(출력제로패턴추출). 비트마스크 생성단계(S320)에서는, 비트마스크 생성부가 상기 희소성 기준 픽셀들 각각의 출력제로패턴을 비트와이즈(Bitwise) OR 연산으로 취합하여 상기 희소성 비율을 나타내는 비트마스크를 생성한다(비트마스크 생 성). 선택정보 생성단계(S330)에서는, 선택정보 생성부가 상기 복수의 뉴럴엔진들 중 하나로 상기 복수의 뉴럴 엔진들 중 하나로 상기 DNN 추론을 위한 태스크들 각각을 할당하기 위한 선택정보를 생성하되, 상기 비트마스크 가 가지는 0의 개수에 따라 상기 선택정보를 생성한다(선택정보생성). 오프로딩단계(S340)에서는, 상기 선택정보에 의한 상기 복수의 뉴럴엔진들 각각의 태스크 할당정보를 모니터링 하고 상기 복수의 뉴럴엔진들 각각의 연산수행시간 점유율 특성에 의해 태스크 오프로딩을 실시하되, 상기 복수 의 뉴럴엔진들 중 연산수행시간 점유율이 일정한 하나의 뉴럴엔진의 활용도를 향상시키는 방향으로 오프로딩을 수행한다(오프로딩). 클럭제어단계(S350)에서는, 상기 비트마스크에 의거하여 상기 복수의 뉴럴엔진들 각각의 클럭을 제어한다(클럭 제어). 이 때, 상기 오프로딩단계(S340), 및 클럭제어단계(S350)는 HNE에서 수행될 수 있다. 단계 S300에서는, HNE가 상기 단계 S200에서 결정된 DNN 추론 방법에 의해, 상기 DNN 추론범위에 포함된 DNN 추론을 가속한다. 이를 위해, HNE는 도 29에 예시된 바와 같이, 모듈로 기반 위치 인코딩(S410), 및 추론단계(S420)을 수행 한다. 먼저, 단계 S410에서는, PEU(즉, Mod PEU)가 2차 함수와 모듈로 함수로 구성된 근사수식을 이용하여 정현 파를 생성한 후, 상기 정현파를 이용하여 위치 인코딩을 수행한다(모듈로 기반 위치 인코딩). 특히, 단계 S410은, 반정밀도 형식의 샘플좌표를 2로 나눈 나머지값을 산출하고, 그에 대한 2의 보수를 취하여 제1 및 제2 파라미터를 생성한 후, 상기 제1 및 제2 파라미터를 하기의 (수학식 2)에 적용하여 위치 인코딩에 필요한 다수의 사인파 및 코사인파를 생성한다. 수학식 2"}
{"patent_id": "10-2023-0056064", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "단계 S420에서는, 상기 선택정보에 의거하여 상기 태스크들 각각을 추론하되, 입력 데이터에 0이 있을 때 해당 연산을 스킵하는 1D 뉴럴엔진(NE) 및 입력 데이터에 0의 존재 여부와 상관없이 데이터를 재사용하는 2D 뉴럴엔 진(NE) 중 상기 태스크들 각각에 할당된 어느 하나를 이용하여 대응된 태스크들을 DNN 추론한다(추론). 한편, NeRF 알고리즘에서는, 이와 같이, 위치 인코딩(단계 S410), 및 추론(단계 S420)을 수행한 후, 볼륨 렌더 링(Volume Rendering) 과정(미도시)을 더 수행하며, 상기 볼륨 렌더링(Volume Rendering) 과정(미도시)은 공지 의 기술을 이용할 수 있다. 도 23 내지 도 32를 참조한 본 발명의 3D 렌더링 방법 설명에 있어서, 도 1 내지 도 22를 참조한 3D 렌더링 가 속기 설명시 설명된 내용에 대하여는 중복 설명을 생략하였다. 상기한 바와 같이, 본 발명은 3D 공간을 저해상도 복셀(voxel)로 미리 표현하고, 샘플링 수행시 복셀 내부에 위 치한 샘플만 취함으로써 필요한 샘플의 개수를 최소화시킬 수 있고, 이로 인해, 외부 메모리 접근량을 최소화함 과 동시에 연산량을 크게 줄여 렌더링 속도를 향상시킬 수 있는 특징이 있다. 또한 본 발명은, 데이터 희소성을 활용하는 1D NE(Neural Engine)와, 데이터 재사용성을 극대화한 2D NE를 함께 채택하고 연산 대상 이미지의 희소성 비율에 의해 둘 중 하나를 선택 적용함으로써 연산 효율성을 향상시키고, 이로 인해, 렌더링 속도를 향상시킬 수 있는 특징이 있다. 또한, 본 발명은, 관찰자의 위치 변화시, 이전프레임과 현재프레임의 유사도에 의해 이전프레임의 픽셀값을 재 사용함으로써, 렌더링에 필요한 픽셀 개수를 효과적으로 줄일 수 있고, 이로 인해, 심층신경망 연산량을 줄여 렌더링 속도를 향상시킬 수 있는 특징이 있다. 또한, 본 발명은, 심층신경망 기반 3D 렌더링 연산에서 반드시 필요한 위치 인코딩(positional encoding) 동안 2차함수와 모듈로함수로 구성된 다항식으로 정현파 함수를 근사하여 대체함으로써 회로 복잡도를 최소화할 수 있으며, 한 주기 내에서 여러 위치 인코딩 결과를 생성함으로써 전력 및 면적 소모를 줄일 수 있고, 결과적으로 심층신경망 기반 3D 렌더링을 가속화할 수 있는 특징이 있다. 한편, 본 발명은, Power-efficient 모드, Normal 모드, High-speed 모드 총 3가지 동작 모드를 제공하며, Power-efficient 모드의 경우 30 FPS 이상을 유지하면서 133mW의 전력소모 만을 보이고, High-speed 모드의 경 우 최대 118 FPS까지 렌더링 속도를 높일 수 있다. 결과적으로, 본 발명은 NVIDIA사의 V100 서버보다도 911배 높은 렌더링 속도, 99.95배 낮은 전력 소모를 달성할 수 있다. 이상의 설명에서는 본 발명의 바람직한 실시예를 제시하여 설명하였으나, 본 발명이 반드시 이에 한정되는 것은 아니며, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자라면 본 발명의 기술적 사상을 벗어나지 않는 범위 내에서 여러 가지 치환, 변형 및 변경할 수 있음을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2023-0056064", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 인공지능 기반 고속 저전력 3D 렌더링 가속기에 대한 개략적인 블록도이다. 도 2는 본 발명의 일 실시 예에 따른 시간적 친숙도유닛(TFU)에 대한 개략적인 블록도이다. 도 3은 본 발명의 일 실시 예에 따른 공간적 주의유닛(SAU)에 대한 개략적인 블록도이다. 도 4 내지 도 9는 본 발명의 일 실시 예에 따른 시각인지코어(VPC)의 동작을 설명하기 위한 도면들이다. 도 10은 본 발명의 일 실시 예에 따른 하이브리드 뉴럴엔진(HNE)에 대한 개략적인 블록도이다. 도 11은 본 발명의 일 실시 예에 따른 하이브리드 뉴럴엔진(HNE)의 동작을 설명하기 위한 도면이다. 도 12 내지 도 16은 본 발명의 일 실시 예에 따른 모듈로 기반 위치 인코딩 유닛(Mod PEU)의 구성 및 동작을 설 명하기 위한 도면들이다. 도 17은 본 발명의 일 실시 예에 따른 동적신경망할당(DNNA) 과정에 대한 개념을 설명하기 위한 도면이다. 도 18은 본 발명의 일 실시 예에 따른 동적신경망할당(DNNA) 코어에 대한 개략적인 블록도이다. 도 19 내지 도 22는 본 발명의 일 실시 예에 따른 동적신경망할당(DNNA) 코어의 동작을 설명하기 위한 도면들이 다. 도 23 내지 도 29는 본 발명의 일 실시 예에 따른 인공지능 기반 고속 저전력 3D 렌더링 가속방법을 설명하기 위한 도면들이다. 도 30 내지 도 32는 본 발명의 일 실시 예에 따른 인공지능 기반 고속 저전력 3D 렌더링 가속방법을 설명하기 위한 도면들이다."}
