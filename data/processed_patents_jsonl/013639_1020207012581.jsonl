{"patent_id": "10-2020-7012581", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0128378", "출원번호": "10-2020-7012581", "발명의 명칭": "이미지 생성 네트워크의 훈련 및 이미지 처리 방법, 장치, 전자 기기, 매체", "출원인": "선전 센스타임 테크놀로지 컴퍼니 리미티드", "발명자": "장, 유"}}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이미지 생성 네트워크의 훈련 방법으로서,샘플 이미지를 획득하는 단계 - 상기 샘플 이미지는 제1 샘플 이미지 및 상기 제1 샘플 이미지에 대응하는 제2샘플 이미지를 포함함 - ; 이미지 생성 네트워크에 기반하여 상기 제1 샘플 이미지에 대해 처리를 수행함으로써, 예측된 목표 이미지를 획득하는 단계; 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 차이 손실을 결정하는 단계; 및상기 차이 손실에 기반하여 상기 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하는 단계를 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 차이 손실을 결정하는 단계는, 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 차이 손실을 결정하는단계를 포함하고,상기 차이 손실에 기반하여 상기 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하는 단계는, 상기 차이 손실에 기반하여 상기 이미지 생성 네트워크 및 상기 구조 분석 네트워크에 대해 적대적 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하는 단계를 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 차이 손실은 제1 구조 차이 손실 및 특징 손실을 포함하고, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 차이 손실을 결정하는 단계는, 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지 및 상기 제2 샘플 이미지에 대해 처리를수행함으로써, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하는 단계;및상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 특징 손실을 결정하는 단계를 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지 및 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하는 단계는, 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표이미지에서 적어도 하나의 위치의 적어도 하나의 제1 구조 특징을 결정하는 단계; 상기 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 제2 샘플 이미지공개특허 10-2020-0128378-3-에서 적어도 하나의 위치의 적어도 하나의 제2 구조 특징을 결정하는 단계; 및 상기 적어도 하나의 제1 구조 특징 및 상기 적어도 하나의 제2 구조 특징에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하는 단계를 포함하는 것을 특징으로 하는 이미지생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표이미지에서 적어도 하나의 위치의 적어도 하나의 제1 구조 특징을 결정하는 단계는, 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표 이미지의 적어도 하나의 스케일의 제1 특징맵을 획득하는 단계; 및 각 상기 제1 특징맵에 대해, 상기 제1 특징맵에서 적어도 하나의 위치 중 각 위치의 특징과 상기 위치의 인접영역 특징 사이의 코사인 거리에 기반하여, 상기 예측된 목표 이미지의 적어도 하나의 제1 구조 특징을 획득하는 단계 - 상기 제1 특징맵에서의 각 위치는 하나의 제1 구조 특징에 대응하고, 상기 인접 영역 특징은 상기 위치를 중심으로 하여 적어도 2 개의 위치를 포함하는 영역 내의 각 특징임 - 를 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항 또는 제5항에 있어서, 상기 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 제2 샘플 이미지에서 적어도 하나의 위치의 적어도 하나의 제2 구조 특징을 결정하는 단계는, 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 적어도 하나의 스케일에서의 상기 제2 샘플 이미지의 제2 특징맵을 획득하는 단계; 및 각 상기 제2 특징맵에 대해, 상기 제2 특징맵에서 적어도 하나의 위치 중 각 위치의 특징과 상기 위치의 인접영역 특징 사이의 코사인 거리에 기반하여, 상기 제2 샘플 이미지의 적어도 하나의 제2 구조 특징을 획득하는단계 - 상기 제2 특징맵에서의 각 위치는 하나의 제2 구조 특징에 대응함 - 를 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 제1 특징맵에서의 각 위치와 상기 제2 특징맵에서의 각 위치 사이에는 대응 관계가 존재하고; 상기 적어도 하나의 제1 구조 특징 및 상기 적어도 하나의 제2 구조 특징에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하는 단계는, 대응 관계가 존재하는 위치에 대응하는 상기 제1 구조 특징과 상기 제2 구조 특징 사이의 거리를 계산하는단계; 및 상기 예측된 목표 이미지에 대응하는 모든 상기 제1 구조 특징과 상기 제2 구조 특징 사이의 거리에 기반하여,상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하는 단계를 포함하는 것을특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제3항 내지 제7항 중 어느 한 항에 있어서, 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 특징 손실을 결정하는 단계는, 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지 및 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표 이미지의 적어도 하나의 스케일의 제1 특징맵 및 적어도 하나의 스케일에서의 상기공개특허 10-2020-0128378-4-제2 샘플 이미지의 제2 특징맵을 획득하는 단계; 및 상기 적어도 하나의 제1 특징맵 및 상기 적어도 하나의 제2 특징맵에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 특징 손실을 결정하는 단계를 포함하는 것을 특징으로 하는 이미지 생성 네트워크의훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 제1 특징맵에서의 각 위치와 상기 제2 특징맵에서의 각 위치 사이에는 대응 관계가 존재하고, 상기 적어도 하나의 제1 특징맵 및 상기 적어도 하나의 제2 특징맵에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 특징 손실을 결정하는 단계는, 대응 관계가 존재하는 위치에 대응하는 상기 제1 특징맵에서의 특징과 상기 제2 특징맵에서의 특징 사이의 거리를 계산하는 단계; 및상기 제1 특징맵에서의 특징과 상기 제2 특징맵에서의 특징 사이의 거리에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 특징 손실을 결정하는 단계를 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제3항 내지 제9항 중 어느 한 항에 있어서, 상기 차이 손실은 색상 손실을 더 포함하고, 상기 차이 손실에 기반하여 상기 이미지 생성 네트워크에 대해 훈련을 수행하여, 훈련된 이미지 생성 네트워크를 획득하기 전에, 상기 이미지 생성 네트워크의 훈련 방법은, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 색상 차이에 기반하여, 상기 이미지 생성 네트워크의색상 손실을 결정하는 단계를 더 포함하고, 상기 차이 손실에 기반하여 상기 이미지 생성 네트워크 및 상기 구조 분석 네트워크에 대해 적대적 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하는 단계는, 제1 반복에서, 상기 제1 구조 차이 손실, 상기 특징 손실 및 상기 색상 손실에 기반하여 상기 이미지 생성 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계; 제2 반복에서, 상기 제1 구조 차이 손실에 기반하여 상기 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계 - 상기 제1 반복 및 상기 제2 반복은 연속적으로 수행되는 2 회의 반복임 - ; 및훈련 정지 조건을 만족시킬 때까지 조정을 수행하여, 훈련된 이미지 생성 네트워크를 획득하는 단계를 포함하는것을 특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제10항 중 어느 한 항에 있어서, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 차이 손실을 결정하기 전에, 상기 제2 샘플 이미지에 소음을 추가하여, 소음 이미지를 획득하는 단계; 및 상기 소음 이미지 및 상기 제2 샘플 이미지에 기반하여 제2 구조 차이 손실을 결정하는 단계를 더 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 소음 이미지 및 상기 제2 샘플 이미지에 기반하여 제2 구조 차이 손실을 결정하는 단계는, 구조 분석 네트워크에 기반하여 상기 소음 이미지에 대해 처리를 수행함으로써, 상기 소음 이미지에서 적어도하나의 위치의 적어도 하나의 제3 구조 특징을 결정하는 단계; 공개특허 10-2020-0128378-5-구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 제2 샘플 이미지에서적어도 하나의 위치의 상기 적어도 하나의 제2 구조 특징을 결정하는 단계; 및상기 적어도 하나의 제3 구조 특징 및 상기 적어도 하나의 제2 구조 특징에 기반하여, 상기 소음 이미지와 상기제2 샘플 이미지 사이의 제2 구조 차이 손실을 결정하는 포함하는 것을 특징으로 하는 이미지 생성 네트워크의훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 구조 분석 네트워크에 기반하여 상기 소음 이미지에 대해 처리를 수행함으로써, 상기 소음 이미지에서 적어도 하나의 위치의 적어도 하나의 제3 구조 특징을 결정하는 단계는, 상기 구조 분석 네트워크에 기반하여 상기 소음 이미지에 대해 처리를 수행함으로써, 상기 소음 이미지의 적어도 하나의 스케일의 제3 특징맵을 획득하는 단계; 및 각 상기 제3 특징맵에 대해, 상기 제3 특징맵에서 적어도 하나의 위치 중 각 위치의 특징과 상기 위치의 인접영역 특징 사이의 코사인 거리에 기반하여, 상기 소음 이미지의 적어도 하나의 제3 구조 특징을 획득하는 단계- 상기 제3 특징맵에서의 각 위치는 하나의 제3 구조 특징에 대응하고, 상기 인접 영역 특징은 상기 위치를 중심으로 하여 적어도 2 개의 위치를 포함하는 영역 내의 각 특징임 - 를 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항 또는 제13항에 있어서, 상기 제3 특징맵에서의 각 위치와 상기 제2 특징맵에서의 각 위치 사이에는 대응 관계가 존재하고, 상기 적어도 하나의 제3 구조 특징 및 상기 적어도 하나의 제2 구조 특징에 기반하여, 상기 소음 이미지와 상기제2 샘플 이미지 사이의 제2 구조 차이 손실을 결정하는 단계는, 대응 관계가 존재하는 위치에 대응하는 상기 제3 구조 특징과 상기 제2 구조 특징 사이의 거리를 계산하는단계; 및상기 소음 이미지에 대응하는 모든 상기 제3 구조 특징과 상기 제2 구조 특징 사이의 거리에 기반하여, 상기 소음 이미지와 상기 제2 샘플 이미지 사이의 제2 구조 차이 손실을 결정하는 단계를 포함하는 것을 특징으로 하는이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항 내지 제14항 중 어느 한 항에 있어서, 상기 차이 손실에 기반하여 상기 이미지 생성 네트워크 및 상기 구조 분석 네트워크에 대해 적대적 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하는 단계는, 제3 반복에서, 상기 제1 구조 차이 손실, 상기 특징 손실 및 상기 색상 손실에 기반하여 상기 이미지 생성 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계; 제4 반복에서, 상기 제1 구조 차이 손실 및 상기 제2 구조 차이 손실에 기반하여 상기 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계 - 상기 제3 반복 및 상기 제4 반복은 연속적으로 수행되는 2 회의 반복임 - ; 및훈련 정지 조건을 만족시킬 때까지 조정을 수행하여, 훈련된 이미지 생성 네트워크를 획득하는 단계 를 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제4항 내지 제15항 중 어느 한 항에 있어서, 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표공개특허 10-2020-0128378-6-이미지에서 적어도 하나의 위치의 적어도 하나의 제1 구조 특징을 결정한 후, 이미지 재구성 네트워크에 기반하여 상기 적어도 하나의 제1 구조 특징에 대해 이미지 재구성 처리를 수행함으로써, 제1 재구성 이미지를 획득하는 단계; 및상기 제1 재구성 이미지와 상기 예측된 목표 이미지에 기반하여 제1 재구성 손실을 결정하는 단계를 더 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 제2 샘플 이미지에서 적어도 하나의 위치의 적어도 하나의 제2 구조 특징을 결정한 후, 이미지 재구성 네트워크에 기반하여 상기 적어도 하나의 제2 구조 특징에 대해 이미지 재구성 처리를 수행함으로써, 제2 재구성 이미지를 획득하는 단계; 및상기 제2 재구성 이미지 및 상기 제2 샘플 이미지에 기반하여 제2 재구성 손실을 결정하는 단계를 더 포함하는것을 특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 차이 손실에 기반하여 상기 이미지 생성 네트워크 및 구조 분석 네트워크에 대해 적대적 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하는 단계는, 제5 반복에서, 상기 제1 구조 차이 손실, 상기 특징 손실 및 상기 색상 손실에 기반하여 상기 이미지 생성 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계; 제6 반복에서, 상기 제1 구조 차이 손실, 상기 제2 구조 차이 손실, 상기 제1 재구성 손실 및 상기 제2 재구성손실에 기반하여 상기 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계 - 상기 제5 반복및 상기 제6 반복은 연속적으로 수행되는 2 회의 반복임 - ; 및 훈련 정지 조건을 만족시킬 때까지 조정을 수행하여, 훈련된 이미지 생성 네트워크를 획득하는 단계를 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제1항 내지 제18항 중 어느 한 항에 있어서, 상기 차이 손실에 기반하여 상기 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득한 후,상기 훈련된 이미지 생성 네트워크에 기반하여 처리될 이미지에 대해 처리를 수행함으로써, 목표 이미지를 획득하는 단계를 더 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 처리될 이미지는 좌안 이미지를 포함하고; 상기 목표 이미지는 상기 좌안 이미지에 대응하는 우안 이미지를 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "이미지 처리 방법으로서, 3 차원 이미지 생성 장면에서, 좌안 이미지를 이미지 생성 네트워크에 입력하여, 우안 이미지를 획득하는 단계;및 상기 좌안 이미지 및 상기 우안 이미지에 기반하여 3 차원 이미지를 생성하는 단계 - 상기 이미지 생성 네트워공개특허 10-2020-0128378-7-크는 상기 제1항 내지 제20항 중 어느 한 항에 따른 이미지 생성 네트워크의 훈련 방법으로 훈련하여 획득된 것임 - 를 포함하는 것을 특징으로 하는 이미지 처리 방법."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "이미지 생성 네트워크의 훈련 장치로서, 샘플 이미지를 획득하도록 구성된 샘플 획득 유닛 - 상기 샘플 이미지는 제1 샘플 이미지 및 상기 제1 샘플 이미지에 대응하는 제2 샘플 이미지를 포함함 - ; 이미지 생성 네트워크에 기반하여 상기 제1 샘플 이미지에 대해 처리를 수행함으로써, 예측된 목표 이미지를 획득하도록 구성된 목표 예측 유닛; 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 차이 손실을 결정하도록 구성된 차이 손실 결정 유닛;및상기 차이 손실에 기반하여 상기 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하도록 구성된 네트워크 훈련 유닛을 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서, 상기 차이 손실 결정 유닛은 구체적으로, 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지와 상기 제2샘플 이미지 사이의 차이 손실을 결정하도록 구성되고,상기 네트워크 훈련 유닛은 구체적으로, 상기 차이 손실에 기반하여 상기 이미지 생성 네트워크 및 상기 구조분석 네트워크에 대해 적대적 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하도록 구성된 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 상기 차이 손실은 제1 구조 차이 손실 및 특징 손실을 포함하고, 상기 차이 손실 결정 유닛은, 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지 및 상기 제2 샘플 이미지에 대해 처리를수행함으로써, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하도록 구성된 제1 구조 차이 결정 모듈; 및상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 특징 손실을 결정하도록 구성된 특징 손실 결정 모듈을 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제24항에 있어서, 상기 제1 구조 차이 결정 모듈은, 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지에 대해 처리를수행함으로써, 상기 예측된 목표 이미지에서 적어도 하나의 위치의 적어도 하나의 제1 구조 특징을 결정하고;상기 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 제2 샘플 이미지에서 적어도 하나의 위치의 적어도 하나의 제2 구조 특징을 결정하며; 상기 적어도 하나의 제1 구조 특징 및 상기 적어도 하나의 제2 구조 특징에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하도록 구성된 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제25항에 있어서, 상기 제1 구조 차이 결정 모듈은 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지에 대해 처리를공개특허 10-2020-0128378-8-수행함으로써, 상기 예측된 목표 이미지에서 적어도 하나의 위치의 적어도 하나의 제1 구조 특징을 결정할 때,구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표 이미지의 적어도 하나의 스케일의 제1 특징맵을 획득하고; 각 상기 제1 특징맵에 대해, 상기 제1 특징맵에서 적어도하나의 위치 중 각 위치의 특징과 상기 위치의 인접 영역 특징 사이의 코사인 거리에 기반하여, 상기 예측된 목표 이미지의 적어도 하나의 제1 구조 특징을 획득하도록 구성되며, 상기 제1 특징맵에서의 각 위치는 하나의 제1 구조 특징에 대응하고, 상기 인접 영역 특징은 상기 위치를 중심으로 하여 적어도 2 개의 위치를 포함하는 영역 내의 각 특징인 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제25항 또는 제26항에 있어서, 상기 제1 구조 차이 결정 모듈은 상기 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 제2 샘플 이미지에서 적어도 하나의 위치의 적어도 하나의 제2 구조 특징을 결정할 때, 구조분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 적어도 하나의 스케일에서의 상기 제2 샘플 이미지의 제2 특징맵을 획득하고; 각 상기 제2 특징맵에 대해, 상기 제2 특징맵에서 적어도 하나의위치 중 각 위치의 특징과 상기 위치의 인접 영역 특징 사이의 코사인 거리에 기반하여, 상기 제2 샘플 이미지의 적어도 하나의 제2 구조 특징을 획득하도록 구성되며, 상기 제2 특징맵에서의 각 위치는 하나의 제2 구조 특징에 대응하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제27항에 있어서, 상기 제1 특징맵에서의 각 위치와 상기 제2 특징맵에서의 각 위치 사이에는 대응 관계가 존재하고, 상기 제1 구조 차이 결정 모듈은 상기 적어도 하나의 제1 구조 특징 및 상기 적어도 하나의 제2 구조 특징에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정할 때, 대응 관계가 존재하는 위치에 대응하는 상기 제1 구조 특징과 상기 제2 구조 특징 사이의 거리를 계산하고; 상기 예측된목표 이미지에 대응하는 모든 상기 제1 구조 특징과 상기 제2 구조 특징 사이의 거리에 기반하여, 상기 예측된목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하도록 구성된 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제24항 내지 제28항 중 어느 한 항에 있어서, 상기 특징 손실 결정 모듈은, 구체적으로 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지 및 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표 이미지의 적어도 하나의 스케일의 제1 특징맵 및 적어도 하나의 스케일에서의 상기 제2 샘플 이미지의 제2 특징맵을 획득하고; 상기 적어도 하나의 제1 특징맵 및 상기 적어도 하나의 제2 특징맵에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의특징 손실을 결정하도록 구성된 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제29항에 있어서, 상기 제1 특징맵에서의 각 위치와 상기 제2 특징맵에서의 각 위치 사이에는 대응 관계가 존재하고, 상기 특징 손실 결정 모듈은 상기 적어도 하나의 제1 특징맵 및 상기 적어도 하나의 제2 특징맵에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 특징 손실을 결정할 때, 대응 관계가 존재하는 위치에대응하는 상기 제1 특징맵에서의 특징과 상기 제2 특징맵에서의 특징 사이의 거리를 계산하고; 상기 제1 특징맵에서의 특징과 상기 제2 특징맵에서의 특징 사이의 거리에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플이미지 사이의 특징 손실을 결정하도록 구성된 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제24항 내지 제30항 중 어느 한 항에 있어서, 공개특허 10-2020-0128378-9-상기 차이 손실은 색상 손실을 더 포함하고; 상기 차이 손실 결정 유닛은, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 색상 차이에 기반하여, 상기 이미지 생성 네트워크의색상 손실을 결정하도록 구성된 색상 손실 결정 모듈을 더 포함하고, 상기 네트워크 훈련 유닛은 구체적으로, 제1 반복에서, 상기 제1 구조 차이 손실, 상기 특징 손실 및 상기 색상손실에 기반하여 상기 이미지 생성 네트워크의 네트워크 파라미터에 대해 조정을 수행하고; 제2 반복에서, 상기제1 구조 차이 손실에 기반하여 상기 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행하며; 훈련정지 조건을 만족시킬 때까지 조정을 수행하여, 훈련된 이미지 생성 네트워크를 획득하도록 구성되며, 상기 제1반복 및 상기 제2 반복은 연속적으로 수행되는 2 회의 반복인 것을 특징으로 하는 이미지 생성 네트워크의 훈련장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제22항 내지 제31항 중 어느 한 항에 있어서, 상기 장치는, 상기 제2 샘플 이미지에 소음을 추가하여, 소음 이미지를 획득하도록 구성된 소음 추가 유닛; 및상기 소음 이미지 및 상기 제2 샘플 이미지에 기반하여 제2 구조 차이 손실을 결정하도록 구성된 제2 구조 차이손실 유닛을 더 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "제32항에 있어서,상기 제2 구조 차이 손실 유닛은 구체적으로, 구조 분석 네트워크에 기반하여 상기 소음 이미지에 대해 처리를수행함으로써, 상기 소음 이미지에서 적어도 하나의 위치의 적어도 하나의 제3 구조 특징을 결정하고; 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 제2 샘플 이미지에서 적어도하나의 위치의 상기 적어도 하나의 제2 구조 특징을 결정하며; 상기 적어도 하나의 제3 구조 특징 및 상기 적어도 하나의 제2 구조 특징에 기반하여, 상기 소음 이미지와 상기 제2 샘플 이미지 사이의 제2 구조 차이 손실을결정하도록 구성된 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제33항에 있어서,상기 제2 구조 차이 손실 유닛은 구조 분석 네트워크에 기반하여 상기 소음 이미지에 대해 처리를수행함으로써, 상기 소음 이미지에서 적어도 하나의 위치의 적어도 하나의 제3 구조 특징을 결정할 때, 상기 구조 분석 네트워크에 기반하여 상기 소음 이미지에 대해 처리를 수행함으로써, 상기 소음 이미지의 적어도 하나의 스케일의 제3 특징맵을 획득하고; 각 상기 제3 특징맵에 대해, 상기 제3 특징맵에서 적어도 하나의 위치 중각 위치의 특징과 상기 위치의 인접 영역 특징 사이의 코사인 거리에 기반하여, 상기 소음 이미지의 적어도 하나의 제3 구조 특징을 획득하도록 구성 - 상기 제3 특징맵에서의 각 위치는 하나의 제3 구조 특징에 대응하고,상기 인접 영역 특징은 상기 위치를 중심으로 하여 적어도 2 개의 위치를 포함하는 영역 내의 각 특징임 - 된것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "제33항 또는 제34항에 있어서,상기 제3 특징맵에서의 각 위치와 상기 제2 특징맵에서의 각 위치 사이에는 대응 관계가 존재하고,상기 제2 구조 차이 손실 유닛은 상기 적어도 하나의 제3 구조 특징 및 상기 적어도 하나의 제2 구조 특징에 기반하여, 상기 소음 이미지와 상기 제2 샘플 이미지 사이의 제2 구조 차이 손실을 결정할 때, 대응 관계가 존재하는 위치에 대응하는 상기 제3 구조 특징과 상기 제2 구조 특징 사이의 거리를 계산하고; 상기 소음 이미지에대응하는 모든 상기 제3 구조 특징과 상기 제2 구조 특징 사이의 거리에 기반하여, 상기 소음 이미지와 상기 제2 샘플 이미지 사이의 제2 구조 차이 손실을 결정하도록 구성된 것을 특징으로 하는 이미지 생성 네트워크의 훈공개특허 10-2020-0128378-10-련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "제32항 내지 제35항 중 어느 한 항에 있어서,상기 네트워크 훈련 유닛은 구체적으로, 제3 반복에서, 상기 제1 구조 차이 손실, 상기 특징 손실 및 상기 색상손실에 기반하여 상기 이미지 생성 네트워크의 네트워크 파라미터에 대해 조정을 수행하고; 제4 반복에서, 상기제1 구조 차이 손실 및 상기 제2 구조 차이 손실에 기반하여 상기 구조 분석 네트워크의 네트워크 파라미터에대해 조정을 수행하며; 훈련 정지 조건을 만족시킬 때까지 조정을 수행하여, 훈련된 이미지 생성 네트워크를 획득하도록 구성되며, 상기 제3 반복 및 상기 제4 반복은 연속적으로 수행되는 2 회의 반복인 것을 특징으로 하는이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_37", "content": "제25항 내지 제36항 중 어느 한 항에 있어서,상기 제1 구조 차이 결정 모듈은 또한, 이미지 재구성 네트워크에 기반하여 상기 적어도 하나의 제1 구조 특징에 대해 이미지 재구성 처리를 수행함으로써, 제1 재구성 이미지를 획득하고; 상기 제1 재구성 이미지와 상기예측된 목표 이미지에 기반하여 제1 재구성 손실을 결정하도록 구성된 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_38", "content": "제37항에 있어서, 상기 제1 구조 차이 결정 모듈은, 이미지 재구성 네트워크에 기반하여 상기 적어도 하나의 제2 구조 특징에 대해 이미지 재구성 처리를 수행함으로써, 제2 재구성 이미지를 획득하고; 상기 제2 재구성 이미지 및 상기 제2샘플 이미지에 기반하여 제2 재구성 손실을 결정하도록 구성된 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_39", "content": "제38항에 있어서, 상기 네트워크 훈련 유닛은 구체적으로, 제5 반복에서, 상기 제1 구조 차이 손실, 상기 특징 손실 및 상기 색상손실에 기반하여 상기 이미지 생성 네트워크의 네트워크 파라미터에 대해 조정을 수행하고; 제6 반복에서, 상기제1 구조 차이 손실, 상기 제2 구조 차이 손실, 상기 제1 재구성 손실 및 상기 제2 재구성 손실에 기반하여 상기 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행하며; 훈련 정지 조건을 만족시킬 때까지 조정을 수행하여, 훈련된 이미지 생성 네트워크를 획득하도록 구성되며, 상기 제5 반복 및 상기 제6 반복은 연속적으로 수행되는 2 회의 반복인 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_40", "content": "제22항 내지 제39항 중 어느 한 항에 있어서, 상기 장치는, 상기 훈련된 이미지 생성 네트워크에 기반하여 처리될 이미지에 대해 처리를 수행함으로써, 목표 이미지를 획득하도록 구성된 이미지 처리 유닛을 더 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_41", "content": "제40항에 있어서, 상기 처리될 이미지는 좌안 이미지를 포함하고; 상기 목표 이미지는 상기 좌안 이미지에 대응하는 우안 이미지를 포함하는 것을 특징으로 하는 이미지 생성 네트워크의 훈련 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_42", "content": "이미지 처리 장치로서,공개특허 10-2020-0128378-11-3 차원 이미지 생성 장면에서, 좌안 이미지를 이미지 생성 네트워크에 입력하여, 우안 이미지를 획득하도록 구성된 우안 이미지 획득 유닛; 및 상기 좌안 이미지 및 상기 우안 이미지에 기반하여 3 차원 이미지를 생성하도록 구성된 3 차원 이미지 생성 유닛 - 상기 이미지 생성 네트워크는 상기 제1항 내지 제20항 중 어느 한 항에 따른 이미지 생성 네트워크의 훈련방법으로 훈련하여 획득된 것임 - 을 포함하는 것을 특징으로 하는 이미지 처리 장치."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_43", "content": "전자 기기로서, 프로세서를 포함하고, 상기 프로세서는 제22항 내지 제41항 중 어느 한 항에 따른 이미지 생성 네트워크의 훈련장치 또는 제42항에 따른 이미지 처리 장치를 포함하는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_44", "content": "전자 기기로서, 프로세서; 및프로세서에서 실행 가능한 명령어를 포함하기 위한 메모리를 포함하고; 상기 프로세서는, 상기 실행 가능한 명령어가 실행될 때, 제1항 내지 제20항 중 어느 한 항에 따른 이미지 생성네트워크의 훈련 방법, 및 제21항에 따른 상기 이미지 처리 방법 중 적어도 하나를 구현하는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_45", "content": "컴퓨터 판독 가능한 명령어가 저장되어 있는 컴퓨터 저장 매체로서, 상기 명령어가 실행될 때, 제1항 내지 제20항 중 어느 한 항에 따른 이미지 생성 네트워크의 훈련 방법의 단계,및 제21항에 따른 이미지 처리 방법의 단계 중 적어도 하나를 실행하는 것을 특징으로 하는 컴퓨터 저장 매체."}
{"patent_id": "10-2020-7012581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_46", "content": "컴퓨터 판독 가능한 코드를 포함하는 컴퓨터 프로그램 제품으로서, 상기 컴퓨터 판독 가능한 코드가 기기에서 작동될 때, 상기 기기의 프로세서는 제1항 내지 제20항 중 어느 한항에 따른 이미지 생성 네트워크의 훈련 방법을 구현하기 위한 명령어, 및 제21항에 따른 이미지 처리 방법을구현하기 위한 명령어 중 적어도 하나를 실행하는 것을 특징으로 하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2020-7012581", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원의 실시예는 이미지 생성 네트워크의 훈련 및 이미지 처리 방법 및 장치, 전자 기기, 저장 매체를 개시하 였고, 여기서, 이미지 생성 네트워크의 훈련방법은, 샘플 이미지를 획득하는 단계 - 샘플 이미지는 제1 샘플 이 미지 및 제1 샘플 이미지에 대응하는 제2 샘플 이미지를 포함함 - ; 이미지 생성 네트워크에 기반하여 제1 샘플 이미지에 대해 처리를 수행함으로써, 예측된 목표 이미지를 획득하는 단계; 예측된 목표 이미지와 제2 샘플 이미 지 사이의 차이 손실을 결정하는 단계; 및 차이 손실에 기반하여 이미지 생성 네트워크에 대해 훈련을 수행함으 로써, 훈련된 이미지 생성 네트워크를 획득하는 단계를 포함한다."}
{"patent_id": "10-2020-7012581", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 출원번호가 201910363957.5이고, 출원일이 2019년 04월 30일인 중국 특허출원에 기반하여 제출된 것 이며, 상기 중국 특허출원의 우선권을 주장하며, 상기 중국 특허출원의 전부 내용은 본 출원에 원용되어 참조된 다. 본 출원은 이미지 처리 기술에 관한 것이며, 특히 이미지 생성 네트워크의 훈련 및 이미지 처리 방법 및 장치, 전자 기기, 저장 매체에 관한 것이다."}
{"patent_id": "10-2020-7012581", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "2 차원(2D, 2 Dimensions)에서 3 차원(3D, 3 Dimensions) 스테레오 효과로의 전환은, 입력된 단안 이미지에 따 라, 다른 시점에서 캡처된 장면 컨텐츠를 복원해야 한다. 3D 계층적 룩앤필을 형성하기 위해, 상기 과정은 입력 장면의 깊이 정보를 이해하고, 양안 시차 관계에 기반하여, 입력 좌안의 픽셀을 시차에 따라 전환하여, 우안 컨 텐츠를 생성해야 한다. 종래의 수동 제조 과정은, 일반적으로 깊이 재구축, 계층적 분할, 및 공동 영역 충전 등 프로세스를 포함하므로, 그 과정은 시간이 많이 걸리고 노력이 필요하다. 인공지능 분야가 부상하면서, 학계에 서는 양안 시차에 기반한 이미지 합성 과정을 모델링하고, 대량의 스테레오 이미지 데이터에서 훈련을 수행함으 로써, 정확한 시차 관계를 자동으로 학습하도록, 컨볼루션 신경망을 사용할 것을 제안한다. 훈련 과정에서, 상기 시차를 통해 왼쪽 이미지를 전환하여 생성된 오른쪽 이미지는, 실제 오른쪽 이미지와 색상 값이 일치할 것을 요구한다. 그러나, 실제 적용에서, 상기 방식으로 생성된 오른쪽 이미지 컨텐츠는 구조적 손실과 객체 변형이 자주 발생하여, 생성 이미지의 품질에 심각한 영향을 미친다."}
{"patent_id": "10-2020-7012581", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 출원의 실시예는 이미지 생성 네트워크의 훈련 및 이미지 처리 기술 방안을 제안한다."}
{"patent_id": "10-2020-7012581", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 출원의 실시예의 제1 측면에 따르면, 이미지 생성 네트워크의 훈련 방법을 제공하며, 상기 방법은, 샘플 이 미지를 획득하는 단계 - 상기 샘플 이미지는 제1 샘플 이미지 및 상기 제1 샘플 이미지에 대응하는 제2 샘플 이 미지를 포함함 - ; 이미지 생성 네트워크에 기반하여 상기 제1 샘플 이미지에 대해 처리를 수행함으로써, 예측 된 목표 이미지를 획득하는 단계; 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 차이 손실을 결정하 는 단계; 및 상기 차이 손실에 기반하여 상기 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 훈련된 이미 지 생성 네트워크를 획득하는 단계를 포함한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 차이 손실을 결정하는 단계는, 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 차 이 손실을 결정하는 단계를 포함하고, 상기 차이 손실에 기반하여 상기 이미지 생성 네트워크에 대해 훈련을 수 행함으로써, 훈련된 이미지 생성 네트워크를 획득하는 단계는, 상기 차이 손실에 기반하여 상기 이미지 생성 네 트워크 및 상기 구조 분석 네트워크에 대해 적대적 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득 하는 단계를 포함한다. 본 출원의 실시예에 따른 훈련 단계에서, 구조 분석 네트워크 및 이미지 생성 네트워크를 이용하여 적대적 훈련 을 수행함으로써, 적대적 훈련을 통해 이미지 생성 네트워크의 성능을 향상시킨다. 본 출원의 상기 임의의 방법 실시예에서, 상기 차이 손실은 제1 구조 차이 손실 및 특징 손실을 포함하고, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 차이 손실을 결정하는 단계는, 구조 분석 네트워크에 기반 하여 상기 예측된 목표 이미지 및 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표 이미지 와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하는 단계; 및 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 특징 손실을 결정하는 단계를 포함한다. 본 출원의 실시예에서, 구조 분석 네트워크를 통해 목표 이미지 및 제2 샘플 이미지에 대해 처리를 수행함으로 써, 복수 개의 스케일의 특징맵을 각각 획득할 수 있고, 각 스케일의 특징맵에서의 각 위치의 구조 특징에 대해, 목표 이미지에 대응하는 복수 개의 특징맵에서의 각 위치의 구조 특징 및 제2 샘플 이미지에 대응하는 복 수 개의 특징맵에서의 각 위치의 구조 특징에 기반하여, 제1 구조 차이 손실을 결정하며; 특징 손실은 예측된 목표 이미지에 대응하는 복수 개의 특징맵에서의 각 위치 및 제2 샘플 이미지에 대응하는 복수 개의 특징맵에서 의 각 위치에 기반하여 결정된다. 본 출원의 상기 임의의 방법 실시예에서, 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지 및 상 기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하는 단계는, 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지에 대해 처리 를 수행함으로써, 상기 예측된 목표 이미지에서 적어도 하나의 위치의 적어도 하나의 제1 구조 특징을 결정하는 단계; 상기 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 제2 샘플 이미지에서 적어도 하나의 위치의 적어도 하나의 제2 구조 특징을 결정하는 단계; 및 상기 적어도 하나의 제1 구조 특징 및 상기 적어도 하나의 제2 구조 특징에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하는 단계를 포함한다. 본 출원의 실시예 구조 분석 네트워크를 통해 예측된 목표 이미지 및 제2 샘플 이미지에 대해 각각 처리를 수행 함으로써, 예측된 목표 이미지에 대해 적어도 하나의 특징맵을 획득하고, 각 특징맵에서의 각 위치에 대해 하나 의 제1 구조 특징을 획득하며, 즉 적어도 하나의 제1 구조 특징을 획득하며; 마찬가지로 제2 샘플 이미지에 대 해 적어도 하나의 제2 구조 특징을 획득하며, 본 출원의 실시예에서의 제1 구조 차이 손실은 각 스케일에서의 각 위치에 대응하는 목표 이미지의 제1 구조 특징 및 제2 샘플 이미지의 제2 구조 특징 사이의 차이를 통계함으로써 획득되고, 각 스케일에서의 동일한 위치에 대응하는 제1 구조 특징 및 제2 구조 특징 사이의 구조 차이를 각각 계산하여, 두 개의 이미지 사이의 구조 차이 손실을 결정한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표 이미지에서 적어도 하나의 위치의 적어도 하나의 제1 구조 특징을 결정 하는 단계는, 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지에 대해 처리를 수행함으로써, 상기 예측 된 목표 이미지의 적어도 하나의 스케일의 제1 특징맵을 획득하는 단계; 및 각 상기 제1 특징맵에 대해, 상기 제1 특징맵에서 적어도 하나의 위치 중 각 위치의 특징과 상기 위치의 인접 영역 특징 사이의 코사인 거리에 기 반하여, 상기 예측된 목표 이미지의 적어도 하나의 제1 구조 특징을 획득하는 단계 - 상기 제1 특징맵에서의 각 위치는 하나의 제1 구조 특징에 대응하고, 상기 인접 영역 특징은 상기 위치를 중심으로 하여 적어도 2 개의 위 치를 포함하는 영역 내의 각 특징임 - 를 포함한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처 리를 수행함으로써, 상기 제2 샘플 이미지에서 적어도 하나의 위치의 적어도 하나의 제2 구조 특징을 결정하는 단계는, 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 적어도 하나의 스 케일에서의 상기 제2 샘플 이미지의 제2 특징맵을 획득하는 단계; 및 각 상기 제2 특징맵에 대해, 상기 제2 특 징맵에서 적어도 하나의 위치 중 각 위치의 특징과 상기 위치의 인접 영역 특징 사이의 코사인 거리에 기반하여, 상기 제2 샘플 이미지의 적어도 하나의 제2 구조 특징을 획득하는 단계 - 상기 제2 특징맵에서의 각 위치는 하나의 제2 구조 특징에 대응함 - 를 포함한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 제1 특징맵에서의 각 위치와 상기 제2 특징맵에서의 각 위치 사 이에는 대응 관계가 존재하고, 상기 적어도 하나의 제1 구조 특징 및 상기 적어도 하나의 제2 구조 특징에 기반 하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하는 단계는, 대응 관계가 존재하는 위치에 대응하는 상기 제1 구조 특징과 상기 제2 구조 특징 사이의 거리를 계산하는 단계; 및 상기 예측된 목표 이미지에 대응하는 모든 상기 제1 구조 특징과 상기 제2 구조 특징 사이의 거리에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하는 단계를 포함한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 특징 손실을 결정하는 단계는, 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지 및 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표 이미지의 적어도 하나의 스케 일의 제1 특징맵 및 적어도 하나의 스케일에서의 상기 제2 샘플 이미지의 제2 특징맵을 획득하는 단계; 및 상기 적어도 하나의 제1 특징맵 및 상기 적어도 하나의 제2 특징맵에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 특징 손실을 결정하는 단계를 포함한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 제1 특징맵에서의 각 위치와 상기 제2 특징맵에서의 각 위치 사 이에는 대응 관계가 존재하고, 상기 적어도 하나의 제1 특징맵 및 상기 적어도 하나의 제2 특징맵에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 특징 손실을 결정하는 단계는, 대응 관계가 존재하는 위치에 대응하는 상기 제1 특징맵에서의 특징과 상기 제2 특징맵에서의 특징 사이의 거리를 계산하는 단계; 및 상기 제1 특징맵에서의 특징과 상기 제2 특징맵에서의 특징 사이의 거리에 기반하여, 상기 예측된 목표 이미지 와 상기 제2 샘플 이미지 사이의 특징 손실을 결정하는 단계를 포함한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 차이 손실은 색상 손실을 더 포함하고, 상기 차이 손실에 기반하 여 상기 이미지 생성 네트워크에 대해 훈련을 수행하여, 훈련된 이미지 생성 네트워크를 획득하기 전에, 상기 방법은, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 색상 차이에 기반하여, 상기 이미지 생성 네 트워크의 색상 손실을 결정하는 단계를 더 포함하고, 상기 차이 손실에 기반하여 상기 이미지 생성 네트워크 및 상기 구조 분석 네트워크에 대해 적대적 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하는 단계는, 제1 반복에서, 상기 제1 구조 차이 손실, 상기 특징 손실 및 상기 색상 손실에 기반하여 상기 이미지 생성 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계; 및 제2 반복에서, 상기 제1 구조 차이 손실 에 기반하여 상기 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계 - 상기 제1 반복 및 상기 제2 반복은 연속적으로 수행되는 2 회의 반복임 - ; 훈련 정지 조건을 만족시킬 때까지 조정을 수행하여 훈련된 이미지 생성 네트워크를 획득하는 단계를 포함한다. 본 출원의 실시예에서, 적대적 훈련의 목표는 이미지 생성 네트워크에 의해 획득된 예측된 목표 이미지와 제2 샘플 이미지 사이의 차이를 감소시키는 것이다. 적대적 훈련은 일반적으로 교대 훈련의 방식을 사용하여 구현되 며, 본 출원의 실시예에서, 이미지 생성 네트워크 및 구조 분석 네트워크에 대해 교대로 훈련을 수행하여, 요구사항에 부합되는 이미지 생성 네트워크를 획득한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 차이 손실을 결정하기 전에, 상기 제2 샘플 이미지에 소음을 추가하여, 소음 이미지를 획득하는 단계; 및 상기 소음 이미지 및 상기 제2 샘플 이미지에 기반하여 제2 구조 차이 손실을 결정하는 단계를 더 포함한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 소음 이미지 및 상기 제2 샘플 이미지에 기반하여 제2 구조 차이 손실을 결정하는 단계는, 구조 분석 네트워크에 기반하여 상기 소음 이미지에 대해 처리를 수행함으로써, 상기 소음 이미지에서 적어도 하나의 위치의 적어도 하나의 제3 구조 특징을 결정하는 단계; 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 제2 샘플 이미지에서 적어도 하나의 위치의 상기 적어도 하나의 제2 구조 특징을 결정하는 단계; 및 상기 적어도 하나의 제3 구조 특징 및 상기 적어도 하 나의 제2 구조 특징에 기반하여, 상기 소음 이미지와 상기 제2 샘플 이미지 사이의 제2 구조 차이 손실을 결정 하는 단계를 포함한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 구조 분석 네트워크에 기반하여 상기 소음 이미지에 대해 처리를 수행함으로써, 상기 소음 이미지에서 적어도 하나의 위치의 적어도 하나의 제3 구조 특징을 결정하는 단계는, 상기 구조 분석 네트워크에 기반하여 상기 소음 이미지에 대해 처리를 수행함으로써, 상기 소음 이미지의 적어 도 하나의 스케일의 제3 특징맵을 획득하는 단계; 및 각 상기 제3 특징맵에 대해, 상기 제3 특징맵에서 적어도 하나의 위치 중 각 위치의 특징과 상기 위치의 인접 영역 특징 사이의 코사인 거리에 기반하여, 상기 소음 이미 지의 적어도 하나의 제3 구조 특징을 획득하는 단계 - 상기 제3 특징맵에서의 각 위치는 하나의 제3 구조 특징 에 대응하고, 상기 인접 영역 특징은 상기 위치를 중심으로 하여 적어도 2 개의 위치를 포함하는 영역 내의 각 특징임 - 를 포함한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 제3 특징맵에서의 각 위치와 상기 제2 특징맵에서의 각 위치 사 이에는 대응 관계가 존재하고, 상기 적어도 하나의 제3 구조 특징 및 상기 적어도 하나의 제2 구조 특징에 기반 하여, 상기 소음 이미지와 상기 제2 샘플 이미지 사이의 제2 구조 차이 손실을 결정하는 단계는, 대응 관계가 존재하는 위치에 대응하는 상기 제3 구조 특징과 상기 제2 구조 특징 사이의 거리를 계산하는 단계; 및 상기 소 음 이미지에 대응하는 모든 상기 제3 구조 특징과 상기 제2 구조 특징 사이의 거리에 기반하여, 상기 소음 이미 지와 상기 제2 샘플 이미지 사이의 제2 구조 차이 손실을 결정하는 단계를 포함한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 차이 손실에 기반하여 상기 이미지 생성 네트워크 및 상기 구조 분석 네트워크에 대해 적대적 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하는 단계는, 제3 반복 에서, 상기 제1 구조 차이 손실, 상기 특징 손실 및 상기 색상 손실에 기반하여 상기 이미지 생성 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계; 제4 반복에서, 상기 제1 구조 차이 손실 및 상기 제2 구조 차 이 손실에 기반하여 상기 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계 - 상기 제3 반 복 및 상기 제4 반복은 연속적으로 수행되는 2 회의 반복임 - ; 및 훈련 정지 조건을 만족시킬 때까지 조정을 수행하여, 훈련된 이미지 생성 네트워크를 획득하는 단계를 포함한다. 본 출원의 실시예에서, 소음 이미지에 대응하는 제2 구조 차이 손실을 획득한 후, 구조 분석 네트워크의 성능을 향상시키기 위해, 구조 분석 네트워크의 네트워크 파라미터를 조정할 때, 제2 구조 차이 손실을 추가한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표 이미지에서 적어도 하나의 위치의 적어도 하나의 제1 구조 특징을 결정 한 후, 이미지 재구성 네트워크에 기반하여 상기 적어도 하나의 제1 구조 특징에 대해 이미지 재구성 처리를 수 행함으로써, 제1 재구성 이미지를 획득하는 단계; 및 상기 제1 재구성 이미지와 상기 예측된 목표 이미지에 기 반하여 제1 재구성 손실을 결정하는 단계를 더 포함한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처 리를 수행함으로써, 상기 제2 샘플 이미지에서 적어도 하나의 위치의 적어도 하나의 제2 구조 특징을 결정한 후, 이미지 재구성 네트워크에 기반하여 상기 적어도 하나의 제2 구조 특징에 대해 이미지 재구성 처리를 수행 함으로써, 제2 재구성 이미지를 획득하는 단계; 및 상기 제2 재구성 이미지 및 상기 제2 샘플 이미지에 기반하 여 제2 재구성 손실을 결정하는 단계를 더 포함한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 차이 손실에 기반하여 상기 이미지 생성 네트워크 및 구조 분석 네트워크에 대해 적대적 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하는 단계는, 제5 반복에서, 상기 제1 구조 차이 손실, 상기 특징 손실 및 상기 색상 손실에 기반하여 상기 이미지 생성 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계; 제6 반복에서, 상기 제1 구조 차이 손실, 상기 제2 구조 차이 손실, 상기 제1 재구성 손실 및 상기 제2 재구성 손실에 기반하여 상기 구조 분석 네트워크의 네트워크 파라미터에 대 해 조정을 수행하는 단계 - 상기 제5 반복 및 상기 제6 반복은 연속적으로 수행되는 2 회의 반복임 - ; 및 훈련 정지 조건을 만족시킬 때까지 조정을 수행하여, 훈련된 이미지 생성 네트워크를 획득하는 단계 를 포함한다. 본 출원의 실시예에서, 이미지 생성 네트워크의 파라미터에 대해 조정을 수행하기 위한 손실은 변하지 않고, 구 조 분석 네트워크의 성능에 대해서만 성능을 향상시키며, 구조 분석 네트워크와 이미지 생성 네트워크 사이는 적대적 훈련되므로, 구조 분석 네트워크의 성능을 향상시킴으로써, 이미지 생성 네트워크의 훈련을 가속화시킬 수 있다. 본 출원의 상기 임의의 방법 실시예에서, 상기 차이 손실에 기반하여 상기 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득한 후, 상기 훈련된 이미지 생성 네트워크에 기반하여 처리 될 이미지에 대해 처리를 수행함으로써, 목표 이미지를 획득하는 단계를 더 포함한다. 본 출원의 상기 임의의 방법 실시예에서, 상기 처리될 이미지는 좌안 이미지를 포함하고; 상기 목표 이미지는 상기 좌안 이미지에 대응하는 우안 이미지를 포함한다. 본 출원의 실시예의 다른 하나의 측면에 따르면, 이미지 처리 방법이 제공되고, 3 차원 이미지 생성 장면에서, 좌안 이미지를 이미지 생성 네트워크에 입력하여, 우안 이미지를 획득하는 단계; 및 상기 좌안 이미지 및 상기 우안 이미지에 기반하여 3 차원 이미지를 생성하는 단계 - 상기 이미지 생성 네트워크는 상기 실시예 중 어느 한 항에 따른 이미지 생성 네트워크의 훈련 방법을 통해 훈련하여 획득된 것임 - 를 포함한다. 본 출원의 실시예에서 제공한 이미지 처리 방법에서, 이미지 생성 네트워크를 통해 좌안 이미지에 대해 처리를 수행하여 대응하는 우안 이미지를 획득하는 바, 조명, 차단, 소음 등 환경적 요인에 의한 영향이 적어, 작은 시 각 면적을 갖는 객체의 합성 정확도를 유지할 수 있으므로, 획득된 우안 이미지와 좌안 이미지를 통해 변형이 작고, 디테일 유지가 완전한 3 차원 이미지를 생성할 수 있다. 본 출원의 실시예의 제2 측면에 따르면, 이미지 생성 네트워크의 훈련 장치를 제공하며, 샘플 이미지를 획득하 도록 구성된 샘플 획득 유닛 - 상기 샘플 이미지는 제1 샘플 이미지 및 상기 제1 샘플 이미지에 대응하는 제2 샘플 이미지를 포함함 - ; 이미지 생성 네트워크에 기반하여 상기 제1 샘플 이미지에 대해 처리를 수행함으로써, 예측된 목표 이미지를 획득하도록 구성된 목표 예측 유닛; 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 차이 손실을 결정하도록 구성된 차이 손실 결정 유닛; 및 상기 차이 손실에 기반하여 상기 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하도록 구성된 네트워 크 훈련 유닛을 포함한다. 본 출원의 상기 임의의 장치 실시예에서, 상기 차이 손실 결정 유닛은 구체적으로, 구조 분석 네트워크에 기반 하여 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 차이 손실을 결정하도록 구성되고, 상기 네트워 크 훈련 유닛은 구체적으로, 상기 차이 손실에 기반하여 상기 이미지 생성 네트워크 및 상기 구조 분석 네트워 크에 대해 적대적 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하도록 구성된다. 본 출원의 상기 임의의 장치 실시예에서, 상기 차이 손실은 제1 구조 차이 손실 및 특징 손실을 포함하고, 상기 차이 손실 결정 유닛은, 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지 및 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결 정하도록 구성된 제1 구조 차이 결정 모듈; 및 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 특징 손실을 결정하도록 구성된 특징 손실 결정 모듈을 포함한다. 본 출원의 상기 임의의 장치 실시예에서, 상기 제1 구조 차이 결정 모듈은, 상기 구조 분석 네트워크에 기반하 여 상기 예측된 목표 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표 이미지에서 적어도 하나의 위치의 적어도 하나의 제1 구조 특징을 결정하고; 상기 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 제2 샘플 이미지에서 적어도 하나의 위치의 적어도 하나의 제2 구조 특징을 결정하 며; 상기 적어도 하나의 제1 구조 특징 및 상기 적어도 하나의 제2 구조 특징에 기반하여, 상기 예측된 목표 이 미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하도록 구성된다. 본 출원의 상기 임의의 장치 실시예에서, 상기 제1 구조 차이 결정 모듈은 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표 이미지에서 적어도 하나의 위치의 적 어도 하나의 제1 구조 특징을 결정할 때, 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지에 대해 처리 를 수행함으로써, 상기 예측된 목표 이미지의 적어도 하나의 스케일의 제1 특징맵을 획득하고; 각 상기 제1 특징맵에 대해, 상기 제1 특징맵에서 적어도 하나의 위치 중 각 위치의 특징과 상기 위치의 인접 영역 특징 사이 의 코사인 거리에 기반하여, 상기 예측된 목표 이미지의 적어도 하나의 제1 구조 특징을 획득하도록 구성되며, 상기 제1 특징맵에서의 각 위치는 하나의 제1 구조 특징에 대응하고, 상기 인접 영역 특징은 상기 위치를 중심 으로 하여 적어도 2 개의 위치를 포함하는 영역 내의 각 특징이다. 본 출원의 상기 임의의 장치 실시예에서, 상기 제1 구조 차이 결정 모듈은 상기 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 제2 샘플 이미지에서 적어도 하나의 위치의 적어도 하 나의 제2 구조 특징을 결정할 때, 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함 으로써, 적어도 하나의 스케일에서의 상기 제2 샘플 이미지의 제2 특징맵을 획득하고; 각 상기 제2 특징맵에 대 해, 상기 제2 특징맵에서 적어도 하나의 위치 중 각 위치의 특징과 상기 위치의 인접 영역 특징 사이의 코사인 거리에 기반하여, 상기 제2 샘플 이미지의 적어도 하나의 제2 구조 특징을 획득하도록 구성되며, 상기 제2 특징 맵에서의 각 위치는 하나의 제2 구조 특징에 대응한다. 본 출원의 상기 임의의 장치 실시예에서, 상기 제1 특징맵에서의 각 위치와 상기 제2 특징맵에서의 각 위치 사 이에는 대응 관계가 존재하고, 상기 제1 구조 차이 결정 모듈은 상기 적어도 하나의 제1 구조 특징 및 상기 적 어도 하나의 제2 구조 특징에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차 이 손실을 결정할 때, 대응 관계가 존재하는 위치에 대응하는 상기 제1 구조 특징과 상기 제2 구조 특징 사이의 거리를 계산하고; 상기 예측된 목표 이미지에 대응하는 모든 상기 제1 구조 특징과 상기 제2 구조 특징 사이의 거리에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하도록 구성된다. 본 출원의 상기 임의의 장치 실시예에서, 상기 특징 손실 결정 모듈은, 구체적으로 상기 구조 분석 네트워크에 기반하여 상기 예측된 목표 이미지 및 상기 제2 샘플 이미지에 대해 처리를 수행함으로써, 상기 예측된 목표 이 미지의 적어도 하나의 스케일의 제1 특징맵 및 적어도 하나의 스케일에서의 상기 제2 샘플 이미지의 제2 특징맵 을 획득하고; 상기 적어도 하나의 제1 특징맵 및 상기 적어도 하나의 제2 특징맵에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 특징 손실을 결정하도록 구성된다. 본 출원의 상기 임의의 장치 실시예에서, 상기 제1 특징맵에서의 각 위치와 상기 제2 특징맵에서의 각 위치 사 이에는 대응 관계가 존재하고, 상기 특징 손실 결정 모듈은 상기 적어도 하나의 제1 특징맵 및 상기 적어도 하 나의 제2 특징맵에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 특징 손실을 결정할 때, 대응 관계가 존재하는 위치에 대응하는 상기 제1 특징맵에서의 특징과 상기 제2 특징맵에서의 특징 사이의 거리 를 계산하고; 상기 제1 특징맵에서의 특징과 상기 제2 특징맵에서의 특징 사이의 거리에 기반하여, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 특징 손실을 결정하도록 구성된다. 본 출원의 상기 임의의 장치 실시예에서, 상기 차이 손실은 색상 손실을 더 포함하고; 상기 차이 손실 결정 유 닛은, 상기 예측된 목표 이미지와 상기 제2 샘플 이미지 사이의 색상 차이에 기반하여, 상기 이미지 생성 네트 워크의 색상 손실을 결정하도록 구성된 색상 손실 결정 모듈을 더 포함하고, 상기 네트워크 훈련 유닛은 구체적 으로, 제1 반복에서, 상기 제1 구조 차이 손실, 상기 특징 손실 및 상기 색상 손실에 기반하여 상기 이미지 생 성 네트워크의 네트워크 파라미터에 대해 조정을 수행하고; 제2 반복에서, 상기 제1 구조 차이 손실에 기반하여 상기 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행하며; 훈련 정지 조건을 만족시킬 때까지 조 정을 수행하여, 훈련된 이미지 생성 네트워크를 획득하도록 구성되며, 상기 제1 반복 및 상기 제2 반복은 연속 적으로 수행되는 2 회의 반복이다. 본 출원의 상기 임의의 장치 실시예에서, 상기 장치는, 상기 제2 샘플 이미지에 소음을 추가하여, 소음 이미지 를 획득하도록 구성된 소음 추가 유닛; 및 상기 소음 이미지 및 상기 제2 샘플 이미지에 기반하여 제2 구조 차 이 손실을 결정하도록 구성된 제2 구조 차이 손실 유닛을 더 포함한다. 본 출원의 상기 임의의 장치 실시예에서, 상기 제2 구조 차이 손실 유닛은 구체적으로, 구조 분석 네트워크에 기반하여 상기 소음 이미지에 대해 처리를 수행함으로써, 상기 소음 이미지에서 적어도 하나의 위치의 적어도 하나의 제3 구조 특징을 결정하고; 구조 분석 네트워크에 기반하여 상기 제2 샘플 이미지에 대해 처리를 수행함 으로써, 상기 제2 샘플 이미지에서 적어도 하나의 위치의 상기 적어도 하나의 제2 구조 특징을 결정하며; 상기 적어도 하나의 제3 구조 특징 및 상기 적어도 하나의 제2 구조 특징에 기반하여, 상기 소음 이미지와 상기 제2 샘플 이미지 사이의 제2 구조 차이 손실을 결정하도록 구성된다. 본 출원의 상기 임의의 장치 실시예에서, 상기 제2 구조 차이 손실 유닛은, 구조 분석 네트워크에 기반하여 상 기 소음 이미지에 대해 처리를 수행함으로써, 상기 소음 이미지에서 적어도 하나의 위치의 적어도 하나의 제3 구조 특징을 결정할 때, 상기 구조 분석 네트워크에 기반하여 상기 소음 이미지에 대해 처리를 수행함으로써, 상기 소음 이미지의 적어도 하나의 스케일의 제3 특징맵을 획득하고; 각 상기 제3 특징맵에 대해, 상기 제3 특 징맵에서 적어도 하나의 위치 중 각 위치의 특징과 상기 위치의 인접 영역 특징 사이의 코사인 거리에 기반하여, 상기 소음 이미지의 적어도 하나의 제3 구조 특징을 획득하도록 구성되며, 상기 제3 특징맵에서의 각 위치는 하나의 제3 구조 특징에 대응하고, 상기 인접 영역 특징은 상기 위치를 중심으로 하여 적어도 2 개의 위 치를 포함하는 영역 내의 각 특징이다. 본 출원의 상기 임의의 장치 실시예에서, 상기 제3 특징맵에서의 각 위치와 상기 제2 특징맵에서의 각 위치 사 이에는 대응 관계가 존재하고, 상기 제2 구조 차이 손실 유닛은 상기 적어도 하나의 제3 구조 특징 및 상기 적 어도 하나의 제2 구조 특징에 기반하여, 상기 소음 이미지와 상기 제2 샘플 이미지 사이의 제2 구조 차이 손실 을 결정할 때, 대응 관계가 존재하는 위치에 대응하는 상기 제3 구조 특징과 상기 제2 구조 특징 사이의 거리를 계산하고; 상기 소음 이미지에 대응하는 모든 상기 제3 구조 특징과 상기 제2 구조 특징 사이의 거리에 기반하 여, 상기 소음 이미지와 상기 제2 샘플 이미지 사이의 제2 구조 차이 손실을 결정하도록 구성된다. 본 출원의 상기 임의의 장치 실시예에서, 상기 네트워크 훈련 유닛은 구체적으로, 제3 반복에서, 상기 제1 구조 차이 손실, 상기 특징 손실 및 상기 색상 손실에 기반하여 상기 이미지 생성 네트워크의 네트워크 파라미터에 대해 조정을 수행하고; 제4 반복에서, 상기 제1 구조 차이 손실 및 상기 제2 구조 차이 손실에 기반하여 상기 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행하며; 훈련 정지 조건을 만족시킬 때까지 조정을 수행하여, 훈련된 이미지 생성 네트워크를 획득하도록 구성되며, 상기 제3 반복 및 상기 제4 반복은 연속적으로 수행되는 2 회의 반복이다. 본 출원의 상기 임의의 장치 실시예에서, 상기 제1 구조 차이 결정 모듈은 또한, 이미지 재구성 네트워크에 기 반하여 상기 적어도 하나의 제1 구조 특징에 대해 이미지 재구성 처리를 수행함으로써, 제1 재구성 이미지를 획 득하고; 상기 제1 재구성 이미지와 상기 예측된 목표 이미지에 기반하여 제1 재구성 손실을 결정하도록 구성된 다. 본 출원의 상기 임의의 장치 실시예에서, 상기 제1 구조 차이 결정 모듈은 또한, 이미지 재구성 네트워크에 기 반하여 상기 적어도 하나의 제2 구조 특징에 대해 이미지 재구성 처리를 수행함으로써, 제2 재구성 이미지를 획 득하고; 상기 제2 재구성 이미지 및 상기 제2 샘플 이미지에 기반하여 제2 재구성 손실을 결정하도록 구성된다. 본 출원의 상기 임의의 장치 실시예에서, 상기 네트워크 훈련 유닛은 구체적으로, 제5 반복에서, 상기 제1 구조 차이 손실, 상기 특징 손실 및 상기 색상 손실에 기반하여 상기 이미지 생성 네트워크의 네트워크 파라미터에 대해 조정을 수행하고; 제6 반복에서, 상기 제1 구조 차이 손실, 상기 제2 구조 차이 손실, 상기 제1 재구성 손 실 및 상기 제2 재구성 손실에 기반하여 상기 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행하며; 훈련 정지 조건을 만족시킬 때까지 조정을 수행하여, 훈련된 이미지 생성 네트워크를 획득하도록 구 성되며, 상기 제5 반복 및 상기 제6 반복은 연속적으로 수행되는 2 회의 반복이다. 본 출원의 상기 임의의 장치 실시예에서, 상기 장치는, 상기 훈련된 이미지 생성 네트워크에 기반하여 처리될 이미지에 대해 처리를 수행함으로써, 목표 이미지를 획득하도록 구성된 이미지 처리 유닛을 더 포함한다. 본 출원의 상기 임의의 장치 실시예에서, 상기 처리될 이미지는 좌안 이미지를 포함하고; 상기 목표 이미지는 상기 좌안 이미지에 대응하는 우안 이미지를 포함한다. 본 출원의 실시예의 또 다른 측면에 따르면, 이미지 처리 장치를 제공하며, 상기 장치는 3 차원 이미지 생성 장 면에서, 좌안 이미지를 이미지 생성 네트워크에 입력하여, 우안 이미지를 획득하도록 구성된 우안 이미지 획득 유닛; 및 상기 좌안 이미지 및 상기 우안 이미지에 기반하여 3 차원 이미지를 생성하도록 구성된 3 차원 이미지 생성 유닛 - 상기 이미지 생성 네트워크는 상기 실시예 중 어느 한 항에 따른 이미지 생성 네트워크의 훈련 방 법을 통해 훈련하여 획득된 것임 - 을 포함한다. 본 출원의 실시예의 제3 측면에 따르면, 프로세서를 포함하는 전자 기기를 제공하며, 상기 프로세서는 상기 실 시예 중 어느 한 항에 따른 이미지 생성 네트워크의 훈련 장치 또는 상기 실시예에 따른 이미지 처리 장치를 포 함한다. 본 출원의 실시예의 제4 측면에 따르면, 전자 기기를 제공하며, 프로세서; 및 프로세서에서 실행 가능한 명령어 를 포함하기 위한 메모리를 포함하며, 여기서, 상기 프로세서는 상기 실행 가능한 명령어를 실행함으로써, 전술 한 실시예 중 어느 한 항에 따른 이미지 생성 네트워크의 훈련 방법, 및 이미지 처리 방법 중 적어도 하나를 구현하도록 구성된다. 본 출원의 실시예의 제5 측면에 따르면, 컴퓨터 판독 가능한 명령어를 저장하기 위한 컴퓨터 저장 매체를 제공 하며, 상기 판독 가능한 명령어가 실행될 때, 상기 실시예 중 어느 한 항 따른 이미지 생성 네트워크의 훈련 방 법의 단계, 및 상기 실시예에 따른 이미지 처리 방법의 단계 중 적어도 하나를 실행한다. 본 출원의 실시예의 제6 측면에 따르면, 컴퓨터 판독 가능한 코드를 포함하는 컴퓨터 프로그램 제품을 제공하며, 상기 컴퓨터 판독 가능한 코드가 기기에서 작동될 때, 상기 기기의 프로세서는 상기 실시예 중 어느 한 항에 따른 이미지 생성 네트워크의 훈련 방법을 구현하기 위한 명령어, 및 상기 실시예에 따른 이미지 처리 방법을 구현하기 위한 명령어 중 적어도 하나를 실행한다."}
{"patent_id": "10-2020-7012581", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 출원의 상기 실시예에 기반하여 제공된 이미지 생성 네트워크의 훈련 및 이미지 처리 방법 및 장치, 전자 기 기는, 샘플 이미지를 획득하고, 샘플 이미지는 제1 샘플 이미지 및 제1 샘플 이미지에 대응하는 제2 샘플 이미 지를 포함하며; 이미지 생성 네트워크에 기반하여 제1 샘플 이미지에 대해 처리를 수행함으로써, 예측된 목표 이미지를 획득하며; 예측된 목표 이미지와 제2 샘플 이미지 사이의 차이 손실을 결정하고; 차이 손실에 기반하 여 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하며, 차이 손실을 통해 예측된 목표 이미지와 제2 샘플 이미지 사이의 구조 차이를 설명하여, 차이 손실로써 이미지 생성 네트워 크에 대해 훈련을 수행함으로써, 이미지 생성 네트워크에 기반하여 생성된 이미지의 구조가 왜곡되지 않도록 보 장한다. 이해해야 할 것은, 이상의 일반적인 설명 및 하기의 상세한 설명은 다만 예시적이고 해석적인 것이며, 본 발명 을 한정하려는 것은 아니다. 아래의 도면에서 예시적인 실시예의 상세한 설명에 따라, 본 출원의 다른 특징 및 측면은 더욱 명확해질 것이다."}
{"patent_id": "10-2020-7012581", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 다양한 예시적인 실시예, 특징 및 측면을 상세하게 설명한다. 도면에서 동일 한 도면 부호는 동일하거나 유사한 기능을 갖는 요소를 나타낸다. 실시예의 다양한 측면이 도면에 도시되어 있 지만, 특별히 언급되지 않는 한, 도면을 비율에 따라 그릴 필요는 없다. 아래에 첨부 도면을 참조하여 본 출원의 다양한 실시예를 상세히 설명한다. 유의해야 할 것은, 달리 구체적으로 언급되지 않는 한, 실시예에 제시된 구성 요소, 단계의 상대적인 배열, 수치 표현 및 값은 본 출원의 범위를 한 정하려는 것이 아니다. 또한, 설명의 편의를 위해, 도면에 도시된 각 부분의 크기는 실제 비율로 도시되지 않았다는 것을 이해해야한다. 적어도 하나의 예시적인 실시예에 대한 다음의 설명은 실제로 예시적인 것에 불과하며, 본 출원 및 그 적용이나 사용에 대한 어떠한 한정으로도 간주되지 않는다. 관련 기술 분야의 통상의 기술자에게 공지된 기술, 방법 및 기기는 상세하게 논의되지 않을 수 있지만, 적절한 경우, 상기 기술, 방법 및 기기는 명세서의 일부로 간주되어야 한다. 유의해야 할 것은, 다음의 도면에서 유사한 참조 번호 및 문자는 유사한 항목을 표시하므로, 어느 한 항목이 하 나의 도면에서 정의되면, 후속 도면에서 추가로 논의될 필요가 없다. 최근에는, 3D 스테레오 영화, 광고, 라이브 방송 플랫폼과 같은 미디어의 인기가 사람들의 일상 생활을 다채롭 게 해왔으며, 산업 규모는 계속 증가하고 있다. 그러나, 시중의 3D 디스플레이 하드웨어의 높은 보급률, 높은 점유율과 반대로, 스테레오 이미지 비디오 컨텐츠의 제작은 비용이 많이 들고, 제작 주기가 길며, 인건비가 많 아, 기존 물량이 부족하다. 이에 비해, 2D 이미지 비디오 소재는 상당한 규모로 형성되어 있으며, 영화와 텔레 비전 엔터테이먼트, 문화예술, 과학연구 등 분야에서 소중한 정보를 축적하였다. 이러한 2D 이미지 비디오를, 자동적이고 적은 비용으로, 고품질의 스테레오 이미지 비디오로 전환할 수 있으면, 새로운 사용자 경험을 창출 할 수 있으므로, 광범위한 시장 적용 발전성을 갖는다. 2D에서 3D 스테레오 효과로의 전환은, 입력된 단안 이미지에 따라, 다른 하나의 시점에서 캡처된 장면 컨텐츠를 복원해야 한다. 3D 계층적 룩앤필을 형성하기 위해, 상기 과정은 입력 장면의 깊이 정보를 이해하고, 양안 시차 관계에 기반하여, 입력 좌안의 픽셀을 시차에 따라 전환하여, 우안 컨텐츠를 생성해야 한다. 2D에서 3D 스테레 오로 전환하는 일반적인 방법은 비교를 통해 오른쪽 이미지와 실제 오른쪽 이미지 사이의 평균 색상 차이를 생 성하여 훈련 신호로 사용하기에, 조명, 차단, 소음 등 환경적 요인에 의한 영향을 쉽게 받고, 작은 시각 면적을 갖는 객체의 합성 정확도를 유지하기 어려우므로, 변형이 크고, 세부적인 손실이 있는 합성 결과를 초래한다. 기존의 이미지 형상 보존 생성 방법은 주로 3 차원 세계의 감독 신호를 도입하여, 네트워크로 하여금 정확한 크 로스 뷰 변환을 학습하도록 함으로써, 상이한 뷰 하에서의 형상의 일치성을 유지한다. 그러나, 도입된 3 차원 정보는 특수한 적용 조건으로 인해, 모델의 일반화 능력을 제한하여, 실제 산업 분야에서 역할을 발휘하기 어렵 다. 상기 2D에서 3D 스테레오 효과로 전환하는 과정에서 발생하는 문제점에 대해, 본 출원의 실시예는 하기의 이미 지 생성 네트워크의 훈련 방법을 제안하며, 본 출원의 실시예의 훈련 방법에 의해 획득된 이미지 생성 네트워크 는, 상기 이미지 생성 네트워크에 입력된 단안 이미지에 기반하여, 다른 시점에서 캡처된 장면 컨텐츠를 출력하 도록 구현될 수 있으며, 2D에서 3D 스테레오 효과로의 전환을 구현한다. 도 1은 본 출원의 실시예에서 제공한 이미지 생성 네트워크의 훈련 방법의 하나의 프로세스 모식도이다. 도 1에 도시된 바와 같이, 상기 실시예의 방법은 하기 단계를 포함한다. 단계 110에 있어서, 샘플 이미지를 획득한다. 여기서, 샘플 이미지는 제1 샘플 이미지 및 제1 샘플 이미지에 대응하는 제2 샘플 이미지를 포함한다. 본 출원의 실시예에서의 이미지 생성 네트워크의 훈련 방법의 실행 주체는 단말 기기 또는 서버 또는 다른 처리 기기일 수 있으며, 여기서, 단말 기기는 사용자 기기(User Equipment, UE), 모바일 기기, 사용자 단말, 단말, 셀룰러 폰, 무선 전화, 개인 휴대 정보 단말기(Personal Digital Assistant, PDA), 핸드 헬드 기기, 계산 기기, 차량 탑재 기기, 웨어러블 기기 등일 수 있다. 일부 가능한 구현방식에서, 상기 이미지 생성 네트워크의 훈련 방법은 프로세서가 메모리에 저장된 컴퓨터 판독 가능한 명령어를 호출하는 방식으로서 구현될 수 있다. 여기서, 상기 이미지 프레임은 단일 프레임 이미지일 수 있으며, 이미지 수집 기기에 의해 수집된 이미지일 수 있으며, 예컨대, 단말 기기의 카메라에 의해 캡처된 사진, 또는 비디오 수집 기기에 의해 수집된 비디오 데이터 중의 단일 프레임 이미지 등이며, 본 출원의 실시예의 구체적인 구현은 한정되지 않는다. 하나의 실시형태로서, 제2 샘플 이미지는 실제 이미지일 수 있으며, 본 출원의 실시예에서 이미지 생성 네트워 크 성능을 측정하는 참조 정보로 사용될 수 있으며, 이미지 생성 네트워크의 목표는 획득된 예측된 목표 이미지 가 제2 샘플 이미지에 더 가까워지는 것이다. 샘플 이미지의 획득은 공지된 대응 관계의 이미지 라이브러리로부 터 선택되거나 실제 필요에 따라 캡처되어 획득될 수 있다. 단계 120에 있어서, 이미지 생성 네트워크에 기반하여 제1 샘플 이미지에 대해 처리를 수행함으로써, 예측된 목 표 이미지를 획득한다. 하나의 실시형태로서, 본 출원의 실시예에서 제안된 이미지 생성 네트워크는 예를 들어, 3D 이미지 합성 등 기 능에 적용될 수 있고, 이미지 생성 네트워크는 임의의 스테레오 이미지 생성 네트워크, 예를 들어, 워싱턴 대학 의 Xie 등 사람이 2016년에 제안한 딥(Deep) 3D 네트워크 등을 사용할 수 있으며; 다른 이미지 생성 적용의 경 우, 이미지 생성 네트워크에 대해 상응하게 교체할 수 있으며, 상기 이미지 생성 네트워크가 입력된 샘플 이미 지에 기반하여 엔드투엔드 목표 이미지를 생성하도록 보장하면 된다. 단계 130에 있어서, 예측된 목표 이미지와 제2 샘플 이미지 사이의 차이 손실을 결정한다. 본 출원의 실시예는 차이 손실로써 이미지 생성 네트워크에 의해 획득된 예측된 목표 이미지와 제2 샘플 이미지 사이의 차이를 설명하며, 따라서, 차이 손실로써 훈련된 이미지 생성 네트워크는, 생성된 예측된 목표 이미지와 제2 샘플 이미지 사이의 유사성을 증가시켜, 이미지 생성 네트워크의 성능을 향상시킨다. 단계 140에 있어서, 차이 손실에 기반하여 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득한다. 본 출원의 상기 실시예에서 제공한 이미지 생성 네트워크의 훈련 방법에 기반하여, 샘플 이미지를 획득하고, 샘 플 이미지는 제1 샘플 이미지 및 제1 샘플 이미지에 대응하는 제2 샘플 이미지를 포함하며; 이미지 생성 네트워 크에 기반하여 제1 샘플 이미지에 대해 처리를 수행함으로써, 예측된 목표 이미지를 획득하며; 예측된 목표 이 미지와 제2 샘플 이미지 사이의 차이 손실을 결정하고; 차이 손실에 기반하여 이미지 생성 네트워크에 대해 훈 련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하며, 차이 손실을 통해 예측된 목표 이미지와 제2 샘 플 이미지 사이의 구조 차이를 설명하여, 차이 손실로써 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 이 미지 생성 네트워크에 기반하여 생성된 이미지의 구조가 왜곡되지 않도록 보장한다. 도 2는 본 출원의 실시예에서 제공한 이미지 생성 네트워크의 훈련 방법의 다른 프로세스 모식도이다. 도 2에 도시된 바와 같이, 본 출원의 실시예는 하기의 단계를 포함한다. 단계 210에 있어서, 샘플 이미지를 획득한다. 여기서, 샘플 이미지는 제1 샘플 이미지 및 제1 샘플 이미지에 대응하는 제2 샘플 이미지를 포함한다. 단계 220에 있어서, 이미지 생성 네트워크에 기반하여 제1 샘플 이미지에 대해 처리를 수행함으로써, 예측된 목 표 이미지를 획득한다. 단계 230에 있어서, 구조 분석 네트워크에 기반하여 예측된 목표 이미지와 제2 샘플 이미지 사이의 차이 손실을 결정한다. 하나의 실시예에서, 구조 분석 네트워크는 세 계층의 특징을 추출할 수 있으며, 즉 여러 계층의 컨볼루션 신경 망(CNN, Convolutional Neural Networks)으로 구성된 인코더를 포함하면 된다. 선택적으로, 본 출원의 실시예 에서 구조 분석 네트워크는 인코더와 디코더로 구성된다. 여기서, 인코더는 하나의 이미지(본 출원의 실시예에 서의 예측된 목표 이미지 및 제2 샘플 이미지)를 입력으로 하여, 일련의 상이한 스케일의 특징맵을 얻으며, 예 를 들어, 여러 계층의 CNN 네트워크를 포함한다. 디코더는 이러한 특징맵을 입력으로 하여, 입력 이미지 자체를 재구성한다. 상기 요구사항에 부합되는 네트워크 구조는 모두 구조 분석 네트워크로 사용될 수 있다. 적대적 훈련의 참조 정보로서, 상기 차이 손실은 구조 특징에 기반하여 결정되며, 예를 들어, 예측된 목표 이미 지의 구조 특징 및 제2 샘플 이미지의 구조 특징 사이의 차이를 통해 차이 손실을 결정하며, 본 출원의 실시예 에서 제안된 구조 특징은 하나의 위치를 중심으로 하는 로컬 영역과 그 주변 영역 사이의 정규화된 상관 관계로 간주될 수 있다. 하나의 선택적인 실시형태로서, 본 출원의 실시예는 UNet 구조를 사용할 수 있다. 상기 구조의 인코더는 3 개의 컨볼루션 모듈을 포함하고, 각 모듈은 2 개의 컨볼루션 계층 및 하나의 평균 풀링 계층을 포함한다. 따라서, 하 나의 컨볼루션 모듈을 통과할 때마다, 해상도는 절반이 되고, 최종적으로 크기가 원래 이미지 크기의 1/2, 1/4 및 1/8인 특징맵을 얻는다. 디코더는 3 개의 업샘플링 계층을 포함하며, 각 계층이 이전 계층의 출력을 업샘플 링한 후, 2 개의 컨볼루션 계층을 통과하며, 마지막 계층의 출력은 원래 해상도이다. 단계 240에 있어서, 차이 손실에 기반하여 이미지 생성 네트워크 및 구조 분석 네트워크에 대해 적대적 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득한다. 하나의 선택적인 실시형태로서, 훈련 단계에서, 이미지 생성 네트워크 및 구조 분석 네트워크를 이용하여 적대 적 훈련을 수행함으로써, 입력 이미지는 이미지 생성 네트워크를 통과하고, 예를 들어, 3D 이미지 생성에 적용 될 때, 하나의 시점에서의 이미지를 이미지 생성 네트워크에 입력하여, 상기 이미지가 다른 시점에서의 생성 이 미지를 얻는다. 생성 이미지는 상기 시점에서의 실제 이미지와 동일한 구조 분석 네트워크에 입력되어, 각자의 스케일 특징맵을 얻는다. 각 스케일에서, 각자의 특징 상관성 표현은, 상기 스케일에서의 구조 표현으로 계산된 다. 훈련 과정은 적대적 방식으로 수행되며, 생성 이미지와 실제 이미지의 구조 표현 사이의 거리를 지속적으로 확대해나가는 동시에, 이미지 생성 네트워크에 의해 획득된 생성 이미지가 가능한 상기 거리를 작게 하도록 구 조 분석 네트워크에 요구한다. 도 3은 본 출원의 실시예에서 제공한 이미지 생성 네트워크의 훈련 방법의 또 다른 프로세스 모식도이다. 상기 실시예에서, 차이 손실은 제1 구조 차이 손실 및 특징 손실을 포함한다. 상기 도 1 및 도 2 중 적어도 하나에 도시된 실시예에서 단계 130 및 단계 230 중 적어도 하나는 하기의 단계를 포함한다. 단계 302에 있어서, 구조 분석 네트워크에 기반하여 예측된 목표 이미지 및 제2 샘플 이미지에 대해 처리를 수 행함으로써, 예측된 목표 이미지와 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정한다. 단계 304에 있어서, 구조 분석 네트워크에 기반하여 예측된 목표 이미지와 제2 샘플 이미지 사이의 특징 손실을 결정한다. 본 출원의 실시예에서, 구조 분석 네트워크를 통해 목표 이미지 및 제2 샘플 이미지(예를 들어, 제1 샘플 이미 지에 대응하는 실제 이미지)에 대해 처리를 수행함으로써, 복수 개의 스케일의 특징맵을 각각 획득할 수 있고, 각 스케일의 특징맵에서의 각 위치의 구조 특징에 대해, 목표 이미지에 대응하는 복수 개의 특징맵에서의 각 위 치의 구조 특징 및 제2 샘플 이미지에 대응하는 복수 개의 특징맵에서의 각 위치의 구조 특징에 기반하여, 제1 구조 차이 손실을 결정하며; 특징 손실은 예측된 목표 이미지에 대응하는 복수 개의 특징맵에서의 각 위치 및 제2 샘플 이미지에 대응하는 복수 개의 특징맵에서의 각 위치에 기반하여 결정된다. 하나의 실시형태로서, 단계 302는, 구조 분석 네트워크에 기반하여 예측된 목표 이미지에 대해 처리를 수행함으 로써, 예측된 목표 이미지에서 적어도 하나의 위치의 적어도 하나의 제1 구조 특징을 결정하는 단계; 구조 분석 네트워크에 기반하여 제2 샘플 이미지에 대해 처리를 수행함으로써, 제2 샘플 이미지에서 적어도 하나의 위치의 적어도 하나의 제2 구조 특징을 결정하는 단계; 및 적어도 하나의 제1 구조 특징 및 적어도 하나의 제2 구조 특 징에 기반하여, 예측된 목표 이미지와 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하는 단계를 포함한다. 본 출원의 실시예는 구조 분석 네트워크를 통해 예측된 목표 이미지 및 제2 샘플 이미지에 대해 각각 처리를 수 행함으로써, 예측된 목표 이미지에 대해 적어도 하나의 특징맵을 획득하고, 각 특징맵에서의 각 위치에 대해 하 나의 제1 구조 특징을 획득하며, 즉 적어도 하나의 제1 구조 특징을 획득하며; 마찬가지로 제2 샘플 이미지에 대해 적어도 하나의 제2 구조 특징을 획득하며, 본 출원의 실시예에서의 제1 구조 차이 손실은 각 스케일에서의 각 위치에 대응하는 목표 이미지의 제1 구조 특징 및 제2 샘플 이미지의 제2 구조 특징 사이의 차이를 통계함으 로써 획득되고, 각 스케일에서의 동일한 위치에 대응하는 제1 구조 특징 및 제2 구조 특징 사이의 구조 차이를 각각 계산하여, 두 개의 이미지 사이의 구조 차이 손실을 결정한다. 예를 들어, 하나의 예에서, 본 출원의 실시예를 3D 이미지 생성 네트워크의 훈련에 적용하고, 즉 이미지 생성 네트워크는 좌안 이미지(샘플 이미지에 대응함)에 기반하여 우안 이미지(목표 이미지에 대응함), 입력된 좌안 이미지를 x로, 생성된 우안 이미지를 y로, 실제 우안 이미지를 로 가정한다. 하기의 식 을 통해 계산할 수 있다. 식 여기서, 는 제1 구조 차이 손실을 나타내고, 는 생성된 우안 이미지 y 중 하나의 스케일의 특징맵에 서의 위치 p의 제1 구조 특징을 나타내며, 는 실제 우안 이미지 중 하나의 스케일의 특징맵에서의 위치 p 의 제2 구조 특징을 나타내며, P는 모든 스케일의 특징맵에서의 모든 위치를 나타내며, 은 와 사이의 거리 을 나타낸다. 훈련 단계에서, 구조 분석 네트워크는 상기 식으로 표현된 구조 거리를 최대화하는 하나의 특징 공간을 찾는다. 이와 동시에, 이미지 생성 네트워크는 실제 오른쪽 이미지와 최대한 유사한 구조를 생성함으로써, 구조 분석 네 트워크가 양자의 차이를 구별하는 것을 어렵게 한다. 적대적 훈련을 통해, 상이한 계층의 구조 차이를 발견하고, 이미지 생성 네트워크를 지속적으로 수정할 수 있다. 하나의 실시형태로서, 구조 분석 네트워크에 기반하여 예측된 목표 이미지에 대해 처리를 수행함으로써, 예측된 목표 이미지에서 적어도 하나의 위치의 적어도 하나의 제1 구조 특징을 결정하는 단계는, 구조 분석 네트워크에 기반하여 예측된 목표 이미지에 대해 처리를 수행함으로써, 예측된 목표 이미지의 적어도 하나의 스케일의 제1 특징맵을 획득하는 단계; 각 제1 특징맵에 대해, 제1 특징맵에서 적어도 하나의 위치 중 각 위치의 특징과 위치 의 인접 영역 특징 사이의 코사인 거리에 기반하여, 예측된 목표 이미지의 적어도 하나의 제1 구조 특징을 획득 하는 단계를 포함한다. 여기서, 제1 특징맵에서의 각 위치는 하나의 제1 구조 특징에 대응하고, 인접 영역 특징은 위치를 중심으로 하 여 적어도 2 개의 위치를 포함하는 영역 내의 각 특징이다. 하나의 실시형태로서, 본 출원의 실시예에서의 인접 영역 특징은 각 위치 특징을 중심으로 하고, 크기가 K*K인 영역 내의 각 특징으로 표현될 수 있다. 하나의 선택적인 예에서, 본 출원의 실시예를 3D 이미지 생성 네트워크의 훈련에 적용하고, 즉 이미지 생성 네 트워크는 좌안 이미지(샘플 이미지에 대응함)에 기반하여 우안 이미지(목표 이미지에 대응함), 입력된 좌안 이 미지를 x로, 생성된 우안 이미지를 y로, 실제 우안 이미지를 로 가정한다. y와 를 구조 분석 네트워크에 각 각 입력한 후, 멀티 스케일 특징맵을 얻는다. 이하 어느 한 스케일만 예로 들며, 다른 스케일의 처리 방법은 유 사하다. 상기 스케일에서, 생성된 오른쪽 이미지와 실제 오른쪽 이미지의 특징맵을 각각 f와 로 가정한다. 생 성된 오른쪽 이미지 특징맵에서의 어느 한 픽셀 위치 p에 대해, f(p)는 상기 위치의 특징을 나타낸다. 상기 스 케일에서, 위치 p의 제1 구조 특징의 획득은 하기 식 에 기반하여 구현될 수 있다. 식 여기서, 는 위치 p를 중심으로 하고, 크기가 kХk인 영역 내의 위치 세트를 나타내고, q는 위치 세트 중의 하나의 위치이고, f(q)는 위치 q의 특징이며; 는 벡터의 놈이고, vec는 벡터화를 나타낸다. 상기 식 으로부터 특징맵에서의 위치 p와 그 주변 인접 위치의 코사인 거리를 계산한다. 선택적으로, 본 출원의 실시예 는 윈도우 크기 k를 3으로 설정할 수 있다. 하나의 실시형태로서, 구조 분석 네트워크에 기반하여 제2 샘플 이미지에 대해 처리를 수행함으로써, 제2 샘플 이미지에서 적어도 하나의 위치의 적어도 하나의 제2 구조 특징을 결정하는 단계는, 구조 분석 네트워크에 기반 하여 제2 샘플 이미지에 대해 처리를 수행함으로써, 제2 샘플 이미지의 적어도 하나의 스케일에서의 제2 특징맵 을 획득하는 단계; 및 각 제2 특징맵에 대해, 제2 특징맵에서 적어도 하나의 위치 중 각 위치의 특징과 위치의 인접 영역 특징 사이의 코사인 거리에 기반하여, 제2 샘플 이미지의 적어도 하나의 제2 구조 특징을 획득하는 단계를 포함한다. 여기서, 제2 특징맵에서의 각 위치는 하나의 제2 구조 특징에 대응한다. 하나의 선택적인 예에서, 본 출원의 실시예를 3D 이미지 생성 네트워크의 훈련에 적용하고, 즉 이미지 생성 네 트워크는 좌안 이미지(제1 샘플 이미지에 대응함)에 기반하여 우안 이미지(예측된 목표 이미지에 대응함)를 생 성하고, 입력된 좌안 이미지를 x로, 생성된 우안 이미지를 y로, 실제 우안 이미지를 로 가정한다. y와 를 구조 분석 네트워크에 각각 입력한 후, 멀티 스케일 특징맵을 얻는다. 이하 어느 한 스케일만 예로 들며, 다른 스케일의 처리 방법은 유사하다. 상기 스케일에서, 생성된 오른쪽 이미지와 실제 오른쪽 이미지의 특징맵을 각 각 f와 로 가정한다. 실제 오른쪽 이미지 특징맵에서의 어느 한 픽셀 위치 p에 대해, 는 상기 위치의 특 징을 나타낸다. 상기 스케일에서, 위치 p의 제2 구조 특징의 획득은 하기 식 에 기반하여 구현될 수 있다. 식 여기서, 는 위치 p를 중심으로 하고, 크기가 kХk인 영역 내의 위치 세트를 나타내고, q는 위치 세트 중의 하나의 위치이고, 는 위치 q의 특징이며; 는 벡터의 놈이고, vec는 벡터화를 나타낸다. 상기 식 으로부터 특징맵에서의 위치 p와 그 주변 인접 위치의 코사인 거리를 계산한다. 선택적으로, 본 출원의 실시예 는 윈도우 크기 k를 3으로 설정할 수 있다. 하나의 실시형태로서, 제1 특징맵에서의 각 위치와 제2 특징맵에서의 각 위치 사이에는 대응 관계가 존재하고, 적어도 하나의 제1 구조 특징 및 적어도 하나의 제2 구조 특징에 기반하여, 예측된 목표 이미지와 제2 샘플 이 미지 사이의 제1 구조 차이 손실을 결정하는 단계는, 대응 관계가 존재하는 위치에 대응하는 제1 구조 특징과 제2 구조 특징 사이의 거리를 계산하는 단계; 예측된 목표 이미지에 대응하는 모든 제1 구조 특징과 제2 구조 특징 사이의 거리에 기반하여, 예측된 목표 이미지와 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하는 단계를 포함한다. 본 출원의 실시예에서 제1 구조 차이 손실을 계산하여 획득하는 과정은 상기 실시예의 식 을 참조할 수 있고, 상기 실시예에서 식 및 식 에 기반하여 목표 이미지 y 중 하나의 스케일에서의 특징맵에서 위치 p 의 제1 구조 특징 c(p), 및 실제 이미지 중 하나의 스케일의 특징맵에서 위치 p의 제2 구조 특징 를 각 각 획득할 수 있으며; 제1 구조 특징과 제2 구조 특징 사이의 거리는 거리 일 수 있다. 하나 또는 복수 개의 선택적인 실시예에서, 단계 304는 구조 분석 네트워크에 기반하여 예측된 목표 이미지 및 제2 샘플에 대해 이미지 처리를 수행함으로써, 예측된 목표 이미지의 적어도 하나의 스케일의 제1 특징맵 및 제2 샘플 이미지의 적어도 하나의 스케일에서의 제2 특징맵을 획득하는 단계; 및 적어도 하나의 제1 특징맵 및 적어도 하나의 제2 특징맵에 기반하여, 예측된 목표 이미지와 제2 샘플 이미지 사이의 특징 손실을 결정하는 단 계를 포함한다. 본 출원의 실시예에서의 특징 손실은 예측된 목표 이미지와 제2 샘플 이미지에 의해 획득된, 대응하는 특징맵 사이의 차이에 따라 결정되며, 이는 상기 실시예에서의 구조 특징에 기반하여 제1 구조 차이 손실을 획득하는 것과 상이하며; 선택적으로, 여기서, 제1 특징맵에서의 각 위치와 제2 특징맵에서의 각 위치 사이에는 대응 관 계가 존재하고, 적어도 하나의 제1 특징맵 및 적어도 하나의 제2 특징맵에 기반하여, 예측된 목표 이미지와 제2 샘플 이미지 사이의 특징 손실을 결정하는 단계는, 대응 관계가 존재하는 위치에 대응하는 제1 특징맵에서의 특 징과 제2 특징맵에서의 특징 사이의 거리를 계산하는 단계; 및 제1 특징맵에서의 특징과 제2 특징맵에서의 특징 사이의 거리에 기반하여, 예측된 목표 이미지와 제2 샘플 이미지 사이의 특징 손실을 결정하는 단계를 포함한다. 하나의 선택적인 실시예에서, 각 위치에 대응하는 제1 특징맵에서의 특징과 제2 특징맵에서의 특징 사이의 거리 을 계산하고, 거리 을 통해 특징 손실을 결정한다. 선택적으로, 예측된 목표 이미지를 y로, 제2 샘플 이미 지를 로 가정한다. y와 를 구조 분석 네트워크에 각각 입력한 후, 멀티 스케일 특징맵을 얻는다. 이하 어느 한 스케일만 예로 들며, 다른 스케일의 처리 방법은 유사하다. 상기 스케일에서, 예측된 목표 이미지와 제2 샘 플 이미지의 특징맵을 각각 f와 로 가정한다. 제2 샘플 이미지의 특징맵에서의 어느 한 위치 p에 대해, (p) 는 상기 위치의 특징을 나타내고; 이 경우, 하기 식 에 기반하여 특징 손실을 획득할 수 있다. 식 여기서, 는 예측된 목표 이미지와 제2 샘플 이미지의 특징 손실을 나타내며, f(p)는 제1 특징맵에서 위 치 p의 특징이고, 는 제2 특징맵에서 위치 p의 특징을 나타낸다. 하나의 실시형태로서, 차이 손실은 색상 손실을 더 포함할 수 있고, 단계 240을 실행하기 전에, 예측된 목표 이 미지와 제2 샘플 이미지 사이의 색상 차이에 기반하여, 이미지 생성 네트워크의 색상 손실을 결정하는 단계를 더 포함한다. 본 출원의 실시예는 색상 손실을 통해 예측된 목표 이미지와 제2 샘플 이미지 사이의 색상 차이를 구현하여, 예 측된 목표 이미지와 제2 샘플 이미지 사이의 색상이 최대한 비슷하며, 선택적으로, 예측된 목표 이미지가 y이고, 제2 샘플 이미지를 로 가정하며, 색상 손실은 하기 식 에 기반하여 획득된다. 식 여기서, 는 예측된 목표 이미지와 제2 샘플 이미지의 색상 손실을 나타내고, 은 예측된 목표 이미지 y와 제2 샘플 이미지 사이의 거리 을 나타낸다. 본 실시예에서, 단계 240은, 제1 반복에서, 제1 구조 차이 손실, 특징 손실 및 색상 손실에 기반하여 이미지 생 성 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계; 및 제2 반복에서, 제1 구조 차이 손실에 기반 하여 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행하며; 훈련 정지 조건을 만족시킬 때까지 조 정을 수행하여, 훈련된 이미지 생성 네트워크를 획득하는 단계를 포함한다. 여기서, 제1 반복 및 제2 반복은 연속적으로 수행되는 2 회의 반복이다. 선택적으로, 훈련 정지 조건은 미리 설 정된 반복 횟수 또는 이미지 생성 네트워크에 의해 생성된 예측된 목표 이미지와 제2 샘플 이미지 사이의 차이 가 설정값보다 작은 것 등일 수 있으며, 본 출원의 실시예는 구체적으로 어느 훈련 정지 조건을 사용할지에 대 해 한정하지 않는다. 적대적 훈련의 목표는 이미지 생성 네트워크에 의해 획득된 예측된 목표 이미지와 제2 샘플 이미지 사이의 차이 를 감소시키는 것이다. 적대적 훈련은 일반적으로 교대 훈련의 방식을 사용하여 구현되며, 본 출원의 실시예에 서, 이미지 생성 네트워크 및 구조 분석 네트워크에 대해 교대로 훈련을 수행하여, 요구사항에 부합되는 이미지 생성 네트워크를 획득하며, 선택적으로, 이미지 생성 네트워크의 네트워크 파라미터데 대한 조정은 다음 식 을 통해 수행될 수 있다. 식 여기서, 는 이미지 생성 네트워크에서 최적화될 파라미터를 나타내고, 는 이미지 생성 네트워크에 대 응하는 전체 손실을 나타내고, 는 이미지 생성 네트워크의 파라미터를 조정함으로써 감소된 이미 지 생성 네트워크의 전체 손실을 나타내고, , , 는 이미지 생성 네트워크에 의해 생성 된 예측된 목표 이미지 및 제2 샘플 이미지 사이의 색상 손실, 제1 구조 차이 손실 및 특징 손실을 나타내며, 선택적으로, 이러한 손실의 획득은 상기 식 , 식 및 식 를 참조하여 결정될 수 있거나, 다른 방식으 로 이 세 가지 손실을 획득할 수 있으며, 본 출원의 실시예는 색상 손실, 제1 구조 차이 손실 및 특징 손실을 획득하는 구체적인 방식에 대해 한정하지 않는다. 하나의 실시형태로서, 구조 분석 네트워크의 네트워크 파라미터 조정을 수행하는 단계는 하기의 식 을 통해 수행될 수 있다. 식 여기서, 는 구조 분석 네트워크에서 최적화될 파라미터를 나타내고, 는 구조 분석 네트워크에 대응하 는 전체 손실을 나타내고, 는 구조 분석 네트워크의 파라미터를 조정함으로써 증가된 구조 분석 네트워크의 전체 손실을 나타내고, 는 구조 분석 네트워크의 제1 구조 차이 손실을 나타내고, 선택적으 로, 제1 구조 차이 손실의 획득은 상기 식 을 참조하여 결정될 수 있거나, 다른 방식으로 획득될 수 있으며, 본 출원의 실시예는 제1 구조 차이 손실의 구체적인 방식에 대해 한정하지 않는다. 하나 또는 복수 개의 선택적인 실시예에서, 목표 이미지와 실제 이미지 사이의 구조 차이 손실을 결정하기 전에, 제2 샘플 이미지에 소음을 추가하여, 소음 이미지를 획득하는 단계; 및 소음 이미지 및 제2 샘플 이미지 에 기반하여 제2 구조 차이 손실을 결정하는 단계를 포함한다. 예측된 목표 이미지는 샘플 이미지로부터 생성되는 반면, 제2 샘플 이미지는 일반적으로 조명 차이를 가지고 소 음의 영향을 받으므로, 생성된 예측된 목표 이미지와 제2 샘플 이미지 사이에 일정한 분포 차이를 초래한다. 구 조 분석 네트워크가 장면 구조 정보가 아닌 이러한 차이에 주목하는 것을 방지하도록, 본 출원의 실시예는 훈련 과정에서 소음에 대한 저항 메커니즘을 추가한다. 하나의 실시형태로서, 소음 이미지 및 제2 샘플 이미지에 기반하여 제2 구조 차이 손실을 결정하는 단계는, 구 조 분석 네트워크에 기반하여 소음 이미지에 대해 처리를 수행함으로써, 소음 이미지에서 적어도 하나의 위치의적어도 하나의 제3 구조 특징을 결정하는 단계; 구조 분석 네트워크에 기반하여 제2 샘플 이미지에 대해 처리를 수행함으로써, 제2 샘플 이미지에서 적어도 하나의 위치의 적어도 하나의 제2 구조 특징을 결정하는 단계; 및 적어도 하나의 제3 구조 특징 및 적어도 하나의 제2 구조 특징에 기반하여, 소음 이미지와 제2 샘플 이미지 사 이의 제2 구조 차이 손실을 결정하는 단계를 포함한다. 하나의 실시형태로서, 소음 이미지는 제2 샘플 이미지에 기반하여 처리를 수행함으로써 얻으며, 예를 들어, 제2 샘플 이미지에 대해 인공 소음을 추가하여, 소음 이미지를 생성하며, 소음을 추가하는 방식은 다양하며, 예를 들어, 랜덤 가우시안 소음을 추가하고, 실제 이미지(제2 샘플 이미지)에 대해 가우시안 블러링을 수행하고, 콘 트라스트가 변경되는 등이다. 본 출원의 실시예는 소음을 추가한 후 획득된 소음 이미지에 대해 제2 샘플 이미 지 중 구조에 영향을 미치지 않는 속성(예를 들어, 색상, 텍스처 등) 만을 변경하고, 제2 샘플 이미지 중의 모 양 구조는 변경되지 않으며, 본 출원의 실시예는 소음 이미지를 획득하기 위한 구체적인 방식에 대해 한정하지 않는다. 본 출원의 실시예에서의 구조 분석 네트워크는 컬러 이미지를 입력으로 하는 반면, 기존의 구조 분석 네트워크 는 주로 마스크 이미지 또는 스레이 스케일 이미지를 입력으로 한다. 컬러 이미지와 같은 고차원 신호를 처리할 때, 환경 소음의 간섭을 더 쉽게 받는다. 따라서, 본 출원의 실시예는 제2 구조 차이 손실을 도입하여 구조 특 징의 소음 견고성(robustness)을 향상시킨다. 기존 구조가 적대적 훈련 방법에 대해 이러한 소음 방지 메커니즘 이 없는 단점을 보완한다. 하나의 실시형태로서, 구조 분석 네트워크에 기반하여 소음 이미지에 대해 처리를 수행함으로써, 소음 이미지에 서 적어도 하나의 위치의 적어도 하나의 제3 구조 특징을 결정하는 단계는, 구조 분석 네트워크에 기반하여 소 음 이미지에 대해 처리를 수행함으로써, 소음 이미지의 적어도 하나의 스케일의 제3 특징맵을 획득하는 단계; 각 제3 특징맵에 대해, 제3 특징맵에서 적어도 하나의 위치 중 각 위치의 특징과 위치의 인접 영역 특징 사이의 코사인 거리에 기반하여, 소음 이미지의 적어도 하나의 제3 구조 특징을 획득하는 단계를 포함한다. 여기서, 제3 특징맵에서의 각 위치는 하나의 제3 구조 특징에 대응하고, 인접 영역 특징은 위치를 중심으로 하 여 적어도 2 개의 위치를 포함하는 영역 내의 각 특징이다. 본 출원의 실시예에서, 제3 구조 특징을 결정하는 방식은 제1 구조 특징을 획득하는 방식과 유사하며, 선택적으 로, 하나의 예에서, 입력된 제1 샘플 이미지를 x로, 제2 샘플 이미지를 로, 소음 이미지를 로 가정한다. 과 를 구조 분석 네트워크에 각각 입력한 후, 멀티 스케일 특징을 얻는다. 이하 어느 한 스케일만 예로 들며, 다른 스케일의 처리 방법은 유사하다. 상기 스케일에서, 소음 이미지와 제2 샘플 이미지의 특징맵을 각각 와 로 가정한다. 소음 이미지의 특징맵에서의 어느 한 픽셀 위치 p에 있어서, 는 상기 위치의 특징을 나타낸 다. 상기 스케일에서, 위치 p의 제3 구조 특징의 획득은 하기 식 에 기반하여 구현될 수 있다. 식 여기서, 은 위치 p를 중심으로 하고, 크기가 kХk인 영역 내의 위치 세트를 나타내고, q는 위치 세트 중의 하나의 위치이고, 는 위치 q의 특징이며; 는 벡터의 놈이고, vec는 벡터화를 나타낸다. 상기 식 으로부터 특징맵에서의 위치 p와 그 주변 인접 위치의 코사인 거리를 계산한다. 선택적으로, 본 출원의 실시예 는 윈도우 크기 k를 3으로 설정할 수 있다. 하나의 실시형태로서, 제3 특징맵에서의 각 위치와 제2 특징맵에서의 각 위치 사이에는 대응 관계가 존재하고, 적어도 하나의 제3 구조 특징 및 적어도 하나의 제2 구조 특징에 기반하여, 소음 이미지와 제2 샘플 이미지 사 이의 제2 구조 차이 손실을 결정하는 단계는, 대응 관계가 존재하는 위치에 대응하는 제3 구조 특징과 제2 구조 특징 사이의 거리를 계산하는 단계; 및 소음 이미지에 대응하는 모든 제3 구조 특징과 제2 구조 특징 사이의 거 리에 기반하여, 소음 이미지와 제2 샘플 이미지 사이의 제2 구조 차이 손실을 결정하는 단계를 포함한다. 본 출원의 실시예에서, 제2 구조 차이 손실을 획득하는 과정과 제1 구조 차이 손실을 획득하는 과정은 유사하며, 제1 구조 차이 손실을 획득하는 동안의 예측된 목표 이미지의 제1 구조 특징만이 본 출원의 실시예에 서의 소음 이미지의 제3 구조 특징으로 대체된다. 선택적으로, 하기 식 에 기반하여 제2 구조 차이 손실을 획득할 수 있다. 식 여기서, 는 제2 구조 차이 손실을 나타내고, 는 위치 p의 제3 구조 특징을 나타내고, P는 모든 스 케일의 특징맵에서의 모든 위치를 나타내고, 는 위치 p의 제2 구조 특징(상기 식 에 기반하여 획득됨)을 나타내며, 는 와 사이의 거리 을 나타낸다. 하나 또는 복수 개의 선택적인 실시예에서, 단계 240은, 제3 반복에서, 제1 구조 차이 손실에 기반하여, 특징 손실 및 색상 손실에 기반하여 이미지 생성 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계; 제4 반복에서, 제1 구조 차이 손실 및 제2 구조 차이 손실에 기반하여 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계; 및 훈련 정지 조건을 만족시킬 때까지 조정을 수행하여, 훈련된 이미지 생성 네트 워크를 획득하는 단계를 포함한다. 여기서, 제3 반복 및 제4 반복은 연속적으로 수행되는 2 회의 반복이다. 소음 이미지에 대응하는 제2 구조 차이 손실을 획득한 후, 구조 분석 네트워크의 성능을 향상시키기 위해, 구조 분석 네트워크의 네트워크 파라미터를 조정할 때, 제2 구조 차이 손실을 추가하며, 이 경우, 구조 분석 네트워크의 네트워크 파라미터에 대한 조정은 하기 식 을 통해 수행될 수 있다. 식 여기서, 는 구조 분석 네트워크에서 최적화될 파라미터를 나타내고, 는 구조 분석 네트워크에 대응 하는 전체 손실을 나타내고, 는 구조 분석 네트워크의 파라미터를 조정함으로써 증가된 구조 분석 네트워크의 전체 손실을 나타내고, 는 구조 분석 네트워크의 제1 구조 차이 손실을 나타내며, 는 구조 분석 네트워크의 제2 구조 차이 손실을 나타내고, 은 구조 분석 네트워크의 파라미터 조정 중의 제2 구조 차이 손실의 비율을 조정하기 위한 하나의 설정된 상수를 나타내며, 선택적으로, 제1 구조 차이 손실 및 제2 구조 차이 손실의 획득은 각각 상기 식 및 식 를 참조하여 결정되거나, 다른 방식을 통해 획득되며, 본 출원의 실시예는 제1 구조 차이 손실의 구체적인 방식에 대해 한정하지 않는다. 하나 또는 복수 개의 선택적인 실시예에서, 구조 분석 네트워크에 기반하여 예측된 목표 이미지에 대해 처리를 수행함으로써, 예측된 목표 이미지에서 적어도 하나의 위치의 적어도 하나의 제1 구조 특징을 결정한 후, 이미 지 재구성 네트워크에 기반하여 적어도 하나의 제1 구조 특징에 대해 이미지 재구성 처리를 수행함으로써, 제1 재구성 이미지를 획득하는 단계; 및 제1 재구성 이미지와 예측된 목표 이미지에 기반하여 제1 재구성 손실을 결 정하는 단계를 더 포함한다. 본 실시예에서, 구조 분석 네트워크의 성능을 향상시키기 위해, 구조 분석 네트워크 후에 이미지 재구성 네트워 크를 추가하며, 선택적으로, 도 4를 참조하면, 구조 분석 네트워크의 출력단에 이미지 재구성 네트워크를 연결 하여, 상기 이미지 재구성 네트워크가 구조 분석 네트워크의 출력을 입력으로 하고, 구조 분석 네트워크에 입력 된 이미지에 대해 재구성을 수행하며, 예를 들어, 도 4에 도시된 3D 이미지 적용 장면에서, 이미지 생성 네트워 크에 의해 생성된 우안 이미지(상기 실시예에서의 예측된 목표 이미지에 대응함) 및 실제 우안 이미지(상기 실 시예에서의 제2 샘플 이미지에 대응함)에 대해 재구성을 수행하여, 재구성된 생성된 우안 이미지와 이미지 생성 네트워크에 의해 생성된 우안 이미지 사이의 차이, 및 재구성된 실제 우안 이미지와 입력된 좌안 이미지에 대응 하는 실제 우안 이미지 사이의 차이로 구조 분석 네트워크의 성능을 측정하며, 즉 제1 재구성 손실 및 제2 재구 성 손실을 추가함으로써 구조 분석 네트워크의 성능을 향상시키고, 구조 분석 네트워크의 훈련 속도를 증가시킨 다. 하나 또는 복수 개의 선택적인 실시예에서, 구조 분석 네트워크에 기반하여 제2 샘플 이미지에 대해 처리를 수 행함으로써, 제2 샘플 이미지에서 적어도 하나의 위치의 적어도 하나의 제2 구조 특징을 결정한 후, 이미지 재 구성 네트워크에 기반하여 적어도 하나의 제2 구조 특징에 대해 이미지 재구성 처리를 수행함으로써, 제2 재구 성 이미지를 획득하는 단계; 및 제2 재구성 이미지 및 제2 샘플 이미지에 기반하여 제2 재구성 손실을 결정하는 단계를 더 포함한다. 위의 실시예를 참조하면, 본 실시예에서의 이미지 재구성 네트워크는 제2 샘플 이미지에 기반하여 구조 분석 네 트워크에 의해 획득된 제2 구조 특징에 대해 재구성을 수행하여, 획득된 제2 재구성 이미지와 제2 샘플 이미지사이의 차이로 이미지 재구성 네트워크 및 구조 분석 네트워크의 성능을 측정하여, 제2 재구성 손실을 통해 구 조 분석 네트워크의 성능을 향상시킬 수 있다. 하나의 실시형태로서, 단계 240은, 제5 반복에서, 제1 구조 차이 손실, 특징 손실 및 색상 손실에 기반하여 이 미지 생성 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계; 제6 반복에서, 제1 구조 차이 손실, 제 2 구조 차이 손실, 제1 재구성 손실 및 제2 재구성 손실에 기반하여 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행하는 단계; 및 훈련 정지 조건을 만족시킬 때까지 조정을 수행하여, 훈련된 이미지 생성 네트 워크를 획득하는 단계를 포함한다. 여기서, 제5 반복 및 제6 반복은 연속적으로 수행되는 2 회의 반복이다. 본 출원의 실시예에서, 이미지 생성 네 트워크의 파라미터에 대해 조정을 수행하기 위한 손실은 변하지 않고, 구조 분석 네트워크의 성능에 대해서만 성능을 향상시키며, 구조 분석 네트워크와 이미지 생성 네트워크 사이는 적대적 훈련되므로, 구조 분석 네트워 크의 성능을 향상시킴으로써, 이미지 생성 네트워크의 훈련을 가속화시킬 수 있다. 하나의 선택적인 예에서, 하 기 식 을 이용하여 제1 재구성 손실 및 제2 재구성 손실을 획득할 수 있다. 식 여기서, 는 제1 재구성 손실 및 제2 재구성 손실의 합을 나타내고, y는 이미지 생성 네트워크에 의해 출 력된 예측된 목표 이미지를 나타내고, 는 제2 샘플 이미지를 나타내고, 는 이미지 재구성 네트워크에 의해 출력된 제1 재구성 이미지를 나타내며, 은 이미지 재구성 네트워크에 의해 출력된 제2 재구성 이 미지를 나타내고, 은 제1 재구성 손실에 대응하는, 예측된 목표 이미지 y와 제1 재구성 이미지 사이의 거리 을 나타내며; 은 제2 재구성 손실에 대응하는, 제2 샘플 이미지와 제2 재구성 이 미지 사이의 거리 을 나타낸다. 도 4는 본 출원의 실시예에서 제공한 이미지 생성 네트워크의 훈련 방법에 관련된 네트워크 구조 모식도이다. 도 4에 도시된 바와 같이, 본 실시예에서 이미지 생성 네트워크의 입력은 좌안 이미지이고, 이미지 생성 네트워 크는 좌안 이미지에 기반하여 생성된 우안 이미지(상기 실시예에서의 예측된 목표 이미지에 대응함)를 획득하며; 생성된 우안 이미지, 실제 우안 이미지 및 실제 우안 이미지(상기 실시예의 제2 샘플 이미지에 대응 함)에 기반하여 추가된 소음 이미지는 각각 동일한 구조 분석 네트워크에 입력되며, 구조 분석 네트워크를 통해 생성된 우안 이미지 및 실제 우안 이미지에 대해 처리를 수행함으로써, 특징 손실(이미지 중의 특징 매칭 손실 에 대응함), 제1 구조 차이 손실(이미지 중의 구조 손실에 대응함), 제2 구조 차이 손실(이미지 중의 다른 구조 손실에 대응함)을 획득하며; 구조 분석 네트워크 후에 이미지 재구성 네트워크를 더 포함하며, 이미지 재구성 네트워크는 생성된 우안 이미지에 의해 생성된 특징을 새로운 생성된 우안 이미지로 재구성하고, 실제 우안 이 미지에 의해 생성된 특징을 새로운 실제 우안 이미지로 재구성한다. 하나 또는 복수 개의 선택적인 실시예에서, 단계 140 이후, 훈련된 이미지 생성 네트워크에 기반하여 처리될 이미지에 대해 처리를 수행함으로써, 목표 이미지를 획득하는 단계를 더 포함한다. 본 출원의 실시예에서 제공한 훈련 방법은, 구체적인 적용에서, 훈련된 이미지 생성 네트워크에 기반하여 입력 된 처리될 이미지에 대해 처리를 수행함으로써, 원하는 목표 이미지를 획득하고, 상기 이미지 생성 네트워크는 2D 이미지 비디오에서 3D 스테레오 이미지로의 전환, 높은 프레임 비디오 생성 등에 적용될 수 있으며, 알려진 하나의 뷰의 이미지가 이미지 생성 네트워크의 처리를 통해, 다른 뷰의 이미지를 획득하는 단계를 더 포함한다. 생성된 고품질의 우안 이미지는 다른 시각 작업에도 도움이 되며, 예를 들어, 양안 이미지(좌안 이미지 및 우안 이미지를 포함함)에 기반하여 깊이 추정을 구현한다. 선택적으로, 이미지 생성 네트워크를 2D 이미지 비디오에 서 3D 스테레오 이미지로 전환할 때, 처리될 이미지는 좌안 이미지를 포함하고; 목표 이미지는 좌안 이미지에 대응하는 우안 이미지를 포함한다. 스테레오 이미지를 생성하는 것 외에, 상기 방법은 다른 이미지/비디오의 생 성 작업에 적용될 수 있다. 예를 들어, 이미지의 임의의 새로운 시점 컨텐츠 생성, 키 프레임에 기반한 비디오 보간 등이다. 이러한 경우, 이미지 생성 네트워크를 목표 작업에 필요한 네트워크 구조로 교체하기만 하면 된다. 본 출원의 실시예에서 제공한 훈련 방법이 3 차원 이미지 생성 장면에 적용될 때, 이미지 생성 네트워크 및 구 조 분석 네트워크의 하나의 적대적 훈련은 하기 단계를 포함할 수 있다 1) 훈련 세트(복수 개의 샘플 이미지를 포함)로부터, m 개의 샘플 이미지를 포함한 왼쪽 이미지 , 및 이 에 대응하는 실제 오른쪽 이미지 를 샘플링한다. 2) 왼쪽 이미지를 이미지 생성 네트워크에 입력하여, 생성된 오른쪽 이미지 를 얻고; 각 실제 오른쪽 이 미지에 대해, 소음을 추가하여 소음 오른쪽 이미지 를 얻는다. 3) 생성된 오른쪽 이미지 , 실제 오른쪽 이미지 와 소음 오른쪽 이미지 를 구조 분석 네트 워크에 각각 입력하여, 구조 표현 특징 , , 및 을 계산한다. 4) 구조 분석 네트워크에 대해, 기울기 상승을 실행한다."}
{"patent_id": "10-2020-7012581", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "5) 이미지 생성 네트워크에 대해, 기울기 하강을 실행한다."}
{"patent_id": "10-2020-7012581", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, 감쇠 학습률 γ는 반복 횟수의 증가에 따라 점차 감소할 수 있고, 학습률을 통해 네트워크 손실이 네트 워크 파라미터 조정 중의 비율을 제어하고; 소음 오른쪽 이미지를 획득할 때, 추가된 소음 진폭은 반복할 때마 동일하거나, 반복 횟수의 증가에 따라 소음 진폭은 점차 감소된다. 도 5는 본 출원의 실시예에서 제공한 이미지 처리 방법의 하나의 프로세스 모식도이다. 상기 실시예 방법은 하 기 단계를 포함한다. 단계 510에 있어서, 3 차원 이미지 생성 장면에서, 좌안 이미지를 이미지 생성 네트워크에 입력하여, 우안 이미 지를 획득한다. 단계 520에 있어서, 좌안 이미지 및 우안 이미지에 기반하여 3 차원 이미지를 생성한다. 여기서, 이미지 생성 네트워크는 상기 실시예 중 어느 한 항에 따라 제공된 이미지 생성 네트워크의 훈련 방법 을 통해 훈련하여 획득된다. 본 출원의 실시예에서 제공한 이미지 처리 방법에서, 이미지 생성 네트워크를 통해 좌안 이미지에 대해 처리를 수행하여 대응하는 우안 이미지를 획득하고, 조명, 차단, 소음 등 환경적 요인에 의한 영향이 적어, 작은 시각 면적을 갖는 객체의 합성 정확도를 유지하고, 획득된 우안 이미지와 좌안 이미지를 통해 변형이 작고, 디테일 유지가 완전한 3 차원 이미지를 생성할 수 있다. 본 출원의 실시예에서 제공한 이미지 처리 방법은 영화 2D 에 서 3D로의 자동 전환에 적용될 수 있다. 수동의 3D 영화 전환은 높은 비용, 긴 제작 기간, 대량의 인건비가 필 요하다. 예를 들어, \"타이타닉\"의 3D 버전 전환 비용은 최대 1800만 달러이며, 후반 작업에 참여한 특수 효과 엔지니어가 300 여명이고, 75만 시간을 소비하였다. 자동의 2D에서 3D로의 알고리즘은 이러한 비용을 크게 줄이 고, 3D 영화 제작 프로세스를 가속화할 수 있다. 고품질의 3D 영화를 생성하는 하나의 중요한 요인은 구조가 왜 곡되지 않고, 비뚤어지지 않은 스테레오 이미지를 생성하고, 정확한 3D 볼륨감을 조성하여, 국부적 변형으로 인 한 시각의 불편함을 방지해야 한다. 따라서, 형상이 유지되는 스테레오 이미지 생성은 중요한 의미를 갖는다. 본 출원의 실시예에서 제공한 이미지 처리 방법은 3D 광고 산업에도 적용될 수 있다. 현재, 많은 도시에서 상업 구, 영화관 및 놀이터와 같은 시설에 3D 광고 디스플레이 화면을 설치했다. 고품질의 3D 광고를 생성하면, 브랜 드 홍보 품질을 강화하여, 고객이 더 우수한 현장 경험을 체험할 수 있다. 본 출원의 실시예에서 제공한 이미지 처리 방법은 3D 라이브 방송 산업에도 적용될 수 있다. 기존의 3D 라이브 방송은 방송주들에게 전문적인 양안 카메라를 구입하도록 요구하여, 업계 진입의 비용과 조건을 높인다. 고품질 자동 2D에서 3D로의 전환은, 진입 비용을 낮추고, 라이브 방송의 현장감과 인터랙션을 증가시킬 수 있다. 본 출원의 실시예에서 제공한 이미지 처리 방법은 또한 미래에 스마트폰 산업에 적용될 수 있다. 현재, 육안 3D 디스플레이 기능을 갖는 휴대폰은 핫이슈가 되었고, 일부 제조업체는 콘셉트폰 프로토타입을 설계하였다. 캡처 된 2D 이미지에서 자동으로 3D로 전환되며, 쇼셜 APP를 통해 사용자 간의 전파, 공유를 허용해, 모바일 단말에 기반한 인터랙션으로 하여금 새로운 사용자 체험을 갖도록 한다. 당업자는, 상기 방법 실시예를 구현하는 전부 또는 부분 단계는 프로그램 명령어와 관련된 하드웨어를 통해 완 료되고, 전술한 프로그램은 하나의 컴퓨터 판독 가능한 저장 매체에 저장되고, 상기 프로그램이 실행될 때, 상 기 방법 실시예를 포함한 단계를 실행하며; 전술한 저장 매체는, 판독 전용 메모리(ROM, Read-Only Memory), 랜 덤 액세스 메모리(RAM, Random Access Memory), 자기 디스크 또는 광 디스크 등 프로그램 코드를 저장할 수 있 는 다양한 매체를 포함한다. 도 6은 본 출원의 실시예에서 제공한 이미지 생성 네트워크의 훈련 장치의 하나의 구조 모식도이다. 상기 실시 예의 장치는 본 출원의 상기 각 방법에 따른 실시예를 구현하기 위한 것일 수 있다. 도 6에 도시된 바와 같이, 상기 실시예의 장치는, 샘플 이미지를 획득하도록 구성된 샘플 획득 유닛 - 샘플 이미지는 제1 샘플 이미지 및 제1 샘플 이미지에 대응하는 제2 샘플 이미지를 포함함 - ; 이미지 생성 네트워크에 기반하여 제1 샘플 이미 지에 대해 처리를 수행함으로써, 예측된 목표 이미지를 획득하도록 구성된 목표 예측 유닛; 예측된 목표 이 미지와 제2 샘플 이미지 사이의 차이 손실을 결정하도록 구성된 차이 손실 결정 유닛; 및 차이 손실에 기반 하여 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하도록 구성된 네 트워크 훈련 유닛을 포함한다. 본 출원의 상기 실시예에서 제공한 이미지 생성 네트워크의 훈련 장치에 기반하여, 샘플 이미지를 획득하고, 샘 플 이미지는 제1 샘플 이미지 및 제1 샘플 이미지에 대응하는 제2 샘플 이미지를 포함하며; 이미지 생성 네트워 크에 기반하여 제1 샘플 이미지에 대해 처리를 수행함으로써, 예측된 목표 이미지를 획득하며; 예측된 목표 이 미지와 제2 샘플 이미지 사이의 차이 손실을 결정하며; 차이 손실에 기반하여 이미지 생성 네트워크에 대해 훈 련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득하고, 차이 손실을 통해 예측된 목표 이미지와 제2 샘 플 이미지 사이의 구조 차이를 설명하여, 차이 손실로써 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 이 미지 생성 네트워크에 기반하여 생성된 이미지의 구조가 왜곡되지 않도록 보장한다. 하나 또는 복수 개의 선택적인 실시예에서, 차이 손실 결정 유닛은, 구체적으로 구조 분석 네트워크에 기반 하여 예측된 목표 이미지와 제2 샘플 이미지 사이의 차이 손실을 결정하도록 구성되고; 네트워크 훈련 유닛(6 4)은, 구체적으로 차이 손실에 기반하여 이미지 생성 네트워크 및 구조 분석 네트워크에 대해 적대적 훈련을 수 행함으로써, 훈련된 이미지 생성 네트워크를 획득하도록 구성된다. 하나의 실시형태로서, 훈련 단계에서, 이미지 생성 네트워크 및 구조 분석 네트워크를 이용하여 적대적 훈련을 수행하고, 입력 이미지는 이미지 생성 네트워크를 통과하며, 예를 들어, 3D 이미지 생성에 적용될 때, 하나의 시점에서의 이미지를 이미지 생성 네트워크에 입력하여, 상기 이미지가 다른 시점에서의 생성 이미지를 얻는다. 생성된 이미지는 상기 시점에서의 실제 이미지와 동일한 구조 분석 네트워크에 입력되어, 각각의 멀티 스케일 특징맵을 얻는다. 각 스케일에서, 각자의 특징 상관성 표현은, 상기 스케일에서의 구조 표현으로 계산된다. 훈 련 과정은 적대적 방식으로 수행되며, 생성 이미지와 실제 이미지의 구조 표현 사이의 거리를 지속적으로 확대 해나가는 동시에, 이미지 생성 네트워크에 의해 획득된 생성 이미지가 가능한 상기 거리를 작게 하도록 구조 분 석 네트워크에 요구한다. 하나의 실시형태로서, 차이 손실은 제1 구조 차이 손실 및 특징 손실을 포함한다. 차이 손실 결정 유닛은, 구조 분석 네트워크에 기반하여 예측된 목표 이미지 및 제2 샘플에 대해 이미지 처리를 수행함으로써, 예측된 목표 이미지와 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하도록 구성된 제1 구조 차이 결정 모듈; 구조 분석 네트워크에 기반하여 예측된 목표 이미지와 제2 샘플 이미지 사이의 특징 손실을 결정하도록 구성된 특징 손실 결정 모듈을 포함한다. 하나의 실시형태로서, 제1 구조 차이 결정 모듈은, 구조 분석 네트워크에 기반하여 예측된 목표 이미지에 대해 처리를 수행함으로써, 예측된 목표 이미지에서 적어도 하나의 위치의 적어도 하나의 제1 구조 특징을 결정하고; 구조 분석 네트워크에 기반하여 제2 샘플 이미지에 대해 처리를 수행함으로써, 제2 샘플 이미지에서 적어도 하 나의 위치의 적어도 하나의 제2 구조 특징을 결정하며; 적어도 하나의 제1 구조 특징 및 적어도 하나의 제2 구 조 특징에 기반하여, 예측된 목표 이미지와 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정하도록 구성된다. 하나의 실시형태로서, 제1 구조 차이 결정 모듈은, 구조 분석 네트워크에 기반하여 예측된 목표 이미지에 대해 처리를 수행함으로써, 예측된 목표 이미지에서 적어도 하나의 위치의 적어도 하나의 제1 구조 특징을 결정할 때, 구조 분석 네트워크에 기반하여 예측된 목표 이미지에 대해 처리를 수행함으로써, 예측된 목표 이미지의 적 어도 하나의 스케일의 제1 특징맵을 획득하고; 각 제1 특징맵에 대해, 제1 특징맵에서 적어도 하나의 위치 중 각 위치의 특징과 위치의 인접 영역 특징 사이의 코사인 거리에 기반하여, 예측된 목표 이미지의 적어도 하나의 제1 구조 특징을 획득하도록 구성된다. 여기서, 제1 특징맵에서의 각 위치는 하나의 제1 구조 특징에 대응하고, 인접 영역 특징은 위치를 중심으로 하 여 적어도 2 개의 위치를 포함하는 영역 내의 각 특징이다. 하나의 실시형태로서, 제1 구조 차이 결정 모듈은 구조 분석 네트워크에 기반하여 제2 샘플 이미지에 대해 처리 를 수행함으로써, 제2 샘플 이미지에서 적어도 하나의 위치의 적어도 하나의 제2 구조 특징을 결정할 때, 구조 분석 네트워크에 기반하여 제2 샘플 이미지에 대해 처리를 수행함으로써, 제2 샘플 이미지의 적어도 하나의 스 케일에서의 제2 특징맵을 획득하고; 각 제2 특징맵에 대해, 제2 특징맵에서 적어도 하나의 위치 중 각 위치의 특징과 위치의 인접 영역 특징 사이의 코사인 거리에 기반하여, 제2 샘플 이미지의 적어도 하나의 제2 구조 특 징을 획득하도록 구성된다. 여기서, 제2 특징맵에서의 각 위치는 하나의 제2 구조 특징에 대응한다. 하나의 실시형태로서, 제1 특징맵에서의 각 위치와 제2 특징맵에서의 각 위치 사이에는 대응 관계가 존재한다. 제1 구조 차이 결정 모듈은 적어도 하나의 제1 구조 특징 및 적어도 하나의 제2 구조 특징에 기반하여, 예측된 목표 이미지와 제2 샘플 이미지 사이의 제1 구조 차이 손실을 결정할 때, 대응 관계가 존재하는 위치에 대응하 는 제1 구조 특징과 제2 구조 특징 사이의 거리를 계산하고; 예측된 목표 이미지에 대응하는 모든 제1 구조 특 징과 제2 구조 특징 사이의 거리에 기반하여, 예측된 목표 이미지와 제2 샘플 이미지 사이의 제1 구조 차이 손 실을 결정하도록 구성된다. 하나의 실시형태로서, 특징 손실 결정 모듈은, 구체적으로 구조 분석 네트워크에 기반하여 예측된 목표 이미지 및 제2 샘플에 대해 이미지 처리를 수행함으로써, 예측된 목표 이미지의 적어도 하나의 스케일의 제1 특징맵 및 제2 샘플 이미지의 적어도 하나의 스케일에서의 제2 특징맵을 획득하고; 적어도 하나의 제1 특징맵 및 적어 도 하나의 제2 특징맵에 기반하여, 예측된 목표 이미지와 제2 샘플 이미지 사이의 특징 손실을 획득하도록 구성 된다. 하나의 실시형태로서, 제1 특징맵에서의 각 위치와 제2 특징맵에서의 각 위치 사이에는 대응 관계가 존재한다. 특징 손실 결정 모듈은 적어도 하나의 제1 특징맵 및 적어도 하나의 제2 특징맵에 기반하여, 예측된 목표 이미 지와 제2 샘플 이미지 사이의 특징 손실을 결정할 때, 대응 관계가 존재하는 위치에 대응하는 제1 특징맵에서의 특징과 제2 특징맵에서의 특징 사이의 거리를 계산하고; 제1 특징맵에서의 특징과 상기 제2 특징맵에서의 특징 사이의 거리에 기반하여, 예측된 목표 이미지와 제2 샘플 이미지 사이의 특징 손실을 결정한다. 하나의 실시형태로서, 차이 손실은 색상 손실을 더 포함한다. 차이 손실 결정 유닛은, 예측된 목표 이미지와 제2 샘플 이미지 사이의 색상 차이에 기반하여, 이미지 생성 네트워크의 색상 손실을 결정하도록 구성된 색상 손실 결정 모듈을 더 포함하고; 네트워크 훈련 유닛은, 구 체적으로 제1 반복에서, 제1 구조 차이 손실에 기반하여, 특징 손실 및 색상 손실 이미지 생성 네트워크의 네트 워크 파라미터에 대해 조정을 수행하고; 제2 반복에서, 제1 구조 차이 손실에 기반하여 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행하며; 훈련 정지 조건을 만족시킬 때까지 조정을 수행하여, 훈련된 이미 지 생성 네트워크를 획득하도록 구성된다. 여기서, 제1 반복 및 제2 반복은 연속적으로 수행되는 2 회의 반복이다. 적대적 훈련의 목표는 이미지 생성 네 트워크에 의해 획득된 예측된 목표 이미지와 제2 샘플 이미지 사이의 차이를 감소시키는 것이다. 적대적 훈련은 일반적으로 교대 훈련의 방식을 사용하여 구현되며, 본 출원의 실시예에서, 이미지 생성 네트워크 및 구조 분석 네트워크에 대해 교대로 훈련을 수행하여, 요구사항에 부합되는 이미지 생성 네트워크를 획득한다. 하나 또는 복수 개의 선택적인 실시예에서, 본 출원의 실시예에서 제공한 장치는, 제2 샘플 이미지에 소음을 추 가하여, 소음 이미지를 획득하도록 구성된 소음 추가 유닛; 및 소음 이미지 및 제2 샘플 이미지에 기반하여 제2 구조 차이 손실을 결정하도록 구성된 제2 구조 차이 손실 유닛을 더 포함한다. 예측된 목표 이미지는 샘플 이미지로부터 생성되는 반면, 제2 샘플 이미지는 일반적으로 조명 차이를 가지고 소 음의 영향을 받으므로, 생성된 예측된 목표 이미지와 제2 샘플 이미지 사이에 일정한 분포 차이를 초래한다. 구 조 분석 네트워크가 장면 구조 정보가 아닌 이러한 차이에 주목하는 것을 방지하도록, 본 출원의 실시예는 훈련 과정에서 소음에 대한 저항 메커니즘을 추가한다. 하나의 실시형태로서, 제2 구조 차이 손실 유닛은 구체적으로, 구조 분석 네트워크에 기반하여 소음 이미지에 대해 처리를 수행함으로써, 소음 이미지에서 적어도 하나의 위치의 적어도 하나의 제3 구조 특징을 결정하고; 구조 분석 네트워크에 기반하여 제2 샘플 이미지에 대해 처리를 수행함으로써, 제2 샘플 이미지에서 적어도 하 나의 위치의 적어도 하나의 제2 구조 특징을 결정하며; 적어도 하나의 제3 구조 특징 및 적어도 하나의 제2 구 조 특징에 기반하여, 소음 이미지와 제2 샘플 이미지 사이의 제2 구조 차이 손실을 결정하도록 구성된다. 하나의 실시형태로서, 제2 구조 차이 손실 유닛은 구조 분석 네트워크에 기반하여 소음 이미지에 대해 처리를 수행함으로써, 소음 이미지에서 적어도 하나의 위치의 적어도 하나의 제3 구조 특징을 결정할 때, 구조 분석 네 트워크에 기반하여 소음 이미지에 대해 처리를 수행함으로써, 소음 이미지의 적어도 하나의 스케일의 제3 특징 맵을 획득하고; 각 제3 특징맵에 기반하여, 제3 특징맵에서 적어도 하나의 위치 중 각 위치의 특징과 위치의 인 접 영역 특징 사이의 코사인 거리에 기반하여, 소음 이미지의 적어도 하나의 제3 구조 특징을 획득하도록 구성 되며; 여기서, 제3 특징맵에서의 각 위치는 하나의 제3 구조 특징에 대응하고, 인접 영역 특징은 위치를 중심으 로 하여 적어도 2 개의 위치를 포함하는 영역 내의 각 특징이다. 하나의 실시형태로서, 제3 특징맵에서의 각 위치와 제2 특징맵에서의 각 위치 사이에는 대응 관계가 존재한다. 제2 구조 차이 손실 유닛은 적어도 하나의 제3 구조 특징 및 적어도 하나의 제2 구조 특징에 기반하여, 소음 이 미지와 제2 샘플 이미지 사이의 제2 구조 차이 손실을 결정할 때, 대응 관계가 존재하는 위치에 대응하는 제3 구조 특징과 제2 구조 특징 사이의 거리를 계산하고; 소음 이미지에 대응하는 모든 제3 구조 특징과 제2 구조 특징 사이의 거리에 기반하여, 소음 이미지와 제2 샘플 이미지 사이의 제2 구조 차이 손실을 결정하도록 구성된 다. 하나의 실시형태로서, 네트워크 훈련 유닛은 구체적으로, 제3 반복에서, 제1 구조 차이 손실에 기반하여, 특징 손실 및 색상 손실 이미지 생성 네트워크의 네트워크 파라미터에 대해 조정을 수행하고; 제4 반복에서, 제1 구 조 차이 손실 및 제2 구조 차이 손실에 기반하여 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행 하며; 훈련 정지 조건을 만족시킬 때까지 조정을 수행하여, 훈련된 이미지 생성 네트워크를 획득하도록 구성된 다. 여기서, 제3 반복 및 제4 반복은 연속적으로 수행되는 2 회의 반복이다. 하나의 실시형태로서, 제1 구조 차이 결정 모듈은 또한, 이미지 재구성 네트워크에 기반하여 적어도 하나의 제1 구조 특징 이미지에 대해 재구성 처리를 수행함으로써, 제1 재구성 이미지를 획득하고; 제1 재구성 이미지와 예 측된 목표 이미지에 기반하여 제1 재구성 손실을 결정하도록 구성된다. 하나의 실시형태로서, 제1 구조 차이 결정 모듈은 또한, 이미지 재구성 네트워크에 기반하여 적어도 하나의 제2 구조 특징 이미지에 대해 재구성 처리를 수행함으로써, 제2 재구성 이미지를 획득하고; 제2 재구성 이미지 및 제2 샘플 이미지에 기반하여 제2 재구성 손실을 결정하도록 구성된다. 하나의 실시형태로서, 네트워크 훈련 유닛은 구체적으로, 제5 반복에서, 제1 구조 차이 손실에 기반하여, 특징 손실 및 상기 색상 손실 이미지 생성 네트워크의 네트워크 파라미터에 대해 조정을 수행하고; 제6 반복에서, 제 1 구조 차이 손실에 기반하여, 제2 구조 차이 손실, 제1 재구성 손실 및 제2 재구성 손실에 기반하여 구조 분석 네트워크의 네트워크 파라미터에 대해 조정을 수행하며; 훈련 정지 조건을 만족시킬 때까지 조정을 수행하여, 훈련된 이미지 생성 네트워크를 획득하도록 구성된다. 여기서, 제5 반복 및 제6 반복은 연속적으로 수행되는 2 회의 반복이다. 하나 또는 복수 개의 선택적인 실시예에서, 본 출원의 실시예에서 제공한 장치는, 훈련된 이미지 생성 네트워크 에 기반하여 처리될 이미지에 대해 처리를 수행함으로써, 목표 이미지를 획득하도록 구성된 이미지 처리 유닛을 더 포함한다. 본 출원의 실시예에서 제공한 훈련 장치는, 구체적인 적용에서, 훈련된 이미지 생성 네트워크에 기반하여 입력 된 처리될 이미지에 대해 처리를 수행함으로써, 원하는 목표 이미지를 획득하며, 상기 이미지 생성 네트워크는 2D 이미지 비디오에서 3D 스테레오 이미지로 전환하여, 높은 프레임 비디오 생성 등에 적용될 수 있다. 하나의 실시형태로서, 처리될 이미지는 좌안 이미지를 포함하고; 목표 이미지는 좌안 이미지에 대응하는 우안 이미지를 포함한다. 도 7은 본 출원의 실시예에서 제공한 이미지 처리 장치의 하나의 구조 모식도이다. 상기 실시예 장치는 3 차원 이미지 생성 장면에서, 좌안 이미지를 이미지 생성 네트워크에 입력하여, 우안 이미지를 획득하도록 구성된 우 안 이미지 획득 유닛; 및 좌안 이미지 및 우안 이미지에 기반하여 3 차원 이미지를 생성하도록 구성된 3 차 원 이미지 생성 유닛을 포함한다. 여기서, 이미지 생성 네트워크는 상기 실시예 중 어느 한 항에 따라 제공된 이미지 생성 네트워크의 훈련 방법 을 통해 훈련하여 획득된다. 본 출원의 실시예에서 제공한 이미지 처리 장치에서, 이미지 생성 네트워크를 통해 좌안 이미지에 대해 처리를 수행하여 대응하는 우안 이미지를 획득하고, 조명, 차단, 소음 등 환경적 요인에 의한 영향이 적어, 작은 시각 면적을 갖는 객체의 합성 정확도를 유지하고, 획득된 우안 이미지와 좌안 이미지를 통해 변형이 작고, 디테일 유지가 완전한 3 차원 이미지를 생성할 수 있다. 본 출원의 실시예는 프로세서를 포함하는 전자 기기를 제공하며, 상기 프로세서는 상기 실시예 중 어느 한 항에 따른 이미지 생성 네트워크의 훈련 장치 또는 상기 실시예에 따른 이미지 처리 장치를 포함한다. 본 출원의 실시예는 프로세서; 프로세서에서 실행 가능한 명령어를 포함하기 위한 메모리를 포함하는 전자 기기 를 제공하며; 여기서, 상기 프로세서는 상기 실행 가능한 명령어를 실행함으로써, 전술한 실시예 중 어느 한 항 에 따른 이미지 생성 네트워크의 훈련 방법 또는 이미지 처리 방법을 구현하도록 구성된다. 본 출원의 실시예는 컴퓨터 판독 가능한 명령어를 저장하기 위한 컴퓨터저장 매체를 제공하며, 상기 판독 가능 한 명령어가 실행될 때, 상기 실시예 중 어느 한 항에 따른 이미지 생성 네트워크의 훈련 방법의 단계 또는 상 기 실시예에 따른 이미지 처리 방법의 단계를 실행한다. 본 출원의 실시예는 컴퓨터 판독 가능한 코드를 포함하는 컴퓨터 프로그램 제품을 제공하며, 상기 컴퓨터 판독 가능한 코드가 기기에서 작동될 때, 상기 기기의 프로세서는 상기 실시예 중 어느 한 항에 따른 이미지 생성 네 트워크의 훈련 방법을 구현하기 위한 명령어, 또는 상기 실시예에 따른 이미지 처리 방법을 구현하기 위한 명령 어를 실행한다. 본 출원의 실시예는 또한 전자 기기를 제공하며, 예를 들어, 모바일 단말, 개인용 컴퓨터(PC, Personal Computer), 태블릿 컴퓨터, 서버 등일 수 있다. 도 8을 참조하면, 본 출원의 실시예의 단말 기기 또는 서버를 구현하기에 적합한 전자 기기의 구조 모식도를 도시하며, 도 8에 도시된 바와 같이, 전자 기기는 하 나 또는 복수 개의 프로세서, 통신부 등을 포함하고, 상기 하나 또는 복수 개의 프로세서는, 예를 들어, 하나 또는 복수 개의 중앙처리장치(CPU, Central Processing Unit), 및 하나 또는 복수 개의 전용 프로세서 중 적어도 하나이며, 전용 프로세서는 가속 유닛으로서, 그래픽 처리 장치(GPU, Graphics Processing Unit), 필드 프로그래머블 게이트 어레이(FPGA, Field－Programmable Gate Array), 디지털 신호 프로세서(DSP, Digital Signal Processing) 및 다른 주문형 집적 회로(ASIC, Application-Specific Integrated Circuit) 칩과 같은 전용 프로세서 등을 포함하지만 이에 한정되지 않으며, 프로세서는 판독 전용 메모리(ROM)에 저장된 실행 가능한 명령어 또는 저장 부분으로부터 랜덤 액세스 메모리(RAM)에 로드된 실행 가능한 명령어 에 따라 다양한 적절한 동작 및 처리를 수행할 수 있다. 통신부는 인피니밴드(Infiniband, IB) 네트워크 카드를 포함할 수 있지만 이에 한정되지 않는다. 프로세서는 판독 전용 메모리 및 랜덤 액세스 메모리 중 적어도 하나와 통신하여 실행 가능한 명령어 를 실행하고, 버스를 통해 통신부에 연결되고, 통신부를 통해 다른 목표 기기와 통신함으로써, 본 출원의 실시예에서 제공한 임의의 방법에 대응하는 단계를 완료하며, 예를 들어, 샘플 이미지를 획득하고, 샘플 이미지는 제1 샘플 이미지 및 제1 샘플 이미지에 대응하는 제2 샘플 이미지를 포함하며; 이미지 생성 네트 워크에 기반하여 제1 샘플 이미지에 대해 처리를 수행함으로써, 예측된 목표 이미지를 획득하고; 예측된 목표 이미지와 제2 샘플 이미지 사이의 차이 손실을 결정하며; 차이 손실에 기반하여 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득한다. 또한, RAM은 또한 장치 동작에 필요한 다양한 프로그램 및 데이터를 저장할 수 있다. CPU, ROM 및 RAM은 통신 버스를 통해 서로 연결된다. RAM이 있는 경우, ROM은 옵션 모듈이다. RAM은 실행 가능 명령어를 저장하고, 또는 작동될 경우, ROM에 실행 가능 명령어를 기록하며, 실행 가능 명령어는 중앙처리장치로 하여금 상기 방법에 대응하는 단계를 실행하도록 한다. 입력/출력(I/O, Input/Output) 인터페이스는 또한 버스에 연결된다. 통신부는 통합될 수 있거나, 버스에 연결된복수 개의 서브 모듈(예를 들어 복수 개의 IB 랜 카드)을 갖도록 구성될 수 있다. 키보드, 마우스 등을 포함하는 입력 부분; 음극 선관(CRT, Cathode Ray Tube), 액정 디스플레이(LCD, Liquid Crystal Display), 스피커 등을 포함하는 출력 부분; 하드웨어 등을 포함하는 저장 부분; 및 근거리 통신망(LAN, Local Area Network) 카드, 모뎀 등을 포함하는 네트워크 인터페이스 카드의 통신 부분 등 구성 요소는 I/O 인터페이스에 연결된다. 통신 부분은 인터넷과 같은 네트워크를 통해 통신 처리를 수행한다. 드라이버는 필요에 따라 I/O 인터페이스에 연결될 수도 있다. 자기 디스크, 광 디 스크, 광 자기 디스크, 반도체 메모리 등과 같은 탈착 가능한 매체는 필요에 따라 저장 부분에 설치 된 컴퓨터 프로그램을 판독할 수 있도록 필요에 따라 드라이버에 설치된다. 설명해야 할 것은, 도 8에 도시된 아키텍쳐는 다만 선택적인 구현 방식일 뿐, 구체적인 실천 과정에서, 상기 도 8의 구성 요소의 개수 및 유형은 실제 필요에 따라 선택, 감소, 증가 또는 교체되며; 상이한 기능적 구성 요소 설치에서 분리 설치 또는 통합 설치 등 구현 방식을 사용할 수 있으며, 예를 들어 가속 유닛 및 CPU 는 분리 설치되거나 가속 유닛이 CPU에 통합되며, 통신부는 CPU 또는 가속 유닛에 분리 설 치 또는 통합 설치될 수 있는 등이다. 이러한 대안적인 실시형태는 모두 본 출원의 보호 범위에 속한다. 본 출원의 실시예에 따른 흐름도를 참조하여 설명된 과정은 컴퓨터 소프트웨어 프로그램에 의해 구현된다. 예를 들어, 본 출원의 실시예는 기계 판독 가능한 매체에 유형적으로 포함된 컴퓨터 프로그램을 포함하는 컴퓨터 프 로그램 제품을 포함하며, 컴퓨터 프로그램은 흐름도에 도시된 방법을 실행하기 위한 프로그램 코드를 포함하며, 프로그램 코드는 본 출원의 실시예에서 제공한 방법을 실행하는 단계, 예를 들어, 샘플 이미지를 획득하는 단계 에 대응하는 명령어를 포함하며, 샘플 이미지는 제1 샘플 이미지 및 제1 샘플 이미지에 대응하는 제2 샘플 이미 지를 포함하며; 이미지 생성 네트워크에 기반하여 제1 샘플 이미지에 대해 처리를 수행함으로써, 예측된 목표 이미지를 획득하고; 예측된 목표 이미지와 제2 샘플 이미지 사이의 차이 손실을 결정하며; 차이 손실에 기반하 여 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크를 획득한다. 이러한 실시 예에서, 상기 컴퓨터 프로그램은 통신 부분를 통해 네트워크로부터 다운로드 및 설치될 수 있는 것 및 탈 착 가능한 매체로부터 설치될 수 있는 것 중 적어도 하나이다. 상기 컴퓨터 프로그램은 중앙처리장치 (CPU)에 의해 실행될 때, 본 발명의 방법에 정의된 상기 기능의 동작을 실행한다. 본 출원의 방법과 장치는 많은 방식으로 구현된다. 예를 들어, 본 출원의 방법과 장치는 소프트웨어, 하드웨어, 펌웨어 또는 소프트웨어, 하드웨어, 펌웨어의 임의의 조합으로 구현될 수 있다. 달리 구체적으로 언급되지 않는 한, 방법을 위한 상기 단계의 상기 순서는 다만 구체적인 설명을 위한 것이며, 본 출원의 실시 형태의 방법의 단계를 한정하려는 것은 아니다. 또한, 일부 실시예에 있어서, 본 출원은 기록 매체에 기록된 프로그램으로서 구현될 수도 있으며, 이들 프로그램은 본 출원의 방법을 구현하기 위한 기계 판독 가능 명령어를 포함한다. 따 라서, 본 출원은 본 출원에 따른 방법들을 실행하기 위한 프로그램을 저장하는 기록 매체를 더 포함한다. 본 출원의 설명은 예시 및 설명을 목적으로 제공되며, 누락되지 않는 형태로 한정하거나 본 출원을 개시된 형태 로 한정하려는 것은 아니다. 또한 많은 수정과 변경은 당업자에게 명백하다. 실시예들은 본 출원의 원리 및 실 제 적용을 더 잘 설명하고, 당어자가 본 출원을 이해하여, 특정 용도에 적용 가능한 다양한 수정들을 갖는 다양 한 실시예들을 설계하도록 선택되고 설명된다. 산업상 이용가능성 본 출원의 실시예의 기술방안은, 샘플 이미지를 획득하고, 샘플 이미지는 제1 샘플 이미지 및 제1 샘플 이미지 에 대응하는 제2 샘플 이미지를 포함하며; 이미지 생성 네트워크에 기반하여 제1 샘플 이미지에 대해 처리를 수 행함으로써, 예측된 목표 이미지를 획득하며; 예측된 목표 이미지와 제2 샘플 이미지 사이의 차이 손실을 결정 하고; 차이 손실에 기반하여 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 훈련된 이미지 생성 네트워크 를 획득하며, 이와 같이, 차이 손실을 통해 예측된 목표 이미지와 제2 샘플 이미지 사이의 구조 차이를 설명하 여, 차이 손실로써 이미지 생성 네트워크에 대해 훈련을 수행함으로써, 이미지 생성 네트워크에 기반하여 생성 된 이미지의 구조가 왜곡되지 않도록 보장한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2020-7012581", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서의 일부를 구성하는 도면은 본 출원의 실시예를 설명하고, 본 명세서의 원리를 설명과 함께 해석하기 위한 것이다. 도면을 참조하면, 본 출원은 다음의 상세한 설명에 따라, 더욱 명확하게 이해될 수 있다. 도 1은 본 출원의 실시예에서 제공한 이미지 생성 네트워크의 훈련 방법의 하나의 프로세스 모식도이다. 도 2는 본 출원의 실시예에서 제공한 이미지 생성 네트워크의 훈련 방법의 다른 프로세스 모식도이다. 도 3은 본 출원의 실시예에서 제공한 이미지 생성 네트워크의 훈련 방법의 또 다른 부분 프로세스 모식도이다. 도 4는 본 출원의 실시예에서 제공한 이미지 생성 네트워크의 훈련 방법에 관련된 네트워크 구조 모식도이다. 도 5는 본 출원의 실시예에서 제공한 이미지 처리 방법의 하나의 프로세스 모식도이다. 도 6은 본 출원의 실시예에서 제공한 이미지 생성 네트워크의 훈련 장치의 하나의 구조 모식도이다. 도 7은 본 출원의 실시예에서 제공한 이미지 처리 장치의 하나의 구조 모식도이다. 도 8은 본 출원의 실시예의 단말 기기 또는 서버를 구현하기에 적합한 전자 기기의 구조 모식도이다."}
