{"patent_id": "10-2023-0057771", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0114673", "출원번호": "10-2023-0057771", "발명의 명칭": "공간 맵을 획득하는 방법 및 전자 장치", "출원인": "삼성전자주식회사", "발명자": "이용석"}}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 센서를 이용하여 획득된 공간에 대한 공간 스캔 정보로부터 상기 공간에 속하는 객체를 인식하는단계(S610);상기 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는(unrecognizable) 객체와 관련된 특징 정보를획득하는 단계(S620);상기 획득된 특징 정보에 기초한 쿼리(query)를 이용하여, 상기 객체 인식 모델을 통해 인식할 수 없는 객체를개인화된(personalized) 데이터베이스에 기초하여 식별하는 단계(S630); 및상기 공간 스캔 정보 및 상기 공간에 속하는 객체에 대한 객체 정보에 기초하여, 상기 공간에 대한 공간 맵을생성하는 단계(S640);를 포함하는, 공간 맵을 획득하는 방법."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 식별하는 단계(S630)는,상기 쿼리에 대한 응답으로, 상기 개인화된 데이터베이스로부터 객체 후보군에 대한 정보를 획득하는 단계; 및상기 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보와 상기 객체 후보군에 포함된 객체들각각의 이미지 정보를 비교하여, 상기 비교 결과에 기초하여 상기 객체 인식 모델을 통해 인식할 수 없는 객체를 식별하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항 또는 제2 항에 있어서,상기 객체 후보군에 대한 정보를 획득하는 단계는,상기 쿼리에 포함된 상기 특징 정보와 상기 개인화된 데이터베이스에 저장된 객체 별 속성 정보를 비교하여, 상기 특징 정보에 대응되는 속성 정보를 가지는 객체 후보군에 대한 정보를 획득하는, 방법."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항 내지 제3 항 중 어느 한 항에 있어서,상기 쿼리는,상기 개인화된 데이터베이스에 저장된 객체 별 속성 정보가 상기 획득된 특징 정보와 일정한 수준 이상으로 매칭되는 적어도 하나의 객체에 대한 객체 정보의 수집을 요청하는 것인, 방법."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항 내지 제4 항 중 어느 한 항에 있어서,상기 비교 결과에 기초하여 상기 객체 인식 모델을 통해 인식할 수 없는 객체를 식별하는 단계는,상기 적어도 하나의 센서를 포함하는 전자 장치(100)의 위치를 소정의 시점으로 이동시키는 단계; 및상기 이동된 위치에서 상기 적어도 하나의 센서를 이용하여, 상기 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보를 생성하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2024-0114673-3-제1 항 내지 제5 항 중 어느 한 항에 있어서,상기 객체 후보군에 대한 정보를 획득하는 단계는,상기 개인화된 데이터베이스를 포함하는 클라우드 서버(200)에 상기 쿼리를 전송한 것에 대한 응답으로, 상기클라우드 서버(200)로부터 객체 후보군에 대한 정보를 수신하는, 방법."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항 내지 제6 항 중 어느 한 항에 있어서,상기 공간에 속하는 객체를 인식하는 단계(S610)는,상기 객체 인식 모델을 이용하여, 상기 공간 스캔 정보로부터 상기 공간에 속하는 객체를 인식하고,상기 특징 정보를 획득하는 단계(S620)는,특징 분석 모델을 이용하여, 상기 객체 인식 결과에 따라 레이블링된 상기 공간 스캔 정보로부터 상기 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보를 추출하는, 방법."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항 내지 제7 항 중 어느 한 항에 있어서,상기 공간 스캔 정보 및 상기 공간에 속하는 객체에 대한 객체 정보에 기초하여, 상기 개인화된 데이터베이스를업데이트하는 단계를 더 포함하고,상기 공간에 대한 공간 맵을 생성하는 단계(S640)는,상기 업데이트된 개인화된 데이터베이스에 기초하여, 상기 공간에 대한 공간 맵을 생성하는, 방법."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항 내지 제8 항 중 어느 한 항에 있어서,상기 개인화된 데이터베이스는 사용자의 자산에 속하는 객체들 각각의 속성 정보를 객체별로 등록한 것이고,상기 속성 정보는 객체의 생산 과정에서 결정되는 모델 속성 정보 및 상기 사용자의 사용 과정에서 결정되는 사용 속성 정보를 포함하는, 방법."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항 내지 제9 항 중 어느 한 항의 방법을 실행시키기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "하나 이상의 인스트럭션을 저장하는 메모리(110);상기 메모리(110)에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서(120); 및적어도 하나의 센서를 포함하는 센싱부(130)를 포함하고,상기 프로세서(120)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 센싱부(130)를 이용하여 획득된 공간에 대한 공간 스캔 정보로부터 상기 공간에 속하는 객체를 인식하고,상기 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보를 획득하고, 상기획득된 특징 정보에 기초한 쿼리를 이용하여, 상기 객체 인식 모델을 통해 인식할 수 없는 객체를 개인화된 테이터베이스에 기초하여 식별하고, 상기 공간 스캔 정보 및 상기 공간에 속하는 객체에 대한 객체 정보에 기초하여, 상기 공간에 대한 공간 맵을 생성하는, 전자 장치(100)."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,공개특허 10-2024-0114673-4-상기 프로세서(120)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 쿼리에 대한 응답으로, 상기 개인화된 데이터베이스로부터 객체 후보군에 대한 정보를 획득하고, 상기 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보와 상기 객체 후보군에 포함된 객체들 각각의이미지 정보를 비교하여, 상기 비교 결과에 기초하여 상기 객체 인식 모델을 통해 인식할 수 없는 객체를 식별하는, 전자 장치(100)."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11 항 또는 제12 항에 있어서,상기 프로세서(120)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 쿼리에 포함된 상기 특징 정보와 상기 개인화된 데이터베이스에 저장된 객체 별 속성 정보를 비교하여, 상기 특징 정보에 대응되는 속성 정보를 가지는 객체 후보군에 대한 정보를 획득하는, 전자 장치(100)."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11 항 내지 제13 항 중 어느 한 항에 있어서,상기 쿼리는,상기 개인화된 데이터베이스에 저장된 객체 별 속성 정보가 상기 획득된 특징 정보와 일정한 수준 이상으로 매칭되는 적어도 하나의 객체에 대한 객체 정보의 수집을 요청하는 것인, 전자 장치(100)."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11 항 내지 제14 항 중 어느 한 항에 있어서,상기 프로세서(120)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 전자 장치(100)의 위치를 소정의 시점으로 이동시키고, 상기 이동된 위치에서 상기 센싱부(130)를 이용하여, 상기 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보를 생성하는, 전자 장치(100)."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11 항 내지 제15 항 중 어느 한 항에 있어서,통신부(140)를 더 포함하고,상기 프로세서(120)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 통신부(140)를 통해, 상기 개인화된 데이터베이스를 포함하는 클라우드 서버(200)에 상기 쿼리를 전송한것에 대한 응답으로, 상기 클라우드 서버(200)로부터 객체 후보군에 대한 정보를 수신하는, 전자 장치(100)."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11 항 내지 제16 항 중 어느 한 항에 있어서,상기 프로세서(120)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 객체 인식 모델을 이용하여, 상기 공간 스캔 정보로부터 상기 공간에 속하는 객체를 인식하고, 특징 분석모델을 이용하여, 상기 객체 인식 결과에 따라 레이블링된 상기 공간 스캔 정보로부터 상기 객체 인식 모델을통해 인식할 수 없는 객체와 관련된 특징 정보를 추출하는, 전자 장치(100)."}
{"patent_id": "10-2023-0057771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11 항 내지 제17 항 중 어느 한 항에 있어서,상기 프로세서(120)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 공간 스캔 정보 및 상기 공간에 속하는 객체에 대한 객체 정보에 기초하여, 상기 개인화된 데이터베이스를업데이트하고, 상기 업데이트된 개인화된 데이터베이스에 기초하여, 상기 공간에 대한 공간 맵을 생성하는, 전자 장치(100).공개특허 10-2024-0114673-5-청구항 19 제11 항 내지 제18 항 중 어느 한 항에 있어서,상기 개인화된 데이터베이스는 사용자의 자산에 속하는 객체들 각각의 속성 정보를 객체별로 등록한 것이고,상기 속성 정보는 객체의 생산 과정에서 결정되는 모델 속성 정보 및 상기 사용자의 사용 과정에서 결정되는 사용 속성 정보를 포함하는, 전자 장치(100)."}
{"patent_id": "10-2023-0057771", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "공간에 대한 공간 스캔 정보로부터 공간에 속하는 객체를 인식하고, 공간 스캔 정보로부터 객체 인식 모델을 통 해 인식할 수 없는 객체와 관련된 특징 정보를 획득하고, 획득된 특징 정보에 기초한 쿼리를 이용하여, 상기 객 체 인식 모델을 통해 인식할 수 없는 객체를 개인화된 데이터베이스에 기초하여 객체를 식별하고, 공간 스캔 정 보 및 공간에 속하는 객체에 대한 객체 정보에 기초하여, 공간에 대한 공간 맵을 생성하는 전자 장치 및 방법이 개시된다."}
{"patent_id": "10-2023-0057771", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "공간 맵을 획득하는 방법 및 전자 장치에 관한 것이다."}
{"patent_id": "10-2023-0057771", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인터넷은 인간이 정보를 생성하고 소비하는 인간 중심의 연결 망에서, 사물 등 분산된 구성 요소들 간에 정보를 주고 받아 처리하는 IoT(Internet of Things, 사물인터넷) 망으로 진화하고 있다. 클라우드 서버 등과의 연결을 통한 빅데이터(Big data) 처리 기술 등이 IoT 기술에 결합된 IoE (Internet of Everything) 기술도 대두되고 있다. IoT는 기존의 IT(information technology)기술과 다양한 산업 간의 융합 및 복합을 통하여 스마트 가전, 스마트홈, 스마트 빌딩, 스마트 시티 등의 분야에 응용될 수 있다. IoT 환경에서 서로 연결된 전자 장치들 각각은 데이터를 수집, 생성, 분석, 또는 가공하고, 상호 간에 데이터를 서로 공유하여, 각 장치의 태스크에 활용할 수 있다. 최근에는 컴퓨터 비전 분야의 비약적인 발전에 따라, 비전 태스크를 수행하는 신경망 모델을 활용하는 다양한 종류의 전자 장치가 개발되고 있다. 이에 따라, IoT 환경에 서 다양한 종류의 전자 장치 간의 연결에 대한 관심이 고조되고 있다."}
{"patent_id": "10-2023-0057771", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, 공간 맵을 획득하는 방법이 제공된다. 공간 맵을 획득하는 방법은 적어도 하나 의 센서를 이용하여 획득된 공간에 대한 공간 스캔 정보로부터 상기 공간에 속하는 객체를 인식하는 단계를 포 함한다. 또한, 공간 맵을 획득하는 방법은 상기 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 (unrecognizable) 객체와 관련된 특징 정보를 획득하는 단계를 포함한다. 또한, 공간 맵을 획득하는 방법은 상 기 획득된 특징 정보에 기초한 쿼리(query)를 이용하여, 상기 객체 인식 모델을 통해 인식할 수 없는 객체를 개 인화된(personalized) 데이터베이스에 기초하여 식별하는 단계를 포함한다. 또한, 신경망 모델을 학습시키는 방 법은 상기 공간 스캔 정보 및 상기 공간에 속하는 객체에 대한 객체 정보에 기초하여, 상기 공간에 대한 공간 맵을 생성하는 단계를 포함한다. 본 개시의 일 실시예에 따르면, 공간 맵을 획득하는 전자 장치가 제공된다. 공간 맵을 획득하는 전자 장치는 하 나 이상의 인스트럭션을 저장하는 메모리, 상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로 세서, 및 적어도 하나의 센서를 포함하는 센싱부를 포함한다. 프로세서는 하나 이상의 인스트럭션을 실행함으로 써, 상기 센싱부를 이용하여 획득된 공간에 대한 공간 스캔 정보로부터 상기 공간에 속하는 객체를 인식한다. 또한, 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 상기 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보를 획득한다. 또한, 프로세서는 하나 이상의 인스트럭션을 실행함으로 써, 획득된 특징 정보에 기초한 쿼리를 이용하여, 상기 객체 인식 모델을 통해 인식할 수 없는 객체를 개인화된 테이터베이스에 기초하여 식별한다. 또한, 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 상기 공간 스캔 정보 및 상기 공간에 속하는 객체에 대한 객체 정보에 기초하여, 상기 공간에 대한 공간 맵을 생성할 수 있다. 본 개시의 일 실시예에 따르면, 전술한 공간 맵을 획득하는 방법을 실행시키기 위한 프로그램이 기록된 컴퓨터 로 읽을 수 있는 기록매체를 제공된다."}
{"patent_id": "10-2023-0057771", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시에 서, \"a, b 또는 c 중 적어도 하나\" 표현은 \"a\", \"b\", \"c\", \"a 및 b\", \"a 및 c\", \"b 및 c\", \"a, b 및 c 모두\", 혹은 그 변형들을 지칭할 수 있다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의 미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 또한, 본 명세서에서 사용되는 '제1' 또는 '제2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만 사용된다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소 프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다.기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 전자 장치와 외부 장치들이 서로 연결되는 댁내 IoT 환경을 설명하기 위한 도면이다. 본 개시에서 전자 장치는 로봇 청소기인 것을 전제로 설명하나, 사용자의 편의를 위해 구동되는 다양한 종 류의 어시스턴트 로봇이나 모바일 장치, AR(Augmented Reality) 기기, VR(Virtual Reality) 기기, 주변 환경을 감지하고 특정 위치 또는 공간에서 소정의 서비스를 제공하는 기기일 수 있다. 전자 장치는 공간을 스캔하 고 공간 내의 객체를 검출하기 위한 다양한 종류의 센서와 신경망(Neural Network) 모델을 탑재할 수 있다. 예 를 들어, 전자 장치는 카메라와 같은 이미지 센서, LDS(Laser Distance Sensor)와 같은 라이다(LiDAR, Light Detection And Ranging) 센서, ToF(Time of Flight) 센서 중 적어도 하나를 구비할 수 있다. 전자 장치 는 DNN(Deep Neural Network), CNN(Convolution Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network)과 같은 모델을 적어도 하나 탑재할 수 있고, 이들을 조 합적으로 이용할 수도 있다. 전자 장치와 서로 연결되는 외부 장치들은 클라우드 서버와 다양한 종류의 IoT 기기들(300-1, 300-2, 300-3)일 수 있다. IoT 기기들은 도 1에 도시된 바와 같이, 버틀러 로봇(300-1), 애완로봇(300-2), 스마트 홈카 메라(300-3) 등이 될 수 있으나, 이에 한정되는 것은 아니며, 전자 장치와 동종의 기기일 수 있다. 버틀러 로봇(300-1), 애완로봇(300-2), 스마트 홈카메라(300-3) 각각은 구비된 다양한 종류의 센서를 이용하여 공간을 스캔하고 공간 내의 객체를 검출할 수 있다. 본 개시의 일 실시예에 따르면, 전자 장치, 버틀러 로봇(300-1), 애완로봇(300-2), 및 스마트 홈카메라 (300-3)는 각각에서 수집된 공간 스캔 정보 또는 객체 정보를 이용하여 공간 맵을 적어도 하나의 객체를 포함하 는 공간에 대한 공간 정보로써 생성하고 저장할 수 있다. 전자 장치, 버틀러 로봇(300-1), 애완로봇(300- 2), 및 스마트 홈카메라(300-3)는 공간 스캔 정보나 객체 정보, 또는 공간 맵을 상호 간에 송신 또는 수신하여 저장함으로써 서로 공유할 수 있다. 동일한 공간 내에 있는 장치들이라하더라도, 각 장치의 위치나 각 장치의 성능 또는 센싱 레인지, 각 장치가 고 정형인지 이동형인지, 각 장치가 동작하는 행태 등에 따라, 서로 다른 시점(viewpoint)에서 서로 다른 화각으로 공간을 스캔하고 객체를 검출하기 때문에, 어느 하나의 장치에서 획득된 영상 또는 음성을 비롯한 센싱 정보가 다른 장치에 탑재된 인공지능 모델을 학습시키는데 유용하게 활용될 수 있다. 본 개시의 일 실시예에 따르면, 전자 장치, 버틀러 로봇(300-1), 애완로봇(300-2), 및 스마트 홈카메라 (300-3) 중 어느 하나의 기기가 마스터 디바이스 또는 서버 디바이스가 될 수 있고, 나머지 기기들은 슬레이브 디바이스 또는 클라이언트 디바이스가 될 수 있다. 마스터 디바이스 또는 서버 디바이스에 해당하는 기기는 다른 IoT 기기들로부터 공간 스캔 정보나 객체 정보, 또는 공간 맵을 수신하여, 저장하고 관리할 수 있다. 마스터 디바이스 또는 서버 디바이스에 해당하는 기기는 수신된 정보들을 위치 별로 분류하여 저장하고 관리할 수 있다. 예를 들어, 마스터 디바이스 또는 서버 디바이스에 해당하는 기기는 동일한 공간인지, 동일한 구역인지, 또는 동일한 지역인지에 따라, 공간 스캔 정보나 객체 정보, 또는 공간 맵을 분류하여 취합하고 관리할 수 있다. 마스터 디바이스 또는 서버 디바이스에 해당하는 기기는 저장하고 있던 제1 정보를 동일한 위치에 대응되 는 제2 정보로 업데이트함으로써, 해당 위치와 관련된 정보의 최신성 및 적확성을 유지할 수 있다. 본 개시의 일 실시예에 따르면, 전자 장치, 버틀러 로봇(300-1), 애완로봇(300-2), 및 스마트 홈카메라 (300-3)는 공간 스캔 정보나 객체 정보, 또는 공간 맵을 클라우드 서버로 전송하여, 클라우드 서버를 통해 공간 스캔 정보나 객체 정보, 또는 공간 맵을 저장하고 관리할 수 있다. 예를 들어, IoT 기기들의 전원이 꺼져 있거나 IoT 기기에서 특정 기능을 실행 중이어서 전자 장치에 공간 스캔 정보나 객체 정보, 또는 공 간 맵의 송신이 불가능한 경우, 전자 장치는 클라우드 서버에 공간 스캔 정보나 객체 정보, 또는 공 간 맵을 요청하여 수신할 수 있다. 도 1에 도시된 바와 같이, 클라우드 서버는 전자 장치, 버틀러 로봇(300-1), 애완로봇(300-2), 스마 트 홈카메라(300-3) 각각으로부터 수신된 공간 스캔 정보나 객체 정보, 또는 공간 맵을 관리하고, 댁내 공간을 모니터링할 수 있다. 클라우드 서버는 복수의 IoT 기기들로부터 수집된 공간 스캔 정보나 객체 정보, 또는 공간 맵을 등록된 사용자의 계정이나 등록된 위치 별로 저장 및 관리할 수 있다. 예를 들어, 클라우드 서버 는 동일한 공간인지 또는 동일한 구역인지에 따라, 공간 스캔 정보나 객체 정보, 또는 공간 맵을 분류하여 취합하고 관리할 수 있다. 클라우드 서버는 댁내에 위치한 전자 장치, 버틀러 로봇(300-1), 애완로봇 (300-2), 스마트 홈카메라(300-3)의 요청에 응답하여, 공간 맵과 같은 댁내 공간에 대한 정보를 전송할 수 있다. 본 개시의 일 실시예에 따르면, 클라우드 서버 대신, 댁내 위치한 AI 허브(예를 들어, AI 스피커)가 댁내 IoT 기기로부터 공간 스캔 정보나 객체 정보, 또는 공간 맵을 수신하여, 저장하고 관리할 수 있다. AI 허브는 복수의 IoT 기기들로부터 수집된 공간 스캔 정보나 객체 정보, 또는 공간 맵을 댁내의 공간 또는 구역 별로 저 장 및 관리할 수 있다. 본 개시의 일 실시예에 따르면, 댁내 위치한 AI 허브는 클라우드 서버와 함께 공간 스캔 정보나 객체 정보, 또는 공간 맵을 저장하고 관리할 수 있다. 예를 들어, AI 허브는 공간 맵을 생성 또는 관리하기 위해, 공 간 스캔 정보 또는 객체 정보를 가공 내지 처리하거나, 개인 정보가 보호되도록 데이터를 변환하여 클라우드 서 버로 전송할 수 있다. 클라우드 서버는 AI 허브로부터 수신된 정보를 가공 내지 처리하여, 공간 스캔 정보나 객체 정보, 또는 공간 맵을 저장하고 관리할 수 있으며, AI 허브로 전송할 수 있다. 본 개시의 일 실시예에 따르면, 로봇 청소기와 같은 전자 장치는 청소와 같은 태스크를 수행하기 위해 공 간 맵을 이용할 수 있다. 이를 위해, 전자 장치는 다양한 종류의 센서를 이용하여 공간을 스캔하여 최신의 공간 스캔 정보로 공간 맵을 업데이트할 수 있다. 전자 장치는 직접 센싱한 정보뿐만 아니라, 댁내 IoT 환 경에서 서로 연결되는 클라우드 서버, 버틀러 로봇(300-1), 애완로봇(300-2), 스마트 홈카메라(300-3)로부 터 수신된 공간 맵의 일부 또는 전체를 이용하여 전자 장치에 저장된 공간 맵을 업데이트할 수 있다. 예를 들어, 로봇 청소기는 댁내의 공간을 청소하기 위해, 충전 스테이션에서 충전이 완료되면, 로봇 청소기에 저장된 공간 맵을 이용하여 청소를 수행할 수 있다. 로봇 청소기는 동일한 공간에 대한 청소를 수행하기 위해, 최근에 이용한 공간 맵을 그대로 이용할 수도 있다. 하지만, 이전 청소 시의 공간의 상태와 현재의 공간의 상태 가 서로 다르므로, 효율적인 청소를 수행하기 위해, 공간 내 위치한 객체들의 최신 정보를 공간 맵에 반영하는 것이 바람직하다. 이를 위해, 로봇 청소기는 충전 스테이션에서 출발하여, 주요 루트를 사전 주행하여, 공간 내 의 객체 정보를 직접 수집할 수 있다. 그러나 사전 주행을 하게 되면, 사전 주행을 위한 시간이 더 소요되고, 사전 주행에 따라 배터리가 더 소모될 수 있다. 이때, 로봇 청소기는 다른 로봇 청소기나 동일한 공간에 위치한 적어도 하나의 외부 장치로부터 최신의 공간 맵을 수신하여, 로봇 청소기에 저장된 공간 맵을 업데이트할 수 있 다. 로봇 청소기는 외부 장치로부터 수신된 공간 맵의 일부 또는 전부를 활용할 수 있다. 로봇 청소기는 동종의 로 봇 청소기로부터 수신된 공간 맵을 그대로 활용하거나 잦은 위치 변화가 예상되는 객체들에 관한 정보를 공간 맵의 업데이트에 활용할 수 있다. 로봇 청소기는 이종의 기기로부터 수신된 공간 맵이라 하더라도, 동일한 공간 에 대한 공간 맵의 일부 또는 전부를 공간 맵의 업데이트에 활용할 수 있다.도 2a 및 도 2b는 공간 맵을 설명하기 위한 흐름도이다. 도 2a를 참조하면, 로봇 청소기인 전자 장치에 저장된 공간 맵과 공간 맵을 구성하는 복수의 레이어들 간 의 계층적 구조를 나타내고 있다. 도 2a에 도시된 바와 같이, 공간 맵은 베이스 레이어, 시맨틱 맵 레이어, 실 시간 레이어로 구성될 수 있으나, 이에 한정되는 것은 아니며, 태스크의 특성에 따라 레이어가 가감될 수 있다. 베이스 레이어는 벽, 기둥, 통로 등 공간 전체의 기본 구조에 관한 정보를 제공한다. 3차원 포인트 클라우드 데 이터를 처리하여, 좌표계를 정합하고, 위치를 저장함으로써, 베이스 레이어는 공간의 3차원 정보, 객체의 위치 정보, 이동 궤적 정보 등을 제공할 수 있다. 베이스 레이어는 베이스 맵과 지오메트릭 맵의 역할을 수행한다. 시멘틱 맵 레이어는 베이스 레이어 위에 시멘틱 정보를 제공하는 레이어이다. 전자 장치의 사용자는 베이 스 레이어의 공간 전체의 기본 구조에 'Room 1', 'Room 2', '접근 제한 구역' 등과 같은 시멘틱 정보를 부여하 여, 전자 장치의 태스크 수행에 활용할 수 있다. 예를 들어, 전자 장치가 로봇 청소기인 경우, 사용 자는 'Room 2'만 청소하게 하거나, '접근 제한 구역'은 로봇 청소기가 청소하지 않도록, 시멘틱 맵 레이어에 시 멘틱 정보를 설정할 수 있다. 실시간 레이어는 공간 내의 적어도 하나의 객체 정보를 제공하는 레이어이다. 객체는 정적 객체와 동적 객체 모 두 포함될 수 있다. 본 개시에서 실시간 레이어는 객체의 속성 정보에 기초한 복수의 레이어들을 포함할 수 있 으며, 레이어들 간의 계층적 구조를 가질 수 있다. 도 2a에 도시된 바와 같이, 실시간 레이어는 제1 레이어, 제 2 레이어, 제3 레이어를 포함할 수 있으나, 이에 한정되는 것은 아니며, 객체의 속성 정보의 분류 기준에 따라 레이어의 개수가 가감될 수 있다. 도 2a를 보면, 제1 레이어에는 시스템 옷장, 붙박이 장이 포함되고, 제2 레이 어에는 테이블과 소파가 포함되고, 제3 레이어에는 의자가 포함됨을 알 수 있다. 도 2b를 참조하면, 객체의 속성 정보에 기초한 복수의 레이어들을 포함하는 실시간 레이어의 다양한 예를 나타 내고 있다. 객체의 속성 정보는 객체의 종류, 형상, 사이즈, 높이 등과 같은 객관적인 기준이나 복수의 기준을 조합하여 분 류될 수 있는 정보일 수 있다. 또한, 객체의 속성 정보는 사용자 및 환경에 따라 달라질 수 있으므로, 객체별로 레이블링하여 속성 정보를 입력해 둘 수있다. 본 개시의 일 실시예에 따르면, 객체의 속성 정보가 객체의 이동성 레벨(ML, Movability Level)인 경우, 제1 레 이어에는 ML 1에 해당하는 객체가 포함되고, 제2 레이어에는 ML 2와 ML 3에 해당하는 객체가 포함되며, 제3 레 이어에는 ML 4에 해당하는 객체가 포함될 수 있다. 객체의 이동성 레벨은 객체의 객관적인 특징을 이동성을 평 가하는 소정의 분류 기준에 적용함으로써 정해질 수 있다. 예를 들어, ML 1은 이동이 불가능한 객체, ML 2는 이 동이 가능하지만, 주로 고정된 상태로 있는 객체, ML 3는 이동이 가능하지만, 가끔 이동하는 객체, ML 4는 이동 가능하며, 자주 이동하는 객체에 각각 대응된다. 본 개시의 일 실시예에 따르면, 객체의 속성 정보가 객체의 위치 이동 주기(Position Movement Cycle)인 경우, 제1 레이어에는 1개월 내로 위치 이동이 없었던 객체가 포함되고, 제2 레이어에는 1개월 내로 위치 이동이 있었 던 객체가 포함되며, 제3 레이어에는 1주일 내로 위치 이동이 있었던 객체가 포함될 수 있다. 객체의 객관적 특 징에 기초하여 분류되는 이동성 레벨과 달리, 위치 이동 주기는 객체를 사용하는 사용자나 객체가 위치하는 환 경에 따라 동일한 객체라 하더라도, 위치 이동 주기는 다를 수 있다. 예를 들어, 'A'라는 객체는 제1 사용자가 자주 사용되는 객체인 반면, 제2 사용자는 거의 사용되지 않는 객체일 수 있다. 'B'라는 객체는 제1 장소에서는 자주 사용되는 객체인 반면, 제2 장소에서는 거의 사용되지 않는 객체일 수 있다. 본 개시의 일 실시예에 따르면, 객체의 속성 정보가 객체가 위치하는 높이(Height)인 경우, 제1 레이어에는 1m 이하에 해당하는 객체가 포함되고, 제2 레이어에는 1m 이상 2m 이하에 해당하는 객체가 포함되며, 제3 레이어에 는 2m를 초과하는 객체가 포함될 수 있다. 본 개시의 일 실시예에 따르면, 실시간 레이어에 포함되는 복수의 레이어들의 분류 기준은 사용자에 의해 정의 될 수 있다. 예를 들어, 사용자는 분류 기준에 대해 복수의 종류의 객체의 속성 정보를 조합하여 설정해둠으로 써, 태스크의 특성을 반영한 공간 맵을 생성할 수 있다. 예를 들어, 로봇 청소기의 경우, 일반적으로 50cm 높이 보다 아래에서 이동하기 때문에 1m 보다 높은 곳에 위치하는 객체들, 예를 들어, 전등이나 벽에 걸린 액자 등은 고려할 필요가 없다. 따라서, 사용자는 각 레이어를 구분하는 분류 기준을 직접 설정하여, 제1 레이어는 ML 1이 고 1m 이하에 위치하는 객체가 포함되고, 제2 레이어는 ML 2 또는 ML 3이고 1m 이하에 위치하는 객체가 포함되 며, 제3 레이어는 ML 4이고 1m 이하에 위치하는 객체가 포함되도록 할 수 있다.도 3a, 도 3b, 도 3c, 도 3d는 공간 맵을 구성하는 레이어를 활용하는 방식을 설명하기 위한 도면이다. 전자 장치와 IoT 기기들의 종류나 태스크의 특성에 따라, 각 장치에서 이용되는 공간 맵이 서로 다를 수 있다. 전자 장치는 전자 장치에 저장된 기존의 공간 맵을 그대로 활용할 수도 있지만, 태스크를 수행 할 공간에 변화가 생긴 경우, 해당 변화를 반영하기 위해 공간 맵을 업데이트할 수 있다. 전자 장치는 공 간에 생긴 변화를 이미 반영하고 있는 공간 맵을 적어도 하나의 외부 장치로부터 수신하여, 기존의 공간 맵을 업데이트 할 수 있다. 전자 장치는 기존의 공간 맵을 기초로, 새로운 공간 맵을 생성할 수 있다. 도 3a를 보면, 전자 장치는 저장되어 있던 기존의 공간 맵(이하, 제1 공간 맵)을 불러올 수 있다. 제1 공 간 맵은 베이스 레이어, 제1 레이어, 제2 레이어, 및 제3 레이어로 구성되어 있다. 이하, 설명의 편의상, 제1 레이어 내지 제3 레이어가 도 2b의 임의의 분류 기준에 따라 객체를 포함하는 것을 전제로 설명한다. 제1 공간 맵이 불과 몇분 전에 생성되었거나 제1 공간 맵이 이용된 후로 공간 내에 변화가 없는 경우, 전자 장치는 제1 공간 맵을 그대로 활용하여, 새로운 공간 맵(이하, 제2 공간 맵)을 획득하고, 새로운 태스크를 수행하는데 제2 공간 맵을 이용할 수 있다. 도 3b를 보면, 전자 장치는 저장되어 있던 제1 공간 맵을 불러올 수 있다. 전자 장치가 태스크를 수 행함에 있어서, 자주 이동하는 ML 4의 객체 정보는 필요하지 않거나, 1주일 이상 이동이 없었던 객체 정보만 이 용하는 경우, 제1 공간 맵을 구성하는 레이어들 중에 베이스 레이어, 제1 레이어, 및 제2 레이어를 선별하거나 제1 공간 맵에서 제3 레이어를 제거하여, 제2 공간 맵을 획득할 수 있다. 도 3c를 보면, 전자 장치는 저장되어 있던 제1 공간 맵을 불러올 수 있다. 전자 장치가 새로운 태스 크를 수행함에 있어서, ML 1의 객체 정보만 필요하거나, 1개월 이상 이동이 없었던 객체 정보만 이용하는 경우, 제1 공간 맵을 구성하는 레이어들 중에 베이스 레이어 및 제1 레이어를 선별하거나 제1 공간 맵에서 제2 레이어 와 제3 레이어를 제거하여, 제2 공간 맵을 획득할 수 있다. 도 3d를 보면, 전자 장치는 저장되어 있던 제1 공간 맵을 불러올 수 있다. 전자 장치가 새로운 태스 크를 수행함에 있어서, 이동이 가능한 ML 2, ML 3, 및 ML 4에 해당하는 객체들의 최신 정보를 반영할 필요가 경 우, 제1 공간 맵을 구성하는 레이어들 중에 베이스 레이어 및 제1 레이어를 선별하거나 제1 공간 맵에서 제2 레 이어와 제3 레이어를 제거하여, 제2 공간 맵을 획득할 수 있다. 이후, 전자 장치는 외부 장치로부터 수신 된 공간 맵에서 제2 레이어와 제3 레이어를 추출하여, 제2 공간 맵에 반영하여, 제3 공간 맵을 획득할 수 있다. 또는, 전자 장치에 구비된 적어도 하나의 센서를 이용하여, ML 2, ML 3, 및 ML 4에 해당하는 객체들을 검 출하여, 제2 공간 맵에 반영하여, 제3 공간 맵을 획득할 수 있다. 도 4는 본 개시의 일 실시예에 따른 공간 맵을 획득하는 방법을 설명하기 위한 흐름도이다. 전자 장치는 제1 공간 맵을 획득할 수 있다.(S410) 제1 공간 맵은 객체의 속성 정보에 기초한 복수의 레이 어들로 구성될 수 있다. 제1 공간 맵은 전자 장치에서 생성되었거나, 전자 장치의 외부 장치로부터 수신된 것일 수 있다. 전자 장치는 제1 공간 맵에 대한 업데이트가 필요한지 판단할 수 있다.(S420) 예를 들어, 전자 장치 는 태스크의 특성에 따라 제1 공간 맵의 업데이트가 필요한 지 판단할 수 있다. 태스크는 전자 장치 고유 의 용도 또는 전자 장치에서 실행할 수 있는 기능을 통해 전자 장치가 수행하도록 설정된 작업을 의 미한다. 태스크의 수행과 관련된 설정 정보는 사용자에 의해 전자 장치에 직접 입력되거나 모바일 장치나 전용 리모컨 등과 같은 단말을 통해 전자 장치로 전송될 수 있다. 예를 들어, 전자 장치가 로봇 청소 기인 경우, 로봇 청소기의 태스크는 댁내 청소 또는 사용자가 설정한 영역에 대한 청소이거나 예약 기능에 따른 예약 청소, 저소음 모드 청소 등일 수 있다. 전자 장치는 태스크의 수행에 이용되는 정보가 부족한 경우, 제1 공간 맵에 대한 업데이트가 필요한 것으로 판단할 수 있다. 전자 장치는 태스크가 수행될 공간 내의 객체 정보에 대한 최신 정보가 필요한 경우, 업데이트가 필요한 것으로 판단할 수 있다. 또는, 전자 장치 는 제1 공간 맵을 획득한 시점으로부터의 경과 시간이나 설정된 업데이트 주기에 따라 제1 공간 맵에 대한 업데 이트가 필요한지 판단할 수 있다. 제1 공간 맵에 대한 업데이트가 필요 없는 경우, 전자 장치는 제1 공간 맵을 태스크를 수행하는데 이용되는 제2 공간 맵으로써 활용할 수 있다. 제1 공간 맵에 대한 업데이트가 필요한 경우, 전자 장치는 객체 정보를 획득할 수 있다.(S430) 전자 장치 는 적어도 하나의 센서를 이용하여, 공간 스캔 정보 또는 객체 정보를 직접 수집할 수 있다. 전자 장치 는 외부 장치로부터 공간 맵의 일부 또는 전부를 수신하거나, 공간 스캔 정보 또는 객체 정보를 수신할 수 있다. 전자 장치는 획득된 공간 스캔 정보 또는 객체 정보를 이용하여, 제1 공간 맵에 공간 스캔 정보 또는 객체 정보를 업데이트할 수 있다.(S440) 예를 들어, 전자 장치는 이동이 잦은 객체에 대해서는 최신 위치 정보 가 반영되도록 해당 객체 정보 또는 해당 객체가 위치하던 곳의 공간 스캔 정보를 새로 획득하여, 제1 공간 맵 에 업데이트할 수 있다. 전자 장치는 제2 공간 맵을 획득할 수 있다.(S450) 전자 장치는 제1 공간 맵을 그대로 활용하거나, 일부 객체 정보나 일부 레이어가 수정된 형태의 제1 공간 맵을 활용하거나, 제1 공간 맵을 업데이트 함으로써, 제2 공간 맵을 획득할 수 있다. 한편, 태스크를 수행하기 위해 이용되는 제2 공간 맵은 전자 장치의 기능이나 태스크의 특성에 따라, 적절 한 형태의 맵으로 변형되거나 생성되어 이용될 수 있다. 예를 들어, 전자 장치가 로봇 청소기인 경우, 공 간 맵에 기초한 네비게이션 맵을 생성하여, 네비게이션 맵이 제공하는 이동 경로를 따라 청소를 수행할할 수 있 다. 본 개시의 일 실시예에서, 공간 맵은 서로 다른 장치들로부터 수집된 공간 스캔 정보 또는 객체 정보를 취합함 으로써 생성될 수 있다. 공간 맵은 수집된 각각의 정보가 어느 장치로부터 획득된 것인지 또는 어느 위치 및/또 는 시점으로부터 획득된 것인지 나타내는 메타데이터 형태의 정보를 더 포함할 수 있다. 예를 들어, 서로 다른 장치들이 서로 다른 위치 및/또는 시점에서 소정의 공간을 스캔하고 객체를 검출한 경우, 공간 맵은 각 장치들 로부터 획득된 영상 또는 영상으로부터 획득된 객체 인식 결과를 이용하여 생성될 수 있다. 공간 맵은 공간 내 의 각 객체에 대하여, 객체 인식 결과와 객체 인식 결과가 어느 위치 및/또는 시점으로부터 획득된 것인지를 나 타내는 정보가 태그 또는 레이블링(labeling)되어 있을 수 있다. 앞서 설명한 바와 같이, 공간 맵은 공간에서 수행되는 전자 장치의 태스크의 특성을 고려하여 생성될 수 있다. 공간에서 수행되는 전자 장치의 태스크는 해당 공간 내에 위치한 객체의 영향을 받으므로, 클라우드 서버는 공간 내에 위치한 객체들에 대한 객체 정보를 데이터베이스에 저장하고 관리할 수 있다. 데이터베 이스는 객체의 식별 정보 및 속성 정보와 같은 객체 정보를 객체별로 등록하여 저장할 수 있다. 데이터베이스에 저장된 객체 정보는 공간 맵을 생성하는데 이용될 뿐만 아니라, 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는(unrecognizable) 객체를 식별하는데 이용될 수 있다. 객체 인식 모델은 공간 스캔 정보로부터 객체를 인식하는데 이용된다. 객체 인식 모델은 공간 스캔 정보에 해당 하는 이미지로부터 객체를 인식하는데 이용될 수 있다. 객체 인식 모델은 이미지를 입력으로 받아, 이미지 또는 이미지 내의 객체가 객체의 카테고리에 해당하는 각각의 클래스에 속하는 확률 값을 출력할 수 있다. 객체 인식 모델의 출력 값을 통해, 객체가 어느 클래스에 속하는지 결정될 수 있다. 객체 인식 모델은 이미지 내에서 특징 을 추출하고, 추출된 특징에 기초하여, 객체의 클래스를 분류할 수 있다. 예를 들어, 객체 인식 모델은 이미지 내에서 객체가 존재할 것으로 추정되는 위치와 특징 값을 획득하고, 획득된 특징 값을 완전 연결 층들(fully connected layers)의 각 레이어에 포함된 노드들과 에지를 따라 연산시킴으로써, 객체의 클래스를 분류할 수 있 다. 객체 인식 모델은 소프트맥스(softmax) 함수와 같은 활성화 함수를 이용하여, 각각의 클래스 별로 계산된 확률값을 출력할 수 있다. '객체 인식 모델을 통해 객체를 인식할 수 없다'는 것은 객체 인식 모델을 이용하여 공간 스캔 정보로부터 추출 된 특징 값에 기초한 객체의 분류 결과, 특정한 클래스의 객체로 판정하는 것에 실패한 것을 의미한다. 즉, '객 체 인식 모델을 통해 인식할 수 없는 객체'는 객체 인식 모델을 이용하여 공간 스캔 정보로부터 추출된 특징 값 에 기초한 객체의 분류 결과, 특정한 클래스로의 판정이 실패한 객체를 의미한다. 공간 스캔 정보 내에 객체의 존재에 대한 신뢰도는 높으나, 객체의 클래스 별 확률값이 신뢰할 수 없는 수준인 경우, 공간 스캔 정보 내의 객체는 객체 인식 모델을 통해 인식할 수 없는 것으로 처리될 수 있다. 객체 인식 모델은 객체 인식 결과로서 객체 인식 모델이 인식할 수 있는 모든 객체의 클래스 별 확률값(또는 스코어) 중 상위 n개의 값들을 출력할 수 있다. 출력된 값은 그 값이 클수록, 객체가 해당 클래스일 가능성이 높다는 것을 의미한다. 다만, 출력된 값은 객체 인식 결과를 신뢰할 수 있는 것인지 결정하는 기준인 소정의 임계값 (threshold)보다 큰 값이어야 한다. 예를 들어, 객체 인식 모델은 객체 인식 결과로서, 상위 5개의 클래스에 대 한 확률값으로 '0.35'. '0.15', '0.13', '0.11', 및 '0.1'를 출력할 수 있다. 이때, 객체 인식 결과를 신뢰할 수 있는지 결정하는 기준인 소정의 임계값이 '0.4'이면, 출력된 어떠한 확률값도 '0.4'보다 크지 않으므로, 객 체 인식 모델을 통한 객체 인식은 실패한 것으로 처리될 수 있다. 공간 스캔 정보 내에 객체의 존재에 대한 신뢰도는 높으나, 객체의 클래스 별 확률값 간의 차이가 유의미하지 않는 수준이어서, 특정한 클래스의 객체로 판정할 수 없는 경우, 공간 스캔 정보 내의 객체는 객체 인식 모델을 통해 인식할 수 없는 것으로 처리될 수 있다. 예를 들어, 객체 인식 모델은 객체 인식 결과로서, 상위 5개의 클 래스에 대한 확률값으로 '0.45'. '0.44', '0.05', '0.04', 및 '0.01'를 출력할 수 있다. 이 중 클래스 A에 대 응되는 확률값 '0.45'와 클래스 B에 대응되는 확률값 '0.44'의 경우, 각각은 객체 인식 결과를 신뢰할 수 있는 것인지 결정하는 기준인 소정의 임계값 '0.4'보다 크다. 클래스 A의 확률값이 '0.01'의 미세한 차이로 클래스 B 의 확률값보다 크지만, 확률값 계산의 오차를 고려하면, 실제 객체는 클래스 A가 아닌, 클래스 B에 속할 가능성 도 충분히 존재한다. 이와 같은 경우, 객체 인식 모델을 통한 객체 인식은 실패한 것으로 처리될 수 있다. 도 5는 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체가 속한 공간을 설명하기 위한 도면이 다. 공간에 대한 공간 스캔 정보는 전자 장치에 구비된 적어도 하나의 센서를 이용하여 획득될 수 있다. 예를 들어, 전자 장치는 카메라, 라이다 센서, ToF(Time of Flight) 센서 등과 같은 센서를 구비할 수 있다. 예 를 들어, 전자 장치가 카메라를 구비하는 경우, RGB 신호를 획득하고, RGB 신호로부터 공간에 대한 이미지 를 생성할 수 있다. 다른 예를 들어, 전자 장치가 라이다 센서를 구비하는 경우, 포인트 클라우드 형태의 데이터를 획득하고, 클러스터링을 통해, 공간 내의 적어도 하나의 객체의 위치, 사이즈, 형상 등의 정보를 확인 할 수 있다. 전자 장치는 카메라를 이용하여 획득된 이미지나 라이다 센서를 이용하여 확인되는 정보와 같은 공간 스캔 정보로부터 공간에 속하는 객체를 인식할 수 있다. 전자 장치는 객체를 정확히 인식할 수 있도록, 동종이 나 이종의 복수의 센서들을 구비할 수 있다. 그럼에도 불구하고, 일부 객체들은 실내 디자인 과정에서 연출되는 디자인의 통일성이나, 객체들 간의 외형의 유사성에 의해, 정확히 인식할 수 없거나 구별이 어려울 수 있다. 도 5를 참조하면, 전자 장치가 적어도 하나의 센서를 이용하여, 거실에서 공간 스캔 정보를 획득하는 모습 을 나타내고 있다. 도 5에 도시된 바와 같이, 거실의 한쪽 벽면에 여러 개의 액자와 벽걸이 형태의 텔레비전을 배치시키는 경우, 전자 장치는 공간 스캔 정보로부터 각 객체를 정확히 인식하지 못할 수 있다. 벽걸이 형 태의 텔레비전이 사용자가 텔레비전을 시청하지 않는 경우에 명화나 사진들을 디스플레이해주는 기능이 있는 경 우, 실제 액자와 구별이 더 어려워지므로, 객체 인식 모델을 통한 객체 인식에 실패할 수 있다. 도 5에 도시된 예 외에도, 빌트인 식기세척기와 싱크대의 하부장, 냉장고와 냉동고의 경우, 객체들 간의 외형의 유사성이나 의 도된 실내 디자인 연출로 인해, 객체 인식 모델을 통해 출력된 확률값들만으로는 객체를 정확히 인식하지 못할 수가 있다. 이와 같이, 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체가 속한 공간의 경우, 클라우드 서버의 데이터베이스에 저장된 객체 정보를 이용하면, 공간 내의 객체가 정확히 인식된 공간 맵 이 생성될 수 있다. 이하, 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체가 속한 공간에 대 한 공간 맵을 획득하는 방식에 대해 상세히 설명한다. 도 6은 본 개시의 일 실시예에 따른 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체가 속한 공간에 대한 공간 맵을 획득하는 방법을 설명하기 위한 흐름도이다. S610 단계에서, 전자 장치는 적어도 하나의 센서를 이용하여 획득된 공간에 대한 공간 스캔 정보로부터 공 간에 속하는 객체를 인식할 수 있다. 예를 들어, 전자 장치는 객체 인식 모델을 이용하여, 공간 스캔 정보 로부터 공간에 속하는 객체를 인식할 수 있다. 예를 들어, 객체 인식 모델은 RGB 신호로부터 생성된 이미지나 클러스터링된 포인트 클라우드 데이터를 입력으로 하여, 객체를 분석하고 분류할 수 있다. 전자 장치는 객 체의 분석 및 분류에 따라 공간에 속하는 객체를 인식한다. 객체 인식 모델에 의해 인식되지 않거나 특정 클래 스의 객체로 분류되지 못한 객체는 인식할 수 없는(recognizable) 객체로 처리될 수 있다. 전자 장치는 객 체 인식 모델의 객체 인식 결과에 기초하여, 공간 스캔 정보를 레이블링할 수 있다. 예를 들어, 공간 스캔 정보 내에서 객체로 인식된 영역에 해당 객체의 객체 정보를 레이블링할 수 있다. S620 단계에서, 전자 장치는 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 (unrecognizable) 객체와 관련된 특징 정보를 획득할 수 있다. 예를 들어, 전자 장치는 특징 분석 모델을 이용하여, 객체 인식 결과에 따라 레이블링된 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객 체와 관련된 특징 정보를 추출할 수 있다. 예를 들어, 전자 장치는 RGB 신호로부터 생성된 이미지나 클러 스터링된 포인트 클라우드 데이터로부터 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보를 획득할 수 있다. 전자 장치는 특징 분석 모델을 이용하여, 객체 인식 결과에 따라 레 이블링된 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보를 추출할 수 있다. S630 단계에서, 전자 장치는 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보에 기초한 쿼 리(query)를 이용하여, 객체 인식 모델을 통해 인식할 수 없는 객체를 개인화된(personalized) 데이터베이스에 기초하여 식별할 수 있다. 전자 장치는 객체 인식 모델을 통해 인식할 수 없는 객체를 개인화된 데이터베 이스에 기초하여, 특정 클래스의 객체로 추론할 수 있다. 전자 장치는 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보와 개인화된 데이터베이스에 저장된 정보를 비교함으로써, 특정 클래스의 객체로 판정할 수 있다. 쿼리는 개인화된 데이터베이스에 저장된 객체별 속성 정보가 객체 인식 모델을 통해 인식할 수 없는 객체와 관 련된 특징 정보와 일정한 수준 이상으로 매칭되는 적어도 하나의 객체에 대한 객체 정보의 수집을 요청하는 것 이다. 개인화된 데이터베이스는 사용자의 자산에 속하는 객체들 각각의 속성 정보를 객체별로 등록한 것일 수 있다. 개인화된 데이터베이스는 소정의 공간별로, 사용자의 자산에 속하는 객체들 각각의 속성 정보를 객체별로 등록할 수 있다. 예를 들어, 개인화된 데이터베이스는 사용자의 집이나 회사에 위치하는 객체들의 속성 정보를 객체별로 저장할 수 있다. 개인화된 데이터베이스는 사용자의 집 안의 구역이나 회사 내의 구역 별로 위치하는 객체들의 속성 정보를 객체별로 저장할 수 있다. 객체의 속성 정보는 객체의 생산 과정에서 결정되는 모델 속성 정보 및 사용자의 사용 과정에서 결정되는 사용 속성 정보를 포함할 수 있다. 개인화된 데이터베이스 및 개인화 된 데이터베이스와 쿼리의 연동에 대해서는 도 7에서 상세히 후술한다. 전자 장치는 쿼리에 대한 응답으로, 개인화된 데이터베이스로부터 객체 후보군에 대한 정보를 획득할 수 있다. 전자 장치는 쿼리에 포함된 특징 정보와 개인화된 데이터베이스에 저장된 객체별 속성 정보를 비교 하여, 특징 정보에 대응되는 속성 정보를 가지는 객체 후보군에 대한 정보를 획득할 수 있다. 예를 들어, 전자 장치는 개인화된 데이터베이스를 포함하는 클라우드 서버에 쿼리를 전송한 것에 대한 응답으로, 클라 우드 서버로부터 객체 후보군에 대한 정보를 수신할 수 있다. 객체 후보군에 대한 정보는 특징 정보와 유 사도가 높은 속성 정보를 가지는 상위 n 개의 객체들의 식별 정보를 포함할 수 있다. 객체 후보군에 대한 정보 는 상위 n 개의 객체들의 식별 정보와 각 객체의 식별 정보에 대응되는 적어도 하나의 속성 정보를 포함할 수 있다. 적어도 하나의 속성 정보는 개체의 이미지 정보를 포함할 수 있다. 전자 장치는 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보와 객체 후보군에 포함된 객체들 각각의 이미지 정보를 비교하여, 비교 결과에 기초하여 객체 인식 모델을 통해 인식할 수 없는 객체를 식별할 수 있다. 전자 장치는 객체 인식 모델을 통해 인식할 수 없는 객체가 존재하는 영역으로부터 추정 된 이미지 정보와 객체 후보군에 포함된 객체들 각각의 이미지 정보를 비교할 수 있다. 전자 장치는 비교 결과, 추정된 이미지 정보와 유사도가 가장 높은 이미지 정보에 해당되는 객체를 객체 인식 모델을 통해 인식할 수 없는 객체로 식별할 수 있다. 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보를 확보할 수 없는 경우, 전자 장치는 전자 장치의 위치를 소정의 시점으로 이동시키고, 이동된 위치에서 적어 도 하나의 센서를 이용하여, 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보를 생성할 수 있 다. S640 단계에서, 전자 장치는 공간 스캔 정보 및 공간에 속하는 객체에 대한 객체 정보에 기초하여, 공간에 대한 공간 맵을 생성할 수 있다. 공간에 속하는 객체에 대한 객체 정보는, 공간 스캔 정보로부터 객체 인식 모 델을 통해 인식한 객체에 대한 객체 정보와 객체 인식 모델을 통해 인식할 수 없었으나 개인화된 데이터베이스 에 기초하여 식별된 객체에 대한 객체 정보를 포함할 수 있다. 예를 들어, 전자 장치는 공간 스캔 정보 및 공간에 속하는 객체에 대한 객체 정보에 기초하여, 개인화된 데이터베이스를 업데이트할 수 있다. 전자 장치 는 업데이트된 개인화된 데이터베이스에 기초하여, 공간에 대한 공간 맵을 생성할 수 있다. 도 7은 본 개시의 일 실시예 따라 클라우드 서버에 구축되는 데이터베이스를 설명하기 위한 도면이다. 클라우드 서버는 전자 장치, IoT 기기들(300-1, 300-2, 300-3), 사용자 단말(미도시), 전자 제품이 나 가구 등과 같은 공간에 설치 또는 배치되는 객체를 판매하는 웹사이트나 홍보하는 SNS(Social Network Service)에 연결되어, 객체 정보를 수신하여 저장할 수 있다. 클라우드 서버는 공간 내에 위치한 객체들에 대한 객체 정보를 데이터베이스에 저장하고 관리할 수 있다. 클라우드 서버는 전자 장치, IoT 기기들 (300-1, 300-2, 300-3), 사용자 단말(미도시) 등과 같이 외부 장치로부터 데이터베이스에 대한 요청이 있는 경 우, 해당 요청에 대한 응답으로, 데이터베이스 일부 또는 전부나 데이터베이스에 저장된 소정의 정보를 외부 장 치로 전송해 줄 수 있다. 예를 들어, 클라우드 서버는 소정의 공간 내에 전자 장치 또는 IoT 기기들(300-1, 300-2, 300-3)이 설치 또는 배치되면, 전자 장치나 IoT 기기들(300-1, 300-2, 300-3)로부터 객체 정보를 수신할 수 있다.클라우드 서버는 사용자 단말(미도시)로부터 객체 정보를 수신할 수 있다. 사용자는 전자 제품이나 가구 등의 객체를 구매한 뒤, 사용자 단말(미도시)에 구매한 객체의 객체 정보를 직접 입력하거나 모델명과 같은 제 품 식별 번호나 QR(Quick Response) 코드를 촬영하여 클라우드 서버로 전송할 수 있다. 클라우드 서버 는 소정의 공간 내에 전자 제품이나 가구 등과 같은 객체가 설치 또는 배치되면, 해당 객체를 판매하는 웹 사이트나 홍보하는 SNS로부터 객체 정보를 수신할 수 있다. 한편, 소정의 공간 내에 설치 또는 배치되어 있던 기존의 객체가 소정의 공간으로부터 반출되는 경우, 해당 객 체에 관련된 객체 정보는 클라우드 서버의 데이터베이스로부터 삭제될 수 있다. 클라우드 서버는 데이터베이스를 사용자 및/또는 공간별로 개인화하여 관리할 수 있다. 개인화된 데이터베 이스는 사용자의 자산에 속하는 객체들 각각의 속성 정보를 객체별로 등록한 것일 수 있다. 개인화된 데이터베 이스는 소정의 공간별로 사용자의 자산에 속하는 객체들 각각의 속성 정보를 객체별로 등록한 것일 수 있다. 도 7을 참조하면, 개인화된 데이터베이스는 객체별로 객체의 카테고리 및 모델명의 식별 정보와 객체의 속성 정보 를 저장할 수 있다. 객체의 속성 정보는 객체의 생산 과정에서 결정되는 모델 속성(Model-property) 정보 및 사 용자의 사용 과정에서 결정되는 사용 속성(Use-property) 정보를 포함할 수 있다. 모델 속성 정보는 객체의 이미지, 색상, 사이즈, 이동성 레벨 등의 정보일 수 있으나, 이에 제한되는 것은 아니 다. 객체의 이미지는 사용자가 직접 촬영한 사진으로서, 정면 사진 및 설치 또는 배치 이후 사진일 수 있다. 객 체의 이미지는 제조사에서 제공하는 해당 제품의 사진들로서, 카탈로그나 웹사이트에 올라온 사진일 수 있다. 객체의 이미지는 타 사용자가 업로드한 사진일 수 있다. 또한, 객체의 이미지는 3차원 모델이거나 특정 시점 (viewpoint)의 촬영 각도로 촬영된 사진들로, 가공된 이미지일 수 있다. 객체의 색상은 해당 객체의 주된 색상 또는 해당 객체의 특색이 있는 부분의 색상일 수 있다. 도 7을 보면, 객체의 카테고리가 \"TV\"이고, 모델명이 \"The Frame 85\"인 전자 제품은 이미지 정보가 \"제조사에서 제공하는 해당 제품의 사진들\"이고, 색상은 \"블랙\", 사이즈(폭 x 높이 x 깊이)가 \"1904.3 x 1085.3 x 26.9\", 이동성 레벨이 \"ML2\"인 모델 속성 정보를 가짐을 알 수 있다. 객체의 카테고리가 \"정수기\"이고, 모델명이 \"냉온 정수기\"인 전자 제품은 이미지 정보가 \"타 사용자가 동일한 제품을 업로드한 사진\"이고, 색상은 \"그레이\", 사이 즈(폭 x 높이 x 깊이)가 \"165 x 400 x 250\", 이동성 레벨이 \"ML2\"인 모델 속성 정보를 가짐을 알 수 있다. 객체 의 카테고리가 \"테이블\"이고, 모델명이 \"수 제작\"인 가구는 이미지 정보가 \"사용자가 직접 촬영한 사진들\"이고, 색상은 \"화이트\", 사이즈(폭 x 높이 x 깊이)가 \"1600 x 900 x 800\", 이동성 레벨이 \"ML3\"인 모델 속성 정보를 가짐을 알 수 있다. 사용 속성 정보는 객체의 설치 위치, 구매 일시, 라이프 사이클 등의 정보일 수 있으나, 이에 제한되는 것은 아 니다. 도 7을 보면, 객체의 카테고리가 \"TV\"이고, 모델명이 \"The Frame 85\"인 전자 제품은 설치 위치가 \"거실\" 이고, 구매 일시는 \"2022.12(2022년 12월을 의미함)\" 라이프 사이클은 \"15Y(15년을 의미함)\"인 사용 속성 정보 를 가짐을 알 수 있다. 객체의 카테고리가 \"정수기\"이고, 모델명이 \"냉온정수기\"인 전자 제품은 설치 위치가 \" 주방\"이고, 구매 일시는 \"2023.01\" 라이프 사이클은 \"5Y\"인 사용 속성 정보를 가짐을 알 수 있다. 객체의 카테 고리가 \"테이블\"이고, 모델명이 \"수 제작\"인 가구는 설치 위치가 \"서재\"이고, 구매 일시는 \"2023.02\" 라이프 사 이클은 \"10Y\"인 사용 속성 정보를 가짐을 알 수 있다. 도 7에 개시된 개인화된 데이터베이스의 속성 정보의 값은 설명을 위한 예시일 뿐 그 형식이 제한되는 것은 아 니다. 예를 들어, 모델 속성 정보 중 이미지 정보는 실제 이미지일 수도 있고, 이미지를 분석한 특징 정보의 형 태일 수 있다. 개인화된 데이터베이스는 클라우드 서버에 입력되지 않아 알 수 없는 속성 정보의 경우, 해 당 속성 정보가 업데이트될 때까지, 해당 속성 정보의 값을 \"NULL\"로 할 수 있다. 개인화된 데이터베이스에 저장된 객체 정보는 공간 맵을 생성하는데 이용될 있다. 예를 들어, 공간 스캔 정보에 서 인식된 객체의 경우, 공간 맵의 생성 시에, 공간 맵에서의 해당 객체의 위치에 개인화된 데이터베이스에 저 장된 객체 정보를 레이블링 또는 태그해 둘 수 있다. 또한, 개인화된 데이터베이스에 저장된 객체 정보는 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없 는 객체를 식별하는데 이용될 수 있다. 전자 장치나 IoT 장치들에서 획득한 공간 스캔 정보로부터 객체를 정확히 인식할 수 없거나 다른 객체와 구별할 수 없거나 오인식 가능성이 있는 경우, 전자 장치는 개인화 된 데이터베이스에 저장된 객체 정보를 이용할 수 있다. 예를 들어, 도 5에서와 같이, 여러 개의 액자들과 명화를 디스플레이하는 벽걸이 형태의 텔레비전의 경우, 의도 된 실내 디자인 연출로 인해, 텔레비전을 인식할 수 없거나 액자로 오인식할 수 있다. 이때, 전자 장치에서 획득된 공간 스캔 정보가 \"거실\"에서 촬영된 이미지이고, 이미지 내에서 해당 객체의 테두리의 색상이 \"블랙\"이고, 해당 객체의 폭과 높이에 해당하는 사이즈가 \"1904.3 x 1085.3\"와 유사한 것으로 확인되는 경우, 도 7에 도시된 개인화된 데이터베이스에 의하면, 텔레비전인 것으로 정확히 추론할 수 있다. 이와 같이, 객체들 간의 외형의 유사성이나 의도된 실내 디자인 연출로 인해, 공간 스캔 정보만으로 객체를 인식할 수 없거나 오인 식할 우려가 있는 경우, 개인화된 데이터베이스에 저장된 객체 정보를 이용하면, 공간 내의 객체를 정확히 식별 할 수 있다. 개인화된 데이터베이스에 저장된 객체 정보 중 다른 객체들의 속성 정보와 겹치지 않는 속성 정보는 키(key) 속 성 정보가 될 수 있다. 예를 들어, 객체 인식 모델을 통해 인식할 수 없는 객체에 해당하는 영역으로부터 검출 된 사이즈가 개인화된 데이터베이스에 저장된 특정한 수치와 같고, 다른 객체들의 사이즈와 다른 경우, 사이즈 는 키 속성 정보가 될 수 있다. 이와 같이, 객체 인식 모델을 통해 인식할 수 없는 객체에 해당하는 영역으로부 터 검출된 특징 정보가 개인화된 데이터베이스에 저장된 특정 객체의 키 속성 정보에 해당하는 경우, 전자 장치 는 객체 인식 모델을 통해 인식할 수 없는 객체를 키 속성 정보를 가지는 특정 객체로 식별할 수 있다. 객체 인식 모델을 통해 인식할 수 없는 객체에 해당하는 영역으로부터 검출된 적어도 하나의 특징 정보 중에서 키 속성 정보가 없는 경우, 전자 장치는 적어도 하나의 특징 정보와 가장 높은 수준으로 매칭되는 속성 정 보를 가지는 객체를 객체 인식 모델을 통해 인식할 수 없는 객체의 객체 인식 결과로 결정할 수 있다. 또는, 전 자 장치는 적어도 하나의 특징 정보와 일정한 수준 이상으로 매칭되는 속성 정보를 가지는 객체들을 객체 후보군으로 선정할 수 있다. 개인화된 데이터베이스는 객체 인식 모델을 통해 인식할 수 없는 객체에 해당하는 영역으로부터 검출된 적어도 하나의 특징 정보에 기초하여 생성된 쿼리(query)에 응답하여, 개인화된 데이터베이스에 저장된 객체 정보를 리 턴(return)하도록 설계될 수 있다. 전자 장치는 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특 징 정보에 기초한 쿼리를 이용하여, 객체 인식 모델을 통해 인식할 수 없는 객체를 개인화된 데이터베이스에 기 초하여 식별할 수 있다. 전자 장치는 쿼리를 이용하여, 개인화된 데이터베이스에 저장된 객체별 속성 정보 가 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보와 동일하거나 가장 높은 수준 또는 일정한 수준 이상으로 매칭되는 적어도 하나의 객체에 대한 객체 정보의 수집을 요청할 수 있다. 한편, 개인화된 데이터베이스에 저장된 객체 정보를 활용한 공간 맵은 로봇 청소기의 운용, 효율적인 가전 제품 배치 및 실내 디자인 추천 등에 활용할 수 있다. 또한, 공간 맵에 객체 정보를 레이블링(labelling) 또는 태그 하여 붙임으로서, 공간 내의 객체들 및 객체들이 위치한 공간의 상태 정보를 공간 맵을 통해 전달할 수 있다. 또한, 개인화된 데이터베이스에 저장된 객체의 속성 정보의 조합에 따르면, 공간 맵은 라이프 사이클이 도래한 제품 구매를 추천하는 기능을 제공할 수 있다. 도 8은 본 개시의 일 실시예에 따라 공간 맵을 획득하는 전자 장치의 동작을 설명하기 위한 도면이다. 전자 장치는 적어도 하나의 센서를 이용하여, 적어도 하나의 객체를 포함하는 공간을 스캔하고, 공간 스캔 정보를 획득할 수 있다. 공간 스캔 정보는 센서의 종류에 따라 서로 다른 형태의 정보를 포함할 수 있다. 예를 들어, 센서가 카메라와 같은 이미지 센서인 경우, 공간 스캔 정보는 이미지가 될 수 있다. 센서가 라이다 센서 인 경우, 공간 스캔 정보는 포인트 클라우드 데이터가 될 수 있다. 전자 장치는 획득된 공간 스캔 정보를 객체 인식 모델에 입력하여, 공간에 속하는 객체를 인식할 수 있다. 객체 인식 모델은 공간 스캔 정보를 입력으로 받아 객체 인식 결과를 출력할 수 있다. 객체 인식 결과는 객체 인식 모델을 통해 인식된 객체와 객체 인식 모델을 통해 인식할 수 없는 객체로 나눌 수 있다. 전자 장치 는 객체 인식 결과에 기초하여, 공간 스캔 정보를 레이블링할 수 있다. 객체 인식 모델에 의해 인식된 객체는 객체의 분석 및 분류가 이루어져, 공간 스캔 정보 내의 각각의 객체에 대하여, 객체 식별 정보를 레이블링할 수 있다. 객체 인식 모델을 통해 인식할 수 없는 객체는 공간 스캔 정보 내에서 객체 인식 모델을 통해 인식할 수 없는 객체에 해당하는 영역에 대하여, 객체 인식 모델을 통해 인식할 수 없는 객체임을 레이블링할 수 있다. 레 이블링된 공간 스캔 정보는 별도의 맵 데이터베이스에 저장되거나, 개인화된 데이터베이스 내의 맵 데이터베이 스에 저장될 수 있다. 전자 장치는 소정의 주기나 클라우드 서버에 저장된 데이터베이스의 업데이트가 있는 경우, 클라우드 서버로부터 개인화된 데이터베이스를 수신하여 메모리나 별도의 스토리지에 저장해 둘 수 있다. 개인 화된 데이터베이스는 자산 데이터베이스(asset DB)일 수 있다. 개인화된 데이터베이스는 맵 데이터베이스(map DB)를 더 포함할 수 있다. 자산 데이터베이스는 사용자의 자산에 속하는 객체들 각각의 속성 정보를 객체별로저장하고 관리할 수 있다. 맵 데이터베이스는 공간 맵을 생성하는데 이용되는 공간 스캔 정보 또는 레이블링된 공간 스캔 정보, 또는 공간 맵을 저장하고 관리할 수 있다. 전자 장치는 공간 스캔 정보에 객체 인식 모델을 통해 인식할 수 없는 객체가 없는 경우, 객체 식별 정보 가 레이블링된 공간 스캔 정보를 맵 데이터베이스에 업데이트할 수 있다. 전자 장치는 업데이트된 맵 데이 터베이스에 기초하여, 공간 맵을 생성할 수 있다. 전자 장치는 공간 스캔 정보에 객체 인식 모델을 통해 인식할 수 없는 객체가 있는 경우, 레이블링된 공간 스캔 정보를 특징 분석 모델에 입력하여, 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보를 획 득할 수 있다. 특징 분석 모델은 레이블링된 공간 스캔 정보 내에서 객체 인식 모델을 통해 인식할 수 없는 객 체에 대응되는 영역과 관련된 특징 정보를 추출할 수 있다. 예를 들어, 특징 분석 모델은 레이블링된 이미지 내 에서 객체 인식 모델을 통해 인식할 수 없는 객체에 대응되는 영역의 이미지, 색상, 사이즈 등에 관한 정보를 특징 정보로서 추출할 수 있다. 전자 장치는 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보에 기초한 쿼리를 이용하여, 개인화된 테이터베이스에 기초하여 객체 인식 모델을 통해 인식할 수 없는 객 체를 식별할 수 있다. 전자 장치는 쿼리에 포함된 특징 정보와 개인화된 데이터베이스에 저장된 객체 별 속성 정보를 비교하여, 특징 정보에 대응되는 속성 정보를 가지는 객체 후보군에 대한 정보를 획득할 수 있다. 객체 후보군은 적어도 하나의 객체를 포함할 수 있다. 전자 장치는 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보와 객체 후보군에 포함된 객체들 각각의 이미지 정보를 비교하고, 비교 결과에 기초 하여 객체 인식 모델을 통해 인식할 수 없는 객체를 식별할 수 있다. 공간 스캔 정보 내에서 객체 인식 모델을 통해 인식할 수 없었던 객체에 대해서까지 객체 식별이 완료되면, 객체 식별 결과가 객체 인식 모델을 통해 인 식할 수 없는 객체를 포함하는 레이블링된 공간 스캔 정보에 반영될 수 있다. 전자 장치는 공간 스캔 정보 및 공간에 속하는 객체에 대한 객체 정보에 기초하여, 공간에 대한 공간 맵을 생성할 수 있다. 전자 장치는 업데이트된 개인화된 데이터베이스에 기초하여, 공간에 대한 공간 맵을 생성 할 수 있다. 도 9는 본 개시의 일 실시예에 따라 클라우드 서버와의 통신을 통해 공간 맵을 획득하는 전자 장치의 동작을 설명하기 위한 도면이다. 앞서 도 8에서는 전자 장치가 소정의 주기나 클라우드 서버에 저장된 데이터베이스의 업데이트가 있 는 경우, 클라우드 서버로부터 개인화된 데이터베이스를 수신하여 메모리나 별도의 스토리지에 저장 해두고, 공간 맵을 생성하는 방식에 대해 설명하였다. 도 9에서는 전자 장치가 클라우드 서버에 저장 된 개인화된 데이터베이스를 이용하여 공간 맵을 생성하는 방식을 설명한다. 도 8에서 설명한 내용과 중복되는 내용에 대해서는 이하 설명을 생략한다. 클라우드 서버는 개인화된 데이터베이스를 사용자 별로 관리할 수 있다. 개인화된 데이터베이스는 사용자 의 자산에 속하는 객체들 각각의 속성 정보를 객체별로 저장하고 관리하는 자산 데이터베이스와 공간 맵을 생성 하는데 이용되는 공간 스캔 정보 또는 레이블링된 공간 스캔 정보, 또는 공간 맵을 저장하고 관리하는 맵 데이 터베이스를 포함할 수 있다. 전자 장치는 공간 스캔 정보를 획득하고, 획득된 공간 스캔 정보를 객체 인식 모델에 입력하여, 공간에 속 하는 객체를 인식할 수 있다. 전자 장치는 객체 인식 결과에 기초하여, 공간 스캔 정보를 레이블링하고, 레이블링된 공간 스캔 정보를 클라우드 서버에 전송할 수 있다. 공간 스캔 정보에 객체 인식 모델을 통해 인식할 수 없는 객체가 있는 경우, 전자 장치는 레이블링된 공간 스캔 정보를 특징 분석 모델에 입력하여, 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보를 획득할 수 있다. 전자 장치는 객체 인 식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보에 기초한 쿼리를 생성하여, 개인화된 데이터베이스를 포함하는 클라우드 서버에 전송할 수 있다. 전자 장치는 클라우드 서버에 쿼리를 전송한 것에 대한 응답으로, 클라우드 서버로부터 객체 후보군에 대한 정보를 수신할 수 있다. 클라우드 서버는 쿼리에 포함된 특징 정보와 개인화된 데이터베이스에 저장된 객체 별 속성 정보를 비교하여, 특징 정보에 대응 되는 속성 정보를 가지는 객체 후보군에 대한 정보를 전자 장치에 전송할 수 있다. 전자 장치는 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보와 객체 후보군에 포함된 객체들 각각의 이미지 정보를 비교하고, 비교 결과에 기초하여 객체 인식 모델을 통해 인식할 수 없는 객체를 식별할 수 있다. 전자 장치는 객체 식별 결과를 클라우드 서버로 전송할 수 있다. 클라우드 서버는 공간 스캔 정보 및 공간에 속하는 객체에 대한 객체 정보에 기초하여, 공간에 대한 공간 맵을 생성할 수 있다. 클라우드 서버는 업데이트된 개인화된 데이터베이스에 기초하여, 공간에 대한 공간 맵을 생성할 수 있다. 클라우드 서버는 공간에 대한 공간 맵을 전자 장치에 전송할 수 있다. 도 10 및 도 11은 본 개시의 일 실시예에 따른 전자 장치의 구성을 나타낸 블록도이다. 도 10을 참조하면, 일 실시예에 따른 전자 장치는, 메모리, 프로세서, 센싱부를 포함할 수 있으나, 이에 한정되는 것은 아니며, 범용적인 구성이 더 추가될 수 있다. 예를 들어, 도 11에 도시된 바와 같 이, 전자 장치는, 메모리, 프로세서, 센싱부 외에 통신부, 입출력부, 구동부 를 더 포함할 수 있다. 이하, 도 10 및 도 11을 참조하여, 각 구성에 대해 상세히 설명한다. 일 실시예에 따른 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 전자 장치 로 입력되거나 전자 장치로부터 생성되는 데이터를 저장할 수 있다. 메모리는 프로세서가 판독할 수 있는 명령어들, 데이터 구조, 및 프로그램 코드(program code)가 저장될 수 있다. 개시된 실시예들에 서, 프로세서가 수행하는 동작들은 메모리에 저장된 프로그램의 명령어들 또는 코드들을 실행함으로 써 구현될 수 있다. 일 실시예에 따른 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모 리 등)를 포함할 수 있으며, 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read- Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나를 포함하는 비 휘발성 메모리 및 램(RAM, Random Access Memory) 또는 SRAM(Static Random Access Memory)과 같 은 휘발성 메모리를 포함할 수 있다. 일 실시예에 따른 메모리는 전자 장치가 신경망 모델을 학습시킬 수 있도록 제어하는 하나 이상의 인 스트럭션 및/또는 프로그램을 저장할 수 있다. 예를 들어, 메모리에는 객체 인식 모듈, 특징 분석 모듈, 객체 식별 모듈, 공간 맵 생성 모듈 등이 저장될 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 명령어들이나 프로그램화된 소프트웨어 모듈을 실행함 으로써, 전자 장치가 태스크를 수행할 수 있도록 동작이나 기능을 제어할 수 있다. 프로세서는 산술, 로직 및 입출력 연산과 시그널 프로세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 프로세서는 메 모리에 저장된 하나 이상의 인스트럭션(instructions)을 실행함으로써, 전자 장치가 신경망 모델을 학습시키고, 학습된 신경망 모델을 이용하여 태스크를 수행하는 전반적인 동작들을 제어할 수 있다. 프로세서 는 메모리에 저장된 프로그램들을 실행함으로써, 적어도 하나의 센서를 포함하는 센싱부, 통신 부, 입출력부, 통신부, 구동부를 제어할 수 있다. 일 실시예에 따른 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서 (microprocessor), 그래픽 처리 장치(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 애플리케이션 프로세서 (Application Processor), 신경망 처리 장치(Neural Processing Unit) 또는 인공지능 모델의 처리에 특화된 하 드웨어 구조로 설계된 인공지능 전용 프로세서 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 프로세서를 구성하는 각 프로세서는 소정의 기능을 수행하기 위한 전용 프로세서일 수 있다. 일 실시예에 따른 인공 지능(AI; artificial intelligence) 프로세서는, 인공지능(AI) 모델을 이용하여, 전자 장치가 수행하도록 설정된 태스크의 처리를 위해, 연산 및 제어를 수행할 수 있다. AI 프로세서는, 인공 지능(AI)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전자 장치에 탑재될 수도 있다. 일 실시예에 따른 센싱부는, 전자 장치 주변 환경에 관한 정보를 감지하도록 구성되는 다수의 센서들 을 포함할 수 있다. 예를 들어, 센싱부는, 카메라, 라이다(LiDAR, Light Detection And Ranging) 센 서, 적외선 센서, 초음파 센서, ToF(Time of Flight) 센서, 자이로 센서 등을 포함 할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에 따른 카메라는 스테레오 카메라, 모노 카메라, 와이드 앵글 카메라, 어라운드 뷰 카메라 또는 3D 비전 센서 등을 포함할 수 있다. 라이다 센서는 레이저를 목표물에 비춰 사물과의 거리 및 다양한 물성을 감지할 수 있다. 라이다 센서 는 주변 사물, 지형지물 등을 감지하고 이를 3D 영상으로 모델링하는데 이용될 수 있다. 적외선 센서는 적외선을 복사해 빛이 차단됨으로써 변화를 검지하는 능동식 적외선 센서와 발광기를 가지 지 않고 외계로부터 받는 적외선의 변화만을 감지하는 수동식 적외선 센서 중 어느 하나가 될 수 있다. 예를 들 어, 적외선 근접 센서는 전자 장치의 바퀴 주변에 설치되어, 바닥으로 적외선을 조사한 후 수신함으로써, 추락 방지 센서로 사용될 수 있다. 초음파 센서는 초음파를 이용하여 물체까지의 거리를 측정할 수 있으며, 물체의 근접성에 대한 정보를 전 달하는 초음파 펄스를 방출 및 검출할 수 있다. 초음파 센서는 근접한 물체의 감지 및 투명한 물체의 감지 에 이용될 수 있다. ToF 센서는 물체로 발사한 빛이 튕겨져 돌아오는 거리를 시간으로 계산하여, 사물의 입체감과 움직임, 공 간 정보를 획득할 수 있다. ToF 센서는 복잡한 공간이나 어두운 곳, 그리고 눈앞의 장애물까지 수준 높은 사물 인지가 가능하도록 하여, 전자 장치가 장애물을 피해가도록 할 수 있다. 자이로 센서는 각속도를 검출할 수 있다. 자이로 센서는 전자 장치의 위치 측정과 방향 설정에 이용될 수 있다. 본 개시의 일 실시예에 의하면, 센싱부는 적어도 하나의 센서를 이용하여, 적어도 하나의 객체를 포함하는 공간을 스캔하고, 공간 스캔 정보를 생성하는데 이용될 수 있다. 전자 장치는 카메라, 라이다 센서 , 적외선 센서, 초음파 센서, ToF 센서, 및 자이로 센서 중 동종 또는 이종의 복수 의 센서를 이용하여, 공간 스캔 정보 또는 객체 정보를 획득함으로써, 적어도 하나의 객체를 포함하는 공간에 대한 공간 정보를 획득할 수 있다. 객체가 바라보는 방향이나 객체와 전자 장치 간의 거리 또는 상대적 위 치에 따라, 전자 장치가 객체를 인식하기 어려운 경우에는, 전자 장치는 소정의 시점으로 위치를 이 동하여, 이동된 위치에서 센싱부를 이용하여, 공간 스캔 정보 또는 객체 정보를 다시 획득할 수 있다. 통신부는, 전자 장치가 외부 장치 예컨대, 클라우드 서버, IoT 기기들(300-1, 300-2 , 300-3), 사용자 단말(미도시)과 통신을 가능하게 하는 하나 이상의 구성요소를 포함할 수 있다. 예를 들어, 통신부(14 0)는, 근거리 통신부(short-range wireless communication unit), 이동 통신부 등을 포함할 수 있으 나, 이에 한정되는 것은 아니다. 근거리 통신부(short-range wireless communication unit)는, 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, 근거리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 지그비 (Zigbee) 통신부, Ant+ 통신부, WFD(Wi-Fi Direct) 통신부, UWB(ultra wideband) 통신부, 적외선(IrDA, infrared Data Association) 통신부, 마이크로 웨이브(uWave) 통신부 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한다. 여기에서, 무선 신호는, 음성 호 신호, 화상 통화 호 신호 또는 문자/멀티미디어 메시지 송수신에 따른 다양한 형태의 데이터를 포함할 수 있다. 도 11에 도시된 바와 같이, 전자 장치는 입출력부, 구동부를 더 포함할 수 있으며, 도 11에 도 시되지 않았지만 전원부와 같은 구성을 더 포함할 수 있다. 입출력부는 입력부와 출력부을 포함할 수 있다. 입출력부는 입력부와 출력부가 분리된 형태이거나, 터치스크린과 같이 통합된 하나의 형태일 수 있다. 입출력부는 사용자로부터 입력 정 보를 수신할 수 있고, 사용자에게 출력 정보를 제공할 수 있다. 입력부는, 사용자가 전자 장치를 제어하기 위한 데이터를 입력하는 수단을 의미할 수 있다. 예를 들 어, 입력부는 키 패드(key pad), 터치 패널(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방 식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등) 등이 될 수 있다. 뿐만 아니라, 입 력부는 조그 휠, 조그 스위치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 출력부는, 오디오 신호 또는 비디오 신호 또는 진동 신호를 출력할 수 있으며, 출력부는 디스플레이 부, 음향 출력부, 및 진동 모터를 포함할 수 있다. 디스플레이부는 전자 장치에서 처리되는 정보를 표시할 수 있다. 예를 들어, 디스플레이부는 사용자의 조 작을 입력받기 위한 사용자 인터페이스를 디스플레이할 수 있다. 디스플레이부와 터치패드가 레이어 구조를 이루어 터치 스크린으로 구성되는 경우, 디스플레이부는 출력 장치 이외에 입력 장치로도 사용될 수 있다. 디스플 레이부는 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이(thin film transistor- liquid crystal display), 유기 발광 다이오드(organic light-emitting diode), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display) 중에서 적어도 하나를 포함할 수 있다. 전자 장치의 구현 형태에 따라 전자 장치는 디스플레이부를 2개 이상 포함할 수 있다. 음향 출력부는 메모리에 저장된 오디오 데이터를 출력할 수 있다. 음향 출력부는 전자 장치에서 수행 되는 기능과 관련된 음향 신호를 출력할 수 있다. 음향 출력부에는 스피커(speaker), 버저(Buzzer) 등이 포함될 수 있다. 진동 모터는 진동 신호를 출력할 수 있다. 예를 들어, 진동 모터는 오디오 데이터 또는 비디오 데이터의 출력에 대응하는 진동 신호를 출력할 수 있다. 진동 모터는 터치스크린에 터치가 입력되는 경우 진동 신호를 출력할 수 있다. 구동부는 전자 장치의 구동(주행) 및 전자 장치 내부의 장치들의 동작에 이용되는 구성들을 포 함할 수 있다. 전자 장치가 로봇 청소기인 경우, 구동부는 흡입부, 주행부 등을 포함할 수 있으나, 이에 한정되는 것은 아니며, 구동부는 전자 장치의 종류에 따라 다를 수 있다. 흡입부는, 공기를 흡입하면서 바닥의 먼지를 집진하는 기능을 하는데, 회전브러쉬 또는 빗자루, 회전브러쉬 모 터, 공기흡입구, 필터, 집진실, 공기배출구 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 흡입부는, 부 가적으로 구석 먼지를 쓸어낼 수 있는 솔이 회전되는 구조로 장착될 수도 있다. 주행부는 전자 장치에 설치된 바퀴를 각각 회전 구동시키는 모터 및 바퀴에서 발생되는 동력을 전달할 수 있도록 설치된 타이밍 벨트 등이 포함될 수 있으나, 이에 한정되는 것은 아니다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 센싱부를 이용하여 획득된 공간에 대한 공간 스캔 정보로부터 공간에 속하는 객체를 인식할 수 있다. 예를 들어, 센싱부가 카메라 및/또는 라이다 센서를 포함하는 경우, 센싱부는 공 간에 대한 공간 스캔 정보로써, RGB 신호 및/또는 포인트 클라우드 형태의 데이터를 획득할 수 있다. 프로세서 는 센싱부를 이용하여 획득된 공간 스캔 정보를 객체 인식 모델에 입력하여, 공간에 속하는 객체를 인식할 수 있다. 객체 인식 모델은 공간 스캔 정보에 기초하여, 객체를 분석하고, 분석된 객체를 분류할 수 있 다. 예를 들어, 객체 인식 모델은 RGB 신호로부터 생성된 이미지를 입력으로 하여, 이미지 내의 객체를 분석하 고 분류할 수 있다. 다른 예를 들어, 객체 인식 모델은 클러스터링된 포인트 클라우드를 입력으로 하여, 객체를 분석하고 분류할 수 있다. 프로세서는 객체의 분석 및 분류에 따라 공간에 속하는 객체를 인식할 수 있다. 객체 인식 모델에 의해 인식되지 않거나 특정 클래스의 객체로 분류되지 못한 객체는 인식할 수 없는 (recognizable) 객체로 처리될 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 공간 스캔 정보로부터 객체 인 식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보를 획득할 수 있다. 예를 들어, 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보는 RGB 신호로부터 생성된 이미지나 포인트 클 라우드 형태의 데이터로부터 획득될 수 있다. 프로세서는 객체 인식 모델을 이용하여, 공간 스캔 정보로부 터 공간에 속하는 객체를 인식한 후, 특징 분석 모델을 이용하여, 객체 인식 결과에 따라 레이블링된 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보를 추출할 수 있다. 예를 들어, 프 로세서는 제1 특징 분석 모델을 통하여 RGB 신호로부터 생성된 이미지에서 객체 인식 모델을 통해 인식할 수 없는 객체의 크기 또는 색상 등에 관한 정보를 특징 정보로서 획득할 수 있다. 다른 예를 들어, 프로세서 는 제2 특징 분석 모델을 통하여 포인트 클라우드 형태의 데이터에서 객체 인식 모델을 통해 인식할 수 없 는 객체의 형상 또는 크기 등에 관한 정보를 특징 정보로서 획득할 수 있다. 또 다른 예를 들어, 프로세서(12 0)는 제3 특징 분석 모델을 통하여, 인식된 다른 객체들과의 관계나 공간 스캔 정보가 획득된 위치 등에 기초하 여, 객체 인식 모델을 통해 인식할 수 없는 객체의 위치 정보를 특징 정보로서 획득할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보에 기초한 쿼리를 이용하여, 객체 인식 모델을 통해 인식할 수 없는 객체를 개 인화된 테이터베이스에 기초하여 식별할 수 있다. 쿼리는 개인화된 데이터베이스에 저장된 객체 별 속성 정보가 획득된 특징 정보와 일정한 수준 이상으로 매칭되는 적어도 하나의 객체에 대한 정보의 수집을 요청하는 것이다. 개인화된 데이터베이스는 외부의 클라우드 서버에 저장되어 있을 수 있다. 개인화된 테이터베이스는 클라우드 서버에 의해 관리될 수 있다. 전자 장치는 소정의 주기나 클라우드 서버에 저장된 데이터베이스의 업데이트가 있는 경우, 클라우드 서버로부터 개인화된 데이터베이스를 수신하여 메모리 나 별도의 스토리지에 저장해 둘 수 있다. 프로세서는 쿼리에 대한 응답으로, 개인화된 데이터베이스로부터 객체 후보군에 대한 정보를 획득할 수 있 다. 개인화된 데이터베이스는 사용자의 자산에 속하는 객체들 각각의 속성 정보를 객체별로 등록한 것이다. 속 성 정보는 객체의 생산 과정에서 결정되는 모델 속성 정보 및 사용자의 사용 과정에서 결정되는 사용 속성 정보 를 포함할 수 있다. 예를 들어, 프로세서는 쿼리에 포함된 특징 정보와 개인화된 데이터베이스에 저장된 객체 별 속성 정보를 비교하여, 특징 정보에 대응되는 속성 정보를 가지는 객체 후보군에 대한 정보를 획득할 수 있다. 예를 들어, 프로세서는 통신부를 통해, 개인화된 데이터베이스를 포함하는 클라우드 서버 에 쿼리를 전송한 것에 대한 응답으로, 클라우드 서버로부터 객체 후보군에 대한 정보를 수신할 수 있다. 프로세서는 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보와 객체 후보군에 포 함된 객체들 각각의 이미지 정보를 비교하여, 비교 결과에 기초하여 객체 인식 모델을 통해 인식할 수 없는 객 체를 식별할 수 있다. 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보를 확보할 수 없는 경 우, 프로세서는 전자 장치의 위치를 소정의 시점으로 이동시킬 수 있다. 프로세서는 이동된 위 치에서 센싱부를 이용하여, 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보를 생성 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 공간 스캔 정보 및 공간에 속 하는 객체에 대한 객체 정보에 기초하여, 공간에 대한 공간 맵을 생성할 수 있다. 프로세서는 공간 스캔 정보 및 공간에 속하는 객체에 대한 객체 정보에 기초하여, 개인화된 데이터베이스를 업데이트할 수 있다. 프로 세서는 업데이트된 개인화된 데이터베이스에 기초하여, 공간에 대한 공간 맵을 생성할 수 있다. 도 12는 본 개시의 일 실시예에 따른 서버의 구성을 도시한 블록도이다. 일 실시예에 따른 서버는 메모리, 프로세서, 통신부, 스토리지를 포함할 수 있다. 메모리는 서버를 구동하고 제어하기 위한 다양한 데이터, 프로그램 또는 어플리케이션을 저장할 수 있다. 메모리에 저장된 하나 이상의 명령어들 또는 어플리케이션은 프로세서에 의해 실행될 수 있다. 메모리에는 데이터베이스 관리 모듈, 공간 맵 생성 모듈과 이에 대응되는 데이터 및 프로그램 명령어 코드 들이 저장될 수 있다. 프로세서는 서버를 전반적으로 제어할 수 있다. 일 실시예에 따른 프로세서 는 메모리에 저장되는 하나 이상의 명령어들을 실행할 수 있다. 통신부는 근거리 통신망(Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 부가가치 통 신망(Value Added Network; VAN), 이동 통신망(mobile radio communication network), 위성 통신망 및 이들의 상호 조합을 통하여 통신을 하게 하는 하나 이상의 구성요소를 포함할 수 있다. 스토리지는 개인화된 데이터베이스가 저장될 수 있다. 개인화된 데이터베이스는 사용자의 자산에 속하는 객체들 각각의 속성 정보를 객체별로 저장하고 관리하는 자산 데이터베이스일 수 있다. 개인화된 데이터베이스 는 공간 맵을 생성하는데 이용되는 공간 스캔 정보 또는 레이블링된 공간 스캔 정보, 또는 공간 맵을 저장하고 관리하는 맵 데이터베이스를 더 포함할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 개인화된 데이터베이스를 사용자 및/또는 공간별로 관리할 수 있다. 개인화된 데이터베이스의 구 축 및 관리에 대해서는 앞서 도 7에서 설명하였는 바, 상세한 설명은 생략한다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 통신부를 통해, 외부 장치로부터 개인화된 데이터베이스에 관련된 요청이 있는 경우, 해당 요청에 대한 응답으로, 데이터베이스 일부 또는 전부나 데이터베이스에 저장된 소정의 정보를 외부 장치로 전송 해 줄 수 있다. 예를 들어, 클라우드 서버는 전자 장치로부터 수신된 쿼리에 포함된 특징 정보와 개 인화된 데이터베이스에 저장된 객체 별 속성 정보를 비교하여, 특징 정보에 대응되는 속성 정보를 가지는 객체 후보군에 대한 정보를 전자 장치에 전송할 수 있다. 다른 예를 들어, 클라우드 서버는 전자 장치 로부터 수신된 공간 맵 요청에 따라, 사용자의 자산에 속하는 객체들 각각의 속성 정보를 객체별로 저장하 고 관리하는 자산 데이터베이스와 공간 스캔 정보 또는 레이블링된 공간 스캔 정보, 또는 공간 맵을 저장하고 관리하는 맵 데이터베이스에 기초하여 공간 맵을 생성하여, 전자 장치로 전송할 수 있다. 한편, 본 개시의 실시예들은 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어 를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스 될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨 터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구 현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독 가 능 명령어, 데이터 구조, 또는 프로그램 모듈과 같은 변조된 데이터 신호의 기타 데이터를 포함할 수 있다. 또한, 컴퓨터에 의해 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다 는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경 우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 본 개시의 일 실시예에 따르면, 공간 맵을 획득하는 방법이 제공된다. 공간 맵을 획득하는 방법은 적어도 하나 의 센서를 이용하여 획득된 공간에 대한 공간 스캔 정보로부터 공간에 속하는 객체를 인식하는 단계(S610)를 포 함한다. 또한, 공간 맵을 획득하는 방법은 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보를 획득하는 단계(S620)를 포함한다. 또한, 공간 맵을 획득하는 방법은 획득된 특징 정보에 기 초한 쿼리를 이용하여, 객체 인식 모델을 통해 인식할 수 없는 객체를 개인화된 데이터베이스에 기초하여 식별 하는 단계(S630)를 포함한다. 또한, 공간 맵을 획득하는 방법은 공간 스캔 정보 및 공간에 속하는 객체에 대한 객체 정보에 기초하여, 공간에 대한 공간 맵을 생성하는 단계(S640)를 포함한다. 또한, 본 개시의 일 실시예에 따르면, 객체 인식 모델을 통해 인식할 수 없는 객체를 개인화된 데이터베이스에 기초하여 식별하는 단계(S630)는 쿼리에 대한 응답으로, 개인화된 데이터베이스로부터 객체 후보군에 대한 정보 를 획득하는 단계를 포함한다. 또한, 객체 인식 모델을 통해 인식할 수 없는 객체를 개인화된 데이터베이스에 기초하여 식별하는 단계(S630)는 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보와 객체 후 보군에 포함된 객체들 각각의 이미지 정보를 비교하여, 비교 결과에 기초하여 객체 인식 모델을 통해 인식할 수 없는 객체를 식별하는 단계를 포함한다. 또한, 객체 후보군에 대한 정보를 획득하는 단계는 쿼리에 포함된 특징 정보와 개인화된 데이터베이스에 저장된 객체 별 속성 정보를 비교하여, 특징 정보에 대응되는 속성 정보를 가지는 객체 후보군에 대한 정보를 획득한다. 또한, 쿼리는 개인화된 데이터베이스에 저장된 객체 별 속성 정보가 획득된 특징 정보와 일정한 수준 이상으로 매칭되는 적어도 하나의 객체에 대한 객체 정보의 수집을 요청하는 것이다. 또한, 비교 결과에 기초하여 객체 인식 모델을 통해 인식할 수 없는 객체를 식별하는 단계는 적어도 하나의 센 서를 포함하는 전자 장치의 위치를 소정의 시점으로 이동시키는 단계와 이동된 위치에서 적어도 하나의 센 서를 이용하여, 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보를 생성하는 단계를 더 포함 한다. 또한, 객체 후보군에 대한 정보를 획득하는 단계는 개인화된 데이터베이스를 포함하는 클라우드 서버에 쿼 리를 전송한 것에 대한 응답으로, 클라우드 서버로부터 객체 후보군에 대한 정보를 수신한다. 또한, 본 개시의 일 실시예에 따르면, 공간에 속하는 객체를 인식하는 단계(S610)는 객체 인식 모델을 이용하여, 공간 스캔 정보로부터 공간에 속하는 객체를 인식한다. 또한, 특징 정보를 획득하는 단계(S620)는 특 징 분석 모델을 이용하여, 객체 인식 결과에 따라 레이블링된 공간 스캔 정보로부터 객체 인식 모델을 통해 인 식할 수 없는 객체와 관련된 특징 정보를 추출한다. 또한, 본 개시의 일 실시예에 따르면, 공간 맵을 획득하는 방법은 공간 스캔 정보 및 공간에 속하는 객체에 대 한 객체 정보에 기초하여, 개인화된 데이터베이스를 업데이트하는 단계를 더 포함한다. 또한, 공간에 대한 공간맵을 생성하는 단계(S640)는 업데이트된 개인화된 데이터베이스에 기초하여, 공간에 대한 공간 맵을 생성한다. 또한, 개인화된 데이터베이스는 사용자의 자산에 속하는 객체들 각각의 속성 정보를 객체별로 등록한 것이다. 또한, 속성 정보는 객체의 생산 과정에서 결정되는 모델 속성 정보 및 사용자의 사용 과정에서 결정되는 사용 속성 정보를 포함한다. 본 개시의 일 실시예에 따르면, 전술한 방법을 실행시키기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록 매체를 제공할 수 있다. 본 개시의 일 실시예에 따르면, 전자 장치는 하나 이상의 인스트럭션을 저장하는 메모리, 메모리 에 저장된 하나 이상의 인스트럭션을 실행하는 프로세서, 및 적어도 하나의 센서를 포함하는 센싱부 를 포함한다. 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 센싱부를 이용하여 획득된 공간에 대한 공간 스캔 정보로부터 공간에 속하는 객체를 인식한다. 또한, 프로세서는 하나 이상의 인스트 럭션을 실행함으로써, 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보를 획득한다. 또한, 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 획득된 특징 정보에 기초한 쿼리를 이용하여, 객체 인식 모델을 통해 인식할 수 없는 객체를 개인화된 테이터베이스에 기초하여 식별한다. 또한, 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 공간 스캔 정보 및 공간에 속하는 객체에 대한 객체 정보에 기초하여, 공간에 대한 공간 맵을 생성한다. 또한, 본 개시의 일 실시예에 따르면, 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 쿼리에 대한 응답으로, 개인화된 데이터베이스로부터 객체 후보군에 대한 정보를 획득한다. 또한, 프로세서는 하나 이 상의 인스트럭션을 실행함으로써, 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보와 객체 후 보군에 포함된 객체들 각각의 이미지 정보를 비교하여, 비교 결과에 기초하여 객체 인식 모델을 통해 인식할 수 없는 객체를 식별한다. 또한, 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 쿼리에 포함된 특징 정보와 개인화된 데이터베 이스에 저장된 객체 별 속성 정보를 비교하여, 특징 정보에 대응되는 속성 정보를 가지는 객체 후보군에 대한 정보를 획득한다. 또한, 쿼리는 개인화된 데이터베이스에 저장된 객체 별 속성 정보가 획득된 특징 정보와 일정한 수준 이상으로 매칭되는 적어도 하나의 객체에 대한 객체 정보의 수집을 요청하는 것이다. 또한, 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 전자 장치의 위치를 소정의 시점으로 이 동시키고, 이동된 위치에서 센싱부를 이용하여, 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이 미지 정보를 생성한다. 또한, 전자 장치는 통신부를 더 포함하고, 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 통신 부를 통해, 개인화된 데이터베이스를 포함하는 클라우드 서버에 쿼리를 전송한 것에 대한 응답으로, 클라우드 서버로부터 객체 후보군에 대한 정보를 수신한다. 또한, 본 개시의 일 실시예에 따르면, 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 객체 인식 모 델을 이용하여, 공간 스캔 정보로부터 공간에 속하는 객체를 인식하고, 특징 분석 모델을 이용하여, 객체 인식 결과에 따라 레이블링된 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보 를 추출한다. 또한, 본 개시의 일 실시예에 따르면, 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 공간 스캔 정 보 및 공간에 속하는 객체에 대한 객체 정보에 기초하여, 개인화된 데이터베이스를 업데이트하고, 업데이트된 개인화된 데이터베이스에 기초하여, 공간에 대한 공간 맵을 생성한다. 또한, 개인화된 데이터베이스는 사용자의 자산에 속하는 객체들 각각의 속성 정보를 객체별로 등록한 것이다. 또한, 속성 정보는 객체의 생산 과정에서 결정되는 모델 속성 정보 및 사용자의 사용 과정에서 결정되는 사용 속성 정보를 포함한다."}
{"patent_id": "10-2023-0057771", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2023-0057771", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 전자 장치와 외부 장치들이 서로 연결되는 댁내 IoT 환경을 설명하기 위한 도면이다. 도 2a 및 도 2b는 공간 맵을 설명하기 위한 흐름도이다. 도 3a, 도 3b, 도 3c, 도 3d는 공간 맵을 구성하는 레이어를 활용하는 방식을 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시예에 따른 공간 맵을 획득하는 방법을 설명하기 위한 흐름도이다. 도 5는 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체가 속한 공간을 설명하기 위한 도면이 다. 도 6은 본 개시의 일 실시예에 따른 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체가 속한 공간에 대한 공간 맵을 획득하는 방법을 설명하기 위한 흐름도이다. 도 7은 본 개시의 일 실시예 따라 클라우드 서버에 구축되는 데이터베이스를 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시예에 따라 공간 맵을 획득하는 전자 장치의 동작을 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시예에 따라 클라우드 서버와의 통신을 통해 공간 맵을 획득하는 전자 장치의 동작 을 설명하기 위한 도면이다. 도 10 및 도 11은 본 개시의 일 실시예에 따른 전자 장치의 구성을 나타낸 블록도이다. 도 12는 본 개시의 일 실시예에 따른 서버의 구성을 도시한 블록도이다."}
