{"patent_id": "10-2022-0171118", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0086822", "출원번호": "10-2022-0171118", "발명의 명칭": "메타버스 제작방법 및 시스템", "출원인": "(주)셀빅", "발명자": "이상노"}}
{"patent_id": "10-2022-0171118", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "공지의 인공신경망 소프트웨어가 적용된 서버와, 단말로 구성되고, 상기 서버와 상기 단말 간 정보를 상호 송수신하는 메타버스 제작 방법에 있어서,상기 서버는 공간에 대한 공간 이미지를 생성하고, 상기 공간 이미지를 공간영상정보로 저장하는 단계;상기 서버는 인물에 대한 캐릭터 이미지를 생성하고 상기 캐릭터 이미지에 대한 캐릭터 객체정보를 제 1영상정보로 저장하는 단계; 상기 제 1영상정보의 후면영상을 추정하여 상기 후면 영상정보를 생성하는 단계; 및 상기 제 1영상정보와 상기 후면 영상정보를 합성하여 캐릭터 후면보정 영상정보를 생성하고, 상기 캐릭터 후면보정 영상정보를 저장하는 단계;상기 단말로부터 메타버스 제작 요청이 수신되면, 상기 공간영상정보 및 상기 캐릭터 후면보정 영상정보를 이용하여 메타버스를 생성하는 단계를 포함하고, 상기 후면영상 정보를 생성하는 단계는, 상기 캐릭터 이미지가 정면의 인체 영상이 포함된 경우, 상기 제 1영상정보로부터 M개의 관절 좌표로 구성된 휴먼포즈 데이터를 생성하는 단계; 상기 제 1영상정보로부터 레이블 맵을 생성하는 단계;상기 M개의 관절 좌표 중 제 1 관절 좌표와 상기 레이블 맵의 이격 거리가 기 설정된 이격 거리 이하인 경우,상기 레이블 맵을 상기 제 1 관절 좌표에 대응되는 제 1인체 레이블로 생성하는 단계;상기 제 1인체 레이블을 생성하는 단계를 상기 M개의 모든 관절 좌표에 대해 순차적으로 수행하여, M개의 인체레이블을 생성하고, 상기 M개의 인체 레이블로 구성된 인체 레이블 맵을 생성하는 단계;상기 M개의 관절 좌표와 상기 레이블 맵의 이격 거리가 기 설정된 이격 거리를 초과한 경우, 비인체 레이블 맵을 생성하고, 상기 인체 레이블 맵과 상기 비인체 레이블 맵으로 구성되는 제 2영상 정보를 생성하는 단계;상기 제 1영상정보를 N개의 패치로 분리하여 N개의 제 1영상정보패치를 생성하고, 상기 N개의 제 1영상정보패치로 구성되는 제 1패치 맵을 생성하는 단계;상기 제 2영상정보를 N개의 패치로 분리하여 N개의 제 2영상정보패치를 생성하고, 상기 N개의 제 2영상정보패치로 구성되는 제 2패치 맵을 생성하는 단계;상기 N개의 제 1영상정보패치 중 제 1영상정보패치를 A개의 서브패치로 분리하고, 상기 제 1영상정보패치와 대응되는 상기 A개의 서브패치로 구성된 제 1서브패치군을 생성하는 단계;상기 제 1서브패치군을 생성하는 단계를 상기 N개의 모든 제 1영상정보패치에 대해 순차적으로 수행하여, 상기N개의 모든 제 1영상정보패치 각각에 대응되는 N개의 서브패치군을 생성하고, 상기 N개의 서브패치군으로 구성된 서브 패치 맵을 생성하는 단계;상기 제 1서브패치군을 구성하는 A개의 서브패치 색상정보 값을 합산하여 평균 값을 계산하고, 상기 평균 값을상기 A개의 서브패치의 색상정보 값으로 변경하고, 상기 변경된 색상정보 값이 반영된 A개의 서브패치로 구성된제 1평균서브패치군을 생성하는 단계;상기 제 1평균서브패치군을 생성하는 단계를 상기 N개의 모든 서브패치군에 대해 순차적으로 수행하여, N개의평균서브패치군을 생성하고, 상기 N개의 평균서브패치군으로 구성된 평균서브 패치 맵을 생성하는 단계;상기 N개의 평균서브패치군이 포함된 평균서브 패치 맵 중 제 1평균서브패치군을 둘러싸고 있는 복수개의 제 1인접평균서브패치군을 설정하고, 상기 제 1평균서브패치군의 제 1가중치와, 상기 제 1평균서브패치군과 상기 복공개특허 10-2024-0086822-3-수개의 인접평균서브패치군 간의 이격 거리에 비례하여 상기 복수개의 평균서브패치군의 제 2가중치를설정하고, 상기 제 1평균서브패치군에 상기 제 1가중치가 반영된 제 1색상정보 값과, 상기 복수개의 인접평균서브패치군의 색상정보에 제 2가중치가 반영된 제 2색상정보 값의 평균 값을 반영하여 후면 색상정보 값을 생성하고, 상기 후면 색상정보 값이 반영된 후면서브패치군을 생성하는 단계; 및상기 후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 수행하여, N개의 후면서브패치군을 생성하고, 상기 N개의 후면서브패치군으로 구성되는 후면서브패치 맵을생성하는 단계;를 포함하고, 상기 패치, 서브패치는 복수개의 픽셀로 구성되고, 상기 픽셀은 상기 픽셀의 주소 값, 상기 픽셀의 위치정보 및상기 픽셀의 색상정보가 저장되어 있는 것을 특징으로 하는, 메타버스 제작 방법."}
{"patent_id": "10-2022-0171118", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 후면 색상정보 값이 반영된 후면서브패치군을 생성하는 단계는, 상기 평균서브 패치 맵을 구성하는 N개의평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중하나의 위치좌표와 동일한 위치 좌표인 경우에 한해, 상기 후면 색상정보 값이 반영된 제 1후면서브패치군을 생성하고, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표가 아닌 경우, 상기 제 1평균서브패치군의 색상정보 값이 반영된 제 2후면서브패치군을 생성하고, 상기 N개의 후면서브패치군으로 구성되는 후면서브패치 맵을 생성하는 단계는, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표인 경우에 한해, 상기 후면 색상정보 값이 반영된 후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 수행하여, S개의 제 1후면서브패치군을 생성하고, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표가 아닌 경우, 상기 제 1평균서브패치군의 색상정보 값이 반영된 제 2후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N개의모든 평균서브패치군에 순차적으로 수행하여, T개의 제 2후면서브패치군을 생성하여, 상기 S개의 제 1후면서브패치군과, 상기 T개의 제 2후면서브패치군으로 구성되는 후면서브패치 맵을 생성하는것을 특징으로 하는, 메타버스 제작 방법."}
{"patent_id": "10-2022-0171118", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 복수개의 제 1인접 평균서브패치군은,상기 복수개의 제 1인접 평균서브패치군의 위치좌표가 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중하나의 위치좌표와 동일한 위치 좌표인 것을 특징으로 하는, 메타버스 제작 방법."}
{"patent_id": "10-2022-0171118", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 제 1가중치는 상기 제 2가중치 보다 큰 값으로 설정되고,상기 제 1가중치와 상기 복수개의 제 1 인접평균서브패치군에 설정된 제 2가중치들의 합이 1이고, 상기 제 1 가중치인 C는 이고, 상기 제 2 가중치인 w는공개특허 10-2024-0086822-4-이고,상기 제 1가중치와 상기 제 2가중치들의 상관 관계식인 W은 이고, 상기 Z는 상기 제 1평균서브패치군과, 상기 복수개의 제 1 인접평균서브패치군의 패치군수의 합인 것을 특징으로 하는, 메타버스 제작 방법."}
{"patent_id": "10-2022-0171118", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "메타버스 제작시스템에 있어서, 공간에 대한 공간 이미지를 생성하고, 상기 공간 이미지를 공간영상정보로 저장하고, 인물에 대한 캐릭터 이미지를 생성하고 상기 캐릭터 이미지에 대한 캐릭터 객체정보를 제 1영상정보로 저장하는 영상부; 상기 제 1영상정보의 후면영상을 추정하여 상기 후면 영상정보를 생성하고, 상기 제 1영상정보와 상기 후면 영상정보를 합성하여 캐릭터 후면보정 영상정보를 생성하고, 상기 캐릭터 후면보정 영상정보를 저장하는 후면영상처리부; 및 단말로부터 메타버스 제작 요청을 수신하는 통신부;를 포함하고,상기 영상부는, 상기 공간영상정보 및 상기 캐릭터 후면보정 영상정보를 이용하여 메타버스를 생성하고, 상기 후면영상처리부는, 상기 제 1영상정보로부터 M개의 관절 좌표로 구성된 휴먼포즈 데이터를 생성하는 휴먼포즈 생성부; 상기 제 1영상정보로부터 레이블 맵을 생성하는 레이블 맵 생성부;상기 M개의 관절 좌표 중 제 1 관절 좌표와 상기 레이블 맵과의 이격 거리가 기 설정된 이격 거리 이하인 경우,상기 레이블 맵을 상기 제 1 관절 좌표에 대응되는 제 1인체 레이블로 생성하고, 상기 M개의 모든 관절 좌표에대해서 순차적으로 M개의 인체 레이블을 생성하고, 상기 M개의 인체 레이블로 구성된 인체 레이블 맵을 생성하고, 상기 M개의 관절 좌표와 상기 레이블 맵의 이격 거리가 기 설정된 이격 거리를 초과한 경우, 비인체 레이블맵을 생성하고, 상기 인체 레이블 맵과 상기 비인체 레이블 맵으로 구성되는 제 2영상 정보를 생성하는 인체레이블 맵 생성부;상기 제 1영상정보를 N개의 패치로 분리하여 N개의 제 1영상정보패치를 생성하고, 상기 N개의 제 1영상정보패치로 구성되는 제 1패치 맵을 생성하고, 상기 제 2영상정보를 N개의 패치로 분리하여 N개의 제 2영상정보패치를생성하고, 상기 N개의 제 2영상정보패치로 구성되는 제 2패치 맵을 생성하고, 상기 N개의 제 1영상정보패치 중제 1영상정보패치를 A개의 서브패치로 분리하고, 상기 제 1영상정보패치와 대응되는 상기 A개의 서브패치로 구성된 제 1서브패치군을 생성하고, 상기 N개의 모든 제 1영상정보패치에 대해 순차적으로 상기 N개의 모든 제 1영상정보패치 각각에 대응되는 N개의 서브패치군을 생성하고, 상기 N개의 서브패치군으로 구성된 서브 패치 맵을 생성하여 서브 패치 맵을 생성하고, 상기 제 1서브패치군을 구성하는 A개의 서브패치 색상정보 값을 합산하여 평균 값을 계산하고, 상기 평균 값을 상기 A개의 서브패치의 색상정보 값으로 변경하고, 상기 변경된 색상정보 값이 반영된 A개의 서브패치로 구성된 제 1평균서브패치군을 생성하고, 상기 N개의 모든 서브패치군에 대해순차적으로 N개의 평균서브패치군을 생성하고, 상기 N개의 평균서브패치군으로 구성된 평균서브 패치 맵을 생성하는 패치 맵 생성부를 포함하고,상기 패치 맵 생성부는,상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표인 경우에 한해, 상기 N개의 평균서브패치군이 포함된 평균서브 패치 맵 중 제 1평균서브패치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치군을 설정하고, 상기 제 1평균서브패치군의 제 1가중치와, 상기 제 1평균서브패치군과 상기 복수개의 인접평공개특허 10-2024-0086822-5-균서브패치군 간의 이격 거리에 비례하여 상기 복수개의 평균서브패치군의 제 2가중치를 설정하고, 상기 제 1평균서브패치군에 상기 제 1가중치가 반영된 제 1색상정보 값과, 상기 복수개의 인접평균서브패치군의 색상정보에제 2가중치가 반영된 제 2색상정보 값의 평균 값을 반영하여 후면 색상정보 값을 생성하고, 상기 후면 색상정보값이 반영된 제 1후면서브패치군을 생성하고, 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에순차적으로 S개의 제 1후면서브패치군을 생성하고, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와동일한 위치 좌표가 아닌 경우, 상기 제 1평균서브패치군의 색상정보 값이 반영된 제 2후면서브패치군을 생성하고, 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 T개의 제 2후면서브패치군을 생성하고, 상기 S개의 제 1후면서브패치군과, 상기 T개의 제 2후면서브패치군으로 구성되는 후면서브패치 맵을생성하고, 상기 복수개의 제 1인접 평균서브패치군은,상기 복수개의 제 1인접 평균서브패치군의 위치좌표가 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중하나의 위치좌표와 동일한 위치 좌표이고, 상기 제 1가중치는 상기 제 2가중치 보다 큰 값으로 설정되고,상기 제 1가중치와 상기 복수개의 제 1 인접평균서브패치군에 설정된 제 2가중치들의 합이 1이고,상기 제 1 가중치인 C는 이고, 상기 제 2 가중치인 w는이고,상기 제 1가중치와 상기 제 2가중치들의 상관 관계식인 W은 이고, 상기 Z는 상기 제 1평균서브패치군과, 상기 복수개의 제 1 인접평균서브패치군의 패치군수의 합이고, 상기 패치, 서브패치는 복수개의 픽셀로 구성되고, 상기 픽셀은 상기 픽셀의 주소 값, 상기 픽셀의 위치정보 및상기 픽셀의 색상정보가 저장되어 있는 것을 특징으로 하는, 메타버스 제작시스템."}
{"patent_id": "10-2022-0171118", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5항에 있어서,로드밸런서부를 더 포함하고,상기 로드밸런서부는 단말로부터 메타버스 생성요청 정보가 포함된 제 1프레임이 수신되면, 상기 영상부, 상기 휴먼포즈 생성부, 상기 레이블 맵 생성부, 상기 인체레이블 맵 생성부, 및 상기 후면 영상처리부의 각각의 처리용량을 기초하여 우선순위를 부여하여 메타버스를 생성하는 것을 특징으로 하는 메타버스 제작시스템."}
{"patent_id": "10-2022-0171118", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 공지의 인공신경망 소프트웨어가 적용된 서버와, 단말로 구성되고, 상기 서버와 상기 단말 간 정보를 상호 송수신하는 메타버스 제작 방법에 있어서, 상기 서버는 공간에 대한 공간 이미지를 생성하고, 상기 공간 이 미지를 공간영상정보로 저장하는 단계; 상기 서버는 인물에 대한 캐릭터 이미지를 생성하고 상기 캐릭터 이미지 (뒷면에 계속)"}
{"patent_id": "10-2022-0171118", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 메타버스 제작방법 및 시스템에 관한 것으로서, 심층인공신경망을 이용하여 입력된 영상으로부터 휴 먼포즈 데이터, 레이블 맵 및 3D 메쉬데이터를 추출하여 사용자가 필요한 메타버스를 제작하는 방법 및 시스템 을 제공하는 것에 관한 것이다."}
{"patent_id": "10-2022-0171118", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "컨텐츠 개발 분야는, 하드웨어 및 소프트웨어의 전반적인 성능의 발전으로 인해, 2D 캐릭터 콘텐츠 개발에서 시 작하여 3D 캐릭터를 이용한 콘텐츠의 개발 및 활용하려는 시도가 증가하고 있다. 3D 캐릭터를 활용할 경우, 기 존에 제작한 3D 캐릭터를 여러 소프트웨어에서 재사용할 수 있는 장점과, 입체적인 애니메이션 표현 및 다양한 제어 방법을 적용할 수 있는 등 다양한 장점이 있다. 그러나 3D 캐릭터 제작의 기술적인 한계가 있어, 이를 극 복하기 위한 다양한 연구 및 개발이 이루어지고 있다. 또한, 최근 심층신경망 기반의 인공지능을 적용한 다양한 연구와 상용화가 활발해 지고 있다. 또한, 인공신경망 과 연계하여 실시간으로 사용자와 상호작용을 구현하는 메타버스에 대해 수요가 증가하고 있다. 따라서, 기존에 제작된 3D 컨텐츠와 인공지능 기술을 활용하여 메타버스를 구현하기 위한 메타버스 저작 플랫폼 및 시스템에 대한 연구가 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록번호공보 10-2245220(2021.04.27. 공고) (특허문헌 0002) 대한민국 공개특허공보 10-1906431(2018.10.11. 공고) (특허문헌 0003) 대한민국 공개특허공보 10-1829733(2018.02.09. 공고)"}
{"patent_id": "10-2022-0171118", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 인공신경망 소프트웨어가 적용된 서버와, 단말로 구성되고, 상기 서버와 상기 단말 간 정보를 상호 송수신하여, 상기 정보를 기초로 영상을 생성하고 제공하는 메타버스 제작 방법 및 시스템을 제공하는 것을 과 제로 한다."}
{"patent_id": "10-2022-0171118", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 해결하기 위한 메타버스 제작 방법은, 공지의 인공신경망 소프트웨어가 적용된 서버와, 단말로 구성되고, 상기 서버와 상기 단말 간 정보를 상호 송수 신하는 메타버스 제작 방법에 있어서, 상기 서버는 공간에 대한 공간 이미지를 생성하고, 상기 공간 이미지를 공간영상정보로 저장하는 단계; 상기 서버는 인물에 대한 캐릭터 이미지를 생성하고 상기 캐릭터 이미지에 대한 캐릭터 객체정보를 제 1영상정보로 저장하는 단계; 상기 제 1영상정보의 후면영상을 추정하여 상기 후면 영상정 보를 생성하는 단계; 및 상기 제 1영상정보와 상기 후면 영상정보를 합성하여 캐릭터 후면보정 영상정보를 생성 하고, 상기 캐릭터 후면보정 영상정보를 저장하는 단계;를 포함하고, 상기 후면영상 정보를 생성하는 단계는, 상기 캐릭터 이미지가 정면의 인체 영상이 포함된 경우, 상기 제 1영상정보로부터 M개의 관절 좌표로 구성된 휴 먼포즈 데이터를 생성하는 단계; 상기 제 1영상정보로부터 레이블 맵을 생성하는 단계; 상기 M개의 관절 좌표 중 제 1 관절 좌표와 상기 레이블 맵의 이격 거리가 기 설정된 이격 거리 이하인 경우, 상기 레이블 맵을 상기 제 1 관절 좌표에 대응되는 제 1인체 레이블로 생성하는 단계; 상기 제 1인체 레이블을 생성하는 단계를 상기 M 개의 모든 관절 좌표에 대해 순차적으로 수행하여, M개의 인체 레이블을 생성하고, 상기 M개의 인체 레이블로 구성된 인체 레이블 맵을 생성하는 단계; 상기 M개의 관절 좌표와 상기 레이블 맵의 이격 거리가 기 설정된 이 격 거리를 초과한 경우, 비인체 레이블 맵을 생성하고, 상기 인체 레이블 맵과 상기 비인체 레이블 맵으로 구성 되는 제 2영상 정보를 생성하는 단계; 상기 제 1영상정보를 N개의 패치로 분리하여 N개의 제 1영상정보패치를 생성하고, 상기 N개의 제 1영상정보패치로 구성되는 제 1패치 맵을 생성하는 단계; 상기 제 2영상정보를 N개의 패치로 분리하여 N개의 제 2영상정보패치를 생성하고, 상기 N개의 제 2영상정보패치로 구성되는 제 2패치 맵을 생성하는 단계; 상기 N개의 제 1영상정보패치 중 제 1영상정보패치를 A개의 서브패치로 분리하고, 상기 제 1영 상정보패치와 대응되는 상기 A개의 서브패치로 구성된 제 1서브패치군을 생성하는 단계; 상기 제 1서브패치군을 생성하는 단계를 상기 N개의 모든 제 1영상정보패치에 대해 순차적으로 수행하여, 상기 N개의 모든 제 1영상정보패치 각각에 대응되는 N개의 서브패치군을 생성하고, 상기 N개의 서브패치군으로 구성된 서브 패치 맵을 생성 하는 단계; 상기 제 1서브패치군을 구성하는 A개의 서브패치 색상정보 값을 합산하여 평균 값을 계산하고, 상기 평균 값을 상기 A개의 서브패치의 색상정보 값으로 변경하고, 상기 변경된 색상정보 값이 반영된 A개의 서브패 치로 구성된 제 1평균서브패치군을 생성하는 단계; 상기 제 1평균서브패치군을 생성하는 단계를 상기 N개의 모 든 서브패치군에 대해 순차적으로 수행하여, N개의 평균서브패치군을 생성하고, 상기 N개의 평균서브패치군으로 구성된 평균서브 패치 맵을 생성하는 단계; 상기 N개의 평균서브패치군이 포함된 평균서브 패치 맵 중 제 1평균 서브패치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치군을 설정하고, 상기 제 1평균서브패치군의 제 1가 중치와, 상기 제 1평균서브패치군과 상기 복수개의 인접평균서브패치군 간의 이격 거리에 비례하여 상기 복수개 의 평균서브패치군의 제 2가중치를 설정하고, 상기 제 1평균서브패치군에 상기 제 1가중치가 반영된 제 1색상정 보 값과, 상기 복수개의 인접평균서브패치군의 색상정보에 제 2가중치가 반영된 제 2색상정보 값의 평균 값을 반영하여 후면 색상정보 값을 생성하고, 상기 후면 색상정보 값이 반영된 후면서브패치군을 생성하는 단계; 및 상기 후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적 으로 수행하여, N개의 후면서브패치군을 생성하고, 상기 N개의 후면서브패치군으로 구성되는 후면서브패치 맵을 생성하는 단계;를 포함하고, 상기 패치, 서브패치는 복수개의 픽셀로 구성되고, 상기 픽셀은 상기 픽셀의 주소 값, 상기 픽셀의 위치정보 및 상기 픽셀의 색상정보가 저장되어 있는 것을 특징으로 한다. 또한, 상기 후면 색상정보 값이 반영된 후면서브패치군을 생성하는 단계는, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌 표 중 하나의 위치좌표와 동일한 위치 좌표인 경우에 한해, 상기 후면 색상정보 값이 반영된 제 1후면서브패치 군을 생성하고, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표가 아닌 경우, 상기 제 1평균서브패치군의 색상정보 값이 반영된 제 2후면서브패치군을 생성하고, 상기 N개의 후면서브패치군으로 구성되는 후면서브패치 맵을 생성하는 단계는, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일 한 위치 좌표인 경우에 한해, 상기 후면 색상정보 값이 반영된 후면서브패치군을 생성하는 단계를 상기 평균서 브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 수행하여, S개의 제 1후면서브패치군을 생성하 고, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표가 아닌 경우, 상기 제 1평균 서브패치군의 색상정보 값이 반영된 제 2후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N 개의 모든 평균서브패치군에 순차적으로 수행하여, T개의 제 2후면서브패치군을 생성하여, 상기 S개의 제 1후면 서브패치군과, 상기 T개의 제 2후면서브패치군으로 구성되는 후면서브패치 맵을 생성하는 것을 특징으로 한다. 또한, 상기 복수개의 제 1인접 평균서브패치군은, 상기 복수개의 제 1인접 평균서브패치군의 위치좌표가 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표인 것을 특징으로 한다. 또한, 상기 제 1가중치는 상기 제 2가중치 보다 큰 값으로 설정되고, 상기 제 1가중치와 상기 복수개의 제 1 인접평균서브패치군에 설정된 제 2가중치들의 합이 1이고, 상기 제 1 가 중치인 C는 이고, 상기 제 2 가중치인 w는 이고, 상기 제 1가중치와 상기 제 2가 중치들의 상관 관계식인 W은 이고, 상기 Z는 상기 제 1평균서브패치군과, 상기 복수개 의 제 1 인접평균서브패치군의 패치군수의 합인 것을 특징으로 한다. 상기 과제를 해결하기 위한 메타버스 제작시스템은 공간에 대한 공간 이미지를 생성하고, 상기 공간 이미지를 공간영상정보로 저장하고, 인물에 대한 캐릭터 이미지를 생성하고 상기 캐릭터 이미지에 대한 캐릭터 객체정보 를 제 1영상정보로 저장하는 영상부; 상기 제 1영상정보의 후면영상을 추정하여 상기 후면 영상정보를 생성하고, 상기 제 1영상정보와 상기 후면 영상정보를 합성하여 캐릭터 후면보정 영상정보를 생성하고, 상기 캐 릭터 후면보정 영상정보를 저장하는 후면영상처리부; 및 단말로부터 메타버스 제작 요청을 수신하는 통신부;를 포함하고, 상기 영상부는, 상기 후면보정영상정보 및 상기 공간영상정보를 이용하여 메타버스를 생성하고, 상기 후면영상처리부는, 상기 제 1영상정보로부터 M개의 관절 좌표로 구성된 휴먼포즈 데이터를 생성하는 휴먼포즈 생성부; 상기 제 1영상정보로부터 레이블 맵을 생성하는 레이블 맵 생성부; 상기 M개의 관절 좌표 중 제 1 관절좌표와 상기 레이블 맵과의 이격 거리가 기 설정된 이격 거리 이하인 경우, 상기 레이블 맵을 상기 제 1 관절 좌표에 대응되는 제 1인체 레이블로 생성하고, 상기 M개의 모든 관절 좌표에 대해서 순차적으로 M개의 인체 레 이블을 생성하고, 상기 M개의 인체 레이블로 구성된 인체 레이블 맵을 생성하고, 상기 M개의 관절 좌표와 상기 레이블 맵의 이격 거리가 기 설정된 이격 거리를 초과한 경우, 비인체 레이블 맵을 생성하고, 상기 인체 레이블 맵과 상기 비인체 레이블 맵으로 구성되는 제 2영상 정보를 생성하는 인체레이블 맵 생성부; 상기 제 1영상정보 를 N개의 패치로 분리하여 N개의 제 1영상정보패치를 생성하고, 상기 N개의 제 1영상정보패치로 구성되는 제 1 패치 맵을 생성하고, 상기 제 2영상정보를 N개의 패치로 분리하여 N개의 제 2영상정보패치를 생성하고, 상기 N 개의 제 2영상정보패치로 구성되는 제 2패치 맵을 생성하고, 상기 N개의 제 1영상정보패치 중 제 1영상정보패치 를 A개의 서브패치로 분리하고, 상기 제 1영상정보패치와 대응되는 상기 A개의 서브패치로 구성된 제 1서브패치 군을 생성하고, 상기 N개의 모든 제 1영상정보패치에 대해 순차적으로 상기 N개의 모든 제 1영상정보패치 각각 에 대응되는 N개의 서브패치군을 생성하고, 상기 N개의 서브패치군으로 구성된 서브 패치 맵을 생성하여 서브 패치 맵을 생성하고, 상기 제 1서브패치군을 구성하는 A개의 서브패치 색상정보 값을 합산하여 평균 값을 계산 하고, 상기 평균 값을 상기 A개의 서브패치의 색상정보 값으로 변경하고, 상기 변경된 색상정보 값이 반영된 A 개의 서브패치로 구성된 제 1평균서브패치군을 생성하고, 상기 N개의 모든 서브패치군에 대해 순차적으로 N개의 평균서브패치군을 생성하고, 상기 N개의 평균서브패치군으로 구성된 평균서브 패치 맵을 생성하는 패치 맵 생성 부를 포함하고, 상기 패치 맵 생성부는, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균 서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위 치 좌표인 경우에 한해, 상기 N개의 평균서브패치군이 포함된 평균서브 패치 맵 중 제 1평균서브패치군을 둘러 싸고 있는 복수개의 제 1 인접평균서브패치군을 설정하고, 상기 제 1평균서브패치군의 제 1가중치와, 상기 제 1 평균서브패치군과 상기 복수개의 인접평균서브패치군 간의 이격 거리에 비례하여 상기 복수개의 평균서브패치군 의 제 2가중치를 설정하고, 상기 제 1평균서브패치군에 상기 제 1가중치가 반영된 제 1색상정보 값과, 상기 복 수개의 인접평균서브패치군의 색상정보에 제 2가중치가 반영된 제 2색상정보 값의 평균 값을 반영하여 후면 색 상정보 값을 생성하고, 상기 후면 색상정보 값이 반영된 제 1후면서브패치군을 생성하고, 상기 평균서브패치 맵 을 구성하는 N개의 모든 평균서브패치군에 순차적으로 S개의 제 1후면서브패치군을 생성하고, 상기 평균서브 패 치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표가 아닌 경우, 상기 제 1평균서브패치군의 색상정보 값이 반영된 제 2후면서브패치군을 생성하고, 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 T개의 제 2후면서브패치군을 생성하고, 상기 S개의 제 1후면서브패치군과, 상기 T개의 제 2후면서 브패치군으로 구성되는 후면서브패치 맵을 생성하고, 상기 복수개의 제 1인접 평균서브패치군은, 상기 복수개의 제 1인접 평균서브패치군의 위치좌표가 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표 와 동일한 위치 좌표이고, 상기 제 1가중치는 상기 제 2가중치 보다 큰 값으로 설정되고, 상기 제 1가중치와 상 기 복수개의 제 1 인접평균서브패치군에 설정된 제 2가중치들의 합이 1이고, 상기 제 1 가중치인 C는 이고, 상기 제 2 가중치인 w는 이고, 상기 제 1가중치와 상기 제 2가중치들의 상관 관계식인 W은 이고, 상기 Z는 상기 제 1평균서브패치군과, 상기 복수개의 제 1 인접평 균서브패치군의 패치군수의 합이고, 상기 패치, 서브패치는 복수개의 픽셀로 구성되고, 상기 픽셀은 상기 픽셀 의 주소 값, 상기 픽셀의 위치정보 및 상기 픽셀의 색상정보가 저장되어 있는 것을 특징으로 한다. 또한, 메타버스 제작시스템은 로드밸런서부를 더 포함하고, 상기 로드밸런서부는 단말로부터 메타버스 생성요청 정보가 포함된 제 1프레임이 수신되면, 상기 영상부, 상기 휴먼포즈 생성부, 상기 레이블 맵 생성부, 상기 인체 레이블 맵 생성부, 및 상기 후면 영상처리부의 각각의 처리용량을 기초하여 우선순위를 부여하여 메타버스를 생 성하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0171118", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 이미 제작된 2D/3D 컨텐츠를 이용하여, 디지털 환경의 메타버스에서 직접적으로 적용되는 메타버스 제작 시스템 및 방법을 제공할 수 있는 장점이 있다. 또한, 본 발명은 2D 컨텐츠의 경우에도, 2D 컨텐츠 후면영상을 추정하여 3D 컨텐츠로 변환하여 메타버스에 직접 적으로 적용할 수 있는 메타버스 제작 시스템 및 방법을 제공하는 장점이 있다."}
{"patent_id": "10-2022-0171118", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예를 참조하면 명확해질 것이다. 그러나 본 발명은 여기서 설명되는 실시예들에 한정되지 않고 다른 형태로 구 체화될 수도 있다. 오히려, 여기서 소개되는 실시예들은 개시된 내용이 철저하고 완전해질 수 있도록 그리고 당 업자에게 본 발명의 사상이 충분히 전달될 수 있도록 하기 위해 제공되는 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미가 있다. 일반적으 로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미가 있는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하에서는 본 발명의 구체적인 실시예를 도면을 참조하여 상세히 설명하도록 한다. 도 1은 본 발명에 따른 메타버스 제작을 위한 메타버스 제작방법을 나타내는 흐름도이다. 도 1을 참조하면, 공 간에 대한 공간 이미지를 생성하고, 상기 공간 이미지를 공간영상정보로 저장한다(S110). 인물에 대한 캐릭터 이미지를 생성하고 상기 캐릭터 이미지에 대한 캐릭터 객체정보를 제 1영상정보로 저장한다(S120). 제 1영상정 보의 후면영상을 추정하여 상기 후면 영상정보를 생성한다(S130). 상기 제 1영상정보와 상기 후면 영상정보를 합성하여 캐릭터 후면보정 영상정보를 생성하고, 상기 캐릭터 후면보정 영상정보를 저장한다(S140). 상기 단말 로부터 메타버스 제작 요청이 수신되면, 상기 공간영상정보 및 상기 캐릭터 후면보정 영상정보를 이용하여 메타 버스를 생성한다(S150). 여기서, 공간에 대한 공간 이미지를 생성하고, 상기 공간 이미지를 공간영상정보로 저장한다(S110). 상기 공간 영상정보는 공지된 3D 카메라 및 알고리즘이 적용되어 3D 깊이 기반 촬영된 3D영상정보를 포함하고, RGB 기반 색상정보, 위치정보가 포함되어 있고, 공지된 모델링 알고리즘이 적용되어 3D 모델링 및 렌더링이 되어 일반적 인 디스플레이를 통해 디스플레이될 수 있다. 또한, 상기 공간영상정보는 기 생성된 정보가 상기 서버에 저장되 어 있는 공간영상정보 일 수도 있다. 도 2는 본 발명에 따른 메타버스 제작을 위한 공간영상정보를 나타내는 일 예시도이다. 도 2를 참조하면, 상기 공간영상정보가 디스플레이 된 일 실시예를 보여주고 있다. 다시 도 1을 참조하여 기술하면, 인물에 대한 캐릭터 이미지를 생성하고 상기 캐릭터 이미지에 대한 캐릭터 객 체정보를 제 1영상정보로 저장한다(S120). 여기서, 상기 제 1영상정보는 공지된 2D/3D 카메라 및 알고리즘이 적용되어 촬영된 영상정보이고, 이미 저장되어 있는 영상정보일 수 있다. 다만, 상기 제 1영상정보는 인물의 전면부가 포함되어 있어, 후면추정 및 관절부를 추정할 수 있는 영상이 바람직하다. 제 1영상정보의 후면영상을 추정하여 상기 후면 영상정보를 생성한다(S130). 해당 상기 후면영상정보를 생성하 는 방법은 도 4를 참조하여 후술하기로 한다. 후면 영상정보가 생성되면, 상기 제 1영상정보와 상기 후면 영상정보를 합성하여 캐릭터 후면보정 영상정보를 생성하고, 상기 캐릭터 후면보정 영상정보를 저장한다(S140). 여기서, 상기 캐릭터 후면보정 영상정보 생성기술은 공지의 합성알고리즘 또는 모델링 기술을 적용하여 캐릭터 후면 영상정보를 생성 및 저장할 수 있다. 상기 캐릭터 후면보정 영상정보가 생성되면, 단말로부터 메타버스 제작 요청이 수신되면, 상기 공간영상정보 및 상기 캐릭터 후면보정 영상정보를 이용하여 메타버스를 생성한다(S150). 여기서, 메타버스 생성기술은 공지된 3D 가상공간 모델링 기술을 적용하고, 상기 캐릭터 후면보정 영상정보를 공지된 폴리곤 메쉬 변환기술을 적용하여 생성될 수 있고, 여기서 생성된 데이터를 데이터베이스화 저장하고, 필요 시, 디스플레이 할 수 있다. 또한, 상기 공간영상정보 및 상기 캐릭터 후면보정 영상정보는 반복적으로 생성되어 복수개의 정보가 생성될 수 있고, 또는, 기 생성된 공간영상정보 및 상기 캐릭터 후면보정 영상정보를 이용할 수 있다. 또한, 해당 복수개 의 정보를 선택적으로 적용하여 메타버스를 생성 할 수 있다. 해당 복수개의 정보가 적용되어 메타버스를 생성 하고, 해당 메타버스를 생성하는 사용자 인터페이스를 제공할 수 있다. 도 3은 본 발명에 따른 메타버스 제작방법의 사용자 인터페이스를 나타내는 일 예시도이다. 도 3을 참조하면, 해당 복수개의 정보가 적용되어 메타버스를 생성하는 사용자 인터페이스를 보여준다. 도 4는 본 발명에 따른 메타버스 제작을 위한 메타버스 제작방법의 후면 영상정보를 생성하는 단계(S130)를 구 체적으로 나타내는 흐름도이다. 도 5는 본 발명에 따른 메타버스 제작을 위한 메타버스 제작시스템을 나타내는 메타버스 제작 시스템도이다. 도 4 내지 도 5를 참조하여, 제 1영상정보의 후면영상을 추정하여 상기 후면 영상 정보를 생성(S130)하는 단계에 대해서 구체적으로 기술한다. 도 4 및 5를 참조하면, 본 발명에 따른 후면 영상정보를 생성하는 장치 또는 시스템은, 서버 또는 단말 , 서버 및 단말로 구성될 수 있다. 일반적으로는 서버로 메타버스 제작 시스템을 구성하는 것이 바람직하다. 상기 서버 및 단말은 개인용 PC, 스마트폰, 서버일 수 있으며, 상기 서버와 단말 간 무선 또는 유선 통신을 통한 장거리 통신을 할 수 있고, 블루투스, 무선랜 등 근거리 통신을 수행할 수 있다. 또한, 상기 서버 및 단말은 입력 및 출력 수단과, 카메라를 포함하여 영상촬영을 수행할 수 있고, 저장수단이 포 함되어 앱 소프트웨어 설치 및 처리가 가능하다. 일반적인 PC와 서버 등이 포함하는 공지 기술이 적용될 수 있 고, 이에 대한 설명은 생략하기로 한다. 상기 서버는 영상부, 후면영상처리부 및 통신부를 포함하여 구성되고, 물리적 또는 논리적 으로 구성될 수 있다. 또한, 상기 후면영상처리부는 휴먼포즈 생성부, 레이블 맵 생성부, 인체 레이블 맵 생성부, 패치 맵 생성부 및 3D 매쉬 생성부를 포함하여 구성될 수 있다. 여기서, 상기 서버를 구성하는 영상부, 후면영상처리부 및 통신부는 특정 기능 및 연산을 수행 하는 프로세서로 구성되고, 하나 또는 복수개의 프로세서로 구성될 수 있고, 특정 알고리즘이 적용될 수 있다. 상기 영상부는 서버를 구성하는 내장된 카메라 등 영상장치를 이용하여 영상정보를 획득하거나, 기 저장된 영상정보를 획득한다. 또한, 상기 영상부는 단말을 구성하는 영상부가 획득된 영상정보를 수신하여, 해당 영상정보를 이용하여 처리할 수 도 있다. 상기 영상부는 제 1영상정보를 촬영하여 생성한 후, 저장할 수 도 있고, 이미 저장되어 있는 영상정보를 저장할 수 도 있다. 휴먼포즈 생성부는 입력된 제 1영상정보로부터 M개의 관절 좌표로 구성된 휴먼포즈 데이터를 생성한다. 레이블 맵 생성부는 상기 제 1영상정보로부터 레이블 맵을 생성한다. 인체 레이블 맵 생성부는 상기 M개의 관절 좌표 중 제 1 관절 좌표와 상기 레이블 맵과의 이격 거리가 기 설정된 이격 거리 이하인 경우, 상기 레이블 맵을 상기 제 1 관절 좌표에 대응되는 제 1인체 레이블로 생성하고, 상기 M개의 모든 관절 좌표에 대해서 순차적으로 M개의 인체 레이블을 생성하고, 상기 M개의 인체 레 이블로 구성된 인체 레이블 맵을 생성하고, 상기 M개의 관절 좌표와 상기 레이블 맵의 이격 거리가 기 설정된 이격 거리를 초과한 경우, 비인체 레이블 맵을 생성하고, 상기 인체 레이블 맵과 상기 비인체 레이블 맵으로 구 성되는 제 2영상 정보를 생성한다. 패치 맵 생성부는 상기 제 1영상정보를 N개의 패치로 분리하여 N개의 제 1영상정보패치를 생성하고, 상기 N개의 제 1영상정보패치로 구성되는 제 1패치 맵을 생성하고, 상기 제 2영상정보를 N개의 패치로 분리하여 N개 의 제 2영상정보패치를 생성하고, 상기 N개의 제 2영상정보패치로 구성되는 제 2패치 맵을 생성하고, 상기 N개 의 제 1영상정보패치 중 제 1영상정보패치를 A개의 서브패치로 분리하고, 상기 제 1영상정보패치와 대응되는 상 기 A개의 서브패치로 구성된 제 1서브패치군을 생성하고, 상기 N개의 모든 제 1영상정보패치에 대해 순차적으로 상기 N개의 모든 제 1영상정보패치 각각에 대응되는 N개의 서브패치군을 생성하고, 상기 N개의 서브패치군으로 구성된 서브 패치 맵을 생성하여 서브 패치 맵을 생성하고, 상기 제 1서브패치군을 구성하는 A개의 서브패치 색 상정보 값을 합산하여 평균 값을 계산하고, 상기 평균 값을 상기 A개의 서브패치의 색상정보 값으로 변경하고, 상기 변경된 색상정보 값이 반영된 A개의 서브패치로 구성된 제 1평균서브패치군을 생성하고, 상기 N개의 모든 서브패치군에 대해 순차적으로 N개의 평균서브패치군을 생성하고, 상기 N개의 평균서브패치군으로 구성된 평균 서브 패치 맵을 생성한다. 또한, 상기 패치 맵 생성부는 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브 패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표인 경우에 한해, 상기 N개의 평균서브패치군이 포함된 평균서브 패치 맵 중 제 1평균서브패치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치군을 설정하고, 상기 제 1평균서브패치군의 제 1가중치와, 상기 제 1평균 서브패치군과 상기 복수개의 인접평균서브패치군 간의 이격 거리에 비례하여 상기 복수개의 평균서브패치군의 제 2가중치를 설정하고, 상기 제 1평균서브패치군에 상기 제 1가중치가 반영된 제 1색상정보 값과, 상기 복수개 의 인접평균서브패치군의 색상정보에 제 2가중치가 반영된 제 2색상정보 값의 평균 값을 반영하여 후면 색상정 보 값을 생성하고, 상기 후면 색상정보 값이 반영된 제 1후면서브패치군을 생성하고, 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 S개의 제 1후면서브패치군을 생성하고, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패 치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표가 아닌 경우, 상기 제 1평균서브패치군의 색상정보 값 이 반영된 제 2후면서브패치군을 생성하고, 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순 차적으로 T개의 제 2후면서브패치군을 생성하고, 상기 S개의 제 1후면서브패치군과, 상기 T개의 제 2후면서브패치군으로 구성되는 후면서브패치 맵을 생성한다. 또한, 상기 패치 맵 생성부는, 상기 복수개의 제 1인접 평균서브패치군의 위치좌표가 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표인, 상기 복수개의 제 1인접 평균서브 패치군을 설정한다. 또한, 상기 패치 맵 생성부는 상기 제 1가중치를 상기 제 2가중치 보다 큰 값으로 설정하고, 상기 제 1가 중치와 상기 복수개의 제 1 인접평균서브패치군에 설정된 제 2가중치들의 합이 1로 설정하고, 상기 제 1 가중 치인 C는 이고, 상기 제 2 가중치인 w는 이고, 상기 제 1가중치와 상기 제 2가중 치들의 상관 관계식인 W은 이고, 상기 Z는 상기 제 1평균서브패치군과, 상기 복수개 의 제 1 인접평균서브패치군의 패치군수의 합으로 설정한다. 여기서, 상기 패치, 서브패치는 복수개의 픽셀로 구성되고, 상기 픽셀은 상기 픽셀의 주소 값, 상기 픽셀 의 위치정보 및 상기 픽셀의 색상정보가 저장되어 있다. 통신부는 일반적인 통신 기술이 적용되고, 서버와 단말간 구성된 시스템에 한해서, 특정 정보를 전달하는 기능을 수행하고, 유선 또는 무선 통신을 이용할 수 있다. 여기서, 특정정보는 제 1영상정보, 제 2영상정보, 제 1패치 맵, 제 2패치 맵, 후면 패치 맵 등 데이터를 의미한 다. 단말도 서버와 동일한 구성으로 되어 있어, 이에 대한 기재를 생략한다. 상기 서버의 구체적인 동작 관련 설명은 후술하기로 한다. 도 6은 본 발명에 따른 메타버스 제작방법의 후면 영상정보를 생성하는 방법을 나타내는 개념도이다. 도 4 및 6 을 다시 참조하여 기술하면, 제 1영상정보를 이용하여 휴먼포즈 데이터를 생성하는 단계(S410), 상기 제 1영상 정보를 이용하여 레이블 맵 데이터를 생성하는 단계(S420), 상기 휴먼포즈 데이터를 이용하여 상기 인체 레이블 맵을 생성하는 단계(S430), 상기 인체 레이블 맵 및 비인체 레이블 맵을 이용하여 제 2영상정보를 생성하는 단 계(S440), 상기 제 1영상정보와 상기 제 2영상정보를 이용하여 패치 정보를 생성하는 단계(S450) 및 상기 패치 정보를 이용하여 후면 영상정보 생성하는 단계(S460)를 포함하여 구성될 수 있다. 제 1영상정보를 이용하여 휴먼포즈 데이터를 생성하는 단계(S210)는, 단말 또는 서버내 영상부(510, 610)가 카메라로부터 획득된 영상, 즉, 제 1영상정보를 상기 단말 또는 서버 내에 저장되어 있는 제 1영상정보를 이용하여 휴먼포즈 데이터를 생성한다. 상기 제 1영상정보는, 일반적으로 데이터를 저장하는 파일형식인 JPG 파일 등 다양한 형태로 영상 또는 이미지 를 저장하는 데이터 또는 데이터 파일을 의미한다. 또한, 상기 제 1영상정보는, 상기 제 1영상정보 내에 인체 관련 정보를 포함하는 이미지 영상을 포함할 수 있고, 특히, 상기 인체 관련 정보는 전면 영상을 포함하고, 후 면 영상을 포함하지 않을 수 도 있고, 반대로 후면 영상을 포함하고, 전면 영상을 포함하지 않을 수도 있다. 도 7은 본 발명에 일실시예에 따른 입력된 제 1영상정보를 이용하여 휴먼포즈 데이터를 생성하는 개념도이다. 도 7을 참조하면, 휴먼포즈 생성부는 상기 제 1영상정보를 이용하여 휴먼포즈 데이터를 생성한다. 공지의 휴먼포즈 생성 알고리즘을 이용하고, 상기 공지의 휴먼포즈 생성 알고리즘이 적용되어, 심층신경망의 한 종류인 합성곱 신경망(CNN, Convolutional Neural Network)을 이용하여 반복 학습하여 최종적으로 휴먼포즈 백 터 맵을 생성한다. 여기서, 상기 합성곱 신경망(CNN, Convolutional Neural Network)은 상기 제 1영상정보에 저장되어 있는 인체 관련 정보를 추출하고, 상기 추출된 인체정보를 이용하여 각 인체 관절의 좌표를 출력하고, 상기 출력된 인체의 관절 좌표 중 예측 정확도가 높은 좌표를 선택해서 2차원 관절 좌표를 설정한다. 이후, 상 기 2차원 관절 좌표를 이용하여 3차원 관절 좌표를 생성하는데, 3차원 표준 인체 메쉬 데이터 모델(SMPL, Skinned Multi-Person Linear Model)을 이용하여, 상기 2차원 관절 좌표를 상기 3차원 표준 인체 메쉬 데이터 모델에 적용하여 매칭된 3차원 관절좌표, 즉, 휴먼포즈 백터 맵을 생성한다. 여기서, 일반적으로 휴먼포즈의 의미는, 입력된 원본 이미지 상에서 검출된 사람에 대해 코, 팔꿈치, 발목 등의 지정된 개수의 관절과 각각의 이미지 좌표 체계 상에서의 3차원 좌표 벡터를 의미하고, 상기 좌표는 0~1 사이의값으로 정규화 되어 있는 공지된 기술이다. 여기서, 상기 생성된 휴먼포즈 백터 맵은 도 6을 참조한다. 도 8은 본 발명에 일실시예에 따른 입력된 제 1영상정보를 이용하여 휴먼포즈 데이터인 관절좌표에 대한 도면이 다. 도 8을 참조하면, 일 실시예로, 상기 휴먼포즈 데이터는 23개의 관절좌표로 구성되고, 각각의 관절좌표에는 명칭 및 고유번호가 부여되어, 이후 인체 레이블 맵을 생성시, 상기 관절좌표가 이용될 수 있다. 상기 관절좌 표는 필요에 따라 임의로 설정될 수 있다. 또한, 필요에 따라, 3차원 좌표인 휴먼포즈 백터 맵을 이용할 수 있 다. 도 9는 본 발명에 일실시예에 따른 입력된 제 1영상정보를 이용하여 세그멘테이션하여 레이블 맵을 생성하는 개 념도이다. 도 9를 참조하면, 휴먼포즈 생성부가 상기 제 1 영상정보를 이용하여 휴먼포즈 데이터를 생성하 면, 레이블 맵 생성부는 상기 제 1영상정보를 이용하여 레이블 맵 데이터를 생성하는 단계(S420)를 수행한 다. 일반적으로 세그멘테이션(Semantic Image Segmentation)의 의미는 영상정보 상에서 인체정보를 검출하고, 검출 된 인체정보가 존재하는 픽셀을 참(True)으로, 검출된 인체정보가 존재하지 않는 픽셀을 거짓(False)으로 픽셀 값을 지정하여 원본과 같은 크기로 레이블 맵(Label Map)을 구성하는 기술을 의미한다. 공지의 레이블 맵 생성 알고리즘을 이용하고, 상기 공지의 레이블 맵생성 알고리즘이 적용되어, 심층신경망의 한 종류인 합성곱 신경망(CNN, Convolutional Neural Network)을 이용하여 반복 학습하여 최종적으로 레이블 맵 을 생성한다. 여기서, 레이블 맵 추출방법은 상기 레이블 맵이 상기 영상 정보의 이미지 크기와 동일한 이미지 크기로 설정하 고, 일반적인 RGB 채널이 아닌 흑백 채널을 사용하여 0~255의 값을 사용하도록 설정한다. 상기 영상정보 중 인체정보에 해당되는 픽셀은 255로 설정하고, 상기 영상정보 중 인체정보에 해당되지 않는 픽 셀은 0으로 설정하여 레이블 맵을 생성하고, 저장한다. 상기 레이블 맵 추출방법을 합성곱 신경망(CNN, Convolutional Neural Network)에 적용하여, 인체 영역에 해당 되는 픽셀의 정보만 분리하여 레이블 맵을 추출하도록 반복하여 학습한다. 상기 추출된 레이블 맵은 상기 전달 된 영상정보와 비교해 데이터 크기가 작아진다. 이러한 데이터 손실을 보상하기 위해, 공지의 합성곱 신경망(인코더-디코더 구조로 합성곱 신경망)을 적용하여 최종적으로 레이블 맵을 생성한다. 여기서, 세그멘테이션 결과 레이블 맵은 도 6을 참조한다. 레이블 맵 생성부가 상기 제 1영상정보를 이용하여 레이블 맵 데이터를 생성한 이후, 인체 레이블 맵 생성 부은 상기 휴먼포즈 데이터를 이용하여 상기 인체 레이블 맵을 생성하는 단계(S430)를 수행한다. 도 11은 본 발명에 일시예에 따른 인체 레이블 맵과 비인체 레이블 맵을 나타내는 일 예시도이다. 인체 레이블 맵 생성부는 상기 휴먼데이터의 관절 좌표와, 상기 레이블 맵과의 거리를 측정하고, 상기 측 정된 거리가 기 설정된 거리보다 작은 경우, 해당 관절좌표와 대응되는 레이블을 인체 레이블로 설정한다. 여기서, 인체 레이블 맵 생성부는 기 설정된 거리는 임의로 설정할 수 있으며, 상기 설정 값에 따라 인체 레이블 수가 변경 될 수 있다. 여기서는, 기 설정된 거리는 관절좌표에 대응되는 인체 레이블 수가 결정될 수 있도록 설정하는 것이 바람직하다. 또한, 관절좌표가 H개로 구성된 경우, H개의 관절좌표에 대해서, 상기 각각의 관절좌표와, 상기 레이블 맵과의 거리를 측정하고, 상기 측정된 거리가 기 설정된 거리보다 작은 경우, 해당 관절좌표와 대응되는 레이블을 인체 레이블로 설정하고, 이를 순차적으로 반복 수행하여 H개의 인체 레이블을 생성하고, 상기 생성된 H개의 인체 레 이블로 구성된 인체 레이블 맵을 생성한다. 여기서, 상기 거리는 일반적인 거리특정 용어인, 유클리디안 거리(Euclidean distance)를 의미한다. 또한, 앞에서 기술된 상기 휴먼데이터인 관절 좌표가 23개인 경우에 이에 대응되는 23개의 인체 레이블이 생성 된다. 즉, H개의 관절좌표가 이용될 경우, H개의 인체 레이블이 생성되고, 생성된 H개의 인체 레이블로 구성되 는 인체 레이블 맵이 생성된다. 인체 레이블 맵 생성부가 인체 레이블 맵이 생성된 이후, 상기 인체 레이블 맵 및 비인체 레이블 맵(112 0)을 이용하여 제 2영상정보를 생성하는 단계(S440)를 수행한다. 여기서, 비인체 레이블 맵은 상기 관절 좌표와 기설정된 거리보다 큰 경우에 해당하는 영역을 의미한다. 여기서, 기설정된 거리는 임의로 설정될 수 있다. 즉, 제 2 영상정보는 제 1영상정보의 인체영역에 해당되는 인체 레이블 맵과, 상기 제 1영상정보의 인체 영역에 해당되지 않는 비인체 레이블 맵으로 구성된다. 상기 제 2영상정보가 생성된 이후, 패치 맵 생성부는 상기 제 1영상정보와 상기 제 2영상정보를 이용하여 패치 정보를 생성하는 단계(S450)를 수행한다. 도 10은 본 발명에 일실시예에 따른 제 1영상정보와 제 2영상정보를 이용하여 패치 정보를 생성하는 세부 흐름 도이다. 도 10을 참조하면, 상기 제 1영상정보를 특정단위로 분리하여 제 1패치 맵을 생성하는 단계(S1010)와, 상기 제 2영상정보를 특정단위로 분리하여 제 2패치 맵을 생성하는 단계(S1020) 및 상기 제 1패치 맵, 상기 제 2패치 맵을 이용하여 후면 패치 맵 생성하는 단계(S1030)를 포함한다. 먼저, 상기 패치 맵 생성부는 상기 제 1영상정보를 특정단위로 분리하여 제 1패치 맵을 생성하는 단계 (S1010)를 수행한다. 도 12는 본 발명에 일시예에 따른 제 1입력영상과, 제 2입력영상이 복수개의 패치들로 분리되고, 생성되는 후면 서브패치맵을 나타내는 개념도이다. 도 13은 본발명에 일시예에 따른 제 1입력영상의 분리된 제 1영상패치를 서 브패치로 분리된 서브패치군을 나타내는 개념도이다. 도 12 및 도 13을 참조하여, 상기 분리된 특정단위인 패치 및 서브 패치에 관해 기술한다. 도 12를 참조하면, 패치 맵 생성부는 상기 제 1영상정보를 N개의 패치로 분리하여 N개의 제 1영상정보패치 를 생성하고, 상기 N개의 제 1영상정보패치로 구성되는 제 1패치 맵을 생성한다. 여기서, 패치 맵 생성부는 P와 Q를 임의로 설정할 수 있고, P와 Q를 동일하게 또는 다르게 설정할 수 있다. 일반적으로 영상이미지는 각각의 픽셀 단위로 표현되고, 저장되는 구조이어서, P*Q=N개로 분리된 패치도 픽셀 단위로 저장되는 바, 이에 대해서는 공지의 기술이 적용되어 구체적인 기재는 생략한다. 상기 패치 맵 생성부는 상기 제 1영상정보를 분리하여, (1,1)으로 표현되는 제 1패치부터, (P,Q)으로 표현 되는 P*Q의 패치를 생성하고, 상기 생성된 P*Q개, 즉, N개의 제 1영상정보패치를 제 1패치 맵으로 규정하여 용 어를 정의한다. 또한, 상기 패치 맵 생성부는 상기 제 2영상정보를 N개의 패치로 분리하여 N개의 제 2영상정보패치를 생성 하고, 상기 N개의 제 2영상정보패치로 구성되는 제 2패치 맵을 생성한다. 상기 패치 맵 생성부는 상기 제 2영상정보를 분리하여, (1,1)으로 표현되는 제 1패치부터, (P,Q)으로 표현 되는 P*Q의 패치를 생성하고, 상기 생성된 P*Q개, 즉, N개의 제 2영상정보패치를 제 2패치 맵으로 규정하여 용 어를 정의한다. 여기서, 패치 맵 생성부는 P와 Q를 임의로 설정할 수 있고, P와 Q를 동일하게 또는 다르게 설정할 수 있다. 일반적으로 영상이미지는 각각의 픽셀 단위로 표현되고, 저장되고 구조이어서, N개로 분리된 패치도 픽셀 단위로 저장되는 바, 이에 대해서는 공지의 기술이 적용되어 구체적인 기재는 생략한다. 여기서, 상기 픽셀은 공지로 기술된 기술 용어이고, 본 발명에 필요한 범위 내에서 해당 픽셀의 정보에 저장된 정보에 대해 기술한다. 상기 픽셀은 일정정보를 저장하고 있고, 해당 정보를 색상 및 밝기 등으로 표현한다. 상 기 일정 정보는 상기 픽셀의 주소 값, 상기 픽셀의 주소 값에 대응되는 위치정보와 색상정보를 포함할 수 있다. 상기 위치정보는 상기 픽셀의 위치한 위치좌표정보를 포함하고, 상기 색상정보는 공지기술인 색상정보 표시 형 식 인 RGB 값으로 구성되고, RGB 각각의 값은 0~255 범위로 설정하여 사용될 수 있다. 여기서, 상기 제 1패치 맵의 (1,1) 제 1영상정보패치와, 상기 제 2패치 맵의 (1,1) 제 2영상정보패치를 1:1로 매핑하는 것을 동기화로 표현하고, 상기 제 1패치 맵의 (1,2) 제 1영상정보패치와, 상기 제 2패치 맵의 (1,2) 제 1영상정보패치를 1:1로 매핑하고, 순차적으로 상기 제 1패치 맵의 (P,Q)인 제 1영상정보패치와, 상기 제 2패 치 맵의 (P,Q)인 제 2영상정보패치를 1:1로 매핑하여, 상기 제 1패치 맵과 상기 제 2패치 맵의 각각의 구성 패 치를 매핑하여 동기화를 수행한다. 여기서, 상기 제 1패치 맵을 구성하는 N개의 제 1영상정보패치와 제 2패치 맵을 구성하는 N개의 제 2영상정보 패치의 동기화를 위해, 각각의 패치를 구성하는 위치좌표를 이용할 수 있고, 상기 동기화된 제1영상정보패치와, 상기 제 2영상정보패치는 동일한 위치좌표를 가지고 매핑되어 동기화 된다. 이로 인해, 상기 제 1패치 맵을 구성하는 N개의 제 1영상정보패치와 제 2패치 맵을 구성하는 N개의 제 2영상정보패치 각각은 동 일한 위치정보를 저장하고 있다. 여기서, 상기 제 1패치 맵을 구성하는 N개의 제 1영상정보패치는 N개의 서브패치군으로 구성된다. 상기 서브 패치는 한 개 또는 복수 개의 픽셀로 구성된다. 여기서, 상기 픽셀은 공지로 기술된 기술 용어이고, 본 발명에 필요한 범위 내에서 해당 픽셀의 정보에 저장된 정보에 대해 기술한다. 상기 픽셀은 일정정보를 저장하고 있고, 해당 정보를 색상 및 밝기 등으로 표현한다. 상 기 일정 정보는 상기 픽셀의 주소 값, 상기 픽셀의 주소 값에 대응되는 위치정보와 색상정보를 포함할 수 있다. 상기 위치정보는 상기 픽셀의 위치한 위치좌표정보를 포함하고, 상기 색상정보는 공지기술인 색상정보 표시 형 식 인 RGB 값으로 구성되고, RGB 각각의 값은 0~255 범위로 설정하여 사용될 수 있다. 상기 서브 패치는 상기 픽셀을 J개로 구성되고, 상기 J개는 임의로 설정될 수 있다. 바람직하게는 J=4로 설정할 수 있으나, 이에 한정되지 않는다. 또한, 상기 패치는 상기 서브패치 K개로 구성될 수 있고, 상기 K개는 임의로 설정될 수 있다. 바람직하게는 K=4로 설정할 수 있으나, 이에 한정되지 않는다. 여기서, 상기 서브 패치를 구성 하는 특정단위는, J개로 구성된 픽셀을 의미하고, 상기 패치를 구성하는 특정단위는, K개로 구성된 서브패치를 의미한다. 다시, 상기 제 1영상정보를 특정단위로 분리하여 제 1패치 맵을 생성하는 단계(S1010)를 기재하면, 상기 패치 맵 생성부는 상기 제 1영상정보를 N개의 패치로 분리하여 N개의 제 1영상정보패치를 생성하고, 상기 N개의 제 1영상정보패치로 구성되는 제 1패치 맵을 생성한다. 또한, 상기 제 1영상정보패치는 A개의 서브패치로 분리하고, 상기 제 1영상정보패치와 대응되는 상기 A개의 서 브패치로 구성된 서브패치군을 생성한다. 또한, 상기 N개의 모든 제 1영상정보패치에 대해 순차적으로 A개의 서브패치로 분리하고, 상기 N개의 모든 제 1 영상정보패치 각각에 대응되는 N개의 서브패치군을 생성하고, 상기 N개의 서브패치군으로 구성된 서브 패치 맵 을 생성한다. 여기서, 상기 서브 패치맵을 구성하는 N개의 서브패치군과, 상기 제 1패치 맵을 구성하는 N개의 제 1영상정보패 치는, 앞에서 기재된 복수개의 픽셀들로 구성되고, 상기 픽셀의 저장정보인 주소 값, 상기 픽셀의 주소 값에 대 응되는 위치정보와 색상정보도 함께 저장된다. 상기 서브 패치 맵이 생성된 이후, 상기 제 1서브패치군을 구성하는 A개 서브패치의 색상정보 값을 합산하여 평 균 값을 계산하고, 상기 평균 값을 상기 A개의 서브패치의 색상정보 값으로 변경하고, 상기 변경된 색상정보 값 이 반영된 A개의 서브패치로 구성되어 제 1평균서브패치군을 생성한다. 또한, 상기 A개의 서브패치 색상정보 값을 합산하여 평균 값을 계산하고, 상기 평균 값을 상기 A개의 서브패치 의 색상정보 값으로 변경하고, 상기 변경된 색상정보 값이 반영된 A개의 서브패치로 구성되어 제 1평균서브패치 군을 생성하는 과정을, 상기 N개의 모든 서브패치군에 대해 순차적으로 수행하여, N개의 평균서브패치군을 생성 하고, 상기 N개의 평균서브패치군으로 구성된 평균서브 패치 맵을 생성한다. 도 14는 본발명에 일시예에 따른 서브패치군을 구성하는 서브패치의 픽셀 정보 및 평균 연산을 수행하여 제 1평 균서브패치군을 생성하는 개념도이다. 도 14를 참조하면, 1개의 패치가 4개의 서브패치로 구성되고, 상기 서브패치가 4개의 픽셀로 구성된 일 실시예 이다. 여기서, 앞서 기재된 바와 같이, 하나의 픽셀은 RGB 형태의 3가지 색상정보를 포함하고 있으며, 각각의 표현 값 은 0 ~ 255까지 자연수로 표현된다. 상기 서브패치1을 구성하는 4개 픽셀은 색상정보가 기재되어 있고, 상기 서 브패치 2 내지 4를 각각 구성하는 4개의 픽셀은 색상정보 기재되어 있다. 이들 각각의 색상정보를 합산 및 평균 연산을 수행하여, 제 1평균 서브패치군을 생성하고, 상기 생성된 제 1 평균 서브 패치군에는 합산 및 평균 연산 이 수행된 색상정보가 반영된다. 앞에서 기술된 바와 같이, 서브 패치는 임의개의 픽셀로 설정할 수 있고, 제 1 패치도 임의개의 서브패치로 설 정할 수 있다. 상기 패치 맵 생성부는 상기 제 1영상정보를 특정단위로 분리하여 제 1패치 맵을 생성하면, 상기 패치 맵 생성부는 상기 제 2영상정보를 특정단위로 분리하여 제 2패치 맵을 생성하는 단계(S1020)를 수행한다. 보다 구체적으로 기술하면, 상기 제 2영상정보를 N개의 패치로 분리하여 N개의 제 2영상정보패치를 생성하고, 상기 N개의 제 2영상정보패치로 구성되는 제 2패치 맵을 생성한다. 일반적으로, 상기 N개의 제 2영상정보패치로 구성되는 제 2패치 맵의 N개의 제 2영상정보패치는 상기 제 1패치 맵을 구성하는 N개의 제 1영상정보패치와 동일한 패치 개수로 구성하는 것이 바람직하다. 결과적으로, 상기 제 1패치 맵을 구성하는 N개의 제 1영상정보패치와, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군과, 상기 제 2패치 맵을 구성하는 N개의 제 2영상정보패치는 동일한 N개의 패치 개수로 구성되는 것이 바람직하다. 상기 제 2영상정보를 특정단위로 분리하여 제 2패치 맵이 생성된 이후, 상기 패치 맵 생성부는 상기 제 1 패치 맵, 상기 제 2패치 맵을 이용하여 후면 패치 맵 생성하는 단계(S1030)를 수행한다. 실시예 중 제 1실시예를 기재한다. 제 1실시예에 대해 기술하면, 상기 N개의 평균서브패치군이 포함된 평균서브 패치 맵 중 제 1평균서브패치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치군을 설정하고, 상기 제 1평균서브패치군의 제 1가중치와, 상기 제 1평균서브패치군과 상기 복수개의 인접평균서브패치군 간의 이격 거리에 비례하여 상기 복수개의 평균서브패 치군의 제 2가중치를 설정하고, 상기 제 1평균서브패치군에 상기 제 1가중치가 반영된 제 1색상정보 값과, 상기 복수개의 인접평균서브패치군의 색상정보에 제 2가중치가 반영된 제 2색상정보 값의 평균 값을 반영하여 후면 색상정보 값을 생성하고, 상기 후면 색상정보 값이 반영된 후면서브패치군을 생성하고, 상기 후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 수행하여, N개의 후면서브패치군을 생성하고, 상기 N개의 후면서브패치군으로 구성되는 후면서브패치 맵을 생성한다. 도 12 내지 14을 참조하여 구체적으로 기재하면, 도 12는 제 1패치 맵과, 제 2패치 맵을 이용하여 생성된 후면 서브패치 맵을 나타내고 있다. 상기 패치 맵 생성부는 상기 제 1패치 맵의 N개의 제 1영상정보패치로부터 생성된 N개의 평균서브패치군으 로 구성된 평균서브 패치 맵을 이용하여, 즉, 일정 연산을 수행하여 N개의 후면서브패치군을 구성된 후면서브패 치 맵을 생성한다. 여기서, 상기 패치 맵 생성부는 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 하나인 제 1 평균서브패치군을 임의로 선정하여, 상기 제 1평균서브패치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치 군을 설정한다. 도 15는 본발명에 일시예에 따른 제 1평균서브패치군과, 제 1인접평균서브패치군에 제 1 및 제 2 가중치를 부여 하는 개념도이다. 도 15를 참조하면, 상기 패치 맵 생성부가 중앙에 제 1평균서브패치군을 설정하면, 인접한 평균서브패치군은 8개가 설정되고, 상기 설정된 8개의 평균서브패치군을 제 1인접평균서브 패 치군으로 한다. 여기서, 상기 패치 맵 생성부가 제 1평균 서브패치군에 제 1가중치를 임의로 설정할 수 있고, 일 예 로, 0.4를 설정한 후, 상기 제 1인접평균서브 패치군에 제 2가중치를 임의로 설정할 수 있고, 일 예로, 0.075를 설정할 수 있다. 제 1평균 서브패치군의 제1 가중치와 제 1인접평균서브 패치군을 구성하는 8개의 평균서브패치군의 제 2 가중치 합을 1로 하는 것이 바람직하고, 제 1평균 서브패치군의 제1 가중치를 제 1인접평균서브 패치군의 제 2 가중치보다 크게 설정하는 것이 바람직하다. 또한, 제 1인접평균서브 패치군을 구성하는 8개의 평 균서브패치군의 제 2 가중치는 균등하게 설정하는 것이 바람직하다. 일 예로, 상기 제 1 가중치와 상기 제 1인접평균서브 패치군의 제 2가중치는 아래의 수식조건을 만족한다. 여기서, 상기 제 1가중치를 상기 제 2가중치 보다 큰 값으로 설정하고, 상기 제 1가중치와 상기 복수개의 제 1 인접평균서브패치군에 설정된 제 2가중치들의 합이 1로 설정하고, 상기 제 1 가중치인 C는 이고, 상기 제 2 가중치인 w는 이고, 상기 제 1가중치와 상기 제 2가중치들의 상관 관계식인 W은 이고, 상기 Z는 상기 제 1평균서브패치군과, 상기 복수개의 제 1 인접평균서브패치군 의 패치군수의 합으로 설정한다 도 15를 다시 참조하여, 후면서브 패치군을 생성하는 단계를 기술한다. 상기 제 1평균서브패치군은 RGB 색상정보를 저장하고 있고, 상기 제 1가중치를 적용하여, 각각의 RGB 색상정보 값에 상기 제 1가중치가 적용된 합산 값을 구한다. 또한, 제 1인접평균서브 패치군을 구성하는 8개의 평균서브패치군도 각각의 RGB 색상정보 값을 저장하고 있고, 각각의 RGB 색상정보 값에 상기 제 2가중치가 적용된 합산 값을 구한다. 제 1평균서브패치군에 저장된 상기 제 1가중치가 적용된 합산 값과, 제 1인접평균서브 패치군을 구 성하는 8개의 평균서브패치군에 각각의 RGB 색상정보 값에 상기 제 2가중치가 적용된 합산 값의 평균 값을 계산 한다. 상기 평균 값을, 상기 제 1평균서브패치군의 각각의 RGB 색상정보 값으로 대체하여 저장하고, 상기 각각 의 RGB 색상정보 값으로 대체된 상기 제 1평균서브패치군을 제 1 후면서브패치군으로 생성한다. 위에서 기술된 방법을 상기 후면서브패치군을 생성하는 단계를, 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 수행하여, N개의 후면서브패치군을 생성하고, 상기 N개의 후면서브패치군으로 구 성되는 후면서브패치 맵을 생성한다. 상기 후면서브패치 맵이 생성된 이후, 상기 패치 정보를 이용 후면 영상정보 생성(S460)한다. 상기 N개의 후면서브패치군 사이의 노이즈 제거를 위해서, 상기 노이즈는 공지된 엣지 블렌딩 알고리즘을 적용 하여, 각각 후면 패치의 가장자리 픽셀을 가우시안 블러(Gaussian Blur) 연산을 수행하여 노이즈를 제거하는 엣 지 블렌딩을 수행하고, 최종적인 후면 텍스처 맵을 생성한다. 실시예 중 제 2실시예를 기재한다. 상기 제 2실시예는 데이터 연산량을 감소시키기 위해서, 제 2영상정보 중 인 체 레이블 맵에 해당되는 인체 레이블 패치에 대해서만, 제 1실시예의 가중치 기반 연산을 수행하여 제 1후면서 브패치군을 생성하고, 비인체레이블 맵의 경우, 별도의 가중치 연산을 수행하지 않고, 평균서브패치군을 적용하 여 제 2후면서브패치군을 생성하고, 상기 제 1후면서브패치군과, 상기 제 2후면서브패치군을 적용하여 후면서브 패치 맵을 생성한다. 이에 대해 구체적으로 기술하면, 상기 제 1패치 맵의 (1,1)의 제 1영상정보패치와, 상기 제 2패치 맵의 (1,1)의 제 2영상정보패치를 1:1로 매핑하는 것을 동기화로 표현하고, 상기 제 1패치 맵의 (1,2) 제 1영상정보패치와, 상기 제 2패치 맵의 (1,2) 제 1영상정보패치를 1:1로 매핑하고, 순차적으로 상기 제 1패치 맵의 (P,Q) 제 1영상 정보패치와, 상기 제 2패치 맵의(P,Q) 제 2영상정보패치를 1:1로 매핑하여, 상기 제 1패치 맵과 상기 제 2패치 맵의 각각의 구성 패치를 매핑하여 동기화를 수행한다. 여기서, 상기 제 1패치 맵을 구성하는 N개의 제 1영상정보패치와 제 2패치 맵을 구성하는 N개의 제 2영상정보 패치의 동기화를 위해, 각각의 패치를 구성하는 위치좌표를 이용할 수 있고, 상기 동기화된 제 1영상정보패치와, 상기 제 2영상정보패치는 동일한 위치좌표를 가지고 매핑되어 동기화 된다. 이로 인해, 상기 제 1패치 맵을 구성하는 N개의 제 1영상정보패치와 제 2패치 맵을 구성하는 N개의 제 2영상정보패치 각각은 동 일한 위치정보를 저장하고 있다. 또한, 앞서 기술된 바와 같이, 상기 N개의 서브패치군과, 상기 N개의 제 1평균서브패치군은 색상정보 값만 변경 되어 저장되어 있고, 상기 N개의 서브패치군과, 상기 N개의 제 1평균서브패치군은 상기 N개의 제 1영상정보패치 의 각각의 위치정보를 그대로 저장되어 있다. 따라서, 상기 N개의 제 1평균서브패치군은 상기 제 2패치 맵을 구 성하는 N개의 제 2영상정보패치와 동기화 되어 있어, 동일한 위치좌표를 저장하고 있다. 또한, 앞서 기술된 바와 같이, 상기 제 2패치 맵을 구성하는 N개의 제 2영상정보패치도 각각의 위치정보가 저장 되어 있고, 상기 각각의 위치정보는 인체 레이블 맵과, 비인체레이블 맵의 각각의 패치에 저장되어 있다. 따라서, 상기 N개의 제 1평균서브패치군은, 상기 인체 레이블 맵과, 비인체레이블 맵의 위치정보를 기초로 동기 화 될 수 있다. 상기 N개의 제 1평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들 의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표인 경우, 가중치 연산을 수행하여 제 1후면서브패치군을 생 성하고, 상기 N개의 제 1평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 비인체 레이블 맵을 구성하 는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표인 경우, 가중치 연산을 수행하지 않고, 상기 제 1평균서브패치군을 제 2후면서브패치군으로 대체한다. 결과적으로 가중치 연산을 수행하여 생성된 제 1후면서브패치군이 S개, 가중치 연산을 수행하지 않고 생성된 제 2후면서브패치군이 T개라면, S+T=N을 만족하여, 후면서브패치 맵이 생성된다. 이를 상세히 기술하면, 인체 레이블 맵을 구성하는 패치들의 경우, 아래의 과정을 통해 S개의 제 1후면서브패치 군이 생성된다. 상기 N개의 평균서브패치군이 포함된 평균서브 패치 맵 중 제 1평균서브패치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치군을 설정하고, 상기 제 1평균서브패치군의 제 1가중치와, 상기 제 1평균서브패치군과 상기 복 수개의 인접평균서브패치군 간의 이격 거리에 비례하여 상기 복수개의 평균서브패치군의 제 2가중치를 설정하고, 상기 제 1평균서브패치군에 상기 제 1가중치가 반영된 제 1색상정보 값과, 상기 복수개의 인접평균서 브패치군의 색상정보에 제 2가중치가 반영된 제 2색상정보 값의 평균 값을 반영하여 후면 색상정보 값을 생성하 고, 상기 후면 색상정보 값이 반영된 후면서브패치군을 생성하고, 상기 후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 수행하여, S개의 제 1후면서브패치군을 생성한다. 도 12 내지 16을 참조하여 구체적으로 기재하면, 도 12는 제 1패치 맵과, 제 2패치 맵을 이용하여 생성된 후면 서브패치 맵을 나타내고 있다. 상기 패치 맵 생성부는 상기 제 1패치 맵의 N개의 제 1영상정보패치로부터 생성된 N개의 평균서브패치군을 구성된 평균서브 패치 맵을 이용하여, 즉, 일정 연산을 수행하여 S개의 제 1후면서브패치군을 생성한다. 여기서, 상기 패치 맵 생성부는 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 하나인 제 1 평균서브패치군을 임의로 선정하여, 상기 제 1평균서브패치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치 군을 설정한다. 도 15를 참조하면, 상기 패치 맵 생성부가 중앙에 제 1평균서브패치군을 설정하면, 인접한 평균서브 패치군은 8개가 설정되고, 상기 설정된 8개의 평균서브패치군을 제 1인접평균서브 패치군으로 한다. 여기서, 상기 패치 맵 생성부가 제 1평균 서브패치군에 제 1가중치를 임의로 설정할 수 있고, 일 예 로, 0.4를 설정한 후, 상기 제 1인접평균서브 패치군에 제 2가중치를 임의로 설정할 수 있고, 일 예로, 0.075를 설정할 수 있다. 제 1평균 서브패치군의 제1 가중치와 제 1인접평균서브 패치군을 구성하는 8개의 평균서브패치군의 제 2 가중치 합을 1로 하는 것이 바람직하고, 제 1평균 서브패치군의 제1 가중치를 제 1인접평균서브 패치군의 제 2 가중치보다 크게 설정하는 것이 바람직하다. 또한, 제 1인접평균서브 패치군을 구성하는 8개의 평 균서브패치군의 제 2 가중치는 균등하게 설정하는 것이 바람직하다. 여기서, 상기 제 1평균 서브패치군과 인접한 제 1인접평균서브 패치군 중 8개의 평균서브패치군이 상기 인체 레 이블 맵을 구성하는 패치의 위치정보 값에 포함되지 않은 영역, 즉, 비인체 레이블 맵을 구성하는 패치인 경우, 해당 가중치인 제 2가중치를 0으로 설정하고, 상기 제 1평균 서브패치군과 인접한 제 1인접평균서브 패치군 중 8개의 평균서브패치군이 상기 인체 레이블 맵을 구성하는 패치의 위치정보 값에 해당되는 영역인 경우, 제 2가 중치를 부여한다. 일 예로, 상기 제 1 가중치와 상기 제 1인접평균서브 패치군의 제 2가중치는 아래의 수식조건을 만족한다. 상기 제 1가중치를 상기 제 2가중치 보다 큰 값으로 설정하고, 상기 제 1가중치와 상기 복수개의 제 1 인접평균서브패치군에 설정된 제 2가중치들의 합이 1로 설정하고, 상기 제 1 가중치인 C는 이고, 상기 제 2 가중치인 w는 이고, 상기 제 1가중치와 상기 제 2가중치들의 상관 관계식인 W은 이고, 상기 Z는 상기 제 1평균서브패치군과, 상기 복수개의 제 1 인 접평균서브패치군의 패치군수의 합으로 설정한다. 도 14를 다시 참조하여, 후면서브 패치군을 생성하는 단계를 기술한다. 상기 제 1평균서브패치군은 RGB 색상정보를 저장하고 있고, 상기 제 1가중치를 적용하여, 각각의 RGB 색상정보 값에 상기 제 1가중치가 적용된 합산 값을 구한다. 또한, 제 1인접평균서브 패치군을 구성하는 8개의 평균서브패치군도 각각의 RGB 색상정보 값을 저장하고 있고, 각각의 RGB 색상정보 값에 상기 제 2가중치가 적용된 합산 값을 구한다. 제 1평균서브패치군에 저장된 상기 제 1가중치가 적용된 합산 값과, 제 1인접평균서브 패치군을 구 성하는 8개의 평균서브패치군에 각각의 RGB 색상정보 값에 상기 제 2가중치가 적용된 합산 값의 평균 값을 계산 한다. 상기 평균 값을, 상기 제 1평균서브패치군의 각각의 RGB 색상정보 값으로 대체하여 저장하고, 상기 각각 의 RGB 색상정보 값으로 대체된 상기 제 1평균서브패치군을 제 1 후면서브패치군으로 생성한다. 위에서 기술된 방법을 상기 후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N개의 모든 평 균서브패치군에 순차적으로 수행하여, S개의 후면서브패치군을 생성한다. 비인체 레이블 맵을 구성하는 패치들의 경우, 아래의 과정을 통해 T개의 제 2후면서브패치군이 생성된다. 다시 기술하면, 상기 N개의 제 1평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 비인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표인 경우, 가중치 연산을 수행하지 않고, 상 기 제 1평균서브패치군을 제 2후면서브패치군으로 대체하여, T개의 제 2후면서브패치군을 생성한다. 상기 S개의 제 1후면서브패치군과, 상기 T개의 제 2후면서브패치군을 적용하여 최종적은 S+T=N 개의 후면서브 패치군으로 구성되는 후면서브패치 맵을 생성한다. 상기 후면서브패치 맵이 생성된 이후, 상기 패치 정보를 이용 후면 영상정보 생성(S460)한다. 상기 N개의 후면서브패치군 사이의 노이즈 제거를 위해서, 상기 노이즈는 공지된 엣지 블렌딩 알고리즘을 적용 하여, 각각 후면 패치의 가장자리 픽셀을 가우시안 블러(Gaussian Blur) 연산을 수행하여 노이즈를 제거하는 엣 지 블렌딩을 수행하고, 최종적인 후면 텍스처 맵을 생성한다. 도 5는 본 발명에 따른 메타버스 제작을 위한 메타버스 제작시스템을 나타내는 메타버스 제작 시스템도이다. 도 17은 본 발명에 따른 메타버스 제작방법을 나타내는 흐름도이다. 도 18은 본 발명에 따른 메타버스 제작방법의 입력영상, 생성된 휴먼포즈 정보, 레이블 맵, 인체 레이블 맵 및 3D 메쉬 정보를 송수신하기 위한 데이터 프레 임 개념도이다. 도 5, 도 17 및 도 18을 참조하면, 상기 서버는 메타버스 제작시스템은 로드밸런서부를 더 포함하고, 상기 로드밸런서부는 단말로부터 메타버스 생성요청 정보가 포함된 제 1프레임이 수신되면, 상기 영상부, 상기 휴먼포즈 생성부, 상기 레이블 맵 생성부, 상기 인체레이블 맵 생성부, 및 상기 후면 영상처리부의 각각의 처리 용량을 기초하여 우선순위를 부여하여 메타버스를 생성하는 것을 특징으로 한다. 상기 로드밸런서부는 상기 서버를 구성하고 있는 특정부의 연산처리 능력 및 현재 처리하고 있는 연 산처리량을 기준으로 상기 수신된 영상정보, 즉 프레임들을 분배한다. 또한, 상기 서버가 복수개의 서버로 구성될 경우, 상기 복수개의 서버를 구성하고 있는 특정부의 연산처리 능력 및 현재 처리하고 있는 연산처리량 을 기준으로 상기 수신된 영상정보, 즉 프레임들을 분배한다. 또한, 상기 로드밸런서부는, 일 예로 인공신 경망 알고리즘을 이용하여, 각각의 특정부가 특정 기능을 수행하기 위해서 연산처리용량, 연산량 등의 로드에 관한 실시간 정보를 획득하여, 상기 로드가 적은 특정부로 상기 수신영상정보를 전달한다. 이러한 로드밸런싱 기능을 적용하여, 상기 각각의 특정부의 연산처리 효율을 증대 시킬 수 있다. 또한, 상기 서버의 로드밸런서부는 단말이 요청 또는 송신한 영상정보를 하나의 단위로 분배한 다. 이러한 로드밸런싱 기능을 적용하여, 서버에 복수의 단말이 접속한 경우에도 활성화된 합성곱 신경망 (CNN, Convolutional Neural Network)을 최대로 활용할 수 있다. 서버는 영상정보를 단말로부터 수신단계(S1710), 서버는 수신영상정보를 특정부로 전달하는 단계(S1720), 서버 를 구성하는 특정부는 전달된 영상정보를 가공하는 단계(S1730), 서버는 가공영상 정보를 단말로 송신하는 단계 (S1740), 단말은 상기 가공영상을 후처리하는 단계(S1750), 단말은 상기 가공영상을 이용하여 편집영상 생성하 는 단계(S1760) 및 단말은 상기 편집영상을 재생하는 단계(S1770)를 포함하여 구성될 수 있다. 상기 서버는 영상정보를 단말로부터 수신단계(S1720)는, 단말을 구성하는 영상부가 카메라로부터 획 득된 영상을 영상정보로 저장한 이후, 상기 영상정보를 서버로 통신부를 이용하여 서버로 송신한다. 상기 서버는 상기 단말로부터 수신된 상기 영상정보를 상기 서버를 구성하고 있는 통신부를 이용하여 수신한다. 도 18을 참조하여, 상기 영상정보 및 프레임 구조에 대해서 기술한다. 여기서, 상기 영상정보는, 일반적으로 데이터를 저장하는 파일형식인 JPG 파일 등 다양한 형태로 영상 또는 이 미지를 저장하는 데이터 또는 데이터 파일을 의미한다. 또한, 일련의 연속된 이미지인 동영상 파일을 포함할 수 있다. 상기 영상정보는 N개의 영상정보를 저장하고 있고, 상기 N개의 영상정보를 구성하는 영상정보군을 생성하여 저 장한다. 상기 N개의 각각의 영상정보는 각각의 프레임에 저장되고 송수신된다. 상기 프레임은, 공지된 데이터 전송 방법인, OSI 7 Layer 구조를 채용하고 있어, 일반적이 통신 전송 데이터와 호환성을 유지하고 있으며, 상위단인 Applicaition 단계에서 일부 구조가 변경된 형태이다. 즉, Applicaition 단계의 프레임 구조의 헤더 부분에 프레임 번호의 일련번호를 부가하고, 일예로, 1, 2, 3 등 순서로 일련번호를 부가한다. 이후, 상기 헤더 이후 데이터 저장공간에 일정량의 저장용량을 설정하여, 영상정보, 휴먼포즈 데이터, 레이블 맵 정보, 인체 레이블 맵 정보, 매쉬정보를 순차적으로 저장한다. 이러한 프레임 구조를 적용하 여 상기 서버와 상기 단말간 데이터 교환 시, 기존 보다 빠른 데이터 전송 및 처리가 가능하다. 또 한, 상기 프레임은 픽셀의 주소 값, 위치좌표 관련 위치정보 등이 저장될 수 있다. 여기서, 상기 단말은 상기 프레임을 N개의 프레임들로 설정하고, 상기 단말은 상기 제 1 영상정보와, 일련번호 를 부가 및 저장하여 제 1 프레임을 생성한다. 또한, 상기 단말은 상기 N개의 영상정보와 일련번호들을 순차적 으로 부가 및 저장하여 N개의 프레임을 생성한다. 상기 단말을 구성하는 상기 통신부는 상기 N개의 프레임들을 서버로 송신한다. 여기서, 상기 통신부는 상기 제 1프레임을 생성 시, 바로 서버로 송신하고, 순차적으로 생성되는 N개의 프레임들을 서버로 송신할 수 있고, 또 는 모든 N개의 프레임들이 생성된 후, 상기 모든 N개의 프레임들을 서버로 송신할 수 도 있다. 즉, 상기 단말은 N개의 영상정보로 구성되는 영상정보군 중 제 1영상정보와, 상기 제 1영상정보와 대응되는 프 레임 번호를 저장하는 제 1프레임을 생성하여 상기 제 1프레임을 저장한다. 또한, 상기 단말은 상기 영상정보군 의 모든 N개의 영상정보에 대해 순차적으로 상기 N개의 영상정보와, 상기 N개의 영상정보와 대응되는 프레임의 일련번호들을 저장하는 N개의 프레임들을 생성하여, 상기 N개의 프레임들을 저장하고, 상기 N개의 프레임들을 상기 서버로 송신한다. 또한, 상기 단말은 상기 N개의 프레임들을 동시에 서버로 송신할 수도 있고, 지정된 프레임들만 선택적으로 송 신할 수 도 있다. 상기 서버는 영상정보를 단말로부터 수신한 이후, 상기 수신 영상정보를 특정부로 전달하는 단계(S1720)를 수행 한다. 상기 서버를 구성하고 있는 로드밸런서부는 상기 서버를 구성하고 있는 특정부의 연산처리 능력 및 현재 처리하 고 있는 연산처리량을 기준으로 상기 수신된 영상정보, 즉 프레임들을 분배한다. 또한, 상기 서버가 복수개의 서버로 구성될 경우, 상기 복수개의 서버를 구성하고 있는 특정부의 연산처리 능력 및 현재 처리하고 있는 연산 처리량을 기준으로 상기 수신된 영상정보, 즉 프레임들을 분배할 수 있다. 또한, 상기 로드밸런서부는, 일 예 로 인공신경망 알고리즘을 이용하여, 각각의 특정부가 특정 기능을 수행하기 위해서 연산처리용량, 연산량 등의 로드에 관한 실시간 정보를 획득하여, 상기 로드가 적은 특정부로 상기 수신영상정보를 전달한다. 이러한 로드 밸런싱 기능을 적용하여, 상기 각각의 특정부의 연산처리 효율을 증대 시킬 수 있다. 또한, 상기 서버를 구성하는 로드밸런스부는 단말이 요청 또는 송신한 영상정보를 하나의 단위로 분배한다. 이 러한 로드밸런싱 기능을 적용하여, 서버에 많은 수의 단말이 접속한 경우에도 활성화된 합성곱 신경망(CNN, Convolutional Neural Network)을 최대로 활용할 수 있다. 여기서, 특정부는, 도 5를 참조하여 기재하면, 휴먼포즈 생성부, 레이블 맵 생성부, 인체 레이블 맵 생성부, 패치 맵 생성부, 3D 매쉬 생성부을 포함하여 구성된다. 또한, 일 예로, 휴먼포즈 생성부, 레이블 맵 생성부, 인체 레이블 맵 생성부, 패치 맵 생성부, 3D 매쉬 생성부 는 특정 기능 및 연산을 수행하는 프로세서로 구성되고, 하나 또는 복수개의 프로세서로 구성될 수 있다. 상기 수신 영상정보를 특정부로 전달하는 단계(S1720)가 수행된 이후, 상기 서버를 구성하는 특정부는 전달된 영상정보를 가공하는 단계(S1730)를 수행한다. 상기 서버를 구성하는 특정부는 전달된 영상정보를 가공하는 단 계(S1730)는 상기 전달된 영상정보, 즉, 프레임들을 이용하여, 휴먼포즈 데이터 생성, 레이블 맵 생성, 3D 매쉬 생성 단계를 수행한다. 여기서, 상기 휴먼포즈 데이터 생성, 상기 레이블 맵 생성, 상기 3D 매쉬 생성 단계는 수신된 프레인 단위로 수 행되고, 순서와 무관하게 선택적으로 수행할 수 있다."}
{"patent_id": "10-2022-0171118", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 메타버스 제작을 위한 메타버스 제작방법을 나타내는 흐름도이다. 도 2는 본 발명에 따른 메타버스 제작을 위한 공간영상정보를 나타내는 일 예시도이다. 도 3은 본 발명에 따른 메타버스 제작방법의 사용자 인터페이스를 나타내는 일 예시도이다. 도 4는 본 발명에 따른 메타버스 제작을 위한 메타버스 제작방법의 후면 영상정보를 생성하는 단계(S130)를 구 체적으로 나타내는 흐름도이다. 도 5는 본 발명에 따른 메타버스 제작을 위한 메타버스 제작시스템을 나타내는 메타버스 제작 시스템도이다. 도 6은 본 발명에 따른 메타버스 제작방법의 후면 영상정보를 생성하는 방법을 나타내는 개념도이다. 도 7은 본 발명에 일실시예에 따른 입력된 제 1영상정보를 이용하여 휴먼포즈 데이터를 생성하는 개념도이다. 도 8은 본 발명에 일실시예에 따른 입력된 제 1영상정보를 이용하여 휴먼포즈 데이터인 관절좌표에 대한 도면이 다. 도 9는 본 발명에 일실시예에 따른 입력된 제 1영상정보를 이용하여 세그멘테이션하여 레이블 맵을 생성하는 개 념도이다. 도 10은 본 발명에 일실시예에 따른 제 1영상정보와 제 2영상정보를 이용하여 패치 정보를 생성하는 세부 흐름 도이다. 도 11은 본 발명에 일시예에 따른 인체 레이블 맵과 비인체 레이블 맵을 나타내는 일 예시도이다. 도 12는 본 발명에 일시예에 따른 제 1입력영상과, 제 2입력영상이 복수개의 패치들로 분리되고, 생성되는 후면 서브패치맵을 나타내는 개념도이다. 도 13은 본발명에 일시예에 따른 제 1입력영상의 분리된 제 1영상패치를 서브패치로 분리된 서브패치군을 나타 내는 개념도이다. 도 14는 본발명에 일시예에 따른 서브패치군을 구성하는 서브패치의 픽셀 정보 및 평균 연산을 수행하여 제 1평 균서브패치군을 생성하는 개념도이다. 도 15는 본발명에 일시예에 따른 제 1평균서브패치군과, 제 1인접평균서브패치군에 제 1 및 제 2 가중치를 부여 하는 개념도이다. 도 16은 본발명에 일시예에 따른 제 1 및 제 2 가중치를 부여하여 후면서브패치 맵을 생성하는 개념도이다. 도 17은 본 발명에 따른 메타버스 제작방법을 나타내는 흐름도이다. 도 18은 본 발명에 따른 메타버스 제작방법의 입력영상, 생성된 휴먼포즈 정보, 레이블 맵, 인체 레이블 맵 및 3D 메쉬 정보를 송수신하기 위한 데이터 프레임 개념도이다."}
