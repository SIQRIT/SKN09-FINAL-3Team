{"patent_id": "10-2021-0178871", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0090007", "출원번호": "10-2021-0178871", "발명의 명칭": "다중 센서를 이용한 딥러닝 기반의 3차원 물체 검출 및 추적 통합 기술", "출원인": "한양대학교 산학협력단", "발명자": "최준원"}}
{"patent_id": "10-2021-0178871", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "검출 및 추적 통합 시스템에 의해 수행되는 딥러닝 기반의 3차원 물체 검출 및 추적 통합 방법에 있어서,다중 센서를 이용한 센서 데이터로부터 획득된 각각의 특징 지도에 대하여 생성된 융합 특징 지도를 물체 검출및 추적 통합 모델을 이용하여 물체 검출의 결과를 추출하는 단계; 및 상기 물체 검출에서 사용된 특징 지도를 이용하여 획득된 각 물체의 특징 지도를 그래프 뉴럴 네트워크(GNN)를통해 유사도에 따라 공유되는 물체들을 연결하여 물체를 추적하는 단계 를 포함하는 3차원 물체 검출 및 추적 통합 방법."}
{"patent_id": "10-2021-0178871", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 탐지 물체 검출 및 추적 통합 모델은, 물체 검출을 수행할 때 물체 추적 정보를 사용하고 물체 추적을 수행할 때 물체 검출 정보를 사용하도록구성된, 것을 특징으로 하는 3차원 물체 검출 및 추적 통합 방법."}
{"patent_id": "10-2021-0178871", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 탐지 물체 검출 및 추적 통합 모델은, 상기 물체 검출을 수행할 때 각 물체의 특징 지도를 융합 네트워크를 통해 시공간적으로 융합하고 상기 물체 추적에서 획득된 추적 결과를 이용하여 물체가 검출되도록 학습된, 것을 특징으로 하는 3차원 물체 검출 및 추적통합 방법."}
{"patent_id": "10-2021-0178871", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 물체 검출 및 추적 통합 모델은, 카메라와 센서 데이터(LiDAR)를 입력으로 하는 딥뉴럴 네트워크에서 물체가 있는 지역 정보를 획득하기 위한 네트워크와 상기 물체가 있는 지역 정보를 포함하는 두 프레임 간의 정보에 상호 연관성을 부여하기 위한 네트워크를 포함하는 융합 네트워크가 구성된, 것을 특징으로 하는 3차원 물체 검출 및 추적 통합 방법."}
{"patent_id": "10-2021-0178871", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 물체 검출의 결과를 추출하는 단계는,다중 센서 데이터를 딥뉴럴 네트워크를 이용하여 각각의 특징 지도를 획득하고, 상기 획득된 각각의 특징 지도에 시공간적 융합과 센서 융합 기술을 통해 융합 특징 지도를 생성하는 단계를 포함하는 3차원 물체 검출 및 추적 통합 방법."}
{"patent_id": "10-2021-0178871", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 물체 검출의 결과를 추출하는 단계는,현재 시점을 기준으로 이전의 특징 지도와 현재 시점의 특징 지도 사이의 가중치 지도를 CNN을 통해 생성하고,공개특허 10-2023-0090007-3-상기 생성된 가중치 지도를 각각의 특징 지도에 곱함에 따라 생성된 각각의 특징 결과를 더해주어 시공간 융합특징 지도를 생성하는 단계 를 포함하는 3차원 물체 검출 및 추적 통합 방법."}
{"patent_id": "10-2021-0178871", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 물체 검출의 결과를 추출하는 단계는,상기 생성된 시공간 융합 특징 지도에 센서 융합 기술을 적용하여 센서 융합 특징 지도를 추출하는 단계를 포함하는 3차원 물체 검출 및 추적 통합 방법."}
{"patent_id": "10-2021-0178871", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 물체 검출의 결과를 추출하는 단계는,현재 시점을 기준으로 이전 시간까지 축적된 물체 추적의 결과를 이용하여 시간 데이터 기반의 물체 검출의 결과를 추출하는 단계를 포함하는 3차원 물체 검출 및 추적 통합 방법."}
{"patent_id": "10-2021-0178871", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 물체 검출의 결과를 추출하는 단계는,상기 물체 추적의 결과와 현재 앵커 박스 사이의 IoU(Intersection over Union)을 계산하여 물체 후보군을 획득하고, 상기 획득된 물체 후보군을 상기 물체 추적의 결과와의 IoU를 계산하여 물체 검출의 결과를 정제하는 단계를 포함하는 3차원 물체 검출 및 추적 통합 방법."}
{"patent_id": "10-2021-0178871", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 물체를 추적하는 단계는, 시공간 그래프 뉴럴 네트워크를 통해 시공간적으로 유사도가 높은 각 물체의 특징 지도끼리 정보를 공유하고,상기 공유되는 각 물체의 특징 지도에 대하여 시간 축으로 계산된 유사도에 따라 물체들을 연결시키는 단계 를 포함하는 3차원 물체 검출 및 추적 통합 방법."}
{"patent_id": "10-2021-0178871", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제10항 중 어느 한 항의 3차원 물체 검출 및 추적 통합 방법을 상기 검출 및 추적 통합 시스템에 실행시키기 위해 비-일시적인 컴퓨터 판독가능한 기록 매체에 저장되는 컴퓨터 프로그램."}
{"patent_id": "10-2021-0178871", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "검출 및 추적 통합 시스템에 있어서,다중 센서를 이용한 센서 데이터로부터 획득된 각각의 특징 지도에 대하여 생성된 융합 특징 지도를 물체 검출및 추적 통합 모델을 이용하여 물체 검출의 결과를 추출하는 물체 검출부; 및 상기 물체 검출에서 사용된 특징 지도를 이용하여 획득된 각 물체의 특징 지도를 그래프 뉴럴 네트워크(GNN)를통해 유사도에 따라 공유되는 물체들을 연결하여 물체를 추적하는 물체 추적부 공개특허 10-2023-0090007-4-를 포함하는 검출 및 추적 통합 시스템."}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다중 센서를 이용한 딥러닝 기반의 3차원 물체 검출 및 추적 통합 기술이 개시된다. 일 실시예에 따른 검출 및 추적 통합 시스템에 의해 수행되는 딥러닝 기반의 3차원 물체 검출 및 추적 통합 방법은, 다중 센서를 이용한 센 서 데이터로부터 획득된 각각의 특징 지도에 대하여 생성된 융합 특징 지도를 물체 검출 및 추적 통합 모델을 이 용하여 물체 검출의 결과를 추출하는 단계; 및 상기 물체 검출에서 사용된 특징 지도를 이용하여 획득된 각 물체 의 특징 지도를 그래프 뉴럴 네트워크(GNN)를 통해 유사도에 따라 공유되는 물체들을 연결하여 물체를 추적하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 다중 센서를 이용하여 3차원 물체를 검출 및 추적하는 기술에 관한 것이다."}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥러닝 기술은 보다 일반화된 학습 모델인 딥 뉴럴 네트워크 구조를 사용하여 방대한 양의 데이터로부터 데이터 의 표현 방법 즉, 특징값을 학습하게 된다. 이러한 경우 데이터의 표현 방법을 다양한 종류의 데이터를 통해 얻기 때문에 영상 정보의 다양한 변화와 악의적인 요소에 대해 좋은 성능을 얻을 수 있다. 영상 정보를 기반으 로 한 딥러닝 물체 검출 기법의 등장과 더불어, 라이다 센서 데이터 정보를 이용하여 물체의 위치와 더불어 센 서와의 거리까지 예측할 수 있는 3D 검출 기법이 많이 제안되었다. 3D 검출 기법으로는 라이다 센서만을 이용 한 단일 센서를 이용하는 딥러닝 기반의 물체 검출 기법과 카메라 정보 등의 라이다 센서 데이터외의 다중 센서 정보를 이용하여 3D 물체 검출을 수행하는 기법이 있다. 물체 추적 기술은 크게 두 가지로 나눌 수 있다. 첫 번째는 Intersection over Union(IoU) 기반의 물체 추적 기술로 이전에 물체 검출 알고리즘에서 얻은 박스와 현재 물체 검출 알고리즘에서 얻은 박스 사이의 겹치는 정 도를 IoU로 계산하고 물체들을 연결시켜 ID를 부여하는 방식이다. 두 번째는 특징값 기반의 물체 추적 기술이 있다. 이전에 물체 검출 알고리즘에서 얻은 박스의 위치를 센서 데이터에서 크롭(crop)하고 현재 물체 검출 알 고리즘에서 얻은 박스의 위치를 센서 데이터에서 크롭한다. 이렇게 얻은 입력 데이터들을 CNN에 통과시켜 특징 값을 추출한다. 이전 입력에서 얻은 특징값과 현재 입력에서 얻은 특징값 사이의 유사도를 계산하여 연결 시켜 준다. 자율주행 인지 시스템에서는 물체 검출 기술이 적용되고 그 결과를 이용하여 물체 추적 기술이 적용된다. 이러 한 물체 검출 기술 및 물체 추적 기술을 포함하는 두 기술은 독립적인 네트워크로 물체 추적 기술에서 사용하는 정보가 물체 검출에서는 사용되지 않고 물체 검출에서 사용되는 특징값 등의 정보가 물체 추적에서 사용되지 않 는다. 이에, 인지 시스템에서 두 네트워크를 독립적으로 최적화 시키고 서로의 정보를 공유하지 않는다는 문제 점이 존재한다. 이를 공유하기 위해서는 물체 검출에서 사용된 특징값과 같은 정보를 사용하여 물체 추적을 수 행해야 하고, 물체 추적에서 사용되던 비디오 정보를 물체 검출에서 사용해야 한다."}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "다중 센서를 이용한 딥러닝 기반의 3차원 물체 검출 및 물체 추적을 통합하는 방법 및 시스템을 제공할 수 있다. 물체 검출에서 중간에 획득된 특징 지도를 사용하여, 물체 추적을 위한 추가적인 네트워크 없이 물체 검출과 물 체 추적을 동시에 최적화 하여 물체 검출 및 추적을 수행하는 방법 및 시스템을 제공할 수 있다."}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "검출 및 추적 통합 시스템에 의해 수행되는 딥러닝 기반의 3차원 물체 검출 및 추적 통합 방법은, 다중 센서를 이용한 센서 데이터로부터 획득된 각각의 특징 지도에 대하여 생성된 융합 특징 지도를 물체 검출 및 추적 통합 모델을 이용하여 물체 검출의 결과를 추출하는 단계; 및 상기 물체 검출에서 사용된 특징 지도를 이용하여 획득 된 각 물체의 특징 지도를 그래프 뉴럴 네트워크(GNN)를 통해 유사도에 따라 공유되는 물체들을 연결하여 물체 를 추적하는 단계를 포함할 수 있다. 상기 탐지 물체 검출 및 추적 통합 모델은, 물체 검출을 수행할 때 물체 추적 정보를 사용하고 물체 추적을 수 행할 때 물체 검출 정보를 사용하도록 구성된 것일 수 있다. 상기 탐지 물체 검출 및 추적 통합 모델은, 상기 물체 검출을 수행할 때 각 물체의 특징 지도를 융합 네트워크 를 통해 시공간적으로 융합하고 상기 물체 추적에서 획득된 추적 결과를 이용하여 물체가 검출되도록 학습된 것 일 수 있다. 상기 물체 검출 및 추적 통합 모델은, 카메라와 센서 데이터(LiDAR)를 입력으로 하는 딥뉴럴 네트워크에서 물체 가 있는 지역 정보를 획득하기 위한 네트워크와 상기 물체가 있는 지역 정보를 포함하는 두 프레임 간의 정보에 상호 연관성을 부여하기 위한 네트워크를 포함하는 융합 네트워크가 구성된 것일 수 있다. 상기 물체 검출의 결과를 추출하는 단계는, 다중 센서 데이터를 딥뉴럴 네트워크를 이용하여 각각의 특징 지도 를 획득하고, 상기 획득된 각각의 특징 지도에 시공간적 융합과 센서 융합 기술을 통해 융합 특징 지도를 생성 하는 단계를 포함할 수 있다. 상기 물체 검출의 결과를 추출하는 단계는, 현재 시점을 기준으로 이전의 특징 지도와 현재 시점의 특징 지도 사이의 가중치 지도를 CNN을 통해 생성하고, 상기 생성된 가중치 지도를 각각의 특징 지도에 곱함에 따라 생성 된 각각의 특징 결과를 더해주어 시공간 융합 특징 지도를 생성하는 단계를 포함할 수 있다. 상기 물체 검출의 결과를 추출하는 단계는, 상기 생성된 시공간 융합 특징 지도에 센서 융합 기술을 적용하여 센서 융합 특징 지도를 추출하는 단계를 포함할 수 있다. 상기 물체 검출의 결과를 추출하는 단계는, 현재 시점을 기준으로 이전 시간까지 축적된 물체 추적의 결과를 이 용하여 시간 데이터 기반의 물체 검출의 결과를 추출하는 단계를 포함할 수 있다. 상기 물체 검출의 결과를 추출하는 단계는, 상기 물체 추적의 결과와 현재 앵커 박스 사이의 IoU(Intersection over Union)을 계산하여 물체 후보군을 획득하고, 상기 획득된 물체 후보군을 상기 물체 추적의 결과와의 IoU를 계산하여 물체 검출의 결과를 정제하는 단계를 포함할 수 있다. 상기 물체를 추적하는 단계는, 시공간 그래프 뉴럴 네트워크를 통해 시공간적으로 유사도가 높은 각 물체의 특 징 지도끼리 정보를 공유하고, 상기 공유되는 각 물체의 특징 지도에 대하여 시간 축으로 계산된 유사도에 따라 물체들을 연결시키는 단계를 포함할 수 있다. 3차원 물체 검출 및 추적 통합 방법을 상기 검출 및 추적 통합 시스템에 실행시키기 위해 비-일시적인 컴퓨터 판독가능한 기록 매체에 저장되는 컴퓨터 프로그램을 포함할 수 있다. 검출 및 추적 통합 시스템은, 다중 센서를 이용한 센서 데이터로부터 획득된 각각의 특징 지도에 대하여 생성된 융합 특징 지도를 물체 검출 및 추적 통합 모델을 이용하여 물체 검출의 결과를 추출하는 물체 검출부; 및 상기 물체 검출에서 사용된 특징 지도를 이용하여 획득된 각 물체의 특징 지도를 그래프 뉴럴 네트워크(GNN)를 통해 유사도에 따라 공유되는 물체들을 연결하여 물체를 추적하는 물체 추적부를 포함할 수 있다."}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "딥러닝 기법을 이용한 물체 검출 수행 시 지역 정보와 시간 정보를 함께 이용하여 검출 성능을 향상시킬 수 있 다. 카메라 센서 데이터를 입력으로 하는 딥뉴럴 네트워크에서 물체가 있는 지역 정보를 얻기 위한 네트워크와 두 프레임간의 정보에 상호 연관성을 주기 위한 융합 네트워크가 구성되어 두 정보를 효율적으로 융합하여 물체의 시간에 따른 변화에 대한 정보를 이해하여 효율적인 물체 검출을 수행할 수 있다."}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 실시예를 첨부한 도면을 참조하여 상세히 설명한다. 실시예에서는 다중 센서를 이용한 딥러닝 기반의 3차원 물체 검출 및 추적 통합 기술을 통해 자율주행 환경에서 의 효율적인 인지 기술을 제안하기로 한다. 기존의 자율주행 환경에서의 인지 기술은 물체 검출과 추적을 독립 적으로 사용하여, 딥러닝 네트워크의 학습이 따로 수행되어 각각의 성능에 한계가 존재하였다. 이에 따라 두 네트워크를 하나의 시스템으로 통합하고 동시에 학습시켜 물체 검출 시에는 물체 추적 정보를 사용하고 물체 추 적 시에는 물체 검출 정보를 사용하는, 서로 상호 보완하는 동작에 대하여 설명하기로 한다. 추가적으로 물체 검출을 수행할 때 시간 정보를 활용하기 위하여 시공간적으로 특징 지도를 융합하는 동작에 대해서도 설명하기 로 한다. 도 1은 일 실시예에 있어서, 물체 검출 및 추적 통합 모델을 설명하기 위한 도면이다. 검출 및 추적 통합 시스템은 하나 이상의 카메라, 라이다 등의 다중 센서 신호를 딥뉴럴 네트워크를 이용하여 특징 지도를 획득하고, 획득된 특징 지도를 시공간적 융합과 센서 융합 기술을 통해 3차원 물체 검출을 위한 보 다 강화된 특징 지도를 추출할 수 있다. 추가적으로, 현재 시점을 기준으로 이전 시간까지의 물체 추적 결과를 물체 검출에 함께 이용하여 이전 시간까지의 정보를 보다 적극적으로 활용할 수 있다. 또한, 물체 추적을 수행 하기 위해서 기존에 물체 검출 결과만을 사용하여 물체 추적을 사용했던 것과 달리, 실시예에 따른 검출 및 추 적 통합 시스템은 물체 검출 중간에 획득한 특징 지도를 사용한다. 이는 물체 추적을 위한 추가적인 네트워크 없이 물체 검출과 물체 추적을 동시에 최적화 하여 보다 정확한 물체 검출 및 추적을 수행할 수 있다. 제안하 는 기술의 핵심은 이전 시간의 정보를 기존 방식보다 더 적극적으로 활용하고 두 인지 기술을 동시에 최적화하 여 전체적인 인지 성능을 향상시킨다는 점이다. 도 1은 다중 센서 데이터를 입력으로 사용하는 물체 검출 및 추적 통합 모델을 나타낸 것이다. 실시예에서는 카메라와 라이더 센서를 이용하여 물체 검출 및 물체 추적을 수행하는 것을 예를 들어 설명하기로 한다. 카메 라, 라이더 센서 이외에도 레이더 센서 등 다양한 센서가 적용될 수 있다. 물체 검출 및 추적 통합 모델에서는 각 센서(카메라, 라이더)로부터 들어온 입력 데이터를 전처리한 후, 컨볼루 셔널 뉴럴 네트워크(CNN) 구조를 이용하여 각각의 (센서) 특징 지도를 추출할 수 있다. 추출된 각각의 특징 지 도는 도 4와 같이 각각 시공간적으로 융합될 수 있다. 이러한 융합을 통해 시공간 융합 특징 지도가 생성될 수 있다. 도 4를 참고하면, 시공간적 특징 지도 융합 동작을 설명하기 위한 도면이다. 현재 시점을 기준으로 이 전(t-1)의 특징 지도와 현재(t)의 특징 지도 사이의 가중치 지도를 CNN을 통해 획득하고, 획득된 가중치 지도를 각각의 특징 지도에 곱해주어 생성된 두 특징 결과를 더하는 연산을 통해 시공간 융합 특징 지도가 생성될 수 있다. 이는 현재의 특징 지도를 이전의 특징 지도를 통해 더욱 강화된 특징 지도로 만들어주어 3차원 물체 검 출을 더욱 정교하게 만들어주는 장점이 있다. 도 2는 일 실시예에 있어서, 물체 검출 및 추적 통합 모델의 구조를 설명하기 위한 도면이다. 물체 검출 및 추적 통합 모델은 물체 검출 동작과 물체 추적 동작이 수행되도록 구성된 것일 수 있다. 물체 검출 및 추적 통합 모델은 물체 검출을 수행할 때 물체 추적 정보를 사용하고 물체 추적을 수행할 때 물체 검출 정보를 사용하도록 구성된 것일 수 있다. 물체 검출 및 추적 통합 모델은 물체 검출을 수행할 때 각 물체의 특징 정보를 융합 네트워크를 통해 시공간적으로 융합하고 물체 추적에서 획득된 추적 결과를 이용하 여 물체가 검출되도록 학습된 것일 수 있다. 물체 검출 및 추적 통합 모델은 카메라와 센서 데이터(LiDAR)를 입력으로 하는 딥뉴럴 네트워크에서 물체가 있는 지역 정보를 획득하기 위한 네트워크와 물체가 있는 지역 정보 를 포함하는 두 프레임 간의 정보에 상호 연관성을 부여하기 위한 네트워크를 포함하는 융합 네트워크가 구성된것일 수 있다. 이에, 물체 검출 및 추적 통합 모델에 대하여 보다 상세하게 설명하기로 한다. 카메라의 이미지 정보(RGB 이미지)와 라이더의 센서 데이터(포인트 클라우드)가 물체 검출 및 추적 통합 모델에 입력 데이터로 입력됨에 따라 각각의 특징 지도가 추출될 수 있다. 카메라의 특징 지도와 라이더의 특징 지도는 SFANet을 통해 수집될 수 있다. Trk-RPN(Tracklet-aware Region Proposal Network) 및 Trk-RefNet(Tracklet-aware Refinement Network는 물체 추적의 결과를 사용하여 검 출 결과 출력을 재구성할 수 있다. 물체 검출에 의해 생성된 정렬된 ROI 특징을 사용하여 물체는 SG-GNN을 사용하여 연결될 수 있다. SG-GNN은 물체 연관성을 위해 물체 간의 시공간 관계를 활용한다. SG-GNN의 출력을 기반으로 선호도 행렬이 계산될 수 있다. 물체 검출 및 추적 통합 모델의 네트워크는 종단 간 학습이 가능하다. 실시예에서는 2단계 검출 모델인 3D-CVF을 3차원 물체 검출 동작에 채택하기로 한다. 3D-CVF은 카메라 뷰 2차원 특징과 조감도(BEV; bird's eye view) 라이더 특징을 모두 생성할 수 있다. 시공간 특징을 생성하기 위 해 3D-CVF가 수정될 수 있다. 공유 CNN 백본 네트워크를 통해 카메라 이미지( ) 정보로부터 카메 라의 특징 지도( )가 추출될 수 있다. 카메라의 특징 지도( )를 3차원 CNN이 뒤따르는 복셀화 프로세스에 획득된 조감도 특징이라고 한다. SFANet는 두 개의 연결된 특징 지도( )와 ( )를 수집하여 시공간 특징 지 도( )를 생성할 수 있다. 이러한 두 특징 지도는 시간적으로 상관 관계가 있지만 정확 하게 일치하지 않기 때문에 최종 작업과의 연관성에 따라 다른 비율로 결합되어야 한다. SFANet은 두 개의 인접한 시간 단계에서 획득된 두 개의 공간적 특징 지도를 선택적으로 결합할 수 있다. 동일 한 크기의 CХXХY 크기의 두 개의 특징 지도 및 가 있다고 가정하기로 한다. SFANet은 및 의 가중치 수집을 다음과 같이 적용할 수 있다. 수학식 1:"}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 는 픽셀 단위 곱셈을 나타내고, 어텐션 지도 와 는 1ХX ХY크기를 갖는다. 어텐션 지 도 와 는 다음과 같이 계산될 수 있다. 수학식 2:"}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 3:"}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 는 로지스틱-시그모이드 함수이고, 는 3x3 커널이 있는 컨볼루션 레이어이고, 연 산 은 연결을 나타낸다.이를 위하여, 학습 가능한 가중치 지도 와 를 곱함으로써 특징 지도 ( )와 ( )의 기여도를 적응적으로 조정하는 게이트 어텐션 메커니즘을 사용하기로 한다. 3D-CVF의 절차에 따라 특징 융합 네트워크를 통해 카메라 특징 지도( )와 라이더 특징 지도( )를 로 융합할 수 있다. 시간 경과에 따라 여러 센서 모달리티에 걸쳐 수집된 센서 융합 특징 지도( )를 기반으로 RPN은 물체 박스 와 각 앵커 박스에 대한 객체 점수를 예측할 수 있다. 그런 다음, 정제 과정에서 박스의 좌표를 수정하고 분류 점수를 계산할 수 있다. 트랙렛(추적 결과)에서 획득된 정보를 활용하여 RPN 및 정제 과정을 향상시킬 수 있다. Trk-RPN(racklet-aware RPN)은 BEV 도메인에서 각 앵커와 가장 가까운 트랙렛 사이의 IOU를 기반으로 객체 점수 를 보정할 수 있다. 트랙렛에서 묵시되는 물체는 주변에서 물체가 검출된 가능성을 높이는 것으로 가정되며, 이는 추적기 동작에서 검출 작업을 지원함을 의미한다. Trk-RefNet(tracklet-aware refinement network)는 어텐션 기반의 코사인 유사도를 기반으로 시간 t 및 t-1에 서 인스턴스 수준의 특징 지도를 수집하고, 앵커와 가장 가까운 트랙렛 사이의 IOU를 기반으로 분류 점수를 조 정할 수 있다. Trk-RPN 및 Trk-RefNet를 통해 3차원 객체가 검출될 수 있다. 물체 검출 과정을 통해 획득된 시공간 특징 지도를 기반으로 검출 결과( )를 트랙렛( )과 연결 할 수 있다. 검출 결과( )에서 검출된 물체에 대한 3D 박스는 EDV 도메인에 투영되어 2D 박스를 생성할 수 있다. 2D ROI 풀링은 i번째 물체에 대하여 수행되어 카메라 특징 지도( )와 라이더 특징 지도 ( )로부터 정렬된 ROI 특징 과 을 각각 추출할 수 있다. 실시예에서는 물체 추적 동작에서 3D-ROI 정렬 방법을 통해 포인트-인코디드 특징( )을 풀링할 수 있 다. = , , 와 같이 특징들이 연결될 수 있다. 유사하게, 유사한 특징 풀 링 절차가 트랙렛 의 i번째 물체에 적용될 수 있다. 두 개의 특징 그룹 와 는 물체 연관성을 위해 사용되는 구별되는 특징을 제공한다. 두 개의 특징 그룹 와 는 SG-GNN에 입력될 수 있다. 이러한 특징들은 그래프에서 노드로 표시될 수 있다. SG-GNN의 역할은 와 를 일치시켜 검출 결과( )에 있는 물체를 의 물체와 연결하는 것이다. 이러한 조밀한 연결은 노드 간의 불필요한 특징 교환으로 이어질 수 있으므로 SG-GNN을 개선하기 위해 규 칙 기반 푸루닝 및 어텐션 기반 엣지 게이팅을 고안하기로 한다. 마지막으로, SG-GNN은 검출 결과( ) 의 노드와 트랙렛( )를 연결하는 모든 엣지에 대한 쌍별 유사도 점수를 기반으로 선호도 행렬을 생성할 수있다. 선호도 행렬은 헝가리 알고리즘에 의해 처리되어 최종 트랙렛( )을 출력할 수 있다. 3차원 객체(물체)가 추적될 수 있다. 입력 시퀀스가 완료될 때까지 전체 프로세스가 반복될 수 있다. 도 3은 일 실시예에 있어서, 물체 검출을 위한 네트워크 구조를 설명하기 위한 도면이다. 트랙렛(추적 결과)를 이용한 3차원 물체 검출을 위한 네트워크에 대하여 설명하기로 한다. 도 3(a)는 Trk- RPN(Tracklet-aware Region Proposal Network), 도 3(b)는 Trk-RefNet(Tracklet-aware Refinement Network)를 나타낸 것이다. Trk-RPN과 TrkRefNet은 모두 트랙렛( )을 활용하여 검출 성능을 향상시킨다. Trk-RPN은 SFANet로부터 획득한 융합 특징 지도 를 기반으로 P 영역 제안 을 생성할 수 있다. 각 앵커에 대해, 1×1 컨볼루션을 통해 초기 객체 점수(objectness score)와 3D 박스 좌표를 예측할 수 있다. 이때, 객체 점수는 물체를 포함하고 있을 가능성을 점수화한 것이다. 객체 점수는 BEV 도메인의 트 랙렛( ) 박스와 앵커 박스 사이의 IOU를 사용하여 보정될 수 있다. 각 앵커에 대해 IoU는 모든 트랙렛 박스 중에서 가장 높은 IoU로 획득될 수 있다. 앵커가 트랙렛 박스와 중첩되지 않으면 IoU가 0으로 설정될 수 있다. 입력 특징, 초기 객체 점수 및 IoU가 연결되고 추가 피드포워드 신경망을 통해 전달하여 조정된 객체 점 수가 출력될 수 있다. IoU가 높을수록 앵커가 긍정적일 가능성이 더 높기 때문에 IoU가 높을수록 앵커의 객체 점수가 증가할 것으로 예상된다. Trk-RefNet은 Trk-RPN에서 탐색된 모든 지역 제안에 대한 3D 박스 예측 및 분류 점수를 개선할 수 있다. j번째 영역 제안 를 기반으로 정렬된 ROI 특징 및 는 및 에 서 풀링될 수 있다. 또한, ROI 정렬을 적용하여 포인트 인코딩된 특징 지도 가 추출될 수 있다. 이러 한 특징 지도는 = 로 연결될 수 있다. SFANet은 정렬없이 특징 지도를 결합 하는 반면, Trk-RefNet은 특징 수집을 수행하기 전에 물체 특징을 공간적으로 정렬한다. 를 앵커로 취급 하여, Trk-RPN은 을 기반으로 (t-1) 번째 시간 단계에 대한 3D 경계 박스를 예측한다. 그럼 다음 (t- 1)번째 시간 단계에 대하여 연결된 특징은 과 같이 획득될 수 있다. 마지막으로 인스턴스 수준의 특징 지도 와 는 다음과 같이 수집될 수 있다. 수학식 4:"}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "는 다음과 같이 정의된 코사인 유사도를 나타낸다. 수학식 5:"}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, 는 전역 풀링 연산을 나타내고, 는 내적 연산을 나타낸다. 코사인 유사도를 두 검출 결과 사이의 상관 관계를 측정하고, (t-1) 시간 단계에서 특징에 적용되는 가중치를 조정하는데 사용될 수 있다. Trk-RefNet은 영역 제안과 가장 가까운 트랙렛 박스 사이의 IoU와 연결된 초기 분류 점수에 완전 연결 계층을 적용하여 분류 점수를 보정할 수 있다. 도 2에 도시된 시공간 게이트 GNN(Spatio-Temporal Gated Graph Neural Network)에 대하여 보다 상세하게 설명하기로 한다. 시공간 그래프 모델은 검출 결과( )와 트랙렛( )에 있는 물체 간의 관계를 모델링한다. 검출 결과 ( )와 트랙렛( )에 있는 3D 박스에 따르면, 정렬된 ROI 특징 와 을 획득하기 위하여 ROI 풀링이 수행될 수 있다. 이러한 정렬된 RoI 특징은 노드로 표시되고 명시적인 쌍별 관계는 엣지로 인코딩될 수 있다. 실시예에서는 (t- 1)번째 시간 단계에서 노드 내의 노드와 t번째 시간 단계에서 노드 내의 노드를 추가로 연결하는 시공간 그래프 를 고려하기로 한다. 이는 물체 사이의 공간적 관계를 포착한 것이다. 완전 연결 그래프는 물체들 간의 공간 적 관계를 이해하면 물체를 시간적으로 더욱 잘 연결시키는데 도움이 된다는 아이디어에 착안된 것이다. 그러 나 그래프의 조밀한 연결로 인해 GNN은 기능의 불필요한 교환을 요구할 수 있으므로 더 높은 수렴 속도를 초래 할 수 있다. 이러한 문제를 해결하기 위해 SG-GNN에 규칙 기반 엣지 프루닝과 어텐션 기반 엣지 게이팅을 적용 하기로 한다. 규칙 기반 엣지 프루닝은 물체 간의 공간적 거리를 기반으로 그래프에서 불필요한 엣지를 제거한다. 이때, 두 가지 유형의 규칙이 적용될 수 있다. 먼저, BEV 도메인에서 물체 중심 간의 유클리드 거리가 임계값 Ls 미터보 다 큰 경우 t 번째 시간 단계에서 노드를 연결하는 엣지를 제거할 수 있다. 마찬가지로, (t-1)번째 시간 단계 에서 노드를 연결하는 엣지는 동일한 조건에 따라 제거될 수 있다. 이는 SG-GNN이 주변 물체 간의 공간적 관계 에만 관심을 가짐을 의미한다. 둘째, 물체 간의 유클리드 거리가 Lt 미터보다 크면 t 번째 시간 단계와 (t - 1) 번째 시간 단계 사이의 노드를 연결하는 엣지가 제거될 수 있다. 서로 멀리 떨어져 있는 물체가 연결될 가 능성이 적다는 사실에 의해 정당화된다. 이러한 프루닝 규칙은 노드 연결을 단순화하기 때문에 적은 수의 반복 이 수행될 수 있다. 어텐션 메커니즘을 통해 영향력 있는 엣지에만 어텐션 기반 엣지 게이팅이 적용될 수 있다. 어텐션 기반 엣지 게이잉은 양쪽 끝의 노드와 관련된 두 특징의 유사성을 기반으로 엣지 가중치를 적응적으로 조정한다. N개의 소스 노드( )와 단일 타겟 노드( )를 고려하기로 한다. GNN의 중간 반복에서 소스 노드 및 단일 타겟 노드 의 각각에 특징( 및 )이 존 재한다. 어텐션 가중치 는 노드 특징 수집 중에 에서 로 방향성 엣지 에 적 용될 수 있다. 구체적으로, 단일 타겟 노드 에서 특징 이 수집될 때, 터텐션 가중치 에 특징 을 곱할 수 있다. 주의 가중치 는 다음과 같이 계산될 수 있다. 수학식 6:"}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 7:"}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서, 는 내적을 나타내고, w는 학습 가능한 매개변수를 나타낸다. 어텐션 가중치는 두 특징이 잘 정렬되 지 않은 엣지의 영향을 줄일 수 있다. 이를 통해 SG-GNN은 중요한 특징의 연결에만 집중하게 된다. 고정된 반복 후에, SG-GNN은 노드에서 특징 와"}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "이 출력될 수 있다. 검출 결과( )의 트랙렛( )의 물체 사이이 유사도 점수를 기반으로 선호도 행렬 A가 구성될 수 있다. 선호도 행렬 A의 (i, j)번째 요소는 와 사이의 유사도 점수 에 의 해 제공될 수 있다. 유사도 점수는 다음과 같이 계산될 수 있다. 수학식 8:"}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "여기서, fc는 깊이가 3인 완전 연결 계층을 나타낸다. 유사도 점수는 0과 1 사이의 값을 가지며, 선호도 행렬 A는 최종 트랙릿 를 결정하기 위해 헝가리 알고리즘에 의해 제공될 수 있다. 본 발명에서 제안한 각각의 모듈의 효과를 실험을 통해 입증한 결과를 설명하기로 한다. 실험은 KITTI 물체 추 적 데이터셋을 활용하였으며, 일례로 3D-CVF에 적용하여 실험을 진행하여 표 1에 나타내었다. 표 1:"}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "물체 검출 정확도는 KITTI에서 제공하는 AP(Average Precision)으로 계산되었다. 물체 검출의 어려움 정도를 가려진 정도와 센서와의 거리를 통해 Easy, Moderate, Hard로 나누어 계산될 수 있다. 물체 추적 정확도는 sAMOTA라는 방식이 사용될 수 있다. 방법 에서의 결과는 그래프 뉴럴 네트워크를 이용하였을 때의 결과로 물체 추적 결과를 사용하지 않은 물체 검출 성능은 향상하지 않았지만 물체 추적 성능이 2.82% 올랐다. 방법 는 방법 에서 얻은 물체 추적 결과를 물체 후보군을 추출할 때만 사용하여 물체 검출 결과를 얻었다. Easy에서의 결과가 비약적으로 상승한 것을 확인할 수 있으며, Moderate과 Hard에서도 성능이 올라간 것을 확인 할 수 있다. 또한 물체 추적 성능도 소폭 상승한 것을 통해 동시에 최적화가 잘된 것을 확인할 수 있다. 방법 은 방법 에 최종 물체 검출을 수행 할 때도 물체 추적 결과를 이용하였고, 이 또한 물체 검출 성능과 추적 성능이 모두 향산된 것을 확인할 수 있다. 최종적으로 제안하는 발명인 방법 는 시공간 특징 지도 융합 을 통해 다른 방법들보다 물체 검출 성능과 물체 추적 성능이 모두 향상된 것을 확인할 수 있다. 본 발명을 통 해 시공간적으로 특징 지도를 융합하고 물체 추적에서 얻은 결과를 물체 검출에 사용하여 시간 정보를 적극적으 로 활용함으로써 물체 검출 성능을 향상 시켰으며, 물체 추적 성능 또한 향상시켜 동시에 최적화가 잘 이루어진 것을 실험을 통해 확인할 수 있다. 또한 물체 추적을 사용할 때 시공간적인 유사도를 활용하여 정보를 공유하 는 방식을 사용하면 물체를 시간적으로 연결시킬 때 더 정교하게 연결시켜 물체 추적 성능을 향상시키는데 도움 을 주는 것을 실험을 통해 확인할 수 있다. 실시예에 따르면, 최근 스마트 홈 환경에나 자율 주행 환경에서는 카메라 센서 데이터를 이용하여 물체 검출을 수행할 때 물체 검출과 동시에 시간 정보를 이해하는 데에 활용될 것으로 예상이 된다. 제안하는 방법은 이러 한 물체와 그 물체의 시간 정보에 대한 이해를 효과적으로 수행할 수 있는 해결책을 제시한다. 또한 스마트 폰 이나 자율주행뿐만 아니라 환경이나 물체를 인식하는 다양한 인공지능 기술에 적용이 가능하다. 도 5는 일 실시예에 있어서, 이전 물체 추적 기술을 이용한 물체 검출 결과를 생성하는 동작을 설명하기 위한 도면이다. 다중 센서를 이용한 센서 데이터 각각을 이용하여 생성된 시공간 융합 특징 지도는 센서 융합 기술을 적용하여 센서 융합 특징 지도가 추출될 수 있다. 센서 융합 특징 지도는 도면 5와 같이 현재(t)를 기준으로 이전 (t- 1)까지 획득된 물체 추적 결과(tracklet)을 이용하여 보다 적극적으로 시간 정보를 사용한 물체 검출 결과를 추 출한다. 두 단계로 구성되어 있으며, 첫 번째로 물체 추적 결과와 현재 앵커 박스 사이의 IoU (Intersection over Union)을 계산하여 점수를 계산하는 데에 도움을 주어 더욱 정교한 물체 후보군을 획득할 수 있다. 이는 현재 검출해야 되는 물체 중에 가려졌거나 거리가 멀어져서 검출이 힘들어진 물체의 검출 성능을 향상시키는데 도움을 줄 수 있다. 획득된 물체 후보군은 물체 추적 결과와의 IoU를 계산하여 물체 검출 결과를 정제해주는데 사용될 수 있다. 최종 물체 검출 결과를 더욱 정교하게 만들어주며 잘못 잡은 물체 정보에 대해서 한 번 더 정 제해주는 효과를 가진다. 도 6은 일 실시예에 따른 물체 검출 및 추적 통합 시스템의 구성을 설명하기 위한 블록도이고, 도 7은 일 실시 예에 따른 물체 검출 및 추적 통합 시스템에서 딥러닝 기반의 3차원 물체 검출 및 추적 통합 방법을 설명하기 위한 흐름도이다. 물체 검출 및 추적 통합 시스템의 프로세서는 물체 검출부 및 물체 추적부를 포함할 수 있다. 이러한 프로세서의 구성요소들은 물체 검출 및 추적 통합 시스템에 저장된 프로그램 코드가 제공하는 제어 명령 에 따라 프로세서에 의해 수행되는 서로 다른 기능들(different functions)의 표현들일 수 있다. 프로세서 및 프로세서의 구성요소들은 도 7의 딥러닝 기반의 3차원 물체 검출 및 추적 통합 방법이 포함하는 단계들(710 내 지 720)을 수행하도록 물체 검출 및 추적 통합 시스템을 제어할 수 있다. 이때, 프로세서 및 프로세서의 구성 요소들은 메모리가 포함하는 운영체제의 코드와 적어도 하나의 프로그램의 코드에 따른 명령(instruction)을 실 행하도록 구현될 수 있다. 프로세서는 딥러닝 기반의 3차원 물체 검출 및 추적 통합 방법을 위한 프로그램의 파일에 저장된 프로그램 코드 를 메모리에 로딩할 수 있다. 예를 들면, 물체 검출 및 추적 통합 시스템에서 프로그램이 실행되면, 프로세서 는 운영체제의 제어에 따라 프로그램의 파일로부터 프로그램 코드를 메모리에 로딩하도록 물체 검출 및 추적 통 합 시스템을 제어할 수 있다. 이때, 프로세서는 물체 검출부 및 물체 추적부 각각은 메모리에 로딩 된 프로그램 코드 중 대응하는 부분의 명령을 실행하여 이후 단계들(710 내지 720)을 실행하기 위한 프로세서의 서로 다른 기능적 표현들일 수 있다. 단계에서 물체 검출부는 다중 센서를 이용한 센서 데이터로부터 획득된 각각의 특징 지도에 대하여 생성된 융합 특징 지도를 물체 검출 및 추적 통합 모델을 이용하여 물체 검출의 결과를 추출할 수 있다. 물체 검출부는 다중 센서 데이터를 딥뉴럴 네트워크를 이용하여 각각의 특징 지도를 획득하고, 획득된 각각의 특징 지도에 시공간적 융합과 센서 융합 기술을 통해 융합 특징 지도를 생성할 수 있다. 물체 검출부는 현재 시점을 기준으로 이전(t-1)의 특징 지도와 현재(t) 시점의 특징 지도 사이의 가중치 지도를 CNN을 통해 생 성하고, 생성된 가중치 지도를 각각의 특징 지도에 곱함에 따라 생성된 각각의 특징 결과를 더해주어 시공간 융 합 특징 지도를 생성할 수 있다. 물체 검출부는 생성된 시공간 융합 특징 지도에 센서 융합 기술을 적용 하여 센서 융합 특징 지도를 추출할 수 있다. 물체 검출부는 현재 시점을 기준으로 이전 시간까지 축적된 물체 추적의 결과를 이용하여 시간 데이터 기반의 물체 검출의 결과를 추출할 수 있다. 물체 검출부는 물 체 추적의 결과와 현재 앵커 박스 사이의 IoU(Intersection over Union)을 계산하여 물체 후보군을 획득하고,획득된 물체 후보군을 상기 물체 추적의 결과와의 IoU를 계산하여 물체 검출의 결과를 정제할 수 있다. 단계에서 물체 추적부는 물체 검출에서 사용된 특징 지도를 이용하여 획득된 각 물체의 특징 지도를 그래프 뉴럴 네트워크(GNN)를 통해 유사도에 따라 공유되는 물체들을 연결하여 물체를 추적할 수 있다. 물체 추적부는 그래프 뉴럴 네트워크를 통해 시공간적으로 유사도가 높은 각 물체의 특징 지도끼리 정보를 공유 하고, 공유되는 각 물체의 특징 지도에 대하여 시간 축으로 계산된 유사도에 따라 물체들을 연결시킬 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2021-0178871", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2021-0178871", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 있어서, 물체 검출 및 추적 통합 모델을 설명하기 위한 도면이다. 도 2는 일 실시예에 있어서, 물체 검출 및 추적 통합 모델의 구조를 설명하기 위한 도면이다. 도 3은 일 실시예에 있어서, 물체 검출을 위한 네트워크 구조를 설명하기 위한 도면이다. 도 4는 일 실시예에 있어서, 시공간적 특징 지도 융합 동작을 설명하기 위한 도면이다. 도 5는 일 실시예에 있어서, 이전 물체 추적 기술을 이용한 물체 검출 결과를 생성하는 동작을 설명하기 위한 도면이다. 도 6은 일 실시예에 따른 물체 검출 및 추적 통합 시스템의 구성을 설명하기 위한 블록도이다. 도 7은 일 실시예에 따른 물체 검출 및 추적 통합 시스템에서 딥러닝 기반의 3차원 물체 검출 및 추적 통합 방 법을 설명하기 위한 흐름도이다."}
