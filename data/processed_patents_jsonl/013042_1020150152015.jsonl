{"patent_id": "10-2015-0152015", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2017-0050465", "출원번호": "10-2015-0152015", "발명의 명칭": "얼굴 인식 장치 및 방법", "출원인": "에스케이텔레콤 주식회사", "발명자": "황영규"}}
{"patent_id": "10-2015-0152015", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라로부터 입력되는 입력영상을 획득하는 입력영상 획득부;상기 입력영상에서 얼굴영역을 검출하여 얼굴포즈(Pose)를 정규화함으로써 정면포즈 영상을 생성하고, 상기 카메라와 피사체 간의 거리에 따른 원근왜곡(Perspective Distortion)을 제거하기 위하여 상기 정면포즈 영상의원근감(Perspective)을 정규화하여 정규화 영상을 생성하는 정규화부;상기 정규화 영상으로부터 상기 피사체의 얼굴을 표현하는 특징벡터(Feature Vector)를 추출하는 특징벡터 추출부; 및기 학습된 분류모델에 상기 특징벡터를 적용하여 상기 입력영상에 포함된 상기 피사체의 얼굴을 인식하는 얼굴인식부를 포함하는 얼굴 인식 장치."}
{"patent_id": "10-2015-0152015", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 정규화부는,다양한 포즈의 학습용 얼굴영상을 제1 인공신경망의 입력층에 입력하고, 정면포즈의 학습용 얼굴영상이 상기 제1 인공신경망의 출력층에서 출력되도록 상기 제1 인공신경망을 학습시키는 얼굴포즈 정규화 학습부; 및상기 제1 인공신경망의 출력층에서 출력된 데이터를 제 2 인공신경망의 입력층에 입력하고, 원근왜곡이 없는 학습용 얼굴영상이 상기 제 2 인공신경망의 출력층에서 출력되도록 상기 제2 인공신경망을 학습시키는 원근감 정규화 학습부를 포함하는 얼굴 인식 장치."}
{"patent_id": "10-2015-0152015", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 정규화부는,학습이 완료된 상기 제1 인공신경망과 상기 제2 인공신경망을 통합한 통합 인공신경망의 입력층에 다양한 원근왜곡이 있는 다양한 포즈의 학습용 얼굴영상을 입력하고, 정면포즈의 원근왜곡이 없는 학습용 얼굴영상이 상기통합 인공신경망의 출력층에서 출력되도록 상기 통합 인공신경망을 학습시키는 얼굴 인식 장치."}
{"patent_id": "10-2015-0152015", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 정규화부, 상기 특징벡터 추출부, 및 상기 얼굴 인식부가 학습하는데 이용되는 복수의 가상 얼굴영상을 생성하는 가상 얼굴영상 생성부를 더 포함하되,상기 복수의 가상 얼굴영상은,상기 가상 얼굴영상 생성부가 상기 카메라로부터 획득된 하나 이상의 2차원 기준영상을 이용하여 합성한 3차원얼굴모델을 변형시킴으로써 생성되는 얼굴 인식 장치."}
{"patent_id": "10-2015-0152015", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,공개특허 10-2017-0050465-3-상기 가상 얼굴영상 생성부는,상기 하나 이상의 2차원 기준영상으로부터 얼굴의 깊이정보를 추출하여 3차원 얼굴형상을 생성하는 3차원 얼굴형상 생성부;상기 하나 이상의 2차원 기준영상으로부터 얼굴의 텍스처정보를 추출하여 상기 3차원 얼굴형상에 매핑시킴으로써 상기 3차원 얼굴모델을 합성하는 텍스처정보 매핑부;상기 3차원 얼굴모델에 대하여 X축, Y축, 및 Z축 방향의 회전각도 및 상기 카메라와 상기 2차원 기준영상의 피사체 간의 거리 중 적어도 하나를 변형시켜 복수의 3차원 얼굴변형모델을 생성하는 3차원 얼굴모델 변형부; 및상기 복수의 3차원 얼굴변형모델을 2차원 평면에 투영시키는 2차원 투영부를 포함하는 얼굴 인식 장치."}
{"patent_id": "10-2015-0152015", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,픽셀 인텐시티(Pixel Intensity)를 조정하여 상기 2차원 기준영상으로부터 추정되는 조명 환경을 상기 3차원 얼굴모델에 반영하는 조명 조정부를 더 포함하는 얼굴 인식 장치."}
{"patent_id": "10-2015-0152015", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "카메라로부터 입력되는 입력영상을 획득하는 입력영상 획득과정;상기 입력영상에서 얼굴영역을 검출하여 얼굴포즈(Pose)를 정규화함으로써 정면포즈 영상을 생성하고, 상기 카메라와 피사체 간의 거리에 따른 원근왜곡(Perspective Distortion)을 제거하기 위하여 상기 정면포즈 영상의원근감(Perspective)을 정규화하여 정규화 영상을 생성하는 정규화과정;상기 정규화 영상으로부터 상기 피사체의 얼굴을 표현하는 특징벡터(Feature Vector)를 추출하는 특징벡터 추출과정; 및기 학습된 분류모델에 상기 특징벡터를 적용하여 상기 입력영상에 포함된 상기 피사체의 얼굴을 인식하는 얼굴인식과정을 포함하는 얼굴 인식 방법."}
{"patent_id": "10-2015-0152015", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 정규화과정은,다양한 포즈의 학습용 얼굴영상을 제1 인공신경망의 입력층에 입력하고, 정면포즈의 학습용 얼굴영상이 상기 제1 인공신경망의 출력층에서 출력되도록 상기 제1 인공신경망을 학습시키는 얼굴포즈 정규화 학습과정; 및상기 제1 인공신경망의 출력층에서 출력된 데이터를 제2 인공신경망의 입력층에 입력하고, 원근왜곡이 없는 학습용 얼굴영상이 상기 제2 인공신경망의 출력층에서 출력되도록 상기 제2 인공신경망을 학습시키는 원근감 정규화 학습과정을 포함하는 얼굴 인식 방법."}
{"patent_id": "10-2015-0152015", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 정규화과정은,학습이 완료된 상기 제1 인공신경망과 상기 제2 인공신경망을 통합한 통합 인공신경망의 입력층에 다양한 원근왜곡이 있는 다양한 포즈의 학습용 얼굴영상을 입력하고, 정면포즈의 원근왜곡이 없는 학습용 얼굴영상이 상기통합 인공신경망의 출력층에서 출력되도록 상기 통합 인공신경망을 학습시키는 얼굴 인식 방법.공개특허 10-2017-0050465-4-청구항 10 제7항에 있어서,상기 얼굴 인식 방법을 수행하는 얼굴 인식 장치의 학습에 이용되는 복수의 가상 얼굴영상을 생성하는 가상 얼굴영상 생성과정을 더 포함하되,상기 가상 얼굴영상 생성과정은,상기 카메라로부터 획득된 2차원 기준영상으로부터 얼굴의 깊이정보를 추출하여 3차원 얼굴형상을 생성하는 3차원 얼굴형상 생성과정;상기 2차원 기준영상으로부터 얼굴의 텍스처정보를 추출하여 상기 3차원 얼굴형상에 매핑시킴으로써 3차원 얼굴모델을 합성하는 텍스처정보 매핑과정;상기 3차원 얼굴모델에 대하여 X축, Y축, 및 Z축 방향의 회전각도 및 상기 카메라와 상기 2차원 기준영상의 피사체 간의 거리 중 적어도 하나를 변형시켜 복수의 3차원 얼굴변형모델을 생성하는 3차원 얼굴모델 변형과정;및상기 복수의 3차원 얼굴변형모델을 2차원 평면에 투영시키는 2차원 투영과정을 포함하는 얼굴 인식 방법."}
{"patent_id": "10-2015-0152015", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "얼굴 인식 장치 및 방법을 개시한다. 본 실시예에 의하면, 기계학습을 이용하여 입력영상으로부터 얼굴을 인식함에 있어, 얼굴포즈 및 원근감을 정규 화하여 얼굴인식률을 향상시키고, 얼굴 학습 데이터로서 가상 얼굴 영상을 자동으로 생성하여 얼굴 학습 데이터 를 획득하는데 드는 비용 및 시간을 절약할 수 있는 장치 및 방법을 제공하는데 주된 목적이 있다."}
{"patent_id": "10-2015-0152015", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 실시예는 기계학습(Machine Learning)을 이용하여 입력영상으로부터 얼굴을 인식하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2015-0152015", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 본 실시예에 대한 배경 정보를 제공할 뿐 종래기술을 구성하는 것은 아니다. 얼굴인식은 정지 영상이나 동영상에서 검출된 얼굴영상에서 특징을 추출하여 데이터베이스에 저장되어 있는 특 징 데이터와 비교하여 신분을 확인하는 기술이다. 얼굴인식 기술은 보안 분야 및 인간-기계 인터페이스(Human- Machine Interface) 분야에 특히 유용한 기술이나, 인식률 문제로 인하여 상용화되기 어려운 점이 있다. 얼굴인식의 인식률을 저하시키는 요인으로는 얼굴포즈(Pose) 변화, 카메라와 피사체와의 거리에 따른 원근감 (Perspective) 변화, 및 조명 변화 등이 있다. 이러한 변화에도 안정적이고 강인한 인식률을 확보하기 위한 방 안 중 하나로서 기계학습(Machine Learning) 기법이 이용될 수 있다. 예를 들어, 얼굴의 포즈, 원근감, 및 조명 등이 다양하게 변화된 영상을 얼굴 학습 데이터로서 학습하여 얼굴 인식을 위한 특징을 추출할 수 있다. 이 때 추출된 특징은 얼굴의 포즈, 원근감, 및 조명의 변화를 반영한 것으로서 얼굴 인식률을 향상시킬 수 있다. 다만, 높은 인식률을 확보하기 위해서는 많은 양의 얼굴 학습 데이터가 필요하므로 얼굴 학습 데이터를 획득하 는데 소요되는 시간과 비용이 크다는 문제점이 있다. 또한, 얼굴 학습 데이터를 획득하기 위하여 사용자에게 다양한 포즈의 얼굴 영상, 카메라와의 거리변화에 따른 다양한 얼굴 영상 등을 제공하도록 요구하는 것은 사용자에게 불편함을 야기할 수 있는 문제점이 있다."}
{"patent_id": "10-2015-0152015", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예들은, 기계학습을 이용하여 입력영상으로부터 얼굴을 인식함에 있어, 얼굴포즈 및 원근감을 정 규화하여 얼굴인식률을 향상시키고, 얼굴 학습 데이터로서 가상 얼굴 영상을 자동으로 생성하여 얼굴 학습 데이 터를 획득하는데 드는 비용 및 시간을 절약할 수 있는 장치 및 방법을 제공하는데 주된 목적이 있다."}
{"patent_id": "10-2015-0152015", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 의하면, 카메라로부터 입력되는 입력영상을 획득하는 입력영상 획득부, 입력영상에서 얼굴 영역을 검출하여 얼굴포즈(Pose)를 정규화함으로써 정면포즈 영상을 생성하고, 카메라와 피사체 간의 거리에 따 른 원근왜곡(Perspective Distortion)을 제거하기 위하여 정면포즈 영상의 원근감(Perspective)을 정규화하여 정규화 영상을 생성하는 정규화부, 정규화 영상으로부터 피사체의 얼굴을 표현하는 특징벡터(Feature Vector)를 추출하는 특징벡터 추출부, 및 기 학습된 분류모델에 특징벡터를 적용하여 입력영상에 포함된 피사체의 얼굴을 인식하는 얼굴 인식부를 포함하는 얼굴 인식 장치를 제공한다. 본 발명의 실시예에 의하면, 카메라로부터 입력되는 입력영상을 획득하는 입력영상 획득과정, 입력영상에서 얼 굴영역을 검출하여 얼굴포즈(Pose)를 정규화함으로써 정면포즈 영상을 생성하고, 카메라와 피사체 간의 거리에 따른 원근왜곡(Perspective Distortion)을 제거하기 위하여 정면포즈 영상의 원근감(Perspective)을 정규화하여 정규화 영상을 생성하는 정규화과정, 정규화 영상으로부터 피사체의 얼굴을 표현하는 특징벡터(Feature Vecto r)를 추출하는 특징벡터 추출과정, 및 기 학습된 분류모델에 특징벡터를 적용하여 입력영상에 포함된 피사체의 얼굴을 인식하는 얼굴 인식과정을 포함하는 얼굴 인식 방법."}
{"patent_id": "10-2015-0152015", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같이 본 발명의 실시예들에 의하면, 기계학습을 이용하여 입력영상으로부터 얼굴을 인식 함에 있어, 얼굴포즈 및 원근감을 정규화하여 얼굴인식률을 향상시키는 효과가 있다. 본 발명의 실시예에 의하면, 얼굴 학습 데이터로서 가상 얼굴영상을 자동으로 생성하여 얼굴 학습 데이터를 획 득하는데 드는 비용 및 시간을 절약할 수 있는 효과가 있다. 본 발명의 실시예에 의하면, 2차원 입력영상을 3차원 얼굴모델로 변환하여 X축, Y축, Z축에 대한 회전각을 달리 함으로써 다양한 얼굴포즈가 반영된 가상 얼굴영상을 생성할 수 있다. 또한, 카메라와 피사체 간의 거리에 변화 를 주어 다양한 원근감을 갖는 가상 얼굴영상을 생성할 수 있다. 이로써, 본 발명의 실시예에 의하면 얼굴포즈 변화 및 원근왜곡에도 안정적인 인식결과를 획득할 수 있는 효과가 있다. 본 발명의 실시예에 의하면, 2차원 입력영상을 3차원 얼굴모델로 변환하여 조명 환경을 반영함으로써, 조명 변 화에도 강인한 인식결과를 획득할 수 있는 효과가 있다."}
{"patent_id": "10-2015-0152015", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "명세서에 기재된 '…부', '모듈' 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 이하, 본 발명의 일부 실시예들을 예시적인 도면을 통해 상세하게 설명한다. 도 1은 본 발명의 실시예에 따른 얼굴인식장치의 개략적인 구성도이다. 도 1을 참조하면, 본 발명의 실시예에 따른 얼굴인식장치는 입력영상 획득부, 정규화부, 특징벡 터 추출부, 및 얼굴인식부를 포함한다. 또한, 실시예에 따라 가상 얼굴영상 생성부 및 가상 얼 굴영상 DB를 포함할 수 있다. 도 1에서는 각각의 구성요소가 별개의 장치로 존재하는 것으로 도시하였으나, 이에 한정되지 않고 각각의 기능을 모두 포함하는 하나의 통합된 장치로 구현될 수도 있다."}
{"patent_id": "10-2015-0152015", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 2, "content": "도 1에 도시된 얼굴인식장치는 본 실시예와 관련된 구성요소들만이 도시되어 있다. 따라서, 도 1에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음을 본 실시예와 관련된 기술분야에서 통상의 지 식을 가진 자라면 이해할 수 있다. 또한, 도 1에 도시된 얼굴인식장치는 하나 또는 복수 개의 프로세서를 포함할 수 있다. 프로세서는 다수의 논리 게이트들의 어레이로 구현될 수 있고, 범용적인 마이크로 프로세서와 이 마이크로 프로세서에서 실행될 수 있는 프로그램이 저장된 메모리의 조합으로 구현될 수도 있다. 또한, 다른 형태의 하드웨어로 구현될 수도 있음"}
{"patent_id": "10-2015-0152015", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "을 본 실시예가 속하는 기술분야에서 통상의 지식을 가진 자라면 이해할 수 있다. 얼굴인식장치는 영상 표시 장치, 영상 촬영 장치, 얼굴인식서버, 태블릿 PC(Tablet PC), 랩톱(Laptop), 개 인용 컴퓨터(PC: Personal Computer), 스마트폰(Smart Phone), 개인휴대용 정보단말기(PDA: Personal Digital Assistant), 이동통신 단말기(Mobile Communication Terminal), 및 지능로봇(Intelligence Robot) 등 중 어느 하나일 수 있다. 입력영상 획득부는 카메라(미도시)로부터 입력되는 입력영상을 획득한다. 여기서 카메라(미도시)는 깊이인 식 카메라, 스테레오 카메라, 및 컬러 카메라일 수 있다(예를 들어, 키넥트(Kinect) 카메라 등). 또한, 입력영 상은 인식대상이 되는 피사체의 얼굴이 포함된 영상으로서 2차원 정지영상 및 동영상을 포함한다. 입력영상은 컬러영상, 깊이영상, 및 컬러-깊이(RGB-D) 영상을 포함할 수 있다. 정규화부는 입력영상으로부터 얼굴영역을 검출하고 얼굴포즈(Pose) 및 원근감(Perspective)을 정규화하여 정규화 영상을 생성한다. 얼굴포즈에 변화가 있는 경우, 그레이 스캐일, 형상, 특징점의 위치 등이 달라지기 때 문에 얼굴인식률이 저하된다. 또한, 카메라와 피사체 간의 거리가 달라지면 동일한 피사체라 하더라도 촬영된 위치마다 원근왜곡(Perspective Distortion, 예컨대 뒤틀림)이 다르게 발생하므로, 다른 피사체를 촬영한 것처 럼 보이기도 한다. 따라서 얼굴인식률을 향상시키기 위해서는 입력영상의 얼굴포즈 및 원근감을 정규화할 필요 가 있다. 정규화부에 대한 구체적인 설명은 다른 도면을 참조하여 후술한다. 특징벡터 추출부는 정규화 영상으로부터 피사체의 얼굴을 표현하는 특징벡터(Feature Vector)를 추출한다. 특징벡터는 얼굴인식에 사용되는 특징값들을 원소로 가지는 벡터이다. 특징벡터를 추출하는데 사용되는 필터로 서 가버(Gabor) 필터, 하(Haar) 필터, LBP(Local Binary Pattern) - DLBP(Discriminative LBP), ULBP(Uniform LBP), NLBP (Number LBP) 등을 포함 - 등이 있으나, 반드시 이에 한정되는 것은 아니고 그 밖의 다른 필터가 사 용될 수 있다. 특징벡터 추출부는 기계학습(Machine Learning)을 통해 결정되며 이에 대한 구체적인 설명은 다른 도면을 참조하여 후술한다. 얼굴 인식부는 기 학습된 분류모델에 특징벡터 추출부에서 추출된 특징벡터를 적용하여 입력영상에 포함된 피사체의 얼굴을 인식한다. 여기서 기 학습된 분류모델은 서포트 벡터 머신(Support Vector Machine: SVM), 선형판별분석(Linear Discriminant Analysis: LDA), 및 소프트맥스(Softmax) 등을 포함할 수 있으나, 반 드시 이에 한정되는 것은 아니다. 가상 얼굴영상 생성부는 정규화부, 특징벡터 추출부, 및 얼굴 인식부가 학습하는데 이용되 는 복수의 가상 얼굴영상을 생성할 수 있다. 여기서, 복수의 가상 얼굴영상은 가상 얼굴영상 생성부가 카 메라(미도시)로부터 획득된 하나 이상의 2차원 기준영상을 이용하여 합성한 3차원 얼굴모델을 변형시킴으로써 생성되는 얼굴영상을 의미한다. 안정적으로 얼굴을 인식하기 위해서는 기계학습시 인식하고자 하는 얼굴의 다양한 변화가 반영된 학습영상이 필 요하다. 대규모의 학습영상을 이용할수록 얼굴인식률은 향상될 수 있다. 그러나 대규모의 학습영상을 획득하기 위해서는 많은 시간과 노력 그리고 비용이 필요하기 때문에 현실적으로는 대규모의 학습영상을 획득하기가 어렵 다. 따라서 본 실시예에서는 복수의 가상 얼굴영상을 생성하여 큰 비용 및 시간 투자없이 효율적으로 얼굴인식 장치를 학습시킨다. 이하, 도 2를 참조하여 가상 얼굴영상 생성부에 대하여 구체적으로 설명한다. 도 2는 본 발명의 실시예에 따른 가상 얼굴영상 생성부의 개략적인 구성도이다. 가상 얼굴영상 생성부는 3차원 얼굴형상 생성부, 텍스처정보 매핑부, 3차원 얼굴모델 변형부 , 및 2차원 투영부를 포함할 수 있으며 실시예에 따라, 조명 조정부를 더 포함할 수 있다. 도 2에서는 각각의 구성요소가 별개의 장치로 존재하는 것으로 도시하였으나, 이에 한정되지 않고 각각의 기능을 모 두 포함하는 하나의 통합된 장치로 구현될 수도 있다. 도 2에 도시된 가상 얼굴영상 생성부는 본 실시예와 관련된 구성요소들만이 도시되어 있다. 따라서, 도 2"}
{"patent_id": "10-2015-0152015", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음을 본 실시예와 관련된 기술분야에서 통상의 지식을 가진 자라면 이해할 수 있다. 또한, 도 2에 도시된 가상 얼굴영상 생성부는 하나 또는 복수 개의 프로세서에 해당할 수 있다. 프로세서 는 다수의 논리 게이트들의 어레이로 구현될 수 있고, 범용적인 마이크로 프로세서와 이 마이크로 프로세서에서 실행될 수 있는 프로그램이 저장된 메모리의 조합으로 구현될 수도 있다. 또한, 다른 형태의 하드웨어로 구현될"}
{"patent_id": "10-2015-0152015", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수도 있음을 본 실시예가 속하는 기술분야에서 통상의 지식을 가진 자라면 이해할 수 있다. 3차원 얼굴형상 생성부는 하나 이상의 2차원 기준영상으로부터 얼굴의 깊이정보를 추출하여 3차원 얼굴형 상을 생성할 수 있다. 여기서 2차원 기준영상은 복수의 가상 얼굴영상을 생성하기 위하여 이용되는 원본 영상을 의미한다. 예를 들어, 3차원 얼굴형상 생성부는 변형가능 얼굴모델(Morphable Model)을 정합하거나 기계 학습 기법을 이용하여 구현 가능하다. 변형가능 얼굴모델은 3D 스캐너나 깊이 카메라를 이용하여 얼굴의 3차원 형상정보와 텍스처정보를 통계적으로 학습함으로써 얼굴의 3차원 정보를 표현한다. 또 다른 예로서, 3차원 얼굴형상 생성부는 스테레오 매칭을 이용할 수 있다. 즉, 여러 시점에서 촬영된 다 시점(Multi-View) 영상으로부터 영상간 픽셀의 간격(Disparity)을 이용하여 2차원 기준영상의 깊이 정보를 추정 할 수 있다. 텍스처정보 매핑부는 하나 이상의 2차원 기준영상으로부터 얼굴의 텍스처정보를 추출하여 3차원 얼굴형상 에 매핑시킴으로써 3차원 얼굴모델을 합성할 수 있다. 구체적으로 텍스처정보 매핑부는 2차원 기준영상의 각 픽셀에 깊이정보를 매핑한다. 조명 조정부는 픽셀 인텐시티(Pixel Intensity)를 조정하여 2차원 기준영상으로부터 추정되는 조명 환경을 3차원 얼굴모델에 반영할 수 있다. 조명의 변화는 얼굴인식률을 저하시키는 가장 중요한 요소 중 하나이기 때문 에, 조명 변화에 강인한(Robust) 얼굴인식을 위해서는 다양하게 변화하는 조명 환경을 반영한 학습영상이 필요 하다. 조명 환경을 반영하기 위해 조명 조정부에서 이용할 수 있는 함수는 [수학식 1]과 같다. 수학식 1"}
{"patent_id": "10-2015-0152015", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, 은 조명에 의해 추가되는 픽셀 인텐시티, 는 빛의 원점(Point Light)의 밝기, 는 피사체의 확산반사계수(Diffuse Reflection Coefficient)로서 각 R, G, B 채널별로 0 내지 1 사이에 존재하는 값, 은 표면 법선(Surface Normal) 벡터, 은 광원 방향 벡터, 는 내적을 의미한다. 3차원 얼굴모델 변형부는 3차원 얼굴모델에 대하여 (i) X축, Y축, 및 Z축 방향의 회전각도 및 (ii) 카메라 와 2차원 기준영상의 피사체 간의 거리 중 적어도 하나를 변형시켜 복수의 3차원 얼굴변형모델을 생성할 수 있 다. X축, Y축, 및 Z축 방향에 대하여 3차원 얼굴모델을 회전시킴으로써 다양한 얼굴포즈를 반영할 수 있다. 본 실시 예에서는 회전축 방향을 달리할 뿐만 아니라 각 회전축에 대한 회전각도도 변형함으로써 더욱 다양한 얼굴포즈 영상을 생성할 수 있다. 또한, 카메라와 2차원 기준영상의 피사체 간의 거리를 변형시켜 다양한 원근감을 갖는 얼굴영상을 생성할 수 있다. 2차원 투영부는 3차원 얼굴모델 변형부에 의해 생성된 복수의 3차원 얼굴변형모델을 2차원 평면에 투 영시킬 수 있다. 이로써 2차원의 가상 얼굴영상이 생성된다. 이 때 이용될 수 있는 방법은 예를 들어, 원근투영 (Perspective Projection) 및 간략화한 원근투영(Weak Perspective Projection) 등이 있다. 가상 얼굴영상 생성부에 의해 생성된 가상 얼굴영상은 가성 얼굴영상 DB에 저장되어 얼굴인식장치 의 학습에 이용될 수 있다. 이하, 도 3 및 도 4를 참조하여 정규화부에 대하여 구체적으로 설명한다. 도 3은 본 발명의 실시예에 따른 정규화부의 개략적인 구성도이다. 도 4a 내지 도 4c는 본 발명의 실시예에 따른 정규화부를 설명하기 위한 개념도이다. 도 4a를 참조하면, 정규화부는 (i) 입력영상에서 얼굴영역을 검출하여 얼굴포즈를 정규화함으로써 정면포 즈 영상(중간결과영상)을 생성하고, (ii) 카메라(미도시)와 피사체 간의 거리에 따른 원근왜곡을 제거하기 위하 여 정면포즈 영상의 원근감을 정규화하여 정규화 영상(출력영상)을 생성할 수 있다. 얼굴포즈 정규화에 이용되 는 은닉층(Hidden Layer: L1 ... LN) 및 원근감 정규화에 이용되는 은닉층(Lp1 ... LpN)의 수는 설계자에 의해 다르게 설정될 수 있다. 정규화부는 얼굴포즈를 정규화하는 과정과 원근감을 정규화하는 과정을 통합하여 수행한다. 다만, 얼굴포 즈 정규화와 원근감 정규화를 동시에 수행하는 것이 아니고 얼굴포즈를 정규화한 결과영상(정면포즈 영상)을 이 용하여 원근감 정규화를 수행한다. 정규화부는 딥 러닝(Deep Learning) 기법으로 학습할 수 있다. 딥 러닝은 러닝의 층(Layer) 수가 3개 이상 인 러닝 구조에서의 러닝 기법을 말한다. 본 실시예에 따른 각각의 층 간의 연결관계는 [수학식 2]와 같이 나타 낼 수 있다. 수학식 2"}
{"patent_id": "10-2015-0152015", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, 는 n번째 은닉층(Hidden Layer)의 k번째 노드, 는 (n-1)번째 은닉층의 i번째 노드와 연결된 가중치를 의미한다. 는 기계학습을 통해 결정될 수 있다. 도 3을 참조하면, 정규화부는 얼굴포즈 정규화 학습부 및 원근감 정규화 학습부를 포함할 수 있 다. 정규화부는 얼굴포즈 정규화를 위한 학습과 원근감 정규화를 위한 학습을 각각 수행한다. 설명의 편의 상, 얼굴포즈 정규화에 이용되는 인공신경망(Artificial Neural Network: ANN) 및 정규화에 이용되는 인공신경 망을 구분하기 위하여 전자를 제1 인공신경망, 후자를 제2 인공신경망이라 칭한다. 구체적으로, 얼굴포즈 정규화 학습부는 다양한 포즈의 학습용 얼굴영상을 제1 인공신경망의 입력층에 입력 하고, 정면포즈의 학습용 얼굴영상이 제1 인공신경망의 출력층에서 출력되도록 제1 인공신경망을 학습시킬 수 있다. 여기서 학습용 얼굴영상은 가상 얼굴영상 DB에 저장된 가상 얼굴영상일 수 있다. 얼굴포즈 정규화 학습부에 대한 개념도는 도 4b와 같다.원근감 정규화 학습부는 제1 인공신경망의 출력층에서 출력된 데이터를 을 제 2 인공신경망의 입력층에 입 력하고, 원근왜곡이 없는 학습용 얼굴영상이 제 2 인공신경망의 출력층에서 출력되도록 제2 인공신경망을 학습 시킬 수 있다. 원근감 정규화 학습부에 대한 개념도는 도 4c와 같다. 정규화부는 학습이 완료된 제1 인공신경망과 제2 인공신경망을 통합한 통합 인공신경망의 입력층에 다양한 원근왜곡이 있는 다양한 포즈의 학습용 얼굴영상을 입력하고, 정면포즈의 원근왜곡이 없는 학습용 얼굴영상이 통합 인공신경망의 출력층에서 출력되도록 통합 인공신경망을 학습시킬 수 있다. 여기서 다양한 원근왜곡이 있 는 다양한 포즈의 학습용 얼굴영상 및 정면포즈의 원근왜곡이 없는 학습용 얼굴영상은 가상 얼굴영상 DB에 저장된 가상 얼굴영상일 수 있다. 정규화부는 통합 인공신경망을 학습시킴으로써 은닉층의 파라미터를 재조정할 수 있다. 이하, 도 5를 참조하여 특징벡터 추출부에 대하여 구체적으로 설명한다. 도 5는 본 발명의 실시예에 따른 특징벡터 추출부를 설명하기 위한 개념도이다. 특징벡터 추출부 역시 딥 러닝 기법으로 학습할 수 있다. 예를 들어, 컨볼루셔널 신경망(Convolutional Neural Network: CNN)이 이용될 수 있다. 컨볼루셔널 신경망은 컨볼루셔널층(Convolutional Layer)에서 두 가 지 연산을 번갈아 수행하고, 최종적으로 완전연결층(Fully Connected Layer)를 통해 분류(Classification)을 수행하는 계층 모델이다. 컨볼루셔널 신경망의 학습은 역전파 알고리즘(Back Propagation Algorithm)을 이용하 여 이루어질 수 있다. 컨볼루셔널층은 입력데이터에 2차원 필터링을 수행하고 지역적으로 최대값을 추출하여 2차원 영상으로 매핑하여 다운 샘플링(Down Sampling)을 수행한다. 완전연결층은 입력 벡터와 가중치를 선형결합한다. 컨볼루셔널 신경망 을 이용하는 실시예를 나타낸 것이 도 5의 개념도이다. 도 5를 참조하면, C_1 내지 C_5는 컨볼루셔널층, FC_1 및 FC_2는 완전연결층을 의미한다. 컨볼루셔널층의 차원 (Dimension)은 설계자에 의해 조절가능하다. 도 5에 도시된 예시에 의하면, C_1은 50x50 필터를 96개, C_2는 27x27 필터를 256개, C_3는 13x13 필터를 384개, C_4는 13x13 필터를 384개, C_5는 13x13 필터를 256개 포함한 다. 그리고 FC_1 및 FC_2는 4096개의 벡터를 포함한다. 다만, 이는 예시에 불과하며 설계자에 의해 다르게 설정 될 수 있다. f1 내지 f7은 각 층 별로 얼굴영상을 변환하는데 필요한 함수이고, 기계학습을 통해 결정될 수 있다. 또한, f1 내지 f7의 함수는 특징벡터를 추출하는데 이용된다. 맨 마지막 층인 소프트맥스(Softmax)에서는 원하는 출력데이터(그라운드 트루스: Ground Truth)와 입력데이터 즉, 학습용 얼굴영상(예컨대, 가상 얼굴영상)을 인공신경망에 입력함으로써 출력되는 실제 출력데이터와의 유사 도에 대한 확률값을 도출할 수 있다. 구체적으로, FC_2에서 입력된 벡터를 이용하여 분류모델에 의해 분류되는 얼굴 클래스(Class) 별로 유사도에 대한 확률값을 도출한다. 유사도에 대한 확률값은 [수학식 3]에 의해 계산될 수 있다. 수학식 3"}
{"patent_id": "10-2015-0152015", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서, 는 얼굴 클래스 의 인덱스, 는 FC_2의 결과 벡터, 는 오프라인 학습으로 결정되는 변수를 의미한다.이하, 도 6을 참조하여 본 발명의 실시예에 따른 얼굴인식방법에 대하여 설명한다. 도 6은 본 발명의 실시예에 따른 얼굴인식방법을 나타낸 흐름도이다. 본 실시예의 얼굴인식방법은 입력영상 획득과정(S610), 정규화과정(S630), 특징벡터 추출과정(S640), 및 얼굴 인식과정(S650)을 포함한다. 또한, 실시예에 따라 가상 얼굴영상 생성과정(S620)을 더 포함할 수 있다. 본 실시 예의 얼굴인식방법은 하나 또는 복수 개의 프로세서를 포함하는 얼굴인식장치에 의해 수행될 수 있다. 과정 S610에서는 카메라(미도시)로부터 입력되는 입력영상을 획득한다. 여기서 카메라(미도시)는 깊이인식 카메 라, 스테레오 카메라, 및 컬러 카메라일 수 있다(예를 들어, 키넥트(Kinect) 카메라 등). 또한, 입력영상은 인 식대상이 되는 피사체의 얼굴이 포함된 영상으로서 2차원 정지영상 및 동영상을 포함한다. 입력영상은 컬러영상, 깊이영상, 및 컬러-깊이(RGB-D) 영상을 포함할 수 있다. 과정 S630에서는 입력영상으로부터 얼굴영역을 검출하고 얼굴포즈 및 원근감을 정규화하여 정규화 영상을 생성 한다. 얼굴포즈에 변화가 있는 경우, 그레이 스캐일, 형상, 특징점의 위치 등이 달라지기 때문에 얼굴인식률이 저하된다. 또한, 카메라와 피사체 간의 거리가 달라지면 동일한 피사체라 하더라도 촬영된 위치마다 원근왜곡 (예컨대, 뒤틀림)이 다르게 발생하므로, 다른 피사체를 촬영한 것처럼 보이기도 한다. 따라서 얼굴인식률을 향 상시키기 위해서는 입력영상의 얼굴포즈 및 원근감을 정규화할 필요가 있다. 도 4a를 참조하여 구체적으로 설명하면, 정규화과정(S630)에서는 (i) 입력영상에서 얼굴영역을 검출하여 얼굴포 즈를 정규화함으로써 정면포즈 영상(중간결과영상)을 생성하는 과정(S632), 및 (ii) 카메라(미도시)와 피사체 간의 거리에 따른 원근왜곡을 제거하기 위하여 정면포즈 영상의 원근감을 정규화하여 정규화 영상(출력영상)을 생성하는 과정(S634)을 포함할 수 있다. 얼굴포즈 정규화에 이용되는 은닉층(Hidden Layer: L1 ... LN) 및 원근 감 정규화에 이용되는 은닉층(Lp1 ... LpN)의 수는 설계자에 의해 다르게 설정될 수 있다. 정규화과정(S630)에서는 얼굴포즈를 정규화하는 과정과 원근감을 정규화하는 과정을 통합하여 수행한다. 다만, 얼굴포즈 정규화와 원근감 정규화를 동시에 수행하는 것이 아니고 얼굴포즈를 정규화한 결과영상(정면포즈 영상)을 이용하여 원근감 정규화를 수행한다. 정규화과정(S630)에서는 딥 러닝 기법으로 학습하는 과정을 포함할 수 있다. 딥 러닝은 러닝의 층(Layer) 수가 3개 이상인 러닝 구조에서의 러닝 기법을 말한다. 본 실시예에 따른 각각의 층 간의 연결관계는 전술한 [수학식 2]와 같이 나타낼 수 있다. 과정 S640에서는 정규화 영상으로부터 피사체의 얼굴을 표현하는 특징벡터를 추출한다. 특징벡터는 얼굴인식에 사용되는 특징값들을 원소로 가지는 벡터이다. 특징벡터를 추출하는데 사용되는 필터로서 가버(Gabor) 필터, 하 (Haar) 필터, LBP(Local Binary Pattern) - DLBP(Discriminative LBP), ULBP(Uniform LBP), NLBP (Number LBP) 등을 포함 - 등이 있으나, 반드시 이에 한정되는 것은 아니고 그 밖의 다른 필터가 사용될 수 있다. 특징벡터 추출과정(S640)은 기계학습(Machine Learning)을 통해 결정되며 이에 대한 구체적인 설명은 도 5를 참 조하여 전술한 설명과 유사하다. 과정 S650에서는 기 학습된 분류모델에 추출된 특징벡터를 적용하여 입력영상에 포함된 피사체의 얼굴을 인식한 다. 여기서 기 학습된 분류모델은 서포트 벡터 머신(Support Vector Machine: SVM), 선형판별분석(Linear Discriminant Analysis: LDA), 및 소프트맥스(Softmax) 등을 포함할 수 있으나, 반드시 이에 한정되는 것은 아 니다. 가상 얼굴영상 생성과정(S620)에서는 얼굴인식장치가 학습하는데 이용되는 복수의 가상 얼굴영상을 생성할 수 있다. 여기서, 복수의 가상 얼굴영상은 카메라(미도시)로부터 획득된 하나 이상의 2차원 기준영상을 이용하 여 합성한 3차원 얼굴모델을 변형시킴으로써 생성되는 얼굴영상을 의미한다. 안정적으로 얼굴을 인식하기 위해서는 기계학습시 인식하고자 하는 얼굴의 다양한 변화가 반영된 학습영상이 필 요하다. 대규모의 학습영상을 이용할수록 얼굴인식률은 향상될 수 있다. 그러나 대규모의 학습영상을 획득하기 위해서는 많은 시간과 노력 그리고 비용이 필요하기 때문에 현실적으로는 대규모의 학습영상을 획득하기가 어렵 다. 따라서 본 실시예에서는 복수의 가상 얼굴영상을 생성하여 큰 비용 및 시간 투자없이 효율적으로 얼굴인식 장치를 학습시킨다.이하, 도 7을 참조하여 가상 얼굴영상 생성과정(S620)에 대하여 구체적으로 설명한다. 도 7은 도 6에서의 과정 S620을 세부적으로 나타낸 흐름도이다. 가상 얼굴영상 생성과정(S620)은 3차원 얼굴형상 생성과정(S710), 텍스처정보 매핑과정(S720), 3차원 얼굴모델 변형과정(S730), 및 2차원 투영과정(S740)을 포함할 수 있다. 3차원 얼굴형상 생성과정(S710)에서는 하나 이상의 2차원 기준영상으로부터 얼굴의 깊이정보를 추출하여 3차원 얼굴형상을 생성할 수 있다. 여기서 2차원 기준영상은 복수의 가상 얼굴영상을 생성하기 위하여 이용되는 원본 영상을 의미한다. 예를 들어, 과정 S710은 변형가능 얼굴모델(Morphable Model)을 정합하거나 기계 학습 기법을 이용하여 구현 가 능하다. 변형가능 얼굴모델은 3D 스캐너나 깊이 카메라를 이용하여 얼굴의 3차원 형상정보와 텍스처정보를 통계 적으로 학습함으로써 얼굴의 3차원 정보를 표현한다. 또 다른 예로서, 과정 S710은 스테레오 매칭을 이용하여 구현될 수 있다. 즉, 여러 시점에서 촬영된 다시점 영 상으로부터 영상간 픽셀의 간격을 이용하여 2차원 기준영상의 깊이 정보를 추정할 수 있다. 텍스처정보 매핑과정(S720)에서는 하나 이상의 2차원 기준영상으로부터 얼굴의 텍스처정보를 추출하여 3차원 얼 굴형상에 매핑시킴으로써 3차원 얼굴모델을 합성할 수 있다. 구체적으로 과정 S720에서는 2차원 기준영상의 각 픽셀에 깊이정보를 매핑한다. 3차원 얼굴모델 변형과정(S730)는 3차원 얼굴모델에 대하여 (i) X축, Y축, 및 Z축 방향의 회전각도 및 (ii) 카 메라와 2차원 기준영상의 피사체 간의 거리 중 적어도 하나를 변형시켜 복수의 3차원 얼굴변형모델을 생성할 수 있다. 본 실시예에서는 X축, Y축, 및 Z축 방향에 대하여 3차원 얼굴모델을 회전시킴으로써 다양한 얼굴포즈를 반영할 수 있다. 본 실시예에서는 회전축 방향을 달리할 뿐만 아니라 각 회전축에 대한 회전각도도 변형함으로써 더욱 다양한 얼굴포즈 영상을 생성할 수 있다. 또한, 카메라와 2차원 기준영상의 피사체 간의 거리를 변형시켜 다양 한 원근감을 갖는 얼굴영상을 생성할 수 있다. 2차원 투영과정(S740)에서는 과정 S730에 의해 생성된 복수의 3차원 얼굴변형모델을 2차원 평면에 투영시킬 수 있다. 이로써 2차원의 가상 얼굴영상이 생성된다. 이 때 이용될 수 있는 방법은 예를 들어, 원근투영 (Perspective Projection) 및 간략화한 원근투영(Weak Perspective Projection) 등이 있다. 가상 얼굴영상 생성과정(S620)에서 생성된 가상 얼굴영상은 가성 얼굴영상 DB에 저장되어 얼굴인식장치 의 학습에 이용될 수 있다. 이하, 도 8을 참조하여 정규화과정(S630)에 대하여 구체적으로 설명한다. 도 8은 도 6에서의 과정 S630에 포함되는 학습 과정을 나타낸 흐름도이다. 정규화과정(S630)은 얼굴포즈 정규화 학습과정(S810) 및 원근감 정규화 학습과정(S820)을 포함할 수 있다. 정규 화과정(S630)에서는 얼굴포즈 정규화를 위한 학습과 원근감 정규화를 위한 학습을 각각 수행한다. 설명의 편의 상, 얼굴포즈 정규화에 이용되는 인공신경망 및 정규화에 이용되는 인공신경망을 구분하기 위하여 전자를 제1 인공신경망, 후자를 제2 인공신경망이라 칭한다. 구체적으로, 얼굴포즈 정규화 학습과정(S810)에서는 다양한 포즈의 학습용 얼굴영상을 제1 인공신경망의 입력층 에 입력하고, 정면포즈의 학습용 얼굴영상이 제1 인공신경망의 출력층에서 출력되도록 제1 인공신경망을 학습시 킬 수 있다. 여기서 학습용 얼굴영상은 가상 얼굴영상 DB에 저장된 가상 얼굴영상일 수 있다. 얼굴포즈 정 규화 학습과정(S810)에 대한 개념도는 도 4b와 같다. 원근감 정규화 학습과정(S820)에서는 제1 인공신경망의 출력층에서 출력된 데이터를 제 2 인공신경망의 입력층 에 입력하고, 원근왜곡이 없는 학습용 얼굴영상이 제 2 인공신경망의 출력층에서 출력되도록 제2 인공신경망을 학습시킬 수 있다. 원근감 정규화 학습과정(S820)에 대한 개념도는 도 4c와 같다. 정규화과정(S630)은 학습이 완료된 제1 인공신경망과 제2 인공신경망을 통합한 통합 인공신경망의 입력층에 다 양한 원근왜곡이 있는 다양한 포즈의 학습용 얼굴영상을 입력하고, 정면포즈의 원근왜곡이 없는 학습용 얼굴영상이 통합 인공신경망의 출력층에서 출력되도록 통합 인공신경망을 학습시키는 과정을 더 포함할 수 있다. 여기 서 다양한 원근왜곡이 있는 다양한 포즈의 학습용 얼굴영상 및 정면포즈의 원근왜곡이 없는 학습용 얼굴영상은 가상 얼굴영상 DB에 저장된 가상 얼굴영상일 수 있다. 정규화과정(S630)에서는 통합 인공신경망을 학습시킴으로써 은닉층의 파라미터를 재조정할 수 있다. 도 6 내지 도 8에 도시된 과정은 하나 또는 복수 개의 프로세서를 포함하는 얼굴인식장치에 의하여 수행될 수 있다. 도 6 내지 도 8에서는 각각의 과정을 순차적으로 실행하는 것으로 기재하고 있으나, 반드시 이에 한정되는 것은 아니다. 다시 말해, 도 6 내지 도 8에 기재된 과정을 변경하여 실행하거나 하나 이상의 과정을 병렬적으로 실행 하는 것으로 적용 가능할 것이므로, 도 6 내지 도 8은 시계열적인 순서로 한정되는 것은 아니다. 도 6 내지 도 8에 기재된 본 실시예에 따른 얼굴인식방법은 프로그램으로 구현되고 컴퓨터로 읽을 수 있는 기록 매체에 기록될 수 있다. 본 실시예에 따른 얼굴인식방법을 구현하기 위한 프로그램이 기록되고 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한 다. 이상의 설명은 본 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술 분 야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변 형이 가능할 것이다. 따라서, 본 실시예들은 본 실시예의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위 한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다. 산업상 이용가능성"}
{"patent_id": "10-2015-0152015", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "이상에서 설명한 바와 같이 본 실시예은 얼굴인식 기술분야에 적용되어, 얼굴포즈 및 원근감을 정규화하여 얼굴 인식률을 향상시키고, 얼굴 학습 데이터로서 가상 얼굴영상을 자동으로 생성하여 얼굴 학습 데이터를 획득하는 데 드는 비용 및 시간을 절약할 수 있는 효과를 발생하는 유용한 발명이다."}
{"patent_id": "10-2015-0152015", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 얼굴인식장치의 개략적인 구성도이다. 도 2는 본 발명의 실시예에 따른 가상 얼굴영상 생성부의 개략적인 구성도이다. 도 3은 본 발명의 실시예에 따른 정규화부의 개략적인 구성도이다. 도 4a 내지 도 4c는 본 발명의 실시예에 따른 정규화부를 설명하기 위한 개념도이다. 도 5는 본 발명의 실시예에 따른 특징벡터 추출부를 설명하기 위한 개념도이다. 도 6은 본 발명의 실시예에 따른 얼굴인식방법을 나타낸 흐름도이다. 도 7은 도 6에서의 과정 S620을 세부적으로 나타낸 흐름도이다. 도 8은 도 6에서의 과정 S630에 포함되는 학습 과정을 나타낸 흐름도이다."}
