{"patent_id": "10-2022-0177738", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0096950", "출원번호": "10-2022-0177738", "발명의 명칭": "상용 메모리의 데이터 버퍼에 구현된 딥러닝 연산 가속 장치", "출원인": "한국전자기술연구원", "발명자": "이상설"}}
{"patent_id": "10-2022-0177738", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "호스트와 메모리 사이에서 데이터를 버퍼링하는 버퍼 로직;호스트와 메모리 사이에서 딥러닝 연산을 수행하는 딥러닝 연산기;를 포함하는 것을 특징으로 하는 데이터버퍼."}
{"patent_id": "10-2022-0177738", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,메모리에 버퍼 로직과 딥러닝 연산기 중 하나를 연결하는 제1 스위치;호스트에 버퍼 로직과 딥러닝 연산기 중 하나를 연결하는 제2 스위치;를 더 포함하는 것을 특징으로 하는 데이터 버퍼."}
{"patent_id": "10-2022-0177738", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,버퍼 로직은,제2 스위치를 통해 호스트로부터 전달되는 데이터를 버퍼링하여 제1 스위치를 통해 메모리에 저장하고,딥러닝 연산기는,제1 스위치를 통해 메모리로부터 데이터를 읽어들여 딥러닝 연산한 후에 제2 스위치를 통해 호스트로 전달하는것을 특징으로 하는 데이터 버퍼."}
{"patent_id": "10-2022-0177738", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "에 있어서,연산 제어기는,메모리의 저장 영역 중 버퍼 로직이 사용하지 않는 Reserved 영역을 사용하는 것을 특징으로 하는 데이터 버퍼."}
{"patent_id": "10-2022-0177738", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,연산 제어기는,호스트의 명령에 대해 버스트 명령으로 처리하여 다수의 딥러닝 연산을 수행하는 것을 특징으로 하는 데이터 버퍼.공개특허 10-2024-0096950-3-청구항 6"}
{"patent_id": "10-2022-0177738", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 4에 있어서,딥러닝 연산은,컨볼루션 연산 및 누적 연산을 포함하는 것을 특징으로 하는 데이터 버퍼."}
{"patent_id": "10-2022-0177738", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 1에 있어서,메모리는,DIMM(Dual In-line Memory Module)이고,데이터 버퍼는,LRDIMM(Load Reduced DIMM)에 구현되어 있는 것을 특징으로 하는 데이터 버퍼."}
{"patent_id": "10-2022-0177738", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 1에 있어서,호스트는,NPU(Neural Processing Unit)를 포함하는 것을 특징으로 하는 데이터 버퍼."}
{"patent_id": "10-2022-0177738", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "버퍼 로직이, 호스트와 메모리 사이에서 데이터를 버퍼링하는 단계;딥러닝 연산기가, 호스트와 메모리 사이에서 딥러닝 연산을 수행하는 단계;를 포함하는 것을 특징으로 하는 데이터 처리 방법."}
{"patent_id": "10-2022-0177738", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "다수의 메모리; 및호스트와 메모리 사이에서 데이터를 버퍼링하고, 딥러닝 연산을 수행하는 데이터 버퍼;를 포함하는 것을 특징으로 하는 메모리 모듈."}
{"patent_id": "10-2022-0177738", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "데이터 버퍼가, 호스트와 메모리 사이에서 데이터를 버퍼링하는 단계;메모리가, 버퍼링된 데이터를 저장하는 단계;공개특허 10-2024-0096950-4-데이터 버퍼가, 저장된 데이터를 이용하여 딥러닝 연산을 수행하는 단계;를 포함하는 것을 특징으로 하는 데이터 처리 방법."}
{"patent_id": "10-2022-0177738", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "상용 메모리의 데이터 버퍼에 구현된 딥러닝 연산 가속 장치가 제공된다. 본 발명의 실시예에 따른 데이터 버퍼 는, 호스트와 메모리 사이에서 데이터를 버퍼링하는 버퍼 로직 및 호스트와 메모리 사이에서 딥러닝 연산을 수행 하는 딥러닝 연산기를 포함한다. 이에 의해, 상용 메모리의 데이터 버퍼에 딥러닝 연산 가속 장치를 탑재함으로 써, 상용 메모리의 기존 구성과 본래 기능에 대한 변경 없이 딥러닝 연산 가속 장치를 추가할 수 있게 되어, 손 쉬운 기술 개발과 사업화를 가능하게 한다."}
{"patent_id": "10-2022-0177738", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥러닝 연산 가속 장치에 관한 것으로, 더욱 상세하게는 상용 메모리의 기존 구성에 대한 변경 없이 딥러닝 연산 가속 장치를 추가로 탑재하는 설계 기술에 관한 것이다."}
{"patent_id": "10-2022-0177738", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "AI 반도체 회로 및 시스템은 학습 및 추론 등 인공지능 알고리즘 구현에 요구되는 대규모 데이터 처리를 위한 기존 반도체 회로 및 시스템의 한계점을 극복하기 위해 개발된 새로운 회로 및 시스템 기술이다. 이 중 PIM(Processing In Memory) 기술은 인공 신경망 딥러닝 연산의 가속을 위한 디지털 기반 가속기 설계에 적합한 방식으로 여겨져, 이에 대한 많은 연구 개발이 이루어지고 있다. 현재 PIM 개발은 메모리와 연산기 모두를 설계하는 방식으로 접근하고 있는데, 이는 연구 개발을 어렵게 하는 요인이다."}
{"patent_id": "10-2022-0177738", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위하여 안출된 것으로서, 본 발명의 목적은, 상용 메모리의 기존 구 성과 본래 기능에 대한 변경 없이 딥러닝 연산 가속 장치를 추가로 탑재하기 위한 방안으로, 상용 메모리의 데 이터 버퍼에 딥러닝 연산 가속 장치를 구현하는 방법을 제공함에 있다."}
{"patent_id": "10-2022-0177738", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른 데이터 버퍼는 호스트와 메모리 사이에서 데이터를 버 퍼링하는 버퍼 로직; 호스트와 메모리 사이에서 딥러닝 연산을 수행하는 딥러닝 연산기;를 포함한다. 본 발명에 따른 데이터 버퍼는 메모리에 버퍼 로직과 딥러닝 연산기 중 하나를 연결하는 제1 스위치; 호스트에 버퍼 로직과 딥러닝 연산기 중 하나를 연결하는 제2 스위치;를 더 포함할 수 있다. 버퍼 로직은, 제2 스위치를 통해 호스트로부터 전달되는 데이터를 버퍼링하여 제1 스위치를 통해 메모리에 저장 하고, 딥러닝 연산기는, 제1 스위치를 통해 메모리로부터 데이터를 읽어들여 딥러닝 연산한 후에 제2 스위치를 통해 호스트로 전달할 수 있다. 딥러닝 연산기는, 메모리로부터 읽어들인 데이터를 이용하여 딥러닝 연산을 수행하는 연산기; 호스트의 명령을 파싱하는 명령어 파서; 명령어 파서에 의해 파싱된 명령에 따라 연산기를 제어하는 연산 제어기;를 포함할 수 있다. 연산 제어기는, 호스트의 명령에 대해 버스트 명령으로 처리하여 다수의 딥러닝 연산을 수행할 수 있다. 연산 제어기는, 메모리의 저장 영역 중 버퍼 로직이 사용하지 않는 Reserved 영역을 사용할 수 있다. 딥러닝 연산은, 컨볼루션 연산 및 누적 연산을 포함할 수 있다. 메모리는, DIMM(Dual In-line Memory Module)이고, 데이터 버퍼는, LRDIMM(Load Reduced DIMM)에 구현되어 있 을 수 있다. 호스트는, NPU(Neural Processing Unit)를 포함할 수 있다. 본 발명의 다른 측면에 따르면, 버퍼 로직이, 호스트와 메모리 사이에서 데이터를 버퍼링하는 단계; 딥러닝 연 산기가, 호스트와 메모리 사이에서 딥러닝 연산을 수행하는 단계;를 포함하는 것을 특징으로 하는 데이터 처리 방법이 제공된다. 본 발명의 또다른 측면에 따르면, 다수의 메모리; 및 호스트와 메모리 사이에서 데이터를 버퍼링하고, 딥러닝 연산을 수행하는 데이터 버퍼;를 포함하는 것을 특징으로 하는 메모리 모듈이 제공된다. 본 발명의 또다른 측면에 따르면, 데이터 버퍼가, 호스트와 메모리 사이에서 데이터를 버퍼링하는 단계; 메모리 가, 버퍼링된 데이터를 저장하는 단계; 데이터 버퍼가, 저장된 데이터를 이용하여 딥러닝 연산을 수행하는 단계;를 포함하는 것을 특징으로 하는 데이터 처리 방법이 제공된다."}
{"patent_id": "10-2022-0177738", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상 설명한 바와 같이, 본 발명의 실시예들에 따르면, 상용 메모리의 데이터 버퍼에 딥러닝 연산 가속 장치를 탑재함으로써, 상용 메모리의 기존 구성과 본래 기능에 대한 변경 없이 딥러닝 연산 가속 장치를 추가할 수 있 게 되어, 손쉬운 기술 개발과 사업화를 가능하게 한다."}
{"patent_id": "10-2022-0177738", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 발명을 보다 상세하게 설명한다. 도 1은 서버용 DDR(Double Data Rate) 메모리로 활용되고 있는 LRDIMM(Load Reduced Dual In-line Memory Module)의 내부 구조를 도시한 도면이다. RDIMM은 도시된 바와 같이 DRAM들, 클럭/명령/어드레싱을 위한 RCD(Register Clock Driver), DRAM들과 외부 디바이스 사이에서 데이터를 버퍼링하는 데이터 버퍼(Data Buffer, DB)들을 포함하여 구성된다. 데이터 버퍼(DB)들에 의해 보다 안정적인 동작이 가능하며, LRDIMM의 구성들과 배치는 모두 JEDEC(Joint Electron Device Engineering Council) 표준을 준수한다. 한편 대부분의 컴퓨팅 코어의 경우 외부 메모리와 내부 프로세서 간 데이터 이동량이 많아 해당 기능 동작에 전 력 소모가 상당하다. 따라서 최근 인공지능 및 빅데이터 데이터 센터에서의 데이터량 및 에너지 소모가 심각하 다. 도 2는 연산기와 DRAM 간 에너지 소모가 극심함을 보여준다. 이를 해결하기 위하여 In-memory Computing 기술이 최근 많이 시도되고 있다. 아날로그 방식으로 메모리 셀을 변경하여 HBM(High Bandwidth Memory)으로 연산 코어와 직접 연결하는 방법 등은 개발하는 파운드리 및 공정에 영향을 많이 받고 있다. 연산 로직이 메모리와 함께 집적되는 방식이기 때문에 이를 설계함에 있어 많은 어려움 이 있다. 이에 따라 본 발명의 실시예에서는 상용 메모리의 데이터 버퍼(DB)에 딥러닝 연산 가속 장치를 구현하는 방법을 제시한다. 도 3은 본 발명의 일 실시예에 따른 딥러닝 네트워크 연산 시스템의 구성을 도시한 도면이다. 본 발명의 실시예 에 따른 딥러닝 네트워크 연산 시스템은 LRDIMM과 호스트를 포함하여 구성된다.LRDIMM은 다수의 DRAM들을 메모리로 활용하며, 제어를 위한 RCD와 데이터 버퍼링을 위한 데이터 버퍼(D B)들을 포함하여 구성된다. LRDIMM의 구성들은 JEDEC 표준을 준수한다. 호스트는 내부 메모리와 컴퓨팅 코어를 포함하고 있는데, 컴퓨팅 코어는 NPU(Neural Processing Unit)로 구현할 수 있다. 한편 LRDIMM의 데이터 버퍼(DB)들은 DRAM에 직접 연결되어 있기 때문에, 호스트의 NPU와 연결 없이 직접 연산 처리가 가능할 수 있다. 이에 따라 본 발명의 실시예에서는 데이터 버퍼(DB) 내에 딥러닝 연산 가속 기를 구현하여 호스트와 연동 없는 딥러닝 연산을 가능하게 한다. 단 데이터 버퍼 칩셋은 JEDEC 표준에서 최대 크기를 제한하고 있으므로, 이를 벗어나지 않는 범위에서 딥러닝 연산 가속기를 탑재하여야 한다. 도 4는 딥러닝 연산 가속기를 탑재하여 PIM(Processing In Memory)이 가능한 데이터 버퍼(DB) 칩셋의 구조를 도 시한 도면이다. 본 발명의 다른 실시예에 따른 데이터 버퍼(DB)는 도시된 바와 같이, 스위치, 데이터 버퍼 로직, 딥러닝 연산 가속기 및 스위치를 포함하여 구성된다. 데이터 버퍼 로직은 호스트와 LRDIMM의 DRAM 사이에서 데이터를 버퍼링하는 버퍼이다. 종래 데 이터 버퍼(DB)의 본래 기능을 수행하는 구성이다. 딥러닝 연산 가속기는 호스트와 LRDIMM의 DRAM 사이에서 호스트의 연결/개입 없이 딥러닝 연산을 수행하는 구성이다. 딥러닝 연산 가속기는 기존 데이터 버퍼(DB)에 새롭게 추가되는 구성으로, 상 세 구조에 대해서는 도 5를 참조하여 상세히 후술한다. 스위치는 LRDIMM의 DRAM에 버퍼 로직과 딥러닝 연산기 중 하나가 연결되도록 스위칭 동작 한다. 스위치는 호스트에 버퍼 로직과 딥러닝 연산기 중 하나가 연결되도록 스위칭 동작한 다. 데이터 버퍼 로직은 스위치를 통해 호스트로부터 전달되는 데이터를 버퍼링하여 스위치를 통해 LRDIMM의 DRAM에 저장한다. 딥러닝 연산 가속기는 스위치를 통해 LRDIMM의 DRAM로부터 데이터를 읽어들여 딥러닝 연산한 후 에 스위치를 통해 호스트로 전달한다. 도 5는 딥러닝 연산 가속기의 상세 구조를 도시한 도면이다. 딥러닝 연산 가속기는 도시된 바와 같이, 명령어 파서(Instruction Parser, 331), 연산 제어기(Operation Controller, 332), 레지스터(Register, 333,334), 연산기(Operator, 335), 스위치(Switch, 336), 출력 버퍼(Output Buffer, 337,338)를 포함하여 구성 된다. 명령어 파서는 호스트의 NPU로부터 수신되는 명령을 파싱하고, 연산 제어기는 명령어 파서(33 1)에 의해 파싱된 명령에 따라 연산기를 제어한다. 연산 제어기는 호스트의 NPU의 명령에 대해 버스트 명령으로 처리하여 다수의 딥러닝 연산을 수행하 도록 연산기를 제어할 수 있다. 연산 제어기는 DRAM의 저장 영역 중 버퍼 로직이 사용하지 않는 Reserved 영역을 사용한다. 레지스터(333,334)는 DRAM으로부터 읽어들인 데이터들이 임시 저장되는 공간이다. 연산기는 DRAM으로부터 읽어들여 레지스터(333,334)에 임시 저장된 데이터들을 이용하여 연산 제어기의 명령에 따라 딥러닝 연산 을 수행한다. 딥러닝 연산에는 컨볼루션 연산 및 누적 연산 등이 포함된다. 스위치는 연산기에 의해 출력되는 출력 데이터를 출력 버퍼(337,338)를 통해 호스트로 전달한다. 단순 반복 입출력 연산/element-wise 연산/누적 연산 등을 데이터 버퍼(DB) 안의 남은 공간에서 가능한 연산 하 드웨어 로직인 딥러닝 연산 가속기를 설계하여 집적함으로써, 딥러닝 연산 과정에서 호스트와 불필요 한 데이터 입출력이 없어진다. 이는 버퍼 로직의 By-pass 형태와 함께 LRDIMM의 DRAM과 딥러닝 연산 가속기 간 연결 혹은 딥러닝 연산 가속기와 호스트와의 연결 필요에 따라서 스위치(310,340)를 제어하여 데이터를 주고 받을 수 있다. 지금까지 상용 메모리의 데이터 버퍼에 구현된 딥러닝 연산 가속 장치에 대해 바람직한 실시예를 들어 상세히 설명하였다. 본 발명의 실시예들에서는 상용 메모리의 데이터 버퍼에 딥러닝 연산 가속 장치를 구현함으로써, 상용 메모리의 기존 구성과 본래 기능에 대한 변경 없이 딥러닝 연산 가속 장치를 추가할 수 있게 되어, 손쉬운 기술 개발과 사업화를 가능하게 하였다. 또한, 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2022-0177738", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2022-0177738", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1. LRDIMM의 내부 구조 도 2. 딥러닝 연산 처리를 위한 에너지 소모 비교 도 3. 본 발명의 일 실시예에 따른 딥러닝 네트워크 연산 시스템 구성 도 4. PIM 동작을 위한 데이터 버퍼(DB) 칩셋의 개념도 도 5. 딥러닝 연산 가속기 구조"}
