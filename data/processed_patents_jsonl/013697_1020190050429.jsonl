{"patent_id": "10-2019-0050429", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0130768", "출원번호": "10-2019-0050429", "발명의 명칭": "비디오 시간 정보를 활용하는 딥러닝 기반 물체 검출 방법 및 장치", "출원인": "한양대학교 산학협력단", "발명자": "최준원"}}
{"patent_id": "10-2019-0050429", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라 센서 데이터를 입력으로 하는 딥뉴럴 네트워크를 이용하여 검출하고자 하는 물체에 대한 지역정보와 함께 현재 프레임과 이전 프레임과의 상관관계를 표현하는 시간정보를 융합하는 단계; 및현재 프레임과 이전 프레임과의 상관관계에 따라 이전 프레임의 정보의 사용 정도를 결정하여 물체 검출을 수행하는 단계를 포함하는 딥러닝 기반 물체 검출 방법."}
{"patent_id": "10-2019-0050429", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 카메라 센서 데이터를 입력으로 하는 딥뉴럴 네트워크를 이용하여 검출하고자 하는 물체에 대한 지역정보와 함께 현재 프레임과 이전 프레임과의 상관관계를 표현하는 시간정보를 융합하는 단계는, 입력되는 카메라 센서 데이터의 이전 프레임과 현재 프레임에 대한 영상 정보가 시간 축에 따라 분리된 네트워크에 각각 통과 되고, 각 네트워크 연산에 사용되는 웨이트는 시간 축에 대해 서로 공유되며, 물체에 대한 지역정보와 함께 별도의 CNN구조를 활용하여 얻은 시간정보를 이용하는 딥러닝 기반 물체 검출 방법."}
{"patent_id": "10-2019-0050429", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 시간 축에 따라 분리된 네트워크를 통과한 출력 값은, 현재 프레임에 대한 물체 검출을 수행하기 위해 필요한정보를 이전 프레임 영상으로부터 얻기 위하여 현재 프레임과의 연관성을 이용하는 TIE(Temporal informationextractor) 구조로 입력되는 딥러닝 기반 물체 검출 방법."}
{"patent_id": "10-2019-0050429", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 각 프레임의 웨이트를 GIF(Gated Information Fusion) 기법을 이용하여 판단한 뒤 지역정보와 시간정보를 융합하는 딥러닝 기반 물체 검출 방법."}
{"patent_id": "10-2019-0050429", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, GIF 기법은 라이다에서 얻은 포인트 클라우드로 만들어진 전방 이미지로부터의 원본 특징지도의 웨이트와 카메라 이미지로부터의 원본 특징지도의 웨이트를 판단하고, 각 이미지에서 얻은 특징지도를 이어 붙여서 얻은 특징지도를 이용하여 단일채널 특징지도를 만들고, 단일채널 특징지도와 원본 특징지도들을 이용하여 각 시간별 특징 지도를 만드는 딥러닝 기반 물체 검출 방법."}
{"patent_id": "10-2019-0050429", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "카메라 센서 데이터를 입력으로 하는 딥뉴럴 네트워크를 이용하여 검출하고자 하는 물체에 대한 지역정보와 함공개특허 10-2020-0130768-3-께 현재 프레임과 이전 프레임과의 상관관계를 표현하는 시간정보를 융합하는 지역정보 및 시간정보 융합부; 및현재 프레임과 이전 프레임과의 상관관계에 따라 이전 프레임의 정보의 사용 정도를 결정하여 물체 검출을 수행하는 물체 검출부를 포함하는 딥러닝 기반 물체 검출 장치."}
{"patent_id": "10-2019-0050429", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 지역정보 및 시간정보 융합부는, 입력되는 카메라 센서 데이터의 이전 프레임과 현재 프레임에 대한 영상 정보가 시간 축에 따라 분리된 네트워크에 각각 통과 되고, 각 네트워크 연산에 사용되는 웨이트는 시간 축에 대해 서로 공유되며, 물체에 대한 지역정보와 함께 별도의 CNN구조를 활용하여 얻은 시간정보를 이용하는딥러닝 기반 물체 검출 장치."}
{"patent_id": "10-2019-0050429", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 시간 축에 따라 분리된 네트워크를 통과한 출력 값은, 현재 프레임에 대한 물체 검출을 수행하기 위해 필요한정보를 이전 프레임 영상으로부터 얻기 위하여 현재 프레임과의 연관성을 이용하는 TIE(Temporal informationextractor) 구조로 입력되는 딥러닝 기반 물체 검출 장치."}
{"patent_id": "10-2019-0050429", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 각 프레임의 웨이트를 GIF(Gated Information Fusion) 기법을 이용하여 판단한 뒤 지역정보와 시간정보를 융합하는 딥러닝 기반 물체 검출 장치."}
{"patent_id": "10-2019-0050429", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, GIF 기법은 라이다에서 얻은 포인트 클라우드로 만들어진 전방 이미지로부터의 원본 특징지도의 웨이트와 카메라 이미지로부터의 원본 특징지도의 웨이트를 판단하고, 각 이미지에서 얻은 특징지도를 이어 붙여서 얻은 특징지도를 이용하여 단일채널 특징지도를 만들고, 단일채널 특징지도와 원본 특징지도들을 이용하여 각 시간별 특징 지도를 만드는 딥러닝 기반 물체 검출 장치."}
{"patent_id": "10-2019-0050429", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에서 제안하는 비디오 시간 정보를 활용하는 딥러닝 기반 물체 검출 방법은 카메라 센서 데이터를 입력으 로 하는 딥뉴럴 네트워크를 이용하여 검출하고자 하는 물체에 대한 지역정보와 함께 현재 프레임과 이전 프레임 과의 상관관계를 표현하는 시간정보를 융합하는 단계 및 현재 프레임과 이전 프레임과의 상관관계에 따라 이전 프레임의 정보의 사용 정도를 결정하여 물체 검출을 수행하는 단계를 포함한다."}
{"patent_id": "10-2019-0050429", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 비디오 시간 정보를 활용하는 딥러닝 기반 물체 검출 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2019-0050429", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "물체 검출기법이란 카메라 영상으로부터 검출하고자 하는 물체의 위치와 클래스를 구분하는 기술을 의미한다. 영상 정보를 통한 물체 검출 기술은 컴퓨터 비전 분야에서 오랫동안 연구되어 왔던 분야이다. 최근에 딥뉴럴네 트워크 구조를 이용하는 딥러닝 기술이 발전함에 따라 대용량의 영상데이터로부터 고차원의 특집지도를 학습하 여 이를 통해 매우 높은 수준의 정확도로 물체를 검출하는 방법이 제안되었다. 이러한 기술은 자율주행, 로봇공 학, 의료, 보안 등 다양한 분야에서 활발히 적용되고 있고 공장에서 사용되는 로봇 또한 영상 기반 물체 인지기술을 사용하여 스스로 공장 환경의 변화와 특징을 학습하고 궁극적으로 로봇의 지능과 처리 성능을 극대화하 는 기법에도 중요한 기술로 사용되고 있다. 이처럼 영상분야의 인지 기술의 발달과 함께 환경과 상황에 대한 이 해를 통한 물체 검출 기술의 필요성이 높아지고 있다. 이러한 인지기술을 바탕으로 물체의 주변 환경과 상황에 대한 이해가 함께 이루어지는 기술은 물체 검출을 넘어 물체간의 관계 파악, 물체의 위치 예측 등의 다양한 분 야에 응용 될 수 있다. 제안하는 기술과 관련도가 높은 종래 기술은 영상 기반의 물체 검출기술이 있다. 딥러닝 기술이 적용되기 이전 에는 발명자가 데이터의 주요 특징들을 추출할 수 있는 기법들을 정교하게 설계하여 영상의 특징값을 얻고 이를 통계적인 분류기를 통해 물체를 인식 또는 검출하는 기술이 주로 사용되었다. 예를 들어, 영상의 선의 구조나 형태 등의 특징들을 알아내고 이를 이미 알고 있는 템플릿과 비교하여 물체를 인지하거나 검출하는 기술이다. 대표적인 특징 추출 기술로는 SIFT(Scale invariant feature transform)과 HOG (Histogram of oriented gradients) 표현자 등이 있다. SIFT는 영상에서 코너점 등 시결이 용이한 특징점들을 선택한 후에 각 특징점을 중심으로 한 로컬 패치에 대해 방향성을 갖는 특징 벡터를 추출하는 방법이다. 이는 주변의 밝기 변화의 방향 및 밝기 변화의 급격한 정도를 표현하는 특징을 이용한 방법이다. 이는 주변의 밝기 변화의 방향 및 밝기 변화 의 급격한 정도를 표현하는 특징을 이용한 방법이다. HOG는 대산 영역을 일정 크기의 셀로 분할하고, 각 셀마다 경계 픽셀들의 방향에 대한 히스토그램을 구한 후 이들 히스토그램 bin 값들을 일렬로 연결한 벡터를 이용한 방 법이다. HOG경계의 방향정보를 이용하기 때문에 경계기반 템플릿의 매칭 방법이다. 또한 물체의 실루엣 정보를 이용하므로 사람, 자동차 등과 같이 내부 패턴이 복잡하지 않으면서도 고유의 독특한 윤곽선 정보를 갖는 물체 를 식별하는데 적합한 방법이다. 이러한 기술들은 미리 엣지나 형태에 대한 물체의 알려진 정보만을 활용하기 때문에 영상 데이터에 다양한 조도 변화나 형태 왜곡, 노이즈, 가림 등이 발생하는 경우에 특징값이 예측된 분 포에서 벗어나게 되면 인식 성능이 크게 떨어지는 단점이 있다. 이러한 특징값 기반의 물체 검출 기법의 한계를 극복하기 위해서 딥러닝 기술은 보다 일반화된 학습 모델인 딥 뉴럴 네트워크 구조를 사용하여 방대한 양의 데이터로부터 데이터의 표현 방법 즉 특징지도를 학습하게 된다. 이러한 경우 데이터의 표현 방법을 다양한 종류의 데이터를 통해 얻기 때문에 영상 정보의 다양한 변화와 악의 적인 요소에 대해 좋은 성능을 얻을 수 있다. 딥러닝 기법을 이용한 종래 물체검출 방법에는 R-CNN 기법이 있다. R-CNN 기법은 카메라 센서로부터 입력을 받아 먼저 이미지에서 물체의 후보가 될 수 있는 영역을 제안하 는 전처리 네트워크를 거친 후, 그 영역에 대한 정보를 각각 딥뉴럴 네트워크의 입력으로 하는 물체 분류 네트 워크에 통과시키는 방법이다. 또한 R-CNN의 단점을 개선한 Fast R-CNN 기법은 기존의 R-CNN 기법의 연산량을 줄 이기 위해 CNN 네트워크를 이용하여 특징값을 찾고 중간 노드의 특징지도 단에서 물체 후보 영역에 대한 정보를 추출하는 영역제안 네트워크와 물체의 종류를 판별하는 컨볼루션 네트워킹을 사용하여 물체 검출을 수행하게 된 다. 최근에는 이러한 두 가지 네트워크를 하나로 통합하여 물체 영역의 위치를 찾는 단계와 물체의 종류를 구분 하는 단계를 통합하여 처리하는 SSD(Single shot detector)와 YOLO(You only look once)하는 딥러닝 물체 검출 기법이 제안되었다. 딥러닝을 기반으로 하는 종래의 물체 검출 기술의 문제점으로는 CNN으로부터 특징값으로부터 물체에 해당하는 특징값을 매칭하여 물체의 영역과 종류를 판별하기 때문에 영상 데이터의 시간정보를 활용하지 않아서 가려진 물체나 사라진 물체에 대한 검출에 한계가 있다. 하지만 실제 사람의 경우 이전의 물체 위치를 기억하고 현재 물체가 가려지더라도 애매한 위치에 있는 물체라도 매우 높은 가능성으로 물체를 인지할 수 있다. 이처럼 영상 데이터에서 가지고 있는 시간정보를 이용하지 않는 것은 데이터가 가지고 있는 정보를 충분히 활용하지 않는다 는 문제를 가지게 된다."}
{"patent_id": "10-2019-0050429", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적 과제는 딥러닝 기반 물체 검출 기법의 성능을 개선하기 위하여 물체가 있는 지 역정보와 함께 별도의 CNN구조를 활용하여 얻은 비디오 시퀀스의 시간 정보를 함께 이용하여 물체를 검출할 수 있는 방법 및 장치를 제안하고자 한다. 또한, 딥러닝을 기반으로 하는 물체 검출의 기술을 비디오 데이터에서 프레임간의 상관관계에 대한 이해를 수행하여 물체 검출 성능의 수준을 향상시키는 것을 목적으로 한다."}
{"patent_id": "10-2019-0050429", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 측면에 있어서, 본 발명에서 제안하는 비디오 시간 정보를 활용하는 딥러닝 기반 물체 검출 방법은 카메라 센서 데이터를 입력으로 하는 딥뉴럴 네트워크를 이용하여 검출하고자 하는 물체에 대한 지역정보와 함께 현재 프레임과 이전 프레임과의 상관관계를 표현하는 시간정보를 융합하는 단계 및 현재 프레임과 이전 프레임과의 상관관계에 따라 이전 프레임의 정보의 사용 정도를 결정하여 물체 검출을 수행하는 단계를 포함한다. 카메라 센서 데이터를 입력으로 하는 딥뉴럴 네트워크를 이용하여 검출하고자 하는 물체에 대한 지역정보와 함 께 현재 프레임과 이전 프레임과의 상관관계를 표현하는 시간정보를 융합하는 단계는 입력되는 카메라 센서 데 이터의 이전 프레임과 현재 프레임에 대한 영상 정보가 시간 축에 따라 분리된 네트워크에 각각 통과 되고, 각 네트워크 연산에 사용되는 웨이트는 시간 축에 대해 서로 공유되며, 물체에 대한 지역정보와 함께 별도의 CNN구 조를 활용하여 얻은 시간정보를 이용한다. 시간 축에 따라 분리된 네트워크를 통과한 출력 값은, 현재 프레임에 대한 물체 검출을 수행하기 위해 필요한 정보를 이전 프레임 영상으로부터 얻기 위하여 현재 프레임과의 연관성을 이용하는 TIE(Temporal information extractor) 구조로 입력된다. 각 프레임의 웨이트를 GIF(Gated Information Fusion) 기법을 이용하여 판단한 뒤 지역정보와 시간정보를 융합 한다. GIF 기법은 라이다에서 얻은 포인트 클라우드로 만들어진 전방 이미지로부터의 원본 특징지도의 웨이트와 카메라 이미지로부터의 원본 특징지도의 웨이트를 판단하고, 각 이미지에서 얻은 특징지도를 이어 붙여서 얻은 특징지도를 이용하여 단일채널 특징지도를 만들고, 단일채널 특징지도와 원본 특징지도들을 이용하여 각 시간별 특징 지도를 만든다. 또 다른 일 측면에 있어서, 본 발명에서 제안하는 비디오 시간 정보를 활용하는 딥러닝 기반 물체 검출 장치는 카메라 센서 데이터를 입력으로 하는 딥뉴럴 네트워크를 이용하여 검출하고자 하는 물체에 대한 지역정보와 함 께 현재 프레임과 이전 프레임과의 상관관계를 표현하는 시간정보를 융합하는 지역정보 및 시간정보 융합부 및 현재 프레임과 이전 프레임과의 상관관계에 따라 이전 프레임의 정보의 사용 정도를 결정하여 물체 검출을 수행 하는 물체 검출부를 포함한다."}
{"patent_id": "10-2019-0050429", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들에 따르면 딥러닝 기법을 이용한 물체 검출 수행 시 지역정보와 시간정보를 함께 이용하여 물체 검출 성능을 향상시킬 수 있다. 제안하는 방법은 카메라 센서 데이터를 입력으로 하는 딥뉴럴 네트워크에 서 물체가 있는 지역정보를 얻기 위한 네트워크와 두 프레임간의 정보에 상호 연관성을 주기 위한 융합 네트워 크가 구성되어 두 정보를 효율적으로 융합하고, 물체의 시간에 따른 변화에 대한 정보를 이해하여 효율적인 물 체 검출을 수행할 수 있다. 최근 스마트 홈 환경에나 자율 주행 환경에서는 카메라 센서 데이터를 이용하여 물 체 검출을 수행할 때 물체 검출과 동시에 시간정보를 이해하는 데에 활용될 것으로 예상이 되며 제안하는 방법 은 이러한 물체와 그 물체의 시간 정보에 대한 이해를 효과적으로 수행할 수 있는 해결책을 제시한다. 또한, 스 마트폰이나 자율주행뿐만 아니라 환경이나 물체를 인식하는 다양한 인공지능 기술에 적용이 가능하다."}
{"patent_id": "10-2019-0050429", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에서는 자율주행 또는 스마트 가정을 위한 사물인터넷 환경에서 카메라 센서 정보를 이용한 물체 검출 수행 시 비디오의 시간정보를 함께 이용하는 딥러닝 기반 물체 검출 기법에 대해 제안하고자 한다. 기존의 딥러 닝 기반 물체 검출 방법은 CNN(Convolutional Neural Network)을 사용하여 단일 이미지로부터 특징지도를 추출 하고 특징지도로부터 특정 물체에 해당하는 지역정보를 이용하여 물체의 위치를 표시하는 바운딩박스 정보를 찾고 물체의 종류를 분류한다. 이러한 방법을 통해 얻은 모델의 웨이트를 이용해 비디오 영상에서 인퍼런스를 해 보면 매우 끊기는 현상이 발생하기 때문에 본 발명은 딥러닝 기반 물체 검출 기법의 성능을 개선하기 위하여 물 체가 있는 지역정보와 함께 별도의 CNN구조를 활용하여 얻은 비디오 시퀀스의 시간 정보를 함께 이용하여 물체 를 검출할 수 있는 기술을 제안한다. 이하, 본 발명의 실시 예를 첨부된 도면을 참조하여 상세하게 설명한다. 도 1은 본 발명의 일 실시예에 따른 비디오 시간 정보를 활용하는 딥러닝 기반 물체 검출 방법을 설명하기 위한 흐름도이다. 비디오 시간 정보를 활용하는 딥러닝 기반 물체 검출 방법은 카메라 센서 데이터를 입력으로 하는 딥뉴럴 네트 워크를 이용하여 검출하고자 하는 물체에 대한 지역정보와 함께 현재 프레임과 이전 프레임과의 상관관계를 표 현하는 시간정보를 융합하는 단계 및 현재 프레임과 이전 프레임과의 상관관계에 따라 이전 프레임의 정보 의 사용 정도를 결정하여 물체 검출을 수행하는 단계를 포함한다. 단계에서, 카메라 센서 데이터를 입력으로 하는 딥뉴럴 네트워크를 이용하여 검출하고자 하는 물체에 대한 지역정보와 함께 현재 프레임과 이전 프레임과의 상관관계를 표현하는 시간정보를 융합한다. 입력되는 카메라 센서 데이터의 이전 프레임과 현재 프레임에 대한 영상 정보가 시간 축에 따라 분리된 네트워 크에 각각 통과 된다. 각 네트워크 연산에 사용되는 웨이트는 시간 축에 대해 서로 공유되고, 물체에 대한 지역 정보와 함께 별도의 CNN구조를 활용하여 얻은 시간정보를 이용한다. 시간 축에 따라 분리된 네트워크를 통과한 출력 값은, 현재 프레임에 대한 물체 검출을 수행하기 위해 필요한 정보를 이전 프레임 영상으로부터 얻기 위하여 현재 프레임과의 연관성을 이용하는 TIE(Temporal information extractor) 구조로 입력된다. 이후, 각 프레임의 웨이트를 GIF(Gated Information Fusion) 기법을 이용하여 판단한 뒤 지역정보와 시간정보를 융합한다. GIF 기법을 통해 라이다에서 얻은 포인트 클라우드로 만들어진 전방 이미지로부터의 원본 특징지도의 웨이트와 카메라 이미지로부터의 원본 특징지도의 웨이트를 판단하고, 각 이미지에서 얻은 특징지도를 이어 붙 여서 얻은 특징지도를 이용하여 단일채널 특징지도를 만든다. 이러한 단일채널 특징지도와 원본 특징지도들을 이용하여 각 시간별 특징 지도를 만든다. 단계에서, 현재 프레임과 이전 프레임과의 상관관계에 따라 이전 프레임의 정보의 사용 정도를 결정하여 물체 검출을 수행한다. 제안하는 기술은 위의 종래 기술의 문제점을 다음과 같이 해결해준다. 먼저, 종래의 딥러닝 기반 물체 인지 기 술은 딥뉴럴 네트워크의 특징지도에서 지역 정보만을 활용하여 물체 검출을 수행하지만, 제안하는 기술은 현재 검출하고자 하는 프레임정보 뿐만이 아니라 이전 프레임의 정보를 같이 활용하기 때문에 이전에 검출되었다가 가려진 물체에 대한 정보를 가져와서 현재 프레임에서 물체를 검출하는 데에 큰 도움이 된다. 두 프레임의 상호 작용을 적용하기 위해 센서융합에서 사용했던 GIF 구조를 사용하였고 이러한 구조를 사용함으로써 이전 프레임 의 정보에 대한 중요도를 네트워크가 직접 학습하여 필요한 정보만 가져오게 되었다. 도 2 및 도 3을 참조하여 본 발명에서 제안하는 딥뉴럴 네트워크 구조에 대하여 더욱 상세히 설명한다. 도 2는 본 발명의 일 실시예에 따른 시간정보를 이용하여 물체 검출을 수행하기 위한 딥뉴럴 네트워크 구조를 나타내는 도면이다. 제안하는 기술은 딥뉴럴 네트워크를 이용하여 물체 검출을 수행하는 종래의 방식에서 사용하는 물체에 대한 지 역정보와 함께 이전 프레임과의 상관관계를 표현하는 시간정보를 융합하여 영상 기반의 물체 검출 성능을 높이 는 것을 목표로 한다. 제안하는 기술은 다양한 딥러닝 기반 물체 인지 알고리즘에 적용 가능하며, 지역적 정보와 시간적 정보를 추출 하기 위해서 CNN 구조를 활용하고 특징지도로부터 물체를 검출하기 위한 구조로 레티나넷(Retinanet) 방법의 일 부를 활용하였다. 도 2에서는 제안하는 시간 정보 융합 물체 검출 방법의 딥뉴럴 네트워크 구조를 나타낸다. 도 2에 보이는 바와 같이 제안하는 방법은 카메라 영상 정보를 레스넷18(ResNet18)이라는 CNN구조를 통과시킨 뒤 FPN구조를 통해 물 체 검출을 수행한다. 현재 시간 t 에서의 입력 영상에 대한 물체 검출을 수행하는 경우, 이전 프레임(T = t-1)에 대한 특징 추출과 현재 프레임(T = t)에 대한 특징 추출을 수행한다. 이와 같이 추출된 특징에 대한 영상 정보가 시간 축에 따라 분리된 네트워크에 각각 통과 되며 각 네트워크 연산에 사용되는 웨이트는 시 간 축에 대해 서로 공유되어 시간정보를 추출한다. 이러한 구조를 통과한 출력 값은 제안하는 TIE(Temporal information extractor) 구조의 입력으로 이용된다. 제안하는 TIE 구조는 현재 프레임에 대한 물 체 검출을 수행함에 있어 도움이 될 수 있는 정보를 이전 프레임 영상으로부터 얻기 위해 현재 프레임과의 연관 성을 이용하며, 분류 및 회귀분석을 수행한다. 이 과정에서 각 프레임의 중요도를 GIF(Gated Information Fusion) 기법을 이용해 판단한 뒤 정보 융합을 통해 물체 검출을 수행한다. 도 3은 본 발명의 일 실시예에 따른 이전과 현재 프레임 정보를 융합하기 위한 딥뉴럴 네트워크 구조를 나타내 는 도면이다. GIF 기법은 센서 융합에서 사용되는 기술로서, 라이다에서 얻은 포인트 클라우드로 만들어진 전방 이미지로부터 의 특징지도의 중요도와 카메라 이미지로부터의 특징지도의 중요도를 판단하여 카메라 이미지에서 물체검출을 수행할 때에 도움을 주는 기법이다. 이 구조는 각각의 이미지에서 얻은 특징지도의 중요도를 정해주는 구조로, 이전과 현재 프레임의 시간 정보를 추출하여 융합하기 위한 딥뉴럴 네트워크 구조이다. 더욱 상세하게는, 연속한(Concatenation) 프레임간의 시간 정보를 활용하여 두 특징지도를 이어 붙여서 얻 은 특징지도에 대한 각각 컨볼루션 연산을 수행하고 활성함수로 시그모이드(Sigmoid) 함수를 적용하여 각 각의 픽셀 값을 얼마나 사용할지를 0에서 1 사이의 값으로 정해주는 단일채널 특징지도를 만든다. 이 특징지도 를 원본 특징지도에 각 픽셀(pixel)별로 곱해주는 엘리먼트-와이즈 곱(Element-wise Product)을 수행하여 나온 각 시간별 특징 지도를 다시 이어 붙인 뒤에 1x1 컨볼루션을 이용해 채널 수를 줄여주고 시간 정보 추출 을 수행한다. 이 구조를 이용하면 현재 프레임과 이전 프레임에 대한 특징 지도를 단순히 이어 붙일 때보 다 이전 프레임의 정보를 얼마나 사용할지를 결정하여 현재 프레임에 도움이 되는 정보만을 이용하여 검출을 수 행하므로 물체검출 성능 향상에 도움을 줄 수 있다. 도 4는 본 발명의 일 실시예에 따른 비디오 시간 정보를 활용하는 딥러닝 기반 물체 검출 장치의 구성을 나타내 는 도면이다. 비디오 시간 정보를 활용하는 딥러닝 기반 물체 검출 장치는 지역정보 및 시간정보 융합부 및 물체 검출부를 포함한다. 지역정보 및 시간정보 융합부 및 물체 검출부는 도 1의 단계들(110~120)을 수행하기 위해 구성될 수 있다. 지역정보 및 시간정보 융합부는 카메라 센서 데이터를 입력으로 하는 딥뉴럴 네트워크를 이용하여 검출하 고자 하는 물체에 대한 지역정보와 함께 현재 프레임과 이전 프레임과의 상관관계를 표현하는 시간정보를 융합 한다. 입력되는 카메라 센서 데이터의 이전 프레임과 현재 프레임에 대한 영상 정보가 시간 축에 따라 분리된 네트워 크에 각각 통과 된다. 각 네트워크 연산에 사용되는 웨이트는 시간 축에 대해 서로 공유되고, 물체에 대한 지역 정보와 함께 별도의 CNN구조를 활용하여 얻은 시간정보를 이용한다. 시간 축에 따라 분리된 네트워크를 통과한 출력 값은, 현재 프레임에 대한 물체 검출을 수행하기 위해 필요한 정보를 이전 프레임 영상으로부터 얻기 위하여 현재 프레임과의 연관성을 이용하는 TIE(Temporal information extractor) 구조로 입력된다. 이후, 각 프레임의 웨이트를 GIF(Gated Information Fusion) 기법을 이용하여 판단한 뒤 지역정보와 시간정보를 융합한다. GIF 기법을 통해 라이다에서 얻은 포인트 클라우드로 만들어진 전방 이미지로부터의 원본 특징지도의 웨이트와 카메라 이미지로부터의 원본 특징지도의 웨이트를 판단하고, 각 이미지에서 얻은 특징지도를 이어 붙 여서 얻은 특징지도를 이용하여 단일채널 특징지도를 만든다. 이러한 단일채널 특징지도와 원본 특징지도들을 이용하여 각 시간별 특징 지도를 만든다. 물체 검출부는 현재 프레임과 이전 프레임과의 상관관계에 따라 이전 프레임의 정보의 사용 정도를 결정하 여 물체 검출을 수행한다. <표 3>"}
{"patent_id": "10-2019-0050429", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "표 3은 제안하는 기술과 기존 알고리즘의 성능을 비교한 도표이다. 검출기의 성능은 mAP(Mean Average Precision)로 나타내었고 트레이닝을 위한 데이터는 KITTI를 사용하였다. KITTI 데이터는 물체 검출의 난이도에 따라 Easy, Moderate, Hard로 나눠지고 차에 대한 검출 결과를 위 표에서 나타냈다. 결과를 보면 종래 기술인 레티나넷(Retinanet)보다 Easy는 0.9프로, Moderate은 0.5프로가 상승한 효과를 볼 수 있다. 이와 같이 제안하는 기술은 위의 종래 기술의 문제점을 다음과 같이 해결해준다. 먼저, 종래의 딥러닝 기반 물 체 인지 기술은 딥뉴럴 네트워크의 특징지도에서 지역 정보만을 활용하여 물체 검출을 수행하지만, 제안하는 기 술은 현재 검출하고자 하는 프레임정보 뿐만이 아니라 이전 프레임의 정보를 같이 활용하기 때문에 이전에 검출 되었다가 가려진 물체에 대한 정보를 가져와서 현재 프레임에서 물체를 검출하는 데에 큰 도움이 된다. 두 프레 임의 상호작용을 적용하기 위해 센서융합에서 사용했던 GIF 구조를 사용하였고 이 구조를 사용함으로써 이전 프 레임의 정보에 대한 중요도를 네트워크가 직접 학습하여 필요한 정보만 가져오게 되었다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPA(field programmable array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로"}
{"patent_id": "10-2019-0050429", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "설명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크 로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이 터는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2019-0050429", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성 될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2019-0050429", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 비디오 시간 정보를 활용하는 딥러닝 기반 물체 검출 방법을 설명하기 위한 흐름도이다. 도 2는 본 발명의 일 실시예에 따른 시간정보를 이용하여 물체 검출을 수행하기 위한 딥뉴럴 네트워크 구조를 나타내는 도면이다. 도 3은 본 발명의 일 실시예에 따른 이전과 현재 프레임 정보를 융합하기 위한 딥뉴럴 네트워크 구조를 나타내 는 도면이다. 도 4는 본 발명의 일 실시예에 따른 비디오 시간 정보를 활용하는 딥러닝 기반 물체 검출 장치의 구성을 나타내 는 도면이다."}
