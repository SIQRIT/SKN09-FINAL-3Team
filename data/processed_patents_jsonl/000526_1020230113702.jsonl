{"patent_id": "10-2023-0113702", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0031788", "출원번호": "10-2023-0113702", "발명의 명칭": "디지털-아날로그 메모리 통합형 딥러닝 가속기 시스템 및 이를 이용한 인공신경망 학습 방법", "출원인": "포항공과대학교 산학협력단", "발명자": "김세영"}}
{"patent_id": "10-2023-0113702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "온칩(on-chip) 학습을 위한 가중치(weight)를 저장하는 디지털 방식의 제1 어레이를 구현하는 메인 디지털소자;상기 온칩 학습 동안 상기 가중치에 관한 기울기 정보(gradient information)를 업데이트하여 저장하는 아날로그 방식의 제2 어레이를 구현하는 아날로그 소자; 및상기 제2 어레이로부터 독출된 값을 저장하고 임계값을 초과하는 경우 해당 값을 상기 제1 어레이에게 전달하는상기 디지털 방식의 제3 어레이를 구현하는 서브 디지털 소자;를 포함하고,상기 제1 어레이, 상기 제2 어레이 및 상기 제3 어레이로 구성된 어레이 셋을 통해 매트릭스 단위의 학습 과정을 수행하는 디지털-아날로그 메모리 통합형 딥러닝 가속기 시스템."}
{"patent_id": "10-2023-0113702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 메인 디지털 소자는상기 온칩 학습 동안 상기 가중치를 기초로 순방향 전파(Forward propagation) 단계 및 오류 역전파(Errorbackpropagation) 단계를 통해 활성화(activation) 연산 및 오차(error) 연산을 수행하는 것을 특징으로 하는디지털-아날로그 메모리 통합형 딥러닝 가속기 시스템."}
{"patent_id": "10-2023-0113702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 아날로그 소자는매트릭스-벡터 곱 연산을 완전 병렬(fully parallel)적으로 수행한 결과로서 상기 기울기 정보를 업데이트하는것을 특징으로 하는 디지털-아날로그 메모리 통합형 딥러닝 가속기 시스템."}
{"patent_id": "10-2023-0113702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 아날로그 소자는상기 제1 어레이로부터 전달받은 활성화(activation) 값 및 오차(error) 값 간의 외적 연산(outer product)을기초로 상기 업데이트를 위한 업데이트 크기를 결정하는 것을 특징으로 하는 디지털-아날로그 메모리 통합형 딥러닝 가속기 시스템."}
{"patent_id": "10-2023-0113702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 서브 디지털 소자는원-핫 벡터(One-Hot Vector))와의 매트릭스-벡터 곱 연산을 통해 상기 제2 어레이로부터 독출된 값을 업데이트하여 저장하는 것을 특징으로 하는 디지털-아날로그 메모리 통합형 딥러닝 가속기 시스템."}
{"patent_id": "10-2023-0113702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 서브 디지털 소자는공개특허 10-2025-0031788-3-상기 제2 어레이로부터 독출된 값에 학습률(learning rate)을 적용하여 업데이트 크기를 조정하는 것을 특징으로 하는 디지털-아날로그 메모리 통합형 딥러닝 가속기 시스템."}
{"patent_id": "10-2023-0113702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서, 상기 서브 디지털 소자는상기 제2 어레이로부터 독출된 값을 행(row) 단위로 누적하여 저장하는 것을 특징을 하는 디지털-아날로그 메모리 통합형 딥러닝 가속기 시스템."}
{"patent_id": "10-2023-0113702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "디지털 방식의 어레이를 구현하는 메인 디지털 소자와 서브 디지털 소자, 그리고 아날로그 방식의 어레이를 구현하는 아날로그 소자를 포함하는 디지털-아날로그 메모리 통합형 딥러닝 가속기 시스템에서 수행되는 인공신경망 학습 방법에 있어서,상기 메인 디지털 소자의 가중치(weight)를 기초로 순방향 전파(Forward propagation) 단계 및 오류 역전파(Error backpropagation) 단계를 수행하는 단계;상기 순방향 전파 단계 및 오류 역전파 단계의 활성화(activation) 값 및 오차(error) 값을 이용하여 상기 아날로그 소자의 기울기 정보를 업데이트하는 단계; 및상기 아날로그 소자로부터 독출되어 상기 서브 디지털 소자에 저장되는 상기 기울기 정보 중에서 임계값을 초과하는 값을 이용하여 상기 메인 디지털 소자의 가중치를 업데이트하는 단계;를 포함하는 인공신경망 학습 방법."}
{"patent_id": "10-2023-0113702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 기울기 정보를 업데이트하는 단계는매트릭스-벡터 곱 연산을 완전 병렬(fully parallel)적으로 수행하여 상기 기울기 정보를 업데이트하는 단계를포함하는 것을 특징으로 하는 인공신경망 학습 방법."}
{"patent_id": "10-2023-0113702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 상기 가중치를 업데이트하는 단계는상기 아날로그 소자로부터 독출된 값을 원-핫 벡터(One-Hot Vector))와 매트릭스-벡터 곱 연산하여 업데이트한후 상기 서브 디지털 소자에 저장하는 단계를 포함하는 것을 특징으로 하는 인공신경망 학습 방법."}
{"patent_id": "10-2023-0113702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 가중치를 업데이트하는 단계는상기 아날로그 소자로부터 독출된 값에 학습률(learning rate)을 적용하여 업데이트 크기를 조정하는 단계를 포함하는 것을 특징으로 하는 인공신경망 학습 방법."}
{"patent_id": "10-2023-0113702", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 디지털-아날로그 메모리 통합형 딥러닝 가속기 시스템 및 이를 이용한 인공신경망 학습 방법에 관한 것으로, 상기 딥러닝 가속기 시스템은 온칩(on-chip) 학습을 위한 가중치(weight)를 저장하는 디지털 방식의 제1 어레이를 구현하는 메인 디지털 소자; 상기 온칩 학습 동안 상기 가중치에 관한 기울기 정보(gradient information)를 업데이트하여 저장하는 아날로그 방식의 제2 어레이를 구현하는 아날로그 소자; 및 상기 제2 어 레이로부터 독출된 값을 저장하고 임계값을 초과하는 경우 해당 값을 상기 제1 어레이에게 전달하는 상기 디지털 방식의 제3 어레이를 구현하는 서브 디지털 소자;를 포함하고, 상기 제1 어레이, 상기 제2 어레이 및 상기 제3 어레이로 구성된 어레이 셋을 통해 매트릭스 단위의 학습 과정을 수행한다."}
{"patent_id": "10-2023-0113702", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공신경망 구현 기술에 관한 것으로, 보다 상세하게는 아날로그 및 디지털 방식으로 구현된 어레이 들을 혼합하여 뉴럴 네트워크를 빠르게 가속시킴으로써 정밀성이 낮은 디지털 소자에서 학습이 가능한 동시에 높은 연산 속도와 에너지 효율성을 제공하는 인공 신경망 구현 방법에 관한 것이다."}
{"patent_id": "10-2023-0113702", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 들어 뉴럴 네트워크를 하드웨어적으로 구현한 뉴로모픽 소자에 대한 연구가 다양한 방향으로 진행되고 있 다. 뉴로모픽 소자는 생체의 뇌신경계를 이루는 뉴런과 시냅스의 구조를 모방한 것으로, 대체로 시냅스 전에 위 치한 시냅스 전 뉴런(Pre neuron), 시냅스, 시냅스 후에 위치한 시냅스 후 뉴런(Post neuron)의 구조를 포함할 수 있다. 시냅스는 뉴런과 뉴런 사이의 연결 지점으로써, 양쪽 뉴런에서 발생한 스파이크 (spike) 신호에 따라 시냅스 가중치 (synaptic weight)를 업데이트하고(updating), 이를 저장하는(memorizing) 기능을 포함할 수 있 다. 시냅스 소자 어레이를 기반으로 구현된 딥러닝 가속기는 뉴럴 네트워크의 학습을 가속화하기 위한 전용 장치에 해당할 수 있다. 시냅스 소자 어레이는 아날로그 방식 또는 디지털 방식으로 구현될 수 있으며, 시냅스 소자 어 레이의 구현 방식에 따라 디지털 가속기 또는 아날로그 가속기로 구분될 수 있다. 디지털 가속기의 경우 순차적 인 연산 방식을 사용하게 되면서 어레이가 커질수록 연산의 속도가 느려지는 단점이 있으며, 차지하는 면적이 많다는 단점이 존재할 수 있다. 반면, 아날로그 가속기의 경우 멀티 레벨을 저장할 수 있기 때문에 작은 면적에 서 많은 양의 정보를 저장할 수 있으며, 행렬 연산을 완전 병렬적으로 수행할 수 있다는 장점을 가질 수 있다. 따라서, 각 어레이의 장점만을 이용하여 딥러닝 가속기를 구현하는 경우 보다 빠르고 저전력이며 효율적인 연산 을 수행하는 가속기 시스템의 구현할 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 제10-2022-0059396호 (2022.05.10)"}
{"patent_id": "10-2023-0113702", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예는 뉴로모픽 시스템(neuromorphic system)을 구현하기 위해서 디지털과 아날로그 방식의 디 바이스를 혼합한 형태의 인 메모리 컴퓨팅 장치를 설계할 수 있고, 디지털 디바이스의 장점과 아날로그 디바이 스의 장점을 기초로 이들의 장점을 살릴 수 있는 위치에 각각의 디바이스를 배치한 형태의 새로운 디바이스 셋 을 제공하고자 한다."}
{"patent_id": "10-2023-0113702", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예들 중에서, 디지털-아날로그 메모리 통합형 딥러닝 가속기 시스템은 온칩(on-chip) 학습을 위한 가중치 (weight)를 저장하는 디지털 방식의 제1 어레이를 구현하는 메인 디지털 소자; 상기 온칩 학습 동안 상기 가중 치에 관한 기울기 정보(gradient information)를 업데이트하여 저장하는 아날로그 방식의 제2 어레이를 구현하 는 아날로그 소자; 및 상기 제2 어레이로부터 독출된 값을 저장하고 임계값을 초과하는 경우 해당 값을 상기 제 1 어레이에게 전달하는 상기 디지털 방식의 제3 어레이를 구현하는 서브 디지털 소자;를 포함하고, 상기 제1 어 레이, 상기 제2 어레이 및 상기 제3 어레이로 구성된 어레이 셋을 통해 매트릭스 단위의 학습 과정을 수행한다. 상기 메인 디지털 소자는 상기 온칩 학습 동안 상기 가중치를 기초로 순방향 전파(Forward propagation) 단계 및 오류 역전파(Error backpropagation) 단계를 통해 활성화(activation) 연산 및 오차(error) 연산을 수행할 수 있다. 상기 아날로그 소자는 매트릭스-벡터 곱 연산을 완전 병렬(fully parallel)적으로 수행한 결과로서 상기 기울기 정보를 업데이트할 수 있다. 상기 아날로그 소자는 상기 제1 어레이로부터 전달받은 활성화(activation) 값 및 오차(error) 값 간의 외적 연 산(outer product)을 기초로 상기 업데이트를 위한 업데이트 크기를 결정할 수 있다. 상기 서브 디지털 소자는 원-핫 벡터(One-Hot Vector))와의 매트릭스-벡터 곱 연산을 통해 상기 제2 어레이로부 터 독출된 값을 업데이트하여 저장할 수 있다. 상기 서브 디지털 소자는 상기 제2 어레이로부터 독출된 값에 학습률(learning rate)을 적용하여 업데이트 크기 를 조정할 수 있다. 상기 서브 디지털 소자는 상기 제2 어레이로부터 독출된 값을 행(row) 단위로 누적하여 저장할 수 있다. 실시예들 중에서, 인공신경망 학습 방법은 상기 메인 디지털 소자의 가중치(weight)를 기초로 순방향 전파 (Forward propagation) 단계 및 오류 역전파(Error backpropagation) 단계를 수행하는 단계; 상기 순방향 전파 단계 및 오류 역전파 단계의 활성화(activation) 값 및 오차(error) 값을 이용하여 상기 아날로그 소자의 기울 기 정보를 업데이트하는 단계; 및 상기 아날로그 소자로부터 독출되어 상기 서브 디지털 소자에 저장되는 상기 기울기 정보 중에서 임계값을 초과하는 값을 이용하여 상기 메인 디지털 소자의 가중치를 업데이트하는 단계;를 포함할 수 있다. 상기 기울기 정보를 업데이트하는 단계는 매트릭스-벡터 곱 연산을 완전 병렬(fully parallel)적으로 수행하여 상기 기울기 정보를 업데이트하는 단계를 포함할 수 있다. 상기 가중치를 업데이트하는 단계는 상기 아날로그 소자로부터 독출된 값을 원-핫 벡터(One-Hot Vector))와 매 트릭스-벡터 곱 연산하여 업데이트한 후 상기 서브 디지털 소자에 저장하는 단계를 포함할 수 있다. 상기 가중치를 업데이트하는 단계는 상기 아날로그 소자로부터 독출된 값에 학습률(learning rate)을 적용하여 업데이트 크기를 조정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0113702", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시된 기술은 다음의 효과를 가질 수 있다. 다만, 특정 실시예가 다음의 효과를 전부 포함하여야 한다거나 다 음의 효과만을 포함하여야 한다는 의미는 아니므로, 개시된 기술의 권리범위는 이에 의하여 제한되는 것으로 이 해되어서는 아니 될 것이다. 본 발명의 일 실시예에 따른 디지털-아날로그 메모리 통합형 딥러닝 가속기 시스템 및 이를 이용한 인공신경망 학습 방법은 아날로그 저항 변화형 메모리 소자와 디지털 메모리 어레이를 한 개의 칩으로 집적하고 디지털 어 레이와 아날로그 어레이의 장단점을 이용하여 각 어레이의 장점을 극대화할 수 있는 알고리즘을 도입하고 역할 을 부여함으로써, 연산 정확도를 높이고 완전 병렬적인 연산 기능을 최대한 활용하며 Bit precision을 낮춘 디 지털 어레이를 사용하여 연산 정확성과 효율성을 챙길 수 있으며, 이를 통해 디지털 가속기의 장점과 아날로그 가속기의 장점을 극대화하면서 단점을 상쇄하여 인공지능 학습 연산의 성능을 향상시킬 수 있는 새로운 가속기 를 구현할 수 있도록 한다."}
{"patent_id": "10-2023-0113702", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에 관한 설명은 구조적 내지 기능적 설명을 위한 실시예에 불과하므로, 본 발명의 권리범위는 본문에 설 명된 실시예에 의하여 제한되는 것으로 해석되어서는 아니 된다. 즉, 실시예는 다양한 변경이 가능하고 여러 가 지 형태를 가질 수 있으므로 본 발명의 권리범위는 기술적 사상을 실현할 수 있는 균등물들을 포함하는 것으로 이해되어야 한다. 또한, 본 발명에서 제시된 목적 또는 효과는 특정 실시예가 이를 전부 포함하여야 한다거나 그러한 효과만을 포함하여야 한다는 의미는 아니므로, 본 발명의 권리범위는 이에 의하여 제한되는 것으로 이해 되어서는 아니 될 것이다. 한편, 본 출원에서 서술되는 용어의 의미는 다음과 같이 이해되어야 할 것이다. \"제1\", \"제2\" 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위한 것으로, 이들 용어들에 의해 권리범위가 한정되어서는 아니 된다. 예를 들어, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\"있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결될 수 도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\"있다고 언급된 때에는 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 한편, 구성요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃 하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함하는 것으로 이해되어야 하고, \"포함 하다\"또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 각 단계들에 있어 식별부호(예를 들어, a, b, c 등)는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단 계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순 서와 다르게 일어날 수 있다. 즉, 각 단계들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수 행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 본 발명은 컴퓨터가 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 코드로서 구현될 수 있고, 컴퓨터가 읽을 수 있는 기록 매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록 장치를 포함 한다. 컴퓨터가 읽을 수 있는 기록 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 컴퓨터가 읽을 수 있는 기록 매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 여기서 사용되는 모든 용어들은 다르게 정의되지 않는 한, 본 발명이 속하는 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 용어들은 관 련 기술의 문맥상 가지는 의미와 일치하는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한 이 상적이거나 과도하게 형식적인 의미를 지니는 것으로 해석될 수 없다. 도 1a는 디지털 방식의 어레이에 사용되는 디지털 소자의 일 실시예를 설명하는 도면이고, 도 1b는 아날로그 방 식의 어레이에 사용되는 아날로그 소자의 일 실시예를 설명하는 도면이다. 도 1a를 참조하면, 디지털 방식의 어레이는 0과 1의 두 가지 정보를 저장하도록 구현된 복수의 디지털 소자들을 포함하여 구현될 수 있다. 이때, 복수의 디지털 소자들은 제1 방향의 비트라인(BL)과 제2 방향의 워드라인(WL) 이 교차하는 영역에 각각 배치된 결과 m×n 크기의 어레이를 형성할 수 있다. 도 1b를 참조하면, 아날로그 방식의 어레이는 최솟값과 최댓값 사이에 수많은 값의 정보를 저장하도록 구현된 복수의 아날로그 소자들을 포함하여 구현될 수 있다. 예를 들어, 복수의 아날로그 소자들은 ReRAM(Resistive RAM), PCM(Phase Change Memory), FeRAM(Ferroelectric RAM), ECRAM(Electrochemical RAM) 등을 포함할 수 있 다. 이때, 복수의 아날로그 소자들은 평행적으로 모든 값을 한번에 업데이트 할 수 있다는 장점을 가질 수 있다. 그러나, 아날로그 소자는 동일한 컨덕턴스 값을 갖고 있는 상태에서도 컨덕턴스의 증감 방향에 따라 한 번에 업데이트되는 컨덕턴스의 양이 달라질 수 있다. 이처럼, 아날로그 소자는 다양한 비이상성(non- ideality)들이 나타날 수 있는 단점을 가질 수 있다.도 2a는 아날로그 방식의 어레이에서 발생할 수 있는 비이상성 중 비대칭적 갱신 특성을 설명하는 도면이고, 도 2b는 아날로그 방식의 어레이에서 발생할 수 있는 비이상성 중 낮은 유지성(low retention) 특성을 설명하는 도 면이다. 도 2a를 참조하면, 두 개의 서로 다른 장치에 대한 펄스 응답 및 가중치 변조 특성(weight modulation characteristic)이 도시되어 있다. 먼저 왼쪽 상단 및 하단의 그림은 선형이고 대칭적인 디바이스의 펄스 응답 에 해당할 수 있다. 가중치 증가(빨간색) 및 감소(파란색)는 크기가 동일하게 나타날 수 있으며, 가중치에 의존 하지 않을 수 있다. 이러한 유형의 디바이스 동작은 일반적으로 SGD(Stochastic Gradient Descent)에 필요한 이 상적인 장치에 대응될 수 있다. 즉, 이상적인 아날로그 소자는 +방향과 -방향에서의 업데이트 경향성이 완벽하 게 대칭적일 수 있으며, 매우 작은 소음(noise), 유지(retention) 및 분산(variance)을 가질 수 있다. 또한, 오른쪽 상단 및 하단의 그림은 기하급수적으로 포화되고 비대칭적인 디바이스의 펄스 응답에 해당할 수 있다. 즉, 가중치 증가 및 감소 모두 가중치에 선형 종속성을 가질 수 있다. 그러나, 가중치 증가와 감소의 강 도(strength)가 서로 동일한 단일 가중치 값이 존재할 수 있으며, 해당 포인트는 대칭점(symmetry point)에 해 당하고 그림에서 w=0에 대응될 수 있다. 즉, 일반적인 아날로그 소자는 +방향과 -방향에서 업데이트 경향성이 상이할 수 있으며, 소음, 유지, 분산 및 상태의 수와 같은 부분에서 비 이상성을 가질 수 있다. 따라서, 비선형 적 특성을 가지므로 +방향과 -방향의 업데이트 경향성이 대칭되는 지점인 대칭점을 찾고, 해당 지점을 '0'포인 트로 설정한 후 동작을 진행시킬 필요가 있다. 도 3은 본 발명에 따른 어레이 셋의 구성을 설명하는 도면이다. 도 3을 참조하면, 본 발명에 따른 디지털-아날로그 메모리 통합형 딥러닝 가속기 시스템은 제1 어레이, 제 2 어레이 및 제3 어레이로 구성된 어레이 셋(set)을 통해 매트릭스 단위의 학습 과정을 수행할 수 있다. 이때, 제1 어레이와 제3 어레이는 디지털 방식으로 구현된 시냅스 소자 어레이에 해당할 수 있으며, 제2 어레이는 아 날로그 방식으로 구현된 시냅스 소자 어레이에 해당할 수 있다. 구체적으로, 딥러닝 가속기 시스템은 디지털 방식의 제1 어레이를 구현하는 메인 디지털 소자, 아날 로그 방식의 제2 어레이를 구현하는 아날로그 소자, 그리고 디지털 방식의 제3 어레이를 구현하는 서브 디 지털 소자를 포함할 수 있다. 즉, 딥러닝 가속기 시스템은 아날로그 방식의 어레이의 장단점과 디지 털 어레이의 장단점을 조합하여 알맞은 위치에 디지털과 아날로그 어레이를 조합하여 하나의 어레이 셋을 설계 할 수 있다. 메인 디지털 소자는 완전 온칩(fully on-chip) 학습을 위한 가중치(weight)를 저장할 수 있다. 여기에서, 가중치는 시냅스 소자의 연결 강도를 나타낼 수 있으며, 시냅스 소자의 전하 저장층 영역에 전자 또는 정공을 주입하여 컨덕턴스를 조절함에 따라 조절될 수 있다. 즉, 인공신경망의 학습 과정이 진행됨에 따라 메인 디지털 소자에 저장된 가중치는 계속적으로 업데이트될 수 있다. 일 실시예에서, 메인 디지털 소자는 온칩 학습 동안 가중치를 기초로 순방향 전파(Forward propagation) 단계 및 오류 역전파(Error backpropagation) 단계를 통해 활성화(activation) 연산 및 오차(error) 연산을 수 행할 수 있다. 즉, 온칩 학습의 순방향 전파 단계는 인공신경망의 입력 데이터가 여러 층의 신경망을 따라 신호 를 전파하면서 최종적인 출력을 생성하는 과정에 해당할 수 있다. 순방향 전파 단계에서는 최종 출력을 생성하 는 과정에서 활성화 연산을 통해 활성화 값이 산출될 수 있다. 또한, 온칩 학습의 오류 역전파 단계는 순방향 전파 단계에서 생성된 출력과 타깃과의 오차(error)를 산출한 뒤 역전파하는 과정에 해당할 수 있다. 오류 역전 파 단계에서는 오차 연산을 통해 출력과 타깃 간의 오차 값이 산출될 수 있다. 이때, 활성화 값과 오착값은 메 인 디지털 소자로부터 아날로그 소자에게 전달될 수 있다. 아날로그 소자는 온칩 학습 동안 가중치에 관한 기울기 정보(gradient information)를 업데이트하여 저장 할 수 있다. 여기에서, 기울기 정보는 가중치 값의 에러 변화값에 해당할 수 있다. 예를 들어, 기울기 정보는 가중치에 관한 손실 함수(loss function)의 기울기를 포함할 수 있다. 일 실시예에서, 아날로그 소자는 매트릭스-벡터(mat-vec) 곱 연산을 완전 병렬(fully parallel)적으로 수 행한 결과로서 기울기 정보를 업데이트할 수 있다. 즉, 아날로그 소자의 업데이트 과정은 하드웨어에 의한 병렬 업데이트(hardware-induced parallel update) 과정에 해당할 수 있다.일 실시예에서, 아날로그 소자는 제1 어레이로부터 전달받은 활성화(activation) 값 및 오차(error) 값 간 의 외적 연산(outer product)을 기초로 업데이트를 위한 업데이트 크기를 결정할 수 있다. 예를 들어, 업데이트 의 양을 결정하는 업데이트 크기는 활성화(activation) 값 및 오차(error) 값 간의 외적 연산(outer product) 의 결과에 사전 설정된 학습률(learning rate) 이 적용되어 결정될 수 있다. 서브 디지털 소자는 아날로그 소자의 제2 어레이로부터 독출된 값을 저장하고 임계값(threshold)을 초과하는 값을 메인 디지털 소자의 제1 어레이에게 전달하여 메인 디지털 소자에 저장된 가중치가 업 데이트되도록 할 수 있다. 이에 따라, 서브 디지털 소자는 저역 통과 필터(low pass filter)의 역할을 수 행할 수 있다. 즉, 서브 디지털 소자는 메인 디지털 소자의 비트 정밀도(bit precision)를 줄여주는 역할을 수행할 수 있다. 구체적으로, 서브 디지털 소자는 제2 어레이로부터 독출된 값을 누적하여 저장할 수 있으며, 누적 결과 특 정 임계값(예를 들어, 1)을 초과하는 값이 검출된 경우 해당 값을 메인 디지털 소자에 전달한 다음 해당 값은 0으로 초기화될 수 있다. 메인 디지털 소자로 전달된 값은 단일 펄스(single pulse)를 통해 병렬로 업데이트될 수 있다. 일 실시예에서, 서브 디지털 소자는 원-핫 벡터(One-Hot Vector))와의 매트릭스-벡터 곱 연산을 통해 아날 로그 소자의 제2 어레이로부터 독출된 값을 업데이트하여 저장할 수 있다. 예를 들어, 서브 디지털 소자 에 저장된 매트릭스는 원 핫 인코딩(One-Hot Encoding)된 벡터와 곱 연산될 수 있으며, 곱 연산에 의해 새 로운 벡터 v가 생성될 수 있다. 이후, 벡터 v는 서브 디지털 소자에 저장될 수 있으며, 벡터 v의 각 벡터 값은 서브 디지털 소자에 저장된 값에 누적되어 저장될 수 있다. 일 실시예에서, 서브 디지털 소자는 아날로그 소자의 제2 어레이로부터 독출된 값에 학습률(learning rate)을 적용하여 업데이트 크기를 조정할 수 있다. 예를 들어, mat-vec 연산을 통해 생성된 벡터 v의 각 벡터 값은 사전 설정된 학습률 와 연산된 후 서브 디지털 소자에 저장된 값에 누적되어 저장될 수 있으며, 학 습률 에 따라 업데이트의 양이 조정될 수 있다. 일 실시예에서, 서브 디지털 소자는 아날로그 소자의 제2 어레이로부터 독출된 값을 행(row) 단위로 누적하여 저장할 수 있다. 즉, 서브 디지털 소자에 저장되는 아날로그 어레이의 값은 행(row) 단위로 누적 되어 업데이트될 수 있다. 일 실시예에서, 서브 디지털 소자는 아날로그 소자로부터 전달받은 값들의 누적 값을 평균 낸 이동 평균 값(moving average)을 도출하고, 이동 평균 값을 다시 아날로그 소자로 전달할 수 있다. 이때, 이동 평균 값은 다음의 수학식 1과 같이 계산하여 메인 디지털 소자 또는 서브 디지털 소자로 넘어갈 때 업데이트 해줄 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0113702", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "또한, 이동 평균 값은 기존의 평균 값과 새로운 아날로그 소자의 값을 특정 비율로 더해주는 형태로 계산 될 수 있으며, 특정 비율은 윈도우(window)로 정의될 수 있다. 특정 비율은 일정하게 유지되거나 해당 값을 변 동하여 수렴 정도를 조절할 수 있다. 아날로그 소자의 평균 값 전달 시 계속적으로 평균 값을 업데이트하 여 이를 오프 셋(off set)으로 처리할 수 있으며, 비대칭적인 소자에서 발산하는 현상을 방지하기 위해서 업데 이트 시마다 주기적인 감쇠를 넣어줄 수 있다. 이때, 주기적인 감쇠는 0과 1사이의 감마 파라미터(gamma parameter)를 정의하고, 이를 이동 평균 값에 곱해줌 으로써 이동 평균 값을 감소시키는 방식으로 적용할 수 있다. 또한, 이동 평균값은 소자의 특성에 따라 최적화 되어야 하며, 적당한 값을 선택해 줄 경우 매끄러운(smooth) 곡선을 그려 업데이트 값이 빠르게 한 점으로 수렴 할 수 있다.도 4는 본 발명에 따른 딥러닝 가속기 시스템을 설명하는 도면이다. 도 4를 참조하면, 딥러닝 가속기 시스템은 디지털 방식으로 구현된 디지털 어레이와 아날로그 방식으 로 구현된 아날로그 어레이를 조합하여 학습 과정에서 각자의 역할을 담당하도록 함으로써 어레이 집합이 하나의 매트릭스의 학습을 수행하도록 하는 어레이 셋을 포함할 수 있다. 예를 들어, 도 3의 메인 디지털 소자 와 서브 디지털 소자는 디지털 어레이 상에 구현될 수 있고, 아날로그 소자는 아날로그 어 레이 상에 구현될 수 있다. 결과적으로, 딥러닝 가속기 시스템은 뉴로모픽 시스템(neuromorphic system)을 구현하기 위해서 디지털과 아날로그 방식의 디바이스를 혼합한 형태의 인 메모리 컴퓨팅 장치를 설계할 수 있고, 디지털 디바이스의 장점 과 아날로그 디바이스의 장점을 기초로 이들의 장점을 살릴 수 있는 위치에 각각의 디바이스를 배치한 형태의 새로운 디바이스 셋을 구현할 수 있다. 즉, 디지털 영역에서 구현되는 메인 디지털 어레이는 정확한 값을 저장해야 하므로 비이상성이 존재하지 않은 deterministic한 값을 저장할 수 있다. 반면, 아날로그 영역에서 구현되는 아날로그 어레이는 기울기(gradien t)의 외적 연산(outer product)을 빠르고 병렬적으로 수행하여 그 결과를 저장할 수 있다. 또한, 메인 디지털 어레이는 낮은 정밀도(low precision)를 가진 어레이 만으로도 연산이 가능하도록 하기 위해서 디지털 영역에서 구현된 다른 서브 디지털 어레이의 도움을 받을 수 있다. 도 5는 본 발명에 따른 인공신경망 학습 방법을 설명하는 순서도이다. 도 5를 참조하면, 딥러닝 가속기 시스템은 각 어레이의 장점만을 이용하여 디지털 및 아날로그 어레이를 적용한 듀얼 메모리 아키텍처를 구현할 수 있다. 예를 들어, 딥러닝 가속기 시스템은 2개의 디지털 어레이 와 하나의 아날로그 어레이로 구성된 어레이 셋에 Tiki-Taka version 2 학습 알고리즘을 도입하여 빠르고, 저전 력이며, 고효율의 연산을 수행할 수 있으며, 인공신경망을 위한 학습 방법을 온디바이스(on-device)로 수행할 수 있다. 일반적인 인공신경망은 입력 계층(Input layer), 은닉 계층(hidden layer) 및 출력 계층(output layer)으로 구 성될 수 있다. 이때, 여러 뉴런들이 모인 단위를 계층(layer)이라고 하며, 전결합 계층 구조는 각 계층의 모든 경우들이 연결되어 있는 구조에 해당할 수 있다. 즉, 입력 계층의 뉴런들과 출력 계층의 뉴런들이 연결될 수 있 는 모든 경우의 수와 동일하게 연결이 되어 있으면 전결합 계층(Fully Conneted Layer)에 해당할 수 있다. 또한, 입력 계층은 입력을 받아서 다음 계층인 은닉 계층으로 넘기는 역할을 할 수 있으며, 은닉 계층은 입력 계층과 연결된 전결합 계층으로서 복잡한 문제를 해결할 수 있게 하는 핵심적인 계층에 해당할 수 있다. 마지막 으로, 출력계층은 은닉 계층 다음에 오는 전결합 계층으로서 신경망의 외부로 출력 신호를 전달하는데 사용될 수 있으며, 신경망의 기능은 출력 계층의 활성 함수에 의해 결정될 수 있다. 신경망의 트레이닝 과정은 정방향 패스(forward pass) 및 역방향 패스(backward pass)로 구성될 수 있으며, 정 방향 패스는 들어온 입력 값이 은닉 계층들을 통과하여 출력 계층으로 진행하는 과정에 해당할 수 있다. 또한, 에러(error)값의 변화 값(gradient)은 역방향 패스를 통해 각 뉴런에 전달될 수 있으며, 이후 업데이트가 이루 어질 수 있다. 구체적으로, 본 발명에 따른 인공신경망 학습 방법은 메인 디지털 소자에 저장된 가중치를 이용하여 온칩 학습 동안 순방향 전파(Forward propagation) 단계 및 오류 역전파(Error backpropagation) 단계를 수행할 수 있다(단계 S410). 즉, 순방향 전파 단계 및 오류 역전파 단계를 통해 활성화(activation) 연산 및 오차(error) 연산이 수행될 수 있으며, 그 결과로 활성화 값과 오차 값이 산출될 수 있다. 이후, 학습에 따른 기울기 정보가 업데이트되어 아날로그 소자에 저장될 수 있다(단계 S430). 아날로그 소 자에 저장된 기울기 정보는 서브 디지털 소자에 의해 독출된 후 누적되어 저장될 수 있다. 서브 디지 털 소자에 누적된 결과 특정 임계값(예를 들어, 1)을 초과하는 값은 메인 디지털 소자에 전달될 수 있고, 메인 디지털 소자는 전달된 값을 통해 가중치를 업데이트할 수 있다(단계 S450). 한편, 비 이상성(non-ideality)을 보완할 수 있는 알고리즘(Tiki-Taka)에 대한 구조를 설명하면, 해당 알고리즘 은 메인 어레이인 C 매트릭스와, 서브 어레이이자 기울기 정보(gradient information)을 나타내는 A 매트릭스 2 개를 사용할 수 있으며, 특정한 학습 비율에 따라 C 매트릭스의 변화 값을 A 매트릭스에 업데이트, 특정 에포크(epoch)마다 A 매트릭스의 일부 값을 C 매트릭스에 업데이트함으로써 수행될 수 있다. Tiki-Taka version 2 학습 알고리즘의 경우, 여기에 새로운 어레이(또는 매트릭스)를 추가하여 비 이상성에 대 한 허용 오차(tolerance)를 높인 새로운 알고리즘에 해당할 수 있다. 새로운 매트릭스인 H 매트릭스는 메인 어 레이인 C 매트릭스와 함께 디지털 영역에서 구현될 수 있으며, A 매트릭스의 값이 전달되어 기존의 값에 누적됨 으로써 업데이트될 수 있다. 만약 누적된 값이 특정 임계값 이상일 경우 C 매트릭스로 전달되는 구조를 가질 수 있다. 상기에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특 허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2023-0113702", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 디지털 방식의 어레이에 사용되는 디지털 소자의 일 실시예를 설명하는 도면이다. 도 1b는 아날로그 방식의 어레이에 사용되는 아날로그 소자의 일 실시예를 설명하는 도면이다. 도 2a는 아날로그 방식의 어레이에서 발생할 수 있는 비이상성 중 비대칭적 갱신 특성을 설명하는 도면이다. 도 2b는 아날로그 방식의 어레이에서 발생할 수 있는 비이상성 중 낮은 유지성 특성을 설명하는 도면이다. 도 3은 본 발명에 따른 어레이 셋의 구성을 설명하는 도면이다. 도 4는 본 발명에 따른 딥러닝 가속기 시스템을 설명하는 도면이다. 도 5는 본 발명에 따른 인공신경망 학습 방법을 설명하는 순서도이다."}
