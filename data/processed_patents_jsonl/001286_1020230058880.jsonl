{"patent_id": "10-2023-0058880", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0162184", "출원번호": "10-2023-0058880", "발명의 명칭": "딥러닝 기반 공백 값을 유사 값으로 치환하여 현실감을 높이는 입체복원 작업으로 디지털트윈", "출원인": "주식회사 그라운드원", "발명자": "홍윤정"}}
{"patent_id": "10-2023-0058880", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "(A) 전자기기에서 2D 이미지 복수개를 전송하는 단계; 및(B) 메인 서버에서 2D 이미지를 수신하고, 수신한 이미지에서 오브젝트를 분류하고, 딥러닝 신경망을 통해 학습하여 오브젝트의 가상 3차원 좌표 설정 값과 포인트 클라우드를 병합하고, 병합한 데이터를 통해 생성된 3D 메쉬를 이용하여 오브젝트 고유의 재질 값을 투영하여 3D 모델링을 자동 생성하는 단계; 를 포함하는 딥러닝 기반의 3D 모델링 자동생성 방법."}
{"patent_id": "10-2023-0058880", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "딥러닝 기반 공백 값을 유사 값으로 치환하여 현실감을 높이는 입체복원 작업으로 디지털트윈을 구현하는 3D 모 델링 자동생성 방법을 제공한다."}
{"patent_id": "10-2023-0058880", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥러닝 기반 공백 값을 유사 값으로 치환하여 현실감을 높이는 입체복원 작업으로 디지털트윈을 구현 하는 3D 모델링 자동생성 방법에 관한 것이다."}
{"patent_id": "10-2023-0058880", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 명세서에서 달리 표시되지 않는 한, 이 섹션에 설명되는 내용들은 이 출원의 청구항들에 대한 종래 기술이 아니며, 이 섹션에 포함된다고 하여 종래 기술이라고 인정되는 것은 아니다. 디지털 트윈(digital twin)은 컴퓨터에 현실 속 사물의 쌍둥이를 만들고, 현실에서 발생할 수 있는 상황을 컴퓨 터로 시뮬레이션함으로써 결과를 미리 예측하는 기술이다. 디지털 트윈은 제조업뿐만 아니라 다양한 산업, 사회 문제를 해결할 수 있는 기술로 주목받는다. 그리고 기본적으로 다양한 물리적 시스템의 구조, 맥락, 작동을 나 타내는 데이터와 정보의 조합으로, 과거와 현재의 운용 상태를 이해하고 미래를 예측할 수 있는 인터페이스라고 할 수 있다. 디지털 트윈은 물리적 세계를 최적화하기 위해 사용될 수 있는 강력한 디지털 객체로서, 운용 성능 과 사업 프로세스를 대폭 개선할 수 있다. 정보 통신 기술이 발전하며, 디지털 트윈에 대한 수요가 급격히 늘고 있다. 디지털 트윈은 3차원 모델링을 통해 생성될 수 있다. 한편, 컴퓨터상에서의 3D 모델은 그 크기를 실제의 크기에서 축척에 의하여 축소 또는 확대하여 컴퓨터상에서 볼 수 있도록 한 것이므로, 설계자가가 컴퓨터상에서 3D 모델의 설계상 문제점들을 용이하게 체크확인 수 있고, 각 펌프, 모터, 파이프, 밸브, 트레이, 덕트 라인, 각종 피팅류 등이 전체적으로 연결되어 있는지 여부, 예를 들어 전체 배관이 완성되었는지를 쉽게 확인할 수도 있다. 3D 모델링의 경우 각종 시공상의 문제점들, 예를 들어 배관 라인이 다른 장비나 밸브 또는 구조물 등과 부딪히 는 경우나, 배관 라인이 전기, 계장 트레이와 간섭되는지 여부를 쉽게 찾아낼 수 있는 기능도 가지고 있어, 현 재 대부분의 엔지니어링사, 건설사 및 중공업사에서 3D 그래픽 설계 프로그램을 많이 사용하고 있다. 하지만, 종래 3D 모델 생성을 위해서는 많은 부분을 수작업으로 직접 진행해야 하는 번거로움이 있다."}
{"patent_id": "10-2023-0058880", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 딥러닝 기반 공백 값을 유사 값으로 치환하여 현실감을 높이는 입체복원 작 업으로 디지털트윈을 구현하는 3D 모델링 자동생성 방법을 제공하는 것이다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0058880", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명의 방법은 (A) 전자기기에서 2D 이미지 복수개를 전송하는 단계; (B) 메인 서버에서 2D 이미지를 수신하고, 수신한 이미지에서 오브젝트를 분류하고, 딥러닝 신경망을 통해 학습하여 오브 젝트의 가상 3차원 좌표 설정 값과 포인트 클라우드를 병합하고, 병합한 데이터를 통해 생성된 3D 메쉬를 이용 하여 오브젝트 고유의 재질 값을 투영하여 3D 모델링을 자동 생성하는 단계; 를 포함하는 것을 특징으로 할 수 있다."}
{"patent_id": "10-2023-0058880", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서와 같은 딥러닝 기반의 3D 모델링 자동생성 시스템 및 방법은 오브젝트에 대한 소수의 2D 이미지를 통 해 이미지에 포함된 오브젝트를 3D 모델링 이미지로 자동으로 생성할 수 있도록 한다. 실시예에서는 3D 모델링 의 완벽성을 위해, 비어 있는 값들을 유사한 값으로 채우며 현실감을 높이는 입체복원 작업으로 증강현실 기법 을 경제적, 효과적으로 구현할 수 있다. 또한, 3D 모델링을 자동 생성하여 생성 시간을 대폭 단축할 수 있다."}
{"patent_id": "10-2023-0058880", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0058880", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야의 통상의 기술자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단 지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 도 1은 실시예에 따른 딥러닝 기반의 3D 모델링 자동생성 시스템 구성을 나타낸 도면이다. 도 1을 참조하면, 실 시예에 따른 딥러닝 기반의 3D 모델링 자동 생성 시스템은 전자기기 및 메인 서버를 포함하여 구성될 수 있다. 실시예에서 전자기기는 사용자 단말을 포함하는 스마트 기기로, 2D 이미지 복수개를 메인서버로 전송 한다. 메인 서버는 이미지를 수신하고, 이미지에 포함된 오브젝트를 분류하고, 딥러닝 신경망을 통해 학습 하여 오브젝트의 가상 3차원 좌표 설정 값과 포인트 클라우드를 병합한다. 이후 메인서버는 병합된 데이터 를 이용하여 3D 메쉬를 생성하고, 생성된 3D 메쉬를 통해 오브젝트 고유의 재질 값을 투영하여 3D 모델링을 자 동 생성한다.실시예에서, 적어도 하나의 전자기기는, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨 터로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 이때, 적어도 하나의 전자기기는, 네트워크를 통 해 원격지의 서버나 단말에 접속할 수 있는 단말로 구현될 수 있다. 적어도 하나의 전자기기는, 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트폰(smartphone), 스마트 패드(smartpad), 태블릿 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 실시예에 따른 딥러닝 기반의 3D 모델링 자동생성 시스템 및 방법은 단말기, PC 등의 전자기기로부터 수신한 2D 이미지를 처리하여 딥러닝 모델을 기반으로 3D 모델링을 자동 생성할 수 있도록 한다. 또한, 실시예를 통한 딥 러닝 기반의 3D 모델링 자동생성 시스템 및 방법은 건축물과 같은 건물 도면의 경우, 2D 이미지만으로는 보이지 않는 부분을 딥러닝을 통해 채워넣어, 잘 보이지 않는 부분도 3D모델링 도면을 통해 확인할 수 있도록 한다. 또한, 실시예에서는 확장된 3차원의 위치 값에 특징 값을 매칭하고 매칭된 특징 값에 따라 3D 메쉬(mesh)를 생 성한다. 실시예에서 3D 메쉬는 오브젝트 안의 정점(Vertex)간의 연결 관계를 고려하여 학습된다. 또한, 실시예 에서는 3D 모델링을 한 표면을 층으로 두어 구성하고, 위치 값을 설정할 고정 기준을 완성하기 때문에 층을 기 준으로 오브젝트를 적용하여 3D 모델링을 자동 생성할 수 있도록 한다. 도 2는 실시예에 따른 메인 서버의 데이터 처리 구성을 나타낸 도면이다. 도 2를 참조하면, 실시예에 따른 메인서버은 이미지 수집 모듈, 제1 생성모듈, 제2 생성 모듈, 변환모듈, 설정모듈 및 피드백 모듈을 포함하여 구성될 수 있다. 본 명세서에서 사용되는 '모듈' 이라는 용어는 용어가 사용된 문맥에 따라서, 소프트웨어, 하드웨어 또는 그 조합을 포함할 수 있는 것으로 해석되어야 한다. 예를 들 어, 소프트웨어는 기계어, 펌웨어(firmware), 임베디드코드(embedded code), 및 애플리케이션 소프트웨어일 수 있다. 또 다른 예로, 하드웨어는 회로, 프로세서, 컴퓨터, 집적 회로, 집적 회로 코어, 센서, 멤스(MEMS; Micro-Electro-Mechanical System), 수동 디바이스, 또는 그 조합일 수 있다. 이미지 수집 모듈은 전자기기로부터 복수개의 2D 이미지를 수신한다. 제1 생성모듈은 수신한 2D 이미 지의 배경과 오브젝트를 딥러닝 신경망을 통해 분류하고, 각 이미지를 통해 선택된 오브젝트의 고유 값을 병합 하여 단일 설정값을 생성한다. 실시예에서 제1생성 모듈은 딥러닝 신경망을 통한 분류 및 3D 모델링을 생 성하기 위해 DNN(Deep Neural Network), CNN(Convolutional Neural Network) RNN(Recurrent Neural Network) 및 BRDNN(Bidirectional Recurrent Deep Neural Network) 중 적어도 하나를 포함하는 딥러닝 뉴럴 네트워크를 트레이닝 데이터 셋으로 학습시킬 수 있다. 제2 생성모듈은 포인트 클라우드를 생성한 후 각 오브젝트의 특징 값으로, 단일 설정값을 가진 오브젝트의 3D 모델링을 생성하기 위해, 딥러닝 모델을 통해 보정되는 이미지 특징(feature)을 생성한다. 포인트 클라우드 (point cloud)는 어떤 좌표계에 속한 점들의 집합으로, 3차원 좌표계에서 점은 보통 X, Y, Z 좌표로 정의되며 종종 사물의 표면을 나타내기 위해 사용된다. 포인트 클라우드는 사물의 표면에서 수많은 점을 자동으로 측정하 고, 이를 통해 생성한 점구름을 파일로 출력하기도 한다. 또한, 시공 시 포인트 클라우드는 주로 개조 공사에 사용되어 개축될 건물이나 구조를 정의한다. 실시예에서 변환모듈은 생성된 이미지를 학습하고 학습 결과를 기반으로 2D 이미지를 3D메쉬로 변환한다. 설정모듈은 오브젝트의 비어 있는 위치 값을 파악하고, 비어있는 위치 값을 기존 특징 값의 유사 값으로 설정한다. 실시예에서 설정모듈은 비어 있는 위치 값에서 일정 거리 미만의 위치 값을 복수개 추출하고 추 출된 복 수개 위치 값의 평균 데이터로 기존 특징 값의 유사 값을 산출할 수 있다. 실시예에서 설정모듈은 유효 값을 반영하여 점군들의 특징 묶음을 3D 메쉬 데이터로 변환 후 렌더링하여 3D 모델을 생성한다. 실시예에서 설정모듈은 하나의 표면을 층(Ground)으로 두고, 다른 표면의 3D 모델링 을 재구성한다. 또한, 설정모듈은 이미지 특징에 포함되는 오브젝트의 재질 값을 자동으로 투영하여 사용 자의 명령정보와 설정정보에 따라 3D 모델링을 자동으로 생성한다. 피드백 모듈은 비어 있는 위치 값을 기존 특징 값의 유사 값으로 설정하여 완성한 3D 모델링 이미지를 피 드백 한다. 실시예에서 피드백 모듈은 기존 특징 값의 유사 값을 오브젝트의 실제 데이터와 비교하여 피드백 하거나, 사용자의 데이터 보정 값을 해당 유사 값과 비교하여 피드백 할 수 있다. 예컨대, 피드백 모듈(26 0)은 유사 값과 오브젝트의 실제 데이터의 일치율이 일정 수준 미만인 경우, 유사 값 산출 과정 또는 알고리즘 을 수정하도록 한다. 또한, 사용자의 데이터 보정 값과 해당 유사 값의 일치율이 일정 수준 미만인 경우, 유사 값 산출 과정 또는 알고리즘을 수정하도록 한다. 또한, 유사값과 사용자의 데이터 보정값의 일치율 또는 오브젝 트의 실제 데이터와 유사 값의 일치율 수준에 따라 유사값 산출 알고리즘을 피드백 할 수 있다. 실시예에서 제1 생성모듈은 인공지능 머신러닝을 통한 이미지 인식(image recognition)과정을 통해 오브젝 트를 인식하고, 제1 생성모듈 및 제2 생성모듈은 인공지능 머신러닝을 통해 이미지 특징을 생성할 수 있다. 인공지능 이미지 인식은 기계가 마치 사람처럼 사진으로부터 사물을 인식하고 장면을 이해하는 것으로, 컴퓨터 비전 기술 중 하나에 해당한다. 실시예에서는 이미지 인식을 위해, 이미지에 포함된 오브젝트의 개체 분 류(classification), 검출(detection) 및 개체를 픽셀 단위로 식별하여 분할(segmentation)하는 데이터 처리과 정을 수행한다. 또한, 실시예에서 제1 생성모듈 및 제2 생성모듈은 노이즈 대응 외 학습하지 못한 패 턴 처리를 위해 학습 외 분포 데이터 탐지(out of distribution detection)과정을 수행한다. 학습 외 분포 데이 터 탐지는 인공지능에 입력된 이미지가 학습된 확률분포 데이터 인지 아닌지 식별하는 것이다. 실시예에서는 학 습 외 분포 데이터 탐지를 통해 인공 신경망이 판단하기 어려운 이미지를 걸러내거나 예외 처리하여 안정성과 신뢰성을 높일 수 있도록 한다. 실시예에서는 학습 외 분포 데이터 탐지를 위해서 딥러닝 판정에 대해 얼마나 확신(confidence)하는지를 나타내는 확률 값을 보정(calibration)하거나 학습 외 분포 데이터를 생성적 대립 신 경망(GAN, Generative Adversarial Network)으로 생성하고 학습하여 탐지 정확도를 향상시킬 수 있도록 한다. 또한, 실시예에서는 이미지 인식 정확도를 유지하면서 모델의 크기를 줄이기 위해, 연산을 간소화하는 경량 딥 러닝 기술을 이용하여 체형박스를 최종 확정할 수 있도록 한다. 실시예에서는 이미지 인식을 위해 콘볼루션 신 경망(CNN, Convolution Neural Network)에서 콘볼루션 필터를 변형하여 연산 차원을 축소(Reduction)하거나 큰 영향이 없는 신경망의 가중치(weight)를 삭제하는 가지치기, 가중치 값의 부동 소수점을 줄여 연산을 간소화하 는 양자화 과정을 수행하여 데이터 경량화를 가능하도록 한다. 또한, 실시예에서는 미리 학습시킨 큰 신경망의 출력을 작은 신경망에서 모방 학습하도록 하여 연산을 간소화하며 정확도를 유지할 수 있도록 한다. 도 3은 실시예에 따른 3D 모델링 생성 이미지를 나타낸 도면이다. 도 3을 참조하면, 실시예에서는 전자기기로부 터 수신한 도 3의 (a)와 같은 2D 이미지를 도 3의 (b)에 도시된 바와 같은 3D메쉬로 변환한다. 이후 오브젝트의 비어 있는 위치 값을 파악하고, 비어 있는 위치 값을 기존 특징 값의 유사 값으로 설정하여 도 3의 (c)에 도시 된 바와 같은 3D 모델링 이미지를 생성할 수 있다. 실시예에서 건축물 2D 이미지(a)를 가지고 3D 모델링(c)을 생성한다고 가정하면, 메인 서버는 사용자 단말로부 터 건축물 2D 이미지(a)를 수신한다. 실시예에서는 딥러닝 분류작업으로 배경과 오브젝트(건축물)을 분리하여 하나의 오브젝트를 생성하기 위한 작업을 시작하기 위해 배경부분의 고유 값을 버리고 오브젝트의 고유 값 만을 유지한다. 실시예에서는 각각의 이미지를 통해 건축물을 다면으로 바라볼 수 있도록 통합하는 방식의 포인트 클라우드를 생성하기 위하여, 각각의 이미지가 가지고 있는 오브젝트의 고유 값을 가상의 위치에 표현하고, 표현된 오브젝 트의 고유 값을 첨가하는 방식으로 이미지를 확장하여 이미지에 대한 건축물의 3차원 상에서의 위치 값을 생성 한다. 실시예에서는 확장된 이미지 중에서 이미지를 통해 얻지 못한 비어 있는 데이터는 오브젝트의 위치에 기 반하여 주변 값과 유사한 값을 갖도록 설정한다. 실시예에서는 이미지 오브젝트의 해당하는 부분에 대한 이미지 특징(feature)을 딥러닝 기반으로 생성한다. 이 는 완벽한 3D 모델링을 생성하기 위한 작업으로 오브젝트의 특징 값을 만들기 위한 작업이다. 실시예에서는 확 장된 3차원의 위치 값에 특징 값을 매칭하고 매칭된 특징 값에 따라 3D메쉬를 생성한다. 실시예에서는 3D 메쉬 는 오브젝트안의 정점(vertex)간의 연결 관계를 고려하여 학습하며, 오브젝트 형태에 대한 정보를 모두 담으면 서 계산과정이 빠르고 적은 메모리를 사용하기 위해 사용한다. 실시예에서는 3D 메쉬에 오브젝트 재질 값을 자 동으로 투영하고 사용자의 명령 및 설정 정보에 따라 3D 모델링이 자동 생성되도록 한다. 이하에서는 딥러닝 기반의 3D 모델링 자동생성 방법에 대해서 차례로 설명한다. 실시예에 따른 딥러닝 기반의 3D 모델링 자동생성 방법의 작용(기능)은 딥러닝 기반의 3D 모델링 자동생성 시스템의 기능과 본질적으로 같은 것이므로 도 1 내지 도 3과 중복되는 설명은 생략하도록 한다. 도 4는 실시예에 따른 딥러닝 기반의 3D 모델링 자동생성 과정을 나타낸 흐름도이다. 도 4를 참조하면, S100 단계에서는 이미지 수집 모듈에서 2D 이미지 복수개를 수집한다. S200 단계에서는 제1생 성모듈에서 수신한 2D 이미지의 배경과 오브젝트를 딥러닝 신경망을 통해 분류하고, 각 이미지를 통해 선택된 오브젝트의 고유 값을 병합하여 단일 설정값을 생성한다. 예컨대 S200 단계에서는 2D 이미지로부터 오브젝트를 분류하고, 분류된 오브젝트의 식별과 분류에 대응하는 특징 이미지인 피처링 이미지를 생성한다. 실시예에서는 제1생성모듈에서 수신한 2D 이미지의 배경과 오브젝트를 딥러닝 신경망을 통해 분류하고, 각 이미지를 통해 선 택된 오브젝트의 고유 값을 병합하여 단일 설정값을 생성할 수 있다. S300 단계에서는 원본과 특징 이미지를 통해 특징을 인식하여 원본의 포인트 클라우드에 유효 값을 전달한다. 실시예에서는 제2생성모듈에서 포인트 클라우드를 생성한 후 각 오브젝트의 특징 값으로, 단일 설정값을 가진 오브젝트의 3D 모델링을 생성하기 위해, 딥러닝 모델을 통해 보정되는 이미지 특징(feature)을 생성할 수 있다. S300 단계에서는 딥러닝 신경망을 통한 분류 및 3D 모델링을 생성하기 위해 DNN(Deep Neural Network), CNN(Convolutional Neural Network) RNN(Recurrent Neural Network) 및 BRDNN(Bidirectional Recurrent Deep Neural Network) 중 적어도 하나를 포함하는 딥러닝 뉴럴 네트워크를 트레이닝 데이터 셋으로 학습시킬 수 있다. S400 단계에서는 특징을 가진 포인트 클라우드를 바라보는 가상의 카메라 위치 값에 대응하여 3차원 상의 설정 및 매칭을 수행한다. S500 단계에서는 유효 값을 반영하여 점군들의 특징 묶음을 3D 메쉬 데이터로 변환 후 렌 더링하여 3D 모델을 생성한다. 실시예에서는 변환모듈에서 생성된 이미지를 학습하고 학습결과를 기반으로 2D 이미지를 3D메쉬로 변환한다. 이후, 설정모듈에서 오브젝트의 비어 있는 위치 값을 파악하고, 비어 있는 위치 값을 기존 특징 값의 유사 값으로 설정할 수 있다. 실시예에서는 비어 있는 위치 값에서 일정 거리 미만의 위치 값을 복수개 추출하고 추출된 복수개 위치 값의 평균 데이터로 기존 특징 값의 유사 값을 산출할 수 있다. 또한, S500 단계에서는 하나의 표면을 층(Ground)으로 두고, 다른 표면의 3D 모델링을 재구성할 수 있고, 이미 지 특징에 포함되는 오브젝트의 재질 값을 자동으로 투영하여 사용자의 명령정보와 설정정보에 따라 3D 모델링 을 자동으로 생성할 수 있다. 실시예에서 S600 단계에서는 피드백 모듈에서 은 비어 있는 위치 값을 기존 특징 값의 유사 값으로 설정하여 완 성한 3D 모델링 이미지를 피드백 한다. 실시예에서는 기존 특징 값의 유사 값을 오브젝트의 실제 데이터와 비교하여 피드백 하거나, 사용자의 데이터 보정 값을 해당 유사 값과 비교하여 피드백 할 수 있다. 예컨대, 유사 값과 오브젝트의 실제 데이터의 일치율이 일정 수준 미만인 경우, 유사 값 산출 과정 또는 알고리즘을 수정하도록 한다. 또한, 사용자의 데이터 보정 값 과 해당 유사 값의 일치율이 일정 수준 미만인 경우, 유사 값 산출 과정 또는 알고리즘을 수정하도록 한다. 또 한, 유사값과 사용자의 데이터 보정값의 일치율 또는 오브젝트의 실제 데이터와 유사 값의 일치율 수준에 따라 유사 값 산출 알고리즘을 피드백 할 수 있다. 이상에서와 같은 딥러닝 기반의 3D 모델링 자동생성 시스템 및 방법은 오브젝트에 대한 소수의 2D 이미지를 통 해 이미지에 포함된 오브젝트를 3D 모델링 이미지로 자동으로 생성할 수 있도록 한다. 실시예에서는 3D 모델링 의 완벽성을 위해, 비어 있는 값들을 유사한 값으로 채우며 현실감을 높이는 입체복원 작업으로 증강현실 기법 을 경제적, 효과적으로 구현할 수 있다. 또한, 3D 모델링을 자동 생성하여 생성 시간을 대폭 단축할 수 있다. 이하, 본 발명의 변형례의 딥러닝 기반의 3D 모델링 자동생성 시스템을 설명한다. 본 발명의 변형례의 딥러닝 기반의 3D 모델링 자동생성 시스템에서는 메인 서버는 보통 야외의 설비시설 등에 배치되는데, 야생동물 등이 침입하여 고가의 전장부품을 망가트려 경제적 손실을 입히거나 시스템을 셧다운시키는 문제가 있어 이에 대한 해결방안을 제시한다. 이를 위해, 메인 서버는 케이스(미도시), 케이스의 내/외부에 배치되며 적외선 영상을 생성하는 적외선 센 서(미도시), 케이스의 내/외부에 배치되며 가시광선 영상을 생성하는 카메라 센서(미도시), 케이스의 내/외부에 배치되며 적외선 센서와 카메라 센서를 제어하고 적외선 영상과 가시광선 영상을 수신하는 제어 모듈(미도시), 제어 모듈의 제어에 따라 발진하는 발진기(미도시)를 더 포함할 수 있다. 이 경우, 이미지 수집 모듈과 제 1 생성모듈과 제2 생성 모듈과 변환모듈과 설정모듈 및 피드백 모듈은 케이스의 내부 에 배치될 수 있으며, 상술한 구성에 의해 야생동물의 침입에 의해 망실되는 것을 보호받을 수 있다. 제어 모듈은 적외선 영상을 처리하여 생물체 여부를 판단하고 가시광선 영상을 처리하여 생물체 정보를 판단할 수 있다. 이 경우, 제어 모듈은 적외선 센서를 온시키고 카메라 센서를 오프시키고, 적외선 영상으로부터 생물 체가 존재하는 것을 판단한 다음 카메라 센서를 온시킬 수 있다. 즉, 제어 모듈은 평상 시에는 적외선 센서만을작동시켜 열화상 영상을 분석하여 생명체의 온도가 감지되면 케이스 내부에 생물체가 존재하는 것으로 판단한 다음, 케이스의 내부에 생물체가 존재하는 경우에만 카메라 센서를 온시켜 가시광선 영상을 생성하고 선명한 가 시광선 영상을 분석하여 생물체 정보를 구체적으로 판단할 수 있다. 즉, 전력소비량이 높은 카메라 센서는 필요 시에만 온시켜 작동시킴으로써 전력 효율을 높일 수 있다. 생물체 정보는 \"생물체(야생동물)의 종 등\"을 포함할 수 있으나 이에 한정되는 것은 아니다. 제어 모듈의 데이 터베이스에는 생물체의 온도 범위에 대한 데이터가 저장되어 있고 적외선 센서의 적외선 영상으로부터 데이터베 이스에 저장된 생물체의 온도 범위에 대한 열화상 데이터가 감지되면 제어 모듈은 케이스의 내부/주변에 생물체 가 존재하는 것으로 판단할 수 있다. 또한, 제어 모듈의 데이터베이스에는 각각의 이미지에 따른 야생동물의 종 에 대한 데이터가 맵핑되어 있고 카메라 센서의 가시광선 영상의 특정 이미지에서 데이터베이스에 저장된 이미 지를 매칭한 다음 해당 이미지에 맵핑되어 있는 야생동물의 종, 크기에 대한 데이터로서 생물체 정보를 산출할 수 있다. 이 경우, 발진기는 초음파 발진기일 수 있으며 제어 모듈이 판단한 생물체 정보에 따라 주파수의 세기와 대역폭 이 제어되어 작동될 수 있다(일 예로, 뱀과 쥐는 가청영역이 달라 상호 다른 주파수의 세기와 대역폭으로 발진 기가 작동되어야 함). 이에 따라, 케이스로 야생 동물 등이 침입하여 고가의 전장 부품(중앙 처리 장치 구성 품)을 훼손시키고 제어 계통을 마비시키는 것을 방지할 수 있다. 나아가 메인 서버는 적외선 센서와 카메라 센서 외에 케이스의 내/외부에 배치되는 3차원 카메라(미도시, 일 예로, 라이다; 3차원 뎁스 영상을 생성)를 추가적으로 포함할 수 있다. 이 경우, 제어 모듈은 평상 시 적외선 센서를 온시키고 카메라 센서와 3차원 카메라(미도시)와 발진기를 오프시 키고, 적외선 영상으로부터 생물체가 존재하는 것을 판단한 다음 카메라 센서를 온시킬 수 있다. 그 다음, 제어 모듈은 가시광선 영상을 분석하여 생물체 정보를 판단할 수 있다. 이 경우, 생물체 정보는 \"생물 체(야생동물)의 종과 속도 등\"을 포함할 수 있으나, 이에 한정되는 것은 아니다. 이 경우, 제어 모듈이 가시광 선 영상에서 생물체의 이미지의 위치가 단위 시간에 따라 변하는 것을 연산하여 단위 시간에 따른 야생동물의 속도를 측정할 수 있다. 제어 모듈은 야생동물의 속도가 특정값 미만이면 야생동물의 종에 매칭되는 주파수의 세기와 대역폭으로 발진기 를 발진시킬 수 있다. 이와 달리, 제어 모듈은 야생동물의 속도가 특정값 이상이면 3차원 카메라를 온시켜 생물체 부피(미도시)를 판 단할 수 있다. 이 경우, 제어 모듈은 생물체 부피가 특정값 이상이면 야생동물의 속도가 특정값 미만이 될 때까 지 발진기를 작동시키지 않은 다음 야생동물의 속도가 특정값 미만이 되면 야생동물의 종에 매칭되는 주파수의 세기와 대역폭으로 발진하도록 발진기를 작동시킬 수 있다. 이와 달리, 제어 모듈은 생물체 부피가 특정값 미만 이면 야생동물의 속도에 상관없이 야생동물의 종에 매칭되는 주파수의 세기와 대역폭으로 발진하도록 발진기를 작동시킬 수 있다. 즉, 야생동물의 속도가 특정값 이상인 경우 야생동물이 갑작스럽게 케이스의 내부로 들어오거나 좁은 공간에서 당황한 경우로서, 발진기를 갑작스럽게 작동시키면 혼란이 가중되어 더욱 빠른 속도로 케이스의 내부를 돌아다 녀 큰 손상을 일으킬 확률이 있다. 이를 방지하기 위해, 제어 모듈은 3차원 카메라(미도시)로 야생동물의 크기를 판단한 다음 크기가 작으면 빠른 속도로 돌아다닌다고 하더라도 손상 위험이 적고 조속히 내보내는 것이 중요하므로 바로 발진기를 작동시킬 수 있고, 크기가 크면 갑자기 발진기를 작동시키는 것보다 속도가 어느 정도 줄어든 다음 발진기를 작동시켜 야생 동물이 진정한 상태에서 찬찬히 케이스 외부로 빠져나가도록 유도할 수 있다. 나아가 메인 서버에서는 제어 모듈에 의해 제어되는 스피커(미도시)를 더 포함할 수 있다. 스피커는 평상 시 제어 모듈에 의해 오프되어 있으며, 야생동물의 속도가 특정값 이상인 시간이 특정값 이상인 경우 제어 모듈 에 의해 작동될 수 있다. 이 경우, 주변의 관리자는 야생동물이 케이스 내부에서 요동하는 것을 인지하여 긴급 하게 출동할 수 있다. 더 나아가 메인 서버에서는 제어 모듈에 의해 제어되는 광원모듈(미도시)을 더 포함할 수 있다. 광원모듈 은 평상 시 제어 모듈에 의해 오프되어 있으며, 제어 모듈이 적외선 영상으로부터 생물체가 존재하는 것을 판단 한 다음 온되어 케이스의 내/외부로 가시광선을 출사할 수 있다. 이에 따라, 카메라 센서는 광원모듈의 가시광 선에 의해 풍부하게 수광하여 정확한 가시광선 영상을 생성할 수 있다. 또한, 제어 모듈이 야생동물의 속도가특정값 미만인 것으로 판단한 경우 광원모듈은 제1시간동안 온된 상태를 지속하다가 오프될 수 있고, 제어 모듈 이 야생동물의 속도가 특정값 이상인 것으로 판단한 경우 광원모듈은 제1시간보다 긴 제2시간동안 온된 상태를 지속하다가 오프될 수 있다. 야생동물의 속도가 특정값 이상인 경우에는 지속적으로 야생동물의 속도를 트랙킹 할 필요성이 있으며 이에 따라 카메라 센서에서 보다 선명한 가시광선 영상이 오래 생성될 필요가 있기 때문이 다."}
{"patent_id": "10-2023-0058880", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2023-0058880", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 딥러닝 기반의 3D 모델링 자동생성 시스템 구성을 나타낸 도면, 도 2는 실시예에 따른 메인 서버의 데이터 처리 구성을 나타낸 도면, 도 3은 실시예에 따른 3D 모델링 생성 이미지를 나타낸 도면, 도 4는 실시예에 따른 딥러닝 기반의 3D 모델링 자동생성 과정을 나타낸 흐름도이다."}
