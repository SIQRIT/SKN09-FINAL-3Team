{"patent_id": "10-2021-0179385", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0054219", "출원번호": "10-2021-0179385", "발명의 명칭": "딥러닝 기반의 한국어 의료 자연어 처리 장치 및 방법", "출원인": "주식회사 틸더", "발명자": "주형준"}}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "딥러닝 기반의 한국어 의료 자연어 처리 장치에 있어서,의료 분야의 텍스트 데이터를 자연어 처리 모델의 학습을 위한 변환 데이터로 변환하는 데이터 도입부;상기 변환 데이터를 문장 단위의 말뭉치 데이터로 분할하는 텍스트 분할부;상기 말뭉치 데이터에서 일부의 단어를 토큰으로 가린 후, 상기 토큰에 의해 가려진 단어를 예측하는 가려진 언어 모델 수행부;상기 말뭉치 데이터에서 일부의 단어가 가려진 상태에서 문장의 선후 관계를 예측하는 다음 문장 예측 수행부;및상기 말뭉치 데이터에 기초하여 상기 가려진 언어 모델 수행부 및 상기 다음 문장 예측 수행부의 자연어 처리모델을 학습시키는 학습부를 포함하는,자연어 처리 장치."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 학습부는,상기 말뭉치 데이터에 포함된 분할된 한 쌍의 문장을 결합한 문장 쌍을 기초로 상기 자연어 처리 모델을 학습시키는 것인, 자연어 처리 장치."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 학습부는,토크나이저를 이용하여 확장한 의료 영역 단어를 기반으로 하여 상기 학습을 수행하는 것인, 자연어 처리 장치."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 학습부는,사전 학습된 한국어 자연어 처리 모델의 가중치를 초기 가중치로 활용하여 학습하는 것인, 자연어 처리 장치."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 학습부는,상기 가려진 언어 모델 수행부의 자연어 처리 모델을 통해 상기 토큰의 주변 단어를 기반으로 가려진 단어를 예측하여 상기 말뭉치 데이터에 포함된 각 단어의 의미를 학습하고,상기 다음 문장 예측 수행부의 자연어 처리 모델을 통해 상기 선후 관계를 이진 분류로 예측하여 상기 말뭉치데이터에 포함된 문장 간의 관계를 학습하는 것인, 자연어 처리 장치."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,공개특허 10-2023-0054219-3-상기 텍스트 분할부는,단일 말뭉치 데이터의 형태인 상기 변환 데이터를 형태소 분석을 통해 문장 단위의 말뭉치 데이터로 분할하는것인, 자연어 처리 장치."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,정규 표현식을 이용하여 상기 말뭉치 데이터를 필터링하는 전처리 필터부,를 더 포함하는 것인, 자연어 처리 장치."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 전처리 필터부는,상기 말뭉치 데이터에 포함된 영문 부분 중 대문자를 소문자로 변환하고, 상기 말뭉치 데이터에 포함된 웹 링크부분 및 미리 설정된 유형의 특수 문자 부분을 제거하는 것인, 자연어 처리 장치."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 자연어 처리 모델을 통해 개체 명 인식 및 문장 쌍 유사도 예측 중 적어도 하나를 수행하는 분석부,를 더 포함하는 것인, 자연어 처리 장치."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "딥러님 기반의 한국어 의료 자연어 처리 방법에 있어서,의료 분야의 텍스트 데이터를 자연어 처리 모델의 학습을 위한 변환 데이터로 변환하는 단계;상기 변환 데이터를 문장 단위의 말뭉치 데이터로 분할하는 단계;상기 말뭉치 데이터에서 일부의 단어를 토큰으로 가린 후, 상기 토큰에 의해 가려진 단어를 예측하는 단계;상기 말뭉치 데이터를 결합한 문장 쌍에서 일부의 단어가 가려진 상태에서 두 문장 쌍의 문장의 선후 관계 여부를 예측하는 단계; 및상기 말뭉치 데이터에 기초하여 상기 가려진 언어 모델 수행부 및 상기 다음 문장 예측 수행부의 자연어 처리모델을 학습시키는 단계를 포함하는,자연어 처리 방법."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 자연어 처리 모델을 학습시키는 단계는,상기 말뭉치 데이터에 포함된 분할된 한 쌍의 문장을 결합한 문장 쌍을 기초로 상기 자연어 처리 모델을 학습시키는 것인, 자연어 처리 방법."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 자연어 처리 모델을 학습시키는 단계는,토크나이저를 이용하여 확장한 의료 영역 단어를 기반으로 하여 상기 학습을 수행하는 것인, 자연어 처리 방법."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "공개특허 10-2023-0054219-4-제10항에 있어서,상기 자연어 처리 모델을 학습시키는 단계는,사전 학습된 한국어 자연어 처리 모델의 가중치를 초기 가중치로 활용하여 학습하는 것인, 자연어 처리 방법."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서,상기 자연어 처리 모델을 학습시키는 단계는,가려진 단어를 예측하는 단계에서의 자연어 처리 모델을 통해, 상기 토큰의 주변 단어를 기반으로 가려진 단어를 예측하여 상기 말뭉치 데이터에 포함된 각 단어의 의미를 학습하고,상기 문장의 선후 관계 여부를 예측하는 단계에서의 자연어 처리 모델을 통해, 상기 선후 관계를 이진 분류로예측하여 상기 말뭉치 데이터에 포함된 문장 간의 관계를 학습하는 것인,자연어 처리 방법."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,상기 말뭉치 데이터로 분할하는 단계는,단일 말뭉치 데이터의 형태인 상기 변환 데이터를 형태소 분석을 통해 문장 단위의 말뭉치 데이터로 분할하는것인, 자연어 처리 방법."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서,정규 표현식을 이용하여 상기 말뭉치 데이터를 필터링하는 단계,를 더 포함하는, 자연어 처리 방법."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 필터링하는 단계는,상기 말뭉치 데이터에 포함된 영문 부분 중 대문자를 소문자로 변환하고, 상기 말뭉치 데이터에 포함된 웹 링크부분 및 미리 설정된 유형의 특수 문자 부분을 제거하는 것인, 자연어 처리 방법."}
{"patent_id": "10-2021-0179385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항에 있어서,상기 자연어 처리 모델을 통해 개체 명 인식 및 문장 쌍 유사도 예측 중 적어도 하나를 수행하여 의료 언어를분석하는 단계,를 더 포함하는, 자연어 처리 방법."}
{"patent_id": "10-2021-0179385", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "딥러닝 기반의 한국어 의료 자연어 처리 장치는, 의료 분야의 텍스트 데이터를 자연어 처리 모델의 학습을 위한 변환 데이터로 변환하는 데이터 도입부, 상기 변환 데이터를 문장 단위의 말뭉치 데이터로 분할하는 텍스트 분할 부, 상기 말뭉치 데이터에서 일부의 단어를 토큰으로 가린 후, 상기 토큰에 의해 가려진 단어를 예측하는 가려진 언어 모델 수행부, 상기 말뭉치 데이터에서 일부의 단어가 가려진 상태에서 문장의 선후 관계를 예측하는 다음 문장 예측 수행부 및 상기 말뭉치 데이터에 기초하여 상기 가려진 언어 모델 수행부 및 상기 다음 문장 예측 수 행부의 자연어 처리 모델을 학습시키는 학습부를 포함할 수 있다."}
{"patent_id": "10-2021-0179385", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본원은 딥러닝 방법을 기반으로 종합적인 한국어 의료 자연어 처리를 수행하는 시스템 및 방법에 관한 것이며, 상세하게는 의료 기관에서 발생하는 한국어 의료 텍스트 데이터의 다양한 분석에 활용할 수 있는 인공지능 자연 어 처리 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0179385", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "의료 분야에서 발생하는 텍스트 빅데이터를 자연어 처리 모델을 통해 분석·처리하기 위해서는 모델에 대한 일 반적 텍스트 데이터뿐만 아닌 의료 텍스트 데이터에 대한 학습이 필수적이다. 검사결과와 같은 병원 내 대다수 의 텍스트 데이터는 전문적인 용어를 포함하는 경우가 많기 때문에 일반적인 텍스트 데이터를 대상으로 하는 자 연어 처리 모델을 통해 분석하기 어렵다. 딥러닝 기반의 자연어 처리 모델은 위키피디아와 같은 모든 분야에 걸친 대규모 말뭉치 데이터를 먼저 학습하고 해결하고자하는 문제에 대한 소규모 데이터를 학습하는 것이 일반적인 접근법이다. 모델이 말뭉치 데이터를 학 습하는 과정에서 단어의 의미와 문장 간의 관계를 학습하게 되는데, 의료 분야에의 적용에 있어서 의료 텍스트 를 충분히 학습하지 못하면 문제를 해결하는 데에 성능 손실이 발생한다. 영어를 사용하는 해외 자연어 처리 모델은 의료 분야에 특화하여 성능을 높인 사례가 다수이지만, 이는 한국어 를 포함한 한국어 의료 텍스트를 처리하는 데에 부적합하다. 한국어를 대상으로 개발된 자연어 처리 모델은 존 재하지만 상기의 이유로 한국어 의료 텍스트를 분석하는 과정에서 성능 손실이 발생한다. 딥러닝 자연어 처리 기반의 한국어 의료 텍스트 데이터 분석을 통한 서비스(ex. 검색, 챗봇)는 기존에도 많이 연구·개발되어 왔으나, 이것의 핵심 엔진에 대해서는 그렇지 않다. 본 발명에선 딥러닝 자연어 처리 모델의 핵 심 엔진을 한국어 및 의료 분야에 특화하여 고도화한 자연어 처리 모델과 그 방법을 다룬다. 이를 종합하면, 한국어를 포함한 임상 텍스트 데이터의 분석에 최적화된 자연어 처리 시스템은 전무한 실정이다. 한국어 의료 텍스트는 임상정보, 질병의 기저요인, 국내 의료 특성 등의 중요한 정보를 포함하기 때 문에, 이를 분석할 수 있는 자연어 처리 시스템을 개발하는 것은 반드시 필요한 상황이다. 본원의 배경이 되는 기술은 한국등록특허공보 제10-2059743호에 개시되어 있다."}
{"patent_id": "10-2021-0179385", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 병원에서 생성되는 한국어 의료 텍스트 데이터에 한정하여, 딥러닝 기술을 사용하여 한국어 의료 텍스트에 관련된 여러 가지 문제를 해결·분석할 수 있는 인공 지능 자연어 처리 시스템 및 방법을 제공하려는 것을 목적으로 한다. 본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 의료 분야에서 생성되는 한국어 의료 텍스트 데 이터의 분석 및 처리를 할 수 있는 인공지능 자연어 처리 시스템 및 방법을 제공하려는 것을 목적으로 한다. 본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 다양한 의료 텍스트 문제를 해결하는 데에 핵심 엔진으로 활용될 수 있는 인공지능 자연어 처리 시스템 및 방법을 제공하려는 것을 목적으로 한다. 다만, 본원의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2021-0179385", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본원의 일 실시예에 따른 딥러닝 기반의 한국어 의료 자연어 처리 장치는, 의료 분야의 텍스트 데이터를 자연어 처리 모델의 학습을 위한 변환 데이터로 변환하는 데 이터 도입부, 상기 변환 데이터를 문장 단위의 말뭉치 데이터로 분할하는 텍스트 분할부, 상기 말뭉치 데이터에 서 일부의 단어를 토큰으로 가린 후, 상기 토큰에 의해 가려진 단어를 예측하는 가려진 언어 모델 수행부, 상기 말뭉치 데이터에서 일부의 단어가 가려진 상태에서 문장의 선후 관계를 예측하는 다음 문장 예측 수행부 및 상 기 말뭉치 데이터에 기초하여 상기 가려진 언어 모델 수행부 및 상기 다음 문장 예측 수행부의 자연어 처리 모 델을 학습시키는 학습부를 포함할 수 있다. 본원의 일 실시예에 따르면, 상기 학습부는, 상기 말뭉치 데이터에 포함된 분할된 한 쌍의 문장을 결합한 문장 쌍을 기초로 상기 자연어 처리 모델을 학습시키는 것일 수 있다. 본원의 일 실시예에 따르면, 상기 학습부는, 토크나이저를 이용하여 확장한 의료 영역 단어를 기반으로 하여 상 기 학습을 수행하는 것일 수 있다.본원의 일 실시예에 따르면, 상기 학습부는, 사전 학습된 한국어 자연어 처리 모델의 가중치를 초기 가중치로 활용하여 학습하는 것일 수 있다. 본원의 일 실시예에 따르면, 상기 학습부는, 상기 가려진 언어 모델 수행부의 자연어 처리 모델을 통해 상기 토 큰의 주변 단어를 기반으로 가려진 단어를 예측하여 상기 말뭉치 데이터에 포함된 각 단어의 의미를 학습하고, 상기 다음 문장 예측 수행부의 자연어 처리 모델을 통해 상기 선후 관계를 이진 분류로 예측하여 상기 말뭉치 데이터에 포함된 문장 간의 관계를 학습하는 것일 수 있다. 본원의 일 실시예에 따르면, 상기 텍스트 분할부는, 단일 말뭉치 데이터의 형태인 상기 변환 데이터를 형태소 분석을 통해 문장 단위의 말뭉치 데이터로 분할하는 것일 수 있다. 본원의 일 실시예에 따른 딥러닝 기반의 한국어 의료 자연어 처리 장치는, 정규 표현식을 이용하여 상기 말뭉치 데이터를 필터링하는 전처리 필터부를 더 포함할 수 있다. 본원의 일 실시예에 따르면, 상기 전처리 필터부는, 상기 말뭉치 데이터에 포함된 영문 부분 중 대문자를 소문 자로 변환하고, 상기 말뭉치 데이터에 포함된 웹 링크 부분 및 미리 설정된 유형의 특수 문자 부분을 제거하는 것일 수 있다. 본원의 일 실시예에 따른 딥러닝 기반의 한국어 의료 자연어 처리 장치는, 상기 자연어 처리 모델을 통해 개체 명 인식 및 문장 쌍 유사도 예측 중 적어도 하나를 수행하는 분석부를 더 포함할 수 있다. 본원의 일 실시예에 따른 딥러닝 기반의 한국어 의료 자연어 처리 방법은, 의료 분야의 텍스트 데이터를 자연어 처리 모델의 학습을 위한 변환 데이터로 변환하는 단계, 상기 변환 데이터를 문장 단위의 말뭉치 데이터로 분할 하는 단계, 상기 말뭉치 데이터에서 일부의 단어를 토큰으로 가린 후, 상기 토큰에 의해 가려진 단어를 예측하 는 단계, 상기 말뭉치 데이터를 결합한 문장 쌍에서 일부의 단어가 가려진 상태에서 두 문장 쌍의 문장의 선후 관계 여부를 예측하는 단계 및 상기 말뭉치 데이터에 기초하여 상기 가려진 언어 모델 수행부 및 상기 다음 문 장 예측 수행부의 자연어 처리 모델을 학습시키는 단계를 포함할 수 있다. 본원의 일 실시예에 따르면, 상기 자연어 처리 모델을 학습시키는 단계는, 상기 말뭉치 데이터에 포함된 분할된 한 쌍의 문장을 결합한 문장 쌍을 기초로 상기 자연어 처리 모델을 학습시키는 것일 수 있다. 본원의 일 실시예에 따르면, 상기 자연어 처리 모델을 학습시키는 단계는, 토크나이저를 이용하여 확장한 의료 영역 단어를 기반으로 하여 상기 학습을 수행하는 것일 수 있다. 본원의 일 실시예에 따르면, 상기 자연어 처리 모델을 학습시키는 단계는, 사전 학습된 한국어 자연어 처리 모 델의 가중치를 초기 가중치로 활용하여 학습하는 것일 수 있다. 본원의 일 실시예에 따르면, 상기 자연어 처리 모델을 학습시키는 단계는, 가려진 단어를 예측하는 단계에서의 자연어 처리 모델을 통해, 상기 토큰의 주변 단어를 기반으로 가려진 단어를 예측하여 상기 말뭉치 데이터에 포 함된 각 단어의 의미를 학습하고, 상기 문장의 선후 관계 여부를 예측하는 단계에서의 자연어 처리 모델을 통해, 상기 선후 관계를 이진 분류로 예측하여 상기 말뭉치 데이터에 포함된 문장 간의 관계를 학습하는 것일 수 있다. 본원의 일 실시예에 따르면, 상기 말뭉치 데이터로 분할하는 단계는, 단일 말뭉치 데이터의 형태인 상기 변환 데이터를 형태소 분석을 통해 문장 단위의 말뭉치 데이터로 분할하는 것일 수 있다. 본원의 일 실시예에 따르면, 본원의 일 실시예에 따른 딥러닝 기반의 한국어 의료 자연어 처리 방법은, 정규 표 현식을 이용하여 상기 말뭉치 데이터를 필터링하는 단계를 더 포함할 수 있다. 본원의 일 실시예에 따르면, 상기 필터링하는 단계는, 상기 말뭉치 데이터에 포함된 영문 부분 중 대문자를 소 문자로 변환하고, 상기 말뭉치 데이터에 포함된 웹 링크 부분 및 미리 설정된 유형의 특수 문자 부분을 제거하 는 것일 수 있다. 본원의 일 실시예에 따르면, 본원의 일 실시예에 따른 딥러닝 기반의 한국어 의료 자연어 처리 방법은, 상기 자 연어 처리 모델을 통해 개체 명 인식 및 문장 쌍 유사도 예측 중 적어도 하나를 수행하는 단계를 더 포함할 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본원을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예 시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2021-0179385", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본원의 과제 해결 수단에 의하면, 의료 분야에서 생성되는 한국어 의료 텍스트 데이터의 분석 및 처리를 할 수 있는 인공지능 자연어 처리 시스템 및 방법을 제공할 수 있다. 대표적인 예로, 개체 명인식 및 문장 쌍 유사도 분석(MedSTS; Medical Semantic Textual Similarity)을 들 수 있는데 본 발명을 통해 기존의 룰 베이스 방법 혹은 간단한 딥러닝 자연어 처리 엔진에 대비하여 더 고도화된 성능을 얻을 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 다양한 의료 텍스트 문제를 해결하는 데에 핵심 엔진으로 활용될 수 있는 인공지능 자연어 처리 시스템 및 방법을 제공할 수 있다. 본 발명에서 사용하는 딥러닝 자연어 처리 모델 은 상기의 예시 외에 질의응답, 문장추론, 감성분석 등에 활용이 가능한 효과가 있다. 다만, 본원에서 얻을 수 있는 효과는 상기된 바와 같은 효과들로 한정되지 않으며, 또 다른 효과들이 존재할 수 있다."}
{"patent_id": "10-2021-0179385", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본원이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본원의 실시예를 상세히 설명한다. 그러나 본원은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본원을 명확하게 설명하기 위해서 설명과 관계없는 부분 은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본원 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\" 또는 \"간접적으로 연결\"되어 있는 경우 도 포함한다. 본원 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\", \"상부에\", \"상단에\", \"하에\", \"하부에\", \"하단에\" 위치 하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존 재하는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 도 1은 본원의 일 실시예에 따른 인공지능 의료 언어 분석 시스템의 개략적인 구성도이다. 예를 들면, 본원은 의료 분야에 적합한 딥러닝 기반의 한국어 의료 자연어 처리 장치 및 방법에 관한 것이다. 도 1을 참조하면, 본원의 일 실시예에 따른 인공지능 의료 언어 분석 시스템은 자연어 처리 장치 및 데이터 베이스를 포함할 수 있다. 이와 관련하여, 의료 영역의 텍스트 데이터는 병력, 진단 및 치료 정보와 같은 중요한 요소를 가지고 있다. 그 러나 의학 텍스트는 단어 표현과 전문 용어의 복잡성으로 인해 분석하기가 매우 어렵기 때문에, 기계 학습 또는 딥 러닝을 기반으로 하는 자연어 처리 모델의 채택이 필요하다. 지난 몇 년 동안 딥 러닝이 크게 발전하면서 언어 처리에 사용되는 기존 모델의 한계를 극복하기 위해 자연어 처리(NLP: Natural Language Processing) 모델이 개발되었다. 자연어 처리 모델 중 BERT(Bidirectional encoder representations from transformer)는 변환기의 인코더 구조 를 사용하여 구성된 딥 러닝 언어 모델이다. BERT는 다양한 자연어 처리 작업에서 특출한 성능을 보여주었으며, BERT를 기반으로 수많은 자연어 처리 모델이 지속적으로 개발되고 있다. 그러나, BERT는 영어를 중점으로 사전 학습된 언어 모델로, 언어의 다양한 속성을 충분히 방영하기엔 어려움이 있다. 이러한 이유로 다양한 언어에 적용될 수 있는 BERT의 연구가 활발히 진행되고 있다. 한국어 기반의 BERT(KR-BERT)는 한국어의 대표적인 딥러닝 자연어 처리 모델이다. 이는 한국어 말뭉치에 대해 학습된 다른 언어 모델에 비해 뛰어난 성능을 보였다. 그러나, KR-BERT 는 일반적인 한국어 데이터를 학습하는 모델로, 의료 분야의 언어들에 적용하기에는 적합하지 않다는 한계가 있다. 한편, 본원의 실시예에 관한 설명에서 데이터 베이스는 자연어 처리 장치에 입력되는 데이터를 저장 하기 위한 스토리지를 의미할 수 있다. 또한, 이러한 데이터 베이스에 저장되는 의료 분야의 데이터는 단 어 표현과 전문 용어의 복잡성으로 인해 분석이 어려운 특성을 가지는 텍스트 자료일 수 있으나, 이에 한정되는 것은 아니다. 또한, 도 1을 참조하면, 자연어 처리 장치 및 데이터 베이스 상호간은 네트워크를 통해 통신할 수 있다. 네트워크는 단말들 및 서버들과 같은 각각의 노드 상호간에 정보 교환이 가능한 연결 구조를 의 미하는 것으로, 이러한 네트워크의 일 예에는, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, 5G 네트워크, WIMAX(World Interoperability for Microwave Access) 네 트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), wifi 네트워크, 블루투스(Bluetooth) 네트워크, 위성 방송 네트 워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지 는 않는다. 이하, 설명의 편의를 위해, 자연어 처리 장치를 본 장치로 특정한다. 도 2는 본원의 일 실시예에 따른 변환 데이터의 예시를 나타내는 도면이다. 도 2를 참조하면, 본 장치는 의료 분야의 텍스트 데이터를 자연어 처리 모델의 학습을 위한 변환 데이터 로 변환할 수 있다. 구체적으로, 본 장치는 텍스트 데이터를 자연어 처리 모델의 학습에 용이하게 활 용되도록 변환하여, 텍스트 데이터를 처리할 수 있다. 여기서, 텍스트 데이터는 상술한 데이터 베이스에 포함(저장)된 것일 수 있다. 달리 말해, 본 장치로 제공되는 데이터는 데이터 베이스로부터 직접 전달되는 것일 수 있으나, 이에 한정되는 것은 아니다. 다른 예로, 본 장치는 사용자로부터 직접 텍스트 데이터를 입력 받거나, CSV 혹은 엑셀(exscl) 등의 파일 형식 으로 텍스트 데이터를 획득하는 것일 수 있다. 또 다른 예로, 본 장치는 MS-SQL과 같은 데이터 베이스 관 리 시스템(DBMS)을 통해 텍스트 데이터를 획득하는 것일 수 있다. 도 3은 본원의 일 실시예에 따른 말뭉치 데이터 및 문장 쌍의 예시를 나타내는 도면이다. 도 3을 참조하면, 본 장치는 변환 데이터를 문장 단위의 말뭉치 데이터로 분할할 수 있다. 구체 적으로, 본 장치는 단일 말뭉치 데이터의 형태인 변환 데이터를 형태소 분석을 통해 문장 단위의 말 뭉치 데이터로 분할할 수 있다. 또한, 본 장치는 말뭉치 데이터에 포함된 분할된 한 쌍의 문장을 결합하여, 문장 쌍을 생성할 수 있다. 다시 말해, 문장 단위의 말뭉치 데이터들을 한 쌍씩 결합할 수 있다. 이러한 문장 쌍들은 자연어 처리 모델의 학습에 활용될 수 있다. 도 4는 본원의 일 실시예에 따른 필터링 데이터의 예시를 나타내는 도면이다. 도 4를 참조하면, 본 장치는 정규 표현식을 이용하여 말뭉치 데이터를 필터링할 수 있다. 구체적으로, 본 장치는 문장 단위로 분할된 말뭉치 데이터를 자연어 처리에 필요한 방향으로 문자의 변환 혹은 제거 등의 방법으로 필터링하여, 필터링 데이터를 생성할 수 있다. 본원의 일 실시예에 따르면, 본 장치는 말뭉치 데이터 또는 문장 쌍에 포함된 영문 부분 중 대 문자를 소문자로 변환할 수 있고, 말뭉치 데이터 또는 문장 쌍에 포함된 웹 링크 부분 및 미리 설정 된 유형의 특수 문자 부분을 제거할 수 있다. 여기서 미리 설정된 유형의 특수 문자는 '#' 및 '.'을 제외하는 특수 문자들을 의미할 수 있으나, 이에 한정되는 것은 아니다. 도 3 및 도 4를 참조하면, 도 3의 각 말뭉치 데이터와 도 4의 필터링 데이터들을 비교하면, 필터링 데이터는 도 3의 말뭉치 데이터에서 특수 문자 부분이 제거된 데이터임을 확인할 수 있다. 본원의 일 실시예에 따르면, 본 장치는 상술한 과정을 통해 생성된 데이터를 이용하여, 자연어 처리 모델 의 학습을 수행할 수 있다. 본원의 일 실시예에 따른 자연어 처리 모델에서 활용하는 입력 데이터는 상술한 필 터링 과정까지 거친 필터링 데이터들일 수 있으나, 상술한 바와 같이, 자연어 처리 학습에는 문장 쌍(12 2)의 형태를 기초로 활용하므로, 이하에서 설명하는 말뭉치 데이터 또는 문장 쌍은 필터링 과정을 거 친 말뭉치 데이터 또는 필터링 과정을 거친 문장 쌍으로 해석될 수 있다. 다시 말해, 본 장치는 말뭉치 데이터에 포함된 분할된 한 쌍의 문장을 결합한 문장 쌍을 기초로 자연어 처리 모델을 학습시 킬 수 있다. 본원의 일 실시예에 따르면, 본 장치는 사전 학습된 한국어 자연어 처리 모델의 가중치를 초기 가중치로 활용하여 학습할 수 있다. 여기서 사전 학습된 한국어 자연어 처리 모델이란, 상술한 KR-BERT일 수 있으나, 이 에 한정되는 것은 아니다. 본 장치는 미리 학습된 자연어 처리 모델의 기존의 가중치를 초기 가중치로 활용함으로써, 보다 효율적인 학습을 할 수 있다. 본원의 일 실시예에 따르면, 본 장치는 자연어 처리 모델의 학습을 위해, 말뭉치 데이터에서 일부의 토큰을 가린 후, 가려진 토큰을 예측할 수 있다. 이하, 이러한 과정을 '가려진 언어 모델(MLM: masked language model) 수행'이라 지칭하도록 한다. 또한, '토큰'이란, 입력 데이터를 의미 있는 단위로 나눠 정의한 것으로, 단위로는 단어, 단어구 및 문자열 등이 포함될 수 있다. 도 5는 본원의 일 실시예에 따른 가려진 문장 모델 수행을 설명하기 위한 개념도이다. 도 5를 참조하면, 가려진 언어 모델(MLM: masked language model)은 두 문장으로 연결된 한 쌍의 문장인 문장 쌍을 입력 받을 수 있다. 이때, 각 문장 쌍에 대한 모든 토큰 중 미리 설정된 비율(예를 들면, 15% 등)의 토큰이 무작위로 가려질 수 있다(Masking). 또한, 가려진 토큰 중 제1비율(예를 들면, 80% 등)의 토큰은 [MASK] 토큰으로 변경되는 방식으로 가려지고, 제2비율(예를 들면, 10% 등)의 토큰은 특정한 토큰으로 가려지는 것이 아닌 랜덤 단어(랜덤 토큰)로 변경되고, 제3비율(예를 들면, 나머지 10% 등)의 토큰은 본래의 단어 그대로 를 유지하며 변경되지 않을 수 있다. 본원의 일 실시예에 따르면, 가려진 토큰에 대한 레이블(Label)은 어휘의 크기로 제한될 수 있다. 다시 말해, 가려진 언어 모델(MLM: masked language model)의 레이블(Label)의 크기는 입력되는 전체 어휘 크기에 해당될 수 있다. 또한, 가려진 언어 모델(MLM: masked language model)의 손실은 하기 식 1과 같이 정의될 수 있다. [식 1]"}
{"patent_id": "10-2021-0179385", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "[식 1]에서, C는 가려진 토큰에 대한 원-핫 레이블 벡터(one-hot label vector)을 의미하고, P는 예측 확률을 의미하고, V는 어휘의 크기를 의미한다. 본원의 일 실시예에 따른, 가려진 언어 모델(MLM: masked language model)의 손실은 [식 1]에 따른 각 문장 쌍에서 모든 가려진 토큰에 대한 손실들의 평균일 수 있으나, 이 에 한정되는 것은 아니다. 또한, 본원의 일 실시예에 따르면, 본 장치는 자연어 처리 모델의 학습을 위해, 말뭉치 데이터에서 일부의 단어가 가려진 상태에서 문장의 선후 관계를 예측할 수 있다. 이하에서는 설명의 편의를 위하여 이러한 과정을 '다음 문장 예측(NSP: next sentence prediction) 수행'이라 지칭하도록 한다. 도 6은 본원의 일 실시예에 따른 다음 문장 예측 수행을 설명하기 위한 개념도이다. 도 6을 참조하면, 본 장치는 다음 문장 예측(NSP: next sentence prediction)을 위하여 두 문장으로 연결 된 한 쌍의 문장인 문장 쌍을 입력 받을 수 있다. 본원의 일 실시예에 따르면, 다음 문장 예측(NSP: next sentence prediction)은 sNext와 NotNext로 단 두 개의 레이블(Label)을 출력한다. 또한, 다음 문장 예측(NSP: next sentence prediction)의 손실은 하기 식 2과 같이 정의될 수 있다. [식 2]"}
{"patent_id": "10-2021-0179385", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "[식 2]에서, 는 다음 문장 관계의 레이블을 의미하고, 는 다음 문장 관계의 예측 확률을 의미한다. 본원의 일 실시예에 따르면, 본 장치는 상술한 가려진 언어 모델(MLM: masked language model)의 손실 및 다음 문장 예측(NSP: next sentence prediction)의 손실을 합산하여 총 손실을 도출할 수 있다. 또한, 본원의 일 실시예에 따른 자연어 처리 모델의 가중치는 도출된 총 손실에 대해 업데이트되는 것일 수 있으나, 이에 한 정되는 것은 아니다. 또한, 본원의 일 실시예에 따르면, 본 장치는 토크나이저를 이용하여 확장한 의료 영역 단어를 기반으로 하여 학습을 수행할 수 있다.만약 상술한 가려진 언어 모델(MLM: masked language model) 및 다음 문장 예측(NSP: next sentence prediction)의 수행 중, 잘못된 토큰화가 빈번하게 발생하면, 이는 자연어 처리 모델의 언어 이해에 방해가 될 수 있다. 따라서, 본 장치는 자연어 처리 모델의 학습을 위한 어휘로, 의료 영역 단어를 기반으로, 토크나 이저를 이용하여 기존의 어휘보다 확장한 어휘를 고려할 수 있다. 본원의 일 실시예에 따르면, 확장한 어휘는 대한 의학 저널 편집인 협회(KAMJE) 및 식품 의약품 안전처(MFDS)가 발표한 의학 용어 데이터 베이스를 통해 의학 용어를 수집하고, 중복되는 용어를 제거한 뒤 남은 의학 용어를 포함할 수 있다. 또한, 확장한 어휘는 한국 의학 말뭉치의 각 용어 별 출현 횟수를 고려하여, 전체 말뭉치에 세 번 미만으로 나 타난 희귀 단어가 제거되고, 유사성 및 연관성 실험을 통한 유사한 어휘가 추가된 것일 수 있다. 위와 같은 과정을 통해, 의료 영역 단어 기반으로 확장된 어휘는 이후, 의료 영역의 자연어 처리에 있어서, 성 능 향상에 도움이 될 수 있다. 예를 들어, '전신경화증 (systemic sclerosis)'의 발음을 로마자 표기법으로 표기하면 'censinkyenghwacung'이 고, '신경화증 (nephrosclerosis)'의 발음을 로마자 표기법으로 표기하면 'sinkyenghwacung'이므로, 이 두 단 어는 '전신경화증'의 'cen'만 다르고, 나머지는 같은 단어로 구성된다. 그러나 두 단어는 전혀 다른 질병을 의 미한다. '전신경화증'은 한국어에서 '전신' 및 '경화증'으로 끊어 읽히는 반면, '신경화증'에서의 '신경'은 영어로 nerve을 의미하는 점에서 두 단의 '신경'은 'sinkyeng'으로 동일하게 표기되나, 같은 의미로 받아 들여져선 안 된다. 따라서, '전신경화증'은 전(cen)', '##신(sin)', '##경(kyeng)', '##화(hwa)', '##증(cung)'으로 토큰 화 되고, '신경화증'은 '신경(sinkyeng)', '##화(hwa)', '##증(cung)'으로 토큰 화 되어야한다. 그러나, 기존의 한국어 자연어 처리 모델(예를 들어, KR-BERT)은 위와 같은 경우의 두 단어를 적절하게 토큰 화 할 수 없다. 그러나, 본원의 일 실시예에 따른 확장된 어휘는 상술한 두 단어를 모두 포함하고 있다. 이러한 예 시는 본원의 일 실시예에 따른 확장된 어휘가 전문적이고 복잡한 의료 영역의 자연어 처리에 도움이 될 수 있음 을 보여준다. 본원의 일 실시예에 따르면, 본 장치는 말뭉치 데이터에 기초하여, 상술한 가려진 언어 모델(MLM: masked language model) 및 다음 문장 예측(NSP: next sentence prediction)을 수행하는 자연어 처리 모델을 학습시킬 수 있다. 구체적으로, 본 장치는 가려진 언어 모델(MLM: masked language model)의 수행 시, 자연어 처리 모델을 통해 가려진 토큰의 주변 단어를 기반으로 가려진 원래의 단어가 무엇인지 정확히 예측하도록, 말뭉치 데이터 에 포함된 각 단어의 의미를 학습할 수 있다. 또한, 본 장치는 다음 문장 예측(NSP: next sentence prediction)의 수행 시, 자연어 처리 모델을 통해 문장 쌍의 선후 관계를 이진 분류로 예측하고, 이러한 예측을 통해 문장 간의 관계를 학습할 수 있다. 본원의 일 실시예에 따르면, 본 장치는 기존의 인공지능 딥러닝 기법에서 주로 사용되는 최적화 기법을 통 해 자연어 처리 모델 내부의 가중치를, 목표한 바의 손실을 최소화하는 방향으로 갱신할 수 있다. 본원의 일 실시예에 따르면, 본 장치는 상술한 자연어 처리 모델을 기반으로 의료 언어 분석을 수행할 수 있다. 예를 들어, 본 장치는 자연어 처리 모델을 통해 개체 명 인식 및 문장 쌍 유사도 예측을 수행할 수 있다. 도 7은 본원의 일 실시예에 따른 개체 명 인식을 설명하기 위한 개념도이다. 도 7을 참조하면, 본 장치는 상술한 과정을 통해 학습된 자연어 처리 모델을 기반으로, 개체 명 인식(NER: named entity recognition)을 위한 딥러닝 층을 추가하여, 개체 명 인식을 수행할 수 있다. 예를 들어, 본 장치는 입력되는 말뭉치 데이터에 포함되어 있는 단어들을 신체 부위, 질병 및 증상 등의 의료 관 련 태그로 분류할 수 있다. 도 8은 본원의 일 실시예에 따른 문장 쌍 유사도 예측을 설명하기 위한 개념도이다. 도 8을 참조하면, 본 장치는 상술한 과정을 통해 자연어 처리 모델을 기반으로, 문장 쌍 유사도 예측 (MedSTS: medical semantic textual similarity)을 위한 딥러닝 층을 추가하여, 문장 쌍 유사도 예측을 수행할 수 있다. 도 9는 본원의 일 실시예에 따른 자연어 처리 장치의 개략적인 구성도이다. 도 9를 참조하면, 본 장치는 데이터 도입부, 텍스트 분할부, 전처리 필터부, 가려진 언어 모델 수행부, 다음 문장 예측 수행부 및 학습부를 포함할 수 있다. 본원의 일 실시예에 따르면, 데이터 도입부는 의료 분야의 텍스트 데이터를 자연어 처리 모델의 학습을 위 한 변환 데이터로 변환할 수 있다. 본원의 일 실시예에 따르면, 텍스트 분할부는 변환 데이터를 문장 단위의 말뭉치 데이터로 분할 할 수 있다. 구체적으로, 텍스트 분할부는 단일 말뭉치 데이터의 형태인 변환 데이터를 형태소 분석 을 통해 문장 단위의 말뭉치 데이터로 분할할 수 있다. 또한, 텍스트 분할부는 문장 단위의 말뭉치 데이터에 포함된 두 문장을 한 쌍의 문장 쌍으로 결 합할 수 있다. 본원의 일 실시예에 따르면, 전처리 필터부는 정규 표현식을 이용하여 말뭉치 데이터를 필터링할 수 있다. 구체적으로 예시하면, 전처리 필터부는 말뭉치 데이터에 포함된 영문 부분 중 대문자를 소문자 로 변환하고, 말뭉치 데이터에 포함된 웹 링크 부분 및 미리 설정된 유형의 특수 문자 부분을 제거할 수 있다. 본원의 일 실시예에 따르면, 가려진 언어 모델 수행부는 말뭉치 데이터에서 일부의 토큰을 가린 후, 가려진 토큰을 예측할 수 있다. 본원의 일 실시예에 따르면, 다음 문장 예측 수행부는 말뭉치 데이터에서 일부의 단어가 가려진 상태 에서 문장의 선후 관계를 예측할 수 있다. 본원의 일 실시예에 따르면, 학습부는 말뭉치 데이터에 기초하여 가려진 언어 모델 수행부 및 상기 다음 문장 예측 수행부의 자연어 처리 모델을 학습시킬 수 있다. 구체적으로, 학습부는 가려진 언어 모델 수행부의 자연어 처리 모델을 통해 가려진 토큰의 주변 단어 를 기반으로 가려진 단어를 예측하여, 말뭉치 데이터에 포함된 각 단어의 의미를 학습하고, 다음 문장 예 측 수행부의 자연어 처리 모델을 통해 선후 관계를 이진 분류로 예측하여 말뭉치 데이터에 포함된 문 장 간의 관계를 학습할 수 있다. 또한, 학습부는 말뭉치 데이터에 포함된 분할된 한 쌍의 문장을 결합한 문장 쌍을 기초로 자연어 처 리 모델을 학습시킬 수 있다. 또한, 학습부는 토크나이저를 이용하여 확장한 의료 영역 단어를 기반으로 하여 학습을 수행할 수 있고, 사전 학습된 한국어 자연어 처리 모델의 가중치를 초기 가중치로 활용하여 학습할 수 있다. 본원의 일 실시예에 따르면, 분석부는 상술한 자연어 처리 모델을 기반으로 의료 언어 분석을 수행할 수 있다. 구체적으로, 분석부는 자연어 처리 모델을 통해 개체 명 인식 및 문장 쌍 유사도 예측 중 적어도 하 나를 수행할 수 있다. 이하에서는 상기에 자세히 설명된 내용을 기반으로, 본원의 동작 흐름을 간단히 살펴보기로 한다. 도 10은 본원의 일 실시예에 따른 자연어 처리 방법의 개략적인 동작 흐름도이다. 도 10에 도시된 자연어 처리 방법은 앞서 설명된 자연어 처리 장치에 의하여 수행될 수 있다. 따라서, 이 하 생략된 내용이라고 하더라도 자연어 처리 장치에 대하여 설명된 내용은 자연어 처리 방법에 대한 설명 에도 동일하게 적용될 수 있다. 도 10을 참조하면, 단계 S11에서 데이터 도입부는, 의료 분야의 텍스트 데이터를 자연어 처리 모델의 학습 을 위한 변환 데이터로 변환할 수 있다. 다음으로, 단계 S12에서 텍스트 분할부는 변환 데이터를 문장 단위의 말뭉치 데이터로 분할할 수 있다. 구체적으로, 단계 S420에서 텍스트 분할부는 단일 말뭉치 데이터의 형태인 변환 데이터를 형태소 분석을 통해 문장 단위의 말뭉치 데이터로 분할할 수 있다.또한, 단계 S12에서 텍스트 분할부는 문장 단위의 말뭉치 데이터에 포함된 두 문장을 한 쌍의 문장 쌍으로 결합할 수 있다. 다음으로, 단계 S13에서 전처리 필터부는 정규 표현식을 이용하여 말뭉치 데이터를 필터링할 수 있다. 구체적으로 예시하면, 단계 S13에서 전처리 필터부는 말뭉치 데이터에 포함된 영문 부분 중 대 문자를 소문자로 변환하고, 말뭉치 데이터에 포함된 웹 링크 부분 및 미리 설정된 유형의 특수 문자 부분 을 제거할 수 있다. 다음으로, 단계 S14에서 가려진 언어 모델 수행부는 말뭉치 데이터에서 일부의 토큰을 가린 후, 가려 진 토큰을 예측할 수 있다. 다음으로, 단계 S15에서 다음 문장 예측 수행부는 말뭉치 데이터에서 일부의 단어가 가려진 상태에서 문장의 선후 관계를 예측할 수 있다. 다음으로, 단계 S16에서 학습부는 말뭉치 데이터에 기초하여 가려진 언어 모델 수행부 및 상기 다음 문장 예측 수행부의 자연어 처리 모델을 학습시킬 수 있다. 구체적으로, 단계 S16에서 학습부는 가려진 언어 모델 수행부의 자연어 처리 모델을 통해 가려진 토 큰의 주변 단어를 기반으로 가려진 단어를 예측하여, 말뭉치 데이터에 포함된 각 단어의 의미를 학습하고, 다음 문장 예측 수행부의 자연어 처리 모델을 통해 선후 관계를 이진 분류로 예측하여 말뭉치 데이터(12 1)에 포함된 문장 간의 관계를 학습할 수 있다. 또한, 단계 S16에서 학습부는 말뭉치 데이터에 포함된 분할된 한 쌍의 문장을 결합한 문장 쌍을 기초 로 자연어 처리 모델을 학습시킬 수 있다. 또한, 단계 S16에서 학습부는 토크나이저를 이용하여 확장한 의료 영역 단어를 기반으로 하여 학습을 수행 할 수 있고, 사전 학습된 한국어 자연어 처리 모델의 가중치를 초기 가중치로 활용하여 학습할 수 있다. 다음으로, 단계 S17에서 분석부는 상술한 자연어 처리 모델을 기반으로 의료 언어 분석을 수행할 수 있다. 구체적으로, 단계 S17에서 분석부는 자연어 처리 모델을 통해 개체 명 인식 및 문장 쌍 유사도 예측 중 적 어도 하나를 수행할 수 있다. 상술한 설명에서, 단계 S11 내지 S17은 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단 계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 본원의 일 실시예에 따른 자연어 처리 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태 로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발 명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수 도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체 (magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장 하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지 는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코 드를 포함한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작 동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 지금까지 상술한 자연어 처리 장치 및 이를 포함하는 인공지능 의료 언어 분석 시스템에 대한 설명은, 본원의 구현예에 따라서, 하기에서 서술하는 한국어 의료 자연어 처리 인공지능 시스템에 대한 설명을 통해서 이해될 수 있다. 따라서, 이하, 생략된 내용이라고 하더라도 상술한 자연어 처리 장치 및 포함하는 인공지 능 의료 언어 분석 시스템에 대하여 설명된 내용은 하기의 한국어 의료 자연어 처리 인공지능 시스템에도 동일하게 적용될 수 있다. 도 11은 본원의 일 실시예에 따른 한국어 의료 자연어 처리 인공지능 시스템의 개략적인 블록도이다. 설명의 편의를 위해 한국어 의료 자연어 처리 인공지능 시스템을 이하, 본 시스템이라 특정한다. 도 11을 참조하면, 본 시스템은 데이터 도입부, 텍스트 분할부, 전처리 필터부, 가려진 언어 모 델 수행부, 다음 문장 예측 수행부 및 인공지능 딥러닝 학습 수행부를 포함할 수 있다. 도 12는 본원의 일 실시예에 따른 데이터 도입부, 텍스트 분할부 및 전처리 필터부를 설명하기 위한 개략적인 구성도이다. 도 12를 참조하면, 데이터 도입부는 의료 분야의 텍스트 데이터를 자연어 처리 모델의 학습에 용이한 변환 데이터로 변환할 수 있다. 데이터 도입부는 텍스트를 직접 입력하거나, CSV 또는 EXCEL 등과 같은 파일 형식을 도입하거나, MS-SQL 등의 DBMS를 통해 직접 데이터베이스에 접속하여 데이터를 도입할 수 있다. 도 12를 참조하면, 텍스트 분할부는 변환 데이터의 단일 말뭉치 데이터를 형태소 분석을 통해 문장 단위의 분할 말뭉치 데이터로 분할하고, 분할 말뭉치 데이터를 문장 쌍 형태로 결합할 수 있다. 텍스트 분할부에 서 결합된 문장 쌍은 이후, 후술할 자연어 처리 모델의 학습에 활용될 수 있다. 도 12를 참조하면, 전처리 필터부는 분할 말뭉치 데이터를 정규 표현식을 이용하여 필요한 부분을 필터링 할 수 있다. 예를 들어, 문장 쌍 내에 영어가 있을 경우, 대문자를 소문자로 변형하고, 웹 링크 및 특수 문자를 제거할 수 있으나, 여기서 특수 문자는 '#' 및 ',' 등의 일부 특수 문자를 제외한다. 본원의 일 실시예에 따르면, 본 시스템은 한국어 의료 자연어 처리 인공지능 모델을 포함하고, 한국어 의료 자 연어 처리 인공지능 모델은 상술한 전처리 필터부를 거치고 필터링 된 문장 쌍을 입력으로, 자연어 처리를 수행하는 인공지능 모델을 의미한다. 본원의 일 실시예에 따르면, 한국어 의료 자연어 처리 인공지능 모델은 가려진 언어 모델 수행부, 다음 문 장 예측 수행부 및 인공지능 딥러닝 학습 수행부를 포함할 수 있다. 설명의 편의를 위해 한국어 의료 자연어 처리 인공지능 모델을 이하, 자연어 처리 모델이라 특정한다. 도 13a 및 도 13b는 본원의 일 실시예에 따른 한국어 의료 자연어 처리 인공지능 시스템의 각 블록을 상세 설명 하기 위한 대표적인 예문 및 코드이다. 도 13a를 참조하면, 가려진 언어 모델 수행부는 전처리 필터부에서 필터링 된 문장 쌍에서 일부의 단 어를 아무 의미 없는 토큰으로 가린 후, 토큰에 의해 가려진 단어가 어떤 단어인지 예측할 수 있다. 가려진 언 어 모델(Masked Language Model)은 약자로 MLM으로 표현될 수 있다. 다음 문장 예측 수행부는 전처리 필터부에서 필터링 된 문장 쌍에서 일부의 단어가 가려진 상태를 유 지한 채로 두 문장 쌍의 선/후 관계 여부를 예측할 수 있다. 다음 문장 예측(Next Sentence Prediction)은 약자 로 NSP로 표현될 수 있다. 도 13b를 참조하면, 인공지능 딥러닝 학습 수행부는 인공지능 딥러닝 기법을 통해 가려진 언어 모델 수행 부 및 다음 문장 예측 수행부에 의한 수행에 대한 손실을 최소화하는 방향으로 학습하고, 사전 학습 된 결과에 가중치를 더하여 학습할 수 있다. 사전 학습은 본 시스템이 적용되기 전의 기존의 자연어 처리 인공지능 시스템에 의한 학습을 말하는 것이다. 본 시스템은 효율적인 학습을 위해, 자연어 처리 모델의 초기 가중치를 사전 학습된 KR-BERT의 가중치로 대체할 수 있다. 본원의 일 실시예에 따르면, 인공지능 딥러닝 학습 수행부는 가려진 언어 모델 수행부의 수행 과정을 통해, 토큰의 주변 단어를 기반으로 가려진 단어를 맞추도록 각 단어의 의미를 학습할 수 있다. 본원의 일 실시예에 따르면, 인공지능 딥러닝 학습 수행부는 다음 문장 예측 수행부의 수행 과정을 통해, 이진 분류로 선/후 관계 여부를 예측하고, 이를 통해 문장 간의 관례를 학습할 수 있다. 전술한 도 11을 참조하면, 전처리 필터부에서 필터링 된 문장 쌍은 가려진 언어 모델 수행부 또는 다 음 문장 예측 수행부로 전달될 수 있고, 인공지능 딥러닝 학습 수행부는 가려진 언어 모델 수행부 또는 다음 문장 예측 수행부의 수행 과정을 통해 학습하고, 이러한 과정은 반복을 통해 학습되어, 자연어 처리 모델의 예측 정확도를 상승시킬 수 있다. 본원의 일 실시예에 따르면, 자연어 처리 모델은 자연어 처리 엔진으로 활용되어, 이를 기반으로 한 정밀 학습 을 통해 한국어 의료 텍스트 분석을 수행할 수 있다. 본원의 일 실시예에 따르면, 자연어 처리 모델의 마지막 층(Layer)에 목적에 부합하는 딥러닝 층을 추가하여, 상술한 학습 단계에서 수행한 작업이 아닌 새로운 문제를 해결하기 위한 작업을 수행할 수 있다. 예를 들어, 도 15a 및 도 15b를 참조하면, 이러한 작업은, 개체 명 인식(도 15a) 또는 문장 쌍 유사도 예측(도 15b)일 수 있고, 이때, 자연어 처리 모델은 개체 명 인식 수행 결과값 또는 문장 쌍 유사도 예측 수행 결과값을 잘 예측하도록 정밀 학습될 수 있다. 이는 이전의 학습 단계와 비교하여 소규모 데이터로 학습이 가능하고, 학 습이 빠르게 수행되기 때문에 활용도가 매우 높다고 할 수 있다. 개체 명 인식(Named Entity Recognition)은 약자로 NER, 문장 쌍 유사도 예측(Medical Semantic Textual Similarity)은 약자로 MedSTS로 표현된다. 의료 말뭉치 문장 쌍 데이터 120만여건을 이용하여 본 발명의 결과물인 한국어 의료 자연어 처리 모델(KM-BERT; Korean Medical BERT)을 학습하였다. 의료 분야에서의 활용도를 평가하기 위하여 한국어에 적용 가능한 인공지 능 자연어 처리 모델 2가지 KR-BERT, M-BERT (Multilingual BERT)를 적용하고 3가지 자연어 처리 문제의 해결 에 대한 성능을 도출하고 비교하였다. 자연어 처리에서 우수함을 이미 증명한 BERT를 사용하였으며 이 모델은 12개의 self-attention 층으로 이루어져있다. KR-BERT는 한국어에 특화하여 학습된 딥러닝 자연어 처리 모델이다. 본 발명과는 달리 분야를 특정하여 학습된 것이 아닌 일반적인 한국어 데이터를 학습한 모델이다. M-BERT는 104개의 언어를 아우르는 다국어 자연어 처리 모델이다. 여러 어로 작성된 위키백과를 학습한 자연어 처리 모델로 한국어 텍스트 데이터를 분석하는 데에 많이 활용되는 대표적인 자연어 처리 모델이다. 도 14은 본원의 일 실시예에 따른 한국어 의료 자연어 처리 인공지능 시스템의 언어이해능력을 평가하기 위하여 한국어 의료 텍스트에 대한 다음문장예측의 정확도 측정 결과를 나타내는 표이다. 도 14를 참조하면, 본 발명의 언어이해능력을 평가하기 위하여 한국어 의료 텍스트에 대한 다음문장예측의 정확 도 측정 결과를 확인할 수 있다. 성능 평가를 위하여 3가지 범주의 의료 말뭉치 데이터를 활용하였다. 본 발명 은 기존의 한국어 자연어 처리 모델보다 월등한 성능을 보였다. 도 16은 본원의 일 실시예에 따른 한국어 의료 자연어 처리 인공지능 시스템의 의료 텍스트 문제해결에 대한 활 용도를 평가하기 위하여 한국어 의료 개체 명인식 문제와 의료 문장 쌍 유사도 평가 문제를 수행한 결과를 나타 내는 표이다. 도 16을 참조하면, 본 발명의 의료 텍스트 문제해결에 대한 활용도를 평가하기 위하여 한국어 의료 개체 명인식 문제와 의료 문장 쌍 유사도 평가 문제를 수행 결과를 확인할 수 있다. 각 문제에서 본 발명이 가장 우수한 성 능을 보였고 이는 의료 텍스트에 본 발명을 적용하는 것의 의의와 활용성을 대변하는 결과이다. 이하에서는, KR-BERT문자 토크나이저와 BRAT에서 사용되는 사전 학습 프레임위크를 이용한, 본 시스템의 구체적 인 딥러닝 기반의 자연어 처리 인공지능 시스템의 학습 방법에 대해 상세히 서술한다. 여기서, 상술한 본원의 자연어 처리 모델 및 이를 포함한 본 시스템을 포함한, 본 발명의 결과물을 한국어 의료 BERT(Krean Medical BERT)의 의미로 KM-BERT라고 특정한다. 사전 학습 과정에서, KM-BERT는 MLM(가려진 언어 모델) 및 NSP(다음 문장 예측) 작업에 대해 사전 학습할 수 있 다. MLM은 마스킹 된 토큰에 대한 토큰 수준의 작업이고, NSP는 두 문장의 관계 여부를 판단하는 작업이다. 두 작업 모두 두 문장에 대한 모델의 교차 엔트로피 손실을 최소화하여 올바른 레이블을 분류하는 것을 목표로 한다. MLM에서 모든 토큰의 15%가 각 문장에 대해 무작위로 마스킹 되고, 마스킹 된 토큰만 예측에 고려된다. 마스킹 된 토큰 중 80%는 MASK 토큰으로 변경되고, 10%는 랜덤 토큰으로 변경되며, 나머지 10%는 변경되지 않았다. 그 리고, 토큰을 마스킹 한 레이블은 단어의 크기로 제한되었다. 즉, MLM 레이블의 크기는 모델의 전체 단어 크기에 해당한다. 예를 들어, 'c'는 마스킹 된 토큰에 대한 one-hot 레이블 벡터이고, 'p'는 예측 확률이라 할 때, 단일 마스킹 된 토큰에 대한 MLM 손실은 아래와 같이 정의할 수 있다.[식 3]"}
{"patent_id": "10-2021-0179385", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "[식 3]에서 'V'는 단어의 크기를 나타낸다. 한 쌍의 문장에서 모든 마스킹 된 토큰에 대한 평균 MLM 손실을 사 용했다. NSP에는 IsNext와 NotNext라는 두 개의 레이블이 있다. cIsNext와 pIsNext를 각각 다음 문장 관계의 레이블과 예측 확률이라고 할 때, NSP 손실은 다음과 같이 정의할 수 있다. [식 4]"}
{"patent_id": "10-2021-0179385", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이후, MLM 손실과 NSP 손실을 합산하여, 총 손실을 도출할 수 있으며, KM-BERT의 가중치는 총 손실에 대해 업데 이트 된다. 본원의 일 실시예에 따르면, 위해 KM-BERT는 토크나이저를 사용한 단어를 보완함으로써, 잘못된 토큰화가 빈번 할 경우의 발생할 수 있는 언어의 이해에 대한 방해를 방지할 수 있다. 여기서, 토크나이저란, 텍스트를 '토 큰'이라는 작은 단위로 분리하는 작업을 하는 함수나 메소드를 일컫는다. 상술한 단어 보완을 위해, 대한 의학 저널 편집인 협회(KAMJE)와 식품의약품안전처(MFDS)가 발표한 의학용어 데 이터베이스를 검색해 70,415개의의학용어를 수집한 후, 두 데이터베이스 간에 중복되는 용어를 제거함으로써 69,206개의 의학 용어를 고려했다. 비록 KAMJE와 MFDS의 용어들이 문맥에 따라 잠재적으로 유익하거나 의미 있 지만, 몇몇 단어들은 의료용 말뭉치에서도 거의 사용되지 않는다. 또한, 희귀어를 제거하기 위해, 우리는 한국 의학 말뭉치의 각 용어별 출현 횟수를 고려했다. MFDS 약물 데이터 세트의 주요 성분과 첨가물에 대한 용어를 고려했고 전체 말뭉치에 세 번 미만으로 나타난 단어를 제거했다. 또한, 출현 횟수가 적은 단어들을 제거한 말뭉치들 중에서, 코사인 유사성을 기반으로 유사 단어가 추가된 것들 중 상위 10,000개의 단어들을 선택한 후, 유사성과 연관성 실험에 의해 1,629개의 단어를 추가하여 확장된 단어 로 통합했다. KR-BERT 어휘와 중복되는 것을 제외한 10,562개의 의학용어를 채택하고, 무분별한 양의 증가를 방지하기 위해 드물게 사용되는 단어를 어휘에서 제외하였다. 제안된 모델에 대한 의료 영역의 언어 이해를 향상시키기 위해 26,986(KM-BERT-vocab)의 어휘 크기로 KM-BERT에 확장된 의료 단어의 보충을 포함할 것을 제안하고, 이 보완이 추가된 후 모델의 임베딩 레이어의 가중치는 초기화 되었다. 부록은 어휘에서 의학 용어의 범위를 늘렸다. 예를 들어, '전신경화증 (systemic sclerosis)' 의 한글 로마자는 'censinkyenghwacung' 이고, '신경화증 (nephrosclerosis)' 의 한글 로마자는 'sinkyenghwacung' 이다. 이 두 한국어 용어는 같은 단어로 구성되며 첫 번째 'cen' 음절만 다르므로 각 단어는 완전히 다른 질병을 나타낸다. 확장 어휘에는 해당하는 단일 토큰으로 토큰 화 된 두 의학 용어가 모두 포함되어 있다. KR-BERT는 해당 용어를 '전(cen)', '##신(sin)', '##경(kyeng)', '##화(hwa)', '##증(cung)' 토큰과 '신경(sinkyeng)', '##화(hwa)', '##증(cung)' 토큰으로 적절히 토큰 화하지 못한다. '신경(sinkyeng)'은 한국어로 신경을 의미한다는 점에 유의 해야한다. 이 예는 의학용어의 보충을 포함하는 것이 전문적이고 복잡한 의학 분야에서 자연어 처리에 도움이 될 수 있음을 시사한다. 따라서, KM-BERT는, 이러한 방법으로, 의학용어를 기반으로 확장되고 보완된 단어들을 포함함으로써, 전문적이 고 복잡한 의학 분야에서의 자연어 처리 작업이 더욱 유리해질 수 있다. 상술한 사전 학습 및 단어의 확장을 기반으로 수행한 학습 방법을 이용한 KM-BERT, 즉 본 시스템은 한국어 의학 용어에 대한 인공지능 자연어 처리에 있어서 높은 성능을 나타낼 수 있다. 이하에서는, 상술한 과정에 의한 KM-BERT의 언어 이해 능력을 평가하고, NLP 실험을 통해 KM-BERT와 기존의 BERT 모델(KR-BERT 및 M-BERT)과의 성능 비교 결과에 대해 상세히 서술한다. M-BERT 및 KR-BERT 모델은 실험의 기준 모델로 간주하였다.상술한 바와 같이, KR-BERT는 대표적인 한국어 기반의 BERT이고, M-BERT는 영어를 포함한 상위 104개의 언어를 기반으로 하는 다국어 BERT이다. 성능 비교를 위한 실험은, 사전 학습, 내부 평가 및 외부 평가의 수행으로 진행하였다. 한국 의료 말뭉치는 사전 학습에 사용되고, 이 말뭉치의 90%는 학습 세트로, 10%는 검증 세트로 무작위로 분할 되었다. 모델은 학습 세트에서 학습되었고 성능은 검증 세트를 사용하여 측정되었다. 또한, 모델을 본질적으로 평가하기 위해 실험을 위한 말뭉치 유형으로써 외부 데이터 세트를 수집했다. 데이터 세트는 다음 문장 관계가 있는 294개 문장 쌍의 3개 세트로 구성되고, 각 세트의 각 문장 쌍은 의학 교과서, 건 강 정보 뉴스 및 의학 연구 기사에서 수동 검토를 통해 추출되었다. 그러나 국문 말뭉치와 외부 데이터 세트 간 에 중복되는 부분은 없었다. 외부 데이터 세트에 사용된 의학 교과서는 언급된 두 출판사의 것이 아니고, 2021 년 1월과 2월에 업로드 된 건강 정보 뉴스와 2009년에 게재된 의학 연구 기사만 고려하였다. 마지막으로, 본원에서는, 3121개의 영어 문장 쌍과 0-5의 해당 유사도 점수로 구성된 원본 MedSTS에서 각 문장 을 번역한 한국 의료 의미 텍스트 유사성(MedSTS) 데이터 세트를 획득했다. 먼저 Google 기계 번역을 통해 MedSTS 데이터 세트를 처리하고 수동 검증을 통해 정제하고, 학습 세트에 2,393개의 문장 쌍을 사용하고 테스트 세트에 728개의 문장 쌍을 사용했다. 또한 임상 용어가 태그 된 2,189개의 국문 문장으로 구성된 국문 NER(Medical Named Entity Recognition) 데이터 세트를 획득하였다. 각 모델의 의료 태그 성능을 평가하기 위 해 5중 교차 검증을 사용했다. 모든 실험은 Intel(R) Xeon(R) Silver 4210R CPU 2.40GHz, 256GB RAM 및 RTX 3090의 듀얼 GPU가 있는 Ubuntu 18.04.2 LTS 서버에서 수행되었다. 이하, 상술한 사전 학습에 대해 서술한다. MLM(가려진 언어 모델) 및 NSP(다음 문장 예측) 작업에 대한 BERT의 사전 학습을 위해 레이블이 지정되지 않은 말뭉치가 사용되었다. MLM 작업은 각 마스킹 된 토큰에 대한 적절한 토큰 레이블을 예측하는 것을 목표로 하고 NSP 작업은 두 레이블(IsNext 또는 NotNext)을 사용하여 분류를 수행한다. 각 작업은 학습 과정에서 감독 된 메 커니즘을 따랐다. 그러나 두 문장을 무작위로 결합하고 토큰을 마스킹하여 레이블이 없는 말뭉치에서 필요한 데 이터를 구성할 수 있다. 문장을 연결할 때 문장 쌍의 절반이 두 개의 관련 없는 문장으로 대체되었다. 즉, IsNext와 NotNext 레이블의 비율은 NSP 작업에 대해 일 대 일이었다. 다음으로, 문장을 토큰으로 토큰화 한 다음 각 토큰을 MLM 작업을 위 해 무작위로 마스킹 했다. 따라서 우리는 한국 의료 말뭉치를 기반으로 사전 학습을 위한 600만 문장 쌍 데이터 세트를 구축했다. 계산 사양을 고려하여 배치 크기 32와 최대 문장 길이 128 토큰을 사용하고, 학습률 1e-6을 사용했다. 도 17은 본원의 일 실시예에 따른 사전 학습에서의, 시대에 따른 MLM 및 NSP 작업에 대한 KM-BERT 및 KM-BERT- vocab의 사전 학습 결과 및 KR-BERT 및 M-BERT에 대한 각 점선은 최종 사전 학습된 모델의 성능을 나타내는 도 면이다. 도 17을 참조하면, M-BERT는 MLM 정확도 0.547, NSP 정확도 0.786, MLM 손실 2.295, NSP 손실 0.479를 달성했 다. KR-BERT는 MLM 정확도 0.619, NSP 정확도 0.821, MLM 손실 1.869, NSP 손실 0.916을 달성했다. KR-BERT는 약간 더 나은 성능을 보였다. NSP 손실을 제외하고 M-BERT보다 KM-BERT와 KM-BERT-vocab은 모두 기본 언어 모델에 비해 상당히 향상된 성능을 보였다. 학습을 한 번 한 후에도 성능 격차가 나타났다. 이는 일반 말뭉치로 학습하는 것이 한국 의료 영역에 대한 적절한 언어 이해를 보장할 수 없음을 의미할 수 있다. 이하, 상술한 내부 평가에 대해 서술한다. 모델의 언어 이해 능력을 비교하기 위해 외부 한국 의료 말뭉치에 대해 MLM과 NSP에 대한 내부 평가를 수행하였 다. 본원에서는, 294개 문장 쌍의 3개 세트에 대해 MLM 작업을 수행하였다. 이 평가에서는 동일한 규칙을 사용하여 토큰을 마스킹 했다. 이 규칙에는 임의의 측면이 포함되어 있다. 따라서 성능은 MLM 작업을 100회 반복하여 측 정되었다.도 18은 본원의 일 실시예에 따른 내부 평가에서의, 각 말뭉치 유형에 대한 각 언어 모델에 대한 100회 반복에 의한 MLM 정확도 분포를 나타내는 도면이다. 도 18을 참조하면, 반복 실험을 통해 외부 한국어 의료 말뭉치에 대한 각 언어 모델의 MLM 정확도를 평가하였다. KM-BERT는 말뭉치 유형에 관계없이 MLM과 KM-BERT-vocab에서 사전 학습된 언어 모델을 능가했다. M-BERT는 가장 낮은 성능을 보였다. 4개의 동일한 모델의 성능은 사용된 말뭉치의 유형에 따라 달라질 수 있다. M-BERT를 제외하고, 모델의 전반적 인 성능은 다른 의학 교과서나 의학 연구 기사보다 건강 정보 뉴스에서 더 높았다. 의학 교과서 및 연구 논문이 전문화되고 해독이 어려운 점을 감안할 때 일반 및 대중 건강 정보 뉴스에 대한 모델의 성능이 더 우수함을 유 추할 수 있으므로 영역별 NLP 모델과 본 발명의 자연어 처리 모델인 KM-BERT 및 KM-BERT-vocab 의 개발이 필요 함을 시사하고 효율성과 시급성을 강조한다. 실제로 KM-BERT와 KR-BERT의 건강정보 뉴스 성적 차이는 0.067, 의 학 연구 기사의 경우 0.119였다. MLM 작업 외에도 외부 한국 의료 말뭉치에 대해 NSP 작업을 수행하였다. NSP의 경우, 다음 관계가 없는 294개의 임의 문장 쌍으로 구성된 3개의 추가 세트를 생성했다. 즉, 유형별로 다음 문장 관계로 분류되어야 하는 문장 쌍이 294개, 그렇지 않아야 하는 임의의 문장 쌍이 294개 있었다. 여기서, 다음 관계란, 문장 쌍 사이의 선/후 관계, 즉 어느 하나의 문장 쌍 다음에 또 다른 하나의 문장 쌍이 이어지는가에 관한 관계를 의미한다. 도19는 본원의 일 실시예에 따른 내부 평가에서의, NSP 작업에 대한 예측된 다음 문장 확률 분포를 나타내는 도 면이다. 도 19를 참조하면, 각 모델은 의학 교과서, 건강 정보 뉴스 및 의학 연구 기사에 대한 다음 문장 쌍의 세 그룹 을 분류하고, 세 그룹의 모든 샘플은 다음 문장 관계를 갖도록 분류되어야 한다. 다른 세 그룹은 의학 교과서, 건강 정보 뉴스 및 의학 연구 기사에 대한 임의의 문장 쌍으로 구성되었다. 전반적으로 NSP 성능은 다음 문장 그룹에서 높은 것으로 측정되었다(도 20의 4A-C). 이 네 가지 모델은 다음 관 계에 대한 이진 분류에 대해 허용 가능한 오류를 보여주었다. 반면에 NSP 성능은 다음 문장 관계가 없는 데이터 그룹에서 더 낮았다(도 20의 4D-F). 또한, KR-BERT는 IsNext 레이블에 대한 매우 낮은 오류에 비해 NotNext 레 이블에 대해 상당히 큰 오류를 보였다. 그러나, KM-BERT와 KM-BERT-vocab은 다른 모델에 비해 NotNext 레이블에 대해 상대적으로 낮은 오류를 보였다. 이러한 결과는 영역별 사전 학습이 해당 영역 말뭉치의 언어 이해에 영향을 줄 수 있음을 분명히 보여준다. 이러한 전반적인 경향은 감독 되지 않은 NSP 과제를 사용한 사전 학습의 효과에 대한 이전 연구 결과와 일치한 다. BERT가 NSP 학습 목표를 사용하여 생물의학 말뭉치에 대해 사전 학습을 받을 때 BERT 표현은 생물 의학 텍 스트의 연결 및 부정과 같은 담화 기대치에 점점 더 민감해지는 것으로 보고되었다. 구체적으로, PubMed 기사와 추상물에 대해 학습된 BioBERT는 생물 의학 담화 관계 은행이 제안한 기본적인 담화 관계를 이해하는 데 있어 몇 가지 개선점을 보여주었다. 도 20은 본원의 일 실시예에 따른 내부 평가에서의, 내부 평가 데이터 세트의 NSP 정확도를 나타내는 도면이다. NSP 정확도는 예측 확률 0.5를 임계값으로 하여 다음 문장 관계를 결정함으로써 평가되었다. KM-BERT-vocab은 다음 문장 관계 그룹 중에서 NSP 정확도가 가장 높았다. 같은 그룹에서 M-BERT는 가장 낮은 NSP 정확도를 보였 지만 차이는 크지 않았다. 그러나 다음 관계가 없는 데이터 그룹에서의 모델별 NSP 정확도 차이는 명확하게 드 러났다. NSP 정확도가 가장 높은 언어 모델은 KM-BERT였으며, KM-BERT는 KM-BERT-vocab보다 약간 더 높은 NSP 정확도를 달성했다. KR-BERT는 KM-BERT에 비해 성능 차이가 크게 나 동일한 데이터 그룹에서 가장 낮은 정확도 를 보였다. 이는 의료 영역 텍스트에 대한 KR-BERT의 문장 관계 추론에 한계가 있는 것으로 해석될 수 있다. 이하, 상술한 외부 평가에 대해 서술한다. 다운스트림 작업에 대한 미세 조정 성능을 입증하기 위해 MedST 데이터 세트와 한국 의료 NER 데이터 세트에 대 해 외부 평가가 수행되었다. 각 언어 모델에 의해 측정된 유사도와 MedSTS의 실제 사람에 의해 측정된 유사도 사이의 Pearson 상관(Pearson correlation)과 Spearman 상관(Spearman correlation)을 조사하였다. 또한 한국 의료 NER 데이터 세트의 태그 작업에 대한 F1 점수를 측정했다. 각 모델은 학습 세트로 미세 조정되 었고, 성능은 테스트 세트를 사용하여 평가되었으며, 본 발명에서는, 32의 배치 크기를 사용했고 2e-5, 3e-5, 5e-5의 학습 속도와 2, 3, 4의 학습 기간을 고려했다.도 21은 본원의 일 실시예에 따른 외부 평가에서의, MedSTS에 대한 외부 평가 결과를 나타내는 도면이다. 도 21을 참조하면, 문장 유사도 측정 작업에서 가장 우수한 언어 모델은 KM-BERT였다. 반면, KR-BERT는 예측된 문장 유사성과 가장 낮은 상관관계를 보였다. 이는 MedSTS 데이터 세트의 문장 관계가 한국의 의료 말뭉치에 대 한 사전 학습을 통해 적절하게 학습되었음을 나타낸다. 도 22는 본원의 일 실시예에 따른 외부 평가에서의, KM-BERT 및 KR-BERT로 측정한 실제 MedSTS 유사성과 유사성 을 포함하는 MedSTS 데이터 세트의 예를 나타내는 도면이다. 도 22를 참조하면, MedSTS 데이터 세트의 예를 사용하여 KM-BERT 및 KR-BERT에 의한 유사성 측정에 대한 사례 연구를 수행했고, 각 모델에서 측정된 문장 유사도의 성능 차이를 보인 문장 쌍의 두 가지 경우를 확인할 수 있 다. 도 21을 참조하면, KM-BERT가 예측한 유사성은 KR-BERT가 예측한 유사성과 비교하여 실제 사람이 측정한 유사성 과 유사했다. 이는 KM-BERT와 KR-BERT 사이의 약물과 제제에 대한 임베딩(embedding)이 다르기 때문인 것으로 추측된다. 반면, 도 22를 참조하면, KR-BERT가 실제 사람이 측정한 점수에 더 가까운 유사성을 측정하는 경우이다. 이 경 우는 의료 시스템의 환자 관리에 대한 지침이며 세부 사항에는 차이가 있다. 또한, KM-BERT는 유사성을 더 높게 측정했지만, 결과의 유효성은 해석에 따라 다르다. MedSTS 작업 외에도 한국 의료 NER(자연어 처리) 데이터 세트에 대해 본 발명의 자연어 처리 모델을 평가했다. 도 23은 본원의 일 실시예에 따른 외부 평가에서의, 한국어 의료 자연어 처리에 대한 외부 평가 결과를 나타내 는 도면이다. 도 23을 참조하면, 데이터 세트는 신체 부위, 질병, 증상의 3가지 의료 태그로 구성된다. 한국 의료 NER의 성능 은 3개의 의료 태그에 대한 평균 F1 점수를 통해 측정되었다. KM-BERT는 상당한 성능 향상과 함께 가장 높은 F1 점수를 보였다. KR-BERT 및 M-BERT와 비교하여 성능 향상이 관찰되었다. 이는 한국 의료 말뭉치에 대한 사전 학 습이 한국 의료 NER 과제에 효과적임을 의미한다. 본원의 일 실시예에 따르면, 사전 학습 된 한국어 의료 NLP 모델을 확장된 어휘로 제시했다. 또한, 본 발명의 자연어 처리 모델인 KM-BERT는 3가지 유형의 논문(의학 교과서, 건강정보 뉴스, 의학 연구 논문)에서 수집된 한 국 의학 말뭉치에 대해 학습하였다. 한국 의학 말뭉치는 600만 개의 무명 문장과 1억 1600만 단어로 구성되어 있고, KM-BERT는 MLM 및 NSP 작업에 대해 레이블이 지정되지 않은 말뭉치를 사용하여 한국어로 작성된 의료 영 역에 대한 언어 이해를 사전 학습하는 데 사용되었다. 특히 한국 의료 영역에서 KM-BERT의 우수성을 입증하기 위해 내부 평가 및 외부 평가를 수행했고, 새로운 한국 의료 말뭉치와 MedSTS 데이터 세트에 대해 KM-BERT과 기준선의 성능을 조사했다. 각 결과는 기본 언어 모델과 비교하여 KM-BERT의 우수한 성능을 보여주었고, KM-BERT는 전반적으로 향상된 언어 이해 능력을 보였다. 본 발명은 사전 학습 된 언어별 모델에서 영역별 사전 학습의 타당성을 입증했다. 본 발명의 사전 학습 접근 방 식을 사용하면 모델의 언어 이해도가 증가하는 것으로 나타났고, 내부 평가는 모델 자체의 언어 이해 능력을 보 여주었고, 외적 평가는 다른 NLP 과제에 대한 적용 가능성을 보여주었다. 따라서 본 발명은 의사를 포함한 의료 분야 관련 종사자들에게 도움이 될 것으로 기대되고, 이후로는 다양한 언어에도 적용될 수 있는 가능성을 가지 고 있다."}
{"patent_id": "10-2021-0179385", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "전술한 본원의 설명은 예시를 위한 것이며, 본원이 속하는 기술분야의 통상의 지식을 가진 자는 본원의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해 석되어야 한다. 부호의 설명10: 인공지능 의료 언어 분석 시스템 100: 자연어 처리 장치 110: 데이터 도입부 111: 변환 데이터 120: 텍스트 분할부 121: 말뭉치 데이터 122: 문장 쌍 130: 전처리 필터부 131: 필터링 데이터 140: 가려진 언어 모델 수행부 150: 다음 문장 예측 수행부 160: 학습부 161: 개체 명 인식 딥러닝 층 162: 문장 쌍 유사도 예측 딥러닝 층 170: 분석부 200: 네트워크 300: 데이터 베이스 201: 데이터 도입부 202: 텍스트 분할부 203: 전처리 필터부 301: 가려진 언어 모델 수행부 302: 다음 문장 예측 수행부 303: 인공지능 딥러닝 학습 수행부 401: 한국어 의료 텍스트에 대한 다음문장예측의 정확도 측정 결과 501: 개체 명 인식 수행시, 모델의 입력값으로 들어가는 한국어 텍스트 502: 개체 명 인식 수행시, 딥러닝 한국어 의료 자연어 처리 모델 503: 개체 명 인식 수행시, 추가되는 딥러닝 층 504: 문장 쌍 유사도 예측 수행시, 모델의 입력값으로 들어가는 한국어 텍스트 505: 문장 쌍 유사도 예측 수행시, 딥러닝 한국어 의료 자연어 처리 모델 506: 문장 쌍 유사도 예측 수행시, 추가되는 딥러닝 층 601: 한국어 의료 개체 명인식 문제와 의료 문장 쌍 유사도 평가 문제 수행 결과"}
{"patent_id": "10-2021-0179385", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본원의 일 실시예에 따른 인공지능 의료 언어 분석 시스템의 개략적인 구성도이다. 도 2는 본원의 일 실시예에 따른 변환 데이터의 예시를 나타내는 도면이다. 도 3은 본원의 일 실시예에 따른 말뭉치 데이터 및 문장 쌍의 예시를 나타내는 도면이다. 도 4는 본원의 일 실시예에 따른 필터링 데이터의 예시를 나타내는 도면이다. 도 5는 본원의 일 실시예에 따른 가려진 문장 모델 수행을 설명하기 위한 개념도이다. 도 6은 본원의 일 실시예에 따른 다음 문장 예측 수행을 설명하기 위한 개념도이다. 도 7은 본원의 일 실시예에 따른 개체 명 인식을 설명하기 위한 개념도이다. 도 8은 본원의 일 실시예에 따른 문장 쌍 유사도 예측을 설명하기 위한 개념도이다. 도 9는 본원의 일 실시예에 따른 자연어 처리 장치의 개략적인 구성도이다. 도 10은 본원의 일 실시예에 따른 자연어 처리 방법의 개략적인 동작 흐름도이다. 도 11은 본원의 일 실시예에 따른 한국어 의료 자연어 처리 인공지능 시스템의 개략적인 블록도이다. 도 12는 본원의 일 실시예에 따른 데이터 도입부, 텍스트 분할부 및 전처리 필터부를 설명하기 위한 개략적인 구성도이다. 도 13a 및 도 13b는 본원의 일 실시예에 따른 한국어 의료 자연어 처리 인공지능 시스템의 각 블록을 상세 설명 하기 위한 대표적인 예문 및 코드이다. 도 14은 본원의 일 실시예에 따른 한국어 의료 자연어 처리 인공지능 시스템의 언어이해능력을 평가하기 위하여 한국어 의료 텍스트에 대한 다음문장예측의 정확도 측정 결과를 나타내는 표이다. 도 15a은 본원의 일 실시예에 따른 한국어 의료 자연어 처리 인공지능 시스템과 개체 명 인식에 대한 개략적인 동작 흐름도이다. 도 15b은 본원의 일 실시예에 따른 한국어 의료 자연어 처리 인공지능 시스템과 문장 쌍 유사도 예측에 대한 개 략적인 동작 흐름도이다. 도 16은 본원의 일 실시예에 따른 한국어 의료 자연어 처리 인공지능 시스템의 의료 텍스트 문제해결에 대한 활 용도를 평가하기 위하여 한국어 의료 개체 명인식 문제와 의료 문장 쌍 유사도 평가 문제를 수행한 결과를 나타 내는 표이다. 도 17은 본원의 일 실시예에 따른 사전 학습에서의, 시대에 따른 MLM 및 NSP 작업에 대한 KM-BERT 및 KM-BERT- vocab의 사전 훈련 결과 및 KR-BERT 및 M-BERT에 대한 각 점선은 최종 사전 훈련된 모델의 성능을 나타내는 도 면이다. 도 18은 본원의 일 실시예에 따른 내부 평가에서의, 각 말뭉치 유형에 대한 각 언어 모델에 대한 100회 반복에 의한 MLM 정확도 분포를 나타내는 도면이다.도19 는 본원의 일 실시예에 따른 내부 평가에서의, NSP 작업에 대한 예측된 다음 문장 확률 분포를 나타내는 도면이다. 도 20은 본원의 일 실시예에 따른 내부 평가에서의, 내부 평가 데이터 세트의 NSP 정확도를 나타내는 도면이다. 도 21은 본원의 일 실시예에 따른 외부 평가에서의, MedSTS에 대한 외부 평가 결과를 나타내는 도면이다. 도 22는 본원의 일 실시예에 따른 외부 평가에서의, KM-BERT 및 KR-BERT로 측정한 실제 MedSTS 유사성과 유사성 을 포함하는 MedSTS 데이터 세트의 예를 나타내는 도면이다. 도 23은 본원의 일 실시예에 따른 외부 평가에서의, 한국어 의료 자연어 처리에 대한 외부 평가 결과를 나타내 는 도면이다."}
