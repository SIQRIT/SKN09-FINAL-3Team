{"patent_id": "10-2023-0186513", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0099068", "출원번호": "10-2023-0186513", "발명의 명칭": "ROI 제한 및 작물판단 및 회피", "출원인": "주식회사 한국쓰리축", "발명자": "정희종"}}
{"patent_id": "10-2023-0186513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "중앙에 위치하는 주행기체부;상기 주행기체부의 좌우 양측부에 배치되는 한쌍 구성이고, 주행기체부의 이동성을 담당하기 위한 주행부;상기 주행기체부의 중앙부에 위치시켜 착탈 가능하게 구비되고, 앞쪽에 주간 제초용 구동형 제초날과 뒤쪽에 조간 제초용 쟁기형 제초날을 구비하여 작업지의 주간과 조간 측 제초작업을 동시에 수행하기 위한 주간조간제초유닛부;를 포함하되,상기 주간조간제초유닛부는,주행기체부 상에 장착되고, 작물 인식을 통해 작물 사이의 잡초 제거에 사용하기 위한 영상정보를 제공하는 작물인식카메라; 및상기 작물인식카메라로부터 입력되는 영상의 ROI(region of interest) 영역에서 작물영역을 판단하는 인공신경망 기반의 작물인식모델; 상기 작물인식모델로부터 판단된 작물인식결과에 대응하여 주간 및 조간 제초작업을 제어하기 위한 제초컨트롤러부;를 포함하고상기 제초컨트롤러부는 작물인식결과 작물영역이 인식되면 상기 구동형 제초날을 회피위치로 전환시키는 것을특징으로 하는 제초 로봇."}
{"patent_id": "10-2023-0186513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 ROI 영역은 작물인식카메라로부터 입력되는 영상중 구동형 제초날이 위치된 좌측 및 우측 하단 영역으로제한되는 것을 특징으로 하는 제초 로봇."}
{"patent_id": "10-2023-0186513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 구동형 제초날은 제초 위치에서 회피 위치로 전환될 때 90도 회전하도록 동작하는 것을 특징으로 하는제초 로봇."}
{"patent_id": "10-2023-0186513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 작물인식모델은 ANN(Artificial Neural Networks), CNN(convolution neural network)으로 인공신경망 모델인 것을 특징으로 하는제초 로봇.공개특허 10-2024-0099068-3-"}
{"patent_id": "10-2023-0186513", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 작물인식에 기반한 제초 로봇에 관한 것으로 본 발명의 일양태에 따르면 중앙에 위치하는 주행기체부; 상기 주행기체부의 좌우 양측부에 배치되는 한쌍 구성이고, 주행기체부의 이동성을 담당하기 위한 주행부; 상기 주행기체부의 중앙부에 위치시켜 착탈 가능하게 구비되고, 앞쪽에 주간 제초용 구동형 제초날과 뒤쪽에 조간 제 (뒷면에 계속)"}
{"patent_id": "10-2023-0186513", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 작물인식에 기반한 제초 로봇에 관한 것으로 보다 구체적으로는 ROI(region of interest)를 제한하고 제한된 ROI에서 작물을 판단하고 작물을 회피하여 제초작업을 수행할 수 있는 작물인식에 기반한 제초 로봇에 관한 것이다."}
{"patent_id": "10-2023-0186513", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "제초 작업은 6-8월의 한여름에 집중적으로 진행이 되고, 1회 제초 작업 시 보통 2-3일의 시일이 소요되므로 작 물를 재배하는 농부의 육체적 피로도는 매우 큰 편이다. 특히, 최근의 고령화 추세를 감안하면 농부의 육체적 피로도는 더욱 클 것으로 예상된다. 또한, 제초 작업 시 나뭇가지에 눈을 찔리거나 미숙한 제초기 사용으로 인 한 사고의 위험이 있어 인명피해를 없애기 위한 노력이 별도로 요구되고 있는 실정이다. 또한, 제초 작업은 매우 단순한 작업의 반복일 뿐 만 아니라 평균적인 과수 농가의 면적이 수천평에 이르는 점 을 감안할 때 전형적인 3D 작업(Dirty, Dull, Dangerous)의 유형이라고 볼 수 있다. 최근 들어, 제초 작업에 따른 이러한 어려움을 해소하기 위해 제초 기계(제초기)들이 과수 현장에 속속 도입되 고 있는데, 이러한 제초 기계로서는, 예컨대 예초기, 보행형, 승용형 등이 있으며, 승용형(사용자 탑승형)의 경 우가 가장 최신형이면서 상대적으로 가격이 비싸지만 이 역시 사용자가 직접 제초기를 운행해야 하는 단점이 있 다. 이러한 작업을 자동화하기 위한 노력으로 제초 로봇에 대한 연구가 최근 주요 기업을 중심으로 진행되고 있다. 특히, John Deere, Friendly robotics, I-guide robotics, husqvarna 등의 기업에서 제초용 로봇을 출시한 바 있으나, 이들 업체에서 출시한 제품(제초 로봇)은 대부분 개인정원 제초용 로봇으로 주로 잔디 관리를 목적으로 개발이 되었기 때문에 과수밭과 같이 불규칙한 노면과 경사지에서 동작이 가능하고 특히, 수간 잡초까지 제거하 는 경우에는 적용이 실질적으로 어렵다는 문제가 있다. 또한 현재 자동화를 위한 제초 로봇의 경우 콩과 같은 작물과 잡초를 인식하는 인식율이 낮기 때문에 제초 작업 시 콩작물을 잡초와 함께 제거하는 문제점도 발생되고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 등록특허공보 제10-1156477호 (특허문헌 0002) 2. 등록특허공보 제10-1573027호"}
{"patent_id": "10-2023-0186513", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제점에 기반하여 안출된 발명으로 제초로봇이 제초작업중 작물을 자동으로 인식하고 작물이 인식된 경우 작물을 회피한 후 제초동작을 재수행할 수 있는 제초 로봇을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2023-0186513", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 과제를 해결하기 위해 본 발명의 일양태에 따르면 중앙에 위치하는 주행기체부; 상기 주행기체부의 좌우 양측부에 배치되는 한쌍 구성이고, 주행기체부의 이동성을 담당하기 위한 주행부; 상기 주행기체부의 중앙부에 위치시켜 착탈 가능하게 구비되고, 앞쪽에 주간 제초용 구동형 제초날과 뒤쪽에 조간 제초용 쟁기형 제초날을 구비하여 작업지의 주간과 조간 측 제초작업을 동시에 수행하기 위한 주간조간제초유닛부;를 포함하되, 상기 주 간조간제초유닛부는, 주행기체부 상에 장착되고, 작물 인식을 통해 작물 사이의 잡초 제거에 사용하기 위한 영 상정보를 제공하는 작물인식카메라; 및 상기 작물인식카메라로부터 입력되는 영상의 ROI(region of interest) 영역에서 작물영역을 판단하는 인공신경망 기반의 작물인식모델; 상기 작물인식모델로부터 판단된 작물인식결 과에 대응하여 주간 및 조간 제초작업을 제어하기 위한 제초컨트롤러부;를 포함하고, 상기 제초컨트롤러부는 작 물인식결과 작물영역이 인식되면 상기 구동형 제초날을 회피위치로 전환시키도록 구동된다. 전술한 양태에서, ROI 영역은 작물인식카메라로부터 입력되는 영상중 구동형 제초날이 위치된 좌측 및 우측 하 단 영역으로 제한된다. 또한 전술한 어느 하나의 양태에서, 구동형 제초날은 제초 위치에서 회피 위치로 전환될 때 90도 회전하도록 동 작한다. 또한 전술한 어느 하나의 양태에서, 작물인식모델은 ANN(Artificial Neural Networks), CNN(convolution neural network)으로 인공신경망 모델로 이루어진다."}
{"patent_id": "10-2023-0186513", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 제초로봇이 제초작업중 작물을 자동으로 인식하고 작물이 인식된 경우 작물을 회피한 후 제초 동작을 수행할 수 있는 제초 로봇을 제공할 수 있다."}
{"patent_id": "10-2023-0186513", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되는 실시예를 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예에 한정되는 것이 아니라 서로 다른 다 양한 형태로 구현될 것이다. 본 명세서에서 본 실시예는 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 그리고 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 따라서, 몇몇 실시예들에서, 잘 알려진 구성 요소, 잘 알려진 동작 및 잘 알려진 기술들은 본 발명이 모호하게 해석되는 것을 피하기 위하여 구체적으로 설명되지 않는다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 그리고, 본 명세서에서 사용된(언급된) 용어 들은 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구 에서 특별히 언급하지 않는 한 복수형도 포함한다. 또한, '포함(또는, 구비)한다'로 언급된 구성 요소 및 동작 은 하나 이상의 다른 구성요소 및 동작의 존재 또는 추가를 배제하지 않는다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 정의되어 있지 않은 한 이상적으로 또는 과도하게 해석되지 않는다. 이하, 첨부된 도면들을 참조하여 본 발명의 기술적 특징을 구체적으로 설명하기로 한다. 첨부도면의 도 1 내지 도 18은 본 발명에 따른 무한궤도형 주행부를 포함하는 제초 로봇, 제초 로봇의 자율 주행, 및 제초 동작을 설 명하기 위해 나타낸 도면들이다. 본 발명의 실시예에 따른 주간조간제초유닛부를 포함하는 제초 로봇은 주행기체부와 주행부, 주행 제어유닛부 및 주간조간 제초유닛부를 포함하는 구성으로 이루어진다. 상기 주행기체부는 제초 로봇의 구성요소 중 중앙에 위치하는 베이스 구성으로서, 주행부 및 제어 유닛부와의 유용한 결합구조를 위해 다수의 프레임을 연결시킨 프레임구조체로 구비된다. 상기 주행기체부는 주행부와의 지지 결합을 통해 지상고를 높인 형태로 구비함이 바람직하며, 이를 통해 작업지에서 재배되는 작물의 훼손을 막고 두둑을 갖는 작업지에서의 용이한 이동성을 구현할 수 있는 장점 을 제공할 수 있다.상기 주행부는 주행기체부의 좌우 양측부에 배치되는 한쌍 구성으로서, 동력 전달에 의한 회전을 통 해 주행기체부의 이동성을 담당하기 위한 구성이며, 브래킷 등을 사용하는 연결을 통해 주행기체부의 하단부에 지지 결합함으로써 주행기체부에 대해 지상고를 높여주는 역할을 담당하도록 구비된다. 이를 위 해, 상기 주행부는 주행프레임, 하부주행바퀴, 지지브래킷, 상부주행보조바퀴, 동력 부, 제1보조브래킷 및 제2보조브래킷을 포함할 수 있다. 상기 주행프레임은 주행기체부의 하단부 외측에 위치하여 지면과 접촉되게 구비된 채로 회전 가능하 게 배치되며, 무한궤도형 벨트타입으로 구비된다. 상기 하부주행바퀴는 무한궤도형 벨트타입으로 구비되는 주행프레임의 내측 하부에 걸림 배치된 채로 지지 결합되고, 다수 개가 배열되는 구성으로서, 동력부로부터 회전동력을 전달받아 회전함으로써 무한궤 도형 벨트타입의 주행프레임 측 회전을 돕는 기능을 하도록 구비된다. 상기 지지브래킷은 다수 개가 배열된 하부주행바퀴들의 상부를 커버하도록 지지 결합되는 구조체이면 서 이와 더불어 주행기체부에 체결되어 고정 결합되는 구성요소로서, 주행기체부와 주행부를 연 결하는 연결매개체가 되는 구성이다. 상기 상부주행보조바퀴는 지지브래킷 상에 고정 결합되는 제1보조브래킷에 지지 결합되어 회전 가능하게 구비되고, 무한궤도형 벨트타입인 주행프레임의 내측 상부 일측단에 배치되어 주행프레임을 지지 및 회전을 돕는 기능을 하도록 구비된다. 상기 동력부는 지지브래킷 상에 고정 결합되는 제2보조브래킷에 고정 결합되어 하부주행바퀴 의 상측에 위치되는 것으로서, 회전동력을 하부주행바퀴 측으로 전달하여 주행프레임을 정역회 전시킴으로써 이동성을 갖게 하며, 무한궤도형 벨트타입인 주행프레임의 궤도폭을 벗어나지 않게 비돌출형 태로 설치된다. 상기 동력부는 모터 및 감속기가 사용된다. 상기 동력부는 스프로킷 및 체인 등을 비롯한 부가적 구 성을 통해 모터 측 회전력에 대해 방향을 전환시켜 하부주행바퀴에 전달하도록 구성할 수 있으며, 기타 다 양한 방식으로 변형 또는 수정할 수 있다 할것이다. 상기 주행제어유닛부는 주행부를 제어하여 주행을 가능하게 하되, 각종 센서의 입력정보에 따라 주행 기체부의 주행을 자동 제어 및 작업지의 경로 추종을 통한 자율 주행을 가능하게 하는 구성요소이다. 이를 위해, 상기 주행제어유닛부는 배터리박스, 배터리, 전원분배장치, 구동드라이버 , 원격조정기, 카메라센서, GPS센서, 셀프구동용 라이다센서, 작업경로추종용 라이다 센서, 주행컨트롤러부를 포함할 수 있다. 상기 배터리박스는 프레임구조체로 구성되는 주행기체부의 좌우 양측부에 위치되어 고정 결합되는 한 쌍 구성으로서, 주행기체부의 상부에 고정 결합된다. 이때, 상기 배터리박스는 개폐 가능하도록 덮개 를 구비하되, 잠금부를 장착하는 구성이 바람직하다. 상기 배터리는 배터리박스 내에 배치되고, 동력 부 및 센서 등 전원에 의해 동작되는 필요 구성요소에 전원을 공급하여주기 위한 구성이다.기 전원분배장치는 배터리박스 내에 배치되고, 동력부 및 센서 등 전원에 의해 동작되는 필요 구성요 소에 안정된 전원을 공급하기 위해 전원을 분배하여 공급하는 구성이다. 상기 구동드라이버는 배터리박스 내에 배치되고, 동력부 측 모터의 구동을 제어하기 위한 구성 이다. 상기 전원분배장치 및 구동드라이버는 배터리박스 내에 배치하지 않고, 주행기체부의 프레 임구조체 상에 고정 배치하는 구성일 수도 있다. 상기 원격조정기는 제초 로봇의 동작을 원격 조정하기 위한 구성으로서, 비사용시 배터리박스 내 에 보관할 수 있다. 상기 카메라센서는 프레임구조체인 주행기체부 상에 장착되어 전방 또는 전후방의 영상정보를 제공하 기 위한 구성이다. 카메라센서는 콩 밭 제초 작업 시 작물 영역 인식을 위한 실시간 영상(RGB)을 수집하도 록 구성된다. 영상수집을 위한 카메라 센서의 FOV (field of view) 및 조간 길이를 고려하여 카메라센서는 제초 로봇의 전면부 중심의 높이는 1m 위치에 설치되었으며, 2조의 동시 촬영이 가능하도록 구성된다. 상기 GPS센서는 프레임구조체인 주행기체부 상에 장착되고, 작업지의 작업공간 내에 진입하기 전 주 행기체부의 위치로부터 작업시작점까지 유도를 위한 GPS 좌표정보를 제공함과 더불어 작업경로 추종시 주 행기체부 측 위치정보 판단에 의한 경로이탈여부를 확인하기 위한 구성이다. 상기 셀프구동용 라이다센서는 프레임구조체인 주행기체부 상에 장착되는 것으로서, 실시간으로 제초 로봇, 즉 주행기체부의 주변환경을 매핑(Mapping)하고 주행기체부의 주행 환경정보를 획득하며 작 업공간의 진입을 유도하는데 사용하기 위한 구성이다. 상기 작업경로추종용 라이다센서는 프레임구조체인 주행기체부 상에 장착되는 것으로서, 작업지역 내 작업경로를 추종하고 경로이탈여부를 확인 및 주행제어용 신호정보를 수집하기 위한 구성이다. 상기 주간조간제초유닛부는 프레임구조체인 주행기체부의 중앙부에 위치시켜 착탈 가능하게 착탈식으 로 구비되는 구성으로서, 앞쪽에 주간 제초용 구동형 제초날과 뒤쪽에 조간 제초용 쟁기형 제초날을 각각 구비 하여 작업지의 주간과 조간 측 제초작업을 동시에 수행하기 위한 구성요소이다. 이때, 상기 주간조간제초유닛부는 착탈 가능한 착탈식 구성으로서, 이를 주행기체부로부터 분리해낸 후 새로운 제품으로 교체하여 사용할 수 있으며, 때로는 제초제를 분사하여 잡초를 제거하는 방식의 방제유닛부 나 중경로터리 등 다른 작업기로 교체하여 사용할 수 있는 장점을 제공할 수 있다. 여기에서, 조간은 두둑(이랑)의 길이방향으로 심어진 작물의 열을 의미하고, 주간은 두둑(이랑)의 폭 방향으로 심어진 작물의 간 격을 의미한다. 상세하게, 상기 주간조간제초유닛부는 승하강 구동체, 주간제초부, 조간제초부, 경심유지 부를 포함할 수 있다. 상기 승하강 구동체는 주행기체부 상에 착탈 가능하게 체결 조립되는 프레임구조체로서, 접철 가능한 링크부를 갖되 전동실린더의 결합을 통해 승하강 구동이 가능하도록 구비된다. 상기 주간제초부는 승하강 구동체의 하단 앞쪽에 고정 결합되어 주행기체부의 전면부 중앙 하단 에 위치되는 것으로서, 1조 이상의 회전운동 또는 왕복회동운동이 가능한 구동형 제초날이 구비된다. 상기 구동형 제초날은 좌우 양측에 2조를 배치할 수 있는데, 각각은 승하강 구동체에 구동모터 가 고정 결합되고 상기 구동모터의 회전축에 구동형 제초날이 회전 가능하게 수평 배치되는 구성일수 있다. 상기 구동형 제초날은 길이나 폭의 변형을 통해 제초작업에 변화를 줄 수 있다. 구동형 제초날은 제초로봇에서 실시간 촬영되는 영상을 입력 받아 콩이 자라고 있는 영역(무게중심)을 인 식하고 2차원 좌표를 이동속도를 평가하여 제초부에 접근 시 제초날을 회피, 그 외 조간에서는 제초날 투입하도 록 동작된다. 도 10a은 구동형 제초날의 일례를 나타내는 도면이다. 도 10에 도시된 바와 같이 구동형 제초날 은 제초날을 유지하는 지지홀더의 가이드를 통해 슬라이딩 이동가능하게 유지된다. 구동형 제초 날의 가이드를 따라 상측 또는 하측으로 슬라이딩 이동하면서 구동형 제초날의 블레이드 각도가 변경된다. 작업위치에서 구동형 제초날은 주간에서 제초 진행방향과 수직이며 날은 안쪽 방향으로 향하고 있어 두둑 지면 아래 토양을 가로지르면서 경운작업을 통해 잡초를 제거할 수 있지만, 콩 영역이 인식되면 제초 날이 회피위치로 이동되고 제초날은 도시된 바와 같이 진행 반대방향(제초날을 기준으로 반시계 방향)으로 90° 회전하여 콩이 생육하고 있는 영역을 회피하게 된다. 도 10b는 전술한 구동형 제초날의 위치제어를 위한 모터 시스템을 나타내는 도면이다. 위치제어가 가능한 모터는 2개가 이용되여 좌, 우 제초날을 제어한다. 카메라가 지면을 바라보고 영상의 상단이 진행방향일 때, 좌 측 모터는 시계방향으로, 우측 모터는 반시계방향으로 회전하게 된다. 작물인식모델에서 작물 검출 시 위치제어 모터는 제초날을 90도씩 위치 이동시킨다. 제초날의 위치 제어는 위해 5상 기어드(브레이크 일체형) 스테핑 모터(A200K-M599-GB10, Autonics, Korea)를 이용하였으며, 모터 제어를 위한 모터 드라이브(MD5-HD14, Autonics, Korea), 상위 제어기, 컨버터 등으로 구성 된다. 모터는 기어박스와 브레이크가 포함되어 있으며, 최대허용토크는 200kgfcm, 정격전류 1.4 A/Phase, 감속비 1:10, 허용속도범위 0-180 rpm의 주요 사양을 가지고 있으며, 특히, 브레이크가 포함되어 있어 제초 시 부하로 인해 위치가 변경되는 것을 방지 할 수 있다. 모터 드라이브는 바이폴라 정전류 펜타곤 드라이브(pentagon drive) 방식으로 20-35 VDC의 전원전압을 가지며 최대구동전류는 1.4A/Phase, 최대소비전류는 3A 등으로 사용된 모터 제어를 위한 전용 사양으로 구성된다. 상위 제어기는 마이크로 컨트롤러(STM32-Nucleo, STMicroelectronics, Switzerland)를 이용하여 개발하였으며, 작물인식 정보 수집 및 모터 상태 정보 회신을 위한 NVIDIA Jetson board와의 통신은 UART로 설계되었다. 전력 공급은 본체의 배터리로부터 나오는 48V를 DC-DC 컨버터를 이용하여 각각의 요소 구동에 필요한 전압 레벨 로 변환하여 사용하였으며, 이때, 모터와 드라이버는 24V, 제어기와 브레이크 릴레이는 5V이다. 제초날의 안정적인 토양 진입 및 고정을 위해 모터 내 브레이크를 제어하였으며, 모터의 위치 제어 후 릴레이를 통해 자동으로 동작되도록 알고리즘을 구성하였다. 상기 조간제초부는 승하강 구동체의 하단 뒤쪽에 고정 결합되어 주행기체부의 후면부 중앙 하단 에 위치되는 것으로서, 두둑의 토양을 솎아주면서 잡초를 제거하도록 하기 위해 하나 이상의 쟁기형 제초날 로 구비될 수도 있다. 쟁기형 제초날은 다수를 간격 배치하되 역브이(∧)자형 배열, 즉 갈매기 구조형 배열을 갖도록 구성함이 바람직하다. 이러한 구조 배열을 통해서는 작물 뽑힘을 방지 및 작물을 보호할 수 있고 두둑 측 토양 파손을 방 지할 수 있는 장점을 제공할 수 있다. 부연하여, 두둑 내 토양의 형태가 깨지는 것을 방지하면서 토양을 좌우로 배출해줌으로써 제초작업의 원활함을 더해줄 수 있다. 이때, 상기 쟁기형 제초날은 자체적으로 높낮이 조 절하여 사용 가능하도록 구비함으로써 두둑 내 형성된 토양 조건에 따라 높낮이를 변형하여 사용하도록 구성할 수 있다. 상기 경심유지부는 승하강 구동체의 하단 앞쪽과 뒤쪽에 각각 위치하여 고정 결합되는 체결브래킷 과, 상기 체결브래킷 각각의 좌우 외측면에 체결되고 탄성장력을 제공하는 가스스프링 구조를 갖는 가스쇼버와, 상기 체결브래킷 각각에 연결 고정 및 회전 가능하게 지지 결합되는 경심유지롤러 를 포함한다. 상기 경심유지부는 승하강 구동체와 주간제초부의 사이에 개재되고, 승하강 구동체와 조간 제초부의 사이에 개재되는 구성일 수 있는데, 체결브래킷 각각에 주간제초부와 조간제초부(43 0)를 체결하여 장착할 수 있다. 상기 경심유지롤러는 승하강 구동체와 주간제초부의 사이에 개재시, 구동형 제초날의 측부 에 위치 및 서로 간섭되지 않게 배치된다. 상기 경심유지롤러는 승하강 구동체와 조간제초부의 사이에 개재시, 쟁기형 제초날의 앞쪽에 위치 및 서로 간섭되지 않게 배치된다. 이와 같은 구성을 갖는 상기 주간조간제초유닛부는 주행기체부 또는 승하강 구동체 상에 장착하 는 작물인식카메라에서의 영상정보를 활용함으로써 제초작업을 수행할 수 있으며, 작업지의 주간 및 조간 제초작업을 제어하기 위한 제초컨트롤러부를 포함한다. 이때, 상기 제초컨트롤러부는 주행기체부 상에 장착될 수 있다. 상세하게, 상기 제초컨트롤러부에서는 하기의 순서를 갖는 알고리즘을 통해 주간 및 조간의 제조작업을 자 동 제어할 수 있으며, 도 9를 참조하여 설명한다. 상기 제초컨트롤러부는 시작제어모드와 종료제어모드로 구분할 수 있다. 먼저, 상기 시작제어모드는 하기와 같은 순서로 제어할 수 있다. 주행기체부에 대해 작업지의 고랑 진입신호를 체크한다. 이때, 제초컨트롤러부에서는 주행제어유닛부 측 주행컨트롤러부로부터 주행제어신호를 입력받아 고랑 진입여부를 체크한다. 주행기체부의 고랑 진입신호가 입력되면, 전동실린더를 통해 승하강 구동체를 하강시킨다. 경심유지롤러의 두둑 측 지면 접촉여부를 체크한다. 경심유지롤러의 두둑 측 지면 접촉이 입력되면, 전동실린더의 작동을 정지시킨다. 제초작업을 시작하되, 작물인식카메라에서의 영상정보를 이용하여 작물 인식을 체크한다. 작물이 인식되면 작물을 회피하여 구동형 제초날로 주간 제초함과 동시에 쟁기형 제초날로 조간 제초를 동시 수행하고, 작물이 인식되지 않으면 구동형 제초날로 주간 제초함과 동시에 쟁기형 제초날 로 조간 제초를 동시 수행하도록 제어한다.이때, 작물이 인식되면 작물과 작물 사이의 공간에 위치한 잡초를 구동형 제초날로 절단하여 제거하고, 그 렇지 않으면 작물을 회피할 필요없이 구동형 제초날로 잡초를 절단하여 제거한다. 그리고, 상기 종료제어모드는 하기와 같이 제어할 수 있다. 주행기체부에 대해 작업지의 고랑 진입신호를 체크한다. 고랑 이탈신호가 입력되면 전동실린더를 통해 승하강 구동체를 상승시킨다. 이때, 필요에 따라 제초 로봇 측 주행을 정지시킬 수 있다. 이에 따라, 상술한 구성으로 이루어지는 본 발명에 따른 주간조간제초유닛부를 포함하는 제초 로봇을 통해서 는 기계장치를 이용하여 주간 제초작업은 물론 조간 제초작업까지 동시에 수행할 수 있고 사용 용이성 및 편의 성을 구현할 수 있는 등 제초작업에 따른 작업효율성을 높일 수 있으며, 주간조간 제초유닛부에 대해 주행 기체부 상에 착탈하여 교체 사용할 수 있으며, 제초작업시 작물 훼손과 두둑의 형태 파손을 방지할 수 있 는 장점을 제공할 수 있다. 이하에는 전술한 설명 중 작물의 인식 동작에 대해 보다 구체적으로 설명하도록 한다. 도 11은 카메라센서로부터의 영상입력에 기반하여 작물인식을 수행하고 작물인식결과에 따라 제초날의 회 피동작 또는 제초동작을 수행하는 과정을 나타낸느 도면이다. 도 11에 도시된 바와 같이 카메라로부터의 입력은 제초유닛부에 입력된다. 제초유닛부에는 인공지능에 기반하여 학습된 작물인식모델이 탑재되어 있다. 작물인식모델은 카메라로부터의 영상을 입력으로 하여 ROI 영역내에 작물의 존재여부를 판단하도록 학습 된 인공지능모델의 일종이다. 본 발명에서는 영상 기반 작물(콩작물) 인식을 위해 인공신경망 모델(Artificial Neural Networks, ANN)을 이용될 수 있으며, ANN은 인간의 뇌 구조를 모방한 구조의 기계학습(machine learning) 방법으로 비선형 문제 해결에 효과적인 인공신경망 모델로 알려져 있다. 또한 본 발명에서 작물인식모델은 전술한 바와 같은 ROI 내에서 작물의 존재여부를 판단하기 위해 영상을 입력으로 하는 인공신경망 예를 들면 컨볼루션 신경망(CNN: Convolutional Neural Network)을 이용할 수도 있다. 기존 영상 학습은 pixel 단위의 특징 이용하였지만 CNN 구조는 영상의 공간적(spatial) 특징을 이용하여 특징추출(feature extraction)에 효과적이며 학습을 통한 특징추출이 가능하다. 인공신경망은 생물학적 뉴런의 동작원리와 뉴런간의 연결 관계를 모델링한 것으로 노드(node) 또는 처리 요소 (processing element)라고 하는 다수의 뉴런들이 레이어(layer) 구조의 형태로 연결된 정보처리 시스템이다. 인 공신경망은 시냅스(synapse)의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시냅스의 결합 세기 를 변화시켜, 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 용어 인공신경망은 용어 뉴럴 네트워크(Neural Network)와 혼용되어 사용될 수 있으며, 인공신경망은 복수의 레 이어(layer)를 포함할 수 있고, 레이어들 각각은 복수의 뉴런(neuron)을 포함할 수 있다. 또한 인공신경망은 뉴 런과 뉴런을 연결하는 시냅스를 포함할 수 있다. 인공 신경망은 일반적으로 다음의 세가지 인자, 즉 다른 레이어의 뉴런들 사이의 연결 패턴 연결의 가 중치를 갱신하는 학습 과정 이전 레이어로부터 수신되는 입력에 대한 가중 합으로부터 출력값을 생성하는 활성화 함수에 의해 정의될 수 있다.전술한 바와 같이 본 발명에서 작물인식모델은 인공 신경망을 이용하여 구성될수 있으며, 예를 들면 CNN(Convolutional Neural Network), DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network), MLP(Multilayer Perceptron), ANN 와 같은 방식의 네 트워크 모델들을 포함할 수 있으나, 본 발명이 이에 한정되는 것은 아니다. 본 명세서에서 용어 '레이어'는 용어 '계층'과 혼용되어 사용될 수 있다. 인공신경망은 계층 수에 따라 단층 신경망(Single-Layer Neural Networks)과 다층 신경망(Multi-Layer NeuralNetworks)으로 구분된다. 일반적인 단층 신경망은, 입력층과 출력층으로 구성된다. 또한 일반적인 다층 신경망은 입력층(Input Layer)과 하나 이상의 은닉층(Hidden Layer), 출력층(Output Layer)으로 구성된다. 입력층은 외부의 자료들을 받아들이는 층으로서, 입력층의 뉴런 수는 입력되는 변수의 수와 동일하며, 은닉층은 입력층과 출력층 사이에 위치하며 입력층으로부터 신호를 받아 특성을 추출하여 출력층으로 전달한다. 출력층은 은닉층으로부터 신호를 받고, 수신한 신호에 기반한 출력 값을 출력한다. 뉴런간의 입력신호는 각각의 연결강도 (가중치)와 곱해진 후 합산되며 이 합이 뉴런의 임계치보다 크면 뉴런이 활성화되어 활성화 함수를 통하여 획득 한 출력값을 출력한다. 한편 입력층과 출력 층 사이에 복수의 은닉층을 포함하는 심층 신경망은, 기계 학습 기술의 한 종류인 딥 러닝 을 구현하는 대표적인 인공 신경망일 수 있다. 한편 용어 '딥 러닝'은 용어 '심층 학습'과 혼용되어 사용될 수 있다. 인공 신경망은 훈련 데이터(training data)를 이용하여 학습(training)될 수 있다. 여기서 학습이란, 입력 데이 터를 분류(classification)하거나 회귀분석(regression)하거나 군집화(clustering)하는 등의 목적을 달성하기 위하여, 학습 데이터를 이용하여 인공 신경망의 파라미터(parameter)를 결정하는 과정을 의미할 수 있다. 인공신경망의 파라미터의 대표적인 예시로써, 시냅스에 부여되는 가중치(weight)나 뉴런에 적용되는 편향(bia s)을 들 수 있다. 훈련 데이터에 의하여 학습된 인공 신경망은, 입력 데이터를 입력 데이터가 가지는 패턴에 따 라 분류하거나 군집화 할 수 있다. 한편 훈련 데이터를 이용하여 학습된 인공 신경망을, 본 명세서에서는 학습 모델(a trained model)이라 명칭 할 수 있으며, 학습된 인공 신경망은 작물인식모델로 명칭될 수 있다. 인공 신경망의 학습 방식은 크게, 지도 학습, 비 지도 학습, 준 지도 학습(Semi-Supervised Learning), 강화 학 습(Reinforcement Learning)으로 분류될 수 있으며, 본 발명의 실시예에서는 바람직하게 입력 데이터 중 일부분 에 대해 지도 학습을 통해 학습 모델을 훈련하여 예측 모델을 훈련하였지만 본 발명이 이에 한정되는 것은 아니 다. 지도 학습은 훈련 데이터로부터 하나의 함수를 유추해내기 위한 기계 학습의 한 방법이다. 그리고 이렇게 유추 되는 함수 중, 연속적인 값을 출력하는 것을 회귀분석(Regression)이라 하고, 입력 벡터의 클래스(class)를 예 측하여 출력하는 것을 분류(Classification)라고 할 수 있다. 지도 학습에서는, 훈련 데이터에 대한 레이블(label)이 주어진 상태에서 인공 신경망을 학습시킨다. 여기서 레 이블이란, 훈련 데이터가 인공 신경망에 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과 값)을 의미할 수 있다. 본 명세서에서는 훈련 데이터가 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과값)을 레이블 또 는 레이블링 데이터(labeling data)이라 명칭 할 수도 있다. 또한 본 명세서에서는, 인공 신경망의 학습을 위하 여 훈련 데이터에 레이블을 설정하는 것을, 훈련 데이터에 레이블링 데이터를 레이블링(labeling) 한다고 명칭 한다. 이 경우 훈련 데이터와 훈련 데이터에 대응하는 레이블은 하나의 트레이닝 셋(training set)을 구성하고, 인공 신경망에는 트레이닝 셋의 형태로 입력될 수 있다. 한편 훈련 데이터는 복수의 특징(feature)을 나타내고, 훈련 데이터에 레이블이 레이블링 된다는 것은 훈련 데이터가 나타내는 특징에 레이블이 달린다는 것을 의미할 수 있 다. 이 경우 훈련 데이터는 입력 객체의 특징을 벡터 형태로 나타낼 수 있다. 인공 신경망은 훈련 데이터와 레이블링 데이터를 이용하여, 훈련 데이터와 레이블링 데이터의 연관 관계에 대 한 함수를 유추할 수 있다. 그리고, 인공 신경망에서 유추된 함수에 대한 평가를 통해 인공 신경망의 파라미터 가 결정(최적화)될 수 있다. 객체 검출(object detection) 기술은 대상체의 클래스 분류 및 위치정보까지 검출해야하므로 학습을 위해서는 모든 영상을 대상으로 포함된 객체의 클래스와 위치정보를 별도로 작성해야 한다. 주석(annotation) 작업의 경 우 데이터량이 방대한 경우 노동력 및 비용투입이 매우 크게되며, 본 발명의 콩 영역은 화질에 따라 차이가 있 지만 복잡한 형상 혹은 주변과의 모호한 경계로 정확한 판단이 어려움이 있다. 따라서 본 발명에서는 영상 내에 객체의 존재 유무만의 정보로만 객체 검출이 가능한 약지도 학습(weakly supervised learning) 방법을 이용하였 다. 약지도 학습은 합성곱 층(convolution layer)을 거쳐 나온 최종 특징맵(feature maps)의 정보에 아래의 식과 같 은 GAP(global average pooling)을 연결하여 특징맵 각각의 중요도를 학습하는 방법이다."}
{"patent_id": "10-2023-0186513", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "where, Gk is global average pooling of the kth feature map fk(x,y) is pixel value at xth row-yth column in kth feature map N is total number of pixels in the feature map 또한 해당 영상의 각각의 클래스에 대한 점수는 아래와 같이 중요도 가중치와 GAP 값을 이용하였다."}
{"patent_id": "10-2023-0186513", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "where, Sc is the score of the cth class, ωkc is importance parameter of kth feature map for cth class 또한 본 발명에서 분류는 클래스 점수와 아래의 식의 softmax 분류기를 이용하였다."}
{"patent_id": "10-2023-0186513", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "Where, Pc is the probability of the cth class 영상 검출은 아래의 식과 같이 각각의 특징맵별 가중치와 곱한 뒤 전체를 합한 값을 이용하였으며, 각각의 픽셀 의 활성도에 따라 검출 위치 및 범위를 결정하였다(class activation map (CAM))."}
{"patent_id": "10-2023-0186513", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "Where, Mc(x,y) is activation value at (x, y) pixel for cth class 도 12는 약지도 학습의 모델 구조를 예시적으로 나타내는 도면으로, vgg기반의 deep neural network arichitecture로 특징추출(feature extraction)을 위한 컨벌루젼 레이어(Convolutional layers)와 이미지-레벨 로컬리제이션(image-level localization)을 위한 GAP (global average pooling) 및 뷴류기(classifier)로 구성 된다. 본 발명에서 작물영역인 콩 영역 인식을 위해 약지도 학습(weakly supervised learning) 기반 딥러닝 모델을 사 용하였으며, 이는 학습데이터 구축이 쉬울 뿐만 아니라 분류 학습과 동시에 내제적인 지역화 정보의 동시 습득 이 가능하다는 장점을 갖는다. 콩 영역 인식 및 분할을 위해서 약지도 학습방법 중 모델의 분류학습 후 최상위 특징맵의 결과의 가중치 된 합 (weighted sum)을 지역화(localization) 정보로 활용하는 방식을 이용하였으며, 분류 활성화 맵(class activation map, CAM)을 통해 시각화하였다. 도 13은 본 발명에서 제안된 작물인식모델 또는 콩 영역 인식 모델 구조를 보여주고 있으며, 전체 구조는 학습 과 추론의 2개 단계로 구분할 수 있다. 학습단계에서는 2개의 부류(콩 영역, 잡초 및 배경)에 대해 분류 학습을 수행하며, 이를 위해 학습데이터 입력 으로 해당되는 영상단위 라벨(image-level label) 정보를 기반으로 모델 가중치를 조정한다. 학습모델은 추론속도 향상을 위해 얕은층(shallow layers)으로 구성되었으며 총 4개의 합성곱신경망층 (convolutional layer)을 이용하여 특징정보를 추출하였으며, 각각의 층에는 비선형 활성화 함수인 rectified linear unit (ReLU)와 max pooling이 추가되었다. 마지막 합성곱신경망의 경우 max pooling 대신 global average pooling (GAP)을 사용하였으며, 이는 추론단계 에서 지역화 정보 추출을 위한 특징맵의 가중치로 활용되었다. 추론단계에서는 학습단계에서 최적화된 분류모델의 내부 결과 중 마지막 층의 특징 맵(feature maps)들을 이용 하여 영역분할 정보를 획득하며, 이는 각각의 특징 맵에 가중치를 할당하여 합한 후 해당 부류의 활성화도를 기 반으로 영역을 추출해내는 과정이다. 추론의 결과는 2개 분류에 대한 CAM 정보로 나타낼 수 있으며, 이를 각각의 정보에 대한 상대점수로 표현하기 위해 비선형 활성화 함수인 softmax를 채널방향으로 수행하였다. 이를 통해 각각의 픽셀에 대한 2개의 CAM 정보 는 확률값으로 변환될 수 있다.학습데이터는 전라북도 김제시 죽산면에서 수집한 실시간 콩 영상 수집 데이터를 전처리하여 사용하였다. 모델 학습을 위해 각각의 영상에서 콩 영역을 라벨링하였으며, 학습 반복마다 160x160 사이즈로 임의 추출하여 배치 데이터를 구성하였고, 이때 콩 영역이 포함되어 있는지 여부를 평가하여 실시간 학습데이터의 라벨을 부여 하였다. 콩 영역의 학습데이터는 매 반복 시 전체 영역에서 임의 샘플되므로 별도로 검증 데이터 세트를 분리하지 않았 으며, 1회 반복 시 학습-검증을 반복하여 검증 손실이 최소가 되는 학습 파라미터를 최종적으로 선정하였다. 학습 파라미터로는 손실함수는 Cross-entropy, 최적화기로는 Adam optimizer을 사용하였으며, 0.001의 학습율로 500회 학습을 진행하면서 과적합(overfitting) 방지를 위해 L2 정규화(regularization)을 사용하였다. 작물인식모델 학습 결과 도 14는 반복학습에 따른 작물인식학습 모델의 손실 및 정확도(좌측)와 재현율(우측)을 나타내는 도면이다. 콩 영역 인식 모델의 학습은 반복에 따라 손실은 점차 감소 및 수렴되었으며, 이를 통해 콩과 주변 영역과의 분류 가 가능하다. 분류 오류의 위험(risk)는 배경→콩 보다 콩→배경이 더 크므로 영상 내 모든 콩이 검출되는 것이 중요하다. 따라서, 정밀도(recall)을 통해 반복 시 콩 영역 검출을 평가하였으며, 그 결과 최종적으로 0.85 수 준을 나타내었다. 연속 영상샘플을 이용한 콩 영역 검출 결과 도 15는 연속 영상 입력의 콩 영역 인식 결과를 시각화한 도면이다. 도시된 바와 같이, 실시간 수집된 영상을 시간순으로 연속적으로 입력하였으며, 이에 따른 검출 성능을 평가 및 시각화 한 결과는 도 15와 같다. 평가에 사용된 영상은 수집된 전체 영상으로 총 6000장이며, 학습 시 사용된 영상은 전체 수집된 영상의 1/10인 600장이다. 입력된 영상은 오른쪽에만 콩이 파종되어 있는 상태로 콩 영역의 검출이 원활하게 가능한 것으로 관찰되나 일부 의 경우 콩 주간이 일반적이지 않은 경우도 있어 데이터 라벨의 신뢰성 확보 또는 알고리즘의 개선이 필요하다. 한편 도 15에서는 카메라로부터 입력되는 영상 전체를 ROI로 하여 콩 영역을 인식하였다. 이는 약지도 학습을 이용하여 전체 영상에서 콩 영역 인식 속도를 향상시켰지만 임베디드 시스템에 탑재 및 실시간 활용을 위해서는 추가적인 속도 향상이 필요하다. 즉 인식외 영상처리, 제어를 위한 연산 등에 필요한 자원도 고려되어야 하므로, 인식 과정에 필요한 연산량을 최소화할 필요성이 있다. 일반적으로 딥러닝 모델의 연산량을 줄이기 위해서는 입력의 크기를 감소하거나 내부 특징맵의 개수를 줄이는 방법 등이 대표적이며, 본 발명은 이미 얕은층의 모델 구조를 가지고 있어 입력 크기를 감소하는 방향으로 경량 화를 수행하였다. 도 16은 전술한 바와 같이 딥러닝 모델의 연산량을 줄이기 위한 하나의 방법을 예시하는 도면이다. 도 16에 도 시된 바와 같이 제초 로봇이 주행하는 고랑의 안쪽으로 콩이 파종되어 있으며, 본 발명에서는 학습모델의 연산 량을 줄이기 위해 전체 영역을 ROI로 설정하지 않고 제초날이 위치하는 하단의 좌우에 ROI를 설정하였다. 따라 서 제초날이 위치되는 영역을 중심으로 ROI를 제한함으로써 불필요한 영상 입력을 줄일 수 있으며, 이 때 검출 되는 콩의 누적 확률 분포를 계산하면서 해당 영역에 대한 신뢰성을 검증한다.따라서, 예측된 RoI 영역 내에서 콩을 검출 및 위치별 제어를 수행하며, 콩이 나올 확률이 높을 수평 좌표를 중 심으로 RoI를 형성함으로써 수용영역을 최소화하는 것이 가능하다. 본 발명에서 사용되는 Jetson board의 제조사인 NVIDIA에서는 딥러닝 추론 최적화 라이브러리인 TensorRT를 제 공하며, 기존 모델을 구조적으로 개선하여 현재의 성능을 향상시킬 수 있다. 낮은 정밀도의 모델일수록 데이터 의 크기 및 가중치들의 비트수가 작기 때문에 더 빠르고 효율적인 연산이 가능하며, TensorRT에서는 Symmetric Linear Quantization 기법을 이용하여 데이터의 정밀도를 낮출 수 있다. 또한 Layer fusion을 통해 모델의 구조 를 단순화 시켜주고 이를 통하여 전체 네트워크 층의 갯수가 크게 감소될 수 있다. 도 17은 본 발명에 따른 최적화된 작물인식모델의 처리속도를 나타낸 그래프이다. 작물인식모델의 처리 속도 평 가를 위해 수집된 실시간 영상을 순차적, 연속적으로 입력하여 콩 영역 인식을 수행하였으며, 이때의 추론 속도 를 소프트웨어 타이머를 이용하여 계산하였다(영상 간 샘플링 간격은 10ms임). 측정 기준은 영상 입력으로부터 콩 영역 검출 완료까지이며 1초 동안 처리된 영상 프레임 수(frame per second, fps)를 계수하여 측정하였다. 소프트웨어 타이머를 이용하여 추론 시간을 평가한 결과, 1장의 영상을 처리하는 데 걸린 시간은 평균 0.05초이 고 따라서, 20 fps의 속도로 실시간 콩 영역 인식이 가능하므로 가변 제초 인식에 활용 가능하다. [표 1] 작물인식모델의 추론속도 측정 결과"}
{"patent_id": "10-2023-0186513", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 6, "content": "도 18은 작물인식모델에서의 작물 인식 과정을 나타내는 도면이다. 도 18의 (a) 내지 (d)에 순차적으로 도시된 바와 같이, 제초로봇이 작업경로를 따라 이동함에 따라 제초날이 작업할 제한된 ROI 영역(좌측 및 우측) 내에 작물이 차례대로 검출된다. 작물인식모델은 검출된 작물영역에서의 중심점(x,y) 좌표를 예측하게 된다. 제초로 봇의 제초유닛부는 작물영역의 중심점의 Y축 좌표를 기준으로 회피 타이밍을 결정하고, X축 좌료를 기준으로 작 물의 중심영역을 일치시킬 수 있다. 전술한 설명에서 제초로봇을 한정하여 설명하고 있지만 본 발명은 이에 한정되는 것은 아니고 대상의 인식기술 을 활용하여 장애물의 인지 및 회피 동작 또는 선택적 작업이 가능하며, 이를 활용하는 축산작업기 및 유사한 형태의 농작업기에도 이용가능하다는 것은 자명하다. 이상에서 설명한 실시예는 본 발명의 바람직한 실시예를 설명한 것에 불과하고 이러한 실시예에 극히 한정되는"}
{"patent_id": "10-2023-0186513", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "것은 아니며, 본 발명의 기술적 사상과 청구범위 내에서 이 기술분야의 당해업자에 의하여 다양한 수정과 변형 등이 이루어질 수 있다 할 것이며, 이는 본 발명의 기술적 권리범위 내에 속한다 할 것이다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는이상에서 설명된 장치는 하드웨어 구 성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(Arithmetic Logic Unit), 디지털 신호 프로세서(Digital Signal Processor), 마이크로컴퓨터, FPGA(Field Programmable Gate Array), PLU(Programmable Logic Unit), 마이크로프로세서, 또는 명령(Command)을 실행하고 응답할 수 있는 다 른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있 다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다."}
{"patent_id": "10-2023-0186513", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리요소(Processing Element) 및/또는 복수 유형의 처리 요소를 포 함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트 롤러를 포함할 수 있다. 또한, 병렬 프로세서(Parallel Processor)와 같은, 다른 처리 구성(Processing Configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(Computer Program), 코드(Code), 명령(Command), 또는 이들 중 하나 이상의 조 합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (Collectively)처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(Component), 물리적 장치, 가상 장치(Virtual Equipment), 컴퓨터 저장매체 또는 장치에 구체화(Embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(Magnetic Media), CD- ROM, DVD와 같은 광기록 매체(Optical Media), 플롭티컬 디스크(Floptical Disk)와 같은 자기-광 매체 (Magneto-Optical Media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2023-0186513", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속하 는 것으로 해석되어야만 한다."}
{"patent_id": "10-2023-0186513", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 주간조간제초유닛부를 포함하는 제초 로봇을 나타낸 사시도이다. 도 2는 본 발명에 있어 배터리박스를 제거한 상태의 제초 로봇을 나타낸 사시도이다. 도 3은 본 발명에 있어 주간조간제초유닛부를 설명하기 위해 나타낸 제초 로봇의 저면 사시도이다. 도 4는 본 발명에 있어 주간조간제초유닛부를 설명하기 위해 나타낸 요부 측면도이다. 도 5는 본 발명에 있어 주행부를 설명하기 위해 나타낸 도면이다. 도 6은 본 발명에 있어 제초유닛부 측 승하강 구동상태를 나타낸 도면이다. 도 7은 본 발명에 있어 주간제초작업 상태와 조간제초작업 상태를 나타낸 도면이다. 도 8은 본 발명의 실시예에 따른 주간조간제초유닛부를 포함하는 제초 로봇을 나타낸 개략적 블록구성도이다. 도 9는 본 발명에 따른 주간조간제초유닛부 측 동작을 설명하기 위해 나타낸 순서도이다. 도 10a은 제초날의 작업위치 및 회피위치를 설명하기 위한 설명도이다. 도 10b는 제초날의 위치제어를 위한 모터 제어 시스템의 구성을 나타내는 도면이다. 도 11은 카메라의 입력에 기반하여 작물을 인식하고 인식 결과에 따라 회피 및 제초 동작을 수행하는 작업 흐름 을 나타낸 도면이다.도 12는 약지도 학습 모델의 구조를 예시적으로 도시한 도면이다. 도 13은 약지도 학습을 이용한 콩작물 영역 인식 모델의 구조를 나타내는 도면이다. 도 14는 반복학습에 따른 손실 및 정확도와 재현율을 나타내는 그래프이다. 도 15는 연속 영상 입력의 콩 영역 인식 결과를 시각화하여 나타낸 도면이다. 도 16은 검출대상 최소화 및 콩영역 검출 누적 확율 분포를 이용한 ROI 예측을 나타내는 도면이다. 도 17은 경량화 및 최적화된 모델의 성능을 나타내는 그래프이다. 도 18은 ROI 영역에서 작물의 영역 검출 및 중심점 좌표 생성 과정을 나타낸 도면이다."}
