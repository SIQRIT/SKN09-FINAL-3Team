{"patent_id": "10-2023-0012106", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0119732", "출원번호": "10-2023-0012106", "발명의 명칭": "연합 학습 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "윤종훈"}}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 클라이언트들의 가중치들을 수신하는 단계;디퀀타이저를 이용하여, 상기 가중치들 각각에 대응하는 고유 정밀도(precision)를 기준 정밀도로 변경하는 단계;상기 고유 정밀도에 기초하여, 상기 가중치들 각각에 대응하는 마스크들을 결정하는 단계;상기 마스크들에 기초하여, 상기 기준 정밀도로 변경된 가중치들을 병합하여 통합 가중치를 결정하는 단계; 및상기 통합 가중치를 상기 가중치들 각각에 대응하는 고유 정밀도로 양자화하여, 상기 복수의 클라이언트들에게전송하는 단계;를 포함하는 연합 학습 방법."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 디퀀타이저는복수의 블록들을 포함하고,상기 복수의 블록들 각각은 고유의 입력 정밀도와 출력 정밀도를 갖는, 연합 학습 방법."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 변경하는 단계는상기 고유 정밀도를 상기 입력 정밀도로 갖는 블록에 상기 가중치들 각각을 입력하는 단계; 및상기 기준 정밀도를 상기 출력 정밀도로 갖는 블록의 출력을 획득하는 단계를 포함하는, 연합 학습 방법."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 마스크들을 결정하는 단계는상기 가중치들 중 상기 고유 정밀도가 미리 정해진 임계 정밀도 이상인 제1 가중치들의 통계값을 획득하는단계; 및상기 통계값에 기초하여, 상기 마스크들을 결정하는 단계를 포함하는, 연합 학습 방법."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2024-0119732-3-제4항에 있어서,상기 통계값에 기초하여, 상기 마스크들을 결정하는 단계는상기 가중치들 중 상기 고유 정밀도가 상기 통계값 미만인 제2 가중치 각각에 대하여, 상기 통계값과의 유사도를 획득하는 단계; 및상기 유사도에 기초하여, 상기 제2 가중치 각각에 대응하는 마스크를 결정하는 단계를 포함하는, 연합 학습 방법."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 제2 가중치 각각에 대응하는 마스크를 결정하는 단계는상기 제2 가중치 각각의 상기 유사도를 최대화하는 이진 마스크를 결정하는 단계를 포함하는, 연합 학습 방법."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,미리 정해진 주기로 상기 디퀀타이저를 학습하는 단계를 더 포함하는, 연합 학습 방법."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 디퀀타이저는복수의 블록들을 포함하고,상기 디퀀타이저를 학습하는 단계는학습 가중치 데이터를 수신하는 단계;상기 학습 가중치 데이터를 양자화하여 복수의 양자화된 가중치 데이터를 생성하는 단계;상기 복수의 블록들 별로, 해당 블록에서 예측한 중간 출력 가중치 데이터와 상기 해당 블록에 대응하는 양자화된 가중치 데이터 사이의 차이에 기초하여 결정되는 제1 손실을 획득하는 단계;상기 학습 가중치 데이터를 수신한 상기 디퀀타이저가 출력한 최종 출력 가중치 데이터와 상기 학습 가중치 데이터에 대응하는 정답 가중치 데이터 사이의 차이에 기초하여 결정되는 제2 손실을 획득하는 단계; 및상기 제1 손실과 상기 제2 손실에 기초하여 상기 디퀀타이저를 학습하는 단계를 포함하는, 연합 학습 방법."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 가중치들을 수신하는 단계는상기 복수의 클라이어트들로부터, 개별적으로 학습된 인공 신경망 모델의 상기 가중치들을 수신하는 단계공개특허 10-2024-0119732-4-를 포함하는, 연합 학습 방법."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "하드웨어와 결합되어 제1항 내지 제9항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "적어도 하나의 명령어를 저장하는 메모리; 및상기 메모리에 저장된 명령어를 실행함으로써,복수의 클라이언트들의 가중치들을 수신하고,디퀀타이저를 이용하여, 상기 가중치들 각각에 대응하는 고유 정밀도(precision)를 기준 정밀도로 변경하고,상기 고유 정밀도에 기초하여, 상기 가중치들 각각에 대응하는 마스크들을 결정하고,상기 마스크들에 기초하여, 상기 기준 정밀도로 변경된 가중치들을 병합하여 통합 가중치를 결정하고,상기 통합 가중치를 상기 가중치들 각각에 대응하는 고유 정밀도로 양자화하여, 상기 복수의 클라이언트들에게전송하는 적어도 하나의 프로세서를 포함하는, 전자 장치."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 디퀀타이저는복수의 블록들을 포함하고,상기 복수의 블록들 각각은 고유의 입력 정밀도와 출력 정밀도를 갖는, 전자 장치."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 프로세서는상기 고유 정밀도를 상기 입력 정밀도로 갖는 블록에 상기 가중치들 각각을 입력하고,상기 기준 정밀도를 상기 출력 정밀도로 갖는 블록의 출력을 획득하는, 전자 장치."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 프로세서는상기 가중치들 중 상기 고유 정밀도가 미리 정해진 임계 정밀도 이상인 제1 가중치들의 통계값을 획득하고,상기 통계값에 기초하여, 상기 마스크들을 결정하는, 전자 장치.공개특허 10-2024-0119732-5-청구항 15 제14항에 있어서,상기 프로세서는상기 가중치들 중 상기 고유 정밀도가 미리 정해진 임계 정밀도 미만인 제2 가중치 각각에 대하여, 상기 통계값과의 유사도를 획득하고,상기 유사도에 기초하여, 상기 제2 가중치 각각에 대응하는 마스크를 결정하는, 전자 장치."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 프로세서는상기 제2 가중치 각각의 상기 유사도를 최대화하는 이진 마스크를 결정하는, 전자 장치."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,상기 프로세서는미리 정해진 주기로 상기 디퀀타이저를 학습하는, 전자 장치."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 디퀀타이저는복수의 블록들을 포함하고,상기 프로세서는학습 가중치 데이터를 수신하고,상기 학습 가중치 데이터를 양자화하여 복수의 양자화된 가중치 데이터를 생성하고,상기 복수의 블록들 별로, 해당 블록에서 예측한 중간 출력 가중치 데이터와 상기 해당 블록에 대응하는 양자화된 가중치 데이터 사이의 차이에 기초하여 결정되는 제1 손실을 획득하고,상기 학습 가중치 데이터를 수신한 상기 디퀀타이저가 출력한 최종 출력 가중치 데이터와 상기 학습 가중치 데이터에 대응하는 정답 가중치 데이터 사이의 차이에 기초하여 결정되는 제2 손실을 획득하고,상기 제1 손실과 상기 제2 손실에 기초하여 상기 디퀀타이저를 학습하는, 전자 장치."}
{"patent_id": "10-2023-0012106", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 프로세서는상기 복수의 클라이어트들로부터, 개별적으로 학습된 인공 신경망 모델의 상기 가중치들을 수신하는, 전자장치."}
{"patent_id": "10-2023-0012106", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "연합 학습 방법 및 장치가 개시된다. 일 실시예에 따른 연합 학습 방법은 복수의 클라이언트들의 가중치들을 수 신하는 단계, 디퀀타이저를 이용하여, 가중치들 각각에 대응하는 고유 정밀도(precision)를 기준 정밀도로 변경 하는 단계, 고유 정밀도에 기초하여, 가중치들 각각에 대응하는 마스크들을 결정하는 단계, 마스크들에 기초하여, 기준 정밀도로 변경된 가중치들을 병합하여 통합 가중치를 결정하는 단계 및 통합 가중치를 가중치들 각각에 대응하는 고유 정밀도로 양자화하여, 복수의 클라이언트들에게 전송하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0012106", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 개시는 연합 학습 방법 및 장치에 관한 것으로, 보다 구체적으로 연산 정밀도(precision)가 서로 다른 임베디드 디바이스들 간에 연합 학습을 수행하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-0012106", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "온 디바이스(On-device) 환경이나 포터블 임베디드(portable embedded) 장비 간의 연합 학습을 수행할 때 하드 웨어적으로 서로 다른 정밀도의 오퍼레이션(operation) 혹은 메모리(memory)를 갖는 디바이스 간에도 연합 학습 이 필요할 수 있다. 하지만 서로 다른 정밀도 기반 디바이스의 연합 학습은 모델 가중치의 분포 붕괴 (degenerate distribution)를 발생시키며 성능을 떨어트리는 문제를 유발할 수 있다."}
{"patent_id": "10-2023-0012106", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 연합 학습 방법은 복수의 클라이언트들의 가중치들을 수신하는 단계; 디퀀타이저를 이용하여, 상기 가중치들 각각에 대응하는 고유 정밀도(precision)를 기준 정밀도로 변경하는 단계; 상기 고유 정밀도에 기초하여, 상기 가중치들 각각에 대응하는 마스크들을 결정하는 단계; 상기 마스크들에 기초하여, 상기 기준 정 밀도로 변경된 가중치들을 병합하여 통합 가중치를 결정하는 단계; 및 상기 통합 가중치를 상기 가중치들 각각 에 대응하는 고유 정밀도로 양자화하여, 상기 복수의 클라이언트들에게 전송하는 단계를 포함할 수 있다. 상기 디퀀타이저는 복수의 블록들을 포함하고, 상기 복수의 블록들 각각은 고유의 입력 정밀도와 출력 정밀도를 가질 수 있다. 상기 변경하는 단계는 상기 고유 정밀도를 상기 입력 정밀도로 갖는 블록에 상기 가중치들 각각을 입력하는 단 계; 및 상기 기준 정밀도를 상기 출력 정밀도로 갖는 블록의 출력을 획득하는 단계를 포함할 수 있다. 상기 마스크들을 결정하는 단계는 상기 가중치들 중 상기 고유 정밀도가 미리 정해진 임계 정밀도 이상인 제1 가중치들의 통계값을 획득하는 단계; 및 상기 통계값에 기초하여, 상기 마스크들을 결정하는 단계를 포함할 수 있다. 상기 통계값에 기초하여, 상기 마스크들을 결정하는 단계는 상기 가중치들 중 상기 고유 정밀도가 상기 통계값 미만인 제2 가중치 각각에 대하여, 상기 통계값과의 유사도를 획득하는 단계; 및 상기 유사도에 기초하여, 상기 제2 가중치 각각에 대응하는 마스크를 결정하는 단계를 포함할 수 있다. 상기 제2 가중치 각각에 대응하는 마스크를 결정하는 단계는 상기 제2 가중치 각각의 상기 유사도를 최대화하는 이진 마스크를 결정하는 단계를 포함할 수 있다. 일 실시예에 따른 연합 학습 방법은 미리 정해진 주기로 상기 디퀀타이저를 학습하는 단계를 더 포함할 수 있다. 상기 디퀀타이저는 복수의 블록들을 포함하고, 상기 디퀀타이저를 학습하는 단계는 학습 가중치 데이터를 수신 하는 단계; 상기 학습 가중치 데이터를 양자화하여 복수의 양자화된 가중치 데이터를 생성하는 단계; 상기 복수 의 블록들 별로, 해당 블록에서 예측한 중간 출력 가중치 데이터와 상기 해당 블록에 대응하는 양자화된 가중치 데이터 사이의 차이에 기초하여 결정되는 제1 손실을 획득하는 단계; 상기 학습 가중치 데이터를 수신한 상기 디퀀타이저가 출력한 최종 출력 가중치 데이터와 상기 학습 가중치 데이터에 대응하는 정답 가중치 데이터 사이 의 차이에 기초하여 결정되는 제2 손실을 획득하는 단계; 및 상기 제1 손실과 상기 제2 손실에 기초하여 상기 디퀀타이저를 학습하는 단계를 포함할 수 있다. 상기 가중치들을 수신하는 단계는 상기 복수의 클라이어트들로부터, 개별적으로 학습된 인공 신경망 모델의 상 기 가중치들을 수신하는 단계를 포함할 수 있다. 일 실시예에 따른 전자 장치는 적어도 하나의 명령어를 저장하는 메모리; 및 상기 메모리에 저장된 명령어를 실 행함으로써, 복수의 클라이언트들의 가중치들을 수신하고, 디퀀타이저를 이용하여, 상기 가중치들 각각에 대응 하는 고유 정밀도(precision)를 기준 정밀도로 변경하고, 상기 고유 정밀도에 기초하여, 상기 가중치들 각각에 대응하는 마스크들을 결정하고, 상기 마스크들에 기초하여, 상기 기준 정밀도로 변경된 가중치들을 병합하여 통 합 가중치를 결정하고, 상기 통합 가중치를 상기 가중치들 각각에 대응하는 고유 정밀도로 양자화하여, 상기 복수의 클라이언트들에게 전송하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 디퀀타이저는 복수의 블록들을 포함하고, 상기 복수의 블록들 각각은 고유의 입력 정밀도와 출력 정밀도를 가질 수 있다. 상기 프로세서는 상기 고유 정밀도를 상기 입력 정밀도로 갖는 블록에 상기 가중치들 각각을 입력하고, 상기 기 준 정밀도를 상기 출력 정밀도로 갖는 블록의 출력을 획득할 수 있다. 상기 프로세서는 상기 가중치들 중 상기 고유 정밀도가 미리 정해진 임계 정밀도 이상인 제1 가중치들의 통계값 을 획득하고, 상기 통계값에 기초하여, 상기 마스크들을 결정할 수 있다. 상기 프로세서는 상기 가중치들 중 상기 고유 정밀도가 미리 정해진 임계 정밀도 미만인 제2 가중치 각각에 대 하여, 상기 통계값과의 유사도를 획득하고, 상기 유사도에 기초하여, 상기 제2 가중치 각각에 대응하는 마스크 를 결정할 수 있다. 상기 프로세서는 상기 제2 가중치 각각의 상기 유사도를 최대화하는 이진 마스크를 결정할 수 있다. 상기 프로세서는 미리 정해진 주기로 상기 디퀀타이저를 학습할 수 있다. 상기 디퀀타이저는 복수의 블록들을 포함하고, 상기 프로세서는 학습 가중치 데이터를 수신하고, 상기 학습 가 중치 데이터를 양자화하여 복수의 양자화된 가중치 데이터를 생성하고, 상기 복수의 블록들 별로, 해당 블록에 서 예측한 중간 출력 가중치 데이터와 상기 해당 블록에 대응하는 양자화된 가중치 데이터 사이의 차이에 기초 하여 결정되는 제1 손실을 획득하고, 상기 학습 가중치 데이터를 수신한 상기 디퀀타이저가 출력한 최종 출력 가중치 데이터와 상기 학습 가중치 데이터에 대응하는 정답 가중치 데이터 사이의 차이에 기초하여 결정되는 제 2 손실을 획득하고, 상기 제1 손실과 상기 제2 손실에 기초하여 상기 디퀀타이저를 학습할 수 있다. 상기 프로세서는 상기 복수의 클라이어트들로부터, 개별적으로 학습된 인공 신경망 모델의 상기 가중치들을 수 신할 수 있다."}
{"patent_id": "10-2023-0012106", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 개시되어 있는 특정한 구조적 또는 기능적 설명들은 단지 기술적 개념에 따른 실시예들을 설명하 기 위한 목적으로 예시된 것으로서, 실제로 구현된 형태는 다양한 다른 모습을 가질 수 있으며 본 명세서에 설 명된 실시예로만 한정되지 않는다. 제1 또는 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 이런 용어들은 하나의 구성요소 를 다른 구성요소로부터 구별하는 목적으로만 이해되어야 한다. 예를 들어 제1 구성요소는 제2 구성요소로 명명 될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관계를 설명하는 표현들, 예를 들어 \"~간의\"와 \"바로~간의\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 해당 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되 는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 실시예들은 퍼스널 컴퓨터, 랩톱 컴퓨터, 태블릿 컴퓨터, 스마트 폰, 텔레비전, 스마트 가전 기기, 지능형 자동 차, 키오스크, 웨어러블 장치 등 다양한 형태의 제품으로 구현될 수 있다. 이하, 실시예들을 첨부된 도면을 참 조하여 상세하게 설명한다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다. 도 1은 일 실시예에 따른 연합 학습 시스템을 도시한 도면이다. 도 1을 참조하면, 일 실시예에 따른 연합 학습 시스템은 서버와 복수의 클라이언트들(예를 들어, 제1 클라 이언트(120-1) 내지 제4 클라이언트(120-4))를 주체로 포함할 수 있고, 복수의 클라이언트들은 도면에 도시된 제1 클라이언트(120-1) 내지 제4 클라이언트(120-4)로 한정되지 않고, 다양하게 채택될 수 있다. 일 실시예에 따른 서버는 복수의 클라이언트들을과 네트워크(미도시)를 통해 각각 연결될 수 있다. 여기 서, 네트워크는 인터넷, 하나 이상의 로컬 영역 네트워크(local area networks), 광역 네트워크(wire area networks), 셀룰러 네트워크, 모바일 네트워크, 그 밖에 다른 종류의 네트워크들, 또는 이러한 네트워크들의 조 합을 포함할 수 있다. 일 실시예에 따른 복수의 클라이언트들은 인공 신경망 모델에 기반하여 사용자에게 서비스를 제공할 수 있다. 이하, 복수의 클라이언트들에서 인공 신경망 모델에 기반하여 제공하는 서비스를 인공 지능 서비스로 지칭한다. 예를 들어, 클라이언트는 인공 지능에 기반한 얼굴 인식 서비스를 제공하는 단말일 수 있고, 로컬 디바이스, 사 용자 단말 등으로 지칭될 수 있다. 단말은 웨어러블 디바이스, 태블릿 PC, 스마트폰, 개인용 컴퓨터(예를 들어, 노트북 컴퓨터 등), 스마트 TV, 이동 전화기, 내비게이션, 웹 패드, PDA, 워크스테이션 등과 같이 메모리 수단을 구비하고 마이크로 프로세서를 탑재하여 연산 능력을 갖춘 디지털 기기를 모두 포함하는 개념일 수 있다. 다만, 클라이언트의 종류를 전술한 바로 한정하는 것은 아니고, 클라이언트는 인공 지능 서비스를 제공 할 수 있는 다양한 전자 장치(예: 사물 인터넷(IoT) 장치, 의료 기기, 자율 주행 장치)를 포함할 수 있다. 복수의 클라이언트들 각각은 서로 다른 데이터에 기반하여 서로 다른 인공 신경망 모델을 구축하여 인공 지능 서비스를 제공할 수 있다. 복수의 클라이언트들은 서로 다른 인공 지능 서비스를 제공할 수 있다. 예를 들어, 제1 클라이언트(120-1)는 얼굴 인식 서비스를 제공할 수 있고, 제2 클라이언트(120-2)는 지문 인식 서비 스를 제공할 수 있다. 또는, 복수의 클라이언트들은 동일한 인공 지능 서비스(예: 얼굴 인식 서비스)를 제공하 더라도 서로 다른 데이터에 기반하여 각각의 인공 신경망 모델을 구축할 수 있다. 특히, 복수의 클라이언트들은 서로 다른 하드웨어 스펙을 가질 수 있고, 이를 고려하여 서로 다른 정밀도로 세 팅될 수 있다. 다시 말해, 복수의 클라이언트들은 하드웨어적으로 서로 다른 정밀도의 오퍼레이션 또는 메모리 를 가질 수 있다. 서로 다른 정밀도를 갖는다는 것은 서로 다른 비트폭(bitwidth)을 갖는 것을 의미할 수 있다. 예를 들어, 제1 클라이언트(120-1)는 int4의 정밀도의 디바이스 규격을 가질 수 있고, 제2 클라이언트(120-2)는 int8의 정밀도의 디바이스 규격을 가질 수 있고, 제3 클라이언트(120-3)는 int16의 정밀도의 디바이스 규격을 가질 수 있고, 제4 클라이언트(120-4)는 Float32 정밀도의 디바이스 규격을 가질 수 있다. int n의 정밀도는 2n개의 정수를 표현하는 정밀도를 의미하고, flaot 16은 1비트는 부호에, 5비트는 정수부분을 나타내는데, 10비 트는 소수부분을 나타내는데 사용되는 정밀도를 의미하고, float 32는 1비트는 부호에, 8비트는 정수부분을 나 타내는데, 23비트는 소수부분을 나타내는데 사용되는 정밀도를 의미할 수 있다.서버는 서로 다른 정밀도를 갖는 복수의 클라이언트들로부터 각각 학습 완료된 인공 신경망 모델의 가중치 를 수신하여, 통합 가중치를 생성하고, 생성된 통합 가중치를 다시 복수의 클라이언트들로 전송할 수 있다. 이 때, 낮은 정밀도의 모델 가중치와 높은 정밀도의 가중치를 단순히 병합할 경우, 가중치 값 분포의 차이 때문에 높은 정밀도의 모델 성능을 유지할 수 없다. 아래에서 상세히 설명하겠지만, 서버는 서로 다른 정밀도를 갖는 가중치들을 수신할 수 있고, 디퀀타이저 를 이용하여 해당 가중치를 특정 정밀도를 갖는 가중치로 변환할 수 있다. 아래에서, 복수의 클라이언트들 각 각이 인공 신경망 모델을 학습하고 추론할 때 사용되는 정밀도를 고유 정밀도라 지칭하고, 서버에서 변환 한 가중치의 정밀도를 기준 정밀도라 지칭할 수 있다. 서버는 양자화를 통해 수십 배 낮은 대역폭으로도 서버와 통신하여 연합 학습을 수행할 수 있고, 데이터를 전송하지 않고 학습된 모델 가중치만을 전송해 프라이 버시 이슈를 피할 수 있다. 얼굴 인식은 많은 학습 데이터가 요구되는 인공지능 적용 기술인데, 얼굴 데이터는 개인의 사생활과 밀접하게 연관되어 있기 때문에 기존에는 스마트 워치와 스마트폰부터 노트북까지 얼굴 인식 기술이 필요한 다양한 디바 이스들에 많은 얼굴 데이터가 산재되어 있더라도 그 데이터를 모아 얼굴인식 모델을 향상시키는 것이 불가능했 다. 그러나 일 실시예에 따른 연합 학습 시스템에 따르면, 복수의 클라이언트들(예를 들어, 제1 클라이언트(120-1) 내지 제4 클라이언트(120-4)) 사양에 맞는 정밀도로 로컬 얼굴 인식 모델을 학습한 후, 그 모델의 가중치만을 주고 받을 수 있다. 따라서, 일 실시예에 따른 연합 학습 시스템에 따르면, 사생활 침해의 우려가 적고, 또 각 디바이스의 하드웨어 사양에 맞는 양자화된 모델을 얻을 수 있다. 도 2 내지 도 3은 일 실시예에 따른 연합 학습 방법을 설명하기 위한 도면이다. 도 1을 참조하여 설명한 내용은 도 2 내지 도 3에도 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있다. 설명의 편의를 위해, 단계들(210 내지 250)은 도 1에 도시된 서버를 사용하여 수행되는 것으로 기술된다. 그러나 이 단계들(210 내지 250)은 어떤 다른 적절한 전자 기기를 통해, 그리고 어떤 적절한 시스템 내에서도 사용될 수 있을 것이다. 나아가, 도 2의 동작은 도시된 순서 및 방식으로 수행될 수 있지만, 도시된 실시예의 사상 및 범위를 벗어나지 않으면서 일부 동작의 순서가 변경되거나 일부 동작이 생략될 수 있다. 도 2에 도시된 다수의 동작은 병렬로 또는 동시에 수행될 수 있다. 단계에서, 일 실시예에 따른 서버는 복수의 클라이언트들의 가중치들을 수신할 수 있다. 각 클라이 언트는 서버로 고유 정밀도를 갖는 가중치를 전송할 수 있다. 도 3을 참조하면, 제1 클라이언트(320-1)는 int6 정밀도의 가중치를, 제2 클라이언트(320-2)는 int8 정밀도의 가중치를, 제3 클라이언트(320-3)는 int16 정밀도의 가중치를, 제n 클라이언트(320-n)는 Float32 정밀도의 가중 치를 서버로 전송할 수 있다. 단계에서, 일 실시예에 따른 서버는 디퀀타이저를 이용하여, 가중치들 각각에 대응하는 고유 정밀도 를 기준 정밀도로 변경할 수 있다. 일 실시예에 따른 디퀀타이저는 점진적 가중치 디퀀타이저로 지칭될 수 있 다. 디퀀타이저는 서버에 존재하며, 낮은 비트 가중치를 점진적으로 높은 비트 가중치 값으로 예측하는 인공 신경망 모델일 수 있다. 낮은 비트 가중치는 정밀도 가 상대적으로 낮은 가중치를 의미하고, 높은 비트 가중치는 정밀도가 상대적으로 높은 가중치를 의미할 수 있다. 서버는 일정 주기마다 받은 고정밀도 가중 치 값을 사용하여 디퀀타이저를 학습할 수 있다. 디퀀타이저를 이용하여 정밀도를 변경하는 방법 및 디퀀타이 저를 학습하는 방법은 아래에서 도 4를 참조하여 상세히 설명된다. 단계에서, 일 실시예에 따른 서버는 고유 정밀도에 기초하여, 가중치들 각각에 대응하는 마스크들을 결정할 수 있고, 단계에서, 일 실시예에 따른 서버는 마스크들에 기초하여, 기준 정밀도로 변경된 가 중치들을 병합하여 통합 가중치를 결정할 수 있다. 도 3을 참조하면, 서버는 디퀀타이저를 통해 학습된 가중치들을 선택적으로 병합하여 서로 다른 비트의 가 중치 간 부정적인 간섭을 최소화하여 높은 성능을 이끌어 낼 수 있다. 서버는 복구된 고정밀도 가중치들 에 대하여, 선택적 가중치 병합을 사용하여 하나의 고정밀도 가중치를 생성할 수 있다. 선택적 가중치 병합 방법은 아래에서 도 5를 참조하여 상세히 설명된다. 단계에서, 일 실시예에 따른 서버는 통합 가중치를 가중치들 각각에 대응하는 고유 정밀도로 양자화 하여, 복수의 클라이언트들에게 전송할 수 있다. 도 3을 참조하면, 서버는 병합된 고정밀도 가중치(이하, 통합 가중치)를 각 클라이언트의 하드웨어 정밀도 에 맞게 양자화한 뒤, 브로드캐스팅할 수 있다. 예를 들어, 서버는 통합 가중치를 int6 정밀도로 양자화 하여, 제1 클라이언트(320-1)로 브로드캐스팅할 수 있고, int8 정밀도로 양자화하여, 제2 클라이언트(320-2)로 브로드캐스팅할 수 있고, int16 정밀도로 양자화하여, 제3 클라이언트(320-3)로 브로드캐스팅할 수 있고, float32 정밀도로 양자화하여, 제n 클라이언트(320-n)로 브로드캐스팅할 수 있다. 각 클라이언트에서는 서버 로부터 받은 가중치 값을 자신의 로컬 모델에 반영할 수 있다. 도 4는 일 실시예에 따른 디퀀타이저를 이용하여 정밀도를 변경하는 방법 및 디퀀타이저를 학습하는 방법을 설 명하기 위한 도면이다. 도 1 내지 도 3를 참조하여 설명한 내용은 도 4에도 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있다. 도 4를 참조하면, 일 실시예에 따른 디퀀타이저는 복수의 블록들(예: 제1 블록 내지 제4 블록)을 포 함할 수 있다. 다만, 도 4에는 디퀀타이저가 4개의 블록들로 구성된 것으로 도시되었으나, 블록들의 수는 이에 한정되지 않고 설계에 따라 블록의 수가 달라질 수 있다. 일 실시예에 따른 복수의 블록들 각각은 고유의 입력 정밀도와 출력 정밀도를 가질 수 있다. 예를 들어, 제1 블록은 int2 정밀도의 가중치를 int4 정밀도의 가중치로 변경하는 블록일 수 있고, 제2 블록은 int4 정밀도의 가중치를 int8 정밀도의 가중치로 변경하는 블록일 수 있고, 제3 블록은 int8 정밀도의 가중치를 int16 정밀도의 가중치로 변경하는 블록일 수 있고, 제4 블록은 int16 정밀도의 가중치를 float32 정밀도 의 가중치로 변경하는 블록일 수 있다. 다만, 블록들 각각의 입력 정밀도와 출력 정밀도는 위 예시에 한정되지 않고, 설계에 따라 다양하게 변경될 수 있다. 연합 학습에 참여하는 k종류의 디바이스의 하드웨어 정밀도들을 포함하는 여러 정밀도들의 집합을 라고 할 수 있다. 여기서 들은 오름차순으로 정렬되어 있을 수 있다. 디퀀타이저 함수는 와 같을 수 있다. 여기서 는 비트의 가중치에서 비트의 가중치로 변환하는 블록을 나타내고, 는 함수의 합성 연산자를 의미할 수 있다. 각 블록은 가중치 텐서의 크기(dimension)를 보존하는 인공 신경망 으로 구현될 수 있다. 여기서 는 인공 신경망의 파라미터일 수 있다. 디퀀타이저는 클라이언트로부터 비트의 가중치 값 를 전달받으면, 이 를 비트부터 비트까지로 양자화하여 j개의 가중치 값들 을 만들 수 있다. 이 값 들로부터 더 높은 정밀도의 가중치 로 변환하는 연산은 아래 수학식 1과 같이 이루어질 수 있다. 수학식 1 수학식 1에서, 는 전달받은 가중치 텐서를 일정한 크기로 쪼개서 사용할 수 있다. 디퀀타이저는 제1 손실 함 수 및 제2 손실 함수에 기초하여 학습될 수 있다. 제1 손실 함수는 재구 손실 함수( : reconstruction loss function)로 지칭될 수 있고, 제2 손실 함수는 대조 손실 함수(distillation loss function)로 지칭될 수 있다. 재구 손실함수는 실제 높은 비트폭의 가중치에 얼마나 근접했는지를 수학식2와 같이 L1 거리를 사용하여 수치화할 수 있다. 수학식 2"}
{"patent_id": "10-2023-0012106", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 2에서, 학습 데이터는 로컬 디바이스로부터 받은 가중치 중 가장 높은 정밀도의 가중치 값들을 사용할 수 있다. 예를 들어, 서버는 학습 데이터로 WFloat32를 수신할 수 있고, WFloat32를 양자화하여 Wint2, Wint4, Wint8, Wint16의 양자화된 가중치 데이터를 생성할 수 있다. 제1 블록은 양자화된 Wint2를 수신하여 int4 정밀도를 갖는 가중치를 출력할 수 있다. 제1 블록이 변환환 int4 정밀도를 갖는 가중치와 Wint4사이의 차이에 기초 하여, 제1 블록에 대응하는 재구 손실이 결정될 수 있다. 제2 블록이 변환환 int8 정밀도를 갖 는 가중치와 Wint8사이의 차이에 기초하여, 제2 블록에 대응하는 재구 손실이 결정될 수 있다. 제3 블록이 변환환 int16 정밀도를 갖는 가중치와 Wint16사이의 차이에 기초하여, 제3 블록에 대응하는 재 구 손실이 결정될 수 있다. 제4 블록이 변환환 float32 정밀도를 갖는 가중치와 Wfloat32사이의 차이에 기초하여, 제4 블록에 대응하는 재구 손실이 결정될 수 있다. 대조 손실함수는 서버에 저장되어 있는 작은 데이터 버퍼 를 사용하여 같은 입력이 제공되었을 때, 재구 된 가중치의 네트워크의 출력이 실제 가중치의 네트워크의 출력과 얼마나 근접했는지를 수학식3과 같이 계산할 수 있다. 수학식 3"}
{"patent_id": "10-2023-0012106", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 3에서, 은 두 값 사이의 코사인 유사도(cosine similarity)를 나타내고, 는 가중치 w를 가지는 네트워크에 입력으로 u를 넣은 출력값을 나타내고, 는 디퀀타이저 각 블록의 파라미터를 모은 집합을 나타낼 수 있다. 예를 들어, 대조 손실은 Wint2를 수신한 디퀀타이저가 출력한 최종 출력 가중치 데 이터와 학습 가중치 데이터에 대응하는 정답 가중치 데이터 사이의 차이에 기초하여 결정될 수 있다. 최종 손실 함수는 이 두 가지 손실 함수를 합친 수학식 4와 같은 함수를 사용한다.수학식 4"}
{"patent_id": "10-2023-0012106", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 4에서, 는 두 손실 함수의 균형을 맞추는 스칼라 값일 수 있다. 디퀀타이저는 연합 학습 과정 중 주기 적으로 새로 받은 가중치를 학습 데이터로 사용하여 업데이트될 수 있다. 서버는 수학식 4에 기초하여 결정된 손실 함수가 최소가 되도록 역전파를 통해 디퀀타이저의 블록들 각각의 파라미터를 조정할 수 있다. 학습이 완료된 디퀀타이저는 저정밀도의 인공신경망 가중치를 고정밀도로 복구할 수 있다. 예를 들어, 클라이 언트로부터 int2 기준 가중치를 수신하고, 기준 정밀도가 float 32일 경우, 디퀀타이저는 해당 가중치를 제1 블 록에 입력하여 제4 블록의 flaot32 정밀도의 출력을 획득할 수 있다. 마찬가지로, 클라이언트로부터 int8 기준 가중치를 수신한 경우, 디퀀타이저는 해당 가중치를 제2 블록에 입력하여 제4 블록의 flaot32 정밀도의 출력을 획득할 수 있다. 디퀀타이저는 저정밀도의 인공신경망 가중치를 고정밀도로 복구하는 기능을 하는 블록 단위로 구성되어 다양한 고유 정밀도들을 기준 정밀도로 변경할 수 있다. 도 5는 일 실시예에 따른 선택적 가중치 병합 방법을 설명하기 위한 도면이다. 도 1 내지 도 4를 참조하여 설명한 내용은 도 5에도 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있다. 도 5를 참조하면, 일 실시예에 따른 서버는 서로 다른 비트 가중치 간 유사도를 측정해 고비트 가중치와 낮은 유사도를 가지는 저비트 가중치 부분을 병합 전에 제거하여 단순 병합 시 발생할 수 있는 부정적 비트 간섭을 방지할 수 있다. 서버는 기준 정밀도로 변경된 가중치들에 마스크를 적용하여 통합 가중치를 결정할 수 있고, 마스크는 고유 정 밀도의 신뢰도에 기초하여 결정될 수 있다. 예를 들어, 높은 정밀도를 갖는 가중치(예: Wfloat32)가 낮은 정밀도 를 갖는 가중치(예:Wint4)보다 더 높은 신뢰도를 갖는 것으로 판단될 수 있다. 따라서, 서버는 통합 가중치를 결 정 시 낮은 정밀도를 갖는 가중치(예:Wint4)보다 높은 정밀도를 갖는 가중치(예: Wfloat32)의 비중을 높일 수 있는 마스크를 결정할 수 있다. 서버는 미리 정해진 기준보다 높은 정밀도를 갖는 가중치를 제1 가중치로, 제1 가중 치의 통계값(예: 평균)보다 낮은 가중치를 갖는 가중치를 제2 가중치로 결정할 수 있다. 보다 구체적으로, 서버는 가중치들 중 고유 정밀도가 미리 정해진 임계 정밀도 이상인 가중치들을 제1 가중치들 로 결정할 수 있고, 제1 가중치들의 통계값을 획득하고, 통계값에 기초하여 마스크들을 결정할 수 있다. 정밀 도의 높고 낮음은 비트폭의 길이에 결정될 수 있다. 예를 들어, Wfloat32는 Wint4 보다 정밀도가 높다고 판단될 수 있다 또는, 서버는 가중치들 중 고유 정밀도가 상위 n번째에 포함되는 가중치들을 제1 가중치로 결정할 수 있고, 제1 가중치들의 통계값을 획득하고, 통계값에 기초하여 마스크들을 결정할 수 있다. 예를 들어, 서버는 고유 정밀 도가 가장 높은 가중치들을 제1 가중치로 결정할 수 있다. 아래에서, 제1 가중치는 고유 정밀도가 가장 높은 가중치들이고, 제2 가중치는 제1 가중치의 통계값(예: 평균) 보다 낮은 가중치들인 것을 가정한다. 다만, 제1 가중치 및 제2 가중치를 결정하는 방법은 위 예시에 한정되는 것은 아니다. 과 를 각각 r라운드에 로컬 디바이스로부터 받은 가장 높은 정밀도를 가진 가중치(제1 가중치)의 평 균치와 그보다 낮은 정밀도를 가진 가중치(제2 가중치)라 하고, 로, 로 정의할 수 있다. 제2 가중치에 대해, 이진 마스크 를 수학식 5와 같이 계산할 수 있다. 수학식 5"}
{"patent_id": "10-2023-0012106", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 5에서, 은 원소끼리의 곱셈 (Hadamard product), 는 가중치 벡터의 총 원소 수, 는 이진 마스크 속의 1의 비율을 의미할 수 있다. 이후, 수학식 6에 따라 가중치 병합을 수행할 수 있다. 수학식 6에 따르면, 일 실시예에 따른 이진 마스크는 제2 가중치 각각의 유사도를 최대화하는 이진 마스크를 의미할 수 있다. 수학식 6"}
{"patent_id": "10-2023-0012106", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 6에서, 은 n번 로컬 디바이스의 이진 마스크, , N은 전체 로컬 디바이스의 개수, 은 n 번 로컬 디바이스에서 받은 가중치를 의미할 수 있다. 도 6은 일 실시예에 따른 서버의 동작을 도시한 순서도이다. 도 1 내지 도 5를 참조하여 설명한 내용은 도 6에도 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있다. 설명의 편의를 위해, 단계들(610 내지 655)은 도 1에 도시된 서버를 사용하여 수행되는 것으로 기술된다. 그러나 이 단계들(610 내지 655)은 어떤 다른 적절한 전자 기기를 통해, 그리고 어떤 적절한 시스템 내에서도 사용될 수 있을 것이다. 나아가, 도 6의 동작은 도시된 순서 및 방식으로 수행될 수 있지만, 도시된 실시예의 사상 및 범위를 벗어나지 않으면서 일부 동작의 순서가 변경되거나 일부 동작이 생략될 수 있다. 도 6에 도시된 다수의 동작은 병렬로 또는 동시에 수행될 수 있다. 단계에서, 일 실시예에 따른 서버는 글로벌 모델의 가중치를 랜덤 값으로 초기화하고, 단계에서, 서버는 초기화된 글로벌 모델 값을 모든 클라이언트에 초기값으로 브로드캐스팅할 수 있고, 단계에서, 서버 는 클라이언트로부터 양자화된 가중치를 수신할 수 있다. 전술한 바와 같이 서버는 미리 정해진 주기로 디퀀타이저를 학습할 수 있다. 단계에서, 서버는 현재 라운드가 디퀀타이저 학습 라운드인지 판단할 수 있다. 단계에서, 현재 라운드가 디퀀타이저 학습 라운드라는 판단에 기초하여, 서버는 디퀀타이저를 학습할 수 있고, 단계에서, 서버는 디퀀타이저를 사용하여 고유 정밀도(예: 저정밀도)의 가중치를 기준 정밀 도(예: 고정밀도)의 가중치로 변환할 수 있다. 현재 라운드가 디퀀타이저 학습 라운드가 아닐 경우에는, 서버 는 단계를 생략할 수 있다. 단계에서, 서버는 각 가중치에 대해 선택적 통합 마스크를 계산할 수 있고, 단계에서, 서버 는 마스크를 이용하여 통합 가중치를 결정할 수 있다. 단계에서, 서버는 각 클라이언트에 맞게 통합된 가중치를 양자화하여, 단계에서 각 클라이언트 에 양자화된 가중치를 브로드캐스팅하고, 현재 라운드를 1 단계 올린 후 단계들(620 내지 655)을 수렴할 때 까 지 반복할 수 있다. 도 7은 일 실시예에 따른 클라이언트의 동작을 도시한 순서도이다. 도 1 내지 도 6을 참조하여 설명한 내용은 도 7에도 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있다. 설명의 편의를 위해, 단계들(710 내지 740)은 도 1에 도시된 클라이언트를 사용하여 수행되는 것으로 기술된다. 그러나 이 단계들(710 내지 740)은 어떤 다른 적절한 전자 기기를 통해, 그리고 어떤 적절한 시스템 내에서도 사용될 수 있을 것이다. 나아가, 도 7의 동작은 도시된 순서 및 방식으로 수행될 수 있지만, 도시된 실시예의 사상 및 범위를 벗어나지 않으면서 일부 동작의 순서가 변경되거나 일부 동작이 생략될 수 있다. 도 7에 도시된 다수의 동작은 병렬로 또는 동시에 수행될 수 있다. 단계에서, 일 실시예에 따른 클라이언트는 서버로부터 초기 가중치를 수신할 수 있다. 단계에서, 초기 가중치를 수신한 클라이언트는 수신된 가중치를 로컬 모델에 반영할 수 있고, 단계에 서, 클라이언트는 로컬 데이터를 활용하여 일정한 스텝 수만큼 확률경사하강법(Stochastic Gradient Descent)등 의 방법을 이용하여 저정밀도로 로컬 모델을 학습할 수 있다. 단계에서, 클라이언트는 서버로 로컬 모델의 양자화된 가중치를 전송 하고, 현재 라운드를 1 단계 올린 후 단계들(720 내지 740)을 수렴할 때 까지 반복할 수 있다. 도 8은 일 실시예에 따른 메타 학습 알고리즘에 점진적 가중치 디퀀타이저를 사용한 연합 학습 방법의 예시를 도시한 도면이다. 도 8을 참조하면, 메타 학습은 여러 태스크에 빠르게 적응하여 일반화(generalization) 성능을 높일 수 있는 메 타 가중치를 찾는 알고리즘으로, 여러 태스크에 대해 동시에 인공 신경망 모델을 학습해야 하기 때문에 학습 시 간이 매우 오래 걸리는 단점이 있다. 따라서 각 태스크의 난도에 맞게 연산 정밀도를 배정하여 양자화 학습을 하면 학습 시간이 훨씬 줄어들 수 있다. 나아가, 서로 다른 정밀도의 가중치 그래디언트를 병합하기 위해 일 실시예에 따른 점진적 가중치 디퀀 타이저와 선택적 가중치 통합 기술을 적용할 수 있다. 도 9은 일 실시예에 따른 전자 장치의 구성의 예시도이다. 도 9을 참조하면, 전자 장치는 프로세서, 메모리 및 통신 모듈을 포함할 수 있다. 일 실 시예에 따른 전자 장치는 도 1 내지 도 7을 통하여 전술한 서버에 포함될 수 있다. 일 실시예에 따른 프로세서는 도 1 내지 도 7을 통하여 전술한 적어도 하나의 동작을 수행할 수 있다. 예 를 들어, 프로세서는 복수의 클라이언트들의 가중치들을 수신하고, 디퀀타이저를 이용하여, 상기 가중치들 각각에 대응하는 고유 정밀도(precision)를 기준 정밀도로 변경하고, 상기 고유 정밀도에 기초하여, 상기 가중 치들 각각에 대응하는 마스크들을 결정하고, 상기 마스크들에 기초하여, 상기 기준 정밀도로 변경된 가중치들을 병합하여 통합 가중치를 결정하고, 상기 통합 가중치를 상기 가중치들 각각에 대응하는 고유 정밀도로 양자화하 여, 상기 복수의 클라이언트들에게 전송할 수 있다. 일 실시예에 따른 메모리는 휘발성 메모리 또는 비휘발성 메모리일 수 있으며, 도 1 내지 도 7을 통하여 전술한 연합 학습 방법에 관한 데이터를 저장할 수 있다. 일 예로, 메모리는 복수의 클라이언트들로부터 수신한 가중치 혹은 연합 학습을 수행하기 위하여 필요한 데이터를 저장할 수 있다. 일 실시예에 따른 통신 모듈은 네트워크를 통해 전자 장치가 다른 전자 기기 또는 다른 서버와 통신 하기 위한 기능을 제공할 수 있다. 다시 말해, 장치는 통신 모듈을 통하여 외부 장치(예를 들어, 클 라이언트 또는 네트워크)에 연결되고, 데이터를 교환할 수 있다. 예를 들어, 전자 장치는 통신 모듈 을 통해 연합 학습을 위한 학습 데이터 셋을 저장한 데이터베이스와 데이터를 송수신할 수 있다. 일 실시예에 따르면, 메모리는 도 1 내지 도 7을 통하여 전술한 연합 학습 방법이 구현된 프로그램을 저장 할 수 있다. 프로세서는 메모리에 저장된 프로그램을 실행하고, 장치를 제어할 수 있다. 프로 세서에 의하여 실행되는 프로그램의 코드는 메모리에 저장될 수 있다.일 실시예에 따른 장치는 도시되지 않은 다른 구성 요소들을 더 포함할 수 있다. 예를 들어, 장치는 통신 모듈과의 인터페이스를 위한 수단으로 입력 장치 및 출력 장치를 포함하는 입출력 인터페이스를 더 포함할 수 있다. 또 예를 들어, 장치는 트랜시버(transceiver), 각종 센서, 데이터베이스 등과 같은 다른 구성 요소들을 더 포함할 수도 있다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리 케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처 리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2023-0012106", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하 나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들의 조합을 포함 할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로(collectively) 처 리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2023-0012106", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2023-0012106", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 연합 학습 시스템을 도시한 도면이다. 도 2 내지 도 3은 일 실시예에 따른 연합 학습 방법을 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 디퀀타이저를 이용하여 정밀도를 변경하는 방법 및 디퀀타이저를 학습하는 방법을 설 명하기 위한 도면이다. 도 5는 일 실시예에 따른 선택적 가중치 병합 방법을 설명하기 위한 도면이다. 도 6은 일 실시예에 따른 서버의 동작을 도시한 순서도이다. 도 7은 일 실시예에 따른 클라이언트의 동작을 도시한 순서도이다. 도 8은 일 실시예에 따른 메타 학습 알고리즘에 점진적 가중치 디퀀타이저를 사용한 연합 학습 방법의 예시를 도시한 도면이다. 도 9은 일 실시예에 따른 전자 장치의 구성의 예시도이다."}
