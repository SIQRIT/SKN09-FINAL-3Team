{"patent_id": "10-2023-0054348", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0157472", "출원번호": "10-2023-0054348", "발명의 명칭": "인공지능을 이용한 음성 향상을 위한 방법 및 그 장치", "출원인": "한양대학교 산학협력단", "발명자": "장준혁"}}
{"patent_id": "10-2023-0054348", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능을 이용하여 전자 장치에 의해 수행되는 음성 향상 방법에 있어서,제1 신경망에서, 입력된 음성 신호의 시퀀스에 대한 잠재 표현(hidden representation)을 결정하는 단계;상기 잠재 표현을 기반으로 음성 인식 정보를 결정하는 단계;제2 신경망에서, 상기 음성 인식 정보 및 입력 데이터 블록을 수신하는 단계; 및상기 음성 인식 정보와 상기 입력 데이터 블록을 결합하여 출력 데이터 블록을 생성하는 단계를 포함하는 방법."}
{"patent_id": "10-2023-0054348", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 출력 데이터 블록과 상기 입력 데이터 블록을 제1 확률을 기반으로 결합하는 단계; 및상기 결합된 데이터 블록을 출력하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2023-0054348", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제1 확률은 학습 모듈(module)에 의해 설정되고,상기 학습 모듈은 time pooling 연산 층(layer), linear 연산 층, 및 softmax 연산 층을 포함하고,상기 학습 모듈은 임의의 입력 데이터 블록 및 임의의 출력 데이터 블록을 학습데이터로 사전 학습된 것인방법."}
{"patent_id": "10-2023-0054348", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 음성 인식 정보는 상기 음성 신호의 각 프레임 별 출력 라벨에 대한 확률 분포 정보를 포함하는 방법."}
{"patent_id": "10-2023-0054348", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 음성 인식 정보와 상기 입력 데이터 블록을 결합하여 출력 데이터 블록 생성하는 단계는:상기 음성 인식 정보에 대한 연산을 통해 가중치(weight) 및 편향(bias)를 결정하는 단계;상기 가중치 및 상기 편향을 기반으로 상기 입력 데이터 블록을 연산하여 상기 출력 데이터 블록을 생성하는 단계를 포함하는 방법."}
{"patent_id": "10-2023-0054348", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2024-0157472-3-제5항에 있어서,상기 가중치 및 상기 편향을 통해 상기 입력 데이터 블록을 연산하여 상기 출력 데이터 블록을 생성하는 단계는FiLM(feature-wise linear modulation) 층에서 수행되는 방법."}
{"patent_id": "10-2023-0054348", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 제1 신경망은 음성 인식을 위한 모델인 CTC(connectionist temporal classification) 모델이고, 및상기 제2 신경망은 음성 향상을 위한 모델인 Conv-TasNet 모델에 포함되는 Temporal Convolutional Network(TCN) 블록인 방법."}
{"patent_id": "10-2023-0054348", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "전자 장치에 있어서,메모리;모뎀; 및상기 모뎀 및 상기 메모리에 연결되는 프로세서를 포함하고,상기 프로세서는:제1 신경망에서, 입력된 음성 신호의 시퀀스에 대한 잠재 표현(hidden representation)을 결정하고,상기 잠재 표현을 기반으로 음성 인식 정보를 결정하고,제2 신경망에서, 상기 음성 인식 정보 및 입력 데이터 블록을 수신하고, 그리고상기 음성 인식 정보와 상기 입력 데이터 블록을 결합하여 출력 데이터 블록을 생성하도록 구성되는 전자 장치."}
{"patent_id": "10-2023-0054348", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 프로세서는:상기 출력 데이터 블록과 상기 입력 데이터 블록을 제1 확률을 기반으로 결합하고, 및상기 결합된 데이터 블록을 출력하도록 더 구성되는 전자 장치."}
{"patent_id": "10-2023-0054348", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 제1 확률은 학습 모듈(module)에 의해 설정되고,상기 학습 모듈은 time pooling 연산 층(layer), linear 연산 층, 및 softmax 연산 층을 포함하고,상기 학습 모듈은 임의의 입력 데이터 블록 및 임의의 출력 데이터 블록을 학습데이터로 사전 학습된 것인 전자장치."}
{"patent_id": "10-2023-0054348", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 음성 인식 정보는 상기 음성 신호의 각 프레임 별 출력 라벨에 대한 확률 분포 정보를 포함하는 전자공개특허 10-2024-0157472-4-장치."}
{"patent_id": "10-2023-0054348", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서, 상기 프로세서는:상기 음성 인식 정보에 대한 연산을 통해 가중치(weight) 및 편향(bias)를 결정하고, 및상기 가중치 및 상기 편향을 기반으로 상기 입력 데이터 블록을 연산하여 상기 출력 데이터 블록을 생성하도록구성되는 전자 장치."}
{"patent_id": "10-2023-0054348", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 프로세서는:FiLM(feature-wise linear modulation) 층에서, 상기 가중치 및 상기 편향을 기반으로 상기 입력 데이터 블록을 연산하여 상기 출력 데이터 블록을 생성하도록 구성되는 전자 장치."}
{"patent_id": "10-2023-0054348", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서,상기 제1 신경망은 음성 인식을 위한 모델인 CTC(connectionist temporal classification) 모델이고, 및상기 제2 신경망은 음성 향상을 위한 모델인 Conv-TasNet 모델에 포함되는 Temporal Convolutional Network(TCN) 블록인 전자 장치."}
{"patent_id": "10-2023-0054348", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "프로세서(processor)에 의해 실행 가능한 인공지능 알고리즘을 통해 음성 품질을 향상시키는 방법을 수행하기위한 매체에 저장된 프로그램으로서,제1 신경망에서, 입력된 음성 신호의 시퀀스에 대한 잠재 표현(hidden representation)을 결정하는 단계;상기 잠재 표현을 기반으로 음성 인식 정보를 결정하는 단계;제2 신경망에서, 상기 음성 인식 정보 및 입력 데이터 블록을 수신하는 단계; 및상기 음성 인식 정보와 상기 입력 데이터 블록을 결합하여 출력 데이터 블록을 생성하는 단계를 수행하는 프로그램."}
{"patent_id": "10-2023-0054348", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공지능을 이용하여 전자 장치에 의해 수행되는 음성 향상 방법에 있어서, 제1 신경 망에서, 입력된 음성 신호의 시퀀스에 대한 잠재 표현(hidden representation)을 결정하는 단계; 상기 잠재 표현 을 기반으로 음성 인식 정보를 결정하는 단계; 제2 신경망에서, 상기 음성 인식 정보 및 입력 데이터 블록을 수 신하는 단계; 및 상기 음성 인식 정보와 상기 입력 데이터 블록을 결합하여 출력 데이터 블록 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0054348", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공지능을 이용하여 음성을 향상시키기 위한 방법 및 그 장치 나타낸다. 구체적으로, 음성 인식 기 술을 활용한 인공지능을 학습시켜 음성을 향상시키는 방법을 나타낸다."}
{"patent_id": "10-2023-0054348", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 개시는 음성 신호에 대한 잡음(noise)를 제거하여 향상된 음성을 제공하는 시스템 및 방법에 관한 것이다. 최근 음성 신호를 수집하고 데이터로 가공하는 음성 인식 기술이 대두되고 있다. 음성 인식 기술은 프로그램을 통해 사람의 음성을 텍스트 형식으로 처리할 수 있도록 하는 기술을 나타낸다. 음성 인식 프로그램은 화자의 문 법, 구문, 구조 등을 이해하고 처리할 수 있다. 음성 인식 프로그램의 기능을 향상시키기 위하여 음성 신호에대한 전처리를 통해 음성을 향상시키는 음성 향상 시스템이 필요하다. 음성 향상 시스템에는 다양한 종류가 존재하지만 특히 인공지능 기반의 음성 향상 시스템이 주목받고 있다. 다 만, 인공지능 기반의 음성 향상 시스템에 있어서, 음성 품질의 향상을 목표로 학습이 수행되다 보니 음성 인식 성능이 저하되는 문제가 발생하였다. 따라서, 음성 향상 기능과 음성 인식 기능을 동시에 향상시키기 위한 방법 이 요구되고 있다. 이와 관련하여 인공지능 알고리즘에 음성 인식과 관련된 정보들을 적용하여 음성 향상 기능 을 학습시키는 방법이 제안되었지만, 음성 향상 모델과 음성 인식 모델이 동시에 학습(joint training)되어야 하는 한계가 있었다. 공동 학습에 따라 새로운 모듈이 결합되고 모델의 복잡도 및 크기가 증가하여 사용이 제한 되는 문제가 발생하기도 하였다."}
{"patent_id": "10-2023-0054348", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에서는 음성 인식 정보를 이용하여 음성 향상 기능을 향상시키는 방법 및 그 장치를 제공하고자 한다. 본 개시에서는 계산에 대한 부하를 감소시키면서 음성 인식 기능과 음성 향상 기능을 향상시키는 방법을 제공하 고자 한다."}
{"patent_id": "10-2023-0054348", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공지능을 이용하여 전자 장치에 의해 수행되는 음성 향상 방법에 있어서, 제1 신경 망에서, 입력된 음성 신호의 시퀀스에 대한 잠재 표현(hidden representation)을 결정하는 단계; 상기 잠재 표 현을 기반으로 음성 인식 정보를 결정하는 단계; 제2 신경망에서, 상기 음성 인식 정보 및 입력 데이터 블록을 수신하는 단계; 및 상기 음성 인식 정보와 상기 입력 데이터 블록을 결합하여 출력 데이터 블록을 생성하는 단 계를 포함할 수 있다. 일 실시예에서, 상기 출력 데이터 블록과 상기 입력 데이터 블록을 제1 확률을 기반으로 결합하는 단계; 및 상 기 결합된 데이터 블록을 출력하는 단계를 더 포함할 수 있다. 일 실시예에서, 상기 제1 확률은 학습 모듈(module)에 의해 설정되고, 상기 학습 모듈은 time pooling 연산 층 (layer), linear 연산 층, 및 softmax 연산 층을 포함하고, 상기 학습 모듈은 임의의 입력 데이터 블록 및 임의 의 출력 데이터 블록을 학습데이터로 사전 학습된 것일 수 있다. 일 실시예에서, 상기 음성 인식 정보는 상기 음성 신호의 각 프레임 별 출력 라벨에 대한 확률 분포 정보를 포 함할 수 있다. 일 실시예에서, 상기 음성 인식 정보와 상기 입력 데이터 블록을 결합하여 출력 데이터 블록 생성하는 단계는: 상기 음성 인식 정보에 대한 연산을 통해 가중치(weight) 및 편향(bias)를 결정하는 단계; 상기 가중치 및 상기 편향을 기반으로 상기 입력 데이터 블록을 연산하여 상기 출력 데이터 블록을 생성하는 단계를 포함할 수 있다. 일 실시예에서, 상기 가중치 및 상기 편향을 통해 상기 입력 데이터 블록을 연산하여 상기 출력 데이터 블록을 생성하는 단계는 FiLM(feature-wise linear modulation) 층에서 수행될 수 있다. 일 실시예에서, 상기 제1 신경망은 음성 인식을 위한 모델인 CTC(connectionist temporal classification) 모 델이고, 및 상기 제2 신경망은 음성 향상을 위한 모델인 Conv-TasNet 모델에 포함되는 Temporal Convolutional Network (TCN) 블록일 수 있다. 본 발명의 실시 예에 따른 전자 장치에 있어서, 메모리; 모뎀; 및 상기 모뎀 및 상기 메모리에 연결되는 프로세 서를 포함하고, 상기 프로세서는: 제1 신경망에서, 입력된 음성 신호의 시퀀스에 대한 잠재 표현(hidden representation)을 결정하고, 상기 잠재 표현을 기반으로 음성 인식 정보를 결정하고, 제2 신경망에서, 상기 음 성 인식 정보 및 입력 데이터 블록을 수신하고, 및 상기 음성 인식 정보와 상기 입력 데이터 블록을 결합하여 출력 데이터 블록을 생성하도록 구성될 수 있다. 본 발명의 실시 예에 따른 프로세서(processor)에 의해 실행 가능한 인공지능 알고리즘을 통해 음성 품질을 향 상시키는 방법을 수행하기 위한 매체에 저장된 프로그램으로서, 제1 신경망에서, 입력된 음성 신호의 시퀀스에 대한 잠재 표현(hidden representation)을 결정하는 단계; 상기 잠재 표현을 기반으로 음성 인식 정보를 결정하 는 단계; 제2 신경망에서, 상기 음성 인식 정보 및 입력 데이터 블록을 수신하는 단계; 및 상기 음성 인식 정보와 상기 입력 데이터 블록을 결합하여 출력 데이터 블록을 생성하는 단계를 수행할 수 있다."}
{"patent_id": "10-2023-0054348", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, 음성 인식 정보를 이용하여 인공지능을 학습시켜 음성의 품질을 향상시킬 수 있 다. 본 개시의 일 실시예에 따르면, 음성 인식 정보를 선택적으로 활용하는 모듈을 추가하여 음성 명료도를 향상시 킬 수 있다."}
{"patent_id": "10-2023-0054348", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 기술적 사상은 다양한 변경을 가할 수 있고 여러 가지 실시 예를 가질 수 있는 바, 특정 실시 예들을 도면에 예시하고 이를 상세한 설명을 통해 상세히 설명하고자 한다. 그러나, 이는 본 발명의 기술적 사상을 특 정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 기술적 사상의 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 발명의 기술적 사상을 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 본 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제1, 제2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별기호에 불과하다. 또한, 본 명세서에서, 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것이다. 또한, 본 명세서에 기재된 \"~부\", \"~기\", \"~자\", \"~모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 프로세서(Processor), 마이크로 프로세서(Micro Processer), 마이크로 컨트롤러(Micro Controller), CPU(Central Processing Unit), GPU(Graphics Processing Unit), APU(Accelerate Processor Unit), DSP(Drive Signal Processor), ASIC(Application Specific Integrated Circuit), FPGA(Field Programmable Gate Array) 등과 같은 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있으며, 적어도 하나의 기능이나 동작의 처리에 필요한 데이터를 저장하는 메모리(memory)와 결합되는 형태 로 구현될 수도 있다. 그리고 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기능 별로 구분한 것에 불과함을 명확 히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이하에서 설명할 구성부 각각은 자 신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전부의 기능을 추가적으로 수행할수도 있으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의해 전담되어 수행될 수도 있음은 물론이다. 본 개시의 실시예들을 설명함에 있어서 관련된 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필 요하게 흐릴 수 있다고 판단된 경우 그 상세한 설명은 생략한다. 그리고 후술되는 용어들은 본 개시에서의 기능 을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 마찬가지 이유로 첨부 도면에 있어서 일부 구성요소는 과장되거나 생략되거나 개략적으로 도시될 수 있다. 또한, 각 구성요소의 크기는 실제 크기를 전적으로 반영하는 것이 아니다. 각 도면에서 동일한 또는 대응하는 구성요소에는 동일한 참조 번호를 부여하였다. 본 개시의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 실시예들은 본 개시의 설명이 완전하도록 하고, 본 개시의 실시예"}
{"patent_id": "10-2023-0054348", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "들이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 개시의 청구하고자 하는 범위는 청구항의 범주에 의해 정의될 뿐이다. 이때, 처리 흐름도를 보이는 도면들의 각 블록과 처리 흐름도 도면들의 조합들은 컴퓨터 프로그램 인스트럭션들 에 의해 수행될 수 있음을 이해할 수 있을 것이다. 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서를 통해 수행되는 그 인스트럭션들이 흐름도 블록(들)에서 설 명된 기능들을 수행하는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구 현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능하므로, 그 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저 장된 인스트럭션들은 흐름도 블록(들)에서 설명된 기능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생 산하는 것도 가능하다. 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장 비 상에 탑재되는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에서 일련의 동 작 단계들이 수행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능한 데이터 프로 세싱 장비를 수행하는 인스트럭션들은 흐름도 블록(들)에서 설명된 기능들을 실행하기 위한 단계들을 제공하는 것도 가능하다. 또한, 각 블록은 특정된 논리적 기능(들)을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또, 몇 가지 대체 실행 예들에서는 블록들에서 언급된 기 능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들 은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들이 때때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다. 본 개시에서 사용되는 '~부(unit or part)'라는 용어는 소프트웨어 또는 FPGA(field-Programmable Gate Array) 또는 ASIC(Application Specific Integrated Circuit)과 같은 하드웨어 구성요소를 의미하며, '~부'는 특정한 역할들을 수행하도록 구성될 수 있다. 그렇지만 '~부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '~부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 실행시키 도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브 루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들, 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수 의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구 성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 CPU들을 재생시키도록 구 현될 수도 있다. 또한 실시예에서 '~부'는 하나 이상의 프로세서 및/또는 장치를 포함할 수 있다. 이하, 본 발명의 기술적 사상에 따른 실시 예들을 차례로 상세히 설명한다. 도 1은 본 개시의 일 실시 예에 따른 인공지능 구조의 기본적인 원리를 나타낸 개념도이다. 도 1을 참조하면, 인공지능 구조에서 학습이 수행되는 기본적인 원리를 나타낸다. 인공지능 기술은 학습, 문제 해결, 인식 등과 같이 주로 인간 지능과 연결된 인지 문제를 해결하기 위한 기술을 나타낸다. 인공지능은 Machine learning(ML)이라고 불리는 기계 학습 방식과 Deep learning(DL)이라고 불리는 딥 러닝 방식을 통해 학습될 수 있다. 머신 러닝은 패턴 인식 및 학습에 사용되는 기법에 주로 사용되며 기록된 데이터를 학습하여 이를 기반으로 이후의 데이터를 예측하는 알고리즘을 나타낸다. 사전에 정의된 규칙이나 패 턴을 기반으로 하지 않고 데이터로부터 스스로 학습하는 기술을 나타낸다. 반면에 딥 러닝은 머신 러닝의 한 분 야로 인공 신경망(Artificial Neural Network: ANN)을 기반으로 하여 데이터를 처리하는 차이점이 있다. 딥 러 닝은 인공 신경망을 이용하기 때문에 머신 러닝보다 더욱 복잡하고 정교한 연산을 처리할 수 있다. 딥 러닝을 위한 알고리즘 종류로는 합성곱 신경망(Convolution neural network: CNN), 인공 신경망(ANN), 순환 신경망 (Recurrent Neural Network: RNN)등을 포함할 수 있다. 도 1을 참고하면, 인공지능 구조는 인공지능 모듈로 나타낼 수 있다. 인공지능 모듈은 소정의 입력 데이터를 수신하여 모듈에서 정해진 소정의 방식을 통해 학습을 수행하고, 학습 결과에 대한 출력 데이터 를 출력하게 된다. 일 실시예에 따르면, 입력 데이터에는 소정의 데이터, 음성 신호, 입력 시퀀스를 포함할 수 있다. 출력 데이터에는 향상된 음성 신호, 음성 인식 정보(예를 들어, posterior probability) 등이 포함될 수 있다. 도 2는 본 개시의 일 실시예에 따른, 음성향상 시스템의 인공지능 알고리즘 구조 중 하나를 나타낸 도면이다. 도 2의 인공지능 알고리즘은 도 1의 인공지능 모듈의 종류 중 하나일 수 있다. 도 2의 인공지능 알고리즘은 합성곱 신경망(CNN)의 일종인 Conv-TasNet일 수 있다. Conv-TasNet은 주파수 영역에서 딥 러닝을 사용하여 음성 신호를 처리하는 음원 분리 모델을 나타낼 수 있다. Conv-TasNet은 음성 신 호를 처리하여 음성 인식, 음악 분석, 음악 생성 등의 기능을 수행할 수 있다. 도 2를 참조하면, 인공지능 알고리즘은 인코더(encoder) 모듈, 추정(estimation) 모듈, 디코더 (decoder) 모듈을 포함할 수 있다. 인코더 모듈은 오디오 신호를 입력 받아 프레임 단위로 나누고 이 를 스펙트로그램으로 변환할 수 있다. 인코더 모듈은 스펙트로그램을 통하여 입력 신호의 특징을 추출할 수 있다. 인코더 모듈은 1차원(1D, dimension) 콘볼루션(합성곱) 층으로 이루어져 있으며 시간 영역의 raw waveform을 잠재 영역의 특징(feature)으로 변환시킬 수 있다. 추정 모듈은 인코더 모듈에서 추출된 신호의 특징을 기반으로 소스 신호를 추정할 수 있다. 추정 모 듈은 복수의 시간 합성곱 네트워크(temporal convolution network: TCN)들을 포함할 수 있다. TCN은 입력 신호의 시간적인 특성을 획득하기 위한 구조를 가질 수 있다. TCN은 시계열 데이터에 대 한 모델링에서 주로 사용되어 시간에 따른 데이터에 대한 학습을 수행할 수 있다. 각 TCN블록은 이후 도 3 에서 나타난 바와 같이 1Х1 convolution 단계, parametric rectified linear unit (PReLU) 비선형 함수 단계, normalization 단계, depth-wise dilated convolution(D-conv) 단계, 및 잔차 연결 (residual connection path) 단계 중 적어도 하나를 포함할 수 있다. 다만, 각각의 단계들이 반드시 포함되어야 하는 것은 아니다. 추 정 모듈에서 추정된 마스크(mask)는 인코더 모듈에서의 출력과 곱해져서 향상된 잠재 영역 특징 (feature)를 출력할 수 있으며, 출력된 특징은 디코더 모듈을 통해 다시 시간영역 신호로 변환될 수 있다. 디코더 모듈은 분리된 소스 신호를 재구성할 수 있다. 디코더 모듈은 소스 신호에 대해서 시간 도 메인으로 변환하고 재구성하여 오디오 신호를 생성할 수 있다. 일 실시예에 따르면, 도 2의 인공지능 알고리즘은 end-to-end 방식으로 학습하며, 입력 신호와 각 소스 신 호 간의 차이를 최소화하는 방향으로 학습할 수 있다. 도 3은 본 개시의 일 실시예에 따른, 음성 품질을 향상시키기 위한 인공지능 알고리즘의 블록 구조도를 나타낸 것이다. 도 3의 TCN 구조는 도 2의 TCN 구조와 동일한 구조일 수 있다. 도 3을 참조하면, 본 개시의 일 실시예에 따른 전체 인공지능 알고리즘 구조는 CTC(Connectionist Temporal Classification) 구조 및 TCN 구조를 포함할 수 있다. 일 실시예에 따르면, CTC 구조는 CTC ASR(Automatic speech recognition)이라고도 불리며, 입력된 음성 신호를 텍스트 시퀀스로 변환하는 모델을 나타낼 수 있다. 즉, CTC 구조는 입력 음성으로부터 타겟 시퀀스 를 예측하는 end-to-end 음성인식 시스템을 나타낸다. CTC 기반 음성인식 시스템은 입력 음성 시퀀스와 타 겟 시퀀스 간의 명시적인 정렬 정보 없이도 음성 인식 기능을 수행할 수 있다. CTC 구조는 모든 가능한 시 퀀스에 대한 확률 분포를 고려할 수 있다. 즉, 주어진 입력 음성 시퀀스에 대한 모든 가능한 출력 시퀀스의 확 률 분포를 고려할 수 있다. 이를 계산하기 위한 수학식은 다음과 같다. [수학식 1]"}
{"patent_id": "10-2023-0054348", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 1에서 X는 입력 시퀀스, Y는 타겟 시퀀스를 나타내며, B(Y,X)는 가 Y에 매핑될 수 있는 모든 가능한 경 로를 의미할 수 있다. T개의 프레임별 예측 출력 라벨 를 모든 곱한 후 가능한 경로에 대해 모두 더해주면 입 력 시퀀스 X가 주어졌을 때 타겟 시퀀스 Y가 나타날 확률이 될 수 있다. 여기서 X는 입력 음성 신호로부터 생성 된 음성인식 관련 특징(feature)이고 Y는 텍스트 정보일 수 있다. 는 X가 T개의 프레임을 가지고 있을 때, t 번째 프레임에서 예측한 라벨을 나타낼 수 있다. CTC 음성인식 시스템은 해당 확률의 negative log 값이 최소가 되는 방향으로 학습이 진행될 수 있으며, 학습에 서 손실(loss)를 구하는 수식은 다음과 같다. [수학식 2]"}
{"patent_id": "10-2023-0054348", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "일 실시예에 따르면, CTC 구조는 음성 신호의 컨텍스트 정보를 내포하고 있는 probability vector를 추출 하여 이를 음성 향상 시스템 학습에 활용할 수 있다. Probability vector는 각 프레임 별 CTC 출력 라벨(labe l)이 지니는 posterior probability를 나타낼 수 있다. CTC 구조 기반 posterior probability는 다음 수 식을 통해 결정될 수 있다. [수학식 3]"}
{"patent_id": "10-2023-0054348", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, H는 음성인식 시스템이 학습되는 과정에서 중간에 출력되는 잠재 특징으로 음성인식 모델 인코더 모듈 의 hidden representation(잠재 표현)을 나타내고, H에 대해 linear 및 softmax 연산을 수행하여 posterior probability인 Z(이하 Z)를 출력할 수 있다. Z는 각 프레임에 대한 CTC class label 분포 매트릭스를 나타내고, 음성향상 모델의 추정 모듈의 각 TCN 블록에 대해서 컨디셔닝 정보로 활용될 수 있다. Z는 상기 음성 신호의 각 프레임 별 출력 라벨에 대한 확률 분포 정보를 포함할 수 있다. CTC 구조에서 출력된 Z는 TCN에 컨디셔닝 정보로 입력될 수 있다. Z는 linear layer를 통해 특징이 변형될 수 있다. 이 때, 라는 linear 연산을 통해 가중치(weight) 값을 출력하고 라는 linear 연산 을 통해 편향(bias) 값을 출력할 수 있다. 출력된 가중치 값 및 편향 값과 TCN 블록으로의 입력 은 featurewise linear modulation (FiLM) layer를 통해 결합될 수 있다. FiLM은 서로 다른 두 특징을 결합하기 위해 활용되는 컨디셔닝 방법 중 하나의 방식이며 다음과 같은 수식으로 계산될 수 있다. [수학식 4] 여기서 은 n번째 TCN 블록의 입력을 나타내고, linear 연산을 통해 음성인식 정보인 Z와 C를 결합할 수 있 다. FiLM의 출력값은 기존 TCN 블록의 입력과 같은 메커니즘으로 연산이 이루어질 수 있다. FiLM의 출력으로 획득되는 잠재 특징은 으로 나타낼 수 있다. 일 실시예에 따르면, TCN 블록에는 1Х1 convolution 단계, parametric rectified linear unit (PReLU) 비선형 함수 단계, normalization 단계, depth-wise dilated convolution(D-conv) 단계, 및 잔차 연결 (residual connection path) 단계를 포함할 수 있다. 추가로, TCN 블록에는 선택적 컨디셔닝 방식이 적용될 수 있다. 음성 인식 정보를 활용하여 음성 향상 시스템에 적용할 때 무조건적으로 획득된 잠재 특징을 사용하는 것 보다 필요한 만큼만 선택하여 학습에 사용하는 것이 효율적일 수 있다. 이 때, 선택적 컨디셔닝 방식을 적용한 FeatSelect 모듈이 활용될 수 있다. TCN 블록은 선택적으로 FeatSelect 모듈을 포함할 수 있다. FeatSelect 모듈은 time pooling 단계, linear 단계, softmax 단계를 포함할 수 있다. FeatSelect 모듈은 TCN 블록의 입력인 과 FiLM 컨디셔닝을 통해 획득된 잠재 특징인 을 입력으로 받아 두 피 쳐를 결합하는 방식을 사용할 수 있다. 결합된 결과 값은 다음 TCN 블록을 위한 residual connection path로 전 달될 수 있다. FeatSelect 모듈에 적용되는 수식은 다음과 같다. [수학식 5]"}
{"patent_id": "10-2023-0054348", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "[수학식 6]"}
{"patent_id": "10-2023-0054348", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "[수학식 7]"}
{"patent_id": "10-2023-0054348", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서, 과 은 각각 컨디셔닝 된 특징과 원래 입력 특징이 결합될 확률을 나타내는 것으로 모두 0과 1 사이의 확률 값을 나타내고 두 확률의 합은 항상 1이되도록 설정된다. FeatSelect 모듈로부터 결합된 피쳐 는 TCN 블록의 계산된 피쳐와 더해져 다음 TCN 블록의 입력 피쳐로 사용된다. 상기 절차들에 따라 계산된 음성 의 경우 품질 및 명료도가 향상되어 기존의 다른 모델들보다 더 나은 성능을 나타낸다. 도 4는 본 개시의 일 실시예에 따른 인공지능 모델과 기존 모델에 대한 음성 향상 실험 결과 값을 나타낸다. 도 4에서 사용된 데이터 셋은 공용 데이터인 월스트릿 저널(wall street journal, WSJ)을 사용한 것이다. WSJ 데이터 셋으로 음성인식기 모델을 학습하고 각 프레임 별 라벨 정보를 추출하여 음성 향상 시스템에 적용하였다. 비교 결과로는 음성향상 시스템을 적용하지 않은 Noisy, 기존의 모델인 Conv-TasNet 방식, 음성 인식 정보를 음성향상 시스템에 적용하는 FiLM 방식, 음성인식 정보를 선택적으로 활용하도록 하는 FeatSelect 방식을 나타내었다. 실험 방법으로는 음성 품질 평가 지표로 통상적으로 활용되는 CSIG(Clean Speech Intelligibility Guarantee), CBAK(Composite Background Noise Attenuation Key), COVL(Coverage), PESQ(Perceptual Evaluation of Speech Quality)를 사용하였다. 본 개시에서 제안하는 FiLM 방식 및 FeatSelect 방식 모두 모든 분야에서 수치가 향상되는 것을 나타내며, 특히, 선택적인 방식인 FeatSelect에서의 수치가 크게 상승하였다. 그 중 CSIG는 음성의 왜곡된 정도를 나타내 는 것으로 종래 모델에 비하여 수치가 가장 크게 증가하였다. 도 5는 본 개시의 일 실시예에 따른 인공지능 모델과 기존 모델에 대한 음성 인식 측정 결과 값을 나타낸다. 도 5에서 사용된 데이터 셋은 공용 데이터인 WSJ을 사용한 것이다. WSJ 데이터 셋으로 음성인식기 모델을 학습 하고 각 프레임 별 라벨 정보를 추출하여 음성 향상 시스템에 적용한 뒤 음성 인식 기능에 대해서 측정한 것이다. 비교 결과로는 음성향상 시스템을 적용하지 않은 Noisy, 기존의 모델인 Conv-TasNet 방식, 음성 인식 정보를 음성향상 시스템에 적용하는 FiLM 방식, 음성인식 정보를 선택적으로 활용하도록 하는 FeatSelect 방식을 나타내었다. 측정 결과 값으로는 단어 오류율(word error rate)를 측정한 것으로 다음 수식과 같이 계산될 수 있다. [수학식 8]"}
{"patent_id": "10-2023-0054348", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서 D는 음성 인식된 텍스트에 잘못 삭제된 단어의 수, S는 음성 인식된 텍스트에 잘못 대체된 단어의 수, I 는 음성 인식된 테스트에 잘못 추가된 단어의 수, N은 정답 텍스트 단어의 수를 나타낸다. 본 개시에서 제안하는 FiLM 방식 및 FeatSelect 방식 모두 모든 분야에서 WER 값이 감소하는 것을 확인할 수 있 으며, 특히, 선택적인 방식인 FeatSelect에서의 수치가 더 감소하였다. 도 6은 본 개시의 일 실시예에 따른 인공지능 모델에서 선택적 방식을 사용할 때의 결합 확률을 나타낸 것이다. 도 6의 그래프들에서 x축은 기존 입력 특징(feature)를 결합하는 확률, y축은 음성인식 정보가 결합된 특징 (feature)을 결합하는 확률을 나타내며, 두 확률의 합은 1을 나타낸다. 모든 신호대잡음비(signal noise ratio: SNR)에서 분포가 2사분면에 치우쳐 있는 것을 통하여 음성인식 정보가 결합된 특징이 음성향상 모델의 성능 향 상에 더 도움이 될 수 있음을 확인할 수 있다. 도 7은 본 개시의 일 실시예에 따른 음성 향상 시스템을 위한 전자 장치에 대한 블록 구성도이다. 도 7을 참조하면, 전자 장치는 모뎀(MODEM, 720), 메모리(MEMORY, 740) 및 프로세서(PROCESSOR, 730)를 포함할 수 있다. 모뎀은 다른 전자 장치들과 전기적으로 연결되어 상호 통신이 이뤄지도록 하는 통신 모뎀일 수 있다. 특히 모뎀은 데이터 입력을 수신하여 프로세서로 전송할 수 있고, 프로세서는 입력된 데이터 값을 메 모리에 저장할 수 있다. 또한, 시스템에서 학습된 인공지능 알고리즘에 의해 출력된 데이터 값을 다른 전 자 장치로 전송할 수 있다. 메모리는 전자 장치의 동작을 위한 각종 정보 및 프로그램 명령어들이 저장되는 구성으로서, 하드 디 스크(Hard Disk), SSD(Solid State Drive) 등과 같은 기억장치일 수 있다. 특히 메모리는 프로세서 의 제어에 의해 모뎀에서 입력되는 하나 이상의 데이터 입력 값을 저장할 수 있다. 또한, 메모리는 프로세서에 의해 실행 가능한 음성인식 향상 및 음성 품질 향상을 위한 인공지능 알고리즘과 같은 프로그 램 명령어들을 저장할 수 있다. 프로세서는 적어도 하나의 프로세서로 구성되며, 메모리에 저장된 데이터 및 프로그램 명령어들을 이 용하여 음성 인식 향상 인공지능 알고리즘, 및 음성 품질 향상 인공지능 알고리즘을 학습하고 이를 활용하여 데 이터를 계산할 수 있다. 프로세서는 도 1 내지 도 6에서 설명한 모든 인공지능 알고리즘(예를 들어, Conv- TasNet, CTC, TCN)을 제어하고 계산할 수 있다. 도 8은 본 개시의 일 실시예에 따른 음성 품질 향상 방법을 설명하기 위한 순서도이다. 이하 도 8을 참조하여, 도 1 내지 도 7을 참조하여 설명한 전자 장치의 인공지능 알고리즘의 학습 동작 및 음성 인식 향상, 음성 품질 향상 방법에 대해 정리하여 설명한다. 각 동작들은 일련의 과정에서 필수적으로 포함되어 야 하는 동작들은 아니며 상황에 따라 일부만이 구성되어 동작할 수 있다. 단계 S810에서, 인공지능을 학습시키기 위하여 제1 신경망에서, 입력된 음성 신호의 시퀀스에 대한 잠재 표현 (예를 들어, 도 3의 H)을 결정할 수 있다. 상기 인공지능은 음성 인식 시스템 및 음성 향상 시스템에 사용되는 인공지능 신경망일 수 있다. 상기 제1 신경망은 음성 인식을 위한 모델인 CTC(connectionist temporal classification) 모델일 수 있다. 단계 S820에서, 상기 잠재 표현을 기반으로 음성 인식 정보를 결정할 수 있다. 상기 음성 인식 정보는 결정된 잠재 표현에 대하여 linear 연산, softmax 연산을 수행하여 획득된 posterior probability일 수 있다. 상기 음 성 인식 정보는 상기 음성 신호의 각 프레임 별 출력 라벨에 대한 확률 분포 정보를 포함할 수 있다. 단계 S830에서, 제2 신경망에서, 상기 음성 인식 정보 및 입력 데이터 블록을 수신할 수 있다. 상기 제2 신경망 은 음성 향상을 위한 모델인 Conv-TasNet 모델에 포함되는 Temporal Convolutional Network (TCN) 블록을 나타 낼 수 있다. 상기 입력 데이터 블록은 전 단계 TCN 블록에서 출력된 데이터일 수 있다. 상기 음성 인식 정보는 linear 연산을 통해 특징이 변형될 수 있다. 상기 음성 인식 정보는 연산을 통해 가중치 및 편향을 결정할 수 있다. 단계 S840에서, 상기 음성 인식 정보와 상기 입력 데이터 블록을 결합하여 출력 데이터 블록을 생성할 수 있다. 상기 음성 인식 정보와 상기 입력 데이터 블록을 결합하는 동작은 FiLM 층에서 수행될 수 있다. 상기 출력 데이 터 블록과 상기 입력 데이터 블록을 제1 확률을 기반으로 결합하여 그 결합된 데이터 블록을 출력할 수 있다. 상기 제1 확률은 상기 제1 확률은 학습 모듈(module)에 의해 설정되고, 상기 학습 모듈은 time pooling 연산 층 (layer), linear 연산 층, 및 softmax 연산 층을 포함하고, 상기 학습 모듈은 임의의 입력 데이터 블록 및 임의 의 출력 데이터 블록을 학습데이터로 사전 학습된 것일 수 있다. 상기 학습 모듈은 도 3의 FeatSelect 모듈과 동일한 것일 수 있다. 이상, 본 발명의 기술적 사상을 다양한 실시 예들을 들어 상세하게 설명하였으나, 본 발명의 기술적 사상은 상 기 실시 예들에 한정되지 않고, 본 발명의 기술적 사상의 범위 내에서 당 분야에서 통상의 지식을 가진 자에 의 하여 여러가지 변형 및 변경이 가능하다."}
{"patent_id": "10-2023-0054348", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 상세한 설명에서 인용되는 도면을 보다 충분히 이해하기 위하여 각 도면의 간단한 설명이 제공된다. 도 1은 본 개시의 일 실시 예에 따른 인공지능 구조의 기본적인 원리를 나타낸 개념도이다. 도 2는 본 개시의 일 실시예에 따른, 음성향상 시스템의 인공지능 알고리즘 구조 중 하나를 나타낸 도면이다. 도 3은 본 개시의 일 실시예에 따른, 음성 품질을 향상시키기 위한 인공지능 알고리즘의 블록 구조도를 나타낸 것이다. 도 4는 본 개시의 일 실시예에 따른 인공지능 모델과 기존 모델에 대한 음성 향상 실험 결과 값을 나타낸다. 도 5는 본 개시의 일 실시예에 따른 인공지능 모델과 기존 모델에 대한 음성 인식 측정 결과 값을 나타낸다. 도 6은 본 개시의 일 실시예에 따른 인공지능 모델에서 선택적 방식을 사용할 때의 결합 확률을 나타낸 것이다. 도 7은 본 개시의 일 실시예에 따른 음성 향상 시스템을 위한 전자 장치에 대한 블록 구성도이다. 도 8은 본 개시의 일 실시예에 따른 음성 품질 향상 방법을 설명하기 위한 순서도이다."}
