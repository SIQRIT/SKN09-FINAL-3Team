{"patent_id": "10-2021-0144301", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0060061", "출원번호": "10-2021-0144301", "발명의 명칭": "작업자 위치 측정 방법 및 그 장치와 시스템", "출원인": "주식회사 파이미디어랩", "발명자": "여병상"}}
{"patent_id": "10-2021-0144301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "작업자 위치 측정 장치(100)로서,CCTV(200) 및 뎁스 카메라(300)가 촬영한 영상 이미지의 거리 정보를 분석하도록 구성되는 거리정보분석부(120);상기 분석된 거리 정보를 학습하여 상기 CCTV(200)가 촬영한 영상 이미지에서 촬영 객체의 거리를 구하는 인공지능 알고리즘을 생성하도록 구성되는 AI 학습부(140); 및상기 생성된 인공지능 알고리즘을 기반으로 상기 촬영 객체의 위치를 측정하고 상기 촬영 객체의 동선을 트래킹하도록 구성되는 객체트래킹부(150)를 포함하는,작업자 위치 측정 장치(100)."}
{"patent_id": "10-2021-0144301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,적어도 하나의 상기 CCTV(200) 및 상기 뎁스 카메라(300)가 촬영한 영상 이미지의 좌표 정보를 분석하도록 구성되는 좌표정보분석부(130)를 더 포함하는,작업자 위치 측정 장치(100)."}
{"patent_id": "10-2021-0144301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 거리정보분석부(120)는,상기 CCTV(200)가 촬영한 영상 이미지에서 상기 촬영 객체를 탐지하도록 구성되는 객체탐지 유닛(121); 및상기 탐지된 촬영 객체의 영역을 추출하도록 구성되는 영역추출 유닛(122)을 포함하는,작업자 위치 측정 장치(100)."}
{"patent_id": "10-2021-0144301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 거리정보분석부(120)는,상기 추출된 촬영 객체의 영역과 상기 뎁스 카메라(300)가 촬영한 영상 이미지를 매핑시키도록 구성되는 이미지매핑 유닛(123)을 더 포함하는,작업자 위치 측정 장치(100)."}
{"patent_id": "10-2021-0144301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "작업자 위치 측정 시스템(1000)으로서,제 1항에 따른 작업자 위치 측정 장치(100);상기 작업자 위치 측정 장치(100)와 통신 가능하게 결합되는 CCTV(200); 및상기 작업자 위치 측정 장치(100)와 통신 가능하게 결합되는 뎁스 카메라(300)를 포함하는,작업자 위치 측정 시스템(1000).공개특허 10-2023-0060061-3-청구항 6 작업자 위치 측정 방법으로서,CCTV 및 뎁스 카메라가 촬영한 영상 이미지의 거리 정보를 분석하는 단계;상기 분석된 거리 정보를 학습하여 상기 CCTV가 촬영한 영상 이미지에서 촬영 객체의 거리를 구하는 인공지능알고리즘을 생성하는 단계; 및상기 생성된 인공지능 알고리즘을 기반으로 상기 촬영 객체의 위치를 측정하고 상기 촬영 객체의 동선을 트래킹하는 단계를 포함하는,작업자 위치 측정 방법."}
{"patent_id": "10-2021-0144301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서,적어도 하나의 상기 CCTV 및 상기 뎁스 카메라가 촬영한 영상 이미지의 좌표 정보를 분석하는 단계를 더 포함하는,작업자 위치 측정 방법."}
{"patent_id": "10-2021-0144301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 6항에 있어서,상기 CCTV 및 뎁스 카메라가 촬영한 영상 이미지의 거리 정보를 분석하는 단계는,상기 CCTV가 촬영한 영상 이미지에서 상기 촬영 객체를 탐지하는 단계; 및상기 탐지된 촬영 객체의 영역을 추출하는 단계를 포함하는,작업자 위치 측정 방법."}
{"patent_id": "10-2021-0144301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서,상기 CCTV 및 뎁스 카메라가 촬영한 영상 이미지의 거리 정보를 분석하는 단계는,상기 추출된 촬영 객체의 영역과 상기 뎁스 카메라가 촬영한 영상 이미지를 매핑시키는 단계를 더 포함하는,작업자 위치 측정 방법."}
{"patent_id": "10-2021-0144301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 6항 내지 제 9항 중 어느 한 항에 따른 방법을 수행하기 위한 컴퓨터 프로그램이 기록되는,컴퓨터 판독 가능한 기록 매체."}
{"patent_id": "10-2021-0144301", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "작업자 위치 측정 장치가 제공된다. 상기 작업자 위치 측정 장치는, CCTV 및 뎁스 카메라가 촬영한 영상 이미지 의 거리 정보를 분석하도록 구성되는 거리정보분석부; 상기 분석된 거리 정보를 학습하여 상기 CCTV가 촬영한 영 상 이미지에서 촬영 객체의 거리를 구하는 인공지능 알고리즘을 생성하도록 구성되는 AI 학습부; 및 상기 생성된 인공지능 알고리즘을 기반으로 상기 촬영 객체의 위치를 측정하고 상기 촬영 객체의 동선을 트래킹하도록 구성되 는 객체트래킹부를 포함할 수 있다."}
{"patent_id": "10-2021-0144301", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 작업자 위치 측정 방법 및 그 장치와 시스템에 관한 발명으로서, 보다 구체적으로는 CCTV가 촬영한 영상 이미지에서 촬영 객체의 탐지 및 추출을 수행하고, 탐지 및 추출이 수행된 촬영 객체의 영역을 뎁스 카메 라로 촬영한 뎁스 이미지와 매핑함으로써 촬영 객체의 거리 정보를 용이하게 분석할 수 있으며, 분석된 거리 정 보를 학습하여 인공지능 알고리즘을 생성하고, 생성된 인공지능 알고리즘을 기반으로 CCTV의 영상 이미지만으로 용이하게 촬영 객체의 거리 정보를 파악하여 촬영 객체의 위치를 측정하고 동선을 트래킹할 수 있는 작업자 위 치 측정 방법 및 그 장치와 시스템에 관한 발명이다."}
{"patent_id": "10-2021-0144301", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 영상 이미지에서 사람, 동물, 차량 등 의미 있는 객체의 종류와 그 위치를 정확하게 찾을 수 있는 인공지능 딥 러닝 기반의 컴퓨터 비전(computer vision) 기술이 존재하고, 이러한 객체 탐지(object detection) 기술은 얼굴 인식, 도로상의 보행자, 차량 등의 인식 등 실생활에 다양하게 활용되고 있다. 그러나, 이와 같은 객체 탐지 기술만으로는 촬영 객체에 대한 거리 정보 즉, 촬영 객체의 정확한 위치, 촬영 카 메라로부터 촬영 객체까지의 거리 및 촬영 객체의 동선 등에 관한 정보를 용이하게 파악할 수 없으므로, 이러한 기존의 객체 탐지 기술만으로는 작업 현장의 특정 구역에서 작업 중인 작업자를 관리 감독 및 감시하고, 작업자 의 동선을 트래킹(tracking)하기에 부적합하다는 문제점이 있다. 또한, CCTV 등의 RGB 기반의 카메라를 통해 촬영되는 이미지는 촬영 지점에서 먼 지점에 위치한 촬영 객체가 작 게 보이는 등 원근의 영향을 받으므로 거리 정보 파악 시 촬영 객체의 원근으로 인한 거리 차이로 인해 정확하 게 촬영 객체 즉, 작업자의 위치를 측정할 수 없다는 문제점이 있다. 한편, 특정 영역에서 촬영 객체의 위치 측정 및 동선 트래킹을 수행하기 위해 단일의 카메라로 특정 영역을 촬 영하고 촬영된 영상 이미지에 카메라 캘리브레이션, 변환행렬 생성, 뷰 변환 및 객체 탐지 등의 작업이 수행될 수 있으나, 이러한 작업만으로는 비교적 넓은 영역에 위치한 촬영 객체의 위치 측정에 활용되기 어렵고 또한 장 애물이 존재하거나(예를 들어, 차량 공장에서의 작업 시 차량 자체가 촬영 영역을 방해하는 장애물이 될 수 있 음) 촬영되는 특정 영역이 복잡한 구조인 경우에는 정확한 위치 측정 및 동선 트래킹이 수행될 수 없다는 한계 점이 존재한다. 그러므로, 이러한 문제점을 해결하기 위해서, 뎁스 카메라를 통해 촬영한 거리 정보를 포함하는 뎁스 이미지를 CCTV 등 RGB 기반의 카메라가 촬영한 영상 이미지와 매핑시킴으로써 촬영 객체의 거리 정보를 용이하게 획득 가 능하도록 하고, 획득한 거리 정보를 학습시키고 인공지능 알고리즘을 생성함으로써 이후 CCTV 등 RGB 기반의 카 메라가 촬영한 영상 이미지만으로 촬영 객체의 거리 정보를 신속하고 용이하게 파악할 수 있도록 하며, 동일한 영역을 촬영하는 적어도 하나 이상의 CCTV 및 뎁스 카메라를 활용하여 보다 정밀하게 촬영 객체의 위치를 측정 하고 동선을 트래킹할 수 있도록 하는 작업자 위치 측정 방법 및 그 장치와 시스템에 대한 필요가 점차 증가하 고 있는 상황이다."}
{"patent_id": "10-2021-0144301", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기의 문제점을 해결하기 위해서 안출된 것으로, 본 발명은 뎁스 카메라를 통해 촬영한 거리 정보를 포함하는 뎁스 이미지를 CCTV 등 RGB 기반의 카메라가 촬영한 영상 이미지와 매핑시킴으로써 촬영 객체의 거리 정보를 용이하게 획득할 수 있는 작업자 위치 측정 방법 및 그 장치와 시스템을 제공하는 것을 목적으로 한다. 또한, 본 발명은 매핑 작업을 통해 획득한 거리 정보를 인공지능을 통해 학습시키고 인공지능 알고리즘을 생성 함으로써 이후 CCTV 등 RGB 기반의 카메라가 촬영한 영상 이미지만으로도 촬영 객체의 거리 정보를 신속하고 용 이하게 파악할 수 있도록 하는 작업자 위치 측정 방법 및 그 장치와 시스템을 제공하는 것을 목적으로 한다. 또한, 본 발명은 적어도 하나 이상의 CCTV 및 뎁스 카메라가 촬영하는 영상 이미지의 공통 영역을 계산함으로써 보다 정밀하게 촬영 객체의 위치를 측정하고 동선을 트래킹할 수 있는 작업자 위치 측정 방법 및 그 장치와 시 스템을 제공하는 것을 목적으로 한다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재들로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0144301", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기의 기술적 과제를 해결하기 위한 본 발명의 일 실시예에 따른 작업자 위치 측정 장치는, CCTV 및 뎁스 카메 라가 촬영한 영상 이미지의 거리 정보를 분석하도록 구성되는 거리정보분석부; 상기 분석된 거리 정보를 학습하 여 상기 CCTV가 촬영한 영상 이미지에서 촬영 객체의 거리를 구하는 인공지능 알고리즘을 생성하도록 구성되는 AI 학습부; 및 상기 생성된 인공지능 알고리즘을 기반으로 상기 촬영 객체의 위치를 측정하고 상기 촬영 객체의 동선을 트래킹하도록 구성되는 객체트래킹부를 포함할 수 있다. 또한, 적어도 하나의 상기 CCTV 및 상기 뎁스 카메라가 촬영한 영상 이미지의 좌표 정보를 분석하도록 구성되는 좌표정보분석부를 더 포함할 수 있다.또한, 상기 거리정보분석부는, 상기 CCTV가 촬영한 영상 이미지에서 상기 촬영 객체를 탐지하도록 구성되는 객 체탐지 유닛; 및 상기 탐지된 촬영 객체의 영역을 추출하도록 구성되는 영역추출 유닛을 포함할 수 있다. 또한, 상기 거리정보분석부는, 상기 추출된 촬영 객체의 영역과 상기 뎁스 카메라가 촬영한 영상 이미지를 매핑 시키도록 구성되는 이미지매핑 유닛을 더 포함할 수 있다. 상기의 기술적 과제를 해결하기 위한 본 발명의 일 실시예에 따른 작업자 위치 측정 시스템은, 상기 작업자 위 치 측정 장치; 상기 작업자 위치 측정 장치와 통신 가능하게 결합되는 CCTV; 및 상기 작업자 위치 측정 장치와 통신 가능하게 결합되는 뎁스 카메라를 포함할 수 있다. 상기의 기술적 과제를 해결하기 위한 본 발명의 일 실시예에 따른 작업자 위치 측정 방법은, CCTV 및 뎁스 카메 라가 촬영한 영상 이미지의 거리 정보를 분석하는 단계; 상기 분석된 거리 정보를 학습하여 상기 CCTV가 촬영한 영상 이미지에서 촬영 객체의 거리를 구하는 인공지능 알고리즘을 생성하는 단계; 및 상기 생성된 인공지능 알 고리즘을 기반으로 상기 촬영 객체의 위치를 측정하고 상기 촬영 객체의 동선을 트래킹하는 단계를 포함할 수 있다. 또한, 적어도 하나의 상기 CCTV 및 상기 뎁스 카메라가 촬영한 영상 이미지의 좌표 정보를 분석하는 단계를 더 포함할 수 있다. 또한, 상기 CCTV 및 뎁스 카메라가 촬영한 영상 이미지의 거리 정보를 분석하는 단계는, 상기 CCTV가 촬영한 영 상 이미지에서 상기 촬영 객체를 탐지하는 단계; 및 상기 탐지된 촬영 객체의 영역을 추출하는 단계를 포함할 수 있다. 또한, 상기 CCTV 및 뎁스 카메라가 촬영한 영상 이미지의 거리 정보를 분석하는 단계는, 상기 추출된 촬영 객체 의 영역과 상기 뎁스 카메라가 촬영한 영상 이미지를 매핑시키는 단계를 더 포함할 수 있다. 상기의 기술적 과제를 해결하기 위한 본 발명의 일 실시예에 따른 컴퓨터 판독 가능한 기록 매체는, 상기 작업 자 위치 측정 방법의 각 단계들을 수행하기 위한 컴퓨터 프로그램이 기록될 수 있다."}
{"patent_id": "10-2021-0144301", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 작업자 위치 측정 방법 및 그 장치와 시스템에 의하면, 뎁스 카메라를 통해 촬영한 거리 정보를 포함하는 뎁스 이미지를 CCTV 등 RGB 기반의 카메라가 촬영한 영상 이미지와 매핑시킴으로써 촬영 객체의 거리 정보를 용이하게 획득할 수 있다. 또한, 본 발명의 일 실시예에 따른 작업자 위치 측정 방법 및 그 장치와 시스템에 의하면, 매핑 작업을 통해 획 득한 거리 정보를 인공지능을 통해 학습시키고 인공지능 알고리즘을 생성함으로써 이후 CCTV 등 RGB 기반의 카 메라가 촬영한 영상 이미지만으로도 촬영 객체의 거리 정보를 신속하고 용이하게 파악할 수 있다. 또한, 본 발명의 일 실시예에 따른 작업자 위치 측정 방법 및 그 장치와 시스템에 의하면, 적어도 하나 이상의 CCTV 및 뎁스 카메라가 촬영하는 영상 이미지의 공통 영역을 계산함으로써 보다 정밀하게 촬영 객체의 위치를 측정하고 동선을 트래킹할 수 있다."}
{"patent_id": "10-2021-0144301", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명에 따른 실시예들은 첨부된 도면들을 참조하여 설명한다. 각 도면의 구성요소들에 참조 부호를 부 가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면 상에 표시되더라도 가능한 한 동일한 부호를 가 지도록 하고 있음에 유의해야 한다. 또한, 본 발명의 실시예를 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 실시예에 대한 이해를 방해한다고 판단되는 경우에는 그 상세한 설명은 생략한 다. 또한, 이하에서 본 발명의 실시예들을 설명할 것이나, 본 발명의 기술적 사상은 이에 한정되거나 제한되지 않고 당업자에 의해 변형되어 다양하게 실시될 수 있다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"간접적으로 연결\"되어 있는 경우도 포함한다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외 하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 본 발명의 실시예의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질이나 차례 또는 순서 등이 한 정되지 않는다. 도 1은 본 발명의 일 실시예에 따른 작업자 위치 측정 시스템을 설명하기 위한 개략적인 블록도이다. 도 1에 도시되는 바와 같이, 본 발명의 일 실시예에 따른 작업자 위치 측정 시스템은 작업자 위치 측정 장치 , CCTV, 뎁스 카메라(300, depth camera) 등을 포함할 수 있다. 본 발명의 일 실시예에 따른 CCTV는 특정 영역을 촬영하도록 구성될 수 있다. 보다 구체적으로, 본 발명의 일 실시예에 따른 CCTV는 작업자(즉, 촬영 객체)가 작업하는 작업 현장의 적어도 일부 영역을 촬영하도록 구성될 수 있다. 예를 들어, 본 발명의 일 실시예에 따른 CCTV는 자동차 생산(또는 조립) 라인에서 자동차 를 생산(또는 조립)하는 작업자의 작업 영역을 촬영하도록 구성될 수 있고, CCTV는 작업 영역의 상단 코너 에 적어도 하나에 배치될 수 있다. 또한, 예시적으로, CCTV에 의해 촬영되는 작업 영역은 4m x 8m의 넓이 영역을 가질 수 있으나, 이러한 수치의 영역에 한정되는 것은 아니다. 또한, 본 발명의 일 실시예에 따른 CCTV는 작업자 위치 측정 장치와 통신 가능하게 결합되어, 촬영한 영상 이미지를 작업자 위치 측정 장치로 송신하도록 구성될 수 있다. 본 발명의 일 실시예에 따른 작업자 위치 측정 장치는 CCTV로부터 수신한 영상 이미지의 거리 정보를 분석하고, 분석한 거리 정보를 기초 로 촬영 객체의 위치 측정 및 동선 트래킹을 수행하도록 구성될 수 있다. 또한, 본 발명의 일 실시예에 따른 CCTV는 적어도 하나 이상으로 구성될 수 있고, 작업자의 작업 영역 주 변부 임의 영역에 설치되어 작업자의 작업 영역을 촬영하도록 구성될 수 있다. 본 발명의 일 실시예에 따른 작 업자 위치 측정 장치는 적어도 하나 이상(예를 들어, 4개 등)의 CCTV가 촬영한 영상 이미지를 종합하 여 촬영 객체의 위치 측정 및 동선 트래킹을 수행하도록 구성될 수 있다. 또한, 본 발명의 일 실시예에 따른 CCTV는 RGB 기반의 카메라를 포함할 수 있고, 촬영한 RGB 형식의 영상 이미지를 작업자 위치 측정 장치로 송신하도록 구성될 수 있다. RGB 기반의 카메라로 구성된 CCTV가 촬영한 영상 이미지는 이미지 형식의 데이터로서 색상, 명도 등에 관한 정보가 표현되어 있을 뿐 객관적인 거리 정보를 포함하지 않으므로, 본 발명의 일 실시예에 따른 작업자 위치 측정 장치는 RGB 기반의 CCTV로 부터 수신한 영상 이미지와 뎁스 카메라로부터 수신한 뎁스 이미지를 매핑하여 영상 이미지에 거리 정보를매핑하도록 구성될 수 있다. 본 발명의 추가 실시예에 따르면, 적어도 하나 이상으로 구성된 CCTV는 한 세트를 구성할 수 있고, 한 세 트로 구성된 CCTV는 각 세트별로 일 작업 영역을 촬영하도록 구성될 수 있다. 또한, 본 발명의 추가 실시 예에 따른 CCTV는 각각 고유 ID를 포함할 수 있고, 고유 ID에는 해당 CCTV가 설치된 위치 정보가 추 가로 반영될 수 있으며, 따라서 작업자 위치 측정 장치는 CCTV로부터 영상 이미지를 수신하면 해당 영상 이미지가 어느 작업 영역을 촬영하는 CCTV인지 판단할 수 있다. 본 발명의 일 실시예에 따르면, 뎁스 카메라는 특정 영역을 촬영하고 촬영된 영역의 거리 정보를 포함하는 뎁스 이미지를 생성하도록 구성될 수 있다. 참고로, 뎁스 카메라는 촬영되는 대상 즉, 촬영 객체와의 거리 를 인식하고 측정하도록 구성될 수 있고, 거리 별로 상이한 색상으로 표현되는 뎁스 이미지를 생성하도록 구성 될 수 있다. 본 발명의 일 실시예에 따른 뎁스 카메라는 특정 영역을 촬영하여 생성한 뎁스 이미지를 작업 자 위치 측정 장치로 송신하도록 구성될 수 있다. 또한, 본 발명의 일 실시예에 따른 뎁스 카메라는, CCTV와 마찬가지로, 작업자(즉, 촬영 객체)가 작 업하는 작업 현장의 적어도 일부 영역을 촬영하도록 구성될 수 있고, 본 발명의 일 실시예에 따른 CCTV와 인접하게 배치되어 인접한 CCTV와 동일한 작업 영역을 촬영하도록 구성될 수 있다. 또한, 본 발명의 일 실시예에 따른 뎁스 카메라는 작업자 위치 측정 장치와 통신 가능하게 결합되어, 촬영하여 생성한 뎁스 이미지를 작업자 위치 측정 장치로 송신하도록 구성될 수 있다. 또한, 본 발명의 일 실시예에 따른 뎁스 카메라는 적어도 하나 이상으로 구성될 수 있고, 작업자의 작업 영역 주변부 임의 영 역에 설치된 CCTV와 인접하게 배치될 수 있으며, 인접한 CCTV와 한 세트를 이루어 동일한 작업 영역 을 촬영하도록 구성될 수 있다. 본 발명의 일 실시예에 따른 CCTV 및 뎁스 카메라가 복수 개로 구비되어 동일한 작업 영역을 중복하 여 촬영함으로써 단일의 360도로 회전하는 카메라를 통해 촬영 객체의 위치를 측정하는 것에 비해 보다 정밀하 고 정확하게 촬영 객체의 위치를 측정할 수 있다. 본 발명의 일 실시예에 따르면, 작업자 위치 측정 장치는 CCTV 및 뎁스 카메라로부터 수신한 영 상 이미지의 거리 정보를 분석하고, 분석된 거리 정보를 학습하여 CCTV가 촬영한 영상 이미지에서 촬영 객 체의 거리를 구할 수 있는 인공지능 알고리즘을 생성할 수 있으며, 생성된 인공지능 알고리즘을 기반으로 촬영 객체의 위치를 측정하고 촬영 객체의 동선을 트래킹하도록 구성될 수 있다. 또한, 도 1에 도시되는 바와 같이, 작업자 위치 측정 장치는 제어부, 거리정보분석부, 좌표정보분석부, AI 학습부, 객체 트래킹부, 통신부, 저장부 등으로 구성될 수 있다. 참고로, 도 1에 도시되는 작업자 위치 측정 장치의 구성요소들(110, 120, 130, 140, 150, 160, 170)은 본 발명의 일 실시예에 따른 작업자 위치 측정 장치의 동작, 기능 등을 설명하기 위한 예시적인 구성요소들에 불과하다. 즉, 본 발명의 일 실시예에 따른 작업자 위치 측정 장치가 도시된 구성요소들(110, 120, 130, 140, 150, 160, 170) 이외의 다른 구성요소(예를 들어, 전원부, 모니터링부 등)를 추가로 포함할 수 있음은 명 백하다. 또한, 본 발명의 일 실시예에 따른 작업자 위치 측정 장치는 개인 또는 사설 기업에 의해 제작되어 운영되"}
{"patent_id": "10-2021-0144301", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 자체 컴퓨터 프로그램 기반의 장치에 해당하며, 관련 기술분야에서의 다양한 표현 방식에 따라 디바이스 (device), 장비(equipment), 서버(server), 플랫폼(platform) 등의 용어로 지칭될 수도 있다. 본 발명의 일 실시예에 따르면, 작업자 위치 측정 장치는 작업자 위치 측정 장치의 세부적인 구성요 소들(120, 130, 140, 150, 160, 170)의 작동을 제어하도록 구성되는 제어부를 포함할 수 있다. 참고로, 제어부는 프로세서(processor), 마이크로프로세서(micro-processor), 컨트롤러(controller), 마이크로컨 트롤러(micro-controller) 등으로 구현될 수 있다. 즉, 제어부는 응용 프로그램의 구동을 위하여 작업자 위치 측정 장치에 포함된 구성요소들, 특히 거리정보분석부 및 좌표정보분석부에 포함된 구성요 소들 중 적어도 둘 이상을 서로 조합하여 작동시킬 수 있다. 본 발명의 일 실시예에 따르면, 작업자 위치 측정 장치는 CCTV 및 뎁스 카메라가 촬영한 영상 이미지의 거리 정보를 분석하도록 구성되는 거리정보분석부를 포함할 수 있다. 도 2에 도시되는 바와 같이, 본 발명의 일 실시예에 따른 거리정보분석부는 객체탐지 유닛, 영역추출 유닛, 이미지매 핑 유닛, 라벨링 유닛 등으로 보다 세부적으로 구성될 수 있다.먼저, 본 발명의 일 실시예에 따른 거리정보분석부의 객체탐지 유닛은 CCTV가 촬영한 영상 이미 지에서 촬영 객체(예를 들어, 작업자 등)를 탐지하도록 구성될 수 있다. 보다 구체적으로, 본 발명의 일 실시예 에 따른 객체탐지 유닛은 통신부를 통해 CCTV로부터 수신한 작업 영역의 영상 이미지에서 인공 지능 딥 러닝 알고리즘을 통해 촬영 객체를 탐지하도록 구성될 수 있다. 예시적으로, 본 발명의 일 실시예에 따른 객체탐지 유닛이 촬영 객체를 탐지하기 위해 활용하는 딥 러닝 알고리즘은 2차 네트워크(R-CNN 계열) 객체 탐지 모델로서, 객체탐지 유닛은 이러한 객체 탐지 모델을 활 용하여 CCTV로부터 수신한 영상 이미지에 나타나는 작업자를 촬영 객체로서 탐지할 수 있다. 또한, 본 발명의 일 실시예에 따른 객체탐지 유닛이 촬영 객체를 탐지하기 위해 활용하는 딥 러닝 알고리 즘은 합성곱 신경망 즉, CNN(Convolution Neural Network) 알고리즘을 포함할 수 있다. 즉, CNN 알고리즘을 활 용하는 객체탐지 유닛은 CCTV가 촬영한 영상 이미지를 컨볼루션으로 변환하여 풀링 레이어(Pooling layer)에 넣는 과정을 복수 회 반복함으로써 영상에 표시되는 작업자를 촬영 객체로서 예측하여 탐지할 수 있다. 본 발명의 일 실시예에 따른 객체탐지 유닛이 작업자를 촬영 객체로서 탐지하기 위한 딥 러닝 알고리즘에 활용되는 빅데이터 기반을 마련하기 위해, 예시적으로 작업 영역 내에 위치한 작업자의 행동을 CCTV로 촬 영할 수 있고, 예를 들어, 서있기, 팔 올리기, 앉기, 상반신 좌우회전하기, 제자리 걷기 등 작업자의 작업 영역 에서의 작업 행동 시나리오에 따른 행동을 촬영하여 딥 러닝 알고리즘을 위한 빅데이터를 구축할 수 있다. 본 발명의 일 실시예에 따르면, 거리정보분석부의 영역추출 유닛은 객체탐지 유닛에 의해 탐지 된 촬영 객체의 영역을 추출하도록 구성될 수 있다. 보다 구체적으로, 본 발명의 일 실시예에 따른 영역추출 유 닛은 객체탐지 유닛에 의해 탐지된 촬영 객체가 위치하는 영역에 바운딩 박스(bounding box)를 생성 할 수 있다. 영역추출 유닛에 의해 생성되는 바운딩 박스는 탐지된 촬영 객체를 둘러싸는 사각형 테두리 형상을 가질 수 있다. 다만, 바운딩 박스는 투명색으로 구성되어 시각적으로 노출되지 않을 수도 있다. 또한, 본 발명의 일 실시예에 따른 영역추출 유닛은 영상 이미지 상에서 객체탐지 유닛에 의해 탐지 된 촬영 객체가 위치하는 영역의 좌표 정보를 추출할 수 있고, 탐지된 촬영 객체의 영상 이미지 상 영역을 영상 이미지의 나머지 영역으로부터 분리하여 추출하도록 구성될 수 있다. 참고로, 본 발명의 추가 실시예에 따른 영역추출 유닛은 탐지된 촬영 객체의 영역의 좌표 정보 추출 시 접 지 영역을 기준으로 하여 좌표 정보를 추출하도록 구성될 수 있다. 예를 들어, 본 발명의 추가 실시예에 따른 영역추출 유닛은 촬영되는 작업 영역 상 작업자를 객체로서 탐지 시 작업자와 지면의 접지 영역을 기준으 로 하여 좌표 정보를 추출하도록 구성될 수 있다. 이에 따라, 촬영 객체의 영역의 좌표 정보를 보다 정밀하게 추출할 수 있어 작업자의 작업 영역 상 위치를 보다 정밀하고 정확하게 측정할 수 있다. 이어서, 본 발명의 일 실시예에 따른 거리정보분석부의 이미지매핑 유닛은 영역추출 유닛에 의 해 추출된 촬영 객체의 영역과 뎁스 카메라가 촬영한 영상 이미지를 매핑시키도록 구성될 수 있다. 참고로, 본 발명의 일 실시예에 따른 뎁스 카메라가 촬영한 영상 이미지는 거리 정보를 포함하는 뎁스 이 미지로서 뎁스 카메라로부터의 거리별로 상이한 색상으로 표현되는 이미지를 포함할 수 있다. 보다 구체적으로, 본 발명의 일 실시예에 따른 이미지매핑 유닛은 영역추출 유닛에 의해 나머지 영역 으로부터 분리되어 추출된 촬영 객체의 영상 이미지 상 영역과 해당 영역의 좌표 정보와 일치하는 좌표 정보를 갖는 뎁스 카메라로부터 수신한 뎁스 이미지 상 영역을 매핑하도록 구성될 수 있다. 즉, 본 발명의 일 실시예에 따른 CCTV와 뎁스 카메라는 동일한 구도 및 각도로 동일한 작업 영역을 촬영할 수 있도록 상호 인접하게 설치될 수 있으므로 CCTV와 뎁스 카메라가 촬영한 영상 이미지는 동 일 또는 극히 유사하게 겹쳐질 수 있다. 따라서, 본 발명의 일 실시예에 따른 이미지매핑 유닛은 영역추출 유닛에 의해 추출된 촬영 객체의 영상 이미지 상 영역의 좌표 정보와 동일한 좌표 정보를 갖는 뎁스 카메 라의 영상 이미지 즉, 뎁스 이미지 상 영역을 겹침으로써 CCTV로 촬영한 영상 이미지의 촬영 객체의 영역과 뎁스 카메라로 촬영한 뎁스 이미지의 촬영 객체의 영역을 매핑할 수 있다. 본 발명의 일 실시예에 따른 이미지매핑 유닛이 CCTV의 영상 이미지의 촬영 객체의 영역과 뎁스 카메 라의 뎁스 이미지의 촬영 객체의 영역을 매핑시킴으로써, CCTV로 촬영한 영상 이미지에 뎁스 이미지 의 거리 정보가 표시될 수 있다. 즉, 객체탐지 및 영역 추출은 정확도 향상을 위해 RGB 기반의 CCTV가 촬 영한 영상 이미지에 수행되고, 객체탐지 및 영역 추출이 완료된 영상 이미지에 동일한 위치의 뎁스 이미지를 매핑함으로써, RGB 형식의 영상 이미지에 촬영 객체의 영역의 거리 정보를 첨부시킬 수 있다. 본 발명의 일 실시예에 따른 거리정보분석부의 라벨링 유닛은 이미지매핑 유닛에 의해 영상 이 미지와 뎁스 이미지가 상호 매핑된 촬영 객체의 영역에 거리 정보를 라벨링하도록 구성될 수 있다. 참고로, 본 발명에서 정의되는 거리 정보는 기본적으로 촬영을 수행하는 CCTV 또는 뎁스 카메라와 촬영 객체 간 의 거리 정보를 나타내는 것이나, 다만 이에 제한되지 않고, 촬영 객체의 작업 영역 상 위치를 나타내는 좌표 정보(예를 들어, 탑 다운 뷰(top down view) 형식으로 표현되는 작업 영역 상의 X축 및 Y축 좌표 정보)까지 포 함하는 개념으로서 활용될 수도 있다. 보다 구체적으로, 본 발명의 일 실시예에 따른 라벨링 유닛은 뎁스 이미지가 매핑된 영상 이미지의 촬영 객체의 영역에 ID를 부여하고, ID가 부여된 촬영 객체의 영역에 거리 정보를 라벨링하도록 구성될 수 있다. 이 에 따라, RGB 형식의 영상 이미지의 적어도 일부 영역에 표시되는 촬영 객체의 영역에 용이하게 거리 정보가 라 벨링될 수 있고, 거리 정보가 라벨링된 촬영 객체의 영역에 관한 데이터는 AI 학습부에 의해 학습되어 CCTV가 촬영한 영상 이미지만으로 촬영 객체의 거리 정보를 구하는 인공지능 알고리즘 생성에 활용될 수 있다. 본 발명의 일 실시예에 따른 거리정보분석부의 세부적인 구성요소들(121, 122, 123, 124)에 의해 영상 이 미지의 거리 정보가 분석되는 구체적인 일 예는 후술할 도 8에서 보다 상세하게 기술하기로 한다. 본 발명의 일 실시예에 따르면, 작업자 위치 측정 장치는 적어도 하나의 CCTV 및 뎁스 카메라가 촬영한 영상 이미지의 좌표 정보를 분석하도록 구성되는 좌표정보분석부를 더 포함할 수 있다. 도 3에 도 시되는 바와 같이, 본 발명의 일 실시예에 따른 좌표정보분석부는 카메라 캘리브레이션 유닛, 이미지 형태변환 유닛, 공통영역계산 유닛, 객체영역추정 유닛 등으로 보다 세부적으로 구성될 수 있다. 참고로, 본 발명의 일 실시예에 따른 좌표정보분석부에 의해 분석되는 좌표 정보는 촬영 객체의 촬영되는 작업 영역 상 위치를 나타내는 좌표 정보(예를 들어, 탑 다운 뷰 형식으로 표현되는 작업 영역 상의 X축 및 Y축 좌표 정보)를 의미할 수 있다. 먼저, 본 발명의 일 실시예에 따른 좌표정보분석부의 카메라 캘리브레이션 유닛은 CCTV의 카메 라 캘리브레이션(camera calibration)을 수행하도록 구성될 수 있다. 참고로, 카메라 캘리브레이션은 CCTV(20 0)와 같은 카메라가 3차원 공간 상의 점들을 2차원 이미지 평면에 투사할 때 발생하는 왜곡을 교정하는 것을 의 미할 수 있으며, 수식적으로 3D 공간좌표와 2D 영상좌표 사이의 변환관계 또는 이러한 변환관계를 설명하는 파 라미터를 찾는 과정을 의미할 수 있다. 예를 들어, 본 발명의 일 실시예에 따른 카메라 캘리브레이션 유닛은 핀홀 카메라(pinhole camera)로 구성 되는 CCTV가 촬영하는 영상 이미지의 방사형 왜곡 및 접선 왜곡을 교정할 수 있는 오픈CV 알고리즘 코드 함수를 이용하여 카메라 캘리브레이션을 수행하도록 구성될 수 있다. 참고로, 본 발명의 일 실시예에 따른 카메라 캘리브레이션 유닛에 의해 카메라 캘리브레이션이 수행될 시 거리정보분석부의 객체탐지 유닛에 의해서 또는 좌표정보분석부의 별도의 유닛에 의해서 영상 이미지의 촬영 객체가 탐지될 수도 있다. 따라서 후술할 이미지형태변환 유닛에 의한 탑 다운 뷰 형식으로 이미지 형태 변환 시 탐지된 촬영 객체도 탑 다운 뷰 형식으로 표현되는 작업 영역 상의 절대적인 X축 및 Y축 좌표에 위치할 수 있다. 이어서, 본 발명의 일 실시예에 따른 좌표정보분석부의 이미지형태변환 유닛은 카메라 캘리브레이션 유닛에 의해 카메라 캘리브레이션이 수행된 이미지를 탑 다운 뷰 형태로 변환시키도록 구성될 수 있다. 보 다 구체적으로, 본 발명의 일 실시예에 따른 이미지형태변환 유닛은 역 관점 매핑(IPM, Inverse Perspective Mapping)을 수행할 수 있는 변환 행렬이 포함된 오픈CV를 통해 CCTV로 촬영된 영상 이미지를 탑 다운 뷰 이미지로 변환시키도록 구성될 수 있다. 본 발명의 일 실시예에 따른 카메라 캘리브레이션 유닛 및 이미지형태변환 유닛에 의해 CCTV가 촬영한 영상 이미지의 카메라 캘리브레이션 및 탑 다운 뷰 형태 변환이 수행됨으로써, CCTV가 촬영한 영상 이미지의 원근 효과 등으로 인한 왜곡이 보정될 수 있고, CCTV가 촬영한 영상 이미지의 탑 다운 뷰 형식으 로 표현되는 작업 영역 상의 절대적인 X축 및 Y축 좌표 정보가 정확하게 산출될 수 있다. 본 발명의 일 실시예에 따른 좌표정보분석부의 공통영역계산 유닛은 CCTV가 복수 개로 구비되어 각 CCTV가 동일한 작업 영역을 서로 다른 각도 및 위치에서 촬영하는 경우 복수 개로 구비되는 각 CCTV의 출력 데이터를 하나의 가상공간 데이터로 취합하여 공통된 작업 영역을 추정(또는 계산)하도록 구 성될 수 있다. 보다 구체적으로, 본 발명의 일 실시예에 따른 공통영역계산 유닛은 CCTV가 복수 개로 구비되어 각 CCTV가 동일한 작업 영역을 서로 다른 각도 및 위치에서 촬영하는 경우 카메라 캘리브레이션 및 이미지 형 태 변환이 수행되어 작업 영역 상 절대적인 X축 및 Y축 좌표 정보를 포함한 탑 다운 형태의 영상 이미지의 좌표 정보를 일치시킴으로써 각 CCTV가 촬영한 공통된 작업 영역을 추정(또는 계산)하도록 구성될 수 있다. 또한, 본 발명의 일 실시예에 따른 공통영역계산 유닛은 추정(또는 계산)된 공통된 작업 영역을 가상공간 상에 이미지화하도록 구성될 수 있다. 보다 구체적으로, 본 발명의 일 실시예에 따른 공통영역계산 유닛은 추정(또는 계산)된 공통된 작업 영역을 좌표 정보가 표시된 탑 다운 뷰 형태의 가상공간 상 이미지로 구현함과 동시에 복수 개의 CCTV 각각의 촬영 지점도 함께 탑 다운 뷰 형태의 이미지로 구현된 가상공간 상 이미지 에 표시하도록 구성될 수 있다. 본 발명의 일 실시예에 따른 CCTV가 단일로 구성되어 작업 영역을 촬영하는 경우 본 발명의 일 실시예에 따른 공통영역계산 유닛은, 복수 개의 CCTV의 출력 데이터를 하나의 가상공간 데이터로 취합하는 과 정 없이, 촬영된 작업 영역을 좌표 정보가 표시된 탑 다운 뷰 형태의 가상공간 상 이미지로 구현함과 동시에 단 일의 CCTV의 촬영 지점도 함께 탑 다운 뷰 형태의 이미지로 구현된 가상공간 상 이미지에 표시하도록 구성 될 수 있다. 본 발명의 일 실시예에 따른 객체영역추정 유닛은 거리정보분석부의 객체탐지 유닛 또는 좌표정 보분석부의 별도의 유닛에 의해서 탐지된 영상 이미지의 촬영 객체의 영역을 추출하고, 추출한 촬영 객체 의 영역을 가상공간 상 이미지로 구현된 절대적인 X축 및 Y축 좌표 정보를 포함한 탑 다운 형태의 영상 이미지 의 좌표 상에 표시함으로써 2D 상 촬영 객체의 영역을 추정하도록 구성될 수 있다. 예시적으로, 이미지형태변환 유닛에 의해 탑 다운 뷰 형식으로 변환된 이미지에 포함된 좌표 정보는 0.2m 단위로 분할될 수 있고, 이에 따라 작업 영역에서의 촬영 객체의 위치 측정도 0.2m 단위로 정밀하게 측정될 수 있다. 본 발명의 추가 실시예에 따른 객체영역추정 유닛은 탐지된 촬영 객체의 영역의 좌표 정보 추출 시 접지 영역을 기준으로 하여 좌표 정보를 추출하도록 구성될 수 있다. 예를 들어, 본 발명의 추가 실시예에 따른 객체 영역추정 유닛은 촬영되는 작업 영역 상 작업자를 객체로서 탐지 시 작업자와 지면의 접지 영역을 기준으 로 하여 가상공간 상 이미지로 구현된 절대적인 X축 및 Y축 좌표 정보를 포함한 탑 다운 형태의 영상 이미지의 2D 상 좌표 정보를 추출하도록 구성될 수 있다. 이에 따라, 촬영 객체의 영역의 좌표 정보를 보다 정밀하게 추 출할 수 있어 작업자의 작업 영역 상 위치를 보다 정밀하고 정확하게 측정할 수 있다. 또한, 본 발명의 일 실시예에 따른 객체영역추정 유닛은 추정된 2D 상 촬영 객체의 영역에 ID를 부여하고, ID가 부여된 촬영 객체의 영역을 촬영 영상 이미지의 시간의 흐름에 따른 트래킹 대상으로 설정하도록 구성될 수도 있다. 이에 따라, 촬영 영상 이미지의 시간의 흐름에 따라 변화하는 작업 영역 상 촬영 객체의 영역의 2D 상 X축 및 Y축 좌표 정보는 촬영 영상 이미지의 시간의 흐름 따라 변화하는 촬영 객체의 영역을 반영할 수 있다. 본 발명의 일 실시예에 따른 좌표정보분석부가 구비됨에 따라 본 발명의 일 실시예에 따른 작업자 위치 측 정 장치는 CCTV 및 뎁스 카메라로 촬영되는 작업 영역 상 촬영 객체의 영역의 절대적인 좌표 상 위치가 보다 정밀하고 정확하게 측정될 수 있다. 본 발명의 일 실시예에 따르면, 작업자 위치 측정 장치는 거리정보분석부에 의해 분석된 거리 정보를 학습하여 CCTV가 촬영한 영상 이미지에서 촬영 객체의 거리를 구하는 인공지능 알고리즘을 생성하도록 구 성되는 AI 학습부를 포함할 수 있다. 또한, 본 발명의 일 실시예에 따른 AI 학습부는 거리정보분석부에 의해 분석된 거리 정보 및/또는 좌 표정보분석부에 의해 분석된 좌표 정보를 학습하여 CCTV가 촬영한 영상 이미지에서 촬영 객체의 거리 를 구하는 인공지능 알고리즘을 생성하도록 구성될 수도 있다. 보다 구체적으로, 본 발명의 일 실시예에 따른 AI 학습부는 AI 분석 즉, 거리정보분석부 및/또는 좌 표정보분석부에 의해 분석된 영상 이미지의 거리 정보 및/또는 좌표 정보를 포함하는 영상 이미지 데이터 를 데이터 세트로서 확보하고, 확보된 데이터 세트를 CCTV가 촬영한 영상 이미지에서 촬영 객체의 거리를 구하는 인공지능 알고리즘 트레이닝 및 예외 케이스 트레이닝을 수행하며, 인공지능 알고리즘의 신경망을 조정하도록 구성될 수 있다. 또한, 본 발명의 일 실시예에 따른 AI 학습부는 트레이닝이 수행된 인공지능 알고리즘의 정확도를 테스트 하고 객체 인식률 및 객체 오인식률을 개선하도록 구성될 수 있으며, 생성된 인공지능 알고리즘을 위한 인공지 능 엔진 연동 모듈, 트랜잭션(transaction) 모듈 및 Rest API를 개발하도록 구성될 수도 있다. 또한, 도 10에 도시되는 바와 같이, 본 발명의 일 실시예에 따른 AI 학습부는 AI 분석을 위한 제1 AI 학습 부(140-a) 및 AI 분석이 완료된 데이터의 후처리를 위한 제2 AI 학습부(140-b)로 이원화되어 구성될 수 있다. 보다 구체적으로, 본 발명의 일 실시예에 따른 AI 학습부는 이원화되어 AI 분석을 위한 제1 AI 학습부 (140-a) 및 AI 분석이 완료된 데이터의 후처리를 위한 제2 AI 학습부(140-b)로 구성될 수 있고, CCTV가 촬 영하는 4K 영상 이미지의 처리를 위하여 제1 AI 학습부(140-a)는 AI 분석을 전적으로 수행하는 서버로 구성될 수 있고, 제2 AI 학습부(140-b)는 AI 분석이 완료된 영상 이미지 데이터를 위한 Rest API 및 영상 이미지 후처 리(시각화) 작업 수행을 위한 서버로 구성될 수 있다. 본 발명의 추가 실시예에 따른 AI 학습부는 객체 탐지 데이터 확보를 위한 작업자 행동 데이터를 작업자의 실시간 행동을 판단하는 인공지능 알고리즘 생성을 위한 데이터 세트로 활용할 수 있고, 이에 따라 촬영되는 작 업자의 위치 및 동선뿐만 아니라 실시간으로 작업자의 행동을 판단할 수도 있다. 다시 도 1로 돌아와서, 본 발명의 일 실시예에 따른 작업자 위치 측정 장치는 AI 학습부에 의해 생성 된 인공지능 알고리즘을 기반으로 작업 영역 상 촬영 객체의 위치를 측정하고 촬영 객체의 동선을 트래킹하도록 구성되는 객체트래킹부를 포함할 수 있다. 보다 구체적으로, 본 발명의 일 실시예에 따른 객체트래킹부 는 AI 학습부에 의해 생성된 인공지능 알고리즘을 기반으로 CCTV로부터 수신한 영상 이미지에서 별도의 학습이나 연산 없이 작업자와 같은 촬영 객체의 위치 정보(즉, 절대적인 X축 및 Y축 좌표 정보) 및 거리 정보를 판단하고, 촬영 객체의 동선을 트래킹하도록 구성될 수 있다. 본 발명의 일 실시예에 따르면, 작업자 위치 측정 장치는 CCTV 및/또는 뎁스 카메라와 통신하도 록 구성되는 통신부를 포함할 수 있다. 예를 들어, 통신부를 통해 작업자 위치 측정 장치는 CCTV 및 뎁스 카메라로부터 영상 이미지 및 뎁스 이미지를 수신할 수 있다. 참고로, 통신부는 외부와의 직접 연결 또는 네트워크를 통한 연결을 위해 제공되는 것으로서, 유선 및/또 는 무선 통신부일 수 있다. 구체적으로, 통신부는 제어부, 거리정보분석부, 좌표정보분석 부, AI 학습부, 객체트래킹부 등으로부터의 데이터를 유선 또는 무선으로 전송하거나, 외부로부 터 데이터를 유선 또는 무선 수신하여 제어부, 거리정보분석부, 좌표정보분석부, AI 학습부 또는 객체트래킹부로 전달하거나 저장부에 저장할 수 있다. 상기 데이터에는 텍스트, 이미지, 동화상 등의 컨텐츠 등이 포함될 수 있다. 통신부는 랜(LAN), WCDMA(Wideband Code Division Multiple Access), LTE(Long Term Evolution), WiBro(Wireless Broadband Internet), RF(Radio Frequency)통신, 무선랜(Wireless LAN), 와이파이(Wireless Fidelity), NFC(Near Field Communication), 블루투스, 적외선 통신 등을 통해 통신할 수 있다. 다만, 이는 예"}
{"patent_id": "10-2021-0144301", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "시적인 것으로서, 본 발명이 적용되는 실시예에 따라 당해 기술분야에서 적용 가능한 다양한 유, 무선 통신 기 술이 이용될 수 있다. 또한, 본 발명의 일 실시예에 따른 작업자 위치 측정 장치는 작업자 즉, 촬영 객체의 위치 측정 및 동선 트래킹과 관련된 임의의 데이터 및 정보를 저장하도록 구성되는 저장부를 더 포함할 수 있다. 예를 들어, 저장부에는 객체 탐지에 관한 데이터, 영역 추출에 관한 데이터, 이미지 매핑에 관한 데이터, 라벨링에 관 한데이터, 카메라 캘리브레이션에 관한 데이터, 이미지 형태 변환에 관한 데이터, 공통 영역 추정(또는 계산)에 관한 데이터, 객체 영역 추정에 관한 데이터, AI 학습에 관한 데이터, AI 분석에 관한 데이터, CCTV가 촬 영한 영상 이미지에서 촬영 객체의 거리를 구하는 인공지능 알고리즘에 관한 데이터, 촬영 객체의 위치 측정 및 동선 트래킹에 관한 데이터, 데이터 후처리에 관한 데이터, 거리 정보에 관한 데이터, 좌표 정보에 관한 데이터 등이 저장될 수 있다. 참고로, 저장부는 통상의 기술자에게 알려진 바와 같이, HDD(Hard Disk Drive), ROM(Read Only Memory), RAM(Random Access Memory), EEPROM(Electrically Erasable and Programmable Read Only Memory), 플래시 메 모리(flash memory), CF(Compact Flash) 카드, SD(Secure Digital) 카드, SM(Smart Media) 카드, MMC(Multimedia) 카드 또는 메모리 스틱(Memory Stick) 등 정보의 입출력이 가능한 다양한 형태의 저장 장치로 구현될 수 있으며, 도 1에 도시된 바와 같이 작업자 위치 측정 장치의 내부에 구비되거나 별도의 외부 장치에 구비될 수 있다. 또는, 저장부가 인터넷 상에서 저장 기능을 수행하는 웹 스토리지(web storage)로 대체될 수도 있다. 본 발명의 추가 실시예에 따르면, 작업자 위치 측정 시스템은 작업자 즉, 촬영 객체의 위치 및 동선을 실 시간으로 측정하고, 촬영 객체의 행동을 실시간으로 판단하도록 구성될 수 있으며, 측정된 위치 및 동선이 미리 입력된 위험 영역을 침범하거나 또는 촬영 객체의 행동이 미리 입력된 위험 행동에 해당되는 경우 실시간으로 작업자에게 경고를 하도록 구성될 수 있다. 도 4는 본 발명의 일 실시예에 따른 작업자 위치 측정 방법(S10)을 설명하기 위한 순서도이다. 먼저, CCTV 및 뎁스 카메라는 작업 현장의 특정 작업 영역을 촬영하고 영상 이미지 및 뎁스 이미지를 작업자 위치 측정 장치로 송신할 수 있다(S100). 다음으로, 작업자 위치 측정 장치의 거리정보분석부는 CCTV 및 뎁스 카메라가 촬영한 영상 이미지의 거리 정보를 분석할 수 있다(S200). 이어서, AI 학습부는 거리정보분석부에 의해 분석된 거리 정보를 학습하여 CCTV가 촬영한 영상 이미지에서 작업 영역에 위치하는 촬영 객체 즉, 작업자와의 거리를 구하는 인공지능 알고리즘을 생성할 수 있 다(S300). 또한, 객체트래킹부는 AI 학습부에 의해 생성된 인공지능 알고리즘을 기반으로 CCTV로부터의 영 상 이미지만을 활용하여 촬영 객체의 위치를 측정하고 촬영 객체의 동선을 트래킹할 수 있다(S400). 본 발명의 일 실시예에 따른 작업자 위치 측정 장치가 분석된 거리 정보를 인공지능을 통해 학습시키고 인 공지능 알고리즘을 생성하고 생성된 인공지능 알고리즘을 기반으로 촬영 객체의 위치를 측정하고 촬영 객체의 동선을 트래킹함으로써 CCTV 등의 RGB 기반의 카메라가 촬영한 영상 이미지만으로도 촬영 객체의 거리 정 보를 신속하고 용이하게 파악할 수 있음은 앞서 기술한 바와 같다. 도 5는 본 발명의 일 실시예에 따른 촬영된 영상 이미지의 거리 정보를 분석하는 방법(S200)을 설명하기 위한 순서도이다. 먼저, 거리정보분석부의 객체탐지 유닛은 CCTV가 촬영한 영상 이미지에서 촬영 객체를 탐지할 수 있고(S210), 이어서 영역추출 유닛은 객체탐지 유닛에 의해 탐지된 촬영 객체의 영역을 추출할 수 있으며(S220), 이미지매핑 유닛은 추출된 촬영 객체의 영역과 뎁스 카메라가 촬영한 영상 이미지 즉, 뎁스 이미지를 매핑시킬 수 있다(S230). 다음으로, 라벨링 유닛은 이미지매핑 유닛에 의해 영상 이미지와 뎁스 이미지가 상호 매핑된 촬영 객 체의 영역에 거리 정보를 라벨링할 수 있다(S240). 이와 같이, 본 발명의 일 실시예에 따른 거리정보분석부 가 뎁스 카메라를 통해 촬영한 거리 정보를 포함하는 뎁스 이미지를 CCTV 등 RGB 기반의 카메라 가 촬영한 영상 이미지와 매핑시켜 영상 이미지에 거리 정보를 라벨링함으로써 CCTV의 영상 이미지에서 촬 영 객체의 거리 정보를 용이하게 획득할 수 있다. 도 6은 본 발명의 일 실시예에 따른 복수 개의 CCTV 및 뎁스 카메라를 활용한 작업자 위치 측정 방법 (S20)을 설명하기 위한 순서도이다. 먼저, 복수 개의 CCTV 및 뎁스 카메라는 작업 현장의 특정 작업 영역을 촬영하고 영상 이미지 및 뎁 스 이미지를 작업자 위치 측정 장치로 송신할 수 있다(S100). 참고로, 뎁스 카메라는 복수 개의 CCTV와 동일한 개수로 구비되어 작업 영역을 각각 CCTV와 동시에 촬영할 수 있거나, 또는 뎁스 카메 라는 단일로 구비되어 복수 개의 CCTV에 대해 순차적으로 작업 영역을 함께 촬영할 수도 있다. 다음으로, 작업자 위치 측정 장치의 거리정보분석부는 복수 개의 CCTV 및 뎁스 카메라가 촬영한 영상 이미지의 거리 정보를 분석할 수 있고(S200-a), 좌표정보분석부는 복수 개의 CCTV 및 뎁 스 카메라가 촬영한 영상 이미지의 좌표 정보를 분석할 수 있다(S200-b). 참고로, 복수 개의 CCTV에 의해 촬영된 촬영 객체의 좌표 정보가 복수 개의 CCTV 각각에 대해 차이를 갖는 경우 복수 개의 CCTV(20 0)에 기초한 좌표 정보를 평균화(averaging)하여 촬영 객체의 좌표 정보가 결정될 수 있고, 본 발명의 추가 실 시예에 따르면 복수 개의 CCTV 중 일부의 CCTV만을 촬영 객체의 위치 측정 및 동선 트래킹에 활용하 도록 본 작업자 위치 측정 시스템이 구현될 수도 있다(예를 들어, 작업자가 자동차의 좌측 도어를 부착하 는 작업을 하고 있어 우측에 배치된 CCTV에 의해서 해당 작업자를 촬영하여 식별하기가 곤란한 경우, 우측에 배치된 CCTV를 객체 위치 측정 및 트래킹에서 배제할 수 있음). 참고로, 작업자 위치 측정 장치에 의한 작업 영역에서의 작업자 위치 측정 및 동선 트래킹은 좌표정보분석 부에 의한 좌표 정보 분석 단계(S200-b)를 포함하지 않고 거리정보분석부에 의한 거리 정보 분석 단 계(S200-a)를 포함하는 작업자 위치 측정 방법(S10, 도 4 참고)만으로도 이루어질 수 있으나, 좌표정보분석부 에 의해 작업자 즉, 촬영 객체의 절대적인 2D 상 좌표 정보를 추가적으로 측정하고 측정된 데이터를 활용 하여 인공지능 알고리즘을 생성함으로써, 보다 정밀하고 정확하게 작업 영역에서 촬영 객체의 위치 측정 및 동 선 트래킹이 수행될 수 있다. 이어서, AI 학습부는 거리정보분석부에 의해 분석된 거리 정보 및 좌표정보분석부에 의해 분석 된 좌표 정보를 학습하여 CCTV가 촬영한 영상 이미지에서 작업 영역에 위치하는 촬영 객체 즉, 작업자와의 거리를 구하는 인공지능 알고리즘을 생성할 수 있다(S300). 또한, 객체트래킹부는 AI 학습부에 의해 생성된 인공지능 알고리즘을 기반으로 촬영 객체의 위치를 측정하고 촬영 객체의 동선을 트래킹할 수 있다 (S400). 도 7은 본 발명의 일 실시예에 따른 촬영된 영상 이미지의 좌표 정보를 분석하는 방법(S200-b)을 설명하기 위한 순서도이다. 먼저, 좌표정보분석부의 카메라 캘리브레이션 유닛은 CCTV의 카메라 캘리브레이션을 수행할 수 있다(S250). 참고로, 카메라 캘리브레이션은 CCTV와 같은 카메라가 3차원 공간 상의 점들을 2차원 이미지 평면에 투사할 때 발생하는 왜곡을 교정하는 것을 의미할 수 있으며, 수식적으로 3D 공간좌표와 2D 영상좌표 사 이의 변환관계 또는 이러한 변환관계를 설명하는 파라미터를 찾는 과정을 의미할 수 있음은 앞서 기술한 바와 같다. 다음으로, 이미지형태변환 유닛은 카메라 캘리브레이션 유닛에 의해 카메라 캘리브레이션이 수행된 이미지를 탑 다운 뷰 형태로 변환시킬 수 있다(S260). 보다 구체적으로, 이미지형태변환 유닛은 역 관점 매핑(IPM)을 수행할 수 있는 변환 행렬이 포함된 오픈CV를 통해 CCTV로 촬영된 영상 이미지를 탑 다운 뷰 이미지로 변환시킬 수 있다. 본 발명의 일 실시예에 따른 카메라 캘리브레이션 유닛 및 이미지형태변환 유닛에 의해 CCTV가 촬영한 영상 이미지의 카메라 캘리브레이션 및 탑 다운 뷰 형태 변환이 수행됨으로써, CCTV가 촬영한 영상 이미지의 원근 효과 등으로 인한 왜곡이 보정될 수 있고, CCTV가 촬영한 영상 이미지의 탑 다운 뷰 형식으 로 표현되는 작업 영역 상의 절대적인 X축 및 Y축 좌표 정보가 정확하게 산출될 수 있다. 이어서, 공통영역계산 유닛은 CCTV가 복수 개로 구비되어 각 CCTV가 동일한 작업 영역을 서로 다른 각도 및 위치에서 촬영하는 경우 복수 개로 구비되는 각 CCTV의 출력 데이터를 하나의 가상공간 데이 터로 취합하여 공통된 작업 영역을 추정(또는 계산)할 수 있다(S270). 만일, CCTV가 단일로 구성되어 작업 영역을 촬영하는 경우 공통영역계산 유닛은, 복수 개의 CCTV의 출력 데이터를 하나의 가상공간 데이 터로 취합하는 과정 없이도, 촬영된 작업 영역을 좌표 정보가 표시된 탑 다운 뷰 형태의 가상공간 상 이미지로 구현함과 동시에 단일의 CCTV의 촬영 지점도 함께 탑 다운 뷰 형태의 이미지로 구현된 가상공간 상 이미지 에 표시할 수 있다. 또한, 객체영역추정 유닛은 거리정보분석부의 객체탐지 유닛 또는 좌표정보분석부의 별도 의 유닛에 의해서 탐지된 영상 이미지의 촬영 객체의 영역을 추출하고, 추출한 촬영 객체의 영역을 가상공간 상 이미지로 구현된 절대적인 X축 및 Y축 좌표 정보를 포함한 탑 다운 형태의 영상 이미지의 좌표 상에 표시함으로 써 2D 상 촬영 객체의 영역을 추정할 수 있다(S280). 도 8은 본 발명의 일 실시예에 따른 촬영된 영상 이미지의 거리 정보를 분석하는 방법을 설명하기 위한 예시도 이다. 도 8의 (a)는 CCTV가 촬영한 RGB 형식의 영상 이미지의 예시적인 이미지를 도시한다. 도시되는 바와 같이, CCTV가 촬영한 영상 이미지는 촬영 객체(좌측에 서있는 사람) 및 배경이 모두 포함된 영상 이미지일 수 있 다. 도 8의 (b)는 뎁스 카메라가 촬영하여 생성한 거리 정보를 포함하는 뎁스 이미지의 예시적인 이미지를 도 시한다. 도시되는 바와 같이, 뎁스 이미지는 뎁스 카메라와의 거리별로 상이한 색상으로 표현될 수 있다. 도 8의 (c)는 객체탐지 유닛에 의해 촬영 객체가 탐지되고 영역추출 유닛에 의해서 탐지된 촬영 객체 의 영역이 나머지 영역으로부터 분리되어 추출된 촬영 객체의 영역 이미지의 예시적인 이미지를 도시한다. 도 8의 (d)는 영역추출 유닛에 의해 추출된 촬영 객체의 영역 이미지가 이미지매핑 유닛에 의해 뎁스 카메라가 촬영하여 생성한 뎁스 이미지와 매핑된 이미지의 예시적인 이미지를 도시한다. 이에 따라, 추출 된 촬영 객체의 영역의 이미지는 뎁스 이미지의 거리 정보를 포함할 수 있다. 도 8의 (e)는 뎁스 이미지와 매핑되어 거리 정보를 포함하는 촬영 객체의 영역 이미지가 라벨링 유닛에 의 해 ID가 부여되고 좌표 정보 및 거리 정보가 라벨링된 이미지의 예시적인 이미지를 도시한다. 도시된 예시적인 이미지에서, 촬영 객체의 영역 이미지에 ID는 human으로, 좌표 정보의 X position은 200으로, 좌표 정보의 Y position은 100으로, 거리 정보(distance)는 3000으로 도시되었다. 도 8의 (f)는 AI 학습부가 분석된 거리 정보를 학습하여 생성한 인공지능 알고리즘을 기반으로 객체트래킹 부가 촬영 객체의 위치를 측정한 이미지의 예시적인 이미지를 도시한다. 도시되는 바와 같이, 별도의 학습 이나 연산 없이 CCTV가 촬영한 영상 이미지만으로 촬영 객체의 거리 정보 및 위치 정보 등이 파악될 수 있 다. 참고로, 도 8의 (f)에는 촬영 영역에 촬영 객체가 단일인 경우를 예시적으로 도시하고 있으나, 본 발명의 일 실시예에 따른 작업자 위치 측정 방법, 장치 및 그 시스템은 촬영 영역에 촬영 객체가 복수인 경우에도 마찬 가지로 적용될 수 있으며, 이때 객체탐지 유닛 및 객체트래킹부는 딥 러닝 기반의 다중 객체 탐지 및 트래킹(multiple object detection and tracking)이 가능하도록 구성될 수도 있다. 도 9는 본 발명의 일 실시예에 따른 촬영된 영상 이미지의 좌표 정보를 분석하는 방법을 설명하기 위한 예시도 이다. 도 9의 (a)는 이미지형태변환 유닛에 의해 탑 다운 뷰 형태로 변환되기 전 영상 이미지의 예시적인 이미지 이고, 도 9의 (b)는 이미지형태변환 유닛에 의해 탑 다운 뷰 형태로 변환된 영상 이미지의 예시적인 이미 지이다. 또한 도 9의 (a)에 도시되는 바와 같이, 거리정보분석부의 객체탐지 유닛에 의해서 또는 좌 표정보분석부의 별도의 유닛에 의해서 영상 이미지의 촬영 객체가 탐지될 수 있고, 도 9의 (b)에 도시되는 바와 같이, 탐지된 촬영 객체도 탑 다운 뷰 형식으로 표현되는 작업 영역 상의 절대적인 X축 및 Y축 좌표에 위 치할 수 있다. 상술한 바와 같이, 본 발명의 일 실시예에 따른 작업자 위치 측정 방법 및 그 장치와 시스템에 의하면, 뎁스 카 메라를 통해 촬영한 거리 정보를 포함하는 뎁스 이미지를 CCTV 등 RGB 기반의 카메라가 촬영한 영상 이미지와 매핑시킴으로써 촬영 객체의 거리 정보를 용이하게 획득할 수 있다. 또한, 본 발명의 일 실시예에 따른 작업자 위치 측정 방법 및 그 장치와 시스템에 의하면, 매핑 작업을 통해 획 득한 거리 정보를 인공지능을 통해 학습시키고 인공지능 알고리즘을 생성함으로써 이후 CCTV 등 RGB 기반의 카 메라가 촬영한 영상 이미지만으로도 촬영 객체의 거리 정보를 신속하고 용이하게 파악할 수 있다. 또한, 본 발명의 일 실시예에 따른 작업자 위치 측정 방법 및 그 장치와 시스템에 의하면, 적어도 하나 이상의 CCTV 및 뎁스 카메라가 촬영하는 영상 이미지의 공통 영역을 계산함으로써 보다 정밀하게 촬영 객체의 위치를 측정하고 동선을 트래킹할 수 있다. 한편, 본 명세서에 기재된 다양한 실시예들은 하드웨어, 미들웨어, 마이크로코드, 소프트웨어 및/또는 이들의 조합에 의해 구현될 수 있다. 예를 들어, 다양한 실시예들은 하나 이상의 주문형 반도체(ASIC)들, 디지털 신호 프로세서(DSP)들, 디지털 신호 프로세싱 디바이스(DSPD)들, 프로그램어블 논리 디바이스(PLD)들, 필드 프로그램 어블 게이트 어레이(FPGA)들, 프로세서들, 컨트롤러들, 마이크로컨트롤러들, 마이크로프로세서들, 여기서 제시 되는 기능들을 수행하도록 설계되는 다른 전자 유닛들 또는 이들의 조합 내에서 구현될 수 있다. 또한, 예를 들어, 다양한 실시예들은 명령들을 포함하는 컴퓨터-판독가능한 매체에 수록되거나 인코딩될 수 있 다. 컴퓨터-판독가능한 매체에 수록 또는 인코딩된 명령들은 프로그램 가능한 프로세서 또는 다른 프로세서로 하여금 예컨대, 명령들이 실행될 때 방법을 수행하게끔 할 수 있다. 컴퓨터-판독가능한 매체는 컴퓨터 저장 매 체를 포함하며, 컴퓨터 저장 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수도 있다. 예를 들어, 이러한 컴퓨터-판독가능한 매체는 RAM, ROM, EEPROM, CD-ROM 또는 기타 광학 디스크 저장 매체, 자기 디 스크 저장 매체 또는 기타 자기 저장 디바이스를 포함할 수 있다.이러한 하드웨어, 소프트웨어, 펌웨어 등은 본 명세서에 기술된 다양한 동작들 및 기능들을 지원하도록 동일한 디바이스 내에서 또는 개별 디바이스들 내에서 구현될 수 있다. 추가적으로, 본 발명에서 \"~부\"로 기재된 구성 요소들, 유닛들, 모듈들, 컴포넌트들 등은 함께 또는 개별적이지만 상호 운용 가능한 로직 디바이스들로서 개별 적으로 구현될 수 있다. 모듈들, 유닛들 등에 대한 서로 다른 특징들의 묘사는 서로 다른 기능적 실시예들을 강 조하기 위해 의도된 것이며, 이들이 개별 하드웨어 또는 소프트웨어 컴포넌트들에 의해 실현되어야만 함을 필수 적으로 의미하지 않는다. 오히려, 하나 이상의 모듈들 또는 유닛들과 관련된 기능은 개별 하드웨어 또는 소프트 웨어 컴포넌트들에 의해 수행되거나 또는 공통의 또는 개별의 하드웨어 또는 소프트웨어 컴포넌트들 내에 통합 될 수 있다. 특정한 순서로 동작들이 도면에 도시되어 있지만, 이러한 동작들이 원하는 결과를 달성하기 위해 도시된 특정한 순서, 또는 순차적인 순서로 수행되거나, 또는 모든 도시된 동작이 수행되어야 할 필요가 있는 것으로 이해되지 말아야 한다. 임의의 환경에서는, 멀티태스킹 및 병렬 프로세싱이 유리할 수 있다. 더욱이, 상술한 실시예에서 다양한 구성요소들의 구분은 모든 실시예에서 이러한 구분을 필요로 하는 것으로 이해되어서는 안되며, 기술된 구성요소들이 일반적으로 단일 소프트웨어 제품으로 함께 통합되거나 다수의 소프트웨어 제품으로 패키징될 수 있다는 것이 이해되어야 한다. 이상에서와 같이 도면과 명세서에서 최적 실시예가 개시되었다. 여기서 특정한 용어들이 사용되었으나, 이는 단 지 본 발명을 설명하기 위한 목적에서 사용된 것이지 의미한정이나 특허청구범위에 기재된 본 발명의 범위를 제 한하기 위하여 사용된 것은 아니다. 그러므로 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이해할 것이다. 따라서 본 발명의 진정한 기술적 보호범위는 첨부된 특 허청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2021-0144301", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 상세한 설명에서 인용되는 도면을 보다 충분히 이해하기 위하여 각 도면의 간단한 설명이 제공된다. 도 1은 본 발명의 일 실시예에 따른 작업자 위치 측정 시스템을 설명하기 위한 개략적인 블록도이다. 도 2는 본 발명의 일 실시예에 따른 거리정보분석부를 설명하기 위한 개략적인 블록도이다. 도 3은 본 발명의 일 실시예에 따른 좌표정보분석부를 설명하기 위한 개략적인 블록도이다. 도 4는 본 발명의 일 실시예에 따른 작업자 위치 측정 방법(S10)을 설명하기 위한 순서도이다. 도 5는 본 발명의 일 실시예에 따른 촬영된 영상 이미지의 거리 정보를 분석하는 방법(S200)을 설명하기 위한 순서도이다. 도 6은 본 발명의 일 실시예에 따른 복수 개의 CCTV 및 뎁스 카메라를 활용한 작업자 위치 측정 방법 (S20)을 설명하기 위한 순서도이다.도 7은 본 발명의 일 실시예에 따른 촬영된 영상 이미지의 좌표 정보를 분석하는 방법(S200-b)을 설명하기 위한 순서도이다. 도 8은 본 발명의 일 실시예에 따른 촬영된 영상 이미지의 거리 정보를 분석하는 방법을 설명하기 위한 예시도 이다. 도 9는 본 발명의 일 실시예에 따른 촬영된 영상 이미지의 좌표 정보를 분석하는 방법을 설명하기 위한 예시도 이다. 도 10은 본 발명의 일 실시예에 따른 AI 학습부가 이원화되어 제1 및 제2 AI 학습부(140-a, 140-b)로 작동 하는 일 예를 설명하기 위한 예시도이다."}
