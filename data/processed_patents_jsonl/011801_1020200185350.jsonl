{"patent_id": "10-2020-0185350", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0084332", "출원번호": "10-2020-0185350", "발명의 명칭": "상호의존정보에 기반한 기계학습 수행 방법 및 장치", "출원인": "한국과학기술원", "발명자": "서창호"}}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "상호의존정보에 기반한 기계학습 방법에 있어서,각각의 데이터 엔트리별로 적어도 제1 정보, 제2 정보, 및 제3 정보를 포함하는 제1 데이터 셋(data set)을 입력받는 단계;분류기(classifier)를 통해 상기 제1 및 제3 정보에 대한 학습을 수행하여 상기 제2 정보에 대한 예측값을 출력하는 단계;구분자(discriminator)를 통해, 상기 제2 정보에 대한 예측값에 대한 학습을 수행하여 상기 제3 정보에 대한 예측값을 출력하는 단계; 및상기 제2 정보에 대한 예측값 및 상기 제3 정보 간의 상호의존정보가 최소화되도록, 상기 제2 정보에 대한 예측값을 출력하는 단계와 상기 제3 정보에 대한 예측값을 출력하는 단계를 반복 수행하는 단계를 포함하는, 기계학습 방법."}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 분류기는 상기 제2 정보에 대한 예측값과 상기 제3 정보 간의 DI(disparate impact) 값을 최대화하는 방향으로 학습을 수행하는 것을 특징으로 하는, 기계학습 방법."}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 분류기는 상기 제2 정보에 대한 예측값과 상기 제3 정보 간의 EO(equalized odds) 값을 최대화하는 방향으로 학습을 수행하는 것을 특징으로 하는, 기계학습 방법."}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 분류기와 상기 구분자는 생성적 적대 신경망(generative adversarial network, GAN) 방식에 따른 경쟁적관계를 가지도록 설정되는 인공 신경망들인 것을 특징으로 하는, 기계학습 방법."}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,상기 제2 정보에 대한 예측값을 출력하는 단계와 상기 제3 정보에 대한 예측값을 출력하는 단계를 반복 수행하는 단계는, 경사하강법에 기초하여 수행되는 것을 특징으로 하는, 기계학습 방법."}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서,상기 제2 정보에 대한 예측값을 출력하는 단계와 상기 제3 정보에 대한 예측값을 출력하는 단계를 반복 수행하는 단계는,상기 제2 정보에 대한 예측값을 출력하는 단계의 수행 횟수와 상기 제3 정보에 대한 예측값을 출력하는 단계의수행 횟수를 1:k (k는 2 이상의 자연수) 비율로 수행하는 것을 특징으로 하는, 기계학습 방법."}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2021-0084332-3-청구항 1에 있어서,상기 분류기 및 상기 구분자는,상기 제2 정보 및 상기 제2 정보에 대한 예측값에 대한 교차 엔트로피 함수로 설정되는 제1 손실함수항, 및 상기 제2 정보 및 상기 제3 정보에 대한 예측값에 대한 교차 엔트로피 함수로 설정되는 제2 손실함수항의 조합으로 정의되는 손실함수에 기초하여 학습을 수행하는 것을 특징으로 하는, 기계학습 방법."}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 1에 있어서,상기 상호의존정보는, 상기 제2 정보에 대한 예측값의 확률변수, 및 상기 제3 정보의 확률 변수에 기초하여 정의되는 것을 특징으로 하는, 기계학습 방법."}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "상호의존정보에 기반한 기계학습 장치에 있어서,프로세서(processor);상기 프로세서와 전자적(electronic)으로 통신하는 메모리(memory); 및상기 메모리에 저장되는 명령들(instructions)을 포함하며,상기 명령들이 상기 프로세서에 의해 실행되는 경우, 상기 명령들은 상기 기계학습 장치가;각각의 데이터 엔트리별로 적어도 제1 정보, 제2 정보, 및 제3 정보를 포함하는 제1 데이터 셋(data set)을 입력받고;분류기(classifier)를 통해 상기 제1 및 제3 정보에 대한 학습을 수행하여 상기 제2 정보에 대한 예측값을 출력하고;구분자(discriminator)를 통해, 상기 제2 정보에 대한 예측값에 대한 학습을 수행하여 상기 제3 정보에 대한 예측값을 출력하고; 그리고상기 제2 정보에 대한 예측값 및 상기 제3 정보 간의 상호의존정보가 최소화되도록, 상기 분류기를 통한 학습과상기 구분자를 통한 학습을 반복 수행하는 것을 야기하도록 동작하는, 기계학습 장치."}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서,상기 분류기는 상기 제2 정보에 대한 예측값과 상기 제3 정보 간의 DI(disparate impact) 값을 최대화하는 방향으로 학습을 수행하는 것을 특징으로 하는, 기계학습 장치."}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 9에 있어서,상기 분류기는 상기 제2 정보에 대한 예측값과 상기 제3 정보 간의 EO(equalized odds) 값을 최대화하는 방향으로 학습을 수행하는 것을 특징으로 하는, 기계학습 장치."}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 9에 있어서,상기 분류기와 상기 구분자는 생성적 적대 신경망(generative adversarial network, GAN) 방식에 따른 경쟁적관계를 가지도록 설정되는 인공 신경망들인 것을 특징으로 하는, 기계학습 장치."}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 9에 있어서,상기 분류기를 통한 학습과 상기 구분자를 통한 학습의 반복 수행은 경사하강법에 기초하여 수행되는 것을 특징공개특허 10-2021-0084332-4-으로 하는, 기계학습 장치."}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 13에 있어서,상기 분류기를 통한 학습과 상기 구분자를 통한 학습의 반복 수행은, 상기 분류기를 통한 학습의 수행 횟수와 상기 구분자를 통한 학습의 수행 횟수는 1:k (k는 2 이상의 자연수) 비율로 설정되는 것을 특징으로 하는, 기계학습 장치."}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 9에 있어서,상기 분류기 및 상기 구분자는,상기 제2 정보 및 상기 제2 정보에 대한 예측값에 대한 교차 엔트로피 함수로 설정되는 제1 손실함수항, 및 상기 제2 정보 및 상기 제3 정보에 대한 예측값에 대한 교차 엔트로피 함수로 설정되는 제2 손실함수항의 조합으로 정의되는 손실함수에 기초하여 학습을 수행하는 것을 특징으로 하는, 기계학습 장치."}
{"patent_id": "10-2020-0185350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 9에 있어서,상기 상호의존정보는, 상기 제2 정보에 대한 예측값의 확률변수, 및 상기 제3 정보의 확률 변수에 기초하여 정의되는 것을 특징으로 하는, 기계학습 장치."}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따른 상호의존정보에 기반한 기계학습 방법은, 각각의 데이터 엔트리별로 적어도 제1 정보, 제2 정보, 및 제3 정보를 포함하는 제1 데이터 셋(data set)을 입력받는 단계, 분류기(classifier)를 통해 상기 제1 및 제 3 정보에 대한 학습을 수행하여 상기 제2 정보에 대한 예측값을 출력하는 단계, 구분자(discriminator)를 통해, 상기 제2 정보에 대한 예측값에 대한 학습을 수행하여 상기 제3 정보에 대한 예측값을 출력하는 단계, 및 상기 제2 정보에 대한 예측값 및 상기 제3 정보 간의 상호의존정보가 최소화되도록 상기 제2 정보에 대한 예측값을 출 력하는 단계와 상기 제3 정보에 대한 예측값을 출력하는 단계를 반복 수행하는 단계를 포함할 수 있다."}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 기계학습 수행 방법 및 장치에 관한 것으로, 더욱 상세하게는 상호 의존 정보(mutual information)에 기초하여 기계학습을 수행하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 기계학습 기술이 나날이 발전하여 컴퓨터 비전, 자연어 처리, 음성인식 등 다양한 분야에서 기존 방법론들 을 압도하고 있다. 이에 따라 넷플릭스나 유튜브 등의 추천시스템, 의료 영상에 기초한 의료진단 서비스, 맞춤 형 자산관리를 위한 로보 어드바이저, 금융상품 트레이딩, 고객 신용정보를 이용한 대출심사, 기업에서의 채용 심사 등 인공지능이 사람의 의사결정을 돕거나 완전히 사람을 대신하여 의사결정을 내려주는 상품과 서비스도 늘어나고 있다. 하지만 일각에서는 인공지능 모델이 사람을 차별할 수 있다는 지적이 제기되고 있다. 이를테면, 인공지능 모델 의 구축을 통하여 학습하는 데이터군 자체가 편향되어 있을 경우, 이를 학습한 인공지능 모델은 학습된 데이터 군 자체의 편향성으로 인해 차별적인 또는 편향된 예측결과를 도출하게 될 수 있다. 이에 따라, 공정성 (fairness)을 고려한 기계학습의 필요성이 대두되고 있다. 여기서 공정성이란 평가 또는 의사결정 과정이 나이, 성별, 인종, 종교 등과 같이 '민감한 속성'에 영향을 받지 않는 것을 의미할 수 있다. 이러한 배경에서, 편향된 학습 데이터를 학습하더라도 공정한(fair) 기계학습 모델을 얻기 위한 방법에 대한 연구가 요구되고 있다."}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "이 배경기술 부분에 기재된 사항은 발명의 배경에 대한 이해를 증진하기 위하여 작성된 것으로서, 이 기술이 속 하는 분야에서 통상의 지식을 가진 자에게 이미 알려진 종래 기술이 아닌 사항을 포함할 수 있다."}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기와 같은 문제점을 해결하기 위한 본 발명의 목적은 모델의 예측값과 민감한 속성이 서로 독립이 될 수 있도 록, 두 확률변수 사이의 종속성을 최소화하기 위한 방향으로 분류기(classifier)를 학습시키기 위한 기계학습 방법 및 장치를 제공하는 데 있다."}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 상호의존정보에 기반한 기계학습 방법은, 각각의 데이터 엔트리별로 적어도 제1 정 보, 제2 정보, 및 제3 정보를 포함하는 제1 데이터 셋(data set)을 입력받는 단계, 분류기(classifier)를 통해 상기 제1 및 제3 정보에 대한 학습을 수행하여 제2 정보의 예측값을 출력하는 단계, 구분자(discriminator)를 통해, 상기 제2 정보의 예측값에 대한 학습을 수행하여 제3 정보의 예측값을 출력하는 단계, 및 상기 제2 정보 의 예측값 및 상기 제3 정보 간의 상호의존정보가 최소화되도록 상기 제2 정보의 예측값을 출력하는 단계와 상 기 제3 정보의 예측값을 출력하는 단계를 반복 수행하는 단계를 포함할 수 있다. 상기 분류기는 상기 제2 정보의 예측값과 상기 제3 정보 간의 DI(disparate impact) 값을 최대화하는 방향으로 학습을 수행하는 것을 특징으로 할 수 있다. 상기 분류기는 상기 제2 정보의 예측값과 상기 제3 정보 간의 EO(disparate impact) 값을 최대화하는 방향으로 학습을 수행하는 것을 특징으로 할 수 있다. 상기 분류기와 상기 구분자는 생성적 적대 신경망(generative adversarial network, GAN) 방식에 따른 경쟁적 관계를 가지도록 설정되는 것을 특징으로 할 수 있다. 상기 제2 정보의 예측값을 출력하는 단계와 상기 제3 정보의 예측값을 출력하는 단계를 반복 수행하는 단계는, 경사하강법에 기초하여 수행되는 것을 특징으로 할 수 있다. 상기 제2 정보의 예측값을 출력하는 단계와 상기 제3 정보의 예측값을 출력하는 단계를 반복 수행하는 단계는, 상기 제2 정보의 예측값을 출력하는 단계의 수행 횟수와 상기 제3 정보의 예측값을 출력하는 단계의 수행 횟수 를 1:k (k는 2 이상의 자연수) 비율로 수행하는 것을 특징으로 할 수 있다. 상기 분류기 및 상기 구분자는, 상기 제2 정보 및 상기 제2 정보에 대한 예측값에 대한 교차 엔트로피 함수로 설정되는 제1 손실함수항, 및 상기 제2 정보 및 상기 제3 정보에 대한 예측값에 대한 교차 엔트로피 함수로 설 정되는 제2 손실함수항의 조합으로 정의되는 손실함수에 기초하여 학습을 수행하는 것을 특징으로 할 수 있다. 상기 상호의존정보는, 상기 제2 정보에 대한 예측값의 확률변수, 및 상기 제3 정보의 확률 변수에 기초하여 정 의되는 것을 특징으로 할 수 있다. 본 발명의 다른 실시예에 따른 상호의존정보에 기반한 기계학습 장치는, 프로세서(processor), 상기 프로세서와 전자적(electronic)으로 통신하는 메모리(memory), 및 상기 메모리에 저장되는 명령들(instructions)을 포함하 며, 상기 명령들이 상기 프로세서에 의해 실행되는 경우, 상기 명령들은 상기 기계학습 장치가, 각각의 데이터 엔트리별로 적어도 제1 정보, 제2 정보, 및 제3 정보를 포함하는 제1 데이터 셋(data set)을 입력받고, 분류기 (classifier)를 통해 상기 제1 및 제3 정보에 대한 학습을 수행하여 제2 정보의 예측값을 출력하고, 구분자 (discriminator)를 통해, 상기 제2 정보의 예측값에 대한 학습을 수행하여 제3 정보의 예측값을 출력하고, 그리 고 상기 제2 정보의 예측값 및 상기 제3 정보 간의 상호의존정보가 최소화되도록 상기 분류기를 통한 학습과 상 기 구분자를 통한 학습을 반복 수행하는 것을 야기하도록 동작할 수 있다. 상기 분류기는 상기 제2 정보의 예측값과 상기 제3 정보 간의 DI(disparate impact) 값을 최대화하는 방향으로 학습을 수행하는 것을 특징으로 할 수 있다. 상기 분류기는 상기 제2 정보의 예측값과 상기 제3 정보 간의 EO(equalized odds) 값을 최대화하는 방향으로 학 습을 수행하는 것을 특징으로 할 수 있다. 상기 분류기와 상기 구분자는 생성적 적대 신경망(generative adversarial network, GAN) 방식에 따른 경쟁적 관계를 가지도록 설정되는 것을 특징으로 할 수 있다. 상기 분류기를 통한 학습과 상기 구분자를 통한 학습의 반복 수행은 경사하강법에 기초하여 수행되는 것을 특징 으로 할 수 있다. 상기 반복 수행하는 단계는, 상기 제2 정보의 예측값을 출력하는 단계의 수행 횟수와 상기 제3 정보의 예측값을 출력하는 단계의 수행 횟수를 1:k (k는 2 이상의 자연수) 비율로 수행하는 것을 특징으로 할 수 있다. 상기 분류기 및 상기 구분자는, 상기 제2 정보 및 상기 제2 정보에 대한 예측값에 대한 교차 엔트로피 함수로 설정되는 제1 손실함수항, 및 상기 제2 정보 및 상기 제3 정보에 대한 예측값에 대한 교차 엔트로피 함수로 설 정되는 제2 손실함수항의 조합으로 정의되는 손실함수에 기초하여 학습을 수행하는 것을 특징으로 할 수 있다.상기 상호의존정보는, 상기 제2 정보에 대한 예측값의 확률변수, 및 상기 제3 정보의 확률 변수에 기초하여 정 의되는 것을 특징으로 할 수 있다."}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 상호 의존 정보에 기반하여 학습을 수행하는 기계학습 방법 및 장치가 제공될 수 있다. 이에 따라, 기계학습을 통해 구축된 예측모델의 예측값과 민감한 속성 간의 독립성이 용이하게 확보될 수 있다. 본 발명의 일 실시예에 따르면, 기계학습 장치는 민감하지 않은 일반적 정보들과 민감한 정보를 입력받아서 레 이블의 예측값을 출력하는 분류기와, 분류기에서 출력된 레이블의 예측값을 입력받아서 민감한 정보의 예측값을 출력하는 구분자를 포함할 수 있다. 분류기와 구분자의 상호 경쟁적인 학습을 통하여, 분류기가 민감한 정보와 독립적인 예측값을 출력해내는 성능이 향상될 수 있다. 따라서 본 발명에 따른 분류기 또는 기계학습 장치의 공 정성이 향상될 수 있다."}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명 의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의 해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된 다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유 사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인의미로 해석되지 않는다. 본 발명에 따른 실시예들이 적용되는 기계학습(machine learning) 기술이 설명될 것이다. 본 발명에 따른 실시 예들이 적용되는 기계학습 기술은, 기계학습 방법, 기계학습 장치, 또는 기계학습 시스템 등으로 구현될 수 있 다. 본 발명에 따른 실시예들이 적용되는 기계학습 기술은 아래 설명된 내용에 한정되지 않으며, 다양한 형태의 기계학습 기술에 적용될 수 있다. 명세서 전체에서 기계학습(machine learning)은, 인공지능의 연구 분야 중 하나로 인간의 학습 능력과 같거나 유사한 기능을 컴퓨터에서 실현하고자 하는 기술 및 기법을 의미할 수 있다. 또는, 기계학습은 클러스터링, 딥 러닝(deep learning), 각종 인공신경망, 표현 학습법, 강화 학습법, 베이즈 네트워크 등 다양한 접근법 중 일부 또는 전부를 의미할 수 있다. 기계학습 모델은 훈련 데이터를 이용하여 학습될 수 있다. 기계학습 모델은 이미 훈련된 모델을 의미할 수 있다. 또는, 기계학습 모델은 본 발명의 실시예에 따른 학습 과정을 통해 구축되는 모 델을 의미할 수 있다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 본 발명을 설 명함에 있어 전체적인 이해를 용이하게 하기 위하여 도면상의 동일한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 도 1은 기계학습 장치의 일 실시예를 도시한 블록도이다. 도 1을 참조하면, 기계학습 장치의 일 실시예는 적어도 하나의 프로세서, 메모리 및 저장 장치 등을 포함할 수 있다. 프로세서는 메모리 및/또는 저장 장치에 저장된 적어도 하나 이상의 명령(command)을 실행할 수 있다. 프로세서에 의해 실행되는 적어도 하나 이상의 명령은 프로그램 명령(program command)을 의미할 수 있다. 프로세서는 중앙 처리 장치(central processing unit; CPU), 그래픽 처리 장치(graphics processing unit; GPU) 또는 본 발명에 따른 방법들이 수행되는 전용의 프로세서를 의미할 수 있다. 메모리 와 저장 장치는 휘발성 저장 매체 및/또는 비휘발성 저장 매체로 구성될 수 있다. 예를 들어, 메모리 는 읽기 전용 메모리(read only memory; ROM) 및/또는 랜덤 액세스 메모리(random access memory; RAM)로 구성될 수 있다. 메모리 및/또는 저장 장치는 프로세서에서 실행되기 위한 적어도 하나 이상의 명령을 저장하거 나 로드할 수 있다. 메모리 및/또는 저장 장치에 저장되는 적어도 하나 이상의 명령은 기계학습을 수 행하기 위한 일련의 명령들에 해당할 수 있다. 메모리 및/또는 저장 장치는 인공지능 모델 학습을 위 한 학습용 데이터 베이스를 저장하거나 로드할 수 있다. 학습용 데이터 베이스에는 인공지능 모델 학습을 위한 적어도 하나 이상의 데이터 셋(data set)이 포함될 수 있다. 이 포함될 수 있다. 데이터 셋은 데이터 집합, 또 는 데이터 군 등으로도 칭할 수 있다. 데이터 셋은 적어도 하나 이상의 엔트리들로 구성될 수 있다. 데이터 셋 을 구성하는 적어도 하나 이상의 엔트리들은 적어도 하나 이상의 속성이나 변수, 또는 파라미터, 또는 정답 레 이블 등을 포함하도록 구성될 수 있다. 적어도 하나 이상의 엔트리들 각각에 대하여는 식별정보가 부여될 수 있 다. 이를테면, 적어도 하나 이상의 엔트리들 각각에 대하여는 식별자(identifier) 등의 식별정보가 부여될 수 있다. 메모리 및/또는 저장 장치는 프로세서에서 실행되기 위한 적어도 하나 이상의 명령을 저장하거 나 로드할 수 있다. 적어도 하나 이상의 명령은, 프로세서에서의 기계학습 동작을 위한 명령을 포함할 수 있다. 적어도 하나 이상의 명령은, 학습용 데이터 베이스에 포함된 데이터 셋을 구성하는 엔트리들의 속성 및/ 또는 식별 정보 등에 기초하여 학습을 수행하기 위한 명령을 포함할 수 있다. 적어도 하나 이상의 명령은, 프로 세서에서 수행되는 기계학습 동작에 의해 업데이트될 수 있다. 프로세서가 수행하는 기계학습은 지도 학습 방식에 의해 이루어질 수 있다. 또는, 프로세서가 수행하는 기계학습은 비지도 학습 방식에 의해 이 루어질 수 있다. 프로세서는 메모리 및/또는 저장 장치에 저장된 적어도 하나 이상의 명령에 따라, 메모리 및/또는 저장 장치로부터 학습용 데이터 베이스나, 학습용 데이터 베이스에 포함되는 적어도 하나 이상의 데이터 셋이나, 또는 적어도 하나 이상의 데이터 셋을 구성하는 적어도 하나 이상의 엔트리들 등의 정보를 로드 또는 독출할 수 있다. 프로세서는 로드 또는 독출된 정보에 기초한 기계학습 동작을 수행할 수 있다. 프로 세서는 기계학습 동작을 수행함으로써 적어도 하나 이상의 연산 모델을 생성할 수 있다. 기계학습 동작을 통해 생성되는 연산 모델은, 이를테면 데이터 셋을 입력 받아서, 입력된 데이터 셋을 통해 예측되는 정보를 출력하는 예측 모델을 의미할 수 있다. 기계학습 동작에는 딥러닝 기술이 이용될 수 있다. 기계학습은 지도 학습 방식, 비지도 학습 방식, 강화 학습 방식, 생성적 적대 신경망(generative adversarial network; GAN) 방식 등 의 방식에 기반하여 수행될 수 있다. 다만, 이는 설명의 편의를 위하여 제시된 일부의 예시일 뿐이며, 본 발명 의 실시예는 이에 제한되지 않는다. 프로세서에 의해 생성된 연산 모델, 또는 생성된 연산 모델에 대한 정 보는 메모리 및/또는 저장 장치에 저장될 수 있다. 도 2는 기계학습 장치에 포함된 인공 신경망(artificial neural network, ANN)의 일 실시예를 도시한 개념도이 다. 도 2를 참조하면, 기계학습 장치의 인공 신경망은 복수개의 계층(layer)들을 포함할 수 있으며, 각각의 계층들 은 복수개의 인공 노드(artificial node)들을 포함할 수 있다. 인공 노드들은 인공 뉴런이라고도 칭할 수 있다. 인공 신경망은 복수의 적응적 가중 벡터(adaptive weight vector)들을 포함할 수 있으며, 인공 신경망의 각각의 계층들에 포함된 인공 노드들은 가중 벡터들에 의해 연결될 수 있다. 인공 신경망은 미리 설정된 파라미터에 따 라 복수개의 계층들 및 인공 노드들을 포함할 수 있으며, 복수개의 계층들, 인공노드들, 및 가중 벡터들 간의 상호작용에 기초하여 기계학습을 수행할 수 있다. 인공 신경망을 구성하는 복수개의 계층들은, 입력계층, 은닉계층, 및 출력계층 등을 포함할 수 있다. 입력계층 은 학습하고자 하는 데이터 셋 또는 데이터 그룹이 입력되는 계층일 수 있다. 입력계층은 적어도 하나 이상의 입력노드들을 포함할 수 있다. 입력계층을 구성하는 적어도 하나 이상의 입력노드들 각각에는 데이터 셋을 구성 하는 엔트리들의 일부 또는 전부가 입력될 수 있다. 입력계층을 구성하는 적어도 하나 이상의 입력노드들에 입 력되는 데이터 셋은 사전에 데이터 전처리(preprocessing)를 거친 데이터일 수 있다. 출력계층은 인공 신경망에 입력된 데이터 또는 신호가 인공 신경망에서의 연산을 거쳐서 출력되는 계층을 의미할 수 있다. 출력계층은 적 어도 하나 이상의 출력노드들을 포함할 수 있다. 입력계층과 출력계층 사이에는 적어도 하나 이상의 은닉계층들이 배치 수 있다. 은닉계층은 히든계층(hidden layer)이라고도 한다. 둘 이상의 은닉계층을 가지는 인공 신경망을 심층 신경망(deep neural network, DNN)이라 할 수 있다. 즉, DNN은 입력계층과 은닉계층, 출력계층으로 구성되는 신경망 구조에 있어서, 입력계층과 출력계 층 사이에 복수 개의 은닉계층들이 배치되는 신경망 구조를 의미할 수 있다. DNN 구조에 기초한 기계학습 방식 을 딥러닝(deep learning)이라 칭할 수 있다. 은닉계층은 가중 벡터들을 통해 입력계층, 출력계층 또는 다른 은 닉계층과 연결될 수 있다. 기계학습 장치는, 인공 신경망의 가중 벡터들을 업데이트하는 학습(learning) 동작을 수행할 수 있다. 기계학습 장치는 다층 퍼셉트론(multi-layer perceptron) 분류기를 포함할 수 있다. 인공 신경망의 학습 동작은 기계학습 장치에 포함된 다층 퍼셉트론 분류기에 의해 수행될 수 있다. 다층 퍼셉트론 분류기는 미리 설정된 학습 알고리 즘을 통해 인공 신경망을 훈련(training)할 수 있다. 학습 알고리즘은 지도 학습 알고리즘(supervised learning algorithm), 비지도 학습 알고리즘(non-supervised learning algorithm)과 같은 기계학습 알고리즘들을 포함할 수 있다. 기계학습 장치는 인공 신경망 구조에서 피드 포워드(feed-forward) 동작을 통해 일련의 연산을 수행하고 출력값 을 얻을 수 있다. 기계학습 장치는 출력값 및 기설정된 기준값에 기초하여 오차 정보를 획득할 수 있다. 기계학 습 장치는 산출된 오차 정보를 역전파(back-propagation)하여 인공 신경망의 계층간의 가중 벡터들을 수정하는 학습 동작을 수행할 수 있다. 기계학습 장치는 미리 설정된 최적화 알고리즘을 통해 인공 신경망의 계층간의 가 중 벡터들을 수정할 수 있다. 이를테면, 최적화 알고리즘은 경사 하강법(gradient descent), 교차 경사 하강법 (alternating gradient descent), 확률적 경사 하강법(stochastic gradient descent) 또는 아담 최적화(adam- optimizer) 알고리즘 등을 포함할 수 있다. 기계학습 장치는 미리 설정된 학습 횟수에 해당하는 이폭(epoch)의 수만큼 학습 동작을 반복하여 수행할 수 있다. 이폭의 수가 클수록 기계학습을 통해 획득되는 모델의 예측 성능 또는 정확도 등이 향상될 수 있다. 한편, 이폭의 수가 클수록 기계학습 과정에서의 연산량이 증가하고 연산 부 하가 증가하며 학습 효율 등이 저하될 수 있다. 이폭의 수는 통상의 기술자가 기계학습 장치의 성능을 향상시키 기에 적절하다고 판단하는 값으로 설정될 수 있다. 인공 신경망의 전체 계층의 수는 개일 수 있다. 인공 신경망이 DNN 구조를 가질 경우, 은 4 이상의 자연 수일 수 있다. 각각의 계층들은 입력계층부터 출력계층까지 번째 계층으로 표현될 수있으며, 이 중 번째부터 번째 까지의 계층들이 은닉계층일 수 있다. 일 실시예에서, DNN 구 조는 3개의 은닉계층을 포함할 수 있으며, 각각 32개, 64개, 32개의 은닉노드들로 구성될 수 있다. 다만 이는 이해를 돕기 위한 하나의 예시일 뿐이며, 본 발명의 실시예는 이에 국한되지 않고 다양한 형태의 인공 신경망 실시예들을 포괄할 수 있다. 인공 신경망의 입력계층에 입력된 입력 데이터 는 각 계층들 또는 각 계층들을 거치며, 각 계층들 사이에 설정 된 함수들에 기초한 연산을 거칠 수 있다. 각 계층들 사이에 설정된 함수들은 연속적인 선형 또는 비선형 함수 들을 의미할 수 있다. 입력 데이터 가 인공 신경망 구조를 통과함 따라 출력계층에서 따라 출력 데이터 가 출력될 수 있다. 수 있다. 이를테면, 수학식 1과 같을 수 있다. 수학식 1"}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 는 각 계층의 노드 간에 설정되는 가중치 파라미터들일 수 있다. 은 번째 계층과 번째 계 층 간에 설정되는 함수일 수 있다. 이를테면, 인공 신경망의 일 실시예에서 은 출력 매핑에 사용되는 시그 모이드(Sigmoid) 함수, 또는 입력계층 및 히든계층들에서 활성화 함수로 사용되는 ReLu(rectified linear unit) 함수 등에 해당할 수 있다. 시그모이드 함수는 수학식 2와 같이 표현될 수 있고, ReLu 함수는 수학식 3과 같이 표현될 수 있다. 수학식 2"}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 3"}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "다만 수학식 2 및 3과 같은 함수들은 이해를 돕기 위하여 제시된 예시일 뿐이며, 본 발명의 실시예는 이에 국한 되지 않고 다양한 형태의 인공 신경망 실시예들을 포괄할 수 있다. DNN 등의 구조를 가지는 인공 신경망에서는 회귀(regression) 학습 모델에 따라 출력값이 평가되고 각 파라미터 들이 업데이트될 수 있다. 출력값의 평가를 위하여, 출력값과 정답값 간의 관계에 기초하여 손실 함수(loss function)가 정의될 수 있다. 이를테면, 인공 신경망의 일 실시예에서 손실 함수는 수학식 4와 같이 정의될 수 있다.수학식 4"}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, K는 학습 샘플 수를 의미할 수 있다. 한편, a는 인공 신경망을 통해 학습하고자 하는 정답값 또는 정답 벡터에 해당할 수 있고, 는 인공 신경망의 출력 계층을 통해 출력되는 출력값 또는 출력벡터에 해당할 수 있다. 그러나, 수학식 4와 같은 형태의 손실 함수는 이해를 돕기 위한 하나의 예시일 뿐이며, 본 발명의 실시예 는 이에 국한되지 않고 다양한 형태의 손실 함수 실시예들을 포괄할 수 있다. 손실함수는 출력값 와 정답값 a 간의 차이가 적을수록 작은 값이 될 수 있다. 기계학습 장치의 일 실시예에서, 손실함수를 최소화되는 방향으로 반복 학습 및 파라미터 갱신이 수행될 수 있다. 이에 따라, 인공 신경망 구조 를 통해 출력되는 출력값 가 정답값 a에 근접해갈 수 있다. 즉, 인공 신경망 구조를 통해 획득된 연산 모델 또 는 예측 모델의 연산 성능 또는 예측 성능 등이 향상될 수 있다. 도 3은 생성적 적대 신경망(generative adversarial network, GAN) 방식에 따른 기계학습 방법의 일 실시예를 설명하기 위한 개념도이다. 도 3을 참조하면, 기계학습 장치는 GAN 방식에 기초한 기계학습을 수행할 수 있다. 여기서, GAN은 특정한 데이 터 셋(dataset)이 입력되었을 때 해당 데이터 셋의 분포를 학습하고 분포에 해당되는 데이터를 생성할 수 있는 모델을 의미할 수 있다. GAN은 생성자(Generator, G) 및 구분자(Discriminator, D)를 포함하도록 구성될 수 있 다. 생성자 및 구분자 각각은 인공신경망 구조를 가질 수 있다. 생성자는 노이즈 데이터를 입력받아서, 실 제 데이터와 유사한 가짜 데이터를 생성할 수 있다. 보다 구체적으로, 생성자는 특정 확률 분포 를 갖는 실제 데이터를 이용해 학습을 수행함으로써, 실제 데이터(x)와 유사한 분포를 갖는 가짜 데이터 를 생성할 수 있다. 한편, 구분자는 입력되는 데이터가 실제 데이터에 해당하는지 또는 생성자가 생성한 가짜 데이 터에 해당하는지를 판별할 수 있다. 즉, 구분자는 실제 데이터 및/또는 구분자에서 생성된 가짜 데이 터를 입력받을 수 있고, 입력된 데이터에 대한 연산 또는 분석을 수행함으로써 입력된 데이터가 실제 데이 터에 해당하는지 또는 생성자가 생성한 가짜 데이터에 해당하는지를 판별할 수 있다. 생성자는 실제 데이터를 학습하고 가짜 데이터를 생성함에 있어서, 구분자를 속일 수 있을 정도로 실제 데이터와 구분하기 용이하지 않은 또는 구분이 불가능한 가짜 데이터를 생성해내는 것을 목표로 할 수 있다. 한편, 구분자는 실제 데이터 및 가짜 데이터를 이용하여 학습을 수행함으로 써, 실제 데이터와 가짜 데이터를 정확하게 판별 또는 분류해내는 것을 목표로 할 수 있다. 이와 같이 생성자 및 구분자는 서로 상반된 목표를 가지고 학습을 반복 수행함으로써 서로의 성능이 향상되도록 유도할 수 있다. 즉, 생성자의 가짜 데이터 생성 성능이 향상되었을 경우, 구분자 역시 이를 구분하기 위해 가짜 데이터 판별 성능이 향상되어야 할 수 있다. 반대로, 구분자의 가짜 데이어 판별 성능이 향상되었을 경우, 생성자 역시 구분자를 속이기 위해 가짜 데이터 생 성 성능이 향상되어야 할 수 있다. 도 4는 본 발명에 따른 기계학습 장치에서 풀고자 하는 최적화 문제의 일 실시예를 설명하기 위한 예시도이다. 최근 기계학습 기술은 GAN 방식 등 다양하고 우수한 기술적 성취들로 인하여 나날이 발전중이다. 이에 따라 컴 퓨터 비전, 자연어 처리, 음성인식 등 다양한 분야에서 기존 방법론들을 압도하고 있다. 이에 따라 넷플릭스나 유튜브 등의 추천시스템, 의료 영상에 기초한 의료진단 서비스, 맞춤형 자산관리를 위한 로보 어드바이저, 금융 상품 트레이딩, 고객 신용정보를 이용한 대출심사, 기업에서의 채용 심사 등 인공지능이 사람의 의사결정을 돕 거나 완전히 사람을 대신하여 의사결정을 내려주는 상품과 서비스도 늘어나고 있다. 하지만 일각에서는 인공지능 모델이 사람을 차별할 수 있다는 지적이 제기되고 있다. 이를테면, 인공지능 모델 의 구축을 통하여 학습하는 데이터군 자체가 편향되어 있을 경우, 이를 학습한 인공지능 모델은 학습된 데이터군 자체의 편향성으로 인해 차별적인 또는 편향된 예측결과를 도출하게 될 수 있다. 이에 따라, 공정성 (fairness)을 고려한 기계학습의 필요성이 대두되고 있다. 여기서 공정성이란 평가 또는 의사결정 과정이 나이, 성별, 인종, 종교 등과 같이 ‘민감한 속성'에 영향을 받지 않는 것을 의미할 수 있다. 이러한 배경에서, 편향 된 학습 데이터를 학습하더라도 공정한(fair) 기계학습 모델을 얻기 위한 방법에 대한 연구가 요구되고 있다. 본 발명에 따른 기계학습 장치에서 학습되는 데이터 셋(data set)은 각각의 데이터 엔트리별로 적어도 3개 이상의 변수 내지는 속성 또는 파라미터를 포함하도록 구성될 수 있다. 이를테면, 데이터 셋은 와 같이 표현될 수 있다. 여기서, , , 및 는 각각 i번째 데이터 엔트리 의 일반적 정보(normal information), 정답 레이블, 및 민감한 정보(sensitive information)을 의미할 수 있다. 일반적 정보 는 민감한 정보 와 구분되는 개념으로서, '민감하지 않은 정보'와 같이 표현될 수도 있다. 일반적 정보 는 i번째 데이터 엔트리의 특징 벡터(feature vector)에 해당할 수도 있다. 민감한 정보 는 나이, 성별, 인종, 종교 등과 같이 경우에 따라 차별 또는 불공정 판단의 대상이 될 수 있는 속성들을 의미할 수 있다. 는 레이블을 나타내는 카테고리 값을 의미할 수 있다. 기계학습 장치는 데이터 셋 에 대한 학습을 수행할 수 있다. 기계학습 장치의 인공 신경망은 입력계층으로 일반적 정보 및 민감한 정보 를 입력받을 수 있고, 출력 계층에서 정답 레이블 에 대한 예측값 를 출력할 수 있다. 이를 다르게 표현하면, 인공 신경망은 일반적 정보 에 대한 확률변수 X와 민감한 정보 에 대한 확률변수 Z를 입력받아서, 정답 레이블 에 대한 예측값 에 대한 확률변수 를 출력할 수 있다. 상기한 학습을 반복함으로써 예측 모델의 예측 성능이 향상될 수 있다. 여기서, 예측 모델의 높은 공정성 (fairness)을 위해서는, 일반적 정보값 에 기초하여 레이블 예측값 를 도출함에 있어서 민감한 정보 와 예 측값 간의 독립성이 담보될 필요가 있을 수 있다. 다르게 표현하면, 일반적 정보값 에 기초하여 레이블 예측 값 를 도출함에 있어서 민감한 정보 가 예측값 에 영향을 줄 경우 예측 모델이 편향되었거나 차별적인 것으 로 판단될 수 있다. 상기한 바와 같은 공정성 또는 편향성을 정량화하여 평가하기 위하여, 이를테면 DI(disparate impact)와 같은 함수가 정의되어 사용될 수 있다. DI는 불평등 효과 또는 간접 차별 등의 개념에 대응되는 것으로 볼 수 있다. EO는 기회 균등과 같은 개념에 대응되는 것으로 볼 수 있다. DI는 수학식 5 또는 6과 같이 정의될 수 있다. 수학식 5"}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 6"}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 5는 민감한 정보에 대한 확률변수 Z와 정답 레이블에 대한 예측값에 대한 확률변수 각각이 0 또는 1의 이진값을 가지는 실시예를 가정한 수식으로 볼 수 있다. 한편, 수학식 6은 민감한 정보에 대한 확률변수 Z가 이 진값으로만 정의되지 않는 보다 일반적인 실시예를 가정한 수식으로 볼 수 있다. 수학식 5 및 6을 참조하면, DI 는 와 Z 간의 관계성에 따라 다른 값을 가질 수 있다. 보다 구체적으로는, DI의 값이 커진다는 것은 민감한 속성 Z에 상관없이 모델의 예측 값 의 값이 1이 나올 확률이 비슷해진다는 것을 의미할 수 있다. 즉, DI가 커질 수록 학습 모델이 민감한 속성에 덜 의존하게 된다는 것을 의미할 수 있다. 다르게 표현하면, DI 값이 클수록 학습을 통해 획득된 예측모델이 보다 공정한 것으로 볼 수 있다. DI의 최대값은 1일 수 있다. DI의 값이 1인 경 우, 와 Z는 서로 독립인 것을 의미할 수 있다. 이를 수식으로 표현하면 수학식 7과 같을 수 있다. 수학식 7"}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "한편, 상기한 바와 같은 공정성 또는 편향성을 정량화하여 평가하기 위하여, 이를테면 EO(equalized odds)와 같 은 함수가 정의되어 사용될 수 있다. EO는 균등화된 가능성과 같은 개념에 대응되는 것으로 볼 수 있다. EO는 수학식 8과 같이 정의될 수 있다. 수학식 8"}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "수학식 8을 참조하면, EO는 , Y 및 Z 간의 관계성에 따라 다른 값을 가질 수 있다. 보다 구체적으로는, EO의 값이 커진다는 것은 정답 레이블의 값이 y로 동일한 경우, 민감한 속성 Z에 상관없이 모델의 예측 값 의 값이 1이 나올 확률이 비슷해진다는 것을 의미할 수 있다. 즉, EO가 커질수록 동일한 정답 레이블 y 값에 대하여 학 습 모델이 민감한 속성에 덜 의존하게 된다는 것을 의미할 수 있다. 다르게 표현하면, EO 값이 클수록 학습을 통해 획득된 예측모델이 보다 공정한 것으로 볼 수 있다. EO의 최대값은 1일 수 있다. EO의 값이 1인 경우, 정 답 레이블의 값이 y로 동일한 경우 와 Z는 서로 독립인 것을 의미할 수 있다. 수학식 8에서, y가 특정 값(이를 테면, 1)인 경우에 한정되는 보다 구체적인 EO 함수가 정의될 수 있다. 이와 같이 정의된 EO 함수는 Equal opportunity(기회 균등)에 해당하는 함수를 의미할 수 있다. 기계학습 모델의 공정성, 또는 기계학습 모델을 통해 획득되는 예측값에서 차별의 정도 또는 가능성을 줄이고 공정성을 담보/보장하기 위하여, (i) 학습전처리(pre-processing), (ii) 학습과정처리(in-processing), (iii) 학습후처리 (post-processing) 등의 접근 방법론을 생각해볼 수 있다. 학습 전처리 방식은, 인공 신경망을 통해 학습하고자 하는 데이터에 대하여 미리 소정의 처리 또는 보정을 가한 이후 인공 신경망에 입력하는 방식을 의 미할 수 있다. 이를테면 학습 전처리 방식의 일례로서, 특정 소수 집단에 대한 차별의 정도 또는 가능성을 줄이 기 위해 해당 소수 집단에 포함된 데이터의 가중치를 올려주는 가중치 조절(reweighting) 방식 등이 제안될 수 있다. 한편, 학습 후처리 방식은, 인공 신경망으로부터 출력된 출력값 또는 예측값 등의 데이터에 대해 사후 처 리 또는 보정을 수행하여 최종 결과에 반영하는 방식을 의미할 수 있다. 이를테면 학습 후처리 방식의 일례로서, 학습을 통해 획득된 예측 모델을 통해 출력되는 전체 예측 데이터 중에서 일부를 샘플링하고, 만약 샘플링된 데이터에서 차별 또는 편향성이 발견될 경우, 발견된 차별 또는 편향성의 효과를 보정하기 위하여, 샘 플링된 데이터 또는 전체 예측 데이터에 대한 후처리 또는 후보정을 수행하는 방식 등이 제안될 수 있다. 한편 본 발명은 학습과정처리 방식의 일환으로서, 인공 신경망을 통한 학습의 방향성을 좌우하는 손실함수(loss function)에 공정성을 위한 손실항으 추가하는 방식을 제안한다. 본 발명에 따른 인공 신경망에 적용되는 손실 함수는, 학습을 통해 획득되는 연산/예측 모델의 연산/예측 성능을 위한 손실함수항과, 연산/예측 모델의 공정 성을 위한 손실함수항의 조합으로 정의될 수 있다. 이를테면, 본 발명에 따른 인공 신경망에 적용되는 손실함수 는 수학식 9와 같이 정의될 수 있다.수학식 9"}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "수학식 9에서, L은 손실함수를 의미할 수 있고, L1은 연산/예측 성능을 위한 손실함수항을 의미할 수 있고, L2는 공정성을 위한 손실함수항을 의미할 수 있고, λ는 공정성에 대한 가중치를 결정하는 계수를 의미할 수 있다. 여기서, λ 값이 과도하게 커서(예를 들어, λ=1) 공정성을 위한 손실함수항의 비중이 과도하게 클 경우, 연산/ 예측 모델의 연산/예측 성능이 우수하지 않을 수 있다. 한편, λ 값이 과도하게 작아서(예를 들어, λ=0) 공정 성을 위한 손실함수항의 비중이 과도하게 작을 경우, 연산/예측 모델의 공정성이 확보되지 않을 수 있다. λ 값 은 통상의 기술자가 기계학습을 통해 획득되는 연산/예측 모델의 연산/예측 성능 및 공정성 양쪽 모두를 일정 이상 만족시켜서 본 발명에 따른 기계학습 장치의 기술적 목표를 달성하기에 적절하다고 판단하는 값으로 설정 될 수 있다. 본 발명에 따른 인공 신경망에 적용되는 손실함수 L은, 연산/예측 성능을 위한 손실함수항 L1과, 공정성을 위한 손실함수항 L2의 조합으로 정의될 수 있다. 연산/예측 성능을 위한 손실함수항 L1은, 이를테면 교차 엔트로피 (cross entropy) 함수로 정의될 수 있다. 교차 엔트로피 함수를 사용하여 정의된 L1은 수학식 10과 같을 수 있 다. 수학식 10"}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "한편, 본 발명에 따른 공정성을 위한 손실함수항 L2는 상호의존정보(mutual information, MI) 개념에 기초하여 정의될 수 있다. 상호의존정보는 두 확률변수에 기초하여, 또는 두 확률변수 사이에서 정의될 수 있다. 이를테 면, 두 확률변수 U, V 사이의 상호의존정보란, 확률변수 의 엔트로피 H(U)에서 V가 주어졌을 때의 조건부 엔트 로피 H(U|V)를 뺀 값으로 정의될 수 있다. 즉, 두 확률변수 U, V 사이의 상호의존정보 I(U;V)는 수학식 11과 같 이 정의될 수 있다. 수학식 11"}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "수학식 11을 참조하면, 확률변수 U의 엔트로피 H(U)는, V가 주어졌을 때의 조건부 엔트로피 H(U|V)보다 크거나 같은 값을 가질 수 있다. 즉, 상호의존정보 I(U;V)는 0 이상의 값을 가질 수 있다. 상호의존정보 I(U;V)는 두 확률변수 U, V가 서로 독립일 때 0의 값을 가질 수 있다. 본 발명에 기계학습 장치는 정답 레이블에 대한 예측값에 대한 확률변수 와 민감한 정보에 대한 확률변수 Z 간의 상호의존정보 I( ;Z)가 0 또는 가능한 최소의 값을 가지도록 하는 방향으로 학습을 수행할 수 있다. 상 호의존정보 I( ;Z)가 0일 경우, 확률변수 와 확률변수 Z는 서로 독립인 것으로 볼 수 있다. 이와 같은 상호의 존정보 개념과, 수학식 5 또는 6과 같이 정의된 DI 개념을 함께 참고하여 보면, 확률변수 와 확률변수 Z가 서 로 독립일 경우, 상호의존정보 I( ;Z) 값은 0이고 DI 값은 1이 될 수 있다. 이는, 연산/예측 모델을 통한 의사 결정 또는 예측이, 민감한 속성에 영향을 받지 않고 결정된다는 것을 의미할 수 있다. 즉, 기계학습 장치를 통해 생성된 연산/예측 모델이 공정성을 가진다는 것을 의미할 수 있다. 본 발명에 따른 기계학습 장치는 상호의존정보 I( ;Z)를 최소화하기 위해, 또는 DI를 최대화하기 위해 도 3을 참조하여 설명한 것과 동일 또는 유사한 GAN 구조를 포함할 수 있다. 기계학습 장치는 생성자(G)와 구 분자(D)를 포함할 수 있다. 생성자(G)는 x를 입력받아서 를 출력할 수 있다. 구분자(D)는 생성자에서 생성된 를 입력받아서 z를 출력할 수 있다. 생성자(G)와 구분자(D)는 수학식 9와 같이 정의된 손실함수 L에 기초하여 연산을 수행할 수 있다. 손실함수 L은, 연산/예측 성능을 위한 손실함수항 L1과, 공정성을 위한 손실함수 항 L2의 조합으로 정의될 수 있다. 연산/예측 성능을 위한 손실함수항 L1 및 공정성을 위한 손실함수항 L2은, 교 차 엔트로피 함수에 기초하여 정의될 수 있다. 교차 엔트로피 함수를 사용하여 정의된 L1은 상술한 수학식 11과 같이 y와 에 대한 교차 엔트로피 함수 또는 그 변형에 기초하여 정의될 수 있다. 한편, L2는 z와 z에 대 한 예측값 및 교차 엔트로피 함수 또는 그 변형에 기초하여 정의될 수 있다. 이를테면 수학식 12와 같 을 수 있다. 수학식 12"}
{"patent_id": "10-2020-0185350", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "여기서, 는 생성자(G)가 x를 입력받아서 출력한 값에 해당하기 때문에, 와 같이 표현될 수 있다 . 한편, z는 구분자(D)가 를 입력받아서 출력한 값에 해당하기 때문에, 와 같이 표현될 수 있다. 도 5는 본 발명에 따른 분류기(classifier)의 일 실시예를 도식화한 개념도이다. 도 5를 참조하면, 본 발명에 따른 기계학습 장치는 분류기를 포함할 수 있다. 분류기는 하나 또는 복수의 인공 신경망 구조로 구성될 수 있다. 분류기는 와 같이 표현되는 데이터 셋에 대한 학습을 수 행할 수 있다. 여기서, , , 및 는 각각 i번째 데이터 엔트리의 일반적 정보(normal information), 정답 레이블, 및 민감한 정보(sensitive information)을 의미할 수 있다. 분류기는 입력계층으로 일반적 정보 및 민감한 정보 를 입력받을 수 있고, 출력 계층에서 정답 레이블 에 대한 예측값 를 출력할 수 있다. 이 를 다르게 표현하면, 분류기는 일반적 정보 에 대한 확률변수 X와 민감한 정보 에 대한 확률변수 Z를 입력받 아서, 정답 레이블 에 대한 예측값 에 대한 확률변수 를 출력할 수 있다. 분류기가 X와 Z를 입력받아서 를 출력함에 있어서, Z의 영향이 있을 수 있다. 또는, 분류기가 X와 Z를 입력받 아서 출력한 는 Z와 독립적이지 않고 상호관계 또는 종속관계(dependence)가 존재할 수 있다. 이 경우, 분류 기가 입력받은 데이터 셋의 정보들을 분석하고 결과를 출력함에 있어서 민감한 정보 또는 민감한 속성의 영향을 받는 것으로 해석할 수 있다. 이러한 문제를 해결하기 위해, 분류기 후단에서 민감한 정보의 확률변수 Z와 분류 기에서 출력된 예측값의 확률변수 를 입력받는 구분자(discriminator)와 분류기가 서로 경쟁하는 구조를 제안 한다. 이는 도 3을 참조하여 설명한 GAN 구조와 동일 또는 유사할 수 있다. 본 발명에 따라 분류기와 구분자가 서로 경쟁하는 구조를 통해 분류기의 공정성을 확보하고자 하는 기계학습 장치의 실시예를, 이하 도 6을 참조하 여 보다 상세하게 설명한다. 도 6은 본 발명에 따른 상호의존정보에 기반한 기계학습 방법 및 장치의 일 실시예를 설명하기 위한 개념도이다.도 6을 참조하면, 본 발명에 따른 상호의존정보에 기반한 기계학습 장치는 분류기와 구분자를 포함할 수 있다. 본 발명에 따른 상호의존정보에 기반한 기계학습 방법은 후술하는 기계학습 장치가 수행 하는 동작들의 일부 또는 전부를 포함할 수 있다. 기계학습 장치는 데이터 셋 에 대한 학습을 수행할 수 있다. 분류기는 도 5를 참조하여 설명한 분류기와 동일 또는 유사할 수 있다. 분류기는 도 3을 참조하여 설명한 생성자(G)와 동일 또는 유사할 수 있다. 분류기는 일반적 정보 에 대한 확률변수 X와 민감한 정보 에 대한 확률변수 Z를 입력받아서, 정답 레이블 에 대한 예측값 에 대한 확률변수 를 출력할 수 있다. 구분자는 도 3을 참 조하여 설명한 구분자(D)와 동일 또는 유사할 수 있다. 구분자는 분류기에서 출력된 예측값의 확률변 수 를 입력받아서, 민감한 속성의 확률변수 Z에 대한 예측값 확률변수 를 출력할 수 있다. 기계학습 장치 는 도 4를 참조하여 설명한 최적화 문제를 해결하기 위해 설계되었을 수 있다. 기계학습 장치의 분류기는 일반적 정보(즉, 민감하지 않은 속성들로 구성된 정보)와 민감한 정보를 함께 입력받아서, 레이블의 예측값을 출력할 수 있다. 분류기가 공정하다고 가정할 경우, 분류기가 출력하는 레이블의 예측값은 민감한 정보와 독립적일 것으로 추정할 수 있다. 다르게 이야기하면, 분류기 가 출력하는 레이블의 예측값과 민감한 정보가 독립적이지 않다면, 분류기는 공정하지 않은 것으로 추정할 수 있다. 구분자는 분류기에서 출력된 레이블의 예측값 를 입력받아서, 민감한 속성에 대한 예측값 를 출 력할 수 있다. 만약 분류기가 충분히 공정하지 않아서 분류기가 출력된 레이블의 예측값 와 민감한 속성 Z가 독립적이지 않을 경우, 구분자는 의 경향성에 기초하여 Z를 예측 또는 판별해낼 수 있을 것이다. 한편, 만약 분류기의 공정성이 충분히 확보되어서 분류기가 출력된 레이블의 예측값 와 민 감한 속성 Z가 독립적일 경우, 구분자는 의 경향성에 기초하여 Z를 예측 또는 판별해낼 수 없을 것이다. 분류기는 확률변수 가 확률변수 Z와 독립적일 수 있도록 하는 방향으로 학습을 수행할 수 있다. 구분자 는 확률변수 로부터 확률변수 Z를 예측해낼 수 있도록 하는 방향으로 학습을 수행할 수 있다. 확률변수 가 확률변수 Z가 독립적일 경우 확률변수 로부터 확률변수 Z를 예측해낼 수 없기 때문에, 분류기와 구 분자는 서로 상반된 목표를 가지는 경쟁적인 관계인 것으로 볼 수 있다. 분류기 및 구분자는 서로 상반된 목표를 가지고 학습을 반복 수행함으로써 서로의 성능이 향상되도록 유도할 수 있다. 즉, 분류기의 공정성이 향상되어 확률변수 가 확률변수 Z 간의 독립성이 향상될수록, 구 분자는 로부터 확률변수 Z를 예측/판별해내는 성능이 더욱 향상될 수 있다. 또는, 구분자가 로부 터 확률변수 Z를 예측/판별해내는 성능이 향상될수록, 이러한 구분자의 예측/판별을 용이하지 않도록 하기 위해 분류기가 확률변수 Z로부터 독립적인 확률변수 확률변수 를 출력하는 성능이 더욱 향상될 수 있다. 이를 위해, 수학식 9와 같은 손실함수 L이 정의될 수 있다. 손실함수 L은 연산/예측 성능을 위한 손실함수항 L1 과, 공정성을 위한 손실함수항 L2의 조합으로 정의될 수 있다. 손실함수 L은 수학식 11과 같이 정의된 상호의존 정보를 최소화하는 방향으로 설정될 수 있다. L1과 L2는 각각 수학식 10 및 12와 같이 정의될 수 있다. 기계학습 장치의 분류기 및 구분자 간의 상호 경쟁적인 반복 학습을 통하여, 분류기가 민 감한 정보와 독립적인 예측값을 출력해내는 성능이 향상될 수 있다. 따라서 분류기 또는 기계학습 장치 의 공정성이 향상될 수 있다. 분류기를 통한 학습과 구분자를 통한 학습의 반복 수행은, 경사하강법에 기초하여 수행될 수 있다. 분류기 및 구분자의 계층들 또는 노드들 간의 연결을 구성하는 가중치 파라미터들은, 분류기 및 구분자에서 출력되는 및 에 대한 평가 결과에 따라 업데이트될 수 있다. 분류기를 통한 학습과 구분자를 통한 학습의 반복 수행은, 교차(alternating) 경사하강법에 기초하여 수행될 수 있다. 분류기 및 구분자의 계층들 또는 노드들 간의 연결을 구성하는 가중치 파라미터들은, 분류기 및 구분자에서 출력되는 및 에 대한 평가 결과에 따라 업데이트될 수 있 다. 여기서, 분류기에서 1회 학습 및 업데이트가 수행되는 동안, 구분자에서 k회 학습 및 업데이트가 수행될 수 있다. 분류기를 통한 학습 및 업데이트의 수행 횟수와 구분자를 통한 학습의 수행 횟수는 1:k (k는 2 이상의 자연수) 비율을 가질 수 있다. 분류기는 학습을 통하여 연산/예측 모델을 생성할 수 있다. 생성된 연산/예측 모델은 일반적 정보 x 또는 그 확률변수인 X와, 민감한 정보 z 또는 그 확률변수인 Z를 입력받아서, 정답값 y의 예측값 확률변수 Y의 예측 값 를 출력할 수 있다. 생성된 연산/예측 모델은 x 또는 X를 입력받아서 정답값 y의 예측값 또는 그 확률변 수들인 Y의 예측값 를 출력할 수 있다. 분류기의 공정성이 확보되었을 경우, 출력되는 또는 는 민감한 정 보 z 또는 Z와 독립적일 수 있다. 이를테면, 데이터 셋은 범죄자(또는 재소자들 등)의 정보를 포함할 수 있다. x는 각 범죄자들의 일반적 정보에 해당하거나, 또는 일반적 정보에 대응되는 특징 벡터에 해당할 수 있다. y는 각 범죄자들의 일정 기간(이를테면, 3년) 내 재범률에 해당하는 레이블일 수 있다. z는 각 범죄자들의 인종 정보에 해당할 수 있다. 기계학습 장치는 주어진 데이터 셋에 대한 학습을 수행하여, 재범률 연산/예측 모델을 생성할 수 있다. 생성된 예측 모델은, 추가로 제공되는 데이터의 x 및 z 값을 입력받아서 재범률 y의 예측값을 출력할 수 있다. 즉, 각 범죄자들의 일반적 정보 및 인종 정보를 입력 받아서 해당 범죄자의 재범률을 예측하여 출력할 수 있다. 공정성 이 확보되었을 경우, 연산/예측 모델이 예측하는 재범률 정보는 인종 정보와 무관하게 일반적 정보로부터만 기 초하여 출력될 것으로 기대될 수 있다. 이는 이해를 돕기 위한 일 실시예일 뿐이며, 본 발명에 따라 구축되는 연산/예측 모델은 이에 국한되지 않는다. 이를테면, 연산/예측 모델은 채용 절차에서 성별과 무관한 지원자 평 가를 수행하기 위한 연산/예측 모델에 해당할 수 있으며, 기타 다양한 '민감한 정보와 무관한 평가/연산 결과를 출력하기 위한' 예측/연산 모델 또는 기계학습 장치를 필요로 하는 다양한 현장에서 적용될 수 있다. 본 발명의 일 실시예에 따르면, 상호 의존 정보에 기반하여 학습을 수행하는 기계학습 방법 및 장치가 제공될 수 있다. 이에 따라, 기계학습을 통해 구축된 예측모델의 예측값과 민감한 속성 간의 독립성이 용이하게 확보될 수 있다. 본 발명의 일 실시예에 따르면, 기계학습 장치는 민감하지 않은 일반적 정보들과 민감한 정보를 입력받아서 레 이블의 예측값을 출력하는 분류기와, 분류기에서 출력된 레이블의 예측값을 입력받아서 민감한 정보의 예측값을 출력하는 구분자를 포함할 수 있다. 분류기와 구분자의 상호 경쟁적인 학습을 통하여, 분류기가 민감한 정보와 독립적인 예측값을 출력해내는 성능이 향상될 수 있다. 따라서 본 발명에 따른 분류기 또는 기계학습 장치의 공 정성이 향상될 수 있다. 본 발명에 따른 방법들은 다양한 컴퓨터 수단을 통해 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 컴퓨터 판독 가능 매체에 기록되는 프로그램 명령은 본 발명을 위해 특별 히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 매체의 예에는 롬(rom), 램(ram), 플래시 메모리(flash memory) 등과 같이 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러(compiler)에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터(interpreter) 등을 사용해서 컴퓨터에 의해 실 행될 수 있는 고급 언어 코드를 포함한다. 상술한 하드웨어 장치는 본 발명의 동작을 수행하기 위해 적어도 하 나의 소프트웨어 모듈로 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 이상 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6"}
{"patent_id": "10-2020-0185350", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 기계학습 장치의 일 실시예를 도시한 블록도이다. 도 2는 기계학습 장치에 포함된 인공 신경망(artificial neural network, ANN)의 일 실시예를 도시한 개념도이 다. 도 3는 생성적 적대 신경망(generative adversarial network, GAN) 방식에 따른 기계학습 방법의 일 실시예를 설명하기 위한 개념도이다. 도 4는 본 발명에 따른 기계학습 장치에서 풀고자 하는 최적화 문제의 일 실시예를 설명하기 위한 예시도이다. 도 5는 본 발명에 따른 분류기(classifier)의 일 실시예를 도식화한 개념도이다. 도 6은 본 발명예 따른 상호의존정보에 기반한 기계학습 방법 및 장치의 일 실시예를 설명하기 위한 개념도이다."}
