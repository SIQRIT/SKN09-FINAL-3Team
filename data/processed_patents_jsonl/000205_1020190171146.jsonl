{"patent_id": "10-2019-0171146", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0079060", "출원번호": "10-2019-0171146", "발명의 명칭": "화자 음성 위조 검사 방법 및 장치", "출원인": "엘지전자 주식회사", "발명자": "송정민"}}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 인식 인공지능 기술을 활용한 화자 음성 위조 검사 방법으로서, 위조 검사 기준을 위한 화자의 음성을 등록하는 단계; 음성 위조를 검증할 검증 대상 음성을 수신하는 단계; 등록된 상기 화자의 음성과 수신된 상기 검증 대상 음성이 동일인의 음성인지 판단하는 단계; 및 등록된 상기 화자의 음성과 수신된 상기 검증 대상 음성이 동일인의 것으로 판단되면, 상기 검증 대상 음성이위조인지 판단하는 단계를 포함하고, 상기 검증 대상 음성이 위조인지 판단하는 단계는, 유사도 판단 신경망을 통해 상기 화자의 음성 데이터에서 추출한 화자 음성 지문(voice fingerprint)과 상기 검증 대상 음성의 데이터에서 추출한 검증 대상 음성 지문의 유사도가 임계값 이상인 경우 상기 검증 대상 음성이위조 음성인 것으로 판단하는 단계를 포함하는, 화자 음성 위조 검사 방법."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 화자의 음성을 등록하는 단계는, 상기 화자의 음성 데이터를 음성 주파수로 추출하는 단계; 상기 음성 주파수에서 추출한 스펙트럼 에너지 분포를 분석하는 단계; 분석된 상기 에너지 분포에서 평균 에너지보다 큰 에너지를 가지는 복수의 스펙트럼 피크(Spectral Peak)를 추출하는 단계; 및추출한 상기 스펙트럼 피크를 기초로 상기 화자 음성 지문(voice fingerprint)을 추출하는 단계를 포함하는, 화자 음성 위조 검사 방법."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 화자 음성 지문을 추출하는 단계는, 상기 화자 음성 지문에서 복수의 음성 지문 요소를 추출하는 단계를 포함하고, 상기 복수의 음성 지문 요소를 추출하는 단계는, 상기 복수의 스펙트럼 피크에서 최대의 에너지를 가지는 제1 스펙트럼 피크와 상기 제1 스펙트럼 피크의 에너지보다 작은 에너지를 가지는 스펙트럼 피크 각각과의 시간 차이를 측정하는 단계를 포함하는, 화자 음성 위조 검사 방법."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "공개특허 10-2021-0079060-3-제1항에 있어서, 상기 검증 대상 음성이 위조인지 판단하는 단계는, 상기 검증 대상 음성의 데이터를 음성 주파수로 추출하는 단계; 상기 음성 주파수에서 추출한 스펙트럼 에너지 분포를 분석하는 단계; 분석된 상기 에너지 분포에서 평균 에너지보다 큰 에너지를 가지는 복수의 스펙트럼 피크를 추출하는 단계; 추출한 상기 스펙트럼 피크를 기초로 검증 대상 음성 지문을 추출하는 단계를 포함하는, 화자 음성 위조 검사 방법."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 검증 대상 음성 지문을 추출하는 단계는, 상기 검증 대상 음성 지문에서 복수의 음성 지문 요소를 추출하는 단계를 포함하고, 상기 복수의 음성 지문 요소를 추출하는 단계는, 상기 복수의 스펙트럼 피크에서 최대의 에너지를 가지는 제1 스펙트럼 피크와 상기 제1 스펙트럼 피크의 에너지보다 작은 에너지를 가지는 스펙트럼 피크 각각과의 시간 차이를 측정하는 단계를 포함하는, 화자 음성 위조 검사 방법."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 동일인의 음성인지 판단하는 단계는, 상기 화자의 음성 데이터에서 상기 화자의 음성 특징을 추출하는 단계; 상기 검증 대상 음성의 데이터에서 상기 검증 대상 음성의 음성 특징을 추출하는 단계;상기 화자의 음성 특징과 상기 검증 대상 음성의 음성 특징이 미리 저장된 임계값 이상 유사한 경우 상기 화자와 상기 검증 대상 음성의 화자가 동일인이라고 판단하는 단계를 포함하는, 화자 음성 위조 검사 방법."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 화자의 음성 특징을 추출하는 단계는, 상기 화자의 발화 속도, 발화 음높이, 음성 데이터에서 추출한 음성 주파수 영역(domain) 중 적어도 어느 하나의 통계적인 특징을 추출하는 단계를 포함하는, 화자 음성 위조 검사 방법."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서, 상기 검증 대상 음성의 음성 특징을 추출하는 단계는, 공개특허 10-2021-0079060-4-상기 검증 대상 음성의 발화 속도, 발화 음높이, 음성 데이터에서 추출한 음성 주파수 영역(domain) 중 적어도어느 하나의 통계적인 특징을 추출하는 단계를 포함하는, 화자 음성 위조 검사 방법."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서, 상기 화자와 상기 검증 대상 음성의 화자가 동일인이라고 판단하는 단계는, 상기 화자 음성 지문과 상기 검증 대상 음성 지문의 유사도가 미리 설정된 임계치 이하인 경우, 상기 검증 대상음성의 위조 판단을 중지하는 단계를 포함하는, 화자 음성 위조 검사 방법."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "음성 인식 인공지능 기술을 활용한 화자 음성 위조 검사 장치로서, 프로세서들; 및 상기 프로세서들에 연결된 메모리를 포함하고, 상기 메모리는, 상기 프로세서들에 의해 수행되고, 음성 위조를 검증할 검증 대상 음성의 음성을 수신하고, 등록된 상기 화자의음성과 수신된 상기 검증 대상 음성이 동일인인지 판단하고, 등록된 상기 화자의 음성과 수신된 상기 검증 대상음성이 동일인인 것으로 판단되면, 상기 검증 대상 음성의 음성이 위조인지 판단하기 위해, 유사도 판단 신경망을 통해 상기 화자의 음성 데이터에서 추출한 화자 음성 지문(voice fingerprint)과 상기 검증 대상 음성의 음성 데이터에서 추출한 검증 대상 음성의 음성 지문의 유사도가 임계값 이상인 경우 상기 검증 대상 음성의 발화음성이 위조 음성인 것으로 판단하기 위한 명령들을 저장하는, 화자 음성 위조 검사 장치."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 메모리는, 상기 화자의 음성 데이터를 음성 주파수로 추출하고, 상기 음성 주파수에서 추출한 스펙트럼 에너지 분포를 분석하며, 분석된 상기 에너지 분포에서 평균 에너지보다 큰 에너지를 가지는 복수의 스펙트럼 피크(SpectralPeak)를 추출하고, 추출한 상기 스펙트럼 피크를 기초로 상기 화자 음성 지문(voice fingerprint)을 추출하기위한 명령들을 저장하는, 화자 음성 위조 검사 장치."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 메모리는, 상기 화자 음성 지문에서 복수의 화자 음성 지문 요소를 추출하기 위해 상기 스펙트럼 피크에서 에너지가 최대인 제1 스펙트럼 피크와 상기 제1 스펙트럼 피크의 에너지보다 작은 에너지를 포함하는 복수의 스펙트럼 피크공개특허 10-2021-0079060-5-각각과의 시간 차이를 측정하기 위한 명령들을 저장하는, 화자 음성 위조 검사 장치."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서, 상기 메모리는, 상기 검증 대상 음성의 음성 데이터를 음성 주파수로 추출하고, 상기 음성 주파수에서 추출한 스펙트럼 에너지분포를 분석한 뒤, 분석된 상기 에너지 분포에서 평균 에너지보다 큰 에너지를 가지는 복수의 스펙트럼 피크를추출한 후 추출한 상기 스펙트럼 피크를 기초로 검증 대상 음성의 음성 지문을 추출하기 위한 명령들을 저장하는, 화자 음성 위조 검사 장치."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 메모리는, 상기 검증 대상 음성의 음성 지문에서 복수의 검증 대상 음성의 음성 지문 요소를 추출하고, 상기 복수의 검증대상 음성의 음성 지문 요소를 추출하면, 상기 스펙트럼 피크에서 에너지가 최대인 제1 스펙트럼 피크와 상기제1 스펙트럼 피크의 에너지보다 작은 에너지를 포함하는 복수의 스펙트럼 피크 각각과의 시간 차이를 측정하기위한 명령들을 포함하는, 화자 음성 위조 검사 장치."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서, 상기 메모리는, 상기 화자의 음성 데이터에서 상기 화자의 음성 특징을 추출하고, 상기 검증 대상 음성의 음성 데이터에서 상기검증 대상 음성의 음성 특징을 추출하면, 상기 화자의 음성 특징과 상기 검증 대상 음성의 음성 특징이 미리 저장된 임계값 이상인 경우 상기 화자와 상기 검증 대상 음성이 동일인이라고 판단하기 위한 명령들을 포함하는, 화자 음성 위조 검사 장치."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 메모리는, 상기 화자의 발화 속도, 발화 음높이, 음성 데이터에서 추출한 음성 주파수 영역(domain) 중 적어도 어느 하나의 통계적인 특징을 추출하기 위한 명령들을 포함하는, 화자 음성 위조 검사 장치."}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "공개특허 10-2021-0079060-6-제15항에 있어서, 상기 메모리는, 상기 검증 대상 음성의 발화 속도, 발화 음높이, 음성 데이터에서 추출한 음성 주파수 영역(domain) 중 적어도어느 하나의 통계적인 특징을 추출하기 위한 명령들을 포함하는,"}
{"patent_id": "10-2019-0171146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서, 상기 메모리는, 상기 화자 음성 지문과 상기 검증 대상 음성의 음성 지문 유사도가 임계값 이하이고, 상기 화자의 음성 특징과상기 검증 대상 음성의 음성 특징이 미리 저장된 임계값 이상인 경우 상기 검증 대상 음성이 동일한 화자가 다른 시점에서 발화된 음성인 것으로 판단하기 위한 명령들을 포함하는, 화자 음성 위조 검사 장치."}
{"patent_id": "10-2019-0171146", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 화자 음성 위조 검사 방법 및 장치는, 화자의 실제 목소리와 화자의 음성이 녹음된 녹음 파일을 구분하여 제3자가 녹음 파일을 이용하여 화자 인증을 시도하는 것을 방지하도록 한다. 또한, 음성 인증 시, 화자가 한번의 발화를 통해서도 음성 인증이 가능하도록 음성 인식 인공 지능 기술을 선택하여 활용할 수 있고, 화자 음성 수신은 5G 네트워크를 이용한 사물 인터넷 환경에서 이루어질 수 있다."}
{"patent_id": "10-2019-0171146", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 한번의 발화로 화자의 음성과 화자의 음성을 녹음한 녹음 음성의 차이를 추출하여 실제 화자의 목소 리 특성을 기초하여 음성 위조를 검사하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2019-0171146", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이하에서 기술되는 내용은 본 발명의 실시 예와 관련되는 배경 정보를 제공할 목적으로 기재된 것일 뿐이고, 기 술되는 내용들이 당연하게 종래기술을 구성하는 것은 아니다. 바이오 인식이란, 타인이 모방할 수 없는 신체정보를 식별하고 비교해 타인과 구분하고 인증하는 기술을 의미한 다. 다양한 바이오 인식 기술 중에서도 최근 음성인식기술에 관한 연구가 활발히 진행되고 있다. 음성인식기술 은 크게 '음성인식'과 '화자인증'으로 나뉜다. 음성 인식은, 어떤 사람이 이야기하든 상관없이 불특정 다수가 말한 '내용'을 알아듣는 것이다. 반면, 화자인증은 '누가' 이 이야기를 했는지를 구별하는 것이다. 화자인증 기술의 일 예시로, '목소리 인증 서비스'가 있다. 만약, 목소리만으로 '누구'인지 주체를 정확하고 신 속하게 확인할 수 있다면, 각종 분야에서 개인인증을 위해 필요했던 기존의 방법들, 예를 들어, 로그인 후 비밀 번호 입력, 공인인증서 인증 등과 같은 번거로운 단계를 줄여 이용자의 편의를 제공할 수 있을 것이다. 화자인증 기술은 최초 화자의 목소리를 등록한 뒤 이후, 인증 요청 시마다 화자가 발화한 목소리와 등록된 목소 리와 비교하여 일치 여부로 인증을 수행한다. 화자가 목소리를 등록하면, 목소리에서 특징을 추출하며, 특징은 수초(ex, 10sec) 단위로 추출할 수 있다. 특징은 억양, 말 빠르기 등 다양한 유형으로 추출될 수 있고 이러한 특징을 조합으로 어떤 사람인지 구별할 수 있다. 한편, 화자인증 기술의 핵심은 보안성인데, 등록 화자가 목소리를 등록하거나 인증할 때 한번 이상의 발화를 통 해 인증이 이루어지는 경우, 화자 인증의 번거로움이 발생한다. 또한, 인근에 위치하는 제3자가 등록 화자의 목소리를 무단 녹음하고, 해당 녹음파일로 화자인증을 시도하는 경 우 이를 필터링할 수 없다면 화자에게 막대한 피해가 발생하게 되고, 화자인증에 대한 신뢰도는 낮아지는 한계 가 있다. 이와 같이 화자 인증 기술에 있어, 제3자의 무단 녹음에 의한 녹음 파일을 필터링할 수 있는 기술이 요구되고 있다. 이를 구체화한 기술로, 한국등록특허 제 10-1564087호에 따르면, 화자 등록이나 화자 검증 과정에서 입력된 음 성 데이터를 누적하고, 누적된 음성 데이터를 이용해 주변 음향 환경의 변동에 의해 변경되지 않는 화자 검증 기술이 기재되어 있다. 상술된 문헌에는 전체배경모델 GMM 모델을 점진적으로 주변 음향 환경에 적응하도록 하여 화자 검증 성능 및 정 확도를 개선하도록 하는 기술이 기재되어 있으나, 한번의 발화로 인증이 이루어지는 기술까지는 기재되고 있지 않다. 또한, 한국공개특허 제10-2019-0077296호에 따르면, 화자 검증 절차를 통해 화자를 식별 및 인식할 수 있도록 하며, 나아가 도용의 우려 없이 화자 명령을 실행할 수 있도록 하는 기술이 기재되어 있다. 상술된 문헌에서는 화자의 음성 신호에서 화자 특징 벡터를 추출하고, 추출한 화자 특징 벡터를 통해 화자가 등 록된 화자인지를 결정한 뒤 음성 인식 장치와 통신 연결된 다른 장칠 음성 인식 결과를 송신하는 기술이 기재되 어 있다. 그러나, 상술된 문헌에는 한번의 발화로 음성 인식이 결정되는 기술까지는 기재되고 있지 않다. 상술된 바와 같은 한계를 극복하기 위해, 한번의 발화로 음성 인증이 실행되되, 음성 인증을 위한 보안력이 향 상된 기술이 필요하다. 특히, 녹음 시 발생하는 음성의 변형이나 발화한 음성의 백그라운드 사운드의 특성을 추 출하여 음성을 인증하는 방법이 아닌 실제 화자의 목소리 특성을 통한 인증 기술이 필요하다. 한편, 전술한 선행기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다."}
{"patent_id": "10-2019-0171146", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시 예는, 화자의 실제 목소리와 화자의 음성이 녹음된 녹음 파일을 구분하여 제3자가 녹음 파일을 이용하여 화자 인증을 시도하는 것을 방지할 수 있도록 한다. 또한, 본 발명의 실시 예는 음성 인증 시, 화자가 한번의 발화를 통해서도 음성 인증이 가능하도록 하여 음성 인증의 간편성이 향상될 수 있는데 있다. 본 발명의 목적은 이상에서 언급한 과제에 한정되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시 예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발명 의 목적 및 장점들은 청구범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 알 수 있을 것이다."}
{"patent_id": "10-2019-0171146", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 음성 인식 인공지능 기술을 활용한 화자 음성 위조 검사 방법 및 장치는, 화자 음성 위조를 검사하기 위해 복수의 프로세서 및 프로세서들에 의해 수행되는 메모리를 포함할 수 있다. 화자 음성 위조 검사를 위해서는 위조 검사 기준을 위한 화자의 음성을 등록하고, 음성 위조를 검증할 검증 대 상 음성을 수신한 뒤, 등록된 화자의 음성과 수신된 검증 대상 음성이 동일인의 음성인지 판단하고, 등록된 화 자의 음성과 수신된 검증 대상 음성이 동일인의 것으로 판단되면, 검증 대상 음성이 위조인지 판단하는 과정으 로 이루어질 수 있다. 이때, 검증 대상 음성의 음성이 위조인지 판단할 때, 유사도 판단 신경망을 통해 화자의 음성 데이터에서 추출 한 화자 음성 지문(voice fingerprint)과 검증 대상 음성의 데이터에서 추출한 검증 대상 음성 지문의 유사도가 임계값 이상인 경우 검증 대상 음성이 위조 음성인 것으로 판단할 수 있다. 전술한 것 외의 다른 측면, 특징, 이점이 이하의 도면, 청구범위 및 발명의 상세한 설명으로부터 명확해질 것이다."}
{"patent_id": "10-2019-0171146", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 따른 화자 음성 위조 검사 방법 및 장치에 따르면, 화자의 실제 목소리와 화자의 음성이 녹음된 녹음 파일을 구분하여 제3자가 녹음 파일을 이용하여 화자 인증을 시도하는 것을 방지할 수 있게 한다. 구체적으로, 화자가 전자기기를 작동시킬 때 발화한 음성은 발화 시점마다 다른 분포를 가지는 스펙트럼 피크를 생성할 수 있다. 한편, 제3자가 화자가 발화한 음성을 녹음한 음성 파일을 전자기기를 향해 발화시키면 녹음한 음성 파일로부터 스펙트럼 피크를 생성할 수 있다. 이때, 녹음한 음성 파일로부터 생성한 스펙트럼 피크는 앞서 생성된 스펙트럼 피크들 중 어느 하나와 일치하거나 유사하다. 따라서, 녹음한 음성 파일로부터 추출한 녹음한 음성 파일의 음성 지문 요소는 앞서 추출한 어느 하나의 음성 지문 요소와 일부 유사 및/또는 동일한 값을 가지 게 된다. 따라서, 발화한 검증 대상 음성으로부터 추출한 새로움 음성 지문 요소와 화자 음성 지문 요소가 미리 정해진 임계값 이상 유사한 경우 검증 대상 음성이 녹음된 파일이거나 위조된 파일이라고 판단할 수 있다. 또한, 검증 대상 음성이 녹음된 파일이거나 위조된 파일이라고 판단되는 경우 전자기기의 동작이 이루어지지 않 도록 함으로써, 제3자가 전자기기를 사용할 수 없도록 전자기기의 보안이 향상될 수 있다. 더욱이, 화자는 한번의 발화만 실행한다. 이때, 발화된 화자의 음성과 미리 저장된 정보와 매칭하여 발화된 화 자의 음성이 위조된 음성인지를 판단할 수 있다. 따라서, 한번의 발화로 음성 인증이 가능해지므로 음성 인증의 간편성이 향상될 수 있다."}
{"patent_id": "10-2019-0171146", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0171146", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 발명을 보다 상세하게 설명한다. 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며, 여기에서 설명하는 실시 예들에 한정되지 않는다. 이하 실시 예에서는 본 발명을 명확하게 설명하기 위 해서 설명과 직접적인 관계가 없는 부분을 생략하지만, 본 발명의 사상이 적용된 장치 또는 시스템을 구현함에 있어서, 이와 같이 생략된 구성이 불필요함을 의미하는 것은 아니다. 아울러, 명세서 전체를 통하여 동일 또는 유사한 구성요소에 대해서는 동일한 참조번호를 사용한다. 이하의 설명에서 제 1, 제 2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들 은 상기 용어들에 의해 한정되어서는 안 되며, 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 또한, 이하의 설명에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 이하의 설명에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요 소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 이하 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 도 1은 본 발명의 실시 예에 따른 화자 위조 검사를 위한 환경의 예시도이고, 도 2는 본 발명의 실시 예에 따른 화자 위조 검사를 위한 음성 인공 지능 기술을 설명하기 위한 도면이다. 도면을 참조하면, 본 발명의 실시 예에 따른 화자 위조 검사를 위한 환경은 음성 발화 가능한 화자와 화자의 음성을 기초로 발화하는 음성이 위조인지 여부를 검증하려는 검증 대상 음성, 화자 및 검증 대상 음성의 음성을 수신하는 전자기기 및 서버 및 이들이 서로 통신할 수 있도록 하는 네 트워크를 포함할 수 있다. 화자는 전자기기를 향해 “하이 엘지”, “음악 틀어줘” 등과 같은 전자기기의 동작을 제어할 수 있는 음성을 발화할 수 있는 사람을 의미한다. 이때, 화자가 발화하는 음성은 전자기기의 동작이 실행되기 위한 명령어가와, 화자자 발화한 명 령어에 의해 전자기기가 동작할 수 있는지 명령어를 인증하기 위해 전자기기에 저장된 인증어로 구분 될 수 있다. 구체적으로 인증어는 전자기기 동작을 위해 화자 인증 서비스를 이용하려는 사용자(본 발명의 실시 예: 화 자)로부터 발화된 목소리이다. 즉, 인증어는 전자기기를 최초로 동작할 때, 전자기기를 동작시키는 사용자의 목소리, 이후 전자기기를 동작시키기 위한 사용자의 목소리 등이 될 수 있고, 이러한 사용자의 목소리는 전자기기의 데이터 베이스에 저장될 수 있다. 이러한 인증어는 전자기기 사용시 보안을 위해 화자 인증 서비스를 신청하여 승인된 화자의 음성 파일이고, 이후 화자 인증을 요청할 때, 요청되는 음성(본 발명의 실시 예: 검증 대상 음성)과 대조군으로 사용 되어 요청되는 음성이 위조 음성인지 판단할 수 있는 기준이라고 할 수 있다. 화자 및 검증 대상 음성의 음성을 수신할 수 있는 전자기기는 사물 지능 통신(IoT(internet of things), IoE(internet of everything), IoST(internet of small things) 등)을 지원할 수 있으며, M2M(machine to machine) 통신, D2D(device to device) 통신 등을 지원할 수 있다. 또한, 전자기기는 사물 인터넷을 위해 연결된 5G 환경에서 빅데이터, 인공지능(artificial intelligence, AI) 알고리즘 및/또는 기계학습(machine learning) 알고리즘을 이용하여 이미지 변환 방식을 결정할 수 있다. 이러한 전자기기는 전자기기 내에 설치된 마이크를 통해 화자 및 검증 대상 음성이 발화한 음성 데이터를 수신 받을 수 있다. 한편, 전자기기는 화자의 음성 데이터를 기초로 화자 인증이 수행 되어야 하므로, 음성 입력/출력 인터페이스를 포함하고, 사물인터넷(Internet of thing)으로서 임베디드 시스템 (Embedded System)을 포함하도록 구성될 수 있다. 전자기기의 예로는 인공지능 비서 기능을 수행하는 단말 (예: 휴대폰, 태블릿 PC 등)일 수 있다. 전자기기에 화자의 음성을 등록하면, 음성 위조를 검증할 검증 대상 음성의 음성을 수신 받을 수 있다. 이후, 전자기기에서 화자의 음성과 수신된 검증 대상 음성이 동일인이지 판단한 후, 화자와 검증 대상 음성이 동일인으로 판단되면 검증 대상 음성의 음성이 위조 음성인지 판단하는 과정을 통해 음성 위조 과정이 이루어질 수 있다. 구체적으로, 유사도 판단 신경망을 통해 화자의 음성 데이터에서 추출한 화자 음성 지문(voice fingerprint)과 검증 대상 음성의 음성 데이터에서 추출한 검증 대상 음성의 음성 지문의 유사도를 판단한 다. 이때, 화자 음성 지문과 검증 대상 음성의 음성 지문이 미리 설정된 임계값 이상 유사한 경우 검증 대상 음 성이 발화한 음성이 위조 음성인 것으로 판단하게 된다. 이와 같이 위조 음성 파일을 판단하는 기술은 인공 지능을 통해 이루어질 수 있다. 인공 지능 기술은 전자기기 에 적용된 트레이닝 시스템(미도시)에 의해 트레이닝 단계를 거쳐 생성될 수 있다. 트레이닝 시스템을 통해 생성되는 학습 모델은 음성 인식 신경망으로서, 전자기기에 저장되어 있거나 전자 기기에서 수신한 화자의 음성 데이터를 음성 주파수로 추출하기 위해 미리 훈련된 것일 수도 있다. 통상적으로 학습 모델은 별도의 서버 또는 트레이닝 시스템(미도시)에서 트레이닝 단계를 마친 상태에서 화자 의 음성 데이터를 음성 주파수로 추출하기 전자기기에 미리 저장되어 있을 수 있으나, 일부 실시 예 에서 학습 모델은 전자기기에서 추가적으로 트레이닝을 거쳐 업데이트 또는 업그레이드될 수도 있도록 구 현될 수 있다. 한편, 전자기기는 5G 네트워크를 통해 서버와 데이터를 전송하고 수신할 수 있다. 특히 전자기기 는 5G 네트워크를 통해 모바일 브로드밴드(Enhanced Mobile Broadband, eMBB), URLLC(Ultra-reliable and low latency communications) 및 mMTC(Massive Machine-type communications) 중에서 적어도 하나의 서비스를 이용하여 서버와 데이터 통신할 수 있다. eMBB(Enhanced Mobile Broadband)는 모바일 브로드밴드 서비스로, 이를 통해 멀티미디어 콘텐츠, 무선데이터 액 세스 등이 제공된다. 또한, 폭발적으로 증가하고 있는 모바일 트래픽을 수용하기 위한 핫스팟 (hot spot)과 광 대역 커버리지 등 보다 향상된 모바일 서비스가 eMBB를 통해 제공될 수 있다. 핫스팟을 통해 화자 이동성이 작 고 밀도가 높은 지역으로 대용량 트래픽이 수용될 수 있다. 광대역 커버리지를 통해 넓고 안정적인 무선 환경과 화자 이동성이 보장될 수 있다. URLLC(Ultra-reliable and low latency communications) 서비스는 데이터 송수신의 신뢰성과 전송 지연 측면에 서 기존 LTE 보다 훨씬 엄격한 요구사항을 정의하고 있으며, 산업 현장의 생산 프로세스 자동화, 원격 진료, 원 격 수술, 운송, 안전 등을 위한 5G 서비스가 여기에 해당한다. mMTC(Massive Machine-type communications)는 비교적 작은 양의 데이터 전송이 요구되는 전송지연에 민감하지 않은 서비스이다. 센서 등과 같이 일반 휴대폰 보다 훨씬 더 많은 수의 단말들이 동시에 무선액세스 네트워크에 mMTC에 의해 접속할 수 있다. 이 경우, 단말의 통신모듈 가격은 저렴해야 하고, 배터리 교체나 재충전 없이 수 년 동안 동작할 수 있도록 향상된 전력 효율 및 전력 절감 기술이 요구된다. 이와 같이, 본 발명의 실시 예의 전자기기는 화자의 음성이 저장되어 있고, 검증 대상 음성이 발화한 음성 데이터에서 추출한 음성 지문이 위조 음성인지를 판단할 수 있는 인공 지능 기술이 적용된 심층 신 경망 또는 다른 타입의 머신 러닝 모델들과 같은 다양한 학습 모델 또는 이들을 포함하는 기술을 저장하거나 포 함할 수 있다. 설명한 바와 같이 여기서 인공 지능(artificial intelligence, AI)은, 인간의 지능으로 할 수 있는 사고, 학습, 자기계발 등을 컴퓨터가 할 수 있도록 하는 방법을 연구하는 컴퓨터 공학 및 정보기술의 한 분야로, 컴퓨터가 인간의 지능적인 행동을 모방할 수 있도록 하는 것을 의미할 수 있다. 또한, 인공지능은 그 자체로 존재하는 것이 아니라, 컴퓨터 과학의 다른 분야와 직간접으로 많은 관련을 맺고 있다. 특히 현대에는 정보기술의 여러 분야에서 인공지능적 요소를 도입하여, 그 분야의 문제 풀이에 활용하려 는 시도가 매우 활발하게 이루어지고 있다. 머신 러닝(machine learning)은 인공지능의 한 분야로, 컴퓨터에 명시적인 프로그램 없이 배울 수 있는 능력을 부여하는 연구 분야를 포함할 수 있다. 구체적으로 머신 러닝은, 경험적 데이터를 기반으로 학습을 하고 예측을 수행하고 스스로의 성능을 향상시키는 시스템과 이를 위한 알고리즘을 연구하고 구축하는 기술이라 할 수 있다. 머신 러닝의 알고리즘들은 엄격하게 정해진 정적인 프로그램 명령들을 수행하는 것이라기보다, 입력 데이터를 기반으로 예측이나 결정을 이끌어내기 위해 특정한 모델을 구축하는 방식을 취할 수 있다. 이러한 인공신경망의 머신 러닝 방법으로는 자율학습(unsupervised learning)과 지도학습(supervised learning)이 모두 사용될 수 있다. 또한, 머신 러닝의 일종인 딥러닝(deep learning) 기술은 데이터를 기반으로 다단계로 깊은 수준까지 내려가 학 습할 수 있다. 딥러닝은 단계를 높여갈수록 복수의 데이터들로부터 핵심적인 데이터를 추출하는 머신 러닝 알고 리즘의 집합을 나타낼 수 있다. 딥러닝 구조는 인공신경망(ANN)을 포함할 수 있으며, 예를 들어 딥러닝 구조는 CNN(convolutional neural network), RNN(recurrent neural network), DBN(deep belief network) 등 심층신경망(CNN)으로 구성될 수 있다. 본 실시 예에 따른 딥러닝 구조는 공지된 다양한 구조를 이용할 수 있다. 예를 들어, 본 발명에 따른 딥 러닝 구조는 CNN, RNN, DBN 등을 포함할 수 있다. RNN은, 자연어 처리 등에 많이 이용되고 있으며, 시간의 흐름 에 따라 변하는 시계열 데이터(time-series data) 처리에 효과적인 구조로 매 순간마다 레이어를 쌓아 올려 인 공신경망 구조를 구성할 수 있다. DBN은 딥러닝 기법인 RBM(restricted boltzman machine)을 다층으로 쌓아 구 성되는 딥러닝 구조를 포함할 수 있다. RBM 학습을 반복하여, 일정 수의 레이어가 되면 해당 개수의 레이어를 가지는 DBN을 구성할 수 있다. CNN은 사람이 물체를 인식할 때 물체의 기본적인 특징들을 추출한 다음 뇌 속에 서 복잡한 계산을 거쳐 그 결과를 기반으로 물체를 인식한다는 가정을 기반으로 만들어진 사람의 뇌 기능을 모 사한 모델을 포함할 수 있다. 한편, 인공신경망의 학습은 주어진 입력에 대하여 원하는 출력이 나오도록 노드간 연결선의 웨이트(weight)를 조정(필요한 경우 바이어스(bias) 값도 조정)함으로써 이루어질 수 있다. 또한, 인공신경망은 학습에 의해 웨이 트(weight) 값을 지속적으로 업데이트시킬 수 있다. 또한, 인공신경망의 학습에는 역전파(back propagation) 등 의 방법이 사용될 수 있다. 본 발명의 실시 예에서 용어 '머신 러닝'은 용어 '기계 학습'과 혼용되어 사용될 수 있다. 기계 학습에서 데이터를 어떻게 분류할 것인가를 놓고, 많은 기계 학습 알고리즘이 개발되었다. 의사결정나무 (Decision Tree)나 베이지안 망(Bayesian network), 서포트벡터머신(SVM: support vector machine), 그리고 인 공 신경망(ANN: Artificial Neural Network) 등이 대표적이다. 의사결정나무는 의사결정규칙(Decision Rule)을 나무구조로 도표화하여 분류와 예측을 수행하는 분석방법이다. 베이지안 망은 다수의 변수들 사이의 확률적 관계(조건부독립성: conditional independence)를 그래프 구조로 표현하는 모델이다. 베이지안 망은 비지도 학습(unsupervised learning)을 통한 데이터마이닝(data mining)에 적합하다. 서포트벡터머신은 패턴인식과 자료분석을 위한 지도 학습(supervised learning)의 모델이며, 주로 분류와 회귀 분석을 위해 사용한다. 인공신경망은 생물학적 뉴런의 동작원리와 뉴런간의 연결 관계를 모델링한 것으로 노드(node) 또는 처리 요소 (processing element)라고 하는 다수의 뉴런들이 레이어(layer) 구조의 형태로 연결된 정보처리 시스템이다. 인공 신경망은 기계 학습에서 사용되는 모델로써, 기계학습과 인지과학에서 생물학의 신경망(동물의 중추신경계 중 특히 뇌)에서 영감을 얻은 통계학적 학습 알고리즘이다. 구체적으로 인공신경망은 시냅스(synapse)의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시냅 스의 결합 세기를 변화시켜, 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 용어 인공신경망은 용어 뉴럴 네트워크(Neural Network)와 혼용되어 사용될 수 있다. 인공신경망은 복수의 레이어(layer)를 포함할 수 있고, 레이어들 각각은 복수의 뉴런(neuron)을 포함할 수 있다. 또한 인공신경망은 뉴런과 뉴런을 연결하는 시냅스를 포함할 수 있다. 인공 신경망은 일반적으로 다음의 세가지 인자, 즉 다른 레이어의 뉴런들 사이의 연결 패턴 연결의 가 중치를 갱신하는 학습 과정 이전 레이어로부터 수신되는 입력에 대한 가중 합으로부터 출력값을 생성하는 활성화 함수에 의해 정의될 수 있다. 인공 신경망은, CNN(Deep Neural Network), RNN(Recurrent Neural Network), BRCNN(Bidirectional Recurrent Deep Neural Network), MLP(Multilayer Perceptron), CNN(Convolutional Neural Network)와 같은 방식의 네트 워크 모델들을 포함할 수 있으나, 이에 한정되지 않는다. 본 명세서에서 용어 '레이어'는 용어 '계층'과 혼용되어 사용될 수 있다. 인공신경망은 계층 수에 따라 단층 신경망(Single-Layer Neural Networks)과 다층 신경망(Multi-Layer Neural Networks)으로 구분된다. 일반적인 단층 신경망은, 입력층과 출력층으로 구성된다. 또한 일반적인 다층 신경망은 입력층(Input Layer)과 하나 이상의 은닉층(Hidden Layer), 출력층(Output Layer)으로 구성된다. 입력층은 외부의 자료들을 받아들이는 층으로서, 입력층의 뉴런 수는 입력되는 변수의 수와 동일하며, 은닉층은 입력층과 출력층 사이에 위치하며 입력층으로부터 신호를 받아 특성을 추출하여 출력층으로 전달한다. 출력층은 은닉층으로부터 신호를 받고, 수신한 신호에 기반한 출력 값을 출력한다. 뉴런간의 입력신호는 각각의 연결강도 (가중치)와 곱해진 후 합산되며 이 합이 뉴런의 임계치보다 크면 뉴런이 활성화되어 활성화 함수를 통하여 획득 한 출력값을 출력한다. 한편 입력층과 출력 층 사이에 복수의 은닉층을 포함하는 심층 신경망은, 기계 학습 기술의 한 종류인 딥 러닝 을 구현하는 대표적인 인공 신경망일 수 있다. 한편 용어 '딥 러닝'은 용어 '심층 학습'과 혼용되어 사용될 수 있다. 인공 신경망은 훈련 데이터(training data)를 이용하여 학습(training)될 수 있다. 여기서 학습이란, 입력 데이 터를 분류(classification)하거나 회귀분석(regression)하거나 군집화(clustering)하는 등의 목적을 달성하기 위하여, 학습 데이터를 이용하여 인공 신경망의 파라미터(parameter)를 결정하는 과정을 의미할 수 있다. 인공 신경망의 파라미터의 대표적인 예시로써, 시냅스에 부여되는 가중치(weight)나 뉴런에 적용되는 편향(bias)을 들 수 있다. 훈련 데이터에 의하여 학습된 인공 신경망은, 입력 데이터를 입력 데이터가 가지는 패턴에 따라 분류하거나 군 집화 할 수 있다. 한편 훈련 데이터를 이용하여 학습된 인공 신경망을, 본 명세서에서는 학습 모델(a trained model)이라 명칭 할 수 있다. 다음은 인공 신경망의 학습 방식에 대하여 설명한다. 인공 신경망의 학습 방식은 크게, 지도 학습, 비 지도 학습, 준 지도 학습(Semi-Supervised Learning), 강화 학 습(Reinforcement Learning)으로 분류될 수 있다. 지도 학습은 훈련 데이터로부터 하나의 함수를 유추해내기 위한 기계 학습의 한 방법이다. 그리고 이렇게 유추되는 함수 중, 연속적인 값을 출력하는 것을 회귀분석(Regression)이라 하고, 입력 벡터의 클래스(class)를 예측하여 출력하는 것을 분류(Classification)라고 할 수 있다. 지도 학습에서는, 훈련 데이터에 대한 레이블(label)이 주어진 상태에서 인공 신경망을 학습시킨다. 여기서 레이블이란, 훈련 데이터가 인공 신경망에 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결 과 값)을 의미할 수 있다. 본 명세서에서는 훈련 데이터가 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과값)을 레이블 또 는 레이블링 데이터(labeling data)이라 명칭 한다. 또한 본 명세서에서는, 인공 신경망의 학습을 위하여 훈련 데이터에 레이블을 설정하는 것을, 훈련 데이터에 레 이블링 데이터를 레이블링(labeling) 한다고 명칭 한다. 이 경우 훈련 데이터와 훈련 데이터에 대응하는 레이블)은 하나의 트레이닝 셋(training set)을 구성하고, 인공 신경망에는 트레이닝 셋의 형태로 입력될 수 있다. 한편 훈련 데이터는 복수의 특징(feature)을 나타내고, 훈련 데이터에 레이블이 레이블링 된다는 것은 훈련 데 이터가 나타내는 특징에 레이블이 달린다는 것을 의미할 수 있다. 이 경우 훈련 데이터는 입력 객체의 특징을 벡터 형태로 나타낼 수 있다. 인공 신경망은 훈련 데이터와 레이블링 데이터를 이용하여, 훈련 데이터와 레이블링 데이터의 연관 관계에 대한 함수를 유추할 수 있다. 그리고, 인공 신경망에서 유추된 함수에 대한 평가를 통해 인공 신경망의 파라미터가결정(최적화)될 수 있다. 비 지도 학습은 기계 학습의 일종으로, 훈련 데이터에 대한 레이블이 주어지지 않는다. 구체적으로, 비 지도 학습은, 훈련 데이터 및 훈련 데이터에 대응하는 레이블의 연관 관계 보다는, 훈련 데이터 자체에서 패턴을 찾아 분류하도록 인공 신경망을 학습시키는 학습 방법일 수 있다. 비 지도 학습의 예로는, 군집화 또는 독립 성분 분석(Independent Component Analysis)을 들 수 있다. 본 명세서에서 용어 '군집화'는 용어 '클러스터링'과 혼용되어 사용될 수 있다. 비지도 학습을 이용하는 인공 신경망의 일례로 생성적 적대 신경망(GAN: Generative Adversarial Network), 오 토 인코더(AE: Autoencoder)를 들 수 있다. 생성적 적대 신경망이란, 생성기(generator)와 판별기(discriminator), 두 개의 서로 다른 인공지능이 경쟁하며 성능을 개선하는 머신 러닝 방법이다. 이 경우 생성기는 새로운 데이터를 창조하는 모형으로, 원본 데이터를 기반으로 새로운 데이터를 생성할 수 있 다. 또한 판별기는 데이터의 패턴을 인식하는 모형으로, 입력된 데이터가 원본 데이터인지 또는 생성기에서 생성한 새로운 데이터인지 여부를 감별하는 역할을 수행할 수 있다. 그리고 생성기는 판별기를 속이지 못한 데이터를 입력 받아 학습하며, 판별기는 생성기로부터 속은 데이터를 입 력 받아 학습할 수 있다. 이에 따라 생성기는 판별기를 최대한 잘 속이도록 진화할 수 있고, 판별기는 원본 데 이터와 생성기에 의해 생성된 데이터를 잘 구분하도록 진화할 수 있다. 오토 인코더는 입력 자체를 출력으로 재현하는 것을 목표로 하는 신경망이다. 오토 인코더는 입력층, 적어도 하나의 은닉층 및 출력층을 포함한다. 이 경우 은닉 계층의 노드 수가 입력 계층의 노드 수보다 적으므로 데이터의 차원이 줄어들게 되며, 이에 따라 압축 또는 인코딩이 수행되게 된다. 또한 은닉 계층에서 출력한 데이터는 출력 계층으로 들어간다. 이 경우 출력 계층의 노드 수는 은닉 계층의 노 드 수보다 많으므로, 데이터의 차원이 늘어나게 되며, 이에 따라 압축 해제 또는 디코딩이 수행되게 된다. 한편 오토 인코더는 학습을 통해 뉴런의 연결 강도를 조절함으로써 입력 데이터가 은닉층 데이터로 표현된다. 은닉층에서는 입력층보다 적은 수의 뉴런으로 정보를 표현하는데 입력 데이터를 출력으로 재현할 수 있다는 것 은, 은닉층이 입력 데이터로부터 숨은 패턴을 발견하여 표현했다는 것을 의미할 수 있다. 준 지도 학습은 기계 학습의 일종으로, 레이블이 주어진 훈련 데이터와 레이블이 주어지지 않은 훈련 데이터를 모두 사용하는 학습 방법을 의미할 수 있다. 준 지도 학습의 기법 중 하나로, 레이블이 주어지지 않은 훈련 데이터의 레이블을 추론한 후 추론된 라벨을 이 용하여 학습을 수행하는 기법이 있으며, 이러한 기법은 레이블링에 소요되는 비용이 큰 경우에 유용하게 사용될 수 있다. 강화 학습은, 에이전트(Agent)가 매 순간 어떤 행동을 해야 좋을지 판단할 수 있는 환경이 주어진다면, 데이터 없이 경험으로 가장 좋을 길을 찾을 수 있다는 이론이다. 강화 학습은 주로 마르코프 결정 과정(MDP: Markov Decision Process)에 의하여 수행될 수 있다. 마르코프 결정 과정을 설명하면, 첫 번째로 에이전트가 다음 행동을 하기 위해 필요한 정보들이 구성된 환경이 주어지며, 두 번째로 그 환경에서 에이전트가 어떻게 행동할지 정의하고, 세 번째로 에이전트가 무엇을 잘하면 보상(reward)을 주고 무엇을 못하면 벌점(penalty)을 줄지 정의하며, 네 번째로 미래의 보상이 최고점에 이를 때까지 반복 경험하여 최적의 정책(policy)을 도출하게 된다. 인공 신경망은 모델의 구성, 활성 함수(Activation Function), 손실 함수(Loss Function) 또는 비용 함수(Cost Function), 학습 알고리즘, 최적화 알고리즘 등에 의해 그 구조가 특정되며, 학습 전에 하이퍼파라미터 (Hyperparameter)가 미리 설정되고, 이후에 학습을 통해 모델 파라미터(Model Parameter)가 설정되어 내용이 특 정될 수 있다.예컨대, 인공 신경망의 구조를 결정하는 요소에는 은닉층의 개수, 각 은닉층에 포함된 은닉 노드의 개수, 입력 특징 벡터(Input Feature Vector), 대상 특징 벡터(Target Feature Vector) 등이 포함될 수 있다. 하이퍼파라미터는 모델 파라미터의 초기값 등과 같이 학습을 위하여 초기에 설정하여야 하는 여러 파라미터들을 포함한다. 그리고, 모델 파라미터는 학습을 통하여 결정하고자 하는 여러 파라미터들을 포함한다. 예컨대, 하이퍼파라미터에는 노드 간 가중치 초기값, 노드 간 편향 초기값, 미니 배치(Mini-batch) 크기, 학습 반복 횟수, 학습률(Learning Rate) 등이 포함될 수 있다. 그리고, 모델 파라미터에는 노드 간 가중치, 노드 간 편향 등이 포함될 수 있다. 손실 함수는 인공 신경망의 학습 과정에서 최적의 모델 파라미터를 결정하기 위한 지표(기준)로 이용될 수 있다. 인공 신경망에서 학습은 손실 함수를 줄이기 위하여 모델 파라미터들을 조작하는 과정을 의미하며, 학습 의 목적은 손실 함수를 최소화하는 모델 파라미터를 결정하는 것으로 볼 수 있다. 손실 함수는 주로 평균 제곱 오차(MSE: Mean Squared Error) 또는 교차 엔트로피 오차(CEE, Cross Entropy Error)를 사용할 수 있으며, 본 발명이 이에 한정되지는 않는다. 교차 엔트로피 오차는 정답 레이블이 원 핫 인코딩(one-hot encoding)된 경우에 사용될 수 있다. 원 핫 인코딩 은 정답에 해당하는 뉴런에 대하여만 정답 레이블 값을 1로, 정답이 아닌 뉴런은 정답 레이블 값이 0으로 설정 하는 인코딩 방법이다. 머신 러닝 또는 딥 러닝에서는 손실 함수를 최소화하기 위하여 학습 최적화 알고리즘을 이용할 수 있으며, 학습 최적화 알고리즘에는 경사 하강법(GD: Gradient Descent), 확률적 경사 하강법(SGD: Stochastic Gradient Descent), 모멘텀(Momentum), NAG(Nesterov Accelerate Gradient), Adagrad, AdaDelta, RMSProp, Adam, Nadam 등이 있다. 경사 하강법은 현재 상태에서 손실 함수의 기울기를 고려하여 손실 함수값을 줄이는 방향으로 모델 파라미터를 조정하는 기법이다. 모델 파라미터를 조정하는 방향은 스텝(step) 방향, 조정하는 크기는 스텝 사이즈(size)라고 칭한다. 이때, 스텝 사이즈는 학습률을 의미할 수 있다. 경사 하강법은 손실 함수를 각 모델 파라미터들로 편미분하여 기울기를 획득하고, 모델 파라미터들을 획득한 기 울기 방향으로 학습률만큼 변경하여 갱신할 수 있다. 확률적 경사 하강법은 학습 데이터를 미니 배치로 나누고, 각 미니 배치마다 경사 하강법을 수행하여 경사 하강 의 빈도를 높인 기법이다. Adagrad, AdaDelta 및 RMSProp는 SGD에서 스텝 사이즈를 조절하여 최적화 정확도를 높이는 기법이다. SGD에서 모멘텀 및 NAG는 스텝 방향을 조절하여 최적화 정확도를 높이는 기법이다. Adam은 모멘텀과 RMSProp를 조합하여 스텝 사이즈와 스텝 방향을 조절하여 최적화 정확도를 높이는 기법이다. Nadam은 NAG와 RMSProp를 조합하여 스 텝 사이즈와 스텝 방향을 조절하여 최적화 정확도를 높이는 기법이다. 인공 신경망의 학습 속도와 정확도는 인공 신경망의 구조와 학습 최적화 알고리즘의 종류뿐만 아니라, 하이퍼파 라미터에 크게 좌우되는 특징이 있다. 따라서, 좋은 학습 모델을 획득하기 위하여는 적당한 인공 신경망의 구조 와 학습 알고리즘을 결정하는 것뿐만 아니라, 적당한 하이퍼파라미터를 설정하는 것이 중요하다. 통상적으로 하이퍼파라미터는 실험적으로 다양한 값으로 설정해가며 인공 신경망을 학습시켜보고, 학습 결과 안 정적인 학습 속도와 정확도를 제공하는 최적의 값으로 설정한다. 네트워크는 유선 및 무선 네트워크, 예를 들어 LAN(local area network), WAN(wide area network), 인터 넷(internet), 인트라넷(intranet) 및 엑스트라넷(extranet), 그리고 모바일 네트워크, 예를 들어 셀룰러, 3G, 4G LTE, 5G, WiFi 네트워크, 애드혹 네트워크 및 이들의 조합을 비롯한 임의의 적절한 통신 네트워크 일 수 있 다. 네트워크는 허브, 브리지, 라우터, 스위치 및 게이트웨이와 같은 네트워크 요소들의 연결을 포함할 수 있 다. 네트워크는 인터넷과 같은 공용 네트워크 및 안전한 기업 사설 네트워크와 같은 사설 네트워크를 비롯 한 하나 이상의 연결된 네트워크들, 예컨대 다중 네트워크 환경을 포함할 수 있다. 네트워크에의 액세스는 하나 이상의 유선 또는 무선 액세스 네트워크들을 통해 제공될 수 있다.도 3은 본 발명의 실시 예에 따른 화자 위조 검사를 위한 전자기기의 구성을 설명하기 위한 도면이고, 도 4는 본 발명의 실시 예에 따른 화자의 음성 데이터에서 추출한 스펙트럼 에너지 분포의 특징을 예시적으로 도시한 도면이며, 도 5는 본 발명의 실시 예에 따라 화자의 음성 데이터에서 추출한 음성 지문과 화자의 발화 음성에서 추출한 발화 음성 지문의 유사도를 판단하기 위한 도면이다. 도면을 설명하기에 앞서, 전자기기에는 화자가 발화한 음성이 등록되고, 검증 대상 음성이 발화한 음 성이 위조 음성인지를 판단하기까지의 일련의 과정들을 각각 수행하는 복수의 프로세서를 포함하여 구성될 수 있다. 여기서 전자기기를 이루는 프로세서들은 하나의 서버 형태 또는 각각이 하나 이상의 서버 형태로 구 성될 수 있다. 또한, 전자기기는 화자의 음성을 기준 데이터로 등록하기 위한 프로세서와 검증 대상 음성의 음 성을 등록된 화자의 음성과 비교하여 위조인지 여부를 판단하기 위한 프로세서들을 포함할 수 있다. 구체적으로 도면을 참조하면, 전자기기는 화자의 음성을 수신하는 음성 수신 프로세서를 포함한 다. 음성 수신 프로세서는 전자기기에 포함된 마이크 등을 통해 화자의 발화 음성을 수신하는 구성 이다. 즉, 화자 음성 수신 프로세서에서 수집하는 데이터는 화자로부터 발화된 음성일 수 있으며, 화 자로부터 발화된 음성은 예를 들어 “하이 엘지”, “음악 틀어줘” 등과 같은 전자기기의 동작을 제 어할 수 있는 음성이 될 수 있다. 여기서 화자가 발화한 음성은 전자기기의 동작을 제어하기 위한 명령어와 화자자 발화한 명령어에 의 해 전자기기가 동작할 수 있는지 명령어를 인증하기 위해 전자기기에 저장된 인증어로 구분될 수 있 다. 예를 들어, 전자기기를 처음 사용하는 경우 전자기기를 on/off 하기 위해 “하이 엘지”를 입력할 수 있다. 이때, 화자가 발화하는 “하이 엘지”는 인증어가 될 수 있으며, 인증어가 저장된 후 화자가 전자기기를 동작시키기 위해 “하이 엘지”를 발화하는 경우 발화한 “하이 엘지”는 명령어가 될 수 있다. 음성 수신 프로세서에서 화자의 음성을 수신하면, 음성 변환 프로세서를 통해 수집된 화자(20 1)의 음성을 변환할 수 있다. 구체적으로, 전자기기에서 화자의 음성 데이터를 수신하면, 음성 데이터를 음성 주파수로 추출할 수 있다. 음성 주파수란, 일반적으로 사람의 음성 중에 포함되어 있는 범위의 주파수를 말한다. 이와 유사하게, 대화 등을 전하기 위해 필요한 200㎐~3,500㎐의 주파수를 말하는 경우도 있다. 음성 변환 프로세서를 통해 수집된 화자의 음성을 변환한 뒤, 스펙트럼 추출 프로세서를 통해 음성 변환 프로세서에서 추출한 음성 주파수에서 스펙트럼 에너지 분포를 추출 및 분석할 수 있다. 스펙트럼 에너지 분포란, 음성 주파수의 에너지의 분포를 의미하며 구체적으로 단위 시간당 발견되는 스펙트럼 에너지 분포도를 의미한다. 동일 화자가 동일한 단어 또는 문장을 발화하더라도 발화 시점의 환경, 화자의 음성 상태 등에 의해 발화할 때 마다 다른 주파수 대역이 추출될 수 있다. 따라서, 동일 화자가 동일한 단어 또는 문장을 발화할 때마다 다른 크기의 스펙트럼 에너지 분포를 가질 수 있다. 이러한 특징에 의해 스펙트럼 추출 프로세서는 화자가 발화할 때마다 생성되는 음성 주파수에서 스펙 트럼 에너지 분포를 추출할 수 있다. 또한, 스펙트럼 추출 프로세서는 추출한 스펙트럼 에너지 분포의 평균 에너지보다 큰 에너지를 가지는 복 수의 스펙트럼 피크(Spectral Peak)를 추출할 수 있다. 스펙트럼 피크는 화자가 발화할 때 특정 어휘, 특정 모음 또는 자음 등을 중심으로 발화하는 경향을 나타 내는 것을 의미한다. 예컨대, 화자가 \"하이 엘지\"라고 발화할 때, \"엘\"을 발화하는 악센트가 강하거나, 음역대 가 높을 수 있다. 이 경우, \" 엘\" 을 발화하는 주파수가 높게 측정될 수 있으며, 주파수가 높은 만큼 \"엘\"을 발 화할 때의 음성 데이터에서 추출한 스펙트럼 에너지 분포의 에너지가 크다는 것을 의미할 수 있다. 이와 같이 스펙트럼 에너지 분포의 평균 에너지보다 큰 에너지를 가지는 스펙트럼 피크는 에너지가 높기 때문에 노이즈에 강하고, 녹음을 하더라도 에너지가 변화하지 않는다는 특징이 있다. 이렇게 추출된 스펙트럼 피크는 음성 지문 추출 프로세서를 통해 화자 음성 지문(voice fingerprint)이 추 출될 수 있도록 하는 데이터로 이용된다. 구체적으로, 화자 음성 지문은 검증 대상 음성이 발화한 음성이 위조된 음성인지를 판단할 수 있도록 하는 데이터이다. 상세하게 동일한 화자가 다른 시점에 동일한 문장 또는 단어를 발화하더라도 발화 시점마다 다른 스펙트럼 에너 지 분포를 가지게 된다. 즉, 다른 시점에 동일한 문장 또는 단어를 발화할 때 생성되는 평균 에너지보다 큰 에 너지를 가지는 복수의 스펙트럼 피크의 분포가 다를 수 있다. 따라서, 여러 번 발화할 때마다 생성된 스펙트럼 피크에 의해 발화 시점마다 다른 특징의 화자 음성 지문이 추출될 수 있다. 이렇게 추출된 화자 음성 지문은 데 이터 베이스에 저장될 수 있고, 데이터 베이스에 저장된 음성 지문과 검증 대상 음성에서 추출 한 검증 대상 음성의 음성 지문의 유사도가 임계값 이상인 경우 검증 대상 음성의 음성이 위조된 음성이라 고 판단할 수 있다. 구체적으로 살펴보면, 음성 지문은 복수의 음성 지문 요소를 포함한다. 음성 지문 요소란, 최대 에너지를 가지 는 스펙트럼 피크에서부터 순차적으로 에너지가 작아지는 스펙트럼 피크를 9개 내지 11개 추출한 뒤, 각각의 스 펙트럼 피크마다 시간 차이를 비교한 것을 의미한 것이다. 예를 들어, 화자 음성 지문의 경우 최대 에너지를 가지는 스펙트럼 피크를 제1 스펙트럼 피크(도 4의 참 고)라고 하고, 이후 두 번째, 세 번째 에너지를 가지는 스펙트럼 피크를 제2 스펙트럼 피크(도 4의 참고), 제3 스펙트럼 피크(도 4의 참고)등을 포함할 수 있다. 이와 같이, 스펙트럼 피크를 복수개(도 4의 내지 참고) 추출한 상태에서 제1 스펙트럼 피크와 제2 스 펙트럼 피크 사이의 시간 차이를 측정하여 제1 음성 지문 요소를 추출한다. 이와 유사하게, 제1 스펙트럼 피크 와 제3 스펙트럼 피크의 시간 차이를 측정하여 제2 음성 지문 요소를 추출하게 된다. 이렇게 추출한 음성 지문 요소에 의해 화자 발화 시, 어느 음절을 중심으로 발화하는지, 스펙트럼 에너지 분포의 평균 에너지보다 큰 에너지들이 생성되는 주파수가 어느 영역인지 등을 추측할 수 있다. 한편, 본 발명의 실시 예는 스펙트럼 에너지 분포의 평균 에너지보다 큰 에너지를 가지는 스펙트럼 피크를 10개 추출한 뒤, 최대의 에너지를 가지는 제1 스펙트럼 피크와 나머지 9개의 스펙트럼 피크 사이의 시간 차를 측정하 고, 두 번째 최대 에너지를 가지는 제2 스펙트럼 피트와 나머지 8개의 스펙트럼 피크 사이의 시간 차를 측정하 는 방법으로 총 35개의 음성 지문 요소를 추출할 수 있다. 이와 같이 음성 지문 요소를 추출한 후, 검증 대상 음성의 음성 데이터를 수신하면, 앞서 설명한 복수의 프로세스들을 이용하여 검증 대상 음성의 음성 지문을 추출한다. 설명한 바와 같이, 다른 시점에 동일한 문장 또는 단어를 발화하더라도 발화 시점마다 다른 스펙트럼 에너지 분 포를 가지게 되고, 이로 인해 발화 시점마다 다른 특징의 음성 지문이 추출될 수 있다. 따라서, 발화 시점마다 스펙트럼 에너지 분포의 평균 에너지보다 큰 에너지를 가지는 스펙트럼 피크의 분포가 다르게 생성될 수 있다. 즉, 화자에서 발화한 새로운 음성 데이터에서 추출한 새로운 음성 지문 요소와 데이터 베이스에 저장 된 음성 지문 요소들과 매칭한다. 구체적으로 도 5에 도시된 바와 같이, 저장된 음성 지문 요소(본 발명의 실시 예: 화자)를 A라고 하고, 발화되 어 추출된 음성 지문 요소를 B(본 발명의 실시 예: 검증 대상 음성) 라고 가정하고, A와 B에서 추출한 지문 요 소 A와 지문 요소 B를 매칭한다. 이때, A1, A2, A3과 B1, B2, B3 의 비율이 유사한 것으로 판단할 수 있다. 여기 서, 유사한 비율이 3개 이상인 경우, 새롭게 발화된 음성이 위조된 음성이라고 판단한다고 가정하면, 지문 요소 B는 지문 요소 A가 추출된 음성을 위조한 음성이라고 판단할 수 있다. 이와 같이, 검증 대상 음성의 음성 지문 요소와 저장된 화자 음성 지문 요소 사이에 임계값 이상 유사점이 발생 하면, 검증 대상 음성의 음성 데이터는 기존에 발화하여 화자 음성 지문 요소가 추출된 음성 중 어느 하나 인 것으로 판단할 수 있다. 따라서, 검증 대상 음성은 녹음된 위조 음성 이라고 판단하여 전자기기의 동작이 실행되지 않도록 한다.이때, 화자는 한번만 발화한다. 즉, 발화된 화자의 음성과 데이터 베이스에 저장된 정보와 매칭하여 발화 된 화자의 음성이 위조된 음성인지를 판단할 수 있는 것이다. 여기서 위조 음성이라고 판단할 수 있는 임계값은 음성 데이터에서 추출한 검증 대상 음성의 음성 지문 요소와 데이터 베이스에 저장된 음성 지문 요소를 비교하여 동일한 비율이 정해진 비율 이상 동일한 경우 검증 대 상 음성을 위조 음성이라고 판단할 수 있다. 한편, 음성 수신 프로세서에서 검증 대상 음성의 음성을 수신하면 검증 대상 음성의 음성이 전 자기기를 인증한 음성이 등록된 화자와 동일인인지 판단해야 한다. 이를 위해 검증 대상 음성 판단 프로세서를 통해 화자의 음성 데이터에서 화자의 음성 특성을 추출한다. 이와 유사하게, 검증 대상 음성의 음성 데이터에서 검증 대상 음성의 음성 특성을 추출한 다. 이후, 화자의 음성 특징과 검증 대상 음성의 음성 특징이 미리 저장된 임계값 이상인 경우 화자 와 검증 대상 음성이 동일인이라고 판단할 수 있다. 이때, 화자의 음성 특징 및 검증 대상 음성의 음성 특징은 화자 및 검증 대상 음성의 발화 속도, 발 화 음높이, 음성 데이터에서 추출한 음성 주파수 영역(domain) 중 적어도 어느 하나의 통계적인 특징이 조건으 로 작용할 수 있다. 즉, 검증 대상 음성과 화자가 동일인인 경우 검증 대상 음성의 평균적인 음 높이, 평균 발화 속 도, 평균 음성 주파수 영역이 대략적으로 동일할 수 있기 때문이다. 이때, 위조 추측 모델에서 학습한 데이터를 이용하여 유사도 검출 프로세서를 통해 화자 음성 지문과 검증 대상자 음성 지문의 유사도가 미리 설정된 임계치 이하인 경우, 검증 대상 음성의 위조 판단을 중지할 수 있다. 예를 들어, 화자와 다른 사람이 발화한 음성 또는 다른 사람이 발화한 음성을 녹음한 녹음 음성을 발화한 경우, 다른 사람에서 추출한 음성 지문과 화자의 음성 지문은 다르게 추출된다. 예컨대, 화자 음성 지문과 검증 대상 음성 지문의 유사도 임계치가 3개 이상일 때 검증 대상 음성이 화자 음성을 위조한 음성이라고 판단 할 수 있다. 이때, 화자 음성 지문과 검증 대상 음성 지문의 유사도가 나타나지 않는 경우, 검증 대상 음성이 화자와 다른 사람이라고 판단하여 음성 위조 판단을 중지하고, 나아가 전자기기 동작을 중지시키도록 할 수 있다. 이와 다르게, 화자의 음성 특징과 검증 대상 음성의 음성 특징이 임계값 이상으로 유사한 경우에도 검증 대상 음성이 화자인 것으로 판단할 수 있다. 이러한 특징을 통해 유사도가 임계값 이하이고, 음성 특징이 유사하다고 판단되면 검증 대상 음성은 화자 와 동일인이며, 발화한 언어는 다른 시점에서 발화된 언어라고 추측할 수 있는 것이다. 도 6은 본 발명의 실시 예에 따른 화자 위조 검증 과정을 설명하기 위한 흐름도이고, 도 7은 본 발명의 실시 예 에 따른 화자 음성 위조 검사 방법에 대한 순서도이다. 또한, 도 8A는 본 발명의 실시 예에 따라 화자의 음성 데이터에서 추출한 음성 주파수를 도시한 도면이고, 도 8B는 도 8A의 음성 주파수를 분석하여 추출한 스펙트럼 에너지 분포를 도시한 도면이며, 도 8C는 도 8B의 스펙 트럼 에너지 분포의 평균 에너지보다 큰 에너지를 가지는 복수의 스펙트럼 피크를 도시한 도면이다. 또한 도 9A는 본 발명의 실시 예에 따른 화자의 음성 데이터에서 추출한 노이즈가 첨가되지 않은 스펙트럼 에너 지 분포를 도시한 도면이고, 도 9B는 도 9A의 노이즈가 첨가되지 않은 스펙트럼 에너지 분포에 10dB의 노이즈를 첨가한 예를 도시한 도면이며, 도 9C는 도 9A의 노이즈가 첨가되지 않은 스펙트럼 에너지 분포에 5dB의 노이즈 를 첨가한 예를 도시한 도면이다. 또한, 도 10은 본 발명의 실시 예에 따른 동일 화자가 여러 번 발화한 경우 각각의 발화에서 추출한 스펙트럼 에너지 분포의 특징을 예시적으로 도시한 도면이다. 도면을 참고하면, 화자는 전자기기에 입력될 수 있는 키워드를 발화할 수 있다(도 6의 ). 예를 들 어 화자가 “하이 엘지”라고 발화할 수 있고, 발화 음성에서 추출한 음성 데이터는 전자기기 보안을 위한 화자 인증 데이터로 이용되도록 등록할 수 있다(S110). 화자가 발화하면, 발화된 음성에서 음성 주파수를 추출한 뒤(S121), 추출된 음성 주파수에서 스펙트럼 에 너지 분포를 분석할 수 있다(도 6의 , ). 음성 주파수란, 사람의 음성 중에 포함되어 있는 범위의 주파수를 의미하고, 화자가 발화하면 도 8A와 같은 시 간에 대해 주파수 분포도가 생성될 수 있다. 이때, 신호의 크기가 큰 주파수 대역은 도 8A의 영역 A와 같이 주 변 영역보다 밝거나 넓은 영역에 걸쳐 분포되는 것을 확인할 수 있다. 음성 주파수를 분석하여 추출한 스펙트럼 에너지 분포는 도 8B에 도시된 바와 같이 단위 시간당 발견되는 음성 주파수의 스펙트럼 에너지 분포도를 의미한다. 일반적으로 주파수 분포와 유사한 분포를 가질 수 있다. 추출한 스펙트럼 에너지 분포의 평균 에너지보다 큰 에너지를 가지는 복수의 스펙트럼 피크를 추출할 수 있다. 즉, 도 8B 및 도 8C를 참고하면, 전체 스펙트럼 에너지 분포에서 복수의 스펙트럼 에너지 분포를 추출할 수 있 으며, 이를 스펙트럼 피크라고 할 수 있다. 구체적으로 추출된 스펙트럼 피크는, 전체 스펙트럼 에너지 분포에서 에너지가 가장 큰 주파수 대역을 의미하고, 에너지가 큰 주파수 대역의 음성 데이터는 주변 환경 변화에 관계 없이 일정한 에너지 크기를 가질 수 있다. 따라서, 추출된 스펙트럼 피크에 노이즈를 첨가하여도 스펙트럼 피크의 위치(에너지 크기)는 변하지 않을 수 있다. 이러한 특징으로 발화 시점에 화자가 어느 주파수를 중심으로 발화하는지 알 수 있다. 즉, 화자가 발화하여 생성된 음성 데이터에서 추출한 노이즈가 첨가되지 않은 스펙트럼 에너지 분포(도 9A 참고)와 노이즈가 첨가되지 않은 스펙트럼 에너지 분포에 노이즈 10dB 또는 노이즈 5dB를 첨부하여도 스펙트럼 피크의 위치는 변화하지 않는다(도 9B, 9C 참고). 즉, 에너지가 높은 스펙트럼 피크는 노이즈에 의해 에너지가 감소되지 않으므로 화자의 발화에서 특징되는 주파수를 추정할 수 있는 것이다. 이에 반해 동일 화자가 다른 시점에 동일 문장 또는 단어를 발화하는 경우 다른 음성 데이터가 생성될 수 있으며, 이로 인해 발화 시점마다 다른 크기의 에너지를 가지는 스펙트럼 피크가 추출될 수 있다. 즉 도 10에 도시된 바와 같이 동일 화자가 서로 다른 시점에 발화하는 경우, 화자가 발화하는 환경, 음성 상태 등에 따라 발화의 높낮이, 발화 속도, 강세 등이 변화될 수 있다. 따라서 도 10과 같이 각각의 시점에서 다른 에너지를 가지는 스펙트럼 피크가 추출될 수 있다. 이러한 특징을 기초로 화자가 발화하여 추출한 스펙트럼 피크와 데이터 베이스에 저장된 스펙트럼 피크를 비교하여 발화한 화자의 음성이 녹음된 파일(위조 음성)인지를 판단할 수 있다. 이를 위해, 스펙트럼 에너지 분포에서 추출한 스펙트럼 피크를 이용하여 음성 지문을 추출한다(도 6의 ). 음성 지문은 복수의 음성 지문 요소를 포함한다. 음성 지문 요소란, 최대 에너지를 가지는 스펙트럼 피크에서부 터 순차적으로 에너지가 작아지는 스펙트럼 피크를 9개 내지 11개 추출한 뒤, 각각의 스펙트럼 피크마다 시간 차이를 비교한 것을 의미한다. 예를 들어, 스펙트럼 피크를 최대 에너지를 가지는 스펙트럼 피크인 제1 스펙트럼 피크에서부터 제10 스펙트럼 피크(도 4의 내지 참고)까지 추출한 뒤, 제1 스펙트럼 피크와 제2 내지 제10 스펙트럼 피크 사이의 시 간 차이, 제2 스펙트럼 피크와 제3 내지 제10 스펙트럼 피크 사이의 시간 차이를 순차적으로 추출한다. 이렇게 추출한 음성 지문 요소는 데이터 베이스에 저장될 수 있으며(도 6의 ), 추출한 음성 지문 요소 는 화자 발화 시, 어느 음절을 중심으로 발화하는지, 스펙트럼 에너지 분포의 평균 에너지보다 큰 에너지 들이 생성되는 주파수가 어느 영역인지 등을 추측할 수 있는 데이터로 활용할 수 있다. 이와 같이 음성 지문 요소를 추출한 후, 위조 검증을 위한 검증 대상 음성의 데이터를 수신하고, 수신한 검증 대상 음성의 음성과 화자가 동일인인지 판단한다(S120, S130). 구체적으로, 화자의 음성 데이터에서 화자의 음성 특성을 추출한다. 이와 유사하게, 검증 대상 음성 의 음성 데이터에서 검증 대상 음성의 음성 특성을 추출한다. 이후, 화자의 음성 특징과 검증 대상 음성의 음성 특징이 미리 저장된 임계값 이상인 경우 화자와 검증 대상 음성이 동일인이라 고 판단할 수 있다. 이때, 화자의 음성 특징 및 검증 대상 음성의 음성 특징은 화자 및 검증 대상 음성의 발화 속도, 발 화 음높이, 음성 데이터에서 추출한 음성 주파수 영역(domain) 중 적어도 어느 하나의 통계적인 특징이 조건으로 작용할 수 있다. 이와 같이 검증 대상 음성과 화자가 동일인이라고 판단되면, 복수의 프로세스들을 이용하여 검증 대상 음성의 데이터에 대한 검증 대상 음성의 음성 지문을 추출한다(도 6의 ). 이렇게 추출된 검증 대상 음성의 음성 지문 요소와 앞서 화자의 음성 데이터를 통해 추출된 음성 지문 요 소를 매칭하여 유사점을 측정할 수 있다(도 6의 ). 즉, 다른 시점에 동일한 문장 또는 단어를 발화하더라도 발화 시점마다 다른 스펙트럼 에너지 분포를 가지게 되 고, 이로 인해 발화 시점마다 다른 특징의 음성 지문이 추출된다. 따라서, 발화 시점마다 스펙트럼 에너지 분포 의 평균 에너지보다 큰 에너지를 가지는 스펙트럼 피크의 분포가 다르게 생성된다. 예컨대, 화자가 전자기기를 작동시킬 때 “하이 엘지”라 발화하고, 발화 시점마다 다른 분포를 가지 는 스펙트럼 피크가 생성될 수 있다. 이렇게 생성된 스펙트럼 피크들은 데이터 베이스에 저장될 수 있다. 한편, 제3자가 화자가 발화한 “하이 엘지”를 녹음한 음성 파일을 전자기기를 향해 발화시키면 녹음 한 음성 파일로부터 스펙트럼 피크를 생성한다. 녹음한 음성 파일로부터 생성한 스펙트럼 피크는 데이터 베이스 에 저장된 스펙트럼 피크들 중 어느 하나와 일치하거나 유사하다. 따라서, 녹음한 음성 파일로부터 추출한 녹음한 음성 파일의 음성 지문 요소는 데이터 베이스에 저장된 어느 하나의 음성 지문 요소와 일부 유사 및/또는 동일한 값을 가지게 된다. 이를 기초로 발화한 검증 대상 음성으로부터 추출한 검증 대상 음성의 음성 지문 요소와 화자 음성 지문 요소가 미리 정해진 임계값 이상 유사한 경우 검증 대상 음성이 녹음된 파일이거나 위조된 파일이라고 판단할 수 있다 (S140). 이때, 화자는 한번의 발화만 실행한다. 한번만 발화된 화자의 음성과 데이터 베이스에 저장된 정보와 매칭 하여 발화된 화자의 음성이 위조된 음성인지를 판단할 수 있다. 따라서, 한번의 발화로 음성 인증이 가능해지므 로 음성 인증의 간편성이 향상될 수 있다. 이와 같이, 화자의 실제 목소리와 화자의 음성이 녹음된 녹음 파일을 구분하여 제3자가 녹음 파일을 이용하여 화자 인증을 시도하는 것을 방지할 수 있도록 한다. 즉, 화자가 전자기기를 작동시킬 때 발화한 음성은 발화 시점마다 다른 분포를 가지는 스펙트럼 피크를 생성할 수 있다. 한편, 제3자가 화자가 발화한 음성을 녹음한 음성 파일을 전자기기를 향해 발화시키면 녹음한 음성 파 일로부터 스펙트럼 피크를 생성할 수 있다. 이때, 녹음한 음성 파일로부터 생성한 스펙트럼 피크는 앞서 생성된 스펙트럼 피크들 중 어느 하나와 일치하거나 유사하다. 따라서, 녹음한 음성 파일로부터 추출한 녹음한 음성 파 일의 음성 지문 요소는 앞서 추출한 어느 하나의 음성 지문 요소와 일부 유사 및/또는 동일한 값을 가지게 된다. 따라서, 발화한 검증 대상 음성으로부터 추출한 새로움 음성 지문 요소와 화자 음성 지문 요소가 미리 정해진 임계값 이상 유사한 경우 검증 대상 음성이 녹음된 파일이거나 위조된 파일이라고 판단할 수 있다. 또한, 검증 대상 음성이 녹음된 파일이거나 위조된 파일이라고 판단되는 경우 전자기기의 동작이 이루어지지 않 도록 함으로써, 제3자가 전자기기를 사용할 수 없도록 전자기기의 보안이 향상될 수 있다. 더욱이, 화자는 한번의 발화만 실행한다. 이때, 발화된 화자의 음성과 미리 저장된 정보와 매칭하여 발화된 화 자의 음성이 위조된 음성인지를 판단할 수 있다. 따라서, 한번의 발화로 음성 인증이 가능해지므로 음성 인증의 간편성이 향상될 수 있다. 이상 설명된 본 발명에 따른 실시 예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그 램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이 때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자 에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다.본 발명의 명세서(특히 청구범위에서)에서 \"상기\"의 용어 및 이와 유사한 지시 용어의 사용은 단수 및 복수 모 두에 해당하는 것일 수 있다. 또한, 본 발명에서 범위(range)를 기재한 경우 범위에 속하는 개별적인 값을 적용 한 발명을 포함하는 것으로서(이에 반하는 기재가 없다면), 발명의 상세한 설명에 범위를 구성하는 각 개별적인 값을 기재한 것과 같다. 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 단계들은 적당한 순서로 행해질 수 있다. 반드시 단계들의 기재 순서에 따라 본 발명이 한정되는 것은 아니다. 또한, 본 발명에 따른 방법들에 포함된 단계들은 프로세서 또는 해당 단계의 기능을 수행하기 위한 모듈들을 통해서 수행 될 수 있다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 청구범위에 의해 한정되지 않는 이상 예들 또는 예시적인 용어로 인해 본 발명의 범위 가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 청구범위 또는 그 균등물의 범 주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 발명의 사상은 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 청구범위뿐만 아니라 이 청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한다고 할 것이다."}
{"patent_id": "10-2019-0171146", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 화자 위조 검사를 위한 환경의 예시도이다. 도 2는 본 발명의 실시 예에 따른 화자 위조 검사를 위한 음성 인공 지능 기술을 설명하기 위한 도면이다. 도 3은 본 발명의 실시 예에 따른 화자 위조 검사를 위한 전자기기의 구성을 설명하기 위한 도면이다. 도 4는 본 발명의 실시 예에 따른 화자의 음성 데이터에서 추출한 스펙트럼 에너지 분포의 특징을 예시적으로 도시한 도면이다. 도 5는 본 발명의 실시 예에 따라 화자의 음성 데이터에서 추출한 음성 지문과 화자의 발화 음성에서 추출한 발 화 음성 지문의 유사도를 판단하기 위한 도면이다. 도 6은 본 발명의 실시 예에 따른 화자 위조 검증 과정을 설명하기 위한 흐름도이다. 도 7은 본 발명의 실시 예에 따른 화자 음성 위조 검사 방법에 대한 순서도이다. 도 8A는 본 발명의 실시 예에 따라 화자의 음성 데이터에서 추출한 음성 주파수를 도시한 도면이다. 도 8B는 도 8A의 음성 주파수를 분석하여 추출한 스펙트럼 에너지 분포를 도시한 도면이다. 도 8C는 도 8B의 스펙트럼 에너지 분포의 평균 에너지보다 큰 에너지를 가지는 복수의 스펙트럼 피크를 도시한 도면이다. 도 9A는 본 발명의 실시 예에 따른 화자의 음성 데이터에서 추출한 노이즈가 첨가되지 않은 스펙트럼 에너지 분 포를 도시한 도면이다. 도 9B는 도 9A의 노이즈가 첨가되지 않은 스펙트럼 에너지 분포에 10dB의 노이즈를 첨가한 예를 도시한 도면이 다. 도 9C는 도 9A의 노이즈가 첨가되지 않은 스펙트럼 에너지 분포에 5dB의 노이즈를 첨가한 예를 도시한 도면이다. 도 10은 본 발명의 실시 예에 따른 동일 화자가 여러 번 발화한 경우 각각의 발화에서 추출한 스펙트럼 에너지 분포의 특징을 예시적으로 도시한 도면이다."}
