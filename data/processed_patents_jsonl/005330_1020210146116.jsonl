{"patent_id": "10-2021-0146116", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0061161", "출원번호": "10-2021-0146116", "발명의 명칭": "패션 시뮬레이션 장치 및 방법", "출원인": "주식회사 케이티", "발명자": "박형준"}}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "원본 이미지, 원본 포즈 정보 및 타겟 포즈 정보를 이용하여, 이미지 특징 및 공간 특징을 포함하는 특징 맵을추출하는 인코더;상기 특징 맵을 이용하여 포즈 변환 이미지를 생성하는 디코더;상기 원본 이미지로부터 스타일 코드를 추출하고, 상기 스타일 코드 및 상기 특징 맵을 이용하여 스타일 강화이미지를 생성하는 스타일 강화 모델; 및상기 포즈 변환 이미지 및 상기 스타일 강화 이미지를 합성하여 최종 이미지를 생성하는 제어부;를 포함하는패션 시뮬레이션 장치."}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 스타일 강화 모델은,상기 원본 이미지로부터 색상, 질감 및 패턴에 대한 특징을 포함하는 상기 스타일 코드를 추출하는 스타일 인코더; 및상기 특징 맵에 상기 스타일 코드를 매핑하여 업샘플링을 함으로써 상기 스타일 강화 이미지를 생성하는 스타일디코더;를 포함하는패션 시뮬레이션 장치."}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 스타일 디코더는, 복수의 업샘플링 레이어를 포함하고,상기 복수의 업샘플링 레이어 각각은,이전 업샘플링 레이어에서 출력된 강화 맵에 상기 스타일 코드를 매핑하여 현재 강화 맵을 출력하는패션 시뮬레이션 장치."}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,상기 인코더는,상기 원본 포즈 정보 및 상기 타겟 포즈 정보 사이의 중간 포즈에 대한 중간 특징 맵을 생성하는패션 시뮬레이션 장치."}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서,상기 인코더는, 복수의 중간 생성 유닛을 포함하고,상기 복수의 중간 생성 유닛 각각은,이전 중간 특징 맵을 수신하고, 상기 이전 중간 특징 맵을 이용하여 해당 중간 생성 유닛에 대응하는 중간 타겟포즈가 반영된 현재 중간 특징 맵을 생성하는공개특허 10-2023-0061161-3-패션 시뮬레이션 장치."}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5항에 있어서,상기 복수의 중간 생성 유닛 각각은,상기 이전 중간 특징 맵에 포함된 이전 중간 공간 특징을 포즈 처리하여 포즈 코드를 획득하고, 상기 이전 중간특징 맵에 포함된 이전 중간 이미지 특징을 상기 포즈 코드에 반영하여 현재 중간 공간 특징을 출력하는 포즈처리부;를 포함하는패션 시뮬레이션 장치."}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서,상기 복수의 중간 생성 유닛 각각은,상기 이전 중간 특징 맵에 포함된 이전 중간 이미지 특징을 이미지 처리하여 이미지 코드를 획득하고, 상기 이미지 코드에 상기 포즈 코드를 반영하여 현재 중간 이미지 특징을 출력하는 이미지 처리부;를 더 포함하는패션 시뮬레이션 장치."}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1항에 있어서,상기 원본 이미지로부터 얼굴을 탐지하여 얼굴 이미지를 생성하고, 상기 얼굴 이미지, 원본 얼굴 포즈 정보 및타겟 얼굴 포즈 정보를 이용하여 얼굴 포즈 변환 이미지를 생성하는 얼굴 변환 모델;을 더 포함하고,상기 제어부는,상기 최종 이미지에 상기 얼굴 포즈 변환 이미지를 추가적으로 합성하여 2차 최종 이미지를 생성하는패션 시뮬레이션 장치."}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "인코더가, 원본 이미지, 원본 포즈 정보 및 타겟 포즈 정보를 이용하여, 이미지 특징 및 공간 특징을 포함하는특징 맵을 추출하는 단계;디코더가, 상기 특징 맵을 이용하여 포즈 변환 이미지를 생성하는 단계;스타일 강화 모델이, 상기 원본 이미지로부터 스타일 코드를 추출하고, 상기 스타일 코드 및 상기 특징 맵을 이용하여 스타일 강화 이미지를 생성하는 단계; 및제어부가, 상기 포즈 변환 이미지 및 상기 스타일 강화 이미지를 합성하여 최종 이미지를 생성하는 단계;를 포함하는패션 시뮬레이션 방법."}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,상기 원본 이미지로부터 스타일 코드를 추출하고, 상기 스타일 코드 및 상기 특징 맵을 이용하여 스타일 강화이미지를 생성하는 단계는,상기 원본 이미지로부터 색상, 질감 및 패턴에 대한 특징을 포함하는 상기 스타일 코드를 추출하는 단계;상기 특징 맵에 상기 스타일 코드를 매핑하여 업샘플링을 함으로써 상기 스타일 강화 이미지를 생성하는 단계;를 포함하는공개특허 10-2023-0061161-4-패션 시뮬레이션 방법."}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10항에 있어서,상기 특징 맵에 상기 스타일 코드를 매핑하여 업샘플링을 함으로써 상기 스타일 강화 이미지를 생성하는단계는,복수의 업샘플링 레이어 각각이, 이전 업샘플링 레이어에서 출력된 강화 맵에 상기 스타일 코드를 매핑하여 현재 강화 맵을 출력하는 단계;를 포함하는패션 시뮬레이션 방법."}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 9항에 있어서,상기 이미지 특징 및 공간 특징을 포함하는 특징 맵을 추출하는 단계는,상기 원본 포즈 정보 및 상기 타겟 포즈 정보 사이의 중간 포즈에 대한 중간 특징 맵을 생성하는 단계;를 포함하는패션 시뮬레이션 방법."}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 있어서,상기 중간 특징 맵을 생성하는 단계는,복수의 중간 생성 유닛 각각이, 이전 중간 특징 맵을 수신하고, 상기 이전 중간 특징 맵을 이용하여 해당 중간생성 유닛에 대응하는 중간 타겟 포즈가 반영된 현재 중간 특징 맵을 생성하는 단계;를 포함하는패션 시뮬레이션 방법."}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서,상기 복수의 중간 생성 유닛 각각이 현재 중간 특징 맵을 생성하는 단계는,상기 이전 중간 특징 맵에 포함된 이전 중간 공간 특징을 포즈 처리하여 포즈 코드를 획득하고, 상기 이전 중간특징 맵에 포함된 이전 중간 이미지 특징을 상기 포즈 코드에 반영하여 현재 중간 공간 특징을 출력하는 단계;를 포함하는패션 시뮬레이션 방법."}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14항에 있어서,상기 복수의 중간 생성 유닛 각각이 현재 중간 특징 맵을 생성하는 단계는,상기 이전 중간 특징 맵에 포함된 이전 중간 이미지 특징을 이미지 처리하여 이미지 코드를 획득하고, 상기 이미지 코드에 상기 포즈 코드를 반영하여 현재 중간 이미지 특징을 출력하는 단계;를 더 포함하는패션 시뮬레이션 방법."}
{"patent_id": "10-2021-0146116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 9항에 있어서,얼굴 변환 모델이, 상기 원본 이미지로부터 얼굴을 탐지하여 얼굴 이미지를 생성하고, 상기 얼굴 이미지, 원본얼굴 포즈 정보 및 타겟 얼굴 포즈 정보를 이용하여 얼굴 포즈 변환 이미지를 생성하는 단계; 및공개특허 10-2023-0061161-5-상기 제어부가, 상기 최종 이미지에 상기 얼굴 포즈 변환 이미지를 추가적으로 합성하여 2차 최종 이미지를 생성하는 단계;를 더 포함하는패션 시뮬레이션 방법."}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "패션 시뮬레이션 장치가 개시된다. 본 발명에 따른 패션 시뮬레이션 장치는, 원본 이미지, 원본 포즈 정보 및 타 겟 포즈 정보를 이용하여, 이미지 특징 및 공간 특징을 포함하는 특징 맵을 추출하는 인코더, 상기 특징 맵을 이 용하여 포즈 변환 이미지를 생성하는 디코더, 상기 원본 이미지로부터 스타일 코드를 추출하고, 상기 스타일 코 드 및 상기 특징 맵을 이용하여 스타일 강화 이미지를 생성하는 스타일 강화 모델, 및, 상기 포즈 변환 이미지 및 상기 스타일 강화 이미지를 합성하여 최종 이미지를 생성하는 제어부를 포함한다."}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은, 사람의 패션을 유지하면서 포즈를 변환하는 기술에 있어서, 스타일 정보를 별도로 처리한 후 합성함 으로써, 포즈가 변환된 이후에도 패션을 디테일하고 정확하게 구현할 수 있는, 패션 시뮬레이션 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 사람의 패션(옷, 메이크업, 머리 스타일 등)을 그대로 유지하면서, 사람의 포즈를 변환 시키는 휴먼 포즈 변환(Human Pose Transformer, HPT)에 대한 연구가 활발하게 진행되고 있다. 다만 현재 구현된 HPT 기술로는, 영상의 자연스러운 구현이 어렵다는 문제가 있다. 도 1은 원본 이미지를 현재 구현된 HPT 기술에 따라 변환한 결과를 도시한 도면이다. 도 1을 참고하면, 원본 이미지로부터 포즈를 변환한 타겟 이미지(1120, 1130)를 생성하는 경우, 옷감에 대한 디테일한 해상도가 떨어지고, 옷에 대한 색상, 질감, 패턴 등의 다양한 스타일 정보가 왜곡되거나 누락되 는 문제가 발생한다. 또한 원본 이미지로부터 포즈가 변경되는 경우, 원본 이미지에서는 표현이 되지 않았던 영역(예를 들어 사람이 셔츠를 입고 있는 경우, 팔에 의해 가려진 셔츠의 일부)에 대하여 스타일 정보가 유추되어야 한다. 다만 종래의 HPT 기술로는, 해당 영역에서의 스타일 정보가 모호하게 표현되는 문제가 있었다."}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 해결하기 위한 것으로, 본 발명의 목적은 사람의 패션을 유지하면서 포즈를 변환하 는 기술에 있어서, 스타일 정보를 별도로 처리한 후 합성함으로써, 포즈가 변환된 이후에도 패션을 디테일하고 정확하게 구현할 수 있는, 패션 시뮬레이션 장치 및 방법을 제공하기 위함이다."}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 패션 시뮬레이션 장치는, 원본 이미지, 원본 포즈 정보 및 타겟 포즈 정보를 이용하여, 이미지 특징 및 공간 특징을 포함하는 특징 맵을 추출하는 인코더, 상기 특징 맵을 이용하여 포즈 변환 이미지를 생성 하는 디코더, 상기 원본 이미지로부터 스타일 코드를 추출하고, 상기 스타일 코드 및 상기 특징 맵을 이용하여 스타일 강화 이미지를 생성하는 스타일 강화 모델, 및, 상기 포즈 변환 이미지 및 상기 스타일 강화 이미지를 합성하여 최종 이미지를 생성하는 제어부를 포함한다. 이 경우 상기 스타일 강화 모델은, 상기 원본 이미지로부터 색상, 질감 및 패턴에 대한 특징을 포함하는 상기 스타일 코드를 추출하는 스타일 인코더, 및, 상기 특징 맵에 상기 스타일 코드를 매핑하여 업샘플링을 함으로써 상기 스타일 강화 이미지를 생성하는 스타일 디코더를 포함할 수 있다. 이 경우 상기 스타일 디코더는, 복수의 업샘플링 레이어를 포함하고, 상기 복수의 업샘플링 레이어 각각은, 이 전 업샘플링 레이어에서 출력된 강화 맵에 상기 스타일 코드를 매핑하여 현재 강화 맵을 출력할 수 있다. 한편 상기 인코더는, 상기 원본 포즈 정보 및 상기 타겟 포즈 정보 사이의 중간 포즈에 대한 중간 특징 맵을 생 성할 수 있다. 이 경우 상기 인코더는, 복수의 중간 생성 유닛을 포함하고, 상기 복수의 중간 생성 유닛 각각은, 이전 중간 특 징 맵을 수신하고, 상기 이전 중간 특징 맵을 이용하여 해당 중간 생성 유닛에 대응하는 중간 타겟 포즈가 반영 된 현재 중간 특징 맵을 생성할 수 있다.이 경우 상기 복수의 중간 생성 유닛 각각은, 상기 이전 중간 특징 맵에 포함된 이전 중간 공간 특징을 포즈 처 리하여 포즈 코드를 획득하고, 상기 이전 중간 특징 맵에 포함된 이전 중간 이미지 특징을 상기 포즈 코드에 반 영하여 현재 중간 공간 특징을 출력하는 포즈 처리부를 포함할 수 있다. 이 경우 상기 복수의 중간 생성 유닛 각각은, 상기 이전 중간 특징 맵에 포함된 이전 중간 이미지 특징을 이미 지 처리하여 이미지 코드를 획득하고, 상기 이미지 코드에 상기 포즈 코드를 반영하여 현재 중간 이미지 특징을 출력하는 이미지 처리부를 더 포함할 수 있다. 한편 상기 원본 이미지로부터 얼굴을 탐지하여 얼굴 이미지를 생성하고, 상기 얼굴 이미지, 원본 얼굴 포즈 정 보 및 타겟 얼굴 포즈 정보를 이용하여 얼굴 포즈 변환 이미지를 생성하는 얼굴 변환 모델을 더 포함하고, 상기 제어부는, 상기 최종 이미지에 상기 얼굴 포즈 변환 이미지를 추가적으로 합성하여 2차 최종 이미지를 생성할 수 있다. 한편 본 발명에 따른 패션 시뮬레이션 방법은, 인코더가, 원본 이미지, 원본 포즈 정보 및 타겟 포즈 정보를 이 용하여, 이미지 특징 및 공간 특징을 포함하는 특징 맵을 추출하는 단계, 디코더가, 상기 특징 맵을 이용하여 포즈 변환 이미지를 생성하는 단계, 스타일 강화 모델이, 상기 원본 이미지로부터 스타일 코드를 추출하고, 상 기 스타일 코드 및 상기 특징 맵을 이용하여 스타일 강화 이미지를 생성하는 단계, 및, 제어부가, 상기 포즈 변 환 이미지 및 상기 스타일 강화 이미지를 합성하여 최종 이미지를 생성하는 단계를 포함한다. 이 경우 상기 원본 이미지로부터 스타일 코드를 추출하고, 상기 스타일 코드 및 상기 특징 맵을 이용하여 스타 일 강화 이미지를 생성하는 단계는, 상기 원본 이미지로부터 색상, 질감 및 패턴에 대한 특징을 포함하는 상기 스타일 코드를 추출하는 단계, 상기 특징 맵에 상기 스타일 코드를 매핑하여 업샘플링을 함으로써 상기 스타일 강화 이미지를 생성하는 단계를 포함할 수 있다. 이 경우 상기 특징 맵에 상기 스타일 코드를 매핑하여 업샘플링을 함으로써 상기 스타일 강화 이미지를 생성하 는 단계는, 복수의 업샘플링 레이어 각각이, 이전 업샘플링 레이어에서 출력된 강화 맵에 상기 스타일 코드를 매핑하여 현재 강화 맵을 출력하는 단계를 포함할 수 있다. 한편 상기 이미지 특징 및 공간 특징을 포함하는 특징 맵을 추출하는 단계는, 상기 원본 포즈 정보 및 상기 타 겟 포즈 정보 사이의 중간 포즈에 대한 중간 특징 맵을 생성하는 단계를 포함할 수 있다. 이 경우 상기 중간 특징 맵을 생성하는 단계는, 복수의 중간 생성 유닛 각각이, 이전 중간 특징 맵을 수신하고, 상기 이전 중간 특징 맵을 이용하여 해당 중간 생성 유닛에 대응하는 중간 타겟 포즈가 반영된 현재 중간 특징 맵을 생성하는 단계를 포함할 수 있다. 이 경우 상기 복수의 중간 생성 유닛 각각이 현재 중간 특징 맵을 생성하는 단계는, 상기 이전 중간 특징 맵에 포함된 이전 중간 공간 특징을 포즈 처리하여 포즈 코드를 획득하고, 상기 이전 중간 특징 맵에 포함된 이전 중 간 이미지 특징을 상기 포즈 코드에 반영하여 현재 중간 공간 특징을 출력하는 단계를 포함할 수 있다. 이 경우 상기 복수의 중간 생성 유닛 각각이 현재 중간 특징 맵을 생성하는 단계는, 상기 이전 중간 특징 맵에 포함된 이전 중간 이미지 특징을 이미지 처리하여 이미지 코드를 획득하고, 상기 이미지 코드에 상기 포즈 코드 를 반영하여 현재 중간 이미지 특징을 출력하는 단계를 더 포함할 수 있다. 한편 얼굴 변환 모델이, 상기 원본 이미지로부터 얼굴을 탐지하여 얼굴 이미지를 생성하고, 상기 얼굴 이미지, 원본 얼굴 포즈 정보 및 타겟 얼굴 포즈 정보를 이용하여 얼굴 포즈 변환 이미지를 생성하는 단계, 및, 상기 제 어부가, 상기 최종 이미지에 상기 얼굴 포즈 변환 이미지를 추가적으로 합성하여 2차 최종 이미지를 생성하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 색상, 색감, 질감, 패턴 등과 같은 스타일 정보의 손상을 최소화 하면서 포즈를 변환한 이미 지를 생성할 수 있으며, 특히 디테일한 색상 표현의 결핍, 무늬 패턴의 모호, 스타일 불일치 등을 해결함으로써, 자연스러운 포즈 변환 이미지를 제공할 수 있는 장점이 있다."}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또 는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘어져서 구현될 수도 있다. 도 2는 본 발명에 따른, 패션 시뮬레이션 장치를 설명하기 위한 블록도이다. 도 1에서 설명하는 패션 시뮬레이션 장치의 구성요소들은 본 발명에 따른 동작을 구현하는데 필수적인 것 은 아니어서, 구성 요소들 중 일부는 생략될 수 있다. 패션 시뮬레이션 장치는, 영상 획득부, 제어부, 메모리 및 출력부를 포함할 수 있다. 패션 시뮬레이션 장치는, 데이터 마이닝, 데이터 분석, 지능형 의사 결정 및 기계 학습 알고리즘을 위해 이용될 정보를 수신, 분류, 저장 및 출력하도록 구성될 수 있다. 영상 획득부는 원본 이미지를 수집할 수 있다. 여기서 원본 이미지는 포즈 변환 전의 이미지를 의미한다. 여기서 영상 획득부는 영상 신호 입력을 위한 카메라를 포함하고, 카메라에 의해 촬영된 원본 이미지를 획 득할 수 있다. 또한 영상 획득부는 외부 장치와 통신하기 위한 통신부 또는 사용자로부터 데이터를 입력 받기 위한 입력부를 포함하고, 통신부 또는 입력부를 통하여 원본 이미지를 수신할 수 있다. 또한 영상 획득부는 타겟 이미지를 획득할 수 있다. 여기서 타겟 이미지는 변환될 포즈 정보(타겟 포즈 정 보)를 포함할 수 있으며, 이 경우 제어부는 타겟 이미지로부터 타겟 포즈 정보를 추출할 수 있다. 또한 영상 획득부는 외부에서 생성된 타겟 포즈 정보를 획득할 수 있다. 출력부는 시각과 관련된 출력을 발생시키는 디스플레이부를 포함할 수 있다. 디스플레이부는 패션 시뮬레 이션 장치에서 처리되는 정보, 예를 들어 패션 시뮬레이션 장치에서 구동되는 응용 프로그램의 실행 화면 정보나 이러한 실행화면 정보에 따른 UI(User Interface), GUI(Graphic User Interface) 정보를 표시할 수 있다. 메모리는 인공지능 모델을 저장할 수 있다. 구체적으로 인공지능 모델은 하드웨어, 소프트웨어 또는 하드웨어와 소프트웨어의 조합으로 구현될 수 있다. 이 경우 인공지능 모델을 구성하는 하나 이상의 명령어는 메모리에 저장될 수 있다. 또한 메모리는 패션 시뮬레이션 장치의 동작을 위한 프로그램 또는 기타 명령어를 저장할 수 있다. 한편 제어부는 패션 시뮬레이션 장치의 전반적인 동작을 제어할 수 있다. 여기서 제어부는, 컨트롤러, 프로세서, 마이크로 프로세서 등의 용어와 혼용되어 사용될 수 있다. 한편 제어부는 메모리에 저장된 인공지능 모델을 독출하여 구동시킬 수 있다. 따라서 이하에서 설명하는 인공지능 모델의 동작은, 제어부의 동작으로도 볼 수 있다. 도 3은 본 발명에 따른 패션 시뮬레이션 방법을 설명하기 위한 순서도이다. 본 발명에 따른 패션 시뮬레이션 방법은, 인코더가, 원본 이미지, 원본 포즈 정보 및 타겟 포즈 정보를 이용하 여, 이미지 특징 및 공간 특징을 포함하는 특징 맵을 추출하는 단계(S310), 디코더가, 상기 특징 맵을 이용하여 포즈 변환 이미지를 생성하는 단계(S330), 스타일 강화 모델이, 상기 원본 이미지로부터 스타일 코드를 추출하 고, 상기 스타일 코드 및 상기 특징 맵을 이용하여 스타일 강화 이미지를 생성하는 단계(S350), 및, 제어부가, 상기 포즈 변환 이미지 및 상기 스타일 강화 이미지를 합성하여 최종 이미지를 생성하는 단계(S370)를 포함할 수 있다. 도 4는 본 발명에 따른, 인공지능 모델을 설명하기 위한 도면이다. 본 발명에 따른 인공지능 모델은, 포즈 변환 모델 및 스타일 강화 모델을 포함할 수 있다. 포즈 변환 모델은, 원본 이미지(Io)를 입력 받아, 원본 이미지의 스타일 정보는 유지하며 인물의 포즈만을 변환하는 것을 목적으로 하는 인공 신경망이다. 따라서 포즈 변환 모델은 입력 데이터를 입력 받아 특징 맵(Ft)를 추출하는 인코더를 포함할 수 있다. 이 경우 인코더는 인코더를 구성하는 요소(신경망, 노드 등)의 파라미터(가중치, 편향 등)에 기반하 여 입력 데이터를 인코딩 하여 특징 맵(Ft)을 출력할 수 있다. 또한 포즈 변환 모델은 특징 맵(Ft)을 입력 받아 포즈 변환 이미지(Ic)를 출력하는 디코더를 포함할 수 있다. 이 경우 디코더는 디코더를 구성하는 요소(신경망, 노드 등)의 파라미터(가중치, 편향 등)에 기 반하여 입력 데이터를 디코딩 하여 포즈 변환 이미지(Ic)를 출력할 수 있다. 한편 포즈 변환 모델에 대한 입력 데이터는, 원본 이미지(Io), 원본 포즈 정보(Ps) 및 타겟 포즈 정보(P t)를 포함할 수 있다. 여기서 원본 포즈 정보(Ps)는 원본 이미지(Io)에 포함되는 인물의 포즈에 대한 정보를 포함하는 것으로, 원본 이미지(Io)에 포함되는 인물의 골격 포인트를 표현하는 스켈레톤 정보일 수 있다. 예를 들어 제어부는 원본 이미지(Io)로부터 원본 포즈 정보(Ps)를 추출할 수 있다. 이 경우 제어부는 사전에 학습된 포즈 추출기를 통해, 원본 이미지(Io)로부터 18개의 골격 포인트를 추출하고, 추출된 골격 포인 트의 좌표를 18채널의 포즈 히트맵으로 나타낸 원본 포즈 정보(Ps)를 생성할 수 있다. 또한 타겟 포즈 정보(Pt)는 원본 이미지(Io)에 포함되는 인물의 변환될 포즈에 대한 정보를 포함하는 것으로, 변환된 포즈를 취하는 인물의 골격 포인트를 표현하는 스켈레톤 정보일 수 있다. 한편, 스타일 강화 모델은, 포즈 변환 모델보다, 원본 이미지(Io)의 스타일 정보를 강화하여 표현하 는 것을 목적으로 하는 인공 신경망이다. 여기서 스타일 정보는 색상, 질감 및 패턴 중 적어도 하나를 포함할 수 있다. 여기서 패턴은 티셔츠의 스프라이 트 무늬, 바둑판 무늬 등과 같이, 색상이나 질감이 반복되어 나타나는 패턴을 의미할 수 있다. 스타일 강화 모델에 대한 입력 데이터는 원본 이미지(Io)일 수 있다. 즉 포즈 변환 모델보다 원본 이 미지(Io)의 스타일 정보를 강화하여 표현하기 위해, 포즈 변환 모델에서는 원본 이미지(Io), 원본 포즈 정보(Ps) 및 타겟 포즈 정보(Pt)가 입력 데이터로 사용된 것에 반해, 스타일 강화 모델에서는 원본 이미지 (Io)만이 입력 데이터로 사용될 수 있다. 그리고 스타일 강화 모델은 원본 이미지(Io)로부터 색상, 질감 및 패턴에 대한 특징을 포함하는 스타일 코 드를 추출할 수 있다. 또한 스타일 강화 모델은 스타일 코드 및 특징 맵(Ft)을 이용하여 스타일 강화 이미 지(Rt)를 출력할 수 있다. 다음은 S310과 관련하여, 도 4와 함께 도 5를 참고하여 설명한다. 도 5는 본 발명에 따른, 포즈 변환 모델의 동작을 구체적으로 설명하기 위한 도면이다. 제어부는 원본 이미지(Io), 원본 포즈 정보(Ps) 및 타겟 포즈 정보(Pt)를 포즈 변환 모델에 입력할 수 있다. 이 경우 포즈 변환 모델의 인코더는, 원본 이미지(Io), 원본 포즈 정보(Ps) 및 타겟 포즈 정보(Pt)를 이용하여, 특징 맵(Ft)을 추출하여 출력할 수 있다. 여기서 특징 맵(Ft)은, 원본 이미지(Io), 원본 포즈 정보(Ps) 및 타겟 포즈 정보(Pt)를 다운 샘플링 하여 획득 한 것으로, 이미지 특징(Fin) 및 공간 특징(Fpn)을 포함할 수 있다. 여기서 공간 특징(Fpn)은 인물의 포즈에 대한 특징(feature) 벡터일 수 있으며, 변환 후의 포즈(타겟 포즈)에 대한 특징(공간적 정보)을 포함할 수 있다. 또한 공간 특징(Fpn)은 인물의 자세에 대한 특징뿐만 아니라 인물이 착용한 옷, 액세서리 등에 대한 특징을 포함할 수 있다. 또한 이미지 특징(Fin)은, 인물의 포즈 및 스타일 정보에 대한 특징(feature) 벡터일 수 있다. 즉 이미지 특징 (Fin)은 변환 후의 포즈(타겟 포즈)에 원본 이미지(Io)의 스타일 정보가 반영된 정보일 수 있다. 한편 원본 포즈 정보(Ps)로부터 타겟 포즈 정보(Pt)로 변환되는 범위가 클수록 스타일 정보 및 포즈에 왜곡이 많이 발생하는 반면, 원본 포즈 정보(Ps)로부터 타겟 포즈 정보(Pt)로 변환되는 범위가 작을수록 정확도가 높아 지게 된다. 따라서 본 발명에서는, 원본 포즈 정보(Ps)로부터 타겟 포즈 정보(Pt) 사이의 중간 포즈들에 대한 중간 특징 맵 들을 산출하는 방식으로, 정확도를 높힌다. 구체적으로, 포즈 변환 모델의 인코더는 원본 포즈 정보(Ps) 및 타겟 포즈 정보(Pt) 사이의 중간 포 즈에 대한 중간 특징 맵을 생성할 수 있다. 더욱 구체적으로, 최초에 원본 이미지(Io)가 포즈 변환 모델의 인코더에 입력될 수 있다. 이 경우 인 코더는 다운 샘플링 컨볼루션 레이어를 통하여 초기 이미지 특징(Fio)을 출력할 수 있다. 또한 최초에, 원본 포즈 정보(Ps) 및 타겟 포즈 정보(Pt)가 인코더에 입력될 수 있다. 이 경우 인코더 는 다운 샘플링 컨볼루션 레이어를 통하여 초기 공간 특징(Fpo)를 출력할 수 있다. 그리고 초기 이미지 특징(Fio) 및 초기 공간 특징(Fpo)을 포함하는 초기 공간 맵은, 인코더 내 복수의 중 간 생성 유닛(Unit 1, Unit 2, Unit n)을 순차적으로 통과하면서 변환되고, 이에 따라 최종적으로 이미지 특징 (Fin) 및 공간 특징(Fpn)을 포함하는 특징 맵(Ft)가 출력될 수 있다. 여기서 유닛의 개수(n)는 원본 이미지의 종류나 기타 설정에 따라 변경될 수 있다. 그리고 복수의 중간 생성 유닛(Unit 1, Unit 2, Unit n) 각각은, 이전 중간 특징 맵을 이용하여, 해당 중간 생 성 유닛에 대응하는 중간 타겟 포즈가 반영된 현재 중간 특징 맵을 생성할 수 있다. 이하에서는 제2 중간 생성 유닛(Unit 2)의 예를 들어 설명하며, 제2 중간 생성 유닛(Unit 2)의 동작은 다른 중 간 생성 유닛에도 적용될 수 있다. 도 5b를 참고하면, 제2 중간 생성 유닛(Unit 2)은 이전 중간 생성 유닛(Uint 1)로부터 이전 중간 특징 맵을 수 신할 수 있다. 여기서 이전 중간 특징 맵은, 이전 중간 이미지 특징(Fi1) 및 이전 중간 공간 특징(Fp1)를 포함 할 수 있다. 그리고, 제2 중간 생성 유닛(Unit 2)은 하나 이상의 포즈 처리 레이어로 구성되는 포즈 처리부를 포함하고, 이전 중간 특징 맵에 포함된 이전 중간 공간 특징(Fp1)을 포즈 처리하여 포즈 코드를 획득할 수 있다. 이 경우 제2 중간 생성 유닛(Unit 2)에는, 이전 중간 공간 특징(Fp1)뿐만 아니라, 제2 중간 생성 유닛(Unit 2) 에 상응하는 중간 타겟 포즈가 제공될 수 있다. 즉 제어부는 원본 포즈 정보(Ps) 및 타겟 포즈 정보(Pt)를 이용하여, 원본 포즈 정보(Ps)로부터 타겟 포즈 정보(Pt)로 진행하는 과정의 중간 자세에 대한 중간 타겟 포즈 를 생성할 수 있다. 또한 제어부는 중간 생성 유닛의 개수와 동일한 개수의 중간 타겟 포즈들을 생성하고, 중간 타겟 포즈들을 포즈가 변환되는 순서에 따라 중간 생성 유닛들(Unit 1, Unit 2, Unit n)에 순차적으로 제 공할 수 있다. 따라서 제2 중간 생성 유닛(Unit 2)에는, 원본 포즈 정보(Ps)로부터 타겟 포즈 정보(Pt)로 진행 하는 과정의 두번째 중간 자세에 대한 중간 타겟 포즈가 제공될 수 있다. 이 경우 제2 중간 생성 유닛(Unit 2)은, 제2 중간 생성 유닛(Unit 2)에 상응하는 중간 타겟 포즈를 이용하여 이 전 중간 공간 특징(Fp1)을 포즈 처리함으로써 포즈 코드를 획득할 수 있다. 즉, 제2 중간 생성 유닛(Unit 2)의 포즈 처리부에서 출력되는 포즈 코드는, 제2 중간 생성 유닛(Unit 2)에 대응하는 중간 타겟 포즈가 반영될 수 있다. 한편 제2 중간 생성 유닛(Unit 2)은 하나 이상의 이미지 처리 레이어로 구성되는 이미지 처리부를 포함하 고, 이전 중간 특징 맵에 포함된 이전 중간 이미지 특징(Fi1)을 이미지 처리하여 이미지 코드를 획득할 수 있다. 한편 이전 중간 이미지 특징(Fi1)은 제1 중간 생성 유닛(Unit 1)에 상응하는 중간 타겟 포즈가 적용된 스타일 정보를 포함하고, 제2 중간 생성 유닛(Unit 2)은 이전 중간 이미지 특징(Fi1)을 이용하여 이미지 코드를 생성하 였다. 즉 제2 중간 생성 유닛(Unit 2)에서 생성된 이미지 코드는 아직, 이전의 중간 타겟 포즈 정보를 반영하고 있는 상태이다. 따라서 이미지 처리부는, 산출된 이미지 코드에 제2 중간 생성 유닛(Unit 2)에서 생성한 포즈 코드를 반영 하여 현재 중간 이미지 특징(Fi2)을 출력할 수 있다. 구체적으로 이미지 처리부는 제2 중간 생성 유닛(Unit 2)의 포즈 처리부에서 출력되는 포즈 코드에 시그모이드 함수()를 적용하여, 제2 중간 생성 유닛(Unit 2)에 상응하는 중간 타겟 포즈에서의 마스크 정보 (Mt)를 생성할 수 있다. 그리고 이미지 처리부는 제2 중간 생성 유닛(Unit 2)에서 출력된 이미지 코드와 마스크 정보(Mt) 간의 요소 별 곱셈(multiply)을 통하여, 현재 중간 이미지 특징(Fi2)을 출력할 수 있다. 즉, 중간 이미지 특징(Fi2)은 제2 중간 생성 유닛(Unit 2)에 상응하는 중간 타겟 포즈가 적용된 스타일 정보를 포함 할 수 있다. 한편 포즈 처리부에서 출력된 포즈 코드는, 제2 중간 생성 유닛(Unit 2)에 상응하는 중간 타겟 포즈를 취 하는 인물의 골격 포인트에 대한 정보를 포함하고 있다. 그리고 포즈 처리부는 이전 중간 특징 맵에 포함된 이전 중간 이미지 특징(Fio)을 포즈 코드에 반영하여 현재 중간 공간 특징(Fp2)을 출력할 수 있다. 즉 포즈 처리부는 이전 중간 이미지 특징(Fio)과 포즈 코드 간의 접합(depth Concatenation) 연산을 통해, 중간 타겟 포즈를 취하는 인물의 골격 포인트 및 골격 포인트를 연결하는 뼈대에 대한 정보를 포함하는 현재 중간 공간 특징(Fp2)을 출력할 수 있다. 즉 포즈 처리부는 이 전 중간 이미지 특징(Fio)과 포즈 코드를 이용하여, 골격 포인트 간의 오차가 보정되고 골격 포인트 간의 연결 정보가 강화된 현재 중간 공간 특징(Fp2)을 생성하고, 생성된 현재 중간 공간 특징(Fp2)을 다음의 중간 생성 유 닛에 전달할 수 있다. 한편 동일한 방식으로, 마지막 중간 생성 유닛(Unit n)은 현재 중간 공간 특징(Fpn) 및 현재 중간 이미지 특징 (Fin)을 포함하는 중간 특징 맵을 출력할 수 있다. 이 경우 마지막 중간 생성 유닛(Unit n)에서 출력된 중간 특징 맵은, 포즈 변환 모델의 인코더에서 출력한 특징 맵(Ft)이 될 수 있다. 즉 마지막 중간 생성 유닛(Unit n)에서 출력된 중간 공간 특징(Fpn)에는 타 겟 포즈 정보(Pt)가 반영되고, 마지막 중간 생성 유닛(Unit n)에서 출력된 중간 이미지 특징(Fin)은 타겟 포즈 정보(Pt)가 적용된 스타일 정보가 반영될 수 있다. 다음으로 도 4를 참고하면, 포즈 변환 모델의 디코더는 이미지특징 특징 및 공간 특징을 포함하는 특 징 맵(Ft)을 이용하여 포즈 변환 이미지(Ic)를 생성할 수 있다. 구체적으로 포즈 변환 모델의 디코더는 하나 이상의 업샘플링 레이어를 포함하며, 하나 이상의 업샘 플링 레이어는 특징 맵(Ft)을 업샘플링 하여 타겟 포즈(Pt)가 반영된 포즈 변환 이미지(Ic)를 생성할 수 있다.한편 포즈 변환 모델의 포즈 변환 프로세스(Gp)는 다음과 같은 함수로 표현될 수 있다. 수학식 1"}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "(Ic: 포즈 변환 이미지, Go: 포즈 변환 모델의 포즈 변환 프로세스 함수, Io: 원본 이미지, Ps: 원본 포즈 정보, Pt: 타겟 포즈 정보) 한편 포즈 변환 이미지(Ic)는 타겟 포즈를 취하는 인물을 포함하며, 이 인물에는 원본 이미지(Io)에 포함된 인 물의 색상, 질감, 패턴 등에 대한 스타일 정보가 반영되어 있다. 다만 도 1에서 설명한 바와 같이, 이러한 스타 일 정보는 왜곡되어 있거나 일부가 누락되어 있는 상태이다. 그리고 이렇게 불완전한 스타일 정보는, 스타일 강 화 모델에 의해 보완될 수 있다. 이와 관련해서는 도 4와 함께 도 6을 참고하여 설명한다. 도 6은 본 발명에 따른 스타일 강화 모델의 동작을 설명하기 위한 도면이다. 본 발명에 따른 스타일 강화 모델은 스타일 인코더 및 스타일 디코더를 포함할 수 있다. 그리고 스타일 강화 모델은, 원본 이미지(Io)로부터 스타일 코드를 추출하고, 스타일 코드 및 특징 맵(Ft)을 이용 하여 스타일 강화 이미지(Rt)를 생성할 수 있다(S350). 먼저 스타일 인코더는, 원본 이미지(Io)로부터 스타일 정보와 관련된 특징(feature)을 추출할 수 있다. 구체적으로 스타일 인코더는 하나 이상의 스타일 인코딩 레이어를 포함할 수 있다. 이 경우 하나 이 상의 스타일 인코딩 레이어는 원본 이미지(Io)를 다운샘플링 함으로써 색상, 질감 및 패턴에 대한 특징 (feature)을 추출할 수 있다. 또한 스타일 인코더 내 완전 연결 신경망(FC)는, GAP(Global Average Pooling)를 통하여, 추출된 특징 (feature)을 스타일 코드(style code)로 전환할 수 있다. 이에 따라 스타일 코드는, 원본 이미지(Io)로부터 추 출된, 색상, 질감 및 패턴에 대한 특징을 포함할 수 있다. 다음으로, 스타일 디코더는 스타일 코드 및 특징 맵(Ft)을 이용하여 스타일 강화 이미지(Rt)를 생성할 수 있다. 여기서 스타일 강화 이미지(Rt)는 Detail Residual Map이라 명칭될 수도 있다. 구체적으로 스타일 디코더는 복수의 업샘플링 레이어를 포함할 수 있다. 이 경우 복수의 업샘플링 레이어는 특징 맵(Ft)에 스타일 코드를 매핑하여 업샘플링을 함으로써, 스타일 강화 이미지(Rt)를 생성할 수 있다. 즉 앞서 설명한 특징 맵(Ft)은 공간 특징을 포함하고, 공간 특징에는 타겟 포즈 정보가 반영된다. 그리고 복수 의 업샘플링 레이어는 특징 맵(Ft)에 포함되는 공간 특징과 스타일 코드를 매핑 및 업샘플링 하여, 스타일 강화 이미지(Rt)를 생성할 수 있다. 또한 복수의 업샘플링 레이어는, 개별적으로 스타일 코드를 반영하여 강화 맵을 출력할 수 있다. 구체적으로 복수의 업샘플링 레이어 각각은, 이전 업샘플링 레이어에서 출력된 강화 맵에 스타일 코드를 매핑하여 현재 강화 맵을 출력할 수 있다. 예를 들어 제1 업샘플링 레이어는 특징 맵(Ft)에 포함되는 공간 특징과 스타일 코드를 매핑 및 업샘플링 하여 제1 강화 맵을 출력할 수 있다. 또한 제2 업샘플링 레이어는 제1 강화 맵과 스타일 코드를 매핑 및 업샘플링 하 여 제2 강화 맵을 출력할 수 있다. 이와 같은 방식으로, 복수의 업샘플링 레이어 중 마지막 업샘플링 레이어가 출력한 강화 맵이 스타일 강화 이미지(Rt)로 사용될 수 있다. 한편 하나 이상의 스타일 디코딩 레이어는, 적응적 인스턴트 정규화(Adaptive Instance Normalization, AdaIN) 레이어로 구성될 수 있다. 한편 스타일 강화 이미지(Rt)는 스타일 코드와 특징 맵(Ft)의 매핑 및 업샘플링을 반복하여 생성되었기 때문에, 스타일 정보에 타겟 포즈 정보가 반영된 상태이다. 또한 포즈 변환 모델에서 추출된 이미지 특징은 포즈와관련된 정보와 스타일에 관련된 정보가 혼합된 것인데 반해, 스타일 강화 모델에서 추출된 스타일 코드는 원본 이미지(Io)만으로부터 스타일에 관련된 정보를 뽑아낸 것이다. 따라서 스타일 강화 이미지(Rt)는 포즈 변 환 이미지(Ic)에 비해 강화된 스타일 정보를 포함할 수 있다. 한편 스타일 강화 모델의 스타일 디코더의 스타일 강화 프로세스(GT)는 다음과 같은 함수로 표현될 수 있다. 수학식 2"}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "(Rt: 스타일 강화 이미지, GT: 스타일 강화 함수, style code: 스타일 코드, Ft: 특징 맵) 다음으로, 제어부는 포즈 변환 이미지(Ic)에 스타일 강화 이미지(Rt)를 합성하여 최종 이미지(It)를 생성 할 수 있다(S370). 이 경우 제어부는 포즈 변환 이미지(Ic) 상에 스타일 강화 이미지(Rt)를 중첩할 수 있으며, 알파 블랜딩 기법을 사용하여 포즈 변환 이미지(Ic) 상에 스타일 강화 이미지(Rt)를 중첩할 수 있다. 한편 도 4를 다시 참고하면, 인공지능 모델은 얼굴 변환 모델을 더 포함할 수 있다. 여기서 얼굴 변환 모델은, 원본 이미지(Io)로부터 얼굴 이미지를 추출하고, 얼굴 이미지의 스타일 정보는 유지하며 얼굴의 포즈만을 변환하는 것을 목적으로 하는 인공 신경망이다. 따라서 얼굴 변환 모델은 원본 이미지(Io)로부터 얼굴을 탐지하여 얼굴 이미지(Fo)를 생성하는 얼굴 탐지 기를 포함할 수 있다. 또한 앞서 설명한 포즈 변환 모델의 동작은, 얼굴 강화 모델의 동작에도 적용될 수 있다. 즉 제어부는 얼굴 이미지(Fo), 원본 얼굴 포즈 정보 및 타겟 얼굴 포즈 정보(FS)를 포함하는 입력 데이터 를 얼굴 강화 모델에 제공할 수 있다. 이 경우 얼굴 강화 모델은 얼굴 이미지(Fo), 원본 얼굴 포즈 정보 및 타겟 얼굴 포즈 정보(Fs)를 이용하여 얼굴 포즈 변환 이미지(Fg)를 생성할 수 있다. 구체적으로, 얼굴 강화 모델의 인코더는 입력 데이터를 인코딩 하여 얼굴 특징 맵을 출력하고, 얼굴 강화 모델의 디코더는 얼굴 특징 맵을 디코딩하여 얼굴 포즈 변환 이미지(Fg)를 출력할 수 있다. 이 경우 제어부는 최종 이미지(It)에 얼굴 포즈 변환 이미지(Fg)를 추가적으로 합성하여 2차 최종 이미지 (IF)를 생성할 수 있다. 이는 다음과 같은 수학식으로 표현될 수 있다. 수학식 3"}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 4"}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 3에서, 는 2D 가우시간(Gaussian) 커널을 의미하고, *는 2D 컨볼루션 연산자를 의미할 수 있다. 또한 1BF는 인디케이터(indicator) 함수로, 얼굴 영역에서는 1을 반환하고, 나머지 영역에서는 0을 반영할 수 있 다. 따라서 수학식 4에 따라, 얼굴 영역에서는 얼굴 포즈 변환 이미지(Fg)가 반영되고, 나머지 영역에서는 최종 이 미지(It)가 반영되는, 2차 최종 이미지(IF)가 생성될 수 있다. 다음은 인공지능 모델을 트레이닝 하기 위한 손실 함수에 대하여 설명한다. 먼저 포즈 변환 모델을 트레이닝 하기 위한 손실 함수는 다음과 같이 정의될 수 있다. 수학식 5"}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "(LPTP: 포즈 변환 모델에 대한 손실 함수, Lrecon: 정답 이미지( )와 포즈 변환 이미지(Ic)간의 차이, Lper: Perceptual loss, : 상수, : 상수) 즉 제어부는 정답 이미지( )(타겟 포즈를 취하고 완전한 스타일 정보를 가지고 있는 이미지)와 포즈 변 환 이미지(Ic)간의 차이(Lrecon)를 이용하여 포즈 변환 모델을 트레이닝 할 수 있다. 더욱 구체적으로 정 답 이미지( )와 포즈 변환 이미지(Ic)간의 차이(Lrecon)는, 정답 이미지( )와 포즈 변환 이미지(Ic)의 각 픽셀 값을 유클리드 거리(Euclidean Distance)로 정규화(Normalized)함으로써 산출될 수 있다. 또한 Lper는 Perceptual loss를 의미하는 것으로, 다음과 같이 표현될 수 있다. 수학식 6"}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "( : 미리 학습된 VGG19 네트워크, l: 레이어의 인덱스, C: 채널수, H: 높이, W: 넓이, : 정답 이미지, Ic: 포즈 변환 이미지) 다음으로, 수학식 5의 손실 함수에, 스타일 강화 모델을 트레이닝 하기 위한 손실 함수와, 생성적 적대 신 경망(Generative Adversarial Network, GAN) 알고리즘에 기반하여 포즈 변환 모델 및 스타일 강화 모델 을 트레이닝 하기 위한 손실 함수가 추가될 수 있다. 이는 다음과 같은 수학식으로 정의될 수 있다. 수학식 7"}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "(LDEP: 포즈 변환 모델 및 스타일 강화 모델에 대한 손실 함수, Lsty: 스타일 강화 모델에 대한 손실 함수, LGAN: GAN 알고리즘에 기반한 손실 함수) 또한 Lsty는 Gram Matrix에 기반한 손실 함수로, 다음과 같이 표현될 수 있다. 수학식 8"}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "(Lsty: 스타일 강화 모델에 대한 손실 함수, : 미리 학습된 VGG19 네트워크, l: 레이어의 인덱스, C: 채널수, H: 높이, W: 넓이, : 정답 이미지, IF: 최종 이미지) 이 경우 제어부는 정답 이미지( )와 최종 이미지(IF)를 VGG19 네트워크에 입력하고, 레이어에서 출력한 Style Representation에 Gram Matrix 함수(G)를 활용하여 내적을 수행함으로써, 최소 손실 값을 산출할 수 있 다. 즉 Gram Matrix 함수(G)를 활용하여 레이어의 Style Representation를 내적함으로써, 스타일 정보에 더 집 중한 손실 함수가 설계될 수 있다. 한편 LGAN은 GAN 알고리즘에 기반한 손실 함수로 다음과 같이 표현될 수 있다. 수학식 9"}
{"patent_id": "10-2021-0146116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "즉 GAN 알고리즘에 기반한 손실 함수(LGAN)는 두 개의 조건부 디스크립터를 포함할 수 있다. 구체적으로 GAN 알 고리즘에 기반한 손실 함수(LGAN)는 스타일 디스크립터(Ds) 및 포즈 디스크립터(Dp)를 포함할 수 있다. 이 경우 스타일 디스크립터(Ds)는 스타일 정보에 대하여, 원본 이미지(Io)와 최종 이미지(It) 간의 제1 차이와, 원본 이미지(Io)와 정답 이미지( ) 간의 제2 차이를 산출하고, 제1 차이와 제2 차이 간의 차를 산출할 수 있 다. 이에 따라, 원본 이미지(Io)와 최종 이미지(It)의 스타일 정보에 대하여, 제1 차이와 제2 차이의 차가 0에 가까울수록 GAN 알고리즘에 기반한 손실 함수(LGAN)는 작아질 수 있다. 또한 포즈 디스크립터(Dp)는 포즈 정보에 대하여, 타겟 포즈 정보(Pt)와 최종 이미지(It) 간의 제1 차이와, 타 겟 포즈 정보(Pt)와 정답 이미지( ) 간의 제2 차이를 산출하고, 제1 차이와 제2 차이 간의 차를 산출할 수 있 다. 이에 따라, 타겟 포즈 정보(Pt)와 최종 이미지(It)의 포즈 정보에 대하여, 제1 차이와 제2 차이의 차가 0에 가까울수록 GAN 알고리즘에 기반한 손실 함수(LGAN)는 작아질 수 있다. 현재 상용 온라인 패션 쇼핑몰 등에서 적용된 가상 피팅 서비스 기술의 경우, 포즈가 고정되어 있을 뿐만 아니 라, 옷의 질감, 색감, 패턴 무늬 등을 실감나게 표현하지 못하는 한계가 있다. 다만 본 발명에 따르면, 색상, 색감, 질감, 패턴 등과 같은 스타일 정보의 손상을 최소화 하면서 포즈를 변환한 이미지를 생성할 수 있으며, 특히 디테일한 색상 표현의 결핍, 무늬 패턴의 모호, 스타일 불일치 등을 해결함으 로써, 자연스러운 포즈 변환 이미지를 제공할 수 있는 장점이 있다. 또한 본 발명에 따르면, 또한 원본 이미지로부터 포즈가 변경되는 경우, 원본 이미지에서는 표현이 되지 않았던 영역의 스타일 정보까지 명확하게 표현할 수 있는 장점이 있다. 이에 따라 본 발명은 패션, 보안, 영상 제작 등 다양한 분야에 적용될 수 있다. 예를 들어 본 발명은, CCTV 등 의 영상처리 보안 분야에서 용의자를 다각적으로 분석하는데 활용될 수도 있다. 즉 본 발명에서는 원본 이미지 한장으로 다양한 포즈의 이미지를 생성할 수 있을 뿐만 아니라, 용의자가 입은 옷을 손상 없이 재연할 수 있기때문에, 각종 범죄 현장이나 보안 분야에서 용의자를 분석하는데 효과적으로 사용될 수 있다. 또 다른 예를 들어 본 발명은, 온라인 쇼핑몰을 이용하는 소비자에게 다양한 포즈의 패션 정보를 제공하는데 사 용될 수 있으며, 영상 제작에 있어서 추가 촬영 없이도 인물의 다양한 포즈를 생성해낼 수 있는 장점이 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 상기 컴 퓨터는 제어부를 포함할 수도 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니 되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하 고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2021-0146116", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 원본 이미지를 현재 구현된 HPT 기술에 따라 변환한 결과를 도시한 도면이다. 도 2는 본 발명에 따른, 패션 시뮬레이션 장치를 설명하기 위한 블록도이다. 도 3은 본 발명에 따른 패션 시뮬레이션 방법을 설명하기 위한 순서도이다. 도 4는 본 발명에 따른, 인공지능 모델을 설명하기 위한 도면이다. 도 5는 본 발명에 따른, 포즈 변환 모델의 동작을 구체적으로 설명하기 위한 도면이다. 도 6은 본 발명에 따른 스타일 강화 모델의 동작을 설명하기 위한 도면이다."}
