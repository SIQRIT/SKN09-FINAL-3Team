{"patent_id": "10-2021-0062760", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0064123", "출원번호": "10-2021-0062760", "발명의 명칭": "안전 벨트의 착용 상태 인식 방법, 장치, 전자 기기 및 저장 매체", "출원인": "베이징 바이두 넷컴 사이언스 앤 테크놀로지 코.,", "발명자": "왕, 커야오"}}
{"patent_id": "10-2021-0062760", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "안전 벨트의 착용 상태 인식 방법에 있어서,교통 수단에 대해 모니터링하여 획득된 모니터링 이미지를 획득하는 단계;상기 모니터링 이미지에 대해 얼굴 인식을 수행하여, 얼굴 영역을 획득하는 단계;상기 얼굴 영역의 크기 및 위치에 따라, 상기 모니터링 이미지로부터 타겟 영역을 결정하는 단계; 및,상기 타겟 영역의 이미지 특징에 따라, 안전 벨트의 착용 상태를 인식하는 단계;를 포함하는,것을 특징으로 하는 안전 벨트의 착용 상태 인식 방법."}
{"patent_id": "10-2021-0062760", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 얼굴 영역의 크기 및 위치에 따라, 상기 모니터링 이미지로부터 타겟 영역을 결정하는 단계는,상기 얼굴 영역의 높이에 따라, 간격 거리를 결정하는 단계; 및,상기 얼굴 영역의 위치에 따라, 상기 얼굴 영역 하부에 위치하고 상기 얼굴 영역과 상기 간격 거리를 충족하는영역을 상기 타겟 영역으로 하는 단계;를 포함하는,것을 특징으로 하는 안전 벨트의 착용 상태 인식 방법."}
{"patent_id": "10-2021-0062760", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 얼굴 영역의 위치에 따라, 상기 얼굴 영역 하부에 위치하고 상기 얼굴 영역과 상기 간격 거리를 충족하는영역을 상기 타겟 영역으로 하는 단계는,상기 얼굴 영역의 면적에 따라, 검출 프레임을 생성하는 단계 - 상기 검출 프레임의 면적은 상기 얼굴 영역의면적의 설정 배수임 - ;상기 얼굴 영역과 상기 간격 거리를 가지도록 상기 검출 프레임을 상기 얼굴 영역의 하부에 설치하는 단계; 및,상기 모니터링 이미지 중 상기 검출 프레임 내에 위치한 부분을 상기 타겟 영역으로 하는 단계;를 포함하는,것을 특징으로 하는 안전 벨트의 착용 상태 인식 방법."}
{"patent_id": "10-2021-0062760", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 얼굴 영역의 크기 및 위치에 따라, 상기 모니터링 이미지로부터 타겟 영역을 결정하는 단계 이후에,상기 타겟 영역에 대해 해상도 변환을 수행하여, 변환된 상기 타겟 영역이 타겟 해상도에 부합되도록 하는단계;를 더 포함하는,것을 특징으로 하는 안전 벨트의 착용 상태 인식 방법."}
{"patent_id": "10-2021-0062760", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 타겟 영역에 대해 해상도 변환을 수행하여, 변환된 상기 타겟 영역이 타겟 해상도에 부합되도록 하는 단계이후에,공개특허 10-2021-0064123-3-상기 타겟 해상도의 타겟 영역 중 각 픽셀점의 값에 대해 정규화 처리를 수행하여, 각 픽셀점의 값이 타겟 값구간 내에 있도록 하는 단계;를 더 포함하는,것을 특징으로 하는 안전 벨트의 착용 상태 인식 방법."}
{"patent_id": "10-2021-0062760", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 타겟 영역의 이미지 특징에 따라, 안전 벨트의 착용 상태를 인식하는 단계는,상기 타겟 영역의 이미지 특징에 따라, 분류하는 단계; 및,분류하여 획득된 카테고리에 따라, 안전 벨트의 착용 상태를 결정하는 단계;를 포함하는,것을 특징으로 하는 안전 벨트의 착용 상태 인식 방법."}
{"patent_id": "10-2021-0062760", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "안전 벨트의 착용 상태 인식 장치에 있어서,교통 수단에 대해 모니터링하여 획득된 모니터링 이미지를 획득하는 획득 모듈;상기 모니터링 이미지에 대해 얼굴 인식을 수행하여, 얼굴 영역을 획득하는 얼굴 인식 모듈;상기 얼굴 영역의 크기 및 위치에 따라, 상기 모니터링 이미지로부터 타겟 영역을 결정하는 결정 모듈; 및,상기 타겟 영역의 이미지 특징에 따라, 안전 벨트의 착용 상태를 인식하는 상태 인식 모듈;을 포함하는,것을 특징으로 하는 안전 벨트의 착용 상태 인식 장치."}
{"patent_id": "10-2021-0062760", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 결정 모듈은,상기 얼굴 영역의 높이에 따라, 간격 거리를 결정하는 결정 유닛; 및,상기 얼굴 영역의 위치에 따라, 상기 얼굴 영역 하부에 위치하고 상기 얼굴 영역과 상기 간격 거리를 충족하는영역을 상기 타겟 영역으로 하는 처리 유닛;을 포함하는,것을 특징으로 하는 안전 벨트의 착용 상태 인식 장치."}
{"patent_id": "10-2021-0062760", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 처리 유닛은 구체적으로,상기 얼굴 영역의 면적에 따라, 검출 프레임을 생성하되, 상기 검출 프레임의 면적은 상기 얼굴 영역의 면적의설정 배수이고, 상기 설정 배수는 2보다 크거나 같은 정수이며;상기 얼굴 영역과 상기 간격 거리를 가지도록 상기 검출 프레임을 상기 얼굴 영역의 하부에 설치하고;상기 모니터링 이미지 중 상기 검출 프레임 내에 위치한 부분을 상기 타겟 영역으로 하는,것을 특징으로 하는 안전 벨트의 착용 상태 인식 장치."}
{"patent_id": "10-2021-0062760", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 장치는,상기 타겟 영역에 대해 해상도 변환을 수행하여, 변환된 상기 타겟 영역이 타겟 해상도에 부합되도록 하는 변환모듈;을 더 포함하는,공개특허 10-2021-0064123-4-것을 특징으로 하는 안전 벨트의 착용 상태 인식 장치."}
{"patent_id": "10-2021-0062760", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 장치는,상기 타겟 해상도의 타겟 영역 중 각 픽셀점의 값에 대해 정규화 처리를 수행하여, 각 픽셀점의 값이 타겟 값구간 내에 있도록 하는 처리 모듈;을 더 포함하는,것을 특징으로 하는 안전 벨트의 착용 상태 인식 장치."}
{"patent_id": "10-2021-0062760", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서,상기 상태 인식 모듈은 구체적으로,상기 타겟 영역의 이미지 특징에 따라, 분류하고;분류하여 획득된 카테고리에 따라, 안전 벨트의 착용 상태를 결정하는,것을 특징으로 하는 안전 벨트의 착용 상태 인식 장치."}
{"patent_id": "10-2021-0062760", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "전자 기기에 있어서,적어도 하나의 프로세서; 및,상기 적어도 하나의 프로세서와 통신 가능하게 연결되는 메모리를 포함하고;상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령이 상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 제1항 내지 제6항 중 어느 한 항에 따른 안전 벨트의 착용 상태 인식 방법을 수행하도록 하는,것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2021-0062760", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체에 있어서,상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제6항 중 어느 한 항에 따른 안전 벨트의 착용 상태 인식 방법을수행하도록 하는,것을 특징으로 하는 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2021-0062760", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "컴퓨터 판독 가능 저장 매체에 저장되어 있는 컴퓨터 프로그램에 있어서,상기 컴퓨터 프로그램중의 명령이 실행될 경우, 제1항 내지 제6항 중 어느 한 항에 따른 안전 벨트의 착용 상태인식 방법이 실행되는, 것을 특징으로 하는 컴퓨터 판독 가능 저장 매체에 저장되어 있는 컴퓨터 프로그램."}
{"patent_id": "10-2021-0062760", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 컴퓨터 비전, 인공 지능, 딥 러닝 분야에 관한 안전 벨트의 착용 상태 인식 방법, 장치, 전자 기기 및 저장 매체를 개시한다. 구현 수단은, 교통 수단에 대해 모니터링하여 획득된 모니터링 이미지에 대해 얼굴 인식 을 수행하여, 얼굴 영역을 획득하고, 얼굴 영역의 크기 및 위치에 따라, 모니터링 이미지로부터 타겟 영역을 결 정하며, 계속하여 타겟 영역의 이미지 특징에 따라, 안전 벨트의 착용 상태를 인식하는 것이다. 상기 해결수단은 본 출원에서 타겟 영역으로 기재된 안전 벨트의 착용 영역을 추정하고, 상기 타겟 영역에 대해서만 안전 벨트의 착용 상태 인식을 수행하여, 모니터링 이미지 중 다른 쓸모없는 정보의 간섭을 효과적으로 감소시키며, 계산량을 감소시킬 수 있어 인식 속도를 향상시키고, 차량용 기기와 같은 컴퓨팅 기능이 상대적으로 낮은 기기에 적용되어, 상기 방법의 적용성을 향상시킬 수 있다."}
{"patent_id": "10-2021-0062760", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 이미지 처리 분야에 관한 것으로, 구체적으로 컴퓨터 비전, 인공 지능, 딥 러닝 기술 분야에 관한 것 이고, 특히 안전 벨트의 착용 상태 인식 방법, 장치, 전자 기기 및 저장 매체에 관한 것이다."}
{"patent_id": "10-2021-0062760", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "안전 벨트는 교통 수단의 능동형 안전 장비로, 교통 수단에 충돌이 발생하거나 예상치 못한 상황에서 급제동할 경우, 제약 작용을 통해, 운전자 또는 승객을 좌석에 구속시킴으로써, 운전자 또는 승객이 2차 충돌을 당하거나 심지어 교통 수단으로부터 튕겨 나가는 경우를 방지한다. 따라서, 운전자 또는 승객이 안전 벨트를 착용하고 있는지 여부를 식별하는 것은 매우 중요한 바, 예를 들어 안 전 벨트를 착용하지 않았을 경우 알림 또는 경고를 하여 안전 주행을 보장하는 동시에 교통 법규 준수에 대한 사람들의 의식도 높일 수 있다."}
{"patent_id": "10-2021-0062760", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 출원은 적어도 일정한 정도에서 관련 기술의 기술적 문제 중 하나를 해결하는 것을 목적으로 한다."}
{"patent_id": "10-2021-0062760", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 출원은 안전 벨트의 착용 상태 인식 방법, 장치, 전자 기기 및 저장 매체를 제공하여, 본 출원에서 타겟 영 역으로 기재된 안전 벨트의 착용 영역을 추정하고, 상기 타겟 영역에 대해서만 안전 벨트의 착용 상태 인식을 수행하는 것을 구현하여, 모니터링 이미지 중 다른 쓸모없는 정보의 간섭을 효과적으로 감소시키며, 계산량을 감소시킬 수 있어 인식 속도를 향상시키고, 차량용 기기와 같은 컴퓨팅 기능이 상대적으로 낮은 기기에 적용되 어, 상기 방법의 적용성을 향상시킬 수 있다. 본 출원의 제1 양태의 실시예는 안전 벨트의 착용 상태 인식 방법을 제공하는 바, 교통 수단에 대해 모니터링하여 획득된 모니터링 이미지를 획득하는 단계; 상기 모니터링 이미지에 대해 얼굴 인식을 수행하여, 얼굴 영역을 획득하는 단계; 상기 얼굴 영역의 크기 및 위치에 따라, 상기 모니터링 이미지로부터 타겟 영역을 결정하는 단계; 및, 상기 타겟 영역의 이미지 특징에 따라, 안전 벨트의 착용 상태를 인식하는 단계;를 포함한다. 본 출원의 제2 양태의 실시예는 안전 벨트의 착용 상태 인식 장치를 제공하는 바, 교통 수단에 대해 모니터링하여 획득된 모니터링 이미지를 획득하는 획득 모듈; 상기 모니터링 이미지에 대해 얼굴 인식을 수행하여, 얼굴 영역을 획득하는 얼굴 인식 모듈; 상기 얼굴 영역의 크기 및 위치에 따라, 상기 모니터링 이미지로부터 타겟 영역을 결정하는 결정 모듈; 및, 상기 타겟 영역의 이미지 특징에 따라, 안전 벨트의 착용 상태를 인식하는 상태 인식 모듈;을 포함한다. 본 출원의 제3 양태의 실시예는 전자 기기를 제공하는 바, 적어도 하나의 프로세서; 및, 상기 적어도 하나의 프로세서와 통신 가능하게 연결되는 메모리를 포함하고; 여기서, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령이 상기 적 어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 본 출원의 제1 양태의 실시예에서 제공 된 안전 벨트의 착용 상태 인식 방법을 수행하도록 한다. 본 출원의 제4 양태의 실시예는 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체를 제공하는 바, 상기 컴퓨터 명령은 상기 컴퓨터가 본 출원의 제1 양태의 실시예에서 제공된 안전 벨트의 착용 상태 인식 방법을 수행하도록 한다. 본 출원의 제5 양태의 실시예는 또한 컴퓨터 판독 가능 매체에 저장되어 있는 컴퓨터 프로그램을 제공한다. 상 기 컴퓨터 프로그램 중의 명령이 실행될 경우, 본 출원의 제1 양태의 실시예에서 제공된 안전 벨트의 착용 상태 인식 방법이 실행된다."}
{"patent_id": "10-2021-0062760", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기 출원의 일 실시예는 하기와 같은 장점 또는 유익한 효과를 갖는다. 교통 수단에 대해 모니터링하여 획득된 모니터링 이미지에 대해 얼굴 인식을 수행하여, 얼굴 영역을 획득하고, 얼굴 영역의 크기 및 위치에 따라, 모니터링 이미지로부터 타겟 영역을 결정하며, 계속하여 타겟 영역의 이미지 특징에 따라, 안전 벨트의 착용 상태를 인식한다. 이로써, 본 출원에서 타겟 영역으로 기재된 안전 벨트의 착용 영역을 추정하고, 상기 타겟 영역에 대해서만 안전 벨트의 착용 상태 인식을 수행하여, 모니터링 이미지 중 다 른 쓸모없는 정보의 간섭을 효과적으로 감소시키며, 계산량을 감소시킬 수 있어 인식 속도를 향상시키고, 차량 용 기기와 같은 컴퓨팅 기능이 상대적으로 낮은 기기에 적용되어, 상기 방법의 적용성을 향상시킬 수 있다. 본 부분에서 설명된 내용은 본 출원의 실시예의 핵심 또는 중요한 특징을 식별하기 위한 것이 아니며, 본 출원 의 범위를 한정하려는 의도도 아님을 이해해야 할 것이다. 본 출원의 다른 특징은 아래 명세서에 의해 쉽게 이 해될 것이다."}
{"patent_id": "10-2021-0062760", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래 첨부된 도면을 결부하여 본 출원의 예시적 실시예를 설명하되, 여기에는 이해를 돕기 위한 본 출원의 실시"}
{"patent_id": "10-2021-0062760", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예의 다양한 세부 사항이 포함되며, 이는 단지 예시적인 것으로 간주되어야 한다. 따라서, 본 기술분야의 통상 의 기술자는 본 출원의 범위와 사상을 벗어나지 않으면서, 여기서 설명되는 실시예에 대한 다양한 변경과 수정 이 이루어질 수 있음을 이해해야 한다. 마찬가지로, 명확성 및 간결성을 위해, 아래의 설명에서 공지된 기능과 구조에 대한 설명을 생략한다. 아래 도면을 참조하여 본 출원의 실시예의 안전 벨트의 착용 상태 인식 방법, 장치, 전자 기기 및 저장 매체를 설명한다. 도 1은 본 출원의 실시예 1에서 제공된 안전 벨트의 착용 상태 인식 방법의 흐름도이다. 본 출원의 실시예는 안전 벨트의 착용 상태 인식 장치에 구성된 상기 안전 벨트의 착용 상태 인식 방법을 예로 들어 설명하며, 상기 안전 벨트의 착용 상태 인식 장치는 임의의 전자 기기에 적용될 수 있어, 상기 전자 기기 가 안전 벨트의 착용 상태 인식 기능을 수행하도록 한다. 전자 기기는 컴퓨팅 기능을 가진 임의의 기기일 수 있는 바, 예를 들어, 개인용 컴퓨터(Personal Computer, PC 로 약칭함), 이동 단말기, 서버 등일 수 있고, 이동 단말기는 예를 들어 휴대폰, 태블릿 컴퓨터, 개인용 정보 단말기, 웨어러블 기기, 차량 기기 등 다양한 작동 시스템, 터치 스크린 및/또는 디스플레이 스크린을 가진 하 드웨어 기기일 수 있다. 도 1에 도시된 바와 같이, 상기 안전 벨트의 착용 상태 인식 방법은 하기와 같은 단계를 포함할 수 있다. 단계 101에서, 교통 수단에 대해 모니터링하여 획득된 모니터링 이미지를 획득한다. 본 출원의 실시예에서, 교통 수단은 사람이 이동하거나 이동하는데 사용되는 장치를 의미하는 바, 예를 들어 교 통 수단은 차량(자동차, 기차 등), 수상 장비(선박, 잠수함 등), 비행 장비(비행기, 우주 왕복선, 로켓 등) 등 일 수 있다. 본 출원의 실시예에서, 모니터링 이미지는 전자 기기가 실시간으로 수집한 이미지이거나, 모니터링 이미지는 전 자 기기가 미리 수집하거나 다운로드한 이미지이거나, 모니터링 이미지는 전자 기기가 온라인으로 열람하는 이 미지이거나, 모니터링 이미지는 또한 전자 기기가 외부 기기측으로부터 획득한 이미지일 수도 있으며, 본 출원 은 이에 대해 한정하지 않는다. 일 예시로서, 전자 기기는 교통 수단에 대해 모니터링하여 모니터링 이미지를 획득할 수 있는 바, 예를 들어, 전자 기기에는 카메라가 설치될 수 있어, 카메라를 통해 교통 수단에 대해 실시간으로 또는 간헐적으로 모니터 링하여 모니터링 이미지를 획득할 수 있다. 예를 들어, 전자 기기는 휴대폰, 태블릿 컴퓨터, 차량 기기 등 이동 단말기일 수 있고, 이로써 전자 기기는 차량 내 환경에 대해 이미지를 수집하여 모니터링 이미지를 획득할 수 있다. 다른 예시로서, 외부 기기를 통해 교통 수단에 대해 모니터링하여 모니터링 이미지를 획득할 수 있고, 전자 기 기는 외부 기기와 통신하여 상기 모니터링 이미지를 획득할 수 있다. 예를 들어, 교통 수단이 차량일 경우, 상 기 외부 기기는 교차로의 카메라일 수 있고, 교차로의 카메라를 통해 교통 수단에 대해 모니터링하여 모니터링 이미지를 획득하며, 전자 기기는 모니터링 센터의 기기일 수 있고, 이로써 전자 기기는 교차로의 카메라와 통신 하여 교차로의 카메라에 의해 수집된 모니터링 이미지를 획득할 수 있다. 전자 기기에 설치된 카메라의 개수는 한정되지 않으며 예를 들어 하나이거나, 복수 개일 수도 있다. 전자 기기 에 설치된 카메라의 형태는 한정되지 않으며 예를 들어 전자 기기에 내장된 카메라이거나, 전자 기기 외부에 설 치된 카메라일 수도 있고, 다시 예를 들어 전방 카메라이거나 후방 카메라일 수 있다. 카메라는 컬러 카메라, 흑백 카메라, 깊이 카메라, 망원 카메라, 광각 카메라와 같은 임의의 유형의 카메라일 수 있으며, 여기에 한정 되지 않는다. 전자 기기에 복수 개의 카메라가 설치될 경우, 복수 개의 카메라는 동일한 유형의 카메라일 수 있고, 상이한 유 형의 카메라일 수도 있으며, 본 출원은 이에 대해 한정하지 않는다. 예를 들어, 모두 컬러 카메라일 수 있고, 모두 흑백 카메라이거나, 그 중 하나의 카메라가 망원 카메라이고 다른 카메라는 광각 카메라일 수 있다. 본 출원의 실시예에서, 사용자 동작을 탐측하고, 사용자 동작에 응답하여 모니터링 이미지를 획득하거나, 또한 지속적으로 또는 간헐적으로 이미지를 수집하여 모니터링 이미지를 획득할 수 있다. 또는, 외부 기기와 지속적 으로 또는 간헐적으로 통신하여 외부 기기에 의해 수집된 모니터링 이미지를 획득할 수도 있다. 단계 102에서, 모니터링 이미지에 대해 얼굴 인식을 수행하여, 얼굴 영역을 획득한다. 본 출원의 실시예에서, 얼굴 인식 알고리즘을 기반으로 모니터링 이미지에 대해 얼굴 인식을 수행하여 얼굴 영 역을 획득하거나, 타겟 인식 알고리즘을 기반으로 모니터링 이미지에 대해 얼굴 인식을 수행하여 얼굴 영역을 획득할 수 있다. 예를 들어, 싱글숏 멀티박스 검출(Single Shot MultiBox Detector, SSD로 약칭함), 욜로(You Only Look Once, YOLO로 약칭함), Faster-RCNN 등 타겟 검출 알고리즘을 기반으로 모니터링 이미지에 대해 얼굴 인식을 수행하여 얼굴 영역을 획득할 수 있다. 일 예시로서, 인식 결과의 정확성을 향상시키기 위해, 딥 러닝 기술을 기반으로 모니터링 이미지에 대해 얼굴 인식을 수행하여 얼굴 영역을 획득할 수 있다. 예를 들어, 얼굴 영역이 라벨링된 대량의 샘플 이미지를 사용하 여, 얼굴 검출 모델에 대해 트레이닝하여 트레이닝된 얼굴 검출 모델이 얼굴 영역과 이미지 사이의 대응 관계를 학습하여 얻을 수 있도록 한다. 이로써, 본 출원에서, 모니터링 이미지를 획득한 후, 상기 모니터링 이미지를 입력으로 하고, 얼굴 검출 모델을 사용하여, 상기 모니터링 이미지에 대해 얼굴 인식을 수행함으로써 얼굴 영역 을 출력하여 얻을 수 있다. 이해해야 할 것은, 모니터링 이미지에는 복수의 얼굴이 포함될 수 있으며, 예를 들어, 운전석 영역 및 조수석 영역에 동시에 얼굴이 존재하면, 이 경우, 검출 결과의 정확성을 향상시키기 위해, 모니터링 이미지 중 각 얼굴 에 대해 검출하여, 각 얼굴에 대응되는 얼굴 영역을 획득할 수 있다. 단계 103에서, 얼굴 영역의 크기 및 위치에 따라, 모니터링 이미지로부터 타겟 영역을 결정한다. 본 출원의 실시예에서, 타겟 영역은 안전 벨트의 착용 위치를 지시하는데 사용된다. 선행 지식에 따르면, 운전자 또는 승객이 안전 벨트를 착용하는 행동은 일반적으로 얼굴 하부 영역에서 나타나 는 것을 알 수 있으며, 즉 안전 벨트의 착용 위치는 얼굴 하부에 있으므로, 본 출원에서, 얼굴 영역을 인식한 후, 얼굴 영역의 하부 영역에 따라 안전 벨트의 인식 영역을 결정하여 본 출원에서는 타겟 영역으로 표기한다. 하부는 얼굴 영역의 하부 위치를 의미하며, 얼굴 영역의 위치와 상대적인 위치이다.이해해야 할 것은, 모니터링 이미지가 하나의 얼굴 영역만 포함할 경우 타겟 영역은 하나이고, 모니터링 이미지 가 복수의 얼굴 영역을 포함할 경우 타겟 영역도 복수 개이며, 각 얼굴 영역의 크기 및 위치에 따라 대응되는 타겟 영역을 각각 결정할 수 있다. 단계 104에서, 타겟 영역의 이미지 특징에 따라, 안전 벨트의 착용 상태를 인식한다. 본 출원의 실시예에서, 안전 벨트의 착용 상태는 이미 착용한 상태 및 미착용 상태를 포함한다. 본 출원의 실시예에서, 이미지 특징은 색상 특징, 텍스처 특징, 형상 특징, 공간 관계 특징 중 적어도 하나를 포함할 수 있다. 본 출원의 실시예에서, 각각의 타겟 영역을 결정한 후, 특징 추출 알고리즘을 기반으로, 각 타겟 영역에 대해 특징 추출을 수행하여 각 타겟 영역의 이미지 특징을 획득할 수 있다. 예를 들어, 컬러 히스토그램 방법을 사용 하여 각 타겟 영역의 색상 특징을 추출하고, 통계 기반 방법을 사용하여 각 타겟 영역의 텍스처 특징을 추출하 며, 기하학적 파라미터 방법, 형상 불변법을 사용하여 각 타겟 영역의 형상 특징을 추출하여, 타겟 영역을 다수 의 규칙 서브 블록으로 균일하게 분할한 다음, 각각의 이미지 서브 블록에서 특징을 추출하고 인덱스를 구축하 여 각 타겟 영역에 대응되는 공간 관계 특징을 획득할 수 있다. 특징 추출은 컴퓨터 비전 및 이미지 처리의 개념이다. 이는 컴퓨터를 사용하여 이미지 정보를 추출하여 각각의 이미지의 포인트가 하나의 이미지 특징에 속하는지 여부를 결정하는 것을 의미한다. 특징 추출의 결과는 이미지 의 포인트를 상이한 서브 집합으로 나누는 것이고, 이러한 서브 집합은 종종 고립된 포인트, 연속적인 곡선 또 는 연속적인 영역에 속한다. 본 출원의 실시예에서, 각 타겟 영역의 이미지 특징을 결정한 후, 각 타겟 영역의 이미지 특징에 따라 안전 벨 트의 착용 상태를 인식할 수 있다. 가능한 구현 방식으로서, 인식 결과의 정확성을 향상시키기 위해, 딥 러닝 기술을 기반으로, 각 타겟 영역에 대 해 인식하여 각 타겟 영역 중 안전 벨트의 착용 상태를 결정할 수 있다. 예를 들어, 분류 모델을 통해, 각 타겟 영역에 대해 인식하여 각 타겟 영역 중 안전 벨트의 착용 상태를 결정할 수 있다. 분류 모델이 트레이닝 시, 트레이닝 샘플 사진 중 안전 벨트의 착용 상태가 이미 착용한 상태이면, 상기 트레이 닝 샘플 사진의 태그는 1이고, 트레이닝 샘플 사진 중 안전 벨트의 착용 상태가 미착용 상태이면, 상기 트레이 닝 샘플 사진의 태그는 0이며, 트레이닝된 분류 모델을 이용하여 타겟 영역의 이미지 특징에 대해 인식하면 출 력된 것은 0 내지 1의 분류 확률이고, 여기서 분류 확률이 1에 근접하면 모니터링 이미지 중 안전 벨트의 착용 상태가 이미 착용한 상태인 확률이 크다. 따라서, 0.5와 같은 하나의 확률 임계값을 설정하고, 분류 모델이 출 력한 분류 확률이 상기 확률 임계값보다 크거나 같을 경우 안전 벨트의 착용 상태가 이미 착용한 상태인 것으로 결정하고, 분류 모델이 출력한 분류 확률이 확률 임계값보다 작을 경우 안전 벨트의 착용 상태가 미착용 상태인 것으로 결정할 수 있다. 일 예시로서, 각각의 타겟 영역에 대해, 콘볼루션 신경망을 통해 상기 타겟 영역에 대해 특징을 추출하여 상기 타겟 영역의 이미지 특징을 획득하고, 상기 타겟 영역의 이미지 특징을 풀링크 레이어에 입력하여 풀링크 레이 어의 출력에 따라 안전 벨트의 착용 상태를 결정할수 있다. 예를 들어, 풀링크 레이어에 의해 출력된 분류 확률 이 0.5보다 낮으면 근사하게 0인 것으로 간주하여 안전 벨트의 착용 상태가 미착용 상태인 것으로 결정할 수 있 고, 풀링크 레이어에 의해 출력된 분류 확률이 0.5보다 높으면, 근사하게 1인 것으로 간주하여 안전 벨트의 착 용 상태가 이미 착용한 상태인 것으로 결정할 수 있다. 콘볼루션 신경망은 콘볼루션 레이어 및 풀링 레이어를 포함한다. 일 응용 상황으로서, 전자 기기를 통해 교통 수단 내 환경에 대해 이미지를 수집하여 모니터링 이미지를 획득할 수 있으며, 예를 들어 전자 기기는 휴대폰, 태블릿 컴퓨터, 차량 기기 등 이동 단말기일 수 있고, 상기 전자 기 기는 차량 내에 위치할 수 있으며 수집된 모니터링 이미지는 복수의 얼굴을 포함할 수 있고, 예를 들어 운전석 영역, 조수석 영역, 뒤좌석 승객 영역에 동시에 얼굴이 존재하면 이 경우 모니터링 이미지에 대해 얼굴 인식을 수행하여 복수의 얼굴을 획득할 수 있으며, 각 얼굴 영역 하부의 안전 벨트의 착용 영역, 즉 타겟 영역에 대해 안전 벨트의 착용 상태를 각각 인식할 수 있다. 또한, 안전 벨트의 착용 상태가 미착용 상태일 경우, 또한 운전자 또는 승객에게 알림을 제공할 수 있다. 예를 들어, 스피커를 통한 음성 방송으로 운전자 또는 승객에게 알림 메시지를 방송하거나, 지시등을 통해 안전 벨트 의 미착용 상태를 가시화로 디스플레이하거나, 디스플레이 스크린을 통해 안전 벨트 미착용 알림 메시지를 디스플레이할 수 있거나, 또한 운전자의 모바일 기기에 알림 메시지를 송신할 수 있거나, 소리, 진동 등 방식을 통 해 운전자 또는 승객에게 안전 벨트 미착용 상태를 알릴 수도 있으며, 본 출원은 이에 대해 한정하지 않는다. 다른 응용 상황으로서, 교통 수단이 차량인 것을 예로 들면, 교차로의 카메라를 통해 교차로의 차량에 대해 모 니터링하여 모니터링 이미지를 획득할 수 있고, 전자 기기는 교차로의 카메라와 통신하여 모니터링 이미지를 획 득할 수 있다. 이해해야 할 것은, 촬영 시각 및 촬영 거리의 제한으로 인해, 카메라에 의해 수집된 모니터링 이 미지에는 운전석 영역 및 조수석 영역만 포함될 수 있고, 뒤좌석 승객 영역은 나타날 수 없으므로, 따라서 본 출원에서, 단지 운전석 영역 및 조수석 영역의 얼굴에 대해서만 인식하고, 각 얼굴 영역 하부의 안전 벨트의 착 용 영역, 즉 타겟 영역에 대해 안전 벨트의 착용 상태를 인식할 수 있다. 또한, 안전 벨트의 착용 상태가 미착용 상태일 경우, 또한, 차량의 번호판에 대해 계속하여 인식할 수 있으며, 예를 들어, 타겟 인식 알고리즘을 기반으로, 모니터링 이미지로부터 차량 번호판 영역을 인식하고, 딥 러닝 기 술을 기반으로, 차량 번호판 영역에 대해 텍스트 인식을 수행하여 차량 번호판 정보를 획득할 수 있다. 차량 번 호판 정보를 획득한 후, 관련자는 상기 차량 번호판 정보에 대해 표기하여, 상기 차량에 대해 상응하게 처벌할 수 있으며, 이로써 운전자에게 알림 및 경고를 하여 교통 법규 준수에 대한 운전자의 의식을 높일 수 있다. 설명해야 할 것은, 본 출원의 상기에서는 단지 교통 수단이 차량인 것을 예로 들었으며, 실제 응용 시, 교통 수 단은 차량에 한정되지 않으며, 예를 들어 비행기, 우주 왕복선 등일 수 있고, 마찬가지로 상기 방식을 기반으로, 수집된 모니터링 이미지 중 안전 벨트의 착용 상태에 대해 인식할 수 있으며, 본 출원은 이에 대해 한정하지 않는다. 설명해야 할 것은, 비록 모델을 통해 모니터링 이미지에 대해 직접 검출하여 안전 벨트의 착용 상태를 결정할 수 있지만, 전체 이미지에 대해 인식하는 방식은 입력 이미지의 크기를 더 크게 하여 알고리즘의 연산량을 증가 시키므로 컴퓨팅 기능이 상대적으로 낮은 기기에 적용되지 않는다. 본 출원에서, 교통 수단에 대해 모니터링하여 획득된 모니터링 이미지를 획득한 후, 운전자 또는 승객의 안전 벨트 착용 행동이 일반적으로 얼굴 하부 영역에 나타나는 사전 지식을 이용하여, 안전 벨트의 착용 영역을 추정 하여, 본 출원에서는 타겟 영역으로 표기하고, 상기 타겟 영역에 대해서만 안전 벨트의 착용 상태 인식을 수행 하여, 모니터링 이미지 중 다른 쓸모없는 정보의 간섭을 효과적으로 감소시키며, 동시에 모델 입력 이미지의 크 기를 감소시켜, 계산량을 감소시키고 인식 속도를 향상시키는 기초상에서, 또한 인식 결과의 정확도를 향상시킬 수 있어, 차량 기기와 같은 컴퓨팅 기능이 상대적으로 낮은 기기에 적용되어 상기 방법의 적용성을 향상시킬 수 있다. 본 출원의 실시예의 안전 벨트의 착용 상태 인식 방법에 있어서, 교통 수단에 대해 모니터링하여 획득된 모니터 링 이미지에 대해 얼굴 인식을 수행하여, 얼굴 영역을 획득하고, 얼굴 영역의 크기 및 위치에 따라, 모니터링 이미지로부터 타겟 영역을 결정하며, 계속하여 타겟 영역의 이미지 특징에 따라, 안전 벨트의 착용 상태를 인식 한다. 이로써, 본 출원에서 타겟 영역으로 기재된 안전 벨트의 착용 영역을 추정하고, 상기 타겟 영역에 대해서 만 안전 벨트의 착용 상태 인식을 수행하여, 모니터링 이미지 중 다른 쓸모없는 정보의 간섭을 효과적으로 감소 시키며, 계산량을 감소시킬 수 있어 인식 속도를 향상시키고, 차량용 기기와 같은 컴퓨팅 기능이 상대적으로 낮 은 기기에 적용되어, 상기 방법의 적용성을 향상시킬 수 있다. 가능한 구현 방식으로서, 계산량을 더 감소시키기 위해, 본 출원에서, 얼굴 영역 하부와 얼굴 영역 사이의 거리 가 얼굴 영역의 높이를 충족하는 영역을 타겟 영역으로 할 수 있다. 아래에 실시예2를 결합하여, 상기 과정에 대해 상세하게 설명한다. 도 2는 본 출원의 실시예 2에서 제공된 안전 벨트의 착용 상태 인식 방법의 흐름도이다. 도 2에 도시된 바와 같이, 상기 안전 벨트의 착용 상태 인식 방법은 하기와 같은 단계를 포함할 수 있다. 단계 201에서, 교통 수단에 대해 모니터링하여 획득된 모니터링 이미지를 획득한다. 단계 201의 수행 과정은 상기 실시예에서 단계 101의 수행 과정을 참조할 수 있으며, 여기서 더이상 서술하지 않는다. 단계 202에서, 모니터링 이미지에 대해 얼굴 인식을 수행하여, 얼굴 영역을 획득한다. 가능한 구현 방식으로서, 인식 결과의 정확성을 향상시키기 위해, 딥 러닝 기술을 기반으로, 모니터링 이미지에 대해 얼굴 인식을 수행하여, 얼굴 영역을 획득할 수 있다.예를 들어, 얼굴 검출 모델을 통해, 모니터링 이미지에 대해 얼굴 영역을 검출하여, 얼굴 영역을 획득하되, 여 기서 얼굴 검출 모델 중 6계층의 콘볼루션 네트워크를 통해 얼굴 기초 특징을 추출하며, 각 계층의 콘볼루션 네 트워크는 한 번의 이미지 다운 샘플링을 구현하고, 마지막의 3계층의 콘볼루션 신경망을 기반으로 고정된 수의 다양한 크기의 얼굴 앵커 프레임을 미리 설정하여 얼굴 검출 프레임 회귀를 수행하여, 최종 출력에 의해 얼굴 영역의 인식 결과를 획득하며, 즉 출력된 것은 얼굴 영역에 대응되는 4개의 정점 좌표이다. 단계 203에서, 얼굴 영역의 높이에 따라, 간격 거리를 결정한다. 본 출원의 실시예에서, 얼굴 영역을 결정한 후, 얼굴 영역의 4개의 정점 좌표에 따라, 얼굴 영역의 높이를 결정 할 수 있으며, 따라서 얼굴 영역의 높이를 간격 거리로 사용할 수 있다. 구체적으로, 얼굴 영역의 4개의 정점 좌표는, 왼쪽 상단에 대응되는 픽셀점 좌표, 왼쪽 하단에 대응되는 픽셀점 좌표, 오른쪽 상단에 대응되는 픽셀 점 좌표 및 오른쪽 하단에 대응되는 픽셀점 좌표를 포함하고, 왼쪽 상단에 대응되는 픽셀점 좌표를 (x1, y1), 오 른쪽 상단에 대응되는 픽셀점 좌표를 (x2, y2), 오른쪽 하단에 대응되는 픽셀점 좌표를 (x3, y3), 왼쪽 하단에 대응되는 픽셀점 좌표를 (x4, y4)로 표기하면, 얼굴 영역의 폭은 w=x2-x1이고, 높이는 h=y4-y1이므로, 간격 거리 는 h이다. 단계 204에서, 얼굴 영역의 위치에 따라, 얼굴 영역 하부에 위치하고 얼굴 영역과 간격 거리를 충족하는 영역을 타겟 영역으로 한다. 사전 지식에 따르면, 안전 벨트의 착용 위치는 얼굴 하부에 있으므로, 따라서 본 출원에서, 얼굴 영역 하부에 위치하고 얼굴 영역과 간격 거리 h를 충족하는 영역을 타겟 영역으로 할 수 있다는 것을 알 수 있다. 이로써, 이미지 중 쓸모없는 정보의 간섭을 효과적으로 감소시켜, 이미지의 처리 속도를 향상시킬 수 있다. 하부는 얼굴 영역의 하부에 대한 상대적인 위치를 의미하며, 이와 얼굴 영역의 위치는 상대적 위치이다. 단계 205에서, 타겟 영역의 이미지 특징에 따라, 안전 벨트의 착용 상태를 인식한다. 단계 205의 수행 과정은 상기 실시예에서 단계 104의 수행 과정을 참조할 수 있으며, 여기서 더이상 서술하지 않는다. 가능한 구현 방식으로서, 인식 효율을 더 향상시키기 위해, 본 출원에서, 얼굴 영역 하부에 위치하고 얼굴 영역 과의 거리가 h인 전부 영역을 타겟 영역으로 하는 것이 아니라, 얼굴 영역 하부에 위치하고 얼굴 영역과의 거리 가 h이고 면적이 얼굴 영역 설정 배수인 영역을 타겟 영역으로 하며, 이로써, 프레임이 배경을 차지하는 것을 방지하는 전제 하에서 안전 벨트의 인식 영역을 최대한 극대화할 수 있다. 아래에 실시예 3을 결합하여, 상기 과정에 대해 상세하게 설명한다. 도 3은 본 출원의 실시예 3에서 제공된 안전 벨트의 착용 상태 인식 방법의 흐름도이다. 도 3에 도시된 바와 같이, 상기 안전 벨트의 착용 상태 인식 방법은 하기와 같은 단계를 포함할 수 있다. 단계 301에서, 교통 수단에 대해 모니터링하여 획득된 모니터링 이미지를 획득한다. 단계 302에서, 모니터링 이미지에 대해 얼굴 인식을 수행하여, 얼굴 영역을 획득한다. 단계 303에서, 얼굴 영역의 높이에 따라, 간격 거리를 결정한다. 단계 301 내지 단계 303의 수행 과정은 상기 실시예의 수행 과정을 참조할 수 있으며, 여기서 더이상 서술하지 않는다. 단계 304에서, 얼굴 영역의 면적에 따라, 검출 프레임을 생성하되, 검출 프레임의 면적은 얼굴 영역의 면적의 설정 배수이다. 본 출원의 실시예에서, 설정 배수는 미리 설정된 것이다. 본 출원의 실시예에서, 검출 프레임에 위치한 모니터링 이미지는 안전 벨트의 착용 위치를 지시하는데 사용된다. 이해해야 할 것은, 안전 벨트의 착용 상태를 정확하게 인식하기 위해, 검출 프레임의 면적을 너무 작게 설정하 지 말아야 하며, 동시에 프레임이 배경 영역을 차지하는 것을 방지하기 위해, 검출 프레임의 면적도 너무 크게 설정하지 말아야 한다. 따라서, 처리 효율을 향상시키고 동시에 인식 결과의 정확성을 향상시키기 위해, 검출 프레임의 면적은 얼굴 영역의 면적의 설정 배수일 수 있되, 여기서 설정 배수는 2보다 크거나 같은 정수 또는부동 소수점일 수 있고, 예를 들어 검출 프레임의 면적은 얼굴 영역의 면적의 2배일 수 있으며, 이로써 프레임 이 배경을 차지하는 것을 방지하는 전제 하에서 안전 벨트의 영역을 최대한 극대화할 수 있다. 단계 305에서, 얼굴 영역과 간격 거리를 가지도록 검출 프레임을 얼굴 영역의 하부에 설치한다. 사전 지식에 따르면, 안전 벨트의 착용 위치는 얼굴 하부에 위치하므로, 따라서 본 출원에서 얼굴 영역과 간격 거리를 가지도록 검출 프레임을 얼굴 영역의 하부에 설치할 수 있다는 것을 알 수 있다. 다시 말해서, 얼굴 영역을 결정한 후, 얼굴 영역에 대응되는 4개의 정점 좌표를 결정할 수 있으며, 예를 들어 왼쪽 상단에 대응되는 픽셀점 좌표 (x1, y1), 오른쪽 상단에 대응되는 픽셀점 좌표(x2, y2), 오른쪽 하단에 대응 되는 픽셀점 좌표(x3, y3), 왼쪽 하단에 대응되는 픽셀점 좌표(x4, y4)를 결정할 수 있고, 얼굴 영역의 폭은 w=x2-x1이며, h=y4-y1이므로, 간격 거리는 h이다. 이 경우, 얼굴 영역에 대응되는 얼굴 검출 프레임을 아래로 h 개의 단위로 평행 이동하여 안전 벨트에 대응되는 검출 프레임에 대응되는 4개의 정점 좌표, 즉 왼쪽 상단에 대 응되는 픽셀점 좌표 (x1, y1-h), 오른쪽 상단에 대응되는 픽셀점 좌표(x2, y2-h), 오른쪽 하단에 대응되는 픽셀 점 좌표(x3, y3-h), 왼쪽 하단에 대응되는 픽셀점 좌표(x4, y4-h)를 획득할 수 있다. 또한, 프레임이 배경을 차 지하는 것을 방지하는 전제 하에서, 안전 벨트 인식 영역을 최대한 극대화하는 것을 구현하기 위해, 본 출원에 서, 또한 안전 벨트에 대응되는 검출 프레임을 설정 배수로 확대할 수 있으며, 예를 들어 설정 배수는 2, 2.5 등일 수 있다. 단계 306에서, 모니터링 이미지 중 검출 프레임 내에 위치한 부분을 타겟 영역으로 한다. 본 출원의 실시예에서, 검출 프레임의 위치를 설정한 후, 모니터링 이미지 중 검출 프레임 내에 위치한 부분을 타겟 영역으로 할 수 있다. 이로써, 이미지 중 쓸모없는 정보의 간섭을 효과적으로 감소시켜, 이미지의 처리 속 도를 향상시킬 수 있다. 단계 307에서, 타겟 영역의 이미지 특징에 따라, 안전 벨트의 착용 상태를 인식한다. 단계 307의 수행 과정은 상기 실시예에서 단계 104의 수행 과정을 참조할 수 있으며, 여기서 더이상 서술하지 않는다. 가능한 구현 방식으로서, 모니터링 이미지로부터 타겟 영역을 결정한 후, 또한 타겟 영역에 대해 해상도 변환을 수행하여, 변환된 타겟 영역이 타겟 해상도에 부합되도록 할 수 있다. 이로써, 타겟 영역을 통합된 크기로 변환 시켜 후속 인식을 용이하게 할 수 있다. 타겟 해상도는 미리 설정된 것이다. 예를 들어, 분류 모델을 이용하여, 타겟 영역에 대해 안전 벨트의 착용 상 태 인식을 수행할 경우, 상기 타겟 해상도는 분류 모델의 입력 이미지 크기일 수 있는 바, 예를 들어 144*144이 다. 이로써, 타겟 영역을 통합된 크기로 변환시켜 후속의 분류 모델의 입력으로 하는데 편이하도록 한다. 설명해야 할 것은, 타겟 영역 중 각 픽셀점의 값은 0 내지 255 사이에 있을 수 있으며, 타겟 영역 중 각 픽셀점 밝기로 인한 인식에 대한 간섭을 방지하기 위해, 본 출원에서, 타겟 해상도의 타겟 영역 중 각 픽셀점의 값에 대해 정규화 처리를 수행하여, 각 픽셀점의 값이 타겟 값 구간 내에 있도록 할 수 있다. 예를 들어, 정규화 공식은 (x-128)/256일 수 있는데, 여기서 x는 픽셀점의 값을 나타내고, x는 0 내지 255 사이 에 있으며, 타겟 해상도의 타겟 영역 중 각 픽셀점의 값에 대해 정규화 처리를 수행한 후, 각 픽셀점의 값은 [- 0.5, 0.5] 사이에 있다. 가능한 구현 방식으로서, 인식 결과의 정확성을 향상시키기 위해, 딥 러닝 기술을 기반으로 타겟 영역의 이미지 특징에 대해 분류하여, 안전 벨트의 착용 상태를 결정할 수 있다. 아래에 실시예 4를 결합하여, 상기 과정에 대 해 상세하게 설명한다. 도 4는 본 출원의 실시예 4에서 제공된 안전 벨트의 착용 상태 인식 방법의 흐름도이다. 도 4에 도시된 바와 같이, 상기 안전 벨트의 착용 상태 인식 방법은 하기와 같은 단계를 포함할 수 있다. 단계 401에서, 교통 수단에 대해 모니터링하여 획득된 모니터링 이미지를 획득한다. 단계 402에서, 모니터링 이미지에 대해 얼굴 인식을 수행하여, 얼굴 영역을 획득한다. 단계 403에서, 얼굴 영역의 크기 및 위치에 따라, 모니터링 이미지로부터 타겟 영역을 결정한다. 단계 401 내지 단계 403의 수행 과정은 상기 실시예의 수행 과정을 참조할 수 있으며, 여기서 더이상 서술하지 않는다. 단계 404에서, 타겟 영역의 이미지 특징에 따라 분류한다. 이미지 분류 원리는 다음과 같다. 즉 이미지 중 동일한 유형의 장면은 동일한 조건에서 동일하거나 유사한 이미 지 특징, 예를 들어 스펙트럼 정보 특징 및 공간 정보 특징을 가져야 하며, 이로써 동일한 유형의 장면의 특정 된 내적 유사성을 나타낼 수 있고, 즉 동일한 유형의 장면 픽셀의 특징 벡터는 동일한 특징의 공간 영역과 클러 스터링되고, 상이한 장면은 스펙트럼 정보 특징 및 공간 정보 특징이 상이하므로 상이한 특징의 공간 영역에 클 러스터링된다. 따라서, 본 출원에서, 타겟 영역의 이미지 특징에 대해 분류하여, 안전 벨트의 착용 상태를 결정할 수 있다. 예 를 들어, 분류 모델을 사용하여 타겟 영역에 대해 분류할 수 있다. 단계 405에서, 분류하여 획득된 카테고리에 따라, 안전 벨트의 착용 상태를 결정한다. 본 출원의 실시예에서, 분류하여 획득된 카테고리에 따라, 안전 벨트의 착용 상태를 결정할 수 있다. 예를 들어, 분류 모델은 콘볼루션 네트워크에서 특징을 추출한 후 풀링크 레이어 및 출력 레이어를 연결하여 분 류 확률을 출력할 수 있으며, 분류 확률이 0.5 이하이면 근사하게 0인 것으로 간주하여 안전 벨트의 착용 상태 가 미착용 상태인 것으로 결정할 수 있고, 분류 확률이 0.5 및 그 이상이면, 근사하게 1인 것으로 간주하여 안 전 벨트의 착용 상태가 이미 착용한 상태인 것으로 결정할 수 있다. 일 예시로서, 도 5에 도시된 콘볼루션 신경망을 기반으로, 타겟 영역에 대해 특징을 추출하고, 풀링크 레이어를 통해 출력하여 안전 벨트의 착용 상태를 획득할 수 있다. 콘볼루션 신경망은 콘볼루션 레이어 및 풀링 레이어를 포함한다. 콘볼루션 신경망은 8 계층의 콘볼루션 레이어 및 5 계층의 풀링 레이어(도 5에 도시되지 않음)를 포함하고, 콘 볼루션 신경망의 입력은 레드·그린·블루(Red Green Blue, RGB로 약칭함) 3색 채널의 이미지일 수 있으며, 해 상도는 144*144이고, 여기서 상이한 콘볼루션 레이어는 상이한 콘볼루션 커널을 통해 이미지 특징에 대해 콘볼 루션을 수행하여, 그 중으로부터 상이한 크기 또는 상이한 입도의 특징을 추출할 수 있으며, 최종 출력된 특징 벡터의 크기는 1*1*5(텐서 공간 크기)이다. 일 예시로서, 모니터링 이미지를 획득한 후, 얼굴 검출 모델을 기반으로, 모니터링 이미지에 대해 얼굴 인식을 수행하여, 각 얼굴 영역에 대응되는 얼굴 검출 프레임을 획득할 수 있으며, 각각의 얼굴 영역에 대해, 얼굴 검 출 프레임을 표기한 4개의 정점 좌표가, 왼쪽 상단에 대응되는 픽셀점 좌표 (x1, y1), 오른쪽 상단에 대응되는 픽셀점 좌표(x2, y2), 오른쪽 하단에 대응되는 픽셀점 좌표(x3, y3), 왼쪽 하단에 대응되는 픽셀점 좌표(x4, y4) 이면, 얼굴 검출 프레임의 폭은 w=x2-x1이고, 높이는 h=y4-y1이다. 사전 지식에 따르면, 안전 벨트 착용 위치는 얼굴 하부에 있고, 얼굴 검출 프레임을 아래로 h개의 단위로 평행 이동하여 안전 벨트 검출 프레임의 4개의 정점 좌표, 즉 왼쪽 상단에 대응되는 픽셀점 좌표 (x1, y1-h), 오른쪽 상단에 대응되는 픽셀점 좌표(x2, y2-h), 오른쪽 하단에 대응되는 픽셀점 좌표(x3, y3-h), 왼쪽 하단에 대응되는 픽셀점 좌표(x4, y4-h)를 획득할 수 있다는 것을 알 수 있다. 프레임이 배경을 차지하는 것을 방지하는 전제 하에서, 안전 벨트의 인식 영역을 최대한 극대화하는 것을 구현 하기 위해, 본 출원에서, 또한 안전 벨트에 대응되는 검출 프레임을 2배 확대하여 잘라낼 수 있다. 잘라낸 이미 지의 크기를 해상도가 144*144인 이미지로 변환시킨다. 이어서, 타겟 영역 중 각 픽셀점 밝기로 인한 인식에 대한 간섭을 방지하기 위해, 본 출원에서, 변환된 이미지 를 정규화 처리하여, 각각의 픽셀점의 픽셀값을 [-0.5,0.5] 사이에 있도록 할 수 있다. 마지막에, 콘볼루션 신경망을 통해, 처리된 이미지에 대해 특징을 추출하고, 풀링크 레이어를 통해 안전 벨트의 착용 상태를 출력한다. 본 출원의 실시예의 안전 벨트의 착용 상태 인식 방법에 있어서, 운전자 또는 승객의 안전 벨트 착용 행동이 얼 굴 하부 영역에 나타나는 사전 지식을 이용하여, 얼굴 검출을 기반으로 안전 벨트의 착용 영역을 추정하고, 다 시 분류 방법을 통해 운전자 또는 승객이 안전 벨트를 착용하였는지 여부를 인식하여, 이미지 중 다른 쓸모없는정보의 간섭을 효과적으로 감소시키고, 동시에 모델 입력 이미지 크기를 감소시켜, 인식 결과의 정확도를 향상 시키는 동시에 계산량을 크게 감소시켜, 차량 기기와 같은 컴퓨팅 기능이 상대적으로 낮은 기기에 적용되어 상 기 방법의 적용성을 향상시킬 수 있다. 상기 실시예를 구현하기 위해, 본 출원은 안전 벨트의 착용 상태 인식 장치를 더 제공한다. 도 6은 본 출원의 실시예 5에서 제공된 안전 벨트의 착용 상태 인식 장치의 구조 개략도이다. 도 6에 도시된 바와 같이, 상기 안전 벨트의 착용 상태 인식 장치는 획득 모듈, 얼굴 인식 모듈 , 결정 모듈 및 상태 인식 모듈을 포함한다. 획득 모듈은 교통 수단에 대해 모니터링하여 획득된 모니터링 이미지를 획득한다. 얼굴 인식 모듈은 모니터링 이미지에 대해 얼굴 인식을 수행하여, 얼굴 영역을 획득한다. 결정 모듈은 얼굴 영역의 크기 및 위치에 따라, 모니터링 이미지로부터 타겟 영역을 결정한다. 상태 인식 모듈은 타겟 영역의 이미지 특징에 따라, 안전 벨트의 착용 상태를 인식한다. 또한, 본 출원의 실시예의 가능한 구현 방식에서, 도 7을 참조하면, 도 6에 도시된 실시예를 기반으로, 상기 안 전 벨트의 착용 상태 인식 장치는 결정 모듈을 더 포함할 수 있다. 결정 모듈은, 얼굴 영역의 높이에 따라, 간격 거리를 결정하는 결정 유닛; 및, 얼굴 영역의 위치에 따라, 얼굴 영역 하부에 위치하고 얼굴 영역과 간격 거리를 충족하는 영역을 타겟 영역으로 하는 처리 유닛;을 포함한다. 가능한 구현 방식으로서, 처리 유닛은 구체적으로, 얼굴 영역의 면적에 따라, 검출 프레임을 생성하되, 검출 프 레임의 면적은 얼굴 영역의 면적의 설정 배수이고; 얼굴 영역과 간격 거리를 가지도록 검출 프레임을 얼굴 영역 의 하부에 설치하며; 모니터링 이미지 중 검출 프레임 내에 위치한 부분을 타겟 영역으로 한다. 변환 모듈은, 타겟 영역에 대해 해상도 변환을 수행하여, 변환된 타겟 영역이 타겟 해상도에 부합되도록 한다. 처리 모듈은, 타겟 해상도의 타겟 영역 중 각 픽셀점의 값에 대해 정규화 처리를 수행하여, 각 픽셀점의 값이 타겟 값 구간 내에 있도록 한다. 가능한 구현 방식으로서, 상태 인식 모듈은 구체적으로, 타겟 영역의 이미지 특징에 따라, 분류하고; 분류 하여 획득된 카테고리에 따라, 안전 벨트의 착용 상태를 결정한다. 설명해야 할 것은, 전술한 도 1 내지 도 4의 실시예의 안전 벨트의 착용 상태 인식 방법에 대한 해석 설명은 상 기 실시예의 안전 벨트의 착용 상태 인식 장치에도 적용되며, 여기서 더이상 서술하지 않는다. 본 출원의 실시예의 안전 벨트의 착용 상태 인식 장치에 있어서, 교통 수단에 대해 모니터링하여 획득된 모니터 링 이미지에 대해 얼굴 인식을 수행하여, 얼굴 영역을 획득하고, 얼굴 영역의 크기 및 위치에 따라, 모니터링 이미지로부터 타겟 영역을 결정하며, 계속하여 타겟 영역의 이미지 특징에 따라, 안전 벨트의 착용 상태를 인식 한다. 이로써, 본 출원에서 타겟 영역으로 기재된 안전 벨트의 착용 영역을 추정하고, 상기 타겟 영역에 대해서 만 안전 벨트의 착용 상태 인식을 수행하여, 모니터링 이미지 중 다른 쓸모없는 정보의 간섭을 효과적으로 감소 시키며, 계산량을 감소시킬 수 있어 인식 속도를 향상시키고, 차량용 기기와 같은 컴퓨팅 기능이 상대적으로 낮 은 기기에 적용되어, 상기 방법의 적용성을 향상시킬 수 있다. 본 출원의 실시예에 따르면, 본 출원은 전자 기기 및 판독 가능 저장 매체를 더 제공한다. 본 출원의 실시예에 따르면, 컴퓨터 판독 가능 매체에 저장되어 있는 컴퓨터 프로그램을 더 제공한다. 당해 컴퓨터 프로그램 중의 명령이 실행될 경우, 상기 안전 벨트의 착용 상태 인식 방법이 실행된다. 도 8에 도시된 바와 같이, 본 출원의 실시예에 따른 안전 벨트의 착용 상태 인식 방법의 전자 기기의 블록도이 다. 전자 기기는 랩톱 컴퓨터, 데스크톱 컴퓨터, 운영 플랫폼, 개인 정보 단말기, 서버, 블레이드 서버, 대형 컴퓨터, 및 다른 적합한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 의미한다. 전자 기기는 개인 디지털 처 리, 셀룰러폰, 스마트폰, 웨어러블 기기 및 다른 유사한 컴퓨팅 장치와 같은 다양한 형태의 이동 장치를 의미할 수도 있다. 본문에서 나타낸 부재, 이들의 연결과 관계, 및 이들의 기능은 단지 예시적인 것으로, 본문에서 설명 및/또는 요구된 본 출원의 구현을 한정하지 않는다. 도 8에 도시된 바와 같이, 상기 전자 기기는, 하나 또는 다수의 프로세서, 메모리, 및 고속 인터페이 스 및 저속 인터페이스를 포함하는 각 부재를 연결하기 위한 인터페이스를 포함한다. 각각의 부재는 상이한 버 스를 사용하여 상호 연결되고, 또한 공통 마더보드에 설치되거나 수요에 따라 다른 방식으로 설치될 수 있다. 프로세서는 전자 기기 내에서 실행되는 명령을 처리할 수 있고, 상기 명령은, 외부 입력/출력 장치(예를 들어, 인터페이스에 결합된 디스플레이 기기)에 GUI의 그래픽 정보를 디스플레이하기 위해 메모리 내 또는 메모리에 저장되는 명령을 포함한다. 다른 실시형태에서, 필요에 따라 다수의 프로세서 및/또는 다수의 버스를 다수의 메 모리와 함께 사용할 수 있다. 마찬가지로, 다수의 전자 기기를 연결할 수 있고, 각 기기는 일부 필요한 동작(예 를 들어, 서버 어레이, 한 그룹의 블레이드 서버, 또는 다중 프로세서 시스템)을 제공한다. 도 8에서는 하나의 프로세서를 예로 한다. 메모리는 본 출원에서 제공된 비일시적 컴퓨터 판독 가능 저장 매체이다. 상기 메모리에는 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어, 상기 적어도 하나의 프로세서가 본 출원에서 제공된 안전 벨트 의 착용 상태 인식 방법을 수행하도록 한다. 본 출원의 비일시적 컴퓨터 판독 가능 저장 매체는 컴퓨터 명령을 저장하며, 상기 컴퓨터 명령은 컴퓨터가 본 출원에서 제공된 안전 벨트의 착용 상태 인식 방법을 수행하도록 한 다. 메모리는 비일시적 컴퓨터 판독 가능 저장 매체로서, 본 출원의 실시예에서의 안전 벨트의 착용 상태 인식 방법에 대응되는 프로그램 명령/모듈(예를 들어, 도 6에 도시된 획득 모듈, 얼굴 인식 모듈, 결정 모 듈 및 상태 인식 모듈)과 같은 비일시적 소프트웨어 프로그램, 비일시적 컴퓨터 실행 가능 프로그램 및 모듈을 저장하는데 사용될 수 있다. 프로세서는 메모리에 저장된 비일시적 소프트웨어 프로그램, 명령 및 모듈을 실행함으로써, 서버의 다양한 기능 애플리케이션 및 데이터 처리를 수행하며, 즉 상기 방법의 실시예에서의 안전 벨트의 착용 상태 인식 방법을 구현한다. 메모리는 프로그램 저장 영역 및 데이터 저장 영역을 포함할 수 있는 바, 여기서 프로그램 저장 영역은 운 영 체제, 적어도 하나의 기능에 필요한 애플리케이션 프로그램을 저장할 수 있고; 데이터 저장 영역은 안전 벨 트의 착용 상태 인식 방법의 전자 기기의 사용에 따라 구축된 데이터 등을 저장할 수 있다. 이밖에, 메모리 는 고속 랜덤 액세스 메모리를 포함할 수 있고, 적어도 하나의 자기 디스크 저장 소자, 플래시 소자, 또는 다른 비일시적 솔리드 스테이트 저장 소자와 같은 비일시적 메모리를 더 포함할 수 있다. 일부 실시예에서, 메 모리는 프로세서에 대해 원격으로 설치되는 메모리를 선택적으로 포함할 수 있고, 이러한 원격 메모 리는 네트워크를 통해 전자 기기에 연결될 수 있다. 상기 네트워크의 구현예는 인터넷, 기업 인트라넷, 근거리 통신망, 이동 통신망, 및 이들의 조합을 포함하지만 이에 한정되지 않는다. 전자 기기는, 입력 장치 및 출력 장치를 더 포함할 수 있다. 프로세서, 메모리, 입력 장치 및 출력 장치는 버스 또는 다른 방식을 통해 연결될 수 있고, 도 8에서는 버스를 통한 연결을 예로 한다. 입력 장치는 입력된 숫자 또는 캐릭터 정보를 수신할 수 있고, 위치 결정 전자 기기의 사용자 설정 및 기 능 제어와 관련된 키 신호 입력을 생성할 수 있으며, 예를 들어 터치 스크린, 키패드, 마우스, 트랙 패드, 터치 패드, 포인팅 스틱, 하나 또는 다수의 마우스 버튼, 트랙볼, 조이스틱 등 입력 장치일 수 있다. 출력 장치(90 4)는 디스플레이 기기, 보조 조명 장치(예를 들어, LED) 및 촉각 피드백 장치(예를 들어, 진동 모터) 등을 포함 할 수 있다. 상기 디스플레이 기기는 액정 디스플레이 장치(LCD), 발광 다이오드(LED) 디스플레이 장치 및 플라 즈마 디스플레이 장치를 포함할 수 있으나 이에 한정되지 않는다. 일부 실시형태에서, 디스플레이 기기는 터치 스크린일 수 있다. 여기서 설명된 시스템 및 기술의 다양한 실시형태는 디지털 전자 회로 시스템, 집적 회로 시스템, 주문형 ASIC (주문형 집적 회로), 컴퓨터 하드웨어, 펌웨어, 소프트웨어, 및/또는 이들의 조합에서 구현될 수 있다. 이러한 다양한 실시형태는 하나 또는 다수의 컴퓨터 프로그램에서의 구현을 포함할 수 있고, 상기 하나 또는 다수의 컴 퓨터 프로그램은 적어도 하나의 프로그램 가능 프로세서를 포함하는 프로그램 가능 시스템에서 실행 및/또는 해 석될 수 있으며, 상기 프로그램 가능 프로세서는 주문형 또는 일반 프로그램 가능 프로세서일 수 있고, 저장 시 스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장치로부터 데이터 및 명령을 수신할 수 있으며, 또한, 데이터 및 명령을 상기 저장 시스템, 상기 적어도 하나의 입력 장치 및 상기 적어도 하나의 출력 장치에 전송할 수 있다. 이러한 컴퓨팅 프로그램(프로그램, 소프트웨어, 소프트웨어 애플리케이션 또는 코드로 지칭되기도 함)은 프로그 램 가능 프로세서의 기계 명령을 포함하고, 또한 고급 프로세스 및/또는 객체 지향 프로그래밍 언어, 및/또는 어셈블리/기계 언어를 사용하여 이러한 컴퓨팅 프로그램을 실행할 수 있다. 본문에 사용된 바와 같이, 용어 \"기 계 판독 가능 매체\" 및 \"컴퓨터 판독 가능 매체\"는 기계 명령 및/또는 데이터를 프로그램 가능 프로세서에 제공 하기 위한 임의의 컴퓨터 프로그램 제품, 기기 및/또는 장치(예를 들어, 자기 디스크, 광 디스크, 메모리, 프로 그램 가능 논리 장치(PLD))를 의미하고, 기계 판독 가능 신호인 기계 명령을 수신하는 기계 판독 가능 매체를 포함한다. 용어 \"기계 판독 가능 신호\"는 기계 명령 및/또는 데이터를 프로그램 가능 프로세서에 제공하기 위한 임의의 신호를 의미한다. 사용자와의 인터랙션을 제공하기 위해, 컴퓨터에서 여기에 설명된 시스템 및 기술을 구현할 수 있고, 상기 컴퓨 터는 사용자에게 정보를 디스플레이하기 위한 디스플레이 장치(예를 들어, CRT(음극선관) 또는 LCD(액정 표시 장치) 모니터); 및 키보드 및 포인팅 장치(예를 들어, 마우스 또는 트랙 볼)를 구비하며, 사용자는 상기 키보드 및 상기 포인팅 장치를 통해 컴퓨터에 입력을 제공한다. 다른 타입의 장치는 또한 사용자와의 인터랙션을 제공 할 수 있는데, 예를 들어, 사용자에게 제공된 피드백은 임의의 형태의 센서 피드백(예를 들어, 시각적 피드백, 청각적 피드백 또는 촉각적 피드백)일 수 있고; 임의의 형태(소리 입력, 음성 입력, 또는 촉각 입력)로 사용자 로부터의 입력을 수신할 수 있다. 여기서 설명된 시스템 및 기술은 백엔드 부재를 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서버로 사용됨), 또 는 미들웨어 부재를 포함하는 컴퓨팅 시스템(예를 들어, 애플리케이션 서버), 또는 프론트 엔드 부재를 포함하 는 컴퓨팅 시스템(예를 들어, 그래픽 사용자 인터페이스 또는 네트워크 브라우저를 구비하는 사용자 컴퓨터인 바, 사용자는 상기 그래픽 사용자 인터페이스 또는 상기 네트워크 브라우저를 통해 여기서 설명된 시스템 및 기 술의 실시형태와 인터랙션할 수 있음), 또는 이러한 백엔드 부재, 미들웨어 부재, 또는 프론트 엔드 부재의 임 의의 조합을 포함하는 컴퓨팅 시스템에서 구현될 수 있다. 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워크)을 통해 시스템의 부재를 서로 연결시킬 수 있다. 통신 네트워크의 예는, 근거리 통신망 (LAN), 광역망(WAN), 인터넷을 포함한다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 고, 일반적으로 통신 네트워크를 통해 서로 인터랙션한다. 대응되는 컴퓨터에서 실행되고 또한 서로 클라이언트 -서버 관계를 가지는 컴퓨터 프로그램을 통해 클라이언트 및 서버의 관계를 생성한다. 서버는 클라우드 컴퓨팅 서버 또는 클라우드 호스트로도 지칭되는 클라우드 서버일 수 있으며, 기존의 물리적 호스트와 VPS 서비스에서 존재하는 관리가 어렵고, 비즈니스 확장성이 약한 결함을 해결하기 위한 클라우드 컴퓨팅 서비스 시스템 중 하 나의 호스트 제품이다. 본 출원의 실시예의 기술적 해결수단에 따르면, 교통 수단에 대해 모니터링하여 획득된 모니터링 이미지에 대해 얼굴 인식을 수행하여, 얼굴 영역을 획득하고, 얼굴 영역의 크기 및 위치에 따라, 모니터링 이미지로부터 타겟 영역을 결정하며, 계속하여 타겟 영역의 이미지 특징에 따라, 안전 벨트의 착용 상태를 인식한다. 이로써, 본 출원에서 타겟 영역으로 기재된 안전 벨트의 착용 영역을 추정하고, 상기 타겟 영역에 대해서만 안전 벨트의 착 용 상태 인식을 수행하여, 모니터링 이미지 중 다른 쓸모없는 정보의 간섭을 효과적으로 감소시키며, 계산량을 감소시킬 수 있어 인식 속도를 향상시키고, 차량용 기기와 같은 컴퓨팅 기능이 상대적으로 낮은 기기에 적용되 어, 상기 방법의 적용성을 향상시킬 수 있다. 위에서 설명된 다양한 형태의 프로세스를 사용하여 단계를 재배열, 추가 또는 삭제할 수 있음을 이해해야 한다. 예를 들어, 본 출원에 기재된 각 단계는 동시에, 순차적으로, 또는 상이한 순서로 수행될 수 있으며, 본 출원에 개시된 기술적 해결수단이 이루고자 하는 결과를 구현할 수 있는 한, 본문은 여기서 한정되지 않는다."}
{"patent_id": "10-2021-0062760", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기 구체적인 실시형태는 본 출원의 보호 범위를 한정하지 않는다. 본 기술분야의 통상의 기술자는 설계 요구 및 다른 요소에 따라 다양한 수정, 조합, 서브 조합 및 대체를 진해할 수 있음을 이해해야 한다. 본 출원의 정 신 및 원칙 내에서 진행한 임의의 수정, 등가적 대체 및 개선 등은 모두 본 출원의 보호 범위 내에 속해야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2021-0062760", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면은 본 해결수단을 더 잘 이해하기 위한 것으로, 본 출원에 대해 한정하는 것으로 구성되지 않는다. 여기서, 도 1은 본 출원의 실시예 1에서 제공된 안전 벨트의 착용 상태 인식 방법의 흐름도이다. 도 2는 본 출원의 실시예 2에서 제공된 안전 벨트의 착용 상태 인식 방법의 흐름도이다. 도 3은 본 출원의 실시예 3에서 제공된 안전 벨트의 착용 상태 인식 방법의 흐름도이다. 도 4는 본 출원의 실시예 4에서 제공된 안전 벨트의 착용 상태 인식 방법의 흐름도이다. 도 5는 본 출원에서 콘볼루션 신경망의 네트워크 구조 개략도이다. 도 6은 본 출원의 실시예 5에서 제공된 안전 벨트의 착용 상태 인식 장치의 구조 개략도이다. 도 7은 본 출원의 실시예 6에서 제공된 안전 벨트의 착용 상태 인식 장치의 구조 개략도이다. 도 8은 본 출원의 실시예의 안전 벨트의 착용 상태 인식 방법을 구현하기 위한 전자 기기의 블록도이다."}
