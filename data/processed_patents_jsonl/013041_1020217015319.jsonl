{"patent_id": "10-2021-7015319", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0082204", "출원번호": "10-2021-7015319", "발명의 명칭": "지도 생성 방법, 운전 제어 방법, 장치, 전자 기기 및 시스템", "출원인": "센스타임 그룹 리미티드", "발명자": "왕, 제"}}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "지도 생성 방법으로서, 차량 탑재 카메라를 통해 차량이 위치한 도로 환경의 적어도 일부 영역의 이미지 정보를 획득하고, 차량 탑재레이더 센서를 통해 상기 차량이 위치한 도로 환경의 적어도 일부 영역의 포인트 클라우드 정보를 동기적으로대응하여 획득하는 단계;상기 이미지 정보에 대해 시멘틱 분할 처리를 수행하여 상기 영역 중 도로 요소의 제1 시멘틱 정보를 획득하는단계 - 상기 제1 시멘틱 정보는 상기 도로 요소의 2차원 위치 정보 및 속성 정보를 포함함 - ;상기 영역 중 도로 요소의 제1 시멘틱 정보 및 상기 영역의 포인트 클라우드 정보에 대해 매칭 처리를수행하여, 상기 영역 중 도로 요소의 제2 시멘틱 정보를 획득하는 단계 - 상기 제2 시멘틱 정보는 상기 도로 요소의 3차원 위치 정보 및 속성 정보를 포함함 - ;상기 제2 시멘틱 정보를 기반으로 지도를 생성하거나 지도 중 상기 영역에 대응하는 부분을 업데이트하는 단계를 포함하는 것을 특징으로 하는 지도 생성 방법."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 영역 중 도로 요소의 제1 시멘틱 정보 및 상기 영역의 포인트 클라우드 정보에 대해 매칭 처리를수행하여, 상기 영역 중 도로 요소의 제2 시멘틱 정보를 획득하는 단계는, 상기 포인트 클라우드 정보에 대해 3차원 좌표계에서 2차원 좌표계로의 좌표계 전환을 수행하여, 상기 2차원 위치 정보가 위치한 좌표계에서 상기 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득하는 단계;상기 포인트 클라우드 2차원 정보 및 상기 도로 요소의 2차원 위치 정보에 대해 매칭 처리를 수행하여, 상기 영역 중 상기 도로 요소의 제2 시멘틱 정보를 획득하는 단계를 포함하는 것을 특징으로 하는 지도 생성 방법."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 포인트 클라우드 2차원 정보 및 상기 도로 요소의 2차원 위치 정보에 대해 매칭 처리를 수행하여, 상기 영역 중 상기 도로 요소의 제2 시멘틱 정보를 획득하는 단계는, 상기 도로 요소의 2차원 위치 정보에 따라, 상기 포인트 클라우드 2차원 정보 중 각 픽셀이 상기 도로 요소에속하는지 여부를 결정하는 단계; 상기 포인트 클라우드 2차원 정보 중 제1 픽셀이 상기 도로 요소에 속하는 것에 응답하여, 상기 제1 픽셀이 상기 포인트 클라우드 정보에서의 3차원 위치 정보 및 상기 제1 픽셀이 상기 제1 시멘틱 정보에서의 속성 정보를획득하여, 상기 제1 픽셀의 3차원 위치 정보 및 속성 정보를 획득하는 단계 - 상기 제1 픽셀은 상기 포인트 클라우드 2차원 정보 중 어느 한 픽셀임 - 를 포함하는 것을 특징으로 하는 지도 생성 방법."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항 또는 제3항에 있어서,상기 포인트 클라우드 정보에 대해 3차원 좌표계에서 2차원 좌표계로의 좌표계 전환을 수행하여, 상기 2차원 위치 정보가 위치한 좌표계에서 상기 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득하는 단계는, 상기 포인트 클라우드 정보를 NED 좌표계에서 픽셀 좌표계로 전환하여 상기 픽셀 좌표계에서 상기 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득하는 단계 - 상기 2차원 위치 정보는 상기 픽셀 좌표계에서의공개특허 10-2021-0082204-3-정보임 - 를 포함하는 것을 특징으로 하는 지도 생성 방법."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 포인트 클라우드 정보를 NED 좌표계에서 픽셀 좌표계로 전환하는 단계는, 상기 포인트 클라우드 정보를 NED 좌표계에서 관성 측정 유닛 좌표계로 전환하여 상기 관성 측정 유닛 좌표계에서 상기 포인트 클라우드 정보의 정보를 획득하는 단계; 상기 관성 측정 유닛 좌표계와 카메라 좌표계의 회전 및 평행 이동 매트릭스에 따라, 상기 관성 측정 유닛 좌표계에서 상기 포인트 클라우드 정보의 정보를 상기 카메라 좌표계로 전환하여, 상기 카메라 좌표계에서 상기 포인트 클라우드 정보의 정보를 획득하는 단계; 카메라의 파라미터 매트릭스에 따라, 상기 카메라 좌표계에서 상기 포인트 클라우드 정보의 정보를 상기 픽셀좌표계로 전환하여, 상기 픽셀 좌표계에서 상기 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득하는 단계를 포함하는 것을 특징으로 하는 지도 생성 방법."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 포인트 클라우드 정보를 NED 좌표계에서 픽셀 좌표계로 전환하는 단계는,상기 포인트 클라우드 정보를 NED 좌표계에서 레이더 좌표계로 전환하여 상기 레이더 좌표계에서 상기 포인트클라우드 정보의 정보를 획득하는 단계;상기 레이더 좌표계와 카메라 좌표계의 회전 및 평행 이동 매트릭스에 따라, 상기 레이더 좌표계에서 상기 포인트 클라우드 정보의 정보를 상기 카메라 좌표계로 전환하여, 상기 카메라 좌표계에서 상기 포인트 클라우드 정보의 정보를 획득하는 단계;카메라의 파라미터 매트릭스에 따라, 상기 카메라 좌표계에서 상기 포인트 클라우드 정보의 정보를 상기 픽셀좌표계로 전환하여, 상기 픽셀 좌표계에서 상기 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득하는 단계를 포함하는 것을 특징으로 하는 지도 생성 방법."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항 내지 제6항 중 어느 한 항에 있어서,상기 포인트 클라우드 2차원 정보 및 상기 도로 요소의 2차원 위치 정보에 대해 매칭 처리를 수행하여, 상기 영역 중 상기 도로 요소의 제2 시멘틱 정보를 획득하는 단계는,상기 이미지 정보에 대해 주행 가능 영역 검출을 수행하여, 상기 영역 내의 주행 가능 영역의 정보를 획득하는단계;상기 포인트 클라우드 2차원 정보 중 제2 픽셀이 상기 영역 내의 주행 가능 영역 중 픽셀인 것에 응답하여, 상기 제2 픽셀 및 상기 도로 요소의 2차원 위치 정보에 대해 매칭 처리를 수행하여, 상기 영역의 지도 중 상기 도로 요소의 제2 시멘틱 정보를 획득하는 단계 - 상기 제2 픽셀은 상기 포인트 클라우드 2차원 정보 중 어느 한픽셀임 - 를 포함하는 것을 특징으로 하는 지도 생성 방법."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제6항 중 어느 한 항에 있어서,상기 영역 중 도로 요소의 제1 시멘틱 정보 및 상기 영역의 포인트 클라우드 정보에 대해 매칭 처리를 수행하기전에, 상기 영역의 상기 이미지 정보 및 상기 포인트 클라우드 정보를 수집하는 동시에, 차량 탑재 내비게이션 시스템을 통해 상기 차량의 포즈 정보를 획득하는 단계;차량의 포즈 정보에 따라, 상기 차량 탑재 레이더 센서에 의해 수집된 포인트 클라우드 정보로 구성된 포인트공개특허 10-2021-0082204-4-클라우드 정보 집합 중에서 상기 영역의 포인트 클라우드 정보를 선별하는 단계를 더 포함하는 것을 특징으로하는 지도 생성 방법."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 수집된 포인트 클라우드 정보로 구성된 포인트 클라우드 정보 집합 중에서 상기 영역의 포인트 클라우드정보를 선별하기 전에, 수집된 각 영역의 이미지 정보에 대해 주행 가능 영역 검출을 수행하여, 각 영역 내의 주행 가능 영역의 정보를획득하는 단계; 상기 차량 탑재 레이더 센서에 의해 수집된 각 영역의 포인트 클라우드 정보에서 각 영역 내의 주행 가능 영역의 포인트 클라우드 정보를 선별하는 단계;각 영역 내의 주행 가능 영역의 포인트 클라우드 정보를 스플라이싱하여 상기 포인트 클라우드 정보 집합을 획득하는 단계를 더 포함하는 것을 특징으로 하는 지도 생성 방법."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항 또는 제9항에 있어서,상기 차량 탑재 내비게이션 시스템은 위성 항법 시스템 및 관성 측정 유닛 중 적어도 하나를 포함하는 것을 특징으로 하는 지도 생성 방법."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제10항 중 어느 한 항에 있어서,상기 제2 시멘틱 정보를 기반으로 지도를 생성하거나 지도 중 상기 영역에 대응하는 부분을 업데이트하는 단계는,상기 도로 요소에 대응하는 기설정된 특징 정보에 따라, 상기 영역의 지도 중 상기 도로 요소를 선별하여 선별된 도로 요소를 획득하는 처리 방식; 상기 3차원 위치 정보로 특징화되는 상기 도로 요소 중 픽셀에 대해 피팅처리를 수행하여, 선 파라미터로 특징화되는 상기 도로 요소를 획득하는 처리 방식; 상기 도로 요소에 대해 샘플링 처리를 수행하여, 샘플링된 상기 도로 요소를 획득하는 처리 방식; 상기 3차원 위치 정보를 NED 좌표계에서 목표 좌표계로 전환하여 상기 목표 좌표계에서 상기 3차원 위치 정보의 위치 정보를 획득하는 처리 방식 중적어도 하나를 사용하여, 상기 도로 요소를 처리하는 단계;처리하여 획득된 상기 도로 요소의 제2 시멘틱 정보를 기반으로 지도를 생성하거나 지도 중 상기 영역에 대응하는 부분을 업데이트하는 단계를 포함하는 것을 특징으로 하는 지도 생성 방법."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "지도 생성 장치로서, 차량 탑재 카메라를 통해 차량이 위치한 도로 환경의 적어도 일부 영역의 이미지 정보를 획득하고, 차량 탑재레이더 센서를 통해 상기 차량이 위치한 도로 환경의 적어도 일부 영역의 포인트 클라우드 정보를 동기적으로대응하여 획득하는 수집 모듈;상기 이미지 정보에 대해 시멘틱 분할 처리를 수행하여 상기 영역 중 도로 요소의 제1 시멘틱 정보를 획득하는분할 모듈 - 상기 제1 시멘틱 정보는 상기 도로 요소의 2차원 위치 정보 및 속성 정보를 포함함 - ;상기 영역 중 도로 요소의 제1 시멘틱 정보 및 상기 영역의 포인트 클라우드 정보에 대해 매칭 처리를수행하여, 상기 영역 중 도로 요소의 제2 시멘틱 정보를 획득하는 매칭 모듈 - 상기 제2 시멘틱 정보는 상기 도로 요소의 3차원 위치 정보 및 속성 정보를 포함함 - ;상기 제2 시멘틱 정보를 기반으로 지도를 생성하거나 지도 중 상기 영역에 대응하는 부분을 업데이트하는 생성모듈을 포함하는 것을 특징으로 하는 지도 생성 장치.공개특허 10-2021-0082204-5-청구항 13 제12항에 있어서,상기 매칭 모듈은,상기 포인트 클라우드 정보에 대해 3차원 좌표계에서 2차원 좌표계로의 좌표계 전환을 수행하여, 상기 2차원 위치 정보가 위치한 좌표계에서 상기 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득하는 전환 유닛;상기 포인트 클라우드 2차원 정보 및 상기 도로 요소의 2차원 위치 정보에 대해 매칭 처리를 수행하여, 상기 영역 중 상기 도로 요소의 제2 시멘틱 정보를 획득하는 매칭 유닛을 포함하는 것을 특징으로 하는 지도 생성장치."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 매칭 유닛은, 상기 도로 요소의 2차원 위치 정보에 따라, 상기 포인트 클라우드 2차원 정보 중 각 픽셀이상기 도로 요소에 속하는지 여부를 결정하고; 상기 포인트 클라우드 2차원 정보 중 제1 픽셀이 상기 도로 요소에 속하는 것에 응답하여, 상기 제1 픽셀이 상기 포인트 클라우드 정보에서의 3차원 위치 정보 및 상기 제1 픽셀이 상기 제1 시멘틱 정보에서의 속성 정보를 획득하여, 상기 제1 픽셀의 3차원 위치 정보 및 속성 정보를 획득하며; 상기 제1 픽셀은 상기 포인트 클라우드 2차원 정보 중 어느 한 픽셀인 것을 특징으로 하는 지도 생성장치."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항 또는 제14항에 있어서,상기 전환 유닛은 상기 포인트 클라우드 정보를 NED 좌표계에서 픽셀 좌표계로 전환하여 상기 픽셀 좌표계에서상기 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득하며, 상기 2차원 위치 정보는 상기 픽셀 좌표계에서의 정보인 것을 특징으로 하는 지도 생성 장치."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 전환 유닛은, 상기 포인트 클라우드 정보를 NED 좌표계에서 관성 측정 유닛 좌표계로 전환하여 상기 관성측정 유닛 좌표계에서 상기 포인트 클라우드 정보의 정보를 획득하고; 상기 관성 측정 유닛 좌표계와 카메라 좌표계의 회전 및 평행 이동 매트릭스에 따라, 상기 관성 측정 유닛 좌표계에서 상기 포인트 클라우드 정보의 정보를 상기 카메라 좌표계로 전환하여, 상기 카메라 좌표계에서 상기 포인트 클라우드 정보의 정보를 획득하고;카메라의 파라미터 매트릭스에 따라, 상기 카메라 좌표계에서 상기 포인트 클라우드 정보의 정보를 상기 픽셀좌표계로 전환하여, 상기 픽셀 좌표계에서 상기 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득하는 것을 특징으로 하는 지도 생성 장치."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 전환 유닛은, 상기 포인트 클라우드 정보를 NED 좌표계에서 레이더 좌표계로 전환하여 상기 레이더 좌표계에서 상기 포인트 클라우드 정보의 정보를 획득하고; 상기 레이더 좌표계와 카메라 좌표계의 회전 및 평행 이동매트릭스에 따라, 상기 레이더 좌표계에서 상기 포인트 클라우드 정보의 정보를 상기 카메라 좌표계로전환하여, 상기 카메라 좌표계에서 상기 포인트 클라우드 정보의 정보를 획득하고; 카메라의 파라미터 매트릭스에 따라, 상기 카메라 좌표계에서 상기 포인트 클라우드 정보의 정보를 상기 픽셀 좌표계로 전환하여, 상기 픽셀 좌표계에서 상기 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득하는 것을 특징으로 하는 지도생성 장치."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항 내지 제17항 중 어느 한 항에 있어서,공개특허 10-2021-0082204-6-상기 매칭 유닛은, 상기 이미지 정보에 대해 주행 가능 영역의 검출을 수행하여 상기 영역 내의 주행 가능 영역의 정보를 획득하고; 상기 포인트 클라우드 2차원 정보 중 제2 픽셀이 상기 영역 내의 주행 가능 영역 중 픽셀인 것에 응답하여, 상기 제2 픽셀 및 상기 도로 요소의 2차원 위치 정보에 대해 매칭 처리를 수행하여, 상기 영역의 지도 중 상기 도로 요소의 제2 시멘틱 정보를 획득하며; 상기 제2 픽셀은 상기 포인트 클라우드 2차원 정보 중 어느 한 픽셀인 것을 특징으로 하는 지도 생성 장치."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항 내지 제17항 중 어느 한 항에 있어서,상기 영역의 상기 이미지 정보 및 상기 포인트 클라우드 정보를 수집하는 동시에, 차량 탑재 내비게이션 시스템을 통해 상기 차량의 포즈 정보를 획득하는 획득 모듈;차량의 포즈 정보에 따라, 상기 차량 탑재 레이더 센서에 의해 수집된 포인트 클라우드 정보로 구성된 포인트클라우드 정보 집합 중에서 상기 영역의 포인트 클라우드 정보를 선별하는 제1 선별 모듈을 더 포함하는 것을특징으로 하는 지도 생성 장치."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,수집된 각 영역의 이미지 정보에 대해 주행 가능 영역 검출을 수행하여, 각 영역 내의 주행 가능 영역의 정보를획득하는 검출 모듈;상기 차량 탑재 레이더 센서에 의해 수집된 각 영역의 포인트 클라우드 정보에서 각 영역 내의 주행 가능 영역의 포인트 클라우드 정보를 선별하는 제2 선별 모듈;각 영역 내의 주행 가능 영역의 포인트 클라우드 정보를 스플라이싱하여 상기 포인트 클라우드 정보 집합을 획득하는 스플라이싱 모듈을 더 포함하는 것을 특징으로 하는 지도 생성 장치."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서,상기 차량 탑재 내비게이션 시스템은 위성 항법 시스템 및 관성 측정 유닛 중 적어도 하나를 포함하는 것을 특징으로 하는 지도 생성 장치."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제12항 내지 제21항 중 어느 한 항에 있어서,상기 생성 모듈은,상기 도로 요소에 대응하는 기설정된 특징 정보에 따라, 상기 영역의 지도 중 상기 도로 요소를 선별하여 선별된 도로 요소를 획득하는 처리 방식; 상기 3차원 위치 정보로 특징화되는 상기 도로 요소 중 픽셀에 대해 피팅처리를 수행하여, 선 파라미터로 특징화되는 상기 도로 요소를 획득하는 처리 방식; 상기 도로 요소에 대해 샘플링 처리를 수행하여, 샘플링된 상기 도로 요소를 획득하는 처리 방식; 상기 3차원 위치 정보를 NED 좌표계에서 목표 좌표계로 전환하여 상기 목표 좌표계에서 상기 3차원 위치 정보의 위치 정보를 획득하는 처리 방식 중적어도 하나를 사용하여, 상기 도로 요소를 처리하는 처리 유닛;처리하여 획득된 상기 도로 요소의 제2 시멘틱 정보를 기반으로 지도를 생성하거나 지도 중 상기 영역에 대응하는 부분을 업데이트하는 생성 유닛을 포함하는 것을 특징으로 하는 지도 생성 장치."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "운전 제어 방법으로서,운전 제어 장치가 차량이 위치한 도로 환경의 적어도 일부 영역의 지도 정보를 획득하는 단계 - 지도 정보는 제1항 내지 제11항 중 어느 한 항에 따른 지도 생성 방법을 적용하여 획득됨 - ;상기 운전 제어 장치가 상기 지도 정보에 따라 차량에 대해 지능형 운전 제어를 수행하는 단계를 포함하는 것을공개특허 10-2021-0082204-7-특징으로 하는 운전 제어 방법."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "운전 제어 장치로서,차량이 위치한 도로 환경의 적어도 일부 영역의 지도 정보를 획득하는 획득 모듈 - 지도 정보는 제1항 내지 제11항 중 어느 한 항에 따른 지도 생성 방법을 적용하여 획득됨 - ;상기 지도 정보에 따라 차량에 대해 지능형 운전 제어를 수행하는 운전 제어 모듈을 포함하는 것을 특징으로 하는 운전 제어 장치."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "전자 기기로서,프로그램 명령을 저장하는 메모리;상기 메모리 중 프로그램 명령을 호출 및 수행하여 제1항 내지 제11항 중 어느 한 항에 따른 방법 단계를 수행하는 프로세서를 포함하는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "지능형 운전 시스템으로서, 통신적으로 연결된 센서, 제25항에 따른 전자 기기 및 제24항에 따른 운전 제어 장치를 포함하며, 상기 센서는차량이 위치한 도로 환경의 적어도 일부 영역의 이미지 정보 및 포인트 클라우드 정보를 수집하는 것을 특징으로 하는 지능형 운전 시스템."}
{"patent_id": "10-2021-7015319", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "컴퓨터 판독 가능한 저장매체로서, 프로세서에 의해 실행되면 제1항 내지 제11항 중 어느 한 항에 따른 방법 단계를 구현하거나, 프로세서에 의해실행되면 제23항에 따른 방법 단계를 구현하는 컴퓨터 프로그램이 저장되는 것을 특징으로 하는 컴퓨터 판독 가능한 저장매체."}
{"patent_id": "10-2021-7015319", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시예는 지도 생성 방법, 운전 제어 방법, 장치, 전자 기기 및 시스템을 장치를 개시하며, 상기 지도 생성 방법은, 차량 탑재 카메라를 통해 차량이 위치한 도로 환경의 적어도 일부 영역의 이미지 정보를 획득하고, 차량 탑재 레이더 센서를 통해 상기 차량이 위치한 도로 환경의 적어도 일부 영역의 포인트 클라우드 정보를 동 (뒷면에 계속)"}
{"patent_id": "10-2021-7015319", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원의 상호 참조 본 출원은 출원번호가 201910496345.3이고 출원일자가 2019년 6월 10일인 중국 특허 출원을 기반으로 제출되며, 당해 중국 특허 출원의 우선권을 주장하며, 당해 중국 특허 출원의 전부 내용은 여기서 인용방식으로 본 출원에 결합된다. 본 발명의 실시예는 지능형 운전 기술에 관한 것으로서, 특히 지도 생성 방법, 운전 제어 방법, 장치, 전자 기 기 및 시스템에 관한 것이다."}
{"patent_id": "10-2021-7015319", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "지능형 운전 분야에서, 고정밀 지도는 중요한 역할을 하며, 지능형 운전 분야에서 없어서는 안되는 구성부분이 다. 차량 지향 지도는 일반적으로 고정밀 지도라고 하며, 이는 사람 지향 지도(내비게이션 지도)와 달리, 고정 밀 지도는 풍부한 시멘틱 정보 및 운전 보조 정보를 포함한다. 예를 들어, 고정밀 지도에서는 도로뿐만 아니라 도로 표시선의 위치 및 유형 등과 같은 도로의 도로 표시선 정보도 표시할 수 있다. 상술한 고정밀 지도를 기반 으로, 차량의 위치 결정, 운전 제어 등을 구현할 수 있다."}
{"patent_id": "10-2021-7015319", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예는 지도 생성 방법, 운전 제어 방법, 장치, 전자 기기 및 시스템을 제공한다."}
{"patent_id": "10-2021-7015319", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "제1 측면에서, 본 발명의 실시예는 지도 생성 방법을 제공하며, 상기 방법은 차량 탑재 카메라를 통해 차량이 위치한 도로 환경의 적어도 일부 영역의 이미지 정보를 획득하고, 차량 탑재 레이더 센서를 통해 상기 차량이 위치한 도로 환경의 적어도 일부 영역의 포인트 클라우드 정보를 동기적으로 대응하여 획득하는 단계; 상기 이미지 정보에 대해 시멘틱 분할 처리를 수행하여 상기 영역 중 도로 요소의 제1 시멘틱 정보를 획득하는 단계 - 상기 제1 시멘틱 정보는 상기 도로 요소의 2차원 위치 정보 및 속성 정보를 포함함 - ; 상기 영역 중 도로 요소의 제1 시멘틱 정보 및 상기 영역의 포인트 클라우드 정보에 대해 매칭 처리를 수행하여, 상기 영역 중 도로 요소의 제2 시멘틱 정보를 획득하는 단계 - 상기 제2 시멘틱 정보는 상기 도로 요 소의 3차원 위치 정보 및 속성 정보를 포함함 - ; 상기 제2 시멘틱 정보를 기반으로 지도를 생성하거나 지도 중 상기 영역에 대응하는 부분을 업데이트하는 단계 를 포함한다. 제2 측면에서, 본 발명의 실시예는 지도 생성 장치를 제공하며, 상기 장치는 차량 탑재 카메라를 통해 차량이 위치한 도로 환경의 적어도 일부 영역의 이미지 정보를 획득하고, 차량 탑재 레이더 센서를 통해 상기 차량이 위치한 도로 환경의 적어도 일부 영역의 포인트 클라우드 정보를 동기적으로 대응하여 획득하는 수집 모듈; 상기 이미지 정보에 대해 시멘틱 분할 처리를 수행하여 상기 영역 중 도로 요소의 제1 시멘틱 정보를 획득하는 분할 모듈 - 상기 제1 시멘틱 정보는 상기 도로 요소의 2차원 위치 정보 및 속성 정보를 포함함 - ; 상기 영역 중 도로 요소의 제1 시멘틱 정보 및 상기 영역의 포인트 클라우드 정보에 대해 매칭 처리를 수행하여, 상기 영역 중 도로 요소의 제2 시멘틱 정보를 획득하는 매칭 모듈 - 상기 제2 시멘틱 정보는 상기 도 로 요소의 3차원 위치 정보 및 속성 정보를 포함함 - ; 상기 제2 시멘틱 정보를 기반으로 지도를 생성하거나 지도 중 상기 영역에 대응하는 부분을 업데이트하는 생성 모듈을 포함한다. 제3 측면에서, 본 발명의 실시예는 운전 제어 방법을 제공하며, 상기 방법은 운전 제어 장치가 차량이 위치한 도로 환경의 적어도 일부 영역의 지도 정보를 획득하는 단계 - 지도 정보는 상 술한 제1 측면에 따른 지도 생성 방법을 적용하여 획득됨 - ; 상기 운전 제어 장치가 상기 지도 정보에 따라 차량에 대해 지능형 운전 제어를 수행하는 단계를 포함한다. 제4 측면에서, 본 발명의 실시예는 운전 제어 장치를 제공하며, 상기 장치는 차량이 위치한 도로 환경의 적어도 일부 영역의 지도 정보를 획득하는 획득 모듈 - 지도 정보는 상술한 제1 측 면에 따른 지도 생성 방법을 적용하여 획득됨 - ; 상기 지도 정보에 따라 차량에 대해 지능형 운전 제어를 수행하는 운전 제어 모듈을 포함한다. 제5 측면에서, 본 발명의 실시예는 전자 기기를 제공하며, 상기 전자 기기는 프로그램 명령을 저장하는 메모리; 상기 메모리 중 프로그램 명령을 호출 및 수행하여 상술한 제1 측면에 따른 방법 단계를 수행하는 프로세서를 포함한다. 제6 측면에서, 본 발명의 실시예는 통신적으로 연결된 센서, 상술한 제5 측면에 따른 전자 기기, 및 상술한 제4 측면에 따른 운전 제어 장치를 포함하는 지능형 운전 시스템을 제공하며, 상기 센서는 차량이 위치한 도로 환경 의 적어도 일부 영역의 이미지 정보 및 포인트 클라우드 정보를 수집한다. 제7 측면에서, 본 발명의 실시예는 상술한 제1 측면에 따른 방법 단계 또는 상술한 제3 측면에 따른 방법 단계 를 수행하기 위한 컴퓨터 프로그램이 저장된 판독 가능한 저장매체를 제공한다."}
{"patent_id": "10-2021-7015319", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 의해 제공된 지도 생성 방법, 운전 제어 방법, 장치, 전자 기기 및 시스템은, 차량 탑재 카 메라를 통해 도로 환경 중 적어도 일부 영역의 이미지 정보를 수집하고, 이미지 정보에 대해 시멘틱 분할 처리 를 수행하여 영역 중 도로 요소의 2차원 위치 정보 및 속성 정보를 획득하는 동시에, 차량 탑재 레이더 센서를 통해 영역의 포인트 클라우드 정보를 동기적으로 수집한 후, 제1 시멘틱 정보 및 포인트 클라우드 정보에 대해 매칭 처리를 수행하여, 영역 중 도로 요소의 3차원 위치 정보 및 속성 정보를 획득할 수 있다. 상술한 과정에서, 차량 탑재 카메라 및 차량 탑재 레이더 센서는 차량에 설치된 서로 다른 유형의 센서로서 동기적으로 작동하며, 서로 다른 유형의 센서에 의해 수집된 정보를 기반으로 매칭 처리를 수행하여 영역의 지도를 직접 생 성하거나 업데이트할 수 있으며, 지도 생성 또는 업데이트 과정에서의 인공 조작을 감소하거나 생략함으로써 지 도를 구축하는 자동화 정도가 높고, 고정밀 지도의 구축 효율을 크게 향상시킨다. 또한, 제1 시멘틱 정보 및 포 인트 클라우드 정보를 매칭하여 도로 요소를 특징화하는 다양한 정보의 효과적인 통합을 가능하게 하여, 지도 중 도로 요소의 정확도를 크게 향상시킬 수 있다."}
{"patent_id": "10-2021-7015319", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 실시예의 목적, 기술적 방안 및 장점이 더욱 명확해지도록, 이하 본 발명의 실시예 중의 첨부 도면을 결부하여 본 발명의 실시예 중의 기술적 방안을 명확하고 완정하게 설명하며, 설명된 실시예가 본 발명의 일부 실시예이지 전부 실시예가 아님은 자명한 것이다. 본 발명의 실시예를 기반으로, 본 분야의 통상의 기술자가 창 조성 노동 없이 획득한 모든 다른 실시예는 모두 본 발명의 실시예의 보호 범위에 속한다. 도 1은 본 발명의 실시예에 의해 제공된 지도 구축 방법의 개략적인 흐름도 1이며, 상기 방법의 수행 주체는 데 이터 계산 처리 능력이 구비된 전자 기기일 수 있다. 도 1에 도시된 바와 같이, 상기 방법은 아래의 단계들을 포함한다. S101 단계: 차량 탑재 카메라를 통해 차량이 위치한 도로 환경의 적어도 일부 영역의 이미지 정보를 획득하고, 차량 탑재 레이더 센서를 통해 상기 차량이 위치한 도로 환경의 적어도 일부 영역의 포인트 클라우드 정보를 동기적으로 대응하여 획득한다. 본 발명의 실시예에서 생성된 지도는 차량 지향 지도, 즉 고정밀 지도이다. 본 발명의 실시예는 고정밀 지도를 생성하거나 고정밀 지도 중 일부 영역을 업데이트하는 시나리오에 적용될 수 있다. 어느 한 영역의 고정밀 지도 를 생성하거나 고정밀 지도의 적어도 일부 영역을 업데이트하기 전에, 먼저 차량을 상기 영역 내에서 주행시키 고 차량의 복수 개의 센서를 통해 각각 상기 영역 내의 정보를 동시에 수집하며 각 센서에 의해 수집된 정보를 처리하여 상기 지역의 지도를 획득할 수 있다. 여기서, 차량의 운전 모드는 인공 운전 모드일 수도 있고, 무인 운전 모드일 수도 있으며, 본 발명의 실시예는 이에 대해 구체적으로 한정하지 않는다. 예를 들어, 어느 한 도 시의 지도를 구축하기 전에, 차량을 해당 도시의 각 도로에서 주행시키고, 주행 과정에 차량 탑재 카메라(차량 카메라라고도 칭함)에 의해 차량 전방 노면 및 주변 건물 등의 이미지 정보를 수집하고, 차량 탑재 레이더 센서 에 의해 차량 주변 환경의 포인트 클라우드 정보를 수집할 수 있다. 상술한 이미지 정보 및 포인트 클라우드 정 보를 기반으로, 후술 단계의 처리를 통해, 차량이 위치한 도로 환경 중 적어도 일부 영역의 지도를 생성하거나 업데이트할 수 있다. 선택적으로, 차량의 주행 과정에서, 차량의 위성 항법 시스템(Global Positioning System, GPS) 또는 관성 측정 유닛(Inertial Measurement Unit, IMU)을 통해 차량의 각 시각에서의 포즈(pose) 정보를 획득하고 포즈 정보를 기반으로 포인트 클라우드 정보를 선별할 수도 있으며, 포즈 정보를 기반으로 포인트 클 라우드 정보를 선별하는 것은 아래의 실시예에서 설명할 것이다. 상술한 과정에서, 차량 탑재 카메라, 차량 탑재 레이더 센서, GPS, IMU 등은 차량에 설치된 서로 다른 유형의 센서이며, 이러한 센서들은 동시에 작동한다. 여기서, 본 발명의 실시예 중 서로 다른 센서들의 동기화는 하드 웨어 기기를 통해 데이터 수집을 동시에 트리거하는 방식으로 구현될 수도 있고, 소프트웨어 방법을 이용하여 각 센서에 의해 각각 수집된 데이터에 대해 시간 정렬을 수행하는 방식으로 구현될 수도 있으며, 본 발명의 실 시예는 이에 대해 한정하지 않는다. 본 실시예에서, 각 센서는 일정한 주기에 따라 정보를 수집하며, 각 센서가 각 주기에 수집한 정보의 시간은 정 렬된다. 예시적으로, 차량 탑재 카메라가 A 시각에 한 프레임의 차량 전방의 이미지 정보를 수집하였으면, 차량 탑재 레이더 센서는 A 시각에 한 프레임의 이미지 정보에 대응하는 포인트 클라우드 데이터를 수집하며, GPS 및 IMU는 각각 A 시각에 차량의 포즈 정보를 획득한다. 각 센서의 동기화 정보 수집을 통해, 지도를 구축하거나 업 데이트하기 위한 이미지 정보, 포인트 클라우드 정보의 시간이 동기화되어 수집된 것이 동일한 객체의 정보임을 보장하고, 후속 매칭 처리 결과의 정확도를 보장한다. 또한, 상술한 과정에서, 차량 탑재 카메라, 차량 탑재 레이더 센서, GPS, IMU 등 센서는 서로 통합되어 지도의 생성 또는 업데이트를 완료한다. 각 센서에는 각각의 성능 경계가 있을 수 있다. 성능 경계에는 제한된 검출 범 위, 감지 결함, 사전 정보 결함 등이 포함되지만 이에 한정되지 않는다. 여기서, 제한된 검출 범위는 센서가 주 변 환경에 대한 검출이 고정된 범위를 가지고 있음을 가리킨다. 예시적으로, 장거리 밀리미터 파 레이더의 탐지 거리는 1 미터 (m) ~ 280m이고, 적외선 센서의 탐지 거리는 0.2m-120m이다. 감지 결함은 센서가 그 사용 환경 조건이 있음을 가리킨다. 예시적으로, 고해상도 카메라는 이미지 중 물체를 검출할 수 있고, 시야가 좁은 카메 라는 거리가 먼 물체를 검출할 수 있다. 사전 정보는 사전에 수집할 수 있고 단시간 내에 변경되지 않는 정보를 가리킨다. 사전 정보 결함은 센서를 통해 수집할 수 없는 사전 정보를 가리킨다. 예시적으로, 센서는 차량이 현 재 고속도로에 있는지 여부를 감지할 수 없다. 각 센서가 각각의 성능 경계를 갖고 있다는 점을 감안하여, 본 발명의 실시예에서는 각 센서를 통합하여 각 센서가 동시에 수집한 정보를 획득하여 서로 다른 유형의 정보를 수집할 수 있으며, 이러한 서로 다른 유형의 정보를 기반으로 지도를 생성하거나 업데이트하여, 단일 센서의 성 능 경계로 인해 발생할 수 있는 정보 수집 누락과 같은 문제를 크게 줄이거나 제거할 수 있다. S102 단계: 상기 이미지 정보에 대해 시멘틱 분할 처리를 수행하여 상기 영역 중 도로 요소의 제1 시멘틱 정보 를 획득하며, 상기 제1 시멘틱 정보는 상기 도로 요소의 2차원 위치 정보 및 속성 정보를 포함한다. 선택적으로, 상술한 도로 요소는 도로 환경에 나타나는 모든 유형의 객체일 수 있다. 예시적으로, 도로 요소는 도로 표시선, 교통 지시등, 교통 표지판, 로드 블록, 도로 양쪽의 가로등, 도로 양쪽의 나무, 도로 양쪽의 건물 등 중 하나 또는 복수 개일 수 있다. 도로 표시선은 차선, 정지선, 교차로, 회전선 등이 될 수 있다. 본 발명의 실시예는 도로 요소의 구체적인 형태에 대해 한정하지 않는다. 차량 탑재 카메라에 의해 수집된 이미지 정보에 대해 시멘틱 분할 처리를 수행하여, 수집된 영역 중 노면 요소 의 제1 시멘틱 정보를 획득할 수 있다. 제1 시멘틱 정보는 노면 요소의 2차원 위치 정보 및 속성 정보를 포함한 다. 2차원 위치 정보는 예를 들어 도로 요소의 각 포인트의 2차원 좌표치 등을 포함할 수 있다. 선택적으로, 상기 제1 시멘틱 정보 중 속성 정보는 도로 요소의 속성을 설명한다. 서로 다른 도로 요소에 대하 여, 상기 제1 시멘틱 정보 중 속성 정보는 서로 다른 의미일 수 있다. 예를 들어, 도로 요소가 차선인 경우, 상 기 속성 정보는 선형 차원의 실선, 점선, 색상 차원의 흰색, 노란색 등과 같은 서로 다른 차원의 차선 유형을 가리킬 수 있다. 또 예를 들어, 도로 요소가 정지선인 경우, 상기 속성 정보는 정지선에 대응하는 고정치일 수 있다. 본 발명의 실시예는 상기 속성 정보에 대해 구체적으로 한정하지 않는다. 선택적으로, 차량 탑재 레이더 센서는 먼저 원시의 3차원 포인트 클라우드 정보를 수집할 수 있으며, 포인트 클 라우드 정보를 수집할 때 차량의 포즈 정보를 기반으로 선별 등 처리를 수행하여 상기 포인트 클라우드 정보를 획득할 수 있다. 상기 제1 시멘틱 정보 및 포인트 클라우드 정보를 획득하는 과정은 아래의 실시예에서 상세히 설명한다. S103 단계: 상기 영역 중 도로 요소의 제1 시멘틱 정보 및 상기 영역의 포인트 클라우드 정보에 대해 매칭 처리 를 수행하여, 상기 영역 중 도로 요소의 제2 시멘틱 정보를 획득하며, 상기 제2 시멘틱 정보는 상기 도로 요소 의 3차원 위치 정보 및 속성 정보를 포함한다. 상기 제1 시멘틱 정보에는 도로 요소의 2차원 위치 정보가 포함되며, 상기 포인트 클라우드 정보는 공간 내 한 포인트의 3차원 위치 정보를 특징화할 수 있으며, 도로 요소의 3차원 위치 정보를 포함한다. 본 단계에서 도로 요소의 제1 시멘틱 정보 및 포인트 클라우드 정보에 대해 매칭 처리를 수행하면 상기 도로 요소의 3차원 위치 정보 및 속성 정보를 획득할 수 있다. 이렇게 획득된 지도 중 도로 요소는 3차원 위치 정보 및 속성 정보를 가 지며, 지도 중 도로 요소의 정확도를 크게 향상시킨다. S104 단계: 상기 제2 시멘틱 정보를 기반으로 지도를 생성하거나 지도 중 상기 영역에 대응하는 부분을 업데이 트한다. 전술한 바와 같이, 본 발명의 실시예는 고정밀 지도를 생성하는 시나리오에 적용될 수도 있고, 고정밀 지도 중 일부 영역을 업데이트하는 시나리오에 적용될 수도 있다. 상기 생성의 시나리오에서, 전술한 단계를 거쳐 어느 한 영역의 도로 요소의 제2 시멘틱 정보를 획득한 후, 상 기 제2 시멘틱 정보에 포함된 3차원 위치 정보를 기반으로 상기 영역의 지도를 구축할 수 있으며, 상기 영역의 지도에 상기 영역 중 노면 요소의 3차원 위치 정보를 상세히 표시하는 동시에 노면 요소의 속성 정보를 상세히 표시할 수 있다. 상기 업데이트의 시나리오에서, 기존의 지도 중 어느 한 영역의 도로 요소와 상기 단계를 거쳐 획득된 도로 요 소를 비교하여, 상기 영역 중 원래의 도로 요소를 상술한 3차원 위치 정보 및 속성 정보를 포함한 도로 요소로 대체할 수 있다. 본 실시예에서, 차량 탑재 카메라를 통해 도로 환경 중 적어도 일부 영역의 이미지 정보를 수집하고, 이미지 정 보에 대해 시멘틱 분할 처리를 수행하여 영역 중 도로 요소의 2차원 위치 정보 및 속성 정보를 획득하는 동시에, 차량 탑재 레이더 센서를 통해 영역의 포인트 클라우드 정보를 동기적으로 수집한 후, 제1 시멘틱 정보 및 포인트 클라우드 정보에 대해 매칭 처리를 수행하여, 영역 중 도로 요소의 3차원 위치 정보 및 속성 정보를 획득할 수 있다. 상술한 과정에서, 차량 탑재 카메라 및 차량 탑재 레이더 센서는 차량에 설치된 서로 다른 유 형의 센서로서 동기적으로 작동하며, 서로 다른 유형의 센서에 의해 수집된 정보를 기반으로 매칭 처리를 수행 하여 영역의 지도를 직접 생성하거나 업데이트할 수 있으며, 지도 생성 또는 업데이트 과정에서의 인공 조작을 감소하거나 생략할 수 있다. 따라서, 본 실시예의 방법은 지도 구축의 고도의 자동화를 가능하게 하고, 고정밀 지도의 구축 효율을 크게 향상시킨다. 또한, 본 실시예의 방법은 제1 시멘틱 정보 및 포인트 클라우드 정보를 매칭하여 도로 요소를 나타내는 다양한 정보를 효과적인 통합을 가능하게 하여, 지도 중 도로 요소의 정확도를 크게 향상시킬 수 있다. 선택적인 실시방식에서, 아래와 같은 방식으로 상기 제1 시멘틱 정보 및 포인트 클라우드 정보에 대해 매칭 처 리를 수행할 수 있다. 도 2는 본 발명의 실시예에 의해 제공된 지도 구축 방법의 개략적인 흐름도 2이며, 도 2에 도시된 바와 같이, 상기 S103 단계의 선택적인 실시과정은 아래의 단계들을 포함한다. S201 단계: 상기 포인트 클라우드 정보에 대해 3차원 좌표계에서 2차원 좌표계로의 좌표계 전환을 수행하여, 상 기 제1 시멘틱 정보가 위치한 좌표계에서 상기 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득할 수 있다. 선택적으로, 차량 탑재 센서에 의해 수집된 원시의 포인트 클라우드 정보는 레이더 좌표계에서의 데이터이고, 수집된 포인트 클라우드 정보에 따라 선별 처리를 수행하여 포인트 클라우드 정보를 획득하기 전에, 먼저 NED(North East Down) 좌표계에서의 데이터를 획득할 수 있다. 즉, 선택적으로, 상기 포인트 클라우드 정보는 NED 좌표계에서의 포인트 클라우드 정보일 수 있다. NED 좌표계는 북축, 동축 및 지축을 포함하며, 북축은 지구 북쪽을 가리키고, 동축은 지구 동쪽을 가리키며, 지축은 지구 표면에 수직하여 아래를 가리킨다. 선택적으로, 상기 제1 시멘틱 정보는 차량 탑재 카메라에 의해 수집된 영상을 처리하여 획득된 것이고, 차량 탑 재 카메라에 의해 수집된 데이터는 픽셀 좌표계에서의 데이터이다. 픽셀 좌표계는 이미지 좌표계라고 칭할 수도 있으며, 픽셀 좌표계는 차량 탑재 카메라에 의해 수집된 이미지의 좌상단을 원점으로 하는 2차원 좌표계이다. 선택적으로, 상기 포인트 클라우드 정보가 상기 NED 좌표계에서의 데이터이고 상기 제1 시멘틱 정보가 픽셀 좌 표계에서의 좌표이면, 상기 포인트 클라우드 정보를 NED 좌표계에서 픽셀 좌표계로 전환하여 픽셀 좌표계에서의 상기 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득할 수 있다. 해당 과정을 거쳐, 포인트 클라우 드 정보의 NED 좌표계로부터 픽셀 좌표계로의 투영을 구현한다. 아래의 어느 한 방식으로 상기 포인트 클라우드 정보를 NED 좌표계에서 픽셀 좌표계로 전환할 수 있다. 제1 방식은, 먼저 포인트 클라우드 정보를 NED 좌표계에서 IMU 좌표계로 전환하여 상기 IMU 좌표계에서 포인트 클라우드 정보의 정보를 획득한 후, IMU 좌표계와 카메라 좌표계의 회전 및 평행 이동 매트릭스에 따라, IMU 좌 표계에서 포인트 클라우드 정보의 정보를 카메라 좌표계로 전환하여, 카메라 좌표계에서 포인트 클라우드 정보 의 정보를 획득하고, 카메라의 파라미터 매트릭스에 따라, 카메라 좌표계에서 포인트 클라우드 정보의 정보를 픽셀 좌표계로 전환하여, 픽셀 좌표계에서 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득한다. 제2 방식은, 먼저 포인트 클라우드 정보를 NED 좌표계에서 레이더 좌표계로 전환하여 레이더 좌표계에서 포인트 클라우드 정보의 정보를 획득한 후, 레이더 좌표계와 카메라 좌표계의 회전 및 평행 이동 매트릭스에 따라, 레 이더 좌표계에서 포인트 클라우드 정보의 정보를 카메라 좌표계로 전환하여, 카메라 좌표계에서 포인트 클라우 드 정보의 정보를 획득하고, 카메라의 파라미터 매트릭스에 따라, 카메라 좌표계에서 포인트 클라우드 정보의 정보를 픽셀 좌표계로 전환하여, 픽셀 좌표계에서 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득 한다. 설명할 것은, 상술한 두 가지 방식에서 언급한 카메라 좌표계는 상술한 차량 탑재 카메라의 초점 중심을 원점으 로 하고 광축을 Z축으로 하여 형성된 좌표계를 가리킨다. 상술한 제2 방식에서 언급한 카메라의 파라미터 매트 릭스는 상술한 차량 탑재 카메라의 파라미터 매트릭스를 가리킨다. 상기 포인트 클라우드 정보가 NED 좌표계에서의 정보이고 제1 시멘틱 정보가 픽셀 좌표계에서의 정보인 것을 제 외하고, 본 발명의 실시예에서, 포인트 클라우드 정보는 다른 3차원 좌표계에서의 정보일 수도 있으며, 상기 제 1 시멘틱 정보는 다른 2차원 좌표계에서의 정보일 수도 있고, 좌표계 전환을 통해 포인트 클라우드 정보를 제1 시멘틱 정보가 위치한 좌표계로 투영할 수도 있다. S202 단계: 상기 포인트 클라우드 2차원 정보 및 상기 도로 요소의 2차원 위치 정보에 대해 매칭 처리를 수행하 여, 상기 영역의 지도 중 상기 도로 요소의 제2 시멘틱 정보를 획득한다. 포인트 클라우드 정보를 제1 시멘틱 정보가 위치한 좌표계에서의 포인트 클라우드 2차원 정보에 투영한 후, 포 인트 클라우드 2차원 정보와 제1 시멘틱 정보 중 2차원 위치 정보는 동일한 좌표계에 위치한다. 따라서, 동일한 좌표계에서 포인트 클라우드 2차원 정보 및 제1 시멘틱 정보 중 2차원 위치 정보에 대해 매칭 처리를 수행하여, 도로 요소의 제2 시멘틱 정보를 획득할 수 있다. 본 실시예에서, 포인트 클라우드 정보에 대해 좌표 전환을 수행하여 포인트 클라우드 정보를 제1 시멘틱 정보의 좌표계에 투영한 후, 동일한 좌표계에서 포인트 클라우드 2차원 정보 및 제1 시멘틱 정보 중 2차원 위치 정보에 대해 매칭 처리를 수행함으로써, 포인트 클라우드 정보와 제1 시멘틱 정보 중 2차원 위치 정보의 매칭 결과의 정확도가 크게 향상된다. 선택적인 실시방식으로서, 아래와 같은 방식으로 상술한 포인트 클라우드 2차원 정보와 제1 시멘틱 정보 중 2차 원 위치 정보에 대해 매칭 처리를 수행할 수 있다.도 3은 본 발명의 실시예에 의해 제공된 지도 구축 방법의 개략적인 흐름도 3이다. 도 3에 도시된 바와 같이, 상기 S202 단계에서 포인트 클라우드 2차원 정보와 제1 시멘틱 정보 중 2차원 위치 정보에 대해 매칭 처리를 수 행하는 한 선택적인 방식은 아래의 단계들을 포함한다. S301 단계: 상기 도로 요소의 2차원 위치 정보에 따라, 상기 포인트 클라우드 2차원 정보 중 각 픽셀이 상기 도 로 요소에 속하는지 여부를 결정한다. 전술한 바와 같이, 도로 요소의 제1 시멘틱 정보는 차량 탑재 카메라에 의해 수집된 이미지를 처리하여 획득할 수 있으며, 처리할 때, 특정된 방식에 따라 이미지 중 하나 이상의 이미지 프레임을 선택하고, 각 이미지 프레 임에 대해, 이미지의 시멘틱 분할 처리를 통해, 이미지로부터 도로 요소를 분할할 수 있다. 도로 요소를 분할한 후, 이미지 중 각 픽셀이 도로 요소에 속하는지 여부를 알 수 있으며, 도로 요소에 속하는 각 픽셀은 모두 특정 된 2차원 위치 정보를 가지며, 상기 2차원 위치 정보는 2차원 좌표치일 수 있다. 따라서, 본 단계에서, 포인트 클라우드 2차원 정보에서 각 픽셀은 특정된 2차원 위치 정보를 가진다. 선택적으 로, 픽셀 단위로 포인트 클라우드 2차원 정보 중 각 픽셀을 트래버스하여 각 픽셀이 도로 요소 중 픽셀인지 여 부를 판단할 수 있으며, 도로 요소 중 픽셀이면, 상기 포인트 클라우드 2차원 정보 중 픽셀이 도로 요소 중 픽 셀인 것으로 판단한다. 예시적으로, 포인트 클라우드 2차원 정보에 픽셀(x1, y1)이 존재하면, 해당 픽셀에 대하여, 상기 포인트 클라우 드 2차원 정보에 대응하는, 차량 탑재 카메라에 의해 수집된 이미지 프레임에서 픽셀(x1, y1)이 도로 요소 중 픽셀인지를 판단하며, 도로 요소 중 픽셀이면, 포인트 클라우드 2차원 정보 중 픽셀(x1, y1)이 상기 도로 요소 에 속하는 것으로 결정할 수 있다. 설명할 것은, 본 발명의 실시예에서, 매칭 처리를 수행하는 도로 요소의 제1 시멘틱 정보 및 포인트 클라우드 정보는 동일한 물리적 위치에 대한 정보이다. 예를 들어, 모두 도시 내 어느 한 특정 도로의 정보이다. 따라서, 선택적인 실시방식으로서, 각 센서는 데이터를 동시에 수집하고 수집된 데이터에 타임 스템프 정보를 추가할 수 있으며, 각 센서에 의해 수집된 데이터를 처리할 때, 처리 결과에 상기 타임 스템프 정보를 보류할 수 있다. 따 라서, 본 발명의 실시예에서 매칭을 수행할 때 타임 스템프가 동일한 포인트 클라우드 정보와 제1 시멘틱 정보 를 선택하여 상술한 매칭 처리를 수행할 수 있다. 예를 들어, 상술한 실예에서, 포인트 클라우드 정보에 대응하 는 차량 탑재 카메라에 의해 수집된 이미지 프레임은 타임 스템프가 포인트 클라우드 2차원 정보가 속한 포인트 클라우드 정보의 타임 스템프와 동일한 이미지 프레임일 수 있다. S302 단계: 상기 포인트 클라우드 2차원 정보 중 제1 픽셀이 상기 도로 요소에 속하는 것에 응답하여, 상기 제1 픽셀이 상기 포인트 클라우드 정보에서의 3차원 위치 정보 및 상기 제1 픽셀이 상기 제1 시멘틱 정보에서의 속 성 정보를 획득하여, 상기 제1 픽셀의 3차원 위치 정보 및 속성 정보를 획득한다. 상기 제1 픽셀은 상기 포인트 클라우드 2차원 정보 중 어느 한 픽셀을 가리킬 수 있다. 상기 제1 픽셀은 포인트 클라우드 정보가 위치한 3차원 좌표계에서 제1 시멘틱 정보가 위치한 2차원 좌표계로 투영한 후 획득된 픽셀이 다. 따라서, 상기 제1 픽셀은 3차원 좌표계에서의 하나의 3차원 위치 정보에 유일하게 대응할 수 있다. 따라서, 상기 제1 픽셀이 상기 도로 요소에 속하는 것을 결정한 경우, 상기 제1 픽셀의 3차원 위치 정보 및 속성 정보를 동시에 획득할 수 있다. 상기 처리 과정을 거친 후, 지도 내 도로 요소 중 각 픽셀은 3차원 위치 정보뿐만 아니 라 속성 정보도 가지므로 고정밀 지도 중 도로 요소의 정보를 획득한다. 본 실시예에서, 먼저 도로 요소의 2차원 위치 정보에 따라 포인트 클라우드 2차원 정보 중 각 픽셀이 도로 요소 에 속하는지 여부를 결정하며, 픽셀이 도로 요소에 속하는 경우, 지도 중 상기 픽셀의 3차원 위치 정보 및 속성 정보를 동시에 획득할 수 있으며, 이에 따라 고정밀 지도 중 도로 요소의 정보를 획득할 수 있다. 구체적인 실시 과정에서, 차량 탑재 레이더 센서는 복수의 시각에 데이터를 수집하며, 하나의 수집 시각에 전방 노면의 포인트 클라우드 정보, 주변 나무의 포인트 클라우드 정보, 집의 포인트 클라우드 정보 등과 같은 차량 주변 환경의 다양한 포인트 클라우드 정보를 수집할 수 있다. 본 발명의 실시예는 제1 시멘틱 정보에 대응하는 시각의 포인트 클라우드 정보를 획득하고 전술한 방법에 따라 매칭 처리를 수행하기만 하면 된다. 따라서, 선택 적인 실시방식으로서, 상기 영역의 이미지 정보 및 포인트 클라우드 정보를 획득할 때, 차량 탑재 내비게이션 시스템을 통해 상기 차량의 포즈 정보를 획득하고; 차량의 포즈 정보에 따라, 상기 차량 탑재 레이더 센서에 의 해 수집된 포인트 클라우드 정보로 구성된 포인트 클라우드 정보 집합 중에서 상기 영역의 포인트 클라우드 정 보를 선별할 수 있다. 구체적으로, 전술한 바와 같이, 차량의 센서가 정보를 수집하는 시각마다, 차량은 특정 포즈를 취한다. 전술한 바와 같이, 차량 탑재 카메라 및 차량 탑재 레이더 센서가 정보를 수집하는 동시에, GPS, IMU 등 센서를 통해 차량의 포즈를 획득할 수 있다. 본 실시예에서, 제1 시멘틱 정보 중 2차원 위치 정보에 대응하는 타임 스템프를 기준으로, 상기 타임 스템프에 대응하는 시각의 차량 포즈를 검색할 수 있다. 차량의 포즈를 통해, 상기 시각에 서 차량의 방향을 획득할 수 있다. 따라서, 포인트 클라우드 정보 집합에서만 상기 방향에서 차량 전방 기설정 된 범위 내의 포인트 클라우드 정보를 선택할 수 있다. 상기 기설정된 범위는 예를 들어 기설정된 크기의 직사 각형 블록일 수 있으며, 상기 기설정된 범위 내에는 예를 들어 차량 전방 노면의 포인트 클라우드 정보를 포함 할 수 있다. 상기 포인트 클라우드 정보 집합은 차량 탑재 레이더 센서에 의해 수집된 대량의 포인트 클라우드 정보를 처리 한 후 형성된 포인트 클라우드 정보의 집합일 수 있으며, 상기 집합 중 포인트 클라우드 정보는 복수 개의 영역 중 노면의 포인트 클라우드 정보 외에, 복수 개의 영역 중 차량 주변의 나무, 집, 고가교와 같은 환경의 포인트 클라우드 정보도 포함할 수 있다. 본 실시예에서, 차량 포즈에 따라 포인트 클라우드 정보를 선별하고, 후속 매칭 처리에서 선별된 포인트 클라우 드 정보만 사용하여 매칭하므로, 매칭 처리 시의 처리 시간을 크게 단축하고, 무효 매칭 처리 과정을 피하며, 매칭 처리의 효율을 크게 향상시킬 수 있다. 선택적인 실시방식으로서, 상기 사전 저장된 포인트 클라우드 정보 집합 중에서 상기 영역의 포인트 클라우드 정보를 선별하기 전에, 복수 개의 영역에 대응하는 주행 가능 영역(FreeSpace)의 정보에 따라, 차량 탑재 레이 더 센서에 의해 수집된 복수 개의 영역의 포인트 클라우드 정보에 대해 선별 및 스플라이싱을 수행하여, 상기 포인트 클라우드 정보 집합을 획득할 수도 있다. 상기 주행 가능 영역 정보는 포인트 클라우드 정보와 동일한 시각에 수집된 이미지에 대해 분할 처리를 수행하 여 획득될 수 있다. 선택적으로, 수집된 이미지 정보에 대해 주행 가능 영역 검출을 수행하여, 영역 내의 주행 가능 영역의 정보를 획득할 수 있다. 차량 탑재 레이더 센서에 의해 수집된 복수 개의 영역의 포인트 클라우드 정보는 주행 가능 영역의 포인트 클라우드 정보를 포함할 뿐만 아니라 주행 가능 영역 주변의 나무, 집, 고가교 와 같은 환경의 포인트 클라우드 정보도 포함할 수 있다. 포인트 클라우드 정보 집합을 구성하기 전에 먼저 차 량 탑재 레이더 센서에 의해 수집된 각 영역의 포인트 클라우드 정보에서 각 영역 내의 주행 가능 영역의 포인 트 클라우드 정보를 선별하고, 이들 포인트 클라우드 정보만 저장하고 포인트 클라우드 정보 집합을 구성한 후, 후속 매칭 처리 과정에서는 주행 가능 영역의 포인트 클라우드 정보와 제1 시멘틱 정보만 매칭하면 되므로, 무 효 매칭 처리를 피하고 매칭 처리의 효율성을 크게 향상시킬 수 있다. 이하, 주행 가능 영역의 정보에 따라, 포인트 클라우드 정보에 대해 선별 및 스플라이싱을 수행하는 과정을 설 명한다. 도 4는 본 발명의 실시예에 의해 제공된 지도 구축 방법의 개략적인 흐름도 4이다. 도 4에 도시된 바와 같이, 주행 가능 영역의 정보에 따라, 포인트 클라우드 정보에 대해 선별 및 스플라이싱을 수행하는 과정은 아래의 단 계들을 포함한다. S401 단계: 수집된 각 영역의 이미지 정보에 대해 주행 가능 영역 검출을 수행하여, 각 영역 내의 주행 가능 영 역의 정보를 획득한다. 각 영역 내의 주행 가능 영역의 정보를 획득하는 동시에, 차량 탑재 레이더 센서에 의해 수집된 모든 포인트 클 라우드 정보 및 각 시각에서 차량의 포즈 정보를 획득한다. 차량 탑재 레이더 센서에 의해 수집된 모든 포인트 클라우드 정보는 차량 탑재 레이더 센서가 복수 개의 시각에 수집한 포인트 클라우드 정보를 가리키며, 각 시각에서, 카메라는 한 프레임의 이미지를 수집하고, 차량 탑재 레이더 센서는 대응하는 포인트 클라우드 정보를 수집하고, GPS 또는 IMU는 차량의 포즈 정보를 획득한다. 복수 개의 시각에 수집한 정보는 복수 개의 영역의 정보를 포함한다. S402 단계: 차량 탑재 레이더 센서에 의해 수집된 각 영역의 포인트 클라우드 정보에서 각 영역 내의 주행 가능 영역의 포인트 클라우드 정보를 선별한다. 선택적으로, 각 영역 내의 주행 가능 영역의 정보를 획득한 것에 기초하여, 이미지와 동일한 시각에 수집된 포 인트 클라우드 정보에 대해 좌표 전환을 수행하여, 포인트 클라우드 정보를 이미지가 위치한 좌표계에 투영하고 포인트 클라우드 정보가 투영된 후의 2차원 포인트 중 어느 것이 주행 가능 영역에 속하는지 판단하여, 주행 가능 영역에 속하는 2차원 포인트에 대응하는 포인트 클라우드 정보만을 보류한다. 상기 S103 단계의 매칭 처리를 수행하여 지도 중 고정밀 도로 요소를 생성하거나 업데이트할 때 주행 가능 영역 외의 정보를 관계할 필요가 없 으므로, 본 단계에서 주행 가능 영역에 따라 포인트 클라우드 정보를 선별하고 주행 가능 영역에 대응하는 포인 트 클라우드 정보만 보류한다. 이러한 처리를 통해, 후속 매칭 처리 시 완정하고 정확한 도로 요소의 3차원 위 치 정보를 획득할 수 있도록 보장하면서, 포인트 클라우드 정보의 저장량을 최대 한도로 감소할 수 있고, 매칭 처리 시 무효한 처리 과정을 감소하여 매칭 처리의 효율을 크게 향상시킨다. 복수 개의 이미지 프레임에 대해 각각 상술한 처리를 수행한 후, 복수 개의 영역의 주행 가능 영역의 포인트 클 라우드 정보를 획득할 수 있다. S403 단계: 각 영역 내의 주행 가능 영역의 포인트 클라우드 정보를 스플라이싱하여 상기 포인트 클라우드 정보 집합을 획득한다. 선택적으로, 상술한 S402~S403 단계는 이미지 프레임별로 선별 및 저장할 수 있다. 한 프레임의 이미지에 대응 하는 영역의 주행 가능 영역의 정보를 획득할 때마다, 해당 이미지를 수집하는 시각에 수집된 포인트 클라우드 정보에 대해 선별을 수행하여, 해당 시각에 대응하는 영역의 포인트 클라우드 정보를 획득한다. 따라서, 차량이 해당 시각에서의 포즈에 따라, 획득된 해당 포인트 클라우드 정보를 레이더 좌표계에서 NED 좌표계로 전환한다. 따라서, 상기 전환된 포인트 클라우드 정보의 색인을 만들고 저장한다. 다음 시각에 대응하는 영역의 다음 포인 트 클라우드 정보를 획득한 후, 상기 다음 포인트 클라우드 정보의 색인을 만들고 저장한다. 복수 개의 영역의 포인트 클라우드 정보의 저장을 완료한 후 획득된 것은 바로 포인트 클라우드 정보 집합이다. 두 개의 연속된 영역의 색인은 연속될 수 있다. 따라서, 포인트 클라우드 정보를 저장할 때 포인트 클라우드 정보의 스플라이싱 을 완료하여, 모든 영역의 포인트 클라우드 정보를 획득하며, 이러한 포인트 클라우드 정보는 포인트 클라우드 정보 집합을 구성한다. 상술한 S401-S403 단계의 선택적인 방식에서, 포인트 클라우드 정보 집합을 생성할 때, 저장된 포인트 클라우드 정보 집합 중 포인트 클라우드 정보가 주행 가능 영역의 포인트 클라우드 정보만 특징화하도록, 포인트 클라우 드 정보에 대해 먼저 주행 가능 영역에 따라 선별하며, 이에 따라 매칭 시 포인트 클라우드 정보의 저장량을 감 소하고 매칭 처리 효율을 향상시킬 수 있다. 다른 선택적인 실시방식으로서, 포인트 클라우드 정보 집합을 생성할 때, 주행 가능 영역에 따라 선별하지 않고, 상술한 S401단계를 수행한 후 바로 모든 포인트 클라우드 정보에 대해 좌표 전환을 수행하고 색인에 따라 저장할 수 있다. 이러한 방식에서, 포인트 클라우드 정보 집합 중 포인트 클라우드 정보는 주행 가능 영역의 정 보를 특징화할 수 있을 뿐만아니라, 차량 주변의 나무, 집, 고가교와 같은 주행 가능 영역 외의 정보를 특징화 할 수도 있다. 상기 방식을 기반으로, 상술한 S101단계에 수집된 포인트 클라우드 정보는 상술한 두 가지 정보 를 특징화할 수 있다. 따라서, 상술한 S202단계에서 상기 포인트 클라우드 정보를 전환하여 획득된 포인트 클라 우드 2차원 정보 및 도로 요소의 2차원 위치 정보에 대해 매칭 처리를 수행할 때, 아래와 같은 과정에 따라 처 리할 수 있다. 상기 이미지 정보에 대해 주행 가능 영역의 검출을 수행하여 상기 영역 내의 주행 가능 영역의 정보를 획득하고; 상기 포인트 클라우드 2차원 정보 중 제2 픽셀이 영역 내의 주행 가능 영역 중 픽셀인지 여부를 판단 하며, 상기 포인트 클라우드 2차원 정보 중 제2 픽셀이 영역 내의 주행 가능 영역 중 픽셀인 것에 응답하여, 상 기 제2 픽셀 및 도로 요소의 2차원 위치 정보에 대해 매칭 처리를 수행하여, 상기 영역의 지도 중 도로 요소의 제2 시멘틱 정보를 획득한다. 상기 제2 픽셀은 포인트 클라우드 2차원 정보 중 어느 한 픽셀을 가리킬 수 있다. 제2 픽셀이 영역 내의 주행 가능 영역 중 픽셀인지 여부를 판단할 때, 제2 픽셀의 좌표가 주행 가능 영역 내에 있는지 여부를 직접 판단할 수 있으며, 있다고 판단되면, 제2 픽셀이 주행 가능 영역 중 픽셀임을 결정할 수 있 다. 따라서, 포인트 클라우드 2차원 정보 중 주행 가능 영역 내에 속하는 픽셀만을 도로 요소의 2차원 위치 정 보와 매칭 처리하여, 영역 중 도로 요소의 3차원 위치 정보 및 속성 정보를 결정할 수 있다. 상기 방식에서, 포인트 클라우드를 처리하여 포인트 클라우드 정보 집합을 획득할 때, 포인트 클라우드 정보 집 합 중 포인트 클라우드 정보는 주행 가능 영역 및 차량 주변 환경 중 다른 물체의 정보를 포함하며, 매칭 처리 를 수행할 때, 포인트 클라우드 정보의 포인트 클라우드 2차원 정보에 대해 주행 가능 영역에 따라 선별한다. 이러한 방식은 완정한 포인트 클라우드 정보를 저장하였으므로, 일부 노면에 의거해야 하는 주행 가능 영역 외 의 정보를 처리하는 시나리오에서, 상기 방식을 이용하여 효과적인 처리를 수행하여 정확한 처리 결과를 획득할수 있다. 상기 선택적인 방식에서, 주행 가능 영역의 정보는 상기 영역에 대응하는 한 프레임의 이미지에 대해 이미지의 시멘틱 분할을 수행하여 획득될 수 있다. 상기 영역에 대응하는 한 프레임의 이미지의 이미지 시멘틱 분할 결과 에서, 상기 제1 시멘틱 정보, 즉 도로 요소의 2차원 위치 정보 및 속성 정보를 포함할 뿐만 아니라, 주행 가능 영역의 정보도 포함할 수 있다. 이하, 이미지 시멘틱 분할을 수행하여 상기 제1 시멘틱 정보 및 주행 가능 영역의 정보를 획득하는 과정에 대해 설명한다. 도 5는 본 발명의 실시예에 의해 제공된 지도 구축 방법의 개략적인 흐름도 5이다. 도 5에 도시된 바와 같이, 이미지를 분할하여 상기 제1 시멘틱 정보 및 주행 가능 영역의 정보를 획득하는 과정은 아래의 단계들을 포함한 다. S501 단계: 차량 탑재 카메라에 의해 수집된 이미지 정보에 대해 프레임 분할 처리를 수행하여 복수 개의 이미 지 프레임을 획득한다. S502 단계: 각 이미지 프레임에 대해 시멘틱 분할 처리를 수행하여, 도로 요소의 분할 결과, 도로 요소의 속성 정보 및 주행 가능 영역의 분할 결과를 획득한다. 도로 요소의 분할 결과는 이미지 프레임 중 각 픽셀이 도로 요소에 속하는지 여부를 포함하고, 도로 요소의 속 성 정보는 도로 요소에 속하는 픽셀의 속성 정보를 포함한다. 예를 들어, 도로 요소가 차선인 경우, 도로 요소 에 속하는 픽셀의 어느 한 속성 정보는 색상 및/또는 선형 등 정보(예를 들어, 흰 실선 등)를 포함할 수 있고, 주행 가능 영역의 분할 결과는 이미지 프레임 중 각 픽셀이 주행 가능 영역에 속하는지 여부를 포함한다. 선택적인 방식으로서, 신경망을 기반으로 시멘틱 분할 처리를 수행할 수 있다. 상기 신경망은 예를 들어 컨볼루 션 신경망, 비 컨볼루션 다층 신경망 등일 수 있다. 상기 신경망은 해당 요소에 대해 분할 처리를 수행하는 능력을 구비하며, 상기 신경망을 사용하여 시멘틱 분할 처리를 수행하기 전에, 해당 요소의 마킹 정보가 포함된 훈련 샘플 이미지 집합을 사전에 적용하여 감독 또는 반감독의 방식으로 상기 신경망을 훈련할 수 있다. S503 단계: 상기 도로 요소의 분할 결과에 대해 클러스터링 처리를 수행하여, 각 이미지 프레임 중 각 도로 요 소의 정보를 획득한다. 획득된 각 도로 요소의 정보는 도로 요소 중 각 픽셀의 2차원 위치 정보 및 속성 정보를 포함한다. S504 단계: 상기 도로 요소 중 각 픽셀의 2차원 위치 정보, 속성 정보 및 이미지 중 주행 가능 영역의 정보를 저장한다. 상술한 정보를 획득한 후, 이러한 정보를 기반으로, 전술한 실시예에 따른 처리 과정을 수행할 수 있다. 전술한 과정을 거쳐 영역 중 도로 요소의 3차원 위치 정보 및 속성 정보를 획득한 후, 영역 지도를 생성하거나 지도 중 대응하는 영역의 부분을 업데이트할 때, 먼저 아래와 같은 적어도 한 방식을 수행하여 획득된 정보에 대해 후처리를 수행하고, 후처리를 거친 도로 요소의 제2 시멘틱 정보를 사용하여 지도를 생성하거나 지도 중 대응하는 영역의 부분을 업데이트할 수 있다. 제1 방식에서, 상기 도로 요소에 대응하는 기설정된 특징 정보에 따라, 영역의 지도 중 도로 요소를 선별하여 선별된 도로 요소를 획득한다. 상기 기설정된 특징 정보는 도로 요소 고유의 특징이다. 전술한 과정을 거쳐 도로 요소의 3차원 위치 정보 및 속성 정보를 획득한 후, 도로 요소의 3차원 위치 정보 및/또는 속성 정보가 도로 요소의 기설정된 특징에 부합 하는지 여부를 판단할 수 있으며, 부합하지 않으면, 지도에서 상기 도로 요소를 삭제할 수 있다. 상기 처리 과 정을 거쳐, 잘못된 도로 요소를 제거할 수 있으며, 지도의 정확도를 더욱 향상시킨다. 제2 방식에서, 상기 3차원 위치 정보로 특징화되는 도로 요소 중 포인트에 대해 피팅(fitting) 처리를 수행하여, 선 파라미터로 특징화되는 도로 요소를 획득한다. 전술한 처리를 거쳐 획득된 도로 요소는 대량의 포인트들로 특징화될 수 있으며, 각 포인트는 모두 3차원 위치 정보 및 속성 정보를 가진다. 상기 방식에서, 이러한 포인트들에 대해 피팅을 수행하여 선 파라미터로 특징화되 는 도로 요소를 피팅할 수 있다. 상기 선 파라미터는 선의 방정식, 선의 시작점 위치 및 선의 종점 위치를 포함할 수 있다. 또한, 동일한 도로 요소에 속하는 포인트의 속성 정보는 동일하고, 피팅된 도로 요소의 속성 정보 는 피팅 전 각 포인트 중 어느 한 포인트의 속성 정보일 수 있다. 상기 처리를 거친 후, 몇몇 선 파라미터만으 로 지도 중 고정밀 도로 요소를 표시할 수 있으며, 이에 따라 도로 요소의 저장량을 크게 감소하고, 지도를 사 용하여 운전 제어 등 조작을 수행할 때에도 조작 효율을 크게 향상시킬 수 있다. 제3 방식에서, 상기 도로 요소에 대해 샘플링 처리를 수행하여, 샘플링된 도로 요소를 획득한다. 전술한 방법을 거쳐 획득된 도로 요소에서, 도로 요소를 구성하는 포인트의 수량이 엄청나다. 일부 시나리오에 서, 예를 들어, 처리 속도 요구가 높은 시나리오에서, 도로 요소를 샘플링할 수 있으며, 샘플링 후, 도로 요소 의 정확도가 시나리오 요구 사항을 충족하도록 보장하면서, 도로 요소의 포인트의 수량을 크게 감소시킬 수 있 고, 지도를 사용하여 운전 제어 등 조작을 수행할 때, 조작 처리의 속도를 크게 향상시킬 수 있다. 설명할 것은, 구체적인 실시과정에서, 상기 상술한 방식 중 하나를 선택하는 것은 상술한 방식 중 복수 개를 동 시에 선택할 수도 있다. 즉 상술한 방식은 결합되어 실시될 수 있으며, 본 발명의 실시예는 이에 대해 구체적으 로 한정하지 않는다. 일부 시나리오에서, 본 발명의 실시예에 따른 방식으로 획득된 지도와 다른 방식으로 획득된 지도를 통합하여 사용해야 할 수 있으며, 서로 다른 방식으로 획득된 지도가 기반으로 하는 좌표계는 서로 다를 수 있다. 예를 들어, 본 발명의 실시예에서, 포인트 클라우드 정보는 NED 좌표계에서의 정보이면, 획득된 지도 중 도로 요소의 3차원 위치 정보는 NED 좌표에서의 위치 정보이다. 위치 정보가 세계 지구 좌표계-84(World Geodetic System- 84, WGS84)에서의 정보인 다른 지도가 있으면, 두 지도는 직접 통합하여 사용할 수 없다. 따라서, 선택적으로, 전술한 과정을 거쳐 획득된 3차원 위치 정보를 NED 좌표계에서 다른 지도에 대응하는 목표 좌표계로 전환하여, 목표 좌표계에서 3차원 위치 정보의 위치 정보를 획득할 수 있다. 상기 처리를 거친 후, 서로 다른 지도 간의 통합 사용을 구현할 수 있다. 도 6은 본 발명의 실시예에 의해 제공된 지도 생성 장치의 모듈 구성도 1이며, 도 6에 도시된 바와 같이, 상기 장치는 차량 탑재 카메라를 통해 차량이 위치한 도로 환경의 적어도 일부 영역의 이미지 정보를 획득하고, 차량 탑재 레이더 센서를 통해 상기 차량이 위치한 도로 환경의 적어도 일부 영역의 이미지 정보 및 포인트 클라우드 정보 를 동기적으로 대응하여 획득하는 수집 모듈; 상기 이미지 정보에 대해 시멘틱 분할 처리를 수행하여 상기 영역 중 도로 요소의 제1 시멘틱 정보를 획득하는 분할 모듈 - 상기 제1 시멘틱 정보는 상기 도로 요소의 2차원 위치 정보 및 속성 정보를 포함함 - ; 상기 영역 중 도로 요소의 제1 시멘틱 정보 및 상기 영역의 포인트 클라우드 정보에 대해 매칭 처리를 수행하여, 상기 영역 중 도로 요소의 제2 시멘틱 정보를 획득하는 매칭 모듈 - 상기 제2 시멘틱 정보는 상 기 도로 요소의 3차원 위치 정보 및 속성 정보를 포함함 - ; 상기 제2 시멘틱 정보를 기반으로 지도를 생성하거나 지도 중 상기 영역에 대응하는 부분을 업데이트하는 생성 모듈을 포함한다. 상기 장치는 전술한 방법 실시예의 기술적 방안을 구현하며, 그 구현 원리 및 기술적 효과는 유사하므로, 여기 서 더 설명하지 않는다. 도 7은 본 발명의 실시예에 의해 제공된 지도 생성 장치의 모듈 구성도 2이며, 도 7에 도시된 바와 같이, 매칭 모듈은 상기 포인트 클라우드 정보에 대해 3차원 좌표계에서 2차원 좌표계로의 좌표계 전환을 수행하여, 상기 2차원 위 치 정보가 위치한 좌표계에서 상기 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득하는 전환 유닛 ; 상기 포인트 클라우드 2차원 정보 및 상기 도로 요소의 2차원 위치 정보에 대해 매칭 처리를 수행하여, 상기 영 역 중 상기 도로 요소의 제2 시멘틱 정보를 획득하는 매칭 유닛을 포함한다. 다른 실시예에서, 매칭 유닛은, 상기 도로 요소의 2차원 위치 정보에 따라, 상기 포인트 클라우드 2차원 정보 중 각 픽셀이 상기 도로 요소에 속하는지 여부를 결정하고; 상기 포인트 클라우드 2차원 정보 중 제1 픽셀 이 상기 도로 요소에 속하는 것에 응답하여, 상기 제1 픽셀이 상기 포인트 클라우드 정보에서의 3차원 위치 정 보 및 상기 제1 픽셀이 상기 제1 시멘틱 정보에서의 속성 정보를 획득하여, 상기 제1 픽셀의 3차원 위치 정보및 속성 정보를 획득하며; 상기 제1 픽셀은 상기 포인트 클라우드 2차원 정보 중 어느 한 픽셀이다. 다른 실시예에서, 전환 유닛은 상기 포인트 클라우드 정보를 NED 좌표계에서 픽셀 좌표계로 전환하여 상 기 픽셀 좌표계에서 상기 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득하며, 상기 2차원 위치 정 보는 상기 픽셀 좌표계에서의 정보이다. 다른 실시예에서, 전환 유닛은, 상기 포인트 클라우드 정보를 NED 좌표계에서 관성 측정 유닛 좌표계로 전환하여 상기 관성 측정 유닛 좌표계에서 상기 포인트 클라우드 정보의 정보를 획득하고; 상기 관성 측정 유닛 좌표계와 카메라 좌표계의 회전 및 평행 이동 매트릭스에 따라, 상기 관성 측정 유닛 좌표계에서 상기 포인트 클라우드 정보의 정보를 상기 카메라 좌표계로 전환하여, 상기 카메라 좌표계에서 상기 포인트 클라우드 정보의 정보를 획득하고; 카메라의 파라미터 매트릭스에 따라, 상기 카메라 좌표계에서 상기 포인트 클라우드 정보의 정보를 상기 픽셀 좌표계로 전환하여, 상기 픽셀 좌표계에서 상기 포인트 클라우드 정보의 포인트 클라우드 2차 원 정보를 획득한다. 다른 실시예에서, 전환 유닛은, 상기 포인트 클라우드 정보를 NED 좌표계에서 레이더 좌표계로 전환하여 상기 레이더 좌표계에서 상기 포인트 클라우드 정보의 정보를 획득하고; 상기 레이더 좌표계와 카메라 좌표계의 회전 및 평행 이동 매트릭스에 따라, 상기 레이더 좌표계에서 상기 포인트 클라우드 정보의 정보를 상기 카메라 좌표계로 전환하여, 상기 카메라 좌표계에서 상기 포인트 클라우드 정보의 정보를 획득하고; 카메라의 파라미터 매트릭스에 따라, 상기 카메라 좌표계에서 상기 포인트 클라우드 정보의 정보를 상기 픽셀 좌표계로 전환하여, 상기 픽셀 좌표계에서 상기 포인트 클라우드 정보의 포인트 클라우드 2차원 정보를 획득한다. 다른 실시예에서, 매칭 유닛은, 상기 이미지 정보에 대해 주행 가능 영역의 검출을 수행하여 상기 영역 내의 주행 가능 영역의 정보를 획득하고; 상기 포인트 클라우드 2차원 정보 중 제2 픽셀이 상기 영역 내의 주행 가능 영역 중 픽셀인 것에 응답하여, 상기 제2 픽셀 및 상기 도로 요소의 2차원 위치 정보에 대해 매칭 처리를 수행하여, 상기 영역의 지도 중 상기 도로 요소의 제2 시멘틱 정보를 획득하며; 상기 제2 픽셀은 상기 포인트 클라우드 2차원 정보 중 어느 한 픽셀이다. 도 8은 본 발명의 실시예에 의해 제공된 지도 생성 장치의 모듈 구성도 3이며, 도 8에 도시된 바와 같이, 상기 장치는 상기 영역의 상기 이미지 정보 및 상기 포인트 클라우드 정보를 수집하는 동시에, 차량 탑재 내비게이션 시스템 을 통해 상기 차량의 포즈 정보를 획득하는 획득 모듈; 차량의 포즈 정보에 따라, 차량 탑재 레이더 센서에 의해 수집된 포인트 클라우드 정보로 구성된 포인트 클라우 드 정보 집합 중에서 상기 영역의 포인트 클라우드 정보를 선별하는 제1 선별 모듈을 더 포함한다. 도 9는 본 발명의 실시예에 의해 제공된 지도 생성 장치의 모듈 구성도 4이며, 도 9에 도시된 바와 같이, 상기 장치는 수집된 각 영역의 이미지 정보에 대해 주행 가능 영역 검출을 수행하여, 각 영역 내의 주행 가능 영역의 정보를 획득하는 검출 모듈; 차량 탑재 레이더 센서에 의해 수집된 각 영역의 포인트 클라우드 정보에서 각 영역 내의 주행 가능 영역의 포 인트 클라우드 정보를 선별하는 제2 선별 모듈; 각 영역 내의 주행 가능 영역의 포인트 클라우드 정보를 스플라이싱하여 상기 포인트 클라우드 정보 집합을 획 득하는 스플라이싱 모듈을 더 포함한다. 다른 실시예에서, 상기 차량 탑재 내비게이션 시스템은 위성 항법 시스템 및/또는 관성 측정 유닛를 포함한다. 도 10은 본 발명의 실시예에 의해 제공된 지도 생성 장치의 모듈 구성도 5이며, 도 10에 도시된 바와 같이, 생 성 모듈은 상기 도로 요소에 대응하는 기설정된 특징 정보에 따라, 상기 영역의 지도 중 상기 도로 요소를 선별하여 선별 된 도로 요소를 획득하는 처리 방식; 상기 3차원 위치 정보로 특징화되는 상기 도로 요소 중 픽셀에 대해 피팅 처리를 수행하여, 선 파라미터로 특징화되는 상기 도로 요소를 획득하는 처리 방식; 상기 도로 요소에 대해 샘 플링 처리를 수행하여, 샘플링된 상기 도로 요소를 획득하는 처리 방식; 상기 3차원 위치 정보를 상기 NED 좌표 계에서 목표 좌표계로 전환하여 상기 목표 좌표계에서 상기 3차원 위치 정보의 위치 정보를 획득하는 처리 방식 중 적어도 하나를 사용하여, 상기 도로 요소를 처리하는 처리 유닛;처리하여 획득된 상기 도로 요소의 제2 시멘틱 정보를 기반으로 지도를 생성하거나 지도 중 상기 영역에 대응하 는 부분을 업데이트하는 생성 유닛을 포함한다. 설명할 것은, 이상의 장치의 각 모듈의 구분은 단지 논리 기능적 구분이며, 실제 구현 시 전부 또는 일부를 하 나의 물리 실체에 집적하거나, 물리적으로 분리될 수도 있음을 이해해야 한다. 그리고 이러한 모듈은 모두 처리 요소에 의해 호출되는 소프트웨어의 형태로 구현될 수 있다. 또한, 모두 하드웨어의 형태로 구현될 수도 있다. 또한, 일부 모듈은 처리 요소에 의해 호출되는 소프트웨어의 형태로 구현되고, 일부 모듈은 하드웨어의 형태로 구현될 수 있다. 예를 들어, 결정 모듈은 단독으로 구비된 처리 요소일 수도 있고, 상기 장치의 어느 한 칩에 집적될 수도 있다. 또한, 프로그램 코드의 형태로 상기 장치의 메모리에 저장되어, 상기 장치의 어느 한 처리 요소에 의해 호출되어 이상의 결정 모듈의 기능을 수행할 수도 있다. 다른 모듈의 구현은 이와 유사하다. 또한, 이러한 모듈의 전부 또는 일부는 하나로 집적될 수도 있고, 독립적으로 구현될 수도 있다. 여기서 말하는 처리 요소는 신호 처리 능력을 구비한 집적 회로일 수 있다. 구현 과정에서, 상술한 방법의 각 단계 또는 이상의 각 모듈은 프로세서 요소 중 하드웨어의 집적 논리 회로 또는 소프트웨어 형태의 명령을 통해 완료될 수 있다. 예를 들어, 이상의 모듈들은 이상의 방법을 실시하도록 구성되는, 하나 또는 복수 개의 전용 집적 회로 (Application Specific Integrated Circuit, ASIC), 또는 하나 또는 복수 개의 마이크로 프로세서(Digital Signal Processor, DSP), 또는 하나 또는 복수 개의 현장 프로그래머블 게이트 어레이(Field Programmable Gate Array, FPGA) 등과 같은 하나 또는 복수 개의 집적 회로일 수 있다. 또 예를 들어, 이상의 어느 한 모듈이 처리 요소에 의해 프로그램 코드를 스케줄링하는 형태로 구현되는 경우, 상기 처리 요소는 중앙 처리 장치 (Central Processing Unit, CPU)와 같은 범용 프로세서이거나 프로그램 코드를 호출할 수 있는 다른 프로세서일 수 있다. 또 예를 들어, 이러한 모듈은 하나로 집적되어 시스템 온 칩(System-On-a-Chip, SOC)의 형태로 구현될 수 있다. 상술한 실시예에서, 전부 또는 부분적으로 소프트웨어, 하드웨어, 펌웨어 또는 이들의 임의의 조합으로 구현될 수 있다. 소프트웨어를 이용하여 구현되는 경우, 전부 또는 부분적으로 컴퓨터 프로그램 제품의 형식으로 구현 될 수 있다. 상기 컴퓨터 프로그램 제품은 하나 또는 복수 개의 컴퓨터 명령을 포함할 수 있다. 상기 컴퓨터 프 로그램 명령이 컴퓨터에 로딩되어 수행되는 경우, 전부 또는 부분적으로 본 발명의 실시예에 따른 흐름 또는 기 능을 생성한다. 상기 컴퓨터는 범용 컴퓨터, 전용 컴퓨터, 컴퓨터 네트워크 또는 다른 프로그래머블 장치일 수 있다. 상기 컴퓨터 명령은 컴퓨터 판독 가능한 저장매체에 저장되거나 한 컴퓨터 판독 가능한 저장매체로부터 다른 한 컴퓨터 판독 가능한 저장매체로 전송될 수 있다. 예를 들어, 상기 컴퓨터 명령은 한 웹사이트 포털, 컴 퓨터, 서버 또는 데이터 센터로부터 유선(예를 들어, 동축 케이블, 광섬유, 디지털 가입자 회선(Digital Subscriber Line, DSL)) 또는 무선(예를 들어, 적외선, 무선, 마이크로파 등) 방식으로 다른 한 웹사이트 포털, 컴퓨터, 서버 또는 데이터 센터로 전송될 수 있다. 상기 컴퓨터 판독 가능한 저장매체는 컴퓨터가 액세스할 수 있는 임의의 사용 가능 매체이거나, 하나 또는 복수 개의 사용 가능 매체로 집적된 서버, 데이터 센터 등 데이 터 저장 장비를 포함할 수 있다. 상기 사용 가능 매체는 자성 매체(예를 들어, 플로피 디스크, 하드 디스크, 테 이프), 광매체(예를 들어, DVD) 또는 반도체 매체(예를 들어, 솔리드 스테이트 디스크(Solid State Disk, SS D))등 일 수 있다. 도 11은 본 발명의 실시예에 의해 제공된 전자 기기의 개략적인 구성도이다. 도 11에 도시된 바와 같이, 상기 전자 기기는 프로세서, 메모리, 통신 인터페이스 및 시스템 버스를 포함할 수 있으 며, 상기 메모리와 상기 통신 인터페이스는 상기 시스템 버스를 통해 상기 프로세서에 연 결되어 상호간의 통신을 완료할 수 있고, 상기 메모리는 컴퓨터 실행 명령을 저장하며, 상기 통신 인터페 이스는 다른 기기와 통신하기 위한 것이고, 상기 프로세서는 상기 컴퓨터 프로그램을 실행하면, 상기 도 1 내지 도 5 중 어느 하나에 도시된 바와 같은 실시예의 방안을 구현한다. 상기 도 11에 언급된 시스템 버스는 주변 장치 연결 표준(Peripheral Component Interconnect, PCI) 버스 또는 확장 기술 표준 구조(Extended Industry Standard Architecture, EISA) 버스 등일 수 있다. 상기 시스템 버스 는 어드레스 버스, 데이터 버스, 제어 버스 등으로 구분된다. 표현의 편의를 위해 도면에 하나의 굵은 선으로만 표시되지만 버스가 하나만 있거나 버스 유형이 하나만 있음을 의미하지는 않는다. 통신 인터페이스는 데이터베 이스 액세스 장치와 다른 장치(예를 들어, 클라이언트, 읽기-쓰기 라이브러리 및 읽기 전용 라이브러리) 간의 통신을 구현하는데 사용된다. 메모리는 램(Random Access Memory, RAM)을 포함할 수 있으며, 적어도 하나의 자 기 디스크 메모리와 같은 비 휘발성 메모리(non-volatile memory)를 더 포함할 수도 있다. 상술한 프로세서는 중앙 처리 장치(Central Processing Unit, CPU), 네트워크 프로세서(Network Processor, NP) 등을 포함하는 범용 프로세서일 수 있으며, 디지털 신호 프로세서(Digital Signal Processor, DSP), 전용 집적 회로(Application Specific Integrated Circuit, ASIC), 현장 프로그래머블 게이트 어레이(Field Programmable Gate Array, FPGA) 또는 다른 프로그래머블 논리 소자, 개별 게이트 또는 트랜지스터 논리 소자, 개별 하드웨어 컴포넌트일 수도 있다. 도 12는 본 발명의 실시예에 의해 제공된 운전 제어 방법의 개략적인 흐름도이며, 상술한 실시예를 기초로, 본 발명의 실시예는 아래의 단계들을 포함하는 운전 제어 방법을 더 제공한다. S1201 단계: 운전 제어 장치는 차량이 위치한 도로 환경의 적어도 일부 영역의 지도 정보를 획득하며, 지도 정 보는 본 발명의 실시예에 의해 제공된 지도 생성 방법을 적용하여 획득된다. S1202 단계: 운전 제어 장치는 상기 지도 정보에 따라 차량에 대해 지능형 운전 제어를 수행한다. 본 실시예의 수행 주체는 운전 제어 장치이고, 본 실시예의 운전 제어 장치는 상술한 실시예에 따른 전자 기기 와 동일한 기기에 위치할 수도 있고, 서로 다른 기기에 별도로 배치될 수도 있다. 본 실시예의 운전 제어 장치 는 상술한 전자 기기와 통신 연결을 설정한다. 지도 정보는 상술한 실시예의 방법을 적용하여 획득된 것이며, 구체적인 과정은 상술한 실시예의 설명을 참조하 면 되며, 여기서 더 설명하지 않는다. 구체적으로, 전자 기기는 상술한 지도 생성 방법을 수행하여 차량이 위치한 도로 환경의 적어도 일부 영역의 지 도 정보를 획득하고, 차량이 위치한 도로 환경의 적어도 일부 영역의 지도 정보를 출력한다. 운전 제어 장치는 차량이 위치한 도로 환경의 적어도 일부 영역의 지도 정보를 획득하고, 차량이 위치한 도로 환경의 적어도 일부 영역의 지도 정보에 따라 차량에 대해 지능형 운전 제어를 수행한다. 본 실시예의 지능형 운전은 보조 운전, 자동 운전, 보조 운전과 자동 운전 간의 운전 모드 전환 중 적어도 하나 를 포함한다. 상술한 지능형 운전 제어는 제동, 주행 속도 변경, 주행 방향 변경, 차선 유지, 램프 상태 변경, 운전 모드 전 환 등 중 적어도 하나를 포함할 수 있다. 운전 모드 전환은 보조 운전과 자동 운전 간의 전환일 수 있다(예를 들어, 보조 운전에서 자동 운전으로 전환). 본 실시예에 의해 제공된 운전 제어 방법은, 운전 제어 장치가 차량이 위치한 도로 환경의 적어도 일부 영역의 지도 정보를 통해 획득하고, 차량이 위치한 도로 환경의 적어도 일부 영역의 지도 정보에 따라 지능형 운전 제 어를 수행함으로써, 지능형 운전의 안전성과 신뢰성을 향상시킨다. 도 13은 본 발명의 실시예에 의해 제공된 운전 제어 장치의 개략적인 구성도이며, 상술한 실시예를 기초로, 본 발명의 실시예에 따른 운전 제어 장치는, 차량이 위치한 도로 환경의 적어도 일부 영역의 지도 정보를 획득하는 획득 모듈 - 상기 지도 정보는 상 술한 지도 생성 방법을 적용하여 획득됨 - ; 상기 지도 정보에 따라 차량에 대해 지능형 운전 제어를 수행하는 운전 제어 모듈을 포함한다. 본 발명의 실시예에 따른 운전 제어 장치는 상술한 방법 실시예의 기술적 방안을 수행할 수 있으며, 그 구현 원 리 및 기술적 효과는 유사하므로, 여기서 더 설명하지 않는다. 도 14는 본 발명의 실시예에 의해 제공된 지능형 운전 시스템의 개략도이다. 도 14에 도시된 바와 같이, 본 실 시예의 지능형 운전 시스템은 통신적으로 연결된 센서, 전자 기기 및 운전 제어 장치 를 포함한다. 전자 기기는 도 11에 도시된 바와 같고, 운전 제어 장치는 도 13에 도시된 바와 같다. 센서는 차량 탑재 카메라, 차량 탑재 레이더 센서, GPS, IMU 등 센서를 포함할 수 있다. 구체적으로, 도 14에 도시된 바와 같이, 실제 사용 시, 센서는 차량이 위치한 도로 환경의 적어도 일부 영역의 이미지 정보, 포인트 클라우드 정보, 차량의 포즈 정보를 수집하고 이러한 정보를 전자 기기에 송 신하며, 전자 기기는 이러한 정보를 수신한 후, 상술한 지도 생성 방법에 따라 지도를 생성하거나 대응하 는 영역의 부분을 업데이트한다. 이어서, 전자 기기는 생성된 지도 또는 업데이트된 지도를 운전 제어 장 치에 송신하고, 운전 제어 장치는 생성된 지도 또는 업데이트된 지도에 따라 차량에 대해 지능형 운전 제어를 수행한다. 선택적으로, 본 발명의 실시예는 프로세서에 의해 실행되면 상기 도 1 내지 도 5 중 어느 하나에 도시된 바와 같은 실시예의 방법을 구현하거나, 프로세서에 의해 실행되면 상기 도 12에 도시된 바와 같은 실시예의 방법을 구현하는 컴퓨터 프로그램이 저장된 판독 가능한 저장매체를 더 제공한다. 선택적으로, 본 발명의 실시예는 상기 도 1 내지 도 5 중 어느 하나에 도시된 실시예의 방법을 수행하거나, 상 기 도 12에 도시된 실시예의 방법을 수행하기 위한, 명령을 실행하는 칩을 더 제공한다. 본 발명의 실시예는 컴퓨터 프로그램을 포함하는 프로그램 제품을 더 제공하며, 상기 컴퓨터 프로그램은 저장매 체에 저장되고, 적어도 하나의 프로세서는 상기 저장매체로부터 상기 컴퓨터 프로그램을 판독할 수 있으며, 상 기 적어도 하나의 프로세서가 상기 컴퓨터 프로그램을 실행하면, 상기 도 1 내지 도 5 중 어느 하나에 도시된 실시예의 방법을 구현하거나, 상기 적어도 하나의 프로세서가 상기 컴퓨터 프로그램을 실행하면, 상기 도 12에 도시된 실시예의 방법을 구현할 수 있다. 본 발명의 실시예에서, ‘적어도 하나’는 하나 또는 복수 개를 가리키고, '복수 개'는 둘 또는 둘 이상을 가리 킨다. ‘및/또는’은 관련된 대상의 관련 관계를 설명하며, 3가지 관계가 존재할 수 있음을 나타낸다. 예를 들 어, A 및/또는 B는 A가 단독으로 존재, A와 B가 동시에 존재, B가 단독으로 존재하는 경우를 나타낼 수 있다. 여기서, A, B는 단수 또는 복수일 수 있다. 부호 ‘/’는 일반적으로 앞, 뒤 관련 대상이 ‘또는’의 관계임을 나타낸다. 공식에서, 부호 ‘/’는 일반적으로 앞, 뒤 관련 대상이 ‘상제’의 관계임을 나타낸다. ‘다음 중 적어도 하나(개)’ 또는 이와 유사한 표현은 이 항목들 중 임의 조합을 가리키며, 하나(개) 또는 복수(개)의 임 의 조합을 의미한다. 예를 들어, a, b 또는 c 중 적어도 하나(개)는 a, b, c, a-b, a-c, b-c 또는 a-b-c를 나 타낼 수 있다. 여기서, a, b, c는 하나일 수도 있고, 복수 개일 수도 있다. 이해할 것은, 본 발명의 실시예에 언급된 각종 숫자 번호는 단지 설명의 편리를 위한 구분이며, 본 발명의 실시 예의 범위를 한정하지 않는다. 이해할 것은, 본 발명의 실시예에서, 상술한 각 과정의 번호의 크기는 수행되는 선후 순서를 의미하지 않으며, 각 과정의 수행 순서는 응당 그 기능 및 내재적 논리에 의해 확정되어야 하지 본 발명의 실시예의 실시 과정에 대해 어떠한 한정을 구성해서는 않된다. 마지막으로 설명할 것은, 이상의 각 실시예는 본 발명의 기술적 방안을 설명하기 위한 것이며 이에 대해 한정하 지 않는다. 본 발명은 전술한 각 실시 예를 참조하여 상세하게 설명되었지만, 본 분야의 당업자는 전술한 각 실 시예에 기재된 기술적 방안이 여전히 수정될 수 있거나 기술적 특징의 일부 또는 전체가 동등하게 대체될 수 있 으며, 이러한 수정 또는 교체가 해당 기술적 방안의 본질이 본 발명의 각 실시예의 기술적 방안의 범위에서 벗 어나게 하지 않음을 이해해야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14"}
{"patent_id": "10-2021-7015319", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명 또는 종래 기술 중의 기술적 방안을 더 명확하게 설명하기 위하여, 이하 실시예 또는 종래 기술의 설명 에 사용될 첨부 도면에 대해 간단히 소개한다. 이하 설명 중 첨부 도면이 본 발명의 일부 실시예임은 본 분야의 통상의 기술자에게 있어서 자명한 것이며 창조성 노동을 하지 않고 이러한 첨부 도면에 따라 기타 첨부 도면을 획득할 수도 있다. 도 1은 본 발명의 실시예에 의해 제공된 지도 구축 방법의 개략적인 흐름도 1이다. 도 2는 본 발명의 실시예에 의해 제공된 지도 구축 방법의 개략적인 흐름도 2이다. 도 3은 본 발명의 실시예에 의해 제공된 지도 구축 방법의 개략적인 흐름도 3이다. 도 4는 본 발명의 실시예에 의해 제공된 지도 구축 방법의 개략적인 흐름도 4이다. 도 5는 본 발명의 실시예에 의해 제공된 지도 구축 방법의 개략적인 흐름도 5이다. 도 6은 본 발명의 실시예에 의해 제공된 지도 생성 장치의 모듈 구성도 1이다. 도 7은 본 발명의 실시예에 의해 제공된 지도 생성 장치의 모듈 구성도 2이다. 도 8은 본 발명의 실시예에 의해 제공된 지도 생성 장치의 모듈 구성도 3이다. 도 9는 본 발명의 실시예에 의해 제공된 지도 생성 장치의 모듈 구성도 4이다. 도 10은 본 발명의 실시예에 의해 제공된 지도 생성 장치의 모듈 구성도 5이다. 도 11은 본 발명의 실시예에 의해 제공된 전자 기기의 개략적인 구성도이다. 도 12는 본 발명의 실시예에 의해 제공된 운전 제어 방법의 개략적인 흐름도이다. 도 13은 본 발명의 실시예에 의해 제공된 운전 제어 장치의 개략적인 구성도이다. 도 14는 본 발명의 실시예에 의해 제공된 지능형 운전 시스템의 개략적인 구성도이다."}
