{"patent_id": "10-2022-0180064", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0098367", "출원번호": "10-2022-0180064", "발명의 명칭": "비디오 합성 서비스를 제공하는 방법 및 장치", "출원인": "주식회사 자이냅스", "발명자": "주동원"}}
{"patent_id": "10-2022-0180064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "타겟 이미지 및 구동 비디오를 포함하는, 사용자가 업로드한 입력 데이터를 수신하는 단계;상기 입력 데이터를 합성 비디오 생성 모델에 입력하기에 적합하도록 전처리하는 단계;상기 전처리된 데이터에 기초하여, 합성 비디오를 생성하는 단계; 및상기 합성 비디오를 상기 사용자가 다운로드하기에 적합하도록 후처리하는 단계;를 포함하는,방법."}
{"patent_id": "10-2022-0180064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 입력 데이터가 텍스트 및 발화자 정보를 포함하는 경우,상기 합성 비디오를 생성하는 단계는,상기 전처리된 데이터에 기초하여, 제1 합성 비디오를 생성하는 단계;상기 텍스트 및 상기 발화자 정보에 기초하여 합성 오디오를 생성하는 단계; 및상기 텍스트에 기초하여, 상기 제1 합성 비디오에 발화 비디오를 추가하는 단계;를 포함하고,상기 후처리하는 단계는,상기 발화 비디오가 추가된 제1 합성 비디오 및 상기 합성 오디오에 기초하여, 제2 합성 비디오를 생성하는 단계;를 포함하는,방법."}
{"patent_id": "10-2022-0180064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 입력 데이터가 구동 오디오를 포함하는 경우,상기 합성 비디오를 생성하는 단계는,상기 전처리된 데이터에 기초하여, 제1 합성 비디오를 생성하는 단계; 및상기 구동 오디오로부터 입 모양 데이터를 추출하여, 상기 제1 합성 비디오에 발화 비디오를 추가하는 단계;를 포함하고,상기 후처리하는 단계는,상기 발화 비디오가 추가된 제1 합성 비디오 및 상기 구동 오디오에 기초하여, 제2 합성 비디오를 생성하는 단계;공개특허 10-2024-0098367-3-를 포함하는,방법."}
{"patent_id": "10-2022-0180064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 전처리하는 단계는,상기 타겟 이미지의 인물 및 배경을 분리하는 단계; 및상기 구동 비디오로부터 비디오 정보를 추출하는 단계;를 포함하는,방법."}
{"patent_id": "10-2022-0180064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 합성 비디오를 생성하는 단계는,비지도(unsupervised) 학습 기반의 뉴럴 네트워크를 이용하는 것인,방법."}
{"patent_id": "10-2022-0180064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 전처리된 데이터는 전처리된 타겟 이미지 및 전처리된 구동 비디오를 포함하고,상기 합성 비디오를 생성하는 단계는,상기 전처리된 구동 비디오에 포함된 복수의 프레임 중 제1 프레임으로부터 배경 모션(background motion) 데이터를 추출하는 단계;상기 제1 프레임 및 상기 전처리된 타겟 이미지로부터 포즈 데이터를 추출하는 단계;상기 배경 모션 데이터 및 상기 포즈 데이터에 기초하여, 매핑 데이터를 산출하는 단계; 및 상기 매핑 데이터에 기초하여 상기 전처리된 타겟 이미지를 변환하여, 제1 합성 프레임을 생성하는 단계;를 포함하는,방법."}
{"patent_id": "10-2022-0180064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 후처리하는 단계는,상기 합성 비디오에 포함된 블러 및 아티팩트를 제거하기 위한 이미지 복원(restoration)을 수행하는 단계; 및상기 이미지 복원이 수행된 합성 비디오의 포맷을 변환하는 단계;를 포함하는,공개특허 10-2024-0098367-4-방법."}
{"patent_id": "10-2022-0180064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제3 항에 있어서,상기 제1 합성 비디오에 발화 비디오를 추가하는 단계는,상기 구동 오디오에 기초하여 멜-스펙트로그램을 생성하는 단계;상기 멜-스펙트로그램을 분할하여 상기 제1 합성 비디오에 포함된 복수의 프레임 각각에 대응하는 복수의 서브멜-스펙트로그램을 생성하는 단계;상기 복수의 프레임 각각으로부터 복수의 얼굴을 검출하는 단계;상기 복수의 얼굴 및 상기 복수의 서브 멜-스펙트로그램에 기초하여 복수의 입 모양 데이터를 생성하는 단계;및 상기 복수의 프레임 각각에, 대응하는 입 모양 데이터를 덮어쓰는 단계;를 포함하는,방법."}
{"patent_id": "10-2022-0180064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "적어도 하나의 프로그램이 저장된 메모리; 및상기 적어도 하나의 프로그램을 실행함으로써 동작하는 프로세서;를 포함하고,상기 프로세서는,타겟 이미지 및 구동 비디오를 포함하는, 사용자가 업로드한 입력 데이터를 수신하고,상기 입력 데이터를 합성 비디오 생성 모델에 입력하기에 적합하도록 전처리하며,상기 전처리된 데이터에 기초하여, 합성 비디오를 생성하고,상기 합성 비디오를 상기 사용자가 다운로드하기에 적합하도록 후처리하는,장치."}
{"patent_id": "10-2022-0180064", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2022-0180064", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 비디오 합성 서비스를 제공하는 방법 및 장치에 관한 것이다. 본 개시의 일 실시예에 따른 방법은, 타 겟 이미지 및 구동 비디오를 포함하는, 사용자가 업로드한 입력 데이터를 수신하는 단계; 상기 입력 데이터를 합 성 비디오 생성 모델에 입력하기에 적합하도록 전처리하는 단계; 상기 전처리된 데이터에 기초하여, 합성 비디오 를 생성하는 단계; 및 상기 합성 비디오를 상기 사용자가 다운로드하기에 적합하도록 후처리하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2022-0180064", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 비디오 합성 서비스를 제공하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0180064", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥러닝은 기계학습 기술의 종류 중 하나인 뉴럴 네트워크를 수많은 계층 형태로 연결한 기법을 의미하며, 컴퓨 터의 처리 속도가 빨라지고 그래픽 처리 장치가 발전함에 따라, 딥러닝과 연관된 기술들 또한 다양한 분야와 접목되며 빠르게 발전해왔다. 특히, 최근 딥러닝을 통해 사진이나 영상을 활용하여 합성된 영상을 제작하는 것에 대한 요구가 높아지고 있다. 하지만 이러한 딥러닝을 활용한 합성된 영상을 제작하는 것은, 딥러닝의 연구자와 같은 딥러닝 관련 지식을 갖 고 있지 않은 경우, 불가능하거나 어렵다는 문제점이 존재한다."}
{"patent_id": "10-2022-0180064", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다."}
{"patent_id": "10-2022-0180064", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 목적은 비디오 합성 서비스를 제공하는 방법 및 장치를 제공하는 데 있다. 본 개시가 해결하고자 하 는 과제는 이상에서 언급한 과제에 한정되지 않으며, 언급되지 않은 본 개시의 다른 과제 및 장점들은 하기의 설명에 의해서 이해될 수 있고, 본 개시의 실시예에 의해 보다 분명하게 이해될 것이다. 또한, 본 개시가 해결 하고자 하는 과제 및 장점들은 특허 청구범위에 나타난 수단 및 그 조합에 의해 실현될 수 있음을 알 수 있을 것이다."}
{"patent_id": "10-2022-0180064", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 제1 측면은, 타겟 이미지 및 구동 비디오를 포함하는, 사용자가 업로드한 입력 데이터를 수신하는 단 계; 상기 입력 데이터를 합성 비디오 생성 모델에 입력하기에 적합하도록 전처리하는 단계; 상기 전처리된 데이 터에 기초하여, 합성 비디오를 생성하는 단계; 및 상기 합성 비디오를 상기 사용자가 다운로드하기에 적합하도 록 후처리하는 단계;를 포함하는 방법을 제공할 수 있다. 본 개시의 제2 측면은, 적어도 하나의 프로그램이 저장된 메모리; 및 상기 적어도 하나의 프로그램을 실행함으 로써 동작하는 프로세서;를 포함하고, 상기 프로세서는, 타겟 이미지 및 구동 비디오를 포함하는, 사용자가 업 로드한 입력 데이터를 수신하고, 상기 입력 데이터를 합성 비디오 생성 모델에 입력하기에 적합하도록 전처리하 며, 상기 전처리된 데이터에 기초하여, 합성 비디오를 생성하고, 상기 합성 비디오를 상기 사용자가 다운로드하 기에 적합하도록 후처리하는 장치를 제공할 수 있다. 본 개시의 제3 측면은, 제1 측면에 따른 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체를 제공할 수 있다."}
{"patent_id": "10-2022-0180064", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 다양한 실시예에 따르면, 일반적인 사용자가 딥러닝 관련 지식 없이도 합성된 영상을 제작할 수 있다. 구체적으로, 사용자는 합성을 원하는 사진과 영상을 입력하기만 하면, 사진의 인물이 영상의 움직임을 따 라하도록 합성된 영상을 제공하는 시스템이 제공될 수 있다. 또한, 사용자의 추가적인 데이터 편집 또는 수정을 최대한으로 배제하기 위해, 사용자가 업로드한 데이터를 전 처리하고, 생성된 데이터를 후처리하는 과정이 수행됨으로써, 사용자의 편의가 증대될 수 있다. 또한, 비지도 학습 기반의 뉴럴 네트워크를 이용함으로써, 합성하고자 하는 대상에 대한 학습 없이도, 임의의 대상에 기초하여 합성된 영상이 제작될 수 있다."}
{"patent_id": "10-2022-0180064", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 설명되는 실시예들 을 참조하면 명확해질 것이다. 그러나 본 발명은 아래에서 제시되는 실시예들로 한정되는 것이 아니라, 서로 다 른 다양한 형태로 구현될 수 있고, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 아래에 제시되는 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이"}
{"patent_id": "10-2022-0180064", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 일부 실시예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기 술을 채용할 수 있다. \"매커니즘\", \"요소\", \"수단\" 및 \"구성\"등과 같은 용어는 넓게 사용될 수 있으며, 기계적 이고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 일 실시예에 따른 비디오 합성 서비스를 제공하는 시스템을 나타내는 도면이다. 일 실시예에 따른 비디오 합성 서비스를 제공하는 시스템은 클라이언트 장치 및 서버 장치를 포함 할 수 있다. 한편, 도 1에 도시된 비디오 합성 서비스를 제공하는 시스템에는 일 실시예와 관련된 구성요소들만 이 도시되어 있다. 따라서, 비디오 합성 서비스를 제공하는 시스템에는 도 1에 도시된 구성요소들 외에 다른 범"}
{"patent_id": "10-2022-0180064", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "용적인 구성요소들이 더 포함될 수 있음은 당해 기술분야의 통상의 기술자에게 자명하다. 클라이언트 장치 및 서버 장치는 네트워크를 이용하여 통신을 수행할 수 있다. 예를 들어, 네트워 크는 근거리 통신망(Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 부가가치 통신망(Value Added Network; VAN), 이동 통신망(mobile radio communication network), 위성 통신망 및 이들의 상호 조합을 포함하며, 도 1에 도시된 각 네트워크 구성 주체가 서로 원활하게 통신을 할 수 있도록 하는 포괄적인 의미의 데이터 통신망이며, 유선 인터넷, 무선 인터넷 및 모바일 무선 통신망을 포함할 수 있다. 또한, 무선 통신은 예 를 들어, 무선 랜(Wi-Fi), 블루투스, 블루투스 저 에너지(Bluetooth low energy), 지그비, WFD(Wi-Fi Direct), UWB(ultra wideband), 적외선 통신(IrDA, infrared Data Association), NFC(Near Field Communication) 등이 있을 수 있으나, 이에 한정되는 것은 아니다. 클라이언트 장치는 비디오 합성 서비스의 사용자의 단말에 해당할 수 있다. 클라이언트 장치는 사 용자로부터 데이터를 입력 받을 수 있고, 입력된 데이터 또는 입력된 데이터에 기초하여 산출되거나 생성되는 데이터를 네트워크를 통해 서버 장치로 전송할 수 있다. 또한, 서버 장치로부터 네트워크를 통해 전송되는 데이터를 수신할 수 있다. 예를 들어, 클라이언트 장치는 스마트폰, 태블릿 PC, PC, 스마트 TV, 휴대폰, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지털 카메라, 가전기기, 카메라가 탑재된 디바이스 및 기타 모바일 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 도 1에서, 클라이언트 장치가 하나인 것으로 도시되었으나, 관제 서버와 네트워크를 통해 통신하는 클라이언트 장치는 하나 이상일 수 있다. 서버 장치는 클라이언트 장치로부터 네트워크를 통해 전송되는 데이터를 수신할 수 있다. 서버 장 치는 수신된 데이터에 기초하여 본 개시의 비디오 합성 서비스를 제공하기 위한 컨텐츠, 즉 합성 비디오 를 생성할 수 있다. 서버 장치는 생성된 컨텐츠를 네트워크를 통해 클라이언트 장치로 전송할 수 있다. 예를 들어, 서버 장치는 네트워크를 통해 통신하여 명령, 코드, 파일, 컨텐츠, 서비스 등을 제공하는 컴 퓨터 장치 또는 복수의 컴퓨터 장치들로 구현될 수 있다. 서버 장치는 API(application programming interface) 서버이거나 API 서버를 포함하는 개념으로 이해될 수 있다. 도 2는 본 개시의 일 실시예에 따른 서버 장치가 수행하는 동작을 개략적으로 도시하는 도면이다. 도 2의 서버 장치는 도 1을 참조하여 전술한 서버 장치에 대응될 수 있다. 본 개시에서, 서버 장치는 입력 데이터를 수신하여, 합성 비디오를 생성하고 출력하는 동작을 수행할 수 있다. 일 실시예에서, 입력 데이터는 비디오 합성 서비스의 사용자가 전송한 데이터로서, 전술한 클라이언트 장 치에 의해 전송된 것일 수 있다. 일 실시예에서, 입력 데이터는 타겟 이미지 및 구동 비디오를 포함할 수 있다. 본 개시에서, 타겟 이미지 는 비디오 합성 서비스의 사용자가 합성 비디오에 삽입하고 싶어하는 인물의 이미지를 지칭할 수 있다. 본 개시에서, 구동 비디오는 비디오 합성 서비스의 사용자가 타겟 이미지의 인물이 따라하길 희망하는 모션 (motion)을 포함하는 비디오를 지칭할 수 있다. 예를 들어, 타겟 이미지가 사용자의 얼굴이 찍힌 사진이고, 구 동 비디오가 축구 선수가 드리블하는 비디오인 경우, 사용자가 원하는 결과물인 합성 비디오(202는 사용자의 얼 굴로 대체된 선수가 드리블하는 비디오일 것이다. 일 실시예에서, 합성 비디오는 서버 장치의 출력으로써, 네트워크를 통해 사용자의 클라이언트 장치 로 전송될 수 있다. 도 2에 도시된 합성 비디오는 후술할 전처리하기 전의 합성 비디오 및 전처리 후의 합 성 비디오를 포함하는 개념으로 이해될 수 있다. 이하에서, 본 개시의 다양한 실시예에 따른 비디오 합성 서비스를 제공하는 장치가 수행하는 동작에 관하여 설 명한다. 다양한 실시예에 따른 동작을 수행하는 비디오 합성 서비스를 제공하는 장치는 서버 장치 또는 서버 장치의 일부일 수 있다. 본 개시의 비디오 합성 서비스를 제공하는 장치는 타겟 이미지 및 구동 비디오를 포함하는, 사용자가 업로드한 입력 데이터를 수신할 수 있다. 본 개시의 비디오 합성 서비스를 제공하는 장치는 입력 데이터를 합성 비디오 생성 모델에 입력하기에 적합하도록 전처리할 수 있다. 본 개시의 비디오 합성 서비스를 제공하는 장치는 전처 리된 데이터에 기초하여, 합성 비디오를 생성할 수 있다. 본 개시의 비디오 합성 서비스를 제공하는 장치는 생 성된 합성 비디오를 사용자가 다운로드하기에 적합하도록 후처리할 수 있다. 이하에서, 비디오 합성 서비스를 제공하는 장치가 비디오 합성 서비스를 제공하는 방법의 각 단계에 관하여 상세히 설명한다. 전술한 바와 같이, 본 개시의 비디오 합성 서비스를 제공하는 장치는 타겟 이미지 및 구동 비디오를 포함하는, 사용자가 업로드한 입력 데이터를 수신할 수 있다. 전술한 바와 같이, 입력 데이터는 비디오 합성 서비스의 사용자가 전송한 데이터를 지칭할 수 있다. 본 개시의 비디오 합성 서비스를 제공하는 장치는 클라이언트 장치 또는 서버 장치에 포함된 메모리로부터 입력 데이터를 수신할 수 있다. 일 실시예에서, 입력 데이터는 타겟 이미지 및 구동 비디오를 포함할 수 있다. 일 실시예에서, 입력 데이터는 텍스트 및 발화자 정보를 더 포함할 수 있다. 텍스트 및 발화자 정보 또한 비디 오 합성 서비스의 사용자가 입력한 데이터이며, 일 실시예에서, 텍스트는 직접 입력하는 방식으로, 발화자 정보 는 비디오 합성 서비스에서 제공하는 하나 이상의 발화자 정보 중 어느 하나를 선택하는 방식으로 입력될 수 있다. 비디오 합성 서비스의 사용자는 텍스트 및 발화자 정보를 입력함으로써, 텍스트에 대응하는 입모양의 변화 및 텍스트 및 발화자 정보에 대응하는 오디오를 포함하는 합성 비디오를 제공받을 수 있다. 일 실시예에서, 입력 데이터는 구동 오디오를 더 포함할 수 있다. 구동 오디오 또한 비디오 합성 서비스의 사용 자가 입력한 데이터일 수 있다. 본 개시에서, 구동 오디오는 사람의 목소리를 포함하는 임의의 오디오를 지칭할 수 있다. 비디오 합성 서비스의 사용자는 구동 오디오를 입력함으로써, 구동 오디오에 대응하는 입모양의 변화 및 구동 오디오를 포함하는 합성 비디오를 제공받을 수 있다. 전술한 바와 같이, 본 개시의 비디오 합성 서비스를 제공하는 장치는 입력 데이터를 합성 비디오 생성 모델에 입력하기에 적합하도록 전처리할 수 있다. 본 개시의 일 실시예에 따른 비디오 합성 서비스를 제공하는 시스템은, 비디오 합성 서비스의 사용자가 타겟 이 미지 또는 구동 비디오를 특정 제한(예컨대, 용량, 사이즈 등)에 부합하도록 변환하거나 변경할 필요가 없고, 임의의 규격을 갖는 타겟 이미지 또는 구동 비디오를 업로드함으로써, 간편하게 비디오 합성 서비스를 제공하게 할 수 있다. 이를 위해, 본 개시의 비디오 합성 서비스를 제공하는 장치는 입력 데이터를 합성 비디오를 생성하 기에 적합하도록, 구체적으로 합성 비디오 생성 모델에 입력하기에 적합하도록 전처리할 수 있다. 구체적으로, 전처리 과정은 이미지 전처리 및 비디오 전처리를 포함할 수 있다. 도 3은 본 개시의 일 실시예에 따른 입력 데이터를 전처리하는 과정을 개략적으로 도시하는 흐름도이다. 일 실시예에서, 입력 데이터는 전처리 과정을 거쳐 전처리된 데이터로 변환될 수 있다. 구체적으로, 입력 데이터에 포함된 타겟 이미지는 이미지 전처리 과정이 수행될 수 있고, 입력 데이터에 포함된 구동 비디오는 비디오 전처리 과정이 수행될 수 있다. 일 실시예에서, 이미지 전처리 과정은 이미지 크기를 합성 비디오 생성 모델에 입력하기에 적합하도록 크기를 변환하는 이미지 리사이즈(resize) 과정을 포함할 수 있다. 일 실시예에서, 이미지 전처리 과정은 합성 비디오 생성 과정에서 이미지의 선명도가 저하되는 것을 보완하기 위한 이미지 샤프닝(sharpening) 과정을 포함할 수 있다. 일 실시예에서, 이미지 전처리 과정은 이미지의 인물과 배경을 분리하는 이미지 세그멘테이션 (segmentation) 과정을 포함할 수 있다. 일 실시예에서, 비디오 전처리 과정은 비디오를 구성하는 프레임의 크기를 합성 비디오 생성 모델에 입력하기에 적합하도록 크기를 변화하는 프레임 리사이즈 과정을 포함할 수 있다. 일 실시예에서, 비디오 전처리 과정은 비 디오의 FPS(frames per second)와 같은 합성 비디오 생성에 필요한 비디오 정보를 추출하는 과정을 포함할 수 있다. 도 3에 도시된 예시에서, 전처리된 데이터에 포함된 이미지 및 비디오를 구성하는 하나 이상의 프레임은 각각 전처리된 타겟 이미지 및 전처리된 구동 비디오에 대응될 수 있다. 전술한 바와 같이, 본 개시의 비디오 합성 서비스를 제공하는 장치는 전처리된 데이터에 기초하여, 합성 비디오 를 생성할 수 있다. 도 4는 본 개시의 일 실시예에 따른 합성 비디오를 생성하는 과정을 개략적으로 도시하는 순서도이다. 이하에서, 합성 비디오를 생성하는 과정은 구동 비디오의 프레임 단위로 수행될 수 있다. 비디오 합성 서비스를 제공하는 장치는 타겟 이미지를, 프레임 마다, 구동 비디오에 포함된 프레임의 모션을 따라하도록 변환함으로써 합성 비디오를 생성할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 전처리된 구동 비디오에 포함된 하나 이상의 프레임 중 제1 프레임으로부터 배경 모션(background motion) 데이터를 추출할 수 있다. 본 개시에서, 배 경 모션 데이터는 구동 비디오의 배경의 움직임을 나타내는 데이터를 지칭할 수 있다. 일 실시예에서, 배 경 모션 데이터는 아핀 변환(affine transformation)을 위한 데이터로 추출될 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 제1 프레임 및 전처리된 타겟 이미지로부터 포즈 데이터를 추출할 수 있다. 본 개시에서, 포즈 데이터는 구동 비디오 및 타겟 이미지의 인 물의 자세를 나타내는 데이터를 지칭할 수 있다. 일 실시예에서, 포즈 데이터는 키포인트 검출을 통해 추 출될 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 배경 모션 데이터 및 포즈 데이터에 기초하여, 매핑 데이터를 산출할 수 있다. 본 개시에서, 매핑 데이터는 타겟 이미지의 인물이구동 비디오의 포즈를 취하도록 타겟 이미지를 변환하기 위한 데이터를 지칭할 수 있다. 일 실시예에서, 매핑 데이터는 TPS(thin plate spline) 변환을 위한 데이터로 추출될 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 매핑 데이터에 기초하여 전처리된 타겟 이미지 를 변환할 수 있다. 전처리된 타겟 이미지에 대해 변환 과정이 수행된 결과로써, 제1 합성 프레 임이 생성될 수 있다. 제1 합성 프레임 생성 과정에서, 타겟 이미지의 인물이 구동 비디오의 포즈를 취하도록 타겟 이미지가 변환될 수 있다. 더 구체적인 실시예에서, 배경 모션 데이터, 포즈 데이터 및 매핑 데이터는 덴스 모션 네트워크 (dense motion network)의 입력으로 사용될 수 있고, 덴스 모션 네트워크는 입력된 데이터를 옵티컬 플로우 (optical flow) 및 오클루전 마스크(occlusion mask)로 변환할 수 있다. 옵티컬 플로우는 타겟 이미지에서 변환 이 필요한 위치에 대한 정보를 포함할 수 있다. 오클루전 마스크는 타겟 이미지의 변환에 따른 마스킹 정보를 포함할 수 있다. 옵티컬 플로우 및 오클루전 마스크는 인페인팅 네트워크(inpainting network)의 입력으로 사용 될 수 있고, 인페인팅 네트워크는 제1 합성 프레임을 생성할 수 있다. 본 개시에서, 제1 합성 프레임은 전처리된 구동 비디오에 포함된 하나 이상의 프레임 중 제1 프레임 에 대응되어 타겟 이미지를 변환하여 생성된 프레임을 지칭할 수 있다. 이후, 전처리된 구동 비디오에 포함된 하나 이상의 프레임 전부에 대응되어 각각 생성된 하나 이상의 프레임들을 순서대로 나열하여 비디오 데이터(예 컨대, 합성 비디오)를 생성할 수 있을 것이다. 전술한 바와 같이, 일 실시예에서, 입력 데이터는 텍스트 및 발화자 정보를 더 포함할 수 있다. 입력 데이터가 텍스트 및 발화자 정보를 포함하는 경우, 합성 비디오를 생성하는 과정은 텍스트 및 발화자 정보를 처리하여 합 성 오디오를 생성하고, 발화 비디오를 추가하는 과정을 포함할 수 있다. 구체적으로, 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 전처리된 데이터에 기초하여 제1 합성 비디 오를 생성할 수 있다. 제1 합성 비디오라는 용어는, 후술할 합성 오디오가 결합된 후의 합성 비디오인 제2 합성 비디오와 구분되는 합성 비디오를 지칭하기 위해 사용될 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 텍스트 및 발화자 정보에 기초하여 합성 오디오를 생성 할 수 있다. 예를 들어, 텍스트가 \"Have a good day!\"이고, 발화자 정보가 \"화자 1\"인 경우, 비디오 합성 서비스를 제공하는 장치는 화자 1의 발화 특징이 반영된 \"Have a good day!\"에 대한 합성 오디오를 생성할 수 있다. 발화 특징은 음성, 운율, 음높이 및 감정 등 다양한 요소들 중 적어도 하나를 포함할 수 있다. 즉, 본 예시에서, 생성되는 합성 오디오는 화자 1이 \"Have a good day!\"를 자연스럽게 발음하는 듯한 오디오일 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 발화자 정보에 대응하는 발화 임베딩 벡터(embedding vector)를 데이터베이스로부터 획득할 수 있다. 다른 실시예에서, 비디오 합성 서비스를 제공하는 장치는 발화 자 정보에 대응하는 오디오 샘플 또는 오디오 신호에 기초하여 발화 임베딩 벡터를 생성할 수 있다. 발화 임베 딩 벡터는 대응하는 발화 특징을 나타낼 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 입력 데이터에 포함된 텍스트에 기초하여 텍스트 임베딩 벡터를 생성할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 발화 임베딩 벡터 및 텍스트 임베딩 벡터에 기초하여, 멜-스펙트로그램을 생성할 수 있다. 즉, 비디오 합성 서비스를 제공하는 장치는 발화자 정보에 대응하는 발화 특징이 반영된 텍스트에 대한 멜-스펙트로그램을 생성할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 멜-스펙트로그램에 기초하여 합성 오디오를 생성할 수 있다. 구체적인 실시예에서, ISFT(inverse short-time Fourier transform)을 이용하여 합성 오디오가 생성될 수 있다. 다른 구체적인 실시예에서, 그리핀-림 알고리즘(Griffin-Lim algorithm)을 이용하여 합성 오디오가 생 성될 수 있다. 또 다른 구체적인 실시예에서, 뉴럴 보코더(neural vocoder)를 이용하여 합성 오디오가 생성될 수 있다. 뉴럴 보코더는 멜-스펙트로그램을 입력으로 받아 오디오를 생성하는 인공 신경망 모델이다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 합성 오디오를 생성하기 위한 인공지능 추론 모델인 오 디오 합성 모델을 포함할 수 있다. 오디오 합성 모델은 전술한 합성 오디오를 생성하는 과정의 적어도 일부를 수행하기 위한 모델을 지칭할 수 있다. 또한, 오디오 합성 모델은 하나 이상의 인공지능 추론 모델을 포함할 수 있으며, 오디오 합성 모델에 포함된 하나 이상의 인공지능 추론 모델 각각은 전술한 합성 오디오를 생성하는 과정의 일부를 수행하도록 학습될 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 텍스트에 기초하여 발화 비디오를 생성할 수 있고, 발화 비디오를 제1 합성 비디오에 추가할 수 있다. 예를 들어, 발화 비디오는 텍스트에 포함된 음운에 기초하여 생성 될 수 있다. 구체적으로, 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 제1 합성 비디오에 포함된 프 레임 각각에서 얼굴을 검출할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는, 대응하는 프레 임마다, 검출된 얼굴에 기초하여, 텍스트에 대응하는 입모양 데이터를 생성할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는, 대응하는 프레임마다, 검출된 얼굴에 입모양 데이터에 기초한 입 부분의 이미 지를 새롭게 생성할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 입 부분의 이미지가 새롭 게 생성된 얼굴을 제1 합성 비디오에 포함된 프레임 각각에 덮어쓸 수 있다. 이후, 비디오 합성 서비스를 제공하는 장치는 발화 비디오가 추가된 제1 합성 비디오 및 합성 오디오에 기초하 여 제2 합성 비디오를 생성할 수 있다. 전술한 바와 같이, 일 실시예에서, 입력 데이터는 구동 오디오를 더 포함할 수 있다. 입력 데이터가 구동 오디 오를 포함하는 경우, 합성 비디오를 생성하는 과정은 구동 오디오를 처리하여 발화 비디오를 추가하는 과정을 포함할 수 있다. 구체적으로, 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 전처리된 데이터에 기초하여 제1 합성 비디 오를 생성할 수 있다. 여기에서의 제1 합성 비디오라는 용어 또한 구동 오디오가 결합된 후의 합성 비디오인 제 2 합성 비디오와 구분되는 합성 비디오를 지칭하기 위해 사용될 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 구동 오디오에 기초하여 발화 비디오를 생성할 수 있고, 발화 비디오를 제1 합성 비디오에 추가할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 구동 오디오로부터 입 모양 데이터를 추출할 수 있고, 추출된 입모양에 기초하여 발화 비디오를 생성할 수 있다. 구체적으로, 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 구동 오디오에 기초하여 멜-스펙트로그램 (mel-spectrogram)을 생성할 수 있다. 멜-스펙트로그램 생성은 구동 오디오에 대한 소리 추출(sound extraction)을 통해 수행될 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 멜-스펙트로그램을 분할하여 복수의 서브 멜-스펙트로그램을 생성할 수 있다. 복수의 서브 멜-스펙트로그램 각각은 제1 합성 비디 오에 포함된 복수의 프레임 각각에 대응할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 제1 합성 비디오에 포함된 프레임 각각에서 얼굴을 검출할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는, 대응하는 프레임마다, 검출된 얼굴에 기초하여 서브 멜-스펙트로그램에 대응하는 입모양 데이터를 생성 할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는, 대응하는 프레임마다, 검출된 얼굴에 입모 양 데이터에 기초한 입 부분의 이미지를 새롭게 생성할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하 는 장치는 입 부분의 이미지가 새롭게 생성된 얼굴을 제1 합성 비디오에 포함된 프레임 각각에 덮어쓸 수 있다. 이후, 비디오 합성 서비스를 제공하는 장치는 발화 비디오가 추가된 제1 합성 비디오 및 구동 오디오에 기초하 여 제2 합성 비디오를 생성할 수 있다. 한편, 입력 데이터가 텍스트 및 발화자 정보를 더 포함하는 실시예에서, 비디오 합성 서비스를 제공하는 장치는, 입력 데이터가 구동 오디오를 더 포함하는 실시예의 경우와 유사한 과정을 적용하여 합성 비디오를 생 성할 수도 있다. 구체적으로, 비디오 합성 서비스를 제공하는 장치는, 전술한 바와 같이, 텍스트 및 발화자 정보에 기초하여 합 성 오디오를 생성하는 과정에서, 멜-스펙트로그램을 생성할 수 있다. 이 멜-스펙트로그램은 발화 임베딩 벡터 및 텍스트 임베딩 벡터에 기초하여 생성된 것이다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 합성 오디오를 생성하는 과정에서 생성된 멜-스펙트로그램을 분할하여 복수의 서브 멜-스펙트로그램을 생성할 수 있 다. 복수의 서브 멜-스펙트로그램 각각은 제1 합성 비디오에 포함된 복수의 프레임 각각에 대응할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 제1 합성 비디오에 포함된 프레임 각각에서 얼굴을 검출할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는, 대응하는 프레임마다, 검출된 얼굴에 기초하 여 서브 멜-스펙트로그램에 대응하는 입모양 데이터를 생성할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는, 대응하는 프레임마다, 검출된 얼굴에 입모양 데이터에 기초한 입 부분의 이미지를 새롭게 생 성할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 입 부분의 이미지가 새롭게 생성된 얼굴 을 제1 합성 비디오에 포함된 프레임 각각에 덮어쓸 수 있다. 일 실시예에서, 입력 데이터가 텍스트 및 발화정보 또는 구동 오디오를 포함하지 않고, 타겟 이미지 및 구동 비 디오만을 포함하는 경우, 합성 비디오는 발화 비디오가 없는 비디오일 수 있고, 이 경우 구현에 따라, 합성 비 디오는 구동 비디오에 포함된 오디오를 포함할 수도 있고, 어떠한 오디오도 포함하지 않을 수도 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 합성 비디오를 생성하기 위한 인공지능 추론 모델인 비 디오 합성 모델을 포함할 수 있다. 비디오 합성 모델은 전술한 합성 비디오를 생성하는 과정의 적어도 일부를 수행하기 위한 모델을 지칭할 수 있다. 또한, 비디오 합성 모델은 하나 이상의 인공지능 추론 모델을 포함할 수 있으며, 비디오 합성 모델에 포함된 하나 이상의 인공지능 추론 모델 각각은 전술한 합성 비디오를 생성하는 과 정의 일부를 수행하도록 학습될 수 있다. 본 개시에서, 비디오 합성 모델(비디오 합성 모델에 포함된 하나 이상의 인공지능 추론 모델을 포함함)은 비지 도(unsupervised) 학습 기반의 뉴럴 네트워크(neural network)를 포함할 수 있다. 즉, 합성 비디오를 생성하는 과정에 비지도 학습 기반의 뉴럴 네트워크가 이용될 수 있다. 종래의 비디오 합성 모델은 합성하고자 하는 대상에 대해 학습이 수행되지 않으면, 해당 대상에 기초한 합성 비 디오를 생성할 수 없었다. 즉, 종래에는 학습이 수행된 대상에 대해서만 비디오 합성이 가능하였다. 이러한 문 제를 해결하기 위해, 본 개시의 합성 비디오 생성을 수행하는 비디오 합성 모델은 비지도 학습 기반의 뉴럴 네 트워크를 포함할 수 있다. 본 개시의 비디오 합성 서비스를 제공하는 장치는 비지도 학습 기반의 뉴럴 네트워크 를 이용함으로써, 대상에 한정되지 않고 개인뿐만 아니라 애니메이션 캐릭터, 동물 등까지 타겟 이미지로 활용 될 수 있다. 전술한 바와 같이, 본 개시의 비디오 합성 서비스를 제공하는 장치는 생성된 합성 비디오를 사용자가 다운로드 하기에 적합하도록 후처리할 수 있다. 도 5는 본 개시의 일 실시예에 따른 합성 비디오를 후처리하는 과정을 개략적으로 도시하는 흐름도이다. 이하에서, 합성 비디오는 생성된 합성 프레임의 집합으로, 본 개시에서 언급되는, 타겟 이미지가 변환되어 생성 된 비디오 중 어느 하나를 지칭할 수 있다. 즉, 합성 비디오는 제1 합성 비디오, 발화 비디오가 추가된 제1 합 성 비디오, 제2 합성 비디오, 이미지 복원 과정이 수행된 합성 비디오 등을 포함할 수 있다. 도 5를 참조하면, 합성 비디오가 도시된다. 합성 비디오는 도 4에 도시된 제1 합성 프레임과 같 은 합성 프레임의 집합일 수 있다. 일 실시예에서, 합성 비디오는 후처리 과정을 거쳐 사용자 제공용 비디오로 변환될 수 있다. 구체적 으로, 합성 비디오에 대해서 이미지 복원(restoration) 과정이 수행될 수 있고, 비디오 처리(processing) 과정이 수행될 수 있다. 이미지 복원 과정은 합성 비디오에 포함된 블러(blur) 및 아티팩트(artifact)를 제거하기 위한 과정을 지 칭할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 이미지 복원 과정을 수행하기 위한 인공 지능 추론 모델인 이미지 복원 모델을 포함할 수 있다. 일 실시예에서, 이미지 복원 모델은 합성 비디오에 대해 인물의 식별(identity) 정보를 추출하여, 잠재 코드 매핑(latent code mapping)을 수행함으로써, 인물의 특징이 부각되도록 할 수 있다. 일 실시예에서, 이미지 복원 모델의 아키텍처는 U-Net 구조를 포함할 수 있다. 일 실시예에서, 이미지 복원 과정은 업스케일링(upscaling) 과정을 포함할 수 있다. 비디오 처리 과정은 합성 비디오의 포맷을 변환하는 과정을 포함할 수 있다. 비디오 처리 과정을 통해, 비 디오 합성 서비스의 사용자가 웹 또는 애플리케이션 등을 통해 결과물로써의 영상을 다운로드할 수 있게 될 수 있다. 예를 들어, 비디오 처리 과정은 합성 비디오를 H.264 포맷으로 인코딩하는 것을 포함할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 발화 비디오가 추가된 제1 합성 비디오 및 합성 오디오 (또는 구동 오디오)에 기초하여 제2 합성 비디오를 생성할 수 있다. 즉, 발화 비디오가 추가된 제1 합성 비디오 와 합성 오디오(또는 구동 오디오)를 결합하여 제2 합성 비디오를 생성할 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 발화 비디오가 추가된 제1 합성 비디오에 대해 후처리 과정을 수행한 후의 합성 비디 오에 기초하여 제2 합성 비디오를 생성할 수도 있다. 즉, 제2 합성 비디오 생성의 기초가 되는 제1 합성 비디오 는 후처리 과정을 거친 후의 합성 비디오일 수 있다. 또는 비디오 합성 서비스를 제공하는 장치는, 후처리 과정 의 일부로서, 제2 합성 비디오를 생성할 수도 있다. 생성된 제2 합성 비디오는 사용자 제공용 비디오일 수 있다. 일 실시예에서, 비디오 합성 서비스를 제공하는 장치는 사용자 제공용 비디오를 클라이언트 장치로 전송할 수 있다. 도 6은 본 개시의 일 실시예에 따른 비디오 합성 서비스를 제공하는 방법의 흐름도이다. 도 6에 도시된 동작들은 전술한 비디오 합성 서비스를 제공하는 장치에 의하여 실행될 수 있다. 구체적으로, 도 6에 도시된 동작들은 전술한 비디오 합성 서비스를 제공하는 장치에 포함된 프로세서에 의하여 실행될 수 있다. 단계 610에서, 프로세서는 타겟 이미지 및 구동 비디오를 포함하는, 사용자가 업로드한 입력 데이터를 수신할 수 있다. 일 실시예에서, 입력 데이터는 텍스트 및 발화자 정보를 포함할 수 있다. 일 실시예에서, 입력 데이터는 구동 오디오를 포함할 수 있다. 단계 620에서, 프로세서는 입력된 데이터를 합성 비디오 생성 모델에 입력하기에 적합하도록 전처리할 수 있다. 일 실시예에서, 단계 620은 타겟 이미지의 인물 및 배경을 분리할 수 있다. 일 실시예에서, 단계 620은 구동 비디오로부터 비디오 정보를 추출할 수 있다. 단계 630에서, 프로세서는 전처리된 데이터에 기초하여, 합성 비디오를 생성할 수 있다. 일 실시예에서, 단계 630은 비지도 학습 기반의 뉴럴 네트워크를 이용하는 것일 수 있다. 일 실시예에서, 전처리된 데이터는 전처리된 타겟 이미지 및 전처리된 구동 비디오를 포함할 수 있다. 일 실시예에서, 단계 630은 전처리된 구동 비디오에 포함된 복수의 프레임 중 제1 프레임으로부터 배경 모션 데 이터를 추출하는 단계를 포함할 수 있다. 일 실시예에서, 단계 630은 제1 프레임 및 전처리된 타겟 이미지로부터 포즈 데이터를 추출하는 단계를 포함할 수 있다. 일 실시예에서, 단계 630은 매핑 데이터에 기초하여 전처리된 타겟 이미지를 변환하여, 제1 합성 프레임을 생성 하는 단계를 포함할 수 있다. 일 실시예에서, 입력 데이터가 텍스트 및 발화자 정보를 포함하는 경우, 단계 630은 전처리된 데이터에 기초하 여, 제1 합성 비디오를 생성하고, 텍스트 및 발화자 정보에 기초하여 합성 오디오를 생성하며, 텍스트에 기초하 여 제1 합성 비디오에 발화 비디오를 추가하는 단계를 포함할 수 있다. 일 실시예에서, 입력 데이터가 구동 오디오를 포함하는 경우, 단계 630은 전처리된 데이터에 기초하여, 제1 합 성 비디오를 생성하고, 구동 오디오로부터 입 모양 데이터를 추출하여, 제1 합성 비디오에 발화 비디오를 추가 하는 단계를 포함할 수 있다. 일 실시예에서, 제1 합성 비디오에 발화 비디오를 추가하는 단계는, 구동 오디오에 기초하여 멜-스펙트로그램을 생성하고, 멜-스펙트로그램을 분할하여 제1 합성 비디오에 포함된 복수의 프레임 각각에 대응하는 복수의 서브 멜-스펙트로그램을 생성하며, 복수의 프레임 각각으로부터 복수의 얼굴을 검출하고, 복수의 얼굴 및 복수의 서 브 멜-스펙트로그램에 기초하여 복수의 입 모양 데이터를 생성하며, 복수의 프레임 각각에 대응하는 입 모양 데 이터를 덮어쓰는 단계를 포함할 수 있다. 단계 640에서, 프로세서는 합성 비디오를 사용자가 다운로드하기에 적합하도록 후처리할 수 있다. 일 실시예에서, 단계 640은 합성 비디오에 포함된 블러 및 아티팩트를 제거하기 위한 이미지 복원을 수행하는 단계를 포함할 수 있다. 일 실시예에서, 단계 640은 이미지 복원이 수행된 합성 비디오의 포맷을 변환하는 단계를 포함할 수 있다. 일 실시예에서, 입력 데이터가 텍스트 및 발화자 정보를 포함하는 경우, 단계 640은 발화 비디오가 추가된 제1 합성 비디오 및 합성 오디오에 기초하여, 제2 합성 비디오를 생성하는 단계를 포함할 수 있다. 일 실시예에서, 입력 데이터가 구동 오디오를 포함하는 경우, 단계 640은 발화 비디오가 추가된 제1 합성 비디 오 및 구동 오디오에 기초하여 제2 합성 비디오를 생성하는 단계를 포함할 수 있다. 도 7은 본 개시의 일 실시예에 따른 비디오 합성 서비스를 제공하는 장치의 블록도이다. 도 7을 참조하면, 비디오 합성 서비스를 제공하는 장치는 통신부, 프로세서 및 DB를 포함 할 수 있다. 도 7의 비디오 합성 서비스를 제공하는 장치에는 실시예와 관련된 구성요소들만이 도시되어"}
{"patent_id": "10-2022-0180064", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "있다. 따라서, 도 7에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음을 당해 기술분야 의 통상의 기술자라면 이해할 수 있다. 통신부는 외부 서버 또는 외부 장치와 유선/무선 통신을 하게 하는 하나 이상의 구성 요소를 포함할 수 있 다. 예를 들어, 통신부는, 근거리 통신부(미도시), 이동 통신부(미도시) 및 방송 수신부(미도시) 중 적어 도 하나를 포함할 수 있다. DB는 비디오 합성 서비스를 제공하는 장치 내에서 처리되는 각종 데이터들을 저장하는 하드웨어로서, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있다. DB는 결제 정보, 사용자 정보 등을 저 장할 수 있다. DB는 DRAM(dynamic random access memory), SRAM(static random access memory) 등과 같은 RAM(random access memory), ROM(read-only memory), EEPROM(electrically erasable programmable read-only memory), CD-ROM, 블루레이 또는 다른 광학 디스크 스토리지, HDD(hard disk drive), SSD(solid state drive), 또는 플 래시 메모리를 포함할 수 있다. 프로세서는 비디오 합성 서비스를 제공하는 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서 는 DB에 저장된 프로그램들을 실행함으로써, 입력부(미도시), 디스플레이(미도시), 통신부, DB 등을 전반적으로 제어할 수 있다. 프로세서는, DB에 저장된 프로그램들을 실행함으로써, 비 디오 합성 서비스를 제공하는 장치의 동작을 제어할 수 있다. 프로세서는 도 1 내지 도 6에서 상술한 비디오 합성 서비스를 제공하는 장치의 동작 중 적어도 일부 를 제어할 수 있다. 프로세서는 ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서 (microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 일 실시예로, 비디오 합성 서비스를 제공하는 장치는 이동성을 가지는 전자 장치일 수 있다. 예를 들어, 비디오 합성 서비스를 제공하는 장치는 스마트폰, 태블릿 PC, PC, 스마트 TV, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 네비게이션, 카메라가 탑재된 디바이스 및 기타 모바일 전자 장치로 구현 될 수 있다. 또한, 비디오 합성 서비스를 제공하는 장치는 통신 기능 및 데이터 프로세싱 기능을 구비한 시계, 안경, 헤어 밴드 및 반지 등의 웨어러블 장치로 구현될 수 있다. 다른 실시예로, 비디오 합성 서비스를 제공하는 장치는 클라이언트 장치 외부에 위치하는 서버일 수 있다. 서버는 네트워크를 통해 통신하여 명령, 코드, 파일, 컨텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구현될 수 있다. 또 다른 실시예로, 비디오 합성 서비스를 제공하는 장치에서 수행되는 프로세스는 이동성을 가지는 전자 장치 및 클라이언트 장치 외부에 위치하는 서버 중 적어도 일부에 의해 수행될 수 있다. 본 발명에 따른 실시예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같 은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 일 실시예에 따르면, 본 개시의 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들 간에직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 발명이 한정되는 것은 아니 다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위 가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한 다고 할 것이다."}
{"patent_id": "10-2022-0180064", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 비디오 합성 서비스를 제공하는 시스템을 나타내는 도면이다. 도 2는 본 개시의 일 실시예에 따른 서버 장치가 수행하는 동작을 개략적으로 도시하는 도면이다. 도 3은 본 개시의 일 실시예에 따른 입력 데이터를 전처리하는 과정을 개략적으로 도시하는 흐름도이다. 도 4는 본 개시의 일 실시예에 따른 합성 비디오를 생성하는 과정을 개략적으로 도시하는 순서도이다. 도 5는 본 개시의 일 실시예에 따른 합성 비디오를 후처리하는 과정을 개략적으로 도시하는 흐름도이다. 도 6은 본 개시의 일 실시예에 따른 비디오 합성 서비스를 제공하는 방법의 흐름도이다. 도 7은 본 개시의 일 실시예에 따른 비디오 합성 서비스를 제공하는 장치의 블록도이다."}
