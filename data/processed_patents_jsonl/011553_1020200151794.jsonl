{"patent_id": "10-2020-0151794", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0059648", "출원번호": "10-2020-0151794", "발명의 명칭": "그래픽 프로세싱 유닛 프로세싱 및 캐싱 개선", "출원인": "인텔 코포레이션", "발명자": "마이유란, 수브라마니암"}}
{"patent_id": "10-2020-0151794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "방법으로서,미디어 IP(intellectual property)에 의해, 메모리로부터 데이터 단위를 판독하는 단계; 및그래픽 프로세싱 유닛(GPU)의 인공 지능(AI)-특정 코어가 연산하도록 구성되어 있는 상기 데이터 단위 내의 데이터의 각각의 분석 프로세싱 단위에 대해:상기 미디어 IP에 의해, 상기 분석 프로세싱 단위에 대해 미디어 프로세싱을 수행하는 단계;제1 신호에 응답하여, 상기 미디어 IP에 의해, 상기 미디어 프로세싱의 결과를 상기 미디어 IP와 상기AI-특정 코어 사이에 논리적으로 개재된 스트리밍 버퍼에 기입하는 단계;제2 신호를 통해 상기 스트리밍 버퍼 내의 상기 데이터의 이용가능성에 관해 상기 AI-특정 코어에 통지하는 단계;상기 제2 신호에 응답하여, 상기 AI-특정 코어에 의해, 상기 스트리밍 버퍼로부터 상기 데이터를 판독하는 단계;상기 제1 신호를 통해 상기 AI-특정 코어에 의한 상기 데이터의 소비에 관해 상기 미디어 IP에 통지하는 단계;상기 AI-특정 코어에 의해, 상기 데이터에 대해 미디어 분석 프로세싱을 수행하는 단계; 및상기 AI-특정 코어에 의해, 상기 미디어 분석 프로세싱의 결과를 상기 메모리에 기입하는 단계에 의해 상기 미디어 IP와 상기 AI-특정 코어에 의한 병렬 프로세싱을 용이하게 하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0151794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 스트리밍 버퍼는 캐시, 동적 랜덤 액세스 메모리, 컴퓨터 시스템의 시스템 메모리, 또는전용 그래픽 메모리를 포함하는, 방법."}
{"patent_id": "10-2020-0151794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서, 상기 스트리밍 버퍼 내의 상기 데이터의 이용가능성에 관해 상기 AI-특정 코어에통지하는 상기 단계는 상기 스트리밍 버퍼에 의해 수행되는, 방법."}
{"patent_id": "10-2020-0151794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 또는 제2항에 있어서, 상기 스트리밍 버퍼 내의 상기 데이터의 이용가능성에 관해 상기 AI-특정 코어에통지하는 상기 단계는 상기 미디어 IP에 의해 수행되는, 방법."}
{"patent_id": "10-2020-0151794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 또는 제2항에 있어서, 상기 AI-특정 코어에 의한 상기 데이터의 소비에 관해 상기 미디어 IP에 통지하는상기 단계는 상기 스트리밍 버퍼에 의해 수행되는, 방법."}
{"patent_id": "10-2020-0151794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 또는 제2항에 있어서, 상기 AI-특정 코어에 의한 상기 데이터의 소비에 관해 상기 미디어 IP에 통지하는상기 단계는 상기 AI-특정 코어에 의해 수행되는, 방법."}
{"patent_id": "10-2020-0151794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 데이터 단위는 이미지 프레임을 포함하고, 상기 분석 프로세싱 단위는 이미지 프레임의공개특허 10-2021-0059648-3--3-일부를 포함하는, 방법."}
{"patent_id": "10-2020-0151794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 미디어 분석 프로세싱은 인공 지능(AI) 추론들을 수행하는 것을 포함하는, 방법."}
{"patent_id": "10-2020-0151794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항, 제2항, 제7항 및 제8항 중 어느 한 항에 청구된 방법을 수행하는 수단을 포함하는 장치."}
{"patent_id": "10-2020-0151794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "시스템으로서,생산자 IP(intellectual property);계산 코어; 및상기 생산자 IP와 상기 계산 코어 사이에 논리적으로 개재된 스트리밍 버퍼를 포함하고;상기 생산자 IP는 메모리로부터의 데이터를 소비하고 결과들을 상기 스트리밍 버퍼에 출력하도록 동작가능하고;상기 계산 코어는 상기 스트리밍 버퍼로부터 소비되는 데이터에 기초하여 AI 추론 프로세싱을 수행하고 AI 추론프로세싱 결과들을 상기 메모리에 출력하도록 동작가능한, 시스템."}
{"patent_id": "10-2020-0151794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 계산 코어는 중앙 프로세싱 유닛(CPU), 그래픽 프로세싱 유닛(GPU) 또는 AI-특정 코어를포함하는, 시스템."}
{"patent_id": "10-2020-0151794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항 또는 제11항에 있어서, 상기 스트리밍 버퍼는 상기 스트리밍 버퍼가 제1 미리 결정된 또는 구성가능한임계값보다 적은 데이터를 포함할 때 상기 생산자 IP에 통지하도록 동작가능한, 시스템."}
{"patent_id": "10-2020-0151794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항 또는 제11항에 있어서, 상기 스트리밍 버퍼는 상기 스트리밍 버퍼가 제2 미리 결정된 또는 구성가능한임계값보다 많은 데이터를 포함할 때 상기 계산 코어에 통지하도록 동작가능한, 시스템."}
{"patent_id": "10-2020-0151794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서, 상기 생산자 IP는 미디어 IP를 포함하고 상기 계산 코어는 GPU의 AI-특정 코어를 포함하는,시스템."}
{"patent_id": "10-2020-0151794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 미디어 IP와 상기 AI-특정 코어는, 상기 AI-특정 코어에 의한 상기 AI 추론 프로세싱을위한 상기 스트리밍 버퍼에서의 데이터의 분석 프로세싱 단위의 이용가능성을 지시하는 상기 미디어 IP로부터상기 AI-특정 코어로의 제1 핸드셰이크 신호 및 상기 데이터가 상기 AI-특정 코어에 의해 판독된 것을 지시하는상기 AI-특정 코어로부터 상기 미디어 IP로의 제2 핸드셰이크 신호를 포함하는, 핸드셰이크 신호들을 교환하는,시스템."}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 명세서에 설명된 실시예들은 일반적으로 GPU 프로세싱/캐싱에 관한 전력, 레이턴시, 대역폭, 및/또는 성능 문 제들에 관한 개선들에 관한 것이다. 일 실시예에 따르면, 시스템은 생산자 IP(intellectual property)(예를 들 어, 미디어 IP), 계산 코어(예를 들어, GPU 또는 GPU의 AI-특정 코어), 생산자 IP와 계산 코어 사이에 논리적으 로 개재된 스트리밍 버퍼를 포함한다. 생산자 IP는 메모리로부터의 데이터를 소비하고 결과들을 스트리밍 버퍼 에 출력하도록 동작가능하다. 계산 코어는 스트리밍 버퍼로부터 소비되는 데이터에 기초하여 AI 추론 프로세싱 을 수행하고 AI 추론 프로세싱 결과들을 메모리에 출력하도록 동작가능하다. 공개특허10-2021-0059648 -1-공개특허10-2021-0059648 CPC특허분류 G06F 9/30138 (2013.01) G06N 20/00 (2019.01) G06T 1/20 (2013.01) 발명자 레이, 조이딥 미국 95630 캘리포니아주 폴솜 미스티 릿지 서클 727 야누스, 스콧 미국 95650 캘리포니아주 루미스 비스타 드라이브 4670 자하기르다르, 산지브 미국 95630 캘리포니아주 폴솜 스트론세이 코트 1675 인스코, 브렌트 미국 97209 오리건주 포틀랜드 노스웨스트 19번 애 비뉴 550 아파트먼트 313 쉬, 리둥 중국 100190 베이징 하이뎬 디스트릭트 커쉐위안 사우스 로드 넘버 2 레이콤 인포테크 파크 에이 8 층 아푸, 아브히쉐크 알. 미국 95762 캘리포니아주 엘 도라도 힐스 머시아 웨이 8032 홀랜드, 제임스 미국 95630 캘리포니아주 폴솜 프라이리 시티 로드 1900 에프엠5-64랑가나탄, 바산스 미국 95762 캘리포니아주 엘 도라도 힐스 로즈크레 스트 서클 3620 카버라소스, 니코스 미국 95630 캘리포니아주 폴솜 무어 웨이 700 코커, 알투그 미국 95762 캘리포니아주 엘 도라도 힐스 트레비 웨이 8241 톈, 신민 미국 94587 캘리포니아주 유니온 시티 피나클스 코 트 34392 루에, 구에이-유안 미국 95129 캘리포니아주 산 호세 코로나 드라이브 4614 왕, 창량 미국 98008 워싱턴주 벨뷰 노스이스트 156번 애비 뉴 2700 스위트 300 청구범위유예 : 있음 임시명세서출원 : 있음 -2-명 세 서 청구범위 청구항 1 방법으로서, 미디어 IP(intellectual property)에 의해, 메모리로부터 데이터 단위를 판독하는 단계; 및 그래픽 프로세싱 유닛(GPU)의 인공 지능(AI)-특정 코어가 연산하도록 구성되어 있는 상기 데이터 단위 내의 데 이터의 각각의 분석 프로세싱 단위에 대해: 상기 미디어 IP에 의해, 상기 분석 프로세싱 단위에 대해 미디어 프로세싱을 수행하는 단계; 제1 신호에 응답하여, 상기 미디어 IP에 의해, 상기 미디어 프로세싱의 결과를 상기 미디어 IP와 상기 AI-특정 코어 사이에 논리적으로 개재된 스트리밍 버퍼에 기입하는 단계; 제2 신호를 통해 상기 스트리밍 버퍼 내의 상기 데이터의 이용가능성에 관해 상기 AI-특정 코어에 통지 하는 단계; 상기 제2 신호에 응답하여, 상기 AI-특정 코어에 의해, 상기 스트리밍 버퍼로부터 상기 데이터를 판독 하는 단계; 상기 제1 신호를 통해 상기 AI-특정 코어에 의한 상기 데이터의 소비에 관해 상기 미디어 IP에 통지하 는 단계; 상기 AI-특정 코어에 의해, 상기 데이터에 대해 미디어 분석 프로세싱을 수행하는 단계; 및 상기 AI-특정 코어에 의해, 상기 미디어 분석 프로세싱의 결과를 상기 메모리에 기입하는 단계 에 의해 상기 미디어 IP와 상기 AI-특정 코어에 의한 병렬 프로세싱을 용이하게 하는 단계 를 포함하는, 방법. 청구항 2 제1항에 있어서, 상기 스트리밍 버퍼는 캐시, 동적 랜덤 액세스 메모리, 컴퓨터 시스템의 시스템 메모리, 또는 전용 그래픽 메모리를 포함하는, 방법. 청구항 3 제1항 또는 제2항에 있어서, 상기 스트리밍 버퍼 내의 상기 데이터의 이용가능성에 관해 상기 AI-특정 코어에 통지하는 상기 단계는 상기 스트리밍 버퍼에 의해 수행되는, 방법. 청구항 4 제1항 또는 제2항에 있어서, 상기 스트리밍 버퍼 내의 상기 데이터의 이용가능성에 관해 상기 AI-특정 코어에 통지하는 상기 단계는 상기 미디어 IP에 의해 수행되는, 방법. 청구항 5 제1항 또는 제2항에 있어서, 상기 AI-특정 코어에 의한 상기 데이터의 소비에 관해 상기 미디어 IP에 통지하는 상기 단계는 상기 스트리밍 버퍼에 의해 수행되는, 방법. 청구항 6 제1항 또는 제2항에 있어서, 상기 AI-특정 코어에 의한 상기 데이터의 소비에 관해 상기 미디어 IP에 통지하는 상기 단계는 상기 AI-특정 코어에 의해 수행되는, 방법. 청구항 7 제1항에 있어서, 상기 데이터 단위는 이미지 프레임을 포함하고, 상기 분석 프로세싱 단위는 이미지 프레임의-3-일부를 포함하는, 방법. 청구항 8 제1항에 있어서, 상기 미디어 분석 프로세싱은 인공 지능(AI) 추론들을 수행하는 것을 포함하는, 방법. 청구항 9 제1항, 제2항, 제7항 및 제8항 중 어느 한 항에 청구된 방법을 수행하는 수단을 포함하는 장치. 청구항 10 시스템으로서, 생산자 IP(intellectual property); 계산 코어; 및 상기 생산자 IP와 상기 계산 코어 사이에 논리적으로 개재된 스트리밍 버퍼 를 포함하고; 상기 생산자 IP는 메모리로부터의 데이터를 소비하고 결과들을 상기 스트리밍 버퍼에 출력하도록 동작가능하고; 상기 계산 코어는 상기 스트리밍 버퍼로부터 소비되는 데이터에 기초하여 AI 추론 프로세싱을 수행하고 AI 추론 프로세싱 결과들을 상기 메모리에 출력하도록 동작가능한, 시스템. 청구항 11 제10항에 있어서, 상기 계산 코어는 중앙 프로세싱 유닛(CPU), 그래픽 프로세싱 유닛(GPU) 또는 AI-특정 코어를 포함하는, 시스템. 청구항 12 제10항 또는 제11항에 있어서, 상기 스트리밍 버퍼는 상기 스트리밍 버퍼가 제1 미리 결정된 또는 구성가능한 임계값보다 적은 데이터를 포함할 때 상기 생산자 IP에 통지하도록 동작가능한, 시스템. 청구항 13 제10항 또는 제11항에 있어서, 상기 스트리밍 버퍼는 상기 스트리밍 버퍼가 제2 미리 결정된 또는 구성가능한 임계값보다 많은 데이터를 포함할 때 상기 계산 코어에 통지하도록 동작가능한, 시스템. 청구항 14 제10항에 있어서, 상기 생산자 IP는 미디어 IP를 포함하고 상기 계산 코어는 GPU의 AI-특정 코어를 포함하는, 시스템. 청구항 15 제14항에 있어서, 상기 미디어 IP와 상기 AI-특정 코어는, 상기 AI-특정 코어에 의한 상기 AI 추론 프로세싱을 위한 상기 스트리밍 버퍼에서의 데이터의 분석 프로세싱 단위의 이용가능성을 지시하는 상기 미디어 IP로부터 상기 AI-특정 코어로의 제1 핸드셰이크 신호 및 상기 데이터가 상기 AI-특정 코어에 의해 판독된 것을 지시하는 상기 AI-특정 코어로부터 상기 미디어 IP로의 제2 핸드셰이크 신호를 포함하는, 핸드셰이크 신호들을 교환하는, 시스템. 발명의 설명"}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원들에 대한 상호 참조 본 출원은 2019년 11월 15일자로 출원된 미국 가출원 제62/935,729호의 이익을 주장하며, 그 전체가 이로써 모"}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "든 목적을 위해 참조로 통합된다.-4-기술분야 본 명세서에 설명된 실시예들은 일반적으로 그래픽 프로세싱 유닛(GPU) 분야에 관한 것으로, 특히, GPU 프로세 싱/캐싱에 관한 전력, 레이턴시, 대역폭 및/또는 성능 문제들에 관한 개선들에 관한 것이다."}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재의 GPU 프로세싱 시나리오들 및 캐싱 아키텍처들은 전력, 레이턴시, 대역폭 및/또는 성능 문제들을 나타낸 다. 예를 들어, 현재 원자 감소(atomic reduction)(히스토그램 유사 애플리케이션들(histogram like applications)에서 사용되는 일종의 연산)는 한 곳에서(예를 들어, 공유 로컬 메모리(SLM)에서 또는 L3 캐시에 서) 수행/유지되고 대역폭을 소비하며 레이턴시를 생성한다. 컴퓨터 그래픽 이미지 또는 비디오가 광학 공간에서 규칙적인 그리드로 세분된 다음에 그리드의 각각의 섹션, 또는 타일을 개별적으로 렌더링하는 타일형 렌더링(tiled rendering)의 맥락에서, 전체 프레임을 한번에 그리는 즉시 모드 렌더링 시스템들에 비해 메모리의 양과 대역폭이 감소된다는 이점이 있다. 그러나, 예를 들어, 인공 지능(AI) 추론들에 사용될 때, 비디오 타이틀들의 이러한 사용 모델은 단점들을 갖는다. 비디오 타일들은 크고 픽셀들은 동적 랜덤 액세스 메모리(DRAM)에 기입되며, 이것은 그 다음에 AI 추론과 같은 사용들을 위해 메모리 로부터 GPU로 되판독(read back)된다. 이것은 엄청난 대역폭 및 레이턴시 비용으로 이어진다. 이제 다양한 캐싱 시나리오들로 돌아가면, 통상적으로, 중간-레벨 캐시가 중앙 패브릭(central fabric)의 일부 인 다수의 지적 재산(intellectual property, IP) 코어들에 의해 공유된다. 그러나, 단일 IP 코어(예를 들어, 미디어 IP 코어)가 다른 IP 코어들과 통신할 필요가 없고 그 자체로 독립형 작업부하들인 특정 작업부하들(예를 들어, 미디어 디코드/인코드/트랜스 코드)에 작용하는 경우, 이러한 경우에 이 중앙 패브릭을 통과하여 중간-레 벨 캐시와 소통하는 것은, 캐시 전력뿐만 아니라 중앙 패브릭 전력도 발생시킬 것이며, 따라서 작업부하에 대한 시스템 온 칩(system on a chip, SoC) 전력에 불이익을 주고 배터리 수명에 영향을 미친다. GPU의 마지막-레벨 캐시(last-level cache, LLC)(예를 들어, L3 또는 L2 캐시)는 전역적 자원이므로 많은 전력 을 소비하고 높은 평균 레이턴시를 발생시킨다. GPU의 크기가 커짐에 따라, LLC는 셰이더 코어(shader core)들 로부터 더 멀리 떨어지므로, 전력과 레이턴시 둘 다를 증가시킨다. 이것은 더 큰 GPU들의 성능 확장성 (performance scalability)을 손상시킨다."}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 설명된 실시예들은 일반적으로 GPU 프로세싱/캐싱에 관한 전력, 레이턴시, 대역폭 및 성능 문제들 에 관한 개선들에 관한 것이다. 위에 언급한 바와 같이, 현재, 원자 감소(히스토그램 유사 애플리케이션들에서 사용되는 일종의 연산)는 공유 로컬 메모리(SLM)에서 또는 L3 캐시에서 수행된다; 그러나, 현재 원자 감소 접근법은 한 곳에서 수행/유지되고 대역폭을 소비하며 레이턴시를 생성한다. 미디어와 GPU가 캐시를 공유하며 미디어가 이 캐시를 통해 메모리에 기입하지만, GPU가 캐시 히트(cache hit)를 통해 필요한 데이터를 찾을 가능성이 있으므로 일부 DRAM 대역폭을 감소시킨다; 그러나, 일부 다른 트래픽은 GPU가 원하는 캐시 라인들을 축출(evict)할 수 있기 때문에 항상 캐시 히트가 있다는 보장은 없다. 독립형 IP 코어들의 맥락에서, 그것들은 다른 IP 코어들과 공유할 필요가 없는 특정 시나리오들에서 그 자신의 -6-내부 캐시를 가질 수 있고 중간-레벨 캐시를 우회하고 패브릭을 통해 메모리로 횡단(traversing)하는 비-스누프 (non-snoop) 경로를 취할 수 있다. 이러한 접근법의 단점은, IP 코어 내부의 추가적인 캐시 구조가 필요하고 이는 면적 비용(area cost)을 발생시킨다는 점이다. 둘째로, IP 코어가 중간-레벨 캐시를 사용하지 않는지와 무관하게 메인 메모리에 액세스하기 위해 중앙 패브릭을 계속 거치게 되어, 중앙 패브릭을 웨이크 업하는 (waking up) 결과를 가져온다. 결과적으로, 중앙 패브릭은 완전히 셧오프(shut off)될 수 없고, 따라서 그러한 작업부하들에 대해 더 높은 전체 SoC 전력에 반영되는 추가의 전력을 소비한다. LLC의 전력을 감소시키기 위한 양호한 이전의 해결책은 없다. 완화하는 한 가지 방식은 (LLC로의 트래픽을 감 소시키기 위해) 상위 레벨 캐시들을 더 크게 만드는 것이지만, 그것은 면적을 증가시키고 다수의 캐시들에 걸쳐 데이터 복제(data replication)를 야기한다. 이와 같이, 더 큰 GPU들의 성능 스케일링(performance scaling) 은 현재 제한된다. 시스템 개요 도 1은 본 명세서에 설명된 실시예들의 하나 이상의 양태를 구현하도록 구성되는 컴퓨팅 시스템을 도시하 는 블록도이다. 컴퓨팅 시스템은 메모리 허브를 포함할 수 있는 상호접속 경로를 통해 통신하는 하 나 이상의 프로세서(들)와 시스템 메모리를 갖는 프로세싱 서브시스템을 포함한다. 메모리 허 브는 칩셋 컴포넌트 내의 별도의 컴포넌트일 수 있거나 또는 하나 이상의 프로세서(들) 내에 통합될 수 있다. 메모리 허브는 통신 링크를 통해 I/O 서브시스템과 결합된다. I/O 서브시스템 은 컴퓨팅 시스템이 하나 이상의 입력 디바이스(들)로부터 입력을 수신할 수 있게 할 수 있는 I/O 허 브를 포함한다. 추가적으로, I/O 허브는, 하나 이상의 프로세서(들)에 포함될 수 있는 디스플 레이 컨트롤러가 하나 이상의 디스플레이 디바이스(들)(110A)에 출력들을 제공하게 할 수 있다. 일 실시예에서, I/O 허브와 결합된 하나 이상의 디스플레이 디바이스(들)(110A)는 로컬, 내부, 또는 내장형 디스플레이 디바이스를 포함할 수 있다. 예를 들어, 프로세싱 서브시스템은 버스 또는 다른 통신 링크를 통해 메모리 허브에 결합된 하 나 이상의 병렬 프로세서(들)를 포함한다. 통신 링크는 PCI 익스프레스(PCI Express)와 같은, 그러 나 이에 제한되지 않는, 임의의 수의 표준-기반 통신 링크 기술들 또는 프로토콜들 중 하나일 수 있거나, 또는 벤더 특정 통신 인터페이스 또는 통신 패브릭일 수 있다. 하나 이상의 병렬 프로세서(들)는 MIC(many integrated core) 프로세서와 같은 많은 수의 프로세싱 코어들 및/또는 프로세싱 클러스터들을 포함할 수 있는 계산적으로 집중된 병렬 또는 벡터 프로세싱 시스템을 형성할 수 있다. 예를 들어, 하나 이상의 병렬 프로세서 (들)는 I/O 허브를 통해 결합된 하나 이상의 디스플레이 디바이스(들)(110A) 중 하나에 픽셀들을 출 력할 수 있는 그래픽 프로세싱 서브시스템을 형성한다. 하나 이상의 병렬 프로세서(들)는 또한 하나 이상 의 디스플레이 디바이스(들)(110B)로의 직접 접속을 가능하게 하는 디스플레이 컨트롤러 및 디스플레이 인터페 이스(도시되지 않음)를 포함할 수 있다. I/O 서브시스템 내에서, 시스템 스토리지 유닛이 컴퓨팅 시스템에 대한 스토리지 메커니즘을 제 공하기 위해 I/O 허브에 접속할 수 있다. I/O 스위치는, I/O 허브와 다른 컴포넌트들, 예컨대, 플랫폼에 통합될 수 있는 네트워크 어댑터 및/또는 무선 네트워크 어댑터, 및 하나 이상의 애드-인 디바이스(들)를 통해 추가될 수 있는 다양한 다른 디바이스들 사이의 접속들을 가능하게 하기 위한 인터페 이스 메커니즘을 제공하기 위해 사용될 수 있다. 애드-인 디바이스(들)는 또한, 예를 들어, 하나 이상의 외부 그래픽 프로세서 디바이스, 그래픽 카드, 및/또는 계산 가속기(compute accelerator)를 포함할 수 있다. 네트워크 어댑터는 이더넷 어댑터 또는 다른 유선 네트워크 어댑터일 수 있다. 무선 네트워크 어댑터 는 Wi-Fi, 블루투스, NFC(near field communication), 또는 하나 이상의 무선 라디오를 포함하는 다른 네 트워크 디바이스 중 하나 이상을 포함할 수 있다. 컴퓨팅 시스템은 USB 또는 다른 포트 접속들, 광학 스토리지 드라이브들, 비디오 캡처 디바이스들 등을 포 함하고 또한 I/O 허브에 접속될 수 있는, 명시적으로 도시되지 않은, 다른 컴포넌트들을 포함할 수 있다. 도 1의 다양한 컴포넌트들을 상호접속하는 통신 경로들은 임의의 적절한 프로토콜들, 예컨대 PCI(Peripheral Component Interconnect) 기반 프로토콜들(예를 들어, PCI-Express), 또는 임의의 다른 버스 또는 점대점 통신 인터페이스들 및/또는 프로토콜(들), 예컨대 NVLink 고속 인터커넥트, CXL™(Compute Express Link™)(예를 들 어, CXL.mem), IF(Infinity Fabric), 이더넷(IEEE 802.3), RDMA(remote direct memory access), InfiniBand, iWARP(Internet Wide Area RDMA Protocol), TCP(Transmission Control Protocol), UDP(User Datagram Protocol), QUIC(quick UDP Internet Connections), RoCE(RDMA over Converged Ethernet), 인텔-7-QPI(QuickPath Interconnect), 인텔 UPI(Ultra Path Interconnect), IOSF(Intel On-Chip System Fabric), Omnipath, HyperTransport, AMBA(Advanced Microcontroller Bus Architecture) 인터커넥트, OpenCAPI, Gen-Z, CCIX(Cache Coherent Interconnect for Accelerators), 3GPP LTE(Long Term Evolution)(4G), 3GPP 5G, 및 그"}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "의 변형들, 또는 이 기술분야에 알려진 유선 또는 무선 인터커넥트 프로토콜들을 사용하여 구현될 수 있다. 일 부 예들에서, 데이터는 NVMe-oF(non-volatile memory express (NVMe) over Fabrics) 또는 NVMe와 같은 프로토 콜을 사용하여 가상화된 스토리지 노드들에 복사되거나 저장될 수 있다. 하나 이상의 병렬 프로세서(들)는, 예를 들어, 비디오 출력 회로를 포함하는, 그래픽 및 비디오 프로세싱 에 최적화된 회로를 통합할 수 있고, 그래픽 프로세싱 유닛(GPU)을 구성한다. 대안적으로 또는 추가적으로, 하 나 이상의 병렬 프로세서(들)는, 본 명세서에서 더 상세히 설명되는, 기저 계산 아키텍처를 보존하면서, 범용 프로세싱에 최적화된 회로를 통합할 수 있다. 컴퓨팅 시스템의 컴포넌트들은 단일 집적 회로 상의 하나 이상의 다른 시스템 요소와 통합될 수 있다. 예를 들어, 하나 이상의 병렬 프로세서(들), 메모리 허 브, 프로세서(들), 및 I/O 허브는 시스템 온 칩(system on chip, SoC) 집적 회로에 통합될 수 있다. 대안적으로, 컴퓨팅 시스템의 컴포넌트들은 SIP(system in package) 구성을 형성하기 위해 단일 패 키지에 통합될 수 있다. 일 실시예에서, 컴퓨팅 시스템의 컴포넌트들의 적어도 일부는, 모듈러 컴퓨팅 시 스템 내로 다른 멀티-칩 모듈들과 상호접속될 수 있는, 멀티-칩 모듈(MCM) 내로 통합될 수 있다. 본 명세서에 도시된 컴퓨팅 시스템은 예시적이며, 변형들 및 수정들이 가능하다는 것을 이해할 것이다. 브리지들의 수 및 배열, 프로세서(들)의 수, 및 병렬 프로세서(들)의 수를 포함하는 접속 토폴로지는 원하는 대로 수정될 수 있다. 예를 들어, 시스템 메모리는 브리지를 통하기보다는 직접적으로 프로세서 (들)에 접속될 수 있고, 다른 디바이스들은 메모리 허브 및 프로세서(들)를 통해 시스템 메모리 와 통신한다. 다른 대안적인 토폴로지들에서, 병렬 프로세서(들)는 메모리 허브가 아니라, I/O 허브에 또는 하나 이상의 프로세서(들) 중 하나에 직접적으로 접속된다. 다른 실시예들에서, I/O 허 브 및 메모리 허브는 단일 칩에 통합될 수 있다. 프로세서(들)의 둘 이상의 세트가 병렬 프로 세서(들)의 둘 이상의 인스턴스와 결합될 수 있는 다수의 소켓들을 통해 부착되는 것이 또한 가능하다. 본 명세서에 도시된 특정 컴포넌트들 중 일부는 선택적이며, 컴퓨팅 시스템의 모든 구현들에 포함되지 않 을 수 있다. 예를 들어, 임의의 수의 애드-인 카드들 또는 주변기기들이 지원될 수 있거나, 또는 일부 컴포넌 트들이 제거될 수 있다. 또한, 일부 아키텍처들은 도 1에 예시된 것들과 유사한 컴포넌트들에 대해 상이한 용 어를 사용할 수 있다. 예를 들어, 메모리 허브는 일부 아키텍처들에서 노스브리지(Northbridge)로 지칭될 수 있고, I/O 허브는 사우스브리지(Southbridge)로 지칭될 수 있다. 도 2a는 병렬 프로세서를 도시한다. 병렬 프로세서는 본 명세서에 설명된 바와 같은 GPU, GPGPU 등 일 수 있다. 병렬 프로세서의 다양한 컴포넌트들은 프로그램가능 프로세서, ASIC(application specific integrated circuit), 또는 FPGA(field programmable gate array)와 같은 하나 이상의 집적 회로 디바이스를 사용하여 구현될 수 있다. 예시된 병렬 프로세서는 도 1에 도시된 병렬 프로세서(들) 중 하나 이상 일 수 있다. 병렬 프로세서는 병렬 프로세싱 유닛을 포함한다. 병렬 프로세싱 유닛은 병렬 프로세싱 유닛의 다른 인스턴스들을 포함하는 다른 디바이스들과의 통신을 가능하게 하는 I/O 유닛을 포함한다. I/O 유닛 은 다른 디바이스들에 직접 접속될 수 있다. 예를 들어, I/O 유닛은, 메모리 허브와 같은 허브 또는 스위치 인터페이스의 사용을 통해 다른 디바이스들과 접속한다. 메모리 허브와 I/O 유닛 사이 의 접속들은 통신 링크를 형성한다. 병렬 프로세싱 유닛 내에서, I/O 유닛은 호스트 인터페이 스 및 메모리 크로스바와 접속하고, 여기서 호스트 인터페이스는 프로세싱 연산들을 수행하는 것에 관한 커맨드들을 수신하고 메모리 크로스바는 메모리 연산들을 수행하는 것에 관한 커맨드들을 수신 한다. 호스트 인터페이스가 I/O 유닛을 통해 커맨드 버퍼를 수신할 때, 호스트 인터페이스는 프론트 엔드에 이 커맨드들을 수행하라고 작업 연산들을 지시할 수 있다. 일 실시예에서, 프론트 엔드는, 커맨드들 또는 다른 작업 항목들을 프로세싱 클러스터 어레이에 분배하도록 구성되는 스케줄러와 결 합된다. 스케줄러는, 프로세싱 클러스터 어레이가 제대로 구성되고 태스크들이 프로세싱 클러스터 어레이의 프로세싱 클러스터들에 분배되기 전에 유효 상태에 있도록 보장한다. 스케줄러는 마이크로 컨트롤러 상에서 실행되는 펌웨어 로직을 통해 구현될 수 있다. 마이크로컨트롤러로 구현되는 스케줄러는, 복잡한 스케줄링 및 작업 분배 동작들을 조대 및 미세 입도(coarse and fine granularity)로-8-수행하여 프로세싱 클러스터 어레이 상에서 실행되는 스레드들의 빠른 선점 및 컨텍스트 스위칭을 가능하 게 하도록 구성가능하다. 바람직하게는, 호스트 소프트웨어는 다수의 그래픽 프로세싱 도어벨들 중 하나를 통 해 프로세싱 클러스터 어레이 상에서 스케줄링하기 위한 작업부하들을 증명할 수 있다. 다른 예들에서, 새로운 작업부하들 또는 인터럽트들에 대한 폴링(polling)을 사용하여 수행할 작업의 이용가능성을 식별하거나 표시할 수 있다. 이어서 작업부하들은 스케줄러 마이크로컨트롤러 내의 스케줄러 로직에 의해 프로세싱 클러스터 어레이에 걸쳐 자동으로 분배될 수 있다. 프로세싱 클러스터 어레이는 최대 \"N\"개의 프로세싱 클러스터(예를 들어, 클러스터(214A), 클러스터 (214B), 내지 클러스터(214N))를 포함할 수 있다. 프로세싱 클러스터 어레이의 각각의 클러스터(214A- 214N)는 많은 수의 동시 스레드들을 실행할 수 있다. 스케줄러는 각각의 타입의 프로그램 또는 계산에 대 해 발생하는 작업부하에 따라 달라질 수 있는 다양한 스케줄링 및/또는 작업 분배 알고리즘들을 사용하여 프로 세싱 클러스터 어레이의 클러스터들(214A-214N)에 작업을 할당할 수 있다. 스케줄링은 스케줄러에 의해 동적으로 핸들링될 수 있거나, 또는 프로세싱 클러스터 어레이에 의한 실행을 위해 구성된 프로그램 로직의 컴파일 동안 컴파일러 로직에 의해 부분적으로 보조(assist)될 수 있다. 선택적으로, 프로세싱 클러스 터 어레이의 상이한 클러스터들(214A-214N)은 상이한 타입들의 프로그램들을 프로세싱하거나 상이한 타입 들의 계산들을 수행하기 위해 할당될 수 있다. 프로세싱 클러스터 어레이는 다양한 타입들의 병렬 프로세싱 연산들을 수행하도록 구성될 수 있다. 예를 들어, 프로세싱 클러스터 어레이는 범용 병렬 계산 연산들을 수행하도록 구성된다. 예를 들어, 프로세싱 클러스터 어레이는 비디오 및/또는 오디오 데이터의 필터링, 물리 연산들을 포함하는 모델링 연산들의 수 행, 및 데이터 변환들의 수행을 포함하는 프로세싱 태스크들을 실행하는 로직을 포함할 수 있다. 프로세싱 클러스터 어레이는 병렬 그래픽 프로세싱 연산들을 수행하도록 구성된다. 병렬 프로세서가 그래픽 프로세싱 연산들을 수행하도록 구성되는 이러한 실시예들에서, 프로세싱 클러스터 어레이는, 텍스 처 연산들을 수행하는 텍스처 샘플링 로직뿐만 아니라 테셀레이션 로직(tessellation logic) 및 다른 정점 프로 세싱 로직을 포함하지만 이에 제한되지 않는, 이러한 그래픽 프로세싱 연산들의 실행을 지원하는 추가적인 로직 을 포함할 수 있다. 추가적으로, 프로세싱 클러스터 어레이는, 정점 셰이더, 테셀레이션 셰이더, 지오메 트리 셰이더, 및 픽셀 셰이더와 같은, 그러나 이에 제한되지 않는, 그래픽 프로세싱 관련 셰이더 프로그램들을 실행하도록 구성될 수 있다. 병렬 프로세싱 유닛은 프로세싱을 위해 I/O 유닛을 통해 시스템 메모리 로부터 데이터를 전송할 수 있다. 프로세싱 동안, 전송된 데이터는 프로세싱 동안 온-칩 메모리(예를 들어, 병 렬 프로세서 메모리)에 저장되고, 이후 시스템 메모리에 라이트백(write back)될 수 있다. 병렬 프로세싱 유닛이 그래픽 프로세싱을 수행하기 위해 사용되는 실시예들에서, 스케줄러는 프로세 싱 클러스터 어레이의 다수의 클러스터들(214A-214N)에 그래픽 프로세싱 연산들을 더 양호하게 분배할 수 있게 하기 위해 프로세싱 작업부하를 대략 동일한 크기의 태스크들로 분할하도록 구성될 수 있다. 이러한 실시 예들 중 일부에서, 프로세싱 클러스터 어레이의 부분들은 상이한 타입들의 프로세싱을 수행하도록 구성될 수 있다. 예를 들어, 디스플레이를 위한 렌더링된 이미지를 생성하기 위해, 제1 부분은 정점 셰이딩 및 토폴로 지 생성을 수행하도록 구성될 수 있고, 제2 부분은 테셀레이션 및 지오메트리 셰이딩을 수행하도록 구성될 수 있고, 제3 부분은 픽셀 셰이딩 또는 다른 스크린 공간 연산들을 수행하도록 구성될 수 있다. 클러스터들(214A- 214N) 중 하나 이상에 의해 생성되는 중간 데이터는, 중간 데이터가 추가 프로세싱을 위해 클러스터들(214A- 214N) 사이에서 송신될 수 있게 하기 위해 버퍼들에 저장될 수 있다. 동작 동안, 프로세싱 클러스터 어레이는 스케줄러를 통해 실행될 프로세싱 태스크들을 수신할 수 있 고, 스케줄러는 프론트 엔드로부터 프로세싱 태스크들을 정의하는 커맨드들을 수신한다. 그래픽 프 로세싱 연산들의 경우, 프로세싱 태스크들은 프로세싱될 데이터, 예를 들어, 표면 (패치) 데이터, 프리미티브 데이터(primitive data), 정점 데이터, 및/또는 픽셀 데이터의 인덱스들뿐만 아니라, 데이터가 어떻게 프로세싱 되는지(예를 들어, 어떤 프로그램이 실행되는지)를 정의하는 상태 파라미터들 및 커맨드들을 포함할 수 있다. 스케줄러는 태스크들에 대응하는 인덱스들을 페치하도록 구성될 수 있거나 또는 프론트 엔드로부터 인덱스들을 수신할 수 있다. 프론트 엔드는, 착신 커맨드 버퍼들(incoming command buffers)(예를 들어, 배치-버퍼들(batch-buffers), 푸시 버퍼들(push buffers) 등)에 의해 특정된 작업부하가 개시되기 전에 유효 상 태로 프로세싱 클러스터 어레이가 구성되는 것을 보장하도록 구성될 수 있다. 병렬 프로세싱 유닛의 하나 이상의 인스턴스 각각은 병렬 프로세서 메모리와 결합할 수 있다. 병렬 프로세서 메모리는, 프로세싱 클러스터 어레이뿐만 아니라 I/O 유닛으로부터 메모리 요청들을-9-수신할 수 있는 메모리 크로스바를 통해 액세스될 수 있다. 메모리 크로스바는 메모리 인터페이스 를 통해 병렬 프로세서 메모리에 액세스할 수 있다. 메모리 인터페이스는 병렬 프로세서 메모 리의 일부분(예를 들어, 메모리 유닛)에 각각 결합될 수 있는 다수의 파티션 유닛들(예를 들어, 파티션 유 닛(220A), 파티션 유닛(220B), 내지 파티션 유닛(220N))을 포함할 수 있다. 제1 파티션 유닛(220A)은 대응하는 제1 메모리 유닛(224A)을 갖고, 제2 파티션 유닛(220B)은 대응하는 제2 메모리 유닛(224B)을 갖고, 제N 파티션 유닛(220N)은 대응하는 제N 메모리 유닛(224N)을 갖도록, 파티션 유닛들(220A-220N)의 수는 메모리 유닛들의 수 와 동일하도록 구성될 수 있다. 다른 실시예들에서, 파티션 유닛들(220A-220N)의 수는 메모리 디바이스들의 수 와 동일하지 않을 수 있다. 메모리 유닛들(224A-224N)은, 그래픽 더블 데이터 레이트(graphics double data rate, GDDR) 메모리를 포함하 는, 동기식 그래픽 랜덤 액세스 메모리(synchronous graphics random access memory, SGRAM)와 같은, 그래픽 랜덤 액세스 메모리 또는 동적 랜덤 액세스 메모리(DRAM)를 포함하는 다양한 타입들의 메모리 디바이스들을 포 함할 수 있다. 선택적으로, 메모리 유닛들(224A-224N)은 또한 고대역폭 메모리(high bandwidth memory, HBM)"}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "를 포함하지만 이에 제한되지 않는 3D 스택형 메모리를 포함할 수 있다. 본 기술분야의 통상의 기술자들은 메 모리 유닛들(224A-224N)의 특정 구현이 달라질 수 있고, 다양한 종래의 설계들 중 하나로부터 선택될 수 있다는 것을 이해할 것이다. 프레임 버퍼들 또는 텍스처 맵들과 같은 렌더 타겟(render target)들은 메모리 유닛들 (224A-224N)에 걸쳐 저장될 수 있으므로, 파티션 유닛들(220A-220N)이 병렬 프로세서 메모리의 이용가능한 대역폭을 효율적으로 사용하기 위해 각각의 렌더 타겟의 부분들을 병렬로 기입할 수 있게 한다. 일부 실시예들 에서, 병렬 프로세서 메모리의 로컬 인스턴스는 로컬 캐시 메모리와 함께 시스템 메모리를 이용하는 통합 메모리 설계(unified memory design)를 위해 배제될 수 있다. 선택적으로, 프로세싱 클러스터 어레이의 클러스터들(214A-214N) 중 임의의 하나는 병렬 프로세서 메모리 내의 메모리 유닛들(224A-224N) 중 임의의 것에 기입될 데이터를 프로세싱하는 능력을 갖는다. 메모리 크로스바는, 각각의 클러스터(214A-214N)의 출력을, 출력에 대해 추가적인 프로세싱 연산들을 수행할 수 있는 임의의 파티션 유닛(220A-220N) 또는 다른 클러스터(214A-214N)에 전송하도록 구성될 수 있다. 각각의 클 러스터(214A-214N)는 다양한 외부 메모리 디바이스들로부터 판독하거나 그에 기입하기 위해 메모리 크로스바 를 통해 메모리 인터페이스와 통신할 수 있다. 메모리 크로스바를 갖는 실시예들 중 하나에서, 메모리 크로스바는 I/O 유닛과 통신하기 위한 메모리 인터페이스에의 접속뿐만 아니라, 병렬 프 로세서 메모리의 로컬 인스턴스에의 접속을 가지므로, 상이한 프로세싱 클러스터들(214A-214N) 내의 프로 세싱 유닛들이 시스템 메모리 또는 병렬 프로세싱 유닛에 로컬이 아닌 다른 메모리와 통신할 수 있게 한다. 일반적으로, 메모리 크로스바는, 예를 들어, 클러스터들(214A-214N)과 파티션 유닛들(220A-220N) 사이에 트래픽 스트림들을 분리하기 위해 가상 채널들을 사용가능할 수 있다. 병렬 프로세싱 유닛의 단일 인스턴스가 병렬 프로세서 내에 도시되어 있지만, 병렬 프로세싱 유닛 의 임의의 수의 인스턴스들이 포함될 수 있다. 예를 들어, 병렬 프로세싱 유닛의 다수의 인스턴스들 이 단일 애드-인 카드 상에 제공될 수 있거나, 또는 다수의 애드-인 카드들이 상호접속될 수 있다. 예를 들어, 병렬 프로세서는, 하나 이상의 GPU, 하나 이상의 메모리 디바이스, 및 디바이스-투-디바이스 또는 네트워 크 또는 패브릭 인터페이스들을 포함하는 개별 그래픽 카드와 같은 그래픽 카드일 수 있는, 도 1의 애드-인 디 바이스와 같은 애드-인 디바이스일 수 있다. 병렬 프로세싱 유닛의 상이한 인스턴스들은 상이한 인 스턴스들이 상이한 수의 프로세싱 코어들, 상이한 양의 로컬 병렬 프로세서 메모리, 및/또는 다른 구성 차이들 을 갖더라도 상호-동작하도록 구성될 수 있다. 선택적으로, 병렬 프로세싱 유닛의 일부 인스턴스들은 다 른 인스턴스들에 비해 더 높은 정밀도 부동 소수점 유닛들을 포함할 수 있다. 병렬 프로세서 또는 병렬 프로세싱 유닛의 하나 이상의 인스턴스를 통합하는 시스템들은 데스크톱, 랩톱, 또는 핸드헬드 개인용 컴 퓨터들, 서버들, 워크스테이션들, 게임 콘솔들, 및/또는 내장형 시스템들을 포함하지만 이에 제한되지 않는 다 양한 구성들 및 폼 팩터들로 구현될 수 있다. 오케스트레이터(orchestrator)는 분해된(disaggregated) 프로세 서 자원들, 캐시 자원들, 메모리 자원들, 스토리지 자원들, 및 네트워킹 자원들 중 하나 이상을 사용하여 작업 부하 성능에 대한 복합 노드들(composite nodes)을 형성할 수 있다. 도 2b는 파티션 유닛의 블록도이다. 파티션 유닛은 도 2a의 파티션 유닛들(220A-220N) 중 하나의 파 티션 유닛의 인스턴스일 수 있다. 도시된 바와 같이, 파티션 유닛은 L2 캐시, 프레임 버퍼 인터페이 스, 및 ROP(래스터 연산 유닛)을 포함한다. L2 캐시는 메모리 크로스바 및 ROP로부 터 수신된 로드 및 스토어 연산들을 수행하도록 구성되는 판독/기입 캐시이다. 판독 미스들(read misses) 및 긴급 라이트-백 요청들(urgent write-back requests)은 L2 캐시에 의해 프로세싱을 위해 프레임 버퍼 인-10-터페이스에 출력된다. 업데이트들은 또한 프로세싱을 위해 프레임 버퍼 인터페이스를 통해 프레임 버퍼에 전송될 수 있다. 일 실시예에서, 프레임 버퍼 인터페이스는 (예를 들어, 병렬 프로세서 메모리 내의) 도 2a의 메모리 유닛들(224A-224N)과 같은 병렬 프로세서 메모리 내의 메모리 유닛들 중 하나와 인 터페이스한다. 파티션 유닛은 추가적으로 또는 대안적으로 메모리 컨트롤러(도시되지 않음)를 통해 병렬 프로세서 메모리 내의 메모리 유닛들 중 하나와 또한 인터페이스할 수 있다. 그래픽 애플리케이션들에서, ROP는 스텐실, z 테스트, 블렌딩 등과 같은 래스터 연산들을 수행하는 프로세 싱 유닛이다. 다음에, ROP는 그래픽 메모리에 저장되는 프로세싱된 그래픽 데이터를 출력한다. 일부 실 시예들에서, ROP는 메모리 또는 L2 캐시에 기입되는 깊이 또는 컬러 데이터를 압축하고 메모리 또는 L2 캐시로부터 판독되는 깊이 또는 컬러 데이터를 압축해제(decompress)하는 압축 로직을 포함하는 코덱 (CODEC)을 포함하거나 이와 결합한다. 압축 로직은 다수의 압축 알고리즘 중 하나 이상을 사용하는 무손 실 압축 로직일 수 있다. 코덱에 의해 수행되는 압축의 타입은 압축될 데이터의 통계적 특성들에 기초하 여 달라질 수 있다. 예를 들어, 일 실시예에서, 델타 컬러 압축은 타일-당 기반으로(on a per-tile basis) 깊 이 및 컬러 데이터에 대해 수행된다. 일 실시예에서, 코덱은 머신 러닝 연산들과 연관된 계산 데이터를 압축 및 압축해제할 수 있는 압축 및 압축해제 로직을 포함한다. 코덱은, 예를 들어, 희소 머신 러닝 연 산들을 위해 희소 행렬 데이터(sparse matrix data)를 압축할 수 있다. 코덱은 또한 희소 행렬 포맷으로 인코딩되는 희소 행렬 데이터(예를 들어, COO(coordinate list encoding), CSR(compressed sparse row), CSC(compress sparse column) 등)를 압축하여, 압축되고 인코딩된 희소 행렬 데이터를 생성할 수 있다. 압축되 고 인코딩된 희소 행렬 데이터는 프로세싱 요소들에 의해 프로세싱되기 전에 압축해제 및/또는 디코딩될 수 있 거나 또는 프로세싱 요소들은 프로세싱을 위해 압축된, 인코딩된, 또는 압축되고 인코딩된 데이터를 소비하도록 구성될 수 있다. ROP는 파티션 유닛 대신에 각각의 프로세싱 클러스터(예를 들어, 도 2a의 클러스터(214A-214N)) 내에 포함될 수 있다. 이러한 실시예에서, 픽셀 프래그먼트 데이터 대신에 픽셀 데이터에 대한 판독 및 기입 요청들 이 메모리 크로스바를 통해 송신된다. 프로세싱된 그래픽 데이터는, 도 1의 하나 이상의 디스플레이 디바 이스(들) 중 하나와 같은 디스플레이 디바이스 상에 디스플레이되거나, 프로세서(들)에 의한 추가 프 로세싱을 위해 라우팅되거나, 또는 도 2a의 병렬 프로세서 내의 프로세싱 엔티티들 중 하나에 의한 추가 프로세싱을 위해 라우팅될 수 있다. 도 2c는 병렬 프로세싱 유닛 내의 프로세싱 클러스터의 블록도이다. 예를 들어, 프로세싱 클러스터는 도 2a의 프로세싱 클러스터들(214A-214N) 중 하나의 인스턴스이다. 프로세싱 클러스터는 많은 스레드들을 병 렬로 실행하도록 구성될 수 있고, 여기서 \"스레드\"라는 용어는 특정한 세트의 입력 데이터에서 실행되는 특정한 프로그램의 인스턴스를 지칭한다. 선택적으로, 단일-명령어, 다중-데이터(single-instruction, multiple- data, SIMD) 명령어 발행 기법들이 다수의 독립 명령어 유닛들을 제공하지 않고 많은 수의 스레드들의 병렬 실 행을 지원하기 위해 사용될 수 있다. 대안적으로, 단일-명령어, 다중-스레드(single-instruction, multiple- thread, SIMT) 기법들이 프로세싱 클러스터들 각각의 것 내의 프로세싱 엔진들의 세트에 명령어들을 발행하도록 구성되는 공통 명령어 유닛을 사용하여 많은 수의 일반적으로 동기화된 스레드들의 병렬 실행을 지원하기 위해 사용될 수 있다. 모든 프로세싱 엔진들이 통상적으로 동일한 명령어들을 실행하는 SIMD 실행 체제와 달리, SIMT 실행은 상이한 스레드들이 주어진 스레드 프로그램을 통해 발산 실행 경로들(divergent execution paths)"}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "을 더 용이하게 따를 수 있게 한다. 본 기술분야의 통상의 기술자는 SIMD 프로세싱 체제가 SIMT 프로세싱 체제 의 기능적 서브세트를 나타낸다는 것을 이해할 것이다. 프로세싱 클러스터의 동작은 프로세싱 태스크들을 SIMT 병렬 프로세서들에 분배하는 파이프라인 관리자 를 통해 제어될 수 있다. 파이프라인 관리자는 도 2a의 스케줄러로부터 명령어들을 수신하고, 그래픽 멀티프로세서 및/또는 텍스처 유닛을 통한 그 명령어들의 실행을 관리한다. 예시된 그래픽 멀티프로세서는 SIMT 병렬 프로세서의 예시적인 인스턴스이다. 그러나, 상이한 아키텍처들의 SIMT 병렬 프로세서들의 다양한 타입들이 프로세싱 클러스터 내에 포함될 수 있다. 그래픽 멀티프로세서의 하 나 이상의 인스턴스가 프로세싱 클러스터 내에 포함될 수 있다. 그래픽 멀티프로세서는 데이터를 프 로세싱할 수 있고 데이터 크로스바가 프로세싱된 데이터를 다른 셰이더 유닛들을 포함하는 다수의 가능한 목적지들 중 하나에 분배하는데 사용될 수 있다. 파이프라인 관리자는 데이터 크로스바를 통해 분배 될 프로세싱된 데이터에 대한 목적지들을 특정함으로써 프로세싱된 데이터의 분배를 용이하게 할 수 있다. 프로세싱 클러스터 내의 각각의 그래픽 멀티프로세서는 동일한 세트의 함수 실행 로직(예를 들어, 산 술 논리 유닛들, 로드-스토어 유닛들 등)을 포함할 수 있다. 함수 실행 로직은 이전 명령어들이 완료되기 전에-11-새로운 명령어들이 발행될 수 있는 파이프라인 방식으로 구성될 수 있다. 함수 실행 로직은 정수 및 부동 소수 점 산술, 비교 연산들, 부울(Boolean) 연산들, 비트-시프팅(bit-shifting), 및 다양한 대수 함수들의 계산을 포 함하는 다양한 연산들을 지원한다. 동일한 함수 유닛 하드웨어가 상이한 연산들을 수행하기 위해 이용 (leverage)될 수 있고, 함수 유닛들의 임의의 조합이 존재할 수 있다. 프로세싱 클러스터에 송신되는 명령어들은 스레드를 구성한다. 병렬 프로세싱 엔진들의 세트에 걸쳐 실행 되는 스레드들의 세트는 스레드 그룹이다. 스레드 그룹은 상이한 입력 데이터에서 동일한 프로그램을 실행한다. 스레드 그룹 내의 각각의 스레드는 그래픽 멀티프로세서 내의 상이한 프로세싱 엔진에 할당될 수 있다. 스레드 그룹은 그래픽 멀티프로세서 내의 프로세싱 엔진들의 수보다 적은 스레드들을 포함할 수 있다. 스레드 그룹이 프로세싱 엔진들의 수보다 적은 스레드들을 포함할 때, 프로세싱 엔진들 중 하나 이상은 그 스레드 그룹이 프로세싱되고 있는 사이클들 동안 유휴(idle)일 수 있다. 스레드 그룹은 또한 그래픽 멀티프 로세서 내의 프로세싱 엔진들의 수보다 많은 스레드들을 포함할 수 있다. 스레드 그룹이 그래픽 멀티프로 세서 내의 프로세싱 엔진들의 수보다 많은 스레드들을 포함할 때, 프로세싱은 연속적인 클록 사이클들에 걸쳐 수행될 수 있다. 선택적으로, 다수의 스레드 그룹들이 그래픽 멀티프로세서 상에서 동시에 실행될 수 있다. 그래픽 멀티프로세서는 로드 및 스토어 연산들을 수행하는 내부 캐시 메모리를 포함할 수 있다. 선택적으 로, 그래픽 멀티프로세서는 내부 캐시를 포기(forego)하고 프로세싱 클러스터 내의 캐시 메모리(예를 들어, 레벨 1(L1) 캐시)를 사용할 수 있다. 각각의 그래픽 멀티프로세서는 또한 모든 프로세싱 클러 스터들 사이에 공유되고 스레드들 사이에 데이터를 전송하는 데 사용될 수 있는 파티션 유닛들(예를 들어, 도 2a의 파티션 유닛들(220A-220N)) 내의 레벨 2(L2) 캐시들에 대한 액세스를 갖는다. 그래픽 멀티프로세서 는 또한 로컬 병렬 프로세서 메모리 및/또는 시스템 메모리 중 하나 이상을 포함할 수 있는 오프-칩 전역 적 메모리(off-chip global memory)에 액세스할 수 있다. 병렬 프로세싱 유닛 외부의 임의의 메모리는 전 역적 메모리로서 사용될 수 있다. 프로세싱 클러스터가 그래픽 멀티프로세서의 다수의 인스턴스들을 포함하는 실시예들은 L1 캐시에 저장될 수 있는 공통 명령어들 및 데이터를 공유할 수 있다. 각각의 프로세싱 클러스터는 가상 어드레스들을 물리 어드레스들에 매핑하도록 구성되는 MMU(memory management unit)를 포함할 수 있다. 다른 실시예들에서, MMU의 하나 이상의 인스턴스는 도 2a의 메모리 인터페이스 내에 상주할 수 있다. MMU는 가상 어드레스를 타일의 물리 어드레스 및 선택적으로 캐시 라인 인덱스에 매핑하는 데 사용되는 페이지 테이블 엔트리(page table entry, PTE)들의 세트를 포함한다. MMU는 그래픽 멀티프로세서 또는 L1 캐시 또는 프로세싱 클러스터 내에 상주할 수 있는 어드레 스 변환 색인 버퍼(translation lookaside buffer, TLB)들 또는 캐시들을 포함할 수 있다. 물리 어드레스는, 파티션 유닛들 사이의 효율적인 요청 인터리빙을 허용하기 위해 표면 데이터 액세스 집약성(surface data access locality)을 분산하도록 프로세싱된다. 캐시 라인 인덱스는 캐시 라인에 대한 요청이 히트인지 또는 미 스인지를 결정하는 데 사용될 수 있다. 그래픽 및 컴퓨팅 애플리케이션들에서, 프로세싱 클러스터는 각각의 그래픽 멀티프로세서가 텍스처 매핑 연산들, 예를 들어, 텍스처 샘플 위치 결정, 텍스처 데이터 판독, 및 텍스처 데이터 필터링을 수행하기 위 해 텍스처 유닛에 결합되도록 구성될 수 있다. 텍스처 데이터는 내부 텍스처 L1 캐시(도시되지 않음)로부 터 또는 일부 실시예들에서 그래픽 멀티프로세서 내의 L1 캐시로부터 판독되고, 필요에 따라 L2 캐시, 로 컬 병렬 프로세서 메모리, 또는 시스템 메모리로부터 페치된다. 각각의 그래픽 멀티프로세서는 프로세싱 된 태스크들을 데이터 크로스바에 출력하여 프로세싱된 태스크를 추가 프로세싱을 위한 다른 프로세싱 클 러스터에 제공하거나 또는 프로세싱된 태스크를 메모리 크로스바를 통해 L2 캐시, 로컬 병렬 프로세 서 메모리, 또는 시스템 메모리에 저장한다. preROP(pre-raster operations unit)은 그래픽 멀티프로세 서로부터 데이터를 수신하고, 데이터를 본 명세서에 설명된 바와 같은 파티션 유닛들(예를 들어, 도 2a의 파티션 유닛들(220A-220N))과 함께 위치할 수 있는 ROP 유닛들로 보내도록 구성된다. preROP 유닛은 컬러 블렌딩에 대한 최적화들을 수행하고, 픽셀 컬러 데이터를 조직화하고, 어드레스 변환들을 수행할 수 있다. 본 명세서에서 설명되는 코어 아키텍처는 예시적이며, 변형들 및 수정들이 가능하다는 것을 이해할 것이다. 임 의의 수의 프로세싱 유닛들, 예를 들어, 그래픽 멀티프로세서, 텍스처 유닛들, preROP들 등이 프로세싱 클러스터 내에 포함될 수 있다. 또한, 하나의 프로세싱 클러스터만이 도시되지만, 본 명세 서에 설명된 바와 같은 병렬 프로세싱 유닛이 프로세싱 클러스터의 임의의 수의 인스턴스들을 포함할 수 있다. 선택적으로, 각각의 프로세싱 클러스터는 별도의 및 별개의 프로세싱 유닛들, L1 캐시들, L2 캐시-12-들 등을 사용하여 다른 프로세싱 클러스터들과 독립적으로 동작하도록 구성될 수 있다. 도 2d는 그래픽 멀티프로세서가 프로세싱 클러스터의 파이프라인 관리자와 결합하는 그래픽 멀 티프로세서의 예를 도시한다. 그래픽 멀티프로세서는 명령어 캐시, 명령어 유닛, 어드레 스 매핑 유닛, 레지스터 파일, 하나 이상의 범용 그래픽 프로세싱 유닛(GPGPU) 코어들, 및 하나 이상의 로드/스토어 유닛들을 포함하지만 이에 제한되지 않는 실행 파이프라인을 갖는다. GPGPU 코어들 및 로드/스토어 유닛들은 메모리 및 캐시 인터커넥트를 통해 캐시 메모리 및 공유 메모리 와 결합된다. 그래픽 멀티프로세서는 행렬 및/또는 광선 추적 연산들을 가속하는 하드웨어 로직을 포함하는 텐서 및/또는 광선 추적 코어들(tensor and/or ray-tracing cores)을 추가적으로 포함할 수 있 다. 명령어 캐시는 파이프라인 관리자로부터 실행할 명령어들의 스트림을 수신할 수 있다. 명령어들은 명령어 캐시에 캐싱되고 명령어 유닛에 의한 실행을 위해 디스패치(dispatch)된다. 명령어 유닛 은 명령어들을 스레드 그룹들(예를 들어, 워프(warp)들)로서 디스패치할 수 있고, 스레드 그룹의 각각의 스레드는 GPGPU 코어 내의 상이한 실행 유닛에 할당된다. 명령어는 통합 어드레스 공간(unified address space) 내의 어드레스를 특정함으로써 로컬, 공유, 또는 전역적 어드레스 공간 중 임의의 것에 액세스할 수 있 다. 어드레스 매핑 유닛은 통합 어드레스 공간 내의 어드레스들을 로드/스토어 유닛들에 의해 액세 스될 수 있는 별개의 메모리 어드레스로 변환하는 데 사용될 수 있다. 레지스터 파일은 그래픽 멀티프로세서의 함수 유닛들에 대한 레지스터들의 세트를 제공한다. 레지스 터 파일은 그래픽 멀티프로세서의 함수 유닛들(예를 들어, GPGPU 코어들, 로드/스토어 유닛들 )의 데이터 경로들에 접속된 피연산자들을 위한 임시 스토리지를 제공한다. 레지스터 파일은 각각의 함수 유닛에 레지스터 파일의 전용 부분이 할당되도록 각각의 함수 유닛들 사이에서 분할될 수 있다. 예 를 들어, 레지스터 파일은 그래픽 멀티프로세서에 의해 실행되는 상이한 워프들 사이에서 분할될 수 있다. GPGPU 코어들은 각각 그래픽 멀티프로세서의 명령어들을 실행하는 데 사용되는 부동 소수점 유닛 (floating point unit, FPU)들 및/또는 정수 산술 로직 유닛(arithmetic logic unit, ALU)들을 포함할 수 있다. 일부 구현들에서, GPGPU 코어들은 다른 방식으로 텐서 및/또는 광선 추적 코어들 내에 상주할 수 있는 하드웨어 로직을 포함할 수 있다. GPGPU 코어들은 아키텍처가 유사할 수 있거나 아키텍처가 상이 할 수 있다. 예를 들어, 일 실시예에서, GPGPU 코어들의 제1 부분은 단정밀도 FPU 및 정수 ALU를 포함하 고, GPGPU 코어들의 제2 부분은 배정밀도 FPU를 포함한다. 선택적으로, FPU들은 부동 소수점 산술에 대한 IEEE 754-2008 표준을 구현할 수 있거나 또는 가변 정밀도 부동 소수점 산술을 가능하게 할 수 있다. 그래픽 멀티프 로세서는 복사 직사각형 또는 픽셀 블렌딩 연산들과 같은 특정 함수들을 수행하기 위해 하나 이상의 고정 함수 또는 특수 함수 유닛을 추가적으로 포함할 수 있다. GPGPU 코어들 중 하나 이상은 고정 또는 특수 함수 로직을 또한 포함할 수 있다. GPGPU 코어들은 다수의 데이터 세트들에서 단일 명령어를 수행할 수 있는 SIMD 로직을 포함할 수 있다. 선택적으로, GPGPU 코어들은 SIMD4, SIMD8, 및 SIMD16 명령어들을 물리적으로 실행하고, SIMD1, SIMD2, 및 SIMD32 명령어들을 논리적으로 실행할 수 있다. GPGPU 코어들에 대한 SIMD 명령어들은 셰이더 컴파일러에 의해 컴파일 시에 생성되거나 또는 단일 프로그램 다중 데이터(single program multiple data, SPMD) 또는 SIMT 아키텍처들을 위해 기입되고 컴파일된 프로그램들을 실행할 때 자동으로 생성될 수 있다. SIMT 실행 모델 을 위해 구성된 프로그램의 다수의 스레드들은 단일 SIMD 명령어를 통해 실행될 수 있다. 예를 들어, 일 실시 예에서, 동일하거나 유사한 연산들을 수행하는 8개의 SIMT 스레드가 단일 SIMD8 로직 유닛을 통해 병렬로 실행 될 수 있다. 메모리 및 캐시 인터커넥트는 그래픽 멀티프로세서의 함수 유닛들 각각을 레지스터 파일 및 공 유 메모리에 접속하는 인터커넥트 네트워크이다. 예를 들어, 메모리 및 캐시 인터커넥트는 로드/스 토어 유닛이 공유 메모리와 레지스터 파일 사이의 로드 및 스토어 동작들을 구현할 수 있게 하 는 크로스바 인터커넥트이다. 레지스터 파일은 GPGPU 코어들과 동일한 주파수에서 동작할 수 있으므 로, GPGPU 코어들과 레지스터 파일 사이의 데이터 전송은 매우 낮은 레이턴시이다. 공유 메모리 는 그래픽 멀티프로세서 내의 함수 유닛들에서 실행되는 스레드들 사이의 통신을 가능하게 하는 데 사용될 수 있다. 캐시 메모리는 함수 유닛들과 텍스처 유닛 사이에서 통신되는 텍스처 데이터를 캐 싱하기 위해, 예를 들어, 데이터 캐시로서 사용될 수 있다. 공유 메모리는 또한 프로그램 관리되는 캐시-13-로서 사용될 수 있다. 공유 메모리 및 캐시 메모리는 데이터 크로스바와 결합하여 프로세싱 클 러스터의 다른 컴포넌트들과의 통신을 가능하게 할 수 있다. GPGPU 코어들에서 실행되는 스레드들은 캐시 메모리 내에 저장되는 자동으로 캐싱된 데이터에 부가하여 공유 메모리 내에 데이터를 프로그램적으로 저 장할 수 있다. 도 3a 내지 도 3c는 실시예들에 따른 추가적인 그래픽 멀티프로세서들을 도시한다. 도 3a 및 도 3b는 도 2c의 그래픽 멀티프로세서와 관련되고 그것들 중 하나 대신에 사용될 수 있는 그래픽 멀티프로세서들(325, 35 0)을 도시한다. 따라서, 본 명세서에서의 그래픽 멀티프로세서와 조합된 임의의 특징들의 개시내용은 그 래픽 멀티프로세서(들)(325, 350)와의 대응하는 조합을 또한 개시하지만, 그러한 것으로 제한되지 않는다. 도 3c는 그래픽 멀티프로세서들(325, 350)에 대응하는 멀티-코어 그룹들(365A-365N)로 배열된 그래픽 프로세싱 자 원들의 전용 세트들을 포함하는 그래픽 프로세싱 유닛(GPU)을 도시한다. 도시된 그래픽 멀티프로세서들 (325, 350) 및 멀티-코어 그룹들(365A-365N)은 많은 수의 실행 스레드들의 동시 실행이 가능한 스트리밍 멀티프 로세서(streaming multiprocessor, SM)들일 수 있다. 도 3a의 그래픽 멀티프로세서는 도 2d의 그래픽 멀티프로세서에 대한 실행 자원 유닛들의 다수의 추 가적인 인스턴스들을 포함한다. 예를 들어, 그래픽 멀티프로세서는 명령어 유닛(332A-332B), 레지스터 파 일(334A-334B), 및 텍스처 유닛(들)(344A-344B)의 다수의 인스턴스들을 포함할 수 있다. 그래픽 멀티프로세서 는 또한 다수의 세트들의 그래픽 또는 계산 실행 유닛들(예를 들어, GPGPU 코어(336A-336B), 텐서 코어 (337A-337B), 광선 추적 코어(338A-338B)) 및 다수의 세트들의 로드/스토어 유닛들(340A-340B)을 포함한다. 실행 자원 유닛들은 공통 명령어 캐시, 텍스처 및/또는 데이터 캐시 메모리, 및 공유 메모리를 갖는다. 다양한 컴포넌트들은 인터커넥트 패브릭을 통해 통신할 수 있다. 인터커넥트 패브릭은 그래픽 멀티 프로세서의 다양한 컴포넌트들 사이의 통신을 가능하게 하는 하나 이상의 크로스바 스위치를 포함할 수 있 다. 인터커넥트 패브릭은 그래픽 멀티프로세서의 각각의 컴포넌트가 그 위에 적층되는 별개의 고속 네트워크 패브릭 층일 수 있다. 그래픽 멀티프로세서의 컴포넌트들은 인터커넥트 패브릭을 통해 원 격 컴포넌트들과 통신한다. 예를 들어, 코어들(336A-336B, 337A-337B, 및 338A-338B)은 각각 인터커넥트 패브 릭을 통해 공유 메모리와 통신할 수 있다. 인터커넥트 패브릭은 컴포넌트들 사이의 공정한 대 역폭 할당을 보장하기 위해 그래픽 멀티프로세서 내의 통신을 중재할 수 있다. 도 3b의 그래픽 멀티프로세서는 다수의 세트들의 실행 자원들(356A-356D)을 포함하고, 여기서 각각의 세트 의 실행 자원은 도 2d 및 도 3a에 도시된 바와 같이, 다수의 명령어 유닛들, 레지스터 파일들, GPGPU 코어들, 및 로드 스토어 유닛들을 포함한다. 실행 자원들(356A-356D)은, 명령어 캐시 및 공유 메모리를 공유 하면서, 텍스처 연산들을 위한 텍스처 유닛(들)(360A-360D)과 협력하여 작업할 수 있다. 예를 들어, 실행 자원 들(356A-356D)은 명령어 캐시 및 공유 메모리뿐만 아니라, 텍스처 및/또는 데이터 캐시 메모리(358A- 358B)의 다수의 인스턴스들을 공유할 수 있다. 다양한 컴포넌트들은 도 3a의 인터커넥트 패브릭과 유사한 인터커넥트 패브릭을 통해 통신할 수 있다."}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "본 기술분야의 통상의 기술자는 도 1, 도 2a 내지 도 2d, 및 도 3a 내지 도 3b에 설명된 아키텍처가 설명적이고 본 실시예들의 범위에 대해 제한적이지 않다는 것을 이해할 것이다. 따라서, 본 명세서에 설명된 기법들은, 본 명세서에 설명된 실시예들의 범위로부터 벗어나지 않고서, 하나 이상의 모바일 애플리케이션 프로세서, 멀티-코 어 CPU들을 포함하는 하나 이상의 데스크톱 또는 서버 중앙 프로세싱 유닛(CPU), 도 2a의 병렬 프로세싱 유닛 과 같은 하나 이상의 병렬 프로세싱 유닛뿐만 아니라, 하나 이상의 그래픽 프로세서 또는 특수 목적 프로 세싱 유닛을 포함하지만 이에 제한되지 않는 임의의 적절히 구성된 프로세싱 유닛 상에서 구현될 수 있다. 본 명세서에 설명된 바와 같은 병렬 프로세서 또는 GPGPU는 그래픽 연산들, 머신 러닝 연산들, 패턴 분석 연산 들, 및 다양한 범용 GPU(GPGPU) 함수들을 가속하기 위해 호스트/프로세서 코어들에 통신가능하게 결합될 수 있 다. GPU는 버스 또는 다른 인터커넥트(예를 들어, PCIe, NVLink, 또는 다른 알려진 프로토콜들, 표준화된 프로 토콜들, 또는 사유 프로토콜들과 같은 고속 인터커넥트)를 통해 호스트 프로세서/코어들에 통신가능하게 결합될 수 있다. 다른 실시예들에서, GPU는 코어들과 동일한 패키지 또는 칩 상에 집적되고 내부 프로세서 버스/인터 커넥트(즉, 패키지 또는 칩 내부)를 통해 코어들에 통신가능하게 결합될 수 있다. GPU가 접속되는 방식에 관계 없이, 프로세서 코어들은 작업 디스크립터(work descriptor)에 포함된 커맨드들/명령어들의 시퀀스들의 형태로 GPU에 작업을 할당할 수 있다. GPU는 이후 이러한 커맨드들/명령어들을 효율적으로 프로세싱하기 위해 전용 회 로/로직을 사용한다.-14-도 3c는 멀티-코어 그룹들(365A-365N)로 배열된 그래픽 프로세싱 자원들의 전용 세트들을 포함하는 그래픽 프로 세싱 유닛(GPU)을 도시한다. 단일 멀티-코어 그룹(365A)만의 세부사항이 제공되지만, 다른 멀티-코어 그 룹들(365B-365N)이 동일하거나 유사한 그래픽 프로세싱 자원 세트를 갖추고 있을 수 있다는 것을 이해할 것이다. 멀티-코어 그룹들(365A-365N)에 관하여 설명된 세부사항은 또한 본 명세서에 설명된 임의의 그래픽 멀 티프로세서(234, 325, 350)에 적용될 수 있다. 도시된 바와 같이, 멀티-코어 그룹(365A)은 그래픽 코어들의 세트, 텐서 코어들의 세트, 및 광선 추 적 코어들의 세트를 포함할 수 있다. 스케줄러/디스패처가 다양한 코어들(370, 371, 372) 상에서의 실행을 위해 그래픽 스레드들을 스케줄링하고 디스패치한다. 레지스터 파일들의 세트는 그래픽 스레드들 을 실행할 때 코어들(370, 371, 372)에 의해 사용되는 피연산자 값들을 저장한다. 이것들은, 예를 들어, 정수 값들을 저장하기 위한 정수 레지스터들, 부동 소수점 값들을 저장하기 위한 부동 소수점 레지스터들, 패킹된 데 이터 요소들을 저장하기 위한 벡터 레지스터들(정수 및/또는 부동 소수점 데이터 요소들) 및 텐서/행렬 값들을 저장하기 위한 타일 레지스터들을 포함할 수 있다. 타일 레지스터들은 벡터 레지스터들의 조합된 세트들로서 구현될 수 있다. 하나 이상의 조합된 레벨 1(L1) 캐시들 및 공유 메모리 유닛들은 각각의 멀티-코어 그룹(365A) 내에 로컬 적으로 텍스처 데이터, 정점 데이터, 픽셀 데이터, 광선 데이터, 바운딩 볼륨 데이터(bounding volume data) 등 과 같은 그래픽 데이터를 저장한다. 하나 이상의 텍스처 유닛이 또한 텍스처 매핑 및 샘플링과 같은 텍스 처링 연산들을 수행하기 위해 사용될 수 있다. 멀티-코어 그룹들(365A-365N)의 전부 또는 서브세트에 의해 공 유되는 레벨 2(L2) 캐시는 다수의 동시 그래픽 스레드들에 대한 그래픽 데이터 및/또는 명령어들을 저장한 다. 예시된 바와 같이, L2 캐시는 복수의 멀티-코어 그룹들(365A-365N)에 걸쳐 공유될 수 있다. 하나 이 상의 메모리 컨트롤러는 시스템 메모리(예를 들어, DRAM) 및/또는 전용 그래픽 메모리(예를 들어, GDDR6 메모리)일 수 있는 메모리에 GPU를 결합한다. 입력/출력(I/O) 회로는 GPU를 디지털 신호 프로세서(DSP)들, 네트워크 컨트롤러들, 또는 사용자 입력 디바이스들과 같은 하나 이상의 I/O 디바이스에 결합한다. 온-칩 인터커넥트(on-chip interconnect)가 I/O 디바이스들을 GPU 및 메모리에 결합하기 위해 사용될 수 있다. I/O 회로의 하나 이상 의 I/O 메모리 관리 유닛(IOMMU)은 I/O 디바이스들을 시스템 메모리에 직접적으로 결합한다. 선택적으로, IOMMU는 가상 어드레스들을 시스템 메모리 내의 물리 어드레스들에 매핑하는 다수의 세 트들의 페이지 테이블들을 관리한다. 이어서, I/O 디바이스들, CPU(들), 및 GPU(들)는 동일한 가상 어드레스 공간을 공유할 수 있다. IOMMU의 일 구현에서, IOMMU는 가상화를 지원한다. 이 경우, 그것은 게스트/그래픽 가상 어드레스들 을 게스트/그래픽 물리 어드레스들에 매핑하는 제1 세트의 페이지 테이블들 및 게스트/그래픽 물리 어드레스들 을 시스템/호스트 물리 어드레스들(예를 들어, 시스템 메모리 내의)에 매핑하는 제2 세트의 페이지 테이블 들을 관리할 수 있다. 제1 및 제2 세트들의 페이지 테이블들 각각의 베이스 어드레스들은 제어 레지스터들에 저장되고 (예를 들어, 새로운 컨텍스트가 관련 세트의 페이지 테이블들에 대한 액세스를 제공받도록) 컨텍스트 스위치(context switch)에서 스왑 아웃(swap out)될 수 있다. 도 3c에 도시되지 않았지만, 코어들(370, 371, 372) 및/또는 멀티-코어 그룹들(365A-365N) 각각은 게스트 가상 대 게스트 물리 변환들(guest virtual to guest physical translations), 게스트 물리 대 호스트 물리 변환들(guest physical to host physical translations), 및 게스트 가상 대 호스트 물리 변환들(guest virtual to host physical translations)을 캐싱 하는 변환 색인 버퍼(TLB)들을 포함할 수 있다. CPU들, GPU들, 및 I/O 디바이스들은 단일 반도체 칩 및/또는 칩 패키지 상에 집적될 수 있다. 예시된 메모리는 동일한 칩 상에 집적될 수 있거나 또는 오프-칩 인터페이스를 통해 메모리 컨트롤러들 에 결합될 수 있다. 일 구현에서, 메모리는 다른 물리 시스템-레벨 메모리들과 동일한 가상 어드레 스 공간을 공유하는 GDDR6 메모리를 포함하지만, 본 명세서에 설명된 기본 원리들은 이 특정 구현으로 제한되지 않는다. 텐서 코어들은, 딥 러닝 연산들을 수행하는데 사용되는 기본 계산 연산인 행렬 연산들을 수행하도록 특별 히 설계되는 복수의 실행 유닛들을 포함할 수 있다. 예를 들어, 동시 행렬 곱셈 연산들은 신경망 훈련 및 추론 에 사용될 수 있다. 텐서 코어들은 단정밀도 부동 소수점(예를 들어, 32 비트), 반정밀도(half- precision) 부동 소수점(예를 들어, 16 비트), 정수 워드들(16 비트), 바이트들(8 비트), 및 하프-바이트들(4 비트)을 포함하는 다양한 피연산자 정밀도들을 사용하여 행렬 프로세싱을 수행할 수 있다. 예를 들어, 신경망-15-구현은 각각의 렌더링된 장면의 특징들을 추출하고, 잠재적으로 다수의 프레임들로부터의 상세사항들을 조합하 여, 고품질 최종 이미지를 구성한다. 딥 러닝 구현들에서, 병렬 행렬 곱셈 작업은 텐서 코어들 상에서 실행을 위해 스케줄링될 수 있다. 신경 망들의 훈련은, 특히, 상당한 수의 행렬 내적 연산(matrix dot product operation)들을 요구한다. N x N x N 행렬 곱셈의 내적 공식화를 프로세싱하기 위해, 텐서 코어들은 적어도 N개의 내적 프로세싱 요소를 포함할 수 있다. 행렬 곱셈이 시작되기 전에, 하나의 전체 행렬이 타일 레지스터들에 로드되고, 제2 행렬의 적어도 하 나의 열이 N 사이클 동안 각각의 사이클에 로드된다. 각각의 사이클에는, 프로세싱되는 N개의 내적이 존재한다. 행렬 요소들은 16-비트 워드들, 8-비트 바이트들(예를 들어, INT8) 및 4-비트 하프-바이트들(예를 들어, INT4) 을 포함하여 특정 구현에 따라 상이한 정밀도들로 저장될 수 있다. 상이한 작업부하들(예를 들어, 바이트들 및 하프-바이트들에 대한 양자화를 용인할 수 있는 추론 작업부하들과 같은 것)을 위해 가장 효율적인 정밀도가 사 용되는 것을 보장하기 위해 텐서 코어들에 대해 상이한 정밀도 모드들이 특정될 수 있다. 지원되는 포맷 들은 64-비트 부동 소수점(FP64) 및 비-IEEE 부동 소수점 포맷들, 예컨대, bfloat16 포맷(예를 들어, 브레인 부 동 소수점(Brain floating point)), 1개의 부호 비트, 8개의 지수 비트, 및 8개의 가수 비트(그 중 7개는 명시 적으로 저장됨)를 갖는 16-비트 부동 소수점 포맷을 추가적으로 포함한다. 일 실시예는 FP16(10-비트)의 정밀 도를 갖는 FP32(8-비트)의 범위를 갖는 감소된 정밀도 텐서-부동 포맷(TF32)에 대한 지원을 포함한다. 감소된 정밀도 TF32 연산들은 FP32 입력들에 대해 수행되고 FP32에 대해 더 높은 성능으로 그리고 FP16에 대해 증가된 정밀도로 FP32 출력들을 생성할 수 있다. 일 실시예에서, 텐서 코어들은 대다수의 값들이 제로인 행렬들에 대한 연산의 희소 모드를 지원한다. 텐 서 코어들은 희소 행렬 표현으로 인코딩되는 희소 입력 행렬들(예를 들어, COO(coordinate list encoding), CSR(compressed sparse row), CSC(compress sparse column) 등)에 대한 지원을 포함한다. 텐서 코 어들은 또한 희소 행렬 표현이 더 압축될 수 있는 경우에 압축된 희소 행렬 표현들에 대한 지원을 포함한 다. 압축된, 인코딩된, 및/또는 압축되고 인코딩된 행렬 데이터는, 연관된 압축 및/또는 인코딩 메타데이터와 함께, 텐서 코어들에 의해 준비될 수 있고, 논-제로 값들이 추출될 수 있다. 예를 들어, 주어진 입력 행 렬 A의 경우, 행렬 A의 적어도 일부의 압축된 및/또는 인코딩된 표현으로부터 논-제로 값이 로드될 수 있다. 논-제로 값과 연관된 인덱스 또는 좌표 메타데이터로부터 결정될 수 있는 논-제로 값에 대한 행렬 A 내의 위치 에 기초하여, 입력 행렬 B 내의 대응하는 값이 로드될 수 있다. 수행될 연산(예를 들어, 곱셈)에 따라, 입력 행렬 B로부터의 값의 로드는 대응하는 값이 제로 값이면 우회될 수 있다. 일 실시예에서, 곱셈 연산들과 같은 특정 연산들에 대한 값들의 쌍들(pairings)은 스케줄러 로직에 의해 사전-스캐닝될 수 있고, 논-제로 입력들 사 이의 연산들만이 스케줄링된다. 행렬 A 및 행렬 B의 차원들 및 수행될 연산에 따라, 출력 행렬 C는 조밀하거나 희소할 수 있다. 출력 행렬 C가 희소한 경우, 그리고 텐서 코어들의 구성에 따라, 출력 행렬 C는 압축된 포맷, 희소 인코딩, 또는 압축된 희소 인코딩으로 출력될 수 있다. 광선 추적 코어들은 실시간 광선 추적 및 비-실시간 광선 추적 구현들 둘 다에 대한 광선 추적 연산들을 가속할 수 있다. 특히, 광선 추적 코어들은 BVH(bounding volume hierarchy)들을 사용하여 광선 횡단 (ray traversal)을 수행하고 BVH 볼륨들 내에 둘러싸인 광선들과 프리미티브들 사이의 교차들을 식별하는 광선 횡단/교차 회로(ray traversal/intersection circuitry)를 포함할 수 있다. 광선 추적 코어들은 또한 깊 이 테스팅 및 컬링(culling)(예를 들어, Z 버퍼 또는 유사한 배열을 사용함)을 수행하기 위한 회로를 포함할 수 있다. 일 구현에서, 광선 추적 코어들은 그의 적어도 일부가 텐서 코어들 상에서 실행될 수 있는 본 명세서에 설명된 이미지 잡음제거 기법들과 협력하여 횡단 및 교차 연산들을 수행한다. 예를 들어, 텐서 코어 들은 광선 추적 코어들에 의해 생성된 프레임들의 잡음제거를 수행하기 위해 딥 러닝 신경망을 구현 할 수 있다. 그러나, CPU(들), 그래픽 코어들, 및/또는 광선 추적 코어들은 또한 잡음제거 및/ 또는 딥 러닝 알고리즘들의 전부 또는 일부를 구현할 수 있다. 또한, 전술한 바와 같이, GPU가 네트워크 또는 고속 인터커넥트를 통해 다른 컴퓨팅 디바이스들에 결합된 컴퓨팅 디바이스에 있는 잡음제거에 대한 분산형 접근법이 이용될 수 있다. 이러한 분산형 접근법에서, 상호접 속된 컴퓨팅 디바이스들은 신경망 러닝/훈련 데이터를 공유하여, 전체 시스템이 상이한 타입들의 이미지 프레임 들 및/또는 상이한 그래픽 애플리케이션들에 대해 잡음제거를 수행하는 것을 학습하는 속도를 개선할 수 있다. 광선 추적 코어들은 모든 BVH 횡단 및/또는 광선-프리미티브 교차들을 프로세싱할 수 있어, 그래픽 코어들 이 광선마다 수천개의 명령어들로 과부하되는 것을 세이브할 수 있다. 예를 들어, 각각의 광선 추적 코어-16-는 바운딩 박스 테스트(bounding box test)들을 수행하기 위한 제1 세트의 특수화된 회로(예를 들어, 횡단 연산들을 위한) 및/또는 광선-삼각형 교차 테스트(ray-triangle intersection test)들(예를 들어, 횡단된 교차 광선들)을 수행하기 위한 제2 세트의 특수화된 회로를 포함한다. 따라서, 예를 들어, 멀티-코어 그룹(365A)은 단순히 광선 프로브(ray probe)를 론칭할 수 있고, 광선 추적 코어들은 독립적으로 광선 횡단 및 교차를 수행하고 히트 데이터(예를 들어, 히트, 히트 없음(no hit), 다중 히트들 등)를 스레드 컨텍스트에 리턴한다. 다른 코어들(370, 371)은 다른 그래픽 또는 계산 작업을 수행하도록 자유롭게 되는 반면, 광선 추적 코어들 은 횡단 및 교차 연산들을 수행한다. 선택적으로, 각각의 광선 추적 코어는 BVH 테스팅 연산들을 수행하는 횡단 유닛 및/또는 광선-프리미티브 교차 테스트들을 수행하는 교차 유닛을 포함할 수 있다. 교차 유닛은 \"히트(hit)\", \"히트 없음(no hit)\", 또는 \"다중 히트(multiple hit)\" 응답을 생성하여, 적절한 스레드에 제공한다. 횡단 및 교차 연산들 동안, 다른 코 어들(예를 들어, 그래픽 코어들 및 텐서 코어들)의 실행 자원들은 다른 형태들의 그래픽 작업을 수행 하도록 자유롭게 된다. 아래에 설명되는 하나의 선택적 실시예에서, 그래픽 코어들과 광선 추적 코어들 사이에 작업이 분산 되는 하이브리드 래스터화/광선 추적 접근법(hybrid rasterization/ray tracing approach)이 사용된다. 광선 추적 코어들(및/또는 다른 코어들(370, 371))은, 각각의 객체에 대한 셰이더들 및 텍스처들의 고유한 세트들의 할당을 가능하게 하는, 광선-생성, 최근접-히트(closest-hit), 임의의-히트(any-hit), 및 미스(miss) 셰이더들은 물론, DispatchRays 커맨드를 포함하는 Microsoft의 DirectX 광선 추적(DXR)과 같은 광선 추적 명 령어 세트에 대한 하드웨어 지원을 포함할 수 있다. 광선 추적 코어들, 그래픽 코어들 및 텐서 코어 들에 의해 지원될 수 있는 다른 광선 추적 플랫폼은 Vulkan 1.1.85이다. 그러나, 본 명세서에 설명된 기 본 원리들은 임의의 특정 광선 추적 ISA로 제한되지 않는다는 점에 유의한다. 일반적으로, 다양한 코어들(372, 371, 370)은 광선 생성(ray generation), 최근접 히트(closest hit), 임의의 히트(any hit), 광선-프리미티브 교차(ray-primitive intersection), 프리미티브마다 및 계층적 바운딩 박스 구성(per-primitive and hierarchical bounding box construction), 미스(miss), 방문(visit), 및 예외들 (exceptions) 중 하나 이상에 대한 명령어들/함수들을 포함하는 광선 추적 명령어 세트를 지원할 수 있다. 더 구체적으로, 바람직한 실시예는 다음의 함수들 중 하나 이상을 수행하는 광선 추적 명령어들을 포함한다: 광선 생성 - 광선 생성 명령어들은 각각의 픽셀, 샘플, 또는 다른 사용자-정의된 작업 할당을 위해 실행될 수 있다. 최근접 히트 - 최근접 히트 명령어는 장면 내의 프리미티브들과 광선의 최근접 교차점을 찾기 위해 실행될 수 있다. 임의의 히트 - 임의의 히트 명령어는 장면 내의 프리미티브들과 광선 사이의 다수의 교차들을 식별하여, 잠재적 으로 새로운 최근접 교차점을 식별한다. 교차 - 교차 명령어는 광선-프리미티브 교차 테스트를 수행하고 결과를 출력한다. 프리미티브마다 바운딩 박스 구성 - 이 명령어는 주어진 프리미티브 또는 프리미티브들의 그룹 주위에 바운딩 박스를 구축(build)한다(예를 들어, 새로운 BVH 또는 다른 가속 데이터 구조를 구축할 때). 미스 - 광선이 장면 내의 모든 지오메트리, 또는 장면의 특정된 영역을 미스한다는 것을 나타낸다. 방문 - 광선이 횡단할 자식 볼륨들(children volumes)을 나타낸다. 예외들 - 다양한 타입들의 예외 핸들러들(예를 들어, 다양한 에러 조건들에 대해 인보크됨)을 포함한다. 일 실시예에서 광선 추적 코어들은 광선 교차 테스트들과 유사한 계산 기법들을 사용하여 가속될 수 있는 범용 계산 연산들을 가속하도록 적응될 수 있다. 셰이더 프로그램들이 광선 추적 코어들을 통해 범용 계산 연 산들을 수행하는 저레벨 명령어들 및/또는 프리미티브들로 컴파일될 수 있게 하는 계산 프레임워크가 제공될 수 있다. 광선 추적 코어들 상에서 수행되는 계산 연산들로부터 이득을 얻을 수 있는 예시적인 계산 문제들 은 좌표 공간 내의 빔, 파, 광선, 또는 입자 전파를 수반하는 계산들을 포함한다. 그 전파와 연관된 상호작용 들은 좌표 공간 내의 지오메트리 또는 메시에 대해 계산될 수 있다. 예를 들어, 환경을 통한 전자기 신호 전파 와 연관된 계산들은 광선 추적 코어들을 통해 실행되는 명령어들 또는 프리미티브들의 사용을 통해 가속될 수 있다. 환경 내의 객체들에 의한 신호들의 회절 및 반사는 직접 광선-추적 유추들(direct ray-tracing-17-analogies)로서 계산될 수 있다. 광선 추적 코어들은 광선 추적과 직접적으로 유사하지 않은 계산들을 수행하기 위해 또한 사용될 수 있다. 예를 들어, 메시 투영(mesh projection), 메시 정제(mesh refinement), 및 볼륨 샘플링 계산들은 광선 추적 코 어들을 사용하여 가속될 수 있다. 가장 가까운 이웃 계산들(nearest neighbor calculations)과 같은 일 반적인 좌표 공간 계산들이 또한 수행될 수 있다. 예를 들어, 주어진 포인트 근처의 포인트들의 세트는 그 포 인트 주위의 좌표 공간에서 바운딩 박스를 정의함으로써 발견될 수 있다. 이어서, 광선 추적 코어들 내의 BVH 및 광선 프로브 로직이 바운딩 박스 내의 포인트 교차들의 세트를 결정하는 데 사용될 수 있다. 교차들은 원점 및 그 원점에 대한 가장 가까운 이웃들을 구성한다. 광선 추적 코어들을 사용하여 수행되는 계산들 은 그래픽 코어들 및 텐서 코어들에 대해 수행되는 계산들과 병렬로 수행될 수 있다. 셰이더 컴파일 러는 계산 셰이더 또는 다른 범용 그래픽 프로세싱 프로그램을 그래픽 코어들, 텐서 코어들, 및 광선 추적 코어들에 걸쳐 병렬화될 수 있는 저레벨 프리미티브들로 컴파일하도록 구성될 수 있다. GPU 대 호스트 프로세서 상호접속을 위한 기법들 도 4a는 예를 들어 도 2a에 도시된 병렬 프로세서들과 같은 복수의 GPU들(410-413)이 고속 링크들(440A- 440D)(예를 들어, 버스들, 점대점 인터커넥트들 등)을 통해 복수의 멀티-코어 프로세서들(405-406)에 통신가능 하게 결합되는 예시적인 아키텍처를 도시한다. 고속 링크들(440A-440D)은 구현에 따라 4GB/s, 30GB/s, 80GB/s 또는 그 이상의 통신 스루풋을 지원할 수 있다. PCIe 4.0 또는 5.0 및 NVLink 2.0을 포함하지만 이에 제한되지 않는 다양한 인터커넥트 프로토콜들이 사용될 수 있다. 그러나, 본 명세서에 설명된 기본 원리들은 임의의 특 정 통신 프로토콜 또는 스루풋으로 제한되지 않는다. GPU들(410-413) 중 2개 이상은 고속 링크들(440A-440D)에 사용되는 것들과 동일하거나 상이한 프로토콜들/링크 들을 사용하여 구현될 수 있는 고속 링크들(442A-442B)을 통해 상호접속될 수 있다. 유사하게, 멀티-코어 프로 세서들(405-406) 중 2개 이상은 20GB/s, 30GB/s, 120GB/s 또는 더 낮거나 더 높은 속도로 동작하는 대칭적 멀 티-프로세서(symmetric multi-processor, SMP) 버스들일 수 있는 고속 링크를 통해 접속될 수 있다. 대 안적으로, 도 4a에 도시된 다양한 시스템 컴포넌트들 사이의 모든 통신은 동일한 프로토콜들/링크들을 사용하여 (예를 들어, 공통 인터커넥트 패브릭을 통해) 달성될 수 있다. 그러나, 언급된 바와 같이, 본 명세서에 설명된 기본 원리들은 임의의 특정 타입의 인터커넥트 기술로 제한되지 않는다. 각각의 멀티-코어 프로세서(405-406)는 각각 메모리 인터커넥트들(430A-430B)을 통해 프로세서 메모리(401- 402)에 통신가능하게 결합될 수 있고, 각각의 GPU(410-413)는 각각 GPU 메모리 인터커넥트들(450A-450D)을 통해 GPU 메모리(420-423)에 통신가능하게 결합된다. 메모리 인터커넥트들(430A-430B 및 450A-450D)은 동일하거나 상이한 메모리 액세스 기술들을 이용할 수 있다. 제한이 아닌 예로서, 프로세서 메모리들(401-402) 및 GPU 메 모리들(420-423)은 동적 랜덤 액세스 메모리(DRAM)들(스택형 DRAM들을 포함함), 그래픽 DDR SDRAM(GDDR)(예를 들어, GDDR5, GDDR6), 또는 고대역폭 메모리(High Bandwidth Memory, HBM)와 같은 휘발성 메모리들일 수 있고/ 있거나, 3D XPoint/Optane 또는 Nano-Ram과 같은 비휘발성 메모리들일 수 있다. 예를 들어, 메모리들의 일부 부분은 휘발성 메모리일 수 있고 다른 부분은 비휘발성 메모리일 수 있다(예를 들어, 2-레벨 메모리(2LM) 계층 구조를 사용하여). 본 명세서에 설명된 바와 같은 메모리 서브시스템은 JEDEC(Joint Electronic Device Engineering Council)에 의해 릴리즈된 더블 데이터 레이트(Double Data Rate) 버전들과 같은 다수의 메모리 기술들과 호환될 수 있다. 후술하는 바와 같이, 다양한 프로세서들(405-406) 및 GPU들(410-413)이 각각 특정 메모리(401-402, 420-423)에 물리적으로 결합될 수 있지만, 동일한 가상 시스템 어드레스 공간(\"유효 어드레스\" 공간으로도 지칭됨)이 모든 다양한 물리 메모리들 사이에 분산되는 통합 메모리 아키텍처가 구현될 수 있다. 예를 들어, 프로세서 메모리 들(401-402)은 각각 64GB의 시스템 메모리 어드레스 공간을 포함할 수 있고 GPU 메모리들(420-423)은 각각 32GB 의 시스템 메모리 어드레스 공간을 포함할 수 있다(이 예에서 결과적으로 총 256GB 어드레싱가능 메모리를 초래 함). 도 4b는 멀티-코어 프로세서와 그래픽 가속 모듈 사이의 상호 접속에 대한 추가적인 선택적 세부사항 을 도시한다. 그래픽 가속 모듈은 고속 링크를 통해 프로세서에 결합되는 라인 카드 상에 집적 된 하나 이상의 GPU 칩을 포함할 수 있다. 대안적으로, 그래픽 가속 모듈은 프로세서와 동일한 패키 지 또는 칩 상에 집적될 수 있다. 예시된 프로세서는, 변환 색인 버퍼(461A-461D) 및 하나 이상의 캐시(462A-462D)를 각각 갖는 복수의 코어 -18-들(460A-460D)을 포함한다. 코어들은 본 명세서에서 설명되는 컴포넌트들의 기본 원리들을 모호하게 하는 것을 회피하기 위해 예시되지 않은 명령어들 및 프로세싱 데이터를 실행하기 위한 다양한 다른 컴포넌트들(예를 들어, 명령어 페치 유닛들, 분기 예측 유닛들, 디코더들, 실행 유닛들, 재배열 버퍼들 등)을 포함할 수 있다. 캐시들(462A-462D)은 레벨 1(L1) 및 레벨 2(L2) 캐시들을 포함할 수 있다. 또한, 하나 이상의 공유 캐시 가 캐싱 계층구조에 포함되고 코어들(460A-460D)의 세트들에 의해 공유될 수 있다. 예를 들어, 프로세서 의 일 실시예는 24개의 코어를 포함하고, 각각의 코어는 그 자신의 L1 캐시, 12개의 공유 L2 캐시, 및 12개의 공유 L3 캐시를 갖는다. 이 실시예에서, L2 및 L3 캐시들 중 하나는 2개의 인접한 코어에 의해 공유된다. 프 로세서 및 그래픽 가속기 통합 모듈은 프로세서 메모리들(401-402)을 포함할 수 있는 시스템 메모리 와 접속한다. 코히어런스 버스(coherence bus)를 통한 인터-코어 통신을 통해 다양한 캐시들(462A-462D, 456) 및 시스 템 메모리에 저장된 데이터 및 명령어들에 대해 코히어런시(coherency)가 유지된다. 예를 들어, 각각의 캐시는 특정 캐시 라인들에의 검출된 판독들 또는 기입들에 응답하여 코히어런스 버스를 통해 통신하기 위 해 그와 연관된 캐시 코히어런시 로직/회로를 가질 수 있다. 일 구현에서, 캐시 액세스들을 스누핑하기 위해 코히어런스 버스를 통해 캐시 스누핑 프로토콜(cache snooping protocol)이 구현된다. 캐시 스누핑/코히"}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "어런시 기법들은 본 기술분야의 통상의 기술자에 의해 잘 이해되며, 본 명세서에 설명되는 기본 원리들을 모호 하게 하는 것을 회피하기 위해 여기서 상세히 설명되지 않을 것이다. 그래픽 가속 모듈을 코히어런스 버스에 통신가능하게 결합하는 프록시 회로가 제공될 수 있어, 그래픽 가속 모듈이 코어들의 피어로서 캐시 코히어런스 프로토콜에 참가할 수 있게 한다. 특히, 인터페 이스는 고속 링크(예를 들어, PCIe 버스, NVLink 등)를 통해 프록시 회로에 접속성 (connectivity)을 제공하고, 인터페이스는 그래픽 가속 모듈을 고속 링크에 접속한다. 일 구현에서, 가속기 통합 회로가 그래픽 가속 모듈의 복수의 그래픽 프로세싱 엔진들(431, 432, N) 을 대신하여 캐시 관리, 메모리 액세스, 컨텍스트 관리, 및 인터럽트 관리 서비스들을 제공한다. 그래픽 프로 세싱 엔진들(431, 432, N)은 각각 별개의 그래픽 프로세싱 유닛(GPU)을 포함할 수 있다. 대안적으로, 그래픽 프로세싱 엔진들(431, 432, N)은 그래픽 실행 유닛들, 미디어 프로세싱 엔진들(예를 들어, 비디오 인코더들/디 코더들), 샘플러들, 및 블릿 엔진들(blit engines)과 같은 GPU 내의 상이한 타입들의 그래픽 프로세싱 엔진들을 포함할 수 있다. 다시 말해서, 그래픽 가속 모듈은 복수의 그래픽 프로세싱 엔진들(431-432, N)을 갖는 GPU일 수 있거나 또는 그래픽 프로세싱 엔진들(431-432, N)은 공통 패키지, 라인 카드, 또는 칩 상에 집적된 개별 GPU 들일 수 있다. 가속기 통합 회로는 가상-대-물리 메모리 변환들(유효-대-실제 메모리 변환들(effective-to-real memory translations)로도 지칭됨) 및 시스템 메모리에 액세스하기 위한 메모리 액세스 프로토콜들과 같은 다양한 메모리 관리 기능들을 수행하기 위한 메모리 관리 유닛(MMU)을 포함할 수 있다. MMU는 또한 가상/유 효 대 물리/실제 어드레스 변환들을 캐싱하기 위한 변환 색인 버퍼(TLB)(도시되지 않음)를 포함할 수 있다. 일 구현에서, 캐시는 그래픽 프로세싱 엔진들(431, 432, N)에 의한 효율적 액세스를 위한 커맨드들 및 데이터 를 저장한다. 캐시 및 그래픽 메모리들(433-434, M)에 저장된 데이터는 코어 캐시들(462A-462D, 456) 및 시스템 메모리와 코히어런트하게 유지될 수 있다. 언급된 바와 같이, 이것은 캐시 및 메모리들(433- 434, M)을 대신하여 캐시 코히어런시 메커니즘에 참가하는 프록시 회로를 통해 달성될 수 있다(예를 들어, 프로세서 캐시들(462A-462D, 456) 상의 캐시 라인들의 수정들/액세스들과 관련된 업데이트들을 캐시에 전 송하고 캐시로부터 업데이트들을 수신함). 레지스터들의 세트가 그래픽 프로세싱 엔진들(431-432, N)에 의해 실행되는 스레드들에 대한 컨텍스트 데 이터를 저장하고 컨텍스트 관리 회로가 스레드 컨텍스트들을 관리한다. 예를 들어, 컨텍스트 관리 회로 는 컨텍스트 스위치들 동안에 다양한 스레드들의 컨텍스트들을 세이브 및 복원하기 위해 세이브 및 복원 동작들을 수행할 수 있다(예를 들어, 제1 스레드가 세이브되고 제2 스레드가 복원되어 제2 스레드가 그래픽 프 로세싱 엔진에 의해 실행될 수 있게 한다). 예를 들어, 컨텍스트 스위치에서, 컨텍스트 관리 회로는 메모 리 내의 지정된 영역(예를 들어, 컨텍스트 포인터에 의해 식별된 영역)에 현재 레지스터 값들을 저장할 수 있다. 그것은 그 후 컨텍스트로 리턴할 때 레지스터 값들을 복원할 수 있다. 인터럽트 관리 회로는, 예 를 들어, 시스템 디바이스들로부터 인터럽트들을 수신하고 수신된 인터럽트들을 프로세싱할 수 있다. 일 구현에서, 그래픽 프로세싱 엔진으로부터의 가상/유효 어드레스들은 MMU에 의해 시스템 메모리 내의 실제/물리 어드레스들로 변환된다. 선택적으로, 가속기 통합 회로는 다수의(예를 들어, 4, 8,-19-16개의) 그래픽 가속기 모듈들 및/또는 다른 가속기 디바이스들을 지원한다. 그래픽 가속기 모듈은 프로세서 상에서 실행되는 단일 애플리케이션에 전용될 수 있거나 또는 다수의 애플리케이션 사이에서 공 유될 수 있다. 선택적으로, 그래픽 프로세싱 엔진들(431-432, N)의 자원들이 다수의 애플리케이션들, 가상 머 신(VM)들, 또는 컨테이너들과 공유되는 가상화된 그래픽 실행 환경이 제공된다. 자원들은 VM들 및/또는 애플리 케이션들과 연관된 프로세싱 요건들 및 우선순위들에 기초하여 상이한 VM들 및/또는 애플리케이션들에 할당되는 \"슬라이스들\"로 세분될 수 있다. VM들 및 컨테이너들은 본 명세서에서 교환가능하게 사용될 수 있다. 가상 머신(VM)은 운영 체제 및 하나 이상의 애플리케이션을 실행하는 소프트웨어일 수 있다. VM은 사양, 구성 파일들, 가상 디스크 파일, 비휘발성 랜덤 액세스 메모리(NVRAM) 설정 파일, 및 로그 파일에 의해 정의될 수 있 고, 호스트 컴퓨팅 플랫폼의 물리 자원들에 의해 지원된다. VM은 전용 하드웨어를 모방하는 소프트웨어 상에 설치되는 운영 체제(OS) 또는 애플리케이션 환경을 포함할 수 있다. 최종 사용자는 전용 하드웨어 상에서 가질 수 있는 것과 동일한 경험을 가상 머신 상에서 갖는다. 하이퍼바이저라고 불리는 특수화된 소프트웨어는 PC 클 라이언트 또는 서버의 CPU, 메모리, 하드 디스크, 네트워크 및 다른 하드웨어 자원들을 완전히 에뮬레이트하여, 가상 머신들이 자원들을 공유할 수 있게 한다. 하이퍼바이저는 서로로부터 격리되는 다수의 가상 하드웨어 플 랫폼들을 에뮬레이트할 수 있어, 가상 머신들이 Linux®, Windows® 서버, VMware ESXi, 및 다른 운영 체제들을 동일한 기저 물리 호스트 상에서 실행할 수 있게 한다. 컨테이너는 애플리케이션들, 구성들 및 종속성들의 소프트웨어 패키지일 수 있으므로, 애플리케이션들은 하나의 컴퓨팅 환경에서 다른 컴퓨팅 환경으로 신뢰성있게 실행된다. 컨테이너들은 서버 플랫폼 상에 설치된 운영 체 제를 공유하고 격리된 프로세스들로서 실행할 수 있다. 컨테이너는 시스템 도구, 라이브러리 및 설정과 같은 소프트웨어가 실행될 필요가 있는 모든 것을 포함하는 소프트웨어 패키지일 수 있다. 컨테이너들은 전통적인 소프트웨어 프로그램들과 같이 설치되지 않으며, 이는 그것들이 다른 소프트웨어 및 운영 체제 자체로부터 격리 될 수 있게 한다. 컨테이너들의 격리된 성질은 여러 이점을 제공한다. 먼저, 컨테이너 내의 소프트웨어는 상 이한 환경들에서 동일하게 실행될 것이다. 예를 들어, PHP 및 MySQL을 포함하는 컨테이너는 Linux® 컴퓨터와 Windows® 머신 둘 다에서 동일하게 실행될 수 있다. 둘째, 컨테이너들은 추가된 보안을 제공하는데, 그 이유 는 소프트웨어가 호스트 운영 체제에 영향을 미치지 않을 것이기 때문이다. 설치된 애플리케이션은, 윈도우즈 레지스트리와 같은, 자원들을 수정하고 시스템 설정들을 변경할 수 있지만, 컨테이너는 컨테이너 내의 설정들만 을 수정할 수 있다. 따라서, 가속기 통합 회로는 그래픽 가속 모듈을 위한 시스템에 대한 브리지로서 작용하고, 어드레스 변환 및 시스템 메모리 캐시 서비스들을 제공한다. 일 실시예에서, 브리징 기능을 용이하게 하기 위해, 가속기 통합 회로는 또한 공유 I/O(예를 들어, PCIe, USB 등) 및 전압, 클로킹, 성능, 열, 및 보안의 시스템 제어를 가능하게 하는 하드웨어를 포함할 수 있다. 공유 I/O는 개별 물리 접속들을 이용할 수 있거나 또 는 고속 링크를 횡단할 수 있다. 또한, 가속기 통합 회로는 그래픽 프로세싱 엔진들, 인터럽트들, 및 메모리 관리의 가상화를 관리하기 위해 호스트 프로세서에 대한 가상화 설비들을 제공할 수 있다. 그래픽 프로세싱 엔진들(431-432, N)의 하드웨어 자원들은 호스트 프로세서에 의해 보여지는 실제 어드레 스 공간에 명시적으로 매핑되기 때문에, 임의의 호스트 프로세서는 유효 어드레스 값을 사용하여 이들 자원들을 직접 어드레싱할 수 있다. 가속기 통합 회로의 하나의 선택적인 기능은 그래픽 프로세싱 엔진들(431-432, N)의 물리적 분리이므로, 그것들이 시스템에 독립적인 유닛들로서 나타난다. 하나 이상의 그래픽 메모리(433-434, M)가 각각 그래픽 프로세싱 엔진들(431-432, N) 각각에 결합될 수 있다. 그래픽 메모리들(433-434, M)은 그래픽 프로세싱 엔진들(431-432, N) 각각에 의해 프로세싱되는 명령어들 및 데 이터를 저장한다. 그래픽 메모리들(433-434, M)은 DRAM들(스택형 DRAM들을 포함함), GDDR 메모리(예를 들어, GDDR5, GDDR6), 또는 HBM과 같은 휘발성 메모리들일 수 있고/있거나, 3D XPoint/Optane, 삼성 Z-NAND, 또는 Nano-Ram과 같은 비휘발성 메모리들일 수 있다. 고속 링크를 통한 데이터 트래픽을 감소시키기 위해, 그래픽 메모리들(433-434, M)에 저장된 데이터가 그 래픽 프로세싱 엔진들(431-432, N)에 의해 가장 빈번하게 사용되고 바람직하게는 코어들(460A-460D)에 의해 사 용되지 않을(적어도 빈번하게는 아님) 데이터인 것을 보장하기 위해 바이어싱 기법들이 사용될 수 있다. 유사 하게, 바이어싱 메커니즘은 코어들의 캐시들(462A-462D, 456) 및 시스템 메모리 내에 코어들(그리고 바람 직하게는 그래픽 프로세싱 엔진들(431-432, N)은 아님)에 의해 필요한 데이터를 유지하려고 시도한다. 도 4c에 도시된 변형예에 따르면, 가속기 통합 회로는 프로세서 내에 통합된다. 그래픽 프로세싱 엔 진들(431-432, N)은 인터페이스 및 인터페이스(다시, 임의의 형태의 버스 또는 인터페이스 프로토콜-20-을 이용할 수 있음)를 통해 고속 링크를 거쳐서 가속기 통합 회로에 직접 통신한다. 가속기 통합 회 로는 도 4b와 관련하여 설명된 것들과 동일한 연산들을 수행할 수 있지만, 코히어런스 버스 및 캐시 들(462A-462D, 456)에 근접한 것을 고려할 때 잠재적으로 더 높은 스루풋에서 수행할 수 있다. 설명된 실시예들은 전용-프로세스 프로그래밍 모델(그래픽 가속 모듈 가상화 없음) 및 공유 프로그래밍 모델(가 상화 있음)을 포함하는 상이한 프로그래밍 모델들을 지원할 수 있다. 후자는 가속기 통합 회로에 의해 제 어되는 프로그래밍 모델들 및 그래픽 가속 모듈에 의해 제어되는 프로그래밍 모델들을 포함할 수 있다. 전용 프로세스 모델의 실시예들에서, 그래픽 프로세싱 엔진들(431, 432, … N)은 단일 운영 체제 하의 단일 애 플리케이션 또는 프로세스에 전용될 수 있다. 단일 애플리케이션은 다른 애플리케이션 요청들을 그래픽 엔진들 (431, 432, … N)로 이동(funnel)시켜, VM/파티션 내에 가상화를 제공할 수 있다. 전용-프로세스 프로그래밍 모델들에서, 그래픽 프로세싱 엔진들(431, 432, N)은 다수의 VM/애플리케이션 파티션 들에 의해 공유될 수 있다. 공유 모델들은 그래픽 프로세싱 엔진들(431-432, N)을 가상화하여 각각의 운영 체 제에 의한 액세스를 허용하는 시스템 하이퍼바이저를 요구한다. 하이퍼바이저가 없는 단일-파티션 시스템들의 경우, 그래픽 프로세싱 엔진들(431-432, N)은 운영 체제에 의해 소유된다. 두 경우 모두에서, 운영 체제는 그 래픽 프로세싱 엔진들(431-432, N)을 가상화하여 각각의 프로세스 또는 애플리케이션에 대한 액세스를 제공할 수 있다. 공유 프로그래밍 모델의 경우, 그래픽 가속 모듈 또는 개별 그래픽 프로세싱 엔진(431-432, N)은 프로세스 핸들(process handle)을 사용하여 프로세스 요소를 선택한다. 프로세스 요소들은 시스템 메모리에 저장되 고, 본 명세서에 설명된 유효 어드레스 대 실제 어드레스 변환 기법들을 사용하여 어드레싱가능할 수 있다. 프 로세스 핸들은 그것의 컨텍스트를 그래픽 프로세싱 엔진(431-432, N)에 등록할 때(즉, 프로세스 요소를 프로세 스 요소 링크된 리스트(process element linked list)에 추가하기 위해 시스템 소프트웨어를 호출할 때) 호스트 프로세스에 제공되는 구현-특정 값일 수 있다. 프로세스 핸들의 하위 16-비트는 프로세스 요소 링크된 리스트 내의 프로세스 요소의 오프셋일 수 있다. 도 4d는 예시적인 가속기 통합 슬라이스를 도시한다. 본 명세서에서 사용되는 바와 같이, \"슬라이스\"는 가속기 통합 회로의 프로세싱 자원들의 특정된 부분을 포함한다. 시스템 메모리 내의 애플리케이션 유효 어드레스 공간은 프로세스 요소들을 저장한다. 프로세스 요소들은 프로세서 상에서 실행되는 애플리케이션들로부터의 GPU 기동들(invocations)에 응답하여 저장될 수 있다. 프로세스 요소는 대응하는 애플리케이션에 대한 프로세스 상태를 포함한다. 프로세스 요소에 포함된 작 업 디스크립터(WD)는 애플리케이션에 의해 요청된 단일 잡(job)일 수 있거나 또는 잡들의 큐(queue of jobs)에 대한 포인터를 포함할 수 있다. 후자의 경우, WD는 애플리케이션의 어드레스 공간 내의 잡 요청 큐에 대한 포인터이다. 그래픽 가속 모듈 및/또는 개별 그래픽 프로세싱 엔진들(431-432, N)은 시스템 내의 프로세스들의 전부 또 는 서브세트에 의해 공유될 수 있다. 예를 들어, 본 명세서에 설명된 기술들은 프로세스 상태를 설정하고 WD를 그래픽 가속 모듈에 전송하여 가상화된 환경에서 잡을 시작하기 위한 인프라스트럭처를 포함할 수 있다. 일 구현에서, 전용-프로세스 프로그래밍 모델은 구현-특정적이다. 이 모델에서는, 단일 프로세스가 그래픽 가 속 모듈 또는 개별 그래픽 프로세싱 엔진을 소유한다. 그래픽 가속 모듈이 단일 프로세스에 의 해 소유되기 때문에, 하이퍼바이저는 소유 파티션에 대해 가속기 통합 회로를 초기화하고, 운영 체제는 그 래픽 가속 모듈이 할당되는 시점에 소유 프로세스에 대해 가속기 통합 회로를 초기화한다. 동작 시에, 가속기 통합 슬라이스 내의 WD 페치 유닛이 그래픽 가속 모듈의 그래픽 프로세싱 엔 진들 중 하나에 의해 행해질 작업의 표시를 포함하는 다음 WD를 페치한다. WD로부터의 데이터는 레 지스터들에 저장되고, 예시된 바와 같은 MMU, 인터럽트 관리 회로 및/또는 컨텍스트 관리 회로 에 의해 사용될 수 있다. 예를 들어, MMU는 OS 가상 어드레스 공간 내의 세그먼트/페이지 테이 블들에 액세스하기 위한 세그먼트/페이지 워크 회로(segment/page walk circuitry)를 포함할 수 있다. 인터럽트 관리 회로는 그래픽 가속 모듈로부터 수신된 인터럽트 이벤트들을 프로세싱할 수 있다. 그래픽 연산들을 수행할 때, 그래픽 프로세싱 엔진(431-432, N)에 의해 생성된 유효 어드레스는 MMU에 의해 실제 어드레스로 변환된다. 동일한 세트의 레지스터들은 각각의 그래픽 프로세싱 엔진(431-432, N) 및/또는 그래픽 가속 모듈에 -21-대해 복제(duplicate)될 수 있고 하이퍼바이저 또는 운영 체제에 의해 초기화될 수 있다. 이러한 복제된 레지 스터들 각각은 가속기 통합 슬라이스에 포함될 수 있다. 일 실시예에서, 각각의 그래픽 프로세싱 엔진 (431-432, N)은 별개의 그래픽 프로세서 디바이스로서 하이퍼바이저에 제시될 수 있다. QoS 설정들은 특 정 그래픽 프로세싱 엔진(431-432, N)의 클라이언트들에 대해 구성될 수 있고 각각의 엔진의 클라이언트들 사이 의 데이터 격리는 인에이블(enable)될 수 있다. 하이퍼바이저에 의해 초기화될 수 있는 예시적인 레지스터들이 표 1에 도시되어 있다."}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "운영 체제에 의해 초기화될 수 있는 예시적인 레지스터들이 표 2에 도시되어 있다."}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "각각의 WD는 특정한 그래픽 가속 모듈 및/또는 그래픽 프로세싱 엔진(431-432, N)에 특정적일 수 있 다. 그것은 그래픽 프로세싱 엔진(431-432, N)이 작업을 수행하는 데 필요한 모든 정보를 포함하거나 또는 그 것은 애플리케이션이 완료될 작업의 커맨드 큐를 셋업한 메모리 위치에 대한 포인터일 수 있다. 도 4e는 공유 모델의 추가적인 선택적 상세사항을 도시한다. 그것은 프로세스 요소 리스트가 저장되는 하 이퍼바이저 실제 어드레스 공간을 포함한다. 하이퍼바이저 실제 어드레스 공간은 운영 체제에 대한 그래픽 가속 모듈 엔진들을 가상화하는 하이퍼바이저를 통해 액세스가능하다. 공유 프로그래밍 모델들은 시스템 내의 파티션들의 전부 또는 서브세트로부터의 프로세스들의 전부 또는 서브세 트가 그래픽 가속 모듈을 사용할 수 있게 한다. 그래픽 가속 모듈이 다수의 프로세스들 및 파티션들 에 의해 공유되는 2가지 프로그래밍 모델이 있다: 시간-슬라이스 공유(time-sliced shared) 및 그래픽 지향 공 유(graphics directed shared). 이 모델에서, 시스템 하이퍼바이저는 그래픽 가속 모듈을 소유하고 그의 기능을 모든 운영 체제들 에 이용가능하게 한다. 시스템 하이퍼바이저에 의한 가상화를 지원하는 그래픽 가속 모듈의 경 우, 그래픽 가속 모듈은 다음의 요건들을 준수할 수 있다: 1) 애플리케이션의 잡 요청이 자율적이어야 하 거나(즉, 상태가 잡들 사이에서 유지될 필요가 없음), 또는 그래픽 가속 모듈이 컨텍스트 세이브 및 복원 메커니즘을 제공해야 한다. 2) 애플리케이션의 잡 요청이 임의의 변환 결함들을 포함하여, 특정된 시간량 내에 완료되도록 그래픽 가속 모듈에 의해 보장되거나, 또는 그래픽 가속 모듈은 잡의 프로세싱을 선점하 는 능력을 제공한다. 3) 그래픽 가속 모듈은 지향 공유 프로그래밍 모델(directed shared programming-22-model)에서 동작할 때 프로세스들 사이의 공정성을 보장받아야 한다. 공유 모델의 경우, 애플리케이션은 그래픽 가속 모듈 타입, 작업 디스크립터(WD), 권한 마스크 레지 스터(authority mask register, AMR) 값, 및 컨텍스트 세이브/복원 영역 포인터(context save/restore area pointer, CSRP)로 운영 체제 시스템 호출을 행하도록 요구될 수 있다. 그래픽 가속 모듈 타입은 시 스템 호출에 대한 타겟화된 가속 기능을 설명한다. 그래픽 가속 모듈 타입은 시스템-특정 값일 수 있다. WD는 구체적으로 그래픽 가속 모듈에 대해 포맷화되고 그래픽 가속 모듈 커맨드, 사용자-정의 구조에 대한 유효 어드레스 포인터, 커맨드들의 큐에 대한 유효 어드레스 포인터, 또는 그래픽 가속 모듈에 의해 수행될 작업을 설명하는 임의의 다른 데이터 구조의 형태로 되어 있을 수 있다. 일 실시예에서, AMR 값은 현재 프로세스에 사용하기 위한 AMR 상태이다. 운영 체제로 전달되는 값은 AMR을 설정하는 애플리케이션과 유사하다. 가속기 통합 회로 및 그래픽 가속 모듈 구현들이 UAMOR(User Authority Mask Override Register)를 지원하지 않는 경우, 운영 체제는 하이퍼바이저 호출에서 AMR을 전달하기 전에 현재 UAMOR 값을 AMR 값에 적용할 수 있다. 하이퍼바이저는 AMR을 프로세스 요소 내에 배치하기 전에 현재 AMOR(Authority Mask Override Register) 값을 선택적으로 적용할 수 있다. CSRP는 그래픽 가속 모듈이 컨텍스트 상태를 세이브 및 복원하기 위해 애플리케이션의 어드레스 공간 내의 영역의 유효 어드레스를 포 함하는 레지스터들 중 하나일 수 있다. 이러한 포인터는 잡들 사이에 상태를 세이브할 필요가 없는 경우 또는 잡이 선점되는 경우 선택적이다. 컨텍스트 세이브/복원 영역은 핀형 시스템 메모리(pinned system memory)일 수 있다. 시스템 호출을 수신하면, 운영 체제는 애플리케이션이 등록되었고 그래픽 가속 모듈을 사용할 권한을 부여받았다는 것을 검증할 수 있다. 운영 체제는 이어서 표 3에 도시된 정보로 하이퍼바이저(49 6)를 호출한다."}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "하이퍼바이저 호출을 수신하면, 하이퍼바이저는 운영 체제가 등록되었고 그래픽 가속 모듈을 사 용할 권한을 부여받았다는 것을 검증한다. 이어서, 하이퍼바이저는 프로세스 요소를 대응하는 그래 픽 가속 모듈 타입에 대한 프로세스 요소 링크된 리스트에 넣는다. 프로세스 요소는 표 4에 도시된 정보 를 포함할 수 있다.-23- 하이퍼바이저는 복수의 가속기 통합 슬라이스 레지스터들을 초기화할 수 있다. 도 4f에 도시된 바와 같이, 하나의 선택적인 구현에서, 물리적 프로세서 메모리들(401-402) 및 GPU 메모리들 (420-423)에 액세스하는 데 사용되는 공통 가상 메모리 어드레스 공간을 통해 어드레싱가능한 통합 메모리가 이 용된다. 이 구현에서, GPU들(410-413) 상에서 실행되는 연산들은 동일한 가상/유효 메모리 어드레스 공간을 이 용하여 프로세서 메모리들(401-402)에 액세스하고 그 반대도 가능하므로, 프로그램가능성(programmability)을 단순화한다. 가상/유효 어드레스 공간의 제1 부분은 프로세서 메모리에 할당될 수 있고, 제2 부분은 제2 프로세서 메모리에 할당될 수 있고, 제3 부분은 GPU 메모리에 할당될 수 있으며, 기타 등등이다. 그 에 의해 전체 가상/유효 메모리 공간(때때로 유효 어드레스 공간으로 지칭됨)이 프로세서 메모리들(401-402) 및 GPU 메모리들(420-423) 각각에 걸쳐 분산될 수 있어, 임의의 프로세서 또는 GPU가 그 메모리에 매핑된 가상 어 드레스로 임의의 물리 메모리에 액세스할 수 있게 한다. GPU들(410-413)과 호스트 프로세서들(예를 들어, 405)의 캐시들 사이의 캐시 코히어런스를 보장하고 특정 타입 들의 데이터가 저장되어야 하는 물리 메모리들을 나타내는 바이어싱 기법들을 구현하는 MMU들(439A-439E) 중 하 나 이상 내의 바이어스/코히어런스 관리 회로(494A-494E)가 제공될 수 있다. 바이어스/코히어런스 관리 회로 (494A-494E)의 다수의 인스턴스들이 도 4f에 도시되어 있지만, 바이어스/코히어런스 회로는 하나 이상의 호스트 프로세서의 MMU 내에 및/또는 가속기 통합 회로 내에 구현될 수 있다. GPU-부착 메모리(GPU-attached memory)(420-423)는 시스템 메모리의 일부로서 매핑되고, 공유 가상 메모리 (SVM) 기술을 사용하여 액세스될 수 있지만, 전체 시스템 캐시 코히어런스와 연관된 전형적인 성능 단점을 겪지 않는다. 부담되는 캐시 코히어런스 오버헤드 없이 시스템 메모리로서 액세스되는 GPU-부착 메모리(420-423)에 대한 능력은 GPU 오프로드를 위한 유익한 동작 환경을 제공한다. 이러한 배열은 종래의 I/O DMA 데이터 복사들 의 오버헤드 없이 호스트 프로세서 소프트웨어가 피연산자들을 셋업하고 계산 결과들을 액세스할 수 있게 한다. 그러한 종래의 복사들은 드라이버 호출들, 인터럽트들 및 메모리 매핑된 I/O(MMIO) 액세스들을 수반하며, 이들 모두가 단순한 메모리 액세스들에 비해 비효율적이다. 동시에, 캐시 코히어런스 오버헤드들 없 이 GPU 부착 메모리(420-423)에 액세스하는 능력은 오프로드된 계산의 실행 시간에 중요할 수 있다. 예를 들어, 상당한 스트리밍 기입 메모리 트래픽을 갖는 경우에, 캐시 코히어런스 오버헤드는 GPU(410-413)에 의해 보여지는 유효 기입 대역폭을 상당히 감소시킬 수 있다. 피연산자 셋업의 효율, 결과 액세스의 효율, 및 GPU 계산의 효율은 모두 GPU 오프로드의 유효성을 결정하는데 역할을 한다. GPU 바이어스와 호스트 프로세서 바이어스 사이의 선택은 바이어스 추적기 데이터 구조에 의해 구동될 수 있다. 예를 들어, GPU-부착 메모리 페이지당 1 또는 2 비트를 포함하는 페이지-입상 구조(page-granular structure) (즉, 메모리 페이지의 입도(granularity)로 제어됨)일 수 있는 바이어스 테이블이 사용될 수 있다. 바이어스 테이블은 GPU(410-413) 내의 바이어스 캐시(예를 들어, 바이어스 테이블의 빈번하게/최근에 사용된 엔트리들을 캐싱하는 것)를 갖거나 갖지 않는, 하나 이상의 GPU-부착 메모리들(420-423)의 도난 메모리 범위(stolen memory-24-range)에서 구현될 수 있다. 대안적으로, 전체 바이어스 테이블은 GPU 내에 유지될 수 있다. 일 구현에서, GPU-부착 메모리(420-423)에 대한 각각의 액세스와 연관된 바이어스 테이블 엔트리는 GPU 메모리 에 대한 실제 액세스 전에 액세스되어, 다음의 동작들을 야기한다. 첫째, GPU 바이어스에서 그들의 페이지를 발견하는 GPU(410-413)로부터의 로컬 요청들은 대응하는 GPU 메모리(420-423)로 직접 포워딩된다. 호스트 바이 어스에서 그들의 페이지를 발견하는 GPU로부터의 로컬 요청들은 (예를 들어, 위에서 논의한 바와 같은 고속 링 크를 통해) 프로세서에 포워딩된다. 선택적으로, 호스트 프로세서 바이어스에서 요청된 페이지를 발견하 는 프로세서로부터의 요청은 정상 메모리 판독과 같이 요청을 완료한다. 대안적으로, GPU-바이어싱된 페 이지로 향하는 요청들은 GPU(410-413)로 포워딩될 수 있다. 그 다음, GPU는 페이지를 현재 사용하고 있지 않다 면 페이지를 호스트 프로세서 바이어스로 전환할 수 있다. 페이지의 바이어스 상태는, 소프트웨어-기반 메커니즘, 하드웨어-보조 소프트웨어-기반 메커니즘, 또는 제한된 세트의 경우들에 대해, 순수 하드웨어-기반 메커니즘에 의해 변경될 수 있다. 바이어스 상태를 변경하기 위한 하나의 메커니즘은 API 호출(예를 들어, OpenCL)을 이용하고, 이는 차례로, GPU 의 디바이스 드라이버를 호출하고, 이는 차례로, GPU에 바이어스 상태를 변경하도록 지시하는 메시지를 전송(또 는 커맨드 디스크립터를 인큐(enqueue))하고, 일부 전환들의 경우, 호스트에서의 캐시 플러싱 동작(cache flushing operation)을 수행한다. 캐시 플러싱 동작은 호스트 프로세서 바이어스로부터 GPU 바이어스로의 전환에 대해 요구되지만, 반대 전환에 대해서는 요구되지 않는다. 캐시 코히어런시는 호스트 프로세서에 의해 캐시불가능한 GPU-바이어싱된 페이지들을 일시적으로 렌더링함 으로써 유지될 수 있다. 이러한 페이지들에 액세스하기 위해, 프로세서는 구현에 따라 즉시 액세스를 승 인할 수 있거나 그렇지 않을 수 있는 GPU로부터의 액세스를 요청할 수 있다. 따라서, 호스트 프로세서 와 GPU 사이의 통신을 줄이기 위해, GPU-바이어싱된 페이지들이 GPU에 의해 요구되지만 호스트 프로 세서에 의해 요구되지 않는 것들이고 그 반대도 가능한 것들임을 보장하는 것이 유익하다. 그래픽 프로세싱 파이프라인 도 5는 그래픽 프로세싱 파이프라인을 도시한다. 도 2d에서와 같은 그래픽 멀티프로세서, 도 3a의 그래픽 멀티프로세서, 도 3b의 그래픽 멀티프로세서와 같은 그래픽 멀티프로세서는 예시된 그래픽 프 로세싱 파이프라인을 구현할 수 있다. 그래픽 멀티프로세서는, 도 1의 병렬 프로세서(들)에 관련될 수 있고 그것들 중 하나 대신에 사용될 수 있는, 도 2a의 병렬 프로세서와 같은, 본 명세서에 설명된 바와 같은 병렬 프로세싱 서브시스템들 내에 포함될 수 있다. 다양한 병렬 프로세싱 시스템들은 본 명세서에 설명된 바와 같이 병렬 프로세싱 유닛(예를 들어, 도 2a의 병렬 프로세싱 유닛)의 하나 이상의 인스턴스를 통해 그래픽 프로세싱 파이프라인을 구현할 수 있다. 예를 들어, 셰이더 유닛(예를 들어, 도 2c의 그래픽 멀티 프로세서)은 정점 프로세싱 유닛, 테셀레이션 제어 프로세싱 유닛, 테셀레이션 평가 프로세싱 유닛, 지오메트리 프로세싱 유닛, 및 프래그먼트/픽셀 프로세싱 유닛 중 하나 이상의 유닛의 기 능들을 수행하도록 구성될 수 있다. 데이터 어셈블러, 프리미티브 어셈블러들(506, 514, 518), 테셀레이 션 유닛, 래스터화기, 및 래스터 연산 유닛의 기능들은 또한 프로세싱 클러스터(예를 들어, 도 2a의 프로세싱 클러스터) 및 대응하는 파티션 유닛(예를 들어, 도 2a의 파티션 유닛(220A-220N)) 내의 다 른 프로세싱 엔진들에 의해 수행될 수 있다. 그래픽 프로세싱 파이프라인은 또한 하나 이상의 기능을 위 한 전용 프로세싱 유닛들을 사용하여 구현될 수 있다. 그래픽 프로세싱 파이프라인의 하나 이상의 부분이 범용 프로세서(예를 들어, CPU) 내의 병렬 프로세싱 로직에 의해 수행되는 것도 가능하다. 선택적으로, 그래픽 프로세싱 파이프라인의 하나 이상의 부분은 도 2a의 메모리 인터페이스의 인스턴스일 수 있는 메모리 인터페이스를 통해 온-칩 메모리(예를 들어, 도 2a에서와 같은 병렬 프로세서 메모리)에 액세스할 수 있다. 그래픽 프로세서 파이프라인은 또한 도 3c에서와 같은 멀티-코어 그룹(365A)을 통해 구현될 수 있 다. 데이터 어셈블러는 표면들 및 프리미티브들에 대한 정점 데이터를 수집할 수 있는 프로세싱 유닛이다. 데 이터 어셈블러는 이어서 정점 속성들(vertex attributes)을 포함하는 정점 데이터를 정점 프로세싱 유닛 에 출력한다. 정점 프로세싱 유닛은 정점 셰이더 프로그램들을 실행하여, 정점 셰이더 프로그램들에 의해 특정된 바와 같이 정점 데이터를 라이팅(lighting) 및 변환하는 프로그램가능 실행 유닛이다. 정점 프로 세싱 유닛은 정점 데이터를 프로세싱하는데 사용하기 위해 캐시, 로컬 또는 시스템 메모리에 저장되는 데 이터를 판독하고, 정점 데이터를 객체-기반 좌표 표현으로부터 세계 공간 좌표 공간 또는 정규화된 디바이스 좌 표 공간으로 변환하도록 프로그램될 수 있다.-25-프리미티브 어셈블러의 제1 인스턴스는 정점 프로세싱 유닛으로부터 정점 속성들을 수신한다. 프리 미티브 어셈블러는 필요에 따라 저장된 정점 속성들을 판독하고, 테셀레이션 제어 프로세싱 유닛에 의한 프로세싱을 위해 그래픽 프리미티브들을 구성한다. 그래픽 프리미티브들은 다양한 그래픽 프로세싱 애플 리케이션 프로그래밍 인터페이스(API)에 의해 지원되는 바와 같은 삼각형들, 라인 세그먼트들, 포인트들, 패치 들 등을 포함한다. 테셀레이션 제어 프로세싱 유닛은 입력 정점들을 지오메트릭 패치에 대한 제어 포인트들로서 취급한다. 제어 포인트들은 패치(예를 들어, 패치의 베이스들)로부터의 입력 표현으로부터 테셀레이션 평가 프로세싱 유닛 에 의한 표면 평가에 사용하기에 적합한 표현으로 변환된다. 테셀레이션 제어 프로세싱 유닛은 또한 지오메트릭 패치들의 에지들에 대한 테셀레이션 팩터들을 계산할 수 있다. 테셀레이션 팩터는 단일 에지에 적 용되고, 에지와 연관된 뷰-의존적 상세 레벨(view-dependent level of detail)을 정량화한다. 테셀레이션 유닛 은 패치의 에지들에 대한 테셀레이션 팩터들을 수신하고, 테셀레이션 평가 프로세싱 유닛에 송신되는 라인, 삼각형, 또는 사변형 프리미티브들과 같은 다수의 지오메트릭 프리미티브들로 패치를 테셀레이션하도록 구성된다. 테셀레이션 평가 프로세싱 유닛은 세분된 패치의 파라미터화된 좌표들에 대해 연산하여 지오메 트릭 프리미티브들과 연관된 각각의 정점에 대한 정점 속성들 및 표면 표현을 생성한다. 프리미티브 어셈블러의 제2 인스턴스는 테셀레이션 평가 프로세싱 유닛으로부터 정점 속성들을 수신 하고, 필요에 따라 저장된 정점 속성들을 판독하고, 지오메트리 프로세싱 유닛에 의한 프로세싱을 위해 그 래픽 프리미티브들을 구성한다. 지오메트리 프로세싱 유닛은 지오메트리 셰이더 프로그램들을 실행하여 지오메트리 셰이더 프로그램들에 의해 특정된 바와 같이 프리미티브 어셈블러로부터 수신된 그래픽 프리미 티브들을 변환하는 프로그램가능 실행 유닛이다. 지오메트리 프로세싱 유닛은 그래픽 프리미티브들을 하 나 이상의 새로운 그래픽 프리미티브로 세분하고 새로운 그래픽 프리미티브들을 래스터화하는데 사용되는 파라 미터들을 계산하도록 프로그램될 수 있다. 지오메트리 프로세싱 유닛은 지오메트리 스트림에 요소들을 추가 또는 삭제할 수 있다. 지오메트리 프로 세싱 유닛은 새로운 그래픽 프리미티브들을 특정하는 파라미터들 및 정점들을 프리미티브 어셈블러에 출력한다. 프리미티브 어셈블러는 지오메트리 프로세싱 유닛으로부터 파라미터들 및 정점들을 수신 하고 뷰포트 스케일, 컬, 및 클립 유닛(viewport scale, cull, and clip unit)에 의한 프로세싱을 위해 그래픽 프리미티브들을 구성한다. 지오메트리 프로세싱 유닛은 지오메트리 데이터를 프로세싱하는데 사용 하기 위해 병렬 프로세서 메모리 또는 시스템 메모리에 저장되는 데이터를 판독한다. 뷰포트 스케일, 컬, 및 클립 유닛은 클리핑, 컬링, 및 뷰포트 스케일링을 수행하고 프로세싱된 그래픽 프리미티브들을 래스터화기 에 출력한다. 래스터화기는 깊이 컬링 및 다른 깊이-기반 최적화들을 수행할 수 있다. 래스터화기는 또한 새로운 그래픽 프리미티브들에 대한 스캔 변환을 수행하여 프래그먼트들을 생성하고 이들 프래그먼트들 및 연관된 커버 리지 데이터를 프래그먼트/픽셀 프로세싱 유닛에 출력한다. 프래그먼트/픽셀 프로세싱 유닛은 프래 그먼트 셰이더 프로그램들 또는 픽셀 셰이더 프로그램들을 실행하도록 구성되는 프로그램가능 실행 유닛이다. 프래그먼트/픽셀 프로세싱 유닛은 프래그먼트 또는 픽셀 셰이더 프로그램들에 의해 특정된 바와 같이, 래 스터화기로부터 수신된 프래그먼트들 또는 픽셀들을 변환한다. 예를 들어, 프래그먼트/픽셀 프로세싱 유 닛은 텍스처 매핑, 셰이딩, 블렌딩, 텍스처 보정 및 원근 보정을 포함하지만 이에 제한되지 않는 연산들을 수행하여 래스터 연산 유닛에 출력되는 셰이딩된 프래그먼트들 또는 픽셀들을 생성하도록 프로그램될 수 있다. 프래그먼트/픽셀 프로세싱 유닛은 프래그먼트 데이터를 프로세싱할 때 사용하기 위해 병렬 프로세 서 메모리 또는 시스템 메모리에 저장되는 데이터를 판독할 수 있다. 프래그먼트 또는 픽셀 셰이더 프로그램들 은 프로세싱 유닛들을 위해 구성된 샘플링 레이트에 따라 샘플, 픽셀, 타일, 또는 다른 입도들로 셰이딩하도록 구성될 수 있다. 래스터 연산 유닛은 스텐실, z-테스트, 블렌딩 등을 포함하지만 이에 제한되지 않는 래스터 연산들을 수행 하고, 그래픽 메모리(예를 들어, 도 2a에서와 같은 병렬 프로세서 메모리, 및/또는 도 1에서와 같은 시스 템 메모리)에 저장되거나, 하나 이상의 디스플레이 디바이스(들) 상에 디스플레이되거나 하나 이상의 프로세서(들) 또는 병렬 프로세서(들) 중 하나에 의한 추가 프로세싱을 위해 픽셀 데이터를 프로세싱 된 그래픽 데이터로서 출력하는 프로세싱 유닛이다. 래스터 연산 유닛은 메모리에 기입되는 z 또는 컬러 데이터를 압축하고 메모리로부터 판독되는 z 또는 컬러 데이터를 압축해제하도록 구성될 수 있다. 머신 러닝 개요 -26- 전술한 아키텍처는 머신 러닝 모델들을 사용하여 훈련 및 추론 연산들을 수행하기 위해 적용될 수 있다. 머신 러닝은 많은 종류의 태스크들을 해결하는 데 성공적이었다. 머신 러닝 알고리즘들(예를 들어, 신경망)을 훈련 하고 사용할 때 발생하는 계산들은 자연스럽게 효율적인 병렬 구현들에 적합하다. 따라서, 범용 그래픽 프로세 싱 유닛(GPGPU)들과 같은 병렬 프로세서들은 딥 신경망들의 실제 구현에서 상당한 역할을 하였다. 단일 명령어, 다중 스레드(SIMT) 아키텍처들을 갖는 병렬 그래픽 프로세서들은 그래픽 파이프라인에서의 병렬 프로세 싱의 양을 최대화하도록 설계된다. SIMT 아키텍처에서, 병렬 스레드들의 그룹들은 프로세싱 효율을 증가시키기 위해 가능한 한 자주 프로그램 명령어들을 동기식으로 함께 실행하려고 시도한다. 병렬 머신 러닝 알고리즘 구 현들에 의해 제공되는 효율은 고용량 네트워크(high capacity network)들의 사용을 허용하고 이들 네트워크들이 더 큰 데이터세트들 상에서 훈련될 수 있게 한다. 머신 러닝 알고리즘은 데이터 세트에 기초하여 학습할 수 있는 알고리즘이다. 예를 들어, 머신 러닝 알고리즘 들은 데이터 세트 내에서 고레벨 추상화들을 모델링하도록 설계될 수 있다. 예를 들어, 이미지 인식 알고리즘 들은 여러 카테고리들 중에서 주어진 입력이 속하는 카테고리를 결정하는 데 사용될 수 있고; 회귀 알고리즘들 은 입력이 주어지면 수치 값을 출력할 수 있고; 패턴 인식 알고리즘들은 변환된 텍스트를 생성하거나 텍스트 대 음성(text to speech) 및/또는 음성 인식을 수행하기 위해 사용될 수 있다. 예시적인 타입의 머신 러닝 알고리즘은 신경망이다. 많은 타입들의 신경망들이 있고; 간단한 타입의 신경망이 피드포워드 네트워크(feedforward network)이다. 피드포워드 네트워크는 노드들이 층들로 배열되는 비순환 그 래프로서 구현될 수 있다. 전형적으로, 피드포워드 네트워크 토폴로지는 적어도 하나의 은닉 층에 의해 분리되 는 입력 층과 출력 층을 포함한다. 은닉 층은 입력 층에 의해 수신된 입력을 출력 층에서 출력을 생성하는데 유용한 표현으로 변환한다. 네트워크 노드들은 에지들을 통해 인접한 층들 내의 노드들에 완전히 접속되지만, 각각의 층 내의 노드들 사이에는 에지들이 존재하지 않는다. 피드포워드 네트워크의 입력 층의 노드들에서 수 신된 데이터는 층들을 접속하는 에지들 각각과 각각 연관된 계수들(\"가중치들\")에 기초하여 네트워크 내의 각각 의 연속적인 층의 노드들의 상태들을 계산하는 활성화 함수를 통해 출력 층의 노드들로 전파된다(즉, 피드포워 드된다). 실행 중인 알고리즘에 의해 표현되는 특정 모델에 따라, 신경망 알고리즘으로부터의 출력은 다양한 형태들을 취할 수 있다. 머신 러닝 알고리즘이 특정 문제를 모델링하기 위해 사용될 수 있기 전에, 알고리즘은 훈련 데이터 세트 (training data set)를 사용하여 훈련된다. 신경망을 훈련하는 것은 네트워크 토폴로지를 선택하는 것, 네트워 크에 의해 모델링되는 문제를 표현하는 훈련 데이터의 세트를 사용하는 것, 및 훈련 데이터 세트의 모든 인스턴 스들에 대해 최소 에러로 네트워크 모델이 수행될 때까지 가중치들을 조정하는 것을 수반한다. 예를 들어, 신 경망에 대한 지도 학습 훈련 프로세스(supervised learning training process) 동안, 훈련 데이터 세트에서의 인스턴스를 나타내는 입력에 응답하여 네트워크에 의해 생성된 출력이 그 인스턴스에 대한 \"올바른\" 라벨링된 출력과 비교되고, 출력과 라벨링된 출력 사이의 차이를 나타내는 에러 신호가 계산되고, 접속들과 연관된 가중 치들은 에러 신호가 네트워크의 층들을 통해 역방향으로 전파됨에 따라 그 에러를 최소화하도록 조정된다. 네 트워크는 훈련 데이터 세트의 인스턴스들로부터 생성된 출력들 각각에 대한 에러들이 최소화될 때 \"훈련된\" 것으로 간주된다. 머신 러닝 알고리즘의 정확도는 알고리즘을 훈련시키는데 사용되는 데이터 세트의 품질에 의해 상당히 영향을 받을 수 있다. 훈련 프로세스는 계산 집약적일 수 있고, 종래의 범용 프로세서 상에서 상당한 양의 시간을 요 구할 수 있다. 따라서, 병렬 프로세싱 하드웨어는 많은 타입들의 머신 러닝 알고리즘들을 훈련시키는 데 사용 된다. 이것은, 신경망들에서의 계수들을 조정하는 데에 수행되는 계산들이 자연스럽게 병렬 구현들에 적합하기 때문에, 신경망들의 훈련을 최적화하는데 특히 유용하다. 구체적으로, 많은 머신 러닝 알고리즘들 및 소프트웨 어 애플리케이션들은 범용 그래픽 프로세싱 디바이스들 내에서 병렬 프로세싱 하드웨어를 사용하도록 적응되어 있다. 도 6은 머신 러닝 소프트웨어 스택의 일반화된 도면이다. 머신 러닝 애플리케이션은 훈련 데이터세 트를 사용하여 신경망을 훈련하거나 또는 훈련된 딥 신경망을 사용하여 머신 지능(machine intelligence)을 구 현하도록 구성될 수 있는 임의의 로직이다. 머신 러닝 애플리케이션은 배치 전에 신경망을 훈련시키기 위 해 사용될 수 있는 신경망 및/또는 특수화된 소프트웨어에 대한 훈련 및 추론 기능을 포함할 수 있다. 머신 러 닝 애플리케이션은 이미지 인식, 매핑 및 로컬라이제이션(mapping and localization), 자율 내비게이션, 음성 합성, 의료 영상(medical imaging), 또는 언어 번역을 포함하지만 이에 제한되지 않는 임의의 타입의 머신 지능을 구현할 수 있다. 예시적인 머신 러닝 애플리케이션들은 음성-기반 가상 보조자들(voice-based virtual assistants), 이미지 또는 얼굴 인식 알고리즘들, 자율 네비게이션, 및 머신 러닝 애플리케이션들(60-27-2)에 의해 사용되는 머신 러닝 모델들을 훈련시키는데 사용되는 소프트웨어 도구들을 포함하지만, 이에 제한되 지 않는다. 머신 러닝 애플리케이션에 대한 하드웨어 가속은 머신 러닝 프레임워크를 통해 인에이블될 수 있다. 머신 러닝 프레임워크는 머신 러닝 프리미티브들의 라이브러리를 제공할 수 있다. 머신 러닝 프리미티브 들은 머신 러닝 알고리즘들에 의해 일반적으로 수행되는 기본 연산들이다. 머신 러닝 프레임워크가 없다 면, 머신 러닝 알고리즘들의 개발자들은 머신 러닝 알고리즘과 연관된 메인 계산 로직을 생성하고 최적화한 다 음, 새로운 병렬 프로세서들이 개발됨에 따라 계산 로직을 재-최적화하도록 요구될 것이다. 대신에, 머신 러닝 애플리케이션은 머신 러닝 프레임워크에 의해 제공되는 프리미티브들을 사용하여 필요한 계산들을 수행하 도록 구성될 수 있다. 예시적인 프리미티브들은 컨볼루션 신경망(convolutional neural network, CNN)을 훈련 하는 동안 수행되는 계산 연산들인 텐서 컨볼루션들(tensor convolutions), 활성화 함수들, 및 풀링(pooling)을 포함한다. 머신 러닝 프레임워크는 또한 행렬 및 벡터 연산들과 같은 많은 머신 러닝 알고리즘들에 의해 수행되는 기본 선형 대수 서브프로그램들(basic linear algebra subprograms)을 구현하기 위해 프리미티브들을 제공할 수 있다. 머신 러닝 프레임워크의 예들은, TensorFlow, TensorRT, PyTorch, MXNet, Caffee, 및 다른 고레벨 머신 러닝 프레임워크들을 포함하지만, 이에 제한되지 않는다. 머신 러닝 프레임워크는 머신 러닝 애플리케이션으로부터 수신된 입력 데이터를 프로세싱하고, 계산 프레임워크에 적절한 입력을 생성할 수 있다. 계산 프레임워크는, 머신 러닝 프레임워크가 GPGPU 하드웨어의 아키텍처를 숙지할 필요 없이 머신 러닝 프레임워크가 GPGPU 하드웨어를 통해 하드웨어 가속을 이용할 수 있게 하도록 GPGPU 드라이버에 제공된 기저 명령어들을 추상화할 수 있다. 추 가적으로, 계산 프레임워크는 GPGPU 하드웨어의 다양한 타입들 및 세대들에 걸쳐 머신 러닝 프레임워 크에 대한 하드웨어 가속을 가능하게 할 수 있다. 예시적인 계산 프레임워크들은 CUDA 계산 프레임 워크 및 CUDA 딥 신경망(cuDNN) 라이브러리와 같은 연관된 머신 러닝 라이브러리들을 포함한다. 머신 러닝 소 프트웨어 스택은 멀티-GPU 및 멀티-노드 계산을 용이하게 하는 통신 라이브러리들 또는 프레임워크들을 또 한 포함할 수 있다. GPGPU 머신 러닝 가속 도 7은 도 2a의 병렬 프로세서 또는 도 1의 병렬 프로세서(들)일 수 있는 범용 그래픽 프로세싱 유닛 을 도시한다. 범용 프로세싱 유닛(GPGPU)은, 딥 신경망들을 훈련하는 것과 연관된 계산 작업부하들 의 타입의 프로세싱을 가속하기 위해 머신 러닝 프레임워크에 의해 제공되는 프리미티브들의 하드웨어 가속에 대한 지원을 제공하도록 구성될 수 있다. 추가적으로, GPGPU는 GPGPU의 다른 인스턴스들에 직접적으로 링 크되어 멀티-GPU 클러스터를 생성함으로써 특히 딥 신경망들에 대한 훈련 속도를 개선시킬 수 있다. 프리미티 브들은 또한 배치된 신경망들에 대한 추론 연산들을 가속하기 위해 지원된다. GPGPU는 호스트 프로세서와의 접속을 가능하게 하는 호스트 인터페이스를 포함한다. 호스트 인터페 이스는 PCI 익스프레스 인터페이스일 수 있다. 그러나, 호스트 인터페이스는 또한 벤더 특정 통신 인터페 이스 또는 통신 패브릭일 수 있다. GPGPU는 호스트 프로세서로부터 커맨드들을 수신하고 전역적 스케줄러 를 사용하여 그러한 커맨드들과 연관된 실행 스레드들을 프로세싱 클러스터들(706A-706H)의 세트에 분배한 다. 프로세싱 클러스터들(706A-706H)은 캐시 메모리를 공유한다. 캐시 메모리는 프로세싱 클러스터 (706A-706H) 내의 캐시 메모리들을 위한 상위-레벨 캐시로서 역할을 할 수 있다. 예시된 프로세싱 클러스터들 (706A-706H)은 도 2a에서와 같은 프로세싱 클러스터들(214A-214N)과 대응할 수 있다. GPGPU는 메모리 컨트롤러들(712A-712B)의 세트를 통해 프로세싱 클러스터들(706A-706H)과 결합된 메모리 (714A-714B)를 포함한다. 메모리(714A-714B)는 동적 랜덤 액세스 메모리(DRAM) 또는 그래픽 더블 데이터 레이 트(GDDR) 메모리를 포함하는 동기식 그래픽 랜덤 액세스 메모리(SGRAM)와 같은 그래픽 랜덤 액세스 메모리를 포 함하는 다양한 타입들의 메모리 디바이스들을 포함할 수 있다. 메모리(714A-714B)는 또한 고대역폭 메모리 (HBM)를 포함하지만 이에 제한되지 않는 3D 스택형 메모리를 포함할 수 있다. 프로세싱 클러스터들(706A-706H) 각각은 도 2d의 그래픽 멀티프로세서, 도 3a의 그래픽 멀티프로세서 , 도 3b의 그래픽 멀티프로세서와 같은 그래픽 멀티프로세서들의 세트를 포함할 수 있거나, 또는 도 3c에서와 같은 멀티-코어 그룹(365A-365N)을 포함할 수 있다. 계산 클러스터의 그래픽 멀티프로세서들은 머신 러닝 계산들에 적합한 것을 포함하는 정밀도들의 범위에서 계산 연산들을 수행할 수 있는 다수의 타입들의 정수 및 부동 소수점 로직 유닛들을 포함한다. 예를 들어, 프로세싱 클러스터들(706A-706H) 각각에서의 부동 소수점 유닛들의 적어도 서브세트는 16-비트 또는 32-비트 부동 소수점 연산들을 수행하도록 구성될 수 있고, 부동 소-28-수점 유닛들의 상이한 서브세트는 64-비트 부동 소수점 연산들을 수행하도록 구성될 수 있다. GPGPU의 다수의 인스턴스들은 계산 클러스터로서 동작하도록 구성될 수 있다. 동기화 및 데이터 교환을 위해 계산 클러스터에 의해 사용되는 통신 메커니즘은 실시예들에 걸쳐 달라진다. 예를 들어, GPGPU의 다 수의 인스턴스들은 호스트 인터페이스를 통해 통신한다. 일 실시예에서, GPGPU는 GPGPU를 GPGPU의 다른 인스턴스들로의 직접 접속을 가능하게 하는 GPU 링크와 결합하는 I/O 허브를 포함한다. GPU 링크는 GPGPU의 다수의 인스턴스들 사이의 통신 및 동기화를 가능하게 하는 전용 GPU-대-GPU 브 리지에 결합될 수 있다. 선택적으로, GPU 링크는 데이터를 다른 GPGPU들 또는 병렬 프로세서들에 송신 및 수신하기 위해 고속 인터커넥트와 결합한다. GPGPU의 다수의 인스턴스들은 별개의 데이터 프로세싱 시스 템들에 위치될 수 있고 호스트 인터페이스를 통해 액세스가능한 네트워크 디바이스를 통해 통신할 수 있다. GPU 링크는 호스트 인터페이스에 추가하여 또는 대안으로서 호스트 프로세서에 대한 접속을 가능하게 하도록 구성될 수 있다. GPGPU의 예시된 구성이 신경망들을 훈련시키도록 구성될 수 있지만, GPGPU의 대안적인 구성은 고성능 또는 저전력 추론 플랫폼 내의 배치를 위해 구성될 수 있다. 추론 구성에서, GPGPU는 훈련 구성에 대해 더 적은 프로세싱 클러스터들(706A-706H)을 포함한다. 추가적으로, 메모리(714A-714B)와 연관된 메모리 기술은 추론과 훈련 구성 사이에서 상이할 수 있다. 일 실시예에서, GPGPU의 추론 구성은 특정 명령어들의 추론 을 지원할 수 있다. 예를 들어, 추론 구성은 배치된 신경망들에 대한 추론 연산들 동안 일반적으로 사용되는 하나 이상의 8-비트 정수 내적 명령어에 대한 지원을 제공할 수 있다. 도 8은 멀티-GPU 컴퓨팅 시스템을 도시한다. 멀티-GPU 컴퓨팅 시스템은 호스트 인터페이스 스위치 를 통해 다수의 GPGPU들(806A-806D)에 결합된 프로세서를 포함할 수 있다. 호스트 인터페이스 스위 치는 프로세서를 PCI 익스프레스 버스에 결합하는 PCI 익스프레스 스위치 디바이스일 수 있으며, 이 를 통해 프로세서는 GPGPU들(806A-806D)의 세트와 통신할 수 있다. 다수의 GPGPU들(806A-806D) 각각은 도 7의 GPGPU의 인스턴스일 수 있다. GPGPU들(806A-806D)은 고속 점대점 GPU 대 GPU 링크들의 세트 를 통해 상호접속할 수 있다. 고속 GPU 대 GPU 링크들은 도 7에서와 같은 GPU 링크와 같은 전용 GPU 링크 를 통해 GPGPU들(806A-806D) 각각에 접속할 수 있다. P2P GPU 링크들은 프로세서가 접속되는 호스 트 인터페이스 버스를 통한 통신을 요구하지 않고 GPGPU들(806A-806D) 각각 사이의 직접 통신을 가능하게 한다. P2P GPU 링크들로 지향되는 GPU-대-GPU 트래픽으로 인해, 호스트 인터페이스 버스는 시스템 메모리 액세스를 위 해 또는 예를 들어 하나 이상의 네트워크 디바이스를 통한 멀티-GPU 컴퓨팅 시스템의 다른 인스턴스들과의 통신을 위해 이용가능한 상태로 유지된다. 도 8에서 GPGPU들(806A-806D)이 호스트 인터페이스 스위치를 통해 프로세서에 접속하지만, 프로세서는 대안적으로 P2P GPU 링크들에 대한 직접 지원을 포함 하고 GPGPU들(806A-806D)에 직접 접속할 수 있다. 일 실시예에서, P2P GPU 링크는 멀티-GPU 컴퓨팅 시스 템이 단일 논리 GPU로서 동작할 수 있게 한다. 머신 러닝 신경망 구현들 본 명세서에 설명된 컴퓨팅 아키텍처는 머신 러닝을 위해 신경망들을 훈련 및 배치하기에 특히 적합한 병렬 프 로세싱의 타입들을 수행하도록 구성될 수 있다. 신경망은 그래프 관계를 갖는 함수들의 망으로서 일반화될 수"}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "있다. 본 기술분야에 잘 알려진 바와 같이, 머신 러닝에 사용되는 다양한 타입들의 신경망 구현들이 있다. 전 술한 바와 같이, 하나의 예시적인 타입의 신경망이 피드포워드 네트워크이다. 제2 예시적인 타입의 신경망이 컨볼루션 신경망(Convolutional Neural Network, CNN)이다. CNN은 이미지 데이 터와 같은 알려진 그리드형 토폴로지를 갖는 데이터를 프로세싱하기 위한 특수화된 피드포워드 신경망이다. 따 라서, CNN들은 계산 비전 및 이미지 인식 애플리케이션들에 일반적으로 사용되지만, 그것들은 또한 음성 및 언 어 프로세싱과 같은 다른 타입들의 패턴 인식에도 사용될 수 있다. CNN 입력 층 내의 노드들은 \"필터들\"(망막 에서 발견되는 수용 필드(receptive field)들에 의해 유발되는(inspired) 특징 검출기들)의 세트로 조직화되고, 각각의 필터 세트의 출력은 네트워크의 연속적인 층들 내의 노드들로 전파된다. CNN에 대한 계산들은 각각의 필터에 컨볼루션 수학 연산을 적용하여 그 필터의 출력을 생성하는 것을 포함한다. 컨볼루션은 2개의 원래 함 수 중 하나의 함수의 수정된 버전인 제3 함수를 생성하기 위해 2개의 함수에 의해 수행되는 특수화된 종류의 수 학 연산이다. 컨볼루션 네트워크 용어에서, 컨볼루션에 대한 제1 함수는 입력으로 지칭될 수 있고, 제2 함수는 컨볼루션 커널로 지칭될 수 있다. 출력은 특징 맵(feature map)으로 지칭될 수 있다. 예를 들어, 컨볼루션 층 에 대한 입력은 입력 이미지의 다양한 컬러 컴포넌트들을 정의하는 데이터의 다차원 어레이일 수 있다. 컨볼루 션 커널은 파라미터들의 다차원 어레이일 수 있으며, 여기서 파라미터들은 신경망에 대한 훈련 프로세스에 의해-29-적응된다. 순환 신경망(RNN)들은 층들 사이의 피드백 접속들을 포함하는 피드포워드 신경망들의 계열이다. RNN들은 신경 망의 상이한 부분들에 걸쳐 파라미터 데이터를 공유함으로써 순차 데이터의 모델링을 가능하게 한다. RNN에 대 한 아키텍처는 사이클들을 포함한다. RNN으로부터의 출력 데이터의 적어도 일부가 시퀀스로 후속 입력을 프로 세싱하기 위한 피드백으로서 사용되기 때문에, 사이클들은 미래 시간에 그 자신의 값에 대한 변수의 현재 값의 영향을 나타낸다. 이 특징은 언어 데이터가 구성될 수 있는 가변적인 성질로 인해 RNN들을 언어 프로세싱에 특 히 유용하게 만든다. 아래에 설명되는 도면들은 예시적인 피드포워드, CNN 및 RNN 네트워크들을 제시할 뿐만 아니라, 그러한 타입들 의 네트워크들 각각을 각각 훈련 및 배치하기 위한 일반적인 프로세스를 설명한다. 이러한 설명들은 본 명세서 에 설명된 임의의 특정 실시예에 대해 예시적이고 비제한적이며, 예시된 개념들은 일반적으로 딥 신경망들 및 머신 러닝 기법들에 일반적으로 적용될 수 있다는 것이 이해될 것이다. 전술한 예시적인 신경망은 딥 러닝을 수행하는데 사용될 수 있다. 딥 러닝은 딥 신경망들을 사용하는 머신 러 닝이다. 딥 러닝에 사용되는 딥 신경망들은, 단일 은닉 층만을 포함하는 얕은 신경망(shallow neural networ k)들과는 대조적으로, 다수의 은닉 층들로 구성되는 인공 신경망들이다. 딥 신경망들은 일반적으로 훈련하기에 더 계산 집약적이다. 그러나, 네트워크의 추가적인 은닉 층들은 얕은 머신 러닝 기법들에 비해 감소된 출력 에 러를 초래하는 멀티스텝 패턴 인식을 가능하게 한다. 전형적으로, 딥 러닝에서 사용되는 딥 신경망들은 모델에 제공되는 특징 표현(feature representation)에 기초 하여 연산들(예를 들어, 객체 분류, 음성 인식 등)을 수행할 수 있는 수학적 모델을 나타내는 백-엔드 네트워크 에 결합된 특징 인식(feature recognition)을 수행하는 프론트-엔드 네트워크를 포함한다. 딥 러닝은 모델에 대해 수작업 특징 엔지니어링(hand crafted feature engineering)이 수행될 필요 없이 머신 러닝이 수행될 수 있게 한다. 대신에, 딥 신경망들은 입력 데이터 내의 통계적 구조 또는 상관에 기초하여 특징들을 학습할 수 있다. 학습된 특징들은 검출된 특징들을 출력에 매핑할 수 있는 수학적 모델에 제공될 수 있다. 네트워크에 의해 사용되는 수학적 모델은 일반적으로 수행될 특정 태스크에 대해 특수화되고, 상이한 모델들이 상이한 태스 크를 수행하기 위해 사용될 것이다. 일단 신경망이 구조화되면, 러닝 모델을 네트워크에 적용하여 특정 태스크들을 수행하도록 네트워크를 훈련시킬 수 있다. 러닝 모델은 네트워크의 출력 에러를 감소시키기 위해 모델 내의 가중치를 조정하는 방법을 설명한다. 에러들의 역전파(backpropagation)는 신경망들을 훈련하는 데 사용되는 일반적인 방법이다. 프로세 싱을 위해 입력 벡터가 네트워크에 제시된다. 네트워크의 출력은 손실 함수를 사용하여 원하는 출력과 비교되 고, 출력 층에서의 뉴런들 각각에 대해 에러 값이 계산된다. 그 다음, 에러 값들은 각각의 뉴런이 원래 출력에 대한 그의 기여를 개략적으로 나타내는 연관된 에러 값을 가질 때까지 역방향으로 전파된다. 그 다음, 네트워 크는 확률적 경사 하강 알고리즘(stochastic gradient descent algorithm)과 같은 알고리즘을 사용하여 그러한 에러들로부터 학습하여 신경망의 가중치들을 업데이트할 수 있다. 도 9a 및 도 9b는 예시적인 컨볼루션 신경망을 도시한다. 도 9a는 CNN 내의 다양한 층들을 도시한다. 도 9a에 도시된 바와 같이, 이미지 프로세싱을 모델링하기 위해 사용되는 예시적인 CNN은 입력 이미지의 적색, 녹색, 및 청색(RGB) 성분을 기술하는 입력을 수신할 수 있다. 입력은 다수의 컨볼루션 층들(예를 들어, 컨볼 루션 층, 컨볼루션 층)에 의해 프로세싱될 수 있다. 다수의 컨볼루션 층들로부터의 출력은 선택적으 로 완전 접속된 층들의 세트에 의해 프로세싱될 수 있다. 완전 접속된 층에서의 뉴런들은 피드포워드 네 트워크에 대해 이전에 설명된 바와 같이, 이전 층에서의 모든 활성화들에 대한 완전한 접속들을 갖는다. 완전 접속된 층들로부터의 출력은 네트워크로부터 출력 결과를 생성하는 데 사용될 수 있다. 완전 접속된 층들 내의 활성화들은 컨볼루션 대신에 행렬 곱셈을 사용하여 계산될 수 있다. 모든 CNN 구현들이 완전 접속 된 층들을 사용하는 것은 아니다. 예를 들어, 일부 구현들에서 컨볼루션 층은 CNN에 대한 출력을 생 성할 수 있다. 컨볼루션 층들은 희소하게 접속되며, 이는 완전 접속된 층들에서 발견되는 전통적인 신경망 구성과는 상이 하다. 전통적인 신경망 층들은 모든 출력 유닛이 모든 입력 유닛과 상호작용하도록 완전 접속된다. 그러나, 도시된 바와 같이, 필드의 컨볼루션의 출력이 (필드 내의 노드들 각각의 각자의 상태 값 대신에) 후속 층의 노 드들에 입력되기 때문에 컨볼루션 층들은 희소하게 접속된다. 컨볼루션 층들과 연관된 커널들은 컨볼루션 연산 들을 수행하고, 그의 출력은 다음 층으로 전송된다. 컨볼루션 층들 내에서 수행되는 차원수 감소 (dimensionality reduction)는 CNN이 큰 이미지들을 프로세싱하도록 스케일링될 수 있게 하는 하나의 양태이다.-30-도 9b는 CNN의 컨볼루션 층 내의 예시적인 계산 스테이지들을 도시한다. CNN의 컨볼루션 층에의 입력은 컨볼루션 층의 3개의 스테이지에서 프로세싱될 수 있다. 3개의 스테이지는 컨볼루션 스테이지, 검출 기 스테이지, 및 풀링 스테이지를 포함할 수 있다. 이어서, 컨볼루션 층은 연속적인 컨볼루션 층에 데이터를 출력할 수 있다. 네트워크의 최종 컨볼루션 층은 출력 특징 맵 데이터를 생성하거나 또는 완전 접속된 층에 입력을 제공하여, 예를 들어, CNN에의 입력을 위한 분류 값을 생성할 수 있다. 컨볼루션 스테이지에서 수개의 컨볼루션들을 병렬로 수행하여 선형 활성화들의 세트를 생성한다. 컨볼루 션 스테이지는 선형 변환 + 변환(linear transformation plus a translation)으로서 특정될 수 있는 임의 의 변환인 아핀 변환(affine transformation)을 포함할 수 있다. 아핀 변환들은 회전들, 변환들, 스케일링, 및 이러한 변환들의 조합들을 포함한다. 컨볼루션 스테이지는 뉴런과 연관된 로컬 영역으로서 결정될 수 있는 입 력에서의 특정 영역들에 접속되는 함수들(예를 들어, 뉴런들)의 출력을 계산한다. 뉴런들은 뉴런들이 접속되는 로컬 입력에서의 영역과 뉴런들의 가중치들 사이의 내적을 계산한다. 컨볼루션 스테이지로부터의 출력은 컨볼루션 층의 연속적인 스테이지들에 의해 프로세싱되는 선형 활성화들의 세트를 정의한다. 선형 활성화들은 검출기 스테이지에 의해 프로세싱될 수 있다. 검출기 스테이지에서, 각각의 선형 활성화는 비-선형 활성화 함수에 의해 프로세싱된다. 비-선형 활성화 함수는 컨볼루션 층의 수용 필드들에 영 향을 미치지 않고 전체 네트워크의 비선형 속성들을 증가시킨다. 몇몇 타입의 비선형 활성화 함수들이 사용될 수 있다. 하나의 특정 타입은, 활성화가 제로에서 임계화되도록, 로서 정의되는 활성화 함수를 사용하는, 정류 선형 유닛(rectified linear unit, ReLU)이다."}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "풀링 스테이지는 컨볼루션 층의 출력을 인근 출력들의 요약 통계로 대체하는 풀링 함수를 사용한다. 풀링 함수는, 입력에 대한 작은 변환들이 풀링된 출력들을 변경하지 않도록, 변환 불변성(translation invariance)을 신경망 내로 도입하기 위해 사용될 수 있다. 로컬 변환에 대한 불변성은 입력 데이터에서의 특 징의 존재가 특징의 정확한 위치보다 더 중요한 시나리오들에서 유용할 수 있다. 최대 풀링, 평균 풀링, 및 l2-norm 풀링을 포함하는 다양한 타입들의 풀링 함수들이 풀링 스테이지 동안 사용될 수 있다. 추가적으 로, 일부 CNN 구현들은 풀링 스테이지를 포함하지 않는다. 대신에, 이러한 구현들은 이전의 컨볼루션 스테이지 들에 비해 증가된 스트라이드(stride)를 갖는 추가적인 컨볼루션 스테이지를 대체한다. 이어서, 컨볼루션 층으로부터의 출력은 다음 층에 의해 프로세싱될 수 있다. 다음 층은 추가적 인 컨볼루션 층 또는 완전 접속된 층들 중 하나일 수 있다. 예를 들어, 도 9a의 제1 컨볼루션 층은 제2 컨볼루션 층에 출력할 수 있고, 제2 컨볼루션 층은 완전 접속된 층들의 제1 층에 출력할 수 있다. 도 10은 예시적인 순환 신경망을 도시한다. 순환 신경망(RNN)에서, 네트워크의 이전 상태는 네트워크의 현재 상태의 출력에 영향을 준다. RNN들은 다양한 함수들을 사용하여 다양한 방식들로 구축될 수 있다. RNN들 의 사용은 일반적으로 이전 입력 시퀀스에 기초하여 미래를 예측하기 위해 수학적 모델들을 사용하는 것을 중심 으로 한다. 예를 들어, RNN은 이전의 단어 시퀀스가 주어지면 다가오는 단어를 예측하기 위해 통계적 언어 모 델링을 수행하는 데 사용될 수 있다. 예시된 RNN은 입력 벡터를 수신하는 입력 층, 순환 함수 (recurrent function)를 구현하는 은닉 층들, 이전 상태들의 '메모리'를 인에이블하는 피드백 메커니즘 , 및 결과를 출력하는 출력 층을 갖는 것으로 설명될 수 있다. RNN은 시간-단계들에 기초하 여 동작한다. 주어진 시간 단계에서의 RNN의 상태는 피드백 메커니즘을 통한 이전 시간 단계에 기초하여 영향을 받는다. 주어진 시간 단계에 대해, 은닉 층들의 상태는 현재 시간 단계에서의 입력과 이전 상태 에 의해 정의된다. 제1 시간 단계에서의 초기 입력(x1)은 은닉 층에 의해 프로세싱될 수 있다. 제2 입 력(x2)은 초기 입력(x1)의 프로세싱 동안 결정되는 상태 정보를 사용하여 은닉 층에 의해 프로세싱될 수 있다. 주어진 상태는 로서 계산될 수 있고, 여기서 U 및 W는 파라미터 행렬들이다. 함수 f는 일반적으로 쌍곡 탄젠트 함수(hyperbolic tangent function)(Tanh) 또는 정류기 함수 의 변형과 같은 비선형성이다. 그러나, 은닉 층들에서 사용되는 특정 수학 함수는 RNN의 특정 구현 세부사항들에 따라 변할 수 있다. 설명된 기본 CNN 및 RNN 네트워크들에 부가하여, 그 네트워크들에서의 변형들에 대한 가속이 가능하게 될 수 있 다. 하나의 예시적인 RNN 변형은 장단기 메모리(long short term memory, LSTM) RNN이다. LSTM RNN은 더 긴 언어 시퀀스들을 프로세싱하는데 필요할 수 있는 장기 종속성들을 학습할 수 있다. CNN에 대한 변형은 CNN과-31-유사한 구조를 갖고 딥 신뢰망(deep belief network)과 유사한 방식으로 훈련되는 컨볼루션 딥 신뢰망 (convolutional deep belief network)이다. 딥 신뢰망(deep belief network, DBN)은 확률(랜덤) 변수들의 다 수의 층들로 구성되는 생성 신경망(generative neural network)이다. DBN들은 탐욕 비지도 학습(greedy unsupervised learning)을 사용하여 층별로 훈련될 수 있다. 그 다음, DBN의 학습된 가중치들은 신경망에 대한 최적의 초기 가중치 세트를 결정함으로써 사전-훈련 신경망들(pre-train neural networks)을 제공하는 데 사용 될 수 있다. 추가 실시예들에서, 강화 학습(reinforcement learning)을 위한 가속이 가능하게 된다. 강화 학 습에서, 인공 에이전트는 그 환경과 상호작용함으로써 학습한다. 에이전트는 누적 보상들(cumulative reward s)을 최대화하기 위해 특정 목적들을 최적화하도록 구성된다. 도 11은 딥 신경망의 훈련 및 배치를 도시한다. 일단 주어진 네트워크가 태스크에 대해 구조화되었다면, 신경 망은 훈련 데이터세트를 사용하여 훈련된다. 훈련 프로세스의 하드웨어 가속을 가능하게 하기 위해 다양 한 훈련 프레임워크들이 개발되었다. 예를 들어, 도 6의 머신 러닝 프레임워크는 훈련 프레임워크 로서 구성될 수 있다. 훈련 프레임워크는 훈련되지 않은 신경망으로 후크(hook)할 수 있고 훈 련되지 않은 신경망이 훈련된 신경망을 생성하기 위해 본 명세서에 설명된 병렬 프로세싱 자원들을 사용 하여 훈련될 수 있게 한다. 훈련 프로세스를 시작하기 위해, 초기 가중치들은 랜덤하게 또는 딥 신뢰망을 사용하여 사전-훈련에 의해 선택 될 수 있다. 그 후 훈련 사이클은 지도 또는 비지도 방식으로 수행된다. 지도 학습은, 훈련 데이터세트가 입력에 대한 원하는 출력과 쌍을 이루는 입력을 포함하는 경우, 또는 훈 련 데이터세트가 알려진 출력을 갖는 입력을 포함하고 신경망의 출력이 수동으로 등급화(grade)되는 경우와 같 이, 중재 연산으로서 훈련이 수행되는 학습 방법이다. 네트워크는 입력들을 프로세싱하고 결과적인 출력들을 예상되거나 원하는 출력들의 세트와 비교한다. 이어서, 에러들이 시스템을 통해 역전파된다. 훈련 프레임워크 는 훈련되지 않은 신경망을 제어하는 가중치들을 조정하도록 조정할 수 있다. 훈련 프레임워크 는 훈련되지 않은 신경망이 알려진 입력 데이터에 기초하여 올바른 답변을 생성하는 데 적합한 모 델로 얼마나 잘 수렴하는지를 모니터링하는 도구들을 제공할 수 있다. 훈련 프로세스는 신경망에 의해 생성된 출력을 정제하기 위해 네트워크의 가중치들이 조정됨에 따라 반복적으로 발생한다. 훈련 프로세스는 신경망이 훈련된 신경망과 연관된 통계적으로 원하는 정확도에 도달할 때까지 계속될 수 있다. 훈련된 신경망 은 이후 새로운 데이터의 입력에 기초하여 추론 결과를 생성하기 위해 임의의 수의 머신 러 닝 연산들을 구현하도록 배치될 수 있다. 비지도 학습은 네트워크가 라벨링되지 않은 데이터를 사용하여 자신을 훈련하려고 시도하는 학습 방법이다. 따 라서, 비지도 학습의 경우 훈련 데이터세트는 임의의 연관된 출력 데이터 없이 입력 데이터를 포함할 것 이다. 훈련되지 않은 신경망은 라벨링되지 않은 입력 내의 그룹화들을 학습할 수 있고, 개별 입력들이 전체 데이터세트에 어떻게 관련되는지를 결정할 수 있다. 비지도 훈련은 데이터의 차원수를 감소시키는데 유용 한 연산들을 수행할 수 있는 훈련된 신경망의 타입인 자기-조직화 맵(self-organizing map)을 생성하는데 사용될 수 있다. 비지도 훈련은 또한 데이터의 정상 패턴들로부터 벗어나는 입력 데이터세트 내의 데이터 포인 트들의 식별을 허용하는 비정상 검출(anomaly detection)을 수행하기 위해 사용될 수 있다. 지도 및 비지도 훈련에 대한 변형들이 또한 이용될 수 있다. 반-지도 학습(semi-supervised learning)은 훈련 데이터세트에서 동일한 분포의 라벨링된 데이터와 라벨링되지 않은 데이터의 혼합을 포함하는 기법이다. 증분 학습(incremental learning)은 모델을 더 훈련시키기 위해 입력 데이터가 연속적으로 사용되는 지도 학습 의 변형이다. 증분 학습은 훈련된 신경망이 초기 훈련 동안에 네트워크 내에 주입된 지식을 잊지 않고 새로운 데이터에 적응할 수 있게 한다. 지도이든 비지도이든 간에, 특히 딥 신경망들에 대한 훈련 프로세스는 단일 계산 노드에 대해 너무 계산 집약적 일 수 있다. 단일 계산 노드를 사용하는 대신에, 계산 노드들의 분산 네트워크를 사용하여 훈련 프로세스를 가 속할 수 있다. 도 12a는 분산 학습을 도시하는 블록도이다. 분산 학습은 신경망의 지도 또는 비지도 훈련을 수행하기 위해 다 수의 분산 컴퓨팅 노드들을 사용하는 훈련 모델이다. 분산 계산 노드들은 도 7에서와 같은 고도 병렬 범용 그 래픽 프로세싱 유닛(highly parallel general-purpose graphics processing unit)과 같은 하나 이상의 범 용 프로세싱 노드와 하나 이상의 호스트 프로세서를 각각 포함할 수 있다. 도시된 바와 같이, 분산 학습은 모 델 병렬성, 데이터 병렬성, 또는 모델 병렬성과 데이터 병렬성의 조합으로 수행될 수 있다.-32-모델 병렬성에서, 분산 시스템 내의 상이한 계산 노드들은 단일 네트워크의 상이한 부분들에 대한 훈련 계산들을 수행할 수 있다. 예를 들어, 신경망의 각각의 층은 분산 시스템의 상이한 프로세싱 노드에 의해 훈련 될 수 있다. 모델 병렬성의 이점들은 특히 큰 모델들로 스케일링하는 능력을 포함한다. 신경망의 상이한 층들 과 연관된 계산들을 분할(splitting)하는 것은 모든 층들의 가중치들이 단일 계산 노드의 메모리에 맞지 않는 매우 큰 신경망들의 훈련을 가능하게 한다. 일부 경우들에서, 모델 병렬성은 큰 신경망들의 비지도 훈련을 수 행하는데 특히 유용할 수 있다. 데이터 병렬성에서, 분산 네트워크의 상이한 노드들은 모델의 완전한 인스턴스를 가지며, 각각의 노드는 데이터의 상이한 부분을 수신한다. 그 다음, 상이한 노드들로부터의 결과들이 조합된다. 데이터 병렬성에 대 한 상이한 접근법들이 가능하지만, 데이터 병렬 훈련 접근법들 모두는 결과들을 조합하고 각각의 노드 사이의 모델 파라미터들을 동기화하는 기법을 요구한다. 데이터를 조합하는 예시적인 접근법들은 파라미터 평균화 및 업데이트 기반 데이터 병렬성을 포함한다. 파라미터 평균화는 훈련 데이터의 서브세트 상에서 각각의 노드를 훈련하고 전역적 파라미터들(예를 들어, 가중치들, 바이어스들)을 각각의 노드로부터의 파라미터들의 평균으로 설정한다. 파라미터 평균화는 파라미터 데이터를 유지하는 중앙 파라미터 서버를 사용한다. 업데이트 기반 데 이터 병렬성은, 노드들로부터 파라미터 서버로 파라미터들을 전송하는 대신에, 모델에 대한 업데이트들이 전송 된다는 것을 제외하고는 파라미터 평균화와 유사하다. 추가적으로, 업데이트 기반 데이터 병렬성은 비집중형 방식으로 수행될 수 있고, 여기서 업데이트들은 압축되 어 노드들 사이에 전송된다. 조합된 모델 및 데이터 병렬성은, 예를 들어, 각각의 계산 노드가 다수의 GPU들을 포함하는 분산 시스템 에서 구현될 수 있다. 각각의 노드는 모델의 상이한 부분들을 훈련하는 데 사용되는 각각의 노드 내의 별개의 GPU들을 갖는 모델의 완전한 인스턴스를 가질 수 있다. 분산 훈련은 단일 머신 상에서의 훈련에 비해 증가된 오버헤드를 갖는다. 그러나, 본 명세서에서 설명되는 병 렬 프로세서들 및 GPGPU들은 고대역폭 GPU-대-GPU 데이터 전송 및 가속된 원격 데이터 동기화를 가능하게 하는 기법들을 포함한, 분산 훈련의 오버헤드를 감소시키는 다양한 기법들을 각각 구현할 수 있다. 도 12b는 프로그램가능 네트워크 인터페이스 및 데이터 프로세싱 유닛을 도시하는 블록도이다. 프로그램 가능 네트워크 인터페이스는 분산 환경 내에서 네트워크-기반 계산 태스크들을 가속하는 데 사용될 수 있 는 프로그램가능 네트워크 엔진이다. 프로그램가능 네트워크 인터페이스는 호스트 인터페이스를 통해 호스트 시스템과 결합할 수 있다. 프로그램가능 네트워크 인터페이스는 호스트 시스템의 CPU들 또 는 GPU들에 대한 네트워크 또는 스토리지 연산들을 가속하는데 사용될 수 있다. 호스트 시스템은, 예를 들어, 도 12a에 도시된 바와 같이, 예를 들어, 분산 훈련을 수행하는데 사용되는 분산 학습 시스템의 노드일 수 있다. 호스트 시스템은 또한 데이터 센터 내의 데이터 센터 노드일 수 있다. 일 실시예에서, 모델 데이터를 포함하는 원격 스토리지에의 액세스는 프로그램가능 네트워크 인터페이스 에 의해 가속될 수 있다. 예를 들어, 프로그램가능 네트워크 인터페이스는 원격 스토리지 디바이스들을 로컬 스토리지 디바이스들로서 호스트 시스템에 제시하도록 구성될 수 있다. 프로그램가능 네트워크 인터페이 스는 또한 원격 시스템들의 GPU들과 호스트 시스템의 GPU들 사이에서 수행되는 원격 직접 메모리 액세스 (remote direct memory access, RDMA) 연산들을 가속할 수 있다. 일 실시예에서, 프로그램가능 네트워크 인터 페이스는 NVME-oF와 같은, 그러나 이에 제한되지 않는, 스토리지 기능을 가능하게 할 수 있다. 프로그램 가능 네트워크 인터페이스는 또한 호스트 시스템을 대신하여 원격 스토리지를 위한 암호화, 데이터 무결 성, 압축, 및 다른 연산들을 가속하여, 원격 스토리지가 호스트 시스템에 직접 부착되는 스토리지 디바이스들의 레이턴시들에 접근할 수 있게 한다. 프로그램가능 네트워크 인터페이스는 또한 호스트 시스템을 대신하여 자원 할당 및 관리도 수행할 수 있 다. 스토리지 보안 연산들은 프로그램가능 네트워크 인터페이스로 오프로드되고, 원격 스토리지 자원들 의 할당 및 관리와 협력하여 수행될 수 있다. 그렇지 않으면 호스트 시스템의 프로세서에 의해 수행될 원격 스 토리지에 대한 액세스를 관리하기 위한 네트워크-기반 연산들은 그 대신에 프로그램가능 네트워크 인터페이스 에 의해 수행될 수 있다. 일 실시예에서, 네트워크 및/또는 데이터 보안 연산들은 호스트 시스템으로부터 프로그램가능 네트워크 인터페 이스로 오프로드될 수 있다. 데이터 센터 노드에 대한 데이터 센터 보안 정책은 호스트 시스템의 프로세 서들 대신에 프로그램가능 네트워크 인터페이스에 의해 핸들링될 수 있다. 예를 들어, 프로그램가능 네-33-트워크 인터페이스는 호스트 시스템 상의 시도된 네트워크-기반 공격(예를 들어, DDoS)을 검출하고 완화 하여, 공격이 호스트 시스템의 이용가능성을 손상시키는 것을 방지할 수 있다. 프로그램가능 네트워크 인터페이스는 다수의 프로세서 코어를 통해 운영 체제를 실행하는 SoC(system on a chip)를 포함할 수 있다. 프로세서 코어들은 범용 프로세서(예를 들어, CPU) 코 어들을 포함할 수 있다. 일 실시예에서, 프로세서 코어들은 또한 하나 이상의 GPU 코어를 포함할 수 있 다. SoC는 메모리 디바이스에 저장된 명령어들을 실행할 수 있다. 스토리지 디바이스는 로 컬 운영 체제 데이터를 저장할 수 있다. 스토리지 디바이스 및 메모리 디바이스는 또한 호스트 시 스템에 대한 원격 데이터를 캐싱하는 데 사용될 수 있다. 네트워크 포트들(1260A-1260B)은 네트워크 또는 패브 릭에 대한 접속을 가능하게 하고 SoC에 대한 네트워크 액세스를 용이하게 하고 호스트 인터페이스 를 통해 호스트 시스템에 대한 네트워크 액세스를 용이하게 한다. 프로그램가능 네트워크 인터페이스는 또한 USB 인터페이스와 같은 I/O 인터페이스를 포함할 수 있다. I/O 인터페이스는 디버그 인터페 이스로서 또는 프로그램가능 네트워크 인터페이스에 외부 디바이스들을 결합하기 위해 사용될 수 있다. 프로그램가능 네트워크 인터페이스는 또한 호스트 디바이스 상의 소프트웨어가 프로그램가능 네트워크 인 터페이스 및/또는 SoC를 관리하고 구성할 수 있게 하는 관리 인터페이스를 포함한다. 일 실 시예에서, 프로그램가능 네트워크 인터페이스는 또한 SoC, 호스트 시스템, 또는 네트워크 포트들 (1260A-1260B)을 통해 결합된 원격 시스템들로부터의 병렬 계산 태스크들의 오프로드를 수용하기 위한 하나 이 상의 가속기 또는 GPU를 포함할 수 있다. 예시적인 머신 러닝 애플리케이션들 머신 러닝은 컴퓨터 비전, 자율 주행 및 내비게이션, 음성 인식, 및 언어 프로세싱을 포함하지만 이에 제한되지 않는 다양한 기술적 문제들을 해결하기 위해 적용될 수 있다. 컴퓨터 비전은 전통적으로 머신 러닝 애플리케이 션들에 대한 가장 활발한 연구 영역들 중 하나였다. 컴퓨터 비전의 애플리케이션들의 범위는 얼굴 인식과 같은 인간 시각 능력 재현으로부터 새로운 카테고리들의 시각 능력 생성에 이른다. 예를 들어, 컴퓨터 비전 애플리 케이션들은 비디오에서 보이는 객체들에서 유도된 진동들로부터의 음파를 인식하도록 구성될 수 있다. 병렬 프 로세서 가속화된 머신 러닝은 컴퓨터 비전 애플리케이션들이 이전에 실현가능한 것보다 상당히 더 큰 훈련 데이 터세트를 사용하여 훈련될 수 있게 하고, 추론 시스템들이 저전력 병렬 프로세서들을 사용하여 배치될 수 있게 한다. 병렬 프로세서 가속화된 머신 러닝은 차선 및 도로 표지판 인식, 장애물 회피, 내비게이션, 및 주행 제어를 포 함하는 자율 주행 애플리케이션들을 갖는다. 특정 훈련 입력에 대한 적절한 응답들을 정의하는 데이터세트들에 기초하여 구동 모델들을 훈련하기 위해 가속화된 머신 러닝 기법들이 사용될 수 있다. 본 명세서에 설명된 병 렬 프로세서들은 자율 주행 솔루션들에 사용되는 점점 더 복잡한 신경망들의 신속한 훈련을 가능하게 할 수 있 고, 자율 차량들에 통합하기에 적합한 모바일 플랫폼에서의 저전력 추론 프로세서들의 배치를 가능하게 한다. 병렬 프로세서 가속화된 딥 신경망들은 자동 음성 인식(ASR)에 대한 머신 러닝 접근법들을 가능하게 하였다. ASR은 입력 음향 시퀀스가 주어지면 최고 확률 언어 시퀀스(most probable linguistic sequence)를 계산하는 함수의 생성을 포함한다. 딥 신경망을 사용하는 가속화된 머신 러닝은 ASR에 대해 이전에 사용된 HMM(hidden Markov model)들과 GMM(Gaussian mixture model)들의 대체를 가능하게 하였다. 병렬 프로세서 가속화된 머신 러닝은 자연어 프로세싱을 가속하는 데 또한 사용될 수 있다. 자동 학습 절차들 은 통계적 추론 알고리즘들을 사용하여 잘못된 또는 친숙하지 않은 입력에 강건한 모델들을 생성할 수 있다. 예시적인 자연어 프로세서 애플리케이션들은 인간 언어들 사이의 자동 기계 번역을 포함한다. 머신 러닝에 사용되는 병렬 프로세싱 플랫폼들은 훈련 플랫폼들 및 배치 플랫폼들로 분할될 수 있다. 훈련 플 랫폼들은 일반적으로 매우 병렬적이며 멀티-GPU 단일 노드 훈련 및 멀티-노드, 멀티-GPU 훈련을 가속하기 위한 최적화들을 포함한다. 훈련에 적합한 예시적인 병렬 프로세서들은 도 7의 범용 그래픽 프로세싱 유닛 및 도 8의 멀티-GPU 컴퓨팅 시스템을 포함한다. 반대로, 배치된 머신 러닝 플랫폼들은 일반적으로 카메라들, 자율 로봇들, 및 자율 차량들과 같은 제품들에서 사용하기에 적합한 더 낮은 전력 병렬 프로세서들을 포함한다. 추가적으로, 그래픽 프로세싱 활동들을 가속 또는 향상시키기 위해 머신 러닝 기법들이 적용될 수 있다. 예를 들어, 머신 러닝 모델은 GPU 가속화된 애플리케이션에 의해 생성된 출력을 인식하고 그 출력의 업스케일링된 버 전을 생성하도록 훈련될 수 있다. 이러한 기법들은 게이밍 애플리케이션에 대한 고해상도 이미지들의 생성을 가속화하기 위해 적용될 수 있다. 다양한 다른 그래픽 파이프라인 활동들은 머신 러닝의 사용으로부터 이익을-34-얻을 수 있다. 예를 들어, 머신 러닝 모델들은 지오메트릭 모델들의 복잡성을 증가시키기 위해 지오메트리 데 이터에 대한 테셀레이션 연산들을 수행하도록 훈련될 수 있어, 미세-세부사항의 지오메트리(fine-detailed geometry)가 상대적으로 더 낮은 세부사항의 지오메트리로부터 자동으로 생성될 수 있게 한다. 도 13은 훈련된 모델을 사용하여 추론을 수행하기에 적합한 예시적인 추론 시스템 온 칩(SOC)을 도시한다. SOC는 미디어 프로세서, 비전 프로세서, GPGPU 및 멀티-코어 프로세서 를 포함하는 프로세싱 컴포넌트들을 통합할 수 있다. GPGPU는 GPGPU와 같은 본 명세서에 설 명된 GPGPU일 수 있고, 멀티-코어 프로세서는 멀티-코어 프로세서들(405-406)과 같은 본 명세서에 설명된 멀티-코어 프로세서일 수 있다. SOC는 프로세싱 컴포넌트들 각각에 의해 액세스가능한 공유 온-칩 데이 터 풀(shared on-chip data pool)을 가능하게 할 수 있는 온-칩 메모리를 추가적으로 포함할 수 있다. 프로세싱 컴포넌트들은 자율 차량들 및 자율 로봇들을 포함하는 다양한 머신 러닝 플랫폼들로의 배치를 가능하 게 하도록 저전력 동작에 대해 최적화될 수 있다. 예를 들어, SOC의 일 구현은 자율 차량에 대한 메인 제어 시스템의 일부로서 사용될 수 있다. SOC가 자율 차량들에서의 사용을 위해 구성되는 경우, SOC는 배치 관할권의 관련 기능 안전 표준들을 준수하도록 설계되고 구성된다. 동작 동안, 미디어 프로세서 및 비전 프로세서는 컴퓨터 비전 연산들을 가속하기 위해 협력하여 작 업할 수 있다. 미디어 프로세서는 다수의 고해상도(예를 들어, 4K, 8K) 비디오 스트림들의 낮은 레이턴 시 디코딩을 가능하게 할 수 있다. 디코딩된 비디오 스트림들은 온-칩 메모리 내의 버퍼에 기입될 수 있 다. 이어서, 비전 프로세서는, 훈련된 이미지 인식 모델을 사용하여 프레임들을 프로세싱하는 것의 준비 로 디코딩된 비디오를 파싱하고 디코딩된 비디오의 프레임들에 대해 예비 프로세싱 연산들을 수행할 수 있다. 예를 들어, 백 엔드 모델 계산들이 GPGPU에 의해 수행되는 동안, 비전 프로세서는 고해상도 비디오 데이터에 대한 이미지 인식을 수행하는데 사용되는 CNN에 대한 컨볼루션 연산들을 가속할 수 있다. 멀티-코어 프로세서는 미디어 프로세서 및 비전 프로세서에 의해 수행되는 데이터 전송들 및 공유 메모리 연산들의 시퀀싱 및 동기화를 돕기 위한 제어 로직을 포함할 수 있다. 멀티-코어 프로세서 는 또한 GPGPU의 추론 계산 능력을 이용할 수 있는 소프트웨어 애플리케이션들을 실행하기 위한 애플리케 이션 프로세서로서 기능할 수 있다. 예를 들어, 내비게이션 및 구동 로직의 적어도 일부는 멀티-코어 프로세서 상에서 실행되는 소프트웨어로 구현될 수 있다. 이러한 소프트웨어는 GPGPU에 계산 작업부하들을 직접 발행할 수 있거나 또는 계산 작업부하들은 그러한 연산들의 적어도 일부를 GPGPU에 오프로드할 수 있는 멀티-코어 프로세서에 발행될 수 있다. GPGPU는 범용 그래픽 프로세싱 유닛 내의 프로세싱 클러스터들(706A-706H)의 저전력 구성과 같은 계 산 클러스터들을 포함할 수 있다. GPGPU 내의 계산 클러스터들은 훈련된 신경망 상에서 추론 계산들을 수행하도록 특별히 최적화된 명령어를 지원할 수 있다. 예를 들어, GPGPU는 8-비트 및 4-비트 정수 벡터 연산들과 같은 저 정밀도 계산들을 수행하기 위한 명령어들을 지원할 수 있다. 추가적인 시스템 개요 도 14는 프로세싱 시스템의 블록도이다. 본 명세서의 임의의 다른 도면의 요소들과 동일하거나 유사한 명칭들을 갖는 도 14의 요소들은 다른 도면들에서와 동일한 요소들을 설명하고, 그와 유사한 방식으로 동작하거 나 기능할 수 있고, 동일한 컴포넌트들을 포함할 수 있고, 본 명세서의 다른 곳에서 설명된 것들과 같이 다른 엔티티들에 링크될 수 있지만, 이에 한정되지 않는다. 시스템은 단일 프로세서 데스크톱 시스템, 멀티프 로세서 워크스테이션 시스템, 또는 다수의 프로세서 또는 프로세서 코어를 갖는 서버 시스템에서 사용될 수 있다. 시스템은 로컬 영역 또는 광역 네트워크로의 유선 또는 무선 접속성을 갖는 사물 인터 넷(IoT) 디바이스들 내에서와 같은 모바일, 핸드헬드, 또는 내장형 디바이스들에서 사용하기 위한 시스템 온 칩 (SoC) 집적 회로 내에 통합된 프로세싱 플랫폼일 수 있다. 시스템은 도 1의 컴포넌트들에 대응하는 컴포넌트들을 갖는 프로세싱 시스템일 수 있다. 예를 들어, 상 이한 구성들에서, 프로세서(들) 또는 프로세서 코어(들)는 도 1의 프로세서(들)에 대응할 수 있다. 그래픽 프로세서(들)는 도 1의 병렬 프로세서(들)에 대응할 수 있다. 외부 그래픽 프로세서 는 도 1의 애드-인 디바이스(들) 중 하나일 수 있다. 시스템은 서버 기반 게이밍 플랫폼; 게임 및 미디어 콘솔을 포함하는 게임 콘솔; 모바일 게이밍 콘솔, 핸 드헬드 게임 콘솔, 또는 온라인 게임 콘솔을 포함하거나, 그와 결합되거나, 그 내부에 통합될 수 있다. 시스템 은 모바일 폰, 스마트 폰, 태블릿 컴퓨팅 디바이스 또는 낮은 내부 저장 용량을 갖는 랩톱과 같은 모바일-35-인터넷 접속 디바이스의 일부일 수 있다. 프로세싱 시스템은 또한, 스마트 워치 웨어러블 디바이스 등의 웨어러블 디바이스; 실제 세계 시각, 오디오 또는 촉각 경험들을 보완하기 위해 시각, 오디오 또는 촉각 출력들 을 제공하거나 그렇지 않으면 텍스트, 오디오, 그래픽, 비디오, 홀로그래픽 이미지들 또는 비디오, 또는 촉각 피드백을 제공하기 위한 증강 현실(AR) 또는 가상 현실(VR) 특징들로 향상된 스마트 아이웨어 또는 의류; 다른 증강 현실(AR) 디바이스; 또는 다른 가상 현실(VR) 디바이스를 포함하거나, 이와 결합되거나, 그 내부에 통합될 수 있다. 프로세싱 시스템은 텔레비전 또는 셋톱 박스 디바이스를 포함하거나 그의 일부일 수 있다. 시 스템은 버스, 트랙터 트레일러, 자동차, 모터 또는 전력 사이클, 비행기 또는 글라이더(또는 이들의 임의 의 조합)와 같은 자율-주행(self-driving) 차량을 포함할 수 있거나, 이와 결합될 수 있거나, 또는 그 내부에 통합될 수 있다. 자율 주행 차량은 시스템을 사용하여 차량 주위에서 감지되는 환경을 프로세싱할 수 있 다. 하나 이상의 프로세서는, 실행될 때, 시스템 또는 사용자 소프트웨어에 대한 동작들을 수행하는 명령어들 을 프로세싱하기 위한 하나 이상의 프로세서 코어를 포함할 수 있다. 하나 이상의 프로세서 코어 중 적어도 하나는 특정 명령어 세트를 프로세싱하도록 구성될 수 있다. 명령어 세트는, CISC(Complex Instruction Set Computing), RISC(Reduced Instruction Set Computing), 또는 VLIW(Very Long Instruction Word)를 통한 컴퓨팅을 용이하게 할 수 있다. 하나 이상의 프로세서 코어는 다른 명령어 세 트들의 에뮬레이션을 용이하게 하는 명령어들을 포함할 수 있는 상이한 명령어 세트를 프로세싱할 수 있 다. 프로세서 코어는 또한 디지털 신호 프로세서(DSP)와 같은 다른 프로세싱 디바이스들을 포함할 수 있 다. 프로세서는 캐시 메모리를 포함할 수 있다. 아키텍처에 종속하여, 프로세서는 단일의 내부 캐시 또는 다중 레벨의 내부 캐시를 가질 수 있다. 일부 실시예들에서, 캐시 메모리는 프로세서의 다양 한 컴포넌트들 사이에서 공유된다. 일부 실시예들에서, 프로세서는 또한 외부 캐시(예를 들어, 레벨- 3(L3) 캐시 또는 마지막 레벨 캐시(LLC))(도시되지 않음)를 사용하는데, 이는 공지된 캐시 코히어런시 기술들을 사용하여 프로세서 코어들 사이에 공유될 수 있다. 레지스터 파일은 프로세서에 추가로 포 함될 수 있고, 상이한 타입들의 데이터를 저장하기 위한 상이한 타입들의 레지스터들(예를 들어, 정수 레지스터 들, 부동 소수점 레지스터들, 상태 레지스터들, 및 명령어 포인터 레지스터)을 포함할 수 있다. 일부 레지스터 들은 범용 레지스터들일 수 있는 반면, 다른 레지스터들은 프로세서의 설계에 특정적일 수 있다. 하나 이상의 프로세서(들)는 프로세서와 시스템 내의 다른 컴포넌트들 사이에서 어드레스, 데이터, 또는 제어 신호들과 같은 통신 신호들을 송신하기 위해 하나 이상의 인터페이스 버스(들)와 결합 될 수 있다. 인터페이스 버스는, 이러한 실시예들 중 하나에서, DMI(Direct Media Interface) 버스의 버전과 같은, 프로세서 버스일 수 있다. 그러나, 프로세서 버스들은 DMI 버스에 한정되지 않으며, 하나 이상의 주변 컴포넌트 인터커넥트 버스(예를 들어, PCI, PCI 익스프레스), 메모리 버스들, 또는 다른 타입들의 인터페 이스 버스들을 포함할 수 있다. 예를 들어, 프로세서(들)는 통합 메모리 컨트롤러 및 플랫폼 컨트 롤러 허브를 포함할 수 있다. 메모리 컨트롤러는 메모리 디바이스와 시스템의 다른 컴포넌 트들 사이의 통신을 용이하게 하는 한편, 플랫폼 컨트롤러 허브(PCH)는 로컬 I/O 버스를 통해 I/O 디바이 스들에 대한 접속들을 제공한다. 메모리 디바이스는 동적 랜덤 액세스 메모리(DRAM) 디바이스, 정적 랜덤 액세스 메모리(SRAM) 디바이스, 플래시 메모리 디바이스, 상변화 메모리 디바이스, 또는 프로세스 메모리로서 기능하기에 적합한 성능을 갖는 일부 다른 메모리 디바이스일 수 있다. 메모리 디바이스는, 예를 들어, 시스템에 대한 시스템 메 모리로서 동작하여, 하나 이상의 프로세서가 애플리케이션 또는 프로세스를 실행할 때 사용하기 위한 데 이터 및 명령어들을 저장할 수 있다. 메모리 컨트롤러는 또한 그래픽 및 미디어 연산들을 수행하기 위해 프로세서들 내의 하나 이상의 그래픽 프로세서와 통신할 수 있는 선택적인 외부 그 래픽 프로세서와 결합한다. 일부 실시예들에서, 그래픽, 미디어 및/또는 계산 연산들은, 전문화된 그래 픽, 미디어 또는 계산 연산들의 세트를 수행하도록 구성될 수 있는 코프로세서인 가속기에 의해 보조될 수 있다. 예를 들어, 가속기는 머신 러닝 또는 계산 연산들을 최적화하기 위해 사용되는 행렬 곱셈 가속 기일 수 있다. 가속기는 그래픽 프로세서와 협력하여 광선-추적 연산들을 수행하기 위해 사용될 수 있는 광선-추적 가속기일 수 있다. 일 실시예에서, 외부 가속기는 가속기 대신에 또는 그와 협 력하여 사용될 수 있다. 프로세서(들)에 접속할 수 있는 디스플레이 디바이스가 제공될 수 있다. 디스플레이 디바이스 는 디스플레이 인터페이스(예를 들어, 디스플레이포트 등)를 통해 부착된 모바일 전자 디바이스 또는 랩-36-톱 디바이스 또는 외부 디스플레이 디바이스에서와 같이, 내부 디스플레이 디바이스 중 하나 이상일 수 있다. 디스플레이 디바이스는 가상 현실(VR) 애플리케이션들 또는 증강 현실(AR) 애플리케이션들에서 사용하기 위한 입체 디스플레이 디바이스와 같은 헤드 마운티드 디스플레이(HMD)일 수 있다. 플랫폼 컨트롤러 허브는 주변 장치들이 고속 I/O 버스를 통해 메모리 디바이스 및 프로세서 에 접속하는 것을 가능하게 할 수 있다. I/O 주변 장치들은 오디오 컨트롤러, 네트워크 컨트롤러, 펌웨어 인터페이스, 무선 송수신기, 터치 센서들, 데이터 스토리지 디바이스(예를 들 어, 비휘발성 메모리, 휘발성 메모리, 하드 디스크 드라이브, 플래시 메모리, NAND, 3D NAND, 3D XPoint/Optane 등)를 포함하지만, 이들로 제한되지 않는다. 데이터 스토리지 디바이스는 저장 인터페이 스(예를 들어, SATA)를 통해 또는 주변 컴포넌트 인터커넥트 버스(예를 들어, PCI, PCI 익스프레스)와 같은 주 변 버스를 통해 접속될 수 있다. 터치 센서들은 터치 스크린 센서들, 압력 센서들, 또는 지문 센서들을 포함할 수 있다. 무선 송수신기는 Wi-Fi 송수신기, 블루투스 송수신기, 또는 3G, 4G, 5G 또는 LTE(Long-Term Evolution) 송수신기와 같은 모바일 네트워크 송수신기일 수 있다. 펌웨어 인터페이스는 시스템 펌웨어와의 통신을 가능하게 하고, 예를 들어, 통합형 확장가능 펌웨어 인터페이스(UEFI)일 수 있다. 네트워크 컨트롤러는 유선 네트워크로의 네트워크 접속을 가능하게 할 수 있다. 일부 실시예들에서, 고 성능 네트워크 컨트롤러(도시되지 않음)는 인터페이스 버스와 결합된다. 오디오 컨트롤러는 멀티- 채널 고화질 오디오 컨트롤러일 수 있다. 이들 실시예들 중 일부에서, 시스템은 레거시(예를 들어, 개인 시스템 2(PS/2)) 디바이스들을 시스템에 결합하기 위한 선택적 레거시 I/O 컨트롤러를 포함한다. 플랫폼 컨트롤러 허브는 또한 키보드 및 마우스 조합들, 카메라, 또는 다른 USB 입력 디바이스들과 같은 입력 디바이스들을 접속시키는 하나 이상의 USB(Universal Serial Bus) 컨트롤러에 접속할 수 있다. 상이하게 구성된 다른 타입들의 데이터 프로세싱 시스템들도 사용될 수 있기 때문에, 도시된 시스템은 예 시적이고 비제한적인 것으로 이해될 것이다. 예를 들어, 메모리 컨트롤러 및 플랫폼 컨트롤러 허브 의 인스턴스는 외부 그래픽 프로세서와 같은 개별 외부 그래픽 프로세서에 통합될 수 있다. 플랫 폼 컨트롤러 허브 및/또는 메모리 컨트롤러는 하나 이상의 프로세서(들) 외부에 있을 수 있 다. 예를 들어, 시스템은 프로세서(들)와 통신하는 시스템 칩셋 내의 메모리 컨트롤러 허브 및 주 변 컨트롤러 허브로서 구성될 수 있는 외부 메모리 컨트롤러 및 플랫폼 컨트롤러 허브를 포함할 수 있다. 예를 들어, CPU들, 메모리 등의 컴포넌트들, 및 기타 컴포넌트들이 배치된 회로 보드들(\"슬레드들(sleds)\")이 사용될 수 있고, 증가된 열 성능을 위해 설계된다. 프로세서들과 같은 프로세싱 컴포넌트들은 슬레드의 상부 측면에 위치될 수 있는 반면, DIMM들과 같은, 니어 메모리(near memory)는 슬레드의 하부 측면 상에 위치된다. 이 설계에 의해 제공되는 향상된 기류의 결과로서, 컴포넌트들은 전형적인 시스템들에서보다 높은 주파수들 및 전력 레벨들에서 동작할 수 있으며, 그로써 성능을 증가시킬 수 있다. 게다가, 슬레드들은 랙 내의 전력 및 데 이터 통신 케이블들과 맹목적으로 메이팅(blindly mate)하도록 구성됨으로써, 그들의 능력을 향상시켜 신속하게 제거, 업그레이드, 재설치, 및/또는 교체될 수 있다. 유사하게, 프로세서들, 가속기들, 메모리, 및 데이터 스 토리지 드라이브들과 같은, 슬레드들 상에 위치된 개별 컴포넌트들은 그들의 서로로부터의 증가된 간격으로 인 해 쉽게 업그레이드되도록 구성된다. 예시적인 실시예에서, 컴포넌트들은 그들의 진정성(authenticity)을 증명 하기 위해 하드웨어 보증(hardware attestation) 특징들을 추가적으로 포함한다. 데이터 센터는 이더넷 및 Omni-Path를 포함하는 다수의 다른 네트워크 아키텍처를 지원하는 단일 네트워크 아키 텍처(\"패브릭\")를 이용할 수 있다. 슬레드들은, 전형적인 연선(twisted pair) 케이블링(예를 들어, 카테고리 5, 카테고리 5e, 카테고리 6 등)보다 더 높은 대역폭 및 더 낮은 레이턴시를 제공하는 광섬유들을 통해 스위치 들에 결합된다. 고 대역폭, 저 레이턴시 인터커넥트들 및 네트워크 아키텍처로 인해 데이터 센터는, 사용 중에, 물리적으로 분리되어(disaggregated) 있는 메모리, 가속기들(예를 들어, GPU들, 그래픽 가속기들, FPGA들, ASIC들, 신경망 및/또는 인공 지능 가속기들 등), 및 데이터 스토리지 드라이브들과 같은, 자원들을 풀 링하고, 이들을 필요에 따라 계산 자원들(예를 들어, 프로세서들)에 제공할 수 있어, 풀링된 자원들이 로컬인 것처럼 계산 자원들이 풀링된 자원들에 액세스할 수 있게 해준다. 전원 또는 전력 소스는 시스템 또는 본 명세서에 설명된 임의의 컴포넌트 또는 시스템에 전압 및/또는 전 류를 제공할 수 있다. 일 예에서, 전원은 벽 콘센트에 플러그하기 위한 AC-DC(교류-직류) 어댑터를 포함한다. 그러한 AC 전력은 재생가능 에너지(예를 들어, 태양 전력) 전력 소스일 수 있다. 일 예에서, 전력 소스는 외부 AC-DC 컨버터와 같은 DC 전력 소스를 포함한다. 전력 소스 또는 전원은 충전 필드에 대한 근접을 통해 충전하 기 위한 무선 충전 하드웨어를 또한 포함할 수 있다. 전력 소스는 내부 배터리, 교류 서플라이(alternating-37-current supply), 모션 기반 전원, 태양 전원, 또는 연료 전지 소스를 포함할 수 있다. 도 15a 내지 도 15c는 컴퓨팅 시스템들 및 그래픽 프로세서들을 예시한다. 본 명세서의 임의의 다른 도면의 요 소들과 동일하거나 유사한 명칭들을 갖는 도 15a 내지 도 15c의 요소들은 다른 도면들에서와 동일한 요소들을 설명하고, 본 명세서의 다른 곳에서 설명된 것들과 같이 그와 유사한 방식으로 동작하거나 기능할 수 있고, 동 일한 컴포넌트들을 포함할 수 있고, 다른 엔티티들에 링크될 수 있지만, 이에 한정되지 않는다. 도 15a는 프로세서들 중 하나의 프로세서의 변형일 수 있고 그것들 중 하나를 대신하여 사용될 수 있는 프로세서의 블록도이다. 따라서, 본 명세서에서 프로세서와 조합한 임의의 특징부들의 개시내용은 또한 프로세서(들)와의 대응하는 조합을 개시하지만, 이에 한정되지 않는다. 프로세서는 하나 이 상의 프로세서 코어(1502A-1502N), 통합 메모리 컨트롤러 및 통합 그래픽 프로세서를 가질 수 있다. 통합 그래픽 프로세서가 배제되는 경우, 프로세서를 포함하는 시스템은 시스템 칩셋 내에 있거나 시스템 버스를 통해 결합되는 그래픽 프로세서 디바이스를 포함할 것이다. 프로세서는 파선 박스들로 표 현되는 추가적인 코어(1502N)까지의 그리고 추가적인 코어(1502N)를 포함한 추가적인 코어들을 포함할 수 있다. 프로세서 코어들(1502A-1502N) 각각은 하나 이상의 내부 캐시 유닛(1504A-1504N)을 포함한다. 일부 실시예들에 서, 각각의 프로세서 코어(1502A-1502N)는 또한 하나 이상의 공유 캐시 유닛에 대한 액세스를 갖는다. 내부 캐시 유닛들(1504A-1504N) 및 공유 캐시 유닛들은 프로세서 내의 캐시 메모리 계층구조를 나 타낸다. 캐시 메모리 계층구조는 각각의 프로세서 코어 내의 적어도 하나의 레벨의 명령어 및 데이터 캐시, 및 레벨 2(L2), 레벨 3(L3), 레벨 4(L4), 또는 다른 레벨들의 캐시와 같은 하나 이상의 레벨의 공유 중간-레벨 캐 시를 포함할 수 있고, 여기서 외부 메모리 이전의 가장 높은 레벨의 캐시는 LLC로서 분류된다. 일부 실시예들 에서, 캐시 코히어런시 로직은 다양한 캐시 유닛들(1506 및 1504A-1504N) 사이의 코히어런시를 유지한다. 프로세서는 또한 하나 이상의 버스 컨트롤러 유닛의 세트 및 시스템 에이전트 코어를 포함할 수 있다. 하나 이상의 버스 컨트롤러 유닛은 하나 이상의 PCI 또는 PCI 익스프레스 버스와 같은 주변 버 스들의 세트를 관리한다. 시스템 에이전트 코어는 다양한 프로세서 컴포넌트들에 대한 관리 기능을 제공 한다. 시스템 에이전트 코어는 다양한 외부 메모리 디바이스들(도시되지 않음)에 대한 액세스를 관리하 기 위한 하나 이상의 통합 메모리 컨트롤러를 포함할 수 있다. 예를 들어, 프로세서 코어들(1502A-1502N) 중 하나 이상은 동시 멀티스레딩을 위한 지원을 포함할 수 있다. 시 스템 에이전트 코어는 멀티 스레드 프로세싱 동안 코어들(1502A-1502N)을 조정 및 동작시키기 위한 컴포 넌트들을 포함한다. 시스템 에이전트 코어는 프로세서 코어들(1502A-1502N) 및 그래픽 프로세서의 전력 상태를 조절하기 위한 로직 및 컴포넌트들을 포함하는 전력 제어 유닛(PCU)을 추가로 포함할 수 있다. 프로세서는 그래픽 프로세싱 연산들을 실행하기 위한 그래픽 프로세서를 추가로 포함할 수 있다. 이러한 실시예들 중 일부에서, 그래픽 프로세서는 하나 이상의 통합 메모리 컨트롤러를 포함하는 시스템 에이전트 코어 및 공유 캐시 유닛들의 세트와 결합한다. 시스템 에이전트 코어는 또 한 그래픽 프로세서 출력을 하나 이상의 결합된 디스플레이로 구동하는 디스플레이 컨트롤러를 포함할 수 있다. 디스플레이 컨트롤러는 또한 적어도 하나의 인터커넥트를 통해 그래픽 프로세서와 결합된 별개의 모듈일 수 있거나, 그래픽 프로세서 내에 통합될 수 있다. 링-기반 인터커넥트 유닛은 프로세서의 내부 컴포넌트들을 결합하기 위해 사용될 수 있다."}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "그러나, 점대점 인터커넥트, 스위칭형 인터커넥트, 또는 본 기술분야에 공지된 기술들을 포함하는 다른 기술들 과 같은 대안적인 인터커넥트 유닛이 사용될 수 있다. 링-기반 인터커넥트를 갖는 이러한 실시예들 중 일부에서, 그래픽 프로세서는 I/O 링크를 통해 링-기반 인터커넥트와 결합한다. 예시적인 I/O 링크는 다양한 프로세서 컴포넌트들과, eDRAM 모듈과 같은 고성능 내장형 메모리 모듈 사이의 통신을 용이하게 하는 온 패키지 I/O 인터커넥트를 포함하는, 다수의 다양한 I/O 인터커넥트 중 적어도 하나를 나타낸다. 선택적으로, 프로세서 코어들(1502A-1502N) 각각 및 그래픽 프로세서는 공유 마지막 레벨 캐시로서 내장형 메모리 모듈들을 사용할 수 있다. 프로세서 코어들(1502A-1502N)은, 예를 들어, 동일한 명령어 세트 아키텍처를 실행하는 동종 코어들일 수 있다. 대안적으로, 프로세서 코어들(1502A-1502N)은 명령어 세트 아키텍처(instruction set architecture)(ISA)의 관 점에서 이종이며, 여기서 프로세서 코어들(1502A-1502N) 중 하나 이상은 제1 명령어 세트를 실행하는 한편, 다 른 코어들 중 적어도 하나는 제1 명령어 세트의 서브세트 또는 상이한 명령어 세트를 실행한다. 프로세서 코어 들(1502A-1502N)은 마이크로아키텍처의 관점에서 이종일 수 있으며, 여기서 비교적 더 높은 전력 소비를 갖는-38-하나 이상의 코어는 더 낮은 전력 소비를 갖는 하나 이상의 전력 코어와 결합한다. 다른 예로서, 프로세서 코 어들(1502A-1502N)은 계산 능력의 관점에서 이종이다. 추가적으로, 프로세서는, 다른 컴포넌트들에 추가 하여, 예시된 컴포넌트들을 갖는 SoC 집적 회로로서 또는 하나 이상의 칩 상에 구현될 수 있다. 도 15b는 본 명세서에 설명된 일부 실시예들에 따른 그래픽 프로세서 코어의 하드웨어 로직의 블록도이다. 때때로 코어 슬라이스라고 지칭되는, 그래픽 프로세서 코어는 모듈러 그래픽 프로세서 내의 하나 또는 다수의 그래픽 코어일 수 있다. 그래픽 프로세서 코어는 하나의 그래픽 코어 슬라이스의 예이 며, 본 명세서에 설명된 그래픽 프로세서는 타겟 전력 및 성능 엔벨로프들에 기초한 다수의 그래픽 코어 슬라이 스를 포함할 수 있다. 각각의 그래픽 프로세서 코어는 범용 및 고정 함수 로직의 모듈러 블록들을 포함 하는, 서브 슬라이스들이라고도 하는 다수의 서브-코어(1521A-1521F)와 결합된 고정 함수 블록을 포함할 수 있다. 고정 함수 블록은, 예를 들어, 저성능 및/또는 저전력 그래픽 프로세서 구현들에서, 그래픽 프로세서 코 어 내의 모든 서브-코어들에 의해 공유될 수 있는 지오메트리/고정 함수 파이프라인을 포함할 수 있다. 지오메트리/고정 함수 파이프라인은 3D 고정 함수 파이프라인(예를 들어, 이하에서 설명된 도 16a 에서와 같은 3D 파이프라인), 비디오 프론트-엔드 유닛, 스레드 스포너(thread spawner) 및 스레드 디스 패처, 및 통합 리턴 버퍼들(예를 들어, 이하에서 설명된 바와 같은, 도 17의 통합 리턴 버퍼)을 관리하는 통합 리턴 버퍼 관리자를 포함할 수 있다. 고정 함수 블록은 또한 그래픽 SoC 인터페이스, 그래픽 마이크로컨트롤러, 및 미디어 파이프 라인을 포함할 수 있다. 그래픽 SoC 인터페이스는 그래픽 프로세서 코어와 시스템 온 칩 집 적 회로 내의 다른 프로세서 코어들 사이의 인터페이스를 제공한다. 그래픽 마이크로컨트롤러는, 스레드 디스패치, 스케줄링, 및 선점(pre-emption)을 포함하는, 그래픽 프로세서 코어의 다양한 기능들을 관리하 도록 구성가능한 프로그램가능 서브-프로세서이다. 미디어 파이프라인(예를 들어, 도 16a 및 도 17의 미 디어 파이프라인)은 이미지 및 비디오 데이터를 포함하는 멀티미디어 데이터의 디코딩, 인코딩, 프리-프 로세싱, 및/또는 포스트-프로세싱을 용이하게 하는 로직을 포함한다. 미디어 파이프라인은 서브-코어들 (1521-1521F) 내의 로직을 계산 또는 샘플링하라는 요청들을 통해 미디어 연산들을 구현한다. SoC 인터페이스는 그래픽 프로세서 코어가 공유 마지막 레벨 캐시 메모리와 같은 메모리 계층구조 요소들, 시스템 RAM, 및/또는 내장형 온-칩 또는 온-패키지 DRAM을 포함하는, 범용 애플리케이션 프로세서 코어 들(예를 들어, CPU들) 및/또는 SoC 내의 다른 컴포넌트들과 통신하는 것을 가능하게 할 수 있다. SoC 인터페이 스는 또한 카메라 이미징 파이프라인들과 같은 SoC 내의 고정 함수 디바이스들과의 통신을 가능하게 할 수 있고, SoC 내의 CPU들과 그래픽 프로세서 코어 사이에 공유될 수 있는 전역 메모리 원자들(global memory atomics)의 사용을 가능하게 하고/하거나 이들을 구현한다. SoC 인터페이스는 또한 그래픽 프로 세서 코어에 대한 전력 관리 제어들을 구현할 수 있고, 그래픽 코어의 클록 도메인과 SoC 내의 다 른 클록 도메인들 사이의 인터페이스를 인에이블할 수 있다. 선택적으로, SoC 인터페이스는 그래픽 프로 세서 내의 하나 이상의 그래픽 코어 각각에 커맨드들 및 명령어들을 제공하도록 구성되는 커맨드 스트리머 및 전역 스레드 디스패처로부터의 커맨드 버퍼들의 수신을 가능하게 한다. 커맨드들 및 명령어들은, 미디어 연산 들이 수행될 때, 미디어 파이프라인에 디스패치될 수 있거나, 또는 그래픽 프로세싱 연산들이 수행될 때, 지오메트리 및 고정 함수 파이프라인(예를 들어, 지오메트리 및 고정 함수 파이프라인, 지오메트리 및 고 정 함수 파이프라인)에 디스패치될 수 있다. 그래픽 마이크로컨트롤러는 그래픽 프로세서 코어에 대한 다양한 스케줄링 및 관리 태스크들을 수 행하도록 구성될 수 있다. 일 구성에서, 그래픽 마이크로컨트롤러는, 예를 들어, 서브-코어들(1521A- 1521F) 내의 실행 유닛(EU) 어레이들(1522A-1522F, 1524A-1524F) 내의 다양한 그래픽 병렬 엔진들에 대해 그래 픽 및/또는 계산 작업부하 스케줄링을 수행할 수 있다. 이러한 작업부하 스케줄링에서, 그래픽 프로세서 코어 를 포함하는 SoC의 CPU 코어 상에서 실행되는 호스트 소프트웨어는 작업부하들을 다수의 그래픽 프로세서 도어벨 중 하나에 제출할 수 있으며, 이는 적절한 그래픽 엔진 상의 스케줄링 동작을 호출한다. 스케줄링 동작 들은 다음에 어느 작업부하를 실행할지를 결정하는 것, 커맨드 스트리머에 작업부하를 제출하는 것, 엔진 상에 서 실행되는 기존의 작업부하들을 선점하는 것, 작업부하의 진행을 모니터링하는 것, 및 작업부하가 언제 완료 되는지를 호스트 소프트웨어에 통지하는 것을 포함한다. 선택적으로, 그래픽 마이크로컨트롤러는 또한 그래픽 프로세서 코어에 대한 저-전력 또는 유휴 상태들을 용이하게 하여, 운영 체제 및/또는 시스템 상 의 그래픽 드라이버 소프트웨어와 독립적으로 저-전력 상태 천이들에 걸쳐 그래픽 프로세서 코어 내의 레-39-지스터들을 세이브 및 복원하는 능력을 그래픽 프로세서 코어에 제공할 수 있다. 그래픽 프로세서 코어는 예시된 서브-코어들(1521A-1521F)보다 더 많거나 더 적은 수의, 최대 N개의 모듈 러 서브-코어를 가질 수 있다. N개의 서브 코어의 각각의 세트에 대해, 그래픽 프로세서 코어는 또한 공 유 함수 로직, 공유 및/또는 캐시 메모리, 지오메트리/고정 함수 파이프라인뿐만 아니라, 다 양한 그래픽 및 계산 프로세싱 연산들을 가속시키기 위한 추가적인 고정 함수 로직을 포함할 수 있다. 공유 함수 로직은 그래픽 프로세서 코어 내의 각각의 N개의 서브 코어에 의해 공유될 수 있는 도 17의 공유 함수 로직(예를 들어, 샘플러, 수학 및/또는 인터-스레드 통신 로직)과 연관된 로직 유닛들을 포함할 수 있다. 공유 및/또는 캐시 메모리는 그래픽 프로세서 코어 내의 N개의 서브코어(1521A- 1521F)의 세트에 대한 마지막 레벨 캐시일 수 있고, 또한 다수의 서브코어에 의해 액세스가능한 공유 메모리로 서 기능할 수 있다. 지오메트리/고정 함수 파이프라인은 고정 함수 블록 내의 지오메트리/고정 함 수 파이프라인 대신에 포함될 수 있고, 동일하거나 유사한 로직 유닛들을 포함할 수 있다. 그래픽 프로세서 코어는 그래픽 프로세서 코어에 의해 사용하기 위한 다양한 고정 함수 가속 로직 을 포함할 수 있는 추가적인 고정 함수 로직을 포함할 수 있다. 선택적으로, 추가적인 고정 함수 로직 은 포지션 온리 셰이딩(position only shading)에 사용하기 위한 추가적인 지오메트리 파이프라인을 포함 한다. 포지션 온리 셰이딩에서, 2개의 지오메트리 파이프라인 즉, 지오메트리/고정 함수 파이프라인(1538, 1531) 내의 풀(full) 지오메트리 파이프라인, 및 추가적인 고정 함수 로직 내에 포함될 수 있는 추가적인 지오메트리 파이프라인인 컬(cull) 파이프라인이 존재한다. 예를 들어, 컬 파이프라인은 풀 지오메트리 파이프 라인의 트리밍 다운된 버전(trimmed down version)일 수 있다. 풀 파이프라인 및 컬 파이프라인은 동일한 애플 리케이션의 상이한 인스턴스들을 실행할 수 있고, 각각의 인스턴스는 별개의 컨텍스트를 갖는다. 포지션 온리 셰이딩은 폐기된 삼각형들의 긴 컬 구간(long cull runs)을 숨길 수 있어서, 일부 경우들에서 셰이딩이 더 일찍 완료되는 것을 가능하게 한다. 예를 들어, 추가적인 고정 함수 로직 내의 컬 파이프라인 로직은 주요 애 플리케이션과 병렬로 포지션 셰이더(position shader)들을 실행할 수 있고, 일반적으로 풀 파이프라인보다 더 빠르게 중요한 결과들을 생성하는데, 그 이유는 컬 파이프라인이 프레임 버퍼에 대한 픽셀들의 래스터화 및 렌 더링을 수행하지 않고, 정점들의 포지션 속성만을 페치 및 셰이딩하기 때문이다. 컬 파이프라인은 생성된 임계 결과들을 사용하여 모든 삼각형들에 대한 가시성 정보를 이러한 삼각형들이 컬링되는지에 관계없이 계산할 수 있다. (이 경우에 리플레이(replay) 파이프라인이라고 할 수 있는) 풀 파이프라인은 최종적으로 래스터화 단계 로 전달되는 가시적 삼각형들만을 셰이딩하기 위해 컬링된 삼각형들을 스킵하도록 가시성 정보를 소비할 수 있 다. 선택적으로, 추가적인 고정 함수 로직은 또한 머신 러닝 훈련 또는 추론을 위한 최적화들을 포함하는 구 현들을 위한, 고정 함수 행렬 곱셈 로직과 같은, 머신 러닝 가속 로직을 포함할 수 있다. 각각의 그래픽 서브-코어(1521A-1521F) 내에, 그래픽 파이프라인, 미디어 파이프라인, 또는 셰이더 프로그램들 에 의한 요청들에 응답하여 그래픽, 미디어, 및 계산 연산들을 수행하기 위해 사용될 수 있는 실행 자원들의 세 트가 포함된다. 그래픽 서브-코어들(1521A-1521F)은 다수의 EU 어레이(1522A-1522F, 1524A-1524F), 스레드 디 스패치 및 인터-스레드 통신(TD/IC) 로직(1523A-1523F), 3D(예를 들어, 텍스처) 샘플러(1525A-1525F), 미디어 샘플러(1526A-1526F), 셰이더 프로세서(1527A-1527F), 및 공유 로컬 메모리(SLM)(1528A-1528F)를 포함한다. EU 어레이들(1522A-1522F, 1524A-1524F)은 각각 다수의 실행 유닛을 포함하고, 이들은 그래픽, 미디어, 또는 계 산 셰이더 프로그램들을 포함하는, 그래픽, 미디어, 또는 계산 연산의 서비스에서 부동 소수점 및 정수/고정 소 수점 로직 연산들을 수행할 수 있는 범용 그래픽 프로세싱 유닛들이다. TD/IC 로직(1523A-1523F)은 서브-코어 내의 실행 유닛들에 대한 로컬 스레드 디스패치 및 스레드 제어 동작들을 수행하고, 서브-코어의 실행 유닛들 상에서 실행하는 스레드들 사이의 통신을 용이하게 한다. 3D 샘플러(1525A-1525F)는 텍스처 또는 다른 3D 그래 픽 관련 데이터를 메모리 내로 판독할 수 있다. 3D 샘플러는 구성된 샘플 상태 및 주어진 텍스처와 연관된 텍 스처 포맷에 기초하여 텍스처 데이터를 상이하게 판독할 수 있다. 미디어 샘플러(1526A-1526F)는 미디어 데이 터와 연관된 타입 및 포맷에 기초하여 유사한 판독 동작들을 수행할 수 있다. 예를 들어, 각각의 그래픽 서브- 코어(1521A-1521F)는 통합 3D 및 미디어 샘플러를 대안적으로 포함할 수 있다. 서브-코어들(1521A-1521F) 각각 내의 실행 유닛들 상에서 실행되는 스레드들은, 스레드 그룹 내에서 실행되는 스레드들이 온-칩 메모리의 공통 풀(common pool)을 사용하여 실행될 수 있게 하기 위해, 각각의 서브-코어 내의 공유 로컬 메모리(1528A- 1528F)를 이용할 수 있다. 도 15c는 본 명세서에 설명된 실시예들에 따른 그래픽 프로세서, 예를 들어, 그래픽 프로세서 및/또는 계 산 가속기로서 구성될 수 있는 범용 그래픽 프로세싱 유닛(GPGPU)의 블록도이다. GPGPU는 하나 이-40-상의 시스템 및/또는 메모리 버스를 통해 호스트 프로세서들(예를 들어, 하나 이상의 CPU(들)) 및 메모리 (1571, 1572)와 상호접속될 수 있다. 메모리는 하나 이상의 CPU(들)와 공유될 수 있는 시스템 메 모리일 수 있는 한편, 메모리는 GPGPU에 전용인 디바이스 메모리이다. 예를 들어, 디바이스 메모 리 및 GPGPU 내의 컴포넌트들은 하나 이상의 CPU(들)에 액세스가능한 메모리 어드레스들에 매핑될 수 있다. 메모리(1571 및 1572)로의 액세스는 메모리 컨트롤러를 통해 용이하게 될 수 있다. 메 모리 컨트롤러는 내부 DMA(direct memory access) 컨트롤러를 포함할 수 있거나, 그렇지 않으면 DMA 컨트롤러에 의해 수행될 동작들을 수행하기 위한 로직을 포함할 수 있다. GPGPU는 L2 캐시, L1 캐시, 명령어 캐시, 및 공유 메모리를 포함하는 다수의 캐시 메모리를 포함하며, 이들 중 적어도 일부는 또한 캐시 메모리로서 파티셔닝될 수 있다. GPGPU는 또 한 다수의 계산 유닛(1560A-1560N)을 포함한다. 각각의 계산 유닛(1560A-1560N)은 벡터 레지스터들, 스 칼라 레지스터들, 벡터 로직 유닛들, 및 스칼라 로직 유닛들의 세트를 포함한다. 계산 유닛 들(1560A-1560N)은 또한 로컬 공유 메모리 및 프로그램 카운터를 포함할 수 있다. 계산 유닛들 (1560A-1560N)은 상수 캐시(constant cache)와 결합할 수 있고, 이는 GPGPU 상에서 실행되는 커널 또는 셰이더 프로그램의 실행 동안 변하지 않을 데이터인 상수 데이터를 저장하기 위해 사용될 수 있다. 상수 캐시는 스칼라 데이터 캐시일 수 있고, 캐싱된 데이터는 스칼라 레지스터들 내로 직접 페치될 수 있다. 동작 동안, 하나 이상의 CPU(들)는 액세스가능한 어드레스 공간에 매핑된 GPGPU에서의 레지스터들 또는 메모리에 커맨드들을 기입할 수 있다. 커맨드 프로세서는 레지스터들 또는 메모리로부터 커맨드들 을 판독하고 그러한 커맨드들이 GPGPU 내에서 어떻게 프로세싱될지를 결정할 수 있다. 스레드 디스패처 는 그 후 그 커맨드들을 수행하기 위해 계산 유닛들(1560A-1560N)에 스레드들을 디스패치하기 위해 사용 될 수 있다. 각각의 계산 유닛(1560A-1560N)은 다른 계산 유닛들과 독립적으로 스레드들을 실행할 수 있다. 추가적으로, 각각의 계산 유닛(1560A-1560N)은 조건적 계산을 위해 독립적으로 구성될 수 있고, 계산의 결과들 을 메모리에 조건부로 출력할 수 있다. 커맨드 프로세서들은 제출된 커맨드들이 완료될 때 하나 이상의 CPU(들)를 인터럽트할 수 있다. 도 16a 내지 도 16c는, 예를 들어, 도 15a 내지 도 15c에 따른, 본 명세서에 설명된 실시예들에 의해 제공되는 추가적인 그래픽 프로세서 및 계산 가속기 아키텍처들의 블록도들을 예시한다. 본 명세서의 임의의 다른 도면 의 요소들과 동일하거나 유사한 명칭들을 갖는 도 16a 내지 도 16c의 요소들은 다른 도면들에서와 동일한 요소 들을 설명하고, 본 명세서의 다른 곳에서 설명된 것들과 같이 그와 유사한 방식으로 동작하거나 기능할 수 있고, 동일한 컴포넌트들을 포함할 수 있고, 다른 엔티티들에 링크될 수 있지만, 이에 한정되지 않는다. 도 16a는 개별 그래픽 프로세싱 유닛일 수 있거나, 복수의 프로세싱 코어, 또는 메모리 디바이스들 또는 네트워 크 인터페이스들과 같은, 그러나 이에 한정되지 않는 다른 반도체 디바이스들과 통합된 그래픽 프로세서일 수 있는 그래픽 프로세서의 블록도이다. 그래픽 프로세서는 그래픽 프로세서의 변형일 수 있고, 그래픽 프로세서 대신에 사용될 수 있다. 따라서, 본 명세서에서 그래픽 프로세서와 조합된 임의의 특징부들의 개시내용도 그래픽 프로세서와의 대응하는 조합을 개시하지만, 이에 제한되지 않는다. 그래픽 프로세서는 프로세서 메모리에 배치된 커맨드들에 의해 그리고 그래픽 프로세서 상의 레지스터들에 대한 메모리 매핑된 I/O 인터페이스를 통해 통신할 수 있다. 그래픽 프로세서는 메모리에 액세스하기 위한 메 모리 인터페이스를 포함할 수 있다. 메모리 인터페이스는 로컬 메모리, 하나 이상의 내부 캐시, 하나 이상의 공유 외부 캐시, 및/또는 시스템 메모리에 대한 인터페이스일 수 있다. 선택적으로, 그래픽 프로세서는 또한, 디스플레이 출력 데이터를 디스플레이 디바이스에 구동하기 위한 디스플레이 컨트롤러를 포함한다. 디스플레이 컨트롤러는 비디오 또는 사용자 인터페이스 요 소들의 다수의 층의 디스플레이 및 구성을 위한 하나 이상의 오버레이 평면에 대한 하드웨어를 포함한다. 디스 플레이 디바이스는 내부 또는 외부 디스플레이 디바이스일 수 있다. 일 실시예에서, 디스플레이 디바이 스는 가상 현실(VR) 디스플레이 디바이스 또는 증강 현실(AR) 디스플레이 디바이스와 같은 헤드 마운티드 디스플레이 디바이스이다. 그래픽 프로세서는, MPEG-2와 같은 MPEG(Moving Picture Experts Group) 포 맷들, H.264/MPEG-4 AVC, H.265/HEVC, AOMedia(Alliance for Open Media) VP8, VP9와 같은 AVC(Advanced Video Coding) 포맷들뿐만 아니라, SMPTE(Society of Motion Picture & Television Engineers) 421M/VC-1, 및 JPEG와 같은 JPEG(Joint Photographic Experts Group) 포맷들, 및 MJPEG(Motion JPEG) 포맷들을 포함하지만 이 에 제한되지 않는 하나 이상의 미디어 인코딩 포맷으로, 이들로부터, 또는 이들 사이에서 미디어를 인코딩, 디-41-코딩, 또는 트랜스코딩하기 위한 비디오 코덱 엔진을 포함할 수 있다. 그래픽 프로세서는 예를 들어, 비트 경계 블록 전송들을 포함하는 2차원(2D) 래스터화기 연산(rasterizer operation)들을 수행하기 위한 블록 이미지 전송(BLIT) 엔진을 포함할 수 있다. 그러나, 대안적으로, 그 래픽 프로세싱 엔진(GPE)의 하나 이상의 컴포넌트를 사용하여 2D 그래픽 연산들이 수행될 수 있다. 일부 실시예들에서, GPE는 3차원(3D) 그래픽 연산들 및 미디어 연산들을 포함하는 그래픽 연산들을 수행하기 위한 계산 엔진이다. GPE는 3D 프리미티브 형상들(예를 들어, 직사각형, 삼각형 등)에 작용하는 프로세싱 함수들을 사용하여 3 차원 이미지들 및 장면들을 렌더링하는 것과 같은 3D 연산들을 수행하기 위한 3D 파이프라인을 포함할 수 있다. 3D 파이프라인은 3D/미디어 서브시스템에 대해 스포닝된(spawn) 실행 스레드들 및/또는 요 소 내의 다양한 태스크들을 수행하는 프로그램가능 및 고정 함수 요소들을 포함한다. 3D 파이프라인이 미디어 연산들을 수행하기 위해 사용될 수 있지만, GPE의 실시예는 또한, 비디오 포스트-프로세싱 및 이 미지 향상과 같은, 미디어 연산들을 수행하기 위해 구체적으로 사용되는 미디어 파이프라인을 포함한다. 미디어 파이프라인은 비디오 코덱 엔진 대신에, 또는 비디오 코덱 엔진을 대표하여, 비디오 디코드 가속, 비디오 디-인터레이싱, 및 비디오 인코드 가속과 같은, 하나 이상의 특수화된 미디어 연산을 수행 하는 고정 함수 또는 프로그램가능 로직 유닛들을 포함할 수 있다. 미디어 파이프라인은 추가적으로 3D/ 미디어 서브시스템 상에서의 실행을 위해 스레드를 스포닝하는 스레드 스포닝 유닛(thread spawning unit)을 포함할 수 있다. 스포닝된 스레드들은 3D/미디어 서브시스템에 포함된 하나 이상의 그래픽 실행 유닛에 대해 미디어 연산들에 대한 계산들을 수행한다. 3D/미디어 서브시스템은 3D 파이프라인 및 미디어 파이프라인에 의해 스포닝되는 스레드들을 실행하기 위한 로직을 포함할 수 있다. 파이프라인들은 스레드 실행 요청들을 3D/미디어 서브시스템으로 전송할 수 있으며, 이 3D/미디어 서브시스템은 다양한 요청들을 중재하고 이용가능한 스레드 실행 자원들로 디 스패치하기 위한 스레드 디스패치 로직을 포함한다. 실행 자원들은 3D 및 미디어 스레드들을 프로세싱하기 위 한 그래픽 실행 유닛들의 어레이를 포함한다. 3D/미디어 서브시스템은 스레드 명령어들 및 데이터에 대 한 하나 이상의 내부 캐시를 포함할 수 있다. 추가적으로, 3D/미디어 서브시스템은 또한 스레드들 간에 데이터를 공유하고 출력 데이터를 저장하기 위한, 레지스터들 및 어드레싱가능 메모리를 포함하는 공유 메모리 를 포함할 수 있다. 도 16b는 그래픽 프로세서의 변형이며 그래픽 프로세서 대신에 사용될 수 있고 그 반대도 가능한 그래픽 프로세서를 예시한다. 따라서, 본 명세서에서 그래픽 프로세서와 조합된 임의의 특징부들 의 개시내용도 그래픽 프로세서와의 대응하는 조합을 개시하지만, 이에 제한되지 않는다. 그래픽 프로세 서는 본 명세서에 설명된 실시예들에 따른 타일형 아키텍처를 갖는다. 그래픽 프로세서는 그래픽 엔진 타일(1610A-1610D) 내에 도 16a의 그래픽 프로세싱 엔진의 다수의 인스턴스를 갖는 그래픽 프로세싱 엔진 클러스터를 포함할 수 있다. 각각의 그래픽 엔진 타일(1610A-1610D)은 타일 인터커넥트들(1623A- 1623F)의 세트를 통해 상호접속될 수 있다. 각각의 그래픽 엔진 타일(1610A-1610D)은 또한 메모리 인터커넥트 들(1625A-1625D)을 통해 메모리 모듈 또는 메모리 디바이스(1626A-1626D)에 접속될 수 있다. 메모리 디바이스 들(1626A-1626D)은 임의의 그래픽 메모리 기술을 사용할 수 있다. 예를 들어, 메모리 디바이스들(1626A- 1626D)은 그래픽 더블 데이터 레이트(graphics double data rate)(GDDR) 메모리일 수 있다. 메모리 디바이스 들(1626A-1626D)은 그들 각각의 그래픽 엔진 타일(1610A-1610D)과 온-다이일 수 있는 고대역폭 메모리(HBM) 모 듈들일 수 있다. 메모리 디바이스들(1626A-1626D)은 그들 각각의 그래픽 엔진 타일(1610A-1610D)의 상부에 적 층될 수 있는 스택형 메모리 디바이스들일 수 있다. 각각의 그래픽 엔진 타일(1610A-1610D) 및 연관된 메모리 (1626A-1626D)는 도 24b 내지 도 24d에서 더 상세히 설명되는 바와 같이, 베이스 다이 또는 베이스 기판에 본딩 되는 별개의 칩렛들 상에 상주할 수 있다. 그래픽 프로세서는 메모리 디바이스들(1626A-1626D)이 연관된 그래픽 엔진 타일(1610A-1610D)과 결합되는 비-균일성 메모리 액세스(NUMA) 시스템으로 구성될 수 있다. 주어진 메모리 디바이스는 그것이 직접 접속되는 타일 이외에 그래픽 엔진 타일들에 의해 액세스될 수 있다. 그러나, 메모리 디바이스들(1626A-1626D)에 대한 액세스 레이턴시는 로컬 타일에 액세스할 때 최저일 수 있다. 일 실시예에서, 하나보다 많은 캐시가 동일한 메 모리 위치를 저장할 때 일관된 메모리 이미지를 유지하기 위해 그래픽 엔진 타일들(1610A-1610D) 내의 캐시 컨 트롤러들 사이의 통신을 가능하게 하기 위해 타일 인터커넥트들(1623A-1623F)을 사용하는 캐시 코히어런트 NUMA(ccNUMA) 시스템이 인에이블된다.-42-그래픽 프로세싱 엔진 클러스터는 온-칩 또는 온-패키지 패브릭 인터커넥트와 접속될 수 있다. 일 실시예에서, 패브릭 인터커넥트는 네트워크 프로세서, NoC(network on a chip), 또는 패브릭 인터커넥트 가 그래픽 프로세서의 컴포넌트들 사이에서 데이터 패킷들을 스위칭하는 패킷 스위칭형 패브릭 인 터커넥트로서 기능할 수 있게 해주는 다른 스위칭 프로세서를 포함한다. 패브릭 인터커넥트는 그래픽 엔 진 타일들(1610A-1610D)과, 비디오 코덱 엔진 및 하나 이상의 복사 엔진과 같은 컴포넌트들 사이의 통신을 가능하게 할 수 있다. 복사 엔진들은 메모리 디바이스들(1626A-1626D)과 그래픽 프로세서 의 외부에 있는 메모리(예를 들어, 시스템 메모리)로부터, 그것들 내로, 그리고 그것들 사이에서 데이터를 이동 시키기 위해 사용될 수 있다. 패브릭 인터커넥트는 또한, 그래픽 엔진 타일(1610A-1610D)을 인터커넥트 하기 위해 사용될 수 있다. 그래픽 프로세서는 외부 디스플레이 디바이스와의 접속을 가능하게 하 는 디스플레이 컨트롤러를 선택적으로 포함할 수 있다. 그래픽 프로세서는 또한 그래픽 또는 계산 가속 기로서 구성될 수 있다. 가속기 구성에서, 디스플레이 컨트롤러 및 디스플레이 디바이스는 생략될 수 있다. 그래픽 프로세서는 호스트 인터페이스를 통해 호스트 시스템에 접속할 수 있다. 호스트 인터페이 스는 그래픽 프로세서, 시스템 메모리, 및/또는 다른 시스템 컴포넌트들 사이의 통신을 가능하게 할 수 있다. 호스트 인터페이스는, 예를 들어, PCI 익스프레스 버스 또는 다른 타입의 호스트 시스템 인 터페이스일 수 있다. 예를 들어, 호스트 인터페이스는 NVLink 또는 NVSwitch 인터페이스일 수 있다. 호 스트 인터페이스 및 패브릭 인터커넥트는 그래픽 프로세서의 다수의 인스턴스가 단일 로직 디바이스로서 기능할 수 있게 하기 위해 협력할 수 있다. 호스트 인터페이스와 패브릭 인터커넥트 사이의 협력은 또한 개별 그래픽 엔진 타일들(1610A 내지 1610D)이 별개의 논리적 그래픽 디바이스들로서 호스 트 시스템에 제시될 수 있게 할 수 있다. 도 16c는 본 명세서에 설명된 실시예들에 따른 계산 가속기를 예시한다. 계산 가속기는 도 16b의 그래픽 프로세서와의 아키텍처 유사성들을 포함할 수 있고, 계산 가속을 위해 최적화된다. 계산 엔진 클 러스터는 병렬 또는 벡터 기반 범용 계산 연산들에 대해 최적화되는 실행 로직을 포함하는 계산 엔진 타 일들(1640A-1640D)의 세트를 포함할 수 있다. 계산 엔진 타일들(1640A-1640D)은 고정 함수 그래픽 프로세싱 로 직을 포함하지 않을 수 있지만, 일부 실시예들에서 계산 엔진 타일들(1640A-1640D) 중 하나 이상은 미디어 가속 을 수행하기 위한 로직을 포함할 수 있다. 계산 엔진 타일들(1640A-1640D)은 메모리 인터커넥트들(1625A- 1625D)을 통해 메모리(1626A-1626D)에 접속될 수 있다. 메모리(1626A-1626D) 및 메모리 인터커넥트들(1625A- 1625D)은 그래픽 프로세서에서와 유사한 기술일 수 있거나, 상이할 수 있다. 그래픽 계산 엔진 타일들 (1640A-1640D)은 또한 타일 인터커넥트들(1623A-1623F)의 세트를 통해 상호접속될 수 있고, 패브릭 인터커넥트 와 접속될 수 있고 및/또는 패브릭 인터커넥트에 의해 상호접속될 수 있다. 일 실시예에서, 계산 가속기는 디바이스-와이드 캐시(device-wide cache)로서 구성될 수 있는 큰 L3 캐시를 포함한다. 계산 가속기는 또한 도 16b의 그래픽 프로세서와 유사한 방식으로 호스트 인터페이스를 통해 호스트 프로세서 및 메모리에 접속될 수 있다. 계산 가속기는 또한 통합 네트워크 인터페이스를 포함할 수 있다. 일 실시예에서, 네트워크 인터 페이스는 계산 엔진 클러스터가 호스트 시스템의 메모리를 횡단할 데이터를 요구하지 않고 물리 층 인터커넥트를 통해 통신할 수 있게 하는 네트워크 프로세서 및 컨트롤러 로직을 포함한다. 일 실시예에 서, 계산 엔진 타일들(1640A-1640D) 중 하나는 네트워크 프로세서 로직에 의해 대체되고, 물리 층 인터커넥트 를 통해 송신 또는 수신될 데이터는 메모리(1626A-1626D)로 또는 그로부터 직접 송신될 수 있다. 계산 가속기의 다수의 인스턴스가 물리 층 인터커넥트를 통해 단일 로직 디바이스에 결합될 수 있다. 대안적으로, 다양한 계산 엔진 타일들(1640A-1640D)은 별개의 네트워크 액세스가능 계산 가속기 디바이스들로서 제시될 수 있다. 그래픽 프로세싱 엔진 도 17은 일부 실시예들에 따른 그래픽 프로세서의 그래픽 프로세싱 엔진의 블록도이다. 그래픽 프로세싱 엔진(GPE)은 도 16a에 도시된 GPE의 버전일 수 있고, 또한 도 16b의 그래픽 엔진 타일(1610A- 1610D)을 나타낼 수 있다. 본 명세서의 임의의 다른 도면의 요소들과 동일하거나 유사한 명칭들을 갖는 도 17 의 요소들은 다른 도면들에서와 동일한 요소들을 설명하고, 그와 유사한 방식으로 동작하거나 기능할 수 있고, 동일한 컴포넌트들을 포함할 수 있고, 본 명세서의 다른 곳에서 설명된 것들과 같이 다른 엔티티들에 링크될 수 있지만, 이에 한정되지 않는다. 예를 들어, 도 16a의 3D 파이프라인 및 미디어 파이프라인이 또한 도 17에 예시된다. 미디어 파이프라인은 GPE의 일부 실시예들에서 선택적이며, GPE 내에 명-43-시적으로 포함되지 않을 수 있다. 예를 들어, 적어도 하나의 실시예에서, 별개의 미디어 및/또는 이미지 프로 세서가 GPE에 결합된다. GPE는 커맨드 스트림을 3D 파이프라인 및/또는 미디어 파이프라인들에 제공하는 커맨드 스트 리머와 결합되거나 이를 포함할 수 있다. 대안적으로 또는 추가적으로, 커맨드 스트리머는 통합 리턴 버퍼에 직접 결합될 수 있다. 통합 리턴 버퍼는 그래픽 코어 어레이에 통신가능하게 결합될 수 있다. 선택적으로, 커맨드 스트리머는 시스템 메모리, 또는 내부 캐시 메모리 및 공유 캐시 메모리 중 하나 이상일 수 있는 메모리와 결합된다. 커맨드 스트리머는 메모리로부터 커맨드들을 수신하 고 커맨드들을 3D 파이프라인 및/또는 미디어 파이프라인으로 전송할 수 있다. 커맨드들은 3D 파 이프라인 및 미디어 파이프라인에 대한 커맨드들을 저장하는 링 버퍼로부터 페치된 지시어들이다. 링 버퍼는 다수의 커맨드의 배치(batch)들을 저장하는 배치 커맨드 버퍼들을 추가로 포함할 수 있다. 3D 파이 프라인에 대한 커맨드들은 또한 3D 파이프라인에 대한 정점 및 지오메트리 데이터 및/또는 미디어 파이프라인에 대한 이미지 데이터 및 메모리 객체들과 같은, 그러나 이에 제한되지 않는, 메모리에 저장 되는 데이터에 대한 참조들을 포함할 수 있다. 3D 파이프라인 및 미디어 파이프라인은 각자의 파 이프라인들 내의 로직을 통해 연산들을 수행함으로써 또는 하나 이상의 실행 스레드를 그래픽 코어 어레이 로 디스패치함으로써 커맨드들 및 데이터를 프로세싱한다. 그래픽 코어 어레이는 하나 이상의 그 래픽 코어 블록(예를 들어, 그래픽 코어(들)(1715A), 그래픽 코어(들)(1715B))을 포함할 수 있고, 각각의 블록 은 하나 이상의 그래픽 코어를 포함한다. 각각의 그래픽 코어는 그래픽 및 계산 연산들을 수행하기 위한 범용 및 그래픽 특정 실행 로직뿐만 아니라, 고정 함수 텍스처 프로세싱 및/또는 머신 러닝 및 인공 지능 가속 로직 을 포함하는 그래픽 실행 자원들의 세트를 포함한다. 다양한 실시예들에서, 3D 파이프라인은 명령어들을 프로세싱하고 실행 스레드들을 그래픽 코어 어레이 에 디스패치함으로써, 정점 셰이더들, 지오메트리 셰이더들, 픽셀 셰이더들, 프래그먼트 셰이더들, 계산 셰이더들, 또는 다른 셰이더 프로그램들과 같은 하나 이상의 셰이더 프로그램을 프로세싱하기 위한 고정 함수 및 프로그램가능 로직을 포함할 수 있다. 그래픽 코어 어레이는 이러한 셰이더 프로그램들을 프로세싱하 기 위해 사용하기 위한 통합된 실행 자원 블록을 제공한다. 그래픽 코어 어레이의 그래픽 코어 (들)(1715A-1715B) 내의 다목적 실행 로직(예를 들어, 실행 유닛들)은 다양한 3D API 셰이더 언어들에 대한 지 원을 포함하고, 다수의 셰이더와 연관된 다수의 동시 실행 스레드를 실행할 수 있다. 그래픽 코어 어레이는 비디오 및/또는 이미지 프로세싱과 같은 미디어 기능들을 수행하는 실행 로직을 포 함할 수 있다. 실행 유닛들은 그래픽 프로세싱 연산들에 더하여 병렬 범용 계산 연산들을 수행하도록 프로그램 가능한 범용 로직을 포함할 수 있다. 범용 로직은 도 14의 프로세서 코어(들) 또는 도 15a에서와 같은 코어(1502A-1502N) 내의 범용 로직과 병렬로 또는 그와 함께 프로세싱 연산들을 수행할 수 있다. 그래픽 코어 어레이 상에서 실행되는 스레드들에 의해 생성된 출력 데이터는 통합 리턴 버퍼(URB) 에서의 메모리에 데이터를 출력할 수 있다. URB는 다수의 스레드에 대한 데이터를 저장할 수 있다. URB는 그래픽 코어 어레이 상에서 실행되는 상이한 스레드들 사이에서 데이터를 전송하기 위해 사 용될 수 있다. URB는 그래픽 코어 어레이 상의 스레드들과 공유 함수 로직 내의 고정 함수 로직 사이의 동기화를 위해 추가적으로 사용될 수 있다. 선택적으로, 그래픽 코어 어레이는, 어레이가 가변 개수의 그래픽 코어를 포함하도록 스케일링가능할 수 있고, 각각의 그래픽 코어는 GPE의 성능 레벨 및 타겟 전력에 기초하여 가변 개수의 실행 유닛을 갖는다. 실행 자원들은 동적으로 스케일링가능할 수 있어서, 실행 자원들은 필요에 따라 인에이블 또는 디스에이블될 수 있다. 그래픽 코어 어레이는 그래픽 코어 어레이 내의 그래픽 코어들 사이에 공유되는 다수의 자원을 포함하는 공유 함수 로직과 결합한다. 공유 함수 로직 내의 공유 함수들은 그래픽 코어 어레이에 특 수화된 보충 기능을 제공하는 하드웨어 로직 유닛들이다. 다양한 실시예들에서, 공유 함수 로직은 샘플 러, 수학 및 인터-스레드 통신(ITC) 로직을 포함하지만, 이에 한정되지 않는다. 추가적으로, 공유 함수 로직 내의 하나 이상의 캐시(들)가 구현될 수 있다. 공유 함수는 적어도, 주어진 특수화된 함수에 대한 요구가 그래픽 코어 어레이 내에 포함하기에 불충분한 경우에 구현된다. 대신에, 그 특수화된 함수의 단일 인스턴스화는 공유 함수 로직에서의 독립형 엔티티 로서 구현되고 그래픽 코어 어레이 내의 실행 자원들 사이에서 공유된다. 그래픽 코어 어레이 사 이에 공유되고 그래픽 코어 어레이 내에 포함되는 정확한 함수 세트는 실시예들에 걸쳐 변동된다. 그래-44-픽 코어 어레이에 의해 광범위하게 사용되는 공유 함수 로직 내의 특정 공유 함수들은 그래픽 코어 어레이 내의 공유 함수 로직 내에 포함될 수 있다. 선택적으로, 그래픽 코어 어레이 내의 공유 함수 로직은 공유 함수 로직 내의 일부 또는 모든 로직을 포함할 수 있다. 공유 함수 로직 내의 모든 로직 요소들은 그래픽 코어 어레이의 공유 함수 로직 내에 복제될 수 있다. 대 안적으로, 공유 함수 로직은 그래픽 코어 어레이 내의 공유 함수 로직을 위해 배제된다. 실행 유닛들 도 18a 및 도 18b는 본 명세서에 설명된 실시예들에 따른 그래픽 프로세서 코어에서 이용되는 프로세싱 요소들 의 어레이를 포함하는 스레드 실행 로직을 예시한다. 본 명세서의 임의의 다른 도면의 요소들과 동일하 거나 유사한 명칭들을 갖는 도 18a 및 도 18b의 요소들은 다른 도면들에서와 동일한 요소들을 설명하고, 본 명 세서의 다른 곳에서 설명된 것들과 같이 그와 유사한 방식으로 동작하거나 기능할 수 있고, 동일한 컴포넌트들 을 포함할 수 있고, 다른 엔티티들에 링크될 수 있지만, 이에 한정되지 않는다. 도 18a 및 도 18b는, 도 15b의 각각의 서브코어(1521A-1521F)로 예시된 하드웨어 로직을 나타낼 수 있는, 스레드 실행 로직의 개요를 예 시한다. 도 18a는 범용 그래픽 프로세서 내의 실행 유닛을 나타내는 반면, 도 18b는 계산 가속기 내에서 사용 될 수 있는 실행 유닛을 나타낸다. 도 18a에 예시된 바와 같이, 스레드 실행 로직은 셰이더 프로세서, 스레드 디스패처, 명령어 캐시, 복수의 그래픽 실행 유닛(1808A-1808N)을 포함하는 스케일링가능 실행 유닛 어레이, 샘플러, 공유 로컬 메모리, 데이터 캐시, 및 데이터 포트를 포함할 수 있다. 선택적으로, 스케일링 가능 실행 유닛 어레이는 작업부하의 계산 요건들에 기초하여 하나 이상의 실행 유닛(예를 들어, 그래픽 실행 유닛들(1808A, 1808B, 1808C, 1808D 내지 1808N-1 및 1808N) 중 임의의 것)을 인에이블 또는 디스에이블함으로 써 동적으로 스케일링될 수 있다. 포함된 컴포넌트들은 컴포넌트들 각각에 링크되는 인터커넥트 패브릭을 통해 상호접속될 수 있다. 스레드 실행 로직은 명령어 캐시, 데이터 포트, 샘플러, 및 그 래픽 실행 유닛들(1808A-1808N) 중 하나 이상을 통한, 시스템 메모리 또는 캐시 메모리와 같은, 메모리에 대한 하나 이상의 접속을 포함할 수 있다. 각각의 실행 유닛(예를 들어, 1808A)은 각각의 스레드에 대해 다수의 데 이터 요소를 병렬로 프로세싱하면서 다수의 동시 하드웨어 스레드를 실행할 수 있는 독립형 프로그램가능 범용 계산 유닛일 수 있다. 다양한 실시예들에서, 실행 유닛들(1808A-1808N)의 어레이는 임의의 수의 개별 실행 유 닛을 포함하도록 스케일링가능하다. 일부 실시예들에서, 그래픽 실행 유닛들(1808A-1808N)은 주로 셰이더 프로그램들을 실행하기 위해 사용될 수 있 다. 셰이더 프로세서는 다양한 셰이더 프로그램들을 프로세싱하고 스레드 디스패처를 통해 셰이더 프로그램들과 연관된 실행 스레드들을 디스패치할 수 있다. 스레드 디스패처는 그래픽 및 미디어 파이프라인들 로부터의 스레드 개시 요청들을 중재하고 그래픽 실행 유닛들(1808A-1808N) 내의 하나 이상의 실행 유닛 상에서 요청된 스레드들을 인스턴스화하기 위한 로직을 포함할 수 있다. 예를 들어, 지오메트리 파이프라인은 정점, 테셀레이션, 또는 지오메트리 셰이더들을 프로세싱을 위해 스레드 실행 로직으로 디스패치할 수 있다. 선택적 으로, 스레드 디스패처는 또한 실행 중인 셰이더 프로그램들로부터의 런타임 스레드 스포닝 요청들을 프 로세싱할 수 있다. 일부 실시예들에서, 그래픽 실행 유닛들(1808A-1808N)은, 그래픽 라이브러리들로부터의 셰이더 프로그램들(예를 들어, Direct 3D 및 OpenGL)이 최소한의 변환으로 실행되도록, 많은 표준 3D 그래픽 셰이더 명령어들에 대한 네 이티브 지원(native support)을 포함하는 명령어 세트를 지원할 수 있다. 실행 유닛들은 정점 및 지오메트리 프로세싱(예를 들어, 정점 프로그램들, 지오메트리 프로그램들, 정점 셰이더들), 픽셀 프로세싱(예를 들어, 픽 셀 셰이더들, 프래그먼트 셰이더들) 및 범용 프로세싱(예를 들어, 계산 및 미디어 셰이더들)을 지원한다. 그래 픽 실행 유닛들(1808A-1808N) 각각은 SIMD(multi-issue single instruction multiple data) 실행을 할 수 있고, 멀티-스레드 동작은 더 높은 레이턴시 메모리 액세스들에 직면하여 효율적인 실행 환경을 가능하게 한다. 각각의 실행 유닛 내의 각각의 하드웨어 스레드는 전용 고-대역폭 레지스터 파일 및 연관된 독립적 스레드-상태 를 갖는다. 실행은 정수, 단정밀도 및 배정밀도 부동 소수점 연산들, SIMD 분기 능력, 로직 연산들, 초월 연산 들(transcendental operations), 및 다른 기타 연산들이 가능한 파이프라인들에 대한 클록당 다중-발행(multi- issue per clock)이다. 메모리 또는 공유 함수들 중 하나로부터의 데이터를 대기하는 동안, 실행 유닛들 (1808A-1808N) 내의 의존성 로직은 요청된 데이터가 리턴될 때까지 대기 스레드가 슬립하게 한다. 대기 스레드 가 슬립하고 있는 동안, 하드웨어 자원들은 다른 스레드들을 프로세싱하는데 충당될 수 있다. 예를 들어, 정점 셰이더 연산과 연관된 지연 동안, 실행 유닛은 픽셀 셰이더, 프래그먼트 셰이더, 또는 도 21에 예시된 정점 셰 이더와 같은 상이한 정점 셰이더를 포함하는 다른 타입의 셰이더 프로그램에 대한 연산들을 수행할 수 있-45-다. 다양한 실시예들은 SIMD의 사용에 대한 대안으로서 또는 SIMD의 사용에 더하여 SIMT(Single Instruction Multiple Thread)의 사용에 의해 실행을 사용하기 위해 적용될 수 있다. SIMD 코어 또는 연산에 대한 참조는 SIMT에도 적용될 수 있거나, SIMT와 조합하여 SIMD에도 적용될 수 있다. 그래픽 실행 유닛들(1808A-1808N) 내의 각각의 실행 유닛은 데이터 요소들의 어레이들에 대해 동작한다. 데이 터 요소들의 수는 \"실행 크기\" 또는 명령어에 대한 채널들의 수이다. 실행 채널은 명령어들 내에서의 데이터 요소 액세스, 마스킹, 및 흐름 제어를 위한 실행의 로직 유닛이다. 채널들의 수는 특정 그래픽 프로세서에 대 한 물리적 산술 로직 유닛(ALU)들, 부동 소수점 유닛(FPU)들, 또는 다른 로직 유닛들(예를 들어, 텐서 코어들, 광선-추적 코어들 등)의 수와 독립적일 수 있다. 추가적으로, 그래픽 실행 유닛(1808A-1808N)은 정수 및 부동 소수점 데이터 타입들을 지원할 수 있다. 실행 유닛 명령어 세트는 SIMD 명령어들을 포함한다. 다양한 데이터 요소들은 패킹된 데이터 타입으로서 레지 스터에 저장될 수 있고, 실행 유닛은 요소들의 데이터 크기에 기초하여 다양한 요소들을 프로세싱할 것이다. 예를 들어, 256-비트 폭 벡터 상에서 동작할 때, 256-비트의 벡터는 레지스터에 저장되고, 실행 유닛은 4개의 개별 184-비트 패킹된 데이터 요소(쿼드-워드(QW) 크기 데이터 요소들), 8개의 개별 32-비트 패킹된 데이터 요 소들(더블 워드(DW) 크기 데이터 요소들), 16개의 개별 16-비트 패킹된 데이터 요소들(워드(W) 크기 데이터 요 소들), 또는 32개의 개별 8-비트 데이터 요소들(바이트(B) 크기 데이터 요소들)로서의 벡터 상에서 동작한다. 그러나, 상이한 벡터 폭들 및 레지스터 크기들이 가능하다. 선택적으로, 하나 이상의 실행 유닛은 융합된 EU들에 공통인 스레드 제어 로직(1807A-1807N)을 갖는 융합된 그 래픽 실행 유닛(1809A-1809N)으로 조합될 수 있다. 다수의 EU는 EU 그룹으로 융합될 수 있다. 융합된 EU 그룹 내의 각각의 EU는 별개의 SIMD 하드웨어 스레드를 실행하도록 구성될 수 있다. 융합된 EU 그룹 내의 EU들의 수 는 실시예들에 따라 변동될 수 있다. 추가적으로, SIMD8, SIMD16 및 SIMD32를 포함하지만 이에 한정되지 않는 다양한 SIMD 폭들이 EU마다(per-EU) 수행될 수 있다. 각각의 융합된 그래픽 실행 유닛(1809A-1809N)은 적어도 2개의 실행 유닛을 포함한다. 예를 들어, 융합된 실행 유닛(1809A)은 제1 EU(1808A), 제2 EU(1808B), 및 제1 EU(1808A) 및 제2 EU(1808B)에 공통인 스레드 제어 로직(1807A)을 포함한다. 스레드 제어 로직(1807A)은 융합 된 그래픽 실행 유닛(1809A) 상에서 실행되는 스레드들을 제어하여, 융합된 실행 유닛들(1809A-1809N) 내의 각 각의 EU가 공통 명령어 포인터 레지스터를 사용하여 실행할 수 있게 한다. 실행 유닛들에 대한 스레드 명령어들을 캐싱하기 위해 하나 이상의 내부 명령어 캐시(예를 들어, 1806)가 스레 드 실행 로직에 포함된다. 스레드 실행 동안 스레드 데이터를 캐싱하기 위해 하나 이상의 데이터 캐시 (예를 들어, 1812)가 스레드 실행 로직에 포함될 수 있다. 실행 로직 상에서 실행되는 스레드들은 또한 명시적으로 관리되는 데이터를 공유 로컬 메모리에 저장할 수 있다. 샘플러는 3D 연산들에 대한 텍스처 샘플링 및 미디어 연산들에 대한 미디어 샘플링을 제공하기 위해 포함될 수 있다. 샘플러는 샘플링된 데이터를 실행 유닛에 제공하기 전에 샘플링 프로세스 동안 텍스처 또는 미디어 데이터를 프로세싱하 기 위해 특수화된 텍스처 또는 미디어 샘플링 기능을 포함할 수 있다. 실행 동안, 그래픽 및 미디어 파이프라인들은 스레드 스포닝 및 디스패치 로직을 통해 스레드 개시 요청들을 스 레드 실행 로직으로 전송한다. 일단 지오메트릭 객체들의 그룹이 프로세싱되고 픽셀 데이터로 래스터화 되면, 셰이더 프로세서 내의 픽셀 프로세서 로직(예를 들어, 픽셀 셰이더 로직, 프래그먼트 셰이더 로직 등)이 호출되어 출력 정보를 추가로 계산하고 결과들이 출력 표면(output surface)들(예를 들어, 컬러 버퍼들, 깊이 버퍼들, 스텐실 버퍼들 등)에 기입되게 한다. 픽셀 셰이더 또는 프래그먼트 셰이더는 래스터화된 객체에 걸쳐 보간될 다양한 정점 속성들의 값들을 계산할 수 있다. 그 후, 셰이더 프로세서 내의 픽셀 프로세서 로직은 애플리케이션 프로그래밍 인터페이스(API)-공급 픽셀 또는 프래그먼트 셰이더 프로그램을 실행할 수 있 다. 셰이더 프로그램을 실행하기 위해, 셰이더 프로세서는 스레드들을 스레드 디스패처를 통해 실 행 유닛(예를 들어, 1808A)에 디스패치한다. 셰이더 프로세서는 샘플러에서의 텍스처 샘플링 로직 을 사용하여 메모리에 저장된 텍스처 맵들에서의 텍스처 데이터에 액세스할 수 있다. 텍스처 데이터 및 입력 지오메트리 데이터에 대한 산술 연산들은 각각의 지오메트릭 프래그먼트에 대한 픽셀 컬러 데이터를 계산하거나, 추가 프로세싱으로부터 하나 이상의 픽셀을 폐기한다. 추가적으로, 데이터 포트는 그래픽 프로세서 출력 파이프라인 상에서의 추가 프로세싱을 위해 프로세싱된 데이터를 메모리에 출력하기 위한 스레드 실행 로직에 대한 메모리 액세스 메커니즘을 제공할 수 있다. 데이터 포트는 데이터 포트를 통한 메모리 액세스를 위한 데이터를 캐싱하기 위해 하나 이상의 캐 시 메모리(예를 들어, 데이터 캐시)를 포함하거나 그에 결합될 수 있다.-46-선택적으로, 실행 로직은 또한 광선-추적 가속 기능을 제공할 수 있는 광선 추적기를 포함할 수 있 다. 광선 추적기는 광선 생성을 위한 명령어들/함수들을 포함하는 광선-추적 명령어 세트를 지원할 수 있다. 광선-추적 명령어 세트는 도 3c의 광선-추적 코어들에 의해 지원되는 광선-추적 명령어 세트와 유 사하거나 상이할 수 있다. 도 18b는 실행 유닛의 예시적인 내부 상세들을 예시한다. 그래픽 실행 유닛은 명령어 페치 유닛 , GRF(general register file array), ARF(architectural register file array), 스레드 아비터(thread arbiter), 전송 유닛, 분기 유닛, SIMD FPU(floating point unit)들의 세트 , 및 선택적으로 전용 정수 SIMD ALU들의 세트를 포함할 수 있다. GRF 및 ARF는 그 래픽 실행 유닛에서 활성일 수 있는 각각의 동시 하드웨어 스레드와 연관된 일반 레지스터 파일들 및 아 키텍처 레지스터 파일들의 세트를 포함한다. 스레드당 아키텍처 상태는 ARF에 유지될 수 있는 반면, 스 레드 실행 동안 사용되는 데이터는 GRF에 저장된다. 각각의 스레드에 대한 명령어 포인터들을 포함하는 각각의 스레드의 실행 상태는 ARF 내의 스레드-특정 레지스터들에 유지될 수 있다. 그래픽 실행 유닛은 SMT(Simultaneous Multi-Threading)와 미세한 입도의(fine-grained) IMT(Interleaved Multi-Threading)의 조합인 아키텍처를 가질 수 있다. 아키텍처는 실행 유닛당 레지스터들의 수 및 동시 스레드들의 타겟 수에 기초하여 디자인 타임(design time)에서 미세 조정될 수 있는 모듈러 구성을 가질 수 있으며, 여기서 실행 유닛 자원들은 다수의 동시 스레드를 실행하기 위해 사용되는 로직에 걸쳐 분할된 다. 그래픽 실행 유닛에 의해 실행될 수 있는 논리적 스레드들의 수는 하드웨어 스레드들의 수에 제한되 지 않으며, 다수의 논리적 스레드가 각각의 하드웨어 스레드에 할당될 수 있다. 선택적으로, 그래픽 실행 유닛은, 각각이 상이한 명령어들일 수 있는, 다수의 명령어를 공동 발행할 수 있다. 그래픽 실행 유닛 스레드의 스레드 아비터는 실행을 위해 전송 유닛, 분기 유닛 , 또는 SIMD FPU(들) 중 하나에 명령어들을 디스패치할 수 있다. 각각의 실행 스레드는 GRF 내의 128개의 범용 레지스터에 액세스할 수 있으며, 각각의 레지스터는 32-비트 데이터 요소들의 SIMD 8-요소 벡터로서 액세스가능한 32-바이트를 저장할 수 있다. 각각의 실행 유닛 스레드는 GRF 내의 4 킬로바이트에 액세스할 수 있지만, 실시예들은 그렇게 제한되지 않으며, 다른 실시예들에서는 더 많거나 더 적은 레지스터 자원들이 제공될 수 있다. 그래픽 실행 유닛은 계산 연산들을 독립적으로 수행할 수 있는 7개의 하드웨어 스레드로 파티셔닝될 수 있지만, 실행 유닛당 스레드들의 수는 또한 실시예들에 따라 변동될 수 있는데, 예를 들어, 최대 16개의 하드웨어 스레드가 지원될 수 있다. 7개의 스레드가 4 킬로바이트에 액세스할 수 있는 예시적인 실시예에서, GRF는 총 28 킬로바이트를 저장할 수 있다. 16개의 스레드가 4 킬로바이 트에 액세스할 수 있는 다른 예시적인 실시예에서, GRF는 총 64 킬로바이트를 저장할 수 있다. 그러나, 실행 유닛당 스레드들의 수는 그러한 예들에 한정되지 않으며, 주어진 수들보다 많거나 적을 수 있다. 융통성 있는 어드레싱 모드들은 효과적으로 더 넓은 레지스터들을 구축하거나 스트라이드형(strided) 직사각형 블록 데 이터 구조들을 표현하기 위해 레지스터들이 함께 어드레싱되는 것을 허용할 수 있다. 추가적으로 또는 대안적으로, 메모리 동작들, 샘플러 동작들, 및 다른 더 긴-레이턴시 시스템 통신들은 메시지 전달 전송 유닛에 의해 실행되는 \"전송\" 명령어들을 통해 디스패치될 수 있다. 분기 명령어들은 SIMD 발 산 및 최종 수렴을 용이하게 하기 위해 전용 분기 유닛으로 디스패치될 수 있다. 그래픽 실행 유닛은 부동 소수점 연산들을 수행하기 위해 하나 이상의 SIMD 부동 소수점 유닛(FPU (들))을 포함할 수 있다. FPU(들)는 또한 정수 계산을 지원할 수 있다. 일부 경우들에서, FPU(들)는 최대 M개의 32-비트 부동 소수점(또는 정수) 연산을 SIMD 실행(SIMD execute)하거나, 최대 2M 개의 16-비트 정수 또는 16-비트 부동 소수점 연산을 SIMD 실행할 수 있다. 선택적으로, FPU(들) 중 적어도 하 나는 고-스루풋 초월 수학 함수들 및 배정밀도 184-비트 부동 소수점을 지원하는 확장된 수학 능력을 제공한다. 8-비트 정수 SIMD ALU들의 세트가 또한 존재할 수 있고, 머신 러닝 계산들과 연관된 연산들을 수행하도록 구체적으로 최적화될 수 있다. 선택적으로, 그래픽 실행 유닛의 다수의 인스턴스의 어레이는 그래픽 서브-코어 그룹화(예를 들어, 서브- 슬라이스)에서 인스턴스화될 수 있다. 스케일링가능성을 위해, 제품 아키텍처들은 서브-코어 그룹화당 정확한 수의 실행 유닛을 선택할 수 있다. 실행 유닛은 복수의 실행 채널에 걸쳐 명령어들을 실행할 수 있다. 추가적으로, 그래픽 실행 유닛 상에서 실행되는 각각의 스레드가 상이한 채널에서 실행될 수 있다. 도 19는 추가의 예시적인 실행 유닛을 예시한다. 본 명세서의 임의의 다른 도면의 요소들과 동일하거나 유사한 명칭들을 갖는 도 19의 요소들은 다른 도면들에서와 동일한 요소들을 설명하고, 그와 유사한 방식으로-47-동작하거나 기능할 수 있고, 동일한 컴포넌트들을 포함할 수 있고, 본 명세서의 다른 곳에서 설명된 것들과 같 이 다른 엔티티들에 링크될 수 있지만, 이에 한정되지 않는다. 실행 유닛은 예를 들어, 도 16c에서와 같 이 계산 엔진 타일(1640A-1640D)에서 사용하기 위한 계산 최적화된 실행 유닛일 수 있지만 이에 한정되지 않는 다. 실행 유닛은 또한 도 16b에서와 같이 그래픽 엔진 타일(1610A-1610D)에서 사용될 수 있다. 실행 유 닛은 스레드 제어 유닛, 스레드 상태 유닛, 명령어 페치/프리페치 유닛, 및 명령어 디 코드 유닛을 포함할 수 있다. 실행 유닛은 실행 유닛 내의 하드웨어 스레드들에 할당될 수 있는 레지스터들을 저장하는 레지스터 파일을 추가로 포함할 수 있다. 실행 유닛은 전송 유닛 및 분기 유닛을 추가로 포함할 수 있다. 전송 유닛 및 분기 유닛은 도 18b의 그래픽 실행 유닛 의 전송 유닛 및 분기 유닛과 유사하게 동작할 수 있다. 실행 유닛은 또한 다수의 상이한 타입의 함수 유닛들을 포함하는 계산 유닛을 포함할 수 있다. 계 산 유닛은 또한 ALU, 시스톨릭 어레이 및 수학 유닛을 포함할 수 있다. ALU는 산술 로직 유닛들의 어레이를 포함한다. ALU는 다수의 프로세싱 레인 및 데이터 채널에 걸쳐 그리고 다 수의 하드웨어 및/또는 소프트웨어 스레드에 대해 64-비트, 32-비트, 및 16-비트 정수 및 부동 소수점 연산들을 수행하도록 구성될 수 있다. ALU는 정수 및 부동 소수점 연산들을 동시에(예를 들어, 동일한 클록 사이 클 내에서) 수행할 수 있다. 시스톨릭 어레이는 시스톨릭 방식으로 벡터 또는 다른 데이터-병렬 연산들을 수행하기 위해 사용될 수 있 는 데이터 프로세싱 유닛들의 W 와이드(wide) 및 D 딥(deep) 네트워크를 포함한다. 시스톨릭 어레이는 내적, 외적, 및 일반 행렬-행렬 곱셈(GEMM) 연산들을 포함하는 다양한 행렬 연산들을 수행하도록 구성될 수 있 다. 시스톨릭 어레이는 16-비트 부동 소수점 연산들뿐만 아니라, 8-비트, 4-비트, 2-비트 및 이진 정수 연산들을 지원할 수 있다. 시스톨릭 어레이는 머신 러닝 연산들을 가속화하도록 구성될 수 있다. 시스 톨릭 어레이는 IEEE(Institute of Electrical and Electronics Engineers) 754 포맷들에 대해 상이한 수 의 가수 및 지수 비트를 갖는 bfloat16, 즉 (브레인 부동 소수점(brain floating point)) 16-비트 부동 소수점 포맷 또는 텐서 부동 32-비트 부동 소수점 포맷(TF32)에 대한 지원과 함께 구성될 수 있다. FP64 포맷들이 또 한 지원될 수 있다. 일 실시예에서, 시스톨릭 어레이는 희소 행렬 연산들을 가속화하기 위한 하드웨어를 포함한다. 입력 데 이터의 희소 영역들에 대한 곱셈 연산들은 스루풋을 희생하지 않고 바이패스될 수 있다. 입력 행렬들 내의 블 록 희소성이 검출될 수 있고, 알려진 출력 값들을 갖는 연산들이 바이패스될 수 있다. 일 실시예에서, 시스톨 릭 어레이는 압축된 표현을 갖는 희소 데이터에 대한 연산들을 가능하게 하기 위한 하드웨어를 포함한다. 희소 행렬의 압축된 표현은 행렬 내의 논-제로 값들의 위치를 정의하는 메타데이터 및 논-제로 값들을 저장한다. 예시적인 압축된 표현들은 CSR(compressed sparse row), CSC(compressed sparse column), CSF(compressed sparse fiber) 표현들과 같은 압축된 텐서 표현들을 포함하지만 이들로 제한되지 않는다. 압축 된 표현들에 대한 지원은 압축된 표현이 압축해제되거나 디코딩될 것을 요구하지 않고 압축된 텐서 포맷으로 입 력에 대해 연산들이 수행될 수 있게 한다. 이러한 실시예에서, 연산들은 논-제로 입력 값들에 대해서만 수행될 수 있고 결과적인 논-제로 출력 값들은 출력 행렬에 매핑될 수 있다. 일부 실시예들에서, 하드웨어 내에서 또 는 시스템 버스들에 걸쳐 데이터를 송신할 때 사용되는 머신-특정 무손실 데이터 압축 포맷들에 대한 하드웨어 지원이 또한 제공된다. 이러한 데이터는 희소 입력 데이터에 대해 압축된 포맷으로 보유될 수 있고, 시스톨릭 어레이는 압축된 데이터에 대한 압축 메타데이터를 사용하여 연산들이 논-제로 값들에서만 수행될 수 있 게 하거나 제로 데이터 입력의 블록들이 곱셈 연산들에 대해 바이패스될 수 있게 할 수 있다. 수학 유닛은 ALU 유닛보다 효율적이고 더 낮은 전력 방식으로 수학 연산들의 특정 서브세트를 수행 하도록 구성될 수 있다. 수학 유닛은 설명된 다른 실시예들에 의해 제공되는 그래픽 프로세싱 엔진의 공 유 함수 로직에서 발견되는 수학 로직, 예를 들어, 도 17의 공유 함수 로직의 수학 로직을 포함할 수 있다. 수학 유닛은 32-비트 및 64-비트 부동 소수점 연산들을 수행하도록 구성될 수 있다. 스레드 제어 유닛은 실행 유닛 내에서의 스레드들의 실행을 제어하기 위한 로직을 포함한다. 스레드 제 어 유닛은 실행 유닛 내의 스레드들의 실행을 시작, 정지, 및 선점하기 위한 스레드 중재 로직을 포함할 수 있다. 스레드 상태 유닛은 실행 유닛 상에서 실행되도록 할당된 스레드들에 대한 스레 드 상태를 저장하기 위해 사용될 수 있다. 스레드 상태를 실행 유닛 내에 저장하는 것은 그러한 스레드 들이 차단되거나 유휴가 될 때 스레드들의 급속한 선점을 가능하게 한다. 명령어 페치/프리페치 유닛은 상위-레벨 실행 로직의 명령어 캐시(예를 들어, 도 18a에서와 같은 명령어 캐시)로부터 명령어들을 페치 할 수 있다. 명령어 페치/프리페치 유닛은 또한 현재 실행 중인 스레드들의 분석에 기초하여 명령어 캐-48-시에 로드될 명령어들에 대한 프리페치 요청들을 발행할 수 있다. 명령어 디코드 유닛은 계산 유닛들에 의해 실행될 명령어들을 디코딩하기 위해 사용될 수 있다. 명령어 디코드 유닛은 복합 명령어들을 구성 마이크로 연산들로 디코딩하기 위한 2차 디코더로서 사용될 수 있다. 실행 유닛은 실행 유닛 상에서 실행되는 하드웨어 스레드들에 의해 사용될 수 있는 레지스터 파일 을 추가로 포함한다. 레지스터 파일 내의 레지스터들은 실행 유닛의 계산 유닛 내의 다수의 동시 스레드를 실행하기 위해 사용되는 로직에 걸쳐 분할될 수 있다. 그래픽 실행 유닛에 의해 실행될 수 있는 논리적 스레드들의 수는 하드웨어 스레드들의 수로 제한되지 않고, 다수의 논리적 스레드가 각 각의 하드웨어 스레드에 할당될 수 있다. 레지스터 파일의 크기는 지원되는 하드웨어 스레드들의 수에 기초하여 실시예들에 따라 변동될 수 있다. 레지스터 리네이밍은 하드웨어 스레드들에 레지스터들을 동적으로 할당하기 위해 사용될 수 있다. 도 20은 그래픽 프로세서 명령어 포맷들을 예시하는 블록도이다. 그래픽 프로세서 실행 유닛들은 다수의 포맷의 명령어들을 갖는 명령어 세트를 지원한다. 실선 박스들은 일반적으로 실행 유닛 명령어에 포함되는 컴 포넌트들을 예시하는 한편, 파선들은 선택적이거나 명령어들의 서브세트에만 포함되는 컴포넌트들을 포함한다. 일부 실시예들에서, 설명되고 예시된 그래픽 프로세서 명령어 포맷들은 일단 명령어가 프로세싱되면 명령 어 디코드로부터 생기는 마이크로-연산들과 대조적으로, 그것들이 실행 유닛에 공급되는 명령어들이라는 점에서 매크로-명령어들이다. 따라서, 단일 명령어들은 하드웨어로 하여금 다수의 마이크로-연산을 수행하게 할 수 있 다. 본 명세서에 설명된 것과 같은 그래픽 프로세서 실행 유닛들은 128-비트 명령어 포맷의 명령어들을 네이 티브 지원(natively support)할 수 있다. 선택된 명령어, 명령어 옵션들 및 피연산자들의 수에 기초한 일부 명 령어들에 대해 64-비트 압축된 명령어 포맷이 이용가능하다. 네이티브 128-비트 명령어 포맷은 모 든 명령어 옵션들에 대한 액세스를 제공하는 반면, 일부 옵션들 및 동작들은 64-비트 포맷으로 제한된다. 64-비트 포맷에서 이용가능한 네이티브 명령어들은 실시예에 따라 다르다. 이 명령어는 인덱스 필드 내의 인덱스 값 세트를 사용하여 부분적으로 압축된다. 실행 유닛 하드웨어는 인덱스 값들에 기초하여 압축 테이블들의 세트를 참조하고, 압축 테이블 출력들을 사용하여 128-비트 명령어 포맷으로 네이티브 명령어를 재구성한다. 명령어의 다른 크기들 및 포맷들이 사용될 수 있다. 각각의 포맷에 대해, 명령어 오피코드(instruction opcode)는 실행 유닛이 수행할 연산을 정의한다. 실 행 유닛들은 각각의 피연산자의 다수의 데이터 요소에 걸쳐 병렬로 각각의 명령어를 실행한다. 예를 들어, add 명령어에 응답하여, 실행 유닛은 텍스처 요소 또는 픽처 요소를 나타내는 각각의 컬러 채널에 걸쳐 동시 덧셈 연산을 수행한다. 디폴트로, 실행 유닛은 피연산자들의 모든 데이터 채널들에 걸쳐 각각의 명령어를 수행한다. 명령어 제어 필드는 채널 선택(예를 들어, 프리디케이션(predication)) 및 데이터 채널 순서(예를 들어, 스위즐(swizzle))와 같은 특정 실행 옵션들에 대한 제어를 가능하게 할 수 있다. 128-비트 명령어 포맷 의 명령어들에 대해, exec-size 필드는 병렬로 실행될 데이터 채널들의 수를 제한한다. exec-size 필드 는 64-비트 컴팩트 명령어 포맷에서의 사용을 위해 이용가능하지 않을 수 있다. 일부 실행 유닛 명령어들은 2개의 소스 피연산자, src0, src1, 및 하나의 목적지를 포함하는 최대 3개의 피연산자를 갖는다. 실행 유닛들은 목적지들 중 하나가 암시되는 이중 목적지 명령어들을 지원할 수 있다. 데이터 조작 명령어들은 제3 소스 피연산자(예를 들어, SRC2)를 가질 수 있고, 여기서 명령어 오피코드는 소스 피연산자들의 수를 결정한다. 명령어의 최종 소스 피연산자는 명령어와 함께 전달된 즉 치(예를 들어, 하드-코딩) 값일 수 있다. 128-비트 명령어 포맷은, 예를 들어, 직접 레지스터 어드레싱 모드가 사용되는지 또는 간접 레지스터 어 드레싱 모드가 사용되는지를 지정하는 액세스/어드레스 모드 필드를 포함할 수 있다. 직접 레지스터 어 드레싱 모드가 사용될 때, 하나 이상의 피연산자의 레지스터 어드레스는 명령어 내의 비트들에 의해 직접 제공 된다. 128-비트 명령어 포맷은 또한 명령어에 대한 어드레스 모드 및/또는 액세스 모드를 지정하는 액세스/어드 레스 모드 필드를 포함할 수 있다. 액세스 모드는 명령어에 대한 데이터 액세스 정렬을 정의하기 위해 사용될 수 있다. 16-바이트 정렬 액세스 모드 및 1-바이트 정렬 액세스 모드를 포함하는 액세스 모드들이 지원 될 수 있으며, 액세스 모드의 바이트 정렬은 명령어 피연산자들의 액세스 정렬을 결정한다. 예를 들어, 제1 모 드에 있을 때, 명령어는 소스 및 목적지 피연산자들에 대해 바이트-정렬된 어드레싱을 사용할 수 있고, 제2 모 드에 있을 때, 명령어는 모든 소스 및 목적지 피연산자들에 대해 16-바이트 정렬된 어드레싱을 사용할 수 있다.-49-액세스/어드레스 모드 필드의 어드레스 모드 부분은 명령어가 직접 어드레싱을 사용할지 또는 간접 어드 레싱을 사용할지를 결정할 수 있다. 직접 레지스터 어드레싱 모드가 사용될 때, 명령어 내의 비트들은 하나 이 상의 피연산자의 레지스터 어드레스를 직접 제공한다. 간접 레지스터 어드레싱 모드가 사용될 때, 하나 이상의 피연산자의 레지스터 어드레스는 명령어에서의 어드레스 레지스터 값 및 어드레스 즉치 필드에 기초하여 계산될 수 있다. 명령어들은 오피코드 디코드를 단순화하기 위해 오피코드 비트-필드들에 기초하여 그룹화될 수 있 다. 8-비트 오피코드의 경우, 비트들 4, 5 및 6은 실행 유닛이 오피코드의 타입을 결정할 수 있게 한다. 도시 된 정확한 오피코드 그룹화는 단지 예이다. 이동 및 로직 오피코드 그룹은 데이터 이동 및 로직 명령어 들(예를 들어, 이동(mov), 비교(cmp))을 포함할 수 있다. 이동 및 로직 그룹은 5개의 최하위 비트(LSB) 를 공유할 수 있으며, 이동(mov) 명령어들은 0000xxxxb의 형태로 되고, 로직 명령어들은 0001xxxxb의 형태로 된 다. 흐름 제어 명령어 그룹(예를 들어, 호출, 점프(jmp))은 0010xxxxb(예를 들어, 0x20)의 형태의 명령 어들을 포함한다. 기타 명령어 그룹은 0011xxxxb(예를 들어, 0x30)의 형태의 동기화 명령어들(예를 들어, 대기, 전송)을 포함하는 명령어들의 혼합을 포함한다. 병렬 수학 명령어 그룹은 0100xxxxb(예를 들어, 0x40)의 형태의 성분별(component-wise) 산술 명령어들(예를 들어, add, 곱셈(mul))을 포함한다. 병렬 수학 명령어 그룹은 데이터 채널들에 걸쳐 병렬로 산술 연산들을 수행한다. 벡터 수학 그룹은 0101xxxxb(예를 들어, 0x50)의 형태의 산술 명령어들(예를 들어, dp4)을 포함한다. 벡터 수학 그룹은 벡터 피 연산자들에 대한 내적 계산들과 같은 산술을 수행한다. 예시된 오피코드 디코드는, 일 실시예에서, 실행 유닛의 어느 부분이 디코딩된 명령어를 실행하기 위해 사용될 것인지를 결정하기 위해 사용될 수 있다. 예를 들어, 일부 명령어들은 시스톨릭 어레이에 의해 수행될 시스톨릭 명령어들로서 지정될 수 있다. 광선-추적 명 령어들(도시되지 않음)과 같은 다른 명령어들은 실행 로직의 슬라이스 또는 파티션 내의 광선-추적 코어 또는 광선-추적 로직으로 라우팅될 수 있다. 그래픽 파이프라인 도 21은 다른 실시예에 따른 그래픽 프로세서의 블록도이다. 본 명세서의 임의의 다른 도면의 요소들과 동일하거나 유사한 명칭들을 갖는 도 21의 요소들은 다른 도면들에서와 동일한 요소들을 설명하고, 그와 유사한 방식으로 동작하거나 기능할 수 있고, 동일한 컴포넌트들을 포함할 수 있고, 본 명세서의 다른 곳에서 설명된 것들과 같이 다른 엔티티들에 링크될 수 있지만, 이에 한정되지 않는다. 그래픽 프로세서는 지오메트리 파이프라인, 미디어 파이프라인, 디스플레이 엔진, 스 레드 실행 로직, 및 렌더 출력 파이프라인과 같은 상이한 타입들의 그래픽 프로세싱 파이프라인들 을 포함할 수 있다. 그래픽 프로세서는 하나 이상의 범용 프로세싱 코어를 포함하는 멀티-코어 프로세싱 시스템 내의 그래픽 프로세서일 수 있다. 그래픽 프로세서는 링 인터커넥트를 통해 그래픽 프로세서 에 발행된 커맨드들을 통해 또는 하나 이상의 제어 레지스터(도시되지 않음)에 대한 레지스터 기입들에 의해 제어될 수 있다. 링 인터커넥트는 그래픽 프로세서를 다른 그래픽 프로세서들 또는 범용 프 로세서들과 같은 다른 프로세싱 컴포넌트들에 결합할 수 있다. 링 인터커넥트로부터의 커맨드들은 지오 메트리 파이프라인 또는 미디어 파이프라인의 개별 컴포넌트들에 명령어들을 공급하는 커맨드 스트 리머에 의해 해석된다. 커맨드 스트리머는 메모리로부터 정점 데이터를 판독하고 커맨드 스트리머에 의해 제공된 정점-프 로세싱 커맨드들을 실행하는 정점 페처의 동작을 지시할 수 있다. 정점 페처는 정점 데이터를 정 점 셰이더에 제공할 수 있고, 정점 셰이더는 각각의 정점에 대한 좌표 공간 변환 및 라이팅 연산들 (coordinate space transformation and lighting operations)을 수행한다. 정점 페처 및 정점 셰이더 는 실행 스레드들을 스레드 디스패처를 통해 실행 유닛들(2152A-2152B)로 디스패치함으로써 정점- 프로세싱 명령어들을 실행할 수 있다. 실행 유닛들(2152A-2152B)은 그래픽 및 미디어 연산들을 수행하기 위한 명령어 세트를 갖는 벡터 프로세서들의 어레이일 수 있다. 실행 유닛들(2152A-2152B)은 각각의 어레이에 대해 특정적이거나 어레이들 간에 공유되는 부착된 L1 캐시를 가질 수 있다. 캐시는 데이터 캐시, 명령어 캐시, 또는 상이한 파티션들에 데이터 및 명령어들을 포함하도록 파티셔닝되는 단일 캐시로서 구성될 수 있다. 지오메트리 파이프라인은 3D 객체들의 하드웨어-가속(hardware-accelerated) 테셀레이션을 수행하기 위한 테셀레이션 컴포넌트들을 포함할 수 있다. 프로그램가능 헐 셰이더(programmable hull shader)는 테셀레 이션 연산들을 구성할 수 있다. 프로그램가능 도메인 셰이더는 테셀레이션 출력의 백-엔드 평가를 제공-50-할 수 있다. 테셀레이터는 헐 셰이더의 방향으로 동작하고, 지오메트리 파이프라인에 대한 입력으로서 제공되는 조대성(coarse) 지오메트릭 모델에 기초하여 상세한 지오메트릭 객체들의 세트를 생성하기 위한 특수 목적 로직을 포함할 수 있다. 또한, 테셀레이션이 사용되지 않으면, 테셀레이션 컴포넌트들(예를 들 어, 헐 셰이더, 테셀레이터 및 도메인 셰이더)이 바이패스될 수 있다. 테셀레이션 컴포넌트 들은 정점 셰이더로부터 수신된 데이터에 기초하여 동작할 수 있다. 완전한 지오메트릭 객체들은 실행 유닛들(2152A-2152B)로 디스패치된 하나 이상의 스레드를 통해 지오메트리 셰 이더에 의해 프로세싱될 수 있거나, 클리퍼로 직접 진행할 수 있다. 지오메트리 셰이더는 그래픽 파이프라인의 이전 스테이지들에서와 같이 정점들 또는 정점들의 패치들이 아니라, 전체 지오메트리 객체들에 대해 동작할 수 있다. 테셀레이션이 디스에이블된 경우, 지오메트리 셰이더는 정점 셰이더로부터 의 입력을 수신한다. 지오메트리 셰이더는 테셀레이션 유닛들이 디스에이블되는 경우에 지오메트리 테셀 레이션을 수행하기 위해 지오메트리 셰이더 프로그램에 의해 프로그램가능할 수 있다. 래스터화 전에, 클리퍼는 정점 데이터를 프로세싱한다. 클리퍼는 클리핑 및 지오메트리 셰이더 기 능들을 갖는 프로그램가능 클리퍼 또는 고정 함수 클리퍼일 수 있다. 렌더 출력 파이프라인에서의 래스 터화기 및 깊이 테스트 컴포넌트는 지오메트릭 객체들을 픽셀당(per pixel) 표현들로 변환하기 위해 픽셀 셰이더들을 디스패치할 수 있다. 픽셀 셰이더 로직은 스레드 실행 로직에 포함될 수 있다. 선택적으로, 애플리케이션은 래스터화기 및 깊이 테스트 컴포넌트를 바이패스하고, 스트림 아웃 유닛을 통해 래 스터화되지 않은 정점 데이터에 액세스할 수 있다. 그래픽 프로세서는 인터커넥트 버스, 인터커넥트 패브릭, 또는 프로세서의 주요 컴포넌트들 사이에서 데 이터 및 메시지가 전달되는 것을 허용하는 일부 다른 인터커넥트 메커니즘을 갖는다. 일부 실시예들에서, 실행 유닛들(2152A-2152B) 및 연관된 로직 유닛들(예를 들어, L1 캐시, 샘플러, 텍스처 캐시 등)은 메모리 액세스를 수행하고 프로세서의 렌더 출력 파이프라인 컴포넌트들과 통신하기 위해 데이터 포트 를 통해 상호접속된다. 샘플러, 캐시들(2151, 2158) 및 실행 유닛들(2152A-2152B) 각각은 별개의 메모리 액세스 경로들을 가질 수 있다. 선택적으로, 텍스처 캐시는 또한 샘플러 캐시로서 구성될 수 있 다. 렌더 출력 파이프라인은 정점-기반 객체들을 연관된 픽셀-기반 표현으로 변환하는 래스터화기 및 깊이 테스트 컴포넌트를 포함할 수 있다. 래스터화기 로직은 고정 함수 삼각형 및 라인 래스터화를 수행하기 위해 윈도우어/마스커(windower/masker) 유닛을 포함할 수 있다. 일부 실시예들에서, 연관된 렌더 캐시 및 깊이 캐시가 또한 이용가능하다. 픽셀 연산 컴포넌트는 데이터에 대해 픽셀-기반 연산들을 수 행하지만, 일부 경우들에서, 2D 연산들과 연관된 픽셀 연산들(예를 들어, 블렌딩을 한 비트 블록 이미지 전송들)은 2D 엔진에 의해 수행되거나, 오버레이 디스플레이 평면들을 사용하여 디스플레이 컨트롤러 에 의해 디스플레이 타임(display time)에서 대체된다. 공유 L3 캐시는 모든 그래픽 컴포넌트들에 이용가능할 수 있어, 메인 시스템 메모리의 사용 없이 데이터의 공유를 허용한다. 미디어 파이프라인은 미디어 엔진 및 비디오 프론트-엔드를 포함할 수 있다. 비디오 프론트 -엔드는 커맨드 스트리머로부터 파이프라인 커맨드들을 수신할 수 있다. 미디어 파이프라인(213 0)은 별개의 커맨드 스트리머를 포함할 수 있다. 비디오 프론트-엔드는 커맨드를 미디어 엔진으로 전송하기 전에 미디어 커맨드들을 프로세싱할 수 있다. 미디어 엔진은 스레드 디스패처를 통해 스 레드 실행 로직으로 디스패치하기 위한 스레드들을 스포닝하기 위한 스레드 스포닝 기능을 포함할 수 있 다. 그래픽 프로세서는 디스플레이 엔진을 포함할 수 있다. 이 디스플레이 엔진은 프로세서 외부에 있을 수 있고, 링 인터커넥트, 또는 일부 다른 인터커넥트 버스 또는 패브릭을 통해 그래 픽 프로세서와 결합될 수 있다. 디스플레이 엔진은 2D 엔진 및 디스플레이 컨트롤러를 포함 할 수 있다. 디스플레이 엔진은 3D 파이프라인과는 독립적으로 동작할 수 있는 특수 목적 로직을 포함할 수 있다. 디스플레이 컨트롤러는 랩톱 컴퓨터에서와 같은 시스템 통합 디스플레이 디바이스 또는 디스플 레이 디바이스 커넥터를 통해 부착된 외부 디스플레이 디바이스일 수 있는 디스플레이 디바이스(도시되지 않 음)와 결합될 수 있다. 지오메트리 파이프라인 및 미디어 파이프라인은 다수의 그래픽 및 미디어 프로그래밍 인터페이스에 기초하여 연산들을 수행하도록 구성가능할 수 있고, 임의의 하나의 API(application programming interface)에 특정적이지 않다. 그래픽 프로세서를 위한 드라이버 소프트웨어는 특정 그래픽 또는 미디어 라이브러리에 특정-51-한 API 호출들을 그래픽 프로세서에 의해 프로세싱될 수 있는 커맨드들로 변환할 수 있다. 지원은 모두 Khronos Group으로부터의 OpenGL(Open Graphics Library), OpenCL(Open Computing Language), 및/또는 Vulkan 그래픽 및 계산 API에 대해 제공될 수 있다. 마이크로소프트사의 Direct3D 라이브러리에 대한 지원도 제공될 수 있다. 이러한 라이브러리들의 조합이 지원될 수 있다. OpenCV(Open Source Computer Vision Library)에 대한 지원이 또한 제공될 수 있다. 만약 미래의 API의 파이프라인으로부터 그래픽 프로세서의 파이프라인으로 의 매핑이 이루어질 수 있다면, 호환 가능한 3D 파이프라인을 갖는 미래의 API도 지원될 것이다. 그래픽 파이프라인 프로그래밍 도 22a는, 예를 들어, 도 16a, 도 17, 도 21과 관련하여 본 명세서에 설명된 파이프라인들과 같은, 그래픽 프로 세싱 파이프라인들을 프로그래밍하기 위해 사용되는 그래픽 프로세서 커맨드 포맷을 예시하는 블록도이다. 도 22b는 실시예에 따른 그래픽 프로세서 커맨드 시퀀스를 예시하는 블록도이다. 도 22a의 실선 박스들은 일반적으로 그래픽 커맨드에 포함되는 컴포넌트들을 예시하는 한편, 파선들은 선택적이거나 그래 픽 커맨드들의 서브세트에만 포함되는 컴포넌트들을 포함한다. 도 22a의 예시적인 그래픽 프로세서 커맨드 포 맷은 클라이언트를 식별하기 위한 데이터 필드들, 커맨드 오피코드, 및 커맨드에 대한 데이 터를 포함한다. 서브-오피코드 및 커맨드 크기도 일부 커맨드들에 포함된다. 클라이언트는 커맨드 데이터를 프로세싱하는 그래픽 디바이스의 클라이언트 유닛을 지정할 수 있다. 그 래픽 프로세서 커맨드 파서는 각각의 커맨드의 클라이언트 필드를 검사하여 커맨드의 추가 프로세싱을 조절하고 커맨드 데이터를 적절한 클라이언트 유닛으로 라우팅할 수 있다. 그래픽 프로세서 클라이언트 유닛들은 메모리 인터페이스 유닛, 렌더 유닛, 2D 유닛, 3D 유닛, 및 미디어 유닛을 포함할 수 있다. 각각의 클라이언트 유닛은 커맨드들을 프로세싱하는 대응하는 프로세싱 파이프라인을 가질 수 있다. 커맨드가 클라이언트 유닛에 의해 수 신되면, 클라이언트 유닛은 수행할 연산을 결정하기 위해 오피코드 및, 존재한다면, 서브-오피코드(220 5)를 판독한다. 클라이언트 유닛은 데이터 필드 내의 정보를 사용하여 커맨드를 수행한다. 일부 커맨드 들의 경우, 명시적 커맨드 크기는 커맨드의 크기를 지정할 것으로 예상된다. 커맨드 파서는 커맨드 오피 코드에 기초하여 커맨드들 중 적어도 일부의 크기를 자동으로 결정할 수 있다. 커맨드들은 더블 워드의 배수들 (multiples of a double word)을 통해 정렬될 수 있다. 다른 커맨드 포맷들이 또한 사용될 수 있다. 도 22b의 흐름도는 예시적인 그래픽 프로세서 커맨드 시퀀스를 예시한다. 예시적인 그래픽 프로세서를 특징으로 하는 데이터 프로세싱 시스템의 소프트웨어 또는 펌웨어는 그래픽 연산들의 세트를 셋업하고, 실행하 고, 종료하기 위해 도시된 커맨드 시퀀스의 버전을 이용할 수 있다. 샘플 커맨드 시퀀스는 단지 예시의 목적으 로 도시되고 설명되며, 이러한 특정 커맨드들 또는 이러한 커맨드 시퀀스에 제한되지 않는다. 더욱이, 커맨드 들은 커맨드 시퀀스 내의 커맨드들의 배치(batch)로서 발행되어, 그래픽 프로세서가 커맨드들의 시퀀스를 적어 도 부분적으로 동시에 프로세싱할 것이다. 그래픽 프로세서 커맨드 시퀀스는 파이프라인 플러시 커맨드로 시작할 수 있어 임의의 활성 그래픽 파이프라인이 파이프라인에 대한 현재 계류중인 커맨드들을 완료하게 할 수 있다. 선택적으로, 3D 파이프라인 과 미디어 파이프라인은 동시에 동작하지 않을 수 있다. 파이프라인 플러시가 수행되어 활성 그래 픽 파이프라인이 임의의 계류중인 커맨드들을 완료하게 한다. 파이프라인 플러시에 응답하여, 그래픽 프로세서 에 대한 커맨드 파서는 활성 드로잉 엔진들이 계류중인 연산들을 완료하고 관련 판독 캐시들이 무효화될 때까지 커맨드 프로세싱을 일시 정지할 것이다. 선택적으로, \"더티(dirty)\"로 마킹된 렌더 캐시 내의 임의의 데이터는 메모리로 플러싱될 수 있다. 파이프라인 플러시 커맨드는 파이프라인 동기화를 위해 또는 그래픽 프로세 서를 저전력 상태로 두기 전에 사용될 수 있다. 파이프라인 선택 커맨드는 커맨드 시퀀스가 파이프라인 간에 명시적으로 전환하도록 그래픽 프로세서에 요구할 때 사용될 수 있다. 파이프라인 선택 커맨드는, 컨텍스트가 둘 다의 파이프라인들에 대한 커맨드 들을 발행한 것이지 않는 한, 파이프라인 커맨드들을 발행하기 전에 실행 컨텍스트 내에서 한번만 요구될 수 있 다. 파이프라인 플러시 커맨드는 파이프라인 선택 커맨드를 통해 파이프라인 스위치 직전에 요구 될 수 있다. 파이프라인 제어 커맨드는 연산을 위한 그래픽 파이프라인을 구성할 수 있고, 3D 파이프라인 및 미 디어 파이프라인을 프로그래밍하기 위해 사용될 수 있다. 파이프라인 제어 커맨드는 활성 파이프 라인에 대한 파이프라인 상태를 구성할 수 있다. 파이프라인 제어 커맨드는 파이프라인 동기화를 위해 그리고 커맨드들의 배치(batch)를 프로세싱하기 전에 액티브 파이프라인 내의 하나 이상의 캐시 메모리로부터의 데이터를 소거하기 위해 사용될 수 있다.-52-리턴 버퍼 상태에 관련된 커맨드들은 데이터를 기입하기 위해 각자의 파이프라인들에 대한 리턴 버퍼들의 세트를 구성하기 위해 사용될 수 있다. 일부 파이프라인 연산들은 연산들이 프로세싱 동안 중간 데이터를 기입 하는 하나 이상의 리턴 버퍼의 할당, 선택, 또는 구성을 필요로 한다. 그래픽 프로세서는 또한 출력 데이터를 저장하고 크로스 스레드(cross thread) 통신을 수행하기 위해 하나 이상의 리턴 버퍼를 이용할 수 있다. 리턴 버퍼 상태는 파이프라인 연산들의 세트에 사용할 리턴 버퍼들의 크기 및 수를 선택하는 것을 포함할 수 있다. 커맨드 시퀀스에서의 나머지 커맨드들은 연산들을 위한 활성 파이프라인에 기초하여 상이하다. 파이프라인 결 정에 기초하여, 커맨드 시퀀스는 3D 파이프라인 상태로 시작하는 3D 파이프라인 또는 미디어 파이프라인 상태로 시작하는 미디어 파이프라인에 맞춤화된다. 3D 파이프라인 상태를 구성하는 커맨드들은 정점 버퍼 상태, 정점 요소 상태, 일정한 컬러 상태, 깊이 버 퍼 상태, 및 3D 프리미티브 커맨드들이 프로세싱되기 전에 구성되어야 하는 다른 상태 변수들에 대한 3D 상태 설정 커맨드들을 포함한다. 이 커맨드들의 값들은 사용 중인 특정의 3D API에 적어도 부분적으로 기초하여 결 정된다. 3D 파이프라인 상태 커맨드들은 또한 그 요소들이 사용되지 않는 경우 특정 파이프라인 요소들 을 선택적으로 디스에이블 또는 바이패스할 수 있다. 3D 프리미티브 커맨드는 3D 파이프라인에 의해 프로세싱될 3D 프리미티브들을 제출하기 위해 사용될 수 있다. 3D 프리미티브 커맨드를 통해 그래픽 프로세서에 전달되는 커맨드들 및 연관된 파라미터들은 그래 픽 파이프라인 내의 정점 페치 함수로 포워딩된다. 정점 페치 함수는 정점 데이터 구조들을 생성하기 위해 3D 프리미티브 커맨드 데이터를 사용한다. 정점 데이터 구조들은 하나 이상의 리턴 버퍼에 저장된다. 3D 프리미티브 커맨드는 정점 셰이더들을 통해 3D 프리미티브들에 대한 정점 연산들을 수행하기 위해 사용될 수 있다. 정점 셰이더들을 프로세싱하기 위해, 3D 파이프라인은 셰이더 실행 스레드들을 그래픽 프로세 서 실행 유닛들로 디스패치한다. 3D 파이프라인은 실행 커맨드 또는 이벤트를 통해 트리거링될 수 있다. 레지스터는 트리거 커맨드 실행들을 기입할 수 있다. 실행은 커맨드 시퀀스 내의 '고(go)' 또는 '킥(kick)' 커맨드를 통해 트리거링될 수 있다. 커맨드 실행은 그래픽 파이프라인을 통해 커맨드 시퀀스를 플러싱하기 위해 파이프라인 동기화 커맨드를 사용하여 트리거링될 수 있다. 3D 파이프라인은 3D 프리미티브들에 대한 지오메트리 프로세싱을 수행할 것이다. 연산들이 완료되면, 결과적인 지오메트릭 객체들은 래스터화되고, 픽셀 엔진은 결과적인 픽셀들을 컬 러링(color)한다. 픽셀 셰이딩 및 픽셀 백 엔드 연산들을 제어하기 위한 추가적인 커맨드들이 또한 이러한 연 산들에 대해 포함될 수 있다. 그래픽 프로세서 커맨드 시퀀스는 미디어 연산들을 수행할 때 미디어 파이프라인 경로를 따를 수 있다. 일반적으로, 미디어 파이프라인에 대한 프로그래밍의 특정의 사용 및 방식은 수행될 미디어 또는 계산 연산들에 의존한다. 특정 미디어 디코드 연산들은 미디어 디코드 동안 미디어 파이프라인으로 오프로드될 수 있다. 미디어 파이프라인은 또한 바이패스될 수 있고, 미디어 디코드는 하나 이상의 범용 프로세싱 코어에 의해 제공되는 자원들을 사용하여 전체적으로 또는 부분적으로 수행될 수 있다. 미디어 파이프라인은 또한 범 용 그래픽 프로세서 유닛(GPGPU) 연산들을 위한 요소들을 포함할 수 있고, 여기서 그래픽 프로세서는 그래픽 프 리미티브들의 렌더링과 명시적으로 관련되지 않은 계산 셰이더 프로그램들을 사용하여 SIMD 벡터 연산들을 수행 하기 위해 사용된다. 미디어 파이프라인은 3D 파이프라인과 유사한 방식으로 구성될 수 있다. 미디어 파이프라인 상태 를 구성하기 위한 커맨드들의 세트는 미디어 객체 커맨드들 이전에 커맨드 큐에 디스패치되거나 배 치된다. 미디어 파이프라인 상태에 대한 커맨드들은 미디어 객체들을 프로세싱하기 위해 사용될 미디어 파이프라인 요소들을 구성하기 위한 데이터를 포함할 수 있다. 이것은 인코드 또는 디코드 포맷과 같은, 미디 어 파이프라인 내에 비디오 디코드 및 비디오 인코드 로직을 구성하기 위한 데이터를 포함한다. 미디어 파이프 라인 상태에 대한 커맨드들은 또한 상태 설정들의 배치(batch)를 포함하는 \"간접\" 상태 요소들에 대한 하 나 이상의 포인터의 사용을 지원할 수 있다. 미디어 객체 커맨드들은 미디어 파이프라인에 의한 프로세싱을 위해 미디어 객체들에 포인터들을 공급할 수 있다. 미디어 객체들은 프로세싱될 비디오 데이터를 포함하는 메모리 버퍼들을 포함한다. 선택적으로, 모 든 미디어 파이프라인 상태들은 미디어 객체 커맨드를 발행하기 전에 유효해야 한다. 일단 파이프라인 상태가 구성되고 미디어 객체 커맨드들이 큐잉되면, 미디어 파이프라인은 실행 커맨드 또는 동등한 실행 이벤트(예를 들어, 레지스터 기입)를 통해 트리거링된다. 미디어 파이프라인으로부터의 출-53-력은 이어서 3D 파이프라인 또는 미디어 파이프라인에 의해 제공되는 연산들에 의해 포스트 프로세 싱될 수 있다. GPGPU 연산들은 미디어 연산들과 유사한 방식으로 구성되고 실행될 수 있다. 그래픽 소프트웨어 아키텍처 도 23은 데이터 프로세싱 시스템에 대한 예시적인 그래픽 소프트웨어 아키텍처를 예시한다. 이러한 소프 트웨어 아키텍처는 3D 그래픽 애플리케이션, 운영 체제, 및 적어도 하나의 프로세서를 포함 할 수 있다. 프로세서는 그래픽 프로세서 및 하나 이상의 범용 프로세서 코어(들)를 포함할 수 있다. 프로세서는 프로세서의 변형 또는 본 명세서에 설명된 프로세서들 중 임의의 다른 것일 수 있다. 프로세서는 프로세서 또는 본 명세서에 설명된 프로세서들 중 임의의 다른 것 대신에 사 용될 수 있다. 따라서, 프로세서 또는 본 명세서에 설명된 프로세서들 중 임의의 다른 것과 조합된 임의 의 특징부들의 개시내용은 그래픽 프로세서와의 대응하는 조합을 또한 개시하지만, 이에 제한되지 않는다. 더욱이, 본 명세서의 임의의 다른 도면의 요소들과 동일하거나 유사한 명칭들을 갖는 도 23의 요소들 은 다른 도면들에서와 동일한 요소들을 설명하고, 그와 유사한 방식으로 동작하거나 기능할 수 있고, 동일한 컴 포넌트들을 포함할 수 있고, 본 명세서의 다른 곳에서 설명된 것들과 같이 다른 엔티티들에 링크될 수 있지만, 이에 한정되지 않는다. 그래픽 애플리케이션 및 운영 체제는 각각 데이터 프로세싱 시스템의 시스 템 메모리에서 실행된다. 3D 그래픽 애플리케이션은 셰이더 명령어들을 포함하는 하나 이상의 셰이더 프로그램을 포함할 수 있다. 셰이더 언어 명령어들은 Direct3D의 HLSL(High-Level Shader Language), GLSL(OpenGL Shader Language) 등과 같은 고레벨 셰이더 언어로 되어 있을 수 있다. 애플리케이션은 또한 범용 프로세서 코어에 의한 실행에 적합한 머신 언어로 된 실행가능 명령어들을 포함할 수 있다. 애플리케이션은 또한 정점 데이터 에 의해 정의된 그래픽 객체들을 포함할 수 있다. 운영 체제는 마이크로소프트사의 Microsoft® Windows® 운영 체제, 독점 UNIX-유사 운영 체제, 또는 리 눅스 커널의 변형을 사용하는 오픈 소스 UNIX-유사 운영 체제일 수 있다. 운영 체제는 Direct3D API, OpenGL API, 또는 Vulkan API와 같은 그래픽 API를 지원할 수 있다. Direct3D API가 사용 중일 때, 운 영 체제는 HLSL로 된 임의의 셰이더 명령어들을 하위-레벨 셰이더 언어로 컴파일하기 위해 프론트- 엔드 셰이더 컴파일러를 사용한다. 컴파일은 저스트-인-타임(just-in-time)(JIT) 컴파일일 수 있거나, 또는 애플리케이션은 셰이더 프리-컴파일(shader pre-compilation)을 수행할 수 있다. 고레벨 셰이더들은 3D 그래픽 애플리케이션의 컴파일 동안 저레벨 셰이더들로 컴파일될 수 있다. 셰이더 명령어들은 Vulkan API에 의해 사용되는 SPIR(Standard Portable Intermediate Representation)의 버전과 같은 중간 형태 로 제공될 수 있다. 사용자 모드 그래픽 드라이버는 셰이더 명령어들을 하드웨어 특정 표현으로 변환하기 위해 백-엔드 셰이더 컴파일러를 포함할 수 있다. OpenGL API가 사용 중일 때, GLSL 고레벨 언어의 셰이더 명령어들 은 컴파일을 위해 사용자 모드 그래픽 드라이버로 전달된다. 사용자 모드 그래픽 드라이버 는 운영 체제 커널 모드 함수들을 사용하여 커널 모드 그래픽 드라이버와 통신할 수 있다. 커널 모드 그래픽 드라이버는 그래픽 프로세서와 통신하여 커맨드들 및 명령어들을 디스패치할 수 있다. IP 코어 구현들 하나 이상의 양태는 프로세서와 같은 집적 회로 내의 로직을 나타내고/나타내거나 정의하는 머신 판독가능 매체 상에 저장되는 대표적 코드(representative code)에 의해 구현될 수 있다. 예를 들어, 머신 판독가능 매체는 프로세서 내의 다양한 로직을 나타내는 명령어들을 포함할 수 있다. 머신에 의해 판독될 때, 명령어들은 머신 으로 하여금 본 명세서에 설명된 기술들을 수행하기 위한 로직을 제작하게 할 수 있다. \"IP 코어들\"로서 알려 진 이러한 표현들은 집적 회로의 구조를 설명하는 하드웨어 모델로서 유형의(tangible) 머신 판독가능 매체 상 에 저장될 수 있는 집적 회로를 위한 재사용가능한 로직의 유닛들이다. 하드웨어 모델은 집적 회로를 제작하는 제조 머신들에 하드웨어 모델을 로드하는 다양한 고객들 또는 제조 시설들에 공급될 수 있다. 집적 회로는 회 로가 본 명세서에 설명된 실시예들 중 임의의 것과 관련하여 설명된 동작들을 수행하도록 제작될 수 있다. 도 24a는 실시예에 따른 동작들을 수행하기 위해 집적 회로를 제조하기 위해 사용될 수 있는 IP 코어 개발 시스 템을 예시한 블록도이다. IP 코어 개발 시스템은 더 큰 설계에 통합되거나 전체 집적 회로(예를 들어, SOC 집적 회로)를 구성하기 위해 사용될 수 있는 모듈러, 재사용가능 설계들을 생성하기 위해 사용될 수 있다. 설계 설비는 고레벨 프로그래밍 언어(예를 들어, C/C++)로 IP 코어 설계의 소프트웨어 시뮬레이션-54-을 생성할 수 있다. 소프트웨어 시뮬레이션은 시뮬레이션 모델을 사용하여 IP 코어의 거동 을 설계, 테스트 및 검증하기 위해 사용될 수 있다. 시뮬레이션 모델은 기능, 거동, 및/또는 타이밍 시 뮬레이션들을 포함할 수 있다. 레지스터 전송 레벨(RTL) 설계가 이어서 시뮬레이션 모델로부터 생 성되거나 합성될 수 있다. RTL 설계는 모델링된 디지털 신호들을 사용하여 수행되는 연관된 로직을 포함 하는, 하드웨어 레지스터들 사이의 디지털 신호들의 흐름을 모델링하는 집적 회로의 거동의 추상화 (abstraction)이다. RTL 설계에 추가하여, 로직 레벨 또는 트랜지스터 레벨에서의 하위-레벨 설계들이 또한 생성, 설계, 또는 합성될 수 있다. 따라서, 초기 설계 및 시뮬레이션의 특정 상세들은 변할 수 있다. RTL 설계 또는 동등물은 설계 설비에 의해, 하드웨어 설명 언어(HDL), 또는 물리적 설계 데이터의 일부 다른 표현으로 되어 있을 수 있는 하드웨어 모델로 추가로 합성될 수 있다. HDL은 IP 코어 설계를 검증 하기 위해 추가로 시뮬레이션되거나 테스트될 수 있다. IP 코어 설계는 비휘발성 메모리(예를 들어, 하 드 디스크, 플래시 메모리, 또는 임의의 비휘발성 저장 매체)를 사용하여 제3자 제작 설비로 전달하기 위 해 저장될 수 있다. 대안적으로, IP 코어 설계는 유선 접속 또는 무선 접속을 통해 (예를 들어, 인터넷을 통해) 송신될 수 있다. 제작 설비는 이어서 IP 코어 설계에 적어도 부분적으로 기초하는 집적 회로를 제작할 수 있다. 제작된 집적 회로는 본 명세서에 설명된 적어도 하나의 실시예에 따른 동작들을 수행 하도록 구성될 수 있다. 도 24b는 집적 회로 패키지 어셈블리의 측단면도를 예시한다. 집적 회로 패키지 어셈블리는 본 명 세서에 설명된 바와 같은 하나 이상의 프로세서 또는 가속기 디바이스의 구현을 예시한다. 패키지 어셈블리 는 기판에 접속된 하드웨어 로직(2472, 2474)의 다수의 유닛을 포함한다. 로직(2472, 2474)은 구 성가능한 로직 또는 고정 함수 로직 하드웨어로 적어도 부분적으로 구현될 수 있고, 본 명세서에 설명된 프로세 서 코어(들), 그래픽 프로세서(들), 또는 다른 가속기 디바이스들 중 임의의 것의 하나 이상의 부분을 포함할 수 있다. 로직의 각각의 유닛(2472, 2474)은 반도체 다이 내에 구현될 수 있고 인터커넥트 구조물을 통 해 기판과 결합될 수 있다. 인터커넥트 구조물은 로직(2472, 2474)과 기판 사이에 전기 신 호들을 라우팅하도록 구성될 수 있고, 범프들 또는 필러들과 같은, 그러나 이에 제한되지 않는, 인터커넥트들을 포함할 수 있다. 인터커넥트 구조물은, 예를 들어, 로직(2472, 2474)의 동작과 연관된 입력/출력(I/O) 신호들 및/또는 전력 또는 접지 신호들과 같은 전기 신호들을 라우팅하도록 구성될 수 있다. 선택적으로, 기판 은 에폭시-기반 라미네이트 기판일 수 있다. 기판은 또한 다른 적당한 타입들의 기판들을 포함할 수 있다. 패키지 어셈블리는 패키지 인터커넥트를 통해 다른 전기 디바이스들에 접속될 수 있다. 패키지 인터커넥트는 마더보드, 다른 칩셋, 또는 멀티-칩 모듈과 같은, 다른 전기 디바이스들에 전기 신 호들을 라우팅하기 위해 기판의 표면에 결합될 수 있다. 로직의 유닛들(2472, 2474)은 로직(2472, 2474) 사이에 전기 신호들을 라우팅하도록 구성되는 브리지와 전기적으로 결합될 수 있다. 브리지는 전기 신호들에 대한 루트를 제공하는 조밀한 인터커넥트 구조물일 수 있다. 브리지는 유리 또는 적합한 반도체 재료로 구성된 브리지 기판을 포함할 수 있다. 로직(2472, 2474) 사이에 칩-대-칩 접속을 제공하기 위해 브리지 기판 상에 전기적 라우팅 피처들이 형성될 수 있다. 2개의 로직의 유닛(2472, 2474) 및 브리지가 예시되어 있지만, 본 명세서에 설명된 실시예들은 하나 이상 의 다이 상에 더 많거나 더 적은 로직 유닛들을 포함할 수 있다. 로직이 단일 다이 상에 포함될 때 브리지 가 배제될 수 있기 때문에, 하나 이상의 다이는 제로 이상의 브리지에 의해 접속될 수 있다. 대안적으로, 다수의 다이 또는 로직의 유닛들은 하나 이상의 브리지에 의해 접속될 수 있다. 추가적으로, 다수 의 로직 유닛, 다이들, 및 브리지들이 3차원 구성들을 포함하는 다른 가능한 구성들에서 함께 접속될 수 있다. 도 24c는 기판(예를 들어, 베이스 다이)에 접속된 하드웨어 로직 칩렛들의 다수의 유닛을 포함하는 패키 지 어셈블리를 예시한다. 본 명세서에 설명되는 바와 같은 그래픽 프로세싱 유닛, 병렬 프로세서, 및/또 는 계산 가속기는 개별적으로 제조되는 다양한 실리콘 칩렛들로부터 구성될 수 있다. 이러한 맥락에서, 칩렛은 더 큰 패키지 내로 다른 칩렛들과 조립될 수 있는 별개의 로직의 유닛들을 포함하는 적어도 부분적으로 패키징 된 집적 회로이다. 상이한 IP 코어 로직을 갖는 다양한 칩렛들의 세트가 단일 디바이스로 조립될 수 있다. 추 가적으로 칩렛들은 능동 인터포저 기술을 사용하여 베이스 다이 또는 베이스 칩렛에 통합될 수 있다. 본 명세 서에 설명된 개념들은 GPU 내의 상이한 형태들의 IP 사이의 상호접속 및 통신을 가능하게 한다. IP 코어들은 상이한 프로세스 기술들을 사용하여 제조되고 제조 동안 구성될 수 있으며, 이는 특히 몇몇 플레이버 IP들 (flavors IPs)을 갖는 대형 SoC 상에서, 다수의 IP를 동일한 제조 프로세스에 수렴하는 복잡성을 회피한다. 다 수의 프로세스 기술들의 사용을 가능하게 하는 것은 출시 기간(time to market)을 개선하고 다수의 제품 SKU들 을 생성하는 비용 효율적인 방법을 제공한다. 또한, 분해된 IP들은 독립적으로 전력 게이팅되는 것에 더 잘 적-55-용가능하고, 주어진 작업부하에서 사용하고 있지 않는 컴포넌트들은 파워 오프(power off)되어, 전체 전력 소비 를 감소시킬 수 있다. 다양한 실시예들에서, 패키지 어셈블리는 패브릭 또는 하나 이상의 브리지에 의해 상호접속 되는 더 적거나 더 많은 수의 컴포넌트들 및 칩렛들을 포함할 수 있다. 패키지 어셈블리 내의 칩렛들은, 칩렛들을 패키지 인터커넥트에 대한 전기적 접속들을 포함하는 기판과 결합하기 위해 다수의 다이 가 TSV(through-silicon via)들을 포함하는 실리콘 인터포저 상에 나란히 적층되는 칩-온-웨이퍼-온-기판(Chip- on-Wafer-on-Substrate) 적층을 사용하여 2.5D 배열을 가질 수 있다. 일 실시예에서, 실리콘 인터포저는 TSV들에 더하여 내장형 로직을 포함하는 능동 인터포저이다. 이러한 실시예에서, 패키지 어셈블리 내의 칩렛들은 능동 인터포저의 상부 상의 3D 면 대 면(face to face) 다이 적층을 사용하여 배열된다. 능동 인터포저는, 인터커넥트 패브릭 및 실리콘 브리지 에 더하여, I/O에 대한 하드웨어 로직, 캐시 메모리, 및 다른 하드웨어 로직을 포함할 수 있다. 패브릭은 액티브 인터포저 내의 다양한 로직 칩렛들(2472, 2474)과 로직(2491, 2493) 사이의 통신을 가능하게 한다. 패브릭은 NoC 인터커넥트 또는 패키지 어셈블리의 컴포넌트들 사이에서 데이터 패킷들을 스위칭하는 다른 형태의 패킷 스위칭형 패브릭일 수 있다. 복잡한 어셈블리들의 경우, 패브릭 은 패키지 어셈블리의 다양한 하드웨어 로직 사이의 통신을 가능하게 해주는 전용 칩렛일 수 있다. 능동 인터포저 내의 브리지 구조물들은, 예를 들어, 로직 또는 I/O 칩렛들과 메모리 칩렛들 사이의 점대점 인터커넥트를 용이하게 하기 위해 사용될 수 있다. 일부 구현들에서, 브리지 구조물들 이 또한 기판 내에 내장될 수 있다. 하드웨어 로직 칩렛들은 특수 목적 하드웨어 로직 칩렛들, 로직 또는 I/O 칩렛들, 및/또는 메모리 칩렛들을 포함할 수 있다. 하드웨어 로직 칩렛들 및 로직 또는 I/O 칩렛들은 구성가능한 로 직 또는 고정 함수 로직 하드웨어로 적어도 부분적으로 구현될 수 있고, 본 명세서에 설명된 프로세서 코어 (들), 그래픽 프로세서(들), 병렬 프로세서들, 또는 다른 가속기 디바이스들 중 임의의 것의 하나 이상의 부분 을 포함할 수 있다. 메모리 칩렛들은 DRAM(예를 들어, GDDR, HBM) 메모리 또는 캐시(SRAM) 메모리일 수 있다. 능동 인터포저(또는 기판) 내의 캐시 메모리는 패키지 어셈블리에 대한 전역 캐시, 분산형 전역 캐시의 일부로서, 또는 패브릭에 대한 전용 캐시로서 기능할 수 있다. 각각의 칩렛은 기판과 결합되거나 기판 내에 내장되는 베이스 다이와 결합되고 별개의 반도체 다이 로서 제작될 수 있다. 기판과의 결합은 인터커넥트 구조물을 통해 수행될 수 있다. 인터커넥트 구조물은 다양한 칩렛들과 기판 내의 로직 사이에 전기 신호들을 라우팅하도록 구성될 수 있다. 인터커넥트 구조물은 범프들 또는 필러들과 같은, 그러나 이에 한정되지 않는 인터커넥트들을 포함할 수 있다. 일부 실시예들에서, 인터커넥트 구조물은, 예를 들어, 로직, I/O 및 메모리 칩렛들의 동작과 연관 된 입력/출력(I/O) 신호들 및/또는 전력 또는 접지 신호들과 같은 전기 신호들을 라우팅하도록 구성될 수 있다. 일 실시예에서, 추가적인 인터커넥트 구조물은 능동 인터포저를 기판과 결합시킨다. 기판은 에폭시-기반 라미네이트 기판일 수 있지만, 그것은 그것으로 제한되지 않고 기판은 또한 다 른 적합한 타입들의 기판들을 포함할 수 있다. 패키지 어셈블리는 패키지 인터커넥트를 통해 다른 전기 디바이스들에 접속될 수 있다. 패키지 인터커넥트는 마더보드, 다른 칩셋, 또는 멀티-칩 모듈과 같 은, 다른 전기 디바이스들에 전기 신호들을 라우팅하기 위해 기판의 표면에 결합될 수 있다. 로직 또는 I/O 칩렛 및 메모리 칩렛은 로직 또는 I/O 칩렛과 메모리 칩렛 사이에 전기 신호들을 라우팅하도록 구성된 브리지를 통해 전기적으로 결합될 수 있다. 브리지는 전기 신호들 에 대한 루트를 제공하는 조밀한 인터커넥트 구조물일 수 있다. 브리지는 유리 또는 적합한 반도체 재료 로 구성된 브리지 기판을 포함할 수 있다. 로직 또는 I/O 칩렛과 메모리 칩렛 사이에 칩-대-칩 (chip-to-chip) 접속을 제공하기 위해 브리지 기판 상에 전기적 라우팅 피처들이 형성될 수 있다. 브리지 는 또한 실리콘 브리지 또는 인터커넥트 브리지로 지칭될 수 있다. 예를 들어, 브리지는 EMIB(Embedded Multi-die Interconnect Bridge)이다. 대안적으로, 브리지는 단순히 하나의 칩렛으로부 터 다른 칩렛으로의 직접 접속일 수 있다. 도 24d는 일 실시예에 따른, 교체가능한 칩렛들을 포함하는 패키지 어셈블리를 예시한다. 교체가 능한 칩렛들은 하나 이상의 베이스 칩렛(2496, 2498) 상의 표준화된 슬롯들로 조립될 수 있다. 베이스 칩렛들(2496, 2498)은 브리지 인터커넥트를 통해 결합될 수 있고, 이는 본 명세서에 설명된 다른 브리지-56-인터커넥트들과 유사할 수 있고, 예를 들어, EMIB일 수 있다. 메모리 칩렛들은 또한 브리지 인터커넥트를 통해 로직 또는 I/O 칩렛들에 접속될 수 있다. I/O 및 로직 칩렛들은 인터커넥트 패브릭을 통해 통신할 수 있다. 베이스 칩렛들은 로직 또는 I/O 또는 메모리/캐시 중 하나를 위한 표준화된 포맷의 하나 이상의 슬롯을 각각 지 원할 수 있다. SRAM 및 전력 전달 회로들은 베이스 칩렛들(2496, 2498) 중 하나 이상으로 제작될 수 있으며, 베이스 칩렛들은 베이스 칩렛들의 상부에 적층되는 교체가능한 칩렛들에 대해 상이한 프로세스 기술을 사용하여 제작될 수 있다. 예를 들어, 베이스 칩렛들(2496, 2498)은 더 큰 프로세스 기술을 사용하여 제작될 수 있는 반면, 교체가 능한 칩렛들은 더 작은 프로세스 기술을 사용하여 제조될 수 있다. 교체가능한 칩렛들 중 하나 이상은 메모리(예를 들어, DRAM) 칩렛들일 수 있다. 패키지 어셈블리를 사용하는 제품에 대해 타겟화된 전력 및 /또는 성능에 기초하여 패키지 어셈블리에 대해 상이한 메모리 밀도들이 선택될 수 있다. 추가적으로, 상이한 수의 타입의 함수 유닛들을 갖는 로직 칩렛들이 제품에 대해 타겟화된 전력, 및/또는 성능에 기초하여 조립 시에 선택될 수 있다. 추가적으로, 상이한 타입들의 IP 로직 코어들을 포함하는 칩렛들이 교체가능한 칩 렛 슬롯들 내로 삽입될 수 있어서, 상이한 기술 IP 블록들을 혼합하고 매칭시킬 수 있는 하이브리드 프로세서 설계들을 가능하게 한다. 예시적인 시스템 온 칩 집적 회로 도 25 내지 도 26b는 하나 이상의 IP 코어를 사용하여 제조될 수 있는 예시적인 집적 회로들 및 연관된 그래픽 프로세서들을 예시한다. 예시된 것에 부가하여, 추가의 그래픽 프로세서들/코어들, 주변 인터페이스 컨트롤러 들, 또는 범용 프로세서 코어들을 포함한, 다른 로직 및 회로들이 포함될 수 있다. 본 명세서의 임의의 다른 도면의 요소들과 동일하거나 유사한 명칭들을 갖는 도 25 내지 도 26b의 요소들은 다른 도면들에서와 동일한 요 소들을 기술하고, 그것과 유사한 방식으로 동작하거나 기능할 수 있고, 동일한 컴포넌트들을 포함할 수 있고, 본 명세서의 다른 곳에서 설명된 것들과 같이, 다른 엔티티들에 링크될 수 있지만, 그러한 것에 제한되지는 않 는다. 도 25는 하나 이상의 IP 코어를 사용하여 제조될 수 있는 예시적인 시스템 온 칩 집적 회로를 예시하는 블록도이다. 예시적인 집적 회로는 하나 이상의 애플리케이션 프로세서(들)(예를 들어, CPU들), 그래픽 프로세서(1408, 1508, 2510)의, 또는 본 명세서에 설명된 임의의 그래픽 프로세서의 변형일 수 있고 설 명된 임의의 그래픽 프로세서 대신에 사용될 수 있는, 적어도 하나의 그래픽 프로세서를 포함한다. 따라 서, 본 명세서에서 그래픽 프로세서와 결합된 임의의 특징들의 개시내용은 그래픽 프로세서와의 대응하는 결합을 또한 개시하지만, 그러한 것으로 제한되지는 않는다. 집적 회로는 이미지 프로세서 및/또 는 비디오 프로세서를 추가적으로 포함할 수 있고, 이들 중 임의의 것은 동일하거나 다수의 상이한 설계 설비로부터의 모듈러 IP 코어일 수 있다. 집적 회로는 USB 컨트롤러, UART 컨트롤러, SPI/SDIO 컨트롤러, 및 I2S/I2C 컨트롤러를 포함하는 주변 또는 버스 로직을 포함할 수 있다. 추 가적으로, 집적 회로는 HDMI(high-definition multimedia interface) 컨트롤러 및 MIPI(mobile industry processor interface) 디스플레이 인터페이스 중 하나 이상에 결합된 디스플레이 디바이스를 포함 할 수 있다. 플래시 메모리 및 플래시 메모리 컨트롤러를 포함하는 플래시 메모리 서브시스템에 의해 스 토리지가 제공될 수 있다. SDRAM 또는 SRAM 메모리 디바이스들에 액세스하기 위해 메모리 컨트롤러를 통 해 메모리 인터페이스가 제공될 수 있다. 일부 집적 회로들은 내장형 보안 엔진을 추가적으로 포함한다. 도 26a 및 도 26b는 본 명세서에 설명된 실시예들에 따른, SoC 내에서 사용하기 위한 예시적인 그래픽 프로세서 들을 예시하는 블록도들이다. 그래픽 프로세서들은 그래픽 프로세서(1408, 1508, 2510), 또는 본 명세서에 설 명된 임의의 다른 그래픽 프로세서의 변형들일 수 있다. 그래픽 프로세서들은 그래픽 프로세서(1408, 1508, 2510), 또는 본 명세서에 설명된 임의의 다른 그래픽 프로세서 대신에 사용될 수 있다. 따라서, 그래픽 프로세 서(1408, 1508, 2510), 또는 본 명세서에 설명된 그래픽 프로세서들 중 임의의 다른 것과 결합된 임의의 특징들 의 개시내용은 도 26a 및 도 26b의 그래픽 프로세서들과의 대응하는 결합을 또한 개시하지만, 그러한 것으로 제 한되지는 않는다. 도 26a는 실시예에 따른, 하나 이상의 IP 코어를 사용하여 제조될 수 있는 시스템 온 칩 집 적 회로의 예시적인 그래픽 프로세서를 예시한다. 도 26b는 실시예에 따른, 하나 이상의 IP 코어를 사용 하여 제조될 수 있는 시스템 온 칩 집적 회로의 추가의 예시적인 그래픽 프로세서를 예시한다. 도 26a의 그래픽 프로세서는 저전력 그래픽 프로세서 코어의 예이다. 도 26b의 그래픽 프로세서는 고성능 그래픽 프로세서 코어의 예이다. 예를 들어, 그래픽 프로세서 및 그래픽 프로세서 각각은, 이 단 락의 처음에 언급된 바와 같이, 도 25의 그래픽 프로세서의 변형일 수 있다.-57-도 26a에 도시된 바와 같이, 그래픽 프로세서는 정점 프로세서 및 하나 이상의 프래그먼트 프로세 서(들)(2615A-2615N)(예를 들어, 2615A, 2615B, 2615C, 2615D, 내지 2615N-1, 및 2615N)를 포함한다. 그래픽 프로세서는, 정점 프로세서는 정점 셰이더 프로그램들에 대한 연산들을 실행하도록 최적화되는 한 편, 하나 이상의 프래그먼트 프로세서(들)(2615A-2615N)는 프래그먼트 또는 픽셀 셰이더 프로그램들에 대한 프 래그먼트(예를 들어, 픽셀) 셰이딩 연산들을 실행하도록, 별개의 로직을 통해 상이한 셰이더 프로그램들을 실행 할 수 있다. 정점 프로세서는 3D 그래픽 파이프라인의 정점 프로세싱 스테이지를 수행하고 프리미티브들 및 정점 데이터를 생성한다. 프래그먼트 프로세서(들)(2615A-2615N)는 정점 프로세서에 의해 생성된 프 리미티브 및 정점 데이터를 사용하여 디스플레이 디바이스 상에 디스플레이되는 프레임버퍼를 생성한다. 프래 그먼트 프로세서(들)(2615A-2615N)는, Direct 3D API에서 제공되는 바와 같은 픽셀 셰이더 프로그램과 유사한 동작들을 수행하기 위해 사용될 수 있는, OpenGL API에서 제공되는 바와 같은 프래그먼트 셰이더 프로그램들을 실행하도록 최적화될 수 있다. 그래픽 프로세서는 하나 이상의 메모리 관리 유닛(MMU)(2620A-2620B), 캐시(들)(2625A-2625B), 및 회로 인터커넥트(들)(2630A-2630B)를 추가적으로 포함한다. 하나 이상의 MMU(들)(2620A-2620B)는, 하나 이상의 캐시 (들)(2625A-2625B)에 저장된 정점 또는 이미지/텍스처 데이터에 부가하여, 메모리에 저장된 정점 또는 이미지/ 텍스처 데이터를 참조할 수 있는, 정점 프로세서 및/또는 프래그먼트 프로세서(들)(2615A-2615N)에 대한 것을 포함하여, 그래픽 프로세서에 대한 가상 대 물리 어드레스 매핑을 제공한다. 하나 이상의 MMU (들)(2620A-2620B)는, 도 25의 하나 이상의 애플리케이션 프로세서(들), 이미지 프로세서, 및/또는 비디오 프로세서와 연관된 하나 이상의 MMU를 포함하는, 시스템 내의 다른 MMU들과 동기화될 수 있어, 각 각의 프로세서(2505-2520)가 공유 또는 통합 가상 메모리 시스템에 참여할 수 있도록 한다. 그래픽 프로세서 의 컴포넌트들은 본 명세서에 설명된 다른 그래픽 프로세서들의 컴포넌트들과 대응할 수 있다. 하나 이 상의 MMU(들)(2620A-2620B)는 도 2c의 MMU와 대응할 수 있다. 정점 프로세서 및 프래그먼트 프로 세서(2615A-2615N)는 그래픽 멀티프로세서와 대응할 수 있다. 하나 이상의 회로 인터커넥트(들)(2630A- 2630B)는 그래픽 프로세서가, 실시예들에 따라, SoC의 내부 버스를 통해 또는 직접 접속을 통해, SoC 내 의 다른 IP 코어들과 인터페이스할 수 있게 한다. 하나 이상의 회로 인터커넥트(들)(2630A-2630B)는 도 2c의 데이터 크로스바와 대응할 수 있다. 그래픽 프로세서의 유사한 컴포넌트들과 본 명세서에 설명된 다양한 그래픽 프로세서 아키텍처들 간에 추가의 대응관계가 발견될 수 있다. 도 26b에 도시된 바와 같이, 그래픽 프로세서는 도 26a의 그래픽 프로세서의 하나 이상의 MMU (들)(2620A-2620B), 캐시(들)(2625A-2625B), 및 회로 인터커넥트(들)(2630A-2630B)를 포함한다. 그래픽 프로 세서는, 단일 코어 또는 타입 또는 코어가, 정점 셰이더들, 프래그먼트 셰이더들, 및/또는 계산 셰이더들 을 구현하는 셰이더 프로그램 코드를 포함하는, 모든 타입의 프로그램 가능한 셰이더 코드를 실행할 수 있는 통 합 셰이더 코어 아키텍처를 제공하는, 하나 이상의 셰이더 코어(2655A-2655N)(예를 들어, 2655A, 2655B, 2655C, 2655D, 2655E, 2655F, 내지 2655N-1, 및 2655N)를 포함한다. 존재하는 셰이더 코어들의 정확한 수는 실시예들 및 구현들 사이에 달라질 수 있다. 추가적으로, 그래픽 프로세서는 실행 스레드들을 하나 이상 의 셰이더 코어(2655A-2655N)에 디스패치하기 위한 스레드 디스패처로서의 역할을 하는 인터-코어 태스크 관리 자 및 타일-기반 렌더링을 위한 타일링 동작들을 가속시키기 위한 타일링 유닛을 포함하고, 여기서 장면에 대한 렌더링 동작들은 예를 들어 장면 내의 로컬 공간 코히어런스를 이용하거나 내부 캐시들의 사용을 최적화하기 위해 이미지 공간에서 세분된다. 셰이더 코어들(2655A-2655N)은, 예를 들어, 도 2d에서와 같은 그 래픽 멀티프로세서, 또는 도 3a 및 도 3b 각각의 그래픽 멀티프로세서들(325, 350), 또는 도 3c의 멀티-코 어 그룹(365A)과 대응할 수 있다."}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "전술한 설명 및 도면들은 제한적인 의미보다는 예시적인 의미로 간주되어야 한다. 본 기술분야의 통상의 기술 자들은 첨부된 청구항들에 제시된 특징들의 더 넓은 정신 및 범위를 벗어나지 않고 본 명세서에 설명된 실시예 들에 다양한 수정들 및 변경들이 이루어질 수 있다는 것을 이해할 것이다. 원자 감소 일 실시예에 따르면, 원자 감소는 그것을 계층적으로 수행하는 것(예를 들어, (i) 실행 유닛에서 감소를 수행하 는 것, (ii) L1에서 다음 레벨의 감소를 수행하는 것, 및 (iii) L3에서 제3 레벨의 감소를 수행하는 것)에 의해 개선될 수 있다. 이러한 방식으로, 레이턴시 및 대역폭 둘 다 감소될 수 있다. 스트리밍 버퍼 일 실시예에서, 스트리밍 버퍼는 다수의 GPU IP 코어들(예를 들어, 미디어 IP 코어 및 GPU 셰이더 코어) 간에 -58-논리적으로 개재될 수 있다. 특정 구현에 의존하여, 스트리밍 버퍼는 IP 코어들 간에 공유되는 메모리-측 캐시 일 수 있다. 도 27은 다양한 실시예들에 의해 회피하려고 하는 대역폭 및 레이턴시 비용들을 예시하는 것의 블록도이다. 이 예에서, GPU는 미디어 IP 코어(예를 들어, 미디어) 및 계산 코어(예를 들어, GPU, CPU, GPU 의 AI 코어)를 포함하고, 이들 둘 다는 동일한 미디어 스트림(예를 들어, 비디오 스트림, 오디오 스트림, 또는 비디오 및 오디오 트랙들 둘 다를 포함하는, 멀티미디어 스트림)에 관한 데이터의 프로세싱에 관련될 수 있다. 미디어 스트림은 외부 디바이스(예를 들어, 자율 차량 센서(LiDAR(Light Detection and Ranging)), 비디오 카 메라, 스트리밍 서버, 또는 등등)에 의해 생성되고 다양한 IP 코어들(예를 들어, 미디어 IP 코어 및 계산 코어)에 의한 프로세싱을 위해 메모리(예를 들어, DRAM)에 저장될 수 있다. 문제가 되는 미디어 스트림에 대해 수행될 엔드-투-엔드 프로세싱이 미디어 IP 코어 및 계산 코어에 의한 순차적인 프 로세싱을 수반한다고 가정하면, 미디어는 메모리로부터 하나 이상의 판독 동작(예를 들어, 판독)을 수행하여 프로세싱을 위한 데이터 단위를 검색하고, 데이터 단위를 프로세싱하고, 그 후 하나 이상의 기입 동작 (예를 들어, 기입)을 수행하여 미디어 IP 코어에 의해 수행된 프로세싱의 결과들을 저장할 수 있다. 그의 부분에 대해, 계산 코어는 미디어 IP 코어의 출력에 의존할 수 있고 하나 이상의 판독 동작(예를 들어, 판독)을 수행하여 프로세싱을 위한 데이터 단위(예를 들어, 미디어 IP 코어에 의 해 이전에 프로세싱된 데이터)를 검색하고, 데이터 단위를 프로세싱하고, 그 후 하나 이상의 기입 동작(예를 들 어, 기입)을 수행하여 계산 코어에 의해 수행된 프로세싱의 결과들을 저장할 수 있다. 본 기술분 야의 통상의 기술자들에 의해 이해되겠지만, 계산 코어가 미디어 IP 코어의 출력을 프로세싱하는 그러한 시나리오에서, DRAM에의 기입 및 DRAM으로부터의 판독은 메모리 대역폭의 불필 요한 사용을 나타낸다. 그러한 불필요한 메모리 대역폭을 감소시키고 레이턴시를 감소시키기 위한 노력으로, 도 28a 내지 도 28d를 참조하여 아래에 설명되는 바와 같이 미디어 IP 코어와 계산 코어 사이에 중간 버퍼가 개 재될 수 있다. 도 28a 내지 도 28d는 실시예에 따른 생산자 IP와 소비자 IP 사이의 스트리밍 버퍼의 사용을 예시하는 블록도들이다. 본 예의 컨텍스트에서, 소비자 IP 코어에 의한 프로세싱을 위한 입력으로서 사 용되도록, 시스템 메모리 및/또는 전용 그래픽 메모리일 수 있는 DRAM에 픽셀들(예를 들어, 비디오 타일 들로부터의)이 기입될 때, 소비자 IP 코어는 그것의 출력 결과들을 스트리밍 버퍼에 기입할 수 있 고, 그에 의해 소비자 IP가 다양한 사용 시나리오들에 대해 DRAM으로부터 판독하는 것을 회 피할 수 있게 한다. 특정 구현에 의존하여, 생산자 IP 및/또는 소비자 IP는 계산 코어(예를 들어, CPU 또는 GPU)를 나 타낼 수 있다. 대안적으로, 생산자 IP, 스트리밍 버퍼, 및 소비자 IP 중 하나 이상은 GPU 내에 포함될 수 있다. 예를 들어, 소비자 IP는 AI 코어(예를 들어, GPU의 셰이더 코어)일 수 있다. 일 실시예에서, 생산자 IP 코어는 그것의 출력 결과들(예를 들어, 미디어 디코딩, 미디어 인코딩, 미디어 트랜스코딩, 미디어 다운스케일링 및/또는 미디어 컬러 공간 변환의 결과들)을 스트리밍 버퍼에 기입 하고, 그에 의해 소비자 IP(GPU 셰이더 코어와 같은 AI 코어를 나타낼 수 있음)가, 미디어 분석 프 로세싱(예를 들어, AI 추론 등)을 수행하는 것을 포함하여, 다양한 사용 시나리오들에 대해 DRAM으로부터 판독하는 것을 회피할 수 있게 하도록 동작가능한 미디어 IP를 나타낼 수 있다. 미디어 분석 프로세싱의 비제 한적인 예가 도 29를 참조하여 아래에 설명된다. 특정 구현에 의존하여, 스트리밍 버퍼는 소비자 IP의 작업 세트(예를 들어, 하나 이상의 이미지 프 레임 또는 이미지 프레임의 일부와 같은 분석 프로세싱 단위)로 크기가 정해진 SRAM, DRAM, 및 캐시의 조합 중 하나 이상일 수 있다. 소비자 IP에 의한 프로세싱을 위한 스트리밍 버퍼 내의 데이터의 이용가능 성에 관한 시그널링 및 소비자 IP에 의한 데이터의 소비에 관한 시그널링은 스트리밍 버퍼에 의해 유래되는 엠프티 신호(empty signal) 및 풀 신호(full signal)의 사용 또는 생산자 IP와 소 비자 IP 사이의 핸드셰이크를 수반할 수 있다. 일부 실시예들에서, 스트리밍 버퍼는 스트리 밍 버퍼가 가득 차 있거나 비어 있을 때 각각 풀 신호 및 엠프티 신호를 통해 생산자 IP 및 소비자 IP에게 통지하기 위한 일부 하드웨어/소프트웨어 후크들을 포함한다. 대안적으로, 소비자 IP 및 생산자 IP는 정보 또는 신호들의 교환을 통해 핸드셰이크를 구현할 수 있다. 이러한 방식으로, 각각의 IP들은 스트리밍 버퍼로부터의 데이터를 소비하거나 또는 스트리밍 버퍼 를 데이터로 채우도록 통지받을 수 있다. 이 제안된 배열은 DRAM으로의 감소된 트래픽으로 인해 더 낮은-59-레이턴시 및 더 낮은 SoC 전력을 제공한다. 도 29는 실시예에 따른 미디어 분석 프로세싱을 예시하는 흐름도이다. 본 예의 컨텍스트에서, 흐름도의 좌측의 프로세싱 및 결정 블록들은 생산자 IP(예를 들어, 미디어 IP와 같은 생산자 IP)(및 잠재적으로 스트리밍 버퍼(예를 들어, 스트리밍 버퍼))에 의해 수행되는 프로세싱을 나타내고 흐름도의 우측의 프로세싱 블록 들은 소비자 IP(예를 들어, CPU, GPU, 또는 GPU(예를 들어, GPU)의 셰이더 코어와 같은 AI-특정 코어) (및 잠재적으로 스트리밍 버퍼)에 의해 수행되는 프로세싱을 나타낸다. 간결성을 위해, 단일 데이터 단 위(예를 들어, 하나 이상의 비디오 프레임)의 프로세싱이 도시되어 있다; 그러나, 미디어 분석 프로세싱은 임의 의 수의 데이터 단위들에 대해 반복될 수 있다는 것을 이해해야 한다. 블록 2910에서는, 데이터 단위가 메모리(예를 들어, DRAM)로부터 판독된다. 일 실시예에서, 미디어 IP는, 외부 소스(예를 들어, 하나 이상의 CCTV(closed-circuit television) 카메라, 트래픽 카메라 및/또는 온 라인 비디오 피드)로부터 채워질 수 있는, 메모리로부터 작업 세트(예를 들어, 하나 이상의 이미지 프레임)를 판독한다. 블록 2920에서는, 반복에 의존하여, 데이터 단위의 제1/다음 부분이 미디어 IP에 의해 프로세싱된다. 일 실시 예에 따르면, AI-특정 코어의 작업 세트는 미디어 IP의 작업 세트의 것보다 작다. 예를 들어, 미디어 IP에 의 해 프로세싱되는 개별 데이터 단위는 하나 이상의 이미지 프레임일 수 있고, AI-특정 코어에 의해 프로세싱되는 개별 단위는 이미지 프레임의 일부(예를 들어, 이미지 프레임의 절반, 이미지 프레임의 라인, 또는 이미지 프레 임의 어떤 다른 부분)일 수 있다. 일 실시예에 따르면, 이미지 프레임들은 압축되고 다수의 잠재적인 디지털 압축 및 코딩 포맷들 중 제1 포맷으로(예를 들어, MPEG(Moving Picture Experts Group) 또는 JPEG(Joint Photographic Experts Group) 표준들 중 하나에 따라) 저장될 수 있다. 미디어 IP에 의해 수행되는 프로세싱은 미디어 디코딩, 미디어 다운스케일링, 미디어 컬러 공간 변환, 및/또는 미디어 트랜스코딩(예를 들어, 다수의 잠재적인 디지털 압축 및 코딩 포맷들 중 제2 포맷으로의) 중 하나 이상을 수반할 수 있다. 일 실시예에 따르 면, 하나 이상의 프레임은 AI-특정 코어에 의한 프로세싱을 용이하게 하기 위해 래스터 스캔 순서로 프로세싱될 수 있다. 미디어 분석의 컨텍스트에서, 생산자 IP에 의해 수행되는 미디어 디코딩, 미디어 다운스케일링, 및 미디어 컬러 공간 변환의 결과들은 소비자 IP에 의한 사용을 위해 스트리밍 버퍼에 기입될 수 있다. 블록 2930에서, 데이터 단위의 프로세싱된 부분은 미디어 IP 코어에 의해 미디어 IP와 AI-특정 코어 사이에 논 리적으로 개재된 중간 스트리밍 버퍼(예를 들어, 스트리밍 버퍼)에 기입된다. 특정 구현에 의존하여, 해 당 부분은 이미지 프레임의 서브세트(예를 들어, 이미지 프레임의 절반 또는 이미지 프레임의 하나 이상의 라인)일 수 있다. 블록 2940에서, AI-특정 코어는 스트리밍 버퍼 내의 프로세싱을 위해 이용가능한 데이터의 이용가능성을 통지받"}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "는다. 본 기술분야의 통상의 기술자라면 이해하겠지만, 그러한 통지가 수행될 수 있는 다양한 메커니즘들이 있 다. 예를 들어, 일 실시예에서, 미디어 IP는 미디어 IP와 AI-특정 코어의 프로세싱을 동기화하는 핸드셰이크 (예를 들어, 핸드셰이크) I/O 제어 방법의 데이터 이용가능 신호를 통해 AI-특정 코어에 데이터의 이용가 능성을 시그널링할 수 있다. 대안적으로, 동기화 방법의 이 부분은 AI-특정 코어에 대한 풀 신호(예를 들어, 풀 신호)의 형태로 스트리밍 버퍼에 의해 구현될 수 있다. 블록 2950에서는, 블록 2940의 통지에 응답하여, 데이터의 이용가능한 부분이 AI-특정 코어에 의해 스트리밍 버 퍼로부터 판독된다."}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "블록 2960에서, 미디어 IP는 데이터가 판독되었음을 통지받는다. 본 기술분야의 통상의 기술자들라면 이해하겠 지만, 그러한 통지가 수행될 수 있는 다양한 메커니즘들이 있다. 예를 들어, 일 실시예에서, AI-특정 코어는 핸드셰이크 I/O 제어 방법의 준비완료 신호(ready signal)를 통해 데이터의 소비를 미디어 IP에 시그널링할 수 있다. 대안적으로, 동기화 방법의 이 부분은 미디어 IP에 대한 엠프티 신호(예를 들어, 엠프티 신호)의 형태로 스트리밍 버퍼에 의해 구현될 수 있다. 블록 2980에서는, AI-특정 코어에 의해 미디어 분석 프로세싱이 수행될 수 있다. 미디어 분석 프로세싱은 광범 위한 다양한 미디어 분석들 중 임의의 것을 나타낼 수 있다. 미디어 분석의 비제한적인 예들은 실시간 비디오 콘텐츠 분석, 비디오 마이닝, 실시간 모니터링, 비디오 감시, 객체 인식(예를 들어, 차량, 번호판, 보행자, 자 전거 탄 사람 등의 인식), 차량 카운팅, 차량 교통 모니터링, 의료 이미지 프로세싱, 얼굴 인식, 걷기 패턴들 및/또는 사람들의 응시 방향을 검출하는 것)을 포함한다.-60-블록 2990에서는, 문제의 데이터의 부분에 대한 미디어 분석 프로세싱 결과들이 메모리에 기입된다. 결정 블록 2970에서는, 블록 2910에서 판독된 데이터 단위의 더 많은 부분들이 프로세싱을 위해 이용가능한지에 관한 결정이 이루어진다. 그렇다면, 블록 2920에서 다음 부분에 대해 미디어 분석 프로세싱이 계속된다; 그렇 지 않으면 블록 2910에서 판독된 데이터 단위의 프로세싱이 완료된다. 흐름도 형태로 묘사하기는 어렵지만, 본"}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "기술분야의 통상의 기술자들은 이용되는 특정 동기화 방법을 조건으로 하여, 흐름도의 좌측의 프로세싱 및 결정 블록들 및 흐름도의 우측의 프로세싱 블록들은 병렬로 수행될 수 있고, 그에 의해 AI-특정 코어가 전체 프레임 이 미디어 IP에 의해 프로세싱되기를 기다릴 필요가 없고, 오히려 미디어 IP가 프레임의 개별 부분들(예를 들어, 프레임의 절반 또는 프레임의 하나 이상의 라인)을 스트리밍 버퍼에 출력함에 따라 그것들의 프로세싱을 시작할 수 있기 때문에 전체 레이턴시를 감소시킬 수 있다는 것을 이해할 것이다. 위의 예는 생산자 IP로서의 미디어 IP 및 소비자 IP로서의 AI-특정 코어를 수반하는 미디어 분석 프로세싱을 참 조하여 설명되지만, 본 명세서에 설명된 시스템들 및 방법들은 다른 구성들 및 응용들에 동등하게 적용가능하다. 예를 들어, 비디오 레코딩의 컨텍스트에서, 생산자 IP는 미디어 인코딩을 수행하는 미디어 IP에 의한 사용을 위해 비디오 데이터를 스트리밍 버퍼에 출력할 수 있다. 스크린 레코딩의 컨텍스트에서, 디스플레 이는 미디어 인코딩을 수행하는 미디어 IP에 의한 사용을 위해 원시 프레임을 스트리밍 버퍼에 저장할 수 있다. 게임 스트리밍의 컨텍스트에서, GPU(예를 들어, GPU)는 미디어 인코딩을 수행하는 미디어 IP에 의한 사용 을 위해 데이터를 스트리밍 버퍼에 기입할 수 있다. 초해상도 기반 트랜스코딩의 컨텍스트에서, 제1 미디어 IP 는 미디어 디코딩의 결과들을 GPU, CPU, 또는 AI-특정 코어에 의한 프로세싱을 위해 스트리밍 버퍼에 저장할 수 있고, 그 출력은 미디어 인코딩을 수행하는 제1 미디어 IP 또는 제2 미디어 IP에 의한 추가 프로세싱을 위해 스 트리밍 버퍼에 저장된다. 도 30a 내지 도 30b는 실시예에 따른 더블 버퍼링 기법을 구현하는 스트리밍 버퍼를 예시하는 블록도들이다. 본 예의 컨텍스트에서, 도 30a는 미디어 IP 코어(생산자 IP에 대응할 수 있음)로부터 유래하는 데 이터(예를 들어, 미디어 프로세싱 결과들)가 더블 버퍼의 제1 버퍼(예를 들어, 버퍼(3071a))에 기입되고 셰이더 코어(소비자 IP에 대응할 수 있음)에 의해 판독된 데이터가 더블 버퍼의 제2 버퍼(예를 들어, 버퍼 (3071b))로부터 판독되는 제1 상태에서의 스트리밍 버퍼(도 28a 내지 도 28d의 스트리밍 버퍼에 대 응할 수 있음)의 기입 포인터 및 판독 포인터를 도시한다. 위에 언급된 바와 같이, 버퍼들(3071a- b)은 셰이더 코어의 작업 세트에 따라 크기가 정해질 수 있다. 도 30b는 미디어 IP 코어(생산자 IP에 대응할 수 있음)로부터 유래하는 데이터가 더블 버퍼의 제2 버퍼에 기입되고 셰이더 코어(소비자 IP에 대응할 수 있음)에 의해 판독된 데이터가 더블 버퍼의 제2 버퍼로부터 판독되는 제2 상태에서의 기입 포인터 및 판독 포인터를 도시한다. 스트리밍 버퍼 는 이용되는 동기화 방법(예를 들어, (i) 핸드셰이크 또는 (ii) 엠프티 신호 및 풀 신호)에"}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "따라 제1 상태와 제2 상태 간에 전이할 수 있다. 본 기술분야의 통상의 기술자들라면 사용될 수 있는 다수의 버퍼링 스킴들이 있다는 것을 이해할 것이다. 예를 들어, 더블 버퍼링 스킴(double buffering scheme)보다는, 원형 버퍼가 스트리밍 버퍼 내에 구현될 수 있다. 저전력 로컬 캐시 일 실시예에 따르면, 단일 IP 코어만이 활성일 때 패브릭을 통해 다수의 IP 코어들에 의해 공유되는 캐시(예를 들어, 중간-레벨 캐시)가 로컬 캐시로서 사용될 수 있다. 도 31a는 실시예에 따른, 중앙 패브릭의 일부인 다수의 IP 코어들(3110a-n)에 의해 공유되는 캐시 에 대한 제1 사용 시나리오를 예시하는 블록도이다. 본 예의 컨텍스트에서, GPU는 다수의 IP 코어들 (3110a-n)을 포함하는 것으로 도시되어 있고 여기서 문제의 작업부하는 IP 코어들(3110a-n) 중 하나 이상의 IP 코어 사이의 통신, 캐시로의 액세스 및/또는 패브릭을 달리 사용하는 것을 수반한다. 그에 따라, 그러한 사용 시나리오에서는, 패브릭 및 캐시에 전력이 제공된다. 간결성을 위해, 다수의 잠재적"}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "인 그래픽 실행 자원들이 도 31a 및 도 31b에 도시되어 있지 않다. 본 기술분야의 통상의 기술자들은 GPU가 본 명세서에 설명된 바와 같은 하나 이상의 그래픽 엔진(들), 그래픽 프로세서 코어들, 및 다른 그 래픽 실행 자원들(도시되지 않음)을 포함할 수 있다는 것을 이해할 것이다. 그러한 그래픽 실행 자원들은 실행 유닛들, 셰이더 엔진들, 프래그먼트 프로세서들, 정점 프로세서들, 스트리밍 멀티프로세서들, 그래픽 프로세서 클러스터들, 또는 그래픽 자원들 또는 이미지 자원들의 프로세싱, 또는 이종 프로세서에서 범용 계산 연산들을 수행하기에 적합한 컴퓨팅 자원들의 임의의 컬렉션을 포함하지만 이들에 제한되지 않는 형태들로 제시될 수 있-61-다. 도 31b는 실시예에 따른, 중앙 패브릭의 일부인 다수의 IP 코어들(3110a-n)에 의해 공유되는 캐시 에 대한 제2 사용 시나리오를 예시하는 블록도이다. 이 예에서, 단일 IP(예를 들어, IP(3110a))만이 활성이다 (파선들로 예시된 바와 같이). 이 상황은, 예를 들어, 미디어 IP 코어가 다른 IP들(예를 들어, IP들(3110b- n))과의 통신을 수반하지 않고 독립형 작업부하들을 나타내는 특정 작업부하들, 예를 들어, 미디어 디코딩/인코 딩/트랜스코딩을 프로세싱하고 있을 때 발생할 수 있다. 그러한 시나리오에서, 중간-레벨 캐시와 소통하기 위 해 중앙 패브릭을 통하는 것은 캐시 전력뿐만 아니라 중앙 패브릭 전력도 초래할 것이고 따라서 작업부하 에 대한 SoC 전력을 불리하게 하고 배터리 수명에 영향을 줄 것이다. 그에 따라, 일 실시예에 따르면, 패브릭 은 파워 오프될 수 있고(파선 윤곽에 의해 지시된 바와 같이) 저전력 액세스 경로가 패브릭 외부의 캐시에 제공되고 따라서 단일 IP 코어만이 캐시의 사용을 필요로 할 때 전체 패브릭 전력을 소진 하는 것을 회피하고 더 낮은 SoC 전력 사용을 야기한다. 이는 활성 IP(예를 들어, 본 예의 컨텍스트에서 IP(3110a))가 패브릭 전력을 소비하지 않고 로컬 캐시로서 캐시를 사용하는 것을 허용한다. 셰이더 모듈 당 로컬 캐시 일 실시예에 따르면, 캐시 뱅크들은, 예를 들어, 주어진 응용에 대해 최적일 로컬 파티션의 크기를 결정함으로 써 작업부하 특성들에 기초하여 상이하게 분할된다. 일 실시예에서, GPU의 마지막 레벨 캐시(예를 들어, L2/L3 캐시)는, 작업부하 요구에 기초하여, 서브-슬라이스 당 로컬 캐시들로서 재구성될 수 있다. 전역적 마지막-레벨 캐시는 보통 다이의 중간에서 다수의 뱅크들 사이 에 분산된다. 일부 뱅크들은 주어진 서브-슬라이스(셰이더 모듈(SM)로도 알려짐(a/k/a))에 더 가까운 반면, 대 부분의 뱅크들은 다이에서 더 멀리 있을 것이다. 캐시가 전역적 자원으로서 조직될 때, 캐시 뱅크에 대한 평균 레이턴시는 데이터가 뱅크들에 걸쳐 분산됨으로 인해 높을 것이다. 작업부하 요구들에 기초하여, 각각의 캐시 뱅크는 \"전역적\" 부분과 \"로컬\" 부분으로 분할될 수 있다. 로컬 부분은 해당 뱅크에 가장 가까운 서브-슬라이 스(들)에 대한 로컬 캐시의 역할을 한다. 그 결과, 서브-슬라이스가 그것의 로컬 뱅크에 액세스하기 위한 레이 턴시 및 전력은 낮을 것이다. 로컬 캐시가 미스(miss)하면, 전역적 캐시에서의 검색(lookup)이 수행될 것이다. 일부 머신 러닝(Machine Learning)(ML)/딥 러닝(Deep Learning)(DL) 커널들에 대해, 전역적/공유 캐시를 다수 의 프라이빗/로컬 캐시들(SM 당)로 구성하는 것은 훨씬 더 전력/성능 효율적인 솔루션이다. 이 접근법은 도 32에 예시된 바와 같은 다이-스택형 GPU에도 적용가능하고, 여기서 상부 다이들은 계산 자원들 (서브-슬라이스들)을 포함하고 하부 다이는 마지막-레벨 캐시를 갖는다. 서브-슬라이스들의 세트 바로 아래의 뱅크들은 상부 서브-슬라이스들에 대한 로컬 캐시 뱅크들의 역할을 할 것이다(낮은 레이턴시). 도 32는 실시예에 따른 칩렛 및 베이스 다이 스택형 접근법을 예시하는 블록도이다. 일 실시예에 따르면, 관리 자는 베이스 칩렛의 마지막-레벨 캐시 뱅크들(예를 들어, L2 캐시 뱅크들(3225a-n))과 칩렛들에 포 함된 서브-슬라이스들의 세트의 개별 서브-슬라이스들 사이의 연관을 형성하기 위한 구성 정보를 특정할 수 있 다. 이 구성 정보는 그래픽 카드가 부팅될 때 판독될 수 있고 GPU(들)는 그에 따라 구성될 수 있다. 본 예의 컨텍스트에서, 칩렛들에 포함된 서브-슬라이스들의 세트 바로 아래의 베이스 칩렛의 해당 마지막-레벨 캐시 뱅크들은 액세스 레이턴시를 감소시키기 위해 서브-슬라이스들의 세트에 대한 로컬 캐시 뱅크 들의 역할을 할 수 있다. 특정 구현에 의존하여, 마지막-레벨 캐시 뱅크들은 각각의 타일이 하나의 파티션을 얻는 동등한 크기의 파티션 들로 분할될 수 있다. 대안적으로 파티션들의 할당은 비대칭일 수 있다. 일부 실시예들에서, 다수의(예를 들 어, 2개의) 칩렛은 마지막-레벨 캐시 뱅크들의 하나의 세트(파티션)를 공유할 수 있고 나머지(예를 들어, 2개의) 칩렛은 마지막-레벨 캐시 뱅크들의 다른 세트(파티션)를 공유할 수 있다. 일부 실시예들에서, 칩 렛들(예를 들어, 칩렛 당 하나 또는 다수) 및 다른 자원들과 연관된 메모리 채널들(도시되지 않음)이 유 사한 방식으로 분할될 수 있다. 방법들 중 다수는 그들의 가장 기본적인 형태로 기술되지만, 본 실시예들의 기본 범위를 벗어나지 않은 채로 프 로세스들이 그 방법들 중 임의의 것으로부터 삭제되거나 임의의 것에 추가될 수 있고, 정보가 기술된 메시지들 중 임의의 메시지로부터 감해지거나 임의의 메시지에 추가될 수 있다. 다수의 추가의 수정들 및 적응들이 이루"}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 19, "content": "어질 수 있음이 본 기술분야의 통상의 기술자들에게 명백할 것이다. 특정 실시예들은 개념을 제한하기 위해 제 공되는 것이 아니라 그것을 예시하기 위해 제공된다. 실시예들의 범위는 위에 제공된 특정 예들에 의해서만 결 정되는 것이 아니라 아래 청구항들에 의해서만 결정된다.-62-요소 \"A\"가 요소 \"B\"에 또는 그와 결합된다고 하면, 요소 A는 요소 B에 직접 결합되거나, 예를 들어, 요소 C를 통해 간접적으로 결합될 수 있다. 명세서 또는 청구항들이, 컴포넌트, 특징, 구조, 프로세스, 또는 특성 A가 컴포넌트, 특징, 구조, 프로세스, 또는 특성 B를 \"야기한다(cause)\"고 기술할 때, 이는 \"A\"가 \"B\"의 적어도 부 분적인 원인이지만, \"B\"를 야기하는 데 도움이 되는 적어도 하나의 다른 컴포넌트, 특징, 구조, 프로세스, 또는 특성이 또한 존재할 수 있음을 의미한다. 명세서가 컴포넌트, 특징, 구조, 프로세스, 또는 특성이 포함될 수 있음(\"may\", \"might\", 또는 \"could\" be included)을 지시한다면, 해당 특정 컴포넌트, 특징, 구조, 프로세스, 또는 특성이 포함되는 것이 요구되는 것은 아니다. 명세서 또는 청구항이 하나의(\"a\" 또는 \"an\") 요소를 언급 한다면, 이는 기술된 요소들 중 하나만이 존재함을 의미하지 않는다. 실시예는 구현 또는 예이다. 명세서에서 \"실시예\", \"일 실시예\", \"일부 실시예들\", 또는 \"다른 실시예들\"에 대 한 언급은 실시예들과 관련하여 설명된 특정 특징, 구조, 또는 특성이 적어도 일부 실시예들에 포함되지만, 반 드시 모든 실시예들에 포함되는 것은 아님을 의미한다. \"실시예\", \"일 실시예\", 또는 \"일부 실시예들\"의 다양 한 출현들은 반드시 모두가 동일한 실시예들을 언급하는 것은 아니다. 예시적인 실시예들에 대한 전술한 설명 에서, 다양한 특징들은 개시내용을 간소화하고 다양한 새로운 양태들 중의 하나 이상의 이해를 도울 목적으로, 그의 단일 실시예, 도면, 또는 설명에서 때때로 함께 그룹화된다는 것을 이해해야 한다. 그러나, 이러한 개시 의 방법은, 청구된 실시예들이 각각의 청구항에서 명백하게 열거되는 것보다 더 많은 특징들을 요구한다는 의도 를 반영하는 것으로 해석되지 않아야 한다. 오히려, 다음의 청구항들이 반영하는 바와 같이, 새로운 양태들은 단일의 전술한 개시된 실시예의 모든 특징들보다 더 적은 것에 있을 수 있다. 따라서, 청구항들은 이로써 이 설명에 명백하게 포함되고, 각각의 청구항은 개별 실시예로서 그 자체적으로 독립적이다. 다음의 조항들 및/또는 예들은 추가 실시예들 또는 예들에 관한 것이다. 예들에서의 세부사항들은 하나 이상의 실시예에서 어디에서든 사용될 수 있다. 상이한 실시예들 또는 예들의 다양한 특징들은 다양한 상이한 응용들 에 적합하도록 포함된 일부 특징들 및 배제된 다른 특징들과 다양하게 조합될 수 있다. 예들은 방법, 방법의 동작들을 수행하기 위한 수단, 머신에 의해 수행될 때 머신으로 하여금 방법의 동작들을 수행하게 하는 명령어 들을 포함하는 적어도 하나의 머신 판독가능 매체, 또는 본 명세서에 설명된 실시예들 및 예들에 따라 하이브리 드 통신을 용이하게 하기 위한 장치 또는 시스템과 같은 주제를 포함할 수 있다. 일부 실시예들은 시스템을 포함하는 예 1에 관한 것으로, 이 시스템은: 생산자 IP(intellectual property); 계 산 코어; 상기 생산자 IP와 상기 계산 코어 사이에 논리적으로 개재된 스트리밍 버퍼를 포함하고; 상기 생산자 IP는 메모리로부터의 데이터를 소비하고 결과들을 상기 스트리밍 버퍼에 출력하도록 동작가능하고; 상기 계산 코어는 상기 스트리밍 버퍼로부터 소비되는 데이터에 기초하여 AI 추론 프로세싱을 수행하고 AI 추론 프로세싱 결과들을 상기 메모리에 출력하도록 동작가능하다. 예 2는 예 1의 주제를 포함하고, 상기 계산 코어는 중앙 프로세싱 유닛(CPU) 또는 그래픽 프로세싱 유닛(GPU)을 포함한다. 예 3은 예 1-2의 주제를 포함하고, 상기 계산 코어는 AI-특정 코어를 포함한다. 예 4는 예 1-3의 주제를 포함하고, 상기 AI-특정 코어는 그래픽 프로세싱 유닛(GPU)의 셰이더 코어를 포함한다. 예 5는 예 1-4의 주제를 포함하고, 상기 스트리밍 버퍼는 로컬 캐시를 포함한다. 예 6은 예 1-5의 주제를 포함하고, 상기 메모리는 동적 랜덤 액세스 메모리를 포함한다. 예 7은 예 1-5의 주제를 포함하고, 상기 메모리는 시스템 메모리를 포함한다. 예 8은 예 1-5의 주제를 포함하고, 상기 메모리는 전용 그래픽 메모리를 포함한다. 예 9는 예 1-8의 주제를 포함하고, 상기 스트리밍 버퍼는 상기 스트리밍 버퍼가 제1 미리 결정된 또는 구성가능 한 임계값보다 적은 데이터를 포함할 때 상기 생산자 IP에 통지하도록 동작가능하다. 예 10은 예 1-9의 주제를 포함하고, 상기 스트리밍 버퍼는 상기 스트리밍 버퍼가 제2 미리 결정된 또는 구성가 능한 임계값보다 많은 데이터를 포함할 때 상기 계산 코어에 통지하도록 동작가능하다. 예 11은 예 1-10의 주제를 포함하고, 상기 생산자 IP는 미디어 IP를 포함하고 상기 계산 코어는 GPU의 AI-특정 코어를 포함한다. 예 12는 예 11의 주제를 포함하고, 상기 미디어 IP와 상기 AI-특정 코어는, 상기 AI-특정 코어에 의한 상기 AI 추론 프로세싱을 위한 상기 스트리밍 버퍼에서의 데이터의 분석 프로세싱 단위의 이용가능성을 지시하는 상기-63-미디어 IP로부터 상기 AI-특정 코어로의 제1 핸드셰이크 신호 및 상기 데이터가 상기 AI-특정 코어에 의해 판독 된 것을 지시하는 상기 AI-특정 코어로부터 상기 미디어 IP로의 제2 핸드셰이크 신호를 포함하는, 핸드셰이크 신호들을 교환한다. 예 13은 예 1-12의 주제를 포함하고, 상기 분석 프로세싱 단위는 이미지 프레임 또는 이미지 프레임의 일부를 포함한다. 예 14는 예 11의 주제를 포함하고, 상기 스트리밍 버퍼는 상기 미디어 IP에 의해 데이터의 제1 분석 프로세싱 단위가 기입되는 기입 포인터에 의해 지정된 제1 버퍼 및 상기 AI-특정 코어에 의해 데이터의 제2 분석 프로세 싱 단위가 판독되는 판독 포인터에 의해 지정된 제2 버퍼를 포함하는 더블 버퍼를 구현함으로써 상기 미디어 IP 와 상기 AI-특정 코어에 의한 병렬 프로세싱을 용이하게 한다. 일부 실시예들은 미디어 분석 프로세싱을 수행하기 위한 방법을 포함하는 예 15에 관한 것으로, 이 방법은: 미 디어 IP(intellectual property)에 의해, 메모리로부터 데이터 단위를 판독하는 단계; 그래픽 프로세싱 유닛 (GPU)의 인공 지능(AI)-특정 코어가 연산하도록 구성되어 있는 상기 데이터 단위 내에서 데이터의 각각의 분석 프로세싱 단위에 대해: 상기 미디어 IP에 의해, 상기 분석 프로세싱 단위에 대해 미디어 프로세싱을 수행하는 단계; 제1 신호에 응답하여, 상기 미디어 IP에 의해, 상기 미디어 프로세싱의 결과를 상기 미디어 IP와 상기 AI-특정 코어 사이에 논리적으로 개재된 스트리밍 버퍼에 기입하는 단계; 제2 신호를 통해 상기 스트리밍 버퍼 내의 상기 데이터의 이용가능성에 관해 상기 AI-특정 코어에 통지하는 단계; 상기 제2 신호에 응답하여, 상기 AI-특정 코어에 의해, 상기 스트리밍 버퍼로부터 상기 데이터를 판독하는 단계; 상기 제1 신호를 통해 상기 AI- 특정 코어에 의한 상기 데이터의 소비에 관해 상기 미디어 IP에 통지하는 단계; 상기 AI-특정 코어에 의해, 상 기 데이터에 대해 미디어 분석 프로세싱을 수행하는 단계; 상기 AI-특정 코어에 의해, 상기 미디어 분석 프로세 싱의 결과를 상기 메모리에 기입하는 단계에 의해 상기 미디어 IP와 상기 AI-특정 코어에 의한 병렬 프로세싱을 용이하게 하는 단계를 포함한다. 예 16은 예 15의 주제를 포함하고, 상기 스트리밍 버퍼는 캐시를 포함한다. 예 17은 예 15-16의 주제를 포함하고, 상기 메모리는 동적 랜덤 액세스 메모리를 포함한다. 예 18은 예 15-16의 주제를 포함하고, 상기 메모리는 컴퓨터 시스템의 시스템 메모리를 포함한다. 예 19는 예 15-16의 주제를 포함하고, 상기 메모리는 전용 그래픽 메모리를 포함한다. 예 20은 예 15-19의 주제를 포함하고, 상기 스트리밍 버퍼 내의 상기 데이터의 이용가능성에 관해 상기 AI-특정 코어에 통지하는 상기 단계는 상기 스트리밍 버퍼에 의해 수행된다. 예 21은 예 15-19의 주제를 포함하고, 상기 스트리밍 버퍼 내의 상기 데이터의 이용가능성에 관해 상기 AI-특정 코어에 통지하는 상기 단계는 상기 미디어 IP에 의해 수행된다. 예 22는 예 15-21의 주제를 포함하고, 상기 AI-특정 코어에 의한 상기 데이터의 소비에 관해 상기 미디어 IP에 통지하는 상기 단계는 상기 스트리밍 버퍼에 의해 수행된다. 예 23은 예 15-21의 주제를 포함하고, 상기 AI-특정 코어에 의한 상기 데이터의 소비에 관해 상기 미디어 IP에 통지하는 상기 단계는 상기 AI-특정 코어에 의해 수행된다. 예 24는 예 15-23의 주제를 포함하고, 상기 데이터 단위는 이미지 프레임을 포함하고, 상기 분석 프로세싱 단위 는 이미지 프레임의 일부를 포함한다. 예 25는 예 15-24의 주제를 포함하고, 상기 미디어 프로세싱은 미디어를 하나 이상의 미디어 인코딩 포맷으로, 하나 이상의 미디어 인코딩 포맷으로부터, 또는 하나 이상의 미디어 인코딩 포맷 사이에 인코딩, 디코딩, 또는 트랜스코딩하는 것 중 하나 이상을 포함한다. 예 26은 예 15-25의 주제를 포함하고, 상기 미디어 분석 프로세싱은 인공 지능(AI) 추론들을 수행하는 단계를 포함한다. 일부 실시예들은 절전 방법을 포함하는 예 27에 관한 것으로, 이 방법은: 그래픽 프로세싱 유닛(GPU)에 의해, 중앙 패브릭을 통해 공통 캐시에 액세스할 수 있는 복수의 IP(intellectual property) 코어의 상태를 관찰하는 단계; 및 상기 관찰된 상태가 상기 복수의 IP 코어 중 제1 IP 코어에 의한 독립형 작업부하의 수행을 지시하는 것에 응답하여, 상기 중앙 패브릭을 파워 오프하고 상기 제1 IP 코어로 하여금 상기 중앙 패브릭 외부에 있는-64-상기 공통 캐시와 상기 제1 IP 코어 사이의 저전력 액세스 경로를 통해 상기 공통 캐시에 액세스하게 함으로써 상기 공통 캐시를 상기 제1 IP 코어의 로컬 캐시로서 취급하는 단계를 포함한다. 예 28은 예 27의 주제를 포함하고, 상기 제1 IP 코어는 미디어 IP 코어를 포함하고 상기 독립형 작업부하는 미 디어 디코딩, 미디어 인코딩 또는 미디어 트랜스코딩을 포함한다. 예 29는 예 27-28의 주제를 포함하고, 상기 관찰된 상태는 상기 제1 IP 코어가 활성이고 상기 복수의 IP 코어 중 다른 IP 코어들이 비활성인 것을 포함한다. 일부 실시예들은 그래픽 프로세싱 유닛(GPU)을 포함하는 예 30에 관한 것으로, 이 GPU는: 복수의 캐시 뱅크; 상 기 복수의 캐시 뱅크에 결합된 복수의 셰이더 모듈을 포함하고; 상기 복수의 캐시 뱅크의 각각의 캐시 뱅크는 상기 복수의 셰이더 모듈 중 특정 셰이더 모듈에 대한 작업부하 요구 및 상기 캐시 뱅크와 상기 특정 셰이더 모 듈 사이의 거리 중 적어도 하나에 기초하여 상기 특정 셰이더 모듈에 대한 로컬 캐시로서 또는 전역적 마지막 레벨 캐시의 일부로서 동작하도록 재구성가능하다. 예 31은 예 30의 주제를 포함하고, 상기 GPU는 다이-스택형 GPU를 포함한다. 예 32는 예 30-31의 주제를 포함하고, 상기 복수의 캐시 뱅크는 레벨 2(L2) 캐시 뱅크들을 포함한다. 예 33은 예 30-31의 주제를 포함하고, 상기 복수의 캐시 뱅크는 레벨 3(L3) 캐시 뱅크들을 포함한다."}
{"patent_id": "10-2020-0151794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 20, "content": "도면들 및 전술한 설명은 실시예들의 예들을 제공한다. 본 기술분야의 통상의 기술자들은 기술된 요소들 중 하 나 이상이 단일 기능 요소로 잘 조합될 수 있다는 것을 이해할 것이다. 대안적으로, 특정 요소들은 다수의 기 능 요소들로 분할될 수 있다. 일 실시예로부터의 요소가 다른 실시예에 추가될 수 있다. 예를 들어, 본 명세 서에 설명된 프로세스들의 순서들은 변경될 수 있고 본 명세서에 설명된 방식으로 제한되지 않는다. 더욱이, 임의의 흐름도의 액션들은 도시된 순서로 구현될 필요는 없다; 모든 동작들이 반드시 수행될 필요가 있는 것도 아니다. 또한, 다른 동작들에 의존하지 않는 해당 동작들은 다른 동작들과 병렬로 수행될 수 있다. 실시예들 의 범위는 결코 이들 특정 예에 의해 제한되지 않는다. 본 명세서에 명시적으로 주어지든 아니든 간에, 구조, 치수, 및 재료의 사용의 차이들과 같은 다수의 변형들이 가능하다. 실시예들의 범위는 적어도 다음의 청구항들 에 의해 주어진 만큼 넓다.-65-도면 도면1 -66-도면2a -67-도면2b -68-도면2c -69-도면2d -70-도면3a -71-도면3b -72-도면3c -73-도면4a -74-도면4b -75-도면4c -76-도면4d -77-도면4e -78-도면4f -79-도면5 -80-도면6 -81-도면7 -82-도면8 도면9a -83-도면9b -84-도면10 -85-도면11 -86-도면12a -87-도면12b -88-도면13 -89-도면14 -90-도면15a -91-도면15b -92-도면15c -93-도면16a -94-도면16b -95-도면16c -96-도면17 -97-도면18a -98-도면18b -99-도면19 -100-도면20 -101-도면21 도면22a -102-도면22b -103-도면23 -104-도면24a -105-도면24b -106-도면24c -107-도면24d -108-도면25 -109-도면26a -110-도면26b -111-도면27 -112-도면28a -113-도면28b -114-도면28c -115-도면28d -116-도면29 -117-도면30a -118-도면30b -119-도면31a 도면31b -120-도면32 -121- 임시명세서(첨부)공개특허10-2021-0059648 -122-"}
{"patent_id": "10-2020-0151794", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 설명된 실시예들은 첨부 도면들의 도면들에서 제한으로서가 아니라 예로서 예시되며, 도면들에서 동일한 참조 번호들은 유사한 요소들을 가리킨다. 도 1은 본 명세서에 설명된 실시예들의 하나 이상의 양태를 구현하도록 구성되는 컴퓨터 시스템을 도시하는 블 록도이다. 도 2a 내지 도 2d는 병렬 프로세서 컴포넌트들을 도시한다. 도 3a 내지 도 3c는 그래픽 멀티프로세서들 및 멀티프로세서-기반 GPU들의 블록도이다. 도 4a 내지 도 4f는 복수의 GPU들이 복수의 멀티-코어 프로세서들에 통신가능하게 결합되는 예시적인 아키텍처 를 도시한다. 도 5는 그래픽 프로세싱 파이프라인을 도시한다. 도 6은 머신 러닝 소프트웨어 스택(machine learning software stack)을 도시한다. 도 7은 범용 그래픽 프로세싱 유닛을 도시한다. 도 8은 멀티-GPU 컴퓨팅 시스템을 도시한다. 도 9a 내지 도 9b는 예시적인 딥 신경망(deep neural network)들의 층들을 도시한다. 도 10은 예시적인 순환 신경망(recurrent neural network)을 도시한다. 도 11은 딥 신경망의 훈련 및 배치를 도시한다. 도 12a는 분산 학습을 도시하는 블록도이다.-5-도 12b는 프로그램가능 네트워크 인터페이스 및 데이터 프로세싱 유닛을 도시하는 블록도이다. 도 13은 훈련된 모델을 사용하여 추론을 수행하기에 적합한 예시적인 추론 시스템 온 칩(SOC)을 도시한다. 도 14는 프로세싱 시스템의 블록도이다. 도 15a 내지 도 15c는 컴퓨팅 시스템들 및 그래픽 프로세서들을 도시한다. 도 16a 내지 도 16c는 추가적인 그래픽 프로세서 및 계산 가속기 아키텍처들의 블록도들을 도시한다. 도 17은 그래픽 프로세서의 그래픽 프로세싱 엔진의 블록도이다. 도 18a 및 도 18b는 그래픽 프로세서 코어에서 이용되는 프로세싱 요소들의 어레이를 포함하는 스레드 실행 로 직을 도시한다. 도 19는 추가적인 실행 유닛을 도시한다. 도 20은 그래픽 프로세서 명령어 포맷들을 도시하는 블록도이다. 도 21은 추가적인 그래픽 프로세서 아키텍처의 블록도이다. 도 22a 및 도 22b는 그래픽 프로세서 커맨드 포맷 및 커맨드 시퀀스를 도시한다. 도 23은 데이터 프로세싱 시스템에 대한 예시적인 그래픽 소프트웨어 아키텍처를 도시한다. 도 24a는 IP 코어 개발 시스템을 도시하는 블록도이다. 도 24b는 집적 회로 패키지 어셈블리의 측면 단면도를 도시한다. 도 24c는 기판(예를 들어, 베이스 다이)에 접속된 하드웨어 로직 칩렛(hardware logic chiplet)들의 다수의 유 닛들을 포함하는 패키지 어셈블리를 도시한다. 도 24d는 교체가능한 칩렛들을 포함하는 패키지 어셈블리를 도시한다. 도 25는 예시적인 시스템 온 칩 집적 회로를 도시하는 블록도이다. 도 26a 및 도 26b는 SoC 내에서 사용하기 위한 예시적인 그래픽 프로세서들을 도시하는 블록도들이다. 도 27은 다양한 실시예들에 의해 회피하고자 하는 대역폭 및 레이턴시 비용들을 도시하는 블록도이다. 도 28a 내지 도 28d는 다양한 실시예들에 따른 생산자 IP와 소비자 IP 사이의 스트리밍 버퍼의 사용을 도시하는 블록도들이다. 도 29는 일 실시예에 따른 미디어 분석 프로세싱을 도시하는 흐름도이다. 도 30a 내지 도 30b는 일 실시예에 따른 더블 버퍼링 기법을 구현하는 스트리밍 버퍼를 도시하는 블록도들이다. 도 31a 및 도 31b는 일 실시예에 따른 중앙 패브릭의 일부인 다수의 IP 코어들에 의해 공유되는 캐시에 대한 2 개의 상이한 사용 시나리오를 도시하는 블록도들이다. 도 32는 일 실시예에 따른 칩렛 및 베이스 다이 스택형 접근법을 도시하는 블록도이다."}
