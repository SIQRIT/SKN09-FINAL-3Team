{"patent_id": "10-2020-0070856", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0153919", "출원번호": "10-2020-0070856", "발명의 명칭": "다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델의 결합", "출원인": "한양대학교 산학협력단", "발명자": "장준혁"}}
{"patent_id": "10-2020-0070856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터로 구현되는 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델의 결합 학습 방법에 있어서, 잡음 및 잔향이 존재하는 환경에서 입력되는 다채널 음향 신호를 심화 신경망 기반의 WPE(Weighted PredictedError) 잔향 제거 기술을 이용하여 잔향을 제거하는 단계; 상기 잔향이 제거된 다채널 음향 신호를 심화 신경망 기반의 MVDR(Minimum Variance Distortionless Response)빔포밍 기술을 이용하여 잡음을 제거하는 단계; 및 상기 잡음이 제거된 단일 채널의 향상된 음향 신호를 합성곱 순환 신경망(convolutional recurrent neuralnetwork) 기반의 음향 인지 모델로 입력하는 단계를 포함하고, 상기 잔향을 제거하는 잔향 제거 모델, 상기 빔포밍을 수행하는 빔포밍 모델, 및 상기 음향 인지 모델은 하나의결합된 신경망으로 동작하는 것을 특징으로 하는, 결합 학습 방법."}
{"patent_id": "10-2020-0070856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 잔향 제거 모델, 상기 빔포밍 모델, 및 상기 음향 인지 모델은 상기 음향 인지 모델의 출력과 타겟에 의해계산되는 에러에 의하여 결합 학습하는 단계를 더 포함하는, 결합 학습 방법."}
{"patent_id": "10-2020-0070856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 다채널 음향 신호를 심화 신경망 기반의 WPE 잔향 제거 기술을 이용하여 잔향을 제거하는 단계는, 상기 다채널 음향 신호를 STFT(short-time Fourier Transform)를 통하여 시간 축에서 주파수 축의 값으로 변환하는 단계; 및 변환된 주파수 축의 STFT 계수는 상기 심화 신경망 기반의 WPE 잔향 제거 기술을 이용하여 추정된 spectralmask에 의해 향상되는 단계를 포함하는, 결합 학습 방법."}
{"patent_id": "10-2020-0070856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 잔향이 제거된 다채널 음향 신호를 심화 신경망 기반의 MVDR 빔포밍 기술을 이용하여 잡음을 제거하는 단계는, 상기 잔향이 제거된 다채널 음향 신호의 STFT 계수는 상기 심화 신경망 기반의 MVDR 빔포밍 기술을 이용하여 추정된 두 종류의 spectral mask에 의해 향상되는 것을 특징으로 하는, 결합 학습 방법."}
{"patent_id": "10-2020-0070856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2021-0153919-3-제1항에 있어서,상기 잡음이 제거된 단일 채널의 향상된 음향 신호를 합성곱 순환 신경망 기반의 음향 인지 모델로 입력하는 단계는, 상기 잡음이 제거된 단일 채널의 향상된 음향 신호의 STFT 계수는 로그 스케일(log scale)의 멜 필터 뱅크(melfilter bank)로 변환되어 합성곱 순환 신경망(convolutional recurrent neural network) 기반의 음향 인지 모델로 입력되는 것을 특징으로 하는, 결합 학습 방법."}
{"patent_id": "10-2020-0070856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 잡음이 제거된 단일 채널의 향상된 음향 신호를 합성곱 순환 신경망 기반의 음향 인지 모델로 입력하는 단계는, 상기 합성곱 순환 신경망의 합성곱 모듈에서 주파수 축만 고려하여 합성곱을 진행하는 방법과 주파수 축과 시간축을 순차적으로 고려하여 합성곱을 진행하는 방법을 병렬로 연결한 후 결합시키는 것을 특징으로 하는, 결합 학습 방법."}
{"patent_id": "10-2020-0070856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서,상기 잔향 제거 모델, 상기 빔포밍 모델, 및 상기 음향 인지 모델은 상기 음향 인지 모델의 출력과 타겟에 의해계산되는 에러에 의하여 결합 학습하는 단계는, 신경망의 손실 함수를 focal loss로 설정하여 데이터 양의 불균형을 완화하는 것을 특징으로 하는, 결합 학습 방법."}
{"patent_id": "10-2020-0070856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델의 결합 학습 장치에 있어서, 잡음 및 잔향이 존재하는 환경에서 입력되는 다채널 음향 신호를 심화 신경망 기반의 WPE(Weighted PredictedError) 잔향 제거 기술을 이용하여 잔향을 제거하는 잔향 제거 모델; 상기 잔향이 제거된 다채널 음향 신호를 심화 신경망 기반의 MVDR(Minimum Variance Distortionless Response)빔포밍 기술을 이용하여 잡음을 제거하는 빔포밍 모델; 및 상기 잡음이 제거된 단일 채널의 향상된 음향 신호를 합성곱 순환 신경망(convolutional recurrent neuralnetwork) 기반의 음향 인지 모델로 입력하는 음향 인지 모델을 포함하고, 상기 잔향 제거 모델, 상기 빔포밍 모델, 및 상기 음향 인지 모델은 하나의 결합된 신경망으로 동작하는 것을 특징으로 하는, 결합 학습 장치."}
{"patent_id": "10-2020-0070856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 잔향 제거 모델, 상기 빔포밍 모델, 및 상기 음향 인지 모델은 상기 음향 인지 모델의 출력과 타겟에 의해계산되는 에러에 의하여 결합 학습하는 학습부를 더 포함하는, 결합 학습 장치."}
{"patent_id": "10-2020-0070856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2021-0153919-4-제8항에 있어서,상기 잔향 제거 모델은, 상기 다채널 음향 신호를 STFT(short-time Fourier Transform)를 통하여 시간 축에서 주파수 축의 값으로 변환하고, 변환된 주파수 축의 STFT 계수는 상기 심화 신경망 기반의 WPE 잔향 제거 기술을 이용하여 추정된spectral mask에 의해 향상되는 것을 특징으로 하는, 결합 학습 장치."}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델의 결합 학습 방법 및 장치 가 제시된다. 일 실시예에 따른 컴퓨터로 구현되는 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델의 결합 학습 방법은, 잡음 및 잔향이 존재하는 환경에서 입력되는 다채널 음향 신호를 (뒷면에 계속)"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 실시예들은 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델의 결 합 학습 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음향 인지란 주어진 마이크 입력 신호에서 발생한 음향의 시작 위치(onset)와 종료 위치(offset)를 찾고 해당 음향의 종류(예컨대, 기침소리, 키보드소리, 말소리, 벨소리 등)를 분류하는 기술이다. (비특허문헌 1)에서는 심화 신경망 기반의 잔향 제거와 빔포밍 모듈을 시스템적으로 결합하기 위한 다양한 방법 에 대해 연구를 진행하여 잡음과 잔향이 존재하는 환경에서의 음성 인식 실험을 진행하였다. (비특허문헌 2)에 서는 심화 신경망 기반의 잔향 제거와 빔포밍 모듈을 x-vector 기반의 화자 검증 모듈과 결합하여 학습하는 방 법을 제안하였다. (비특허문헌 3)에서는 합성곱 순환 신경망을 이용하여 음향을 인지하고 음향의 방향 추정을 동시에 실행하는 방법을 제안하였다. 종래의 음향 인지 기술은 신경망 모델 자체의 구조 변경을 통하여(예컨대, 합성곱 순환 신경망) 성능 향상을 도 모하거나 다른 기능(예컨대, 방향 추정)을 동시에 실행하기 위한 연구가 주로 진행되었다. 유사 분야인 음성 인식 또는 화자 검증 분야에서 사용되는 음성 신호와 달리, 음향 신호는 매우 다양한 특성을 가지므로, 앞 단 (front-end)에 전처리 모듈을 통하여 음향 신호를 향상시킴으로써 음향 인지 성능을 향상시키려는 시도가 많지 않았다. 이와 같이 종래의 기술은 단순히 합성곱 순환 신경망 기반의 음향 인지 모델을 사용함으로써 잡음 및 잔향 환경 에서 강인하지 못하며, 다채널 음향 신호를 사용하는 이점을 활용하지 못하고 있다. 선행기술문헌 비특허문헌 (비특허문헌 0001) “Integrating neural network based beamforming and weighted prediction error dereverberation,” L. Drude, C. Boeddeker, J. Heymann, R. Haeb-Umbach, K. Kinoshita, M. Delcroix, and T. Nakatani, University of Paderborn & NTT, Interspeech, 2018. (비특허문헌 0002) “Joint optimization of neural acoustic beamforming and dereverberation with x- vectors for robust speaker verification,\" J.-Y. Yang and J.-H. Chang, Hanyang University, Interspeech, 2019. (비특허문헌 0003) “Sound event localization and detection of overlapping sources using convolutional recurrent neural networks,” S. Adavanne, A. Politis, J. Nikunen, and T. Virtanen, Tampere University of Technology, IEEE Journal of Selected Topics in Signal Processing, 2018."}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예들은 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델의 결합 학습 방법 및 장치에 관하여 기술하며, 보다 구체적으로 잡음과 잔향이 존재하는 환경에서 다채널 음향 신호를 이용 하여 강인한 음향인지 시스템을 구성하는 기술을 제공한다. 실시예들은 다채널 음향 신호를 이용하여 심화 신경망(deep neural network) 기반의 잔향 제거 (dereverberation)와 빔포밍(beamforming) 및 음향 인지(sound event detection) 모델을 결합 학습함으로써 잡 음 및 잔향이 존재하는 환경에서 향상된 성능을 획득할 수 있는, 다채널 음향 신호를 이용한 심화 신경망 기반 의 잔향 제거, 빔포밍 및 음향 인지 모델의 결합 학습 방법 및 장치를 제공하는데 있다."}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 컴퓨터로 구현되는 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음 향 인지 모델의 결합 학습 방법은, 잡음 및 잔향이 존재하는 환경에서 입력되는 다채널 음향 신호를 심화 신경 망 기반의 WPE(Weighted Predicted Error) 잔향 제거 기술을 이용하여 잔향을 제거하는 단계; 상기 잔향이 제거 된 다채널 음향 신호를 심화 신경망 기반의 MVDR(Minimum Variance Distortionless Response) 빔포밍 기술을 이용하여 잡음을 제거하는 단계; 및 상기 잡음이 제거된 단일 채널의 향상된 음향 신호를 합성곱 순환 신경망 (convolutional recurrent neural network) 기반의 음향 인지 모델로 입력하는 단계를 포함하고, 상기 잔향을 제거하는 잔향 제거 모델, 상기 빔포밍을 수행하는 빔포밍 모델, 및 상기 음향 인지 모델은 하나의 결합된 신경 망으로 동작할 수 있다. 상기 잔향 제거 모델, 상기 빔포밍 모델, 및 상기 음향 인지 모델은 상기 음향 인지 모델의 출력과 타겟에 의해 계산되는 에러에 의하여 결합 학습하는 단계를 더 포함할 수 있다. 상기 다채널 음향 신호를 심화 신경망 기반의 WPE 잔향 제거 기술을 이용하여 잔향을 제거하는 단계는, 상기 다 채널 음향 신호를 STFT(short-time Fourier Transform)를 통하여 시간 축에서 주파수 축의 값으로 변환하는 단 계; 및 변환된 주파수 축의 STFT 계수는 상기 심화 신경망 기반의 WPE 잔향 제거 기술을 이용하여 추정된 spectral mask에 의해 향상되는 단계를 포함할 수 있다. 상기 잔향이 제거된 다채널 음향 신호를 심화 신경망 기반의 MVDR 빔포밍 기술을 이용하여 잡음을 제거하는 단 계는, 상기 잔향이 제거된 다채널 음향 신호의 STFT 계수는 상기 심화 신경망 기반의 MVDR 빔포밍 기술을 이용 하여 추정된 두 종류의 spectral mask에 의해 향상될 수 있다. 상기 잡음이 제거된 단일 채널의 향상된 음향 신호를 합성곱 순환 신경망 기반의 음향 인지 모델로 입력하는 단 계는, 상기 잡음이 제거된 단일 채널의 향상된 음향 신호의 STFT 계수는 로그 스케일(log scale)의 멜 필터 뱅 크(mel filter bank)로 변환되어 합성곱 순환 신경망(convolutional recurrent neural network) 기반의 음향 인지 모델로 입력될 수 있다. 상기 잡음이 제거된 단일 채널의 향상된 음향 신호를 합성곱 순환 신경망 기반의 음향 인지 모델로 입력하는 단 계는, 상기 합성곱 순환 신경망의 합성곱 모듈에서 주파수 축만 고려하여 합성곱을 진행하는 방법과 주파수 축 과 시간 축을 순차적으로 고려하여 합성곱을 진행하는 방법을 병렬로 연결한 후 결합시킬 수 있다. 상기 잔향 제거 모델, 상기 빔포밍 모델, 및 상기 음향 인지 모델은 상기 음향 인지 모델의 출력과 타겟에 의해 계산되는 에러에 의하여 결합 학습하는 단계는, 신경망의 손실 함수를 focal loss로 설정하여 데이터 양의 불균 형을 완화할 수 있다. 다른 실시예에 따른 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델의 결 합 학습 장치는, 잡음 및 잔향이 존재하는 환경에서 입력되는 다채널 음향 신호를 심화 신경망 기반의 WPE(Weighted Predicted Error) 잔향 제거 기술을 이용하여 잔향을 제거하는 잔향 제거 모델; 상기 잔향이 제거 된 다채널 음향 신호를 심화 신경망 기반의 MVDR(Minimum Variance Distortionless Response) 빔포밍 기술을 이용하여 잡음을 제거하는 빔포밍 모델; 및 상기 잡음이 제거된 단일 채널의 향상된 음향 신호를 합성곱 순환 신경망(convolutional recurrent neural network) 기반의 음향 인지 모델로 입력하는 음향 인지 모델을 포함하 고, 상기 잔향 제거 모델, 상기 빔포밍 모델, 및 상기 음향 인지 모델은 하나의 결합된 신경망으로 동작할 수 있다. 상기 잔향 제거 모델, 상기 빔포밍 모델, 및 상기 음향 인지 모델은 상기 음향 인지 모델의 출력과 타겟에 의해 계산되는 에러에 의하여 결합 학습하는 학습부를 더 포함할 수 있다. 상기 잔향 제거 모델은, 상기 다채널 음향 신호를 STFT(short-time Fourier Transform)를 통하여 시간 축에서 주파수 축의 값으로 변환하고, 변환된 주파수 축의 STFT 계수는 상기 심화 신경망 기반의 WPE 잔향 제거 기술을 이용하여 추정된 spectral mask에 의해 향상될 수 있다. 상기 음향 인지 모델은, 상기 잡음이 제거된 단일 채널의 향상된 음향 신호의 STFT 계수는 로그 스케일(log scale)의 멜 필터 뱅크(mel filter bank)로 변환되어 합성곱 순환 신경망(convolutional recurrent neural network) 기반의 음향 인지 모델로 입력될 수 있다."}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예들에 따르면 다채널 음향 신호를 이용하여 심화 신경망(deep neural network) 기반의 잔향 제거 (dereverberation)와 빔포밍(beamforming) 및 음향 인지(sound event detection) 모델을 결합 학습함으로써 잡 음 및 잔향이 존재하는 환경에서 향상된 성능을 획득할 수 있는, 다채널 음향 신호를 이용한 심화 신경망 기반 의 잔향 제거, 빔포밍 및 음향 인지 모델의 결합 학습 방법 및 장치를 제공할 수 있다."}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 실시예들을 설명한다. 그러나, 기술되는 실시예들은 여러 가지 다른 형태로 변 형될 수 있으며, 본 실시예의 범위가 이하 설명되는 실시예들에 의하여 한정되는 것은 아니다. 또한, 여러 실"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "시예들은 당해 기술분야에서 평균적인 지식을 가진 자에게 본 실시예를 더욱 완전하게 설명하기 위해서 제공되 는 것이다. 도면에서 요소들의 형상 및 크기 등은 보다 명확한 설명을 위해 과장될 수 있다. 아래의 실시예들은 다채널 음향 신호를 이용하여 심화 신경망(deep neural network) 기반의 잔향 제거 (dereverberation)와 빔포밍(beamforming) 및 음향 인지(sound event detection) 모델을 결합 학습함으로써 잡 음 및 잔향이 존재하는 환경에서 향상된 성능을 얻는 것을 목적으로 한다. 도 1은 일 실시예에 따른 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델 의 결합 학습 방법을 설명하기 위한 도면이다. 도 1을 참조하면, 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거 모델, 빔포밍 모델 및 음향 인지 모델의 결합 학습 방법을 나타내는 것으로, 먼저 잔향 제거 모델은 잡음 및 잔향이 존재하 는 환경에서 입력되는 다채널 음향 신호를 STFT(short-time Fourier Transform)를 통하여 시간 축에서 주파수 축의 값으로 변환한다. 변환된 주파수 축의 STFT 계수는 심화 신경망 기반의 WPE(Weighted Predicted Error) 잔향 제거 기술을 이용하여 추정된 spectral mask에 의해 향상된다. 다음으로, 빔포밍 모델에서 잔향이 제거된 다채널의 향상된 음향 신호 STFT 계수는 심화 신경망 기반의 MVDR(Minimum Variance Distortionless Response) 빔포밍 기술을 이용하여 추정된 두 종류의 spectral mask(source mask와 noise mask)에 의해 향상된다. 결과적으로, 잡음이 제거된 단일 채널의 향상된 음향 신호 STFT 계수는 로그 스케일(log scale)의 멜 필터 뱅크 (mel filter bank)로 변환되어 합성곱 순환 신경망(convolutional recurrent neural network) 기반의 음향 인 지 모델로 입력된다. 잔향 제거 모델, 빔포밍 모델 및 음향 인지 모델의 세 개의 모델은 하나의 결합된 신경망으로 동작하며, 학습 시 음향 인지 모델의 출력과 타겟에 의해 계산되는 에러에 의하여 공동으로 학습된다. 이 때, 불균형한 음향 데이터의 양으로 인하여 모델의 학습 능력이 저하되는 현상을 완화하기 위해 focal loss가에러 계산에 사용된다. 실험 결과, focal loss를 손실 함수로써 이용하여 결합 학습된 심화 신경망 기반의 잔향 제거 모델, 빔포 밍 모델 및 음향 인지 모델은 잡음과 잔향이 존재하는 환경에서 향상된 음향 인지 성능을 보였다. 도 2는 일 실시예에 따른 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델 의 결합 학습 방법을 나타내는 흐름도이다. 도 2를 참조하면, 일 실시예에 따른 컴퓨터로 구현되는 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제 거, 빔포밍 및 음향 인지 모델의 결합 학습 방법은, 잡음 및 잔향이 존재하는 환경에서 입력되는 다채널 음향 신호를 심화 신경망 기반의 WPE(Weighted Predicted Error) 잔향 제거 기술을 이용하여 잔향을 제거하는 단계 (S110), 잔향이 제거된 다채널 음향 신호를 심화 신경망 기반의 MVDR(Minimum Variance Distortionless Response) 빔포밍 기술을 이용하여 잡음을 제거하는 단계(S120), 및 잡음이 제거된 단일 채널의 향상된 음향 신 호를 합성곱 순환 신경망(convolutional recurrent neural network) 기반의 음향 인지 모델로 입력하는 단계 (S130)를 포함하고, 잔향을 제거하는 잔향 제거 모델, 빔포밍을 수행하는 빔포밍 모델, 및 음향 인지 모델은 하 나의 결합된 신경망으로 동작할 수 있다. 잔향 제거 모델, 빔포밍 모델, 및 음향 인지 모델은 음향 인지 모델의 출력과 타겟에 의해 계산되는 에러에 의 하여 결합 학습하는 단계(S140)를 더 포함할 수 있다. 아래에서 일 실시예에 따른 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모 델의 결합 학습 방법의 각 단계를 설명한다. 일 실시예에 따른 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델의 결합 학습 방법은 일 실시예에 따른 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델의 결합 학습 장치를 예를 들어 보다 상세히 설명할 수 있다. 도 3은 일 실시예에 따른 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델 의 결합 학습 장치를 나타내는 블록도이다. 도 3을 참조하면, 일 실시예에 따른 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델의 결합 학습 장치는 잔향 제거 모델, 빔포밍 모델 및 음향 인지 모델을 포함할 수 있다. 실시예에 따라 결합 학습 장치는 학습부를 더 포함할 수 있다. 단계(S110)에서, 잔향 제거 모델은 잡음 및 잔향이 존재하는 환경에서 입력되는 다채널 음향 신호를 심화 신경망 기반의 WPE(Weighted Predicted Error) 잔향 제거 기술을 이용하여 잔향을 제거할 수 있다. 여기서, 잔 향 제거 모델은 다채널 음향 신호를 STFT(short-time Fourier Transform)를 통하여 시간 축에서 주파수 축의 값으로 변환한 후, 변환된 주파수 축의 STFT 계수는 심화 신경망 기반의 WPE 잔향 제거 기술을 이용하여 추정된 spectral mask에 의해 향상될 수 있다. 단계(S120)에서, 빔포밍 모델은 잔향이 제거된 다채널 음향 신호를 심화 신경망 기반의 MVDR(Minimum Variance Distortionless Response) 빔포밍 기술을 이용하여 잡음을 제거할 수 있다. 여기서, 빔포밍 모델 은 잔향이 제거된 다채널 음향 신호의 STFT 계수는 심화 신경망 기반의 MVDR 빔포밍 기술을 이용하여 추정 된 두 종류의 spectral mask에 의해 향상될 수 있다. 단계(S130)에서, 음향 인지 모델은 잡음이 제거된 단일 채널의 향상된 음향 신호를 합성곱 순환 신경망 (convolutional recurrent neural network) 기반의 음향 인지 모델로 입력할 수 있다. 잔향 제거 모델, 빔포밍 모델 및 음향 인지 모델은 하나의 결합된 신경망으로 동작할 수 있다. 여기서, 음향 인지 모 델에서 잡음이 제거된 단일 채널의 향상된 음향 신호의 STFT 계수는 로그 스케일(log scale)의 멜 필터 뱅 크(mel filter bank)로 변환되어 합성곱 순환 신경망(convolutional recurrent neural network) 기반의 음향 인지 모델로 입력될 수 있다. 음향 인지 모델은 합성곱 순환 신경망의 합성곱 모듈에서 주파수 축만 고려하여 합성곱을 진행하는 방법과 주파수 축과 시간 축을 순차적으로 고려하여 합성곱을 진행하는 방법을 병렬로 연결한 후 결합시킬 수 있다. 단계(S140)에서, 학습부는 잔향 제거 모델, 빔포밍 모델 및 음향 인지 모델은 음향 인지 모델의 출력과 타겟에 의해 계산되는 에러에 의하여 결합 학습할 수 있다. 이 때, 학습부는 신경망 의 손실 함수를 focal loss로 설정하여 데이터 양의 불균형을 완화할 수 있다. 아래에서 일 실시예에 따른 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모 델의 결합 학습 방법 및 장치를 예를 들어 보다 상세히 설명한다. 본 실시예에서는, 종래의 음성 인식 및 화자 검증 분야의 기술을 참고하여 다채널 음향 신호를 이용한 결합된 잔향 제거, 빔포밍 및 음향 인지 모듈을 focal loss 기반의 하나의 손실 함수로써 학습하였다. 이 때, 종래의 기술과 달리, 합성곱 순환 신경망의 세부 모듈을 변형하여 추가적인 성능 향상을 보였으며, 또한 종래의 기술에 서 심화 신경망 기반 잔향 제거 시 STFT 계수를 직접 추정하는 것과 달리, 0~1 사이의 값을 가지는 spectral mask를 추정함으로써 원활한 학습을 가능하게 하였다. 실시예 신호 모델 및 심화 신경망 기반의 WPE 잔향 제거 잡음과 잔향이 존재하는 환경에서 D개의 마이크를 통해 음향 신호를 수집한다고 가정할 때, 마이크에 입력되는 음향 신호는 잔향이 있는 음향 신호와 잡음의 합으로 표현할 수 있으며, 그 식은 아래와 같다. [수학식 1]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이 때, x와 n은 잔향에 의해 열화된 음향 신호와 잡음 신호의 STFT(short-time Fourier transform) 계수를, t, f, d는 각각 time frame index와 frequency-bin index, microphone index를 의미하고, y는 음향 신호와 잡음 신호를 더한 마이크 입력 신호를 의미한다. 또한, 위첨자 (early)와 (late)는 각각 early reflection 신호와 late reflection 신호를 의미하며, 각각의 신호는 원 신호가 공간의 반향 특성에 의하여 열화된 것으로, 전자의 경우 그 시간 간격이 짧아 충분히 허용 가능한 열화로 가정하며, 후자의 경우 그 시간 간격이 비교적 길게 지속 되어 크게 열화된 것으로 제거해야 할 대상으로 본다. 이 때, 잔향 제거를 통해 얻고자 하는 신호는 다음과 같 이 선형 예측 필터에 기반하여 계산된다. [수학식 2]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 는 선형 예측 기법을 통해 추정한 early reflection 신호의 추정값을, 는 선형 예측 알고리즘의 delay를, 와 G는 각각 마이크 입력 신호의 STFT 계수와 선형 예측 필터 계수를 현재 프레임 t를 기준으로 과거 번째 프레임부터 과거 번째 프레임까지 쌓아 놓은 stacked representation이다. 고전적인 WPE 잔향 제거 기술은 입력 신호의 late reflection 성분을 추정하기 위한 선형 예측 필터를 아래와 같은 반복적인 (iterative) 방식으로 추정한다. [수학식 3]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "[수학식 4]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "[수학식 5] [수학식 6]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "이 때, 는 추정한 early reflection 신호의 시간-주파수 축에서의 파워를, R는 선형 예측 필터의 차수 (order)를 의미한다. 반면, 심화 신경망을 활용한 WPE 잔향 제거는 고전적인 WPE 알고리즘의 일부분을 심화신경망을 활용한 로직으로 대체한다. 위의 수학식 3에서의 early reflection 신호의 파워를 추정하는 부분을 심화 신경망으로 대체하게 되며, 이 때, 심화신경망은 마이크 입력 신호 의 파워를 입력 받아 late reflection 성분이 제거된 성분의 파워를 추정하도록 학습된다. 이는 음향 성분과 잡음 성분 모두에서 late reverberation 제거하는 것을 목적으로 심화 신경망을 학습하는 방법이며, 본 실시예에서는 학습을 더욱 원활하게 하기 위하여 값의 범위가 상대적으로 넓은 STFT 계수 대신에 0~1 사이의 값을 가지는 spectral mask를 추정하여 STFT 계수에 곱하는 방법으로 향상된 STFT 계수를 추정한다. Mask의 값이 0~1 사이가 되도록 하기 위해서 mask 추정을 위한 심화 신경망의 출력 레이어에서는 ReLU(Rectified Linear Unit) 함수를 사용한 뒤 출력값이 최대 1이 되도록 상 한값을 설정해 준다. 심화 신경망의 학습이 끝나면 심화 신경망을 이용하여 각 마이크로폰 채널별로 early reflection 신호의 파워 추정값을 계산한 뒤, 모든 채널에 대해 평균을 취하여 수학식 3의 좌변을 대신할 수 있 는 파워 추정값을 계산하고, 수학식 4 내지 수학식 6의 과정을 거쳐 최종적으로는 수학식 2를 통해 early reflection 신호의 STFT 계수를 추정할 수 있다. 심화 신경망 기반의 MVDR 빔포밍 고전적인 MVDR 빔포밍 기술은 빔포밍을 적용한 출력 신호가 왜곡이 없게 하면서 출력 신호에 남아있는 잔여 잡 음의 파워를 최소화하는 것을 목적으로 한다. 이와 같은 최소화 문제를 풀면 아래와 같은 MVDR 이득(gain)을 얻을 수 있다. [수학식 7]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서, 와 는 각각 음향 성분과 잡음 성분의 power spectral density(PSD) 행렬을 나타내며, 는 출 력 채널 선택을 위한 one-hot 벡터를 나타낸다. MVDR 빔포머의 출력은 MVDR 이득(gain)과 입력 신호를 곱하여 얻을 수 있으며, 그 식은 아래와 같이 표현될 수 있다. [수학식 8]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서, 은 시간-주파수 축에서의 빔포머 출력 음향 신호를 의미한다. 반면, 심화 신경망을 활용한 MVDR 빔포머는 고전적인 빔포머 알고리즘의 일부분을 심화 신경망을 활용한 로직으 로 대체한다. 본 실시예에서는 spectral mask 기반 MVDR 빔포머를 사용하였으며, 해당 빔포머는 음성 성분과 잡음 성분에 대한 시간-주파수 축의 spectral mask를 심화 신경망을 이용하여 추정한 뒤, 추정한 mask를 이용하 여 음성 성분과 잡음 성분에 대한 PSD 행렬을 계산하게 된다. 이 때, mask 추정은 마이크 채널 각각에 대해 독 립적으로 이루어지기 때문에 마이크의 개수와 같은 개수의 mask가 음성 성분 및 잡음 성분에 대해 각각 계산된 다. Mask의 값이 0과 1 사이가 되도록 하기 위해서 mask 추정을 위한 심화 신경망의 출력 레이어에서는 시그모 이드(sigmoid) 함수를 사용하여 출력값이 0과 1 사이에서 나타나도록 모델을 설계한다. 음향 성분과 잡음 성분 에 해당하는 spectral mask를 각각 추정하기 때문에, mask 추정을 위한 심화 신경망은 따로 구성되며, 심화 신경망의 학습이 끝나면 아래의 식을 이용하여 음향 성분과 잡음 성분 신호의 PSD 행렬을 추정할 수 있다. [수학식 9]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "이 때, 은 심화신경망을 통해 각 마이크로폰 채널별로 얻은 mask의 추정값을 모든 채널에 대해 평균을 취한 average mask이다. 이와 같은 방식으로 얻은 PSD 행렬을 수학식 7에 대입하여 MVDR 이득(gain)을 구할 수 있다. Mask 추정을 위한 심화 신경망은 입력 신호로부터 계산한 LPS(log-scale power spectra)를 입력 받아 mask를 출력으로 하도록 학 습된다. 합성곱 순환 신경망 기반의 음향 인지 심화 신경망 기반의 WPE 잔향 제거와 MVDR 빔포밍이 순차적으로 완료된 후, 출력된 단일 채널의 향상된 STFT 계 수는 합성곱 순환 신경망 기반의 음향 인지 모델로 입력된다. 이 때, 신경망의 입력으로는 종래 기술과 유사하 게 로그 스케일(log scale)의 멜 필터 뱅크(mel filter bank)가 사용되며, 합성곱 순환 신경망 모델을 이용하여 음향의 시작 위치와 종료 위치를 찾고 해당 음향의 종류를 추정하게 된다. 여기서, 멜 필터 뱅크(mel filter bank)는 STFT 계수의 크기 값에 멜 필터(mel filter)를 적용하여 계산되는 에너지(energy) 값으로, 멜 필터 (mel filter)는 사람의 귀를 모방한 비선형적 필터이다. 도 3은 일 실시예에 따른 합성곱 순환 신경망 모델을 설명하기 위한 도면이다. 도 3을 참조하면, 종래 기술과 일 실시예에 따른 합성곱 순환 신경망 모델을 비교하여 나타낸다. 본 실시예에 서는 종래 기술에서 사용된 합성곱 순환 신경망에서 합성곱 파트를 변형하여 성능 향상을 도모하였다. 기존의 합성곱 파트에서는 3x3 합성곱 필터를 여러 층 사용하여 시간-주파수 축의 특징을 추출하는 방법을 사용하였으 나, 본 실시예에서는 주파수 축만 고려하여 합성곱을 진행하는 방법과 주파수 축과 시간 축을 순차적으로 고려 하여 합성곱을 진행하는 방법을 병렬로 연결한 후 결합시키는 방법을 사용함으로써 더욱 효과적으로 특징을 추 출하고 향상된 성능을 얻을 수 있다. 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델 결합 학습 방법 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델은 모두 미분 가능한 연산으로만 구성되어 있으며, 따 라서 하나의 신경망으로 연결되어 결합 학습이 가능하다. 이 때, 신경망 학습의 에러 역전파를 위하여, 손실 함수로는 focal loss가 사용될 수 있다. 음향 데이터는 음향의 특성 상, 짧은 음향부터 시작하여 긴 음향까지 매우 다양하며, 음성처럼 연구용으로 체계적으로 수집 및 관리가 되기 시작한지 얼마되지 않아 그 데이터의 양 이 매우 다양하다고 할 수 있다. 신경망 학습은 일반적으로 각 클래스의 데이터의 양이 동일해야 효율적인 학 습이 가능한데, 음향 인지에서는 데이터 양의 불균형으로 인하여 신경망 학습에 항상 어려움이 있어왔고, 그것 을 완화하기 위하여 다양한 방법들이 제안되었다. 본 실시예에서는 영상 분야에서 제안된 focal loss를 음향 인지 분야에 도입하여 데이터 양의 불균형을 자동으로 보상함으로써 성능 향상을 도모하였다. [수학식 10]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "[수학식 11] 여기서, gt는 정답을 나타내며, 즉 1이면 해당 시간에 음향이 존재하는 것을 의미하고, 0이면 해당 시간에 음향 이 존재하지 않는 것을 의미한다. p는 신경망 모델에서 추정한 음향 존재 확률, 그리고 는 focal loss의 focusing 파라미터를 나타낸다. Focal loss는 분류가 매우 손쉽게 되는 데이터에 패널티를 줌으로써 동작하는 손실 함수이다. 일반적으로 데이 터 양이 많은 클래스의 경우 분류가 매우 손쉽게 되며, 이 때 신경망 모델에서 추정한 음향 존재 확률 p의 값이 매우 크게 된다. 수학식 10에 의하면, p의 값이 매우 크면 focusing 파라미터 에 의하여 에러가 강제로 작게 반영되게 된다. 한편, 결합 학습 시 WPE 잔향 제거와 MVDR 빔포밍 알고리즘은 모두 복소수 값을 갖는 STFT 계수들을 처리하는 연산들로 구성되어 있기 때문에, 결합 학습을 실제로 구현하기 위해서는 복소수의 실수부와 허수부를 별도로 연 산할 필요가 있다. 특히, 수학식 6 및 수학식 7에서 나타나는 복소수 행렬의 역(inverse) 연산은 아래와 같은 공식을 통해 해결할 수 있다. [수학식 12]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "[수학식 13]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "여기서, 는 복소수 행렬이며, 와 는 각각 역행렬이 존재하는 실수 행렬이다. 실험 결과 본 실시예의 평가를 위하여, 잡음과 잔향이 존재하는 실내 환경에서 다채널 마이크로 녹음된 음향 신호로 구성 된 TAU Spatial Sound Events 2019-Microphone Array 공개 데이터셋을 사용하였다. 본 데이터셋은 사면체 구 조의 4채널 마이크로 녹음되었으며, 500개의 파일로 구성되어 있다. 각 파일은 1분 길이이며, 샘플링 주파수는 48,000 Hz이고, 신호대잡음비는 30 dB로, 잡음이 강하지는 않은 편이다. 잡음이 강한 환경에서의 평가를 위하 여, 실내에서 녹음된 잡음을 10 dB의 신호대잡음비로 더하여 추가적인 평가에 사용하였다. 본 데이터셋에서 고 려되는 음향 종류는 총 11가지로, 목 가다듬는 소리, 기침 소리, 노크 소리, 문 닫는 소리, 서랍 여닫는 소리, 웃는 소리, 키보드 소리, 키를 테이블에 놓는 소리, 책장을 넘기는 소리, 전화벨 소리, 말 소리이며, 각 종류 당 20개의 파일이 사용되었다. 신경망 학습은 데이터의 양에 따라 학습의 효과가 크게 달라지므로, 신경망 학 습의 효과를 향상시키기 위하여 pitch shifting 및 block mixing의 두 가지 데이터 증폭 방법이 사용되었다. 음향 인지 알고리즘은 일반적으로 F-score 및 error rate(ER) 두 가지 지표로 평가된다. 지표를 계산하는 방법 은 여러 가지가 있을 수 있으나, 본 실시예에서는 겹치는 부분 없이 1초 단위의 segment를 shifting하며 결과와 정답을 비교하는 방법으로 계산하였다. F-score는 다음과 같이 정의될 수 있다. [수학식 14]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "이 때, K는 세그먼트(segment)의 총 개수, TP는 true positive(정답과 결과가 모두 1일 때)의 개수, FP는 false positive(정답이 0인데 결과가 1일 때)의 개수, FN은 false negative(정답이 1인데 결과가 0일 때)의 개 수를 나타낸다. 다음으로, ER은 아래와 같이 정의될 수 있다. [수학식 15] 이 때, N(k)는 정답이 1인 것의 총 개수를 나타내며, S(k), D(k) 및 I(k)는 각각 substitution, deletion, insertion의 약자로 아래와 같이 정의될 수 있다. [수학식 16]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "[수학식 17]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "[수학식 18]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "가장 이상적인 조건에서는, F-score는 1이 되며, ER은 0이 된다. 표 1은 일 실시예에 따른 TAU Spatial Sound Events 2019-Microphone Array 데이터셋을 이용한 F-score 및 ER 결과를 나타낸다. [표 1]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "표 2는 일 실시예에 따른 TAU Spatial Sound Events 2019-Microphone Array 데이터셋에 실내 잡음을 10 dB로 더한 데이터셋을 이용한 F-score 및 ER 결과를 나타낸다. [표 2]"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 19, "content": "실험 결과 음향 인지 모델에 사용된 합성곱 파트의 변형으로 인하여 종래 기술보다 F-score가 1~2% 향상되었으 며, ER이 유사 수준인 것을 알 수 있다. 또한 심화 신경망 기반의 WPE 잔향 제거 및 MVDR 빔포밍과 결합 학습 함으로써 대폭 성능 향상이 있었으며, 특히 세 개의 모듈을 결합 학습하였을 때 성능이 가장 좋았다. 특히, 잡 음 및 잔향이 상대적으로 강한 신호 대 잡음비 10 dB 환경에서는, F-score가 종래 기술 대비 10%, ER이 0.2 수 준 향상되었다. 또한 결합 학습 시 신경망의 손실 함수로 focal loss를 사용하였을 때, 기존의 크로스 엔트로 피(cross entropy)를 손실 함수로 사용하였을 때에 대비하여 다소 성능이 향상되었다. 본 실시예에 따른 심화 신경망 기반의 WPE 잔향 제거와 MVDR 빔포밍 및 음향 인지 모델의 결합 학습 기법을 이 용하여 잡음과 잔향이 존재하는 환경에서 다채널 마이크를 통해 음향을 입력하여 처리하는 경우, 특히 실내 환 경에서 스마트폰, 인공지능 스피커, 로봇, CCTV 등에 적용될 수 있는 음향 인지 기반 어플리케이션에 적용되어 향상된 성능을 기대할 수 있다. 이상과 같이, 실시예들은 잡음과 잔향이 존재하는 환경에서 다채널 음향 신호를 이용하여 강인한 음향인지 시스 템을 구성하는 방법에 관한 것이다. 실시예들에 따르면 잡음과 잔향이 존재하는 환경에서 음향 인지를 필요로 하는 스마트폰, 인공지능 스피커, 로봇, CCTV 등에 적용되어 음향 인지의 성능을 향상시킬 수 있으며, 마이크 특성을 반영하기 위하여 해당 마이크로 수집된 음향 신호를 학습에 사용하거나 또는 마이크 특성에 적응하는 adaptation 기술을 사용하여 최적화된 성능을 얻을 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 컨트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPA(field programmable array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 20, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2020-0070856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 21, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2020-0070856", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델 의 결합 학습 방법을 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델 의 결합 학습 방법을 나타내는 흐름도이다. 도 3은 일 실시예에 따른 다채널 음향 신호를 이용한 심화 신경망 기반의 잔향 제거, 빔포밍 및 음향 인지 모델 의 결합 학습 장치를 나타내는 블록도이다. 도 4는 일 실시예에 따른 합성곱 순환 신경망 모델을 설명하기 위한 도면이다."}
