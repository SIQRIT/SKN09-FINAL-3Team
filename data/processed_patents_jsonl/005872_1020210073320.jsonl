{"patent_id": "10-2021-0073320", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0164957", "출원번호": "10-2021-0073320", "발명의 명칭": "인공지능 및 사물인식을 이용한 이미지 기반의 장소 추정 방법 및 이를 수행하는 컴퓨팅 시스", "출원인": "(주)위버스마인드", "발명자": "정성은"}}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "입력 레이어를 통해 입력된 이미지를 입력받아 입력된 이미지에 상응하는 장소를 판단하기 위한 출력 값을 출력레이어를 통해 출력하는 인공 뉴럴 네트워크인 장소 검출 모델(place detection model);입력 레이어를 통해 이미지를 입력받아 입력된 이미지에 포함된 1 이상의 오브젝트를 검출하기 위한 출력 값을출력 레이어를 통해 출력하는 인공 뉴럴 네트워크인 오브젝트 검출 모델(object detection model); 및오브젝트의 집합, 장소 및 빈도로 구성된 항목의 리스트인 이미지 기반 딕셔너리-여기서, 상기 이미지 기반 딕셔너리 내의 각 항목의 빈도는, 해당 항목의 집합 내의 오브젝트 모두가 해당 항목의 장소에 등장한 빈도를 나타냄-를 저장하는 저장모듈; 및소정의 판단 대상 이미지에 상응하는 장소를 결정하는 결정모듈을 포함하되,상기 결정모듈은,상기 장소 검출 모델에 상기 판단 대상 이미지를 입력하고, 상기 장소 검출 모델이 출력한 출력 값에 기초하여상기 판단 대상 이미지에 상응하는 제1예상장소를 판단하는 제1판단모듈;상기 오브젝트 검출 모델에 상기 판단 대상 이미지를 입력하고, 상기 오브젝트 검출 모델이 출력하는 출력 값에기초하여 상기 판단 대상 이미지에 포함된 1 이상의 오브젝트를 검출하는 오브젝트 검출 모듈;상기 이미지 기반 딕셔너리에 포함된 항목 중 어느 하나를 상기 판단 대상 이미지의 매칭 항목으로 판단하고-여기서 상기 매칭 항목은, 상기 판단 대상 이미지에 포함된 상기 1 이상의 오브젝트를 모두 포함하는 집합을 가진항목 중 가장 빈도가 큰 항목임-, 상기 매칭 항목의 장소를 제2예상장소로 판단하는 제2판단모듈; 및상기 제1예상장소 및 상기 제2예상장소 중 어느 하나를 상기 판단 대상 이미지에 상응하는 장소로 결정하는 장소결정모듈을 포함하는 이미지 기반 장소 추정 시스템."}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,복수의 학습용 이미지를 획득하는 학습용 이미지 획득모듈-상기 복수의 학습용 이미지 각각은, 해당 학습용 이미지에 상응하는 장소가 각각 태깅되어 있음;상기 복수의 학습용 이미지 각각을, 상기 장소 검출 모델에 입력하여 상기 장소 검출 모델을 학습하는학습모듈;상기 복수의 학습용 이미지 각각에 대하여,상기 학습용 이미지를 상기 오브젝트 검출 모델에 입력하여 상기 학습용 이미지에 포함된 적어도 하나의 오브젝트를 검출하고, 검출된 상기 적어도 하나의 오브젝트 및 상기 학습용 이미지에 태깅된 장소에 기초하여 상기 이미지 기반 딕셔너리를 업데이트하는 이미지 기반 딕셔너리 구축모듈을 더 포함하는 이미지 기반 장소 추정 시스템."}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 이미지 기반 딕셔너리 구축모듈은,검출된 상기 적어도 하나의 오브젝트로 구성된 집합의 모든 부분 집합 각각에 대하여,공개특허 10-2022-0164957-3-상기 이미지 기반 딕셔너리에 포함된 항목 중 상기 부분 집합 및 상기 학습용 이미지에 태깅된 장소에 해당하는항목의 빈도를 증가시키는 이미지 기반 장소 추정 시스템."}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 장소결정모듈은,상기 장소 검출 모델이 출력한 상기 출력 값이 소정의 임계 값 이상인 경우, 상기 제1예상장소를 상기 판단 대상 이미지에 상응하는 장소로 결정하고,상기 장소 검출 모델이 출력한 상기 출력 값이 상기 임계 값 미만인 경우, 상기 제1예상장소가 상기 제2예상장소와 동일하면 상기 제1예상장소를 상기 판단 대상 이미지에 상응하는 장소로 결정하고, 상기 제1예상장소가 상기 제2예상장소와 상이하면 소정의 판단 기준에 의해 상기 제1예상장소 및 상기 제2예상장소 중 어느 하나를 상기 판단 대상 이미지에 상응하는 장소로 결정하는 이미지 기반 장소 추정 시스템."}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 저장모듈은,오브젝트의 집합, 장소 및 빈도로 구성된 항목의 리스트인 텍스트 기반 딕셔너리-여기서, 상기 텍스트 기반 딕셔너리 내의 각 항목의 빈도는, 해당 항목의 집합 내의 오브젝트 모두가 해당 항목의 장소에 등장한 빈도를 나타냄-를 더 저장하고,상기 이미지 기반 장소 추정 시스템은,복수의 학습용 텍스트를 획득하는 학습용 텍스트 획득모듈-여기서 상기 복수의 학습용 텍스트 각각에는 장소가태깅됨; 및상기 복수의 학습용 텍스트 각각에 대하여,상기 학습용 텍스트에서 적어도 하나의 오브젝트를 추출하고, 추출된 상기 적어도 하나의 오브젝트 및 상기 학습용 텍스트에 태깅된 장소에 기초하여 상기 텍스트 기반 딕셔너리를 업데이트하는 텍스트 기반 딕셔너리 구축모듈을 더 포함하고,상기 장소결정모듈은,상기 장소 검출 모델이 출력한 상기 출력 값이 상기 임계 값 미만이고 상기 제1예상장소 및 상기 제2예상장소가상이한 경우, 상기 텍스트 기반 딕셔너리에 기초하여 제1예상장소 및 상기 제2예상장소 중 어느 하나를 상기 판단 대상 이미지에 상응하는 장소로 결정하는 이미지 기반 장소 추정 시스템."}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 텍스트 기반 딕셔너리 구축모듈은,추출된 상기 적어도 하나의 오브젝트로 구성된 집합의 모든 부분 집합 각각에 대하여, 상기 텍스트 기반 딕셔너리에 포함된 항목 중 상기 부분 집합 및 상기 학습용 텍스트에 태깅된 장소에 해당하는항목의 빈도를 증가시키는 이미지 기반 장소 추정 시스템."}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2022-0164957-4-입력 레이어를 통해 이미지를 입력받아 입력된 이미지에 포함된 1 이상의 오브젝트를 검출하기 위한 출력 값을출력 레이어를 통해 출력하는 인공 뉴럴 네트워크인 오브젝트 검출 모델; 및오브젝트의 집합, 장소 및 빈도로 구성된 항목의 리스트인 딕셔너리-여기서, 상기 딕셔너리 내의 각 항목의 빈도는, 해당 항목의 집합 내의 오브젝트 모두가 해당 항목의 장소에 등장한 빈도를 나타냄-를 저장하는저장모듈;복수의 학습용 이미지를 획득하는 학습용 이미지 획득모듈-상기 복수의 학습용 이미지 각각은, 해당 학습용 이미지에 상응하는 장소가 각각 태깅되어 있음;상기 복수의 학습용 이미지 각각에 대하여,상기 학습용 이미지를 상기 오브젝트 검출 모델에 입력하여 상기 학습용 이미지에 포함된 적어도 하나의 오브젝트를 검출하고, 검출된 상기 적어도 하나의 오브젝트 및 상기 학습용 이미지에 태깅된 장소에 기초하여 상기 딕셔너리를 업데이트하는 딕셔너리 구축모듈;소정의 판단 대상 이미지에 상응하는 장소를 결정하는 결정모듈을 포함하되,상기 결정모듈은,상기 오브젝트 검출 모델에 상기 판단 대상 이미지를 입력하고, 상기 오브젝트 검출 모델이 출력하는 출력 값에기초하여 상기 판단 대상 이미지에 포함된 1 이상의 오브젝트를 검출하는 오브젝트 검출 모듈;상기 이미지 기반 딕셔너리에 포함된 항목 중 어느 하나를 상기 판단 대상 이미지의 매칭 항목으로 판단하고-여기서 상기 매칭 항목은, 상기 판단 대상 이미지에 포함된 상기 1 이상의 오브젝트를 모두 포함하는 집합을 가진항목 중 가장 빈도가 큰 항목임-, 상기 매칭 항목의 장소를 상기 판단 대상 이미지에 상응하는 장소로 결정하는장소결정모듈을 포함하는 이미지 기반 장소 추정 시스템."}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "입력 레이어를 통해 입력된 이미지를 입력받아 입력된 이미지에 상응하는 장소를 판단하기 위한 출력 값을 출력레이어를 통해 출력하는 인공 뉴럴 네트워크인 장소 검출 모델(place detection model);입력 레이어를 통해 이미지를 입력받아 입력된 이미지에 포함된 1 이상의 오브젝트를 검출하기 위한 출력 값을출력 레이어를 통해 출력하는 인공 뉴럴 네트워크인 오브젝트 검출 모델(object detection model); 및오브젝트의 집합, 장소 및 빈도로 구성된 항목의 리스트인 이미지 기반 딕셔너리-여기서, 상기 이미지 기반 딕셔너리 내의 각 항목의 빈도는, 해당 항목의 집합 내의 오브젝트 모두가 해당 항목의 장소에 등장한 빈도를 나타냄-를 포함하는 컴퓨팅 시스템에 의해 수행되며, 소정의 판단 대상 이미지에 상응하는 장소를 결정하는 이미지 기반 장소 추정 방법으로서,상기 장소 검출 모델에 상기 판단 대상 이미지를 입력하고, 상기 장소 검출 모델이 출력한 출력 값에 기초하여상기 판단 대상 이미지에 상응하는 제1예상장소를 판단하는 제1판단단계;상기 오브젝트 검출 모델에 상기 판단 대상 이미지를 입력하고, 상기 오브젝트 검출 모델이 출력하는 출력 값에기초하여 상기 판단 대상 이미지에 포함된 1 이상의 오브젝트를 검출하는 오브젝트 검출 단계;상기 이미지 기반 딕셔너리에 포함된 항목 중 어느 하나를 상기 판단 대상 이미지의 매칭 항목으로 판단하고-여기서 상기 매칭 항목은, 상기 판단 대상 이미지에 포함된 상기 1 이상의 오브젝트를 모두 포함하는 집합을 가진항목 중 가장 빈도가 큰 항목임-, 상기 매칭 항목의 장소를 제2예상장소로 판단하는 제2판단단계; 및상기 제1예상장소 및 상기 제2예상장소 중 어느 하나를 상기 판단 대상 이미지에 상응하는 장소로 결정하는 장소결정단계를 포함하는 이미지 기반 장소 추정 방법."}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 이미지 기반 장소 추정 방법은,공개특허 10-2022-0164957-5-복수의 학습용 이미지를 획득하는 학습용 이미지 획득단계-상기 복수의 학습용 이미지 각각은, 해당 학습용 이미지에 상응하는 장소가 각각 태깅되어 있음;상기 복수의 학습용 이미지 각각을, 상기 장소 검출 모델에 입력하여 상기 장소 검출 모델을 학습하는학습단계;상기 복수의 학습용 이미지 각각에 대하여,상기 학습용 이미지를 상기 오브젝트 검출 모델에 입력하여 상기 학습용 이미지에 포함된 적어도 하나의 오브젝트를 검출하고, 검출된 상기 적어도 하나의 오브젝트 및 상기 학습용 이미지에 태깅된 장소에 기초하여 상기 이미지 기반 딕셔너리를 업데이트하는 이미지 기반 딕셔너리 구축단계를 더 포함하는 이미지 기반 장소 추정방법."}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 이미지 기반 딕셔너리 구축단계는,검출된 상기 적어도 하나의 오브젝트로 구성된 집합의 모든 부분 집합 각각에 대하여, 상기 이미지 기반 딕셔너리에 포함된 항목 중 상기 부분 집합 및 상기 학습용 이미지에 태깅된 장소에 해당하는항목의 빈도를 증가시키는 단계를 포함하는 이미지 기반 장소 추정 방법."}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 장소결정단계는,상기 장소 검출 모델이 출력한 상기 출력 값이 소정의 임계 값 이상인 경우, 상기 제1예상장소를 상기 판단 대상 이미지에 상응하는 장소로 결정하는 단계;상기 장소 검출 모델이 출력한 상기 출력 값이 상기 임계 값 미만인 경우, 상기 제1예상장소가 상기 제2예상장소와 동일하면 상기 제1예상장소를 상기 판단 대상 이미지에 상응하는 장소로 결정하는 단계; 및상기 장소 검출 모델이 출력한 상기 출력 값이 상기 임계 값 미만인 경우, 상기 제1예상장소가 상기 제2예상장소와 상이하면 소정의 판단 기준에 의해 상기 제1예상장소 및 상기 제2예상장소 중 어느 하나를 상기 판단 대상이미지에 상응하는 장소로 결정하는 단계를 포함하는 이미지 기반 장소 추정 방법."}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 컴퓨팅 시스템은,오브젝트의 집합, 장소 및 빈도로 구성된 항목의 리스트인 텍스트 기반 딕셔너리-여기서, 상기 텍스트 기반 딕셔너리 내의 각 항목의 빈도는, 해당 항목의 집합 내의 오브젝트 모두가 해당 항목의 장소에 등장한 빈도를 나타냄-를 더 포함하고,상기 이미지 기반 장소 추정 방법은,복수의 학습용 텍스트를 획득하는 학습용 텍스트 획득단계-여기서 상기 복수의 학습용 텍스트 각각에는 장소가태깅됨; 및상기 복수의 학습용 텍스트 각각에 대하여,상기 학습용 텍스트에서 적어도 하나의 오브젝트를 추출하고, 추출된 상기 적어도 하나의 오브젝트 및 상기 학공개특허 10-2022-0164957-6-습용 텍스트에 태깅된 장소에 기초하여 상기 텍스트 기반 딕셔너리를 업데이트하는 텍스트 기반 딕셔너리 구축단계를 더 포함하고,상기 장소결정단계는,상기 장소 검출 모델이 출력한 상기 출력 값이 상기 임계 값 미만이고 상기 제1예상장소 및 상기 제2예상장소가상이한 경우, 상기 텍스트 기반 딕셔너리에 기초하여 제1예상장소 및 상기 제2예상장소 중 어느 하나를 상기 판단 대상 이미지에 상응하는 장소로 결정하는 단계를 포함하는 이미지 기반 장소 추정 방법."}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 텍스트 기반 딕셔너리 구축단계는,추출된 상기 적어도 하나의 오브젝트로 구성된 집합의 모든 부분 집합 각각에 대하여, 상기 텍스트 기반 딕셔너리에 포함된 항목 중 상기 부분 집합 및 상기 학습용 텍스트에 태깅된 장소에 해당하는항목의 빈도를 증가시키는 단계를 포함하는 이미지 기반 장소 추정 방법."}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "입력 레이어를 통해 이미지를 입력받아 입력된 이미지에 포함된 1 이상의 오브젝트를 검출하기 위한 출력 값을출력 레이어를 통해 출력하는 인공 뉴럴 네트워크인 오브젝트 검출 모델; 및오브젝트의 집합, 장소 및 빈도로 구성된 항목의 리스트인 이미지 기반 딕셔너리-여기서, 상기 이미지 기반 딕셔너리 내의 각 항목의 빈도는, 해당 항목의 집합 내의 오브젝트 모두가 해당 항목의 장소에 등장한 빈도를 나타냄-를 포함하는 컴퓨팅 시스템에 의해 수행되며, 소정의 판단 대상 이미지에 상응하는 장소를 결정하는 이미지 기반 장소 추정 방법으로서,복수의 학습용 이미지를 획득하는 학습용 이미지 획득단계-상기 복수의 학습용 이미지 각각은, 해당 학습용 이미지에 상응하는 장소가 각각 태깅되어 있음;상기 복수의 학습용 이미지 각각에 대하여,상기 학습용 이미지를 상기 오브젝트 검출 모델에 입력하여 상기 학습용 이미지에 포함된 적어도 하나의 오브젝트를 검출하고, 검출된 상기 적어도 하나의 오브젝트 및 상기 학습용 이미지에 태깅된 장소에 기초하여 상기 이미지 기반 딕셔너리를 업데이트하는 이미지 기반 딕셔너리 구축단계;소정의 판단 대상 이미지에 상응하는 장소를 결정하는 결정단계를 포함하되,상기 결정단계는,상기 오브젝트 검출 모델에 상기 판단 대상 이미지를 입력하고, 상기 오브젝트 검출 모델이 출력하는 출력 값에기초하여 상기 판단 대상 이미지에 포함된 1 이상의 오브젝트를 검출하는 오브젝트 검출 단계; 및상기 이미지 기반 딕셔너리에 포함된 항목 중 어느 하나를 상기 판단 대상 이미지의 매칭 항목으로 판단하고-여기서 상기 매칭 항목은, 상기 판단 대상 이미지에 포함된 상기 1 이상의 오브젝트를 모두 포함하는 집합을 가진항목 중 가장 빈도가 큰 항목임-, 상기 매칭 항목의 장소를 상기 판단 대상 이미지에 상응하는 장소로 결정하는장소결정단계를 포함하는 이미지 기반 장소 추정 방법."}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "데이터 처리장치에 설치되며 제8항 내지 제14항 중 어느 한 항에 기재된 방법을 수행하기 위한 매체에 기록된컴퓨터 프로그램.공개특허 10-2022-0164957-7-청구항 16 제8항 내지 제14항 중 어느 한 항에 기재된 방법을 수행하기 위한 컴퓨터 프로그램이 기록된 컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2021-0073320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "컴퓨팅 시스템으로서,프로세서; 및 컴퓨터 프로그램을 저장하는 메모리를 포함하고,상기 컴퓨터 프로그램은, 상기 프로세서에 의해 실행되는 경우, 상기 컴퓨팅 시스템으로 하여금 제8항 내지 제14항 중 어느 한 항에 기재된 방법을 수행하도록 하는 컴퓨팅 시스템."}
{"patent_id": "10-2021-0073320", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "장소를 추정하기 위한 인공 뉴럴 네트워크 및 딕셔너리를 이용하여 이미지로부터 해당 이미지가 촬영된 장소를 추정할 수 있는 방법 및 이를 수행하는 컴퓨팅 시스템이 개시된다. 본 발명의 일 측면에 따르면, 입력 레이어를 통해 입력된 이미지를 입력받아 입력된 이미지에 상응하는 장소를 판단하기 위한 출력 값을 출력 레이어를 통해 (뒷면에 계속)"}
{"patent_id": "10-2021-0073320", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이미지 기반의 장소 추정 방법 및 이를 수행하는 컴퓨팅 시스템에 관한 것이다. 보다 상세하게는 장 소를 추정하기 위한 인공 뉴럴 네트워크 및 딕셔너리를 이용하여 이미지로부터 해당 이미지가 촬영된 장소를 추 정할 수 있는 방법 및 이를 수행하는 컴퓨팅 시스템에 관한 것이다."}
{"patent_id": "10-2021-0073320", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근들어 디지털 카메라, 카메라가 장착된 스마트폰와 같이 사진을 촬영할 수 있는 촬영기기가 급속도로 보급됨 과 동시에 이미지에 기반한 다양한 서비스들이 등장하고 있다. 이미지 기반의 서비스를 제공함에 있어서 해당 이미지의 배경이 되는 장소를 특정하는 것은 대단히 유용할 수 있다. 예를 들어, 특정 이미지를 활용하여 외국 어를 학습하는 서비스가 있다고 하면, 해당 서비스에서는 이미지의 배경이 되는 장소에 맞는 예문이나 학습 컨 텐츠를 제공함으로써 학습의 질을 더욱 높일 수 있게 될 수 있다. 이 외에도 이미지로부터 장소를 특정/추정하 는 기술이 다양한 방면에서 유용하게 이용될 수 있음은 너무나 자명하다. 한편, 종래에는 촬영 장치에 내장된 위치 판단 모듈(예를 들어, GPS 등)이 제공하는 정보를 이미지에 태깅함으 로써 해당 이미지가 촬영된 장소를 파악하는 방식이 이용되었는데, 이러한 방식은 이미지가 촬영된 위치의 좌표 를 정확히 파악할 수 있다는 점에서는 매우 유용하지만 해당 이미지가 어떠한 장소적 배경을 가지는지(예를 들 어, 촬영장소가 식당인지, 사무실인지, 호텔인지 등)를 파악하는 데에는 크게 도움이 되지 못한다는 단점이 있 다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허 10-2020-0086570"}
{"patent_id": "10-2021-0073320", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적인 과제는 이미지로부터 장소를 추정할 수 있는 방법 및 시스템을 제공하는 것 이다."}
{"patent_id": "10-2021-0073320", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, 입력 레이어를 통해 입력된 이미지를 입력받아 입력된 이미지에 상응하는 장소를 판단하기 위한 출력 값을 출력 레이어를 통해 출력하는 인공 뉴럴 네트워크인 장소 검출 모델(place detection model); 입력 레이어를 통해 이미지를 입력받아 입력된 이미지에 포함된 1 이상의 오브젝트를 검출하기 위한 출력 값을 출력 레이어를 통해 출력하는 인공 뉴럴 네트워크인 오브젝트 검출 모델(object detection model); 및 오브젝트의 집합, 장소 및 빈도로 구성된 항목의 리스트인 이미지 기반 딕셔너리-여기서, 상기 이미지 기반 딕 셔너리 내의 각 항목의 빈도는, 해당 항목의 집합 내의 오브젝트 모두가 해당 항목의 장소에 등장한 빈도를 나 타냄-를 저장하는 저장모듈; 및 소정의 판단 대상 이미지에 상응하는 장소를 결정하는 결정모듈을 포함하되, 상 기 결정모듈은, 상기 장소 검출 모델에 상기 판단 대상 이미지를 입력하고, 상기 장소 검출 모델이 출력한 출력 값에 기초하여 상기 판단 대상 이미지에 상응하는 제1예상장소를 판단하는 제1판단모듈; 상기 오브젝트 검출 모 델에 상기 판단 대상 이미지를 입력하고, 상기 오브젝트 검출 모델이 출력하는 출력 값에 기초하여 상기 판단 대상 이미지에 포함된 1 이상의 오브젝트를 검출하는 오브젝트 검출 모듈; 상기 이미지 기반 딕셔너리에 포함된 항목 중 어느 하나를 상기 판단 대상 이미지의 매칭 항목으로 판단하고-여기서 상기 매칭 항목은, 상기 판단 대 상 이미지에 포함된 상기 1 이상의 오브젝트를 모두 포함하는 집합을 가진 항목 중 가장 빈도가 큰 항목임-, 상 기 매칭 항목의 장소를 제2예상장소로 판단하는 제2판단모듈; 및 상기 제1예상장소 및 상기 제2예상장소 중 어 느 하나를 상기 판단 대상 이미지에 상응하는 장소로 결정하는 장소결정모듈을 포함하는 이미지 기반 장소 추정 시스템이 제공된다. 일 실시예에서, 복수의 학습용 이미지를 획득하는 학습용 이미지 획득모듈-상기 복수의 학습용 이미지 각각은, 해당 학습용 이미지에 상응하는 장소가 각각 태깅되어 있음; 상기 복수의 학습용 이미지 각각을, 상기 장소 검 출 모델에 입력하여 상기 장소 검출 모델을 학습하는 학습모듈; 상기 복수의 학습용 이미지 각각에 대하여, 상 기 학습용 이미지를 상기 오브젝트 검출 모델에 입력하여 상기 학습용 이미지에 포함된 적어도 하나의 오브젝트 를 검출하고, 검출된 상기 적어도 하나의 오브젝트 및 상기 학습용 이미지에 태깅된 장소에 기초하여 상기 이미 지 기반 딕셔너리를 업데이트하는 이미지 기반 딕셔너리 구축모듈을 더 포함할 수 있다. 일 실시예에서, 상기 이미지 기반 딕셔너리 구축모듈은, 검출된 상기 적어도 하나의 오브젝트로 구성된 집합의 모든 부분 집합 각각에 대하여, 상기 이미지 기반 딕셔너리에 포함된 항목 중 상기 부분 집합 및 상기 학습용 이미지에 태깅된 장소에 해당하는 항목의 빈도를 증가시킬 수 있다. 일 실시예에서, 상기 장소결정모듈은, 상기 장소 검출 모델이 출력한 상기 출력 값이 소정의 임계 값 이상인 경 우, 상기 제1예상장소를 상기 판단 대상 이미지에 상응하는 장소로 결정하고, 상기 장소 검출 모델이 출력한 상 기 출력 값이 상기 임계 값 미만인 경우, 상기 제1예상장소가 상기 제2예상장소와 동일하면 상기 제1예상장소를 상기 판단 대상 이미지에 상응하는 장소로 결정하고, 상기 제1예상장소가 상기 제2예상장소와 상이하면 소정의 판단 기준에 의해 상기 제1예상장소 및 상기 제2예상장소 중 어느 하나를 상기 판단 대상 이미지에 상응하는 장 소로 결정할 수 있다. 일 실시예에서, 상기 저장모듈은, 오브젝트의 집합, 장소 및 빈도로 구성된 항목의 리스트인 텍스트 기반 딕셔 너리-여기서, 상기 텍스트 기반 딕셔너리 내의 각 항목의 빈도는, 해당 항목의 집합 내의 오브젝트 모두가 해당 항목의 장소에 등장한 빈도를 나타냄-를 더 저장하고, 상기 이미지 기반 장소 추정 시스템은, 복수의 학습용 텍 스트를 획득하는 학습용 텍스트 획득모듈-여기서 상기 복수의 학습용 텍스트 각각에는 장소가 태깅됨; 및 상기 복수의 학습용 텍스트 각각에 대하여, 상기 학습용 텍스트에서 적어도 하나의 오브젝트를 추출하고, 추출된 상 기 적어도 하나의 오브젝트 및 상기 학습용 텍스트에 태깅된 장소에 기초하여 상기 텍스트 기반 딕셔너리를 업 데이트하는 텍스트 기반 딕셔너리 구축모듈을 더 포함하고, 상기 장소결정모듈은, 상기 장소 검출 모델이 출력 한 상기 출력 값이 상기 임계 값 미만이고 상기 제1예상장소 및 상기 제2예상장소가 상이한 경우, 상기 텍스트 기반 딕셔너리에 기초하여 제1예상장소 및 상기 제2예상장소 중 어느 하나를 상기 판단 대상 이미지에 상응하는 장소로 결정할 수 있다. 일 실시예에서, 상기 텍스트 기반 딕셔너리 구축모듈은, 추출된 상기 적어도 하나의 오브젝트로 구성된 집합의 모든 부분 집합 각각에 대하여, 상기 텍스트 기반 딕셔너리에 포함된 항목 중 상기 부분 집합 및 상기 학습용 텍스트에 태깅된 장소에 해당하는 항목의 빈도를 증가시킬 수 있다. 본 발명의 다른 일 측면에 따르면, 입력 레이어를 통해 이미지를 입력받아 입력된 이미지에 포함된 1 이상의 오 브젝트를 검출하기 위한 출력 값을 출력 레이어를 통해 출력하는 인공 뉴럴 네트워크인 오브젝트 검출 모델; 및 오브젝트의 집합, 장소 및 빈도로 구성된 항목의 리스트인 딕셔너리-여기서, 상기 딕셔너리 내의 각 항목의 빈 도는, 해당 항목의 집합 내의 오브젝트 모두가 해당 항목의 장소에 등장한 빈도를 나타냄-를 저장하는 저장모듈; 복수의 학습용 이미지를 획득하는 학습용 이미지 획득모듈-상기 복수의 학습용 이미지 각각은, 해당 학습용 이미지에 상응하는 장소가 각각 태깅되어 있음; 상기 복수의 학습용 이미지 각각에 대하여, 상기 학습용 이미지를 상기 오브젝트 검출 모델에 입력하여 상기 학습용 이미지에 포함된 적어도 하나의 오브젝트를 검출하고, 검출된 상기 적어도 하나의 오브젝트 및 상기 학습용 이미지에 태깅된 장소에 기초하여 상기 딕셔너리를 업 데이트하는 딕셔너리 구축모듈; 소정의 판단 대상 이미지에 상응하는 장소를 결정하는 결정모듈을 포함하되, 상 기 결정모듈은, 상기 오브젝트 검출 모델에 상기 판단 대상 이미지를 입력하고, 상기 오브젝트 검출 모델이 출 력하는 출력 값에 기초하여 상기 판단 대상 이미지에 포함된 1 이상의 오브젝트를 검출하는 오브젝트 검출 모듈; 상기 이미지 기반 딕셔너리에 포함된 항목 중 어느 하나를 상기 판단 대상 이미지의 매칭 항목으로 판단 하고-여기서 상기 매칭 항목은, 상기 판단 대상 이미지에 포함된 상기 1 이상의 오브젝트를 모두 포함하는 집합 을 가진 항목 중 가장 빈도가 큰 항목임-, 상기 매칭 항목의 장소를 상기 판단 대상 이미지에 상응하는 장소로 결정하는 장소결정모듈을 포함하는 이미지 기반 장소 추정 시스템이 제공된다. 본 발명의 다른 일 측면에 따르면 입력 레이어를 통해 입력된 이미지를 입력받아 입력된 이미지에 상응하는 장 소를 판단하기 위한 출력 값을 출력 레이어를 통해 출력하는 인공 뉴럴 네트워크인 장소 검출 모델(place detection model); 입력 레이어를 통해 이미지를 입력받아 입력된 이미지에 포함된 1 이상의 오브젝트를 검출하 기 위한 출력 값을 출력 레이어를 통해 출력하는 인공 뉴럴 네트워크인 오브젝트 검출 모델(object detection model); 및 오브젝트의 집합, 장소 및 빈도로 구성된 항목의 리스트인 이미지 기반 딕셔너리-여기서, 상기 이미 지 기반 딕셔너리 내의 각 항목의 빈도는, 해당 항목의 집합 내의 오브젝트 모두가 해당 항목의 장소에 등장한 빈도를 나타냄-를 포함하는 컴퓨팅 시스템에 의해 수행되며, 소정의 판단 대상 이미지에 상응하는 장소를 결정 하는 이미지 기반 장소 추정 방법으로서, 상기 장소 검출 모델에 상기 판단 대상 이미지를 입력하고, 상기 장소 검출 모델이 출력한 출력 값에 기초하여 상기 판단 대상 이미지에 상응하는 제1예상장소를 판단하는 제1판단단 계; 상기 오브젝트 검출 모델에 상기 판단 대상 이미지를 입력하고, 상기 오브젝트 검출 모델이 출력하는 출력 값에 기초하여 상기 판단 대상 이미지에 포함된 1 이상의 오브젝트를 검출하는 오브젝트 검출 단계; 상기 이미 지 기반 딕셔너리에 포함된 항목 중 어느 하나를 상기 판단 대상 이미지의 매칭 항목으로 판단하고-여기서 상기 매칭 항목은, 상기 판단 대상 이미지에 포함된 상기 1 이상의 오브젝트를 모두 포함하는 집합을 가진 항목 중 가장 빈도가 큰 항목임-, 상기 매칭 항목의 장소를 제2예상장소로 판단하는 제2판단단계; 및 상기 제1예상장소 및 상기 제2예상장소 중 어느 하나를 상기 판단 대상 이미지에 상응하는 장소로 결정하는 장소결정단계를 포함 하는 이미지 기반 장소 추정 방법이 제공된다. 일 실시예에서, 상기 이미지 기반 장소 추정 방법은, 복수의 학습용 이미지를 획득하는 학습용 이미지 획득단계 -상기 복수의 학습용 이미지 각각은, 해당 학습용 이미지에 상응하는 장소가 각각 태깅되어 있음; 상기 복수의 학습용 이미지 각각을, 상기 장소 검출 모델에 입력하여 상기 장소 검출 모델을 학습하는 학습단계; 상기 복수 의 학습용 이미지 각각에 대하여, 상기 학습용 이미지를 상기 오브젝트 검출 모델에 입력하여 상기 학습용 이미 지에 포함된 적어도 하나의 오브젝트를 검출하고, 검출된 상기 적어도 하나의 오브젝트 및 상기 학습용 이미지 에 태깅된 장소에 기초하여 상기 이미지 기반 딕셔너리를 업데이트하는 이미지 기반 딕셔너리 구축단계를 더 포 함할 수 있다. 일 실시예에서, 상기 이미지 기반 딕셔너리 구축단계는, 검출된 상기 적어도 하나의 오브젝트로 구성된 집합의 모든 부분 집합 각각에 대하여, 상기 이미지 기반 딕셔너리에 포함된 항목 중 상기 부분 집합 및 상기 학습용 이미지에 태깅된 장소에 해당하는 항목의 빈도를 증가시키는 단계를 포함할 수 있다. 일 실시예에서, 상기 장소결정단계는, 상기 장소 검출 모델이 출력한 상기 출력 값이 소정의 임계 값 이상인 경 우, 상기 제1예상장소를 상기 판단 대상 이미지에 상응하는 장소로 결정하는 단계; 상기 장소 검출 모델이 출력 한 상기 출력 값이 상기 임계 값 미만인 경우, 상기 제1예상장소가 상기 제2예상장소와 동일하면 상기 제1예상 장소를 상기 판단 대상 이미지에 상응하는 장소로 결정하는 단계; 및 상기 장소 검출 모델이 출력한 상기 출력 값이 상기 임계 값 미만인 경우, 상기 제1예상장소가 상기 제2예상장소와 상이하면 소정의 판단 기준에 의해 상 기 제1예상장소 및 상기 제2예상장소 중 어느 하나를 상기 판단 대상 이미지에 상응하는 장소로 결정하는 단계 를 포함할 수 있다. 일 실시예에서, 상기 컴퓨팅 시스템은, 오브젝트의 집합, 장소 및 빈도로 구성된 항목의 리스트인 텍스트 기반 딕셔너리-여기서, 상기 텍스트 기반 딕셔너리 내의 각 항목의 빈도는, 해당 항목의 집합 내의 오브젝트 모두가 해당 항목의 장소에 등장한 빈도를 나타냄-를 더 포함하고, 상기 이미지 기반 장소 추정 방법은, 복수의 학습용 텍스트를 획득하는 학습용 텍스트 획득단계-여기서 상기 복수의 학습용 텍스트 각각에는 장소가 태깅됨; 및 상 기 복수의 학습용 텍스트 각각에 대하여, 상기 학습용 텍스트에서 적어도 하나의 오브젝트를 추출하고, 추출된 상기 적어도 하나의 오브젝트 및 상기 학습용 텍스트에 태깅된 장소에 기초하여 상기 텍스트 기반 딕셔너리를 업데이트하는 텍스트 기반 딕셔너리 구축단계를 더 포함하고, 상기 장소결정단계는, 상기 장소 검출 모델이 출 력한 상기 출력 값이 상기 임계 값 미만이고 상기 제1예상장소 및 상기 제2예상장소가 상이한 경우, 상기 텍스트 기반 딕셔너리에 기초하여 제1예상장소 및 상기 제2예상장소 중 어느 하나를 상기 판단 대상 이미지에 상응 하는 장소로 결정하는 단계를 포함할 수 있다. 일 실시예에서, 상기 텍스트 기반 딕셔너리 구축단계는, 추출된 상기 적어도 하나의 오브젝트로 구성된 집합의 모든 부분 집합 각각에 대하여, 상기 텍스트 기반 딕셔너리에 포함된 항목 중 상기 부분 집합 및 상기 학습용 텍스트에 태깅된 장소에 해당하는 항목의 빈도를 증가시키는 단계를 포함할 수 있다. 본 발명의 다른 일 측면에 따르면, 입력 레이어를 통해 이미지를 입력받아 입력된 이미지에 포함된 1 이상의 오 브젝트를 검출하기 위한 출력 값을 출력 레이어를 통해 출력하는 인공 뉴럴 네트워크인 오브젝트 검출 모델; 및 오브젝트의 집합, 장소 및 빈도로 구성된 항목의 리스트인 이미지 기반 딕셔너리-여기서, 상기 이미지 기반 딕 셔너리 내의 각 항목의 빈도는, 해당 항목의 집합 내의 오브젝트 모두가 해당 항목의 장소에 등장한 빈도를 나 타냄-를 포함하는 컴퓨팅 시스템에 의해 수행되며, 소정의 판단 대상 이미지에 상응하는 장소를 결정하는 이미 지 기반 장소 추정 방법으로서, 복수의 학습용 이미지를 획득하는 학습용 이미지 획득단계-상기 복수의 학습용 이미지 각각은, 해당 학습용 이미지에 상응하는 장소가 각각 태깅되어 있음; 상기 복수의 학습용 이미지 각각에 대하여, 상기 학습용 이미지를 상기 오브젝트 검출 모델에 입력하여 상기 학습용 이미지에 포함된 적어도 하나 의 오브젝트를 검출하고, 검출된 상기 적어도 하나의 오브젝트 및 상기 학습용 이미지에 태깅된 장소에 기초하 여 상기 이미지 기반 딕셔너리를 업데이트하는 이미지 기반 딕셔너리 구축단계; 소정의 판단 대상 이미지에 상 응하는 장소를 결정하는 결정단계를 포함하되, 상기 결정단계는, 상기 오브젝트 검출 모델에 상기 판단 대상 이 미지를 입력하고, 상기 오브젝트 검출 모델이 출력하는 출력 값에 기초하여 상기 판단 대상 이미지에 포함된 1 이상의 오브젝트를 검출하는 오브젝트 검출 단계; 및 상기 이미지 기반 딕셔너리에 포함된 항목 중 어느 하나를 상기 판단 대상 이미지의 매칭 항목으로 판단하고-여기서 상기 매칭 항목은, 상기 판단 대상 이미지에 포함된 상기 1 이상의 오브젝트를 모두 포함하는 집합을 가진 항목 중 가장 빈도가 큰 항목임-, 상기 매칭 항목의 장소 를 상기 판단 대상 이미지에 상응하는 장소로 결정하는 장소결정단계를 포함하는 이미지 기반 장소 추정 방법이 제공된다. 본 발명의 다른 일 측면에 따르면, 데이터 처리장치에 설치되며 상술한 방법을 수행하기 위한 매체에 기록된 컴 퓨터 프로그램이 제공된다. 본 발명의 다른 일 측면에 따르면, 상술한 방법을 수행하기 위한 컴퓨터 프로그램이 기록된 컴퓨터 판독 가능한 기록매체가 제공된다. 본 발명의 다른 일 측면에 따르면, 컴퓨팅 시스템으로서, 프로세서; 및 컴퓨터 프로그램을 저장하는 메모리를 포함하고, 상기 컴퓨터 프로그램은, 상기 프로세서에 의해 실행되는 경우, 상기 컴퓨팅 시스템으로 하여금 상술 한 방법을 수행하도록 하는 컴퓨팅 시스템이 제공된다."}
{"patent_id": "10-2021-0073320", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 기술적 사상에 의하면, 이미지로부터 장소를 추정할 수 있는 방법 및 시스템을 제공할 수 있다. 특히 본 발명의 기술적 사상에 의하면, 인공 뉴럴 네트워크뿐만 아니라 이미지 기반의 딕셔너리와 텍스트 기반 의 딕셔너리를 사전에 구축하여 이를 통해 이미지로부터 장소를 추정할 수 있으며 이로 인하여 추정의 정확도가 매우 향상될 수 있는 효과가 있다."}
{"patent_id": "10-2021-0073320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변환을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이해되어 야 한다. 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다 고 판단되는 경우 그 상세한 설명을 생략한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의 해 한정되어서는 안 된다. 제1, 제2 등의 용어는 특별한 순서를 나타내는 것이 아니며, 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에 있어서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성 요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 또한, 본 명세서에 있어서는 어느 하나의 구성요소가 다른 구성요소로 데이터를 '전송'하는 경우에는 상기 구성 요소는 상기 다른 구성요소로 직접 상기 데이터를 전송할 수도 있고, 적어도 하나의 또 다른 구성요소를 통하여 상기 데이터를 상기 다른 구성요소로 전송할 수도 있는 것을 의미한다. 반대로 어느 하나의 구성요소가 다른 구 성요소로 데이터를 '직접 전송'하는 경우에는 상기 구성요소에서 다른 구성요소를 통하지 않고 상기 다른 구성 요소로 상기 데이터가 전송되는 것을 의미한다. 이하, 첨부된 도면들을 참조하여 본 발명의 실시예들을 중심으로 본 발명을 상세히 설명한다. 각 도면에 제시된 동일한 참조부호는 동일한 부재를 나타낸다. 도 1은 본 발명의 기술적 사상에 따른 이미지 기반의 장소 추정 방법(이하, '장소 추정 방법'이라고 함)이 수행 되는 환경을 개략적으로 도시한 도면이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 장소 추정 방법은 이미지 기반 장소 추정 시스템에 의해 수 행될 수 있다. 상기 장소 추정 시스템은 미리 구축된 모델을 이용하여 소정의 판단 대상 이미지에 상응하는 장소를 추정할 수 있다. 상기 판단 대상 이미지에 상응하는 장소는 상기 판단 대상 이미지에 의해 표현되는 장소일 수 있다. 본 명세서에서 장소는, 예를 들어, 공항, 부엌, 교실, 사무실, 공항 등과 같은 일종의 분류 혹은 카테고 리를 의미할 수 있다. 상기 모델은 장소 검출 모델, 오브젝트 검출 모델, 및 이미지 기반 딕셔너리를 포함할 수 있으며, 실시예에 따라서, 텍스트 기반 딕셔너리를 더 포함할 수도 있다. 상기 장소 검출 모델 및 상기 오브젝트 검출 모델은 인공 뉴럴 네트워크일 수 있다. 본 명세서에서 인공 뉴럴 네트워크는 인간의 뉴런의 동작 원리에 기초하여 인공적으로 구축한 신경망으로서, 다층 퍼셉트론 모 델을 포함하며, 인공 뉴럴 네트워크를 정의하는 일련의 설계사항들을 표현하는 정보의 집합을 의미할 수 있다. 일 실시예에서, 상기 장소 검출 모델 및 상기 오브젝트 검출 모델은 합성곱 신경망(convolutional neural network)이거나 혹은 합성곱 신경망을 포함할 수 있다. 합성곱 신경망은 잘 알려진 바와 같이, 입력 레 이어, 복수의 히든 레이어들, 및 출력 레이어를 포함할 수 있다. 복수의 히든 레이어들 각각은 컨볼루션 레이어 및 풀링 레이어(또는 서브 샘플링 레이어)를 포함할 수 있다. 합성곱 신경망은 이러한 각각의 레이어들을 정의 하기 위한 함수, 필터, 스트라이드(stride), 웨이트 팩터 등에 의해 정의될 수 있다. 또한, 출력 레이어는 풀리 커넥티드(fully connected)된 전방향 레이어(FeedForward layer)로 정의될 수 있다. 합성곱 신경망을 구성하는각각의 레이어별 설계 사항은 널리 알려져 있다. 예를 들어, 복수의 레이어들에 포함될 레이어의 개수, 상기 복 수의 레이어들을 정의하기 위한 컨볼루션 함수, 풀링 함수, 활성화 함수 각각에 대해서는 공지된 함수들이 이용 될 수도 있고, 본 발명의 기술적 사상을 구현하기 위해 별도로 정의된 함수들이 이용될 수도 있다. 상기 장소 검출 모델은 입력 레이어를 통해 이미지를 입력받을 수 있으며, 입력된 이미지에 상응하는 장소 를 판단하기 위한 출력 값을 출력 레이어를 통해 출력할 수 있다. 예를 들어, 상기 장소 검출 모델은 판단 가능한 모든 장소 혹은 그들 중 적어도 일부에 대한 각각의 확률 값을 출력할 수 있다. 한편, 상기 장소 검출 모델로 입력되는 이미지로부터 판단 가능한 모든 장소는 미리 정의되어 있을 수 있다. 상기 오브젝트 검출 모델은 입력 레이어를 통해 이미지를 입력받을 수 있으며, 입력된 이미지에 포함된 1 이상의 오브젝트를 검출하기 위한 출력 값을 출력 레이어를 통해 출력할 수 있다. 예를 들어, 상기 장소 검출 모델은 판단 가능한 모든 오브젝트 혹은 그들 중 적어도 일부에 대한 각각의 확률 값을 출력할 수 있다. 또는 상기 장소 검출 모델은 입력된 이미지의 각 픽셀 혹은 각 영역 별로 해당 픽셀 혹은 영역이 어느 오 브젝트에 해당하는지를 판단할 수 있도록 하는 정보(예를 들어 확률 값 등)를 출력할 수도 있다. 상기 오브젝트 검출 모델로 입력되는 이미지로부터 판단 가능한 모든 오브젝트는 미리 정의되어 있을 수 있다. 판단 가능한 오브젝트 각각은 시각적으로 구분 가능하며, 특정한 키워드에 의해 지칭이 가능한 다양한 요 소를 포함할 수 있다. 예를 들어, 상기 오브젝트는 각종 사물, 자연물, 인공물이나 배경적 요소 등을 포함할 수 있다. 일 실시예에서 상기 오브젝트 검출 모델은 멀티 클래스 클래시피케이션(multi-class classification)용 뉴 럴 네트워크 혹은 이미지 세그멘테이션(image segmentation)용 뉴럴 네트워크일 수 있다. 경우에 따라서 상기 오브젝트 검출 모델은 시멘틱 세그멘테이션 뉴럴 네트워크일 수도 있다. 상기 장소 검출 모델은 상기 모델/딕셔너리 구축 시스템에 의해 미리 학습될 수 있는데, 이에 대하여 는 후술하기로 한다. 한편, 상기 오브젝트 검출 모델 역시 모델/딕셔너리 구축 시스템에 의해 미리 학습될 수 있으나 이에 한정되는 것은 아니며, 타 시스템에 의해 미리 학습되어 있을 수 있다. 한편 상기 이미지 기반 딕셔너리 및 상기 텍스트 기반 딕셔너리는 오브젝트의 집합, 장소 및 빈도로 구성된 항목의 리스트일 수 있다. 예를 들어, 상기 이미지 기반 딕셔너리는 딕셔너리 자료형, 리스트 자료 형, 배열 자료형, 테이블 자료형 등에 의해 구현될 수 있다. 상기 이미지 기반 딕셔너리 및 상기 텍스트 기반 딕셔너리에서 오브젝트의 집합 및 장소의 쌍이 각 항목의 키 값이 될 수 있다. 상기 이미지 기반 딕셔너리는 다수의 이미지를 기반으로 구축되는 딕셔너리이며, 상기 텍스트 기반 딕셔너 리는 다수의 텍스트를 기반으로 구축되는 딕셔너리이다. 상기 모델/딕셔너리 구축 시스템에 의해 미 리 구축될 수 있으며, 이에 대하여는 후술하기로 한다. 도 2a는 이미지 기반 딕셔너리의 일 예를 도시한 도면이며, 도 2b는 텍스트 기반 딕셔너리의 일 예를 도시한 도면이다. 도 2a 및 도 2b는 상기 오브젝트 검출 모델에 의해 검출 가능한 오브젝트가 A, B, C이고, 상기 장소 추정 시스템 혹은 상기 장소 검출 모델에 의해 검출 가능한 장소가 P1, P2, P3인 경 우의 예를 도시한 것이다. 도 2a 및 도 2b에 도시된 바와 같이, 상기 이미지 기반 딕셔너리 및 상기 텍스트 기반 딕셔너리는 검 출 가능한 오브젝트의 각 조합 및 각 장소 별 빈도를 포함할 수 있다. 도 2a의 이미지 기반 딕셔너리 및 도 2b의 텍스트 기반 딕셔너리는 [전체 오브젝트의 집합의 공집합이 아닌 부분집합의 개수] * [장소의 개 수] = 3*7 = 21개의 항목으로 구성되며, 도 2a의 Fi(1<=i<=21) 및 도 2b의 Gj(1<=j<=21)는 각각 해당 항목의 오 브젝트 집합 내의 오브젝트 모두가 해당 항목의 장소에 등장한 빈도를 나타낸다. 예를 들어, F8은 오브젝트 A, B가 모두 P2라는 장소에 상응하는 이미지에 등장한 빈도를 나타낸다. 여기서 빈도는 등장 횟수를 나타낼 수도 있 으며, 등장 비율을 나타낼 수도 있다. 다만 후술하는 바와 같이 상기 이미지 기반 딕셔너리는 다수의 이미 지를 기반으로 구축되는 딕셔너리이며, 상기 텍스트 기반 딕셔너리는 다수의 텍스트를 기반으로 구축되는 딕셔너리이므로 오브젝트 집합과 장소가 동일한 이미지 기반 딕셔너리의 항목과 텍스트 기반 딕셔너리 의 항목의 빈도는 서로 상이할 수 있다. 다시 도 1을 참조하면, 상기 모델/딕셔너리 구축 시스템 및/또는 상기 이미지 기반 장소 추정 시스템(10 0)은 본 발명의 기술적 사상을 구현하기 위한 연산능력을 가진 데이터 처리장치인 컴퓨팅 시스템일 수 있으며, 일반적으로 네트워크를 통해 클라이언트가 접속 가능한 데이터 처리 장치인 서버뿐만 아니라 개인용 컴퓨터나휴대 단말 등과 같은 컴퓨팅 장치를 포함할 수 있다. 상기 모델/딕셔너리 구축 시스템 및/또는 상기 이미지 기반 장소 추정 시스템은 어느 하나의 물리적 장치로 구현될 수도 있으나, 필요에 따라 복수의 물리적 장치가 유기적으로 결합되어 본 발명의 기술적 사상에 따른 상기 모델/딕셔너리 구축 시스템 및/또는 상기 이미지 기반 장소 추정 시스템을 구현할 수 있음"}
{"patent_id": "10-2021-0073320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "을 본 발명의 기술분야의 평균적 전문가는 용이하게 추론할 수 있을 것이다. 도 1에 도시된 바와 같이, 상기 모델/딕셔너리 구축 시스템 및/또는 상기 이미지 기반 장소 추정 시스템 은 소정의 모(母) 시스템의 서브 시스템의 형태로 구현될 수도 있다. 상기 모 시스템은 서버일 수 있다. 상기 서버는 본 발명의 기술적 사상을 구현하기 위한 연산능력을 가진 데이터 처리장치를 의미하며, 일반적으로 네트워크를 통해 클라이언트가 접속 가능한 데이터 처리장치뿐만 아니라 개인용 컴퓨터, 휴대 단말"}
{"patent_id": "10-2021-0073320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "등과 같이 특정 서비스를 수행할 수 있는 어떠한 장치도 서버로 정의될 수 있음을 본 발명의 기술분야의 평균적 전문가는 용이하게 추론할 수 있을 것이다. 또는 실시예에 따라, 상기 모델/딕셔너리 구축 시스템 및 상기 이미지 기반 장소 추정 시스템은 서로 분리된 형태로 구현될 수도 있다. 또는 상기 모델/딕셔너리 구축 시스템 및 상기 이미지 기반 장소 추정 시스템은 하나의 시스템으로 구현될 수도 있다. 도 3은 본 발명의 일 실시예에 따른 모델/딕셔너리 구축 시스템의 개략적인 구성을 도시한 블록도이다. 상기 모델/딕셔너리 구축 시스템 및 상기 이미지 기반 장소 추정 시스템은 본 발명의 기술적 사상을 구현하기 위해 필요한 하드웨어 리소스(resource) 및/또는 소프트웨어를 구비한 논리적인 구성을 의미할 수 있 으며, 반드시 하나의 물리적인 구성요소를 의미하거나 하나의 장치를 의미하는 것은 아니다. 즉, 상기 모델/딕 셔너리 구축 시스템 및 상기 이미지 기반 장소 추정 시스템은 본 발명의 기술적 사상을 구현하기 위 해 구비되는 하드웨어 및/또는 소프트웨어의 논리적인 결합을 의미할 수 있으며, 필요한 경우에는 서로 이격된 장치에 설치되어 각각의 기능을 수행함으로써 본 발명의 기술적 사상을 구현하기 위한 논리적인 구성들의 집합 으로 구현될 수도 있다. 또한, 상기 모델/딕셔너리 구축 시스템 및 상기 이미지 기반 장소 추정 시스템 은 본 발명의 기술적 사상을 구현하기 위한 각각의 기능 또는 역할별로 별도로 구현되는 구성들의 집합을 의미할 수도 있다. 상기 모델/딕셔너리 구축 시스템 및 상기 이미지 기반 장소 추정 시스템의 각 구 성은 서로 다른 물리적 장치에 위치할 수도 있고, 동일한 물리적 장치에 위치할 수도 있다. 또한, 구현 예에 따 라서는 상기 모델/딕셔너리 구축 시스템 및 상기 이미지 기반 장소 추정 시스템의 구성 요소 각각을 구성하는 소프트웨어 및/또는 하드웨어의 결합 역시 서로 다른 물리적 장치에 위치하고, 서로 다른 물리적 장치 에 위치한 구성들이 서로 유기적으로 결합되어 각각의 상기 모듈들을 구현할 수도 있다. 또한, 본 명세서에서 모듈이라 함은, 본 발명의 기술적 사상을 수행하기 위한 하드웨어 및 상기 하드웨어를 구 동하기 위한 소프트웨어의 기능적, 구조적 결합을 의미할 수 있다. 예컨대, 상기 모듈은 소정의 코드와 상기 소 정의 코드가 수행되기 위한 하드웨어 리소스(resource)의 논리적인 단위를 의미할 수 있으며, 반드시 물리적으"}
{"patent_id": "10-2021-0073320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "로 연결된 코드를 의미하거나, 한 종류의 하드웨어를 의미하는 것은 아님은 본 발명의 기술분야의 평균적 전문 가에게는 용이하게 추론될 수 있다. 도 3을 참조하면, 상기 모델/딕셔너리 구축 시스템은 저장모듈, 학습용 이미지 획득모듈, 학습 모듈, 이미지 기반 딕셔너리 구축모듈을 포함할 수 있다. 실시예에 따라서, 상기 모델/딕셔너리 구축 시스템은 학습용 텍스트 획득모듈, 텍스트 기반 딕셔너리 구축모듈을 더 포함할 수 있다. 본 발 명의 실시예에 따라서는, 상술한 구성요소들 중 일부 구성요소는 반드시 본 발명의 구현에 필수적으로 필요한 구성요소에 해당하지 않을 수도 있으며, 또한 실시예에 따라 상기 모델/딕셔너리 구축 시스템은 이보다 더 많은 구성요소를 포함할 수도 있음은 물론이다. 예를 들어 상기 모델/딕셔너리 구축 시스템은 외부 장치와 통신하기 위한 통신모듈(미도시), 상기 모델/딕셔너리 구축 시스템의 구성요소 및 리소스를 제어하기 위한 제어모듈(미도시)을 더 포함할 수 있다. 상기 저장모듈은 상기 장소 검출 모델, 상기 오브젝트 검출 모델, 상기 이미지 기반 딕셔너리 을 저장할 수 있다. 또한 상기 저장모듈은 상기 텍스트 기반 딕셔너리를 더 저장할 수도 있다. 실시예에 따라서 상기 저장모듈은 상기 장소 검출 모델 및/또는 상기 오브젝트 검출 모델, 및/ 또는 상기 상기 이미지 기반 딕셔너리 및/또는 상기 텍스트 기반 딕셔너리 구축에 이용될 데이터를 더 저 장할 수도 있다. 상기 저장모듈은 RAM 등의 휘발성 메모리 장치 또는 SDD나 HDD 등의 비휘발성 메모리 장 치에 각종 정보 및 데이터를 저장할 수 있다.상기 학습용 이미지 획득모듈은 복수의 학습용 이미지를 획득할 수 있다. 이때, 상기 복수의 학습용 이미 지 각각은, 해당 학습용 이미지에 상응하는 장소가 각각 태깅되어 있을 수 있다. 일 실시예에서 상기 학습용 이 미지 획득모듈은 소정의 외부 입력 장치 혹은 네트워크를 통해 연결된 외부 장치로부터 상기 복수의 학습 용 이미지를 획득할 수 있다. 상기 학습모듈은 상기 복수의 학습용 이미지 각각을, 상기 장소 검출 모델에 입력하여 상기 장소 검 출 모델을 학습할 수 있다. 상기 장소 검출 모델은 장소가 라벨링된 이미지를 입력받고 상기 장소 검출 모 델이 입력된 이미지로부터 추론하는 결과와 라벨링된 값의 차이가 감소되도록 학습하는 지도 학습 기법을 이용하여 학습될 수 있다. 상기 이미지 기반 딕셔너리 구축모듈은 상기 복수의 학습용 이미지를 이용하여 상기 이미지 기반 딕셔너리 를 구축할 수 있다. 도 4는 본 발명의 일 실시예에 따른 이미지 기반 딕셔너리 구축모듈이 상기 이미지 기반 딕셔너리를 구축하는 과정을 도시한 도면이다. 도 4를 참조하면, 상기 이미지 기반 딕셔너리 구축모듈은 상기 복수의 학습용 이미지 각각에 대하여, S110 내지 S130 단계를 수행할 수 있다(S100). S110 단계에서, 상기 이미지 기반 딕셔너리 구축모듈은 상기 학습용 이미지를 상기 오브젝트 검출 모델 에 입력하여 상기 학습용 이미지에 포함된 적어도 하나의 오브젝트를 검출할 수 있다. S110 단계가 수행되 기 전, 상기 오브젝트 검출 모델은 미리 학습되어 있을 수 있다. 실시예에 따라 상기 오브젝트 검출 모델 은 상기 모델/딕셔너리 구축 시스템 혹은 별도의 시스템에 의해 미리 학습되어 있을 수 있다. 이후 상기 이미지 기반 딕셔너리 구축모듈은 검출된 상기 적어도 하나의 오브젝트 및 상기 학습용 이미지 에 태깅된 장소에 기초하여 상기 이미지 기반 딕셔너리를 업데이트할 수 있다. 예를 들어 상기 이미지 기반 딕셔너리 구축모듈은 도 4의 S120 및 S130 단계를 수행할 수 있다. 즉, 상기 이미지 기반 딕셔너리 구축모듈은 상기 적어도 하나의 오브젝트로 구성된 집합의 모든 부분 집합 각각에 대하여(S120), 상기 이미지 기반 딕셔너리에 포함된 항목 중 상기 부분 집합 및 상기 학습용 이미지에 태깅된 장소에 해당하는 항목의 빈도를 증가시킬 수 있다(S130). 만약 이미지 기반 딕셔너리가 도 2a에 도시된 바와 같다고 하고, 상기 S110 단계에서 장소 P2가 태깅된 학 습용 이미지 x를 입력받은 오브젝트 검출 모델에 의하여 오브젝트 A, C가 검출되었다고 가정하면, 상기 이 미지 기반 딕셔너리 구축모듈은 검출된 오브젝트로 구성된 집합 {A, C}의 공집합이 아닌 모든 부분 집합 {A}, {A, C}, {C} 및 장소 P2에 해당하는 항목의 빈도인 F2, F8, F20을 증가시킬 수 있다. 이 외에도 상기 이미지 기반 딕셔너리를 업데이트할 수 있는 방법은 다양할 수 있다. 예를 들어, 상기 이 미지 기반 딕셔너리 구축모듈은 상기 적어도 하나의 오브젝트로 구성된 집합 및 상기 학습용 이미지에 태 깅된 장소에 해당하는 항목만의 빈도를 증가시킬 수도 있다. 위와 방식으로 상기 이미지 기반 딕셔너리 구축모듈은 모든 학습용 이미지에 대하여 S110 내지 S130 단계 를 수행함으로써 상기 이미지 기반 딕셔너리를 구축할 수 있다. 한편, 위에서는 상기 장소 검출 모델을 학습하기 위한 이미지 및 상기 이미지 기반 딕셔너리를 구축 하기 위한 이미지가 동일한 예를 설명하였으나 이와 달리, 상기 장소 검출 모델을 학습하기 위한 이미지와 상기 이미지 기반 딕셔너리를 구축하기 위한 이미지가 상이한 실시예도 있을 수 있음은 물론이다. 다시 도 3을 참조하면, 상기 학습용 텍스트 획득모듈은 복수의 학습용 텍스트를 획득할 수 있다. 이때, 상 기 복수의 학습용 텍스트 각각은, 해당 학습용 텍스트에 상응하는 장소가 각각 태깅되어 있을 수 있다. 상기 복 수의 학습용 텍스트 각각은 하나의 문장일 수도 있으나 이에 한정되는 것이 아니라 여러 문장이 결합된 하나의 단락 혹은 여러 단락으로 구성될 수 있다. 일 실시예에서 상기 학습용 텍스트 획득모듈은 소정의 외부 입 력 장치 혹은 네트워크를 통해 연결된 외부 장치로부터 상기 복수의 학습용 텍스트를 획득할 수 있다. 예를 들 어, 상기 학습용 텍스트 획득모듈은 소정의 커뮤니티 사이트 혹은 소정의 사회관계망서비스(SNS)로부터 장 소가 태깅된 텍스트를 크롤링함으로써 상기 복수의 학습용 텍스트를 획득할 수 있다. 이 외에도 상기 학습용 텍 스트 획득모듈이 학습용 텍스트를 획득하는 방법은 다양할 수 있다. 예를 들어, 상기 학습용 텍스트 획득 모듈은 내부적으로 미리 구축해 둔 소정의 데이터베이스로부터 상기 복수의 학습용 텍스트를 획득할 수 있다. 한편, 상기 텍스트 기반 딕셔너리 구축모듈은 상기 복수의 학습용 텍스트를 이용하여 상기 텍스트 기반 딕 셔너리를 구축할 수 있다. 도 5는 본 발명의 일 실시예에 따른 텍스트 기반 딕셔너리 구축모듈이 상기 텍스트 기반 딕셔너리를 구축하는 과정을 도시한 도면이다. 도 5를 참조하면, 상기 텍스트 기반 딕셔너리 구축모듈은 상기 복수의 학습용 텍스트 각각에 대하여, S210 내지 S230 단계를 수행할 수 있다(S200). S210 단계에서, 상기 텍스트 기반 딕셔너리 구축모듈은 상기 학습용 텍스트로부터 적어도 하나의 오브젝트 의 명칭을 검출할 수 있다. 상기 학습용 텍스트로부터 특정 키워드(즉, 오브젝트의 명칭)을 검출하는 방법은 다 양할 수 있다. 예를 들어, 상기 텍스트 기반 딕셔너리 구축모듈은 텍스트 비교를 통해 상기 학습용 텍스트 로부터 특정 키워드(즉, 오브젝트의 명칭)을 검출할 수 있다. 이후 상기 텍스트 기반 딕셔너리 구축모듈은 검출된 상기 적어도 하나의 오브젝트 및 상기 학습용 텍스트 에 태깅된 장소에 기초하여 상기 텍스트 기반 딕셔너리를 업데이트할 수 있다. 예를 들어 상기 텍스트 기반 딕셔너리 구축모듈은 도 5의 S220 및 S230 단계를 수행할 수 있다. 즉, 상기 텍스트 기반 딕셔너리 구축모듈은 상기 적어도 하나의 오브젝트로 구성된 집합의 모든 부분 집합 각각에 대하여(S220), 상기 텍스트 기반 딕셔너리에 포함된 항목 중 상기 부분 집합 및 상기 학습용 텍스트에 태 깅된 장소에 해당하는 항목의 빈도를 증가시킬 수 있다(S230). 만약 텍스트 기반 딕셔너리가 도 2b에 도시된 바와 같다고 하고, 상기 S210 단계에서 장소 P3가 태깅된 학 습용 텍스트 t로부터 오브젝트 B, C의 명칭이 검출되었다고 가정하면, 상기 텍스트 기반 딕셔너리 구축모듈 은 검출된 오브젝트로 구성된 집합 {B, C}의 공집합이 아닌 모든 부분 집합 {B}, {B, C}, {C} 및 장소 P3 에 해당하는 항목의 빈도인 G15, G18, G21을 증가시킬 수 있다. 이 외에도 상기 텍스트 기반 딕셔너리를 업데이트할 수 있는 방법은 다양할 수 있다. 예를 들어, 상기 텍 스트 기반 딕셔너리 구축모듈은 상기 적어도 하나의 오브젝트로 구성된 집합 및 상기 학습용 텍스트에 태 깅된 장소에 해당하는 항목만의 빈도를 증가시킬 수도 있다. 위와 방식으로 상기 텍스트 기반 딕셔너리 구축모듈은 모든 학습용 텍스트에 대하여 S210 내지 S230 단계 를 수행함으로써 상기 텍스트 기반 딕셔너리를 구축할 수 있다. 도 6은 본 발명의 일 실시예에 따른 이미지 기반 장초 추정 시스템의 구성을 도시한 블록이다. 도 6을 참조하면 상기 장초 추정 시스템은 저장모듈, 결정모듈을 포함할 수 있으며, 상기 결정 모듈은 제1판단모듈, 오브젝트 검출모듈, 제2판단모듈, 장소결정모듈을 포함할 수 있 다. 본 발명의 실시예에 따라서는, 상술한 구성요소들 중 일부 구성요소는 반드시 본 발명의 구현에 필수적으로 필요한 구성요소에 해당하지 않을 수도 있으며, 또한 실시예에 따라 상기 장초 추정 시스템은 이보다 더 많은 구성요소를 포함할 수도 있음은 물론이다. 예를 들어 상기 장초 추정 시스템은 외부 장치와 통신하기 위한 통신모듈(미도시), 상기 장초 추정 시스템의 구성요소 및 리소스를 제어하기 위한 제어모듈(미도시) 을 더 포함할 수 있다. 또한 실시예에 따라 상기 장소 추정 시스템은 상기 모델/딕셔너리 구축 시스템과 통합된 형태로 구현 될 수 있으며, 이 경우, 상기 장초 추정 시스템은 상술한 상기 모델/딕셔너리 구축 시스템에 포함된 구성을 더 포함할 수 있다. 상기 저장모듈은 미리 학습된 장소 검출 모델, 오브젝트 검출 모델을 포함할 수 있으며, 미리 구축된 이미지 기반 딕셔너리 및/또는 미리 구축된 텍스트 기반 딕셔너리를 더 포함할 수도 있다. 상기 획득모듈은 소정의 판단 대상 이미지를 획득할 수 있다. 상기 판단 대상 이미지는 상기 장소 추정 시 스템에 의해 장소가 추정될 이미지이다. 상기 획득모듈은 소정의 외부 장치(예를 들어, 입력장치) 혹 은 네트워크를 통해 연결된 외부 단말(예를 들어, 모바일 단말) 혹은 네트워크를 통해 연결된 외부 서버로부터 상기 판단 대상 이미지를 획득할 수 있다.상기 결정모듈은 상기 판단 대상 이미지에 상응하는 장소를 결정할 수 있다. 이를 위하여, 상기 제1판단모듈은 상기 장소 검출 모델에 상기 판단 대상 이미지를 입력하고, 상기 장소 검출 모델이 출력한 출력 값에 기초하여 상기 판단 대상 이미지에 상응하는 제1예상장소를 판단할 수 있다. 예를 들어 상기 판단 대상 이미지를 입력받은 상기 장소 검출 모델은 각 장소 별 확률을 출력할 수 있으며, 상기 제1판단모듈은 그 중 가장 높은 확률을 가지는 장소를 상기 제1예상장소라고 판단할 수 있다. 상기 오브젝트 검출 모듈는 상기 오브젝트 검출 모델에 상기 판단 대상 이미지를 입력하고, 상기 장 소 검출 모델이 출력하는 출력 값에 기초하여 상기 판단 대상 이미지에 포함된 1 이상의 오브젝트를 검출 할 수 있다. 예를 들어 상기 판단 대상 이미지를 입력받은 상기 오브젝트 검출 모델은 각 오브젝트 별 확 률을 출력할 수 있으며, 상기 오브젝트 검출모듈은 일정 값 이상의 확률을 가지는 오브젝트를 상기 판단 대상 이미지에 포함된 오브젝트라고 판단할 수 있다. 한편, 상기 제2판단모듈은 상기 이미지 기반 딕셔너리에 포함된 항목 중 어느 하나를 상기 판단 대상 이미지의 매칭 항목으로 판단할 수 있으며, 상기 매칭 항목의 장소를 제2예상장소로 판단할 수 있다. 이때, 상 기 매칭 항목은, 상기 판단 대상 이미지에 포함된 상기 1 이상의 오브젝트를 모두 포함하는 집합을 가진 항목 중 가장 빈도가 큰 항목이다. 예를 들어, 상기 이미지 기반 딕셔너리가 도 2a와 같으며, 상기 오브젝트 검 출모듈이 상기 판단 대상 이미지에 오브젝트 A, B가 포함되어 있다고 판단한 경우, 상기 제2판단모듈(12 3)은 빈도 F4, F5, F6를 비교할 수 있으며, 만약 F4가 가장 크다면 상기 제2판단모듈은 장소 P2를 제2예상장 소라고 판단할 수 있다. 한편 상기 장소결정모듈은 상기 제1예상장소 및 상기 제2예상장소 중 어느 하나를 상기 판단 대상 이미지 에 상응하는 장소로 결정할 수 있다. 일 실시예에서, 상기 장소결정모듈은, 상기 장소 검출 모델이 출력한 상기 출력 값이 소정의 임계 값 이상인 경우, 상기 제1예상장소를 상기 판단 대상 이미지에 상응하는 장소로 결정할 수 있다. 상기 임계 값은 소정의 테스트 셋으로 미리 시뮬레이션한 결과가 소정의 기준치(예를 들어 99%) 이상이 되도록 하는 값으로 미 리 정해져 있을 수 있다. 한편 상기 장소결정모듈은 상기 장소 검출 모델이 출력한 상기 출력 값이 상기 임계 값 미만인 경우, 상기 제1예상장소가 상기 제2예상장소와 동일하면 상기 제1예상장소를 상기 판단 대상 이미지에 상응하는 장소 로 결정할 수 있다. 만약 상기 제1예상장소가 상기 제2예상장소와 상이하면, 상기 장소결정모듈은, 소정의 판단 기준에 의해 상기 제1예상장소 및 상기 제2예상장소 중 어느 하나를 상기 판단 대상 이미지에 상응하는 장소로 결정할 수 있 다. 상기 판단 기준은 실시예에 따라 다양할 수 있다. 바람직하게는 상기 장소결정모듈은 상기 장소 검출 모델이 출력한 상기 출력 값이 상기 임계 값 미만 이고 상기 제1예상장소 및 상기 제2예상장소가 상이한 경우, 상기 텍스트 기반 딕셔너리에 기초하여 제1예 상장소 및 상기 제2예상장소 중 어느 하나를 상기 판단 대상 이미지에 상응하는 장소로 결정할 수 있다. 도 2a 및 도 2b를 예를 들어 설명하면, 상기 제1판단모듈이 제1예상장소를 P1이라고 판단하였고, 상기 제2판단모 듈이 제2예상장소를 P3이라고 판단하였고, 상기 오브젝트 검출 모델이 상기 판단 대상 이미지에 오브 젝트 B, C가 포함되어 있다고 판단한 경우, 상기 장소결정모듈은 상기 텍스트 기반 딕셔너리의 항목 중 상기 판단 대상 이미지에 포함된 오브젝트 B, C 및 제1예상장소 P1에 해당하는 항목의 빈도 G16과 상기 텍스 트 기반 딕셔너리의 항목 중 상기 판단 대상 이미지에 포함된 오브젝트 B, C 및 제2예상장소 P2에 해당하 는 항목의 빈도 G17을 비교하여 빈도가 큰 항목의 장소를 상기 판단 대상 이미지에 상응하는 장소로 결정할 수 있다. 만약 G17가 G16보다 크다면 상기 장소결정모듈은 제2예상장소 P2를 상기 판단 대상 이미지에 상응하는 장소로 결정할 수 있다. 한편 실시예에 따라서는, 상기 이미지 기반 장소 추정 시스템은 도 5와 달리, 이미지 기반 딕셔너리를 기 초로 판단한 결과만을 가지고 판단 대상 이미지에 상응하는 장소를 판단할 수도 있다. 즉, 본 실시예에서 상기 이미지 기반 장소 추정 시스템은 상기 오브젝트 검출 모델에 상기 판단 대상 이미지를 입력하고, 상 기 장소 검출 모델이 출력하는 출력 값에 기초하여 상기 판단 대상 이미지에 포함된 1 이상의 오브젝트를검출할 수 있으며, 상기 판단 대상 이미지에 포함된 상기 1 이상의 오브젝트를 모두 포함하는 집합을 가진 항목 중 가장 빈도가 큰 항목의 장소를 상기 판단 대상 이미지에 상응하는 장소로 결정할 수 있다. 도 7은 본 발명의 일 실시예에 따른 이미지 기반 장소 추정 방법의 개략적인 과정을 도시한 흐름도이다. 도 7을 참조하면, 상기 장소 추정 시스템은 소정의 판단 대상 이미지를 획득할 수 있다(S300). 이후 상기 장소 추정 시스템은 상기 장소 검출 모델에 상기 판단 대상 이미지를 입력하고, 상기 장소 검출 모델이 출력한 출력 값에 기초하여 상기 판단 대상 이미지에 상응하는 제1예상장소를 판단할 수 있다. 만약 상기 장소 검출 모델이 출력한 상기 출력 값이 소정의 임계 값 이상인 경우(S320), 상기 장소 추정 시스템은 상기 제1예상장소를 상기 판단 대상 이미지에 상응하는 장소로 결정할 수 있다(S330). 만약 상기 장소 검출 모델이 출력한 상기 출력 값이 소정의 임계 값 미만인 경우(S320), 상기 장소 추정 시스템은 상기 오브젝트 검출 모델에 상기 판단 대상 이미지를 입력하고, 상기 장소 검출 모델 이 출력하는 출력 값에 기초하여 상기 판단 대상 이미지에 포함된 1 이상의 오브젝트를 검출할 수 있다(S340). 또한 상기 장소 추정 시스템은 상기 판단 대상 이미지에 포함된 1 이상의 오브젝트에 기초하여, 상기 이미 지 기반 딕셔너리로부터 제2예상장소를 판단할 수 있다(S350). 보다 상세하게는 상기 장소 추정 시스템 은 상기 이미지 기반 딕셔너리에 포함된 항목 중 어느 하나를 상기 판단 대상 이미지의 매칭 항목으 로 판단하고 상기 매칭 항목의 장소를 제2예상장소로 판단할 수 있다(S350). 여기서 상기 매칭 항목은, 상기 판 단 대상 이미지에 포함된 상기 1 이상의 오브젝트를 모두 포함하는 집합을 가진 항목 중 가장 빈도가 큰 항목일 수 있다. 만약 상기 제1예상장소가 상기 제2예상장소와 동일하면(S360), 상기 장소 추정 시스템은 상기 제1예상장소 를 상기 판단 대상 이미지에 상응하는 장소로 결정할 수 있다(S370). 만약 상기 제1예상장소가 상기 제2예상장소와 상이하면(S360), 상기 장소 추정 시스템은 상기 텍스트 기반 딕셔너리에 기초하여 제1예상장소 및 상기 제2예상장소 중 어느 하나를 상기 판단 대상 이미지에 상응하는 장소로 결정할 수 있다(S380). 한편, 구현 예에 따라서, 상기 이미지 기반 장소 추정 시스템 및 상기 모델/딕셔너리 구축 시스템은 프로세서 및 상기 프로세서에 의해 실행되는 프로그램을 저장하는 메모리를 포함할 수 있다. 상기 프로세서는 싱글 코어 CPU혹은 멀티 코어 CPU를 포함할 수 있다. 메모리는 고속 랜덤 액세스 메모리를 포함할 수 있고 하나 이상의 자기 디스크 저장 장치, 플래시 메모리 장치, 또는 기타 비휘발성 고체상태 메모리 장치와 같은 비휘발 성 메모리를 포함할 수도 있다. 프로세서 및 기타 구성 요소에 의한 메모리로의 액세스는 메모리 컨트롤러에 의 해 제어될 수 있다. 한편, 본 발명의 실시예에 따른 방법은 컴퓨터가 읽을 수 있는 프로그램 명령 형태로 구현되어 컴퓨터로 읽을 수 있는 기록 매체에 저장될 수 있으며, 본 발명의 실시예에 따른 제어 프로그램 및 대상 프로그램도 컴퓨터로 판독 가능한 기록 매체에 저장될 수 있다. 컴퓨터가 읽을 수 있는 기록 매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록 장치를 포함한다. 기록 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 소프트웨어 분야 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터로 읽을 수 있는 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체 (magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media) 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하 고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용 해서 전자적으로 정보를 처리하는 장치, 예를 들어, 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한 다. 상술한 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될"}
{"patent_id": "10-2021-0073320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수 있으며, 그 역도 마찬가지이다.전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시 예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타나며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2021-0073320", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 상세한 설명에서 인용되는 도면을 보다 충분히 이해하기 위하여 각 도면의 간단한 설명이 제공된다. 도 1은 본 발명의 기술적 사상에 따른 이미지 기반의 장소 추정 방법이 수행되는 환경을 개략적으로 도시한 도 면이다. 도 2a는 이미지 기반 딕셔너리의 일 예를 도시한 도면이며, 도 2b는 텍스트 기반 딕셔너리의 일 예를 도시한 도 면이다. 도 3은 본 발명의 일 실시예에 따른 모델/딕셔너리 구축 시스템의 개략적인 구성을 도시한 블록도이다. 도 4는 본 발명의 일 실시예에 따른 모델/딕셔너리 구축 시스템이 이미지 기반 딕셔너리를 구축하는 과정을 도 시한 도면이다. 도 5는 본 발명의 일 실시예에 따른 모델/딕셔너리 구축 시스템이 텍스트 기반 딕셔너리를 구축하는 과정을 도시한 도면이다. 도 6은 본 발명의 일 실시예에 따른 이미지 기반 장초 추정 시스템의 구성을 도시한 블록이다. 도 7은 본 발명의 일 실시예에 따른 이미지 기반 장소 추정 방법의 개략적인 과정을 도시한 흐름도이다."}
