{"patent_id": "10-2022-0155291", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0161234", "출원번호": "10-2022-0155291", "발명의 명칭": "단대단 자체 적응에 기반한 분산식 훈련 방법, 장치, 기기", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "왕, 하이펑"}}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "단대단 자체 적응에 기반한 분산식 훈련 방법에 있어서,훈련할 모델을 분할하여, 분할 결과를 획득하는 단계; 상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 상기 컴퓨팅 자원의 속성을 획득하는 단계 -상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 상기 훈련할 모델의 컴퓨팅 자원 수요, 기타 훈련하고 있는 모델에 의해 점용된 컴퓨팅 자원 및 유휴 컴퓨팅 자원에 의해 결정된 것이고, 상기 컴퓨팅 자원의 속성은 상기 컴퓨팅 자원의 토폴로지 관계, 태스크 처리 능력 중의 적어도 하나를 나타내는데 사용됨 - ; 상기 컴퓨팅 자원의 속성을 이용하여, 상기 컴퓨팅 자원에서 각 상기 분할 결과의 분산 전략을 결정하는 단계;및상기 분산 전략에 따라, 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,훈련할 모델을 분할하여, 분할 결과를 획득하는 단계는, 상기 훈련할 모델의 연산자 및 텐서를 결정하는 단계; 상기 분할 전략을 이용하여, 상기 훈련할 모델의 연산자 및 텐서를 분할하여, 상기 분할 결과를 획득하는 단계;를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 분할 전략을 이용하여, 상기 훈련할 모델의 연산자 및 텐서를 분할하여, 상기 분할 결과를 획득하는 단계는,상기 분할 전략을 이용하여, 상기 훈련할 모델의 연산자 및 텐서를 분할하여, N개의 슬라이스를 획득하는 단계- 상기 N은 양의 정수임 - ; 각 상기 슬라이스에 대해, 상기 슬라이스의 분산식 속성 정보를 로딩하는 단계 - 상기 분산식 속성 정보는 상기훈련할 모델에서 당해 슬라이스의 프로세스 토폴로지 정보, 당해 슬라이스의 분할 매핑 정보, 당해 슬라이스의슬라이스 크기 정보 중의 적어도 하나를 포함함 - ; 상기 분산식 속성 정보를 로딩하는 슬라이스를 상기 분할 결과로 하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 분산식 속성 정보 카테고리의 결정 방식은,미리 설정된 방식을 이용하여 상기 분산식 속성 정보의 복수 후보 카테고리를 수신하는 단계;공개특허 10-2022-0161234-3-상기 복수의 후보 카테고리에서 타겟 카테고리를 결정하여, 상기 분산식 속성 정보의 카테고리로 하는 단계; 를포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,각 상기 슬라이스의 분산식 속성을 이용하여, 각 상기 슬라이스의 배치 정보를 결정하는 단계를 더 포함하고,상기 배치 정보가 상기 슬라이스와 상기 컴퓨팅 자원의 물리 매핑 관계를 나타내는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 슬라이스가 상기 훈련할 모델의 인접 네트워크층에 위치하고 상기 슬라이스의 배치 정보가 부동할 경우,상기 배치 정보를 이용하여, 통신 보조 연산자를 결정하하는 단계를 포함하고, 상기 통신 보조 연산자가 각 상기 슬라이스 사이의 논리 연산 관계를 나타내는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 슬라이스가 훈련할 모델의 동일 네트워크층에 위치할 경우,각 상기 슬라이스 사이의 네트워크층 일치성 관계를 나타내는데 사용되는 재구성 전환 연산자를 결정하는 단계를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제2항에 있어서,상기 분할 전략의 결정 방식은,상기 사용자 단말에 의해 시작된 모델 훈련 요청에 대해 분석 결정을 수행하는 단계를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제2항에 있어서,상기 분할 전략의 결정 방식은,미리 훈련된 분할 전략을 이용하여 모델 결정을 수행하는 단계를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 컴퓨팅 자원의 속성을 획득하는 단계는, 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하고, 상기 하드웨어 토폴로지 관계를 상기 컴퓨팅 자원의속성으로 하는 단계를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.공개특허 10-2022-0161234-4-청구항 11 제10항에 있어서, 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하는 단계는, 상기 컴퓨팅 자원의 최소 어셈블리를 결정하는 단계 - 상기 최소 어셈블리는 프로세서 또는 메모리를 포함함 -; 적어도 하나의 상기 최소 어셈블리로 구성된 기계 기기를 결정하는 단계 - 각 상기 기계 기기의 최소 어셈블리는 중복되지 않음 - ; 적어도 하나의 상기 기계 기기로 구성된 클러스터를 결정하는 단계 - 각 상기 클러스터의 기계 기기는 중복되지않음 - ; 및상기 최소 어셈블리, 상기 기계 기기 및 상기 클러스터를 컴퓨팅 자원의 하드웨어 토폴로지 관계로 하는 단계;를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하는 단계는,각 상기 최소 어셈블리의 밀접 관계 리스트를 결정하는 단계 - 상기 밀접 관계 리스트는 소스 최소 어셈블리와목적 최소 어셈블리 사이의 연결 관계, 대역폭 정보 및 지연 정보 중의 적어도 하나를 포함함 - ; 상기 밀접 관계 리스트를 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계로 하는 단계; 를 더 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항 또는 제10항에 있어서,상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 상기 사용자 단말에 의해 시작된 모델 훈련 요청의 내용및 모델 훈련 요청을 시작하는 사용자 단말의 수량 중의 적어도 하나에 따라 결정되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항 또는 제10항에 있어서,상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 상기 컴퓨팅 자원의 속성을 획득하는 단계는,상기 컴퓨팅 자원의 통신 경로를 획득하는 단계; 상기 컴퓨팅 자원의 통신 경로를 이용하여, 각 상기 컴퓨팅 자원 사이의 통신 토폴로지 관계를 구축하는 단계;및상기 통신 토폴로지 관계를 상기 컴퓨팅 자원의 속성으로 하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 통신 토폴로지 관계에 따라, 소스 컴퓨팅 자원과 타겟 컴퓨팅 자원 사이의 최단 통신 경로를 결정하는 단계를 더 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.공개특허 10-2022-0161234-5-청구항 16 제1항에 있어서,상기 컴퓨팅 자원의 속성을 이용하여, 상기 컴퓨팅 자원에서 각 상기 분할 결과의 분산 전략을 결정하는단계는,상기 컴퓨팅 자원에서 각 상기 분할 결과의 후보 분산 전략을 결정하는 단계; 각 상기 후보 분산 전략의 효율을 각각 통계하는 단계; 및각 상기 후보 분산 전략의 효율에 따라, 상기 후보 분산 전략에서 타겟 분산 전략을 결정하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제1항에 있어서,각 상기 후보 분산 전략의 효율에 따라, 상기 후보 분산 전략에서 타겟 분산 전략을 결정하는 단계는,미리 설정된 규칙을 이용하여, 각 상기 후보 분산 전략을 정렬하는 단계; 정렬된 결과에 따라, 상기 후보 분산 전략에서 타겟 분산 전략을 결정하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제1항에 있어서,상기 분산 전략에 따라, 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련하는 단계는,상기 컴퓨팅 자원의 가용성을 정기적으로 검출하는 단계;검출 결과에 상기 컴퓨팅 자원의 불가용이 존재할 경우, 보완 조치를 수행하는 단계 - 상기 불가용 상황은 컴퓨팅 자원 고장 또는 컴퓨팅 자원 수량의 축소를 포함함 - ; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 불가용 상황이 컴퓨팅 자원 고장일 경우, 상기 보완 조치를 수행하는 단계는, 상기 사용자 단말에 의해 시작된 모델 훈련 요청에 포함된 훈련 모드를 획득하는 단계;상기 훈련 모드가 내결함성 훈련 모드일 경우, 컴퓨팅 자원의 고장이 복구될 때 까지 대기하는 단계; 및미리 설정된 시간 내에 상기 컴퓨팅 자원의 고장이 복구되지 않을 경우, 수행 종료로 결정하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 불가용이 컴퓨팅 자원 고장일 경우, 상기 보완 조치를 수행하는 단계는,상기 훈련 모드가 탄성 훈련 모드일 경우, 후보 컴퓨팅 자원을 결정하는 단계;상기 후보 컴퓨팅 자원에서 훈련의 재시행을 진행하는 단계; 를 더 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.공개특허 10-2022-0161234-6-청구항 21 제20항에 있어서,상기 후보 컴퓨팅 자원에서 훈련의 재시행을 진행하는 단계는,상기 컴퓨팅 자원이 고장날 경우의 훈련 상태를 획득하는 단계; 상기 훈련 상태를 기반으로, 상기 후보 컴퓨팅 자원에서 훈련 재시행을 진행하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제20항에 있어서,상기 후보 컴퓨팅 자원에서 재시행하는 단계는, 훈련의 최초 상태를 획득하는 단계; 상기 최초 상태를 기반으로, 상기 후보 컴퓨팅 자원에서 훈련 재시행을 진행하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제18항에 있어서,상기 불가용 상황이 컴퓨팅 자원 수량의 축소일 경우, 상기 보완 조치를 수행하는 단계는,축소된 상기 컴퓨팅 자원의 제1 수량을 결정하는 단계;상기 제1 수량에 따라, 상기 훈련할 모델을 재분할하여, 재분할된 제1 결과를 획득하는 단계;재결정된 축소 후의 나머지 상기 컴퓨팅 자원의 속성을 이용하여, 축소된 상기 컴퓨팅 자원에서 각 상기 재분할된 제1 결과의 제1 분산 전략을 결정하는 단계; 및상기 제1 분산 전략에 따라, 축소된 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련을 수행하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제18항에 있어서,검출 결과에 사용 가능한 여분의 컴퓨팅 자원이 존재할 경우,사용 가능한 상기 여분의 컴퓨팅 자원의 제2 수량을 결정하는 단계;상기 제2 수량에 따라, 상기 훈련할 모델을 재분할하여, 재분할된 제2 결과를 획득하는 단계;다시 결정된 여분의 상기 컴퓨팅 자원의 속성을 이용하여, 확장된 상기 컴퓨팅 자원에서 각 상기 재분할된 제2결과의 제2 분산 전략을 결정하는 단계; 및상기 제2 분산 전략에 따라, 확장된 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련을 수행하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제23항에 있어서,상기 컴퓨팅 자원의 수량이 변화될 경우,변화된 수량에 따라, 상기 훈련할 모델의 학습률 및 단번의 훈련에 선택된 샘플 수량을 조정하는 단계를 더 포공개특허 10-2022-0161234-7-함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제1항에 있어서,상기 분산식 훈련이, 분산 비동기 파이프라인 훈련을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제1항에 있어서,상기 훈련할 모델은 사용자 단말에 의해 시작된 모델 훈련 요청에 따라 획득되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "단대단 자체 적응에 기반한 분산식 훈련 장치에 있어서,훈련할 모델을 분할하여, 분할 결과를 획득하는데 사용되는 분할 모듈; 상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 상기 컴퓨팅 자원의 속성을 획득하는데 사용되는 컴퓨팅 자원의 속성 결정 모듈 - 상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 상기 훈련할 모델의컴퓨팅 자원 수요, 기타 훈련하고 있는 모델에 의해 점용된 컴퓨팅 자원 및 유휴 컴퓨팅 자원에 의해 결정된 것이고, 상기 컴퓨팅 자원의 속성은 상기 컴퓨팅 자원의 토폴로지 관계, 태스크 처리 능력 중의 적어도 하나를 나타내는데 사용됨 - ; 상기 컴퓨팅 자원의 속성을 이용하여, 상기 컴퓨팅 자원에서 각 상기 분할 결과의 분산 전략을 결정하는데 사용되는 분산 전략 결정 모듈; 및 상기 분산 전략에 따라, 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련하는데 사용되는 분산식 훈련 모듈; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제28항에 있어서,상기 분할 모듈은,상기 훈련할 모델의 연산자 및 텐서를 결정하는데 사용되는 연산자 및 텐서의 결정 서브 모듈; 상기 분할 전략을 이용하여, 상기 훈련할 모델의 연산자 및 텐서를 분할하여, 상기 분할 결과를 획득하는데 사용되는 분할 수행 서브 모듈; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제29항에 있어서,상기 분할 수행 서브 모듈은,상기 분할 전략을 이용하여, 상기 훈련할 모델의 연산자 및 텐서를 분할하여, N개의 슬라이스를 획득하는데 사용되는 분할 전략 수행 유닛 - 상기 N은 양의 정수임 - ; 각 상기 슬라이스에 대해, 상기 슬라이스의 분산식 속성 정보를 로딩하는데 사용되는 분산식 속성 정보 로딩 유닛 - 상기 분산식 속성 정보는 상기 훈련할 모델에서 당해 슬라이스의 프로세스 토폴로지 정보, 당해 슬라이스의 분할 매핑 정보, 당해 슬라이스의 슬라이스 크기 정보 중의 적어도 하나를 포함함 - ; 을 포함하고,공개특허 10-2022-0161234-8-상기 분산식 속성 정보를 로딩하는 슬라이스를 상기 분할 결과로 하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제30항에 있어서,상기 분산식 속성 정보 로딩 유닛은, 미리 설정된 방식을 이용하여 상기 분산식 속성 정보의 복수 후보 카테고리를 수신하는데 사용되는 후보 카테고리 수신 서브 유닛; 상기 복수의 후보 카테고리에서 타겟 카테고리를 결정하여, 상기 분산식 속성 정보의 카테고리로 하는데 사용되는 선별 서브 유닛; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제30항에 있어서,배치 정보 결정 유닛을 더 포함하고, 상기 배치 정보 결정 유닛은, 각 상기 슬라이스의 분산식 속성을 이용하여, 각 상기 슬라이스의 배치 정보를 결정하는데 사용되고, 상기 배치정보가 상기 슬라이스와 상기 컴퓨팅 자원의 물리 매핑 관계를 나타내는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "제32항에 있어서,상기 슬라이스가 상기 훈련할 모델의 인접 네트워크층에 위치하고 상기 슬라이스의 배치 정보가 부동할 경우,통신 보조 연산자 결정 유닛을 포함하고, 구체적으로, 상기 배치 정보를 이용하여, 통신 보조 연산자를 결정하하는데 사용되고, 상기 통신 보조 연산자가 각 상기 슬라이스 사이의 논리 연산 관계를 나타내는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제32항에 있어서,상기 슬라이스가 훈련할 모델의 동일 네트워크층에 위치할 경우, 재구성 전환 연산자 결정 유닛을 포함하고, 상기 재구성 전환 연산자 결정 유닛은, 각 상기 슬라이스 사이의 네트워크층 일치성 관계를 나타내는데 사용되는 재구성 전환 연산자를 결정하는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "제29항 내지 제34항 중의 어느 한 항에 있어서,상기 분할 수행 서브 모듈은, 상기 사용자 단말에 의해 시작된 모델 훈련 요청에 대해 분석 결정을 수행하는데 사용되는 분할 전략 결정 유닛을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "공개특허 10-2022-0161234-9-제29항 내지 제34항 중의 어느 한 항에 있어서,상기 분할 수행 서브 모듈은, 미리 훈련된 분할 전략을 이용하여 모델 결정을 수행하는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_37", "content": "제28항에 있어서,상기 컴퓨팅 자원의 속성 결정 모듈은, 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하고, 상기 하드웨어 토폴로지 관계를 상기 컴퓨팅 자원의속성으로 하는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_38", "content": "제37항에 있어서,상기 컴퓨팅 자원의 속성 결정 모듈은, 상기 컴퓨팅 자원의 최소 어셈블리를 결정하는데 사용되는 최소 어셈블리 결정 서브 모듈 - 상기 최소 어셈블리는 프로세서 또는 메모리를 포함함 - ; 적어도 하나의 상기 최소 어셈블리로 구성된 기계 기기를 결정하는데 사용되는 기계 기기 결정 서브 모듈 - 각상기 기계 기기의 최소 어셈블리는 중복되지 않음 - ; 및적어도 하나의 상기 기계 기기로 구성된 클러스터를 결정하는데 사용되는 클러스터 결정 서브 모듈 - 각 상기클러스터의 기계 기기는 중복되지 않음 - ; 를 포함하고,상기 최소 어셈블리, 상기 기계 기기 및 상기 클러스터를 컴퓨팅 자원의 하드웨어 토폴로지 관계로 하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_39", "content": "제38항에 있어서,상기 컴퓨팅 자원의 속성 결정 모듈은, 각 상기 최소 어셈블리의 밀접 관계 리스트를 결정하고; 상기 밀접 관계 리스트는 소스 최소 어셈블리와 목적최소 어셈블리 사이의 연결 관계, 대역폭 정보 및 지연 정보 중의 적어도 하나를 포함하고, 상기 밀접 관계 리스트를 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계로 하는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_40", "content": "제28항 또는 제37항에 있어서,상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 상기 사용자 단말에 의해 시작된 모델 훈련 요청의 내용및 모델 훈련 요청을 시작하는 사용자 단말의 수량 중의 적어도 하나에 따라 결정되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_41", "content": "제28항 또는 제37항에 있어서,상기 컴퓨팅 자원의 속성 결정 모듈은, 공개특허 10-2022-0161234-10-상기 컴퓨팅 자원의 통신 경로를 획득하는데 사용되는 통신 경로 획득 서브 모듈; 상기 컴퓨팅 자원의 통신 경로를 이용하여, 각 상기 컴퓨팅 자원 사이의 통신 토폴로지 관계를 구축하는데 사용되는 통신 토폴로지 관계 구축 서브 모듈; 을 포함하고, 상기 통신 토폴로지 관계를 상기 컴퓨팅 자원의 속성으로 하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_42", "content": "제41항에 있어서,최단 통신 경로 구축 서브 모듈을 더 포함하고, 상기 최단 통신 경로 구축 서브 모듈은, 상기 통신 토폴로지 관계에 따라, 소스 컴퓨팅 자원과 타겟 컴퓨팅 자원 사이의 최단 통신 경로를 결정하는데사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_43", "content": "제28항에 있어서,상기 분산 전략 결정 모듈은, 상기 컴퓨팅 자원에서 각 상기 분할 결과의 후보 분산 전략을 결정하는데 사용되는 후보 분산 전략 획득 서브모듈; 각 상기 후보 분산 전략의 효율을 각각 통계하는데 사용되는 효율 통계 서브 모듈; 및 각 상기 후보 분산 전략의 효율에 따라, 상기 후보 분산 전략에서 타겟 분산 전략을 결정하는데 사용되는 타겟분산 전략 결정 서브 모듈; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_44", "content": "제28항 또는 제43항에 있어서,상기 타겟 분산 전략 결정 서브 모듈은, 미리 설정된 규칙을 이용하여, 각 상기 후보 분산 전략을 정렬하는데 사용되는 정렬 유닛; 미리 설정된 규칙을 이용하여, 각 상기 후보 분산 전략을 정렬하는데 사용되는 결과 결정 유닛; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_45", "content": "제28항에 있어서,상기 분산식 훈련 모듈은, 상기 컴퓨팅 자원의 가용성을 정기적으로 검출하는데 사용되는 가용성 검출 서브 모듈; 검출 결과에 상기 컴퓨팅 자원의 불가용이 존재할 경우, 보완 조치를 수행하는데 사용되는 보완 조치 수행 서브모듈 - 상기 불가용 상황은 컴퓨팅 자원 고장 또는 컴퓨팅 자원 수량의 축소를 포함함 - ; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_46", "content": "제45항에 있어서,상기 불가용 상황이 컴퓨팅 자원 고장일 경우, 상기 보완 조치 수행 서브 모듈은, 공개특허 10-2022-0161234-11-상기 사용자 단말에 의해 시작된 모델 훈련 요청에 포함된 훈련 모드를 획득하는데 사용되는 훈련 모드 획득 유닛; 상기 훈련 모드가 내결함성 훈련 모드일 경우, 컴퓨팅 자원의 고장이 복구될 때 까지 대기하는데 사용되는 대기유닛; 및 미리 설정된 시간 내에 상기 컴퓨팅 자원의 고장이 복구되지 않을 경우, 수행 종료로 결정하는데 사용되는 결과결정 유닛; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_47", "content": "제46항에 있어서,상기 불가용이 컴퓨팅 자원 고장일 경우, 상기 보완 조치 수행 서브 모듈은, 상기 훈련 모드가 탄성 훈련 모드일 경우, 후보 컴퓨팅 자원을 결정하는데 사용되는 후보 컴퓨팅 자원 결정 유닛; 상기 후보 컴퓨팅 자원에서 훈련의 재시행을 진행하는데 사용되는 재시행 유닛; 을 더 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_48", "content": "제47항에 있어서,상기 재시행 유닛은, 상기 컴퓨팅 자원이 고장날 경우의 훈련 상태를 획득하는데 사용되는 훈련 상태 획득 서브 유닛; 상기 훈련 상태를 기반으로, 상기 후보 컴퓨팅 자원에서 훈련 재시행을 진행하는데 사용되는 재시행 수행 서브유닛; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_49", "content": "제47항에 있어서,상기 재시행 유닛은, 훈련의 최초 상태를 획득하는데 사용되는 최초 상태 획득 서브 유닛; 훈련의 최초 상태를 획득하는데 사용되는 재시행 수행 서브 유닛; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_50", "content": "제45항에 있어서,상기 불가용 상황이 컴퓨팅 자원 수량의 축소일 경우, 상기 보완 조치 수행 서브 모듈은, 축소된 상기 컴퓨팅 자원의 제1 수량을 결정하는데 사용되는 제1 수량 결정 유닛; 상기 제1 수량에 따라, 상기 훈련할 모델을 재분할하여, 재분할된 제1 결과를 획득하는데 사용되는 제1 재분할유닛; 재결정된 축소 후의 나머지 상기 컴퓨팅 자원의 속성을 이용하여, 축소된 상기 컴퓨팅 자원에서 각 상기 재분할된 제1 결과의 제1 분산 전략을 결정하는데 사용되는 제1 분산 전략 결정 유닛; 및 상기 제1 분산 전략에 따라, 축소된 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련을 수행하는데 사용되는 분산식 훈련 수행 유닛; 을 포함하는,공개특허 10-2022-0161234-12-것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_51", "content": "제45항에 있어서,검출 결과에 사용 가능한 여분의 컴퓨팅 자원이 존재할 경우,사용 가능한 상기 여분의 컴퓨팅 자원의 제2 수량을 결정하는데 사용되는 제2 수량 결정 유닛; 상기 제2 수량에 따라, 상기 훈련할 모델을 재분할하여, 재분할된 제2 결과를 획득하는데 사용되는 제2 재분할유닛; 다시 결정된 여분의 상기 컴퓨팅 자원의 속성을 이용하여, 확장된 상기 컴퓨팅 자원에서 각 상기 재분할된 제2결과의 제2 분산 전략을 결정하는데 사용되는 제2 분산 전략 결정 유닛; 및상기 제2 분산 전략에 따라, 확장된 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련을 수행하는데 사용되는 분산식 훈련 수행 유닛; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_52", "content": "제50항 또는 제51항에 있어서,상기 컴퓨팅 자원의 수량이 변화될 경우, 조정 서브 유닛을 더 포함하고, 상기 조정 서브 유닛은, 변화된 수량에 따라, 상기 훈련할 모델의 학습률 및 단번의 훈련에 선택된 샘플 수량을 조정하는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_53", "content": "제28항, 제45항, 제50항 또는 제51항 중 어느 한 항에 있어서,상기 분산식 훈련이, 분산 비동기 파이프라인 훈련을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_54", "content": "제28항 내지 제53항 중 어느 한 항에 있어서,상기 훈련할 모델은 사용자 단말에 의해 시작된 모델 훈련 요청에 따라 획득되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_55", "content": "전자 기기에 있어서,적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서에 통신 가능하게 연결되는 메모리; 를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령이 당해 적어도 하나의 프로세서에 의해 실행될 경우, 상기 적어도 하나의 프로세서가 제1항 내지 제27항 중 어느 한 항의방법을 수행하는, 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_56", "content": "컴퓨터 프로그램이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체에 있어서,상기 컴퓨터 프로그램이 수행될 경우 제1항 내지 제27항 중 어느 한 항의 방법이 구현되는,공개특허 10-2022-0161234-13-것을 특징으로 하는 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2022-0155291", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_57", "content": "컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램이 프로세서에 의해 수행 될 경우 제1항 내지 제27항 중 어느 한 항의 방법을 구현하는,것을 특징으로 하는 컴퓨터 프로그램."}
{"patent_id": "10-2022-0155291", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 단대단 자체 적응에 기반한 분산식 훈련 방법, 장치, 기기 및 저장 매체를 제공하고, 인공지능"}
{"patent_id": "10-2022-0155291", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것으로, 특히 딥러닝, 클라우드 컴퓨팅 등 분야에 관한 것이다. 구체적인 구현 수단은, 훈련할 모델 을 분할하여, 분할 결과를 획득하는 단계; 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 컴퓨팅 자 (뒷면에 계속) 대 표 도 - 도1"}
{"patent_id": "10-2022-0155291", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2022-0161234 원의 속성을 획득하는 단계 - 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 훈련할 모델의 컴퓨팅 자원 수요, 기타 훈련하고 있는 모델에 의해 점용된 컴퓨팅 자원 및 유휴 컴퓨팅 자원에 의해 결정된 것이고, 컴퓨팅 자원의 속성은 컴퓨팅 자원의 토폴로지 관계, 태스크 처리 능력 중의 적어도 하나를 나타내는데 사용됨 - ; 컴퓨팅 자원 의 속성을 이용하여, 컴퓨팅 자원에서 각 분할 결과의 분산 전략을 결정하는 단계; 및 분산 전략에 따라, 컴퓨팅 자원을 이용하여 훈련할 모델에 대해 분산식 훈련하는 단계; 를 포함한다. 모델 훈련의 단대단 자체 적응 조절을 구현할 수 있다. CPC특허분류 G06F 9/5083 (2013.01) G06N 20/20 (2021.08) G06N 3/08 (2013.01) 발명자 유, 디안하이 중국 베이징 100085 하이디안 디스트릭트 샹디 10 번가 넘버 10, 바이두 캠퍼스 2층 마, 얀준 중국 베이징 100085 하이디안 디스트릭트 샹디 10 번가 넘버 10, 바이두 캠퍼스 2층우, 티안 중국 베이징 100085 하이디안 디스트릭트 샹디 10 번가 넘버 10, 바이두 캠퍼스 2층명 세 서 청구범위 청구항 1 단대단 자체 적응에 기반한 분산식 훈련 방법에 있어서, 훈련할 모델을 분할하여, 분할 결과를 획득하는 단계; 상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 상기 컴퓨팅 자원의 속성을 획득하는 단계 - 상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 상기 훈련할 모델의 컴퓨팅 자원 수요, 기타 훈련하고 있 는 모델에 의해 점용된 컴퓨팅 자원 및 유휴 컴퓨팅 자원에 의해 결정된 것이고, 상기 컴퓨팅 자원의 속성은 상 기 컴퓨팅 자원의 토폴로지 관계, 태스크 처리 능력 중의 적어도 하나를 나타내는데 사용됨 - ; 상기 컴퓨팅 자원의 속성을 이용하여, 상기 컴퓨팅 자원에서 각 상기 분할 결과의 분산 전략을 결정하는 단계; 및 상기 분산 전략에 따라, 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련하는 단계; 를 포함 하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 2 제1항에 있어서, 훈련할 모델을 분할하여, 분할 결과를 획득하는 단계는, 상기 훈련할 모델의 연산자 및 텐서를 결정하는 단계; 상기 분할 전략을 이용하여, 상기 훈련할 모델의 연산자 및 텐서를 분할하여, 상기 분할 결과를 획득하는 단계; 를 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 3 제2항에 있어서, 상기 분할 전략을 이용하여, 상기 훈련할 모델의 연산자 및 텐서를 분할하여, 상기 분할 결과를 획득하는 단계 는, 상기 분할 전략을 이용하여, 상기 훈련할 모델의 연산자 및 텐서를 분할하여, N개의 슬라이스를 획득하는 단계 - 상기 N은 양의 정수임 - ; 각 상기 슬라이스에 대해, 상기 슬라이스의 분산식 속성 정보를 로딩하는 단계 - 상기 분산식 속성 정보는 상기 훈련할 모델에서 당해 슬라이스의 프로세스 토폴로지 정보, 당해 슬라이스의 분할 매핑 정보, 당해 슬라이스의 슬라이스 크기 정보 중의 적어도 하나를 포함함 - ; 상기 분산식 속성 정보를 로딩하는 슬라이스를 상기 분할 결과로 하는 단계; 를 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 4 제3항에 있어서, 상기 분산식 속성 정보 카테고리의 결정 방식은, 미리 설정된 방식을 이용하여 상기 분산식 속성 정보의 복수 후보 카테고리를 수신하는 단계;상기 복수의 후보 카테고리에서 타겟 카테고리를 결정하여, 상기 분산식 속성 정보의 카테고리로 하는 단계; 를 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 5 제3항에 있어서, 각 상기 슬라이스의 분산식 속성을 이용하여, 각 상기 슬라이스의 배치 정보를 결정하는 단계를 더 포함하고, 상기 배치 정보가 상기 슬라이스와 상기 컴퓨팅 자원의 물리 매핑 관계를 나타내는데 사용되는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 6 제5항에 있어서, 상기 슬라이스가 상기 훈련할 모델의 인접 네트워크층에 위치하고 상기 슬라이스의 배치 정보가 부동할 경우, 상기 배치 정보를 이용하여, 통신 보조 연산자를 결정하하는 단계를 포함하고, 상기 통신 보조 연산자가 각 상 기 슬라이스 사이의 논리 연산 관계를 나타내는데 사용되는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 7 제5항에 있어서, 상기 슬라이스가 훈련할 모델의 동일 네트워크층에 위치할 경우, 각 상기 슬라이스 사이의 네트워크층 일치성 관계를 나타내는데 사용되는 재구성 전환 연산자를 결정하는 단계 를 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 8 제2항에 있어서, 상기 분할 전략의 결정 방식은, 상기 사용자 단말에 의해 시작된 모델 훈련 요청에 대해 분석 결정을 수행하는 단계를 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 9 제2항에 있어서, 상기 분할 전략의 결정 방식은, 미리 훈련된 분할 전략을 이용하여 모델 결정을 수행하는 단계를 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 10 제1항에 있어서, 상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 컴퓨팅 자원의 속성을 획득하는 단계는, 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하고, 상기 하드웨어 토폴로지 관계를 상기 컴퓨팅 자원의 속성으로 하는 단계를 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.청구항 11 제10항에 있어서, 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하는 단계는, 상기 컴퓨팅 자원의 최소 어셈블리를 결정하는 단계 - 상기 최소 어셈블리는 프로세서 또는 메모리를 포함함 - ; 적어도 하나의 상기 최소 어셈블리로 구성된 기계 기기를 결정하는 단계 - 각 상기 기계 기기의 최소 어셈블리 는 중복되지 않음 - ; 적어도 하나의 상기 기계 기기로 구성된 클러스터를 결정하는 단계 - 각 상기 클러스터의 기계 기기는 중복되지 않음 - ; 및 상기 최소 어셈블리, 상기 기계 기기 및 상기 클러스터를 컴퓨팅 자원의 하드웨어 토폴로지 관계로 하는 단계; 를 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 12 제11항에 있어서, 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하는 단계는, 각 상기 최소 어셈블리의 밀접 관계 리스트를 결정하는 단계 - 상기 밀접 관계 리스트는 소스 최소 어셈블리와 목적 최소 어셈블리 사이의 연결 관계, 대역폭 정보 및 지연 정보 중의 적어도 하나를 포함함 - ; 상기 밀접 관계 리스트를 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계로 하는 단계; 를 더 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 13 제1항 또는 제10항에 있어서, 상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 상기 사용자 단말에 의해 시작된 모델 훈련 요청의 내용 및 모델 훈련 요청을 시작하는 사용자 단말의 수량 중의 적어도 하나에 따라 결정되는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 14 제1항 또는 제10항에 있어서, 상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 상기 컴퓨팅 자원의 속성을 획득하는 단계는, 상기 컴퓨팅 자원의 통신 경로를 획득하는 단계; 상기 컴퓨팅 자원의 통신 경로를 이용하여, 각 상기 컴퓨팅 자원 사이의 통신 토폴로지 관계를 구축하는 단계; 및 상기 통신 토폴로지 관계를 상기 컴퓨팅 자원의 속성으로 하는 단계; 를 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 15 제14항에 있어서, 상기 통신 토폴로지 관계에 따라, 소스 컴퓨팅 자원과 타겟 컴퓨팅 자원 사이의 최단 통신 경로를 결정하는 단 계를 더 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.청구항 16 제1항에 있어서, 상기 컴퓨팅 자원의 속성을 이용하여, 상기 컴퓨팅 자원에서 각 상기 분할 결과의 분산 전략을 결정하는 단계는, 상기 컴퓨팅 자원에서 각 상기 분할 결과의 후보 분산 전략을 결정하는 단계; 각 상기 후보 분산 전략의 효율을 각각 통계하는 단계; 및 각 상기 후보 분산 전략의 효율에 따라, 상기 후보 분산 전략에서 타겟 분산 전략을 결정하는 단계; 를 포함하 는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 17 제1항에 있어서, 각 상기 후보 분산 전략의 효율에 따라, 상기 후보 분산 전략에서 타겟 분산 전략을 결정하는 단계는, 미리 설정된 규칙을 이용하여, 각 상기 후보 분산 전략을 정렬하는 단계; 정렬된 결과에 따라, 상기 후보 분산 전략에서 타겟 분산 전략을 결정하는 단계; 를 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 18 제1항에 있어서, 상기 분산 전략에 따라, 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련하는 단계는, 상기 컴퓨팅 자원의 가용성을 정기적으로 검출하는 단계; 검출 결과에 상기 컴퓨팅 자원의 불가용이 존재할 경우, 보완 조치를 수행하는 단계 - 상기 불가용 상황은 컴퓨 팅 자원 고장 또는 컴퓨팅 자원 수량의 축소를 포함함 - ; 를 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 19 제18항에 있어서, 상기 불가용 상황이 컴퓨팅 자원 고장일 경우, 상기 보완 조치를 수행하는 단계는, 상기 사용자 단말에 의해 시작된 모델 훈련 요청에 포함된 훈련 모드를 획득하는 단계; 상기 훈련 모드가 내결함성 훈련 모드일 경우, 컴퓨팅 자원의 고장이 복구될 때 까지 대기하는 단계; 및 미리 설정된 시간 내에 상기 컴퓨팅 자원의 고장이 복구되지 않을 경우, 수행 종료로 결정하는 단계; 를 포함하 는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 20 제19항에 있어서, 상기 불가용이 컴퓨팅 자원 고장일 경우, 상기 보완 조치를 수행하는 단계는, 상기 훈련 모드가 탄성 훈련 모드일 경우, 후보 컴퓨팅 자원을 결정하는 단계; 상기 후보 컴퓨팅 자원에서 훈련의 재시행을 진행하는 단계; 를 더 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.청구항 21 제20항에 있어서, 상기 후보 컴퓨팅 자원에서 훈련의 재시행을 진행하는 단계는, 상기 컴퓨팅 자원이 고장날 경우의 훈련 상태를 획득하는 단계; 상기 훈련 상태를 기반으로, 상기 후보 컴퓨팅 자원에서 훈련 재시행을 진행하는 단계; 를 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 22 제20항에 있어서, 상기 후보 컴퓨팅 자원에서 재시행하는 단계는, 훈련의 최초 상태를 획득하는 단계; 상기 최초 상태를 기반으로, 상기 후보 컴퓨팅 자원에서 훈련 재시행을 진행하는 단계; 를 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 23 제18항에 있어서, 상기 불가용 상황이 컴퓨팅 자원 수량의 축소일 경우, 상기 보완 조치를 수행하는 단계는, 축소된 상기 컴퓨팅 자원의 제1 수량을 결정하는 단계; 상기 제1 수량에 따라, 상기 훈련할 모델을 재분할하여, 재분할된 제1 결과를 획득하는 단계; 재결정된 축소 후의 나머지 상기 컴퓨팅 자원의 속성을 이용하여, 축소된 상기 컴퓨팅 자원에서 각 상기 재분할 된 제1 결과의 제1 분산 전략을 결정하는 단계; 및 상기 제1 분산 전략에 따라, 축소된 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련을 수행 하는 단계; 를 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 24 제18항에 있어서, 검출 결과에 사용 가능한 여분의 컴퓨팅 자원이 존재할 경우, 사용 가능한 상기 여분의 컴퓨팅 자원의 제2 수량을 결정하는 단계; 상기 제2 수량에 따라, 상기 훈련할 모델을 재분할하여, 재분할된 제2 결과를 획득하는 단계; 다시 결정된 여분의 상기 컴퓨팅 자원의 속성을 이용하여, 확장된 상기 컴퓨팅 자원에서 각 상기 재분할된 제2 결과의 제2 분산 전략을 결정하는 단계; 및 상기 제2 분산 전략에 따라, 확장된 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련을 수행 하는 단계; 를 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 25 제23항에 있어서, 상기 컴퓨팅 자원의 수량이 변화될 경우, 변화된 수량에 따라, 상기 훈련할 모델의 학습률 및 단번의 훈련에 선택된 샘플 수량을 조정하는 단계를 더 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 26 제1항에 있어서, 상기 분산식 훈련이, 분산 비동기 파이프라인 훈련을 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 27 제1항에 있어서, 상기 훈련할 모델은 사용자 단말에 의해 시작된 모델 훈련 요청에 따라 획득되는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 28 단대단 자체 적응에 기반한 분산식 훈련 장치에 있어서, 훈련할 모델을 분할하여, 분할 결과를 획득하는데 사용되는 분할 모듈; 상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 상기 컴퓨팅 자원의 속성을 획득하는데 사용되 는 컴퓨팅 자원의 속성 결정 모듈 - 상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 상기 훈련할 모델의 컴퓨팅 자원 수요, 기타 훈련하고 있는 모델에 의해 점용된 컴퓨팅 자원 및 유휴 컴퓨팅 자원에 의해 결정된 것 이고, 상기 컴퓨팅 자원의 속성은 상기 컴퓨팅 자원의 토폴로지 관계, 태스크 처리 능력 중의 적어도 하나를 나 타내는데 사용됨 - ; 상기 컴퓨팅 자원의 속성을 이용하여, 상기 컴퓨팅 자원에서 각 상기 분할 결과의 분산 전략을 결정하는데 사용 되는 분산 전략 결정 모듈; 및 상기 분산 전략에 따라, 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련하는데 사용되는 분 산식 훈련 모듈; 을 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 29 제28항에 있어서, 상기 분할 모듈은, 상기 훈련할 모델의 연산자 및 텐서를 결정하는데 사용되는 연산자 및 텐서의 결정 서브 모듈; 상기 분할 전략을 이용하여, 상기 훈련할 모델의 연산자 및 텐서를 분할하여, 상기 분할 결과를 획득하는데 사 용되는 분할 수행 서브 모듈; 을 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 30 제29항에 있어서, 상기 분할 수행 서브 모듈은, 상기 분할 전략을 이용하여, 상기 훈련할 모델의 연산자 및 텐서를 분할하여, N개의 슬라이스를 획득하는데 사 용되는 분할 전략 수행 유닛 - 상기 N은 양의 정수임 - ; 각 상기 슬라이스에 대해, 상기 슬라이스의 분산식 속성 정보를 로딩하는데 사용되는 분산식 속성 정보 로딩 유 닛 - 상기 분산식 속성 정보는 상기 훈련할 모델에서 당해 슬라이스의 프로세스 토폴로지 정보, 당해 슬라이스 의 분할 매핑 정보, 당해 슬라이스의 슬라이스 크기 정보 중의 적어도 하나를 포함함 - ; 을 포함하고,상기 분산식 속성 정보를 로딩하는 슬라이스를 상기 분할 결과로 하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 31 제30항에 있어서, 상기 분산식 속성 정보 로딩 유닛은, 미리 설정된 방식을 이용하여 상기 분산식 속성 정보의 복수 후보 카테고리를 수신하는데 사용되는 후보 카테고 리 수신 서브 유닛; 상기 복수의 후보 카테고리에서 타겟 카테고리를 결정하여, 상기 분산식 속성 정보의 카테고리로 하는데 사용되 는 선별 서브 유닛; 을 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 32 제30항에 있어서, 배치 정보 결정 유닛을 더 포함하고, 상기 배치 정보 결정 유닛은, 각 상기 슬라이스의 분산식 속성을 이용하여, 각 상기 슬라이스의 배치 정보를 결정하는데 사용되고, 상기 배치 정보가 상기 슬라이스와 상기 컴퓨팅 자원의 물리 매핑 관계를 나타내는데 사용되는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 33 제32항에 있어서, 상기 슬라이스가 상기 훈련할 모델의 인접 네트워크층에 위치하고 상기 슬라이스의 배치 정보가 부동할 경우, 통신 보조 연산자 결정 유닛을 포함하고, 구체적으로, 상기 배치 정보를 이용하여, 통신 보조 연산자를 결정하하는데 사용되고, 상기 통신 보조 연산자가 각 상기 슬 라이스 사이의 논리 연산 관계를 나타내는데 사용되는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 34 제32항에 있어서, 상기 슬라이스가 훈련할 모델의 동일 네트워크층에 위치할 경우, 재구성 전환 연산자 결정 유닛을 포함하고, 상 기 재구성 전환 연산자 결정 유닛은, 각 상기 슬라이스 사이의 네트워크층 일치성 관계를 나타내는데 사용되는 재구성 전환 연산자를 결정하는데 사 용되는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 35 제29항 내지 제34항 중의 어느 한 항에 있어서, 상기 분할 수행 서브 모듈은, 상기 사용자 단말에 의해 시작된 모델 훈련 요청에 대해 분석 결정을 수행하는데 사용되는 분할 전략 결정 유닛 을 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 36 제29항 내지 제34항 중의 어느 한 항에 있어서, 상기 분할 수행 서브 모듈은, 미리 훈련된 분할 전략을 이용하여 모델 결정을 수행하는데 사용되는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 37 제28항에 있어서, 상기 컴퓨팅 자원의 속성 결정 모듈은, 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하고, 상기 하드웨어 토폴로지 관계를 상기 컴퓨팅 자원의 속성으로 하는데 사용되는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 38 제37항에 있어서, 상기 컴퓨팅 자원의 속성 결정 모듈은, 상기 컴퓨팅 자원의 최소 어셈블리를 결정하는데 사용되는 최소 어셈블리 결정 서브 모듈 - 상기 최소 어셈블리 는 프로세서 또는 메모리를 포함함 - ; 적어도 하나의 상기 최소 어셈블리로 구성된 기계 기기를 결정하는데 사용되는 기계 기기 결정 서브 모듈 - 각 상기 기계 기기의 최소 어셈블리는 중복되지 않음 - ; 및 적어도 하나의 상기 기계 기기로 구성된 클러스터를 결정하는데 사용되는 클러스터 결정 서브 모듈 - 각 상기 클러스터의 기계 기기는 중복되지 않음 - ; 를 포함하고, 상기 최소 어셈블리, 상기 기계 기기 및 상기 클러스터를 컴퓨팅 자원의 하드웨어 토폴로지 관계로 하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 39 제38항에 있어서, 상기 컴퓨팅 자원의 속성 결정 모듈은, 각 상기 최소 어셈블리의 밀접 관계 리스트를 결정하고; 상기 밀접 관계 리스트는 소스 최소 어셈블리와 목적 최소 어셈블리 사이의 연결 관계, 대역폭 정보 및 지연 정보 중의 적어도 하나를 포함하고, 상기 밀접 관계 리스트를 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계로 하는데 사용되는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 40 제28항 또는 제37항에 있어서, 상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 상기 사용자 단말에 의해 시작된 모델 훈련 요청의 내용 및 모델 훈련 요청을 시작하는 사용자 단말의 수량 중의 적어도 하나에 따라 결정되는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 41 제28항 또는 제37항에 있어서, 상기 컴퓨팅 자원의 속성 결정 모듈은, 상기 컴퓨팅 자원의 통신 경로를 획득하는데 사용되는 통신 경로 획득 서브 모듈; 상기 컴퓨팅 자원의 통신 경로를 이용하여, 각 상기 컴퓨팅 자원 사이의 통신 토폴로지 관계를 구축하는데 사용 되는 통신 토폴로지 관계 구축 서브 모듈; 을 포함하고, 상기 통신 토폴로지 관계를 상기 컴퓨팅 자원의 속성으로 하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 42 제41항에 있어서, 최단 통신 경로 구축 서브 모듈을 더 포함하고, 상기 최단 통신 경로 구축 서브 모듈은, 상기 통신 토폴로지 관계에 따라, 소스 컴퓨팅 자원과 타겟 컴퓨팅 자원 사이의 최단 통신 경로를 결정하는데 사용되는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 43 제28항에 있어서, 상기 분산 전략 결정 모듈은, 상기 컴퓨팅 자원에서 각 상기 분할 결과의 후보 분산 전략을 결정하는데 사용되는 후보 분산 전략 획득 서브 모듈; 각 상기 후보 분산 전략의 효율을 각각 통계하는데 사용되는 효율 통계 서브 모듈; 및 각 상기 후보 분산 전략의 효율에 따라, 상기 후보 분산 전략에서 타겟 분산 전략을 결정하는데 사용되는 타겟 분산 전략 결정 서브 모듈; 을 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 44 제28항 또는 제43항에 있어서, 상기 타겟 분산 전략 결정 서브 모듈은, 미리 설정된 규칙을 이용하여, 각 상기 후보 분산 전략을 정렬하는데 사용되는 정렬 유닛; 미리 설정된 규칙을 이용하여, 각 상기 후보 분산 전략을 정렬하는데 사용되는 결과 결정 유닛; 을 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치. 청구항 45 제28항에 있어서, 상기 분산식 훈련 모듈은, 상기 컴퓨팅 자원의 가용성을 정기적으로 검출하는데 사용되는 가용성 검출 서브 모듈; 검출 결과에 상기 컴퓨팅 자원의 불가용이 존재할 경우, 보완 조치를 수행하는데 사용되는 보완 조치 수행 서브 모듈 - 상기 불가용 상황은 컴퓨팅 자원 고장 또는 컴퓨팅 자원 수량의 축소를 포함함 - ; 을 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 46 제45항에 있어서, 상기 불가용 상황이 컴퓨팅 자원 고장일 경우, 상기 보완 조치 수행 서브 모듈은, 상기 사용자 단말에 의해 시작된 모델 훈련 요청에 포함된 훈련 모드를 획득하는데 사용되는 훈련 모드 획득 유 닛; 상기 훈련 모드가 내결함성 훈련 모드일 경우, 컴퓨팅 자원의 고장이 복구될 때 까지 대기하는데 사용되는 대기 유닛; 및 미리 설정된 시간 내에 상기 컴퓨팅 자원의 고장이 복구되지 않을 경우, 수행 종료로 결정하는데 사용되는 결과 결정 유닛; 을 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 47 제46항에 있어서, 상기 불가용이 컴퓨팅 자원 고장일 경우, 상기 보완 조치 수행 서브 모듈은, 상기 훈련 모드가 탄성 훈련 모드일 경우, 후보 컴퓨팅 자원을 결정하는데 사용되는 후보 컴퓨팅 자원 결정 유 닛; 상기 후보 컴퓨팅 자원에서 훈련의 재시행을 진행하는데 사용되는 재시행 유닛; 을 더 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 48 제47항에 있어서, 상기 재시행 유닛은, 상기 컴퓨팅 자원이 고장날 경우의 훈련 상태를 획득하는데 사용되는 훈련 상태 획득 서브 유닛; 상기 훈련 상태를 기반으로, 상기 후보 컴퓨팅 자원에서 훈련 재시행을 진행하는데 사용되는 재시행 수행 서브 유닛; 을 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 49 제47항에 있어서, 상기 재시행 유닛은, 훈련의 최초 상태를 획득하는데 사용되는 최초 상태 획득 서브 유닛; 훈련의 최초 상태를 획득하는데 사용되는 재시행 수행 서브 유닛; 을 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 50 제45항에 있어서, 상기 불가용 상황이 컴퓨팅 자원 수량의 축소일 경우, 상기 보완 조치 수행 서브 모듈은, 축소된 상기 컴퓨팅 자원의 제1 수량을 결정하는데 사용되는 제1 수량 결정 유닛; 상기 제1 수량에 따라, 상기 훈련할 모델을 재분할하여, 재분할된 제1 결과를 획득하는데 사용되는 제1 재분할 유닛; 재결정된 축소 후의 나머지 상기 컴퓨팅 자원의 속성을 이용하여, 축소된 상기 컴퓨팅 자원에서 각 상기 재분할 된 제1 결과의 제1 분산 전략을 결정하는데 사용되는 제1 분산 전략 결정 유닛; 및 상기 제1 분산 전략에 따라, 축소된 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련을 수행 하는데 사용되는 분산식 훈련 수행 유닛; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 51 제45항에 있어서, 검출 결과에 사용 가능한 여분의 컴퓨팅 자원이 존재할 경우, 사용 가능한 상기 여분의 컴퓨팅 자원의 제2 수량을 결정하는데 사용되는 제2 수량 결정 유닛; 상기 제2 수량에 따라, 상기 훈련할 모델을 재분할하여, 재분할된 제2 결과를 획득하는데 사용되는 제2 재분할 유닛; 다시 결정된 여분의 상기 컴퓨팅 자원의 속성을 이용하여, 확장된 상기 컴퓨팅 자원에서 각 상기 재분할된 제2 결과의 제2 분산 전략을 결정하는데 사용되는 제2 분산 전략 결정 유닛; 및 상기 제2 분산 전략에 따라, 확장된 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련을 수행 하는데 사용되는 분산식 훈련 수행 유닛; 을 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 52 제50항 또는 제51항에 있어서, 상기 컴퓨팅 자원의 수량이 변화될 경우, 조정 서브 유닛을 더 포함하고, 상기 조정 서브 유닛은, 변화된 수량에 따라, 상기 훈련할 모델의 학습률 및 단번의 훈련에 선택된 샘플 수량을 조정하는데 사용되는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 53 제28항, 제45항, 제50항 또는 제51항 중 어느 한 항에 있어서, 상기 분산식 훈련이, 분산 비동기 파이프라인 훈련을 포함하는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 54 제28항 내지 제53항 중 어느 한 항에 있어서, 상기 훈련할 모델은 사용자 단말에 의해 시작된 모델 훈련 요청에 따라 획득되는, 것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법. 청구항 55 전자 기기에 있어서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서에 통신 가능하게 연결되는 메모리; 를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령이 당해 적 어도 하나의 프로세서에 의해 실행될 경우, 상기 적어도 하나의 프로세서가 제1항 내지 제27항 중 어느 한 항의 방법을 수행하는, 것을 특징으로 하는 전자 기기. 청구항 56 컴퓨터 프로그램이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체에 있어서, 상기 컴퓨터 프로그램이 수행될 경우 제1항 내지 제27항 중 어느 한 항의 방법이 구현되는,것을 특징으로 하는 비일시적 컴퓨터 판독 가능 저장 매체. 청구항 57 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램이 프로세서에 의해 수행 될 경우 제1항 내지 제27항 중 어느 한 항의 방법을 구현하는, 것을 특징으로 하는 컴퓨터 프로그램. 발명의 설명 기 술 분 야 본 발명은 인공지능 기술 분야에 관한 것으로, 딥러닝, 클라우드 컴퓨팅 등 분야에 관한 것이고, 특히 단대단 자체 적응에 기반한 분산식 훈련 방법, 장치, 기기 및 저장 매체를 제공한다."}
{"patent_id": "10-2022-0155291", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "근년에, 더 좋은 효과를 추구하기 위해, 컴퓨터 비전, 자연언어 처리, 개인화 추천 등 분야의 모델은 모두 더 큰 규모의 모델 파라미터 또는 더 큰 규모의 훈련 데이터를 사용한다. 훈련 프레임 워크의 사용자 각도에 있어 서, 현재 전통적인 분산식 훈련 기술은 사용성, 견실성, 자원 이용율 등 차원에서 직면한 문제는 비교적 심각하 다. 예를 들면, 일반적인 문제는 자동화 정도가 낮고, 단일점 고장율이 높은 등을 포함한다."}
{"patent_id": "10-2022-0155291", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 단대단 자체 적응에 기반한 분산식 훈련 방법, 장치, 기기 및 저장 매체를 제공한다."}
{"patent_id": "10-2022-0155291", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, 단대단 자체 적응에 기반한 분산식 훈련 방법을 제공하고, 당해 방법은, 훈련할 모델을 분할하여, 분할 결과를 획득하는 단계; 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 컴퓨팅 자원의 속성을 획득하는 단계 - 훈련할 모델 에 할당되어 훈련하는 컴퓨팅 자원은 훈련할 모델의 컴퓨팅 자원 수요, 기타 훈련하고 있는 모델에 의해 점용된 컴퓨팅 자원 및 유휴 컴퓨팅 자원에 의해 결정된 것이고, 컴퓨팅 자원의 속성은 컴퓨팅 자원의 토폴로지 관계, 태스크 처리 능력 중의 적어도 하나를 나타내는데 사용됨 - ; 컴퓨팅 자원의 속성을 이용하여, 컴퓨팅 자원에서 각 분할 결과의 분산 전략을 결정하는 단계; 및 분산 전략에 따라, 컴퓨팅 자원을 이용하여 훈련할 모델에 대해 분산식 훈련하는 단계; 를 포함한다. 본 발명의 다른 측면에 따르면, 단대단 자체 적응에 기반한 분산식 훈련 장치를 제공하고, 당해 장치는, 훈련할 모델을 분할하여, 분할 결과를 획득하는데 사용되는 분할 모듈; 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 컴퓨팅 자원의 속성을 획득하는데 사용되는 컴퓨팅 자원의 속성 결정 모듈 - 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 훈련할 모델의 컴퓨팅 자원 수요, 기 타 훈련하고 있는 모델에 의해 점용된 컴퓨팅 자원 및 유휴 컴퓨팅 자원에 의해 결정된 것이고, 컴퓨팅 자원의 속성은 컴퓨팅 자원의 토폴로지 관계, 태스크 처리 능력 중의 적어도 하나를 나타내는데 사용됨 - ; 컴퓨팅 자원의 속성을 이용하여, 컴퓨팅 자원에서 각 분할 결과의 분산 전략을 결정하는데 사용되는 분산 전략 결정 모듈; 및 분산 전략에 따라, 컴퓨팅 자원을 이용하여 훈련할 모델에 대해 분산식 훈련하는데 사용되는 분산식 훈련 모듈; 을 포함한다. 본 발명의 다른 측면에 따르면, 전자 기기를 제공하고, 상기 전자 기기는, 적어도 하나의 프로세서; 및 적어도 하나의 프로세서에 통신 가능하게 연결되는 메모리; 를 포함하고, 당해 메모리에는 당해 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 당해 명령이 당해 적 어도 하나의 프로세서에 의해 실행될 경우, 당해 적어도 하나의 프로세서가 본 발명 실시예의 방법을 수행한다. 본 발명의 다른 측면에 따르면, 컴퓨터 프로그램이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체를 제공 하고, 당해 컴퓨터 프로그램이 컴퓨터에 의해 수행될 경우 본 발명 실시예의 방법이 구현된다. 본 발명의 다른 측면에 따르면, 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램을 제공하고, 컴퓨터 프 로그램이 프로세서에 의해 수행 될 경우 본 발명 실시예의 방법을 구현한다."}
{"patent_id": "10-2022-0155291", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 기술에 따라 훈련할 모델, 컴퓨팅 자원에 대해 자동 분석을 수행한다. 사용자 단말에 있어서, 사용자 단말에서 기타 동작을 하지 않아도, 모델 훈련의 프로세스를 단순화시킬 수 있다."}
{"patent_id": "10-2022-0155291", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "이해해야 할 것은, 본 발명의 내용 부분에서 설명하는 내용은 본 발명 실시예의 관건 또는 중요한 특징을 식별 하기 위한 것이 아니고, 본 발명의 범위를 한정하기 위한 것도 아니다. 본 발명의 기타 특징은 이하의 명세서를 통해 용이하게 이해된다."}
{"patent_id": "10-2022-0155291", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 도면과 결합하여 본 발명의 예시적인 실시예를 설명한다. 여기에는 이해를 돕기 위해 본 발명의 실시예의 다양한 세부 사항을 포함하고, 실시예들은 단지 예시적인 것으로 간주되어야 한다. 때문에 본 발명에 속하는 기 술 분야의 통상의 기술자는 본 발명의 범위 및 사상을 벗어나지 않고 실시예에 여러가지 변경과 수정을 할 수 있다는 것을 인식해야 한다. 동시에 정확성과 간결성을 위해 하기의 설명에서 공지 기능과 구조에 대한 설명은 생략한다. 도1에 도시된 바와 같이, 본 발명은 단대단 자체 적응에 기반한 분산식 훈련 방법에 관한 것으로, 당해 방법은 S101 내지 S104를 포함한다. S101에서, 훈련할 모델을 분할하여, 분할 결과를 획득한다. S102에서, 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 컴퓨팅 자원의 속성을 획득하고, 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 훈련할 모델의 컴퓨팅 자원 수요, 기타 훈련하고 있는 모델에 의해 점 용된 컴퓨팅 자원 및 유휴 컴퓨팅 자원에 의해 결정된 것이고, 컴퓨팅 자원의 속성은 컴퓨팅 자원의 토폴로지 관계, 태스크 처리 능력 중의 적어도 하나를 나타내는데 사용된다. S103에서, 컴퓨팅 자원의 속성을 이용하여, 컴퓨팅 자원에서 각 분할 결과의 분산 전략을 결정한다. S104에서, 분산 전략에 따라, 컴퓨팅 자원을 이용하여 훈련할 모델에 대해 분산식 훈련한다. 본 발명의 상기 방법의 수행 주체는 모델 훈련에 사용되는 크라우드 서버 또는 모델 훈련 플랫폼일 수 있고, 예 시적으로, k8s를 기반으로 하는 이기종 훈련 플랫폼일 수 있다. 수행 주체에 상기 방법을 수행하는 액추에이터를 로딩할 수 있다. 모델 훈련 플랫폼을 예로 들면, 모델 훈련 플 랫폼의 작용은 사용자 단말에 의해 시작된 모델 훈련 요청을 수신하고, 컴퓨팅 자원을 할당하는 것이다. 액추에 이터는 플랫폼과의 인터랙션을 통해, 모델 훈련 요청 및 컴퓨팅 자원 정보를 획득함으로, 모델 훈련 프로세스를 수행한다. 훈련할 모델은 시각 모델, 언어 모델, 추천 모델, 조회수 예측 모델 등을 포함할 수 있다. 훈련할 모델의 파라 미터 수량 레벨 및 훈련 샘플에 수량 레벨은 억을 단위로 한다. 모델에 대한 분산식 훈련 프로세스는 단대단의 프로세스일 수 있다. 예를 들면, 훈련할 모델은 모델 훈련 플랫 폼이 사용자 단말에 의해 시작된 모델 훈련 요청을 분석하여 획득된 것이다. 당해 훈련 요청을 분석함으로, 최 종 모델에서 출력된 결과가 수렴될 때까지, 분석 결과를 기반으로 모델의 훈련 프로세스를 수행할 수 있다. 관련 기술에서, 모델 훈련 프로세스에는 부동한 모델의 분할 전략을 단독으로 개발해야 한다. 또한 훈련 병렬 전략에 대해, 기존의 모델 훈련 플랫폼의 프레임 워크의 기초에서 호환 및 조합을 해야 하고, 병렬 전략의 많아 짐에 따라, 개발 난이도는 반드시 점차 커진다. 하드웨어측 부동한 하드웨어 아키텍처에서의 계산, 저장, 대역 폭 자원 및 연결 관계가 부동한 점을 다시 감안할 경우, 모델 훈련 플랫폼의 프레임 워크 개발자는 하드웨어 특 점과 결합하여 병렬 전략을 커스텀 개발을 더 해야 한다. 예를 들면, 관련 기술에서 개발자는 훈련할 모델 및 모델 훈련 플랫폼의 하드웨어에 따라 수동 적응 개발을 해야 하므로, 사용성이 떨어지는 경우를 초래한다. 부동 한 훈련할 모델의 특점 차이가 클 수 있으므로, 해당 훈련 전략 수단도 부동할 수 있다. 예를 들면, 자연 언어 처리, 컴퓨터 비전 등 모델은, 다차원 혼합 병렬 전략을 조합 응용하여 모델 저장 및 고효율 통신 문제를 해결 해야 한다. 그러나 추천 장면의 모델은 모델 병렬로 희소 저장을 해결해야 하고, 데이터 병렬을 사용하여 처리 효율을 향상시킨다. 이리하여 개발자에 대한 요구가 높은 경우를 초래한다. 다음으로, 관련 기술의 견실성이 떨어진다. 방대한 수량의 컴퓨팅 자원은 단일 노드 고장이 나타나기 쉬움으로, 전체 훈련이 실패하는 경우를 초래한다. 모델 훈련 태스크 제출, 컴퓨팅 자원 할당, 훈련할 모델 로딩, 훈련 시 작 프로세스를 다시할 경우, 몇 십분이 소모되고, 훈련이 지체될 뿐만 아니라, 당해 기간에서 대량의 컴퓨팅 자 원이 유휴되는 경우를 초래한다. 천개의 카드 클러스터로 예를 들면, 반 시간 유휴는 ￥＄10000을 넘는 훈련 원 가가 더 수요된다. 다음으로, 관련 기술에서, 1개의 훈련 태스크는 1종의 컴퓨팅 자원만 사용하지만, 하드웨어의 발전과 끊임없는 업데이트에 따라, 컴퓨팅 자원의 종류 및 모델 번호는 점점 더 많아지고, 대량의 유휴 컴퓨팅 자원이 생성될 수 도 있다. 관련 기술에서 컴퓨팅 자원의 특점에 따라 적합한 병렬 전략을 매칭하는 점을 충분히 감안하지 않아, 관련 기술이 각 하드웨어의 장점을 충분히 활용하지 못하는 경우를 초래한다. 이에 대해, 본 발명의 상기 프로세스는, 자동화의 모델 분할 프로세스를 구성하여, 훈련할 모델을 분할할 수 있 다. 예시적으로, 훈련할 모델을 분할하는 데는 훈련할 모델의 네트워크층을 근거로 할 수 있다. 예를 들면, 같 은 네트워크층의 텐서를 분할하고, 같은 네트워크층의 N개의 텐서를 2개의 그룹으로 분할할 수 있고, 각 그룹에 는 N/2개의 텐서가 있다. 또는, 네트워크층을 단위로 분할하고, 같은 네트워크층에 속하는 텐서를 1개의 슬라이 스로 분할하고, 또는 같은 기능을 구비한 복수의 네트워크층의 텐서를 1개의 슬라이스로 분할할 수 있다. 훈련 할 모델을 분할할 경우, 분산식 연산자 및 분산식 텐서를 디커플링할 수 있으므로, 그룹의 각 종 병렬 전략을 유연하게 나타내고, 분산식 훈련 아키텍처의 확정성과 보전성을 향상시킬 수 있다. 또한, 하드웨어 분석 메커니즘을 이용하여 훈련할 모델에 할당된 컴퓨팅 자원을 분석하여, 컴퓨팅 자원의 속성 을 획득할 수 있다. 여기서, 컴퓨팅 자원의 속성은 컴퓨팅 자원의 토폴로지 관계, 태스크 처리 능력 중의 적어 도 하나를 나타내는데 사용된다. 예를 들면, 컴퓨팅 자원의 토폴로지 관계는 현재 컴퓨팅 자원과 기타 컴퓨팅 자원의 연결 관계, 대역폭 등 정보일 수 있다. 태스크 처리 능력은 현재 컴퓨팅 자원의 태스크 처리 속도 및 태 스크 처리 수량 등을 포함할 수 있다. 일 측면에서, 컴퓨팅 자원의 할당은 사용자 단말에 의해 시작된 모델 훈련 요청에 대한 분석을 기반으로 획득할 수 있다. 예를 들면, 훈련 요청에서 컴퓨팅 자원을 요청하는 수량은 a 내지 b이고, 여기서, a 및 b가 양의 정수 일 경우, 컴퓨팅 자원의 유휴 상황에 따라, 해당 a 내지 b 수치를 할당한다. 당해 수치는 훈련 요청을 응답하는 컴퓨팅 자원의 수량이다. 다른 측면에서, 훈련할 모델에 할당하여 훈련하는 컴퓨팅 자원은, 훈련할 모델의 컴퓨팅 자원 수요, 훈련하고 있는 기타 모델이 점용한 컴퓨팅 자원 및 유휴 컴퓨팅 자원을 참조하여 결정할 수 있다. 예를 들면, 사용자 단 말의 훈련할 모델을 제출하는 훈련 요청을 수신하고, 여기서 수요되는 컴퓨팅 자원의 최소 연산 능력 수량 및 최대 연산 능력 수량를 분석한다. 분석해낸 연산 능력 수요에 따라, 연결이 가능한 한 적은 컴퓨팅 자원을 찾아 당해 훈련할 모델에 할당한다. 구체적으로, 아래의 상황을 기반으로 할당할 수 있다. 현재 유휴인 하드웨어 자원이 현재 사용자 수요를 만족할 수 없고, 현재 사용자에 더 많은 하드웨어 자원을 점 용하는 훈련 태스크가 없을 경우, 현재 사용자의 훈련 태스크는 대기해야 한다. 현재 유휴인 하드웨어 자원이 현재 사용자 수요를 만족할 수 없지만, 현재 사용자에 더 많은 하드웨어 자원을 점용하는 훈련 태스크가 있고, 나머지 하드웨어 자원을 제거한 후 여전히 현재 사용자의 기타 훈련 태스크의 연 산 능력 수요를 만족할 수 있을 경우, 하드웨어 자원의 할당 축소를 트리거링할 수 있다. 현재 유휴인 하드웨어 자원이 현재 사용자 수요를 만족할 수 있지만, 유휴인 하드웨어 자원(예를 들면 카드)이 복수의 기계에 분산될 경우, 디스크 조각 모음을 시작하고, 태스크 훈련하고 있는 내결함성 기능을 트리거링하 고, 훈련하고 있는 태스크를 하나의 기계에서 다른 기계로 옯겨 훈련을 계속함으로, 현재 사용자가 전체 기계를 획득하고 태스크 훈련을 수행하도록 한다. 현재 유휴인 하드웨어 자원이 현재 사용자 수요를 만족할 수 있고, 현재 사용자 수요를 초과하고, 대기하고 있 는 기타 태스크도 없을 경우, 현재 사용자의 최대 연산 능력 수요를 만족하는 전제하에 현재 사용자에 더 많은 하드웨어 자원을 할당한다. 여기서, 컴퓨팅 자원의 입도는 다양할 수 있다. 예를 들면, 최소 어셈블리, 최소 어셈블리로 구성된 기계 어셈 블리 및 기계 어셈블리로 구성된 클러스터를 포함한다. 예시적으로, 클러스터는 클러스터에 대응되고, 기계 어 셈블리는 단일 기계에 대응되고, 최소 어셈블리는 단일 기계의 카드에 대응된다. 훈련할 모델에 할당된 컴퓨팅 자원을 분석함으로, 클러스터 사이, 클러스터 내부의 단일 기계 사이, 단일 기계 내부의 최소 어셈블리 사이의 구체적인 연결 관계를 구현할 수 있다. 연결 관계를 통해, 부동한 컴퓨팅 자원 사이의 통신 상황을 결정하고, 차이가 있고, 통신 효율이 낮고 또는 호환 불가능한 컴퓨팅 자원 사이의 차단을 구현할 수 있다. 현재 실시 방식에서, 훈련할 모델에 대한 분할 및 컴퓨팅 자원 속성의 결정(컴퓨팅 자원의 할당을 포함함)은, 병렬 수행된 것임으로, 모델 훈련의 효율을 향상시킬 수 있다. 예를 들면, 사용자의 모델 훈련 요청을 수신하는 것을 트리거링 조건이라고 할 수 있고, 일 측면에서 모델 훈련 요청을 분석하여, 훈련할 모델을 획득함으로, 모 델의 분할을 구현한다. 다른 측면에서, 트리거링 조건을 기반으로 훈련 플랫폼에 의해 사용 가능한 자원에 대해 전체적인 분석을 하고, 훈련할 모델의 컴퓨팅 자원 수요, 훈련하고 있는 기타 모델에 의해 점용된 컴퓨팅 자원 및 유휴 컴퓨팅 자원에 따라 모델 훈련 요청을 응답하는 컴퓨팅 자원 할당 결과를 결정한다. 컴퓨팅 자원의 속성에 따라, 컴퓨팅 자원에서 각 분할 결과의 분산 전략을 결정할 수 있다. 예시적으로, 분할 결과는 N개의 단편을 포함한다. N개의 단편이 해당 수량의 컴퓨팅 자원에 할당된 후의 바람직한 할당 결과를 근 거로, 분산 전략을 결정할 수 있다. 여기서, 바람직한 할당 결과는 훈련이 가장 빠른 것, 훈련 데이터량이 가장 많은 것, 각 컴퓨팅 자원의 이용율이 가장 높은 것 등을 포함한다. 구체적으로 사용자의 훈련 수요에 따라 해당 설정을 진행할 수 있다. 분산 전략에 따라, 컴퓨팅 자원을 이용하여 훈련할 모델에 대해 분산식 훈련을 수행한다. 여기서, 분산식 훈련 은 훈련할 모델에 할당하고 컴퓨팅 프로세스를 수행하는 것을 포함으로써, 훈련 효율을 향상시킬 수 있다. 본 발명의 상기 프로세스는 컴퓨터 비전, 자연언어 처리, 추천 검색 광고 분야의 초대 모델 훈련 장면에 적용될 수 있다. 컴퓨터 비전 분야를 예로 들면, 상기 프로세스는 천만 또는 억대의 안면 분류 모델 훈련, 몇 십억 비전 모델 훈 련, 백억 이미지와 텍스트 등 멀티 모달 훈련을 서포트할 수 있고, 나아가 하위 태스크에 적용된다. 예를 들면 안면 검출, 차량 검출, 이미지 텍스트 검색 및 이미지 생성 등에 적용된다. 자연언어 처리를 예로 들면, 상기 프로세스는 백억의 대화 모델 훈련, 백억, 천억, 조의 언어 모델 훈련을 서포 트할 수 있고, 나아가 대화 시스템, 의미 연관성 검색 및 스마트 저작 등 장면에 적용된다. 추천 분야를 예로 들면, 상기 프로세스는 조의 조회수 모델 훈련을 서포트할 수 있고, 나아가 비디오 추천, 이 미지 및 텍스트 추천 등 정보의 흐름 장면, 검색 정렬 및 광고 정렬 등 장면에 적용된다. 총체적으로 말하면, 본 발명의 프로세스는 통일 컴퓨팅 뷰를 통해 임의의 모델을 서포트하는 임의의 분할 전략 을 통용화한다. 통일 자원 뷰를 통해 임의의 클러스터의 임의의 하드웨어를 서포트함으로, 이기종 하드웨어 자 원을 차단하여 가져온 차이를 통용화한다. 모델 및 자원이 변화된 후, 전체 시스템은 통일 컴퓨팅 뷰 및 통일 자원 뷰를 자동으로 생성하고, 태스크가 중단되지 않는 상황에서, 후속의 서브 모듈을 자동으로 트리거링하고, 분할, 자원 매핑을 다시 하고, 새로 분산된 태스크를 각 기기에 주고, 프로세스를 시작하고 태스크 할당 및 수 행한다. 상기 프로세스를 통해, 사용자 단말에 의해 업로드된 훈련할 모델, 컴퓨팅 자원에 대해 자동 분석을 진행한다. 사용자 단말이 기타 동작을 할 필요 없고, 사용자 단말에 있어서, 모델 훈련의 프로세스를 단순화시킬 수 있다. 도2에 도시된 바와 같이, 일 실시 방식에서, 단계S101은 S201 내지 S202를 포함한다. S201에서, 훈련할 모델의 연산자 및 텐서를 결정한다. S202에서, 분할 전략을 이용하여, 훈련할 모델의 연산자 및 텐서를 분할하여, 분할 결과를 획득한다. 도3에 도시된 \"통용 자동 분할 전략\"에 대응되게, 도3의 훈련할 모델은 8개의 네트워크층을 포함한다. 훈련할 모델의 첫 번째 네트워크층(도3의 맨 왼쪽)은 훈련할 모델의 입력층으로 될 수 있고, 마지막 네트워크층(도3의 맨 오른쪽)은 훈련할 모델의 출력층으로 될 수 있다. 중간 6개의 네트워크층은 훈련할 모델의 히든층으로 될 수 있다. 첫 번째 네트워크층을 예로 들면, 당해 네트워크층은 4개의 텐서를 포함한다. 도3에서 각 네트워크층의 텐서 사이를 연결하는 링크는 연산자로 될 수 있다. 훈련할 모델에 대한 분석을 통해, 훈련할 모델의 연산자 및 텐서를 결정할 수 있다. 분할 전략은 사용자 단말에 의해 시작된 모델 훈련 요청에 포함된 것일 수 있다. 사용자 단말에 의해 시작된 모델 훈련 요청에 분할 전략이 포함되지 않을 경우, 미리 훈련된 분할 전략 모델을 이용하여 분할 전략을 결정할 수 있다. 결정된 분할 전략에 따라, 훈련할 모델의 연산자 및 텐서에 대한 분할을 완료하여, 분할 결과를 획득할 수 있다. 분할 결과에 의해 분산식 수행을 할 수 있으므로, 분할 결과는 분산식 연산자 및 분산식 텐서라고도 할 수 있다. 상기 프로세스를 통해, 분산식 연산자 및 분산식 텐서를 디커플링하고, 그룹의 각 종 병렬 전략을 유연하게 나 타내고, 분산식 훈련 아키텍처의 확정성과 보전성을 향상시킬 수 있다. 도4에 도시된 바와 같이, 일 실시 방식에서, 단계S202는 S401 내지 S403을 포함한다 S401에서, 분할 전략을 이용하여, 훈련할 모델의 연산자 및 텐서를 분할하여, N개의 슬라이스를 획득하고, N은 양의 정수이다. S402에서, 각 슬라이스에 대해, 슬라이스의 분산식 속성 정보를 로딩하고, 분산식 속성 정보는 훈련할 모델에서 당해 슬라이스의 프로세스 토폴로지 정보, 당해 슬라이스의 분할 매핑 정보, 당해 슬라이스의 슬라이스 크기 정보 중의 적어도 하나를 포함한다. S403에서, 분산식 속성 정보가 로딩된 슬라이스를 분할 결과로 한다. 분할 전략을 이용하여, 훈련할 모델의 연산자 및 텐서를 분할한 후, N개의 해당 슬라이스를 획득할 수 있다. 도 3에 도시된 분할 예시와 결합하여, 도3의 8개 점선 블록은 각각 8개의 슬라이스에 대응된다. 첫 번째 네트워크 층의 4개 텐서는 2개의 슬라이스로 평균 분할되고, 각 슬라이스는 2개의 텐서를 포함한다. 첫 번째 히든층 내지 다섯 번째 히든층에서 각각에 대응되는 네트워크층은, 1개의 슬라이스로 분할된다. 여섯 번째 히든층 및 훈련할 모델의 출력층은 1개의 슬라이스로 분할된다. 슬라이스의 분산식 속성 정보는 슬라이스의 분할 차원을 나타낼 수 있다. 첫 번째 네트워크층의 4개 텐서가 2개 의 슬라이스로 평균 분할된 것을 예로 든다. 2개의 슬라이스의 분산식 속성 정보는 같고, 여기서 훈련할 모델에 서 당해 슬라이스의 프로세스 토폴로지 정보(process_mesh)는 당해 슬라이스가 훈련할 모델의 입력층임을 나타 낼 수 있고, 당해 입력단은 훈련 샘플이고, 출력단은 첫 번째 히든층이다. 슬라이스의 분할 매핑 정보 (dims_mapping)는 단일 네트워크층이 분할된 수량을 나타내는데 사용된다. 예를 들면 첫 번째 네트워크층이 2개 로 분할된 것을 나타내는데 사용될 수 있다. 예시적으로, 첫 번째 네트워크층의 4개 텐서가 4개의 슬라이스로 분할될 경우, 슬라이스된 분할 매핑 정보는 단일 네트워크층이 4개로 분할된 것을 나타내는데 사용될 수 있다. 슬라이스된 슬라이스 크기 정보(shard_sizes)는 슬라이스에 포함된 네트워크층 수를 나타내는데 사용될 수 있다. 예시적으로, 도3의 맨 오른쪽 슬라이스 크기 정보가 2인 것 이외에, 기타 슬라이스의 크기 정보는 1일 수 있다. 또한, 슬라이스된 슬라이스 크기 정보는 또한 각 슬라이스에 포함된 연산자 수량 및 텐서 수량을 나타내 는데 사용된다. 상기 프로세스를 통해, 각 슬라이스는 각각의 분산식 속성을 구비할 수 있고, 슬라이스의 텐서를 서포트하는 분 산식 속성과 당해 텐서를 사용한 연산자의 해당 분산식 속성은 부동하고, 저장과 컴퓨팅 프로세스의 분리에 유 리하다. 도5에 도시된 바와 같이, 일 실시 방식에서, 분산식 속성 정보 카테고리의 결정 방식은, 단계S501 내지 S502를 포함한다. S501에서, 미리 설정된 방식을 이용하여 분산식 속성 정보의 복수 후보 카테고리를 수신한다. S502에서, 복수의 후보 카테고리에서 타겟 카테고리를 결정하여, 분산식 속성 정보의 카테고리로 한다. 미리 설정된 방식은 분산식 속성 카테고리의 수신 포트를 설치하여 카테고리를 수신하는 방식일 수 있다. 분산 식 속성 정보의 카테고리의 업로드 대상은 자질이 있는 사용자 또는 인증된 제3자 기구일 수 있다. 인공 또는 기계 인식등 방식을 이용하여, 수신된 분산식 속성의 카테고리를 선별하고, 선별 합격된 카테고리를 후보 카테 고리로 한다. 또한, 미리 설정된 방식은 개발자에 의해 작성된 분산식 속성 정보의 카테고리일 수도 있다. 구체적인 미리 설 정 방식은 여기서 열거하지 않는다. 복수의 후보 카테고리에서 타겟 카테고리를 결정하는 방식은 모델의 훈련 수요에 따라 결정할 수 있고, 타겟 카 테고리의 이용율에 따라 결정할 수도 있고, 이용율은 역사 데이터를 기반으로 획득된 것이다. 상기 방식을 통해, 분산식 속성 정보의 카테고리 확장 메커니즘을 개발하여, 분산식 속성 정보에 대해 굵은 입 도, 가는 입도의 다양한 분할을 수행한다. 일 실시 방식에서, 아래의 단계를 더 포함한다. 각 슬라이스의 분산식 속성을 이용하여, 각 슬라이스의 배치 정보를 결정하고, 배치 정보는 슬라이스와 컴퓨팅 자원의 물리 매핑 관계를 나타내는데 사용된다. 슬라이스의 배치 정보(device_placement)는 슬라이스에 수요되는 컴퓨팅 자원을 나타낼 수 있다. 예시적으로, 도3의 첫 번째 네트워크층의 4개 텐서가 2개의 슬라이스로 평균 분할될 경우, 2개 슬라이스의 배치 정보는 같을 수 있어, 2개 슬라이스의 완료 시간이 거의 일치하도록 보장할 수 있다. 이리하여, 2개의 슬라이스에 대응되는 컴퓨팅 자원은 연산 능력과 같고 또는 통신 링크가 짧은 특점을 구비하고, 훈련 효율을 향상시킬 수 있다. 또한, 분산식 속성에 따라 결정된 슬라이스의 연산자 수량 또는 텐서 수량이 비교적 클 경우, 연산 능력이 비교 적 강한 컴퓨팅 자원을 배치 대상으로 선택할 수 있다. 상기 프로세스를 통해, 훈련 모델의 논리 분할과 물리 매핑 사이의 디커플링을 구현할 수 있고, 슬라이스의 배 치 정보를 이용하여, 이기종 하드웨어를 더 잘 호환하여, 훈련 프로세스의 효율이 더 바람직하도록 할 수 있다. 일 실시 방식에서, 슬라이스가 훈련할 모델의 인접 네트워크층에 위치하고 슬라이스의 배치 정보가 부동할 경우, 아래의 단계를 포함한다. 배치 정보를 이용하여, 통신 보조 연산자를 결정하고, 통신 보조 연산자는 각 슬라이스 사이의 상위 및 하위 논 리 연산 관계를 나타내는데 사용된다. 여전히 도3을 예로 들면, 도3의 첫 번째 히든층에 대응되는 슬라이스와 두 번째 히든층의 해당 슬라이스 사이의 관계는 훈련할 모델의 인접 네트워크층에 대응될 수 있다. 인접 네트워크층에 있어서, 상위 네트워크층의 출력 데이터를 하위 네트워크층의 입력 데이터로 할 수 있다. 첫 번째 히든층에 대응되는 컴퓨팅 자원은 도3의 XPU0 이고, 두 번째 히든층에 대응되는 컴퓨팅 자원은 도3의 GPU0이다. 분명하게, 상기 2개의 슬라이스는 훈련할 모델의 인접 네트워크층에 위치하고, 2개 슬라이스의 배치 정보는 부 동하다. 당해 상황에서, 통신 보조 연산자를 결정하고, 2개의 슬라이스 및 해당 컴퓨팅 자원에 알리는데 사용된 다. 예시적으로, 알린 정보가 도3의 XPU0에서 해당 컴퓨팅을 완료하고 컴퓨팅 결과를 획득하는 데에 포함될 수 있을 경우, 통신 보조 연산자로 컴퓨팅 결과를 GPU0으로 전송하여, 컴퓨팅의 연속성을 구현하고 크로스 기기 분 할의 정확성을 보장한다. 일 실시 방식에서, 상기 슬라이스가 훈련할 모델의 동일 네트워크층에 위치할 경우, 아래의 단계를 포함한다. 각 슬라이스 사이의 네트워크층 일치성 관계를 나타내는데 사용되는 재구성 전환 연산자를 결정한다. 여전히 도3으로 예를 들면, 도3의 첫 번째 네트워크층의 4개 텐서는 2개의 슬라이스로 평균 분할된다. 도3에 도 시된 예시에서, 2개 슬라이스의 제1 슬라이스에 대응되는 컴퓨팅 자원은 도3의 CPU0이고, 2개 슬라이스의 제2 슬라이스에 대응되는 컴퓨팅 자원은 도3의 CPU1이다. 당해 상황에서, 재구성 전환 연산자를 결정하여, 2개의 슬 라이스 및 해당 컴퓨팅 자원에 알린다. 예시적으로, 알린 정보가 도3의 CPU0, CPU1에서 해당 컴퓨팅을 완료하고 컴퓨팅 결과를 획득하는 데에 포함될 수 있을 경우, 컴퓨팅 결과를 통합하여, 첫 번째 네트워크층의 출력 데이 터에 대응되도록 한다. 도3에 도시된 2개의 슬라이스에 대응되는 컴퓨팅 자원이 같아도, 여전히 재구성 전환 연산자를 이용하여 컴퓨팅 결과를 통합할 수 있다는 것을 이해하는 것은 어렵지 않다. 상기 프로세스를 통해, 컴퓨팅의 정확성을 보장할 수 있다. 일 실시 방식에서, 분할 전략의 결정 방식은, 사용자 단말에 의해 시작된 모델 훈련 요청에 대해 분석 결정을 수행하는 단계를 포함한다. 일 실시 방식에서, 분할 전략의 결정 방식은, 미리 훈련된 분할 전략을 이용하여 모델 결정을 수행하는 단계를 포함한다. 사용자 단말에 의해 시작된 모델 훈련 요청에 따라, 훈련할 모델을 1개의 논리 컴퓨팅 뷰로 나타내고, 당해 논 리 컴퓨팅 뷰에 대해 속성 태그를 수행한다. 속성 태그는 상기 분산식 속성 정보에 대응될 수 있다. 또한, 훈련 플랫폼에 의해 할당된 컴퓨팅 자원에 따라, 자원뷰를 구축한다. 논리 컴퓨팅 뷰 및 자원 뷰는 상기 도3에 도시 된 예시와 같을 수 있다. 분할 전략 모델은 아래의 상황을 기반으로 분할 전략을 결정할 수 있다. 예를 들면, 논리 컴퓨팅 뷰에 대해 N종의 분할 방식이 있고, 하드웨어 자원도에 대해 M종의 분할 방식이 있고, 대가 모델을 통해 N*M의 대가치를 계산하고, 가장 작은 것을 선택하여 최종 분할 전략으로 한다. 또 예를 들면, 먼저 논리 컴퓨팅 뷰에 대한 N종의 분할 방식을 선별하고, 선별 규칙은 분할 속도가 가장 빠르고, 분할 결과의 수량이 해당 역치 범위 내에 있는 등일 수 있다. 선별된 결과는 N1로 나타낼 수 있다. 대 가 모델을 통해 N1*M의 대가치를 계산하고, 가장 작은 것을 최종 분할 전략으로 선택한다. 더 예를 들면, 논리 컴퓨팅 뷰, 하드웨어 자원도를, 해당 수학 표현식으로 추상화시킨다. 수학 표현식을 구하여, 최종 분할 전략을 획득한다. 미리 훈련된 분할 전략 모델은 비용 모델(cost-model)일 수 있다. 비용 모델은 검색 알고리즘 및 대가 모델을 포함할 수 있다. 검색 알고리즘을 이용하여 부동한 결과를 획득하고, 대가 모델을 이용하여 부동한 결과를 평가 한다. 상기 모델이 따르는 원칙은 분할 전략이 이익 극대화를 만족시키는 것이다. 예시적으로, 이익 극대화는 당해 분할 전략을 이용하여 획득된 분할 결과가 컴퓨팅 시간이 가장 짧은 것을 만족하고, 당해 분할 전략을 이 용하여 획득된 분할 결과가 훈련 정확도가 미리 설정된 역치보다 높은 것을 만족하는 것을 포함한다. 분할 전략 모델은 컴퓨팅 자원의 수량 및 훈련할 모델의 구조에 따라, 훈련할 모델에 대해 분할 동작을 할 수 있다. 구체 적인 분할 전략은 훈련 샘플의 부동함에 따라, 해당 효과를 구현하는 것이다. 비용 모델의 훈련 프로세스에 대 해 더는 설명하지 않는다. 일 실시 방식에서, 단계S102는, 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하고, 하드웨어 토폴로지 관계를 컴퓨팅 자원의 속성으로 하는 단 계를 포함한다. 컴퓨팅 자원의 하드웨어 토폴로지 관계의 결정 방식은 훈련할 모델에 할당된 컴퓨팅 자원을 분석하여 획득할 수 있다. 여기서, 컴퓨팅 자원의 하드웨어 토폴로지 관계는 컴퓨팅 자원의 연결 관계, 대역폭 정보 및 태스크 처리 능력 등을 포함한다. 예시적으로, 현재 컴퓨팅 자원을 소스 컴퓨팅 자원으로 할 경우, 컴퓨팅 자원의 연결 관계는 소 스 컴퓨팅 자원과 타겟 컴퓨팅 자원의 연결 관계를 포함할 수 있다. 예시적으로, 컴퓨팅 자원은 소프트웨어 자원, 하드웨어 자원 등을 포함한다. 구체적으로, 컴퓨팅 자원은 CPU, GPU, XPU 및 Memory 등을 포함한다. 컴퓨팅 자원의 속성에 대한 확인을 통해, (클러스터)컴퓨팅 자원 처리 능력과 토폴로지 연결 관계를 추상적으로 나타냄으로, 하드웨어 사이의 차이를 차단하고, 각 이기종 하드웨어 및 클러스터 환경을 서포트하고, 개발 난이 도를 더 저하시킬 수 있다. 도6에 도시된 바와 같이, 일 실시 방식에서, 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하는 단계는 구체적 으로 단계S601 내지 S604를 포함한다. S601에서, 컴퓨팅 자원의 최소 어셈블리를 결정하고, 최소 어셈블리는 프로세서 또는 메모리를 포함한다. S602에서, 적어도 하나의 최소 어셈블리로 구성된 기계 기기를 결정하고, 각 기계 기기의 최소 어셈블리는 중복 되지 않는다. S603에서, 적어도 하나의 기계 기기로 구성된 클러스터를 결정하고, 각 클러스터의 기계 기기는 중복되지 않는 다. S604에서, 최소 어셈블리, 기계 기기 및 클러스터를 컴퓨팅 자원의 하드웨어 토폴로지 관계로 한다. 도7에 도시된 컴퓨팅 자원의 하드웨어 토폴로지 관계도를 결합한다. 도7에 도시된 클러스터(도7의 Cluster)는 복수의 기계 기기(도7의 Machine)로 구성되고, 각 Machine은 복수의 최소 어셈블리(도7의 Component)를 포함한 다. Component는 Machine을 구성하는 최소 유닛이고, 프로세서(도7의 Processor) 또는 메모리(도7의 Memory)일 수 있다. 프로세서의 연산 능력은 초당 수행된 부동 소수점 연산 횟수(도7의 flops)이다. 메모리의 저장 능력은 도7에서 capacity로 나타낸다. 각 Component에는 Component의 식별자(도7의 Component id), Component의 유형(도7의 Component kind)과 같은 관련 정보가 기록되어 있다. Component의 유형은 프로세서 또는 메모리에 대응된다. 각 Machine에는 당해 포함된 Component(도7의 components)가 기록되어 있다. 또한, 당해 Machine의 식별자(도7 의 machine id), 당해 Machine의 물리 주소(도7의 addr) 및 당해 Machine에 포함된 인터페이스(도7의 port)가 기록되어 있을 수도 있다. Cluster에는 당해 포함된 Machine(도7의 machines) 및 토폴로지 그래프(도7의 Topology Graph)가 기록되어 있 다. Topology Graph의 각 정점은 component에 대응되고, 정점은 밀접 관계 리스트(도7의 Affinity)에도 대응된 다. 대응되게, 일 실시 방식에서, 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하는 단계는, 각 최소 어셈블리의 밀접 관계 리스트를 결정하는 단계 - 밀접 관계 리스트는 소스 최소 어셈블리와 목적 최소 어셈블리 사이의 연결 관계, 대역폭 정보 및 지연 정보 중의 적어도 하나를 포함함 - ; 밀접 관계 리스트를 컴퓨팅 자원의 하드웨어 토폴로지 관계로 하는 단계; 를 포함한다. 도7의 소스 최소 어셈블리는 source component로 나타낼 수 있고, 목적 최소 어셈블리는 target component로 나타낼 수 있다. 소스 최소 어셈블리와 목적 최소 어셈블리 사이의 연결 관계는 link kind로 나타낼 수 있고, 대역폭 정보는 bandwidth로 나타낼 수 있고, 지연 정보는 latancy로 나타낼 수 있다. 여기서, 연결 관계는 PCIE, IB, Shared Memory 및 NVLINK 등을 포함할 수 있다. 상기 프로세스를 통해, 기기 사이의 토폴로지 정보를 포함할 뿐만 아니라, 기기 내의 프로세서, 비디오 메모리 및 대역폭 등 처리 능력 관련 정보를 포함하고, 클러스터 사이, 클러스터 내부 하드웨어 사이, 하드웨어 내부의 구체적인 연결 방식 및 차이의 차단을 구현하고, 각 이기종 하드웨어 및 클러스터 환경을 서포트할 수 있다. 일 실시 방식에서, 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 사용자 단말에 의해 시작된 모델 훈련 요청 의 내용 및 모델 훈련 요청을 시작하는 사용자 단말의 수량 중의 적어도 하나에 따라 결정된 것이다. 사용자 단말은 모델 훈련 플랫폼에서 모델 훈련 요청을 시작한다. 훈련 요청 유형은 탄성 훈련 태스크 및 비탄 성 훈련 태스크를 포함한다. 본 발명의 실시 방식에 관한 유형은 주로 탄성 훈련 태스크이고, 탄성 훈련 태스크 는 내결함성 모드와 탄성 확장 및 축소 모드로 더 나누고, 수요되는 컴퓨팅 자원의 수량(컴퓨팅 노드)이 고정된 값임을 지정할 경우(예를 들면 node_nums=2 또는 node_nums=2:2), 내결함성 모드임을 나타낼 수 있다. 수요되는 컴퓨팅 자원의 수량이 일 범위임을 지정할 경우(예를 들면 node_nums=2:4), 탄성 확장 및 축소 모드임을 나타낼 수 있다. 컴퓨팅 자원의 할당에 있어서, 일 측면에서 사용자 단말에 의해 시작된 모델 훈련 요청의 내용을 기반으로 결정 될 수 있다. 다른 측면에서, 모델 훈련 요청을 시작하는 사용자 단말의 수량을 기반으로 결정될 수도 있다. 예 시적으로, 모델 훈련 요청을 시작하는 사용자 단말의 수량이 많을 경우, 컴퓨팅 자원의 수요량은 증가되므로, 컴퓨팅 자원은 대기해야 하는 경우가 나타날 수 있다. 반대로, 모델 훈련 요청을 시작하는 사용자 단말의 수량 이 적을 경우, 컴퓨팅 자원의 수요량은 감소되고, 컴퓨팅 자원은 유휴될 수 있다. 상기 양 측면을 기반으로, 훈련 플랫폼의 컴퓨팅 자원에 대해 전체적인 조정을 진행하고, 컴퓨팅 자원을 충분히 이용하는 동시에, 각 컴퓨팅 자원의 장점을 충분히 발휘하여, 클러스터 자원 이용율을 더 향상시킬 수 있다. 또 한, 통상적으로 야간에는 대량의 유휴 자원이 있을 수 있고, 상기 방식을 이용하여 컴퓨팅 자원의 시분할 다중 화를 구현할 수 있고, 사용자 단말 및 훈련 플랫폼에 더 큰 이익을 가져올 수 있다. 도8에 도시된 바와 같이, 일 실시 방식에서, 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 컴퓨팅 자원의 속성을 획득하는 단계는 S801 내지 S803을 포함한다. S801에서, 컴퓨팅 자원의 통신 경로를 획득한다. S802에서, 컴퓨팅 자원의 통신 경로를 이용하여, 각 컴퓨팅 자원 사이의 통신 토폴로지 관계를 구축한다. S803에서, 통신 토폴로지 관계를 컴퓨팅 자원의 속성으로 한다. 컴퓨팅 자원의 통신 경로는 소스 통신 자원과 타겟 통신 자원의 통신 연결 상태, 통신 연결 방식 및 통신 속도 를 나타내는데 사용된다. 여기서, 통신 연결 상태는 이미 연결된 상태 및 연결되지 않은 상태를 포함한다. 통신 연결 상태가 이미 연결된 상태일 경우, 통신 연결 방식은 소스 통신 자원 및 타겟 통신 자원의 구체적인 통신 방식에 대응될 수 있다. 통 신 속도는 통신 방식의 부동함에 따라, 해당 측정을 진행하여, 통신 속도를 획득할 수 있다. 컴퓨팅 자원의 통신 경로를 이용하여, 각 컴퓨팅 자원 사이의 통신 토폴로지 관계를 구축할 수 있다. 예시적으 로, 토폴로지 관계는 복수의 통신 서브 영역을 포함할 수 있다. 부동한 통신 서브 영역을 통해 부동한 병렬 모 드를 수행할 수 있다. 복수의 병렬 모드는 동시에 존재할 수 있다. 일 실시 방식에서, 통신 토폴로지 관계에 따라, 소스 컴퓨팅 자원과 타겟 컴퓨팅 자원 사이의 최단 통신 경로를 결정하는 단계를 더 포함한다. 통신 토폴로지 관계를 이용하여, 부동한 컴퓨팅 자원 사이의 통신 시간을 계산할 수 있다. 통신 시간의 비교에 따라, 소스 컴퓨팅 자원과 타겟 컴퓨팅 자원 통신을 해야 할 경우, 통신 토폴로지 관계를 이용하여, 소스 컴퓨 팅 자원과 타겟 컴퓨팅 자원 사이의 최단 통신 경로를 결정할 수 있다. 도9에 도시된 바와 같이, 일 실시 방식에서, 단계S103은 단계S901 내지 S903을 포함한다. S901에서, 컴퓨팅 자원에서 각 분할 결과의 후보 분산 전략을 결정한다. S902에서, 각 후보 분산 전략의 효율을 각각 통계한다. S903에서, 각 후보 분산 전략의 효율에 따라, 후보 분산 전략에서 타겟 분산 전략을 결정한다. 분할 결과에 N개의 단편을 포함하는 것을 예로 들면, 열거 방식을 이용하여, N개의 단편과 컴퓨팅 자원에 대해 할당한 후의 시간 예측, 효율 예측 등을 순차대로 스트리밍한다. 즉 열거 결과는 후보 분산 전략에 대응될 수 있다. 시간 예측 결과, 효율 예측 결과 등은 각 후보 분산 전략의 대가로 될 수 있다. 대가는 각 분할 결과의 훈련 효율, 또는 훈련할 모델의 전체 훈련 효율을 나타내는데 사용된다. 예를 들면, 훈련할 모델의 전체 훈련 효율이 가장 높은 경우에 대응되는 분산 전략을, 결정된 최종 분산 전략으 로 한다. 또는, 각 후보 분산 전략에서, 단일 분할 결과의 훈련 효율이 최고 또는 역치에 도달한 수량을 스트리 밍하고, 수량이 가장 많은 후보 분산 전략을 최종 분산 전략으로 결정한다. 각 분할 결과 효율이 가장 많은 분 산 전략을 결정된 최종 분산 전략으로 한다. 상기 프로세스에 따라, 바람직한 분산 전략의 결정을 구현할 수 있다. 일 실시 방식에서, 단계S903은 구체적으로, 미리 설정된 규칙을 이용하여, 각 상기 후보 분산 전략을 정렬하는 단계; 정렬된 결과에 따라, 상기 후보 분산 전략에서 타겟 분산 전략을 결정하는 단계; 를 포함한다. 미리 훈련된 분산 전략 결정 모델도 비용 모델(cost-model)일 수 있다. 비용 모델이 따르는 원칙은 분산 전략이 이익 극대화를 만족시키는 것이다. 예시적으로, 이익 극대화는 부동한 미리 설정된 규칙에 대응될 수 있다. 예 를 들면, 훈련 모델의 전체 훈련 효율이 가장 높은 것, 단일 분할 결과의 훈련 효율이 최고 또는 역치에 도달하 는 수량이 가장 많은 것 등을 포함할 수 있다. 구체적으로 훈련 샘플의 부동함에 따라, 해당 효과를 구현할 수 있다. 미리 설정된 규칙을 선택한 후, 미리 설정된 규칙에 따라 각 후보 분산 전략을 정렬하고, 마지막으로 정 렬 결과에 따라, 후보 분산 전략에서 타겟 분산 전략을 결정한다. 현재 실시 방식에서, 비용 모델의 훈련 프로 세스에 대해 더는 설명하지 않는다. 도10에 도시된 바와 같이, 일 실시 방식에서, 단계S104는 단계S1001 내지 S1002를 포함한다. S1001에서, 컴퓨팅 자원의 가용성을 정기적으로 검출한다. S1002에서, 검출 결과에 컴퓨팅 자원의 불가용이 존재할 경우, 보완 조치를 수행하고, 불가용 상황은 컴퓨팅 자 원 고장 또는 컴퓨팅 자원 수량의 축소를 포함한다. 컴퓨팅 자원의 가용성은 정기 및 능동적으로 검출할 수 있고, 정보에 의해 획득된 방식을 통해 피동적으로 검출 될 수도 있다. 컴퓨팅 자원의 가용성 검출 결과는 두 종류를 포함한다. 하나는 불가용 컴퓨팅 자원이 이미 존재하는 것, 즉, 현재 훈련할 모델에 이미 할당된 컴퓨팅 자원의 불가용에 대응된다. 다른 하나는 현재 훈련할 모델에 이미 할당 된 컴퓨팅 자원 이외에, 유휴 상태에 있는 기타 자원이 존재하는 것, 즉, 여분의 사용 가능한 컴퓨팅 자원이 존 재하는 것에 대응된다. 컴퓨팅 자원의 불가용 상황에 대해, 두 종류로 세분화할 수 있다. 하나는 컴퓨팅 자원의 고장으로 초래된 불가 용이다. 다른 하나는 모델 훈련 요청을 시작하는 클라이언트 수량의 증가로 컴퓨팅 자원의 공급이 수요에 따르 지 못함으로 초래된 불가용이고, 최종으로 컴퓨팅 자원의 축소를 일으킨다. 검출 결과에 컴퓨팅 자원 불가용이 나타날 경우, 종래의 컴퓨팅 자원 수량이 감소되므로, 보완 조치를 시작하여 모델 훈련 프로세스가 계속 수행되도록 해야 한다. 상기 프로세스를 통해, 의외 상황에 대한 대응 조치를 설정하고, 모델 훈련의 정상적인 수행을 최대로 만족할 수 있다. 도11에 도시된 바와 같이, 일 실시 방식에서, 불가용 상황이 컴퓨팅 자원 고장일 경우, 보완 조치를 수행하는 단계는 단계S1101 내지 S1103을 포함한다. S1101에서, 사용자 단말에 의해 시작된 모델 훈련 요청에 포함된 훈련 모드를 획득한다. S1102에서, 훈련 모드가 내결함성 훈련 모드일 경우, 컴퓨팅 자원의 고장이 복구될 때 까지 대기한다. S1103에서, 미리 설정된 시간 내에 컴퓨팅 자원의 고장이 복구되지 않을 경우, 수행 종료로 결정한다. 모델 훈련 요청에 대한 분석을 통해, 모델 훈련 요청에 포함된 훈련 모드를 획득할 수 있다. 상기에 설명된 바 와 같이, 훈련 모드는 내결함성 훈련 모드 및 탄성 훈련 모드를 더 포함할 수 있다. 내결함성 훈련 모드에 있어서, 컴퓨팅 자원이 고장날 경우, 보완 조치는 훈련 프로세스에서 하나 또는 복수의 컴퓨팅 자원 고장이 나타나면, 전체 훈련 태스크는 로그아웃되지 않고, 현재 컴퓨팅 자원을 릴리스하지도 않고, 고장 노드(컴퓨팅 자원)가 미리 설정된 시간 내에 복구될 때까지 대기한 후, 계속 훈련하고, 그렇지 않으면 시 간 초과로 태스크 종료되고 로그아웃된다. 여기서, 계속 훈련하는 데는 고장 상태에서 계속 훈련하는 것을 포함하고, 최초 상태에서 계속 훈련하는 것을 포함할 수도 있다. 상기 프로세스를 통해, 고장이 나타날 경우 태스크 제출, 자원 할당, 모델 로딩 및 훈련 시작과 같은 프로세스 를 다시 수행할 필요없고, 전체 모델 훈련의 효율을 향상시킬 수 있다. 도12에 도시된 바와 같이, 일 실시 방식에서, 불가용이 컴퓨팅 자원 고장일 경우, 보완 조치를 수행하는 단계는 단계S1201 내지 S1202를 포함한다. S1201에서, 훈련 모드가 탄성 훈련 모드일 경우, 후보 컴퓨팅 자원을 결정한다. S1202에서, 후보 컴퓨팅 자원에서 훈련의 재시행을 진행한다. 탄성 훈련 모드는 컴퓨팅 자원 수량이 동적 조정을 서포트하는 훈련 모드에 대응될 수 있다. 즉, 모델 훈련 요 청에서 이미 요청 컴퓨팅 자원의 수량이 일 범위 내에 있음을 명시하였음으로, 수량 범위에 따라, 컴퓨팅 자원 의 수량을 조정할 수 있다. 당해 상황에서, 컴퓨팅 자원에 고장이 나타날 경우, 기타 사용 가능한 컴퓨팅 자원을 선택하여 후보 컴퓨팅 자 원으로 할 수 있다. 모델 훈련 데이터의 이동을 통해, 후보 컴퓨팅 자원의 훈련의 재시행을 진행한다. 도13에 도시된 바와 같이, 도13의 Logical Distributed Graph는 분할 결과(rank0 내지 rank3은 슬라이스에 대 응됨)에 대응되고, Cluster Object는 컴퓨팅 자원에 대응되고, Physical Distributed Graph는 분산 전략에 대 응될 수 있다. 여기서, 컴퓨팅 자원은 D0 내지 D4를 포함한다. 도13의 왼쪽에 도시된 예시는 컴퓨팅 자원 D0 내 지 D3을 이용하여 모델 훈련하는 프로세스에서, 컴퓨팅 자원 D2에 고장이 나타난 것이다. 이를 기반으로, 도13 의 오른쪽에 도시된 예시는 컴퓨팅 자원 D4를 후보 컴퓨팅 자원으로 하고, 원래 컴퓨팅 자원 D2에서 훈련하는 데이터를 컴퓨팅 자원 D4로 이동하고, 컴퓨팅 자원 D4에서 재시행을 진행한다. 일 실시 방식에서, 후보 컴퓨팅 자원에서 재시행하는 것에 있어서, 아래의 상황을 포함한다. 1: 컴퓨팅 자원이 고장날 경우의 훈련 상태를 획득하고; 훈련 상태를 기반으로, 후보 컴퓨팅 자원에서 훈련 재시행을 진행한다. 2: 훈련의 최초 상태를 획득하고; 최초 상태를 기반으로, 후보 컴퓨팅 자원에서 훈련 재시행을 진행한다. 첫 번째 상황에서, 고장된 컴퓨팅 자원이 고장날 경우의 훈련 상태를 획득하고, 고장날 경우 훈련의 재시행을 진행한다. 고장날 경우 훈련의 재시행을 진행하는 장점은, 전체 훈련 프로세스의 시간을 절약할 수 있다. 두번째 상황에서, 후보 컴퓨팅 자원에서 훈련을 다시 시작할 수 있다. 즉 최초 상태에서 다시 훈련하는 것이다. 최초 상태를 기반으로, 후보 컴퓨팅 자원에서 재시행을 진행하는 장점은, 전체 훈련 프로세스의 정확성 및 훈련 의 완전성을 보장하는 것이다. 도14에 도시된 바와 같이, 일 실시 방식에서, 불가용 상황이 컴퓨팅 자원 수량의 축소일 경우, 보완 조치를 수 행하는 단계는 단계S1401 내지 S1404를 포함한다. S1401에서, 축소된 컴퓨팅 자원의 제1 수량을 결정한다. S1402에서, 제1 수량에 따라, 훈련할 모델을 재분할하여, 재분할된 제1 결과를 획득한다. S1403에서, 재결정된 축소 후의 나머지 컴퓨팅 자원의 속성을 이용하여, 축소된 컴퓨팅 자원에서 각 재분할된 제1 결과의 제1 분산 전략을 결정한다. S1404에서, 제1 분산 전략에 따라, 축소된 컴퓨팅 자원을 이용하여 훈련할 모델에 대해 분산식 훈련을 수행한다. 모델 훈련 요청을 시작하는 클라이언트 수량의 증가, 또는 모델 훈련 요청에서 신청된 컴퓨팅 자원 수량이 비교 적 크므로, 컴퓨팅 자원의 공급이 수요에 따르지 못하는 경우를 초래한다. 컴퓨팅 자원의 공급이 수요에 따르지 못할 경우, 컴퓨팅 자원 축소를 초래할 수 있다. 도15에 도시된 바와 같이, 도15의 왼쪽에 도시된 Logical Distributed Graph는 분할 결과(rank0 내지 rank3는 슬라이스에 대응됨)에 대응되고, Cluster Object는 컴퓨팅 자원에 대응되고, Physical Distributed Graph는 분 산 전략에 대응될 수 있다. 여기서, 최초 훈련 프로세스에서, 컴퓨팅 자원은 D0 내지 D3을 포함한다. 도15의 오 른쪽에 도시된 바와 같이, 컴퓨팅 자원 축소를 초래하는 상황에서, 컴퓨팅 자원D2 및 D3의 상태는 불가용으로 변한다. 이리하여, 축소된 컴퓨팅 자원의 제1 수량은 2로 변한다. 훈련할 모델에 할당하여 훈련하는 컴퓨팅 자 원이 변화(감소)되므로, 상기 훈련할 모델에 할당하여 훈련하는 컴퓨팅 자원을 다시 분석하여, 컴퓨팅 자원의 속성을 획득하고, 컴퓨팅 자원의 토폴로지 정보를 획득한다. 제1 수량에 따라, 훈련할 모델을 재분할한다. 분할 방식은 상기 프로세스와 같아, 여기서 더는 설명하지 않는다. 도15의 오른쪽에 도시된 바와 같이 재분할된 후, 분할 결과는 2개의 슬라이스이고, rank0 및 rank1에 대응된다. 나머지 컴퓨팅 자원(D0 및 D1)의 속성을 이용하여, 축소된 컴퓨팅 자원에서 2개의 슬라이스의 제1 분 산 전략을 결정한다. 즉 도15의 오른쪽에 도시된 바와 같이, 제1 분산 전략에 따라, 새로운 슬라이스 rank0는 컴퓨팅 자원 D0에 할당되고, 새로운 슬라이스 rank1은 컴퓨팅 자원 D1에 할당된다. 후속의 훈련 프로세스에서, 나머지 컴퓨팅 자원(D0 및 D1)에 의해 훈련 프로세스를 계속 수행한다. 전체 프로세 스는 여전히 인공 간섭이 필요 없고, 자동화 방식으로 수행된다. 도16에 도시된 바와 같이, 일 실시 방식에서, 검출 결과에 사용 가능한 여분의 컴퓨팅 자원이 존재할 경우 단계 S1601 내지 S1604를 포함한다. S1601에서, 사용 가능한 여분의 컴퓨팅 자원의 제2 수량을 결정한다. S1602에서, 제2 수량에 따라, 훈련할 모델을 재분할하여, 재분할된 제2 결과를 획득한다. S1603에서, 다시 결정된 여분의 컴퓨팅 자원의 속성을 이용하여, 확장된 컴퓨팅 자원에서 각 재분할된 제2 결과 의 제2 분산 전략을 결정한다. S1604에서, 제2 분산 전략에 따라, 확장된 컴퓨팅 자원을 이용하여 훈련할 모델에 대해 분산식 훈련을 수행한다. 모델 훈련 요청을 시작하는 클라이언트 수량이 감소되고, 또는 모델 훈련 요청에서 신청된 컴퓨팅 자원 수량이 크지 않을 경우, 컴퓨팅 자원의 공급이 수요를 초과하는 경우를 초래한다. 컴퓨팅 자원의 공급이 수요를 초과할 경우, 컴퓨팅 자원 확장을 초래할 수 있다. 즉, 모델 훈련 태스크에 더 많은 컴퓨팅 자원을 여분으로 할당할 수 있다. 훈련할 모델에 할당하여 훈련하는 컴퓨팅 자원이 변화(증가)되므로, 상기 훈련할 모델에 할당되어 훈련하 는 컴퓨팅 자원을 다시 분석하여, 컴퓨팅 자원의 속성을 획득하고, 컴퓨팅 자원의 토폴로지 정보를 획득해야 한 다. 도17에 도시된 바와 같이, 도17은 컴퓨팅 자원 확장된 후의 조정 개략도이다. 도17의 왼쪽에 도시된 바와 같이 Logical Distributed Graph는 분할 결과(rank0 내지 rank3는 슬라이스에 대응됨)에 대응되고, Cluster Object 는 컴퓨팅 자원에 대응되고, Physical Distributed Graph는 분산 전략에 대응될 수 있다. 여기서, 최초 훈련 프로세스에서, 컴퓨팅 자원은 D0 내지 D3을 포함한다. 도17의 오른쪽에 도시된 바와 같이, 컴퓨팅 자원 확장을 초 래할 경우, 여분의 컴퓨팅 자원 D4 및 D5의 상태가 사용 가능으로 변한다. 이리하여, 확장된 컴퓨팅 자원의 제2 수량은 6으로 변한다. 제2 수량에 따라, 훈련할 모델을 재분할한다. 분할 방식은 상기 프로세스와 같아, 여기서 더는 설명하지 않는다. 도17의 오른쪽에 도시된 바와 같이 재분할된 후, 분할 결과는 6개의 슬라이스이고, rank0 내지 rank5에 대응된다. 확장된 컴퓨팅 자원(D0 내지 D5)의 속성을 이용하여, 확장된 컴퓨팅 자원에서 5개 슬라이스의 제2 분 산 전략을 결정한다. 즉, 도17의 오른쪽에 도시된 바와 같이, 제2 분산 전략에 따라, 새로운 슬라이스 rank0는 컴퓨팅 자원 D0에 할당되고, 새로운 슬라이스 rank1은 증가된 컴퓨팅 자원 D4에 할당되고, 새로운 슬라이스 rank2는 컴퓨팅 자원 D1에 할당되며, 새로운 슬라이스 rank3은 컴퓨팅 자원 D5에 할당되고, 새로운 슬라이스 rank4는 증가된 컴퓨팅 자원 D5에 할당되고, 새로운 슬라이스 rank5는 컴퓨팅 자원 D3에 할당된다. 상기 프로세스를 통해, 컴퓨팅 자원이 확장될 경우, 훈련할 모델을 재분할함으로, 컴퓨팅 자원에 대한 최대 한 도의 이용을 구현한다. 일 실시 방식에서, 컴퓨팅 자원의 수량이 변화될 경우, 변화된 수량에 따라, 훈련할 모델의 학습률 및 단번의 훈련에 선택된 샘플 수량을 조정하는 단계를 포함한다 탄성 확장 및 축소를 수행할 경우, 학습률 및 단번에 훈련함으로 선택된 샘플 수량(batch_size)에 대해 조정하 도록 보장하는 일정한 메커니즘이 있을 수 있다. 여기서, 학습률은 훈련할 모델 파라미터를 업데이트하는 하이 퍼파라미터일 수 있다. 예를 들면, 인터페이스를 통해 학습률 및 batch_size에 대한 조정을 트리거링하고, 또는 컴퓨팅 자원의 수량이 변화됨을 검출하였을 경우, 자동으로 조정함으로, 훈련 수렴성 및 훈련 효과에 대한 영향을 최소화하거나 영향 을 생성하지 않는다. 일 실시 방식에서, 분산식 훈련은, 분산 비동기 파이프라인 훈련을 포함한다. 분산 비동기 파이프라인의 수행 방식은 복수의 컴퓨팅 자원의 동시 수행을 구현할 수 있고, 상하위 논리 관계를 구비한 데이터를 자동 연관시키고, 데이터의 별렬화, 동적화를 구현한다. 이리하여, 통신과 컴퓨팅의 동시 발생 을 최대로 향상시키고, 훈련 효율을 향상시킬 수 있다. 동시에 서브 태스크를 디커플링함으로, 1개의 태스크가 복수의 기기에서 운행되도록 한다. 컴퓨팅 자원이 변화될 경우, 분할 전략의 변화를 초래하고, 프로세스를 리부팅하고, 분산 비동기 파이프라인 훈 련을 수행해야 한다. 각 프로세스는 일 수신 서비스의 스레드, 메시지 큐 및 복수의 메시지를 처리하는 스레드 를 포함한다. 1개의 메시지는 프로세스 송신 번호, 프로세스 수신 번호, 태스크 정보를 포함한다. 서비스를 수신하는 스레드는, 메시지를 끊임없이 수신하고, 메시지 큐로 넣는다. 서비스를 처리하는 스레드는, 메시지 큐에서 1개의 메시지를 끊임없이 수신하고, 메시지의 태스크 정보에 따라 수행한다. 수행 후 메시지에 따라, 결과를 다음 기기로 송신한다. 인접 기기 사이는 부동한 서브 태스크를 동시에 처리한다. 내결함성, 확장 또는 축소일 경우, 통일 컴퓨팅 뷰, 통일 자원 뷰의 재구축, 재분할, 매핑하도록 트리거링하고, 수행 태스크를 재구성하고, 프로세스를 시작하여, 훈련 프로세스를 수행한다. 일 실시 방식에서, 훈련할 모델은 사용자 단말에 의해 시작된 모델 훈련 요청에 따라 획득된 것이다. 전체 모델 훈련 플랫폼은 단대단 훈련 플랫폼일 수 있다. 사용자 단말에 있어서, 훈련할 모델의 관련 정보 및 수요되는 컴퓨팅 자원의 수량과 예측된 훈련 효과만 결정하면 된다. 전체 훈련 프로세스는 단대단 훈련 플랫폼 에 의해 자동으로 수행될 수 있고, 사용자 단말에 있어서, 모델 훈련 요청에서만 기본 정보를 결정하면 되고 기 타 동작을 하지 않아도 된다. 이리하여 사용자의 난이도 요구를 단순화하고, 모델의 전자동을 구현한다. 도18에 도시된 바와 같이, 본 발명은 단대단 자체 적응에 기반한 분산식 훈련 방법을 제공하고, 당해 방법은 아 래의 프로세스를 포함한다.1, 사용자가 훈련 태스크를 제출함: 사용자가 훈련 플랫폼에서 분산식 덥러닝(훈련할 모델) 훈련 태스크를 시작 하고, 훈련 태스크 유형은 탄성 훈련 태스크 및 비탄성 훈련 태스크를 포함하고, 탄성 훈련 태스크는 또한 내결 함성 모드 및 탄성 확장 및 축소 모드로 나누고, 지정된 컴퓨팅 노드 수가 고정된 값일 경우(예를 들면 node_nums=2 또는 node_nums=2:2) 내결함성 모드임을 나타내고, 지정된 컴퓨팅 노드 수가 일 범위일 경우(예를 들면 node_nums=2:4) 탄성 확장 및 축소 모드임을 나타낸다. 2, 지능형 스케줄링: 훈련 플랫폼의 AI 플랫폼 스케줄링 시스템(예를 들면 k8s를 기반으로 하는 paddle- operator)은 분산식 딥러닝 훈련 태스크에 대한 스케줄링을 책임지고, 전체 훈련 태스크를 1개의 전체로 라이프 사이클 관리를 진행하고, 훈련 태스크에 대해 확장 및 축소 동작하는 인터페이스를 제공한다. 플랫폼 각도에서, 전체 자원 사용 상황에 따라 훈련 태스크를 능동적으로 트리거링하여 컴퓨팅 자원의 확장 및 축소 동작을 진행 하고, 또는 조각 모음의 고려를 기반으로, 일부 컴퓨팅 자원에 대해 동적 이동 동작을 진행한다. 당해 동작은 현재 훈련 태스크를 중단하지 않는 상황에서 수행될 수 있다. 3, 탄성 훈련 컨트롤러: 훈련 컨트롤러는 훈련 태스크에 대한 할당의 시작을 책임지고, 탄성 태스크 및 비탄성 태스크로 나눈다. 탄성 훈련 태스크일 경우, 태스크 시작 후, 컨트롤러는 자체 및 당해 모니터링하는 서브 프로 세스를 \"서비스 발견\"(ETCD)에 등록하는 동시에 탄성 훈련 컨트롤러도 \"서비스 발견\"을 통해 기타 컨트롤러 및 당해 서브 프로세스의 상태(노드 다운 또는 불가용, 또는 카드 고장 등 상황)를 감지한다. 탄성 훈련 컨트롤러 가 기타 노드 변화(노드 또는 카드 고장의 로그아웃 또는 확장 및 축소)를 감자하였을 경우, 기존 노드를 보존 하고, 훈련 프로세스(서브 프로세스)를 복구한다. 탄성 훈련 태스크는 내결함성 모드 및 탄성 모드를 포함한다. 내결함성 모드의 태스크는, 훈련 프로세스에서 하나 또는 복수의 컴퓨팅 자원 고장(노드 불가용 또는 GPU 카드 고장)을 만난 후, 전체 훈련 태스크는 로그아웃되지 않고, 현재 컴퓨팅 자원을 릴리스하지도 않고, 고장 노드가 시간 초과 시간 내에 복구된 후, 훈련을 계속(고장 시각에서 계속 훈련함)하고, 그렇지 않으면 시간 초과일 경 우 태스크 실패로 로그아웃된다. 탄성 확장 및 축소 모드의 태스크는, 훈련 프로세스에서 하나 또는 복수의 훈련 컴퓨팅 자원 고장(노드 불가용 또는 GPU 카드 고장) 또는 수동/자동 확장 및 축소 동작을 만날 경우, 전체 훈련 태스크는 로그아웃되지 않고, 현재 컴퓨팅 자원을 릴리스하지도 않고, 확장 또는 축소된 노드 수로, 훈련(타임 시각에서 계속 훈련함)을 계속 한다. 동시에 탄성 확장 및 축소를 할 경우, 학습률 및 batch_size에 대해 조정하도록 보장하는 일정한 메커니즘이 있 을 수 있음으로(인터페이스를 통해 학습률 및 batch_size에 대한 조정을 트리거링하고, 또는 당해 2항을 자동으 로 조정함), 훈련 수렴성 및 효과에 대한 영향을 최소화하거나 영향을 생성하지 않는다. 4, 분산식 컴퓨팅 뷰 분석: 모델의 훈련 프로세스는 컴퓨팅 데이터 흐름도로 설명될 수 있다. 각 연산자와 텐서 를 병렬화하면, 전체 모델의 네트워크층을 병렬화하고, 순차대로 수행된 컴퓨팅도를 분산식 컴퓨팅도로 전환할 수 있다. 분산식 텐서, 분산식 연산자 및 재구성 변환 등 개념 및 더 세밀한 입도 분산식 속성으로 임의의 분할 전략을 서포트하고, 마지막으로 훈련할 모델의 분할 결과를 획득할 수 있다. 또한, 기기와 관계 없는 분할 전략 및 기기와 관련된 배치 전략의 디커플링을 서포트한다. 여기서 분산식 속성은 논리 프로세스 토폴로지 정보 (process_mesh)를 포함하고, 텐서 각 차원 분할 매핑 정보(dims_mapping), 텐서 각 차원 슬라이스 크기 정보 (shard_sizes) 및 슬라이스 물리 기기 배치 정보(device_placement)를 포함하고, 각 분산식 텐서 및 분산식 연 산자는 모두 각각의 분산식 속성을 구비할 수 있고, 1개 텐서의 분산식 속성과 당해 텐서를 사용한 연산자의 해 당 분산식 속성과 부동하고, 저장 및 컴퓨팅 분리하는데 유리하다. 5, 클러스터 하드웨어 토폴로지 탐지: 훈련 태스크에 대응되는 클러스터 하드웨어 자원의 속성 정보를 기반으로 클러스터 자원 뷰를 생성한다. 즉, 해당 컴퓨팅 자원의 속성이다. 즉, 클러스터 하드웨어 자원(기계, 교환기 등)추상 표시, 기기 사이의 토폴로지 정보, 기기 내의 프로세서, 비디오 메모리, 대역폭 등 처리 능력 관련 정 보를 포함하고, 클러스터 사이, 클러스터 내부 하드웨어 사이, 하드웨어 내부의 구체적인 연결 방식 및 차이의 차단을 구현하고, 각 이기종 하드웨어 및 클러스터 환경을 서포트할 수 있다. 6, 분산식 컴퓨팅도 및 하드웨어 통신 토폴로지 매핑: 제4 단계의 분산식 컴퓨팅 뷰 및 제5 단계의 클러스터 자 원 뷰를 기반으로, 분산식 훈련 태스크의 배치 전략을 결정하고, 배치 전략 매핑 파일을 생성한다. 배치 전략은 컴퓨팅 자원에서 컴퓨팅 자원의 분산 전략에 대응된다. 토폴로지 매핑이 완료된 후 태스크 훈련 태스크의 수행을 정식으로 스케줄링하기 시작한다. 7, 물리 수행 계획을 구축함: 제6 단계의 배치 전략 매핑 파일에 따라, 물리 수행 계획을 생성하고, 물리 수행 계획은 컴퓨팅 프로세스(분산식 컴퓨팅도)와 하드웨어 배치 전략을 포함한다. 또한, 물리 수행 계획은 탄성 자 원 관리 메커니즘과 결합하고, 컴퓨팅 자원 유휴 또는 긴장할 경우 탄성 확장 및 축소를 구현하고, 컴퓨팅 노드 수량을 동적으로 조정하고, 수요에 따라 재분할할 수 있다. 당해 설계는 논리 분할 및 물리 매핑을 디커플링하여, 이기종 하드웨어를 더 잘 호환할 수 있다. 또한, 분산식 연산자 및 분산식 텐서를 더 디커플링하여, 부동한 병렬 전략으로 더 잘 확장한다. 입력 출력 텐서의 정의 및 연산자 정의가 매핑되지 않을 경우, 프레임 워크는 재구성 전환 연산자를 자동으로 삽입하여, 컴퓨팅의 정확성 을 보장할 수 있다. 입력 출력 텐서의 기기와 연산자의 기기가 일치하지 않을 경우, 프레임 워크는 통신 연산자 를 자동으로 삽입하여, 크로스 기기 분할의 정확성을 보장한다. 사용자가 사용할 경우, 전자동 모드로 프레임 워크가 자동으로 분할을 완료하도록 하고, API 인터페이스를 통해 원하는 분할 전략을 정의할 수도 있다. 8, 비동기 파이프라인 액추에이터: 제7 단계의 물리 수행 계획을 기반으로 훈련할 딥러닝 모델에 대해 분산식 훈련을 수행한다. 분산 비동기 파이프라인 액추에이터를 통해, 통신 및 컴퓨팅의 동시 발생 정도를 최대로 향상 시키고, 훈련 효율을 향상시킬 수 있다. 동시에 각 서브 태스크를 디커플리하여, 1개의 태스크가 복수의 기기에 서 운행되도록 한다. 9, 토폴로지 감지 통신: 수행 단계에서 자동으로 물리 수행 계획에 따라, 자동으로 부동한 컴퓨팅도의 병렬 통 신 모드를 구축하고, 부동한 통신 서브 영역을 통해 부동한 병렬 모드를 진행하고, 복수의 병렬 모드는 동시에 존재할 수 있다. 예를 들면, 통신 서브 영역 1은 데이터 병렬을 사용하고, 통신 서브 영역 2는 모델 병렬을 사 용한다. 감지 통신은 도18의 검출 노드(checkpoint)를 이용하여 수행될 수 있다. 총체적으로, 상기 훈련할 모델에 대한 훈련 프로세스는 단대단의 자체 적응 프로세스이다. 컴퓨팅 자원에 의해 나타낸 노드 변동은 전체 시스템을 트리거링할 수 있고, 2개의 뷰 구축(분산식 컴퓨팅 뷰는 모델 분할에 대응되 고, 클러스터 자원 뷰는 컴퓨팅 자원 속성의 결정에 대응됨), 구체적으로 수행하려는 태스크 구축(분할 결과는 컴퓨팅 자원의 분산 전략)을 포함하고, 프로세스 훈련을 시작하고, 훈련 태스크의 할당을 진행하며, 컴퓨팅 노 드는 훈련 태스크를 수행한다. 도19에 도시된 바와 같이, 본 발명은 단대단 자체 적응에 기반한 분산식 훈련 장치를 포함하고, 당해 장치는, 훈련할 모델을 분할하여, 분할 결과를 획득하는데 사용되는 분할 모듈; 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 컴퓨팅 자원의 속성을 획득하는데 사용되는 컴퓨팅 자원의 속성 결정 모듈 - 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 훈련할 모델의 컴퓨팅 자원 수 요, 기타 훈련하고 있는 모델에 의해 점용된 컴퓨팅 자원 및 유휴 컴퓨팅 자원에 의해 결정된 것이고, 컴퓨팅 자원의 속성은 컴퓨팅 자원의 토폴로지 관계, 태스크 처리 능력 중의 적어도 하나를 나타내는데 사용됨 - ; 컴퓨팅 자원의 속성을 이용하여, 컴퓨팅 자원에서 각 분할 결과의 분산 전략을 결정하는데 사용되는 분산 전략 결정 모듈; 및 분산 전략에 따라, 컴퓨팅 자원을 이용하여 훈련할 모델에 대해 분산식 훈련하는데 사용되는 분산식 훈련 모듈 ; 을 포함한다. 일 실시 방식에서, 분할 모듈은 구체적으로, 훈련할 모델의 연산자 및 텐서를 결정하는데 사용되는 연산자 및 텐서의 결정 서브 모듈; 분할 전략을 이용하여, 훈련할 모델의 연산자 및 텐서를 분할하여, 분할 결과를 획득하는데 사용되는 분할 수행 서브 모듈; 을 포함한다. 일 실시 방식에서, 분할 수행 서브 모듈은 구체적으로, 분할 전략을 이용하여, 훈련할 모델의 연산자 및 텐서를 분할하여, N개의 슬라이스를 획득하는데 사용되는 분할 전략 수행 유닛 - N은 양의 정수임 - ; 각 슬라이스에 대해, 슬라이스의 분산식 속성 정보를 로딩하는데 사용되는 분산식 속성 정보 로딩 유닛 - 분산 식 속성 정보는 훈련할 모델에서 당해 슬라이스의 프로세스 토폴로지 정보, 당해 슬라이스의 분할 매핑 정보, 당해 슬라이스의 슬라이스 크기 정보 중의 적어도 하나를 포함함 - ; 을 포함한다.분산식 속성 정보를 로딩하는 슬라이스를 분할 결과로 한다. 일 실시 방식에서, 분산식 속성 정보 로딩 유닛은, 미리 설정된 방식을 이용하여 분산식 속성 정보의 복수 후보 카테고리를 수신하는데 사용되는 후보 카테고리 수 신 서브 유닛; 복수의 후보 카테고리에서 타겟 카테고리를 결정하여, 분산식 속성 정보의 카테고리로 하는데 사용되는 선별 서 브 유닛; 을 포함한다. 일 실시 방식에서, 배치 정보 결정 유닛은 구체적으로, 각 슬라이스의 분산식 속성을 이용하여, 각 슬라이스의 배치 정보를 결정하고, 배치 정보는 슬라이스와 컴퓨팅 자원의 물리 매핑 관계를 나타내는데 사용된다. 일 실시 방식에서, 슬라이스가 훈련할 모델의 인접 네트워크층에 위치하고 슬라이스의 배치 정보가 부동할 경우, 통신 보조 연산자 결정 유닛을 포함하고, 구체적으로, 배치 정보를 이용하여, 통신 보조 연산자를 결정하고, 통신 보조 연산자는 각 슬라이스 사이의 논리 연산 관계 를 나타내는데 사용된다. 일 실시 방식에서, 슬라이스가 훈련할 모델의 동일 네트워크층에 위치할 경우, 재구성 전환 연산자 결정 유닛을 포함하고, 구체적으로, 각 슬라이스 사이의 네트워크층 일치성 관계를 나타내는데 사용되는 재구성 전환 연산자를 결정하는데 사용된다. 일 실시 방식에서, 분할 수행 서브 모듈은, 사용자 단말에 의해 시작된 모델 훈련 요청에 대해 분석 결정을 수행하는데 사용되는 분할 전략 결정 유닛을 포 함한다. 일 실시 방식에서, 분할 수행 서브 모듈은, 미리 훈련된 분할 전략을 이용하여 모델 결정을 수행하는데 사용되는 분할 전략 결정 유닛을 포함한다. 일 실시 방식에서, 컴퓨팅 자원의 속성 결정 모듈은, 구체적으로, 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하고, 하드웨어 토폴로지 관계를 컴퓨팅 자원의 속성으로 하는데 사용된다. 일 실시 방식에서, 컴퓨팅 자원의 속성 결정 모듈은, 컴퓨팅 자원의 최소 어셈블리를 결정하는데 사용되는 최소 어셈블리 결정 서브 모듈 - 최소 어셈블리는 프로세 서 또는 메모리를 포함함 - ; 적어도 하나의 최소 어셈블리로 구성된 기계 기기를 결정하는데 사용되는 기계 기기 결정 서브 모듈 - 각 기계 기기의 최소 어셈블리는 중복되지 않음 - ; 및 적어도 하나의 기계 기기로 구성된 클러스터를 결정하는데 사용되는 클러스터 결정 서브 모듈 - 각 클러스터의 기계 기기는 중복되지 않음 - ; 을 포함한다. 최소 어셈블리, 기계 기기 및 클러스터를 컴퓨팅 자원의 하드웨어 토폴로지 관계로 한다. 일 실시 방식에서, 컴퓨팅 자원의 속성 결정 모듈은, 구체적으로, 각 최소 어셈블리의 밀접 관계 리스트를 결정하고; 밀접 관계 리스트는 소스 최소 어셈블리와 목적 최소 어셈블 리 사이의 연결 관계, 대역폭 정보 및 지연 정보 중의 적어도 하나를 포함하고, 밀접 관계 리스트를 컴퓨팅 자원의 하드웨어 토폴로지 관계로 하는데 사용된다. 일 실시 방식에서, 훈련할 모델에 할당하여 훈련하는 컴퓨팅 자원은 사용자 단말에 의해 시작된 모델 훈련 요청 에 따른 내용, 및 모델 훈련 요청을 시작하는 사용자 단말의 수량 중의 적어도 하나에 의해 결정된다. 일 실시 방식에서, 컴퓨팅 자원의 속성 결정 모듈은, 컴퓨팅 자원의 통신 경로를 획득하는데 사용되는 통신 경로 획득 서브 모듈; 컴퓨팅 자원의 통신 경로를 이용하여, 각 컴퓨팅 자원 사이의 통신 토폴로지 관계를 구축하는데 사용되는 통신 토폴로지 관계 구축 서브 모듈; 을 포함한다. 통신 토폴로지 관계를 컴퓨팅 자원의 속성으로 한다. 일 실시 방식에서, 최단 통신 경로 구축 서브 모듈을 더 포함하고, 구체적으로, 통신 토폴로지 관계에 따라, 소스 컴퓨팅 자원과 타겟 컴퓨팅 자원 사이의 최단 통신 경로를 결정하는데 사용된 다. 일 실시 방식에서, 분산 전략 결정 모듈은, 컴퓨팅 자원에서 각 분할 결과의 후보 분산 전략을 결정하는데 사용되는 후보 분산 전략 획득 서브 모듈; 각 후보 분산 전략의 효율을 각각 통계하는데 사용되는 효율 통계 서브 모듈; 및 각 후보 분산 전략의 효율에 따라, 후보 분산 전략에서 타겟 분산 전략을 결정는데 사용되는 타겟 분산 전략 결 정 서브 모듈; 을 포함한다. 일 실시 방식에서, 타겟 분산 전략 결정 서브 모듈은, 미리 설정된 규칙을 이용하여, 각 후보 분산 전략을 정렬하는데 사용되는 정렬 유닛; 정렬 결과에 따라, 후보 분산 전략에서 타겟 분산 전략을 결정하는데 사용되는 결과 결정 유닛; 을 포함한다. 일 실시 방식에서, 분산식 훈련 모듈은, 컴퓨팅 자원의 가용성을 정기적으로 검출하는데 사용되는 가용성 검출 서브 모듈; 검출 결과에 컴퓨팅 자원 불가용이 존재할 경우, 보완 조치를 수행하는데 사용되는 보완 조치 수행 서브 모듈 - 불가용 상황은 컴퓨팅 자원 고장 또는 컴퓨팅 자원 수량의 축소를 포함함 - ; 을 포함한다. 일 실시 방식에서, 불가용 상황이 컴퓨팅 자원 고장일 경우, 보완 조치 수행 서브 모듈은, 사용자 단말에 의해 시작된 모델 훈련 요청에 포함된 훈련 모드를 획득하는데 사용되는 훈련 모드 획득 유닛; 훈련 모드가 내결함성 훈련 모드일 경우, 컴퓨팅 자원의 고장이 복구될 때 까지 대기하는데 사용되는 대기 유닛; 및 미리 설정된 시간 내에 컴퓨팅 자원의 고장이 복구되지 않을 경우, 수행 종료로 결정하는데 사용되는 결과 결정 유닛; 을 포함한다. 일 실시 방식에서, 불가용 상황이 컴퓨팅 자원 고장일 경우, 보완 조치 수행 서브 모듈은, 훈련 모드가 탄성 훈련 모드일 경우, 후보 컴퓨팅 자원을 결정하는데 사용되는 후보 컴퓨팅 자원 결정 유닛; 후보 컴퓨팅 자원에서 훈련의 재시행을 진행하는데 사용되는 재시행 유닛; 을 더 포함한다. 일 실시 방식에서, 재시행 유닛은, 컴퓨팅 자원이 고장날 경우의 훈련 상태를 획득하는데 사용되는 훈련 상태 획득 서브 유닛; 훈련 상태를 기반으로, 후보 컴퓨팅 자원에서 훈련 재시행을 진행하는데 사용되는 재시행 수행 서브 유닛; 을 포함한다. 일 실시 방식에서, 재시행 유닛은, 훈련의 최초 상태를 획득하는데 사용되는 최초 상태 획득 서브 유닛; 최초 상태를 기반으로, 후보 컴퓨팅 자원에서 훈련 재시행을 진행하는데 사용되는 재시행 수행 서브 유닛; 을 포함한다. 일 실시 방식에서, 불가용 상황이 컴퓨팅 자원 수량의 축소일 경우, 보완 조치 수행 서브 모듈은, 축소된 컴퓨팅 자원의 제1 수량을 결정하는데 사용되는 제1 수량 결정 유닛; 제1 수량에 따라, 훈련할 모델을 재분할하여, 재분할된 제1 결과를 획득하는데 사용되는 제1 재분할 유닛; 재결정된 축소 후의 나머지 컴퓨팅 자원의 속성을 이용하여, 축소된 컴퓨팅 자원에서 각 재분할된 제1 결과의 제1 분산 전략을 결정하는데 사용되는 제1 분산 전략 결정 유닛; 및 제1 분산 전략에 따라, 축소된 컴퓨팅 자원을 이용하여 훈련할 모델에 대해 분산식 훈련을 수행하는데 사용되는 분산식 훈련 수행 유닛; 을 포함한다. 일 실시 방식에서, 검출 결과에 사용 가능한 여분의 컴퓨팅 자원이 존재할 경우, 사용 가능한 여분의 컴퓨팅 자원의 제2 수량을 결정하는데 사용되는 제2 수량 결정 유닛; 제2 수량에 따라, 훈련할 모델을 재분할하여, 재분할된 제2 결과를 획득하는데 사용되는 제2 재분할 유닛; 다시 결정된 여분의 컴퓨팅 자원의 속성을 이용하여, 확장된 컴퓨팅 자원에서 각 재분할된 제2 결과의 제2 분산 전략을 결정하는데 사용되는 제2 분산 전략 결정 유닛; 및 제2 분산 전략에 따라, 확장된 컴퓨팅 자원을 이용하여 훈련할 모델에 대해 분산식 훈련을 수행하는데 사용되는 분산식 훈련 수행 유닛; 을 포함한다. 일 실시 방식에서, 컴퓨팅 자원의 수량이 변화될 경우, 조정 서브 유닛을 더 포함하고, 구체적으로, 변화된 수량에 따라, 훈련할 모델의 학습률 및 단번의 훈련에 선택된 샘플 수량을 조정하는데 사용된다. 일 실시 방식에서, 분산식 훈련은 분산 비동기 파이프라인 훈련을 포함한다. 일 실시 방식에서, 훈련할 모델은 사용자 단말에 의해 시작된 모델 훈련 요청에 따라 획득된 것이다. 본 발명의 기술 수단에서, 언급된 사용자 개인정보의 획득, 저장 및 응용 등은, 모두 관련 법규의 규정에 해당 되고, 공서양속에 위배되지 않는다. 본 발명의 실시예에 따르면, 본 발명은 전자 기기, 판독 가능 저장 매체 및 컴퓨터 프로그램을 더 제공한다. 도20에 도시된 바와 같이, 도20은 본 발명 실시예를 구현하는데 사용되는 전자 기기의 개략적인 블록도이 다. 전자 기기는 다양한 형식의 디지털 컴퓨터를 표시한다. 예를 들면, 랩톱 컴퓨터, 데스크톱 컴퓨터, 워크스 테이션, 개인 정보 단말(PAD), 서버, 블레이드 서버, 메인 프레임 및 기타 적합한 컴퓨터일 수 있다. 전자 기기 는 다양한 형식의 모바일 장치를 표시한다. 예를 들면 개인 정보 단말(PAD), 셀룰러 폰, 스마트 폰, 웨어러블 기기 및 기타 유사한 컴퓨팅 장치일 수 있다. 본 발명에 개시된 컴포넌트, 이들의 연결과 관계, 및 기능은 단지 예시적인 것 뿐이며, 본 발명에서 설명 및/또는 요구한 본 발명의 구현을 한정하려는 것은 아니다. 도20에 도시한 바와 같이, 전자 기기는 컴퓨팅 유닛을 포함하고, 읽기 전용 메모리(ROM)에 저장된 컴퓨터 프로그램 또는 저장 유닛에서 랜덤 액세스 메모리(RAM)에 로딩된 컴퓨터 프로그램/ 명령에 따라, 각 적당한 조작 및 처리를 수행한다. RAM에서, 전자 기기 조작에 수요되는 각 프로그 램 및 데이터를 저장할 수도 있다. 컴퓨팅 유닛, ROM 및 RAM은 버스를 통해 서로 연 결된다. 입력/출력I/O 인터페이스도 버스에 연결된다. 전자 기기의 복수의 컴포넌트는 I/O인터페이스에 연결되고, 복수의 컴포넌트는, 키보드, 마우스 등 과 같은 입력 유닛; 다양한 유형의 모니터, 스피커 등과 같은 출력 유닛; 자기 디스크, 광 디스크 등과 같은 저장 유닛; 및 네트워크 카드, 모뎀 또는 무선 통신 송수신기 등과 같은 통신 유닛을 포 함한다. 통신 유닛은 전자 기기가 인터넷과 같은 컴퓨터 네트워크 및/또는 각 전신 네트워크를 통 해 기타 기기와 정보/데이터를 교환할 수 있도록 허용한다. 컴퓨팅 유닛은 각 처리 및 계산 기능을 구비한 범용/전용 처리 컴포넌트일 수 있다. 컴퓨팅 유닛의 일부 예시는 중앙 처리 장치(CPU), 그래프 처리 장치(GPU), 각 전용 인공지능 계산 칩, 각 기계 학습 모델 알고 리즘을 운행하는 컴퓨팅 유닛, 디지털 신호 처리 장치(DSP), 임의의 적합한 프로세서, 제어기 및 마이크로 제어 기 등을 포함하나 이에 한정되지 않는다. 컴퓨팅 유닛은 상기 설명한 각 방법 및 처리를 수행한다. 예를 들면 단대단 자체 적응에 기반한 분산식 훈련 방법을 수행한다. 예를 들면, 일 실시예에서, 단대단 자체 적응에 기반한 분산식 훈련 방법은 컴퓨터 소프트웨어 프로그램으로 구현될 수 있고, 유형적으로 저장 유닛과 같 은 기계 판독 가능 매체에 포함된다. 일 실시예에서, 컴퓨터 프로그램/명령의 일부 또는 전부는 ROM 및/ 또는 통신 유닛에 의해 전자 기기에 로딩 및/또는 설치될 수 있다. 컴퓨터 프로그램이 RAM에로딩되고 컴퓨팅 유닛에 의해 수행될 경우, 상기 설명한 단대단 자체 적응에 기반한 분산식 훈련 방법의 하나 또는 복수의 단계를 수행할 수 있다. 대안적으로, 기타 실시예에서, 컴퓨팅 유닛은 기타 임의의 적 합한 방식(예를 들면, 펌웨어)으로 본 발명의 실시예에 따른 단대단 자체 적응에 기반한 분산식 훈련 방법을 수 행할 수 있도록 구성된다. 여기서 설명하는 시스템과 기술의 여러 가지 실시형태는 디지털 전자회로 시스템, 집적회로 시스템, 프로그래밍 가능 게이트 어레이(FPGA), 주문형 직접 회로(ASIC), 전용 표준 제품(ASSP), 칩상 시스템(SOC), 복합 프로그래 머블 논리 소자(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및/또는 이들의 조합에서 실현될 수 있다. 이러한 여러 가지 실시형태는 하나 또는 복수의 컴퓨터 프로그램에서 실시되는 것을 포함할 수 있고, 당해 하나 또는 복수의 컴퓨터 프로그램은 적어도 하나의 프로그래밍 가능 프로세서를 포함하는 프로그래밍 가능 시스템에서 실 행 및/또는 해석되며, 당해 프로그래밍 가능 프로세서는 전용 또는 일반 프로그래밍 가능 프로세서일 수 있으며, 저장 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장치에서 데이터와 명령을 수신할 수 있 고, 데이터와 명령을 당해 저장 시스템, 당해 적어도 하나의 입력 장치 및 당해 적어도 하나의 출력 장치에 전 송할 수 있다. 본 발명의 방법을 수행하는데 사용되는 프로그램 코드는 하나 또는 복수의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 당해 프로그램 코드는 범용 컴퓨터, 전용 컴퓨터 또는 기타 프로그래밍 가능한 데이터 처리 장 치의 프로세서 또는 제어기에 제공하여, 프로그램 코드가 프로세서 또는 제어기에 의해 수행될 경우 흐름도 및/ 또는 블록도에서 규정한 기능/조작을 실시하게 된다. 프로그램 코드는 완전히 또는 부분적으로 기계에서 수행되 고, 독립 소프트웨어 패키지로서 부분적으로 기계에서 수행하고 부분적으로 또는 완전히 원거리 기계 또는 서버 에서 수행된다. 본 발명의 콘텍스트에서, 기계 판독 가능 매체는 유형적인 매체일 수 있고, 명령 수행 시스템, 장치 또는 기기 가 사용하거나 명령 수행 시스템, 장치 또는 기기와 결합하여 사용하도록 제공하는 프로그램을 포함 또는 저장 할 수 있다. 기계 판독 가능 매체는 기계 판독 가능 신호 매체 또는 기계 판독 가능 저장 매체일 수 있다. 기계 판독 가능 매체는 전자, 자기, 광학, 전자기, 적외선 또는 반도체 시스템, 장치 및 기기, 또는 상기 내용의 임 의의 적합한 조합을 포함하나 이에 한정되지 않는다. 기계 판독 가능 저장 매체의 더 구체적인 예시는 하나 또 는 복수의 선을 기반으로 하는 전기 연결, 휴대용 컴퓨터 디스크, 하드 디스크, 랜덤 엑세스 메모리(RAM), 읽기 전용 메모리(ROM), 지울 수 있는 프로그래밍 가능한 읽기 전용 메모리(EPROM 또는 플래시 메모리), 광섬유, 시 디롬(CD-ROM), 광학 전자 기기, 자기 전자 기기, 또는 상기 내용의 임의의 적합한 조합을 포함할 수 있다. 사용자와의 인터랙션을 제공하기 위해, 여기서 설명된 시스템 및 기술은 컴퓨터에서 구현할 수 있으며, 당해 컴 퓨터는 사용자에게 정보를 디스플레이하는 디스플레이 장치(예를 들면, CRT 음극선관) 또는 LCD(액정 디스플레 이)모니터); 및 키보드와 지향 장치(예를 들면, 마우스 또는 트랙볼)를 구비하고, 사용자는 당해 키보드와 당해 지향 장치를 통해 컴퓨터에 입력을 제공할 수 있다. 기타 유형의 장치도 사용자와의 인터랙션에 사용될 수 있는 바, 예를 들면 사용자에게 제공된 피드백은 임의의 형식의 감각 피드백(예를 들면, 시각적 피드백, 청각적 피드 백 또는 촉각적 피드백)일 수 있고, 임의의 형식(음향 입력, 음성 입력 또는 촉각 입력)에 의해 사용자로부터의 입력을 수신할 수 있다. 여기서 설명한 시스템과 기술을, 백그라운드 컴포넌트를 포함하는 컴퓨팅 시스템(예를 들면 데이터 서버), 또는 미들웨어 컴포넌트를 포함하는 컴퓨팅 시스템(예를 들면, 애플리케이션 서버), 또는 프론트 엔드 컴포넌트를 포 함하는 컴퓨팅 시스템(예를 들면, 그래픽 사용자 인터페이스 또는 네트워크 브라우저를 구비한 사용자 컴퓨터에 서 실시될 수 있고, 사용자는 당해 그래픽 사용자 인터페이스 또는 당해 네트워크 브라우저를 통해 여기서 설명 한 시스템과 기술의 실시형태와 인터랙션할 수 있다), 또는 이러한 백그라운드 컴포넌트, 미들웨어 컴포넌트 또 는 프론트 엔드 컴포넌트의 임의의 조합을 포함하는 컴퓨팅 시스템에서 실시될 수 있다. 임의의 형태 또는 매체 의 디지털 데이터 통신(예를 들면, 통신 네트워크)을 통해 시스템의 컴포넌트를 서로 연결할 수 있다. 통신 네 트워크의 예시는 근거리 통신망 (LAN), 광역 통신망 (WAN) 및 인터넷을 포함한다. 컴퓨터 시스템은 클라이언트와 서버를 포함할 수 있다. 클라이언트와 서버는 일반적으로 서로 떨어져 있으며, 통신 네트워크를 통해 서로 인터랙션한다. 대응하는 컴퓨터에서 운행되고 서로 클라이언트-서버 관계를 가지는 컴퓨터 프로그램에 의해 클라이언트와 서버의 관계를 생성한다. 서버는 클라우드 서버일 수 있고, 분산식 시스 템의 서버 또는 블록 체인을 결합한 서버일 수도 있다. 이해해야 할 것은, 상기 복수 형식의 흐름에 의해, 단계를 재정렬, 추가 또는 삭제할 수 있다. 예를 들면, 본 발명에 기재한 각 단계는 병행하여 또는 순차적으로 실행할 수도 있고, 서로 다른 순서로 실행할 수도 있다. 본발명에서 개시한 기술적 수단이 원하는 결과만 구현할 수 있으면 본 발명에서는 이에 대해 한정하지 않는다. 상기 구체적인 실시 방식은 본 발명의 보호 범위를 한정하지 않는다. 본 발명이 속하는 기술 분야의 통상의 기 술자는 설계 요구 및 기타 요소에 의해 여러가지 수정, 조합, 서브 조합 및 대체가 이루어질 수 있음을 이해해 야 한다. 본 발명의 정신과 원칙 내에서 이루어진 모든 수정, 동등한 대체 및 개선은 모두 본 발명 보호 범위에 포함된다."}
{"patent_id": "10-2022-0155291", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면은 본 기술적 수단을 더 잘 이해하는데 사용되고, 본 발명을 한정하려는 것은 아니다. 도1은 본 발명에 따른 단대단 자체 적응에 기반한 분산식 훈련 방법의 흐름도 중의 하나이다. 도2는 본 발명에 따른 훈련할 모델을 분할하는 흐름도이다. 도3은 본 발명에 따른 모델의 분산식 훈련 방법의 전체 개략도이다. 도4는 본 발명에 따른 컴퓨팅 자원의 속성을 결정하는 흐름도 중의 하나이다. 도5는 본 발명에 따른 분산식 속성 정보의 카테고리의 결정 방식의 흐름도이다. 도6은 본 발명에 따른 컴퓨팅 자원의 하드웨어 토폴로지 관계의 흐름도이다. 도7은 본 발명에 따른 컴퓨팅 자원의 하드웨어 토폴로지 관계의 개략도이다. 도8은 본 발명에 따른 컴퓨팅 자원의 속성을 결정하는 흐름도 중의 하나이다. 도9는 본 발명에 따른 분산 전략을 결정하는 흐름도이다. 도10은 본 발명에 따른 분산식 훈련의 흐름도 중의 하나이다. 도11은 본 발명에 따른 분산식 훈련의 흐름도 중의 하나이다. 도12는 본 발명에 따른 분산식 훈련의 흐름도 중의 하나이다. 도13은 본 발명에 따른 보완 조치의 개략도 중의 하나이다. 도14는 본 발명에 따른 분산식 훈련의 흐름도 중의 하나이다. 도15는 본 발명에 따른 보완 조치의 개략도 중의 하나이다. 도16은 본 발명에 따른 분산식 훈련의 흐름도 중의 하나이다. 도17은 본 발명에 따른 컴퓨팅 자원 용량을 늘인 후의 조정 개략도이다. 도18은 본 발명에 따른 단대단 자체 적응에 기반한 분산식 훈련 방법의 흐름도 중의 하나이다. 도19는 본 발명에 따른 단대단 자체 적응에 기반한 분산식 훈련 장치의 개략도이다. 도20은 본 발명 실시예의 단대단 자체 적응에 기반한 분산식 훈련 방법을 구현하는 전자 기기의 블록도이다."}
