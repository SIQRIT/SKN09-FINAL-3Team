{"patent_id": "10-2022-7036600", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0156601", "출원번호": "10-2022-7036600", "발명의 명칭": "디바이스의 손 제스처 기반 제어를 위한 방법 및 시스템", "출원인": "후아웨이 테크놀러지 컴퍼니 리미티드", "발명자": "루 주웨이"}}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디바이스의 카메라에 의해 캡처된 프레임 시퀀스(sequence of frames)의 입력 프레임을 처리하여, 상기 입력 프레임에서 구별되는 해부학적 특징(distinguishing anatomical feature)의 적어도 하나의 검출된 인스턴스(instance)의 위치를 결정하는 단계;상기 구별되는 해부학적 특징의 상기 적어도 하나의 검출된 인스턴스 중 적어도 선택된 하나의 인스턴스에대해, 상기 구별되는 해부학적 특징의 선택된 하나의 인스턴스의 위치에 기반하여 가상 제스처-공간(virtualgesture-space)을 정의하는 단계 - 상기 가상 제스처-공간은 제스처 입력을 검출하기 위해 정의된 공간임 -;상기 가상 제스처-공간에서만 상기 프레임 시퀀스에서 각 프레임을 처리하여 적어도 하나의 손을 검출 및 추적하고, 상기 적어도 하나의 손을 검출 및 추적하는 것으로부터 생성된 정보를 사용하여 상기 적어도 하나의 손과연관된 제스처 클래스를 예측하는 단계; 및상기 적어도 하나의 손과 연관된, 상기 예측된 제스처 클래스를 출력하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 구별되는 해부학적 특징은 사람 얼굴인, 방법."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서,상기 구별되는 해부학적 특징의 복수의 검출된 인스턴스가 있으며, 각각의 검출된 인스턴스에 대해 하나의 가상제스처-공간이 정의되고, 각 가상 제스처-공간이 손 검출 및 추적을 수행하기 위해 처리되는, 방법."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,상기 가상 제스처-공간이 정의된 후, 후속 입력 프레임에서 상기 구별되는 해부학적 특징의 검출을 추가로 수행하지 않고, 상기 정의된 가상 제스처-공간에서 손 검출 및 추적을 수행하는 것에 의해, 적어도 하나의 후속 입력 프레임을 처리하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서,상기 적어도 하나의 손을 검출하고 추적하는 것으로부터 생성된 정보를 사용하여, 상기 적어도 하나의 손의 검출된 위치에 기반하여 상기 가상 제스처-공간을 재정의하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 적어도 하나의 손의 검출된 위치에 기반하여 상기 가상 제스처-공간이 재정의된 후, 후속 입력 프레임에서상기 구별되는 해부학적 특징의 검출을 추가로 수행하지 않고, 상기 재정의된 가상 제스처-공간에서 손 검출 및공개특허 10-2022-0156601-3-추적을 수행하는 것에 의해 적어도 하나의 후속 입력 프레임을 처리하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서,상기 적어도 하나의 손을 검출하고 추적하는 것으로부터 생성된 정보는 상기 입력 프레임에서 상기 적어도 하나의 손을 정의하는 바운딩 박스(bounding box)를 포함하고, 제스처 분류는 상기 바운딩 박스를 사용하여 수행되는, 방법."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,상기 가상 제스처-공간에서 하나 이상의 서브공간을 정의하는 단계를 더 포함하고,상기 적어도 하나의 손을 검출하고 추적하는 것으로부터 생성된 정보는 상기 적어도 하나의 손이 상기 하나 이상의 서브공간 중 하나에서 검출됨을 지시하는 정보를 포함하며,각 서브공간은 각각의 마우스 입력과 연관되는, 방법."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서,상기 가상 제스처-공간에서만 상기 프레임 시퀀스의 각 입력 프레임을 처리하여, 상기 적어도 하나의 손을 검출하고 추적하는 단계; 및상기 적어도 하나의 손을 검출하고 추적하는 것으로부터 생성된 정보를 사용하여, 상기 적어도 하나의 손과 연관된 제스처 클래스를 출력하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "장치로서,머신이 실행 가능한 명령어를 저장하는 메모리에 결합된 처리 디바이스를 포함하고,상기 명령어는 상기 처리 디바이스에 의해 실행될 때 상기 장치가:입력 프레임을 처리하여, 상기 입력 프레임에서 구별되는 해부학적 특징의 적어도 하나의 검출된 인스턴스의 위치를 결정하고;상기 구별되는 해부학적 특징의 상기 적어도 하나의 검출된 인스턴스 중 적어도 선택된 하나의 인스턴스에대해, 상기 구별되는 해부학적 특징의 선택된 하나의 인스턴스의 위치에 기반하여 가상 제스처-공간을 정의하며- 상기 가상 제스처-공간은 제스처 입력을 검출하기 위해 정의된 공간임 -;상기 가상 제스처-공간에서만 상기 프레임 시퀀스에서 각 프레임을 처리하여 적어도 하나의 손을 검출 및 추적하고; 그리고상기 적어도 하나의 손을 검출 및 추적하는 것으로부터 생성된 정보를 사용하여 상기 적어도 하나의 손과 연관된 제스처 클래스를 결정하게 하는, 장치."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 구별되는 해부학적 특징은 사람 얼굴인, 장치.공개특허 10-2022-0156601-4-청구항 12 제10항 또는 제11항에 있어서,상기 구별되는 해부학적 특징의 복수의 검출된 인스턴스가 있으며, 각각의 검출된 인스턴스에 대해 하나의 가상제스처-공간이 정의되고, 각 가상 제스처-공간이 손 검출 및 추적을 수행하기 위해 처리되는, 장치."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항 내지 제12항 중 어느 한 항에 있어서,상기 명령어는 추가로 상기 장치가,상기 가상 제스처-공간이 정의된 후, 후속 입력 프레임에서 상기 구별되는 해부학적 특징의 검출을 추가로 수행하지 않고, 상기 정의된 가상 제스처-공간에서 손 검출 및 추적을 수행하는 것에 의해, 적어도 하나의 후속 입력 프레임을 처리하게 하는, 장치."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항 내지 제13항 중 어느 한 항에 있어서,상기 명령어는 추가로 상기 장치가, 상기 적어도 하나의 손을 검출하고 추적하는 것으로부터 생성된 정보를 사용하여, 상기 적어도 하나의 손의 검출된 위치에 기반하여 상기 가상 제스처-공간을 재정의하게 하는, 장치."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 명령어는 추가로 상기 장치가,상기 적어도 하나의 손의 검출된 위치에 기반하여 상기 가상 제스처-공간이 재정의된 후, 후속 입력 프레임에서상기 구별되는 해부학적 특징의 검출을 추가로 수행하지 않고, 상기 재정의된 가상 제스처-공간에서 손 검출 및추적을 수행하는 것에 의해 적어도 하나의 후속 입력 프레임을 처리하게 하는, 장치."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항 내지 제15항 중 어느 한 항에 있어서,상기 적어도 하나의 손을 검출하고 추적하는 것으로부터 생성된 정보는 상기 입력 프레임에서 상기 적어도 하나의 손을 정의하는 바운딩 박스를 포함하고, 제스처 분류는 상기 바운딩 박스를 사용하여 수행되는, 장치."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항 내지 제16항 중 어느 한 항에 있어서,상기 명령어는 추가로 상기 장치가, 상기 가상 제스처-공간에서 하나 이상의 서브공간을 정의하게 하고,상기 적어도 하나의 손을 검출하고 추적하는 것으로부터 생성된 정보는 상기 적어도 하나의 손이 상기 하나 이상의 서브공간 중 하나에서 검출됨을 지시하는 정보를 포함하며, 각 서브공간은 각각의 마우스 입력과연관되는, 장치."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항 내지 제17항 중 어느 한 항에 있어서,상기 장치는 제스처 제어 디바이스이며, 상기 결정된 제스처 클래스는 상기 제스처 제어 디바이스의 커맨드 입력을 결정하는 데 사용되는, 장치."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "공개특허 10-2022-0156601-5-제18항에 있어서, 상기 입력 프레임을 포함하는 상기 프레임 시퀀스를 캡처하기 위한 카메라를 더 포함하는 장치."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항 또는 제19항에 있어서, 상기 제스처 제어 디바이스는:텔레비전;스마트폰;태블릿;차량 결합 디바이스;사물 인터넷 디바이스;인공 현실 디바이스; 또는가상 현실 디바이스중 하나인, 장치."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "머신이 실행 가능한 명령어가 저장된, 컴퓨터가 판독 가능한 매체로서,상기 명령어는 디바이스의 처리 디바이스에 의해 실행될 때 상기 디바이스가 제1항 내지 제9항 중 어느 한 항의방법을 수행하게 하는, 컴퓨터가 판독 가능한 매체."}
{"patent_id": "10-2022-7036600", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "머신이 실행 가능한 명령어가 저장된, 컴퓨터 프로그램으로서, 상기 명령어는 디바이스의 처리 디바이스에 의해 실행될 때 상기 디바이스가 제1항 내지 제9항 중 어느 한 항의방법을 수행하게 하는, 컴퓨터 프로그램."}
{"patent_id": "10-2022-7036600", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "디바이스의 제스처 기반 제어를 위한 방법 및 시스템이 설명된다. 입력 프레임에서 구별되는 해부학적 특징의 위 치를 결정하기 위해 입력 프레임이 처리된다. 가상 제스처-공간은 구별되는 해부학적 특징의 위치에 기반하여 정 의되며, 가상 제스처-공간은 제스처 입력을 검출하기 위해 정의된 공간이다. 입력 프레임은 가상 제스처-공간에 서만 처리되어 손을 검출하고 추적한다. 적어도 하나의 손을 검출하고 추적하여 생성된 정보를 사용하여, 적어도 하나의 손에 대한 제스처 클래스가 결정된다. 디바이스는 스마트 텔레비전, 스마트 폰, 태블릿 등일 수 있다."}
{"patent_id": "10-2022-7036600", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 손 제스처(hand gesture)를 검출(detection) 및 인식(recognition)하고, 그리고 손 제스처를 사용하 여 텔레비전이나 스마트폰과 같은 디바이스를 제어하는 것에 관한 것이다."}
{"patent_id": "10-2022-7036600", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이러한 디바이스의 카메라에 의해 캡처된 디지털 비디오의 프레임 시퀀스(sequence of frames)에서 손 제스처 (hand gesture)의 머신 비전 기반 검출(machine vision-based detection)(일반적으로 컴퓨터 비전이라고 함)를 사용하는, 디바이스(예: 스마트폰, 태블릿, 텔레비전 등)의 원격 제어는, 향상된 사용자 경험을 제공하는 데 관 심이 있었다. 디지털 비디오의 프레임 시퀀스에서 제스처 검출 및 검출을 수행하기 위한 기존 솔루션은 비디오 동작(action)의 분류(즉, 디지털 비디오 프레임 시퀀스의 다수의 프레임에 걸쳐서 검출되고 추적된 손의 움직임 분류)를 기반으로 한다. 이는 일반적으로 디지털 비디오 프레임 시퀀스에 대해 제스처 세분화(segmentation) 및 인식을 수행해야 한다. 그러나, 디지털 이미지 시퀀스에 대해 제스처 세분화 및 인식을 수행하면 일반적으로 상 당한 계산 비용이 발생하지만 상대적으로 정확도는 낮다. 디지털 비디오의 프레임 시퀀스에 대해 제스처 세분화 및 인식을 수행하는 문제 외에도, 실생활 애플리케이션에 서의 손 검출도 문제에 직면해 있다. 예를 들어, 디지털 비디오의 프레임 시퀀스에 대해 제스처 검출을 수행하 는 것은 사용자와 디바이스 사이의 거리가 멀 때(예: 사용자가 벽에 장착된 디바이스를 제어할 때), 또는 저조도(low-light) 환경(예: 야간)일 때, 일반적으로 복잡한 배경(예: 어수선할 수 있는 사용자의 생활 공간)에서 어렵다. 이러한 조건에서 디지털 비디오의 프레임 시퀀스에 대해 제스처 검출 및 인식을 수행하면 종종 거짓 양 성(false positive) 및 거짓 음성(false negative)이 허용할 수 없을 정도로 많이 발생한다. 검출 영역에 다수 의 사람(human)이 있을 때도 문제가 발생하여 제스처 검출 및 인식에 혼란이 발생할 수 있다. 디지털 비디오의 프레임 시퀀스에 대한 세분화 및 인식을 수행하기 위한 머신 러닝(machine-learning) 기반 접 근 방식도 특정 문제에 직면해 있다. 예를 들어, 만족스러운 정확도를 획득하기 위해, 제스처 검출 및 세분화를 수행하도록 구성된 제스처 검출기 및 분류기가, 일반적으로 높은 계산 리소스를 필요로 하는 대형 딥 컨볼루션 신경망을 사용하여 트레이닝될 수 있다. 또한, 더 먼 거리에서 작은 손을 검출하기 위해서, 디지털 비디오의 프 레임이 고해상도를 가져야 하므로 계산 비용이 현저하게 증가한다. 또 다른 문제는 제스처(또는 손) 검출기에 의해 생성된 바운딩 박스(bounding box)가 후속 분류기의 예측된 입력과 매칭하는 크기가 아닐 수 있다는 것이다. 따라서, 비이상적인 실제 환경에서도, 디바이스의 원격 제어를 위해 디바이스의 카메라에 의해 캡처된 디지털 비디오의 프레임 시퀀스에서 제스처의 검출 및 인식을 위한, 보다 정확하고 계산 비용이 덜 드는 머신 러닝 기 반 방법 및 시스템을 제공하는 것이 유용할 것이다. 다양한 예에서, 본 개시는 디바이스의 원격 제어를 위해 디바이스의 카메라에 의해 캡처된 디지털 비디오의 프 레임 시퀀스에서 손 제스처의 검출 및 인식을 위해 종단 간 트레이닝된(trained) 머신 러닝 기반 시스템을 설명 한다. 개시된 머신 러닝 기반 시스템은 디바이스의 원격 제어를 위해 디바이스의 카메라에 의해 캡처된 디지털 비디오의 프레임 시퀀스에서 손 제스처의 실시간 검출 및 인식을 가능하게 한다. 여기에 설명된 다양한 예시적 인 머신 러닝 기반 시스템은 장거리 및/또는 저조도 시나리오에서 기존 접근 방식보다 더 높은 정확도로 디바이 스의 원격 제어를 위해 디바이스의 카메라에 의해 캡처된 디지털 비디오의 프레임 시퀀스에서 손 제스처의 검출 및 인식을 가능하게 할 수 있다. 일부 예에서, 본 개시는 제스처 입력을 처리하기 위한 방법을 설명한다. 상기 방법은: 프레임 시퀀스에서 각각 의 프레임을 처리하여, 상기 각각의 프레임에서 구별되는 해부학적 특징(distinguishing anatomical feature)의 적어도 하나의 검출된 인스턴스(instance)의 위치를 결정하는 단계; 상기 구별되는 해부학적 특징의 상기 적어 도 하나의 검출된 인스턴스 중 적어도 선택된 하나의 인스턴스에 대해, 상기 구별되는 해부학적 특징의 선택된 하나의 인스턴스의 위치에 기반하여 가상 제스처-공간(virtual gesture-space)을 정의하는 단계 - 상기 가상 제 스처-공간은 제스처 입력을 검출하기 위해 정의된 공간임 -; 상기 가상 제스처-공간에서만 상기 프레임 시퀀스 에서 각 프레임을 처리하여, 적어도 하나의 손을 검출하고, 상기 적어도 하나의 손을 검출하는 것으로부터 정보 를 생성하며, 상기 적어도 하나의 손을 검출하는 것으로부터 생성된 정보를 사용하여, 상기 적어도 하나의 손과 연관된 제스처 클래스를 예측하는 단계; 및 상기 적어도 하나의 손과 연관된, 상기 예측된 제스처 클래스에 대 응하는 커맨드(command) 입력을 출력하는 단계를 포함한다. 위의 예 중 어느 하나에서, 상기 구별되는 해부학적 특징은 사람(human) 얼굴일 수 있다. 위의 예 중 어느 하나에서, 상기 구별되는 해부학적 특징의 복수의 검출된 인스턴스가 있을 수 있고, 각각의 검출된 인스턴스에 대해 하나의 가상 제스처-공간이 정의될 수 있으며, 각각의 가상 제스처-공간이 손 검출 및 추적을 수행하기 위해 처리될 수 있다. 위의 예 중 어느 하나에서, 상기 방법은 또한 상기 가상 제스처-공간이 정의된 후, 후속 입력 프레임에서 상기 구별되는 해부학적 특징의 검출을 추가로 수행하지 않고, 상기 정의된 가상 제스처-공간에서 손 검출 및 추적을 수행하는 것에 의해, 적어도 하나의 후속 입력 프레임을 처리하는 단계를 포함할 수 있다. 위의 예 중 어느 하나에서, 상기 방법은 또한 상기 적어도 하나의 손을 검출하고 추적하는 것으로부터 생성된 정보를 사용하여, 상기 적어도 하나의 손의 검출된 위치에 기반하여 상기 가상 제스처-공간을 재정의하는 단계 를 포함할 수 있다. 위의 예 중 어느 하나에서, 상기 방법은 또한 상기 적어도 하나의 손의 검출된 위치에 기반하여 상기 가상 제스 처-공간이 재정의된 후, 후속 입력 프레임에서 상기 구별되는 해부학적 특징의 검출을 추가로 수행하지 않고, 상기 재정의된 가상 제스처-공간에서 손 검출 및 추적을 수행하는 것에 의해 적어도 하나의 후속 입력 프레임을 처리하는 단계를 포함할 수 있다.위의 예 중 어느 하나에서, 상기 적어도 하나의 손을 검출하고 추적하는 것으로부터 생성된 정보는 상기 입력 프레임에서 상기 적어도 하나의 손을 정의하는 바운딩 박스(bounding box)를 포함할 수 있으며, 제스처 분류는 상기 바운딩 박스를 사용하여 수행될 수 있다. 위의 예 중 어느 하나에서, 상기 방법은 또한 상기 가상 제스처-공간에서 하나 이상의 서브공간을 정의하는 단 계를 포함할 수 있으며, 상기 적어도 하나의 손을 검출하고 추적하는 것으로부터 생성된 정보는 상기 적어도 하 나의 손이 상기 하나 이상의 서브공간 중 하나에서 검출됨을 지시하는 정보를 포함할 수 있고, 각 서브공간은 각각의 마우스 입력과 연관될 수 있다. 일부 예에서, 본 개시는 머신 실행 가능한 명령어(machine-executable instruction)를 저장하는 메모리에 결합 된 처리 디바이스를 포함하는 장치를 설명한다. 상기 명령어는 상기 처리 디바이스에 의해 실행될 때 상기 장치 가 위에서 설명된 방법 중 하나를 수행하게 한다. 위의 예 중 어느 하나에서, 상기 장치는 제스처 제어 디바이스(gesture-controlled device)일 수 있고, 결정된 제스처 클래스는 상기 제스처 제어 디바이스에 대한 커맨드 입력을 결정하는 데 사용될 수 있다. 위의 예 중 어느 하나에서, 상기 장치는 상기 입력 프레임을 캡처하기 위한 카메라를 포함할 수 있다. 위의 예 중 어느 하나에서, 상기 제스처 제어 디바이스는 텔레비전; 스마트폰; 태블릿; 차량 결합 디바이스 (vehicle-coupled device); 사물 인터넷 디바이스; 인공 현실 디바이스; 또는 가상 현실 디바이스 중 하나일 수 있다. 일부 예에서, 본 개시는 머신 실행 가능한 명령어가 저장된 컴퓨터가 판독 가능한 매체를 설명한다. 장치의 처 리 디바이스에 의해 실행될 때, 상기 명령어는 상기 장치가 위에서 설명된 방법 중 하나를 수행하게 한다. 여기에 개시된 예는 사용자의 손을 검출하는 데 사용되는 가상 제스처-공간을 정의함으로써 제스처 입력의 더 정확하거나 및/또는 효율적인 검출을 가능하게 할 수 있다. 예를 들어, 사람 얼굴의 검출은 일반적으로 더 빠르 거나 및/또는 더 정확할 수 있고, 검출된 얼굴은 가상 제스처-공간의 기초(basis)가 될 수 있다. 일부 예에서, 검출된 얼굴은 가상 마우스의 제스처 기반 제어의 구현을 위한 기초가 될 수 있다. 이것은 디바이스의 제스처 기반 제어를 위한 직관적인 방법을 제공할 수 있다."}
{"patent_id": "10-2022-7036600", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다양한 예에서, 본 개시는 디바이스의 제스처 기반 제어를 가능하게 하는 방법 및 시스템을 설명한다. 예를 들 어, 제스처 제어 디바이스는 다른 가능성 중에서 텔레비전(예: 스마트 TV), 모바일 통신 디바이스(예: 스마트폰), 태블릿 디바이스, 데스크탑 디바이스, 차량 기반 디바이스(예: 대시보드 디바이스) 또는 스마트 스 피커일 수 있다. 여기에 설명된 제스처 기반 제어는 디스플레이 출력이 있거나 없는 사용자 인터페이스를 포함 하는 제스처 제어 디바이스에 의해 제공되는 임의의 사용자 인터페이스와의 사용자 상호작용을 가능하게 하는 데 사용될 수 있다. 본 개시의 예는 또한 다른 가능성 중에서 증강 현실(augmented reality, AR), 가상 현실 (virtual reality, VR), 또는 비디오 게임 애플리케이션을 위해 구현될 수 있다. 단순화를 위해, 본 개시는 디스플레이 출력을 갖는 제스처 제어 디바이스(예: 스마트 TV, 스마트폰 또는 태블릿)의 콘텍스트에서의 예를 설명하고 비디오의 재생과 상호 작용하기 위한 제스처 기반 제어를 설명한다. 그러나, 본 출원은 이러한 실시예에 제한되지 않고 다양한 애플리케이션에서 다양한 디바이스의 제스처 기반 제 어에 사용될 수 있음을 이해해야 한다. 도 1은 제스처 제어 디바이스와 상호작용하는 사용자의 예를 도시한다. 이 단순화된 도면에서, 제스처 제어 디바이스는 프레임 시퀀스가 제스처 입력을 포함하는 시야(field-of-view, FOV)에서 프레임 시퀀 스(예: 디지털 이미지)를 캡처하는 카메라를 포함한다. FOV는 이하에서 추가로 논의되는 바와 같이 사 용자의 적어도 일부, 특히 사용자의 얼굴 및 손을 포함할 수 있다. 특히, 실제 사용(예: 실험실 설정을 벗어남)에서 FOV는 일반적으로 사용자 이상을 포함한다. 예를 들어, FOV는 또한 다른 객체, 배경 장면, 또는 가능한 다른 사람을 포함할 수 있다. 제스처 제어 디바이스는 카메라 대신에, 사용자(1 0)로부터 제스처 입력을 감지할(sensing) 수 있는 다른 센서, 예를 들어 이미지 캡처 디바이스/센서의 FOV 에서 제스처 입력을 포함하는 프레임 시퀀스(예: 적외선 이미지 센서)를 캡처하는 임의의 이미지 캡처 디바이스 /센서(예: 적외선 이미지 센서)를 가질 수 있다. 제스처 제어 디바이스는 또한 비디오와 같은 출력을 제공 하는 디스플레이를 포함한다. 제스처 제어 디바이스는 도 1에 도시된 실시예에서의 카메라를 포 함하지만, 다른 실시예에서, 카메라는 제스처 제어 디바이스와 통신하는 주변 디바이스일 수 있다. 도 2는 제스처 제어 디바이스의 일부 컴포넌트를 도시하는 블록도이다. 제스처 제어 디바이스의 예시 적인 실시예가 도시되고 아래에서 논의되지만, 다른 실시예는 도시된 것과 상이한 컴포넌트를 포함할 수 있는 본 명세서에 개시된 예를 구현하는 데 사용될 수 있다. 도 2는 각 컴포넌트의 단일 인스턴스를 도시하지만, 도 시된 각 컴포넌트의 다수의 인스턴스가 있을 수 있다. 제스처 제어 디바이스는 프로세서, 마이크로프로세서, ASIC(application-specific integrated circuit), FPGA(field-programmable gate array), 전용 논리 회로, 전용 인공 지능 프로세서 유닛 또는 이들의 조합과 같 은 하나 이상의 처리 디바이스를 포함한다. 제스처 제어 디바이스는 또한 카메라와 같은 입력 디바이스 및 디스플레이와 같은 출력 디바이스를 인터페이스하는 하나 이상의 입력/출력(input/output, I/O) 인터페이스를 포함한다. 제스처 제어 디바이스는 다른 입력 디바이스(예: 버튼, 마이크로폰, 터 치스크린, 키보드 등) 및 기타 출력 디바이스(예: 스피커, 진동 유닛 등)를 포함할 수 있다. 카메라(또는다른 입력 디바이스)는 제스처 입력을 포함하는 프레임 시퀀스를 캡처하기 위한 능력을 가질 수 있다. 캡처된 프레임은 I/O 인터페이스(들)에 의해 저장(예: 내부 버퍼링)을 위해 메모리(들)에 제공되고, 실시간 또는 거의 실시간(예: 10ms 이내)으로 처리되도록 처리 디바이스(들)에 제공될 수 있다. 제스처 제어 디바이스는 네트워크(예: 인트라넷, 인터넷, P2P 네트워크, WAN 및/또는 LAN) 또는 다른 노드 와의 유선 또는 무선 통신을 위한 하나 이상의 선택적 네트워크 인터페이스를 포함할 수 있다. 네트워크 인터페이스(들)는 인트라 네트워크 및/또는 인터 네트워크 통신을 위한 유선 링크(예: 이더넷 케이블) 및/ 또는 무선 링크(예: 하나 이상의 안테나)를 포함할 수 있다. 제스처 제어 디바이스는 하나 이상의 메모리를 포함하며, 이는 휘발성 또는 비휘발성 메모리(예: 플 래시 메모리, RAM(Random Access Memory) 및/또는 읽기 전용 메모리(read-only memory, ROM))를 포함할 수 있 다. 비일시적 메모리(들)는 예를 들어 본 개시에 설명된 예를 수행하기 위해 처리 디바이스(들)에 의 한 실행을 위한 명령어를 저장할 수 있다. 예를 들어, 메모리(들)는 적응적 제스처 감지 시스템(adaptive gesture-sensing system)을 실행하기 위한 명령어를 포함할 수 있다. 메모리(들)는 운영 체제 및 다 른 애플리케이션/기능을 구현하기 위한 것과 같은 다른 소프트웨어 명령어를 포함할 수 있다. 메모리(들) 는 또한 디스플레이를 통해 출력으로 제공될 수 있는 비디오 콘텐츠 파일과 같은 데이터를 포함할 수 있다. 일부 예에서, 제스처 제어 디바이스는 또한 솔리드 스테이트 드라이브, 하드 디스크 드라이브, 자기 디스 크 드라이브 및/또는 광 디스크 드라이브와 같은 하나 이상의 전자 저장 유닛(도시되지 않음)을 포함할 수 있다. 일부 예에서, 하나 이상의 데이터 세트 및/또는 모듈은 외부 메모리(예: 제스처 제어 디바이스와 유 선 또는 무선 통신하는 외부 드라이브)에 의해 제공되거나, 컴퓨터가 판독 가능한 일시적 또는 비일시적 매체에 의해 제공될 수 있다. 컴퓨터가 판독 가능한 비일시적 매체의 예는 RAM, ROM, EPROM(erasable programmable ROM), EEPROM(electrically erasable programmable ROM), 플래시 메모리, CD-ROM 또는 기타 휴대용 메모리 스 토리지를 포함한다. 제스처 제어 디바이스의 컴포넌트는 예를 들어 버스를 통해 서로 통신할 수 있다. 본 개시의 이해를 돕기 위해, 제스처에 대한 논의가 먼저 제공된다. 본 개시에서 손 제스처는 일반적으로 제스 처 제어 디바이스가 특정 커맨드 입력으로 인식할 수 있는 별개의 손 모양(hand shape)으로 정의된다. 손 제스처는 모양과 움직임이 상이할 수 있다. 예를 들어, 손 제스처는 제스처 제어 디바이스에 의해 도 3a 내지 도 3h에 도시된 클래스 중 하나에 속하는 것으로 인식될 수 있다. 카메라에 의해 캡처된 프레임 시퀀 스(예: 이미지)에 존재하는 도 3a 내지 도 3h에 도시된 바와 같은 손 제스처가, 제스처 입력으로 지칭된다. 도 3a는 \"펼친 손(open hand)\" 제스처를 도시하고; 도 3b는 \"주먹(fist)\"(또는 \"닫힌 손(closed hand)\") 제스처를 도시하며; 도 3c는 \"핀치 열림(pinch open)\" 제스처를 도시하고; 도 3d는 \"핀치 닫힘(pinch closed)\" 제스처를 도시하며; 도 3e는 \"음소거(mute)\"(또는 \"침묵(silence)\") 제스처를 도시하고; 도 3f는 \"좋아요(like)\"(또는 \"승인(approve)\") 제스처를 도시하며; 도 3g는 \"기타\"(또는 \"다음\") 제스처(4 2)를 도시하고; 도 3h는 \"터치\"(또는 \"선택\") 제스처를 도시한다. 다른 제스처 클래스는 제스처 제어 디바 이스에 의해 인식될 수 있다. 이러한 제스처 클래스에 기반하여, 손 제스처는 정적 제스처와 동적 제스처로 분류될 수 있다. 정적 제스처는 단일 제스처 클래스로 정의되며, 적어도 정의된 기간(period of time)(예: 1초) 동안 또는 카메라에 의해 캡처된 프레임 시퀀스에서 정의된 수 이상의 연속 프레임(예: 100개 프레임) 동안 일반적으로 고정된 위치(예: 약간의 오차 범위를 허용하는 정의된 영역 내)에서 유지된다. 예를 들어, 정적 펼친 손 제스처는 제스처 제 어 디바이스(예: 적응적 제스처 감지 시스템)에 의해 인식될 수 있고, 비디오 재생의 콘텍스트에서 일시 중지 커맨드 입력으로 해석될 수 있다. 정적 주먹 제스처는 제스처 제어 디바이스에 의해 인식될 수 있고, 비디오 재생의 콘텍스트에서 중지 커맨드 입력으로 해석될 수 있다. 동적 제스처는 하나 이상의 제스처 클래스, 위치 및/또는 움직임의 조합으로 정의된다. 예를 들어, 동적 제스처 는 시간이 지남에 따라 위치가 변하는(예: 카메라에 의해 캡처된 프레임 시퀀스에 걸쳐 상이한 위치에서 검출됨) 단일 제스처 클래스일 수 있다. 위치가 변하는 펼친 손 제스처는 제스처 제어 디바이스(예: 적응적 제스처 감지 시스템)에 의해 인식되어, 디스플레이된 아이콘과 같은 인터페이스 객체를 드래그 (drag)하거나 이동하는 명령어로 해석될 수 있다. 도 4a는 제스처 클래스의 조합일 수 있는 다른 유형의 동적 제스처를 도시한다. 도 4a에서, 동적 제스처는 터치 제스처에 뒤따르는 주먹 제스처의 조합을 포함한다. 이 동적 제스처는 제스처 제어 디바이스(예:제스처 제어 디바이스에서 실행되는 적응적 제스처 감지 시스템)에 의해 인식되고, 마우스 디바이스 를 사용하여 인터페이스 객체를 선택하고 클릭하는 것과 동등한 커맨드 입력으로 해석될 수 있다. 다른 예에서, 핀치 열림 제스처에 뒤따르는 핀치 닫힘 제스처가 함께 \"핀칭(pinching)\" 동적 제스처로서 인식될 수 있고, 이는 제스처 제어 디바이스에 의해 인식될 수 있고 축소(zoom out) 커맨드 입력으로 해석될 수 있다. 더 복잡한 동적 제스처는 제스처 클래스의 조합과 위치 변화를 모두 포함할 수 있다. 예를 들어, 도 4a에서, 터 치 제스처가 시간이 지남에 따라 위치가 변하는 것으로 검출되고(예: 카메라 디바이스에 의해 캡처된 프레임 시퀀스의 상이한 위치에서 검출됨) 주먹 제스처가 뒤따르면, 제스처 제어 디바이스(예: 제스처 제어 디바이스에서 실행되는 적응적 제스처 감지 시스템)은 복잡한 동적 제스처를 주먹 제스처가 검출될 때 클릭 커맨드가 뒤따르는 터치 제스처의 위치 변화를 미러링하는 방식으로 디스플레이된 커서 (cursor)를 이동하는 커맨드 입력으로 해석할 수 있다. 다른 예에서, 핀치 열림 제스처에 뒤따르는 핀치 닫힘 제스처, 핀치 닫힘 제스처의 위치 변화, 그 리고 다시 핀치 열림 제스처가 뒤따르는 것은 함께, 제스처 제어 디바이스(예: 제스처 제어 디바이스 에서 실행되는 적응적 제스처 감지 시스템)에 의해 동적 \"핀치-드래그-릴리스(pinch-drag-release)\" 제스처로서 인식될 수 있다. 위치 변화를 포함하는 동적 제스처는 특정 위치 변화에 따라 상이한 입력으로 해석 될 수 있다는 점에 유의해야 한다. 예를 들어, 도 4b에 도시된 바와 같이 핀치 닫힘 제스처의 위치의 수직 변화(또는 수직 \"드래그\")을 갖는 핀치-드래그-릴리스 제스처는, 비디오 재생의 콘텍스트에서 볼륨을 변경 하기 위한 커맨드 입력으로 해석될 수 있다. 반면, 도 4c에 도시된 바와 같이 핀치 닫힘 제스처의 위치의 수평 변화를 갖는 핀치-드래그-릴리스 제스처는, 비디오 재생의 콘텍스트에서 비디오에서 앞 또는 뒤로 이 동하기 위한 커맨드 입력으로 해석될 수 있다. 이러한 핀치-드래그-릴리스 동적 제스처는 사용자가 제스처 제어 디바이스와 상호작용하기 위한 직관적이고 편리한 방법을 제공할 수 있고, 또한 제스처 입력이 제스처 제 어 디바이스(예: 제스처 제어 디바이스에서 실행되는 적응적 제스처 감지 시스템)에 의해 비교 적 높은 정확도로 검출되고 인식되게 할 수 있다. 특히, 핀치-드래그-릴리스 동적 제스처는 동적 제스처를 정적 제스처 컴포넌트로 분해하는 것(예: 핀치 열림 제스처, 이어서 핀치 닫힘 제스처, 이어서 다른 핀치 열 림 제스처)에 의해 검출 및 인식될 수 있다. 손 제스처 인식을 위한 일부 기존의 기존 컴퓨터 비전 기술은 카메라에 의해 캡처된 프레임 시퀀스(예: 디 지털 이미지)에서 손 모양 및 위치를 기반으로 손 검출, 손 모양 분류 및 제스처 인식을 수행한다. 제스처 세분 화 및 인식은 일반적으로 계산 비용이 많이 든다. 추가로, 프레임 시퀀스가 제어되지 않고 복잡한 환경(예: 사 용자가 디바이스에서 저조도 환경에서 멀리 떨어져 있을 때 또는 FOV에 다수의 사람이 있을 때 어수선한 배경을 가짐)에서 프레임 시퀀스가 제스처 제어 디바이스의 카메라에 의해 캡처될 때, 손 제스처(정적이든 동적이든)를 검출하고 인식하기 위해 카메라에 의해 캡처된 프레임 시퀀스를 처리하는 것은 종종 어렵다. 다양한 예에서, 본 개시는 제스처 제어 디바이스의 카메라에 의해 캡처된 프레임 시퀀스에서 더 정확하고 효율 적인 제스처 검출 및 인식을 가능하게 하는 솔루션을 설명한다. 일부 예에서, 본 개시는 제스처 검출을 위해 처 리될 카메라에 의해 캡처된 프레임 시퀀스의 각 프레임에서 영역(area)을 줄이기 위해, 가상 제스처-공간 (virtual gesture-space)을 사용하는 적응적 제스처 감지 시스템을 설명한다. 일부 예에서, 본 개시는 또한 동 적 제스처를 인식하기 위한 (모션 기반 대신에) 상태 기반 접근 방식을 설명한다. 본 개시는 추가적인 측면들 및 특징들을 포함한다는 것이 이해될 것이다. 본 개시는 프레임 시퀀스에서 손 제스처를 검출하기 위해 카메라에 의해 캡처된 프레임 시퀀스의 각 프레임을 처리하기 위해, 적어도 초기에 사용자의 얼굴을 둘러싸는 공간으로 정의된 가상 제스처-공간의 사용을 설명한다. 가상 제스처-공간은 카메라에 의해 캡처된 FOV보다 작아야 한다. 가상 제스처-공간 내에서 검출되고 인식된 손 제스처(예: 제스처 입력)만 유효한 손 제스처(예: 제스처 입력)로 간주될 수 있다. 가상 제 스처-공간을 사용하면 (예: 특히 복잡한 배경에서의) 프레임 시퀀스에서 손 제스처의 검출의 거짓 양성(false positive)을 줄일 수 있고, 손 제스처를 특정 사용자와 더 쉽게 연관시킬 수 있으며, 손 제스처(예: 제스처 입 력)를 검출하고 인식하기 위해 프레임 시퀀스를 보다 효율적으로 처리할 수 있다. 도 5는 적응적 제스처 감지 시스템의 일부 예시적인 서브시스템을 도시하는 블록도이다. 이 예에서, 적응 적 제스처 감지 시스템은 가상 제스처-공간 서브시스템 및 제스처 파싱(parsing) 서브시스템을 사용하여 구현될 수 있다. 다음 예에서, 적응적 제스처 감지 시스템은 두 서브시스템(310, 320)을 모두 포 함하거나, 두 서브시스템(310, 320)의 기능을 제공하는 것으로 설명될 것이다. 그러나, 다른 예에서, 적응적 제스처 감지 시스템은 서브시스템(310, 320) 중 하나만을 포함(또는 그 기능을 제공)할 수 있다. 예를 들어, 적응적 제스처 감지 시스템은 (예: 가상 제스처-공간 서브시스템을 사용하여) 가상 제스처-공간 내에 있는 제스처 제어 디바이스의 카메라에 의해 캡처된 프레임 시퀀스에서 손 제스처의 검출 및 가상 제 스처-공간의 적응 생성만을 제공할 수 있으며, 제스처 인식 및 파싱은 (예: 임의의 적절한 기존 제스처 인식 기 술을 사용하여) 제스처 제어 디바이스의 다른 컴포넌트에 의해 수행될 수 있다. 다른 예에서, 적응적 제스 처 감지 시스템은 (예: 제스처 파싱 서브시스템을 사용하여) 다수의 사용자의 관리 및 제스처 인식만 을 제공할 수 있으며, 제스처 검출은 (예: 적절한 기존 제스처 검출 기술 사용하여) 제스처 제어 디바이스(10 0)의 다른 컴포넌트에 의해 수행될 수 있다. 일부 예에서, 적응적 제스처 감지 시스템은 별개의 서브시스템(310, 320)을 포함하지 않을 수 있다. 대신 에, 서브시스템(310, 320)의 서브블록이 적응적 제스처 감지 시스템 자체의 서브블록으로 간주될 수 있다. 따라서, 별개의 서브시스템(310, 320)을 사용하는 적응적 제스처 감지 시스템의 구현은 선택적이다. 적응적 제스처 감지 시스템은 얼굴 검출 및 추적 서브시스템, 가상 제스처-공간 생성 서브시스템 , 손 검출 및 추적 서브시스템, 제스처 인식 서브시스템, 및 사용자 리스트를 포함한다. 얼굴 검출 및 추적 서브시스템, 가상 제스처-공간 생성 서브시스템, 및 손 검출 및 추적 서브시스템 은 가상 제스처-공간 서브시스템의 일부일 수 있고; 제스처 인식 서브시스템 및 사용자 리스트 는 제스처 파싱 서브시스템의 일부일 수 있다. 일부 예에서, 얼굴 검출 및 추적 서브시스템 대신에 또는 이에 추가하여, 다른 서브시스템(도시되지 않 음)이 카메라에 의해 캡처된 프레임 시퀀스에서 상이한 해부학적 특징(예: 전체 인체 또는 사람의 몸통)의 검출 및 추적을 위해 사용될 수 있다. 아래에서 추가로 논의되는 바와 같이, 가상 제스처-공간을 생성하기 위한 기초로서 사람의 얼굴 대신에 또는 그에 추가하여 다른 해부학적 특징이 사용될 수 있다. 단순화를 위해, 본 개 시는 카메라에 의해 캡처된 프레임 시퀀스에서 얼굴 검출 및 추적의 사용에 초점을 맞출 것이지만, 이것이 제한하려는 의도가 아님을 이해해야 한다. 카메라에 의해 캡처된 프레임 시퀀스의 프레임은 적응적 제스처 감지 시스템에 대한 입력 프레임으 로 수신된다. 얼굴 검출 및 추적 서브시스템은 입력 프레임에 대해 얼굴 검출을 수행한다. 얼굴 검출 및 추적 서브시스템은 임의의 적절한 얼굴 검출 기술을 사용하여, 입력 프레임에서 얼굴을 검출하고 검출된 얼굴에 대한 바운딩 박스를 생성할 수 있다. 바운딩 박스는 입력 프레임에서 검출된 얼굴을 중심으로 둘러싸는 2차원(two-dimensional, 2D) 또는 3차원(three-dimensional, 3D) 박스일 수 있다. 입력 프레임에서 검출된 얼굴에 대해 생성된 바운딩 박스는 가상 제스처-공간 생성 서브시스템에 의해 가 상 제스처-공간을 정의하는 데 사용된다. 본 개시에서, 가상 제스처-공간(또는 간단히 제스처-공간)은 입력 프 레임에 정의되는 2차원 또는 3차원 공간을 의미하며, 손 제스처(예: 제스처 입력)가 검출될 수 있는 사용자(1 0)의 실생활 환경에서의 가상 공간에 매핑된다. 달리 말하면, 사용자는 제스처 제어 디바이스에 커맨 드 입력을 제공하기 위해, 가상으로 정의된 2D 또는 3D 가상 제스처-공간 내에서 손 제스처를 만들 수 있다. 가 상 제스처-공간 외부에서 수행되는 제스처는 검출되지 않을 수 있으며, 제스처 제어 디바이스에 의해 커맨 드 입력으로 인식되지 않을 수 있다. 가상 제스처-공간의 차원은 얼굴의 바운딩 박스의 차원과 매칭하거나 매칭 하지 않을 수 있다(예: 얼굴의 바운딩 박스는 2D일 수 있고 가상 제스처-공간은 3D일 수 있음). 가상 제스처-공간 생성 서브시스템에 의해 정의된 가상 제스처-공간은 손 검출 및 추적 서브시스템에 의해, 카메라에 의해 캡처된 프레임 시퀀스에서 손 검출 및 추적을 수행하는 데 사용된다. 특히, 손 검출 및 추 적 서브시스템은 프레임 시퀀스에서 입력 프레임 및 각 후속 프레임 내에서 정의된 가상 제스처-공간만을 분석하여, 프레임 시퀀스에서 손을 검출하고 손을 추적할 수 있다. 손 검출 및 추적 서브시스템은 사용하 여, 입력 프레임에서 손을 검출하고, 검출된 손에 대한 2D 또는 3D 바운딩 박스를 정의할 수 있다. 일부 예에서, 얼굴 검출 및 추적 서브시스템은 얼굴 검출을 수행하도록 구성된 트레이닝된 신경망을 포함 할 수 있다. 유사하게, 손 검출 및 추적 서브시스템은 손 검출을 수행하도록 구성된 다른 트레이닝된 신경 망을 포함할 수 있다. 예를 들어, 얼굴 또는 손 검출을 위해 구성된 적절한 트레이닝된 신경망은, ResNet(residual neural network)34(예: 2016년, 컴퓨터 비전 및 패턴 인식에 관한 IEEE 회의의 절차에서, He, Kaiming 등이 \"이미지 인식을 위한 심층 잔여 학습\"에서 설명함)와 같은 ResNet 아키텍처에 기반하여 YoloV3(예: 2018년, arXiv preprint arXiv:1804.02767에서, Redmon 등이 \"Yolov3: 점진적 개선(An incremental Improvement)\"에서 설명함)를 사용하는 것과 같은 트레이닝된 객체 검출기일 수 있다. 얼굴 또는 손 검출을 위 해 구성된 적절한 트레이닝된 신경망의 다른 예는, MobileNetV2(예: 2018년, 컴퓨터 비전 및 패턴 인식에 관한IEEE 회의의 절차에서, Sandler 등이 \"Mobilenetv2: 반전된 잔차 및 선형 병목현상\"에서 설명함)과 같은 컨볼루 션 신경망(convolutional neural network, CNN)에 기반하여 multibox SSD(예: 2016년 Springer, Cham의 컴퓨터 비전에 대한 유럽 회의에서 Liu 등이 \"Ssd: 단일 샷 멀티박스 검출기(Single shot multibox detector)\"에서 설 명함)와 같은 트레이닝된 단일 샷 검출기(single shot detector, SSD)일 수 있다. 얼굴 및 손 추적은 Lucas- Kanade 광학 플로 기술(1981년 이미징 이해 워크셥의 진행에서 Lucas 등이 \"스테레오 비전으로의 적용을 가지는 반복적 이미지 등록 기술\"에서 설명함)을 사용하여 각각, 얼굴 검출 및 추적 서브시스템 및 손 검출 및 추 적 서브시스템에 의해 수행될 수 있다. 검출된 손에 대해 정의된 바운딩 박스는 제스처 인식 서브시스템에 의해 검출된 손의 모양의 식별 및 제스 처 클래스로의 분류를 수행하는 데 사용된다. 제스처 인식 서브시스템은 임의의 적절한 분류 기술을 사용 하여, 검출된 손의 모양을 특정 제스처 클래스로 분류할 수 있다. 예를 들어, 제스처 인식 서브시스템은 제스처 클래스의 미리 정의된 세트에 따라 제스처를 분류하도록 트레이닝된 신경망(예: CNN)을 포함할 수 있다. 신경망은 알려진 머신 러닝 알고리즘을 사용하여 신경망의 파라미터(예: 가중치)를 학습하도록 트레이닝되었다. 트레이닝된 신경망은 검출된 손 제스처에 대한 바운딩 박스를 수신하고, 바운딩 박스에 대응하는 제스처 클래스 의 미리 정의된 세트로부터 특정 제스처 클래스를 예측한다. 제스처 인식 서브시스템에 의해 예측된 제스 처 클래스는 적응적 제스처 감지 시스템으로부터 (예: 레이블(label)로서) 출력될 수 있다. 제스처 제어 디바이스의 소프트웨어 애플리케이션(예: 운영 체제)은 적응된 제스처 감지 시스템에 의 해 출력된 제스처 클래스를 커맨드 입력으로 변환할(translate) 수 있다. 제스처 클래스를 커맨드 입력으로 변 환하는 것은 애플리케이션에 따라 다를 수 있다. 예를 들어, 주어진 제스처 클래스는 제1 애플리케이션이 활성 화될(active) 때 제1 커맨드 입력으로 변환될 수 있지만, 제2 애플리케이션이 활성화될 때 제2 커맨드 입력으로 변환될 수 있다(또는 유효하지 않은 것으로 간주될 수 있음). 일부 예에서, 적응적 제스처 감지 시스템은 주 사용자(primary user)를 추적하기 위해 사용자 리스트(32 4)를 저장 및 유지한다. 예를 들어, 카메라의 FOV에 다수의 사람이 있을 수 있다. 따라서, 얼굴 검출 및 추적 서브시스템은 카메라에 의해 FOV에서 캡처된 프레임 시퀀스에서 다수의 사람 얼굴을 검 출하고 추적할 수 있다. 검출된 각각의 얼굴은 제스처 제어 디바이스에 입력을 제공할 수 있는 잠재적 사 용자인 사람에 속할 수 있다. 따라서, 검출된 사람이 현재 인식된 손 제스처(예: 제스처 입력)를 제공하지 않더 라도 검출된 각각의 사람은 사용자(또는 잠재적 사용자)로 간주될 수 있다. 사용자 리스트는 검출된 모든 사용자를 추적하고 일부 미리 정의된 기준(예: 사용자의 크기, 제스처 제어 디바이스로부터 사용자의 거리, 사용자의 시선이 제스처 제어 디바이스를 향하는지 여부에 기반하여)에 따라 검출된 사용자의 순위 를 매긴다. 사용자 리스트에서 가장 높은 순위의 사용자가 주 사용자로 간주될 수 있다. 주 사용자와 연관 된 프레임 시퀀스에서의 손 제스처(예: 제스처 입력)는 검출된 다른 사용자와 연관된 프레임 시퀀스에서 검출된 다른 손 제스처(예: 제스처 입력)보다 우선순위가 높을 수 있다. 일부 예에서, 승인되거나 사전 등록된 사용자 만이 사용자 리스트에 포함될 수 있다. 예를 들어, 사용자 프로필은 승인되거나 사전 등록된 사용자와 연 관될 수 있고, 사용자 프로필은 승인되거나 사전 등록된 사용자가 (예: 적절한 얼굴 인식 기술 사용하여) 제스 처 제어 디바이스에 의해 식별되게 할 수 있는 데이터(예: 생체 데이터)를 포함할 수 있다. 이러한 승인 또는 사전 등록된 사용자의 얼굴 인식은 적응적 제스처 감지 시스템 또는 제스처 제어 디바이스의 별 도의 얼굴 인식 시스템에 의해 수행될 수 있다. 승인되거나 또는 사전 등록된 사용자만을 포함하도록 사용자 리 스트를 제한하는 것에 의해, 디바이스의 승인되지 않은 제스처 기반 제어가 회피될 수 있다. 추가적 으로, 제스처 입력의 오검출(false positive detection)이 감소될 수 있다. 적응적 제스처 감지 시스템이 상이한 서브블록(또는 서브시스템)을 갖는 것으로 예시되어 있지만, 이것이 제한하려는 의도가 아님을 이해해야 한다. 예를 들어, 적응적 제스처 감지 시스템은 더 많거나 더 적은 수 의 서브블록(또는 서브시스템)을 사용하여 구현될 수 있거나, 임의의 서브블록(또는 서브시스템)을 필요로 하지 않을 수 있다. 또한, 특정 서브블록(또는 서브시스템)에 의해 수행되는 것으로 여기에서 설명된 기능은 대신에 다른 서브블록(또는 서브시스템)에 의해 수행될 수 있다. 일반적으로, 적응적 제스처 감지 시스템의 기능은 다양한 적절한 방식으로 구현될 수 있고 본 개시의 범위 내에서 유지될 수 있다. 이제 적응적 제스처 감지 시스템의 작동(operation) 예를 설명한다. 도 6은 예를 들어 가상 제스처-공간 서브시스템(및 서브시스템(312, 314, 316))을 사용하는 적응적 제스처 감지 시스템에 의해 수행될 수 있는 예시적인 방법을 도시하는 흐름도이다. 방법은 제스처 제어디바이스의 처리 디바이스에 의해 실행되는 소프트웨어의 루틴 또는 서브루틴에 의해 수행될 수 있다. 이러한 루틴 또는 서브루틴을 수행하기 위한 소프트웨어의 코딩은 본 개시와 관련하여 당업자의 범위 내 에 충분히 있다. 방법은 도시 및 설명된 추가 또는 더 적은 단계 또는 동작을 포함할 수 있으며, 상이한 순서로 수행될 수 있다. 예를 들어, 처리 디바이스에 의해 실행 가능한, 컴퓨터가 판독 가능한 코드는 컴 퓨터가 판독 가능한 매체에 저장될 수 있다. 602에서, 프레임 시퀀스의 입력 프레임이 수신된다. 일반적으로 프레임 시퀀스의 입력 프레임과 입력 프레임에 대한 각 후속 프레임은 실시간 또는 거의 실시간으로 한 번에 하나씩 수신된다. 입력 프레임(및 각각의 후속 프 레임)은 카메라에 의해 캡처된 미처리된 디지털 이미지일 수 있거나 최소한으로 처리된(예: 정규화된) 디 지털 이미지일 수 있다. 604에서, 적응적 제스처 감지 시스템은 입력 프레임에서, 구별되는 해부학적 특징을 검출한다. 전체 입력 프레임이 단계에서 처리될 수 있다. 구별되는 해부학적 특징은 배경에서 쉽게 검출되고 구별될 수 있는 사 용자 신체의 임의의 부분일 수 있다. (예: 얼굴 검출 및 추적 서브시스템 사용하는) 사람의 얼굴을 검출하 는 예가 있다. 일부 상황에서는 얼굴을 검출하기 어려울 수 있으며, 이 경우 상이한 해부학적 특징(예: 인체 전 체 또는 사람의 몸통)이 대신 검출될 수 있다. 위에서 언급한 바와 같이, 해부학적 특징은 임의의 적절한 컴퓨 터 비전 기술을 사용하는 것을 포함하여 임의의 적절한 접근 방식을 사용하여 검출될 수 있다. 구별되는 해부학 적 특징을 검출하는 것은 해부학적 특징의 위치(예: 바운딩 박스 또는 좌표로 나타내짐)를 결정하는 것을 포함 할 수 있다. 606에서, 검출된 구별되는 해부학적 특징(예: 검출된 얼굴)에 기반하여 (예: 가상 제스처-공간 생성 서브시스템 을 사용하여) 가상 제스처-공간이 생성된다. 일부 예에서, 구별되는 해부학적 특징의 다수의 인스턴스가 검출될 수 있으며(예: 카메라에 의해 FOV에서 캡처된 입력 프레임 내에 다수의 사람이 있으면 다수의 얼굴이 검출될 수 있음), 이 경우, 구별되는 해부학적 특징의 각각의 검출된 인스턴스에 대해 하나의 가상 제스 처-공간이 생성될 수 있다. 아래에서 추가로 논의되는 바와 같이, 일부 예에서 구별되는 해부학적 특징의 다수 의 인스턴스가 검출될 때 생성된 가상 제스처-공간이 하나만 있을 수 있거나, 가상 제스처-공간(들)의 생성이, 구별되는 해부학적 특징의 검출된 인스턴스의 순위 지정 또는 우선 순위 지정에 기반할 수 있다. 가상 제스처-공간은 입력 프레임에서 검출된 각각의 해부학적 특징의 위치와 관련된 미리 정의된 수식을 사용하 여 생성될 수 있다. 예를 들어, 가상 제스처-공간은 검출된 얼굴의 바운딩 박스에 대한 직사각형 공간을 계산함 으로써 생성될 수 있다. 몇 가지 예제 수식이 아래에 추가로 제공된다. 선택적으로, 608에서, 생성된 가상 제스처-공간에 대한 정보가 적응적 제스처 감지 시스템에 의해 제공되 어, 제스처 제어 디바이스가 생성된 가상 제스처-공간에 대한 피드백을 사용자에게 제공하게 할 수 있 다. 예를 들어, 적응적 제스처 감지 시스템은 가상 제스처-공간의 좌표 또는 다른 파라미터를 지시하는 정 보를 제공하여, 제스처 제어 디바이스가 디스플레이 상에 사용자에 대해 가상 제스처-공간의 표 현 (예: 라이브 카메라 이미지의 상단의 오버레이로서)을 렌더링할 수 있도록 할 수 있다. 다른 예에서, 가상 제스처-공간은 가상 제스처-공간에 대응하는 FOV만을 도시하기 위해 제스처 제어 디바이스에 의해 디스플 레이 상에 렌더링된 삽입 또는 보조 윈도우를 가지는 것에 의해, 사용자에게 표현될 수 있다. 사용자 에게 피드백을 제공하는 다른 방식도 적합할 수 있다. 610에서, (예: 손 검출 및 추적 서브시스템을 사용하여) 생성된 가상 제스처-공간의 입력 프레임에서 손이 검출된다. 검출된 손은 입력 프레임에서 손이 검출된 각각의 가상 제스처-공간과 연관(예: 레이블링)될 수 있다. 다수의 생성된 가상 제스처-공간이 있으면, 입력 프레임에서 생성된 각각의 가상 제스처-공간에서 손을 검출하려는 시도가 이루어질 수 있다. 입력 프레임의 주어진 가상 제스처-공간에서 손이 검출되지 않으면, 이 가상 제스처-공간이 무시되거나 폐기될 수 있다. 입력 프레임에서 생성된 가상 제스처-공간(들) 중 어느 것에서도 손이 검출되지 않으면, 입력 프레임에서 발견 된 손 제스처(예: 제스처 입력)가 없는 것으로 결정될 수 있고, 방법은 프레임 시퀀스에서 다음 입력 프레 임을 수신하기 위해 단계로 돌아갈 수 있다. 적어도 하나의 가상 제스처-공간에서 적어도 하나의 손이 검 출된다고 가정하면, 방법은 선택적 단계로 진행한다. 선택적으로, 612에서, 입력 프레임의 주어진 가상 제스처-공간에서 둘 이상의 손이 검출되면, 하나의 기본 손 (primary hand)이 주어진 가상 제스처-공간에서 식별될 수 있다. 기본 손은 예를 들어 다른 가능성 중에서, 입 력 프레임의 주어진 가상 제스처-공간에서 가장 큰 손; 입력 프레임의 주어진 가상 제스처-공간에서 검출된 구별되는 해부학적 특징(예: 얼굴)에 가장 가까운 검출된 손; 또는 입력 프레임의 주어진 가상 제스처-공간에서 검출된 구별되는 해부학적 특징(예: 얼굴)에 조명 및/또는 색조에서 가장 가까운 검출된 손에 기반하여 식별될 수 있다. 입력 프레임의 주어진 가상 제스처-공간에서 하나의 손만 검출되면, 이 하나의 손이 기본 손이라고 가 정할 수 있다. 614에서, 검출된 손(또는 기본 손)은 프레임 시퀀스의 입력 프레임에 대한 후속 프레임에서 각각의 가상 제스처 -공간에서 (예: 손 검출 및 추적 서브시스템을 사용하여) 추적된다. 검출된 손(또는 기본 손)의 추적은 각 후속 프레임을 처리하는 것에 의해 수행된다. 각 후속 프레임에서 손(또는 기본 손)을 검출하고 추적하는 정보 는 추가 분석 및 파싱을 위해 제공된다. 예를 들어, 후속 프레임에서 검출된 손을 추적하기 위해 바운딩 박스 및 선택적 식별자가 생성될 수 있다. 그 다음, 바운딩 박스(및 선택적 식별자)는 분석 및 파싱을 위해 (예: 제 스처 인식 서브시스템에) 제공될 수 있다. 일부 예에서, 방법은 가상 제스처-공간 서브시스템만을 사용하여 적응적 제스처 감지 시스템에 의해 구현될 수 있다. 적응적 제스처 감지 시스템은 제스처 클래스(도 5 참조)를 출력하는 대신에, 추적된 손(예: 바운딩 박스)에 대한 정보를 기존 제스처 인식 시스템에 출력할 수 있으며, 기존 제스처 인식 시스템은 정보(예: 바운딩 박스)에 대한 손 분류 및 제스처 인식을 수행한다. 상술한 예는 사용자의 손을 직접 검출하는 대신에, 먼저 입력 프레임에서 구별되는 해부학적 특징(예: 사용자의 얼굴)을 검출하고, 검출된 특징에 기반하여 가상 제스처-공간(입력 프레임에서 FOV보다 작음)을 생성한다. 그런 다음 가상 제스처-공간의 입력 프레임에서만 손 검출이 수행된다. 얼굴 검출은 일반적으로 손 검출보다 더 정확 하고 신뢰할 수 있기 때문에 사용자의 얼굴은 가상 제스처-공간을 생성하기 위한 구별되는 해부학적 특징으로 사용될 수 있다. 손 검출을 가상 제스처-공간으로 제한함으로써 손 검출을 위해 후속 프레임을 처리하는 데 필 요한 처리가 단순화될 수 있고, 거짓 양성이 감소될 수 있으며, 제스처 입력에 대해 후속 프레임에서 기본 손을 식별하는 것이 더 쉬울 수 있다. 일부 예에서, 방법은 카메라에 의해 캡처된 모든 프레임을 처리하는 데 사용될 수 있다. 다른 예에서, 방법은 제스처 입력이 예상될 때만 사용될 수 있다. 예를 들어, 방법은 (예: 키보드 입력, 마우스 입력 또는 음성 입력을 통해) 입력을 수신하는 것에 응답하여 시작될(initiate) 수 있다. 일부 예에서, 방법은 사람 주의(attention)의 검출에 기반하여 시작될 수 있다. 예를 들어, 제스처 제어 디바이스 는 주의 검출(attention detection) 기술(예: 눈 추적 소프트웨어를 실행할 수 있음)을 사용하여, 사람이 제스 처 제어 디바이스를 직접 보고 있는지를 판정할 수 있고, 방법은 제스처 제어 디바이스에 의해 직접적인 사람 시선이 검출될 때만 시작될 수 있다. 검출된 사람 주의에 응답하여 방법을 시작하여, 제스 처 입력의 거짓 양성 또는 부정확한 해석을 방지하는 데에 유용할 수 있다. 도 7은 가상 제스처-공간이 검출된 얼굴에 기반하여 생성되는 방법의 예시적인 구현을 도시한다. 이 예에 서, 주 사용자의 얼굴이 604에서 검출되었고, 얼굴이 606에서 가상 제스처-공간을 생성하기 위한 기초 로서 구별되는 해부학적 특징으로 사용된다고 가정한다. 바운딩 박스는 전술한 바와 같은 컴퓨터 비전 기반 기술을 포함하는 임의의 적합한 얼굴 검출 기술을 사용 하여 얼굴에 대해 생성될 수 있다. 이 예에서, 바운딩 박스는 값 세트 에 의해 정의 되며, 및 는 각각 바운딩 박스의 앵커 포인트(예: 중심)의 (적응적 제스처 감지 시스템에 의 해 정의된 기준 프레임에서) x 및 y 좌표를 정의하며, 및 는 바운딩 박스의 너비와 높이를 각각 정의한다. 바운딩 박스에 기반하여, 가상 제스처-공간이 생성되고(예: 단계 606에서) 값 세트 에 의해 정의되며, 여기서 및 는 가상 제스처-공간의 앵커 포인트(예: 중앙)의 (적응적 제스처 감지 시스템에 의해 정의된 기준 프레임에서) x 및 y 좌표를 정의하고, 및 는 가 상 제스처-공간의 너비와 높이를 각각 정의한다. 예를 들어, 가상 제스처-공간을 생성하기 위해 다음 수식이 사용될 수 있다:"}
{"patent_id": "10-2022-7036600", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 는 미리 정의된 상대 위치 파라미터이고, 는 미리 정의된 스케일 파라미터이다. 파라미터 및 는 가상 제스처-공간의 원하는 크기 및 가상 제스처-공간 내의 바운딩 박스의 원하는 위치의 결과에 따라 (예: 사용자에 의해 또는 제스처 제어 디바이스의 제조업체에 의해) 미리 정의될 수 있다. 일부 예에서, 가상 제스처-공간은 얼굴의 바운딩 박스가 가상 제스처-공간(70 4)의 부분적으로 또는 전체적으로 외부에 있도록 생성될 수 있다는 점에 유의해야 한다. 즉, 얼굴이 가상 제스처-공간을 생성하기 위한 기초로 사용될 수 있지만, 가상 제스처-공간이 얼굴을 포함할 필요 는 없다. 도 7의 예에서, 가상 제스처-공간은 직사각형 모양의 2차원 공간으로 생성된다. 그러나 가상 제스처-공간 은 2D 공간 또는 3D 공간으로 생성될 수 있으며 임의의 기하학적 모양(예: 정사각형, 직사각형, 원 등), 규칙적인 모양 또는 불규칙한 모양을 갖도록 생성될 수 있음을 이해해야 한다. 일부 예에서, 가상 제스처-공간은 특정 입력 기능을 구현하는 데 사용될 수 있는 하나 이상의 서브공간 (706, 708)을 추가로 정의할 수 있다. 서브공간(들)(706, 708)은 검출된 얼굴의 특징에 기반하여 (예: 가상 제스처-공간 생성 서브시스템에 의해) 정의될 수 있다. 예를 들어, 왼쪽 서브공간 및 오른쪽 서브공 간은 검출된 얼굴의 검출된 눈 및 코의 위치에 기반하여 검출된 얼굴의 하부 왼쪽 및 오른쪽 부분 에 대응하는 가상 제스처-공간에서 정의될 수 있다. 왼쪽 서브공간에서 터치(또는 포인트) 제스처의 검출 은 왼쪽 마우스 버튼 클릭 입력으로 해석될 수 있다. 유사하게, 오른쪽 서브공간에서 터치(또는 포인트) 제스처의 검출은 오른쪽 마우스 버튼 클릭 입력으로 해석될 수 있다. 이러한 방식으로, 정의된 서브공간(706, 708)을 갖는 가상 제스처-공간은 가상 마우스를 구현하는 데 사용될 수 있다. 일부 예에서, 도 4a에 예시 된 동적 제스처는 가상 커서(virtual cursor)를 구현하기 위한 제스처 입력으로 검출될 수 있다. 가상 커서는 터치(또는 포인트) 제스처가 추적됨에 따라 이동될 수 있고(그리고 사용자에게 디스플레이되는 시각적 오버레이를 통해 디스플레이될 수 있음), 닫힌 손 제스처가 검출될 때 마우스 클릭 입력이 검출될 수 있다. 이러한 방식으로, 가상 마우스가 구현될 수 있다. 도 8a 및 8b는 카메라에 의해 캡처된 프레임 시퀀스의 입력 프레임에서 검출된 사용자의 얼굴에 기반하여 생성된 가상 제스처-공간의 다른 예를 도시한다. 도 8a에서, 가상 제스처-공간은 2D 공간이 고 사용자의 얼굴과 손 모두를 포함하는 직사각형 모양을 갖는다(예: 도 7의 예와 유사함). 도 8b 에서, 가상 제스처-공간은 사용자의 얼굴과 손 모두를 포함하는 3D 공간이다. 가상 제스처-공 간은 깊이 정보가 이용 가능할 때 3D 공간으로 생성될 수 있다. 예를 들어, 깊이 정보는 비디오 분석 기술 을 사용하여 프레임 시퀀스로부터 계산될 수 있다. 예를 들어, 제스처 제어 디바이스는 (예: 컴퓨터 스테 레오비전 기술을 사용하여) 깊이 정보를 계산하기 위해 두 개의 카메라를 사용할 수 있거나, 카메라 는 (기존 RGB 이미지 정보 이외에) 깊이 정보를 생성할 수 있는 RGB-깊이(RGB-depth, RGBD) 카메라일 수 있거나, 또는 제스처 제어 디바이스는 RGB 이미지 정보 및 추가 대응 깊이 정보를 획득하기 위해 기존 카 메라 외에 ToF(Time-of-Flight) 카메라를 포함할 수 있다. 일부 예에서, 깊이 정보는 카메라 외에 깊 이 정보를 캡처할 수 있는 센서(예: 적외선 센서)를 사용하여 캡처될 수 있다. 3D 가상 제스처-공간의 사 용은 깊이 기반 제스처 입력(예: 제스처 제어 디바이스에 더 가까이 또는 더 멀리 손을 움직이는 것)이 검 출되고 커맨드 입력으로 인식되도록 하는 데 유용할 수 있다. 일부 예에서, 가상 제스처-공간은 초기에 프레임 시퀀스의 입력 프레임에서 검출된 구별되는 해부학적 특징(예: 얼굴)에 기반하여 생성되고, 프레임 시퀀스의 입력 프레임에 대한 후속 프레임에서 검출된 손에 기반하여 후속 적으로 재정의되거나 업데이트될 수 있다. 이러한 방식으로, 가상 제스처-공간은 손이 구별되는 해부학적 특징에서 멀리 이동하더라도 검출된 손의 위치를 따를 수 있다. 도 9는 예를 들어 가상 제스처-공간 서브시스템(및 서브시스템(312, 314, 316))을 사용하여 적응적 제스처 감지 시스템에 의해 수행될 수 있는 예시적인 방법을 도시하는 흐름도이다. 방법은 제스처 제어 디바이스의 처리 디바이스에 의해 실행되는 소프트웨어의 루틴 또는 서브루틴에 의해 수행될 수 있다. 이러한 루틴 또는 서브루틴을 수행하기 위한 소프트웨어의 코딩은 본 개시와 관련하여 당업자의 범위 내 에 충분히 있다. 방법은 도시되고 설명된 추가 또는 더 적은 단계 또는 동작을 포함할 수 있으며 상이한 순서로 수행될 수 있다. 예를 들어, 처리 디바이스에 의해 실행 가능한 컴퓨터가 판독 가능한 코드는 컴퓨 터가 판독 가능한 매체에 저장될 수 있다. 방법은 위의 방법에 대해 설명된 단계와 유사한 단계를 포 함할 수 있으며, 이 경우 유사한 단계가 다시 자세히 설명되지 않을 수 있다. 902에서, 프레임 시퀀스의 입력 프레임이 수신된다. 이 단계는 위에서 설명된 단계와 유사할 수 있다. 904에서, 적응적 제스처 감지 시스템은 입력 프레임에서 구별되는 해부학적 특징을 검출한다. 이 단계는 위에서 설명한 단계와 유사할 수 있다. 906에서, 입력 프레임에서 검출된 구별되는 해부학적 특징(예: 검출된 얼굴)에 기반하여 (예: 가상 제스처-공간 생성 서브시스템을 사용하여) 가상 제스처-공간이 생성된다. 이 단계는 위에서 설명된 단계와 유사할 수 있다. 선택적으로, (예: 피드백이 사용자에게 제공될 수 있도록) 가상 제스처-공간을 나타내는 정보가 제공될 수 있다. 단순화를 위해, 방법의 다음 설명에서, 단지 하나의 가상 제스처-공간이 생성되는 것으로 가정된다. 그러나, 방법은 (예: 입력 프레임에서 구별되는 해부학적 특징의 다수의 검출된 인스턴스에 기 반하여) 다수의 가상 제스처-공간이 생성되는 경우에 적응될 수 있다는 것을 이해해야 한다. 908에서, 손이 (예: 손 검출 및 추적 서브시스템을 사용하여) 입력 프레임의 가상 제스처-공간에서 검출되 고, 손이 검출된 가상 제스처-공간과 연관된다. 이 단계는 위에서 설명된 단계와 유사할 수 있다. 선택적 으로, 기본 손이 식별되고 가상 제스처-공간과 연관될 수 있다. 910에서, 가상 제스처-공간은 검출된 손에 기반하여 재정의된다. 가상 제스처-공간을 재정의하는 것은 입력 프 레임에 대한 후속 프레임에서 (검출된 해부학적 특징과 관련되는 것 대신에) 검출된 손과 관련된 미리 정의된 수식을 사용하여 가상 제스처-공간의 위치 및/또는 치수(dimension)를 재계산하는 것을 포함할 수 있다. 예를 들어, 가상 제스처-공간이 검출된 손의 바운딩 박스 주위에 중심이 되도록 가상 제스처-공간이 재정의될 수 있 다. 일부 예시 수식은 아래에서 추가로 설명된다. 912에서, 재정의된 가상 제스처-공간이 저장된다. 이것은 재정의된 가상 제스처-공간(검출된 손을 기반으로 재 정의됨)이, 초기에 생성된 가상 제스처-공간(검출된 얼굴과 같이 입력 프레임에서 검출된 구별되는 해부학적 특 징을 기반으로 초기에 생성되었음) 대신에, 입력 프레임에 대한 후속 프레임에서 손의 검출 및 추적을 위한 기 초로 사용되게 할 수 있다. 914에서, 입력 프레임에서 검출된 손(또는 기본 손)은 (예: 손 검출 및 추적 서브시스템을 사용하여) 재정 의된 가상 제스처-공간의 입력 프레임에 대한 후속 프레임에서 추적된다. 이 단계는 위에서 설명된 단계와 유사할 수 있다. 바운딩 박스(및 선택적인 식별자)는 제스처 입력을 분석하고 파싱하기 위해 (예: 제스처 인식 서브시스템 또는 다른 손 분류기에) 제공될 수 있다. 방법은 가상 제스처-공간이 입력 프레임에서 검출된 손에 기반하여 재정의될 수 있게 하여, 손이 구별되는 해부학적 특징에서 더 멀리 떨어져 이동되더라도 입력 프레임에 대한 각각의 후속 프레임에서 손이 계속 추적되 고 검출될 수 있도록 한다. 검출된 손을 기반으로 가상 제스처-공간을 재정의한 후, 재정의된 가상 제스처-공간 을 사용하여 후속 프레임을 처리할 수 있다. 재정의된 가상 제스처-공간은 손이 공간에서 위치를 변경함에 따라 각 후속 프레임에서 계속해서 재정의될 수 있으므로, 가상 제스처-공간은 손이 움직일 때 계속해서 검출된 손의 중심에 있게 된다. 예를 들어, 프레임 시퀀스의 입력 프레임에 대한 후속 프레임은 단계(904 및 906)가 생략되 는 방법의 변형을 사용하여 처리될 수 있다. 일부 예에서, 후속 프레임의 재정의된 가상 제스처-공간에서 손이 더 이상 검출되지 않으면, 가상 제스처-공간 은 입력 프레임에서 검출된 구별되는 해부학적 특징에 기반하여 재생성될 수 있다. 다시 말해, 구별되는 해부학 적 특징은 가상 제스처-공간을 정의하기 위한 앵커 또는 기본 기초(default basis)로 사용될 수 있다. 일부 예 에서, 구별되는 해부학적 특징을 가상 제스처-공간에 대한 기본 기초로 사용하는 것으로의 복귀는, 손이 미리 정의된 수 이상의 후속 프레임(예: 입력 프레임 이후의 최소 10프레임)에 대한 재정된 가상 제스처-공간에서 검출될 수 없을 경우에만 수행될 수 있다. 도 10a 및 10b는 가상 제스처-공간이 초기에 프레임 시퀀스의 입력 프레임에서 검출된 사용자의 얼굴 에 기반하여 생성되고, 입력 프레임에서 검출된 사용자의 손에 기반하여 후속적으로 재정의되는 방 법의 예시적인 구현을 도시한다. 도 10a에서, 가상 제스처-공간은 입력 프레임에서 검출된 얼굴 의 바운딩 박스에 기반하여 생성되는 직사각형 모양을 갖는 2D 공간이다(예: 도 7의 예와 유사). 손이 입력 프레임의 가상 제스처-공간에서 검출되고, 손에 대한 바운딩 박스가 정의된다. 도 10b에서, 가상 제스처-공간(704b)은 손의 바운딩 박스에 기반하여 재정의된다. 예를 들어, 손의 바운딩 박스는 값 세트 에 의해 정의될 수 있으며, 여기서"}
{"patent_id": "10-2022-7036600", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "및 각각은 바운딩 박스의 앵커 포인트(예: 중앙)의 (적응적 제스처 감지 시스템에 의해 정의된 기준 프레임에서) x 및 y 좌표를 정의하며, 및 는 각각 바운딩 박스의 너비와 높이를 정의한다. 바운딩 박스에 기반하여, 가상 제스처-공간(704b)이 재정의된다(예: 단계에서). 예를 들어, 가상 제 스처-공간(704b)을 재정의하기 위해 다음 수식이 사용될 수 있다:"}
{"patent_id": "10-2022-7036600", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서 는 이전에 논의된 가상 제스처-공간(704b)을 정의하는 파라미터이고, 는 미 리 정의된 상대 위치 파라미터이며, 는 검출된 손에 대한 미리 정의된 스케일 파라미터이다. 파라미터 및 는 재정의된 가상 제스처-공간(704b)의 원하는 크기 및 재정의된 가상 제스처-공간 (704b) 내에서 바운딩 박스의 원하는 위치에서의 결과에 따라 (예: 사용자에 의해 또는 제스처 제어 디바이스의 제조업체에 의해) 미리 정의될 수 있다. 특히, 도 10b의 예에 도시된 바와 같이, 얼굴은 재정의된 가상 제스처-공간(704b)에서 부분적으로 또는 전체적으로 제외될 수 있다. 일부 예에서, 다수의 사람이 입력 프레임에서 검출될 때(예: 다수의 얼굴이 얼굴 검출 및 추적 서브시스템(31 2)에 의해 검출됨), 적응적 제스처 감지 시스템은 사용자 리스트를 구현하여 검출된 사람의 순위를 매기고, 하나의 사람을 주 사용자(또는 주 컨트롤러(primary controller))로 식별할 수 있다. 가상 제스처-공간 은 주 사용자에 대해서만 생성될 수 있다. 도 11은 예를 들어 가상 제스처-공간 서브시스템 및 제스처 파싱 서브시스템(및 서브시스템(312, 314, 316, 322, 324))을 사용하여 적응적 제스처 감지 시스템에 의해 수행될 수 있는 예시적인 방법(110 0)을 도시하는 흐름도이다. 방법은 제스처 제어 디바이스의 처리 디바이스에 의해 실행되는 소 프트웨어의 루틴 또는 서브루틴에 의해 수행될 수 있다. 이러한 루틴 또는 서브루틴을 수행하기 위한 소프트웨 어의 코딩은 본 개시와 관련하여 당업자의 범위 내에 충분히 있다. 방법은 도시 및 설명된 추가 또는 더 적은 단계 또는 동작을 포함할 수 있고, 상이한 순서로 수행될 수 있다. 예를 들어, 처리 디바이스에 의해 실행 가능한 컴퓨터가 판독 가능한 코드는 컴퓨터가 판독 가능한 매체에 저장될 수 있다. 방법은 위의 방 법에 대해 설명된 단계와 유사한 단계를 포함할 수 있으며, 이 경우 유사한 단계가 다시 상세하게 설명되 지 않을 수 있다. 1102에서, 프레임 시퀀스의 입력 프레임이 수신된다. 이 단계는 위에서 설명된 단계와 유사할 수 있다. 1104에서, 주 사용자가 이미 식별되고 선택되었는지가 판정된다. 예를 들어, 주 사용자는 프레임 시퀀스에서 이 전 입력 프레임을 분석하여 식별되고 선택되었을 수 있다. 주 사용자가 이미 선택되었다면, 방법은 단계로 진행하고; 그렇지 않으면 방법은 단계로 진행한다. 1106에서, 주 사용자의 구별되는 해부학적 특징(예: 얼굴)이 (예: 얼굴 검출 및 추적 서브시스템을 사용하 여) 입력 프레임에서 검출되고 프레임 시퀀스에서 입력 프레임에 대한 후속 프레임에서 추적된다. 주 사용자가 이전 입력 프레임에서 식별되었으면, 가상 제스처-공간이 주 사용자에 대해 이미 정의되었을 수 있다. 이러한 경우에, 입력 프레임 및 입력 프레임의 후속 프레임에서 해부학적 특징의 검출 및 추적은 이미 정의된 가상 제 스처-공간에서만 각 후속 프레임을 처리하는 것에 의해 수행될 수 있다. 해부학적 특징의 추적은 모든 후속 프 레임을 처리하여 수행되지만 검출은 더 낮은 빈도(예: 하나 이상의 후속 프레임 건너뛰기)로 수행될 수 있다. 해부학적 특징의 검출은 추적 오류를 수정하기 위해 수행될 수 있다(예: 많은 후속 프레임을 추적할 때 추적 오 류가 누적될 수 있음). 비록 이 논의가 주 사용자의 구별되는 해부학적 특징(예: 얼굴)을 검출하고 추적하는 콘 텍스트에 있지만, 단계의 수정은 가상 제스처-공간이 입력 프레임에서 검출된 손에 기반하여 재정의되는 경우에(예: 도 10a 및 10b와 관련하여 위에서 논의된 바와 같이), 입력 프레임 및 후속 프레임을 처리하여 주 사용자의 손을 검출 및 추적하도록 수행될 수 있다는 점에 유의해야 한다. 1108에서, 주 사용자가 이전에 선택되지 않으면, 전체 입력 프레임은 예를 들어 얼굴 검출 및 추적 서브시스템 을 사용하여 구별되는 해부학적 특징의 인스턴스(예: 사람 얼굴의 모든 인스턴스)를 검출하도록 처리될 수 있다. 검출된 각 해부학적 특징에 대해 바운딩 박스 및 식별자가 생성될 수 있다. 구별되는 해부학적 특징의 인 스턴스가 입력 프레임에서 검출되지 않으면, 방법은 프레임 시퀀스에서 다음 입력 프레임을 처리하기 위 해 1102로 돌아갈 수 있다. 1110에서, 해부학적 특징의 검출된 인스턴스에 기반하여 순위가 매겨진 사용자 리스트가 생성된다. 각 검 출된 인스턴스는 각각의 검출된 사용자와 연관될 수 있다. 사용자 리스트는 미리 정의된 순위 지정 기준에 따라 (예: 임의의 눈 추적 기술과 같은 임의의 적절한 얼굴 분석 기법을 사용하여) 검출된 해부학적 특징을 추 가로 분석함으로써 순위가 매겨질 수 있다. 예를 들어, 해부학적 특징이 얼굴이면, 순위 지정 기준은 (제스처 제어 디바이스에 더 가까운 것으로 가정되는) 큰 얼굴이 작은 얼굴보다 높은 순위가 매겨지고; 제스처 제 어 디바이스를 향한 얼굴은 제스처 제어 디바이스로부터 멀어지는 얼굴보다 더 높은 순위가 매겨질 수 있으며; 또는 제스처 제어 디바이스를 응시하는 눈을 가진 얼굴은 제스처 제어 디바이스로부터 시 선을 돌리는 눈을 가진 얼굴보다 더 높은 순위가 매겨질 수 있는 것으로 지정할 수 있다. 다른 순위 지정 기준 이 사용될 수 있다. 구별되는 해부학적 특징의 인스턴스가 하나뿐이면, 그 하나의 인스턴스는 기본적으로 리스 트에서 가장 높은 순위를 가질 수 있다. 1112에서, 순위가 매겨진 사용자 리스트에서 가장 높은 순위의 사용자가 주 사용자로서 선택된다. 사용자 리스트에 단 하나의 사용자가 있으면, 그 사용자가 기본적으로 주 사용자로서 선택될 수 있다. 그 다음, 방법은 카메라에 의해 캡처된 프레임 시퀀스에서 주 사용자의 해부학적 특징을 추적하기 위해 단계 로 진행한다. 1114에서, 가상 제스처-공간이 주 사용자에 대해 생성된다. 가상 제스처-공간이 (카메라에 의해 캡처된 이 전 프레임의 분석에 기반하여) 이전에 정의되었으면, 가상 제스처-공간을 생성하는 대신에 이미 정의된 가상 제 스처-공간이 사용될 수 있다. 그렇지 않으면, 가상 제스처-공간이 프레임 시퀀스의 입력 프레임에서 검출된 주 사용자의 구별되는 해부학적 특징(예: 얼굴)에 기반하여 생성된다(예: 이전에 설명된 단계와 유사함). 선 택적으로, 가상 제스처-공간을 나타내는 정보가 (예: 피드백이 주 사용자에게 제공될 수 있도록) 제공될 수 있 다. 1116에서, 프레임 시퀀스의 입력 프레임에서 (예: 손 검출 및 추적 서브시스템을 사용하여) 가상 제스처- 공간에서 손이 검출된다. 이 단계는 위에서 설명된 단계와 유사할 수 있다. 선택적으로, 입력 프레임의 가 상 제스처-공간에서 둘 이상의 손이 감지되면, 기본 손이 (예: 손 크기와 같은 일부 미리 정의된 기준에 기반하 여) 식별되고 가상 제스처-공간과 연관될 수 있다. 선택적으로, 가상 제스처-공간은 입력 프레임에서 검출된 손 에 기반하여 재정의될 수 있다(도 9에 대해 위에서 설명된 것과 유사함). 가상 제스처-공간이 입력 프레임에서 검출된 손에 기반하여 입력 프레임에 대한 후속 프레임에서 재정의되면, 검출 및 추적은 단계에서 이미 수행되었을 수 있으며 이 단계는 필요하지 않을 수 있다. 1118에서, 제스처 인식이 입력 프레임에 대한 프레임 시퀀스에서 (예: 바운딩 박스에 의해 정의된 바와 같이) 검출되고 추적된 손에 대해 (예: 제스처 인식 서브시스템을 사용하여) 수행되어 검출된 손에 대해 제스처 클래스를 예측한다. 예측된 제스처 클래스(유효한 제스처가 식별되면)가 출력되어 예를 들어 소프트웨어 애플리 케이션에 대한 커맨드 입력으로 변환된다. 사용자 리스트의 임의의 비주(non-primary) 사용자는 폐기되고(즉, 주 사용자만 유지), 방법은 카메라에 의해 캡처된 프레임 시퀀스에서 다음 입력 프레임을 수신 하고 처리하기 위해 1102로 돌아간다. 제스처 인식이 유효한 제스처를 예측하지 못하면(예: 손 모양은 미리 정의된 제스처 클래스로 분류될 수 없음) 또는 제스처가 현재 활성화된 소프트웨어 애플리케이션에 대한 유효한 제스처가 아니면(예: 소프트웨어 애플리 케이션이 적응적 제스처 감지 시스템에 무효 입력을 다시 보고함), 방법은 단계로 진행한다. 1120에서, 현재 선택된 주 사용자는 사용자 리스트에서 폐기된다. 1122에서, 사용자 리스트에 임의의 다른 사용자가 있는지가 판정된다. 사용자 리스트에 적어도 하나 의 남은 사용자가 있다면, 단계에서 사용자 리스트에서 가장 높은 순위를 가지는 남은 사용자가 주 사용자로서 선택되고, 방법은 위에서 설명된 바와 같이 단계로 진행한다. 사용자 리스트에 남 아 있는 사용자가 없다면, 방법은 프레임 시퀀스에서 다음 입력 프레임을 수신하고 처리하기 위해 단계 로 돌아간다. 사용자 리스트는 적응적 제스처 감지 시스템이 카메라의 FOV 내에 다수의 사람이 있는 경우 에도 감소된 거짓 양성으로 제스처 입력을 분석 및 처리할 수 있게 한다. 사용자 리스트는 다수의 사람의 존재를 수용하는 비교적 효율적인 방법일 수 있지만, 위에서 논의된 바와 같이 사용자 리스트 대신에 또는 이에 추가하여 다른 기술이 사용될 수 있다. 위에서 논의된 일부 예에서, 구별되는 해부학적 특징(예: 사람 얼굴)의 검출은 전체 입력 프레임을 처리함으로 써 수행될 수 있다. 아래에서 논의되는 다른 예에서, 구별되는 해부학적 특징의 검출은 입력 프레임 내에서 관 심 영역(region of interest, ROI)만을 처리함으로써 수행될 수 있다. 예를 들어, 위에서 설명된 단계에 서, 적응적 ROI 접근 방식이 사용될 수 있다(예: 얼굴 검출 및 추적 서브시스템이 얼굴 검출을 위해 구현 할 수 있음). 본 개시에서 적응적 ROI는 ROI의 크기 및/또는 위치가 예를 들어, 얼굴 검출기(예: 얼굴 검출 및 추적 시스템 )의 요건, 입력 프레임의 해상도, 또는 처리 효율에 기반하여 조정될 수 있다. 예를 들어, 머신 러닝 기반 (예: 컴퓨터 비전 기반) 얼굴 및 손 검출기는 일반적으로 정사각형 입력 이미지를 처리하도록 트레이닝된다. 따 라서, 얼굴 및 손 검출에서의 성능 향상을 위해서는 검출 수행을 위한 ROI가 정사각형이어야 한다. 유사한 이유 로 손 검출을 위한 가상 제스처-공간은 정사각형으로 정의될 수 있다. 도 12는 카메라에 의해 캡처된 프레임 시퀀스의 입력 프레임에서 구별되는 해부학적 특징을 검출하기 위해 적응적 ROI를 사용하는 예시적인 방법을 도시하는 흐름도이다. 방법은 위에서 설명된 단계의 일부로서 사용될 수 있다. 예를 들어, 방법은 얼굴 검출 및 추적 서브시스템에 의해 구현될 수 있다. 방법은 단계에 대한 다른 기술을 사용하여 구현될 수 있고, 적응적 ROI가 사용되거나 사용되 지 않을 수 있음을 이해해야 한다. 1202에서, 해부학적 특징이 이전 입력 프레임에서 검출되었는지가 검출된다. 그렇다면, 1204에서 이전 입력 프 레임에서 해부학적 특징(예: 얼굴)의 검출에 사용된 ROI가 현재 입력 프레임에서 다시 사용되도록 선택된다. 일 반적으로, 해부학적 특징의 검출을 위한 ROI는 전체 입력 프레임보다 작아야 하며, (검출 알고리즘이 어떻게 트 레이닝되거나 설계되었는지에 기반하여) 정사각형 모양일 수 있다. 해부학적 특징이 이전 입력 프레임에서 검출되지 않았으면(또는 이전 입력 프레임이 없으면), 1206에서 ROI 시 퀀스로부터 ROI가 선택된다. ROI 시퀀스로부터의 ROI가 이전 입력 프레임에서 사용되었으면, ROI 시퀀스의 다음 ROI가 현재 입력 프레임에서 사용하기 위해 선택될 수 있다. ROI 시퀀스는 미리 정의될 수 있다(예: 얼굴 검출 및 추적 서브시스템에서 미리 정의됨). ROI 시퀀스는 순차적 입력 프레임을 처리하는 데 사용할 상이한 ROI의 시퀀스를 정의한다. 예를 들어, ROI 시퀀스가 8개의 상이한 ROI(예: 다른 위치 및/또는 크기를 가짐)의 시퀀스이면, 시퀀스의 각 ROI는 8개의 입력 프레임의 시퀀스에서 해부학적 특징의 검출을 수행하기 위해 차례로 선택된다. 그런 다음, ROI 시퀀스는 시퀀스의 제1 ROI로 다시 순환할 수 있다. 도 13은 8개의 상이한 ROI(1302, 1304, 1306, 1308, 1310, 1312, 1314, 1316)를 갖는 예시적인 ROI 시퀀스를 도시한다. 8개의 ROI(1302-1316)는 8개의 상이한 입력 프레임의 시퀀스를 통해 순환될 수 있고, 상이한 해상도 의 입력 프레임에 적용될 수 있다. 예를 들어, 6개의 ROI(1302-1312)는 입력 프레임의 원래 해상도에 적 용될 수 있고, 더 작은 해부학적 특징의 검출을 가능하게 하도록 설계될 수 있다(예: 사용자가 제스처 제어 디바이스로부터 더 멀리 떨어져 있는 경우). 2개의 ROI(1314, 1316)는 입력 프레임의 축소된 버전 (더 낮은 해상도를 가짐)에 적용될 수 있고, 더 큰 해부학적 특징의 검출을 가능하게 하도록 설계될 수있다(예: 사용자가 제스처 제어 디바이스에 더 가까이 있는 경우). 일부 ROI(1314, 1316)에 대해 입력 프레임의 축소된 버전을 사용하여 입력 프레임의 더 큰 영역의 계산 비용이 덜 드는 처리를 가능하게 하는 것이 유용할 수 있다. ROI 시퀀스는 카메라에 의해 캡처된 프레임 시퀀스에 걸쳐 순환되므로, 각 입력 프레임은 (둘 이상의 ROI 를 사용하여 동일한 입력 프레임을 처리하는 대신에) 선택된 ROI만을 사용하여 처리된다. 카메라에 의해 캡처된 입력 프레임은 일반적으로 높은 빈도로 캡처되기 때문에, 인접 프레임 간의 시간 차이가 이 방식에서 ROI 시퀀스를 사용하여 프레임 시퀀스를 처리하는 것에 의해 손실되는 정보가 없어야(또는 매우 적은) 할 만큼 충분히 작을 수 있다. 미리 정의된(예: 얼굴 검출 및 추적 서브시스템에 저장되는) 상이한 ROI 시퀀스가 있을 수 있다. 사용되는 ROI 시퀀스는 사용자에 의해 선택될 수 있거나, 상이한 ROI 시퀀스를 통해 순환하기 위한 미리 정의된 순서 가 있을 수 있다(즉, 사용할 ROI 시퀀스의 미리 정의된 시퀀스가 있을 수 있음). 또한, 비록 도 13의 예가 시퀀 스에서 한 번 사용되는 ROI 시퀀스의 각 ROI를 도시하지만, 일부 예에서 ROI 시퀀스는 ROI 시퀀스 내에서 주어 진 ROI를 두 번 이상 사용하도록 정의될 수 있다. 다른 이러한 변형이 가능할 수 있다. 1208에서, 선택된 ROI(단계에서 이전 입력 프레임에서 선택된 ROI, 또는 단계에서 ROI 시퀀스로부 터 선택된 ROI), 구별되는 해부학적 특징의 검출은 선택된 ROI를 사용하여 수행된다. 구별되는 해부학적 특징(예: 얼굴)의 검출을 수행하기 위한 적응적 ROI의 사용은 계산 비용의 감소 및/또는 트 레이닝된 검출기의 개선된 성능을 가능하게 할 수 있다. 일부 예에서, 적응적 ROI 기술은 제스처 검출이 활성화될 때(또는 제스처 검출이 디폴트로 사용될 때), 카메라 에 의해 캡처되는 모든 프레임을 처리하는 데 사용될 수 있다. 다른 예에서, 적응적 ROI 기술은 모든 N(여 기서 N>1)개의 프레임을 처리하는 데 사용될 수 있다. 이전에 논의된 바와 같이, 일부 예에서 손 검출 및 추적 서브시스템은 제스처 인식을 위해 제스처 인식 서 브시스템에 의해 사용될 바운딩 박스를 출력할 수 있다. 일부 실시예에서, 제스처 인식 서브시스템은 머신 러닝 알고리즘을 사용하여 구성된 모델로 구현될 수 있다. 일부 실시예에서, 제스처 인식 서브시스템(32 2)은 제스처 분류를 수행하도록 구성된 트레이닝된 신경망(이하, 트레이닝된 제스처 분류 네트워크로 지칭됨)을 포함할 수 있다. 트레이닝된 제스처 분류 네트워크는 신경망의 파라미터(예: 가중치)를 학습하기 위해 알려진 머신 러닝 알고리즘을 사용하여 트레이닝되었다. 트레이닝된 제스처 분류는 검출된 손 제스처에 대한 바운딩 박 스를 수신하고, 바운딩 박스에 대응하는 미리 정의된 제스처 클래스 세트로부터 특정 제스처 클래스를 예측한다. 일반적으로 제스처 분류를 수행하도록 구성된 트레이닝된 신경망에 의해 달성되는 제스처 분류의 정확도는 (예: 바운딩 박스가 그라운드 트루스(ground truth)로부터 큰 오프셋을 갖을 때) 손 이미지가 잘릴(cropped)수록 저 하된다. 바운딩 박스 조정의 예는 2019년 3월 15일에 출원되고 명칭이 \"얼굴 인식을 위한 적응적 이미지 자르기\"인 미국 특허 출원 번호 제16/355,665호에 설명되어 있으며, 그 전체 내용이 여기에 참조로 포함된다. 제스처 인식을 개선하는 데 도움이 되는 바운딩 박스 조정에 대한 유사한 접근 방식이 여기에 설명되어 있다. 도 14는 제스처 인식 서브시스템에 사용될 수 있는 제스처 분류 네트워크의 예시적인 구현을 도시하는 블 록도이다. 제스처 분류 네트워크는 바운딩 박스 리파인먼트(refinement) 네트워크에 대한 사이드 브랜치(side branch)들과 함께 구현될 수 있다. 제스처 분류 네트워크는 입력 프레임에서 바운딩 박스에 의해 정의된 손 이미지에 대한 제스처 분류를 수행하고, 바운딩 박스 리파인먼트 네트워크는 제스처 분류 네트워크에서 사용되는 바운딩 박스의 리파인먼트를 수행한다. 입력 프레임이 제스처 분류 네트워크으로의 입력 데이터로서 수신된다. 입력 데이터는 (예: 손에 대해 정 의된 바운딩 박스를 기반하여) 입력 프레임의 잘린 버전(cropped version)일 수 있다. 일부 실시예에서, 입력 데이터는 네트워크(1400, 1450)의 묶음 기반 트레이닝(batch-based training)을 위해 또는 프레임 시퀀스에 기 반한 제스처 분류를 가능하게 하기 위한 것과 같이 이미지 묶음(batch of images)일 수 있다. 제스처 분류 네트 워크는 일련의 컨볼루션 블록(예: ResNet 설계를 사용하여 구현됨)을 포함한다. 3개의 이러한 컨볼 루션 블록이 단순화를 위해 도시되지만, 제스처 분류 네트워크에는 더 많거나 더 적은 컨볼루션 블 록이 있을 수 있다. 일련의 컨볼루션 블록은 결정된 제스처 클래스를 출력하는 제스처 분류 완전 연결 네트워크(fully connected network, FCN)로 출력한다. 제스처 분류 FCN은 일련의 컨볼루션 블록에서 마지막 컨볼루션 블록으로부터 출력된 벡터를 입력으로 수신한다. 제스처 분류 FCN은 특징 임베딩을 사용하여 바운딩 박스에 의해 정의된 손에 대한 제스처 클래스를 결정하고, 결정된 제스처 클래스를 레이블로 출력한다. 일부 예에서, 제스처 분류 FCN은 가능한 제스처 클래스에 대한 확률 분포를 포함하는 벡터를 출력한다. 즉, 제스처 분류 네트워크의 출력은 하나의 확정적으로 결정된 제스처 클래스 대신에, 서로 다른 제스처 클래스에 대한 확률일 수 있다. 일부 예에서, 제스처 분류 FCN은 가능한 제스 처 클래스들에 대한 출력된 확률 분포들을 정규화하는 역할을 하는 마지막 출력 레이어에서의 소프트맥스 함수 (softmax function)를 포함한다. 각각의 컨볼루션 블록은 또한 바운딩 박스 리파인먼트 네트워크에 속하는 사이드 브랜치로 출력한다. 각 사이드 브랜치는 바운딩 박스 리파인먼트 FCN으로 출력한다. 각 사이드 브랜치(145 2)는 선택적인 맥스 풀링(max-pooling) 레이어, 선택적인 크기 조정(resizing) 레이어, 및 컨볼루션 블록을 독 립적으로 포함할 수 있다. 사이드 브랜치의 출력은 조합된 출력 벡터로 연결되며(concatenated), 이는 바 운딩 박스 리파인먼트 FCN에 입력되기 전에 1×1 컨볼루션 블록(도시되지 않음)에 의해 평탄화될 수 있다. 바운딩 박스 리파인먼트 FCN의 출력은 입력 프레임에서 손을 정의하는 바운딩 박스의 크기 및 위치 를 조정하거나 리파인먼트하는(refine) 정보(예: 바운딩 박스에 대한 좌표 정보의 형태로)이다. 이제 조인트 네트워크(joint network)(1400, 1450)의 트레이닝이 논의된다. 전술한 바와 같이, 제스처 분류 FCN은 소프트맥스 레이어를 포함할 수 있다. 제스처 분류 FCN은 추가로, 모델에서 출력된 확률 분 포와 원래 확률 분포 간의 차이의 척도로 간주될 수 있는 교차 엔트로피 손실(cross-entropy loss)을 계산 및 출력할 수 있다. 이 교차 엔트로피 손실은 소프트맥스 레이어에 대한 손실 함수로 사용될 수 있으며, 따라서 소 프트맥스 손실이라고도 한다. 이와 유사하게, 바운딩 박스 손실이 바운딩 박스 리파인먼트 FCN으로부터 출력될 수 있다. 소프트맥스 손실 및 바운딩 박스 손실은 조인트 네트워크(1400, 1450)의 트레이닝에 사 용될 수 있는 총 손실 함수(total loss function)에 대해 조합될 수 있다. 총 손실 함수를 사용하는 소프트맥스 손실, 바운딩 박스 손실 및 트레이닝은 네트워크(1400, 1450)의 트레이닝 동안에만 사용될 수 있고, 추론 동안에는 필요하지 않을 수 있다. 네트워크(1400, 1450)의 트레이닝 동안, 트레이닝 데이터 샘플은 그라운드 트루스 손 바운딩 박스(ground truth hand bounding box)를 기반으로 하는 무작위로 자른 손 이미지(random cropped hand image)로 생성될 수 있다. 일부 예가 도 15에 도시되어 있으며, 여기서 그라운드 트루스(ground truth)는 손 이미지에 대한 최적화 된 바운딩 박스를 정의하고, 다른 무작위로 자른 손 이미지는 트레이닝 데이터 샘플로서 생성된다. 트레 이닝 데이터 샘플은 바운딩 박스의 위치를 이동할 수 있을 뿐만 아니라 (바운딩 박스의 손 이미지가 더 크거나 작게 나타날 수 있도록) 바운딩 박스의 크기도 변경할 수 있다. 그라운드 트루스에 대한 각 트레 이닝 데이터 샘플의 바운딩 박스 오프셋은 바운딩 박스 리파인먼트를 트레이닝하기 위한 레이블로서 사용 된다. 조인트 네트워크(1400, 1450)는 이 예에서 분류 손실 함수(소프트맥스 손실)와 바운딩 박스 손실 함수의 선형 조합인 총 손실 함수를 최소화하는 것에 의해 트레이닝된다. 이제 바운딩 박스 손실 함수의 예에 대해 설명한다. 도 16의 단순화된 예를 고려하며, 도 16은 객체 주위에 정의된 그라운드 트루스 바운딩 박스 및 잘린 트 레이닝 데이터 샘플 바운딩 박스를 도시한다. 를 트레이닝 데이터 샘플 바운딩 박스의 위치(이 예에서는 네 모서리)를 정의하는 좌표라고 하고, 를 대응하는 그라운드 트루스 바운딩 박스의 위치를 정의하는 좌표 라고 한다. 바운딩 박스 리파인먼트 네트워크는 트레이닝 데이터 샘플 바운딩 박스와 그라운드 트 루스 바운딩 박스 사이의 상대 회전 θ 및 상대 변위 를 추정하며, 여기서: 이다. 바운딩 박스 손실 함수는 다음: 과 같이 정의될 수 있으며, 여기서 λ는 정규화 파라미터이다. 추론 동안, 입력 프레임에서 손 이미지를 정의하는 바운딩 박스는 바운딩 박스 리파인먼트 네트워크에 의 해 예측된 오프셋이 0에 가까울 때까지 반복적으로 보정될 수 있다. 최종 제스처 분류 점수(score)는 다음:"}
{"patent_id": "10-2022-7036600", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "과 같이 각 반복에서 획득된 모든 개별 제스처 분류 점수를 조합하여 계산될 수 있으며, 여기서 은 m번째 반복의 분류 점수(예: 소프트맥스 출력)이고, 은 m번째 바운딩 박스와 최종 리파인먼트된 바운딩 박스의 대 응하는 가중치(예: IoU(intersection over union))이다. 추론 동안, 제스처 분류 네트워크를 사용하여 입력 손 이미지(입력 프레임에 적용된 바운딩 박스에 의해 정의됨)에 반복 분류가 적용된다. 각각의 반복에서, 제스처 분류 네트워크에 대한 입력 이미지가 이전 반 복의 출력된 바운딩 박스 리파인먼트 파라미터에 의해 보정된 이전 입력 이미지에 기반하여 획득된다. 따라서, 바운딩 박스 리파인먼트 네트워크 및 제스처 분류 네트워크는 제스처 분류 네트워크(140 0)의 성능 향상을 돕기 위해 함께 작동하여, 입력 프레임에서 손 이미지를 정의하는 바운딩 박스를 리파인먼트 하기 위한 피드백을 제공한다. 도 17은 제스처 인식을 수행하기 위해 (예: 위에서 설명된 조인트 네트워크(1400, 1450)를 사용하여) 바운딩 박 스 리파인먼트를 사용하는 예시적인 방법을 도시하는 흐름도이다. 방법은 위에서 설명된 단계 의 일부로서 사용될 수 있다. 예를 들어, 방법은 제스처 인식 서브시스템에 의해 구현될 수 있다. 방법은 단계에 대한 다른 기술을 사용하여 구현될 수 있고, 바운딩 박스 리파인먼트가 사용 될 수도 있고 사용되지 않을 수도 있다는 것을 이해해야 한다. 1702에서, 입력 프레임이 물론 검출된 손을 정의하는 바운딩 박스(예: 손 검출 및 추적 서브시스템에 의해 출력됨)가 수신된다. 1704에서, (상술한 바와 같이) 조인트 바운딩 박스 리파인먼트 네트워크를 갖는 제스처 분류 네트워크가 사용되 어, 바운딩 박스 리파인먼트와 함께 제스처 분류를 수행할 수 있다. 선택적으로, 1706에서 제스처 분석이 다수의 입력 프레임에 걸쳐 수행될 수 있다. 예를 들어, 제스처 인식 서브 시스템은 이전 입력 프레임의 버퍼를 저장하고 이전 입력 프레임을 고려하여 제스처 분석을 수행할 수 있 다. 버퍼(예: 적응적 제스처 감지 시스템에서 구현됨)는 미리 결정된 수의 이전 입력 프레임을 저장하는 데 사 용될 수 있다. 버퍼에 저장되는 이전 입력 프레임의 수는 메모리 리소스의 보다 효율적인 사용을 위해 상대적으 로 작을 수 있다(예: 10-30개의 이전 입력 프레임). 일부 예에서, 버퍼는 적은 수의 이전 입력 프레임에 대해 수행된 제스처 분석의 결과를 추가적으로 또는 다르게는 저장할 수 있다. 인식될 단일 정적 제스처의 경우, 제스처 인식 서브시스템은 미리 정의된 수(N)의 이전 입력 프레임에 걸 쳐 미리 정의된 최소 횟수(K)로 동일한 제스처 클래스가 검출되도록 요구할 수 있으며, 여기서 K≥ 1 및 K≤N이 다. 이 요건은 검출 정확도를 개선하고 거짓 양성을 줄이는 데 도움이 될 수 있다. 일부 예에서, N개의 이전 입 력 프레임에 걸쳐 K개의 연속적인 입력 프레임에 걸쳐 동일한 제스처 클래스가 검출될 필요가 있을 수 있다. 미 리 정의된 최소 K는 더 나은 검출을 가능하게 하고 여전히 거의 실시간 제스처 인식을 달성하기 위해 비교적 작 은 숫자(예: 10)로 선택될 수 있다. 이 접근 방식을 사용하여 검출될 수 있는 정적 제스처는 예를 들어 음소거 제스처(예: 음소거 또는 음소거 해제(unmute) 커맨드용) 또는 펼친 손 제스처(예: 재생 또는 일시 중지 커맨드 용)를 포함할 수 있다. N개의 이전 입력 프레임은 버퍼에 저장될 수 있고, 거짓 양성을 줄이는 데 도움이 되도 록 제스처를 검출하기 위한 슬라이딩 윈도우로 사용될 수 있다. 동적 제스처는 둘 이상의 정적 제스처의 조합에 기반하여 제스처 인식 서브시스템에 의해 인식될 수 있다. 예를 들어, 완전한 동적 제스처는 상이한 상태로 분리될 수 있으며, 여기서 상태 간의 전환(transition)은 정적 제스처의 검출 결과이다. 제스처 인식 서브시스템은 동적 제스처의 상태 기반 인식을 위해 미리 정의된 상 태 전환 규칙 세트를 구현할 수 있다. 도 18은 제스처 인식 서브시스템에 의해 구현될 수 있는 동적 제스처의 상태 기반 인식의 예를 도시하는 상태도이다. 중립 상태(neutral state)는 제스처 입력이 처음 활성화되거나 현재 유효한 제스처가 검출되 지 않을 때 기본적으로 초기 상태일 수 있다. 스와이프 동적 제스처(swipe dynamic gesture)는 스와이프 준비(swipe ready) 상태로의 전환을 위해 주 먹 제스처가 처음 검출되고 이어서 스와이프 상태로의 전환을 위해 펼친 손 제스처의 검출이 뒤따를 때, 검출될 수 있다. 스와이프 상태에 도달하면, 제스처 인식 서브시스템은 제스처 입력을 동적 스와이 프 제스처로 인식한다. 따라서, 정적 주먹 제스처에 이은 정적 펼친손 제스처(적절한 순서대로)의 인식은 동적 스와이프 제스처의 인식을 초래한다. 또한, 검출된 주먹 제스처와 검출된 펼친 손 제스처 사이의 위치 변화가 (예: 스와이프 제스처를 위치 변화를 포함하지 않는 다른 동적 제스처와 구별하기 위해) 동적 스와이프 제스처 를 긍정적으로 검출하기 위해 필요할 수 있다. 검출된 제스처의 위치 변화는 손 바운딩 박스의 좌표 변경에 기 반하여 계산될 수 있다. 스와이프 상태에 도달하면, 제스처 인식 서브시스템은 인식된 제스처를 지 시하는 출력(예: 제스처 클래스 레이블)을 생성할 수 있고, 스와이프 준비 상태와 스와이프된 상태(180 6)의 검출 사이의 위치 변화를 지시하는 출력을 추가로 제공할 수 있다. 수직 또는 수평 동적 드래그 (drag)제스처는 핀치 열림(pinch open), 핀치 닫힘(pinch closed) 및 핀치 열림 정적 제스처의 조합으로 검출될 수 있다. 예를 들어, 중립 상태로부터, 핀치 열림 정적 제스처의 검출 후 에 핀치 준비 상태로의 전환이 발생한다. 핀치 준비 상태로부터, 핀치 닫힘 정적 제스처의 검출은 핀치 활성화 상태(pinch activated state)로의 전환을 야기한다. 핀치 활성화 상태 및 핀치 닫힌 정적 제스처에 머무르는 것부터, 수직 위치에서의 변화(예: 미리 정의된 임계값보다 큰 변화)는 수직 드래그 상 태로의 전환을 야기한다. 이와 유사하게, 핀치 활성화 상태 및 핀치 닫힌 정적 제스처에 머무르는 것으로부터, 수평 위치에서의 변화(예: 미리 정의된 임계값보다 큰 변화)가 수평 드래그 상태로의 전환을 야기한다. 위치 변화가 수직 변화 및 수평 변화의 조합(예: 위치에서의 대각선 변화)이면, 크기가 더 큰 변화가 상태 전환을 결정하는 데 사용될 수 있다. 다르게는, 위치 변화가 수직 변화 및 수평 변화의 조합이면, 상태 전 환이 인식되지 않을 수 있다. 수직 드래그 상태 또는 수평 드래그 상태에 도달하면, 제스처 인식 서브시스템은 인식된 제스처를 지시하는 출력(예: 제스처 클래스 레이블)을 생성할 수 있고, 수직 위치 또 는 수평 위치에서의 변화를 지시하는 출력을 추가로 제공할 수 있다. 예를 들어, 제스처 인식 서브시스템 은 (예: 입력 프레임에 정의된 좌표에 기반하여) 거리를 계산하고 이 값을 출력할 수 있다. 거리 값은 동적 드 래그 제스처를 드래그 커맨드 입력에 매핑하는 데 사용될 수 있다. 수직 드래그 상태 또는 수평 드래그 상태로부터, 핀치 열림 정적 제스처의 검출은 핀치 준비 상태로의 전환을 야기한다. 핀치 준비 상 태로의 복귀는 동적 드래그 제스처의 끝으로 인식될 수 있다. 위치에서의 변화를 수반하는 동적 제스처의 경우, 제스처 인식 서브시스템은 물리 법칙 및/또는 예상되는 사람 모션에 기반하여 미리 정의된 규칙을 구현하여, 가능한 거짓 양성을 추가로 배제할 수 있다. 예를 들어, 미리 정의된 규칙은 검출된 손이 연속 입력 프레임 간에 미리 정의된 임계값(예: 100 픽셀 이상의 변화)보다 큰 위치에서의 변화를 나타내지 않아야 한다는 것일 수 있다. 상태 기반 제스처 인식을 사용하는 것은 모션 기반 제스처 세분화 및 인식보다 유리할 수 있다. 예를 들어, 정 적 제스처를 검출하는 것과 비교하여, 제스처 모션을 검출하고 처리하는 데 훨씬 더 높은 처리 리소스가 필요할 수 있다. 또한, 상태 기반 제스처 인식은 거짓 양성에 덜 취약할 수 있다. 일부 예에서, 본 개시는 이미지 품질을 개선하는 것을 돕기 위해 이미지 조정을 수행하는 것을 포함하는, 카메 라에 의해 캡처된 프레임 시퀀스의 입력 프레임에서의 손 검출을 위한 방법을 설명한다. 일반적으로, 제스 처 인식 성능은 저조도(low-light) 시나리오에서 저하되는 경향이 있다. 예를 들어, 제스처 제어 디바이스(10 0)가 어두운 방에서 시청 중인 스마트 TV이면, 제스처 제어 디바이스의 카메라가 프레임 시퀀스를 캡 처할 때 스마트 TV의 화면이 유일한 주요 광원일 수 있다. 이 발명에서, 문제를 해결하기 위해 세 가지 방법을 제안한다. 이미지 조정을 위한 일부 예시적인 기술이 아래에서 설명되며, 이들 각각은 예를 들어 손 검출 및 추 적 서브시스템에 의해 구현될 수 있고 조합하여 사용될 수 있다. 도 19는 카메라에 의해 캡처된 프레임 시퀀스에서 이미지 조정을 수행하는 것을 포함하여 손 검출 및 추적 을 수행하기 위한 예시적인 방법을 도시하는 흐름도이다. 방법은 위에서 설명된 단계의 일부 로서 사용될 수 있다. 예를 들어, 방법은 손 검출 및 추적 서브시스템에 의해 구현될 수 있다. 방법 은 단계에 대한 다른 기술을 사용하여 구현될 수 있고, 아래에서 설명되는 이미지 조정이 사용될 수도 있고 사용되지 않을 수도 있음을 이해해야 한다. 방법은 가상 제스처-공간이 정의된 후(예: 단계에서 가상 제스처-공간 생성 서브시스템에 의 해) 시작된다. 1902에서, 카메라에 의해 캡처된 프레임 시퀀스의 이전 입력 프레임에서 손이 이미 검출되었는지가 판정된 다. 손이 이미 검출되었다면, 방법은 단계로 진행할 수 있다. 예를 들어, 이전 입력 프레임에서 손 이 이미 성공적으로 검출되었으면, 이전 입력 프레임에서의 손의 성공적 검출로부터 생성된 바운딩 박스를 (예: 연속 프레임 사이의 시간이 손이 적어도 부분적으로 이전 바운딩 박스 내에 있을 만큼 충분히 짧다는 가정에 기 반하여) 프레임 시퀀스의 현재 입력 프레임에서 손을 추적하기 위한 시작점으로 사용할 수 있다. 또한, 프레임 시퀀스의 이전 입력 프레임에서 손이 성공적으로 검출되었으면, (예: 환경의 광 레벨(light level)이 연속 프레 임 사이의 짧은 시간 동안 크게 변경되지 않아야 한다는 가정에 기반하여) 환경의 조명이 충분하고 이미지 조정 이 필요하지 않은 것으로 간주될 수 있다. 카메라에 의해 캡처된 프레임 시퀀스의 이전 입력 프레임에서 손이 이미 검출되지 않았다면, 방법은 단계로 진행한다. 선택적으로, 1904에서 이미지 조정이 수행된다. 일부 예에서, 이미지 조정이 필요하다고 결정된 경우에만 이미 지 조정이 수행될 수 있다. 예를 들어, 제스처 제어 디바이스의 광 센서는, 주변 광 레벨을 검출하고 광 레벨이 이미지 조정을 필요로 할 만큼 충분히 낮은지를 판정하는 데 사용될 수 있다. 일부 예에서, 입력 이미지 의 적어도 일부의 분석(예: 전체 입력 이미지에 걸쳐, 가상 제스처-공간에만 걸쳐, 또는 손 바운딩 박스에만 걸 쳐)이 수행되어(예: 전체 픽셀 세기 결정 레벨) 이미지 조정이 필요한지를 판정한다. 일부 예에서, 이미지 조정이 필요한지를 먼저 판정하지 않고 이미지 조정이 기본적으로 수행될 수 있다. 이러한 경우에, 이미지가 이미 충분히 조명되어 있으면, 이미지 조정(예: 감마 보정)을 수행해도 이미지가 거의 또는 전혀 변경되지 않을 수 있다. 이미지 조정, 특히 저조도 조건을 보정하기 위해 다양한 기술이 사용될 수 있다. 일부 예에서, 이미지 조정은 (사람 얼굴이 해부학적 특징인 경우에) 프레임 시퀀스의 이전 프레임에서 검출된 얼굴을 참조(reference)로 사용하여 이미지의 조명을 조정하는 것을 포함할 수 있다. 얼굴이 (예: 얼굴 검출 및 추적 서브시스템을 사용하여) 이전 프레임에서 검출되었다고 가정하면, 검출된 얼굴은 입력 프레임에 대한 조명 조정을 수행하기 위한 참조로 사용될 수 있다. 및 를 각각, 미리 정의된(예: 보정을 통해 경험적으로 결정되거나 사전 코딩된) 수단 및 저조 도 및 선호하는 조명 조건에서 캡처된 얼굴 이미지에 대한 픽셀 세기의 표준 편차를 표시하는 것으로 한다. 도 20은 저조도에서 얼굴을 포함하는 이미지를 캡처할 때의 픽셀 세기값의 대표 히스토그램과, 선호하는 조명 조건에서 얼굴을 포함하는 이미지를 캡처할 때의 픽셀 세기값의 대표 히스토그램을 도시하는 그래프 이다. 저조도 픽셀에서 선호하는 조명 픽셀로의 매핑은 다음 수식을 사용하여 계산될 수 있다:"}
{"patent_id": "10-2022-7036600", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이 수식을 사용하여 입력 프레임에 정의된 가상 제스처-공간 내의 모든 픽셀 은 더 나은 손 검출을 위해 위의 매핑 수식을 사용하여 조정된 픽셀 로 변환될 수 있다. 위의 설명은 저조도 조건을 보정하기 위한 조명 조정 에 대해 논의했지만, 유사한 조명 조정을 사용하여 지나치게 밝은 조건을 보정할 수 있음을 이해해야 한다. 일부 예에서, 이미지 조정은 감마 보정(조도 보정의 한 형태로 간주될 수 있음)을 수행하는 것을 포함할 수 있 다. 다양한 감마 보정 기술이 사용될 수 있다. 예를 들어, 를 입력 프레임의 단일 채널의 픽셀 값이라고 하자. 그런 다음 감마 변환은 다음:"}
{"patent_id": "10-2022-7036600", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "과 같이 계산될 수 있으며, 여기서, 는 조정된 픽셀 값이고 는 감마 변환의 표준 파라미터이다. 일부 예에서, 이미지 조정은 제스처 제어 디바이스의 디스플레이를 변경하는 것을 포함할 수 있다. 이 접 근 방식은 제스처 제어 디바이스의 화면이 환경의 조명의 소스인 상황(예: 제스처 제어 디바이스이 텔레비전, 스마트폰 또는 태블릿임)에서 유용할 수 있다. 이러한 접근 방식에서, 저조도 조건이 임의의 적절한 기술을 사용하여 먼저 검출될 수 있다. 예를 들어, 저조도 조건은 제스처 제어 디바이스의 일부일 수 있는 광 센서를 사용하여 검출될 수 있다. 저조도 조건은 또한 입력 프레임의 픽셀 세기를 분석하는 것에 의해 검출 될 수 있고, 대다수의 픽셀이 미리 정의된 세기 임계값 아래로 떨어지면, 저조도 조건이 결정될 수 있다. 저조도 조건이 검출된 후, 제스처 제어 디바이스의 디스플레이 콘텐츠 및/또는 화면의 밝기가, 더 나은 품 질의 이미지를 캡처하기 위해 화면이 더 강한 광원이 되도록 제어될 수 있다. 적응적 제스처 감지 시스템 으로부터의 출력이 입력 프레임이 열악한 조명을 갖는 것으로 분석되었음을 지시하기 위해 통신될 수 있고, 처 리 디바이스는 디스플레이 콘텐츠 및/또는 화면의 밝기를 그에 따라 변경하도록 디스플레이를 제어할 수 있다. 일부 예에서, 저조도 조건의 검출이 (예: 제스처 제어 디바이스의 광 센서를 사용하는) 이미지 분석에 기반하지 않는 경우, 처리 디바이스는 적응적 제스처 감지 시스템으로부터의 임의의 정보 없 이 그에 따라 디스플레이를 제어할 수 있다. 일부 예에서, 이러한 방식으로 디스플레이 콘텐츠 및/또는 밝기를 제어하는 것은 저조도 조건이 검출된 후 및 제스처 입력이 시작된 후(예: 사용자가 제스처 기반 커맨드 입력을 활성화하기 위해 수동으로 입력을 제공 하거나, 또는 인식된 손 제스처가 초기에 검출됨), 수행될 수 있다. 일부 예에서, 제스처 제어 디바이스의 화면은 화면 배경 조명을 더 밝게 변경하도록 제어될 수 있다. 일부 실시예에서, 제스처 제어 디바이스의 화면은 디스플레이된 컨텐츠에 조명 구간(section)을 추가하도록 제어될 수 있다. 조명 구간은 디스플레이의 더 밝은 구간(예: 전체 흰색 구간)일 수 있다. 예를 들어, 도 21a는 정규 조명 조건 하에서, 또는 제스처 입력이 텔레비전 또는 스마트폰과 같은 제스처 제어 디바이스의 디스플레이 상에서 시작되지 않았을 때, 디스플레이될 수 있는 정규 이미지를 도시한다. 저조도 조건이 검출되고 제스처 입력이 시작된 후, 디스플레이되는 콘텐츠는 도 21b의 콘텐츠로 조정될 수 있다. 도 21b에서, 이미지는 크기가 감소되었고 조명 구간이 추가되었다. 이 예에서, 조명 구간 은 디스플레이의 4개의 측면 모두를 따르는 경계선(border)이다. 다른 구간에서, 조명 구간은 단지 한 측면, 2개의 측면, 또는 3개의 측면을 따라 있을 수 있거나, 디스플레이의 하나 이상의 측면을 따라 불연속 적인 구간을 포함할 수 있다. 조명 구간의 밝기, 색조(hue) 및/또는 크기(예: 두께 및 길이)는 검출된 저 조도 조건에 기반하여 자동으로 조정될 수 있다. 예를 들어, (예: 검출된 픽셀 세기에 기반하여, 또는 광 센서 의 출력에 기반하여) 미리 정의된 임계값에서 상이한 저조도 레벨이 있을 수 있고, 조명 구간에 대한 상 이한 파라미터가 상이한 저조도 레벨에서 미리 정의될 수 있다. 일반적으로, 더 낮은 광 레벨은 더 크거나, 및/ 또는 더 밝은 조명 구간을 필요로 할 수 있다. 도 19로 돌아가면, 1906에서, (예: 손 검출 및 추적 서브시스템을 사용하여) 가상 제스처-공간에서 손 검 출이 수행된다. 손 검출 및 추적 서브시스템은 전술한 바와 같이 이미지에서 손을 검출하도록 구성 된 트레이닝된 신경망을 포함할 수 있다. 트레이닝된 신경망을 사용하는 손 검출 및 추적 서브시스템에 의 한 성공적인 손 검출은 가상 제스처-공간에서 검출된 손에 대해 정의된 바운딩 박스를 출력할 수 있다. 1908에서, 손 추적이, 검출된 손에 대해 정의된 바운딩 박스에 기반하여 손 검출 및 추적 서브시스템을 사 용하여 수행된다. 바운딩 박스는 추적을 기반으로 업데이트될 수 있다. 손 검출 및 추적으로부터의 정보(예: 손에 대해 정의된 바운딩 박스)는 (예: 제스처 인식 서브시스템에 의 해) 제스처 인식을 위해 제공될 수 있다. 다양한 예에서, 본 개시는 제스처 입력을 검출하고 인식하기 위한 정확도 및 효율성을 개선하는 것을 돕는 시스 템 및 방법을 설명한다. 본 개시는 복잡한 환경에서 제스처 입력을 검출 및 인식하거나 및/또는 제스처의 장거 리 검출하는 데 유용할 수 있다. 위에서 설명된 방법(예: 적응적 ROI 기술, 바운딩 박스 리파인먼트 조인트 네트워크, 가상 제스처-공간, 이미지 조정, 상태 기반 제스처 인식) 중 하나 이상을 사용하면, 복잡한 실생활 시나리오에서도 제스처 입력의 보다 강 력한 검출 및 인식을 가능하게 한다. 제스처 검출의 개선된 정확도는 캡처된 입력 프레임의 더 효율적인 처리를 가능하게 할 수 있다. 일부 예에서, 입력 프레임은 이미지 캡처의 레이트보다 낮은 빈도로 처리될 수 있다. 예 를 들어, 입력 프레임마다의 처리 대신에, N(N>1)개의 프레임마다 얼굴(또는 기타 구별되는 해부학적 특징)과 손 검출 및 추적을 위해 처리된다. N은 사용자가 선택하거나, 사전 프로그래밍될 수 있거나, 제스처 제어 디바이스에 의해 자동으로 선택될 수 있는 파라미터일 수 있다(예: 미리 정의된 임계값 미만의 레이트로 이미 지가 캡처될 때 N은 1일 수 있으며; 이미지가 미리 정의된 임계값 이상으로 캡처된 경우 N은 2 이상일 수 있고; 이미지 품질이 좋지 않거나 해상도가 낮을 때 N은 1일 수 있고; 이미지 해상도가 높을 때 N은 2 이상일 수 있음). N(N>1)개의 프레임 마다 처리하는 것에 의해, 제스처 검출 및 인식은 여전히 거의 실시간으로 여전히 높 은 정확도로 수행될 수 있으며, 제스처 제어 디바이스에 필요한 처리 리소스가 감소될 수 있다. 본 개시는 얼굴 및 손 검출을 위해 신경망을 사용하는 예시적인 구현을 개시한다. 제스처 분류 및 인식의 정확 도를 향상시키는 데 도움이 되도록 손 바운딩 박스를 개선할 수 있는 예시적인 조인트 신경망이 설명되어 있다. 일부 예에서, 가상 제스처-공간이 설명되며, 이는 검출된 사람의 얼굴(또는 다른 구별되는 해부학적 특징)에 기 반하여 정의될 수 있다. 손 검출을 위해 정의된 가상 제스처-공간을 사용함으로써, 손 제스처의 보다 정확하고 및/또는 효율적인 검출이 달성될 수 있다. 일부 예에서, 가상 제스처-공간은 추가로, 특정 서브공간에 대한 제 스처 입력이 마우스 입력에 매핑될 수 있는 서브공간으로 추가로 정의될 수 있다. 따라서, 가상 제스처-공간은 가상 마우스로 사용될 수 있다. 디스플레이 및 카메라를 갖는 제스처 제어 디바이스(예: 스마트 TV, 스마트폰 또는 태블릿)와 관련하여 예가 설 명되었지만, 본 개시는 디스플레이 및/또는 카메라를 포함하거나 포함하지 않을 수 있는 다른 제스처 제어 디바 이스와 관련될 수 있다. 예를 들어, 본 개시는 스마트 스피커, 스마트 가전, 사물 인터넷(Internet of things, IoT) 디바이스, 대시보드 디바이스(예: 차량에 설치됨) 또는 계산 리소스가 적은 디바이스와 관련될 수 있다. 여기에 설명된 예는 인공 현실(artificial reality, AR), 가상 현실(virtual reality, VR) 및/또는 비디오 게 임 애플리케이션에 적용될 수 있다. 본 개시는 특정 순서의 단계를 갖는 방법 및 프로세스를 설명하지만, 방법 및 프로세스의 하나 이상의 단계는 적절하게 생략되거나 변경될 수 있다. 하나 이상의 단계는 적절하게, 설명된 순서 이외의 순서로 수행될 수 있 다. 본 개시가 방법의 측면에서 적어도 부분적으로 설명되지만, 당업자는 본 개시가 또한 본 개시가 설명된 방법의 측면 및 특징의 적어도 일부를 수행하기 위한 다양한 컴포넌트에 관한 것이며, 하드웨어 컴포넌트, 소프트웨어 또는 이 둘의 조합을 통해 이루어짐을 이해할 것이다. 따라서, 본 개시의 기술 솔루션은 소프트웨어 제품의 형 태로 구현될 수 있다. 적절한 소프트웨어 제품은 미리 기록된 저장 디바이스 또는 예를 들어, DVD, CD-ROM, USB 플래시 디스크, 이동식 하드 디스크, 또는 다른 저장 매체를 포함하는, 다른 유사한 컴퓨터가 판독 가능한 비휘 발성 또는 비일시적 매체에 저장될 수 있다. 소프트웨어 제품은 처리 디바이스(예: 개인용 컴퓨터, 서버 또는 네트워크 디바이스)가 여기에 개시된 방법의 예를 실행할 수 있게 하는 유형으로 저장된 명령어를 포함한다. 본 개시는 청구범위의 요지를 벗어나지 않고 다른 구체적인 형태로 구체화될 수 있다. 설명된 예시적인 실시예 는 모든 면에서 단지 예시적인 것이며 제한적인 것이 아닌 것으로 간주되어야 한다. 전술한 실시예 중 하나 이 상으로부터 선택된 특징은 명시적으로 설명되지 않은 대안적인 실시예를 생성하기 위해 조합될 수 있으며, 이러 한 조합에 적합한 특징은 본 개시의 범위 내에서 이해된다. 개시된 범위 내의 모든 값 및 서브 범위도 개시된다. 또한, 여기에 개시되고 도시된 시스템, 디바이스 및 프로 세스가 특정 수의 엘리먼트/컴포넌트를 포함할 수 있지만, 시스템, 디바이스 및 어셈블리는 이러한 엘리먼트/컴 포넌트의 추가 또는 더 적은 수를 포함하도록 수정될 수 있다. 예를 들어, 개시된 엘리먼트/컴포넌트 중 임의의 것이 단수인 것으로 언급될 수 있지만, 여기에 개시된 실시예는 복수의 이러한 엘리먼트/컴포넌트를 포함하도록 수정될 수 있다. 여기에 설명된 주제는 기술의 모든 적절한 변경을 커버하고 포괄한다.도면 도면1 도면2 도면3a 도면3b 도면3c 도면3d 도면3e 도면3f 도면3g 도면3h 도면4a 도면4b 도면4c 도면5 도면6 도면7 도면8a 도면8b 도면9 도면10a 도면10b 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21a 도면21b"}
{"patent_id": "10-2022-7036600", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이제 예로서, 본 출원의 예시적인 실시예를 도시하는 첨부 도면을 참조할 것이며, 여기서: 도 1은 예시적인 제스처 제어 디바이스와 상호작용하는 사용자를 도시하는 블록도이다. 도 2는 예시적인 제스처 제어 디바이스의 일부 컴포넌트를 도시하는 블록도이다. 도 3a 내지 도 3h는 예시적인 제스처 제어 디바이스에 의해 검출 및 인식될 수 있는 일부 예시적인 제스처 클래 스를 도시한다. 도 4a 내지 도 4c는 예시적인 제스처 제어 디바이스에 의해 검출 및 인식될 수 있는 일부 예시적인 동적 제스처 를 도시한다. 도 5는 예시적인 제스처 제어 디바이스에서 구현될 수 있는 예시적인 적응적 제스처 감지 시스템의 일부 세부사 항을 도시하는 블록도이다. 도 6은 가상 제스처-공간을 사용하는 손 검출을 위한 예시적인 방법을 도시하는 흐름도이다. 도 7은 가상 마우스를 구현하기 위해 정의된 서브공간을 포함하는 가상 제스처-공간의 예를 도시한다. 도 8a 및 도 8b는 2D 및 3D 가상 제스처-공간의 예를 도시한다. 도 9는 검출된 손에 기반한 손 검출 및 가상 제스처-공간 재정의를 위한 예시적인 방법을 도시하는 흐름도이다. 도 10a 및 10b는 도 9의 방법의 예시적인 구현을 도시한다. 도 11은 사용자 리스트의 구현과 함께, 가상 제스처-공간을 사용하는 손 검출을 위한 예시적인 방법을 도시하는 흐름도이다. 도 12는 적응적 ROI를 사용하여 검출을 수행하는 예시적인 방법을 도시하는 흐름도이다.도 13은 도 12의 방법에서 사용될 수 있는 예시적인 ROI 시퀀스를 도시한다. 도 14는 제스처 인식을 위해 사용될 수 있는 예시적인 조인트 네트워크를 도시하는 블록도이다. 도 15 및 16은 도 14의 조인트 네트워크를 트레이닝하는 데 사용될 수 있는 일부 예시적인 트레이닝 데이터 샘 플을 도시한다. 도 17은 제스처 인식을 위한 예시적인 방법을 도시하는 흐름도이다. 도 18은 상태 기반 제스처 인식의 일 예를 도시하는 상태도이다. 도 19는 이미지 조정을 포함하는, 손 검출을 위한 예시적인 방법을 도시하는 흐름도이다. 도 20은 픽셀 세기에 기반한 이미지 조정의 일 예를 도시하는 그래프이다. 도 21a 및 도 21b는 디스플레이되는 컨텐츠에 조명 구간을 추가하는 것을 포함하는 이미지 조정의 일 예를 도시 한다. 유사한 컴포넌트를 표시하기(denote) 위해 유사한 참조 번호가 상이한 도면에서 사용될 수 있다."}
