{"patent_id": "10-2023-7037479", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0169188", "출원번호": "10-2023-7037479", "발명의 명칭": "이상 탐지 시스템 및 방법", "출원인": "비트데펜더 아이피알 매니지먼트 엘티디", "발명자": "안드레이 엠., 마놀라케"}}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터로 구현되는 이상 탐지 방법으로서,토큰 시퀀스들의 트레이닝 코퍼스로부터 트레이닝 토큰 시퀀스를 선택하는 것에 응답으로, 그리고 미리 결정된복수의 시퀀스 변환들로부터 변환(transformation)을 선택하는 것에 응답으로, 상기 선택된 변환을 상기 트레이닝 토큰 시퀀스에 적용하여 수정된 토큰 시퀀스를 생성하는 단계;조정가능한 파라미터들의 세트를 가지며, 상기 수정된 토큰 시퀀스에 따라 변환 예측 표시자(transformationprediction indicator)를 결정하도록 구성되는 시퀀스 분석기를 실행하는 단계로서, 상기 변환 예측 표시자는상기 선택된 변환이 상기 수정된 토큰 시퀀스를 생성하기 위해 적용되었을 가능성을 나타내도록 구성되는 시퀀스 분석기를 실행하는 단계;상기 예측 표시자를 결정하는 것에 응답으로, 상기 변환 예측 표시자에 따라 상기 조정가능한 파라미터들의 세트의 적어도 하나의 파라미터를 조정하는 단계; 및 상기 적어도 하나의 파라미터를 조정하는 것에 응답으로, 상기 시퀀스 분석기를 채용하여 타겟 토큰 시퀀스가변칙적인지(이상한지, anomalous) 여부를 결정하는 단계를 수행하기 위하여, 컴퓨터 시스템의 적어도 하나의 하드웨어 프로세서를 채용하는 것을 포함하는, 컴퓨터로 구현되는 이상 탐지 방법."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 선택된 변환을 적용하는 것은 상기 트레이닝 토큰 시퀀스의 선택된 토큰을 대체 토큰으로 교체하는 것을포함하는 것을 특징으로 하는, 컴퓨터로 구현되는 이상 탐지 방법."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,조정가능한 파라미터들의 또 다른 세트를 가지고 상기 트레이닝 토큰 시퀀스에 따라 상기 대체 토큰을 생성하도록 구성되는 토큰 발생기를 실행하는 것; 및 상기 변환 예측 표시자를 결정하는 것에 응답으로, 상기 변환 예측 표시자에 따라 조정가능한 파라미터들의 다른 세트의 또 다른 파라미터를 조정하는 것;을 추가로 포함하는 것을 특징으로 하는, 컴퓨터로 구현되는 이상탐지 방법."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 선택된 변환을 적용하는 것은, 상기 트레이닝 토큰 시퀀스의 선택된 토큰을 삭제하는 것, 상기 트레이닝토큰 시퀀스에 추가적인 토큰을 삽입하는 것, 그리고 상기 트레이닝 토큰 시퀀스의 토큰의 선택된 서브세트를치환하는 것으로 구성되는 그룹으로 선택된 아이템을 포함하는 것을 특징으로 하는, 컴퓨터로 구현되는 이상 탐지 방법."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 시퀀스 분석기는, 상기 수정된 토큰 시퀀스에 따라 토큰 예측 표시자를 결정하도록 추가적으로 구성되며,상기 토큰 예측 표시자는 상기 수정된 토큰 시퀀스의 선택된 토큰이 상기 선택된 변환의 적용에 의해 변경되었다는 가능성을 나타내고; 그리고공개특허 10-2023-0169188-3-상기 적어도 하나의 조정가능한 파라미터를 조정하는 것은, 추가로 상기 토큰 예측 표시자에 따라 상기 적어도하나의 조정가능한 파라미터를 조정하는 것을 포함하는 것을 특징으로 하는, 컴퓨터로 구현되는 이상 탐지방법."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 트레이닝 토큰 시퀀스 및 상기 타겟 토큰 시퀀스는 자연어로 표현된(formulated) 텍스트로 구성되고; 그리고상기 방법은, 상기 타겟 토큰 시퀀스가 변칙적인지 여부를 결정하는 것에 응답으로, 상기 타겟 토큰 시퀀스가변칙적인 경우, 상기 타겟 토큰 시퀀스의 작성자가 상기 트레이닝 토큰 시퀀스의 작성자와 다르다고 결정하는것을 추가로 포함하는 것을 특징으로 하는, 컴퓨터로 구현되는 이상 탐지 방법."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 트레이닝 토큰 시퀀스 및 상기 타겟 토큰 시퀀스는 자연어로 표현된(formulated) 텍스트로 구성되고; 그리고상기 방법은, 상기 타겟 토큰 시퀀스가 변칙적인지 여부를 결정하는 것에 응답으로, 상기 타겟 토큰 시퀀스가변칙적인 경우, 상기 타겟 토큰 시퀀스의 주제(subject matter)가 상기 트레이닝 토큰 시퀀스의 주제와 다르다고 결정하는 것을 추가로 포함하는 것을 특징으로 하는, 컴퓨터로 구현되는 이상 탐지 방법."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 트레이닝 토큰 시퀀스 및 상기 타겟 토큰 시퀀스는 자연어로 표현된(formulated) 텍스트로 구성되고; 그리고상기 방법은, 상기 타겟 토큰 시퀀스가 변칙적인지 여부를 결정하는 것에 응답으로, 상기 타겟 토큰 시퀀스가변칙적인 경우, 상기 타겟 토큰 시퀀스가 기계-생성된 것으로 결정하는 것을 추가로 포함하는 것을 특징으로 하는, 컴퓨터로 구현되는 이상 탐지 방법."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 트레이닝 코퍼스는 선택 기준에 따라 선택된 텍스트 조각으로 구성되고; 그리고상기 방법은, 상기 타겟 토큰 시퀀스가 변칙적인지 여부를 결정하는 것에 응답으로, 상기 타겟 토큰 시퀀스가변칙적인 경우, 상기 타겟 토큰 시퀀스가 상기 선택 기준을 만족하지 않는다고 결정하는 것을 추가로 포함하는것을 특징으로 하는, 컴퓨터로 구현되는 이상 탐지 방법."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 트레이닝 토큰 시퀀스 및 상기 타겟 토큰 시퀀스는 컴퓨팅 이벤트의 시퀀스로 구성되고; 그리고상기 방법은, 상기 타겟 토큰 시퀀스가 변칙적인지 여부를 결정하는 것에 응답으로, 상기 타겟 토큰 시퀀스가변칙적인 경우, 상기 타겟 토큰 시퀀스가 컴퓨터 보안 위협을 나타낸다고 결정하는 것을 추가로 포함하는 것을특징으로 하는, 컴퓨터로 구현되는 이상 탐지 방법."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "컴퓨터 시스템으로서, 토큰 시퀀스들의 트레이닝 코퍼스로부터 트레이닝 토큰 시퀀스를 선택하는 것에 응답으로, 그리고 미리 결정된공개특허 10-2023-0169188-4-복수의 시퀀스 변환들로부터 변환(transformation)을 선택하는 것에 응답으로, 상기 선택된 변환을 트레이닝 토큰 시퀀스에 적용하여 수정된 토큰 시퀀스를 생성하도록;조정가능한 파라미터들의 세트를 가지고 상기 수정된 토큰 시퀀스에 따라 변환 예측 표시자(transformationprediction indicator)를 결정하도록 구성되는 시퀀스 분석기를 실행하도록(이 때, 상기 변환 예측 표시자는 상기 선택된 변환이 상기 수정된 토큰 시퀀스를 생성하기 위해 적용되었을 가능성을 나타내도록 구성됨);상기 예측 표시자를 결정하는 것에 응답으로, 상기 변환 예측 표시자에 따라 상기 조정가능한 파라미터들의 세트의 적어도 하나의 파라미터를 조정하도록; 그리고,상기 적어도 하나의 파라미터를 조정하는 것에 응답으로, 상기 시퀀스 분석기를 실행하여 타겟 토큰 시퀀스가변칙적인지 여부를 결정하도록; 구성되는 적어도 하나의 하드웨어 프로세서를 포함하는, 컴퓨터 시스템."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 선택된 변환을 적용하는 것은 상기 트레이닝 토큰 시퀀스의 선택된 토큰을 대체 토큰으로 교체하는 것을포함하는 것을 특징으로 하는, 컴퓨터 시스템."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 적어도 하나의 하드웨어 프로세서는,조정가능한 파라미터들의 또 다른 세트를 가지고 상기 트레이닝 토큰 시퀀스에 따라 상기 대체 토큰을 생성하도록 구성되는 토큰 발생기를 실행하도록; 그리고 상기 변환 예측 표시자를 결정하는 것에 응답으로, 상기 변환 예측 표시자에 따라 조정가능한 파라미터들의 다른 세트의 또 다른 파라미터를 조정하도록; 추가로 구성되는 것을 특징으로 하는, 컴퓨터 시스템."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서, 상기 선택된 변환을 적용하는 것은, 상기 트레이닝 토큰 시퀀스의 선택된 토큰을 삭제하는 것, 상기 트레이닝토큰 시퀀스에 추가적인 토큰을 삽입하는 것, 그리고 상기 트레이닝 토큰 시퀀스의 토큰의 선택된 서브세트를치환하는 것으로 구성되는 그룹으로 선택된 아이템을 포함하는 것을 특징으로 하는, 컴퓨터 시스템."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서, 상기 시퀀스 분석기는, 상기 수정된 토큰 시퀀스에 따라 토큰 예측 표시자를 결정하도록 추가적으로 구성되며,상기 토큰 예측 표시자는 상기 수정된 토큰 시퀀스의 선택된 토큰이 상기 선택된 변환의 적용에 의해 변경되었다는 가능성을 나타내고; 그리고상기 적어도 하나의 조정가능한 파라미터를 조정하는 것은, 추가로 상기 토큰 예측 표시자에 따라 상기 적어도하나의 조정가능한 파라미터를 조정하는 것을 포함하는 것을 특징으로 하는, 컴퓨터 시스템."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서, 상기 트레이닝 토큰 시퀀스 및 상기 타겟 토큰 시퀀스는 자연어로 표현된(formulated) 텍스트로 구성되고; 그리고상기 방법은, 상기 타겟 토큰 시퀀스가 변칙적인지 여부를 결정하는 것에 응답으로, 상기 타겟 토큰 시퀀스가변칙적인 경우, 상기 타겟 토큰 시퀀스의 작성자가 상기 트레이닝 토큰 시퀀스의 작성자와 다르다고 결정하는것을 추가로 포함하는 것을 특징으로 하는, 컴퓨터 시스템.공개특허 10-2023-0169188-5-청구항 17 제11항에 있어서, 상기 트레이닝 토큰 시퀀스 및 상기 타겟 토큰 시퀀스는 자연어로 표현된(formulated) 텍스트로 구성되고; 그리고상기 방법은, 상기 타겟 토큰 시퀀스가 변칙적인지 여부를 결정하는 것에 응답으로, 상기 타겟 토큰 시퀀스가변칙적인 경우, 상기 타겟 토큰 시퀀스의 주제(subject matter)가 상기 트레이닝 토큰 시퀀스의 주제와 다르다고 결정하는 것을 추가로 포함하는 것을 특징으로 하는, 컴퓨터 시스템."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서, 상기 트레이닝 토큰 시퀀스 및 상기 타겟 토큰 시퀀스는 자연어로 표현된(formulated) 텍스트로 구성되고; 그리고상기 방법은, 상기 타겟 토큰 시퀀스가 변칙적인지 여부를 결정하는 것에 응답으로, 상기 타겟 토큰 시퀀스가변칙적인 경우, 상기 타겟 토큰 시퀀스가 기계-생성된 것으로 결정하는 것을 추가로 포함하는 것을 특징으로 하는, 컴퓨터 시스템."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서, 상기 트레이닝 코퍼스는 선택 기준에 따라 선택된 텍스트 조각으로 구성되고; 그리고상기 방법은, 상기 타겟 토큰 시퀀스가 변칙적인지 여부를 결정하는 것에 응답으로, 상기 타겟 토큰 시퀀스가변칙적인 경우, 상기 타겟 토큰 시퀀스가 상기 선택 기준을 만족하지 않는다고 결정하는 것을 추가로 포함하는것을 특징으로 하는, 컴퓨터 시스템."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서, 상기 트레이닝 토큰 시퀀스 및 상기 타겟 토큰 시퀀스는 컴퓨팅 이벤트의 시퀀스로 구성되고; 그리고상기 방법은, 상기 타겟 토큰 시퀀스가 변칙적인지 여부를 결정하는 것에 응답으로, 상기 타겟 토큰 시퀀스가변칙적인 경우, 상기 타겟 토큰 시퀀스가 컴퓨터 보안 위협을 나타낸다고 결정하는 것을 추가로 포함하는 것을특징으로 하는, 컴퓨터 시스템."}
{"patent_id": "10-2023-7037479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "컴퓨터 시스템의 적어도 하나의 하드웨어 프로세서에 의해 실행될 때, 상기 컴퓨터 시스템으로 하여금, 토큰 시퀀스들의 트레이닝 코퍼스로부터 트레이닝 토큰 시퀀스를 선택하는 것에 응답으로, 그리고 미리 결정된복수의 시퀀스 변환들로부터 변환(transformation)을 선택하는 것에 응답으로, 상기 선택된 변환을 상기 트레이닝 토큰 시퀀스에 적용하여 수정된 토큰 시퀀스를 생성하도록 하고;조정가능한 파라미터들의 세트를 가지며, 상기 수정된 토큰 시퀀스에 따라 변환 예측 표시자(transformationprediction indicator)를 결정하도록 구성되는 시퀀스 분석기를 실행하도록 하고(이 때, 상기 변환 예측 표시자는 상기 선택된 변환이 상기 수정된 토큰 시퀀스를 생성하기 위해 적용되었을 가능성을 나타내도록 구성됨);상기 예측 표시자를 결정하는 것에 응답으로, 상기 변환 예측 표시자에 따라 상기 조정가능한 파라미터들의 세트의 적어도 하나의 파라미터를 조정하도록 하고; 그리고 상기 적어도 하나의 파라미터를 조정하는 것에 응답으로, 상기 시퀀스 분석기를 실행하여 타겟 토큰 시퀀스가변칙적인지 여부를 결정하도록 하는, 명령들을 저장하는 비-일시적 컴퓨터 판독가능 매체(non-transitorycomputer-readable medium).공개특허 10-2023-0169188-6-"}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일부 실시예들은 자연 언어 프로세싱 및 컴퓨터 보안과 같은 어플리케이션들에서 비정상 탐지를 위해 인공 지능 시스템(예를 들어, 심층 신경망들의 세트)을 트레이닝하는 새로운 절차를 채용한다. 트레이닝 코퍼스로부터 선택 된 토큰 시퀀스들은, 시퀀스 분석기에 공급되기 전에, 복수의 미리 결정된 시퀀스 변환들 중 적어도 하나에 따라 왜곡된다. 차례로 상기 시퀀스 분석기는 각 입력 토큰 시퀀스를 생성하는 데 어떤 변환이 사용되었는지 올바르게 추측하도록 학습된다."}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능에 관한 것으로서, 특히 자연어 처리 및 컴퓨터 보안 어플리케이션을 위한 데이터의 이상 (anomaly)을 자동으로 탐지하기 위한 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능(AI) 및 기계 학습 기술은 특히 패턴 인식, 자동 분류 및 이상 탐지와 같은 어플리케이션을 위해 대량 의 데이터를 처리하는 데 점점 더 많이 사용되고 있다. 이상 탐지는 참조 그룹(기준 그룹, reference group) 의 해 집합적으로 정의된 표준 또는 '정상'에서 실질적으로 벗어난 표본을 식별하는 것에 해당한다. 이상 탐지는 정상(normality)의 의미와 경계가 명확하지 않거나 선험적으로 정의되지 않을 수 있는 복잡한 데이터의 경우 상 당한 기술적 도전을 가져올 수 있다. 데이터로부터 정교한 모델을 자동으로 추론할 수 있는 이들의 기능으로, 최신 인공 지능 시스템(예: 심층 신경망, deep neural network)은 이러한 작업을 잘 수행하는 것으로 나타났다."}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "그러나 이상 탐지기를 훈련하기 위해 기계 학습을 구현하는 것은 그 자체적인 여러 기술적 도전을 제기한다. 종 래의 접근법들 중 일부에서, 훈련은 극단적인 컴퓨팅 비용을 발생시킬 수 있고, 매우 큰 트레이닝 코퍼스 (corpus)를 필요로 할 수 있고, 불안정하고 그리고/또는 비효율적일 수 있다. 따라서 자연어 처리 및 컴퓨터 보 안 어플리케이션을 위한 이상 탐지기를 훈련하는 새로운 탐지기 아키텍처와 새로운 방법을 개발할 상당한 필요 가 있다."}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 태양에 따르면, 컴퓨터로 구현되는 이상 탐지 방법은, 토큰 시퀀스들의 트레이닝 코퍼스로부터 트 레이닝 토큰 시퀀스를 선택하는 것에 응답으로, 그리고 미리 결정된 복수의 시퀀스 변환들로부터 변환 (transformation)을 선택하는 것에 응답으로, 컴퓨터 시스템의 적어도 하나의 하드웨어 프로세서를 채용하여 상 기 선택된 변환을 트레이닝 토큰 시퀀스에 적용하여 수정된 토큰 시퀀스를 생성하는 것을 포함한다. 상기 방법 은 조정가능한 파라미터들의 세트를 가지며, 상기 수정된 토큰 시퀀스에 따라 변환 예측 표시자(transformation prediction indicator)를 결정하도록 구성되는 시퀀스 분석기를 실행하는 것을 추가로 포함하고, 상기 변환 예 측 표시자는 상기 선택된 변환이 상기 수정된 토큰 시퀀스를 생성하기 위해 적용되었을 가능성을 나타낸다. 상 기 방법은 또한, 상기 예측 표시자를 결정하는 것에 응답으로, 상기 변환 예측 표시자에 따라 상기 조정가능한 파라미터들의 세트의 적어도 하나의 파라미터를 조정하는 것, 및 상기 적어도 하나의 파라미터를 조정하는 것에 응답으로, 상기 시퀀스 분석기를 채용하여 타겟 토큰 시퀀스가 변칙적인지(이상한지, anomalous) 여부를 결정하 는 것을 포함한다. 본 발명의 또 다른 태양에 따르면, 컴퓨터 시스템은, 토큰 시퀀스들의 트레이닝 코퍼스로부터 트레이닝 토큰 시 퀀스를 선택하는 것에 응답으로, 그리고 미리 결정된 복수의 시퀀스 변환들로부터 변환(transformation)을 선택 하는 것에 응답으로, 상기 선택된 변환을 트레이닝 토큰 시퀀스에 적용하여 수정된 토큰 시퀀스를 생성하도록 구성된 적어도 하나의 하드웨어 프로세서를 포함한다. 상기 적어도 하나의 하드웨어 프로세서는 추가적으로, 조 정가능한 파라미터들의 세트를 가지고 상기 수정된 토큰 시퀀스에 따라 변환 예측 표시자(transformation prediction indicator)를 결정하도록 구성되는 시퀀스 분석기를 실행하도록 구성되고, 상기 변환 예측 표시자는 상기 선택된 변환이 상기 수정된 토큰 시퀀스를 생성하기 위해 적용되었을 가능성을 나타낸다. 상기 적어도 하 나의 하드웨어 프로세서는 추가적으로, 상기 예측 표시자를 결정하는 것에 응답으로, 상기 변환 예측 표시자에 따라 상기 조정가능한 파라미터들의 세트의 적어도 하나의 파라미터를 조정하도록, 그리고, 상기 적어도 하나의 파라미터를 조정하는 것에 응답으로, 상기 시퀀스 분석기를 실행하여 타겟 토큰 시퀀스가 변칙적인지 여부를 결 정하도록 구성된다. 본 발명의 또 다른 태양에 따르면, 비-일시적 컴퓨터 판독가능 매체(non-transitory computer-readable medium)는, 컴퓨터 시스템의 적어도 하나의 하드웨어 프로세서에 의해 실행될 때, 상기 컴퓨터 시스템으로 하여 금, 토큰 시퀀스들의 트레이닝 코퍼스로부터 트레이닝 토큰 시퀀스를 선택하는 것에 응답으로, 그리고 미리 결정된 복수의 시퀀스 변환들로부터 변환을 선택하는 것에 응답으로, 상기 선택된 변환을 상기 트레이닝 토큰 시 퀀스에 적용하여 수정된 토큰 시퀀스를 생성하도록 하는 명령들을 저장한다. 상기 명령은 추가적으로 상기 컴퓨 터 시스템으로 하여금 조정가능한 파라미터들의 세트를 가지며, 상기 수정된 토큰 시퀀스에 따라 변환 예측 표 시자(transformation prediction indicator)를 결정하도록 구성되는 시퀀스 분석기를 실행하도록 하고, 상기 변환 예측 표시자는 상기 선택된 변환이 상기 수정된 토큰 시퀀스를 생성하기 위해 적용되었을 가능성을 나타낸 다. 상기 명령은 또한, 상기 컴퓨터 시스템으로 하여금 상기 예측 표시자를 결정하는 것에 응답으로, 상기 변환 예측 표시자에 따라 상기 조정가능한 파라미터들의 세트의 적어도 하나의 파라미터를 조정하도록 하고, 그리고 상기 적어도 하나의 파라미터를 조정하는 것에 응답으로, 상기 시퀀스 분석기를 실행하여 타겟 토큰 시퀀스가 변칙적인지 여부를 결정하도록 한다."}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하의 설명에서, 구조들 사이에서 언급된 모든 연결들은 직접적인 동작 연결들 (operative connections) 또는 매개 구조들을 통한 간접적인 동작 연결들일 수 있는 것으로 이해된다. 구성 요소들의 세트는 하나 이상의 구성 요소를 포함한다. 구성 요소의 임의의 열거는 적어도 하나의 구성 요소를 언급하는 것으로 이해된다. 복수의 구 성 요소는 적어도 2개의 구성 요소를 포함한다. 달리 특정되지 않는다면, \"또는(OR)\"의 어떠한 사용도 비배타적 인 \"또는\"을 의미한다. 달리 요구되지 않는다면, 기술된 어떠한 방법 단계들도 설명된 특정 순서로 반드시 실행 될 필요는 없다. 제2 구성 요소로부터 유도되는 제1 구성 요소(예컨대, 데이터)는 제2 구성 요소와 동일한 제1 구성 요소는 물론, 제2 구성 요소 그리고 선택적으로는 다른 데이터를 처리하는 것에 의해 생성된 제1 구성 요 소를 포함한다. 파라미터에 따라 결정 또는 판정하는 것은 파라미터에 따라 그리고 선택적으로는 다른 데이터에 따라 결정 또는 판정하는 것을 포함한다. 달리 구체화되지 않는다면, 일부 수량/데이터의 표시자는 수량/데이터 그 자체, 또는 수량/데이터 그 자체와 상이한 표시자일 수 있다. 컴퓨터 프로그램은 과업을 수행하는 프로세서 명령들의 시퀀스이다. 본 발명의 일부 실시예들에서 설명되는 컴퓨터 프로그램들은 독립형 소프트웨어 개체들 또는 다른 컴퓨터 프로그램들의 서브-개체들(예를 들어, 서브루틴들, 라이브러리들)일 수 있다. 컴퓨터 판독 가 능 매체는 자성, 광, 및 반도체 저장 매체와 같은 비-일시적 매체(non-transitory media)(예컨대, 하드 드라이 브, 광 디스크, 플래시 메모리, DRAM)는 물론, 전도성 케이블 및 파이버 옵틱 링크와 같은 통신 링크들을 포함 한다. 일부 실시예들에 따르면, 본 발명은, 그 중에서도, 본원에 설명된 방법들을 수행하기 위해 프로그래밍된 하드웨어(예컨대, 하나 이상의 프로세서들)는 물론, 본원에서 설명된 방법들을 수행하기 위한 명령들을 인코딩 하는 컴퓨터-판독 가능 매체를 포함하는 컴퓨터 시스템을 제공한다.후술하는 설명은 본 발명의 실시예들을 예시적으로 설명하는 것이며, 반드시 제한적인 것은 아니다. 도 1 은 본 발명의 일부 실시예들에 따른 데이터에서 이상들을 탐지하기 위해 유틸리티 서버와 협력할 수 있는 클라이언트 시스템들(10a-c)의 예시적인 세트를 보여준다. 여기에서 이상(비정상, 변칙)은 항목의 참조 컬 렉션/코퍼스로 집합적으로 표시되는 표준 또는 '정상'에서 실질적으로 벗어난 항목을 나타내는 것으로 이해된다. 본 명세서의 설명은 변칙적인 텍스트 조각(fragment)과 컴퓨팅 이벤트 시퀀스들과 같은 변칙적인 토 큰 시퀀스를 탐지하는 데 중점을 둔다. 이러한 실시예들에서, 예시적인 이상 탐지는 타겟 텍스트의 저자(작성자, author)가 참조 텍스트의 저자와 다르다고 결정하는 것을 포함한다. 또 다른 예시적인 이상 탐지 는 컴퓨팅 이벤트들의 시퀀스가 각각의 컴퓨터의 정상적인 동작으로부터 벗어나는 것을 결정하는 것을 포함하여, 아마도 보안 위반 또는 악성 소프트웨어의 존재를 나타낼 수 있다. 몇 가지 예시적인 이상 탐지 사용 사례 시나리오가 아래에 설명되어 있다. 클라이언트 시스템들(10a-c)은 총칭적으로 프로세서, 메모리, 및 통신 인터페이스를 가지는 임의의 전자 장치를 나타낸다. 예시적인 클라이언트 시스템들(10a-c)은 특히 개인용 컴퓨터, 기업 메인프레임 컴퓨터(corporate mainframe computers), 서버, 랩탑, 태블릿 컴퓨터, 모바일 통신 장치(mobile telecommunication device)(예를 들어서, 스마트폰), 미디어 플레이어, TV, 게임 컨솔, 홈 어플라이언스, 및 웨어러블 장치들(예를 들어서, 스마 트워치)을 포함한다. 도시된 클라이언트 시스템들은 근거리 통신망(local area network, LAN) 및/또는 인터넷과 같은 광역 통신망(wide area network, WAN)을 포함할 수 있는 통신 네트워크에 의해 상호연결된다. 서버 는 총칭적으로 서로 물리적으로 근접할 수 있거나 그렇지 않은 통신 가능하게 연결된 컴퓨터 시스템들의 세 트를 나타낸다. 도 2는 본 발명의 일부 실시예들에 따른 예시적인 이상 탐지기의 동작을 보여준다. 이상 탐지기는 소프 트웨어, 즉, 메모리에 로드되고 개인용 컴퓨터 또는 스마트폰과 같은 컴퓨팅 장치의 하드웨어 프로세서에 의해 실행될 때 각 장치가 각각의 작업을 수행하도록 하는 명령을 포함하는 컴퓨터 프로그램의 세트로 구현될 수 있 다. 그러나, 숙련된 기술자는 이러한 실시예가 제한적인 것으로 의도되지 않는다는 것을 이해할 것이다. 대신에, 탐지기는 소프트웨어 및 하드웨어의 임의의 조합으로 구현될 수 있다. 예를 들어, 탐지기의 일 부 또는 모든 기능은 펌웨어 및/또는 필드 프로그래머블 게이트 어레이(FPGA, Field Programmable Gate Array) 또는 다른 용도 특정 집적회로(ASIC, Application-Specific Integrated Circuit)와 같은 전용 하드웨어에서 구 현될 수 있다. 각각의 하드웨어 모듈은 각각의 기능에 대해 고도로 최적화될 수 있으며, 예를 들어 심층 신경망 아키텍처의 특정 버전을 직접 구현할 수 있어 범용 프로세서에서 달성 가능한 것보다 실질적으로 더 높은 처리 속도를 가능하게 할 수 있다. 더욱이, 숙련된 기술자는 후술하는 바와 같이 이상 탐지기 및/또는 탐지기 를 훈련시키도록 구성된 컴퓨터 시스템의 별개의 구성요소들이 별개이지만 통신적으로 결합된 기계들 및/또 는 동일한 컴퓨터 시스템의 별개의 하드웨어 프로세서들 상에서 실행될 수 있다는 것을 이해할 것이다. 이상 탐지기는 타겟 토큰 시퀀스의 컴퓨터 판독가능 인코딩(encoding)을 수신하고, 응답으로, 각각의 토큰 시퀀스가 변칙적인지 여부를 나타내는 이상 표시자를 출력하도록 구성될 수 있다. 예시적인 토큰 시퀀스는, 특히 영어 및 중국어와 같은 자연 언어(자연어)로 표현된(formulated) 텍스트의 조각과 같은 토큰의 정렬된 어레이(ordered array)를 포함한다. 일반성을 잃지 않고, 이하의 설명은 주로 자연 언어 처리 예들에 초 점을 맞출 것이며, 여기서 예시적인 토큰들은 특히, 개별 단어들, 구문들, 문장들, 숫자들, 구두점들(예를 들면, ? ! ; : / () , ...), 특수 문자들(예를 들면, $ # %), 약어들(USA, LOL, IMHO 등), 소셜 미디어 핸들들 (예를 들면, @POTUS), 해시태그들, 및 이모티콘들 등을 포함할 수 있다. 숙련된 기술자는 본 명세서에 기술된 시스템 및 방법들이 다른 것들 중에서도 컴퓨팅 이벤트들의 시퀀스 및 사운드 시퀀스들(예를 들어, 음악, 스피 치)과 같은 다른 타입의 토큰 시퀀스들을 처리하는데 적합화(adaptation)될 수 있다는 것을 이해할 것이다. 예시적인 이상 표시자는 각각의 타겟 토큰 시퀀스가 변칙적일 가능성을 나타내는 수치 스코어(numerical score)를 포함한다. 스코어는 불린(Boolean, 예를 들어, 예/아니오)일 수 있거나, 또는 미리 결정된 경계들 사 이(예를 들어, 0과 1 사이)에서 점진적으로 변할 수 있다. 이러한 한 예에서, 값이 높을수록 각 시퀀스가 변칙 적일 가능성이 더 높다는 것을 나타낸다. 대안적인 이상 표시자는 시퀀스가 속할 가능성이 있는 토큰 시퀀스의 카테고리(예를 들어, 변칙적, 정상, 알 수 없음, 의심됨 등)를 나타내는 분류 라벨을 포함할 수 있다. 하나의 예시적인 시나리오에서, 이상 탐지기의 별개의 인스턴스가 각각의 클라이언트 시스템(10a-c) 상에서 실행될 수 있고, 따라서 각 클라이언트는 그 자신의 이상 탐지 활동을 국부적으로 그리고 독립적으로 수행할 수 있다. 대안적인 실시예에서, 이상 탐지기는 유틸리티 서버 상에서 실행될 수 있고, 이것은 따라서 복수 의 클라이언트 시스템(10a-c)을 대신하여 집중화된 이상 탐지 활동을 수행할 수 있다. 이러한 실시예들에서, 서버는 각각의 클라이언트 시스템(10a-c)으로부터 타겟 토큰 시퀀스의 인코딩을 수신할 수 있고, 각각의 이상 표시자를 각각의 클라이언트에게 반환할 수 있다. 하나의 이러한 예에서, 클라이언트들(10a-c)은 유틸 리티 서버에 의해 노출된 웹 인터페이스를 통해 이상 탐지 서비스들에 액세스할 수 있다. 도 3은 결정 모듈에 연결된 시퀀스 분석기와 같은 이상 탐지기의 예시적인 구성요소를 나타낸다. 일부 실시예들에서, 시퀀스 분석기는 참조 토큰 시퀀스들의 코퍼스 상에서 훈련된 심층 신경망과 같은 인공 지능(AI) 시스템을 포함한다. 자연 언어 처리 시나리오에서, 코퍼스는 자연 언어(예를 들어, 영어)로 작성 된 텍스트 조각들의 컬렉션을 포함할 수 있다. 코퍼스의 보다 구체적인 예들은 특정 저자에 의한 텍스트들 의 컬렉션, 전자 메시지들의 컬렉션(예를 들면, 단문 메시지 서비스 - SMS 메시지들, 이메일들, 소셜 미디어 포 스트들 등), 특정 주제 또는 관심 영역(예를 들면, 비즈니스 뉴스, 스포츠, 중동 등)에 관한 텍스트들의 컬렉션, 및 특정 스타일로 쓰여진 텍스트들의 컬렉션(예를 들면, 소설, 시, 과학 기사, 뉴스 등)으로 구성될 수 있다. 개별 코퍼스 아이템들은 예를 들어 메타데이터를 사용하여 태깅되고, 라벨링되고, 그리고/또는 주석이 달 릴 수 있다. 예시적인 메타데이터는 아이템들의 선택된 클래스/카테고리에 대한 멤버십의 표시자(예를 들면,"}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "특정 사용자에 의해 전송된 이메일 메시지들, 금융 뉴스 등)를 포함할 수 있다. 코퍼스는 본 기술분야에 알 려진 임의의 포맷으로, 예를 들어 관계형 데이터베이스, 단순 리스트, 또는 XML 또는 JSON 포맷으로 특정된 구 조화된 데이터로서 조직화되고 저장될 수 있다. 코퍼스의 콘텐트(content)는 통신의 참조(reference, 기준) 또는 '정상' 패턴을 집합적으로 정의하고, 일부 실시예에서 이상 탐지기는 각각의 참조 패턴의 내부 모델을 구성하도록 훈련되고, 응답으로, 타겟 텍스트 조각이 학습된 패턴에 들어맞는지 여부를 결정할 수 있도록 훈련된다. 타겟 토큰 시퀀스가 (코퍼스에 따라) '정상' 텍스트에 대응하는 참조 패턴에 적합하지 않는 것으로 판명되면, 시퀀스는 이상으로 간주될 수 있고, 이상 표시자를 통해 그와 같이 보고될 수 있다. 일부 실시예들에서, 이상 탐지기의 트레이닝(훈련)은 도 1의 AI 트레이닝 장치로서 예시된 별도의 전용 컴퓨터 시스템에 의해 수행된다. 장치는 유틸리티 서버 및/또는 클라이언트 시스템(10a-c)에 통신 가능 하게 결합될 수 있고, 컴퓨팅 비용이 드는 트레이닝 절차를 용이하게 하기 위한 그래픽 처리 유닛(GPU) 팜 (farm)과 같은 특수 하드웨어를 포함할 수 있다. 용어 '트레이닝(training)'은 인공 지능 시스템(예를 들어, 신 경망)에 다양한 트레이닝 입력이 부여되고, 각각의 입력이 생성하는 출력에 따라 점진적으로 튜닝(tuning)되는"}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "기계 학습 절차를 나타내기 위해 본 기술분야에서 전형적으로 사용된다. 각각의 트레이닝 입력/배치에 대해, 트 레이닝은 트레이닝 출력을 생성하기 위하여 각각의 입력을 처리하는 것, 각각의 트레이닝 출력 및/또는 입력에 따라 문제-특정 유틸리티 함수(utility function)의 값을 결정하는 것, 각각의 유틸리티 값에 따라 각각의 AI 시스템의 파라미터의 세트를 조정하는 것을 포함할 수 있다. 파라미터를 조정하는 것은 유틸리티 함수를 최대화 (또는 경우에 따라 최소화)하는 것을 목표로 할 수 있다. 신경망을 훈련시키는 한 예에서, 조정가능한 파라미터 는 시냅스 가중치의 세트(a set of synapse weights)를 포함할 수 있는 반면, 유틸리티 함수는 예상 또는 원하 는 출력으로부터 훈련 출력의 이탈(departure)을 정량화할 수 있다. 이러한 예에서, 트레이닝은 트레이닝 출력 을 각각의 트레이닝 입력에 대응하는 원하는 출력에 더 가깝게 가져오도록 시냅스 가중치 및 가능하게는 다른 네트워크 파라미터를 조정하는 것을 포함할 수 있다. 트레이닝의 알려진 특징(flavor)에는 특히 감독식 (supervised), 자율식(unsupervised), 자기 감독식 및 강화 학습이 포함된다. 일부 실시예에서, 전형적인 탐지 기의 조정가능한 파라미터의 수는 수천에서 수백만까지 다양할 수 있다. 성공적인 트레이닝은 클라이언트 시스템들(10a-c) 및/또는 유틸리티 서버에서 실행되는 이상 탐지기의 로컬 인스턴스들을 인스턴스화하 기(instantiate) 위해 사용될 수 있는 최적화된 탐지기 파라미터 값들의 세트를 생성할 수 있다 (도 2). 탐지기의 트레이닝은 도 3에 개략적으로 도시되어 있다. 숙련된 기술자는 도시된 구성요소 모두가 AI 트레 이닝 장치의 동일한 하드웨어 프로세서 또는 물리적 머신 상에서 실행될 필요는 없다는 것을 이해할 것이다. 본 발명의 일부 실시예들은 트레이닝 코퍼스에 포함된 샘플들 중 적어도 일부를, 이들을 이상 탐지기에 공급하기 전에 왜곡(distortion)하고, 이어서 적용된 왜곡의 유형을 식별하기 위해 탐지기를 훈련시킨다. 도 3에서 설명된 하나의 예에서, 입력 수정자(input modifier)는 트레이닝 코퍼스로부터 선택된 트레이 닝 토큰 시퀀스를 수신하고, 시퀀스 변환의 미리 결정된 세트 중 적어도 하나를 트레이닝 시퀀스에 적용한 결과를 포함하는 수정된 토큰 시퀀스를 출력하도록 구성된다. 예시적인 시퀀스 변환들은, 무엇보다도, 시퀀스 내의 토큰들의 선택된 서브세트를 대체 토큰들로 교체 하는 것, 시퀀스로부터 토큰들의 선택된 서브세트를 삭제하는 것, 시퀀스 내로 토큰들의 세트를 삽입하는 것, 및 시퀀스 내에서 토큰들의 선택된 서브세트를 치환(permutating)하는 것을 포함한다. 각각의 변환 에 의해 수정을 위해 타겟팅되는 토큰들의 서브세트는 트레이닝 시퀀스 내에서 각 토큰의 위치에 따라 선택될 수 있다. 목표로 하는 위치는 바이너리 마스크(binary mask)로 표시될 수 있으며, 0은 변경되지 않은 채 남아 있는 토큰의 위치를 표시하고 1은 각 변환의 영향을 받는 위치를 표시한다. 예를 들어, 마스크(mask) [0 0 1 0 1]에 의해 정의되는 치환 변환(permutation transformation)은 토큰 시퀀스 'They were prepared to leave'를 수정된 토큰 시퀀스 'They were leave to prepared'로 변환할 수 있으며, 여기서 세 번째 토큰은 다섯 번째 토 큰으로 교환되었다. 대안적인 실시예들에서, 변환에 의해 타겟팅된 토큰들은 각각의 토큰들의 타입에 따라 선택될 수 있다. 예 를 들어, 일부 변환은 특정 품사(예: 명사, 동사, 형용사) 또는 특정 문법적 역할(예: 문장의 주어)을 갖는 토 큰을 대상으로 할 수 있다. 그러한 하나의 예시적인 변환은 동사를 대체 동사 또는 동사 구로 교체할 수 있다. 각각의 대체 토큰 또는 토큰 시퀀스는 타겟 토큰/시퀀스의 동의어 또는 반의어가 되도록 선택될 수 있다. 시퀀 스 변환들의 보다 정교한 예들은 패러프레이징(paraphrasing, 말 바꿔 설명하기), 즉, 의미를 보존하면서 전체 토큰 시퀀스들을 대체 시퀀스들로 교체하는 것을 포함할 수 있다. 패러프레이징 변환의 한 예는 트레이닝 시퀀스 'Kids by the lake were being eaten alive by mosquitoes(호숫가의 아이들이 모기에게 산 채로 먹히고 있었다)'를 수정된 시퀀스 'Mosquitoes ferociously attacked the kids by the lake (모기가 호숫가의 아이들 을 사납게 공격했다)'로 교체하는 것을 포함한다. 유사한 변환들이 시퀀스의 각각의 토큰이 개별적인 컴퓨팅 이벤트를 포함하는 컴퓨터 보안 실시예에서 적용 될 수 있다. 예를 들어, 예시적인 변환은 트레이닝 시퀀스로부터 '프로세스 생성(create process)' 타 입의 토큰들을 제거할 수 있다. 이러한 실시예에서 패러프레이징(paraphrasing)과 동등한 것은, 이벤트들의 타 겟 시퀀스를 각각의 컴퓨터 시스템을 동일한 최종 상태로 가져오는 이벤트들의 대체 시퀀스로 교체하는 것을 포 함할 수 있다. 도 4는 본 발명의 일부 실시예들에 따라 복수의 미리 정의된 시퀀스 변환들을 구현하는 입력 수정자의 예시적인 작동을 보여준다. 트레이닝 시퀀스는 토큰들(35a-e)을 포함하는데, 이는 현재의 예에서 개별적인 단어들이다. 도시된 실시예에서, 각각의 변환은 트레이닝 시퀀스로부터의 토큰들의 세트를 대체 토큰으 로 교체하는 것을 포함한다. 각각의 변환은 도시된 바와 같이 별개의 바이너리 마스크에 의해 정의될 수 있 으며, 토큰 교체를 위해 타겟팅된 트레이닝 시퀀스 내의 위치들의 별개의 세트를 나타낸다. 도시된 예에서, 시퀀스에 T2 마스크를 적용하면, 시퀀스의 세 번째 및 다섯 번째 토큰이 마스킹되어, 교체를 위해 상기 토큰을 효과적으로 마킹한다. 일부 실시예들에서, 입력 수정자는 시퀀스 내에서 마스킹된 토큰들을 교체하기 위해 한 세트의 대체 토 큰들을 출력하도록 구성된 토큰 발생기를 더 포함한다. 도시된 예에서, 토큰 발생기는 각각, 토큰들(35c 및 35e)을 교체하기 위해 대체 토큰들(35f 및 35g)을 출력한다. 발생기의 간단한 실시예는 기준 풀(reference pool)로부터 대체 토큰을 랜덤하게 뽑도록 구성될 수 있다. 보다 진보된 실시예들에서, 토큰 발생기는 사전 /유의어 사전(thesaurus)을 포함할 수 있고, 각각의 마스킹된 토큰에 대해, 각각의 토큰의 동의어 또는 반의어 를 출력하도록 구성될 수 있다. 다른 예시적인 실시예에서, 발생기는 마스킹된 토큰에 따라 그리고 또한 마 스킹된 토큰의 맥락(context)에 따라, 대체 토큰을 결정할 수 있고, 상기 맥락은 마스킹된 토큰 이전의 시퀀스 의 조각 및/또는 마스킹된 토큰 이후의 시퀀스의 조각으로 구성된다. 예를 들어, 도 4의 예에서, 토큰 (35c)('ready')의 맥락은 토큰들(35b 및 35d)('were to')을 포함할 수 있다. 이러한 실시예들은 마스킹된 토큰 의 맥락 내에서 각각의 대체 토큰의 발생 확률에 따라 대체 토큰을 생성하기 위해 통계적 언어 모델을 채용할 수 있다. 다시 말해, 토큰 발생기는 각각의 토큰 시퀀스의 맥락(컨텍스트, context)이 주어지면 그럴듯한 대체 토큰을 생성하도록 구성될 수 있다. 그럴듯한 대체 토큰을 생성하는 토큰 발생기의 하나의 예시적인 실시예는 각각의 이상 탐지 어플리케이션을 대표하는 토큰 시퀀스의 코퍼스 상에서 훈련된 AI 시스템(예를 들어, 심층 신경망의 세트)을 포함한다. 이러한 버전의 발생기는 시퀀스 내에서 마스킹된 토큰에 선행하는 토큰들의 서브시퀀스에 따라 대체 토큰을 출 력할 수 있다. 도시된 예에서, 훈련된 발생기는 토큰들(35a-d)('they were ready to')의 시퀀스를 따를 가 능성이 높은 것으로서 대체 토큰(35g)('leave')을 생성할 수 있다. 이러한 AI 기반 토큰 발생기의 한 예는, 예를 들어, J. Devlin et al. 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding', arXiv:1810.04805에 기술된 바와 같이, 언어의 BERT(Bidirectional Encoder Representation From Transformers) 모델을 구현한다. 일부 실시예들에서, 토큰 발생기는 트레이닝 동안, 토큰 발생기가 도 3 내지 도 4에 도시된 바와 같이 시퀀스 분석기에 연결되고, 발생기는 시퀀스 분석기의 조정 가능한 파라미터와 구별되는 한 세트의 조정가능한 기능적 파라미터(functional parameter, 예를 들어, 시냅스 가중치 등)를 가지며, 훈련된 발생기의 적어도 하나의 조정가능한 파라미터는 시퀀스 분석기의 출력에 따라 튜닝(tuning)된다는 점에서 시퀀스 분석기와 공동-훈련된다. 입력 수정자에 의해 구현되는 다른 예시적인 시퀀스 변환들은 토큰 임베딩 벡터(token embedding vector)들의 조작을 포함할 수 있다. 이러한 실시예들에서, 수정된 시퀀스는 토큰들 그 자체의 시퀀스 대신 에 임베딩 벡터(embedding vector)들의 어레이를 포함할 수 있다. 입력 수정자는 임베딩 공간(embedding"}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "space)으로서 본 기술분야에서 일반적으로 알려진 추상적인 다차원 벡터 공간(abstract multidimensional vector space)에서 트레이닝 시퀀스의 각 토큰의 위치를 나타내는 좌표들의 세트를 결정하도록 구성된 토큰 인코더(token encoder)를 포함할 수 있다. 좌표들의 각각의 세트는 각 토큰과 연계된 토큰 임베딩 벡터를 집합 적으로 정의한다. 도 5는 예시적인 토큰 임베딩 공간 및 토큰들(35a-b)을 나타내는 토큰 임베딩 벡터들 (55a-b)의 세트를 각각 나타낸다. 예시적인 임베딩 공간은 축들의 세트에 의해 스패닝(spanning)되며, 여기서 각 축은 (예를 들면, 주 구성요소/ 특이값 분해(principal component/singular value decomposition) 실시예에서) 별개의 토큰 특징(token feature) 또는 토큰 특징들의 선형 조합(linear combination)을 나타낸다. 컴퓨팅 이벤트들의 시퀀스들에서 이 상들을 탐지하도록 구성된 실시예들에서, 토큰 특징들은 각각의 이벤트의 다양한 이벤트 특징들(예를 들면, 이 벤트의 유형, 경로 표시자, 네트워크 주소 등)을 포함할 수 있다. 바람직한 실시예들에서, 토큰들은 트레이닝 시퀀스 내에서의 그들의 위치에 따라 임베딩되거나, 또는 그들의 맥락에 따라 달리 언급된다. 이러한 경우들에 서, 임베딩 공간은 추상적인 컨텍스트 공간(abstract context space)을 포함할 수 있으며, 여기서 유사한 컨텍스트에서 우세하게 발생하는 두 개의 토큰들은 비교적 가깝게 함께 위치된다. 이러한 여러 임베딩은 특히"}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "word2vec, GloVe, 및 BERT를 비롯하여 본 기술분야에 알려져 있다. 임베딩 벡터 표현들(embedding vector representations)(55a-b)을 생성하기 위해, 토큰 인코더는 트레이닝 코퍼스, 즉, 트레이닝 시퀀스 분석기 를 위해 사용되는 코퍼스와 일치할 수 있는 토큰 시퀀스들의 코퍼스 상에서 훈련되어야 한다. 트레이닝은"}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "본 기술분야에 알려진 임의의 방법에 따라, 예를 들어 단어주머니(a bag-of-words) 및/또는 스킵-그램(skip- gram) 알고리즘에 따라 진행될 수 있다. 일부 실시예들에서, 토큰 인코더의 조정가능한 파라미터들이 시퀀스 분 석기의 출력에 따라 튜닝된다는 점에서 토큰 인코더는 분석기와 공동-훈련된다. 트레이닝 시퀀스 왜곡을 위한 일부 시퀀스 변환(도 3)은 도 6에 예시된 바와 같이 임베딩 벡터에 대해 직접 동작할 수 있다. 예시적인 변환(Tj)은 트레이닝 시퀀스의 선택된 토큰을 나타내는 오리지널 토큰 임베 딩 벡터(55c)를 수정된 벡터(55d)로 변경할 수 있다. 예시적인 임베딩 변환은 축들 중 하나를 따라 또는 변환- 특정된 미리 결정된 방향을 따라 벡터를 소량(ε) 만큼 넛징하는 것(nudging, 밀어내기 하는 것)을 포함한다. 다른 예시적인 변환은 미리 결정된 평면에 대한 회전 및 반사를 포함할 수 있다. 각각의 변환은 트레이닝 시퀀 스의 모든 토큰에 적용될 수 있거나, 또는 예를 들어 바이너리 마스크(위에 도시된 바와 같음) 또는 다른 선택 기준에 의해 식별된 선택된 토큰에만 적용될 수 있다. 일부 실시예들에서, 시퀀스 분석기는 입력 토큰 시퀀스를 처리하여 입력 토큰 시퀀스에 따라 결정된 변환 예측 표시자 및 토큰 예측 표시자를 포함하는 예측 표시자들의 세트를 생성하도록 구성된다. 변환 예측 표시자는 어떤 시퀀스 변환이 입력 토큰 시퀀스를 생성하는데 사용되었을 가능성이 있는지를 나타낸다. 예시적인 실시예에서, 변환 예측 표시자는 복수의 수치 스코어 P(T1), P(T2), ... P(Tk)를 포함하고, 각각 의 스코어 P(Tj)는 각각의 입력 토큰 시퀀스를 생성하기 위해 각각의 변환 Tj가 적용되었을 가능성을 나타낸다. 예를 들어, 표시자는 입력 수정자에 의해 구현된 각각의 별개의 시퀀스 변환에 대한 별개의 스코어 를 포함할 수 있다. 스코어 P(Tj)는 미리 결정된 경계들 사이(예를 들어, 0과 1 사이)에서 스케일링될 수 있으 며, 값이 높을수록 가능성이 높음을 나타낸다. 차례로, 토큰 예측 표시자의 일부 실시예들은 입력 시퀀스의 어떤 토큰들이 입력 수정자에 의해 수정되 었을 가능성이 있는지를 나타낸다. 예시적인 실시예에서, 토큰 예측 표시자는 복수의 수치 스코어들(S1, S2, ...)을 포함하고, 이 때 스코어(Sn)는 입력 시퀀스의 n번째 토큰이 입력 수정자에 의해 변경되었을 가능성 을 나타낸다. 도 3에 도시된 바와 같은 트레이닝 과정에서, 각각의 스코어(Sn)는 수정된 토큰 시퀀스의 n번 째 토큰이 각각의 트레이닝 시퀀스의 n번째 토큰과 상이할 가능성을 나타낼 수 있다.직관적인 관점에서, 변환 예측 표시자는 어떤 변환이 트레이닝 시퀀스를 왜곡하는 데 사용되었는지를 추측하려는 시도를 나타내는 반면, 토큰 예측 표시자는 어떤 개별 토큰이 손상되었는지를 추측하기 위한 시 도를 나타낸다. 표시자(36 및 38)가 중복 정보(redundant information)를 전달하는 것처럼 보이지만(결국, 각각 의 변환은 특정 토큰 마스크를 가짐), 표시자(36 및 38)는 이들이 시퀀스 분석기의 별개의 서브시스템(예를 들어, 심층 신경망의 뉴런의 별개의 그룹)에 의해 생성된다는 의미에서 독립적이다. 더욱이, 시퀀스 변환과 그와 연관된 토큰 마스크 사이의 연결 또는 상관관계에 대한 선험적 지식이 시퀀스 분석기에 구축되어 있지 않다. 대신에, 분석기는 트레이닝 동안에 이러한 상관관계를 자동적으로 학습할 수 있다. 일부 실시예 들은 표시자들(36 및 38) 모두를 사용하는 것이 시퀀스 분석기의 트레이닝을 실질적으로 용이하게 할 수 있다는 점에 의존하는데, 예를 들어, 학습을 가속화하거나 또는 실질적으로 더 작은 트레이닝 코퍼스의 사용이 표시자 들(36 및 38) 중 하나만을 사용하는 것과 유사한 이상 탐지 성능을 달성하는 것이 가능하게 한다. 시퀀스 분석기의 예시적인 아키텍처가 도 7에 예시되어 있고, 레이어/신경망 모듈들의 스택을 포함하고, 각 각의 레이어는 이전 레이어/모듈의 출력을 수신하고 상기 스택의 다음 레이어에 입력을 제공한다. 시퀀스 분석 기는 토큰 표현의 어레이의 형태로 입력을 수신할 수 있으며, 각각의 토큰 표현은 입력 시퀀스의 각각 의 토큰을 특징짓는 숫자들의 벡터를 포함한다. 트레이닝 시나리오에서, 도 7의 각각의 토큰 표현은 수정된"}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "시퀀스의 별개의 토큰을 나타낼 수 있다(도 3). 1-핫 인코딩(1-hot encoding)으로서 본 기술분야에 알려진 것을 사용하는 하나의 예시적인 실시예에서, 토큰 표현은 Nx1 벡터를 포함하며, 여기서 각 행(row)은 별개 의 토큰 타입을 나타내고, N은 토큰 어휘(token vocabulary)의 크기를 나타내고, 0이 아닌 요소는 각각의 토큰 이 각각의 토큰 타입임을 나타낸다. 토큰 어휘의 예시적인 크기 N의 범위는 특정 어플리케이션에 대해 수백에서"}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "수백만까지 다양하다. 다른 예에서, 각각의 토큰 표현은 본 기술분야에서 알려진 임의의 임베딩 알고리즘에 따라 생성된 토큰 임베딩 벡터를 포함할 수 있다. 예를 들어, 위에서 설명된 도 5의 임베딩 벡터(55a-b)를 참조 한다. 각각의 연속적인 레이어(Li)는 각각의 레이어에 특정된 파라미터의 세트(예를 들어, 활성화(activation), 가중 치, 바이어스(biase))에 따라 이전 레이어로부터 수신된 입력을 변환하여, 내부 벡터를 생성하며, 그것의 값의 크기 및 범위는 분석기의 별개의 레이어/모듈들 사이에서 변할 수 있다. 예를 들어, 일부 레이어는 풀 링 또는 손실 레이어(pooling or loss layer)의 경우와 같이 각 입력 벡터의 차원 축소(dimensionality reduction)를 달성한다. 각 레이어의 유형 및 아키텍처는 실시예에 따라 다를 수 있다. 시퀀스 분석기의 하나의 예시적인 아키텍처는 뒤이어 개정자(rectifier)(예를 들어, ReLU 또는 다른 활성화 함수) 및/또는 손실 레이어(loss layer)에 추가로 결합된 조밀한(즉, 완전히 연결된) 레이어(dense layer)가 뒤 따르는 컨볼루션 신경망(convolutional neural network, CNN) 레이어를 포함한다. 대안적인 실시예들은 순환 신 경망(recurrent neural network, RNN)으로 공급되는 CNN 레이어를 포함할 수 있는데, 이에 뒤이어서 완전히 연"}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "결된 그리고 ReLU/손실 레이어를 포함할 수 있다. 컨볼루션 레이어는 내부 벡터를 필터로서 본 기술분야에 서 알려진 가중치의 매트릭스로 효과적으로 곱하여, 임베딩 텐서(embedding tensor)를 생성해서는, 각각의 텐서 의 각 요소가 선택된 토큰으로부터의 기여(contribution) 뿐만 아니라, 또한, 선택된 토큰에 인접한 다른 토큰 으로부터의 기여(contribution)도 갖도록 한다. 따라서 임베딩 텐서는 개별 토큰의 경우보다 더 거친 세밀도 (granularity)로 입력 토큰 시퀀스를 집합적으로 나타낸다. 필터 가중치는 트레이닝 과정에서 튜닝될 수 있는 조정 가능한 매개변수이다. 순환 신경망 (RNN)은 인공 신경망의 특별한 클래스를 형성하며, 여기서 네트워크 노드 간의 연결은 방향 그래프"}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "(directed graph)를 형성한다. RNN의 여러 가지 특징(flavor)이 본 기술분야에서 알려져 있으며, 그 중에서도 LSTM(장단기 기억, long-short-term-memory) 네트워크 및 GNN(그래프 신경망, graph neural network)을 포함한 다. 전형적인 RNN은 은닉 유닛(hidden unit)(예를 들어, 개별적인 뉴런)의 세트를 포함하고, 네트워크의 토폴로 지(topology)는 각각의 은닉 유닛이 각각의 토큰 mj을 특징짓는 입력(예를 들어, 임베딩 벡터)을 수신할 뿐만 아니라, 인접한 은닉 유닛에 의해 제공되는 입력을 수신하고, 이것은 다시 입력 토큰 시퀀스 내에서 토큰 mj을 선행하는 토큰 mj-1을 특징짓는 입력을 수신하도록 구체적으로 구성된다. 결과적으로 각 은닉 유닛의 출력은 각 토큰 mj뿐만 아니라 이전 토큰 mj-1의 영향을 받는다. 달리 말하면, RNN 레이어는 이전 토큰(들)의 컨텍스트(맥 락)에서 각 토큰에 대한 정보를 처리할 수 있다. 양방향 RNN 아키텍처는 입력 토큰 시퀀스의 이전 및 후속 토큰 (들) 모두의 컨텍스트에서 각 토큰에 대한 정보를 처리할 수 있다. 시퀀스 분석기의 또 다른 예시적인 실시예는 트랜스포머 신경망 레이어들(transformer neural network layers)의 스택을 포함할 수 있다. 트랜스포머 아키텍처는 다른 것 보다도, 예를 들어 A. Vaswani et al., 'Attention is all you need', arXiv:1706.03762에 기술되어 있다. 각각의 입력 토큰 시퀀스에 대하여, 트랜스 포머 레이어들은 컨텍스트화된(맥락화된) 토큰 임베딩 벡터들(contextualized token embedding vectors)의 시 퀀스를 생성할 수 있으며, 여기서 각각의 토큰 임베딩 벡터 hj는 입력 시퀀스의 다수의(예를 들면, 모든) 토큰들"}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "(mj)로부터의 정보를 인코딩한다. 트랜스포머 레이어들의 출력은 예측 헤드(prediction head)로서 본 기술분야 에서 알려져 있고 도 7에서 블록들(H1 및 H2)로서 도시된 다수의 별개의 분류자 모듈들(예를 들어, 조밀한 레이 어들)로 공급될 수 있다. 그러고 나서, 헤드들(H1 및 H2)은 변환 예측 표시자 및 토큰 예측 표시자(들) 를 각각 출력할 수 있다. 도 8은 본 발명의 일부 실시예에 따른 이상 탐지기를 훈련시키기 위한 AI 트레이닝 장치(도 1)에 의해 수행되는 단계들의 예시적인 시퀀스를 나타낸다. 코퍼스로부터 트레이닝 시퀀스를 선택하는 것에 응답 하여, 단계들(204-206)의 시퀀스는 시퀀스 변환들의 이용가능한 세트로부터 변환을 (예를 들어, 랜덤하게) 선택할 수 있고, 각각의 변환을 트레이닝 시퀀스에 적용하여, 수정된 토큰 시퀀스를 생성할 수 있다. 수정된 시퀀스는 시퀀스 분석기에 공급되고, 시퀀스 분석기는 이를 처리하여 예측 표시자(36 및/또 는 38)를 생성한다. 그리고, 단계는 트레이닝 시퀀스 및/또는 예측 표시자들(36 및/또는 38)에 따라"}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "유틸리티 함수를 결정할 수 있다. 기계 학습의 기술분야에서 손실(loss)이라고도 알려진 예시적인 유틸리티 함 수(utility function)는 다음과 같이 표현될 수 있다: , [1] 여기서 x는 트레이닝 시퀀스를 나타내고, 는 조정가능한 파라미터들의 세트를 나타낸다. 트레이닝은 유틸리티 U를 최소화하는 방향으로 파라미터 를 조정하는 것을 포함할 수 있다. 간단한 유틸리티 함수는 원하는 출력으로부터 분석기의 출력의 이탈(departure)을 정량화할 수 있다. 예를 들어, 예시적인 유틸리티 함수는 분석기가 단계에서 어떤 변환이 적용되었는지 그리고/또는 단계(20 6)에서 원래의 트레이닝 시퀀스의 어떤 토큰이 손상되었는지를 정확하게 추측했는지를 나타낼 수 있고, 잘 못된 추측에 대해 분석기에 페널티를 줄 수 있다. 일부 실시예들은 표시자들(36 및 38)에 따라 결정된 유틸리티들을 조합하는 것이 트레이닝을 용이하게 할 수 있 고 그리고/또는 더 성능이 좋은 시퀀스 분석기로 이끌 수 있다는 점에 의존한다. 바람직한 실시예는 시퀀스 -레벨 구성요소(시퀀스 변환의 선택을 표시함)와 토큰-레벨 구성요소(각각의 개별 토큰이 손상되었는지 여부를 표시함)를 결합하는 집계 유틸리티 함수(aggregate utility function)를 사용할 수 있다: , [2] 여기서 US 및 UT는 각각 시퀀스-레벨 구성요소 및 토큰-레벨 구성요소를 각각 나타내며, 여기서 및 는 각 유틸리티 함수의 상대적 기여도를 변경할 수 있도록 하는 가중치이다. 최대 가능성 훈련 전략(maximum likelihood training strategy)을 구현하는 일부 실시예들에서는 아래와 같은데,"}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "[3] 여기서, 는 기대를 나타내고, 그리고 는 왜곡된 시퀀스(distorted sequence) 가 시퀀스 변환 Tk 의 적용에 의해 생성될 확률을 나타내고(예를 들어, 도 3의 변환 예측 표시자 참조), 그리고 여기서 는 총칭적으로 시퀀스 분석기의 조정가능한 파라미터를 나타낸다. 한편, , [4] 여기서, 는 트레이닝 시퀀스 x의 토큰 i 가 시퀀스 변환 Tk의 적용에 의해 영향을 받았을 확률을 나 타낸다(예를 들어, 도 3의 토큰 예측 표시자 참조). 일부 실시예들에서, 입력 수정자의 구성요소(예를 들어, 토큰 발생기 및/또는 토큰 임베딩 벡터들을 생 성하도록 구성된 토큰 인코더)는 시퀀스 분석기와 공동-훈련된다. 이러한 실시예들은 상술한 US 및 UT 이외 에 발생기 유틸리티 함수(generator utility function)를 사용할 수 있다: , [5] 여기서, 는 전역 유틸리티(global utility)에 대한 발생기 유틸리티 함수 UG의 기여도를 조정하는 데 사용되 는 또 다른 가중치를 나타내며, 여기서, , [6] 여기서, 는 총칭적으로 토큰 발생기의 조정가능한 파라미터를 나타내고, 는 토큰 ti가 수 정된 시퀀스에 나타날 확률을 나타내거나, 달리 말하면, 토큰 ti가 수정된 시퀀스의 맥락에서 그럴듯할 (타당할 것 같을) 확률을 나타낸다. 추가의 단계는 그리고나서, 결정된 유틸리티 함수에 따라 파라미터들( 및/또는 )의 세트를 조정할 수 있다. 이러한 조정은 경사 하강법(gradient descent) 또는 선택된 유틸리티 함수를 최소화하는 것을 목표로 하 는 임의의 다른 최대 가능성 탐색(maximum likelihood search)에 의한 역전파 (backpropagation) 절차를 구현 할 수 있다. 트레이닝은 종료 조건이 만족될 때까지(단계 212), 예를 들어, 미리 결정된 수의 기간(epoch) 동안, 미리 결정된 수의 훈련 시퀀스가 분석될 때까지, 미리 결정된 수준의 이상-탐지 성능이 입증될 때까지 등 으로, 계속될 수 있다. 성공적인 트레이닝에 응답으로, 시퀀스 분석기의 조절가능한 파라미터들(예를 들어, 시냅스 가중치 등)의 최적 값들이 탐지기 파라미터 값들 (도 2)의 형태로 클라이언트 시스템들(10a-c)로 내 보내지고 전송될 수 있다. 도 9는 본 발명의 일부 실시예들에 따른 이상들을 탐지하기 위해 클라이언트 시스템들(10a-c) 및/또는 유틸리티 서버에 의해 수행되는 단계들의 예시적인 시퀀스를 보여준다. 단계들(222-224)의 시퀀스는 AI 트레이닝 장 치(도 2)로부터 탐지기 파라미터 값들을 수신함으로써 그리고 탐지기의 로컬 인스턴스를 각각의 값 으로 인스턴스화(instantiating)함으로써 탐지기가 동작하도록 준비한다. 그 후, 각각의 타겟 토큰 시퀀스 에 대해, 단계는 시퀀스 분석기를 실행하여 각각의 타겟 토큰 시퀀스에 대한 토큰 예측 표시 자를 결정할 수 있다. 추가의 단계는 이상 표시자를 생성하기 위해 결정 모듈을 적용할 수 있다. 일부 실시예들에서, 결 정 모듈은 토큰 예측 표시자에 따라, 예를 들어 전체 타겟 토큰 시퀀스에 걸쳐 취해진 개별 토큰 예측 스코어들(Si)의 평균으로서, 이상 표시자를 결정하도록 구성된다. 각각의 개별 스코어(Si)는, 도 3과 관련하여 상술된 바와 같이, 시퀀스의 각각의 토큰이 시퀀스 변환의 적용에 의해 손상되었는지의 가능 성을 정량화할 수 있다. 일부 실시예들은 다음식에 따라 시퀀스-특정 이상 스코어 A를 결정할 수 있다: , [7] 여기서 Ls는 타겟 시퀀스의 길이(토큰의 카운트)를 나타낸다. 큰 Si 값이 각각의 토큰이 손상되었을 가능성 이 높다는 것을 나타내는 실시예에서, A의 큰 값은 타겟 토큰 시퀀스가 변칙적일 가능성이 높다는 것을 나 타낼 수 있다. 반대로, 큰 Si 값이 각각의 토큰이 손상되지 않을 가능성이 있음을 나타낼 때, 큰 A 값은 타겟 시퀀스가 이상이 아니라는 것을 나타낼 수 있다. 결정 모듈의 일부 실시예들은 이상 스코어 A의 계산된 값을 미리 결정된 임계치와 비교하고, 비교의 결과에 따라 타겟 토큰 시퀀스가 변칙적인지 아닌지를 결정할 수 있다. 도 10은 본 명세서에 기술된 방법들 중 일부를 실행하도록 프로그래밍된 컴퓨팅 장치의 예시적인 하드웨어 구성을 보여준다. 컴퓨팅 장치는 도 1의 클라이언트 시스템(10a-c), 유틸리티 서버 및 AI 트레이닝 장 치 중 임의의 것을 나타낼 수 있다. 도시된 컴퓨팅 장치는 퍼스널 컴퓨터이다; 서버, 휴대폰, 태블릿 컴퓨터 및 웨어러블과 같은 다른 기기는 구성이 약간 다를 수 있다. 프로세서(들)는 신호 및/또는 데이터의 세 트로 산술 및/또는 논리 연산을 실행하도록 구성된 물리적 장치(예컨대, 반도체 기판에 형성된 멀티-코어 집적 회로, 마이크로프로세서 등)를 포함한다. 그러한 신호 또는 데이터는 프로세서 명령들, 예를 들어, 머신 코드의 형태로 프로세서(들)에 전달되고 인코딩될 수 있다. 프로세서는 일반적으로 명령 세트 아키텍처(Instruction Set Architecture, ISA)에 의해 특징지어지며, 이 는 특히 프로세서 명령(어)들의 각각의 세트(예를 들어, x86 제품군 대 ARM® 제품군) 및 레지스터들의 크기(예 를 들어, 32비트 대 64비트 프로세서)를 특정한다. 프로세서들의 아키텍처는 이들의 의도된 주된 용도에 따 라 추가로 달라질 수 있다. 중앙 처리 장치(CPU)는 범용 프로세서인 반면, 그래픽 처리 장치(GPU)는 이미지/비 디오 처리 및 일부 형태의 병렬 컴퓨팅(parallel computing)에 최적화될 수 있다. 프로세서는Google®, Inc.의 텐서 프로세싱 유닛(TPU, Tensor Processing Unit) 및 다양한 제조사의 신경 망 프로레싱 유닛(Neural Processing Unit, NPU)과 같은 용도 특정 집적회로 (ASIC, Application-Specific Integrated Circuit)를 더 포함할 수 있다. TPU 및 NPU는 본 명세서에 기술된 바와 같이 기계 학습 어플리케이 션에 특히 적합할 수 있다. 메모리 유닛은 연산들을 수행하는 도중에 프로세서(들)에 의해 액세스되거나 생성되는 데이터/신호/명 령 인코딩들을 저장하는 휘발성 컴퓨터-판독 가능 매체(예컨대, 다이나믹 랜덤 액세스 메모리-DRAM)를 포함할 수 있다. 입력 장치는 사용자가 장치로 데이터 및/또는 명령들을 도입할 수 있게 하는 개별 하드웨어 인터페이스 및/또는 어댑터를 포함하여, 특히 컴퓨터 키보드, 마우스, 및 마이크를 포함할 수 있다. 출력 장치 는 특히 모니터와 같은 디스플레이 장치 및 스피커는 물론, 각 컴퓨팅 장치가 사용자에게 데이터를 통신하 게 할 수 있는 그래픽 카드와 같은 하드웨어 인터페이스/어댑터를 포함할 수 있다. 일부 실시예들에서, 입력 장 치와 출력 장치(76-78)는 하드웨어의 공통적인 부품(예를 들어서, 터치 스크린)을 공유한다. 저장 장치는 소프트웨어 명령들 및/또는 데이터의 비휘발성 저장, 판독, 및 기록을 가능하게 하는 컴퓨터-판독 가능 매체를 포함한다. 예시적인 저장 장치는 자기 디스크 및 광 디스크 및 플래시 메모리 장치들은 물론, CD 및/또는 DVD 디스크들 및 드라이브들과 같은 소거 가능 매체를 포함한다. 네트워크 어댑터(들)는 컴퓨팅 장치가 전 자 통신 네트워크(예를 들어, 도 1의 네트워크) 및/또는 다른 장치/컴퓨터 시스템에 접속할 수 있게 한다. 컨트롤러 허브는 프로세서(들)와 장치의 나머지 하드웨어 구성요소들 사이의 통신을 가능하게 하는 복수의 시스템, 주변, 및/또는 칩셋 버스들, 및/또는 다른 모든 회로망을 일반적으로 나타낸다. 예를 들어, 컨 트롤러 허브는 메모리 컨트롤러, 입력/출력(I/O) 컨트롤러, 및 인터럽트 컨트롤러(interrupt controller)를 포함할 수 있다. 하드웨어 제조사에 따라서, 일부의 그러한 컨트롤러는 하나의 집적 회로에 합쳐질 수 있고, 그 리고/또는 프로세서(들)와 통합될 수 있다. 다른 예에서, 컨트롤러 허브는 프로세서를 메모리 에 연결시키는 노스브리지, 및/또는 프로세서를 장치(76, 78, 82 및 84)들에 연결시키는 사우스브리지를 포 함할 수 있다. 상술된 예시적인 시스템 및 방법은 다양한 어플리케이션들에서 이상들의 효율적인 자동 탐지를 가능하게 한다. 일부 실시예들에서, 트레이닝 코퍼스로부터 도출된 토큰 시퀀스들은, 트레이닝을 받고 있는 시퀀스 분석기에 공 급되기 전에, 복수의 사전-결정된 시퀀스 변환들 중 적어도 하나에 따라 왜곡된다. 그런 다음 시퀀스 분석기는 어떤 변환이 각각의 입력 토큰 시퀀스를 생성하는 데 사용되었는지 정확하게 추측하도록 학습된다. 이상 탐지기를 학습하기 위한 일부 기존 절차는 몇몇 토큰들을 랜덤하게 교체하여 트레이닝 토큰 시퀀스를 손상 시키고, 이어서 어떤 토큰이 교체되었는지 추측하도록 탐지기를 훈련시킨다. 그러나, 이러한 트레이닝 전략들은 컴퓨팅 리소스의 관점에서 상대적으로 비용이 많이 들고, 트레이닝 코퍼스 및/또는 어플리케이션들의 일부 선택 들에 대해 불안정할 수 있다. 이러한 종래의 접근법과는 대조적으로, 본 발명의 일부 실시예들은 입력 토큰 시 퀀스들을 왜곡하기 위해 변환들의 미리 정의된 세트를 사용하고, 토큰-레벨 구성요소(각각의 개별 토큰이 손상 되었는지 여부를 표시함)와 시퀀스-레벨 구성요소(전체 입력 시퀀스를 왜곡하는 방식을 표시함)를 결합하는 집 계 유틸리티 함수에 따라 훈련한다. 보다 종래의 토큰-레벨 유틸리티에 더하여 시퀀스-레벨 유틸리티를 사용하 는 것은, 일부 실시예들에서, 각각의 시퀀스 변환이 특정 토큰 마스크를 가지며, 따라서 어떤 변환이 적용되었 는지를 추측하는 것이 또한 어떤 토큰들이 손상되었는지를 추측하는 것에 효과적으로 이를 수 있기 때문에, 직 관에 반대되는 것으로 보일 수 있다. 그러나, 일부 실시예들은, 토큰-레벨 과업(특정 토큰이 손상되었는지 여부 를 추측)과 동시에 시퀀스-레벨 학습 과업(적용된 변환을 추측)을 설정하는 것이 예를 들어, 시퀀스 분석기가 존재하지 않는 마스크 패턴들을 예측하는 것을 억제함으로써 올바른 학습을 강화할 수 있다는 점에 의존한다. 일부 실시예들에서, 토큰-레벨 예측들 및 시퀀스-레벨 예측들은 심층 신경망의 별개의 예측 헤드들에 의해 생성된다. 따라서 이상 탐지기에 변환과 토큰 마스크 간의 상관 관계에 대한 선험적 지식이 구축되어 있지 않다. 대 신, 탐지기는 훈련 중에 이러한 잠재적 상관 관계를 학습하고, 이는 보다 강력한 모델로 이끌 수 있다. 컴퓨터 실험에 따르면 토큰-레벨과 시퀀스-레벨 과업을 결합하면 감지기의 성능을 향상시켜 학습을 용이하게 하 는 것으로 나타났다. 반대로, 동일한 레벨의 이상 탐지 성능은 본 명세서에 기술된 바와 같은 트레이닝 전략을 사용하여 더 작은 트레이닝 코퍼스들(corpora) 및/또는 더 적은 네트워크 파라미터를 사용하여 달성될 수 있다. 이것은 트레이닝 코퍼스가 상대적으로 작은 크기를 갖는 상황들(예를 들어, 트레이닝 코퍼스가 소셜 미디어 포스트들로 구성될 때)에서의 저자권한 귀속(authorship attribution)과 같은 이상 탐지 작업들에 특히 유리할 수 있다. 본 명세서에 기술된 바와 같이 탐지기를 훈련시키는 것은 트레이닝 코퍼스의 크기를 인위적으로 증가 시키는 것에 직관적으로 대응하는데, 그 이유는 동일한 트레이닝 토큰 시퀀스가 별개의 시퀀스 변환들 의 적용에 응답으로 다수의 별개의 수정된 시퀀스들을 발생시킬 수 있기 때문이다(도 3 참조). 일부 실시예들은 트레이닝 시퀀스들의 그럴듯한 왜곡들을 생성하기 위해 제2 AI 시스템을 채용한다. 예를 들어, BERT 언어 모델을 구현하는 토큰 발생기는 각 토큰 시퀀스의 나머지의 컨텍스트가 주어지면 선택된 토큰을 그럴 듯한 교체물로 대체하는 데 사용될 수 있다. 일부 실시예들은 이미 훈련된 발생기가 어떤 의미에서 이상으로 간 주되기에는 '너무 그럴듯한' 수정된 트레이닝 시퀀스들을 생성함으로써 학습을 방해할 수 있다는 점에 의존하여, 토큰 발생기의 사전 훈련된 고성능 버전을 사용하는 대신에, 이상 탐지기와 함께 토큰 발생기를 명시 적으로 공동 훈련시킨다. 공동 훈련(co-training)은 시퀀스 분석기가 수정 사항을 감지하는 데 더 능숙해짐에 따라 토큰 발생기가 그럴듯한 수정된 트레이닝 시퀀스를 생성하는 데 점점 더 능숙해지는 것을 확실히 할 수 있 다. 또한 이상 탐지기를 훈련하는 데 사용되는 코퍼스와 구별되는 별개의 코퍼스에서 토큰 발생기를 미리 훈련 시키면 이상치 정보(outlier information)를 가져오고 이상 탐지기가 이를 그렇게 인식하는 것을 방지할 수 있 다. 본 발명의 일부 실시예들에 따라 훈련된 이상 탐지기들은 특히, 다음을 포함하는 다양한 시나리오들에서 사용될 수 있다: 자동 텍스트 분류 예시적인 자연 언어 처리(natural language processing, NLP) 어플리케이션에서, 이상 탐지기는 특정 카테 고리(예를 들어, 비즈니스 뉴스)로부터 속하는 텍스트로 구성된 코퍼스에 대해 훈련될 수 있고, 그 후 타겟 텍 스트 조각이 각각의 카테고리에 속하는지 여부를 결정하는데 사용될 수 있다. 이러한 실시예들에서, 높은 이상 스코어는 각각의 텍스트가 각각의 카테고리에 속하지 않는다는 것을 나타낼 수 있다. 컴퓨터 실험에서, 본 명세서에 기술된 바와 같은 이상 탐지기는 뉴스 기사들의 표준 기준 코퍼스(20Newsgroups, 20개의 뉴스그륩)의 서브세트에 대해 훈련되었고, 이 서브세트는 선택된 카테고리(컴퓨팅, 레크리에이션, 과학, 기타, 정치 또는 종교)로부터의 기사들로 구성되었다. 이 실험에서는 상단에 2개의 예측 헤드가 있는 4개의 적 층된 변환기 레이어(stacked transformer layer)를 포함하는 시퀀스 분석기를 사용했다. 각 변환기 레이어는 4 개의 자기-주의 헤드(self-attention head), 크기 256의 숨겨진 레이어, 크기 1024 및 256의 피드-포워드 레이 어(feed-forward layer)를 포함하였다. 각 예측 헤드는 비선형성(non-linearity)으로 분리되고 분류 레이어로 끝나는 2개의 선형 레이어를 가졌다. 트레이닝 토큰 시퀀스의 최대 크기는 128였다. 시퀀스 변환은 랜덤 토 큰 발생기(random token generator)를 사용하여 별개의 마스크 패턴에 따라 토큰을 교체하는 것으로 구성되었다. 입력 트레이닝 시퀀스의 25%에서 50% 사이를 커버하는, 5개에서 100개 사이의 별개의 마스크 패턴 들로 다양한 카운트 및 커버리지의 마스크 패턴을 시도했다. 그런 다음 훈련된 탐지기는 컬렉션에서 무작위로 선택된 기사가 탐지기가 훈련된 범주에 속하는지 여부를 식별 하도록 요청받았다. 본 발명의 일부 실시예들에 따라 훈련된 이상 탐지기는 각각의 과업에서 일관되고 실질적으 로 종래의 최신식 이상 탐지기들을 능가하였으며, 수신기 작동 곡선(receiver operating curve) 아래 전형적 영 역(AUROC) 값은 대략 70%(과학 카테고리에 대해 훈련된 경우)에서 92% 이상(컴퓨팅 뉴스에 대해 훈련된 경우)에 이르렀다. 이 실험은 일반적으로 별개의 변환의 수를 늘리면 훈련된 이상 탐지기의 성능을 어느 정도까지 향상 시키고, 토큰 임베딩의 표현력(expressiveness)을 북돋는 것으로 나타났다. 25%에서 50%의 비율의 손상된 토큰 을 가지는 변환이 최상의 결과를 생성하는 것으로 나타났다. 자동 저자권한 귀속(authorship attribution) 이상 탐지기의 일부 실시예들은 선택된 저자에 의해 작성된 텍스트의 코퍼스(예를 들어, 편지들, 기사들, 블로그 포스트들, 이메일들, 소셜 미디어 포스트들)에 대해 훈련될 수 있고, 그 후 타겟 텍스트 조각이 각각의사람에 의해 작성되었는지를 결정하는데 사용될 수 있다. 예시적인 어플리케이션은 익명의 편지의 저자 결정, 다양한 문서의 진위 확인, 및 문학 작품의 사후 귀속이 포함된다. 일부 실시예는 포렌식 응용예를 가질 수 있다. 예를 들어, 법 집행 기관은 다크 웹 리소스의 작성자 또는 사용자를 식별하는 데, 예를 들어, 도난당한 상품, 신용 카드 데이터, 아동 포르노, 총기, 마약 등의 거래와 같은 범죄 활동에 관여하는 사용자들을 위한 만 남의 장소로서 작용하는 포럼에 게시된 메시지의 작성자를 식별하는 데 관심이 있을 수 있다. 여기에서 '다크 웹(Dark Web)'이라는 용어는 검색 엔진에 의해 인덱싱되지 않고 그리고/또는 개인 P2P 네트워크(peer-to-peer network) 또는 토어(Tor)와 같은 익명 소프트웨어(anonymizing software)를 통해서만 액세스할 수 있는 콘텐트 를 나타내는 데 사용된다. 용의자들의 세트에 의해 작성되고 공개적으로 이용가능한 온라인 콘텐트의 코퍼스(예를 들면, 인기 있는 소셜 미디어 사이트들 및/또는 사용자 포럼들 상에 각각의 용의자들에 의해 포스팅된 코멘트들)에 대해 훈련된 이상 탐지기의 예시적인 실시예는 그 후, 다크 웹으로부터 수확된 타겟 텍스트 조각을 분석하기 위해 사용될 수 있다. 타겟 텍스트가 변칙적이지 않음을 나타내는 이상 스코어(anomaly score)는 타겟 텍스트의 저자가 탐지기 가 훈련되었던 텍스트 코퍼스의 저자(작성자) 중 한 명과 일치함을 나타낼 수 있다. 소셜 미디어 모니터링 이상 탐지기의 실시예는 선택된 세트의 소셜 미디어 계정과 연관된 웹 콘텐트, 예를 들어 트위터® 피드의 특정 컬렉션에 대해 훈련될 수 있다. 트레이닝 코퍼스는 특정 시간 윈도우(예를 들어, 하루, 일주일 등) 내에 공개된 콘텐트로 추가로 제한될 수 있다. 그 후, 탐지기는 새롭게 포스팅된 콘텐트를 분석하기 위해 사용될 수 있다. 이상(anomaly, 이례, 변칙)은 주제의 변화 및/또는 진행 중인 교환(ongoing exchange)의 어조의 변화를 나타낼 수 있고 따라서 새로운 주제 및 트렌드를 적시에 자동으로 탐지할 수 있게 한다. 가짜 및 자동 생성된 콘텐트의 탐지 이상 탐지기의 실시예는 선택된 인간 저자에 의해 작성된 텍스트의 코퍼스(예를 들어, 실제 뉴스 기사, 실 제 사용자에 의한 소셜 미디어 포스트)에 대해 훈련될 수 있다. 코퍼스는 선택된 저널, 신문 또는 뉴스 웹사이 트를 위해 작성된 기사 또는 선택된 저널리스트가 작성한 기사로 추가로 좁혀질 수 있다. 그런 다음 훈련된 이 상 탐지기가 타겟 텍스트 조각을 분석하기 위하여 사용될 수 있다. 타겟 텍스트가 변칙적이라는 것을 나타내는 이상 스코어는 각각의 텍스트가 가짜 뉴스를 포함할 수 있고 그리고/또는 기계-생성된 것일 수 있다는 것을 나 타낼 수 있다. 데이터 보호 및 프라이버시 일부 클라우드 컴퓨팅 서비스는 사용자가 다른 사용자와 공유하거나 다양한 조작(예: 멀웨어 스캐닝)을 위해 원 격 서버에 파일을 업로드할 수 있게 한다. 일례로, 사용자의 컴퓨터 상에서 실행되는 소프트웨어 에이전트는 선 택된 폴더의 콘텐트를 자동으로 업로드할 수 있으며, 이는 각각의 사용자에 의해 표시(indicating)될 수 있다. 클라우드에 데이터를 업로드하는 것은 특히 사용자가 업로드할 콘텐트를 명시적으로 선택하지 않는 경우 프라이 버시 위험을 포함할 수 있다. 예를 들어, 사용자가 실수로 일부 민감한 데이터(예를 들어, 개인 파일 또는 사진, 의료 기록 등)를 업로드 폴더에 드롭하는 경우, 각각의 데이터는 사용자의 희망에 반하여 자동으로 업로 드될 것이다. 이상 탐지기의 실시예는 사용자의 컴퓨터에 설치될 수 있고, 각각의 사용자에 의해 통상적으로 업로드되는 파일들, 예를 들어 원격 스캐닝을 위해 가장 최근에 업로드된 100개의 파일들에 대해 훈련될 수 있다. 추가 필 터는 PDF(Portable Document Format) 문서 또는 Microsoft® Office® 파일과 같은 특정 종류의 파일만 선택할 수 있다. 이러한 실시예들은 상술된 바와 같은 자연 언어 처리 기술들을 사용할 수 있으며, 여기서 토큰들은 개 별적인 단어들 등을 포함한다. 그런 다음 훈련된 이상 탐지기는 업로드를 위한 준비 시 원격 스캐닝을 위해 현 재 지정된 각 파일을 분석하는 데 사용될 수 있다. 각각의 파일에 대해 결정된 이상 스코어가 잠재적인 이상을 나타낼 때, 일부 실시예들은 각각의 파일이 업로드되는 것을 방지할 수 있고, 사용자에게 통지할 수 있다. 컴퓨터 보안 이상 탐지기의 일부 실시예들은 활동의 정상 패턴을 나타내는 것으로 간주되는 기준 시간 간격 동안 발생하 는 컴퓨팅 이벤트들의 시퀀스들에 대해 훈련될 수 있고, 그 후 설정된 클라이언트 컴퓨터 시스템들의 행동을 모 니터링하기 위해 사용될 수 있다. 클라이언트에서 탐지된 변칙적인 행동은 예를 들어 각 클라이언트가 악성 소 프트웨어를 실행 중이거나 또는 침입자/해커가 각 클라이언트에 대한 액세스를 획득한 것과 같은 컴퓨터 보안위협을 나타낼 수 있다. 일부 실시예들에서, 이상 탐지는 모니터링된 소프트웨어 엔티티(예를 들어, 프로세스, 가상 머신 등)의 실행 동 안 발생하는 이벤트들의 시퀀스들을 분석하는 것을 포함한다. 이러한 이벤트의 예로는, 특히 프로세스/쓰레드 (thread)의 개시(예: 사용자가 어플리케이션을 시작하고, 부모 프로세스가 자식 프로세스를 생성하는 등), 각 클라이언트 시스템의 입력 장치(예: 카메라, 마이크)에 액세스하려는 시도, 로컬 또는 원격 네트워크 리소스에 액세스하려는 시도(예: 하이퍼텍스트 전송 프로토콜 - 특정 URL에 액세스하기 위한 HTTP 요청, 로컬 네트워크 상에 문서 저장소에 액세스하려는 시도), 특정 URI(uniform resource identifier) 체계로 표현된 요청(예: mailto: 또는 ftp: 요청), 특정 프로세서 명령의 실행(예: 시스템 호출), 라이브러리를 로드하려는 시도(예: 동 적 링크된 라이브러리(dynamic linked library) - DLL), 새 디스크 파일을 생성하려는 시도 , 디스크의 특정 위 치에서 읽거나 쓰려는 시도(예: 기존 파일 덮어쓰기 시도, 특정 폴더 또는 문서 열기 시도) 및 전자 메시지를 보내려는 시도(예: 이메일, 단문 메시지 서비스 - SMS 등) 등이 있다. 일부 실시예들에서, 비활성의 기간들, 즉, 이벤트들 사이의 시간 갭들 및/또는 각각의 클라이언트 시스템이 아이들(idle) 상태이거나, 사용자 활동을 등록하지 않거나, 또는 내부 시스템 작업들만을 수행할 때의 시간 간격들 또한 이벤트로서 자격이 있을 수 있다. 숙련된 기술자는 본 명세서에 기술된 시스템 및 방법이 특히 소셜 미디어 상의 사용자의 활동, 사용자의 브라우징 히스토리 및 사용자의 게임 활동과 관련된 이벤트와 같은 다른 종류의 이벤트를 분석하는 데 적합화될 수 있음을 이해할 것이다."}
{"patent_id": "10-2023-7037479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "이벤트 탐지는 본 기술분야에서 알려진 임의의 방법을 포함할 수 있다. 일례로, 보호된 클라이언트 상에서 실행 되는 보안 에이전트는 모니터링된 소프트웨어 엔티티의 세트를 Windows®에 대한 이벤트 트랙킹과 같은 OS 의 이벤트 로깅 서비스에 등록할 수 있다. 이에 응답하여, 에이전트는 각각의 프로세스의 실행 동안에 발생하는 다양한 이벤트들의 통지들을 실시간 또는 로그 형태로 수신할 수 있다. 이벤트 로깅 도구는 일반적으로 각 이벤 트에 대한 타임스탬프, 이벤트 유형을 식별하는 숫자 코드, 각 이벤트를 생성한 프로세스 또는 어플리케이션의 유형의 표시자, 및 기타 이벤트 파라미터를 포함하는 이벤트 기술자(descriptor)의 목록을 생성한다. 이벤트 시 퀀스는 로그를 파싱(parsing, 분석)하여 조합될 수 있다. 일부 실시예들은 각각의 이벤트를 별도의 토큰(separate token)으로 취급할 수 있다. 토큰들은 이벤트 어휘에 따라 인코딩될 수 있으며, 이는 수천에서 수백만 개의 별개의 이벤트 유형들(distinct event types)을 포함할 수 있다. 다음으로, 이상 탐지기를 훈련시키는 것은 상술한 바와 같이 트레이닝 이벤트 시퀀스들에 다양한 변환 들을 적용하는 것을 포함할 수 있다. 예시적인 시퀀스 변환은 트레이닝 시퀀스의 선택된 이벤트들을 삭제, 삽입, 및 치환하는 것뿐만 아니라, 선택된 이벤트들을 다른 종류의 대체 이벤트들로 교체하는 것을 포함할 수 있다. 대안적인 실시예들은 이벤트 로그 엔트리를 텍스트 토큰들의 시퀀스로서 고려할 수 있다. 예를 들어 로그 엔트 리는 다음과 같다: 20:10 | INFO | manager.storage | Found block rdd_2_3 locally 은 토큰 시퀀스로 파싱될 수 있다: 20:10 ; INFO; manager ; storage ; Found ; block ; rdd_2_3 ; locally, 여기서 개별 토큰은 세미콜론으로 구분된다. 다음으로, 입력 수정자는 선택된 토큰들을 대체물들로 교체함 으로써 각각의 토큰 시퀀스를 왜곡시킬 수 있다. 대체를 위해 선택된 토큰의 위치는 전술한 바와 같이 마스크에 의해 나타내질 수 있다. 이러한 일 예로, 상기 예에 대해 결정된 수정된 토큰 시퀀스는 다음과 같을 수 있다: 20:10 ; DEBUG ; manager; thread ; Found ; block ; rdd_2_3 ; globally, 여기서 대체 토큰은 굵은 글씨로 표시된다. 일부 실시예들에서, 블로그 엔트리의 선택된 필드들이 수정되지 않 도록 마스크들이 선택된다. 차례로, 토큰 발생기는 후보 들의 필드-특정 또는 위치-특정 풀로부터 대체 토 큰들을 선택하도록 구성될 수 있다. 위의 예에서 두 번째 토큰을 위한 후보 대체물의 풀은 {WARNING, DEBUG, INFO, CRITICAL}로 구성될 수 있다. 로그에 대한 이상 탐지의 예시적인 어플리케이션은 허니팟 시스템(honeypot system)에 기록된 액세스 및/또는 이벤트 로그를 분석하여 제로-데이 익스플로잇(zero-day exploit)을 탐지하는 것을 포함한다. 본 명세서에 기술 된 바와 같은 이상 탐지기는 로그의 제1 부분에 대해 훈련될 수 있고, 따라서 로그의 제1 부분에 대응하는 시간 기간 동안 각각의 허니팟의 '정상적인' 행동을 학습할 수 있다. 그런 다음 이상 탐지기를 사용하여 로그의 제2부분을 분석할 수 있다. 이상은 로그의 제1 부분과 제2 부분 사이의 허니팟 행동의 변화를 나타낼 수 있으며, 새로운 멀웨어의 가능한 변형(apparition), 봇넷의 활성화 등을 암시한다. 일부 실시예들은 주기적으로 이상 탐 지기를 재훈련시킬 수 있고(예를 들어, 이전 시간으로부터의 로그 데이터에 대해 매시간) 이를 사용하여 실시간 으로 새로운 위협들을 모니터링할 수 있다. 본 발명의 범위를 벗어나지 않으면서 다양한 방법으로 상기 실시예들이 변경될 수 있음은 통상의 기술자에게 자 명할 것이다. 따라서, 본 발명의 범위는 이하의 청구항들과 이들의 법적 균등물에 의하여 결정되어야 한다."}
{"patent_id": "10-2023-7037479", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 전술한 태양들 및 장점들은 후술하는 상세한 설명 및 도면을 참조로 이해하면 더욱 잘 이해될 것이다. 도 1은 본 발명의 일부 실시예들에 따른 이상들을 탐지하는데 있어서 유틸리티 서버와 협력하는 클라이언트 시 스템들의 세트를 보여준다. 도 2는 본 발명의 일부 실시예들에 따른 이상 탐지기의 예시적인 작동을 보여준다. 도 3은 본 발명의 일부 실시예들에 따른 이상 탐지기의 예시적인 트레이닝을 보여준다. 도 4는 본 발명의 일부 실시예들에 따른 입력 수정자(input modifier)의 예시적인 작동을 보여준다. 도 5는 본 발명의 일부 실시예들에 따른 예시적인 토큰 임베딩 공간(token embedding space)을 보여준다. 도 6은 일부 실시예들에 따른 예시적인 시퀀스 변환을 보여주며, 상기 예시된 변환은 선택된 토큰의 대표 벡터 를 넛징(nudging, 밀어내기)하는 것을 포함한다. 도 7은 본 발명의 일부 실시예들에 따른 시퀀스 분류기(sequence classifier)의 예시적인 구조를 보여준다. 도 8은 본 발명의 일부 실시예들에 따른 이상 탐지기의 트레이닝 동안에 수행되는 단계들의 예시적인 시퀀스를 보여준다. 도 9는 본 발명의 일부 실시예들에 따른 훈련된 이상 탐지기에 의해 수행되는 단계들의 예시적인 시퀀스를 보여 준다. 도 10 은 본 명세서에 기술된 방법들 중 일부를 수행하도록 구성된 예시적인 컴퓨팅 장치를 나타낸다."}
