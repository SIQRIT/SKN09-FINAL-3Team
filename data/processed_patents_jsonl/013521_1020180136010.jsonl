{"patent_id": "10-2018-0136010", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0052694", "출원번호": "10-2018-0136010", "발명의 명칭": "이동체에 포함된 카메라 시스템 및 그 제어방법.", "출원인": "삼성전자주식회사", "발명자": "서정훈"}}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이동체(vehicle)에 포함된 카메라 시스템에 있어서,상기 이동체에 구비되며, 상기 이동체 주변을 촬영하기 위한 카메라; 및상기 카메라에 의해 촬영된 이미지에 기초하여 상기 이동체 주변에 존재하는 객체를 식별하는 프로세서;를 포함하고,상기 카메라는, 광각 렌즈 및 상기 광각 렌즈의 시야각 내의 영역을 촬영하기 위한 복수의 광 센서를 포함하고,상기 광각 렌즈는,상기 시야각이 일정한 각도로 구분된 복수의 각도 범위 중 기설정된 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수가 다른 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수와 달라지도록 설계된, 카메라 시스템."}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 광각 렌즈는,상기 기설정된 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수가 상기 다른 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수보다 많아지도록 설계된, 카메라 시스템."}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 카메라에 의해 촬영된 이미지에서, 상기 기설정된 각도 범위에서 촬영된 영역에 포함된 픽셀의 수는 상기다른 각도 범위에서 촬영된 영역에 포함된 픽셀의 수보다 많은, 카메라 시스템."}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 기설정된 각도 범위는,상기 이동체에서 상기 카메라가 배치되는 각도에 기초하여 기설정되는, 카메라 시스템."}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 기설정된 각도 범위는,상기 이동체의 구조 및 상기 이동체에 탑승한 사용자의 시야에 기초하여 기설정되는, 카메라 시스템."}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 카메라는,상기 이동체의 좌측에 부착되며, 상기 이동체의 전방 및 좌측을 촬영하기 위한 제1 카메라 및 상기 이동체의 후방 및 좌측을 촬영하기 위한 제2 카메라; 및상기 이동체의 우측에 부착되며, 상기 이동체의 전방 및 우측을 촬영하기 위한 제3 카메라 및 상기 이동체의 후공개특허 10-2020-0052694-3-방 및 우측을 촬영하기 위한 제4 카메라;를 포함하는, 카메라 시스템."}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 프로세서는,상기 이동체의 속도 및 주행 방향 중 적어도 하나에 기초하여, 상기 제1 내지 제4 카메라에 의해 촬영된 이미지각각 내에서 주요 영역을 식별하고,상기 식별된 주요 영역에 기초하여 상기 이동체의 주변에 존재하는 객체를 식별하는, 카메라 시스템."}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 프로세서는,상기 주요 영역의 사이즈가 기설정된 값보다 큰 경우, 상기 주요 영역 내 객체 식별을 위한 연산의 양을 기설정된 값 이하로 줄이는, 카메라 시스템."}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 프로세서는,상기 제1 내지 제4 카메라 중 상기 이동체의 주행방향에 대응되는 위치에 부착된 카메라에 의해 촬영된 이미지내에서 식별된 주요 영역에 대해서는, 다른 카메라에 의해 촬영된 이미지 내에서 식별된 주요 영역보다 객체 식별을 위한 연산을 더 많이 수행하여, 상기 이동체의 주변에 존재하는 객체를 식별하는, 카메라 시스템."}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서,상기 제1 내지 제4 카메라에서 촬영된 복수의 이미지에 대응되는 데이터를 병렬로 수신하여 상기 프로세서로 전송하는 Serializer IC(Integrated Circuit);를 더 포함하는, 카메라 시스템."}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 프로세서는,상기 식별된 객체에 대한 정보에 기초하여 상기 객체의 위험도를 식별하고,상기 식별된 위험도에 기초하여 상기 이동체를 제어하는, 카메라 시스템."}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "이동체(vehicle)에 포함된 카메라 시스템의 제어 방법에 있어서,상기 이동체에 구비된 카메라를 이용하여 상기 이동체의 주변을 촬영하는 단계;상기 카메라에 의해 촬영된 이미지에 기초하여 상기 이동체 주변에 존재하는 객체를 식별하는 단계;를포함하고,상기 카메라는, 광각 렌즈 및 상기 광각 렌즈의 시야각 내의 영역을 촬영하기 위한 복수의 광 센서를 포함하고,상기 광각 렌즈는,상기 시야각이 일정한 각도로 구분된 복수의 각도 범위 중 기설정된 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수가 다른 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수와 달라지도록 설계된, 제어방법.공개특허 10-2020-0052694-4-청구항 13 이동체(vehicle)에 포함된 카메라 시스템의 제어 방법에 있어서,상기 이동체의 좌측에 부착되며, 상기 이동체의 전방 및 좌측을 촬영하기 위한 제1 카메라 및 상기 이동체의 후방 및 좌측을 촬영하기 위한 제2 카메라를 이용하여 상기 이동체의 주변을 촬영하는 단계;상기 이동체의 우측에 부착되며, 상기 이동체의 전방 및 우측을 촬영하기 위한 제3 카메라 및 상기 이동체의 후방 및 우측을 촬영하기 위한 제4 카메라를 이용하여 상기 이동체의 주변을 촬영하는 단계; 및상기 제1 내지 제4 카메라에 의해 촬영된 이미지에 기초하여 상기 이동체 주변에 존재하는 객체를 식별하는 단계;를 포함하고,상기 제1 내지 제4 카메라 각각은, 광각 렌즈 및 상기 광각 렌즈의 시야각 내의 영역을 촬영하기 위한 복수의광 센서를 포함하고,상기 광각 렌즈는,상기 시야각이 일정한 각도로 구분된 복수의 각도 범위 중 기설정된 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수가 다른 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수와 달라지도록 설계된, 제어방법."}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 이동체의 속도 및 주행 방향 중 적어도 하나에 기초하여, 상기 제1 내지 제4 카메라에 의해 촬영된 이미지각각 내에서 주요 영역을 식별하는 단계; 및상기 식별된 주요 영역에 기초하여 상기 이동체의 주변에 존재하는 객체를 식별하는 단계;를 더 포함하는, 제어방법."}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 이동체의 주변에 존재하는 객체를 식별하는 단계는,상기 주요 영역의 사이즈가 기설정된 값보다 큰 경우, 상기 주요 영역 내 객체 식별을 위한 연산의 양을 기설정된 값 이하로 줄이는 단계를 포함하는, 제어 방법."}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 이동체의 주변에 존재하는 객체를 식별하는 단계는,상기 제1 내지 제4 카메라 중 상기 이동체의 주행방향에 대응되는 위치에 부착된 카메라에 의해 촬영된 이미지내에서 식별된 주요 영역에 대해서는, 다른 카메라에 의해 촬영된 이미지 내에서 식별된 주요 영역보다 객체 식별을 위한 연산을 더 많이 수행하여, 상기 이동체의 주변에 존재하는 객체를 식별하는, 제어 방법."}
{"patent_id": "10-2018-0136010", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 식별된 객체에 대한 정보에 기초하여 상기 객체의 위험도를 식별하는 단계; 및상기 식별된 위험도에 기초하여 상기 이동체를 제어하는 단계;를 더 포함하는 제어 방법."}
{"patent_id": "10-2018-0136010", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이동체(vehicle)에 포함된 카메라 시스템을 개시한다. 본 카메라 시스템은, 이동체에 구비되며 이동체 주변을 촬 영하기 위한 카메라, 카메라에 의해 촬영된 이미지에 기초하여 이동체 주변에 존재하는 객체를 식별하는 프로세 서를 포함하고, 카메라는, 광각 렌즈 및 광각 렌즈의 시야각 내의 영역을 촬영하기 위한 복수의 광 센서를 포함 하고, 광각 렌즈는, 시야각이 일정한 각도로 구분된 복수의 각도 범위 중 기설정된 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수가 다른 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수와 달라지도록 설 계된 것을 특징으로 한다."}
{"patent_id": "10-2018-0136010", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 이동체에 포함된 카메라 시스템 및 운전자 보조 시스템(Advanced Driver Assistance Systems)에 관 한 것으로, 보다 상세하게는, 이동체 주변의 넓은 범위를 촬영하기 위한 광각 렌즈를 이용하여 이동체 주변의 위험 객체를 식별하기 위한 카메라 시스템에 관한 것이다."}
{"patent_id": "10-2018-0136010", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자동차 등의 이동체(vehicle)를 운전하는 운전자의 안전을 위해, 다양한 운전자 보조 시스템(Advanced Driver Assistant System, ADAS)이 이동체에 탑재되고 있다. 특히, 자동차에 부착된 카메라를 이용하여 자동차의 전방, 후방, 측면 등을 촬영하고 주변의 위험 요소를 인식 하는 카메라 시스템들이 다양하게 제작 및 이용되고 있다. 종래의 카메라 시스템에는 단일 또는 스테레오 카메라를 이용하여 전방의 위험요소를 인식하는 전방 카메라 시 스템, 후방/측방 카메라를 이용하여 후방 및 측방의 위험요소를 인식하는 후/측방 카메라 시스템, 전방/후방/측 방 카메라를 이용하여 근접한 전방/후방/측방의 위험요소를 인식하는 SVM(Surround View Monitoring) 카메라 시 스템 등이 있었다. 도 1은 자동차에 부착된 종래의 카메라 시스템들에 대해 간략히 설명하기 위한 도면이다. 도 1의 (a)는 자동차의 전방에 부착된 스테레오 카메라를 이용한 전방 카메라 시스템의 물체 인식 영역, 도 1의 (b)는 자동차의 사이드 미러에 부착된 후/측방 카메라들을 이용한 후/측방 카메라 시스템의 물체 인식 영역, 도 1의 (c)는 전방과 후방 및 좌/우측 사이드 미러에 각각 부착된 4대의 카메라를 이용한 SVM 카메라 시스템의 물 체 인식 영역을 도시한 것이다. 종래, 상술한 카메라 시스템들은 물체를 인식하는 영역이 서로 다름은 물론 그 역할 자체가 서로 다르므로, 각 각 별도의 ECU(Electronic Control Unit)에 기초하여 제어되었다. 따라서, 종래 상술한 카메라 시스템들을 모두 포함하는 자동차는, 도 1의 (d)와 같이 도합 8개의 카메라 및 3개 의 ECU를 탑재해야 했고, 이에 따라 그 설계 및 배선이 복잡해져 설치비용의 문제가 있음은 물론 차량의 적재 공간이 부족하다는 문제가 있었다. 아울러, 상술한 카메라 시스템들 간의 전자파/노이즈 간섭 역시 무시할 수 없었으며, 상술한 카메라 시스템들은 서로 사용되는 시기가 다르기 때문에(ex. 차량의 고속 주행 중에는 SVM 기 능이 필요 없으므로 SVM 카메라 시스템은 유휴 상태.) 상황에 따라 일부 카메라 시스템 자원은 유휴 상태가 되 어 시스템 자원이 낭비되는 문제도 있었다. 또한, 도 1의 (d)에는 도시되지 않았으나, 자동차 등의 통합적인 제어를 위해서는, 상술한 카메라 시스템들의 ECU 각각으로부터 정보를 받고 각각의 ECU들을 제어하기 위한 통합 ECU도 별도로 필요하다는 점 역시, 설계 및 구현에 있어 난점이었다. 그리고, 도 1의 (e)를 참조하면, 상술한 카메라 시스템을 모두 이용하더라도 촬영되지 않는 사각지대(Blind Spot)가 비교적 넓은 범위에 걸쳐 존재했다."}
{"patent_id": "10-2018-0136010", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 목적은, 비교적 작은 수의 광각 렌즈 카메라에 대한 효율적인 배치 구조 및 하나의 통합 프로세서만 을 이용하여, 종래의 카메라 시스템들이 촬영할 수 있었던 영역은 물론 종래의 카메라 시스템들이 촬영하지 못 했던 사각지대(Blind Spot)도 포함한 넓은 영역에 걸쳐 위험요소를 효율적으로 인식할 수 있는 하나의 통합 카 메라 시스템 및 그 제어 방법을 제공함에 있다. 또한, 본 개시를 통해, 넓은 범위에 대한 이미지를 획득하는 대신 그 정밀도가 비교적 떨어지는 광각 렌즈의 단 점을 고려하여, 광각 렌즈의 시야각 내의 영역 중 중요도가 높은 각도 범위에 대응되는 영역에 대해서는 더 정 밀한 객체 인식이 가능한 카메라 시스템 및 그 제어 방법을 제공함에도 그 목적이 있다. 아울러, 카메라 시스템이 구비된 이동체(vehicle)의 상태에 따라 복수의 카메라를 통해 촬영된 이미지들에 대해 관심영역을 식별하고, 식별된 관심영역에 기초하여 이동체의 주변에 존재하는 객체를 효율적으로 인식하는 카메 라 시스템 및 그 제어 방법도 제공하고자 한다."}
{"patent_id": "10-2018-0136010", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른, 이동체(vehicle)에 포함된 카메라 시스템은, 상기 이동체에 구비되며, 상기 이동 체 주변을 촬영하기 위한 카메라, 상기 카메라에 의해 촬영된 이미지에 기초하여 상기 이동체 주변에 존재하는 객체를 식별하는 프로세서를 포함하고, 상기 카메라는, 광각 렌즈 및 상기 광각 렌즈의 시야각 내의 영역을 촬 영하기 위한 복수의 광 센서를 포함하고, 상기 광각 렌즈는, 상기 시야각이 일정한 각도로 구분된 복수의 각도 범위 중 기설정된 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수가 다른 각도 범위에 대응되는 영역 을 촬영하기 위한 광 센서의 수와 달라지도록 설계된다. 이때, 상기 광각 렌즈는, 상기 기설정된 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수가 상기 다른 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수보다 많아지도록 설계될 수 있다. 그리고, 상기 카메라에 의해 촬영된 이미지에서, 상기 기설정된 각도 범위에서 촬영된 영역에 포함된 픽셀의 수 는 상기 다른 각도 범위에서 촬영된 영역에 포함된 픽셀의 수보다 많을 수 있다. 한편, 상기 기설정된 각도 범위는, 상기 이동체에서 상기 카메라가 배치되는 각도에 기초하여 기설정될 수 있다. 그리고, 상기 기설정된 각도 범위는, 상기 이동체의 구조 및 상기 이동체에 탑승한 사용자의 시야에 기초하여 기설정될 수도 있다. 한편, 상기 카메라는, 상기 이동체의 좌측에 부착되며, 상기 이동체의 전방 및 좌측을 촬영하기 위한 제1 카메 라 및 상기 이동체의 후방 및 좌측을 촬영하기 위한 제2 카메라, 상기 이동체의 우측에 부착되며, 상기 이동체 의 전방 및 우측을 촬영하기 위한 제3 카메라 및 상기 이동체의 후방 및 우측을 촬영하기 위한 제4 카메라를 포 함할 수 있다. 이때, 상기 프로세서는, 상기 이동체의 속도 및 주행 방향 중 적어도 하나에 기초하여, 상기 제1 내지 제4 카메 라에 의해 촬영된 이미지 각각 내에서 주요 영역을 식별하고, 상기 식별된 주요 영역에 기초하여 상기 이동체의 주변에 존재하는 객체를 식별할 수 있다. 이 경우, 상기 프로세서는, 상기 주요 영역의 사이즈가 기설정된 값보다 큰 경우, 상기 관심영역 내 객체 식별 을 위한 연산의 양을 기설정된 값 이하로 줄일 수 있다. 또한, 상기 프로세서는, 상기 제1 내지 제4 카메라 중 상기 이동체의 주행방향에 대응되는 위치에 부착된 카메 라에 의해 촬영된 이미지 내에서 식별된 주요 영역에 대해서는, 다른 카메라에 의해 촬영된 이미지 내에서 식별 된 주요 영역보다 객체 식별을 위한 연산을 더 많이 수행하여, 상기 이동체의 주변에 존재하는 객체를 식별할 수도 있다. 그리고, 본 카메라 시스템은, 제1 내지 제4 카메라에서 촬영된 복수의 이미지에 대응되는 데이터를 병렬로 수신 하여 상기 프로세서로 전송하는 Serializer IC(Integrated Circuit)를 더 포함할 수 있다. 또한, 상기 프로세서는, 상기 식별된 객체에 대한 정보에 기초하여 상기 객체의 위험도를 식별하고, 상기 식별 된 위험도에 기초하여 상기 이동체를 제어할 수 있다. 본 개시의 일 실시 예에 따른, 이동체(vehicle)에 포함된 카메라 시스템의 제어 방법은, 상기 이동체에 구비된 카메라를 이용하여 상기 이동체의 주변을 촬영하는 단계, 상기 카메라에 의해 촬영된 이미지에 기초하여 상기 이동체 주변에 존재하는 객체를 식별하는 단계를 포함하고, 상기 카메라는, 광각 렌즈 및 상기 광각 렌즈의 시 야각 내의 영역을 촬영하기 위한 복수의 광 센서를 포함하고, 상기 광각 렌즈는, 상기 시야각이 일정한 각도로 구분된 복수의 각도 범위 중 기설정된 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수가 다른 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수와 달라지도록 설계된다. 본 개시의 다른 실시 예에 따른, 이동체(vehicle)에 포함된 카메라 시스템의 제어 방법은, 상기 이동체의 좌측 에 부착되며, 상기 이동체의 전방 및 좌측을 촬영하기 위한 제1 카메라 및 상기 이동체의 후방 및 좌측을 촬영 하기 위한 제2 카메라를 이용하여 상기 이동체의 주변을 촬영하는 단계, 상기 이동체의 우측에 부착되며, 상기 이동체의 전방 및 우측을 촬영하기 위한 제3 카메라 및 상기 이동체의 후방 및 우측을 촬영하기 위한 제4 카메 라를 이용하여 상기 이동체의 주변을 촬영하는 단계, 상기 제1 내지 제4 카메라에 의해 촬영된 이미지에 기초하 여 상기 이동체 주변에 존재하는 객체를 식별하는 단계를 포함하고, 상기 제1 내지 제4 카메라 각각은, 광각 렌 즈 및 상기 광각 렌즈의 시야각 내의 영역을 촬영하기 위한 복수의 광 센서를 포함하고, 상기 광각 렌즈는, 상 기 시야각이 일정한 각도로 구분된 복수의 각도 범위 중 기설정된 각도 범위에 대응되는 영역을 촬영하기 위한광 센서의 수가 다른 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수와 달라지도록 설계된다. 이때, 상기 제어 방법은, 상기 이동체의 속도 및 주행 방향 중 적어도 하나에 기초하여, 상기 제1 내지 제4 카 메라에 의해 촬영된 이미지 각각 내에서 주요 영역을 식별하는 단계, 상기 식별된 주요 영역에 기초하여 상기 이동체의 주변에 존재하는 객체를 식별하는 단계를 더 포함할 수 있다. 이 경우, 상기 이동체의 주변에 존재하는 객체를 식별하는 단계는, 상기 관심영역의 사이즈가 기설정된 값보다 큰 경우, 상기 주요 영역 내 객체 식별을 위한 연산의 양을 기설정된 값 이하로 줄이는 단계를 포함할 수 있다. 또한, 상기 이동체의 주변에 존재하는 객체를 식별하는 단계는, 상기 제1 내지 제4 카메라 중 상기 이동체의 주 행방향에 대응되는 위치에 부착된 카메라에 의해 촬영된 이미지 내에서 식별된 주요 영역에 대해서는, 다른 카 메라에 의해 촬영된 이미지 내에서 식별된 주요 영역보다 객체 식별을 위한 연산을 더 많이 수행하여, 상기 이 동체의 주변에 존재하는 객체를 식별할 수도 있다. 그리고, 상기 제어 방법은, 상기 식별된 객체에 대한 정보에 기초하여 상기 객체의 위험도를 식별하는 단계, 상 기 식별된 위험도에 기초하여 상기 이동체를 제어하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2018-0136010", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따른 카메라 시스템은, 광각 렌즈를 사용하여 더 넓은 범위를 촬영하면서도, 촬영된 영역 중 특정 영 역에 대해서는 그 정밀도를 확보하기 위해 각 영역에 대응되는 픽셀 수가 달라지도록 광각 렌즈를 설계하여, 객 체 인식의 정밀성도 갖출 수 있다는 효과가 있다. 본 개시에 있어 4대의 카메라를 사용하는 카메라 시스템은, 종래의 카메라 시스템들의 조합에 비해 더 넓은 범 위를 촬영할 수 있으면서도, 그 설계 및 배선이 한층 간결해지고 공간 확보 및 비용 절감의 효과가 있다. 특히, 이동체 주변의 위험요소 모두를 단 하나의 카메라 시스템만으로 대비할 수 있는 본 카메라 시스템의 특성으로 말미암아 향후 자율주행자동차에 유용하게 사용될 수 있다. 본 개시에 따른 카메라 시스템은, 하나의 카메라 시스템만으로 이동체의 전/후/좌/우 넓은 영역을 촬영할 수 있 으므로, 시스템 간의 전자파/노이즈 간섭을 피할 수 있다. 본 개시에 따른 카메라 시스템은, 각 카메라가 비교적 넓은 범위를 촬영하는 특성상, 이동체의 상황에 따라 특 정 카메라의 유휴 상태가 발생할 여지가 적고, 그 결과, 시스템 자원의 낭비를 줄일 수 있다. 또한, 본 개시에 따른 카메라 시스템은, 하나의 프로세서를 통해 차량 주변 모든 방향의 이미지 및 물체를 파악 할 수 있다. 이는, 카메라 시스템의 소프트웨어 설계를 더욱 간단하게 하고, 향후 자율주행 자동차에 사용됨에 유리하다."}
{"patent_id": "10-2018-0136010", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에 대하여 구체적으로 설명하기에 앞서, 본 명세서 및 도면의 기재 방법에 대하여 설명한다. 먼저, 본 명세서 및 청구범위에서 사용되는 용어는 본 개시의 다양한 실시 예들에서의 기능을 고려하여 일반적 인 용어들을 선택하였다 하지만, 이러한 용어들은 당해 기술 분야에 종사하는 기술자의 의도나 법률적 또는 기 술적 해석 및 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 일부 용어는 출원인이 임의로 선정한 용어 도 있다. 이러한 용어에 대해서는 본 명세서에서 정의된 의미로 해석될 수 있으며, 구체적인 용어 정의가 없으 면 본 명세서의 전반적인 내용 및 당해 기술 분야의 통상적인 기술 상식을 토대로 해석될 수도 있다. 또한, 본 명세서에 첨부된 각 도면에 기재된 동일한 참조번호 또는 부호는 실질적으로 동일한 기능을 수행하는 부품 또는 구성요소를 나타낸다. 설명 및 이해의 편의를 위해서 서로 다른 실시 예들에서도 동일한 참조번호 또 는 부호를 사용하여 설명한다. 즉, 복수의 도면에서 동일한 참조 번호를 가지는 구성요소를 모두 도시되어 있다 고 하더라도, 복수의 도면들이 하나의 실시 예를 의미하는 것은 아니다. 또한, 본 명세서 및 청구범위에서는 구성요소들 간의 구별을 위하여 \"제1\", \"제2\" 등과 같이 서수를 포함하는 용어가 사용될 수 있다. 이러한 서수는 동일 또는 유사한 구성요소들을 서로 구별하기 위하여 사용하는 것이며 이러한 서수 사용으로 인하여 용어의 의미가 한정 해석되어서는 안 된다. 일 예로, 이러한 서수와 결합된 구성 요소는 그 숫자에 의해 사용 순서나 배치 순서 등이 제한되어서는 안 된다. 필요에 따라서는, 각 서수들은 서로 교체되어 사용될 수도 있다. 본 명세서에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성 요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 실시 예에서 \"모듈\", \"유닛\", \"부(part)\" 등과 같은 용어는 적어도 하나의 기능이나 동작을 수행하는 구성요소를 지칭하기 위한 용어이며, 이러한 구성요소는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\", \"유닛\", \"부(part)\" 등은 각각이 개별적인 특정 한 하드웨어로 구현될 필요가 있는 경우를 제외하고는, 적어도 하나의 모듈이나 칩으로 일체화되어 적어도 하나 의 프로세서로 구현될 수 있다. 또한, 본 개시의 실시 예에서, 어떤 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적인 연결뿐 아니라, 다른 매체를 통한 간접적인 연결의 경우도 포함한다. 또한, 어떤 부분이 어떤 구성요소를 포함한다는 의미는, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것 을 의미한다. 도 2는 본 개시의 일 실시 예에 따른 카메라 시스템의 필수 구성요소를 설명하기 위한 블록도이다. 본 카 메라 시스템은 일반적으로 이동체(vehicle)에 구비된다. 도 2를 참조하면, 카메라 시스템은 카메라 및 프로세서를 포함한다. 카메라는 이동체(vehicle)에 구비되어 이동체 주변을 촬영함으로써 이동체 주변에 대한 이미지를 획득하기 위한 구성이다. 이때, 이동체는 자동차, 오토바이, 자전거, 기차, 배, 비행기, 우주선 등 다양한 운송수단을 의 미할 수 있다. 이동체가 자동차인 경우, 카메라는 자동차의 좌/우측 사이드 미러 중 어느 하나에 부착되어 자동차 주변을 촬영할 수 있다. 도 3은 카메라의 구성을 설명하기 위한 블록도이다. 도 3을 참조하면, 카메라는 광각 렌즈, 이 미지 센서를 포함할 수 있다. 광각 렌즈는 이동체의 주변 광을 수신하여 이미지 센서로 전달할 수 있다. 광각 렌즈는 어안 렌 즈 등의 초광각 렌즈로 구현될 수도 있다. 이미지 센서는 광각 렌즈를 통해 모인 주변 광을 인식하여 광각 렌즈의 시야각 내의 영역을 촬 영할 수 있다. 구체적으로, 인식된 주변 광을 전기적 신호로 전환할 수 있다. 이미지 센서는 광각 렌즈를 통해 모인 주변 광을 인식하기 위해 복수의 광 센서를 포함할 수 있다. 광 센서는 입력된 광을 전기 신호로 변환하기 위한 구성으로, 광 다이오드로 구현될 수 있다. 이미지 센서는 CCD(Charge Coupled Device), CMOS(Complementary Metal-Oxide-Semiconductor) 등으로 구 현될 수 있다. 카메라는 프로세서의 제어에 기초하여 이동체의 주변을 촬영할 수 있다. 그리고, 프로세서는 카 메라에 의해 촬영된 이미지에 기초하여 이동체 주변에 존재하는 객체를 식별할 수 있다. 광각 렌즈를 포함하는 카메라를 이용하는 경우, 비교적 넓은 범위의 영역을 촬영할 수 있다는 장점이 있는 반면 촬영된 이미지의 정밀도는 떨어진다는 단점이 있다. 따라서, 카메라의 광각 렌즈는, 광각 렌즈의 시야각(최대로 볼 수 있는 범위)이 일정한 각도로 구분된 복수의 각도 범위 중 기설정된 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수가, 다른 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수와 달라지도록 설계될 수 있다. 이때, 이미지 센서에 포함된 복수의 광 센서 간의 간격은 일정하지만, 광각 렌즈의 영역별 굴절률이 상술한 내용에 부합하도록 설계된 것일 수 있다. 구체적으로, 광각 렌즈는, 기설정된 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수가 다른 각 도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수보다 많아지도록 설계될 수 있다. 그 결과, 카메라에 의해 촬영된 이미지에 있어, 광각 렌즈의 기설정된 각도 범위에 대해 촬영된 영역 에 포함된 픽셀의 수는 다른 각도 범위에 대해 촬영된 영역에 포함된 픽셀의 수보다 많을 수 있다. 이렇듯, 시야각 내 복수의 각도 범위별로 대응되는 픽셀 수가 달라지도록 설계된 광각 렌즈를 이용한 결과, 본 카메라 시스템은, 일반 렌즈를 이용하는 경우에 비해 더 넓은 범위를 촬영할 수 있음은 물론, 촬 영된 이미지에 있어 상대적으로 더 중요한 영역에 대해서는 다른 영역에 비해 더 정밀한 객체 인식이 가능하다. 도 4 내지 도 5는 관심 영역에 기초하여 카메라 내 광각 렌즈를 설계한 경우의 실시 예를 설명하기 위한 도면이 다. 도 4 내지 도 5에 있어, 기설정된 각도 범위는, 광각 렌즈의 시야각 내 영역 중 기설정된 관심 영역을 포함하도록 기설정된 것이다. 도 4는 카메라가 이동체인 자동차의 좌측 사이드 미러에 부착되는 한편, 카메라 및 광각 렌즈 의 중심이 바라보는 방향이 자동차의 운전자 기준으로 좌측 전방이 되도록 카메라가 배치된 경우를 도시한다. 이때, 카메라는 시야각에 대응되는 방향 및 방향 내 영역에 대해 촬영할 수 있다. 다만, 도 4의 (a)를 참조하면, 광각 렌즈의 시야각 내 영역 중, 카메라가 바라보는 방향(광각 렌즈의 중심(각도: 0)이 바라보는 방향)에 근접한 영역이 주된 관심 영역이라는 점을 확인할 수 있다. 이 경우, 광각 렌즈의 시야각 내 영역 중 상술한 관심영역을 포함되는 기설정된 각도 범위에 대해서는, 다 른 각도 범위에 비해 단위 각도당 픽셀 수가 많도록 광각 렌즈가 설계될 수 있다. 도 4의 (b)는, 도 4의 (a)의 카메라에 의해 촬영된 이미지에 있어 광각 렌즈의 시야각을 동일한 각도 간격으로 구분한 복수의 각도 범위에 대응되는 영역을 표시한 것이다. 이때, 같은 동심원에 대응되는 영역 들은 같은 각도 범위에 포함되는 것이다. 도 4의 (b)를 참조하면, 카메라에 의해 촬영된 이미지에 있어, 관심 영역에 대응되는 기설정된 각도 범위(A ~ B)에 대해서는 다른 각도 범위에 비해 단위 각도당 픽셀 수가 많다는 점을 확인할 수 있다. 도 4의 (c)는 도 4의 (b)에 도시된 이미지와 관련하여 'FoV(Field of View)-Image Height'의 관계를 나타 낸 그래프이다. 종래 일반적인 렌즈의 경우, 'FoV(Field of View)-Image Height' 그래프는 각도 구간 또는 Image Height 구간이 다르더라도 그 기울기가 거의 일정한 1차 그래프의 형태를 가진다. 반면, 도 4의 (c)를 참조하면, 'A ~ B' 각도 구간이 \"B ~ C' 및 'C ~ D' 각도 구간에 비해 단위 각도별 픽셀 수 가 많은 결과, Image Height가 증가함에 따라 FoV가 증가하는 기울기가 'A ~ B' 각도 구간에서 확연히 더 작다 는 점을 확인할 수 있다.기설정된 각도 범위는 이동체에서 카메라가 배치되는 각도에 기초하여 기설정된 것일 수 있다. 예로, 도 5는 카메라가 도 4와 마찬가지로 자동차의 좌측 사이드 미러에 부착되기는 했으나, 카메라 가 좌측 전방 방향을 바라보는 도 4와 달리 자동차의 운전자 기준으로 전방 방향을 바라보 는 경우를 나타내는 경우이다. 이때, 실제 관심영역은 자동차의 운전자 기준으로 좌측 전방 영역으로서 도 4와 동일함에도, 기설정된 각도 범위는 도 4와 달라진다. 도 5의 (a)를 참조하면, 카메라는 시야각에 대응되는 방향 및 방향 사이의 영역에 대해 촬영할 수 있다. 도 5의 (a)를 참조하면, 광각 렌즈의 시야각 내 영역 중, 카메라가 바라보는 방향(광각 렌즈 의 중심(각도: 0)이 바라보는 방향)보다 좌측 영역이 주된 관심 영역이라는 점을 확인할 수 있다. 이 경우, 광각 렌즈의 시야각 내 영역 중 상술한 관심영역을 포함되는 기설정된 각도 범위에 대해서는, 다 른 각도 범위에 비해 단위 각도당 픽셀 수가 많도록 광각 렌즈가 설계될 수 있다. 도 5의 (b)는, 도 5의 (a)의 카메라에 의해 촬영된 이미지에 있어 광각 렌즈의 시야각을 동일한 각도 간격으로 구분한 복수의 각도 범위에 대응되는 영역을 표시한 것이다. 도 5의 (b)를 참조하면, 카메라에 의해 촬영된 이미지에 있어, 관심 영역을 포함하는 기설정된 각도 범위(B ~ C)에 대해서는 다른 각도 범위에 비해 단위 각도당 픽셀 수가 많다는 점을 확인할 수 있다. 도 5의 (c)는 도 5의 (b)에 도시된 이미지와 관련하여 'FoV(Field of View)-Image Height'의 관계를 나타 낸 그래프이다. 도 5의 (c)를 참조하면, 'B ~ C' 각도 구간이 \"A ~ B' 및 'C ~ D' 각도 구간에 비해 단위 각도별 픽셀 수가 많 은 결과, Image Height가 증가함에 따라 FoV가 증가하는 기울기가 'B ~ C' 각도 구간에서 확연히 더 작다는 점 을 확인할 수 있다. 한편, 기설정된 각도 범위는, 이동체의 구조 및 이동체에 탑승한 사용자의 시야에 기초하여 기설정될 수도 있다. 예로, 자동차 운전자는, 전방 유리 및 좌측 유리 사이 또는 전방 유리 및 우측 유리 사이에 배치된 차체 프레임 영역을 포함하는 자동차 구조에 따라 일부 시야가 방해받을 수 있다. 이 경우, 운전자 시야가 미치지 않는 사각 지대가 관심영역이 될 수 있고, 이에 기초하여 기설정된 각도 범위 역시 기설정될 수 있다. 프로세서는 카메라 시스템의 전반적인 동작을 제어할 수 있다. 앞서 상술하였듯, 프로세서는 카 메라에 의해 촬영된 이미지에 기초하여 이동체 주변의 객체를 식별할 수 있다. 이를 위해, 프로세서는 RAM(Random Access Memory)(도시되지 않음), ROM(Read Only Memory)(도시되지 않 음), CPU(central processing unit)(도시되지 않음), GPU(Graphic processing unit)(도시되지 않음) 및 시스템 버스(도시되지 않음) 등을 포함할 수 있으며, 카메라 시스템에 포함된 하나 이상의 구성요소들의 제어에 관한 연산이나 데이터 처리를 실행할 수 있다. 프로세서는 이동체에 구비된 ECU(Electronic Control Unit)로 구현되거나, 또는 ECU의 일부로 구현될 수 있다. 이 경우, 프로세서를 포함하는 ECU 는, 카메라에 의해 촬영된 이미지에 기초하여 이동체 주변 의 객체를 식별한 결과에 따라 이동체의 적어도 하나의 구성을 제어할 수 있다. 프로세서는, 이동체에 구비된 하나 이상의 ECU와 별도로 구현되어 ECU와 유선 또는 무선으로 통신을 수행 함으로써 ECU를 제어하거나 또는 ECU의 제어를 받을 수도 있다. 프로세서는 카메라를 통해 촬영된 이미지를 보정할 수 있다. 특히, 카메라가 어안렌즈 등 초광 각 렌즈를 이용하는 경우 렌즈의 특성상 이미지의 왜곡이 생기게 되므로 이미지의 보정이 필수적일 수 있다. 그리고, 프로세서는 보정된 이미지 또는 보정되지 않은 이미지에 존재하는 객체를 식별할 수 있다. 이때, 객체는, 사람, 자동차, 차선 및 기타 이동체의 주행에 방해되는 장애물 등일 수 있다. 이때, 프로세서는 이미지 내 객체 인식에 대한 기계 학습을 기초로, 이미지에 존재하는 객체를 식별할 수 도 있다. 이 경우, 프로세서는 이미지 내 객체 인식에 대하여 딥 러닝 기반으로 학습된 인공지능 모델을 이용하여 이미지 내 객체를 식별할 수 있다. 이때, 인공지능 모델은 카메라 시스템 내의 스토리지(도시되지 않음) 또는 카메라 시스템과 유선 또는 무선으로 통신 가능한 외부 스토리지에 저장되어 있을 수 있다. 프로세서는 식별된 객체에 대한 정보에 기초하여 객체의 위험도를 식별하고, 식별된 위험도에 기초하여 이 동체를 제어할 수 있다. 구체적으로, 식별된 객체 및 위험도에 대한 정보를 알리도록 이동체를 제어할 수 있다. 예로, 프로세서는 식별된 위험도에 대한 정보를 디스플레이하도록 이동체의 디스플레이를 제어하거나, 또 는 식별된 위험도에 대한 정보를 음성 형태로 출력하도록 이동체의 스피커를 제어할 수 있다. 본 카메라 시스템에 있어, 카메라가 한 대인 경우뿐만 아니라 여러 대인 경우도 상정할 수 있다. 바 람직하게는, 4대의 카메라를 이용하여 이동체의 전/후/좌/우 넓은 시야를 확보할 수 있다. 도 6은 본 개시의 일 실시 예에 따라 4대의 카메라를 포함하는 카메라 시스템의 구성요소를 설명하기 위한 블록도이다. 도 6을 참조하면, 카메라 시스템은 제1 카메라(110-1), 제2 카메라(110-2), 제3 카메라(110-3), 제4 카메 라(110-4) 및 프로세서를 포함할 수 있다. 이때, 제1 내지 제4 카메라 각각은, 앞서 도 3 내지 도 5를 통해 설명한 카메라와 동일하게 설계되어 이동 체의 주변에 대한 촬영을 수행할 수 있다. 이 경우, 제1 내지 제4 카메라(110-1, 110-2, 110-3, 110-4) 각각의 광각 렌즈를 설계함에 있어, 기설정 된 각도는 서로 다르게 구현될 수 있다. 각각의 카메라가 촬영하는 시야 범위 내 관심영역이 서로 다를 수 있기 때문이다. 제1 카메라(110-1)는 이동체의 좌측에 부착되는 한편 이동체의 전방 및 좌측을 촬영하고, 제2 카메라(110-2)는 이동체의 좌측에 부착되는 한편 이동체의 좌측 및 후방을 촬영하며, 제3 카메라(110-3)는 이동체의 우측에 부착 되어 이동체의 전방 및 우측을 촬영하고, 제4 카메라(110-4)는 이동체의 우측에 부착되어 이동체의 후방 및 우 측을 촬영할 수 있다. 이때, 제1 카메라(110-1) 및 제2 카메라(110-2)는 이동체의 좌측 사이드 미러에 부착되고, 제3 카메라(110-3) 및 제4 카메라(110-4)는 이동체의 우측 사이드 미러에 부착될 수 있다. 도 7은 이동체가 자동차인 경우, 자동차에 구비된 4대의 카메라를 포함하는 카메라 시스템의 객체 인식 범위(촬영 범위)를 설명하기 위한 도면이다. 도 7의 (a) 및 (b)를 참조하면, 자동차의 좌측 사이드 미러에 부착된 제1 카메라(110-1) 및 제2 카메라 (110-2)의 시야 범위를 각각 확인할 수 있다. 도 7의 (c)는 자동차의 좌측 사이드 미러에 부착된 제1 카메라(110-1) 및 제2 카메라(110-2)의 시야 범위를 합친 것을 나타낸 것이다. 도 7의 (c)를 참조하면, 각각 광각 렌즈를 포함하는 제1 카메라(110-1) 및 제2 카메라(110-2)의 시야범위 를 합친 결과, 좌전방/좌측/좌후방에 걸쳐 넓은 범위의 시야범위가 확보된다. 도 7의 (d)는 자동차의 우측 사이드 미러에 부착된 제3 카메라(110-3) 및 제4 카메라(110-4)의 시야범위를, 도 7의 (c)의 시야범위에 합친 것이다. 도 7의 (d)를 참조하면, 각각 광각 렌즈를 포함하며 좌/우측 사이드 미러에 부착된 제1 내지 제4 카메라 (110-1, 110-2, 110-3, 110-4)는, 이동체 주변의 전후좌우 넓은 영역을 모두 촬영할 수 있다는 점을 확인할 수 있다. 도 7의 (d)를 종래의 카메라 시스템들을 결합한 경우의 시야범위를 나타내는 도 1의 (e)와 비교했을 때, 기존의 사각지대가 더는 사각지대가 아니게 된다는 효과가 있다. 특히, 광각 렌즈를 이용함으로써 수평 방향뿐만 아니라 수직 방향으로도 넓은 시야각을 확보할 수 있기 때문에, 근접 영역뿐만 아니라 원거리 영역까지도 촬영 이미지를 확보할 수 있다. 이렇듯, 단 4대의 카메라(110-1, 110-2, 110-3, 110-4) 및 하나의 프로세서를 포함하는 하나의 카메라 시 스템만으로 이동체의 전후좌우는 물론 근거리 및 원거리를 모두 포함하는 넓은 영역을 촬영할 수 있으므로, 시스템 설계에 있어 배선 구조 및 배치 구조가 종래보다 간단해져 비용 절감 및 공간 확보의 효과가 있다. 이러한 특성으로 말미암아, 도 6의 카메라 시스템은 향후 자율주행자동차 등에 있어 유용하게 사용될 수 있다. 도 6의 프로세서는 도 2를 통해 도시 및 설명한 프로세서와 동일한 구조를 가지는 한편 동일한 동작 을 수행할 수 있다. 다만, 도 6의 프로세서는 4대의 카메라로부터 촬영된 이미지를 이용한다는 점에서 차 이가 있다. 구체적으로, 프로세서는 이동체의 주변을 촬영하도록 제1 내지 제4 카메라(110-1, 110-2, 110-3, 110-4)를 제어할 수 있다. 그리고, 제1 내지 제4 카메라(110-1, 110-2, 110-3, 110-4)를 통해 촬영된 이미지에 기초하여 이동체 주변의 객체를 식별할 수 있다. 이때, 제1 내지 제4 카메라(110-1, 110-2, 110-3, 110-4)에 포함된 복수의 이미지 센서(도시되지 않음)를 통해 촬영된 복수의 이미지에 대한 데이터는 Serializer IC(Intergrated Circuit. 도시되지 않음)를 통해 일 출력의 신호/데이터 형태로 프로세서로 전달될 수 있다. Serializer IC는 복수의 데이터/신호를 병렬로 입력받고 이를 병합한 직렬 데이터/신호를 출력하기 위한 구성이다. Serializer IC를 이용한 결과, 복수 개의 카메라 (110-1, 110-2, 110-3, 110-4)를 포함하는 하드웨어 모듈을 이용하더라도, 카메라별로 각각 별도의 시스템을 구 축할 필요 없이, 하나의 ECU로서 구현된 프로세서를 통해 하드웨어 모듈을 통합적으로 제어하는 하나의 시스템만을 가동할 수 있으므로, 통신 루트 및 설치 비용 측면에서 보다 경제적이다. 이렇듯, 프로세서는 제1 내지 제4 카메라(110-1, 110-2, 110-3, 110-4)에서 촬영된 이미지를 수신하고, 수신된 이미지에 포함된 객체를 식별하며, 식별된 객체에 대한 정보에 기초하여 객체의 위험도를 식별하고, 식 별된 위험도에 기초하여 이동체를 제어할 수 있다. 한편, 프로세서는 이동체의 속도 및 주행 방향 중 적어도 하나에 기초하여 제1 내지 제4 카메라(110-1, 110-2, 110-3, 110-4)에 의해 촬영된 이미지 각각 내에서 주요 영역을 식별하고, 식별된 주요 영역에 기초하여 이동체의 주변에 존재하는 객체를 식별할 수도 있다. 4대의 광각 카메라에 의해 촬영된 넓은 범위의 이미지에 대하여 객체 인식을 수행하는 과정은 다소 많은 양의 연산이 필요하게 되므로, 카메라들에 의해 촬영된 이미지 각각 내에서 주요 영역에 대해서만 객체를 인식함으로써 객체 인식을 위한 연산의 양을 줄이기 위함이다. 프로세서는 식별된 주요 영역에 대해서만 객체 인식을 수행할 수 있으며, 주요 영역은 이동체의 속도 및 주행 방향에 따라 달라질 수 있다. 예로, 이동체의 속도가 클수록 프로세서가 식별하는 주요 영역의 사이즈는 더 작아질 수 있다. 도 8은 이동체인 자동차가 비교적 고속으로 운행하는 경우, 주요 영역을 설명하기 위한 도면이다. 도 8의 (a)를 참조하면, 프로세서는, 제1 카메라(110-1)에 의해 촬영된 넓은 시야각의 이미지 중 자동차 의 정면 방향에 대응되는 좁은 범위에 대해 촬영된 이미지 영역만을 주요 영역으로 식별할 수 있다. 도 8의 (b)를 참조하면, 프로세서는, 제1 카메라(110-1) 및 제3 카메라(110-3)에 의해 촬영된 이미지 중 자동차의 정면 방향에 대응되는 좁은 범위들(810, 820)에 대해 촬영된 이미지 영역만을 주요 영역으로 식별 할 수 있다. 반면, 도 8과 달리 자동차가 비교적 저속으로 운행하는 경우라면, 각 카메라에 의해 촬영된 이미지 내에서 주요 영역의 사이즈는 도 8에 비해 더 커질 수 있다. 이때, 만약 주요 영역의 사이즈가 기설정된 값보다 크다면, 프로세서는 주요 영역 내 객체 식별을 위한 연산의 양을 기설정된 값 이하로 줄일 수 있다. 한편, 프로세서는, 자동차가 비교적 고속으로 주행하는 경우에 있어, 제2 카메라(110-2) 및 제4 카메 라(110-4)가 촬영한 이미지 중 이동체의 후측방 영역에 대응되는 이미지 영역에 대해서도 주요 영역으로 식별할 수 있다. 도 9를 참조하면, 이동체가 고속으로 주행하는 경우, 프로세서는 제1 카메라(110-1) 및 제3 카메라(110- 3)에 의해 촬영되는 영역 중 일부(910, 920)뿐만 아니라, 제2 카메라(110-3) 및 제4 카메라(110-4)에 의해 촬영 되는 영역 중 이동체의 후측방 영역들(930, 940)에 대응되는 이미지 영역에 대해서도 주요 영역으로 식별할 수 있다. 이는, 차선 변경 시 이동체의 후측방에 외부 차량 등이 다가오고 있는지 여부 등을 식별할 필요가 있기 때문이 다. 이때, 프로세서는 이동체인 자동차의 차선변경신호가 작동되었을 때에만 영역들(930, 940)에 대응되는 이미지 영역을 주요 영역으로 식별할 수도 있다. 이 경우, 프로세서는 좌측 차선변경신호가 작동되는 경우 영역에 대응되는 이미지 영역을 주요 영역으로 식별하고, 우측 차선변경신호가 작동되는 경우 영역에 대응되는 이미지 영역을 주요 영역으로 식별할 수도 있다. 한편, 이동체의 주행방향에 따라, 프로세서에 의해 식별되는 주요영역도 변경될 수 있다. 도 10은 이동체가 고속으로 좌회전 중인 경우, 제1 카메라(110-1) 및 제3 카메라(110-3)에 의해 촬영된 이미지 내 주요 영역을 설명하기 위한 도면이다. 도 10의 (a)를 참조하면, 도 8과 달리, 프로세서는 제1 카메라(110-1)에 의해 촬영된 이미지 중 자동차 의 정면보다 (운전자 시야 기준) 조금 좌측으로 치우친 영역에 대응되는 이미지 영역을 주요 영역으 로 식별할 수 있다. 도 10의 (b)를 참조하면, 프로세서는 제1 카메라(110-1) 및 제3 카메라(110-3) 각각에 의해 촬영된 이미지 들 내에서 자동차의 정면보다 조금 좌측으로 치우친 영역들(1010, 1020)에 대응되는 이미지 영역을 주요 영 역으로 식별할 수 있다. 한편, 이동체의 주행방향이 이동체의 정면을 기준으로 얼마나 다른지에 따라 주요 영역이 달라질 수 있다. 만약, 도 10의 경우보다 좌회전의 정도(자동차의 핸들이 꺾이는 정도)가 더 크다면 영역들(1010, 1020)은 도 10보다 좀 더 좌측에 위치하고, 그에 따라 주요 영역도 도 10의 경우와 다를 수 있다. 프로세서는, 제1 내지 제4 카메라(110-1, 110-2, 110-3, 110-4) 중 이동체의 주행방향에 대응되는 위치에 부착된 카메라에 의해 촬영된 이미지 내에서 식별된 주요 영역에 대해서는, 다른 카메라에 의해 촬영된 이미지 내에서 식별된 주요 영역보다 객체 식별을 위한 연산을 더 많이 수행하여, 이동체의 주변에 존재하는 객체를 식 별할 수도 있다. 도 11은 제1 내지 제4 카메라(110-1, 110-2, 110-3, 110-4)에 의해 촬영된 이미지들 각각에 기초하여 식별된 복 수의 주요 영역들 간에, 이동체의 주행 방향에 따라 객체 식별을 위한 연산의 양을 달리하는 실시 예를 설명하 기 위한 도면이다. 도 11의 (a)는 이동체인 자동차가 고속으로 좌회전하는 경우, 도 11의 (b)는 이동체인 자동차가 고속으 로 우회전하는 경우를 상정한다. 도 11의 (a)를 참조하면, 프로세서는 제1 내지 제4 카메라(110-1, 110-2, 110-3, 110-4) 각각의 넓은 촬 영 영역 중 자동차의 속도 및 주행방향(좌회전)에 대응되는 영역들(1105, 1110, 1115, 1120)에 대한 이미지 영역을 주요 영역으로 식별하여 객체를 인식할 수 있다. 다만, 이 경우, 프로세서는 자동차의 주행방향(좌회전)에 기초하여, 좌측에 부착된 제1 카메라(110-1) 및 제2 카메라(110-2)에 의해 촬영된 이미지에 포함되는 주요 영역에 대해서는, 제3 카메라(110-3) 및 제4 카메 라(110-4)에 의해 촬영된 이미지에 포함되는 주요 영역들에 비해 객체 인식을 위한 연산의 양을 더 크게 할 수 있다. 도 11의 (b)를 참조하면, 프로세서는 제1 내지 제4 카메라(110-1, 110-2, 110-3, 110-4) 각각의 넓은 촬 영 영역 중 자동차의 속도 및 주행방향(우회전)에 대응되는 영역들(1125, 1130, 1135, 1140)에 대한 이미지 영역을 주요 영역으로 식별하여 객체를 인식할 수 있다. 다만, 이 경우, 프로세서는 자동차의 주행방향(우회전)에 기초하여, 우측에 부착된 제3 카메라(110-3) 및 제4 카메라(110-4)에 의해 촬영된 이미지에 포함되는 주요 영역에 대해서는, 제1 카메라(110-1) 및 제2 카메 라(110-2)에 의해 촬영된 이미지에 포함되는 주요 영역들에 비해 객체 인식을 위한 연산의 양을 더 크게 할 수 있다. 도 11의 (c)는 자동차가 저속으로 좌회전하는 경우, 도 11의 (d)는 자동차가 저속으로 우회전하는 경우 를 상정한다. 도 11의 (c)를 참조하면, 도 11의 (a) 및 (b)의 경우보다 자동차의 속도가 느리므로, 프로세서는, 제1 카 메라(110-1) 및 제2 카메라(110-2)에 의해 촬영되는 영역 중 비교적 넓은 영역에 대응되는 이미지 영역과 제3 카메라(110-3) 및 제4 카메라(110-4)에 의해 촬영되는 영역 중 비교적 넓은 영역에 대응되는 이미지 영역을 주요 영역으로 식별할 수 있다.이때, 프로세서는 자동차의 주행방향(좌회전)에 기초하여, 좌측 영역에 대응되는 주요 영역에 대해서는 우측 영역에 대응되는 주요 영역보다 객체 인식을 위한 연산의 양을 더 크게 할 수 있다. 반면, 도 11의 (d)를 참조하면, 프로세서는 자동차의 주행방향이 우회전 방향이므로, 우측 영역(116 0)에 대응되는 주요 영역에 대해서는 좌측 영역에 대응되는 주요 영역보다 객체 인식을 위한 연산의 양을 더 크게 할 수 있다. 이하 도 12 내지 도 13과 관련하여서는, 본 개시의 다양한 실시 예에 따라 이동체(vehicle)에 포함된 카메라 시 스템의 제어 방법을 설명한다. 도 12는 본 개시의 일 실시 예에 따른 카메라 시스템의 제어 방법을 설명하기 위한 순서도이다. 도 12를 참조하면, 본 제어 방법은 이동체에 구비된 카메라를 이용하여 이동체의 주변을 촬영할 수 있다 (S1210). 그리고, 카메라에 의해 촬영된 이미지에 기초하여 이동체 주변에 존재하는 객체를 식별할 수 있다 (S1220). 이 경우, 이동체의 주변을 촬영하기 위한 카메라는, 광각 렌즈 및 광각 렌즈의 시야각 내의 영역을 촬영하기 위 한 복수의 광 센서를 포함할 수 있다. 이때, 광각 렌즈는, 시야각이 일정한 각도로 구분된 복수의 각도 범위 중 기설정된 각도 범위에 대응되는 영역 을 촬영하기 위한 광 센서의 수가 다른 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수와 달라지도록 설계될 수 있다. 구체적으로, 광각 렌즈는, 기설정된 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수가 다른 각도 범 위에 대응되는 영역을 촬영하기 위한 광 센서의 수보다 많아지도록 설계될 수 있다. 그 결과, 카메라에 의해 촬 영된 이미지에서, 기설정된 각도 범위에서 촬영된 영역에 포함된 픽셀의 수는 다른 각도 범위에서 촬영된 영역 에 포함된 픽셀의 수보다 많을 수 있다. 한편, 기설정된 각도 범위는, 이동체에서 카메라가 배치되는 각도에 기초하여 기설정될 수 있다. 또한, 기설정 된 각도 범위는, 이동체의 구조 및 이동체에 탑승한 사용자의 시야에 기초하여 기설정될 수 있다. 도 13은 본 개시의 일 실시 예에 따라, 이동체에 구비되는 4대의 카메라를 포함하는 카메라 시스템의 제어 방법 을 설명하기 위한 순서도이다. 본 제어 방법은, 이동체의 좌측에 부착되며 이동체의 전방 및 좌측을 촬영하기 위한 제1 카메라 및 이동체의 좌 측에 부착되며 이동체의 후방 및 좌측을 촬영하기 위한 제2 카메라를 이용하여 이동체의 주변을 촬영할 수 있다 (S1310). 또한, 이동체의 우측에 부착되며 이동체의 전방 및 우측을 촬영하기 위한 제3 카메라 및 이동체의 우 측에 부착되며 이동체의 후방 및 우측을 촬영하기 위한 제4 카메라를 이용하여 이동체의 주변을 촬영할 수 있다 (S1320). 그리고, 제1 내지 제4 카메라에 의해 촬영된 이미지에 기초하여 이동체 주변에 존재하는 객체를 식별할 수 있다 (S1330). 이 경우, 식별된 객체에 대한 정보에 기초하여 객체의 위험도를 식별하고, 식별된 위험도에 기초하여 이동체를 제어할 수도 있다. 이 경우, 제1 내지 제4 카메라 각각은, 광각 렌즈 및 광각 렌즈의 시야각 내의 영역을 촬영하기 위한 복수의 광 센서를 포함할 수 있다. 그리고, 광각 렌즈는, 시야각이 일정한 각도로 구분된 복수의 각도 범위 중 기설정된 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수가 다른 각도 범위에 대응되는 영역을 촬영하기 위한 광 센서의 수와 달라지도록 설계된 것일 수 있다. 이때, 본 제어 방법은, 이동체의 속도 및 주행 방향 중 적어도 하나에 기초하여, 제1 내지 제4 카메라에 의해 촬영된 이미지 각각 내에서 주요 영역을 식별하고, 식별된 주요 영역에 기초하여 이동체의 주변에 존재하는 객 체를 식별할 수도 있다. 구체적으로, 식별된 주요 영역에 대해서만 객체를 식별할 수도 있다. 이 경우, 이동체의 주변에 존재하는 객체를 식별함에 있어, 주요 영역의 사이즈가 기설정된 값보다 큰 경우, 주 요 영역 내 객체 식별을 위한 연산의 양을 기설정된 값 이하로 줄일 수도 있다. 그리고, 이동체의 주변에 존재하는 객체를 식별함에 있어, 제1 내지 제4 카메라 중 이동체의 주행방향에 대응되 는 위치에 부착된 카메라에 의해 촬영된 이미지 내에서 식별된 주요 영역에 대해서는, 다른 카메라에 의해 촬영 된 이미지 내에서 식별된 주요 영역보다 객체 식별을 위한 연산을 더 많이 수행할 수도 있다.도 12 내지 도 13을 통해 상술한 카메라 시스템의 제어 방법은, 도 2 내지 도 11을 통해 도시 및 설명한 카메라 시스템을 통해 구현될 수 있다. 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합된 것을 이용 하여 컴퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 본 개시에서 설명되는 실시 예들은 ASICs(Application Specific Integrated Circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(Programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processor), 제어기 (controller), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서(microprocessor), 기타 기능 수행을 위한 전기적인 유닛(unit) 중 적어도 하나를 이용하여 구현될 수 있다. 일부의 경우에 본 명세서에서 설명되는 실시 예들이 소프트웨어를 토대로 구현될 수 있다. 소프트웨어적인 구현 에 의하면 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들이 복수의 소프트웨어 모듈들을 통해 별도로 구현되는 한편, 상술한 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 구성의 기능 및 작동을 제어할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 카메라 시스템에서의 처리동작을 수행하기 위한 컴퓨터 명령어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable mediu m)에 저장될 수 있다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프로세서 에 의해 실행되었을 때 상술한 다양한 실시 예에 따른 카메라 시스템의 처리 동작을 상술한 특정 기기가 수행하도록 한다. 비일시적 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니 라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상 술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있다. 또한, 이상에서는 본 발명의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2018-0136010", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해돼서는 안 될 것이다."}
{"patent_id": "10-2018-0136010", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래 사용되던 자동차용 카메라 시스템들을 간략히 설명하기 위한 도면, 도 2는 본 개시의 일 실시 예에 따른 카메라 시스템의 필수 구성요소를 설명하기 위한 블록도, 도 3은 본 카메라 시스템에 포함된 적어도 하나의 카메라의 구성을 설명하기 위한 블록도, 도 4 내지 도 5는 관심 영역에 기초하여 카메라 내 광각 렌즈를 설계하는 실시 예를 설명하기 위한 도면, 도 6은 본 개시의 일 실시 예에 따라 4대의 카메라를 포함하는 카메라 시스템의 구성요소를 설명하기 위한 블록 도, 도 7은 4대의 카메라를 포함하는 카메라 시스템의 객체 인식 범위(촬영 범위)를 설명하기 위한 도면, 도 8 내지 도 10은 이동체의 속도 및 주행 방향에 기초하여, 촬영된 이미지 내에서 주요 영역을 식별하고, 식별 된 주요 영역을 이용하여 이동체 주변의 객체를 인식하는 실시 예를 설명하기 위한 도면, 도 11은 4대의 카메라에 의해 촬영된 이미지들로부터 각각 식별한 복수의 주요 영역들에 대하여, 이동체의 주행 방향에 따라 객체 식별을 위한 연산의 양을 달리하는 실시 예를 설명하기 위한 도면, 도 12는 본 개시의 일 실시 예에 따른 카메라 시스템의 제어 방법을 설명하기 위한 순서도, 그리고 도 13은 본 개시의 일 실시 예에 따라 4대의 카메라를 포함하는 카메라 시스템의 제어 방법을 설명하기 위한 순서도이다."}
