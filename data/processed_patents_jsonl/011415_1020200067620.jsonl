{"patent_id": "10-2020-0067620", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0150788", "출원번호": "10-2020-0067620", "발명의 명칭": "뉴스 긍정도 분석을 위한 인공신경망 학습 모델 및 장치", "출원인": "주식회사 웨이커", "발명자": "황규종"}}
{"patent_id": "10-2020-0067620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 뉴스 기사 분석 모델을 학습시키는 방법에 있어서,기 설정된 금융 단어 및 인물 단어를 저장하는 단계;상기 전자 장치가 연결되는 외부의 디바이스로부터, 뉴스 기사를 획득하는 단계;상기 뉴스 기사 내 상기 금융 단어 또는 상기 인물 단어를 포함하는 문장을 식별하는 단계;상기 식별된 문장 중 미리 설정된 수의 문장을 추출하는 단계; 및상기 추출된 문장을 전 처리함으로써, 상기 뉴스 기사 분석 모델을 학습시키기 위한 학습 데이터를 생성하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2020-0067620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 방법은상기 생성된 학습 데이터에 기초하여, 상기 뉴스 기사 분석 모델을 학습시키는 단계; 를 더 포함하는, 방법."}
{"patent_id": "10-2020-0067620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 방법은상기 뉴스 기사와 다른 뉴스 기사를 상기 외부의 디바이스로부터 획득하는 단계; 및상기 획득된 다른 뉴스 기사를 이용하여 상기 뉴스 기사 분석 모델을 검증하기 위한 검증 데이터를 생성하는 단계; 를 더 포함하는, 방법."}
{"patent_id": "10-2020-0067620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 뉴스 기사 분석 모델을 학습 시키는 단계는상기 학습 데이터에 기초하여 학습된 뉴스 기사 분석 모델로부터 출력된 출력 값과 상기 검증 데이터가 상기 뉴스 기사 분석 모델에 입력 시, 상기 뉴스 기사 분석 모델로부터 출력된 출력 값의 차이가 감소하도록, 상기 뉴스 기사 분석 모델을 학습시키는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2020-0067620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 금융 단어 및 상기 인물 단어를 저장하는 단계는상기 금융 단어 및 상기 금융 단어 별 단어 점수를 매칭함으로써 금융 단어 리스트를 생성하는 단계;상기 인물 단어 및 상기 인물 단어 별 인물 단어 가중치를 매칭함으로써 인물 가중치 리스트를 생성하는 단계;상기 생성된 금융 단어 리스트 및 상기 인물 가중치 리스트를 저장하는 단계; 및상기 금융 단어 리스트 및 상기 인물 가중치 리스트를 기 설정된 주기로 수정 및 갱신하는 단계; 를 포함하는,방법."}
{"patent_id": "10-2020-0067620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 방법은상기 뉴스 기사에 포함된 문장들 각각의 위치 정보를 식별하는 단계:상기 식별된 문장의 위치 정보에 기초하여, 상기 뉴스 기사 내 첫 문장 및 상기 뉴스 기사 내 마지막 문장을 식별하는 단계; 및공개특허 10-2021-0150788-3-상기 금융 단어 또는 상기 인물 단어를 포함하는 문장, 상기 첫 문장 및 상기 마지막 문장 중, 점수 산정 대상이 되는 미리 설정된 수의 문장을 추출하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2020-0067620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 학습 데이터를 생성하는 단계는상기 추출된 문장을 전 처리하는 단계; 및상기 전 처리된 문장을 이용하여 상기 학습 데이터를 생성하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2020-0067620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 전 처리하는 단계는상기 추출된 문장을 토큰화(tokenizing)함으로써, 문장 내 각 단어를 식별하는 단계;상기 식별된 각 단어들 중, 문장 점수 산정에 사용되지 않는 단어들을 제거하는 단계; 및상기 문장 점수 산정에 사용되지 않는 단어들을 제거하고 남은 각 문장 내 단어들을 표제어 형태로 변환하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2020-0067620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 전 처리된 문장을 이용하여 상기 학습 데이터를 생성하는 단계는상기 전 처리된 문장 내 부정어구, 부사, 문장 부호, 강조어구, 부정어 또는 상기 인물 단어 중 적어도 하나에기초하여, 상기 전 처리된 문장 각각에 대한 문장 가중치를 결정하는 단계; 및상기 결정된 문장 가중치를, 상기 전 처리된 문장 각각에 부여함으로써, 상기 학습 데이터를 생성하는 단계; 를포함하는, 방법."}
{"patent_id": "10-2020-0067620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 뉴스 기사 분석 모델은레이어들 및 상기 레이어들 간의 연결 강도에 관한 가중치를 포함하는 신경망 모델을 포함하는 것을 특징으로하는, 방법."}
{"patent_id": "10-2020-0067620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "뉴스 기사 분석 모델을 학습시키는 전자 장치에 있어서,하나 이상의 인스트럭션을 저장하는 메모리; 및상기 하나 이상의 인스트럭션들을 실행하는 적어도 하나의 프로세서; 를 포함하고,상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,기 설정된 금융 단어 및 인물 단어를 저장하고,상기 전자 장치가 연결되는 외부의 디바이스로부터, 뉴스 기사를 획득하고,상기 뉴스 기사 내 상기 금융 단어 또는 상기 인물 단어를 포함하는 문장을 식별하고,상기 식별된 문장 중 미리 설정된 수의 문장을 추출하고,상기 추출된 문장을 전 처리함으로써, 상기 뉴스 기사 분석 모델을 학습시키기 위한 학습 데이터를 생성하는,전자 장치."}
{"patent_id": "10-2020-0067620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 적어도 하나의 프로세서는상기 생성된 학습 데이터에 기초하여, 상기 뉴스 기사 분석 모델을 학습시키는, 전자 장치.공개특허 10-2021-0150788-4-청구항 13 제12항에 있어서, 상기 적어도 하나의 프로세서는상기 뉴스 기사와 다른 뉴스 기사를 상기 외부의 디바이스로부터 획득하고,상기 획득된 다른 뉴스 기사를 이용하여 상기 뉴스 기사 분석 모델을 검증하기 위한 검증 데이터를 생성하는,전자 장치."}
{"patent_id": "10-2020-0067620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 적어도 하나의 프로세서는상기 학습 데이터에 기초하여 학습된 뉴스 기사 분석 모델로부터 출력된 출력 값과 상기 검증 데이터가 상기 뉴스 기사 분석 모델에 입력 시, 상기 뉴스 기사 분석 모델로부터 출력된 출력 값의 차이가 감소하도록, 상기 뉴스 기사 분석 모델을 학습시키는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2020-0067620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "전자 장치가 뉴스 기사 분석 모델을 학습시키는 방법에 있어서,기 설정된 금융 단어 및 인물 단어를 저장하는 단계;상기 전자 장치가 연결되는 외부의 디바이스로부터, 뉴스 기사를 획득하는 단계;상기 뉴스 기사 내 상기 금융 단어 또는 상기 인물 단어를 포함하는 문장을 식별하는 단계;상기 식별된 문장 중 미리 설정된 수의 문장을 추출하는 단계; 및상기 추출된 문장을 전 처리함으로써, 상기 뉴스 기사 분석 모델을 학습시키기 위한 학습 데이터를 생성하는 단계; 를 포함하는, 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체."}
{"patent_id": "10-2020-0067620", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 뉴스 기사 분석 모델을 학습 시키는 방법 및 장치에 관한 것이다. 일 실시 예에 의하면, 뉴스 기사 분 석 모델을 학습시키는 방법은 기 설정된 금융 단어 및 인물 단어를 저장하는 단계; 상기 전자 장치가 연결되는 외부의 디바이스로부터, 뉴스 기사를 획득하는 단계; 상기 뉴스 기사 내 상기 금융 단어 또는 상기 인물 단어를 포함하는 문장을 식별하는 단계; 상기 식별된 문장 중 미리 설정된 수의 문장을 추출하는 단계; 및 상기 추출된 문장을 전 처리함으로써, 상기 뉴스 기사 분석 모델을 학습시키기 위한 학습 데이터를 생성하는 단계; 를 포함할 수 있다."}
{"patent_id": "10-2020-0067620", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 뉴스 기사를 분석하기 위한 뉴스 기사 분석 모델을 학습 시키는 방법 및 장치에 관한 것이다. 보다 상세하게는 금융 분야의 뉴스 기사를 분석하기 위한 뉴스 기사 분석 모델을 학습시키는 방법 및 장치에 관한 것 이다."}
{"patent_id": "10-2020-0067620", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인터넷 기술이 발달함에 따라 신문, 방송, 잡지와 같은 언론 매체들은 오프라인 상의 인쇄 매체가 아닌, 인터넷 을 통하여 뉴스 기사들을 전달하고 있다. 또한, 인터넷을 통하여 국내의 정치, 경제, 사회 문화 전반을 비롯한 뉴스들뿐만 아니라, 세계 각국의 정치, 경제, 금융 분야의 뉴스들이 기사화되고 있다. 특히, 갈수록 성장하는 세계 경제의 발달과 함께 금융 분야의 뉴스 기사들에 대한 정보 역시 인터넷 상에 넘쳐 나고 있다. 이러한 금융 분야의 뉴스 기사들은, 해당 금융 이슈들에 대한 긍정적인 측면과 부정적인 측면을 모 두 다룬다. 인터넷이 발달함에 따라 생산되는 대량의 뉴스 기사들을 처리하기 위한, 데이터 처리 기술들이 개발되고 있으나, 일반적인 뉴스 데이터 처리 기술들은 대량의 뉴스 기사들을 객관적으로 평가하고, 분석하는데 여전히 많은 한계를 가지고 있다. 따라서, 대량의 인터넷 뉴스 기사들을 정확하고 객관적으로 평가하기 위한 방법 및 장치 기술에 대한 개발이 요 구되고 있다. 선행기술문헌 특허문헌(특허문헌 0001) 한국공개특허 제10-2009-0047646호"}
{"patent_id": "10-2020-0067620", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일 실시 예에 따르면, 뉴스 기사를 분석하기 위한 뉴스 기사 분석 모델을 학습시키는 방법 및 장치가 제공될 수 있다. 일 실시 예에 의하면 금융 분야의 뉴스 기사를 분석하기 위한 뉴스 기사 분석 모델을 학습시키는 방법 및 장치 가 제공될 수 있다."}
{"patent_id": "10-2020-0067620", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 본 개시의 일 실시 예에 따라, 기 설정된 금융 단어 및 인물 단어를 저장 하는 단계; 상기 전자 장치가 연결되는 외부의 디바이스로부터, 뉴스 기사를 획득하는 단계; 상기 뉴스 기사 내 상기 금융 단어 또는 상기 인물 단어를 포함하는 문장을 식별하는 단계; 상기 식별된 문장 중 미리 설정된 수의 문장을 추출하는 단계; 및 상기 추출된 문장을 전 처리함으로써, 상기 뉴스 기사 분석 모델을 학습시키기 위한 학습 데이터를 생성하는 단계; 를 포함하는, 뉴스 기사 분석 모델을 학습시키는 방법이 제공될 수 있다. 일 실시 예에 의하면, 상기 뉴스 기사 분석 모델을 학습시키는 방법은 생성된 학습 데이터에 기초하여, 뉴스 기 사 분석 모델을 학습 시키는 단계; 를 더 포함할 수 있다. 또한, 상기 기술적 과제를 해결하기 위한 본 개시의 또 다른 실시 예에 따라, 하나 이상의 인스트럭션을 저장하 는 메모리; 및 상기 하나 이상의 인스트럭션들을 실행하는 적어도 하나의 프로세서; 를 포함하고, 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 기 설정된 금융 단어 및 인물 단어를 저장하 고, 상기 전자 장치가 연결되는 외부의 디바이스로부터, 뉴스 기사를 획득하고, 상기 뉴스 기사 내 상기 금융 단어 또는 상기 인물 단어를 포함하는 문장을 식별하고, 상기 식별된 문장 중 미리 설정된 수의 문장을 추출하 고, 상기 추출된 문장을 전 처리함으로써, 상기 뉴스 기사 분석 모델을 학습시키기 위한 학습 데이터를 생성하 는, 전자 장치가 제공될 수 있다. 일 실시 예에 의하면, 상기 전자 장치는 생성된 학습 데이터에 기초하여 뉴스 기사 분석 모델을 학습시킬 수 있 다. 또한, 상기 기술적 과제를 해결하기 위한 본 개시의 또 다른 실시 예에 따라, 기 설정된 금융 단어 및 인물 단 어를 저장하는 단계; 상기 전자 장치가 연결되는 외부의 디바이스로부터, 뉴스 기사를 획득하는 단계; 상기 뉴 스 기사 내 상기 금융 단어 또는 상기 인물 단어를 포함하는 문장을 식별하는 단계; 상기 식별된 문장 중 미리 설정된 수의 문장을 추출하는 단계; 및 상기 추출된 문장을 전 처리함으로써, 상기 뉴스 기사 분석 모델을 학습 시키기 위한 학습 데이터를 생성하는 단계; 를 포함하는, 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록 한 컴퓨터로 읽을 수 있는 기록 매체가 제공될 수 있다."}
{"patent_id": "10-2020-0067620", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시 예에 의하면, 뉴스 기사 분석 모델을 학습하기 위한 학습 데이터를 효과적으로 생성할 수 있다. 일 실시 예에 의하면, 뉴스 기사를 정확하게 분석할 수 있는 뉴스 기사 분석 모델을 학습 시킬 수 있다."}
{"patent_id": "10-2020-0067620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 또한, 본 명세서에서, 어떤 막(또는 층)이 다른 막(또는 층) 또는 기판 상에 있다고 언급되는 경우에 그것은 다 른 막(또는 층) 또는 기판 상에 직접 형성될 수 있거나 또는 그들 사이에 제 3의 막(또는 층)이 개재될 수도 있 다 또한, 도면들에 있어서, 구성들의 크기 및 두께 등은 명확성을 위하여 과장된 것이다. 본 명세서의 다양한 실시예들에서 제1, 제2, 제3 등의 용어가 다양한 영역, 막들(또는 층들) 등을 기술하기 위해서 사용되었지만, 이들 영역, 막들이 이 같은 용어들에 의해서 한정되어서는 안 된다. 이들 용어들은 단지 어느 소정 영역 또는 막(또는 층)을 다른 영역 또는 막(또는 층)과 구별시키기 위해서 사용되었을 뿐이다. 따라서, 어느 한 실시예에 의 제1막질로 언급된 막질이 다른 실시예에서는 제2막질로 언급될 수도 있다. 여기에 설명되고 예시되는 각 실 시예는 그것의 상보적인 실시예도 포함한다. 본 명세서에서 '및/또는' 이란 표현은 전후에 나열된 구성요소들 중 적어도 하나를 포함하는 의미로 사용된다. 명세서 전체에 걸쳐서 동일한 참조번호로 표시된 부분들은 동일한 구성요소들을 나타낸다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 일 실시 예에 따른 뉴스 기사 분석 모델을 학습 시키는 과정을 개략적으로 설명하기 위한 도면이다. S102에서, 일 실시 예에 의하면, 전자 장치는 전자 장치와 연결된 외부 디바이스로부터 뉴스 기사를 획득하고, 획득된 뉴스 기사로부터 학습 데이터를 생성할 수 있다. 예를 들어, 전자 장치는 외부 디바이 스로부터 뉴스 기사에 관한 텍스트 데이터, 이미지 데이터 또는 영상 데이터들을 획득하고, 획득된 뉴스 기사에 대한 데이터를 이용하여, 학습 데이터를 생성할 수 있다. 또 다른 실시 예에 의하면, 전자 장치 는 외부 디바이스로부터 획득된 뉴스 기사를 이용하여 학습 데이터(training data, 106) 및 검증 데 이터(test data, 108)를 생성할 수도 있다. 또한, 일 실시 예에 의하면, 전자 장치는 뉴스 기사를 획득하고, 획득된 뉴스 기사에 대한 텍스트 데이터 를 이용하여 미리 설정된 비율로 학습 데이터 및 검증 데이터를 생성할 수 있다. 일 실시 예에 의하면, 전자 장치는 학습 데이터 및 검증 데이터의 생성 비율을 나타내는 제1 학습 검증 비 또는 제2 학습 검증비를 결정하고, 결정된 학습 검증비에 따라 학습 데이터 및 검증 데이터를 생성할 수도 있다. S104에서, 전자 장치는 생성된 학습 데이터에 기초하여, 뉴스 기사 분석 모델을 학습시킬 수 있다. 일 실시 예에 의하면, 전자 장치는 학습 데이터 및 검증 데이터에 기초하여 뉴스 기사 분석 모델을 학습 시킬 수도 있다. 본 개시에 따른 뉴스 기사 분석 모델은 인공 지능 학습 알고리즘에 따라 학습될 수 있는 인공 지능 모델, 또는 신경망 모델을 포함할 수 있다. 일 실시 예에 의하면, 신경망 모델은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 역시 이에 한정되는 것은 아니다. 일 실시 예 에 의하면, 전자 장치는 학습 데이터 및 검증 데이터에 기초하여 신경망 모델을 학습 시킨 후, 학습 된 신경망 모델을 이용하여 뉴스 기사에 대한 점수를 자동으로 결정할 수 있다. 일 실시 예에 의하면, 전자 장치는 적어도 하나의 뉴스 기사 분석 모델을 학습 시키고, 학습된 뉴스 기사 분석 모델을 이용하여 뉴스 기사에 관한 데이터를 처리하기 위한, AI 프로그램이 탑재되고 음성 인식 기능을 포 함하는 스마트폰, 태블릿 PC, 스마트 TV, 휴대폰, 미디어 플레이어, 서버, 마이크로 서버, 기타 모바일 또는 비 모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 또한, 일 실시 예에 의하면, 전자 장치는 서버와 연동함으로써, 뉴스 기사 분석 모델을 학습 시키 고, 학습된 뉴스 기사 분석 모델을 이용하여 뉴스 기사에 대한 종합 평가 점수를 결정할 수도 있다. 일 실 시 예에 의하면, 전자 장치는 서버와 통신할 수 있는 네트워크 인터페이스를 포함할 수 있다. 예를 들어, 서버는 네트워크 인터페이스를 통하여 전자 장치와 연결됨으로써, 전자 장치와 데이터를 송 수신할 수 있는 기타 컴퓨팅 장치를 포함할 수 있다. 또한, 일 실시 예에 의하면, 서버 장치는 웨어러블 디바이스를 관리하기 위한 W-BMS(Wearable Business Management Server)일 수 있다. 일 실시 예에 의하면, 서버는 근거리 통신망(Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 부가가치 통신망(Value Added Network; VAN), 이동 통신망(mobile radio communication network), 위성 통신망 및 이들의 상호 조합을 포함하고, 도 1에 도시된 각 네트워크 구성 주체가 서로 원활하 게 통신을 할 수 있도록 하는 포괄적인 의미의 데이터 통신망이며, 유선 인터넷, 무선 인터넷 및 모바일 무선 통신망을 포함할 수 있다. 도 2는 일 실시 예에 따른 뉴스 기사 분석 모델을 학습시키는 방법의 흐름도이다. S210에서, 전자 장치는 기 설정된 금융 단어 및 인물 단어를 저장할 수 있다. 일 실시 예에 의하면, 전자 장치는 금융 단어 및 금융 단어 별 단어 점수를 매칭함으로써 금융 단어 리스트를 생성하고, 생성된 금융 단어 리스트를 저장할 수 있다. 또한, 전자 장치는 인물 단어 및 인물 단어 별 인물 단어 가중치를 매칭 함으로써 인물 가중치 리스트를 생성하고, 생성된 인물 가중치 리스트를 저장할 수 있다. 일 실시 예에 의하면, 인물 단어는, 금융(financing)분야와 관련되는 것으로 미리 결정될 수 있다. 일 실시 예에 의하면, 인물 단어는 미리 설정된 기간 동안, 공개된 금융 분야 기사 내 해당 인물 단어의 게재 횟수가 소정의 임계치 이상인지 여부 에 기초하여 결정될 수 있다. S220에서, 전자 장치는 전자 장치가 연결되는 외부의 디바이스로부터 뉴스 기사를 획득할 수 있다. 예를 들어, 전자 장치는 인터넷을 통하여 전자 장치와 연결되는 외부의 디바이스 또는 서버로부터 뉴스 기사에 대한 데이터들을 획득할 수 있다. S230에서, 전자 장치는 뉴스 기사 내 금융 단어 또는 인물 단어를 포함하는 문장을 식별할 수 있다. 예를 들어, 전자 장치는 미리 저장된 금융 단어 리스트 내 금융 단어 또는 인물 가중치 리스트 내 인물 단어 중 적어도 하나를 포함하는 복수의 문장을 식별할 수 있다. S240에서, 전자 장치는 식별된 복수의 문장 중 미리 설정된 수의 문장을 추출할 수 있다. 예를 들어, 전 자 장치는 식별된 문장들의 위치 정보에 기초하여, 식별된 문장 중 소정의 문장을 추출할 수 있다. 후술 하는 도 4를 참조하여 전자 장치가 기 저장된 금융 단어 또는 인물 단어 중 적어도 하나를 포함하는 문장 을 식별하고, 식별된 문장 중 일부의 문장을 추출하는 구체적인 방법을 설명하기로 한다. S250에서, 전자 장치는 S240단계에서 추출된 일부의 문장을 전 처리함으로써, 뉴스 기사 분석 모델을 학 습 시키기 위한 학습 데이터를 생성할 수 있다. 예를 들어, 전자 장치는 추출된 일부의 문장을 이용하여 학습 데이터 및 검증 데이터를 생성할 수도 있다. 전자 장치가 추출된 일부 문장을 전 처리함으로써 학습 데이터를 생성하는 동작은 도 5 및 도 7을 참조하여 구체적으로 설명하기로 한다. 도 3은 일 실시 예에 따라 전자 장치에 미리 저장되는 금융 단어 리스트 및 인물 가중치 리스트를 설명하기 위 한 도면이다. 일 실시 예에 의하면, 전자 장치는 금융 단어 및 금융 단어 별 단어 점수를 매칭함으로써 금융 단어 리스 트를 생성할 수 있다. 일 실시 예에 의하면, 전자 장치는 미리 설정된 금융 단어들에 대한 전문가들 의 전문가 평가 점수를 획득할 수 있다. 일 실시 예에 의하면, 전자 장치는 복수의 전문가들로부터, 특정 금융 단어에 대한 전문가 평가 점수를 획득하고, 획득된 전문가 평가 점수에 기초하여 단어 점수 벡터를 생성할 수 있다. 일 실시 예에 의하면, 단어 점수 벡터는 각 전문가의 평가 점수를 벡터 원소로 포함할 수 있다. 전자 장치는 단어 점수 벡터 내 원소들의 평균 및 표준 편차를 식별할 수 있다. 일 실시 예에 의하면, 전자 장 치는 금융 단어들을 표제어 형태로 변환하고, 표제어 형태로 변환된 금융 단어와 상기 금융 단어 별 단어 점수를 매칭함으로써 금융 단어 리스트를 생성할 수도 있다. 예를 들어, 전자 장치는 5명의 금융 전문가들로부터 'competent'에 대한 사용자 평가 점수로써, 각각 2점, 2점, 3점, 2점, 1점을 획득하고, 금융 전문가들로부터 획득된 각 전문가 평가 점수를 벡터 원소로 하는 단 어 벡터 점수 {2,2,3,2,1}을 생성할 수 있다. 전자 장치는 상기 생성된 단어 벡터 점수의 벡터 원소의 평 균 및 표준 편차를 각각 2 및 0.632456으로 식별할 수 있다. 일 실시 예에 의하면, 전자 장치가 획득하는 전문가 평가 점수는 -5 내지 5사이의 값을 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시 예에 의하면, 전자 장치가 획득한 전문가 평가 점수는 해당 단어에 대한 각 전문가들의 긍정적 또는 부정적 정도를 나타내는 지표 값일 수 있다. 일 실시 예에 의하면, 전자 장치가 획득한 전문가 평가 점수는 다음과 같은 긍정적 또는 부정적 정도를 나타낼 수 있다. 예를 들어, -5 내지 5사이의 전문가 평가 점수 는 다음과 같이, 금융 단어에 대한 긍정적 또는 부정적 정도를 나타낼 수 있다 (예컨대, -5: 극도로 안좋은, -4: 매우 안좋은, -3: 안 좋은, -2: 조금 안좋은, -1: 애매하게 안좋은, 0:보통, 1: 애매하게 좋은, 2: 조금 좋 은, 3: 좋은, 4: 매우 좋은, 5: 극도로 좋은). 하지만, 이에 한정되는 것은 아니며, 금융 단어에 대한 전문가들 의 평가 점수의 범위는 달라질 수 있다. 일 실시 예에 의하면, 전자 장치는 복수의 금융 전문가들로부터 소정의 인물 단어에 대한 평가 점수를 획 득할 수 있다. 전자 장치는 복수의 금융 전문가들로부터 획득된, 상기 인물 단어에 대한 평가 점수에 기 초하여 인물 단어 가중치를 생성할 수 있다. 일 실시 예에 의하면, 인물 단어 별 가중치는 벡터형태로 표현될 수 있다. 전자 장치는 인물 단어 및 상기 인물 단어 별 인물 단어 가중치를 매칭함으로써 인물 가중치 리 스트를 생성할 수 있다. 예를 들어, 전자 장치는 5명의 금융 전문가들로부터 버크셔 해서웨이의 회장인, 'Warren Edward Buffet' 에 대한 평가 점수를 각각 획득하고, 획득된 평가 점수에 기초하여 인물 가중치를 생성할 수 있다. 일 실시 예 에 의하면, 전자 장치가 획득하는 인물 단어에 대한 전문가 평가 점수는 -5 내지 5 사이의 값을 포함할 수 있다. 그러나, 이에 한정되는 것은 아니며, 전자 장치가 획득하는 인물 단어에 대한 전문가 평가 점수 의 범위는 달라질 수 있다. 전자 장치는 상술한 금융 단어 리스트 및 인물 가중치 리스트를 전 자 장치 내 메모리에 미리 저장할 수 있다. 또한, 일 실시 예에 의하면, 전자 장치는 미리 설정된 주기에 따라 금융 단어 리스트 및 인물 가중치 리 스트를 수정 및 갱신할 수 있다. 예를 들어, 전자 장치는 미리 설정된 주기에 따라 금융 단어들에 대한 전문가들의 전문가 평가 점수를 다시 획득하고, 획득된 전문가 평가 점수에 기초하여 단어 점수 벡터를 수정 및 갱신할 수 있다. 또한, 전자 장치는 미리 설정된 주기에 따라 인물 단어에 대한 평가 점수를 다시 획득하 고, 획득된 평가 점수에 기초하여 인물 단어 가중치를 수정 및 갱신할 수 있다. 도 4는 일 실시 예에 따라 전자 장치가, 뉴스 기사 내에서 식별된 문장 중 미리 설정된 수의 문장을 추출하는 과정을 설명하기 위한 도면이다. S420에서, 전자 장치는 뉴스 기사에 포함된 문장들 각각의 위치 정보를 식별할 수 있다. 예를 들어, 전자 장치는 미리 설정된 금융 단어 또는 인물 단어 중 적어도 하나를 포함하는 문장을 뉴스 기사 내에서 식별 할 수 있을 뿐만 아니라, 식별된 문장이 뉴스 기사 내에서 어디에 위치하는지에 관한 위치 정보를 더 식별할 수 있다. 일 실시 예에 의하면, 전자 장치는 획득된 뉴스 기사 내 소정의 금융 단어 또는 인물 단어 중 적어도 하나를 포함하는 문장이 뉴스 기사 내에서 몇 번째 문장인지 여부를 식별함으로써, 위치 정보를 결정할 수 있다. S440에서, 전자 장치는 식별된 문장의 위치 정보에 기초하여, 뉴스 기사 내 첫 문장 및 뉴스 기사 내 마 지막 문장을 식별할 수 있다. 예를 들어, 전자 장치는 위치 정보를 이용하여, 뉴스 기사로부터 식별 가능 한 문장들이, 뉴스 기사 내에서 몇 번째에 위치하는 문장들인지 여부를 식별할 수 있다. 따라서, 전자 장치 는 뉴스 기사 의 첫 문장 및 마지막 문장을 식별할 수 있다. S460에서, 전자 장치는 금융 단어 또는 상기 인물 단어를 포함하는 문장, 상기 뉴스 기사 내의 첫 문장 및 상기 뉴스 기사 내의 마지막 문장 중, 점수 산정 대상이 되는 미리 설정된 수의 문장을 추출할 수 있다. 일 실시 예에 의하면, 전자 장치는 뉴스 기사로부터 추출할 문장의 수를 미리 설정해둘 수 있다. 일 실시 예 에 의하면, 전자 장치는 뉴스 기사 내 식별된 문장 중, 뉴스 기사 내 첫 문장 및 마지막 문장을 포함하는 추출될 문장의 수가 5가 되도록, 식별된 문장 중 일부의 문장을 추출할 수도 있다. 그러나 이에 한정되는 것은 아니며, 전자 장치가 뉴스 기사로부터 추출할 문장의 수는 달라질 수 있다. 도 4에는 도시되지 않았지만, 전자 장치는 추출된 미리 설정된 수의 문장을 이용하여 학습 데이터를 생성 할 수 있다. 예를 들어, 전자 장치는 추출된 미리 설정된 수의 문장을 인코딩함으로써, 전체 뉴스 기사에"}
{"patent_id": "10-2020-0067620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "대한 요약 데이터를 생성하고, 생성된 요약 데이터를 학습 데이터로써 생성할 수도 있다. 또 다른 실시 예에 의"}
{"patent_id": "10-2020-0067620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "하면, 전자 장치는 미리 설정된 수의 문장 자체를 요약 데이터로 생성하고, 생성된 요약 데이터를 학습 데이터로 활용할 수도 있다. 도 5는 일 실시 예에 따라, 전자 장치가 미리 설정된 수의 문장을 전처리 하는 과정을 나타내는 흐름도이다. 일 실시 예에 의하면, 전자 장치는 뉴스 기사 내 식별된 문장 중 일부의 문장을 추출하고, 추출된 일부의 문장을 전 처리함으로써 학습 데이터를 생성할 수 있다. 이하 에서는, 전자 장치가 추출된 일부의 문장을 전 처리 하는 동작을 도 5를 참조하여 구체적으로 설명하기로 한다. S520에서, 전자 장치는 도 4에 기재된 방법에 따라, 추출된 일부의 문장을 토큰화(Tokenizing)함으로써, 문장 내 각 단어들을 식별할 수 있다. 도 5에는 도시되지 않았지만, 전자 장치는 추출된 일부 문장을 토 큰화한 후, 토큰화된 일부 문장 내 단어들을 토큰화 하는 과정을 더 수행함으로써, 추출된 문장 내 단어들을 식 별할 수도 있다. 일 실시 예에 의하면, 전자 장치는 문법적으로 더 이상 나눌 수 없는 단위로, 추출된 문 장들을 분해함으로써, 문장을 토큰화 할 수 있다. 또한, 전자 장치는 문장 내 문장 부호, 띄어쓰기 중 적 어도 하나에 기초하여, 추출된 문장들을 토큰화하고, 토큰화된 문장으로부터 단어를 식별할 수 있다. S540에서, 전자 장치는 추출된 일부 문장들로부터 식별된 단어들 중, 문장 점수 산정에 사용되지 않는 단 어들을 제거할 수 있다. 예를 들어, 전자 장치는 문장을 토큰화함으로써 식별되는 단어들 중, 문장의 점 수 산정에 필요 없는 단어 리스트를 생성해둘 수 있고, 생성된 단어 리스트에 포함된 단어들이 식별되는 경우, 해당 단어들을 제거할 수 있다. S560에서, 전자 장치는 문장 점수 산정에 사용되지 않는 단어들을 제거하고 남은 각 문장 내 단어들을 표 제어 형태로 변환할 수 있다. 예를 들어, 전자 장치는 문장 점수 산정에 사용되지 않는 단어들을 제거하 고 남은 단어들이 사전에 기재된 표제어 형태가 아닌 경우(예컨대 looks) 사전에 기재된 표제어 형태(예컨대 look)로 남은 단어들을 변환할 수 있다. 전자 장치는 표제어 형태로 변환된 단어들을 포함하는 일부 문장 들을 이용하여 학습 데이터를 생성할 수 있다. 즉, 본 개시에 따른 전자 장치는 뉴스 기사로부터 금융 단 어 또는 인물 단어 중 적어도 하나를 포함하는 문장을 식별하고, 식별된 문장 중 미리 설정된 수의 문장을 추출 하며, 추출된 문장을 전 처리함으로써 학습 데이터를 생성할 수 있다. 도 6은 일 실시 예에 따라 전자 장치가, 문장 별로 결정되는 문장 가중치를 결정하기 위해 이용하는 문장 가중 치 요소들을 설명하기 위한 도면이다. 도 6을 참조하면, 전자 장치가 문장 별 문장 가중치를 결정하기 위해 이용하는 문장 점수 요소 및 각 문장 점수 요소의 요소 내역이 도시된다. 전자 장치가 이용하는 문장 점수 요소는 소정의 식별 번호에 따라 전자 장치내 메모리에 미리 저장될 수 있다. 전자 장치는 도 5의 전 처리과정에 따라 전 처리된 문장 내 부정어구, 부사, 문장 부호, 강조어구, 부정어 또는 인물 단어 중 적어도 하나에 기초 하여, 전 처리된 문장 별 문장 가중치를 결정할 수 있다. 일 실시 예에 의하면, 문장 가중치 요소는 부정어구, 부사, 문장 부호, 접속사, 강조어구, 부정어, 인물 단어 중 적어도 하나를 포함할 수 있다. 전자 장치는 전 처리된 문장에 포함된 문장 가중치 요소에 기초 하여 문장 별 문장 가중치를 결정할 수 있다. 그러나, 또 다른 실시 예에 의하면, 상기 문장 가중치 요소를 포 함하는 문장에 인접한 다른 문장의 문장 가중치 요소를 변경할 수도 있다. 예를 들어, 전자 장치는 2개의 연속된 문장이 문장 가중치 요소인 but 접속사로 연결되는 경우(또는 2개의 연속된 문장 중 뒤의 문장이 문장 가중치 요소인 but 접속사를 포함하는 경우), 앞의 전 처리된 문장의 문장 가중치는 0.4만큼 감소시키고, but 접속사 이후에 연결되는 뒤의 문장의 문장 가중치는 0.4만큼 증가시킬 수 있다. 일 실시 예에 의하면, 문장 가중치 요소 중, 부정어구는 요소 내역으로써, not, isn't를 포함할 수 있다. 또한, 일 실시 예에 의하면, 문장 가중치 요소 중, 부사는 긍정 부사 및 부정부사를 포함할 수 있고, 긍정 부사 는 absolutely 또는 amazingly를 포함할 수 있으며, 부정 부사는 scarcely 또는 hardly 중 적어도 하나를 포함 할 수 있다. 그러나 이에 한정되는 것은 아니다. 일 실시 예에 의하면, 문장 부호는 느낌표, 물음표, 쉼표를 포함할 수 있고, 기타 문장 내 일부 위치에 삽입되 어 문장의 의미를 강조하거나, 보조하기 위한 기타 문장 부호들을 더 포함할 수도 있다. 일 실시 예에 의하면, 접속사는 but, however 등을 포함할 수 있으나 이에 한정되는 것은 아니다. 또한, 일 실 시 예에 의하면, 강조어구는 very 등을 포함할 수 있고, 부정어는 never, so, without을 포함할 수 있으며, 인 물 단어는 도 3에 도시된 인물 가중치 리스트에 도시된 인명을 포함할 수 있다. 일 실시 예에 의하면, 전자 장치는 전 처리된 문장에 포함된 인물 단어에 대하여 미리 할당되어 있는 인 물 단어 가중치를, 해당 인물 단어를 포함하는 문장의 가중치로 결정할 수 있다. 또 다른 실시 예에 의하면, 전 자 장치는 전 처리된 문장 내 not, isn't와 같은 부정어구가 포함되는 경우, 해당 부정어구를 포함하는 전 처리된 문장의 문장 가중치에 -1을 곱할 수 있다. 즉, 전자 장치는 전 처리된 문장 내 not, isn't와 같은 부정어구가 포함되는 경우, 해당 부정어구를 포함하는 전 처리된 문장의 문장 가중치를 음수로 결정할 수 있다. 또한, 일 실시 예에 의하면, 전자 장치는 전 처리된 문장 내 긍정 부사(예컨대 absolutely, amazingly)가 포함되는 경우, 포함된 긍정 부사의 수에 기초하여 해당 긍정 부사를 포함하는 문장의 문장 가중치에 소정의 가 중치 값을 더 할 수 있다. 일 실시 예에 의하면, 전자 장치는 전 처리된 문장 내 긍정 부사가 포함되는 경우, 해당 문장의 문장 가중치를 0.3만큼 증가시킬 수 있으나 문장 가중치의 증가 정도는 달라질 수 있다. 또 한, 일 실시 예에 의하면, 전자 장치는 전 처리된 문장 내 긍정 부사가 2개 포함되는 경우 전 처리된 문 장의 가중치를 0.6만큼 증가시킬 수도 있으나, 이에 한정되는 것은 아니다. 또 다른 실시 예에 의하면, 전자 장치는 전 처리된 문장 내 부정 부사(예컨대 scarcely, hardly 등)가 포 함되는 경우, 포함된 부정 부사의 수에 기초하여, 해당 부정 부사를 포함하는 문장의 문장 가중치에 소정의 가 중치 값을 뺄 수 있다. 일 실시 예에 의하면 전자 장치는 전 처리된 문장 내 부정 부사가 포함되는 경우, 해당 문장의 문장 가중치를 0.3만큼 감소시킬 수 있으나, 이에 한정되는 것은 아니다. 또한, 일 실시 예에 의하 면, 전자 장치는 전 처리된 문장 내 부정 부사가 2개 포함되는 경우, 가중치를 0.6만큼 감소 시킬 수도 있으나, 이에 한정되는 것은 아니다. 일 실시 예에 의하면, 전자 장치는 전 처리된 문장 내 문장 부호에 기초하여, 해당 문장 내 문장 가중치 를 결정할 수 있다. 예를 들어, 전자 장치는 전 처리된 문장이 강조 목적의 느낌표 문장 부호를 포함하는 경우, 느낌표를 포함하는 문장의 문장 가중치를 증가시킬 수 있다. 일 실시 예에 의하면, 전자 장치가 문장 가 중치를 증가시키는 동작은, 소정의 가중치 값을 더하거나, 소정의 스케일에 따른 스케일 값을 곱함으로써, 문장 가중치를 스케일업(scale-up)하는 동작에 대응될 수 있다. 그러나 또 다른 실시 예에 의하면, 전자 장치는 전 처리된 문장이 물음표 또는 쉼표와 같은 문장 부호를 포함하는 경우, 해당 문장의 문장 가중치를 감소시킬 수 있다. 일 실시 예에 의하면, 전자 장치가 문장 가중치 를 감소시키는 동작은, 소정의 가중치 값을 빼거나, 소정의 스케일에 따른 스케일 값을 곱함으로써, 문장 가중 치를 스케일다운(scale-down)하는 동작에 대응될 수 있다. 예를 들어, 전자 장치는 문장 가중치가 0.3인 전 처리된 문장이 느낌표 문장 부호로 끝나는 경우, 문장 가중치 0.3을 50% 스케일 업함으로써, 0.45로 결정할 수 있다. 일 실시 예에 의하면, 전자 장치는 문장에 강조어구(예컨대 very)가 포함되는 경우, 전 처리된 문장의 가 중치를 증가시킬 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 전 처리된 문장에 부정어(예컨대never, so, without)가 포함되는 경우, 해당 부정어를 포함하는 전 처리된 문장의 문장 가중치를 크게 하거나 작게 할 수 있다. 예를 들어, 전자 장치는 전 처리된 문장이 1개의 긍정 부사를 포함하고, 느낌표로 종결되며, 부정어구 not을 포함하는 경우, 1개 긍정 부사로 인한 증가된 문장 가중치를 0.3으로 증가시키고, 느낌표로 인하여 문장 가중치를 0.45로 스케일업 하며, 부정어구 not이 포함되었으므로, 스케일업된 문장 가중치 0.45를 -0.45로 변경 할 수 있다. 따라서, 전자 장치는 전 처리된 문장이 1개의 긍정 부사를 포함하고, 느낌표로 종결되며, 부 정어구 not을 포함하는 경우, 해당 문장의 문장 가중치를 -0.45로 결정할 수 있다. 그러나, 전자 장치가 문장 가중치를 증감하는 정도는 이에 한정되는 것은 아니다. 상술한 바와 같이, 전자 장치는 뉴스 기사로부터 추출된 일부의 문장을 전 처리하고, 전 처리된 문장 별 문장 가중치를 결정하며, 결정된 문장 가중치를 전 처리된 문장 별로 할당할 수 있다. 전자 장치는 결정 된 문장 가중치를 전 처리된 문장 각각에 할당하고, 가중치가 할당된 전 처리된 문자들을 이용하여 학습 데이터 를 생성할 수 있다. 도 7은 일 실시 예에 따라 전자 장치가 뉴스 기사로부터 학습 데이터 및 검증 데이터를 생성하는 과정을 설명하 기 위한 도면이다. 일 실시 예에 의하면, 전자 장치는 뉴스 기사를 획득하고, 획득된 뉴스 기사 내 각각의 문장을 식별할 수 있다. 예를 들어, 전자 장치는 미리 설정된 금융 단어 및 인물 단어를 포함하는 문장을 뉴스 기사에서 식 별할 수 있다. 예를 들어, 전자 장치는 뉴스 기사를 획득하고, 획득된 뉴스 기사 내 소정의 금 융 단어 또는 인물 단어 중 적어도 하나를 포함하는 문장 1 내지 문장 6을 식별할 수 있다. 일 실시 예에 의하면, 전자 장치는 뉴스 기사에 포함된 문장을 식별하고, 식별된 문장 각각의 기사 내 위 치 정보를 식별할 수 있다. 전자 장치는 식별된 문장이 뉴스 기사 내에서 몇 번째 문장인지 여부를 식별 할 수 있다. 전자 장치는 식별된 문장의 위치 정보에 기초하여, 뉴스 기사 내 첫 문장 및 뉴스 기사 내 마지막 문장을 식별할 수도 있다. 일 실시 예에 의하면, 전자 장치는 뉴스 기사에서 식별되는 문장 중, 소정의 문장을 추출할 수 있다. 예 를 들어, 전자 장치는 뉴스 기사에서 추출된 문장들 중, 문장 1 내지 4 및 문장 6을 추출할 수 있다. 전자 장치는 뉴스 기사 내 소정의 금융 단어 또는 인물 단어 중 적어도 하나를 포함하는 문장 중,"}
{"patent_id": "10-2020-0067620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "일부 문장을 추출하고, 추출된 일부 문장을 추출하여 요약 뉴스 기사를 생성할 수 있다. 일 실시 예에 의하면, 전자 장치는 금융 단어 또는 상기 인물 단어를 포함하는 문장, 뉴스 기사 내 첫 문 장 및 상기 뉴스 기사 내 마지막 문장 중, 점수 산정 대상이 되는 기 설정된 수의 문장을 추출하고, 추출된 기"}
{"patent_id": "10-2020-0067620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "설정된 수의 문장을 이용하여 요약 뉴스 기사를 생성할 수도 있다."}
{"patent_id": "10-2020-0067620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "또한, 도 7에는 도시되지 않았지만, 전자 장치는 요약 뉴스 기사내 문장들에 대하여, 도 5에서 상술 된 전 처리 과정을 수행한 후, 도 6에 도시된 문장 가중치 요소를 이용하여 도 5에서 상술된 전 처리과정에 따 라 전 처리된 문장 별 문장 가중치를 결정할 수 있다. 전자 장치는 결정된 문장 가중치를, 전 처리된 문 장 별로 할당함으로써, 학습 데이터를 생성할 수 있다. 즉, 전자 장치가 생성한 학습 데이터는 전 처리된 적어도 하나의 문장들을 포함할 수 있고, 각 문장들에는 문장 별 문장 가중치가 매칭되어 함께 저장 될 수 있다. 일 실시 예에 의하면, 전자 장치는 뉴스 기사로부터 학습 데이터를 생성함과 함께, 학습 데이터를 검증하기 위한 검증 데이터를 같이 생성할 수도 있다. 또 다른 실시 예에 의하면, 전자 장치는 기 설정된 기간 동안에 게재된 뉴스 기사를 이용하여 학습 데이터를 생성하고, 상기 학습 데이터를 생성하는데 이 용된 뉴스 기사의 게재 기간과 다른 기간 동안에 게재된 뉴스 기사를 이용하여 검증 데이터를 생성할 수도 있다. 또한, 일 실시 예에 의하면, 전자 장치는 학습 데이터에 기초하여 학습된 뉴스 기사 분석 모델로부터 출 력된 출력 값과 상기 검증 데이터가 상기 뉴스 기사 분석 모델에 입력 시, 상기 뉴스 기사 분석 모델로부터 출 력된 출력 값의 차이가 감소하도록, 상기 뉴스 기사 분석 모델을 학습시킬 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 학습 데이터에 기초하여 뉴스 기사 분석 모델로부터 출력된 값 및 상기 검증 데이터가 뉴스 기사 분석 모델에 입력 시, 상기 뉴스 기사 분석 모델로부터 출력되는 출력 값의 차이에 관한 손실 함수를 정의 하고, 정의된 손실 함수가 최소화되도록, 뉴스 기사 분석 모델을 학습 시킬 수도 있다.또한, 일 실시 예에 의하면, 전자 장치가 학습 데이터를 생성하기 위해 이용하는 뉴스 기사와 검증 데이터를 생성하기 위해 이용하는 뉴스 기사는 서로 다른 뉴스 기사일 수 있다. 예를 들어, 전자 장치 는 제1 기간 동안 게재된 뉴스 기사로부터 학습 데이터를 생성하고, 제1 기간과 다른 제2 기간 동안 게재된 뉴스 기사를 이용하여 검증 데이터를 생성할 수도 있다. 도 8은 일 실시 예에 따라 전자 장치가 학습된 신경망 모델을 이용하여 제1 뉴스 점수를 획득하는 방법을 설명 하기 위한 도면이다. 일 실시 예에 의하면, 전자 장치는 뉴스 기사를 획득하고, 획득된 뉴스 기사를 도 7에서 상술"}
{"patent_id": "10-2020-0067620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "한 과정에 따라 압축함으로써 요약 뉴스 기사를 생성할 수 있다. 전자 장치는 요약 뉴스 기사를 인코딩함"}
{"patent_id": "10-2020-0067620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "으로써 요약 데이터를 생성하고, 생성된 요약 데이터를 미리 학습된 신경망 모델에 입력할 수 있다. 전자 장치는 도 7에서 상술한 과정에 따라 학습 데이터, 또는 학습 데이터 및 검증 데이터에 기초하여 신"}
{"patent_id": "10-2020-0067620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "경망 모델을 학습 시킬 수 있다. 전자 장치는 학습된 신경망 모델에 요약 데이터를 입력함으로 써, 제1 뉴스 점수를 획득할 수 있다. 제1 뉴스 점수는 뉴스 기사가 나타내는 긍정 또는 부정적 성향에 관한 지 표 값을 나타낼 수 있다. 도 9는 일 실시 예에 따른 전자 장치의 블록도이다. 일 실시 예에 따른 전자 장치는 프로세서 및 메모리를 포함할 수 있다. 그러나, 도시된 구성 요소가 모두 필수구성요소인 것은 아니고, 도시된 구성 요소보다 많은 구성 요소에 의해 전자 장치가 구 현될 수도 있고, 그보다 적은 구성 요소에 의해서도 전자 장치는 구현될 수도 있다. 일 실시 예에 의하면, 전자 장치는 프로세서 및 메모리외에 네트워크 인터페이스(미도시)를 더 포함할 수 도 있다. 프로세서는, 통상적으로 전자 장치의 전반적인 동작을 제어한다. 일 실시 예에 의하면, 본 개시에 따른 프로세서는 메모리에 저장된 프로그램들을 실행함으로써, 도 1 내지 도 8에 기재된 전자 장치 의 기능을 수행할 수 있다. 또한, 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있고, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU와 같은 그래 픽 전용 프로세서 또는 인공지능(AI) 전용 프로세서를 포함할 수 있다. 그러나 이에 한정되는 것은 아니며, 프 로세서는 메모리에 저장된 인스트럭션을 실행함으로써 뉴스 기사를 분석하기 위한 기능을 수행하는 기타 처리 장치를 포함할 수 있다. 일 실시 예에 의하면, 프로세서가 범용 프로세서, 인공지능 프로세서 및 그 래픽 전용 프로세서를 포함하는 경우, 인공지능 프로세서는 범용 프로세서 또는 그래픽 전용 프로세서와 별도의 칩으로 구현될 수도 있다. 일 실시 예에 의하면, 프로세서가 복수의 프로세서 또는 그래픽 전용 프로세서 또는 인공 지능 전용 프로 세서로 구현될 때, 복수의 프로세서 또는 그래픽 전용 프로세서 또는 인공 지능 전용 프로세서 중 적어도 일부 는 전자 장치 및 전자 장치와 연결된 다른 전자 장치 또는 서버에 탑재될 수도 있다. 예를 들어, 프로세서는, 메모리에 저장된 프로그램들을 실행함으로써, 기 설정된 금융 단어 및 인 물 단어를 저장하고, 상기 전자 장치가 연결되는 외부의 디바이스로부터, 뉴스 기사를 획득하며, 상기 뉴스 기 사 내 상기 금융 단어 또는 상기 인물 단어를 포함하는 문장을 식별하고, 상기 식별된 문장 중 미리 설정된 수 의 문장을 추출하며, 상기 추출된 문장을 전 처리함으로써, 상기 뉴스 기사 분석 모델을 학습시키기 위한 학습 데이터를 생성할 수 있다. 또한, 프로세서는 상기 생성된 학습 데이터에 기초하여, 상기 뉴스 기사 분석 모델을 학습시킬 수 있다. 또 다른 실시 예에 의하면, 프로세서는 상기 뉴스 기사와 다른 기간에 게재된 다른 뉴스 기사로부터 검증 데이터를 생성하고, 생성된 학습 데이터 및 검증 데이터에 기초하여 뉴스 기사 분석 모델을 학습 시킬 수도 있 다. 또한, 프로세서는 학습 데이터에 기초하여 학습된 뉴스 기사 분석 모델로부터 출력된 출력 값과 상기 검 증 데이터가 상기 뉴스 기사 분석 모델에 입력 시, 상기 뉴스 기사 분석 모델로부터 출력된 출력 값의 차이가 감소하도록, 상기 뉴스 기사 분석 모델을 학습시킬 수도 있다. 또한, 일 실시 예에 의하면, 프로세서는 상기 금융 단어 및 상기 금융 단어 별 단어 점수를 매칭함으로써 금융 단어 리스트를 생성하고, 상기 인물 단어 및 상기 인물 단어 별 인물 단어 가중치를 매칭함으로써 인물 가 중치 리스트를 생성하며, 상기 생성된 금융 단어 리스트 및 상기 인물 가중치 리스트를 저장하고, 상기 금융 단어 리스트 및 상기 인물 가중치 리스트를 기 설정된 주기로 수정 및 갱신할 수 있다. 일 실시 예에 의하면, 프로세서는 상기 뉴스 기사에 포함된 문장들 각각의 위치 정보를 식별하고, 상기 식별된 문장의 위치 정보에 기초하여, 상기 뉴스 기사 내 첫 문장 및 상기 뉴스 기사 내 마지막 문장을 식별하 며, 상기 금융 단어 또는 상기 인물 단어를 포함하는 문장, 상기 첫 문장 및 상기 마지막 문장 중, 점수 산정 대상이 되는 미리 설정된 수의 문장을 추출할 수 있다. 일 실시 예에 의하면, 프로세서는 상기 뉴스 기사 내 식별된 문장 중, 추출된 일부 문장을 전 처리하고, 상기 전 처리된 문장을 이용하여 상기 학습 데이터를 생성할 수 있다. 일 실시 예에 의하면, 프로세서는 추출된 문장을 토큰화(tokenizing)함으로써, 문장 내 각 단어를 식별하 고, 상기 식별된 각 단어들 중, 문장 점수 산정에 사용되지 않는 단어들을 제거하고, 상기 문장 점수 산정에 사 용되지 않는 단어들을 제거하고 남은 각 문장 내 단어들을 표제어 형태로 변환할 수 있다. 일 실시 예에 의하면, 프로세서는 상기 전 처리된 문장 내 부정어구, 부사, 문장 부호, 강조어구, 부정어 또는 상기 인물 단어 중 적어도 하나에 기초하여, 상기 전 처리된 문장 각각에 대한 문장 가중치를 결정하고, 상기 결정된 문장 가중치를, 상기 전 처리된 문장 각각에 부여함으로써, 상기 학습 데이터를 생성할 수 있다. 또 다른 실시 예에 의하면, 프로세서는 네트워크 인터페이스를 통하여 전자 장치와 연결되는 외부 디바이 스로부터 신경망 모델의 가중치에 대한 정보를 수신하고, 수신된 신경망 모델의 가중치에 대한 정보에 기초하여, 전자 장치에 저장된 신경망 모델을 수정 및 갱신할 수도 있다. 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 전자 장치로 입력되 거나 전자 장치로부터 출력되는 데이터를 저장할 수도 있다. 또한, 메모리는 뉴스 기사 분석 모델 또는 신경망 모델을 저장할 수 있다. 일 실시 예에 의하면, 메모리는 신경망 모델의 구성으로써, 신경망 을 구성하는 레이어들, 레이어들에 포함된 노드들 및 레이어들의 연결 강도에 관한 가중치들에 대한 정보를 저 장할 수 있다. 일 실시 예에 의하면, 메모리는 도 3에서 상술한 금융 단어 및 상기 금융 단어 별 단어 점수를 포함하는 금융 단어 리스트를 더 저장할 수도 있다. 또한, 메모리는 미리 설정된 인물 단어 및 인물 단어 별 인물 단어 가중치를 포함하는 인물 가중치 리스트를 더 저장할 수도 있다. 일 실시 예에 의하면, 메모리는 메모리에 기 저장된 사전 학습 모델 및 신경망 모델이 수정 및 갱신되는 경우, 수정 및 갱신된 사전 학습 모델 및 신경망 모델을 저장할 수도 있다. 메모리는 플래시 메모리 타입 (flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있으나 이에 한정되는 것은 아니며, 기타 뉴스 기사를 분석하기 위한 방법을 수행하기 위한 인스트럭션들, 상기 뉴스 기사를 분석하기 위한 적어도 하나의 인공 지능 모델에 대 한 정보를 저장하기 위한 기타 저장 매체일 수 있다. 네트워크 인터페이스(미도시)는 전자 장치가 외부 디바이스 또는 서버와 송수신하는 데이터를 전달할 수 있다. 예를 들어, 전자 장치는 네트워크 인터페이스를 통하여 외부 디바이스로부터 뉴스 기사에 관한 데 이터를 획득할 수 있다. 또한, 전자 장치는 네트워크 인터페이스를 통하여 외부 디바이스로부터 신경망 모델 내지 사전 학습 모델에 대한 정보를 수신할 수도 있다. 또한, 전자 장치는 네트워크 인터페이스를 통하여 학습 시킨 뉴스 기사 분석 모델에 대한 정보를, 전자 장치와 연결된 외부 디바이스 또는 서버로 전송할 수도 있다. 도 10은 일 실시 예에 따른 서버의 블록도이다. 일 실시 예에 따르면, 서버는 네트워크 인터페이스, 데이터 베이스(Data Base, 2200) 및 프로세서 를 포함할 수 있다. 네트워크 인터페이스는 상술한 전자 장치의 네트워크 인터페이스(미도시)에 대응될 수 있다. 예를 들어, 네트워크 인터페이스는 전자 장치로부터 뉴스 기사 분석 모델에 대한 정보, 신경망 모델에 대한 정보(예컨대 레이어들 및 레이어들 사이의 연결 강도에 관한 가중치 값)를 수신할 수 있다. 또 다른 실시 예에 의하면, 네트워크 인터페이스는 인공 신경망의 레이어들 및 레이어들에 포함된 노드에 관한 정보 또는 신경망 내 레이어들의 연결 강도에 관한 가중치 값들을 전자 장치로 전송할 수도 있다. 일 실시 예에 의하면, 네트워크 인터페이스는 전자 장치 또는 전자 장치와 다른 외부 디바이스로부 터 뉴스 기사에 대한 데이터를 수신할 수도 있다. 데이터 베이스는 도 9에 도시된 전자 장치의 메모리 에 대응될 수 있다. 예를 들어, 데이터 베이스는 프로세서의 처리 및 제어를 위한 프로그램 을 저장할 수 있고, 전자 장치로 입력되거나 전자 장치로부터 출력되는 데이터를 저장할 수도 있다. 또한, 데이터 베이스는 신경망 모델을 구성하는 레이어들, 레이어들에 포함된 노드들 및 레이어들 의 연결 강도에 관한 가중치들에 대한 정보를 더 저장할 수도 있다. 또한, 일 실시 예에 의하면 데이터 베이스는 도 3에서 상술한 금융 단어 및 상기 금융 단어 별 단어 점수 를 포함하는 금융 단어 리스트를 더 저장할 수도 있다. 또한, 메모리는 미리 설정된 인물 단어 및 인물 단어 별 인물 단어 가중치를 포함하는 인물 가중치 리스트를 더 저장할 수도 있다. 또한, 데이터 베이스 는 전자 장치 또는 상기 전자 장치와 연결되는 외부 디바이스로부터 수신되는 뉴스 기사에 대한 정보들을 더 저 장할 수도 있다. 일 실시 예에 의하면, 프로세서는 서버의 전반적인 동작을 제어할 수 있다. 예를 들어, 프로세서 는 네트워크 인터페이스 및 데이터 베이스를 제어함으로써, 도 1 내지 9에서 기재된 전자 장 치가 수행하는 동작의 전부 또는 적어도 일부를 함께 수행할 수 있다. 일 실시예에 따른 상술한 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 개시를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 또한, 상기 일 실시 예에 다른 방법을 수행하도록 하는 프로그램이 저장된 기록매체를 포함하는 컴퓨터 프로그 램 장치가 제공될 수 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프 와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크 (floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같 은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴 파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행 될 수 있는 고급 언어 코드를 포함한다. 이상에서 본 개시의 실시예에 대하여 상세하게 설명하였지만 본 개시의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 개시의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 개시의 권리범위에 속한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2020-0067620", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시 예에 따른 뉴스 기사 분석 모델을 학습시키는 과정을 개략적으로 설명하기 위한 도면이다. 도 2는 일 실시 예에 따른 뉴스 기사 분석 모델을 학습시키는 방법의 흐름도이다. 도 3은 일 실시 예에 따라 전자 장치에 미리 저장되는 금융 단어 리스트 및 인물 가중치 리스트를 설명하기 위 한 도면이다. 도 4는 일 실시 예에 따라 전자 장치가, 뉴스 기사 내에서 식별된 문장 중 미리 설정된 수의 문장을 추출하는 과정을 설명하기 위한 도면이다.도 5는 일 실시 예에 따라, 전자 장치가 미리 설정된 수의 문장을 전처리 하는 과정을 나타내는 흐름도이다. 도 6은 일 실시 예에 따라 전자 장치가, 문장 별로 결정되는 문장 가중치를 결정하기 위해 이용하는 문장 가중 치 요소들을 설명하기 위한 도면이다. 도 7은 일 실시 예에 따라 전자 장치가 뉴스 기사로부터 학습 데이터 및 검증 데이터를 생성하는 과정을 설명하 기 위한 도면이다. 도 8은 일 실시 예에 따라 전자 장치가 학습된 신경망 모델을 이용하여 제1 뉴스 점수를 획득하는 방법을 설명 하기 위한 도면이다. 도 9는 일 실시 예에 따른 전자 장치의 블록도이다. 도 10은 일 실시 예에 따른 서버의 블록도이다."}
