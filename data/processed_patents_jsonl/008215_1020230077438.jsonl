{"patent_id": "10-2023-0077438", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0176600", "출원번호": "10-2023-0077438", "발명의 명칭": "딥러닝 기반 성형수술 가이드 장치 및 이를 위한 동작 방법", "출원인": "이규식", "발명자": "이규식"}}
{"patent_id": "10-2023-0077438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "딥러닝 기반 성형수술 가이드 장치를 위한 동작 방법에 있어서,환자의 환부와 연관된 3D 환부 데이터를 미리 연동된 CT 장치로부터 획득하는 단계;상기 3D 환부 데이터를 기반으로 미리 설정된 다운 샘플링을 수행하는 단계;상기 다운 샘플링된 3D 환부 데이터를 제1 스테이지와 연관된 제1 U-Net에 적용하여 제1 예측 이미지 정보를 생성하는 단계;상기 제1 예측 이미지 정보를 기반으로 미리 설정된 업샘플링을 수행하는 단계;상기 업샘플링된 제1 예측 이미지 정보를 제2 스테이지와 연관된 제2 U-Net에 적용하여 제2 예측 이미지 정보를생성하는 단계; 및상기 제2 예측 이미지 정보를 기반으로 상기 환부와 연관된 하나 이상의 인체조직 및 하나 이상의 인공 보형물을 표현하는 3D 이미지 정보를 생성하는 단계를 포함하는 방법."}
{"patent_id": "10-2023-0077438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 제1 예측 이미지 정보는 상기 환부와 연관된 하나 이상의 인체조직을 개별적으로 구분(segmentation)하기위한 제1 구분 정보를 포함하는 방법."}
{"patent_id": "10-2023-0077438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 제2 예측 이미지 정보는 상기 구분된 하나 이상의 인체조직으로부터 하나 이상의 인공 보형물을 구분하기위한 제2 구분 정보를 포함하는, 방법."}
{"patent_id": "10-2023-0077438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서,상기 3D 환부 데이터에 대한 적어도 하나의 전처리 작업을 통해 상기 환부를 위한 외부 외곽선 정보가추출되는, 방법."}
{"patent_id": "10-2023-0077438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 업생플링된 제1 예측 이미지 정보 상에서 상기 외부 외곽선 정보에 따라 복수의 크롭핑된 영역이 정의될때, 상기 복수의 크롭핑된 영역에 상응하는 이미지 정보가 제2 U-Net에 적용되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0077438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "환자의 환부와 연관된 3D 환부 데이터를 미리 연동된 CT 장치로부터 획득하는 의료 영상 획득 모듈;상기 3D 환부 데이터에 대한 적어도 하나의 전처리 작업을 통해 상기 환부를 위한 외부 외곽선 정보를 추출하는전처리 모듈; 및상기 3D 환부 데이터를 기반으로 미리 설정된 다운 샘플링을 수행하도록 구현되고, 상기 다운 샘플링된 3D 환부데이터를 제1 스테이지와 연관된 제1 U-Net에 적용하여 제1 예측 이미지 정보를 생성하도록 구현되고, 상기 제1예측 이미지 정보를 기반으로 미리 설정된 업샘플링을 수행하도록 구현되고, 상기 업샘플링된 제1 예측 이미지공개특허 10-2024-0176600-3-정보를 제2 스테이지와 연관된 제2 U-Net에 적용하여 제2 예측 이미지 정보를 생성하도록 구현되고, 그리고 상기 제2 예측 이미지 정보를 기반으로 상기 환부와 연관된 하나 이상의 인체조직 및 하나 이상의 인공 보형물을표현하는 3D 이미지 정보를 생성하도록 구현되는 의료 영상 분석 모듈을 포함하는, 딥러닝 기반 성형수술 가이드 장치."}
{"patent_id": "10-2023-0077438", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치를 위한 동작 방법은, 환자의 환부와 연관된 3D 환부 데 이터를 미리 연동된 CT 장치로부터 획득하는 단계; 3D 환부 데이터를 기반으로 미리 설정된 다운 샘플링을 수행 하는 단계; 다운 샘플링된 3D 환부 데이터를 제1 스테이지와 연관된 제1 U-Net에 적용하여 제1 예측 이미지 정보 를 생성하는 단계; 제1 예측 이미지 정보를 기반으로 미리 설정된 업샘플링을 수행하는 단계; 업샘플링된 제1 예 측 이미지 정보를 제2 스테이지와 연관된 제2 U-Net에 적용하여 제2 예측 이미지 정보를 생성하는 단계; 및 제2 예측 이미지 정보를 기반으로 환부와 연관된 하나 이상의 인체조직 및 하나 이상의 인공 보형물을 표현하는 3D 이미지 정보를 생성하는 단계를 포함한다."}
{"patent_id": "10-2023-0077438", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서는 딥러닝 기반 성형수술 가이드 장치 및 이를 위한 동작 방법에 관한 것으로, 더 상세하게는, 환자의 환부와 연관된 복수의 인체조직 및 인공 보형물을 구별할 뿐만 아니라 이를 3D 렌더링으로 구현할 수 있는 딥러 닝 기반 성형수술 가이드 장치 및 이를 위한 동작 방법에 관한 것이다."}
{"patent_id": "10-2023-0077438", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "성형수술은 사고 등으로 재건 수술이 필요한 환자 뿐만 아니라 단순히 미적 관점에서 외적 변화를 원하는 일반 인에게 미용 개념으로 인식됨에 따라 보편적인 수술로 자리 잡고 있다. 이에, 성형수술의 보편화에 따라 그에 맞는 다양한 형태의 보형물에 대한 요구조건이 증가하고 있다. 한편, 기존의 성형수술은 환자의 의료영상기반으로 상담이 이루어지지 않고, 의료진의 주관적인 판단으로 성형 수술을 계획하여 수술목적에 부합하지 않는 수술 결과를 초래하는 경우가 있다. 기존의 시뮬레이션 기술은 표면(surface mesh)의 움직임에 따른 이미지의 변화를 시각화한 기술로, 피부의 겉표 면(surface)의 메쉬(Mesh) 데이터에 기반하고 있기 때문에, 환자의 상세한 정보가 반영되기 어렵다. 한편, nnUnet 모델은 U-Net 기반의 의료 이미지 세그멘테이션을 위한 자기 적응적인 프레임워크을 의미하며, 다양한 생물학 및 의료 이미지 세그멘테이션 작업에 대해 U-Net 모델을 기반으로 자동으로 구성되는 딥러닝 기 반 이미지 세그멘테이션 방법과 연관될 수 있다. 이 경우, 의료 이미지 세그멘테이션은 의료 이미지에서 특정한 인체조직을 분리하거나 분류하는 등의 작업을 수 행하기 위해 사용될 수 있다. 여기서, nnUnet 모델에 관하여는 2023년 4월 5일에 수정된 'An optimized, robust and self-adapting framework for U-Net based medical image segmentation' 논문을 참조할 수 있다. 의료분야에서는 CT 영상으로부터 분할(segmentation)의 정확도는 인체 조직을 3D로 렌더링 하기 위해 각 인체조 직별(뼈, 연골, 삽입물 등)로 정확한 영역을 구분한다는 점에서 매우 중요한 요소이다. 즉, CT 영상으로부터 분할을 통해 인체조직별로 정확한 영역이 구분되어야 이를 기초로 3D 렌더링 이미지를 생 성할 수 있고, 이는 임상에서 진단 또는 치료에 이용되기 때문이다. 종래 제안으로 안면보정 이미지 제공방법 및 그 시스템에 관한 공개특허 제10-2012-0096238 호를 참조할 수 있 다."}
{"patent_id": "10-2023-0077438", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 명세서의 목적은 환자의 환부와 연관된 복수의 인체조직 및 인공 보형물을 구별할 뿐만 아니라 이를 3D 렌더 링으로 시각화할 수 있는 딥러닝 기반 성형수술 가이드 장치 및 이를 위한 동작 방법을 제공하는데 있다."}
{"patent_id": "10-2023-0077438", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치를 위한 동작 방법은, 환자의 환부와 연관된 3D 환부 데이터를 미리 연동된 CT 장치로부터 획득하는 단계; 3D 환부 데이터를 기반으로 미리 설정된 다운 샘플링을 수 행하는 단계; 다운 샘플링된 3D 환부 데이터를 제1 스테이지와 연관된 제1 U-Net에 적용하여 제1 예측 이미지 정보를 생성하는 단계; 제1 예측 이미지 정보를 기반으로 미리 설정된 업샘플링을 수행하는 단계; 업샘플링된 제1 예측 이미지 정보를 제2 스테이지와 연관된 제2 U-Net에 적용하여 제2 예측 이미지 정보를 생성하는 단계; 및 제2 예측 이미지 정보를 기반으로 환부와 연관된 하나 이상의 인체조직 및 하나 이상의 인공 보형물을 표현하는 3D 이미지 정보를 생성하는 단계를 포함할 수 있다. 본 일 실시 예에 따르면, 제1 예측 이미지 정보는 환부와 연관된 하나 이상의 인체조직을 개별적으로 구분 (segmentation)하기 위한 제1 구분 정보를 포함할 수 있다. 본 일 실시 예에 따르면, 제2 예측 이미지 정보는 구분된 하나 이상의 인체조직으로부터 하나 이상의 인공 보형 물을 구분하기 위한 제2 구분 정보를 포함할 수 있다. 본 일 실시 예에 따르면, 3D 환부 데이터에 대한 적어도 하나의 전처리 작업을 통해 환부를 위한 외부 외곽선 정보가 추출될 수 있다. 본 일 실시 예에 따르면, 업생플링된 제1 예측 이미지 정보 상에서 외부 외곽선 정보에 따라 복수의 크롭핑된 영역이 정의될 때, 복수의 크롭핑된 영역에 상응하는 이미지 정보가 제2 U-Net에 적용될 수 있다. 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치는, 환자의 환부와 연관된 3D 환부 데이터를 미리 연동 된 CT 장치로부터 획득하는 의료 영상 획득 모듈; 3D 환부 데이터에 대한 적어도 하나의 전처리 작업을 통해 환 부를 위한 외부 외곽선 정보를 추출하는 전처리 모듈; 및 3D 환부 데이터를 기반으로 미리 설정된 다운 샘플링 을 수행하도록 구현되고, 다운 샘플링된 3D 환부 데이터를 제1 스테이지와 연관된 제1 U-Net에 적용하여 제1 예 측 이미지 정보를 생성하도록 구현되고, 제1 예측 이미지 정보를 기반으로 미리 설정된 업샘플링을 수행하도록 구현되고, 업샘플링된 제1 예측 이미지 정보를 제2 스테이지와 연관된 제2 U-Net에 적용하여 제2 예측 이미지 정보를 생성하도록 구현되고, 그리고 제2 예측 이미지 정보를 기반으로 환부와 연관된 하나 이상의 인체조직 및 하나 이상의 인공 보형물을 표현하는 3D 이미지 정보를 생성하도록 구현되는 의료 영상 분석 모듈을 포함한다."}
{"patent_id": "10-2023-0077438", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 일 실시 예에 따르면, 환자의 환부와 연관된 복수의 인체조직 및 인공 보형물을 구별할 뿐만 아니라 이를 3D 렌더링으로 구현할 수 있는 딥러닝 기반 성형수술 가이드 장치 및 이를 위한 동작 방법이 제공될 수 있다. 이에 따라, 본 일 실시 예에 따르면, 환자의 환부와 연관된 복수의 인체조직의 형상 뿐만 아니라 기 삽입된 인 공 보형물의 형상 및 물성을 딥리닝 기술을 이용하여 보다 높은 정확도로 미리 파악할 수 있으므로, 성형수술계 획 혹은 재건수술계획의 사전 수립 시 환자와 의사 간에 원활한 의사소통이 가능해져 보다 효과적이고 정확한 성형수술이 수행될 수 있음은 이해될 것이다. 또한, 본 일 실시 예에 따르면, 성형수술 이후에도 환자의 환부와 연관된 복수의 인체조직의 형상 뿐만 아니라 삽입된 인공 보형물의 형상을 토대로 미리 수립된 성형수술계획에 따른 수술 결과가 획득되는지 여부를 보다 객 관적으로 판단할 수 있는 자료가 제공될 수 있다."}
{"patent_id": "10-2023-0077438", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "전술한 특성 및 이하 상세한 설명은 모두 본 명세서의 설명 및 이해를 돕기 위한 예시적인 사항이다. 즉, 본 명 세서는 이와 같은 실시 예에 한정되지 않고 다른 형태로 구체화될 수 있다. 다음 실시 형태들은 단지 본 명세서 를 완전히 개시하기 위한 예시이며, 본 명세서가 속하는 기술 분야의 통상의 기술자들에게 본 명세서를 전달하 기 위한 설명이다. 따라서, 본 명세서의 구성 요소들을 구현하기 위한 방법이 여럿 있는 경우에는, 이들 방법 중 특정한 것 또는 이와 동일성 있는 것 가운데 어떠한 것으로든 본 명세서의 구현이 가능함을 분명히 할 필요가 있다. 본 명세서에서 어떤 구성이 특정 요소들을 포함한다는 언급이 있는 경우, 또는 어떤 과정이 특정 단계들을 포함 한다는 언급이 있는 경우는, 그 외 다른 요소 또는 다른 단계들이 더 포함될 수 있음을 의미한다. 즉, 본 명세서에서 사용되는 용어들은 특정 실시 형태를 설명하기 위한 것일 뿐이고, 본 명세서의 개념을 한정 하기 위한 것이 아니다. 나아가, 발명의 이해를 돕기 위해 설명한 예시들은 그것의 상보적인 실시 예도 포함한 다. 본 명세서에서 사용되는 용어들은 본 명세서가 속하는 기술 분야의 통상의 기술자들이 일반으로 이해하는 의미 를 갖는다. 보편적으로, 사용되는 용어들은 본 명세서의 맥락에 따라 일관적인 의미로 해석되어야 한다. 또한, 본 명세서에서 사용되는 용어들은, 그 의미가 명확히 정의된 경우가 아니라면, 지나치게 이상적이거나 형 식적인 의미로 해석되지 않아야 한다. 이하 첨부된 도면을 통하여 본 명세서의 실시 예가 설명된다. 본 명세서에서 언급되는 영상 이미지는 별도의 입력 소스(예로, 적외선, 가시광선, 레이저, 초음파, 방사선 등)를 기반으로 3차원 데이터를 측정하여 획득된 이미지를 의미한다. 즉, 영상 이미지 데이터는 입력 소스를 조 사하여 반사되는 경로 상에서 측정되는 값을 기반으로 획득될 수 있다. 한편, 본 명세서에서 언급되는 의료영상 이미지는 의료영상 장치를 이용하여 획득되는 것으로, 다수의 의료영상 이미지의 단면을 적층함으로써 시뮬레이션 상에서 3D 이미지 정보가 구현될 수 있다. 한편, 본 명세서에서 의료영상 이미지는 의료용 디지털 영상처리 및 통신(Digital Imaging and Communications in Medicine, 이하 'DICOM') 표준을 준수하는 규격화된 이미지로 이해될 수 있다. 여기서, 의료영상 장치는 Computed Tomography(이하, 'CT') 장치(또는 MRI 장치)를 포함할 수 있다. 또한, 본 명세서에서 의료영상 이미지 내 각 인체조직은 인체조직의 유형에 상응하는 밀도 값(gray scale value)을 기반으로 분류될 수 있다. 즉, 의료영상 이미지 내 각 인체조직에는 밀도 값(즉, 그레이 스케일 값, gray scale value)의 단위에 따른 고유의 값이 미리 설정될 수 있다. 나아가, 본 명세서에서 언급되는 3D 이미지 정보는 각 인체조직에 상응하는 밀도 값(gray scale value)을 이용 하여 3D 이미지 상에 표현하고자 하는 인체조직만을 표현하도록 선택적으로 구현될 수 있다. 도 1은 본 일 실시 예에 따른 제1 3D 이미지 정보를 나타내는 예시도이다. 도 1의 (a)를 참조하면, 기존 파일 형식에 따른 제1 3D 이미지 정보에는 성형수술을 위한 환부(예로, 환자의 코)와 연관된 복수의 인체조직이 구현될 수 있다. 예를 들어, 제1 3D 이미지 정보를 기반으로 성형수술을 위한 환부(예로, 환자의 코)와 연관된 복수의 인체조 직 중에서 코 뼈와 상응하는 제1 인체조직(bone) 및 코 연골과 상응하는 제2 인체조직(cartilage, 이하 'CTL') 이 구현될 수 있다. 다시 말해, 제1 3D 이미지 정보의 파일형식은 CAD(Computer Aided Design) 또는 3D 프린팅에 3D 모델링된 데이터를 표준 형식의 파일로 저장하기 위해 일반적으로 사용되는 STL(Standard Triangulated Language) 파일 형식일 수 있다. 일 예로, 제1 3D 이미지 정보에 따라 표현되는 복수의 인체조직의 표면은 STL 파일 형식을 위한 기본 단위인 삼각형을 이용한 기하학적 구조로 구현될 수 있다. 더 구체적으로, 제1 3D 이미지 정보에 따라 표현되는 복수의 인체조직의 표면은 3개의 꼭지점(vertex) 및 1 개의 벡터(vector)를 기본 단위로 하는 tri-angle mesh 형태로 표현될 수 있다. 도 1의 (b)를 참조하면, 제1 3D 이미지 정보는 tri-angle mesh 형태로 표현되는 STL 파일 형식을 따르기 때 문에, 제1 3D 이미지 정보를 기반으로 코 연골과 상응하는 제2 인체조직(CTL)은 표면 상부로 볼록하게 올라가도록 변형(m)되거나 안쪽으로 패이도록 변형되는 형태 조정만이 구현되는 한계가 존재한다. 도 2는 본 일 실시 예에 따른 제2 3D 이미지 정보를 나타내는 예시도이다. 도 2(a)를 참조하면, 본 일 실시 예에 따른 제2 3D 이미지 정보는 성형수술을 위한 환부(예로, 환자의 코)와 연관된 적어도 하나의 인체조직의 위치 조정이 가능한 것으로 이해될 수 있다. 예를 들어, 본 일 실시 예에 따른 제2 3D 이미지 정보을 기반으로 성형수술을 위한 환부(예로, 환자의 코)와 연관된 복수의 인체조직 중에서 코 뼈와 상응하는 제1 인체조직(bone) 및 상에 코 연골과 상응하는 제2 인체조 직(CTL_1d)이 구현될 수 있다. 여기서, 제2 인체조직(CTL_1d)은 코 연골(예로, Lateral C 부위)과 연관된 것으로 이해될 수 있다. 일 예로, 제1 인체조직(bone)은 CAD(Computer Aided Design) 또는 3D 프린팅에 일반적으로 사용되는 STL 파일 형식, 즉 3개의 꼭지점(vertex) 및 1개의 벡터(vector)를 기본 단위로 하는 tri-angle mesh 형태를 기반으로 구현될 수 있다. 일 예로, 제2 인체조직(CTL_1d)은 2개의 노드(node) 및 1개의 빔(beam)을 기본 단위로 하는 1차원 요소(1D element) 형태로 표현될 수 있다. 구체적으로, 제2 3D 이미지 정보를 기반으로 코 연골과 상응하는 제2 인체조직(CTL_1d)은 1차원 요소(1D element)를 이용하여 시뮬레이션 상에서 표현될 수 있다. 본 일 실시 예에 따르면, 1차원 요소(1D element)로 표현된 제2 인체조직(CTL_1d)과 연관된 복수의 노드는 이동 (즉, 무빙) 가능하도록 구현되므로, 제2 3D 이미지 정보 상에서 환부(예로, 환자의 코)의 형태는 환자가 원 하는 모양으로 변화될 수 있다. 다시 말해, 제2 3D 이미지 정보 상에서 구현된 코 연골과 상응하는 제2 인체조직(CTL_1d)은 도 1의 (b)와 같 은 형태 조정 뿐만 아니라 위치 조정이 가능하도록 구현될 수 있다. 결국, 본 명세서에서 언급되는 모델링의 적용으로 형태 조정만이 가능한 제1 인체조직(bone)과 형태 조정 및 위 치 조정이 모두 가능한 제2 인체조직(CTL_1d)이 하나의 제2 3D 이미지 정보 상에서 구현될 수 있다. 본 일 실시 예의 명확하고 간결한 이해를 위해, 미리 정해진 위치들(예로, 도 2(a)의 P1, P2) 사이의 수평 간격 (L) 및 수평 간격(L)에서 시뮬레이션의 코 피부 표면 까지의 수직 간격(d)이 정의될 수 있다. 또한, 적어도 하나의 인체조직(예로, 연골)에 대한 무빙(즉, 이동)이 적용된 이후 미리 정해진 위치들(예로, 도 2(b)의 P1', P2') 사이의 수평 간격(L') 및 수평 간격(L')에서 시뮬레이션의 코 피부 표면 까지의 수직 간격 (d')이 정의될 수 있다. 도 3은 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치를 위한 블록도이다. 도 1 내지 도 3을 참조하면, 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치는 의료영상 획득 모 듈, 전처리 모듈 및 의료영상 분석 모듈을 포함할 수 있다. 도 3의 의료영상 획득 모듈은 환자의 환부와 연관된 3D 환부 데이터를 미리 연동된 CT 장치로부터 획득할 수 있다. 즉, 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치는 3D 환부 데이터를 그대로 사용하는 방식으로 구 현될 수 있다. 즉, 3D 환부 데이터는 기존 CT 장치(혹은 MRI 장치)에 의해 촬영된 환부를 3차원으로 구현하기 위한 데이터로 이해될 수 있다. 이와 달리, 2D 기반의 다수의 의료영상 이미지는 기존 U-Net에 적용 가능하며, 3D 환부 데이터를 미리 정해진 방식으로 슬라이스(slice)함으로써 획득될 수 있다. 도 3의 전처리 모듈은 3D 환부 데이터에 대한 제1 전처리 작업 및 제2 전처리 작업 중 적어도 하나를 수행 할 수 있다. 예를 들어, 제1 전처리 작업은 3D 환부 데이터 중 얼굴 전체 영역과 관련된 데이터가 다른 인체조직들과 관련된 데이터 대비하여 많이 존재함에서 기인하는 데이터 불균형(data imbalance)을 해소하기 위한 동작으로 이해될 수 있다.다시 말해, 다른 인체조직에 상응하는 영역은 얼굴 전체에 상응하는 영역과 대비하여 상대적으로 분할 (segmentation)이 잘 되지 않는 현상이 발생할 수 있다. 참고로, 데이터 불균형(data imbalance)에 따른 문제를 해소하기 위한 제1 전처리 작업은 후술되는 도 5를 참조 하여 더 상세하게 설명된다. 예를 들어, 제2 전처리 작업은 3D 환부 데이터에 포함된 노이즈를 경감 혹은 제거하기 위한 잡음 제거 필터를 이용한 필터링 동작으로 이해될 수 있다. 참고로, 제2 전처리 작업은 후술되는 도 6을 참조하여 더 상세하게 설명된다. 도 3의 의료영상 분석 모듈은 3D 환부 데이터(혹은 슬라이스된 다수의 의료영상 이미지)에 대하여 인체 조 직 간 미리 설정된 경계 값을 이용하여 환자의 환부와 연관된 하나 이상의 인체조직을 시각화한 3D 이미지 정보 를 생성할 수 있다. 여기서, 하나 이상의 인체조직은 환자의 뼈(bone), 환자의 연골(cartilage) 및 환자의 피부(skin) 중 적어도 하 나와 연관될 수 있다. 또한, 인체 조직 간 경계 값은 하나 이상의 인체조직에 상응하는 픽셀 데이터에 대한 수식화를 기반으로 한 머 신러닝 기법을 위해 미리 결정될 수 있음은 이해될 것이다. 본 일 실시 예에 따른 의료 영상 분석 모듈은 3D 환부 데이터(혹은 슬라이스된 다수의 의료영상 이미지)에 대하여 다수의 인체 조직 각각에 상응하는 밀도 값(즉, 그레이 스케일 값)을 이용하여 각 인체 조직을 분류(또 는 추적)하도록 구현될 수 있다. 이 경우, 다수의 인체 조직 각각에 상응하는 밀도 값(즉, 그레이 스케일 값)은 미리 결정된 값으로 이해될 수 있다. 예를 들어, 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치에 3D 환부 데이터(혹은 슬라이스된 다수의 의료영상 이미지)가 입력될 때, 의료 영상 분석 모듈은 미리 결정된 밀도 값(즉, 그레이 스케일 값)을 이 용하여 특정한 인체조직을 분류(또는 추적)할 수 있다. 이 경우, 의료 영상 분석 모듈에 의해 분류된 인체조직은 구현방식에 따라 각기 다른 색상으로 표현될 수 있다. 일 예로, 환부(예로, 코)와 연관된 뼈의 밀도 값(즉, 그레이 스케일 값)은 100 내지 200 HU로 미리 결정될 수 있다. 환부(예로, 코)와 연관된 기도(airway)의 밀도 값은 -100 내지 -10 HU로 미리 결정될 수 있다. 환부(예로, 코)와 연관된 연골의 밀도 값은 0 내지 70HU로 미리 결정될 수 있다. 구체적으로, 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치에 3D 환부 데이터(혹은 슬라이스된 다수 의 의료영상 이미지)를 기반으로 환부(예로, 코)와 연관된 뼈가 분석될 때, 의료 영상 분석 모듈은 뼈에 상응하는 밀도 값(즉, 100 내지 200 HU)에 범위에 포함되는 픽셀 데이터를 모두 추적하도록 구현될 수 있다. 이 과정에서, 환부(예로, 코)와 연관된 뼈에 상응하는 인체조직의 부피가 인식될 수 있음은 이해될 것이다. 마찬가지로, 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치에 3D 환부 데이터(혹은 슬라이스된 다수 의 의료영상 이미지)를 기반으로 기도가 분석될 때, 의료 영상 분석 모듈은 기도에 상응하는 밀도 값(즉, -100 내지 -10 HU)에 범위에 포함되는 픽셀 데이터를 모두 추적하도록 구현될 수 있다. 이 과정에서, 환부(예로, 코)와 연관된 기도에 상응하는 인체조직의 부피가 인식될 수 있음은 이해될 것이다. 마찬가지로, 다수의 의료영상 이미지를 기반으로 연골이 분석될 때, 의료 영상 분석 모듈은 연골에 상응하 는 밀도 값(즉, 0 내지 70 HU)에 범위에 포함되는 값들을 모두 추적하도록 구현될 수 있다. 이 과정에서, 환부(예로, 코)와 연관된 연골에 상응하는 인체조직의 부피가 인식될 수 있음은 이해될 것이다. 나아가, 의료영상 분석 모듈은 3D 환부 데이터(혹은 슬라이스된 다수의 의료영상 이미지)에 대하여 하나 이상의 인공 보형물을 위해 미리 설정된 경계 값을 이용하여 환자의 환부와 연관된 하나 이상의 인공 보형물을 시각화한 3D 이미지 정보로 생성할 수 있다. 여기서, 하나 이상의 인공 보형물은 환자의 환부에 삽입된 실리콘 재질의 보형물, ePTFE 재질의 보형물 또는 필 러 중 적어도 하나와 연관될 수 있다. 또한, 인공 보형물을 위한 경계 값은 하나 이상의 인공 보형물에 상응하는 픽셀 데이터에 대한 수식화를 기반으 로 한 머신러닝 기법을 위해 미리 결정될 수 있음은 이해될 것이다. 이에 따라, 의료영상 분석 모듈은 3D 환부 데이터(혹은 슬라이스된 다수의 의료영상 이미지)를 기반으로 하나 이상의 인체조직 및 하나 이상의 인공 보형물을 포함하는 3D 이미지 정보를 자동으로 생성할 수 있다. 본 일 실시 예에 따른 의료영상 분석 모듈에는 nnUnet 모델을 이용한 딥러닝 기술이 적용될 수 있다. 참고 로, 의료영상 분석 모듈에 적용되는 nnUnet 모델에 관하여는 후술되는 도 7을 참조하여 더 상세하게 설명 된다. 다만, 본 명세서가 이에 한정되는 것은 아니며, 의료영상 분석 모듈에는 심층 신경망(Deep Neural Network) 기법 또는 합성곱 신경망(Convolutional Neural Network) 기법 등이 적용될 수도 있다. 구체적으로, 의료영상 이미지(즉, CT 영상)에는 2D 이미지를 활용한 경계화(threshold) 작업이 수행될 수 있다. 다시 말해, 특정한 인체조직과 연관된 픽셀(pixel)의 데이터에 대한 수식화를 기초로 환자의 환부(예로, 코)와 연관된 연골, 뼈 그리고 피부와 같은 인체 조직이 세부적으로 구분될 수 있다. 일 예로, 경계화(threshold) 작업을 거치면서 분류된 값 중에서 3D 영상화를 위해 작업자에 의해 선택된 명암 값들은 STL(Standard Triangulated Language) 파일로 변환될 수 있다. 참고로, STL 파일은 3D 모델링된 데이터를 표준 형식의 파일로 저장하기 위해 제공되는 하나의 파일 형식을 의 미한다. 본 명세서에서 언급되는 3D 이미지 정보는 작업자에 의해 선택된 STL 파일을 통합하여 구현되는 3D 형상 혹은 3D 렌더링 이미지로 이해될 수 있다. 도 4는 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치의 동작 방법을 나타내는 순서도이다. 도 1 내지 도 4를 참조하면, S410 단계에서, 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치(예로, 도 3의 300)는 환자의 환부와 연관된 3D 환부 데이터를 미리 연동된 CT 장치로부터 획득할 수 있다. S420 단계에서, 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치(예로, 도 3의 300)는 3D 환부 데이터 에 대하여 적어도 하나의 전처리 작업을 수행할 수 있다. 예를 들어, 적어도 하나의 전처리 작업은 도 5와 같은 제1 전처리 작업 및 도 6과 같은 제2 전처리 작업을 포함 할 수 있다. 이 경우, 제1 전처리 작업을 제2 전처리 작업의 수행 여부와 무관하게 독립적으로 수행될 수 있다. 또한, 제2 전처리 작업은 앞서 서술된 제1 전처리 작업에 이어서 수행되거나 제1 전처리 작업을 건너 뛰고 단독으로 수행 될 수도 있다. 예를 들어, 3D 환부 데이터에 대한 적어도 하나의 전처리 작업을 수행함으로써 후술되는 도 5와 같은 환부를 위 한 외부 외곽선 정보(예로, 도 5의 500)가 추출될 수 있다. S430 단계에서, 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치(예로, 도 3의 300)는 3D 환부 데이터 를 기반으로 미리 설정된 다운 샘플링을 수행할 수 있다. 이 경우, 다운 샘플링은 의료영상 분석 모듈(예로, 도 3의 330)에 구현된 nnUnet 모델을 위한 3D 환부 데이터와 연관된 입력 이미지의 크기를 줄이기 위해 사용될 수 있다. 참고로, 다운 샘플링을 수행하여 3D 환부 데이터와 연관된 입력 이미지의 크기를 줄이는 것은 이미지의 특징 추 출에 유리할 수 있다. 또한, 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치(예로, 도 3의 300)는 다운 샘플링된 3D 환부 데 이터를 제1 스테이지와 연관된 제1 U-Net에 적용하여 제1 예측 이미지 정보를 생성할 수 있다. 예를 들어, 제1 예측 이미지 정보는 환부와 연관된 하나 이상의 인체조직을 개별적으로 구분(segmentation)하기 위한 제1 구분 정보를 포함할 수 있다. S440 단계에서, 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치(예로, 도 3의 300)는 제1 예측 이미지 정보를 기반으로 미리 설정된 업샘플링을 수행을 수행할 수 있다. 여기서, 제1 예측 이미지 정보는 다운 샘플링된 3D 환부 데이터로부터 생성되는 것임을 이해될 것이다. 이에 따 라, 제1 예측 이미지 정보에 대한 업샘플링은 원본 이미지의 크기로 복원하기 위한 과정으로 이해될 수 있다. 또한, 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치(예로, 도 3의 300)는 업샘플링된 제1 예측 이미 지 정보를 제2 스테이지와 연관된 제2 U-Net에 적용하여 제2 예측 이미지 정보를 생성할 수 있다. 예를 들어, 제2 예측 이미지 정보는 이미 구분된 하나 이상의 인체조직으로부터 하나 이상의 인공 보형물을 구 분하기 위한 제2 구분 정보를 포함할 수 있다. 한편, 업생플링된 제1 예측 이미지 정보 상에서 S420 단계에서 미리 획득된 외부 외곽선 정보(예로, 도 5의 500)에 따라 복수의 크롭핑된 영역이 정의될 수 있다. 즉, 복수의 크롭핑된 영역에 상응하는 이미지 정보가 제2 스테이지와 연관된 제2 U-Net의 입력으로 적용될 수 있음은 이해될 것이다. S450 단계에서, 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치(예로, 도 3의 300)는 제2 예측 이미지 정보를 기반으로 환부와 연관된 하나 이상의 인체조직 및 하나 이상의 인공 보형물을 표현하는 3D 이미지 정보 를 생성할 수 있다. 본 일 실시 예에 따르면, 환자의 환부와 연관된 복수의 인체조직의 형상 뿐만 아니라 기 삽입된 인공 보형물의 형상 및 물성을 딥리닝 기술을 이용하여 보다 높은 정확도로 미리 파악할 수 있으므로, 성형수술계획 혹은 재건 수술계획의 사전 수립 시 환자와 의사 간에 원활한 의사소통이 가능해져 보다 효과적이고 정확한 성형수술이 수 행될 수 있음은 이해될 것이다. 도 5는 본 일 실시 예에 따른 제1 전처리 작업을 설명하기 위한 예시도이다. 도 1 내지 도 5를 참조하면, 도 5의 (a)와 같은 의료영상 이미지로부터 전처리 모듈(예로, 도 3의 320)에 의해 도 5의 (b)의 부분 전처리 작업을 거친 후 도 5의 (c)와 같은 환부의 외부 외곽선(exterior contour, 500)이 추출될 수 있다. 이 경우, 외부 외곽선은 다수의 의료 영상 이미지 각각으로부터 연속적으로 추출될 수 있다. 예를 들어, 다수의 의료 영상 이미지 각각으로부터 연속적으로 추출된 외부 외곽선은 얼굴 전체를 분할하 는 방식이 아닌 얼굴 형태를 이루는 스킨(skin) 영역을 먼저 추출하는데 사용될 수 있음은 이해될 것이다. 도 6은 본 일 실시 예에 따른 제2 전처리 작업을 설명하기 위한 예시도이다. 도 1 내지 도 6을 참조하면, 제2 전처리 작업은 앞서 서술된 제1 전처리 작업에 이어서 수행되거나 단독으로 수 행될 수도 있다. 구체적으로, 다수의 의료영상 이미지에 상응하는 도 6의(a)에 대하여 전처리 모듈(예로, 도 3의 320)에 의해 잡 음 제거 필터링 동작이 수행되면 노이즈가 제거된 3D 이미지 정보가 획득될 수 있다. 이 경우, 도 6의(b)는 노이즈가 제거된 3D 이미지 정보로부터 획득된 2D 의료 영상 이미지로 이해될 수 있다. 도 7은 본 일 실시 예에 따른 U-Net Cascade의 구조를 설명하기 위한 예시도이다. 기존 CT 장치(혹은 MRI 장치)에 의해 촬영된 환자의 환부를 3차원으로 구현하기 위한 3D 환부 데이터는 2D 기반 의 UNet에 바로 적용할 수 없다. 다시 말해, 기존 UNet에 적용 가능한 2D 기반의 다수의 의료영상 이미지는 기존 CT 장치(혹은 MRI 장치)에 의해 촬영된 환부를 3차원으로 구현하기 위한 3D 환부 데이터를 미리 정해진 방식으로 슬라이스함으로써 획득될 수 있다. 기존 이미지 프로세스와 같이 3D 환부 데이터로부터 슬라이스된 2D 기반의 다수의 의료영상 이미지를 UNet에 적 용하는 방식으로는, 기존 CT 장치(혹은 MRI 장치)에 의해 촬영된 3D 환부 데이터를 온전히 활용하기 어렵다는 측면에서 한계가 존재하였다. 이러한 한계를 극복하기 위하여, 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치는 3D 환부 데이터를 그대로 사용하는 방식으로 구현될 수 있다.한편, 본 명세서에서 의료영상 분석 모듈(도 3의 330)에 적용되는 nnUnet 모델은 도 7과 같이 복수의 UNet(1st U-Net, 2nd U-Net)이 케스케이드(cascade)된 복수의 스테이지로 구현될 수 있다. 예를 들어, 의료영상 분석 모듈(도 3의 330)은 제1 스테이지에서 3D 환부 데이터에 대하여 미리 설정된 다 운샘플링을 수행하여 다운샘플링된 3D 환부 데이터를 생성할 수 있다. 예를 들어, 다운 샘플링된 3D 환부 데이터가 제1 U-Net(1st U-Net)에 적용될 때, 제1 예측 이미지 정보 가 생성될 수 있다. 이어, 의료영상 분석 모듈(도 3의 330)은 제1 스테이지에서 제1 예측 이미지 정보에 대하여 미리 설정된 업샘플링을 수행할 수 있다. 이 경우, 업샘플링된 제1 예측 이미지 정보 상에서 미리 획득된 외부 외곽선 정보(예로, 도 5의 500)에 따 라 복수의 크롭핑된 영역이 정의될 수 있다. 즉, 복수의 크롭핑된 영역에 상응하는 이미지 정보는 제2 스테이지와 연관된 제2 U-Net(2nd U-Net)의 입력 으로 적용될 수 있다. 예를 들어, 복수의 크롭핑된 영역에 상응하는 이미지 정보가 제2 U-Net(2nd U-Net)에 적용될 때, 제2 예측 이미지 정보가 생성될 수 있다. 본 일 실시 예에 따르면, 상대적으로 데이터의 크기가 큰 3D 환부 데이터를 그대로 처리하기 위하여, 2개의 U- Net 케스케이드된 구조가 nnUnet 모델에 적용됨은 이해될 것이다. 도 8은 본 일 실시 예에 따른 인공지능 지도학습 과정을 설명하기 위한 도면이다. 도 1 내지 도 8을 참조하면, 본 일 실시 예에 따른 의료영상 분석 모듈(도 3의 330)의 딥러닝 학습모델을 구축 하기 위하여는 인공지능 지도학습 과정이 수행될 수 있다. 예를 들어, 인공지능 지도학습 과정을 위하여, 학습 이미지와 라벨 정보를 로드하는 것은 입력과 타겟 값(즉, 정답)을 주고 학습을 진행하기 위한 것으로 이해될 수 있다. 이 경우, 예측값과 타겟 값에 대한 차이는 손실(loss)로 정의될 수 있다. 이 경우, 손실(loss)는 인공지능 지도 학습 과정을 진행하면서 점차적으로 줄어들도록 구현될 수 있다. 한편, 손실(loss)은 회귀에 대한 것이 아닌 분류(classification)에 관한 것으로 이해될 수 있다. 만일 손실 (loss)이 최소가 될 때 의료영상 분석 모듈(도 3의 330)을 위한 최적의 파라미터 정보가 획득될 수 있다. 도 9는 본 일 실시 예에 따른 학습 데이터의 데이터 증대를 설명하기 위한 예시도이다. 도 1 내지 도 9를 참조하면, 인공지능 지도학습 과정을 위한 학습 데이터는 도 9의 (a) 내지 도 9의 (d)와 같은 원본 데이터의 변형을 통해 임의로 생성하여 초기 학습 데이터를 일정한 수준으로 확보할 수 있다. 도 10은 예시적인 실시예에서 사용되기에 적합한 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하기 위 한 블록도이다. 도 1 내지 도 10을 참조하면, 도시된 실시예에서, 각 컴포넌트들은 이하에 기술된 것 이외에 상이한 기능 및 능 력을 가질 수 있고, 이하에 기술되지 것 이외에도 추가적인 컴포넌트를 포함할 수 있다. 도시된 컴퓨팅 환경은 컴퓨팅 장치를 포함한다. 일 실시예에서, 컴퓨팅 장치는 본 명세서에서 언급 되는 딥러닝 기반 성형수술 가이드 장치(예로, 도 3의 300)와 상응할 수 있다. 컴퓨팅 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함한다. 프로세서는 컴퓨팅 장치로 하여금 앞서 언급된 예시적인 실시예에 따라 동작하도록 할 수 있 다. 예컨대, 프로세서는 컴퓨터 판독 가능 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있다. 상기 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터 실행 가능 명령어는 프로세서에 의해 실행되는 경우 컴퓨팅 장치로 하여금 예시적인 실시예에 따른 동작들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다 른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능 저장 매체에 저장된 프로그램은 프로 세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시예에서, 컴퓨터 판독 가능 저장 매체는 메모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이상의 자기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 장치에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형 태의 저장 매체, 또는 이들의 적합한 조합일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능 저장 매체를 포함하여 컴퓨팅 장치의 다른 다양한 컴 포넌트들을 상호 연결한다. 컴퓨팅 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인터 페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 네트워 크 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치는 입출력 인터페이스를 통해 컴퓨팅 장치의 다른 컴포넌트들에 연결될 수 있다. 예시 적인 입출력 장치는 포인팅 장치(마우스 또는 트랙패드 등), 키보드, 터치 입력 장치(터치패드 또는 터치스 크린 등), 음성 또는 소리 입력 장치, 다양한 종류의 센서 장치 및/또는 촬영 장치와 같은 입력 장치, 및/또는 디스플레이 장치, 프린터, 스피커 및/또는 네트워크 카드와 같은 출력 장치를 포함할 수 있다. 예시적인 입출력 장치는 컴퓨팅 장치를 구성하는 일 컴포넌트로서 컴퓨팅 장치의 내부에 포함될 수 도 있고, 컴퓨팅 장치와는 구별되는 별개의 장치로 미리 확립된 통7신 프로토콜을 기반으로 맞춤형 보형물 추천 장치(예로, 도 3의 300)와 연결될 수도 있다."}
{"patent_id": "10-2023-0077438", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다. 본 명세서의 상세한 설명에서는 구체적인 실시 예에 관하여 설명하였으나, 본 명세서의 범위에서 벗어나지 않는 한도 내에서 여러 가지 변형이 가능하다. 그러므로, 본 명세서의 범위는 상술한 실시 예에 국한되어 정해져서는 안되며, 후술하는 특허청구범위 뿐만 아니라 이 발명의 특허청구범위와 균등한 것들에 의해 정해져야 한다."}
{"patent_id": "10-2023-0077438", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 일 실시 예에 따른 제1 3D 이미지 정보를 나타내는 예시도이다. 도 2는 본 일 실시 예에 따른 제2 3D 이미지 정보를 나타내는 예시도이다. 도 3은 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치를 위한 블록도이다. 도 4는 본 일 실시 예에 따른 딥러닝 기반 성형수술 가이드 장치의 동작 방법을 나타내는 순서도이다. 도 5는 본 일 실시 예에 따른 제1 전처리 작업을 설명하기 위한 예시도이다. 도 6은 본 일 실시 예에 따른 제2 전처리 작업을 설명하기 위한 예시도이다. 도 7은 본 일 실시 예에 따른 U-Net Cascade의 구조를 설명하기 위한 예시도이다. 도 8은 본 일 실시 예에 따른 인공지능 지도학습 과정을 설명하기 위한 도면이다. 도 9는 본 일 실시 예에 따른 학습 데이터의 데이터 증대를 설명하기 위한 예시도이다. 도 10는 예시적인 실시예에서 사용되기에 적합한 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하기 위 한 블록도이다."}
