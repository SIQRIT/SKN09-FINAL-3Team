{"patent_id": "10-2022-0183617", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0021675", "출원번호": "10-2022-0183617", "발명의 명칭": "자율주행차량 탑재형 인공지능 음원-비전 변환처리방법", "출원인": "와이에스모빌리티㈜", "발명자": "유기혁"}}
{"patent_id": "10-2022-0183617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "차량에 설치된 주변 음향센서를 통해 음원으로부터 발생한 음향데이터를 전달받는 음향데이터 수집 단계;상기 수집된 음향데이터를 시각데이터로 변환하는 시각데이터화단계; 및인공신경망 구조의 인공지능 모델 딥러닝을 통해 학습된 인공지능 알고리즘을 활용하여 상기 시각데이터를 분석하여 상기 음원의 정보를 검출하는 음원탐지단계;를 포함하는 자율주행차량 탑재형 인공지능 음원-비전변환 처리방법."}
{"patent_id": "10-2022-0183617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 음원의 정보는 음량, 방향, 위치, 거리, 높이, 방위각 및 종류로 구성되는 군에서 선택되는 적어도 하나인자율주행차량 탑재형 인공지능 음원-비전변환 처리방법."}
{"patent_id": "10-2022-0183617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 음향데이터 수집단계에서 상기 음향데이터는 상기 차량에 4개소 이상으로 구비된 음향센서로부터수집되며, 상기 음향센서들의 위치는 서로 대칭이고, 높이는 서로 다르게 상기 차량에 부착된 자율주행차량 탑재형 인공지능 음원-비전변환 처리방법."}
{"patent_id": "10-2022-0183617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 시각데이터화단계에서 상기 시각데이터는 멜 스펙트로그램(Mel Spectrogram)인 자율주행차량 탑재형 인공지능 음원-비전변환 처리방법."}
{"patent_id": "10-2022-0183617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 음향데이터는 숏타임푸리에 변환(Short time Fourier transform)을 통해 파워스펙트럼(Power-spectrum)로변환된 후 스펙트로그램으로(Spectrogram)으로 변환하고, 다시 멜스케일(Mel scale)로 매핑되어 멜 스펙트로그램(Mel Spectrogram)으로 전처리되는 자율주행차량 탑재형 인공지능 음원-비전변환 처리방법."}
{"patent_id": "10-2022-0183617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 인공지능 모델은 MLP 모델을 활용한 자율주행차량 탑재형 인공지능 음원-비전변환 처리방법."}
{"patent_id": "10-2022-0183617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,공개특허 10-2024-0021675-3-상기 딥러닝은 상기 수집된 음향데이터를 시각데이터로 전처리하여 이루어진 자율주행차량 탑재형 인공지능 음원-비전변환 처리방법."}
{"patent_id": "10-2022-0183617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 객체탐지단계후에 상기 음원의 정보에 따라 상기 음원을 시각화하여 디스플레이하는 표시단계를 더 포함하는 자율주행차량 탑재형 인공지능 음원-비전변환 처리방법."}
{"patent_id": "10-2022-0183617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 인공지능 모델에서 활성함수로 렐루함수(ReLu function)가 사용되고, 마지막 출력활성함수는 소프트맥스(softmax)가 사용된 자율주행차량 탑재형 인공지능 음원-비전변환 처리방법."}
{"patent_id": "10-2022-0183617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 인공지능 모델의 가중치를 최적화하기 위한 경사하강법의 손실함수는 바이너리 크로스-엔트로피가 사용된자율주행차량 탑재형 인공지능 음원-비전변환 처리방법."}
{"patent_id": "10-2022-0183617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "차량에 설치된 주변 음향센서를 통해 음원으로부터 발생한 음향데이터를 전달받는 음향데이터 음향센서;상기 음향센서로부터 수집된 음향데이터를 시각데이터화하는 시각데이터변환부; 및 인공신경망 구조의 인공지능 모델 딥러닝을 통해 학습된 인공지능 알고리즘을 활용하여 상기 시각데이터를 분석하여 상기 음원의 정보를 검출하는 음원탐지부;를 포함하는 자율주행차량 탑재형 인공지능 음원-비전변환 처리기."}
{"patent_id": "10-2022-0183617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 변환처리기는 상기 음원의 정보에 따라 상기 음원을 시각화하여 디스플레이하는 표시부를 더 포함하는 자율주행차량 탑재형 스마트 음원-비전 변환처리기."}
{"patent_id": "10-2022-0183617", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따른 자율주행차량 탑재형 스마트 음원-비전변환 처리방법은, 차량에 설치된 주변 음향센서를 통해 음원으로부터 발생한 음향데이터를 전달받는 음향데이터 수집 단계; 상기 수집된 음향데이터를 시각데이터로 변환하는 시각데이터화단계; 및 인공신경망 구조의 인공지능 모델 딥러닝을 통해 학습된 인공지능 알고리즘을 활용하여 상기 시각데이터를 분석 하여 상기 음원의 정보를 검출하는 음원탐지단계;를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0183617", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 자율주행차량 탑재형 스마트 음원-비전 변환처리기에 관한 것이다."}
{"patent_id": "10-2022-0183617", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기존 자율주행차량 차량 주변환경 인지 기술은, 라이다, 레이더, 카메라, 음파센서 등을 활용하여 주변 물체 이 미지, 물체와의 거리 등의 주변 환경을 판단하는 기술이 있다. 그러나, 악천후 등의 외부조건에 의해 센서 획득 정보의 신뢰도가 떨어지는 문제가 있다. 라이더를 이용하는 경우, 장애물은 크게 이동장애물과 고정 장애물로 분류하나, 고정 장애물과 달리 이동 장애 물은 움직이는 방향 그리고 도로의 형태에 따라서 그 속도를 추정하기가 어렵다. 따라서 이동 장애물이 현재 차 량과 같은 경로를 가고 있다고 가정하여 거리 및 속도를 추정한다. 레이더를 이용하는 경우 탐색 거리가 증가하게 되면 전자파 신호의 강도가 급격히 약화하여 고이득의 레이더가 필수이다. 안테나가 고이득 방사특성을 갖기 위해서는 방사체가 주기적으로 놓인 배열구조 형식으로 이루어야하 나, 배열 안테나는 많은 요소 방사체들을 가질 때 레이더의 물리적 크기가 커지므로 외관의 디자인과 장착물의 최소화라는 상업적 목적에 적용이 어렵다. 기존의 고전적인 영상처리에서는 영상 내에서 ‘특징점(Feature point)’을 추출한 뒤 분류하는 연산을 수행하 였기 때문에, 환경을 인지하기 위해 주의 깊게 봐야 할 특징점들을 선별하는 것에 큰 어려움이 있었으나, 컨볼 루션 신경망은 학습을 거듭함으로써 영상 내에서 주의 깊게 봐야 하는 점들을 추출한 특징 맵(feature map)을 적절하게 생성하고 있으나, 심층 컨볼루션 신경망을 학습하기 위해서는 많은 데이터 및 고성능 병렬 컴퓨팅이 가능한 장치가 요구된다. 자율주행자동차에 마이크를 부착하여 라이더, 레이더, 카메라 등에서 획득되는 시각적 정보만이 아닌 청각적 정 보를 획득하여 주변 환경을 인지한다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 제10-2014060330호"}
{"patent_id": "10-2022-0183617", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 시스템은 자율주행 차량 탑재형 음향 센서의 음원 정보를 AI 비전 데이터로 처리하기 위한 음원-비전 변환 처리방법 및 장치를 제공하는 것을 목적으로 한다. 본 발명에서는 기존 비전 및 RF 위주의 자율주행차량 센서의 한계점을 극복하고자 음원-비전 변환 처리기를 기 반으로 주변 음원을 분석하는 시스템을 제시한다."}
{"patent_id": "10-2022-0183617", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일측면에 따른 자율주행차량 탑재형 인공지능 음원-비전변환 처리방법은, 차량에 설치된 주변 음향센서를 통해 음원으로부터 발생한 음향데이터를 전달받는 음향데이터 수집 단계; 상기 수집된 음향데이터를 시각데이터로 변환하는 시각데이터화단계; 및 인공신경망 구조의 인공지능 모델 딥러닝을 통해 학습된 인공지능 알고리즘을 활용하여 상기 시각데이터를 분석 하여 상기 음원의 정보를 검출하는 음원탐지단계;를 포함하는 것을 특징으로 한다. 이 때, 상기 음원의 정보는 음량, 방향, 위치, 높이, 방위각, 거리 및 종류로 구성되는 군에서 선택되는 적어도 하나이다. 이 때, 상기 음향데이터 수집단계에서 상기 음향데이터는 상기 차량에 4개소 이상으로 구비된 음향센서로부터 수집되며, 상기 음향센서들의 위치는 서로 대칭이고, 높이는 서로 다르게 상기 차량에 부착되는 것이 바람직하 다. 또한, 상기 시각데이터화단계에서 상기 시각데이터는 멜 스펙트로그램(Mel Spectrogram)인 것이 바람직하다. 또한, 상기 음향데이터는 숏타임푸리에 변환(Short time Fourier transform)을 통해 파워스펙트럼(Power- spectrum)로 변환된 후 스펙트로그램으로(Spectrogram)으로 변환하고, 다시 멜스케일(Mel scale)로 매핑되어 멜 스펙트로그램(Mel Spectrogram)으로 전처리되는 것이 바람직하다. 또한, 상기 인공지능 모델은 MLP 모델을 활용한 것이 바람직하다. 또한, 상기 딥러닝은 상기 수집된 음향데이터를 시각데이터로 전처리하여 이루어진 것이 바람직하다. 또한, 상기 객체탐지단계후에 상기 음원의 정보에 따라 상기 음원을 시각화하여 디스플레이하는 표시단계를 더 포함하는 것이 바람직하다. 또한, 상기 인공지능 모델에서 활성함수로 렐루함수(ReLu function)가 사용되고, 마지막 출력활성함수는 소프트 맥스(softmax)가 사용되는 것이 바람직하다. 또한, 상기 인공지능 모델의 가중치를 최적화하기 위한 경사하강법의 손실함수는 바이너리 크로스-엔트로피가 사용되는 것이 바람직하다. 본 발명의 다른 측면은, 차량에 설치된 주변 음향센서를 통해 음원으로부터 발생한 음향데이터를 전달받는 음향데이터 음향센서; 상기 음향센서로부터 수집된 음향데이터를 시각데이터화하는 시각데이터변환부; 및 인공신경망 구조의 인공지능 모델 딥러닝을 통해 학습된 인공지능 알고리즘을 활용하여 상기 시각데이터를 분석 하여 상기 음원의 정보를 검출하는 음원탐지부;를 포함하는 자율주행차량 탑재형 인공지능 음원-비전변환 처리 기를 제공한다. 이 때, 상기 변환처리기는 상기 음원의 정보에 따라 상기 음원을 시각화하여 디스플레이하는 표시부를 더 포함 하는 것이 바람직하다."}
{"patent_id": "10-2022-0183617", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "현재 개발된 자율주행차량 탑재형 음향 센서의 음원정보를 AI 비전으로 처리하기 위한 음원-비전 변환 처리기술 은 4차 산업혁명의 핵심 산업인 자율주행 자동차산업과 인공지능 산업에 포함되어 높은 잠재력을 지닌다. 자율주행 자동차 산업 분야는 자율주행기술의 안전 기술이 요구되며 높은 시장성을 지니고 있으며 본 시스템을 통해 개발된 모듈을 탑재한 차량의 생산으로 인해 기존의 방식에 비해 높은 차량 안정성을 확보 가능하다."}
{"patent_id": "10-2022-0183617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고, 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하 고, 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니고, 본 발명의 기술 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 식으로 이해되어야 하고, 여러 가지 다른 형태로 변형될 수 있으며, 본 발명의 범위가 하기 실시예에 한정되는 것은 아니다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 실시예를 상세히 설명하며, 도면 부호에 관계없이 동일하거나 대응하는 구성요소에 대해서는 동일한 참조 번호를 부여하고, 이에 대해 중복되는 설명을 생략하기로 한다. 본 발명은 다양한 변경을 가할 수 있고, 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하 고, 상세하게 설명하고자 한다. 그러나 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니고, 본 발명의 기술사상 및 기술범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 식으로 이해되어야 하고, 여러 가지 다른 형태로 변형될 수 있으며, 본 발명의 범위가 하기 실시예에 한정되는 것은 아니다. 또한, 본 발 명에 사용된 주요 외래어에 대한 정의를 다음과 같이 표현하여 이해를 명확히 하고자 한다. 본 발명의 일측면에 따른 스마트 음원-비전변환 처리방법은, 음향데이터 수집단계, 시각데이터화단계, 및 객체 탐지단계를 포함한다. 음향데이터 수집단계는 차량에 설치된 주변 음향데이터 음향센서(mic)로 음향데이터를 수집하는 단계이다. 음향 데이터 수집을 위해서 수음하는 음향센서 사이의 거리를 최대한 짧고 음원의 위치가 멀다고 가정하고 수음되는 시간을 통해 거리 및 방향을 계산하여 음원의 위치를 추적한다. 도 1은 음원의 추적원리를 설명하는 설명도이다. 일반적으로 음향센서가 2개소 이상으로 구비되면, 각 음향센서 에 수음되는 시간을 통해 거리 및 방향을 계산할 수 있다. 음향센서 기반으로 하는 위치 추적을 위해서는 음향센서와 소리 발생지점과의 상대적인 거리와 측정된 상대적인 거리를 이용한 음향센서 소리 발생 위치는 다음과 같이 계산될 수 있다. [식 1] . 식 1에서 , 는 각각 음향센서 1, 2로부터 수신된 신호, s는 발생한 소리, , 는 반향파와 마이크의 임펄 스 반응, , 는 각 마이크로폰 채널의 잡음, 는 두 마이크로폰 간의 소리가 도달하는 상대적인 시간차를 나 타낸다. 식 1로부터 두 음향센서로부터 도달하는 소리의 시간차는 음향센서 간에 수집된 신호 간의 상관함수를 정의하게 되고 함수를 기반으로 최적의 위치를 구한다. 도 2는 삼각형 기반 음원 추적 시스템의 원리를 도시한다. 본 발명에서 기존 2차원 공간 음원 추적시스템과 달 리 CNN 및 DNN 알고리즘 기반 음향 데이터로 다양한 대처 가능한 기술로써 3차원 공간에서 음원 방향성을 추적 한다. 삼각형 기반 음원 추적 시스템은 각 음향센서까지의 거리와 각도를 이용하여 중앙의 점과 음원 사이의 각 도 및 방향을 계산한다. 2개의 음향센서 활용 시 2차원 공간의 좌우 방향만 추적 가능하고 3차원 공간의 음원 방향성 추적을 위해 최소 3개 이상의 음향센서가 필요하다. 따라서, 본 발명에서 음향센서는 차량에 4개소 이상으로 구비되는 것이 바람직하며, 음향센서들의 위치는 서로 대칭이고, 높이는 서로 다르게 부착되는 것이 바람직하다. 도 3은 다중음원인식을 위한 다중 음향센서 배치 예시도이다. 이에 따르면, 음향센서는 차량의 좌측 2개 및 우 측 2개에 구비되며, 높이는 4개 모두 다르게 설치되어 있다. 이 때, 음향센서는 선택에 따라 차량 내·외부에 배치를 할 수 있다. 도 4는 본 발명에 따른 정사면체 기반 음원 추적을 위한 시스템의 기본 원리를 도시한다. 이에 따르면, 4개의 음향센서가 이루는 4개의 삼각형 면을 통한 3차원 방향각과 고도각을 구해 4개의 후보 값에서 평균을 계산하여 최종방향 결정한다. 이 때, 정사면체 기반 음원 추적 기술을 보완한 비히클 헤드 모델(Vehicle head model) 방식에 의해 생성된 6쌍 의 AITD(Advanced Inter-aural Time Difference), Advanced ILD로 음원의 위치와 음원까지의 거리 연산, 오차 보정을 통해 검출 정확도를 향상시킬 수 있다. 이로써, 기존 차량 하드웨어가 지닐 수 있는 감지의 사각 영역을 제거하여 더욱 우수한 측정 데이터를 얻을 수 있다. 도 5는 본 발명에 따른 근거리 단일 차량 주변 음원 반응도 확인을 위해 실시간적으로 주변 환경을 인지하는 실 험 장치와 음원 반응 모니터링 소프트웨어의 구현예이다. 모니터링 UI에서 CPU의 사용량, 온도뿐 아니라 음원으 로부터 확인될 수 있는 높이(elevation), 방위각(azimuth) 등의 정보를 시각화할 수 있다. 시각데이터화단계는 수집된 음향데이터를 시각데이터화하는 시각데이터화단계이다. 본 발명에서는 멜 스펙트로 그램(Mel Spectrogram)으로 음향데이터를 시각화한다. 멜 스펙트로그램(Mel Spectrogram)은 시간상 진폭 축의 변화를 시각적으로 볼 수 있는 파형(waveform)과주파수 상 진폭 축의 변화를 시각적으로 볼 수 있는 스펙트럼 (spectrum)의 특징이 모두 결합된 구조이다. 멜 스펙트로그램(Mel Spectrogram)은 음향 신호가 시간 축에서 가지는 진폭과 주파수 대역의 정보를 특별한 처 리 없이 수신하여 1차원적으로 도출하고, 멜 스펙트로그램(Mel Spectrogram)을 통해 이미지로 변환시킨 음원 데 이터는 ITD(Inter-aural Time Difference), ILD(Inter-aural Level Difference)를 통한 음원 위치 인식을 수행 하는 인공지능 알고리즘을 통하여 분석하기 좋은 데이터 형태가 된다. 수신하는 음향데이터에 따라 도출된 멜 스펙트로그램(Mel Spectrogram)을 분석하면 음원 및 주변의 상황에 대한 정보를 시각화하여 도출 가능하다. 음원의 정보는 음량, 방향, 위치, 높이, 방위각, 거리 및 종류로 구성되는 군에서 선택되는 적어도 하나일 수 있다. 즉, 입력으로 들어오는 음향데이터를 멜 스펙트로그램(Mel Spectrogram)기반 이미지로 변환함으로써 비전 데이터 기반으로 위치 확인을 실시한다. 디지털로 바꾼 음향데이터는 차원이 크고, 여러 주파수가 결합 되어 있는 형태이기에 raw audio에서는 머신 러 닝을 통해 특징(feature)를 뽑아내기 어렵다. 이에, 특징(feature)를 적절하게 추출하기 위하여 음향신호를 푸 리에 변환을 이용하여 시간(time) 축의 신호에서 주파수(frequency) 축의 신호로 변환시키고 spectrogpram으로 변환시키는 전치리 과정을 진행한다. 도 6은 본 발명에서 음향신호를 멜 스펙트로그램(Mel Spectrogram)의 디지털방식으로 변환하기 위한 알고리즘을 설명한다. 먼저, 음향신호를 정해진 길이로 나누고(framing) 각각을 윈도우잉(windowing)을 적용하여 경계를 스 무딩한다. 이 때 Hann 함수 등 다양한 종류의 윈도우잉(windowing) 기법을 사용한다. 다음으로 윈도우잉(windowing)과정을 거친 신호를 주파수 영역에서의 신호 처리를 위해 푸리에 변환을 통해 시 간 영역에서 주파수 영역으로 변환한다. 이 때, 프레임마다 푸리에 변환을 실시하는 숏타임푸리에 변환(Shorttime Fourier transform)(STFT)이 적용되어 스펙트럼을 생성한다. 다음으로 주파수 영역대별 데이터 분석을 위해 멜 필터 뱅크(mel filter bank)를 적용하여 멜 스펙트로그램(Mel Spectrogram)을 출력한다. 아래의 그림은 총 13개의 필터로 구성된 멜 필터 뱅크(mel filter bank)를 보여주며 필터의 개수는 실험을 통해 조정하는 수치이다. 도 8은 총 13개의 필터로 구성된 멜 필터 뱅크(mel filter bank)를 보여주며 필터의 개수는 실험을 통해 조정하는 수치이다. 즉, 도 7과 같이 본 발명에서 음성신호는 숏타임푸리에 변환(Short time Fourier transform)(STFT)을 통해 변 환된 신호를 파워스펙트럼(Power-spectrum)을 구한 다음, 도 8과 같이 데시벨 변환 공식을 취해 Log-spectrum을 구하고 이를 세로로 세워 Frame마다 옆으로 쌓아서 스펙트로그램으로(Spectrogram)으로 변환되고, Mel scale로 매핑하여 멜 스펙트로그램(Mel Spectrogram)으로 변환한다. 멜 스펙트로그램(Mel Spectrogram)로 이미지로 변환된 음향데이터는 ITD(Inter-aural Time Difference), ILD(Inter-aural Level Difference)를 통한 음원 위치 인식을 수행하는 인공지능 알고리즘을 통하여 분석하기 좋은 데이터 형태가 된다. 또한, 단일 음원을 Mel Spectrogram으로 시각화하여 시각데이터로 추출할 수 있다. 도 9는 본 발명에 방법에 따라 사이렌등 음향데이터를 시각데이터로 변환하여 매칭율을 검토한 결과로서 100%매 칭 성공율을 보였다. 이 때, 음원 2개를 활용하여 단일음원데이터를 40회 이상 시각 매칭 처리를 진행하고, 120 개의 음원데이터를 변환하여 시각 데이터를 도출하였다. 음원-시각 매칭 처리 후 90%이상(108개 이상)시각 데이 터 도출개수에 따라 성공으로 판단하였다. 객체탐지단계는 시각데이터를 인공지능 알고리즘을 통해 분석하여 객체를 감지하는 단계로서, 차량 주변 복수 음원 특징 데이터의 AI 기반 심층 인공신경망 구조의 인공지능 모델을 활용하여 변환된 멜 스펙트로그램(Mel Spectrogram) 이미지를 구역별로 분류하고 각 구역의 특징을 검출하는 단계이다. 각기 다른 특징을 검출하는 수많은 단계를 통해 특정 패턴에 대해 학습을 진행하고 학습을 완료한 심층 인공신 경망 모델을 활용하여 실제 데이터의 분석 및 결과 도출한다. 본 발명에서 인공지는 기반 학습기술은 MLP(multi-layer pecetron), RNN(Recurrent neural networks) 등 다양 한 유형의 네트워크가 사용될 수 있으나, MLP 모델을 활용하여 mel-spectrogram으로 변환된 차량 주변 복수 음 원 데이터를 학습시키는 것이 바람직하다. 앞서서 언급되었던 음향센서들로부터 얻은 음성데이터들은 멜 스펙 트로그램(Mel Spectrogram)시각데이터로 변환되어 머신러닝 모델의 입력으로 들어온다. MLP는 비선형적인 결정 기준을 설정하기 위해 심층 인공신경망 모델에서 대표적으로 사용되는 모델이고 여러 perceptron을 연결한 형태로 존재하여 비선형적인 입력들을 분석하는데, MLP는 입력층에서 출력층까지 여러 연 산을 거쳐 출력을 내는데, 이때 출력은 실제 정답과의 오차가 발생한다. 인공신경망의 목표는 가장 적합한 가중 치를 찾는 것이며, 가장 적합한 가중치는 오차가 가장 낮을 때의 가중치를 뜻한다. 오차를 줄이기 위해서 주로 오차 곡면의 기울기를 가중치에 대해 구한 뒤 기울기를 따라 내려가는 경사 하강법을 사용한다. 경사 하강법은 기울기를 이용하여 가중치를 수정하는 방법으로 기울기를 구하기 위한 식 3은 다음과 같다. [식 3]"}
{"patent_id": "10-2022-0183617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "식 4는 sigmoid 함수의 미분값을 보여주고 식 3과 식 4를 이용하여 가중치를 조절하는 식은 다음과 같다. [식 4]"}
{"patent_id": "10-2022-0183617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "[식 5]"}
{"patent_id": "10-2022-0183617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "η는 learning rate로 적절한 학습을 위해 조정하는 파라미터 중 하나이고 MLP는 식 5에 따라 가중치를 조절한 다. 시각데이터인 이미지는 머신러닝 모델을 통해 end-to-end 방식으로 특징 추출 및 분류가 동시에 수행되게 되며 저장시킨 훈련된 모델을 기반으로 실제 이미지를 분류하는 동작을 수행할 수 있다. 도 10은 본 발명에 따른 인공지능 학습 및 실제 데이터 분석 동작도이다. 활성화함수는 임계값에 따라 출력을 조절하는 능력을 가지고 있으며 역전파 알고리즘 에서 가중치를 학습하는데 중요한 파라미터이다. 활성화함수로는 대중적인 ReLu function이 사용될 수 있으며 ReLu 활성화 함수를 사용하 면 0보다 작은 값은 모두 0으로 없애면서 가중치 함수를 비선형적으로 근사시킬 수 있다. ReLU 함수는 가중합의 크기가 0보다 큰 경우 y=x 함수에 따라 출력하고, 0보다 작은 경우 0을 출력하는 함수로 Sigmoid와 tanh 함수의 기울기 소실 문제를 보완한 활성화 함수이나 입력값이 음수일 경우 출력값과 미분한 값 을 모두 0으로 취급하기 때문에 또 다른 정보가 소실되는 문제가 발생한다. 구현이 단순하고 미분 형태가 쉬워 연산이 빠르다. [식 6]"}
{"patent_id": "10-2022-0183617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "마지막 출력 활성함수로는 분류를 수행하기 위해 softmax 함수가 사용될 수 있으며 softmax 함수 적용 시 모든 출력 노드들의 확률의 합은 1이 된다. Softmax 함수는 다중 출력값을 갖는 함수로써 입력하는 정보를 여러 클래스 중 하나로 분류하는 multi-class classification에 주로 사용된다. 결과를 확률로 해석할 수 있어 가장 높은 확률을 갖는 class로 분류하며 아래 의 수식으로 표현된다. K는 분류하는 클래스의 수, z는 softmax 함수의 입력을 의미한다. 지수함수는 미분이 가 능하고, 입력의 구분을 용이하게 위해 포함되어 있으며 마지막 출력층에서 사용된다. [식 7]"}
{"patent_id": "10-2022-0183617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "인공지능 모델의 학습을 위해 epoch가 설정되며 해당 epoch는 데이터의 수와 유형에 따라 변경될 수 있는 하이 퍼 파라미터로 지정될 수 있다. [식 8] . 모델이 학습되기 위해서는 모델의 가중치를 최적화하기 위해 경사하강법(adient descent)를 진행하게 되며, 경 사하강법을 수행하기 위한 손실 함수로 바이너리 크로스-엔트로피(binary cross-entropy)가 사용될 수 있다. 차량 주변 복수 음원 데이터를 음원-비전 알고리즘을 통해 mel-spectrogram으로 변환한 데이터를 설계한 MLP 모 델에 역전파 알고리즘을 통해 학습시킨다. 도 11은 차량 주변 복수 음원 인지 AI 모델 출력 결과를 예시하고, 도 12는 차량 주변 복수 음원 인지 AI 모델 학습 코드를 도시한다. 한편, 객체탐지단계후에 음원의 정보에 따라 상기 음원을 시각화하여 디스플레이하는 표시단계를 더 포함할 수 있고, 복수 음원의 특징 데이터의 AI 기반 학습 정도를 확인할 수 있다. 이 때, 표시단계에 이용될 수 있는 디 스플레이 표시장치는 LED등을 이용해 제조될 수 있다. 도 13은 표시장치의 일실시예를 도시한다. 본 발명의 다른 측면에 따른 스마트 음원-비전변환 처리기는, 차량에 설치된 주변 음향센서를 통해 음원으로부터 발생한 음향데이터를 전달받는 음향데이터 음향센서와, 상기 음향센서로부터 수집된 음향데이터를 시각데이터화하는 시각데이터변환부, 및 인공신경망 구조의 인공지능 모델 딥러닝을 통해 학습된 인공지능 알고리즘을 활용하여 상기 시각데이터를 분석하여 상기 음원의 정보를 검출하는음원탐지부를 포함하는 것을 특징으로 한다. 상기 변환처리기는 상기 음원의 정보에 따라 상기 음원을 시각화하여 디스플레이하는 표시부를 더 포함할 수 있 다. 이와 같이 본 발명에 대해서 첨부된 도면을 참조하여 설명하였으나, 본 발명의 기술적 사상을 벗어나지 않는 범 위 내에서 다양한 수정 및 변형이 이루어질 수 있음은 물론이다. 그러므로, 본 발명의 범위는 설명된 실시례에 한정되어서는 아니되며, 후술하는 특허 청구범위 뿐만아니라 이러한 특허청구범위와 균등한 것들에 의해 정해져 야 한다."}
