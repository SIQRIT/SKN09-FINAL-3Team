{"patent_id": "10-2023-0069387", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0171453", "출원번호": "10-2023-0069387", "발명의 명칭": "인공지능네트워크를 이용한 아크 리스크 관리 시스템 및 방법", "출원인": "한국에너지기술연구원", "발명자": "성윤동"}}
{"patent_id": "10-2023-0069387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전기장치에 흐르는 전류의 측정값들을 전처리하는 단계;확장 합성곱 신경망을 포함하는 제1계층과, 순환 신경망을 포함하는 제2계층을 포함하는 일 인공지능네트워크에상기 측정값들을 투입하여 상기 전기장치에서의 아크에너지 레벨을 추정하는 단계; 및상기 아크에너지 레벨에 따라 상기 전기장치의 아크리스크를 정량적으로 표시하는 단계를 포함하는 아크 리스크 관리 방법."}
{"patent_id": "10-2023-0069387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 아크리스크를 정략적으로 표시하는 단계에서,상기 아크리스크를 다이얼 게이지의 형태로 실시간으로 표시하는 아크 리스크 관리 방법."}
{"patent_id": "10-2023-0069387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제1계층은 아크에너지에 영향을 미치는 제1요소값에 대한 클래시피케이션(classification)을 위해 학습된다른 일 인공지능네트워크에서 전이(transfer)된 계층인, 아크 리스크 관리 방법."}
{"patent_id": "10-2023-0069387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 순환 신경망은 시계열데이터 분석에 유리한 LSTM(Long Short-Term Memory)을 포함하는 아크 리스크 관리방법."}
{"patent_id": "10-2023-0069387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 순환 신경망은 Transformer 계층을 포함하는 아크 리스크 관리 방법."}
{"patent_id": "10-2023-0069387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 다른 일 인공지능네트워크는 상기 클래시피케이션을 통해 상기 전기장치의 정상상태와 아크상태를 구분하는 아크 리스크 관리 방법."}
{"patent_id": "10-2023-0069387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "전기장치에 흐르는 전류의 측정값들을 전처리하는 전처리부;확장 합성곱 신경망을 포함하는 제1계층과, 순환 신경망을 포함하는 제2계층을 포함하고, 상기 측정값들을 입력으로 하고 상기 전기장치에서의 아크에너지 레벨을 출력으로 하는 인공지능네트워크부; 및상기 아크에너지 레벨에 따라 상기 전기장치의 아크리스크를 정량적으로 표시하는 아크리스크관리부를 포함하는 아크 리스크 관리 시스템."}
{"patent_id": "10-2023-0069387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2024-0171453-3-제7항에 있어서,상기 전처리부는 상기 측정값들을 정규화하되, 상기 측정값들에서 분산정보가 사라지지 않도록 정규화하는 아크리스크 관리 시스템."}
{"patent_id": "10-2023-0069387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 전처리부는 평균차감기법(MSN : mean subtraction normalization)을 통해 상기 측정값들을 정규화하는 아크 리스크 관리 시스템."}
{"patent_id": "10-2023-0069387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 제1계층은 아크에너지에 영향을 미치는 제1요소값에 대한 클래시피케이션(classification)을 위해 학습된다른 일 인공지능네트워크에서 전이(transfer)된 계층인, 아크 리스크 관리 시스템."}
{"patent_id": "10-2023-0069387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,상기 순환 신경망은 시계열데이터 분석에 유리한 LSTM(Long Short-Term Memory)을 포함하는 아크 리스크 관리시스템."}
{"patent_id": "10-2023-0069387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서,상기 일 인공지능네트워크는 잔차 신경망(ResNet : Residual Neural Network) 구조를 가지는 아크 리스크 관리시스템."}
{"patent_id": "10-2023-0069387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서,상기 다른 일 인공지능네트워크는 상기 측정값들을 둘 이상의 전류 레벨로 클래시피케이션하는 아크 리스크 관리 시스템."}
{"patent_id": "10-2023-0069387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제7항에 있어서,상기 아크리스크의 정량적 지표를 게이지 형태로 표시하는 표시부를 더 포함하는 아크 리스크 관리 시스템."}
{"patent_id": "10-2023-0069387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,상기 제1요소값은 전류 레벨이고,상기 제1인공지능네트워크는 아크가 발생한 상태에서 상기 전기장치로 흐르는 전류 레벨을 클래시피케이션하도록 학습된 인공지능네트워크인 아크 리스크 관리 시스템."}
{"patent_id": "10-2023-0069387", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예는, 전기장치에 흐르는 전류의 측정값들을 전처리하는 단계; 확장 합성곱 신경망을 포함하는 제1계층과, 순환 신경망을 포함하는 제2계층을 포함하는 일 인공지능네트워크에 상기 측정값들을 투입하여 상기 전기장치에서의 아크에너지 레벨을 추정하는 단계; 및 상기 아크에너지 레벨에 따라 상기 전기장치의 아크리스크 를 정량적으로 표시하는 단계를 포함하는 아크 리스크 관리 방법을 제공한다."}
{"patent_id": "10-2023-0069387", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 실시예는 아크를 검출하고 전기장치에서의 아크 리스크를 관리하는 기술에 관한 것이다."}
{"patent_id": "10-2023-0069387", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "화석 및 원자력 에너지를 대체하여 기후변화 문제를 해결할 수 있는 차세대 신재생 에너지원에 대한 연구가 활 발히 진행 중이다. 지금까지의 연구는 신재생 에너지원의 보급과 효율 향상, 기존 계통에 연계하기 위한 적용 기술 등을 처리하는 분야에 집중적으로 수행되어 관련기술이 성숙단계에 도달하였다. 특히, 신재생 에너지원 중 에서 태양광 발전시스템(Photovoltaic System)은 기술 수준과 시장 보급이 급속도로 진행되고 있는 분야로써 전 세계의 3%이상인 600GW-피크(peak)를 생산하고 있으며, 태양광 발전시스템의 성장은 늘 예측을 초과해왔다. 최 근에는 이러한 기술적 진보와 더불어 진단/관리 기술에 대한 요구가 점차 증가함에 따라 관련 시장 규모 또한 점진적으로 확장되고 있는 추세이다. 태양광 발전시스템에서의 고장은 인버터 및 컴바이너 등과 같은 전기변환장치에서 주로 발생하며, 특히 서로 다 른 커넥터들이 연계되는 정션박스에서 자주 발생하는 아크가 태양광 발전시스템의 고장유형으로 중요한 문제로 대두되고 있다. 아크는 발생 에너지의 강도에 따라 시스템에 지속적인 손상을 가하기 때문에, 제품의 수명을 단 축시킬 뿐만 아니라 빠르고 정확하게 탐지하지 못할 경우 화재로 인한 산업재해나 인명피해까지 이어질 수 있다. 따라서, 태양광 발전으로 대표되는 신재생 에너지원의 보급이 활발히 이루어진 상황에서 부정확한 아크 검출 오류는 시스템의 수명 단축, 유지보수 비용의 증가 등의 문제를 야기시킬 수 있다. 일반적인 아크는 외부 인자에 의한 전선의 손상과 장기간의 풍화 및 노화, 결선의 문제 등으로 주로 발생되고 있으며, 이러한 아크로 인하여 두 전기선 사이에 고온의 플라즈마가 발생하여 내부적으로 시스템 구성에 지속적 인 손상을 주게 된다. 한편, 회로 유형별 아크 발생 특징을 살펴보면, 먼저, 병렬 회로의 경우, 아크 발생시 큰 전류가 발생하여 퓨즈, 차단기 등 물리적인 보호계전으로 아크 검출과 차단이 비교적 용이하다. 다음으로, 직렬 AC 회로의 경우는 제로 크로싱 지점에서 아크 특징을 찾을 수 있어 비교적 쉽게 검출이 가능하다. 반면, 직렬 DC 회로에서 발생하는 아크의 경우 전류의 영점이 없으며 정상 전류의 패턴과 거의 유사한 특징을 가지고 있다. 특히 노이즈가 많은 상용 인버터의 경우 상대적으로 전류의 리플이 크며, 아크로 인한 전류의 이 상범위가 정상범위 안에 존재하기 때문에 아크 검출이 매우 어려운 상황이다. 또한, 아크가 검출되더라도 아크에너지를 측정하기 어렵기 때문에 아크에 의한 전기장치의 리스크가 어느 정도 인지 평가하기 어려웠다."}
{"patent_id": "10-2023-0069387", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이러한 배경에서, 본 실시예의 목적은, 일 측면에서, 전기장치에서의 아크에너지 레벨을 측정하는 기술을 제공 하는 것이다. 다른 측면에서, 본 실시예의 목적은, 아크에 의한 전기장치의 리스크를 관리하는 기술을 제공하는 것이다."}
{"patent_id": "10-2023-0069387", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 목적을 달성하기 위하여, 일 실시예는, 전기장치에 흐르는 전류의 측정값들을 전처리하는 단계; 확장 합 성곱 신경망을 포함하는 제1계층과, 순환 신경망을 포함하는 제2계층을 포함하는 일 인공지능네트워크에 상기 측정값들을 투입하여 상기 전기장치에서의 아크에너지 레벨을 추정하는 단계; 및 상기 아크에너지 레벨에 따라 상기 전기장치의 아크리스크를 정량적으로 표시하는 단계를 포함하는 아크 리스크 관리 방법을 제공한다. 상기 아크 리스크 관리 방법은, 상기 아크리스크를 정략적으로 표시하는 단계에서, 상기 아크리스크를 다이얼 게이지의 형태로 실시간으로 표시할 수 있다. 상기 제1계층은 아크에너지에 영향을 미치는 제1요소값에 대한 클래시피케이션(classification)을 위해 학습된 다른 일 인공지능네트워크에서 전이(transfer)된 계층일 수 있다. 상기 순환 신경망은 Transformer 계층을 포함할 수 있다. 상기 순환 신경망은 시계열데이터 분석에 유리한 LSTM(Long Short-Term Memory)을 포함할 수 있다. 상기 일 인공지능네트워크는 잔차 신경망(ResNet : Residual Neural Network) 구조를 가질 수 있다. 상기 다른 일 인공지능네트워크는 상기 클래시피케이션을 통해 상기 전기장치의 정상상태와 아크상태를 구분할 수 있다. 다른 실시예는, 전기장치에 흐르는 전류의 측정값들을 전처리하는 전처리부; 확장 합성곱 신경망을 포함하는 제 1계층과, 순환 신경망을 포함하는 제2계층을 포함하고, 상기 측정값들을 입력으로 하고 상기 전기장치에서의 아크에너지 레벨을 출력으로 하는 인공지능네트워크부; 및 상기 아크에너지 레벨에 따라 상기 전기장치의 아크리 스크를 정량적으로 표시하는 아크리스크관리부를 포함하는 아크 리스크 관리 시스템을 제공한다. 상기 전처리부는 상기 측정값들을 정규화하되, 상기 측정값들에서 분산정보가 사라지지 않도록 정규화할 수 있 다. 상기 전처리부는 평균차감기법(MSN : mean subtraction normalization)을 통해 상기 측정값들을 정규화할 수 있다. 상기 제1계층은 아크에너지에 영향을 미치는 제1요소값에 대한 클래시피케이션(classification)을 위해 학습된 다른 일 인공지능네트워크에서 전이(transfer)된 계층일 수 있다. 상기 순환 신경망은 시계열데이터 분석에 유리한 LSTM(Long Short-Term Memory)을 포함할 수 있다. 상기 일 인공지능네트워크는 잔차 신경망(ResNet : Residual Neural Network) 구조를 가질 수 있다. 상기 다른 일 인공지능네트워크는 상기 측정값들을 둘 이상의 전류 레벨로 클래시피케이션할 수 있다. 상기 아크 리스크 관리 시스템은 상기 아크리스크의 정량적 지표를 게이지 형태로 표시하는 표시부를 더 포함할 수 있다. 상기 제1요소값은 전류 레벨이고, 상기 제1인공지능네트워크는 아크가 발생한 상태에서 상기 전기장치로 흐르는 전류 레벨을 클래시피케이션하도록 학습된 인공지능네트워크일 수 있다."}
{"patent_id": "10-2023-0069387", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같이 본 실시예에 의하면, 전기장치에서의 아크에너지 레벨을 보다 정확하게 측정할 수 있다. 그리고, 본 실시예에 의하면, 아크에 의한 전기장치의 리스크를 관리할 수 있게 된다."}
{"patent_id": "10-2023-0069387", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 일부 실시예들을 예시적인 도면을 통해 상세하게 설명한다. 각 도면의 구성요소들에 참조부호 를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명을 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 또한, 본 발명의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본 질이나 차례 또는 순서 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성요소에 \"연결\", \"결합\" 또는 \"접속\" 된다고 기재된 경우, 그 구성 요소는 그 다른 구성요소에 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구 성 요소 사이에 또 다른 구성 요소가 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다. 도 1은 일 실시예에 따른 전력시스템의 구성도이다. 도 1을 참조하면, 전력시스템에는 제1전기장치와 제2전기장치가 포함될 수 있다. 제1전기장치 와 제2전기장치는 도선에 의해 전기적으로 연결될 수 있다. 제1전기장치는 도선으로 전류(i)를 공급할 수 있고, 제2전기장치는 도선으로부터 전류(i)를 공급받을 수 있다. 제1전기장치는 전력변환장치를 포함할 수 있다. 일 예로서, 제1전기장치는 발전장치로서 태양광발전 장치를 포함하고, 태양광발전장치에서 생산된 전력을 변환하여 도선으로 공급하는 전력변환장치를 포함할 수 있다. 다른 예로서, 제1전기장치는 에너지저장장치를 포함하고, 에너지저장장치에 저장된 전력을 변환 하여 도선으로 공급하는 전력변환장치를 포함할 수 있다. 제1전기장치에 포함되는 전력변환장치는 전력반도체를 포함하고 있으면서 전력반도체를 이용하여 전력을 챠핑(chopping)하는 방식으로 전력을 변환할 수 있다. 예를 들어, 전력변환장치는 벅컨버터, 부스트컨버터, 플 라이백컨버터 등일 수 있다. 제1전기장치에 포함되는 전력변환장치는 일정한 제어주파수를 가지거나 일정 범위 이내의 제어주파수를 가 질 수 있다. 여기서, 제어주파수는 전력을 챠핑하는 주기를 결정할 수 있다. 그리고, 이러한 전력에 대한 주기 적인 챠핑에 의해 제1전기장치, 그리고, 도선에 노이즈가 발생할 수 있다. 제2전기장치는 전력변환장치를 포함할 수 있다. 전력변환장치는 제1전기장치에 포함될 수도 있고, 제 2전기장치에 포함될 수도 있다. 그리고, 전력변환장치는 제1전기장치와 제2전기장치에 모두 포 함될 수도 있다. 제1전기장치에는 전력을 공급하는 장치(예를 들어, 태양광발전장치, 에너지저장장치 등)가 포함되고, 제2 전기장치에는 제1전기장치에서 공급되는 전력을 변환하는 전력변환장치가 포함될 수 있다. 제2전기장치에 포함되는 전력변환장치는 전력반도체를 포함하고 있으면서 전력반도체를 이용하여 전력을 챠핑(chopping)하는 방식으로 전력을 변환할 수 있다. 예를 들어, 전력변환장치는 벅컨버터, 부스트컨버터, 플 라이백컨버터 등일 수 있다. 제2전기장치에 포함되는 전력변환장치는 일정한 제어주파수를 가지거나 일정 범위 이내의 제어주파수를 가 질 수 있다. 여기서, 제어주파수는 전력을 챠핑하는 주기를 결정할 수 있다. 그리고, 이러한 전력에 대한 주기 적인 챠핑에 의해 제2전기장치, 그리고, 도선에 노이즈가 발생할 수 있다. 알려지거나 알려지지 않은 이유에 의해, 도선에 아크가 발생할 수 있다. 그리고, 아크에 의한 전기장치의 고장 리스크를 관리하는 시스템(110, 이하, '관리시스템'이라 함)은 도선에서의 아크발생을 검출할 수 있 다. 관리시스템은 센서 및 장치를 포함할 수 있다. 센서는 도선으로 흐르는 전류(i)의 측정값을 획득할 수 있다. 센서는 전류센서를 이용하여 도선 에 흐르는 전류(i)를 측정하여 시계열데이터를 생성할 수 있다. 센서는 주기적으로 전류(i)를 측정하고, 그 측정값을 시간의 순서에 따라 메모리에 시계열데이터로 저장할 수 있다. 센서는 전류(i)의 측정값을 그대로 저장하여 시계열데이터를 생성할 수도 있고, 측정값을 필터링 하거나 측정값을 스케일링하여 시계열데이터를 생성할 수도 있다. 장치는 시계열데이터를 분석하여 도선에 아크가 발생했는지를 판단할 수 있다. 장치는 전류(i)에 대한 시계열데이터를 분석하여 도선의 상태를 정상상태 및 아크상태로 구분할 수 있다. 혹은 장치는 도선의 상태를 정상상태, 아크상태 및 프리아크상태로 구분할 수 있다.정상상태는 아크가 없는 상태를 나타낼 수 있다. 아크상태는 아크에서 소모되는 아크에너지가 미리 정의한 기준값 이상으로 지속되는 상태를 나타낼 수 있다. 아 크에서 소모되는 아크에너지는 아크갭을 통과하는 전류(i)와 아크갭 양단에 형성되는 아크전압(Varc), 그리고, 단위시간의 곱으로 계산될 수 있다. 매 단위시간마다 아크에너지가 계산된다고 할 때, 미리 정의한 기준값 이상 의 아크에너지가 여러 단위 시간 동안 지속적으로 발생할 때, 도선이 아크상태에 있다고 할 수 있다. 전기장치-예를 들어, 도선-가 아크상태에 있는 경우, 기준값 이상의 에너지를 발산시키는 아크가 지속적으 로 발생하기 때문에, 전기장치가 위험상태-예를 들어, 화재상태-로 진입할 가능성이 높다. 장치는 아크상태를 감지하고, 전기장치가 아크상태라고 판단되면 전기장치로의 전력공급을 차단하여 전기 장치가 위험상태로 진입하지 않도록 하는 기능을 포함할 수 있다. 장치는 더 나아가 전기장치의 상태를 정 상상태, 아크상태 및 프리아크상태로 구분하고, 전기장치가 아크상태로 진입하지 않도록 혹은 아크상태로 진입 하더라도 신속히 그 상태가 종료되도록 프리아크상태에서 전기장치로의 전력공급을 차단하는 기능을 포함할 수 있다. 프리아크상태는 시간적으로 볼 때, 정상상태에서 아크상태로 전환되는 과도기 구간의 상태를 나타낼 수 있다. 프리아크상태에서 아크에너지는 미리 정의한 기준값보다 작을 수 있다. 혹은 프리아크상태에서 아크에너지가 일 시적으로 기준값 이상이 되더라도 일정 시간 이상 지속되지 못할 수 있다. 프리아크상태에서는 대체로 아크에너지가 작다는 측면에서 해당 상태에서의 아크를 스몰에너지아크 혹은 위크아 크라고 부르기도 한다. 하지만 이러한 호칭으로 본 실시예를 제한해서 해석할 필요는 없다. 도 2는 일 실시예에 따른 장치의 구성도이다. 도 2를 참조하면, 장치는 전처리부, 인공지능네트워크부, 아크리스크관리부 및 표시부 등을 포함할 수 있다. 전처리부는 전기장치에 흐르는 전류의 측정값들을 전처리할 수 있다. 전처리부는 측정값들을 인공지능네트워크에 투입하기 전에 전처리할 수 있다. 일 예로서, 전처리부는 미리 정해진 주파수대역으로 측정값들을 필터링할 수 있다. 센서의 주변에는 다양 한 노이즈원이 존재할 수 있다. 특히, 센서 주변에 전력변환장치가 위치하는 경우, 전력변환장치에서 특정 주파 수 대역의 노이즈가 크게 발생할 수 있다. 예를 들어, 전력변환장치의 스위칭 주파수 대역에서 노이즈가 크게 발생할 수 있다. 전처리부는 이러한 대역의 노이즈가 측정값들에 미치는 영향을 최소화시키기 위해 해당 대역이 리젝트되는 필터를 사용할 수 있다. 다른 예로서, 전처리부는 미리 정해진 샘플링레이트로 측정값들이 생성되도록 센서를 제어하거나 측정값들 을 전처리할 수 있다. 전처리부는 전류의 측정값들을 일정 크기의 시구간들로 구분해 놓을 수 있다. 후술하는 인공지능네트워크 에 투입되는 측정값들은 이러한 일정 크기의 시구간들로 구분해 놓은 측정값들로 이해될 수 있다. 전처리부는 측정값들을 정규화할 수 있다. 정규화하는 방법은 다양할 수 있으나 일 실시예에 따른 전처리 부는 측정값들을 정규화하되, 측정값들에서 분산정보가 사라지지 않도록 측정값들을 정규화할 수 있다. 예 를 들어, 전처리부는 평균차감기법(MSN : mean subtraction normalization)을 통해 측정값들을 정규화할 수 있다. 기술에 대한 이해도를 높이기 위해, 직류배선의 아크에 대한 전류 레벨과 아크에너지 레벨의 관계를 도 3 및 도 4를 참조하여 설명한다. 도 3은 직류배선에서 아크가 발생했을 때, 전류레벨별 아크전압을 나타내는 그래프이다. 도 3을 참조하면, 직류배선에 흐르는 전류의 레벨이 4A일 때의 아크전압이 10A일 때의 아크전압보다 높게 나오 는 것을 확인할 수 있다. 예를 들어, 아크갭이 0.4mm인 수준에서 전류 레벨이 4A일 때, 아크전압은 23V 수준을 나타내는데 반해, 전류 레벨이 10A일 때, 아크전압은 20V 수준을 나타내고 있다. 다른 예로서, 아크갭이 1.1mm 인 수준에서 전류 레벨이 4A일 때, 아크전압은 32V 수준을 나타내는데 반해, 전류 레벨이 10A일 때, 아크전압은 27V 수준을 나타내고 있다.도 4는 직류배선에서 아크가 발생했을 때, 전류레벨별 아크에너지를 나타내는 그래프이다. 도 4를 참조하면, 전류 레벨이 증가할 수록 아크에너지 레벨은 증가하나, 전류 레벨에 정비례적으로 증가하지 않고 전류 레벨에 정비례한 값보다 작은 값을 나타낸다는 것을 알 수 있다. 이는 도 3을 참조하여 설명한 것과 같이 일정 범위의 전류 레벨에 대해 전류 레벨이 증가할 수록 아크전압 레벨이 감소하기 때문이다. 이와 같이 전류 레벨이 아크에너지 레벨에 영향을 미치는 요소값이라는 것을 알 수 있다. 다시 도 2를 참조하면, 전처리부는 측정값들을 정규화하되, 정규화에 의해 아크에너지 레벨에 영향을 미치 는 요소값 성분이 사라지지 않도록 정규화할 수 있다. 예를 들어, 전처리부는 측정값들을 정규화하되, 정규화에 의해 전류 레벨의 성분이 사라지지 않도록 정규 화할 수 있다. 이러한 정규화 방법 중의 하나로 전처리부는 평균차감기법을 사용할 수 있다. 전처리부는 측정값들을 구분한 각 시구간별로 평균값을 계산하고 계산된 평균값으로 각 측정값들을 빼는 방식으로 측정값들을 정규화할 수 있다. 이러한 평균차감기법은 측정값들의 평균값을 0으로 만들지만 표준편차, 분산 등의 분포적인 특성은 변 경시키지 않게 된다. 측정값들에서 전류 레벨에 대한 정보는 이러한 분포적인 특성에 남아 있을 수 있다. 예를 들어, 전류 레벨이 높 은 경우, 측정값들의 표준편차 혹은 분산값이 높을 수 있고, 전류 레벨이 낮은 경우, 측정값들의 표준편차 혹은 분산값이 낮을 수 있다. 전처리부는 측정값들에 대해 평균값을 차감하여 정규화함으로서 후술하는 인공지능네트워크의 계산부하를 줄이고 입력특성을 개선하면서도 추정하고자 하는 아크에너지 레벨에 영향을 미치는 요소값 성분이 사라지지 않 게 함으로써 추정의 정확도도 유지할 수 있게 된다. 계속해서 도 2를 참조하면, 장치는 인공지능네트워크부, 아크리스크관리부 및 표시부를 포 함할 수 있다. 인공지능네트워크부는 제1계층과 제2계층을 포함할 수 있다. 측정값들은 시계열데이터이기 때문에, 인공지능네트워크부는 시계열데이터에 대한 해석이 정확한 LSTM(Long Short-Term Memory)계층을 포함할 수 있다. 그런데, LSTM은 피쳐(feature)가 많으면 학습이 어려운 단점을 가지고 있다. 인공지능네트워크부는 피쳐 추출이 용이한 CNN(Convolutional Neural Network)을 포 함할 수 있다. 이에 따라, 인공지능네트워크부는 제1계층으로 CNN을 사용하고, 제2계층으로 LSTM을 사용하는 인공지능네 트워크를 포함할 수 있다. 아크리스크관리부는 인공지능네트워크부에서 추정한 아크에너지 레벨에 따라 전기장치의 고장 리스크 를 평가하고 관리할 수 있다. 아크리스크관리부는 아크에너지 레벨에 따라 전기장치의 아크리스크를 정량적으로 표시할 수 있다. 예를 들어, 아크리스크관리부는 아크리스크를 수치로 표현할 수 있다. 아크리스크관리부는 표시부를 이용하여 아크리스크의 정량적 지표를 게이지 형태로 표시할 수 있다. 표시부는 디스플레이패널을 포함할 수 있는데, 아크리스크관리부는 이러한 디스플레이패널에 아크리 스크의 정량적 지표를 게이지 형태로 표시할 수 있다. 도 5는 아크리스크를 정량적으로 표시하는 다이얼 게이지의 예시 도면이다. 도 5와 같이 아크리스크관리부는 다이얼 게이지의 형태 등 다양한 정량적 표현 방식으로 아크리스크를 실시간으 로 표시할 수 있다. 종래 기술은 전류, 양단 전압, 아크갭의 길이 등 에너지를 추정하기 위하여 사전에 다수의 정보를 필요로 하여 현실적이지 않았다. 그러나, 본 실시예는 인공지능 기반으로 전류 데이터만을 활용하기 때문에 아크에너지를 현 실적으로 추정해 낼 수 있게 된다. 또한, 본 실시예는 전류 데이터만을 활용하고 정규화를 수행하는 간단한 전처리만을 사용하기 때문에, 실시간성 을 확보할 수 있다. 본 실시예에 사용되는 인공지능 모델의 계층이 간단하고, TF-Lite를 통한 모델의 경량화로50ms 이내에서 아크에너지를 추정해 낼 수 있으며, 이러한 속도는 아크에 의한 시스템의 고장에 이르는 시간보 다 빠르기 때문에 실시간성이 있다고 볼 수 있다. 도 6은 일 실시예에 따른 인공지능네트워크부에 포함되는 인공지능네트워크의 제1예시 구성도이다. 도 6을 참조하면, 인공지능네트워크는 CNN계층, LSTM(Long Short-Term Memory)계층, 분류계층 (630, 640) 및 결과출력계층 등을 포함할 수 있다. CNN계층은 1D(Dimension) CNN일 수 있고, 일정 시구간으로 구분되는 전류 측정값들이 입력될 수 있다. LSTM계층은 RNN(Recurrent Neural Network) 기법의 하나로 기존 RNN의 문제인 기울기 소멸 문제를 방지하 도록 개발된 계층이다. CNN계층의 출력은 LSTM계층으로 전달되고, LSTM계층의 출력은 분류계층 (630, 640)으로 전달될 수 있다. 분류계층(630, 640)은 ELU(Exponential Linear Unit)를 포함하는 풀리커넥티드(Fully connected)계층과 배치노멀라이제이션(Batch normalization), 드랍아웃(Dropout) 및 풀리커넥티드(Fully connected)계층을 포함 하는 다른 계층으로 구분될 수 있다. 분류계층(630, 640)에서의 산출결과가 결과출력계층을 통해 표출될 수 있으며, 전술한 인공지능네트워크부 는 결과출력계층의 값을 확인하여 아크에너지 레벨을 추정할 수 있다. 이러한 인공지능네트워크에서 주요한 기능을 담당하는 CNN계층은 학습데이터에 의해 학습될 수 있는 데, 일 실시예는 이러한 CNN계층의 학습 효율을 높이기 위해 전이학습기법을 사용하고 있다. 도 7은 제1예시에 따른 학습장치의 구성도이다. 도 7을 참조하면, 학습장치는 두 개의 인공지능네트워크(710, 600)로 구성될 수 있다. 제1인공지능네트워크는 제1CNN계층을 포함할 수 있고, 이외에 글로벌맥스풀링(Global max pooling)계 층, 풀리커넥티드계층, 그리고, 배치노멀라이제이션, 드랍아웃, 풀리커넥티드계층으로 구성되는 분류계층을 포 함할 수 있다. 제1인공지능네트워크는 적어도 둘 이상의 전류 레벨로 클래시피케이션(classification)하는 학습데이터에 따라 학습될 수 있다. 제1인공지능네트워크에는 일정 시구간으로 구분된 측정값들이 투입될 수 있다. 이때, 각 측정값에 대해서 는 전류 레벨이 미리 확인되어 있다. 그리고, 제1인공지능네트워크는 측정값들에 대한 결과값을 미리 확인 된 상태값(전류 레벨값)과 비교하는 방식으로 내부 파라미터를 학습시킬 수 있다. 여기서, 제1인공지능네트워크로 투입되는 측정값들은 아크상태의 전류에 대한 측정값들일 수 있다. 제2인공지능네트워크는 도 6을 참조하여 설명한 인공지능네트워크와 동일한 것일 수 있다. 제2인공지능네 트워크는 학습장치 내에서 학습된 후 평가장치의 인공지능네트워크부에 삽입될 수 있다. 제2인공지능네트워크는 아크에너지 레벨을 추정할 수 있는 학습데이터에 따라 학습될 수 있다. 제2인공지능네트워크는 제2CNN계층을 포함할 수 있는데, 제2CNN계층은 제1CNN계층에서 전 이학습된 계층일 수 있다. 제2인공지능네트워크가 학습되기 전에 제2CNN계층에는 제1인공지능네트워 크에서 미리 학습된 제1CNN계층이 삽입될 수 있다. 그 후 제2인공지능네트워크는 재학습을 통해 제2CNN계층을 학습시킬 수 있다. 이러한 전이학습을 이용하게 되면, 인공지능네트워크부에 삽입되는 제2인공지능네트워크의 정확도를 높이 면서도 가볍게 만들 수 있는 장점이 있다. 여기서, 제2인공지능네트워크로 투입되는 측정값들은 프리아크상태 및 아크상태의 전류에 대한 측정값들일 수 있다. 일 실시예는 인공지능네트워크부에 삽입되는 인공지능네트워크의 정확도를 높이면서도 가볍게 만들기 위한 여러 가지 구성들을 포함할 수 있다. 아크는 특정 주파수 대역에서 그 특성이 잘 표출될 수 있다. 아크를 주파수분석하면 특정 주파수 대역에서의 성 분값이 크게 나오는 것을 확인할 수 있다. 일 실시예에 따른 인공지능네트워크는 아크 특성이 잘 나타나는 특정주파수 대역을 확인하고 해당 주파수 대역으로 필터링된 측정값을 인공지능네트워크에 투입하거나 해당 주파수 대역에 대응되는 샘플링레이트로 측정한 측정값을 인공지능네트워크에 투입할 수 있다. 이렇게 하게 되면, 인공 지능네트워크의 정확도를 높이면서도 인공지능네트워크를 가볍게 할 수 있다. 제1예시의 성능을 검증하기 위한 테스트가 수행되었다. 도 8은 일 실시예에 의한 장치의 성능을 검증하기 위한 실험 세트의 구성도이다. 도 8을 참조하면, 실험 세트는 직류배선으로 연결되는 직류전류원과 인버터를 포함할 수 있다. 그리고, 인버터 는 교류배선을 통해 상용전력망과 연결될 수 있다. 직류전류원과 인버터 사이의 직류배선에는 직렬 아크 폴트 발생기가 배치될 수 있다. 직렬 아크 폴트 발생기는 모터를 이용하여 직류배선에 아크갭을 형성시킬 수 있다. 이때, 모터는 아크갭의 크기 뿐만아니라 아크갭이 형 성되는 속도도 조절할 수 있다. 직류배선에는 전류를 센싱하는 센서가 배치될 수 있다. 그리고, 계산프로세서를 포함하는 장치는 센서로부터 전 류 측정값들을 획득할 수 있다. 그리고, 계산프로세서를 포함하는 장치에는 일 실시예에 따른 프로그램이 탑재될 수 있다. 시뮬레이션에 의하면, 3 Layer 1D CNN으로 구성된 인공지능네트워크는 MSE(Mean Square Error)가 8.51J이고, MAPE(Mean Absolute Percentage Error)가 11.03%로 계산되었다. 그리고, 2 Layer LSTM으로 구성된 인공지능네 트워크는 MSE가 9.2J이고, MAPE가 12.12%로 계산되었다. 이와 같이 CNN의 한 종류로 구성된 인공지능네트워크와 LSTM 한 종류로 구성된 인공지능네트워크의 성능이 상대 적으로 높지 않다는 것을 알 수 있다. 이에 반해, 2 Layer 1D CNN과 LSTM의 조합으로 구성된 인공지능네트워크는 MSE가 3.06J이고, MAPE가 6.37%로 전술한 인공지능네트워크보다 정확도가 개선된 것을 알 수 있다. 제1예시의 시뮬레이션에 의하면, 다른 인공지능네트워크에서 2 Layer 1D CNN을 미리 학습시키고 이를 전이학습 으로 가진 온 후 LSTM과 결합시킨 인공지능네트워크(제1예시에 따른 인공지능네트워크)의 성능 검증 결과에서, MSE가 2.22J이고, MAPE가 5.20%로 성능 검증한 인공지능네트워크 중에서 가장 높은 정확도를 나타내었다. 도 9는 일 실시예에 따른 인공지능네트워크부에 포함되는 인공지능네트워크의 제2예시 구성도이다. 도 9를 참조하면, 인공지능네트워크는 Dilated CNN계층, LSTM(Long Short-Term Memory)계층 , 분류계층(1030, 1040) 및 결과출력계층 등을 포함할 수 있다. Dilated CNN계층은 확장 합성곱 신경망이라고 불리우기도 하는 것으로, 확장 합성곱(Dilated Convolution)을 사용하여 데이터에서 특징을 추출할 수 있다. 확장 합성곱(Dilated Convolution)은 커널 내에 빈 공간을 두어 필터가 특정 픽셀에서만 작동하도록 하는 것이다. 확장 합성곱 신경망은 이러한 커널의 효과적 인 수용 영역(receptive field)을 증가시키면서도 데이터의 크기를 유지하는 데 도움이 될 수 있다. 그리고, 확 장 합성곱 신경망은 입력 데이터에서 더 큰 수용 영역을 가지므로 더 넓은 범위에서 특징을 추출할 수 있다. Dilated CNN계층은 아크에너지레벨을 추정함에 있어서 일반 CNN에 비해 몇 가지 더 유리한 측면을 가질 수 있다. 예를 들어, Dilated CNN계층은 커널의 효과적인 수용 영역(receptive field)을 증가시킬 수 있 어서 더 넓음 범위에서 특징을 추출할 수 있다. 더 넓은 범위에서 특징을 추출할 수 있음에도 불구하고, 다음 계층인 LSTM계층에서의 데이터량을 증가시키지 않는 장점도 있다. 그리고, Dilated CNN계층은 입력 데이터의 크기를 그대로 유지하기 때문에, 더 큰 커널을 사용하는 일반적인 CNN 대비 작은 메모리 요구사항을 가질 수 있다. 그리고, Dilated CNN계층은 입력 데이터에서 더 넓은 영역을 병렬로 처리할 수 있어 처리 속도가 빠를 수 있고, 이를 통해 대규모 데이터에서 모델의 학습 및 추론 속도를 높일 수 있다. LSTM계층은 RNN(Recurrent Neural Network, 순환 신경망) 기법의 하나로 기존 RNN의 문제인 기울기 소멸 문제를 방지하도록 개발된 계층이다. Dilated CNN계층의 출력은 LSTM계층으로 전달되고, LSTM계층 의 출력은 분류계층(1030, 1040)으로 전달될 수 있다. LSTM계층은 이전 상태를 장기 기억 상태와 단기 기억 상태로 나누어 관리할 수 있다. 이전 상태를 유지하 면서 현재 입력을 처리하고, 그 결과를 다음 상태에 반영하는 방식으로 작동할 수 있다. LSTM계층은 이와 같이 주로 시계열 데이터의 긴 의존성을 처리하는 데 유용하게 사용될 수 있는데, 이러한 특성은 시계열 전류측정값 데이터를 사용하는 본 발명의 특성과 맞아 떨어질 수 있다. 분류계층(1030, 1040)은 ELU(Exponential Linear Unit)를 포함하는 풀리커넥티드(Fully connected)계층 과 배치노멀라이제이션(Batch normalization), 드랍아웃(Dropout) 및 풀리커넥티드(Fully connected)계층을 포 함하는 다른 계층으로 구분될 수 있다. ELU(Exponential Linear Unit)는 인공 신경망의 활성화 함수 중 하나이다. ELU 함수는 ReLU(Rectified Linear Unit) 함수와 유사한 것으로, 입력값이 0 이하일 때 이전 함수보다 덜 빠르게 수렴하도록 설계되었다. Fully connected layer는 인공 신경망의 기본적인 계층 중 하나로, 인접한 두 계층의 모든 뉴런들이 서로 연결되는 형 태의 계층이다. Fully connected layer는 입력값을 받아 출력값을 계산하고, 이를 다음 계층으로 전달하는 역할 을 할 수 있다. Fully connected layer에서 ELU 함수를 사용하면, 입력값이 0 이하일 때 지수 함수를 사용하여 부드럽게 수렴하도록 하여 Gradient vanishing 문제를 완화할 수 있습니다. ELU 함수는 음수의 입력값에 대해 선형적으로 처리하고, 양수의 입력값에 대해서는 지수 함수를 사용하여 비선형적으로 처리한다. 이를 통해 기울 기 소실 문제를 완화하고, 더욱 빠른 학습이 가능해진다. 따라서, ELU를 포함하는 Fully connected layer는 기 울기 소실 문제를 해결하면서도 좋은 성능을 보이는 인공 신경망 모델을 구성할 수 있다. 배치노멀라이제이션(Batch normalization)은 인공 신경망에서 입력값을 정규화하는 기법 중 하나이다. 이 기법 은 각 미니배치(batch) 데이터를 평균과 분산으로 정규화하여 입력값의 분포를 안정화하는 방법이다. 배치노멀 라이제이션을 사용하면 입력값의 분포가 안정화되어 기울기 소실 문제나 폭주 문제를 완화할 수 있습니다. 또한, 학습 속도를 개선하고, 일반화 성능을 향상시키는 효과도 있다. 배치노멀라이제이션은 Convolutional Neural Network(CNN)과 같은 딥러닝 모델에서 유용하게 사용될 수 있다. 드랍아웃(Dropout)은 인공 신경망에서 과적합(overfitting) 문제를 해결하기 위한 기법 중 하나이다. 드랍아웃은 학습 과정에서 무작위로 일부 뉴런을 선택하여 해당 뉴런을 제외한 나머지 뉴런만 사용하는 방식이다. 이를 통해 모델이 특정 뉴런에 지나치게 의존 하는 것을 방지하고, 모델의 일반화 성능을 향상시킬 수 있다. 드랍아웃은 각 학습 단계마다 무작위로 일부 뉴 런을 선택하므로 모델이 다양한 경우의 수를 학습할 수 있어 일반화 성능을 향상시키는 효과가 있다. 따라서, 드랍아웃은 Convolutional Neural Network(CNN)과 같은 딥러닝 모델에서 유용하게 사용될 수 있다. 분류계층(1030, 1040)에서의 산출결과가 결과출력계층을 통해 표출될 수 있으며, 전술한 인공지능네트워 크부는 결과출력계층의 값을 확인하여 아크에너지 레벨을 추정할 수 있다. 이러한 인공지능네트워크에서 주요한 기능을 담당하는 Dilated CNN계층은 학습데이터에 의해 학습 될 수 있는데, 일 실시예는 이러한 Dilated CNN계층의 학습 효율을 높이기 위해 전이학습기법을 사용하고 있다. 도 10은 제2예시에 따른 학습장치의 구성도이다. 도 10을 참조하면, 학습장치는 두 개의 인공지능네트워크(1110, 1000)로 구성될 수 있다. 제1인공지능네트워크는 제1 Dilated CNN계층을 포함할 수 있고, 이외에 글로벌맥스풀링(Global max pooling)계층, 풀리커넥티드계층, 그리고, 배치노멀라이제이션, 드랍아웃, 풀리커넥티드계층으로 구성되는 분류 계층을 포함할 수 있다. 제1인공지능네트워크는 도선의 상태를 정상상태와 아크상태로 클래시피케이션(classification)하는 학습 데이터에 따라 학습될 수 있다. 제1인공지능네트워크에는 일정 시구간으로 구분된 측정값들이 투입될 수 있다. 이때, 각 측정값에 대해서 는 전류 레벨이 미리 확인되어 있다. 그리고, 제1인공지능네트워크는 측정값들에 대한 결과값을 미리 확 인된 상태값(전류 레벨값)과 비교하는 방식으로 내부 파라미터를 학습시킬 수 있다. 여기서, 제1인공지능네트워크로 투입되는 측정값들은 아크상태의 전류에 대한 측정값들일 수 있다. 제2인공지능네트워크는 도 10을 참조하여 설명한 인공지능네트워크와 동일한 것일 수 있다. 제2인공지능 네트워크는 학습장치 내에서 학습된 후 평가장치의 인공지능네트워크부에 삽입될 수 있다. 제2인공지능네트워크는 아크에너지 레벨을 추정할 수 있는 학습데이터에 따라 학습될 수 있다. 제2인공지능네트워크는 제2 Dilated CNN계층을 포함할 수 있는데, 제2 Dilated CNN계층은 제1 Dilated CNN계층에서 전이학습된 계층일 수 있다. 제2인공지능네트워크가 학습되기 전에 제2 Dilated CNN계층에는 제1인공지능네트워크에서 미리 학습된 제1 Dilated CNN계층이 삽입될수 있다. 그 후 제2인공지능네트워크는 재학습을 통해 제2 Dilated CNN계층을 학습시킬 수 있다. 이러한 전이학습을 이용하게 되면, 인공지능네트워크부에 삽입되는 제2인공지능네트워크의 정확도를 높이 면서도 가볍게 만들 수 있는 장점이 있다. 여기서, 제2인공지능네트워크로 투입되는 측정값들은 프리아크상태 및/혹은 아크상태의 전류에 대한 측정 값들일 수 있다. 일 실시예는 인공지능네트워크부에 삽입되는 인공지능네트워크의 정확도를 높이면서도 가볍게 만들기 위한 여러 가지 구성들을 포함할 수 있다. 아크는 특정 주파수 대역에서 그 특성이 잘 표출될 수 있다. 아크를 주파수분석하면 특정 주파수 대역에서의 성 분값이 크게 나오는 것을 확인할 수 있다. 일 실시예에 따른 인공지능네트워크는 아크 특성이 잘 나타나는 특정 주파수 대역을 확인하고 해당 주파수 대역으로 필터링된 측정값을 인공지능네트워크에 투입하거나 해당 주파수 대역에 대응되는 샘플링레이트로 측정한 측정값을 인공지능네트워크에 투입할 수 있다. 이렇게 하게 되면, 인공 지능네트워크의 정확도를 높이면서도 인공지능네트워크를 가볍게 할 수 있다. 시뮬레이션에 의하면, 1D CNN과 LSTM의 조합으로 구성된 인공지능네트워크는 MSE(Mean Square Error)가 3.06J 이고, MAPE(Mean Absolute Percentage Error)가 6.37%로 계산되었다. 그리고, 전이학습이 적용되지 않았으며, 확장된 합성곱 신경망(Dilated CNN)과 순환 신경망(LSTM)의 조합으로 구성된 인공지능네트워크는 MSE가 2.66J이 고, MAPE가 5.32%로 계산되었다. 이와 같이 전이학습이 적용되지 않은 인공지능네트워크의 성능이 상대적으로 높지 않다는 것을 알 수 있다. 이에 반해, 전이학습이 적용되고 1D CNN과 LSTM의 조합으로 구성된 인공지능네트워크는 MSE가 2.22J이고, MAPE 가 5.20%로 전술한 인공지능네트워크보다 정확도가 개선되었다. 제2예시에 따라 전이학습이 적용된 시뮬레이션에서, 확장된 합성곱 신경망(Dilated CNN)과 순환 신경망(LSTM)의 조합으로 구성된 인공지능네트워크의 성능 지표인데, MSE가 1.56J이고, MAPE가 4.13%로 성능 검증한 인공지능네 트워크 중에서 가장 높은 정확도를 나타내었다. 도 11은 일 실시예에 따른 인공지능네트워크부에 포함되는 인공지능네트워크의 제3예시 구성도이다. 도 11을 참조하면, 인공지능네트워크는 Dilated CNN계층, LSTM(Long Short-Term Memory)계층 , 분류계층(1330, 1340) 및 결과출력계층 등을 포함할 수 있다. Dilated CNN계층은 확장 합성곱 신경망이라고 불리우기도 하는 것으로, 확장 합성곱(Dilated Convolution)을 사용하여 데이터에서 특징을 추출할 수 있다. 확장 합성곱(Dilated Convolution)은 커널 내에 빈 공간을 두어 필터가 특정 픽셀에서만 작동하도록 하는 것이다. 확장 합성곱 신경망은 이러한 커널의 효과적 인 수용 영역(receptive field)을 증가시키면서도 데이터의 크기를 유지하는 데 도움이 될 수 있다. 그리고, 확 장 합성곱 신경망은 입력 데이터에서 더 큰 수용 영역을 가지므로 더 넓은 범위에서 특징을 추출할 수 있다. Dilated CNN계층은 아크에너지레벨을 추정함에 있어서 일반 CNN에 비해 몇 가지 더 유리한 측면을 가질 수 있다. 예를 들어, Dilated CNN계층은 커널의 효과적인 수용 영역(receptive field)을 증가시킬 수 있 어서 더 넓음 범위에서 특징을 추출할 수 있다. 더 넓은 범위에서 특징을 추출할 수 있음에도 불구하고, 다음 계층인 LSTM계층에서의 데이터량을 증가시키지 않는 장점도 있다. 그리고, Dilated CNN계층은 입력 데이터의 크기를 그대로 유지하기 때문에, 더 큰 커널을 사용하는 일반적인 CNN 대비 작은 메모리 요구사항을 가질 수 있다. 그리고, Dilated CNN계층은 입력 데이터에서 더 넓은 영역을 병렬로 처리할 수 있어 처리 속도가 빠를 수 있고, 이를 통해 대규모 데이터에서 모델의 학습 및 추론 속도를 높일 수 있다. LSTM계층은 RNN(Recurrent Neural Network, 순환 신경망) 기법의 하나로 기존 RNN의 문제인 기울기 소멸 문제를 방지하도록 개발된 계층이다. Dilated CNN계층의 출력은 LSTM계층으로 전달되고, LSTM계층 의 출력은 분류계층(1330, 1340)으로 전달될 수 있다. LSTM계층은 이전 상태를 장기 기억 상태와 단기 기억 상태로 나누어 관리할 수 있다. 이전 상태를 유지하 면서 현재 입력을 처리하고, 그 결과를 다음 상태에 반영하는 방식으로 작동할 수 있다. LSTM계층은 이와 같이 주로 시계열 데이터의 긴 의존성을 처리하는 데 유용하게 사용될 수 있는데, 이러한 특성은 시계열 전류 측정값 데이터를 사용하는 본 발명의 특성과 맞아 떨어질 수 있다.분류계층(1330, 1340)은 ELU(Exponential Linear Unit)를 포함하는 풀리커넥티드(Fully connected)계층 과 배치노멀라이제이션(Batch normalization), 드랍아웃(Dropout) 및 풀리커넥티드(Fully connected)계층을 포 함하는 다른 계층으로 구분될 수 있다. ELU(Exponential Linear Unit)는 인공 신경망의 활성화 함수 중 하나이다. ELU 함수는 ReLU(Rectified Linear Unit) 함수와 유사한 것으로, 입력값이 0 이하일 때 이전 함수보다 덜 빠르게 수렴하도록 설계되었다. Fully connected layer는 인공 신경망의 기본적인 계층 중 하나로, 인접한 두 계층의 모든 뉴런들이 서로 연결되는 형 태의 계층이다. Fully connected layer는 입력값을 받아 출력값을 계산하고, 이를 다음 계층으로 전달하는 역할 을 할 수 있다. Fully connected layer에서 ELU 함수를 사용하면, 입력값이 0 이하일 때 지수 함수를 사용하여 부드럽게 수렴하도록 하여 Gradient vanishing 문제를 완화할 수 있습니다. ELU 함수는 음수의 입력값에 대해 선형적으로 처리하고, 양수의 입력값에 대해서는 지수 함수를 사용하여 비선형적으로 처리한다. 이를 통해 기울 기 소실 문제를 완화하고, 더욱 빠른 학습이 가능해진다. 따라서, ELU를 포함하는 Fully connected layer는 기 울기 소실 문제를 해결하면서도 좋은 성능을 보이는 인공 신경망 모델을 구성할 수 있다. 배치노멀라이제이션(Batch normalization)은 인공 신경망에서 입력값을 정규화하는 기법 중 하나이다. 이 기법 은 각 미니배치(batch) 데이터를 평균과 분산으로 정규화하여 입력값의 분포를 안정화하는 방법이다. 배치노멀 라이제이션을 사용하면 입력값의 분포가 안정화되어 기울기 소실 문제나 폭주 문제를 완화할 수 있습니다. 또한, 학습 속도를 개선하고, 일반화 성능을 향상시키는 효과도 있다. 배치노멀라이제이션은 Convolutional Neural Network(CNN)과 같은 딥러닝 모델에서 유용하게 사용될 수 있다. 드랍아웃(Dropout)은 인공 신경망에서 과적합(overfitting) 문제를 해결하기 위한 기법 중 하나이다. 드랍아웃은 학습 과정에서 무작위로 일부 뉴런을 선택하여 해당 뉴런을 제외한 나머지 뉴런만 사용하는 방식이다. 이를 통해 모델이 특정 뉴런에 지나치게 의존 하는 것을 방지하고, 모델의 일반화 성능을 향상시킬 수 있다. 드랍아웃은 각 학습 단계마다 무작위로 일부 뉴 런을 선택하므로 모델이 다양한 경우의 수를 학습할 수 있어 일반화 성능을 향상시키는 효과가 있다. 따라서, 드랍아웃은 Convolutional Neural Network(CNN)과 같은 딥러닝 모델에서 유용하게 사용될 수 있다. 분류계층(1330, 1340)에서의 산출결과가 결과출력계층을 통해 표출될 수 있으며, 전술한 인공지능네트워 크부는 결과출력계층의 값을 확인하여 아크에너지 레벨을 추정할 수 있다. 인공지능네트워크는 잔차 신경망(1325, ResNet : Residual Neural Network) 구조를 가질 수 있다. 잔차 신경망(1325, ResNet)은 깊은 신경망의 학습에서 발생하는 기울기 소실 문제(vanishing gradient problem)를 완화하기 위해 제안된 딥러닝 모델이다. ResNet은 전통적인 딥러닝 모델과는 달리, 스킵 연결(skip connectio n)이라는 새로운 구조를 도입한다. 이 스킵 연결은 입력 데이터를 단순히 출력층으로 전달하는 것이 아니라, 중 간 레이어에서 더해주는 방식으로 작동한다. 이렇게 하면 입력 데이터가 네트워크를 통해 전달될 때 발생하는 정보 손실을 최소화할 수 있다. ResNet은 깊이가 수십, 수백 개의 레이어로 구성된 경우에도 좋은 성능을 보인 다. 이것은 스킵 연결이 기울기 손실 문제를 완화하고, 더 깊은 네트워크를 학습할 수 있게 해주기 때문이다. 이러한 인공지능네트워크에서 주요한 기능을 담당하는 Dilated CNN계층은 학습데이터에 의해 학습 될 수 있는데, 일 실시예는 이러한 Dilated CNN계층의 학습 효율을 높이기 위해 전이학습기법을 사용하고 있다. 도 12는 제3예시에 따른 학습장치의 구성도이다. 도 12를 참조하면, 학습장치는 두 개의 인공지능네트워크(1410, 1300)로 구성될 수 있다. 제1인공지능네트워크는 제1 Dilated CNN계층을 포함할 수 있고, 이외에 글로벌맥스풀링(Global max pooling)계층, 풀리커넥티드계층, 그리고, 배치노멀라이제이션, 드랍아웃, 풀리커넥티드계층으로 구성되는 분류 계층을 포함할 수 있다. 제1인공지능네트워크는 도선의 상태를 정상상태와 아크상태로 클래시피케이션(classification)하는 학습 데이터에 따라 학습될 수 있다. 제1인공지능네트워크에는 일정 시구간으로 구분된 측정값들이 투입될 수 있다. 이때, 각 측정값에 대해서 는 전류 레벨이 미리 확인되어 있다. 그리고, 제1인공지능네트워크는 측정값들에 대한 결과값을 미리 확 인된 상태값(전류 레벨값)과 비교하는 방식으로 내부 파라미터를 학습시킬 수 있다. 여기서, 제1인공지능네트워크로 투입되는 측정값들은 아크상태의 전류에 대한 측정값들일 수 있다. 제2인공지능네트워크는 도 13을 참조하여 설명한 인공지능네트워크와 동일한 것일 수 있다. 제2인공지능 네트워크는 학습장치 내에서 학습된 후 평가장치의 인공지능네트워크부에 삽입될 수 있다. 제2인공지능네트워크는 아크에너지 레벨을 추정할 수 있는 학습데이터에 따라 학습될 수 있다. 제2인공지능네트워크는 제2 Dilated CNN계층을 포함할 수 있는데, 제2 Dilated CNN계층은 제1 Dilated CNN계층에서 전이학습된 계층일 수 있다. 제2인공지능네트워크가 학습되기 전에 제2 Dilated CNN계층에는 제1인공지능네트워크에서 미리 학습된 제1 Dilated CNN계층이 삽입될 수 있다. 그 후 제2인공지능네트워크는 재학습을 통해 제2 Dilated CNN계층을 학습시킬 수 있다. 이러한 전이학습을 이용하게 되면, 인공지능네트워크부에 삽입되는 제2인공지능네트워크의 정확도를 높이 면서도 가볍게 만들 수 있는 장점이 있다. 여기서, 제2인공지능네트워크로 투입되는 측정값들은 프리아크상태 및/혹은 아크상태의 전류에 대한 측정 값들일 수 있다. 도 13은 일 실시예에 따른 인공지능네트워크부에 포함되는 인공지능네트워크의 제4예시 구성도이다. 도 13을 참조하면, 인공지능네트워크는 Dilated CNN계층, 포지셔널인코더 및 트랜스포머계층 등을 포함할 수 있다. Dilated CNN계층은 확장 합성곱 신경망이라고 불리우기도 하는 것으로, 확장 합성곱(Dilated Convolution)을 사용하여 데이터에서 특징을 추출할 수 있다. 확장 합성곱(Dilated Convolution)은 커널 내에 빈 공간을 두어 필터가 특정 픽셀에서만 작동하도록 하는 것이다. 확장 합성곱 신경망은 이러한 커널의 효과적 인 수용 영역(receptive field)을 증가시키면서도 데이터의 크기를 유지하는 데 도움이 될 수 있다. 그리고, 확 장 합성곱 신경망은 입력 데이터에서 더 큰 수용 영역을 가지므로 더 넓은 범위에서 특징을 추출할 수 있다. Dilated CNN계층은 아크에너지레벨을 추정함에 있어서 일반 CNN에 비해 몇 가지 더 유리한 측면을 가질 수 있다. 예를 들어, Dilated CNN계층은 커널의 효과적인 수용 영역(receptive field)을 증가시킬 수 있 어서 더 넓음 범위에서 특징을 추출할 수 있다. 더 넓은 범위에서 특징을 추출할 수 있음에도 불구하고, 다음 계층인 트랜스포머계층에서의 데이터량을 증가시키지 않는 장점도 있다. 그리고, Dilated CNN계층 은 입력 데이터의 크기를 그대로 유지하기 때문에, 더 큰 커널을 사용하는 일반적인 CNN 대비 작은 메모리 요구 사항을 가질 수 있다. 그리고, Dilated CNN계층은 입력 데이터에서 더 넓은 영역을 병렬로 처리할 수 있 어 처리 속도가 빠를 수 있고, 이를 통해 대규모 데이터에서 모델의 학습 및 추론 속도를 높일 수 있다. 포지셔널인코더는 트랜스포머계층과 같은 시퀀스모델에서 사용될 수 있으며, 입력신호의 위치 정보 를 임베딩(embedding)에 추가하여 모델이 입력신호의 순서를 학습할 수 있도록 도와줄 수 있다. 트랜스포머 모델은 입력 시퀀스의 입력신호들을 임베딩하여 벡터로 표현할 수 있다. 그러나, 기본적인 트랜스포 머 모델의 임베딩은 입력신호의 의미를 표현하기는 하지만 입력신호의 위치 정보를 포함하지 않을 수 있다. 입 력 시퀀스에서 입력 신호의 순서는 의미에 중요한 영향을 미치는 경우가 많기 때문에, 이를 반영하기 위해 포지 셔널인코더가 사용될 수 있다. 포지셔널인코더는 임베딩에 위치 정보를 가진 벡터를 더하는 방식으로 동작할 수 있다. 일반적으로 사인 함수와 코사인 함수를 사용하여 위치 정보를 부여할 수 있다. 각각의 위치 정보 벡터는 입력 신호의 위치에 따 라 고유한 값을 가지며, 입력 신호의 거리와 상대적인 위치를 인코딩할 수 있다. 트랜스포머계층은 인코더와 디코더로 구성될 수 있으며, 각각의 모듈은 다수의 멀티-헤드 어텐션 레이어 와 피드포워드 신경망 레이어로 이루어질 수 있다. 멀티-헤드 어텐션 레이어는 셀프-어텐션 메커니즘을 여러 개의 “head\"로 나누어 병렬로 수행하는 방식일 수 있 다. 각 head는 서로 다른 가중치 행렬로 구성될 수 있고, 입력 시퀀스에 대한 다양한 표현을 학습할 수 있다. 멀티-헤드 어텐션 레이어는 각 head의 독립성을 활용하여 다양한 관점에서 입력 시퀀스를 바라볼 수 있다. 이를 통해, 트랜스포머 모델이 입력신호의 맥락을 잘 이해하고 입력신호 간의 상호작용을 모델링할 수 있다. 멀티-헤 드 어텐션 레이어는 주로 인코더와 디코더의 셀프-어텐션 레이어에서 사용될 수 있다. 트랜스포머계층에서 피드포워드 신경망 레이어는 멀티-헤드 어텐션 레이어 다음에 적용될 수 있고, 각 위 치별로 독립적으로 적용되는 완전히 연결된 신경망일 수 있다. 피드포워드 신경망 레이어는 입력 벡터를 받아 두 개의 선형 변환을 거친 후, 비선형 활성화 함수를 적용하는 과정으로 구성될 수 있다. 보통 ReLU 활성화 함수가 사용될 수 있으며, 이후에는 두 번째 선형 변환을 거쳐 최 종 출력값을 얻을 수 있다. 트랜스포머 모델에서 피드포워드 신경망 레이어는 멀티-헤드 어텐션 레이어 계층의 결과에 적용되어 위치별로 개별적인 특성을 학습할 수 있다. 이를 통해 모델은 입력 시퀀스의 각 위치에서 다양한 표현을 학습하고, 복잡 한 패턴을 인식할 수 있다. 트랜스포머계층에서의 산출결과가 결과출력계층을 통해 표출될 수 있으며, 전술한 인공지능네트워 크부는 결과출력계층의 값을 확인하여 아크에너지 레벨을 추정할 수 있다. 이러한 인공지능네트워크에서 주요한 기능을 담당하는 Dilated CNN계층은 학습데이터에 의해 학습 될 수 있는데, 일 실시예는 이러한 Dilated CNN계층의 학습 효율을 높이기 위해 전이학습기법을 사용하고 있다. 도 14는 제4예시에 따른 학습장치의 구성도이다. 도 14를 참조하면, 학습장치는 두 개의 인공지능네트워크(1610, 1500)로 구성될 수 있다. 제1인공지능네트워크는 제1 Dilated CNN계층을 포함할 수 있고, 이외에 글로벌맥스풀링(Global max pooling)계층, 풀리커넥티드계층, 그리고, 배치노멀라이제이션, 드랍아웃, 풀리커넥티드계층으로 구성되는 분류 계층을 포함할 수 있다. 제1인공지능네트워크는 도선의 상태를 정상상태와 아크상태로 클래시피케이션(classification)하는 학습 데이터에 따라 학습될 수 있다. 제1인공지능네트워크에는 일정 시구간으로 구분된 측정값들이 투입될 수 있다. 이때, 각 측정값에 대해서 는 전류 레벨이 미리 확인되어 있다. 그리고, 제1인공지능네트워크는 측정값들에 대한 결과값을 미리 확 인된 상태값(전류 레벨값)과 비교하는 방식으로 내부 파라미터를 학습시킬 수 있다. 여기서, 제1인공지능네트워크로 투입되는 측정값들은 아크상태의 전류에 대한 측정값들일 수 있다. 제2인공지능네트워크는 도 13을 참조하여 설명한 인공지능네트워크와 동일한 것일 수 있다. 제2인공지능 네트워크는 학습장치 내에서 학습된 후 평가장치의 인공지능네트워크부에 삽입될 수 있다. 제2인공지능네트워크는 아크에너지 레벨을 추정할 수 있는 학습데이터에 따라 학습될 수 있다. 제2인공지능네트워크는 제2 Dilated CNN계층을 포함할 수 있는데, 제2 Dilated CNN계층은 제1 Dilated CNN계층에서 전이학습된 계층일 수 있다. 제2인공지능네트워크가 학습되기 전에 제2 Dilated CNN계층에는 제1인공지능네트워크에서 미리 학습된 제1 Dilated CNN계층이 삽입될 수 있다. 그 후 제2인공지능네트워크는 재학습을 통해 제2 Dilated CNN계층을 학습시킬 수 있다. 이러한 전이학습을 이용하게 되면, 인공지능네트워크부에 삽입되는 제2인공지능네트워크의 정확도를 높이 면서도 가볍게 만들 수 있는 장점이 있다. 여기서, 제2인공지능네트워크로 투입되는 측정값들은 프리아크상태 및/혹은 아크상태의 전류에 대한 측정 값들일 수 있다. 일 실시예는 인공지능네트워크부에 삽입되는 인공지능네트워크의 정확도를 높이면서도 가볍게 만들기 위한 여러 가지 구성들을 포함할 수 있다. 아크는 특정 주파수 대역에서 그 특성이 잘 표출될 수 있다. 아크를 주파수분석하면 특정 주파수 대역에서의 성 분값이 크게 나오는 것을 확인할 수 있다. 일 실시예에 따른 인공지능네트워크는 아크 특성이 잘 나타나는 특정 주파수 대역을 확인하고 해당 주파수 대역으로 필터링된 측정값을 인공지능네트워크에 투입하거나 해당 주파수 대역에 대응되는 샘플링레이트로 측정한 측정값을 인공지능네트워크에 투입할 수 있다. 이렇게 하게 되면, 인공 지능네트워크의 정확도를 높이면서도 인공지능네트워크를 가볍게 할 수 있다. 도 15는 일 실시예에 따른 아크 리스크 관리 방법의 흐름도이다. 도 15를 참조하면, 아크 리스크 관리 시스템은 전기장치에 흐르는 전류를 측정할 수 있다(S1500). 그리고, 관리시스템은 측정값들을 전처리할 수 있다. 이때, 관리시스템은 측정값들을 정규화할 수 있다(S1502). S1502 단계에서, 관리시스템은 측정값들을 정규화하되, 측정값들에서 분산정보가 사라지지 않도록 측정값들을 정규화할 수 있다. 예를 들어, 관리시스템은 평균차감기법(MSN : mean subtraction normalization)을 통해 상기 측정값들을 정규 화할 수 있다. 관리시스템은 전처리된 측정값들을 인공지능네트워크에 투입할 수 있고(S1504), 이를 통해 전기장치에서의 아크 에너지 레벨을 추정할 수 있다(S1506). 인공지능네트워크는 제1계층과 제2계층을 포함할 수 있는데, 제1계층은 아크에너지에 영향을 미치는 제1요소값 에 대한 클래시피케이션(classification)을 위해 학습된 제1인공지능네트워크에서 전이(transfer)된 계층일 수 있다. 그리고, 제1계층은 피쳐(feature)의 추출이 용이한 CNN(Convolutional Neural Network)을 포함할 수 있고, 제2 계층은 시계열데이터에 대한 해석이 정확한 LSTM(Long Short-Term Memory)계층을 포함할 수 있다. 그리고, 관리시스템은 아크에너지 레벨에 따라 전기장치의 아크리스크를 정량적으로 표시할 수 있다(S1508). 이상에서 설명한 바와 같이 본 실시예에 의하면, 전기장치에서의 아크에너지 레벨을 보다 정확하게 측정할 수 있다. 그리고, 본 실시예에 의하면, 아크에 의한 전기장치의 리스크를 관리할 수 있게 된다. 이상에서 기재된 \"포함하다\", \"구성하다\" 또는 \"가지다\" 등의 용어는, 특별히 반대되는 기재가 없는 한, 해당 구성 요소가 내재될 수 있음을 의미하는 것이므로, 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것으로 해석되어야 한다. 기술적이거나 과학적인 용어를 포함한 모든 용어들은, 다르게 정의 되지 않는 한, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일 한 의미를 가진다. 사전에 정의된 용어와 같이 일반적으로 사용되는 용어들은 관련 기술의 문맥 상의 의미와 일 치하는 것으로 해석되어야 하며, 본 발명에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하 기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다. [이 발명을 지원한 국가연구개발사업] 과제번호 : GP2020-0012-14 부처명 : 과학기술정보통신부 과제관리기관 : 한국에너지기술연구원 연구사업명 : 주요사업 연구과제명 : 고장 및 예지진단 플랫폼 기술개발 기여율 : 1/1 과제수행기관명 : 한국에너지기술연구원 연구기간 : 2023.01.01 ~ 2023.12.31 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15"}
{"patent_id": "10-2023-0069387", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 전력시스템의 구성도이다. 도 2는 일 실시예에 따른 장치의 구성도이다. 도 3은 직류배선에서 아크가 발생했을 때, 전류레벨별 아크전압을 나타내는 그래프이다. 도 4는 직류배선에서 아크가 발생했을 때, 전류레벨별 아크에너지를 나타내는 그래프이다. 도 5는 아크리스크를 정량적으로 표시하는 다이얼 게이지의 예시 도면이다. 도 6은 일 실시예에 따른 인공지능네트워크부에 포함되는 인공지능네트워크의 제1예시 구성도이다. 도 7은 제1예시에 따른 학습장치의 구성도이다. 도 8은 일 실시예에 의한 장치의 성능을 검증하기 위한 실험 세트의 구성도이다. 도 9는 일 실시예에 따른 인공지능네트워크부에 포함되는 인공지능네트워크의 제2예시 구성도이다. 도 10은 제2예시에 따른 학습장치의 구성도이다. 도 11은 일 실시예에 따른 인공지능네트워크부에 포함되는 인공지능네트워크의 제3예시 구성도이다. 도 12는 제3예시에 따른 학습장치의 구성도이다. 도 13은 일 실시예에 따른 인공지능네트워크부에 포함되는 인공지능네트워크의 제4예시 구성도이다. 도 14는 제4예시에 따른 학습장치의 구성도이다. 도 15는 일 실시예에 따른 아크 리스크 관리 방법의 흐름도이다."}
