{"patent_id": "10-2024-0011406", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0161920", "출원번호": "10-2024-0011406", "발명의 명칭": "고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법 및 그 시스템", "출원인": "주식회사 LG 경영개발원", "발명자": "이문태"}}
{"patent_id": "10-2024-0011406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "단말의 적어도 하나의 프로세서가 실행하는 응답 에이전트 애플리케이션이 고도화된 추론 및 추정 기능 기반의지능적 응답 에이전트를 제공하는 방법으로서, 유저의 질문을 특정하는 질의 데이터를 획득하는 단계; 상기 획득된 질의 데이터에 대한 전문문서를 결정하는 단계; 상기 결정된 전문문서 상에서 상기 질의 데이터와 연계되는 적어도 하나의 문단을 포함하는 증거 단락을 검출하는 단계; 상기 검출된 증거 단락을 기초로 상기 질문에 대한 답변을 특정하는 응답 데이터를 생성하는 단계; 및 상기 생성된 응답 데이터를 제공하는 단계를 포함하는 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법."}
{"patent_id": "10-2024-0011406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 검출된 증거 단락을 기초로 상기 응답 데이터를 생성하는 기반 데이터인 근거 데이터를 획득하는 단계와, 상기 획득된 근거 데이터를 기초로 상기 응답 데이터를 생성하는 단계를 더 포함하는 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법."}
{"patent_id": "10-2024-0011406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서, 상기 근거 데이터는, 상기 질의 데이터에 대한 직접적인 답변을 포함하는 주요 답변 데이터, 상기 직접적인 답변에 대한 세부 설명을포함하는 설명 문장 데이터 및 상기 질문과 상기 답변에 관련된 배경지식 정보를 포함하는 보조 정보 데이터 중적어도 하나의 데이터를 포함하는 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법."}
{"patent_id": "10-2024-0011406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서, 상기 증거 단락을 검출하는 단계는, 프롬프트 엔지니어링(Prompt Engineering) 알고리즘을 기초로 상기 증거 단락을 검출하는 단계를 포함하는 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법."}
{"patent_id": "10-2024-0011406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2 항에 있어서, 상기 결정된 전문문서 및 상기 질의 데이터를 멀티 스텝 추론 프로세스(Multi-step Inference Process)를 실행하는 응답 에이전트 모델(Response Agent Model)에 입력하는 단계와, 상기 응답 에이전트 모델을 기초로 상기 응답 데이터를 생성하는 단계를 더 포함하고, 상기 멀티 스텝 추론 프로세스는, 공개특허 10-2024-0161920-3-상기 증거 단락을 검출하는 연관 선택 프로세스(Associative Selection Process), 상기 근거 데이터를 획득하는근거 생성 프로세스(Rationale Generation Process) 및 상기 응답 데이터를 생성하는 체계적 구성 프로세스(Systematic Composition Process)를 포함하는 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법."}
{"patent_id": "10-2024-0011406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서, 상기 응답 에이전트 모델을 기초로 상기 응답 데이터를 생성하는 단계는, 기 저장된 적어도 하나의 질의 데이터 및 응답 데이터를 반영하여 상기 연관 선택 프로세스 및 상기 근거 생성프로세스를 실행하는 단계를 포함하는 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법."}
{"patent_id": "10-2024-0011406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2 항에 있어서, 상기 생성된 응답 데이터를 제공하는 단계는, 상기 응답 데이터에 대한 근거정보를 상기 응답 데이터에 매칭하여 제공하는 단계를 포함하고, 상기 근거정보는, 상기 근거 데이터, 상기 증거 단락 데이터, 상기 증거 단락 식별정보, 상기 전문문서 데이터, 상기 전문문서 식별정보 및 상기 질의 데이터 중 적어도 둘 이상을 포함하는 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법."}
{"patent_id": "10-2024-0011406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서, 상기 생성된 응답 데이터를 제공하는 단계는, 상기 응답 데이터를 적어도 하나의 문장 단위로 분리하는 단계와, 상기 분리된 문장별 상기 근거정보를 검출하는 단계와, 상기 검출된 문장별 근거정보를 각 근거정보에 대응하는 문장에 매칭하여 제공하는 단계를 더 포함하는 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법."}
{"patent_id": "10-2024-0011406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항에 있어서, 상기 질의 데이터에 대한 전문문서를 결정하는 단계는, 상기 유저가 입력한 적어도 하나의 전문문서를 기초로 상기 질의 데이터에 대한 전문문서를 결정하는 단계와, 상기 유저가 입력한 적어도 하나의 전문문서 식별정보에 대응하는 전문문서를 기초로 상기 질의 데이터에 대한전문문서를 결정하는 단계와, 소정의 딥러닝 뉴럴 네트워크를 기초로 상기 질의 데이터와 기 설정된 기준 이상의 연관성을 가지는 적어도 하나의 전문문서를 검출하고, 상기 검출된 적어도 하나의 전문문서를 기초로 상기 질의 데이터에 대한 전문문서를결정하는 단계 중 적어도 하나의 단계를 포함하는 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법."}
{"patent_id": "10-2024-0011406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "응답 에이전트 애플리케이션이 저장된 적어도 하나의 메모리; 및 공개특허 10-2024-0161920-4-상기 메모리에 저장된 응답 에이전트 애플리케이션을 독출하여 고도화된 추론 및 추정 기능 기반의 지능적 응답에이전트를 제공하는 적어도 하나의 프로세서;를 포함하고, 상기 응답 에이전트 애플리케이션의 명령어는, 유저의 질문을 특정하는 질의 데이터를 획득하는 단계와, 상기 획득된 질의 데이터에 대한 전문문서를 결정하는 단계와, 상기 결정된 전문문서 상에서 상기 질의 데이터와 연계되는 적어도 하나의 문단을 포함하는 증거 단락을 검출하는 단계와, 상기 검출된 증거 단락을 기초로 상기 질문에 대한 답변을 특정하는 응답 데이터를 생성하는 단계와, 상기 생성된 응답 데이터를 제공하는 단계를 수행하는 명령어를 포함하는 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 시스템."}
{"patent_id": "10-2024-0011406", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시예에 따른 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법은, 단말의 적어도 하나의 프로세서가 실행하는 응답 에이전트 애플리케이션이 고도화된 추론 및 추정 기능 기반의 지능적 응답 에 이전트를 제공하는 방법으로서, 유저의 질문을 특정하는 질의 데이터를 획득하는 단계; 상기 획득된 질의 데이터 에 대한 전문문서를 결정하는 단계; 상기 결정된 전문문서 상에서 상기 질의 데이터와 연계되는 적어도 하나의 문단을 포함하는 증거 단락을 검출하는 단계; 상기 검출된 증거 단락을 기초로 상기 질문에 대한 답변을 특정하 는 응답 데이터를 생성하는 단계; 및 상기 생성된 응답 데이터를 제공하는 단계를 포함한다."}
{"patent_id": "10-2024-0011406", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법 및 그 시스템에 관한 것이다. 보다 상세하게는, 고도화된 추론 및 추정 기능을 위한 단계적 프로세스를 구현하는 딥러닝 뉴럴 네트워크(Deep- learning Neural Network)를 이용하여 전문문서(Specialized Document) 관련 질의에 대한 응답 데이터를 생성 해 제공하는 방법 및 그 시스템에 관한 것이다."}
{"patent_id": "10-2024-0011406", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "질의응답에 관한 딥러닝 연구는, 인공지능 모델을 통해 유저의 질문에 대한 정확한 답변을 제공해주는 것을 목 표로 한다. 일반적으로, 종래의 질의응답 딥러닝 시스템은, 소정의 질의를 구문 분석하여 의미적 요소를 패턴(규칙)으로 구 축하고, 구조화된 질의어(Structured Query Language: SQL)와 동일한 언어로 구조화된 데이터베이스에서 응답을 추출하는 시스템으로 구현된다. 그러나 다양한 자연어를 처리함에 있어 구축해야 할 구문 패턴이 기하 급수적으로 많아지면서 질의응답 딥러닝 시스템의 효용성이 떨어지는 문제가 발생했다. 그리하여 최근에는 인공지능 알고리즘이 스스로 질의를 분석하고 이에 최적화된 답안을 찾아내는 기술인 기계 독해(Machine Reading Comprehension: MRC) 모델이 널리 이용되고 있다. 구체적으로 기계 독해 모델은, 컴퓨터가 제시문(문장 및/또는 문서 등 질의를 이해하기 위한 텍스트)을 읽고 이해하여 질의에 대한 답을 찾아 제시해주는 시스템이다. 그러나 기계 독해 모델을 이용한 질의응답 딥러닝 시스템을 효과적으로 활용하려면 먼저 제시문이 존재해야 하 며, 제시문이 생성되어 있지 않은 경우 기계 독해 모델을 통한 응답이 어렵다는 문제가 있다. 한편, 종래의 기계 독해 모델들은, 이전의 다양한 모델과 벤치마크 데이터 셋을 통해 오랫동안 학습되어 왔지만, 대부분의 학습 데이터 셋이 문서에 대한 깊은 이해를 요구하지 않는 질의응답 데이터 셋에 기반하고 있 다. 이에 따라서 고도화된 추론 및 추정이 요구되는 심층적인 질의에 대한 응답을 생성하는 딥러닝 기반의 질의응답 프로세스의 개발은 매우 미비한 실정이다. 다시 말해 이전의 연구들에서는, 상당한 기계 독해 답변 능력을 향상시켰음에도 불구하고, 사실에 입각한 factoid QA를 넘어서는 보다 심화된 질의응답을 다루기 어렵다는 한계가 있다. 구체적 예시로, 종래 질의 데이터들의 대부분은 '무엇을', '언제', '어디서', '누가' 등의 사실 확인의 질문이 주를 이루고 있으며, 기계 독해 모델은 이러한 질문과 관련된 특정 단락으로부터 짧은 답변을 추출해 제공할 수 는 있으나, '어떻게' 또는 '왜' 와 같은 심층적 질문에 대한 답변을 제공하는 것에는 어려움을 가진다. 즉, 종래 기술에 따르면, 깊이 있는 기술정보에 대한 전문문서(예컨대, 과학기술 논문 등)와 관련된 지식 처리 및 추론의 혁신 등이 요구되는 심화된 질의에 대해서는, 딥러닝 모델의 답변 정확도 및 품질이 낮다는 문제가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-2449567 B1"}
{"patent_id": "10-2024-0011406", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예는, 고도화된 추론 및 추정 기능을 위한 단계적 프로세스를 구현하는 딥러닝 뉴럴 네트워크 (Deep-learning Neural Network)를 이용하여 전문문서(Specialized Document) 관련 질의에 대한 응답 데이터를 생성해 제공하는 방법 및 그 시스템을 구현하는데 목적이 있다. 또한, 본 발명의 일 실시예는, 생성된 응답 데이터 및 이를 뒷받침하는 근거정보를 상호 연계하여 제공하는 방 법 및 그 시스템을 구현하는데 목적이 있다. 다만, 본 발명 및 본 발명의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되 지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2024-0011406", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법은, 단말의 적어 도 하나의 프로세서가 실행하는 응답 에이전트 애플리케이션이 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트를 제공하는 방법으로서, 유저의 질문을 특정하는 질의 데이터를 획득하는 단계; 상기 획득된 질의 데 이터에 대한 전문문서를 결정하는 단계; 상기 결정된 전문문서 상에서 상기 질의 데이터와 연계되는 적어도 하 나의 문단을 포함하는 증거 단락을 검출하는 단계; 상기 검출된 증거 단락을 기초로 상기 질문에 대한 답변을 특정하는 응답 데이터를 생성하는 단계; 및 상기 생성된 응답 데이터를 제공하는 단계를 포함한다. 다른 측면에서, 본 발명의 실시예에 따른 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법 은, 상기 검출된 증거 단락을 기초로 상기 응답 데이터를 생성하는 기반 데이터인 근거 데이터를 획득하는 단계 와, 상기 획득된 근거 데이터를 기초로 상기 응답 데이터를 생성하는 단계를 더 포함한다. 다른 측면에서, 상기 근거 데이터는, 상기 질의 데이터에 대한 직접적인 답변을 포함하는 주요 답변 데이터, 상 기 직접적인 답변에 대한 세부 설명을 포함하는 설명 문장 데이터 및 상기 질문과 상기 답변에 관련된 배경지식 정보를 포함하는 보조 정보 데이터 중 적어도 하나의 데이터를 포함한다. 다른 측면에서, 상기 증거 단락을 검출하는 단계는, 프롬프트 엔지니어링(Prompt Engineering) 알고리즘을 기 초로 상기 증거 단락을 검출하는 단계를 포함한다. 다른 측면에서, 본 발명의 실시예에 따른 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법 은, 상기 결정된 전문문서 및 상기 질의 데이터를 멀티 스텝 추론 프로세스(Multi-step Inference Process)를 실행하는 응답 에이전트 모델(Response Agent Model)에 입력하는 단계와, 상기 응답 에이전트 모델을 기초로 상 기 응답 데이터를 생성하는 단계를 더 포함하고, 상기 멀티 스텝 추론 프로세스는, 상기 증거 단락을 검출하는 연관 선택 프로세스(Associative Selection Process), 상기 근거 데이터를 획득하는 근거 생성 프로세스 (Rationale Generation Process) 및 상기 응답 데이터를 생성하는 체계적 구성 프로세스(Systematic Composition Process)를 포함한다. 다른 측면에서, 상기 응답 에이전트 모델을 기초로 상기 응답 데이터를 생성하는 단계는, 기 저장된 적어도 하 나의 질의 데이터 및 응답 데이터를 반영하여 상기 연관 선택 프로세스 및 상기 근거 생성 프로세스를 실행하는 단계를 포함한다. 다른 측면에서, 상기 생성된 응답 데이터를 제공하는 단계는, 상기 응답 데이터에 대한 근거정보를 상기 응답 데이터에 매칭하여 제공하는 단계를 포함하고, 상기 근거정보는, 상기 근거 데이터, 상기 증거 단락 데이터, 상 기 증거 단락 식별정보, 상기 전문문서 데이터, 상기 전문문서 식별정보 및 상기 질의 데이터 중 적어도 둘 이 상을 포함한다. 다른 측면에서, 상기 생성된 응답 데이터를 제공하는 단계는, 상기 응답 데이터를 적어도 하나의 문장 단위로 분리하는 단계와, 상기 분리된 문장별 상기 근거정보를 검출하는 단계와, 상기 검출된 문장별 근거정보를 각 근 거정보에 대응하는 문장에 매칭하여 제공하는 단계를 더 포함한다. 다른 측면에서, 상기 질의 데이터에 대한 전문문서를 결정하는 단계는, 상기 유저가 입력한 적어도 하나의 전문 문서를 기초로 상기 질의 데이터에 대한 전문문서를 결정하는 단계와, 상기 유저가 입력한 적어도 하나의 전문 문서 식별정보에 대응하는 전문문서를 기초로 상기 질의 데이터에 대한 전문문서를 결정하는 단계와, 소정의 딥 러닝 뉴럴 네트워크를 기초로 상기 질의 데이터와 기 설정된 기준 이상의 연관성을 가지는 적어도 하나의 전문 문서를 검출하고, 상기 검출된 적어도 하나의 전문문서를 기초로 상기 질의 데이터에 대한 전문문서를 결정하는 단계 중 적어도 하나의 단계를 포함한다. 다른 측면에서, 본 발명의 실시예에 따른 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 시스 템은, 응답 에이전트 애플리케이션이 저장된 적어도 하나의 메모리; 및 상기 메모리에 저장된 응답 에이전트 애 플리케이션을 독출하여 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트를 제공하는 적어도 하나의 프 로세서;를 포함하고, 상기 응답 에이전트 애플리케이션의 명령어는, 유저의 질문을 특정하는 질의 데이터를 획 득하는 단계와, 상기 획득된 질의 데이터에 대한 전문문서를 결정하는 단계와, 상기 결정된 전문문서 상에서 상 기 질의 데이터와 연계되는 적어도 하나의 문단을 포함하는 증거 단락을 검출하는 단계와, 상기 검출된 증거 단 락을 기초로 상기 질문에 대한 답변을 특정하는 응답 데이터를 생성하는 단계와, 상기 생성된 응답 데이터를 제 공하는 단계를 수행하는 명령어를 포함한다."}
{"patent_id": "10-2024-0011406", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법 및 그 시스템 은, 고도화된 추론 및 추정 기능을 위한 단계적 프로세스를 구현하는 딥러닝 뉴럴 네트워크(Deep-learning Neural Network)를 이용하여 전문문서(Specialized Document) 관련 질의에 대한 응답 데이터를 생성해 제공함 으로써, 인간의 인지적 추론과 유사한 과정으로 구현되는 고도화된 추론(Chain-of-thought reasoning) 및 추정 (Speculation) 기능에 기초해 전문문서와 관계되는 심층 질의에 대하여 질문에 충실하고(faithful), 사실에 입 각하며(hallucination-controlled), 명확한 근거를 제시(evidential)하는 응답 데이터를 제공할 수 있는 효과 가 있다. 또한, 본 발명의 일 실시예에 따른 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법 및 그 시스템은, 생성된 응답 데이터 및 이를 뒷받침하는 근거정보를 상호 연계하여 제공함으로써, 응답 데이터의 생 성 근거를 포함하는 객관적인 증거자료를 직관적으로 용이하게 확인하도록 할 수 있으며, 이를 통해 응답 데이 터에 대한 신뢰성 및 타당성을 보다 향상시킬 수 있는 효과가 있다. 다만, 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효 과들은 아래의 기재로부터 명확하게 이해될 수 있다."}
{"patent_id": "10-2024-0011406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변환을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고"}
{"patent_id": "10-2024-0011406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상세한 설명에 상세하게 설명하고자 한다. 본 발명의 효과 및 특징, 그리고 그것들을 달성하는 방법은 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 다양한 형태로 구현될 수 있다. 이하의 실시예에서, 제1, 제2 등의 용어는 한정적 인 의미가 아니라 하나의 구성 요소를 다른 구성 요소와 구별하는 목적으로 사용되었다. 또한, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 또한, 포함하다 또는 가지다 등의 용어는 명 세서상에 기재된 특징, 또는 구성요소가 존재함을 의미하는 것이고, 하나 이상의 다른 특징들 또는 구성요소가 부가될 가능성을 미리 배제하는 것은 아니다. 또한, 도면에서는 설명의 편의를 위하여 구성 요소들이 그 크기가 과장 또는 축소될 수 있다. 예컨대, 도면에서 나타난 각 구성의 크기 및 두께는 설명의 편의를 위해 임의로 나 타내었으므로, 본 발명이 반드시 도시된 바에 한정되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동일 하거나 대응하는 구성 요소는 동일한 도면부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 도 1은 본 발명의 일 실시예에 따른 지능적 응답 에이전트 시스템의 개념도이다. 도 1을 참조하면, 본 발명의 실시예에 따른 지능적 응답 에이전트 시스템은, 고도화된 추론 및 추정 기능 을 위한 단계적 프로세스를 구현하는 딥러닝 뉴럴 네트워크(Deep-learning Neural Network)를 이용하여 전문문 서(Specialized Document) 관련 질의에 대한 응답 데이터를 획득해 제공하는 지능적 응답 에이전트 서비스를 구 현할 수 있다. 실시예에서, 지능적 응답 에이전트 서비스를 구현하는 지능적 응답 에이전트 시스템은, 단말, 응답 에이전트 제공서버 및 네트워크(300: Network)를 포함할 수 있다. 이때, 단말 및/또는 응답 에이전트 제공서버는, 네트워크를 통하여 연결될 수 있다. 여기서, 실시예에 따른 네트워크는, 단말 및/또는 응답 에이전트 제공서버 등과 같은 각각의 노 드 상호 간에 정보 교환이 가능한 연결 구조를 의미하는 것이다. 네트워크의 일례로는, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, WIMAX(World Interoperability for Microwave Access) 네트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), 블루투스(Bluetooth) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크 및/또는 DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 이하, 첨부된 도면을 참조하여 지능적 응답 에이전트 시스템을 구현하는 단말 및 응답 에이전트 제 공서버에 대해 상세히 설명한다. - 단말(100: Terminal) 본 발명의 실시예에 따른 단말은, 지능적 응답 에이전트 서비스를 제공하는 응답 에이전트 애플리케이션 (이하, 애플리케이션)이 설치된 소정의 컴퓨팅 디바이스일 수 있다. 자세히, 하드웨어적 관점에서 단말은, 애플리케이션이 설치된 모바일 타입 컴퓨팅 장치(100-1) 및/또는 데 스크탑 타입 컴퓨팅 장치(100-2) 등을 포함할 수 있다. 여기서, 모바일 타입 컴퓨팅 장치(100-1)는, 애플리케이션이 설치된 모바일 장치일 수 있다. 예를 들어, 모바일 타입 컴퓨팅 장치(100-1)는, 스마트 폰(smart phone), 휴대폰, 디지털방송용 디바이스, PDA(personal digital assistants), PMP(portable multimedia player) 및/또는 태블릿 PC(tablet PC) 등을 포함할 수 있다. 또한, 데스크탑 타입 컴퓨팅 장치(100-2)는, 애플리케이션이 설치된 유/무선 통신 기반 장치일 수 있다. 예를 들면, 데스크탑 타입 컴퓨팅 장치(100-2)는, 고정형 데스크탑 PC, 노트북 컴퓨터(laptop computer) 및/또 는 울트라북(ultrabook)과 같은 퍼스널 컴퓨터 등을 포함할 수 있다. 실시예에 따라서 단말은, 지능적 응답 에이전트 서비스 환경을 제공하는 소정의 서버(Server) 컴퓨팅 디바 이스를 더 포함할 수도 있다. 도 2는 본 발명의 일 실시예에 따른 단말의 내부 블록도이다. 한편, 도 2를 참조하면, 기능적 관점에서 단말은, 메모리, 프로세서 어셈블리, 통신 프로세서 , 인터페이스부, 입력 시스템, 센서 시스템 및 디스플레이 시스템을 포함할 수 있다. 실시예에서 단말은, 상기 구성요소들을 하우징 내에 포함할 수 있다. 자세히, 메모리는, 애플리케이션을 저장할 수 있다. 이때, 애플리케이션은, 지능적 응답 에이전트 서비스 환경을 제공하기 위한 각종 응용 프로그램, 데이터 및 명령어 중 어느 하나 이상을 저장할 수 있다. 즉, 메모리는, 지능적 응답 에이전트 서비스 환경을 생성하기 위하여 사용될 수 있는 명령 및 데이터 등을 저장할 수 있다. 또한, 메모리는, 프로그램 영역과 데이터 영역을 포함할 수 있다. 여기서, 실시예에 따른 프로그램 영역은, 단말을 부팅하는 운영체제(OS: Operating System) 및 기능요소들 사이에 연계될 수 있다. 또한, 실시예에 따른 데이터 영역은, 단말의 사용에 따라 발생하는 데이터가 저장될 수 있다. 또한, 메모리는, 적어도 하나 이상의 비일시적 컴퓨터 판독 가능 저장매체와, 일시적 컴퓨터 판독 가능 저 장매체를 포함할 수 있다. 예를 들어, 메모리는, ROM, EPROM, 플래시 드라이브, 하드 드라이브 등과 같은 다양한 저장기기일 수 있고, 인터넷(internet) 상에서 메모리의 저장 기능을 수행하는 웹 스토리지(web storage)를 포함할 수 있 다. 프로세서 어셈블리는, 지능적 응답 에이전트 서비스 환경을 생성하기 위한 다양한 작업을 수행하기 위하여, 메모리에 저장된 애플리케이션의 명령들을 실행할 수 있는 적어도 하나 이상의 프로세서를 포함할 수 있다. 실시예에서 프로세서 어셈블리는, 지능적 응답 에이전트 서비스를 제공하기 위하여 메모리의 애플리 케이션을 통해 구성요소의 전반적인 동작을 컨트롤할 수 있다. 자세히, 프로세서 어셈블리는, 중앙처리장치(CPU) 및/또는 그래픽처리장치(GPU) 등이 포함된 단말에 적합한 시스템 온 칩(SOC)일 수 있다. 또한, 프로세서 어셈블리는, 메모리에 저장된 운영체제(OS) 및/또는 응용 프로그램 등을 실행할 수 있다. 또한, 프로세서 어셈블리는, 단말에 탑재된 각 구성요소들을 제어할 수 있다. 또한, 프로세서 어셈블리는, 각 구성요소와 내부적으로 시스템 버스(System Bus)에 의해 통신을 수행할 수 있고, 로컬 버스(Local Bus)를 비롯한 소정의 버스 구조들을 하나 이상 포함할 수 있다. 또한, 프로세서 어셈블리는, ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세스 (microprocessors) 및/또는 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 포함하여 구현될 수 있다. 통신 프로세서은, 외부의 장치와 통신하기 위한 하나 이상의 장치를 포함할 수 있다. 이러한 통신 프로세 서은, 무선 네트워크를 통해 통신할 수 있다.자세히, 통신 프로세서은, 지능적 응답 에이전트 서비스 환경을 구현하기 위한 콘텐츠 소스를 저장한 단말 과 통신할 수 있다. 또한, 통신 프로세서는, 유저 입력을 받는 컨트롤러와 같은 다양한 유저 입력 컴포넌트와 통신할 수 있다. 실시예에서, 통신 프로세서은, 지능적 응답 에이전트 서비스와 관련된 각종 데이터를 타 단말 및/또 는 외부의 서버 등과 송수신할 수 있다. 이러한 통신 프로세서은, 이동통신을 위한 기술표준들 또는 통신방식(예를 들어, LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced),5G NR(New Radio), WIFI) 또는 근거리 통신방식 등을 수행 할 수 있는 통신장치를 통해 구축된 이동 통신망 상에서 기지국, 외부의 단말, 임의의 서버 중 적어도 하 나와 무선으로 데이터를 송수신할 수 있다. 센서 시스템은, 이미지 센서, 위치 센서(IMU, 163), 오디오 센서, 거리 센서, 근접 센서, 접촉 센서 등 다양한 센서를 포함할 수 있다. 여기서, 이미지 센서는, 단말 주위의 물리적 공간에 대한 영상(이미지 및/또는 동영상 등)을 촬영할 수 있다. 자세히, 이미지 센서는, 단말의 외부를 향해 배치된 카메라를 통하여 소정의 물리적 공간을 촬영할 수 있다. 실시예로, 이미지 센서는, 단말의 전면 또는/및 후면에 배치되어 배치된 방향 측의 물리적 공간을 촬 영할 수 있다. 실시예에서, 이미지 센서는, 지능적 응답 에이전트 서비스와 관련된 각종 영상(예컨대, 전문문서 이미지 등) 등을 촬영하여 획득할 수 있다. 이러한 이미지 센서는, 이미지 센서장치와 영상 처리 모듈을 포함할 수 있다. 자세히, 이미지 센서는, 이미지 센서장치(예를 들면, CMOS 또는 CCD)에 의해 얻어지는 정지영상 또는 동영 상을 처리할 수 있다. 또한, 이미지 센서는, 영상 처리 모듈을 이용하여 이미지 센서장치를 통해 획득된 정지영상 또는 동영상을 가공해 필요한 정보를 추출하고, 추출된 정보를 프로세서에 전달할 수 있다. 이러한 이미지 센서는, 적어도 하나 이상의 카메라를 포함하는 카메라 어셈블리일 수 있다. 여기서, 카메라 어셈블리는, 가시광선 대역을 촬영하는 일반 카메라를 포함할 수 있으며, 적외선 카메라, 스테 레오 카메라 등의 특수 카메라를 더 포함할 수 있다. 또한, 위와 같은 이미지 센서는, 실시예에 따라서 단말에 포함되어 동작할 수도 있고, 외부의 장치 (예컨대, 외부의 서버 등)에 포함되어 상술된 통신 프로세서 및/또는 인터페이스부에 기초한 연동을 통해 동작할 수도 있다. 위치 센서(IMU, 163)는, 단말의 움직임 및 가속도 중 적어도 하나 이상을 감지할 수 있다. 예를 들어, 가 속도계, 자이로스코 및/또는 자력계와 같은 다양한 위치 센서의 조합으로 이루어질 수 있다. 또한, 위치 센서(IMU, 163)는, 통신 프로세서의 GPS와 같은 위치 통신 프로세서과 연동하여, 단말 주변의 물리적 공간에 대한 공간 정보를 인식할 수 있다. 오디오 센서는, 단말 주변의 소리를 인식할 수 있다. 자세히, 오디오 센서는, 단말을 사용하는 유저의 음성 입력을 감지할 수 있는 마이크로폰을 포함할 수 있다. 실시예에서 오디오 센서는 지능적 응답 에이전트 서비스를 위해 필요한 음성 데이터를 유저로부터 입력 받 을 수 있다. 인터페이스부은, 단말을 하나 이상의 다른 장치와 통신 가능하게 연결할 수 있다. 자세히, 인터페이스부은, 하나 이상의 상이한 통신 프로토콜과 호환되는 유선 및/또는 무선 통신 장치를 포함할 수 있다. 이러한 인터페이스부을 통해 단말은, 여러 입출력 장치들과 연결될 수 있다. 예를 들어, 인터페이스부은, 헤드셋 포트나 스피커와 같은 오디오 출력장치와 연결되어, 오디오를 출력할 수 있다. 예시적으로 오디오 출력장치가 인터페이스부을 통해 연결되는 것으로 설명하였으나, 단말 내부에 설 치되는 실시예도 포함될 수 있다. 또한, 예를 들면 인터페이스부은, 키보드 및/또는 마우스와 같은 입력장치와 연결되어, 유저 입력을 획득 할 수도 있다. 이러한 인터페이스부은, 유/무선 헤드셋 포트(port), 외부 충전기 포트(port), 유/무선 데이터 포트 (port), 메모리 카드(memory card) 포트, 식별 모듈이 구비된 장치를 연결하는 포트(port), 오디오 I/O(Input/Output) 포트(port), 비디오 I/O(Input/Output) 포트(port), 이어폰 포트(port), 전력 증폭기, RF 회로, 송수신기 및 기타 통신 회로 중 적어도 하나를 포함하여 구성될 수 있다. 입력 시스템은 지능적 응답 에이전트 서비스와 관련된 유저의 입력(예를 들어, 제스처, 음성 명령, 버튼의 작동 또는 다른 유형의 입력)을 감지할 수 있다. 자세히, 입력 시스템은 소정의 버튼, 터치 센서, 유저 모션 입력을 감지하는 이미지 센서 및/또는 유 저 음성 입력을 감지하는 오디오 센서 등을 포함할 수 있다. 또한, 입력 시스템은, 인터페이스부을 통해 외부 컨트롤러와 연결되어 유저의 입력을 수신할 수 있다. 디스플레이 시스템은, 지능적 응답 에이전트 서비스와 관련된 다양한 정보를 그래픽 이미지로 출력할 수 있다. 실시예로, 디스플레이 시스템은, 지능적 응답 에이전트 서비스를 위한 각종 유저 인터페이스, 이미지 및/ 또는 텍스트 등을 표시할 수 있다. 이러한 디스플레이는, 액정 디스플레이(liquid crystal display, LCD), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display, TFT LCD), 유기 발광 다이오드(organic light-emitting diode, OLED), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(3D display) 및/또는 전자잉크 디스플레이 (e-ink display) 중에서 적어도 하나를 포함할 수 있으며, 이에 한정되지 않는다. 또한, 실시예에 따라서 디스플레이 시스템은, 이미지를 출력하는 디스플레이와, 유저의 터치 입력을 감지하는 터치 센서를 포함할 수 있다. 예시적으로 디스플레이는, 터치 센서와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써 터치 스크린으로 구현될 수 있다. 이러한 터치 스크린은, 단말과 유저 사이의 입력 인터페이스를 제공하는 유저 입력부로써 기능함과 동시에, 단말과 유저 사이의 출력 인터페이스를 제공할 수 있다. 한편, 본 발명의 실시예에 따른 단말은, 소정의 딥러닝 뉴럴 네트워크(Deep-learning Neural Network)에 기초하여 지능적 응답 에이전트 서비스와 관련된 딥러닝을 수행할 수 있다. 여기서, 실시예에 따른 상기 딥러닝 뉴럴 네트워크는, OpenAI GPT, Instruct GPT, Bi-LSTM(Bidirectional LSTM), LSTM(Long Short-Term Memory models), MLP(Multi-Layer Perceptron), EfficientNet, ResNet, ARIMA(Autoregressive Integrated Moving Average), VAR(Vector Auto Regression), RNN(Recurrent Neural Networks), GRU(Gated Recurrent Unit), GAN(Generative Adversarial Networks), DualStyleGAN, StyleGAN, Graph Convolution Network(GCN), CNN(Convolution Neural Network, CNN), DPSNet(Deep Plane Sweep Network, DPSNet), AGN(Attention Guided Network, AGN), R-CNN(Regions with CNN features), Fast R-CNN, Faster R- CNN, Mask R-CNN 및/또는 U-Net network 등을 포함할 수 있으며, 이에 한정되지 않는다. 자세히, 실시예에서 단말은, 본 발명의 실시예에 따른 응답 에이전트 모델(Response Agent Model)을 구현 가능한 적어도 하나 이상의 딥러닝 뉴럴 네트워크와 연동하여, 지능적 응답 에이전트 서비스에 필요한 딥러닝을 수행할 수 있다. 이때, 실시예에서 응답 에이전트 모델은, 적어도 하나의 전문문서(예컨대, 논문 및/또는 보고서 등) 데이터 및 질의 데이터를 입력으로 하고, 상기 입력된 전문문서 데이터 및 질의 데이터에 기초한 적어도 하나의 응답 데이 터를 출력으로 하는 딥러닝을 수행할 수 있다. 다른 한편, 실시예에 따라서 단말은, 후술되는 응답 에이전트 제공서버에서 수행하는 기능 동작의 적 어도 일부를 더 수행할 수도 있다. - 응답 에이전트 제공서버(200: Response Agent Providing Server) 한편, 본 발명의 실시예에 따른 응답 에이전트 제공서버는, 지능적 응답 에이전트 서비스를 제공하기 위한 일련의 프로세스를 수행할 수 있다. 자세히, 실시예에서 응답 에이전트 제공서버는, 단말과 같은 외부의 장치에서 응답 에이전트 제공 프 로세스를 구동하기 위해 필요한 데이터를 상기 외부의 장치와 교환함으로써, 지능적 응답 에이전트 서비스를 제 공할 수 있다. 보다 상세히, 실시예에서 응답 에이전트 제공서버는, 외부의 장치(실시예에서, 모바일 타입 컴퓨팅 장치 (100-1) 및/또는 데스크탑 타입 컴퓨팅 장치(100-2) 등)에서 애플리케이션이 동작할 수 있는 환경을 제공 할 수 있다. 이를 위해, 응답 에이전트 제공서버는, 애플리케이션이 동작하기 위한 응용 프로그램, 데이터 및/또 는 명령어 등을 포함할 수 있고, 이에 기초한 각종 데이터를 상기 외부의 장치와 송수신할 수 있다. 또한, 실시예에서 응답 에이전트 제공서버는, 질의 데이터를 획득할 수 있다. 여기서, 실시예에 따른 질의 데이터는, 소정의 전문문서(예컨대, 논문 및/또는 보고서 등)와 관련한 유저의 질 문을 특정하는 데이터를 의미할 수 있다. 또한, 실시예에서 응답 에이전트 제공서버는, 획득된 질의 데이터에 대한 전문문서를 결정할 수 있다. 즉, 실시예에서 응답 에이전트 제공서버는, 획득된 질의 데이터에 대한 응답 데이터를 생성할 시 사용되는 적어도 하나의 전문문서를 결정할 수 있다. 또한, 실시예에서 응답 에이전트 제공서버는, 결정된 전문문서 및 질의 데이터를 본 발명의 실시예에 따른 응답 에이전트 모델에 입력할 수 있다. 또한, 실시예에서 응답 에이전트 제공서버는, 전문문서 및 질의 데이터를 입력 받은 응답 에이전트 모델과 연동하여, 상기 입력된 질의 데이터에 대한 응답 데이터를 획득할 수 있다. 여기서, 실시예에 따른 응답 데이터는, 소정의 전문문서(예컨대, 논문 및/또는 보고서 등)와 관련한 유저의 질 문에 대한 답변을 특정하는 데이터를 의미할 수 있다. 또한, 실시예에서 응답 에이전트 제공서버는, 획득된 응답 데이터를 소정의 방식(실시예로, 디스플레이 출 력 등)에 따라서 제공할 수 있다. 또한, 실시예에서 응답 에이전트 제공서버는, 소정의 딥러닝 뉴럴 네트워크(Deep-learning Neural Network)에 기초하여 지능적 응답 에이전트 서비스에 필요한 딥러닝을 수행할 수 있다. 자세히, 실시예에서 응답 에이전트 제공서버는, 본 발명의 실시예에 따른 응답 에이전트 모델(Response Agent Model)을 구현 가능한 적어도 하나 이상의 딥러닝 뉴럴 네트워크와 연동하여, 지능적 응답 에이전트 서비 스에 필요한 딥러닝을 수행할 수 있다. 보다 상세히, 실시예에서 응답 에이전트 제공서버는, 상기 딥러닝을 수행하기 위해 구축되어 있는 소정의 딥러닝 뉴럴 네트워크 구동 프로그램을 메모리 모듈로부터 독출할 수 있다. 그리고 응답 에이전트 제공서버는, 독출된 소정의 딥러닝 뉴럴 네트워크 시스템에 따라서 지능적 응답 에 이전트 서비스에 필요한 딥러닝을 수행할 수 있다. 여기서, 실시예에 따른 딥러닝 뉴럴 네트워크는, OpenAI GPT, Instruct GPT, Bi-LSTM(Bidirectional LSTM), LSTM(Long Short-Term Memory models), MLP(Multi-Layer Perceptron), EfficientNet, ResNet, ARIMA(Autoregressive Integrated Moving Average), VAR(Vector Auto Regression), RNN(Recurrent Neural Networks), GRU(Gated Recurrent Unit), GAN(Generative Adversarial Networks), DualStyleGAN, StyleGAN,Graph Convolution Network(GCN), CNN(Convolution Neural Network, CNN), DPSNet(Deep Plane Sweep Network, DPSNet), AGN(Attention Guided Network, AGN), R-CNN(Regions with CNN features), Fast R-CNN, Faster R- CNN, Mask R-CNN 및/또는 U-Net network 등을 포함할 수 있으며, 이에 한정되지 않는다. 이때, 실시예에 따라서 딥러닝 뉴럴 네트워크는, 응답 에이전트 제공서버에 직접 포함되거나, 또는 응답 에이전트 제공서버와는 별도의 장치 및/또는 서버로서 구현될 수 있다. 이하의 설명에서는, 딥러닝 뉴럴 네트워크가 응답 에이전트 제공서버에 포함되어 구현되는 것으로 설명하 나 이에 한정되는 것은 아니다. 또한, 실시예에서 응답 에이전트 제공서버는, 지능적 응답 에이전트 서비스를 구현하기 위한 각종 응용 프 로그램, 명령어 및/또는 데이터 등을 저장하고 관리할 수 있다. 실시예로, 응답 에이전트 제공서버는, 적어도 하나 이상의 질의 데이터, 전문문서 데이터, 응답 데이터, 근거정보, 데이터 처리 알고리즘, 딥러닝 알고리즘 및/또는 유저 인터페이스 등을 저장 및 관리할 수 있다. 다만, 본 발명의 실시예에서 응답 에이전트 제공서버가 수행할 수 있는 기능 동작은 상술된 바에 한정되지 않으며, 또 다른 기능 동작을 더 수행할 수도 있다. 한편, 도 1을 더 참조하면, 실시예에서 응답 에이전트 제공서버는, 데이터 처리를 위한 적어도 하나 이상 의 프로세서 모듈(210: Processor Module)과, 외부의 장치와의 데이터 교환을 위한 적어도 하나 이상의 커뮤니 케이션 모듈(220: Communication Module)과, 지능적 응답 에이전트 서비스의 제공을 위한 각종 응용 프로그램, 데이터 및/또는 명령어들을 저장하는 적어도 하나 이상의 메모리 모듈(230: Memory Module)을 포함하는 소정의 컴퓨팅 장치로 구현될 수 있다. 여기서, 메모리 모듈은, 지능적 응답 에이전트 서비스를 제공하기 위한 운영체제(OS), 각종 응용 프로그램, 데이터 및 명령어 중 어느 하나 이상을 저장할 수 있다. 또한, 메모리 모듈은, 프로그램 영역과 데이터 영역을 포함할 수 있다. 이때, 실시예에 따른 프로그램 영역은, 서버를 부팅하는 운영체제(OS: Operating System) 및 기능요소들 사이에 연계될 수 있다. 또한, 실시예에 따른 데이터 영역은, 서버의 사용에 따라 발생하는 데이터가 저장될 수 있다. 또한, 메모리 모듈은, ROM, RAM, EPROM, 플래시 드라이브, 하드 드라이브 등과 같은 다양한 저장기기일 수 있고, 인터넷(internet)상에서 상기 메모리 모듈의 저장 기능을 수행하는 웹 스토리지(web storage)일 수 도 있다. 또한, 메모리 모듈은, 서버 상에 탈착 가능한 형태의 기록매체일 수 있다. 한편, 프로세서 모듈은, 지능적 응답 에이전트 서비스를 구현하기 위하여 전술한 각 유닛(unit)의 전반적 인 동작을 컨트롤할 수 있다. 자세히, 프로세서 모듈은, 중앙처리장치(CPU) 및/또는 그래픽처리장치(GPU) 등이 포함된 서버에 적합한 시 스템 온 칩(SOC)일 수 있다. 또한, 프로세서 모듈은, 메모리 모듈에 저장된 운영체제(OS) 및/또는 응용 프로그램 등을 실행할 수 있다. 또한, 프로세서 모듈은, 서버에 탑재된 각 구성요소들을 제어할 수 있다. 또한, 프로세서 모듈은, 각 구성요소와 내부적으로 시스템 버스(System Bus)에 의해 통신을 수행할 수 있 고, 로컬 버스(Local Bus)를 비롯한 소정의 버스 구조들을 하나 이상 포함할 수 있다. 또한, 프로세서 모듈은, ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세스 (microprocessors) 및/또는 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 이상의 설명에서는, 본 발명의 실시예에 따른 응답 에이전트 제공서버가 상술된 바와 같은 기능 동작을 수 행한다고 설명하였으나, 실시예에 따라서 응답 에이전트 제공서버에서 수행하는 기능 동작의 적어도 일부를 외부의 장치(예컨대, 단말 등)에서 수행할 수도 있고, 상기 외부의 장치에서 수행하는 기능 동작의 적 어도 일부를 상기 응답 에이전트 제공서버에서 더 수행할 수도 있는 등 다양한 실시예가 가능할 수 있다. - 응답 에이전트 모델(QALM: Question and Answer Language Model) 본 발명의 실시예에 따른 응답 에이전트 모델(RAM)은, 적어도 하나의 전문문서(예컨대, 논문 및/또는 보고서 등) 데이터 및 질의 데이터를 입력으로 하고, 상기 입력된 전문문서 데이터 및 질의 데이터에 기초한 적어도 하 나의 응답 데이터를 출력으로 하는 딥러닝 모델일 수 있다. 실시예에서 이러한 응답 에이전트 모델(RAM)은, 특정한 전문문서 및 질의를 입력하면, 고도화된 추론 및 추정 기능을 위한 단계적 프로세스(실시예에서, 멀티 스텝 추론 프로세스)를 구현하는 딥러닝을 수행하여, 입력된 질 의를 보다 명확히 해석하고, 이를 기초로 더 최적화된 고품질의 응답 데이터를 제공할 수 있다. 이때, 실시예에서 응답 에이전트 모델(RAM)은, 상술된 기능 동작을 수행하기 위하여 복수의 전문문서를 포함하 는 트레이닝 데이터 셋(Training data set)을 기초로 사전 훈련(Pre-training)된 딥러닝 모델(예컨대, 거대 언 어 모델(Large language model, LLM) 등)일 수 있다. 도 3 및 도 4는 본 발명의 일 실시예에 따른 응답 딥러닝 모델의 멀티 스텝 추론 프로세스(Multi-step Inference Process)를 설명하기 위한 도면의 일례들이다. 자세히, 실시예에서 응답 에이전트 모델(RAM)은, 본 발명의 실시예에 따른 멀티 스텝 추론 프로세스(Multi-step Inference Process)를 기초로 소정의 질의 데이터에 대한 응답 데이터를 생성할 수 있다. 여기서, 실시예에 따른 멀티 스텝 추론 프로세스는, 딥러닝을 이용하여 소정의 전문문서 데이터 및 질의 데이터 에 기초한 응답 데이터를 생성하는 구조화된 프로세스를 의미할 수 있다. 이러한 멀티 스텝 추론 프로세스는, 연관 선택 프로세스(Associative Selection Process), 근거 생성 프로세스 (Rationale Generation Process) 및 체계적 구성 프로세스(Systematic Composition Process)를 포함할 수 있다. 보다 상세히, 실시예에서 응답 에이전트 모델(RAM)은, 1) 질의 데이터와 연계되는 전문문서 내 단락(이하, 증거 단락)을 결정할 수 있다. (Associative Selection Process) 구체적으로, 응답 에이전트 모델(RAM)은, 전문문서가 포함하는 K(K>=1)개의 단락 중에서 질의 데이터에 대한 답 변 및/또는 근거를 포함하는 단락인 증거 단락을 적어도 하나 이상 추출할 수 있다. 이때, 실시예에 따라서 응답 에이전트 모델(RAM)은, 기 저장되어 있는 적어도 하나 이상의 종래 질의 데이터 및 종래 응답 데이터(이하, 기존 질의응답 데이터)를 반영하여 상술된 연관 선택 프로세스를 실행할 수도 있다. 이를 통해 응답 딥러닝 모델은, 질의 데이터에 대한 단문 답변을 추출하는 종래 방식 대비 보다 확장된 근거 데 이터를 토대로 추후 응답 데이터를 생성할 수 있다. 이때, 실시예에서 응답 에이전트 모델(RAM)은, 프롬프트 엔지니어링(Prompt Engineering) 알고리즘에 기반하여 상술된 연관 선택 프로세스를 수행할 수 있다. 참고적으로, 프롬프트 엔지니어링이란, 딥러닝 모델로부터 원하는 결과를 얻기 위해 프롬프트를 만들고 최적화 하는 과정을 의미할 수 있다. 여기서 프롬프트란, 딥러닝 모델에서 출력을 생성하기 위해 입력하는 구조화된 텍스트를 의미할 수 있다. 이러한 프롬프트는, 딥러닝 모델에서 기 학습한 데이터 가운데 특정 내용을 탐색하도록 안내하여 목표에 부합하 는 결과를 출력하게 할 수 있다. 예시적으로, 프롬프트의 구성요소는, 딥러닝 모델이 수행하기를 원하는 작업 또는 지침을 특정하는 '명령 (Instruction)', 딥러닝 모델을 조정할 수 있는 외부 정보 또는 추가 맥락을 특정하는 '맥락 정보(Context)', 답변을 찾고자 하는 입력 또는 질문을 특정하는 '입력 데이터(Input Data)' 및/또는 출력의 유형 또는 형식을 특정하는 '출력 데이터(Output Data)' 등을 포함할 수 있다. 즉, 실시예에서 응답 에이전트 모델(RAM)은, 프롬프트 엔지니어링 알고리즘에 기초하여 소정의 전문문서 및 질 의 데이터에 따른 구조화된 프롬프트(이하, 전문문서 질의 프롬프트)를 생성할 수 있고, 생성된 전문문서 질의 프롬프트를 기초로 해당 전문문서 내 적어도 하나의 증거 단락을 추출하는 연관 선택 프로세스를 수행할 수 있다. 따라서 응답 딥러닝 모델은, 질의 데이터 내 질문과 그 안에 담겨있는 전제들을 더 정확하게 이해하는 등, 질의 데이터에 대한 보다 명확한 해석을 토대로 적어도 하나의 증거 단락을 추출할 수 있다. 이처럼 응답 딥러닝 모델은, 질의 데이터에 대한 해석 성능을 현저히 제고함으로써 추후 생성되는 응답 데이터 의 품질 또한 직접적으로 향상시킬 수 있다. 또한, 실시예에서 응답 에이전트 모델(RAM)은, 2) 결정된 증거 단락을 기초로 질의 데이터에 대한 근거 데이터 를 획득할 수 있다. (Rationale Generation Process) 여기서, 실시예에 따른 근거 데이터란, 질의 데이터에 대한 응답 데이터의 생성 기반이 되는 데이터를 의미할 수 있다. 즉, 실시예에서 근거 데이터는, 응답 데이터를 생성할 시 활용되는 각종 데이터의 집합일 수 있다. 자세히, 실시예에서 응답 에이전트 모델(RAM)은, 적어도 하나의 증거 단락에 기초하여 질의 데이터에 대한 직접 적인 답변을 포함하는 데이터인 주요 답변 데이터, 상기 직접적인 답변을 상세히 설명하는 데이터인 설명 문장 데이터 및/또는 관련 배경지식을 포함하는 데이터인 보조 정보 데이터 등을 검출할 수 있다. 그리고 응답 에이전트 모델(RAM)은, 검출된 데이터들을 토대로 상술된 바와 같은 근거 데이터를 획득할 수 있다. 이때, 실시예에 따라서 응답 에이전트 모델(RAM)은, 기 저장되어 있는 적어도 하나 이상의 기존 질의응답 데이 터를 반영하여 상술된 근거 생성 선택 프로세스를 실행할 수도 있다. 또한, 실시예에서 응답 에이전트 모델(RAM)은, 3) 획득된 근거 데이터를 기초로 응답 데이터를 생성할 수 있다. (Systematic Composition Process) 자세히, 실시예에서 응답 에이전트 모델(RAM)은, 획득된 근거 데이터에 기반한 데이터 가공을 수행하여 응답 데 이터를 생성할 수 있다. 실시예로 응답 에이전트 모델(RAM)은, 근거 데이터에 기반한 답변의 간결성 및 가독성을 제고하는 소정의 데이 터 가공(예컨대, 중복 텍스트 제거 등)을 수행하여 응답 데이터를 생성할 수 있다. 상술된 바와 같이, 실시예에서 응답 딥러닝 모델은, 질의 데이터에 답변할 수 있는 근거 문단을 전문문서로부터 추출하고, 추출된 근거 문단의 내용을 바탕으로 증거적 근거를 생성하고, 생성된 증거적 근거를 기초로 보다 심 층적인 답변을 제공하는 응답 데이터를 제공할 수 있다. 즉, 실시예에서 응답 딥러닝 모델은, 전문문서에 기초한 심층적 질의 및 그에 대한 응답 테스크를 수행함에 있 어서 기존의 범용 언어모델(예컨대, OpenAI GPT 등)이 가지는 한계인 환각(hallucination)과 두루뭉술한 답변 문제를 해소하는 전문문서에 특화된 언어모델로 구현될 수 있다. 이를 통해 본 발명의 실시예에 따른 전문문서 공유 플랫폼 제공 시스템은, 인간의 인지적 추론과 유사한 과정으 로 구현되는 고도화된 추론(Chain-of-thought reasoning) 및 추정(Speculation) 기능에 기초하여 전문문서와 관련되는 심층 질의에 대해 질문에 충실하고(faithful), 사실에 입각하며(hallucination-controlled), 명확한 근거를 제시(evidential)하는 응답 데이터를 제공할 수 있다. - 지능적 응답 에이전트 제공 방법 이하, 본 발명의 실시예에 따른 단말의 적어도 하나 이상의 프로세서에 의하여 실행되는 애플리케이션 이 고도화된 추론 및 추정 기능을 위한 단계적 프로세스를 구현하는 딥러닝 뉴럴 네트워크(Deep-learning Neural Network)를 이용하여 전문문서(Specialized Document) 관련 질의에 대한 응답 데이터를 생성해 제공하 는 방법(즉, 지능적 응답 에이전트 서비스를 구현하는 방법)을 첨부된 도면들을 참조하여 상세히 설명한다. 본 발명의 실시예에서 단말의 적어도 하나 이상의 프로세서는, 적어도 하나 이상의 메모리에 저장된 적어도 하나 이상의 애플리케이션을 실행하거나 백그라운드 상태로 동작하게 할 수 있다. 이하의 실시예에서는, 단말의 적어도 하나 이상의 프로세서가, 애플리케이션의 명령어를 실행하기 위 해 동작하여 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법을 수행하는 것을, 애플리케이션이 수행하는 것으로 단축하여 설명한다. 도 5는 본 발명의 일 실시예에 따른 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법을 설 명하기 위한 흐름도이고, 도 6은 본 발명의 일 실시예에 따른 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법을 설명하기 위한 개념도이다. 도 5 및 도 6을 참조하면, 실시예에서 단말의 적어도 하나 이상의 프로세서에 의하여 실행되거나 백그라운 드 상태로 동작하는 애플리케이션은, 질의 데이터를 획득할 수 있다. (S101) 여기서, 실시예에 따른 질의 데이터란, 소정의 전문문서(예컨대, 논문 및/또는 보고서 등)와 관련한 유저의 질 문을 특정하는 데이터를 의미할 수 있다. 예시적으로 질의 데이터는, '제1 논문의 제1 내용을 뒷받침할 수 있는 근거자료를 분석해주세요.' 또는 '제1 논 문의 제1 구성에 제1 논문엔 개시되지 않은 제2 구성을 결합할 시 예상되는 결과와 기대효과를 설명해주세요.' 등일 수 있다. 실시예에서 애플리케이션은, 지능적 응답 에이전트 서비스 플랫폼을 기초로 소정의 질의 데이터를 입력할 수 있는 유저 인터페이스(이하, 질의 입력 인터페이스)를 제공할 수 있다. 그리고 애플리케이션은, 제공된 질의 입력 인터페이스에 기초한 유저 입력을 토대로 위와 같은 질의 데이 터를 적어도 하나 이상 획득할 수 있다. 또한, 실시예에서 애플리케이션은, 획득된 질의 데이터에 대한 전문문서를 결정할 수 있다. (S103) 즉, 실시예에서 애플리케이션은, 획득된 질의 데이터에 대한 응답 데이터를 생성할 시 사용되는 적어도 하 나의 전문문서를 결정할 수 있다. 다시 말해, 애플리케이션은, 질의 데이터에 대한 응답 데이터를 생성하기 위하여 본 발명의 실시예에 따른 응답 에이전트 모델(RAM)에 입력할 적어도 하나의 전문문서(이하, 베이스 문서)를 결정할 수 있다. 자세히, 실시예로 애플리케이션은, 지능적 응답 에이전트 서비스 플랫폼 상에 1) 유저가 직접 업로드한 적 어도 하나의 전문문서를 베이스 문서로 결정할 수 있다. 다른 실시예로, 애플리케이션은, 지능적 응답 에이전트 서비스 플랫폼 상에 2) 유저가 입력한 전문문서 식 별정보(예컨대, 논문 번호 및/또는 논문 제목 등)를 기초로 검출한 적어도 하나의 전문문서를 베이스 문서로 결 정할 수 있다. 구체적으로, 애플리케이션은, 유저 입력에 따라 획득된 적어도 하나의 전문문서 식별정보 각각에 대응하는 전문문서를 메모리 및/또는 외부의 데이터베이스로부터 검출함으로써 베이스 문서를 결정할 수 있다. 또 다른 실시예로, 애플리케이션은, 지능적 응답 에이전트 서비스 플랫폼 상에 입력된 3) 질의 데이터에 기초한 딥러닝을 수행하여 검출한 적어도 하나의 전문문서를 베이스 문서로 결정할 수 있다. 자세히, 애플리케이션은, 소정의 질의 데이터를 입력으로 하고, 상기 입력된 질의 데이터와 소정의 기준 이상의 연관성을 가지는 적어도 하나의 전문문서(이하, 관련 문서)를 출력으로 하는 딥러닝 모델(이하, 질의 관 련 문서 검출모델)과 연동하여, 상술된 베이스 문서를 결정할 수 있다. 즉, 애플리케이션은, 지능적 응답 에이전트 서비스 플랫폼 상에 입력된 질의 데이터를 질의 관련 문서 검 출모델에 입력하고, 상기 질의 데이터를 입력 받은 질의 관련 문서 검출모델로부터 상기 질의 데이터에 대응하 는 적어도 하나의 관련 문서를 획득할 수 있다. 그리고 애플리케이션은, 획득된 적어도 하나의 관련 문서를 기초로 베이스 문서를 결정할 수 있다. 이때, 실시예에 따라서 질의 관련 문서 검출모델은, 응답 에이전트 모델(RAM)에 포함되어 구현될 수도 있으며, 응답 에이전트 모델(RAM) 학습 시 사용된 트레이닝 데이터 셋(즉, 복수의 전문문서를 포함하는 트레이닝 데이터 셋)에 기초해 기 학습될 수 있다. 이상에서는, 효과적인 설명을 위하여 실시예들을 상술된 바와 같이 구분하여 설명하였으나, 실시예에 따라서 상 기 실시예들 중 적어도 일부가 상호 유기적으로 결합하여 동작할 수도 있는 등 다양한 실시예가 가능하다. 자세히, 실시예에서 애플리케이션은, 유저 설정에 따라서 1] 유저 입력 기반의 전문문서(이하, 유저 입력 문서)를 기초로 베이스 문서를 결정하거나, 또는 2] 유저 입력 문서 및 관련 문서(즉, 딥러닝 모델을 통해 자동으로 검출한 전문문서)를 기초로 베이스 문서를 결정할 수 있다. 다시 말해 애플리케이션은, 유저의 선택에 따라서 유저가 직접 입력한 적어도 하나의 전문문서(즉, 유저 입력 문서)를 기초로 베이스 문서를 결정하거나, 또는 유저가 직접 입력한 적어도 하나의 전문문서(즉, 유저 입 력 문서)와 딥러닝 모델을 통해 자동 검출한 적어도 하나의 전문문서(즉, 관련 문서) 모두를 기초로 베이스 문 서를 결정할 수 있다. 이처럼 애플리케이션은, 유저 질문에 대한 답변을 생성할 시 활용할 전문문서를 유저의 니즈(needs)에 따 라서 선택적으로 결정할 수 있다. 이를 통해 애플리케이션은, 유저가 자신이 타겟으로 하는 전문문서만을 토대로 답변을 얻고 싶은 경우나, 자신이 알고 있는 전문문서 이외에도 질문과 관련되는 다양한 전문문서를 추가적으로 더 활용하여 답변을 얻고 싶은 경우 등, 상황에 따라 달라지는 유저의 니즈에 따라서 유저가 원하는 데이터 영역 상의 정보들을 토대로 해당 질문에 대한 답변을 생성하는 맞춤형 응답 데이터 제공 프로세스를 구현할 수 있다. 또한, 실시예에서 애플리케이션은, 결정된 전문문서 및 질의 데이터를 응답 에이전트 모델(RAM)에 입력할 수 있다. (S105) 즉, 실시예에서 애플리케이션은, 상술된 바와 같이 결정된 베이스 문서와 상기 획득된 질의 데이터를 본 발명의 실시예에 따른 응답 에이전트 모델(RAM)에 입력할 수 있다. 여기서, 다시 말하자면, 실시예에 따른 응답 에이전트 모델(RAM)은, 소정의 전문문서 데이터 및 질의 데이터를 입력으로 하고, 상기 입력된 전문문서 데이터 및 질의 데이터에 기초한 적어도 하나의 응답 데이터를 출력으로 하는 딥러닝 모델일 수 있다. 실시예에서 이러한 응답 에이전트 모델(RAM)은, 특정한 전문문서 및 질의를 입력하면, 고도화된 추론 및 추정 기능을 위한 단계적 프로세스(실시예에서, 멀티 스텝 추론 프로세스)를 구현하는 딥러닝을 수행하여, 입력된 질 의를 보다 명확히 해석하고, 이를 기초로 더 최적화된 고품질의 응답 데이터를 제공할 수 있다. 또한, 실시예에서 애플리케이션은, 입력된 질의 데이터에 대한 응답 데이터를 획득할 수 있다. (S107) 여기서, 실시예에 따른 응답 데이터란, 소정의 전문문서(예컨대, 논문 및/또는 보고서 등)와 관련한 유저의 질 문에 대한 답변을 특정하는 데이터를 의미할 수 있다. 즉, 응답 데이터는, 소정의 질의 데이터에 대한 답변을 제공하는 데이터일 수 있다. 도 7은 본 발명의 일 실시예에 따른 응답 에이전트 모델(RAM)을 기초로 소정의 질의 데이터에 대한 응답 데이터 를 획득하는 방법을 설명하기 위한 도면의 일례이다. 자세히, 도 7을 참조하면, 실시예에서 애플리케이션은, 베이스 문서 및 질의 데이터를 입력 받은 응답 에 이전트 모델(RAM)과 연동하여, 상기 입력된 질의 데이터에 대한 응답 데이터를 획득할 수 있다. 보다 상세히, 도 3 및 도 4를 더 참조하면, 실시예에서 베이스 문서 및 질의 데이터를 입력 받은 응답 에이전트 모델(RAM)은, 본 발명의 실시예에 따른 멀티 스텝 추론 프로세스(Multi-step Inference Process)에 따라서, 입 력된 질의 데이터에 대한 응답 데이터를 생성할 수 있다. 여기서, 다시 말하자면, 실시예에 따른 멀티 스텝 추론 프로세스는, 딥러닝을 이용하여 소정의 전문문서 데이터 및 질의 데이터에 기초한 응답 데이터를 생성하는 구조화된 프로세스를 의미할 수 있다. 실시예에서, 이러한 멀티 스텝 추론 프로세스는, 질의 데이터와 연계되는 전문문서 내 단락(즉, 증거 단락)을 결정하는 연관 선택 프로세스(Associative Selection Process), 결정된 증거 단락을 기초로 질의 데이터에 대한 근거 데이터를 획득하는 근거 생성 프로세스(Rationale Generation Process) 및 획득된 근거 데이터를 기초로 응답 데이터를 생성하는 체계적 구성 프로세스(Systematic Composition Process)를 포함할 수 있다. 또한, 실시예에서 멀티 스텝 추론 프로세스에 따라 응답 데이터를 생성한 응답 에이전트 모델(RAM)은, 생성된 응답 데이터를 애플리케이션으로 제공할 수 있다. 그리하여 실시예에서 애플리케이션은, 응답 에이전트 모델(RAM)과의 연동을 통해 상기 입력된 질의 데이터 에 대한 응답 데이터를 획득할 수 있다. 이처럼, 실시예에서 애플리케이션은, 질의 데이터에 답변할 수 있는 근거 문단을 전문문서로부터 추출하고, 추출된 근거 문단의 내용을 바탕으로 증거적 근거를 생성하고, 생성된 증거적 근거를 기초로 보다 심 층적인 답변을 생성하는 고도화된 추론 및 추정 프로세스를 수행하는 응답 에이전트 모델(RAM)에 기초하여 해당 질의 데이터에 대한 응답 데이터를 획득할 수 있다. 따라서 애플리케이션은, 기존의 질의응답 패러다임인 검색-순위-선택-발췌-편집의 과정을 생성이라는 하나 의 과정으로 해결하여 그 효율성을 높임과 동시에, 두루뭉술한 답변이 아닌 질문의 의도를 객관적인 데이터에 기초해 명확히 해석한 전제에 따른 보다 소상하고 최적화된 고품질의 답변을 제공할 수 있다. 또한, 실시예에서 애플리케이션은, 획득된 응답 데이터를 제고할 수 있다. (S109) 자세히, 실시예에서 애플리케이션은, 적어도 하나의 질의 데이터에 기초하여 상술된 바와 같이 획득된 적 어도 하나의 응답 데이터를 제공할 수 있다. 도 8 내지 도 10은 본 발명의 일 실시예에 따른 답변 출력 인터페이스를 기초로 소정의 응답 데이터를 제공하는 방법을 설명하기 위한 도면의 일례들이다. 보다 상세히, 도 8을 참조하면, 실시예에서 애플리케이션은, 지능적 응답 에이전트 서비스 플랫폼을 기초 로 답변 출력 인터페이스(API)를 제공할 수 있다. 여기서, 실시예에 따른 답변 출력 인터페이스(API)란, 소정의 응답 데이터(AD) 및 이와 관련된 각종 데이터와 정보들을 소정의 방식에 따라서 시각화하여 표시하는 유저 인터페이스를 의미할 수 있다. 또한, 실시예에서 애플리케이션은, 제공된 답변 출력 인터페이스(API)를 기초로 상기 생성된 응답 데이터 (AD)를 표시하여 제공할 수 있다. 이때, 실시예에서 애플리케이션은, 제공되는 각 응답 데이터(AD)에 대응하는 적어도 하나의 근거정보를 해 당 응답 데이터(AD)에 매칭하여 연동 표시해 제공할 수 있다. 여기서, 실시예에 따른 근거정보란, 소정의 응답 데이터(AD) 생성 시 근거자료로서 활용된 데이터 및/또는 정보 를 의미할 수 있다. 실시예에서 이러한 근거정보는, 소정의 응답 데이터(AD)에 대응하는 전문문서 데이터, 전문문서 식별정보(예컨 대, 논문 번호 및/또는 논문 제목 등), 증거 단락 데이터, 증거 단락 식별정보(예컨대, 기 설정된 형식의 증거 단락 식별번호/식별코드 등) 및/또는 근거 데이터 등을 포함할 수 있다. 또한, 실시예에서 근거정보는, 소정의 응답 데이터(AD)에 대응하는 질의 데이터를 더 포함할 수도 있다. 자세히, 실시예에서 애플리케이션은, 각 응답 데이터(AD)에 대응하는 적어도 하나의 근거정보를 검출할 수 있다. 실시예로, 애플리케이션은, 각 응답 데이터(AD)의 생성에 관계된 적어도 하나의 전문문서 데이터, 상기 전 문문서 데이터에 대한 전문문서 식별정보, 증거 단락 데이터, 상기 증거 단락 데이터에 대한 증거 단락 식별정 보 및/또는 근거 데이터를 검출할 수 있다. 또한, 실시예에서 애플리케이션은, 검출된 근거정보를 각 응답 데이터(AD)에 매칭하여 소정의 방식(예컨대, 리스트, 이미지 및/또는 텍스트 등)에 따라 답변 출력 인터페이스(API)를 통해 연동 표시할 수 있 다. 이하의 설명에서는, 각 응답 데이터(AD)에 대응하는 근거정보를 리스트 방식으로 제공하는 실시예에 기준하여 설명하나 이는 일례일 뿐이며 이에 한정되는 것은 아니다. 실시예로, 애플리케이션은, 각 응답 데이터(AD)에 대한 적어도 하나의 근거정보를 포함하는 리스트 인터페 이스(LI: List Interface)를 답변 출력 인터페이스(API)에 더 포함할 수 있다. 그리고 애플리케이션은, 답변 출력 인터페이스(API)를 통하여 각 응답 데이터(AD)를 표시할 시 상기 리스 트 인터페이스(LI)를 대응하는 각 응답 데이터(AD)와 매칭하여 더 표시할 수 있다. 이처럼, 실시예에서 애플리케이션은, 각 응답 데이터(AD)를 도출하는데 활용한 근거자료가 무엇인지, 그 내용은 어떠한지, 그 위치는 어디인지 등에 대한 각종 관련 정보들을 해당하는 응답 데이터(AD)에 매칭하여 함 께 표시할 수 있다. 이를 통해 애플리케이션은, 각 응답 데이터(AD)가 어떠한 근거를 토대로 생성되었는지를 증빙하는 객관적 인 증거자료를 명확하고 직관적으로 제시할 수 있고, 따라서 제공되는 응답 데이터(AD)에 대한 신뢰성과 타당성 을 탄탄하게 향상시킬 수 있다. 이때, 실시예에 따라서 애플리케이션은, 각 근거정보의 속성별로 구분하여 별도의 리스트를 생성할 수 있 다. 그리고 애플리케이션은, 생성된 각각의 리스트를 상술된 리스트 인터페이스(LI)에 기초해 각 근거정보에 대응하는 응답 데이터(AD)에 매칭하여 제공할 수 있다. 실시예로, 애플리케이션은, 각 근거정보의 속성별로 구분하여 질의 데이터 리스트(L1), 전문문서 데이터 리스트(L2), 증거 단락 데이터 리스트(L3) 및/또는 근거 데이터 리스트(L4) 등을 생성할 수 있다. 그리고 애플리케이션은, 생성된 리스트를 각 근거정보에 대응하는 응답 데이터(AD)에 매칭하여 답변 출력 인터페이스(API)를 통해 연동 표시할 수 있다. 이처럼 애플리케이션은, 응답 데이터(AD) 생성의 근거로서 사용된 자료들을 속성에 따라 구분 표시해 보다 정제된 형태로 제공함으로써, 이에 대한 가독성 및 인지성을 더욱 증진시킬 수 있다. 한편, 도 9를 참조하면, 실시예에 따라서 애플리케이션은, 각 응답 데이터(AD) 내 문장(이하, 답변문장) 단위로 매칭되는 근거정보를 연동 표시할 수 있다. 자세히, 실시예에서 애플리케이션은, 각 응답 데이터(AD)를 적어도 하나의 답변문장 단위로 나누어 분리할 수 있다. 그리고 애플리케이션은, 분리된 각 답변문장을 생성할 시 활용된 적어도 하나의 근거정보를 검출할 수 있 다. 또한, 실시예에서 애플리케이션은, 검출된 근거정보를 대응하는 각 답변문장에 매칭하여 답변 출력 인터페 이스(API)를 통해 연동 표시할 수 있다. 예를 들어, 애플리케이션은, 제1 응답 데이터(AD)가 제1 내지 제5 답변문장으로 구성된 경우, 제1 답변문 장을 생성할 시 활용된 적어도 하나의 근거정보인 제1 근거정보, 제2 답변문장을 생성할 시 활용된 적어도 하나 의 근거정보인 제2 근거정보, …, 제5 답변문장을 생성할 시 활용된 적어도 하나의 근거정보인 제5 근거정보를 각기 검출할 수 있다. 그리고 애플리케이션은, 검출된 제1 근거정보를 이에 대응하는 제1 답변문장에 매칭하고, 제2 근거정보를 이에 대응하는 제2 답변문장에 매칭하고, …, 제5 근거정보를 이에 대응하는 제5 답변문장에 매칭하여 답변 출 력 인터페이스(API)를 통해 표시할 수 있다. 이와 같이 애플리케이션은, 응답 데이터(AD) 레벨보다 더 세분화된 문장 레벨에서 각 답변의 근거가 되는 자료를 매칭해 표시함으로써, 응답 데이터(AD)에 대한 증거적 근거들을 보다 소상하게 확인하고 인지하게 할 수 있다. 다른 한편, 실시예에 따라서 애플리케이션은, 기 설정된 출력표시 조건을 충족할 시 각 응답 데이터(AD) 및/또는 각 답변문장에 매칭하는 근거정보를 연동 표시할 수 있다. 실시예로, 상기 기 설정된 표시 조건은, 1> 응답 데이터(AD) 및/또는 답변문장이 타 응답 데이터(AD) 및/또는 타 답변문장 대비 최상단에 위치하는 조건, 2> 응답 데이터(AD) 및/또는 답변문장이 디스플레이 영역 내 소정의 중앙영역에 위치하는 조건 또는 3> 응답 데이터(AD) 및/또는 답변문장이 유저 선택영역(예컨대, 마우스 오버 영 역 등)에 위치하는 조건 등을 포함할 수 있다. 자세히, 실시예에서 애플리케이션은, 유저 입력에 따라서 상술된 바와 같이 기 설정된 표시 조건 중 어느 하나를 선택할 수 있다. 그리고 애플리케이션은, 선택된 표시 조건(이하, 적용 표시 조건)에 기준하여 응답 데이터(AD) 및/또는 답 변문장의 표시 조건 충족여부를 판단할 수 있다. 또한, 애플리케이션은, 적용 표시 조건을 충족한 응답 데이터(AD) 및/또는 답변문장에 기초하여 상술된 근 거정보 연동 표시 프로세스를 수행할 수 있다. 즉, 실시예에서 애플리케이션은, 유저 입력(예컨대, 마우스 스크롤 등)에 따라서 변화하는 응답 데이터 (AD) 및/또는 답변문장에 대한 실시간 주시 상황을 판단하여 유동적으로 관련 근거정보를 선택 및 추출해 연동 표시하여 제공할 수 있다. 이를 통해 애플리케이션은, 응답 데이터(AD)를 확인하는 유저와의 상호작용을 통한 인터액티브 시각화 (Interactive Visualization)를 구현할 수 있으며, 따라서 유저가 보다 용이하고 직관적으로 응답 데이터(AD) 및 관련 근거정보를 인지하게 할 수 있다. 또 다른 한편, 도 10을 참조하면, 실시예에 따라서 애플리케이션은, 기 설정된 강조표시 조건을 충족할 시 각 응답 데이터(AD) 및/또는 각 답변문장에 매칭하는 근거정보를 소정의 방식으로 강조 표시할 수 있다. 실시예로, 상기 기 설정된 표시 조건은, 1> 응답 데이터(AD) 및/또는 답변문장이 타 응답 데이터(AD) 및/또는 타 답변문장 대비 최상단에 위치하는 조건, 2> 응답 데이터(AD) 및/또는 답변문장이 디스플레이 영역 내 소정의 중앙영역에 위치하는 조건 또는 3> 응답 데이터(AD) 및/또는 답변문장이 유저 선택영역(예컨대, 마우스 오버 영 역 등)에 위치하는 조건 등을 포함할 수 있다. 자세히, 실시예에서 애플리케이션은, 유저 입력에 따라서 상술된 바와 같이 기 설정된 표시 조건 중 어느 하나를 선택할 수 있다. 그리고 애플리케이션은, 선택된 표시 조건(이하, 적용 표시 조건)에 기준하여 응답 데이터(AD) 및/또는 답 변문장의 표시 조건 충족여부를 판단할 수 있다. 또한, 애플리케이션은, 적용 표시 조건을 충족한 응답 데이터(AD) 및/또는 답변문장과, 이에 대응하는 근 거정보를 소정의 방식으로 강조 표시할 수 있다. 실시예로 애플리케이션은, 적용 표시 조건을 충족한 응답 데이터(AD) 및/또는 답변문장과, 이에 대응하는 근거정보를 바운딩 박스로 부각하는 강조 표시를 수행할 수 있다. 이에 따라 애플리케이션은, 응답 데이터(AD)에 기초한 인터액티브 시각화 과정에서의 유저 가독성을 더욱 향상시킬 수 있다. 도 11은 본 발명의 일 실시예에 따른 근거정보를 기초로 베이스 문서를 결정하는 방법을 설명하기 위한 도면의 일례이다. 또 다른 한편, 도 11을 참조하면, 실시예에 따라서 애플리케이션은, 유저 입력에 따라서 답변 출력 인터페 이스(API)를 통해 제공된 근거정보 중 적어도 일부를 베이스 문서(BD)로 설정할 수 있다. 자세히, 실시예에서 애플리케이션은, 답변 출력 인터페이스(API)를 통해 표시된 근거정보 중 적어도 일부 를 선택할 수 있는 유저 인터페이스(이하, 베이스 문서(BD) 지정 인터페이스)를 제공할 수 있다. 또한, 실시예에서 애플리케이션은, 제공된 베이스 문서(BD) 지정 인터페이스에 기초한 유저 입력에 따라서 선택된 근거정보(C: 이하, 베이스 근거정보)를 기초로 베이스 문서(BD)를 결정(업데이트)할 수 있다. 실시예로 애플리케이션은, 베이스 문서(BD) 지정 인터페이스에 기초한 유저 입력에 따라서 선택된 전문문 서 데이터 및/또는 증거 단락 데이터를 베이스 근거정보(C)로 하여 베이스 문서(BD)를 결정할 수 있다. 이때, 실시예로 애플리케이션은, 유저 입력에 따라서 베이스 근거정보(C)를 기존 베이스 문서(BD)에 추가 할 수 있다. 다른 실시예로, 애플리케이션은, 유저 입력에 따라서 베이스 근거정보(C)를 이용하여 기존 베이스 문서 (BD)를 대체할 수 있다. 또한, 실시예에서 애플리케이션은, 위와 같이 업데이트된 베이스 문서(BD)를 기반으로 전술된 S105 단계 이하의 프로세스를 실행할 수 있다. 따라서 애플리케이션은, 유저가 자신이 알고 있던 전문문서 이외에 인공지능을 통해 검출된 전문문서 중 적어도 일부를 타겟으로 하여 새로운 답변을 얻고 싶거나, 특정 전문문서 내 단락에 더욱 초점을 맞추어 새로운 답변을 얻고 싶은 등의 경우와 같이, 답변을 제공함에 따라 새롭게 발생되는 유저의 니즈를 효과적으로 지원함 으로써, 지능적 응답 에이전트 서비스의 패러다임을 확장시킴과 동시에 그 사용성 또한 향상시킬 수 있다. 이때, 실시예에 따라서 애플리케이션은, 베이스 문서(BD)를 업데이트할 시 유저 입력에 따라서 신규 질의 데이터를 획득할 수 있다. 그리고 애플리케이션은, 획득된 신규 질의 데이터를 기초로 기존 질의 데이터를 업데이트할 수 있다. 실시예로, 애플리케이션은, 유저 입력에 따라서 신규 질의 데이터를 기존 질의 데이터에 추가할 수 있다. 다른 실시예로, 애플리케이션은, 유저 입력에 따라서 신규 질의 데이터를 이용해 기존 질의 데이터를 대체 할 수 있다. 또한, 실시예에서 애플리케이션은, 업데이트된 질의 데이터에 기초하여 전술된 S105 단계 이하의 프로세스 를 실행할 수 있다. 이와 같이 애플리케이션은, 유저가 답변을 제공받은 이후에도 추가적인 질의를 높은 자유도로 손 쉽게 작 성할 수 있도록 지원하여 그 편의성을 증진시킬 수 있다. 이상, 본 발명의 일 실시예에 따른 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법 및 그 시스템은, 고도화된 추론 및 추정 기능을 위한 단계적 프로세스를 구현하는 딥러닝 뉴럴 네트워크(Deep- learning Neural Network)를 이용하여 전문문서(Specialized Document) 관련 질의에 대한 응답 데이터(AD)를 생성해 제공함으로써, 인간의 인지적 추론과 유사한 과정으로 구현되는 고도화된 추론(Chain-of-thought reasoning) 및 추정(Speculation) 기능에 기초해 전문문서와 관계되는 심층 질의에 대하여 질문에 충실하고 (faithful), 사실에 입각하며(hallucination-controlled), 명확한 근거를 제시(evidential)하는 응답 데이터 (AD)를 제공할 수 있는 효과가 있다. 또한, 본 발명의 일 실시예에 따른 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법 및 그 시스템은, 생성된 응답 데이터(AD) 및 이를 뒷받침하는 근거정보를 상호 연계하여 제공함으로써, 응답 데이터 (AD)의 생성 근거를 포함하는 객관적인 증거자료를 직관적으로 용이하게 확인하도록 할 수 있으며, 이를 통해 응답 데이터(AD)에 대한 신뢰성 및 타당성을 보다 향상시킬 수 있는 효과가 있다. 한편, 이상에서 설명된 본 발명에 따른 실시예는 다양한 컴퓨터 구성요소를 통하여 실행될 수 있는 프로그램 명 령어의 형태로 구현되어 컴퓨터 판독 가능한 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체 는 프로그램 명령어, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판 독 가능한 기록 매체에 기록되는 프로그램 명령어는 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같 은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령어의 예에 는, 컴파일러에 의하여 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해 서 실행될 수 있는 고급 언어 코드도 포함된다. 하드웨어 장치는 본 발명에 따른 처리를 수행하기 위하여 하나 이상의 소프트웨어 모듈로 변경될 수 있으며, 그 역도 마찬가지이다. 본 발명에서 설명하는 특정 실행들은 일 실시 예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아 니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어 시스템들, 소프트웨어, 상기 시스템들의 다른 기 능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재들 은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가 능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, “필 수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요소 가 아닐 수 있다. 또한 설명한 본 발명의 상세한 설명에서는 본 발명의 바람직한 실시 예를 참조하여 설명하였지만, 해당 기술 분"}
{"patent_id": "10-2024-0011406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "야의 숙련된 당업자 또는 해당 기술분야에 통상의 지식을 갖는 자라면 후술할 특허청구범위에 기재된 본 발명의 사상 및 기술 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다. 따라서, 본 발명의 기술적 범위는 명세서의 상세한 설명에 기재된 내용으로 한정되는 것이 아 니라 특허청구범위에 의해 정하여져야만 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2024-0011406", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 지능적 응답 에이전트 시스템의 개념도이다. 도 2는 본 발명의 일 실시예에 따른 단말의 내부 블록도이다. 도 3 및 도 4는 본 발명의 일 실시예에 따른 응답 딥러닝 모델의 멀티 스텝 추론 프로세스(Multi-step Inference Process)를 설명하기 위한 도면의 일례들이다. 도 5는 본 발명의 일 실시예에 따른 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법을 설 명하기 위한 흐름도이다. 도 6은 본 발명의 일 실시예에 따른 고도화된 추론 및 추정 기능 기반의 지능적 응답 에이전트 제공 방법을 설 명하기 위한 개념도이다. 도 7은 본 발명의 일 실시예에 따른 응답 에이전트 모델을 기초로 소정의 질의 데이터에 대한 응답 데이터를 획득하는 방법을 설명하기 위한 도면의 일례이다. 도 8 내지 도 10은 본 발명의 일 실시예에 따른 답변 출력 인터페이스를 기초로 소정의 응답 데이터를 제공하는 방법을 설명하기 위한 도면의 일례들이다. 도 11은 본 발명의 일 실시예에 따른 근거정보를 기초로 베이스 문서를 결정하는 방법을 설명하기 위한 도면의 일례이다."}
