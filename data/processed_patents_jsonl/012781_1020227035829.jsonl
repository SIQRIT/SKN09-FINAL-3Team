{"patent_id": "10-2022-7035829", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0144889", "출원번호": "10-2022-7035829", "발명의 명칭": "디바이스의 손 제스처 기반 제어를 위한 방법 및 시스템", "출원인": "후아웨이 테크놀러지 컴퍼니 리미티드", "발명자": "루 주웨이"}}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제스처 입력을 처리하는 방법으로서,수신된 입력 프레임에 정의된 가상 제스처-공간을 결정하는 단계 - 상기 가상 제스처-공간은 하나 이상의 사용자의 순위가 매겨진 사용자 목록으로부터 주요 사용자와 연관됨 -;손을 검출하고 추적하기 위해 상기 수신된 입력 프레임을 상기 가상 제스처 공간에서만 처리하는 단계;상기 손을 검출하고 추적함으로써 생성된 손 경계 상자를 사용하여, 상기 손과 연관된 제스처 입력을 결정하기위해 제스처 분류를 수행하는 단계; 및상기 결정된 제스처 입력과 연관된 명령 입력의 처리를 야기하기 위해 상기 결정된 제스처 입력을 출력하는 단계를 포함하는 제스처 입력 처리 방법."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 가상 제스처 공간을 결정하는 단계는:상기 하나 이상의 사용자를 검출하기 위해 상기 입력 프레임을 처리하는 단계;상기 검출된 하나 이상의 사용자에 기초해서 상기 순위가 매겨진 사용자 목록을 생성하는 단계 - 상기 주요 사용자는 상기 순위가 매겨진 사용자 목록에서 가장 높은 순위의 사용자로서 식별됨 -; 및상기 주요 사용자의 검출된 해부학적 특징에 기초해서 상기 가상 제스처-공간을 생성하는 단계를 포함하는, 제스처 입력 처리 방법."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 입력 프레임을 처리하는 단계는,상기 입력 프레임을 처리하기 위한 관심 영역(ROI)을 선택하는 단계 - 상기 ROI는 상기 입력 프레임의 전체 영역보다 작은 영역을 정의함 -를 포함하고, 상기 ROI는 정의된 ROI 시퀀스로부터 선택되고, 상기 ROI 시퀀스는 순차적으로 수신된 복수의 입력 프레임 각각을 처리하기 위한 복수의 ROI를 정의하는, 제스처 입력 처리 방법."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,상기 제스처 입력을 결정하는 단계는:상기 주요 사용자와 연관된 상기 가상 제스처-공간에서 검출된 상기 손과 연관된 유효하지 않은 제스처 입력을결정하는 단계;상기 순위가 매겨진 사용자 목록에서 다음으로 높은 순위의 사용자를 새로운 주요 사용자로서 선택하는 단계;및상기 새로운 주요 사용자를 사용하여 상기 방법을 반복하는 단계를 포함하는, 제스처 입력 처리 방법."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2022-0144889-3-제1항 내지 제4항 중 어느 한 항에 있어서,상기 가상 제스처-공간에서만 상기 입력 프레임을 처리하는 단계는:상기 수신된 입력 프레임과 연관된 저조도 조건을 결정하는 단계; 및상기 저조도 조건에 응답하여 상기 수신된 입력 프레임의 픽셀 값을 조정하기 위해 자동으로 이미지 조정을 수행하는 단계를 포함하는, 제스처 입력 처리 방법."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항 중 어느 한 항에 있어서,상기 입력 프레임은 상기 손을 검출하고 추적하기 위해 훈련된 조인트 신경망을 사용하여 처리되고,상기 훈련된조인트 신경망은 훈련된 경계 상자 정제 컨볼루션 신경망에 대한 사이드 브랜치 연결을 갖는 훈련된 제스처 분류 컨볼루션 신경망을 포함하는, 제스처 입력 처리 방법."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서,제스처 분류를 수행하는 단계는:상기 수신된 입력 프레임에서 검출된 상기 손과 연관된 제스처 클래스를 식별하는 단계;이전 입력 프레임과 연관된, 이전 제스처 상태로부터 현재 제스처 상태로의 상태 전환을 결정하는 단계 - 상기상태 전환은 상기 식별된 제스처 클래스에 기초해서 결정됨 -; 및상기 현재 제스처 상태와 연관된 상기 제스처 입력을 결정하는 단계를 포함하는, 제스처 입력 처리 방법."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,상기 수신된 입력 프레임은 상기 수신된 입력 프레임을 캡처하는데 사용되는 이미지 캡처 디바이스의 프레임 캡처 주파수보다 낮은 주파수에서 수신되고 처리되는, 제스처 입력 처리 방법."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "장치로서,기계 실행가능 명령어들을 저장하는 메모리에 연결된 처리 디바이스를 포함하고, 상기 명령어들은 상기 처리 디바이스에 의해 실행될 때 상기 장치로 하여금:수신된 입력 프레임에 정의된 가상 제스처-공간을 결정하게 하고 - 가상 제스처-공간은 하나 이상의 사용자의순위가 매겨진 사용자 목록으로부터 주요 사용자와 연관됨 -;손을 검출하고 추적하기 위해 상기 수신된 입력 프레임을 상기 가상 제스처-공간에서만 처리하게 하고;상기 손을 검출하고 추적함으로써 생성된 손 경계 상자를 사용하여, 상기 손과 연관된 제스처 입력을 결정하기위해 제스처 분류를 수행하게 하며,상기 결정된 제스처 입력은 상기 결정된 제스처 입력과 연관된 명령 입력의 처리를 야기하는, 장치."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 명령어들은 또한:상기 하나 이상의 사용자를 검출하기 위해 상기 입력 프레임을 처리하고;상기 검출된 하나 이상의 사용자에 기초해서 상기 순위가 매겨진 사용자 목록을 생성 - 상기 주요 사용자는 상기 순위가 매겨진 사용자 목록에서 가장 높은 순위의 사용자로서 식별됨 - 하고;상기 주요 사용자의 검출된 해부학적 특징에 기초해서 상기 가상 제스처-공간을 생성함으로써,공개특허 10-2022-0144889-4-상기 장치로 하여금 상기 가상 제스처 공간을 결정하게 하는, 장치."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 명령어들은 또한:상기 입력 프레임을 처리하기 위한 관심 영역(ROI)을 선택 - 상기 ROI는 상기 입력 프레임의 전체 영역보다 작은 영역을 정의함 - 함으로써, 상기 장치로 하여금 상기 입력 프레임을 처리하게 하고,상기 ROI는 정의된 ROI 시퀀스로부터 선택되고, 상기 ROI 시퀀스는 순차적으로 수신된 복수의 입력 프레임 각각을 처리하기 위한 복수의 ROI를 정의하는, 장치."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항 내지 제11항 중 어느 한 항에 있어서,상기 명령어는 또한:상기 주요 사용자와 연관된 상기 가상 제스처-공간에서 검출된 상기 손과 연관된 유효하지 않은 제스처 입력을결정하고;상기 순위가 매겨진 사용자 목록에서 다음으로 높은 순위의 사용자를 새로운 주요 사용자로서 선택하고;상기 새로운 주요 사용자를 사용하여 상기 방법을 반복함으로써,상기 장치로 하여금 상기 제스처 입력을 결정하게 하는, 장치."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항 내지 제12항 중 어느 한 항에 있어서, 상기 명령어들은 또한:상기 수신된 입력 프레임과 연관된 저조도 조건을 결정하고;상기 저조도 조건에 응답하여 상기 수신된 입력 프레임의 픽셀 값을 조정하기 위해 자동으로 이미지 조정을 수행함으로써, 상기 장치로 하여금 상기 수신된 입력 프레임을 상기 가상 제스처-공간에서만 처리하게 하는, 장치."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항 내지 제13항 중 어느 한 항에 있어서,상기 입력 프레임은 상기 손을 검출 및 추적하기 위해 훈련된 조인트 신경망을 사용하여 처리되고, 상기 훈련된조인트 신경망은 훈련된 경계 상자 정제 컨볼루션 신경망에 대한 사이드 브랜치 연결을 갖는 훈련된 제스처 분류 컨볼루션 신경망을 포함하는, 장치."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항 내지 제14항 중 어느 한 항에 있어서,상기 명령들은 또한:상기 수신된 입력 프레임에서 검출된 상기 손과 연관된 제스처 클래스를 식별하고;이전 입력 프레임과 연관된 이전 제스처 상태로부터 현재 제스처 상태로의 상태 전환을 결정 - 상기 상태 전환은 상기 식별된 제스처 클래스에 기초해서 결정됨 - 하고;상기 현재 제스처 상태와 연관된 상기 제스처 입력을 결정함으로써,상기 장치로 하여금 제스처 분류를 수행하게 하는, 장치."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "공개특허 10-2022-0144889-5-제9항 내지 제15항 중 어느 한 항에 있어서,상기 수신된 입력 프레임은, 상기 수신된 입력 프레임을 캡처하는데 사용되는 이미지 캡처 디바이스의 프레임캡처 주파수보다 낮은 주파수에서 수신되고 처리되는, 장치."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제9항 내지 제16항 중 어느 한 항에 있어서,상기 장치는 제스처 제어 디바이스인 장치."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 입력 프레임을 캡쳐하는 카메라를 더 포함하는 장치."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항 또는 제18항에 있어서,상기 제스처 제어 디바이스는:텔레비전;스마트폰;태블릿;차량 결합 디바이스;사물 인터넷 디바이스;인공 현실 디바이스; 또는가상 현실 디바이스 중 하나인, 장치."}
{"patent_id": "10-2022-7035829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "기계 실행가능 명령어가 저장된 컴퓨터 판독가능 매체로서,상기 명령어는 장치의 처리 디바이스에 의해 실행될 때, 상기 장치로 하여금 제1항 내지 제8항 중 어느 한 항의방법을 수행하게 하는, 컴퓨터 판독가능 매체."}
{"patent_id": "10-2022-7035829", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "디바이스의 제스처 기반 제어를 위한 방법 및 시스템이 설명된다. 가상 제스처-공간은 수신된 입력 프레임에서 결정된다. 상기 가상 제스처 공간은 순위가 매겨진 사용자 목록의 주요 사용자와 연관된다. 손을 감지하고 추 적하기 위해, 상기 수신된 입력 프레임은 상기 가상 제스처-공간에서만 처리된다. 상기 손을 검출하고 추적하여 생성된 손 경계 상자를 사용하여, 상기 손과 연관된 제스처 입력을 결정하기 위해 제스처 분류가 수행된다. 상 기 결정된 제스처 입력과 연관된 명령 입력이 처리된다. 상기 디바이스는 스마트 텔레비전, 스마트 폰, 태블릿 등일 수 있다."}
{"patent_id": "10-2022-7035829", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 손 제스처(hand gesture)의 검출과 인식, 및 손 제스처를 이용하여 텔레비전 또는 스마트폰과 같은 디바이스를 제어하는 것에 관한 것이다."}
{"patent_id": "10-2022-7035829", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "디바이스(예를 들어, 스마트폰, 태블릿, 텔레비전, 등)의 카메라에 의해 캡처된 디지털 비디오의 프레임들의 시 퀀스에서 손 제스처의 머신 비전 기반 검출(관련 기술 분야에서 일반적으로 컴퓨터 비전이라고 함)을 사용한 이 러한 디바이스의 원격 제어는 향상된 사용자 경험을 제공하기 위해 관심을 가져왔다. 디지털 비디오의 프레임 들의 시퀀스에서 제스처 검출 및 인식을 수행하기 위한 기존의 솔루션들은 비디오 동작의 분류(즉, 디지털 비디 오의 프레임들의 시퀀스의 여러 프레임에서 검출되고 추적된 손의 움직임의 분류)를 기반으로 하고 있었다. 이 를 위해서는 일반적으로 디지털 비디오의 프레임들의 시퀀스에 대해 제스처 분할 및 인식을 수행해야 한다. 그 러나, 디지털 이미지들의 시퀀스에 대해 제스처 분할 및 인식을 수행하는 것은 일반적으로 상당한 계산 비용을 초래하지만 상대적으로 정확도는 낮다.디지털 비디오의 프레임들의 시퀀스에 대해 제스처 분할 및 인식을 수행하는 어려움 외에도, 실제 애플리케이션 에서의 손 검출도 어려움에 직면해 있다. 예를 들어, 사용자로부터 디바이스까지의 거리가 멀 때(예를 들어, 사용자가 벽에 장착된 디바이스를 제어할 때) 또는 저조도 환경(예를 들어, 야간)에 있는 경우, 디지털 비디오 의 프레임들의 시퀀스에 대해 제스처 검출을 수행하는 것은 일반적으로 복잡한 배경에서 어렵다(예를 들어, 어 수선할 수 있는 사용자의 생활 공간에서). 이러한 조건에서 디지털 비디오의 프레임들의 시퀀스에 대해 제스처 검출 및 인식을 수행하면 종종 위양성(false positives) 및 위음성(false negatives)이 허용할 수 없을 정도로 많이 발생한다. 검출 구역에 여러 사람이 있는 경우에도 어려움이 발생하고, 제스처를 검출하고 인식하는데 혼 란이 발생할 수 있다. 디지털 비디오의 프레임들의 시퀀스에 대한 분할 및 인식을 수행하기 위한 머신 러닝 기반 접근 방식도 특정 어 려움에 직면해 있다. 예를 들어, 만족스러운 정확도를 얻기 위해, 제스처 검출 및 분할을 수행하도록 구성된 제스처 검출기 및 분류기(classifier)는 일반적으로 높은 계산 리소스를 필요로 하는 대형 딥 컨볼루션(large deep convolutional) 신경망을 사용하여 훈련(training)될 수 있다. 또한, 더 먼 거리에서 더 작은 손을 검출 하기 위해서는, 디지털 비디오의 프레임이 고해상도를 가져야 하므로 계산 비용이 현저히 증가한게 된다. 또 다른 어려움은 제스처(또는 손) 검출기에 의해 생성된 경계 상자(bounding box)가 후속 분류기의 예상 입력과 매칭되는 크기가 아닐 수 있다는 것이다. 따라서, 이상적이지 않은 실생활 환경에서도, 디바이스의 원격 제어를 위해 상기 디바이스의 카메라에 의해 캡 처된 디지털 비디오의 프레임들의 시퀀스에서 제스처의 검출 및 인식을 위한 보다 정확하고 계산 비용이 덜 드 는 머신 러닝 기반 방법 및 시스템을 제공하는 것이 유용할 것이다. 다양한 예들에서, 본 개시는 손 제스처들의 검출 및 인식을 위한 종단간(end-to-end) 시스템을 기술한다. 개시 된 시스템 및 방법은 손 제스처의 실시간 검출 및 인식을 가능하게 한다. 본 명세서에 기술된 다양한 예들은 장거리 및/또는 저조도 시나리오에서 기존의 접근 방식보다 더 높은 정확도로 손 제스처의 검출 및 인식을 가능 하게 할 수 있다. 일부 예들에서, 본 개시는 제스처 입력을 처리하기 위한 방법을 기술한다. 상기 방법은 수신된 입력 프레임에 정의된 가상 제스처-공간을 결정하는 단계 - 상기 가상 제스처-공간은 하나 이상의 사용자의 순위가 매겨진 사 용자 목록으로부터 주요 사용자와 연관됨 -; 손을 검출하고 추적하기 위해 상기 수신된 입력 프레임을 상기 가 상 제스처 공간에서만 처리하는 단계; 상기 손을 검출하고 추적함으로써 생성된 손 경계 상자를 사용하여, 상기 손과 연관된 제스처 입력을 결정하기 위해 제스처 분류를 수행하는 단계; 및 상기 결정된 제스처 입력과 연관된 명령 입력의 처리를 야기하기 위해 상기 결정된 제스처 입력을 출력하는 단계를 포함한다. 위의 예들 중 임의의 예에서, 가상 제스처 공간을 결정하는 단계는 상기 하나 이상의 사용자를 검출하기 위해 상기 입력 프레임을 처리하는 단계; 상기 검출된 하나 이상의 사용자에 기초해서 상기 순위가 매겨진 사용자 목 록을 생성하는 단계 - 상기 주요 사용자는 상기 순위가 매겨진 사용자 목록에서 가장 높은 순위의 사용자로서 식별됨 -; 및 상기 주요 사용자의 검출된 해부학적 특징에 기초해서 상기 가상 제스처-공간을 생성하는 단계를 포함할 수 있다. 위의 예들 중 임의의 예에서, 상기 입력 프레임을 처리하는 단계는 상기 입력 프레임을 처리하기 위한 관심 영 역(ROI)을 선택하는 단계 - 상기 ROI는 상기 입력 프레임의 전체 영역보다 작은 영역을 정의함 -를 포함할 수 있고, 상기 ROI는 정의된 ROI 시퀀스로부터 선택되고, 상기 ROI 시퀀스는 순차적으로 수신된 복수의 입력 프레 임 각각을 처리하기 위한 복수의 ROI를 정의한다. 위의 예들 중 임의의 예에서, 상기 제스처 입력을 결정하는 단계는 상기 주요 사용자와 연관된 상기 가상 제스 처-공간에서 검출된 상기 손과 연관된 유효하지 않은 제스처 입력을 결정하는 단계; 상기 순위가 매겨진 사용자 목록에서 다음으로 높은 순위의 사용자를 새로운 주요 사용자로서 선택하는 단계; 및 상기 새로운 주요 사용자 를 사용하여 상기 방법을 반복하는 단계를 포함할 수 있다. 위의 예들 중 임의의 예에서, 상기 입력 프레임을 처리하는 단계는 상기 수신된 입력 프레임과 연관된 저조도 조건을 결정하는 단계; 및 상기 저조도 조건에 응답하여 상기 수신된 입력 프레임의 픽셀 값을 조정하기 위해 자동으로 이미지 조정을 수행하는 단계를 포함할 수 있다. 위의 예들 중 임의의 예에서, 상기 입력 프레임은 상기 손을 검출하고 추적하기 위해 훈련된 조인트 신경망을 사용하여 처리될 수 있고, 상기 훈련된 조인트 신경망은 훈련된 경계 상자 정제 컨볼루션 신경망에 대한 사이드 브랜치 연결을 갖는 훈련된 제스처 분류 컨볼루션 신경망을 포함할 수 있다. 위의 예들 중 임의의 예에서, 제스처 분류를 수행하는 단계는 상기 수신된 입력 프레임에서 검출된 상기 손과 연관된 제스처 클래스를 식별하는 단계; 이전 입력 프레임과 연관된, 이전 제스처 상태로부터 현재 제스처 상태 로의 상태 전환을 결정하는 단계 - 상기 상태 전환은 상기 식별된 제스처 클래스에 기초해서 결정됨 -; 및 상기 현재 제스처 상태와 연관된 상기 제스처 입력을 결정하는 단계를 포함할 수 있다. 위의 예들 중 임의의 예에서, 상기 수신된 입력 프레임은 상기 수신된 입력 프레임을 캡처하는데 사용되는 이미 지 캡처 디바이스의 프레임 캡처 주파수보다 낮은 주파수에서 수신되고 처리될 수 있다. 일부 예들에서, 본 개시는 기계 실행가능 명령어들을 저장하는 메모리에 결합된 프로세싱 디바이스를 포함하는 장치를 설명한다. 상기 명령들은 상기 처리 디바이스에 의해 실행될 때 상기 장치로 하여금 위에 설명된 방법 들 중 하나를 수행하게 한다. 위의 예들 중 임의의 예에서, 상기 장치는 제스처 제어 디바이스일 수 있다. 위의 예들 중 임의의 예에서, 상기 장치는 상기 입력 프레임을 캡처하기 위한 카메라를 포함할 수 있다. 위의 예들 중 임의의 예에서, 상기 제스처 제어 디바이스는 텔레비전; 스마트폰; 태블릿; 차량 결합 디바이스; 사물 인터넷 디바이스; 인공 현실 디바이스; 또는 가상 현실 디바이스 중 하나일 수 있다. 일부 예들에서, 본 개시는 기계 실행가능 명령어들이 저장된 컴퓨터 판독가능 매체를 설명한다. 장치의 처리 디바이스에 의해 실행될 때 상기 명령어들은 상기 장치로 하여금 위에서 설명된 방법들 중 어느 하나를 수행하 게 한다. 본 명세서에 개시된 예들은 (순위가 매겨진 사용자 목록으로부터) 주요 사용자로부터의 제스처 입력만을 검출함 으로써 제스처 입력의 보다 효율적이고 그리고/또는 정확한 검출을 가능하게 할 수 있다. 훈련된 얼굴 또는 손 분류기로 더 나은 성능을 가능하게 할 수 있는 적응형 ROI 기술도 설명된다. 적응형 ROI는 프로세서 요구 사항 을 줄이는데도 도움이 될 수 있다. 저조도 조건이 검출될 때 조명을 조정하여 손 검출을 개선하는데 도움이 되 는 자동 이미지 조정 기술도 설명된다. 일부 예에서, 검출된 손의 경계 상자를 정제함으로써 제스처 분류를 개 선하는데 도움이 될 수 있는 조인트 신경망이 설명된다."}
{"patent_id": "10-2022-7035829", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다양한 예들에서, 본 개시는 디바이스의 제스처 기반 제어를 가능하게 하는 방법들 및 시스템들을 설명한다. 예를 들어, 제스처 제어 디바이스는, 다른 가능성 중에서, 텔레비전(예를 들어, 스마트 TV), 모바일 통신 디바 이스(예를 들어, 스마트폰), 태블릿 디바이스, 데스크탑 디바이스, 차량 기반 디바이스(예를 들어, 대시보드 디 바이스), 또는 스마트 스피커일 수 있다. 본 명세서에 설명된 제스처 기반 제어는 디스플레이 출력이 있거나 없는 사용자 인터페이스를 포함하여, 제스처 제어 디바이스에 의해 제공되는 임의의 사용자 인터페이스와의 사 용자 상호 작용을 가능하게 하는데 사용될 수 있다. 본 개시의 예들은 또한 다른 가능성 중에서 증강 현실 (AR), 가상 현실(VR), 또는 비디오 게임 애플리케이션을 위해 구현될 수 있다. 단순화를 위해, 본 개시는 디스플레이 출력을 갖는 제스처 제어 디바이스(예를 들어, 스마트 TV, 스마트폰, 또 는 태블릿)의 맥락에서 예들을 기술하고, 비디오의 재생과 상호 작용하기 위한 제스처 기반 제어를 기술한다. 그러나, 본 출원은 이러한 실시예들에 국한되지 않고 다양한 애플리케이션에서 다양한 디바이스의 제스처 기반 제어에 사용될 수 있음을 이해해야 한다. 도 1은 제스처 제어 디바이스와 상호 작용하는 사용자의 예를 도시한다. 이 단순화된 도면에서, 제스 처 제어 디바이스는 시야(field of view: FOV)에서 프레임들의 시퀀스(예를 들어, 디지털 이미지)를 캡처하는 카메라를 포함하고, 여기서 프레임들의 시퀀스가 제스처 입력을 포함한다. FOV는 이하에서 더 논의되는 바와 같이 사용자의 적어도 일부, 특히, 사용자의 얼굴 및 손을 포함할 수 있다. 특히, 실생활 사용(예를 들어, 실험실 설정의 외부)에서 FOV는 일반적으로 사용자보다 더 많은 것을 포함한다. 예를 들어, FOV는 또한 다른 객체, 배경 장면, 또는 가능한 다른 인간을 포함할 수 있다. 제스 처 제어 디바이스는 카메라 대신 사용자로부터 제스처 입력을 감지할 수 있는 다른 센서, 예를 들어, 프레임들의 시퀀스(예를 들어, 적외선 이미지 센서)를 캡처하는 임의의 이미지 캡처 디바이스/센서(예를 들어, 적외선 이미지 센서)를 구비할 수 있고, 프레임들의 시퀀스는 이미지 캡처 디바이스/센서의 FOV에서 제스처 입력을 포함한다. 제스처 제어 디바이스는 또한 비디오와 같은 출력을 제공하는 디스플레이 를 포함한다. 제스처 제어 디바이스는 도 1에 도시된 실시예에서 카메라를 포함하지만, 다른 실시예 에서 카메라가 제스처 제어 디바이스와 통신하는 주변 디바이스일 수 있다. 도 2는 제스처 제어 디바이스의 일부 구성요소를 도시하는 블록도이다. 제스처 제어 디바이스의 예 시적인 실시예가 아래에 도시되고 논의되지만, 도시된 것과 상이한 구성요소들을 포함할 수 있는 본 명세서에 개시된 예들을 구현하기 위해 다른 실시예들이 사용될 수 있다. 도 2는 각 구성요소의 단일 인스턴스를 도시하 지만, 도시된 각 구성요소의 여러 인스턴스가 있을 수 있다. 제스처 제어 디바이스는 프로세서, 마이크로프로세서, 애플리케이션 특정 집적 회로(application-specific integrated circuit: ASIC), 필드 프로그램가능 게이트 어레이(field-programmable gate array: FPGA), 전용 논리 회로, 전용 인공 지능 프로세서 유닛, 또는 이들의 조합과 같은 하나 이상의 처리 디바이스를 포함한 다. 제스처 제어 디바이스는 또한 카메라와 같은 입력 디바이스 및 디스플레이와 같은 출력 디바이스를 인터페이스하는 하나 이상의 입/출력(I/O) 인터페이스를 포함한다. 제스처 제어 디바이스 는 다른 입력 디바이스(예를 들어, 버튼, 마이크, 터치스크린, 키보드 등) 및 다른 출력 디바이스(예를 들어, 스피커, 진동 유닛 등)를 포함할 수 있다. 카메라(또는 다른 입력 디바이스)는 제스처 입력을 포함하는 프레임들의 시퀀스를 캡처하기 위한 능력을 가질 수 있다. 캡처된 프레임들은 I/O 인터페이스(들)에 의해 저장(예를 들어, 내부 버퍼링)을 위해 메모리(들)에 제공될 수 있고 실시간 또는 거의 실시간으로(예를 들 어, 10ms 이내) 처리되도록 처리 디바이스(들)에 제공될 수 있다. 제스처 제어 디바이스는 네트워크(예를 들어, 인트라넷, 인터넷, P2P 네트워크, WAN 및/또는 LAN) 또는 다 른 노드와의 유선 또는 무선 통신을 위한 하나 이상의 선택적 네트워크 인터페이스를 포함할 수 있다. 네 트워크 인터페이스는 네트워크내 및/또는 네트워크간 통신을 위한 유선 링크(예를 들어, 이더넷 케이블) 및/또는 무선 링크(예를 들어, 하나 이상의 안테나)를 포함할 수 있다. 제스처 제어 디바이스는 휘발성 또는 비휘발성 메모리(예를 들어, 플래시 메모리, 랜덤 액세스 메모리 (RAM) 및/또는 읽기 전용 메모리(ROM))를 포함할 수 있는 하나 이상의 메모리를 포함한다. 비일시적 메모 리(들)는 예를 들어 본 개시에 기술된 예들을 실행하기 위해 처리 디바이스(들)에 의한 실행을 위한 명령어를 저장할 수 있다. 예를 들어, 메모리(들)는 적응형 제스처 감지 시스템을 실행하기 위한 명 령어를 포함할 수 있다. 메모리(들)는 운영 체제 및 다른 애플리케이션/기능을 구현하기 위한 것과 같은 다른 소프트웨어 명령어를 포함할 수 있다. 메모리(들)는 또한 디스플레이를 통해 출력으로서 제공 될 수 있는 비디오 콘텐츠 파일과 같은 데이터를 포함할 수 있다. 일부 예에서, 제스처 제어 디바이스는 또한 솔리드 스테이트 드라이브, 하드 디스크 드라이브, 자기 디스 크 드라이브 및/또는 광 디스크 드라이브와 같은 하나 이상의 전자 저장 유닛(도시되지 않음)을 포함할 수 있다. 일부 예에서, 하나 이상의 데이터 세트 및/또는 모듈은 외부 메모리(예를 들어, 제스처 제어 디바이스 와 유선 또는 무선 통신하는 외부 드라이브)에 의해 제공되거나 일시적 또는 비일시적 컴퓨터 판독가능 매 체에 의해 제공될 수 있다. 비일시적 컴퓨터 판독가능 매체의 예는 RAM, ROM, EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리, CD-ROM, 또는 기타 휴대용 메모리 저 장 장치를 포함한다. 제스처 제어 디바이스의 구성요소들은 예를 들어 버스를 통해 서로 통신할 수 있다. 본 개시 내용을 이해하는 것을 돕기 위해, 제스처에 대한 논의가 먼저 제공된다. 본 개시에서, 손 제스처는 일 반적으로 제스처 제어 디바이스에 의해 특정 명령 입력으로서 인식될 수 있는 뚜렷한 손 모양으로 정의된 다. 손 제스처는 모양과 움직임이 다를 수 있다. 예를 들어, 손 제스처는 도 3a 내지 도 3h에 도시된 클래스 중 하나에 속하는 것으로 제스처 제어 디바이스에 의해 인식될 수 있다. 카메라에 의해 캡처된 프레 임들(예를 들어, 이미지들)의 시퀀스에 존재하는 도 3a 내지 도 3h에 도시된 것과 같은 손 제스처를 제스처 입 력이라고 부른다. 도 3a는 \"열린 손\" 제스처를 도시한다; 도 3b는 \"주먹\"(또는 \"닫힌 손\") 제스처를 도시한다; 도 3c는 \"핀치 열림\" 제스처를 도시한다; 도 3d는 \"핀치 닫힘\" 제스처를 도시한다; 도 3e는 \"음소거\"(또는 \"침 묵\") 제스처를 도시한다; 도 3f는 \"좋아요\"(또는 \"승인\") 제스처를 도시한다; 도 3g는 \"기타\"(또는 \"다 음\") 제스처를 도시한다; 도 3h는 \"터치\"(또는 \"선택\") 제스처를 도시한다. 다른 제스처 클래스는 제 스처 제어 디바이스에 의해 인식될 수 있다. 이러한 제스처 클래스에 기초해서, 손 제스처는 정적 제스처와 동적 제스처로 분류될 수 있다. 정적 제스처는 단일 제스처 클래스에 의해 정의되고, 일반적으로 고정된 위치(예를 들어, 약간의 오차 범위를 허용하는 정의된 영역 내)에서 적어도 정의된 시간(예를 들어, 1초) 동안 또는 카메라에 의해 캡처된 프레임들의 시퀀스에 서 적어도 정의된 수의 연속 프레임들(예를 들어, 100 프레임) 동안 유지된다. 예를 들어, 정적 열린 손 제스 처는 제스처 제어 디바이스(예를 들어, 적응형 제스처 감지 시스템)에 의해 인식될 수 있고, 비 디오 재생의 맥락에서 일시 정지(pause) 명령 입력으로 해석될 수 있다. 정적 주먹 제스처는 제스처 제어 디바이스에 의해 인식될 수 있고, 비디오 재생의 맥락에서 중지(stop) 명령 입력으로 해석될 수 있다. 동적 제스처는 하나 이상의 제스처 클래스, 위치 및/또는 움직임의 조합으로 정의된다. 예를 들어, 동적 제스 처는 시간이 지남에 따라 위치가 변하는 단일 제스처 클래스일 수 있다(예를 들어, 카메라에 의해 캡처된 프레임들의 시퀀스에 걸쳐 상이한 위치에서 검출됨). 위치가 변하는 열린 손 제스처는 제스처 제어 디바이 스(예를 들어, 적응형 제스처 감지 시스템)에 의해 인식되고 디스플레이된 아이콘과 같은 인터페이스 객체를 드래그하거나 이동시키는 명령으로 해석될 수 있다.도 4a는 제스처 클래스의 조합일 수 있는 다른 유형의 동적 제스처를 예시한다. 도 4a에서, 동적 제스처는 터 치 제스처와 그 후의 주먹 제스처의 조합을 포함한다. 이 동적 제스처는 제스처 제어 디바이스 (예를 들어, 제스처 제어 디바이스에서 실행되는 적응형 제스처 감지 시스템)에 의해 인식되고 인터 페이스 객체를 선택한 다음 클릭하기 위해 마우스 디바이스를 사용하는 것과 균등한 명령 입력으로 해석될 수 있다. 다른 예에서, 핀치 열림 제스처와 그 후의 핀치 닫힘 제스처가 함께 \"핀치\" 동적 제스처로서 인 식될 수 있고, 이는 제스처 제어 디바이스에 의해 인식될 수 있고 줌 아웃(zoom out) 명령 입력으로 해석 될 수 있다. 더 복잡한 동적 제스처에는 제스처 클래스의 조합과 위치의 변경이 모두 포함될 수 있다. 예를 들어, 도 4a에 서, 터치 제스처가 시간 경과에 따른 위치 변화로 검출되고(예를 들어, 카메라 디바이스에 의해 캡처 된 프레임들의 시퀀스의 서로 다른 위치에서 검출됨) 주먹 제스처가 뒤따르면, 제스처 제어 디바이스 (예를 들어, 제스처 제어 디바이스에서 실행되는 적응형 제스처 감지 시스템)는 복잡한 동적 제스처 를 주먹 제스처가 검출될 때 클릭 명령이 뒤따르는 터치 제스처의 위치 변경을 반영하는 방식으로 디스 플레이된 커서를 이동하기 위한 명령 입력으로 해석할 수 있다. 다른 예에서, 핀치 열림 제스처에 이어 핀치 닫힘 제스처, 핀치 닫힘 제스처의 위치 변경, 그리고 다시 핀치 열림 제스처가 뒤따르는 것은 제스처 제어 디바이스(예를 들어, 제스처 제어 디바이스(10 0)에서 실행되는 적응형 제스처 감지 시스템)에 의해 함께 동적 \"핀치-드래그-릴리스(pinch-drag- release)\" 제스처로 인식될 수 있다. 위치 변경을 포함하는 동적 제스처는 특정 위치 변경에 따라 다른 입력으 로 해석될 수 있다는 점에 유의해야 한다. 예를 들어, 도 4b에 도시된 바와 같이 핀치 닫힘 제스처의 위치 에서 수직적 변경(또는 수직 \"드래그\")가 있는 핀치-드래그-릴리스 제스처는 비디오 재생의 맥락에서 볼륨 을 변경하는 명령 입력으로 해석될 수 있다. 대조적으로, 도 4c에 도시된 바와 같이, 핀치 닫힘 제스처의 위치에서 수평적 변경이 있는 핀치-드래그-릴리스 제스처는 비디오 재생의 맥락에서 비디오 재생의 맥락에 서 비디오에서 앞으로 또는 뒤로 이동하기 위한 명령 입력으로 해석될 수 있다. 이러한 핀치-드래그-릴리스 동 적 제스처는 사용자가 제스처 제어 디바이스와 상호 작용하는 직관적이고 편리한 방식을 제공할 수 있고, 또한 제스처 입력이 비교적 높은 정확도로 제스처 제어 디바이스(예를 들어, 제스처 제어 디바이스에 서 실행되는 적응형 제스처 감지 시스템)에 의해 검출 및 인식되도록 할 수 있다. 특히, 핀치-드래그-릴 리스 동적 제스처는 동적 제스처를 정적 제스처 구성요소로 분해함으로써 검출 및 인식될 수 있다(예를 들어, 핀치 열림 제스처, 핀치 닫힘 제스처, 다음으로 다른 핀치 열림 제스처). 손 제스처 인식을 위한 일부 전통적인 기존의 컴퓨터 비전 기술은 카메라에 의해 캡처된 프레임들(예를 들 어, 디지털 이미지들)의 시퀀스에서 손 모양 및 위치에 기초해서 손 검출, 손 모양 분류, 및 제스처 인식을 수 행한다. 제스처 분할 및 인식은 일반적으로 계산 비용이 많이 든다. 또한, 프레임들의 시퀀스가 제어되지 않 은 아마도 복잡한 환경에서(예를 들어, 배경이 어수선한 경우, 사용자가 디바이스에서 멀리 떨어져 있는 경우, 저조도 환경에 있는 경우, 또는 FOV에 여러 사람이 있는 경우) 제스처 제어 디바이스의 카메라에 의 해 캡처될 때, 손 제스처(정적이든 동적이든)를 검출하고 인식하기 위해 카메라에 의해 캡처된 프레임들의 시퀀스를 처리하는 것은 종종 아려운 일이다. 다양한 예들에서, 본 개시는 제스처 제어 디바이스의 카메라에 의해 캡처된 프레임들의 시퀀스에서 더 정확하고 효율적인 제스처 검출 및 인식을 가능하게 하는 솔루션들을 기술한다. 일부 예들에서, 본 개시는 제스처 검출 을 위해 처리되야 할 카메라에 의해 캡처된 프레임들의 시퀀스의 각 프레임에서 영역을 줄이기 위해 가상 제스 처-공간을 사용하는 적응적 제스처 감지 시스템을 기술한다. 일부 예들에서, 본 개시는 또한 동적 제스처를 인 식하기 위한 (움직임 기반 대신에) 상태(state) 기반 접근법을 기술한다. 본 개시는 추가적인 양태들 및 특징 들을 포함한다는 것이 이해될 것이다. 본 개시는 프레임들의 시퀀스에서 손 제스처를 검출하기 위해 카메라에 의해 캡처된 프레임들의 시퀀스의 각 프 레임을 처리하기 위해 적어도 초기에 사용자의 얼굴을 둘러싸는 공간으로 정의된 가상 제스처-공간의 사용을 기 술한다. 가상 제스처-공간은 카메라에 의해 캡처된 FOV보다 작아야 한다. 가상 제스처-공간 내에서 검출되고 인식된 손 제스처(예를 들어, 제스처 입력)만 유효한 손 제스처(예를 들어, 제스처 입력)로서 고려될 수 있다. 가상 제스처-공간을 사용하면 프레임들의 시퀀스(예를 들어, 특히 복잡한 배경에서)에서의 손 제스처 의 검출에서 위양성(false positive)을 줄일 수 있고, 손 제스처를 특정 사용자와 더 쉽게 연관시킬 수 있으며, 손 제스처(예를 들어, 제스처 입력)를 검출하고 인식하기 위해 프레임들의 시퀀스를 보다 효율적으로 처리할 수 있다.도 5는 적응형 제스처 감지 시스템의 일부 예시적인 서브시스템을 도시하는 블록도이다. 이 예에서, 적응 형 제스처 감지 시스템은 가상 제스처-공간 서브시스템 및 제스처 파싱(parsing) 서브시스템을 사용하여 구현될 수 있다. 이하의 예에서, 적응형 제스처 감지 시스템은 두 서브시스템(310, 320)을 모두 포함하거나 두 서브시스템(310, 320)의 기능을 제공하는 것으로 기술될 것이다. 그러나, 다른 예에서, 적응형 제스처 감지 시스템은 서브시스템(310, 320) 중 하나만을 포함(또는 그 기능을 제공)할 수 있다. 예를 들 어, 적응형 제스처 감지 시스템은 (예를 들어, 가상 제스처-공간 서브시스템을 사용하여) 가상 제스 처-공간의 적응형 생성 및 가상 제스처-공간 내에 있는 제스처 제어 디바이스의 카메라에 의해 캡처 된 프레임들의 시퀀스에서 손 제스처의 검출만을 제공할 수 있고, 제스처 인식 및 파싱은 제스처 제어 디바이스 의 다른 구성요소에 의해 수행될 수 있다(예를 들어, 임의의 적절한 기존 제스처 인식 기술을 사용함). 다른 예에서, 적응형 제스처 감지 시스템은 (예를 들어, 제스처 파싱 서브시스템을 사용하여) 제스처 인식 및 다수의 사용자 관리만을 제공할 수 있고, 제스처 검출은 제스처 제어 디바이스의 다른 구성요소에 의해 수행될 수 있다(예를 들어, 임의의 적절한 기존 제스처 검출 기술을 사용함). 일부 예에서, 적응형 제스처 감지 시스템은 별개의 서브시스템(310, 320)을 포함하지 않을 수 있다. 대신 에, 서브시스템(310, 320)의 서브블록이 적응형 제스처 감지 시스템 자체의 서브블록으로 간주될 수 있다. 따라서, 별개의 서브시스템(310, 320)을 사용하는 적응형 제스처 감지 시스템의 구현은 선택적이다. 적응형 제스처 감지 시스템은 얼굴 검출 및 추적 서브시스템, 가상 제스처-공간 생성 서브시스템 , 손 검출 및 추적 서브시스템, 제스처 인식 서브시스템, 및 사용자 목록을 포함한다. 얼 굴 검출 및 추적 서브시스템, 가상 제스처-공간 생성 서브시스템, 및 손 검출 및 추적 서브시스템 은 가상 제스처-공간 서브시스템의 일부일 수 있고; 제스처 인식 서브시스템 및 사용자 목록 은 제스처 파싱 서브시스템의 일부일 수 있다. 일부 예들에서, 얼굴 검출 및 추적 서브시스템 대신에 또는 이에 더하여, 카메라에 의해 캡처된 프레 임들의 시퀀스에서 다른 해부학적 특징(예를 들어, 전체 인체 또는 인간 몸통)의 검출 및 추적을 위해 다른 서 브시스템(도시되지 않음)이 사용될 수 있다. 아래에서 더 논의되는 바와 같이, 가상 제스처-공간을 생성하기 위한 기초로서 사람의 얼굴 대신에 또는 그에 더하여 다른 해부학적 특징이 사용될 수 있다. 단순화를 위해, 본 개시는 카메라에 의해 캡처된 프레임들의 시퀀스에서 얼굴 검출 및 추적의 사용에 초점을 맞출 것이지 만, 이것이 제한적인 의도가 아님을 이해해야 한다. 카메라에 의해 캡처된 프레임들의 시퀀스의 프레임은 적응형 제스처 감지 시스템에 대한 입력 프레임 으로서 수신된다. 얼굴 검출 및 추적 서브시스템은 입력 프레임에 대해 얼굴 검출을 수행한다. 얼굴 검 출 및 추적 서브시스템은 입력 프레임에서 얼굴을 검출하고 검출된 얼굴에 대한 경계 상자를 생성하기 위 해 임의의 적절한 얼굴 검출 기술을 사용할 수 있다. 경계 상자는 입력 프레임에서 검출된 얼굴을 중심으로 둘 러싸는 2차원(2D) 또는 3차원(3D) 상자일 수 있다. 입력 프레임에서 검출된 얼굴에 대해 생성된 경계 상자는 가상 제스처-공간을 정의하기 위해 가상 제스처-공간 생성 서브시스템에 의해 사용된다. 본 명세서에서, 가상 제스처-공간(또는 간단히 제스처-공간)은 입력 프레임에서 정의되고 손 제스처(예를 들어, 제스처 입력)가 검출될 수 있는 사용자의 실생활 환경의 가상 공간에 매핑되는 2차원 또는 3차원 공간을 의미한다. 즉, 사용자는 제스처 제어 디바이스에 명령 입 력을 제공하기 위해 가상으로 정의된 2D 또는 3D 가상 제스처-공간 내에서 손 제스처를 만들 수 있다. 가상 제 스처-공간 외부에서 수행되는 제스처는 검출되지 않고 제스처 제어 디바이스에 의해 명령 입력으로 인식되 지 않을 수 있다. 가상 제스처-공간의 차원은 얼굴의 경계 상자의 차원과 매칭되거나 매칭되지 않을 수 있다 (예를 들어, 얼굴의 경계 상자는 2D일 수 있고 가상 제스처 공간은 3D일 수 있음). 가상 제스처-공간 생성 서브시스템에 의해 정의된 가상 제스처-공간은 카메라에 의해 캡처된 프레임들의 시퀀스에서 손 검출 및 추적을 수행하기 위해 손 검출 및 추적 서브시스템에 의해 사용된다. 특히, 손 검 출 및 추적 서브시스템은 프레임들의 시퀀스에서 손을 검출하고 이를 추적하기 위해 입력 프레임 및 상기 프레임들의 시퀀스에서 각 후속 프레임 내에서 정의된 가상 제스처-공간만을 분석할 수 있다. 손 검출 및 추적 서브시스템은 입력 프레임에서 손을 검출하고 검출된 손에 대한 2D 또는 3D 경계 상자를 정의하기 위해 임 의의 적절한 손 검출 기술을 사용할 수 있다. 일부 예에서, 얼굴 검출 및 추적 서브시스템은 얼굴 검출을 수행하도록 구성된 훈련된 신경망을 포함할 수 있다. 유사하게, 손 검출 및 추적 서브시스템은 손 검출을 수행하도록 구성된 다른 훈련된 신경망을 포함 할 수 있다. 예를 들어, 얼굴 또는 손 검출을 위해 구성된 적절한 훈련된 신경망은 ResNet34(예를 들어, He,Kaiming, et al. \"이미지 인식을 위한 딥 레지듀얼 러닝.\" 컴퓨터 비전 및 패턴 인식에 관한 2016 IEEE 컨퍼런 스 회보에 설명됨)와 같은 잔여 신경망(ResNet) 아키텍처 기반 YoloV3(예를 들어, Redmon et al. \"Yolov3: 점 진적 개선\", arXiv preprint arXiv:1804.02767, 2018에 설명됨)를 사용하는 것과 같은 훈련된 객체 검출기일 수 있다 . 얼굴 또는 손 검출을 위해 구성된 적절한 훈련된 신경망의 다른 예는, MobileNetV2(예를 들어, Sandler et al. \"Mobilenetv2: 역잔차 및 선형 병목 현상.\" 컴퓨터 비전 및 패턴 인식에 관한 2018 IEEE 컨퍼 런스 회보에 설명됨)와 같은 CNN(Convolutional Neural Network) 아키텍처에 기초한 멀티박스 SSD와 같은 훈련 된 단일 샷 검출기(SSD)일 수 있다(예를 들어, Liu et al. \"Ssd: 단일 샷 멀티박스 검출기.\" 컴퓨터 비전에 관 한 유럽 회의. Springer, Cham, 2016에 설명됨) 얼굴 및 손 추적은 Lucas-Kanade 광학 흐름 기술(Lucas et al. \"스테레오 비전에 적용한 반복적인 이미지 등록 기술.\" 영상 이해 워크숍, 1981에 설명됨)을 사용하여 얼굴 검출 및 추적 서브시스템 및 손 검출 및 추적 서브시스템에 의해 각각 수행될 수 있다. 검출된 손에 대해 정의된 경계 상자는 검출된 손의 형상의 제스처 클래스로서의 식별 및 분류를 수행하기 위해 제스처 인식 서브시스템에 의해 사용된다. 제스처 인식 서브시스템은 검출된 손의 형상을 특정 제스 처 클래스로 분류하기 위해 임의의 적절한 분류 기술을 사용할 수 있다. 예를 들어, 제스처 인식 서브시스템 은 제스처 클래스의 미리 정의된 세트에 따라 제스처를 분류하도록 훈련된 신경망(예를 들어, CNN)을 포함 할 수 있다. 신경망은 알려진 머신 러닝 알고리즘을 사용하여 신경망의 매개변수(예를 들어, 가중치)를 학습하 도록 훈련되었다. 훈련된 신경망은 검출된 손 제스처에 대한 경계 상자를 수신하고 경계 상자에 대응하는 제스 처 클래스의 미리 정의된 세트로부터 특정 제스처 클래스를 예측한다. 제스처 인식 서브시스템에 의해 예 측된 제스처 클래스는 적응형 제스처 감지 시스템으로부터 (예를 들어, 라벨(label)로서) 출력될 수 있다. 제스처 제어 디바이스의 소프트웨어 애플리케이션(예를 들어, 운영 체제)은 적응된 제스처 감지 시스템 에 의해 출력된 제스처 클래스를 명령 입력으로 변환할 수 있다. 제스처 클래스를 명령 입력으로 변환하 는 것은 애플리케이션에 따라 다를 수 있다. 예를 들어, 주어진 제스처 클래스는 제1 애플리케이션이 활성화될 때 제1 명령 입력으로 변환될 수 있지만, 제2 애플리케이션이 활성화될 때 제2 명령 입력으로 변환될 수 있다 (또는 유효하지 않은 것으로 간주될 수 있음). 일부 예들에서, 적응형 제스처 감지 시스템은 주요(primary) 사용자를 추적하기 위해 사용자 목록을 저장하고 유지한다. 예를 들어, 카메라의 FOV에 여러 사람이 있을 수 있다. 따라서 얼굴 검출 및 추 적 서브시스템은 카메라에 의해 FOV에서 캡처된 프레임들의 시퀀스에서 다수의 사람 얼굴을 검출 하고 추적할 수 있다. 검출된 각각의 얼굴은 제스처 제어 디바이스에 입력을 제공할 수 있는 잠재적으로 사용자인 사람에 속할 수 있다. 따라서, 검출된 각각의 인간이 현재 인식된 손 제스처(예를 들어, 제스처 입력)를 제공하지 않더라도 검출된 인간은 사용자(또는 잠재적 사용자)로 간주될 수 있다. 사용자 목록은 검출된 모든 사용자를 추적하고 일부 미리 정의된 기준(예를 들어, 사용자의 크기, 제스처 제어 디바이스 으로부터 사용자의 거리, 사용자의 시선이 제스처 제어 디바이스를 향하는지 여부 등에 기초하여)에 따라 검출된 사용자들의 순위를 매긴다. 사용자 목록에서 가장 높은 순위의 사용자는 주요 사용자로 간주될 수 있다. 주요 사용자와 연관된 프레임들의 시퀀스에서의 손 제스처(예를 들어, 제스처 입력)는 검출된 다른 사용 자와 연관된 프레임들의 시퀀스에서 검출된 다른 손 제스처(예를 들어, 제스처 입력)보다 우선순위가 높을 수 있다. 일부 예에서, 승인되거나 사전 등록된 사용자만이 사용자 목록에 포함될 수 있다. 예를 들어, 사 용자 프로파일이 승인되거나 사전 등록된 사용자와 연관될 수 있고, 사용자 프로파일은 승인되거나 사전 등록된 사용자가 (예를 들어, 적절한 얼굴 인식 기술 사용하여) 제스처 제어 디바이스에 의해 식별될 수 있게 하 는 데이터를 포함할 수 있다. 이러한 승인 또는 사전 등록된 사용자의 얼굴 인식은 적응형 제스처 감지 시스템 또는 제스처 제어 디바이스의 별도의 얼굴 인식 시스템에 의해 수행될 수 있다. 승인된 또는 사전 등록된 사용자만 포함하도록 사용자 목록을 제한함으로써, 디바이스의 승인되지 않은 제스처 기반 제 어가 회피될 수 있다. 추가적으로, 제스처 입력의 위양성 검출(false positive detection)이 감소될 수 있다. 적응 제스처 감지 시스템이 상이한 서브블록(또는 서브시스템)을 갖는 것으로 예시되어 있지만, 이것이 제 한하려는 의도가 아님을 이해해야 한다. 예를 들어, 적응형 제스처 감지 시스템은 더 많거나 더 적은 수 의 서브-블록(또는 서브시스템)을 사용하여 구현될 수 있거나, 임의의 서브-블록(또는 서브시스템)을 필요로 하 지 않을 수 있다. 또한, 특정 서브블록(또는 서브시스템)에 의해 수행되는 것으로 본 명세서에서 설명된 기능 은 대신에 다른 서브블록(또는 서브시스템)에 의해 수행될 수도 있다. 일반적으로, 적응형 제스처 감지 시스템의 기능은 다양한 적절한 방식으로 구현될 수 있고 본 개시의 범위 내에 남아 있을 수 있다.적응형 제스처 감지 시스템의 동작의 예가 이제 설명된다. 도 6은 예를 들어 가상 제스처-공간 서브시스템(및 서브시스템(312, 314, 316))을 사용하여 적응형 제스처 감지 시스템에 의해 수행될 수 있는 예시적인 방법을 도시하는 흐름도이다. 방법은 제스처 제 어 디바이스의 처리 디바이스에 의해 실행되는 소프트웨어의 루틴 또는 서브루틴에 의해 수행될 수 있다. 이러한 루틴 또는 서브루틴을 수행하기 위한 소프트웨어의 코딩은 본 개시와 관련하여 충분히 당업자의 범위 내에 있다. 방법은 도시 및 기술된 추가적인 또는 더 적은 단계 또는 동작을 포함할 수 있으며, 다 른 순서로 수행될 수도 있다. 예를 들어, 처리 디바이스에 의해 실행 가능한 컴퓨터 판독가능 코드는 컴 퓨터 판독가능 매체에 저장될 수 있다. 602에서, 프레임들의 시퀀스의 입력 프레임이 수신된다. 일반적으로 입력 프레임과 프레임들의 시퀀스의 입력 프레임에 대한 각 후속 프레임은 실시간 또는 거의 실시간으로 한 번에 하나씩 수신된다. 입력 프레임(및 각각 의 후속 프레임)은 카메라에 의해 캡처된 처리되지 않은 원시(raw) 디지털 이미지일 수 있거나 최소한으로 처리된(예를 들어, 정규화된) 디지털 이미지일 수 있다. 604에서, 적응형 제스처 감지 시스템은 입력 프레임에서 구별되는 해부학적 특징을 검출한다. 전체 입력 프레임은 단계 604에서 처리될 수 있다. 구별되는 해부학적 특징은 배경으로부터 쉽게 검출되고 구별될 수 있 는 사용자 신체의 임의의 부분일 수 있다. 일 예는 사람의 얼굴을 검출하는 것이다(예를 들어, 얼굴 검출 및 추적 서브시스템을 사용). 일부 상황에서는, 얼굴을 검출하기 어려울 수 있으며, 이 경우 다른 해부학적 특징(예를 들어, 인체 전체 또는 몸통)이 대신 검출될 수 있다. 위에서 언급한 바와 같이, 해부학적 특징은 임 의의 적절한 컴퓨터 비전 기술을 사용하는 것을 포함하여 임의의 적절한 접근법을 사용하여 검출될 수 있다. 구별되는 해부학적 특징을 검출하는 것은 해부학적 특징의 위치(예를 들어, 경계 상자 또는 좌표로 표시됨)를 결정하는 것을 포함할 수 있다. 606에서, 검출된 구별되는 해부학적 특징(예를 들어, 검출된 얼굴)에 기초해서 가상 제스처-공간이 생성된다(예 를 들어, 가상 제스처-공간 생성 서브시스템을 사용). 일부 예에서, 구별되는 해부학적 특징의 다수의 인 스턴스가 검출될 수 있으며(예를 들어, 카메라에 의해 FOV에서 캡처된 입력 프레임 내에 다수의 인간 이 있으면 다수의 얼굴이 검출될 수 있음), 이 경우 하나의 가상 제스처-공간이 구별되는 해부학적 특징의 각각 의 검출된 인스턴스에 대해 생성될 수 있다. 아래에서 추가로 논의되는 바와 같이, 일부 예에서 구별되는 해부 학적 특징들의 다수 인스턴스들이 검출될 때 생성된 가상 제스처-공간이 하나만 있을 수 있거나, 또는 가상 제 스처-공간(들)의 생성은 구별되는 해부학적 특징의 검출된 인스턴스들의 순위 또는 우선순위 지정에 기초할 수 있다. 가상 제스처-공간은 입력 프레임에서 검출된 각각의 해부학적 특징의 위치와 관련된 미리 정의된 방정식을 사용 하여 생성될 수 있다. 예를 들어, 가상 제스처-공간은 검출된 얼굴의 경계 상자에 대한 직사각형 공간을 계산 함으로써 생성될 수 있다. 몇 가지 예시적인 방정식이 아래에 추가로 제공된다. 선택적으로, 608에서, 제스처 제어 디바이스가 생성된 가상 제스처-공간에 대한 피드백을 사용자에게 제공할 수 있도록, 생성된 가상 제스처-공간에 대한 정보가 적응형 제스처 감지 시스템에 의해 제공될 수 있다. 예를 들어, 적응형 제스처 감지 시스템은 가상 제스처-공간의 좌표 또는 다른 매개변수를 나타내는 정보를 제공하여 제스처 제어 디바이스가 디스플레이 상에서 (예를 들어, 라이브 카메라 이미지 위에 오버레이로서) 사용자에 게 가상 제스처 공간의 표현을 렌더링할 수 있게 한다. 다른 예에서, 가상 제스처 -공간은 가상 제스처-공간에 대응하는 FOV만을 표시하기 위해 제스처 제어 디바이스에 의해 디스플레이 상에 렌더링된 삽입(inset) 또는 보조 윈도우를 가짐으로써 사용자에게 표현될 수 있다. 사용자(1 0)에게 피드백을 제공하는 다른 방식도 적합할 수 있다. 610에서, (예를 들어, 손 검출 및 추적 서브시스템을 사용하여) 생성된 가상 제스처-공간의 입력 프레임에 서 손이 검출된다. 검출된 손은 입력 프레임에서 손이 검출된 각각의 가상 제스처-공간과 연관(예를 들어, 라 벨링)될 수 있다. 생성된 가상 제스처-공간이 여러 개이면, 입력 프레임에서 생성된 각각의 가상 제스처-공간 에서 손을 검출하려는 시도가 이루어질 수 있다. 입력 프레임의 주어진 가상 제스처-공간에서 손이 검출되지 않으면, 주어진 가상 제스처-공간이 무시되거나 폐기될 수 있다. 입력 프레임의 생성된 가상 제스처-공간(들) 중 어느 것에서도 손이 검출되지 않으면, 입력 프레임에서 발견된 손 제스처(예를 들어, 제스처 입력)가 없는 것으로 결정될 수 있고, 방법은 프레임들의 시퀀스에서 다음 입력 프레임을 수신하기 위해 단계로 돌아갈 수 있다. 적어도 하나의 가상 제스처-공간에서 적어도 하나의 손이 검출된다고 가정하면, 방법은 선택적 단계로 진행한다. 선택적으로, 612에서, 입력 프레임의 주어진 가상 제스처-공간에서 둘 이상의 손이 검출되면, 하나의 주요 손이 주어진 가상 제스처-공간에서 식별될 수 있다. 주요 손은, 다른 가능성들 중에서, 예를 들어, 입력 프레임의 주어진 가상 제스처-공간에서 가장 큰 손; 입력 프레임의 주어진 가상 제스처-공간에서 검출된 구별되는 해부학 적 특징(예를 들어, 얼굴)에 가장 가까운 검출된 손; 또는 입력 프레임의 주어진 가상 제스처-공간에서 검출된 구별되는 해부학적 특징(예를 들어, 얼굴)에 조도 및/또는 색조가 가장 가까운 검출된 손에 기초하여 식별될 수 있다. 입력 프레임의 주어진 가상 제스처-공간에서 한 손만 검출되는 경우 이 한 손이 주요 손이라고 가정할 수 있다. 614에서, 검출된 손(또는 주요 손)은 프레임들의 시퀀스의 입력 프레임에 대한 후속 프레임에서 각각의 가상 제 스처-공간에서(예를 들어, 손 검출 및 추적 서브시스템을 사용하여) 추적된다. 검출된 손(또는 주요 손) 의 추적은 각 후속 프레임을 처리하여 수행된다. 각 후속 프레임에서 손(또는 주요 손)을 검출하고 추적하는 것으로부터의 정보는 추가 분석 및 파싱을 위해 제공된다. 예를 들어, 후속 프레임에서 검출된 손을 추적하기 위해 경계 상자 및 선택적 식별자가 생성될 수 있다. 그 다음, 경계 상자(및 선택적 식별자)는 분석 및 파싱을 위해 (예를 들어, 제스처 인식 서브시스템에) 제공될 수 있다. 일부 예에서, 방법은 가상 제스처-공간 서브시스템만을 사용하여 적응형 제스처 감지 시스템에 의해 구현될 수 있다. (도 5에 도시된 바와 같이) 제스처 클래스를 출력하는 대신에, 적응형 제스처 감지 시스 템은 추적된 손(예를 들어, 경계 상자)에 대한 정보를 종래의 제스처 인식 시스템에 출력할 수 있고, 종래 의 제스처 인식 시스템은 상기 정보(예를 들어, 경계 상자)에 대한 손 분류 및 제스처 인식을 수행할 수 있다. 사용자의 손을 직접 검출하는 대신, 위에서 설명한 예는 입력 프레임에서 구별되는 해부학적 특징(예를 들어, 사용자의 얼굴)을 먼저 검출하고 검출된 기능에 기초해서 (입력 프레임의 FOV보다 작은) 가상 제스처-공간을 생 성한다. 그 다음 가상 제스처-공간에서만 손 검출이 입력 프레임에서 수행된다. 일반적으로 얼굴 검출이 손 검출보다 더 정확하고 신뢰할 수 있기 때문에 사용자의 얼굴은 가상 제스처-공간을 생성하기 위한 구별되는 해 부학적 특징으로서 사용될 수 있다. 손 검출을 가상 제스처-공간으로 제한함으로써, 손 검출을 위한 후속 프레 임을 처리하는데 필요한 처리가 단순화될 수 있고, 위양성이 감소될 수 있으며, 제스처 입력에 대한 후속 프레 임에서 주요 손을 식별하는 것이 더 용이할 수 있다. 일부 예에서, 방법은 카메라에 의해 캡처된 모든 프레임을 처리하는데 사용될 수 있다. 다른 예들에 서, 방법은 제스처 입력이 예상되는 경우에만 사용될 수 있다. 예를 들어, 방법은 (예를 들어, 키보 드 입력, 마우스 입력 또는 음성 입력을 통해) 입력을 수신하는 것에 응답하여 개시될 수 있다. 일부 예들에서, 방법은 인간 주의의 검출에 기초하여 개시될 수 있다. 예를 들어, 제스처 제어 디바이스 는 사람이 제스처 제어 디바이스를 직접 보고 있는지 여부를 결정하기 위해 주의 검출 기술을 사용할 수 있고(예를 들어, 눈 추적 소프트웨어를 실행할 수 있음), 방법은 제스처 제어 디바이스에 대한 인간 의 직접적인 시선이 검출되는 경우에만 개시될 수 있다. 검출된 인간의 주의에 응답하여 방법을 개시하여 제스처 입력의 위양성 또는 부정확한 해석을 방지하는 것이 유용할 수 있다. 도 7은 가상 제스처-공간이 검출된 얼굴에 기초해서 생성되는 방법의 예시적인 구현을 도시한다. 이 예에 서, 주요 사용자의 얼굴이 604에서 검출되었고, 얼굴이 606에서 가상 제스처-공간을 생성하기 위한 기 초로서 구별되는 해부학적 특징으로서 사용된다고 가정한다. 경계 상자는 상술한 바와 같은 컴퓨터 비전 기반 기술을 포함하는 임의의 적절한 얼굴 검출 기술을 사용하 여 얼굴에 대해 생성될 수 있다. 이 예에서, 경계 상자는 값들의 세트 에 의해 정의되 며, 여기서 와 는 각각 경계 상자의 앵커 포인트(예를 들어, 중심)의 x 및 y 좌표(적응형 제스처 감지 시스템에 의해 정의된 참조 프레임에서)를 정의하고, 와 는 각각 경계 상자의 너비와 높이를 정 의한다. 경계 상자에 기초해서, 가상 제스처-공간이 생성되고(예를 들어, 단계에서) 값들의 세 트 에 의해 정의되며, 여기서 와 는 각각 가상 제스처-공간의 앵커 포인트(예를 들어, 중앙)의 x 및 y 좌표(적응형 제스처 감지 시스템에 의해 정의된 참조 프레임)를 정의하고, 와 는 각 각 가상 제스처-공간의 폭과 높이를 정의한다. 예를 들어, 가상 제스처-공간을 생성하기 위해 다음방정식이 사용될 수 있다."}
{"patent_id": "10-2022-7035829", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 는 미리 정의된 상대 위치 매개변수이고, 는 미리 정의된 스케일 매개변수이다. 매개변수 들 와 는 가상 제스처-공간의 원하는 크기 및 가상 제스처-공간 내의 경계 상자의 원하는 위치에서의 결과에 따라 (예를 들어, 사용자 또는 제스처 제어 디바이스의 제조사에 의해) 미 리 정의될 수 있다. 일부 예들에서, 가상 제스처-공간은 얼굴의 경계 상자가 부분적으로 또는 전체적으로 가상 제스처-공간의 외부에 있도록 생성될 수 있다는 점에 유의해야 한다. 즉, 얼굴이 가 상 제스처-공간을 생성하기 위한 기초로 사용될 수 있지만, 가상 제스처-공간이 얼굴을 포함할 필요는 없다. 도 7의 예에서, 가상 제스처-공간은 직사각형 형태를 갖는 2D 공간으로 생성된다. 그러나 가상 제스처-공 간은 2D 공간 또는 3D 공간으로 생성될 수 있으며 임의의 기하학적 모양(예를 들어, 정사각형, 직사각형, 원 등), 규칙적인 모양, 또는 불규칙한 모양을 갖도록 생성될 수 있음을 이해해야 한다. 일부 예에서, 가상 제스처-공간은 특정 입력 기능을 구현하는데 사용될 수 있는 하나 이상의 부분 공간 (706, 708)을 추가로 정의할 수 있다. 부분 공간(들)(706, 708)은 검출된 얼굴의 특징에 기초해서 (예를 들어, 가상 제스처 공간 생성 서브시스템에 의해) 정의될 수 있다. 예를 들어, 왼쪽 부분 공간 및 오른쪽 부분 공간은, 검출된 얼굴의 검출된 눈 및 코의 위치에 기초해서 얼굴의 하부 왼쪽 및 오 른쪽 부분에 대응하는 가상 제스처-공간에서 정의될 수 있다. 왼쪽 부분 공간에서 터치(또는 포인트) 제 스처의 검출은 왼쪽 마우스 버튼 클릭 입력으로 해석될 수 있다. 유사하게, 오른쪽 부분 공간에서 터치 (또는 포인트) 제스처의 검출은 오른쪽 마우스 버튼 클릭 입력으로 해석될 수 있다. 이러한 방식으로, 정의된 부분 공간(706, 708)을 갖는 가상 제스처-공간은 가상 마우스를 구현하는데 사용될 수 있다. 일부 예에서, 도 4a에 예시된 동적 제스처는 가상 커서를 구현하기 위한 제스처 입력으로서 검출될 수 있다. 가상 커서는 터치(또는 포인트) 제스처가 추적됨에 따라 이동될 수 있고(그리고 사용자에게 디스플레이되는 시각적 오버레이를 통해 표시될 수 있음), 닫힌 손 제스처가 검출될 때 마우스 클릭 입력이 검출될 수 있다. 이러한 방식으로 가상 마우스가 구현될 수 있다. 도 8a 및 8b는 카메라에 의해 캡처된 프레임들의 시퀀스의 입력 프레임에서 검출된 사용자의 얼굴(1 2)에 기초해서 생성된 가상 제스처-공간의 다른 예를 도시한다. 도 8a에서, 가상 제스처-공간은 2D 공간이고 사용자의 얼굴과 손 모두를 포함하는 직사각형 형상을 갖는다(예를 들어, 도 7의 예와 유 사함). 도 8b에서, 가상 제스처-공간은 사용자의 얼굴과 손 모두를 포함하는 3D 공간이다. 가상 제스처-공간은 깊이 정보가 이용 가능한 경우 3D 공간으로 생성될 수 있다. 예를 들어, 깊이 정보는 비디오 분석 기술을 사용하여 프레임들의 시퀀스로부터 계산될 수 있다. 예를 들어, 제스처 제어 디바이스 가 (예를 들어, 컴퓨터 스테레오비전 기술을 사용하여) 깊이 정보를 계산하기 위해 두 개의 카메라를 사용할 수 있거나, 카메라가 (기존의 RGB 이미지 정보에 더하여) 깊이 정보를 생성할 수 있는 RGB-깊이 (RGBD) 카메라일 수 있거나, 또는 제스처 제어 디바이스가 RGB 이미지 정보 및 추가적인 대응 깊이 정보를 획득하기 위해 기존의 카메라 외에 ToF(비행 시간 측정, Time-of-Flight) 카메라를 포함할 수 있다. 일부 예들에서, 깊이 정보는 카메라 외에 깊이 정보를 캡처할 수 있는 센서(예를 들어, 적외선 센서)를 사용하 여 캡처될 수 있다. 3D 가상 제스처-공간의 사용은 깊이 기반 제스처 입력(예를 들어, 제스처 제어 디바 이스에 더 가까이 또는 더 멀리 손을 움직이는 것)이 검출되고 명령 입력으로서 인식되도록 하는데 유용할 수 있다. 일부 예들에서, 가상 제스처-공간은 프레임들의 시퀀스의 입력 프레임에서 검출된 구별되는 해부학적 특징(예를 들어, 얼굴)에 기초해서 초기에 생성되고 후속 프레임들에서 검출된 손에 기초해서 후속적으로 프레임들의 시퀀스의 입력 프레임으로 재정의되거나 업데이트될 수 있다. 이러한 방식으로, 가상 제스처-공간은 구별되는 해 부학적 특징으로부터 손이 멀리 이동하더라도 검출된 손의 위치를 따를 수 있다. 도 9는 예를 들어 가상 제스처 공간 서브시스템(및 서브시스템(312, 314, 316))을 사용하여 적응형 제스처 감지 시스템에 의해 수행될 수 있는 예시적인 방법을 도시하는 흐름도이다. 방법 000은 제스처 제어 디바이스의 처리 디바이스에 의해 실행되는 소프트웨어의 루틴 또는 서브루틴에 의해 수행될 수 있다. 이러한 루틴 또는 서브루틴을 수행하기 위한 소프트웨어의 코딩은 본 개시와 관련하여 충분히 당업자의 범위 내에 있다. 방법 000은 도시되고 설명된 추가적인 또는 더 적은 단계 또는 동작을 포함할 수 있으며 다른 순서로 수행될 수 있다. 예를 들어, 처리 디바이스에 의해 실행 가능한 컴퓨터 판독가능 코드는 컴퓨터 판독가능 매체에 저장될 수 있다. 방법은 위의 방법에 대해 설명된 단계와 유사한 단계를 포함할 수 있으며, 이 경우 유사한 단계는 다시 자세히 설명되지 않을 수 있다. 902에서, 프레임들의 시퀀스의 입력 프레임이 수신된다. 이 단계는 위에서 설명된 단계와 유사할 수 있다. 904에서, 적응형 제스처 감지 시스템은 입력 프레임에서 구별되는 해부학적 특징을 검출한다. 이 단계는 위에서 설명한 단계와 유사할 수 있다. 906에서, 입력 프레임에서 검출된 구별되는 해부학적 특징(예를 들어, 검출된 얼굴)에 기초해서 가상 제스처-공 간이 생성된다(예를 들어, 가상 제스처 공간 생성 서브시스템을 사용하여). 이 단계는 위에서 설명된 단 계와 유사할 수 있다. 선택적으로, 가상 제스처 공간을 나타내는 정보가 제공될 수 있다(예를 들어, 피드 백이 사용자에게 제공될 수 있도록). 간단하게 하기 위해, 방법의 이하의 설명에서는, 단지 하나의 가상 제스처-공간이 생성되는 것으로 가정한다. 그러나, 방법은 (예를 들어, 입력 프레임에서 구별되는 해부학적 특징의 다수의 검출된 인스턴스에 기초해서) 다수의 가상 제스처-공간이 생성되는 경우에 적응될 수 있다는 것을 이해해야 한다. 908에서, (예를 들어, 손 검출 및 추적 서브시스템을 사용하여) 입력 프레임의 가상 제스처-공간에서 손이 검출되고, 손이 검출된 가상 제스처 공간과 연관된다. 이 단계는 위에서 설명된 단계와 유사할 수 있다. 선택적으로, 주요 손이 식별되고 가상 제스처-공간과 연관될 수 있다. 910에서, 가상 제스처-공간은 검출된 손에 기초해서 재정의된다. 가상 제스처-공간을 재정의하는 것은 입력 프 레임에 대한 후속 프레임에서 (검출된 해부학적 특징과 관련된 대신에) 검출된 손과 관련된 미리 정의된 방정식 을 사용하여 가상 제스처-공간의 위치 및/또는 치수를 재계산하는 것을 포함할 수 있다. 예를 들어, 가상 제스 처-공간이 검출된 손의 경계 상자를 중심으로 하도록 가상 제스처 공간이 재정의될 수 있다. 일부 예시 방정식 은 아래에서 더 설명된다. 912에서, 재정의된 가상 제스처-공간이 저장된다. 이렇게 하면, 처음에 생성된 가상 제스처-공간(검출된 얼굴 과 같이 입력 프레임에서 검출된 구별되는 해부학적 특징에 기초해서 초기에 생성되었음) 대신에, 입력 프레임 에 대한 후속 프레임에서 손을 검출하고 추적하기 위한 기반으로서 재정의된 가상 제스처-공간(검출된 손을 기 반으로 재정의되었음)이 사용되는 것이 가능하다. 914에서, 입력 프레임에서 검출된 손(또는 주요 손)은 (예를 들어, 검출된 손 및 추적 서브시스템을 사용 하여) 재정의된 가상 제스처-공간의 입력 프레임에 대한 후속 프레임에서 추적된다. 이 단계는 위에서 설명된 단계와 유사할 수 있다. 경계 상자(및 선택적인 식별자)는 제스처 입력을 분석하고 파싱하기 위해 (예를 들어, 제스처 인식 서브시스템 또는 다른 손 분류기에) 제공될 수 있다. 방법은 가상 제스처-공간이 입력 프레임에서 검출된 손에 기초하여 재정의될 수 있게 하여, 손이 구별되는 해부학적 특징으로부터 더 멀리 이동하더라도 입력 프레임에 대한 각각의 후속 프레임에서 손이 계속 추적되고 검출될 수 있도록 한다. 검출된 손에 기초해서 가상 제스처-공간이 재정의된 후, 재정의된 가상 제스처-공간을 사용하여 후속 프레임이 처리될 수 있다. 재정의된 가상 제스처-공간은 손이 공간에서 위치를 변경함에 따라 각각의 후속 프레임에서 계속해서 재정의될 수 있어서, 가상 제스처-공간은 손이 움직일 때 계속해서 검출된 손 의 중심에 있게 된다. 예를 들어, 프레임들의 시퀀스의 입력 프레임에 대한 후속 프레임은 단계 904 및 906이 생략되는 방법의 변형을 사용하여 처리될 수 있다. 일부 예들에서, 후속 프레임의 재정의된 가상 제스처-공간에서 손이 더 이상 검출되지 않으면, 가상 제스처-공 간은 입력 프레임에서 검출된 구별되는 해부학적 특징에 기초해서 재생성될 수 있다. 다시 말해, 구별되는 해 부학적 특징은 가상 제스처-공간을 정의하기 위한 앵커 또는 디폴트 기반으로서 사용될 수 있다. 일부 예들에서, 가상 제스처-공간에 대한 디폴트 기반으로서 구별되는 해부학적 특징을 사용하는 것으로의 복귀는 재정의된 가상 제스처-공간에서 미리 정의된 수 이상의 후속 프레임들(예를 들어, 입력 프레임 이후의 최소 10 프레임)에 대해 손을 검출할 수 없을 때만 수행될 수도 있다. 도 10a 및 10b는 방법의 예시적인 구현을 도시하고, 가상 제스처 공간은 프레임들의 시퀀스의 입력 프레임에서 검출된 사용자의 얼굴에 기초해서 초기에 생성되고, 후속적으로 입력 프레임에서 검출된 사 용자의 손에 기초해서 재정의된다. 도 10a에서, 가상 제스처-공간은 입력 프레임(예를 들어, 도 7의 예와 유사)에서 검출된 얼굴의 경계 상자에 기초해서 생성되는 직사각형 형상을 갖는 2D 공간이다. 손은 입력 프레임의 가상 제스처-공간에서 검출되고 손에 대한 경계 상자가 정의 된다. 도 10b에서, 가상 제스처-공간(704b)은 손의 경계 상자에 기초해서 재정의된다. 예를 들어, 손의 경계 상자는 값들의 세트 에 의해 정의될 수 있으며, 여기서 와"}
{"patent_id": "10-2022-7035829", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "는 각각 경계 상자의 앵커 포인트(예를 들어, 중심)의 (적응형 제스처 감지 시스템에 의해 정의된 참 조 프레임에서) x 및 y 좌표를 정의하고, 와 는 각각 경계 상자의 너비와 높이를 정의한다. 경계 상 자에 기초해서, 가상 제스처-공간(704b)이 재정의된다(예를 들어, 단계에서). 예를 들어, 가상 제스 처-공간(704b)을 재정의하기 위해 다음 방정식이 사용될 수 있다."}
{"patent_id": "10-2022-7035829", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서 는 이전에 논의된 가상 제스처-공간(704b)을 정의하는 매개변수이고, 는 미리 정의된 상대 위치 매개변수이고, 는 검출된 손에 대한 미리 정의된 스케일 매개변수이다. 매개변수 와 는 재정의된 가상 제스처-공간(704b)의 원하는 크기 및 재정의된 가상 제스처-공간(704b) 내의 경계 상자의 원하는 위치에서의 결과에 따라 (예를 들어, 사용자 또는 제스처 제어 디바이스 의 제조사에 의해) 미리 정의될 수 있다. 특히, 도 10b의 예에 예시된 바와 같이, 얼굴은 재정의된 가상 제스처-공간(704b)으로부터 부분적으로 또는 전체적으로 제외될 수 있다. 일부 예들에서, 입력 프레임에서 다수의 사람이 검출될 때(예를 들어, 다수의 얼굴이 얼굴 검출 및 추적 서브시 스템에 의해 검출됨), 적응형 제스처 감지 시스템은 검출된 사람의 순위를 매기고 한 사람을 주요 사 용자(또는 주요 컨트롤러)로서 식별하기 위해 사용자 목록을 구현할 수 있다. 가상 제스처-공간은 주요 사용자에 대해서만 생성될 수 있다. 도 11은 예를 들어 가상 제스처 공간 서브시스템 및 제스처 파싱 서브시스템(및 서브시스템(312, 314, 316, 322, 324))을 사용하여, 적응형 제스처 감지 시스템에 의해 수행될 수 있는 예시적인 방법 을 도시하는 흐름도이다. 방법은 제스처 제어 디바이스의 처리 디바이스에 의해 실행되 는 소프트웨어의 루틴 또는 서브루틴에 의해 수행될 수 있다. 이러한 루틴 또는 서브루틴을 수행하기 위한 소 프트웨어의 코딩은 본 개시내용과 관하여 충분히 당업자의 범위 내에 있다. 방법은 도시 및 설명된 추가 적인 또는 더 적은 단계 또는 동작을 포함할 수 있고, 상이한 순서로 수행될 수 있다. 예를 들어, 처리 디바이 스에 의해 실행가능한 컴퓨터 판독가능 코드는 컴퓨터 판독가능 매체에 저장될 수 있다. 방법은 위 의 방법에 대해 설명된 단계와 유사한 단계를 포함할 수 있으며, 이 경우 유사한 단계는 다시 상세하게 설 명되지 않을 수 있다. 1102에서, 프레임들의 시퀀스의 입력 프레임이 수신된다. 이 단계는 위에서 설명된 단계와 유사할 수 있 다.1104에서, 주요 사용자가 이미 식별되고 선택되었는지 여부가 결정된다. 예를 들어, 주요 사용자는 프레임들의 시퀀스에서 이전 입력 프레임을 분석하여 식별되고 선택되었을 수 있다. 주요 사용자가 이미 선택되었다면, 방 법은 단계 1106으로 진행하고; 그렇지 않으면 방법은 단계로 진행한다. 1106에서, 주요 사용자의 구별되는 해부학적 특징(예를 들어, 얼굴)이 입력 프레임에서 검출되고 프레임들의 시 퀀스의 입력 프레임에 대한 후속 프레임에서 추적된다(예를 들어, 얼굴 검출 및 추적 서브시스템을 사용하 여). 주요 사용자가 이전 입력 프레임에서 식별된 경우 가상 제스처-공간이 주요 사용자에 대해 이미 정의되었 을 수 있다. 이러한 경우에, 입력 프레임 및 입력 프레임의 후속 프레임에서 해부학적 특징의 검출 및 추적은 이미 정의된 가상 제스처-공간에서만 각각의 후속 프레임을 처리함으로써 수행될 수 있다. 해부학적 특징의 추 적은 모든 후속 프레임을 처리하여 수행되지만 검출은 더 낮은 주파수로 수행될 수 있다(예를 들어, 하나 이상 의 후속 프레임 건너뛰기). 해부학적 특징의 검출은 추적 오류를 보정하기 위해 수행될 수 있다(예를 들어, 많 은 후속 프레임을 추적할 때 추적 오류가 누적될 수 있음). 비록 이 논의가 주요 사용자의 구별되는 해부학적 특징(예를 들어, 얼굴)을 검출하고 추적하는 맥락에 있지만, 단계의 수정은 가상 제스처-공간이 입력 프 레임에서 검출된 손에 기초해서 재정의되는 경우(예를 들어, 도 10a 및 도 10b와 관련하여 위에서 논의된 바와 같이), 입력 프레임 및 후속 프레임을 처리하여 주요 사용자의 손을 검출하고 추적하기 위해 수행될 수 있다. 1108에서, 주요 사용자가 이전에 선택되지 않은 경우, 예를 들어 얼굴 검출 및 추적 서브시스템을 사용하 여 구별되는 해부학적 특징의 인스턴스(예를 들어, 인간 얼굴의 모든 인스턴스)를 검출하도록 전체 입력 프레임 이 처리될 수 있다. 검출된 각 해부학적 특징에 대해 경계 상자 및 식별자가 생성될 수 있다. 구별되는 해부 학적 특징의 인스턴스가 입력 프레임에서 검출되지 않으면, 방법은 프레임들의 시퀀스에서 다음 입력 프 레임을 처리하기 위해 1102로 돌아갈 수 있다. 1110에서, 해부학적 특징의 검출된 인스턴스에 기초해서 순위가 매겨진 사용자 목록이 생성된다. 각각의 검출된 인스턴스는 각각의 검출된 사용자와 연관될 수 있다. 사용자 목록은 미리 정의된 순위 기준에 따 라 (예를 들어, 임의의 눈 추적 기술과 같은 임의의 적절한 얼굴 분석 기법을 사용하여) 검출된 해부학적 특징 을 추가로 분석함으로써 순위가 매겨질 수 있다. 예를 들어, 해부학적 특징이 얼굴이면, 순위 기준은 (제스처 제어 디바이스에 더 가까운 것으로 가정되는) 큰 얼굴이 작은 얼굴보다 높은 순위로 매겨지도록 지정할 수 있다; 제스처 제어 디바이스를 향한 얼굴은 제스처 제어 디바이스로부터 멀어지는 얼굴보다 더 높은 순위가 매겨질 수 있다; 또는 제스처 제어 디바이스를 응시하는 눈을 가진 얼굴은 제스처 제어 디바이스 에서 시선을 돌리는 눈을 가진 얼굴보다 더 높은 순위가 매겨질 수 있다. 다른 순위 기준이 사용될 수도 있다. 검출된 구별되는 해부학적 특징의 인스턴스가 하나뿐이면, 해당 인스턴스는 디폴트로 목록에서 가장 높 은 순위를 가질 수 있다. 1112에서, 순위가 매겨진 사용자 목록에서 가장 높은 순위의 사용자가 주요 사용자로서 선택된다. 사용자 목록에 단 하나의 사용자가 있으면, 그 사용자는 디폴트로 주요 사용자로서 선택될 수 있다. 그 다음, 방 법은 카메라에 의해 캡처된 프레임들의 시퀀스에서 주요 사용자의 해부학적 특징을 추적하기 위해 단계로 진행한다. 1114에서, 주요 사용자에 대한 가상 제스처-공간이 생성된다. 가상 제스처-공간이 (카메라에 의해 캡처된 이전 프레임의 분석에 기초해서) 이전에 정의된 경우, 가상 제스처-공간을 생성하는 대신 이미 정의된 가상 제 스처 공간이 사용될 수 있다. 그렇지 않으면, 가상 제스처-공간은 프레임들의 시퀀스의 입력 프레임에서 검출 된 주요 사용자(예를 들어, 이전에 설명된 단계와 유사)의 구별되는 해부학적 특징(예를 들어, 얼굴)에 기 초해서 생성된다. 선택적으로, 가상 제스처-공간을 나타내는 정보가 제공될 수 있다(예를 들어, 피드백이 주요 사용자에게 제공될 수 있도록). 1116에서, 프레임들의 시퀀스의 입력 프레임에서 (예를 들어, 손 검출 및 추적 서브시스템을 사용하여) 가 상 제스처-공간에서 손이 검출된다. 이 단계는 위에서 설명된 단계와 유사할 수 있다. 선택적으로, 입력 프레임의 가상 제스처-공간에서 둘 이상의 손이 검출되면, 주요 손이 식별되고(예를 들어, 손 크기와 같은 일부 미리 정의된 기준에 기초해서) 가상 제스처-공간과 연관될 수 있다. 선택적으로, 가상 제스처-공간은 입력 프 레임에서 검출된 손에 기초해서 재정의될 수 있다(도 9에 대해 위에서 설명한 것과 유사). 가상 제스처-공간이 입력 프레임에서 검출된 손에 기초해서 입력 프레임에 대한 후속 프레임에서 재정의된 경우, 검출 및 추적은 단 계 1106에서 이미 수행되었을 수 있으며 이 단계는 필요하지 않을 수 있다. 1118에서, 검출된 손에 대해 (예를 들어, 제스처 인식 서브시스템을 사용하여) 제스처 인식이 수행되고(예 를 들어, 경계 상자에 의해 정의된 바와 같이) 검출된 손에 대한 제스처 클래스를 예측하기 위해 입력 프레임에대한 프레임들의 시퀀스에서 추적된다. 예측된 제스처 클래스(유효한 제스처가 식별된 경우)가 출력되어 예를 들어 소프트웨어 애플리케이션에 대한 명령 입력으로 변환된다. 사용자 목록의 임의의 비주요 사용자는 폐기되고(즉, 주요 사용자만 유지) 방법은 카메라에 의해 캡처된 프레임들의 시퀀스에서 다음 입력 프레임을 수신하고 처리하기 위해 1102로 돌아간다. 제스처 인식이 유효한 제스처를 예측하는데 실패하거나(예를 들어, 손 모양을 미리 정의된 제스처 클래스로 분 류할 수 없음) 제스처가 현재 활성화된 소프트웨어 애플리케이션에 대해 유효한 제스처가 아닌 경우(예를 들어, 소프트웨어 애플리케이션이 적응형 제스처 감지 시스템에 유효하지 않은 입력을 다시 보고함), 방법(110 0)은 단계로 진행한다. 1120에서, 현재 선택된 주요 사용자는 사용자 목록으로부터 폐기된다. 1122에서, 사용자 목록에 임의의 다른 사용자가 있는지 여부가 결정된다. 사용자 목록에 적어도 하 나의 남은 사용자가 있는 경우, 단계에서 사용자 목록에서 가장 높은 순위의 나머지 사용자가 주요 사용자로서 선택되고, 방법은 위에서 설명된 바와 같이 단계로 진행한다. 사용자 목록에 남 아있는 사용자가 없다면, 방법은 프레임들의 시퀀스에서 다음 입력 프레임을 수신하고 처리하기 위해 단 계로 돌아간다. 사용자 목록은 적응형 제스처 감지 시스템이 카메라의 FOV 내에 여러 사람이 있는 경우에도 위양성을 감소시키면서 제스처 입력을 분석 및 처리할 수 있게 한다. 사용자 목록은 다수의 인간의 존재 를 수용하는 비교적 효율적인 방법일 수 있지만, 위에서 논의된 바와 같이 사용자 목록 대신에 또는 이에 추가하여 다른 기술이 사용될 수 있다. 위에서 논의된 일부 예에서, 구별되는 해부학적 특징(예를 들어, 사람 얼굴)의 검출은 전체 입력 프레임을 처리 함으로써 수행될 수 있다. 아래에서 논의되는 다른 예에서, 구별되는 해부학적 특징의 검출은 입력 프레임 내 에서 관심 영역(ROI)만을 처리함으로써 수행될 수 있다. 예를 들어, 위에서 설명된 단계에서, 적응형 ROI 접근법이 사용될 수 있다(예를 들어, 얼굴 검출 및 추적 서브시스템이 얼굴 검출을 위해 구현할 수 있 음). 본 개시에서 적응형 ROI는, ROI의 크기 및/또는 위치가 예를 들어 얼굴 검출기(예를 들어, 얼굴 검출 및 추적 시스템)의 요구 사항, 입력 프레임의 해상도 또는 처리 효율성에 기초해서 조정될 수 있다는 의미에서, \" 적응형\"으로 간주될 수 있다. 예를 들어, 머신 러닝 기반(예를 들어, 컴퓨터 비전 기반) 얼굴 및 손 검출기는 일반적으로 정사각형 입력 이미지를 처리하도록 훈련된다. 따라서 얼굴 및 손 검출 성능 향상을 위해서는 검출 을 수행하기 위한 ROI가 정사각형이어야 한다. 유사한 이유로 손 검출을 위한 가상 제스처-공간은 정사각형으 로 정의될 수 있다. 도 12는 카메라에 의해 캡처된 프레임들의 시퀀스의 입력 프레임에서 구별되는 해부학적 특징을 검출하기 위해 적응형 ROI를 사용하는 예시적인 방법을 도시하는 흐름도이다. 방법은 위에서 설명된 단계 의 일부로서 사용될 수 있다. 예를 들어, 방법은 얼굴 검출 및 추적 서브시스템에 의해 구현 될 수 있다. 방법은 단계를 위해 다른 기술을 사용하여 구현될 수 있고 적응형 ROI가 사용되거나 사용되지 않을 수 있음을 이해해야 한다. 1202에서, 해부학적 특징이 이전 입력 프레임에서 검출되었는지 여부가 검출된다. 그렇다면, 1204에서 이전 입 력 프레임에서 해부학적 특징(예를 들어, 얼굴)의 검출에 사용된 ROI가 현재 입력 프레임에서 다시 사용되도록 선택된다. 일반적으로 해부학적 특징의 검출을 위한 ROI는 전체 입력 프레임보다 작아야 하며 정사각형 모양일 수 있다(검출 알고리즘의 학습 또는 설계 방식에 기초해서). 해부학적 특징이 이전 입력 프레임에서 검출되지 않은 경우(또는 이전 입력 프레임이 없는 경우), 1206에서 ROI 시퀀스로부터 ROI가 선택된다. ROI 시퀀스의 ROI가 이전 입력 프레임에서 사용된 경우 ROI 시퀀스의 다음 ROI 는 현재 입력 프레임에서 사용하기 위해 선택될 수 있다. ROI 시퀀스는 미리 정의될 수 있다(예를 들어, 얼굴 검출 및 추적 서브시스템에서 미리 정의됨). ROI 시퀀스는 순차적 입력 프레임을 처리하는데 사용되어야 할 상이한 ROI들의 시퀀스를 정의한다. 예를 들어, ROI 시퀀스가 8개의 상이한 ROI(예를 들어, 다른 위치 및/ 또는 크기를 가짐)의 시퀀스인 경우, 시퀀스의 각 ROI는 8개의 입력 프레임들의 시퀀스에서 해부학적 특징의 검 출을 수행하기 위해 차례로 선택된다. 그 다음 ROI 시퀀스는 시퀀스의 첫 번째 ROI로 다시 순환할 수 있다. 도 13은 8개의 상이한 ROI(1302, 1304, 1306, 1308, 1310, 1312, 1314, 1316)를 갖는 예시적인 ROI 시퀀스를 도시한다. 8개의 ROI(1302-1316)는 8개의 상이한 입력 프레임들의 시퀀스를 통해 순환될 수 있고 상이한 해상도의 입력 프레임에 적용될 수 있다. 예를 들어, 6개의 ROI(1302-1312)는 입력 프레임의 원래 해상도에 적용될 수 있고 더 작은 해부학적 특징의 검출을 가능하게 하도록 설계될 수 있다(예를 들어, 사용자가 제 스처 제어 디바이스로부터 더 멀리 떨어져 있는 경우). 2개의 ROI(1314, 1316)는 입력 프레임의 축소된 버전(더 낮은 해상도를 가짐)에 적용될 수 있고, 더 큰 해부학적 특징의 검출을 가능하게 하도록 설계될 수 있다(예를 들어, 사용자가 제스처 제어 디바이스에 더 가까이 있는 경우). 일부 ROI(1314, 1316) 에 대해 입력 프레임의 축소된 버전을 사용하여 입력 프레임의 더 큰 영역의 계산 비용이 덜 드는 처리를 가능 하게 하는 것이 유용할 수 있다. ROI의 시퀀스는 카메라에 의해 캡처된 프레임들의 시퀀스에 걸쳐 순환되어 각 입력 프레임이 선택된 ROI (둘 이상의 ROI를 사용하여 동일한 입력 프레임을 처리하는 대신)만을 사용하여 처리된다는 점에 유의해야 한다. 카메라에 의해 캡처된 입력 프레임은 일반적으로 높은 주파수에서 캡처되기 때문에, 인접 프레임 간의 시간 차는 이러한 방식으로 ROI의 시퀀스를 사용하여 프레임들의 시퀀스를 처리함으로써 손실된 정보가 없 어야 할(또는 거의 없어야 할) 만큼 충분히 작을 수 있다. 미리 정의된(예를 들어, 얼굴 검출 및 추적 서브시스템에 저장되는) 상이한 ROI 시퀀스가 있을 수 있다. 사용되는 ROI 시퀀스는 사용자에 의해 선택될 수 있거나, 상이한 ROI 시퀀스를 통해 순환하기 위한 미리 정 의된 순서가 있을 수 있다(즉, 사용할 ROI 시퀀스의 미리 정의된 시퀀스가 있을 수 있음). 또한, 도 13의 예가 ROI 시퀀스의 각 ROI가 시퀀스에서 한 번 사용되는 것을 보여주지만, 일부 예에서 ROI 시퀀스는 ROI 시퀀스 내 에서 주어진 ROI를 두 번 이상 사용하도록 정의될 수 있다. 다른 그러한 변형이 가능할 수 있다. 1208에서, 선택된 ROI(단계 1204에서 이전 입력 프레임에서 선택된 ROI, 또는 단계 1206에서 ROI 시퀀스로부터 선택된 ROI), 구별되는 해부학적 특징의 검출은 선택된 ROI를 사용하여 수행된다. 구별되는 해부학적 특징(예를 들어, 얼굴)의 검출을 수행하기 위한 적응형 ROI의 사용은 계산 비용의 감소 및/ 또는 훈련된 검출기의 개선된 성능을 가능하게 할 수 있다. 일부 예에서, 적응형 ROI 기술은 제스처 검출이 활성화되는 경우(또는 제스처 검출이 디폴트로 사용되는 경우) 카메라에 의해 캡처되는 모든 프레임을 처리하는 데 사용될 수 있다. 다른 예들에서, 적응형 ROI 기술은 모든 N(여기서 N>1) 프레임을 처리하기 위해 사용될 수 있다. 이전에 논의된 바와 같이, 일부 예들에서 손 검출 및 추적 서브시스템은 제스처 인식을 위해 제스처 인식 서브시스템에 의해 사용될 경계 상자를 출력할 수 있다. 일부 실시예에서, 제스처 인식 서브시스템 은 머신 러닝 알고리즘을 사용하여 구축된 모델로 구현될 수 있다. 일부 실시예에서, 제스처 인식 서브시스템 은 제스처 분류를 수행하도록 구성된 훈련된 신경망(이하, 훈련된 제스처 분류 네트워크로 지칭됨)을 포함 할 수 있다. 훈련된 제스처 분류 네트워크는 신경망의 매개변수(예를 들어, 가중치(weights))를 학습하기 위해 알려진 머신 러닝 알고리즘을 사용하여 훈련되었다. 훈련된 제스처 분류는 검출된 손 제스처에 대한 경계 상자 를 수신하고 경계 상자에 대응하는 미리 정의된 제스처 클래스들의 세트로부터 특정 제스처 클래스를 예측한다. 일반적으로 제스처 분류를 수행하도록 구성된 훈련된 신경망에 의해 달성된 제스처 분류의 정확도는 손 이미지 가 잘릴(cropped) 때 저하된다(예를 들어, 경계 상자가 정답(ground truth)에서 큰 오프셋을 가질 때). 경계 상자 조정의 예는 2019년 3월 15일에 출원된 \"안면 인식을 위한 적응형 이미지 자르기\"라는 명칭의 미국 특허 출원 번호 제16/355,665호에 기술되며, 그 전체 내용이 본원에 참조에 의해 편입된다. 제스처 인식을 향상시키 는데 도움이 되는 경계 상자 조정에 대한 유사한 접근 방식이 본 명세서에 기술된다. 도 14는 제스처 인식 서브시스템에 사용될 수 있는 제스처 분류 네트워크의 예시적인 구현을 도시하는 블 록도이다. 제스처 분류 네트워크는 경계 상자 정제(refinement) 네트워크에 대한 사이드 브랜치들 (side branches)과 함께 구현될 수 있다. 제스처 분류 네트워크는 입력 프레임에서 경계 상자에 의해 정 의된 손 이미지에 대한 제스처 분류를 수행하고, 경계 상자 정제 네트워크는 제스처 분류 네트워크(140 0)에서 사용되는 경계 상자의 세분화를 수행한다. 제스처 분류 네트워크에 입력 데이터로서 입력 프레임이 수신된다. 입력 데이터는 입력 프레임의 잘린 버전일 수 있다(예를 들어, 손에 대해 정의된 경계 상자에 기초해서). 일부 실시예에서, 입력 데이터는 네트워 크(1400, 1450)의 배치 기반 훈련(batch-based training)을 위한 또는 프레임들의 시퀀스에 기초한 제스처 분류 를 가능하게 하기 위한 것과 같은 이미지들의 배치(batch)일 수 있다. 제스처 분류 네트워크는 일련의 컨볼루션(convolution) 블록(예를 들어, ResNet 설계를 사용하여 구현됨)을 포함한다. 3개의 이러한 컨 볼루션 블록이 단순화를 위해 도시되지만, 제스처 분류 네트워크에는 더 많거나 더 적은 컨볼루션블록이 있을 수 있다. 일련의 컨볼루션 블록은 결정된 제스처 클래스를 출력하는 제스처 분류 완 전 연결 네트워크(fully connected network; FCN)로 출력한다. 제스처 분류 FCN은 일련의 컨볼루 션 블록에서 마지막 컨볼루션 블록으로부터 출력된 벡터를 입력으로서 수신한다. 제스처 분류 FCN은 경계 상자에 의해 정의된 손에 대한 제스처 클래스를 결정하기 위해 특징 임베딩을 사용하고, 결정 된 제스처 클래스를 레이블로 출력한다. 일부 예에서, 제스처 분류 FCN은 가능한 제스처 클래스에 대한 확률 분포를 포함하는 벡터를 출력한다. 즉, 제스처 분류 네트워크의 출력은 하나의 확정적으로 결정된 제스처 클래스대신 서로 다른 제스처 클래스에 대한 확률일 수 있다. 일부 예들에서, 제스처 분류 FCN은 가능한 제스처 클래스들에 대한 출력된 확률 분포들을 정규화하는 역할을 하는 마지막 출력 레이어에 소프트맥 스(softmax) 함수를 포함한다. 각각의 컨볼루션 블록은 또한 경계 상자 정제 네트워크에 속하는 사이드 브랜치로 출력한다. 각각의 사이드 브랜치는 경계 상자 정제 FCN으로 출력한다. 각각의 사이드 브랜치는 선택적 인 맥스 풀링 레이어(max-pooling layer), 선택적인 크기 조정 레이어(resizing layer), 및 컨볼루션 블록을 독립적으로 포함할 수 있다. 사이드 브랜치의 출력은 결합된 출력 벡터로 연결(concatenate)되며, 이는 경계 상자 정제 FCN에 입력되기 전에 1x1 컨볼루션 블록(도시되지 않음)에 의해 평탄화될 수 있다. 경계 상자 정제 FCN의 출력은 입력 프레임에서 손을 정의하는 경계 상자의 크기 및 위치를 조정하거나 정제하 는 정보(예를 들어, 경계 상자에 대한 좌표 정보의 형태로)이다. 이제 조인트 네트워크(1400, 1450)의 훈련이 논의된다. 전술한 바와 같이, 제스처 분류 FCN은 소프트맥 스 레이어를 포함할 수 있다. 제스처 분류 FCN은 교차 엔트로피 손실(cross-entropy loss)을 추가로 계 산 및 출력할 수 있으며, 이는 출력된 확률 분포와 모델의 원래 확률 분포 간의 차이의 척도로 간주될 수 있다. 이 교차 엔트로피 손실은 소프트맥스 레이어에 대한 손실 함수로 사용될 수 있으며, 따라서 소프트맥스 손실이 라고도 한다. 유사하게, 경계 상자 손실은 경계 상자 정제 FCN으로부터 출력될 수 있다. 소프트맥스 손 실 및 경계 상자 손실은 결합 네트워크(1400, 1450)의 훈련에 사용될 수 있는 총 손실 함수에 대해 결합 될 수 있다. 소프트맥스 손실, 경계 상자 손실, 및 총 손실 함수를 사용하는 훈련은 네트워크(1400, 1450)의 훈련 동안에만 사용될 수 있고, 추론(inference) 중에는 필요하지 않을 수 있다. 네트워크(1400, 1450)의 훈련 중에, 훈련 데이터 샘플은 정답 손 경계 상자를 기반으로 하는 무작위로 잘린 (random cropped) 손 이미지로 생성될 수 있다. 몇 가지 예가 도 15에 나타나 있으며, 여기서 정답은 손 이미지에 대한 최적화된 경계 상자를 정의하고 다른 무작위로 잘린 손 이미지는 훈련 데이터 샘플로서 생성된다. 훈련 데이터 샘플은 경계 상자 의 위치를 이동할 수 있을 뿐만 아니라, 경계 상자의 크기도 변경할 수 있다(경계 상자에서 손 이미지가 더 크 거나 작게 나타날 수 있도록). 정답에 대한 각 훈련 데이터 샘플의 경계 상자 오프셋은 경계 상자 정제를 훈련하기 위한 라벨로서 사용된다. 조인트 네트워크(1400, 1450)는 이 예에서 분류 손실 함수(소프트맥스 손실)와 경계 상자 손실 함수의 선형 조 합인 총 손실 함수를 최소화함으로써 훈련된다. 이제 경계 상자 손실 함수의 예에 대해 논의한다. 객체 주위에 정의된 정답 경계 상자와 잘린 훈련 데이터 샘플 경계 상자를 나타내는 도 16의 단순 화된 예를 고려한다. 훈련 데이터 샘플 경계 상자의 위치(이 예에서는 네 모서리)를 정의하는 좌표를 라고 하고, 대응하는 정답 경계 상자의 위치를 정의하는 좌표를 라고 한다. 경계 상자 정제 네트워크는 훈련 데이터 샘플 경계 상자 와 정답 경계 상자 사이의 상대 회전 및 상대 변위 를 추정하며, 여기서: , , ,"}
{"patent_id": "10-2022-7035829", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이다. 경계 상자 손실 함수는 다음과 같이 정의될 수 있다: 여기서 _λ_는 정규화(regularization) 매개변수이다. 추론 중에, 입력 프레임에서 손 이미지를 정의하는 경계 상자는 경계 상자 정제 네트워크에 의해 예측된 오프셋이 0에 가까울 때까지 반복적으로 보정될 수 있다. 최종 제스처 분류 점수는 다음과 같이 각 반복에서 얻은 모든 개별 제스처 분류 점수를 결합하여 계산할 수 있다:"}
{"patent_id": "10-2022-7035829", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서 는 m번째 반복의 분류 점수(예를 들어, 소프트맥스 출력)이고 는 m번째 경계 상자와 최종 정제된 경계 상자의 대응하는 가중치(예를 들어, 얼마나 겹쳐져 있는가(intersection over union; IoU))이다. 추론 중에, 제스처 분류 네트워크를 사용하여 (입력 프레임에 적용된 경계 상자에 의해 정의된) 입력 손 이미지에 반복적 분류가 적용된다. 각각의 반복에서, 제스처 분류 네트워크에 대한 입력 이미지는 이전 반복의 출력된 경계 상자 정제 매개변수에 의해 보정된 이전 입력 이미지에 기초해서 획득된다. 따라서, 경계 상자 정제 네트워크 및 제스처 분류 네트워크는 제스처 분류 네트워크의 성능 개선을 돕기 위해 입력 프레임에서 손 이미지를 정의하는 경계 상자를 개선하기 위한 피드백을 제공하도록 함께 동작한다. 도 17은 제스처 인식을 수행하기 위해 (예를 들어, 위에서 설명된 조인트 네트워크(1400, 1450)를 사용하여) 경 계 상자 정제를 사용하는 예시적인 방법을 도시하는 흐름도이다. 방법은 위에서 설명된 단계 의 일부로서 사용될 수 있다. 예를 들어, 방법은 제스처 인식 서브시스템에 의해 구현될 수 있다. 방법은 단계에 대해 다른 기술을 사용하여 구현될 수 있고 경계 상자 정제가 사용될 수도 있고 사용되지 않을 수도 있다는 것을 이해해야 한다. 1702에서, 검출된 손(예를 들어, 손 검출 및 추적 서브시스템에 의해 출력됨)을 정의하는 경계 상자 뿐만 아니라 입력 프레임이 수신된다. 1704에서, (위에서 설명된 바와 같이) 조인트 경계 상자 정제 네트워크를 갖는 제스처 분류 네트워크는 경계 상 자 정제를 포함하는 제스처 분류를 수행하기 위해 사용될 수 있다. 선택적으로, 1706에서, 제스처 분석은 다수의 입력 프레임에 걸쳐 수행될 수 있다. 예를 들어, 제스처 인식 서 브시스템은 이전 입력 프레임의 버퍼를 저장하고 이전 입력 프레임을 고려하여 제스처 분석을 수행할 수 있다. 버퍼(예를 들어, 적응형 제스처 감지 시스템에서 구현됨)는 미리 결정된 수의 이전 입력 프레임을 저장하 는데 사용될 수 있다. 버퍼에 저장되는 이전 입력 프레임의 수는 메모리 리소스의 보다 효율적인 사용을 위해 상대적으로 작을 수 있다(예를 들어, 10-30 이전 입력 프레임). 일부 예들에서, 버퍼는 소수의 이전 입력 프레 임들에 대해 수행된 제스처 분석의 결과를 추가적으로 또는 대안적으로 저장할 수 있다. 단일 정적 제스처가 인식되기 위해, 제스처 인식 서브시스템은 동일한 제스처 클래스가 미리 정의된 수의 이전 입력 프레임(N)에 걸쳐 미리 정의된 최소 횟수(K) 검출되도록 요구할 수 있으며, 여기서 K≥_1 및 K≤_N이 다. 이 요건은 검출 정확도를 개선하고 위양성을 줄이는 데 도움이 될 수 있다. 일부 예들에서, N개의 이전 입력 프레임들에 걸쳐 K개의 연속적인 입력 프레임들에 걸쳐 동일한 제스처 클래스가 검출될 필요가 있을 수 있 다. 미리 정의된 최소 K는 더 나은 검출을 가능하게 하고 거의 실시간의 제스처 인식을 더욱 달성하기 위해 비 교적 작은 숫자(예를 들어, 10)로 선택될 수 있다. 이 접근 방식을 사용하여 검출될 수 있는 정적 제스처는 예 를 들어 음소거 제스처(예를 들어, 음소거 또는 음소거 해제 명령용) 또는 열린 손 제스처(예를 들어, 재생 또 는 일시 정지 명령용)를 포함할 수 있다. N개의 이전 입력 프레임은 버퍼에 저장될 수 있고, 위양성을 줄이는 데 도움이 되도록 제스처를 검출하기 위한 슬라이딩 윈도우로 사용될 수 있다. 동적 제스처는 둘 이상의 정적 제스처의 조합에 기초해서 제스처 인식 서브시스템에 의해 인식될 수 있다. 예를 들어, 완전한 동적 제스처는 다른 상태로 분리될 수 있으며, 여기서 상태 간의 전환(transition)은 정적 제스처의 검출 결과이다. 제스처 인식 서브시스템은 동적 제스처의 상태 기반 인식을 위해 미리 정의된 상태 전환 규칙 세트를 구현할 수 있다. 도 18은 제스처 인식 서브시스템에 의해 구현될 수 있는 동적 제스처의 상태 기반 인식의 예를 나타내는 상태도이다. 중립(neutral) 상태는 제스처 입력이 처음 활성화되거나 현재 유효한 제스처가 검출되지 않는 경우 디폴트로 초기 상태일 수 있다. 주먹 제스처가 먼저 스와이프 준비 상태로 전환하는 것으로 검출되고, 이어서 스와이프 상태로 전 환하기 위한 열린 손 제스처가 검출될 때, 스와이프(swipe) 동적 제스처가 검출될 수 있다. 스와이프된 상태 에 도달하면, 제스처 인식 서브시스템은 제스처 입력을 동적 스와이프 제스처로 인식한다. 따라서, 정적 주먹 제스처에 이어 정적 열린 손 제스처(적절한 순서대로)의 인식은 동적 스와이프 제스처의 인식을 야기 한다. 또한, 검출된 주먹 제스처와 검출된 열린 손 제스처 사이의 위치 변경은 동적 스와이프 제스처를 확실히 검출하기 위해 필요할 수 있다(예를 들어, 스와이프 제스처를 위치 변경을 포함하지 않는 다른 동적 제스처와 구별하기 위해). 검출된 제스처의 위치 변경은 손 경계 상자의 좌표 변경에 기초해서 계산될 수 있다. 스와이 프된 상태에 도달하면, 제스처 인식 서브시스템은 인식된 제스처를 나타내는 출력(예를 들어, 제스 처 클래스 라벨)을 생성할 수 있고, 스와이프 준비 상태의 검출과 스와이프된 상태 사이의 위치 변 화를 나타내는 출력을 추가로 제공할 수 있다. 수직 또는 수평의 동적 드래그 제스처는 핀치 열림, 핀치 닫힘 및 핀치 열림 정적 제스처의 조합으로서 검출될 수 있다. 예를 들어, 중립 상태로부터, 핀치 열림 정적 제스처의 검출 후에 핀치 준비 상태로의 전환이 발생한다. 핀치 준비 상태로부터, 핀치 닫힘 정적 제스처의 검출은 핀치 활성화 상태로의 전환을 야기한다. 핀치 활성화 상태 및 핀치 닫힌 정적 제스처에 머무르는 것으로부터, 수직 위치의 변 경(예를 들어, 미리 정의된 문턱값보다 큰 변경)은 수직 드래그 상태로의 전환을 야기한다. 유사하게, 핀치 활성화 상태로부터 및 핀치 닫힌 정적 제스처에 머무르는 것으로부터, 수평 위치의 변경(예를 들어, 미리 정의된 문턱값보다 큰 변화)은 수평 드래그 상태로의 전환을 야기한다. 위치 변경이 수직 및 수평 변경의 조합(예를 들어, 위치의 대각선 방향의 변경)이면, 크기가 더 큰 변경이 상태 전환을 결정하는데 사용될 수 있다. 또는, 위치 변경이 수직 및 수평 변경의 조합이면, 상태 전환이 인식되지 않을 수 있다. 수직 드래 그 상태 또는 수평 드래그 상태에 도달하면, 제스처 인식 서브시스템은 인식된 제스처를 나타 내는 출력(예를 들어, 제스처 클래스 라벨)을 생성할 수 있고 수직 또는 수평 위치의 변경을 나타내는 출력을 추가로 제공할 수 있다. 예를 들어, 제스처 인식 서브시스템은 (예를 들어, 입력 프레임에 정의된 좌표에 기초해서) 거리를 계산하고 이 값을 출력할 수 있다. 거리 값은 동적 드래그 제스처를 드래그 명령 입력에 매 핑하는데 사용될 수 있다. 수직 드래그 상태 또는 수평 드래그 상태로부터, 핀치 열림 정적 제스 처의 검출은 핀치 준비 상태로의 전환을 야기한다. 핀치 준비 상태로의 복귀는 동적 드래그 제스 처의 끝으로 인식될 수 있다. 위치의 변경을 수반하는 동적 제스처의 경우, 제스처 인식 서브시스템은 가능한 위양성을 추가로 배제하기 위해 물리 법칙 및/또는 예상되는 인간 움직임에 기초해서 미리 정의된 규칙을 구현할 수 있다. 예를 들어, 미 리 정의된 규칙은 검출된 손이 연속 입력 프레임 간에 미리 정의된 문턱값(예를 들어, 100픽셀 이상의 변경)보 다 큰 위치 변경을 나타내지 않아야 한다는 것일 수 있다. 상태 기반 제스처 인식을 사용하는 것은 움직임 기반 제스처 분할 및 인식보다 유리할 수 있다. 예를 들어, 정 적 제스처를 검출하는 것과 비교하여 제스처 움직임을 검출하고 처리하는데 현저히 더 많은 처리 리소스가 필요 할 수 있다. 또한, 상태 기반 제스처 인식은 위양성을 덜 일으킬 수 있다. 일부 예들에서, 본 개시는 이미지 품질을 향상시키는 것을 돕기 위해 이미지 조정을 수행하는 것을 포함하는 카 메라에 의해 캡처된 프레임들의 시퀀스에서 입력 프레임에서의 손 검출을 위한 방법을 설명한다. 일반적 으로 제스처 인식 성능은 저조도(low-light) 시나리오에서 저하되는 경향이 있다. 예를 들어, 제스처 제어 디 바이스가 암실에서 시청 중인 스마트 TV인 경우, 제스처 제어 디바이스의 카메라가 프레임들의 시퀀스를 캡처할 때 스마트 TV의 화면이 유일한 주요 광원일 수 있다. 본 발명에서는, 문제를 해결하기 위해 세 가지 방법을 제안한다. 이미지 조정을 위한 일부 예시적인 기술이 아래에서 설명되며, 이들 각각은 예를 들 어 손 검출 및 추적 서브시스템에 의해 구현될 수 있고 조합하여 사용될 수 있다. 도 19는 카메라에 의해 캡처된 프레임들의 시퀀스에서 이미지 조정을 수행하는 것을 포함하여 손 검출 및 추적을 수행하기 위한 예시적인 방법을 예시하는 흐름도이다. 방법은 위에서 설명된 단계의 일부로서 사용될 수 있다. 예를 들어, 방법은 손 검출 및 추적 서브시스템에 의해 구현될 수 있다. 방법은 단계를 위해 다른 기술을 사용하여 구현될 수 있고, 아래에서 설명되는 이미지 조정이 사용 될 수도 있고 사용되지 않을 수도 있음을 이해해야 한다. 방법은 가상 제스처-공간이 정의된 후(예를 들어, 단계에서 가상 제스처 공간 생성 서브시스템 에 의해) 시작된다.1902에서, 카메라에 의해 캡처된 프레임들의 시퀀스의 이전 입력 프레임에서 손이 이미 검출되었는지 여부 가 결정된다. 손이 이미 검출되었다면, 방법은 단계로 진행할 수 있다. 예를 들어, 이전 입력 프 레임에서 손이 이미 성공적으로 검출된 경우, 이전 입력 프레임에서 손을 성공적으로 검출하여 생성된 경계 상 자를 프레임들의 시퀀스의 현재 입력 프레임에서 손을 추적하기 위한 시작점으로 사용할 수 있다(예를 들어, 연 속 프레임 사이의 시간이 손이 적어도 부분적으로 이전 경계 상자 내에 있을 만큼 충분히 짧다는 가정에 기초해 서). 또한, 프레임들의 시퀀스의 이전 입력 프레임에서 손이 성공적으로 검출된 경우, 환경의 조명이 충분하고 (예를 들어, 환경의 조명 레벨이 연속 프레임 사이의 짧은 시간에 크게 변경되지 않아야 한다는 가정에 기초해 서) 이미지 조정이 필요하지 않다고 간주될 수 있다. 카메라에 의해 캡처된 프레임들의 시퀀스에서 이전 입력 프레임에서 손이 이미 검출되지 않았다면, 방법 은 단계로 진행한다. 선택적으로, 1904에서 이미지 조정이 수행된다. 일부 예들에서, 이미지 조정이 필요하다고 결정되는 경우에만 이미지 조정이 수행될 수도 있다. 예를 들어, 제스처 제어 디바이스의 광 센서는 주변 광 레벨을 검출하 고 광 레벨이 이미지 조정을 필요로 할 만큼 충분히 낮은지를 결정하기 위해 사용될 수 있다. 일부 예들에서, 이미지 조정이 필요한지 여부를 결정하기 위해 입력 이미지의 적어도 일부(예를 들어, 전체 입력 이미지에 걸쳐, 가상 제스처-공간에만 걸쳐, 또는 손 경계 상자에만 걸쳐)의 분석이 수행될 수 있다(예를 들어, 전체 픽 셀 강도 레벨을 결정). 일부 예들에서, 이미지 조정이 필요한지 여부를 먼저 결정하지 않고 이미지 조정이 디폴트로 수행될 수도 있다. 이러한 경우 이미지가 이미 충분히 조명되어 있는 경우 이미지 조정(예를 들어, 감마 보정(gamma correction)) 을 수행해도 이미지가 거의 또는 전혀 변경되지 않을 수 있다. 특히 저조도 조건을 보정하기 위해 다양한 기술을 이미지 조정에 사용할 수 있다. 일부 예에서, 이미지 조정은 프레임들의 시퀀스의 이전 프레임에서 검출된 얼굴을 참조로 사용하여 이미지의 조 명을 조정하는 것을 포함할 수 있다(사람 얼굴이 해부학적 특징인 경우). 얼굴이 이전 프레임에서 검출되었다 고 가정하면(예를 들어, 얼굴 검출 및 추적 서브시스템을 사용하여), 검출된 얼굴은 입력 프레임에 대한 조명 조정을 수행하기 위한 기준으로 사용될 수 있다. 및 가 각각 저조도 및 선호하는 조명 조건에서 캡처된 얼굴 이미지에 대한 픽셀 강도의 미리 정의 된(예를 들어, 교정(calibration)을 통해 경험적으로 결정되거나 미리 코딩된) 평균 및 표준 편차를 나타내도록 한다. 도 20은 얼굴을 포함하는 이미지가 저조도에서 캡처될 때의 픽셀 강도 값의 대표적인 히스토그램과 얼굴 을 포함하는 이미지가 선호 조명에서 캡처될 때의 픽셀 강도 값의 대표적인 히스토그램을 나타내는 그래 프이다. 저조도 픽셀로부터 선호하는 조명 픽셀로의 매핑은 다음 방정식을 사용하여 계산할 수 있다:"}
{"patent_id": "10-2022-7035829", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "이 방정식을 사용하여, 입력 프레임에 정의된 가상 제스처-공간 내의 모든 픽셀 는 더 나은 손 검출을 위해 위의 매핑 공식을 사용하여 조정된 픽셀 로 변환될 수 있다. 위의 설명은 저조도 조건을 보정하기 위한 조명 조정에 대해 논의하지만, 유사한 조명 조정을 사용하여 지나치게 밝은 조건을 보정할 수 있음을 이해해야 한다. 일부 예에서, 이미지 조정은 감마 보정(조도 보정의 형태로 간주될 수 있음)을 수행하는 것을 포함할 수 있다. 다양한 감마 보정 기술이 사용될 수 있다. 예를 들어, 를 입력 프레임의 단일 채널의 픽셀 값이라고 한다. 다음으로, 감마 변환은 다음과 같이 계산할 수 있다:"}
{"patent_id": "10-2022-7035829", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서 는 조정된 픽셀 값이고 γ_는 감마 변환의 표준 매개변수이다. 일부 예들에서, 이미지 조정은 제스처 제어 디바이스의 디스플레이를 변경하는 것을 포함할 수 있다. 이 접근 방법은 제스처 제어 디바이스의 화면이 환경의 조명 소스인 상황(예를 들어, 제스처 제어 디바이스가 텔레비전, 스마트폰 또는 태블릿임)에서 유용할 수 있다. 그러한 접근 방법에서, 저조도 조건은 임의 의 적절한 기술을 사용하여 먼저 검출될 수 있다. 예를 들어, 저조도 조건은 제스처 제어 디바이스의 일 부일 수 있는 광 센서를 사용하여 검출될 수 있다. 저조도 조건은 또한 입력 프레임의 픽셀 강도를 분석함으로 써 검출될 수 있고, 대다수의 픽셀이 미리 정의된 강도 문턱값 아래로 떨어지면 저조도 조건이 결정될 수 있다. 저조도 조건이 검출된 후, 제스처 제어 디바이스의 디스플레이 콘텐츠 및/또는 화면의 밝기는 더 나은 품 질의 이미지를 캡처하기 위해 화면이 더 강한 광원이 되도록 제어될 수 있다. 적응형 제스처 감지 시스템(30 0)으로부터의 출력은 입력 프레임이 열악한 조명을 갖는 것으로 분석되었음을 나타내기 위해 통신될 수 있고, 처리 디바이스는 디스플레이 콘텐츠 및/또는 화면의 밝기를 그에 따라 변경하도록 디스플레이를 제어 할 수 있다. 일부 예들에서, 저조도 조건의 검출이 이미지 분석에 기초하지 않는 경우(예를 들어, 제스처 제어 디바이스의 광 센서를 사용하여), 그에 따라 처리 디바이스는 적응형 제스처 감지 시스템으로부 터의 정보 없이 디스플레이를 제어할 수 있다. 일부 예들에서, 이러한 방식으로 디스플레이 콘텐츠 및/또는 밝기를 제어하는 것은 저조도 조건이 검출된 후 및 제스처 입력이 시작된 후(예를 들어, 사용자가 제스처 기반 명령 입력을 활성화하기 위해 수동으로 입력을 제공하였거나 인식된 손 제스처가 초기에 검출되었음) 수행될 수 있다. 일부 실시예에서, 제스처 제어 디바이 스의 화면은 화면 배경 조명을 더 밝게 변경하도록 제어될 수 있다. 일부 실시예에서, 제스처 제어 디바 이스의 화면은 디스플레이된 콘텐츠에 조명 섹션을 추가하도록 제어될 수 있다. 조명 섹션은 디스플레이 의 더 밝은 섹션(예를 들어, 전체 흰색 섹션)일 수 있다. 예를 들어, 도 21a는 규칙적인 조명 조건 하에서 또는 제스처 입력이 텔레비전 또는 스마트폰과 같은 제스처 제 어 장치의 디스플레이에서 시작되지 않았을 때 디스플레이될 수 있는 일반 이미지를 도시한다. 저 조도 조건이 검출되고 제스처 입력이 시작된 후, 디스플레이된 콘텐츠는 도 21b의 콘텐츠로 조정될 수 있다. 도 21b에서, 이미지는 크기가 감소되었고 조명 섹션이 추가되었다. 이 예에서, 조명 섹션은 디 스플레이의 4개의 측면 모두를 따른 경계선이다. 다른 섹션에서, 조명 섹션은 단지 한 측면, 2개의 측면, 또는 3개의 측면을 따라 있을 수 있거나, 디스플레이의 하나 이상의 측면을 따라 불연속적인 섹션을 포함 할 수 있다. 조명 섹션의 밝기, 색조 및/또는 크기(예를 들어, 두께 및 길이)는 검출된 저조도 조건에 기초해서 자동으로 조정될 수 있다. 예를 들어, 미리 정의된 문턱값(예를 들어, 검출된 픽셀 강도에 기초하여, 또는 광 센서의 출력에 기초하여)에서 저조도의 상이한 레벨이 존재할 수 있고, 조명 섹션에 대한 상이한 매개변수가 상이한 저조도 레벨에서 미리 정의될 수 있다. 일반적으로, 더 낮은 조명 레벨은 더 크고 그리고/ 또는 더 밝은 조명 섹션을 필요로 할 수 있다. 도 19로 돌아가면, 1906에서, 가상 제스처-공간에서 손 검출이 수행된다(예를 들어, 손 검출 및 추적 서브시스 템을 사용하여). 손 검출 및 추적 서브시스템은 상술한 바와 같이 이미지에서 손을 검출하도 록 구성된 훈련된 신경망을 포함할 수 있다. 훈련된 신경망을 사용하는 손 검출 및 추적 서브시스템에 의 한 성공적인 손 검출은 가상 제스처 공간에서 검출된 손에 대해 정의된 경계 상자를 출력할 수 있다. 1908에서, 검출된 손에 대해 정의된 경계 상자에 기초해서 손 검출 및 추적 서브시스템을 사용하여 손 추 적이 수행된다. 경계 상자는 추적에 기초해서 업데이트될 수 있다. 손 검출 및 추적(예를 들어, 손에 대해 정의된 경계 상자)으로부터의 정보는 제스처 인식을 위해(예를 들어, 제 스처 인식 서브시스템에 의해) 제공될 수 있다. 다양한 예들에서, 본 개시는 제스처 입력들을 검출하고 인식하기 위한 정확도 및 효율성을 개선하는 것을 돕기 위한 시스템 및 방법을 기술한다. 본 개시는 복잡한 환경에서 제스처 입력을 검출 및 인식하는데 그리고/또는 제스처의 장거리 검출에 유용할 수 있다. 위에서 설명한 방법 중 하나 이상(예를 들어, 적응형 ROI 기술, 경계 상자 정제 조인트 네트워크, 가상 제스처- 공간, 이미지 조정, 상태 기반 제스처 인식)을 사용하면 복잡한 실생활 시나리오에서도 제스처 입력을 보다 강 력하게 검출하고 인식할 수 있다. 제스처 검출의 향상된 정확도는 캡처된 입력 프레임의 더 효율적인 처리를 가능하게 할 수 있다. 일부 예에서, 입력 프레임은 이미지 캡처 속도보다 낮은 주파수로 처리될 수 있다. 예 를 들어, 모든 입력 프레임을 처리하는 대신, 모든 N(N>1) 프레임이 얼굴(또는 기타 구별되는 해부학적 특징) 및 손 검출 및 추적을 위해 처리된다. N은 사용자가 선택하거나, 사전 프로그래밍될 수 있거나, 제스처 제어 디바이스에 의해 자동으로 선택될 수 있는 매개변수일 수 있다(예를 들어, 미리 정의된 문턱값 미만의 속 도로 이미지가 캡처되는 경우 N은 1일 수 있고; 미리 정의된 문턱값을 초과하여 이미지가 캡처되는 경우 N은 2일 수 있고; 이미지 품질이 좋지 않거나 해상도가 낮은 경우 N은 1일 수 있고; 이미지 해상도가 높은 경우 N은 2 이상일 수 있음). 모든 N(N>1) 프레임을 처리함으로써, 제스처 검출 및 인식은 여전히 거의 실시간으로 높은 정확도로 수행될 수 있으며, 제스처 제어 디바이스에 필요한 처리 리소스가 감소될 수 있다. 본 개시는 얼굴 및 손 검출을 위해 신경망을 사용하는 예시적인 구현을 설명한다. 제스처 분류 및 인식의 정확 도를 향상시키는데 도움이 되도록 손 경계 상자의 정제를 가능하게 하는 예시적인 조인트 신경망이 기술된다. 일부 예들에서, 검출된 인간 얼굴(또는 다른 구별되는 해부학적 특징)에 기초해서 정의될 수 있는 가상 제스처 공간이 기술된다. 손 검출을 위해 정의된 가상 제스처-공간을 사용함으로써, 손 제스처의 보다 정확하고 그리 고/또는 효율적인 검출이 달성될 수 있다. 일부 예에서, 가상 제스처-공간은 특정 부분 공간에 대한 제스처 입 력이 마우스 입력에 매핑될 수 있는 부분 공간으로 추가로 정의될 수 있다. 따라서, 가상 제스처-공간은 가상 마우스로 사용될 수 있다. 디스플레이 및 카메라를 갖는(스마트 TV, 스마트폰 또는 태블릿과 같은) 제스처 제어 디바이스의 맥락에서 예들 이 설명되었지만, 본 개시는 디스플레이 및/또는 카메라를 포함하거나 포함하지 않을 수 있는 다른 제스처 제어 디바이스와 관련될 수 있다. 예를 들어, 본 개시는 스마트 스피커, 스마트 가전, 사물 인터넷(IoT) 디바이스, 대시보드 디바이스(예를 들어, 차량에 설치됨) 또는 계산 리소스가 적은 디바이스와 관련될 수 있다. 본 명세서에 설명된 예들은 인공 현실(AR), 가상 현실(VR) 및/또는 비디오 게임 애플리케이션에 적용될 수 있다. 본 개시는 특정 순서의 단계를 갖는 방법 및 프로세스를 설명하지만, 방법 및 프로세스의 하나 이상의 단계는 적절하게 생략되거나 변경될 수 있다. 설명된 순서와 다른 순서로 하나 이상의 단계를 수행할 수 있다. 본 개시가 적어도 부분적으로 방법의 관점에서 설명되지만, 당업자는 본 개시가 또한 설명된 방법의 양태 및 특 징 중 적어도 일부를 수행하기 위한 다양한 구성요소에 관한 것임을 이해할 것이고, 설명된 방법은 하드웨어 구 성요소, 소프트웨어 또는 이 둘의 조합을 통해 이루어진다. 따라서, 본 발명의 기술 솔루션은 소프트웨어 제품 의 형태로 구현될 수 있다. 적절한 소프트웨어 제품은 미리 기록된 저장 장치 또는, 예를 들어, DVD, CD-ROM, USB 플래시 디스크, 이동식 하드 디스크, 또는 기타 저장 매체를 포함하는 다른 유사한 비휘발성 또는 비일시적 컴퓨터 판독가능 매체에 저장될 수 있다. 소프트웨어 제품은 처리 디바이스(예를 들어, 개인용 컴퓨터, 서버 또는 네트워크 장치)가 본 명세서에 개시된 방법의 예를 실행할 수 있게 하는 유형적으로 저장된 명령어를 포함 한다. 본 개시는 청구범위의 주제를 벗어나지 않으면서 다른 특정한 형태로 구체화될 수 있다. 설명된 예시적인 실시 예들은 모든 면에서 단지 예시적인 것이며 제한적인 것이 아닌 것으로 간주되어야 한다. 상술한 실시예 중 하 나 이상으로부터 선택된 특징은 명시적으로 설명되지 않은 대안적인 실시예를 생성하기 위해 조합될 수 있으며, 이러한 조합에 적합한 특징은 본 개시의 범위 내에서 이해된다. 개시된 범위 내의 모든 값 및 하위 범위 또한 개시된다. 또한, 본 명세서에 개시되고 도시된 시스템, 디바이스, 및 프로세스가 특정 수의 요소/구성요소를 포함할 수 있지만, 시스템, 디바이스 및 어셈블리는 그러 한 요소/구성요소의 추가 또는 더 적은 수를 포함하도록 수정될 수 있다. 예를 들어, 개시된 요소/구성요소 중 임의의 것이 단수인 것으로 언급될 수 있지만, 본 명세서에 개시된 실시예들은 복수의 그러한 요소/구성요소를 포함하도록 수정될 수 있다. 본 명세서에 설명된 주제는 기술의 모든 적절한 변경을 포괄하고 포함한다.도면 도면1 도면2 도면3a 도면3b 도면3c 도면3d 도면3e 도면3f 도면3g 도면3h 도면4a 도면4b 도면4c 도면5 도면6 도면7 도면8a 도면8b 도면9 도면10a 도면10b 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21a 도면21b"}
{"patent_id": "10-2022-7035829", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이제 예로서, 본 출원의 예시적인 실시예들을 도시하는 첨부 도면들을 참조할 것이다: 도 1은 예시적인 제스처 제어 디바이스와 상호 작용하는 사용자를 도시하는 블록도이다; 도 2는 예시적인 제스처 제어 디바이스의 일부 구성요소를 도시하는 블록도이다; 도 3a 내지 도 3h는 예시적인 제스처 제어 디바이스에 의해 검출 및 인식될 수 있는 일부 예시적인 제스처 클래 스를 도시한다; 도 4a 내지 도 4c는 예시적인 제스처 제어 디바이스에 의해 검출 및 인식될 수 있는 일부 예시적인 동적 제스처 를 도시한다; 도 5는 예시적인 제스처 제어 디바이스에서 구현될 수 있는 예시적인 적응형 제스처 감지 시스템의 일부 세부사 항을 도시하는 블록도이다; 도 6은 가상 제스처 공간을 사용하는 손 검출을 위한 예시적인 방법을 도시하는 흐름도이다; 도 7은 가상 마우스를 구현하기 위해 정의된 부분 공간(subspace)을 포함하는 가상 제스처 공간의 예를 도시한 다; 도 8a 및 8b는 2D 및 3D 가상 제스처 공간의 예를 도시한다; 도 9는 검출된 손에 기초한 손 검출 및 가상 제스처 공간 재정의를 위한 예시적인 방법을 나타내는 흐름도이다; 도 10a 및 10b는 도 9의 방법의 예시적인 구현을 도시한다; 도 11은 사용자 목록의 구현과 함께, 가상 제스처 공간을 사용하는 손 검출을 위한 예시적인 방법을 도시하는흐름도이다; 도 12는 적응형 ROI를 사용하여 검출을 수행하기 위한 예시적인 방법을 도시하는 흐름도이다; 도 13은 도 12의 방법에서 사용될 수 있는 예시적인 ROI 시퀀스를 도시한다; 도 14는 제스처 인식을 위해 사용될 수 있는 예시적인 조인트 네트워크를 도시하는 블록도이다; 도 15 및 16은 도 14의 조인트 네트워크를 훈련하는데 사용될 수 있는 일부 예시적인 훈련 데이터 샘플을 도시 한다; 도 17은 제스처 인식을 위한 예시적인 방법을 도시하는 흐름도이다; 도 18은 상태 기반 제스처 인식의 예를 나타내는 상태도이다; 도 19는 이미지 조정을 포함하는 손 검출을 위한 예시적인 방법을 도시하는 흐름도이다; 도 20은 픽셀 강도에 기초한 이미지 조정의 예를 나타내는 그래프이다; 그리고 도 21a 및 21b는 디스플레이된 콘텐츠에 조명 섹션을 추가하는 것을 포함하는 이미지 조정의 예를 도시한다. 유사한 구성요소를 나타내기 위해 유사한 참조 번호가 상이한 도면에서 사용될 수 있다."}
