{"patent_id": "10-2022-0164248", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0080690", "출원번호": "10-2022-0164248", "발명의 명칭": "인공지능 음성 변조를 이용한 외국어 학습 장치 및 방법", "출원인": "(주)라이언로켓", "발명자": "정승환"}}
{"patent_id": "10-2022-0164248", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 기반의 음성 변조를 이용한 외국어 학습 방법으로서,학습자 클라이언트로부터 사용자 모국어 음성 데이터를 수신하는 단계와,다국어 음성 데이터 생성 장치가 상기 사용자 모국어 음성 데이터에 기초하여 사용자의 다국어 음성 데이터를생성하는 단계와,사용자가 애플리케이션 모듈을 통해 상기 사용자의 다국어 음성 데이터에 대해 레벨 파라미터 및 조정 파라미터중 적어도 하나를 입력한 것을 수신하는 단계와,상기 사용자의 다국어 음성 데이터에 대해, 상기 사용자가 입력한 레벨 파라미터 및 조정 파라미터 중 적어도하나를 적용하는 단계와,상기 사용자가 선택한 학습 세션 또는 디폴트 설정된 학습 세션에 기초하여 상기 사용자의 다국어 음성 데이터를 활용한 외국어 학습 세션을 상기 학습자 클라이언트에게 제공하는 단계를 포함하는 외국어 학습 방법."}
{"patent_id": "10-2022-0164248", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 기반의 음성 변조를 이용한 외국어 학습 방법에 관한 것으로서, 학습자 클라이언트로부터 사 용자 모국어 음성 데이터를 수신하는 단계와, 다국어 음성 데이터 생성 장치가 상기 사용자 모국어 음성 데이터 에 기초하여 사용자의 다국어 음성 데이터를 생성하는 단계와, 사용자가 애플리케이션 모듈을 통해 상기 사용자 의 다국어 음성 데이터에 대해 레벨 파라미터 및 조정 파라미터 중 적어도 하나를 입력한 것을 수신하는 단계와, 상기 사용자의 다국어 음성 데이터에 대해, 상기 사용자가 입력한 레벨 파라미터 및 조정 파라미터 중 적어도 하 나를 적용하는 단계와, 상기 사용자가 선택한 학습 세션 또는 디폴트 설정된 학습 세션에 기초하여 상기 사용자 의 다국어 음성 데이터를 활용한 외국어 학습 세션을 상기 학습자 클라이언트에게 제공하는 단계를 포함한다."}
{"patent_id": "10-2022-0164248", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 음성 변조를 이용한 외국어 학습 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0164248", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성 합성 또는 음성 변조는 컴퓨터를 이용하여 인공적으로 음성을 합성 내지는 변조하는 기술이다. 예를 들어, 지하철과 버스 정류장의 안내 방송, 아파트 관리 사무소, ATM기에서 나오는 목소리, 은행에 전화를 걸면 흘러나오는 ARS 음성 등의 목소리들은 실제 사람의 목소리가 아니라 음성 합성을 통해 생성된 음성이다. 최근에는 음성 합성 분야에 딥러닝 알고리즘을 접목하는 기술이 각광받고 있다. 딥 러닝을 통해 정형화된 목소 리가 아니라, 사람의 말에 나타나는 미묘한 특징들도 따라할 수 있게 되었다. 일례로, 딥 러닝 기술을 통해 전 달하는 내용의 맥락에 따라 음성의 강세나 음색 등에 변화를 줄 수 있는 음성을 생성할 수 있다. 외국어 학습 분야에도 이처럼 딥러닝 알고리즘을 접목한 음성 합성 또는 음성 변조 기술을 도입하기 위한 시도 가 생겨나고 있다."}
{"patent_id": "10-2022-0164248", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명의 일 목적은 딥러닝 알고리즘을 접목하여 사용자의 모국어 음성에 기초하여 사용자가 외국어를 능숙하게 구사하는 경우의 사용자 외국어 음성 데이터를 생성하고 이에 기초하여 자신의 음성으로 외국어를 학 습하기 위한 플랫폼을 제공하는 것에 있다. 다만, 본 발명이 해결하고자 하는 과제는 이상에서 언급한 바로 제한되지 않으며, 언급되지는 않았으나 아래의"}
{"patent_id": "10-2022-0164248", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있는 목적을 포함할수 있다."}
{"patent_id": "10-2022-0164248", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이하 본 발명의 목적을 달성하기 위한 구체적 수단에 대하여 설명한다. 본 발명의 일 실시예에 따른 인공지능 기반의 음성 변조를 이용한 외국어 학습 방법은, 학습자 클라이언트로부 터 사용자 모국어 음성 데이터를 수신하는 단계와, 다국어 음성 데이터 생성 장치가 상기 사용자 모국어 음성 데이터에 기초하여 사용자의 다국어 음성 데이터를 생성하는 단계와, 사용자가 애플리케이션 모듈을 통해 상기 사용자의 다국어 음성 데이터에 대해 레벨 파라미터 및 조정 파라미터 중 적어도 하나를 입력한 것을 수신하는 단계와, 상기 사용자의 다국어 음성 데이터에 대해, 상기 사용자가 입력한 레벨 파라미터 및 조정 파라미터 중 적어도 하나를 적용하는 단계와, 상기 사용자가 선택한 학습 세션 또는 디폴트 설정된 학습 세션에 기초하여 상 기 사용자의 다국어 음성 데이터를 활용한 외국어 학습 세션을 상기 학습자 클라이언트에게 제공하는 단계를 포 함한다."}
{"patent_id": "10-2022-0164248", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기한 바와 같이, 본 발명에 의하면 이하와 같은 효과가 있다. 본 발명의 일 실시예에 따르면, 딥러닝 알고리즘을 접목하여 사용자의 모국어 음성에 기초하여 사용자가 외국어 를 능숙하게 구사하는 경우의 사용자 외국어 음성 데이터를 생성하고 이에 기초하여 자신의 음성으로 외국어를 학습하기 위한 플랫폼을 제공할 수 있다. 다만, 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효 과들은 아래의 기재로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있 을 것이다."}
{"patent_id": "10-2022-0164248", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 발명을 쉽게 실시할 수 있는 실시예를 상세히 설명한다. 다만, 본 발명의 바람직한 실시예에 대한 동작원리를 상세하게 설명함에 있 어서 관련된 공지기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되 는 경우에는 그 상세한 설명을 생략한다. 또한, 도면 전체에 걸쳐 유사한 기능 및 작용을 하는 부분에 대해서는 동일한 도면 부호를 사용한다. 명세서 전 체에서, 특정 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐만 아니라, 그 중간에 다른 소자를 사이에 두고, 간접적으로 연결되어 있는 경우도 포함한다. 또한, 특정 구성요소를 포함한다 는 것은 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라, 다른 구성요소를 더 포함할수 있는 것을 의미한다. 딥러닝 기반 음성 변조를 이용한 다국어 음성 데이터 생성 장치의 구성 도 1은 본 발명의 일 실시예에 따른 딥러닝 기반 음성 변조를 이용한 다국어 음성 데이터 생성 장치를 개략적으 로 나타내는 도면이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 딥러닝 기반 음성 변조를 이용한 다국어 음성 데이터 생성 장치 는 음성 처리 인공신경망 모듈 및 언어 처리 인공신경망 모듈과, 디코더 인공신경망 모듈과, 멜 스펙트로그램 인공신경망 모듈과, 외국어 음성 생성 모듈을 포함할 수 있다. 다국어 음성 데이터 생성 장치에는 사용자가 자신의 모국어로 발화한 음성에 대한 사용자 모국어 음성 데 이터, 및 다양한 외국어에 대한 복수의 언어 모델을 포함하는 다국어 언어 모델이 입력으로 제공될 수 있다. 그리고 다국어 음성 데이터 생성 장치는 사용자 모국어 음성 데이터 및 다국어 언어 모델 을 처리하여 사용자의 다국어 음성 데이터를 생성할 수 있다. 사용자의 다국어 음성 데이터는 사용자 의 음성의 특성, 예를 들어, 톤, 빠르기, 억양, 발음 등을 다양한 외국어에 접목하여 사용자가 외국어를 능숙하 게 구사하는 경우를 상정한 데이터일 수 있다. 다만, 외국어의 구사 정도는 파라미터 설정에 의해 다양한 수준 으로 설정할 수 있다. 예를 들어, 사용자가 영어를 원어민 수준으로 완벽히 구사하는 경우, 사용자가 영어를 1 년 정도 공부한 수준으로 구사하는 경우 등 다양한 수준으로 설정할 수도 있다. 이하에서는 본 발명의 일 실시예에 따른 다국어 음성 데이터 생성 장치의 구체적인 동작 과정에 대해서 설 명하도록 한다. ① 음성 처리 인공신경망 모듈이 사용자 모국어 음성 데이터를 입력받아 사용자 모국어 음성 데이터 의 음성 특징 벡터를 생성하여 출력하고, 언어 처리 인공신경망 모듈이 다국어 언어 모델을 입 력받아 다국어 언어 모델의 언어 특징 벡터를 생성하여 출력할 수 있다. 한편, 사용자 모국어 음성 데이터는 사용자가 자신의 모국어(예를 들어, 한국어)를 소정의 시간(예를 들어, 1분 내지 5분, 또는 30분 내지 1시간) 동안 발화한 것일 수 있다. 이 때, 사전에 정해진 스크립트를 사용자가 읽도록 하는 방식 등이 사용될 수 있다. 또한, 언어 특징 벡터는 외국어 별로 사전에 생성되어 있을 수 있으며, 다국어 언어 모델 자체가 언어 특징 벡터로 구성되어 인공신경망 모듈에 의한 별도의 처리를 요하지 않을 수도 있으며, 이에 대해 한정하 지 않는다. ② 디코더 인공신경망 모듈이 음성 특징 벡터 및 언어 특징 벡터를 결합(Concatenation)한 입력 벡 터를 예를 들어 Sequence의 형태로 입력받고, 음성 합성 벡터를 Sequence의 형태로 출력할 수 있다. 일 실시예 에 따르면, 디코더 인공신경망 모듈은 순환 인공신경망(RNN)으로 구성되어 Sequence 형태의 입력 벡터가 입 력된 이후부터는 이전 시기의 음성 합성 벡터의 적어도 일부 스펙트로그램 정보(이전 시기가 t=initial 인 경우 에는 <go>)가 입력 벡터로서 입력되어 현재 시기의 음성 합성 벡터를 출력할 수 있다. ③ 멜 스펙트로그램 인공신경망 모듈(CNN, Convolutional Neural Network)이 음성 합성 벡터를 입력받아 음성 합성 벡터에 대한 보코더 입력 정보인 멜 스펙트로그램(Mel-Spectrogram)을 생성할 수 있다. 이 때, 예를 들어, 본 발명의 일 실시예에 따른 음성 처리 인공신경망 모듈 및 언어 처리 인공신경망 모듈은 256- unit GRU 1 Layer로 구성될 수 있고, 디코더 인공신경망 모듈은 모델의 보다 빠른 수렴을 위하여 residual connection을 포함한 256-unit GRU 2 Layer로 구성될 수 있다. 본 발명의 일실시예에 따른 멜 스펙트로그램 인공신경망 모듈은 n-layer의 ConvNet(CNN, Convolutional Neural Network)으로 구성되어 입력 데이터를 음성 합성 벡터로 하고, 출력 데이터를 해당 음성 합성 벡터의 멜 스펙트로그램(보코더 입력 정보)으로 하는 인공신경망 모듈일 수 있다. 본 발명에서는 설명의 편의를 위하여 멜 스케일의 스펙트로그램인 멜 스펙트로그램으로 기재하였으나 본 발 명의 범위는 이에 한정되지 않으며, 본 발명의 일 실시예에 따른 보코더 입력 정보는 멜 스펙트로그램에 한정되 지 않으며, mel-filterbank를 거치지 않은 기본적인 spectrogram, 스펙트럼, Fundamental frequency를 의미하 는 f0 등 Fourier Transform을 활용한 주파수 정보, 신호에서의 비주기성 구성요소와 음성 신호간 비율을 의미 하는 aperiodicity 등을 포함할 수 있다. 외국어 음성 생성 모듈은 음성 합성 벡터에 대한 보코더 입력 정보인 음성 합성 벡터의 멜 스펙트로그램 (Mel-Spectrogram)를 수신하고, 이에 기초하여 사용자의 다국어 음성 데이터(예를 들어, 1025차 선형 스케일 스펙트로그램)를 생성하기 위한 보코더 모듈(vocoder module)일 수 있다. 외국어 음성 생성 모듈은 예를 들어 Griffin-Lim, WaveNet 등으로 형성될 수 있으며, 멜 스케일의 음성 합성 벡터를 선형 스케일로 변환 하기 위한 후처리 네트워크일 수 있으나, 이에 대해 한정하지는 않는다. 인공지능 기반 음성 변조를 이용한 외국어 학습 장치의 구성 도 2는 본 발명의 일 실시예에 따른 인공지능 기반 음성 변조를 이용한 외국어 학습 장치를 개략적으로 나타내 는 도면이다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 인공지능 기반 음성 변조를 이용한 외국어 학습 장치는 학 습자 클라이언트의 애플리케이션 모듈을 통해 사용자로부터 수신한 사용자 모국어 음성 데이터에 기반하여 다국어 음성 데이터 생성 장치가 생성하여 출력한 사용자의 다국어 음성 데이터를 활용하여 사용자에게 자신이 외국어를 능숙하게 구사하는 경우의 해당 외국어에 대한 톤, 빠르기, 억양, 발음 등을 참고 하면서 외국어 학습을 효율적으로 진행할 수 있도록 해준다. 또한, 인공지능 기반 음성 변조를 이용한 외국어 학습 장치는 레벨 파라미터, 조정 파라미터 및 학습 세션 모듈을 포함하여 사용자가 자신의 다국어 음성 데이터의 외국어 구사 수준, 발음, 톤 등을 조절 가능하도록 하였으며, 다양한 학습 세션을 구비하여 외국어 학습의 흥미도를 향상시킬 수 있도록 하였다. 구체적으로는, 레벨 파라미터는 사용자의 다국어 음성 데이터에 있어서 외국어의 구사 수준을 설정할 수 있는 파라미터일 수 있다. 예를 들어, 사용자가 영어를 원어민 수준으로 완벽히 구사하는 경우, 사용자가 영어를 1년 정도 공부한 수준으로 구사하는 경우 등 다양한 수준으로 설정할 수 있다. 조정 파라미터는 사용자의 다국어 음성 데이터에 있어서 외국어를 구사하는 발음, 톤, 억양 등을 세부 조정할 수 있도록 하는 파라미티일 수 있다. 예를 들어, 영어의 경우도 미국식 발음과 영국식 발음과 같이 발 음 상 미묘한 차이가 있을 수 있고 사용자가 원하는 느낌의 톤이나 억양이 존재할 수 있으므로 이에 대해 세부 조정을 할 수 있도록 하여 사용자의 취향을 살릴 수 있도록 할 수 있다. 학습 세션 모듈은 예를 들어, 사용자의 다국어 음성 데이터를 따라하고 그 모사 정도에 대해 점수를 부여하는 학습 세션, 사용자의 다국어 음성 데이터를 이용한 \"가상의 나\"와 대화를 할 수 있는 학습 세션, 사용자가 텍스트를 입력하면 이를 사용자의 다국어 음성 데이터를 이용하여 청취해볼 수 있는 학습 세션 등 다양한 학습 세션을 구비함으로써 게임을 하는 듯한 느낌을 주어 사용자의 외국어 학습의 효율을 높일 수 있다. 인공지능 기반의 음성 변조를 이용한 외국어 학습 방법 도 3은 본 발명의 일 실시예에 따른 인공지능 기반의 음성 변조를 이용한 외국어 학습 방법을 나타내는 흐름도 이다. 도 3을 참조하면, 먼저 단계 S10에서, 학습자 클라이언트로부터 사용자의 모국어 음성 데이터를 수신할 수 있다. 사용자 모국어 음성 데이터는 사용자가 자신의 모국어(예를 들어, 한국어)를 소정의 시간(예를 들어, 1 분 내지 5분, 또는 30분 내지 1시간) 동안 발화한 것일 수 있다. 단계 S20에서, 다국어 음성 데이터 생성 장치가 사용자 모국어 음성 데이터에 기초하여 사용자의 다국어 음성 데이터를 생성할 수 있다. 단계 S30에서, 사용자가 애플리케이션 모듈을 통해 사용자의 다국어 음성 데이터에 대해 레벨 파라미터 및 조정 파라미터 중 적어도 하나를 입력한 것을 수신할 수 있다. 파라미터 입력이 생략되는 경우도 있을 수 있으며, 이 경우 디폴트 설정된 파라미터가 적용될 수 있다. 단계 S40에서, 사용자의 다국어 음성 데이터에 대해, 사용자가 입력한 레벨 파라미터 및 조정 파라미터 중 적어 도 하나를 적용할 수 있다. 단계 S50에서, 사용자가 선택한 학습 세션 또는 디폴트 설정된 학습 세션에 기초하여 사용자의 다국어 음성 데 이터를 활용한 외국어 학습 세션을 학습자 클라이언트에게 제공할 수 있다. 이상에서 설명한 바와 같이, 본 발명이 속하는 기술 분야의 통상의 기술자는 본 발명이 그 기술적 사상이나 필 수적 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 상술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범 위는 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 등가 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함하는 것으로 해석되어야 한다. 본 명세서 내에 기술된 특징들 및 장점들은 모두를 포함하지 않으며, 특히 많은 추가적인 특징들 및 장점들이 도면들, 명세서, 및 청구항들을 고려하여 당업자에게 명백해질 것이다. 더욱이, 본 명세서에 사용된 언어는 주 로 읽기 쉽도록 그리고 교시의 목적으로 선택되었고, 본 발명의 주제를 묘사하거나 제한하기 위해 선택되지 않 을 수도 있다는 것을 주의해야 한다. 본 발명의 실시예들의 상기한 설명은 예시의 목적으로 제시되었다. 이는 개시된 정확한 형태로 본 발명을 제한 하거나, 빠뜨리는 것 없이 만들려고 의도한 것이 아니다. 당업자는 상기한 개시에 비추어 많은 수정 및 변형이 가능하다는 것을 이해할 수 있다. 그러므로 본 발명의 범위는 상세한 설명에 의해 한정되지 않고, 이를 기반으로 하는 출원의 임의의 청구항들에 의해 한정된다. 따라서, 본 발명의 실시예들의 개시는 예시적인 것이며, 이하의 청구항에 기재된 본 발명의 범 위를 제한하는 것은 아니다."}
{"patent_id": "10-2022-0164248", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 첨부되는 다음의 도면들은 본 발명의 바람직한 실시예를 예시하는 것이며, 발명의 상세한 설명과 함께 본 발명의 기술사상을 더욱 이해시키는 역할을 하는 것이므로, 본 발명은 그러한 도면에 기재된 사항에만 한정되어 해석되어서는 아니 된다. 도 1은 본 발명의 일 실시예에 따른 딥러닝 기반 음성 변조를 이용한 다국어 음성 데이터 생성 장치를 개략적으 로 나타내는 도면이다. 도 2는 본 발명의 일 실시예에 따른 인공지능 기반 음성 변조를 이용한 외국어 학습 장치를 개략적으로 나타내 는 도면이다. 도 3은 본 발명의 일 실시예에 따른 인공지능 기반의 음성 변조를 이용한 외국어 학습 방법을 나타내는 흐름도 이다."}
