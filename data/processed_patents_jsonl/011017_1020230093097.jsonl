{"patent_id": "10-2023-0093097", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0012917", "출원번호": "10-2023-0093097", "발명의 명칭": "영상 컨텐츠 제공 시스템 및 방법", "출원인": "손지언", "발명자": "손지언"}}
{"patent_id": "10-2023-0093097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 프레임을 포함하는 제1 영상을 수신하는 수신부;상기 제1 영상을 기초로 컨텐츠 정보 및 피사체 분석 정보를 생성하는 컨텐츠 분석부;상기 제1 영상 및 상기 컨텐츠 정보를 기초로 번역하여 상기 제1 영상에 대응되는 제2 영상을 생성하는 번역부;및상기 제2 영상, 상기 컨텐츠 정보 및 피사체 분석 정보를 기초로 상기 제2 영상에 대응되는 3차원 모델링 정보를 포함하는 제1 컨텐츠를 생성하는 컨텐츠 생성부를 포함하는 컨텐츠 제공 시스템."}
{"patent_id": "10-2023-0093097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 컨텐츠 분석부는, 상기 제1 영상에서 인식되는 객체 중 미리 저장된 카테고리 리스트에 포함된 구성 요소와 미리 설정된 기준값 이상 일치하는 제1 객체를 인식하고, 상기 제1 객체를 기초로 상기 제1 영상의 주제를분류하여 영상 분야 데이터를 생성하고, 상기 제1 영상에서 제1 음성 데이터 및 제1 자막 데이터 중 적어도 하나를 추출하여 상기 제1 영상에 대응되는 제1 언어를 식별하여 제1 언어 데이터를 생성하고, 상기 컨텐츠 정보는 상기 영상 분야 데이터 및 상기 제1 언어에 대응한 제1 언어 데이터를 포함하는 컨텐츠 제공 시스템."}
{"patent_id": "10-2023-0093097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 피사체 분석 정보는, 상기 제1 객체에 포함되는 피사체 객체의 행동 제스처 및 음성을 기초로 생성되는 상기 피사체 객체의 패턴 데이터인 컨텐츠 제공 시스템."}
{"patent_id": "10-2023-0093097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서,상기 컨텐츠 생성부는, 상기 제1 객체 중 피사체 객체가 아닌 제2 객체가 인식되는 상기 제1 영상 및 상기 제2영상 중 적어도 하나에 포함된 프레임을 인공 지능 모델에 제공하여 상기 모델링 정보를 생성하는 컨텐츠 제공시스템."}
{"patent_id": "10-2023-0093097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 수신부는 상기 제1 컨텐츠 및 상기 제1 영상 중 하나에 대응되는 피드백 정보를 수신하고,상기 컨텐츠 분석부, 상기 번역부 및 상기 컨텐츠 생성부 중 적어도 하나는, 상기 피드백 정보를 기초로 업데이트되는 컨텐츠 제공 시스템.공개특허 10-2025-0012917-3-청구항 6 제1 영상을 기초로 컨텐츠 정보 및 피사체 분석 정보를 생성하는 단계;상기 제1 영상 및 상기 컨텐츠 정보를 기초로 번역하여 상기 제1 영상에 대응되는 제2 영상을 생성하는 단계;상기 제2 영상 및 상기 피사체 분석 정보를 기초로 상기 제2 영상에 대응되는 3차원 모델링 정보 및 상기 제2영상을 포함하는 제1 컨텐츠를 생성하는 단계; 및상기 제2 영상에 포함된 복수의 프레임 중 제1 프레임이 선택되는 경우, 상기 모델링 정보 중 상기 제1 프레임에 대응되는 제1 모델링 정보를 제공하는 단계를 포함하는 컨텐츠 제공 방법."}
{"patent_id": "10-2023-0093097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 제1 영상에서 인식되는 객체 중 미리 저장된 카테고리 리스트에 포함된 구성 요소와 미리 설정된 기준값이상 일치하는 제1 객체를 인식하는 단계; 및상기 제1 영상 및 제2 영상 중 적어도 하나에서 상기 제1 객체가 인식되는 제1 프레임과, 제1 객체를 인식한 데이터를 인공 지능 모델에 제공하여 상기 제1 객체에 대응하는 제1 모델링 정보를 생성하는 단계를 더 포함하고,상기 모델링 정보는 상기 제1 모델링 정보를 포함하는 컨텐츠 제공 방법."}
{"patent_id": "10-2023-0093097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 피사체 분석 정보는, 상기 제1 영상과, 상기 제1 영상에서 추출한 제1 음성 데이터 및 제1 자막 데이터 중적어도 하나를 기초로 상기 제1 객체에 포함된 피사체 객체의 행동 제스처 및 음성에 대한 패턴 데이터인 컨텐츠 제공 방법."}
{"patent_id": "10-2023-0093097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6 항에 있어서,상기 제1 모델링 정보를 제공하는 단계는,상기 모델링 정보에서, 상기 제1 프레임에 대응되어 순차적으로 배치되는 제n 프레임 내지 제m 프레임에 대응되는 모델링 정보 리스트를 추출하는 단계; 및상기 모델링 정보 리스트 중 상기 제1 프레임과 시계열상 차이가 적은 프레임에 대응되는 상기 제1 모델링 정보를 추출하는 단계를 더 포함하는 컨텐츠 제공 방법."}
{"patent_id": "10-2023-0093097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6 항에 있어서,상기 제1 컨텐츠를 생성하는 단계는,상기 제1 영상 및 상기 제2 영상 중 하나에 포함되는 제2 프레임에 대한 피드백 정보를 수신하여 상기 제2 프레임에 대응되는 상기 모델링 정보의 제2 모델링 정보를 생성하는 단계를 더 포함하는 컨텐츠 제공 방법."}
{"patent_id": "10-2023-0093097", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 영상 컨텐츠 제공 시스템 및 방법을 개시한다. 영상 컨텐츠 제공 시스템 및 방법은, 복수의 프레임을 포함하는 제1 영상을 수신하는 수신부, 상기 제1 영상을 기초로 컨텐츠 정보 및 피사체 분석 정보를 생성하는 컨 텐츠 분석부, 상기 제1 영상 및 상기 컨텐츠 정보를 기초로 번역하여 상기 제1 영상에 대응되는 제2 영상을 생성 하는 번역부 및 상기 제2 영상, 상기 컨텐츠 정보 및 피사체 분석 정보를 기초로 상기 제2 영상에 대응되는 3차 원 모델링 정보를 포함하는 제1 컨텐츠를 생성하는 컨텐츠 생성부를 포함한다."}
{"patent_id": "10-2023-0093097", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상 컨텐츠 제공 시스템 및 방법에 관한 것이다. 구체적으로, 본 발명은 영상에 포함된 피사체의 패 턴을 기초로 영상의 각 프레임에 대응되는 3차원 모델링 정보를 생성하고, 영상 재생에 따라 3차원 모델링 정보 가 재생되는 컨텐츠를 제공하는 영상 컨텐츠 제공 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0093097", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 본 실시예에 대한 배경 정보를 제공할 뿐 종래기술을 구성하는 것은 아니다. 영상을 제공받는 시청자는, 영상의 프레임에 포함되는 이미지, 소리 및 문자를 기초로 영상이 제공하는 내용을 인지하고, 영상이 전달하고자 하는 메시지를 파악한다. 영상을 통해 시청자에게 전달되고자 하는 내용이 전문 분야에 포함되는 경우, 사용자는 영상의 이미지, 소리 및 문자만으로 내용을 제대로 인지조차 하기 어렵거나, 인지를 해도 숙지하기 어려운 상황이 발생될 수 있다. 따라 서, 전문 분야 내용이라도, 시청자가 영상의 내용을 직관적으로 인지하되 이해도의 장벽을 낮춰 줄 수 있는 컨 텐츠가 필요하다. 또한, 일반적으로 전문 분야에 대한 영상은, 국제 공용어로 제작되는 경우가 많다. 이에 따라, 영상은, 시청자 의 이해도를 위해 모국어로 번역될 필요성이 있다. 역으로 특정 언어로 제작된 영상은, 모국어가 서로 다른 복 수의 시청자에게 제공될 수 있도록 국제 공용어로 번역될 필요성이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록특허공보 제10-1630595호"}
{"patent_id": "10-2023-0093097", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은, 시청자의 영상에 대한 이해도를 높이는 3차원 모델링 정보를 제공하는 것이다. 또한, 본 발명의 목적은, 영상의 피사체 패턴 데이터를 기초로 영상에 적합한 모델링 정보를 생성하여, 시청자 의 인지 및 이해를 높이는 컨텐츠를 제공하는 것이다. 또한, 본 발명의 목적은, 영상의 주제를 기초로 대상 언어로 번역된 컨텐츠를 제공하는 것이다. 본 발명의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발 명의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것 이다."}
{"patent_id": "10-2023-0093097", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 몇몇 실시예에 따른 영상 컨텐츠 제공 시스템에 있어서, 복수의 프레임을 포함하는 제1 영상을 수신 하는 수신부, 상기 제1 영상을 기초로 컨텐츠 정보 및 피사체 분석 정보를 생성하는 컨텐츠 분석부, 상기 제1 영상 및 상기 컨텐츠 정보를 기초로 번역하여 상기 제1 영상에 대응되는 제2 영상을 생성하는 번역부 및 상기 제2 영상, 상기 컨텐츠 정보 및 피사체 분석 정보를 기초로 상기 제2 영상에 대응되는 3차원 모델링 정보를 포 함하는 제1 컨텐츠를 생성하는 컨텐츠 생성부를 포함한다. 또한, 상기 컨텐츠 분석부는, 상기 제1 영상에서 인식되는 객체 중 미리 저장된 카테고리 리스트에 포함된 구성 요소와 미리 설정된 기준값 이상 일치하는 제1 객체를 인식하고, 상기 제1 객체를 기초로 상기 제1 영상의 주제 를 분류하여 영상 분야 데이터를 생성하고, 상기 제1 영상에서 제1 음성 데이터 및 제1 자막 데이터 중 적어도하나를 추출하여 상기 제1 영상에 대응되는 제1 언어를 식별하여 제1 언어 데이터를 생성하고, 상기 컨텐츠 정 보는 상기 영상 분야 데이터 및 상기 제1 언어에 대응한 제1 언어 데이터를 포함할 수 있다. 또한, 상기 피사체 분석 정보는, 상기 제1 객체에 포함되는 피사체 객체의 행동 제스처 및 음성을 기초로 생성 되는 상기 피사체 객체의 패턴 데이터일 수 있다. 또한, 상기 컨텐츠 생성부는, 상기 제1 객체 중 피사체 객체가 아닌 제2 객체가 인식되는 상기 제1 영상 및 상 기 제2 영상 중 적어도 하나에 포함된 프레임을 인공 지능 모델에 제공하여 상기 모델링 정보를 생성할 수 있다. 또한, 상기 수신부는 상기 제1 컨텐츠 및 상기 제1 영상 중 하나에 대응되는 피드백 정보를 수신하고, 상기 컨 텐츠 분석부, 상기 번역부 및 상기 컨텐츠 생성부 중 적어도 하나는, 상기 피드백 정보를 기초로 업데이트될 수 있다. 본 발명의 몇몇 실시예에 따른 영상 컨텐츠 제공 방법에 있어서, 제1 영상을 기초로 컨텐츠 정보 및 피사체 분 석 정보를 생성하는 단계, 상기 제1 영상 및 상기 컨텐츠 정보를 기초로 번역하여 상기 제1 영상에 대응되는 제 2 영상을 생성하는 단계, 상기 제2 영상 및 상기 피사체 분석 정보를 기초로 상기 제2 영상에 대응되는 3차원 모델링 정보 및 상기 제2 영상을 포함하는 제1 컨텐츠를 생성하는 단계 및 상기 제2 영상에 포함된 복수의 프레 임 중 제1 프레임이 선택되는 경우, 상기 모델링 정보 중 상기 제1 프레임에 대응되는 제1 모델링 정보를 제공 하는 단계를 포함한다. 또한, 상기 제1 영상에서 인식되는 객체 중 미리 저장된 카테고리 리스트에 포함된 구성 요소와 미리 설정된 기 준값 이상 일치하는 제1 객체를 인식하는 단계 및 상기 제1 영상 및 제2 영상 중 적어도 하나에서 상기 제1 객 체가 인식되는 제1 프레임과, 제1 객체를 인식한 데이터를 인공 지능 모델에 제공하여 상기 제1 객체에 대응하 는 제1 모델링 정보를 생성하는 단계를 더 포함할 수 있다. 또한, 상기 피사체 분석 정보는, 상기 제1 영상과, 상기 제1 영상에서 추출한 제1 음성 데이터 및 제1 자막 데 이터 중 적어도 하나를 기초로 상기 제1 객체에 포함된 피사체 객체의 행동 제스처 및 음성에 대한 패턴 데이터 일 수 있다. 또한, 상기 제1 모델링 정보를 제공하는 단계는, 상기 모델링 정보에서, 상기 제1 프레임에 대응되어 순차적으 로 배치되는 제n 프레임 내지 제m 프레임에 대응되는 모델링 정보 리스트를 추출하는 단계 및 상기 모델링 정보 리스트 중 상기 제1 프레임과 시계열상 차이가 적은 프레임에 대응되는 상기 제1 모델링 정보를 추출하는 단계 를 더 포함할 수 있다. 또한, 상기 제1 컨텐츠를 생성하는 단계는, 상기 제1 영상 및 상기 제2 영상 중 하나에 포함되는 제2 프레임에 대한 피드백 정보를 수신하여 상기 제2 프레임에 대응되는 상기 모델링 정보의 제2 모델링 정보를 생성하는 단 계를 더 포함할 수 있다."}
{"patent_id": "10-2023-0093097", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 영상 컨텐츠 제공 시스템 및 방법은, 영상의 피사체 패턴 데이터를 기초로 영상 흐름에 적합한 모델 링 정보를 생성함으로써, 시청자에게 영상에 대한 이해도를 높이는 컨텐츠를 제공할 수 있다. 또한, 본 발명은, 영상과 동시에 모델링 정보를 제공하는 컨텐츠를 생성하여 시청자의 영상에 대한 이해도를 높 일 수 있다. 또한, 본 발명은, 영상 재생에 따라 외형 및 내형이 변형되는 객체가 제공되는 경우, 객체의 외형 및 내형의 변 형과 동시에 외형 및 내형이 변형되는 모델링 정보를 제공할 수 있어, 시청자의 영상에 대한 이해도를 높일 수 있다. 또한, 본 발명은, 시청자에게 영상에 대응된 모델링 정보를 핸들링할 수 있는 인터페이스를 제공하여, 영상에 대한 시청자의 정보 습득 및 이해도를 높일 수 있다. 또한, 본 발명은, 영상의 주제를 기초로 영상을 번역하여 언어 장벽에 따른 시청자의 어려움을 해소할 수 있으 며, 전문 분야에 따른 번역 오역률을 낮출 수 있다. 상술한 내용과 더불어 본 발명의 구체적인 효과는 이하"}
{"patent_id": "10-2023-0093097", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서 및 특허청구범위에서 사용된 용어나 단어는 일반적이거나 사전적인 의미로 한정하여 해석되어서는 아 니된다. 발명자가 그 자신의 발명을 최선의 방법으로 설명하기 위해 용어나 단어의 개념을 정의할 수 있다는 원 칙에 따라, 본 발명의 기술적 사상과 부합하는 의미와 개념으로 해석되어야 한다. 또한, 본 명세서에 기재된 실 시예와 도면에 도시된 구성은 본 발명이 실현되는 하나의 실시예에 불과하고, 본 발명의 기술적 사상을 전부 대 변하는 것이 아니므로, 본 출원시점에 있어서 이들을 대체할 수 있는 다양한 균등물과 변형 및 응용 가능한 예 들이 있을 수 있음을 이해하여야 한다. 본 명세서 및 특허청구범위에서 사용된 제1, 제2, A, B 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성 요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. '및/또는' 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함 한다. 본 명세서 및 특허청구범위에서 사용된 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서 \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해서 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다.또한, 본 발명의 각 실시예에 포함된 각 구성, 과정, 공정 또는 방법 등은 기술적으로 상호 간 모순되지 않는 범위 내에서 공유될 수 있다. 이하에서는, 도 1 내지 도 14를 참조하여, 본 발명의 몇몇 실시예들에 따른 영상 컨텐츠 제공 시스템 및 방법에 대해 자세히 설명하도록 한다. 먼저, 도 1 내지 도 8을 참조하여 영상 컨텐츠 제공 시스템에 대해 서술한다. 도 1은 본 발명의 몇몇 실시예에 따른 영상 컨텐츠 제공 시스템의 구성도이다. 도 2는 도 1의 컨텐츠 분석부의 구성도이다. 도 3은 도 1의 번역부의 구성도이다. 도 4는 도 1의 컨텐츠 생성부의 구성도이다. 도 5는 도 4의 모델링 생성 모듈의 동작을 설명하기 위한 도면이다. 도 6은 도 1의 제1 컨텐츠를 설명하기 위한 도면이다. 도 7은 도 1의 데이터베이스부를 설명하기 위한 도면이다. 도 8은 도 1의 컨텐츠 분석부, 번역부 및 컨텐츠 생성부 를 설명하기 위한 도면이다. 도 1을 참조하면, 영상 컨텐츠 제공 시스템은, 수신부, 컨텐츠 분석부, 번역부, 컨텐츠 생성부 , 학습부 및 데이터베이스부를 포함할 수 있다. 수신부는, 복수의 프레임을 포함하는 제1 영상을 제공받을 수 있다. 제1 영상은, 강의 영상 및 전문 분야 영상을 포함할 수 있다. 예를 들어, 제1 영상은, 치과 진료 영상, 안과 진료 영상, 성형 수술 영상, 정형외과 수술 영상, 흉부외과 수술 영상, 골프 교습 영상 및 조소 강의 영상 등을 포함할 수 있다. 치과 진료 영상은, 치과에서 진료하는 임플란트 수술 및 신경치료 각각에 대응되는 영상을 포함할 수 있다. 안과 진료 영상은, 안 과에서 진료하는 백내장 수술, 렌즈 삽입 수술 및 라식(LASIK)/라섹(LASEK) 수술 각각에 대응되는 영상을 포함 할 수 있다. 성형 수술 영상은, 성형외과에서 진료하는 안면 및 전신 성형에 대한 모든 수술 중 적어도 하나를 포함할 수 있다. 정형외과 수술 영상은, 정형외과에서 진료하는 인공관절 수술을 포함하는 모든 수술 중 적어도 하나를 포함할 수 있다. 흉부외과 수술 영상은, 흉부외과에서 진료하는 판막 성형술, 관상동맥 우회술 및 가슴 튜브 삽입 등을 포함하는 모든 수술 중 적어도 하나를 포함할 수 있다. 골프 교습 영상은, 프로골퍼의 대회 참 가 영상을 포함할 수 있다. 조소 강의 영상은, 조소, 목조, 석조 및 금속조에 대응되는 적어도 하나의 영상을 포함할 수 있다. 다만, 이러한 설명은 단순히 예시적인 것이며, 본 발명의 실시예가 이에 한정되는 것은 아니다. 제1 영상은, 제1 언어에 대응되는 프레임을 포함할 수 있다. 예를 들어, 제1 영상은, 제1 언어로 표시될 수 있 는 자막, 제1 언어에 대응되는 음성 및 제1 언어로 표시되는 문자를 포함한 이미지 중 적어도 하나를 포함할 수 있다. 제1 언어는, 제1 영상에 포함되는 적어도 하나의 언어일 수 있다. 또한, 수신부는, 제1 영상 및 영상 컨텐츠 제공 시스템에서 생성되는 데이터에 대한 피드백 정보를 수신 할 수 있다. 예를 들어, 피드백 정보는, 제1 영상에 대한 전문가 피드백 정보를 포함할 수 있다. 전문가 피드백 정보는, 제1 영상의 적어도 하나의 프레임에 각각 대응하는 모델링 정보를 포함할 수 있다. 또한, 전문가 피드 백 정보는, 영상 컨텐츠 제공 시스템에서 생성하는 제1 컨텐츠에 대한 전문가의 피드백을 포함할 수 있다. 피드백 정보는, 피드백 정보를 제공받아 동작하는 영상 컨텐츠 제공 시스템의 구성 요소를 설명하면서 같이 후술하도록 한다. 컨텐츠 분석부는, 제1 영상을 기초로 컨텐츠 정보 및 피사체 분석 정보를 생성할 수 있다. 컨텐츠 정보는, 제1 영상에 대응되는 제1 언어의 제1 언어 데이터와, 제1 영상의 주제를 분류하여 생성되는 영상 분야 데이터를 포함할 수 있다. 피사체 분석 정보는, 제1 영상에서 인식되는 제1 객체 중 피사체 객체의 행동 제스처 및 음성 을 기초로 생성되는 피사체 객체의 패턴 데이터일 수 있다. 도 2를 함께 참조하면, 컨텐츠 분석부는, 컨텐츠 정보 및 피사체 분석 정보를 생성하기 위해 피사체 특징 추출 모듈 및 컨텐츠 특징 추출 모듈을 포함할 수 있다. 피사체 특징 추출 모듈은, 제1 영상에서 인식되는 제1 객체 중 피사체 객체를 인식하고, 피사체 객체의 행 동 제스처 및 음성을 기초로 피사체 객체의 패턴 데이터인 피사체 분석 정보를 생성할 수 있다. 예를 들어, 피 사체 특징 추출 모듈은, 제1 영상에서 인식되는 객체 중, 미리 저장된 카테고리 리스트에 포함된 구성 요소 와, 미리 저장된 기준값 이상이 일치하는 제1 객체를 추출할 수 있다. 또한, 피사체 특징 추출 모듈은, 제1 객체에 포함되는 피사체 객체를 카테고리 리스트를 기초로 추출할 수 있다. 피사체 특징 추출 모듈은, 피사체 객체가 인식되는 프레임과, 피사체 객체가 인식되는 프레임과 인접한 프 레임을 기초로 피사체 객체의 제스처 및 음성을 인식할 수 있다. 피사체 특징 추출 모듈은, 피사체 객체의 제스처 및 음성을 인식하는데 이용된 프레임과, 인식된 피사체 객체의 제스처 및 음성을 인공 지능 모델에 제공 하여 피사체 객체의 패턴 데이터인 피사체 분석 정보를 생성할 수 있다. 도 8을 함께 참조하면, 피사체 분석 정 보를 생성하는 인공 지능 모델은 피사체 특징 추출 모듈이 포함할 수 있다. 피사체 특징 추출 모듈은, 데이터베이스부에 저장된 학습 데이터의 부가 정보와, 카테고리 리스트를 기초로 미리 지도 학습될 수 있다. 피사체 분석 정보는, 피사체의 제스처 및 음성의 패턴 데이터로서 제1 객체가 인식된 서로 다른 제1 영상마다 다를 수 있다. 예를 들어, 피사체 분석 정보는, 제1 영상에서 피사체인 강사의 말투 패턴, 영상과 내용 설명 순 서 패턴, 강사 제스처에 따른 강의 패턴 및 시범 여부를 포함할 수 있다. 다만, 이러한 설명은 단순히 예시적인 것이며, 본 발명의 실시예가 이에 한정되는 것은 아니다. 피사체는 강사 외 다른 객체일 수 있다. 컨텐츠 특징 추출 모듈은, 제1 영상을 기초로 컨텐츠 정보를 생성할 수 있다. 컨텐츠 정보는, 영상 분야 데 이터 및 제1 언어 데이터를 포함할 수 있다. 예를 들어, 컨텐츠 특징 추출 모듈은, 제1 영상에서 인식되는 객체 중 미리 저장된 카테고리 리스트에 포함된 구성 요소와 미리 설정된 기준값 이상 일치하는 제1 객체를 인 식할 수 있다. 컨텐츠 특징 추출 모듈은, 제1 객체를 기초로 제1 영상의 주제를 분류하여 영상 분야 데이터 를 생성할 수 있다. 예를 들어, 도 8을 함께 참조하면, 컨텐츠 특징 추출 모듈은, 인식되는 적어도 하나의 제1 객체를 인공 지능 모델에 제공하여 제1 영상의 주제를 분류한 영상 분야 데이터를 생성할 수 있다. 영상 분 야 데이터는, 치과 임플란트 수술 강의, 골프 교습 및 미술 조소를 포함할 수 있다. 다만, 이러한 설명은 단순 히 예시적인 것이며, 본 발명의 실시예가 이에 한정되는 것은 아니다. 또한, 컨텐츠 특징 추출 모듈은, 제1 영상에서 제1 음성 데이터 및 제1 자막 데이터 중 적어도 하나를 추출 하고, 추출한 제1 음성 데이터 및 제1 자막 데이터 중 적어도 하나를 기초로 제1 영상에 대응되는 제1 언어를 식별하여 제1 언어 데이터를 생성할 수 있다. 예를 들어, 컨텐츠 특징 추출 모듈은, 제1 영상에서 제1 음성 데이터를 추출하고, 제1 음성 데이터에 대응되는 제1 언어의 제1 언어 데이터를 생성할 수 있다. 제1 언어 데이터는, 제1 영상의 각 프레임마다 대응되는 적어도 하나의 언어 종류를 포함할 수 있다. 또한, 제1 언어 데이터는, 컨텐츠 특징 추출 모듈이 제1 영상에서 적어도 한번 인식한 언어 종류를 포함할 수 있다. 다만, 이러한 설명은 단순히 예시적인 것이며, 본 발명의 실시예가 이에 한정되는 것은 아니다. 다시 도 1을 참조하면, 번역부는, 제1 영상 및 컨텐츠 정보를 제공받아 제2 영상을 생성할 수 있다. 제2 영 상은, 제1 영상의 제1 언어 데이터를 제1 언어와 다른 제2 언어에 대응된 제2 언어 데이터로 번역하여 생성될 수 있다. 도 3을 함께 참조하면, 번역부는, 번역 제어 모듈, 음성 번역 모듈 및 영상 번역 모듈을 포함 할 수 있다. 번역 제어 모듈은, 제1 영상 및 컨텐츠 정보를 제공받아 번역 설정 정보를 생성할 수 있다. 예를 들어, 번 역 제어 모듈은, 제1 영상의 제1 음성 데이터를 번역할지 여부와, 제1 영상의 제1 자막 데이터를 번역할지 여부를 포함하는 번역 설정 정보를 생성할 수 있다. 번역 제어 모듈은, 번역 설정 정보를 기초로 음성 번역 모듈 및 영상 번역 모듈 중 적어도 하나를 통해 제1 영상을 번역한 제2 영상을 생성할 수 있다. 음성 번역 모듈은, 제1 영상에서 추출한 제1 음성 데이터를 번역하여 제1 언어와 다른 제2 언어에 대응된 제2 음성 데이터를 생성할 수 있다. 영상 번역 모듈은, 제1 영상에서 추출한 제1 자막 데이터를 제2 언어에 대응되도록 번역하여 제2 자막 데이 터를 생성할 수 있다. 제2 언어는, 제1 언어와 다른 적어도 하나의 언어일 수 있다. 번역 제어 모듈은, 음성 번역 모듈 및 영상 번역 모듈을 이용하여 생성한 제2 음성 데이터 및 제2 자막 데이터 중 적어도 하나와, 제1 영상을 기초로 제2 영상을 생성할 수 있다. 예를 들어, 번역 제어 모듈(3 1)은, 제1 영상의 제1 음성 데이터를 제2 음성 데이터로 변환하여 제2 영상을 생성할 수 있다. 제2 영상은 제1 음성 데이터가 제거된 제1 영상과 제2 음성 데이터의 결합으로 생성될 수 있다. 또한, 번역 제어 모듈은, 제1 영상의 제1 자막 데이터를 제2 자막 데이터로 변환하여 제2 영상을 생성할 수 있다. 예를 들어, 번역 제어 모듈은, 제1 자막 데이터가 제거된 제1 영상과, 제2 자막 데이터를 결합하여 제2 영상을 생성할 수 있다. 번역 제어 모듈은, 제1 언어에 대응되는 데이터를 제2 언어에 대응되는 데이터로 번역하는 경우, 제1 언어 의 음소 길이 및 제2 언어의 음소 길이를 기초로 제1 영상에 포함되는 프레임의 수를 증감하여 제2 영상을 생성 할 수 있다. 또한, 번역 제어 모듈은, 제1 언어의 음소 길이 및 제2 언어의 음소 길이를 기초로 제2 음성 데이터의 길이를 줄이거나 늘린 제2 영상을 생성할 수 있다. 설명의 편의를 위해, 제1 음성 데이터의 제1 음소 는, 번역되는 제2 음성 데이터의 제2 음소에 대응될 수 있다. 제1 음소의 길이가 제2 음소의 길이보다 긴 경우, 번역 제어 모듈은, 제2 음소의 길이를 제1 음소의 길이에 근접하도록 늘릴 수 있다. 또한, 제1 음소의 길이 가 제2 음소의 길이보다 짧은 경우, 번역 제어 모듈은, 제1 음소에 대응되는 프레임의 수를 제2 음소의 길 이에 대응되도록 늘릴 수 있다. 다만, 이러한 설명은 단순히 예시적인 것이며, 본 발명의 실시예가 이에 한정되 는 것은 아니다. 도 1 및 도 4를 참조하면, 컨텐츠 생성부는, 모델링 생성 모듈 및 컨텐츠 생성 모듈을 포함할 수 있다. 모델링 생성 모듈은, 피사체 분석 정보 및 컨텐츠 정보를 제공받아 모델링 정보를 생성할 수 있다. 상기 피 사체 분석 정보는, 컨텐츠 분석부에서 인식한 제1 객체에 포함되는 피사체 객체의 행동 제스처 및 음성을 기초로 생성되는 피사체 객체의 패턴 데이터일 수 있다. 컨텐츠 정보는, 영상 분야 데이터 및 제1 언어 데이터 를 포함할 수 있다. 예를 들어, 모델링 생성 모듈은, 제1 객체 중 피사체 객체가 아닌 제2 객체가 인식되는 제1 영상 및 제2 영 상 중 적어도 하나에 포함된 프레임을 인공 지능 모델에 제공하여 모델링 정보를 생성할 수 있다. 도 5 및 도 8을 함께 참조하면, 모델링 생성 모듈은, 모델링 정보를 생성하는 인공 지능 모델을 포함할 수 있다. 모델링 생성 모듈은, 제2 객체가 인식되는 적어도 하나의 프레임을 기초로 제2 객체의 변화량을 산출 하여 제2 객체에 대응되는 3차원 모델링 정보를 생성할 수 있다. 예를 들어, 모델링 생성 모듈은, 복수의 제1 프레임 셋(fs1)을 인공 지능 모델에 제공하여 제1 프레임 셋(fs1)에서 인식되는 제2-1 객체의 3차원 모델링 정보인 제1 모델링 정보(m1)를 생성할 수 있다. 제1 모델링 정보(m1)는, 제1 프레임 셋(fs1)에서 외형 및 내형 이 유지되는 제2-1 객체의 경우에 적합한 모델링 정보일 수 있다. 제1 모델링 정보(m1)는 제1 프레임 셋(fs1)에 대응되는 모델링 정보이거나, 제1 프레임 셋(fs1)의 각 프레임에 대응되는 모델링 정보를 그룹핑한 정보일 수 있다. 즉, 모델링 생성 모듈은, 제1 프레임 셋(fs1)에 포함되는 제2-1 객체의 복수의 2차원 이미지를 기초 로 제2-1 객체의 3차원 이미지를 생성할 수 있다. 또한, 모델링 생성 모듈은, 복수의 제2 프레임 셋(fs2)을 인공 지능 모델에 제공하여 제2 프레임 셋(fs2)에 서 인식되는 제2-2 객체의 3차원 모델링 정보인 제2 모델링 정보(m2)를 생성할 수 있다. 제2 모델링 정보(m2)는, 제2 프레임 셋(fs2)에서 인식되는 제2-2 객체가 제2 프레임 셋(fs2) 상에서 외형 및 내형 중 적어 도 하나의 변화가 있는 제2-2 객체의 경우에 적합한 모델링 정보일 수 있다. 제2 모델링 정보(m2)는, 제2 프레 임 셋(fs2)에 포함된 각 프레임에 대응되는 모델링 정보를 그룹핑한 정보일 수 있다. 복수의 제1 프레임 셋(fs1) 및 제2 프레임 셋(fs2)은, 제1 영상에 포함되는 복수의 프레임을 각각 포함할 수 있 다. 예를 들어, 복수의 제1 프레임 셋(fs1)은, 제1 영상에서 제2-1 객체가 인식되는 복수의 프레임을 포함할 수 있다. 복수의 제2 프레임 셋(fs2)은, 제1 영상에서 제2-2 객체가 인식되는 복수의 프레임을 포함할 수 있다. 또한, 모델링 생성 모듈은, 제2 객체가 인식되는 복수의 프레임 내 제2 객체의 인식되는 동일한 일부를 각 각 연결하고, 제2 객체에 대응되는 복수의 시점을 산출함으로써 제2 객체에 대응되는 3차원 모델링 정보를 생성 할 수 있다. 모델링 생성 모듈은, 제2 객체가 인식되는 각 프레임에 대응되는 3차원 모델링 정보를 각각 생성할 수 있다. 이를 통해, 본 발명은, 제1 영상에서 제2 객체의 외형 및 내형 중 적어도 하나가 변형되는 경우, 제1 영 상의 재생과 동시에 외형 및 내형 중 적어도 하나가 변형되도록 재생되는 제2 객체의 모델링 정보를 제공할 수 있다. 또한, 모델링 생성 모듈은, 수신부가 제공받은 피드백 정보를 기초로 제1 영상에 포함된 프레임에 대응 되는 모델링 정보를 생성할 수 있다. 예를 들어, 모델링 생성 모듈은, 제1 영상 및 제2 영상 중 하나에 포 함되는 프레임에 대한 전문가 피드백 정보를 제공받을 수 있다. 이어서, 모델링 생성 모듈은, 전문가 피드 백 정보와 제1 영상 및 제2 영상 중 하나에 포함되는 프레임을 맵핑할 수 있다. 또한, 모델링 생성 모듈은, 각 프레임마다 맵핑되는 3차원 모델링 정보를 생성할 수 있다. 예를 들어, 모델 링 생성 모듈은, 생성되는 모델링 정보에서, 제1 프레임에 대응되는 제1 모델링 정보를 생성할 수 있다. 모 델링 생성 모듈은, 제1 프레임에 대응되는 모델링 정보가 없는 경우, 제1 프레임에 대응되는 제1 모델링 정보를 다른 프레임을 이용하여 생성할 수 있다. 제1 프레임에서 객체가 인식되기 어려운 경우, 모델링 생성 모듈 은, 생성되는 모델링 정보에서, 제1 프레임에 대응되고 순차적으로 배치되는 제n 프레임 내지 제m 프레임에 대응되는 모델링 정보 리스트를 추출할 수 있다. 모델링 생성 모듈은, 모델링 정보 리스트 중 제1 프레임과 시계열상 차이가 적은 프레임에 대응되는 모델링 정보를 제1 프레임에 대응된 제1 모델링 정보로 추출할 수 있 다. 다만, 이러한 설명은 단순히 예시적인 것이며, 본 발명의 실시예가 이에 한정되는 것은 아니다. 도 6을 함께 참조하면, 컨텐츠 생성 모듈은, 제2 영상 및 모델링 정보를 기초로 제1 영상에 대응되는 제1 컨텐츠(C)를 생성할 수 있다. 예를 들어, 컨텐츠 생성 모듈은 제2 영상과, 제2 영상에 대응되는 모델링 정 보를 포함하는 제1 컨텐츠(C)를 생성할 수 있다. 제1 컨텐츠(C)는, 제2 언어로 번역된 제2 영상을 제공하는 제1 인터페이스를 포함할 수 있다. 제1 인터페이스 (v)는, 입력되는 데이터에 대응되는 제2 영상의 프레임을 제공할 수 있다. 또한, 제1 인터페이스(v)는, 제공되 는 언어 데이터에 따라 제1 언어에 대응되는 제1 영상을 제공할 수 있다. 다만, 이러한 설명은 단순히 예시적인 것이며, 본 발명의 실시예가 이에 한정되는 것은 아니다. 또한, 제1 컨텐츠(C)는, 제1 인터페이스(v)에서 재생되는 영상에 대응하여 모델링 정보를 제공하는 제2 인터페 이스(m)를 포함할 수 있다. 제2 인터페이스(m)는, 제1 인터페이스(v)에서 재생되는 영상의 각 프레임에 대응되 는 모델링 정보를 제공할 수 있다. 제2 인터페이스(m)는, 제공되는 모델링 제어 데이터를 기초로 모델링 정보가 회전되도록 업데이트할 수 있다. 예를 들어, 모델링 제어 데이터는, 모델링 정보 내 입력되는 회전 중심 좌표값 을 포함할 수 있다. 모델링 제어 데이터는, 외부 장치로부터 수신되는 데이터일 수 있다. 또한, 제1 컨텐츠(C)는, 제1 인터페이스(v) 및 제2 인터페이스(m)를 기초로 제공되는 데이터에 대한 부가 설명 정보를 표시하는 제3 인터페이스(e)를 더 포함할 수 있다. 제3 인터페이스(e)를 이용하여 제공되는 부가 설명 정보는, 제1 영상 및 제2 영상 중 적어도 하나를 기초로 생성된 데이터일 수 있다. 예를 들어, 부가 설명 정보 는, 제1 영상에서 추출된 제1 자막 데이터를 기초로 생성될 수 있다. 다만, 이러한 설명은 단순히 예시적인 것 이며, 본 발명의 실시예가 이에 한정되는 것은 아니다. 도 7을 참조하면, 데이터베이스부는, 영상 컨텐츠 제공 시스템의 각 구성 요소가 제공받거나 생성하는 데이터를 저장할 수 있다. 예를 들어, 데이터베이스부는, 카테고리 리스트, 학습 데이터 및 설정 정보를 포 함할 수 있다. 카테고리 리스트는, 제1 컨텐츠 대상이 되는 적어도 하나의 객체 및 제1 컨텐츠 대상이 되는 주 제를 포함할 수 있다. 학습 데이터는, 용어 사전, 3차원 모델링 정보 및 부가 정보를 포함할 수 있다. 예를 들어, 용어 사전은, 카테 고리 리스트의 각 구성 요소에 대응되어 정의되는 용어 사전을 포함할 수 있다. 또한, 또한, 용어 사전은, 사전 에 포함되는 어휘를 카테고리 리스트의 각 구성 요소와 각각 맵핑하여 구별한 데이터일 수 있다. 3차원 모델링 정보는, 컨텐츠 생성부의 인공 지능 모델을 학습을 위해 저장되는 학습 데이터일 수 있다. 또 한, 제1 컨텐츠, 제1 영상 및 제2 영상 중 적어도 하나에 대응되어 수신되는 피드백 정보의 3차원 모델링 정보 일 수 있다. 부가 정보는, 영상 내 인식되는 객체 중 피사체를 인식하기 위해 사용되는 학습 데이터일 수 있다. 예를 들어, 부가 정보는, 인공 지능 모델이 영상 내 강사를 인식하기 위해 학습에 사용되는 데이터일 수 있다. 설정 정보는, 컨텐츠 분석부, 번역부 및 컨텐츠 생성부에 각각 포함되는 각 인공 지능 모델의 매개 변수 값, 영상에서 인식되는 객체 중 미리 저장된 카테고리 리스트에 포함된 구성 요소와 일치하는 확률인 미리 설정된 기준값을 포함할 수 있다. 다시 도 1을 참조하면, 학습부는, 영상 컨텐츠 제공 시스템의 구성 요소에 포함되는 각 인공 지능 모델 을 학습시킬 수 있다. 예를 들어, 학습부는, 수신부로부터 피드백 정보를 제공받을 수 있다. 피드백 정 보는, 각 인공 지능 모델의 매개변수를 제어하는 데이터를 포함할 수 있다. 또한, 학습부는, 피드백 정보를 기초로 영상 컨텐츠 제공 시스템에서 생성되는 데이터의 정확도를 높이도록 영상 컨텐츠 제공 시스템의 각 구성 요소를 학습시킬 수 있다. 학습부는, 영상 컨텐츠 제공 시스템이 생성한 제1 컨텐츠 및 피드백 정보를 기초로 영상 컨텐츠 제공 시스템에 포함된 컨텐츠 분석부, 번역부 및 컨텐츠 생성부를 학습시킬 수 있다. 다만, 이러한 설명은 단순히 예시적인 것이며, 본 발명의 실시예가 이에 한정되는 것은 아니 다. 이하에서는, 도 9 내지 도 14를 참조하여, 본 발명의 몇몇 실시예들에 따른 영상 컨텐츠 제공 방법에 대해 자세 히 설명하도록 한다. 영상 컨텐츠 제공 방법은, 도 1 내지 도 8을 참조하여 서술한 영상 컨텐츠 제공 시스템의 구성 요소를 기초로 동작될 수 있다. 도 9는 본 발명의 몇몇 실시예에 따른 영상 컨텐츠 제공 방법의 순서도이다. 도 1 및 도 9를 참조하면, 영상 컨텐츠 제공 시스템은, 제1 영상을 기초로 컨텐츠 정보 및 피사체 분석 정보 를 생성할 수 있다(S100). 예를 들어, 영상 컨텐츠 제공 시스템의 컨텐츠 분석부는, 제1 언어 데이터와 영상 분야 데이터를 포함하는 컨텐츠 정보를 생성할 수 있다. 제1 언어 데이터는, 제1 영상에 대응되는 제1 언 어의 언어 종류일 수 있다. 영상 분야 데이터는, 제1 영상의 주제를 분류한 데이터일 수 있다. 또한, 컨텐츠 분 석부는, 제1 영상에서 인식되는 제1 객체 중 피사체 객체의 행동 제스처 및 음성을 기초로 생성되는 피사체 객체의 패턴 데이터인 피사체 분석 정보를 생성할 수 있다. 단계 S100은, 도 10 및 도 11을 참조하여 구체적으 로 후술하도록 한다. 이어서, 영상 컨텐츠 제공 시스템은, 제1 영상 및 컨텐츠 정보를 기초로 번역하여 제2 영상을 생성할 수 있 다(S200). 제2 영상은, 제1 영상의 제1 언어 데이터를 제1 언어와 다른 제2 언어에 대응된 제2 언어 데이터로 번역하여 생성될 수 있다. 예를 들어, 영상 컨텐츠 제공 시스템의 번역부는, 제1 영상에서 추출한 제1 음성 데이터를 번역하여 제1 언어와 다른 제2 언어에 대응된 제2 음성 데이터를 생성할 수 있다. 또한, 번역부 는, 제1 영상에서 추출한 제1 자막 데이터를 제2 언어에 대응되도록 번역하여 제2 자막 데이터를 생성할 수 있다. 이어서, 번역부는, 제2 음성 데이터 및 제2 자막 데이터 중 적어도 하나와, 제1 영상을 기초로 제2 영상을 생성할 수 있다. 예를 들어, 번역부는, 제1 영상의 제1 음성 데이터를 제2 음성 데이터로 변환하여 제2 영 상을 생성할 수 있다. 제2 영상은 제1 음성 데이터가 제거된 제1 영상과 제2 음성 데이터의 결합으로 생성될 수 있다. 번역부는, 제1 영상의 제1 자막 데이터를 제2 자막 데이터로 변환하여 제2 영상을 생성할 수 있다. 예를 들어, 번역부는, 제1 자막 데이터가 제거된 제1 영상과, 제2 자막 데이터를 결합하여 제2 영상을 생성 할 수 있다. 또한, 제2 영상의 프레임 수와 제1 영상의 프레임 수는 다를 수 있다. 설명의 편의를 위해, 제1 음성 데이터의 제1 음소는, 번역되는 제2 음성 데이터의 제2 음소에 대응될 수 있다. 제1 음소의 길이가 제2 음소의 길이보다 긴 경우, 번역부는, 제2 음소의 길이를 제1 음소의 길이에 근접하도록 늘릴 수 있다. 또한, 제1 음소의 길 이가 제2 음소의 길이보다 짧은 경우, 번역부는, 제1 음소에 대응되는 프레임의 수를 제2 음소의 길이에 대 응되도록 늘릴 수 있다. 이어서, 영상 컨텐츠 제공 시스템은, 제2 영상 및 피사체 분석 정보를 기초로 제2 영상 및 제2 영상에 대응 되는 3차원 모델링 정보를 포함하는 제1 컨텐츠를 생성할 수 있다(S300). 예를 들어, 영상 컨텐츠 제공 시스템 의 컨텐츠 생성부는, 피사체 분석 정보 및 컨텐츠 정보를 기초로 모델링 정보를 생성할 수 있다. 컨텐츠 생성부는, 제1 객체 중 피사체 객체가 아닌 제2 객체가 인식되는 적어도 제1 영상 및 제2 영상 중 적어도 하나에 포함되는 프레임을 기초로 제2 객체의 변화량을 산출하여 3차원 모델링 정보를 생성할 수 있다. 또한, 컨텐츠 생성부는, 각 프레임마다 맵핑되는 3차원 모델링 정보를 생성할 수 있다. 예를 들어, 컨텐츠 생성부는, 제1 프레임에 대응되는 모델링 정보가 없는 경우, 제1 프레임에 대응되는 제1 모델링 정보를 다 른 프레임을 이용하여 생성할 수 있다. 다른 프레임을 이용하여 모델링 정보가 생성되는 방법은, 도 12를 참조 하여 후술하도록 한다. 이어서, 영상 컨텐츠 제공 시스템은, 제1 컨텐츠 중 제2 영상에 포함된 제1 프레임이 선택되는 경우, 모델링 정보 중 제1 프레임에 대응되는 제1 모델링 정보를 제공할 수 있다(S400). 예를 들어, 제1 컨텐츠의 제2 영상이 재생되는 경우, 영상 컨텐츠 제공 시스템은, 재생되는 제2 영상의 각 프레임에 대응한 제1 모델링 정보를 제 공할 수 있다. 이를 통해, 제2 영상이 재생됨에 따라, 제2 영상에 대응되는 모델링 정보도 재생될 수 있다. 도 10은 도 9의 컨텐츠 정보 및 피사체 분석 정보를 생성하는 단계 S100을 설명하기 위한 순서도이다. 도 10을 참조하면, 영상 컨텐츠 제공 시스템은, 제1 영상에서 인식되는 객체 중 미리 저장된 카테고리 리스 트에 포함된 구성 요소와 미리 설정된 기준값 이상 일치하는 제1 객체를 인식할 수 있다(S110). 카테고리 리스 트는, 제1 컨텐츠 대상이 되는 적어도 하나의 객체 및 제1 컨텐츠 대상이 되는 주제를 포함할 수 있다. 제1 객체는, 제1 영상에서 인식되는 객체 중 제1 영상을 통해 시청자에게 제공하는 내용에 대응되는 객체일 수 있다. 또한, 제1 객체는, 적어도 하나의 객체를 포함할 수 있다. 다만, 이러한 설명은 단순히 예시적인 것이며, 본 발 명의 실시예가 이에 한정되는 것은 아니다. 이어서, 영상 컨텐츠 제공 시스템은, 영상 분야 데이터 및 제1 언어 데이터를 포함하는 컨텐츠 정보를 생성 할 수 있다. 영상 컨텐츠 제공 시스템은, 제1 객체를 기초로 제1 영상의 주제를 분류하여 영상 분야 데이터를 생성할 수 있다(S111). 예를 들어, 컨텐츠 특징 추출 모듈은, 제1 객체를 인공 지능 모델에 제공하여 제1 객체에 대응 되는 주제인 영상 분야 데이터를 생성할 수 있다. 영상 분야 데이터는, 치과 임플란트 수술 강의, 골프 교습 및 미술 조소를 포함할 수 있다. 다만, 이러한 설명은 단순히 예시적인 것이며, 본 발명의 실시예가 이에 한정되는 것은 아니다. 이어서, 영상 컨텐츠 제공 시스템은, 제1 영상에서 제1 음성 데이터 및 제1 자막 데이터 중 적어도 하나를 추출할 수 있다(S112). 또한, 영상 컨텐츠 제공 시스템은, 추출되는 제1 음성 데이터 및 제1 자막 데이터의 각 요소와, 각 요소와 대응되는 제1 영상의 프레임을 맵핑할 수 있다. 이어서, 영상 컨텐츠 제공 시스템은, 제1 음성 데이터 및 제1 자막 데이터 중 적어도 하나를 기초로 제1 영 상에 대응되는 제1 언어를 식별하여 제1 언어 데이터를 생성할 수 있다(S113). 예를 들어, 영상 컨텐츠 제공 시 스템의 컨텐츠 분석부는, 제1 영상에서 제1 음성 데이터를 추출하고, 제1 음성 데이터에 대응되는 제1 언어의 제1-1 언어 데이터를 생성할 수 있다. 또한, 컨텐츠 분석부는, 제1 영상에서 제1 자막 데이터를 추 출하고, 제1 자막 데이터가 표시되는 언어 종류인 제1-2 언어 데이터를 생성할 수 있다. 제1-1 언어 데이터 및 제1-2 언어 데이터가 다를 경우, 컨텐츠 분석부는, 제1-1 언어 데이터에 대응되는 제1 음성 데이터와, 제1- 2 언어 데이터에 대응되는 제1 자막 데이터의 제1 영상 내 비중을 기초로 제1 언어 데이터를 생성할 수 있다. 예를 들어, 제1 음성 데이터가 제1 자막 데이터에 비해 제1 영상 내 비중이 작은 경우, 제1 언어 데이터는 제1 자막 데이터를 기초로 생성되는 제1-2 언어 데이터일 수 있다. 또한, 영상 컨텐츠 제공 시스템은, 인식한 제1 객체에 포함되는 피사체 객체를 추출할 수 있다(S121). 예를 들어, 피사체 특징 추출 모듈은, 제1 객체에 포함되는 피사체 객체를 카테고리 리스트를 기초로 추출할 수 있다. 카테고리 리스트는, 피사체 객체에 대응되는 강사를 식별하는 강사 특징 데이터를 포함할 수 있다. 또한, 피사체 객체의 인식률이 낮아 제1 객체에 피사체 객체가 포함되지 않은 경우, 피사체 특징 추출 모듈(2 1)은, 제1 영상의 음성 데이터에 따라 변화량이 생성되는 피사체 객체를 추출할 수도 있다. 다만, 이러한 설명 은 단순히 예시적인 것이며, 본 발명의 실시예가 이에 한정되는 것은 아니다. 이어서, 영상 컨텐츠 제공 시스템은, 피사체 객체의 행동 제스처 및 음성을 기초로 피사체 객체의 패턴 데이 터인 피사체 분석 정보를 생성할 수 있다(S122). 예를 들어, 피사체 분석 정보는, 제1 영상에서 피사체인 강사 의 말투 패턴, 영상과 내용 설명 순서 패턴, 강사 제스처에 따른 강의 패턴 및 시범 여부를 포함할 수 있다. 또 한, 피사체 분석 정보는, 피사체의 제스처 및 음성의 패턴 데이터로서 제1 객체가 인식된 서로 다른 제1 영상마 다 다를 수 있다. 도 11은 도 10의 피사체 분석 정보를 생성하는 단계 S122를 설명하기 위한 순서도이다. 도 11을 참조하면, 영상 컨텐츠 제공 시스템은, 제1 영상에서 제1 음성 데이터 및 제1 자막 데이터 중 적어 도 하나를 추출할 수 있다(S122a). 이어서, 영상 컨텐츠 제공 시스템은, 추출한 제1 음성 데이터 및 제1 자막 데이터 중 적어도 하나와, 제1 영 상을 인공 지능 모델에 제공하여 제1 객체에 포함되는 피사체 객체의 패턴 데이터인 피사체 분석 정보를 생성할 수 있다(S122b). 예를 들어, 피사체 특징 추출 모듈은, 피사체 객체를 인식하는데 이용되는 적어도 하나의 프레임과, 각 프레임에서 피사체 객체의 변화량에 따라 변동되는 제1 음성 데이터의 일부를 인공 지능 모델에 제공하여 피사체 객체의 패턴 데이터인 피사체 분석 정보를 생성할 수 있다. 또한, 피사체 분석 정보는, 제1 영 상에서 피사체인 강사의 말투 패턴, 영상과 내용 설명 순서 패턴, 강사 제스처에 따른 강의 패턴 및 시범 여부 를 포함할 수 있다. 다만, 이러한 설명은 단순히 예시적인 것이며, 본 발명의 실시예가 이에 한정되는 것은 아 니다.도 12는 도 9의 모델링 정보를 생성하는 단계 S300을 설명하기 위한 순서도이다. 도 1 및 도 12를 참조하면, 영상 컨텐츠 제공 시스템은, 제1 영상에서 인식되는 객체 중 미리 저장된 카테고 리 리스트에 포함된 구성 요소와 미리 설정된 기준값 이상 일치하는 제1 객체를 인식할 수 있다(S311). 이어서, 영상 컨텐츠 제공 시스템은, 제1 객체 중 피사체 객체가 아닌 제2 객체를 추출하고, 제1 영상 및 제 2 영상 중 적어도 하나에서 제2 객체가 인식되는 프레임을 인공 지능 모델에 제공하여 제2 객체에 대응하는 3차 원 제1 모델링 정보를 생성할 수 있다(S312). 예를 들어, 도 5를 함께 참조하면, 모델링 생성 모듈은, 복수의 제1 프레임 셋(fs1)을 인공 지능 모델에 제 공하여 제1 프레임 셋(fs1)에서 인식되는 제2-1 객체의 3차원 모델링 정보인 제1 모델링 정보(m1)를 생성할 수 있다. 제1 모델링 정보(m1)는, 제1 프레임 셋(fs1)에서 외형 및 내형이 유지되는 제2-1 객체의 경우에 적합한 모델링 정보일 수 있다. 제1 모델링 정보(m1)는 제1 프레임 셋(fs1)에 대응되는 모델링 정보이거나, 제1 프레임 셋(fs1)의 각 프레임에 대응되는 모델링 정보를 그룹핑한 정보일 수 있다. 즉, 모델링 생성 모듈은, 제1 프 레임 셋(fs1)에 포함되는 제2-1 객체의 복수의 2차원 이미지를 기초로 제2-1 객체의 3차원 이미지를 생성할 수 있다. 또한, 모델링 생성 모듈은, 복수의 제2 프레임 셋(fs2)을 인공 지능 모델에 제공하여 제2 프레임 셋(fs2)에 서 인식되는 제2-2 객체의 3차원 모델링 정보인 제2 모델링 정보(m2)를 생성할 수 있다. 제2 모델링 정보(m2)는, 제2 프레임 셋(fs2)에서 인식되는 제2-2 객체가 제2 프레임 셋(fs2) 상에서 외형 및 내형 중 적어 도 하나의 변화가 있는 제2-2 객체의 경우에 적합한 모델링 정보일 수 있다. 제2 모델링 정보(m2)는, 제2 프레 임 셋(fs2)에 포함된 각 프레임에 대응되는 모델링 정보를 그룹핑한 정보일 수 있다. 도 13은 도 9의 제1 모델링 정보를 제공하는 단계 S400을 설명하기 위한 순서도이다. 영상 컨텐츠 제공 시스템은, 제1 컨텐츠 중 제2 영상에 포함되는 제1 프레임을 선택한 데이터를 제공받을 수 있다. 이에 따라, 영상 컨텐츠 제공 시스템은, 제1 프레임에 대응되는 제1 모델링 정보를 제1 컨텐츠를 이용 하여 제공할 수 있다. 이때, 제1 컨텐츠에 제1 프레임에 대응되는 제1 모델링 정보가 미포함되는 경우, 컨텐츠 생성부는, 생성되 는 모델링 정보에서, 제1 프레임에 대응되고 순차적으로 배치되는 제n 프레임 내지 제m 프레임에 대응되는 모델 링 정보 리스트를 추출할 수 있다(S411). 상기 모델링 정보 리스트는, 제n 프레임 내지 제m 프레임의 각 프레임 에 대응되어 생성된 모델링 정보를 포함할 수 있다. 이어서, 컨텐츠 생성부는, 모델링 정보 리스트 중 제1 프레임과 시계열상 차이가 적은 프레임에 대응되는 모델링 정보를 제1 프레임에 대응된 제1 모델링 정보로 추출할 수 있다(S412). 이어서, 영상 컨텐츠 제공 시스 템은, 제1 모델링 정보를 제1 컨텐츠의 제2 인터페이스를 통해 제공할 수 있다. 도 14는 도 9의 제1 영상 및 제2 영상에 대한 피드백 정보를 수신하여 모델링 정보를 업데이트하는 방법을 설명 하기 위한 순서도이다. 도 14를 참조하면, 영상 컨텐츠 제공 시스템은, 제1 영상 및 제2 영상 중 적어도 하나에 포함되는 제2 프레 임에 대한 피드백 정보를 수신할 수 있다(S500). 피드백 정보는, 제2 프레임에 대한 모델링 정보와, 제2 프레임 에 대한 모델링 정보가 제1 컨텐츠를 통해 제공될 때 적용되는 뷰 초점 정보를 포함할 수 있다. 이어서, 영상 컨텐츠 제공 시스템은, 제2 프레임에 대응되는 모델링 정보 저장 여부를 확인할 수 있다 (S510). 제2 프레임에 대응되는 모델링 정보가 저장되어 있는 경우, 영상 컨텐츠 제공 시스템은, 피드백 정보를 기초 로 제2 프레임에 대응되는 제2 모델링 정보를 업데이트할 수 있다. 예를 들어, 영상 컨텐츠 제공 시스템은, 수신한 피드백 정보의 뷰 초점 정보를 기초로 저장되어 있는 제2 모델링 정보를 업데이트할 수 있다. 또한, 영 상 컨텐츠 제공 시스템은, 제2 프레임에 대응되는 모델링 정보를 피드백 정보에 포함된 모델링 정보로 변경 할 수 있다. 영상 컨텐츠 제공 시스템은, 제2 프레임에 대응되는 모델링 정보와, 피드백 정보에 포함된 모델링 정보를 병합하여 제2 프레임에 대응되는 제2 모델링 정보를 생성할 수도 있다. 제2 프레임에 대응되는 모델링 정보가 없는 경우, 영상 컨텐츠 제공 시스템은, 제2 프레임에 대응되는 모델 링 정보가 미확인 되는 경우, 영상 컨텐츠 제공 시스템은, 피드백 정보를 기초로 제2 프레임에 대응되는 제2 모델링 정보를 생성할 수 있다(S530). 예를 들어, 영상 컨텐츠 제공 시스템은, 제2 프레임에 대응되는 모델 링 정보를 피드백 정보에 포함된 모델링 정보로 변경할 수 있다. 이를 통해, 본 발명의 몇몇 실시예에 따른 영상 컨텐츠 제공 시스템 및 방법은, 영상의 피사체 패턴 데이터를 기초로 영상 흐름에 적합한 모델링 정보를 생성함으로써, 시청자에게 영상에 대한 이해도를 높이는 컨텐츠를 제 공할 수 있다. 또한, 본 발명은, 영상과 동시에 모델링 정보를 제공하는 컨텐츠를 생성하여 시청자의 영상에 대한 이해도를 높 일 수 있다. 또한, 본 발명은, 영상 재생에 따라 내형 및 외형 중 적어도 하나가 변형되는 객체가 제공되는 경우, 객체의 내 형 및 외형 중 적어도 하나의 변형과 동시에 외형 및 내형 중 적어도 하나가 변형되는 모델링 정보를 제공할 수 있어, 시청자의 영상에 대한 이해도를 높일 수 있다. 또한, 본 발명은, 시청자에게 영상에 대응된 모델링 정보를 핸들링할 수 있는 인터페이스를 제공하여, 영상에 대한 시청자의 정보 습득 및 이해도를 높일 수 있다. 또한, 본 발명은, 영상의 주제를 기초로 영상을 번역하여 언어 장벽에 따른 시청자의 어려움을 해소할 수 있으 며, 전문 분야에 따른 번역 오역률을 낮출 수 있다. 이상의 설명은 본 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술 분 야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변 형이 가능할 것이다. 따라서, 본 실시예들은 본 실시예의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위 한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0093097", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 몇몇 실시예에 따른 영상 컨텐츠 제공 시스템의 구성도이다. 도 2는 도 1의 컨텐츠 분석부의 구성도이다. 도 3은 도 1의 번역부의 구성도이다. 도 4는 도 1의 컨텐츠 생성부의 구성도이다. 도 5는 도 4의 모델링 생성 모듈의 동작을 설명하기 위한 도면이다. 도 6은 도 1의 제1 컨텐츠를 설명하기 위한 도면이다. 도 7은 도 1의 데이터베이스부를 설명하기 위한 도면이다. 도 8은 도 1의 컨텐츠 분석부, 번역부 및 컨텐츠 생성부를 설명하기 위한 도면이다. 도 9는 본 발명의 몇몇 실시예에 따른 영상 컨텐츠 제공 방법의 순서도이다. 도 10은 도 9의 컨텐츠 정보 및 피사체 분석 정보를 생성하는 단계 S100을 설명하기 위한 순서도이다. 도 11은 도 10의 피사체 분석 정보를 생성하는 단계 S122를 설명하기 위한 순서도이다. 도 12는 도 9의 모델링 정보를 생성하는 단계 S300을 설명하기 위한 순서도이다. 도 13은 도 9의 단계 S400을 설명하기 위한 순서도이다. 도 14는 도 9의 제1 영상 및 제2 영상에 대한 피드백 정보를 수신하여 모델링 정보를 업데이트하는 방법을 설명 하기 위한 순서도이다."}
