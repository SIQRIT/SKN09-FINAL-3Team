{"patent_id": "10-2020-0160206", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0072512", "출원번호": "10-2020-0160206", "발명의 명칭": "자율 주차를 위한 주차 영역을 인식하기 위한 장치 및 그에 관한 방법", "출원인": "현대모비스 주식회사", "발명자": "이원준"}}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "차량 시스템 장치에 있어서, 영상 감지부; 인공 지능 학습부: 및 상기 영상 감지부 및 상기 인공 지능 학습부와 연결된 제어부를 포함하고, 상기 제어부는, 상기 영상 감지부를 이용하여 영상을 획득하고, 상기 인공 지능 학습부를 통해 딥 러닝(deep learning) 기반으로 상기 획득된 영상 내에서 주차 구획을 검출하고, 상기 획득된 영상 내에서 주차선 및 입구점을 검출하고, 상기 검출된 주차 구획, 주차선, 및 입구점에 기반하여 자율 주차를 위한 주차 정보를 생성하도록 설정된, 차량시스템 장치."}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 제어부는, 상기 영상 감지부를 이용하여 차량을 둘러싸는 360도 형태의 서라운드 뷰 영상을 획득하도록 설정된, 차량 시스템 장치."}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서, 상기 제어부는, 상기 획득된 영상의 영상 데이터에 대한 전처리를 수행하도록 더 설정된, 차량 시스템 장치."}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서, 상기 제어부는, 상기 전처리가 수행된 영상 데이터에 대한 특징점 추출 및 라인 피팅을 수행함으로써 상기 주차선을 검출하도록설정된, 차량 시스템 장치."}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서, 상기 제어부는, 상기 검출된 주차 구획으로부터 지정된 방향으로 연장된 상기 주차선을 감지하도록 설정된, 차량 시스템 장치."}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서, 출력부를 더 포함하고, 상기 제어부는, 상기 출력부를 통해 상기 주차 정보를 출력하도록 설정된, 차량 시스템 장치."}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서, 상기 제어부는, 상기 인공 지능 학습부를 통해 DNN(deep neural network) 기반으로 상기 주차 구획을 검출하도록 설정된, 차량공개특허 10-2022-0072512-3-시스템 장치."}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 1에 있어서, 상기 주차 정보는, 주차가 가능한 영역에 대한 식별 정보, 입구점의 위치 및 각도, 또는 주차 구획의 유형 중 적어도 하나를 포함하는, 차량 시스템 장치."}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "차량 시스템 장치의 방법에 있어서, 영상을 획득하는 동작; 딥 러닝(deep learning) 기반으로 상기 획득된 영상 내에서 주차 구획을 검출하는 동작; 상기 획득된 영상 내에서 주차선 및 입구점을 검출하는 동작; 및 상기 검출된 주차 구획, 주차선, 및 입구점에 기반하여 자율 주차를 위한 주차 정보를 생성하는 동작을 포함하는, 방법."}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서, 상기 영상을 획득하는 동작은, 차량을 둘러싸는 360도 형태의 서라운드 뷰 영상을 획득하는 동작을 포함하는,방법."}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 9에 있어서,상기 획득된 영상의 영상 데이터에 대한 전처리를 수행하는 동작을 더 포함하는, 방법."}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서, 상기 주차선을 검출하는 동작은, 상기 전처리가 수행된 영상 데이터에 대한 특징점 추출 및 라인 피팅을 수행함으로써 상기 주차선을 검출하는동작을 포함하는, 방법."}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 9에 있어서, 상기 주차선을 검출하는 동작은, 상기 검출된 주차 구획으로부터 지정된 방향으로 연장된 상기 주차선을 감지하는 동작을 포함하는, 방법."}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 9에 있어서, 상기 생성된 주차 정보를 출력하는 동작을 더 포함하는, 방법."}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 9에 있어서, 상기 딥 러닝 기반으로 상기 주차 구획을 검출하는 동작은, DNN 기반으로 상기 주차 구획을 검출하는 동작을 포함하는, 방법."}
{"patent_id": "10-2020-0160206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 9에 있어서, 상기 주차 정보는, 주차가 가능한 영역에 대한 식별 정보, 입구점의 위치 및 각도, 또는 주차 구획의 유형 중 적어도 하나를 포함공개특허 10-2022-0072512-4-하는, 방법."}
{"patent_id": "10-2020-0160206", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "차량 시스템 장치는 영상 감지부, 인공 지능 학습부, 및 상기 영상 감지부 및 상기 인공 지능 학습부와 연결된 제어부를 포함하고, 상기 제어부는, 상기 영상 감지부를 이용하여 영상을 획득하고, 상기 인공 지능 학습부를 통 해 딥 러닝(deep learning) 기반으로 상기 획득된 영상 내에서 주차 구획을 검출하고, 상기 획득된 영상 내에서 주차선 및 입구점을 검출하고, 상기 검출된 주차 구획, 주차선, 및 입구점에 기반하여 자율 주차를 위한 주차 정 보를 생성하도록 설정될 수 있다. 이 외에도 명세서를 통해 파악되는 다양한 실시 예가 가능하다."}
{"patent_id": "10-2020-0160206", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 문서에 개시되는 실시예들은 자율 주차를 위한 주차 영역을 인식하는 기술과 관련된다."}
{"patent_id": "10-2020-0160206", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기술의 발전에 따라서 차량이 주차 또는 출차를 보조하는 자율 주차 기술이 도입되고 있다. 예를 들어, RSPA(remote smart parking assist) 시스템을 포함하는 자율 주차 기술에서 사용자가 스마트 키의 버튼을 누르 면 차량이 주차 또는 출차를 스스로 주행할 수 있다."}
{"patent_id": "10-2020-0160206", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "자율 주차를 수행하기 위하여, 차량(또는 차량의 시스템)은 주차 영역을 인식할 필요가 있다. 이 경우, 초음파 를 이용하여 주차 영역을 인식할 수 있지만, 초음파를 이용하는 시스템은 주차하고자 하는 공간의 주변에 기 주 차된 차량, 벽, 또는 기둥과 같은 사물이 존재해야 하므로, 주변에 사물이 없는 주차 영역에서는 자율 주차가 불가능할 수 있다. 이미지 영상을 이용하여 주차 영역을 인식하는 기술은 주변에 사물이 없어도 차량 주변의 공 간을 인식할 수 있지만, 빛의 반사나 그림자와 같은 요인에 의하여 주차선을 검출하기 어려우며, 특히 주차장의 바닥에 그려진 보조선 또는 로드 마크로 인하여 주차 영역을 나타내는 주차 구획선의 구별이 정확하지 않을 수 있다."}
{"patent_id": "10-2020-0160206", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 문서에 개시되는 일 실시 예에 따른 차량 시스템 장치는, 영상 감지부, 인공 지능 학습부, 및 상기 영상 감 지부 및 상기 인공 지능 학습부와 연결된 제어부를 포함하고, 상기 제어부는, 상기 영상 감지부를 이용하여 영 상을 획득하고, 상기 획득된 영상 내에서 적어도 하나의 주차선 페어를 검출하고, 상기 인공 지능 학습부를 통 해 딥 러닝(deep learning) 기반으로 주차 구획을 검출하고, 상기 검출된 주차 구획 및 상기 적어도 하나의 주 차선 페어에 기반하여 주차 구획선을 검출하고, 상기 주차 구획선에 대한 입구점을 검출하고, 상기 주차 구획선 및 상기 입구점에 기반하여 자율 주차를 위한 주차 정보를 생성하도록 설정될 수 있다. 본 문서에 개시되는 일 실시 예에 따른 차량 시스템 장치는, 영상 감지부, 인공 지능 학습부, 및 상기 영상 감 지부 및 상기 인공 지능 학습부와 연결된 제어부를 포함하고, 상기 제어부는, 상기 영상 감지부를 이용하여 영 상을 획득하고, 상기 인공 지능 학습부를 통해 딥 러닝(deep learning) 기반으로 상기 획득된 영상 내에서 주차 구획을 검출하고, 상기 획득된 영상 내에서 주차선 및 입구점을 검출하고, 상기 검출된 주차 구획, 주차선, 및 입구점에 기반하여 자율 주차를 위한 주차 정보를 생성하도록 설정될 수 있다. 본 문서에 개시되는 일 실시 예에 따른 차량 시스템 장치는, 영상 감지부, 및 상기 영상 감지부와 연결된 제어 부를 포함하고, 상기 제어부는, 상기 영상 감지부를 이용하여 영상을 획득하고, 상기 획득된 영상 내에서 주차 선을 검출하고, 상기 검출된 주차선의 픽셀 값에 대한 변화량에 기반하여 주차 영역에 포함되는 입구점을 검출 하고, 상기 검출된 입구점에 대한 정보를 생성하도록 설정될 수 있다. 본 문서에 개시되는 일 실시 예에 따른 차량 시스템 장치는 영상 감지부, 인공 지능 학습부, 및 상기 영상 감지 부 및 상기 인공 지능 학습부와 연결된 제어부를 포함하고, 상기 제어부는, 상기 영상 감지부를 이용하여 영상 을 획득하고, 상기 획득된 영상 내에서 주차선을 검출하고, 상기 검출된 주차선의 픽셀 값에 대한 변화량에 기 반하여 복수의 입구점 후보군을 검출하고, 상기 인공 지능 학습부를 이용하여 딥 러닝 기반으로 상기 입구점 후 보군 중 컨피던스가 높은 입구점을 검출하고, 상기 검출된 입구점에 대한 정보를 생성하도록 설정될 수 있다. 본 문서에 개시되는 일 실시 예에 따른 차량 시스템 장치의 방법은, 영상을 획득하는 동작, 상기 획득된 영상 내에서 적어도 하나의 주차선 페어를 검출하는 동작, 딥 러닝 기반으로 주차 구획을 검출하는 동작, 상기 검출 된 주차 구획 및 상기 적어도 하나의 주차선 페어에 기반하여 주차 구획선을 검출하는 동작, 상기 주차 구획선 에 대한 입구점을 검출하는 동작, 및 상기 주차 구획선 및 상기 입구점에 기반하여 자율 주차를 위한 주차 정보를 생성하는 동작을 포함할 수 있다. 본 문서에 개시되는 일 실시 예에 따른 차량 시스템 장치의 방법은, 영상을 획득하는 동작, 딥 러닝(deep learning) 기반으로 상기 획득된 영상 내에서 주차 구획을 검출하는 동작, 상기 획득된 영상 내에서 주차선 및 입구점을 검출하는 동작, 및 상기 검출된 주차 구획, 주차선, 및 입구점에 기반하여 자율 주차를 위한 주차 정 보를 생성하는 동작을 포함할 수 있다. 본 문서에 개시되는 일 실시 예에 따른 차량 시스템 장치의 방법은, 영상을 획득하는 동작, 상기 획득된 영상 내에서 주차선을 검출하는 동작, 상기 검출된 주차선의 픽셀 값에 대한 변화량에 기반하여 주차 영역에 포함되 는 입구점을 검출하는 동작, 및 상기 검출된 입구점에 대한 정보를 생성하는 동작을 포함할 수 있다. 본 문서에 개시되는 일 실시 예에 따른 차량 시스템 장치의 방법은, 영상을 획득하는 동작, 상기 획득된 영상 내에서 주차선을 검출하는 동작, 상기 검출된 주차선의 픽셀 값에 대한 변화량에 기반하여 복수의 입구점 후보 군을 검출하는 동작, 상기 인공 지능 학습부를 이용하여 딥 러닝 기반으로 상기 입구점 후보군 중 컨피던스가 높은 입구점을 검출하는 동작, 및 상기 검출된 입구점에 대한 정보를 생성하는 동작을 포함할 수 있다."}
{"patent_id": "10-2020-0160206", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 문서에 개시되는 실시 예들에 따르면, 차량 시스템 장치는 주변에 사물이 존재하지 않는 주차 영역을 보다 명확하게 인식할 수 있다. 본 문서에 개시되는 실시 예들에 따르면, 차량 시스템 장치는 주변에 사물이 존재하지 않는 주차 영역에서 입구 점을 보다 명확하게 인식할 수 있다. 이 외에, 본 문서를 통해 직접적 또는 간접적으로 파악되는 다양한 효과들이 제공될 수 있다."}
{"patent_id": "10-2020-0160206", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 다양한 실시 예가 첨부된 도면을 참조하여 기재된다. 그러나, 이는 본 발명을 특정한 실시 형 태에 대해 한정하려는 것이 아니며, 본 발명의 실시 예의 다양한 변경(modification), 균등물(equivalent), 및/ 또는 대체물(alternative)을 포함하는 것으로 이해되어야 한다. 본 문서의 다양한 실시예들 및 이에 사용된 용어들은 본 문서에 기재된 기술적 특징들을 특정한 실시예들로 한 정하려는 것이 아니며, 해당 실시예의 다양한 변경, 균등물, 또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 또는 관련된 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 아이템 에 대응하는 명사의 단수 형은 관련된 문맥상 명백하게 다르게 지시하지 않는 한, 상기 아이템 한 개 또는 복수 개를 포함할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. \"제 1\", \"제 2\", 또는 \"첫째\" 또는 \"둘째\"와 같은 용어들은 단순히 해당 구성요소를 다른 해당 구성요소와 구분하기 위 해 사용될 수 있으며, 해당 구성요소들을 다른 측면(예: 중요성 또는 순서)에서 한정하지 않는다. 어떤(예: 제 1) 구성요소가 다른(예: 제 2) 구성요소에, \"기능적으로\" 또는 \"통신적으로\"라는 용어와 함께 또는 이런 용어 없이, \"커플드\" 또는 \"커넥티드\"라고 언급된 경우, 그것은 상기 어떤 구성요소가 상기 다른 구성요소에 직접적 으로(예: 유선으로), 무선으로, 또는 제 3 구성요소를 통하여 연결될 수 있다는 것을 의미한다. 본 문서의 다양한 실시예들에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함 할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로와 같은 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부 가 될 수 있다. 예를 들면, 일실시예에 따르면, 모듈은 ASIC(application-specific integrated circuit)의 형 태로 구현될 수 있다. 본 문서의 다양한 실시예들은 기기(machine) 의해 읽을 수 있는 저장 매체(storage medium)(예: 내장 메모리 또 는 외장 메모리)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨어(예: 프로그램)로서 구현될 수 있다. 예 를 들면, 기기는, 저장 매체로부터 저장된 하나 이상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실 행할 수 있다. 이것은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도록 운영 되는 것을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적(non-transitory) 저장 매 체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장 매체가 실재(tangible)하는 장치이고, 신호(signal) (예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장 매체에 반영구적으로 저장 되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 일실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory(CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두 개의 사용자 장치들 간에 직접, 온라인으로 배포 (예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사 의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어 도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시예들에 따르면, 상기 기술한 구성요소들의 각각의 구성요소(예: 모듈 또는 프로그램)는 단수 또는 복수의 개체를 포함할 수 있으며, 복수의 개체 중 일부는 다른 구성요소에 분리 배치될 수도 있다. 다양한 실시 예들에 따르면, 전술한 해당 구성요소들 중 하나 이상의 구성요소들 또는 동작들이 생략되거나, 또는 하나 이상 의 다른 구성요소들 또는 동작들이 추가될 수 있다. 대체적으로 또는 추가적으로, 복수의 구성요소들(예: 모듈 또는 프로그램)은 하나의 구성요소로 통합될 수 있다. 이런 경우, 통합된 구성요소는 상기 복수의 구성요소들각각의 구성요소의 하나 이상의 기능들을 상기 통합 이전에 상기 복수의 구성요소들 중 해당 구성요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따르면, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적으로, 병렬적으로, 반복적으로, 또는 휴리스틱하게 실행되거나, 상기 동 작들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또는 하나 이상의 다른 동작들이 추가될 수 있다. 도 1은 다양한 실시예들에 따른 차량 시스템 장치의 기능적 블록도이다. 도 1을 참조하면, 차량 시스템 장치는 차량에 탑재된 시스템 장치를 의미할 수 있다. 차량 시스템 장치 는 차량의 전반적인 기능(예컨대, 자율 주행 또는 자율 주차)을 수행할 수 있다. 차량 시스템 장치는 영상 감지부, 제어부, 인공지능 학습부 및 출력부를 포함할 수 있다. 다른 실시예들에 따 르면, 차량 시스템는 도 1에 도시된 구성들 중 적어도 일부(예: 출력부)를 생략하거나, 도 1에 도시 되지 않은 다른 구성 요소(예: 통신 인터페이스, 메모리)를 더 포함할 수 있다. 차량 시스템 장치에 포함 된 구성들은 하드웨어 구성뿐만 아니라 명령어들(instructions)에 의하여 구현되는 소프트웨어(예: 프로그램)를 의미할 수 있다. 영상 감지부는 영상을 획득하는데 이용될 수 있다. 예를 들어, 영상 감지부는 하나 이상의 렌즈, 이 미지 센서, 이미지 시그널 프로세서, 또는 플래시 중 적어도 하나를 포함하는 카메라일 수 있다. 실시예에 따르 면, 영상 감지부는 차량을 둘러싸는 영상을 획득할 수 있다. 이 경우, 영상 감지부는 차량에 장착된 4 채널 이상의 카메라를 포함할 수 있다. 차량을 둘러싸는 영상은 예를 들어, 360도 영역의 서라운드 뷰 (surround view) 영상일 수 있다. 차량 시스템 장치는 획득된 영상 데이터 또는 서라운드 뷰 영상에 기반 하여 차량이 주차하기 위한 주차 영역(또는 주차 구획선) 및 입구점을 검출할 수 있다. 제어부는 예를 들면, 소프트웨어(예: 프로그램)를 실행하여 제어부에 연결된 차량 시스템 장치 의 적어도 하나의 다른 구성요소(예: 하드웨어 또는 소프트웨어 구성요소)를 제어할 수 있고, 다양한 데이터 처 리 또는 연산을 수행할 수 있다. 일 실시예에 따르면, 데이터 처리 또는 연산의 적어도 일부로서, 제어부 는 다른 구성요소(예: 영상 감지부, 인공지능 학습부, 또는 출력부)로부터 수신된 명령 또는 데 이터를 휘발성 메모리에 저장하고, 휘발성 메모리에 저장된 명령 또는 데이터를 처리하고, 결과 데이터를 비휘 발성 메모리에 저장할 수 있다. 일 실시예에 따르면, 제어부는 메인 프로세서(예: 중앙 처리 장치 또는 어 플리케이션 프로세서) 또는 이와는 독립적으로 또는 함께 운영 가능한 보조 프로세서(예: 그래픽 처리 장치, 이 미지 시그널 프로세서, 센서 허브 프로세서, 또는 커뮤니케이션 프로세서)를 포함할 수 있다. 예를 들어, 제어 부가 메인 프로세서 및 보조 프로세서를 포함하는 경우, 보조 프로세서는 메인 프로세서보다 저전력을 사 용하거나, 지정된 기능에 특화되도록 설정될 수 있다. 보조 프로세서는 메인 프로세서와 별개로, 또는 그 일부 로서 구현될 수 있다. 실시예들에 따르면, 제어부는 주차 정보를 출력하기 위한 차량 시스템 장치의 전반적인 기능을 수행 할 수 있다. 예를 들어, 제어부는 영상 감지부를 통해 영상을 획득하고, 획득된 영상 내에서 복수의 주차선 후보군을 검출할 수 있다. 제어부는 복수의 주차선 후보군 중에서 적어도 하나의 주차선 페어 (fair)를 검출할 수 있다. 제어부는 인공지능 학습부를 통해 딥 러닝(deep learning) 기반으로 획득 된 영상 내에서 주차 구획을 검출할 수 있다. 제어부는 검출된 적어도 하나의 주차선 페어 및 주차 구획에 기반하여 주차 구획선을 검출하고, 검출된 주차 구획선의 입구점을 검출할 수 있다. 제어부는 검출된 주차 구획선 및 입구점에 기반하여 자율 주차를 위한 주차 정보를 생성하고, 생성된 주차 정보를 출력부를 통해 출력할 수 있다. 다른 예를 들어, 제어부는 영상 감지부를 통해 영상을 획득하고, 획득된 영상의 영상 데이터에 대한 전처리를 수행할 수 있다. 제어부는 인공 지능 학습부를 통해 딥 러닝 기반으로 영상 내에서 주차 구 획을 검출할 수 있다. 제어부는 영상 내에서 주차선을 검출할 수 있다. 제어부는 검출된 주차선 및 주차 구획에 기반하여 주차 구획선의 입구점을 검출할 수 있다. 제어부는 검출된 주차 구획, 주차선, 및 입구점에 기반하여 자율 주차를 위한 주차 정보를 생성하고, 생성된 주차 정보를 출력부를 통해 출력할 수 있다. 실시예들에 따르면, 제어부는 입구점에 대한 정보를 출력하기 위한 차량 시스템 장치의 전반적인 기 능을 수행할 수 있다. 예를 들어, 제어부는 영상 감지부를 통해 영상을 획득하고, 획득된 영상 내에 서 주차선을 검출할 수 있다. 제어부는 검출된 주차선의 픽셀 값에 대한 변화량에 기반하여 주차 영역에 대한 입구점을 검출할 수 있다. 제어부는 검출된 입구점에 대한 정보를 생성하고, 생성된 정보를 출력부 를 통해 출력할 수 있다. 다른 예를 들어, 제어부는 영상 감지부를 통해 영상을 획득하고, 획득된 영상 내에서 주차선을 검출 할 수 있다. 제어부는 검출된 주차선의 픽셀 값에 대한 변화량에 기반하여 주차 영역에 대한 입구점 후보 군을 검출할 수 있다. 제어부는 인공 지능 학습부를 이용하여 딥 러닝 기반으로 입구점 후보군 중에 서 컨피던스가 높은 입구점을 검출할 수 있다. 제어부는 검출된 입구점에 대한 정보를 출력할 수 있다. 전술한 예시는 제어부가 주차 정보를 생성하기 위한 각각의 동작을 통합적으로 수행하는 것으로 서술하였 지만, 실시예들에 따른 차량 시스템 장치는 주차선을 검출하기 위한 검출부, 주차 구획을 검출하기 위한 주차 구획 검출부, 및 입구점을 검출하기 위한 입구점 검출부를 별도로 포함할 수 있다. 이들 구성들 각각은 하드웨어 장치이거나 또는 메모리에 저장된 소프트웨어(프로그램)일 수 있다. 각각의 구성들이 하나의 모듈로 동작하지 않고 개별적으로 동작함으로써 알고리즘 변경, 학습, 또는 성능 개선이 각 구성들 마다 개별적으로 수행될 수 있다. 인공 지능 학습부는 예를 들어, 신경망 처리 장치(NPU: neural processing unit)와 같이 인공 지능 모델 의 처리에 특화된 하드웨어 구조를 포함할 수 있다. 다른 예를 들어, 인공 지능 학습부는 차량 시스템 장 치의 메모리(미도시) 내에 별도의 프로그램으로 존재할 수 있다. 인공 지능 모델은 기계 학습을 통해 생성 될 수 있다. 이러한 학습은, 예를 들어, 인공 지능이 수행되는 차량 시스템 장치 자체에서 수행될 수 있고, 별도의 서버를 통해 수행될 수도 있다. 학습 알고리즘은, 예를 들어, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습 (reinforcement learning)을 포함할 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 인공 신경망 레이어들을 포함할 수 있다. 인공 신경망은 심층 신경망(DNN: deep neural network), CNN(convolutional neural network), RNN(recurrent neural network), RBM(restricted boltzmann machine), DBN(deep belief network), BRDNN(bidirectional recurrent deep neural network), 심층 Q-네트워크(deep Q- networks) 또는 상기 중 둘 이상의 조합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 인공 지능 모델은 하드웨어 구조 이외에, 추가적으로 또는 대체적으로, 소프트웨어 구조를 포함할 수 있다. 실시예들에 따르면, 인공 지능 학습부는 딥 러닝 분류기(classifier)를 통해 주차 구획에 대한 영상을 학 습하고, 학습 결과에 따라서 서라운드 뷰 영상 내에서 주차 구획을 구별할 수 있다. 다른 예를 들어, 인공 지능 학습부는 딥 러닝 분류기를 통해 입구점에 대한 영상을 학습하고, 학습 결과에 따라서 입구점 후보군 중 하나의 입구점을 분류할 수 있다. 출력부는 주차 정보 또는 입구점에 대한 정보를 시각적 또는 청각적으로 제공하기 위한 하드웨어 구성을 포함할 수 있다. 예를 들어, 출력부는 디스플레이, 홀로그램 장치, 또는 프로젝터 및 해당 장치를 제어하 기 위한 제어 회로를 포함할 수 있다. 다른 예를 들어, 출력부는 소리를 전기 신호로 변환시키거나, 반대 로 전기 신호를 소리로 변환시킬 수 있는 오디오 장치(예: 스피커)를 포함할 수 있다. 도 2는 다양한 실시예들에 따라 주차 정보를 구성하는 파라미터들을 설명한다. 도 2를 참조하면, 차량 시스템 장치는 영상 감지부를 이용하여 영상을 획득할 수 있다. 영상 은 예를 들어, 차량을 둘러싸는 360도 형태의 서라운드 뷰 영상을 포함할 수 있다. 차량 시스템 장치(10 0)가 자율 주차를 수행하기 위하여 입구점(예: 210-1, 210-2, 210-3, 210-4), 주차선(예: 220-1, 220-2, 220- 3, 220-4), 또는 주차 구획(예: 230-1, 230-2) 중 적어도 하나의 정보가 필요할 수 있다. 입구점은 자율 주차를 제어하기 위하여 이용될 수 있다. 도 2는 입구점이 주차선과 주차 구획이 만나는 점 (point)으로 표현되지만, 다양한 실시예들에 따른 입구점은 주차 영역의 일부 면적을 포함하는 영역일 수 있다. 입구점은 위치 좌표(예: x, y 좌표) 및 방향 정보(예: 각도)를 포함할 수 있다. 예를 들어, 입구점의 방향 정보 중 제1 정보는 주차선의 방향에 대응하고, 제2 정보는 주차 구획의 방향에 대응할 수 있다. 따라서, 차량 시스 템 장치는 입구점의 유형(또는 형태)에 따라서 주차 영역의 유형(또는 형태)를 결정할 수 있다. 입구점의 유형에 대한 예시는 도 11에서 후술된다. 도 3 내지 도 4는 일 실시예에 따라 주차 정보를 생성하는 동작을 설명한다. 도 3을 참조하면, 도 3의 (a)에서, 차량 시스템 장치는 영상 감지부를 이용하여 차량을 둘러싸 는 360도 형태의 서라운드 뷰 영상을 획득할 수 있다. 설명의 편의를 위하여 차량 시스템 장치가 360 도 형태의 서라운드 뷰 영상을 이용하는 실시예들을 설명하지만, 영상 감지부에 의하여 획득된 영상 의 형태는 서라운드 뷰 형태로 제한되는 것은 아니다. 도 3의 (b)에서, 차량 시스템 장치는 영상 내에서 적어도 하나의 주차선 페어를 검출할 수 있다. 주 차선 페어는 예를 들어, 하나의 주차 구획선을 형성하는 두 개의 주차선을 의미할 수 있다. 예를 들어, 주차선 (310-1) 및 주차선(310-2)은 하나의 주차선 페어를 형성하고, 주차선(310-3) 및 주차선(310-4)은 다른 하나의 주차선 페어를 형성할 수 있다. 도 3은 두 개의 주차선 페어만을 검출하는 예를 도시하지만, 차량 시스템 장치 에 의하여 검출되는 주차선 및 주차선 페어의 개수는 제한되지 않는다. 일 실시예에 따르면, 차량 시스템 장치는 주차선 페어를 검출하기 위하여 영상 내에서 복수의 주차선 후보군을 검출할 수 있다. 예를 들어, 제어부는 영상 감지부를 통해 획득된 로우 데이터(raw data) 또는 서라운드 뷰 영상의 노이즈를 제거하기 위하여 필터링(예: gaussian filtering)을 수행하고, 필터링된 영 상에서 엣지(edge) 데이터를 추출할 수 있다. 제어부는 영상 내에서 라인(line)(또는 선)이라고 판단 되는 지점을 라인 특징점으로 결정할 수 있다. 라인 특징점은 예를 들어 영상 내에서 위치 정보(예: x, y 좌표) 및 그라디언트(gradient) 기반의 방향 정보를 포함할 수 있다. 제어부는 결정된 라인 특징점에 대해 라인 피팅(line fitting)을 수행할 수 있다. 예를 들어, 제어부는 결정된 라인 특징점들 중 방향 및 위치 가 유사한 특징점들을 클러스터링(clustering)함으로써 라인들을 추출할 수 있다. 추출된 라인들(즉, 주차선)은 양 끝점(예: x, y좌표) 및 방향 정보를 포함할 수 있다. 제어부는 필터링, 특징점 검출, 및 라인 피팅을 통해 결정된 복수의 주차선 후보군 중에서 서로 평행하고 지정된 간격만큼 떨어진 두 라인을 주차선 페어로 결 정할 수 있다. 도 3의 (c)에서, 차량 시스템 장치는 딥 러닝에 기반하여 적어도 하나의 주차 구획(예: 320-1 또는 320- 2)을 검출할 수 있다. 주차 구획은 예를 들어, 주차선 페어 사이의 공간으로써, 주차 영역의 진입 구간을 의미 할 수 있다. 실시예에 따르면, 제어부는 인공 지능 학습부를 통해 다양한 형태의 주차 구획을 학습하 고, 학습 결과에 기반하여 영상 내에서 주차 구획에 대응하는 영역을 검출할 수 있다. 주차선 페어 및 주 차 구획은 하나의 주차 영역(또는 주차 구획선)을 형성할 수 있다. 도 3의 (d)에서, 차량 시스템 장치는 주차 구획선에 포함되는 입구점(예: 330-1, 330-2, 330-3, 또는 330-4)을 검출할 수 있다. 입구점은 주차 구획의 끝 지점과 주차선 페어의 끝 지점이 만나는 지점을 의미할 수 있다. 또한, 입구점은 주차 구획선의 끝 점을 의미할 수 있다. 입구점은 예를 들어, 영상 내에서 위치 자 표(예: x, y좌표)로 표현될 수 있다. 차량 시스템 장치는 입구점의 위치를 이용하여 자율 주차를 제어할 수 있다. 도 3의 (e)에서, 차량 시스템 장치는 자율 주차를 위한 주차 정보를 출력할 수 있다. 주차 정보는 예를 들 어, 주차가 가능한 영역에 대한 식별 정보(예: Index 0 또는 Index 1), 입구점의 위치 및 각도(예: 340-1, 340-2, 340-3, 또는 340-4), 또는 주차 구획의 유형(예: 평행형, 직각형, 사선형, 계단형) 중 적어도 하나의 정 보를 포함할 수 있다. 도 4는 일 실시예에 따라 주차 정보를 출력하기 위한 차량 시스템 장치의 동작 흐름도를 도시한다. 이하의 설명 에서, 동작 흐름도에 포함된 동작들은 차량 시스템 장치에 의하여 수행되거나 또는 차량 시스템 장치(10 0)에 포함된 구성들에 의하여 수행될 수 있다. 예를 들어, 차량 시스템 장치의 제어부는 다른 구성들 (예: 영상 감지부, 인공 지능 학습부, 및 출력부)을 제어함으로써 동작 흐름도의 동작들을 수행 할 수 있다. 도 4를 참조하면, 동작 410에서, 제어부는 영상 감지부를 이용하여 영상을 획득할 수 있다. 획득된 영상은 예를 들어, 차량 시스템 장치의 차량을 둘러싸는 360도 형태의 서라운드 뷰 영상을 포함할 수 있다. 동작 420에서, 제어부는 획득된 영상 내에서 복수의 주차선 후보군을 검출할 수 있다. 주차선은 예를 들어, 영상 내에서 지정된 방향을 가지는 라인을 의미할 수 있다. 동작 430에서, 제어부는 획득된 영상 내에서 주차선 페어를 검출할 수 있다. 예를 들어, 제어부는 복 수의 주차선 후보군 중에서 서로 평행하고 지정된 간격을 가지는 두 개의 주차선을 주차선 페어로 결정할 수 있 다. 일 실시예에 따르면, 제어부는 동작 420 및 동작 430을 개별적으로 수행하지 않고 동시에 수행할 수 있다. 동작 420 내지 동작 430은 주차선 검출부에 의하여 수행될 수 있다. 동작 440에서, 제어부(예: 주차 구획 검출부)는 딥 러닝 기반으로 영상 내에서 주차 구획을 검출할 수 있다. 예를 들어, 제어부는 검출된 주차선 페어 간 영역을 추출하고, 인공 지능 학습부를 이용하 여 추출된 영역을 분류(classify)할 수 있다. 상기 분류는 예를 들어, DNN 기반의 딥 러닝 분류기에 의하여 수행될 수 있다. 제어부는 분류를 통해 추출된 영역이 주차 구획인지 아닌지를 결정하고, 주차 구획에 해당 한다면 주차 구획의 유형이 무엇인지를 결정할 수 있다. 주차 구획의 유형은 예를 들어, 평행형, 직각형, 사선 형, 및 계단형을 포함할 수 있지만 이에 제한되지 않는다. 동작 450에서, 제어부는 주차 구획선을 검출할 수 있다. 예를 들어, 제어부는 동작 420에서 추출된 주차선 후보군(또는 주차선 페어) 중에서 주차 구획과 대응하는 주차선 및 해당 주차 구획을 주차 구획선으로 결정할 수 있다. 동작 460에서, 제어부(예: 입구점 검출부)는 결정된 주차 구획선의 입구점을 검출할 수 있다. 입구점 은 예를 들어, 위치 좌표 및 방향 정보로 표현될 수 있다. 입구점의 방향 정보는 주차선 페어의 방향에 대응될 수 있다. 일 실시예에 따르면, 입구점은 주차 구획선이 검출될 때 함께 결정될 수 있다. 이 경우, 제어부 는 동작 460을 생략할 수 있다. 동작 470에서, 제어부는 자율 주차를 위한 주차 정보를 출력할 수 있다. 예를 들어, 제어부는 주차 정보를 자율 주행을 위한 차량 시스템 장치의 다른 구성에 전달할 수 있다. 다른 예를 들어, 제어부 는 사용자가 주차 구획선 및 입구점을 확인할 수 있도록 주차 정보를 출력부를 통해 표시할 수 있다. 도 5 내지 도 6은 다른 실시예에 따라 주차 정보를 생성하는 동작을 설명한다. 도 5를 참조하면, 도 5의 (a)에서, 차량 시스템 장치는 영상 감지부를 이용하여 차량을 포함하 는 영상을 획득할 수 있다. 영상은 예를 들어, 차량을 둘러싸는 360도 형태의 서라운드 뷰 영상 일 수 있다. 도 5의 (b)에서, 차량 시스템 장치는 딥 러닝에 기반하여 적어도 하나의 주차 구획(예: 510-1 또는 510- 2)을 검출할 수 있다. 주차 구획은 예를 들어, 주차 영역(또는 주차 구획선)에서 차량이 진입하는 구간을 의미 할 수 있다. 실시예에 따르면, 제어부는 인공 지능 학습부를 통해 다양한 유형의 주차 구획을 학습하 고, 학습 결과에 기반하여 영상 내에서 주차 구획에 대응하는 영역 및 해당 영역이 나타내는 주차 구획의 유형을 검출할 수 있다. 제어부는 검출된 주차 구획의 유형 및 위치 정보(예: x, y 좌표)를 나타내는 주차 구획 정보를 생성할 수 있다. 도 5의 (c)에서, 차량 시스템 장치는 영상 내에서 적어도 하나의 주차선(예: 520-1, 520-2, 520-3, 520-4)을 검출할 수 있다. 예를 들어, 제어부는 영상 감지부를 통해 획득된 로우 데이터(raw data) 또는 서라운드 뷰 영상의 노이즈를 제거하기 위하여 필터링(예: gaussian filtering)을 수행하고, 필터링된 영 상에서 엣지(edge) 데이터를 추출할 수 있다. 제어부는 영상 내에서 라인(line)(또는 선)이라고 판단 되는 지점을 라인 특징점으로 결정할 수 있다. 라인 특징점은 예를 들어 영상 내에서 위치 정보(예: x, y 좌표) 및 그라디언트(gradient) 기반의 방향 정보를 포함할 수 있다. 제어부는 결정된 라인 특징점에 대해 라인 피팅(line fitting)을 수행할 수 있다. 예를 들어, 제어부는 결정된 라인 특징점들 중 방향 및 위치 가 유사한 특징점들을 클러스터링(clustering)함으로써 라인들을 추출할 수 있다. 추출된 라인들(즉, 주차선)은 양 끝점(예: x, y좌표) 및 방향 정보를 포함할 수 있다. 제어부는 필터링, 특징점 검출, 및 라인 피팅을 통해 결정된 복수의 주차선 중에서 서로 평행하고 지정된 간격만큼 떨어진 두 라인을 주차선 페어(예: 520-1과 520-2, 또는 520-3과 520-4)로 결정할 수 있다. 주차선 페어 및 주차 구획은 하나의 주차 구획선을 형성할 수 있다. 도 5의 (d)에서, 차량 시스템 장치는 주차 구획선에 포함되는 입구점(예: 530-1, 530-2, 530-3, 또는 530-4)을 검출할 수 있다. 입구점은 주차 구획의 끝 지점과 주차선 페어의 끝 지점이 만나는 지점을 의미할 수 있다. 또한, 입구점은 주차 구획선의 끝 점을 의미할 수 있다. 입구점은 예를 들어, 영상 내에서 위치 자 표(예: x, y좌표)로 표현될 수 있다. 차량 시스템 장치는 입구점의 위치를 이용하여 자율 주차를 제어할 수 있다. 도 5의 (e)에서, 차량 시스템 장치는 자율 주차를 위한 주차 정보를 출력할 수 있다. 주차 정보는 예를 들 어, 주차가 가능한 영역에 대한 식별 정보(예: Index 0 또는 Index 1), 입구점의 위치 및 각도(예: 540-1, 540-2, 540-3, 또는 540-4), 또는 주차 구획의 유형(예: 평행형, 직각형, 사선형, 계단형) 중 적어도 하나의 정 보를 포함할 수 있다. 도 6은 다른 실시예에 따라 주차 정보를 출력하기 위한 차량 시스템 장치의 동작 흐름도를 도시한다. 이하의 설 명에서, 동작 흐름도에 포함된 동작들은 차량 시스템 장치에 의하여 수행되거나 또는 차량 시스템 장치 에 포함된 구성들에 의하여 수행될 수 있다. 예를 들어, 차량 시스템 장치의 제어부는 다른 구성들(예: 영상 감지부, 인공 지능 학습부, 및 출력부)을 제어함으로써 동작 흐름도의 동작들을 수행할 수 있다. 도 6을 참조하면, 동작 610에서, 제어부는 영상 감지부를 이용하여 영상을 획득할 수 있다. 획득된 영상은 예를 들어, 차량 시스템 장치의 차량을 둘러싸는 360도 형태의 서라운드 뷰 영상을 포함할 수 있다. 동작 620에서, 제어부는 영상 데이터에 대한 전처리를 수행할 수 있다. 상기 영상 데이터는 예를 들어, 도 6의 동작 610에서 획득된 영상의 로우 데이터 또는 서라운드 뷰 영상의 데이터를 의미할 수 있다. 예를 들어, 제어부는 영상 데이터를 필터링함으로써 영상 데이터 내에서 노이즈를 제거할 수 있다. 제어부는 필 터링된 영상 데이터에서 엣지 데이터를 추출하기 위한 작업을 수행할 수 있다. 동작 630에서, 제어부(예: 주차 구획 검출부)는 딥 러닝 기반으로 영상 내에서 주차 구획을 검출할 수 있다. 예를 들어, 제어부는 인공 지능 학습부를 이용하여 영상 내에서 주차 구획에 대응하는 영역 을 인식하고, 인식된 영역이 나타내는 주차 구획의 유형을 분류할 수 있다. 상기 분류는 예를 들어, DNN 기반의 딥 러닝 분류기에 의하여 수행될 수 있다. 주차 구획의 유형은 예를 들어, 평행형, 직각형, 사선형, 및 계단형 을 포함할 수 있지만 이에 제한되지 않는다. 동작 640에서, 제어부(예: 주차선 검출부)는 획득된 영상 내에서 주차선을 검출할 수 있다. 주차선은 예를 들어, 영상 내에서 지정된 방향을 가지는 라인을 의미할 수 있다. 제어부는 획득된 영상에서 특징점 을 추출하고, 추출된 특징점들에 대한 라인 피팅을 통해 주차선을 검출할 수 있다. 제어부는 검출된 복수 의 주차선 중에서 서로 평행하고 지정된 간격을 가지는 두 개의 주차선을 주차선 페어로 결정할 수 있다. 다른 실시예에 따르면, 제어부 또는 주차선 검출부는 검출된 주차 구획에 기반하여 주차선을 검출할 수 있다. 예를 들어, 제어부는 주차 구획의 유형에 따라서, 주차 구획으로부터 연장되는 주차선을 검출할 수 있다. 이 때 주차선의 방향은 검출된 주차 구획의 유형에 기반할 수 있다. 동작 650에서, 제어부(예: 입구점 검출부)는 입구점을 검출할 수 있다. 입구점은 예를 들어, 위치 좌 표 및 방향 정보로 표현될 수 있다. 입구점의 방향 정보는 주차선의 방향에 대응될 수 있다. 일 실시예에서, 제 어부는 검출된 주차 구획 또는 주차선 중 적어도 하나를 이용하여 입구점을 검출할 수 있다. 예를 들어, 입구점은 주차 구획과 주차선이 만나는 지점일 수 있다. 다른 예를 들어, 입구점은 주차 구획 또는 주차선의 끝 지점일 수 있다. 동작 660에서, 제어부는 자율 주차를 위한 주차 정보를 출력할 수 있다. 예를 들어, 제어부는 주차 정보를 자율 주행을 위한 차량 시스템 장치의 다른 구성에 전달할 수 있다. 다른 예를 들어, 제어부 는 사용자가 주차 구획선 및 입구점을 확인할 수 있도록 주차 정보를 출력부를 통해 표시할 수 있다. 도 7은 다양한 실시예들에 따라 주차선 후보군을 검출하기 위한 차량 시스템 장치의 동작 흐름도를 도시한다. 도 7에 도시된 동작들은 예를 들어, 도 4의 동작 420 또는 도 6의 동작 340의 일 예로 수행될 수 있다. 도 7에 도시된 동작들 중 동작 420 내지 440은 주차선 검출부에 의하여 수행될 수 있다. 도 7을 참조하면, 동작 710에서, 제어부는 영상 데이터에 대한 전처리를 수행할 수 있다. 상기 영상 데이 터는 예를 들어, 도 3의 동작 310 또는 도 6의 동작 610에서 획득된 영상의 로우 데이터이거나 서라운드 뷰 영 상의 데이터를 의미할 수 있다. 예를 들어, 제어부는 영상 데이터를 필터링함으로써 영상 데이터 내에서 노이즈를 제거할 수 있다. 제어부는 필터링된 영상 데이터에서 엣지 데이터를 추출하기 위한 작업을 수행 할 수 있다. 동작 720에서, 제어부는 전처리된 영상 데이터에 기반하여 라인 특징점을 검출할 수 있다. 라인 특징점은 복수개일 수 있다. 라인 특징점은 위치 정보 및 방향 정보를 포함할 수 있다. 동작 730에서, 제어부는 검출된 라인 특징점에 대한 라인 피팅을 수행할 수 있다. 예를 들어, 제어부(12 0)는 검출된 라인 특징점들 중 방향 및 위치가 유사한 특징점들을 클러스터링함으로써 라인을 생성할 수 있다. 생성된 라인은 양 끝점에 대한 위치 좌표(예: x, y 좌표) 및 방향 정보(예: 각도)를 포함할 수 있다. 동작 740에서, 제어부는 생성된 라인을 통해 영상 내에서 주차선 후보군을 검출할 수 있다. 예를 들어, 제 어부는 기 결정된 라인들 중에서 지정된 길이를 가지거나 또는 다른 라인들과 평행한 라인들을 주차선 후 보군으로 결정할 수 있다. 도 8은 다양한 실시예들에 따라 딥 러닝 분류기에 기반하여 주차 구획을 검출하는 동작을 설명한다. 도 8을 참조하면, 차량 시스템 장치(예: 제어부)는 주차 구획을 포함하는 영상(예: 810-1, 810-2)을 DNN 기반 주차 구획 분류기(parking slot classifier)의 입력으로 이용할 수 있다. 주차 구획을 포함하는 영상 은 영상 감지부를 통해 기 획득된 영상(예: 도 2의 200) 내에서 추출되거나, 차량 시스템 장치가 주 차선 후보군(또는 주차선 페어)를 검출한 후 추가적으로 영상 감지부를 통해 획득할 수 있다. DNN 기반 주차 구획 분류기는 다양한 형태의 주차 구획을 포함하는 영상을 통해 학습된 상태이므로, 입력된 영 상이 주차 구획을 포함하는지, 포함한다면 어떠한 유형의 주차 구획을 나타내는지를 식별할 수 있다. 예를 들어, 제1 영상(810-1)이 DNN 기반 주차 구획 분류기에 입력되면, 제어부(또는 인공 지능 학습부)는 제1 영상(810-1)이 주차 구획을 나타냄을 인식하고, 인식된 주차 구획의 유형이 사선(diagonal)형(820-1)을 나 타냄을 인식할 수 있다. 유사한 예로, 제2 영상(810-2)이 DNN 기반 주차 구획 분류기에 입력되면, 제어부 는 제2 영상(810-2)이 주차 구획을 나타냄을 인식하고, 인식된 주차 구획의 유형이 직각(perpendicular)형(820- 2)을 나타냄을 인식할 수 있다. 도 9a, 도 9b, 및 도 10은 다양한 실시예들에 따라 주차 구획을 학습하는 동작을 설명한다. 도 9a 및 도 9b는 주차 구획 영상을 획득하는 동작을 설명하고, 도 10은 딥 러닝 분류기를 통해 주차 구획 영상을 학습하는 동작 을 설명한다. 이하 서술되는 주차 구획 영상의 학습 방법은 차량 시스템 장치의 인공 지능 학습부를 통해 수행될 수 도 있고, 차량 시스템 장치와 연계된 별도의 서버를 통해 수행될 수 있다. 이 경우, 차량 시스템 장치는 서버로부터 학습 결과를 수신함으로써 주차 구획을 검출할 수 있다. 도 9a를 참조하면, 차량 시스템 장치(예: 인공 지능 학습부)는 영상 감지부를 통해 적어도 하나 의 주차 구획을 포함하는 영상을 획득할 수 있다. 인공 지능 학습부는 장소(예: 주차장), 날씨, 및 주차 구획의 유형을 변경하면서 주차 구획을 포함하는 영상을 복수 개 획득할 수 있다. 인공 지능 학습부 는 주차 구획을 포함하는 영상에서 학습에 이용될 로컬 패치(local patch) 영상을 생성할 수 있다. 일 실시예에 서, 인공 지능 학습부는 입구점들(예: 920-1, 920-2)의 페어링을 통해 주차 구획(예: 910-1)을 포함하는 복수 개의 로컬 패치 영상을 생성할 수 있다. 로컬 패치 영상은 주차 구획의 위치 좌표(예: x, y), 너비 (width), 높이(height), 또는 유형(예: 직각, 평행, 사선, 계단, 및 개방/폐쇄)에 관한 정보를 포함할 수 있다. 도 9b를 참조하면, 주차 구획의 유형은 예를 들어, 폐쇄된 직각형(930-1), 개방된 직각형(930-2), 폐쇄된 평행 형(930-3), 폐쇄된 사선형(930-4), 개방된 사선형(930-5), 및 계단형(930-6)을 포함할 수 있으나 주차 구획의 유형은 이에 제한되지 않는다. 로컬 패치 영상은 참조 번호(930-1 내지 930-6)이 나타내는 형태를 의미할 수 있 다. 도 10을 참조하면, 인공 지능 학습부는 다양한 상황(예: 장소, 날씨 등)에서도 주차 구획의 유형을 정확하 게 인식하기 위하여 딥 러닝 분류기를 통해 로컬 패치 영상을 학습할 수 있다. 인공 지능 학습부는 학습 이전에 획득된 로컬 패치 영상이 주차 구획인지 여부를 먼저 판단하고, 주차 구획에 해당하면 학습 을 수행할 수 있다. 딥 러닝 분류기는 다양한 형태의 인공 지능 모델에 기반하여 주차 구획을 학습할 수 있다. 예를 들어, 딥 러닝 분류기는 CNN 구조를 이용하여 주차 구획의 유형을 학습함으로써 영상 인식의 정확도를 높 일 수 있다. 예를 들어, 딥 러닝 분류기의 입력은 다양한 유형의 주차 구획을 나타내는 로컬 패치 영상들 과, 각 영상들이 나타내는 주차 구획 유형일 수 있다. 딥 러닝 분류기는 입력 데이터에 대하여 합성곱 (convolution)과 서브 샘플링(sub sampling)을 반복적으로 수행할 수 있다. 합성곱은 입력 영상에 마스크(mas k)를 적용하고, 입력 영상의 픽셀 값 마다 마스크의 가중치를 곱한 후 그들의 합을 출력 영상의 픽셀 값으로 설 정하는 동작으로 이해될 수 있다. 딥 러닝 분류기의 입력은 합성곱을 통해 복수 개의 영상으로 출 력될 수 있다. 상기 복수 개의 영상들은 피처 맵(feature map)으로 참조될 수 있다. 서브 샘플링은 화면 의 크기를 줄이는 동작으로써 풀링(pooling) 동작으로도 참조될 수 있다. 서브 샘플링은 M x M 크기의 피처 맵 을 N X N 크기로 축소하는 동작으로 이해될 수 있다. 서브 샘플링을 통해 크기가 감소된 복수 개의 영상들 이 생성될 수 있다. 위와 같은 합성곱 및 서브 샘플링을 반복하면 영상의 수는 증가하고, 영상의 크기는 축소될 수 있다(1040, 및 1050). 축소된 영상들은 특징만을 가지게 될 수 있다. 특징은 예를 들어, 주차 구획의 유형을 구별하기 위한 것으로써, 입구점의 위치, 방향, 각도, 개방형/폐쇄형 여부 등을 포함할 수 있다. 딥 러 닝 분류기는 합성곱과 서브 샘필링의 반복을 통해 생성된 복수의 영상들을 적어도 하나의 은닉층(hidden layer, 1060)(예: DNN)에 적용함으로써 학습할 수 있다. 딥 러닝 분류기는 학습 결과를 이용하여 이후 획 득된 영상 내에서 주차 구획의 유형을 분류할 수 있다. 도 11 내지 도 18은 다양한 실시예들에 따라 입구점에 대한 정보를 출력하기 위한 동작을 설명한다. 도 11은 다양한 실시예들에 따른 입구점의 유형을 설명한다. 도 11을 참조하면, 차량 시스템 장치는 다양한 입구점 유형에 대한 데이터(1101 내지 1101)를 획득하거나 또는 학습 및 저장할 수 있다. 입구점 유형은 주차 구획의 존재 여부 및 주차 구획과 주차선이 만나는 각도에 기반하여 결정될 수 있다. 입구정 유형은 예를 들어, 열린 타입(open type), T 타입, 왼쪽 L 타입 , 오른쪽 L 타입, 왼쪽으로 경사진(slanted) T 타입, 왼쪽으로 경사진 왼쪽 L 타입, 왼쪽으로 경사진 오른쪽 L 타입, 오른쪽으로 경사진 T 타입, 오른쪽으로 경사진 왼쪽 L 타입 , 오른쪽으로 경사진 오른쪽 L 타입, 및 U 타입을 포함할 수 있다. 도 12 내지 도 14는 일 실시예에 따라 입구점에 대한 정보를 출력하는 동작을 설명한다. 도 12를 참조하면, 도 12의 (a)에서 제어부는 획득된 영상에서 주차선을 검출할 수 있다. 도 12의 (b)에서 제어부는 검출된 주차선의 픽셀 값들에 대한 프로파일을 추출할 수 있다. 상기 프로파일을 나타내는 그래프의 x축은 영상에서의 x축 거리를 나타내고, y축은 픽셀 값을 의미할 수 있다. 그래프에서 변화량이 큰 구간(또는 변화량이 임계값을 초과한 구간)은 주차선이 끝나는 구간 임을 의미할 수 있다. 제어부는 주차선이 끝나는 구간과 인접한 위치에 입구점이 존재 함을 알 수 있지만, 변화량이 큰 구간의 폭이 크거나, 변화량의 차이가 크지 않다면 입구점의 위치 및 유 형에 대한 결과가 정확하지 않을 수 있다. 입구점의 위치 및 유형을 보다 정확하게 인식하기 위하여, 도 12의 (c)에서 제어부는 변화량이 큰 구간(예: 도 12의 1230)에 대한 마스크 필터링을 통해 입구점을 검출할 수 있다. 마스크 필터링은 변화량이 큰 구간에 대한 형태를 차량 시스템 장치에 기 저장된 데이터와 비교하는 방식을 의미할 수 있다. 기 저장된 데이터는 예를 들어, 도 11이 나타내는 다양한 입구점 유형에 대한 데이터를 의미할 수 있다. 제어부는 변 화량이 큰 구간에 대응하는 영상 내의 구간을 기 저장된 데이터와 비교하여 매칭 스코어 (matching score)가 가장 높은 입구점 유형을 해당 구간의 입구점 유형으로 결정할 수 있다. 제어부는 기 검출된 주차선과 결정된 입구점 유형에 기반하여 입구점의 위치를 보다 정확하게 검출할 수 있다. 예를 들어, 도 12의 (d)에서, 제어부는 그래프 상에서의 제1 지점을 영상 내에서 입구점의 위치로 결정할 수 있다. 도 13은 일 실시예에 따라 입구점에 대한 정보를 출력하기 위한 차량 시스템 장치의 동작 흐름도를 도시한다. 이하의 설명에서, 동작 흐름도에 포함된 동작들은 차량 시스템 장치에 의하여 수행되거나 또는 차량 시스 템 장치에 포함된 구성들에 의하여 수행될 수 있다. 예를 들어, 차량 시스템 장치의 제어부는 다른 구성들(예: 영상 감지부 및 출력부)을 제어함으로써 동작 흐름도의 동작들을 수행할 수 있다. 다른 예를 들어, 동작 1320은 주차선 검출부에 의하여 수행되고, 동작 1330 내지 동작 1320은 입구점 검출 부에 의하여 수행될 수 있다. 도 13을 참조하면, 동작 1310에서, 제어부는 영상 감지부를 이용하여 영상을 획득할 수 있다. 획득된 영상은 예를 들어, 차량 시스템 장치의 차량을 둘러싸는 360도 형태의 서라운드 뷰 영상을 포함할 수 있다. 동작 1320에서, 제어부는 획득된 영상에서 주차선을 검출할 수 있다. 예를 들어, 제어부는 영상 감지 부를 통해 획득된 로우 데이터(raw data) 또는 서라운드 뷰 영상의 노이즈를 제거하기 위하여 필터링(예: gaussian filtering)을 수행하고, 필터링된 영상에서 엣지(edge) 데이터를 추출할 수 있다. 제어부는 영상 내에서 라인(line)(또는 선)이라고 판단되는 지점을 라인 특징점으로 결정할 수 있다. 라인 특징점은 예를 들어 영상 내에서 위치 정보(예: x, y좌표) 및 변화량(gradient) 기반의 방향 정보를 포함할 수 있다. 제어부는 결정된 라인 특징점에 대해 라인 피팅(line fitting)을 수행할 수 있다. 예를 들어, 제어부는 결정된 라인 특징점들 중 방향 및 위치가 유사한 특징점들을 클러스터링(clustering)함으로써 라인들을 추출할 수 있다. 추 출된 라인들(즉, 주차선)은 양 끝점(예: x, y좌표) 및 방향 정보를 포함할 수 있다. 동작 1330에서, 제어부는 검출된 주차선의 픽셀 값에 대한 변화량에 기반하여 입구점을 검출할 수 있다. 예를 들어, 주차선에 대응하는 픽셀 값들 간 변화량은 크지 않은 반면에, 주차선이 끝나는 지점에서의 픽셀 값 은 주차선에 대응하는 픽셀 값과 차이가 클 것이므로, 제어부는 변화량이 큰 지점을 입구점으로 결정할 수 있다. 동작 1340에서, 제어부는 입구점에 대한 정보를 출력할 수 있다. 입구점에 대한 정보는 예를 들어, 입구점 의 위치, 각도, 방향, 또는 유형 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 제어부는 입구점에 대 한 정보를 자율 주행을 위한 차량 시스템 장치의 다른 구성에 전달할 수 있다. 다른 예를 들어, 제어부 는 사용자가 입구점을 확인할 수 있도록 입구점에 대한 정보를 출력부를 통해 표시할 수 있다. 도 14는 일 실시예에 따라 입구점을 검출하기 위한 차량 시스템 장치의 동작 흐름도를 도시한다. 도 14에 도시 된 동작들은 제어부 또는 입구점 검출부에 의하여 수행될 수 있다. 도 14를 참조하면, 동작 1410에서, 제어부는 영상에서 주차선을 나타내는 픽셀 값들에 대한 프로파일을 추 출할 수 있다. 동작 1420에서, 제어부는 프로파일 상에서 변화량을 측정할 수 있다. 동작 1430에서, 제어부는 변화량이 큰 구간을 검출할 수 있다. 일 실시예에서, 제어부는 픽셀 값에 대한 변화량이 지정된 임계값을 초과하는 구간을 검출할 수 있다. 동작 1440에서, 제어부는 변화량이 큰 구간(예: 도 5의 530)에 대한 마스크 필터링을 통해 입구점을 검출 할 수 있다. 마스크 필터링은 변화량이 큰 구간에 대한 형태를 차량 시스템 장치에 기 저장된 데이터와 비 교하는 방식을 의미할 수 있다. 도 15 내지 도 18은 다른 실시예에 따라 입구점에 대한 정보를 출력하기 위한 동작을 설명한다. 도 15를 참조하면, 도 15의 (a)에서 제어부는 획득된 영상에서 주차선을 검출할 수 있다. 예 를 들어, 제어부는 획득된 영상에 대한 전처리를 수행하고, 전처리가 수행된 영상의 특징점 추출 및 라인 피팅을 통해 주차선을 검출할 수 있다. 도 15의 (b)에서 제어부는 검출된 주차선의 픽셀 값들에 대한 프로파일을 추출할 수 있다. 상 기 프로파일을 나타내는 그래프의 x축은 영상에서의 x축 거리를 나타내고, y축은 픽셀 값을 의미할 수 있다. 제어부는 픽셀 값에 대한 변화량을 측정하고, 변화량이 지정된 임계값을 초과하는 구간(예: 1530)을 검출할 수 있다. 프로파일 상에서 변화량이 임계값을 초과하는 구간은 복수 개 일 수 있다. 이 경우, 제어부는 각각의 구간을 입구점 후보군으로 결정할 수 있다. 일 실시예에 따르면, 제어부는 입구점 후보군의 수를 N개(여기서, N은 자연수)로 설정할 수 있다. 이 경우, 제어부는 변화량이 임계값을 초과한 복수 개의 입구점 후보군 중 변화량이 가장 큰 N개의 입구점 후 보군을 이용할 수 있다. 도 15의 (c)에서, 제어부는 입구점 후보군 각각에 대한 영상(예: 1540-1, 1540-2, 1540-3, 1540-4)을 추 출할 수 있다. 도 15의 (d) 및 (e)에서, 제어부는 입구점 후보군 각각에 대한 영상을 분류기를 통해 분류 할 수 있다. 예를 들어, 제어부는 입구점 후보군 각각에 대한 영상을 인공 지능 학습부를 통해 기 학 습된 데이터와 비교하고, 컨피던스(confidence)가 가장 높은 영상을 입구점에 대응하는 영상으로 결정할 수 있다. 분류기는 입구점 후보군의 영상과 기 학습된 데이터 간 비교를 통해 영상 내에 포함된 입구점 의 위치 및 유형을 결정할 수 있다. 도 16은 다른 실시예에 따라 입구점에 대한 정보를 출력하기 위한 차량 시스템 장치의 동작 흐름도를 도시한다. 이하의 설명에서, 동작 흐름도에 포함된 동작들은 차량 시스템 장치에 의하여 수행되거나 또는 차량 시스 템 장치에 포함된 구성들에 의하여 수행될 수 있다. 예를 들어, 차량 시스템 장치의 제어부는 다른 구성들(예: 영상 감지부, 인공 지능 학습부, 및 출력부)을 제어함으로써 동작 흐름도의 동 작들을 수행할 수 있다. 다른 예를 들어, 동작 1620은 주차선 검출부에 의하여 수행되고, 동작 1630 내지 동작 1650은 입구점 검출부에 의하여 수행될 수 있다. 도 16을 참조하면, 동작 1610에서, 제어부는 영상 감지부를 이용하여 영상을 획득할 수 있다. 획득된 영상은 예를 들어, 차량 시스템 장치의 차량을 둘러싸는 360도 형태의 서라운드 뷰 영상을 포함할 수 있다. 동작 1620에서, 제어부는 획득된 영상에서 주차선을 검출할 수 있다. 예를 들어, 제어부는 영상 감지 부를 통해 획득된 로우 데이터(raw data) 또는 서라운드 뷰 영상의 노이즈를 제거하기 위하여 필터링(예: gaussian filtering)을 수행하고, 필터링된 영상에서 엣지(edge) 데이터를 추출할 수 있다. 제어부는 영상 내에서 라인(line)(또는 선)이라고 판단되는 지점을 라인 특징점으로 결정할 수 있다. 라인 특징점은 예를 들어영상 내에서 위치 정보(예: x, y좌표) 및 변화량(gradient) 기반의 방향 정보를 포함할 수 있다. 제어부는 결정된 라인 특징점에 대해 라인 피팅(line fitting)을 수행할 수 있다. 예를 들어, 제어부는 결정된 라인 특징점들 중 방향 및 위치가 유사한 특징점들을 클러스터링(clustering)함으로써 라인들을 추출할 수 있다. 추 출된 라인들(즉, 주차선)은 양 끝점(예: x, y좌표) 및 방향 정보를 포함할 수 있다. 동작 1630에서, 제어부는 검출된 주차선의 픽셀 값에 대한 변화량에 기반하여 입구점 후보군을 검출할 수 있다. 예를 들어, 주차선에 대응하는 픽셀 값들 간 변화량은 크지 않은 반면에, 주차선이 끝나는 지점에서의 픽 셀 값은 주차선에 대응하는 픽셀 값과 차이가 클 것이므로, 제어부는 변화량이 큰 지점을 입구점 후보군으 로 결정할 수 있다. 동작 1640에서, 제어부는 딥 러닝에 기반하여 입구점 후보군 중 컨피던스가 높은 입구점을 검출할 수 있다. 예를 들어, 제어부는 입구점 후보군으로 결정된 데이터를 인공 지능 학습부를 통해 학습된 데 이터와 비교하고, 비교 결과 컨피던스가 높은 입구점 후보군을 선택할 수 있다. 동작 1650에서, 제어부는 입구점에 대한 정보를 출력할 수 있다. 입구점에 대한 정보는 예를 들어, 입구점 의 위치, 각도, 방향, 또는 유형 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 제어부는 입구점에 대 한 정보를 자율 주행을 위한 차량 시스템 장치의 다른 구성에 전달할 수 있다. 다른 예를 들어, 제어부 는 사용자가 입구점을 확인할 수 있도록 입구점에 대한 정보를 출력부를 통해 표시할 수 있다. 도 17은 다른 실시예에 따라 입구점에 대한 데이터를 학습하기 위한 차량 시스템 장치의 동작 흐름도를 도시한 다. 도 17을 참조하면, 동작 1710에서, 인공 지능 학습부는 입구점을 포함하는 영상을 수집할 수 있다. 동작 1720에서, 인공 지능 학습부는 딥 러닝 분류기를 통해 수집된 영상을 학습할 수 있다. 딥 러닝 분류 기는 예를 들어, MLP(multilayer perception), SVM(support vector machine), 또는 DNN(deep neural network) 중 적어도 하나의 방식을 이용할 수 있다. 도 18은 입구점에 대한 데이터를 학습하는 동작을 설명한다. 이하 서술되는 입구점에 대한 데이터 학습 방법은 차량 시스템 장치의 인공 지능 학습부를 통해 수행 될 수 도 있고, 차량 시스템 장치와 연계된 별도의 서버를 통해 수행될 수 있다. 이 경우, 차량 시스템 장 치는 서버로부터 학습 결과를 수신함으로써 입구점을 검출할 수 있다. 인공 지능 학습부는 영상 감지부를 통해 입구점을 포함하는 영상들을 획득 및 수집할 수 있다. 인공 지능 학습부는 장소(예: 주차장), 날씨, 및 입구점의 유형을 변경하면서 입구점을 포함하는 영상을 복수 개 획득할 수 있다. 입구점 유형은 도 11에 도시된 예일 수 있으나, 이에 한정되지 않는다. 인공 지능 학습부는 입구점을 포함하는 영상에서 학습에 이용될 로컬 패치 영상을 생성하고, 딥 러닝 분류 기를 통해 로컬 패치 영상을 학습할 수 있다. 딥 러닝 분류기는 다양한 형태의 인공 지능 모델에 기반하여 입구 점에 대한 데이터를 학습할 수 있다. 예를 들어, 딥 러닝 분류기는 CNN 구조를 이용하여 입구점의 유형을 학습 함으로써 영상 인식의 정확도를 높일 수 있다. 딥 러닝 분류기에 의하여 입구점에 대한 데이터가 학습되는 과정 (1810 내지 1870)은 도 10에서 주차 구획에 대한 데이터가 학습되는 과정(1010 내지 1070)과 원리가 유사할 수 있다. 이 경우, 딥 러닝 분류기의 입력은 다양한 유형의 입구점을 나타내는 로컬 패치 영상들과, 각 영상 들이 나타내는 입구점 유형일 수 있다. 또한, 축소된 영상들이 나타내는 특징은 입구점을 구별하기 위한 것으로 써, 입구점의 위치, 방향, 각도, 형태 등을 포함할 수 있다. 딥 러닝 분류기는 학습 결과를 이용하여 입 구점 후보군 중에서 컨피던스가 높은 입구점을 분류할 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9a 도면9b 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18"}
{"patent_id": "10-2020-0160206", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 다양한 실시예들에 따른 차량 시스템 장치의 기능적 블록도이다. 도 2는 다양한 실시예들에 따라 주차 정보를 구성하는 파라미터들을 설명한다. 도 3은 다양한 실시예들에 따라 주차 정보를 생성하기 위한 동작을 설명한다. 도 4는 다양한 실시예들에 따라 주차 정보를 출력하기 위한 차량 시스템 장치의 동작 흐름도를 도시한다. 도 5는 다양한 실시예들에 따라 주차 정보를 생성하기 위한 다른 동작을 설명한다. 도 6은 다양한 실시예들에 따라 주차 정보를 출력하기 위한 차량 시스템 장치의 다른 동작 흐름도를 도시한다. 도 7은 다양한 실시예들에 따라 주차선 후보군을 검출하기 위한 차량 시스템 장치의 동작 흐름도를 도시한다. 도 8은 다양한 실시예들에 따라 딥 러닝 분류기(classifier)에 기반하여 주차 구획을 검출하는 동작을 설명한다. 도 9a는 다양한 실시예들에 따라 다양한 형태의 주차 구획 영상을 획득하는 동작을 설명한다. 도 9b는 다양한 실시예들에 따라 다양한 형태의 주차 구획 영상을 획득하는 동작을 설명한다. 도 10은 다양한 실시예들에 따라 딥 러닝 분류기를 통해 주차 구획 영상을 학습하는 동작을 설명한다. 도 11은 다양한 실시예들에 따른 입구점의 유형을 설명한다. 도 12는 다양한 실시예들에 따라 입구점을 검출하는 동작을 설명한다. 도 13은 다양한 실시예들에 따라 입구점에 대한 정보를 출력하기 위한 차량 시스템 장치의 동작 흐름도를 도시 한다. 도 14는 다양한 실시예들에 따라 입구점을 검출하기 위한 차량 시스템 장치의 동작 흐름도를 도시한다. 도 15는 다양한 실시예들에 따라 입구점을 검출하는 다른 동작을 설명한다. 도 16은 다양한 실시예들에 따라 입구점에 대한 정보를 출력하기 위한 차량 시스템 장치의 다른 동작 흐름도를 도시한다. 도 17은 다양한 실시예들에 따라 입구점에 대한 데이터를 학습하기 위한 차량 시스템 장치의 동작 흐름도를 도 시한다. 도 18은 다양한 실시예들에 따라 입구점에 대한 데이터를 학습하는 동작을 설명한다. 도면의 설명과 관련하여, 동일 또는 유사한 구성요소에 대해서는 동일 또는 유사한 참조 부호가 사용될 수 있다."}
