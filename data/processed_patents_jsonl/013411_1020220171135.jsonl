{"patent_id": "10-2022-0171135", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0086017", "출원번호": "10-2022-0171135", "발명의 명칭": "자세 및 움직임인식을 통한 집중력 측정 시스템 및 방법", "출원인": "김연준", "발명자": "김연준"}}
{"patent_id": "10-2022-0171135", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "자세 및 움직임인식을 통한 집중력 측정 시스템에 있어서, 수업, 스터디를 포함하는 온라인 학습 중 학생의 학습 모습을 촬영한 분석 영상을 생성하여 서버로 전송하는 학생 단말;학생 별 학습 모습을 촬영한 분석 영상에서 영상에 포함된 객체의 자세 및 움직임을 인식을 위해, 학습자의 두눈, 코, 두 어깨, 두 귀를 포함하는 관측 노드의 위치 데이터를 추출하고, 추출된 관측 노드의 위치 데이터를기반으로 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표를 측정하여 측정 결과에 따라학생의 집중도를 평가하는 서버; 를 포함하는 자세 및 움직임 인식을 통한 집중력 측정 시스템."}
{"patent_id": "10-2022-0171135", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 서버; 는학생 단말로부터 학생의 학습 모습을 촬영한 분석 영상을 수집하는 영상 수집 모듈;수집된 분석 영상에서 학생 객체가 포함된 이미지를 순차 추출하고, 추출된 이미지 각각에서 두 눈, 두 귀, 코,목, 두 어깨를 포함하는 관측 노드 각각의 위치 데이터를 추출하는 위치 데이터 추출 모듈; 추출된 관측 노드 각각의 위치 데이터를 기반으로 정면 얼굴의 관측도를 나타낸 정면 얼굴 감지 지표, 움직임정도를 나타낸 신체 움직임 감지 지표 및 척추의 휨 정도를 나타낸 척추 측만 가능성 지표를 측정하는 지표 측정 모듈;측정된 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표와 기 설정된 집중력 평가 기준을 비교하여 학생의 집중도를 평가하는 평가 모듈; 을 포함하는 것을 특징으로 하는 자세 및 움직임 인식을 통한 집중력 측정 시스템."}
{"patent_id": "10-2022-0171135", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 평가 모듈; 은 정면 얼굴 관측도를 나타낸 정면 얼굴 감지 지표에 비례하여 집중도를 평가하고, 움직임 정도를 나타낸 신체 움직임 감지 지표에 반비례하도록 집중도를 평가하고, 척추 휨 정도를 나타낸 척추 측만 가능성 지표에 반비례하도록 집중도를 평가하는 것을 특징으로 하는 자세 및 움직임 인식을 통한 집중력 측정 시스템."}
{"patent_id": "10-2022-0171135", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2항에 있어서, 상기 지표 측정 모듈; 은 관측 노드 각각의 위치데이터 별 이동량을 산출하고 산출된 위치데이터 각각의 이동량을 이용하여 신체 움직임감지 지표를 측정하는 것을 특징으로 하는 자세 및 움직임 인식을 통한 집중력 측정 시스템."}
{"patent_id": "10-2022-0171135", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 평가모듈; 은 OpenPose 신경망, DNN(Deep Neural Network), CNN(Convolutional Neural Network) RNN(Recurrent Neural공개특허 10-2024-0086017-3-Network) 및 BRDNN(Bidirectional Recurrent Deep Neural Network) 중 적어도 하나를 포함하는 딥러닝 뉴럴 네트워크를 테스트 데이터 셋으로 학습시켜 학습 집중도 및 효율성 판단 모델을 구현하는 것을 특징으로 하는 자세 및 움직임 인식을 통한 집중력 측정 시스템."}
{"patent_id": "10-2022-0171135", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서, 상기 지표 측정 모듈은 검출된 학생의 얼굴과 몸통의 위치를 계산하는 1단계, 얼굴과 몸통의 움직임을 계산하는 2단계, 얼굴과 몸통 사이 거리를 산출하는 3단계 및 정상화된 움직임을 계산하는 4단계를 통해 신체 움직임 감지 지표를 산출하는 것을 특징으로 하는 자세 및 움직임 인식을 통한 집중력 측정 시스템."}
{"patent_id": "10-2022-0171135", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 2항에 있어서, 상기 지표 측정 모듈; 은정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표를 인공지능 데이터 셋을 통해 예측한예측 정확도로서 측정하여,관측 노드들의 위치에 따라 정면 얼굴 감지 지표는 정면 얼굴일 확률, 신체 움직임 감지 지표는 움직임 확률,척추 측만 가능성 지표는 척추 측만일 확률을 나타내는 것을 특징으로 하는 자세 및 움직임 인식을 통한 집중력측정 시스템."}
{"patent_id": "10-2022-0171135", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "자세 및 움직임인식을 통한 집중력 측정 방법에 있어서, (A) 학생 단말에서 수업, 스터디를 포함하는 온라인 학습 중 학생의 학습 모습을 촬영한 분석 영상을 생성하여서버로 전송하는 단계;(B) 서버에서 학생 별 학습 모습을 촬영한 분석 영상에서 영상에 포함된 객체의 자세 및 움직임을 인식을 위해,학습자의 두 눈, 코, 두 어깨, 두 귀를 포함하는 관측 노드의 위치 데이터를 추출하고, 추출된 관측 노드의 위치 데이터를 기반으로 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표를 측정하여 측정결과에 따라 학생의 집중도를 평가하는 단계; 를 포함하는 자세 및 움직임 인식을 통한 집중력 측정 방법."}
{"patent_id": "10-2022-0171135", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 (B)의 단계; 는(B-1) 학생 단말로부터 학생의 학습 모습을 촬영한 분석 영상을 수집하는 단계;(B-2) 수집된 분석 영상에서 학생 객체가 포함된 이미지를 순차 추출하고, 추출된 이미지 각각에서 두 눈, 두귀, 코, 목, 두 어깨를 포함하는 관측 노드 각각의 위치 데이터를 추출하는 단계; (B-3) 추출된 관측 노드 각각의 위치 데이터를 기반으로 정면 얼굴의 관측도를 나타낸 정면 얼굴 감지 지표, 움직임 정도를 나타낸 신체 움직임 감지 지표 및 척추의 휨 정도를 나타낸 척추 측만 가능성 지표를 측정하는 단계;(B-4) 측정된 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표와 기 설정된 집중력 평가기준을 비교하여 학생의 집중도를 평가하는 단계; 를 포함하는 것을 특징으로 하는 자세 및 움직임 인식을 통한집중력 측정 방법. 공개특허 10-2024-0086017-4-청구항 10 제8항에 있어서, 상기 (B-3)의 단계; 는 검출된 학생의 얼굴과 몸통의 위치를 계산하는 1단계, 얼굴과 몸통의 움직임을 계산하는 2단계, 얼굴과 몸통 사이 거리를 산출하는 3단계 및 정상화된 움직임을 계산하는 4단계를 통해 신체 움직임 감지 지표를 산출하는 것을 특징으로 하는 자세 및 움직임 인식을 통한 집중력 측정 방법."}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시예에 따른 자세 및 움직임인식을 통한 집중력 측정 시스템 및 방법은 집중력을 평가하는 객관적인 지표를 예 측 정확도 형태로 산출하여, 온라인 학습을 하는 참가자들의 집중도를 평가한다. 실시예에서는 컴퓨터비전 라이 브러리를 이용해 학습자 자세의 위치 데이터를 수집하고, 교육학 이론 데이터에 따라 정면 얼굴 감지 지표, 신체 (뒷면에 계속)"}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공지능 신경망을 이용하여 자세 및 움직임 인식을 통해 학습 집중력 및 효율성을 측정하는 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 명세서에서 달리 표시되지 않는 한, 이 섹션에 설명되는 내용들은 이 출원의 청구항들에 대한 종래 기술이 아니며, 이 섹션에 포함된다고 하여 종래 기술이라고 인정되는 것은 아니다. COVID-19로 인한 팬데믹이 시작되며 가상 회의 플랫폼을 이용한 온라인 회의 및 온라인 수업이 활성화되고 있다. 그러나 갑작스러운 온라인 학습과 업무 플랫폼의 수요 증가로, 온라인을 통한 학습, 업무, 회의 등에 참 여하는 참여자들의 적절한 모니터링 환경은 마련되지 않은 실정이다. 예컨대, 온라인 수업에 참여하는 경우, 온 라인 수업 플랫폼을 켜 놓고 출석은 하지만, 학생은 모니터에 보이지 않게 다른 것을 하는 등, 참석자들의 참석 률과 집중도는 최대 95%까지 떨어지는 것으로 조사되었다. 또한, 온라인 회의나 수업 참여 시 참석자의 자세와 움직임에 따라 학습 효율이 달라지는 것이 모니터링 되었다. 교육학 이론을 통해 학습 중인 사람의 자세나 움직임에 따라 집중도를 파악할 수 있는 것으로 밝혀졌다. 종래에 는 집중력을 예측하거나 평가하기 위해 종래에는 센서를 분석 대상인 사람에게 부착하여 움직임을 감지하거나, 영상 분석을 통해 모션 감지를 수행해 왔다. 하지만, 종래의 자세 및 움직임 분석 방법은 정확성이 떨어지고, 직접 센서를 부착하기 때문에 분석 대상자가 불편감을 일으키는 문제가 있다. 또한, 자세와 움직임 분석 결과를 통해 집중력을 평가하는 지표가 부재하다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 한국 특허출원 제10-2017-0150939호 (2017.11.13) (특허문헌 0002) 2. 한국 특허출원 제10-2021-0049889호 (2021.04.16)"}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예에 따른 자세 및 움직임인식을 통한 집중력 측정 시스템 및 방법은 집중력을 평가하는 객관적인 지표를 예측 정확도 형태로 산출하여, 온라인 학습을 하는 참가자들의 집중도를 평가한다. 실시예에서는 컴퓨터비전 라이브러리를 이용해 학습자 자세의 위치 데이터를 수집하고, 교육학 이론 데이터에 따라 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표의 총 세 가지 측정 항목을 예측 정확도로서 산출한다. 일반적으로 학생들은 수업에 집중할 때 두드러지는 움직임 없이 화면을 바라보며 바르게 앉은 자세를 취하기 때문에, 실시예에서는 학생의 두 눈, 두 귀, 두 어깨, 코, 목, 척추를 포함하는 관측 노드의 위치데이터를 계산 하고, 관측 노드의 위치 데이터를 기반으로 세 가지 측정 지표를 산출하여 집중도를 결정한다. 또한, 실시예에서는 OpenPose 신경망, DNN(Deep Neural Network), CNN(Convolutional Neural Network) RNN(Recurrent Neural Network) 및 BRDNN(Bidirectional Recurrent Deep Neural Network) 중 적어도 하나를 포함하는 딥러닝 뉴럴 네트워크를 테스트 데이터 셋으로 학습시켜 학습 집중도 및 효율성 판단 모델을 구현한다. 또한, 실시예를 통해 학습시간에 따른 학생의 집중력 상태를 그래프 등의 시각적 객체로 변환하여 학생 단말로 제공하고, 집중력 개선을 위한 피드백 정보를 제공할 수 있다."}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예에 따른 자세 및 움직임인식을 통한 집중력 측정 시스템은 수업, 스터디를 포함하는 온라인 학습 중 학생 의 학습 모습을 촬영한 분석 영상을 생성하여 서버로 전송하는 학생 단말; 학생 별 학습 모습을 촬영한 분석 영 상에서 영상에 포함된 객체의 자세 및 움직임을 인식을 위해, 학습자의 두 눈, 코, 두 어깨, 두 귀를 포함하는 관측 노드의 위치 데이터를 추출하고, 추출된 관측 노드의 위치 데이터를 기반으로 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표를 측정하여 측정 결과에 따라 학생의 집중도를 평가하는 서버; 를 포함한다. 바람직하게 서버; 는 학생 단말로부터 학생의 학습 모습을 촬영한 분석 영상을 수집하는 영상 수집 모듈; 수집 된 분석 영상에서 학생 객체가 포함된 이미지를 순차 추출하고, 추출된 이미지 각각에서 두 눈, 두 귀, 코, 목, 두 어깨를 포함하는 관측 노드 각각의 위치 데이터를 추출하는 위치 데이터 추출 모듈; 추출된 관측 노드 각각 의 위치 데이터를 기반으로 정면 얼굴의 관측도를 나타낸 정면 얼굴 감지 지표, 움직임 정도를 나타낸 신체 움 직임 감지 지표 및 척추의 휨 정도를 나타낸 척추 측만 가능성 지표를 측정하는 지표 측정 모듈; 측정된 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표와 기 설정된 집중력 평가 기준을 비교하여 학생의 집중도를 평가하는 평가 모듈; 을 포함한다."}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서와 같은 자세 및 움직임인식을 통한 집중력 측정 시스템 및 방법 은 얼굴 감지, 신체 움직임, 그리고 척추 측만증을 나타내는 세 가지 지표를 예측 정확도 형태로 측정하여, 온라인 수업에 참여하는 학생의 집중도 를 비침습적이며 경제적으로 평가할 수 있도록 한다. 또한, 실시예에서는 인공지능 신경망을 이용한 자동화된 시스템으로 학생의 집중도를 보다 정확하게 평가할 수 있도록 한다. 또한, 학습패턴 자가 진단 자료로 실시예에서 제공하는 집중력 평가 결과를 이용하여 학습 성과를 향상시킬 수 있도록 한다. 또한, 강사, 교수를 포함하는 관리자는 집중도 평가 결과를 통해 학생을 효율적으로 평가할 수 있다. 또한, 학습 시간에 따른 집중력 상태 변화 분석 결과 및 집중력 개선 피드백 정보 제공을 통해 학생의 학습 효 율과 성과를 향상시킬 수 있도록 한다."}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 상기한 효과로 한정되는 것은 아니며, 본 발명의 상세한 설명 또는 특허청구범위에 기재된 발 명의 구성으로부터 추론 가능한 모든 효과를 포함하는 것으로 이해되어야 한다."}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시 예들은 본 발명의 개시가 완전하도록 하고, 본 발명이"}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 도면부호는 동일 구성 요소를 지칭한다. 본 발명의 실시 예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명의 실시 예에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 도 1은 실시예에 따른 자세 및 움직임인식을 통한 집중력 측정 시스템 구성을 나타낸 도면이다. 도 1을 참조하면, 실시예에 따른 자세 및 움직임 인식을 통한 집중력 측정 시스템은 학생 단말, 서버 및 관리자 단말을 포함하여 구성될 수 있다. 학생 단말은 수업, 스터디를 포함하는 온라인 학습 중 학생의 학습 모습을 촬영한 분석 영상을 생성하여 서버로 전송한다. 서버는 학생 별 학습 모습을 촬영한 분석 영상에서 영상에 포함된 객체의 자세 및 움직임을 인식하고, 학 습자 자세 분석을 위한 관측 노드의 위치 데이터를 수집하고, 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표를 측정하여 측정 결과에 따라 학생의 집중도를 평가한다. 실시예에서 관측 노드는 두 눈, 두 귀, 두 어깨, 코, 목의 8개 지점을 포함할 수 있다. 관리자 단말은 서버로부터 학생 별 집중도 평가 결과를 수신하여 학생 평가에 반영할 수 있도록 한다. 또한, 실시예에서 서버는 학생 별 집중도 평가 결과에 따라 집중도 개선 피드백 정보를 생성하여 학생 단 말로 전송할 수 있다. 예컨대, 서버는 학습 시간에 따라 집중도 평가를 수행하여 집중도가 일정 수준으로 떨어진 경우, 학생 및 관리자에게 이를 알림 하거나 학생의 학습 시간에 따른 움직임 특성 파악 결과에 따라 집 중력 개선 피드백을 생성하여 학생 단말로 제공할 수 있다. 여기서, 적어도 하나의 단말(100, 300)은, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크 톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 이때, 적어도 하나의 단말(100, 300)은, 네트워크를 통해 원 격지의 서버나 단말에 접속할 수 있는 단말로 구현될 수 있다. 적어도 하나의 단말(100,300)은, 예를 들어, 휴 대성과 이동성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단 말, 스마트폰(smartphone), 스마트 패드(smartpad), 태블릿 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 실시예에 따른 자세 및 움직임인식을 통한 집중력 측정 시스템 및 방법은 집중력을 평가하는 객관적인 지표를 예측 정확도 형태로 산출하여, 온라인 학습을 하는 참가자들의 집중도를 평가한다. 실시예에서는 컴퓨터비전 라 이브러리를 이용해 학습자 자세의 위치 데이터를 수집하고, 교육학 이론 데이터에 따라 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표의 총 세 가지 측정 항목을 예측 정확도로서 산출한다. 일반적으로 학생들은 수업에 집중할 때 두드러지는 움직임 없이 화면을 바라보며 바르게 앉은 자세를 취하기 때문에, 실시예에서는 학생의 두 눈, 두 귀, 두 어깨, 코, 목, 척추를 포함하는 관측 노드의 위치데이터를 계산 하고, 관측 노드의 위치 데이터를 기반으로 세 가지 측정 지표를 산출하여 집중도를 결정한다. 또한, 실시예에 서는 OpenPose 신경망, DNN(Deep Neural Network), CNN(Convolutional Neural Network) RNN(Recurrent Neural Network) 및 BRDNN(Bidirectional Recurrent Deep Neural Network) 중 적어도 하나를 포함하는 딥러닝 뉴럴 네 트워크를 테스트 데이터 셋으로 학습시켜 학습 집중도 및 효율성 판단 모델을 구현한다. 또한, 실시예를 통해 학습시간에 따른 학생의 집중력 상태를 그래프 등의 시각적 객체로 변환하여 학생 단말로 제공하고, 집중력 개 선을 위한 피드백 정보를 제공할 수 있다. 도 2는 실시예에 따른 서버의 데이터 처리 구성을 나타낸 도면이다. 도 2를 참조하면, 실시예에 따른 서버는 영상 수집 모듈, 위치 데이터 추출 모듈, 지표 측정 모 듈, 평가 모듈 및 집중력 개선 피드백 생성모듈을 포함하여 구성될 수 있다. 본 명세서에서 사 용되는 '모듈' 이라는 용어는 용어가 사용된 문맥에 따라서, 소프트웨어, 하드웨어 또는 그 조합을 포함할 수 있는 것으로 해석되어야 한다. 예를 들어, 소프트웨어는 기계어, 펌웨어(firmware), 임베디드코드(embedded code), 및 애플리케이션 소프트웨어일 수 있다. 또 다른 예로, 하드웨어는 회로, 프로세서, 컴퓨터, 집적 회로, 집적 회로 코어, 센서, 멤스(MEMS; Micro-Electro-Mechanical System), 수동 디바이스, 또는 그 조합일 수 있 다. 영상 수집 모듈은 학생 단말로부터 학생의 학습 모습을 촬영한 분석 영상을 수집한다. 위치 데이터 추출 모듈은 수집된 분석 영상에서 학생 객체가 포함된 이미지를 순차 추출하고, 추출된 이미 지 각각에서 두 눈, 두 귀, 코, 목, 두어깨를 포함하는 관측 노드 각각의 위치 데이터를 추출한다. 도 3은 18개 의 신체 관절과 17개의 라인이 있는 COCO 데이터 세트를 나타낸 도면이다. 실시예에서는 도 3에 도시된 바와 같 이, 전신 추정을 위한 18개의 핵심 포인트가 있는 데이터 세트(예컨대, COCO 데이터 세트)를 통해 학생 객체가 포함된 영상 및 이미지에서 두 눈, 두 귀, 코, 목, 두어깨를 포함하는 8개의 관측 노드 각각의 위치 데이터를 추출할 수 있다. 실시예에서는 테스트를 위해 COCO 키포인트 데이터 세트의 하위집합을 자세 인식 추정에 사용 한다. COCO 데이터 셋은 전신을 추정하는 것을 목표로 하므로, 실시예에서는 앉은 자세 분석을 위해, 두 눈, 두 귀, 코, 목, 두 어깨를 포함하는 8개의 관측 노드를 선택한다. 지표 측정 모듈은 추출된 관측 노드 각각의 위치 데이터를 기반으로 정면 얼굴의 관측도를 나타낸 정면 얼 굴 감지 지표, 움직임 정도를 나타낸 신체 움직임 감지 지표 및 척추의 휨 정도를 나타낸 척추 측만 가능성 지 표를 측정한다. 실시예에서 측정되는 각각의 지표는 예측 정확도의 개념으로, 관측 노드들의 위치에 따라 정면 얼굴일 확률, 움직임이 발생한 확률과 척추 측만일 확률을 인공지능 데이터 셋을 통해 예측한 것이다. 실시예에서 지표 측정 모듈은 정면 얼굴 감지 지표를 8개의 관측 노드 중 얼굴에 해당하는 5가지 관측 노 드(눈2개, 귀2개, 코1개)를 위치 데이터를 이용하여, 수학식 1에 따른 평균값 공식을 통해 정면 얼굴 감지 (Facial Detection) 지표를 측정한다. 수학식 1"}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "실시예에서 지표 측정 모듈은 학생 몸의 움직임 정도를 정량적으로 변환한 신체 움직임 감지 지표를 측정 한다. 실시예에서는 측정된 분석 노드 별 위치 데이터에서 이동량을 계산하여 신체 움직임 감지 지표를 산출할 수 있다. 신체 움직임 감지 지표 산출을 위한 첫 단계에서는 수학식 2를 통해 검출된 학생의 얼굴과 몸통의 위치를 계산 한다. 수학식 2"}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 2에서 Z는 x 또는 y좌표, 타겟은 얼굴 또는 몸통, N은 5또는 3, 타겟 노드들은 관측 노드로서, 5인 경우, 왼쪽 눈, 오른쪽 눈, 왼쪽 귀, 오른쪽 귀, 코, 3인 경우, 왼쪽 어깨, 오른쪽 어깨, 목이다. 신체 움직임 감지 지표 산출을 위한 두 번째 단계에서는 수학식 3 및 수학식 4를 통해 얼굴과 몸통의 움직임을 계산한다. 수학식3"}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 4"}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "신체 움직임 감지 지표 산출을 위한 세 번째 단계에서는 수학식 5를 통해, 얼굴과 몸통 사이 거리를 산출한다. 수학식 5"}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "신체 움직임 감지 지표 산출을 위한 네 번째 단계에서는 수학식 6을 통해, 표준화된 움직임을 계산한다. 수학식 6"}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "실시예에서 지표 측정 모듈은 척추의 휨 정도를 나타내는 척추 측만증 가능성 지표를 수학식 7을 통해 산 출할 수 있다. 수학식 7"}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "평가모듈은 측정된 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표를 이용하여 학 생의 집중도를 평가한다. 실시예에서 평가 모듈은 OpenPose 신경망, DNN(Deep Neural Network), CNN(Convolutional Neural Network) RNN(Recurrent Neural Network) 및 BRDNN(Bidirectional Recurrent Deep Neural Network) 중 적어도 하나를 포함하는 딥러닝 뉴럴 네트워크를 테스트 데이터 셋으로 학습시켜 학습 집중 도 및 효율성 판단 모델을 구현할 수 있다. 또한, 실시예에서 평가 모듈은 정면 얼굴 관측도를 나타낸 정 면 얼굴 감지 지표에 비례하여 집중도를 평가할 수 있다. 또한, 움직임 정도를 나타낸 신체 움직임 감지 지표에 반비례하도록 집중도를 평가하고, 척추 휨 정도를 나타낸 척추 측만 가능성 지표에 반비례하도록 집중도를 평가 할 수 있다. 실시예에서 평가 모듈은 예측 정확도 개념인 각각의 평가 지표(정면 얼굴 감지 지표, 신체 움직임 감지 지 표 및 척추 측만 가능성 지표)를 수집하고, 미리 설정된 집중도 평가기준을 설정하여, 수집된 평가 지표와 평가 기준을 비교하여 온라인에서 학습 중인 학생이 얼마나 집중하고 있는지 파악할 수 있다. 실시예에서 미리 설정 된 집중도 평가 기준은 집중 레벨에 따른 평가 지표 각각의 예측 정확도 수치 및 3개의 예측 정확도 수치의 평 균값을 포함할 수 있다. 실시예에서는 집중 레벨을 하, 중, 상, 최상으로 분류하고, 각 레벨에 해당하는 평가 지표 각각의 범위 및 평균값 수치를 미리 설정하고, 산출된 지표 각각의 수치와 3개의 수치 평균값이 포함된 범 위에 따라 집중 레벨을 파악할 수 있도록 한다. 실시예에서 집중 레벨이 분류되는 임계치는 집중 레벨의 수와 종류에 따라 조정될 수 있고, 집중력이 상위 레벨일수록 임계치가 커질 수 있다. 집중력 개선 피드백 생성 모듈은 집중력 평가 결과 및 학생 별 집중도 개선 피드백 정보를 생성한다. 집중 력 개선 피드백 생성 모듈은 학생 각각의 집중력 평가 결과를 시간에 따라 분석한다. 예컨대, 집중력 개선 피드백 생성 모듈은 집중도 평가 레벨이 일정 수준 이상 변화되는 시점, 측정된 정면 얼굴 감지 지표, 신 체 움직임 감지 지표 및 척추 측만 가능성 지표 중 적어도 하나가 일정 수준 이상 변화한 시점을 포함하는 이상 시점을 추출하고, 이상 시점에서의 이벤트 및 이상시점과 전체 학습 시간과의 상관관계를 파악하여, 해당 학생 단말로 제공할 수 있다. 또한, 실시예에서는 집중력 평가 결과 분석에 따라 이상 시점의 패턴 및 3개의 지표 패턴을 파악하여, 이상 시 점의 패턴을 없앨 수 있도록 하는 집중력 개선 피드백 정보를 생성할 수 있다, 예컨대, 학습시간이 60분 경과하 면, 집중도 레벨이 일정 수준이상 하락하는 패턴을 보이는 학생에게는 학습 시간 경과 시간이 60분이되기 전에 '스트레칭 수행 요망' 등의 피드백 메시지를 생성하여 학생 단말로 전송한다. 해당 학생은 피드백 메시지를 확 인 후 적용하여 집중력이 떨어지기 전에 스스로 환기함으로써, 일정 수준 이상의 집중력을 장시간 유지할 수 있 도록 한다. 도 4는 실시예에서 이용하는 부분 데이터 세트를 나타낸 도면이다. 도 4에 도시된 부분 데이터 세트는 앉은 자 세 추정을 위해 실시예에서 사용하는 관측 노드들이다. 도 4에 도시된 바와 같이, 실시예에서는 오픈 포즈를 사 용한 자세 예측과 분석을 위해, 왼쪽 눈, 오른쪽 코, 왼쪽 귀, 오른쪽 귀, 목, 왼쪽 어깨, 오른쪽 어깨에 해당 하는 8개의 관측 노드 위치를 추정한다. 도 4에 도시된 적색 박스의 수치는 각 관측 노드의 예측 정확도이다. 도 4의 a는 집중도가 일정 수준 이상의 고집중 상태 에서의 관측노드 예측 정확도를 나타낸 도면이고, 도 4의 b 는 집중도가 일정 수준 미만의 저 집중 상태에서 관측 노드 예측 정확도를 나타낸 도면이다. 실시예에 따른 예 측 정확도는 측정된 3가지 항목의 평가기준을 통해 집중도를 평가한 값으로 집중을 잘하고 있는지 여부를 나타 낸다. 도 5는 예측 정확도를 나타내는 실시예에서 측정된 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표를 측정 데이터를 나타낸 표이다. 도 5의 표에 기록된 데이터는, 프레임 수준의 주요 매개변수 통계 로서, 8개의 관측 노드에서 측정된 값은 0과 1 사이인 예측 정확도를 나타낸다. 각 지표들은 평균 및 표준 편차 로 표시될 수 있다. 세 가지 측정항목은 이진 범주형 변수이며 개수 및 백분율로 표시될 수 있다. 도 6은 실시예에 따른 자세 및 움직임 인식을 통한 집중력 측정 시스템의 DNN(Deep Neural Network) 구조를 나 타낸 도면이다. 도 6을 참조하면, 학생의 학습 모습이 녹화된 분석 영상의 캡쳐는 1-b의 1단계 입력값이다. 각 단계는 분기 1의 신체 부위 감지에 대한 신뢰도 맵을 예측하는 2개 분기 CNN과 분기 2의 부품 연관에 대한 부품친화도 필드로 구성될 수 있다. 테스트에서 가장 정제된 결과는 1-d의 더 높은 정확도를 위해 크기가 조정되고 1-e에 표시된 대로 모두 함께 배치하기 위해 이분(bipartite) 매칭 세트를 수행한다. 도 7은 실시예에서 집중도 평가 결과를 시간에 따라 분석한 그래프를 나타낸 도면이다. 도 7을 참조하면, 실시 예에 따른 집중력 개선 피드백 생성 모듈은 사용자로 부터 특정된 얼굴 감지 지표, 움직임지표 및 척추 측만 가 능성 지표를 시간-지표 그래프로 변환하여 각 그래프에서 나타내는 이상지점을 파악할 수 있다. 도 7에 도시된 그래프 각각의 적색 가로 점선은 집중도 평가 레벨이 변화하는 임계값을 이다. 도 7의 a, b, c는 집중도 레벨이 상인 지표의 그래프이고, d, e, f는 집중도 레벨이 하인 지표의 그래프이다. 도 8은 서로 다른 임계값에서 집중도 상 레벨과 집중도 하 레벨의 효율성을 비교하는 집계 메트릭의 카이 제곱 에 대한 히트맵이다. 실시예에 따른 집중도 개선 피드백 생성 모듈은 도 8에 도시된 바와 같이, 측정된 집중도 평가 결과와 지표를 그래프, 히트맵 등 다양한 시각적 자료로 변환하여 학생 단말로 제공할 수 있다. 학생은 단 말을 통해 자신의 집중도 측정 결과를 도 8에 도시된 시각적 자료와 함께 확인할 수 있고, 실시예에서는 전송된 시각적 객체의 분석 결과 또한 제공할 수 있다. 이하에서는 자세 및 움직임인식을 통한 집중력 측정 방법에 대해서 차례로 설명한다. 실시예에 따른 자세 및 움 직임인식을 통한 집중력 측정 방법의 작용(기능)은 위조품 탐지 시스템의 기능과 본질적으로 같은 것이므로 도 1 내지 도 8과 중복되는 설명은 생략하도록 한다. 도 9는 실시예에 따른 자세 및 움직임인식을 통한 집중력 측정을 위한 데이터 처리 흐름을 나타낸 도면이다. 도 9를 참조하면, S100 단계에서는 영상수집 모듈에서 학생 단말로부터 학생의 학습 모습을 촬영한 분석 영상을 수집한다. S200 단계에서는 위치 데이터 추출 모듈에서 수집된 분석 영상에서 학생 객체가 포함된 이미지를 순차 추출 하고, 추출된 이미지 각각에서 두 눈, 두 귀, 코, 목, 두어깨를 포함하는 관측 노드 각각의 위치 데이터를 추출 한다. S300 단계에서는 추출된 관측 노드 각각의 위치 데이터를 기반으로 정면 얼굴의 관측도를 나타낸 정면 얼굴 감 지 지표, 움직임 정도를 나타낸 신체 움직임 감지 지표 및 척추의 휨 정도를 나타낸 척추 측만 가능성 지표를 측정한다. S300 단계에서는 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표를 인공지능 데이터 셋을 통해 예측한 예측 정확도로서 측정하여, 관측 노드들의 위치에 따라 정면 얼굴 감지 지표는 정면 얼굴일 확률, 신체 움직임 감지 지표는 움직임 확률, 척추 측만 가능성 지표는 척추 측만일 확률을 나타낼 수 있도록 한다. 실시예에서는 관측 노드 각각의 위치데이터 별 이동량을 산출하고 산출된 위치데이터 각각의 이동 량을 이용하여 신체 움직임 감지 지표를 측정할 수 있다. S300 단계에서는 검출된 학생의 얼굴과 몸통의 위치를 계산하는 1단계, 얼굴과 몸통의 움직임을 계산하는 2단계, 얼굴과 몸통 사이 거리를 산출하는 3단계 및 정상화된 움직임을 계산하는 4단계를 통해 신체 움직임 감 지 지표를 산출할 수 있다. S400 단계에서는 평가 모듈에서 측정된 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표 를 이용하여 학생의 집중도를 평가한다. 실시예에서는 정면 얼굴 관측도를 나타낸 정면 얼굴 감지 지표에 비례 하여 집중도를 평가하고, 움직임 정도를 나타낸 신체 움직임 감지 지표에 반비례하도록 집중도를 평가하고, 척 추 휨 정도를 나타낸 척추 측만 가능성 지표에 반비례하도록 집중도를 평가할 수 있다. 또한, S400 단계에서는 OpenPose 신경망, DNN(Deep Neural Network), CNN(Convolutional Neural Network) RNN(Recurrent Neural Network) 및 BRDNN(Bidirectional Recurrent Deep Neural Network) 중 적어도 하나를 포함하는 딥러닝 뉴럴 네 트워크를 테스트 데이터 셋으로 학습시켜 학습 집중도 및 효율성 판단 모델을 구현한다. S500 단계에서는 집중력 평가 결과를 분석하여 집중력 개선 피드백 정보를 생성한다. S500 단계에서는 집중력 평가 결과 및 학생 별 집중도 개선 피드백 정보를 생성한다. 실시예에서는 학생 각각의 집중력 평가 결과를 시 간에 따라 분석한다. 예컨대, 집중도 평가 레벨이 일정 수준 이상 변화되는 시점, 측정된 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표 중 적어도 하나가 일정 수준 이상 변화한 시점을 포함하는 이 상 시점을 추출하고, 이상 시점에서의 이벤트 및 이상시점과 전체 학습 시간과의 상관관계를 파악하여, 해당 학 생 단말로 제공할 수 있다. 또한, 실시예에서는 집중력 평가 결과 분석에 따라 이상 시점의 패턴 및 3개의 지표 패턴을 파악하여, 이상 시 점의 패턴을 없앨 수 있도록 하는 집중력 개선 피드백 정보를 생성할 수 있다, 예컨대, 학습시간이 60분 경과하면, 집중도 레벨이 일정 수준이상 하락하는 패턴을 보이는 학생에게는 학습 시간 경과 시간이 60분이되기 전에 '스트레칭 수행 요망' 등의 피드백 메시지를 생성하여 학생 단말로 전송한다. 해당 학생은 피드백 메시지를 확 인 후 적용하여 집중력이 떨어지기 전에 스스로 환기함으로써, 일정 수준 이상의 집중력을 장시간 유지할 수 있 도록 한다. 이상에서와 같은 자세 및 움직임인식을 통한 집중력 측정 시스템 및 방법 은 얼굴 감지, 신체 움직임, 그리고 척추 측만증을 나타내는 세 가지 지표를 예측 정확도 형태로 측정하여, 온라인 수업에 참여하는 학생의 집중도 를 비침습적이며 경제적으로 평가할 수 있도록 한다. 또한, 실시예에서는 인공지능 신경망을 이용한 자동화된 시스템으로 학생의 집중도를 보다 정확하게 평가할 수 있도록 한다. 또한, 학습패턴 자가 진단 자료로 실시예에서 제공하는 집중력 평가 결과를 이용하여 학습 성과 를 향상시킬 수 있도록 한다. 아울러, 강사, 교수를 포함하는 관리자는 집중도 평가 결과를 통해 학생을 효율적 으로 평가할 수 있도록 한다."}
{"patent_id": "10-2022-0171135", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "개시된 내용은 예시에 불과하며, 특허청구범위에서 청구하는 청구의 요지를 벗어나지 않고 당해 기술분야에서 통상의 지식을 가진 자에 의하여 다양하게 변경 실시될 수 있으므로, 개시된 내용의 보호범위는 상술한 특정의 실시예에 한정되지 않는다."}
{"patent_id": "10-2022-0171135", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 자세 및 움직임인식을 통한 집중력 측정 시스템 구성을 나타낸 도면 도 2는 실시예에 따른 서버의 데이터 처리 구성을 나타낸 도면도 3은 18개의 신체 관절과 17개의 라인이 있는 COCO 데이터 세트를 나타낸 도면 도 4는 실시예에서 이용하는 부분 데이터 세트를 나타낸 도면 도 5는 예측 정확도를 나타내는 실시예에서 측정된 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표를 측정 데이터를 나타낸 표 도 6은 실시예에 따른 자세 및 움직임 인식을 통한 집중력 측정 시스템의 DNN(Deep Neural Network) 구조를 나 타낸 도면 도 7은 실시예에서 집중도 평가 결과를 시간에 따라 분석한 그래프를 나타낸 도면 도 8은 서로 다른 임계값에서 집중도 상 레벨과 집중도 하 레벨의 효율성을 비교하는 집계 메트릭의 카이 제곱 에 대한 히트맵 도 9는 실시예에 따른 자세 및 움직임인식을 통한 집중력 측정을 위한 데이터 처리 흐름을 나타낸 도면"}
