{"patent_id": "10-2023-0054346", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0157470", "출원번호": "10-2023-0054346", "발명의 명칭": "인공지능을 이용한 방향 추정을 위한 방법 및 그 장치", "출원인": "한양대학교 산학협력단", "발명자": "장준혁"}}
{"patent_id": "10-2023-0054346", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서,제1 초기 파라미터 및 제1 종료 파라미터를 결정하는 단계;음성 데이터를 입력 정보로 하여 상기 제1 초기 파라미터 및 상기 제1 종료 파라미터를 기반으로 기 학습된 제1인공지능 모듈에서 제1 데이터를 출력하는 단계;제2 초기 파라미터 및 제2 종료 파라미터를 결정하는 단계;상기 제1 데이터를 입력 정보로 하여 상기 제2 초기 파라미터 및 상기 제2 종료 파라미터를 기반으로 기 학습된제2 인공지능 모듈에서 제2 데이터를 출력하는 단계; 및상기 제2 데이터를 기반으로 상기 음성 데이터에서 음성 방향을 추정하는 단계를 포함하는 방법."}
{"patent_id": "10-2023-0054346", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 파라미터는 상기 음성 방향의 각도를 중심으로 하는 소정의 범위를 나타내는 파라미터인 방법."}
{"patent_id": "10-2023-0054346", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제1 종료 파라미터 및 상기 제2 종료 파라미터는 동일한 값을 가지는 방법."}
{"patent_id": "10-2023-0054346", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제2 초기 파라미터는 상기 제1 초기 파라미터보다 크기가 작은 값을 가지는 방법."}
{"patent_id": "10-2023-0054346", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 제1 인공지능 모듈은:파라미터 값을 상기 제1 초기 파라미터의 값으로 결정하는 단계;상기 제1 초기 파라미터를 기반으로 상기 음성 데이터를 연산하는 단계;제1 감소 값을 결정하는 단계; 및상기 파라미터 값이 상기 제1 종료 파라미터의 값이 될 때까지 상기 제1 감소 값만큼 감소시키며 상기 음성 데이터를 반복해서 연산하는 단계를 기반으로 학습되는 방법."}
{"patent_id": "10-2023-0054346", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2024-0157470-3-제1항에 있어서,상기 기 학습된 제1 인공지능 모듈에서, 상기 제1 데이터와 상기 제1 초기 파라미터의 값에 상응하는 특정 데이터 값을 비교하여 제1 손실을 계산하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2023-0054346", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 기 학습된 제2 인공지능 모듈에서, 상기 제1 손실 및 상기 제1 데이터를 입력 정보로 하여 출력된 제3 데이터와 상기 제2 초기 파라미터의 값에 상응하는 특정 데이터 값을 비교하여 제2 손실을 계산하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2023-0054346", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "전자 장치에 있어서,메모리;모뎀; 및상기 모뎀 및 상기 메모리에 연결되는 프로세서를 포함하고,상기 프로세서는:제1 초기 파라미터 및 제1 종료 파라미터를 결정하고,음성 데이터를 입력 정보로 하여 상기 제1 초기 파라미터 및 상기 제1 종료 파라미터를 기반으로 기 학습된 제1인공지능 모듈에서 제1 데이터를 출력하고,제2 초기 파라미터 및 제2 종료 파라미터를 결정하고,상기 제1 데이터를 입력 정보로 하여 상기 제2 초기 파라미터 및 상기 제2 종료 파라미터를 기반으로 기 학습된제2 인공지능 모듈에서 제2 데이터를 출력하고, 그리고상기 제2 데이터를 기반으로 상기 음성 데이터에서 음성 방향을 추정하도록 구성되는 전자 장치."}
{"patent_id": "10-2023-0054346", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 프로세서는:상기 파라미터는 상기 음성 방향의 각도를 중심으로 하는 소정의 범위를 나타내는 파라미터인 전자 장치."}
{"patent_id": "10-2023-0054346", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 제1 종료 파라미터 및 상기 제2 종료 파라미터는 동일한 값을 가지는 전자 장치."}
{"patent_id": "10-2023-0054346", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 제2 초기 파라미터는 상기 제1 초기 파라미터보다 크기가 작은 값을 가지는 전자 장치.공개특허 10-2024-0157470-4-청구항 12 제8항에 있어서,상기 기 학습된 제1 인공지능 모듈은:파라미터 값을 제3 초기 파라미터 값으로 결정하는 단계;상기 제3 초기 파라미터를 기반으로 음성 데이터를 연산하는 단계;제1 감소 값을 결정하는 단계; 및상기 파라미터 값이 제3 종료 파라미터 값이 될 때까지 상기 제1 감소 값만큼 감소시키며 상기 음성 데이터를반복해서 연산하는 단계를 기반으로 학습되는 전자 장치."}
{"patent_id": "10-2023-0054346", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서, 상기 프로세서는:상기 기 학습된 제1 인공지능 모듈에서, 상기 제1 데이터와 상기 제1 초기 파라미터의 값에 상응하는 특정 데이터 값을 비교하여 제1 손실을 계산하도록 더 구성되는 전자 장치."}
{"patent_id": "10-2023-0054346", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 프로세서는:상기 기 학습된 제2 인공지능 모듈에서, 상기 제1 손실 및 상기 제1 데이터를 입력 정보로 하여 출력된 제3 데이터와 상기 제2 초기 파라미터의 값에 상응하는 특정 데이터 값을 비교하여 제2 손실을 계산하도록 더 구성되는 전자 장치."}
{"patent_id": "10-2023-0054346", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "프로세서(processor)에 의해 실행 가능한 인공지능 알고리즘을 통해 방향 추정 방법을 수행하기 위한 매체에 저장된 프로그램으로서,제1 초기 파라미터 및 제1 종료 파라미터를 결정하는 단계;음성 데이터를 입력 정보로 하여 상기 제1 초기 파라미터 및 상기 제1 종료 파라미터를 기반으로 기 학습된 제1인공지능 모듈에서 제1 데이터를 출력하는 단계;제2 초기 파라미터 및 제2 종료 파라미터를 결정하는 단계;상기 제1 데이터를 입력 정보로 하여 상기 제2 초기 파라미터 및 상기 제2 종료 파라미터를 기반으로 기 학습된제2 인공지능 모듈에서 제2 데이터를 출력하는 단계; 및상기 제2 데이터를 기반으로 상기 음성 데이터에서 음성 방향을 추정하는 단계를 수행하는 프로그램."}
{"patent_id": "10-2023-0054346", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서, 제1 초기 파라미터 및 제1 종료 파라미터를 결정하는 단계; 음성 데이터를 입력 정보로 하여 상기 제1 초기 파라미터 및 상기 제1 종료 파라미터를 기반으로 기 학습된 제1 인공지능 모듈에서 제1 데이터를 출력하는 단계; 제2 초기 파라미터 및 제2 종료 파라미터를 결정하는 단계; 상기 제1 데이터를 입력 정보로 하여 상기 제2 초기 파라미터 및 상기 제2 종료 파라미터를 기반으로 기 학습된 제2 인공지능 모듈에서 제2 데이터를 출력하는 단계; 및 상기 제2 데이터를 기반으로 상기 음성 데이터에서 음성 방향을 추정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0054346", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공지능을 이용하여 방향을 추정하기 위한 방법 및 그 장치 나타낸다. 구체적으로, 음성 방향 추정 기술을 활용하여 인공지능을 학습시켜 화자의 방향을 추정하는 방법을 나타낸다."}
{"patent_id": "10-2023-0054346", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 개시는 음성 신호에 대하여 음성이 수신되는 방향을 추정하는 장치 및 방법에 관한 것이다. 최근 음성 신호 를 수집하고 데이터로 가공하는 음성 인식 기술이 대두되고 있다. 음성 인식 기술은 프로그램을 통해 사람의 음 성을 텍스트 형식으로 처리할 수 있도록 하는 기술을 나타낸다. 음성 인식 프로그램은 화자의 문법, 구문, 구조 등을 이해하고 처리할 수 있다. 음성 인식 프로그램의 기능을 향상시키기 위하여 음성 신호를 수신하는 효율적 인 방식이 요구되었으며, 음성의 방향을 특정하여 해당 방향에서의 신호를 집중하여 수신하는 방식 등이 제안되 었다. 음성 방향 추정 기술에는 다양한 종류가 존재하지만 특히 인공지능 기반의 음성 방향 추정 시스템이 주목받고 있다. 다만, 인공지능 기반의 음성 방향 추정 시스템에 있어서, 기존에는 hard labeling 방식 및 soft labeling 방식을 이용하여 인공지능을 학습시켰으나 파라미터를 휴리스틱(heuristic)하게 고정하여 학습하였기 때문에 그 효과가 제한적이라는 한계가 있었다. 따라서, 딥러닝 모델에 대한 다양한 접근을 통해 인공지능이 좀 더 체계적 이고 효율적으로 학습될 수 있도록 하는 방식이 요구되고 있다."}
{"patent_id": "10-2023-0054346", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에서는 커리큘럼 학습 방식을 이용하여 음성 방향 추정 기술을 향상시키는 방법 및 그 장치를 제공하고 자 한다. 본 개시에서는 커리큘럼 학습 방식에 deep supervision 방식을 결합하여 음성 방향 추정 기능을 향상시키는 방 법을 제공하고자 한다."}
{"patent_id": "10-2023-0054346", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서, 제1 초기 파라미터 및 제1 종료 파라미터를 결정하는 단계; 음성 데이터를 입력 정보로 하여 상기 제1 초기 파라미터 및 상기 제1 종료 파라미터를 기반으로 기 학습된 제1 인공지능 모듈에서 제1 데이터를 출력하는 단계; 제2 초기 파라미터 및 제2 종료 파라미터를 결정하는 단계; 상기 제1 데이터를 입력 정보로 하여 상기 제2 초기 파라미터 및 상기 제2 종료 파라미터를 기반으로 기 학습된 제2 인공지능 모듈에서 제2 데이터를 출력하는 단계; 및 상기 제2 데 이터를 기반으로 상기 음성 데이터에서 음성 방향을 추정하는 단계를 포함할 수 있다. 일 실시예에서, 상기 파라미터는 상기 음성 방향의 각도를 중심으로 하는 소정의 범위를 나타내는 파라미터일 수 있다. 일 실시예에서, 상기 제1 종료 파라미터 및 상기 제2 종료 파라미터는 동일한 값을 가질 수 있다. 일 실시예에서, 상기 제2 초기 파라미터는 상기 제1 초기 파라미터보다 크기가 작은 값을 가질 수 있다. 일 실시예에서, 상기 제1 인공지능 모듈은: 파라미터 값을 상기 제1 초기 파라미터 값으로 결정하는 단계; 상기 제1 초기 파라미터를 기반으로 상기 음성 데이터를 연산하는 단계; 제1 감소 값을 결정하는 단계; 및 상기 파라 미터 값이 상기 제1 종료 파라미터 값이 될 때까지 상기 제1 감소 값만큼 감소시키며 상기 음성 데이터를 반복 해서 연산하는 단계를 기반으로 학습될 수 있다. 일 실시예에서, 상기 기 학습된 제1 인공지능 모듈에서, 상기 제1 데이터와 상기 제1 초기 파라미터 값에 상응 하는 특정 데이터 값을 비교하여 제1 손실을 계산하는 단계를 더 포함할 수 있다. 일 실시예에서, 상기 기 학습된 제2 인공지능 모듈에서, 상기 제1 손실 및 상기 제1 데이터를 입력 정보로 하여 출력된 제3 데이터와 상기 제2 초기 파라미터 값에 상응하는 특정 데이터 값을 비교하여 제2 손실을 계산하는 단계를 더 포함할 수 있다. 본 발명의 실시 예에 따른 전자 장치에 있어서, 메모리; 모뎀; 및 상기 모뎀 및 상기 메모리에 연결되는 프로세 서를 포함하고, 상기 프로세서는: 제1 초기 파라미터 및 제1 종료 파라미터를 결정하고, 음성 데이터를 입력 정보로 하여 상기 제1 초기 파라미터 및 상기 제1 종료 파라미터를 기반으로 기 학습된 제1 인공지능 모듈에서 제 1 데이터를 출력하고, 제2 초기 파라미터 및 제2 종료 파라미터를 결정하고, 상기 제1 데이터를 입력 정보로 하 여 상기 제2 초기 파라미터 및 상기 제2 종료 파라미터를 기반으로 기 학습된 제2 인공지능 모듈에서 제2 데이 터를 출력하고, 그리고 상기 제2 데이터를 기반으로 상기 음성 데이터에서 음성 방향을 추정하도록 구성될 수 있다. 본 발명의 실시 예에 따른 프로세서(processor)에 의해 실행 가능한 인공지능 알고리즘을 통해 방향 추정 방법 을 수행하기 위한 매체에 저장된 프로그램으로서, 제1 초기 파라미터 및 제1 종료 파라미터를 결정하는 단계; 음성 데이터를 입력 정보로 하여 상기 제1 초기 파라미터 및 상기 제1 종료 파라미터를 기반으로 기 학습된 제1 인공지능 모듈에서 제1 데이터를 출력하는 단계; 제2 초기 파라미터 및 제2 종료 파라미터를 결정하는 단계; 상 기 제1 데이터를 입력 정보로 하여 상기 제2 초기 파라미터 및 상기 제2 종료 파라미터를 기반으로 기 학습된 제2 인공지능 모듈에서 제2 데이터를 출력하는 단계; 및 상기 제2 데이터를 기반으로 상기 음성 데이터에서 음 성 방향을 추정하는 단계를 수행할 수 있다."}
{"patent_id": "10-2023-0054346", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, 커리큘럼 학습 방식과 deep supervision 방식을 결합한 학습 방식을 통해 복잡 한 환경에서 음성 방향 추정 기능을 향상시킬 수 있다."}
{"patent_id": "10-2023-0054346", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 기술적 사상은 다양한 변경을 가할 수 있고 여러 가지 실시 예를 가질 수 있는 바, 특정 실시 예들을 도면에 예시하고 이를 상세한 설명을 통해 상세히 설명하고자 한다. 그러나, 이는 본 발명의 기술적 사상을 특 정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 기술적 사상의 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 발명의 기술적 사상을 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 본 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제1, 제2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별기호에 불과하다. 또한, 본 명세서에서, 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것이다. 또한, 본 명세서에 기재된 \"~부\", \"~기\", \"~자\", \"~모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 프로세서(Processor), 마이크로 프로세서(Micro Processer), 마이크로 컨트롤러(MicroController), CPU(Central Processing Unit), GPU(Graphics Processing Unit), APU(Accelerate Processor Unit), DSP(Drive Signal Processor), ASIC(Application Specific Integrated Circuit), FPGA(Field Programmable Gate Array) 등과 같은 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있으며, 적어도 하나의 기능이나 동작의 처리에 필요한 데이터를 저장하는 메모리(memory)와 결합되는 형태 로 구현될 수도 있다. 그리고 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기능 별로 구분한 것에 불과함을 명확 히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이하에서 설명할 구성부 각각은 자 신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전부의 기능을 추가적으로 수행할 수도 있으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의해 전담되어 수행될 수도 있음은 물론이다. 본 개시의 실시예들을 설명함에 있어서 관련된 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필 요하게 흐릴 수 있다고 판단된 경우 그 상세한 설명은 생략한다. 그리고 후술되는 용어들은 본 개시에서의 기능 을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 마찬가지 이유로 첨부 도면에 있어서 일부 구성요소는 과장되거나 생략되거나 개략적으로 도시될 수 있다. 또한, 각 구성요소의 크기는 실제 크기를 전적으로 반영하는 것이 아니다. 각 도면에서 동일한 또는 대응하는 구성요소에는 동일한 참조 번호를 부여하였다. 본 개시의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 실시예들은 본 개시의 설명이 완전하도록 하고, 본 개시의 실시예"}
{"patent_id": "10-2023-0054346", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "들이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 개시의 청구하고자 하는 범위는 청구항의 범주에 의해 정의될 뿐이다. 이때, 처리 흐름도를 보이는 도면들의 각 블록과 처리 흐름도 도면들의 조합들은 컴퓨터 프로그램 인스트럭션들 에 의해 수행될 수 있음을 이해할 수 있을 것이다. 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서를 통해 수행되는 그 인스트럭션들이 흐름도 블록(들)에서 설 명된 기능들을 수행하는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구 현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능하므로, 그 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저 장된 인스트럭션들은 흐름도 블록(들)에서 설명된 기능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생 산하는 것도 가능하다. 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장 비 상에 탑재되는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에서 일련의 동 작 단계들이 수행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능한 데이터 프로 세싱 장비를 수행하는 인스트럭션들은 흐름도 블록(들)에서 설명된 기능들을 실행하기 위한 단계들을 제공하는 것도 가능하다. 또한, 각 블록은 특정된 논리적 기능(들)을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또, 몇 가지 대체 실행 예들에서는 블록들에서 언급된 기 능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들 은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들이 때때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다. 본 개시에서 사용되는 '~부(unit or part)'라는 용어는 소프트웨어 또는 FPGA(field-Programmable Gate Array) 또는 ASIC(Application Specific Integrated Circuit)과 같은 하드웨어 구성요소를 의미하며, '~부'는 특정한 역할들을 수행하도록 구성될 수 있다. 그렇지만 '~부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '~부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 실행시키 도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브 루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터구조들, 테이블들, 어레이들, 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수 의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구 성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 CPU들을 재생시키도록 구 현될 수도 있다. 또한 실시예에서 '~부'는 하나 이상의 프로세서 및/또는 장치를 포함할 수 있다. 이하, 본 발명의 기술적 사상에 따른 실시 예들을 차례로 상세히 설명한다. 도 1은 본 개시의 일 실시 예에 따른 인공지능 구조의 기본적인 원리를 나타낸 개념도이다. 도 1을 참조하면, 인공지능 구조에서 학습이 수행되는 기본적인 원리를 나타낸다. 인공지능 기술은 학습, 문제 해결, 인식 등과 같이 주로 인간 지능과 연결된 인지 문제를 해결하기 위한 기술을 나타낸다. 인공지능은 Machine learning(ML)이라고 불리는 기계 학습 방식과 Deep learning(DL)이라고 불리는 딥 러닝 방식을 통해 학습될 수 있다. 머신 러닝은 패턴 인식 및 학습에 사용되는 기법에 주로 사용되며 기록된 데이터를 학습하여 이를 기반으로 이후의 데이터를 예측하는 알고리즘을 나타낸다. 사전에 정의된 규칙이나 패 턴을 기반으로 하지 않고 데이터로부터 스스로 학습하는 기술을 나타낸다. 반면에 딥 러닝은 머신 러닝의 한 분 야로 인공 신경망(Artificial Neural Network: ANN)을 기반으로 하여 데이터를 처리하는 차이점이 있다. 딥 러 닝은 인공 신경망을 이용하기 때문에 머신 러닝보다 더욱 복잡하고 정교한 연산을 처리할 수 있다. 딥 러닝을 위한 알고리즘 종류로는 합성곱 신경망(Convolution neural network: CNN), DNN(deep neural network), 인공 신경망(ANN), 순환 신경망(Recurrent Neural Network: RNN)등을 포함할 수 있다. 도 1을 참고하면, 인공지능 구조는 인공지능 모듈로 나타낼 수 있다. 인공지능 모듈은 소정의 입력 데이터를 수신하여 모듈에서 미리 정해진 방식을 통해 학습을 수행하고, 학습 결과에 대한 출력 데이터 를 출력하게 된다. 일 실시예에 따르면, 입력 데이터에는 소정의 데이터, 음성 신호, 입력 시퀀스를 포함할 수 있다. 출력 데이터에는 출력 시퀀스, 향상된 음성 신호, 등이 포함될 수 있다. 도 2는 본 개시의 일 실시예에 따른, 방향 추정을 위한 인공지능 학습 방식 중 하나를 적용하여 학습된 인공지 능에 따른 결과 데이터를 나타낸 도면이다. 도 2에서 사용되는 인공지능 알고리즘은 도 1의 인공지능 모듈의 종류 중 하나일 수 있다. 본 개시에서 음성 방향 추정 기술이란 각 프레임(frame)별로 음성이 존재할 때, 해당 음성이 수신되는 방향을 추정하는 기술을 나타낼 수 있다. 음성 방향 추정 기술은 일반적으로 빔포밍(beamforming) 기술과 연계되어 사 용된다. 타겟(또는, 방향이 정해진 음성)으로한 음성 방향에서 들어오는 소리 신호를 분리하는 것이 빔포밍 기 술인데 이것을 수행하기 위하여는 음성 방향 추정 기술이 필수적일 수 있다. 음성 방향 추정 기술에 딥러닝을 활용하는 방식으로는 정해진 타겟 방향에 대해서는 출력 값으로 1을 라벨링하 고, 나머지 방향에 대해서는 출력 값을 0을 라벨링하여 인공지능 알고리즘을 학습시키는 방식인 hard label 방 식이 있다. 하지만, 최근에는 정해진 타겟 방향에 출력 값으로 1을 부여하고 타겟 방향의 근처 방향에도 0이 아 닌 소정의 출력 값을 부여하는 방식인 soft label 방식을 통해 인공지능 알고리즘을 학습시키는 경우 학습 효과 가 큰 것으로 나타난다. 도 2를 참조하면, x축은 방위각 방향(Azimuth direction)을 나타내고, y축은 출력 값을 나타낸다. Hard label 방식을 사용하는 경우 타겟 방향인 소스 1 및 소스 2에 대해서만 출력 값을 할당하고 학습이 진행될 것이다. 반면에, soft label 방식의 경우 타겟 방향인 소스 1 및 소스 2뿐만 아니라 소스 1의 주변 값으로 주변 값 1 및 소스 2의 주변 값으로 주변 값 2을 추가로 할당할 수 있다. 이 경우, 하나의 타겟 당 하나의 중간 값을 할당한 예시를 나타낸 것이며, 도 2에 나타난 바와 같이 복수개의 주변 값들 이 할당될 수 있다. Soft label을 할당하는 방식으로는 다음 수학식들을 활용할 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0054346", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "[수학식 2]"}
{"patent_id": "10-2023-0054346", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "[수학식 3]"}
{"patent_id": "10-2023-0054346", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, 수학식 1은 정답 타겟 방향에는 1을 부여하고, 그 주변부에는 1보다 작은 양수를 할당하여 타겟을 만드 는 수식을 나타낸다. 정답과 멀어질수록 0에 가까운 작은 값을 할당하여 정답 방향과는 멀어지고 있음을 인식할 수 있다. 여기서 l은 프레임의 인덱스를 나타내는 것으로 시작으로부터 몇 번째 프레임인지를 나타낸다. 은 화자(speaker)가 위치한 방향으로 이루어진 집합을 나타낸다. 도 3은 본 개시의 실시예에 따른, 커리큘럼 학습 방식을 적용하여 학습된 인공지능에 따른 다양한 결과 데이터 를 나타낸 도면이다. 도 3은 도 1내지 도 2에서 설명한 커리큘럼 학습 방식 중 soft label 방식을 사용하여 학습한 인공지능 알고리 즘의 결과 값을 나타낸 것일 수 있다. 커리큘럼 학습 방식이란 딥 러닝을 통해 인공지능을 학습시키는 방식 중 하나로, 학습 데이터를 점진적으로 어 려운 순서로 제공하여 모델의 학습 속도와 성능을 개선하는 방식이다. 즉, 학습 초반에는 상대적으로 이해하기 쉬운 데이터 셋과 타겟을 설정하여 학습을 진행하고 학습이 진행됨에 따라 난이도를 점차 높여서 상대적으로 이 해하기 어려운 데이터 셋과 타겟을 설정하여 학습을 시켜, 복잡한 task에 대해서도 알고리즘을 적용할 수 있도 록 하는 학습 방식을 나타낸다. 도 3을 참조하면, 기존에는, Soft label 방식에서 수학식 1 내지 수학식 3과 관련하여 감소 레벨(attenuated level)()와 넓이(width)(σ)를 경험에 의하여 선택하여 고정한 상태로 학습을 진행하였으나 이하 방식에서는 를 고정한 채로 σ을 변경하여 학습을 진행한다. 여기서 감소 레벨은 전력(power)의 감소하는 정도를 나타내 는 파라미터이고, 넓이는 타겟 방향으로부터의 일정 폭 또는 떨어진 정도를 나타내는 파라미터일 수 있다. 타겟 방향를 추정하도록 학습하기 위하여 학습 초반부에는 σ값을 크게 설정할 수 있다. 예를 들어, σ를 30으 로 설정하고 학습을 수행하는 경우 제1 결과 값이 나타난다. 제1 결과 값에서 타겟 방향의 주변 부에서도 1과 가까운 크기의 값을 나타내어 학습이 용이하게 수행될 수 있다. 다음으로 σ를 15로 설정하여 학 습을 수행하는 경우 제2 결과 값이 나타난다. 제2 결과 값에서는 타겟 방향의 주변부에서 σ가 30일때보다는 작은 값을 부여하여 학습이 좀더 어렵지만 타겟 방향을 좀 더 명확하게 추정할 수 있도록 학 습된다. 다음으로 σ를 5로 설정하여 학습을 수행하는 경우 제3 결과 값이 나타난다. 제3 결과 값에 서는 타겟 방향의 주변부에서 σ가 15일때보다 작은 값을 부여하여 학습이 더 어려워지지만 타겟 방향 을 더욱 명확하게 추정할 수 있도록 학습된다. σ값이 점차 작아질수록 타겟 방향의 주변부에서 값을 가지 는 범위가 줄어들고 타겟 방향을 인식하기가 더욱 용이해진다는 장점이 있다. 다만, 커리큘럼 학습 방식에서 타겟 방향 주변부에 큰 값을 할당하는 경우 딥 러닝이 학습하기 쉽다는 장점이 있지만, 정답 값인 1과의 차이가 작아져서 정확한 타겟의 방향을 추정하는 것에 대하여는 명확하지 않다는 단점 이 있다. 반면, 타겟 방향 주변부에 작은 값을 할당하면 학습이 어려워지는 대신, 정확한 타겟의 방향을 추정하 도록 학습될 수 있다. 두 가지 방법의 장점들을 모두 활용하기 위하여 인공지능 알고리즘 학습 방식인 커리큘럼학습(curriculum learning) 방식과 딥 슈퍼비젼(deep supervision) 방식을 결합하는 방식을 제안한다. 도 4는 본 개시의 일 실시예에 따른, 인공지능 학습 방식을 통해 학습된 인공지능 모델을 나타낸 도면이다. 도 4는 커리큘럼 학습 방식과 딥 슈퍼비젼 방식을 결합한 형태로 구성될 수 있다. 딥 슈퍼비젼(deep supervision) 방식이란 딥러닝 모델 중 하나로 딥러닝 모델과 같이 끝부분의 출력만 활용하여 타겟 및 손실 (loss)를 계산하여 학습시키는 방식이 아닌 중간층에 추가적인 지도 정보(예를 들어, 중간 출력)를 제공하는 방 식을 나타낸다. 딥 슈퍼비젼 방식을 사용하는 모델에서는 중간 층에 보조 손실 함수(auxiliary loss function) 을 가질 수 있다. 보조 손실 함수는 중간 층의 출력을 기반으로 하여 각 층에서의 오차를 예측할 수 있다. 상기 예측된 오차를 최종 손실 함수와 결합하여 학습을 촉진할 수 있다. 도 4를 참조하면, 멀티 채널 오디오에서 short time Fourier transform(STFT)를 진행한 후, instantaneous relative transfer function (iRTF) 특징(feature)를 추출한다. 추출된 iRTF feature을 합성곱 신경망(convolutional neural network: CNN), batch normalization (BN), 및 exponential linear unit(ELU)로 구성된 shared module을 통과시킨다. Shared module을 통과한 피쳐(feature)는 n개의 SCM(skip- connection module)(415a, 415b, 415c)로 전달된 후 학습을 거쳐 각각 output layer(420a, 420b, 420c)로 전달 된다. 여기서 SCM(415a, 415b, 415c)은 CNN+BN+ELU의 구조를 가질 수 있으며, output layer(420a, 420b, 420 c)는 CNN+Sigmoid 연산 단계로 구성될 수 있다. 각각의 output layer(420a, 420b, 420c)에서 출력된 값과 σ값을 다르게 하여 라벨링한(labeling) 정보(430a, 430b, 430c)(또는, 지도 정보, 특정 σ값에 상응하는 데이터 값)를 이용하여 각각의 Cross-entropy loss(CE Loss)(425a, 425b, 425c)를 측정할 수 있다. CE Loss는 모델의 예측 확률 분포와 실제 레이블 확률 분포 사이의 차이를 나타낼 수 있다. 예를 들어, 제1 SCM(415a)에서의 출력결과는 가장 큰 σ값인 16을 가지는 라벨링 정보(430a)를 지도 정보로 주 어 loss(425a)를 측정할 수 있다. 다음 단계인 제2 SCM(415b)에서는 σ값을 6을 가지는 라벨링 정보(430b)를 지 도 정보로 주어 loss(425b)를 측정할 수 있다. 다음 단계로 제3 SCM(415c)에서는 σ값을 2를 가지는 라벨링 정 보(430c)를 지도 정보로 주어 loss(425c)를 측정할 수 있다. 라벨링 정보를 타겟 주변부에 점차 작은 값을 할당 하여 부여함으로써 layer가 깊어질수록 더 명확한 output을 출력하도록 유도하는 방식일 수 있다. 중간 정보로써 라벨링 정보를 부여하는 것과 별도로 하나의 모듈에서 최초 σ값과 최종 σ값을 결정하여 σ값이 점차 작아지도록 커리큘럼 학습을 수행할 수 있다. 예를 들어, 제1 SCM에서 라벨링 정보(430a)로 최초에는 16을 부여하지만 최종적으로 2를 부여하여 일정하게 감소하도록 학습시키는 커리큘럼 러닝 방식이 함께 수행될 수 있 다. 또한, 첫번째 층의 알고리즘 모듈에서 초기값이 가장 크도록 σ값을 부여 정해진 최종 σ값이 될 때까지 스케쥴 링을 통해 커리큘럼 러닝을 통해 학습이 되고, 다음 층의 모듈에서는 첫번째 모듈보다 초기 σ값이 더 작은 값 을 가지도록 부여하여 층이 증가할수록 점차적으로 초기 σ값이 작은 값을 가지도록 부여하되, 최종 σ값은 동 일하게 설정하여 인공지능 알고리즘을 학습시킬 수 있다. 여기서 스케쥴링은 σ이 감소하는 수치를 일정하게 유 지하여 초기 σ값에서 최종 σ값까지 정해진 σ값이 감소하도록 설정하는 방식을 포함할 수 있다. 딥 슈퍼비젼 방식과 관련하여 제1 SCM(415a)에서 출력된 결과는 output layer(420a)로 출력되지만 또한, 다음 층인 제2 SCM(415b)로도 출력된다. 제2 SCM에서는 제1 SCM(415a)에서의 결과를 반영하여 학습을 수행하게 된다. 따라서 제2 SCM(415b)의 학습 결과로는 제1 SCM(415a)에서의 학습 결과가 추가로 반영된 결과를 도출하게 된다. 이후 층이 증가하더라도 동일하게 이전 층까지의 학습 결과를 반영하여 결과를 도출할 수 있다. 도 5는 본 개시의 일 실시예에 따른 인공지능 모델과 기존 모델에 대한 음성 방향 추정 결과 값을 나타낸다. 도 5에서 사용된 데이터 셋은 공용 데이터를 사용한 것이다. 도 5의 표는 공용 데이터 셋을 특별한 방식을 추가 하지 않은 기존의 알고리즘 모듈인 CRNNk, 커리큘럼 학습 방식을 추가한 알고리즘 모듈인 CL, 딥 슈 퍼비젼 방식을 추가한 알고리즘 모듈인 DS(515, 520), 커리큘럼 학습 방식과 딥 슈퍼비젼 방식을 결합하여 추가 한 알고리즘 모듈인 DSCL(Deeply supervised curriculum learning) 모듈에 각각 입력하여 나타난 결과를 나타낸 것이다. 측정 결과 값으로는 평균 절대 에러(mean absolute error: MSE)와 정확도(accuracy: ACC)를 나타내었다. 여기 서 MSE는 정답과 추정치 간의 각도 차이이며 그 값이 작을수록 효과가 좋음을 나타낸다. ACC는 정답과 추정치간의 차이가 10도 이내일 때 정답으로 처리하고 이때의 정답율을 나타낸다. 그 수치가 높을수록 좋은 결과를 나 타낸다. 또한, Synthetic 결과는 합성된 data로 평가한 결과이고, LOCATA는 실제환경에서 녹음된 데이터를 이용 하여 평가한 것이다. k는 SCM의 인덱스를 나타낸다. 즉, 도 5를 참조하면, CRNNk는 deep supervision 및 curriculum learning을 사용하지 않고 k번째 SCM의 output 만으로 학습했을 때 결과이다. CLk는 k번째 SCM의 output만으로 curriculum learning을 적용했을 때 결과이다. DSd는 전체 SCM에 대해서 같은 σ로 형성한 target으로 학습시켰을 때 결과이다. DSe는 각 SCM에 대해서 다른 σ로 형성한 target으로 학습시켰을 때 결과이다. DSCL은 deep supervision 및 curriculum learning을 동시에 사용했을 때 결과이며, 각 SCM 마다 다른 '', ''를 사용했다. 여기서, k는 레이어 또는 모듈의 인덱스를 나타낼 수 있다. 결과를 보면, 커리큘럼 학습 방식의 경우 실환경 데이터를 사용할 때 성능이 높으며, 딥 슈퍼비젼 방식은 spatially coherent noise가 존재하는 환경에서 성능이 높다. 커리큘럼 학습 방식과 딥 슈퍼비젼 방식을 모두 사용한 모듈의 경우 두 환경 모두에서 성능이 향상되었음을 확인할 수 있다. 도 6은 본 발명의 일 실시예에 따른 음성 향상 시스템을 위한 전자 장치에 대한 블록 구성도이다. 도 6을 참조하면, 전자 장치는 모뎀(MODEM, 620), 메모리(MEMORY, 640) 및 프로세서(PROCESSOR, 630)를 포함할 수 있다. 모뎀은 다른 전자 장치들과 전기적으로 연결되어 상호 통신이 이뤄지도록 하는 통신 모뎀일 수 있다. 특히 모뎀은 데이터 입력을 수신하여 프로세서로 전송할 수 있고, 프로세서는 입력된 데이터 값을 메 모리에 저장할 수 있다. 또한, 시스템에서 학습된 인공지능 알고리즘에 의해 출력된 데이터 값을 다른 전 자 장치로 전송할 수 있다. 메모리는 전자 장치의 동작을 위한 각종 정보 및 프로그램 명령어들이 저장되는 구성으로서, 하드 디 스크(Hard Disk), SSD(Solid State Drive) 등과 같은 기억장치일 수 있다. 특히, 메모리는 프로세서(63 0)의 제어에 의해 모뎀에서 입력되는 하나 이상의 데이터 입력 값을 저장할 수 있다. 또한, 메모리는 프로세서에 의해 실행 가능한 방향 추정을 위한 인공지능 알고리즘과 같은 프로그램 명령어들을 저장할 수 있다. 또한, 메모리는 본 개시에서 설명한 커리큘럼 학습 방식, 딥 슈퍼비젼 방식, deeply supervised curriculum learning을 통해 학습된 인공지능 알고리즘과 같은 프로그램 (또는 프로그램 명령어)를 저장할 수 있다. 프로세서는 적어도 하나의 프로세서로 구성되며, 메모리에 저장된 데이터 및 프로그램 명령어들을 이 용하여 방향 추정 인공지능 알고리즘을 학습하고 이를 활용하여 데이터를 계산할 수 있다. 프로세서는 도 1 내지 도 5에서 설명한 모든 인공지능 알고리즘을 제어하고 계산할 수 있다. 프로세서는 이후 도 7에서 설명하는 방법에 대한 동작을 수행할 수 있다. 도 7은 본 발명의 일 실시예에 따른 음성 방향 추정 방법을 설명하기 위한 순서도이다. 이하 도 7을 참조하여, 도 1 내지 도 6을 참조하여 설명한 전자 장치의 인공지능 알고리즘의 학습 동작 및 음성 방향 추정 방법에 대해 정리하여 설명한다. 각 동작들은 일련의 과정에서 필수적으로 포함되어야 하는 동작들은 아니며 상황에 따라 일부만이 구성되어 동작할 수 있다. 단계 S710에서, 인공지능을 통한 음성 방향을 추정하기 위하여 제1 초기 파라미터 및 제1 종료 파라미터를 결정 할 수 있다. 여기서 파라미터는 도 2 내지 도 4에서 설명한 넓이(width)()를 나타내는 것일 수 있다. 또한, 초기 파라미터는 도 5의 , 종료 파라미터는 도 5의 를 나타낼 수 있다. 단계 S720에서, 음성 데이터를 입력 정보로 하여 상기 제1 초기 파라미터 및 상기 제1 종료 파라미터를 기반으 로 기 학습된 제1 인공지능 모듈에서 제1 데이터를 출력할 수 있다. 상기 음성 데이터는 본 개시의 도 1 내지 도 4에서의 음성 데이터, multi channel audio를 나타낼 수 있다. 여기서 제1 인공지능 모듈은 초기 파라미터 및 종료 파라미터를 기반으로 커리큘럼 학습 방식을 통해 학습될 수 있다. 여기서, 제1 데이터는 도 4에서 제2SCM으로 출력되는 데이터일 수 있다. 단계 S730에서, 제2 초기 파라미터 및 제2 종료 파라미터를 결정할 수 있다. 여기서 파라미터는 도 2 내지 도 4 에서 설명한 넓이(width)()를 나타내는 것일 수 있다. 또한, 초기 파라미터는 도 5의 , 종료 파라미터는 도 5의 를 나타낼 수 있다. 여기서 제2 초기 파라미터 및 제2 종료 파라미터는 각각 도 5에서 k가 2일때의 , 및 를 나타내는 것일 수 있다. 단계 S740에서, 제1 데이터를 입력 정보로 하여 상기 제2 초기 파라미터 및 상기 제2 종료 파라미터를 기반으로 기 학습된 제2 인공지능 모듈에서 제2 데이터를 출력할 수 있다. 여기서, 제1 데이터는 도 4에서 제1 SCM에서 제2 SCM으로 출력되는 데이터일 수 있다. 여기서 제2 인공지능 모듈은 초기 파라미터 및 종료 파라미터를 기반 으로 커리큘럼 학습 방식을 통해 학습될 수 있다. 단계 S750에서, 상기 제2 데이터를 기반으로 상기 음성 데이터에서 음성 방향을 추정할 수 있다. 상기 음성 데 이터에는 화자의 음성, 잡음, 에코 신호 등이 포함될 수 있다. 상기 음성 방향은 일정 각도로 결정될 수 있다. 이상, 본 개시의 기술적 사상을 다양한 실시 예들을 들어 상세하게 설명하였으나, 본 개시의 기술적 사상은 상 기 실시 예들에 한정되지 않고, 본 개시의 기술적 사상의 범위 내에서 당 분야에서 통상의 지식을 가진 자에 의 하여 여러가지 변형 및 변경이 가능하다."}
{"patent_id": "10-2023-0054346", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 상세한 설명에서 인용되는 도면을 보다 충분히 이해하기 위하여 각 도면의 간단한 설명이 제공된다. 도 1은 본 개시의 일 실시 예에 따른 인공지능 구조의 기본적인 원리를 나타낸 개념도이다. 도 2는 본 개시의 일 실시예에 따른, 방향 추정을 위한 인공지능 학습 방식 중 하나를 적용하여 학습된 인공지 능에 따른 결과 데이터를 나타낸 도면이다. 도 3은 본 개시의 실시예에 따른, 커리큘럼 학습 방식을 적용하여 학습된 인공지능에 따른 다양한 결과 데이터 를 나타낸 도면이다. 도 4는 본 개시의 일 실시예에 따른, 인공지능 학습 방식을 통해 학습된 인공지능 모델을 나타낸 도면이다. 도 5는 본 개시의 일 실시예에 따른 인공지능 모델과 기존 모델에 대한 음성 방향 추정 결과 값을 나타낸다. 도 6은 본 개시의 일 실시예에 따른 음성 향상 시스템을 위한 전자 장치에 대한 블록 구성도이다. 도 7은 본 개시의 일 실시예에 따른 음성 방향 추정 방법을 설명하기 위한 순서도이다."}
