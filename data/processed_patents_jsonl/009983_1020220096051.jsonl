{"patent_id": "10-2022-0096051", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0018142", "출원번호": "10-2022-0096051", "발명의 명칭": "감시 장치 및 방법", "출원인": "한화비전 주식회사", "발명자": "김희라"}}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상에서 객체를 검출하는 객체 검출부;상기 검출된 객체를 추적하는 객체 추적부; 및상기 객체의 이상 행동 여부를 판단하는 제1 이상 행동 판단부를 포함하되,상기 제1 이상 행동 판단부는 상기 영상에서 상기 객체의 전체 몸체를 포함하는 제1 영역 및 상기 객체의 일부몸체를 포함하는 제2 영역 중 적어도 하나를 참조하여 상기 객체의 이상 행동 여부를 판단하는 감시 장치."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 객체 검출부는 욜로(YOLO; You Only Live Once) 알고리즘을 이용하여 상기 영상에서 객체를 검출하는 감시장치."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 제1 영역 및 제2 영역은 상기 욜로 알고리즘이 이용되어 생성된 영역을 포함하는 감시 장치."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 객체 추적부는 딥소트(DeepSORT) 알고리즘을 이용하여 상기 검출된 객체를 추적하는 감시 장치."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 제1 이상 행동 판단부는 상기 제1 영역의 종횡비를 참조하여 상기 객체의 이상 행동 여부를 판단하는 감시장치."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 제1 이상 행동 판단부는 상기 제2 영역의 기준 위치에 대한 상기 제2 영역의 현재 위치를 참조하여 상기객체의 이상 행동 여부를 판단하는 감시 장치."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 제1 이상 행동 판단부는 상기 영상에서 상기 객체의 전체 몸체를 포함하는 제3 영역을 설정하고, 상기 제3영역 중 상기 객체의 일부 몸체가 배치된 위치를 참조하여 상기 객체의 이상 행동 여부를 판단하는 감시 장치."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서,학습을 통하여 생성된 이상 행동 분석 모델을 이용하여 상기 객체의 이상 행동 여부를 판단하는 제2 이상 행동판단부를 더 포함하는 감시 장치.공개특허 10-2024-0018142-3-청구항 9 제8 항에 있어서,상기 이상 행동 분석 모델은 관련 분포(in distribution) 데이터 및 비관련 분포(out of distribution) 데이터를 학습하여 생성된 것을 포함하는 감시 장치."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항에 있어서,상기 객체는 사람을 포함하고, 상기 객체의 일부 몸체는 사람의 머리를 포함하는 감시 장치."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "영상에서 객체를 검출하는 단계;상기 검출된 객체를 추적하는 단계; 및상기 객체의 이상 행동 여부를 판단하는 단계를 포함하되,상기 객체의 이상 행동 여부를 판단하는 단계는 상기 영상에서 상기 객체의 전체 몸체를 포함하는 제1 영역 및상기 객체의 일부 몸체를 포함하는 제2 영역 중 적어도 하나를 참조하여 상기 객체의 이상 행동 여부를 판단하는 단계를 포함하는 감시 방법."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 영상에서 객체를 검출하는 단계는 욜로(YOLO; You Only Live Once) 알고리즘을 이용하여 상기 영상에서 객체를 검출하는 단계를 포함하는 감시 방법."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서,상기 제1 영역 및 제2 영역은 상기 욜로 알고리즘이 이용되어 생성된 영역을 포함하는 감시 방법."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11 항에 있어서,상기 검출된 객체를 추적하는 단계는 딥소트(DeepSORT) 알고리즘을 이용하여 상기 검출된 객체를 추적하는 단계를 포함하는 감시 방법."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11 항에 있어서,상기 객체의 이상 행동 여부를 판단하는 단계는 상기 제1 영역의 종횡비를 참조하여 상기 객체의 이상 행동 여부를 판단하는 단계를 포함하는 감시 방법."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11 항에 있어서,상기 객체의 이상 행동 여부를 판단하는 단계는 상기 제2 영역의 기준 위치에 대한 상기 제2 영역의 현재 위치를 참조하여 상기 객체의 이상 행동 여부를 판단하는 단계를 포함하는 감시 방법."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11 항에 있어서,상기 객체의 이상 행동 여부를 판단하는 단계는,공개특허 10-2024-0018142-4-상기 영상에서 상기 객체의 전체 몸체를 포함하는 제3 영역을 설정하는 단계; 및상기 제3 영역 중 상기 객체의 일부 몸체가 배치된 위치를 참조하여 상기 객체의 이상 행동 여부를 판단하는 단계를 포함하는 감시 방법."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11 항에 있어서,학습을 통하여 생성된 이상 행동 분석 모델을 이용하여 상기 객체의 이상 행동 여부를 판단하는 단계를 더 포함하는 감시 방법."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18 항에 있어서,상기 이상 행동 분석 모델은 관련 분포(in distribution) 데이터 및 비관련 분포(out of distribution) 데이터를 학습하여 생성된 것을 포함하는 감시 방법."}
{"patent_id": "10-2022-0096051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11 항에 있어서,상기 객체는 사람을 포함하고, 상기 객체의 일부 몸체는 사람의 머리를 포함하는 감시 방법."}
{"patent_id": "10-2022-0096051", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 감시 장치 및 방법에 관한 것으로서, 경량의 인공지능 모델을 이용하여 감시 영역에 포함된 객체의 이 상 행동을 감시하는 감시 장치 및 방법에 관한 것이다. 본 발명의 실시예에 따른 감시 장치는 영상에서 객체를 검출하는 객체 검출부와, 상기 검출된 객체를 추적하는 객체 추적부, 및 상기 객체의 이상 행동 여부를 판단하는 제1 이상 행동 판단부를 포함하되, 상기 제1 이상 행동 판단부는 상기 영상에서 상기 객체의 전체 몸체를 포함하는 제1 영역 및 상기 객체의 일부 몸체를 포함하는 제2 영역 중 적어도 하나를 참조하여 상기 객체의 이상 행동 여부를 판단한다."}
{"patent_id": "10-2022-0096051", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 감시 장치 및 방법에 관한 것으로서, 더욱 상세하게는 경량의 인공지능 모델을 이용하여 감시 영역에 포함된 객체의 이상 행동을 감시하는 감시 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0096051", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "행동 분석 기술은 동영상에 포함된 객체의 움직임을 분석하여 행동을 추정하는 기술이다. 해당 기술은 동영상의 일정 프레임 간격 동안 관심 객체에 대한 움직임이나 관절 정보를 추출하고 이를 바탕으로 해당 객체의 행동을 추정함으로써 이상 행동을 검출할 수 있다. 행동 분석 기술은 스포츠 및 로보틱스 등 많은 분야에서 활용될 수 있다. 행동 분석 기술에 대한 다양한 연구가 진행되고 있으며 특히 배경, 조명, 크기 변화에 상관없이 강인한 특징 추 출이 가능한 스켈레톤(skeleton) 기반의 행동 분석 기술이 많은 관심을 받고 있다. 스켈레톤 기반의 행동 분석 기술은 입력된 영상에 포함된 객체가 어떤 행동을 하고 있는지 추정하는 기술이다. 여기서, 스켈레톤 데이터는 자세 추정 모델이나 센서를 이용해 뽑은 2D 또는 3D 관절 좌표를 포함할 수 있다. 한편, 스켈레톤 기반의 행동 분석 기술에 따른 행동 분석을 수행하기 위해서는 높은 성능의 연산 비용이 필요하 다. 또한, 본 기술에 따르면 RGB 데이터로부터 스켈레톤을 추출하고, 추출된 스켈레톤을 행동 분석 네트워크에 통과시켜야 하기 때문에 실생활에 적용하는 데에는 무리가 따를 수 있다. 따라서, 보다 적은 연산으로도 영상에 포함된 객체의 이상 행동을 검출할 수 있도록 하는 발명의 등장이 요구된 다. 선행기술문헌 일본 공개특허공보 특개2020-24517호 (2020.02.13)"}
{"patent_id": "10-2022-0096051", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 경량의 인공지능 모델을 이용하여 감시 영역에 포함된 객체의 이상 행동을 감시하는 감시 장치 및 방법을 제공하는 것이다.본 발명의 과제들은 이상에서 언급한 과제로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아래의 기재로 부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0096051", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 달성하기 위하여, 본 발명의 실시예에 따른 감시 장치는 영상에서 객체를 검출하는 객체 검출부와, 상기 검출된 객체를 추적하는 객체 추적부, 및 상기 객체의 이상 행동 여부를 판단하는 제1 이상 행동 판단부를 포함하되, 상기 제1 이상 행동 판단부는 상기 영상에서 상기 객체의 전체 몸체를 포함하는 제1 영역 및 상기 객 체의 일부 몸체를 포함하는 제2 영역 중 적어도 하나를 참조하여 상기 객체의 이상 행동 여부를 판단한다. 상기 객체 검출부는 욜로(YOLO; You Only Live Once) 알고리즘을 이용하여 상기 영상에서 객체를 검출한다. 상기 제1 영역 및 제2 영역은 상기 욜로 알고리즘이 이용되어 생성된 영역을 포함한다. 상기 객체 추적부는 딥소트(DeepSORT) 알고리즘을 이용하여 상기 검출된 객체를 추적한다. 상기 제1 이상 행동 판단부는 상기 제1 영역의 종횡비를 참조하여 상기 객체의 이상 행동 여부를 판단한다. 상기 제1 이상 행동 판단부는 상기 제2 영역의 기준 위치에 대한 상기 제2 영역의 현재 위치를 참조하여 상기 객체의 이상 행동 여부를 판단한다. 상기 제1 이상 행동 판단부는 상기 영상에서 상기 객체의 전체 몸체를 포함하는 제3 영역을 설정하고, 상기 제3 영역 중 상기 객체의 일부 몸체가 배치된 위치를 참조하여 상기 객체의 이상 행동 여부를 판단한다. 상기 감시 장치는 학습을 통하여 생성된 이상 행동 분석 모델을 이용하여 상기 객체의 이상 행동 여부를 판단하 는 제2 이상 행동 판단부를 더 포함한다. 상기 이상 행동 분석 모델은 관련 분포(in distribution) 데이터 및 비관련 분포(out of distribution) 데이터 를 학습하여 생성된 것을 포함한다. 상기 객체는 사람을 포함하고, 상기 객체의 일부 몸체는 사람의 머리를 포함한다. 본 발명의 실시예에 따른 감시 방법은 영상에서 객체를 검출하는 단계와, 상기 검출된 객체를 추적하는 단계, 및 상기 객체의 이상 행동 여부를 판단하는 단계를 포함하되, 상기 객체의 이상 행동 여부를 판단하는 단계는 상기 영상에서 상기 객체의 전체 몸체를 포함하는 제1 영역 및 상기 객체의 일부 몸체를 포함하는 제2 영역 중 적어도 하나를 참조하여 상기 객체의 이상 행동 여부를 판단하는 단계를 포함한다. 상기 영상에서 객체를 검출하는 단계는 욜로(YOLO; You Only Live Once) 알고리즘을 이용하여 상기 영상에서 객 체를 검출하는 단계를 포함한다. 상기 제1 영역 및 제2 영역은 상기 욜로 알고리즘이 이용되어 생성된 영역을 포함한다. 상기 검출된 객체를 추적하는 단계는 딥소트(DeepSORT) 알고리즘을 이용하여 상기 검출된 객체를 추적하는 단계 를 포함한다. 상기 객체의 이상 행동 여부를 판단하는 단계는 상기 제1 영역의 종횡비를 참조하여 상기 객체의 이상 행동 여 부를 판단하는 단계를 포함한다. 상기 객체의 이상 행동 여부를 판단하는 단계는 상기 제2 영역의 기준 위치에 대한 상기 제2 영역의 현재 위치 를 참조하여 상기 객체의 이상 행동 여부를 판단하는 단계를 포함한다. 상기 객체의 이상 행동 여부를 판단하는 단계는, 상기 영상에서 상기 객체의 전체 몸체를 포함하는 제3 영역을 설정하는 단계, 및 상기 제3 영역 중 상기 객체의 일부 몸체가 배치된 위치를 참조하여 상기 객체의 이상 행동 여부를 판단하는 단계를 포함한다. 상기 감시 방법은 학습을 통하여 생성된 이상 행동 분석 모델을 이용하여 상기 객체의 이상 행동 여부를 판단하 는 단계를 더 포함한다. 상기 이상 행동 분석 모델은 관련 분포(in distribution) 데이터 및 비관련 분포(out of distribution) 데이터 를 학습하여 생성된 것을 포함한다. 상기 객체는 사람을 포함하고, 상기 객체의 일부 몸체는 사람의 머리를 포함한다. 기타 실시예들의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2022-0096051", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기한 바와 같은 본 발명의 감시 장치 및 방법에 따르면 경량의 인공지능 모델을 이용하여 감시 영역에 포함된 객체의 이상 행동을 감시하기 때문에 상대적으로 적은 연산으로 객체의 이상 행동을 검출할 수 있는 장점이 있 다."}
{"patent_id": "10-2022-0096051", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 청구범위의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0096051", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예를 상세히 설명한다. 본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 게시되는 실시 예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될"}
{"patent_id": "10-2022-0096051", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수 있으며, 단지 본 실시 예들은 본 발명의 게시가 완전하도록 하고, 본 발명이 속하는 기술분야에서 통상의 지 식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정 의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해 석되지 않는다. 도 1은 감시 시스템을 나타낸 도면이다. 도 1을 참조하면, 감시 시스템은 관리 서버, 감시 장치 및 모니터링 장치를 포함하여 구성 된다. 관리 서버는 감시 장치에 의해 촬영된 영상을 관리하는 역할을 수행한다. 예를 들어, 관리 서버(10 0)는 촬영 영상을 저장하거나 송신할 수 있다. 감시 시스템은 적어도 하나의 감시 장치를 포함할 수 있다. 관리 서버는 적어도 하나의 감시 장치에 의해 촬영된 영상을 개별적으로 저장할 수 있다. 또한, 관리 서버는 인공지능 모델을 생성하여 감시 장치에 제공할 수 있다. 관리 서버는 인공지 능 모델을 감시 시스템에 포함된 모든 감시 장치에 제공할 수 있다. 감시 장치는 관리 서버(10 0)로부터 제공된 인공지능 모델을 이용하여 영상에서 객체를 검출하고, 검출된 객체에 대한 이상 행동 여부를판단할 수 있다. 관리 서버의 구체적인 구성 및 기능에 대해서는 도 2 및 도 3을 통하여 후술하기로 한다. 감시 장치는 감시 영역을 촬영하여 영상을 생성할 수 있다. 감시 장치에 의해 생성되는 영상은 정지 영상 또는 동영상일 수 있다. 감시 장치는 특정 장소의 고정된 위치에 배치된 것이거나, 일정한 경로를 따라 자동 또는 수동으로 이동 가능한 것일 수 있다. 또는, 감시 장치는 사람 또는 로봇 등에 의하여 운반될 수도 있다. 감시 장치 는 유무선 인터넷에 연결하여 사용 가능한 IP 카메라일 수 있다. 감시 장치는 팬(pan), 틸트(tilt), 및 줌 (zoom) 기능을 갖는 PTZ 카메라일 수 있다. 감시 장치는 감시 영역을 녹화하거나 사진을 촬영하는 기능을 가질 수 있다. 감시 장치는 감시 영역에서 발생하는 소리를 녹음하는 기능을 가질 수 있다. 감시 장치 는 감시 영역에서 움직임 또는 소리가 발생하는 경우, 이에 대한 알림을 출력하거나 녹화 또는 사진 촬영 을 수행할 수 있다. 또한, 감시 장치는 촬영 영상을 분석하여 촬영 영상에 포함된 객체의 이상 행동 여부를 판단할 수 있다. 객체의 이상 행동 여부를 판단하기 위하여 감시 장치는 인공지능 모델을 이용할 수 있다. 특히, 감시 장치 는 경량의 인공지능 모델을 이용하여 객체의 이상 행동 여부를 판단할 수 있다. 감시 장치의 구체적 인 구성 및 기능에 대한 자세한 설명은 도 4 및 도 5를 통하여 후술하기로 한다. 모니터링 장치는 관리 서버에 접속하여 감시 장치에 의해 촬영된 영상을 출력할 수 있다. 사용 자는 모니터링 장치에서 출력된 영상을 이용하여 감시 영역에 대한 감시 결과를 확인할 수 있다. 또한, 모 니터링 장치는 감시 장치로 제어 명령을 송신할 수 있다. 제어 명령은 감시 장치의 팬, 틸트 또 는 줌을 제어하기 위한 명령일 수 있으며, 촬영 개시 또는 촬영 종료를 위한 명령일 수 있다. 또한, 모니터링 장치는 감시 장치에 의한 이상 행동 판단 결과를 수신하여 출력할 수 있다. 전술한 바와 같이, 감시 장치는 객체의 이상 행동 여부를 판단할 수 있다. 그리하여, 이상 행동을 수행하는 객체 가 발견되는 경우 감시 장치는 해당 결과를 모니터링 장치로 송신할 수 있다. 이에, 사용자는 모니터 링 장치를 통하여 출력된 이상 행동 판단 결과를 참조하여 해당 객체에 대한 조치를 취할 수 있다. 감시 시스템은 적어도 하나의 감시 장치를 포함할 수 있다. 모니터링 장치는 적어도 하나의 감시 장치 각각에 접속하여 감시 장치에 의한 이상 행동 판단 결과를 개별적으로 수신하여 출력할 수 있다. 관리 서버, 감시 장치 및 모니터링 장치는 통신망을 통해 서로 연결될 수 있다. 통신망 은 유선 통신망이거나 무선 통신망일 수 있다. 예를 들어, 통신망은 LANs(Local Area Networks), WANs(Wide Area Networks) 또는 MANs(Metropolitan Area Networks), ISDNs(Integrated Service Digital Networks) 등의 유선 네트워크이거나, 무선 LANs, CDMA, 블루투스 또는 위성 통신 등의 무선 네트워크를 포함할 수 있다. 그러나, 본 발명의 통신망이 이에 한정되는 것은 아니며 관리 서버, 감시 장치 및 모 니터링 장치는 다양한 형태의 통신망에 의해 서로 통신을 수행할 수 있다. 도 2는 관리 서버의 블록도이고, 도 3은 인공지능 프로세서의 블록도이다. 도 2를 참조하면, 관리 서버는 통신부, 저장부, 제어부, 인공지능 프로세서 및 입력 부를 포함하여 구성된다. 통신부는 감시 장치로부터 촬영 영상을 수신하고, 모니터링 장치로 촬영 영상을 송신할 수 있다. 또한, 통신부는 감시 장치로 인공지능 모델을 송신할 수 있다. 저장부는 감시 장치로부터 수신된 촬영 영상을 저장할 수 있다. 또한, 저장부는 인공지능 프로 세서에 의해 생성된 인공지능 모델을 저장할 수 있다. 구체적으로, 저장부는 후술하는 인공지능 프로 세서의 동작에 필요한 각종 프로그램 및 데이터를 저장할 수 있다. 저장부는 비휘발성 메모리, 휘발 성 메모리, 플래시 메모리, 하드디스크 드라이브(HDD), 솔리드 스테이트 드라이브(SDD) 등으로 구현된다. 저장 부는 인공지능 프로세서에 의해 액세스되고, 인공지능 프로세서에 의한 데이터 읽기, 쓰기, 편 집, 삭제, 갱신이 수행될 수 있다. 또한, 저장부는 본 발명의 일 실시예에 따른 데이터 분류 및 인식을 위 한 학습 알고리즘을 통해 생성된 신경망 모델(예: 딥 러닝 모델)을 저장할 수 있다. 입력부는 인공지능 모델의 학습에 필요한 데이터를 입력 받을 수 있다. 또는, 입력부는 새로운 인공 지능 모델 또는 인공지능 알고리즘을 입력 받을 수도 있다.인공지능 프로세서는 인공지능 모델을 생성하고, 생성된 인공지능 모델에 대한 갱신을 수행할 수 있다. 인 공지능 프로세서는 신경망을 학습할 수 있는 컴퓨팅 장치로서, 서버, 데스크탑 PC, 노트북 PC, 태블릿 PC 등 다양한 전자 장치의 형태로 구현될 수 있다. 인공지능 프로세서는 저장부에 저장된 프로그램을 이용하여 신경망(neural network)을 학습할 수 있 다. 특히, 인공지능 프로세서는 감시 장치에 의한 감시 관련 데이터를 인식하기 위한 신경망을 학습 할 수 있다. 여기서, 감시 관련 데이터를 인식하기 위한 신경망은 컴퓨터 상에서 인간의 뇌 구조를 모사 (simulation)하도록 설계될 수 있으며, 인간 신경망의 뉴런을 모사하는 가중치를 갖는 복수의 네트워크 노드를 포함할 수 있다. 복수의 네트워크 노드는 각각의 연결 관계에 따라 데이터를 교환하여 뉴런이 시냅스를 통해 신 호를 주고받는 뉴런의 시냅스 활동을 모사할 수 있다. 여기서, 신경망은 신경망 모델로부터 개발된 딥 러닝 (Deep Learning) 모델을 포함할 수 있다. 딥 러닝 모델에서 복수의 네트워크 노드는 서로 다른 계층에 위치하여 컨볼루션(convolution) 연결 관계에 따라 데이터를 교환할 수 있다. 신경망 모델의 예로는 심층 신경망(DNN; Deep Neural Network), 컨볼루션 심층 신경망(CNN; Convolutional Neural Network), 순환 신경망(RNN; Recurrent Neural Network), 제한적 볼츠만 기계(RBM; Restricted Boltzmann Machine), 심층신뢰신경망(DBN; Deep Belief Network)이 포함될 수 있다. 이와 같은 기능을 수행하는 인공지능 프로세서는 범용 프로세서(예: CPU)일 수 있으나, 인공지능 학습을 위한 인공지능 전용 프로세서(예: GPU)일 수도 있다. 도 3을 참조하면, 인공지능 프로세서는 데이터 학습부를 포함하여 구성된다. 데이터 학습부는 데이터의 분류 및 인식을 위한 신경망 학습을 수행할 수 있다. 데이터 학습부는 데 이터의 분류 및 인식을 결정하기 위해 어떤 학습 데이터를 사용할 것인지, 그리고 학습 데이터를 이용하여 데이 터를 어떻게 분류하고 인식하는지에 대한 기준을 학습할 수 있다. 데이터 학습부는 학습에 사용할 학습 데 이터를 획득하고, 획득된 학습 데이터를 딥 러닝 모델에 적용하여 딥 러닝 모델을 학습할 수 있다. 데이터 학습부는 적어도 하나의 하드웨어 칩 형태로 제작되어 인공지능 프로세서에 탑재될 수 있다. 예를 들어, 데이터 학습부는 인공지능 전용 하드웨어 칩 형태로 제작되거나, 범용 프로세서(CPU) 또는 전 용 그래픽 프로세서(GPU)의 일부로 제작되어 인공지능 프로세서에 탑재될 수 있다. 또한, 데이터 학습부 는 소프트웨어로 구현될 수 있다. 데이터 학습부가 소프트웨어 모듈(또는 명령어를 포함하는 프로그 램 모듈)로 구현되는 경우, 소프트웨어 모듈은 저장부 또는 별도의 컴퓨터 판독 가능 매체에 저장될 수 있 다. 이러한 경우 적어도 하나의 소프트웨어 모듈은 운영체제(OS; Operating System) 또는 애플리케이션에 의해 실행된다. 데이터 학습부는 데이터 획득부(141a), 모델 학습부(141b) 및 모델 평가부(141c)를 포함하여 구성된다. 데이터 획득부(141a)는 데이터의 분류 및 인식을 위한 신경망 모델에 대해 요청된 학습 데이터를 획득할 수 있 다. 예를 들어, 데이터 획득부(141a)는 신경망 모델에 학습 데이터로 입력하기 위한 감시 관련 데이터 및 샘플 데이터 중 적어도 하나를 획득할 수 있다. 데이터 획득부(141a)에 의해 획득된 데이터는 입력부를 통해 입 력된 것이거나 통신부를 통해 수신된 것일 수 있다. 모델 학습부(141b)는 데이터 획득부(141a)에 의해 획득된 학습 데이터를 이용하여 신경망 모델이 데이터를 어떻 게 분류하는지 판단하는 기준을 갖도록 학습할 수 있다. 이 경우, 모델 학습부(141b)는 학습 데이터의 적어도 일부를 판단 기준으로 하여 지도 학습(supervised learning)을 통해 신경망 모델을 학습시킬 수 있다. 또는, 모 델 학습부(141b)는 비지도 학습을 통해 신경망 모델을 학습시켜 지도 없이 학습 데이터를 사용하여 자가 학습하 여 기준을 발견할 수 있다. 또는, 모델 학습부(141b)는 학습 기반의 상황 판단 결과가 정확한지 피드백을 이용 하여 강화 학습을 통해 신경망 모델을 학습시킬 수 있다. 또는, 모델 학습부(141b)는 오차 역전파(back- propagation) 방법 또는 그래디언트 디센트(gradient decent) 방법을 포함하는 학습 알고리즘을 이용하여 신경 망 모델을 학습시킬 수 있다. 신경망 모델이 학습되면, 모델 학습부(141b)는 학습된 신경망 모델을 저장부에 저장할 수 있다. 데이터 학습부는 학습 데이터 전처리기(미도시) 및 학습 데이터 선택부(미도시)를 더 포함하여 인식 모델 의 분석 결과를 향상시키거나 생성에 필요한 자원 또는 시간을 절약할 수 있다. 학습 데이터 전처리기는 획득된 데이터가 상황을 결정하기 위한 학습에 사용될 수 있도록 획득된 데이터를 전처 리할 수 있다. 예를 들어, 학습 데이터 전처리부는 획득된 데이터를 사전에 설정된 포맷으로 변환하여 모델 학습부(141b)가 학습을 위해 획득한 학습 데이터를 이미지 인식에 사용할 수 있도록 할 수 있다. 학습 데이터 선택부는 데이터 획득부(141a)에 의해 획득된 학습 데이터 또는 전처리기에 의해 전처리된 학습 데 이터로부터 학습에 필요한 데이터를 선택할 수 있다. 선택된 학습 데이터는 모델 학습부(141b)로 제공될 수 있 다. 예를 들어, 학습 데이터 선택부는 감시 장치를 통해 획득된 영상 중 특정 영역을 검출하여 특정 영역 에 포함된 객체에 대한 데이터만을 학습 데이터로 선택할 수 있다. 모델 평가부(141c)는 신경망 모델의 분석 결과를 향상시키는 역할을 수행한다. 모델 평가부(141c)는 평가 데이 터를 신경망 모델에 입력하고, 평가 데이터로부터 출력된 분석 결과가 사전에 설정된 기준을 만족하지 않는 경 우 모델 학습부(141b)가 신경망 모델을 재학습시키도록 할 수 있다. 이러한 경우 평가 데이터는 인식 모델을 평 가하기 위한 미리 정의된 데이터일 수 있다. 예를 들어, 모델 평가부(141c)는 평가 데이터에 대한 학습된 인식 모델의 분석 결과 중 분석 결과가 부정확한 평가 데이터의 개수 또는 비율이 사전에 설정된 기준을 초과하는 경 우 해당 모델이 그 기준을 만족하지 않는 것으로 평가할 수 있다. 이와 같은 방식으로 인공지능 프로세서는 감시를 위한 인공지능 모델을 생성할 수 있으며, 생성된 인공지 능 모델은 감시 장치에 제공될 수 있다. 또한, 인공지능 프로세서는 단일의 인공지능 모델 생성에 이 용될 수 있을 뿐만 아니라, 복수의 인공지능 모델 생성에 이용될 수 있다. 구체적으로, 인공지능 프로세서(14 0)는 객체 검출 모델 및 이상 행동 분석 모델을 동시에 및/또는 시간 차이를 두고 생성할 수 있다. 객체 검출 모델은 영상에서 객체를 검출하는데 이용되고, 이상 행동 분석 모델은 영상을 분석하여 영상에 포함된 객체의 이상 행동 여부를 판단할 수 있다. 제어부는 통신부, 저장부, 인공지능 프로세서 및 입력부에 대한 전반적인 제어를 수 행할 수 있다. 도 4는 본 발명의 실시예에 따른 감시 장치의 블록도이고, 도 5는 영상 분석부의 블록도이다. 도 4를 참조하면, 본 발명의 실시예에 따른 감시 장치는 촬영부, 저장부, 제어부, 영상 분 석부 및 통신부를 포함하여 구성된다. 촬영부는 감시 영역을 촬영하여 감시 영역에 대한 영상을 생성할 수 있다. 이를 위하여, 촬영부는 주 변 광을 수신하는 렌즈(미도시), 광 신호를 전기 신호로 변환하는 이미지 센서(미도시) 및 전기 신호를 영상 신 호로 변환하여 처리하는 영상 처리 센서(미도시)를 구비할 수 있다. 촬영부에 의해 생성되는 영상은 정지 영상 또는 동영상일 수 있다. 저장부는 촬영부에 의해 생성된 촬영 영상을 저장할 수 있다. 또한, 저장부는 통신부를 통 하여 수신된 인공지능 모델을 저장할 수 있다. 통신부는 관리 서버로 촬영 영상을 송신하고, 관리 서버로부터 인공지능 모델을 수신할 수 있다. 또한, 통신부는 모니터링 장치로 촬영 영상을 송신하거나 이상 행동 판단 결과를 송신할 수 있 다. 제어부는 촬영부, 저장부, 영상 분석부 및 통신부에 대한 전반적인 제어를 수행할 수 있다. 영상 분석부는 촬영 영상을 분석하여 객체의 이상 행동 여부를 판단할 수 있다. 이를 위하여, 영상 분석부 는 저장부에 저장된 인공지능 모델을 이용할 수 있다. 영상 분석부가 이용하는 인공지능 모델은 관리 서버로부터 제공된 것일 수 있다. 도 5를 참조하면, 영상 분석부는 객체 검출부, 객체 추적부, 제1 이상 행동 판단부 및 제2 이상 행동 판단부를 포함하여 구성된다. 객체 검출부는 영상에서 객체를 검출하는 역할을 수행한다. 이를 위하여, 객체 검출부는 객체 검출 모델을 이용할 수 있다. 예를 들어, 객체 검출부는 객체 검출 모델로서 욜로(YOLO; You Only Live Once) 알고리즘을 이용하여 영상에서 객체를 검출할 수 있다. 욜로 알고리즘은 영상에서 객체를 검출하는 속도가 상대 적으로 빠르기 때문에 실시간 동영상을 처리하는 감시 카메라에 적당한 인공지능 알고리즘이다. 욜로 알고리즘 은 Faster R-CNN, R_FCN 또는 FPN-FRCN와 같은 다른 객체 검출 알고리즘과는 다른 방식으로 동작할 수 있다. 즉, 욜로 알고리즘은 한 장의 입력 영상을 리사이즈(Resize)후 단일 신경망을 단 한 번 통과시켜 결과를 출력할 수 있다. 욜로 알고리즘에 의해 출력된 결과는 각 객체의 위치를 나타내는 바운딩 박스(Bounding Box) 및 해당객체가 무엇인지에 대한 분류 확률을 포함할 수 있다. 객체 추적부는 객체 검출부에 의해 검출된 객체를 추적하는 역할을 수행한다. 예를 들어, 객체 추적 부는 딥소트(DeepSORT) 알고리즘을 이용하여 객체를 추적할 수 있다. 객체 검출부에 의해 이용되는 욜로 알고리즘 및 객체 추적부에 의해 이용되는 딥소트 알고리즘은 경 량화된 인공지능 알고리즘으로서, 상대적으로 적은 연산량으로 영상에 포함된 객체의 검출 및 추적이 수행될 수 있다. 제1 이상 행동 판단부는 객체의 이상 행동 여부를 판단하는 역할을 수행한다. 예를 들어, 제1 이상 행동 판단부는 객체가 정상적인 자세를 취하고 있는지, 또는 비정상적인 자세를 취하고 있는지를 판단할 수 있 다. 제1 이상 행동 판단부는 영상에서 객체의 전체 몸체를 포함하는 제1 영역 및 객체의 일부 몸체를 포함하는 제2 영역 중 적어도 하나를 참조하여 객체의 이상 행동 여부를 판단할 수 있다. 예를 들어, 제1 이상 행동 판단 부는 제1 영역의 형태 또는 제2 영역의 위치를 참조하여 객체의 이상 행동 여부를 판단할 수 있다. 제1 영 역 및 제2 영역은 전술한 욜로 알고리즘이 이용되어 생성된 영역을 포함할 수 있다. 즉, 제1 영역 및 제2 영역 은 욜로 알고리즘에 의해 생성된 바운딩 박스일 수 있다. 제2 이상 행동 판단부는 학습을 통하여 생성된 이상 행동 분석 모델을 이용하여 객체의 이상 행동 여부를 판단할 수 있다. 이상 행동 분석 모델은 학습용 영상에 대한 학습이 수행되어 생성될 수 있다. 제2 이상 행동 판단부는 제1 영역에 포함된 객체에 대한 영상 데이터를 이상 행동 분석 모델에 적용하여 객체의 이상 행 동 여부를 판단할 수 있다. 예를 들어, 제1 이상 행동 판단부는 객체가 이상 해동을 수행한 것으로 판단되 는 경우 제1 영역에 포함된 객체에 대한 영상 데이터를 제2 이상 행동 판단부로 전달할 수 있다. 제2 이상 행동 판단부는 제1 이상 행동 판단부로부터 전달된 영상 데이터에 대한 분석으로 통하여 객체의 이상 행동 여부를 판단할 수 있다. 제1 이상 행동 판단부에 의한 판단 결과뿐만 아니라 제2 이상 행동 판단부 에 의한 판단 결과가 종합되어 최종적으로 객체의 이상 행동 여부가 판단될 수 있다. 이로 인하여, 최종적 인 판단 결과에 대한 신뢰도가 향상될 수 있다. 본 발명에서 객체는 사람을 포함할 수 있다. 이상 행동 분석 모델은 서 있는 사람의 영상 데이터, 앉아 있는 사 람의 영상 데이터 및 누워 있는 사람의 영상 데이터 등을 학습하여 생성될 수 있다. 한편, 객체의 이상 행동이 발생된 경우 영상 프레임별 객체의 움직임 변화가 크기 때문에 제1 영역 및 제2 영역 에 대한 신뢰도가 감소될 수 있다. 예를 들어, 서 있던 사람이 쓰러지는 경우 객체의 움직임 변화가 크게 발생 될 수 있다. 이러한 경우 객체 검출부가 정상적으로 객체를 검출하지 못할 수 있다. 객체 검출부가 정상적으로 객체를 검출하지 못하는 경우 제1 영역에 객체의 전체 몸체가 포함되지 못하거나 다른 객체의 전체 몸체 또는 일부 몸체가 포함될 수 있으며, 제1 영역에 대한 신뢰도가 감소될 수 있다. 제1 영역 및 제2 영역에 대한 신뢰도 감소를 보상하기 위하여 이상 행동 분석 모델은 관련 분포(in distribution) 데이터 및 비관련 분포(out of distribution) 데이터를 학습하여 생성될 수 있다. 여기서, 관련 분포 데이터는 객체의 정상적인 자세가 포함된 영상 데이터를 나타낸다. 예를 들어, 관련 분포 데이터는 서 있 는 객체, 앉아 있는 객체 및 누워 있는 객체에 대한 영상 데이터를 포함할 수 있다. 비관련 분포 데이터는 객체 의 자세가 명확하지 않은 영상 데이터 및 객체와는 무관한 정보를 포함하는 영상 데이터를 포함할 수 있다. 관련 분포 데이터뿐만 아니라 비관련 분포 데이터가 학습되어 이상 행동 분석 모델이 생성되기 때문에 제2 이상 행동 판단부는 다양한 환경에서 검출된 객체의 이상 행동 여부를 판단할 수 있다. 도 6은 영상에 객체가 포함된 것을 나타낸 도면이고, 도 7은 영상에서 객체가 검출된 것을 나타낸 도면이며, 도 8은 영상에서 객체가 추적되는 것을 나타낸 도면이다. 도 6 및 도 7을 참조하면, 영상은 객체를 포함할 수 있으며, 객체 검출부는 영상에 포함된 객체를 검출할 수 있다. 욜로 알고리즘을 이용하여 객체를 검출하는 객체 검출부는 객체에 제1 영역 및 제2 영역 을 설정할 수 있다. 제1 영역은 객체의 전체 몸체에 설정되고, 제2 영역은 객체의 일 부 몸체에 설정될 수 있다. 전술한 바와 같이, 본 발명에서 객체는 사람을 포함하고, 객체의 일부 몸체는 사람의 머리를 포함할 수 있다. 이러한 경우 객체 검출부는 사람의 전체 몸체에 제1 영역을 설정하고, 사람의 머리에 제2 영역을 설정할 수 있다. 도 6 및 도 7은 영상에 하나의 객체가 포함된 것을 도시하고 있으나, 영상에 복수의 객체가 포 함될 수도 있다. 이러한 경우 객체 검출부는 복수의 객체에 대한 검출을 동시에 수행할 수 있다. 도 8을 참조하면, 객체 추적부는 영상 내에서 객체를 추적할 수 있다. 객체 추적부가 객체를 추적함에 따라 객체 검출부에 의해 설정된 제1 영역 및 제2 영역 도 객체와 함께 영상 내에서 이동할 수 있다. 도 9는 제1 영역의 종횡비가 참조되어 객체의 자세가 판단되는 것을 설명하기 위한 도면이다. 도 9를 참조하면, 제1 영역의 종횡비가 참조되어 객체의 자세가 판단될 수 있다. 본 발명에서 제1 영역의 종횡비는 제1 영역의 가로 길이(H)에 대한 세로 길이(V)의 비율을 나타낸 것 일 수 있다. 예를 들어, 제1 영역의 가로 길이(H) 및 세로 길이(V)가 각각 2 및 3인 경우 제1 영역의 종횡비는 3/2=1.5일 수 있다. 도 9는 (a)는 서 있는 객체의 제1 영역을 도시하고 있고, (b)는 앉아 있는 객체의 제1 영역을 도시하고 있으며, (c)는 누워 있는 객체의 제1 영역을 도시하고 있다. 이와 같이, 서 있는 객체의 제1 영역에 비하여 앉아 있는 객체의 제1 영역의 종횡비 가 작게 형성되고, 앉아 있는 객체의 제1 영역에 비하여 누워 있는 객체의 제1 영역의 종 횡비가 작게 형성될 수 있다. 제1 이상 행동 판단부는 제1 영역의 종횡비를 참조하여 객체의 이상 행동 여부를 판단할 수 있 다. 우선, 제1 이상 행동 판단부는 제1 영역의 종횡비를 참조하여 객체의 자세를 판단할 수 있 다. 예를 들어, 제1 영역의 종횡비가 제1 임계치를 초과하는 경우 제1 이상 행동 판단부는 객체(60 0)가 서 있는 것으로 판단할 수 있다. 제1 영역의 종횡비가 제1 임계치에서 제2 임계치의 사이인 경우 제1 이상 행동 판단부는 객체가 앉아 있는 것으로 판단할 수 있다. 제1 영역의 종횡비가 제2 임계치 이하인 경우 제1 이상 행동 판단부는 객체가 누워 있는 것으로 판단할 수 있다. 객체의 자세에 대한 판단이 완료된 경우 제1 이상 행동 판단부는 객체의 자세간 변화가 사전에 설정된 시간 이내에 수행되는 경우 객체가 이상 행동을 수행한 것으로 판단할 수 있다. 예를 들어, 객체 가 서 있는 상태에서 갑자기 누운 경우 제1 이상 행동 판단부는 객체가 이상 행동을 수행한 것으로 판단할 수 있다. 또는, 제1 이상 행동 판단부는 객체의 자세간 변화가 사전에 설정된 시간 이내에 수행되는 경우 이상 행동 카운팅을 수행할 수 있다. 그리하여 이상 행동 카운팅의 수가 사전에 설정되 임계수를 초과하는 경우 제1 이상 행동 판단부는 객체가 이상 행동을 수행한 것으로 판단할 수 있다. 도 10은 제2 영역의 위치가 참조되어 객체의 자세가 판단되는 것을 설명하기 위한 도면이다. 도 10을 참조하면, 제2 영역의 위치가 참조되어 객체의 자세가 판단될 수 있다. 제1 이상 행동 판단부는 제2 영역의 기준 위치에 대한 제2 영역의 현재 위치를 참조하여 객체 의 이상 행동 여부를 판단할 수 있다. 제2 영역의 기준 위치는 객체가 서 있는 자세에서의 위치 일 수 있고, 이전 프레임에서 제2 영역의 위치일 수도 있다. 기준 위치에 존재하는 제2 영역(이하, 기준 영역이라 한다)과 현재 위치에 존재하는 제2 영역 간의 위치 관계는 기준 영역과 제2 영역 간의 거리(D1, D2) 및 각도(A1, A2)에 의해 결정될 수 있다. 기준 영역과 제 2 영역 간의 거리(D1, D2)는 기준 영역의 중심과 제2 영역의 중심 간의 거리일 수 있다. 기준 영역과 제2 영역 간의 각도(A1, A2)는 기준 영역의 중심과 제2 영역의 중심을 연결한 선과 기준선 간의 각도 일 수 있다. 여기서, 기준선은 기준 영역의 중심에서 방사상으로 형성된 선으로서 예를 들어, 기준 영역의 중심 에서 수직방향으로 하측 방향으로 형성된 선일 수 있다. 기준 영역에 대한 제2 영역의 위치를 참조하여 제1 이상 행동 판단부는 객체의 자세를 판단하고, 이를 기초로 객체의 이상 행동 여부를 판단할 수 있다. 도 11은 객체의 일부 몸체의 위치가 참조되어 객체의 자세가 판단되는 것을 설명하기 위한 도면이다. 도 11을 참조하면, 객체의 일부 몸체의 위치가 참조되어 객체의 자세가 판단될 수 있다. 제1 이상 행동 판단부는 영상에서 객체의 전체 몸체를 포함하는 제3 영역을 설정하고, 제3 영역 중 객체의 일부 몸체가 배치된 위치를 참조하여 객체의 이상 행동 여부를 판단할 수 있다. 제3 영역은 복수의 부분 영역을 포함할 수 있다. 도 11은 제3 영역이 9개의 부분 영역을 포함하고 있 는 것으로 도시하고 있으나, 이는 예시적인 것으로서 제3 영역에 포함된 부분 영역의 개수는 다양하게 결 정될 수 있다. 제1 이상 행동 판단부는 복수의 부분 영역 중 객체의 일부 몸체를 포함하고 있는 부분 영역을 참조하 여 객체의 이상 행동 여부를 판단할 수 있다. 예를 들어, 제1 이상 행동 판단부는 사람의 머리에 해 당되는 객체의 일부 몸체가 상측 부분 영역에 포함되는 경우 객체가 서 있는 것으로 판단할 수 있다. 제1 이상 행동 판단부는 객체의 일부 몸체가 중간 부분 영역에 포함되는 경우 객체가 앉아 있는 것으로 판단할 수 있다. 제1 이상 행동 판단부는 객체의 일부 몸체가 하측 부분 영역에 포함되는 경 우 객체가 누워 있는 것으로 판단할 수 있다. 제1 이상 행동 판단부는 객체의 일부 몸체가 복수 의 부분 영역에 걸쳐 포함되는 경우 객체의 일부 몸체를 대부분 포함하고 있는 부분 영역을 기초로 객체 의 자세를 판단하고, 객체의 이상 행동 여부를 판단할 수 있다. 이상은 관리 서버 및 감시 장치가 별도의 장치로 구현된 것을 도시하고 있으나, 본 발명의 몇몇 실시 예에 따르면 관리 서버 및 감시 장치는 하나의 장치로 구현될 수 있다. 또는, 관리 서버의 기능 중 적어도 일부가 감시 장치에 구비되거나, 감시 장치의 기능 중 적어도 일부가 관리 서버에 구 비될 수도 있다. 예를 들어, 감시 장치는 영상을 저장하고, 저장된 영상을 모니터링 장치로 제공할 수 있다. 또는, 감시 장치는 감시에 필요한 데이터를 학습하여 인공지능 모델을 생성할 수 있다. 이를 위하여, 감시 장치는 관리 서버의 인공지능 프로세서에 대응하는 수단을 구비할 수 있다. 이러 한 경우 감시 장치는 실시간으로 촬영된 영상을 기초로 인공지능 모델을 갱신하고, 갱신된 인공지능 모델을 이용하여 영상 분석을 수행할 수 있다. 또한, 관리 서버는 인공지능 모델을 이용하여 영상에서 객체를 검출하고, 객체를 추적하며, 객체의 이상 행동 여부를 판단할 수 있다. 이를 위하여, 관리 서버는 감시 장치의 영 상 분석부에 대응되는 수단을 구비할 수 있다. 도 12는 본 발명의 실시예에 따른 감시 방법을 나타낸 흐름도이다. 도 12를 참조하면, 감시 장치에 의한 감시 방법은 영상에서 객체를 검출하는 단계(S810), 검출 된 객체를 추적하는 단계(S820), 및 객체의 이상 행동 여부를 판단하는 단계(S830)를 포함할 수 있다. 여기서, 객체의 이상 행동 여부를 판단하는 단계는 영상에서 객체의 전체 몸체를 포함하는 제1 영역 및 객체의 일부 몸체를 포함하는 제2 영역 중 적어도 하나를 참조하여 객체의 이상 행동 여부를 판단하는 단계를 포함할 수 있다. 제1 영역 및 제2 영역은 욜로 알고리즘이 이용되어 생 성된 것으로서, 객체의 이상 행동 여부 판단은 제1 영역의 종횡비를 참조하거나, 제2 영역의 기 준 위치에 대한 제2 영역의 현재 위치를 참조하거나, 영상에서 객체의 전체 몸체를 포함하는 제 3 영역을 설정하고, 제3 영역 중 객체의 일부 몸체가 배치된 위치를 참조하여 수행될 수 있다."}
{"patent_id": "10-2022-0096051", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 첨부된 도면을 참조하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정 적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2022-0096051", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 감시 시스템을 나타낸 도면이다. 도 2는 관리 서버의 블록도이다. 도 3은 인공지능 프로세서의 블록도이다. 도 4는 본 발명의 실시예에 따른 감시 장치의 블록도이다. 도 5는 영상 분석부의 블록도이다. 도 6은 영상에 객체가 포함된 것을 나타낸 도면이다. 도 7은 영상에서 객체가 검출된 것을 나타낸 도면이다. 도 8은 영상에서 객체가 추적되는 것을 나타낸 도면이다. 도 9는 제1 영역의 종횡비가 참조되어 객체의 자세가 판단되는 것을 설명하기 위한 도면이다. 도 10은 제2 영역의 위치가 참조되어 객체의 자세가 판단되는 것을 설명하기 위한 도면이다. 도 11은 객체의 일부 몸체의 위치가 참조되어 객체의 자세가 판단되는 것을 설명하기 위한 도면이다. 도 12는 본 발명의 실시예에 따른 감시 방법을 나타낸 흐름도이다."}
