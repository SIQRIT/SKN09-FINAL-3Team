{"patent_id": "10-2022-0003468", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0108096", "출원번호": "10-2022-0003468", "발명의 명칭": "비문 인식 방법 및 장치", "출원인": "라온피플 주식회사", "발명자": "이재민"}}
{"patent_id": "10-2022-0003468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "비문 인식 장치에 의해 수행되는 비문 인식데이터 가공 방법으로서,소를 촬영한 촬영이미지를 획득하는 단계;학습된 인공지능 모델을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 보정된 비문영역을 획득하는 단계; 및상기 보정된 비문 영역에 기초하여 소의 식별정보를 제공하는 단계를 포함하는, 비문 인식 방법."}
{"patent_id": "10-2022-0003468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 보정된 비문 영역을 획득하는 단계는,학습된 인공지능 모델을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 획득된 바운딩 박스의 각 꼭짓점을 기울어지지 않은 사각형의 꼭짓점에 오도록 워핑(warping)을 수행하는 단계를 포함하는,비문 인식 방법."}
{"patent_id": "10-2022-0003468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 보정된 비문 영역을 획득하는 단계는,상기 촬영이미지 내에서의 특징점에 기초하여 상기 바운딩 박스를 롤(roll)축과 피치(pitch)축을 보정하는 단계를 포함하는, 비문 인식 방법."}
{"patent_id": "10-2022-0003468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 보정된 비문 영역을 획득하는 단계는,학습된 인공지능 모델을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 상기 바운딩박스에서의 비문 영역비율을 높이기 위해 상기 바운딩 박스를 롤(roll)축과 피치(pitch)축을 보정하는 단계를포함하는, 비문 인식 방법."}
{"patent_id": "10-2022-0003468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 보정된 비문 영역을 획득하는 단계는,학습된 인공지능 모델을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 상기 바운딩박스에서의 뎁스 맵(depth map)에 기초하여 상기 바운딩 박스의 롤(roll)축과 피치(pitch)축을 보정하는 단계를포함하는, 비문 인식 방법."}
{"patent_id": "10-2022-0003468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "비문 인식 장치에 있어서,학습된 인공지능 모델을 저장하는 메모리; 및학습된 인공지능 모델을 이용하여 획득된 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 보정된 비문 영역을 획득하고, 상기 보정된 비문 영역에 기초하여 소의 식별정보를 제공하는 제어부를 포함하는, 비문 인공개특허 10-2023-0108096-3-식 장치."}
{"patent_id": "10-2022-0003468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제어부는,학습된 인공지능 모델을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 획득된 바운딩 박스의 각 꼭짓점을 기울어지지 않은 사각형의 꼭짓점에 오도록 워핑(warping)을 수행하는, 비문 인식 장치."}
{"patent_id": "10-2022-0003468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 제어부는,상기 촬영이미지 내에서의 특징점에 기초하여 상기 바운딩 박스를 롤(roll)축과 피치(pitch)축을 보정하는, 비문 인식 장치."}
{"patent_id": "10-2022-0003468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 제어부는,학습된 인공지능 모델을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 상기 바운딩박스에서의 비문 영역비율을 높이기 위해 상기 바운딩 박스를 롤(roll)축과 피치(pitch)축을 보정하는, 비문 인식 장치."}
{"patent_id": "10-2022-0003468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서,상기 제어부는,학습된 인공지능 모델을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 상기 바운딩박스에서의 뎁스 맵(depth map)에 기초하여 상기 바운딩 박스의 롤(roll)축과 피치(pitch)축을 보정하는, 비문인식 장치."}
{"patent_id": "10-2022-0003468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항에 기재된 방법을 수행하는 프로그램이 기록된 컴퓨터 판독 가능한 기록 매체."}
{"patent_id": "10-2022-0003468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "비문 인식 장치에 의해 수행되며, 제 1 항에 기재된 방법을 수행하기 위해 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0003468", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "비문 인식 방법 및 장치를 제시하며, 비문 인식 방법 및 장치는 소를 촬영한 촬영이미지를 획득하는 단계, 학습 된 인공지능 모델을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 보정된 비문 영역 을 획득하는 단계 및 상기 보정된 비문 영역에 기초하여 소의 식별정보를 제공하는 단계를 포함한다."}
{"patent_id": "10-2022-0003468", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서에서 개시되는 실시예들은 비문 인식 방법 및 장치에 관한 것으로, 보다 상세하게는 소를 촬영한 이미 지를 인공지능 모델에 입력하여 출력된 비문 추정 이미지를 보정함으로써 비문을 검출하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0003468", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "소의 비문을 검출하는 인공지능 모델을 학습시키기 위해서는 소의 비문이 포함된 영상 데이터가 필요하다. 일반 적으로 사람이 아닌 동물은 의사소통이 불가능하기 때문에 덩치가 큰 성체의 경우에는 원하는 데이터를 얻기 위 한 환경 제어가 어렵다. 또한, 축사에서 관리되는 소의 경우 겁이 많은 특징이 있어, 가까이서 촬영된 고품질영상 데이터는 취득하기 더욱 어렵다는 문제점이 있다. 따라서 수집된 데이터는 주로 소와 최소 거리를 어느정 도 확보한 상태에서 촬영한 영상이 많으며, 이 경우 수집된 데이터는, 비문을 제외한 신체의 일부 등의 영상 데 이터가 된다. 이러한 이미지를 입력으로 인공지능 모델을 학습하게 되면, 비문이 아닌 다른 신체 부위의 특징을 활용하여 개체를 인식하게 될 가능성을 배제할 수 없다. 이 경우에도 개체 인식을 위한 시스템으로서 목적은 달 성할 수 있으나 인식에 활용되는 부위의 통일성이 없어져 자동화가 어려워지며, 또한 비문 외의 신체 부위는 성 장이나 환경에 따라 시각적 특징이 쉽게 변할 수 있기 때문에 인식부위로서 바람직하지 않다. 관련하여 선행기술 문헌인 한국특허등록번호 제10-2226544호에서는 비문을 선명하고 입체적으로 획득하는 비문 촬영 장치에 대해 기재하고 있다. 그러나 선행기술에서는 이미지를 획득하기 위해 동물을 촬영장치 내로 들어오 도록 유인하는데 이러한 유인이 실패한다면 비문에 관한 정확한 정보를 얻어내기 어렵다는 문제점이 있다. 따라서 상술된 문제점을 해결하기 위한 기술이 필요하게 되었다."}
{"patent_id": "10-2022-0003468", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "한편, 전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다."}
{"patent_id": "10-2022-0003468", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 명세서에서 개시되는 실시예들은, 비문 인식 방법 및 장치를 제시하는데 목적이 있다. 본 명세서에서 개시되는 실시예들은, 소를 촬영한 이미지를 인공지능 모델에 입력하여 획득된 이미지 내에서 비 문 영역을 바운딩 박스로 검출하는 비문 인식 방법 및 장치를 제시하는데 목적이 있다. 본 명세서에 개시되는 실시예들은, 검출된 바운딩 박스 또는 촬영이미지를 보정함으로써 보다 정확한 비문 정보 를 획득할 수 있도록 하는 비문 인식 방법 및 장치를 제시하는데 목적이 있다."}
{"patent_id": "10-2022-0003468", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 일 실시예에 따르면, 비문 인식 방법은, 소를 촬영한 촬영이미지를 획득하는 단계, 학습된 인공지능 모델을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 상기 보정된 비문 영역을 획득하는 단계 및 보정된 비문 영역에 기초하여 소의 식별정보를 제 공하는 단계를 포함할 수 있다. 다른 실시예에 따르면, 비문 인식 장치는, 학습된 인공지능 모델을 저장하는 메모리 및 학습된 인공지능 모델을 이용하여 획득된 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 보정된 비문 영역을 획득하고, 상 기 보정된 비문 영역에 기초하여 소의 식별정보를 제공하는 제어부를 포함할 수 있다. 또 다른 실시예에 따르면, 비문 인식 방법을 수행하는 프로그램이 기록된 컴퓨터 판독 가능한 기록매체에서, 비 문 인식 방법은, 소를 촬영한 촬영이미지를 획득하는 단계, 학습된 인공지능 모델을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 상기 보정된 비문 영역을 획득하는 단계 및 보정된 비문 영역에 기초하여 소의 식별정보를 제공하는 단계를 포함할 수 있다. 그리고 또 다른 실시예에 따르면, 비문 인식 방법에 의해 수행되면, 비문 인식 방법을 수행하기 위해 매체에 저 장된 컴퓨터 프로그램에서, 비문 인식 방법은, 소를 촬영한 촬영이미지를 획득하는 단계, 학습된 인공지능 모델 을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 상기 보정된 비문 영역을 획득하 는 단계 및 보정된 비문 영역에 기초하여 소의 식별정보를 제공하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0003468", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 과제 해결 수단 중 어느 하나에 의하면, 비문 인식 방법 및 장치를 제시할 수 있다. 전술한 과제 해결 수단 중 어느 하나에 의하면, 소를 촬영한 촬영이미지를 인공지능 모델에 입력하여 획득된 이 미지 내에서 비문 영역을 바운딩 박스로 검출하는 비문 인식 방법 및 장치를 제시할 수 있다. 전술한 과제 해결 수단 중 어느 하나에 의하면, 검출된 바운딩 박스 또는 촬영이미지를 보정함으로써 보다 정확 한 비문 정보를 획득할 수 있도록 하는 비문 인식 방법 및 장치를 제시할 수 있다."}
{"patent_id": "10-2022-0003468", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "개시되는 실시예들에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다 른 효과들은 아래의 기재로부터 개시되는 실시예들이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0003468", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 다양한 실시예들을 상세히 설명한다. 아래에서 설명되는 실시예들은 여러 가지 상이한 형태로 변형되어 실시될 수도 있다. 실시예들의 특징을 보다 명확히 설명하기 위하여, 이하의 실시"}
{"patent_id": "10-2022-0003468", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예들이 속하는 기술분야에서 통상의 지식을 가진 자에게 널리 알려져 있는 사항들에 관해서 자세한 설명은 생략 하였다. 그리고, 도면에서 실시예들의 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부 분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 구성이 다른 구성과 \"연결\"되어 있다고 할 때, 이는 '직접적으로 연결'되어 있는 경우뿐 아니라, '그 중간에 다른 구성을 사이에 두고 연결'되어 있는 경우도 포함한다. 또한, 어떤 구성이 어떤 구성을 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한, 그 외 다른 구성을 제외하는 것이 아니라 다른 구 성들을 더 포함할 수도 있음을 의미한다. 이하 첨부된 도면을 참고하여 실시예들을 상세히 설명하기로 한다. 다만 이를 설명하기에 앞서, 아래에서 사용되는 용어들의 의미를 먼저 정의한다. 이하에서 '비문 영역'은 촬영이미지 내의 일 영역으로서, 촬영이미지를 인공지능 모델에 입력하였을 때 바운딩 박스로 검출된 영역을 지칭한다. 위에 정의한 용어 이외에 설명이 필요한 용어는 아래에서 각각 따로 설명한다. 도 1은 일 실시예에 따른 비문 인식 장치의 구성을 도시한 도면이다. 비문 인식 장치는 소를 촬영한 이 미지로부터 비문을 검출하기 위한 장치이다. 도 1을 참조하면, 일 실시예에 따른 비문 인식 장치는, 메모리, 제어부, 입출력부 및 통신부 를 포함할 수 있다. 메모리에는 파일, 어플리케이션 및 프로그램 등과 같은 다양한 종류의 데이터가 설치 및 저장될 수 있다. 제어부는 메모리에 저장된 데이터에 접근하여 이를 이용하거나, 또는 새로운 데이터를 메모리에 저 장할 수도 있다. 또한, 제어부는 메모리에 설치된 프로그램을 실행할 수도 있다. 도 1을 참조하면, 메 모리에는 비문 인식 방법을 수행하기 위한 프로그램이 설치될 수 있다. 또한 메모리에는 인공지능 모델을 학습하기 위해 비문 이미지가 저장될 수 있다. 또한 여러 각도에서 촬영 된 비문 이미지가 업데이트되면 해당 이미지가 저장될 수 있고, 비문을 제외한 신체의 일부 혹은 전체를 포함한 이미지도 계속 업데이트하여 저장될 수 있다. 또한, 메모리는 학습된 인공지능 모델에 의해 검출된 비문 영역이 저장될 수 있다. 예를 들어 비문 영역이 바운딩 박스로 표시된 이미지가 메모리에 저장될 수 있다. 또한 메모리에는 학습된 인공지능 모델이 저장될 수 있다. 이때 인공지능 모델은 CNN(Convolution Neural Network), RNN(Recurrent Neural Network), LSTM(Long Short Term Memory), R-CNN(Region Proposal-CNN) 등일 수 있다. 또한 메모리는 비문별 소의 식별정보를 저장할 수 있다. 한편 실시예에 따른 제어부는 비문 인식 장치의 전체적인 동작을 제어하며, CPU, GPU 등과 같은 프로세 서를 포함할 수 있다. 제어부는 입출력부를 통해 수신한 사용자 입력에 대응되는 동작을 수행하도록 비 문 인식 장치에 포함된 다른 구성들을 제어할 수 있다. 일 실시예에 따르면, 촬영이미지를 획득하면 제어부는 메모리에 저장된 비문 인식 방법을 수행하는 프 로그램을 실행시켜 비문을 검출할 수 있다. 이를 위해 제어부는 소를 촬영한 촬영이미지를 획득할 수 있다. 관련하여 촬영이미지는 비문 인식 장치(1 0)에 포함된 입출력부를 통해 촬영된 영상이거나, 비문 인식 장치의 외부장치로부터 획득된 영상일 수 있으며 소를 촬영한 영상을 구성하는 이미지프레임일 수 있다. 그리고 제어부는 촬영이미지를 학습된 인공지능 모델에 입력하여 촬영이미지 내에서의 비문 영역을 바운딩 박스로 검출할 수 있다. 즉 일 실시예에 따르면 제어부는 비문 영역을 라벨링(masking)하여 라벨링 정보를 토대로 딥 러닝 기반 의미적 분할(semantic segmentation) 모델을 학습시킬 수 있고, 학습된 의미적 분할 모델 을 이용하여 촬영이미지를 입력하였을 때 촬영이미지에서의 비문 영역에 관한 바운딩 박스를 출력 결과로서 획 득할 수 있다. 또 다른 실시예에 따르면 제어부는 바운딩 박스를 검출하는데 있어서 최소 바운딩 사각형 (Minimum Bounding Rectangle) 추출 알고리즘을 이용하여 비문을 에워싸는 바운딩 박스를 검출할 수 있다. 관련하여 제어부는 바운딩 박스를 보정할 수 있는데, 예를 들어 바운딩 박스 그 자체를 보정하거나, 또는 예를 들어 촬영이미지를 요축, 롤축 및 피치축 중 적어도 하나로 보정한 이미지에서 바운딩 박스를 크롭함으로 써 바운딩 박스를 보정할 수 있다. 이하에서는 설명의 편의상, 위 예시에 따라 결과적으로 바운딩 박스(또는 바 운딩 박스 내 비문 영역)가 보정되었을 때, '바운딩 박스가 보정'되었다고 한다. 일 실시예에 따르면 검출된 바운딩 박스가 기울어진 사각형 형태로 검출될 수 있으므로, 제어부는 바운딩 박스의 요(yaw)축을 보정할 수 있다. 즉 제어부는 검출된 비문 영역에 대해 바운딩 박스 어노테이션 (annotation)을 수행한 후, 바운딩 박스의 각 꼭짓점을 기울어지지 않은 사격형의 꼭짓점에 오도록 워핑 (warping)을 수행할 수 있다. 이때 제어부는 바운딩 박스에 대한 워핑을 수행할 수 있고, 또는 원본 이미지 인 촬영이미지에 대해 워핑을 수행할 수 있다. 관련하여 도 2는 촬영이미지 내에서 비문 영역을 바운딩 박스로 검출하는 예시도이다. 도 2를 참조하면, 제어부는 촬영이미지를 학습된 인공지능 모델에 입력함으로써 촬영이미지 내에서의 비문 영역을 바운딩 박스로 검출할 수 있다. 그에 따라 도 2에서 도시된 바와 같이 제어부는 바운딩 박스가 표시된 이미지를 획득할 수 있다. 또한, 제어부는 바운딩 박스의 적어도 일 변의 기울기를 산출함으로 써 바운딩 박스가 기울어졌는지 여부를 판단할 수 있고 도 2에서 도시된 바와 같이 바운딩 박스가 기 울어져있다고 판단하면, 제어부는 바운딩 박스에 대한 워핑을 수행하여 보정된 비문 영역을 획득 하거나, 촬영이미지에 대해 워핑을 수행하고 학습된 인공지능 모델에 워핑된 이미지를 입력하여 비문에 해당되 는 영역을 바운딩 박스로 추출하고 추출된 바운딩 박스를 크롭(crop)함으로써 도 2에서 도시된 바와 같이 보정 된 비문 영역을 획득할 수 있다. 한편 제어부는 바운딩 박스를, 롤(roll)축과 피치(pitch)축으로 보정할 수 있다. 예를 들어 제어부는 롤축 및 피치축으로 바운딩 박스를 보정하거나, 또는 롤축 및 피치축으로 보정된 촬영이미지를 학습된 인공지능 모델에 입력하여 보정된 촬영이미지에서 비문 영역을 바운딩 박스로 크롭할 수 있다. 관련하여 롤축 및 피치축 은 0 또는 다른 값일 수 있으며, 예를 들어 롤축의 값으로서 30도, 그리고 피치축의 값으로서 30도를 획득하거 나, 또는 롤축의 값으로서 0도 피치축의 값으로서 30도, 또는 롤축의 값으로서 30도, 피치축의 값으로서 0도 등 일 수 있다. 일 실시예에 따르면 제어부는 촬영이미지에서의 특징점에 기초하여 롤축 및 피치축으로 보정할 수 있다. 예 를 들어 제어부는 특징점으로서 소의 눈 또는 콧구멍 등을 식별하여 롤축 및 피치축으로 보정할 수 있다. 제어부는 촬영이미지 내에서 두 눈과 콧구멍에 해당하는 특징점을 각각 직선으로 연결하고, 각 직선의 기울 기 또는 길이를 이용하여 촬영이미지 또는 바운딩 박스 내의 비문 영역을 롤(roll)축과 피치(pitch)축을 보정할 수 있다. 관련하여 도 3은 촬영이미지에서의 특징점을 기반으로 롤축 및 피치축으로 보정하는 예시도이다. 도 3을 참조하면, 제어부는 소를 촬영한 이미지 내에서 특징점을 기반으로 이미지를 롤축 및 피치축으로 보 정할 수 있다. 즉 제어부는 눈을 잇는 제1직선과 콧구멍 두 개를 잇는 제2직선 각각에 기초하여 롤축과 피치축을 보정할 수 있다. 예를 들어 제어부는 소를 촬영한 이미지를 롤축 및/또는 피치축으로 회전 시킴으로써 두 눈을 연결한 제1직선을 수평에 가깝도록 촬영이미지를 보정하고 난 이후, 보정된 이미 지에서 두 콧구멍을 연결한 제2직선이 최대 길이가 될 수 있도록 롤축 및 피치축으로 촬영이미지를 보정할 수 있다. 그에 따라 도 3에서 도시된 바와 같이 촬영이미지가 촬영이미지로 보정될 수 있다. 또는 예를 들어 제어부는, 두 눈을 연결한 제1직선이 수평에 가깝도록 촬영이미지가 보정될 수 있도록 하는 롤축 및 피치축의 값을 산출하고, 추가로 산출된 롤축 및 피치축의 값을 보정할 수 있는데, 두 콧구멍을 연결한 제2직선의 길이가 최대 길이가 되도록 촬영이미지를 보정하였을 때의 롤축 및 피치축의 값으 로 보정할 수 있다. 한편 롤축 및 피치축으로 보정하는 또 다른 실시예에 따르면, 제어부는 비문 영역 내에서의 비문 영역비율 을 최대화시킬 수 있도록 롤축 및 피치축으로 보정할 수 있다. 예를 들어 제어부는 학습된 인공지능 모델을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운딩 박스 로 획득하되, 상기 바운딩 박스에서의 비문 영역비율을 높이기 위해 상기 바운딩 박스를 있도록 롤축 및 피치축 으로 보정할 수 있다. 이때 '비문 영역비율'은 바운딩 박스 내에서, 실제 비문에 해당되는 부분이 바운딩 박스 내에서 차지하는 면적 의 비율을 의미한다. 이때 비문 영역비율은 예를 들어, 바운딩 박스 내에서 콧구멍을 제외하고 표시되는 영역을 바운딩 박스의 면적으로 나눈 값일 수 있고, 또는 바운딩 박스를 학습된 인공지능 모델에 입력하였을 때 비문으 로 세그먼테이션(segmentation)되는 영역의 면적을 산출하고 산출된 면적을 바운딩 박스의 면적으로 나눈 값일 수 있다. 제어부는 롤축 및 피치축으로 촬영이미지 또는 바운딩 박스 내 비문 영역을 보정할 때마다 비문 영역비율을 산출할 수 있고 비문 영역비율 중 최대의 값이 산출될 때의 롤축 및 피치축의 값으로, 비문 영역 또 는 촬영이미지를 보정할 수 있다. 도 4는 검출된 비문 영역에서의 비문 영역비율에 기초하여 롤축 및 피치축으로 보정하는 예시도이다. 구체적으로 도 4를 참조하면, 바운딩 박스는 보정하기 전의 촬영이미지에서 바운딩 박스를 식별하였 을 때를 도시한 것으로서, 실제 비문을 식별하였을 때 비문 영역비율을 제어부는 산출할 수 있다. 반 면, 롤축 및 피치축으로 촬영이미지을 보정하였을 때의 촬영이미지에서, 실제 비문이 바운딩 박 스 내에서 차지하는 면적이 넓어짐을 알 수 있으며 제어부는 해당 롤축 및 피치축에 따라 촬영이미지 를 보정하거나 바운딩 박스를 보정할 수 있다. 그에 따라 제어부는 도 4에서 도시된 바운딩 박스(40 2)를 획득할 수 있다. 한편 롤축 및 피치축으로 보정하는 다른 실시예에 따르면, 제어부는 비문 영역을 뎁스 맵(depth map) 으로 변환한 이미지에 기초하여 롤축 및 피치축으로 비문 영역에 관한 보정을 수행할 수 있다. 제어부는 학습된 인공지능 모델에 의해 비문 영역 내에서의 실제 비문을 뎁스 맵으로 변환할 수 있고, 또는 제어부는 비문 영역에서 소실점의 위치를 식별하여 소실점과의 상대적인 깊이값에 따라 뎁스 맵을 생성할 수 있다. 도 5를 참조하면, 촬영이미지에서 바운딩 박스를 식별하였을 때 제어부는 실제 비문을 식별 하고 식별된 실제 비문에 관한 뎁스 맵을 이용하여 실제 비문 영역 내의 깊이 값의 평균 및 표준 편차를 산출할 수 있다. 반면, 제어부는 실제 비문 영역 내의 깊이 값의 평균 및 표준 편차가 최소화되도록 롤축 및 피치축에 촬영이미지를 보정하였을 때의 롤축 및 피치축 값에 따라 촬영이미지 또는 바운딩 박스 를 보정할 수 있다. 그에 따라 도 5에서 도시된 바와 같이, 제어부는 촬영이미지가 촬영이미지로 보정되었을 때의 롤축 및 피치축 값을 산출하고 산출된 롤축 및 피치축 값에 따라 바운딩 박스를 보정하여 바운딩 박스를 획득하거나, 롤축 및 피치축 값에 따라 촬영이미지를 보정하고 보정된 촬영이미지 에서 크롭하여 비문 영역에 관한 바운딩 박스를 획득할 수 있다. 상술된 바에 따라 제어부는 바운딩 박스를, 롤(roll)축과 피치(pitch)축으로 보정할 수 있다. 한편 실시예에 따르면 제어부는 바운딩 박스를 요축으로 보정하고, 요축으로 보정된 바운딩 박스를 롤축 및 피치축으로 보정할 수 있다. 예를 들어 도 2에서 도시된 바와 같이 요축으로 보정된 바운딩 박스를, 도 3에서 도시된 바에 따라 산출된 롤축 및 피치축에 따라 보정하거나, 또는 요축으로 보정된 촬영이미지를, 롤축 및 피치축에 따라 보정한 이후 바운딩 박스를 크롭할 수 있다. 또한 예를 들어 도 5에서 도시된 바와 같이 제어부는 요축으로 보정된 바운 딩 박스에서의 뎁스 맵을 이용하여, 비문 영역에서의 깊이 값의 평균 및 표준 편차를 낮추기 위한 바운딩 박스의 기울기를 설정하며, 설정된 바운딩 박스의 기울기에 따라 비문 영역의 롤(roll)축과 피치(pitch)축을 보 정할 수 있다. 또한 예를 들어 요축으로 보정된 바운딩 박스에서의 비문 영역비율을 이용하여, 비문 영역 에서의 실제 비문이 차지하는 면적이 최대가 되도록 하는 롤축 및 피치축을 산출하여 산출된 롤축 및 피치축에따라 비문 영역을 보정하거나 촬영이미지를 보정하고 비문 영역을 크롭할 수 있다. 또 다른 실시예에 따르면 제어부는 바운딩 박스를 롤축 및 피치축으로 보정하고, 보정된 바운딩 박스를 요 축으로 보정할 수 있다. 예를 들어 제어부는 상술된 실시예에 따라 롤축 및 피치축으로 보정된 촬영이미지에서, 바운딩 박스를 식별 하고 식별된 바운딩 박스를 워핑을 통해 요축으로 보정할 수 있다. 상술된 바에 따라 3차원으로 바운딩 박스를 보정함으로써 비문 인식 장치는 비문에 관한 이미지를 선명하게 획득할 수 있고 해당 이미지를 이용하여 비문에 따른 소 개체 인식율을 높일 수 있다. 그에 따라 비문 인식 장 치는 소를 촬영한 영상으로부터 비문을 식별하여, 비문별 소의 식별정보를 저장하는 메모리를 참조하여 소의 식별정보를 제공할 수 있다. 아울러 종래 기술에 따르면, 인공지능 모델 학습에 있어 비문을 학습시킬 때, 비문을 관심 영역으로 하여 바운 딩 박스로 어노테이션(annotation)하는 작업을 데이터 가공 과정에 포함할 필요가 있는데, 위 과정은 단순한 색 분리로 자동화할 수 없기 때문에 수작업으로 어노테이션(annotation)할 수밖에 없어, 데이터 가공 프로세스를 포함하여 총 개발 기간에 큰 영향을 준다. 그러나 상술된 바에 따른 비문 인식 장치에 따르면 어노테이션 비용을 절감할 수 있고, 영상 데이터 수집의 난이도를 낮출 수 있다. 한편 다시 도 1로 돌아와서, 실시예에 따르면 입출력부는 사용자로부터 입력을 수신하기 위한 입력부와, 작 업의 수행 결과 또는 비문 인식 장치의 상태 등의 정보를 표시하기 위한 출력부를 포함할 수 있다. 예를 들 어, 입출력부는 사용자 입력을 수신하는 조작 패널(operation panel) 및 화면을 표시하는 디스플레이 패널 (display panel) 등을 포함할 수 있다. 구체적으로, 입력부는 키보드, 물리 버튼, 터치 스크린, 카메라 또는 마이크 등과 같이 다양한 형태의 사용자 입력을 수신할 수 있는 장치들을 포함할 수 있다. 또한, 출력부는 디스플레이 패널 또는 스피커 등을 포함할 수 있다. 다만, 이에 한정되지 않고 입출력부는 다양한 입출력을 지원하는 구성을 포함할 수 있다. 실시예에 따르면 입력부는 소를 촬영할 수 있고 출력부는 인식된 비문에 기초하여 소를 식별하는 식별정보를 제 공할 수 있다. 한편, 실시예에 따르면 통신부는 다른 디바이스 또는 네트워크와 유무선 통신을 수행할 수 있다. 이를 위해, 통신부는 다양한 유무선 통신 방법 중 적어도 하나를 지원하는 통신 모듈을 포함할 수 있다. 예를 들 어, 통신 모듈은 칩셋(chipset)의 형태로 구현될 수 있다. 통신부가 지원하는 무선 통신은, 예를 들어 Wi-Fi(Wireless Fidelity), Wi-Fi Direct, 블루투스 (Bluetooth), UWB(Ultra Wide Band) 또는 NFC(Near Field Communication) 등일 수 있다. 또한, 통신부가 지원하는 유선 통신은, 예를 들어 USB 또는 HDMI(High Definition Multimedia Interface) 등일 수 있다. 실시예에 따르면 통신부는 다른 디바이스 또는 촬영장치와 통신하여 촬영이미지를 획득할 수 있다. 한편 도 6는 일 실시예에 따른 비문 인식 방법을 설명하기 위한 순서도이다. 도 6에 도시된 실시예에 따른 비문 인식 방법은 도 1 내지 도 5에 도시된 비문 인식 장치에서 시계열적으로 처리되는 단계들을 포함한다. 따라서, 이하에서 생략된 내용이라고 하더라도 도 1 내지 도 5에 도시된 비문 인 식 장치에 관하여 이상에서 기술한 내용은 도 6에 도시된 실시예에 따른 비문 인식 방법에도 적용될 수 있 다. 도 6를 참조하면, 비문 인식 장치는 소를 촬영한 촬영이미지를 획득할 수 있다(S601). 그리고 비문 인식 장치는 학습된 인공지능 모델을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 보정된 비문 영역을 획득할 수 있다 (S602). 예를 들어 비문 인식 장치는 학습된 인공지능 모델을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운 딩 박스로 획득하되, 획득된 바운딩 박스의 각 꼭짓점을 기울어지지 않은 사각형의 꼭짓점에 오도록 워핑 (warping)을 수행할 수 있다. 또한 예를 들어 비문 인식 장치는 촬영이미지 내에서의 특징점에 기초하여 상기 바운딩 박스를 롤축과 피치 축으로 보정할 수 있다. 또한 예를 들어 비문 인식 장치는 학습된 인공지능 모델을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 상기 바운딩 박스에서의 비문 영역비율을 높이기 위해 바운딩 박스를 롤축과 피치축으 로 보정할 수 있다. 또한 예를 들어 비문 인식 장치는 학습된 인공지능 모델을 이용하여 상기 촬영이미지 내에서의 비문 영역을 바운딩 박스로 획득하되, 상기 바운딩 박스에서의 뎁스 맵(depth map)에 기초하여 바운딩 박스를 롤축과 피치축 으로 보정할 수 있다. 관련하여 비문 인식 장치는 바운딩 박스를 요축으로 보정한 이후 롤축과 피치축을 보정할 수 있고, 또는 롤 축과 피치축으로 보정된 바운딩 박스를 요축으로 보정할 수 있다. 이후 비문 인식 장치는 보정된 비문 영역에 기초하여 소의 식별정보를 제공할 수 있으며, 예를 들어 비문별 소의 식별정보를 저장하는 메모리를 참조하여 소의 식별정보를 제공할 수 있다(S603). 이상의 실시예들에서 사용되는 '~부'라는 용어는 소프트웨어 또는 FPGA(field programmable gate array) 또는 ASIC 와 같은 하드웨어 구성요소를 의미하며, '~부'는 어떤 역할들을 수행한다. 그렇지만 '~부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '~부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구 성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프 로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램특허 코드의 세그먼트들, 드라이버들, 펌웨어, 마 이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들, 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '~부'들로 결합되거나 추가적인 구 성요소들과 '~부'들로부터 분리될 수 있다. 뿐만 아니라, 구성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 CPU 들을 재생시키도록 구현될 수도 있다. 도 6을 통해 설명된 실시예에 따른 비문 인식 방법은 컴퓨터에 의해 실행 가능한 명령어 및 데이터를 저장하는, 컴퓨터로 판독 가능한 매체의 형태로도 구현될 수 있다. 이때, 명령어 및 데이터는 프로그램 코드의 형태로 저 장될 수 있으며, 프로세서에 의해 실행되었을 때, 소정의 프로그램 모듈을 생성하여 소정의 동작을 수행할 수 있다. 또한, 컴퓨터로 판독 가능한 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발 성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터로 판독 가능한 매체는 컴퓨터 기록 매체일 수 있는데, 컴퓨터 기록 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함할 수 있다. 예를 들어, 컴퓨터 기록 매체는 HDD 및 SSD 등과 같은 마그네틱 저장 매체, CD, DVD 및 블루레이 디스크 등과 같은 광학적 기록 매체, 또는 네트워크를 통해 접근 가능한 서버에 포함되는 메모 리일 수 있다. 또한 도 6을 통해 설명된 실시예에 따른 비문 인식 방법은 컴퓨터에 의해 실행 가능한 명령어를 포함하는 컴퓨 터 프로그램(또는 컴퓨터 프로그램 제품)으로 구현될 수도 있다. 컴퓨터 프로그램은 프로세서에 의해 처리되는 프로그래밍 가능한 기계 명령어를 포함하고, 고레벨 프로그래밍 언어(High-level Programming Language), 객체 지향 프로그래밍 언어(Object-oriented Programming Language), 어셈블리 언어 또는 기계 언어 등으로 구현될 수 있다. 또한 컴퓨터 프로그램은 유형의 컴퓨터 판독가능 기록매체(예를 들어, 메모리, 하드디스크, 자기/광학 매체 또는 SSD(Solid-State Drive) 등)에 기록될 수 있다. 따라서 도 6을 통해 설명된 실시예에 따른 비문 인식 방법은 상술한 바와 같은 컴퓨터 프로그램이 컴퓨팅 장치 에 의해 실행됨으로써 구현될 수 있다. 컴퓨팅 장치는 프로세서와, 메모리와, 저장 장치와, 메모리 및 고속 확 장포트에 접속하고 있는 고속 인터페이스와, 저속 버스와 저장 장치에 접속하고 있는 저속 인터페이스 중 적어 도 일부를 포함할 수 있다. 이러한 성분들 각각은 다양한 버스를 이용하여 서로 접속되어 있으며, 공통 머더보 드에 탑재되거나 다른 적절한 방식으로 장착될 수 있다. 여기서 프로세서는 컴퓨팅 장치 내에서 명령어를 처리할 수 있는데, 이런 명령어로는, 예컨대 고속 인터페이스 에 접속된 디스플레이처럼 외부 입력, 출력 장치상에 GUI(Graphic User Interface)를 제공하기 위한 그래픽 정 보를 표시하기 위해 메모리나 저장 장치에 저장된 명령어를 들 수 있다. 다른 실시예로서, 다수의 프로세서 및 (또는) 다수의 버스가 적절히 다수의 메모리 및 메모리 형태와 함께 이용될 수 있다. 또한 프로세서는 독립적인 다수의 아날로그 및(또는) 디지털 프로세서를 포함하는 칩들이 이루는 칩셋으로 구현될 수 있다.또한 메모리는 컴퓨팅 장치 내에서 정보를 저장한다. 일례로, 메모리는 휘발성 메모리 유닛 또는 그들의 집합으 로 구성될 수 있다. 다른 예로, 메모리는 비휘발성 메모리 유닛 또는 그들의 집합으로 구성될 수 있다. 또한 메 모리는 예컨대, 자기 혹은 광 디스크와 같이 다른 형태의 컴퓨터 판독 가능한 매체일 수도 있다. 그리고 저장장치는 컴퓨팅 장치에게 대용량의 저장공간을 제공할 수 있다. 저장 장치는 컴퓨터 판독 가능한 매 체이거나 이런 매체를 포함하는 구성일 수 있으며, 예를 들어 SAN(Storage Area Network) 내의 장치들이나 다른 구성도 포함할 수 있고, 플로피 디스크 장치, 하드 디스크 장치, 광 디스크 장치, 혹은 테이프 장치, 플래시 메 모리, 그와 유사한 다른 반도체 메모리 장치 혹은 장치 어레이일 수 있다."}
{"patent_id": "10-2022-0003468", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상술된 실시예들은 예시를 위한 것이며, 상술된 실시예들이 속하는 기술분야의 통상의 지식을 가진 자는 상술된 실시예들이 갖는 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하 다는 것을 이해할 수 있을 것이다. 그러므로 상술된 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마 찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 명세서를 통해 보호받고자 하는 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지 며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태를 포함하 는 것으로 해석되어야 한다."}
{"patent_id": "10-2022-0003468", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 비문 인식 장치를 도시한 블록도이다. 도 2 내지 도 5는 일 실시예에 따른 비문 인식 장치를 설명하기 위한 예시도이다. 도 6은 일 실시예에 따른 비문 인식 방법을 설명하기 위한 순서도이다."}
