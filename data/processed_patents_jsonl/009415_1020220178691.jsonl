{"patent_id": "10-2022-0178691", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0054133", "출원번호": "10-2022-0178691", "발명의 명칭": "인공 지능 모델의 학습을 위한 훈련용 데이터를 생성하는 방법 및 전자 장치", "출원인": "삼성전자주식회사", "발명자": "이상훈"}}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 지능 모델의 학습을 위한 훈련용 데이터를 생성하는 방법에 있어서,학습 대상에 해당하는 객체를 포함하는 제1 이미지를 획득하는 단계;상기 제1 이미지와 동일한 시점에서 촬영된 제2 이미지에 기초하여, 상기 객체를 포함하지 않는 배경 이미지를획득하는 단계;상기 제1 이미지 내에서 상기 객체를 포함하는 관심 영역을 식별하는 단계;상기 배경 이미지로부터 상기 관심 영역에 해당하는 관심 영역 이미지를 획득하는 단계;기생성된 원본 훈련용 데이터 중에서, 상기 관심 영역 이미지의 너비와 높이의 비율에 기초하여 결정된 상기 객체의 컨텍스트에 대응되는, 제1 목표 훈련용 데이터를 결정하는 단계; 및상기 관심 영역 이미지에 기초하여, 상기 제1 목표 훈련용 데이터에 포함된 제1 훈련용 이미지를 수정함으로써,상기 배경 이미지의 적어도 일부가 포함된 합성 훈련용 데이터를 생성하는 단계를 포함하는, 훈련용 데이터 생성 방법."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 소정의 배경을 포함하는 이미지 및 상기 제1 목표 훈련용 데이터에 기초하여 생성된 제1 테스트 이미지와 상기배경 이미지 및 상기 제1 목표 훈련용 데이터에 기초하여 생성된 제2 테스트 이미지를 이용하여, 상기 인공 지능 모델의 예측 정확도를 결정하는 단계; 및상기 제1 테스트 이미지에 대한 제1 예측 정확도 및 상기 제2 테스트 이미지에 대한 제2 예측 정확도에 기초하여, 추가 합성 훈련용 데이터를 생성하는 단계를 더 포함하는, 훈련용 데이터 생성 방법."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 추가 합성 훈련용 데이터를 생성하는 단계는상기 제1 예측 정확도가 소정의 값보다 크거나 같고, 상기 제2 예측 정확도가 상기 소정의 값보다 작은 것에 기초하여, 상기 원본 훈련용 데이터 중에서 제2 목표 훈련용 데이터를 결정하는 단계; 및상기 관심 영역 이미지에 기초하여, 상기 제2 목표 훈련용 데이터에 포함된 제2 훈련용 이미지를 수정함으로써,추가 합성 훈련용 데이터를 생성하는 단계를 포함하는, 훈련용 데이터 생성 방법."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항 내지 제3항 중 어느 한 항에 있어서, 상기 추가 합성 훈련용 데이터를 생성하는 단계는 상기 제1 예측 정확도 및 상기 제2 예측 정확도가 소정의 값보다 작은 것에 기초하여, 상기 배경 이미지로부터상기 관심 영역 이미지의 높이 및 너비와 동일한 추가 관심 영역 이미지를 획득하는 단계;상기 추가 관심 영역 이미지에 기초하여, 상기 제1 훈련용 이미지를 수정함으로써, 추가 합성 훈련용 데이터를공개특허 10-2024-0054133-3-생성하는 단계를 포함하는, 훈련용 데이터 생성 방법."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서,상기 합성 훈련용 데이터를 생성하는 단계는,상기 관심 영역 이미지의 색상 정보 또는 밝기 정보 중 적어도 하나를 획득하는 단계;상기 관심 영역 이미지의 색상 정보 또는 밝기 정보 중 적어도 하나에 기초하여 상기 제1 훈련용 이미지의 색상또는 밝기 중 적어도 하나를 수정하는 단계; 및상기 관심 영역 이미지에 기초하여, 상기 수정된 제1 훈련용 이미지를 수정함으로써, 상기 합성 훈련용 데이터를 생성하는 단계를 포함하는, 훈련용 데이터 생성 방법."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항 중 어느 한 항에 있어서,상기 제1 목표 훈련용 데이터를 결정하는 단계는,상기 관심 영역 이미지에 기초하여, 상기 관심 영역에 관한 제1 컨텍스트 정보를 획득하는 단계;전자 장치의 상태에 관한 제2 컨텍스트 정보를 획득하는 단계;상기 제1 컨텍스트 정보, 상기 제2 컨텍스트 정보 및 상기 배경 이미지의 너비와 높이의 비율에 기초하여, 상기객체의 컨텍스트를 결정하는 단계; 및상기 원본 훈련용 데이터 중에서 상기 객체의 컨텍스트에 대응되는 상기 제1 목표 훈련용 데이터를 결정하는 단계를 포함하는, 훈련용 데이터 생성 방법."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서,상기 관심 영역을 식별하는 단계는,상기 제1 이미지와 상기 배경 이미지 사이의 잔차 이미지를 획득하는 단계; 및 상기 잔차 이미지에 기초하여 상기 관심 영역을 식별하는 단계를 포함하는, 훈련용 데이터 생성 방법."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서, 상기 합성 훈련용 데이터를 생성하는 단계는, 상기 제1 훈련용 이미지에 포함된 상기 객체에 해당하는 객체 이미지를 추출하는 단계; 및상기 관심 영역 이미지와 상기 객체 이미지를 합성함으로써 생성된 합성 훈련용 이미지를 포함하는 상기 합성훈련용 데이터를 생성하는 단계를 포함하는, 훈련용 데이터 생성 방법."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서, 공개특허 10-2024-0054133-4-상기 객체를 포함하는 제3 이미지를 획득하는 단계;상기 제3 이미지부터 상기 객체에 대한 객체 이미지를 획득하는 단계;상기 객체 이미지 및 상기 배경 이미지에 기초하여, 실측 합성 훈련용 이미지를 생성하는 단계;상기 제3 이미지를 상기 인공 지능 모델에 입력함으로써, 상기 제3 이미지에 포함된 상기 객체에 관한 예측 데이터를 획득하는 단계; 및상기 실측 합성 훈련용 이미지와 상기 예측 데이터에 기초하여, 상기 객체에 관한 실측 합성 훈련용 데이터를생성하는 단계를 더 포함하는, 훈련용 데이터 생성 방법."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항 내지 제9항 중 어느 한 항에 있어서,상기 인공 지능 모델은 포즈 추정 모델, 객체 탐지 모델, 또는 객체 분류 모델 중 적어도 하나를 포함하고,상기 객체는 사람, 동물, 또는 사물 중 적어도 하나를 포함하는 것을 특징으로 하는, 훈련용 데이터 생성 방법."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "인공 지능 모델의 학습을 위한 훈련용 데이터를 생성하는 전자 장치에 있어서,적어도 하나의 프로세서(1420); 및적어도 하나의 인스트럭션을 저장하는 메모리(1410)를 포함하고,상기 적어도 하나의 프로세서(1420)가 상기 적어도 하나의 인스트럭션을 실행함으로써, 학습 대상에 해당하는 객체를 포함하는 제1 이미지를 획득하고,상기 제1 이미지와 동일한 시점에서 촬영된 제2 이미지에 기초하여, 상기 객체를 포함하지 않는 배경 이미지를획득하고,상기 제1 이미지 내에서 상기 객체를 포함하는 관심 영역을 식별하고,상기 배경 이미지로부터 상기 관심 영역에 해당하는 관심 영역 이미지를 획득하고,기생성된 원본 훈련용 데이터 중에서, 상기 관심 영역 이미지의 너비와 높이의 비율에 기초하여 결정된 상기 객체의 컨텍스트에 대응되는 제1 목표 훈련용 데이터를 결정하고,상기 관심 영역 이미지에 기초하여, 상기 제1 목표 훈련용 데이터에 포함된 제1 훈련용 이미지를 수정함으로써,상기 배경 이미지의 적어도 일부가 포함된 합성 훈련용 데이터를 생성하는, 전자 장치."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 적어도 하나의 프로세서(1420)가 상기 적어도 하나의 인스트럭션을 실행함으로써, 소정의 배경을 포함하는 이미지 및 상기 제1 목표 훈련용 데이터에 기초하여 생성된 제1 테스트 이미지와 상기배경 이미지 및 상기 제1 목표 훈련용 데이터에 기초하여 생성된 제2 테스트 이미지를 이용하여, 상기 인공 지능 모델의 예측 정확도를 결정하고,상기 제1 테스트 이미지에 대한 제1 예측 정확도 및 상기 제2 테스트 이미지에 대한 제2 예측 정확도에 기초하여, 추가 합성 훈련용 데이터를 생성하는, 전자 장치.공개특허 10-2024-0054133-5-청구항 13 제12항에 있어서, 상기 적어도 하나의 프로세서(1420)가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 제1 예측 정확도가 소정의 값보다 크거나 같고, 상기 제2 예측 정확도가 상기 소정의 값보다 작은 것에 기초하여, 상기 원본 훈련용 데이터 중에서 제2 목표 훈련용 데이터를 결정하고,상기 관심 영역 이미지에 기초하여, 상기 제2 목표 훈련용 데이터에 포함된 제2 훈련용 이미지를 수정함으로써,추가 합성 훈련용 데이터를 생성하는, 전자 장치."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항 내지 제13항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(1420)가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 제1 예측 정확도 및 상기 제2 예측 정확도가 소정의 값보다 작은 것에 기초하여, 상기 배경 이미지로부터상기 관심 영역 이미지의 높이 및 너비와 동일한 추가 관심 영역 이미지를 획득하고,상기 추가 관심 영역 이미지에 기초하여, 상기 제1 훈련용 이미지를 수정함으로써, 추가 합성 훈련용 데이터를생성하는, 전자 장치."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항 내지 제14항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(1420)가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 관심 영역 이미지의 색상 정보 또는 밝기 정보 중 적어도 하나를 획득하고,상기 관심 영역 이미지의 색상 정보 또는 밝기 정보 중 적어도 하나에 기초하여 상기 제1 훈련용 이미지의 색상또는 밝기 중 적어도 하나를 수정하고,상기 관심 영역 이미지에 기초하여, 상기 수정된 제1 훈련용 이미지를 수정함으로써, 상기 합성 훈련용 데이터를 생성하는, 전자 장치."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항 내지 제15항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(1420)가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 관심 영역 이미지에 기초하여, 상기 관심 영역에 관한 제1 컨텍스트 정보를 획득하고,상기 전자 장치의 상태에 관한 제2 컨텍스트 정보를 획득하고,상기 제1 컨텍스트 정보, 상기 제2 컨텍스트 정보 및 상기 배경 이미지의 너비와 높이의 비율에 기초하여, 상기객체의 컨텍스트를 결정하고, 상기 원본 훈련용 데이터 중에서 상기 객체의 컨텍스트에 대응되는 상기 제1 목표 훈련용 데이터를 결정하는,전자 장치."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항 내지 제16항 중 어느 한 항에 있어서,공개특허 10-2024-0054133-6-상기 적어도 하나의 프로세서(1420)가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 제1 이미지와 상기 배경 이미지 사이의 잔차 이미지를 획득하고,상기 잔차 이미지에 기초하여 상기 관심 영역을 식별하는, 전자 장치."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항 내지 제17항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(1420)가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 제1 훈련용 이미지에 포함된 상기 객체에 해당하는 객체 이미지를 추출하고,상기 관심 영역 이미지와 상기 객체 이미지를 합성함으로써 생성된 합성 훈련용 이미지를 포함하는 상기 합성훈련용 데이터를 생성하는, 전자 장치."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항 내지 제18항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(1420)가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 객체를 포함하는 제3 이미지를 획득하는 단계;상기 제3 이미지부터 상기 객체에 대한 객체 이미지를 획득하는 단계;상기 객체 이미지 및 상기 배경 이미지에 기초하여, 실측 합성 훈련용 이미지를 생성하는 단계;상기 제3 이미지를 상기 인공 지능 모델에 입력함으로써, 상기 제3 이미지에 포함된 상기 객체에 관한 예측 데이터를 획득하는 단계; 및상기 실측 합성 훈련용 이미지와 상기 예측 데이터에 기초하여, 상기 객체에 관한 실측 합성 훈련용 데이터를생성하는, 전자 장치."}
{"patent_id": "10-2022-0178691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 수행하도록 하는 프로그램이 저장된 하나 이상의 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2022-0178691", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "학습 대상에 해당하는 객체를 포함하는 제1 이미지를 획득하고, 훈련용 데이터 생성 방법은 제1 이미지와 동일한 시점에서 촬영된 제2 이미지에 기초하여, 객체를 포함하지 않는 배경 이미지를 획득하고, 훈련용 데이터 생성 방 법은 제1 이미지 내에서 객체를 포함하는 관심 영역을 식별하고, 훈련용 데이터 생성 방법은 배경 이미지로부터 관심 영역에 해당하는 관심 영역 이미지를 획득하고, 훈련용 데이터 생성 방법은 기생성된 원본 훈련용 데이터 중에서, 관심 영역 이미지의 너비와 높이의 비율에 기초하여 결정된 객체의 컨텍스트에 대응되는, 제1 목표 훈련 용 데이터를 결정하고, 훈련용 데이터 생성 방법은 관심 영역 이미지에 기초하여, 제1 목표 훈련용 데이터에 포 함된 제1 훈련용 이미지를 수정함으로써, 배경 이미지의 적어도 일부가 포함된 합성 훈련용 데이터를 생성하는 훈련용 데이터를 생성 방법 및 훈련용 데이터 생성 장치가 제공된다."}
{"patent_id": "10-2022-0178691", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공 지능 모델의 학습을 위한 훈련용 데이터를 생성하는 방법 및 전자 장치에 관한 것이다. 보다 구 체적으로, 배경 이미지를 이용하여 기생성된 원본 훈련용 데이터로부터 합성 훈련용 데이터를 생성하는 방법 및 전자 장치에 관한 것이다."}
{"patent_id": "10-2022-0178691", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능 기술의 발달에 따라, 여러 분야에서 인공 지능 기술이 이용되고 있다. 인공 지능 모델은 많은 훈련용 데이터를 통해 학습이 필요하다. 그러나, 인공 지능 모델의 훈련용 데이터를 직접 만드는 것은 많은 시간과 비 용이 소모된다. 따라서, 많은 경우 비용과 시간을 줄이기 위하여 인터넷 상에 공개된 훈련용 데이터를 이용하여 학습을 진행하기도 한다. 다만, 인터넷 상에 공개된 훈련용 데이터는 범용적으로 사용하기 위하여 제작된 데이 터 셋으로 특정 환경에 대하여는 오류가 발생할 수 있다. 따라서, 기존에 존재하는 훈련용 데이터를 이용하여 인공 지능 모델이 사용되는 환경에서 보다 정확하게 동작할 수 있도록 인공 지능 모델을 학습 시킬 수 있는 특정 환경이 고려된 훈련용 데이터를 생성하는 방법이 필요할 수 있다."}
{"patent_id": "10-2022-0178691", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 양태에 따라서, 인공 지능 모델의 학습을 위한 훈련용 데이터를 생성하는 방법이 제공된다. 훈련 용 데이터 생성 방법은 학습 대상에 해당하는 객체를 포함하는 제1 이미지를 획득하는 단계를 포함할 수 있다. 훈련용 데이터 생성 방법은 제1 이미지와 동일한 시점에서 촬영된 제2 이미지에 기초하여, 객체를 포함하지 않 는 배경 이미지를 획득하는 단계를 포함할 수 있다. 훈련용 데이터 생성 방법은 제1 이미지 내에서 객체를 포함 하는 관심 영역을 식별하는 단계를 포함할 수 있다. 훈련용 데이터 생성 방법은 배경 이미지로부터 관심 영역에 해당하는 관심 영역 이미지를 획득하는 단계를 포함할 수 있다. 훈련용 데이터 생성 방법은 기생성된 원본 훈련 용 데이터 중에서, 관심 영역 이미지의 너비와 높이의 비율에 기초하여 결정된 객체의 컨텍스트에 대응되는, 제 1 목표 훈련용 데이터를 결정하는 단계를 포함할 수 있다. 훈련용 데이터 생성 방법은 관심 영역 이미지에 기초 하여, 제1 목표 훈련용 데이터에 포함된 제1 훈련용 이미지를 수정함으로써, 배경 이미지의 적어도 일부가 포함 된 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 양태에 따라서, 전술한 방법을 수행하도록 하는 프로그램이 저장된 하나 이상의 컴퓨터로 읽을 수 있는 기록매체가 제공된다. 본 개시의 일 양태에 따르면 합성 훈련용 데이터를 생성하는 전자 장치가 제공된다. 전자 장치는 메모리 및 프로세서를 포함할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스 트럭션을 실행함으로써, 학습 대상에 해당하는 객체를 포함하는 제1 이미지를 획득할 수 있다. 프로세서 는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 제1 이미지와 동일한 시점에서 촬영된 제2 이미지에 기초하여, 객체를 포함하지 않는 배경 이미지를 획득할 수 있다. 프로세서는 메모리에 저 장된 하나 이상의 인스트럭션을 실행함으로써, 제1 이미지 내에서 객체를 포함하는 관심 영역을 식별할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 배경 이미지로부터 관 심 영역에 해당하는 관심 영역 이미지를 획득할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 기생성된 원본 훈련용 데이터 중에서, 관심 영역 이미지의 너비와 높이의 비율에 기초하여 결정된 객체의 컨텍스트에 대응되는 제1 목표 훈련용 데이터를 결정할 수 있다. 프로세서는 메 모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 관심 영역 이미지에 기초하여, 제1 목표 훈련용 데이터에 포함된 제1 훈련용 이미지를 수정함으로써, 배경 이미지의 적어도 일부가 포함된 합성 훈련용 데이터 를 생성할 수 있다."}
{"patent_id": "10-2022-0178691", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에서, \"a, b 또는 c 중 적어도 하나\" 표현은 \" a\", \" b\", \" c\", \"a 및 b\", \"a 및 c\", \"b 및 c\", \"a, b 및 c 모두\", 혹은 그 변형들을 지칭할 수 있다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의 미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 또한, 본 명세서에서 사용되는 '제1' 또는 '제2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만 사용된다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소 프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시는 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고, 이를 상세한 설명을 통해 상세히 설명하고자 한다. 그러나, 이는 본 개시의 실시 형태에 대해 한정하 려는 것이 아니며, 본 개시는 여러 실시예들의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 실시예를 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있 다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제 1, 제 2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별 기호에 불과하다.또한, 본 명세서에서, 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것이다. 또한, 본 명세서에서 '~부(유닛)', '모듈' 등으로 표현되는 구성요소는 2개 이상의 구성요소가 하나의 구성요소 로 합쳐지거나 또는 하나의 구성요소가 보다 세분화된 기능별로 2개 이상으로 분화될 수도 있다. 또한, 이하에 서 설명할 구성요소 각각은 자신이 담당하는 주기능 이외에도 다른 구성요소가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성요소 각각이 담당하는 주기능 중 일부 기능이 다른 구성요소 에 의해 전담되어 수행될 수도 있음은 물론이다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 명세서에서 \"배경\"은 이미지에서 학습 대상에 해당하는 객체를 제외한 영역 또는 장면을 의미할 수 있다. 예 를 들면, 이미지가 학습 대상에 해당하는 사람을 포함하면, 배경은 사람을 제외한 나머지 영역을 의미할 수 있 다. 또한, 예를 들면, 이미지가 학습 대상에 해당하는 사람을 전혀 포함하지 않으면, 배경은 이미지 영역 전체 를 의미할 수 있다. 배경은 동일한 이미지에 대하여 학습 대상에 따라 다르게 결정될 수 있다. 본 개시의 일 실시예에 따라, 배경은 학습 대상에 해당하지 않는 객체를 포함할 수 있다. 예를 들면, 학습 대상 에 해당하는 객체가 인간인 경우, 배경은 이미지에 포함된 학습 대상에 해당하지 않는 객체(예: 강아지 등)를 포함할 수 있다. 또한, 예를 들면, 학습 대상이 특정 사람(예: 가족 중 엄마)이라면, 배경은 학습 대상에 해당 하지 않는 사람(예: 가족 중 아빠)을 포함할 수 있다. 또한, 예를 들면, 학습 대상이 특정한 조건(예: 성별, 나 이, 피부색 등)에 해당하는 객체라면, 배경은 특정한 조건에 해당하지 않는 객체를 포함할 수 있다. 본 개시의 일 실시예에 따라, 배경은 학습 대상에 해당하는 이동 객체를 제외한 학습 대상에 해당하지 않는 고 정 객체를 포함할 수 있다. 예를 들면, 배경은 시간에 따라 이동하는 사람, 강아지와 같은 이동 객체를 포함하 지 않고, 시간에 따라 이동이 없는 가구, 벽과 같은 고정 객체를 포함할 수 있다. 본 명세서에서 \"배경 이미지\"는 배경을 포함하는 이미지를 의미할 수 있다. 본 개시의 일 실시예에 따라, 배경 이미지는 동일한 시점에서 촬영된 하나 이상의 이미지를 이용하여 획득될 수 있다. 예를 들면, 시야가 고정된 카메라를 이용하여 촬영된 복수의 이미지를 평균함으로써, 배경 이미지가 획득될 수 있다. 본 개시의 일 실시예에 따라, 배경 이미지는 학습 대상에 해당하는 객체를 포함하지 않은 이미지로 결정될 수 있다. 예를 들면, 배 경 이미지는 하나 이상의 촬영된 이미지들 중에서 학습 대상에 해당하는 객체가 포함되지 않은 이미지로 결정 할 수 있다. 본 개시의 일 실시예에 따라, 배경 이미지는 객체가 포함된 이미지로부터 객체를 제거함으로써 생 성될 수 있다. 예를 들면, 배경 이미지는 객체를 포함하는 이미지의 객체 영역을 제거하고, 나머지 영역에 기초 하여 객체 영역을 보상하는 방법으로 생성될 수 있다. 본 개시의 일 실시예에 따라, 배경 이미지는 복수의 이미 지에 공통으로 포함된 객체를 포함하는 이미지를 의미할 수 있다. 예를 들면, 배경 이미지는 복수의 이미지 내 에서 위치가 이동하는 이동 객체를 제외하고, 복수의 이미지 내에서 위치가 고정된 고정 객체를 포함하는 이미 지를 의미할 수 있다. 본 명세서에서 \"관심 영역\"은 이미지 중에서 학습 대상에 해당하는 객체를 포함하는 영역을 의미할 수 있다. 예 를 들면, 학습 대상이 인간인 경우, 관심 영역은 이미지 중에서 인간을 포함하는 영역일 수 있다. 본 개시의 일 실시예에 따라, 관심 영역은 학습 대상에 해당하는 객체를 포함하는 최소 사이즈의 직사각형 영역을 의미할 수 있다. 예를 들면, 학습 대상이 인간인 경우, 관심 영역은 이미지 중에서 인간을 포함하는 최소의 직사각형 영역 일 수 있다. 본 명세서에서 \"관심 영역 이미지\"는 배경 이미지 중에서 관심 영역에 해당하는 이미지를 의미할 수 있다. 본 개시의 일 실시예에 따라, 관심 영역 이미지는 배경 이미지를 이용하여 획득될 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 배경 이미지를 이용하여 배경의 적어도 일부를 포함하는 훈련용 데이터를 생성할 수 있다. 전자 장치는 배경의 적어도 일부를 포함하는 훈련용 데이터를 이용하여 인공 지능 모델을 학습할 수 있다. 본 명세서에서 \"훈련용 데이터\"는 인공 지능 모델의 학습을 위한 데이터를 의미할 수 있다. 본 개시의 일 실시 예에 따라, 훈련용 데이터는 객체가 포함된 이미지 및 객체에 대한 라벨링 정보를 포함할 수 있다. 예를 들면, 인공 지능 모델이 포즈 추정을 수행하기 위한 인공 지능 모델인 경우, 훈련용 데이터는 객체가 포함된 이미지 및 객체의 포즈에 관한 정보를 포함할 수 있다. 예를 들면, 인공 지능 모델이 객체 탐지를 수행하기 위한 인공 지능 모델인 경우, 훈련용 데이터는 객체가 포함된 이미지 및 객체에 대한 위치 정보 및 객체의 종류에 관한 클 래스 정보를 포함할 수 있다. 본 명세서에서 \"원본 훈련용 데이터\"는 배경이 고려되지 않은 인공 지능 모델의 학습을 위한 훈련용 데이터를 의미할 수 있다. 예를 들면, 원본 훈련용 데이터는 인공 지능 모델의 학습을 위해 공개된 훈련용 데이터일 수 있다. 원본 훈련용 데이터의 배경은 인공 지능 모델을 이용하는 전자 장치의 카메라에 의하여 촬영되는 배경이 아닌 임의의 배경일 수 있다. 원본 훈련용 데이터는 학습 대상이 되는 객체에 관한 훈련용 데이터를 포함할 수 있다. 본 명세서에서 \"목표 훈련용 데이터\"는 배경 이미지와 합성됨으로써 합성 훈련용 데이터를 생성하기 위하여 원 본 훈련용 데이터 중에서 결정된 훈련용 데이터를 의미할 수 있다. 본 개시의 일 실시예에 따라, 목표 훈련용 데이터는 관심 영역 이미지의 너비 및 높이에 기초하여, 원본 훈련용 데이터 중에서 결정될 수 있다. 예를 들면, 목표 훈련용 데이터는 원본 훈련용 데이터 중에서 관심 영역의 너비 및 높이의 비율와 동일하거나 유사한 너비 및 높이의 비율을 갖는 훈련용 데이터일 수 있다. 본 명세서에서 \"합성 훈련용 데이터\"는 목표 훈련용 데이터와 관심 영역 이미지가 합성됨으로써 생성된 훈련용 데이터를 의미할 수 있다. 본 개시의 일 실시예에 따라, 합성 훈련용 데이터는 목표 훈련용 데이터 중에서 인공 지능 모델의 학습 대상이 되는 객체와 관심 영역 이미지가 합성됨으로써 생성될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 본 개시의 일 실시예에 따른 훈련용 데이터를 생성하는 방법을 설명하기 위한 도면이다. 도 1을 참조하면, 전자 장치는 배경을 포함하는 이미지를 획득할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 카메라를 이용하여, 배경을 포함하는 이미지를 획득할 수 있다. 예를 들면, 전자 장치가 TV인 경우, TV는 카메라를 이용하여 실내 공간 배경을 포함하는 이미지를 획득할 수 있다. 배경은 카메라의 시야각에 포함되는 영역일 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 배경을 포함하는 이미지에 기초하여 배경 이미지를 획득할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 동일한 시점에서 촬영된 하나 이상의 이미지 를 이용하여 배경 이미지를 획득할 수 있다. 예를 들면, 전자 장치는 시야가 고정된 카메라를 이용하여 촬영된 복수의 이미지를 평균함으로써, 배경 이미지를 획득할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 학습 대상에 해당하는 객체를 포함하지 않은 이미지를 배경 이미지로 결정할 수 있다. 예를 들면, 전자 장치는 하나 이상의 촬영된 이미지들 중에서 학습 대상에 해당하는 객체가 포함되지 않 은 이미지를 배경 이미지로 결정 할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 객체가 포 함된 이미지로부터 객체를 제거함으로써 배경 이미지를 생성할 수 있다. 예를 들면, 전자 장치는 객체를 포함하는 이미지의 객체 영역을 제거하고, 나머지 영역에 기초하여 객체 영역을 보상하는 방법으로 배경 이미지 를 생성할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 복수의 이미지에 공통으로 포함된 객 체를 포함하는 이미지를 배경 이미지로 결정할 수 있다. 예를 들면, 전자 장치는 복수의 이미지 내 에서 위치가 이동하는 이동 객체를 제외하고, 복수의 이미지 내에서 위치가 고정된 고정 객체를 포함하는 이미 지를 배경 이미지로 결정할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 이미지를 촬영하거나 획득할 때마다 배경 이미지를 획득 할 수 있다. 예를 들면, 전자 장치는 관심 영역을 식별할 때마다 배경 이미지를 획득할 수 있 다. 본 개시의 일 실시예에 따라, 전자 장치는 소정의 조건을 만족하는 경우에 배경 이미지를 획득 할 수 있다. 예를 들면, 전자 장치는 소정의 주기마다 배경 이미지를 획득하고, 새로운 배경 이미지 를 획득하기 전에는 획득된 배경 이미지를 이용하여 관심 영역을 식별할 수 있다. 또는, 예를 들면, 전자 장치는 특정 태스크를 수행하는 경우, 배경 이미지를 생성할 수 있다. 예를 들면, 전자 장치 가 운동 어플리케이션을 실행할 때, 배경 이미지를 생성할 수 있다. 본 개시의 여러 실시예에 따른 배경 이미지를 획득하는 방법은 도 2a 및 도 2b를 참조하여 보다 상세히 설명하도록 한다. 본 개시의 일 실시예에 따라, 전자 장치는 객체를 포함하는 이미지의 관심 영역을 식별할 수 있다. 관심 영역은 객체를 포함하는 이미지의 학습 대상에 해당하는 객체를 포함하는 영역을 의미할 수 있다. 예를 들면, 인공 지능 모델이 사람의 포즈를 인식하는 포즈 추정 모델인 경우, 관심 영역은 사람 이 포함된 영역을 의미할 수 있다. 본 개시의 일 실시예에 따라, 관심 영역은 객체를 포함하는 최소 사이 즈의 직사각형으로 결정될 수 있으나, 이에 제한되지 않고 다양한 형태로 변형될 수 있다. 본 개시의 일 실시예 에 따른 관심 영역을 식별하는 방법은 도 3을 참조하여 보다 상세히 설명하도록 한다. 본 개시의 일 실시예에 따라, 전자 장치는 관심 영역 이미지를 획득할 수 있다. 예를 들면, 관심 영 역 이미지는 배경 이미지 중에서 관심 영역에 해당하는 이미지로 결정될 수 있다. 또는, 관심 영역 이미지는 관심 영역의 기초가 된 촬영된 이미지를 제외한 다른 촬영 이미지에 기초하여 획 득될 수 있다. 관심 영역 이미지는 객체를 포함하는 이미지의 객체에 가려져 촬영되지 않은 영역도 포함할 수 있다. 본 개시의 일 실시예에 따른 관심 영역 이미지를 획득하는 방법은 도 4를 참조하여 보다 상세 히 설명하도록 한다. 본 개시의 일 실시예에 따라, 전자 장치는 원본 훈련용 데이터를 획득할 수 있다. 원본 훈련용 데이 터는 기생성된 훈련용 데이터 세트일 수 있다. 원본 훈련용 데이터는 전자 장치의 카메라가 촬영하는 영역 과 관련이 없는 임의의 배경을 포함하는 훈련용 데이터일 수 있다. 예를 들면, 원본 훈련용 데이터는 여러 배경 에서 촬영된 훈련용 데이터일 수 있다. 전자 장치가 원본 훈련용 데이터를 이용하여 훈련된 인공 지능 모 델을 이용하는 경우 소정의 배경에 대하여 정확도가 낮은 경우가 발생할 수 있다. 예를 들면, 사람의 포즈를 추 론하기 위한 인공 지능 모델이 이미지에 포함된 창틀을 사람의 팔로 판단할 수 있다. 본 개시의 일 실시예에 따 른 원본 훈련용 데이터는 도 5a 및 도 5b를 참조하여 보다 상세히 설명하도록 한다. 본 개시의 일 실시예에 따라, 전자 장치는 합성 훈련용 데이터를 생성할 수 있다. 전자 장치 는 원본 훈련용 데이터와 관심 영역 이미지에 기초하여 합성 훈련용 데이터를 생성할 수 있다. 합성 훈련용 데이터는 원본 훈련용 데이터로부터 인공 지능 모델의 학습 대상이 되는 객체에 관한 데 이터와 관심 영역 이미지를 합성함으로써 생성될 수 있다. 예를 들면, 전자 장치는 원본 훈련용 데 이터에 포함된 사람과 배경 중 적어도 일부인 관심 영역 이미지를 합성함으로써, 배경과 학습 대상인 객체가 포함된 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 원본 훈련용 데이터와 관심 영역 이미지에 기초하여 목표 훈련용 데이터를 결정할 수 있다. 본 개시의 일 실시예에 따라, 목표 훈련용 데이터는 원본 훈련용 데이터 중에서 관심 영역 이미지의 사이즈에 기초하여 결정될 수 있다. 목표 훈련용 데이터는 원본 훈련용 데이터 중에서 관심 영역 이미지의 너비 및 높이의 비율에 대응되는 것으로 결정될 수 있다. 예를 들 면, 관심 영역 이미지의 너비 및 높이의 비율이 1 대 2인 경우, 목표 훈련용 데이터는 원본 훈련용 데이터 중에서 너비 및 높이의 비율이 1 대 2와 동일하거나 유사한 것으로 결정될 수 있다. 전자 장치는 목표 훈 련용 데이터 및 관심 영역 이미지를 이용하여 합성 훈련용 데이터를 생성할 수 있다. 전자 장치는 배경에 기초하여 생성된 합성 훈련용 데이터를 이용하여 인공 지능 모델을 학습시 킬 수 있다. 합성 훈련용 데이터를 이용하여 학습된 인공 지능 모델은 배경에 대하여 촬영된 입력 이 미지에 대하여 보다 높은 정확도로 인공 지능 모델의 목적을 수행할 수 있다. 이하에서는 설명의 편의를 위하여, 별도의 설명이 없는 경우 인공 지능 모델은 포즈 추정 모델이고, 학습 대상 은 사람인 경우를 가정하여 설명하도록 하지만, 이에 제한되지 않고, 인공 지능 모델의 종류에 따라 학습 대상 이 변경될 수 있다. 도 2a는 본 개시의 일 실시예에 따른 배경 이미지를 생성하는 방법을 설명하기 위한 도면이다. 도 2a를 참조하면, 전자 장치는 복수의 촬영 이미지(210, 220, 230)에 기초하여 배경 이미지를 획득 할 수 있다. 일 예에 따른 설명을 위하여, 제1 촬영 이미지와 제2 촬영 이미지는 상이한 위치에 객체 를 포함하는 이미지이고, 제3 촬영 이미지는 객체를 포함하지 않는 이미지일 수 있다. 설명의 편의를 위하 여, 학습 대상이 하나의 이동 객체(예: 사람)인 경우를 예를 들어 설명하고, 이동 객체 하나를 포함하는 촬영 이미지를 대상으로 설명하지만, 이에 제한되지 않고, 학습 대상은 훈련용 데이터에 따라 결정될 수 있으며 복수 의 객체를 포함하는 촬영 이미지를 이용하는 경우에도 동일하게 동작 할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 복수의 촬영 이미지(210, 220, 230) 내에서 위치가 이동하는 이동 객체를 제외하고, 복수의 이미지 내에서 위치가 고정된 고정 객체를 포함하도록 배경 이미지를 생성할 수 있다. 전자 장치는 복수의 이미지(210, 220, 230) 내에서 위치가 이동하는 이동 객체 및 위치가 고정된 고정 객체를 분류할 수 있다. 전자 장치는 고정 객체에 대응되는 이미지에 기초하여 배경 이미지를 획득할 수 있다. 예를 들면, 전자 장치는 제1 촬영 이미지 및 제2 촬영 이미지에 포함된 객체 는 이동 객체로 식별하고, 이외는 고정 객체로 식별할 수 있다. 전자 장치는 제3 촬영 이미지에 포 함된 객체들은 고정 객체로 식별할 수 있다. 전자 장치는 제1 촬영 이미지 중 고정 객체에 대응되는 이미지, 제2 촬영 이미지 중 고정 객체에 대응되는 이미지 및 제3 촬영 이미지 중 고정 객체에 대응 되는 이미지에 기초하여 배경 이미지를 생성할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 복수의 촬영 이미지(210, 220, 230)를 평균함으로써, 배경 이미 지를 획득할 수 있다. 복수의 촬영 이미지는 제1 촬영 이미지 혹은 제2 촬영 이미지와 같이 객 체를 포함하는 이미지들을 포함할 수 있다. 그러나, 전자 장치 다수의 이미지들을 평균함으로써 객체를 포함하지 않는 배경 이미지를 생성할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 학습 대상에 해당하는 객체를 포함하지 않은 이미지를 배경 이 미지로 결정할 수 있다. 예를 들면, 전자 장치는 복수의 촬영 이미지(210, 220, 230) 중에서 학습 대상에 해당하는 객체가 포함되지 않은 제3 촬영 이미지를 배경 이미지로 결정 할 수 있다. 본 개시의 일 실시예에 따라 전자 장치가 객체를 포함하는 촬영 이미지를 이용하여 배경 이미지를 생성하 는 과정은 도 2b를 참조하여 설명한다. 도 2b는 본 개시의 일 실시예에 따른 배경 이미지를 생성하는 방법을 설명하기 위한 도면이다. 도 2b를 참조하면, 전자 장치는 촬영 이미지에 포함된 객체를 제거함으로써 배경 이미지를 획 득할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 학습 대상에 해당하는 객체를 포함하는 촬영 이 미지의 객체 영역을 제거함으로써 객체 제거 이미지를 획득할 수 있다. 전자 장치는 촬영 이미 지에 포함된 학습 대상에 해당하지 않는 객체를 포함하는 객체 제거 이미지를 획득할 수 있다. 예를 들면, 촬영 이미지에 학습 대상인 사람과 학습 대상이 아닌 강아지가 포함된 경우, 전자 장치는 촬 영 이미지 중에서 사람을 제거하고 강아지는 제거하지 않은 객체 제거 이미지를 획득할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 객체 제거 이미지의 객체 영역 이외의 영역에 기초하여 객체 영역을 보상하는 방법으로 배경 이미지를 생성할 수 있다. 예를 들면, 전자 장치는 객체 제거이미지 중 제거되지 않은 영역의 픽셀 값에 기초하여 제거된 영역의 픽셀 값을 복원할 수 있다. 전자 장치 는 다양한 방식의 Inpainting 기법을 이용하여, 객체를 포함하는 이미지로부터 배경 이미지를 획득할 수 있다. 도 3은 본 개시의 일 실시예에 따른 관심 영역을 식별하는 방법을 설명하기 위한 도면이다. 도 3을 참조하면, 배경 이미지는 도 1의 배경 이미지, 도 2a의 배경 이미지 또는 도 2b의 배경 이미지에 대응될 수 있으나, 이에 제한되지 않는다. 촬영 이미지는 도 2a의 복수의 촬영 이미지(210, 220, 230) 혹은 도 2b의 촬영 이미지에 대응될 수 있지만, 이에 제한되지 않고, 따로 촬영된 이미지일 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 촬영 이미지와 배경 이미지에 기초하여 잔차 이미지 를 생성할 수 있다. 예를 들면, 잔차 이미지는 학습 대상의 객체를 포함할 수 있다. 본 개시의 일 실 시예에 따른 전자 장치는 잔차 이미지에 기초하여 관심 영역을 결정할 수 있다. 본 개시의 일 실시예에 따라, 관심 영역은 잔차 이미지 내 객체를 포함하는 최소한의 직사각형일 수 있다. 본 개시의 일 실시예에 따른 잔차 이미지는 객체에 관한 잔차 이미지, 그림자에 관한 잔차 이미지 및 노이즈에 관한 잔차 이미지 중 적어도 일부를 포함할 수 있다. 본 개시의 일 실시예에 따라, 관 심 영역은 객체에 관한 잔차 이미지를 포함하는 최소한의 직사각형일 수 있다. 본 개시의 일 실시예에 따라, 전자 장치가 연속적으로 이미지를 촬영하는 경우, 촬영된 복수의 이미지 에 기초하여 관심 영역을 결정할 수 있다. 예를 들면, 전자 장치는 복수의 이미지 사이의 잔차 이미지에 기초하여 관심 영역을 결정할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 소정의 시간 간격마다 관심 영역을 식별할 수 있다. 예를 들면, 전자 장치는 1초마다 관심 영역을 식별하고, 관심 영역이 존재하는 경우 합성 훈련용 데이터를 생 성할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 소정의 조건을 충족하는 것에 기초하여 관심 영역을 식별할 수 있다. 예를 들면, 전자 장치는 특정 애플리케이션(예: 운동 애플리케이션)이 실행되는 경우, 관심 영역을 식별할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 센서를 통해 움직임이 감지되는 경우, 관심 영역을 식별할 수 있다. 예를 들면, 전자 장치는 적외선 센서를 이용하여 물체의 움직임을 인식한 경우 관심 영역을 식별하 는 동작을 수행할 수 있다. 도 4는 본 개시의 일 실시예에 따른 관심 영역 이미지를 생성하는 방법을 설명하기 위한 도면이다. 도 4를 참조하면, 관심 영역(410a, 410b, 410c, 410d) 및 배경 이미지는 도 1의 관심 영역 및 배경 이미지에 대응될 수 있으나, 이에 제한되지 않는다. 본 개시의 일 실시예에 따라, 전자 장치는 복수의 관심 영역(410a, 410b, 410c, 410d)에 관한 정보와 배 경 이미지를 획득할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 배경 이미지로부터 관 심 영역(410a, 410b, 410c, 410d)에 대응되는 관심 영역 이미지(430a, 430b, 430c, 430d)를 획득할 수 있다. 따라서, 전자 장치는 배경 이미지 중에서 객체가 식별된 영역에 대한 배경인 관심 영역 이미지 (430a, 430b, 430c, 430d)를 획득할 수 있다. 본 개시의 일 실시예에 따라, 배경 이미지는 관심 영역 이미지(430a, 430b, 430c, 430d)를 획득할 때마다 생성된 것일 수 있다. 본 개시의 일 실시예에 따라, 배경 이미지는 특정한 시점에 생성된 배경 이미지일 수 있다. 도 5a는 본 개시의 일 실시예에 따른 훈련용 데이터를 설명하기 위한 도면이다. 도 5a를 참조하면, 훈련용 데이터는 훈련용 이미지(510a) 및 훈련용 데이터(520a)를 포함할 수 있다. 본 개시 의 일 실시예에 따라, 훈련용 데이터는 객체의 포즈 추정(pose estimation)에 관한 인공 지능 모델을 학습시키 기 위한 것일 수 있다. 훈련용 이미지(510a)는 포즈를 추정하려는 객체를 포함하는 이미지일 수 있다. 또한, 훈련용 이미지(510a)는 임 의의 배경을 포함할 수 있다. 훈련용 이미지(510a)의 배경은 실제 인공 지능 모델이 수행되는 환경의 배경과 상이할 수 있다. 훈련용 데이터(520a)는 포즈를 식별하기 위한 정보를 포함할 수 있다. 예를 들면, 훈련용 데이터(520a)는 사람 의 관절 정보 및 관절 사이의 연결 관계에 관한 정보를 포함할 수 있다. 설명의 편의를 위하여, 훈련용 데이터 (520a)는 훈련용 이미지(510a)에 사람의 관절 정보 및 관절 사이의 연결 관계에 관한 정보를 포함하는 이미지로 도시 되었지만, 이에 제한되지 않고, 훈련용 데이터(520a)는 훈련을 위한 데이터가 다양한 방식으로 표현된 형 태일 수 있다. 포즈 추정에 관한 인공 지능 모델은 훈련용 이미지(510a) 및 포즈에 관한 정보를 포함하는 훈련용 데이터(520 a)를 이용하여 학습될 수 있다. 예를 들면, 훈련용 이미지(510a)를 인공 지능 모델에 입력함으로써 획득되는 출 력 데이터와 훈련용 데이터(520a) 사이의 오차를 줄이는 방향으로 인공 지능 모델이 결과 데이터를 출력할 수 있도록 학습될 수 있다. 도 5b는 본 개시의 일 실시예에 따른 훈련용 데이터를 설명하기 위한 도면이다. 도 5b를 참조하면, 훈련용 데이터는 훈련용 이미지(510b) 및 훈련용 데이터(520b)를 포함할 수 있다. 본 개시의 일 실시예에 따라, 훈련용 데이터는 객체 탐지(Object detection)에 관한 인공 지능 모델을 학습시키기 위한 것 일 수 있다. 훈련용 이미지(510b)는 포즈를 추정하려는 객체를 포함하는 이미지일 수 있다. 또한, 훈련용 이미지(510b)는 임 의의 배경을 포함할 수 있다. 훈련용 이미지(510b)의 배경은 실제 인공 지능 모델이 수행되는 환경의 배경과 상 이할 수 있다. 훈련용 데이터(520b)는 탐지의 대상인 객체에 관한 정보를 포함할 수 있다. 예를 들면, 훈련용 데이터(520b)는 객체의 존재 영역(예: Bounding Box)(530b) 및 객체의 종류(예: 사람)에 관한 정보를 포함할 수 있다. 설명의 편의를 위하여, 훈련용 데이터(520b)는 훈련용 이미지(510b)에 객체의 존재 영역(530b) 및 객체의 종류에 관한 정보를 포함하는 이미지로 도시 되었지만, 이에 제한되지 않고, 훈련용 데이터(520b)는 훈련을 위한 데이터를 다양한 방식으로 표현될 수 있다. 예를 들면, 훈련용 데이터(520b)는 텍스트 형태로 저장될 수 있다. 예를 들면, 훈련용 데이터(520b)는 객체의 존재 영역(530b)에 대한 좌표 값(예: Bounding box의 좌상단 좌표의 좌표 값 및 우하단 좌표의 좌표 값) 및 객체의 종류에 관한 정보를 텍스트 형태로 표현될 수 있다. 객체 탐지에 관한 인공 지능 모델은 훈련용 이미지(510b) 및 객체의 존재 영역 및 객체의 종류에 관한 정보를 포함하는 훈련용 데이터(520b)를 이용하여 학습될 수 있다. 예를 들면, 인공 지능 모델은 훈련용 이미지(510b) 를 인공 지능 모델의 입력함으로써 획득되는 출력 데이터와 훈련용 데이터(520b) 사이의 오차를 줄이는 방향으 로 인공 지능 모델이 데이터를 출력할 수 있도록 학습될 수 있다. 도 6는 본 개시의 일 실시예에 따른 인공 지능 모델을 학습하는 방법을 설명하기 위한 도면이다. 도 6을 참조하면, 훈련용 데이터를 이용하여 인공 지능 모델을 학습하는 방법이 도시된다. 훈련용 데 이터는 도 5a, 도 5b의 훈련용 데이터일 수 있지만, 이에 제한되지 않고, 인공 지능 모델의 종류에 대응되 는 훈련용 데이터일 수 있다. 본 개시의 일 실시예에 따라 전자 장치가 인공 지능 모델을 학습하는 과정 을 설명하지만, 이에 제한되지 않고, 인공 지능 모델은 서버를 이용하여 학습될 수 있다. 훈련용 데이터는 인공 지능 모델의 입력 대상인 훈련용 이미지와 훈련용 정보를 포함할 수 있다. 전 자 장치는 훈련용 데이터를 인공 지능 모델에 입력함으로써, 예측 데이터를 출력할 수 있 다. 전자 장치는 훈련용 데이터의 훈련용 정보와 예측 데이터에 기초하여 예측 오차를 측 정할 수 있다. 전자 장치는 예측 오차에 기초하여 인공지능 모델의 파라미터를 갱신할 수 있다. 본 개시의 일 실시예에 따른, 전자 장치는 인공 지능 모델에 관한 학습을 진행하면서 훈련용 데이터 에 적합하게 학습된다. 전자 장치가 배경 이미지의 적어도 일부가 포함된 훈련용 데이터를 이용하여 인공 지능 모델을 학습하는 경우, 임의의 배경에 대한 훈련용 데이터를 이용하여 훈련시킨 인공 지능 모델 보다 예측 정확도를 높일 수 있다. 도 7은 본 개시의 일 실시예에 따른 훈련용 데이터를 생성하는 방법을 설명하기 위한 도면이다. 도 7을 참조하면, 합성 훈련용 데이터는 원본 훈련용 데이터 및 관심 영역 이미지에 기초하여 생성될 수 있다. 본 개시의 일 실시예에 따라, 원본 훈련용 데이터, 관심 영역 이미지 및 합성 훈련용 데이터는 도 1의 원본 훈련용 데이터, 관심 영역 이미지 및 합성 훈련용 데이터에 대응 될 수 있다. 설명의 편의를 위하여, 원본 훈련용 데이터, 관심 영역 이미지 및 합성 훈련용 데이터 중에서 도 1에서 설명된 것은 생략한다. 본 개시의 일 실시예에 따른 전자 장치는 원본 훈련용 데이터에 기초하여 목표 훈련용 데이터를 결정 할 수 있다. 전자 장치는 관심 영역 이미지의 너비와 높이의 비율에 기초하여 목표 훈련용 데이터를 결정할 수 있다. 또는, 전자 장치는 도 1에서 설명된 관심 영역의 너비와 높이의 비율에 기초하여 목표 훈련용 데이터를 결정할 수 있다. 목표 훈련용 데이터는 원본 훈련용 데이터 중에서 선택될 수 있다. 전자 장치는 목표 훈련용 데이터로부터 학습 대상에 해당하는 객체 에 관한 데이터를 획득할 수 있다. 전자 장치는 목표 훈련용 데이터에 포함된 객체 이미지를 분할할 수 있다. 예를 들면, 전자 장치는 목표 훈련용 데이터에 포함된 객체에 대한 이미지 분할(Image segmentation)을 수행할 수 있다. 객체 는 인공 지능 모델의 인식 대상이 되는 것을 의미할 수 있다. 예를 들면, 인공 지능 모델이 사람을 인식하 는 모델인 경우, 사람 이외의 가구 등은 분할되지 않을 수 있지만, 이에 제한되지 않고 인공 지능 모델의 종류 에 따라 다양한 형태의 객체가 결정될 수 있다. 전자 장치는 목표 훈련용 데이터로부터 학습 대상을 분할하도록 학습된 인공 지능 모델을 이용하여 목표 훈련용 데이터로부터 객체를 분할할 수 있다. 전자 장치는 목표 훈련용 데이터의 객체와 배경 사이의 색상 차이를 이용하여 목표 훈련용 데이터로부터 객체를 분할 할 수 있다. 앞서 언급된 방법에 제한되지 않고, 전자 장치는 다양한 방법으로 목표 훈련용 데이터로부터 객체를 분할 할 수 있다. 전자 장치는 관심 영역 이미지에 객체를 합성함으로써 합성 훈련용 데이터를 생성할 수 있다. 도 8은 본 개시의 일 실시예에 따른 추가 합성 훈련용 데이터를 생성하는지 여부를 결정하는 방법을 설명하기 위한 도면이다. 도 8을 참조하면, 전자 장치는 복수의 테스트 이미지(810, 820)를 이용하여 인공 지능 모델의 정확도를 판 단할 수 있다. 본 개시의 일 실시예에 따른, 제1 테스트 이미지는 소정의 배경과 목표 훈련용 데이터에 기초하여 생성될 수 있다. 예를 들면, 제1 테스트 이미지는 목표 훈련용 데이터의 학습 대상에 해당하는 객체와 소정의 배 경을 합성함으로써 생성될 수 있다. 소정의 배경은 훈련용 데이터에 영향을 주지 않는 배경일 수 있다. 예를 들 면, 소정의 배경은 단색의 회색일 수 있다. 본 개시의 일 실시예에 따른, 제2 테스트 이미지는 배경 이미지와 목표 훈련용 데이터에 기초하여 생성될 수 있다. 예를 들면, 제2 테스트 이미지는 목표 훈련용 데이터의 학습 대상에 해당하는 객체와 배경 이미 지의 적어도 일부를 합성함으로써 생성될 수 있다. 예를 들면, 제2 테스트 이미지는 합성 훈련용 데이터일 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 인공 지능 모델에 제1 테스트 이미지와 제2 테스트 이미지 를 각각 입력하여 정확도를 판단할 수 있다. 예를 들면, 전자 장치는 인공 지능 모델에 제1 테스트 이미지와 제2 테스트 이미지가 입력되는 것에 기초하여 출력되는 데이터와 정답 데이터를 비교함으로 써 정확도를 판단할 수 있다. 전자 장치는 제1 테스트 이미지에 대한 정확도 및 제2 테스트 이미지에 대한 정확도에 기초하여, 추 가 합성 훈련용 데이터를 생성하는지 여부를 결정할 수 있다. 본 개시의 일 실시예에 따른 제1 테스트 이 미지에 대한 정확도 및 제2 테스트 이미지에 대한 정확도를 이용하여, 추가 합성 훈련용 데이터를 생 성하는지 여부를 결정하는 방법은 도 9a 및 도 9b를 참조하여 보다 상세하게 설명한다. 도 9a는 본 개시의 일 실시예에 따른 추가 합성 훈련용 데이터를 생성하는지 여부를 결정하는 방법을 설명하기 위한 순서도이다. 도 9a를 참조하면, 본 개시의 일 실시예에 따른 전자 장치가 추가 합성 훈련용 데이터를 생성하는지 여부 를 결정하는 방법(900a)은 단계 910a로부터 진행된다. 전자 장치는 배경 이미지의 적어도 일부를 포함하 는 훈련용 데이터로 학습된 인공 지능 모델을 이용하여, 추가 합성 훈련용 데이터를 생성하는지 여부를 결정할 수 있다.단계 910a에서, 전자 장치는 테스트 이미지를 생성할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치 는 합성 훈련용 데이터에 포함된 훈련용 이미지를 테스트 이미지로 이용할 수 있다. 예를 들면, 전자 장 치는 도 8의 제2 테스트 이미지를 테스트 이미지로 이용할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 합성 훈련용 데이터에 포함된 훈련용 이미지에 소정의 배경을 합성한 이미지를 테스트 이미 지로 이용할 수 있다. 예를 들면, 전자 장치는 도 8의 제1 테스트 이미지를 테스트 이미지로 이용할 수 있다. 단계 920a에서, 전자 장치는 테스트 이미지를 인공 지능 모델에 입력함으로써 획득된 출력 결과에 기초하 여, 예측 정확도를 결정할 수 있다. 단계 930a에서, 전자 장치는 테스트 이미지에 대한 예측 정확도가 임계 값보다 크거나 같은지 여부를 식 별한다. 만약, 예측 정확도가 임계 값보다 크거나 같은 경우에는 단계를 종료하고, 예측 정확도가 임계 값보다 작은 경우에는 단계 940a로 진행한다. 단계 940a에서, 전자 장치는 추가 합성 훈련용 데이터를 생성한다. 본 개시의 일 실시예에 따라, 전자 장 치는 합성 훈련용 데이터와 동일한 객체에 대하여 배경을 변경하여 추가 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 합성 훈련용 데이터와 동일한 배경에 대하여 객체를 변 경하여 추가 합성 훈련용 데이터를 생성할 수 있다. 도 9b는 본 개시의 일 실시예에 따른 추가 합성 훈련용 데이터를 생성하는지 여부를 결정하는 방법을 설명하기 위한 순서도이다. 도 9b를 참조하면, 본 개시의 일 실시예에 따른 전자 장치가 추가 합성 훈련용 데이터를 생성하는지 여부 를 결정하는 방법(900b)은 단계 910b로부터 진행된다. 전자 장치는 배경 이미지의 적어도 일부를 포함하 는 훈련용 데이터로 학습된 인공 지능 모델을 이용하여, 추가 합성 훈련용 데이터를 생성하는지 여부를 결정할 수 있다. 단계 910b에서, 전자 장치는 제1 테스트 이미지 및 제2 테스트 이미지를 생성할 수 있다. 본 개시의 일 실시예에 따라, 제1 테스트 이미지 및 제2 테스트 이미지는 도 8의 제1 테스트 이미지와 제2 테스트 이미 지에 대응될 수 있다. 단계 920b에서, 전자 장치는 제1 테스트 이미지와 제2 테스트 이미지를 각각 인공 지능 모델에 입력함으 로써 획득된 출력 결과에 기초하여, 각각의 예측 정확도를 결정할 수 있다. 단계 930b에서, 전자 장치는 제1 테스트 이미지에 대한 예측 정확도가 임계 값보다 크거나 같은지 여부를 식별한다. 만약, 예측 정확도가 임계 값보다 크거나 같은 경우에는 단계 940b로 진행하고, 예측 정확도가 임계 값보다 작은 경우에는 단계 950b로 진행한다. 단계 940b에서, 전자 장치는 제2 테스트 이미지에 대한 예측 정확도가 임계 값보다 크거나 같은지 여부를 식별한다. 만약, 예측 정확도가 임계 값보다 크거나 같은 경우에는 단계를 종료하고, 예측 정확도가 임계 값보 다 작은 경우에는 단계 960b로 진행한다. 본 개시의 일 실시예에 따라, 단계 940에서의 임계 값과 단계 930에서 의 임계 값은 상황에 따라 다르게 설정될 수 있다. 단계 950b에서, 전자 장치는 추가 합성 훈련용 데이터를 생성한다. 본 개시의 일 실시예에 따라, 전자 장 치는 합성 훈련용 데이터와 동일한 객체에 대하여 배경을 변경하여 추가 합성 훈련용 데이터를 생성할 수 있다. 제1 테스트 이미지에 대한 예측 정확도가 낮은 것은 해당 객체를 포함하는 데이터에 대한 예측이 부정확 한 것으로 이해될 수 있다. 동일한 객체에 대한 추가 합성 훈련용 데이터를 생성함으로써, 인공 지능 모델의 객 체에 대한 예측 정확도를 높일 수 있다. 단계 960b에서, 전자 장치는 추가 합성 훈련용 데이터를 생성한다. 본 개시의 일 실시예에 따라, 전자 장 치는 합성 훈련용 데이터와 동일한 배경에 대하여 객체를 변경하여 추가 합성 훈련용 데이터를 생성할 수 있다. 제2 테스트 이미지에 대한 예측 정확도가 낮은 것은 해당 배경을 포함하는 데이터에 대한 예측이 부정확 한 것으로 이해될 수 있다. 동일한 배경에 대한 추가 합성 훈련용 데이터를 생성함으로써, 인공 지능 모델의 해 당 배경을 포함하는 데이터에 대한 예측 정확도를 높일 수 있다. 도 10은 본 개시의 일 실시예에 따른 훈련용 데이터를 생성하는 방법을 설명하기 위한 도면이다. 도 10을 참조하면, 전자 장치는 관심 영역 이미지의 색상 정보 및 밝기 정보에 기초하여, 합성 훈련용 데 이터를 생성할 수 있다. 본 개시의 일 실시예에 따라, 목표 훈련용 데이터는 도 7의 730과 같이 목 표 훈련용 데이터 중에서 학습 대상에 해당하는 객체일 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 관심 영역 이미지의 색상 정보 또는 밝기 정보 중에서 적어도 하나를 획득할 수 있다. 전자 장치는 관심 영역 이미지의 각 픽셀 값에 기초하여 색상 정보 또는 밝기 정 보 중에서 적어도 하나를 계산할 수 있다. 예를 들면, 전자 장치는 관심 영역 이미지의 픽셀의 색상 정보 (예: RGB)에 기초하여 픽셀에 대한 HSL(색상, 채도, 밝기; Hue, Saturation, Luminance) 값을 계산할 수 있다. 관심 영역 이미지의 색상은 각 픽셀의 H 값의 평균으로 결정될 수 있다. 관심 영역 이미지의 밝기 는 각 픽셀의 L 값의 평균으로 결정될 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 관심 영역 이미지의 색상 정보 또는 밝기 정보 중 적어도 하나 에 기초하여 목표 훈련용 데이터의 색상 또는 밝기 중 적어도 하나를 수정할 수 있다. 전자 장치는 관심 영역 이미지의 H 값 평균(이하 'H_1010')과 훈련용 데이터의 H 값의 평균(이하 'H_1020')에 기초하여 훈련용 데이터의 H 값을 보정할 수 있다. 예를 들면, 훈련용 데이터의 H 값 은 아래와 같이 보정될 수 있다. H_1020(x, y) = H_1020(x, y) + a(H_1010 - H_1020) (a는 보정 정도에 관한 값) 전자 장치는 관심 영역 이미지의 L 값 평균(이하 'L_1010')과 훈련용 데이터의 L 값의 평균(이하 'L_1020')에 기초하여 훈련용 데이터의 L 값을 보정할 수 있다. 예를 들면, 훈련용 데이터의 L 값 은 아래와 같이 보정될 수 있다. L_1020(x, y) = L_1020(x, y) + b(L_1010 - L_1020) (b는 보정 정도에 관한 값) 전자 장치는 색상 또는 밝기 중 적어도 하나가 수정된 목표 훈련용 데이터 및 관심 영역 이미지를 합성함으로써, 합성 훈련용 데이터를 생성할 수 있다. 전자 장치는 합성하려는 관심 영역 이미지와 목표 훈련용 데이터의 색상 및/또는 밝기를 유사하게 변경함으로써 실제 촬영된 이미지와 유사한 합성 훈련용 데이터를 만들 수 있다. 즉, 전자 장치는 실제 촬영된 이미지와 같이 배경과 객체가 모두 같은 조명 상황에서 촬영된 것처럼 모두 밝거나, 모두 어두운 훈련용 데이터 를 획득할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치가 관심 영역 이미지의 밝기 정보를 이용하여 목표 훈련용 데이터 의 밝기를 변경하는 과정을 설명하였지만, 이에 제한되지 않고, 배경 이미지의 밝기 정보를 이용하여 목 표 훈련용 데이터의 밝기를 변경할 수 있다. 예를 들면, 전자 장치는 배경 이미지의 밝기 정보를 획득하 고, 목표 훈련용 데이터에 대하여 관심 영역과 상관 없이 배경 이미지의 밝기 정보에 기초하여 목표 훈련 용 데이터의 밝기를 변경할 수 있다. 도 11은 본 개시의 일 실시예에 따른 컨텍스트를 이용하여 훈련용 데이터를 생성하는 방법을 설명하기 위한 도 면이다. 도 11을 참조하면, 관심 영역 이미지 및 합성 훈련용 데이터는 도 1의 관심 영역 이미지 합성 훈련용 데이터에 대응될 수 있지만, 이에 제한되지 않는다. 목표 훈련용 데이터는 도 7의 목표 훈련 용 데이터에 대응될 수 있지만, 이에 제한되지 않는다. 설명의 편의를 위하여, 사람 포즈 추정에 관한 인공 지능 모델의 합성 훈련용 데이터를 생성하는 방법을 예시로 설명하고, 학습 대상은 사용자로 가정하지만, 이에 제한되지 않고, 다른 인공 지능 모델에도 적용될 수 있다. 전자 장치는 관심 영역 이미지에 기초하여, 목표 훈련용 데이터를 결정할 수 있다. 본 개시 의 일 실시예에 따라서, 전자 장치는 관심 영역 이미지의 너비 및 높이의 비율에 기초하여, 목표 훈련용 데이터를 결정할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 관심 영역 이미지 의 너비 및 높이의 비율과 동일하거나 유사한 훈련용 이미지를 포함하는 목표 훈련용 데이터를 원 본 훈련용 데이터 중에서 선택할 수 있다. 본 개시의 일 실시예에 따라서, 전자 장치는 관심 영역 이미지의 너비 및 높이의 비율에 기초하여, 관심 영역 이미지에 포함된 객체 컨텍스트를 결정할 수 있다. 예를 들면, 객체 컨텍스트는 사용자가 앉아 있는 상태인지, 사용자가 서있는 상태인지, 사용자가 운동 중인 상태 인지 여부에 관한 정보를 포함할 수 있다.본 개시의 일 실시예에 따라서, 전자 장치는 관심 영역 이미지에 기초하여 관심 영역에 관한 제1 컨텍스트를 식별함으로써, 객체 컨텍스트를 결정할 수 있다. 예를 들면, 전자 장치는 관심 영역 이미지 가 소파를 포함한다는 제1 컨텍스트를 식별할 수 있다. 전자 장치는 소파를 포함한다는 제1 컨텍스 트에 기초하여, 사용자가 앉아 있는 상태 혹은 사용자가 누워 있는 상태로 객체 컨텍스트를 결정할 수 있다. 예 를 들면, 전자 장치는 사용자가 앉을 수 있는 가구(예: 의자 등)를 포함하지 않는 것으로 식별된 관심 영 역 이미지(1110a)에 기초하여, 사용자가 서있는 상태로 객체 컨텍스트를 결정할 수 있다. 본 개시의 일 실시예에 따라서, 전자 장치는 전자 장치에 관한 제2 컨텍스트 정보에 기초하 여 객체 컨텍스트를 결정할 수 있다. 본 개시에서 제2 컨텍스트 정보는 훈련용 데이터를 생성하는 전자 장치 혹은 외부 전자 장치의 동작에 관한 컨텍스트 정보를 의미할 수 있다. 예를 들면, 제2 컨텍스트 정보 는 전자 장치의 영상이 일시 정지된 상태라는 정보(1115a), 전자 장치의 영상이 재생 중인 상태라 는 정보(1115b), 또는 전자 장치의 특정 앱(예: 피트니스 앱)을 실행 중인 상태라는 정보(1115c)를 포함할 수 있다. 또한, 예를 들면, 전자 장치는 제2 컨텍스트 정보가 전자 장치의 특정 앱(예: 피트니스 앱)을 실행 중인 상태라는 정보(1115c)를 나타낼 때, 전자 장치는 운동 중인 상태라는 객체 컨텍스트를 결정할 수 있 다. 본 개시의 일 실시예에 따라, 전자 장치는 관심 영역 이미지의 너비 및 높이의 비율, 제1 컨텍스트 또는 제2 컨텍스트 중 적어도 하나에 기초하여, 객체 컨텍스트를 결정할 수 있다. 전술한 예시와 같이, 전자 장치는 관심 영역 이미지의 너비 및 높이의 비율, 제1 컨텍스트 또는 제2 컨텍스트에 기초하여 객체 컨텍스트를 결정할 수 있을 뿐 아니라, 이들의 조합에 의해서도 객체 컨텍스트를 결정할 수 있다. 본 개시의 일 실시예에 따라서, 전자 장치는 뉴럴 네트워크 혹은 테이블을 이용하여, 객체 컨텍스트를 결 정할 수 있다. 예를 들면, 전자 장치는 관심 영역 이미지의 너비 및 높이의 비율, 제1 컨텍스트 또는 제2 컨텍스트 중 적어도 하나가 입력이고, 객체 컨텍스트를 출력으로 포함하는 데이터셋을 이용하여 학습된 인공 지 능 모델을 이용하여 객체 컨텍스트를 결정할 수 있다. 또한, 예를 들면, 전자 장치는 관심 영역 이미지 의 너비 및 높이의 비율, 제1 컨텍스트 또는 제2 컨텍스트 중 적어도 하나와 객체 컨텍스트 사이의 관계 를 포함하는 테이블을 이용하여 객체 컨텍스트를 결정할 수 있다. 전자 장치는 원본 훈련용 데이터 중에서 객체 컨텍스트에 대응되는 목표 훈련용 데이터를 결정할 수 있다. 예를 들면, 객체 컨텍스트가 사용자가 서있는 상태를 나타내는 경우, 전자 장치는 원본 훈련용 데이터 중에서 서있는 상태에 대응되는 훈련용 데이터를 목표 훈련용 데이터(1120b)로 결정할 수 있다. 본 개시 의 일 실시예에 따라, 전자 장치는 객체 컨텍스트 및 관심 영역 이미지의 너비 및 높이의 비율에 기초하여, 목표 훈련용 데이터를 결정할 수 있다. 전자 장치는 객체 컨텍스트에 대응되면서 관심 영역 이미지의 너비 및 높이의 비율이 동일하거나 유사한 훈련용 데이터를 목표 훈련용 데이터로 결정할 수 있다. 예를 들면, 전자 장치는 관심 영역의 이미지(1110a)의 너비와 높이의 비율이 4보다 크고, 객체 컨텍스트가 사용자가 서 있는 상태인 경우, 사용자가 서있는 상태이며, 너비와 높이의 비율이 4이거 나 4에 가까운 훈련용 이미지를 포함하는 목표 훈련용 데이터(1120b)를 선택할 수 있다. 또는, 예를 들면, 전자 장치는 관심 영역의 이미지(1110b)의 너비와 높이의 비율이 2배이고, 객체 컨텍스트가 사용자가 앉아 있 는 상태인 경우, 사용자가 앉아 있으며, 너비와 높이의 비율이 2인 훈련용 이미지를 포함하는 목표 훈련용 데이 터(1120a)를 선택할 수 있다. 또는, 예를 들면, 전자 장치는 관심 영역의 이미지(1110c)의 너비와 높이의 비율이 3이고, 객체 컨텍스트가 사용자가 운동 중인 상태인 경우, 운동 중인 동작이며 너비와 높이의 비율이 3 인 훈련용 이미지를 포함하는 목표 훈련용 데이터(1120c)를 선택할 수 있다. 도 12는 본 개시의 일 실시예에 따른 훈련용 데이터를 생성하는 방법을 설명하기 위한 도면이다. 도 12를 참조하면, 본 개시의 일 실시예에 따른 전자 장치는 제1 촬영 이미지 및 제2 촬영 이미지 에 기초하여 합성 훈련용 데이터를 생성할 수 있다. 제1 촬영 이미지는 전자 장치에 의하여 촬영된 이미지 중에서 인공 지능 모델에 의하여 결정된 예측 신뢰도(confidence)가 소정의 값보다 크거나 같은 이미지일 수 있다. 예를 들면, 전자 장치는 촬영 이미지들 중에서 인공 지능 모델에 의하여 결정된 예측 신뢰도가 소정의 값보다 작은 이미지를 제외하고, 예측 신뢰도가 소정의 값보다 크거나 같은 이미지를 제1 촬영 이미지로 결정할 수 있다. 제2 촬영 이미지는 제1 촬영 이미지와 동일한 객체를 포함하고, 인공 지능 모델에 의하여 결정된 예측 신뢰도(confidence)가 소정의 값보다 작은 이미지일 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 제1 촬영 이미지를 획득할 수 있다. 본 개시의 일 실시 예에 따른 전자 장치는 인공 지능 모델을 이용하여 제1 촬영 이미지로부터 객체 이미지를 획 득할 수 있다. 예를 들면, 전자 장치는 제1 촬영 이미지에 포함된 객체를 포함하는 가장 작은 직사 각형 이미지를 객체 이미지로 결정할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 인공 지 능 모델을 이용하여 예측 데이터를 획득할 수 있다. 예를 들면, 예측 데이터는 제1 촬영 이미지 를 인공 지능 모델에 입력함으로써 획득된 출력 데이터일 수 있다. 예를 들면, 전자 장치는 제1 촬 영 이미지를 객체 탐지를 위한 인공 지능 모델에 입력함으로써 출력된 객체의 존재 영역 및 객체의 종류 를 포함하는 예측 데이터를 획득할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 제2 촬영 이미지를 획득할 수 있다. 본 개시의 일 실시 예에 따른 전자 장치는 인공 지능 모델을 이용하여 제2 촬영 이미지로부터 관심 영역을 획득 할 수 있다. 예를 들면, 전자 장치는 배경 이미지에 기초하여 관심 영역을 획득할 수 있다. 본 개 시의 일 실시예에 따라, 전자 장치는 배경 이미지의 관심 영역에 대응되는 관심 영역 이미지를 획 득할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 객체 이미지 및 관심 영역 이미지에 기초하여 합 성 훈련용 이미지를 생성할 수 있다. 예를 들면, 전자 장치는 객체 이미지의 객체 영역을 추 출하고, 관심 영역 이미지를 합성함으로써 합성 훈련용 이미지를 생성할 수 있다. 전자 장치는 합 성 훈련용 이미지 및 예측 데이터를 포함하는 객체에 관한 실측 합성 훈련용 데이터를 생성할 수 있다. 전자 장치는 인공 지능 모델에 의하여 신뢰도가 높은 입력 이미지에 기초하여 획득된 객체 이미지를 이용 하여 훈련용 데이터를 생성함으로써, 제1 이미지 및 제2 이미지에 포함된 객체에 관한 훈련용 데이 터를 생성할 수 있다. 전자 장치에 의하여 촬영된 이미지에 포함된 객체를 이용하여 훈련용 데이터는 임 의의 객체를 이용하여 생성된 훈련용 데이터보다 인공 지능 모델의 실제 사용 환경에 대한 정확도를 증가하도록 인공 지능 모델을 학습 시킬 수 있다. 전자 장치를 통해 촬영된 이미지에 포함된 객체가 복수인 경우, 복수의 객체 중에서 인공 지능 모델에 의 한 신뢰도가 낮은 객체에 대하여만 훈련용 데이터가 생성될 수 있다. 예를 들면, 전자 장치를 통해 촬영 된 하나 이상의 이미지에 객체 A, 객체 B가 나타나는 경우, 전자 장치는 촬영된 이미지 중에서 인공 지능 모델에 관한 신뢰도가 낮은 객체 B에 관하여 훈련용 데이터를 생성할 수 있다. 도 13은 본 개시의 일 실시예에 따른 훈련용 데이터를 생성하는 방법을 설명하기 위한 순서도이다. 도 13을 참조하면, 본 개시의 일 실시예에 따른 전자 장치가 인공 지능 모델의 학습을 위한 훈련용 데이 터를 생성하 방법은 단계 1310로부터 진행된다. 단계 1310에서, 전자 장치는 학습 대상에 해당하는 객체를 포함하는 제1 이미지를 획득할 수 있다. 예를 들면, 인공 지능 모델이 객체 탐지를 위한 모델인 경우 객체는 인공 지능 모델이 탐지할 수 있는 객체를 의미할 수 있다. 단계 1320에서, 전자 장치는 제1 이미지와 동일한 시점에서 촬영된 제2 이미지에 기초하여, 객체를 포함 하지 않는 배경 이미지를 획득할 수 있다. 예를 들면, 제1 이미지와 제2 이미지는 시점(view)이 동일한 하나의 카메라에 의하여 촬영된 것일 수 있다. 예를 들면, 제1 이미지와 제2 이미지는 위치가 고정된 전자 장치 의 카메라를 이용하여 촬영된 것일 수 있다. 단계 1330에서, 전자 장치는 제1 이미지 내에서 객체를 포함하는 관심 영역을 식별할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 제1 이미지와 배경 이미지에 기초하여 관심 영역을 식별할 수 있다. 예를 들면, 전자 장치는 제1 이미지와 배경 이미지의 차이에 대한 잔차 이미지를 이용하여 관심 영역을 식별할 수 있다. 단계 1340에서, 전자 장치는 배경 이미지로부터 관심 영역에 해당하는 관심 영역 이미지를 획득할 수 있 다. 본 개시의 일 실시예에 따라, 전자 장치는 배경 이미지의 관심 영역을 추출함으로써 관심 영역 이미 지를 획득할 수 있다. 단계 1350에서, 전자 장치는 기생성된 원본 훈련용 데이터 중에서, 관심 영역 이미지의 너비와 높이의 비 율에 기초하여 결정된 객체의 컨텍스트에 대응되는, 제1 목표 훈련용 데이터를 결정할 수 있다. 예를 들면, 제1 목표 훈련용 데이터는 객체의 컨텍스트에 해당하는 훈련용 이미지 및 훈련용 정보를 포함할 수 있다. 예를들면, 제1 목표 훈련용 데이터는 서있는 상태를 나타내는 훈련용 이미지 및 훈련용 정보를 포함할 수 있다. 단계 1360에서, 전자 장치는 관심 영역 이미지에 기초하여, 제1 목표 훈련용 데이터에 포함된 제1 훈련용 이미지를 수정함으로써, 배경 이미지의 적어도 일부가 포함된 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 제1 목표 훈련용 데이터에 포함된 제1 훈련용 이미지와 관심 영역 이미지 를 합성함으로써 훈련용 이미지를 생성할 수 있다. 합성 훈련용 데이터는 합성된 훈련용 이미지와 훈련용 데이 터를 포함할 수 있다. 도 14는 본 개시의 일 실시예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 도 14를 참조하면, 전자 장치는 메모리, 프로세서, 카메라를 포함할 수 있으나, 이에 한정되는 것은 아니며, 범용적인 구성이 더 추가될 수 있다. 일 실시예에 따른 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 전자 장 치로 입력되거나 전자 장치로부터 출력되는 데이터를 저장할 수 있다. 메모리는 프로세서 가 판독할 수 있는 명령어들, 데이터 구조, 및 프로그램 코드(program code)가 저장될 수 있다. 개시된 실시예들에서, 프로세서가 수행하는 동작들은 메모리에 저장된 프로그램의 명령어들 또는 코드들을 실행함으로써 구현될 수 있다. 일 실시예에 따른 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모 리 등)를 포함할 수 있으며, 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read- Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나를 포함하는 비 휘발성 메모리 및 램(RAM, Random Access Memory) 또는 SRAM(Static Random Access Memory)과 같 은 휘발성 메모리를 포함할 수 있다. 일 실시예에 따른 메모리는 훈련용 데이터를 생성하는 전자 장치가 태스크를 수행할 수 있도록 제 어하는 하나 이상의 인스트럭션 및/또는 프로그램을 저장할 수 있다. 예를 들어, 메모리에는 관심 영역 식별부, 관심 영역 이미지 획득부, 목표 훈련용 데이터 결정부, 합성 훈련용 데이터 생성부 등이 저장될 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 명령어들이나 프로그램화된 소프트웨어 모듈을 실행 함으로써, 전자 장치가 태스크를 수행할 수 있도록 동작이나 기능을 제어할 수 있다. 프로세서는 산술, 로직 및 입출력 연산과 시그널 프로세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 프로세서 는 메모리에 저장된 하나 이상의 인스트럭션(instructions)을 실행함으로써, 전자 장치가 합 성 훈련용 데이터를 생성하는 태스크를 수행하는 전반적인 동작들을 제어할 수 있다. 일 실시예에 따른 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서 (microprocessor), 그래픽 처리 장치(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 애플리케이션 프로세서 (Application Processor), 신경망 처리 장치(Neural Processing Unit) 또는 인공지능 모델의 처리에 특화된 하 드웨어 구조로 설계된 인공지능 전용 프로세서 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 프로세서를 구성하는 각 프로세서는 소정의 기능을 수행하기 위한 전용 프로세서일 수 있다. 일 실시예에 따른 인공 지능(AI; artificial intelligence) 프로세서는, 인공지능(AI) 모델을 이용하여, 전자 장치가 수행하도록 설정된 태스크의 처리를 위해, 연산 및 제어를 수행할 수 있다. AI 프로세서는, 인공 지능(AI)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전자 장치에 탑재될 수도 있다. 본 개시의 일 실시예에 따르면 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 학습 대상에 해당하는 객체를 포함하는 제1 이미지를 획득할 수 있다. 프로세서는 메모리에 저 장된 하나 이상의 인스트럭션을 실행함으로써, 제1 이미지와 동일한 시점에서 촬영된 제2 이미지에 기초하여, 객체를 포함하지 않는 배경 이미지를 획득할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인 스트럭션을 실행함으로써, 제1 이미지 내에서 객체를 포함하는 관심 영역을 식별할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 배경 이미지로부터 관심 영역에 해당하는 관심 영역 이미지를 획득할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 기생성된 원본 훈련용 데이터 중에서, 관심 영역 이미지의 너비와 높이의 비율에 기초하여 결정된 객체의 컨텍스트에 대응되는 제1 목표 훈련용 데이터를 결정할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 관심 영역 이미지에 기초하여, 제1 목표 훈련용 데이터에 포함된 제1 훈련 용 이미지를 수정함으로써, 배경 이미지의 적어도 일부가 포함된 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 소정의 배경을 포함하는 이미지 및 제1 목표 훈련용 데이터에 기초하여 생성된 제1 테스트 이미지와 배경 이미지 및 제1 목표 훈련용 데이터에 기초하여 생성된 제2 테스트 이미지를 이용하여, 인공 지능 모델의 예측 정확도를 결정할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 제1 테스트 이미지에 대한 제1 예측 정확도 및 제2 테스트 이미지에 대한 제2 예측 정확도에 기초하여, 추가 합 성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 제1 예측 정확도가 소정의 값보다 크거나 같고, 제2 예측 정확도가 소정의 값보다 작은 것에 기초하여, 원 본 훈련용 데이터 중에서 제2 목표 훈련용 데이터를 결정할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 관심 영역 이미지에 기초하여, 제2 목표 훈련용 데이터에 포함된 제2 훈련용 이미지를 수정함으로써, 추가 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 적어도 하나의 프로세서가 적어도 하나의 인스트럭션을 실행함으로써, 제1 예측 정확도 및 제2 예측 정확도가 소정의 값보다 작은 것에 기초하여, 배경 이미지로부터 관심 영역 이미지의 높이 및 너비와 동일한 추 가 관심 영역 이미지를 획득할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실 행함으로써, 추가 관심 영역 이미지에 기초하여, 제1 훈련용 이미지를 수정함으로써, 추가 합성 훈련용 데이터 를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 관심 영역 이미지의 색상 정보 또는 밝기 정보 중 적어도 하나를 획득할 수 있다. 프로세서는 메모리 에 저장된 하나 이상의 인스트럭션을 실행함으로써, 관심 영역 이미지의 색상 정보 또는 밝기 정보 중 적 어도 하나에 기초하여 제1 훈련용 이미지의 색상 또는 밝기 중 적어도 하나를 수정할 수 있다. 프로세서 는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 관심 영역 이미지에 기초하여, 수정된 제1 훈련용 이미지를 수정함으로써, 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 관심 영역 이미지에 기초하여, 관심 영역에 관한 제1 컨텍스트 정보를 획득할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 전자 장치의 상태에 관한 제2 컨텍스트 정보를 획득할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 제1 컨텍스 트 정보, 제2 컨텍스트 정보 및 배경 이미지의 너비와 높이의 비율에 기초하여, 객체의 컨텍스트를 결정할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 원본 훈련용 데이터 중에서 객체의 컨텍스트에 대응되는 제1 목표 훈련용 데이터를 결정할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 제1 이미지와 배경 이미지 사이의 잔차 이미지를 획득할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 잔차 이미지에 기초하여 관심 영역을 식별할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 제1 훈련용 이미지에 포함된 객체에 해당하는 객체 이미지를 추출할 수 있다. 프로세서는 메모리 에 저장된 하나 이상의 인스트럭션을 실행함으로써, 관심 영역 이미지와 객체 이미지를 합성함으로써 생 성된 합성 훈련용 이미지를 포함하는 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 객체 이미지 및 배경 이미지에 기초하여, 실측 합성 훈련용 이미지를 생성할 수 있다. 프로세서는 메 모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 제3 이미지를 인공 지능 모델에 입력함으로써, 제3 이미지에 포함된 객체에 관한 예측 데이터를 획득할 수 있다. 프로세서는 메모리에 저장된 하 나 이상의 인스트럭션을 실행함으로써, 실측 합성 훈련용 이미지와 상기 예측 데이터에 기초하여, 상기 객체에 관한 실측 합성 훈련용 데이터를 생성할 수 있다.일 실시예에 따른 카메라는, 객체를 촬영하여 비디오 및/또는 이미지를 획득할 수 있다. 본 개시의 일 실 시예에 따라, 카메라는 소정의 위치에 고정되어 촬영을 수행할 수 있다. 카메라는 예를 들어, RGB 카메라, 망원 카메라, 광각 카메라, 초광각 카메라 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 카메라 는 복수의 프레임들을 포함하는 비디오를 획득할 수 있다. 카메라의 구체적인 종류 및 세부 기능은 통상의 기술자가 명확하게 추론할 수 있으므로, 설명을 생략한다. 한편, 본 개시의 실시예들은 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어 를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스 될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨 터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구 현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독 가 능 명령어, 데이터 구조, 또는 프로그램 모듈과 같은 변조된 데이터 신호의 기타 데이터를 포함할 수 있다. 도 15는 본 개시의 일 실시예에 따른 훈련용 데이터를 생성하는 방법을 설명하기 위한 순서도이다. 도 15를 참조하면, 본 개시의 일 실시예에 따른 전자 장치는 TV일 수 있지만, 이에 제한되지 않고, 다양 한 전자 장치일 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 카메라를 이용하여 실내 공간을 촬영할 수 있다. 카메라 에 의하여 촬영된 이미지는 쇼파와 운동 중인 사람을 포함할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 카메라를 이용하여 실내 공간을 촬영하는 기능을 활성화 혹은 비활성화 할 수 있다. 전자 장치는 특정 태스크를 수행중인 경우 이미지를 촬영할 수 있다. 예를 들 면, 전자 장치는 헬스 애플리케이션 실행 중에만 이미지를 촬영할 수 있다. 전자 장치가 특정 태스 크를 수행중인 경우에 촬영된 이미지를 이용하여 훈련용 데이터를 생성하는 경우, 특정 태스크를 수행할 때 식 별되는 관심 영역 이미지를 이용하는 것이므로, 인공 지능 모델의 예측 정확도가 높을 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 사람 포즈 추정에 관한 인공 지능 모델을 이용할 수 있다. 전자 장치는 수행하는 태스크에 따라 다른 인공 지능 모델을 이용할 수 있다. 예를 들면, 전자 장치는 헬스 애플리케이션 실행 중에는 사람 포즈 추정에 관한 인공 지능 모델을 이용할 수 있고, 대기 중에는 객체 탐 지에 관한 인공 지능 모델을 이용할 수 있다. 전자 장치는 이용하는 인공 지능 모델에 따라 생성하는 훈 련용 데이터의 종류가 다를 수 있다. 예를 들면, 인공 지능 모델이 사람 포즈 추정을 위한 것인 경우, 전자 장 치에 의하여 생성되는 훈련용 데이터는 사람 포즈 추정에 대한 학습을 위한 훈련용 데이터일 수 있다. 전자 장치는 촬영된 이미지에 기초하여 배경 이미지를 획득할 수 있다. 전자 장치는 도 1, 도 2a, 도 2b 및 도 13을 참조하여 설명된 배경 생성 방법을 이용하여 촬영 이미지에 기초하여 배경 이미지를 생성할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 소정의 시간 간격마다 배경 이미지를 생성할 수 있다. 예를 들면, 전자 장치는 촬영 주기와는 별도의 시간 간격(예: 30분, 3시간 등)마다 배경 이미지를 생성할 수 있다. 전자 장치는 소정의 시간 간격 사이에 촬영된 이미지 전부 혹은 일부를 이용하여 배경 이미지를 생성할 수 있다. 예를 들면, 전자 장치는 소정의 시간 간격 사이에 촬영된 이미지들 중에서 일 부를 결정하고, 결정된 일부 이미지를 이용하여 배경 이미지를 생성할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 이미지 촬영할 때마다 배경 이미지를 생성할 수 있다. 전자 장치는 촬영된 이미지와 배경 이미지에 기초하여 관심 영역 이미지를 획득할 수 있다. 전자 장치 는 도 1, 도 3, 도 4 및 도 13을 참조하여 설명된 관심 영역 이미지 생성 방법을 이용하여 촬영된 이미지 와 배경 이미지에 기초하여 관심 영역 이미지를 획득할 수 있다. 전자 장치는 관심 영역 이미지에 기초하여 목표 훈련용 데이터를 결정할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 컨텍스트를 고려하여 목표 훈련용 데이터를 결정할 수 있다. 예를 들면, 전자 장치 가 운동 프로그램을 실행중인 경우, 사용자가 운동 중인 상태라는 객체 컨텍스트를 결정할 수 있다. 예를 들면, 전자 장치가 운동 프로그램 중 요가 프로그램을 실행중인 경우, 사용자가 요가 중인 상태라는 객체 컨텍스트를 결정할 수 있다. 전자 장치는 사용자가 운동 중인 상태 혹은 요가 중인 상태라는 객체 컨텍스 트에 기초하여 목표 훈련용 데이터를 결정할 수 있다. 전자 장치는 관심 영역 이미지 및 목표 훈련용 데이터를 이용하여 합성 훈련용 데이터를 생성할 수 있다. 전자 장치는 도 1 및 도 7을 참조하여 설명된 합성 훈련용 데이터 생성 방법을 이용하여 관심 영역 이미 지 및 목표 훈련용 데이터를 이용하여 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 특정 조건에서 합성 훈련용 데이터를 생성할 수 있다. 예를 들 면, 전자 장치는 카메라를 이용하여 촬영 중인 경우에도 특정 조건을 만족하지 않으면 합성 훈련용 데이터를 생성하지 않을 수 있다. 예를 들면, 전자 장치는 사용자가 특정 동작(예: 사용자 정보 등록, 제 스처 컨트롤)할 때 합성 훈련용 데이터를 생성할 수 있다. 이러한 예시에서, 전자 장치는 이미지 촬영 여 부와 별개로 특정 조건을 만족하는 경우에만 관심 영역을 식별하거나 배경 이미지를 생성할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 인공 지능 모델을 이용한 예측 신뢰도(prediction confidenc e)가 낮은 경우, 합성 데이터를 생성할 수 있다. 예를 들면, 전자 장치는 주기적으로 촬영 이미지를 획득 하더라도, 인공 지능 모델에 대한 예측 신뢰도가 높은 것으로 식별되는 경우에는 합성 훈련용 데이터를 생성하 지 않고, 예측 신뢰도가 낮은 것으로 식별된 때부터 합성 훈련용 데이터를 생성할 수 있다. 예측 신뢰도는 인공 지능 모델이 입력 이미지에 대응하는 예측에 대하여 확신하는 점수 또는 확률을 의미할 수 있다. 예를 들면, 객 체 분류 모델에 관한 인공 지능 모델에 있어서, 인공 지능 모델이 분류할 수 있는 각 객체에 대한 예측 신뢰도 는 인공 지능 모델이 입력 이미지에 대응하는 출력으로 각 객체를 예측하는 확률 또는 점수를 의미할 수 있다. 예를 들면, \"사람\"에 대한 예측 신뢰도는 인공 지능 모델이 입력 이미지에 대응하는 예측을 \"사람\"으로 판단하 는 확률 또는 점수를 의미할 수 있다. 도 16은 본 개시의 일 실시예에 따른 훈련용 데이터를 생성하여 인공 지능 모델을 활용하는 과정을 설명하기 위 한 도면이다. 도 16을 참조하면, 본 개시의 일 실시예에 따른 전자 장치가 합성 훈련용 데이터를 생성하는 방법 은 단계 1610부터 진행된다. 단계 1610에서, 전자 장치는 객체 특성을 식별할 수 있다. 예를 들면, 전자 장치는 촬영된 이미지 에 포함된 객체의 특성(예: 종류, 나이, 성별 등)을 식별할 수 있다. 본 개시의 일 실시예에 따른 전자 장치 는 객체 분석을 이용하여 객체의 특성을 식별할 수 있다. 예를 들면, 전자 장치는 촬영된 이미지를 입력으로 하고, 입력된 이미지에 포함된 객체의 특성을 출력으로 하는 인공 지능 모델을 이용하여 객체의 특성 을 식별할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 객체 인식 또는 객체 분류를 이용하여 객체의 특성을 식별할 수 있다. 예를 들면, 전자 장치는 객체 인식 또는 객체 분류를 이용하여 촬영된 이미지에 포함된 객체를 식 별하고, 식별된 객체의 특성을 결정함으로써 객체의 특성을 식별할 수 있다. 단계 1620에서, 전자 장치는 객체의 특성에 따른 훈련용 데이터를 획득할 수 있다. 예를 들면, 전자 장치 는 객체가 흑인, 중년, 남성인 경우에는 해당 피부 타입, 나이, 성별에 대응되는 원본 훈련용 데이터를 획득할 수 있다. 단계 1630에서, 전자 장치는 객체 특성에 따라 획득된 원본 훈련용 데이터를 이용하여 합성 훈련용 데이 터를 생성할 수 있다. 전자 장치가 원본 훈련용 데이터를 이용하여 합성 훈련용 데이터를 생성하는 방법 은 전술한 바 생략한다. 전자 장치는 사용자 혹은 목표 객체와 유사한 원본 훈련용 데이터를 획득함으로 써 객체와 유사한 합성 훈련용 데이터를 생성할 수 있다. 도 17은 본 개시의 일 실시예에 따른 전자 장치와 서버를 이용하여 훈련용 데이터를 생성하는 방법을 설명하기 위한 시퀀스 다이어그램이다. 도 17을 참조하면, 서버는 전자 장치를 통해 획득한 정보에 기초하여 모델을 합성 훈련용 데이터를 생성할 수 있다. 단계 1710에서, 전자 장치는 서버로 합성 훈련용 데이터 생성을 위한 이미지를 전송할 수 있다. 합 성 훈련용 데이터 생성을 위한 이미지는 전자 장치가 촬영한 촬영 이미지, 배경 이미지, 또는 관심 영역 이미지 중 적어도 하나일 수 있다. 단계 1720에서, 서버는 합성 훈련용 데이터를 생성할 수 있다. 예를 들면, 서버가 관심 영역 이미 지를 수신한 경우, 원본 훈련용 데이터와 합성함으로써 합성 훈련용 데이터를 생성할 수 있다. 단계 1730에서, 서버는 합성 훈련용 데이터에 기초하여 인공 지능 모델을 훈련시킬 수 있다. 단계 1740에 서, 서버는 전자 장치로 훈련된 인공 지능 모델을 전송할 수 있다. 일 실시예에 따라, 서버가 합성 훈련용 데이터를 전자 장치로 전달하고 전자 장치가 수신한 합성 훈련용 데이터를 이용하여 인공 지능 모델을 학습할 수 있다. 도 18은 본 개시의 일 실시예에 따른 서버의 구성을 설명하기 위한 블록도이다. 도 18을 참조하면, 서버는 메모리, 프로세서, 통신 인터페이스를 포함할 수 있으나, 이에 한정되는 것은 아니며, 범용적인 구성이 더 추가될 수 있다. 일 실시예에 따른 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 서버 로 입력되거나 서버로부터 출력되는 데이터를 저장할 수 있다. 메모리는 프로세서가 판독할 수 있는 명령어들, 데이터 구조, 및 프로그램 코드(program code)가 저장될 수 있다. 개시된 실시예들에 서, 프로세서가 수행하는 동작들은 메모리에 저장된 프로그램의 명령어들 또는 코드들을 실행함으 로써 구현될 수 있다. 일 실시예에 따른 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모 리 등)를 포함할 수 있으며, 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read- Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나를 포함하는 비 휘발성 메모리 및 램(RAM, Random Access Memory) 또는 SRAM(Static Random Access Memory)과 같 은 휘발성 메모리를 포함할 수 있다. 일 실시예에 따른 메모리는 훈련용 데이터를 생성하는 서버가 태스크를 수행할 수 있도록 제어하는 하나 이상의 인스트럭션 및/또는 프로그램을 저장할 수 있다. 예를 들어, 메모리에는 관심 영역 식별부 , 관심 영역 이미지 획득부, 목표 훈련용 데이터 결정부, 합성 훈련용 데이터 생성부 등이 저장될 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 명령어들이나 프로그램화된 소프트웨어 모듈을 실행 함으로써, 서버가 태스크를 수행할 수 있도록 동작이나 기능을 제어할 수 있다. 프로세서는 산술, 로직 및 입출력 연산과 시그널 프로세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션(instructions)을 실행함으로써, 서버가 합성 훈련용 데이 터를 생성하는 태스크를 수행하는 전반적인 동작들을 제어할 수 있다. 일 실시예에 따른 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서 (microprocessor), 그래픽 처리 장치(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 애플리케이션 프로세서 (Application Processor), 신경망 처리 장치(Neural Processing Unit) 또는 인공지능 모델의 처리에 특화된 하 드웨어 구조로 설계된 인공지능 전용 프로세서 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 프로세서를 구성하는 각 프로세서는 소정의 기능을 수행하기 위한 전용 프로세서일 수 있다. 일 실시예에 따른 인공 지능(AI; artificial intelligence) 프로세서는, 인공지능(AI) 모델을 이용하여, 서버 가 수행하도록 설정된 태스크의 처리를 위해, 연산 및 제어를 수행할 수 있다. AI 프로세서는, 인공 지능 (AI)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 서버에 탑재될 수도 있다. 본 개시의 일 실시예에 따르면 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 학습 대상에 해당하는 객체를 포함하는 제1 이미지를 획득할 수 있다. 프로세서는 메모리에 저 장된 하나 이상의 인스트럭션을 실행함으로써, 제1 이미지와 동일한 시점에서 촬영된 제2 이미지에 기초하여, 객체를 포함하지 않는 배경 이미지를 획득할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인 스트럭션을 실행함으로써, 제1 이미지 내에서 객체를 포함하는 관심 영역을 식별할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 배경 이미지로부터 관심 영역에 해당하는 관심 영역 이미지를 획득할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 기생성된 원본 훈련용 데이터 중에서, 관심 영역 이미지의 너비와 높이의 비율에 기초하여 결정된 객체의 컨텍스트에 대응되는 제1 목표 훈련용 데이터를 결정할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 관심 영역 이미지에 기초하여, 제1 목표 훈련용 데이터에 포함된 제1 훈련용 이미지를 수정함으로써, 배경 이미지의 적어도 일부가 포함된 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 소정의 배경을 포함하는 이미지 및 제1 목표 훈련용 데이터에 기초하여 생성된 제1 테스트 이미지와 배경 이미지 및 제1 목표 훈련용 데이터에 기초하여 생성된 제2 테스트 이미지를 이용하여, 인공 지능 모델의 예측 정확도를 결정할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 제1 테스트 이미지에 대한 제1 예측 정확도 및 제2 테스트 이미지에 대한 제2 예측 정확도에 기초하여, 추가 합 성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 제1 예측 정확도가 소정의 값보다 크거나 같고, 제2 예측 정확도가 소정의 값보다 작은 것에 기초하여, 원 본 훈련용 데이터 중에서 제2 목표 훈련용 데이터를 결정할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 관심 영역 이미지에 기초하여, 제2 목표 훈련용 데이터에 포함된 제2 훈련용 이미지를 수정함으로써, 추가 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 적어도 하나의 프로세서가 적어도 하나의 인스트럭션을 실행함으로써, 제1 예측 정확도 및 제2 예측 정확도가 소정의 값보다 작은 것에 기초하여, 배경 이미지로부터 관심 영역 이미지의 높이 및 너비와 동일한 추 가 관심 영역 이미지를 획득할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실 행함으로써, 추가 관심 영역 이미지에 기초하여, 제1 훈련용 이미지를 수정함으로써, 추가 합성 훈련용 데이터 를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 관심 영역 이미지의 색상 정보 또는 밝기 정보 중 적어도 하나를 획득할 수 있다. 프로세서는 메모리 에 저장된 하나 이상의 인스트럭션을 실행함으로써, 관심 영역 이미지의 색상 정보 또는 밝기 정보 중 적 어도 하나에 기초하여 제1 훈련용 이미지의 색상 또는 밝기 중 적어도 하나를 수정할 수 있다. 프로세서 는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 관심 영역 이미지에 기초하여, 수정된 제1 훈련용 이미지를 수정함으로써, 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 관심 영역 이미지에 기초하여, 관심 영역에 관한 제1 컨텍스트 정보를 획득할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 전자 장치의 상태에 관한 제2 컨텍스트 정보를 획득할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 제1 컨텍스 트 정보, 제2 컨텍스트 정보 및 배경 이미지의 너비와 높이의 비율에 기초하여, 객체의 컨텍스트를 결정할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 원본 훈련용 데이터 중에서 객체의 컨텍스트에 대응되는 제1 목표 훈련용 데이터를 결정할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 제1 이미지와 배경 이미지 사이의 잔차 이미지를 획득할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 잔차 이미지에 기초하여 관심 영역을 식별할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 제1 훈련용 이미지에 포함된 객체에 해당하는 객체 이미지를 추출할 수 있다. 프로세서는 메모리 에 저장된 하나 이상의 인스트럭션을 실행함으로써, 관심 영역 이미지와 객체 이미지를 합성함으로써 생 성된 합성 훈련용 이미지를 포함하는 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 합성 훈련용 데이터를 이용하여 인공 지능 모델을 학습시킬 수 있다. 프로세서는 메모리에 저 장된 하나 이상의 인스트럭션을 실행함으로써, 통신 인터페이스를 이용하여 학습된 인공지능 모델을 외부 전자 장치로 전송할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 인공 지능 모델을 이용하여, 인공 지능 모델을 이용하여, 제1 이미지로부터 객체에 관한 실측 훈련용 데이 터를 생성할 수 있다. 객체 이미지 및 배경 이미지에 기초하여, 실측 합성 훈련용 이미지를 생성할 수 있다. 프 로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 실측 훈련용 데이터와 배경 이 미지에 기초하여, 실측 합성 훈련용 데이터를 생성할 수 있다. 제3 이미지를 인공 지능 모델에 입력함으로써,제3 이미지에 포함된 객체에 관한 예측 데이터를 획득할 수 있다. 프로세서는 메모리에 저장된 하 나 이상의 인스트럭션을 실행함으로써, 실측 합성 훈련용 이미지와 상기 예측 데이터에 기초하여, 상기 객체에 관한 실측 합성 훈련용 데이터를 생성할 수 있다. 통신 인터페이스는 통신 회로를 포함할 수 있다. 통신 인터페이스는 예를 들어, 유선 랜, 무선 랜 (Wireless LAN), 와이파이(Wi-Fi), 블루투스(Bluetooth), 지그비(ZigBee), WFD(Wi-Fi Direct), 적외선 통신 (IrDA, infrared Data Association), BLE (Bluetooth Low Energy), NFC(Near Field Communication), 와이브로 (Wireless Broadband Internet, Wibro), 와이맥스(World Interoperability for Microwave Access, WiMAX), SWAP(Shared Wireless Access Protocol), 와이기그(Wireless Gigabit Alliances, WiGig) 및 RF 통신을 포함하 는 데이터 통신 방식 중 적어도 하나를 이용하여, 서버와 다른 디바이스들 간의 데이터 통신을 수행할 수 있는, 통신 회로를 포함할 수 있다. 통신 인터페이스는 서버의 훈련용 데이터를 생성하기 위한 데이터를 외부 전자 장치와 송수신할 수 있다. 예를 들어, 통신 인터페이스는 서버가 이용하는 인공지능 모델들을 송수신하거나, 인공지능 모델들 혹은 관심 영역 이미지를 외부 전자 장치 등과 송수신할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비 일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미 할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하 지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 본 개시의 일 양태에 따라서, 인공 지능 모델의 학습을 위한 훈련용 데이터를 생성하는 방법이 제공된다. 훈련 용 데이터 생성 방법은 학습 대상에 해당하는 객체를 포함하는 제1 이미지를 획득하는 단계를 포함할 수 있다. 훈련용 데이터 생성 방법은 제1 이미지와 동일한 시점에서 촬영된 제2 이미지에 기초하여, 객체를 포함하지 않 는 배경 이미지를 획득하는 단계를 포함할 수 있다. 훈련용 데이터 생성 방법은 제1 이미지 내에서 객체를 포함 하는 관심 영역을 식별하는 단계를 포함할 수 있다. 훈련용 데이터 생성 방법은 배경 이미지로부터 관심 영역에 해당하는 관심 영역 이미지를 획득하는 단계를 포함할 수 있다. 훈련용 데이터 생성 방법은 기생성된 원본 훈련 용 데이터 중에서, 관심 영역 이미지의 너비와 높이의 비율에 기초하여 결정된 객체의 컨텍스트에 대응되는, 제 1 목표 훈련용 데이터를 결정하는 단계를 포함할 수 있다. 훈련용 데이터 생성 방법은 관심 영역 이미지에 기초 하여, 제1 목표 훈련용 데이터에 포함된 제1 훈련용 이미지를 수정함으로써, 배경 이미지의 적어도 일부가 포함 된 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따라서, 훈련용 데이터 생성 방법은 소정의 배경을 포함하는 이미지 및 제1 목표 훈련용 데이터에 기초하여 생성된 제1 테스트 이미지와 배경 이미지 및 제1 목표 훈련용 데이터에 기초하여 생성된 제2 테스트 이미지를 이용하여, 인공 지능 모델의 예측 정확도를 결정하는 단계를 포함할 수 있다. 훈련용 데이터 생성 방법은 제1 테스트 이미지에 대한 제1 예측 정확도 및 제2 테스트 이미지에 대한 제2 예측 정확도에 기초 하여, 추가 합성 훈련용 데이터를 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따라서, 추가 합성 훈련용 데이터를 생성하는 단계는 제1 예측 정확도가 소정의 값보다 크거나 같고, 제2 예측 정확도가 소정의 값보다 작은 것에 기초하여, 원본 훈련용 데이터 중에서 제2 목표 훈련 용 데이터를 결정하는 단계를 포함할 수 있다. 추가 합성 훈련용 데이터를 생성하는 단계는 관심 영역 이미지에 기초하여, 제2 목표 훈련용 데이터에 포함된 제2 훈련용 이미지를 수정함으로써, 추가 합성 훈련용 데이터를 생 성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따라서, 추가 합성 훈련용 데이터를 생성하는 단계는 제1 예측 정확도 및 제2 예측 정확 도가 소정의 값보다 작은 것에 기초하여, 배경 이미지로부터 관심 영역 이미지의 높이 및 너비와 동일한 추가 관심 영역 이미지를 획득하는 단계를 포함할 수 있다. 추가 합성 훈련용 데이터를 생성하는 단계는 추가 관심영역 이미지에 기초하여, 제1 훈련용 이미지를 수정함으로써, 추가 합성 훈련용 데이터를 생성하는 단계를 포함 할 수 있다. 본 개시의 일 실시예에 따라서, 합성 훈련용 데이터를 생성하는 단계는, 관심 영역 이미지의 색상 정보 또는 밝 기 정보 중 적어도 하나를 획득하는 단계를 포함할 수 있다. 합성 훈련용 데이터를 생성하는 단계는 관심 영역 이미지의 색상 정보 또는 밝기 정보 중 적어도 하나에 기초하여 제1 훈련용 이미지의 색상 또는 밝기 중 적어도 하나를 수정하는 단계를 포함할 수 있다. 합성 훈련용 데이터를 생성하는 단계는 관심 영역 이미지에 기초하여, 수정된 제1 훈련용 이미지를 수정함으로써, 합성 훈련용 데이터를 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따라서, 제1 목표 훈련용 데이터를 결정하는 단계는, 관심 영역 이미지에 기초하여, 관 심 영역에 관한 제1 컨텍스트 정보를 획득하는 단계를 포함할 수 있다. 제1 목표 훈련용 데이터를 결정하는 단 계는, 전자 장치의 상태에 관한 제2 컨텍스트 정보를 획득하는 단계를 포함할 수 있다. 제1 목표 훈련용 데이터 를 결정하는 단계는, 제1 컨텍스트 정보, 제2 컨텍스트 정보 및 배경 이미지의 너비와 높이의 비율에 기초하여, 객체의 컨텍스트를 결정하는 단계를 포함할 수 있다. 제1 목표 훈련용 데이터를 결정하는 단계는, 원본 훈련용 데이터 중에서 객체의 컨텍스트에 대응되는 제1 목표 훈련용 데이터를 결정하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따라서, 관심 영역을 식별하는 단계는, 제1 이미지와 배경 이미지 사이의 잔차 이미지를 획득하는 단계를 포함할 수 있다. 관심 영역을 식별하는 단계는, 잔차 이미지에 기초하여 관심 영역을 식별하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따라서, 합성 훈련용 데이터를 생성하는 단계는, 제1 훈련용 이미지에 포함된 객체에 해 당하는 객체 이미지를 추출하는 단계를 포함할 수 있다. 합성 훈련용 데이터를 생성하는 단계는, 관심 영역 이 미지와 객체 이미지를 합성함으로써 생성된 합성 훈련용 이미지를 포함하는 합성 훈련용 데이터를 생성하는 단 계를 포함할 수 있다. 본 개시의 일 실시예에 따라서, 훈련용 데이터 생성 방법은 객체 이미지 및 배경 이미지에 기초하여, 실측 합성 훈련용 이미지를 생성하는 단계를 포함할 수 있다. 훈련용 데이터 생성 방법은 제3 이미지를 인공 지능 모델에 입력함으로써, 제3 이미지에 포함된 객체에 관한 예측 데이터를 획득하는 단계를 포함할 수 있다. 훈련용 데이 터 생성 방법은 실측 합성 훈련용 이미지와 상기 예측 데이터에 기초하여, 상기 객체에 관한 실측 합성 훈련용 데이터를 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따라서, 인공 지능 모델은 포즈 추정 모델, 객체 탐지 모델, 또는 객체 분류 모델 중 적 어도 하나를 포함할 수 있다. 객체는 사람, 동물, 또는 사물 중 적어도 하나를 포함할 수 있다. 본 개시의 일 양태에 따라서, 전술한 방법을 수행하도록 하는 프로그램이 저장된 하나 이상의 컴퓨터로 읽을 수 있는 기록매체가 제공된다. 본 개시의 일 양태에 따르면 합성 훈련용 데이터를 생성하는 전자 장치가 제공된다. 전자 장치는 메모리 및 적어도 하나의 프로세서를 포함할 수 있다. 적어도 하나의 프로세서는 메모리 에 저장된 하나 이상의 인스트럭션을 실행함으로써, 학습 대상에 해당하는 객체를 포함하는 제1 이미지를 획득할 수 있다. 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 제1 이미지와 동일한 시점에서 촬영된 제2 이미지에 기초하여, 객체를 포함하지 않는 배경 이미지를 획득할 수 있다. 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 제1 이미지 내에서 객체를 포함하는 관심 영역을 식별할 수 있다. 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 배경 이미지로부터 관심 영역에 해당하는 관심 영역 이미지를 획득할 수 있다. 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 기생성된 원본 훈련용 데이터 중에서, 관심 영역 이미지의 너비와 높이의 비율에 기초하여 결정된 객체의 컨텍스트에 대응되는 제1 목표 훈련용 데이터를 결정할 수 있다. 적어도 하나의 프로세서는 메모리(141 0)에 저장된 하나 이상의 인스트럭션을 실행함으로써, 관심 영역 이미지에 기초하여, 제1 목표 훈련용 데이터에 포함된 제1 훈련용 이미지를 수정함으로써, 배경 이미지의 적어도 일부가 포함된 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭션 을 실행함으로써, 소정의 배경을 포함하는 이미지 및 제1 목표 훈련용 데이터에 기초하여 생성된 제1 테스트 이 미지와 배경 이미지 및 제1 목표 훈련용 데이터에 기초하여 생성된 제2 테스트 이미지를 이용하여, 인공 지능 모델의 예측 정확도를 결정할 수 있다. 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 제1 테스트 이미지에 대한 제1 예측 정확도 및 제2 테스트 이미지에 대한 제2 예측 정확도에 기초하여, 추가 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭션 을 실행함으로써, 제1 예측 정확도가 소정의 값보다 크거나 같고, 제2 예측 정확도가 소정의 값보다 작은 것에 기초하여, 원본 훈련용 데이터 중에서 제2 목표 훈련용 데이터를 결정할 수 있다. 적어도 하나의 프로세서 는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 관심 영역 이미지에 기초하여, 제2 목표 훈련용 데이터에 포함된 제2 훈련용 이미지를 수정함으로써, 추가 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭 션을 실행함으로써, 적어도 하나의 프로세서가 적어도 하나의 인스트럭션을 실행함으로써, 제1 예측 정확 도 및 제2 예측 정확도가 소정의 값보다 작은 것에 기초하여, 배경 이미지로부터 관심 영역 이미지의 높이 및 너비와 동일한 추가 관심 영역 이미지를 획득할 수 있다. 적어도 하나의 프로세서는 메모리에 저장 된 하나 이상의 인스트럭션을 실행함으로써, 추가 관심 영역 이미지에 기초하여, 제1 훈련용 이미지를 수정함으 로써, 추가 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭 션을 실행함으로써, 관심 영역 이미지의 색상 정보 또는 밝기 정보 중 적어도 하나를 획득할 수 있다. 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 관심 영역 이미지의 색상 정보 또는 밝기 정보 중 적어도 하나에 기초하여 제1 훈련용 이미지의 색상 또는 밝기 중 적어도 하나를 수정할 수 있다. 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 관심 영역 이미지에 기초하여, 수정된 제1 훈련용 이미지를 수정함으로써, 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭 션을 실행함으로써, 관심 영역 이미지에 기초하여, 관심 영역에 관한 제1 컨텍스트 정보를 획득할 수 있다. 적 어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 전자 장치의 상 태에 관한 제2 컨텍스트 정보를 획득할 수 있다. 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 제1 컨텍스트 정보, 제2 컨텍스트 정보 및 배경 이미지의 너비와 높이의 비 율에 기초하여, 객체의 컨텍스트를 결정할 수 있다. 적어도 하나의 프로세서는 메모리에 저장된 하 나 이상의 인스트럭션을 실행함으로써, 원본 훈련용 데이터 중에서 객체의 컨텍스트에 대응되는 제1 목표 훈련 용 데이터를 결정할 수 있다. 본 개시의 일 실시예에 따르면, 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭 션을 실행함으로써, 제1 이미지와 배경 이미지 사이의 잔차 이미지를 획득할 수 있다. 적어도 하나의 프로세서 는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 잔차 이미지에 기초하여 관심 영역을 식별할 수 있다. 본 개시의 일 실시예에 따르면, 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭 션을 실행함으로써, 제1 훈련용 이미지에 포함된 객체에 해당하는 객체 이미지를 추출할 수 있다. 적어도 하나 의 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 관심 영역 이미지와 객체 이미지를 합성함으로써 생성된 합성 훈련용 이미지를 포함하는 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭 션을 실행함으로써, 객체 이미지 및 배경 이미지에 기초하여, 실측 합성 훈련용 이미지를 생성할 수 있다. 적어 도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 제3 이미지를 인 공 지능 모델에 입력함으로써, 제3 이미지에 포함된 객체에 관한 예측 데이터를 획득할 수 있다. 적어도 하나의 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 실측 합성 훈련용 이미지와 상기 예측 데이터에 기초하여, 상기 객체에 관한 실측 합성 훈련용 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따라, 인공 지능 모델은 포즈 추정 모델, 객체 탐지 모델, 또는 객체 분류 모델 중 적어 도 하나를 포함할 수 있다. 객체는 사람, 동물, 또는 사물 중 적어도 하나를 포함할 수 있다.도면 도면1 도면2a 도면2b 도면3 도면4 도면5a 도면5b 도면6 도면7 도면8 도면9a 도면9b 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18"}
{"patent_id": "10-2022-0178691", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 훈련용 데이터를 생성하는 방법을 설명하기 위한 도면이다. 도 2a는 본 개시의 일 실시예에 따른 배경 이미지를 생성하는 방법을 설명하기 위한 도면이다. 도 2b는 본 개시의 일 실시예에 따른 배경 이미지를 생성하는 방법을 설명하기 위한 도면이다. 도 3은 본 개시의 일 실시예에 따른 관심 영역을 식별하는 방법을 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시예에 따른 관심 영역 이미지를 생성하는 방법을 설명하기 위한 도면이다. 도 5a는 본 개시의 일 실시예에 따른 훈련용 데이터를 설명하기 위한 도면이다. 도 5b는 본 개시의 일 실시예에 따른 훈련용 데이터를 설명하기 위한 도면이다. 도 6는 본 개시의 일 실시예에 따른 인공 지능 모델을 학습하는 방법을 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시예에 따른 훈련용 데이터를 생성하는 방법을 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시예에 따른 추가 합성 훈련용 데이터를 생성하는지 여부를 결정하는 방법을 설명하기위한 도면이다. 도 9a는 본 개시의 일 실시예에 따른 추가 합성 훈련용 데이터를 생성하는지 여부를 결정하는 방법을 설명하기 위한 순서도이다. 도 9b는 본 개시의 일 실시예에 따른 추가 합성 훈련용 데이터를 생성하는지 여부를 결정하는 방법을 설명하기 위한 순서도이다. 도 10은 본 개시의 일 실시예에 따른 훈련용 데이터를 생성하는 방법을 설명하기 위한 도면이다. 도 11은 본 개시의 일 실시예에 따른 컨텍스트를 이용하여 훈련용 데이터를 생성하는 방법을 설명하기 위한 도 면이다. 도 12는 본 개시의 일 실시예에 따른 훈련용 데이터를 생성하는 방법을 설명하기 위한 도면이다. 도 13은 본 개시의 일 실시예에 따른 훈련용 데이터를 생성하는 방법을 설명하기 위한 순서도이다. 도 14는 본 개시의 일 실시예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 도 15는 본 개시의 일 실시예에 따른 훈련용 데이터를 생성하는 방법을 설명하기 위한 순서도이다. 도 16은 본 개시의 일 실시예에 따른 훈련용 데이터를 생성하여 인공 지능 모델을 활용하는 과정을 설명하기 위 한 도면이다. 도 17은 본 개시의 일 실시예에 따른 전자 장치와 서버를 이용하여 훈련용 데이터를 생성하는 방법을 설명하기 위한 시퀀스 다이어그램이다. 도 18은 본 개시의 일 실시예에 따른 서버의 구성을 설명하기 위한 블록도이다."}
