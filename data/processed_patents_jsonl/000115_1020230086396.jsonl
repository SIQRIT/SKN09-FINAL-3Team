{"patent_id": "10-2023-0086396", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0006515", "출원번호": "10-2023-0086396", "발명의 명칭": "청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시스템", "출원인": "(주)휴먼아이티", "발명자": "윤광식"}}
{"patent_id": "10-2023-0086396", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "소리 정보를 수집하여 무선으로 정보 분석기에 전송하고, 상기 정보 분석기로부터 전송된 위험 상황 정보 및 위험 상황 대피 정보를 수신하여 시각적으로 표출해주는 인공지능 안경; 및상기 인공지능 안경과 무선통신을 통해 실시간으로 접속하고, 수신한 소리 정보를 분석하여 위험 상황 유무를판단하며, 위험 상황으로 판단시 위험 상황 정보와 위험 상황 대피정보를 생성하여 상기 인공지능 안경으로 전송하는 정보 분석기를 포함하는 것을 특징으로 하는 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시스템."}
{"patent_id": "10-2023-0086396", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에서, 상기 인공지능 안경은,소리 정보를 감지하는 소리 감지부;상기 소리 감지부에서 감지한 소리 정보를 상기 정보 분석기에 전송하도록 제어하며, 상기 정보 분석기로부터전송된 위험 상황 정보와 위험 상황 대피정보의 시각적 표시를 제어하는 제어부;상기 제어부의 제어에 따라 위험 상황 정보 및 위험상황 대피정보를 시각적으로 표시해주는 디스플레이를 포함하는 것을 특징으로 하는 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시스템."}
{"patent_id": "10-2023-0086396", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에서, 상기 디스플레이는,웨어러블 디스플레이나 스마트 디스플레이 및 헤드업 디스플레이(HUD) 중 어느 하나로 구현되는 것을 특징으로하는 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시스템."}
{"patent_id": "10-2023-0086396", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에서, 상기 정보 분석기는,상기 인공지능 안경으로부터 전송된 정보를 수신하거나 네트워크를 통해 전송된 정보를 수신하는 정보 수신부;상기 정보 수신부를 통해 수신한 정보가 소리 정보일 경우, 소리 분석 알고리즘을 이용하여 소리를 분석하는 소리 분석부;상기 소리 분석부에 의해 분석한 소리 분석 결과가 위험 상황일 경우, 위험 상황 정보 및 위험상황 대피 정보를포함하는 안전 정보를 생성하는 안전정보 생성부;상기 안전정보 생성부에서 생성한 안전 정보를 상기 인공지능 안경으로 전송하도록 제어하는 제어부; 및상기 제어부의 제어에 따라 상기 안전 정보를 상기 인공지능 안경으로 전송하는 안전정보 전송부를 포함하는 것을 특징으로 하는 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시스템."}
{"patent_id": "10-2023-0086396", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2025-0006515-3-청구항 4에서, 상기 제어부는,위험 상황 정보가 화재일 경우, GPS를 통해 현재 위치 정보를 확인하고, 확인한 위치정보가 건물 내부일 경우,네트워크를 통해 건물 내부의 설계도면정보를 수집하여 상기 안전정보 생성부에 전달하도록 제어하며,상기 안전정보 생성부는 수집한 건물 내부의 설계도면정보를 기초로 화재 위치를 인식한 후, 인식한 화재 위치에 따른 대피 방향 정보를 상기 설계도면정보로부터 추출하여 위험 상황 대피정보를 생성하는 것을 특징으로 하는 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시스템."}
{"patent_id": "10-2023-0086396", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 4에서, 상기 소리 분석부는,수신한 소리 정보에 포함된 주파수 특성에 따라 유성음 또는 배경음으로 분류하고, 딥러닝 기술을 통해 학습된데이터를 기반으로 소리 정보의 종류를 분석하여 위험 상황 판단 정보를 안전정보 생성부에 전달하는 것을 특징으로 하는 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시스템."}
{"patent_id": "10-2023-0086396", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 2에서, 상기 인공지능 안경은,소리 감지시 소리가 발생한 방향을 감지하는 방향 감지부;상기 방향 감지부에 의해 감지한 소리 방향에 대하여 소리를 발생한 소리원의 거리를 감지하는 거리 감지부를포함하고,상기 제어부는 소리 감지 정보와 방향 감지 정보 및 거리 감지 정보를 수집 정보로 상기 정보 분석기에 전송하도록 제어하는 것을 특징으로 하는 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시스템."}
{"patent_id": "10-2023-0086396", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 4에서, 상기 정보 분석기는,상기 인공지능 안경으로부터 전송된 수집 정보로부터 거리 및 방향 정보를 추출하는 거리/방향 추출부를 더 포함하고,상기 안전정보 생성부는,상기 소리 분석부에 의해 분석한 소리 종류와 상기 거리/방향 추출부에서 추출한 거리 및 방향 정보를 기초로위험 상황 정보 및 위험상황 대피정보를 안전정보로 생성하는 것을 특징으로 하는 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시스템."}
{"patent_id": "10-2023-0086396", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에서, 상기 위험 상황 정보는 소리 종류에 따른 소리원의 형상 정보를 포함하는 것을 특징으로 하는 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시스템."}
{"patent_id": "10-2023-0086396", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 8에서, 상기 안전정보는,위험 상황 정보, 충돌 위험 정보, 소리원의 형상 정보, 소리원까지의 거리 정보, 위험 상황을 벗어나기 위한 대피 방향 정보 중 적어도 어느 하나 이상을 포함하는 것을 특징으로 하는 청각 장애인과 비장애인의 의사소통 지공개특허 10-2025-0006515-4-원 및 근거리 상황인지가 가능한 인공지능 안경시스템."}
{"patent_id": "10-2023-0086396", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "청각 장애인이 착용한 인공지능 안경을 이용하여 소리에 대하여 시각적으로 상황정보를 표출해줌으로써, 인공지 능 안경을 통해 청각 장애인과 비장애인의 의사소통이 이루어지도록 하고, 청각 장애인에게 근거리 상황에 대하 여 안전 정보를 시각적으로 제공하여 청각 장애인의 안전을 도모하도록 한 청각 장애인과 비장애인의 의사소통 (뒷면에 계속)"}
{"patent_id": "10-2023-0086396", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시스템에 관한 것으로, 특히 청각 장애인이 착용한 인공지능 안경을 이용하여 소리에 대하여 시각적으로 상황정보를 표출해줌 으로써, 인공지능 안경을 통해 청각 장애인과 비장애인의 의사소통이 이루어지도록 하고, 청각 장애인에게 근거 리 상황에 대하여 안전 정보를 시각적으로 제공하여 청각 장애인의 안전을 도모하도록 한 청각 장애인과 비장애 인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시스템에 관한 것이다."}
{"patent_id": "10-2023-0086396", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "청각 장애인은 선천적 또는 후천적으로 청각에 문제가 발생하여 음성 및 음향 등의 소리를 듣지 못하는 사람으 로서, 청각의 문제로 인해 일상생활 중 많은 불편함과 위험에 노출되어 있다. 예를 들어, 청각 장애인은 실내에 서 전화벨, 초인종 및 비상벨 등의 일상생활에서 빈번하게 발생하는 기본적인 소리를 들을 수 없으며, 실외에서 는 각종 다양한 정보를 제공하기 위한 공공장소 및 대중교통 등의 음향서비스, 자동차 경음기(크락션) 등의 소 리를 들을 수 없고, 이에 따라 오로지 시각으로만 모든 위험상황 및 정보를 인식하여야 하기 때문에 무수한 불 편함과 위험을 감수하고 살아가고 있다. 즉, 청각 장애인은 촉각 또는 시각을 통해서만 모든 정보를 인지할 수밖에 없기 때문에 시각을 벗어난 범위에서 발생하는 상황을 인지할 수 없으며, 아울러 시각의 범위 내에서 돌발 상황이 발생하더라도 일반인에 비해 인지 속도 및 정확도가 떨어지는 한계를 갖는다. 특히, 청각 장애인의 수가 증가함과 동시에 청각 장애인을 포함하는 사회적 약자에 대한 관심이 급증함에 따라 청각 장애인의 불편함을 절감하고, 편의성을 높이기 위한 안전보조장치 및 시스템에 대하여 다양한 연구가 진행 되고 있다. 청각 장애인의 불편함을 해소하고 안전을 위해 종래에 제안된 기술이 하기의 <특허문헌 1> 내지 <특허문헌 5> 에 개시되어 있다. <특허문헌 1> 에 개시된 종래기술은 소리를 수신하여 처리하고, 소리의 종류 및 방향 정보를 단말 장치를 이용 하여 시각적으로 제공하여, 청각 장애인이 위험 상황에 능동적으로 대처하도록 한다. 또한, <특허문헌 2> 에 개시된 종래기술은 외부에서 발생하는 청각적 신호를 시각적 신호로 변환하여 안경을 통 해 경고 알람을 발생하여, 청각 장애인의 안전을 도모하도록 한다. 또한, <특허문헌 3> 에 개시된 종래기술은 집음된 소리 원의 위치를 특정하고, 이를 시각적으로 청각 장애인에 게 안경을 통해 제공하여, 청각 장애인이 소리 음을 인지할 수 있도록 한다. 또한, <특허문헌 4> 에 개시된 종래기술은 일상적인 소리를 모바일 기기와 연계된 웨어러블 디스플레이를 통해 시각화하여 보여 줌으로써, 청각 장애인이 일상적 소리를 시각적으로 인지하도록 한다. 또한, <특허문헌 5> 에 개시된 종래기술은 안경을 착용한 사용자(청각 장애인)에게 관리 서버에서 주변 소리를 감지하여 이미지 또는 텍스트로 출력하여, 청각 장애인의 주변의 상황 및 위험 요소를 인지하도록 한다. 그러나 상기와 같은 종래기술들은 단순히 주변 소리를 시각화하여 보여 줌으로써, 사용자가 주변 소리가 정확히 무엇인지 어떠한 위험이 있는 소리인지를 명확히 인지하기 어려우며, 비장애인과 청각 장애인의 실시간 의사소 통이 불가능하여 화재와 같은 상황에서 비장애인의 화재 위험 경보를 청각 장애인이 인지하지 못하여 사고를 방 지하는 데 한계가 있다. 또한, 상기와 같은 종래기술은 서버와 통신을 통해 위험 상황의 소리 정보를 시각적으로 청각 장애인에게 제공 하기 때문에, 관리 서버와 통신이 어려운 상황에서는 실효성이 없는 문제가 있다. 또한, 상기와 같은 종래기술들은 소리로 인한 위험 상황을 감지하여 사용자가 해당 위험으로부터 대비하여 안전 을 도모하도록 하는 대피 정보를 정확하게 제공해주지 못하는 단점이 있다. 특히, 건물의 화재시 청각 장애인이건물의 어느 위치로 대피해야 하는지를 정확하게 인지시켜주지 못하는 단점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 10-0748432(2007.08.06. 등록)(청각 장애인용 착용형 단말장치) (특허문헌 0002) 대한민국 공개특허 10-2008-0029394(2008.04.03. 공개)(안경형 경고 알림 장치) (특허문헌 0003) 대한민국 등록특허 10-1518115(2015.04.29. 등록)(청각 장애인용 안경) (특허문헌 0004) 대한민국 공개특허 10-2015-0055262(2015.05.21. 공개)(모바일기기를 이용한 소리의 시각화 표 시방법) (특허문헌 0005) 대한민국 공개특허 10-2023-0021490(2023.02.14. 공개)(시각을 이용한 청각 보조 시스템 및 청각 보조 방법)"}
{"patent_id": "10-2023-0086396", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서 본 발명은 상기와 같은 비장애인과 청각 장애인과의 의사소통이 어려운 문제와 종래기술에서 발생하는 제반 문제를 해결하기 위해서 제안된 것으로서, 청각 장애인이 착용한 인공지능 안경을 이용하여 소리에 대하여 시각적으로 상황정보를 표출해줌으로써, 인공지능 안경을 통해 청각 장애인과 비장애인의 의사소통이 이루어지 도록 하고, 청각 장애인에게 근거리 상황에 대하여 안전 정보를 시각적으로 제공하여 청각 장애인의 안전을 도 모하도록 한 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시스템을 제 공하는 데 그 목적이 있다."}
{"patent_id": "10-2023-0086396", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 바와 같은 목적을 달성하기 위하여, 본 발명에 따른 \"청각 장애인과 비장애인의 의사소통 지원 및 근거 리 상황인지가 가능한 인공지능 안경시스템\"은, 소리 정보를 수집하여 무선으로 정보 분석기에 전송하고, 상기 정보 분석기로부터 전송된 위험 상황 정보 및 위 험 상황 대피 정보를 수신하여 시각적으로 표출해주는 인공지능 안경; 및 상기 인공지능 안경과 무선통신을 통해 실시간으로 접속하고, 수신한 소리 정보를 분석하여 위험 상황 유무를 판단하며, 위험 상황으로 판단시 위험 상황 정보와 위험 상황 대피정보를 생성하여 상기 인공지능 안경으로 전 송하는 정보 분석기를 포함하는 것을 특징으로 한다. 상기에서 인공지능 안경은, 소리 정보를 감지하는 소리 감지부; 상기 소리 감지부에서 감지한 소리 정보를 상기 정보 분석기에 전송하도록 제어하며, 상기 정보 분석기로부터 전송된 위험 상황 정보와 위험 상황 대피정보의 시각적 표시를 제어하는 제어부; 상기 제어부의 제어에 따라 위험 상황 정보 및 위험상황 대피정보를 시각적으로 표시해주는 디스플레이를 포함 하는 것을 특징으로 한다. 상기에서 디스플레이는, 웨어러블 디스플레이나 스마트 디스플레이 및 헤드업 디스플레이(HUD) 중 어느 하나로 구현되는 것을 특징으로 한다. 상기에서 정보 분석기는, 상기 인공지능 안경으로부터 전송된 정보를 수신하거나 네트워크를 통해 전송된 정보를 수신하는 정보 수신부; 상기 정보 수신부를 통해 수신한 정보가 소리 정보일 경우, 소리 분석 알고리즘을 이용하여 소리를 분석하는 소 리 분석부; 상기 소리 분석부에 의해 분석한 소리 분석 결과가 위험 상황일 경우, 위험 상황 정보 및 위험상황 대피 정보를 포함하는 안전 정보를 생성하는 안전정보 생성부; 상기 안전정보 생성부에서 생성한 안전 정보를 상기 인공지능 안경으로 전송하도록 제어하는 제어부; 및 상기 제어부의 제어에 따라 상기 안전 정보를 상기 인공지능 안경으로 전송하는 안전정보 전송부를 포함하는 것 을 특징으로 한다. 상기에서 제어부는, 위험 상황 정보가 화재일 경우, GPS를 통해 현재 위치 정보를 확인하고, 확인한 위치정보가 건물 내부일 경우, 네트워크를 통해 건물 내부의 설계도면정보를 수집하여 상기 안전정보 생성부에 전달하도록 제어하며, 상기 안전정보 생성부는 수집한 건물 내부의 설계도면정보를 기초로 화재 위치를 인식한 후, 인식한 화재 위치 에 따른 대피 방향 정보를 상기 설계도면정보로부터 추출하여 위험 상황 대피정보를 생성하는 것을 특징으로 한 다. 상기에서 소리 분석부는, 수신한 소리 정보에 포함된 주파수 특성에 따라 유성음 또는 배경음으로 분류하고, 딥러닝 기술을 통해 학습된 데이터를 기반으로 소리 정보의 종류를 분석하여 위험 상황 판단 정보를 안전정보 생성부에 전달하는 것을 특징 으로 한다. 상기에서 인공지능 안경은, 소리 감지시 소리가 발생한 방향을 감지하는 방향 감지부; 상기 방향 감지부에 의해 감지한 소리 방향에 대하여 소리를 발생한 소리원의 거리를 감지하는 거리 감지부를 포함하고, 상기 제어부는 소리 감지 정보와 방향 감지 정보 및 거리 감지 정보를 수집 정보로 상기 정보 분석기에 전송하 도록 제어하는 것을 특징으로 한다. 상기에서 정보 분석기는, 상기 인공지능 안경으로부터 전송된 수집 정보로부터 거리 및 방향 정보를 추출하는 거리/방향 추출부를 더 포 함하고, 상기 안전정보 생성부는, 상기 소리 분석부에 의해 분석한 소리 종류와 상기 거리/방향 추출부에서 추출한 거리 및 방향 정보를 기초로 위험 상황 정보 및 위험상황 대피정보를 생성하는 것을 특징으로 한다. 상기에서 위험 상황 정보는 소리 종류에 따른 소리원의 형상 정보를 포함하는 것을 특징으로 한다. 상기에서 안전정보는, 위험 상황 정보, 충돌 위험 정보, 소리원의 형상 정보, 소리원까지의 거리 정보, 위험 상황을 벗어나기 위한 대 피 방향 정보 중 적어도 어느 하나 이상을 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0086396", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 청각 장애인이 착용한 인공지능 안경을 이용하여 소리에 대하여 시각적으로 상황정보를 표출 해줌으로써, 인공지능 안경을 통해 청각 장애인과 비장애인의 의사소통을 구현할 수 있는 효과가 있다. 또한, 본 발명에 따르면 청각 장애인에게 근거리 상황에 대하여 안전 정보(위험 상황 정보와 위험상황 대피정보)를 시각적으로 제공하여 청각 장애인의 안전을 도모해줄 수 있는 효과가 있다."}
{"patent_id": "10-2023-0086396", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 본 발명의 바람직한 실시 예에 따른 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능 한 인공지능 안경시스템을 첨부된 도면을 참조하여 상세하게 설명한다. 이하에서 설명되는 본 발명에 사용된 용어나 단어는 통상적이거나 사전적인 의미로 한정해서 해석되어서는 안 되며, 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명하기 위해 용어의 개념으로 적절하게 정의할 수 있 다는 원칙에 입각하여 본 발명의 기술적 사상에 부합하는 의미와 개념으로 해석되어야만 한다. 따라서 본 명세서에 기재된 실시 예와 도면에 도시된 구성은 본 발명의 바람직한 실시 예에 불과할 뿐이고, 본 발명의 기술적 사상을 모두 대변하는 것은 아니므로, 본 출원 시점에서 이들을 대체할 수 있는 다양한 균등물과 변형 예들이 있을 수 있음을 이해하여야 한다. 도 1은 본 발명의 바람직한 실시 예에 따른 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가 능한 인공지능 안경시스템의 개략 구성도로서, 인공지능 안경과 정보 분석기를 포함할 수 있다. 인공지능 안경은 청각 장애인이 착용하는 안경으로서, 시야를 확보함과 동시에 위험 상황 정보 및 위험상 황 대피정보를 포함하는 안전정보를 디스플레이해주는 역할을 한다. 이러한 인공지능 안경은 소리 정보를 수집하여 무선으로 정보 분석기에 전송하고, 상기 정보 분석기 로부터 전송된 위험 상황 정보 및 위험 상황 대피 정보를 수신하여 시각적으로 표출해주는 역할을 할 수 있다. 여기서 인공지능 안경과 정보 분석기는 근거리 무선 통신을 실시간으로 정보를 송수신할 수 있으며, 블루투스, 와이-파이 등과 같은 근거리 무선 통신을 이용할 수 있다. 정보 분석기는 상기 인공지능 안경과 무선통신을 통해 실시간으로 접속하고, 수신한 소리 정보를 분 석하여 위험 상황 유무를 판단하며, 위험 상황으로 판단시 위험 상황 정보와 위험 상황 대피정보를 생성하여 상 기 인공지능 안경으로 전송하는 역할을 한다. 이러한 정보 분석기는 청각 장애인이 휴대한 스마트폰과 같은 모바일 기기로 구현할 수 있다. 본 발명에 따른 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시스템은, 단순히 소리 정보만을 수집하여 분석하고, 소리 분석 결과를 시각화하여 위험 상황 정보와 위험상황 대피정보를 표출해주는 실시 예(이하, \"제1 실시 예\"라고 함)와, 소리 정보와 거리 정보 및 방향 정보를 수집하여 분석하고, 정보 분석 결과를 시각화하여 위험 상황의 종류 정보와 위험 상황 형상 정보, 소리원의 거리, 대비 방향 정보를 종합적으로 제공해주는 실시 예(이하, \"제2 실시 예\"라고 함)로 대별된다. <제1 실시 예> 도 2는 본 발명에 따른 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시 스템의 제1 실시 예 구성도로서, 인공지능 안경은 소리 정보를 감지하는 소리 감지부, 상기 소리 감 지부에서 감지한 소리 정보를 상기 정보 분석기에 전송하도록 제어하며, 상기 정보 분석기로부 터 전송된 위험 상황 정보와 위험 상황 대피정보의 시각적 표시를 제어하는 제어부, 상기 제어부의 제어에 따라 위험 상황 정보 및 위험상황 대피정보를 시각적으로 표시해주는 디스플레이, 및 상기 정보 분 석기와 근거리 무선 통신으로 데이터를 송수신하기 위한 통신부를 포함할 수 있다. 상기 디스플레이는 웨어러블 디스플레이나 스마트 디스플레이 및 헤드업 디스플레이(HUD) 중 어느 하나로 구현될 수 있다. 본 발명은 언급한 디스플레이에 한정되는 것은 아니며, 언급한 디스플레이 이외에 안경으로 사 용하면서 정보의 표출이 가능한 모든 정보 표시 디스플레이 기기를 이용할 수 있음은 당해 분야의 통상의 지식 을 가진 사람이면 자명하다 할 것이다.이러한 인공지능 안경은 도면에는 도시하지 않았지만 구동 전원을 공급해주는 배터리가 장착된 것으로 가 정한다. 필요에 따라 인공지능 기능의 온/오프를 위한 전원 버튼을 구비할 수도 있다. 상기 정보 분석기는 상기 인공지능 안경으로부터 전송된 정보를 수신하거나 네트워크를 통해 전송된 정보를 수신하는 정보 수신부, 상기 정보 수신부를 통해 수신한 정보가 소리 정보일 경우, 소리 분석 알고리즘을 이용하여 소리를 분석하는 소리 분석부, 상기 소리 분석부에 의해 분석한 소리 분석 결과 가 위험 상황일 경우, 위험 상황 정보 및 위험상황 대피 정보를 포함하는 안전 정보를 생성하는 안전정보 생성 부, 상기 안전정보 생성부에서 생성한 안전 정보를 상기 인공지능 안경으로 전송하도록 제어하 는 제어부, 상기 제어부의 제어에 따라 상기 안전 정보를 상기 인공지능 안경으로 전송하는 안 전정보 전송부 및 데이터를 저장하는 저장부를 포함할 수 있다. 상기 저장부는 정보 수신부에서 네트워크를 통해 수집한 건물의 설계도면정보 등을 저장할 수 있다. 상기 제어부는 위험 상황 정보가 화재일 경우, GPS 모듈을 통해 현재 위치 정보를 확인하고, 확인한 위치정보가 건물 내부일 경우, 네트워크를 통해 건물 내부의 설계도면정보를 수집하여 상기 안전정보 생성부 에 전달하도록 제어할 수 있다. 상기 안전정보 생성부는 수집한 건물 내부의 설계도면정보를 기초로 화재 위치를 인식한 후, 인식한 화재 위치에 따른 대피 방향 정보를 상기 설계도면정보로부터 추출하여 위험 상황 대피정보를 생성할 수 있다. 상기 소리 분석부는 수신한 소리 정보에 포함된 주파수 특성에 따라 유성음 또는 배경음으로 분류하고, 딥 러닝 기술을 통해 학습된 데이터를 기반으로 소리 정보의 종류를 분석하여 위험 상황 판단 정보를 안전정보 생 성부에 전달할 수 있다. 이와 같이 구성된 본 발명에 따른 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공 지능 안경시스템의 제1 실시 예의 동작을 구체적으로 설명하면 다음과 같다. 먼저, 청각 장애인과 비장애인의 의사소통을 지원하고, 청각 장애인의 근거리 상황인지가 가능하도록 하기 위해 서 청각 장애인은 인공지능 안경을 착용한다. 인공지능 안경을 착용한 청각 장애인은 보행 또는 일상생활을 하게 되며, 일상생활을 하는 도중에 소리 감 지부는 청각 장애인 주변의 소리 정보를 감지한다. 여기서 소리 감지부는 마이크, 증폭기 및 신호 처 리부 등을 이용할 수 있으며, 신호 처리부는 수신한 소리 신호가 일정레벨 이하의 아주 미세한 소리일 경우에는 무시할 수 있다. 소리 감지부는 지향성 마이크를 이용하여 소리를 감지함으로써, 소리가 발생한 방향도 인지할 수 있도록 한다. 신호 처리부는 복수의 지향성 마이크를 통해 수신한 소리 신호 중 소리의 세기가 가장 큰 방향의 소리 신호만을 소리로 감지하고, 나머지 소리 신호는 무시할 수 있다. 처리된 소리 정보에는 방향 정보를 포함할 수 있으며, 방향 정보는 사전에 지향성 마이크마다 식별정보를 부여하여 방향을 판단할 수 있다. 소리 감지부에 의해 소리 정보가 감지되면, 제어부는 통신부를 통해 감지한 소리 정보(방향 정 보를 포함)를 연동하는 정보 분석기로 전송하도록 제어를 한다. 통신부는 상기 제어부의 제어에 따라 소리 감지부에서 감지한 소리 정보를 정해진 근거리 무선 통신 프로토콜에 맞는 데이터 형식으로 포맷하여 무선으로 전송한다. 상기 정보 분석기는 사용자가 휴대한 스마트폰과 같은 모바일 기기일 수 있으며, 사전에 정보 분석기(20 0)와 인공지능 안경은 블루투스와 같은 근거리 무선 통신에 의해 페어링되어 실시간 상호 연동하는 것으로 가정한다. 상기 정보 분석기는 상기 인공지능 안경으로부터 전송된 정보를 정보 수신부를 통해 수신하고, 정보 수신부는 수신한 정보를 소리 분석부에 전달한다. 상기 소리 분석부는 상기 정보 수신부를 통해 수신한 정보가 소리 정보일 경우, 소리 분석 알고리즘 을 이용하여 소리를 분석한다. 예컨대, 소리 분석부는 수신한 소리 정보에 포함된 주파수 특성에 따라 유성음 또는 배경음으로 분류하고, 딥러닝 기술을 통해 학습된 데이터를 기반으로 소리 정보의 종류를 분석하여 위험 상황 판단 정보를 안전정보생성부에 전달한다. 여기서 유성음은 청각 장애인 주변에 위치한 사람들로부터 발생하는 음성일 수 있으며, 배경음은 자동차 소리, 동물 소리, 초인종 소리, 화재 경보 소리 등과 같은 일상생활에서 발생하는 생 활 소리일 수 있다. 유성음 및 배경음 분류를 위해 사전에 다양한 배경음 및 유성음을 학습 데이터 셋으로 설정하고, 학습 데이터 셋을 기초로 딥러닝 학습을 통해 유성음 및 배경음을 정확하게 분류할 수 있는 소리 분석 모델을 구축하여, 소 리를 정확하게 분류할 수 있다. 소리 정보의 분석이 완료되면 소리 정보 분석 결과와 방향 정보를 포함하여 소리 분석 결과 정보로 안전정보 생 성부에 전달한다. 상기 안전정보 생성부는 상기 소리 분석부에 의해 분석한 소리 분석 결과가 위험 상황일 경우, 위험 상황 정보 및 위험상황 대피 정보를 포함하는 안전 정보를 생성한다. 여기서, 위험 상황은 분석한 소리 정보가 자동차 소리, 오토바이 소리, 동물 소리, 화재 경보 소리와 같이 경우에는 위험 상황으로 판단을 한다. 아울러 소리 분석 결과 위험 상황으로 판단이 되면, 소리 정보 수집시 수집한 방향 정보를 기초로 청각 장애인이 위험 으로부터 안전하게 대비할 위험상황 대피정보를 생성하게 된다. 예컨대, 청각 장애인을 기준으로 소리가 좌측에 서 감지되었다면 청각 장애인이 뒤쪽이나 앞쪽으로 피할 수 있도록 한 대피 정보를 생성할 수 있다. 아울러 소리 분석 결과 화재와 같은 위험 상황이고, 화재가 건물 내부에서 발생한 것으로 판단이 되면, 안전정 보 생성부는 제어부를 통해 화재 위치 정보를 획득한다. 즉, 제어부는 GPS 모듈을 통해 현 재 위치 정보를 획득한다. 이어, 획득한 위치 정보를 기초로 제어부는 정보 수신부를 제어하여 네트 워크를 통해 해당 위치(건물)의 설계도면정보를 획득하도록 한다. 정보 수신부는 네트워크를 통해 도면정 보를 제공해주는 사이트에 접속하여 해당 건물의 설계도면정보를 획득할 수 있다. 안전정보 생성부는 획득한 설계도면정보와 화재가 발생한 위치 정보를 매핑하여 건물 어느 위치에서 화재 가 발생했는지를 판단하고, 설계도면정보에 포함된 대피 정보를 기초로 청각 장애인이 안전하게 대피할 수 있는 대피정보를 생성하게 된다. 여기서 각각의 건물 설계도면정보에는 화재 발생시 비상 탈출할 수 있는 비상구나 대피 정보가 사전에 설계되어 있다. 아울러 대피 정보에는 건물 레이아웃과 대피할 방향의 위치를 나타내는 위 치 정보를 포함하여 대피 정보를 구현할 수 있다. 상기와 같은 과정으로 위험 상황 정보와 대피 정보가 생성되면 제어부는 이를 안전정보로 하여 안전정보 전송부를 통해 안전정보를 인공지능 안경으로 전송하도록 한다. 상기 인공지능 안경의 통신부는 수신한 안전정보를 제어부에 전달하게 되며, 제어부는 수 신한 안전정보를 기초로 디스플레이를 제어하여 안전 정보를 시각적으로 표출하도록 한다. 여기서 디스플레이는 웨어러블 디스플레이나 스마트 디스플레이 및 헤드업 디스플레이(HUD) 중 어느 하나 로 구현될 수 있으며, 평소에는 안경으로 사용하다가 위험 상황 정보의 발생시에는 안경 역할과 동시에 디스플 레이 역할을 하여 도 4a와 같이 안전 정보를 디스플레이해준다. 여기서 안전 정보에는 위험 상황 정보 즉, 자동차 접근 등과 같은 위험 상황 정보가 표시되며, 대피 방향 정보 가 표출된다. 즉, 뒤쪽으로 대비하라는 대피 정보가 표출될 수 있다. 건물 내부의 화재일 경우, 건물 레이아웃과 함께 대비 방향의 위치 정보가 표출되므로, 청각 장애인이 쉽게 건 물 화재로부터 안전하게 대피할 수 있게 되는 것이다. 따라서 청각 장애인은 자동차가 좌측에서 접근하는 것으로 인지하고 뒤쪽으로 물러나 자동차와 충돌하는 사고를 미리 방지할 수 있게 된다. 한편, 상기 소리 분석 결과 소리가 사람의 음성인 유성음일 경우, 동일하게 소리 분석을 하고, 소리 분석 결과 를 기초로 위험 상황 정보와 대피 정보를 시각적으로 표출해주어, 청각 장애인이 안전하게 대피할 수 있도록 한 다. 즉, 화재와 같은 위험 상황에서 사람이 화재라고 소리친 경우, 이를 분석하여 화재 발생과 같은 위험 상황 정보를 표출해주고, 뒤쪽으로 대비하도록 하는 대피 정보를 표출해주어, 청각 장애인의 안전을 도모하게 된다. 유성음 분석을 통해 안전정보의 제공은 청각 장애인과 비장애인과의 의사소통을 지원해주게 되는 것이다. <제2 실시 예> 도 3은 본 발명에 따른 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시 스템의 제2 실시 예 구성도로서, 인공지능 안경은 도 2와 같은 소리 감지부, 제어부, 통신부 및 디스플레이를 포함하고, 여기에 소리 감지시 소리가 발생한 방향을 감지하는 방향 감지부, 상기 방향 감지부에 의해 감지한 소리 방향에 대하여 소리를 발생한 소리원의 거리를 감지하는 거리 감지 부를 포함할 수 있다. 상기 제어부는 소리 감지 정보와 방향 감지 정보 및 거리 감지 정보를 수집 정보로 상기 정보 분석기(20 0)에 전송하도록 제어할 수 있다. 아울러 상기 정보 분석기는 도 2와 같은 정보 수신부, 소리 분석부, 안전정보 생성부, 제 어부, 안전정보 전송부, 저장부 및 GPA 모듈을 포함하고, 여기에 인공지능 안경으로 부터 전송된 수집 정보로부터 거리 및 방향 정보를 추출하는 거리/방향 추출부를 더 포함할 수 있다. 상기 안전정보 생성부는 상기 소리 분석부에 의해 분석한 소리 종류와 상기 거리/방향 추출부에 서 추출한 거리 및 방향 정보를 기초로 위험 상황 정보 및 위험상황 대피정보를 포함하는 안전정보를 생성할 수 있다. 여기서 위험 상황 정보는 소리 종류에 따른 소리원의 형상 정보를 포함할 수 있으며, 안전정보는 위험 상황 정 보, 충돌 위험 정보, 소리원의 형상 정보, 소리원까지의 거리 정보, 위험 상황을 벗어나기 위한 대피 방향 정보 중 적어도 어느 하나 이상을 포함할 수 있다. 이와 같이 구성된 본 발명에 따른 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공 지능 안경시스템의 제2 실시 예의 동작을 구체적으로 설명하면 다음과 같다. 먼저, 청각 장애인과 비장애인의 의사소통을 지원하고, 청각 장애인의 근거리 상황인지가 가능하도록 하기 위해 서 청각 장애인은 인공지능 안경을 착용한다. 인공지능 안경을 착용한 청각 장애인은 보행 또는 일상생활을 하게 되며, 일상생활을 하는 도중에 소리 감 지부는 청각 장애인 주변의 소리 정보를 감지한다. 여기서 소리 감지부는 마이크, 증폭기 및 신호 처 리부 등을 이용할 수 있으며, 신호 처리부는 수신한 소리 신호가 일정레벨 이하의 아주 미세한 소리일 경우에는 무시할 수 있다. 소리 감지부는 지향성 마이크를 이용하여 소리를 감지함으로써, 소리가 발생한 방향도 인지할 수 있도록 한다. 신호 처리부는 복수의 지향성 마이크를 통해 수신한 소리 신호 중 소리의 세기가 가장 큰 방향의 소리 신호만을 소리로 감지하고, 나머지 소리 신호는 무시할 수 있다. 처리된 소리 정보에는 방향 정보를 포함할 수 있으며, 방향 정보는 사전에 지향성 마이크마다 식별정보를 부여하여 방향을 판단할 수 있다. 아울러 방향 감지부는 라이다, 레이더, 초음파 등과 같은 물체 감지 장비를 이용하여 소리가 발생한 방향 을 감지한다. 여기서 라이다, 레이더, 초음파 등과 같은 물체 감지 장비의 감지 거리를 조절하고, 물체가 감지 되는 방향을 소리가 발생한 방향으로 감지할 수 있다. 아울러 거리 감지부는 상기 방향 감지부에 의해 소리가 감지된 방향이 판단되며, 해당 방향으로 초음 파, 레이저 등을 투사하고 물체로부터 반사되는 반사 신호의 시간 정보를 이용하여 소리를 발생한 물체와의 거 리를 감지한다. 감지된 방향 정보, 소리 정보 및 거리 정보는 제어부에 전달된다. 상기 제어부는 통신부를 통해 감지한 정보(소리 정보, 방향 정보, 거리 정보)를 수집 정보로 하여 연 동하는 정보 분석기로 전송하도록 제어를 한다. 통신부는 상기 제어부의 제어에 따라 수집한 정보를 정해진 근거리 무선 통신 프로토콜에 맞는 데이 터 형식으로 포맷하여 무선으로 전송한다. 상기 정보 분석기는 사용자가 휴대한 스마트폰과 같은 모바일 기기일 수 있으며, 사전에 정보 분석기(20 0)와 인공지능 안경은 블루투스와 같은 근거리 무선 통신에 의해 페어링되어 실시간 상호 연동하는 것으로 가정한다. 상기 정보 분석기는 상기 인공지능 안경으로부터 전송된 수집 정보를 정보 수신부를 통해 수신 하고, 정보 수신부는 수신한 정보를 소리 분석부에 전달한다. 상기 소리 분석부는 상기 정보 수신부를 통해 수신한 정보가 소리 정보일 경우, 소리 분석 알고리즘 을 이용하여 소리를 분석한다. 예컨대, 소리 분석부는 수신한 소리 정보에 포함된 주파수 특성에 따라 유성음 또는 배경음으로 분류하고, 딥러닝 기술을 통해 학습된 데이터를 기반으로 소리 정보의 종류를 분석하여 위험 상황 판단 정보를 안전정보 생성부에 전달한다. 여기서 유성음은 청각 장애인 주변에 위치한 사람들로부터 발생하는 음성일 수 있으며, 배경음은 자동차 소리, 동물 소리, 초인종 소리, 화재 경보 소리 등과 같은 일상생활에서 발생하는 생 활 소리일 수 있다. 유성음 및 배경음 분류를 위해 사전에 다양한 배경음 및 유성음을 학습 데이터 셋으로 설정하고, 학습 데이터 셋을 기초로 딥러닝 학습을 통해 유성음 및 배경음을 정확하게 분류할 수 있는 소리 분석 모델을 구축하여, 소 리를 정확하게 분류할 수 있다. 소리 정보의 분석이 완료되면 소리 정보 분석 결과를 안전정보 생성부에 전달한다. 아울러 거리/방향 추출부는 상기 수집한 정보에 포함된 거리 정보와 방향 정보를 추출하여 상기 안전정보 생성부에 전달한다. 상기 안전정보 생성부는 상기 소리 분석부에 의해 분석한 소리 분석 결과와 상기 거리/방향 추출부 에서 추출한 거리 및 방향 정보를 기초로 안전정보를 생성한다. 예컨대, 분석한 소리가 위험 상황일 경우, 위험 상황 정보 및 위험상황 대피 정보를 생성하되, 위험 상황 정보 에는 위험의 종류가 무엇인지를 나타내는 충돌 위험 정보, 소리원이 무엇인지를 청각 장애인인 인지할 수 있는 형상 정보, 소리원까지의 거리 정보, 위험 상황을 벗어나기 위한 대피 방향 정보 중 적어도 어느 하나 이상을 포함하여 안전정보를 생성하게 된다. 여기서 형상 정보는 사전에 소리의 종류에 따른 형상 정보는 저장부에 저장해 놓고, 분석한 소리 정보를 기초로 대응하는 소리원의 형상 정보를 저장부로부터 추출하여 사용할 수 있다. 예컨대, 소리원이 자동차 일 경우, 저장부로부터 자동차 형상 정보를 추출하여 소리원의 형상 정보로 활용한다. 여기서, 위험 상황은 분석한 소리 정보가 자동차 소리, 오토바이 소리, 동물 소리, 화재 경보 소리와 같이 경우 에는 위험 상황으로 판단을 한다. 아울러 소리 분석 결과 위험 상황으로 판단이 되면, 소리 정보 수집시 수집한 방향 정보를 기초로 청각 장애인이 위험으로부터 안전하게 대비할 위험상황 대피정보를 생성하게 된다. 예컨대, 청각 장애인을 기준으로 소리가 좌측에서 감지되었다면 청각 장애인이 뒷쪽이나 앞쪽으로 피할 수 있도록 한 대 피 정보를 생성할 수 있다. 아울러 소리 분석 결과 화재와 같은 위험 상황이고, 화재가 건물 내부에서 발생한 것으로 판단이 되면, 안전정 보 생성부는 제어부를 통해 화재 위치 정보를 획득한다. 즉, 제어부는 GPS 모듈을 통해 현 재 위치 정보를 획득한다. 이어, 획득한 위치 정보를 기초로 제어부는 정보 수신부를 제어하여 네트 워크를 통해 해당 위치(건물)의 설계도면정보를 획득하도록 한다. 정보 수신부는 네트워크를 통해 도면정 보를 제공해주는 사이트에 접속하여 해당 건물의 설계도면정보를 획득할 수 있다. 안전정보 생성부는 획득한 설계도면정보와 화재가 발생한 위치 정보를 매핑하여 건물 어느 위치에서 화재 가 발생했는지를 판단하고, 설계도면정보에 포함된 대피 정보를 기초로 청각 장애인이 안전하게 대피할 수 있는 대피정보를 생성하게 된다. 여기서 각각의 건물 설계도면정보에는 화재 발생시 비상 탈출할 수 있는 비상구나 대피 정보가 사전에 설계되어 있다. 아울러 대피 정보에는 건물 레이아웃 및 대피 위치를 표시하여 도면화된 정 보를 제공해줄 수도 있다. 상기와 같은 과정으로 위험 상황 정보와 대피 정보가 생성되면 제어부는 이를 안전정보로 하여 안전정보 전송부를 통해 안전정보를 인공지능 안경으로 전송하도록 한다. 상기 인공지능 안경의 통신부는 수신한 안전정보를 제어부에 전달하게 되며, 제어부는 수 신한 안전정보를 기초로 디스플레이를 제어하여 안전 정보를 시각적으로 표출하도록 한다. 여기서 디스플레이는 웨어러블 디스플레이나 스마트 디스플레이 및 헤드업 디스플레이(HUD) 중 어느 하나 로 구현될 수 있으며, 평소에는 안경으로 사용하다가 위험 상황 정보의 발생시에는 안경 역할과 동시에 디스플 레이 역할을 하여 도 4B와 같이 안전 정보를 디스플레이해준다. 여기서 안전 정보에는 위험 상황이 무언인지를 나타내는 정보 즉, 충돌 위험 정보와 위험 상황을 유발하는 소리 원의 형상 정보, 소리원이 접근하는 거리 정보, 그리고 대피 방향 정보가 표출된다. 즉, 오른쪽으로 대비하라는대피 정보가 표출될 수 있다. 따라서 청각 장애인은 자동차가 좌측에서 30m 정도에서 접근하는 것으로 인지하고 오른쪽으로 물러나 자동차와 충돌하는 사고를 미리 방지할 수 있게 된다. 한편, 상기 소리 분석 결과 소리가 사람의 음성인 유성음일 경우, 동일하게 소리 분석을 하고, 소리 분석 결과 를 기초로 위험 상황 정보와 대피 정보를 시각적으로 표출해주어, 청각 장애인이 안전하게 대피할 수 있도록 한 다. 즉, 화재와 같은 위험 상황에서 사람이 화재라고 소리친 경우, 이를 분석하여 화재 발생과 같은 위험 상황 정보를 표출해주고, 뒤쪽으로 대비하도록 하는 대피 정보를 표출해주어, 청각 장애인의 안전을 도모하게 된다. 유성음 분석을 통해 안전정보의 제공은 청각 장애인과 비장애인과의 의사소통을 지원해주게 되는 것이다. 건물 내부의 화재일 경우, 건물 레이아웃과 함께 대비 방향의 위치 정보가 함께 표출되므로, 청각 장애인이 쉽 게 건물 화재로부터 안전하게 대피할 수 있게 되는 것이다. 이상 상술한 본 발명에 따르면 청각 장애인이 착용한 인공지능 안경을 이용하여 소리에 대하여 시각적으로 상황 정보를 표출해줌으로써, 인공지능 안경을 통해 청각 장애인과 비장애인의 의사소통을 구현할 수 있다. 또한, 본 발명에 따르면 청각 장애인에게 근거리 상황에 대하여 안전 정보(위험 상황 정보와 위험상황 대피정보)를 시각적으로 제공하여 청각 장애인의 안전을 도모해줄 수 있다. 이상 본 발명자에 의해서 이루어진 발명을 상기 실시 예에 따라 구체적으로 설명하였지만, 본 발명은 상기 실시"}
{"patent_id": "10-2023-0086396", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되는 것은 아니고 그 요지를 이탈하지 않는 범위에서 여러 가지로 변경 가능한 것은 이 기술분야에서 통상의 지식을 가진 자에게 자명하다."}
{"patent_id": "10-2023-0086396", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시 스템의 개략 구성도이고,도 2는 본 발명에 따른 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시 스템의 제1 실시 예 구성도이고, 도 3은 본 발명에 따른 청각 장애인과 비장애인의 의사소통 지원 및 근거리 상황인지가 가능한 인공지능 안경시 스템의 제2 실시 예 구성도이며, 도 4a 및 도 4b는 본 발명에서 청각 장애인에게 제공해주는 안전 정보의 예시도이다."}
