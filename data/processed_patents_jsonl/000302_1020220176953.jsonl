{"patent_id": "10-2022-0176953", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0095625", "출원번호": "10-2022-0176953", "발명의 명칭": "인공지능 가속기의 벡터 프로세싱 기능 업데이트를 위한 방법 및 장치", "출원인": "주식회사 사피온코리아", "발명자": "김영근"}}
{"patent_id": "10-2022-0176953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 가속기의 벡터 프로세싱 기능 업데이트를 위한 컴퓨터 구현 방법에 있어서,신경망의 적어도 일부의 레이어에 대해, 각 레이어의 기능을 수행하도록 구성된 복수의 후보 바이너리 집합들중에서 기설정된 최적화 조건에 대응하는 하나 이상의 바이너리 집합을 선택하는 과정 - 상기 복수의 후보 바이너리 집합들 각각은, 적어도 하나의 벡터 프로세싱 바이너리를 포함함 -; 및상기 선택된 하나 이상의 바이너리 집합을 이용하여 상기 인공지능 가속기에 탑재할 커맨드 패킷 스트림을 생성하는 과정을 포함하는, 방법."}
{"patent_id": "10-2022-0176953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 선택하는 과정은,상기 복수의 후보 바이너리 집합들의 목록을 기록하는 테이블에서, 상기 신경망 또는 선택 대상인 레이어에 대해 설정된 최적화 조건에 대응하는 바이너리 집합을 검색하는 과정을 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2022-0176953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 복수의 후보 바이너리 집합들은, 속도에 최적화된 제1 후보 바이너리 집합, 정확도에 최적화된 제2 후보 바이너리 집합 및 속도와 정확도에 최적화된 제3 후보 바이너리 집합 중 2 이상을 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2022-0176953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 복수의 후보 바이너리 집합들은, 제1 데이터 타입을 사용하는 제1 후보 바이너리 집합 및 제2 데이터 타입을 사용하는 제2 후보 바이너리 집합을포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2022-0176953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 제1 후보 바이너리 집합 및 상기 제2 후보 바이너리 집합은,선택 대상인 레이어의 기능을 구현하기 위해 필요한 상기 인공지능 가속기의 하드웨어 자원 및 벡터 프로세싱바이너리가 사용할 수 있는 상기 인공지능 가속기의 하드웨어 자원을 고려하여, 구성되는 것을 특징으로 하는,방법."}
{"patent_id": "10-2022-0176953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 인공지능 가속기의 하드웨어 자원은,룩업 테이블, 곱셈 누적기 및 메모리 중 하나 이상을 포함하는 것을 특징으로 하는, 방법. 공개특허 10-2024-0095625-3-청구항 7 제1항에 있어서,상기 복수의 후보 바이너리 집합들은,선택 대상인 레이어의 하이퍼파라미터에 대한 제1 설정값에 대응하는 제1 후보 바이너리 집합, 및 상기 하이퍼파라미터에 대한 제2 설정값에 대응하는 제2 후보 바이너리 집합을 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2022-0176953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 선택하는 과정은,상기 제1 후보 바이너리 집합 및 상기 제2 후보 바이너리 집합 중 하나 이상을 조합하여, 상기 하이퍼파라미터에 대한 제3 설정값에 대응하는 제3 후보 바이너리 집합을 생성하는 과정을 포함하는 것을 특징으로 하는,방법."}
{"patent_id": "10-2022-0176953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 적어도 일부의 레이어는, 상기 인공지능 가속기가 상기 신경망을 구동하는 중에 최적화 조건의 변경이 요청된 레이어이고, 최적화 조건의 변경요청에 응답하여, 상기 인공지능 가속기로 하여금 상기 적어도 일부의 레이어에 대한 연산을중단하도록 하는 명령어를 전송하는 과정;상기 생성된 커맨드 패킷 스트림을 상기 인공지능 가속기에 탑재하여, 상기 인공지능 가속기의 벡터 프로세싱기능을 업데이트하는 과정; 및 상기 인공지능 가속기로 하여금 상기 적어도 일부의 레이어에 대한 연산을 재시작하도록 하는 명령어를 전송하는 과정을 추가로 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2022-0176953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 선택하는 과정 이후에,상기 최적화 조건이 변경됨에 따라, 입력 및 출력 중 하나 이상의 데이터 타입이 변경된 레이어가 존재하는 경우, 데이터 타입 변환을 수행하도록 구성된 벡터 프로세싱 바이너리를 상기 커맨드 패킷 스트림에 포함시키는과정을 추가로 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2022-0176953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "신경망의 적어도 일부의 레이어에 대해, 각 레이어의 기능을 수행하도록 구성된 복수의 후보 바이너리 집합들중에서 기설정된 최적화 조건에 대응하는 하나 이상의 바이너리 집합을 선택하는 바이너리 선택모듈 - 상기 복수의 후보 바이너리 집합들 각각은, 적어도 하나의 벡터 프로세싱 바이너리를 포함함 -; 및상기 선택된 하나 이상의 바이너리 집합을 이용하여 인공지능 가속기에 탑재할 커맨드 패킷 스트림을 생성하는컴파일러를 포함하는, 장치."}
{"patent_id": "10-2022-0176953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "신경망의 적어도 일부의 레이어에 대해, 각 레이어의 기능을 수행하도록 구성된 복수의 후보 바이너리 집합들중에서 기설정된 최적화 조건에 대응하는 하나 이상의 바이너리 집합을 선택하는 호스트 디바이스 - 상기 복수의 후보 바이너리 집합들 각각은, 적어도 하나의 벡터 프로세싱 바이너리를 포함함 -; 및공개특허 10-2024-0095625-4-상기 선택된 하나 이상의 바이너리 집합을 이용하여, 상기 적어도 일부의 레이어에 대한 연산을 수행하는 인공지능 가속기를 포함하는 가속기 시스템."}
{"patent_id": "10-2022-0176953", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 가속기의 벡터 프로세싱 기능 업데이트를 위한 방법 및 장치를 개시한다. 본 개시의 일 측면에 의하면, 인공지능 가속기의 벡터 프로세싱 기능 업데이트를 위한 컴퓨터 구현 방법에 있어 서, 신경망의 적어도 일부의 레이어에 대해, 각 레이어의 기능을 수행하도록 구성된 복수의 후보 바이너리 집합 들 중에서 기설정된 최적화 조건에 대응하는 하나 이상의 바이너리 집합을 선택하는 과정 - 상기 복수의 후보 바 이너리 집합들 각각은, 적어도 하나의 벡터 프로세싱 바이너리를 포함함 -; 및 상기 선택된 하나 이상의 바이너 리 집합을 이용하여 상기 인공지능 가속기에 탑재할 커맨드 패킷 스트림을 생성하는 과정을 포함하는, 방법을 제 공한다."}
{"patent_id": "10-2022-0176953", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공지능 가속기의 벡터 프로세싱 기능 업데이트를 위한 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0176953", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이하에 기술되는 내용은 단순히 본 실시예와 관련되는 배경 정보만을 제공할 뿐 종래기술을 구성하는 것이 아니 다. 인공지능(Artificial Intelligence, AI) 기술이 발전함에 따라, 인공지능을 구현하고 실행하기 위한 전용 하드 웨어로서 인공지능 가속기에 대한 개발이 이루어지고 있다. 인공지능 가속기는 딥러닝 알고리즘에 최적화된 하 드웨어 구성요소들 또는 엔진들을 포함하며, 일반적인 컴퓨팅 장치에 비해 빠른 신경망 연산 속도를 가진다. 인공지능 가속기는, 하나의 명령어로 벡터(vector)라고 불리는 다수의 데이터를 동시에 처리하는 벡터 프로세서 (vector processor)를 포함할 수 있다. 벡터 프로세서는 일반적으로, 다양한 종류의 데이터 타입(data type)을 지원하고 있다. 예를 들어, 벡터 프로세서는 16bit 데이터 타입과 8bit 데이터 타입을 지원할 수 있다. 또한, 인공지능 가속기는, 룩업 테이블(lookup table, LUT), 곱셈 누적기(multiplier-accumulator, MAC) 및 스칼라 메모리(scalar memory) 등과 같이, 벡터 프로세싱(vector processing)을 위한 다양한 하드웨어 자원 제공하며, 이러한 하드웨어 자원의 갯수는 제한되어 있다. 벡터 프로세싱을 이용하여 특정 레이어에 대한 연산을 수행하기 위해서는, 레이어마다 데이터 타입 및 하드웨어 자원을 고려하여 벡터 프로세싱 바이너리(vector processing binary)를 구성하여야 한다."}
{"patent_id": "10-2022-0176953", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는, 인공지능 가속기의 벡터프로세싱 바이너리를 업데이트하여, 인공지능 가속기를 최적화할 수 있는 방 법 및 장치를 제공하는데 일 목적이 있다. 본 개시는, 신경망의 형태와 최적화 조건을 고려하여 다양한 벡터 프로세싱 바이너리를 제작한 후, 특정한 조건 에 따라 검색된 벡터 프로세싱 바이너리를 인공지능 가속기에 탑재함으로써, 매우 많은 갯수의 벡터 프로세싱 바이너리를 효율적으로 사용할 수 있는 방법 및 장치를 제공하는데 일 목적이 있다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제 들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0176953", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 의하면, 인공지능 가속기의 벡터 프로세싱 기능 업데이트를 위한 컴퓨터 구현 방법에 있어 서, 신경망의 적어도 일부의 레이어에 대해, 각 레이어의 기능을 수행하도록 구성된 복수의 후보 바이너리 집합 들 중에서 기설정된 최적화 조건에 대응하는 하나 이상의 바이너리 집합을 선택하는 과정 - 상기 복수의 후보 바이너리 집합들 각각은, 적어도 하나의 벡터 프로세싱 바이너리를 포함함 -; 및 상기 선택된 하나 이상의 바이 너리 집합을 이용하여 상기 인공지능 가속기에 탑재할 커맨드 패킷 스트림을 생성하는 과정을 포함하는, 방법을 제공한다. 본 개시의 다른 측면에 의하면, 신경망의 적어도 일부의 레이어에 대해, 각 레이어의 기능을 수행하도록 구성된 복수의 후보 바이너리 집합들 중에서 기설정된 최적화 조건에 대응하는 하나 이상의 바이너리 집합을 선택하는 바이너리 선택모듈 - 상기 복수의 후보 바이너리 집합들 각각은, 적어도 하나의 벡터 프로세싱 바이너리를 포함 함 -; 및 상기 선택된 하나 이상의 바이너리 집합을 이용하여 상기 인공지능 가속기에 탑재할 커맨드 패킷 스트 림을 생성하는 컴파일러를 포함하는, 장치를 제공한다.본 개시의 다른 측면에 의하면, 신경망을 구성하는 레이어들 중 적어도 일부의 레이어에 각각에 대해, 복수의 후보 바이너리 집합들 중에서 기설정된 최적화 조건에 대응하는 하나 이상의 바이너리 집합을 선택하는 호스트 디바이스 - 상기 복수의 후보 바이너리 집합들 각각은, 적어도 하나의 벡터 프로세싱 바이너리를 포함함 -; 및 상기 선택된 하나 이상의 바이너리 집합을 이용하여, 상기 적어도 일부의 레이어에 대한 연산을 수행하는 인공 지능 가속기를 포함하는 가속기 시스템을 제공한다."}
{"patent_id": "10-2022-0176953", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일 실시예에 의하면, 인공지능 가속기의 최적화 조건에 따라서, 신경망 전체 또는 신경망의 일부 레 이어를 구성할 수 있다. 본 개시의 일 실시예에 의하면, 인공지능 가속기가 제공하는 하드웨어 자원에 따라, 최적화된 벡터 프로세싱을 이용하여 레이어를 구성할 수 있다. 본 개시의 일 실시예에 의하면, 신경망의 런타임(runtime) 중에 최적화 조건이 변경되면, 그에 따라 인공지능 가속기에 벡터 프로세싱 기능을 업데이트하여 신경망 또는 레이어를 구성할 수 있다. 본 개시의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재 로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0176953", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 일부 실시예들을 예시적인 도면을 이용해 상세하게 설명한다. 각 도면의 구성 요소들에 참조 부호를 부가함에 있어서, 동일한 구성 요소들에 대해서는 비록 다른 도면 상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 개시를 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 본 개시에 따른 실시예의 구성요소를 설명하는 데 있어서, 제1, 제2, i), ii), a), b) 등의 부호를 사용할 수 있다. 이러한 부호는 그 구성요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 부호에 의해 해당 구성요소의 본질 또는 차례나 순서 등이 한정되지 않는다. 명세서에서 어떤 부분이 어떤 구성요소를 '포함' 또는 '구비'한 다고 할 때, 이는 명시적으로 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 첨부된 도면과 함께 이하에 개시될 상세한 설명은 본 개시의 예시적인 실시형태를 설명하고자 하는 것이며, 본 개시가 실시될 수 있는 유일한 실시형태를 나타내고자 하는 것이 아니다. 도 1은 본 개시의 일 실시예에 따른 가속기 시스템을 개략적으로 나타낸 블록구성도이다. 도 1에 도시되듯이, 본 개시의 일 실시예에 따른 가속기 시스템은 인공지능 가속기 및 호스트 디바이스 를 포함할 수 있다. 인공지능 가속기는 신경망(neural network)에 포함된 레이어들의 전부 또는 일부를 실행할 수 있다. 레이 어를 실행하는 것은, 레이어에 대한 연산을 처리하는 것을 포함할 수 있다. 예를 들어, 컨볼루션 레이어 (convolution layer)의 경우, 인공지능 가속기는 입력 데이터에 대해 컨볼루션 연산을 수행하여 출력 데이 터를 생성할 수 있다. 인공지능 가속기는 호스트 디바이스와는 구별되는 별도의 프로세서를 포함할 수 있다. 인공지능 가속기는, 벡터 프로세싱(vector processing)을 위한 적어도 하나의 벡터 프로세서 (vector processor)를 포함할 수 있다. 호스트 디바이스는 인공지능 가속기로 하여금 신경망을 구동하도록 하는 명령어 및/또는 데이터를, 인공지능 가속기로 전달할 수 있다. 예를 들어, 호스트 디바이스는 신경망을 인공지능 가속기에 서 처리하기 위한 요청을 수신할 수 있다. 요청은 인공지능 가속기에서 처리하고자 하는 신경망의 구조, 학습 또는 추론을 위한 데이터 및/또는 신경망의 전체 또는 레이어별 최적화 조건을 포함할 수 있다. 호스트 디바이스는, 수신한 요청에 응답하여 인공지능 가속기에서 실행 가능한 명령어들을 포함하는 커맨드 패킷 스트림(command packet stream)을 생성할 수 있다. 커맨드 패킷 스트림은 벡터 프로세서에서 실행 가능한 명령어들을 포함하는 벡터 프로세싱 바이너리(vector processing binary)를 포함할 수 있다. 호스트 디바이스에는, 인공지능 가속기로 하여금 각 레이어의 기능을 수행할 수 있도록 구성된 벡터 프로세싱 바이너리들이 사전에 제작되어 저장되어 있을 수 있다. 각 레이어의 기능은, 하나 이상의 벡터 프로세 싱 바이너리를 사용하여 구현될 수 있다. 본 개시에서, 인공지능 가속기로 하여금 특정 레이어의 기능을 수행할 수 있도록 구성된 하나 이상의 벡터 프로세싱 바이너리는 '바이너리 집합'으로 지칭될 수 있다. 호스트 디바이스에는, 레이어별로 복수개의 바이너리 집합들이 사전에 제작되어 저장되어 있을 수 있다. 호스트 디바이스는 레이어별로, 복수개의 바이너리 집합들 중에서, 수신한 요청에 포함된 최적화 조건에 대응하는 하나 이상의 바이너리 집합을 선택하여, 커맨드 패킷 스트림을 생성할 수 있다. 호스트 디바이스는 생성된 커맨드 패킷 스트림을 인공지능 가속기에 탑재할 수 있다. 이에 따라, 인 공지능 가속기에서 처리되는 벡터 프로세싱 기능이 업데이트될 수 있다. 인공지능 가속기는 커맨드 패킷 스트림에 포함된 바이너리 집합을 이용하여, 신경망에 포함된 레이어들의 전부 또는 일부를 실행할 수 있 다. 도 2는 본 개시의 일 실시예에 따른 호스트 디바이스를 개략적으로 나타낸 블록구성도이다. 도 2에 도시되듯이, 본 개시의 일 실시예에 따른 호스트 디바이스는 기능 관리모듈, 바이너리 선택모 듈 및 컴파일러의 전부 또는 일부를 포함할 수 있다. 도 2에 도시된 모든 블록이 필수 구성요소는 아 니며, 다른 실시예에서 호스트 디바이스에 포함된 일부 블록이 추가, 변경 또는 삭제될 수 있다. 한편, 도 2에 도시된 구성요소들은 기능적으로 구분되는 요소들을 나타낸 것으로서, 적어도 하나의 구성요소가 실제 물리 적 환경에서는 서로 통합되는 형태로 구현될 수도 있다. 기능 관리모듈은 레이어의 유형별로, 해당 레이어의 기능을 수행하도록 구성된 복수의 바이너리 집합들을 저장할 수 있다. 예를 들어, 인공지능 가속기가 컨볼루션 레이어의 기능을 수행하도록 하는 적어도 하나의 바이너리 집합, 소프트맥스(soft max) 레이어의 기능을 수행하도록 하는 적어도 하나의 바이너리 집합, 픽셀 셔 플(pixel shuffle) 레이어의 기능을 수행하도록 하는 바이너리 집합, 전역 평균 풀링(global average pooling) 레이어의 기능을 수행하도록 하는 적어도 하나의 바이너리 집합, 및 L2 정규화(L2 normalization) 레이어의 기 능을 수행하도록 하는 적어도 하나의 바이너리 집합 등이 사전에 제작되어 기능 관리모듈에 저장되어 있을 수 있다. 기능 관리모듈은 각 레이어에 대해서, 복수의 최적화 조건 각각에 대응하는 바이너리 집합을 저장하고 있 을 수 있다. 예를 들어, 기능 관리모듈은, 기본(default) 바이너리 집합, 속도에 최적화된 바이너리 집합, 정확도에 최적화된 바이너리 집합, 속도 및 정확도에 최적화된 바이너리 집합 중 2 이상을 저장하고 있을 수 있 다. 복수의 최적화 조건 각각에 대응하는 바이너리 집합은, 인공지능 가속기가 지원하는 데이터 타입(data type)을 고려하여 구성될 수 있다. 예를 들어, 기능 관리모듈은 속도에 최적화된 바이너리 집합으로서, 제 1 데이터 타입을 사용하는 벡터 프로세싱 바이너리를 포함하는 바이너리 집합을 생성할 수 있다. 기능 관리모듈 은 정확도에 최적화된 바이너리 집합으로서, 제2 데이터 타입을 사용하는 벡터 프로세싱 바이너리를 포함 하는 바이너리 집합을 생성할 수 있다. 여기서, 제2 데이터 타입은, 바람직하게는, 제1 데이터 타입 대비 크기 (byte)가 큰 데이터 타입일 수 있다. 이와 관련된 실시예는 도 3을 참조하여 설명하도록 한다. 복수의 최적화 조건 각각에 대응하는 바이너리 집합은, 인공지능 가속기에서 제공하는 하드웨어 자원을 고 려하여 구성될 수 있다. 하드웨어 자원은, 예를 들어, 룩업 테이블, 곱셈 누적기 및 메모리 중 하나 이상을 포 함할 수 있다. 하드웨어 자원을 고려함에 있어서, 특정 레이어의 기능을 구현하기 위해 필요한 하드웨어 자원의 수(또는 크기) 및 하나의 벡터 프로세싱 바이너리가 사용할 수 있는 인공지능 가속기의 하드웨어 자원의 수(또는 크기)가 고려 될 수 있다. 예를 들어, 특정 레이어의 기능을 구현하기 위해 두 개의 룩업 테이블이 필요하고, 제1 데이터 타 입 및 제2 데이터 타입을 사용하는 벡터 프로세싱 바이너리가 각각 두 개 및 한 개의 룩업 테이블을 포함하는 경우를 가정할 수 있다. 이 경우, 기능 관리모듈은 속도에 최적화된 바이너리 집합으로서 제1 데이터 타입 을 사용하는 하나의 벡터 프로세싱 바이너리를 포함하는 바이너리 집합을 생성하고, 정확도에 최적화된 바이너 리 집합으로서 제2 데이터 타입을 사용하는 두 개의 벡터 프로세싱 바이너리를 포함하는 바이너리 집합을 생성 할 수 있다. 하드웨어 자원을 고려함에 있어서, 특정 레이어의 기능을 구현하기 위해 특정 하드웨어 자원을 이용할지 여부가 고려될 수 있다. 예를 들어, 기능 관리모듈은 속도에 최적화된 바이너리 집합으로서, 외부 메모리에 접근 하지 않아 빠른 연산 처리가 가능하도록 구성된 벡터 프로세싱 바이너리를 포함하는 바이너리 집합을 생성할 수 있다. 기능 관리모듈은 정확도에 최적화된 바이너리 집합으로서, 외부 메모리를 이용함으로써 정확한 연산 처리가 가능하도록 구성된 벡터 프로세싱 바이너리를 포함하는 바이너리 집합을 생성할 수 있다. 하드웨어 자원을 고려함에 있어서, 하드웨어 자원을 이용하여 처리할 데이터의 범위가 고려될 수 있다. 예를 들 어, 기능 관리모듈은 속도에 최적화된 바이너리 집합으로서, 넓은 범위의 데이터를 처리할 수 있도록 구성 된 벡터 프로세싱 바이너리를 포함하는 바이너리 집합을 생성할 수 있다. 기능 관리모듈은 정확도에 최적 화된 바이너리 집합으로서, 한정 범위 내의 데이터를 출력하도록 구성된 제1 벡터 프로세싱 바이너리 및 좁은 범위의 데이터를 처리할 수 있도록 구성된 제2 벡터 프로세싱 바이너리를 포함하는 바이너리 집합을 생성할 수 있다. 기능 관리모듈은, 각 최적화 조건에 대해서, 소정의 하이퍼파라미터의 값에 대응하는 복수의 바이너리 집 합을 저장하고 있을 수 있다. 여기서, 하이퍼파라미터는, 레이어의 유형에 따라 달라질 수 있다. 예를 들어, 픽 셀 셔플 레이어의 경우, 하이퍼파라미터는, 레이어의 배율일 수 있다. 기능 관리모듈은, 특정 배율에 대해, 속도에 최적화된 벡터 프로세싱 바이너리와 속도 및 정확도에 최적화된 벡터 프로세싱 바이너리를 생성할 수 있다. 여기서, 특정 배율은 소수(prime number)인 배율일 수 있다. 기능 관리모듈은 생성된 하나 이상 의 벡터 프로세싱 바이너리들을 조합하여, 각 배율에 대응하는 바이너리 집합을 구성할 수 있다. 이하, 특정한 신경망 및 최적화 조건에 대응하여 선택되는 바이너리 집합과의 명확한 구별을 위해, 기능 관리모 듈에 저장된 바이너리 집합은, '후보 바이너리 집합'으로 지칭될 수 있다. 기능 관리모듈은 각 레이어에 대한 복수의 후보 바이너리 집합들의 목록을 기능 사용정보 테이블에 기록할 수 있다. 기능 관리모듈은 각각의 후보 바이너리 집합을 최적화 조건 및/또는 하이퍼파라미터 값과 연관시 켜 기록할 수 있다. 바이너리 선택모듈은, 인공지능 가속기에서 처리하고자 하는 신경망에 포함된 적어도 일부의 레이어 각각에 대해, 해당 레이어의 기능을 수행하도록 구성된 복수의 후보 바이너리 집합들 중에서, 하나 이상의 바이 너리 집합을 선택할 수 있다. 바이너리 선택모듈은 신경망 전체 또는, 신경망에 포함된 일부 레이어에 대한 벡터 프로세싱 기능 업데이 트 요청을 획득할 수 있다. 수신한 요청에는, 업데이트할 레이어의 유형 및/또는 최적화 조건이 포함되어 있을 수 있다. 최적화 조건은, 신경망의 전체에 대해 동일하게 설정되거나, 레이어별로 설정될 수도 있다. 바이너리 선택모듈은, 복수의 후보 바이너리 집합들 중에서, 최적화 조건에 대응하는 하나 이상의 바이너 리 집합을 선택할 수 있다. 바이너리 선택모듈은, 기능 사용정보 테이블에서, 신경망의 전체에 대해 설정된 최적화 조건 또는 각 레이어에 대해 설정된 최적화 조건에 대응하는 바이너리 집합을 검색할 수 있다. 컴파일러는 선택된 하나 이상의 바이너리 집합을 이용하여, 인공지능 가속기에 탑재할 커맨드 패킷 스트림을 생성할 수 있다. 컴파일러는 선택된 하나 이상의 바이너리 집합이 인공지능 가속기에서 사 용될 수 있도록 주소(address), 데이터 크기, 타이밍(timing) 및/또는 링크(link) 등을 설정할 수 있다. 컴파일 러에 의해 수행되는 컴파일(compile) 동작은 해당 분야에서 일반적이므로, 이에 대한 구체적인 설명은 생 략하도록 한다. 일부 실시예에서, 인공지능 가속기에 신경망을 구동시키기 위한 커맨드 패킷 스트림이 이미 탑재된 이후에, 호스트 디바이스가 신경망에 포함된 특정 레이어에 대한 벡터 프로세싱 기능 업데이트 요청을 획 득할 수 있다. 벡터 프로세싱 기능 업데이트 요청은, 해당 레이어에 대한 최적화 조건 변경 요청을 포함할 수 있다. 이때, 최적화 조건의 변경이 다른 레이어의 연산에 영향을 미치지 않는 경우, 컴파일러가 생성하는 신규 커맨드 패킷 스트림에는, 해당 레이어에 대해 선택된 바이너리 집합만을 포함할 수 있다. 일부 실시예에서, 인공지능 가속기가 신경망을 구동하고 있는 런타임(runtime) 중에, 호스트 디바이스 가 신경망에 포함된 특정 레이어에 대한 벡터 프로세싱 기능 업데이트 요청을 획득할 수 있다. 벡터 프로 세싱 기능 업데이트 요청은, 해당 레이어에 대한 최적화 조건 변경 요청을 포함할 수 있다. 컴파일러는 해 당 레이어에 대한 연산을 중단하도록 하는 명령어를 생성하여 인공지능 가속기에 전달할 수 있다. 컴파일 러는 해당 레이어에 대해 선택된 바이너리 집합을 포함하는 신규 커맨드 패킷 스트림을 인공지능 가속기 에 탑재한 이후에, 해당 레이어에 대한 연산을 재시작하도록 하는 명령어를 생성하여 인공지능 가속기 에 전달할 수 있다. 실시예들에 따라, 특정 레이어에 대한 연산 중단 및/또는 재시작은, 해당 레이어 다음 에 위치한 레이어들에 대한 연산 중단 및/또는 재시작을 포함할 수 있다. 한편, 최적화 조건 변경에 의해, 해당 레이어의 입력 데이터 타입 및/또는 출력 데이터 타입이 변경된 경우, 컴파일러가 생성하는 신규 커맨드 패킷 스트림에는, 데이터 타입 변환을 위한 벡터 프로세싱 바이너리가 포함될 수 있다. 도 3은 본 개시의 일 실시예에 따라 인공지능 가속기의 벡터 프로세싱 기능을 업데이트하는 과정을 설명하기 위 한 예시도이다. 인공지능 가속기는 다양한 종류의 데이터 타입을 지원할 수 있다. 예를 들어, 인공지능 가속기는 16bit 데이터 타입(예컨대, int16 또는 fp16)과, 8bit 데이터 타입(예컨대, int8 또는 fp8)을 지원할 수 있다. 적은 크기의 데이터 타입을 사용하면 처리 속도는 더 빠를 수 있지만 정확도를 떨어뜨릴 수 있다. 호스트 디바이스는 벡터 프로세싱 기능 업데이트 요청에 응답하여 특정한 데이터 타입을 사용하는 바이너 리 집합을 인공지능 가속기에 탑재함으로써, 벡터 프로세싱 기능을 속도에 최적화되도록 업데이트하거나, 정확도에 최적화되도록 업데이트할 수 있다. 호스트 디바이스는 신경망 전체 또는 특정 레이어(302 내지 308)에 대한 벡터 프로세싱 기능 업데이 트 요청을 수신할 수 있다. 호스트 디바이스는 레이어의 유형별로, 최적화 조건에 따라 선택할 바이너리 집합을 정의한 기능 사용정보 테이블에서, 각 레이어(302 내지 308) 및 최적화 조건에 대응하는 바이너리 집합을 검색할 수 있다. 최적화 조건은, 신경망 전체에 대해 설정되거나, 신경망에 포함된 레이어(302 내지 308)별로 설정될 수도 있다. 예를 들어, 도 3의 예시에서, 컨볼루션 레이어, 활성화 레이어 및 소프트맥스 레이어에 대해서 는 속도 최적화가 설정되고 픽셀 셔플 레이어에 대해서는 정확도 최적화가 설정될 수 있다. 이 경우, 호스 트 디바이스는, 컨볼루션 레이어, 활성화 레이어 및 소프트맥스 레이어에 대해서는 8bit 데이터 타입을 사용하는 바이너리 집합(342, 344 및 348)을 선택하고, 픽셀 셔플 레이어에 대해서는, 16bit 데이터 타입을 사용하는 바이너리 집합을 선택할 수 있다. 도 4는 본 개시의 일 실시예에 따라 소프트맥스 레이어에 대한 벡터 프로세싱 기능을 업데이트하는 과정을 설명 하기 위한 예시도이다. 이하, 도 4를 설명함에 있어, 인공지능 가속기가 int8의 데이터 타입 및 int16의 데이터 타입을 지원하는 경우를 가정한다. 소프트맥스 레이어에서는 수학식 1을 연산할 수 있다. 수학식 1"}
{"patent_id": "10-2022-0176953", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이때, 인공지능 가속기에서 지수(ea) 및 역수(1/b)를 연산하기 위해서는, 2개의 룩업 테이블이 필요하다. 이때, int8의 데이터 타입을 사용하는 벡터 프로세싱 바이너리(이하, int8 벡터 프로세싱 바이너리)는 두 개의 룩업 테이블을 사용할 수 있는 반면에, int16의 데이터 타입을 사용하는 벡터 프로세싱 바이너리(이하, int16 벡터 프로세싱 바이너리)에서는 하나의 룩업 테이블만 사용이 가능하다. 이러한 점을 고려하여, 호스트 디바이스는 최적화 조건에 따라, 인공지능 가속기가 상이한 개수 및 상이한 데이터 타입의 벡터 프로세싱 바이너리를 사용하도록 업데이트할 수 있다. 호스트 디바이스는, 소프트맥스 레이어에 대응하는 후보 바이너리 집합으로서, 속도에 최적화된 제1 바이너리 집합 및 정확도에 최적화된 제2 바이너리 집합을 사전에 제작하여 저장하고 있을 수 있다. 여기서, 속 도에 최적화된 바이너리 집합은, 하나의 int8 벡터 프로세싱 바이너리를 포함할 수 있다. 정확도에 최적화된 바 이너리 집합은, 두 개의 int16 벡터 프로세싱 바이너리를 포함할 수 있다. 호스트 디바이스는 소프트맥스 레이어 또는, 이를 포함하는 신경망에 대한 벡터 프로세싱 기능 업데이트 요청을 수신할 수 있다. 수신한 요청에는, 소프트맥스 레이어 또는 신경망에 대해 설정된 최적화 조건이 포함되어 있을 수 있다. 호스트 디바이스는 최적화 조건과 바이너리 집합 간의 연관관계가 정의된 기능 사용정보 테이블을 참 조하여, 설정된 최적화 조건에 대응하는 바이너리 집합을 선택할 수 있다. 호스트 디바이스는, 인공지능 가속기로 하여금 선택된 바이너리 집합을 사용하여 소프트맥스 레이어 의 기능을 수행하도록 업데이트할 수 있다. 일 예로, 도 4에 도시된 것과 같이, 정확도에 최적화하는 경우, 각각 하나의 룩업 테이블을 포함하는 두 개의 int16 벡터 프로세싱 바이너리(422 및 424)가 사용될 수 있 다. 다른 예로, 속도에 최적화하는 경우에는, 두 개의 룩업 테이블을 포함하는 하나의 int8 벡터 프로세싱 바이 너리가 사용될 수 있다. 도 5는 본 개시의 일 실시예에 따라 전역 평균 풀링 레이어에 대한 벡터 프로세싱 기능을 업데이트하는 과정을 설명하기 위한 예시도이다. 전역 평균 풀링 레이어에서는, 동일 채널 내의 특징값들에 대해 평균을 산출하는 연산이 수행된다. 인공지능 가속기의 메모리의 한계로 인해, 인공지능 가속기에서 많은 양의 연산이 한번에 처리되지 못할 수 있다. 이를 해결하기 위해, 인공지능 가속기는 입력된 특징맵들을 복수의 작은 타일(tile)들로 분 할하고, 분할된 타일별로 연산을 수행할 수 있다. 메모리 사용량을 줄이기 위해서, 인공지능 가속기가 타 일별로 가산연산을 수행함에 있어, 각 타일의 결과값을 채널 내의 특징값들의 수로 나눈 후에 더하는 방식이 이 용될 수 있다. 이 경우, 양자화(quantization) 중에 정확도의 손실이 발생할 수 있다. 이러한 정확도의 손실을 줄이기 위해서, 외부의 메모리에 누산기(accumulator)의 연산을 위한 공간을 마련해 두고, 이를 이용하여 각 타 일의 결과값을 그대로 더하는 방식을 이용할 수 있다. 이 경우, 인공지능 가속기가 외부 메모리에 데이터 를 쓰는 동작, 및 외부 메모리로부터 데이터를 읽어오는 동작에 의해 속도가 줄어들게 된다. 이러한 점을 고려하여, 호스트 디바이스는 최적화 조건에 따라, 인공지능 가속기가 내부 메모리만을 이용하거나, 외부 메모리를 이용하도록 구성된 바이너리 집합을 인공지능 가속기에 탑재할 수 있다. 호스트 디바이스는, 전역 평균 풀링 레이어에 대응하는 후보 바이너리 집합으로서, 속도에 최적화된 제1 바이너리 집합 및 정확도에 최적화된 제2 바이너리 집합을 사전에 제작하여 저장하고 있을 수 있다. 여기서, 속도에 최적화된 바이너리 집합은, 외부 메모리를 사용하지 않으며, 각 타일의 결과값을 특정 수로 나 눈 후에 더하는 방식을 이용하도록 구성된 벡터 프로세싱 바이너리를 포함 수 있다. 정확도에 최적화된 바이너 리 집합은, 외부 메모리를 사용하여, 각 타일의 결과값을 특정 수로 나누지 않고 그대로 더하는 방식을 이용하도록 구성된 벡터 프로세싱 바이너리를 포함할 수 있다. 호스트 디바이스는 전역 평균 풀링 레이어 또는, 이를 포함하는 신경망에 대한 벡터 프로세싱 기능 업데이트 요청을 수신할 수 있다. 수신한 요청에는, 전역 평균 풀링 레이어 또는 신경망에 대해 설정된 최적화 조건이 포함되어 있을 수 있다. 호스트 디바이스는 최적화 조건과 바이너리 집합 간의 연관관계가 정의된 기능 사용정보 테이블을 참 조하여, 설정된 최적화 조건에 대응하는 바이너리 집합을 선택할 수 있다. 호스트 디바이스는, 인공지능 가속기로 하여금 선택된 바이너리 집합을 사용하여 전역 평균 풀링 레 이어의 기능을 수행하도록 업데이트할 수 있다. 일 예로, 도 5에 도시된 것과 같이, 정확도에 최적화하는 경우, 호스트 디바이스는, 외부 메모리를 사용하여 전역 평균 풀링 레이어의 기능을 수행하도록 구성 된 벡터프로세싱 바이너리를 이용하여, 인공지능 가속기의 벡터 프로세싱 기능을 업데이트할 수 있다. 도 6a 내지 도 6c는 본 개시의 일 실시예에 따라 L2 정규화 레이어에 대한 벡터 프로세싱 기능을 업데이트하는 과정을 설명하기 위한 예시도이다. L2 정규화 레이어에서는 루트의 역수(x-1/2)에 대한 연산이 필요하다. 이러한 복잡한 그래프 연산을 처리하 기 위해서, 인공지능 가속기는 룩업 테이블을 사용할 수 있다. 이때, 룩업 테이블의 전체 엔트리(entry) 개수가 한정되어 있기 때문에, 룩업 테이블의 입력 범위 및 출력 범위를 알맞게 설정해야 높은 정밀도를 얻을 수 있다. 예를 들어, 도 6b에 도시된 것과 같이, 룩업 테이블이 상대적으로 넓은 입력 범위를 갖는 데이터를 처 리하는 경우, 엔트리 개수의 제한에 의해 각 엔트리의 출력 값들 간의 간격이 넓어져 정밀도가 떨어지게 된다. 반면, 도 6c에 도시된 것과 같이 룩업 테이블이 상대적으로 좁은 입력 범위를 갖는 데이터를 처리하는 경우, 각 엔트리의 출력 값들 간의 간격이 좁아져 정밀도를 높일 수 있다. 예를 들어, 엔트리의 개수가 5개라고 가정하면, 인공지능 가속기가 룩업 테이블을 이용하여 도 6b에 도시된 입력 범위 내의 데이터에 대응하는 출력 값을 구하는 경우 대략 (1-0.2)/5 단위의 정밀도를 갖는 반면, 도 6c에 도시된 입력 범위 내의 데이터에 대응하는 출력 값을 구하는 경우에는 대략 (1-0.4)/5 단위의 정밀도를 가질 수 있다. 본 개시의 일 실시예에 따른 호스트 디바이스는, 최적화 조건에 따라, 바이너리 집합에 포함되는 벡터 프 로세싱 바이너리의 갯수를 달리함으로써, 룩업 테이블의 입출력 범위를 조정할 수 있다. 호스트 디바이스는, L2 정규화 레이어에 대응하는 후보 바이너리 집합으로서, 속도에 최적화된 제1 바이너리 집합 및 정확도에 최적화된 제2 바이너리 집합을 사전에 제작하여 저장하고 있을 수 있다. 여기서, 속 도에 최적화된 제1 바이너리 집합은, 하나의 벡터 프로세싱 바이너리를 포함할 수 있다. 정확도에 최적화된 제2 바이너리 집합은, 두 개의 벡터 프로세싱 바이너리를 포함할 수 있다. 제2 바이너리 집합의 첫번째 벡터 프로세 싱 바이너리에서 처리된 결과는, 좁은 범위로 한정되어 제2 벡터 프로세싱 바이너리로 전달될 수 있다. 이에 따 라, 제2 벡터 프로세싱 바이너리는, 제1 바이너리 집합에 포함된 벡터 프로세싱 바이너리와 비교할 때, 상대적 으로 좁은 입력범위를 갖는 데이터를 처리할 수 있다. 호스트 디바이스는 L2 정규화 레이어 또는, 이를 포함하는 신경망에 대한 벡터 프로세싱 기능 업데이트 요청을 수신할 수 있다. 수신한 요청에는, L2 정규화 레이어 또는 신경망에 대해 설정된 최 적화 조건이 포함되어 있을 수 있다. 호스트 디바이스는 최적화 조건과 바이너리 집합 간의 연관관계가 정의된 기능 사용정보 테이블을 참 조하여, 설정된 최적화 조건에 대응하는 바이너리 집합을 선택할 수 있다. 호스트 디바이스는, 인공지능 가속기로 하여금 선택된 바이너리 집합을 사용하여 L2 정규화 레이어 의 기능을 수행하도록 업데이트할 수 있다. 일 예로, 도 6a에 도시된 것과 같이, 정확도에 최적화하는 경 우, 두 개의 벡터 프로세싱 바이너리(622 및 624)를 포함하는 바이너리 집합을 이용하여, 인공지능 가속기(10 0)의 벡터 프로세싱 기능을 업데이트할 수 있다. 다른 예로, 속도에 최적화하는 경우에는, 하나의 벡터 프로세 싱 바이너리를 포함하는 바이너리 집합을 이용하여, 인공지능 가속기의 벡터 프로세싱 기능을 업데이트할 수 있다. 이상과 같이, 본 개시의 일 실시예에 따르면, L2 정규화 레이어에 대한 연산을 하나의 벡터 프로세싱 바이 너리에서 처리할 수 있더라도, 복수개의 벡터 프로세싱 바이너리에서 처리하도록 함으로써 정밀도를 향상시킬 수 있다. 도 7a 및 도 7b는 본 개시의 일 실시예에 따라 픽셀 셔플 레이어에 대한 벡터 프로세싱 기능을 업데이트하는 과 정을 설명하기 위한 예시도이다. 이하, 도 7a 및 도 7b를 설명함에 있어, 인공지능 가속기가 int8의 데이 터 타입 및 int16의 데이터 타입을 지원하는 경우를 가정한다. 픽셀 셔플 레이어는 배율에 따라서 특징맵을 확대시키는 기능을 한다. 호스트 디바이스는 픽셀 셔플 레이어에 대응하는 후보 바이너리 집합으로서, 최적화 조건 및/또는 픽 셀 셔플 레이어의 배율을 고려한 복수의 바이너리 집합들을 제공할 수 있다. 예를 들어, 호스트 디바이스 는 모든 배율을 지원하는 기본 바이너리 집합, 특정 배율을 지원하는 속도에 최적화된 바이너리 집합들, 및 특정 배율을 지원하는 속도 및 정확도에 최적화된 바이너리 집합들을 저장하고 있을 수 있다. 기본 바이너리 집합 및 속도에 최적화된 바이너리 집합들은 int8의 데이터 타입을 사용하는 벡터 프로세싱 바이너리를 포함할 수 있다. 속도 및 정확도에 최적화된 바이너리 집합은 int16의 데이터 타입을 사용하는 벡터 프로세싱 바이너리 를 포함할 수 있다. 실시예들에 따라, 호스트 디바이스는, 소수(prime number)의 배율을 지원하는 바이너 리 집합들을 사전에 제작하여 저장하고 있을 수 있다. 호스트 디바이스는 최적화 조건 및/또는 픽셀 셔플 레이어의 배율과, 후보 바이너리 집합 간의 연관 관계가 정의된 기능 사용정보 테이블(720 또는 722)을 저장하고 있을 수 있다. 호스트 디바이스는 픽셀 셔플 레이어 또는, 이를 포함하는 신경망에 대한 벡터 프로세싱 기능 업데이트 요청을 수신할 수 있다. 수신한 요청에는, 픽셀 셔플 레이어 또는 신경망에 대해 설정된 최 적화 조건 및/또는, 픽셀 셔플 레이어의 배율이 포함되어 있을 수 있다. 호스트 디바이스는 수신한 요청에 응답하여, 최적화 조건 및/또는 픽셀 셔플 레이어의 배율에 대응하 는 하나 이상의 바이너리 집합을 선택할 수 있다. 호스트 디바이스는 기능 사용정보 테이블(720 또는 72 2)을 참조하여, 하나 이상의 바이너리 집합을 검색할 수 있다. 도 7a를 참조하면, 일 실시예에 따른 기능 사용정보 테이블에는, 소수(prime number)의 배율을 지원하는 후보 바이너리 집합들에 대한 정보가 기록되어 있을 수 있다. 여기서, 소수의 배율을 지원하는 후보 바이너리 집합들에 대한 정보는, 사전에 제작된 후보 바이너리 집합들 중에서 어느 한 바이너리 집합을 식별할 수 있는 정보를 포함할 수 있다. 픽셀 셔플 레이어의 배율이 합성수인 경우, 호스트 디바이스는 배율에 대해 소인수분해를 수행하여 복수의 소수 값을 획득하고, 기능 사용정보 테이블에서 획득한 소수 값들에 대응하 는 바이너리 집합들을 검색할 수 있다. 도 7b를 참조하면, 다른 실시예에 따른 기능 사용정보 테이블에는, 소수의 배율을 지원하는 바이너리 집합 들에 대한 정보 및 합성수의 배율을 지원하는 바이너리 집합들에 대한 정보가 기록되어 있을 수 있다. 여기서, 합성수의 배율을 지원하는 바이너리 집합들에 대한 정보는, 사전에 제작되어 저장된 바이너리 집합들 중에서 하 나 이상의 바이너리 집합을 식별할 수 있는 정보 및 해당 바이너리 집합의 사용횟수를 포함할 수 있다. 호스트 디바이스는 기능 사용정보 테이블(700 내지 722)을 참조하여, 픽셀 셔플 레이어의 배율을 구 성하기 위해 필요한 하나 이상의 바이너리 집합을 식별하고, 식별된 바이너리 집합을 조합하여 인공지능 가속기 의 벡터 프로세싱 기능을 업데이트할 수 있다. 일 예로, 도 7a에 도시된 것과 같이 픽셀 셔플 레이어의 배율이 6배이고 속도에 최적화하는 경우, 2배의 배율을 지원하고 int8의 데이터 타입을 사용하는 벡터 프로세싱 바이너리와 3배의 배율을 지원하고 하고 int8의 데이터 타입을 사용하는 벡터 프로세싱 바이너리가 사용될 수 있다. 다른 예로, 픽셀 셔플 레이어 의 배율이 4배이고 속도에 최적화하는 경우, 2배의 배율을 지원하고 int8의 데이터 타입을 사용하는 벡터 프로세싱 바이너리가 2번 사용될 수 있다. 또 다른 예로, 픽셀 셔플 레이어의 배율이 8배이고 속도 및 정 확도에 최적화하는 경우, 2배의 배율을 지원하고 하고 int16의 데이터 타입을 사용하는 벡터 프로세싱 바이너리 가 3번 사용될 수 있다. 도 8은 본 개시의 일 실시예에 따른 인공지능 가속기의 벡터 프로세싱 기능 업데이트 방법을 나타내는 흐름도이 다. 도 8에 도시된 방법은, 전술한 호스트 디바이스에 의해 수행될 수 있으므로, 중복되는 설명에 대해서 는 자세한 내용을 생략한다. 호스트 디바이스는 인공지능 가속기에서 구동하고자 하는 신경망에 대한 정보를 획득할 수 있다 (S800). 여기서, 인공지능 가속기는, 하나 이상의 벡터 프로세서를 포함할 수 있다. 호스트 디바이스는 신경망의 적어도 일부의 레이어에 대해, 각 레이어의 기능을 수행하도록 구성된 복수의 후보 바이너리 집합들 중에서 기설정된 최적화 조건에 대응하는 하나 이상의 바이너리 집합을 선택할 수 있다 (S820). 여기서, 복수의 후보 바이너리 집합들 각각은, 적어도 하나의 벡터 프로세싱 바이너리를 포함할 수 있 다. 호스트 디바이스는 복수의 후보 바이너리 집합들의 목록을 기록하는 테이블에서, 신경망 또는 선택 대상인 레이어에 대해 설정된 최적화 조건에 대응하는 바이너리 집합을 검색할 수 있다. 복수의 후보 바이너리 집합들은, 속도에 최적화된 제1 후보 바이너리 집합, 정확도에 최적화된 제2 후보 바이너 리 집합 및 속도와 정확도에 최적화된 제3 후보 바이너리 집합 중 2 이상을 포함할 수 있다. 복수의 후보 바이너리 집합들은, 제1 데이터 타입을 사용하는 제1 후보 바이너리 집합 및 제2 데이터 타입을 사 용하는 제2 후보 바이너리 집합을 포함할 수 있다. 여기서, 제1 후보 바이너리 집합 및 제2 후보 바이너리 집합 은, 선택 대상인 레이어의 기능을 구현하기 위해 필요한 인공지능 가속기의 하드웨어 자원 및 각 벡터 프 로세싱 바이너리가 사용할 수 있는 인공지능 가속기의 하드웨어 자원을 고려하여, 구성될 수 있다. 인공지 능 가속기의 하드웨어 자원은, 룩업 테이블, 곱셈 누적기 및 메모리 중 하나 이상을 포함할 수 있다. 복수의 후보 바이너리 집합들은, 선택 대상인 레이어의 하이퍼파라미터에 대한 제1 설정값에 대응하는 제1 후보 바이너리 집합, 및 상기 하이퍼파라미터에 대한 제2 설정값에 대응하는 제2 후보 바이너리 집합을 포함할 수 있 다. 실시예들에 따라, 호스트 디바이스는 제1 후보 바이너리 집합 및 상기 제2 후보 바이너리 집합 중 하 나 이상을 조합하여, 하이퍼파라미터에 대한 제3 설정값에 대응하는 제3 후보 바이너리 집합을 생성할 수 있다. 실시예들에 따라, 바이너리 집합의 선택 대상이 되는 적어도 일부의 레이어는, 인공지능 가속기가 신경망 을 구동하는 중에 최적화 조건의 변경이 요청된 레이어일 수 있다. 이와 관련된 실시예는 도 9를 참조하여 후술 하도록 한다. 호스트 디바이스는 선택된 하나 이상의 바이너리 집합을 이용하여 커맨드 패킷 스트림을 생성할 수 있다 (S840). 호스트 디바이스는 생성된 커맨드 패킷 스트림을 인공지능 가속기에 탑재하여, 인공지능 가속기(10 0)의 벡터 프로세싱 기능을 업데이트할 수 있다(S860). 도 9는 본 개시의 일 실시예에 따른 런타임 중 인공지능 가속기의 벡터 프로세싱 기능 업데이트 방법을 나타내 는 흐름도이다. 도 9에 도시된 방법은, 전술한 호스트 디바이스에 의해 수행될 수 있으므로, 중복되는 설 명에 대해서는 자세한 내용을 생략한다. 신경망의 런타임 중, 신경망의 적어도 일부의 레이어에 대한 최적화 조건이 변경될 수 있다(S900). 예를 들어, 호스트 디바이스는, 사용자로부터 신경망 전체 또는 특정한 레이어(들)에 대한 최적화 조건 변경 요청을 입력받을 수 있다. 호스트 디바이스는, 적어도 일부의 레이어에 대한 최적화 조건의 변경요청에 응답하여, 인공지능 가속기 로 하여금 최적화 조건이 변경된 레이어에 대한 연산을 중단하도록 하는 명령어를 전송할 수 있다(S910). 호스트 디바이스는, 변경된 최적화 조건에 대응하는 하나 이상의 바이너리 집합을 선택할 수 있다(S920). 과정 S920은 도 8에 도시된 과정 S820과 동일하거나 상응할 수 있다. 호스트 디바이스는, 최적화 조건의 변경에 따라, 입력 및 출력 중 하나 이상의 데이터 타입이 변경된 레이 어가 존재하는지 확인할 수 있다(S930). 데이터 타입이 변경된 레이어가 존재하지 않는 경우(S930, NO), 호스트 디바이스는 선택된 바이너리 집합 (들)을 이용하여 커맨드 패킷 스트림을 생성하고, 생성된 커맨드 패킷 스트림을 인공지능 가속기에 탑재하 여, 인공지능 가속기의 벡터 프로세싱 기능을 업데이트할 수 있다(S960). 과정 S960은 도 8에 도시된 과정 S840 내지 S860과 동일하거나 상응할 수 있다. 반면, 데이터 타입이 변경된 레이어가 존재하는 경우(S930, YES), 호스트 디바이스는 데이터 타입 변환을 위한 벡터 프로세싱 바이너리가 포함된 커맨드 패킷 스트림을, 인공지능 가속기에 탑재할 수 있다(S940 및 S950). 일 예로, 데이터 타입 변환을 위한 벡터 프로세싱 바이너리는 벡터 프로세서가 데이터 타입 변환기능을 수행할 수 있도록 하는 하나 이상의 명령어를 포함할 수 있다. 다른 예로, 인공지능 가속기의 벡터 프로세 서에 데이터 타입 변환 기능이 내장되어 있는 경우에는, 데이터 타입 변환을 위한 벡터 프로세싱 바이너리는 데 이터 타입 변환 기능을 활성화하는 명령어를 포함할 수 있다.호스트 디바이스는 인공지능 가속기로 하여금 적어도 일부의 레이어에 대한 연산을 재시작하도록 하 는 명령어를 전송할 수 있다(S960). 본 발명에 따른 장치 또는 방법의 각 구성요소는 하드웨어 또는 소프트웨어로 구현되거나, 하드웨어 및 소프트 웨어의 결합으로 구현될 수 있다. 또한, 각 구성요소의 기능이 소프트웨어로 구현되고 마이크로프로세서가 각 구성요소에 대응하는 소프트웨어의 기능을 실행하도록 구현될 수도 있다. 본 명세서에 설명되는 시스템들 및 기법들의 다양한 구현예들은, 디지털 전자 회로, 집적회로, FPGA(field programmable gate array), ASIC(application specific integrated circuit), 컴퓨터 하드웨어, 펌웨어, 소프 트웨어, 및/또는 이들의 집합으로 실현될 수 있다. 이러한 다양한 구현예들은 프로그래밍가능 시스템 상에서 실 행 가능한 하나 이상의 컴퓨터 프로그램들로 구현되는 것을 포함할 수 있다. 프로그래밍가능 시스템은, 저장 시 스템, 적어도 하나의 입력 디바이스, 그리고 적어도 하나의 출력 디바이스로부터 데이터 및 명령들을 수신하고 이들에게 데이터 및 명령들을 전송하도록 결합되는 적어도 하나의 프로그래밍가능 프로세서(이것은 특수 목적 프로세서일 수 있거나 혹은 범용 프로세서일 수 있음)를 포함한다. 컴퓨터 프로그램들(이것은 또한 프로그램들, 소프트웨어, 소프트웨어 애플리케이션들 혹은 코드로서 알려져 있음)은 프로그래밍가능 프로세서에 대한 명령어 들을 포함하며 \"컴퓨터가 읽을 수 있는 기록매체\"에 저장된다. 컴퓨터가 읽을 수 있는 기록매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기 록장치를 포함한다. 이러한 컴퓨터가 읽을 수 있는 기록매체는 ROM, CD-ROM, 자기 테이프, 플로피디스크, 메모 리 카드, 하드 디스크, 광자기 디스크, 스토리지 디바이스 등의 비휘발성(non-volatile) 또는 비일시적인(non- transitory) 매체일 수 있으며, 또한 데이터 전송 매체(data transmission medium)와 같은 일시적인 (transitory) 매체를 더 포함할 수도 있다. 또한, 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수도 있다. 본 명세서의 흐름도/타이밍도에서는 각 과정들을 순차적으로 실행하는 것으로 기재하고 있으나, 이는 본 개시의 일 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것이다. 다시 말해, 본 개시의 일 실시예가 속하는 기 술 분야에서 통상의 지식을 가진 자라면 본 개시의 일 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 흐 름도/타이밍도에 기재된 순서를 변경하여 실행하거나 각 과정들 중 하나 이상의 과정을 병렬적으로 실행하는 것으로 다양하게 수정 및 변형하여 적용 가능할 것이므로, 흐름도/타이밍도는 시계열적인 순서로 한정되는 것은 아니다. 이상의 설명은 본 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술 분 야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변 형이 가능할 것이다. 따라서, 본 실시예들은 본 실시예의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위 한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0176953", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 가속기 시스템을 개략적으로 나타낸 블록구성도이다. 도 2는 본 개시의 일 실시예에 따른 호스트 디바이스를 개략적으로 나타낸 블록구성도이다. 도 3은 본 개시의 일 실시예에 따라 인공지능 가속기의 벡터 프로세싱 기능을 업데이트하는 과정을 설명하기 위 한 예시도이다. 도 4는 본 개시의 일 실시예에 따라 소프트맥스 레이어에 대한 벡터 프로세싱 기능을 업데이트하는 과정을 설명 하기 위한 예시도이다. 도 5는 본 개시의 일 실시예에 따라 전역 평균 풀링 레이어에 대한 벡터 프로세싱 기능을 업데이트하는 과정을 설명하기 위한 예시도이다. 도 6a 내지 도 6c는 본 개시의 일 실시예에 따라 L2 정규화 레이어에 대한 벡터 프로세싱 기능을 업데이트하는 과정을 설명하기 위한 예시도이다. 도 7a 및 도 7b는 본 개시의 일 실시예에 따라 픽셀 셔플 레이어에 대한 벡터 프로세싱 기능을 업데이트하는 과 정을 설명하기 위한 예시도이다. 도 8은 본 개시의 일 실시예에 따라 벡터 프로세싱 기능을 업데이트하는 방법을 나타내는 흐름도이다. 도 9는 본 개시의 일 실시예에 따라 런타임 중에 벡터 프로세싱 기능을 업데이트하는 방법을 나타내는 흐름도이 다."}
