{"patent_id": "10-2023-0083294", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0001131", "출원번호": "10-2023-0083294", "발명의 명칭": "개인화된 패턴 기반 장치 제어 시스템 및 장치 제어 방법", "출원인": "주식회사 에스오에스랩", "발명자": "정지성"}}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "동작 예측 모델을 학습시키기 위한 방법으로서,복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계 -이 때, 상기 센서 데이터는 복수의 프레임 데이터 및 복수의 프레임 데이터 각각에 대한 시간 정보를 포함하고, 상기 복수의 프레임 데이터 각각은 복수의포인트 데이터를 포함하며, 상기 복수의 포인트 데이터 각각은 위치 좌표 값을 포함함-;제1 가전기기의 제1 동작에 대한 동작 시간 정보를 포함하는 제1 가전기기 데이터를 획득하는 단계;상기 제1 가전기기 데이터에 포함되는 상기 제1 가전기기의 상기 제1 동작에 대한 동작 시간 정보 및 상기 복수의 프레임 데이터 각각에 대한 시간 정보를 기초로 제1 프레임 데이터 그룹을 선택하는 단계 -이 때, 상기 제1프레임 데이터 그룹은 적어도 둘 이상의 프레임 데이터를 포함하되, 상기 제1 프레임 데이터 그룹에 포함되는적어도 둘 이상의 프레임 데이터에 대한 시간 정보는 상기 제1 동작에 대한 동작 시간 정보 보다 과거 시간에대한 정보임-;상기 선택된 제1 프레임 데이터 그룹을 기초로 상기 제1 가전기기의 제1 동작에 대한 제1 학습 입력 데이터를생성하는 단계; 및적어도 상기 제1 학습 입력 데이터를 이용하여 상기 제1 가전기기에 대한 제1 동작 예측 모델을 학습시키는 단계;를 포함하는,동작 예측 모델을 학습시키기 위한 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 센서 데이터는 포인트 클라우드 데이터, 뎁스 맵 데이터, 인텐시티 맵 데이터, 라이트 캡쳐 맵 데이터 및디텍팅 맵 데이터 중 적어도 하나를 포함하는,동작 예측 모델을 학습시키기 위한 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제1 가전기기의 상기 제1 동작에 대한 동작 시간 정보는, 상기 제1 가전기기가 사용자와 상호작용을 시작한 시점, 상기 제1 가전기기가 사용자와 상호작용하여 워밍업(warmin-up) 된 시점, 상기 제1 가전기기가 상기사용자와 상호작용하여 상기 제1 동작을 시작한 시점, 상기 제1 가전기기가 상기 제1 동작을 마친 시점 및 상기제1 가전기기가 상기 사용자와 상호작용 한 시간 구간 중 적어도 하나에 기초하여 결정된 시간 정보인,동작 예측 모델을 학습시키기 위한 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,제2 가전기기의 제2 동작에 대한 동작 시간 정보를 포함하는 제2 가전기기 데이터를 획득하는 단계;상기 제2 가전기기 데이터에 포함되는 상기 제2 가전기기의 상기 제2 동작에 대한 동작 시간 정보 및 상기 복수의 프레임 데이터 각각에 대한 시간 정보를 기초로 제2 프레임 데이터 그룹을 선택하는 단계 -이때, 상기 제2프레임 데이터 그룹은 적어도 둘 이상의 프레임 데이터를 포함하되, 상기 제2 프레임 데이터 그룹에 포함되는적어도 둘 이상의 프레임 데이터에 대한 시간 정보는 상기 제2 동작에 대한 동작 시간 정보 보다 과거 시간에대한 정보임-;공개특허 10-2025-0001131-3-상기 선택된 제2 프레임 데이터 그룹을 기초로 상기 제2 가전기기의 제2 동작에 대한 제2 학습 입력 데이터를생성하는 단계; 및적어도 상기 제2 학습 입력 데이터를 이용하여 상기 제2 가전기기에 대한 제2 동작 예측 모델을 학습시키는 단계;를 포함하는,동작 예측 모델을 학습시키기 위한 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 제1 프레임 데이터 그룹을 선택하는 단계는,상기 제1 동작에 대한 동작 시간 정보를 기초로 기준 시점을 특정하는 단계; 및상기 복수의 프레임 데이터 중 상기 기준 시점보다 과거인 제1 시점에 대응되는 제1 프레임 데이터 내지 상기기준 시점보다 과거인 제N 시점에 대응되는 제N 프레임 데이터를 선택하는 단계;를 포함하는,동작 예측 모델을 학습시키기 위한 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제1 프레임 데이터 그룹을 선택하는 단계는,상기 제1 동작에 대한 동작 시간 정보를 기초로 기준 시점을 특정하는 단계;상기 기준 시점을 기초로 특정 시간 구간을 특정하는 단계; 및상기 복수의 프레임 데이터 중 상기 특정 시간 구간에 대응되는 프레임 데이터를 선택하는 단계;를 포함하는,동작 예측 모델을 학습시키기 위한 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 특정 시간 구간은, 상기 기준 시점과 상기 기준 시점으로부터 제1 기설정된 시간 간격 이전의 시점 사이의시간 구간인,동작 예측 모델을 학습시키기 위한 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 특정 시간 구간은, 상기 기준 시점으로부터 제1 기설정된 시간 간격 이전의 시점과 상기 기준 시점으로부터 제2 기설정된 시간 간격 이전의 시점 사이의 시간 구간인,동작 예측 모델을 학습시키기 위한 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 선택된 제1 프레임 데이터 그룹을 기초로 상기 제1 가전기기의 상기 제1 동작에 대한 상기 제1 학습 입력데이터를 생성하는 단계는,상기 제1 프레임 데이터 그룹에 포함된 프레임 데이터들 각각에 대해, 상기 프레임 데이터에 포함된 포인트 데이터들 중 동적 객체에 대응되는 적어도 일부의 서브 포인트 데이터를 세그먼트하는 단계;상기 세그먼트된 서브 포인트 데이터들의 위치 좌표 값에 기초하여 상기 프레임 데이터들 각각에 대응되는 중심위치 정보를 획득하는 단계; 및공개특허 10-2025-0001131-4-상기 획득된 중심 위치 정보들에 기초하여 상기 제1 가전기기의 상기 제1 동작에 대한 상기 제1 학습 입력 데이터를 생성하는 단계;를 포함하는,동작 예측 모델을 학습시키기 위한 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 획득된 중심 위치 정보들에 기초하여 상기 제1 가전기기의 상기 제1 동작에 대한 상기 제1 학습 입력 데이터를 생성하는 단계는,상기 획득된 중심 위치 정보들의 위치 좌표 값에 기초하여 상기 중심 위치에 대한 궤적 정보를 획득하는 단계;및상기 획득된 궤적 정보에 기초하여 상기 제1 가전기기의 상기 제1 동작에 대한 상기 제1 학습 입력 데이터를 생성하는 단계;를 포함하는,동작 예측 모델을 학습시키기 위한 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 제1 가전기기에 대한 무동작 트리거 데이터를 획득하는 단계;상기 무동작 트리거 데이터에 포함된 트리거 시점 정보 및 상기 복수의 프레임 데이터 각각에 대한 시간 정보를기초로 제3 프레임 데이터 그룹을 선택하는 단계 -이때, 제3 프레임 데이터 그룹은 적어도 둘 이상의 프레임 데이터를 포함함-;상기 선택된 제3 프레임 데이터 그룹을 기초로 상기 제1 가전기기의 무동작에 대한 제3 학습 입력 데이터를 생성하는 단계; 및상기 제3 학습 입력 데이터를 더 이용하여 상기 제1 가전기기에 대한 상기 제1 동작 예측 모델을 학습시키는 단계;를 포함하는,동작 예측 모델을 학습시키기 위한 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 제1 학습 입력 데이터를 이용하여 상기 제1 가전기기에 대한 상기 제1 동작 예측 모델을 학습시키는 단계는,학습 트리거를 획득하는 단계; 및 상기 제1 학습 입력 데이터를 이용하여 상기 제1 가전기기에 대한 상기 제1 동작 예측 모델을 학습시키는 단계;를 포함하는,동작 예측 모델을 학습시키기 위한 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 제1 학습 입력 데이터를 이용하여 상기 제1 가전기기에 대한 상기 제1 동작 예측 모델을 학습시키는 단계는,상기 제1 학습 입력 데이터의 개수를 판단하는 단계;상기 제1 학습 입력 데이터의 개수가 기설정된 개수 이상이면 상기 제1 학습 입력 데이터를 이용하여 상기 제1가전기기에 대한 상기 제1 동작 예측 모델을 학습시키는 단계; 및 공개특허 10-2025-0001131-5-상기 제1 학습 입력 데이터의 개수가 상기 기설정된 개수 미만이면, 특정 시간동안 기다리는 단계;를 포함하는,동작 예측 모델을 학습시키기 위한 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "사용자의 집에 설치된 후 학습 데이터 수집 기간이 지난 이후부터 가전기기에 대한 동작 제어 정보를 생성하는동작 예측 시스템의 동작 방법으로서,학습된 동작 예측 모델을 생성하는 단계 -이 때, 상기 학습된 동작 예측 모델은 상기 학습 데이터 수집 기간에서 획득된 센서 데이터를 기초로 생성된 학습 데이터를 이용하여 학습됨-; 및상기 학습된 동작 예측 모델에 예측 입력 데이터를 적용하여 가전기기에 대한 동작 제어 정보를 생성하는 단계-이 때, 상기 예측 입력 데이터는 상기 학습 데이터 수집 기간 이후인 가전기기 동작 예측 기간에 획득된 센서데이터를 기초로 생성됨-;를 포함하되,상기 학습 데이터 수집 기간에서 상기 동작 예측 시스템은 아래와 같이 동작됨:복수의 프레임 데이터를 포함하는 센서 데이터를 획득함 -이 때, 복수의 프레임 데이터 각각은 복수의 포인트데이터를 포함하며, 상기 복수의 포인트 데이터 각각은 위치 좌표 값을 포함함-;상기 가전기기의 제1 동작에 대한 동작 시간 정보를 포함하는 가전기기 데이터를 획득함;상기 가전기기 데이터에 포함되는 상기 가전기기의 제1 동작에 대한 동작 시간 정보를 이용하여 상기 복수의 프레임 데이터 중 적어도 둘 이상의 프레임 데이터를 포함하는 제1 프레임 데이터 그룹을 선택함; 및상기 제1 프레임 데이터 그룹을 기초로 상기 가전기기의 제1 동작에 대한 학습 입력 데이터를 생성하여 학습 데이터를 생성함;상기 가전기기 동작 예측 기간에서 상기 동작 예측 시스템은 아래와 같이 동작됨:복수의 프레임 데이터를 포함하는 센서 데이터를 획득함 -이 때, 복수의 프레임 데이터 각각은 복수의 포인트데이터를 포함하며, 상기 복수의 포인트 데이터 각각은 위치 좌표 값을 포함함-;상기 복수의 프레임 데이터 중 적어도 둘 이상의 프레임 데이터를 포함하는 제2 프레임 데이터 그룹을 선택함;상기 제2 프레임 데이터 그룹을 기초로 예측 입력 데이터를 생성함; 및상기 학습된 동작 예측 모델에 예측 입력 데이터를 적용하여 가전기기에 대한 동작 제어 정보를 생성함;동작 예측 시스템의 동작 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 제1 프레임 데이터 그룹을 기초로 상기 가전기기의 제1 동작에 대한 상기 학습 입력 데이터를 생성하여 상기 학습 데이터를 생성하는 단계는,상기 제1 프레임 데이터 그룹에 대한 제1 전처리를 수행하여 상기 가전기기의 제1 동작에 대한 상기 학습 입력데이터를 생성하는 단계;를 포함하며,상기 제2 프레임 데이터 그룹을 기초로 예측 입력 데이터를 생성하는 단계는,상기 제2 프레임 데이터 그룹에 대한 제2 전처리를 수행하여 상기 예측 입력 데이터를 생성하는 단계;를 포함하며,상기 제1 전처리 및 상기 제2 전처리는, 서로 동일한 전처리 알고리즘을 포함하는,동작 예측 시스템의 동작 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,공개특허 10-2025-0001131-6-상기 제2 프레임 데이터 그룹에 포함되는 프레임 데이터의 개수는 상기 제1 프레임 데이터 그룹에 포함되는 프레임 데이터의 개수와 동일한,동작 예측 시스템의 동작 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,상기 제1 프레임 데이터 그룹을 선택하는 단계는,상기 제1 동작에 대한 동작 시간 정보를 기초로 기준 시점을 특정하는 단계; 및상기 복수의 프레임 데이터 중 상기 기준 시점보다 과거인 제1 시점에 대응되는 제1 프레임 데이터 내지 상기기준 시점보다 과거인 제N 시점에 대응되는 제N 프레임 데이터를 선택하는 단계;를 포함하는,동작 예측 시스템의 동작 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14항에 있어서,상기 제1 프레임 데이터 그룹을 선택하는 단계는,상기 제1 동작에 대한 동작 시간 정보를 기초로 기준 시점을 특정하는 단계;상기 기준 시점을 기초로 특정 시간 구간을 특정하는 단계; 및상기 복수의 프레임 데이터 중 상기 특정 시간 구간에 대응되는 프레임 데이터를 선택하는 단계;를 포함하는,동작 예측 시스템의 동작 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 특정 시간 구간은, 상기 기준 시점과 상기 기준 시점으로부터 제1 기설정된 시간 간격 이전의 시점 사이의시간 구간인,동작 예측 시스템의 동작 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에 있어서,상기 특정 시간 구간은, 상기 기준 시점으로부터 제1 기설정된 시간 간격 이전의 시점과 상기 기준 시점으로부터 제2 기설정된 시간 간격 이전의 시점 사이의 시간 구간인,동작 예측 시스템의 동작 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제14항에 있어서,상기 제2 프레임 데이터 그룹을 기초로 상기 예측 입력 데이터를 생성하는 단계는,상기 가전기기가 동작될지 여부를 판단하는 단계; 및상기 가전기기가 동작될 것으로 판단되는 경우, 상기 제2 프레임 데이터 그룹을 기초로 상기 예측 입력 데이터를 생성하는 단계;를 포함하는,동작 예측 시스템의 동작 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서,공개특허 10-2025-0001131-7-상기 가전기기가 동작될지 여부를 판단하는 단계는,상기 제2 프레임 데이터 그룹에 포함된 프레임 데이터들 중 적어도 하나에 동적 객체가 나타나는지 여부에 기초하여 상기 가전기기가 동작될지 여부를 판단하는 단계;를 포함하는,동작 예측 시스템의 동작 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제14항에 있어서,상기 동작 제어 정보는, 상기 가전기기의 동작 여부에 대한 사용자의 응답을 요청하기 위한 정보를 포함하는, 동작 예측 시스템의 동작 방법."}
{"patent_id": "10-2023-0083294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제14항에 있어서,상기 학습된 동작 예측 모델에 상기 예측 입력 데이터를 적용하여 상기 가전기기에 대한 상기 동작 제어 정보를생성하는 단계는,상기 학습된 동작 예측 모델에 연속적으로 획득된 예측 입력 데이터들을 적용하여 연속된 동작 예측 정보들을획득하는 단계; 및상기 획득된 동작 예측 정보들이 기설정된 횟수 이상 제1 값으로 분류되는 경우, 상기 동작 제어 정보를 생성하는 단계;를 포함하는,동작 예측 시스템의 동작 방법."}
{"patent_id": "10-2023-0083294", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 동작 예측 모델을 학습시키기 위한 방법으로서, 복수의 프레임 데이터를 포함하 는 센서 데이터를 획득하는 단계, 가전기기의 제1 동작에 대한 동작 시간 정보를 포함하는 가전기기 데이터를 획 득하는 단계, 가전기기 데이터에 포함되는 가전기기의 제1 동작에 대한 동작 시간 정보 및 복수의 프레임 데이터 각각에 대한 시간 정보를 기초로 프레임 데이터 그룹을 선택하는 단계, 선택된 프레임 데이터 그룹을 기초로 가 전기기의 제1 동작에 대한 학습 입력 데이터를 생성하는 단계 및 적어도 학습 입력 데이터를 이용하여 동작 예측 모델을 학습시키는 단계를 포함하는 동작 예측 모델을 학습시키기 위한 방법이 제공될 수 있다."}
{"patent_id": "10-2023-0083294", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서에서 제안되는 발명은 가전기기의 동작을 예측하기 위해 미리 학습된 후 배포되는 인공지능 모델을 이 용하기 보다 사용자의 생활에 따른 학습 데이터를 직접적으로 이용하여 학습되는 사용자 맞춤형의 동작 예측 모 델 및 가전기기 동작 예측 시스템에 관한 것이다. 보다 상세하게는, 본 발명은 사용자에게 배포된 후 일정 기간 동안 학습 데이터를 수집 및 생성하고, 수집 및 생성된 학습 데이터를 이용하여 동작 예측 모델을 학습하고, 학습된 동작 예측 모델을 이용하여 가전기기에 대 한 동작 예측 정보를 획득하고, 획득된 동작 예측 정보를 이용하여 가전기기를 제어할 수 있는 시스템에 관한 것이다."}
{"patent_id": "10-2023-0083294", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사용자의 행동에 기초하여 사용자가 주변 장치를 동작 시킬지 여부를 예측하고, 예측 결과에 따라 주변 장치를 자동으로 동작시키는 시스템과 관련하여, 기존의 시스템은 사용자의 행동을 감지하여 행동의 의미를 먼저 판단 한 후, 행동의 의미에 기초하여 미리 설정된 규칙에 따라 장치를 동작 시켰다. 이를 위해 기존의 시스템은 사용자의 행동의 의미를 판단하기 위해 사용자 행동 인식 모델을 이용하였다. 사용 자 행동 인식 모델은 사용자의 움직임으로부터 그 움직임이 어떤 행동을 의미하는 것인지 예측하는 모델이다. 예를 들어, 사용자 행동 인식 모델은 사용자의 움직임 정보를 입력 받아 사용자가 현재 걷고 있는지, 앉아 있는 지, 손을 흔들었는지 등 사용자의 행동 정보를 출력하는 모델이다. 사용자 행동 인식 모델은 학습되기 위해 사용자의 움직임 데이터와 그 움직임에 대응되는 행동 데이터가 필요하 다. 이에 따라, 사용자 행동 인식 모델은 미리 학습되어 시스템에 저장되어야 한다. 구체적으로, 시스템이 사용 자에게 배포된 후 사용자 움직임 데이터는 획득될 수 있어도, 그 획득된 사용자 움직임 데이터가 어떤 의미의 행동인지 현실적으로 어노테이션(annotation)될 수 없는 바, 시스템이 사용자에게 배포된 후에는 사용자 행동 인식 모델의 학습을 위한 학습 데이터가 획득될 수 없기 때문이다.이에 따라 기존의 시스템은 사용자 구별 없이 동일한 사용자 행동 인식 모델을 이용함에 따라 사용자 별 움직임 특징을 반영할 수 없는 문제가 있었다."}
{"patent_id": "10-2023-0083294", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 과제는 시스템이 사용자에게 배포된 후 일정 기간 동안 학습 데이터를 수집 및 생성하는 것이다. 본 발명의 다른 일 과제는 수집 및 생성된 학습 데이터를 이용하여 동작 예측 모델을 학습하는 것이다. 본 발명의 다른 일 과제는 학습된 동작 예측 모델을 이용하여 가전기기에 대한 동작 예측 정보를 획득하고, 획 득된 동작 예측 정보를 이용하여 가전기기를 제어하는 것이다. 본 발명의 해결하고자 하는 과제들이 상술한 과제들로 제한되는 것은 아니며, 언급되지 아니한 과제들은 본 명"}
{"patent_id": "10-2023-0083294", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "세서 및 첨부된 도면으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0083294", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계 -이 때, 상기 센서 데이터는 복수의 프레임 데이터 및 복수의 프레임 데이터 각각에 대한 시간 정보를 포함하고, 상기 복수의 프레임 데이터 각각은 복수의 포인트 데이터를 포함하며, 상기 복수의 포인트 데이터 각각은 위치 좌표 값을 포 함함-; 제1 가전기기의 제1 동작에 대한 동작 시간 정보를 포함하는 제1 가전기기 데이터를 획득하는 단계; 상 기 제1 가전기기 데이터에 포함되는 상기 제1 가전기기의 상기 제1 동작에 대한 동작 시간 정보 및 상기 복수의 프레임 데이터 각각에 대한 시간 정보를 기초로 제1 프레임 데이터 그룹을 선택하는 단계 -이 때, 상기 제1 프 레임 데이터 그룹은 적어도 둘 이상의 프레임 데이터를 포함하되, 상기 제1 프레임 데이터 그룹에 포함되는 적 어도 둘 이상의 프레임 데이터에 대한 시간 정보는 상기 제1 동작에 대한 동작 시간 정보 보다 과거 시간에 대 한 정보임-; 상기 선택된 제1 프레임 데이터 그룹을 기초로 상기 제1 가전기기의 제1 동작에 대한 제1 학습 입 력 데이터를 생성하는 단계; 및 적어도 상기 제1 학습 입력 데이터를 이용하여 상기 제1 가전기기에 대한 제1 동작 예측 모델을 학습시키는 단계;를 포함하는, 동작 예측 모델을 학습시키기 위한 방법이 제공될 수 있다. 본 발명의 다른 실시예에 따르면, 사용자의 집에 설치된 후 학습 데이터 수집 기간이 지난 이후부터 가전기기에 대한 동작 제어 정보를 생성하는 동작 예측 시스템의 동작 방법은 학습된 동작 예측 모델을 생성하는 단계 -이 때, 상기 학습된 동작 예측 모델은 상기 학습 데이터 수집 기간에서 획득된 센서 데이터를 기초로 생성된 학습 데이터를 이용하여 학습됨-; 및 상기 학습된 동작 예측 모델에 예측 입력 데이터를 적용하여 가전기기에 대한 동작 제어 정보를 생성하는 단계 -이 때, 상기 예측 입력 데이터는 상기 학습 데이터 수집 기간 이후인 가전기 기 동작 예측 기간에 획득된 센서 데이터를 기초로 생성됨-;를 포함할 수 있다. 이 경우, 상기 학습 데이터 수집 기간에서 상기 동작 예측 시스템은 복수의 프레임 데이터를 포함하는 센서 데 이터를 획득하고 -이 때, 복수의 프레임 데이터 각각은 복수의 포인트 데이터를 포함하며, 상기 복수의 포인트 데이터 각각은 위치 좌표 값을 포함함-; 상기 가전기기의 제1 동작에 대한 동작 시간 정보를 포함하는 가전기기 데이터를 획득하고; 상기 가전기기 데이터에 포함되는 상기 가전기기의 제1 동작에 대한 동작 시간 정보를 이용 하여 상기 복수의 프레임 데이터 중 적어도 둘 이상의 프레임 데이터를 포함하는 제1 프레임 데이터 그룹을 선 택하고; 및 상기 제1 프레임 데이터 그룹을 기초로 상기 가전기기의 제1 동작에 대한 학습 입력 데이터를 생성 하여 학습 데이터를 생성할 수 있다. 이 경우, 상기 가전기기 동작 예측 기간에서 상기 동작 예측 시스템은 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하고 -이 때, 복수의 프레임 데이터 각각은 복수의 포인트 데이터를 포함하며, 상기 복수의 포인 트 데이터 각각은 위치 좌표 값을 포함함-; 상기 복수의 프레임 데이터 중 적어도 둘 이상의 프레임 데이터를 포함하는 제2 프레임 데이터 그룹을 선택하고; 상기 제2 프레임 데이터 그룹을 기초로 예측 입력 데이터를 생성 하고; 및 상기 학습된 동작 예측 모델에 예측 입력 데이터를 적용하여 가전기기에 대한 동작 제어 정보를 생성 할 수 있다."}
{"patent_id": "10-2023-0083294", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 발명의 과제의 해결 수단이 상술한 해결 수단들로 제한되는 것은 아니며, 언급하지 아니한 해결 수단들은 본 명세서 및 첨부된 도면으로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될수 있을 것이다."}
{"patent_id": "10-2023-0083294", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 사용자에게 배포된 후 일정 기간 동안 학습 데이터를 수집 및 생성하는 시스템 이 제공될 수 있다. 본 발명의 다른 실시예에 따르면, 수집 및 생성된 학습 데이터를 이용하여 동작 예측 모델을 학습시키는 시스템 이 제공될 수 있다. 본 발명의 다른 실시예에 따르면, 학습된 동작 예측 모델을 이용하여 가전기기에 대한 동작 예측 정보를 획득하 고, 획득된 동작 예측 정보를 이용하여 가전기기를 제어하는 시스템이 제공될 수 있다."}
{"patent_id": "10-2023-0083294", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들이 상술한 효과들로 제한되는 것은 아니며, 언급되지 아니한 효과들은 본 명세서 및 첨부된 도 면으로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0083294", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 기재된 실시예는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 본 발명의 사상을 명 확히 설명하기 위한 것이므로, 본 발명이 본 명세서에 기재된 실시예에 한정되는 것은 아니며, 본 발명의 범위 는 본 발명의 사상을 벗어나지 아니하는 수정예 또는 변형예를 포함하는 것으로 해석되어야 한다. 본 명세서에서 사용되는 용어는 본 발명에서의 기능을 고려하여 가능한 현재 널리 사용되고 있는 일반적인 용어 를 선택하였으나 이는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자의 의도, 판례 또는 새로운 기술 의 출현 등에 따라 달라질 수 있다. 다만, 이와 달리 특정한 용어를 임의의 의미로 정의하여 사용하는 경우에는 그 용어의 의미에 관하여 별도로 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌 그 용어가 가진 실질적인 의미와 본 명세서의 전반에 걸친 내용을 토대로 해석되어야 한다. 본 명세서에서 본 발명에 관련된 공지의 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있 다고 판단되는 경우에 이에 관한 자세한 설명은 필요에 따라 생략하기로 한다. 본 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제1, 제2 등)는 하나의 구성요소를 다른 구성요소와 구분 하기 위한 식별기호에 불과하다.이하의 실시예에서, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 이하의 실시예에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 또는 구성요소가 존재함을 의미하는 것이고, 하나 이상의 다른 특징들 또는 구성요소가 부가될 가능성을 미리 배제하는 것은 아니다. 어떤 실시예가 달리 구현 가능한 경우에 특정한 공정 순서는 설명되는 순서와 다르게 수행될 수도 있다. 예를 들어, 연속하여 설명되는 두 공정이 실질적으로 동시에 수행될 수도 있고, 설명되는 순서와 반대의 순서로 진행 될 수 있다. 본 명세서에 첨부된 도면은 본 발명을 용이하게 설명하기 위한 것으로 도면에 도시된 형상은 본 발명의 이해를 돕기 위하여 필요에 따라 과장되어 표시된 것일 수 있으므로 본 발명이 도면에 의해 한정되는 것은 아니다. 본 개시의 일 실시예에 따르면, 동작 예측 모델을 학습시키기 위한 방법은 복수의 프레임 데이터를 포함하는 센 서 데이터를 획득하는 단계 -이 때, 상기 센서 데이터는 복수의 프레임 데이터 및 복수의 프레임 데이터 각각에 대한 시간 정보를 포함하고, 상기 복수의 프레임 데이터 각각은 복수의 포인트 데이터를 포함하며, 상기 복수의 포인트 데이터 각각은 위치 좌표 값을 포함함-; 제1 가전기기의 제1 동작에 대한 동작 시간 정보를 포함하는 제 1 가전기기 데이터를 획득하는 단계; 상기 제1 가전기기 데이터에 포함되는 상기 제1 가전기기의 상기 제1 동작 에 대한 동작 시간 정보 및 상기 복수의 프레임 데이터 각각에 대한 시간 정보를 기초로 제1 프레임 데이터 그 룹을 선택하는 단계 -이 때, 상기 제1 프레임 데이터 그룹은 적어도 둘 이상의 프레임 데이터를 포함하되, 상기 제1 프레임 데이터 그룹에 포함되는 적어도 둘 이상의 프레임 데이터에 대한 시간 정보는 상기 제1 동작에 대한 동작 시간 정보 보다 과거 시간에 대한 정보임-; 상기 선택된 제1 프레임 데이터 그룹을 기초로 상기 제1 가전 기기의 제1 동작에 대한 제1 학습 입력 데이터를 생성하는 단계; 및 적어도 상기 제1 학습 입력 데이터를 이용 하여 상기 제1 가전기기에 대한 제1 동작 예측 모델을 학습시키는 단계;를 포함할 수 있다. 본 개시의 일 실시예에 따르면, 사용자의 집에 설치된 후 학습 데이터 수집 기간이 지난 이후부터 가전기기에 대한 동작 제어 정보를 생성하는 동작 예측 시스템의 동작 방법은 학습된 동작 예측 모델을 생성하는 단계 -이 때, 상기 학습된 동작 예측 모델은 상기 학습 데이터 수집 기간에서 획득된 센서 데이터를 기초로 생성된 학습 데이터를 이용하여 학습됨-; 및 상기 학습된 동작 예측 모델에 예측 입력 데이터를 적용하여 가전기기에 대한 동작 제어 정보를 생성하는 단계 -이 때, 상기 예측 입력 데이터는 상기 학습 데이터 수집 기간 이후인 가전기 기 동작 예측 기간에 획득된 센서 데이터를 기초로 생성됨-;를 포함할 수 있다. 이 경우, 상기 학습 데이터 수집 기간에서 상기 동작 예측 시스템은 복수의 프레임 데이터를 포함하는 센서 데 이터를 획득하고 -이 때, 복수의 프레임 데이터 각각은 복수의 포인트 데이터를 포함하며, 상기 복수의 포인트 데이터 각각은 위치 좌표 값을 포함함-; 상기 가전기기의 제1 동작에 대한 동작 시간 정보를 포함하는 가전기기 데이터를 획득하고; 상기 가전기기 데이터에 포함되는 상기 가전기기의 제1 동작에 대한 동작 시간 정보를 이용 하여 상기 복수의 프레임 데이터 중 적어도 둘 이상의 프레임 데이터를 포함하는 제1 프레임 데이터 그룹을 선 택하고; 및 상기 제1 프레임 데이터 그룹을 기초로 상기 가전기기의 제1 동작에 대한 학습 입력 데이터를 생성 하여 학습 데이터를 생성할 수 있다. 이 경우, 상기 가전기기 동작 예측 기간에서 상기 동작 예측 시스템은 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하고 -이 때, 복수의 프레임 데이터 각각은 복수의 포인트 데이터를 포함하며, 상기 복수의 포인 트 데이터 각각은 위치 좌표 값을 포함함-; 상기 복수의 프레임 데이터 중 적어도 둘 이상의 프레임 데이터를 포함하는 제2 프레임 데이터 그룹을 선택하고; 상기 제2 프레임 데이터 그룹을 기초로 예측 입력 데이터를 생성 하고; 및 상기 학습된 동작 예측 모델에 예측 입력 데이터를 적용하여 가전기기에 대한 동작 제어 정보를 생성 할 수 있다. 이하에서는 본 개시의 가전기기 동작 예측 시스템을 설명한다. 도 1은 본 개시의 일 실시예에 따른 가전기기 동작 예측 시스템을 나타낸 도면이다. 본 개시의 일 실시예에 따른 가전기기 동작 예측 시스템은 적어도 하나의 센서로부터 획득된 센서 데 이터를 이용하여 가전기기의 동작을 예측하는 시스템일 수 있다. 본 개시의 일 실시예에 따른 가전기기 동작 예측 시스템은 적어도 하나의 센서로부터 획득된 센서 데 이터를 학습된 동작 예측 모델에 적용하여 가전기기의 동작을 예측하는 시스템일 수 있다. 본 개시의 일 실시예에 따른 가전기기 동작 예측 시스템은 적어도 하나의 센서로부터 획득된 센서 데 이터를 이용하여 가전기기의 동작을 예측하기 위한 동작 예측 모델을 학습시키기 위한 학습 데이터를 생성하고, 생성된 학습 데이터를 이용하여 동작 예측 모델을 학습시키기 위한 구성을 더 포함하는 시스템일 수 있다. 이는 본 개시의 일 실시예에 따른 가전기기 동작 예측 시스템이 미리 학습된 후 배포되는 인공지능 모델을 이용하기 보다 사용자의 생활에 따른 학습 데이터를 직접적으로 수집 및 생성하여 사용자 맞춤형의 시스템을 제 공하는 것을 목적으로 하기 때문일 수 있으나, 이에 한정되지 않는다. 즉, 본 개시의 일 실시예에 따른 가전기기 동작 예측 시스템은 사용자에게 배포된 후 일정 기간 동안 학습 데이터를 수집 및 생성하고, 수집 및 생성된 학습 데이터를 이용하여 동작 예측 모델을 학습하고, 학습된 동작 예측 모델을 이용하여 가전기기에 대한 동작 예측 정보를 획득하고, 획득된 동작 예측 정보를 이용하여 가전기 기를 제어할 수 있는 시스템을 의미할 수 있으나, 이에 한정되지 않는다. 본 개시의 일 실시예에 따른 가전기기 동작 예측 시스템은 상술한 동작들을 구현하기 위한 다양한 구성을 포함하고 있으며, 이에 대하여는 아래에서 보다 구체적으로 설명하기로 한다. 본 개시의 일 실시예에 따른 가전기기 동작 예측 시스템은 적어도 하나의 센서로부터 획득되는 센서 데이터 및 적어도 하나의 가전기기로부터 획득되는 가전기기 데이터를 이용하며, 적어도 하나의 가전기기의 동작을 제어하기 위한 정보를 출력할 수 있으므로, 이에 대하여 구체적으로 기술한 후 본 개시 의 일 실시예에 따른 가전기기 동작 예측 시스템을 구현하기 위한 다양한 구성들에 대하여 설명하기로 한 다. 한편, 본 개시에서 가전기기로 기재된 구성은 설명의 편의를 위해 가전기기로 기재된 것이며, 본 개시에서 가전기기로 기재된 구성은 사용자와 상호작용 가능한 다양한 종류의 전자기기 및/또는 전기기기에 대해서도 적 용될 수 있다. 다만, 본 명세서의 이하에서는 설명의 편의를 위해서 사용자와 상호작용 가능한 다양한 종류의 전자기기 및/또는 전자기기에 대해서 가전기기라는 용어를 이용하여 기재하기로 하며, 특별한 사정이 없는 한 이하에서 가전기기로 기재된 구성은 사용자와 상호작용 가능한 다양한 전자기기 및 또는 전자기기로 이해될 수 있다. 이 때, 사용자와 상호작용 가능한 다양한 종류의 전자기기 및/또는 전기기기는 사무공간, 교육공간 및/또는 공 장 등 다양한 인프라에 위치하는 사용자와 상호작용 가능한 장치를 포함할 수 있다. 특히, 사용자와 상호 작용 가능한 다양한 종류의 전자기기 및/또는 전기기기는 소규모의 인원이 거주 및/또는 점유하거나 생활하는 집, 사무공간, 교육공간 또는 공장 등 다양한 공간에 위치하는 사용자와 상호작용 가능한 장치로 이해될 수 있다. 예를 들어, 사무공간에 위치하는 장치는 프린터, 스캐너, 팩스 머신, 복사기, 컴퓨터, 노트북, 모니터, 조명 장 치, 공기 조화기, 공기 청정기, 전화기, 네트워크 스위치, 모뎀, 라우터, 빔 프로젝터, 에어컨, 히터, 커피 머 신 등을 포함할 수 있으며, 이에 한정되지 않는다. 예를 들어, 교육공간에 위치하는 장치는 전자 칠판, 빔 프로젝터, 터치스크린, 웹캠, 마이크, 학습용 콘솔, 전 자책, 사물 인터넷 기기, 모션 감지 장치, 음성 인식 장치, 컴퓨터, 노트북, 태블릿, 모니터, 조명 장치, 공기 조화기, 공기 청정기, 에어컨, 히터 등을 포함할 수 있으며, 이에 한정되지 않는다. 예를 들어, 공장에 위치하는 장치는 컨베이어 벨트, 로봇 암, 적재기, 운반 장치, 프레스 기계, 절삭 기계, 연 마 기계, 발전기, 전기 패널, 전기 스위치, 전기 모터, 조명 장치, 공기 조화기, 출입 제어 시스템, 인터폰 등 을 포함할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 센서는 라이다 장치를 포함할 수 있다. 본 명세서에서 기술하는 라이다 장치는 레이저를 이용하여 거리를 측정하는 다양한 장치를 포함하는 개념으로 이해될 수 있다. 일 예로, 라이다 장치는 라이다(LiDAR - Light Detection And Ranging) 및/또는 TOF 센서 (Time-of-Flight sensor) 등을 포함하는 개념으로 이해될 수 있으나, 이에 한정되지 않는다.일 실시예에 따른 라이다 장치는 레이저를 이용하여 대상체와의 거리 및 대상체의 위치를 탐지하기 위한 장치일 수 있다. 일 예로, 라이다 장치는 레이저를 출력할 수 있고, 출력된 레이저가 대상체에서 반사된 경우 반사된 레이저를 수신하여 대상체와 라이다 장치의 거리 및 대상체의 위치를 측정할 수 있다. 이 때, 대상체는 적어도 하나의 물체를 의미할 수 있다. 이에 한정되지 않으며, 대상체는 라이다 장치로부터 출 력된 레이저의 적어도 일부를 반사하기 위한 물체의 일 부분을 의미할 수도 있다. 일 실시예에 따른 센서는 다양한 방법을 이용하여 대상체와의 거리를 측정하는 라이다 장치를 포함할 수 있다. 일 예로, 센서는 레이저가 출력된 후 감지되기까지 레이저의 비행 시간(Time Of Flight, TOF)을 이용하는 라이다 장치, 삼각 측량법(Triangulation method)을 이용하는 라이다 장치, 간섭계 방법(Interferometry method)을 이용하는 라이다 장치 및/또는 위상 변화 측정법(Phase shift measurement)을 이용하는 라이다 장치 등을 포함할 수 있다. 이에 한정되지 않으며, 센서는 통상적으로 라이다 장치로 이해되는 다양한 라이다 장치를 포함할 수 있다. 일 실시예에 따른 센서는 다양한 구조의 라이다 장치를 포함할 수 있다. 일 예로, 센서는 레이저 출력 유닛 및 레이저 디텍팅 유닛을 회전시키는 Spinning type 라이다 장치, 레이 저를 반사하기 위한 적어도 하나의 광학 수단을 구동시키는 Mechanical type 라이다 장치 및/또는 기계적 회전 구성이 없는 Solid-state type 라이다 장치 등을 포함할 수 있다. 이에 한정되지 않으며, 센서는 통상적으 로 라이다 장치로 이해되는 다양한 라이다 장치를 포함할 수 있다. 일 실시예에 따른 센서는 센서 데이터를 생성할 수 있다. 도 2는 일 실시예에 따른 센서 데이터를 나타낸 도면이다. 이하에서는 도 2를 참조하여 일 실시예에 따른 센서 데이터를 설명한다. 일 실시예에 따른 센서 데이터는 적어도 하나의 포인트 데이터를 포함할 수 있다. 일 실시예에 따른 센서 데이터는 적어도 하나의 포인트 데이터를 포함하는 라이다 데이터를 포함할 수 있다. 일 실시예에 따른 센서 데이터는 적어도 하나의 포인트 데이터를 포함하는 포인트 클라우드(Point Cloud) 데이터를 포함할 수 있다. 이 경우, 적어도 하나의 포인트 데이터는 3차원 위치 좌표(X,Y,Z)를 포함할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 센서 데이터는 적어도 하나의 포인트 데이터를 포함하는 포인트 클라우드 데이터를 포함할 수 있다. 이 경우, 적어도 하나의 포인트 데이터는 3차원 위치 좌표(X,Y,Z) 및 인텐시티 값(i)을 포함할 수도 있으며, 이에 한정되지 않는다. 일 실시예에 따른 센서 데이터는 적어도 하나의 포인트 데이터를 포함하는 뎁스 맵(Depth map) 데이터 를 포함할 수 있다. 이 경우, 적어도 하나의 포인트 데이터는 2차원 위치 좌표(X,Y) 및 뎁스 값(d)을 포함 할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 센서 데이터는 적어도 하나의 포인트 데이터를 포함하는 인텐시티 맵(Intensity map) 데 이터를 포함할 수 있다. 이 경우, 적어도 하나의 포인트 데이터는 2차원 위치 좌표(X,Y) 및 인텐시티 값 (i)을 포함할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 센서 데이터는 적어도 하나의 포인트 데이터를 포함하는 라이트 캡쳐 맵(Light capture map) 데이터를 포함할 수 있다. 이 경우, 적어도 하나의 포인트 데이터는 2차원 위치 좌표(X,Y) 및 라이트 캡쳐 값(v)을 포함할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 센서 데이터는 적어도 하나의 포인트 데이터를 포함하는 디텍팅 맵(Detecting map) 데이 터를 포함할 수 있다. 이 경우, 적어도 하나의 포인트 데이터는 2차원 위치 좌표(X,Y), 뎁스 값(d), 인텐 시티 값(i) 및 라이트 캡쳐 값(v)을 포함할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 센서 데이터는 상술한 예시들 외에도 라이다 데이터로 인식되는 다양한 데이터들을 포함 할 수 있다. 일 실시예에 따른 센서 데이터는 적어도 하나의 프레임 데이터(Frame data)를 포함할 수 있다. 일 실시예에 따른 프레임 데이터는 하나의 시점에서 획득된 것으로 간주되는 복수의 포인트 데이터 그룹을 의미 할 수 있다. 일 예로, 프레임 데이터는 모든 2차원 위치 좌표에 대응되는 포인트 데이터들이 획득되는 한 주기 동안 획득된 포인터 데이터들의 그룹일 수 있다. 이에 한정되지 않으며, 프레임 데이터는 한 주기보다 짧은 시 간 간격 동안 획득된 포인트 데이터들의 그룹일 수도 있다. 일 실시예에 따른 프레임 데이터는 하나의 장면을 표현하는 복수의 포인트 데이터 그룹을 의미할 수 있다. 일 예로, 프레임 데이터는 가능한 모든 2차원 위치 좌표에 대응되는 포인트 데이터들의 그룹일 수 있다. 이에 한정 되지 않으며, 프레임 데이터는 가능한 일부 2차원 위치 좌표에 대응되는 포인트 데이터들의 그룹일 수 있다. 이에 한정되지 않으며, 일 실시예에 따른 센서 데이터는 상술한 예시들 외에도 통상적으로 프레임 데이터 로 이해되는 다양한 데이터들을 포함할 수 있다. 일 실시예에 따른 센서 데이터는 적어도 하나의 속성 데이터를 포함할 수 있다. 일 실시예에 따른 속성 데이터는 일 실시예에 따른 하나의 프레임 데이터에 포함되는 서브 포인트 데이터 셋에 대한 클래스 정보, 중심 위치 정보, 사이즈 정보, 형상 정보, 식별 정보 등 서브 포인트 데이터 셋의 속성과 관 련된 데이터를 의미할 수 있다. 일 실시예에 따른 속성 데이터는 일 실시예에 따른 복수개의 프레임 데이터에 포함되는 복수개의 서브 포인트 데이터 셋에 대한 이동 정보, 식별 정보, 궤적 정보 등 복수개의 프레임 데이터에서 동일한 물체를 표현하는 것으로 간주되는 복수개의 서브 포인트 데이터 셋의 속성과 관련된 데이터를 의미할 수 있다. 이에 한정되지 않으며, 일 실시예에 따른 센서 데이터는 상술한 예시들 이외에도 통상적으로 속성 데이터 로 이해되는 다양한 데이터들을 포함할 수 있다. 한편, 이하에서 프레임 데이터와 속성 데이터를 특별히 구별하지 않는 한 프레임 데이터로 기재한 구성은 속성 데이터로도 구성될 수 있다. 일 실시예에 따른 센서 데이터는 시간에 따라 연속된 프레임 데이터를 포함할 수 있다. 일 실시예에 따른 시간에 따라 연속된 프레임 데이터는 시간 순으로 프레임 데이터들이 획득된 것을 의미할 수 있다. 일 실시예에 따른 센서는 기설정된 프레임 레이트에 따라 프레임 데이터들을 생성할 수 있다. 일 예로, 센 서는 1초에 10개 내지 30개의 프레임 데이터들을 생성할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 프레임 데이터는 대응되는 시점 정보를 포함할 수 있다. 이 때, 일 실시예에 따른 프레임 데 이터가 대응되는 시점 정보를 포함한다는 의미는 일 실시예에 따른 프레임 데이터에 특정 시점 정보가 매칭되는 것을 의미할 수 있으나, 이에 한정되지 않는다. 일 예로, 일 실시예에 따른 프레임 데이터는 프레임 데이터가 생성되기 시작한 시점에 대응되는 시점 정보를 포 함할 수 있다. 일 예로, 일 실시예에 따른 프레임 데이터는 프레임 데이터가 생성 완료된 시점에 대응되는 시점 정보를 포함할 수 있다. 일 예로, 일 실시예에 따른 프레임 데이터는 프레임 데이터가 생성되기 시작한 시점 및 /또는 생성 완료된 시점을 기초로 획득되는 대표 시점에 대응되는 시점 정보를 포함할 수 있다. 일 예로, 일 실 시예에 따른 프레임 데이터는 프레임 데이터에 포함되는 포인트 데이터가 임계치 이상으로 획득된 시점에 대응 되는 시점 정보를 포함할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 센서 데이터는 시간에 따라 연속된 속성 데이터를 포함할 수 있다. 일 실시예에 따른 속성 데이터는 대응되는 시점 정보를 포함할 수 있다. 이 때, 일 실시예에 따른 속성 데이터 가 대응되는 시점 정보를 포함한다는 의미는 일 실시예에 따른 속성 데이터에 특정 시점 정보가 매칭되는 것을 의미할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 속성 데이터에 대응되는 시점 정보는 속성 데이터 생성에 이용된 프레임 데이터에 대응되는 시점 정보와 동일할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 속성 데이터가 복수의 프레임 데이터를 이용하여 획득되는 경우, 속성 데이터에 대응되는 시 점 정보는 복수의 프레임 데이터에 대응되는 시점들 중 시작 시점, 끝 시점 또는 중간 시점 중 적어도 하나일 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 센서 데이터는 센서의 설치 위치 정보를 포함할 수 있다. 일 실시예에 따른 설치 위치 정보는 센서가 설치된 사용자 생활 영역에 대한 정보를 포함할 수 있다. 예를 들어, 설치 위치 정보는 거실, 안방, 부엌 및/또는 창고 등의 정보를 포함할 수 있다. 일 실시예에 따른 설치 위치 정보는 인접한 가전기기에 대한 정보를 포함할 수 있다. 예를 들어, 설치 위치 정 보는 TV 구역, 냉장고 구역 및/또는 세탁기 구역 등의 정보를 포함할 수 있다. 일 실시예에 따른 설치 위치 정보는 센서의 시야 범위(Field Of View, FOV) 내에 배치된 가전기기에 대한 정보를 포함할 수 있다. 예를 들어, 설치 위치 정보는 TV 감지 구역, 냉장고 감지 구역 및/또는 세탁기 감지 구 역 등의 정보를 포함할 수 있다. 일 실시예에 따른 설치 위치 정보는 상술한 예에 한정되지 않으며, 설치 위치 정보는 센서가 설치된 위치를 특 정할 수 있는 다양한 정보를 포함할 수 있다. 일 실시예에 따른 센서 데이터는 센서에 대한 센서 식별 정보를 포함할 수 있다. 일 실시예에 따른 센서 식별 정보는 센서를 다른 센서와 구별하기 위한 정보를 포함할 수 있다. 일 실시예에 따른 센서 식별 정보는 센서의 하드웨어 버전에 대한 정보를 포함할 수 있다. 일 실시예에 따른 센서 식별 정보는 센서의 펌웨어 버전에 대한 정보를 포함할 수 있다. 일 실시예에 따른 센서 식별 정보는 상술한 예에 한정되지 않으며, 센서 식별 정보는 해당하는 센서를 특정하기 위한 정보 및/또는 센서의 성능을 나타내기 위한 정보 등을 포함할 수 있다. 일 실시예에 따른 센서는 사용자의 생활 공간에 배치될 수 있다. 일 예로, 센서는 시야 범위가 사용 자의 행동 공간과 적어도 일부 겹치도록 설치될 수 있다. 이 경우, 센서가 생성한 프레임 데이터에는 사용 자가 나타날 수 있다. 일 실시예에 따른 센서는 시야 범위 내에 가전기기가 위치하도록 설치될 수 있다. 일 실시예에 따른 센서는 복수 개 배치될 수 있다. 일 예로, 복수의 센서는 각각의 시야 범위가 서로 겹치 게 설치될 수 있다. 일 예로, 복수의 센서는 각각의 시야 범위가 서로 겹치지 않도록 설치될 수 있다. 일 예로, 복수의 센서는 복수의 센서 중 일부의 센서만 시야 범위가 서로 겹치게 설치될 수 있다. 일 실시예에 따라 센서가 라이다 장치를 포함하는 경우, 복수의 센서는 각각이 생성한 프레임 데이터들을 정합하여 하나의 프레임 데이터를 생성할 수도 있다. 일 예로, 복수의 센서 중 적어도 하나의 센서는 복수의 센 서 각각이 설치된 위치 및 각도를 고려하여 프레임 데이터들의 글로벌 좌표를 판단하고, 이에 기초하여 프레임 데이터들의 좌표를 글로벌 좌표계 상 좌표로 변환하고, 글로벌 좌표로 변환된 프레임 데이터들을 정합하여 글로 벌 좌표계 상의 하나의 프레임 데이터를 생성할 수 있다. 이를 위해서 복수의 센서는 센서들 간의 싱크가 맞으 며, 서로 간의 통신이 원활하고, 일정 수준의 컴퓨팅 파워가 필요할 수 있다. 일 실시예에 따른 센서는 센싱 모듈, 메모리, 통신 모듈 및/또는 프로세서를 포함할 수 있다. 일 실시예에 따른 센싱 모듈은 적어도 하나의 광을 출력하거나 적어도 하나의 광을 감지하기 위해 제공될 수 있 다. 일 실시예에 따른 센싱 모듈은 적어도 하나의 광을 출력하기 위한 레이저 출력 유닛 및/또는 적어도 하나의 광 을 감지하기 위한 디텍팅 유닛을 포함할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 프로세서는 센싱 모듈로부터 획득된 적어도 하나의 신호에 기초하여 적어도 하나의 센서 데이 터를 생성하기 위해 제공될 수 있다. 일 실시예에 따른 프로세서는 센싱 모듈로부터 획득된 적어도 하나의 신호에 기초하여 적어도 하나의 포인트 데 이터를 생성할 수 있다. 일 실시예에 따른 프로세서는 센싱 모듈로부터 획득된 적어도 하나의 신호에 기초하여 적어도 하나의 프레임 데 이터를 생성할 수 있다.일 실시예에 따른 프로세서는 센싱 모듈로부터 획득된 적어도 하나의 신호에 기초하여 적어도 하나의 속성 데이 터를 생성할 수 있다. 이에 한정되지 않으며, 일 실시예에 따른 프로세서는 상술한 예시들 이외에도 통상적으로 센서 데이터로 이해되 는 다양한 종류의 데이터들을 생성할 수 있다. 일 실시예에 따른 프로세서는 생성된 적어도 하나의 센서 데이터를 처리하기 위해 제공될 수 있다. 일 실시예에 따른 프로세서는 적어도 하나의 포인트 데이터를 처리하여 적어도 하나의 프레임 데이터를 획득할 수 있다. 일 실시예에 따른 프로세서는 적어도 하나의 포인트 데이터를 처리하여 적어도 하나의 속성 데이터를 획득할 수 있다. 일 실시예에 따른 프로세서는 적어도 하나의 프레임 데이터를 처리하여 적어도 하나의 속성 데이터를 획득할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 메모리는 일 실시예에 따른 센서 데이터를 저장할 수 있다. 일 실시예에 따른 메모리는 일 실시예에 따른 프로세서가 생성한 데이터를 저장할 수 있다. 일 실시예에 따른 메모리는 일 실시예에 따른 프로세서가 처리한 데이터를 저장할 수 있으며, 이에 한정되지 않 는다. 포인트 데이터, 프레임 데이터 및 속성 데이터와 관련된 내용은 상술한 바 있으므로 중복 설명은 생략한다. 일 실시예에 따른 프로세서는 통신 모듈을 이용하여 외부 장치와 유선 및/또는 무선으로 데이터 통신을 수행할 수 있다. 일 예로, 프로세서는 통신 모듈을 이용하여 외부 장치와 양방향(bi-directional) 또는 단방향 통신을 수행할 수 있으며, 이에 한정되지 않는다. 한편, 프로세서는 중앙 처리 장치(Central Processing Unit, CPU), 그래픽 처리 장치(Graphics Processing Unit, GPU), 디지털 신호 처리 장치(Digital Signal Processor, DSP), 상태 기계(state machine), 주문형 반도 체(Application Specific Integrated Circuit, ASIC), 무선 주파수 집적 회로(Radio-Frequency Integrated Circuit, RFIC) 및 이들의 조합 등으로 구성될 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 센서는 상술한 라이다 장치 외에 다른 센서들로 제공될 수 있다. 일 실시예에 따른 센서는 뎁스 카메라(Depth Camera), RGB 카메라, 흑백 카메라 및/또는 IR 카메라 등을 포함할 수 있다. 이에 한정되지 않으며, 일 실시예에 따른 센서는 다양한 종류의 센서를 포함할 수 있다. 일 실시예에 따른 센서가 상술한 라이다 장치 외에 다른 센서로 제공되는 경우에도 상술한 센서 데이터와 관련된 내용들이 적용될 수 있다. 일 실시예에 따른 센서가 뎁스 카메라를 포함하는 경우, 일 실시예에 따른 센서 데이터는 적어도 하나의 포인트 데이터를 포함하는 뎁스 이미지를 포함할 수 있다. 이 때, 적어도 하나의 포인트 데이터는 2차원 위치 좌표(X,Y) 및 뎁스 값(d)을 포함할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 센서가 RGB 카메라를 포함하는 경우, 일 실시예에 따른 센서 데이터는 적어도 하나의 포 인트 데이터를 포함하는 RGB 이미지를 포함할 수 있다. 이 때, 적어도 하나의 포인트 데이터는 2차원 위치 좌표 (X,Y) 및 색상 값(R,G,B)을 포함할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 센서가 흑백 카메라를 포함하는 경우, 일 실시예에 따른 센서 데이터는 적어도 하나의 포인트 데이터를 포함하는 흑백 이미지를 포함할 수 있다. 이 때, 적어도 하나의 포인트 데이터는 2차원 위치 좌표(X,Y) 및 명도 값(V)을 포함할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 센서가 IR 카메라를 포함하는 경우, 일 실시예에 따른 센서 데이터는 적어도 하나의 포 인트 데이터를 포함하는 IR 이미지를 포함할 수 있다. 이 때, 적어도 하나의 포인트 데이터는 2차원 위치 좌표 (X,Y) 및 복사열 값을 포함할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 센서가 상술한 라이다 장치 이외에 다른 센서로 제공되는 경우에도 상술한 프레임 데이 터 및 속성 데이터와 관련된 내용들이 적용될 수 있다. 일 실시예에 따른 가전기기는 사용자가 일상 생활에서 이용하는 다양한 종류의 가전 제품을 의미할 수 있 다. 예를 들어, 가전기기는 TV, 프로젝터, 셋톱박스, 스피커, 조명 장치, 냉장고, 밥솥, 식기세척기, 전자 레인지, 오븐, 전기포트, 커피머신, 에어컨, 가습기, 제습기, 난방기기, 선풍기, 서큘레이터, 세탁기, 청소기, 공기청정기, 건조기, 의류관리기, 안마기, 전동 커튼 레일 등을 포함할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른, 가전기기는 다양한 생활 보조 장치를 포함할 수도 있다. 일 실시예에 따른, 가전기기는 반려동물과 상호작용하는 장치를 포함할 수도 있다. 예를 들어, 가전기기 는 배식 장치, 급수 장치, 놀이 장치, 배변 장치 등을 포함할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 가전기기는 사용자의 동작 제어 명령에 기초하여 동작할 할 수 있다. 예를 들어, 가전기 기는 사용자의 턴온 명령에 따라 구동을 개시할 수 있고, 사용자의 턴오프 명령에 따라 구동을 중단할 수 있다. 일 예로, 가전기기가 TV를 포함하는 경우, 가전기기는 사용자의 화면 켜짐 명령에 따라 화면을 표시할 수 있고, 채널 변경 명령에 따라 설정된 채널을 변경할 수도 있으며, 이에 한정되지 않는다. 일 실시예에 따른 가전기기는 사용자의 제어 명령을 직접적 및/또는 간접적으로 수신할 수 있다. 이에 한 정되지 않고, 가전기기는 통신 장치를 통해 사용자의 제어 명령을 수신할 수도 있다. 일 실시예에 따른 가전기기는 사용자의 생활 공간에 배치될 수 있다. 이에 따라, 가전기기는 사용자 와 상호작용할 수 있다. 일 실시예에 따른 가전기기가 복수의 부분으로 구별될 수 있는 경우, 일부는 사용 자의 생활 공간에 배치되고, 다른 일부는 사용자의 생활 공간 외부에 배치될 수도 있다. 예를 들어, 에어컨은 사용자의 생활 공간에 배치되고, 실외기는 사용자의 생활 공간 외부에 배치될 수 있다. 일 실시예에 따른 가전기기는 센서의 시야 범위 내에 위치할 수 있다. 이 경우, 센서가 생성한 프레임 데이터에는 가전기기가 나타날 수 있다. 일 실시예에 따른 가전기기는 가전기기 데이터를 생성할 수 있다. 일 실시예에 따른 가전기기 데이터는 가전기기의 상태 및 가전기기의 동작과 관련된 정보를 포함할 수 있 다. 일 실시예에 따른 가전기기 데이터는 가전기기에 대한 가전기기 식별 정보를 포함할 수 있다. 일 실시예에 따른 가전기기 식별 정보는 가전기기를 다른 가전기기와 구별하기 위한 정보를 포함할 수 있다. 일 예로, 가전기기 식별 정보는 TV, 냉장고, 세탁기 등 가전기기의 종류에 대한 정보를 포함할 수 있 다. 일 예로, 가전기기 식별 정보는 제1 TV, 제2 TV 등 동일한 종류의 가전기기를 서로 구별하기 위한 정보를 포함할 수도 있다. 일 실시예에 따른 가전기기 식별 정보는 가전기기의 하드웨어 버전 및/또는 펌웨어 버전에 대한 정보를 포 함할 수도 있다. 일 실시예에 따른 가전기기 데이터는 가전기기의 동작과 관련한 동작 시점 정보를 포함할 수 있다. 일 실시예에 따른 동작 시점 정보는 가전기기와 사용자가 상호작용하여 가전기기가 동작한 시점과 관 련된 정보일 수 있다. 일 예로, 동작 시점 정보는 가전기기가 사용자와 상호작용을 시작한 시점일 수 있다. 일 예로, 동작 시점 정보는 가전기기가 사용자와 상호작용하여 워밍업(warming-up) 된 시점일 수 있 다. 일 예로, 동작 시점 정보는 가전기기가 사용자와 상호작용에 따라 실제 동작을 시작한 시점일 수 있다. 일 예로, 동작 시점 정보는 가전기기가 사용자와 상호작용에 따라 실제 동작을 중단한 시점일 수 있 다. 일 예로, 동작 시점 정보는 가전기기가 사용자와 상호작용을 마친 시점일 수 있다. 일 예로, 동작 시 점 정보는 가전기기가 사용자와 상호작용 한 시간 구간일 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 가전기기 데이터는 가전기기의 동작과 관련한 동작 유형 정보를 포함할 수 있다. 일 실시예에 따른 동작 유형 정보는 가전기기와 사용자가 상호작용하여 가전기기가 동작한 구체적인 동작 내용과 관련된 정보일 수 있다. 일 예로, 동작 유형 정보는 가전기기가 사용자와 상호작용하여 턴온 된 정보일 수 있다. 일 예로, 동작 유형 정보는 가전기기가 사용자와 상호작용하여 턴오프 된 정보일 수 있다. 일 예로, 동작 유형 정보는 가전기기가 사용자와 상호작용하여 워밍업 된 정보일 수 있다. 이에 한정되지 않으며, 동작 유형 정보는 가전기기가 사용자와 상호작용하여 수행한 구체적인 동작 정보일 수 있 다. 구체적인 동작 정보는 가전기기의 목적에 따라 다양한 동작 유형을 반영할 수 있다. 일 실시예에 따른 가전기기 데이터는 가전기기의 설치 위치 정보를 포함할 수 있다. 일 실시예에 따른 설 치 위치 정보는 가전기기가 설치된 사용자 생활 영역에 대한 정보를 포함할 수 있다. 일 예로, 설치 위치 정보는 거실, 안방, 부엌 및/또는 창고 등의 정보를 포함할 수 있다. 일 실시예에 따른 가전기기는 가전기기 데이터를 외부로 전송할 수 있다. 일 예로, 가전기기는 가전기기 데이터를 다른 가전기기, 서버 장치, 센서 등에 전송할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 가전기기는 복수 개 배치될 수 있다. 일 예로, 복수의 가전기기는 동일한 사용자 생활 공간에 배치될 수 있다. 일 예로, 복수의 가전기기 중 일부는 사용자의 제1 생활 공간에 배치되고, 다른 일부는 사용자의 제2 생활 공간에 배치될 수도 있다. 이하에서는 동작 예측 시스템에 포함된 각 모듈을 구체적으로 설명한다. 다시 도 1을 참조하면, 일 실시예에 따른 동작 예측 시스템은 데이터 송수신 모듈, 학습 데이터 생성 모듈, 동작 예측 모델 학습 모듈, 동작 예측 모듈 및/또는 학습 데이터 관리 모듈을 포함 할 수 있다. 일 실시예에 따른 데이터 송수신 모듈은 유선 통신 모듈로 구성될 수 있다. 일 예로, 데이터 송수신 모듈 은 이더넷 모듈, 시리얼 통신 모듈, USB(Universal Serial Bus) 통신 모듈, PLC(전력선 통신) 모듈, CAN(Controller Area Network) 모듈 및/또는 RS-485 모듈로 구성될 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 데이터 송수신 모듈은 무선 통신 모듈로 구성될 수 있다. 일 예로, 데이터 송수신 모듈 은 Wi-Fi 모듈, Bluetooth 모듈, Zigbee 모듈, LTE(Long-Term Evolution) 모듈, NB-IoT(Narrowband Internet of Things) 모듈 및/또는 LoRa(Long range) 모듈로 구성될 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 데이터 송수신 모듈은 센서로부터 센서 데이터를 수신할 수 있다. 일 실시예 에 따른 센서 데이터에 대하여는 상술한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 일 실시예에 따른 송수신 모듈은 센서로부터 후술할 학습 데이터 생성을 위해 필요한 정보, 생성된 학습 데이터를 관리하기 위해 필요한 정보 및/또는 후술할 학습된 동작 예측 모델을 구동하기 위해 필요한 정보 등 다양한 종류의 데이터를 수신할 수 있다. 일 실시예에 따른 데이터 송수신 모듈은 센서로 후술할 센서 데이터 요청 정보를 전송할 수 있다. 이 에 따라, 데이터 송수신 모듈은 센서로부터 센서 데이터를 수신할 수 있으며, 이에 한정되지 않 는다. 일 실시예에 따른 데이터 송수신 모듈은 가진기기로부터 가전기기 데이터를 수신할 수 있다. 일 실시예에 따른 가전기기 데이터에 대해서는 상술한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하 기로 한다. 일 실시예에 따른 데이터 송수신 모듈은 가전기기로 후술할 동작 제어 정보를 전송할 수 있다. 일 실시예에 따른 동작 제어 정보는 가전기기가 수행해야 할 동작 유형에 대한 정보를 포함할 수 있 다. 일 예로, 동작 제어 정보는 가전기기의 켜짐 동작을 위한 정보를 포함할 수 있다. 일 예로, 동작 제어 정보는 가전기기의 꺼짐 동작을 위한 정보를 포함할 수 있다. 일 예로, 동작 제어 정보는 가전기기의 워밍업을 위한 정보를 포함할 수 있다. 이에 한정되지 않고, 동작 제어 정보는 가전기기의 구체적인 동작 유형 별 정보를 포함할 수 있다. 일 실시예에 따른 데이터 송수신 모듈은 센서로부터 센서에 설정된 시점과 관련된 정보를 수신 할 수 있다. 일 실시예에 따른 데이터 송수신 모듈은 가전기기로부터 가전기기에 설정된 시점과 관련된 정보를 수신할 수 있다. 일 실시예에 따른 데이터 송수신 모듈은 센서에 설정된 시점과 가전기기에 설정된 시점을 비교 하여 센서 및/또는 가전기기로 시점 조정과 관련된 정보를 전송할 수 있다. 일 예로, 센서에 설정된 시점이 가전기기에 설정된 시점보다 빠른 경우, 데이터 송수신 모듈은 센서로 시점을 늦추 기 위한 정보를 전송할 수 있다. 일 예로, 센서에 설정된 시점이 가전기기에 설정된 시점보다 빠른 경우, 데이터 송수신 모듈은 가전기기로 시점을 당기기 위한 정보를 전송할 수 있다. 이에 따라, 데 이터 송수신 모듈은 센서 데이터에 포함된 시점과 관련된 정보와 가전기기 데이터에 포함된 시 점과 관련된 정보 사이의 싱크가 맞도록 할 수 있다. 이에 한정되지 않고, 데이터 송수신 모듈은 센서에 설정된 시점과 가전기기에 설정된 시점의 다 른 정도와 관련된 정보를 생성하여 후술할 학습 데이터 생성 모듈에 제공할 수 있다. 본 개시의 일 실시예에 따른 동작 예측 모델은 가전기기의 동작 여부를 예측하기 위해 이용되는 모델을 의미할 수 있다. 일 예로, 동작 예측 모델은 센서 데이터를 입력 받아 가전기기가 동작될지 여부를 예측하는 모델일 수 있다. 일 예로, 동작 예측 모델은 라이다 데이터를 입력 받아 TV가 켜짐 동작을 수행할지 여부를 예측하는 모델 일 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 모델은 인공지능 모델로 구성될 수 있다. 일 예로, 동작 예측 모델은 적어도 하나 의 설계된 인공지능 모델을 포함할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 설계된 인공지능 모델은 적어도 하나의 인공 신경망 층(Artificial neural network, ANN)을 포함할 수 있다. 일 예로, 설계된 인공 지능 모델은 전방 전달 신경망(Feedforward neural network), 방사 신 경망(radial basis function network) 또는 코헨 자기조직 신경망(kohonen self-organizing network), 심층 신경망(Deep neural network, DNN), 합성곱신경망(Convolutional neural network, CNN), 순환 인공 신경망 (Recurrent neural network, RNN), LSTM(Long Short Term Memory Network) 또는 GRUs(Gated Recurrent Units) 등 다양한 인공 신경망 층 중 적어도 하나의 인공 신경망 층을 포함할 수 있으며, 이에 한정되지 않는 다. 일 실시예에 따른 설계된 인공 지능 모델에 포함되는 적어도 하나의 인공 신경망 층은 동일하거나 상이한 활성 함수(Activation function)를 이용할 수 있다. 일 실시예에 따른 활성 함수(Activation function)는 시그모이 드 함수(Sigmoid Function), 하이퍼볼릭탄젠트 함수(Tanh Fucntion), 렐루 함수(Relu Function, Rectified Linear unit Fucntion), 리키 렐루 함수(leaky Relu Function), 엘루 함수(ELU Function, Exponential Linear unit function), 소프트맥스 함수(Softmax function) 등을 포함할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 활성 함수는 결과값을 출력하거나 다른 인공 신경망 층으로 전달하기 위한 다양한 활성 함수(커스텀 활성 함수들 포함)들을 포함할 수 있다. 일 실시예에 따른 후술할 동작 예측 모델 학습 모듈은 설계된 인공 지능 모델을 학습시키기 위하여 적어도 하나의 손실 함수를 이용할 수 있다. 일 실시예에 따른 손실 함수는 MSE(Mean Squared Error), RMSE(Root Mean Squared Error), Binary Crossentropy, Categorical Crossentropy, Sparse Categorical Crossentropy 등을 포함할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 손실 함수는 예측된 결과값과 실제 결과 값의 차 이를 계산하기 위한 다양한 함수(커스텀 손실 함수들 포함)들을 포함할 수 있다. 일 실시예에 따른 동작 예측 모델 학습 모듈은 설계된 인공 지능 모델을 학습시키기 위하여 적어도 하나의 옵티마이저(Optimizer)를 이용할 수 있다. 일 실시예에 따른 옵티마이저는 입력값과 결과값 사이의 관계 파라미 터를 갱신시키기 위하여 이용될 수 있다. 일 실시예에 따른 옵티마이저는 Gradient descent, Batch Gradient Descent, Stochastic Gradient Descent, Mini-batch Gradient Descent, Momentum, AdaGrad, RMSProp, AdaDelta, Adam, NAG, NAdam, RAdam, AdamW 등을 포함할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 모델은 하나의 가전기기에 대해 하나의 동작 유형에 대한 동작 여부를 예측하기 위 한 모델로 구성될 수 있다. 일 예로, 동작 예측 모델은 TV에 대한 켜짐 동작을 예측하기 위한 모델로 구성될 수 있다. 일 예로 동작 예측 모델은 TV에 대한 꺼짐 동작을 예측하기 위한 모델로 구성될 수 있으며, 이에 한정되 지 않는다. 일 실시예에 따른 동작 예측 모델은 하나의 가전기기에 대해 복수의 동작 유형에 대한 동작 여부를 예측하기 위 한 모델로 구성될 수 있다. 일 예로, 동작 예측 모델은 TV에 대한 켜짐 동작 및 꺼짐 동작을 예측하기 위한 모 델로 구성될 수 있다. 일 예로, 동작 예측 모델은 프로젝터에 대한 켜짐 동작 및 꺼짐 동작을 예측하기 위한 모 델로 구성될 수 있으며, 이에 한정되지 않는다.일 실시예에 따른 동작 예측 모델은 복수의 가전기기에 대해 각 가전기기에 대응되는 적어도 하나의 동작을 예 측하기 위한 모델로 구성될 수 있다. 일 예로, 동작 예측 모델은 TV에 대한 켜짐 동작 및 프로젝터에 대한 켜짐 동작을 예측하기 위한 모델로 구성될 수 있다. 일 예로, 동작 예측 모델은 TV에 대한 켜짐 동작 및 꺼짐 동작과 프로젝터에 대한 켜짐 동작와 꺼짐 동작을 예측하기 위한 모델로 구성될 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 학습 데이터 생성 모듈은 상술한 가전기기 동작 예측 모델을 학습시키는데 이용되는 학 습 데이터를 생성하기 위한 모듈을 의미할 수 있으며, 물리적, 기능적 구성을 포함할 수 있다. 일 실시예에 따른 학습 데이터 생성 모듈은 획득된 센서 데이터를 기초로 학습 입력 데이터를 생성할 수 있다. 일 예로, 학습 데이터 생성 모듈은 획득된 복수개의 프레임 데이터를 기초로 학습 입력 데이터를 생성할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 학습 데이터 생성 모듈은 학습 입력 데이터를 생성하기 위하여, 획득된 센서 데이터 중 적어도 일부의 센서 데이터를 선택할 수 있다. 일 예로, 학습 데이터 생성 모듈은 획득된 복수개 의 프레임 데이터 중 적어도 일부의 프레임 데이터를 선택할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 학습 데이터 생성 모듈은 획득된 가전기기 데이터를 기초로 센서 데이터 중 적어도 일부의 센서 데이터를 선택할 수 있다. 일 예로, 학습 데이터 생성 모듈은 획득된 가전기기 데이터 를 기초로 복수의 프레임 데이터 중 적어도 일부의 프레임 데이터를 선택할 수 있으나, 이에 한정되지 않 는다. 일 실시예에 따른 학습 데이터 생성 모듈은 획득된 가전기기 데이터에 포함되는 동작 시점 정보에 기 초하여 복수의 프레임 데이터 중 적어도 일부의 프레임 데이터를 선택할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 학습 데이터 생성 모듈은 획득된 가전기기 데이터에 포함되는 동작 시점 정보 및 복수의 프레임 데이터에 매칭되는 시점 정보에 기초하여 복수의 프레임 데이터 중 적어도 일부의 프레임 데이터 를 선택할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 센서 데이터의 선택과 관련해서는 후술한다. 일 실시예에 따른 학습 데이터 생성 모듈은 학습 입력 데이터를 생성하기 위하여, 획득된 가전기기 데이터 를 기초로 센서 데이터를 요청하기 위한 정보를 생성할 수 있다. 일 실시예에 따른 학습 데이터 생성 모듈은 획득된 가전기기 데이터에 포함되는 동작 시점 정보를 포 함하는 센서 데이터 요청 정보를 생성할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 학습 데이터 생성 모듈은 획득된 가전기기 데이터에 포함되는 동작 시점 정보를 기 초로 획득되는 기준 시점 정보를 포함하는 센서 데이터 요청 정보를 생성할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 학습 데이터 생성 모듈은 가전기기 데이터를 획득한 시점을 기초로 결정된 기준 시 점 정보를 포함하는 센서 데이터 요청 정보를 생성할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 학습 데이터 생성 모듈은 센서 데이터에 대한 전처리를 수행하여 학습 입력 데이터 를 생성할 수 있다. 일 실시예에 따른 전처리는 센서 데이터를 기초로 학습 입력 데이터를 생성하는 것을 포함하는 개념으로 이해될 수 있다. 일 예로, 전처리는 센서 데이터를 동작 예측 모델에 입력될 데이터의 형식으로 변환하는 동작 및/또는 데이터의 노이즈를 제거하기 위한 동작 등 통상적으로 전처리로 이해되는 다양 한 개념들을 포함할 수 있다. 전처리와 관련된 구체적인 내용은 후술한다. 일 실시예에 따른 학습 데이터 생성 모듈은 학습 출력 데이터를 결정할 수 있다. 일 실시예에 따른 학습 출력 데이터는 라벨링 데이터(Labeling Data) 라벨 값, 어노테이션 데이터(Annotation Data) 및/또는 어노테이션 값 등으로 표현될 수 있으며, 머신러닝 또는 인공지능 모델을 학습할 때 이용되는 학 습 입력 데이터에 대응되는 결과 데이터를 의미할 수 있다. 이에 한정되지 않으며, 일 실시예에 따른 학습 출력 데이터는 통상적으로 이해되는 학습 출력 데이터, 라벨링 데이터, 라벨 값, 어노테이션 데이터 및/또는 어노테 이션 값 등의 개념을 포함할 수 있다. 일 실시예에 따른 학습 데이터 생성 모듈은 생성된 학습 입력 데이터에 결정된 학습 출력 데이터를 할당하 여 학습 데이터를 생성할 수 있다. 일 예로, 학습 데이터 생성 모듈은 생성된 학습 입력 데이터에 라벨 값을 할당하여 학습 데이터를 생성할 수 있다. 일 예로, 학습 데이터 생성 모듈은 학습 입력 데이터에 제1 값을 할당하여 학습 데이터를 생성할 수 있다. 일 예로, 학습 데이터 생성 모듈은 학습 입력 데이터에 TV 켜짐에 대응되는 라벨 값을 할당하여 학습 데이터를 생성할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 학습 데이터 생성 모듈은 가전기기 데이터에 기초하여 라벨 값을 결정할 수 있다. 일 실시예에 따른 학습 데이터 생성 모듈은 가전기기 데이터에 포함된 동작 유형 정보에 기초하여 라 벨 값을 결정할 수 있다. 일 예로, 학습 데이터 생성 모듈은 가전기기 데이터에 포함된 TV 켜짐 정보 에 기초하여 대응되는 라벨 값을 결정할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 학습 데이터 생성 모듈은 가전기기 데이터에 포함된 가전기기 식별 정보에 기초하 여 라벨 값을 결정할 수 있다. 일 예로, 학습 데이터 생성 모듈은 가전기기 데이터에 포함된 제1 TV 켜짐 정보에 기초하여 대응되는 라벨 값을 결정할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 학습 데이터 생성 모듈은 가전기기 데이터에 포함된 설치 위치 정보에 기초하여 라 벨 값을 결정할 수 있다. 일 예로, 학습 데이터 생성 모듈은 가전기기 데이터에 포함된 거실 TV 켜짐 정보에 기초하여 대응되는 라벨 값을 결정할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 학습 데이터 생성 모듈은 학습 입력 데이터에 가전기기 무동작에 대응되는 라벨 값을 할 당하여 학습 데이터를 생성할 수 있다. 일 예로, 학습 데이터 생성 모듈은 가전기기가 동작하지 않을 때 획득된 센서 데이터에 기초하여 생성된 학습 입력 데이터에 가전기기 무동작에 대응되는 라벨 값을 할당하여 학 습 데이터를 생성할 수 있다. 일 예로, 학습 데이터 생성 모듈은 TV가 켜지지 않을 때 획득된 센서 데이터 에 기초하여 생성된 학습 입력 데이터에 TV 무동작에 대응되는 라벨 값을 할당하여 학습 데이터를 생성할 수 있 으며, 이에 한정되지 않는다. 일 실시예에 따른 학습 데이터 생성 모듈은 생성된 적어도 하나의 학습 데이터에 기초하여 학습 데이터 세 트를 생성할 수 있다. 일 실시예에 따른 학습 데이터는 하나의 학습 입력 데이터 및 이에 할당된 하나의 학습 출력 데이터를 의미할 수 있다. 일 실시예에 따른 학습 데이터 세트는 복수의 학습 데이터를 포함하는 데이터 세트를 의미할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 학습 데이터 생성 모듈은 라벨 값이 동일한 학습 데이터들을 하나의 학습 데이터 세트로 생성할 수 있다. 일 실시예에 따른 학습 데이터 생성 모듈은 라벨 값에 대응되는 가전기기가 동일한 학습 데이터들을 하나의 학습 데이터 세트로 생성할 수 있다. 이에 한정되지 않으며, 학습 데이터 생성 모듈은 생성된 학습 데이터들을 적어도 하나의 학습 데이터 세트로 구별할 수 있다. 일 실시예에 따른 학습 데이터 세트는 서로 구별될 수 있다. 일 예로, 학습 데이터 세트는 저장된 주소에 기초 하여 서로 구별될 수 있다. 일 예로, 학습 데이터 세트는 할당된 태그에 기초하여 서로 구별될 수 있다. 일 예 로, 학습 데이터 세트는 생성된 시점에 기초하여 서로 구별될 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 하나의 학습 데이터 세트는 하나의 동작 예측 모델을 학습시키는데 이용될 수 있다. 이에 한 정되지 않으며, 일 실시예에 따른 하나의 동작 예측 모델은 복수의 학습 데이터 세트를 이용하여 학습될 수도 있다. 일 실시예에 따른 동작 예측 모델 학습 모듈은 학습 데이터를 이용하여 가전기기의 동작을 예측하기 위해 이용되는 동작 예측 모델을 학습시킬 수 있다. 일 예로, 동작 예측 모델 학습 모듈은 학습 데이터 생 성 모듈이 생성한 학습 데이터를 이용하여 가전기기의 동작을 예측하기 위해 이용되는 동작 예측 모 델을 학습시킬 수 있다. 일 예로, 동작 예측 모델 학습 모듈은 학습 데이터 세트를 이용하여 가전기기 의 동작을 예측하기 위해 이용되는 동작 예측 모델을 학습시킬 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 모델 학습 모듈은 하나의 가전기기에 대해 하나의 동작 유형에 대한 동작 여 부를 예측하기 위한 동작 예측 모델을 학습시킬 수 있다. 일 실시예에 따른 동작 예측 모델 학습 모듈은 하나의 가전기기에 대해 하나의 동작 유형에 대한 동작 여 부를 예측하기 위한 동작 예측 모델을 학습시키기 위해 동작을 예측할 가전기기의 종류 및/또는 동작 유형에 기 초하여 학습 데이터를 선택할 수 있다. 일 예로, 동작 예측 모델 학습 모듈은 TV에 대한 켜짐 동작을 예측 하는 모델을 학습시키기 위해 TV 켜짐에 대응되는 라벨 값이 할당된 학습 데이터를 선택할 수 있다. 일 예로,동작 예측 모델 학습 모듈은 TV에 대한 켜짐 동작을 예측하는 모델을 학습시키기 위해 TV 켜짐에 대응되는 라벨 값이 할당된 학습 데이터 및 TV 무동작에 대응되는 라벨 값이 할당된 학습 데이터를 선택할 수 있으며, 이 에 한정되지 않는다. 일 실시예에 따른 동작 예측 모델 학습 모듈은 하나의 가전기기에 대해 복수의 동작 유형에 대한 동작 여 부를 예측하기 위한 동작 예측 모델을 학습시킬 수 있다. 일 실시예에 따른 동작 예측 모델 학습 모듈은 하나의 가전기기에 대해 복수의 동작 유형에 대한 동작 여 부를 예측하기 위한 동작 예측 모델을 학습시키기 위해 동작을 동작을 예측할 가전기기의 종류 및/또는 동작 유 형에 기초하여 학습 데이터를 선택할 수 있다. 일 예로, 동작 예측 모델 학습 모듈은 TV에 대한 동작을 예 측하는 모델을 학습시키기 위해 TV에 대응되는 라벨 값이 할당된 학습 데이터를 선택할 수 있다. 일 예로, 동작 예측 모델 학습 모듈은 TV에 대한 켜짐 동작 및 꺼짐 동작을 예측하는 모델을 학습시키기 위해 TV 켜짐에 대응되는 라벨 값이 할당된 학습 데이터 및 TV 꺼짐에 대응되는 라벨 값이 할당된 학습 데이터를 선택할 수 있 다. 일 예로, 동작 예측 모델 학습 모듈은 TV에 대한 켜짐 동작 및 꺼짐 동작을 예측하는 모델을 학습시키 기 위해 TV 켜짐에 대응되는 라벨 값이 할당된 학습 데이터, TV 꺼짐에 대응되는 라벨 값이 할당된 학습 데이터 및 TV 무동작에 대응되는 라벨 값이 할당된 학습 데이터를 선택할 수 있다. 일 실시예에 따른 동작 예측 모델 학습 모듈은 복수의 가전기기에 대해 각 가전기기에 대응되는 적어도 하 나의 동작을 예측하기 위한 동작 예측 모델을 학습시킬 수 있다. 일 실시예에 따른 동작 예측 모델 학습 모듈은 복수의 가전기기에 대해 각 가전기기에 대응되는 적어도 하 나의 동작 유형에 대한 동작 여부를 예측하기 위한 동작 예측 모델을 학습시키기 위해 동작을 예측할 가전기기 의 종류 및/또는 동작 유형에 기초하여 학습 데이터를 선택할 수 있다. 일 예로, 동작 예측 모델 학습 모듈 은 TV 및 프로젝터에 대한 동작을 예측하는 모델을 학습시키기 위해 TV에 대응되는 라벨 값이 할당된 학습 데이터 및 프로젝터에 대응되는 라벨 값이 할당된 학습 데이터를 선택할 수 있다. 일 예로, 동작 예측 모델 학 습 모듈은 TV 켜짐, TV 꺼짐, 프로젝터 켜짐 및 프로젝터 꺼짐에 대한 동작을 예측하는 모델을 학습시키기 위해 TV 켜짐에 대응되는 라벨 값이 할당된 학습 데이터, TV 꺼짐에 대응되는 라벨 값이 할당된 학습 데이터, TV 무동작에 대응되는 라벨 값이 할당된 학습 데이터, 프로젝터 켜짐에 대응되는 라벨 값이 할당된 학습 데이터, 프로젝터 꺼짐에 대응되는 라벨 값이 할당된 학습 데이터 및 프로젝터 무동작에 대응되는 라벨 값이 할 당된 학습 데이터를 선택할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 모델 학습 모듈은 사용자를 구별하여 사용자 별 동작 예측 모델을 학습시킬 수 있다. 일 실시예에 따른 동작 예측 모델 학습 모듈은 사용자 별 동작 예측 모델을 학습시키기 위해 사용자에 기 초하여 학습 데이터를 선택할 수 있다. 일 예로, 동작 예측 모델 학습 모듈은 사람 A에 의한 동작 예측 모 델을 학습시키기 위해 사람 A와 관련된 학습 데이터를 선택할 수 있다. 일 예로, 동작 예측 모델 학습 모듈 은 사람 A에 의한 TV 켜짐 동작을 예측하는 동작 예측 모델을 학습시키기 위해 TV 켜짐에 대응되는 라벨 값이 할당된 학습 데이터 중 사람 A와 관련된 학습 데이터를 선택할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 모듈은 학습된 동작 예측 모델을 이용하여 가전기기에 대한 동작 예측 정보를 획득할 수 있다. 일 예로, 동작 예측 모듈은 동작 예측 모델 학습 모듈이 학습시킨 동작 예측 모델을 이용하여 가전기기에 대한 동작 예측 정보를 획득할 수 있다. 일 예로, 동작 예측 모듈은 동 작 예측 모델 학습 모듈이 학습시킨 동작 예측 모델에 획득한 센서 데이터를 적용하여 가전기기에 대 한 동작 예측 정보를 획득할 수 있다. 일 예로, 동작 예측 모듈은 동작 예측 모델 학습 모듈이 학습 시킨 동작 예측 모델에 획득한 센서 데이터에 기초하여 생성된 예측 입력 데이터를 적용하여 가전기기에 대한 동작 예측 정보를 획득할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 모듈은 센서 데이터를 획득할 수 있다. 일 예로, 동작 예측 모듈은 데이터 송수신 모듈을 통해 센서 데이터를 획득할 수 있다. 일 실시예에 따른 동작 예측 모듈은 획득한 센서 데이터를 기초로 예측 입력 데이터를 생성할 수 있 다. 일 예로, 동작 예측 모듈은 획득한 복수개의 프레임 데이터를 기초로 예측 입력 데이터를 생성할 수있으나, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 모듈은 예측 입력 데이터를 생성하기 위하여, 획득된 센서 데이터 중 적 어도 일부의 센서 데이터를 선택할 수 있다, 일 예로, 동작 예측 모듈은 획득된 복수개의 프레임 데이터 중 적어도 일부의 프레임 데이터를 선택할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 모듈이 센서 데이터로부터 예측 입력 데이터를 생성하기 위하여, 상술한 일 실시예에 따른 학습 데이터 생성 모듈이 센서 데이터로부터 학습 입력 데이터를 생성하는 내용들 이 적용될 수 있는 바, 중복 설명은 생략한다. 일 실시예에 따른 동작 예측 모듈이 획득한 동작 예측 정보는 가전기기의 동작 여부를 예측한 결과를 포함할 수 있다. 일 예로, 동작 예측 정보는 가전기기의 동작 여부를 예측한 확률 값을 포함할 수 있다. 일 예로, 동작 예측 정보는 가전기기의 복수의 동작 유형 중 어떤 동작이 예측되는지를 나타내는 값을 포 함할 수 있다. 일 예로, 동작 예측 정보는 어떤 가전기기의 동작이 예측되는지를 나타내는 값을 포함할 수 있다. 일 예로, 동작 예측 정보는 어떤 가전기기의 어떤 동작이 예측되는지를 나타내는 값을 포함할 수 있 으며, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 모듈은 획득한 동작 예측 정보에 기초하여 동작 제어 정보를 생성할 수 있다. 일 예로, 동작 예측 모듈은 동작 예측 정보에 포함된 동작 여부를 예측한 확률 값이 임계치 이상인 경우 가전기기가 해당 동작을 수행하도록 하기 위한 동작 제어 정보를 셍성할 수 있다. 일 예로, 동 작 예측 모듈은 동작 예측 정보에 포함된 동작 유형에 기초하여 가전기기가 해당 동작을 수행하도록 하기 위한 동작 제어 정보를 생성할 수 있다. 일 예로, 동작 예측 모듈은 동작 예측 정보에 포함된 동작 유형 및 어떤 가전기기의 동작인지에 기초하여 해당 가전기기가 해당 동작을 수행하도록 하기 위한 동작 제어 정보를 생성할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 모듈은 획득한 동작 예측 정보와 사용자 응답에 기초하여 가전기기가 동 작을 수행하도록 하기 위한 동작 제어 정보를 생성할 수 있다. 일 예로, 동작 예측 모듈은 동작 예측 정보와 관련된 내용을 사용자에게 제공하고, 사용자 응답을 수신할 수 있다. 이 경우, 동작 예측 모듈은 사용자 응답에 따라 동작 제어 정보를 생성하거나 동작 제어 정보를 생성하지 않을 수 있다. 일 실시예에 따른 동작 예측 시스템은 학습 데이터 관리 모듈을 이용하여 생성된 학습 데이터들을 관 리할 수 있다. 일 실시예에 따른 학습 데이터 관리 모듈은 학습 데이터 생성 모듈에서 생성된 학습 데이터들의 버전 을 관리할 수 있다. 일 실시예에 따른 학습 데이터 관리 모듈은 학습 데이터의 생성 시점에 기초하여 학습 데이터들의 버전을 관리할 수 있다. 일 예로, 학습 데이터 관리 모듈은 학습 데이터가 생성된 시점이 기설정된 시간 구간 중 어디에 포함되는지에 따라 학습 데이터의 버전을 관리할 수 있다. 일 예로, 학습 데이터 관리 모듈은 당해 년도 1월 및 2월에 생성된 학습 데이터를 제1 버전으로 관리하고, 당해 년도 3월 및 4월에 생성된 학습 데이터 를 제2 버전으로 관리할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 학습 데이터 관리 모듈은 학습 데이터의 개수에 기초하여 학습 데이터들의 버전을 관리 할 수 있다. 일 예로, 학습 데이터 관리 모듈은 기설정된 개수만큼의 학습 데이터를 하나의 버전에 대한 학습 데이터로 관리할 수 있다. 일 예로, 학습 데이터 관리 모듈은 최초로 생성된 학습 데이터부터 10번째 로 생성된 학습 데이터를 제1 버전으로 관리하고, 11번째로 생성된 학습 데이터부터 20번째로 생성된 학습 데이 터를 제2 버전으로 관리할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 시스템은 학습 데이터의 버전에 따라 동작 예측 모델을 학습시킬 수 있다. 일 예로, 동작 예측 시스템은 제1 버전의 학습 데이터를 이용하여 제1 동작 예측 모델을 학습시키고, 제2 버 전의 학습 데이터를 이용하여 제2 동작 예측 모델을 학습시킬 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 시스템에 포함된 데이터 송수신 모듈, 학습 데이터 생성 모듈, 동 작 예측 모델 학습 모듈, 동작 예측 모듈 및 학습 데이터 관리 모듈 각각은 하드웨어적으로 구분되어 각각 적어도 하나의 프로세서로 구성될 수 있다. 일 실시예에 따른 동작 예측 시스템에 포함된 데이터 송수신 모듈, 학습 데이터 생성 모듈, 동 작 예측 모델 학습 모듈, 동작 예측 모듈 및 학습 데이터 관리 모듈 각각은 기능적으로 구분되 어 전체가 하나의 프로세서로 구성될 수 있다. 이에 한정되는 것은 아니며, 데이터 송수신 모듈, 학습 데이터 생성 모듈, 동작 예측 모델 학습 모듈 , 동작 예측 모듈 및 학습 데이터 관리 모듈 중 적어도 일부가 하드웨어적으로 구분되어, 둘 이 상의 모듈이 적어도 하나의 프로세서로 구성될 수도 있다. 한편, 프로세서는 중앙 처리 장치(CPU), 그래픽 처리 장치(GPU), 디지털 신호 처리 장치(DSP), 상태 기계(state machine), 주문형 반도체(ASIC), 무선 주파수 집적 회로(RFIC) 및 이들의 조합 등으로 구성될 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 시스템은 서버 장치로 구성될 수 있다. 이 경우, 서버 장치는 센서 및 가전기기와 데이터 통신을 수행할 수 있으며, 상술한 각 모듈들의 동작을 수행할 수 있다. 일 실시예에 따른 동작 예측 시스템은 복수의 서버 장치로 구성될 수 있다. 일 예로, 동작 예측 시스템 은 로컬 서버 장치 및 클라우드 서버 장치로 구성될 수 있다. 일 실시예에 따른 로컬 서버 장치는 사용자의 생활 공간 가까이에 배치된 서버 장치를 포함할 수 있다. 이에 따 라, 로컬 서버 장치는 센서 및 가전기기와 데이터 통신을 원활히 수행할 수 있으며, 서버 장치와 센 서 및/또는 가전기기 사이의 데이터 송수신에 대한 지연은 최소화될 수 있다. 일 실시예에 따른 클라우드 서버 장치는 높은 컴퓨팅 파워를 가지는 서버 장치를 포함할 수 있다. 이에 따라, 클라우드 서버 장치는 학습 데이터 생성 및/또는 동작 예측 모델 학습을 원활히 수행할 수 있다. 일 예로, 클라 우드 서버 장치는 가전기기 및/또는 센서의 제조사가 제공하는 서버 장치일 수 있다. 일 실시예에 따른 동작 예측 시스템에 포함된 데이터 송수신 모듈, 학습 데이터 생성 모듈, 동 작 예측 모듈 및/또는 학습 데이터 관리 모듈은 로컬 서버 장치에 포함된 프로세서로 구성될 수 있다. 일 실시예에 따른 동작 예측 시스템에 포함된 데이터 학습 데이터 생성 모듈, 동작 예측 모델 학습 모듈 및/또는 학습 데이터 관리 모듈은 클라우드 서버 장치에 포함된 프로세서로 구성될 수 있 으며, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 시스템은 센서에 포함된 적어도 하나의 프로세서로 구성될 수 있다. 일 실시예에 따른 동작 예측 시스템은 가전기기에 포함된 적어도 하나의 프로세서로 구성될 수 있다. 일 실시예에 따른 동작 예측 시스템에 포함된 복수의 모듈 중 적어도 일부는 센서에 포함된 프로세서로 구성되고, 다른 일부는 가전기기에 포함된 프로세서로 구성될 수 있다. 이하에서는 도 3 내지 도 12를 참조하여 일 실시예에 따른 동작 예측 시스템에 대하여 설명한다. 도 3은 일 실시예에 따른 동작 예측 시스템을 설명하기 위한 도면이다. 도 3을 참조하면, 일 실시예에 따른 동작 예측 시스템은 센서로부터 획득된 센서 데이터를 기초 로 가전기기에 대한 동작 제어 정보를 생성하기 위한 시스템일 수 있다. 일 예로, 일 실시예에 따른 동작 예측 시스템은 라이다 장치로부터 획득된 라이다 데이터를 기초로 TV에 대한 켜짐 정보를 생성하기 위한 시스템일 수 있으나, 이에 한정되지 않는다. 이 때, 상기 센서, 상기 센서 데이터, 상기 가전기기 및 동작 제어 정보에 대하여는 상술 한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 다시 도 3을 참조하면, 일 실시예에 따른 동작 예측 시스템은 센서로부터 획득된 센서 데이터 및 가전기기로부터 획득된 가전기기 데이터를 기초로 동작 예측 모델을 학습시키고, 학습된 동작 예 측 모델을 이용하여 상기 가전기기에 대한 동작 제어 정보를 생성하기 위한 시스템일 수 있다.일 예로, 일 실시예에 따른 동작 예측 시스템은 라이다 장치로부터 획득된 라이다 데이터 및 TV 로부터 획 득된 TV 켜짐 정보를 기초로 동작 예측 모델을 학습시키고 학습된 동작 예측 모델을 이용하여 상기 TV에 대한 켜짐 정보를 생성하기 위한 시스템일 수 있으나, 이에 한정되지 않는다. 이 때, 상기 센서, 상기 센서 데이터, 상기 가전기기, 상기 가전기기 데이터 및 상기 동작 제어 정보에 대하여는 상술한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 다시 도 3을 참조하면, 일 실시예에 따른 동작 예측 시스템은 센서로부터 획득된 센서 데이터 및 가전기기로부터 획득된 가전기기 데이터를 기초로 동작 예측 모델을 학습시키기 위하여 학습 데이 터를 생성하기 위한 학습 데이터 생성 시스템을 포함할 수 있다. 일 실시예에 따른 학습 데이터 생성 시스템은 센서 데이터 및 가전기기 데이터를 기초로 학습 데이터를 생성하기 위한 시스템일 수 있으며, 학습 데이터 생성 모듈에 의해 구현될 수 있다. 이 때, 상기 센서 데이터, 상기 가전기기 데이터, 상기 학습 데이터 및 상기 학습 데이터 생성 모듈에 대하여는 상술한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 이 때, 상기 센서 데이터는 상기 센서로부터 획득된 센서 데이터의 일부를 의미할 수 있 으며, 센서 데이터 중 일 실시예에 따른 학습 데이터 생성 시스템에서 학습 데이터를 생성하기 위해 이용되는 일부를 특정하여 설명하기 위해 구분되어 설명될 수 있으나, 이에 한정되지 않는다. 또한, 이 때, 상기 가전기기 데이터는 상기 가전기기로부터 획득된 가전기기 데이터의 일부를 의미할 수 있으며, 가전기기 데이터 중 일 실시예에 따른 학습 데이터 생성 시스템에서 학습 데이터 를 생성하기 위해 이용되는 일부를 특정하여 설명하기 위해 구분되어 설명될 수 있으나, 이에 한정되지 않 는다. 일 실시예에 따른 학습 데이터 생성 시스템에 따르면, 제1 시점에 획득된 가전기기 데이터 및 이에 대응되는 센서 데이터를 기초로 제1 학습 데이터가 생성될 수 있으며, 제2 시점에 획득된 가전기기 데이터 및 이에 대응되는 센서 데이터를 기초로 제2 학습 데이터가 생성될 수 있으며, 복수개의 학습 데이 터가 포함되는 학습 데이터 세트가 생성될 수 있으나, 본 명세서에서는 설명의 편의를 위해서 하나의 학습 데이 터를 기준으로 설명될 수 있다. 이하에서는 도 4 내지 도 6을 이용하여, 학습 데이터 생성 시스템에 대하여 보다 구체적으로 설명한 뒤 다 시 동작 예측 시스템에 대하여 설명하기로 한다. 도 4는 일 실시예에 따른 학습 데이터 생성 방법에 대하여 설명하기 위한 도면이다. 도 4를 참조하면, 일 실시예에 따른 학습 데이터 생성 방법은 복수의 프레임 데이터를 포함하는 센서 데 이터를 획득하는 단계(S1010), 동작 시점 정보를 포함하는 가전기기 데이터를 획득하는 단계(S1020), 가전기기 데이터에 포함된 동작 시점 정보를 기초로 센서 데이터에 포함된 복수의 프레임 데이터 중 프레임 데이터 그룹 을 선택하는 단계(S1030), 선택된 프레임 데이터 그룹을 기초로 학습 입력 데이터를 생성하는 단계(S1040), 가 전기기 데이터에 기초하여 학습 출력 데이터를 결정하는 단계(S1050) 및 학습 입력 데이터에 학습 출력 데이터 를 할당하여 학습 데이터를 생성하는 단계(S1060) 중 적어도 하나의 단계를 포함할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계(S1010)에서, 상기 복수의 프 레임 데이터를 포함하는 센서 데이터에 대하여는 상술한 센서 데이터에 관한 내용들이 적용될 수 있으므로, 중 복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 동작 시점 정보를 포함하는 가전기기 데이터를 획득하는 단계(S1020)에서, 상기 동작 시점 정보를 포함하는 가전기기 데이터에 대하여는 상술한 가전기기 데이터에 관한 내용들이 적용될 수 있으므 로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 프레임 데이터 그룹을 선택하는 단계(S1030)에서, 상기 프레임 데이터 그룹은 적어도 두 개의 프레임 데이터를 포함할 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 프레임 데이터 그룹을 선택하는 단계(S1030)에서, 상기 프레임 데이터 그룹은 상기 가 전기기 데이터에 포함된 동작 시점 정보의 동작 시점 이전에 센서에서 획득된 복수의 프레임 데이터로 선택될 수 있다. 일 예로, 일 실시예에 따른 프레임 데이터 그룹을 선택하는 단계(S1030)에서, 상기 프레임 데이터 그룹은 상기 가전기기 데이터에 포함된 동작 시점 정보가 제1 시점을 포함하는 경우, 제1 시점 이전에 센서에서 획득된 복수 의 프레임 데이터로 선택될 수 있으나, 이에 한정되지 않는다. 이 때, 제1 시점 이전에 센서에서 획득된 복수의 프레임 데이터는 상기 제1 시점 이전의 시점에 대응되는 시점 정보와 매칭되는 프레임 데이터들을 의미할 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 프레임 데이터 그룹을 선택하는 단계(S1030)에서, 상기 프레임 데이터 그룹은 상기 가 전기기 데이터에 포함된 동작 시점 정보의 동작 시점 이전의 특정 시간 구간 동안 센서에서 획득된 복수의 프레 임 데이터로 선택될 수 있다. 일 예로, 일 실시예에 따른 프레임 데이터 그룹을 선택하는 단계(S1030)에서, 상기 프레임 데이터 그룹은 상기 가전기기 데이터에 포함된 동작 시점 정보가 제1 시점을 포함하는 경우, 제1 시점 이전인 제1 시간 구간동안 센 서에서 획득된 복수의 프레임 데이터로 선택될 수 있으나, 이에 한정되지 않는다. 이 때, 제1 시점 이전인 제1 시간 구간동안 센서에서 획득된 복수의 프레임 데이터는 상기 제1 시점 이전인 제1 시간 구간에 대응되는 시점 정보와 매칭되는 프레임 데이터들을 의미할 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 프레임 데이터 그룹을 선택하는 단계(S1030)는 가전기기 데이터에 포함된 동작 시점 정 보 및 복수의 프레임 데이터에 매칭된 복수의 시점 정보에 기초하여 복수의 프레임 데이터 중 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹을 선택하는 단계를 포함할 수 있다. 일 예로, 일 실시예에 따른 프레임 데이터 그룹을 선택하는 단계(S1030)는 가전기기 데이터에 포함된 동작 시점 정보 및 복수의 프레임 데이터에 매칭된 복수의 시점 정보를 비교하여, 복수의 프레임 데이터 중 학습 입력 데 이터 생성에 이용되는 프레임 데이터 그룹을 선택하는 단계를 포함할 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 프레임 데이터 그룹을 선택하는 단계(S1030)에 대하여는 도 5를 통해 보다 구체적으로 설명하기로 한다. 또한, 일 실시예에 따른 학습 입력 데이터를 생성하는 단계(S1040)는 선택된 프레임 데이터 그룹을 학습 입력 데이터로 선택하는 단계를 포함할 수 있다. 일 예로, 일 실시예에 따른 학습 입력 데이터를 생성하는 단계(S1040)는 선택된 프레임 데이터 그룹 자체를 학 습 입력 데이터로 선택하는 단계를 포함할 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 학습 입력 데이터를 생성하는 단계(S1040)는 선택된 프레임 데이터 그룹을 처리하여 학 습 입력 데이터를 생성하는 단계를 포함할 수 있다. 이 때, 일 실시예에 따른 학습 입력 데이터를 생성하는 단계(S1040)에서 선택된 프레임 데이터 그룹은 다양한 전처리 알고리즘들에 의해 처리될 수 있다. 일 실시예에 따른 전처리 알고리즘은 통상적으로 전처리로 이해되는 다양한 개념의 알고리즘들을 포함할 수 있 다. 일 실시예에 따른 전처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 대해, 프레임 데이터 에 포함된 포인트 데이터에 대한 포인트 데이터 처리를 수행하는 포인트 데이터 처리 알고리즘을 포함할 수 있 다. 일 실시예에 따른 포인트 데이터 처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 대해, 프 레임 데이터에 포함된 포인트들 중 적어도 일부를 세그먼트하는 알고리즘을 포함할 수 있다. 보다 구체적으로, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이 터 각각에 대해, 프레임 데이터에 포함된 포인트 데이터들 중 적어도 하나의 서브 포인트 데이터 세트를 세그먼 트하는 알고리즘을 포함할 수 있다. 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터 들을 기초로 적어도 하나의 서브 포인트 데이터 세트를 세그먼트하는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 보다 구체적인 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터들을 기초로 제1 서브 포인트 데이터 세트를 세그먼트하는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 보다 구체적인 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터들을 기초로 제1 동적 객체에 대응되는 제1 서브 포인트 데이터 세트를 세그먼트하는 알고 리즘을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 보다 구체적인 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터들을 기초로 제1 동적 객체에 대응되는 제1 서브 포인트 데이터 세트 및 제2 동적 객체에 대응되는 제2 서브 포인트 데이터 세트를 세그먼트하는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 보다 구체적인 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터들을 기초로 제1 사용자에 대응되는 제1 서브 포인트 데이터 세트 및 제2 사용자에 대응되 는 제2 서브 포인트 데이터 세트를 세그먼트하는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 보다 구체적인 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터들의 특징 및 제1 사용자의 특징을 기초로 제1 사용자에 대응되는 제1 서브 포인트 데이터 세트를 세그먼트하는 알고리즘과, 포인트 클라우드 데이터에 포함된 포인트 데이터들의 특징 및 제2 사용자의 특징을 기초로 제2 사용자에 대응되는 제2 서브 포인트 데이터 세트를 세그먼트하는 알고리즘을 포함할 수 있으 나, 이에 한정되지 않는다. 이 경우, 제1 서브 포인트 데이터 세트에 포함된 포인트 데이터와 제2 서브 포인트 데이터 세트에 포함된 포인 트 데이터 증 적어도 일부는 서로 동일한 포인트 데이터일 수 있으며, 이에 한정되지 않는다. 한편, 일 실시예에 따른 포인트 데이터 처리 알고리즘을 통해 세그먼트되는 서브 포인트 데이터 세트의 개수는 전술한 예에 한정되지 않으며, 포인트 클라우드 데이터에 나타난 동적 객체의 수에 기초하여 서브 포인트 데이 터 세트의 수가 결정될 수도 있다. 한편, 일 실시예에 따른 포인트 데이터 처리 알고리즘을 통해 세그먼트되는 서브 포인트 데이터 세트의 개수는 전술한 예에 한정되지 않으며, 포인트 클라우드 데이터에 나타난 사용자의 수에 기초하여 서브 포인트 데이터 세트의 수가 결정될 수도 있다. 일 실시예에 따른 포인트 데이터 처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 대해, 프 레임 데이터에 포함된 포인트 데이터들 중 적어도 하나의 서브 포인트 데이터 세트를 제외한 나머지 포인트 데 이터를 제거하는 알고리즘을 포함할 수 있으며, 이에 한정되지 않는다. 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터 들을 기초로 적어도 하나의 서브 포인트 데이터 세트를 제외한 나머지 포인트 데이터를 제거하는 알고리즘을 포 함할 수 있으며, 이에 한정되지 않는다. 또한, 보다 구체적인 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터들을 기초로 제1 서브 포인트 데이터 세트를 제외한 나머지 포인트 데이터를 제거하는 알 고리즘을 포함할 수 있으며, 이에 한정되지 않는다. 또한, 보다 구체적인 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터들을 기초로 제1 동적 객체에 대응되는 제1 서브 포인트 데이터 세트를 제외한 나머지 포 인트 데이터를 제거하는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 보다 구체적인 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터들을 기초로 제1 동적 객체에 대응되는 제1 서브 포인트 데이터 세트 및 제2 동적 객체에 대응되는 제2 서브 포인트 데이터 세트를 제외한 포인트 데이터를 제거하는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 보다 구체적인 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터들을 기초로 제1 사용자에 대응되는 제1 서브 포인트 데이터 세트 및 제2 사용자에 대응되 는 제2 서브 포인트 데이터 세트를 제외한 포인트 데이터를 제거하는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 보다 구체적인 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터들의 특징 및 제1 사용자의 특징을 기초로 제1 사용자에 대응되는 제1 서브 포인트 데이터 세트를 제외한 포인트 데이터를 제거하는 알고리즘과, 포인트 클라우드 데이터에 포함된 포인트 데이터들의 특 징 및 제2 사용자의 특징을 기초로 제2 사용자에 대응되는 제2 서브 포인트 데이터 세트를 제외한 포인트 데이 터를 제거하는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다. 이 경우, 제1 서브 포인트 데이터 세트에 포함된 포인트 데이터와 제2 서브 포인트 데이터 세트에 포함된 포인 트 데이터 증 적어도 일부는 서로 동일한 포인트 데이터일 수 있으며, 이에 한정되지 않는다. 한편, 일 실시예에 따른 포인트 데이터 처리 알고리즘에서 고려되는 서브 포인트 데이터 세트의 개수는 전술한 예에 한정되지 않으며, 포인트 클라우드 데이터에 나타난 동적 객체의 수에 기초하여 서브 포인트 데이터 세트 의 수가 결정될 수도 있다. 한편, 일 실시예에 따른 포인트 데이터 처리 알고리즘에서 고려되는 서브 포인트 데이터 세트의 개수는 전술한 예에 한정되지 않으며, 포인트 클라우드 데이터에 나타난 사용자의 수에 기초하여 서브 포인트 데이터 세트의 수가 결정될 수도 있다. 일 실시예에 따른 포인트 데이터 처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 대해, 프 레임 데이터에 포함된 포인트 데이터들 각각에 대한 상대 위치 데이터를 획득하는 알고리즘을 포함할 수 있다. 일 실시예에 따른 포인트 데이터 처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 대해, 프 레임 데이터에 포함된 포인트 데이터들의 위치 좌표에 대한 원점을 변경하는 알고리즘을 포함할 수 있다. 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터 들의 위치 좌표에 대한 원점을 변경하는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 보다 구체적인 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터들의 위치 좌표에 대한 원점을 기준 위치로 변경하는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 기준 위치는 미리 설정되어 있을 수 있다. 또는, 일 실시예에 따른 기준 위치는 포인트 클라우드 데이터에 포함된 포인트 데이터의 특징에 기초하여 결정 될 수 있다. 예를 들어, 일 실시예에 따른 기준 위치는 포인트 클라우드 데이터에 포함된 포인트 데이터들 중 정적 객체가 반영된 포인트 데이터의 위치일 수 있다. 예를 들어, 일 실시예에 따른 기준 위치는 포인트 클라우드 데이터에 포함된 포인트 데이터들 중 가전기기가 반 영된 포인트 데이터의 위치일 수 있다. 예를 들어, 일 실시예에 따른 기준 위치는 포인트 클라우드 데이터에 포함된 포인트 데이터들 중 대표 가구가 반영된 포인트 데이터의 위치일 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 포인트 데이터 처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 대해, 프 레임 데이터에 포함된 포인트 데이터들 중 노이즈를 제거하는 알고리즘을 포함할 수 있다. 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터 들 중 적어도 하나의 노이즈 데이터를 판단하고, 노이즈 데이터에 대한 노이즈를 제거하는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다. 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터 들 중 적어도 하나의 노이즈 데이터를 판단하고, 노이즈 데이터를 제거하는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다. 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터 들 중 적어도 하나의 노이즈 데이터를 판단하고, 노이즈 데이터의 값을 변경하는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다.보다 구체적인 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 노이즈 데이터의 값을 인접한 주변 포인트 데이터들의 값들과 비슷한 수준으로 변경하는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다. 보다 구체적인 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 노이즈 데이터의 값을 인접한 주변 포인트 데이터들의 값들의 평균 값으로 변경하는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 노이즈 데이터는 포인트 클라우드 데이터 상의 극소 영역에 대응되는 포인트 데이터일 수 있 다. 예를 들어, 일 실시예에 따른 노이즈 데이터는 1개 내지 3개의 포인트 데이터를 포함할 수 있으며, 이에 한 정되지 않는다. 일 실시예에 따른 노이즈 데이터는 포인트 데이터의 위치 좌표 값, 인텐시티 값, 뎁스 값 및 라이트 캡쳐 값 중 적어도 하나에 기초하여 판단될 수 있으며, 이에 한정되지 않는다. 예를 들어, 일 실시예에 따른 포인트 데이터들 중 3차원 위치 좌표 값이 인접한 주변 포인트 데이터들의 3차원 위치 좌표 값들과 비교하여 임계치 이상 차이나는 포인트 데이터는 노이즈 데이터로 판단될 수 있으며, 이에 한 정되지 않는다. 예를 들어, 일 실시예에 따른 포인트 데이터들 중 인텐시티 값이 인접한 주변 포인트 데이터들의 인텐시티 값들 과 비교하여 임계치 이상 차이나는 포인트 데이터는 노이즈 데이터로 판단될 수 있으며, 이에 한정되지 않는다. 예를 들어, 일 실시예에 따른 포인트 데이터들 중 뎁스 값이 인접한 주변 포인트 데이터들의 뎁스 값들과 비교 하여 임계치 이상 차이나는 포인트 데이터는 노이즈 데이터로 판단될 수 있으며, 이에 한정되지 않는다. 예를 들어, 일 실시예에 따른 포인트 데이터들 중 라이트 캡쳐 값이 인접한 주변 포인트 데이터들의 라이트 캡 쳐 값들과 비교하여 임계치 이상 차이나는 포인트 데이터는 노이즈 데이터로 판단될 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 포인트 데이터 처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 대해, 프 레임 데이터에 포함된 포인트 데이터들을 스무딩하는 알고리즘을 포함할 수 있다. 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터 들을 스무딩하는 알고리즘을 포함할 수 있다. 보다 구체적인 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터들의 값들을 인접한 포인트 데이터들의 값들에 기초하여 스무딩하는 알고리즘을 포함할 수 있다. 보다 구체적인 예를 들어, 일 실시예에 따른 포인트 데이터 처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터들의 값들을 인접한 포인트 데이터들의 값들에 기초하여 값들의 변화를 부드럽게 하고 불규칙한 변동성을 완화시기 위한 스무딩 알고리즘을 포함할 수 있다. 일 실시예에 따른 전처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 대해, 프레임 데이터 에 포함된 포인트 데이터로부터 속성 데이터를 획득하는 알고리즘을 포함할 수 있다. 일 실시예에 따른 전처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 대해, 프레임 데이터 에 포함된 포인트 데이터들의 위치 좌표에 기초하여 속성 데이터를 획득하는 알고리즘을 포함할 수 있다. 일 실시예에 따른 전처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 대해 상술한 포인트 데이터 처리 후, 처리된 프레임 데이터에 포함된 포인트 데이터로부터 속성 데이터를 획득하는 알고리즘을 포함 할 수 있다. 일 실시예에 따른 전처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 대해 상술한 포인트 데이터 처리 후, 처리된 프레임 데이터에 포함된 포인트 데이터들의 위치 좌표에 기초하여 속성 데이터를 획득 하는 알고리즘을 포함할 수 있다. 이 경우, 일 실시예에 따른 속성 데이터는 포인트 데이터들의 중심 위치 정보, 객체 정보, 사이즈 정보, 형상 정보, 부피 정보, 크기 정보 및/또는 스켈레톤 정보 중 적어도 하나를 포함할 수 있다. 일 실시예에 따른 전처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터들로부터 동적 속성 데이터를 획득하는 알고리즘을 포함할 수 있다. 일 실시예에 따른 동적 속성 데이터는 적어도 둘 이상의 프레임 데이터들로부터 획득될 수 있는 속성 데이터를 의미할 수 있으며, 시계열적으로 연속된 프레임 데이터들로부터 획득된다는 점을 기초로 동적 속성 데이터라는 용어를 이용하여 기재하였으나, 이에 한정되지 않고, 동적 속성 데이터는 복수개의 프레임 데이터를 기초로 획 득되는 다양한 종류의 속성 데이터들을 의미할 수 있다. 일 실시예에 따른 전처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 대한 속성 데이터를 획득한 후, 획득된 속성 데이터들에 기초하여 동적 속성 데이터를 획득하는 알고리즘을 포함할 수 있다. 일 실시예에 따른 전처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 대해 상술한 포인트 데이터 처리 후, 처리된 프레임 데이터들로부터 동적 속성 데이터를 획득하는 알고리즘을 포함할 수 있다. 이 경우, 일 실시예에 따른 동적 속성 데이터는 프레임 데이터 그룹에 포함된 연속되는 프레임 데이터 각각에 포함된 포인트 데이터들에 대한 궤적 정보, 이동 정보, 속도 정보 및/또는 방향 정보 중 적어도 하나를 포함할 수 있다. 이 경우, 일 실시예에 따른 동적 속성 데이터는 프레임 데이터 그룹에 포함된 연속되는 프레임 데이터 각각에 대한 속성 데이터들에 대한 궤적 정보, 이동 정보, 속도 정보 및/또는 방향 정보 중 적어도 하나를 포함할 수 있다. 일 실시예에 따른 전처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터들을 중첩하는 알고리즘을 포 함할 수 있다. 일 실시예에 따른 전처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 대해 상술한 포인트 데이터 처리 후, 처리된 프레임 데이터들을 중첩하는 알고리즘을 포함할 수 있다. 이 경우, 일 실시예에 따른 중첩은 프레임 데이터들을 겹쳐 하나의 프레임 데이터를 생성하는 것을 의미할 수 있다. 예를 들어, 일 실시예에 따른 전처리 알고리즘은 포인트 클라우드 데이터들을 중첩하는 알고리즘을 포함할 수 있다. 보다 구체적인 예를 들어, 일 실시예에 따른 전처리 알고리즘은 제1 프레임 데이터인 제1 포인트 클라우드 데이 터에 포함된 포인트 데이터들 및 제2 프레임 데이터인 제2 포인트 클라우드 데이터에 포함된 포인트 데이터들을 중첩하여 하나의 포인트 클라우드 데이터를 생성하는 알고리즘을 포함할 수 있다. 보다 구체적인 예를 들어, 일 실시예에 따른 전처리 알고리즘은 제1 포인트 클라우드 데이터에 포함된 포인트 데이터들과 제2 포인트 클라우드 데이터에 포함된 포인트 데이터들이 모두 나타나는 하나의 포인트 클라우드 데 이터를 생성하는 알고리즘을 포함할 수 있다. 이에 따라, 중첩되어 생성된 포인트 클라우드 데이터에는 중첩에 이용된 포인트 클라우드 데이터들 각각에 포함 된 포인트 데이터들의 값들이 모두 나타날 수 있다. 이에 한정되는 것은 아니며, 일 실시예에 따른 전처리 알고리즘은 제1 포인트 클라우드 데이터에 포함된 포인트 데이터들 중 적어도 일부의 포인트 데이터와 제2 포인트 클라우드 데이터에 포함된 포인트 데이터들 중 적어도 일부의 포인트 데이터가 나타나는 하나의 포인트 클라우드 데이터를 생성하는 알고리즘을 포함할 수 있다. 이에 따라, 중첩되어 생성된 포인트 클라우드 데이터에는 중첩에 이용된 포인트 클라우드 데이터들 각각에 포함 된 포인트 데이터들 중 적어도 일부의 포인트 데이터들의 값들이 나타날 수 있다. 한편, 일 실시예에 따른 전처리 알고리즘은 포인트 클라우드 데이터에 대해 상술한 포인트 데이터 처리 후, 처 리된 포인트 클라우드 데이터들을 중첩하는 알고리즘을 포함할 수 있다. 보다 구체적인 예를 들어, 일 실시예에 따른 전처리 알고리즘은 제1 프레임 데이터인 제1 포인트 클라우드 데이 터에 대해 포인트 데이터 처리 후, 처리된 제1 포인트 클라우드 데이터에 포함된 포인트 데이터들 및 제2 프레 임 데이터인 제2 포인트 클라우드 데이터에 대해 포인트 데이터 처리 후, 처리된 제2 포인트 클라우드 데이터에 포함된 포인트 데이터들을 중첩하여 하나의 포인트 클라우드 데이터를 생성하는 알고리즘을 포함할 수 있다. 보다 구체적인 예를 들어, 일 실시예에 따른 전처리 알고리즘은 처리된 제1 포인트 클라우드 데이터에 포함된 포인트 데이터들과 처리된 제2 포인트 클라우드 데이터에 포함된 포인트 데이터들이 모두 나타나는 하나의 포인 트 클라우드 데이터를 생성하는 알고리즘을 포함할 수 있다. 이에 따라, 중첩되어 생성된 포인트 클라우드 데이터에는 중첩에 이용된 처리된 포인트 클라우드 데이터들 각각 에 포함된 포인트 데이터들의 값들이 모두 나타날 수 있다. 이에 한정되는 것은 아니며, 일 실시예에 따른 전처리 알고리즘은 제1 포인트 클라우드 데이터에 대해 포인트 데이터 처리 후, 처리된 제1 포인트 클라우드 데이터에 포함된 포인트 데이터들 중 적어도 일부의 포인트 데이 터와 제2 포인트 클라우드 데이터에 대해 포인트 데이터 처리 후, 처리된 제2 포인트 클라우드 데이터에 포함된 포인트 데이터들 중 적어도 일부의 포인트 데이터가 나타나는 하나의 포인트 클라우드 데이터를 생성하는 알고 리즘을 포함할 수 있다. 이에 따라, 중첩되어 생성된 포인트 클라우드 데이터에는 중첩에 이용된 처리된 포인트 클라우드 데이터들 각각 에 포함된 포인트 데이터들 중 적어도 일부의 포인트 데이터들의 값들이 나타날 수 있다. 이에 한정되는 것은 아니며, 일 실시예에 따른 데이터 중첩은 통상적으로 데이터 중첩으로 이해되는 다양한 데 이터 처리 방법을 의미할 수 있다. 일 실시예에 따른 전처리 알고리즘은 프레임 데이터 그룹에 데이터를 태깅하는 알고리즘을 포함할 수 있다. 일 실시예에 따른 태깅은 데이터에 레이블 또는 태그를 부여하는 과정을 의미할 수 있으며, 태깅은 인공지능 모 델 학습 과정에서 인공지능 모델이 해당 데이터를 이해하고 활용할 수 있도록 도움을 주기 위해 수행될 수 있다. 보다 구체적으로, 일 실시예에 따른 전처리 알고리즘은 프레임 데이터 그룹에 시간 정보를 태깅하는 알고리즘을 포함할 수 있다.일 실시예에 따른 전처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 매칭 되는 시간 정보에 기초하여 결정된 시간 정보를 프레임 데이터 그룹에 태깅하는 알고리즘을 포함할 수 있다. 일 실시예에 따른 시간 정보는 프레임 데이터 그룹에 포함된 첫 번째 프레임 데이터에 매칭된 시간 정보일 수 있다. 또는, 시간 정보는 프레임 데이터 그룹에 포함된 마지막 프레임 데이터에 매칭된 시간 정보일 수 있다. 또는, 시간 정보는 프레임 데이터 그룹에 포함된 프레임 데이터들 각각에 매칭된 시간 정보의 중간 값일 수 있 으며, 이에 한정되지 않는다. 또는, 일 실시예에 따른 전처리 알고리즘은 프레임 데이터 그룹에 사용자 정보를 태깅하는 알고리즘을 포함할 수 있다. 일 실시예에 따른 사용자 정보는 사용자를 구별하기 위한 정보일 수 있다. 예를 들어 사용자 정보는 사용자 번 호, 사용자 기호, 사용자 이름, 사용자 키워드 등 사용자를 특정할 수 있는 다양한 종류의 정보를 포함할 수 있 으며, 전술한 예에 한정되지 않는다. 일 실시예에 따른 전처리 알고리즘은 프레임 데이터 그룹에 포함된 프레임 데이터 각각에 대해, 프레임 데이터 에 포함된 포인트 데이터들의 특징 및 사용자 별 특징에 기초하여 사용자 정보를 판단하고, 판단된 사용자 정보 를 프레임 데이터 그룹에 태깅하는 알고리즘을 포함할 수 있다. 예를 들어, 일 실시예에 따른 전처리 알고리즘은 포인트 클라우드 데이터에 포함된 포인트 데이터들의 특징 및 사용자 별 특징에 기초하여 사용자 정보를 판단하고, 판단된 사용자 정보를 프레임 데이터 그룹에 태깅하는 알 고리즘을 포함할 수 있다. 일 실시예에 따른 사용자 정보는 프레임 데이터 그룹에 포함된 첫 번째 프레임 데이터로부터 판단된 사용자 정 보일 수 있다. 또는, 사용자 정보는 프레임 데이터 그룹에 포함된 마지막 프레임 데이터로부터 판단된 사용자 정보일 수 있다. 또는, 사용자 정보는 프레임 데이터 그룹에 포함된 프레임 데이터들 각각으로부터 판단된 사용 자 정보 중 가장 많이 판단된 사용자 정보일 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 학습 입력 데이터를 생성하는 단계(S1040)는 선택된 프레임 데이터 그룹에 나타난 사용자 각 각을 세그먼트하는 전처리를 수행하여 사용자 각각에 대한 학습 입력 데이터를 생성하는 단계를 포함할 수 있다. 일 예로, 학습 입력 데이터를 생성하는 단계(S1040)는 선택된 프레임 데이터 그룹에 나타난 제1 사용자를 세그먼트하는 전처리를 수행하여 제1 사용자에 대한 학습 입력 데이터를 생성하는 단계를 포함할 수 있다. 일 예로, 학습 입력 데이터를 생성하는 단계(S1040)는 선택된 프레임 데이터 그룹에 나타난 제2 사용자를 세그먼트 하는 전처리를 수행하여 제2 사용자에 대한 학습 입력 데이터를 생성하는 단계를 포함할 수 있으며, 이에 한정 되지 않는다.또한, 일 실시예에 따른 학습 출력 데이터를 결정하는 단계(S1050)는 가전기기 데이터의 획득 여부에 기초하여 학습 출력 데이터를 결정하는 단계를 포함할 수 있다. 일 예로, 일 실시예에 따른 학습 출력 데이터를 결정하는 단계(S1050)에서, TV 동작에 대응되는 가전기기데이터 가 획득된 경우, TV 동작에 대응되는 제1 값이 학습 출력 데이터로 결정될 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 학습 출력 데이터를 결정하는 단계(S1050)는 가전기기 데이터에 포함되는 동작 유형 정 보에 기초하여 학습 출력 데이터를 결정하는 단계를 포함할 수 있다. 일 예로, 일 실시예에 따른 학습 출력 데이터를 결정하는 단계(S1050)에서, 획득된 가전기기 데이터에 TV ON에 대응되는 동작 유형 정보가 포함되는 경우, TV ON에 대응되는 제1 값이 학습 출력 데이터로 결정되며, 획득된 가전기기 데이터에 TV OFF에 대응되는 동작 유형 정보가 포함되는 경우, TV OFF에 대응되는 제2 값이 학습 출력 데이터로 결정될 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 학습 출력 데이터를 결정하는 단계(S1050)에 대하여는 상술한 내용들이 적용될 수 있으 므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 학습 데이터를 생성하는 단계(S1060)에서 학습 입력 데이터에 학습 출력 데이터를 할당 한다는 의미는 학습 입력 데이터와 학습 출력 데이터를 매칭시킨다는 의미로 이해될 수 있으며, 인공지능 또는 머신러닝 모델을 학습시키기 위한 학습 입력 데이터와 학습 출력 데이터의 쌍을 만드는 것으로 이해될 수 있으 나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 학습 데이터를 생성하는 단계(S1060)에 대하여는 상술한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 도 5는 일 실시예에 따른 프레임 데이터 그룹을 선택하는 방법을 구체적으로 설명하기 위한 도면이다. 도 5를 참조하면, 일 실시예에 따라 복수의 프레임 데이터 중에서 학습 입력 데이터 생성에 이용되는 프 레임 데이터 그룹을 선택하기 위하여 기준 시점(TR)이 특정될 수 있다. 이 때, 상기 기준 시점(TR)은 가전기기의 동작 시점에 대응되도록 특정될 수 있다. 일 예로, 상기 기준 시점(TR)은 획득된 가전기기 데이터에 포함되는 동작 시점 정보에 대응되도록 특정될 수 있 으나, 이에 한정되지 않는다. 또한, 일 예로, 상기 기준 시점(TR)은 가전기기 데이터가 획득된 시점에 대응되도록 특정될 수 있으나, 이에 한 정되지 않는다. 또한, 이 때, 상기 기준 시점(TR)은 가전기기의 동작 시점을 기초로 특정될 수 있다. 일 예로, 상기 기준 시점(TR)은 획득된 가전기기 데이터에 포함되는 동작 시점 정보를 기초로 계산되어 특정될 수 있다. 보다 구체적으로, 상기 기준 시점(TR)은 획득된 가전기기 데이터에 포함되는 동작 시점 정보를 기초로 제1 기 설정된 시간 이전의 시점으로 특정될 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 상기 기준 시점(TR)은 가전기기 데이터가 획득된 시점을 기초로 계산되어 특정될 수 있다. 보다 구체적으로, 상기 기준 시점(TR)은 가전기기 데이터가 획득된 시점을 기초로 제1 기 설정된 시간 이전의 시점으 로 특정될 수 있으나, 이에 한정되지 않는다. 또한, 도 5를 참조하면, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹은 기준 시점 (TR)보다 과거에 센서에서 획득된 복수의 프레임 데이터로 선택될 수 있다. 이 때, 복수의 프레임 데이터 각각이 센서에서 획득된 시점은 복수의 프레임 데이터 각각에 매칭되는 시점 정보 에 의해 판단될 수 있으나, 이에 한정되지 않는다. 일 예로, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹은 상기 기준 시점(TR)보다 과거인 제1 시점(T1)에 센서에서 획득된 제1 프레임 데이터 내지 제N 시점(TN)에서 센서에서 획득된 제N 프레임 데이터로 선택될 수 있으나, 이에 한정되지 않는다. 또한, 도 5를 참조하면, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹을 선택하기 위하여 기준 시점(TR)을 기초로 특정 시간 구간이 특정될 수 있다. 이 때, 상기 특정 시간 구간은 1초 내지 10초 일 수 있으나, 이에 한정되지 않는다. 일 예로, 상기 특정 시간 구간은 상기 기준 시점(TR)과 상기 기준 시점(TR)으로부터 제1 기 설정된 시간 간격 이전의 시점 사이의 시간 구간으로 특정될 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 상기 특정 시간 구간은 상기 기준 시점(TR)으로부터 제1 기 설정된 시간 간격 이전의 시 점과 상기 기준 시점(TR)으로부터 제2 기 설정된 시간 간격 이전의 시점 사이의 시간 구간으로 특정될 수 있으 나, 이에 한정되지 않는다. 또한, 도 5를 참조하면, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹은 상기 특정 시간 구간내에 센서에서 획득된 복수의 프레임 데이터로 선택될 수 있다. 이 때, 복수의 프레임 데이터 각각이 센서에서 획득된 시점은 복수의 프레임 데이터 각각에 매칭되는 시점 정보 에 의해 판단될 수 있으나, 이에 한정되지 않는다. 일 예로, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹은 상기 특정 시간 구간 내에 포함되는 제1 시점(T1) 내지 제N 시점(TN)에 센서에서 획득된 제1 프레임 데이터 내지 제N 프 레임 데이터로 선택될 수 있으나, 이에 한정되지 않는다. 또한, 도 5를 참조하면, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹을 선택하기 위하여 기준 시점(TR)을 기초로 특정 프레임 데이터가 특정될 수 있다. 일 예로, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹을 선택하기 위하여 상기 기 준 시점(TR)보다 과거인 제N 시점(TN)에 센서에서 획득된 제N 프레임 데이터가 특정 프레임 데이터로 특 정될 수 있으나, 이에 한정되지 않는다. 또한, 도 5를 참조하면, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹은 특정 프레 임 데이터를 기초로 선택될 수 있다. 일 예로, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹은 특정 프레임 데이터인 제N 프레임 데이터로부터 제1 개수 이전까지의 프레임 데이터인 제1 프레임 데이터를 포함하도록 선택 될 수 있으나, 이에 한정되지 않는다. 이 때, 상기 제1 개수는 2개 내지 30개일 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹은 시계열적으로 연속된 프레임 데이터를 포함할 수 있으나, 이에 한정되지 않는다. 일 예로, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹은 제1 프레임 데이터 내지 제N 프레임 데이터를 모두 포함할 수 있으나, 이에 한정되지 않으며, 제1 프레임 데이터 내지 제N 프레임 데이터의 일부 만을 포함할 수 있다. 일 예로, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹은 제1 프레임 데이터 내지 제N 프레임 데이터에 포함되는 제1 프레임 데이터, 제3 프레임 데이터, 제5 프레임 데이터 등 홀수 번째 프레임 데이터들로 선택될 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹은 제1 프레임 데이터 내지 제N 프레임 데이터에 포함되는 제2 프레임 데이터, 제4 프레임 데이터, 제6 프레임 데이터 등 짝수 번째 프레임 데이터들로 선택될 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹은 기 설정된 샘플링 레이트에 기초하여 시계열적으로 연속된 프레임 데이터 중 일부로 선택될 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹은 가전기기의 동작 시점으로부 터 제2 시간 간격 이내에 센서에서 획득된 프레임 데이터를 포함하지 않을 수 있다. 이를 위해, 일 실시예에 따라 상기 기준 시점(TR)은 획득된 가전기기 데이터에 포함되는 동작 시점 정보를 기초 로 상기 제2 시간 간격 이전의 시점으로 특정될 수 있으며, 일 실시예에 따라 상기 기준 시점(TR)은 가전기기 데이터가 획득된 시점을 기초로 상기 제2 시간 간격 이전의 시점으로 특정될 수 있고, 상기 기준 시점(TR)이 가전기기의 동작 시점에 대응되도록 특정되는 경우, 상기 특정 시간 구간이 상기 기준 시점(TR)으로부터 상 기 제2 시간 간격 이전의 시점 까지의 시간 구간으로 특정될 수 있으며, 상기 특정 프레임 데이터가 상기 기준 시점(TR)으로부터 상기 제2 시간 간격 이전에 획득된 프레임 데이터로 특정될 수 있으나, 이에 한정되지 않는다. 이는 선택된 프레임 데이터 그룹이 사용자가 가전기기와 직접 상호작용함에 따른 사용자의 움직임을 반영하지 않기 위함일 수 있다. 즉, 일 실시예에 따라 학습 입력 데이터 생성에 이용되는 프레임 데이터 그룹이 가전기기의 동작 시점으로부터 제2 시간 간격 이내에 센서에서 획득된 프레임 데이터를 포함하지 않도록 선택되는 것은 사용자가 TV를 켜기 위 해 리모컨을 손에 들고 TV를 가리키는 움직임을 수행하는 구간에 대응되는 프레임 데이터를 학습 입력 데이터에 포함시키지 않도록 하기 위함일 수 있다. 도 6은 일 실시예에 따른 학습 데이터 생성 방법에 대하여 설명하기 위한 도면이다. 도 6을 참조하면, 일 실시예에 따른 학습 데이터 생성 방법은 복수의 프레임 데이터를 포함하는 센서 데 이터를 획득하는 단계(S1210), 무동작 트리거 데이터를 획득하는 단계(S1220), 무동작 트리거 데이터에 포함된 트리거 시점 정보를 기초로 센서 데이터에 포함된 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단 계(S1230), 선택된 프레임 데이터 그룹을 기초로 학습 입력 데이터를 생성하는 단계(S1240), 무동작 트리거 데 이터에 기초하여 학습 출력 데이터를 결정하는 단계(S1250) 및 학습 입력 데이터에 학습 출력 데이터를 할당하 여 학습 데이터를 생성하는 단계(S1260) 중 적어도 하나의 단계를 포함할 수 있으나, 이에 한정되지 않는다. 이 때, 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계(S1210), 무동작 트리거 데이터에 포함된 트리거 시점 정보를 기초로 센서 데이터에 포함된 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단 계(S1230), 선택된 프레임 데이터 그룹을 기초로 학습 입력 데이터를 생성하는 단계(S1240), 무동작 트리거 데 이터에 기초하여 학습 출력 데이터를 결정하는 단계(S1250) 및 학습 입력 데이터에 학습 출력 데이터를 할당하 여 학습 데이터를 생성하는 단계(S1260)에 대하여는 상술한 내용들이 적용될 수 있으므로, 중복되는 서술은 생 략하기로 한다. 또한, 도 6을 통해 기술하는 학습 데이터 생성 방법은 무동작에 대응되는 학습 데이터를 생성하기 위한 방법으 로서, 도 4를 통해 기술한 학습데이터 생성 방법과 함께 적용될 수 있다. 일 실시예에 따른 무동작 트리거 데이터를 획득하는 단계(S1220)에서, 상기 무동작 트리거 데이터는 무동작에 대한 학습 입력 데이터를 생성하기 위한 트리거 데이터를 의미할 수 있다. 또한, 일 실시예에 따른 무동작 트리거 데이터를 획득하는 단계(S1220)에서, 상기 무동작 트리거 데이터는 기 설정된 주기에 따라 획득될 수 있다. 일 예로, 일 실시예에 따른 무동작 트리거 데이터를 획득하는 단계(S1220)에서, 상기 무동작 트리거 데이터는 1 시간 간격으로 획득될 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 무동작 트리거 데이터를 획득하는 단계(S1220)에서, 상기 무동작 트리거 데이터는 동적 객체 인식 여부에 기초하여 획득될 수 있다. 일 예로, 일 실시예에 따른 무동작 트리거 데이터를 획득하는 단계(S1220)에서, 상기 무동작 트리거 데이터는 동적 객체가 인식되고, 가전기기 데이터가 획득되지 않는 경우 획득될 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 무동작 트리거 데이터를 획득하는 단계(S1220)에서, 상기 무동작 트리거 데이 터는 동적 객체가 인식된 시점으로부터 제3 시간 경과한 시점에 획득될 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 무동작 트리거 데이터를 획득하는 단계(S1220)에서, 상기 무동작 트리거 데이 터는 동적 객체가 인식된 시점으로부터 제5 시간 이상 이전 및/또는 제4 시간 이상 이후 시점에 획득될 수 있으 나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 무동작 트리거 데이터를 획득하는 단계(S1220)에서, 상기 무동작 트리거 데이 터는 기 설정된 주기에 동적 객체가 인식되는 경우에 획득될 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 무동작 트리거 데이터를 획득하는 단계(S1220)에서, 상기 무동작 트리거 데이터는 임의 의 시점에 획득될 수 있다. 또한, 일 실시예에 따른 무동작 트리거 데이터를 획득하는 단계(S1220)에서, 상기 무동작 트리거 데이터는 가전 기기 데이터의 획득 여부에 기초하여 획득될 수 있다. 일 예로, 일 실시예에 따른 무동작 트리거 데이터를 획득하는 단계(S1220)에서, 상기 무동작 트리거 데이터는 기 설정된 주기에 가전기기 데이터가 획득되는 경우 획득되지 않을 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 무동작 트리거 데이터를 획득하는 단계(S1220)에서, 기 설정된 주기에 제1 가 전기기 데이터가 획득되되 제2 가전기기 데이터가 획득되지 않은 경우 제2 가전기기에 대한 무동작 트리거 데이 터가 획득될 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 무동작 트리거 데이터에 포함된 트리거 시점 정보를 기초로 센서 데이터에 포함된 복수 의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계(S1230)에 대하여는 상술한 가전기기 데이터에 포함된 동작 시점 정보를 기초로 센서 데이터에 포함된 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 무동작 트리거 데이터에 기초하여 학습 출력 데이터를 결정하는 단계(S1250)는 학습 출 력 데이터를 무동작에 대응되는 제2 값으로 결정하는 단계를 포함할 수 있다. 또한, 일 실시예에 따른 무동작 트리거 데이터에 기초하여 학습 출력 데이터를 결정하는 단계(S1250)에 대하여 는 상술한 가전기기 데이터에 기초하여 학습 출력 데이터를 결정하는 단계 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 한편, 상술한 학습 데이터 생성 방법은 센서 데이터가 복수의 프레임 데이터를 포함하는 경우에 적용될 수 있는 내용들에 대해 설명하였으나, 상술한 학습 데이터 생성 방법은 센서 데이터가 복수의 속성 데이터를 포함하는 경우에도 적용될 수 있다. 구체적으로, 일 실시예에 따른 학습 데이터 생성 방법은 복수의 속성 데이터를 포함하는 센서 데이터를 획득하 는 단계, 동작 시점 정보를 포함하는 가전기기 데이터를 획득하는 단계, 가전기기 데이터에 포함된 동작 시점 정보를 기초로 센서 데이터에 포함된 속성 데이터 중 속성 데이터 그룹을 선택하는 단계, 선택된 속성 데이터 그룹을 기초로 학습 입력 데이터를 생성하는 단계, 가전기기 데이터에 기초하여 라벨 값을 결정하는 단계 및 학 습 입력 데이터에 라벨 값을 할당하여 학습 데이터를 생성하는 단계를 포함할 수 있다. 이에 따라, 복수의 프레임 데이터를 포함하는 센서 데이터를 이용하여 학습 데이터를 생성하는 방법에서 설명된 내용 중 복수의 속성 데이터를 포함하는 센서 데이터를 이용하여 학습 데이터를 생성하는 방법에서도 적용될 수 있는 내용은 중복 설명하지 않는다. 이하에서는 복수의 프레임 데이터를 포함하는 센서 데이터를 이용하여 학습 데이터를 생성하는 방법과 복수의 속성 데이터를 포함하는 센서 데이터를 이용하여 학습 데이터를 생성하는 방법에서 서로 달라질 수 있는 부분에 대해서 설명한다. 일 실시예에 따른 속성 데이터는 상술한 바와 같이 하나의 프레임 데이터에 포함되는 서브 포인트 데이터 셋에 대한 클래스 정보, 중심 위치 정보, 사이즈 정보, 형상 정보 및/또는 식별 정보 등 서브 포인트 데이터 셋의 속 성과 관련된 데이터를 의미할 수 있다. 이 경우, 상술한 가전기기 데이터에 포함된 동작 시점 정보를 기초로 센서 데이터에 포함된 복수의 프레임 데이 터 중 프레임 데이터 그룹을 선택하는 단계, 선택된 프레임 데이터 그룹을 기초로 학습 입력 데이터를 생성하는 단계, 가전기기 데이터에 기초하여 라벨 값을 결정하는 단계 및 학습 입력 데이터에 라벨 값을 할당하여 학습 데이터를 생성하는 단계에서 설명한 내용은 복수의 속성 데이터를 포함하는 센서 데이터에 대해서도 적용될 수 있다. 한편, 일 실시예에 따른 프레임 데이터 그룹에 대한 전처리와 관련하여 상술한 내용 중 모든 전처리 방법이 속 성 데이터 그룹에 대해 적용되지 않을 수 있다. 일 실시예에 따른 속성 데이터 그룹의 경우에는 중심 위치 정보 와 관련된 속성 데이터를 포함하는 속성 데이터 그룹에 대해 이동 정보 및/또는 궤적 정보를 산출하는 전처리가수행될 수 있다. 한편, 일 실시예에 따른 속성 데이터는 상술한 바와 같이 복수개의 프레임 데이터에 포함되는 복수개의 서브 포 인트 데이터 셋에 대한 이동 정보, 식별 정보 및/또는 궤적 정보 등 복수개의 프레임 데이터에서 동일한 물체를 표현하는 것으로 간주되는 복수개의 서브 포인트 데이터 셋의 속성과 관련된 데이터를 의미할 수 있다. 이 경우, 복수개의 프레임 데이터에 기초하여 하나의 속성 데이터가 결정되는 바, 상술한 가전기기 데이터에 포 함된 동작 시점 정보를 기초로 센서 데이터에 포함된 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계에서 설명한 내용은 적용되지 않을 수 있다. 일 실시예에 따른 가전기기 데이터에 포함된 동작 시점 정보를 기초로 센서 데이터에 포함된 속성 데이터를 선 택하는 단계는, 동작 시점 정보를 기초로 결정된 기준 시점에 대응되는 프레임 데이터로부터 과거 시점으로의 복수개의 프레임 데이터에 기초하여 생성된 속성 데이터를 선택하는 단계로 수행될 수 있다. 이 경우, 일 실시예에 따른 기준 시점은 동작 시점 정보에 따른 동작 시점일 수 있다. 일 실시예에 따른 기준 시점은 가전기기로부터 가전기기 데이터를 획득한 시점일 수 있다. 일 실시예에 따른 기준 시점은 동작 시점 정 보에 따른 동작 시점으로부터 과거 일정 시간 이전의 시점일 수 있다. 일 실시예에 따른 기준 시점은 동작 시점 정보에 따른 동작 시점으로부터 과거 제2 시간 이전 시점일 수 있으며, 이에 한정되지 않는다. 한편, 이 경우, 일 실시예에 따른 기준 시점에 대응되는 프레임 데이터로부터 과거 시점으로의 복수개의 프레임 데이터는 기준 시점에 대응되는 프레임 데이터로부터 과거 제1 시간 이전까지의 프레임 데이터일 수 있다. 일 실시예에 따른 기준 시점에 대응되는 프레임 데이터로부터 과거 시점으로의 복수개의 프레임 데이터는 기준 시 점에 대응되는 프레임 데이터로부터 과거 제1 개수 이전까지의 프레임 데이터일 수 있으며, 이에 한정되지 않는 다. 한편, 일 실시예에 따른 프레임 데이터 그룹에 대한 전처리와 관련하여 상술한 내용은 복수개의 프레임 데이터 에 기초하여 하나의 속성 데이터가 결정되는 경우에는 적용되지 않을 수 있다. 다시 도 3을 참조하면, 일 실시예에 따른 동작 예측 시스템은 획득된 학습 데이터를 이용하여 동작 예측 모델을 학습시키기 위한 학습 시스템을 포함할 수 있다. 일 실시예에 따른 학습 시스템은 학습 데이터를 이용하여 동작 예측 모델을 학습시켜 학습된 동작 예측 모델을 생성하기 위한 시스템일 수 있으며, 동작 예측 모델 학습 모듈에 의해 구현될 수 있다. 이 때, 동작 예측 모델, 동작 예측 모델 학습 모듈 및 학습된 동작 예측 모델에 대하여는 상술한 내 용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 이하에서는 도 7 내지 도 9를 이용하여 학습 시스템에 대하여 보다 구체적으로 설명한 뒤 다시 동작 예측 시스템에 대하여 설명하기로 한다. 도 7 내지 도 9는 일 실시예에 따른 동작 예측 모델의 학습 방법을 설명하기 위한 도면이다. 도 7을 참조하면, 일 실시예에 따른 동작 예측 모델의 학습 방법은, 학습 트리거를 획득하는 단계(S1310) 및 학습 데이터를 이용하여 동작 예측 모델을 학습시키는 단계(S1320)를 포함할 수 있다. 일 실시예에 따른 학습 트리거를 획득하는 단계(S1310)에서, 상기 학습 트리거는 상술한 방법들에 의해 획득된 학습 데이터를 이용하여 동작 예측 모델을 학습시키기 위한 트리거 신호 또는 트리거 데이터를 의미할 수 있다. 또한, 일 실시예에 따른 학습 트리거를 획득하는 단계(S1310)에서, 상기 학습 트리거는 기 설정된 주기에 따라 획득될 수 있다. 일 예로, 일 실시예에 따른 학습 트리거를 획득하는 단계(S1310)에서, 상기 학습 트리거는 매일 0시에 획득될 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 학습 트리거를 획득하는 단계(S1310)에서, 상기 학습 트리거는 획득된 학습 데이터의 개수에 따라 획득될 수 있다. 일 예로, 일 실시예에 따른 학습 트리거를 획득하는 단계(S1310)에서, 상기 학습 트리거는 획득된 학습 데이터 의 개수가 제1 임계치 이상인 경우 획득될 수 있으나, 이에 한정되지 않는다. 보다 구체적인 예를 들어, 일 실시예에 따른 학습 트리거를 획득하는 단계(S1310)에서, 상기 학습 트리거는 획 득된 학습 데이터의 개수가 100개 이상인 경우 획득될 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 트리거를 획득하는 단계(S1310)에서, 상기 학습 트리거는 획득된 학습 데이터의 개수가 제1 임계치의 배수인 경우 획득될 수 있으나, 이에 한정되지 않는다. 보다 구체적인 예를 들어, 일 실시예에 따른 학습 트리거를 획득하는 단계(S1310)에서, 상기 학습 트리거는 획 득된 학습 데이터의 개수가 100개, 200개, 300개 등 100개의 배수인 경우 획득될 수 있으나, 이에 한정되지 않 는다. 또한, 일 실시예에 따른 동작 예측 모델을 학습시키는 단계(S1320)는 학습 데이터 생성 시스템에서 생성된 학습 데이터를 획득하는 단계를 포함할 수 있다. 일 실시예에 따른 동작 예측 모델을 학습시키는 단계(S1320)는, 미리 저장된 학습되지 않은 동작 예측 모델을 학습시키는 단계를 포함할 수 있다. 일 실시예에 따른 동작 예측 모델을 학습시키는 단계(S1320)는, 가전기기 별로 대응되는 동작 예측 모델을 학습 시키는 단계를 포함할 수 있다. 일 예로, TV의 동작을 예측하기 위한 동작 예측 모델을 학습시키는 단계를 포함 할 수 있다. 일 예로, 프로젝터의 동작을 예측하기 위한 동작 예측 모델을 학습시키는 단계를 포함할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 모델을 학습시키는 단계(S1320)는, 가전기기 별 동작 유형마다 대응되는 동작 예측 모델을 학습시키는 단계를 포함할 수 있다. 일 예로, TV의 켜짐 동작을 예측하는 동작 예측 모델을 학습시키는 단계를 포함할 수 있다. 일 예로 TV의 꺼짐 동작을 예측하는 동작 예측 모델을 학습시키는 단계를 포함할 수 있 으며, 이에 한정되지 않는다. 일 실시예에 따른 동작 예측 모델을 학습시키는 단계(S1320)는, 동작 예측 모델 별 대응되는 학습 데이터를 이 용하여 동작 예측 모델을 학습시키는 단계를 포함할 수 있다. 일 예로, 제1 가전기기와 관련된 라벨 값이 할당 된 학습 데이터를 이용하여 제1 가전기기의 동작을 예측하기 위한 동작 예측 모델을 학습시키는 단계를 포함할 수 있다. 일 예로, 제2 가전기기와 관련된 라벨 값이 할당된 학습 데이터를 이용하여 제2 가전기기의 동작을 예 측하기 위한 동작 예측모델을 학습시키는 단계를 포함할 수 있다. 일 예로, 제1 가전기기의 제1 동작과 관련된 라벨 값이 할당된 학습 데이터를 이용하여 제1 가전기기의 제1 동작을 예측하기 위한 동작 예측 모델을 학습시 키는 단계를 포함할 수 있다. 일 예로, 제1 가전기기의 제2 동작과 관련된 라벨 값이 할당된 학습 데이터를 이 용하여 제1 가전기기의 제2 동작을 예측하기 위한 동작 예측 모델을 학습시키는 단계를 포함할 수 있다. 일 예 로, 제1 가전기기의 제1 동작과 관련된 라벨 값이 할당된 학습 데이터와 제1 가전기기의 무동작에 대응되는 라 벨 값이 할당된 학습 데이터를 이용하여 제1 가전기기의 제1 동작을 예측하기 위한 동작 예측 모델을 학습시키 는 단계를 포함할 수 있으며, 이에 한정되지 않는다. 도 8 및 도 9를 참조하여 동작 예측 모델 학습 방법을 보다 구체적으로 설명한다. 도 8을 참조하면, 동작 예측 모델 학습 방법은 학습 데이터의 개수를 판단하는 단계(S1410), 학습 데이터 의 개수가 기설정된 개수 이상이면 학습 데이터를 이용하여 동작 예측 모델을 학습시키는 단계(S1420) 및 학습 데이터의 개수가 기설정된 개수 미만이면 특정 시간동안 기다리는 단계(S1430)를 포함할 수 있다. 일 실시예에 따른 학습 데이터를 이용하여 동작 예측 모델을 학습시키는 단계(S1420)는 상술한 동작 예측 모델 을 학습시키는 단계에서 설명한 내용이 적용될 수 있는 바, 중복 설명은 생략한다. 일 실시예에 따른 기설정된 개수는 동작 예측 모델에 대응되는 가전기기의 종류에 따라 달라질 수 있다. 일 실 시예에 따른 기설정된 개수는 동작 예측 모델에 대응되는 가전기기의 동작 유형에 따라 달라질 수 있다. 일 예 로, 기설정된 개수는 10개 내지 30개일 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 특정 시간은 기설정된 시간 간격일 수 있다. 일 예로, 특정 시간은 하루일 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 특정 시간은 새로운 학습 데이터가 생성되기까지의 시간일 수 있다. 일 예로, 특정 시간은 학 습 데이터들이 생성된 시점들 사이의 평균 시간 간격일 수 있으며, 이에 한정되지 않는다.일 실시예에 따른 특정 시간동안 기다리는 단계는 새로운 학습 데이터가 생성되었는지 판단하는 단계를 포함할 수 있다. 이 경우, 새로운 학습 데이터가 생성되었다고 판단되면 특정 시간을 기다리는 단계가 수행되었다고 볼 수 있다. 한편, 도 9를 참조하면, 일 실시예에 따른 동작 예측 모델 학습 방법은 학습 데이터를 이용하여 동작 예 측 모델을 학습시키는 단계(S1510), 학습된 모델의 정확도가 임계치 이상인지 판단하는 단계(S1520), 학습된 모 델의 정확도가 임계치 이상인 경우 학습된 동작 예측 모델을 저장하는 단계(S1530), 학습된 모델의 정확도가 임 계치 미만인 경우 학습 데이터를 변경하는 단계(S1540) 및 변경된 학습 데이터를 이용하여 동작 예측 모델을 재 학습하는 단계(S1550)를 포함할 수 있다. 일 실시예에 따른 학습 데이터를 이용하여 동작 예측 모델을 학습시키는 단계(S1510)는 상술한 내용이 적용될 수 있으므로, 중복 설명은 생략한다. 일 실시예에 따른 임계치는 동작 예측 모델에 대응되는 가전기기의 종류에 따라 달라질 수 있다. 일 실시예에 따른 임계치는 동작 예측 모델에 대응되는 가전기기의 동작 유형에 따라 달라질 수 있다. 일 예로, 임계치는 0.7 내지 0.9일 수 있으며, 이에 한정되지 않는다. 일 실시예에 따른 학습 데이터를 변경하는 단계(S1540)는 새로운 학습 데이터를 획득하는 단계를 포함할 수 있 다. 일 예로, 학습 데이터를 변경하는 단계(S1540)는 학습 데이터 생성 시스템이 생성한 학습 데이터 중에 동작 예측 모델 학습에 이용되지 않은 학습 데이터를 획득하는 단계를 포함할 수 있다. 일 예로, 학습 데이터를 변경 하는 단계(S1540)는 새로운 학습 데이터가 생성되기까지 대기하는 단계 및 새로 생성된 학습 데이터를 획득하는 단계를 포함할 수 있다. 일 실시예에 따른 학습 데이터를 변경하는 단계(S1540)는 동작 예측 모델 학습에 이용된 학습 데이터 중 적어도 일부를 제외하는 단계를 포함할 수 있다. 일 예로, 학습 데이터를 변경하는 단계(S1540)는 동작 예측 모델 학습 에 이용된 학습 데이터 중 가장 오래 전에 생성된 학습 데이터를 제외하는 단계를 포함할 수 있다. 일 실시예에 따른 동작 예측 모델을 재학습시키는 단계(S1550)는 변경된 학습 데이터를 이용하여 학습된 동작 예측 모델을 추가 학습시키는 단계를 포함할 수 있다. 일 실시예에 따른 동작 예측 모델을 재학습시키는 단계(S1550)는 변경된 학습 데이터를 이용하여 새로운 동작 예측 모델을 학습시키는 단계를 포함할 수 있다. 상술한 일 실시예에 따른 동작 예측 모델 학습 방법은 동작 예측 모델 학습 모듈에서 수행될 수 있다. 다시 도 3을 참조하면, 일 실시예에 따른 동작 예측 시스템은 센서로부터 획득된 센서 데이터 및 학습된 동작 예측 모델을 이용하여 동작 예측 정보를 생성하기 위한 예측 시스템을 포함할 수 있다. 일 실시예에 따른 예측 시스템은 센서 데이터 및 학습된 동작 예측 모델을 이용하여 동작 예측 정보를 생성하기 위한 시스템일 수 있으며, 동작 예측 모듈에 의해 구현될 수 있다. 이 때, 상기 센서 데이터, 상기 학습된 동작 예측 모델, 상기 동작 예측 정보 및 동작 예측 모 듈에 대하여는 상술한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 이 때, 상기 센서 데이터는 상기 센서로부터 획득된 센서 데이터의 일부를 의미할 수 있 으며, 센서 데이터 중 일 실시예에 따른 예측 시스템에서 동작 예측 정보를 생성하기 위해 이용 되는 일부를 특정하여 설명하기 위해 구분되어 설명될 수 있으나, 이에 한정되지 않는다. 또한, 이 때, 상기 센서 데이터는 상기 학습된 동작 예측 모델이 학습 및/또는 생성된 후에 상기 센 서로부터 획득된 센서 데이터를 의미할 수 있으나, 이에 한정되지 않는다. 이하에서는 도 10 내지 도 12를 이용하여, 예측 시스템에 대하여 보다 구체적으로 설명한 뒤 다시 동작 예 측 시스템에 대하여 설명하기로 한다. 도 10은 일 실시예에 따른 동작 제어 정보 생성 방법에 대하여 설명하기 위한 도면이다. 도 10을 참조하면, 일 실시예에 따른 동작 제어 정보 생성 방법은 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계(S1610), 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계(S1620), 선택된 프레임 데이터 그룹을 기초로 예측 입력 데이터를 생성하는 단계(S1630), 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 동작 예측 정보를 획득하는 단계(S1640) 및 동작 예측 정보에 기초하여 동작 제어 정보를 생성 하는 단계(S1650) 중 적어도 하나의 단계를 포함할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계(S1610)에서, 상기 복수의 프 레임 데이터를 포함하는 센서 데이터에 대하여는 상술한 센서 데이터에 관한 내용들이 적용될 수 있으므로, 중 복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계(S1610)에서, 상기 복수 의 프레임 데이터를 포함하는 센서 데이터는 학습된 동작 예측 모델이 학습 또는 생성된 후 획득된 프레임 데이 터를 포함할 수 있다. 또한, 일 실시예에 따른 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계(S1620)에 대하여는 상술 한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계(S1620)에서, 프레임 데 이터 그룹에 포함되는 프레임 데이터의 개수는 학습 데이터 생성을 위한 프레임 데이터 그룹에 포함되는 프레임 데이터의 개수와 동일할 수 있다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹을 기초로 예측 입력 데이터를 생성하는 단계(S1630)에 대하 여는 선택된 프레임 데이터 그룹을 기초로 학습 입력 데이터를 생성하는 단계 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 동작 예측 정보를 획득하는 단 계(S1640)에서 상기 예측 입력 데이터는 상술한 학습 입력 데이터와 동일한 포맷으로 제공될 수 있다. 또한, 일 실시예에 따른 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 동작 예측 정보를 획득하는 단 계(S1640)에서, 동작 예측 정보는 확률 값으로 제공될 수 있다. 일 예로, 일 실시예에 따른 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 동작 예측 정보를 획득하는 단계(S1640)에서, 동작 예측 정보는 TV ON에 대한 확률 값으로 제공될 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 동작 예측 정보를 획득하는 단 계(S1640)에서, 동작 예측 정보는 분류 값으로 제공될 수 있다. 일 예로, 일 실시예에 따른 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 동작 예측 정보를 획득하는 단계(S1640)에서, 동작 예측 정보는 TV ON에 대응되는 분류 값으로 제공될 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 동작 예측 정보에 기초하여 동작 제어 정보를 생성하는 단계(S1650)에서, 동작 제어 정 보는 가전기기를 동작 시키기 위한 정보를 포함할 수 있다. 일 예로, 일 실시예에 따른 동작 예측 정보에 기초하여 동작 제어 정보를 생성하는 단계(S1650)에서, 동작 제어 정보는 TV를 ON 시키기 위한 정보를 포함할 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 동작 예측 정보에 기초하여 동작 제어 정보를 생성하는 단계(S1650)에서, 동작 제어 정 보는 가전기기 동작 여부에 대한 사용자의 응답을 요청하기 위한 정보를 포함할 수 있다. 일 예로, 일 실시예에 따른 동작 예측 정보에 기초하여 동작 제어 정보를 생성하는 단계(S1650)에서, 동작 제어 정보는 TV를 동작 시킬지 여부에 대한 선택을 위한 적어도 하나의 메시지를 포함할 수 있으나, 이에 한정되지 않는다. 이 때, 상기 적어도 하나의 메시지는 다양한 방식으로 출력될 수 있다. 일 예로, 상기 적어도 하나의 메시지는 스피커, 디스플레이 등을 통해 출력될 수 있으며, 사용자 단말에서 상기 적어도 하나의 메시지가 출력되도록 사용자 단말에 적어도 하나의 정보를 전송하는 방식으로 출력될 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 동작 예측 정보에 기초하여 동작 제어 정보를 생성하는 단계(S1650)에서, 동작 제어 정 보는 연속된 예측 입력 데이터에 대한 동작 예측 정보가 기 설정된 횟수 이상 제1 값으로 분류되는 경우 생성될 수 있다. 일 예로, 일 실시예에 따른 동작 예측 정보에 기초하여 동작 제어 정보를 생성하는 단계(S1650)에서, 동작 제어 정보는 연속된 예측 입력 데이터에 대한 동작 예측 정보가 적어도 5회 이상 TV ON에 대응되는 값으로 분류되는 경우 생성될 수 있으나, 이에 한정되지 않는다. 또한, 이 때, 상기 연속된 예측 입력 데이터는 슬라이딩 윈도우 방식으로 선택된 복수의 연속된 프레임 데이터 그룹 각각으로부터 생성되는 예측 입력 데이터들을 의미할 수 있다. 또한, 일 실시예에 따른 동작 예측 정보에 기초하여 동작 제어 정보를 생성하는 단계(S1650)에서, 동작 제어 정 보는 연속된 예측 입력 데이터에 대한 동작 예측 정보의 평균 값이 임계치 이상인 경우 생성될 수 있다. 도 11은 일 실시예에 따른 동작 제어 정보 생성 방법에 대하여 설명하기 위한 도면이다. 도 11을 참조하면, 일 실시예에 따른 동작 제어 정보 생성 방법은 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계(S1710), 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계(S1720), 가전기 기가 동작될지 여부를 판단하는 단계(S1730), 가전기기가 동작될 것으로 판단되면 선택된 프레임 데이터 그룹을 기초로 예측 입력 데이터를 생성하는 단계(S1740), 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 동작 예측 정보를 획득하는 단계(S1750) 및 동작 예측 정보에 기초하여 동작 제어 정보를 생성하는 단계(S1760) 중 적어도 하나의 단계를 포함할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계(S1710)에서, 상기 복수의 프 레임 데이터를 포함하는 센서 데이터에 대하여는 상술한 센서 데이터에 관한 내용들이 적용될 수 있으므로, 중 복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계(S1710)에서, 상기 복수 의 프레임 데이터를 포함하는 센서 데이터는 학습된 동작 예측 모델이 학습 또는 생성된 후 획득된 프레임 데이 터를 포함할 수 있다. 또한, 일 실시예에 따른 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계(S1720)에 대하여는 상술 한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계(S1720)에서, 프레임 데 이터 그룹에 포함되는 프레임 데이터의 개수는 학습 데이터 생성을 위한 프레임 데이터 그룹에 포함되는 프레임 데이터의 개수와 동일할 수 있다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹에 기초하여 가전기기가 동작될지 여부를 판단하는 단계 (S1730)에서, 가전기기가 동작될지 여부는 선택된 프레임 데이터 그룹에 기초하여 판단될 수 있다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹에 기초하여 가전기기가 동작될지 여부를 판단하는 단계 (S1730)에서, 가전기기가 동작될지 여부는 선택된 프레임 데이터 그룹에 포함된 프레임 데이터에 동적 객체가 인식되는지 및/또는 나타나는지 여부에 기초하여 판단될 수 있다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹에 기초하여 가전기기가 동작될지 여부를 판단하는 단계 (S1730)에서, 가전기기가 동작될지 여부는 선택된 프레임 데이터 그룹에 포함된 프레임 데이터에 동적 객체가 인식되면 가전기기가 동작될 것으로 판단될 수 있다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹에 기초하여 가전기기가 동작될지 여부를 판단하는 단계 (S1730)에서, 가전기기가 동작될지 여부는 선택된 프레임 데이터 그룹에 포함된 프레임 데이터에 동적 객체가 인식되고, 동적 객체가 관심 영역(Region of interest, ROI) 내에 위치하는지 여부에 기초하여 판단될 수 있다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹에 기초하여 가전기기가 동작될지 여부를 판단하는 단계 (S1730)에서, 가전기기가 동작될지 여부는 선택된 프레임 데이터 그룹에 포함된 프레임 데이터에 동적 객체가 인식되고, 동적 객체가 관심 영역(Region of interest, ROI) 내에 위치하면 가전기기가 동작될 것으로 판단될 수 있다. 이때, 관심 영역은 동작 예측 모델의 학습에 이용된 학습 입력 데이터를 생성하기 위해 이용된 프레임 데이터들 상에서 동적 객체가 나타나는 영역에 기초하여 결정될 수 있다. 이때, 관심 영역은 동작 예측 모델의 학습에 이용된 학습 입력 데이터를 생성하기 위해 이용된 프레임 데이터들 상에서 동적 객체가 나타난 히트맵에 기초하여 결정될 수 있으며, 이에 한정되지 않는다. 또한, 일 실시예에 따른 가전기기가 동작될 것으로 판단되면 선택된 프레임 데이터 그룹을 기초로 예측 입력 데 이터를 생성하는 단계(S1740)에 대하여는 선택된 프레임 데이터 그룹을 기초로 학습 입력 데이터를 생성하는 단 계 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 동작 예측 정보를 획득하는 단 계(S1750)에서 상기 예측 입력 데이터는 상술한 학습 입력 데이터와 동일한 포맷으로 제공될 수 있다. 또한, 일 실시예에 따른 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 동작 예측 정보를 획득하는 단 계(S1750)에 대하여는 상술한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 동작 예측 정보에 기초하여 동작 제어 정보를 생성하는 단계(S1760)에 대하여는 상술한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 도 12는 일 실시예에 따른 동작 제어 정보 생성 방법에 대하여 설명하기 위한 도면이다. 도 12를 참조하면, 일 실시예에 따른 동작 제어 정보 생성 방법은 가전기기가 동작될지 여부를 판단하는 단계(S1810), 가전기기가 동작될 것으로 판단되면 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단 계(S1820), 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계(S1830), 선택된 프레임 데이터 그룹 을 기초로 예측 입력 데이터를 생성하는 단계(S1840), 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 동작 예측 정보를 획득하는 단계(S1850) 및 동작 예측 정보에 기초하여 동작 제어 정보를 생성하는 단계(S1860) 중 적어도 하나의 단계를 포함할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 선택된 프레임 데이터 그룹에 기초하여 가전기기가 동작될지 여부를 판단하는 단계(S1810)에 서, 가전기기가 동작될지 여부는 현재 시점에 기초하여 판단될 수 있다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹에 기초하여 가전기기가 동작될지 여부를 판단하는 단계 (S1810)에서, 가전기기가 동작될지 여부는 현재 시점이 가전기기의 동작 시간 내인지에 기초하여 판단될 수 있 다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹에 기초하여 가전기기가 동작될지 여부를 판단하는 단계 (S1810)에서, 가전기기가 동작될지 여부는 현재 시점이 가전기기의 동작 시간 내이면 가전기기가 동작될 것으로 판단될 수 있다. 이때, 가전기기의 동작 시간은 동작 예측 모델의 학습에 이용된 학습 입력 데이터를 생성하기 위해 이용된 프레 임 데이터들에 대응되는 시점에 기초하여 결정될 수 있다. 예를 들어, 동작 예측 모델의 학습에 이용된 학습 입력 데이터를 생성하기 위해 이용된 프레임 데이터들에 대응 되는 시점들이 낮 시간대인 경우, 가전기기의 동작 시간은 낮 시간대로 결정될 수 있다. 예를 들어, 동작 예측 모델의 학습에 이용된 학습 입력 데이터를 생성하기 위해 이용된 프레임 데이터들에 대응 되는 시점들이 밤 시간대인 경우, 가전기기의 동작 시간은 밤 시간대로 결정될 수 있으며, 이에 한정되지 않는 다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹에 기초하여 가전기기가 동작될지 여부를 판단하는 단계 (S1810)에서, 가전기기가 동작될지 여부는 현재 가전기기의 상태에 기초하여 판단될 수 있다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹에 기초하여 가전기기가 동작될지 여부를 판단하는 단계 (S1810)에서, 가전기기가 동작될지 여부는 현재 가전기기의 상태에 기초하여 판단될 수 있다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹에 기초하여 가전기기가 동작될지 여부를 판단하는 단계 (S1810)에서, 가전기기가 동작될지 여부는 현재 가전기기의 상태가 동작 수행 상태인지 여부에 기초하여 판단될 수 있다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹에 기초하여 가전기기가 동작될지 여부를 판단하는 단계 (S1810)에서, 가전기기가 동작될지 여부는 현재 가전기기의 상태가 무동작 상태인 경우 가전기기가 동작될 것으 로 판단될 수 있다. 예를 들어, 학습된 동작 예측 모델이 TV의 켜짐 동작을 예측하는 모델인 경우, 현재 TV의 상태가 꺼짐 상태이면 가전기기의 켜짐 동작이 수행될 것으로 판단될 수 있다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹에 기초하여 가전기기가 동작될지 여부를 판단하는 단계 (S1810)에서, 가전기기가 동작될지 여부는 현재 가전기기의 상태가 동작 수행 상태인 경우 가전기기가 동작되지 않을 것으로 판단될 수 있다. 예를 들어, 학습된 동작 예측 모델이 TV의 켜짐 동작을 예측하는 모델인 경우, 현재 TV의 상태가 켜짐 상태이면 가전기기의 켜짐 동작이 수행되지 않을 것으로 판단될 수 있다. 또한, 일 실시예에 따른 가전기기가 동작될 것으로 판단되면 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계(S1820)에서, 상기 복수의 프레임 데이터를 포함하는 센서 데이터에 대하여는 상술한 센서 데이터 에 관한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계(S1820)에서, 상기 복수 의 프레임 데이터를 포함하는 센서 데이터는 학습된 동작 예측 모델이 학습 또는 생성된 후 획득된 프레임 데이 터를 포함할 수 있다. 또한, 일 실시예에 따른 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계(S1830)에 대하여는 상술 한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계(S1830)에서, 프레임 데 이터 그룹에 포함되는 프레임 데이터의 개수는 학습 데이터 생성을 위한 프레임 데이터 그룹에 포함되는 프레임 데이터의 개수와 동일할 수 있다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹을 기초로 예측 입력 데이터를 생성하는 단계(S1840)에 대하 여는 선택된 프레임 데이터 그룹을 기초로 학습 입력 데이터를 생성하는 단계 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 동작 예측 정보를 획득하는 단 계(S1850)에서 상기 예측 입력 데이터는 상술한 학습 입력 데이터와 동일한 포맷으로 제공될 수 있다. 또한, 일 실시예에 따른 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 동작 예측 정보를 획득하는 단 계(S1850)에 대하여는 상술한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 동작 예측 정보에 기초하여 동작 제어 정보를 생성하는 단계(S1860)에 대하여는 상술한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 다시 도 3을 참조하면, 일 실시예에 따른 동작 예측 시스템은 학습 데이터 및 학습된 동작 예측 모델의 버 전 관리 시스템을 더 포함할 수 있다. 사용자가 특정 가전기기에 대한 상호작용을 하는 동작 패턴은 시간이 지남에 따라 변경될 수 있다. 따라서, 특정 시점에 사용자의 동작 패턴을 기초로 특정 가전기기에 대한 상호 작용을 예측하는 모델이 정확한 예측을 하더라도, 시간이 지나며 사용자의 생활 패턴이 변경됨에 따라 부정확한 예측이 빈번하게 발생될 수 있 다. 결국, 변화하는 사용자의 생활 패턴에 대응하기 위하여 학습 데이터 및 학습된 동작 예측 모델의 버전을 관리하 기 위한 시스템이 필요할 수 있다. 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 학습된 동작 예측 모델이 생성 또는 학습된 후에도 학습 데이터를 수집할 수 있다. 이 때, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템이 학습 데이터를 수 집하는 방법에 대하여는 상술한 학습 데이터 생성 방법 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다.또한, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 사용자의 피드백에 기초하여 학습 데이터를 수집할 수 있다. 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 제1 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 생성된 제1 동작 예측 정보가 TV ON에 대응되는 값으로 획득되어 TV가 ON 된 후 사용자가 바로 TV를 OFF 시킨 경우 제1 예측 입력 데이터를 학습 입력 데이터로 하며 TV OFF에 대응되는 값을 학습 출력 데이터로 하는 학습 데이터를 수집할 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 제1 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 생성된 제1 동작 예측 정보가 TV ON에 대응되는 값으로 획득 되어 TV를 동작시킬지 여부에 대한 메시지를 출력하고, 이에 대한 사용자의 응답이 부정인 경우, 제1 예측 입력 데이터를 학습 입력 데이터로 하며 TV OFF에 대응되는 값을 학습 출력 데이터로 하는 학습 데이터를 수집할 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 제1 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 생성된 제1 동작 예측 정보가 TV ON에 대응되는 값으로 획득 되어 TV가 ON 된 후 TV가 일정 시간동안 OFF 되지 않은 경우 제1 예측 입력 데이터를 학습 입력 데이터로 하며 TV ON에 대응되는 값을 학습 출력 데이터로 하는 학습 데이터를 수집할 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 제1 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 생성된 제1 동작 예측 정보가 TV ON에 대응되는 값으로 획득 되어 TV를 동작 시킬지 여부에 대한 메시지를 출력하고, 이에 대한 사용자의 응답이 긍정인 경우, 제1 예측 입 력 데이터를 학습 입력 데이터로 하며 TV ON에 대응되는 값을 학습 출력 데이터로 하는 학습 데이터를 수집할 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 수집된 학습 데이터 를 이용하여 학습 데이터의 버전을 관리할 수 있다. 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 학습 데이터 세 트에 포함되는 학습 데이터의 개수가 유지되도록 수집된 학습 데이터를 추가하되, 시간적으로 오래된 학습 데이 터부터 삭제하는 방식으로 학습 데이터의 버전을 관리할 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 학습 데이 터 세트에 포함되는 학습 데이터의 개수가 확장되도록 수집된 학습 데이터를 추가하는 방식으로 학습 데이터의 버전을 관리할 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 학습 데이 터 세트에 포함되는 학습 데이터들이 획득된 시점이 기 설정된 기간 이내가 되도록 학습 데이터의 버전을 관리 할 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 갱신된 학습 데이터 를 이용하여 새로운 학습된 동작 예측 모델을 생성하거나 학습된 동작 예측 모델을 재학습하여 학습된 동작 예 측 모델의 버전을 관리할 수 있다. 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 갱신된 학습 데 이터를 이용하여 학습되지 않은 동작 예측 모델을 학습시켜 새로운 버전의 학습된 동작 예측 모델을 생성할 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 갱신된 학 습 데이터를 이용하여 학습된 동작 예측 모델을 재학습시켜 새로운 버전의 학습된 동작 예측 모델을 생성할 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 동작 예측 모델의 버전 관리를 위한 트리거가 획득되는 경우 동작 예측 모델의 버전을 변경시킬 수 있다. 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 기 설정된 주기 에 따라 동작 예측 모델의 버전 관리를 위한 트리거가 획득되면 갱신된 학습 데이터를 이용하여 새로운 버전의 학습된 동작 예측 모델을 생성할 수 있으나, 이에 한정되지 않는다.이 때, 기 설정된 주기는 1년일 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 학습된 동 작 예측 모델의 정확도가 임계치 이하가 되는 경우에 동작 예측 모델의 버전 관리를 위한 트리거가 획득되면 갱 신된 학습 데이터를 이용하여 새로운 버전의 학습된 동작 예측 모델을 생성할 수 있으나, 이에 한정되지 않는다. 이 때, 임계치는 60% 일 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 갱신된 학 습 데이터의 수가 임계치 이상이 되는 경우 동작 예측 모델의 버전 관리를 위한 트리거가 획득되면 갱신된 학습 데이터를 이용하여 새로운 버전의 학습된 동작 예측 모델을 생성할 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 새로운 가 전기기에 대한 학습 데이터가 획득되는 경우 동작 예측 모델의 버전 관리를 위한 트리거가 획득되면 갱신된 학 습 데이터를 이용하여 새로운 버전의 학습된 동작 예측 모델을 생성할 수 있으나, 이에 한정되지 않는다. 이하에서는 도 13 내지 도 16을 참조하여 일 실시예에 따른 동작 예측 시스템에 대하여 설명한다. 도 13은 일 실시예에 따른 동작 예측 시스템을 설명하기 위한 도면이다. 도 13을 참조하면, 일 실시예에 따른 동작 예측 시스템은 센서로부터 획득된 센서 데이터를 기초로 제1 가전기기에 대한 제1 동작 제어 정보 및 제2 가전기기에 대한 제2 동작 제어 정 보를 생성하기 위한 시스템일 수 있다. 일 예로, 일 실시예에 따른 동작 예측 시스템은 라이다 장치로부터 획득된 라이다 데이터를 기초로 TV에 대한 켜짐 정보를 생성하거나 냉장고에 대한 열림 정보를 생성하기 위한 시스템일 수 있으나, 이에 한정되지 않 는다. 이 때, 상기 센서, 상기 센서 데이터에 대하여는 상술한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 이 때, 상기 제1 가전기기, 상기 제2 가전기기, 상기 제1 동작 제어 정보, 상기 제2 동작 제어 정보에 대하여는 상술한 가전기기 및 동작 제어 정보 관련 내용들이 적용될 수 있으므로, 중복 되는 서술은 생략하기로 한다. 다시 도 13을 참조하면, 일 실시예에 따른 동작 예측 시스템은 센서로부터 획득된 센서 데이터 , 제1 가전기기로부터 획득된 제1 가전기기 데이터 및 제2 가전기기로부터 획득된 제2 가전기기 데이터를 기초로 적어도 하나의 동작 예측 모델을 학습시키고, 학습된 동작 예측 모델을 이용하 여 상기 제1 가전기기에 대한 제1 동작 제어 정보 또는 상기 제2 가전기기에 대한 제2 동작 제어 정보를 생성하기 위한 시스템일 수 있다. 일 예로, 일 실시예에 따른 동작 예측 시스템은 라이다 장치로부터 획득된 라이다 데이터, TV 로부터 획 득된 TV 켜짐 정보 및 냉장고로부터 획득된 냉장고 열림 정보를 기초로 적어도 하나의 동작 예측 모델을 학습시 키고 학습된 동작 예측 모델을 이용하여 상기 TV에 대한 켜짐 정보 또는 상기 냉장고에 대한 열림 정보를 생성 하기 위한 시스템일 수 있으나, 이에 한정되지 않는다. 이 때, 상기 제1 가전기기 데이터 및 상기 제2 가전기기 데이터에 대하여는 상술한 가전기기 데이 터와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 다시 도 13을 참조하면, 일 실시예에 따른 동작 예측 시스템은 센서로부터 획득된 센서 데이터 , 제1 가전기기로부터 획득된 제1 가전기기 데이터 및 제2 가전기기로부터 획득된 제2 가전기기 데이터를 기초로 동작 예측 모델을 학습시키기 위하여 적어도 하나의 학습 데이터를 생성하기 위한 학습 데이터 생성 시스템을 포함할 수 있다. 일 실시예에 따른 학습 데이터 생성 시스템은 센서 데이터, 제1 가전기기 데이터 및 제2 가 전기기 데이터를 기초로 제1 학습 데이터 및 제2 학습 데이터를 생성하기 위한 시스템일 수 있으며, 학습 데이터 생성 모듈에 의해 구현될 수 있다.이 때, 센서 데이터, 제1 가전기기 데이터, 제2 가전기기 데이터, 제1 학습 데이터, 제2 학습 데이터 및 학습 데이터 생성 모듈에 대하여는 상술한 내용들이 적용될 수 있으므로, 중복 되는 서술은 생략하기로 한다. 또한, 이 때, 상기 센서 데이터는 상기 센서로부터 획득된 센서 데이터의 일부를 의미할 수 있으며, 센서 데이터 중 일 실시예에 따른 학습 데이터 생성 시스템에서 제1 학습 데이터 또 는 제2 학습 데이터를 생성하기 위해 이용되는 일부를 특정하여 설명하기 위해 구분되어 설명될 수 있으 나, 이에 한정되지 않는다. 또한, 이 때, 상기 제1 가전기기 데이터는 상기 제1 가전기기로부터 획득된 제1 가전기기 데이터 의 일부를 의미할 수 있으며, 제1 가전기기 데이터 중 일 실시예에 따른 학습 데이터 생성 시스템 에서 제1 학습 데이터를 생성하기 위해 이용되는 일부를 특정하여 설명하기 위해 구분되어 설명될 수 있으나, 이에 한정되지 않는다. 또한, 이 때, 상기 제2 가전기기 데이터는 상기 제2 가전기기로부터 획득된 제2 가전기기 데이터 의 일부를 의미할 수 있으며, 제2 가전기기 데이터 중 일 실시예에 따른 학습 데이터 생성 시스템 에서 제2 학습 데이터를 생성하기 위해 이용되는 일부를 특정하여 설명하기 위해 구분되어 설명될 수 있으나, 이에 한정되지 않는다. 이하에서는 도 14를 이용하여, 학습 데이터 생성 시스템에 대하여 보다 구체적으로 설명한 뒤 다시 동작 예측 시스템에 대하여 설명하기로 한다. 도 14는 일 실시예에 따른 학습 데이터 생성 방법에 대하여 설명하기 위한 도면이다. 도 14를 참조하면, 일 실시예에 따른 학습 데이터 생성 방법은 복수의 프레임 데이터를 포함하는 센서 데 이터를 획득하는 단계(S3010), 제1 동작 시점 정보를 포함하는 제1 가전기기 데이터를 획득하는 단계(S3021), 제2 동작 시점 정보를 포함하는 제2 가전기기 데이터를 획득하는 단계(S3022), 제1 가전기기 데이터에 포함된 제1 동작 시점 정보를 기초로 센서 데이터에 포함된 복수의 프레임 데이터 중 제1 프레임 데이터 그룹을 선택하 는 단계(S3031), 제2 가전기기 데이터에 포함된 제2 동작 시점 정보를 기초로 센서 데이터에 포함된 복수의 프 레임 데이터 중 제2 프레임 데이터 그룹을 선택하는 단계(S3032), 선택된 제1 프레임 데이터 그룹을 기초로 제1 학습 입력 데이터를 생성하는 단계(S3041), 선택된 제2 프레임 데이터 그룹을 기초로 제2 학습 입력 데이터를 생성하는 단계(S3042), 제1 가전기기 데이터에 기초하여 제1 학습 출력 데이터를 결정하는 단계(S3051), 제2 가 전기기 데이터에 기초하여 제2 학습 출력 데이터를 결정하는 단계(S3052), 제1 학습 입력 데이터에 제1 학습 출 력 데이터를 할당하여 제1 학습 데이터를 생성하는 단계(S3061) 및 제2 학습 입력 데이터에 제2 학습 출력 데이 터를 할당하여 제2 학습 데이터를 생성하는 단계(S3062) 중 적어도 하나의 단계를 포함할 수 있으나, 이에 한정 되지 않는다. 일 실시예에 따른 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계(S3010)에서, 상기 복수의 프 레임 데이터를 포함하는 센서 데이터에 대하여는 상술한 센서 데이터에 관한 내용들이 적용될 수 있으므로, 중 복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 제1 동작 시점 정보를 포함하는 제1 가전기기 데이터를 획득하는 단계(S3021)에서, 상 기 제1 동작 시점 정보를 포함하는 제1 가전기기 데이터에 대하여는 상술한 가전기기 데이터에 관한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 제2 동작 시점 정보를 포함하는 제2 가전기기 데이터를 획득하는 단계(S3022)에서, 상 기 제2 동작 시점 정보를 포함하는 제2 가전기기 데이터에 대하여는 상술한 가전기기 데이터에 관한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 이 때, 상기 제1 가전기기와 상기 제2 가전기기는 서로 상이할 수 있으며, 상기 제1 가전기기 데이터와 상기 제 2 가전기기 데이터는 서로 상이할 수 있다. 또한, 일 실시예에 따른 제1 가전기기 데이터에 포함된 제1 동작 시점 정보를 기초로 센서 데이터에 포함된 복 수의 프레임 데이터 중 제1 프레임 데이터 그룹을 선택하는 단계(S3031)에 대하여는 상술한 가전기기 데이터에 포함된 동작 시점 정보를 기초로 센서 데이터에 포함된 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 제2 가전기기 데이터에 포함된 제2 동작 시점 정보를 기초로 센서 데이터에 포함된 복 수의 프레임 데이터 중 제2 프레임 데이터 그룹을 선택하는 단계(S3032)에 대하여는 상술한 가전기기 데이터에 포함된 동작 시점 정보를 기초로 센서 데이터에 포함된 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하 는 단계 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 이 때, 상기 제1 프레임 데이터 그룹 및 상기 제2 프레임 데이터 그룹에 포함되는 프레임 데이터의 개수는 동일 할 수 있다. 또한, 이 때, 상기 제1 프레임 데이터 그룹 및 상기 제2 프레임 데이터 그룹에 포함되는 프레임 데이터의 개수 는 서로 상이할 수 있다. 또한, 이 때, 상기 제1 프레임 데이터 그룹 및 상기 제2 프레임 데이터 그룹에 포함되는 프레임 데이터의 개수 는 상기 제1 가전기기 및 상기 제2 가전기기의 종류에 따라 서로 상이할 수 있다. 또한, 일 실시예에 따른 선택된 제1 프레임 데이터 그룹을 기초로 제1 학습 입력 데이터를 생성하는 단계 (S3041)에 대하여는 상술한 프레임 데이터 그룹을 기초로 학습 입력 데이터를 생성하는 단계 및 이와 관련된 내 용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 선택된 제2 프레임 데이터 그룹을 기초로 제2 학습 입력 데이터를 생성하는 단계 (S3042)에 대하여는 상술한 프레임 데이터 그룹을 기초로 학습 입력 데이터를 생성하는 단계 및 이와 관련된 내 용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 이 때, 상기 제1 학습 입력 데이터와 상기 제2 학습 입력 데이터의 포맷은 서로 동일할 수 있다. 또한, 이 때, 상기 제1 학습 입력 데이터와 상기 제2 학습 입력 데이터의 포맷은 서로 상이할 수 있다. 또한, 이 때, 상기 제1 학습 입력 데이터와 상기 제2 학습 입력 데이터의 포맷은 상기 제1 가전기기 및 상기 제 2 가전기기의 종류에 따라 서로 상이할 수 있다. 또한, 이 때, 상기 제1 학습 입력 데이터를 생성하기 위한 전처리와 상기 제2 학습 입력 데이터를 생성하기 위 한 전처리는 서로 동일할 수 있다. 또한, 이 때, 상기 제1 학습 입력 데이터를 생성하기 위한 전처리와 상기 제2 학습 입력 데이터를 생성하기 위 한 전처리는 서로 상이할 수 있다. 또한, 이 때, 상기 제1 학습 입력 데이터를 생성하기 위한 전처리와 상기 제2 학습 입력 데이터를 생성하기 위 한 전처리는 상기 제1 가전기기 및 상기 제2 가전기기의 종류에 따라 서로 상이할 수 있다. 또한, 일 실시예에 따른 제1 가전기기 데이터에 기초하여 제1 학습 출력 데이터를 결정하는 단계(S3051)에 대하 여는 상술한 가전기기 데이터에 기초하여 학습 출력 데이터를 결정하는 단계 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 제2 가전기기 데이터에 기초하여 제2 학습 출력 데이터를 결정하는 단계(S3052)에 대하 여는 상술한 가전기기 데이터에 기초하여 학습 출력 데이터를 결정하는 단계 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 이 때, 상기 제1 학습 출력 데이터와 상기 제2 학습 출력 데이터의 값은 서로 동일할 수 있다. 일 예로, 후술할 제1 학습 데이터와 제2 학습 데이터가 서로 다른 분류 모델의 학습 데이터로 이용되는 경우, 상기 제1 학습 출력 데이터와 상기 제2 학습 출력 데이터는 모두 제1 값 또는 제2 값 일 수 있다. 또한, 이 때, 상기 제1 학습 출력 데이터와 상기 제2 학습 출력 데이터의 값은 서로 상이할 수 있다. 일 예로, 후술할 제1 학습 데이터와 제2 학습 데이터가 동일한 동작 예측 모델의 학습 데이터로 이용되는 경우, 상기 제1 학습 출력 데이터는 제1 가전기기의 동작과 관련된 제1 값 또는 제2 값 일 수 있으며, 상기 제2 학습 출력 데이터는 제2 가전기기의 동작과 관련된 제3 값 또는 제4 값 일 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 제1 학습 입력 데이터에 제1 학습 출력 데이터를 할당하여 제1 학습 데이터를 생성하는 단계(S3061)에 대하여는 상술한 학습 입력 데이터에 학습 출력 데이터를 할당하여 학습 데이터를 생성하는 단계 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다.또한, 일 실시예에 따른 제2 학습 입력 데이터에 제2 학습 출력 데이터를 할당하여 제2 학습 데이터를 생성하는 단계(S3062)에 대하여는 상술한 학습 입력 데이터에 학습 출력 데이터를 할당하여 학습 데이터를 생성하는 단계 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 이 때, 상기 제1 학습 데이터 및 상기 제2 학습 데이터는 서로 다른 동작 예측 모델을 학습시키는데 이용될 수 있다. 일 예로, 상기 제1 학습 데이터는 제1 가전기기에 대한 제1 동작 예측 모델을 학습시키는데 이용될 수 있으며, 상기 제2 학습 데이터는 제2 가전기기에 대한 제2 동작 예측 모델을 학습시키는데 이용될 수 있으나, 이에 한정 되지 않는다. 또한, 이 때, 상기 제1 학습 데이터 및 상기 제2 학습 데이터는 서로 동일한 동작 예측 모델을 학습시키는데 이 용될 수 있다. 일 예로, 상기 제1 학습 데이터 및 상기 제2 학습 데이터는 제1 가전기기 및 제2 가전기기의 동작을 한 번에 예 측하기 위한 동작 예측 모델을 학습시키는데 이용될 수 있으나, 이에 한정되지 않는다. 다시 도 13을 참조하면, 일 실시예에 따른 동작 예측 시스템은 획득된 제1 학습 데이터 및 제2 학 습 데이터를 이용하여 적어도 하나의 동작 예측 모델을 학습시키기 위한 학습 시스템을 포함할 수 있다. 이 때, 일 실시예에 따른 학습 시스템은 제1 학습 데이터를 이용하여 제1 동작 예측 모델을 학습시 켜 제1 학습된 동작 예측 모델을 생성하고, 제2 학습 데이터를 이용하여 제2 동작 예측 모델을 학 습시켜 제2 학습된 동작 예측 모델을 생성하기 위한 시스템일 수 있으며, 동작 예측 모델 학습 모듈 에 의해 구현될 수 있다. 또한, 이 때, 일 실시예에 따른 학습 시스템은 제1 학습 데이터 및 제2 학습 데이터를 이용 하여 동작 예측 모델을 학습시켜 학습된 동작 예측 모델을 생성하기 위한 시스템일 수 있으며, 동작 예측 모델 학습 모듈에 의해 구현될 수 있다. 이 때, 동작 예측 모델, 제1 동작 예측 모델, 제2 동작 예측 모델, 동작 예측 모델 학습 모듈, 학습된 동 작 예측 모델, 제1 학습된 동작 예측 모델 및 제2 학습된 동작 예측 모델에 대하여는 상술한 내용 들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 이하에서는 도 15를 이용하여 학습 시스템에 대하여 보다 구체적으로 설명한 뒤 다시 동작 예측 시스템 에 대하여 설명하기로 한다. 도 15는 일 실시예에 따른 동작 예측 모델의 학습 방법에 대하여 설명하기 위한 도면이다. 도 15를 참조하면, 일 실시예에 따른 동작 예측 모델의 학습 방법은, 제1 학습 트리거를 획득하는 단계 (S3111), 제2 학습 트리거를 획득하는 단계(S3112), 제1 학습 데이터를 이용하여 제1 동작 예측 모델을 학습시 키는 단계(S3121) 및 제2 학습 데이터를 이용하여 제2 동작 예측 모델을 학습시키는 단계(S3122) 중 적어도 하 나의 단계를 포함할 수 있다. 일 실시예에 따른 제1 학습 트리거를 획득하는 단계(S3111)에 대하여는 상술한 학습 트리거를 획득하는 단계 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 제2 학습 트리거를 획득하는 단계(S3112)에 대하여는 상술한 학습 트리거를 획득하는 단계 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 이 때, 상기 제1 학습 트리거가 획득되기 위한 제1 기 설정된 주기는 상기 제2 학습 트리거가 획득되기 위한 제2 기 설정된 주기와 동일할 수 있다. 일 예로, 상기 제1 학습 트리거 및 상기 제2 학습 트리거는 매일 0시에 획득될 수 있으나, 이에 한정되지 않는 다. 또한, 이 때, 상기 제1 학습 트리거가 획득되기 위한 제1 기 설정된 주기는 상기 제2 학습 트리거가 획득되기 위한 제2 기 설정된 주기와 서로 상이할 수 있다. 또한, 이 때, 상기 제1 학습 트리거가 획득되기 위한 제1 학습 데이터의 개수는 상기 제2 학습 트리거가 획득되 기 위한 제2 학습 데이터의 개수와 동일할 수 있다. 또한, 이 때, 상기 제1 학습 트리거가 획득되기 위한 제1 학습 데이터의 개수는 상기 제2 학습 트리거가 획득되 기 위한 제2 학습 데이터의 개수와 서로 상이할 수 있다. 또한, 일 실시예에 따른 제1 학습 데이터를 이용하여 제1 동작 예측 모델을 학습시키는 단계(S3121)에 대하여는 상술한 학습 데이터를 이용하여 동작 예측 모델을 학습시키는 단계 및 이와 관련된 내용들이 적용될 수 있으므 로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 제2 학습 데이터를 이용하여 제2 동작 예측 모델을 학습시키는 단계(S3122)에 대하여는 상술한 학습 데이터를 이용하여 동작 예측 모델을 학습시키는 단계 및 이와 관련된 내용들이 적용될 수 있으므 로, 중복되는 서술은 생략하기로 한다. 또한, 이 때, 상기 제2 학습 데이터는 상기 제1 동작 예측 모델을 학습시키는데 이용되지 않을 수 있다. 또한, 이 때, 상기 제1 학습 데이터는 상기 제2 동작 예측 모델을 학습시키는데 이용되지 않을 수 있다. 또한, 이 때, 상기 제1 학습 데이터는 제1 가전기기와 관련된 데이터 일 수 있으며, 상기 제2 학습 데이터는 제 2 가전기기와 관련된 데이터 일 수 있다. 다시 도 13을 참조하면, 일 실시예에 따른 동작 예측 시스템은 센서로부터 획득된 센서 데이터 , 제1 학습된 동작 예측 모델 및 제2 학습된 동작 예측 모델을 이용하여 제1 동작 예측 정보 및 제2 동작 예측 정보를 생성하기 위한 예측 시스템을 포함할 수 있다. 일 실시예에 따른 예측 시스템은 센서 데이터, 제1 학습된 동작 예측 모델 및 제2 학습된 동 작 예측 모델을 이용하여 제1 동작 예측 정보 및 제2 동작 예측 정보를 생성하기 위한 시스 템일 수 있으며, 동작 예측 모듈에 의해 구현될 수 있다. 또한, 일 실시예에 따른 예측 시스템은 센서 데이터 및 하나의 학습된 동작 예측 모델을 이용하여 제1 동작 예측 정보 및 제2 동작 예측 정보를 생성하기 위한 시스템일 수 있으며, 동작 예측 모듈 에 의해 구현될 수 있다. 이 때, 상기 센서 데이터, 상기 하나의 학습된 동작 예측 모델, 상기 제1 학습된 동작 예측 모델, 상기 제2 학습된 동작 예측 모델, 상기 제1 동작 예측 정보, 상기 제2 동작 예측 정보 및 동 작 예측 모듈에 대하여는 상술한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 이 때, 상기 센서 데이터는 상기 센서로부터 획득된 센서 데이터의 일부를 의미할 수 있으며, 센서 데이터 중 일 실시예에 따른 예측 시스템에서 제1 동작 예측 정보 및 제2 동작 예측 정보를 생성하기 위해 이용되는 일부를 특정하여 설명하기 위해 구분되어 설명될 수 있으나, 이에 한정되지 않는다. 또한, 이 때, 상기 센서 데이터는 상기 제1 학습된 동작 예측 모델 및 상기 제2 학습된 된작 예측 모델이 학습/생성된 후에 상기 센서로부터 획득된 센서 데이터를 의미할 수 있으나, 이에 한 정되지 않는다. 이하에서는 도 16을 이용하여, 예측 시스템에 대하여 보다 구체적으로 설명한 뒤 다시 동작 예측 시스템 에 대하여 설명하기로 한다. 도 16은 일 실시예에 따른 동작 제어 정보 생성 방법에 대하여 설명하기 위한 도면이다. 도 16을 참조하면, 일 실시예에 따른 동작 제어 정보 생성 방법은 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계(S3210), 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계(S3220), 선택된 프레임 데이터 그룹을 기초로 예측 입력 데이터를 생성하는 단계(S3230), 예측 입력 데이터를 제1 학습된 동작 예측 모델에 적용하여 제1 동작 예측 정보를 획득하는 단계(S3241), 예측 입력 데이터를 제2 학습된 동작 예측모델에 적용하여 제2 동작 예측 정보를 획득하는 단계(S3242), 제1 동작 예측 정보에 기초하여 제1 동작 제어 정보를 생성하는 단계(S3251) 및 제2 동작 예측 정보에 기초하여 제2 동작 제어 정보를 생성하는 단계(S3252) 중 적어도 하나의 단계를 포함할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따른 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계(S3210)에서, 상기 복수의 프 레임 데이터를 포함하는 센서 데이터에 대하여는 상술한 센서 데이터에 관한 내용들이 적용될 수 있으므로, 중 복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 복수의 프레임 데이터를 포함하는 센서 데이터를 획득하는 단계(S3210)에서, 상기 복수 의 프레임 데이터를 포함하는 센서 데이터는 제1 학습된 동작 예측 모델 및 제2 학습된 동작 예측 모델이 학습 또는 생성된 후 획득된 프레임 데이터를 포함할 수 있다. 또한, 일 실시예에 따른 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계(S3220)에 대하여는 상술 한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계(S3220)에서, 프레임 데 이터 그룹에 포함되는 프레임 데이터의 개수는 제1 학습 데이터 생성을 위한 프레임 데이터 그룹에 포함되는 프 레임 데이터의 개수와 동일할 수 있다. 또한, 일 실시예에 따른 복수의 프레임 데이터 중 프레임 데이터 그룹을 선택하는 단계(S3220)에서, 프레임 데 이터 그룹에 포함되는 프레임 데이터의 개수는 제2 학습 데이터 생성을 위한 프레임 데이터 그룹에 포함되는 프 레임 데이터의 개수와 동일할 수 있다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹을 기초로 예측 입력 데이터를 생성하는 단계(S3230)에 대하 여는 선택된 프레임 데이터 그룹을 기초로 제1 학습 입력 데이터를 생성하는 단계 및 이와 관련된 내용들이 적 용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 선택된 프레임 데이터 그룹을 기초로 예측 입력 데이터를 생성하는 단계(S3230)에 대하 여는 선택된 프레임 데이터 그룹을 기초로 제2 학습 입력 데이터를 생성하는 단계 및 이와 관련된 내용들이 적 용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 예측 입력 데이터를 제1 학습된 동작 예측 모델에 적용하여 제1 동작 예측 정보를 획득 하는 단계(S3241)에 대하여는 상술한 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 동작 예측 정보를 획득하는 단계 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 예측 입력 데이터를 제2 학습된 동작 예측 모델에 적용하여 제2 동작 예측 정보를 획득 하는 단계(S3242)에 대하여는 상술한 예측 입력 데이터를 학습된 동작 예측 모델에 적용하여 동작 예측 정보를 획득하는 단계 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 이 때, 상기 제1 동작 예측 정보는 제1 가전기기에 대한 동작 예측 정보이며, 상기 제2 동작 예측 정보는 제2 가전기기에 대한 동작 예측 정보일 수 있다. 또한, 이 때, 일 실시예에 따른 예측 입력 데이터를 제1 학습된 동작 예측 모델에 적용하여 제1 동작 예측 정보 를 획득하는 단계(S3241) 및 일 실시예에 따른 예측 입력 데이터를 제2 학습된 동작 예측 모델에 적용하여 제2 동작 예측 정보를 획득하는 단계(S3242)는 동시에 수행될 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 제1 동작 예측 정보에 기초하여 제1 동작 제어 정보를 생성하는 단계(S3251)에 대하여 는 상술한 동작 예측 정보에 기초하여 동작 제어 정보를 생성하는 단계 및 이와 관련된 내용들이 적용될 수 있 으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 제2 동작 예측 정보에 기초하여 제2 동작 제어 정보를 생성하는 단계(S3252)에 대하여 는 상술한 동작 예측 정보에 기초하여 동작 제어 정보를 생성하는 단계 및 이와 관련된 내용들이 적용될 수 있 으므로, 중복되는 서술은 생략하기로 한다. 또한, 이 때, 상기 제1 동작 제어 정보는 제1 가전기기로 전송될 수 있으며, 상기 제2 동작 제어 정보는 제2 가 전기기로 전송될 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 제1 동작 예측 정보에 기초하여 제1 동작 제어 정보를 생성하는 단계(S3251)에서, 제1 동작 제어 정보는 제1 가전기기를 동작시키기 위한 정보를 포함할 수 있다.일 예로, 일 실시예에 따른 제1 동작 예측 정보에 기초하여 제1 동작 제어 정보를 생성하는 단계(S3251)에서, 제1 동작 제어 정보는 TV를 ON 시키기 위한 정보를 포함할 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 제2 동작 예측 정보에 기초하여 제2 동작 제어 정보를 생성하는 단계(S3252)에서, 제2 동작 제어 정보는 제2 가전기기를 동작시키기 위한 정보를 포함할 수 있다. 일 예로, 일 실시예에 따른 제2 동작 예측 정보에 기초하여 제2 동작 제어 정보를 생성하는 단계(S3252)에서, 제2 동작 제어 정보는 냉장고를 열기 위한 정보를 포함할 수 있으나, 이에 한정되지 않는다. 다시 도 13을 참조하면, 일 실시예에 따른 동작 예측 시스템은 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템을 더 포함할 수 있다. 사용자가 특정 가전기기에 대한 상호작용을 하는 동작 패턴은 시간이 지남에 따라 변경될 수 있다. 따라서, 특정 시점에 사용자의 동작 패턴을 기초로 특정 가전기기에 대한 상호 작용을 예측하는 모델이 정확한 예측을 하더라도, 시간이 지나며 사용자의 생활 패턴이 변경됨에 따라 부정확한 예측이 빈번하게 발생될 수 있 다. 결국, 변화하는 사용자의 생활 패턴에 대응하기 위하여 학습 데이터 및 학습된 동작 예측 모델의 버전을 관리하 기 위한 시스템이 필요할 수 있다. 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 제1 학습된 동작 예측 모 델 및 제2 학습된 동작 예측 모델이 생성 또는 학습된 후에도 학습 데이터를 수집할 수 있다. 이 때, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템이 학습 데이터를 수 집하는 방법에 대하여는 상술한 학습 데이터 생성 방법 및 이와 관련된 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 또한, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 사용자의 피드백에 기초하여 학습 데이터를 수집할 수 있다. 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 제1 예측 입력 데이터를 제1 학습된 동작 예측 모델에 적용하여 생성된 제1 동작 예측 정보가 TV ON에 대응되는 값으로 획득되 어 TV가 ON 된 후 사용자가 바로 TV를 OFF 시킨 경우 제1 예측 입력 데이터를 제1 학습 입력 데이터로 하며 TV OFF에 대응되는 값을 제1 학습 출력 데이터로 하는 제1 학습 데이터를 수집할 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 제2 예측 입력 데이터를 제2 학습된 동작 예측 모델에 적용하여 생성된 제2 동작 예측 정보가 냉장고 OPEN에 대응되는 값 으로 획득되어 냉장고가 OPEN 된 후 사용자가 바로 냉장고를 닫은 경우 제2 예측 입력 데이터를 제2 학습 입력 데이터로 하며 냉장고 닫음에 대응되는 값을 제2 학습 출력 데이터로 하는 제2 학습 데이터를 수집할 수 있으나, 이에 한정되지 않는다. 이 때, 사용자가 바로 TV를 OFF 시키거나 사용자가 바로 냉장고를 닫는 것을 판단하기 위한 기준은 서로 상이할 수 있다. 일 예로, 사용자가 바로 TV를 OFF 시켰는가를 판단하기 위한 기간은 10초일 수 있으나, 사용자가 바로 냉장고를 닫았는가를 판단하기 위한 기간은 1초일 수 있다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 제1 예측 입력 데이터를 제1 학습된 동작 예측 모델에 적용하여 생성된 제1 동작 예측 정보가 TV ON에 대응되는 값으로 획득되어 TV를 동작 시킬지 여부에 대한 메시지를 출력하고, 이에 대한 사용자의 응답이 부정인 경우, 제1 예측 입력 데이터를 제1 학습 입력 데이터로 하며 TV OFF에 대응되는 값을 제1 학습 출력 데이터로 하는 제1 학습 데 이터를 수집할 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 제2 예측 입력 데이터를 제2 학습된 동작 예측 모델에 적용하여 생성된 제2 동작 예측 정보가 냉장고 OPEN에 대응되는 값 으로 획득되어 냉장고를 OPEN 시킬지여부에 대한 메시지를 출력하고, 이에 대한 사용자의 응답이 부정인 경우,제2 예측 입력 데이터를 제2 학습 입력 데이터로 하며 냉장고 닫음에 대응되는 값을 제2 학습 출력 데이터로 하 는 제2 학습 데이터를 수집할 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 제1 예측 입력 데이터를 제1 학습된 동작 예측 모델에 적용하여 생성된 제1 동작 예측 정보가 TV ON에 대응되는 값으로 획득되어 TV가 ON 된 후 TV가 일정 시간동안 OFF 되지 않은 경우 제1 예측 입력 데이터를 제1 학습 입력 데이터 로 하며 TV ON에 대응되는 값을 제1 학습 출력 데이터로 하는 제1 학습 데이터를 수집할 수 있으나, 이에 한정 되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 제2 예측 입력 데이터를 제2 학습된 동작 예측 모델에 적용하여 생성된 제2 동작 예측 정보가 냉장고 OPEN에 대응되는 값 으로 획득되어 냉장고가 열린 후 냉장고가 일정 시간동안 닫히지 않은 경우 제2 예측 입력 데이터를 제2 학습 입력 데이터로 하며 냉장고 OPEN에 대응되는 값을 제2 학습 출력 데이터로 하는 제2 학습 데이터를 수집할 수 있으나, 이에 한정되지 않는다. 이 때, 일정 시간의 기준은 서로 상이할 수 있다. 일 예로, TV가 일정 시간 동안 OFF 되지 않았는지를 판단하기 위한 일정 시간은 1분 일 수 있고, 냉장고가 일정 시간동안 닫히지 않았는지를 판단하기 위한 일정 시간은 5초일 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 제1 예측 입력 데이터를 제1 학습된 동작 예측 모델에 적용하여 생성된 제1 동작 예측 정보가 TV ON에 대응되는 값으로 획득되어 TV를 동작 시킬지 여부에 대한 메시지를 출력하고, 이에 대한 사용자의 응답이 긍정인 경우, 제1 예측 입력 데이터를 제1 학습 입력 데이터로 하며 TV ON에 대응되는 값을 제1 학습 출력 데이터로 하는 제1 학습 데 이터를 수집할 수 있으나, 이에 한정되지 않는다. 또한, 일 예로, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템은 제2 예측 입력 데이터를 제2 학습된 동작 예측 모델에 적용하여 생성된 제2 동작 예측 정보가 냉장고 OPEN에 대응되는 값 으로 획득되어 냉장고를 OPEN 시킬지여부에 대한 메시지를 출력하고, 이에 대한 사용자의 긍정이 부정인 경우, 제2 예측 입력 데이터를 제2 학습 입력 데이터로 하며 냉장고 OPEN에 대응되는 값을 제2 학습 출력 데이터로 하 는 제2 학습 데이터를 수집할 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 학습 데이터 및 학습된 동작 예측 모델의 버전 관리 시스템에 대하여는 상술한 내용들이 적용될 수 있으므로, 중복되는 서술은 생략하기로 한다. 이하에서는 본 발명에 따른 다양한 동작 예측 시스템에 대한 구체적인 사용 시나리오들에 대해서 기재하기로 한 다. 사용자 A의 시나리오 사용자 A의 집에 적어도 하나의 라이다 장치가 설치되고, 일 실시예에 따른 동작 예측 시스템 및 동작 예측 시 스템에 의해 제어될 수 있는 TV 가 설치될 수 있다. 사용자 A의 집에 라이다 장치, 동작 예측 시스템 및 TV 가 설치된 후에도 사용자 A는 평소와 동일하게 생활을 하며 지내게 된다. 사용자 A는 평소와 다름없이 TV를 보고 싶을 때 TV를 동작 시키며, TV를 끄고 싶을 때 TV를 끌 수 있다. 사용자 A가 TV를 동작 시키고, TV를 끔에 따라 동작 예측 시스템에 의해 학습 데이터들이 수집될 수 있다. 즉, 사용자 A가 TV를 동작 시키면, 이에 대응되는 라이다 데이터들이 학습 입력 데이터로 수집될 수 있고, 사용자 A의 TV에 대한 동작이 학습 출력 데이터로 매칭 될 수 있다. 이렇게 일정 기간 동안 학습 데이터들이 수집됨에 따라 동작 예측 시스템에 포함되는 동작 예측 모 델이 학습될 수 있다. 시간이 지남에 따라 동작 예측 모델은 보다 더 사용자 A에 적합하도록 학습될 수 있다. 따라서, 일정 시간이 흐른 뒤 동작 예측 모델이 기 설정된 수준 이상으로 사용자 A의 TV ON/OFF 동작을 예측하 게 된다면 그 이후부터 사용자A에 대한 예측 시스템이 동작될 수 있다. 즉, 사용자 A가 평소와 동일하게 생활을 하며 지낼 때 사용자 A가 TV를 동작 시키고 싶은 것으로 예측되면 TV를 동작 시키거나, 사용자 A에게 TV를 동작시킬지 여부에 대한 질문을 출력할 수 있다. 이에 따라 사용자 A는 TV를 보기 위해 소파에 앉기만 해도 TV가 동 작되는 놀라운 경험을 할 수 있게 된다. 그리고, 사용자 A의 피드백에 따라 동작 예측 시스템으로부터 학습 데 이터들이 관리될 수 있으며, 이에 따라 사용자 A의 변화하는 생활 패턴에도 보다 더 적합하게 학습될 수 있다. 사용자 B의 시나리오 사용자 B의 집에 적어도 하나의 라이다 장치가 설치되고, 일 실시예에 따른 동작 예측 시스템 및 동작 예측 시 스템에 의해 제어될 수 있는 TV, 전등, 냉장고가 설치될 수 있다. 사용자 B의 집에 라이다 장치, 동작 예측 시 스템, TV, 전등 및 냉장고가 설치된 후에도 사용자 B는 평소와 동일하게 생활을 하며 지내게 된다. 사용자 B는 평소와 다름없이 TV를 보고 싶을 때 TV를 동작 시키며, TV를 끄고 싶을 때 TV를 끌 수 있다. 그리고 사용자 B는 역시 평소와 다름없이 조명을 켜고 싶을 때 조명을 키고, 조명을 끄고 싶을 때 조명을 끌 수 있다. 그리고 사용 자 B는 역시 평소와 다름없이 냉장고에서 물건을 꺼내고 싶을 때 냉장고 문을 열 수 있다. 이 때, 사용자 B가 TV를 동작 시키고, TV를 끄고, 조명을 켜고, 조명을 끄고, 냉장고를 문을 여는 동작을 함에 따라 동작 예측 시 스템에 의해 학습 데이터들이 수집될 수 있다. 즉, 사용자 B의 가전기기에 대한 동작들에 따라 대응되는 라이다 데이터들이 학습 입력 데이터로 수집될 수 있고, 사용자 B의 가전기기에 대한 동작들이 학습 출력 데이터로 매 칭될 수 있다. 이렇게 일정 기간 동안 학습 데이터들이 수집됨에 따라 동작 예측 시스템에 포함되는 동작 예측 모델이 학습될 수 있다. 시간이 지남에 따라 동작 예측 모델은 보다 더 사용자 B에 적합하도록 학습될 수 있다. 이 때, TV, 전등 및 냉장고 각각에 대한 동작 예측 모델이 사용자 B에게 적합해지는 기간은 서로 상이할 수 있 다. 따라서, 예를 들어 한달 뒤 TV ON/OFF 동작 예측에 대한 예측 시스템이 동작될 수 있고, 한달 반 뒤 전등 ON/OFF 동작 예측에 대한 예측 시스템이 동작될 수 있으며, 세 달 뒤 냉장고 열림에 대한 예측 시스템이 동작될 수 있다. 즉 사용자 B는 평소와 다름없이 생활하다 한달 정도 뒤에 동작 예측 시스템으로부터 TV ON/OFF 여부에 대한 질문을 받거나, 자동으로 TV가 ON/OFF 되는 경험을 할 수 있다. 그리고 TV에 대한 놀라운 경험을 하면서 14일이 지난 후에 사용자 B는 동작 예측 시스템으로부터 전등 ON/OFF 여부에 대한 질문을 받거나 자동으로 전등 이 ON/OFF 되는 경험을 할 수 있다. 그리고 그로부터 한달 반이 지난 후 사용자 B는 동작 예측 시스템으로부터 냉장고 열림에 대한 질문을 받거나 자동으로 냉장고가 열리게 되는 경험을 할 수 있다. 이에 따라 사용자 B는 시간이 지나면서 보다 더 자신에게 적합해지는 동작 예측 시스템에 대한 놀라운 경험을 할 수 있다. 사용자 C의 시나리오 사용자 C는 반려동물을 기르고 있으며, 반려동물의 배식, 급수 등을 조절하기 위한 배식기, 급수기를 이용하고 있고, 반려동물과 놀아주기 위한 장난감을 이용하고 있다. 이러한 사용자 C의 집에 적어도 하나의 라이다 장치 가 설치되고, 일 실시예에 따른 동작 예측 시스템 및 동작 예측 시스템에 의해 제어될 수 있는 배식기와 급수기 및 장난감이 설치될 수 있다. 사용자 C의 집에 라이다 장치, 동작 예측 시스템, 배식기, 급수기 및 장난감이 설 치된 후에도 사용자 C는 평소와 동일하게 생활을 하며 지내게 된다. 즉 사용자 C는 배식기에 반려동물의 사료가 떨어지기 전에 반려동물의 사료를 보충하기도 하고, 반려동물의 특정 행동에 따라 사료를 보충하기도 하며, 급 수기에 반려동물의 물이 떨어지기 전에 반려동물의 물을 보충하기도 하고, 반려 동물의 특정 행동에 따라 물을 보충하기도 한다. 그리고, 사용자 C는 반려동물의 특정 행동에 따라 장난감을 동작 시키기도 하고, 장난감을 끄 기도 한다. 이러한 사용자 C의 배식기, 급수기, 장난감에 대한 동작에 따라 동작 예측 시스템에 의해 학습데이 터들이 수집될 수 있다. 즉 사용자 C의 가전기기들에 대한 동작에 따라 대응되는 라이다 데이터들이 학습 입력 데이터로 수집될 수 있고, 사용자 C의 가전기기에 대한 동작들이 학습 출력 데이터로 매칭될 수 있다. 이 때, 학습 입력 데이터로 수집되는 라이다 데이터들에는 사용자 C 또는 사용자 C의 반려동물이 표시되어 있을 수 있 다. 이렇게 일정 기간 동안 학습 데이터들이 수집됨에 따라 동작 예측 시스템에 포함되는 동작 예측 모델이 학 습될 수 있다. 시간이 지남에 따라 동작 예측 모델은 보다 더 사용자 C에 적합하도록 학습될 수 있다. 즉, 이에 따라 사용자 C의 반려 동물의 특정 행동에 따른 사용자 C의 반응들이 학습될 수 있다. 즉, 사용자 C의 반려 동 물이 특정 행동 1을 할 때 사용자 C가 배식기를 동작 시켰던 경우에 동작 예측 시스템에 의해 사용자 C의 반려 동물이 특정 행동 1을 할 때 배식기의 동작이 예측될 수 있다. 이에 따라 시간이 보다 더 지남에 따라 사용자 C 의 반려 동물과 동작 예측 모델은 서로에 대하여 보다 더 학습될 수 있으며, 사용자 C는 자신이 직접 움직이지 않더라도 사용자 C의 반려동물의 행동에 따라 자동으로 동작되는 배식기, 급수기, 장난감에 대한 놀라운 경험을 할 수 있다.사용자 D의 시나리오 사용자 D의 사무공간에 적어도 하나의 라이다 장치가 설치되고, 일 실시예에 따른 동작 예측 시스템 및 동작 예 측 시스템에 의해 제어될 수 있는 팩스 머신, 프린터, 빔 프로젝터가 설치될 수 있다. 사용자 D의 사무공간에 라이다 장치, 동작 예측 시스템, 팩스 머신, 프린터, 빔 프로젝터가 설치된 후에도 사용자 D는 평소와 동일하게 사무 업무를 수행하게 된다. 사용자 D는 평소와 다름없이 팩스를 보내야 할 때 팩스 머신을 동작 시킬 수 있다. 그리고 사용자 D는 역시 평소와 다름없이 자료를 프린트할 필요가 있을 때 프린터를 워밍업 시킬 수 있다. 그리 고 사용자 D는 역시 평소와 다름없이 회의를 준비할 때 빔 프로젝터를 켜며, 회의가 끝난 후 빔 프로젝터를 끌 수 있다. 이 때, 사용자 D가 팩스 머신을 동작 시키고, 프린터를 워밍업 시키고, 빔 프로젝터를 켜고, 빔 프로 젝터를 끄는 동작을 함에 따라 동작 예측 시스템에 의해 학습 데이터들이 수집될 수 있다. 즉, 사용자 D의 사무 기기에 대한 동작들에 따라 대응되는 라이다 데이터들이 학습 입력 데이터로 수집될 수 있고, 사용자 D의 사무 기기에 대한 동작들이 학습 출력 데이터로 매칭될 수 있다. 이렇게 일정 기간 동안 학습 데이터들이 수집됨에 따라 동작 예측 시스템에 포함되는 동작 예측 모델이 학습될 수 있다. 시간이 지남에 따라 동작 예측 모델은 보 다 더 사용자 D에게 적합하도록 학습될 수 있다. 이 때, 팩스 머신, 프린터 및 빔 프로젝터 각각에 대한 동작 예측 모델이 사용자 D에게 적합해지는 기간은 서로 상이할 수 있다. 따라서, 예를 들어 한달 뒤 팩스 머신의 동 작 예측에 대한 예측 시스템이 동작될 수 있고, 두 달 뒤 프린터의 워밍업 동작에 대한 예측 시스템이 동작될 수 있으며, 세 달 뒤 빔 프로젝터의 ON/OFF 동작에 대한 예측 시스템이 동작될 수 있다. 즉, 사용자 D는 평소와 다름없이 사무 업무를 수행하다 한달 정도 뒤에 동작 예측 시스템으로부터 팩스 머신의 동작 시작 여부에 대한 질문을 받거나, 자동으로 팩스 머신이 동작되는 경험을 할 수 있다. 그리고 팩스 머신에 대한 놀라운 경험을 하 면서 그로부터 한달이 지난 후에 사용자 D는 동작 예측 시스템으로부터 프린터 워밍업 여부에 대한 질문을 받거 나 자동으로 프린터가 워밍업 되는 경험을 할 수 있다. 그리고 그로부터 한달이 지난 후에 사용자 D는 동작 예 측 시스템으로부터 빔 프로젝터 ON/OFF 여부에 대한 질문을 받거나 자동으로 빔 프로젝터가 ON/OFF 되는 경험을 할 수 있다. 이에 따라, 사용자 D는 시간이 지나면서 보다 더 자신에게 적합해지는 동작 예측 시스템에 대한 놀 라운 경험과 함께 업무 효율이 올라가는 것을 경험 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2023-0083294", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2023-0083294", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 가전기기 동작 예측 시스템을 나타낸 도면이다. 도 2는 일 실시예에 따른 센서 데이터를 나타낸 도면이다. 도 3은 일 실시예에 따른 동작 예측 시스템을 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 학습 데이터 생성 방법에 대하여 설명하기 위한 도면이다. 도 5는 일 실시예에 따른 프레임 데이터 그룹을 선택하는 방법을 구체적으로 설명하기 위한 도면이다. 도 6은 일 실시예에 따른 학습 데이터 생성 방법에 대하여 설명하기 위한 도면이다. 도 7 내지 도 9는 일 실시예에 따른 동작 예측 모델의 학습 방법을 설명하기 위한 도면이다. 도 10은 일 실시예에 따른 동작 제어 정보 생성 방법에 대하여 설명하기 위한 도면이다. 도 11은 일 실시예에 따른 동작 제어 정보 생성 방법에 대하여 설명하기 위한 도면이다. 도 12는 일 실시예에 따른 동작 제어 정보 생성 방법에 대하여 설명하기 위한 도면이다. 도 13은 일 실시예에 따른 동작 예측 시스템을 설명하기 위한 도면이다. 도 14는 일 실시예에 따른 학습 데이터 생성 방법에 대하여 설명하기 위한 도면이다. 도 15는 일 실시예에 따른 동작 예측 모델의 학습 방법에 대하여 설명하기 위한 도면이다. 도 16은 일 실시예에 따른 동작 제어 정보 생성 방법에 대하여 설명하기 위한 도면이다."}
