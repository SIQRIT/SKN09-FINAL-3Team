{"patent_id": "10-2019-0003004", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0062003", "출원번호": "10-2019-0003004", "발명의 명칭": "사회적 취약계층 보호 시스템 및 그 방법", "출원인": "주식회사 코이노", "발명자": "장 민"}}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사회적 취약계층인 사용자의 신체에 착용한 형태로 외부 영상을 촬영하고 촬영 영상으로부터 사용자의 주변환경을 인식하여 주변환경 인식 결과 값을 사용자의 위치 데이터와 함께 관리 서버에 전송하는 취약계층 보조장치;및취약계층 보조장치로부터 수신된 데이터로부터 사용자의 현재 상황을 파악하여 처리하는 관리 서버;를 포함하는 것을 특징으로 하는 사회적 취약계층 보호 시스템."}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 취약계층 보조장치는사회적 취약계층인 사용자의 신체에 착용 되는 본체;본체에 장착되어 외부 영상을 촬영하는 촬영부;사용자 위치를 인식하는 위치 처리부;촬영부로부터 수신된 촬영 영상을 처리하며 촬영 영상의 영상 속성정보를 획득하는 영상 처리부;촬영 영상으로부터 시각정보를 획득하고 획득된 시각정보 분석을 통해 사용자 주변환경을 인식하는 영상분석부;획득된 영상 속성정보에 인식된 사용자 위치 데이터 및 주변환경 인식 결과 값을 결합하는 데이터 정합부; 및결합 데이터를 관리 서버에 전송하도록 제어하는 전송 제어부;를 포함하는 것을 특징으로 하는 사회적 취약계층 보호 시스템."}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 영상 분석부는촬영 영상으로부터 기계학습을 통해 객체 이미지 및 문자 이미지 중 적어도 하나를 인식하여 사용자의 위치 및현재상황을 포함한 주변환경을 파악하는 것을 특징으로 하는 사회적 취약계층 보호 시스템."}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서, 전송 제어부는미리 설정된 시간 인터벌을 가지고 주기적으로 데이터를 전송하는 방식, 미리 설정된 전송조건에 해당하면 데이터를 전송하는 방식, 관리 서버의 요청 시에 데이터를 전송하는 방식 중 적어도 하나를 이용하여 데이터를 관리서버에 전송하도록 제어하는 것을 특징으로 하는 사회적 취약계층 보호 시스템."}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,미리 설정된 시간 인터벌은 사용자의 개인 별, 상황 별 및 시간 별 중 적어도 하나에 의해 조정되는 것을 특징으로 하는 사회적 취약계층 보호 시스템."}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 2 항에 있어서, 위치 처리부는위치정보 신호로부터 사용자 위치를 인식하는 방식 및 촬영 영상 분석을 통해 인식된 시각정보로부터 사용자 위치를 인식하는 방식 중 적어도 하나를 이용하여 사용자 위치를 인식하는 것을 특징으로 하는 사회적 취약계층공개특허 10-2020-0062003-3-보호 시스템."}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 2 항에 있어서, 취약계층 보조장치는촬영 영상을 저장하는 메모리; 를 더 포함하고,영상 처리부는 촬영 영상을 압축하여 메모리에 저장하며,전송 제어부는 관리 서버의 요청 시에 메모리에 저장된 촬영 영상을 읽어들여 관리 서버에 전송하도록 제어하는것을 특징으로 하는 사회적 취약계층 보호 시스템."}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서, 전송 제어부는결합 데이터 전송 이후에, 관리 서버의 촬영 영상 요청 시에 촬영 영상을 관리 서버에 전송하도록 제어하는 것을 특징으로 하는 사회적 취약계층 보호 시스템."}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7 항에 있어서, 영상 처리부는메모리의 저장 용량이 채워지면 최초 촬영 영상부터 삭제 처리하며, 영상 속성정보의 메모리 내 최소 저장기간을 미리 설정하고 미리 설정된 최소 저장기간 이상의 촬영 영상들은 썸 네일 형태로 축소하여 메모리에 저장하는 것을 특징으로 하는 사회적 취약계층 보호 시스템."}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 2 항에 있어서, 취약계층 보조장치는시각정보를 청각정보로 변환하는 정보 변환부; 및변환된 청각정보를 출력하는 출력부;를 더 포함하는 것을 특징으로 하는 사회적 취약계층 보호 시스템."}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항에 있어서, 관리 서버는사용자를 관리하는 사용자 관리부;취약계층 보조장치와 네트워크 연결되어 취약계층 보조장치로부터 데이터를 수신하는 네트워크 연결부;수신된 데이터를 모니터링하는 모니터링부;모니터링을 통해 사용자 행동을 예측하는 데이터 분석부; 및사용자 행동 예측 결과에 따라 사용자의 위치 이동에 따라 발생하는 상시 데이터 및 위급 상황에 따라 발생하는긴급 데이터를 사용자의 보호자에 제공하기 위해 보호자 단말과의 호 연결을 제어하는 호 연결부;를 포함하는 것을 특징으로 하는 사회적 취약계층 보호 시스템."}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서, 관리 서버는취약계층 보조장치로부터 데이터를 획득하기 위한 데이터 전송 인터벌을 조정하는 인터벌 관리부;를 더 포함하는 것을 특징으로 하는 사회적 취약계층 보호 시스템."}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서, 인터벌 관리부는공개특허 10-2020-0062003-4-사용자의 개인 별, 상황 별 및 시간 별 중 적어도 하나에 의해 데이터 전송 인터벌을 조정하는 것을 특징으로하는 사회적 취약계층 보호 시스템."}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "취약계층 보조장치가 사회적 취약계층인 사용자의 신체에 착용된 형태로 외부 영상을 촬영하는 단계;취약계층 보조장치가 촬영 영상으로부터 사용자의 주변환경을 인식하여 주변환경 인식 결과 값을 사용자의 위치데이터와 함께 관리 서버에 전송하는 단계; 및관리 서버가 취약계층 보조장치로부터 수신된 데이터로부터 사용자의 현재 상황을 파악하여 처리하는 단계;를 포함하는 것을 특징으로 하는 사회적 취약계층 보호방법."}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서, 관리 서버에 전송하는 단계는사용자 위치를 인식하는 단계;수신된 촬영 영상의 영상 속성정보를 획득하는 단계;촬영 영상으로부터 시각정보를 획득하고 획득된 시각정보 분석을 통해 사용자 주변환경을 인식하는 단계; 및획득된 영상 속성정보에 인식된 사용자 위치 데이터 및 주변환경 인식 결과 값을 결합하여 관리 서버에 전송하는 단계;를 포함하는 것을 특징으로 하는 사회적 취약계층 보호방법."}
{"patent_id": "10-2019-0003004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 14 항에 있어서, 관리 서버에 전송하는 단계는미리 설정된 시간 인터벌을 가지고 주기적으로 데이터를 전송하는 방식, 미리 설정된 전송조건에 해당하면 데이터를 전송하는 방식, 관리 서버의 요청 시에 데이터를 전송하는 방식 중 적어도 하나를 이용하여 데이터를 관리서버에 전송하며,사용자의 개인 별, 상황 별 및 시간 별 중 적어도 하나에 의해 데이터 전송 인터벌이 조정되는 것을 특징으로하는 사회적 취약계층 보호방법."}
{"patent_id": "10-2019-0003004", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사회적 취약계층 보호 시스템 및 그 방법이 개시된다. 일 실시 예에 따른 사회적 취약계층 보호 시스템은, 사회 적 취약계층인 사용자의 신체에 착용한 형태로 외부 영상을 촬영하고 촬영 영상으로부터 사용자의 주변환경을 인 식하여 주변환경 인식 결과 값을 사용자의 위치 데이터와 함께 관리 서버에 전송하는 취약계층 보조장치와, 취약 계층 보조장치로부터 수신된 데이터로부터 사용자의 현재 상황을 파악하여 처리하는 관리 서버를 포함한다."}
{"patent_id": "10-2019-0003004", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사회적 취약계층을 보호하기 위한 기술에 관한 것이다."}
{"patent_id": "10-2019-0003004", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 사회 문화가 다변화되면서, 다양한 형태의 사회 문제를 야기하고 있다. 특히, 장애인이나 치매 노인 또는 인지 능력이 떨어지는 어린 아이들의 경우 범죄의 대상이 될 뿐만 아니라, 일상생활에서도 많은 어려움을 겪는 다. 예를 들어, 치매 노인이 가족들이 알 수 없는 곳을 가거나, 아이들이 보호자와 떨어져 길을 잃게 되는 경우 가 빈번하게 발생하고 있다. 현재 제공되고 있는 여러 형태의 아동 및 치매환자와 같은 사회적 취약계층을 보호하기 위한 위치 기반 서비스 (location based service: LBS) 및 기기들은 위성항법장치(Global Positioning System: GPS) 기반으로 되어 있 어 위치 파악은 비교적 수월하나, 해당 시간에 사용자가 어떤 행동을 하는지 알 수 없고 GPS 오차로 인해 정확 한 구체적 위치는 알 수 없다."}
{"patent_id": "10-2019-0003004", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일 실시 예에 따라 아동, 치매환자 등과 같은 사회적 취약계층을 상시 모니터링 하면서 사용자의 상황과 여건을 파악하여 일상 속에서 발생 가능한 위험으로부터 신속하게 대처 및 보호할 수 있고 네트워크 부하 및 배터리 소 모를 줄일 수 있는 사회적 취약계층 보호 시스템 및 그 방법을 제안한다."}
{"patent_id": "10-2019-0003004", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시 예에 따른 사회적 취약계층 보호 시스템은, 사회적 취약계층인 사용자의 신체에 착용한 형태로 외부 영 상을 촬영하고 촬영 영상으로부터 사용자의 주변환경을 인식하여 주변환경 인식 결과 값을 사용자의 위치 데이 터와 함께 관리 서버에 전송하는 취약계층 보조장치와, 취약계층 보조장치로부터 수신된 데이터로부터 사용자의 현재 상황을 파악하여 처리하는 관리 서버를 포함한다. 취약계층 보조장치는, 사회적 취약계층인 사용자의 신체에 착용 되는 본체와, 본체에 장착되어 외부 영상을 촬 영하는 촬영부와, 사용자 위치를 인식하는 위치 처리부와, 촬영부로부터 수신된 촬영 영상을 처리하며 촬영 영 상의 영상 속성정보를 획득하는 영상 처리부와, 촬영 영상으로부터 시각정보를 획득하고 획득된 시각정보 분석 을 통해 사용자 주변환경을 인식하는 영상 분석부와, 획득된 영상 속성정보에 인식된 사용자 위치 데이터 및 주 변환경 인식 결과 값을 결합하는 데이터 정합부와, 결합 데이터를 관리 서버에 전송하도록 제어하는 전송 제어 부를 포함할 수 있다. 영상 분석부는, 촬영 영상으로부터 기계학습을 통해 객체 이미지 및 문자 이미지 중 적어도 하나를 인식하여 사 용자의 위치 및 현재상황을 포함한 주변환경을 파악할 수 있다. 전송 제어부는, 미리 설정된 시간 인터벌을 가지고 주기적으로 데이터를 전송하는 방식, 미리 설정된 전송조건 에 해당하면 데이터를 전송하는 방식, 관리 서버의 요청 시에 데이터를 전송하는 방식 중 적어도 하나를 이용하 여 데이터를 관리 서버에 전송하도록 제어할 수 있다. 미리 설정된 시간 인터벌은 사용자의 개인 별, 상황 별 및 시간 별 중 적어도 하나에 의해 조정될 수 있다. 위치 처리부는, 위치정보 신호로부터 사용자 위치를 인식하는 방식 및 촬영 영상 분석을 통해 인식된 시각정보 로부터 사용자 위치를 인식하는 방식 중 적어도 하나를 이용하여 사용자 위치를 인식할 수 있다. 취약계층 보조장치는, 촬영 영상을 저장하는 메모리를 더 포함하고, 영상 처리부는 촬영 영상을 압축하여 메모 리에 저장하며, 전송 제어부는 관리 서버의 요청 시에 메모리에 저장된 촬영 영상을 읽어들여 관리 서버에 전송 하도록 제어할 수 있다. 전송 제어부는, 결합 데이터 전송 이후에, 관리 서버의 촬영 영상 요청 시에 촬영 영상 을 관리 서버에 전송하도록 제어할 수 있다. 영상 처리부는, 메모리의 저장 용량이 채워지면 최초 촬영 영상부터 삭제 처리하며, 영상 속성정보의 메모리 내 최소 저장기간을 미리 설정하고 미리 설정된 최소 저장기간 이상의 촬영 영상들은 썸 네일 형태로 축소하여 메 모리에 저장할 수 있다. 취약계층 보조장치는, 시각정보를 청각정보로 변환하는 정보 변환부와, 변환된 청각정보를 출력하는 출력부를 더 포함할 수 있다. 관리 서버는, 사용자를 관리하는 사용자 관리부와, 취약계층 보조장치와 네트워크 연결되어 취약계층 보조장치 로부터 데이터를 수신하는 네트워크 연결부와, 수신된 데이터를 모니터링하는 모니터링부와, 모니터링을 통해 사용자 행동을 예측하는 데이터 분석부와, 사용자 행동 예측 결과에 따라 사용자의 위치 이동에 따라 발생하는 상시 데이터 및 위급 상황에 따라 발생하는 긴급 데이터를 사용자의 보호자에 제공하기 위해 보호자 단말과의 호 연결을 제어하는 호 연결부를 포함할 수 있다. 관리 서버는, 취약계층 보조장치로부터 데이터를 획득하기 위한 데이터 전송 인터벌을 조정하는 인터벌 관리부 를 더 포함할 수 있다. 인터벌 관리부는, 사용자의 개인 별, 상황 별 및 시간 별 중 적어도 하나에 의해 데이터 전송 인터벌을 조정할 수 있다. 다른 실시 예에 따른 사회적 취약계층 보호방법은, 취약계층 보조장치가 사회적 취약계층인 사용자의 신체에 착 용된 형태로 외부 영상을 촬영하는 단계와, 취약계층 보조장치가 촬영 영상으로부터 사용자의 주변환경을 인식 하여 주변환경 인식 결과 값을 사용자의 위치 데이터와 함께 관리 서버에 전송하는 단계와, 관리 서버가 취약계 층 보조장치로부터 수신된 데이터로부터 사용자의 현재 상황을 파악하여 처리하는 단계를 포함한다. 관리 서버에 전송하는 단계는, 사용자 위치를 인식하는 단계와, 수신된 촬영 영상의 영상 속성정보를 획득하는 단계와, 촬영 영상으로부터 시각정보를 획득하고 획득된 시각정보 분석을 통해 사용자 주변환경을 인식하는 단계와, 획득된 영상 속성정보에 인식된 사용자 위치 데이터 및 주변환경 인식 결과 값을 결합하여 관리 서버에 전송하는 단계를 포함할 수 있다. 관리 서버에 전송하는 단계는, 미리 설정된 시간 인터벌을 가지고 주기적으로 데이터를 전송하는 방식, 미리 설 정된 전송조건에 해당하면 데이터를 전송하는 방식, 관리 서버의 요청 시에 데이터를 전송하는 방식 중 적어도 하나를 이용하여 데이터를 관리 서버에 전송하며, 사용자의 개인 별, 상황 별 및 시간 별 중 적어도 하나에 의 해 데이터 전송 인터벌이 조정될 수 있다."}
{"patent_id": "10-2019-0003004", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시 예에 따르면, 아동 및 치매 환자를 보다 효과적으로 보호 관리할 수 있다. 예를 들어, 사회적 취약계층 보호 시스템은 사회적 취약계층에 대한 주변의 상황 및 여건을 파악함으로써 특정 상황에 처해 있는 사회적 취 약계층을 감시하고 보호하며 신속하게 대처할 수 있다. 예를 들어, 사회적 취약계층인 사용자 착용한 취약계층 보조장치를 사용하여 사용자가 지켜보고 있는 전방 영상을 촬영한 후 그 화면에 있는 글씨 또는 사물을 인식하 여 인식 결과 값을 위치 데이터와 연계한 패킷 형태로 관리 서버에 전송한다. 이에 따라, 사용자의 상태를 용이 하게 유추할 수 있고 유추 결과를 보호자에 알림으로써 사용자의 상황을 파악하며 위급상황에 대처할 수 있다. 또한, 취약계층 보조장치가 사용자 전방의 영상을 촬영할 때마다 촬영 영상을 매번 실시간으로 관리 서버에 송 신하는 것이 아니라, 영상 속성정보를 주변환경 인식 값을 결합하여 송신함에 따라, 사용자의 상태를 보다 쉽게 파악할 수 있으면서 동시에 네트워크 부하 및 배터리 소모를 줄일 수 있다. 나아가, 사회적 취약계층이 처해 있는 주변 상황을 촬영 및 저장함으로써, 성범죄, 미아, 치매 노인, 학교 폭력, 교통사고 등과 같은 다양한 사회 문제를 예방 및 대처할 수 있다. 또한, 특정 상황이 발생한 위치의 위치 데이터를 함께 제공함으로써 특정 상황 발생시의 촬영 영상뿐만 아니라 위치 등을 확인하여 해당 상황에 대하여 신속하고 정확하게 대처할 수 있다."}
{"patent_id": "10-2019-0003004", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시 예들은 본 발명의 개시가 완전하도록 하고, 본 발명이"}
{"patent_id": "10-2019-0003004", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 본 발명의 실시 예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이며, 후술되는 용어들은 본 발명의 실시 예에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다.첨부된 블록도의 각 블록과 흐름도의 각 단계의 조합들은 컴퓨터 프로그램인스트럭션들(실행 엔진)에 의해 수행 될 수도 있으며, 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서를 통해 수행되는 그 인스트럭션들이 블록도의 각 블록 또는 흐름도의 각 단계에서 설명된 기능 들을 수행하는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능 하므로, 그 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저장된 인스트럭션들은 블록도의 각 블록 또는 흐 름도의 각 단계에서 설명된 기능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생산하는 것도 가능하다. 그리고 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에 탑재되 는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에서 일련의 동작 단계들이 수 행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 수 행하는 인스트럭션들은 블록도의 각 블록 및 흐름도의 각 단계에서 설명되는 기능들을 실행하기 위한 단계들을 제공하는 것도 가능하다. 또한, 각 블록 또는 각 단계는 특정된 논리적 기능들을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있으며, 몇 가지 대체 실시 예들에서는 블록들 또는 단 계들에서 언급된 기능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들 또는 단계들은 사실 실질적으로 동시에 수행되는 것도 가능하며, 또한 그 블록들 또는 단 계들이 필요에 따라 해당하는 기능의 역순으로 수행되는 것도 가능하다. 이하, 첨부 도면을 참조하여 본 발명의 실시 예를 상세하게 설명한다. 그러나 다음에 예시하는 본 발명의 실시 예는 여러 가지 다른 형태로 변형될 수 있으며, 본 발명의 범위가 다음에 상술하는 실시 예에 한정되는 것은 아"}
{"patent_id": "10-2019-0003004", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "니다. 본 발명의 실시 예는 이 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 본 발명을 보다 완전하 게 설명하기 위하여 제공된다. 도 1은 본 발명의 일 실시 예에 따른 사회적 취약계층 보호 시스템의 구성을 도시한 도면이다. 도 1을 참조하면, 사회적 취약계층 보호 시스템은 취약계층 보조장치를 포함하며, 관리 서버 및 보호자 단말을 더 포함할 수 있다. 취약계층 보조장치, 관리 서버 및 보호자 단말은 네트워크를 통해 연결된다. 사회적 취약계층 보호 시스템은 인공지능(artificial intelligence: AI)을 활용하여 사회적 취약계층을 지원하 는 지능형 장치이다. 사회적 취약계층이란 사회적 약자로서, 아동, 치매환자, 노인, 지적 장애인, 정상적인 생 활이 불편한 자, 거동이 불편한 자 등을 포함한다. 사회적 취약계층은 시력 취약계층을 포함할 수 있다. 시력 취약계층은 시력이 정상인과는 다른 계층으로, 스마트폰 사용 등으로 인해 노안, 원시, 근시, 난시 등이 빨리 온 계층과, 기존 원시, 근시, 난시군, 고령층, 시각 장애인층을 모두 포함하는 개념이다. 사회적 취약계층 보호 시스템은 사회적 취약계층의 불편함을 극복하고 독립적으로 생활할 수 있도록 하며 부딪치는 위험으로부터 보호 하고자 취약계층 보조장치를 부담없는 가격에 제공하는 것을 목적으로 한다. 취약계층 보조장치는 사용자인 사회적 취약계층이 소지하고 휴대할 수 있는 장치이다. 이하, 상세한 설명에 는 '사용자'와 '사회적 취약계층'이 혼용되어 사용될 수 있다. 취약계층 보조장치는 사용자가 착용 및 소지 가 용이한 웨어러블 디바이스이다. 웨어러블 디바이스의 예로는 사용자가 착용한 안경의 안경 테 또는 안경 다 리 등에 탈부착하는 형태가 있다. 전면 또는 측면에 촬영부가 장착되어, 촬영부를 통해 영상을 실시간 촬영할 수 있다. 이러한 웨어러블 디바이스는 기존의 일반적인 안경에 탈부착 가능하며, 무게를 최소화하여 착용하기 편리하도록 한다. 취약계층 보조장치는 본체 및 제어장치가 결합한 단독형일 수 있으며, 본체와 스마트폰이 연동한 연동형일 수 있다. 일 실시 예에 따른 취약계층 보조장치는 인공지능(AI) 기반 기계학습(Machine Learning)을 통해 촬영부로 들 어오는 영상으로부터 시각정보를 인식하며 인식한 시각정보를 사용자가 들을 수 있도록 청각정보로 가공하여 출 력한다. 시각정보는 객체, 문자, 깊이 등이다. 청각정보는 음성신호, 경고음 등이다. 예를 들어, 취약계층 보조 장치는 인쇄 형태의 문자를 읽어 소리로 들려준다. 이에 따라, 사용자인 사회적 취약계층이 사물에 대한 인 지를 쉽게 하고 환경에 잘 적응할 수 있도록 한다.일 실시 예에 따른 사회적 취약계층 보호 시스템은 사회적 취약계층을 보호 및 트래킹 처리한다. 예를 들어, 사 용자가 경찰서에 있는 경우, 취약계층 보조장치가 사용자의 전면에서 촬영된 영상으로부터 \"경찰서\"를 인식 하고 주변환경 인식 값을 위치 데이터와 함께 관리 서버에 전송한다. 관리 서버는 수신된 데이터를 분석 하여 사용자가 위급상황임을 파악하고, 보호자 단말에 긴급 연락한다. 취약계층 보조장치는 데이터를 주 기적으로 관리 서버에 제공할 수 있다. 보호자 단말은 사회적 취약계층의 보호자가 소지하고 있는 단말로 서, 사회적 취약계층의 위험 상황으로부터 그들을 보호할 수 있다. 일 실시 예에 따른 취약계층 보조장치는 사용자 전방의 영상을 촬영할 때마다 촬영된 영상을 그때마다 실시 간으로 관리 서버에 송신하는 것이 아니라, 영상 속성정보와 주변환경 인식 값을 결합하여 송신함에 따라 사 용자의 상태를 보다 쉽게 파악할 수 있으면서 동시에 네트워크 부하 및 배터리 소모를 줄일 수 있다. 영상 속성 정보는 촬영 영상(이미지 또는 사진)의 파일명, 촬영 일자정보 등이 포함될 수 있다. 지속적으로 확보한 촬영 영상(이미지나 사진)을 그때마다 관리 서버에 송신하는 경우, 데이터 송신을 통한 네트워크 데이터 사용의 부담이 크다. 또한, 네트워크 연결 시마다 배터리 소모가 큰 관계로 배터리 소진 등의 문제가 발생할 수 있다. 이에, 취약계층 보조장치는 촬영 영상으로부터 인식한 시각정보, 예를 들어 찍힌 글씨, 간판과 같은 단서 등 을 프로세서를 통해 인식한 후 인식 결과 값 데이터를 찍힌 위치 데이터와 결합하여 주기적으로 관리 서버 에 송신한다. 이 경우, 대상자의 상태를 보다 쉽게 파악할 수 있으면서 촬영 영상이 아닌 인식 결과 값 데이 터를 전송하므로 네트워크 부하를 줄일 수 있다. 이후, 관리 서버로부터 촬영 영상 요청신호를 수신하면, 메 모리에 저장된 촬영 영상을 관리 서버에 전송함에 따라 정확도를 높일 수 있다. 일 실시 예에 따른 취약계층 보조장치는 전면의 객체를 인식한다. 인공지능 기반 기계학습을 통해 사람과 동 물, 사물을 구분해 이를 음성으로 알려준다. 기계학습의 특성 상 사용자가 많을수록 정확도는 더 높아진다. 취 약계층 보조장치는 전면 객체와의 거리도 계산해 알려준다. 나아가, 부딪히지 않도록 경고한다. 촬영 영상에 서 문자 이미지를 추출해 이를 읽어주기도 한다. 지금까지는 영상을 지인이나 상담원에게 전송해 구두로 설명을 듣는 방식이었다. 사용자가 원하는 객체를 지목하면, 취약계층 보조장치는 지목한 객체를 대상으로 시력 보 조 서비스를 제공할 수 있다. 원하는 객체를 지목할 때 사용하는 기기 입력방식으로는 증강현실(augmented reality: AR) 기반 포인터를 이용하여 손가락이 지목하는 객체에 대해 바로 인지할 수 있도록 할 수 있다. 예를 들어, 사용자가 검지만 세우면 증강현실 속 포인터가 된다. 음식점에서 메뉴판을 손가락으로 가리키면 촬영부가 인지해 해당 글자를 읽어준다. 책이나 잡지도 혼자서 읽을 수 있다. 손가락으로 'V' 자를 표현하면 책과 잡지로 인지해 자동으로 계속 읽어준다. 손바닥을 펴면 주변 사물과 부딪히지 않도록 깊이 추정 모드로 전환된다. 영상 왜곡 처리 이미지 프로세싱으로 정확한 깊이를 계산해낼 수 있다. 취약계층 보조장치에는 인공지능(AI) 기술, 증강현실(AR), 음성변환(text to speech: TTS) 기술 등의 다양한 기술이 적용된다. 원격제어(remote control)도 가능하다. 인공지능 기술은 기계학습을 통해 영상으로부터 자동 으로 객체, 문자, 거리 등의 시각정보를 인식하는 기술을 포함한다. 증강현실 기술은 사용자와 떨어진 객체를 지목하더라도 사용자가 지목한 객체의 이미지를 인식하여 음성으로 알려주는 것과 같이 가상의 세계와 현실의 세계가 결합한 기술이다. 여기서, 사용자의 제스처를 증강현실 포인터로 인식하고 인식된 증강현실 포인터가 지 시하는 위치를 인식하는 기술이 포함된다. 음성변환 기술은 인식된 시각정보, 예를 들어 문자 이미지를 문자 (text) 정보로 변환하고 이를 사용자가 들을 수 있는 청각정보로 변환하여 음성 출력하는 기술을 포함한다. 원 격제어는 취약계층 보조장치가 네트워크를 통해 연결된 관리 서버로부터 원격제어를 지원받고 관리 서 버가 취약계층 보조장치를 모니터링하는 기술을 포함한다. 관리 서버는 취약계층 보조장치를 관리한다. 또한, 사용자가 취약계층 보조장치를 실제 사용할 때 정 상상태를 유지할 수 있도록 실시간 사전 서비스(Before Service: B/S) 및 사후 서비스(After Service: A/S)를 제공한다. 현장에서 취약계층 보조장치가 고장이 나거나 이상동작을 할 경우 사회적 취약계층인 사용자의 위 험도가 증가하므로 취약계층 보조장치의 상태를 미리 빅 데이터 기반으로 분석하여 이상징후를 미리 파악한 다. 그리고 이상이 발생한 경우, 사용자에게 통보하거나 유지보수인원을 파견하여 사전처리하도록 함에 따라 위 험을 미리 제거할 수 있다. 현장에서 문제가 발생했을 경우 네트워크를 통해 취약계층 보조장치에 대한 기기유지보수도 가능하다. 나아가, 사용자가 동의할 경우 현장의 화면캡처 및 동영상을 저장하는 서비스도 제공 할 수 있다. 이때 서비스를 제공하기 위하여 모니터링이 가능하며 이를 지원한다. 네트워크는 취약계층 보조장치, 관리 서버 및 보호자 단말 간에 데이터의 송수신이 가능한 유무선 네트워크이다. 네트워크는 다양한 형태의 통신망이 이용될 수 있는데, 예를 들어, Wi-Fi, WLAN(Wireless LAN), Wibro, Wimax, HSDPA(High Speed Downlink Packet Access), 블루투스, DSL, LTE, PCS, 2G, 3G, 4G, 5G, LAN, CDMA, TDMA, GSM, WDM 등의 무선 통신방식 또는 이더넷(Ethernet), xDSL(ADSL, VDSL), HFC(Hybrid FiberCoax), FTTC(Fiber to The Curb), FTTH(Fiber To The Home) 등의 유선 통신방식이 이용될 수 있다. 네트워크 는 전술한 통신방식에 한정되는 것은 아니며, 전술한 통신 방식 이외에도 기타 널리 공지되었거나 향후 개발 될 모든 형태의 통신 방식을 포함할 수 있다. 도 2는 본 발명의 일 실시 예에 따른 취약계층 보조장치의 구성을 도시한 도면이다. 도 1 및 도 2를 참조하면, 취약계층 보조장치는 촬영부, 프로세서, 입력부, 출력부, 통신부 , 메모리, 배터리 및 위치정보 수신부를 포함한다. 촬영부는 외부의 전면 영상을 실시간으로 촬영한다. 촬영부는 카메라일 수 있다. 객체의 깊이를 인식하 기 위해 촬영부는 ToF 카메라일 수 있다. 촬영부는 본체의 내부 또는 외부에 정면을 바라보도록 배치되 어 사용자의 정면을 촬영할 수 있다. 예를 들어, 촬영부는 사용자가 안경의 안경 테나 안경 다리에 착용 가 능한 본체에 장착되어, 사용자의 시점에 따른 실제 영상을 촬영할 수 있다. 촬영된 영상은 사용자 요청 시에 관 리 서버에 전송될 수 있다. 촬영 영상은 압축되어 메모리에 저장될 수 있다. 프로세서는 촬영부로부터 촬영 영상을 수신하여 촬영 영상으로부터 사용자의 주변환경을 인식하고 주변 환경 인식 결과 값을 사용자의 위치 데이터와 연계하여 통신부를 통해 관리 서버에 전송한다. 예를 들어, 사용자 전면에서 촬영된 영상에서 시각 정보, 예를 들어 \"송민학교\"라 써진 학교 이름을 인식하면, 주변 환경 인식 결과 값인 \"송민학교\" 데이터를 위치 데이터와 결합하여 패킷 형태로 관리 서버에 전송한다. 사용 자의 위치 데이터는 촬영 영상으로부터 획득된 시각정보를 분석하여 획득할 수 있고, 위치정보 수신부로부 터 수신된 위치정보 신호를 이용하여 획득할 수도 있다. 촬영 영상으로부터 위치 데이터를 획득할 때, 위치정보 신호를 보조수단으로 이용할 수도 있다. 위치정보 신호는 GPS나 블루투스, NFC 등의 모듈을 통해 수신할 수 있 다. 촬영 영상으로부터 얻는 경우 GPS나 블루투스, NFC 등의 모듈 없이 취약계층 보조장치의 본래 기능만을 가지고 위치 데이터를 얻을 수 있다. 프로세서의 세부 구성은 도 3을 참조로 하여 후술한다. 입력부는 사용자 명령을 입력받아 이를 프로세서에 제공한다. 입력부는 입력을 위한 사용자 인터페 이스를 포함할 수 있다. 예를 들어, 전원 버튼, 볼륨 조절 버튼 등을 포함할 수 있다. 사회적 취약계층을 고려 하여 버튼을 양각 처리하거나, 진동을 주는 것과 같이 손의 감각으로 버튼 기능을 구현하는 방법 등 사회적 취 약계층 위주의 입력 인터페이스가 제공된다. 입력부는 에러 예측에 따른 사전 서비스 정보 수신을 위해 에 러 기준이 되는 임계값 및 에러 예측 시의 알림 형태를 사용자로부터 미리 설정 입력받을 수 있다. 출력부는 프로세서에 의해 처리된 정보, 통신부를 통해 수신된 정보 등을 외부로 출력한다. 출력부 는 프로세서에서 변환된 청각정보를 출력한다. 출력 형태는 음성신호일 수 있으며, 음성신호는 경고 메 시지, 경고 음을 포함할 수 있다. 일 실시 예에 따른 출력부는 스피커와 골 전도 이어폰을 포함한다. 스피 커는 청각정보를 출력하며, 골 전도 이어폰은 뼈를 통해 청각정보를 전달한다. 골 전도 이어폰은 진동을 통해 두개골에 음파를 전달한다. 골 전도 이어폰의 가장 큰 장점은 바로 귀를 자유롭게 해준다는 점이다. 즉, 고막의 손상이나 피로를 줄여주고 다른 외부의 소리까지 추가로 들을 수 있도록 해준다. 골 전도 이어폰은 도서관, 지 하철과 같은 대중교통수단, 공공장소 등에서 사용 가능하다. 일 실시 예에 따라 사용자에 의해 골 전도 이어폰 이 장착되면 골 전도 이어폰을 통해 청각정보를 출력한다. 이에 비해, 골 전도 스피커가 장착 해제되면 스피커 를 통해 청각정보를 출력할 수 있다. 출력부는 디스플레이를 포함할 수 있다. 이 경우, 디스플레이를 통해 촬영 영상이 표시될 수 있다. 또한, 촬영 영상에 사용자의 제스처 포인터가 합성되어 표시될 수 있다. 디스플레이를 위해, 취약계층 보조장치는 스마트 글라스(smart glass)와 같은 안경 형태로 구현될 수 있다. 출력부를 통해 음성신호로 사용자가 지정한 음식 메뉴를 읽어줄 수 있고, 책이나 잡지 등의 글을 자동으로 읽어줄 수 있다. 전방에 위험요소가 있는 경우 이를 음성 또는 경고음으로 알려줄 수 있다. 예를 들어, \"전방 3m 이내에 위험요소가 있으니 조심하세요\", \"돌발상황입니다. 멈추세요.\" 등을 음성으로 전달하거나, \"삐-\" 등 의 경고음을 전달할 수 있다. 위험 상황이 발생하면, 위험 경보신호를 즉각적으로 전달하여 위험한 상황에 사전 대응하도록 한다. 통신부는 외부로부터 정보를 수신하거나 외부로 정보를 전송한다. 외부는 관리 서버일 수 있다. 일 실시 예에 따른 통신부는 관리 서버와 네트워크 연결되어 통신하면서, 결합한 형태의 위치 데이터, 영상 속성정보 및 주변 환경 인식 값을 관리 서버에 전송한다. 통신부는 미리 설정된 인터벌로 결합한 형태의 위치 데이터 및 영상 속성정보, 주변 환경 인식 값을 관리 서버에 전송할 수 있다. 지속적으로 확보한 영상 (이미지나 사진)을 그때마다 관리 서버에 송신하는 경우 데이터 송신을 통한 네트워크 데이터 사용의 부담이있고, 네트워크 연결 시마다 배터리 소모가 큰 관계로 배터리 소진 등의 문제가 발생할 수 있다. 이에, 취약계 층 보조장치는 촬영 영상에서 인식한 시각정보, 예를 들어 찍힌 글씨, 간판과 같은 단서 등을 프로세서 를 통해 인식한 후 인식 결과 값을 찍힌 위치 데이터와 결합하여 주기적으로 관리 서버에 송신한다. 이 경 우, 대상자의 상태를 보다 쉽게 파악할 수 있으면서 부하를 줄일 수 있다. 이후, 관리 서버로부터 촬영 영상 요청신호를 수신하면, 메모리에 저장된 촬영 영상을 관리 서버에 전송할 수 있다. 메모리는 취약계층 보조장치에서 동작 수행을 위해 필요한 정보와 동작 수행에 따라 생성되는 정보가 저 장된다. 예를 들어, 메모리에는 촬영 영상에서 객체를 인식하기 위해, 기계학습을 수행하기 위한 명령어와, 객체의 형상 패턴, 색 패턴, 신호 패턴 등의 패턴에 대해 기계학습된 데이터가 미리 저장될 수 있다. 일 실시 예에 따른 메모리에는 촬영 영상이 저장된다. 일 실시 예에 따른 메모리의 저장 용량이 채워지면 메모 리에서 최초 촬영 영상부터 삭제 처리된다. 이때, 미리 설정된 촬영 영상의 최소 저장기간 이상의 촬영 영 상들은 썸 네일 형태로 축소되어 저장될 수 있다. 배터리는 취약계층 보조장치의 구동을 위한 전원을 공급한다. 취약계층 보조장치가 본체와 제어장치 로 분리된 경우, 배터리는 제어장치에 위치할 수 있다. 제어장치에 위치하는 경우 사용자가 착용하는 본체 의 무게를 가볍게 할 수 있다. 본체를 스마트폰과 같은 사용자 단말과 연동하는 경우, 배터리는 사용자 단 말의 배터리를 이용할 수도 있다. 배터리는 교체식, 충전식 또는 이 두 방식 모두를 사용할 수 있다. 예를 들어, 1차적으로 교체식 배터리를 통해 전원공급이 이루어지도록 한 상태에서, 교체식 배터리를 모두 사용할 경 우 충전식 배터리는 예비 전원으로서 사용할 수 있다. 위치정보 수신부는 GPS나 블루투스 NFC 모듈 등을 이용하여 위치정보 신호를 수신하고 이를 프로세서에 전달한다. 프로세서는 수신된 위치 데이터를 사용하여 사용자의 위치를 보다 정밀하게 파악할 수 있다. 도 3은 본 발명의 일 실시 예에 따른 도 2의 프로세서의 세부 구성을 도시한 도면이다. 도 1 내지 도 3을 참조하면, 프로세서는 위치 처리부, 영상 처리부, 데이터 정합부, 전송 제어부, 영상 분석부 및 정보 변환부를 포함한다. 위치 처리부는 사용자 위치를 인식한다. 위치 처리부는 위치정보 신호로부터 사용자 위치를 인식하는 방식 및 촬영 영상 분석을 통해 인식된 시각정보로부터 사용자 위치를 인식하는 방식 중 적어도 하나를 이용하 여 사용자 위치를 인식한다. 영상 처리부는 촬영부로부터 촬영 영상을 수신하여 처리하며, 촬영 영상 의 영상 속성정보를 획득한다. 영상 속성정보는 촬영 영상(이미지 또는 사진)의 파일명, 촬영 일자정보 등이 포 함될 수 있다. 데이터 정합부는 영상 속성정보, 위치 데이터 및 주변환경 인식 값을 결합한다. 전송 제어 부는 데이터 정합부를 통해 결합 데이터를 관리 서버에 전송하도록 제어한다. 일 실시 예에 따른 영상 처리부는 촬영 영상을 압축하여 메모리에 저장하며, 전송 제어부는 결합 데이터를 수신한 관리 서버의 요청 시에 메모리에 저장된 촬영 영상을 읽어들여 관리 서버에 추가로 전송할 수 있다. 영상 처리부는 메모리의 저장 용량이 채워지면 최초 촬영 영상부터 삭제 처리하며, 촬영 영상의 메모리 내 최소 저장기간을 미리 설정하고, 미리 설정된 최소 저장기간 이상의 촬영 영상들은 썸 네일 형태로 축소하여 메모리에 저장할 수 있다. 일 실시 예에 따른 전송 제어부는 미리 설정된 시간 인터벌을 가지고 주기적으로 데이터를 전송하는 방식, 미리 설정된 전송조건에 해당하면 데이터를 전송하는 방식, 관리 서버의 요청 시에 데이터를 전송하는 방식 중 적어도 하나를 이용하여 데이터를 관리 서버에 전송하도록 통신부를 제어한다. 전송하는 데이터는 영 상 속성정보, 위치 데이터, 주변환경 인식 결과값이다. 미리 설정된 시간 인터벌은 사용자의 개인 별, 상황 별 및 시간 별 중 적어도 하나에 의해 조정될 수 있다. 예를 들어, 사용자가 아동인지 치매 환자인지에 따라 달라 질 수 있다. 사용자의 개인 별 차이는 연령, 성별, 지역, 직업 등에 따라 달라질 수 있다. 사용자가 아동이고 학업시간이면 1시간 인터벌로 데이터를 전송하고, 이동 시이면 학업시간보다 전송시간이 짧아져 1, 3, 5, 1O분 등의 인터벌로 데이터를 전송할 수 있다. 미리 설정된 전송조건에 따른 데이터 전송 예를 들면, 주변환경을 파 악한 결과가 경찰서와 같은 위급상황에 해당하는 경우 데이터를 관리 서버에 전송한다. 미리 설정된 전송조 건은 사용자로부터 이상상태를 감지한 것으로, 예를 들어 사용자의 움직임이 급격하게 변하는 경우, 사용자가 소리를 지르는 것과 같이 미리 설정된 크기 이상의 음성이 감지되는 경우 등이 있다. 이를 위해 사용자 움직임 감지 센서, 음성 인식 센서 등이 추가로 장착될 수 있으며, 전송조건은 변경될 수 있다. 영상 분석부는 촬영 영상으로부터 시각 정보를 획득하고 획득된 시각 정보로부터 사용자의 주변환경을 인 식한다. 예를 들어, 영상 분석부는 촬영 영상으로부터 \"송민학교\"를 인식한다. 그러면, 인식 결과 값인 \"송민학교\"를 데이터 정합부에 전송한다. 데이터 정합부는 영상 속성정보 및 위치 데이터에 인식 결과 값인 \"송민학교\"를 결합하여 관리 서버에 전송한다. 일 실시 예에 따른 영상 분석부는 촬영 영상으로부터 기계학습을 통해 객체 이미지 및 문자 이미지 중 적 어도 하나를 인식하여 사용자의 위치 및 현재상황을 포함한 주변환경을 파악할 수 있다. 일 실시 예에 따른 영 상 분석부는 촬영 영상으로부터 인공지능(AI) 기반 기계학습을 통해 객체, 문자, 깊이 등의 시각정보를 인 식한다. 기계학습은 영상 속성정보로부터 특징을 추출하고 추출된 특징들을 이용하여 영상 데이터에서 객체를 구분하는 방법이다. 객체의 종류는 사람, 사물일 수 있다. 사람의 경우, 지인 여부를 인식할 수 있다. 사물이면 신호등인지 책인지 문인지 지하철 출입구인지 버스인지 등을 분류한다. 이때, 객체의 윤곽을 인식할 수 있다. 프로세서는 문자를 인식할 수 있는데, 문자는 단어, 문장, 기호, 숫자 등을 포함한다. 기계학습은 취약계층 보조장치에서 이루어지는데, 필요에 따라 취약계층 보조장치의 처리능력이 떨어지는 경우, 관리 서버 와의 협업을 통해 이루어질 수도 있다. 정보 변환부는 영상 분석부를 통해 인식된 시각정보를 청각정보로 변환하여 출력부에 제공한다. 출력부는 변환된 청각정보를 외부로 출력한다. 예를 들어, 촬영 영상으로부터 \"송민학교\"를 인식한 경우 \" 송민학교\"를 음성으로 사용자에 알려준다. 도 4는 본 발명의 일 실시 예에 따른 관리 서버의 구성을 도시한 도면이다. 도 1 및 도 4를 참조하면, 관리 서버는 사용자 관리부, 모니터링부, 네트워크 연결부, 원격 제 어부, 데이터 처리부, 클라이언트 관리부, 프로토콜 처리부, 데이터 분석부, 호 연결부 및 인터벌 관리부를 포함한다. 사용자 관리부는 사용자 요청에 따라 취약계층 보조장치의 사용자 정보를 관리하고 그 유효성을 검증한 다. 사용자 정보는 사용자 개인에 대한 정보로서, 성향, 나이, 성별, 직업, 연락처 등이 될 수 있다. 모니터링부는 취약계층 보조장치로부터 수신된 데이터를 모니터링한다. 수신된 데이터는 영상 속성정보, 주변환경 인식 결과 값, 위치 데이터 등이 결합한 데이터일 수 있다. 네트워크 연결부는 취약계층 보조장치 및 보호자 단말 등과 정보를 송수신한다. 네트워크 연결부(2 2)는 취약계층 보조장치로부터 결합 데이터를 수신할 수 있다. 네트워크 연결부는 결합 데이터 수신 이 후에, 모니터링부의 모니터링 결과에 따라 위치 확인이 필요한 상황, 사용자가 위치를 이동한 상황 등 보다 정밀한 분석이 필요한 경우 취약계층 보조장치에 촬영 영상을 요청하여 이를 수신할 수 있다. 원격 제어부는 취약계층 보조장치로부터 원격제어 요청을 수신하고 원격 제어명령을 취약계층 보조장치 에 전송하여 원격 엔지니어링을 수행한다. 데이터 처리부는 네트워크 연결부를 통해 취약계층 보조장치로부터 수신된 촬영 영상을 대상으로 기 계학습을 취약계층 보조장치에 이어서 수행하고 수행에 따른 최종 결과를 생성하여 네트워크 연결부에 제공할 수 있다. 이때, 네트워크 연결부는 최종 결과를 취약계층 보조장치에 제공한다. 관리 서버의 기계학습 기반 시각정보 인식은 취약계층 보조장치의 장치 처리능력에 따라 선택적으로 이루어질 수 있다. 예를 들어, 취약계층 보조장치의 장치 처리능력이 떨어지는 경우에, 관리 서버에 요청하면 관리 서버 에서 기계학습을 이어서 수행할 수 있다. 클라이언트 관리부는 취약계층 보조장치의 기기 상태 정보를 모니터링하여 에러를 사전에 예측하고, 에 러가 발생하기 이전에 에러를 처리하기 위한 사전 서비스 정보를 생성한다. 에러 예측은 수신된 기기 상태 정보 를 미리 설정된 임계값과 비교하는 방식을 이용할 수 있다. 예를 들어, 배터리 상태를 정상상태 및 위험상태로 구분하고 이를 배터리 잔량 임계값으로 구분한다. 수신된 기기 상태 정보인 배터리 잔량이, 정상상태 임계값과 위험상태 임계값 중 어디에 포함되는지를 판단하여 에러를 예측한다. 위험상태 임계값에 해당하는 경우 에러 예 측으로 판단할 수 있다. 사전 서비스 정보는 에러 예측 내역, 에러 발생 차단을 위한 경고 메시지 및 에러 이전 조치 정보 중 적어도 하 나를 포함한다. 에러 예측 내역은 에러 예측 상태를 나타내는 것으로, 에러가 예측되는 취약계층 보조장치의 식별을 위한 기기 명칭 또는 식별자, 기기 기본 정보, 기기 위치 정보, 에러 예측에 관한 시간 정보, 에러 원인 정보를 포함할 수 있다. 경고 메시지는 에러 발생을 경고하는 신호이다. 음성, 텍스트, 알람 음 등을 통해 경고 메시지를 출력할 수 있다. 에러 조치 정보에는 에러 사전 해결을 위한 방법, 컨택 포인트, 링크 정보 등이 포함 한다. 에러 사전 해결을 위한 방법의 예로는 문제가 발생한 부품의 교체, 충전 등이 있을 수 있다.프로토콜 처리부는 취약계층 보조장치의 정상신호를 수신하여 파싱하고 이를 처리하기 위한 통신규약을 구현해주는 소프트웨어 모듈이다. 데이터 분석부는 빅 데이터를 획득하여 분석하고 분석정보를 사전 서비스를 위해 클라이언트 관리부에 제공한다. 일 실시 예에 따른 데이터 분석부는 데이터 분석부의 분석 결과 또는 클라이언트 관리부(2 5)의 예측 결과로부터 통계정보를 생성하여 관리한다. 관리자는 통계정보를 통해 에러 예측 결과를 쉽게 파악할 수 있다. 데이터 분석부는 모니터링부의 모니터링을 통해 사용자 행동을 예측한다. 일 실시 예에 따른 데이터 분 석부는 미리 설정된 기간동안 기기 상태 정보를 수집하고 수집된 기기 상태 정보로부터 유효한 표준 데이터 를 추출함에 따라 취약계층 보조장치의 환경에 기반하여 유연하게 표준 데이터를 설정할 수 있다. 미리 설정 된 기간동안 수집되는 상태 정보는 그 양이 방대하므로 대량의 수집 데이터를 신속하게 처리할 수 있도록 빅 데 이터 분석을 수행할 수 있다. 예를 들어, 날씨정보와 날씨에 따른 상태정보를 수집하여 수집된 상태 정보로부터 유효한 표준 데이터를 추출한다. 호 연결부는 데이터 분석부의 사용자 행동 예측 결과에 따라 사용자의 위치 이동에 따라 발생하는 상시 데이터 및 위급 상황에 따라 발생하는 긴급 데이터를 사용자의 보호자에 제공하기 위해 보호자 단말과의 호 연결을 제어한다. 예를 들어, 호 연결부는 보호자에게 위급 상황을 알리는 긴급 데이터를 송부하여 상황에 즉각 대처할 수 있도록 한다. 알림 방식은 E-mail, SMS, ARS 등의 방식 등 기존의 통신수단을 모두 활용할 수 있다. 인터벌 관리부는 취약계층 보조장치로부터 데이터를 획득하기 위한 데이터 전송 인터벌을 조정한다. 인 터벌 관리부는 사용자의 개인 별, 상황 별 및 시간 별 중 적어도 하나에 의해 데이터 전송 인터벌을 조정할 수 있다. 도 5는 본 발명의 일 실시 예에 따른 사회적 취약계층을 위한 지능형 시력 보조 서비스 시스템의 개념을 도시한 도면이다. 도 5를 참조하면, 취약계층 보조장치는 사회적 취약계층인 사용자에 장착되어 사용자의 전면의 영상 속성정보를 획득하여 이를 위치 데이터와 함께 관리 서버에 전송함에 따라 사회적 취약계층을 보호 및 트래 킹한다. 취약계층 보조장치는 촬영 영상으로부터 인식된 시각정보를 청각정보로 변환하여 이를 출력함에 따 라 사용자의 시력을 보완할 수 있다. 사용자는 사회적 취약계층으로서, 개인, 기업, 공공기관으로 확장될 수 있다. 취약계층 보조장치는 본체와 제어장치(7-1)로 분리된 형태일 수 있다. 본체는 도 5에 도시된 바와 같 이 사용자 안경의 안경 다리에 탈부착하는 형태의 웨어러블 디바이스일 수 있다. 연결부는 본체와 제 어장치(7-1)를 연결한다. 연결부는 도 5에 도시된 바와 같이 유선으로 본체와 제어장치(7-1)를 연결할 수 있다. 무선방식을 이용하여 연결하거나 무선방식을 병행하여 사용할 수도 있다. 본체에 촬영부가 장착되고 제어장치(7-1)에 배터리가 장착될 수 있다. 다른 예로, 본체가 사용자 단말(예를 들어, 스마트폰)(7-2)과 연동된 형태일 수 있다. 연결부는 본체 와 사용자 단말(7-2)을 연결한다. 연결부는 도 5에 도시된 바와 같이 유선으로 본체와 사용자 단말(7- 2)을 연결할 수 있다. 무선방식을 이용하여 연결하거나 무선방식을 병행하여 사용할 수도 있다. 본체에 촬영 부가 장착되고 사용자 단말(7-2)의 배터리를 이용할 수 있다. 일 실시 예에 따른 취약계층 보조장치는 사용자 제스처, 예를 들어, 손바닥을 보인다든지 주먹을 쥐는 동작 을 통해 사용자가 하고자 하는 의도를 파악하여 파악된 의도에 맞는 시력 보조 서비스를 제공한다. 예를 들어, 사용자가 손바닥을 보이는 제스처를 보이면, 주변의 위험요소와 사용자 간의 거리를 추정하고 이를 안내 하는 서비스를 제공한다. 사용자가 멀리 떨어진 대상을 지시하더라도 이를 제스처를 통해 인지한다는 점에서 증강현실 기술이 적용된다. 일 실시 예에 따른 취약계층 보조장치는 촬영 영상으로부터 인공지능(AI) 기반 기계학습을 통해 객체를 구분 해 음성으로 알려준다. 취약계층 보조장치는 전면 객체와의 거리도 계산하여 알려준다. 객체를 인식하면 이 를 문자 정보로 변환하고 다시 음성신호로 변환하는 음성변환 기술이 적용된다. 음성신호는 골 전도 이어폰를 통해 사용자에 전달될 수 있다. 관리 서버는 취약계층 보조장치로부터 데이터를 수집하여 사회적 취약계층의 상황을 모니터링한다. 이때, 모니터링 결과에 따라 조치가 필요한 경우 이를 조치하며, 취약계층 보조장치에 대한 원격제어도 가능하다. 모니터링 및 원격제어는 실시간으로 이루어질 수 있다. 일 실시 예에 따른 관리 서버는 에러 예측에 따라 에러 발생 이전에 조치하는 사전 서비스를 제공한다. 이때, 관리자에게 에러 상태를 모니터링하여 경고함에 따라 관리자가 이를 제거하도록 지시할 수 있다. 관리자는 센터 담당자 또는 로컬 엔지니어일 수 있다. 센터 담당자는 총괄 권한이 있는 담당자이다. 로컬 담 당자는 고장 원인에 따라 현장에서 직접 조치할 수 있는 로컬 엔지니어이다. 관리 서버는 취약계층 보조장치 의 부품 불량, 장치 불량, 배터리 소진, 긴급상황 발생 등을 모니터링하여 관리자가 조치하도록 지시한다. 취약계층 보조장치에 긴급상황이 발생하면 이를 관리자에 경고한다. 취약계층 보조장치의 기기 자체나 부품에 문제가 발생하면, 문제가 발생한 기기 또는 부품을 사전 교체하도록 관리자에 지시한다. 조치의 다른 예로, 취약계층 보조장치에 직접 기기 제어 명령을 전송하여 취약계층 보조장치를 제어한다. 예를 들어, 취약계층 보조장치의 배터리 잔량이 미리 설정된 값 이하인 경우, 배터리를 교체하라는 제어 명 령을 전송하여 취약계층 보조장치 사용자가 이를 교체하도록 한다. 관리자는 관리 서버를 사용하는 사람으로서, 관리 서버를 통해 제공되는 정보를 확인한다. 이때, 관리 자는 에러 예측 결과를 다양한 관리자 단말, 예를 들어 컴퓨터, 데스크 탑, 테블릿 PC, 스마트폰 등을 통해 모니터링하면서 취약계층 보조장치의 에러를 사전에 인식한다. 관리자가 에러를 사전에 인식하면 해당 취 약계층 보조장치를 대상으로 원격진단(remote diagnosis) 및 복구(repair) 할 수 있다. 관리자는 관리 서버로부터 취약계층 보조장치에 대한 에러 예측에 따른 경고 메시지를 소정의 방식으 로 통보받을 수 있다. 소정의 방식이라 함은, 전화(call), 문자 메시지(MMS), 이메일(E-mail) 등일 수 있다. 관 리자는 경고 메시지를 통보받으면, 즉시 에러가 예측되는 취약계층 보조장치에 대한 조치를 취하거나, 소 정의 시점, 예를 들어 정기점검 때에 해당 취약계층 보조장치를 점검할 수 있다. 사전 서비스의 실시 예를 들면, 취약계층 보조장치의 사용자가 집을 나가기 전에, 집에서 취약계층 보조장치 를 가지고 Wi-Fi 연결을 통해 관리 서버에 접속하고, 취약계층 보조장치의 기기 상태 정보를 관리 서 버에 전송한다. 배터리 잔량을 예로 들면, 관리 서버는 수신된 기기 상태 정보 내 배터리 잔량이 미리 설 정된 임계값, 예를 들어 60% 이상이면 정상인 것으로 판단하여 사용자에게 정상임을 알린다. 사용자가 활동을 하다 카페에 들어가 Wi-Fi 연결을 통해 관리 서버에 접속하고, 관리 서버는 수신된 기기 상태 정보 내 배 터리 잔량이 미리 설정된 임계값, 예를 들어 30% 이하이면, 사용자에게 \"배터리를 갈아 주세요.\" 또는 \"배터리 를 충전해주세요.\" 등의 경고신호를 생성한다. 경고신호에 따라 사용자는 배터리를 갈거나 충전함에 따라 배터 리 문제를 해결한다. 에러 예측에 따른 사전 서비스를 위해 임계값을 미리 설정할 수 있다. 그리고 미리 설정된 임계값과 취약계층 보조장치로부터 수신된 기기 상태 정보 값을 비교하여 에러를 예측할 수 있다. 임계값은 취약계층 보조장치 의 사용자가 설정할 수 있고, 관리 서버가 빅 데이터 기반 분석을 통해 미리 설정해 놓을 수 있다. 사용 자 설정의 예로서, 사용자가 배터리 잔량이 30% 이하가 되면 관리 서버가 이를 자동으로 알림 하도록 설정할 수 있다. 도 6은 본 발명의 일 실시 예에 따른 사회적 취약계층 보호 프로세스가 적용된 시나리오를 설명하기 위한 도면 이다. 도 1 및 도 6을 참조하여 본 발명의 적용 시나리오를 예로 들면, 취약계층 보조장치는 사용자인 학생에 착용 된 형태로 외부 영상을 촬영하여 촬영 영상으로부터 사용자의 주변환경을 인식하여 주변환경 인식 값을 사용자 의 위치 데이터와 함께 관리 서버에 전송한다. 예를 들어, 촬영 영상으로부터 \"송민학교\"를 인식하여, 영상 속성정보(2018.11.01. 08:30 image00001)와, 인식 결과 값(송민학교) 및 위치 데이터(GPSData00001)를 결합한 패킷(2018.11.01. 08:30 image00001_송민학교_GPSData0000)을 관리 서버에 전송한다. 이때, 사용자의 개인 별, 상황 별 및 시간 별 중 적어도 하나에 의해 데이터 전송 인터벌이 조정될 수 있다. 예를 들어, 학업시간 때 는 1시간 인터벌로, 사용자 이동 시에는 1, 3, 5, 10분 등의 인터벌로 데이터를 전송하도록 인터벌이 조정된다. 도 7은 본 발명의 다른 실시 예에 따른 사회적 취약계층 보호 프로세스가 적용된 시나리오를 설명하기 위한 도 면이다. 도 1 및 도 7을 참조하여 본 발명의 적용 시나리오를 예로 들면, 취약계층 보조장치는 사용자인 치매환자에 착용된 형태로 외부 영상을 촬영하여 촬영 영상으로부터 사용자의 주변환경을 인식하여 영상 속성정보를 사용자 의 위치 데이터와 함께 관리 서버에 전송한다. 예를 들어, 촬영 영상으로부터 \"분당노인종합복지관\"을 인식하여, 영상 속성정보(2018.11.01. 08:30 image00001), 인식 결과 값(분당노인종합복지관) 및 위치 데이터 (GPSData00001)를 결합한 패킷(2018.11.01.08:30.11_image00001_분당노인종합복지관_GPSData00001)을 관리 서 버에 전송한다. 다른 예로, 촬영 영상으로부터 \"강원 횡성 경찰서\"를 인식하여, 영상 속성정보(2018.11.01. 12:30 image00001), 인식 결과 값(강원 횡성 경찰서) 및 위치 데이터(GPSData01001)를 결합한 패킷 (2018.11.01.12:30.31_image00001_강원횡성경찰서_GPSData01001)을 관리 서버에 전송한다. 관리 서버는 취약계층 보조장치로부터 수신된 영상 속성정보 및 위치 데이터로부터 사용자의 현재 상황을 파악하여 처리 한다. 결합 데이터를 수신한 관리 서버는 취약계층 보조장치에 추가로 촬영 영상을 요청하여 취약계층 보 조장치로부터 촬영 영상을 수신할 수 있다. 도 8은 본 발명의 일 실시 예에 따른 사회적 취약계층 보호 프로세스를 도시한 도면이다. 도 8을 참조하면, 취약계층 보조장치가 사회적 취약계층인 사용자의 신체에 착용된 형태로 외부 영상을 촬영 한다. 취약계층 보조장치가 촬영 영상으로부터 사용자의 주변환경을 인식하여 주변환경 인식 값을 사용자의 위치 데이터와 결합한 후, 결합 데이터를 관리 서버에 전송한다. 관리 서버에 전송하는 단계에서, 취약계층 보조장치는 영상 속성정보를 인식된 위치 데이터 및 주변 환경 인식 결과 값과 결합하여 관리 서버에 전송할 수 있다. 관리 서버에 전송하는 단계에서, 취약 계층 보조장치는 미리 설정된 시간 인터벌을 가지고 주기적으로 데이터를 전송하는 방식, 미리 설정된 전송 조건에 해당하면 데이터를 전송하는 방식, 관리 서버의 요청 시에 데이터를 전송하는 방식 중 적어도 하나를 이 용하여 데이터를 관리 서버에 전송할 수 있다. 사용자의 개인 별, 상황 별 및 시간 별 중 적어도 하나에 의 해 데이터 전송 인터벌이 조정될 수 있다. 관리 서버는 취약계층 보조장치로부터 수신된 데이터로부터 사용자의 현재 상황을 파악한다. 결합 데이터를 수신한 관리 서버는 취약계층 보조장치에 추가로 촬영 영상을 요청하여 취약계층 보조장치 로부터 촬영 영상을 수신할 수 있다. 관리 서버는 파악 결과에 따라 현재 상황을 보호자 단말에 알린다."}
{"patent_id": "10-2019-0003004", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이제까지 본 발명에 대하여 그 실시 예들을 중심으로 살펴보았다. 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 본 발명이 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있을 것이다. 그러므로 개시된 실시 예들은 한정적인 관점이 아니라 설명적인 관점에서 고려되어야 한다. 본 발명의 범위는 전술한 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동등한 범위 내에 있는 모 든 차이점은 본 발명에 포함된 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2019-0003004", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 사회적 취약계층 보호 시스템의 구성을 도시한 도면, 도 2는 본 발명의 일 실시 예에 따른 취약계층 보조장치의 구성을 도시한 도면, 도 3은 본 발명의 일 실시 예에 따른 도 2의 프로세서의 세부 구성을 도시한 도면, 도 4는 본 발명의 일 실시 예에 따른 관리 서버의 구성을 도시한 도면, 도 5는 본 발명의 일 실시 예에 따른 사회적 취약계층을 위한 지능형 시력 보조 서비스 시스템의 개념을 도시한 도면, 도 6은 본 발명의 일 실시 예에 따른 사회적 취약계층 보호 프로세스가 적용된 시나리오를 설명하기 위한 도면, 도 7은 본 발명의 다른 실시 예에 따른 사회적 취약계층 보호 프로세스가 적용된 시나리오를 설명하기 위한 도 면, 도 8은 본 발명의 일 실시 예에 따른 사회적 취약계층 보호 프로세스를 도시한 도면이다."}
