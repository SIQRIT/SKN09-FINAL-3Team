{"patent_id": "10-2019-0083437", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0007276", "출원번호": "10-2019-0083437", "발명의 명칭": "영상 생성 장치 및 방법", "출원인": "삼성전자주식회사", "발명자": "조은애"}}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 생성 장치에 있어서,영상을 출력하는 디스플레이;하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 복수의 프레임들을 포함하는 영상에서 오브젝트를 검출하고, 상기 검출된 오브젝트를 마스킹하기 위한 복수의 후보 바운더리들을 제공하고, 상기 제공된 복수의 후보 바운더리들을 평가하여 최적의 바운더리를 식별하고, 상기 최적의 바운더리를 이용하여 상기 오브젝트가 움직이는 부분 동영상을 생성하는, 영상 생성 장치."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 프로세서는 상기 식별된 최적의 바운더리를 이용하여 상기 복수의 프레임들 중 하나의프레임에서 상기 오브젝트를 마스킹하고, 상기 오브젝트가 마스킹된 상기 하나의 프레임과 상기 복수의 프레임들을 이용하여, 상기 오브젝트가 움직이는 부분 동영상을 생성하는, 영상 생성 방법."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서, 상기 프로세서는 제1 AI 모델을 이용하여, 상기 영상에서 상기 검출된 오브젝트를 마스킹하기위한 상기 복수의 후보 바운더리들을 제공하는, 영상 생성 장치."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서, 상기 제1 AI 모델은 복수 개의 세그멘테이션 AI 모델들을 포함하고, 상기 프로세서는 상기 복수 개의 세그멘테이션 AI 모델들을 이용하여 상기 복수 개 후보 바운더리들을 제공하는, 영상 생성 장치."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서, 상기 프로세서는 제2 AI 모델을 이용하여, 상기 제공된 복수의 후보 바운더리들을 평가하여평가 결과를 획득하는, 영상 생성 장치."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서, 상기 제2 AI 모델은 입력 데이터에 대해 기술적인 평가를 수행하는 AI 모델 및 심미적인 평가를 수행하는 AI 모델 중 하나 이상을 포함하는, 영상 생성 장치."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5 항에 있어서, 사용자 인터페이스를 더 포함하고, 상기 디스플레이는 상기 제2 AI 모델을 이용하여 획득한 상기 평가 결과에 따라 상기 복수의 후보 바운더리들중 순위가 높은 소정 개수의 바운더리들을 출력하고, 상기 프로세서는 상기 디스플레이를 통해 출력된 상기 소정 개수의 바운더리들 중 상기 사용자 인터페이스를 통해 사용자로부터 선택된 바운더리를 상기 최적의 바운더리로 식별하는, 영상 생성 장치."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서, 상기 제2 AI 모델은 상기 사용자의 선택에 대한 정보를 입력 받아 학습하고, 상기 후보 바운더리들을 평가할 때 상기 학습 결과를 이용하는, 영상 생성 장치.공개특허 10-2021-0007276-3-청구항 9 제8 항에 있어서, 상기 제2 AI 모델 상기 사용자의 선택에 대한 정보를 각 사용자 별로 분류하여 학습하는, 영상 생성 장치."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항에 있어서, 사용자 인터페이스를 더 포함하고, 상기 프로세서는 상기 복수의 프레임들을 트래킹하여 상기 영상에서 움직임이 있는 오브젝트를 식별하고, 상기식별된 오브젝트 중 상기 사용자 인터페이스를 통해 사용자로부터 선택된 오브젝트를 검출하는, 영상 생성장치."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "복수의 프레임들을 포함하는 영상에서 오브젝트를 검출하는 단계;상기 검출된 오브젝트를 마스킹하기 위한 복수의 후보 바운더리들을 제공하는 단계;상기 제공된 복수의 후보 바운더리들을 평가하여 최적의 바운더리를 식별하는 단계; 및상기 최적의 바운더리를 이용하여 상기 오브젝트가 움직이는 부분 동영상을 생성하는 단계를 포함하는, 영상 생성 방법."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서, 상기 부분 동영상을 생성하는 단계는 상기 식별된 최적의 바운더리를 이용하여 상기 복수의프레임들 중 하나의 프레임에서 상기 오브젝트를 마스킹하는 단계; 및상기 오브젝트가 마스킹된 상기 하나의 프레임과 상기 복수의 프레임들을 이용하여, 상기 오브젝트가 움직이는부분 동영상을 생성하는 단계를 포함하는, 영상 생성 방법."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11 항에 있어서, 상기 복수의 후보 바운더리들을 제공하는 단계는 제1 AI 모델을 이용하여, 상기 영상에서 상기 검출된 오브젝트를 마스킹하기 위한 상기 복수의 후보 바운더리들을 제공하는 단계를 포함하는, 영상 생성방법."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서, 상기 제1 AI 모델은 복수 개의 세그멘테이션 AI 모델들을 포함하고, 상기 복수의 후보 바운더리들을 제공하는 단계는 상기 복수 개의 세그멘테이션 AI 모델들 별로 각각 후보 바운더리를 제공하는 단계를포함하는, 영상 생성 방법."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11 항에 있어서, 상기 후보 바운더리들을 평가하는 단계는 제2 AI 모델을 이용하여, 상기 제공된 복수의 후보바운더리들을 평가하여 평가 결과를 획득하는 단계를 포함하는, 영상 생성 방법."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서, 상기 제2 AI 모델은 입력 데이터에 대해 기술적인 평가를 수행하는 AI 모델 및 심미적인 평가를 수행하는 AI 모델 중 하나 이상을 포함하고, 상기 후보 바운더리들을 평가하는 단계는 상기 제2 AI 모델을 이용하여 상기 후보 바운더리들에 대해 기술적인평가 및 심미적인 평가 중 하나 이상을 수행하는 단계를 포함하는, 영상 생성 방법."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15 항에 있어서, 상기 최적의 바운더리를 식별하는 단계는 상기 제2 AI 모델을 이용하여 획득한 상기 평가 결과에 따라 상기 복수의 후보 바운더리들 중 순위가 높은 소정공개특허 10-2021-0007276-4-개수의 바운더리들을 출력하는 단계; 및상기 출력된 바운더리들 중 사용자로부터 선택된 바운더리를 상기 최적의 바운더리로 식별하는 단계를포함하는, 영상 생성 방법."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17 항에 있어서, 상기 제2 AI 모델을 이용하여 상기 제공된 복수의 후보 바운더리들을 평가하는 단계는 상기 사용자의 선택에 대한 정보를 입력받아 학습하는 단계; 및상기 후보 바운더리들을 평가할 때 상기 학습 결과를 이용하는 단계를 더 포함하는, 영상 생성 방법."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18 항에 있어서, 상기 사용자의 선택에 대한 정보를 입력받아 학습하는 단계는 상기 사용자의 선택에 대한 정보를 각 사용자 별로 분류하여 학습하는 단계를 포함하는, 영상 생성 방법."}
{"patent_id": "10-2019-0083437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "복수의 프레임들을 포함하는 영상에서 오브젝트를 검출하는 단계;상기 검출된 오브젝트를 마스킹하기 위한 복수의 후보 바운더리들을 제공하는 단계;상기 제공된 복수의 후보 바운더리들을 평가하여 최적의 바운더리를 식별하는 단계; 및상기 식별된 최적의 바운더리를 이용하여 상기 오브젝트가 움직이는 부분 동영상을 생성하는 단계를 포함하는,영상 생성 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2019-0083437", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 딥러닝 등의 기계 학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 인공지능 (AI) 시스템 및 그 응용에 관련된 것이다. 일 실시 예에 따른 영상 생성 장치는, 영상을 출력하는 디스플레이, 하나 이상의 인스트럭션을 저장하는 메모리 및 메모리에 저장된 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 프로세서는 하나 이상의 인스트럭 션을 실행함으로써, 복수의 프레임들을 포함하는 영상에서 오브젝트를 검출하고, 검출된 오브젝트를 마스킹하기 위한 복수의 후보 바운더리들을 제공하고, 제공된 복수의 후보 바운더리들을 평가하여 최적의 바운더리를 식별하 고, 최적의 바운더리를 이용하여 오브젝트가 움직이는 부분 동영상을 생성할 수 있다."}
{"patent_id": "10-2019-0083437", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시된 다양한 실시 예들은 영상 생성 장치 및 그 동작 방법에 관한 것으로서, 보다 상세하게는, 인공지능 모델 을 이용하여 보다 자연스럽게 영상의 일부만 움직이는 영상을 생성하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2019-0083437", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이미지의 특정 부분만 움직이는 영상을 만드는 기술이 개발되고 있다. 이미지의 특정 부분만 움직이는 GIF 파일 을 만드는 기술로 Cinemagraph 기법 등이 있다. 이는 동영상 혹은 연속 촬영된 사진들 중 일부분을 추출하여, 이미지 내에서 움직이는 부분과 그렇지 않은 부분을 분리하여 GIF 파일로 합성함으로써 이미지의 특정 부분만 움직이도록 하는 기법이다. 인공지능(Artificial Intelligence, 이하, AI) 시스템은 기계가 스스로 학습(training)하고 판단하며 목적하는 결과를 도출하거나 목적하는 동작을 수행하는 시스템이다."}
{"patent_id": "10-2019-0083437", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "다양한 실시 예들은 인공지능 모델을 이용하여 보다 자연스럽게 영상의 일부만 움직이는 영상을 생성하는 방법 및 장치를 제공하기 위한 것이다."}
{"patent_id": "10-2019-0083437", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시 예에 따른 영상 생성 장치는, 영상을 출력하는 디스플레이, 하나 이상의 인스트럭션을 저장하는 메모리 및 상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 복수의 프레임들을 포함하는 영상에서 오브젝트를 검출하고, 상기 검 출된 오브젝트를 마스킹하기 위한 복수의 후보 바운더리들을 제공하고, 상기 제공된 복수의 후보 바운더리들을 평가하여 최적의 바운더리를 식별하고, 상기 최적의 바운더리를 이용하여 상기 오브젝트가 움직이는 부분 동영 상을 생성할 수 있다. 실시 예에서, 상기 프로세서는 상기 식별된 최적의 바운더리를 이용하여 상기 복수의 프레임들 중 하나의 프레 임에서 상기 오브젝트를 마스킹하고, 상기 오브젝트가 마스킹된 상기 하나의 프레임과 상기 복수의 프레임들을 이용하여, 상기 오브젝트가 움직이는 부분 동영상을 생성할 수 있다. 실시 예에서, 상기 프로세서는 제1 AI 모델을 이용하여, 상기 영상에서 상기 검출된 오브젝트를 마스킹하기 위 한 상기 복수의 후보 바운더리들을 제공할 수 있다. 실시 예에서, 상기 제1 AI 모델은 복수 개의 세그멘테이션 AI 모델들을 포함하고, 상기 프로세서는 상기 복수 개의 세그멘테이션 AI 모델들을 이용하여 상기 복수 개 후보 바운더리들을 제공할 수 있다. 실시 예에서, 상기 프로세서는 제2 AI 모델을 이용하여, 상기 제공된 복수의 후보 바운더리들을 평가하여 평가 결과를 획득 할 수 있다. 실시 예에서, 상기 제2 AI 모델은 입력 데이터에 대해 기술적인 평가를 수행하는 AI 모델 및 심미적인 평가를 수행하는 AI 모델 중 하나 이상을 포함할 수 있다. 실시 예에서, 상기 장치는 사용자 인터페이스를 더 포함하고, 상기 디스플레이는 상기 제2 AI 모델을 이용하여 획득한 상기 평가 결과에 따라 상기 복수의 후보 바운더리들 중 순위가 높은 소정 개수의 바운더리들을 출력하 고, 상기 프로세서는 상기 디스플레이를 통해 출력된 상기 소정 개수의 바운더리들 중 상기 사용자 인터페이스 를 통해 사용자로부터 선택된 바운더리를 상기 최적의 바운더리로 식별할 수 있다. 실시 예에서, 상기 제2 AI 모델은 상기 사용자의 선택에 대한 정보를 입력 받아 학습하고, 상기 후보 바운더리 들을 평가할 때 상기 학습 결과를 이용 할 수 있다. 실시 예에서, 상기 제2 AI 모델 상기 사용자의 선택에 대한 정보를 각 사용자 별로 분류하여 학습 할 수 있다. 실시 예에서, 상기 장치는 사용자 인터페이스를 더 포함하고, 상기 프로세서는 상기 복수의 프레임들을 트래킹 하여 상기 영상에서 움직임이 있는 오브젝트를 식별하고, 상기 식별된 오브젝트 중 상기 사용자 인터페이스를 통해 사용자로부터 선택된 오브젝트를 검출 할 수 있다. 일 실시 예에 따른 영상 생성 방법은 복수의 프레임들을 포함하는 영상에서 오브젝트를 검출하는 단계, 상기 검 출된 오브젝트를 마스킹하기 위한 복수의 후보 바운더리들을 제공하는 단계, 상기 제공된 복수의 후보 바운더리 들을 평가하여 최적의 바운더리를 식별하는 단계 및 상기 최적의 바운더리를 이용하여 상기 오브젝트가 움직이 는 부분 동영상을 생성하는 단계를 포함할 수 있다. 일 실시 예에 따른 컴퓨터로 판독 가능한 기록 매체는 복수의 프레임들을 포함하는 영상에서 오브젝트를 검출하 는 단계, 상기 검출된 오브젝트를 마스킹하기 위한 복수의 후보 바운더리들을 제공하는 단계, 상기 제공된 복수 의 후보 바운더리들을 평가하여 최적의 바운더리를 식별하는 단계 및 상기 식별된 최적의 바운더리를 이용하여 상기 오브젝트가 움직이는 부분 동영상을 생성하는 단계를 포함하는, 영상 생성 방법을 구현하기 위한 프로그램 이 기록된 컴퓨터로 판독 가능한 기록 매체일 수 있다."}
{"patent_id": "10-2019-0083437", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시 예에 따른 영상 생성 장치 및 방법은, 영상에서 검출된 오브젝트를 복수의 세그멘테이션 알고리즘을 이 용하여 복수의 바운더리들을 생성할 수 있다. 일 실시 예에 따른 영상 생성 장치 및 방법은, 복수의 바운더리들을 평가 알고리즘을 이용하여 최적의 바운더리 를 결정하고, 이를 이용하여 영상의 일부분만 움직이는 영상을 생성할 수 있다. 일 실시 예에 따른 영상 생성 장치 및 방법은, 사용자의 취향을 학습하고, 학습 결과를 반영하여 사용자 별로 최적화된 바운더리를 선별하여, 이를 이용하여 영상의 일부분만 움직이는 영상을 생성할 수 있다."}
{"patent_id": "10-2019-0083437", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시 예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시에서 사용되는 용어는, 본 개시에서 언급되는 기능을 고려하여 현재 사용되는 일반적인 용어로 기재되었 으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 다양한 다른 용어를 의미할 수 있다. 따라서 본 개시에서 사용되는 용어는 용어의 명칭만으로 해석되어서는 안되며, 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 해석되어야 한다. 또한, 본 개시에서 사용된 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것이며, 본 개시를 한정하려는 의도로 사용되는 것이 아니다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 본 명세서, 특히, 특허 청구 범위에서 사용된 “상기” 및 이와 유사한 지시어는 단수 및 복수 모두를 지시하는 것일 수 있다. 또한, 본 개시에 따른 방법을 설명하는 단계들의 순서를 명백하게 지정하는 기재가 없다면, 기 재된 단계들은 적당한 순서로 행해질 수 있다. 기재된 단계들의 기재 순서에 따라 본 개시가 한정되는 것은 아 니다. 본 명세서에서 다양한 곳에 등장하는 \"일부 실시 예에서\" 또는 \"일 실시 예에서\" 등의 어구는 반드시 모두 동일 한 실시 예를 가리키는 것은 아니다. 본 개시의 일부 실시 예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구 현될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정 의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로 그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으 로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술을 채용할 수 있다. “매커니즘”, “요소”, “수단” 및 “구성”등과 같은 용어는 넓게 사용될 수 있으 며, 기계적이고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다.또한, 명세서에서 “사용자”라는 용어는 영상 생성 장치를 이용하여 영상 생성 장치의 기능 또는 동작을 제어 하는 사람을 의미하며, 시청자, 관리자 또는 설치 기사를 포함할 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 일 실시 예에 따라, 일부분만 움직이는 영상을 생성하는 기술을 설명하기 위한 도면이다. 도 1을 참조하면, 복수의 프레임들(110, 120, 130, 140)은 연속하여 촬영된 사진 이미지일 수 있다. 복수의 프 레임들(110, 120, 130, 140)은, 시간에 따라 좌측 프레임부터 우측 프레임 순서로 촬영되어 있다고 가정한다. 각각의 프레임들(110, 120, 130, 140)에는 복수 개의 피사체들이 포함될 수 있다. 도 1에서 프레임들 (110, 120, 130, 140)에는 구름, 사람, 꽃, 나비가 함께 촬영되어 있음을 알 수 있다. 오 브젝트는 촬영된 피사체와 같은 의미일 수 있다. 실시 예에서, 오브젝트는 형태를 특정할 수 있는 피사체일 수 있다. 사용자는 연속하여 원하는 피사체, 즉, 오브젝트를 촬영할 수 있다. 오브젝트는 영상에서 시간에 따라 움직이는 것도 있을 수 있고, 정지되어 있는 것도 있을 수 있다. 예컨대, 도 1에서 구름은 시간 순서에 따라 좌측에 서 우측 방향으로 이동하고 있음을 알 수 있다. 도 1에서 사람은 좌측에서 우측으로 걸어가고 있음을 알 수 있고, 꽃은 시간의 흐름과 상관 없이 정지된 채로 있음을 알 수 있다. 도 1에서 나비는 날개를 피 고 있다가 시간의 흐름에 따라 편 날개를 접는 것을 알 수 있다. 이하, 설명의 편의를 위해, 이미지 내에서 특정 부분만 움직이는 영상을 부분 동영상으로 부르기로 한다. 부분 동영상을 생성하기 위해서는 영상에서 정적인 부분과 동적인 부분을 구분하는 것이 필요하다. 사용자는 영상 편 집 도구(tool)나 앱 등을 이용하여 영상에서 동적인 부분과 정적인 부분의 레이어를 구분하는 작업을 하거나 원 하는 영역을 마스킹하여 동적인 부분과 정적인 부분을 구분하는 작업을 할 수 있다. 이를 위해 사용자는 편집 도구에서 제공하는 브러쉬(brush)와 같은 도구를 이용하여 동적인 부분을 설정할 수 있다. 그러나 레이어를 구 분하는 작업을 하거나 마스킹하는 것이 서투른 사용자의 경우에는 자연스러운 바운더리를 생성하여 부분 동영상 을 생성하는 것이 어려울 수 있다. 실시 예에서, 영상 생성 장치(미도시)는 영상에 포함된 오브젝트들 중 동적인 부분으로 표시할 오브젝트를 마스 킹하기 위한 바운더리를 자동으로 결정하고, 결정된 바운더리에 따라 오브젝트를 마스킹하여 자연스러운 부분 동영상을 생성할 수 있다. 도 1에서 사용자는 정지된 이미지에 포함된 복수의 오브젝트들 중, 특정 오브젝트, 예컨대 나비만 날개를 접었다가 폈다가 하면서 움직이고, 다른 오브젝트들, 즉, 구름, 사람, 꽃은 정지되어 있는 부분 동영상을 생성하고 싶다고 가정한다. 도 1에서, 영상 생성 장치는 나비의 움직임을 표시할 영역을 결정하고, 결정된 영역에 따라 나 비를 마스킹할 수 있다. 나비의 움직임을 표시할 영역은 복수의 프레임들(110, 120, 130, 14 0)에서 나비가 움직이는 최대 거리를 반영하여 결정될 수 있다. 실시 예에서, 영상 생성 장치는 사용자가 선택한 나비에 대해 복수의 세그멘테이션 알고리즘들로 복수의 후보 바운더리들을 생성할 수 있다. 실시 예에서, 영상 생성 장치는 복수의 후보 바운더리들을 평가 알고리즘으로 평가하여 최적의 바운더리를 결정할 수 있다. 영상 생성 장치는 결정된 최적의 바운더리를 이용하여 나비의 영역을 마스킹할 수 있다. 영상 생성 장치는 복수의 프레임들(110, 120, 130, 140) 중 하나, 예컨대, 프레임 110을 정지 영상으로 이용하고, 정지 영 상에서 나비의 영역을 최적의 바운더리로 마스킹하고, 이 정지 영상과 복수의 프레임들(110, 120, 130, 140)을 함께 이용하여, 나비가 움직이는 부분 동영상을 생성할 수 있다. 도 1의 도면 부호 150은 실 시 예에 따라 생성된 부분 동영상을 나타낸다. 부분 동영상은 도면 부호 110의 정지 영상과 나머지 영역은 동일하고, 다만 나비가 있는 소정 영역만 다르다. 부분 동영상에 포함된 나비는 소정 영역에서 날개를 위아래로 접었다가 폈다가 하면서 움직이고 있음을 알 수 있다. 도 2는, 실시 예에 따라, 영상 생성 장치가 움직임을 표현할 오브젝트를 마스킹하는 것을 도시한 도면이다. 도 2를 참조하면, 영상 생성 장치(미도시)는 도 1에서 설명한 바와 같이, 사용자가 선택한 오브젝트인 나비를 마스 킹할 수 있다. 도 2에서 영상 생성 장치는 도 1에 개시된 복수의 프레임들(110, 120, 130, 140) 중 정지 영상으로 이용할 하나 의 프레임을 정하고, 정지 영상으로 이용할 하나의 프레임에서 나비가 움직이는 영역을 모자이크로 처리할 수 있다. 영상 생성 장치는 나비가 움직이는 영역을 마스킹되는 영역으로 정하고, 마스 킹되는 영역을 모자이크 처리하여 이를 사용자에게 보여줌으로써 마스킹되는 영역이 어디인지를 사용 자가 알 수 있도록 할 수 있다. 도 2에서는 나비가 움직이는 영역 전체가 모자이크로 처리되어 마스킹되었 으나, 이는 하나의 실시 예로, 영상 생성 장치는 사용자가 선택한 오브젝트의 테두리 부분만을 굵은 실선이나 가는 실선, 점선 등으로 표시함으로써 마스킹되는 영역의 경계 부분만을 표시할 수도 있음은 물론이다. 영상 생성 장치는 세그멘테이션 알고리즘을 이용하여 마스킹되는 영역에 대한 바운더리를 생성할 수 있다. 영상 생성 장치는 복수 개의 세그멘테이션 알고리즘들을 이용하여 복수 개의 후보 바운더리들을 생성할 수 있다. 영상 생성 장치는 생성된 복수 개의 후보 바운더리들을 하나 또는 복수 개의 평가 알고리즘들을 이용하여 평가 할 수 있다. 영상 생성 장치는 평가 결과에 따라 최적의 바운더리를 결정하고, 결정된 최적의 바운더리를 이용 하여 자연스러운 부분 동영상을 생성할 수 있다. 영상 생성 장치는 마스킹되는 영역을 프레임에서 잘 라내고, 소정 영역이 잘라진 프레임 아래로, 복수의 프레임들(110, 120, 130, 140)이 연속하여 보이도록 함으로 써, 정지 영상 중 나비만 움직이는 부분 동영상을 생성할 수 있다. 도 3은 실시 예에 따른 영상 생성 장치의 내부 블록도이다. 도 3을 참조하면, 영상 생성 장치는 프로세서 , 메모리, 디스플레이 및 사용자 인터페이스를 포함할 수 있다. 실시 예에서, 영상 생성 장치는 부분 영상을 생성할 수 있는 다양한 전자 장치로 구현될 수 있다. 영상 생 성 장치는 고정형 또는 이동형일 수 있다. 예를 들어, 영상 생성 장치는 데스크탑, 디지털 TV, 스마 트 폰(smartphone), 태블릿 PC(tablet personal computer), 이동 전화기(mobile phone), 화상전화기, 전자북 리더기(e-book reader), 랩탑 PC(laptop personal computer), 넷북 컴퓨터(netbook computer), 디지털 카메라, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 캠코더, 네비게이션, 웨어러블 장치 (wearable device), 스마트 와치(smart watch)중 적어도 하나를 포함할 수 있다. 프로세서는 영상 생성 장치의 전반적인 동작을 제어한다. 프로세서는 메모리에 저장된 하 나 이상의 인스트럭션을 실행함으로써, 영상 생성 장치가 기능하도록 제어할 수 있다. 실시 예에서, 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 복수의 프레임들을 포함하는 영상에서 오브젝트를 검출하고, 검출된 오브젝트를 마스킹하기 위한 복수의 후보 바운더리들을 생성하고, 이들을 평가하 여 최적의 바운더리를 결정하여 오브젝트가 움직이는 부분 동영상을 생성할 수 있다. 실시 예에서, 프로세서는 최적의 바운더리를 이용하여 복수의 프레임들 중 하나의 프레임에서 오브젝트를 마스킹하고, 오브젝트가 마스킹된 프레임과 복수의 프레임들을 이용하여, 오브젝트가 움직이는 부분 동영상을 생성할 수 있다. 이에 의하면, 프로세서는 복수의 프레임들에 포함된 영상에서 가장 최적의 바운더리를 결정하고 이를 이용 하여 오브젝트를 마스킹함으로써 자연스럽고 심미적으로도 우수한 부분 동영상을 생성할 수 있다. 실시 예에서, 프로세서는 영상에서 복수 개의 오브젝트를 추출할 수 있다. 사용자 별로, 부분 동영상에서 정지 상태로 두고 싶은 영역과 동적 영역으로 만들고 싶은 영역이 다를 수 있다. 따라서, 프로세서는 영상 에서 오브젝트가 복수개인 경우, 복수 개의 오브젝트를 추출하고 이를 디스플레이를 통하여 사용자에게 출 력할 수 있다. 사용자는 사용자 인터페이스를 통하여 동적 영역으로 만들고 싶어하는 오브젝트를 선택할 수 있다. 실시 예에서, 프로세서는 복수의 프레임들을 트래킹하여 영상에서 움직임이 있는 오브젝트만을 추출할 수 도 있다. 실시 예에서, 영상 생성 장치는 인공지능(Artificial Intelligence, AI) 기술을 이용할 수 있다. AI 기술 은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성될 수 있다. AI 기술은 알고리즘을 활용하여 구 현될 수 있다. 여기서, AI 기술을 구현하기 위한 알고리즘 또는 알고리즘의 집합을 신경망(Neural Network, 뉴 럴 네트워크)이라 한다. 여기서, 신경망은 입력 데이터를 입력 받고, 분석 및 분류를 위한 연산을 수행하여, 결 과 데이터를 출력할 수 있다. 이렇게, 신경망이 입력 데이터에 대응되는 결과 데이터를 정확하게 출력하기 위해 서는, 신경망을 트레이닝 시킬 필요가 있다. 여기서, ‘트레이닝(training)’은 신경망으로 다양한 데이터들을 입력시키고, 입력된 데이터들을 분석하는 방법, 입력된 데이터들을 분류하는 방법, 및/또는 입력된 데이터들에 서 결과 데이터 생성에 필요한 특징을 추출하는 방법 등을 신경망이 스스로 발견 또는 터득할 수 있도록 신경망을 훈련시키는 것을 의미할 수 있다. 신경만을 훈련시킨다는 것은 다수의 학습 데이터들에 학습 알고리즘을 적 용함으로써, 원하는 특성의 인공지능 모델이 만들어짐을 의미한다. 이러한 학습은 실시 예에 인공지능이 수행되 는 영상 생성 장치 자체에서 이루어질 수도 있고, 별도의 서버/시스템을 통해 이루어 질 수도 있다. 여기서, 학습 알고리즘은, 다수의 학습 데이터들을 이용하여 소정의 대상 기기(예컨데, 로봇)을 훈련시켜 소정 의 대상 기기 스스로 결정을 내리거나 예측을 할 수 있도록 하는 방법이다. 학습 알고리즘의 예로는, 지도형 학 습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으며, 실시 예에서의 학습 알고리즘은 명시한 경우를 제외하고 전 술한 예에 한정되지 않는다. 신경망을 통하여 입력 데이터에 대응되는 출력 데이터를 출력하도록 하는 알고리즘의 집합, 알고리즘의 집합을 실행하는 소프트웨어 및/또는 알고리집의 집합을 실행하는 하드웨어를 ‘AI 모델’(또는, ‘인공지능 모델’)이 라 칭할 수 있다. 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 AI 모델에 따라, 입력 데이터를 처리할 수 있다. 기 정의된 동작 규칙 또는 AI 모델은 특정한 알고리즘을 이용하여 만들어진 것일 수 있다. 또한 AI 모델 은 특정한 알고리즘이 학습된 것일 수 있다. 프로세서는 AI 모델을 통하여 입력 데이터에 대응되는 출력 데이터를 생성할 수 있다. 실시 예에서 프로세 서는 복수 개의 AI 모델들을 이용하여 입력 데이터로부터 최종 출력 데이터를 생성할 수 있다. 프로세서는 제1 AI 모델을 이용하여 영상에서 검출된 오브젝트를 마스킹하기 위한 복수의 후보 바운더리들 을 제공할 수 있다. 제1 AI 모델은 입력 데이터에서 특정 객체를 세그멘테이션하여 분리하는 알고리즘, 또는 알 고리즘의 집합, 알고리즘의 집합을 실행하는 소프트웨어 및/또는 알고리집의 집합을 실행하는 하드웨어일 수 있 다. 제1 AI 모델은 복수 개의 세그멘테이션 AI 모델들을 포함할 수 있다. 세그멘테이션 AI 모델들은 영상으로부터 오브젝트를 분리하는 AI 모델들 일 수 있으며, 알고리즘에 따라 동일한 입력 데이터가 들어와도 서로 다른 결과 를 출력할 수 있다. 실시 예에서, 각각의 세그멘테이션 AI 모델들은 입력 영상에 포함된 오브젝트를 마스킹하기 위한 바운더리를 각 각 생성할 수 있다. 실시 예에서, 프로세서는 생성된 복수의 후보 바운더리들을, 제2 AI 모델을 이용하여 평가할 수 있다. 제2 AI 모델은 입력 데이터를 평가하는 알고리즘, 또는 알고리즘의 집합, 알고리즘의 집합을 실행하는 소프트웨어 및/또는 알고리집의 집합을 실행하는 하드웨어일 수 있다. 입력 데이터를 평가하는 알고리즘은 입력 데이터에 대해 기술적인 평가를 수행하는 알고리즘이거나 또는 입력 데이터에 대해 심미적인 평가를 수행하는 알고리즘일 수 있다. 실시 예에서, 제2 AI 모델은 이러한 기술적인 평 가를 수행하는 AI 모델 및 심미적인 평가를 수행하는 AI 모델 중 하나 이상을 포함할 수 있다. 프로세서는 제2 AI 모델을 이용하여 복수의 후보 바운더리들 중 기술적 및/또는 심미적으로 우수한 바운더 리를 식별할 수 있다. 디스플레이는 프로세서가 식별한 우수한 바운더리를 화면에 출력할 수 있다. 프로세서가 식별한 우수한 바운더리가 복수 개인 경우, 디스플레이는 복수 개의 바운더리들을 출력할 수 있다. 실시 예에서, 디스플레이는 복수 개의 바운더리들 중 평가 점수가 높은 순서에 따라, 순서대로 바운더리들을 출력할 수 있다. 사용자는 사용자 인터페이스를 통해 디스플레이에 출력된 바운더리들 중 하나를 선택할 수 있다. 실시 예에서, 제2 AI 모델은 사용자가 바운더리를 선택하는 경우, 사용자의 선택에 대한 정보를 입력받아 학습 할 수 있다. 제2 AI 모델은 사용자가 선택한 정보를 학습하여 사용자의 취향이나 선호도를 파악하고, 향후, 입 력 데이터를 평가할 때 사용자의 선호도를 반영할 수 있다. 실시 예에서, 사용자가 복수 명인 경우, 제2 AI 모델은 사용자 별로 각 사용자의 선택 정보를 입력받아 학습할 수 있다. 제2 AI 모델은 사용자 각각이 선택한 정보를 파악하고, 향후 입력 데이터를 평가할 때 각 사용자 별로 학습한 사용자 별 선호도를 반영할 수 있다. 이에 따르면, 프로세서는 사용자 별 선호도를 학습하고 이를 향후 평가 시 이용함으로써 사용자 별로 최적 화된 평가 결과가 획득할 수 있도록 할 수 있다. 일 실시 예에 따른 메모리는, 적어도 하나의 인스트럭션을 저장할 수 있다. 메모리는 프로세서 가 실행하는 적어도 하나의 프로그램을 저장하고 있을 수 있다. 또한 메모리는 영상 생성 장치로 입 력되거나 영상 생성 장치로부터 출력되는 데이터를 저장할 수 있다. 실시 예에서, 메모리는 전술한 AI 모델을 적어도 하나 저장하고 있을 수 있다. 즉, 메모리는 제1 AI 모델 및 제2 AI 모델 중 적어도 하나를 저장할 수 있다. 메모리는 제1 AI 모델에 포함되는 복수 개의 세그 멘테이션 AI 모델들을 저장할 수 있다. 메모리는 제2 AI 모델이 복수 개의 평가 AI 모델들을 포함하는 경 우, 복수 개의 평가 AI 모델들을 저장할 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 실시 예에서, 프로세서는 프로세서의 내부에 또 다른 메모리(미도시)를 구비할 수 있다. 프로세서 는 내부에 구비되는 메모리에 하나 이상의 인스트럭션을 저장하고, 내부에 구비되는 메모리에 저장된 하나 이상의 인스트럭션을 실행하여 전술한 동작들이 수행되도록 제어할 수 있다. 즉, 프로세서는 프로세서 의 내부에 구비되는 내부 메모리 또는 메모리에 저장된 적어도 하나의 인스트럭션 또는 프로그램을 실행하여 소정 동작을 수행할 수 있다. 실시 예에 따른 디스플레이는, 패널(미도시) 등을 통하여 콘텐츠를 출력할 수 있다. 콘텐츠는 미디어 신호 로, 비디오 신호, 텍스트 신호 등을 포함할 수 있다. 디스플레이는 패널을 통하여, 비디오 신호를 사용자 가 시각적으로 인식할 수 있도록 비디오 신호에 대응되는 이미지를 출력할 수 있다. 비디오 신호는 동영상, 정 지 영상, 또는 정지 영상 중 일부분만이 움직이는 부분 동영상 등을 포함할 수 있다. 실시 예에서, 디스플레이는 영상에 포함된 복수의 프레임들을 순서대로 출력할 수 있다. 실시 예에서, 영 상은 촬영된 동영상일 수도 있고, 또는 연속하여 재생할 목적으로 생성된 애니메이션 등일 수도 있다. 실시 예에서, 디스플레이는 프로세서가 영상에서 오브젝트를 검출하면, 검출 결과를 출력할 수 있다. 예컨대, 디스플레이는 검출된 오브젝트의 경계를 선 등으로 표시하는 등의 방법으로 오브젝트를 식별하여 이를 사용자에게 보여줄 수 있다. 사용자는 디스플레이를 통해 영상에 포함된 오브젝트를 식별할 수 있다. 실시 예에서, 디스플레이는 프로세서에서 AI 모델을 통하여 생성한 출력 데이터를 포함하는 사용자 인터페이스 화면을 출력할 수 있다. 예컨대, 프로세서는 제2 AI 모델을 이용하여 복수의 후보 바운더리들 을 평가하고, 디스플레이는 평가 점수가 높은 바운더리들을 사용자에게 출력할 수 있다. 디스플레이 는 평가 점수가 높은 순서대로 바운더리들을 출력하거나 또는 평가 점수나 평가 순위를 나타내는 정보를 바운더 리와 함께 출력할 수 있다. 디스플레이는 사용자가 출력된 바운더리들 중 선호하는 바운더리를 선택할 수 있는 인터페이스 화면을 생성하고 이를 출력할 수 있다. 디스플레이는 최종 결정된 최적의 바운더리를 이용하여 생성된 부분 동영상을 화면에 출력할 수 있다. 디스플레이가 터치 스크린으로 구현되는 경우, 디스플레이는 출력 장치 이외에 입력 장치로 사용될 수 있다. 예를 들어, 디스플레이는 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스 플레이(thin film transistor-liquid crystal display), 유기 발광 다이오드(organic light-emitting diode), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전기 영동 디스플레이 (electrophoretic display) 중에서 적어도 하나를 포함할 수 있다. 그리고, 영상 생성 장치의 구현 형태에 따라, 영상 생성 장치는 디스플레이를 2개 이상 포함할 수 있다. 사용자 인터페이스는 영상 생성 장치를 제어하기 위한 사용자 입력을 수신할 수 있다. 사용자 인터페 이스는 사용자의 터치를 감지하는 터치 패널, 사용자의 푸시 조작을 수신하는 버튼, 사용자의 회전 조작을 수신하는 휠, 키보드(key board), 및 돔 스위치 (dome switch), 음성 인식을 위한 마이크, 모션을 센싱하는 모 션 감지 센서 등을 포함하는 다양한 형태의 사용자 입력 디바이스를 포함할 수 있으나 이에 제한되지 않는다. 또한, 영상 생성 장치가 원격 제어 장치(remote controller)(미도시)에 의해서 조작되는 경우, 사용자 인터페이스는 원격 제어 장치로부터 수신되는 제어 신호를 수신할 수도 있을 것이다. 사용자는 사용자 인터페이스를 통하여 영상에서 검출된 복수의 오브젝트들 원하는 오브젝트를 선택할 수 있다. 또한, 프로세서가 제공한 복수의 후보 바운더리들 중 순위가 높은 소정 개수의 바운더리들이 디스플 레이를 통해서 출력되면, 사용자는 사용자 인터페이스를 통하여 선호하는 바운더리를 선택할 수 있다. 도 4는 다른 실시 예에 따른 영상 생성 장치의 내부 블록도이다. 도 4의 영상 생성 장치는 도 3의 영상 생 성 장치를 포함하는 장치일수 있다. 이하, 도 4의 영상 생성 장치를 설명하는데 있어서 도 3에서와 중복되는 설명은 생략한다. 도 4에 도시된 영상 생성 장치는 도 3에 도시된 영상 생성 장치에 비하여 통신부, 촬영부 및 뉴럴 네트워크 프로세서를 더 포함할 수 있다. 통신부는 유무선의 네트워크를 통하여 외부 장치(미도시)들과 통신할 수 있다. 구체적으로, 통신부는 프로세서의 제어에 따라서 유무선의 네트워크를 통하여 연결되는 외부 장치와 신호를 송수신할 수 있다. 외부 장치는 디스플레이를 통하여 출력되는 콘텐츠를 공급하는 콘텐츠 공급 서버나 방송국 서버 또는 전자 장치 등이 될 수 있고 USB 등과 같은 정보 저장 매체일 수도 있다. 또한 외부 장치는 통신부와 데이터를 송수신하는 데이터를 처리하는 서버, 서버 시스템, 서버 기반의 장치 등을 포함할 수 있다. 통신부는 근거리 통신 모듈, 유선 통신 모듈, 이동 통신 모듈, 방송 수신 모듈 등과 같은 적어도 하나의 통신 모듈을 포함할 수 있다. 통신 모듈은 방송 수신을 수행하는 튜너, 블루투스, WLAN(Wireless LAN)(Wi-Fi), Wibro(Wireless broadband), Wimax(World Interoperability for Microwave Access), CDMA, WCDMA 등과 같은 통신 규격을 따르는 네트워크를 통하여 데이터 송수신을 수행할 수 있는 통신 모듈을 포함할 수 있다. 실시 예에서, 통신부는 외부 장치로부터 복수의 프레임들을 포함하는 영상을 수신할 수 있다. 실시 예에서, 통신부는 각종 인스트럭션이나, 프로세서가 이용하는 알고리즘, 알고리즘들로 구현되는 AI 모델 등을 외부 장치로부터 수신할 수도 있다. 통신부는 프로세서에 의해 생성된 부분 동영상을 외부 장치로 전송할 수도 있다. 촬영부는 피사체, 즉, 오브젝트를 촬영하여 영상을 생성하고, 이를 신호 처리 할 수 있다. 실시 예에서, 촬영부는 카메라(미도시)를 포함할 수 있다. 사용자는 촬영부를 이용하여 촬영하고자 하는 피사체를 소정 시간 동안 촬영하여 복수의 프레임들을 포함하는 영상을 획득할 수 있다. 실시 예에서, 피사체는 복수 개 일 수 있다. 실시 예에서, 복수의 프레임들에 포함된 피사체는 시간에 따라 움직임이 있는 피사체일 수 있다. 카메라는 피사체에 대한 정보를 CCD나 CMOS 등의 이미지 센서(미도시)에 상이 맺히도록 할 수 있고, 이미지 센 서는 카메라를 통해 들어온 빛을 전기적인 신호로 변환할 수 있다. 촬영부는 촬영한 영상에 대해 AE(Auto Exposure), AWB(Auto White Balance), Color recovery, correction, Sharpening, Gamma, Lens shading correction 중 하나 이상의 신호 처리를 수행할 수 있다. 도 4에 도시된 영상 생성 장치는 도 3에 도시된 영상 생성 장치에 비하여 뉴럴 네트워크 프로세서 을 더 포함할 수 있다. 즉, 도 4의 영상 생성 장치는 도 3의 영상 생성 장치와 달리, 뉴럴 네트 워크를 통하여 연산을 수행하는 것을 프로세서와는 별도의 프로세서인 뉴럴 네트워크 프로세서를 통 하여 수행할 수 있다. 뉴럴 네트워크 프로세서는 하나 이상의 인스트럭션을 실행하여 뉴럴 네트워크를 통한 연산이 수행되도록 할 수 있다. 구체적으로, 뉴럴 네트워크 프로세서는 뉴럴 네트워크를 통한 연산을 수행하여, 복수의 프레임들을 포함하 는 영상에서 검출된 오브젝트를 마스킹하기 위한 복수의 후보 바운더리들을 제공하고, 제공된 복수의 후보 바운 더리들을 평가하여 최적의 바운더리를 식별할 수 있다. 프로세서 또는 뉴럴 네트워크 프로세서는 식별된 최적의 바운더리를 이용하여 복수의 프레임들 중 하 나의 프레임에서 오브젝트를 마스킹하고, 오브젝트가 마스킹된 하나의 프레임과 복수의 프레임들을 이용하여, 오브젝트가 움직이는 부분 동영상을 생성할 수 있다. 뉴럴 네트워크 프로세서는 제1 AI 모델을 이용하여, 영상에서 검출된 오브젝트를 마스킹하기 위한 복수의 후보 바운더리들을 제공할 수 있다. 제1 AI 모델은 복수 개의 세그멘테이션 AI 모델들을 포함할 수 있다. 뉴럴네트워크 프로세서는 복수 개의 세그멘테이션 AI 모델들을 이용하여 후보 바운더리들을 복수 개 제공할 수 있다. 뉴럴 네트워크 프로세서는 제2 AI 모델을 이용하여, 복수의 후보 바운더리들을 평가하여 평가 결과를 획득 할 수 있다. 제2 AI 모델은 입력 데이터에 대해 기술적인 평가를 수행하는 AI 모델 및 심미적인 평가를 수행하 는 AI 모델 중 하나 이상을 포함할 수 있다. 디스플레이는 복수의 후보 바운더리들 중 순위가 높은 소정 개수의 바운더리들을 출력하고, 사용자 인터페 이스는 사용자로부터 디스플레이된 소정 개수의 바운더리들 중 하나를 선택 받을 수 있다. 뉴럴 네트워크 프로세서는 사용자로부터 선택된 바운더리를 최적의 바운더리로 식별할 수 있다. 뉴럴 네트 워크 프로세서는 제2 AI 모델을 이용하여 사용자의 선택에 대한 정보를 입력 받아 학습하고, 후보 바운더 리들을 평가할 때 학습 결과를 이용할 수 있다. 뉴럴 네트워크 프로세서는 복수의 사용자들에 대해, 각 사 용자가 특정 바운더리를 선택하는 것을 이용하여, 사용자 별로 사용자의 선택에 대한 정보를 입력 받아 학습하 고, 학습 결과를 각 사용자 별로 분류하여 이용할 수 있다. 뉴럴 네트워크 프로세서는 향후 특정 사용자가 후보 바운더리들에 대한 평가 작업을 요청하면, 사용자 별로 분류된 각 사용자의 취향을 반영하여 특정 사용자 가 선호할 만한 평가 결과를 제공할 수 있다. 실시 예에서, 뉴럴 네트워크 프로세서는 영상 생성 장치에 포함되지 않고, 통신부를 통해 신호 를 송수신할 수 있는 외부 장치에 포함된 것일 수도 있다. 이 경우, 영상 생성 장치는 영상에서 검출된 오 브젝트에 대해 최적의 바운더리를 결정해 줄 것을 통신부를 통해 외부 장치로 요청하고, 외부 장치가 AI 모델을 이용하여 결정된 최적의 바운더리에 대한 정보를 전송하면, 그 결과를 이용하여 부분 동영상을 생성할 수도 있다. 도 5는 실시 예에 따라, AI 모델이 입력 데이터를 처리하여 출력 데이터를 생성하는 것을 설명하기 위한 도면이 다. 실시 예에서, AI 모델은 입력 데이터를 수신하고 목적하는 결과를 출력하도록 동작하는 적어도 하나의 레이어를 포함하는 뉴럴 네트워크 그 자체를 의미할 수 있다. 또한, 실시 예에서, AI 모델은 뉴럴 네트워크를 통한 연산 을 수행하여 목적하는 결과를 출력하는 알고리즘 또는 복수의 알고리즘의 집합, 이러한 알고리즘 또는 그의 집 합을 실행하기 위한 프로세서(processor), 이러한 알고리즘 또는 그의 집합을 실행하기 위한 소프트웨어, 또는 이러한 알고리즘 또는 그의 집합을 실행하기 위한 하드웨어를 의미할 수 있다. 도 5를 참조하면, 실시 예에서, AI 모델은 제1 AI 모델 및 제2 AI 모델을 포함할 수 있다. 제1 AI 모 델 및/또는 제2 AI 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 각 레이어는 복수의 가중치 (weight values)를 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치의 연산을 통해 레이어의 연산을 수행할 수 있다. 실시 예에서, 제1 AI 모델을 구성하는 신경망, 즉, 뉴럴 네트워크(Neural Network)는, 뉴럴 네트워크에 입 력된 영상으로부터, 영상 내의 오브젝트를 세그멘테이션하기 위한 바운더리를 생성하는 방법을 학습하는 알고리 즘의 집합일 수 있다. 실시 예에서, 제2 AI 모델을 구성하는 뉴럴 네트워크는, AI 기술에 기초하여 뉴럴 네트워크에 입력된 복수 의 바운더리 후보군들을 평가하는 방법을 학습하는 알고리즘의 집합일 수 있다. 제2 AI 모델을 구성하는 뉴럴 네트워크는, 평가 대상이 되는 영상이나 바운더리를 입력 값으로 하는 지도 학습(supervised learning), 및/또는 별다른 지도 없이 영상이나 바운더리들을 평가하기 위해 필요한 데이터의 종류를 스스로 학습함으로써, 영상이나 바운더리들을 평가하기 위한 패턴 또는 방법을 발견하는 비지도 학습(unsupervised learning)에 기초 하여, 바운더리를 평가하는 방법을 학습할 수 있다. 실시 예에서, 제2 AI 모델을 구성하는 뉴럴 네트워크는, 학습에 따라 바운더리를 인식한 결과에 대한 피드 백을 이용하는 강화 학습(reinforcement learning)을 이용하여, 바운더리를 평가하는 방법을 학습할 수 있다. 또 다른 예로, 뉴럴 네트워크는 준지도형 학습(semi-supervised learning)을 이용하여, 바운더리를 평가하는 방 법을 학습할 수 있다. 실시 예에서, 제1 AI 모델은 입력 데이터를 입력 받고, 입력 데이터에 대해 뉴럴 네트워크를 통 한 연산을 수행하여, 입력 데이터에 대응되는 결과를 출력할 수 있다. 실시 예에서, 입력 데이터는 오브젝트가 포함된 영상일 수 있다. 제1 AI 모델은 복수의 프레임들로 구성된 영상에 포함된 오브젝트 중사용자가 원하는 오브젝트에 대해, 그 오브젝트를 세그멘테이션하기 위한 바운더리를 생성할 수 있다. 세그멘테이션은 영상에서 오브젝트를 분할하는 것을 의미할 수 있다. 세그멘테이션은 디지털 영상을 여러 개의 픽셀 집합으로 나누는 과정으로, 영상을 보다 의미있고 해석하기 쉬운 것으로 단순화하거나 변환하는 것을 의미 할 수 있다. 실시 예에서, 제1 AI 모델은 영상에서 오브젝트의 선이나 곡선 등의 경계를 찾아, 오브젝트의 윤곽선을 검 출할 수 있다. 제1 AI 모델은 오브젝트의 윤곽선을 표시하는 바운더리를 생성할 수 있다. 제1 AI 모델 에 따라 생성되는 바운더리는 다양한 양상을 가질 수 있다. 또한, 동일한 제1 AI 모델을 이용하더라 도, 입력 데이터에 따라 생성되는 바운더리는 달라질 수 있다. 제2 AI 모델은 제1 AI 모델의 출력 값을 입력 받아 뉴럴 네트워크를 통한 연산을 수행하여 출력 데이 터를 출력할 수 있다. 제2 AI 모델은 제1 AI 모델의 출력 값인, 다양한 바운더리들을 입력 받고, 이들을 평가하여 영상에서 오브젝트를 세그멘테이션하는데 이용될 최적의 바운더리를 찾아 이를 출력 데 이터로 출력할 수 있다. 도 6은 실시 예에 따라, AI 모델을 이용하여 입력 데이터를 처리하여 오브젝트에 대한 최적의 바운더리를 결정 하는 것을 설명하기 위한 도면이다. 도 6을 참조하면, 입력 데이터는 영상일 수 있다. 보다 구체적으로, 입력 데이터는 세그멘테이션 할 수 있는 오브젝트를 포함하는 영상일 수 있다. 실시 예에서, 세그멘테이션 할 오브젝트는 움직임이 있는 오브젝 트일 수 있다. 실시 예에서, 도 6에 개시된 오브젝트는 영상에 포함된 건물일 수 있다. 예컨대, 도 6에 개시된 영상은 지진으 로 인해 건물이 흔들리는 경우를 촬영한 영상이라고 가정한다. 사용자는 건물 외의 다른 부분은 정지되어 있고, 건물만 흔들거리는 부분 동영상을 생성하고 싶다고 가정한다. 사용자는 입력 데이터에 포함된 오브젝트를 직접 식별하고 이를 영상 생성 장치에 알려줄 수 있다. 또는 영상 생성 장치는 입력된 영상에서 움직임을 트래킹하여 움직임이 있는 오브젝트인 건물을 식별하고 이를 화면에 출력하여 사용자에게 보여줄 수도 있다. 영상 생성 장치는 건물 외에도 땅이 흔들거리거나 사 람들이 움직이는 경우, 이러한 움직임을 트래킹하여 움직임이 감지된 땅 또는 사람들을 오브젝트로 표시하여 사 용자에게 보여줄 수도 있다. 사용자는 이 중 원하는 오브젝트인 건물을 선택하여 부분 동영상에서 정지 부분으로 표시할 영역과 동적 부분으 로 표시할 영역을 구분하여 줄 수 있다. 영상 생성 장치는 AI 모델을 이용하여 입력 데이터를 입력 받아 뉴럴 네트워크를 통한 연산을 수행하 여 출력 데이터를 출력할 수 있다. 실시 예에서 AI 모델은 제1 AI 모델 및 제2 AI 모델을 포함 할 수 있다. 실시 예에서, AI 모델에서 사용되는 뉴럴 네트워크는 복수의 은닉 레이어(hidden layer)들을 통한 연산을 수행 하는 심층 신경망(DNN: Deep Neural Network)일 수 있다. 뉴럴 네트워크가 연산을 수행하는 내부의 레이어 (layer)인 은닉 레이어(hidden layer)를 복수 개 포함하는 경우, 즉 연산을 수행하는 뉴럴 네트워크의 심도 (depth)가 증가하는 경우, 이러한 뉴럴 네트워크는 심층 신경망으로 분류될 수 있다. 신경망의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크 (Deep Q-Networks) 등이 있으며, 실시 예에서 뉴럴 네트워크는 명시 한 경우를 제외하고 전술한 예에 한정되지 않는다. 또한, CNN 뉴럴 네트워크는 DCNN(Deep Convolution Neural Network) 또는 캡스넷(Capsnet) 뉴럴 네트워크(미도시) 등으로 세분화 될 수 있다. 실시 예에서, 영상 생성 장치는 제1 AI 모델을 이용하여 입력 데이터를 처리하여 오브젝트에 대한 바 운더리들을 복수 개 생성할 수 있다. 제1 AI 모델에서 출력되는 바운더리는 영상에서 해당 오브젝트를 다 른 것과 식별하기 위한 윤곽선일 수 있다. 제1 AI 모델은 영상에 포함된 오브젝트와 나머지 영역 간 색상, 채도, 명도, 대비 등을 기반으로, 오브젝트를 분리하기 위한 윤곽선의 선명도, 윤곽선의 종류, 윤곽선의 굵기, 텍스처의 크기 등 다양한 특성에 따라 오브젝트를 세그멘테이션하기 위한 바운더리를 생성할 수 있다. 영상에서 오브젝트를 세그멘테이션하는 기술은 크게 픽셀 기반, 엣지(Edge) 기반, 및 영역 기반의 방법을 포함 할 수 있다. 픽셀 기반의 세그멘테이션 알고리즘으로는 thresholding 방법이 있으며 이 방법은 특정 임계값을 정하고 그보다 작으면 검은색으로 그보다 같거나 크면 흰색으로 표시하여 오브젝트를 세그멘테이션하는 방법으 로 영상의 경계를 추출하거나 이진화(Binarization)을 위해 사용되는 경우가 많다. 엣지 기반 세그멘테이션 알고리즘은 엣지에서 차이가 있는 픽셀을 찾고, 찾은 픽셀들을 연결하는 과정으로 이루 어진 알고리즘일 수 있다. 엣지 기반 세그멘테이션 알고리즘은 세그멘테이션에 필요한 의미 있는 엣지뿐 아니라 영상 속에 있는 모든 엣지를 검출하기 때문에 거기서 의미 있는 엣지만을 다시 고르는 후처리 과정을 수반한다. 후처리 과정으로는 Thinning이나 Linking, Hough Transform, 기타 다양한 알고리즘을 이용하여 의미 있는 영역 만을 검출하는 과정 등이 포함될 수 있다. 엣지 기반 세그멘테이션 알고리즘으로 많이 쓰이는 기술은 Canny 엣 지 방법이 있고, 이외에도 Susan 엣지 검출 방법 등이 있을 수 있다. 영역 기반 세그멘테이션 기법은 영상에서 비슷한 속성을 갖는 부분에 집중하여, 밝기 값(intensity), 계조 (gray-level)뿐 아니라 컬러나 표면의 무늬, 질감 등에 있어서 비슷한 속성을 갖는 부분을 같은 영역으로 지정 을 하여 오브젝트를 분류하는 방식이다. 영역 기반 세그멘테이션 기법은 인지가 가능한 객체의 경계를 다른 것 과 구별짓는 알고리즘일 수 있다. 영역 기반 방식에서 가장 많이 사용되는 region-growing 알고리즘 방식은 기 준 픽셀(seed)을 정하고 주변 픽셀과의 비교를 통해 기준 픽셀과 비슷한 속성을 갖는 픽셀들을 같은 영역으로 간주하고 영역을 확장하여 같은 속성을 갖는 것들이 없으면 확장을 마치는 방식일 수 있다. 또 다른 영역 기반 세그멘테이션 기법으로는 region merging 방식, region splitting 방식 등이 있을 수 있다. Watershed 세그멘테이션 방식은 지형학에서 사용하는 개념들과 비슷한 방식으로 영역을 나누는 방식으로, Watershed를 구현하는 알고리즘은 다양한 알고리즘들이 개발되고 있으며 이 중 하나로 Flooding 알고리즘이 있 다. 실시 예에서, 제1 AI 모델은 전술한 다양한 세그멘테이션 알고리즘을 활용하여 구현될 수 있다. 실시 예에 서, 제1 AI 모델에는 복수 개의 세그멘테이션 AI 모델들(611, 612, 613, 614, 615, 616)이 포함될 수 있 다. 복수 개의 세그멘테이션 AI 모델들(611, 612, 613, 614, 615, 616)은 각각 하나 또는 복수의 뉴럴 네트워크 를 이용하여 입력에 대응하는 결과를 출력할 수 있다. 복수 개의 세그멘테이션 AI 모델들(611, 612, 613, 614, 615, 616)을 구현하는 각각의 뉴럴 네트워크는 입력 데이터를 입력 받고, 전술한 분석 및 분류를 위한 연 산을 수행하여, 보다 정확한 결과 데이터인 바운더리를 출력하도록 트레이닝된, 특정한 세그멘테이션 특성을 가 진 알고리즘일 수 있다. 도 6에서 세그멘테이션 AI 모델들(611, 612, 613, 614, 615, 616)로부터 생성된 바운더리 후보들을 살펴 보면, 어떤 것은 바운더리가 매우 디테일하고, 어떤 것은 그렇지 않고, 또 어떤 것은 바운더리의 굵기가 매우 굵고, 어떤 것은 매우 가늘고, 등등 복수의 바운더리들이 모두 다르다는 것을 알 수 있다. 제2 AI 모델은 제1 AI 모델에서 출력되는 복수의 바운더리 후보들을 입력 데이터로 입력 받고, 입력 데이터에 대한 평가를 수행하여 출력 데이터를 출력할 수 있다. 제2 AI 모델은 복수의 이미지 및/또는 바운더리에 대한 기술적인 면을 평가하는 뉴럴 네트워크이거나, 또는 이미지나 바운더리에 대한 복수의 사용자의 심미적 선호도를 학습한 뉴럴 네트워크 중 하나 이상을 포함할 수 있다. 실시 예에서, 제2 AI 모델은 복수의 후보 바운더리들에 대해 기술적 및/또는 심미적인 면을 평가하고, 평 가 결과가 가장 좋은 바운더리를 출력 데이터로 출력할 수 있다. 영상 생성 장치는 출력된 바운더리를 이용하여 프레임에서 오브젝트를 마스킹하고, 오브젝트가 마스 킹된 프레임 및 복수의 프레임들을 이용하여 바운더리 내의 오브젝트만 움직이는 부분 동영상을 생성할 수 있다. 도 7은 실시 예에 따라, 제2 AI 모델이 사용자의 선택을 피드백 데이터로 입력받아 학습하는 것을 설명하기 위 한 도면이다. 도 7은 도 6과 유사하나, 제2 AI 모델이 포함하는 알고리즘이 복수 개라는 점과, 복수 개의 출력 데이터 중 하나를 사용자로부터 선택 받고 그 결과를 제2 AI 모델이 학습한다는 점에서 도 6과 구별된다. 이하, 도 6과 중복되는 내용은 생략하기로 한다. 도 7을 참조하면, 영상 생성 장치는 AI 모델을 이용하여 입력 데이터를 입력 받아 뉴럴 네트워크를 통한 연산을 수행하여 출력 데이터를 출력할 수 있다. 실시 예에서 AI 모델은 제1 AI 모델 및 제2 AI 모델을 포함할 수 있다. 실시 예에서, 영상 생성 장치는 제1 AI 모델을 이용하여 입력 데이터를 처리하여 오브젝트에 대한 바 운더리 후보들을 생성할 수 있다. 실시 예에서, 제2 AI 모델은 입력 데이터를 평가하는 모델일 수 있다. 실시 예에서, 제2 AI 모델은 이미지나 바운더리의 기술적인 부분을 평가하는 AI 모델 및 이미지나 바운더리의 심미적인 면을 평가하는 AI 모델을 포함할 수 있다. 이미지나 바운더리의 기술적인 부분을 평가하는 AI 모델은, 이미지나 바운더리에서 원본과의 오차율, 노이 즈, 흐림(해상도), 압축 아티팩트 등과 같은 픽셀 수준의 품질 저하 여부를 평가하는 알고리즘으로 구현되는 AI 모델일 수 있다. 이미지나 바운더리의 기술적인 부분을 평가하는 알고리즘으로는 PSNR(Peak Signal-to-Noise Ratio), MSE(Mean Square Error), SSIM(Structural Similarity) 등이 있을 수 있다. PSNR은 신호가 가질 수 있는 최대 신호에 대한 잡음의 비를 나타내는데 주로 영상 또는 동영상 손실 압축에서 화질 손실 정보를 평가할 때 사용한다. MSE는 평균 제곱 오차를 의미하며, 원본 영상과, 이 영상에 어떤 영상 처리를 해서 나온 결과 영상을 비교하여 두 영상의 픽셀 값들의 차이에 대한 측정값을 나타낸다. MSE에 Root를 씌운것이 RMSE인데 이것은 통계학에서 표준편차의 의미로 사용될 수 있다. SSIM은 구조적 유사 지수를 의미하며, 압축 및 변환에 의해 발생하는 왜곡에 대하여 원본 영상에 대한 유사도를 측정하는 방법이다. 영상의 기술적인 부분을 평가하는 AI 모델은 전술한 기술들만 구현되는 것으로 한정되지 않으며, 향후 개 발될 수 있는 다양한 형태의 기술 평가 기법들을 이용한 알고리즘으로 구현될 수 있음은 물론이다. 이미지나 바운더리의 심미적인 면을 평가하는 AI 모델은 복수의 사람들이 이미지나 바운더리를 보고 심미 적인 면을 평가한 결과를 학습하여 생성된 알고리즘일 수 있다. 이러한 모델로는, 예컨대, NIMA(Neural Image Assessment) 등이 있을 수 있다. 이미지나 바운더리에 대한 미적 평가는 이미지나 바운더리의 정서 및 아름다움 과 관련된 의미론적 수준의 특성을 다루는 기술로, 이러한 알고리즘은 이미지나 바운더리에 대한 평가 결과를 평점 등으로 매기고 평점의 분포를 예측하여 품질 예측이 가능하도록 하는 기술일 수 있다. NIMA는 전형적인 사용자가 어떤 이미지를 좋게 또는 미적으로 매력적으로 보는지 예측할 수 있도록 교육받은 deep CNN으로, 인간의 인지와 높은 상관 관계를 가지고 안정적으로 이미지의 점수를 매길 수 있는 뉴럴 네트워 크일 수 있다. NIMA 모델은 입력된 이미지나 바운더리 등에 대해 평점 분포를 산출하고, 가능한 각각의 점수별 로 가능성(likelihood)을 구한 다음 NIMA 벡터 점수의 다양한 함수(예: 평균)를 사용하여 미적으로 이미지의 순 위를 매기는 방법을 이용한 알고리즘일 수 있다. 실시 예에서, 심미적인 면을 평가하는 AI 모델은 전술한 NIMA에 한정되지 않으며, 향후 개발될 수 있는 다 양한 형태의 심미적 평가 알고리즘이 AI 모델로 이용될 수 있음은 물론이다. 실시 예에서, 제2 AI 모델은 입력 데이터의 기술적인 부분을 평가하는 AI 모델 및 바운더리의 심미적 인 면을 평가하는 AI 모델을 이용하여, 복수의 이미지나 바운더리들의 기술적인 면과 심미적인 면을 함께 평가 및 학습할 수 있다. 제2 AI 모델은 학습이 완료된 이후 임의의 바운더리가 입력되면 학습 결과를 바 탕으로 사용자들이 선호할만한, 평가 점수가 높은 바운더리들을 출력 데이터로 출력할 수 있다. 도 7에서, 제2 AI 모델은 평가 점수가 높은 세 개의 바운더리들(751, 752, 753)을 출력하고 이 중 사용자가 원하는 바운더리를 선택받을 수 있다. 사용자는 출력되는 바운더리들 중 원하는 바운더리를 선택할 수 있다. 실시 예에서, 제2 AI 모델은 사용자의 선택에 대한 정보를 이용하여 사용자가 선호하는 스타일을 피드백 데이터로 입력받을 수 있다. 제2 AI 모델은 피드백 데이터를 입력 받아 이를 학습할 수 있다. 제2 AI 모델은 다음 평가 시 사용자가 선호하는 스타일에 보다 가까운 바운더리들 세 개를 출력할 수 있다. 도 8은 실시 예에 따라, 제2 AI 모델이 복수 사용자의 선택을 피드백 데이터로 입력받아 이를 이용하는 것을 설 명하기 위한 도면이다. 도 8은 도 6 및 도 7과 유사하다. 다만, 도 8에서는, 복수 개의 출력 데이터에 대해 복수의 사용자로부터 선택을 받고 그 결과를 제2 AI 모델이 학습한다는 점에서 도 7과 구별된다. 이하, 도 6 및 도 7과 중복되 는 내용은 생략하기로 한다. 도 8을 참조하면, 영상 생성 장치는 AI 모델을 이용하여 입력 데이터를 입력 받아 뉴럴 네트워크를 통한 연산을 수행하여 출력 데이터를 출력할 수 있다. 실시 예에서 AI 모델은 제1 AI 모델 및 제2 AI모델을 포함할 수 있다. 실시 예에서, 영상 생성 장치는 제1 AI 모델을 이용하여 입력 데이터를 처리하여 오브젝트에 대한 복 수의 후보 바운더리들을 생성할 수 있다. 실시 예에서, 제2 AI 모델은 복수의 후보 바운더리들을 입력 데이터로 입력받아 평가하는 모델일 수 있다. 실시 예에서, 제2 AI 모델은 이미지나 바운더리의 기술적인 부분을 평가하는 AI 모델 및 이미지나 바운더리의 심미적인 면을 평가하는 AI 모델 중 하나 이상을 포함할 수 있다. 실시 예에서, 제2 AI 모델에 포함된 평가 AI 모델들 두 개는 모두 기술적인 면을 평가하는 AI 모델일 수도 있고, 또는 모두 심미적인 면을 평가하는 AI 모델들일 수도 있다. 예컨대, 제2 AI 모델에 포함된 두 개의 평가 AI 모델들이 모두 심미적인 면을 평가하는 AI 모델들인 경우, 영상 생성 장치는 이러한 AI 모델들을 이용하여 이미지나 바운더리에 대 해 보다 다양한 방식들로, 사람의 눈으로 보기에 아름답게 인식되는 바운더리들을 평가 결과로 출력할 수 있다. 실시 예에서, 제2 AI 모델은 입력 데이터의 기술적인 부분 및/또는 심미적인 부분을 평가하여, 복수의 이 미지나 바운더리들을 평가하고, 학습할 수 있다. 제2 AI 모델은 학습이 완료된 이후 복수의 후보 바운더리 들이 입력되면 학습 결과를 바탕으로 사용자들이 선호할만한, 평가 점수가 높은 바운더리들을 출력 데이터 로 출력하게 된다. 도 8에서, 제2 AI 모델은 평가 점수가 높은 세 개의 바운더리들(851, 852, 853)을 출력하고 사용자로부터 원하는 바운더리를 선택받을 수 있다. 실시 예에서, 사용자는 복수일 수 있다. 예컨대 세 명의 사용자가 동일한 영상 생성 장치를 이용하여 부분 동영상을 생성하는 경우, 사용자 1, 사용자 2 및 사용자 3이 원하는 바운더리는 같을 수도 있고 다를 수도 있다. 도 8에서, 사용자 1은 출력된 데이터 중 첫 번째 바운더리를 선택하고, 사용자 2는 출력된 데 이터 중 두 번째 바운더리를 선택하고, 사용자 3은 출력된 데이터 중 세 번째 바운더리을 선호한다고 가정한다. 실시 예에서, 제2 AI 모델은 각각의 사용자가 선호하는 스타일을 피드백 데이터로 입력받을 수 있다. 도 8에서, 제2 AI 모델은 사용자 1의 선택, 사용자 2의 선택, 사용자 3의 선택에 대한 정보를 각각 피드백 데이터(861, 862, 863)로 입력 받을 수 있다. 제2 AI 모델은 각각의 사용자 별 피드백 데이터(861, 862, 863)를 입력 데이터로 입력 받고, 이를 학습하여 각 사용자 별 선호도를 학습할 수 있다. 제2 AI 모델은 다음 평가 시 각각의 사용자 별로, 사용자가 선호하는 스타일에 보다 가까운 바운더리들 세 개를 출력할 수 있다. 예컨대, 사용자 1이 다음 번에 영상 생성 장치를 이용하여 바운더리를 선택하고자 하는 경우, 제2 AI 모델은 사용자 1의 기존 선택 정보를 이용하여, 사용자 1의 선호도에 맞는 바운더리들 을 출력할 수 있다. 마찬가지로 제2 AI 모델은 사용자 2가 바운더리를 선택하고자 하는 경우, 기존에 사용 자 2가 선택했던 정보를 이용하여, 사용자 2의 선호도에 맞는 바운더리들을 출력할 수 있다. 이에 의하면, 영상 생성 장치는 복수 사용자 별로 사용자의 선호 스타일을 학습하고, 향후 사용자의 선호 스타일에 보다 적절한 바운더리를 출력함으로써, 각 사용자 개개인의 요구 및 취향에 맞춘 결과를 제공할 수 있 다. 도 9는 실시 예에 따른 영상 생성 장치가 뉴럴 네트워크를 이용하여 영상으로부터 정지 영상을 생성하는 것을 설명하기 위한 도면이다. 도 9를 참조하면, 영상 생성 장치는 AI 모델을 이용할 수 있다. AI 모델은 뉴럴 네트워크로 구현될 수 있 다. 뉴럴 네트워크는 복수의 프레임들을 포함하는 영상을 입력받고, 이 중 특정 오브젝트에 대해 해 당 오브젝트를 마스킹하여 자연스러운 부분 동영상을 생성하도록 학습된 모델일 수 있다. 영상 생성 장치는 복수의 프레임들을 포함하는 영상으로부터 오브젝트를 식별할 수 있다. 영상 생성 장치는 식별된 오브젝트들 중 사용자가 선택한 오브젝트인 나비를 검출할 수 있다. 영상 생성 장치는 뉴럴 네트워크를 이용하여 검출된 오브젝트를 마스킹하기 위한 복수의 후보 바운더리들을 생성하고, 생성 된 후보 바운더리들을 평가하여 평가 결과가 우수한 바운더리를 하나 또는 복수 개 출력할 수 있다. 실시 예에서, 뉴럴 네트워크는 복수개의 히든 레이어들을 포함하는 심층 신경망(DNN)일 수 있다. 뉴럴 네 트워크는 입력 데이터를 받고, 입력된 데이터가 히든 레이어들을 통과하여 처리됨으로써, 처리된 데이터가 출력되는 구조를 포함할 수 있다. 뉴럴 네트워크는 컨볼루션 뉴럴 네트워크(CNN: Convolution Neural Network)를 포함할 수 있다. 도 9에서는 뉴럴 네트워크의 숨은 층(hidden layer)이 4개의 심도(depth)를 가지는 심층 신경망(DNN)인 경 우를 예로 들어 도시하였다. 실시 예에서, 영상 생성 장치는 하나의 뉴럴 네트워크를 통한 연산을 수행하여 오브젝트에 대한 바운 더리들을 생성하고 이에 대한 평가를 수행할 수 있다. 실시 예에서, 뉴럴 네트워크는 영상에 포함된 오브 젝트에 대한 바운더리를 생성하는 알고리즘과, 생성된 바운더리를 평가하는 알고리즘이 통합된 형태일 수 있다. 뉴럴 네트워크는 학습 데이터(training data)를 입력 받아 트레이닝(training)될 수 있다. 뉴럴 네트워크 는 학습 데이터를 통한 학습을 수행할 수 있다. 그리고, 학습된 뉴럴 네트워크는 영상 신호 분석을 위한 연산인 추론 연산을 수행할 수 있다. 학습된 뉴럴 네트워크는 바운더리 생성 및 평가를 위한 연산을 수행할 수 있다. 여기서, 뉴럴 네트워크는 모델의 구현 방식(예를 들어, CNN(Convolution Neural Network) 등), 결과의 정확도, 결과의 신뢰도, 프로세서의 연산 처리 속도 및 용량 등에 따라 매우 다양하게 설 계될 수 있다. 뉴럴 네트워크는 입력 계층, 숨은 계층(hidden layer) 및 출력 계층을 포함 하여, 바운더 리 결정을 위한 연산을 수행할 수 있다. 뉴럴 네트워크는 입력 계층과 제1 숨은 계층(HIDDEN LAYER1) 간에 형성되는 제1 계층(Layer 1), 제1 숨은 계층(HIDDEN LAYER1)과 제2 숨은 계층(HIDDEN LAYER2) 간에 형성되는 제2 계층(Layer 2), 제2 숨은 계층(HIDDEN LAYER2)과 제3 숨은 계층(HIDDEN LAYER3) 간에 형성 되는 제3 계층(Layer 3), 제3 숨은 계층(HIDDEN LAYER3)과 제4 숨은 계층(HIDDEN LAYER4) 간에 형성되는 제4 계층(Layer 4), 제4 숨은 계층(HIDDEN LAYER4)과 출력 계층(OUTPUT LAYER) 간에 형성되는 제5 계층(Layer 5)으로 형성될 수 있다. 뉴럴 네트워크를 형성하는 복수개의 계층들 각각은 하나 이상의 노드를 포함할 수 있다. 예를 들어, 입력 계층은 데이터를 수신하는 하나 이상의 노드(node)들을 포함할 수 있다. 도 9에서는 입력 계층 이 복수개의 노드들을 포함하는 경우를 예로 들어 도시하였다. 여기서, 인접한 두 개의 계층들은 도시된 바와 같이 복수개의 엣지(edge)들(예를 들어, 940)로 연결된다. 각각 의 노드들은 대응되는 가중치값을 가지고 있어서, 뉴럴 네트워크는 입력된 신호와 가중치 값을 연산, 예를 들어, 곱하기 연산한 값에 근거하여, 출력 데이터를 획득할 수 있다. 도 9에서는 일 레이어에 포함되는 노드들이 인접한 다른 레이어에 포함되는 노드들과 전체적으로 연결되는 ‘ full -connected’방식으로 연결되어 있는 경우가 도시되었다. 그러나, 실시 예에서, 일 레이어에 포함되는 노 드들이 인접한 다른 레이어에 포함되는 노드들과 일부만 연결되어 있을 수도 있다. 이 경우, 일 레이어에 포함 되는 적어도 하나의 노드는 인접한 다른 레이어에 포함되는 적어도 하나의 노드와 연결되어 있지 않을 수 있다. 뉴럴 네트워크는 복수의 학습 데이터에 학습되어, 객체에 대한 바운더리를 인식 및 평가하는 모델로서 구 축될 수 있다. 구체적으로, 뉴럴 네트워크는 뉴럴 네트워크를 통하여 출력되는 결과의 정확도를 높이 기 위해서, 복수의 학습 데이터에 근거하여 출력 계층에서 입력 계층 방향으로 트레이닝(training)을 반복적으로 수행하며 출력 결과의 정확도가 높아지도록 가중치값들을 수정할 수 있다. 그리고, 최종적으로 수정된 가중치값들을 가지는 뉴럴 네트워크는 최적의 바운더리 결정 모델로 이용될 수 있다. 뉴럴 네트워크는 오브젝트를 포함하는 영상을 입력받는 경우, 영상에 포함된 오브젝트에 대한 바운 더리들을 생성하고 이 중 최적의 바운더리로 평가된 바운더리를 하나 이상 출력할 수 있다. 도 9에서, 뉴럴 네트워크는 영상을 입력 받고, 영상에 포함된 오브젝트에 대한 최적의 바운더리를 이 용하여 해당 오브젝트만 움직이는 부분 동영상을 결과로 출력할 수 있다. 도 10은 실시 예에 따른 부분 동영상을 생성하는 방법을 도시한 순서도이다. 영상 생성 장치는 복수의 프 레임들을 포함하는 영상에서 오브젝트를 식별할 수 있다. 영상 생성 장치는 영상에서 식별된 오브젝트 중 하나를 사용자로부터 선택받을 수 있다. 영상 생성 장치는 사용자로부터 선택된 오브젝트를 검출할 수 있 다(단계 1010). 영상 생성 장치는 검출된 오브젝트에 대해 후보 바운더리들을 생성할 수 있다(단계 1020). 영상 생성 장치 는 제1 AI 모델을 이용하여 오브젝트를 마스킹하기 위한 복수의 후보 바운더리들을 생성할 수 있다. 실시 예예서, 제1 AI 모델은 복수 개의 세그멘테이션 AI 모델들을 포함할 수 있고, 복수 개의 세그멘테이션 AI 모델 들은 각각 오브젝트에 대한 바운더리를 제공할 수 있다. 영상 생성 장치는 복수의 후보 바운더리들을 평가한다(단계 1030). 영상 생성 장치는 제2 AI 모델을 이용하여 복수의 후보 바운더리들을 평가할 수 있다. 실시 예에서, 제2 AI 모델은 입력 데이터에 대해 기술적인 평가를 수행하는 AI 모델 및 심미적인 평가를 수행하는 AI 모델 중 하나 이상을 포함할 수 있다. 영상 생성 장 치는 복수의 후보 바운더리들 중 평가 결과에 따라 평가 점수가 높은 순위부터, 하나 또는 복수 개의 바운 더리를 출력할 수 있다. 영상 생성 장치는 평가 결과에 따라 출력된 복수 개의 바운더리들 중 하나를 선택할 수 있다(단계 1040). 영상 생성 장치는 선택된 바운더리를 이용하여 검출된 오브젝트를 마스킹할 수 있다(단계 1050). 영상 생 성 장치는 복수의 프레임들 중 하나에서 오브젝트를 마스킹하고, 오브젝트가 마스킹된 프레임을 정지 영상 으로 이용할 수 있다. 영상 생성 장치는 정지 영상과 복수의 프레임들을 함께 이용하여 오브젝트가 움직이 는 부분 동영상을 생성할 수 있다(단계 1060). 도 11은 실시 예에 따라, 바운더리를 평가하는 방법을 도시한 순서도이다. 도 11을 참조하면, 영상 생성 장치는 입력된 영상으로부터 검출된 오브젝트에 대해 복수의 후보 바운더리 들을 생성할 수 있다. 실시 예에서, 영상 생성 장치는 다양한 방법을 이용하여 하나의 오브젝트에 대한 복 수 개의 후보 바운더리들을 생성할 수 있다. 실시 예에서, 영상 생성 장치는 AI 모델을 이용하지 않고 후 보 바운더리들을 생성할 수도 있다. 영상 생성 장치는 생성된 복수의 후보 바운더리들을 평가할 수 있다(단계 1010). 영상 생성 장치는 후보 바운더리들에 대해 기술적인 평가 및/또는 심미적인 평가 중 하나 이상을 수행할 수 있다. 실시 예에서, 영상 생성 장치는 평가를 수행하는 AI 모델을 이용하여, 바운더리들을 평가할 수 있다. 영상 생성 장치 는 평가 결과 점수가 높은 순서대로 복수 개의 바운더리들을 선별하고 이를 출력할 수 있다(단계 1120). 영상 생성 장치는 출력된 바운더리들 중 사용자로부터 최적의 바운더리를 선택받을 수 있다(단계 1130). 영상 생성 장치는 사용자의 선택 결과를 입력받아 학습할 수 있다(단계 1140). 즉, 영상 생성 장치가 평가를 하는데 사용하는 AI모델은, 사용자의 선택 정보를 입력 데이터로 입력 받고, 사용자의 선택을 학습할 수 있다. 영상 생성 장치가 사용하는 AI 모델은 이후, 사용자가 다시 후보 바운더리를 평가하고자 할 때, 기 학습된 사용자의 선택 이용하여 사용자가 선호할만한 바운더리를 출력할 수 있다. 실시 예에서, 사용자가 복수인 경우, AI 모델은 복수의 사용자 별로 선택 정보를 입력 받고 이를 각 사용자 별 로 학습하여, 추후 사용자가 후보 바운더리를 평가할 때, 사용자 별로 학습한 사용자의 선호도를 이용하여 각 사용자가 선호할 만한 바운더리를 출력할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network),BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 일부 실시 예에 따른 영상 표시 장치 및 그 동작 방법은 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터 에 의해 실행 가능한 명령어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨 터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체 를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체 및 통신 매체를 모두 포함할 수 있다. 컴퓨 터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매 체는 전형적으로 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈, 또는 반송파와 같은 변조된 데이터 신 호의 기타 데이터, 또는 기타 전송 메커니즘을 포함하며, 임의의 정보 전달 매체를 포함한다. 또한, 본 명세서에서, “부”는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로 세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다. 또한, 전술한 본 개시의 실시 예에 따른 영상 표시 장치 및 그 동작 방법은 다중언어로 구성된 문장을 획득하는 동작; 및 다중언어 번역 모델을 이용하여, 상기 다중언어로 구성된 문장에 포함되는 단어들 각각에 대응하는 벡 터 값들을 획득하고, 상기 획득한 벡터 값들을 목표 언어에 대응하는 벡터 값들로 변환하며, 상기 변환된 벡터 값들에 기초하여, 상기 목표 언어로 구성된 문장을 획득하는 동작을 수행하도록 하는 프로그램이 저장된 기록매 체를 포함하는 컴퓨터 프로그램 제품으로 구현될 수 있다."}
{"patent_id": "10-2019-0083437", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 설명은 예시를 위한 것이며, 발명이 속하는 기술분야의 통상의 지식을 가진 자는 발명의 기술적 사상이 나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시 예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한 다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2019-0083437", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시 예에 따라, 일부분만 움직이는 영상을 생성하는 기술을 설명하기 위한 도면이다. 도 2는, 실시 예에 따라, 영상 생성 장치가 움직임을 표현할 오브젝트를 마스킹하는 것을 도시한 도면이다. 도 3은 실시 예에 따른 영상 생성 장치의 내부 블록도이다. 도 4는 다른 실시 예에 따른 영상 생성 장치의 내부 블록도이다. 도 5는 실시 예에 따라, AI 모델이 입력 데이터를 처리하여 출력 데이터를 생성하는 것을 설명하기 위한 도면이 다. 도 6은 실시 예에 따라, AI 모델을 이용하여 입력 데이터를 처리하여 오브젝트에 대한 최적의 바운더리를 결정 하는 것을 설명하기 위한 도면이다. 도 7은 실시 예에 따라, 제2 AI 모델이 사용자의 선택을 피드백 데이터로 입력받아 학습하는 것을 설명하기 위 한 도면이다. 도 8은 실시 예에 따라, 제2 AI 모델이 복수 사용자의 선택을 피드백 데이터로 입력받아 이를 이용하는 것을 설 명하기 위한 도면이다. 도 9는 실시 예에 따른 영상 생성 장치가 뉴럴 네트워크를 이용하여 영상으로부터 정지 영상을 생성하는 것을 설명하기 위한 도면이다. 도 10은 실시 예에 따른 부분 동영상을 생성하는 방법을 도시한 순서도이다. 도 11은 실시 예에 따라, 바운더리를 평가하는 방법을 도시한 순서도이다."}
