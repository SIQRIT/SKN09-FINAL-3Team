{"patent_id": "10-2022-0127025", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0048063", "출원번호": "10-2022-0127025", "발명의 명칭": "컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치 및 방법", "출원인": "숙명여자대학교산학협력단", "발명자": "동서연"}}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "모니터링 대상자의 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 획득하는 과정;비디오 인코더를 이용해 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오에 기초해 생성된 컬러-근적외선 시공간 특성 정보를 획득하는 과정; 및상기 컬러-근적외선 시공간 특성 정보에 기초해 상기 모니터링 대상자의 생체신호를 획득하는 과정을 포함하는,컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 모니터링 대상자의 컬러 얼굴 비디오 및 근적외선 얼굴 비디오는 동일한 시점에 촬영된 것을 특징으로 하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 컬러-근적외선 시공간 특성 정보를 획득하는 과정은, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오가 시간 축 기준으로 결합한 컬러-근적외선 얼굴 비디오의 저차원 공간에 매핑된 컬러-근적외선 토큰을 생성하는 과정; 및상기 컬러-근적외선 토큰에 기초해 상기 컬러-근적외선 시공간 특성 정보를 획득하는 과정을 포함하는, 컬러 및근적외선 비디오를 이용한 비접촉식 심박 측정 방법."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오가 시간 축 기준으로 결합한 컬러-근적외선 얼굴 비디오의 저차원 공간에 매핑된 컬러-근적외선 토큰을 생성하는 과정은, 튜블렛 임베딩을 이용해 상기 컬러-근적외선 토큰을생성하는 것을 특징으로 하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 비디오 인코더는 비디오 비전 트랜스포머(Video Vision Transformer, ViViT)를 포함하는 것을 특징으로 하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 생체신호는 상기 모니터링 대상자의 원격 광용적맥파(remote Photoplethysmography, rPPG) 신호를 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 컬러-근적외선 시공간 특성 정보에 기초해 상기 모니터링 대상자의 생체신호를 획득하는 과정은, 공개특허 10-2024-0048063-3-rPPG 추정기를 이용해 상기 컬러-근적외선 시공간 특성 정보에 기초해 rPPG 신호를 추정하는 과정; 및상기 추정된 rPPG 신호에 기초해 상기 모니터링 대상자의 생체신호를 획득하는 과정을 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 모니터링 대상자의 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 획득하는 과정 이후에, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 학습시키는 자기 지도 학습 과정을 더 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 학습시키는 자기 지도 학습 과정은, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오에 데이터 어그먼테이션 기법을 적용하는 과정; 및상기 비디오 인코더를 이용해 상기 어그먼테이션된 얼굴 비디오들로부터 획득된 컬러-근적외선 시공간 특성 정보에 기초해 대조 학습을 수행하는 과정을 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 rPPG 추정기는, 동시에 촬영된 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 이용해 계산된 상기 컬러-근적외선 시공간 특성 정보 및 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오와 동시에 측정된 심박 데이터를 학습 데이터로 학습된 인공지능 모델인 것을 특징으로 하는, 컬러 및 근적외선 비디오를 이용한 비접촉식심박 측정 방법."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "메모리 및 프로세서를 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치에 있어서,상기 프로세서는, 모니터링 대상자의 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 획득하는 과정;비디오 인코더를 이용해 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오에 기초해 생성된 컬러-근적외선 시공간 특성 정보를 획득하는 과정; 및상기 컬러-근적외선 시공간 특성 정보에 기초해 상기 모니터링 대상자의 생체신호를 획득하는 과정을 수행하는,컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 모니터링 대상자의 컬러 얼굴 비디오 및 근적외선 얼굴 비디오는 동일한 시점에 촬영된 것을 특징으로 하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 컬러-근적외선 시공간 특성 정보를 획득하는 과정은, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오가 시간 축 기준으로 결합한 컬러-근적외선 얼굴 비디오의 저차원 공간에 매핑된 컬러-근적외선 토큰을 생성하는 과정; 및공개특허 10-2024-0048063-4-상기 컬러-근적외선 토큰에 기초해 상기 컬러-근적외선 시공간 특성 정보를 획득하는 과정을 포함하는, 컬러 및근적외선 비디오를 이용한 비접촉식 심박 측정 장치."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오가 시간 축 기준으로 결합한 컬러-근적외선 얼굴 비디오의 저차원 공간에 매핑된 컬러-근적외선 토큰을 생성하는 과정은, 튜블렛 임베딩을 이용해 상기 컬러-근적외선 토큰을생성하는 것을 특징으로 하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 비디오 인코더는 비디오 비전 트랜스포머(Video Vision Transformer, ViViT)를 포함하는 것을 특징으로 하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 생체신호는 상기 모니터링 대상자의 원격 광용적맥파(remote Photoplethysmography, rPPG) 신호를 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,상기 컬러-근적외선 시공간 특성 정보에 기초해 상기 모니터링 대상자의 생체신호를 획득하는 과정은, rPPG 추정기를 이용해 상기 컬러-근적외선 시공간 특성 정보에 기초해 rPPG 신호를 추정하는 과정; 및상기 추정된 rPPG 신호에 기초해 상기 모니터링 대상자의 생체신호를 획득하는 과정을 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서,상기 프로세서는, 상기 모니터링 대상자의 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 획득하는 과정 이후에, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 학습시키는 자기 지도 학습 과정을 더 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 학습시키는 자기 지도 학습 과정은, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오에 데이터 어그먼테이션 기법을 적용하는 과정; 및상기 비디오 인코더를 이용해 상기 어그먼테이션된 얼굴 비디오들로부터 획득된 컬러-근적외선 시공간 특성 정보에 기초해 대조 학습을 수행하는 과정을 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치."}
{"patent_id": "10-2022-0127025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17항에 있어서,상기 rPPG 추정기는, 동시에 촬영된 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 이용해 계산된 상기 컬공개특허 10-2024-0048063-5-러-근적외선 시공간 특성 정보 및 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오와 동시에 측정된 심박 데이터를 학습 데이터로 학습된 인공지능 모델인 것을 특징으로 하는, 컬러 및 근적외선 비디오를 이용한 비접촉식심박 측정 장치."}
{"patent_id": "10-2022-0127025", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예는, 모니터링 대상자의 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 획득하는 과정; 비디오 인코더를 이용해 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오에 기초해 생성된 컬러-근적외선 시공간 특성 정보를 획득하는 과정; 및 상기 컬러-근적외선 시공간 특성 정보에 기초해 상기 모니터링 대상자의 생체신호를 획득하는 과정을 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법을 제공할 수 있다."}
{"patent_id": "10-2022-0127025", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 장치 및 방법에 관한 것으로, 상세히 는 비접촉 원격 감지 환경에서 모니터링 대상자의 RGB 및 NIR 비디오로부터 획득된 시계열 신호로부터 연속적으 로 rPPG 신호를 추출하는 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0127025", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "비침습적인 방식으로 PPG 센서로 생체신호를 센싱하여 인간의 질병에 대한 사항을 파악하는 연구는 존재한다. 그러나 현재 COVID-19의 대유행으로 인해 비침습적인 방식이면서 원격으로 건강을 모니터링할 수 있는 기술이 상당히 중요해졌다. 각국은 의료 환경에서 COVID-19의 위험을 줄이기 위해 가능하면 원격 건강 전략을 사용할 것을 권고하고 있다. 그렇기 때문에 기존의 신체에 접촉이 필요한 센서를 통한 생체 정보 모니터링 방법이 아닌 새로운 방법이 요구 된다. 원격 건강 모니터링 기술은 휴대전화나 온라인 건강 포털과 같은 통신 시스템에 기반을 두고 있다. 이러한 원격 건강 모니터링 기술은 COVID-19와 같은 유행병이 끝난 후에도 지속적인 환자 모니터링에 매우 인접하게 요구될 수 있다. 카메라를 이용하여 얼굴 비디오를 기반으로 사용자의 생리학적 신호를 측정하는데 사용된다. 이러한 기술은 전 염병뿐 아니라 영유아의 생체정보 모니터링이나 고령자 혹은 정신 건강 모니터링에도 사용될 수 있다. 종래의 rPPG(remote Photoplethysmography) 추정 방법은 RGB 비디오를 수집하여 얼굴 관심 영역(ROI)을 분리하 고 신호처리 접근 방식을 사용하여 얼굴의 미묘한 색상 변화를 분석한다. 또한, 종래의 rPPG 추정 방법은 특정 얼굴 관심 영역에서 공간적 분해 및 시간적 필터링을 통해 피처를 추출한 후 CNN의 입력으로 사용해 심박을 추정했다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 제10-2096617호 (2020.03.27.)"}
{"patent_id": "10-2022-0127025", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예는, 원격 광용적맥파(remote Photoplethysmography, rPPG)에 기반해 원격 심박을 추정하는 컬러(RGB) 및 근적외선(NIR) 비디오 이미지를 이용한 비접촉식 심박 측정 장치 및 방법을 제공할 수 있다. 본 발명의 일 실시예는, RGB-NIR 융합된 특성 정보를 이용해 원격 심박을 추정하는 컬러 및 근적외선 비디오 이 미지를 이용한 비접촉식 심박 측정 장치 및 방법을 제공할 수 있다. 본 발명의 일 실시예는, 자기 지도 학습을 기반으로 RGB-NIR 융합된 특성 정보를 생성하는, 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 장치 및 방법을 제공할 수 있다. 본 발명의 일 실시예는, 저조도 환경 또는 머리 움직임이 많은 환경에서도 rPPG기반해 심박을 추정할 수 있는 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 장치 및 방법을 제공할 수 있다. 본 발명의 일 실시예는, 대규모 데이터 세트가 없더라도 혹은 NIR 비디오로 사전 학습된 ViViT 네트워크가 없더 라도 RGB 및 NIR 융합 모델을 제공하는, 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 장치 및 방법을 제공할 수 있다. 본 발명의 일 실시예는, 트랜스포머 셀프 어텐션 메커니즘을 활용한 Fusion ViViT 네트워크을 이용하여 서로 다 른 양식(RGB, NIR)의 클로벌 컨텍스트를 효과적으로 통합할 수 있는, 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 장치 및 방법을 제공할 수 있다."}
{"patent_id": "10-2022-0127025", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예는, 모니터링 대상자의 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 획득하는 과정; 비디 오 인코더를 이용해 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오에 기초해 생성된 컬러-근적외선 시공간 특 성 정보를 획득하는 과정; 및 상기 컬러-근적외선 시공간 특성 정보에 기초해 상기 모니터링 대상자의 생체신호 를 획득하는 과정을 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 상기 모니터링 대상자의 컬러 얼굴 비디오 및 근적외선 얼굴 비디오는 동일한 시점에 촬영된 것을 특징으로 하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 상기 컬러-근적외선 시공간 특성 정보를 획득하는 과정은, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오가 시간 축 기준으로 결합한 컬러-근적외선 얼굴 비디오의 저차원 공간에 매핑된 컬러-근 적외선 토큰을 생성하는 과정; 및 상기 컬러-근적외선 토큰에 기초해 상기 컬러-근적외선 시공간 특성 정보를 획득하는 과정을 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오가 시간 축 기준으로 결합한 컬러-근적 외선 얼굴 비디오의 저차원 공간에 매핑된 컬러-근적외선 토큰을 생성하는 과정은, 튜블렛 임베딩을 이용해 상 기 컬러-근적외선 토큰을 생성하는 것을 특징으로 하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 상기 비디오 인코더는 비디오 비전 트랜스포머(Video Vision Transformer, ViViT)를 포 함하는 것을 특징으로 하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 상기 생체신호는 상기 모니터링 대상자의 원격 광용적맥파(remote Photoplethysmography, rPPG) 신호를 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 상기 컬러-근적외선 시공간 특성 정보에 기초해 상기 모니터링 대상자의 생체신호를 획 득하는 과정은, rPPG 추정기를 이용해 상기 컬러-근적외선 시공간 특성 정보에 기초해 rPPG 신호를 추정하는 과 정; 및 상기 추정된 rPPG 신호에 기초해 상기 모니터링 대상자의 생체신호를 획득하는 과정을 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 상기 모니터링 대상자의 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 획득하는 과정 이후에, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 학습시키는 자기 지도 학습 과정을 더 포함하는, 컬 러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 학습시키는 자기 지도 학습 과정은, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오에 데이터 어그먼테이션 기법을 적용하는 과정; 및 상기 비디오 인코더를 이용해 상기 어그먼테이션된 얼굴 비디오들로부터 획득된 컬러-근적외선 시공간 특성 정보에 기초해 대조 학습을 수행하는 과정을 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 상기 rPPG 추정기는, 동시에 촬영된 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 이용해 계산된 상기 컬러-근적외선 시공간 특성 정보 및 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오와 동시에 측정된 심박 데이터를 학습 데이터로 학습된 인공지능 모델인 것을 특징으로 하는, 컬러 및 근적외선 비디 오를 이용한 비접촉식 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 메모리 및 프로세서를 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측 정 장치에 있어서, 상기 프로세서는, 모니터링 대상자의 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 획득하는 과정; 비디오 인코더를 이용해 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오에 기초해 생성된 컬러-근적외선 시공간 특성 정보를 획득하는 과정; 및 상기 컬러-근적외선 시공간 특성 정보에 기초해 상기 모니터링 대상자의 생체신호를 획득하는 과정을 수행하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 상기 모니터링 대상자의 컬러 얼굴 비디오 및 근적외선 얼굴 비디오는 동일한 시점에 촬영된 것을 특징으로 하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 상기 컬러-근적외선 시공간 특성 정보를 획득하는 과정은, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오가 시간 축 기준으로 결합한 컬러-근적외선 얼굴 비디오의 저차원 공간에 매핑된 컬러-근 적외선 토큰을 생성하는 과정; 및 상기 컬러-근적외선 토큰에 기초해 상기 컬러-근적외선 시공간 특성 정보를 획득하는 과정을 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오가 시간 축 기준으로 결합한 컬러-근적 외선 얼굴 비디오의 저차원 공간에 매핑된 컬러-근적외선 토큰을 생성하는 과정은, 튜블렛 임베딩을 이용해 상 기 컬러-근적외선 토큰을 생성하는 것을 특징으로 하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 상기 비디오 인코더는 비디오 비전 트랜스포머(Video Vision Transformer, ViViT)를 포 함하는 것을 특징으로 하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 상기 생체신호는 상기 모니터링 대상자의 원격 광용적맥파(remote Photoplethysmography, rPPG) 신호를 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 상기 컬러-근적외선 시공간 특성 정보에 기초해 상기 모니터링 대상자의 생체신호를 획 득하는 과정은, rPPG 추정기를 이용해 상기 컬러-근적외선 시공간 특성 정보에 기초해 rPPG 신호를 추정하는 과 정; 및 상기 추정된 rPPG 신호에 기초해 상기 모니터링 대상자의 생체신호를 획득하는 과정을 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 상기 프로세서는, 상기 모니터링 대상자의 컬러 얼굴 비디오 및 근적외선 얼굴 비디오 를 획득하는 과정 이후에, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 학습시키는 자기 지도 학습 과정 을 더 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 학습시키는 자기 지도 학습 과정은, 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오에 데이터 어그먼테이션 기법을 적용하는 과정; 및 상기 비디오 인코더를 이용해 상기 어그먼테이션된 얼굴 비디오들로부터 획득된 컬러-근적외선 시공간 특성 정보에 기초해 대조 학습을 수행하는 과정을 포함하는, 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 상기 rPPG 추정기는, 동시에 촬영된 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오를 이용해 계산된 상기 컬러-근적외선 시공간 특성 정보 및 상기 컬러 얼굴 비디오 및 근적외선 얼굴 비디오와 동 시에 측정된 심박 데이터를 학습 데이터로 학습된 인공지능 모델인 것을 특징으로 하는, 컬러 및 근적외선 비디 오를 이용한 비접촉식 심박 측정 장치를 제공할 수 있다."}
{"patent_id": "10-2022-0127025", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예는, RGB-NIR 융합 모델로서 융합 비디오 비전 트랜스포머(Fusion Video Vision Transformer, Fusion ViViT)를 제안한다. 본 발명의 일 실시예는, 트랜스포머 모델 기반으로, 컬러(RGB) 및 근적외선(NIR) 비디오로부터 rPPG 추정을 위 한 시공간 특징을 결합하고, 이를 비디오 시퀀스인 시계열 신호로 추출하는 융합 비디오 비전 트랜스포머를 제안한다. 본 발명의 일 실시예는, RGB-NIR 융합 방법을 사용하여 rPPG를 추정하는 종단 간 딥러닝 기반 모델을 제안한다. 본 발명의 일 실시예는, 자기 지도 학습 방법으로 대조 학습을 이용하여 융합 비디오 비전 트랜스포머 네트워크 의 학습을 제안한다. 본 발명의 일 실시예는, 충분히 많은 양의 데이터가 존재하지 않을 때의 과적합(overfitting) 문제를 방지하고 더 나은 표현 학습을 가능하게 할 수 있는 융합 비디오 비전 트랜스포머 네트워크를 제안한다."}
{"patent_id": "10-2022-0127025", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 개시되어 있는 본 발명의 개념에 따른 실시 예들에 대해서 특정한 구조적 또는 기능적 설명은 단지 본 발명의 개념에 따른 실시 예들을 설명하기 위한 목적으로 예시된 것으로서, 본 발명의 개념에 따른 실시 예 들은 다양한 형태들로 실시될 수 있으며 본 명세서에 설명된 실시 예들에 한정되지 않는다. 본 발명의 개념에 따른 실시 예들은 다양한 변경들을 가할 수 있고 여러 가지 형태들을 가질 수 있으므로 실시 예들을 도면에 예시하고 본 명세서에서 상세하게 설명하고자 한다. 그러나, 이는 본 발명의 개념에 따른 실시 예들을 특정한 개시 형태들에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변 경, 균등물, 또는 대체물을 포함한다. 제1 또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용어 들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로 만, 예컨대 본 발명의 개념에 따른 권리 범위로부터 벗어나지 않은 채, 제1구성 요소는 제2구성 요소로 명명될 수 있고 유사하게 제2구성 요소는 제1구성 요소로도 명명될 수 있다. 어떤 구성 요소가 다른 구성 요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성 요소 에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성 요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성 요소가 다른 구성 요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는 중간에 다른 구성 요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성 요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등 도 마찬가지로 해석되어야 한다. 본 명세서에서 사용한 기술적 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로서, 본 발명을 한정하 려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세 서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 본 명세서에 기재된 특징, 숫자, 단계, 동작, 구성 요소, 부분 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계,동작, 구성 요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해 되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 명세서에 서 특별히 다른 의미로 정의되지 않는 한, 본 명세서에 개시된 기술이 속하는 분야에서 통상의 지식을 가진 자 에 의해 일반적으로 이해되는 것과 동일한 의미를 나타낸다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에 서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않아야 한다. 본 명세서에서 사용되는 구성요소에 대한 접미사 \"모듈(module)\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니며, 본 발명의 실시 예에 따른 방법을 수행하기 위한 하드웨어 또는 상기 하드웨어를 구동할 수 있는 소프트웨어의 기능적 또는 구 조적 결합을 의미할 수 있다. 이하에서 첨부된 도면을 참조하여 본 발명의 일 실시예에 따른 컬러 및 근적외선 비디오 이미지를 이용한 비접 촉식 심박 측정 장치 및 방법을 설명한다. 도 1은 본 발명의 일 실시예에 따른 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 장치의 하드 웨어 구성도이다. 도 1을 참조하여 본 발명의 일 실시예에 따른 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 장 치(이하 '비접촉식 심박 측정 장치'라 함)를 설명한다. 본 발명의 일 실시예에 따른 비접촉식 심박 측정 장치는 모니터링 대상자에 물리적으로 접촉하는 센서가 없이도 사용자의 비디오 이미지를 이용해 모니터링 대상자의 심박을 측정할 수 있다. 심박은 단위시간 당 심장 박동 횟수로 교감 신경계와 부교감 신경계로 구성된 자율 신경계의 영향을 받아 사람 의 신체적, 정신적 상태를 반영한다. 일반적으로 심장의 전기적 활동을 기록하는 심전도(ECG; electrocardiogram) 또는 광학센서를 이용하는 광혈류 측정기(PPG; photoplethysmogram)를 사용하여 이러한 생체 신호를 모니터링할 수 있다. 그러나 이러한 방법들은 일반적으로 센서를 피부 표면에 부착하여 신호를 얻으므로 대상과의 물리적 접촉이 필수적이거나 움직임이 제약 된다는 한계점을 가지고 있다. 이러한 문제를 해결하기 위해, 본 발명의 일 실시예에 따른 비접촉식 심박 측정 장치는 비접촉 상황에서 얼굴 비디오를 이용해 PPG 신호를 추정(측정)하는 원격 광용적맥파(rPPG) 추정 방법을 제안할 수 있다. rPPG 추정 방법은 컴퓨터 비전 기반 기술로 심장 박동으로 발생하는 얼굴 피부의 미묘한 색상 변화를 기록한다. 카메라는 피부의 색상 변화를 포착하는 광검출기 역할을 하고, 주변광은 일반적인 광원 역할을 한다. 모니터링 비용을 크게 줄이고 다양한 비접촉 관련 응용 분야에서의 활용도를 높일 수 있다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 장치(이하, \"컴퓨팅 장치\"라 고도 함)는 하나 이상의 프로세서, 프로세서에 의하여 수행되 는 컴퓨터 프로그램을 로드(Load)하는 메모리, 통신 인터페이스 및 컴퓨터 프로그램을 저 장하는 스토리지를 포함할 수 있다. 다양한 실시예에서, 본 명세서에서, 컴퓨팅 장치는 적어도 하나의 프로세서를 포함하는 모든 종류의 하드웨어 장치를 의미하는 것이고, 실시 예에 따라 해당 하드웨어 장치에서 동작하는 소프트웨어적 구성도 포괄 하는 의미로서 이해될 수 있다. 예를 들어, 컴퓨팅 장치는 스마트폰, 태블릿 PC, 데스크톱, 노트북 및 각 장치에서 구동되는 사용자 클라이언트 및 애플리케이션을 모두 포함하는 의미로서 이해될 수 있으며, 또한 이에 제한되는 것은 아니다. 본 명세서에서 설명되는 각 과정들은 컴퓨팅 장치에 의하여 수행되는 것으로 설명 되나, 각 과정의 주체는 이에 제한되는 것은 아니며, 실시 예에 따라 각 과정들의 적어도 일부가 서로 다른 장 치에서 수행될 수도 있다. 프로세서는 컴퓨팅 장치의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 발명의 기술 분야에 잘 알려진 임의의 형태의 프로세서를 포함하여 구성될 수 있다. 또한, 프로세서는 본 발명의 실시예들에 따른 방법을 실행하기 위한 적어도 하나의 애플리케이션 또는 프 로그램에 대한 연산을 수행할 수 있으며, 컴퓨팅 장치는 하나 이상의 프로세서를 구비할 수 있다. 또한, 프로세서는 프로세서 내부에서 처리되는 신호(또는, 데이터)를 일시적 및/또는 영구적으로 저 장하는 램(RAM: Random Access Memory, 미도시) 및 롬(ROM: Read-Only Memory, 미도시)을 더 포함할 수 있다. 또한, 프로세서는 그래픽 처리부, 램 및 롬 중 적어도 하나를 포함하는 시스템온칩(SoC: system on chip) 형태로 구현될 수 있다. 프로세서는 본 발명의 다양한 실시예에 따른 방법/과정들을 수행할 수 있다. 일 예로, 프로세서는 본 발명의 실시예에 따른 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법 및 이 방법을 이루는 적어도 하나의 과정들의 조합을 수행할 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리는 본 발명의 다양한 실시예에 따른 방 법/동작을 실행하기 위하여 스토리지로부터 컴퓨터 프로그램을 로드할 수 있다. 메모리에 컴퓨 터 프로그램이 로드되면, 프로세서는 컴퓨터 프로그램을 구성하는 하나 이상의 인스트럭션들을 실행함으로써 상기 방법/동작을 수행할 수 있다. 메모리는 RAM과 같은 휘발성 메모리로 구현될 수 있을 것 이나, 본 개시의 기술적 범위가 이에 한정되는 것은 아니다. 버스(BUS)는 컴퓨팅 장치의 구성 요소 간 통신 기능을 제공한다. 버스(BUS)는 주소 버스(address Bus), 데 이터 버스(Data Bus) 및 제어 버스(Control Bus) 등 다양한 형태의 버스로 구현될 수 있다. 통신 인터페이스는 컴퓨팅 장치의 유무선 인터넷 통신을 지원한다. 또한, 통신 인터페이스는 인 터넷 통신 외의 다양한 통신 방식을 지원할 수도 있다. 예를 들어, 통신 인터페이스는, 근거리 통신, 이동 통신, 방송 통신 방식 중 적어도 하나를 지원할 수 있다. 이를 위해, 통신 인터페이스는 본 발명의 기술 분야에 잘 알려진 통신 모듈을 포함하여 구성될 수 있다. 몇몇 실시예에서, 통신 인터페이스는 생략될 수 도 있다. 스토리지는 컴퓨터 프로그램을 비 임시적으로 저장할 수 있다. 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모 리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 컴퓨터 프로그램은 메모리에 로드될 때 프로세서로 하여금 본 발명의 다양한 실시예에 따른 방 법/동작을 수행하도록 하는 하나 이상의 인스트럭션들을 포함할 수 있다. 즉, 프로세서는 상기 하나 이상 의 인스트럭션들을 실행함으로써, 본 발명의 다양한 실시예에 따른 상기 방법/동작을 수행할 수 있다. 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 과정들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다. 일 실시예에서, 컴퓨터 프로그램은 컴퓨팅 장치와 결합되어, 컬러 및 근적외선 비디오 이미지를 이용 한 비접촉식 심박 측정 방법을 실행시키기 위하여 컴퓨터로 판독가능한 기록매체에 저장된, 인공지능 기반 모빌 리티 사용자의 이동패턴 판단 컴퓨터 프로그램일 수 있다. 본 발명의 구성 요소들은 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 애플리케이션)으로 구현 되어 매체에 저장될 수 있다. 본 발명의 구성 요소들은 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행 될 수 있으며, 이와 유사하게, 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조 합으로 구현되는 다양한 알고리즘을 포함하여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 나아가, 컴퓨팅 장치는 출력부, A/V입력부, 사용자 입력부, 배터리 중 적어도 하나를 더 포함할 수 있다. 출력부는 실행되는 프로그램(또는 애플리케이션)에 의해 생성 혹은 실행되는 비디오 신호 및 오디오 신호 중 적어도 하나를 출력할 수 있다. 출력부는 비디오 신호를 출력하는 디스플레이부 및 오디오 신호를출력하는 음향 출력부 중 적어도 하나를 포함할 수 있다. A/V(Audio/Video) 입력부는 외부로부터 컴퓨팅 장치로 컬러(RGB) 비디오 신호의 입력을 위한 RGB 카 메라와, 근적외선 비디오 신호의 입력을 위한 NIR 카메라를 포함할 수 있다. RGB카메라는 촬영모드에서 이미지 센서를 통해 정지영상 또는 동영상 등의 RGB 이미지로 이루어진 화상 프 레임을 얻을 수 있다. NIR카메라는 촬영모드에서 이미지 센서를 통해 정지영상 또는 동영상 등의 NIR 이미지로 이루어진 화상 프 레임을 얻을 수 있다. 사용자 입력부는, 사용자가 컴퓨팅 장치를 제어하기 위한 사용자 입력 신호 혹은 데이터를 입력하는 수단을 의미한다. 사용자 입력부는 터치 패드(일 예로, 접촉식 정전 용량 방식, 압력식 저항막 방식, 적외 선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등)와, 키 패드(key pad), 전 원 버튼, 볼륨 버튼 등과 같은 물리 버튼을 포함할 수 있으나, 이에 한정되는 것은 아니다. 본 발명의 일 실시예에 따른 비접촉식 심박 측정 장치는 후술할 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 방법 및 이 방법을 구성하는 적어도 하나의 과정의 조합을 수행할 수 있다. 도 2는 본 발명의 일 실시예에 따른 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 방법의 흐름 도를 도시한 것이다. 도 3은 본 발명의 일 실시예에 따른 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 방법의 개념도를 도시한 것이다. 도 4는 본 발명의 일 실시예에 따른 비디오 인코더의 구조를 도시한 것이다. 도 5는 비디오 분류를 위한 ViViT 네트워크의 다양한 모델들의 구조를 보여준다. 도6은 본 발명의 튜블 렛 임베딩의 개념도를 도시한 것이다. 본 발명의 일 실시에 따른 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 방법은, 얼굴 비디오 를 획득하는 과정(S100), 컬러-근적외선 시공간 특성 정보를 획득하는 과정(S300), 모니터링 대상자의 생체신호 를 획득하는 과정(S400)을 포함할 수 있다. S100 과정에서, 비접촉식 심박 측정 장치는 모니터링 대상자의 얼굴 비디오를 획득할 수 있다. 모니터링 대상자의 얼굴 비디오( )는 컬러 얼굴 비디오( ) 및 근적외선 얼굴 비디오( )를 포함할 수 있 다. 비접촉식 심박 측정 장치는 RGB 카메라 및 NIR 카메라를 각각 이용해 모니터링 대상자의 컬러 얼굴 비디오( ) 및 근적외선 얼굴 비디오( )를 촬영할 수 있다. 또는, 비접촉식 심박 측정 장치는 다른 전자 장치들 혹은 하나의 전자 장치의 RGB 카메라 및 NIR 카메라에 서 촬영된 모니터링 대상자의 컬러 얼굴 비디오( ) 및 근적외선 얼굴 비디오( )를 수신하여 획득할 수 있다. 컬러 얼굴 비디오( ) 및 근적외선 얼굴 비디오( )는 동일한 모니터링 대상자를 촬영한 것으로 동일한 시 점에 촬영된 것일 수 있다. 즉, RGB 카메라 및 NIR 카메라가 동시에 모니터링 대상자의 얼굴을 촬영 하여 얻은 컬러 얼굴 비디오( ) 및 근적외선 얼굴 비디오( )일 수 있다. 컬러 얼굴 비디오( ) 및 근적외선 얼굴 비디오( )는 서로 다른 양식을 가질 수 있다. 예를 들어, 비디오 이미지의 입력 파장, 비디오 이미지 프레임, 비디오 이미지 크기, 비디오 이미지 용량, 비디오 이미지 해상도 중 적어도 하나가 서로 다른 비디오일 수 있다. 컬러 얼굴 비디오( ) 및 근적외선 얼굴 비디오( )는 모니터링 대상자의 머리 움직임, 낮과 밤, 주변 환 경의 변화에 따라 다양한 시나리오에서 녹화된 비디오 일 수 있다. 도 4를 참조하면, S300 과정에서, 비접촉식 심박 측정 장치는 비디오 인코더를 이용해 상기 컬러 얼 굴 비디오( ) 및 근적외선 얼굴 비디오( )에 기초해 생성된 컬러-근적외선 시공간 특성 정보(FFI, )를 획득할 수 있다. 본 발명의 비접촉식 심박 측정 장치는 컬러 얼굴 비디오( ) 뿐만 아니라 근적외선 얼굴 비디오( ) 를 함께 상호 보완적인 특성으로 융합하여 저조도 환경이나 대상자의 상대적 움직임이 많은 환경에서도 안정적 이고 강건한 심박을 측정할 수 있다. 비접촉식 심박 측정 장치는 모니터링 대상자의 컬러 얼굴 비디오( ) 및 근적외선 얼굴 비디오( )로 부터 시계열 정보를 포함하는 컬러 얼굴 비디오 클립들( ) 및 근적외선 얼굴 비디오 클립들( )을 각각 획득할 수 있다. 컬러 얼굴 비디오 클립들( )은 컬러 얼굴 비디오로부터 프레임 단위로 획득한 복수의 컬러 비디오 이미지들 일 수 있다. 근적외선 얼굴 비디오 클립들( )는 근적외선 얼굴 비디오로부터 프레임 단위로 획득한 복수의 근적외선 비디오 이미지들일 수 있다. 비디오 인코더는 컬러(RGB)와 근적외선(NIR) 얼굴 비디오 클립들을 입력으로 사용하여 컬러-근적외선 시공 간 특성 정보(FFI, )를 생성할 수 있다. 컬러-근적외선 시공간 특성 정보(FFI, )는 RGB-NIR 융합 rPPG 표현 벡터(RGB-NIR Fused rPPG Representation"}
{"patent_id": "10-2022-0127025", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "Vector)를 포함할 수 있다. 컬러-근적외선 시공간 특성 정보(FFI)는 시간과 공간 컨텍스트 모두를 요약한 특징 을 포함할 수 있다. 비디오 인코더는 적어도 하나의 융합 비디오 비전 트랜스포머(Fusion Video Vision Transformer, Fusion ViViT) 네트워크를 포함할 수 있다. Fusion ViViT 네트워크는 트랜스포머 셀프 어텐션 메커니즘을 활용하여 서로 다른 양식의 클로벌 컨텍스트를 효 과적으로 통합할 수 있다. Fusion ViViT 네트워크는 하나 또는 복수의 ViViT 네트워크들을 포함할 수 있다. ViViT(Video Vision Transformer) 네트워크는 ViT에서 영감을 받아서 만들어진, 비디오의 분류를 위한 트랜스포 머로서, 비디오를 입력으로 사용하고 시간과 공간의 컨텍스트를 동시에 캡처할 수 있는 시공간 네트워크이다. ViViT 네트워크는 입력된 비디오를 시간과 공간 차원에 따라 요인화(factorise)하여 시공간 토큰을 추출할 수 있다. rPPG 신호는 얼굴 비디오에서 시계열적 비디오 시퀀스들 중 장거리 컨텍스트 단서를 활용해야 모니터링 대상자 의 정확한 현재 심박을 측정할 수 있다. ViViT 네트워크는 신호 시퀀스의 장거리 컨텍스트 단서를 활용하여 현 재 출력 값을 얻으므로, 얼굴 비디오로부터 정확한 rPPG 신호를 측정하기 적합하다. ViViT 네트워크는 장거리 시공간 컨텍스트 관계를 모델링함으로써, 3차원 영상에서 1차원의 시계열 신호로 처리 하는 비디오 시퀀스 문제의 시공간 네트워크로 사용될 수 있다. ViViT 네트워크는 서로 다른 양식을 가지는 RGB얼굴 비디오와 NIR얼굴 비디오의 시공간 rPPG 특성을 잘 융합할 수 있다. 또한, ViViT 네트워크는 융합된 특성을 비디오 시퀀스로 잘 추출할 수 있다. ViViT 네트워크는 입력 비디오로부터 다양한 방법으로 시간과 공간을 요인화하는 복수의 모델들을 포함할 수 있 다. 예를 들어, 복수의 모델들은 모델1(Spatio-temporal attention), 모델2(Factorised encoder), 모델 3(Factorised self-attention), 모델4(Factorised dot-product attention)를 포함할 수 있다. 이들에 대한 설 명은 공지된 부분이므로 생략한다. 도5를 참조하면, 본 발명의 일 실시예에 따른 Fusion ViViT 네트워크는 ViViT 네트워크의 모델3(Factorised self-attention)으로 구성될 수 있다. 모델 3은 셀프 어텐션 연산을 각각 공간과 시간적으로 분리하여 요인화 할 수 있다. 얼굴 비디오의 토큰 임베딩에 위치 임베딩이 추가되어 입력 토큰을 생성하고, 입력 토큰에 대한 셀프 어텐션 연 산은 공간적으로 계산되고, 이후 시간적으로 계산된다. 즉, 트랜스포머의 각 셀프 어텐션 블록(Self-Attention Block)은 시공간 상호작용을 모델링하지만, 더 작은 요소 집합인 공간적 셀프 어텐션 블록(Spatial Self- Attention Block)과 시간적 셀프 어텐션 블록(Temporal Self-Attention Block) 순서로 요인화된다. S300 과정에서, 비접촉식 심박 측정 장치는, 비디오 인코더를 이용해 컬러 얼굴 비디오 클립( ) 및 근적외선 얼굴 비디오 클립( )을 동일한 저차원 공간에 매핑된 컬러-근적외선 시공간 토큰을 생성할 수 있다. 도 4를 다시 참조하면, 비접촉식 심박 측정 장치는 컬러 얼굴 비디오( ) 및 근적외선 얼 굴 비디오( )를 시간 축 기준으로 결합한 컬러-근적외선 얼굴 비디오( )를 생 성할 수 있다. 컬러-근적외선 얼굴 비디오( )는 컬러 얼굴 비디오 클립( ) 및 근적외선 얼굴 비디오 클립( )을 시간 축 기준으로 합쳐서 결합된 것일 수 있다. 컬러-근적외선 얼굴 비디오( )는 컬러 얼굴 비디오( ) 및 근적외선 얼굴 비디오( )를 시간 축 기준으로 합쳐서 결합된 비디오 텐서를 나타낸다. 이 경우 T는 비디오 이미지 프레임의 개수(시간), H는 이미지 프레임의 세로 크기, W는 이미지 프레임의 가로 크기, C는 비디오 양식의 채널 개수를 나타낸다. 비접촉식 심박 측정 장치는 컬러-근적외선 얼굴 비디오( )로 부터 입력 토큰을 생성하고, 생성된 입력 토 큰을 트랜스포머에 입력할 수 있다. 이 경우, 비접촉식 심박 측정 장치는 튜블렛 (tubulet) 임베딩을 이용 해 컬러-근적외선 얼굴 비디오( )에서 입력 토큰을 추출할 수 있다. 도 6을 참조하면, 튜블렛 임베딩은 트랜스포머의 입력에 해당하는 컬러-근적외선 비디오( )를 토큰의 시퀀스로 매핑할 수 있다. 튜블렛 임베딩은 컬러-근적외선 얼굴 비디오( )로부터 겹쳐지지 않는 시공간 튜브(spatiotmeporal tube)를 추 출하고, 추출된 시공간 튜브를 선형적으로 투영하는 방식이다. 튜블렛 임베딩은 ViT의 2D 기반의 유니폼 (uniform) 임베딩을 3D로 확장한 것이다. 비접촉식 심박 측정 장치는 컬러-근적외선 얼굴 비디오( )를 N개의 중첩되지 않는 시공간 튜브( )를 사용해 비디오 토큰을 추출할 수 있다. 추출된 비디오 토큰은 각각 시간 , 높이 , 너비 차원을 가진다. 비접촉식 심박 측정 장치는 튜블렛 입베딩을 사용하여 컬러-근적외선 얼굴 비디오( )를 비디오 토큰 시퀀 스( )로 매핑할 수 있다. 비접촉식 심박 측정 장치는 비디오 토큰 시퀀스( )에 위치 임베딩(P)를 추가하여 1차원의 입력 토큰( )을 생성할 수 있다."}
{"patent_id": "10-2022-0127025", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "비접촉식 심박 측정 장치는 ViViT 네트워크를 이용해 컬러-근적외선 얼굴 비디오( )의 모든 시공간 토큰들 ( ) 사이의 상호작용을 모델링할 수 있다. 즉, 1차원의 입력 토큰( )은 컬러-근적외선 얼굴 비디오에 대한 시공 간 정보를 모두 가지는 저차원 공간에 매핑된 값이다. 도 4 및 도 5를 다시 참조하면, 비접촉식 심박 측정 장치는 ViViT 네트워크의 셀프 어텐션 연산을 이용해 입력 토큰( )을 토큰1-1 ( )으로 재구성할 수 있다. 비접촉식 심박 측 정 장치는 토큰1-1 ( )에서 동일한 시간 인덱스로부터 추출한 토큰들1-1 중 공간 도메 인에 해당되는 토큰들1-1을 먼저 계산하여 토큰2 ( )을 생성할 수 있다. 비접촉식 심박 측정 장치는 토큰2 ( )를 토큰2-1 ( )으로 재구성할 수 있다. 비접촉식 심박 측정 장치는 토큰2-1 ( )에서 동일한 공간 인덱스로부터 추출 된 모든 토큰들 중 시간적 도메인에 해당되는 토큰들2-1을 먼저 계산하여 토큰3( 을 생성할 수 있다."}
{"patent_id": "10-2022-0127025", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "ViViT 네트워크은 복수의 트랜스포머 블록을 포함할 수 있다. 각 트랜스포머 블록은 멀티 헤드 어텐션 (Multi- headed Self-Attention) 블록, 레이어 정규화 (Layer Normalization) 블록, 및 다중 레이어 퍼셉트론(Multi Layer Perceptron) 블록 중 적어도 하나로 구성될 수 있다. ViViT 네트워크의 셀프 어텐션에서 출력된 토큰( )은 시간 축을 따라 순차적으로 서로 다른 양식을 나타내는 2개의 피처맵들, 컬러 피처맵( )와 근적외선 피처맵 ( )으로 분리된다. 서로 다른 양식이 결합된 입력 토큰( )이 셀프 어텐션 연산을 거쳐서 컬러 피처맵과 근적외선 피처맵으로 나뉘 는 이 융합 과정은 2번의 트랜스포머를 거쳐서 수행된다. 2개의 트랜스포머를 거친 후 평균 풀링(average pooling)과 플래튼(flatten) 작업을 적용하여 양식 특성 벡터인 컬러 특성 벡터( )와 근적외선 특성 벡터 ( )을 얻는다."}
{"patent_id": "10-2022-0127025", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "컬러 특성 벡터( )와 근적외선 특성 벡터( )의 요소별 합산(elementwise summation)을 이용하여 추가로 결합하여 컬러-근적외선 시공간 특성 정보(FFI, )를 형성한다. 컬러-근적외선 시공간 특성 정보(FFI, )는 컬러-근적외선 시공간 특성 벡터 혹은 RGB-NIR 융합 rPPG 표현 벡터 를 포함할 수 있다. 컬러-근적외선 시공간 특성 정보는 컬러 비디오와 근적외선 비디오가 모두 융합된 시공간 정보를 나타내는 융합 표현이다. 도 3을 참조하면, S400 과정에서, 비접촉식 심박 측정 장치는 컬러-근적외선 시공간 특성 정보에 기초해 상기 모니터링 대상자의 생체신호를 획득하는 과정을 수행할 수 있다. 비접촉식 심박 측정 장치는 컬러-근적외선 시공간 특성 정보(FFI, )를 이용하여 rPPG 신호를 추출할 수 있다. 상세히는, 비접촉식 심박 측정 장치는, 추출된 RGB-NIR 융합 rPPG 표현 벡터를 rPPG 추정기(rPPG Estimator)에 입력시켜서 rPPG 신호를 추출하거나, 심박수를 추출할 수 있다. rPPG 추정기는 시간과 공간 컨텍스트의 특징을 입력으로 1차원의 rPPG 신호를 출력할 수 있다. rPPG 추정기는 추출된 RGB-NIR 융합 rPPG 표현 벡터(FFI)에 기초해 rPPG 신호를 출력하도록 학습된 인공지 능 모델일 수 있다. rPPG 추정기는 다중 퍼셉트론(MLP)로 구성될 수 있다. 또한, 비접촉식 심박 측정 장치는 rPPG 신호를 이용해 심박수를 계산할 수 있다. 도 7은 본 발명의 일 실시예에 따른 자기 지도 학습 과정의 개념도이다. 트랜스포머 기반 ViVIT 네트워크는 큰 데이터 세트로 사전 학습(pre-training)이 이뤄져야 좋은 성능을 제공한 다. 그러나 생체 데이터의 경우 대규모 데이터가 많지 않고, 분류하기 위한 도메인 전문 지식이 필요하기 때문 에 라벨링(labeling)하는 데도 비용이 많이 든다. 대규모 NIR 비디오에 대해 사전 훈련된 모델을 찾기가 어렵고 사전 학습된 모델의 경우 단일 모델인 RGB 전용 모델이 대부분이어서 융합 모델의 네트워크와 다를 수 있다. 특히, ViViT 네트워크에 대해 NIR 비디오로 사전 학습된 모델이 없다. 위와 같은 문제를 해결하기 위해, 본 발명의 일 실시에 따른 컬러 및 근적외선 비디오를 이용한 비접촉식 심박 측정 방법은, 컬러 및 근적외선 비디오를 학습시키는 자기 지도 학습 과정(S200)을 더 포함할 수 있다. 본 발명의 일 실시예에 따른 자기 지도 학습 과정(S200)은 얼굴 비디오를 획득하는 과정(S100)과 저차원 컬러- 근적외선 시공간 특성 정보를 획득하는 과정(S300) 사이에 수행될 수 있다. 비접촉식 심박 측정 장치는 컬러 및 근적외선 비디오를 학습시키는 자기 지도 학습 과정(S200)을 수행할 수 있다. 이를 통해, 비접촉식 심박 측정 장치는 자기 지도 학습 방식으로 RGB-NIR Fusion ViViT 네트워크를 사전 학습시켜서, 불충분한 레이블 데이터에 대한 지도 학습의 한계를 극복할 수 있다. 자기 지도 학습(SSL; Self-Supervised Learning)은 레이블이 지정되지 않은 데이터에서 표현을 효과적으로 학습 할 수 있다. S200 과정에서, 비접촉식 심박 측정 장치는 컬러 및 근적외선 얼굴 비디오(V)에 데이터 어그먼테이션(data augmentation) 기법 및 대조학습 방법 중 적어도 하나를 수행할 수 있다. 도 7을 참조하면, 비접촉식 심박 측정 장치는 컬러 얼굴 비디오( )와 근적외선 얼굴 비디오( ) 의 데이터 세트에서 샘플링된 비디오 클립( , .., )에 시공간 어그먼테이션(spatiotemporal augmentation)을 동일하게 적용할 수 있다. 컬러 얼굴 비디오( )와 근적외선 얼굴 비디오( )는 동일한 시점에 RGB 카메라와 NIR 카메라로 촬영된 모니터링 대상자의 얼굴 비디오를 포함할 수 있다. 비디오 클립( )은 컬러 얼굴 비디오 클립( )과 동시점에 촬영된 근적외선 얼굴 비디오 클립( )을 포함 할 수 있다. 컬러 얼굴 비디오 클립( )과 근적외선 얼굴 비디오 클립( )은 서로 다른 양식을 가질 수 있다. 시공간 어그먼테이션(spatiotemporal augmentation)은 시간적 어그먼테이션 방법과 공간적 어그먼테이션 방법을 합친 시공간 어그먼테이션이다. 일 예로, 시간적 어그먼테이션 방법은 희소성 기반 시간 어그먼테이션(sparsity-based temporal augmentatio n)을 포함한다. 공간적 어그먼테이션 방법은 무작위 수평 플립 어그먼테이션(random horizontally flip augmentation) 방법을 포함한다. 비접촉식 심박 측정 장치는 컬러 얼굴 비디오 클립( ) 및 근적외선 얼굴 비디오 클립( )에 대해 동일한 시공간 어그먼테이션을 적용시켜 각각 2개의 어그먼테이션된 비디오 클립들 ( )을 생성할 수 있다. 최종적으로 컬러 및 근적외선 비디오 클립( )으로부터 모든 양식들에 대해 총 4개의 어그먼테이션된 클립들 ( )이 생성된다. 비접촉식 심박 측정 장치는 두 양식의 어그먼테이션된 클립들( )이 합쳐진 형태 로 비디오 인코더에 입력된다. 비접촉식 심박 측정 장치는 어그먼테이션이 없을 때 컬러-근적외선 시공간 특성 벡터( )을 생성하는데 반 해, 어그먼테이션 기법을 적용함으로써, 양식들의 융합된 특징인 제1 컬러-근적외선 시공간 특성 벡터( ) 및 제2 컬러-근적외선 시공간 특성 벡터( )를 생성할 수 있다. 비접촉식 심박 측정 장치는 제1 및 제2 컬러-근적외선 시공간 특성 벡터( , )를 MLP 프로젝션 헤드 (projection head)에 입력하여 프로젝션 벡터(projection vector)( , )를 출력할 수 있다. 비접촉식 심박 측정 장치는 자기 지도 학습을 위해 아래의 대조 손실(loss) 함수를 사용하여 학습을 수행 한다. 여기서 는 양의 샘플(positive Samples) 쌍이고, 는 일 때 1임을 나타내는 지시 함수(indicator function)이다. 는 온도 하이퍼파라미터(temperature hyperparameter)이고, 는 와 사이에 코사인 유사도(cosine similarity)를 계산한다. 이 대조 손실은 동일한 입력으로부터 어그먼테이 션된 이미지인 양의 샘플 쌍에 대해서 피쳐 공간(feature space)에서 가깝게 끌어당기고, 음수 쌍에 대해서 멀 어지게 한다. 대조 학습(contrastive learning)은 같은 이미지에서 다른 어그먼테이션(augmentation) 기법을 적용했을 때 생 성된 이미지 간의 특징 벡터들은 서로 가깝게, 별개의 이미지에서 어그먼테이션된 이미지들의 특징 벡터들은 서 로 멀어지도록 학습하는 것이다. 대조 학습을 위한 시공간 데이터 어그먼테이션 작업을 적용함으로써 귀납 편향과 같은 특정 제약을 주면서 표현 피처들을 효과적으로 추출하고, 도메인 정보를 효과적으로 규제하고 일반화할 수 있도록 한다. 비접촉식 심박 측정 장치는 학습 단계 이후 응용 단계(테스트 단계)에서 프로젝션 헤드가 제거되고 비디오 인코더에서 융합된 제1 및 제2 컬러-근적외선 시공간 특성 벡터( , )를 rPPG 추정기로 전달한다. 이로써, rPPG 추정기는 융합된 제1 및 제2 컬러-근적외선 시공간 특성 벡터( , )를 이용해 원격 생리 학적 표현으로 직접 사용되는 rPPG 신호를 예측할 수 있다. 도 8은 본 발명의 일 실시예에 따른 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 방법의 흐름 도를 도시한 것이다. 도 8을 참조하면, 본 발명의 일 실시예에 따른 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 방법을 이용해 rPPG 추정기의 학습 과정을 설명한다. 본 발명의 일 실시예에 따른 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 방법은, 얼굴 비디 오 데이터 세트를 획득하는 과정(S500), 얼굴 비디오 데이터 세트를 전처리하는 과정(S600), 전처리된 학습 데 이터로 rPPG 추정기을 학습시키는 과정(S700)을 포함할 수 있다. S500과정에서, 컴퓨팅 장치는 얼굴 비디오 데이터 세트를 획득할 수 있다. 얼굴 비디오 데이터 세트는 대상자를 촬영한 컬러(RGB) 얼굴 비디오, 동일한 대상자를 촬영한 근적외선(NIR) 얼 굴 비디오, 동일한 대상자의 심박 데이터를 포함한다. 심박 데이터는 대상자의 손가락 맥박 산소 측정기 혹은 산소 농도계로 측정한 대상자의 심박 신호이다. 혹은 심박 데이터는 대상자의 심박을 변환한 PPG 신호일 수 있 다. 여기서, 컬러 얼굴 비디오, 근적외선 얼굴 비디오, 심박 데이터는 동시간에 촬영되고 측정된 데이터일 수 있다. S600과정에서, 컴퓨팅 장치는 얼굴 비디오 데이터 세트를 전처리하는 과정을 수행할 수 있다. 컴퓨팅 장치는 얼굴 비디오 데이터 세트에서 컬러 얼굴 비디오와 근적외선 비디오에 기초해 비디오 인코더(20 0)를 이용해 컬러-근적외선 시공간 특성 정보(FFI, f)를 계산할 수 있다. 또한, 컴퓨팅 장치는 심박 데이터를 이용해 PPG 신호를 획득하거나 혹은 계산하여 획득할 수 있다. 이를 통해서, 컴퓨팅 장치는 동시점에 대응하는 컬러-근적외선 시공간 특정 정보와 PPG 신호를 학습데이터로 구 성할 수 있다. S700 과정에서, 컴퓨팅 장치는 컬러-근적외선 시공간 특정 정보와 PPG 신호를 학습데이터로 rPPG 추정기를 지도 학습시킬 수 있다. 이를 통해서 학습된 rPPG 추정기는 컬러-근적외선 시공간 특정 정보를 입력 받으 면 추정 rPPG 신호를 출력할 수 있다. 본 발명은 도면에 도시된 실시 예를 참조로 설명되었으나 이는 예시적인 것에 불과하며, 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시 예가 가능하다는 점을 이해할 것이다. 따라서, 본 발명의 진정한 기술적 보호 범위는 첨부된 등록청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2022-0127025", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 장치의 하드 웨어 구성도이다. 도 2는 본 발명의 일 실시예에 따른 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 방법의 흐름 도를 도시한 것이다. 도 3은 본 발명의 일 실시예에 따른 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 방법의 개념 도를 도시한 것이다. 도 4는 본 발명의 일 실시예에 따른 비디오 인코더의 구조를 도시한 것이다. 도 5는 비디오 분류를 위한 ViViT 네트워크의 다양한 모델들의 구조를 보여준다. 도6은 본 발명의 튜블렛 임베딩의 개념도를 도시한 것이다. 도 7은 본 발명의 일 실시예에 따른 자기 지도 학습 과정의 개념도이다. 도 8은 본 발명의 일 실시예에 따른 컬러 및 근적외선 비디오 이미지를 이용한 비접촉식 심박 측정 방법의 흐름 도를 도시한 것이다."}
