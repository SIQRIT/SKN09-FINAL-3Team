{"patent_id": "10-2021-0085571", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0003920", "출원번호": "10-2021-0085571", "발명의 명칭": "음성 인식 기반으로 동작하는 협동 로봇 가이드 장치 및 가이드 방법", "출원인": "주식회사 케이티", "발명자": "이종서"}}
{"patent_id": "10-2021-0085571", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서에 의해 동작하는 협동 로봇 가이드 장치가 작업자와 협업하는 협동 로봇을 가이드하는방법으로서,현재 작업을 수행하는 상기 작업자와 상기 협동 로봇을 촬영한 모니터링 영상을 수신하고, 상기 모니터링 영상을 기초로 상기 현재 작업 이후에 실행될 다음 작업을 예측하는 단계, 상기 협동 로봇으로부터 상기 작업자의 음성 명령에 해당하는 가이드 요청 신호를 수신하고, 상기 음성 명령에따른 작업 지시와 상기 다음 작업을 비교하여 음성 명령 타당성을 판단하는 단계, 그리고상기 음성 명령 수행 타당성을 기초로 상기 협동 로봇과 작업자를 가이드 할 가이드 결과를 생성하는 단계를 포함하는, 가이드 방법."}
{"patent_id": "10-2021-0085571", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 다음 작업을 예측하는 단계는,상기 모니터링 영상으로부터 상기 작업자와 협동 로봇이 작업중인 상기 현재 작업에서 사용하는 자재 정보, 상기 작업자와 협동 로봇이 현재 작업중인 작업 라인 정보, 그리고 상기 현재 작업중인 작업 범위를 포함하는 작업 특성을 추출하는 단계를 포함하는, 가이드 방법."}
{"patent_id": "10-2021-0085571", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 음성 명령 타당성을 판단하는 단계는, 상기 가이드 요청 신호와 함께 상기 작업자가 발화한 상기 음성 명령을 수신하는 단계,상기 음성 명령을 텍스트로 변환하고, 변환한 텍스트로부터 기 설정된 주요 단어들을 추출하는 단계, 그리고상기 추출한 주요 단어를 기초로 상기 작업자의 발화자 의도를 추론하는 단계를 포함하는, 가이드 방법."}
{"patent_id": "10-2021-0085571", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 음성 명령 타당성을 검토하는 단계는,상기 발화자 의도와 상기 예측한 다음 작업을 비교하는 단계, 상기 발화자 의도와 상기 다음 작업이 일치하면 상기 음성 명령이 타당하다고 판단하는 단계, 그리고상기 발화자 의도와 상기 다음 작업이 일치하지 않으면, 상기 음성 명령이 부당하다고 판단하는 단계를 포함하는, 가이드 방법."}
{"patent_id": "10-2021-0085571", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 음성 명령 타당성을 판단하는 단계 이후에,공개특허 10-2023-0003920-3-상기 작업 특성을 기초로 상기 작업자와 상기 협동 로봇이 상기 다음 작업을 수행할 때의 작업 안정성을 검토하는 단계를 더 포함하는, 가이드 방법."}
{"patent_id": "10-2021-0085571", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 작업 안정성을 검토하는 단계는,상기 모니터링 영상으로부터 상기 작업자의 작업자 위치 좌표와 상기 협동 로봇의 로봇 위치 좌표를 확인하고,상기 작업자 위치 좌표와 상기 로봇 위치 좌표를 기초로 유클리디언 거리를 계산하는 단계를 포함하는, 가이드 방법."}
{"patent_id": "10-2021-0085571", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 유클리디언 거리를 계산하는 단계 이후에,상기 다음 작업에 필요한 최소 안전 거리와 상기 계산한 유클리디언 거리를 비교하여 상기 다음 작업을 수행하는데 안전한지 또는 위험한지 검토하는 단계를 더 포함하는, 가이드 방법."}
{"patent_id": "10-2021-0085571", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 가이드 결과를 생성하는 단계는,상기 생성한 가이드 결과를 음성으로 변환하여 상기 협동 로봇과 작업자에게 전송하는 단계를 포함하는, 가이드 방법."}
{"patent_id": "10-2021-0085571", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "작업자의 음성 명령에 따라 작업을 수행하는 협동 로봇을 가이드하는 장치로서,현재 작업을 수행하는 상기 작업자와 상기 협동 로봇을 촬영한 모니터링 영상을 수신하고, 상기 모니터링 영상을 기초로 상기 현재 작업 이후에 실행될 다음 작업을 예측하는 다음 작업 예측부,상기 협동 로봇으로부터 상기 작업자의 음성 명령에 해당하는 가이드 요청 신호와 상기 음성 명령을 수신하고,상기 음성 명령으로부터 작업 지시에 해당하는 발화자 의도를 추출하는 발화 의도 추출부,상기 다음 작업과 상기 발화자 의도를 비교하여 음성 명령 타당성을 판단하는 명령 수행 타당성 판정부, 그리고상기 음성 명령 타당성을 기초로 상기 협동 로봇과 작업자를 가이드 할 음성 가이드 결과를 생성하는 음성 가이드 결과 생성부를 포함하는, 협동 로봇 가이드 장치."}
{"patent_id": "10-2021-0085571", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 모니터링 영상으로부터 상기 작업자와 협동 로봇이 작업중인 상기 현재 작업에서 사용하는 자재 정보, 상기 작업자와 협동 로봇이 현재 작업중인 작업 라인 정보, 그리고 상기 현재 작업중인 작업 범위를 포함하는 작업 특성을 추출하는 작업 특성 추출부를 더 포함하는, 협동 로봇 가이드 장치."}
{"patent_id": "10-2021-0085571", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2023-0003920-4-제10항에 있어서,상기 명령 수행 타당성 판정부는,음성 명령을 텍스트로 변환하고, 변환한 텍스트로부터 기 설정된 주요 단어들을 추출하고, 상기 추출한 주요 단어를 기초로 상기 작업자의 발화자 의도를 추론하는, 협동 로봇 가이드 장치."}
{"patent_id": "10-2021-0085571", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 작업 특성을 기초로 상기 작업자와 상기 협동 로봇이 상기 다음 작업을 수행할 때의 작업 안정성을 검토하는 작업 안정성 확인부를 더 포함하는, 협동 로봇 가이드 장치."}
{"patent_id": "10-2021-0085571", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 작업 안정성 확인부는,상기 모니터링 영상으로부터 상기 작업자의 작업자 위치 좌표와 상기 협동 로봇의 로봇 위치 좌표를 확인하고,상기 작업자 위치 좌표와 상기 로봇 위치 좌표를 기초로 유클리디언 거리를 계산하며, 상기 다음 작업에 필요한최소 안전 거리와 상기 계산한 유클리디언 거리를 비교하여 상기 다음 작업을 수행하는데 안전한지 또는 위험한지 검토하는, 협동 로봇 가이드 장치."}
{"patent_id": "10-2021-0085571", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,연동한 모니터링 장비로부터 상기 모니터링 영상을 수신하여 상기 다음 작업 예측부로 전달하는 가이드 요청 수신부를 더 포함하는, 협동 로봇 가이드 장치."}
{"patent_id": "10-2021-0085571", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "현재 작업을 수행하는 작업자와 작업자의 음성 명령에 따라 현재 작업을 협동으로 수행하는 협동 로봇이 촬영된 모니터링 영상으로부터, 현재 작업의 작업 특성을 추출하여 현재 작업이 종료된 이후에 실행될 다음 작업을 예측 한다. 협동 로봇으로부터 가이드 요청 신호를 수신하고, 음성 해석 서버로부터 작업자가 발화한 음성 명령에 대 한 발화자 의도를 수신하면, 발화자 의도와 예측한 다음 작업을 기초로 음성 명령에 따라 협동 로봇의 명령 수행 타당성을 검토한다. 그리고 작업 특성을 기초로 작업자와 협동 로봇이 음성 명령에 따른 작업을 수행할 때의 작업 안정성을 검토한 후, 명령 수행 타당성과 작업 안정성을 기초로 협동 로봇과 작업자를 가이드 할 가이드 결과를 생성한다."}
{"patent_id": "10-2021-0085571", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 스마트 공장에서 협동 로봇이 작업자와 음성 인식 기반으로 협업할 때, 협동 로봇의 동작을 가이드하 는 협동 로봇 가이드 장치 및 가이드 방법에 관한 것이다."}
{"patent_id": "10-2021-0085571", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 협동 로봇은 스마트 공장(Smart Factory)과 같은 5G 기반 B2B 서비스에서 가치가 부각되고 있다. 통신사와 제조업계의 공동 작업을 통해, 통신사는 제조업의 니즈를 파악해 기술을 고도화할 수 있고, 제조사는 스마트 공 장을 선제 도입할 수 있다. 5G 통신이 인공지능 또는 빅데이터 기술과 결합되어 제조업의 로봇 기술에 적용된다면, 미래에 제조방식 자체를 바꿀 수 있기에 높은 사회적 및 경제적 가치를 지닌다. 특히, 음성기반 동작하는 협동로봇은 사람과 즉각적으로 협업해서 업무를 유동적으로 처리할 수 있기 때문에, 최근 더 각광받고 있다. 음성인식 기반으로 작동하는 협동 로봇은 사람에게 명령을 음성으로 전달받고 이를 실시간으로 수행한다. 인공 지능 스피커의 동작과 유사하게 보일 수 있으나 인공지능 스피커는 음성 답변을 하거나 전자 기기(IPTVE, IoT) 를 구동시키지만, 음성인식 기반으로 작동하는 협동 로봇의 경우에는, 협동 로봇이 동작을 가지고 움직인다. 그러므로, 작업자가 의도한 명령과 다른 의도로 협동 로봇이 행동할 경우, 제조 결함 및 안전 사고로 이루어질 수 있다. 따라서, 상황에 적합하지 않은 음성 명령이 발생한 경우, 협동 로봇이 해당 음성 명령을 수행하지 말 도록 사전에 통제해야 한다. 이를 위해, 협동 로봇으로 전달하는 음성인식 결과를, 상황에 맞게 가이드 해줄 가"}
{"patent_id": "10-2021-0085571", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "이드 장치가 요구된다.발명의 내용"}
{"patent_id": "10-2021-0085571", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명은 음성인식 기능을 가진 협동 로봇을 운영할 때, 협동 로봇이 음성 명령어에 따라 동작을 수행 하는 것이 타당하고 안전한지를, 작업자와 협동 로봇의 현재 상황과 행동을 기초로 파악하여 알려주는 음성 인 식 기반으로 동작하는 협동 로봇 가이드 장치 및 방법을 제공한다."}
{"patent_id": "10-2021-0085571", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 본 발명의 기술적 과제를 달성하기 위한 본 발명의 하나의 특징인 적어도 하나의 프로세서에 의해 동작하 는 협동 로봇 가이드 장치가 작업자와 협업하는 협동 로봇을 가이드하는 방법으로서, 현재 작업을 수행하는 상기 작업자와 상기 협동 로봇을 촬영한 모니터링 영상을 수신하고, 상기 모니터링 영상 을 기초로 상기 현재 작업 이후에 실행될 다음 작업을 예측하는 단계, 상기 협동 로봇으로부터 상기 작업자의 음성 명령에 해당하는 가이드 요청 신호를 수신하고, 상기 음성 명령에 따른 작업 지시와 상기 다음 작업을 비 교하여 음성 명령 타당성을 판단하는 단계, 그리고 상기 음성 명령 수행 타당성을 기초로 상기 협동 로봇과 작 업자를 가이드 할 가이드 결과를 생성하는 단계를 포함한다. 상기 다음 작업을 예측하는 단계는, 상기 모니터링 영상으로부터 상기 작업자와 협동 로봇이 작업중인 상기 현 재 작업에서 사용하는 자재 정보, 상기 작업자와 협동 로봇이 현재 작업중인 작업 라인 정보, 그리고 상기 현재 작업중인 작업 범위를 포함하는 작업 특성을 추출하는 단계를 포함할 수 있다. 상기 음성 명령 타당성을 판단하는 단계는, 상기 가이드 요청 신호와 함께 상기 작업자가 발화한 상기 음성 명 령을 수신하는 단계, 상기 음성 명령을 텍스트로 변환하고, 변환한 텍스트로부터 기 설정된 주요 단어들을 추출 하는 단계, 그리고 상기 추출한 주요 단어를 기초로 상기 작업자의 발화자 의도를 추론하는 단계를 포함할 수 있다. 상기 음성 명령 타당성을 검토하는 단계는, 상기 발화자 의도와 상기 예측한 다음 작업을 비교하는 단계, 상기 발화자 의도와 상기 다음 작업이 일치하면 상기 음성 명령이 타당하다고 판단하는 단계, 그리고 상기 발화자 의 도와 상기 다음 작업이 일치하지 않으면, 상기 음성 명령이 부당하다고 판단하는 단계를 포함할 수 있다. 상기 음성 명령 타당성을 판단하는 단계 이후에, 상기 작업 특성을 기초로 상기 작업자와 상기 협동 로봇이 상 기 다음 작업을 수행할 때의 작업 안정성을 검토하는 단계를 더 포함할 수 있다. 상기 작업 안정성을 검토하는 단계는, 상기 모니터링 영상으로부터 상기 작업자의 작업자 위치 좌표와 상기 협 동 로봇의 로봇 위치 좌표를 확인하고, 상기 작업자 위치 좌표와 상기 로봇 위치 좌표를 기초로 유클리디언 거 리를 계산하는 단계를 포함할 수 있다. 상기 유클리디언 거리를 계산하는 단계 이후에, 상기 다음 작업에 필요한 최소 안전 거리와 상기 계산한 유클리 디언 거리를 비교하여 상기 다음 작업을 수행하는데 안전한지 또는 위험한지 검토하는 단계를 더 포함할 수 있 다. 상기 가이드 결과를 생성하는 단계는, 상기 생성한 가이드 결과를 음성으로 변환하여 상기 협동 로봇과 작업자 에게 전송하는 단계를 포함할 수 있다. 상기 본 발명의 기술적 과제를 달성하기 위한 본 발명의 또 다른 특징인 작업자의 음성 명령에 따라 작업을 수 행하는 협동 로봇을 가이드하는 장치로서, 현재 작업을 수행하는 상기 작업자와 상기 협동 로봇을 촬영한 모니터링 영상을 수신하고, 상기 모니터링 영상 을 기초로 상기 현재 작업 이후에 실행될 다음 작업을 예측하는 다음 작업 예측부, 상기 협동 로봇으로부터 상 기 작업자의 음성 명령에 해당하는 가이드 요청 신호와 상기 음성 명령을 수신하고, 상기 음성 명령으로부터 작 업 지시에 해당하는 발화자 의도를 추출하는 발화 의도 추출부, 상기 다음 작업과 상기 발화자 의도를 비교하여 음성 명령 타당성을 판단하는 명령 수행 타당성 판정부, 그리고 상기 음성 명령 타당성을 기초로 상기 협동 로 봇과 작업자를 가이드 할 음성 가이드 결과를 생성하는 음성 가이드 결과 생성부를 포함한다. 상기 모니터링 영상으로부터 상기 작업자와 협동 로봇이 작업중인 상기 현재 작업에서 사용하는 자재 정보, 상 기 작업자와 협동 로봇이 현재 작업중인 작업 라인 정보, 그리고 상기 현재 작업중인 작업 범위를 포함하는 작업 특성을 추출하는 작업 특성 추출부를 더 포함할 수 있다. 상기 명령 수행 타당성 판정부는, 음성 명령을 텍스트로 변환하고, 변환한 텍스트로부터 기 설정된 주요 단어들 을 추출하고, 상기 추출한 주요 단어를 기초로 상기 작업자의 발화자 의도를 추론할 수 있다. 상기 작업 특성을 기초로 상기 작업자와 상기 협동 로봇이 상기 다음 작업을 수행할 때의 작업 안정성을 검토하 는 작업 안정성 확인부를 더 포함할 수 있다. 상기 작업 안정성 확인부는, 상기 모니터링 영상으로부터 상기 작업자의 작업자 위치 좌표와 상기 협동 로봇의 로봇 위치 좌표를 확인하고, 상기 작업자 위치 좌표와 상기 로봇 위치 좌표를 기초로 유클리디언 거리를 계산하 며, 상기 다음 작업에 필요한 최소 안전 거리와 상기 계산한 유클리디언 거리를 비교하여 상기 다음 작업을 수 행하는데 안전한지 또는 위험한지 검토할 수 있다. 연동한 모니터링 장비로부터 상기 모니터링 영상을 수신하여 상기 다음 작업 예측부로 전달하는 가이드 요청 수 신부를 더 포함할 수 있다."}
{"patent_id": "10-2021-0085571", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 협동 로봇이 인식한 음성 명령이 작업자와 협동 로봇의 상황과 행동을 기초로 타당하고 안전 하다고 가이드 된 명령이므로, 스마트 공장과 같은 작업 환경에서 안전 사고나 재조 결함을 방지하거나 감소시 킬 수 있다."}
{"patent_id": "10-2021-0085571", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위 해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 이하, 도면을 참조로 하여 본 발명의 실시예에 따른 음성 인식 기반으로 동작하는 협동 로봇 가이드 장치 및 방 법에 대해 상세히 설명한다. 본 발명의 실시예에서는 하나의 협동 로봇이 전체 작업을 같은 자리에서 순차 적으로 수행하는 경우에 적용되는 발명을 실시예로 하여 설명하며, 반드시 이와 같이 한정되는 것은 아니다. 도 1은 본 발명의 실시예에 따른 협동 로봇 가이드 장치가 적용된 환경의 예시도이다. 도 1에 도시된 바와 같이, 스마트 공장에서 협동 로봇이 작업자의 음성 명령에 따라 정해진 자리 에서 작업을 순자척으로 작업하는 한경에서, 협동 로봇 가이드 장치는 모니터링 장비(400, 410~420)들이 실시간으로 수집한 협동 로봇과 작업자의 현재 상황에 대한 영상(이하, 설명의 편의를 위하여 '모니 터링 영상'이라 지칭함)을 지속적으로 수신한다. 도 1에서는 협동 로봇 가이드 장치가 스마트 공장 외부에 설치되어 있는 것으로 표현하였으나, 스마트 공장 내부에 설치될 수도 있다. 그리고 도 1에서는 협동 로봇과 작업자를 촬영할 수 있는 두 대의 카메라를 모니터링 장비로 표 현하였으나, 모니터링 장비의 수와 장비 종류를 반드시 이와 같이 한정하지 않는다. 또한, 도 1에는 표시하지 않았으나, 모니터링 장비에 작업자가 발화한 명령 음성을 수집하는 마이크가 구비될 수도 있다. 협동 로봇 가이드 장치는 모니터링 장치가 수집한 모니터링 영상에서, 딥러닝 순차 모델을 이용하여 작업자와 협동 로봇의 작업 특성(Feature) 들을 추출한다. 여기서, 작업 특성에는 모니터링 영상에서 추출된 협동 로봇과 작업자가 사용 중인 자재 정보, 협동 로봇과 작업자가 현재 작업중인 작업 라인 정보, 그리고 협동 로봇과 작업자가 작업중인 작업 범위 등이 포함되는 것을 예로 하여 설 명하나, 반드시 이와 같이 한정되는 것은 아니다. 그리고, 협동 로봇 가이드 장치는 모니터링 영상을 기초로, 협동 로봇의 위치 좌표와 작업자의 위치 좌표도 영상으로부터 추출한다. 협동 로봇 가이드 장치가 모니터링 영상에서 협동 로봇과 작업 자의 위치 좌표를 추출하는 방법은 다양한 방법으로 실행할 수 있다. 예를 들어, 협동 로봇 가이드 장치는 거리 정보 기반(Range-based) 방식으로 협동 로봇과 작업자 의 위치 좌표를 추출할 수 있다. 무선통신 기반 위치 측위 기술에 해당하는 거리 정보 기반 방식은, 위치 가 정확하게 알려진 앵커(예를 들어, AP(Access Point) 등)와 위치를 모르는 단말 간 거리정보를 바탕으로 삼변 측량법을 이용하여 단말의 위치를 찾는 기술이다. 단말로부터 앵커 1까지의 거리가 d1, 앵커 2까지의 거리가 d2, 그리고 앵커 3 까지의 거리가 d3이라면, 단말의 위치는 각 앵커를 중심으로 하고 각 앵커에서 단말까지의 각각의 거리를 반지름으로 하는 원의 교점으로 찾을 수 있다. 삼변 측량을 통해 단말의 위치를 찾기 위해서는 2차원 공간의 경우에 최소 3개 이상, 3차원 공간의 경 우에 최소 4개 이상의 앵커가 필요하다. 이렇게 설치된 앵커를 바탕으로 단말과 앵커 간 거리에 따른 앵커 혹은 단말로부터 송신되는 무선 신호의 세기 및 무선 신호의 전파 지연시간 측정을 통해, 단말의 위치와 좌표를 계산할 수 있다. 이러한 거리 정보 기반 방 식은 하나의 예로, 본 발명의 실시예에서는 거리 정보 기반 방식으로만 한정하지 않는다. 협동 로봇 가이드 장치는 추출한 작업 특성을 기초로, 현재 작업이 종료된 후 이어질 다음 작업을 미리 설 정한 주기로 예측한다. 본 발명의 실시예에서는 다음 작업을 예측하는 주기를 어느 하나로 한정하지 않는다. 이 를 위해, 협동 로봇 가이드 장치에는 작업 공정 전체에 대한 공정 절차와, 각 공정별 내용과 해당 공정이 수행되는 설비 또는 장치, 그리고 해당 공정에서 사용되는 자재 정보 등의 공정 절차 정보가 저장되어 있다. 협동 로봇 가이드 장치는 협동 로봇으로부터 가이드 요청 신호와 작업자가 발화한 음성 명령을 수신하면, 음성 명령에서 발화자 의도를 예측한다. 본 발명의 실시예에서는 협동 로봇 가이드 장치가 음성 명령을 처리하여 발화자 의도를 예측하는 것을 예로 하여 설명하나, 협동 로봇 가이드 장치와 물리적으로 구분된 음성 처리 서버에서 발화자 의도를 예측할 수도 있다. 협동 로봇 가이드 장치는 작업자가 협동 로봇에 음성 명령을 발화하면, 협동 로봇으로부터 음성 명령을 전달받아 명령 텍스트로 변형한다. 그리고 협동 로봇 가이드 장치가 음성을 명령 텍스트로 변 환하는 방법은 다양한 방법으로 수행될 수 있으므로, 본 발명의 실시예에서는 어느 하나의 방법으로 한정하지 않는다. 협동 로봇 가이드 장치는 음성 텍스트에서 주요 단어들을 추출한다. 그리고 협동 로봇 가이드 장치는 추출한 주요 단어들의 특성(이하, 설명의 편의를 위하여 '발화 특성'이라 지칭함)을 추출하여 작업자의 발 화 의도를 추론한다. 즉, 협동 로봇 가이드 장치는 음성 텍스트를 가지고 형태소 분석을 수행하여 형태소 단위로 분할 후, 쪼갠 형태소 단위에서 품사를 추출한다. 협동 로봇 가이드 장치가 음성 텍스트에 형태소 분석을 수행하는 방법 은 다양한 방법을 통해 수행할 수 있으므로, 본 발명의 실시예에서는 어느 하나의 방법으로 한정하지 않는다. 형태소 단위에서 추출한 품사가 명사(Noun)와 동사(Verb)일 때 해당 단어들이 핵심 단어들에 해당한다. 협동 로 봇 가이드 장치는 핵심 단어들만 이용하여 의도 분류를 수행할 경우 노이즈가 제거되면서 더 정확한 의도 분류를 수행할 수 있다. 예를 들어, 사용자가 \"다음 전지팩 설치할래\"를 발화한 경우, 협동 로봇 가이드 장치는 형태소 분석을 수 행하여 [(\"전지\",NNG),(\"팩\",\"NNG\"),(\"설치\",NNG)] 의 주요 단어만 남길 수 있다. 협동 로봇 가이드 장치(10 0)는 추출된 핵심 단어들 중에 실제 발화분류에 쓰인 단어들을 이용하여, 다음 수학식 1과 같이 n개의 핵심 단 어들과 작업 클래스 간 발생확률()의 곱을 비교하여, 사용자가 발화한 상태가 어떤 작업 클래스가 될 확률이 높은지( ) 파악할 수 있다. 수학식 1"}
{"patent_id": "10-2021-0085571", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "즉, 사용자의 발화가 \"전지팩탑재\" 공정에서만 주로 사용될 수 있는 [\"전지\", \"팩\"] 단어를 포함하여 발화했기 때문에, \"다음 전지팩 설치할래\" 발화는 통계적 결과에 의해 \"전지팩탑재\" 과정에 가장 높은 확률 값을 가진다. 이를 기반으로 협동 로봇 가이드 장치는 사용자의 발화가 \"전지팩탑재\"에 적합하다고 추론할 수 있다. 협동 로봇 가이드 장치는 예측한 다음 작업과 발화자 의도를 기초로 협동 로봇에 전달된 음성 명령이 타당한 명령인지 아닌지 여부 즉, 명령 수행 타당성을 타당/부당(True/False)으로 판별한다. 또한, 협동 로봇 가이드 장치는 협동 로봇이 음성 명령에 따라 작업을 수행할 때, 작업 안정성을 검 토한다. 즉, 협동 로봇 가이드 장치는 작업자가 요청한 작업에 따른 현재 위치로부터의 작업자 와 협동 로봇의 행동 반경, 충돌 가능성 및 충돌이 나지 않기 위한 작업자의 자리 이동 거리 등을 계 산하여, 안정성 여부를 안전/위험으로 판별한다. 협동 로봇 가이드 장치는 타당한 명령인지 아닌지 확인한 결과, 그리고 작업 안정성 검토 결과를 음성으로 변환하고, 음성 가이드 결과를 협동 로봇과 작업자가 인지하도록 출력한다. 본 발명의 실시예에 따른 협동 로봇 가이드 장치는 음성 신호 처리 기능도 수행하므로 음성 가이드 결과를 출력하지만, 음성 신호 처리를 위한 서버가 별도로 구비되어 있다면 텍스트 형태의 가이드 결과를 음성 신호 처리 서버로 전송할 수도 있다. 협동 로봇 가이드 장치는 작업자의 명령어에 해당하는 작업이 다음 작업에 적합한 작업이면서 안전하 다고 판단된 상황의 음성 명령어에 대해서만, 협동 로봇에 음성 인식된 작업 실행을 허용한다는 메시지를 전송한다. 한편, 결격 상황(부당한 작업 또는 위험한 상황 등)에 대해서는 협동 로봇 가이드 장치는 결격 상황인 사유에 대한 메시지를 협동 로봇과 작업자에게 전달한다. 협동 로봇은 작업자가 발화한 음성 명령을 기초로 작업을 수행한다. 작업을 수행하는 중에 또는 작업 이 완료된 뒤 작업자가 새로운 음성 명령을 발화하면, 음성 명령과 함께 협동 로봇 가이드 장치에 새 로운 작업에 대한 가이드 요청 신호를 전송한다. 이를 위해, 협동 로봇에는 음성 명령을 수집할 마이크가 구비되어 있는 것을 예로 하여 설명한다. 협동 로봇은 협동 로봇 가이드 장치에서 음성으로 변환되어 전송된 음성 가이드 결과를 기초로, 새로 운 작업을 수행하거나 수행중인 작업을 중단한다. 협동 로봇이 작업자의 음성 명령을 인식하여 작업 을 수행하는 방법은 다양한 형태로 실행될 수 있으므로, 본 발명의 실시예에서는 어느 하나의 방법으로 한정하 지 않는다. 이러한 환경에서, 작업자와 협동 로봇을 가이드하는 협동 로봇 가이드 장치의 구조에 대해 도 2 를 참조로 설명한다. 도 2는 본 발명의 실시예에 따른 협동 로봇 가이드 장치의 구조도이다. 도 2에 도시된 바와 같이, 협동 로봇 가이드 장치는 모니터링 영상 수집부, 작업 특성 추출부, 다음 작업 예측부, 가이드 요청 수신부, 발화 의도 추출부, 명령 수행 타당성 판정부, 작 업 안정성 확인부, 그리고 음성 가이드 결과 생성부를 포함한다. 모니터링 영상 수집부는 모니터링 장비로부터 현재 작업을 수행하는 협동 로봇과 작업자의 모니터링 영상을 수신한다. 작업 특성 추출부는 모니터링 영상 수집부가 수집한 모니터링 영상에서 작업자와 협동 로봇 의 작업 특성(Feature) 들을 추출한다. 여기서, 작업 특성에는 모니터링 영상에서 추출된 협동 로봇 과 작업자가 사용 중인 자재 정보, 협동 로봇과 작업자가 작업중인 작업 라인 정보, 그리고 협 동 로봇과 작업자가 작업중인 작업 범위 등을 포함한다. 작업 특성 추출부는 추출한 작업 특성을 이미지화 하여 생성할 수 있다. 이때, 작업 특성 추출부는 다양한 방법으로 복수의 정보들이 포함된 작업 특성을 이미지화할 수 있으므로 본 발명의 실시예에서는 어느 하 나의 방법으로 한정하지 않는다. 또한, 작업 특성 추출부는 모니터링 영상으로부터 작업자와 협동 로봇의 위치 좌표를 각각 추출 한다. 작업 특성 추출부가 작업 특성을 추출하는 방법이나 위치 좌표를 추출하는 방법은 다양한 방법으로 실행될 수 있으므로, 본 발명의 실시예에서는 어느 하나의 방법으로 한정하지 않는다. 다음 작업 예측부는 작업 특성 추출부가 추출한 작업 특성을 이용하여 현재 작업 이후에 실행될 다음 작업을 예측한다. 이를 위해, 다음 작업 예측부는 학습 데이터로 학습된 딥러닝 순차 모델을 이용하여 다 음 작업을 예측한다. 즉, 다음 작업 예측부는 먼저 모니터링 영상 수집부가 수집한 모니터링 영상의 구간별 이미지들을 CNN을 사용하여 축약한다. 이 작업을 통해 다음 작업 예측부는 구간별 M×N 크기의 이미지를 L×1 크기의 데이터로 축약한다. 축약한 이미지에 작업 특성 추출부에서 생성한 작업 특성값들이 잘 반영될 수 있게, 다음 작업 예측부 는 축약한 이미지에 마스킹 기법을 적용한다. 마스킹 기법을 적용하면, CNN을 통해 축약된 이미지에 작업 특성이 추출된 구간에 대한 가중치를, 모니터링 영상의 다른 구간보다 더 둘 수 있다. 다음으로 다음 작업 예측부는 1차원으로 압축된 데이터의 여러 구간정보를 순차정보로 결합한다. 1차원으 로 압축된 데이터의 여러 구간정보를 순차정보로 결합한다. 그리고 다음 작업 예측부는 LSTM(Long Short- Term Memory Model) 알고리즘을 사용하여 다음 공정에 해당하는 작업명(즉, 레이블)의 확률을 학습한다. 즉, 다음 작업 예측부는 제조 일정 구간의 연속된 영상의 데이터를 입력으로 하고 다음 수행될 \"공정이 름\"을 출력으로 하여, 주요 작업 특성들의 변화를 반영한 많은 영상들과 작업명을 학습한다. 이를 통해, 다음 작업 예측부로 새로운 특정 구간의 연속된 데이터를 수신할 경우, 다음으로 이어질 가장 높은 확률의 공정 이름을 구할 수 있다. 가이드 요청 수신부는 협동 로봇으로부터 협동 로봇이 수집한 음성 명령을 포함하는 가이드 요 청 신호를 수신한다. 본 발명의 실시예에서는 협동 로봇이 내장된 또는 외부에 연결된 마이크를 이용하여 음성 명령을 수집하는 것을 예로 하여 설명한다. 그러나, 마이크가 모니터링 장비에 포함되어 있는 경우, 가이드 요청 수신부는 협동 로봇으로부터는 가이드 요청 신호를 수신하고, 협동 로봇이 가이드 요청 신호를 전송한 시점에 모니터링 장비가 수집한 음성 명령을 수신할 수도 있다. 발화 의도 추출부는 음성 명령을 명령 텍스트로 변환한다. 그리고, 명령 텍스트에서 기 설정된 주요 단어 들을 추출한 후, 추출한 주요 단어들의 발화 특성을 추출하여 발화 의도를 추론한다. 명령 수행 타당성 판정부는 다음 작업 예측부가 예측한 다음 작업에 대한 정보와 발화 의도 추출부 가 추출한 발화 의도를 기초로, 협동 로봇에 전달된 음성 명령이 타당한 명령인지 아닌지 판정한다. 작업 안정성 확인부는 음성 명령을 발화한 작업자의 현재 위치 좌표와 협동 로봇의 위치 좌표를 기초로, 작업자와 협동 로봇의 행동 반경, 충돌 가능성 및 충돌이 나지 않기 위한 작업자의 자 리 이동 거리 등을 계산한다. 그리고 계산한 값들을 기초로 작업자가 발화한 음성 명령에 대한 작업을 실 행할 때의 안정성 여부를 안전/위험으로 판별한다. 음성 가이드 결과 생성부는 명령 수행 타당성 판정부가 판정한 명령 수행 타당성 여부와 작업 안정성 확인부가 확인한 안정성 여부에 따라, 협동 로봇 또는 작업자에게 송출할 텍스트 형태의 가이드 결과를 생성한다. 그리고, 음성 가이드 결과 생성부는 생성한 텍스트 형태의 가이드 결과를 음성으로 변환 하여, 협동 로봇 또는 작업자에게 송출한다. 다음은, 협동 로봇 가이드 장치가 작업자와 협업으로 작업하는 협동 로봇을 가이드하는 방법에 대해 도 3을 참조로 설명한다. 도 3은 본 발명의 실시예에 따라 협동 로봇 가이드 장치가 협동 로봇을 가이드하는 방법에 대한 흐름도이다. 도 3에 도시된 바와 같이, 복수의 모니터링 장비들은 협동 로봇 가이드 장치는 스마트 공장에서 작업 자, 그리고 작업자의 음성 명령으로 작업을 수행하는 협동 로봇을 촬영한다(S100, S101). 모니터링 장비들에서 촬영된 모니터링 영상은 협동 로봇 가이드 장치로 전송된다(S102). 이때, 모니터링 장비들은 협동 로봇과 작업자가 작업을 위해 사용하고 있는 자재, 협동 로봇 과 작업자를 포함하여 작업중인 작업 라인 환경 등이 포함되도록 촬영한다. 협동 로봇 가이드 장치는 S102 단계에서 수신한 모니터링 영상을 딥러닝 순차 모델을 이용하여, 모니터링 영상에서 작업 특성들을 추출한다. 그리고 추출한 작업 특성들을 이용하여, 현재 작업이 종료된 후 이어질 다음 작업을 예측한다(S103). 협동 로봇 가이드 장치이 다음 작업을 예측하기 위해, 협동 로봇 가이드 장치 에는 작업 공정 전체에 대한 공정 절차와, 각 공정별 내용과 해당 공정이 수행되는 설비 또는 장치, 그리 고 해당 공정에서 사용되는 자재 정보 등의 공정 절차 정보가 저장되어 있다. 협동 로봇과 작업자가 협동 작업하는 중에, 작업자가 협동 로봇에 음성 명령으로 작업을 지시하면(S104), 협동 로봇은 수신한 음성 명령을 포함하여 협동 로봇 가이드 장치로 가이드 요청 신 호를 전송한다(S105). 협동 로봇 가이드 장치는 작업자 즉, 음성 명령을 발화한 발화자의 발화자 의도를 분석한다(S106). 여기서, 협동 로봇 가이드 장치가 음성 명령으로부터 발화자 의도를 분석하는 방법은 여러 방법으로 실행 될 수 있으므로, 본 발명의 실시예에서는 어느 하나의 방법으로 한정하지 않는다. 협동 로봇 가이드 장치는 S103 단계에서 예측한 다음 작업과 S106 단계에서 분석한 발화자 의도를 기초로, 작업자가 발화한 명령을 협동 로봇이 수행하는 것이 타당한지 여부, 즉 명령 수행 타당성 여부를 검 토한다(S107). 협동 로봇 가이드 장치는 협동 로봇의 명령 수행이 타당하다고 판단하였는지 확인하고 (S108), 명령 수행이 타당하지 않다면 협동 로봇 가이드 장치는 작업 가이드 결과로 명령 수행 부당 결과 를 생성한다(S109). 그러나, 명령 수행이 타당한 것으로 판단하면, 협동 로봇 가이드 장치는 작업 안정성을 검토한다(S110). 협동 로봇 가이드 장치는 검토한 작업 안정성이 안전한 것으로 확인되었는지 판단한다(S111). 협동 로봇 가이드 장치는 작업 안정성이 안전하지 않은 것으로 검토되었으면, 작업 가이드 결과로 작업 위 험 결과를 생성한다(S112). 그러나 작업 안정성도 안전한 것으로 검토되었다면, 협동 로봇 가이드 장치는 작업 가이드 결과로 작업 수행 결과를 생성한다(S113). 협동 로봇 가이드 장치는 S109 단계, S112 단계 또는 S113 단계에서 생성한 텍스트 형태의 작업 가이드 결 과를 기초로 음성 가이드 결과를 생성한다(S114). 그리고 생성한 음성 가이드 결과를 협동 로봇 또는 협동 로봇과 작업자에 전송한다(S115, S116). 이때, 협동 로봇 가이드 장치가 S113 단계에서 작업 수행 결과를 생성하였다면, 협동 로봇 가이드 장치 는 협동 로봇에 음성 가이드 결과를 전송한다. 그리고 협동 로봇 가이드 장치가 S109 단계 또는 S112 단계에서 가이드 결과를 생성하였다면, 협동 로봇 가이드 장치는 협동 로봇과 작업자에 동 시에 음성 가이드 결과를 전송한다. 상술한 바와 같이, 협동 로봇 가이드 장치가 협동 로봇을 가이드하는 과정에, S103 단계에서 딥러닝 순차 모델을 통해 다음 작업을 예측하는 과정에 대해 도 4를 참조로 설명한다. 도 4는 본 발명의 실시예에 따라 다음 작업을 예측하는 과정에 대한 예시도이다. 협동 로봇 가이드 장치는 모니터링 영상을 분석하여 현재 협동 로봇과 작업자가 작업을 위해 사 용하고 있는 자재 정보, 협동 로봇과 작업자의 작업 범위, 조립 라인 위치 등을 확인한다. 그리고, 이를 기초로 현재 진행중인 작업 상황에 대한 작업 특성을 추출한다. 협동 로봇 가이드 장치는 추출한 작업 특성을 딥러닝 순차 모델을 이용하여 현재 작업이 종료된 후 이어질 수 있는 다음 작업을 예측한다. 딥러닝 순차 모델은 사전에 여러 모니터링 영상들로부터 수집한 학습 데이터 셋 을 이용하여 CNN(Convolutional Neural Network), LSTM(Long Short-Term Memory) 신경망 등의 딥러닝 기법을 병합하여 학습된 모델을 의미한다. 여기서, 학습 데이터 셋은 사용중인 자재, 협동 로봇과 작업자의 작업 범위, 조립 라인 위치 등의 데이터가 작업명(레이블)에 할당되어 있다. 딥러닝 순차 모델을 통해서 협동 로봇 가이드 장치는 현재 작업 상황의 다음 작업 상황으로 이어질 수 있 는 작업이 무엇인지 예측할 수 있다. 협동 로봇 가이드 장치는 예측 결과에 softmax를 적용하여, 각 세부 예측별로 확률치가 표시되도록 한다. 예측 결과 중 확률 결과 값이 가장 높은 카테고리를 예측 결과로 선택하게된다. 도 4에는 EV 컴포넌트 조립 라인을 예로 하여 도시하였으며, 딥러닝 순차 모델을 임의의 공정 절차 단계 상황에 맞춰서 설명하면 다음 표 1과 같다. 표 1 모니터링 영상으로부터 추출된 작업 특성 다음 작업 예측 결과 자재 조립 라인 작업 범위 상황 1 전지팩 컴포넌트 조립 라인차량 하단 작업전지팩 차량탑재 장 치 설치 작업 상황 2 리어서스팬션 리어서스팬션 조립 라인차량 후방 하단 프로세스 탑재 작업 표 1에서는 전지팩 공급 장치를 차량에 설치중인 경우(상황 1)와 리어서스팬션을 차량에 탑재하고 있는 경우(상 황2)를 나누어 딥러닝 순차 모델로 작업을 예측한 결과를 나타낸 것으로, 반드시 이와 같이 한정되는 것은 아니 다. 예를 들어, 협동 로봇과 작업자가 현재 전지팩 컴포넌트들을 컴포넌트 조립 라인에서 조립하는 상황 1의 작업을 수행하고 있다면, 협동 로봇 가이드 장치는 다음 작업 예측 결과로 전지팩 차량 탑재 장치 설 치 작업이 진행될 것을 예측할 수 있다. 이때, 협동 로봇 가이드 장치는 딥러닝 순차 모델을 이용하면, 작업자가 모니터링 장비를 등지 고 있어 특정 시점의 모니터링 영상으로부터 일부 작업 특성이 정상적으로 수집되지 못하는 상황이 발생하더라 도, 이미 다른 작업들을 학습할 때 드롭 아웃이 적용될 수 있다. 또한, 협동 로봇 가이드 장치는 다른 시 점의 작업 특성들을 같이 활용하여 다음 작업을 예측하기 때문에, 돌발 상황에도 일반화된 결과를 제공할 수 있 다. 한편, 상술한 도 3의 S107 단계에서 명령 수행 타당성을 판단한 예에 대해 설명하면 다음과 같다. 진행 중인 현 재 작업에 대한 다음 작업이 예측되면, 협동 로봇 가이드 장치는 발화자 의도와 예측된 다음 작업을 비교 한다. 즉, 협동 로봇과 협동하여 작업하고 있는 작업자가 협동 로봇에 음성으로 명령을 실행하면, 음 성 명령을 전달받은 협동 로봇 가이드 장치는 음성 명령을 텍스트로 변환한다. 그리고 텍스트로 변환된 명 령 텍스트에서 주요 단어들의 발화 특성을 추출하여 발화자 의도를 추론한다. 협동 로봇 가이드 장치는 발화자 의도를 추론한 후, 사전에 기 예측한 다음 작업과 비교하여 두 정보가 일 치하면 명령 수행 타당성을 '타당' 또는 '부당'으로 판별한다. 예를 들어, 상술한 표 1의 상황 1과 상황 2에서 작업자가 \"전지팩 설치하자\"라고 명령어를 발화했다고 가정한다. 그러면 다음 표 2와 같이 명령 수행 타당 성이 결정된다. 표 2 다음 작업 예측 결과 발화자 의도 추론 명령 수행 타당성 검토 결과 상황 1 전지팩 탑재장치 설치 작업전지팩 차량 탑재 장치 설치 작업타당(TRUE) 상황 2 프로세스 탑재 작업 부당(FALSE) 상황 1에서의 \"전지팩 설치하자\"라는 작업자의 발화는, 현재 전지팩 공급 장치를 설치하고 있고, 다음으로 는 전지팩 탑재 장치를 설치하는 것으로 판단한 상황에 적합하다. 하지만, 상황 2에서의 \"전지팩 설치하자\"라는 작업자의 발화는 실제 프로세스를 탑재해야 하는 제조 공정에서 주요 작업을 건너 뛴 상황이므로, 다음 작업을 진행하는 적합하지 않은 경우에 해당한다. 이와 같이 명령 수행 타당성을 검토한 결과 작업자가 발화한 음성 명령이 타당한 명령이면, 협동 로봇 가 이드 장치는 작업의 안정성을 판단하기 위해 작업자의 현재 위치에서 협동 로봇과 협업 작업을진행할 때 작업자의 안정성을 검토한다. 이를 위해, 협동 로봇 가이드 장치는 먼저 작업자가 요청한 작업에 대해 협동 로봇과 작업자 의 이동 반경을 파악한다. 그리고 협동 로봇의 이동 거리로부터 파악한 이동 반경만큼 작업자가 충분히 떨어져 있는지 계산한다. 예를 들어, 작업자가 \"전지팩 설치하자\"라고 명령했다고 가정하고 상술한 표 1의 상황 1과 상황 2에서의 안정성을 판단한 말했다고 가정한 경우, 상황 1과 상황 2의 안정성을 판단한 작업의 예시는 다음 표 3 과 같다. 표 3 최소 확보 안 전 거리작업자 작업 반경(a)로봇 작업 반 경(b)작업자의 위 치 좌표협동 로봇의 위치 좌표협동 로봇의 작업 반경 확 보 여부 상황 1 250 100 150 (400, 100, 170)(280, 200, 250)위험(FALSE) 상황 2 250 (400, 100, 170)(280, 200, 250)위험(FLASE) 협동 로봇 가이드 장치는 작업자와 협동 로봇 사이의 거리는 작업자의 위치 좌표(p)와 협 동 로봇의 위치 좌표(q) 간의 3차원 상의 유클리디언 거리 d로 계산할 수 있다. 해당 거리를 구하는 수식 은 다음 수학식 2와 같다. 수학식 2"}
{"patent_id": "10-2021-0085571", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2를 통해 계산된 거리가, 작업자와 협동 로봇이 협동으로 명령한 작업을 수행하기 위해 최소 로 요구되는 최소 거리만큼 떨어져 있지 않다면, 작업자와 협동 로봇이 협동으로 해당 작업을 수행하 기에는 위험하다고 판정할 수 있다. 즉, 다음 작업을 수행하기 위해 필요한 작업자의 작업 반경이 a, 협동 로봇의 작업 반경이 b 라고 가 정한다. 작업자의 중심 좌표와 협동 로봇의 중심 좌표간의 3차원 거리는 유클리디언 거리 d 보다 멀 어야 안전하다고 할 수 있다. 상술한 표 3에서는 작업자와 협동 로봇의 위치의 유클리디언 거리를 계산하면 약 175cm가 나오는데, 확보해야 할 최소 안전 거리인 250cm 보다 작아서 안정성 판단 여부가 위험(FALSE)으로 결정되었다. 다음은 명령 수행 타당성과 안정성을 검토한 결과에 따라 가이드 결과를 제공한 실시예는 다음 표 4와 같다. 표 4 명령 수행 타당성작업 안정성 가이드 결과 상황 1 TURE FALSE 안전한 작업을 위해 거리를 확보해주세요 상황 2 FALSE FALSE 명령하신 작업이 적합한지 확인한 후, 안전한 작업을 위해 거리를 확보해주세요 다음은, 상술한 바와 같이 네트워크 환경에 위치한 협동 로봇 가이드 장치에 대해 도 5를 참조로 설명한다. 도 5는 본 발명의 실시예에 따른 컴퓨팅 장치의 구조도이다. 도 5에 도시된 바와 같이, 협동 로봇 가이드 장치는 적어도 하나의 프로세서에 의해 동작하는 컴퓨팅 장치 에서, 본 발명의 동작을 실행하도록 기술된 명령들(instructions)이 포함된 프로그램을 실행한다. 컴퓨팅 장치의 하드웨어는 적어도 하나의 프로세서, 메모리, 스토리지, 통신 인터페이스 를 포함할 수 있고, 버스를 통해 연결될 수 있다. 이외에도 입력 장치 및 출력 장치 등의 하드웨어가 포함될 수 있다. 컴퓨팅 장치는 프로그램을 구동할 수 있는 운영 체제를 비롯한 각종 소프트웨어가 탑재될 수 있다. 프로세서는 컴퓨팅 장치의 동작을 제어하는 장치로서, 프로그램에 포함된 명령들을 처리하는 다양한 형태의 프로세서일 수 있고, 예를 들면, CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 등 일 수 있다. 메모리는 본 발명의 동작을 실행하도록 기술된 명령들이 프로세서에 의해 처리되도록 해당 프로그램 을 로드한다. 메모리는 예를 들면, ROM(read only memory), RAM(random access memory) 등 일 수 있다. 스토리지는 본 발명의 동작을 실행하는데 요구되는 각종 데이터, 프로그램 등을 저장한다. 통신 인터페이 스는 유/무선 통신 모듈일 수 있다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다."}
{"patent_id": "10-2021-0085571", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 협동 로봇 가이드 장치가 적용된 환경의 예시도이다. 도 2는 본 발명의 실시예에 따른 협동 로봇 가이드 장치의 구조도이다. 도 3은 본 발명의 실시예에 따른 협동 로봇 가이드 방법에 대한 흐름도이다. 도 4는 본 발명의 실시예에 따른 영상 처리 방법에 대한 흐름도이다. 도 5는 본 발명의 실시예에 따라 데이터 처리 장치가 얼굴 인식하는 방법에 대한 흐름도이다."}
