{"patent_id": "10-2021-0176292", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0087772", "출원번호": "10-2021-0176292", "발명의 명칭": "상대방의 언어 표정 몸짓 인식이 가능한 메타버스용 인공지능 비서", "출원인": "주식회사 비주얼라이트", "발명자": "정성근"}}
{"patent_id": "10-2021-0176292", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "접근하는 사용자의 몸짓 영상을 촬영하고 인공지능으로 분석하여 사용자의 몸짓(A1)을 인식하는 사용자 몸짓 인식부(100)와;접근하는 사용자의 얼굴 영상을 촬영하고 인공지능으로 분석하여 사용자의 얼굴 표정(B1)을 인식하는 사용자 얼굴 표정 인식부(200)와;접근하는 사용자의 음성을 인공지능으로 분석하여 사용자의 언어(C1)를 인식하는 사용자 음성 인식부(300)와;사용자 몸짓 인식부(100)와 사용자 얼굴 표정 인식부(200)와 사용자 음성 인식부(300)로부터 전달된 사용자의몸짓(A)과 얼굴 표정(B)과 언어(C)를 분석하여 사용자의 상태(침착, 흥분, 기쁨, 슬픔, 화), 의도, 요청사항,문의 사항을 포함하는 사용자의 종합적 조건(상태 의사)를 판단하는 AI 몸짓, 표정, 음성 종합 판단부(400)와;상기 종합 판단부(400)로부터 전달된 정보를 기초로 하여 사용자의 종합 조건에 대응하는 AI 비서(아바타)의 몸짓 영상(A2)을 생성하는 AI 대응 몸짓 생성부(500)와;상기 종합 판단부(400)로부터 전달된 정보를 기초로 하여 사용자의 종합 조건에 대응하는 AI 비서(아바타)의 얼굴 표정 영상(B2)을 생성하는 AI 대응 표정 생성부(600)와;상기 종합 판단부(400)로부터 전달된 정보를 기초로 하여 사용자의 종합 조건에 대응하는 AI 비서(아바타)의 음성 언어(C2)을 생성하는 AI 대응 언어 생성부(500)와;AI 대응 몸짓 생성부(500)로부터 전달된 AI 비서(아바타)의 몸짓 영상(A2)과 상기 AI 대응 표정 생성부(600)로부터 전달된 AI 비서(아바타)의 얼굴 표정 영상(B2)을 기존에 생성되어 저장된 기본 AI 비서 영상(D)에 블렌딩(혼합)하여 출력영상을 생성하여 애니메이션하는 AI 비서 애니메이션부(700)와;상기 AI 비서 애니메이션부(700)에서 생성된 출력영상을 시각적으로 디스플레이하고, 상기 AI 대응 언어 생성부(500)에서 생성된 언어를 음성으로 출력하는 시청각 출력부(900, 디스플레이와 스피커);를 포함하여 구성되는것을 특징으로 하는 상대방의 언어 표정 몸짓 인식이 가능한 메타버스용 인공지능 비서."}
{"patent_id": "10-2021-0176292", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서상기 사용자 몸짓 인식부(100)는,사용자 영상을 촬영하는 사용자 몸짓 촬영부(110)와,상기 사용자 영상으로부터 신체 주요점들의 좌표(X1)를 추출하고 신체 주요점 좌표를 이용하여 2D 특징 이미지1(I1)를 생성하는 몸짓 특징 추출부(130)와,상기 2D 특징 이미지 1(I1)를 학습하여 사용자의 몸짓을 인식하고, 분류하는 AI 몸짓 분석부(150),를 포함하여구성되고;상기 사용자 얼굴 표정 인식부(200)는,사용자 얼굴 영상을 촬영하는 사용자 얼굴 촬영부(210)와,상기 사용자 얼굴 영상으로부터 얼굴 주요점들의 좌표(X2)를 추출하고 얼굴 주요점 좌표를 이용하여 2D 특징 이미지 2(I2)를 생성하는 얼굴 특징 추출부(230)와,상기 2D 특징 이미지 2(I2)를 학습하여 사용자의 얼굴 표정을 인식하고, 분류하는 AI 표정 분석부(250),를 포함하여 구성되고,공개특허 10-2023-0087772-3-상기 사용자 음성 인식부(300)는,사용자 음성을 녹음하여 음성 파일을 생성하는 사용자 음성 취득부(310)와,상기 사용자 음성 파일을 인공지능으로 분석하여 사용자의 언어를 인식하는 AI 음성 인식부(350),를 포함하여구성되는 것을 특징으로 하는 상대방의 언어 표정 몸짓 인식이 가능한 메타버스용 인공지능 비서."}
{"patent_id": "10-2021-0176292", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 얼굴 특징 추출부(230)는,상기 사용자 얼굴 영상으로부터 눈 주위 주요점들, 코 주요점들, 입(입술) 주요점들, 인중 주요점, 턱 주요점에대한 좌표(X2)를 생성한 후,횡축을 눈 주위 주요점들, 코 주요점들, 입(입술) 주요점들, 인중 주요점, 턱 주요점으로 하고, 종축을 횡축과같은 순서로 눈 주위 주요점들, 코 주요점들, 입(입술) 주요점들, 인중 주요점, 턱 주요점으로 하고,각 주요점 사이의 거리(또는 거리의 비율)를 연산한 후 이를 RGB 색상화 하여 2D 이미지로 생성하여 상기 AI 표정 분석부(250)에 입력(학습) 데이터로 제공하는 것을 특징으로 하는 상대방의 언어 표정 몸짓 인식이 가능한메타버스용 인공지능 비서."}
{"patent_id": "10-2021-0176292", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 얼굴 특징 추출부(230)는,입력층과 은닉층과 출력층을 구비하는 컨벌류션 뉴럴 네트워크(CNN) 이고,상기 2D 특징 이미지 2(I2)를 인식하여 미리 학습되어진 표정 분류 중 하나로 분류 하는 것을 특징으로 하는 인공지능 표정인식 기술이 적용된 가상 현실 심리 치료 방법."}
{"patent_id": "10-2021-0176292", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 상대방의 언어 표정 몸짓 인식이 가능한 메타버스용 인공지능 비서는 접근하는 사용자의 몸짓 영상을 촬영하고 인공지능으로 분석하여 사용자의 몸짓(A1)을 인식하는 사용자 몸짓 인식부와; 접근하는 사용자의 얼굴 영상을 촬영하고 인공지능으로 분석하여 사용자의 얼굴 표정(B1)을 인식하는 사용자 얼굴 표정 인식부(20 (뒷면에 계속)"}
{"patent_id": "10-2021-0176292", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 상대방의 언어 표정 몸짓 인식이 가능한 메타버스용 인공지능 비서에 관한 것이다."}
{"patent_id": "10-2021-0176292", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "공개특허 제10-2021-0030646호 인공지능 비서를 선택하는 전자 장치 및 그 응답 제공 방법은 전자 장치에 있어 서, 마이크; 복수의 음성 비서에 대한 정보가 저장된 메모리; 및 프로세서;를 포함하고, 상기 프로세서는, 상기 마이크를 통해 사용자 음성이 입력되면, 상기 입력된 사용자 음성에 기초하여 상기 복수의 음성 비서 중 하나의 음성 비서를 식별하고, 상기 입력된 사용자 음성이 변환된 텍스트를 상기 식별된 음성 비서가 인식할 수 있는 텍스트에 기초하여 학습된 인공지능 모델에 입력하여, 상기 식별된 음성 비서가 상기 입력된 사용자 음성에 대 한 응답을 제공할 수 있는지 식별하고, 상기 식별된 음성 비서가 상기 입력된 사용자 음성에 대한 응답을 제공 할 수 없는 것으로 식별됨에 기초하여, 상기 복수의 음성 비서 각각으로부터 상기 입력된 사용자 음성에 대한 응답을 획득하고, 상기 획득된 복수의 응답 중 적어도 하나를 상기 입력된 사용자 음성에 대한 응답으로 제공하"}
{"patent_id": "10-2021-0176292", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "는, 전자 장치를 개시한다.발명의 내용"}
{"patent_id": "10-2021-0176292", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 메타버스 공간에사 사용자(접근자)의 음성 뿐 아니라 몸짓 표정을 이해하고 여기에 반응하는 음성, 몸짓, 표정을 표현할 수 있는 상대방의 언어 표정 몸짓 인식이 가능한 메타버스용 인공지능 비서를 제공하기 위 한 것이다."}
{"patent_id": "10-2021-0176292", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 상대방의 언어 표정 몸짓 인식이 가능한 메타버스용 인공지능 비서는 사용자의 몸짓 영상을 촬영하고 인공지능으로 분석하여 사용자의 몸짓(A1)을 인식하는 사용자 몸짓 인식부와; 접근하는 사용자의 얼굴 영 상을 촬영하고 인공지능으로 분석하여 사용자의 얼굴 표정(B1)을 인식하는 사용자 얼굴 표정 인식부와; 접 근하는 사용자의 음성을 인공지능으로 분석하여 사용자의 언어(C1)를 인식하는 사용자 음성 인식부와; 사용자 몸짓 인식부와 사용자 얼굴 표정 인식부와 사용자 음성 인식부로부터 전달된 사용자의 몸짓(A)과 얼굴 표정(B)과 언어(C)를 분석하여 사용자의 상태(침착, 흥분, 기쁨, 슬픔, 화), 의도, 요청사항, 문의 사항을 포함하는 사용자의 종합적 조건(상태 의사)를 판단하는 AI 몸짓, 표정, 음성 종합 판단부와; 상기 종합 판단부로부터 전달된 정보를 기초로 하여 사용자의 종합 조건에 대응하는 AI 비서(아바타)의 몸 짓 영상(A2)을 생성하는 AI 대응 몸짓 생성부와; 상기 종합 판단부로부터 전달된 정보를 기초로 하여 사용자의 종합 조건에 대응하는 AI 비서(아바타)의 얼굴 표정 영상(B2)을 생성하는 AI 대응 표정 생성부와; 상기 종합 판단부로부터 전달된 정보를 기초로 하여 사용자의 종합 조건에 대응하는 AI 비서(아바타)의 음 성 언어(C2)을 생성하는 AI 대응 언어 생성부와; AI 대응 몸짓 생성부로부터 전달된 AI 비서(아바 타)의 몸짓 영상(A2)과 상기 AI 대응 표정 생성부로부터 전달된 AI 비서(아바타)의 얼굴 표정 영상(B2)을 기존에 생성되어 저장된 기본 AI 비서 영상(D)에 블렌딩(혼합)하여 출력영상을 생성하여 애니메이션하는 AI 비 서 애니메이션부와; 상기 AI 비서 애니메이션부에서 생성된 출력영상을 시각적으로 디스플레이하고, 상기 AI 대응 언어 생성 부에서 생성된 언어를 음성으로 출력하는 시청각 출력부(900, 디스플레이와 스피커);를 포함하여 구성되는 것을 특징으로 한다. 본 발명의 상대방의 언어 표정 몸짓 인식이 가능한 메타버스용 인공지능 비서에서, 상기 사용자 몸짓 인식부 는, 사용자 영상을 촬영하는 사용자 몸짓 촬영부와, 상기 사용자 영상으로부터 신체 주요점들의 좌표 (X1)를 추출하고 신체 주요점 좌표를 이용하여 2D 특징 이미지 1(I1)를 생성하는 몸짓 특징 추출부와, 상 기 2D 특징 이미지 1(I1)를 학습하여 사용자의 몸짓을 인식하고, 분류하는 AI 몸짓 분석부,를 포함하여 구 성되고; 상기 사용자 얼굴 표정 인식부는, 사용자 얼굴 영상을 촬영하는 사용자 얼굴 촬영부와, 상기 사용자 얼굴 영상으로부터 얼굴 주요점들의 좌표(X2)를 추출하고 얼굴 주요점 좌표를 이용하여 2D 특징 이미지 2(I2)를 생성하는 얼굴 특징 추출부와, 상기 2D 특징 이미지 2(I2)를 학습하여 사용자의 얼굴 표정을 인식 하고, 분류하는 AI 표정 분석부,를 포함하여 구성되고, 상기 사용자 음성 인식부는, 사용자 음성을 녹음하여 음성 파일을 생성하는 사용자 음성 취득부와, 상기 사용자 음성 파일을 인공지능으로 분석하여 사용자의 언어를 인식하는 AI 음성 인식부를 포함하여 구성된다."}
{"patent_id": "10-2021-0176292", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르는 경우, 메타버스 공간에사 사용자(접근자)의 음성 뿐 아니라 몸짓 표정을 이해하고 여기에 반 응하는 음성, 몸짓, 표정을 표현할 수 있는 상대방의 언어 표정 몸짓 인식이 가능한 메타버스용 인공지능 비서 가 제공된다."}
{"patent_id": "10-2021-0176292", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서 본 발명의 인공지능 표정인식 기술이 적용된 가상 현실 심리 치료 방법에 대하여 첨부된 도면을 참조 하여 상세하게 설명한다. 도 1은 본 발명의 상대방의 언어 표정 몸짓 인식이 가능한 메타버스용 인공지능 비서 시스템 전체 구성도, 도 2은 사용자 몸짓 촬영부를 이용한 좌표 생성 설명도, 도 3은 사용자 얼굴 촬영부를 이 용한 좌표 생성 설명도이다. 도 1에 도시된 바와 같이, 본 발명의 상대방의 언어 표정 몸짓 인식이 가능한 메타버스용 인공지능 비서는 사용 자 몸짓 인식부와 사용자 얼굴 표정 인식부와 사용자 음성 인식부와 음성 종합 판단부와 AI 대응 몸짓 생성부와 AI 대응 표정 생성부와 AI 비서 애니메이션부와 시청각 출력부를 포함한다. 사용자 몸짓 인식부는 접근하는 사용자의 몸짓 영상을 촬영하고 인공지능으로 분석하여 사용자의 몸짓(A 1)을 인식한다. 사용자 얼굴 표정 인식부는 접근하는 사용자의 얼굴 영상을 촬영하고 인공지능으로 분석하 여 사용자의 얼굴 표정(B1)을 인식한다. 사용자 음성 인식부는 접근하는 사용자의 음성을 인공지능으로 분 석하여 사용자의 언어(C1)를 인식한다. AI 몸짓, 표정, 음성 종합 판단부는 사용자 몸짓 인식부와 사용자 얼굴 표정 인식부와 사용자 음성 인식부로부터 전달된 사용자의 몸짓(A)과 얼굴 표정(B)과 언어(C)를 분석하여 사용자의 상태(침착, 흥분, 기쁨, 슬픔, 화), 의도, 요청사항, 문의 사항을 포함하는 사용자의 종합적 조건(상태 의사)를 판단한다. 도 1에 도시된 바와 같이, AI 대응 몸짓 생성부는 종합 판단부로부터 전달된 정보를 기초로 하여 사 용자의 종합 조건에 대응하는 AI 비서(아바타)의 몸짓 영상(A2)을 생성한다. AI 대응 표정 생성부는 종합 판단부로부터 전달된 정보를 기초로 하여 사용자의 종합 조건에 대응하는 AI 비서(아바타)의 얼굴 표정 영 상(B2)을 생성한다. AI 대응 언어 생성부는 종합 판단부로부터 전달된 정보를 기초로 하여 사용자의 종합 조건에 대응하 는 AI 비서(아바타)의 음성 언어(C2)을 생성한다. AI 비서 애니메이션부는 AI 대응 몸짓 생성부로부 터 전달된 AI 비서(아바타)의 몸짓 영상(A2)과 상기 AI 대응 표정 생성부로부터 전달된 AI 비서(아바타) 의 얼굴 표정 영상(B2)을 기존에 생성되어 저장된 기본 AI 비서 영상(D)에 블렌딩(혼합)하여 출력영상을 생성하 여 애니메이션한다.시청각 출력부(900, 디스플레이와 스피커)는 AI 비서 애니메이션부에서 생성된 출력영상을 시각적으로 디 스플레이하고, 상기 AI 대응 언어 생성부에서 생성된 언어를 음성으로 출력한다. 도 1에 도시된 바와 같이, 본 발명의 일실시예에 따른 상대방의 언어 표정 몸짓 인식이 가능한 메타버스용 인공 지능 비서에 있어서, 사용자 몸짓 인식부는, 사용자 영상을 촬영하는 사용자 몸짓 촬영부와, 사용자 영상으로부터 신체 주요점들의 좌표(X1)를 추출하고 신체 주요점 좌표를 이용하여 2D 특징 이미지 1(I1)를 생성 하는 몸짓 특징 추출부와, 2D 특징 이미지 1(I1)를 학습하여 사용자의 몸짓을 인식하고, 분류하는 AI 몸짓 분석부를 포함하여 구성된다. 도 1에 도시된 바와 같이, 사용자 얼굴 표정 인식부는, 사용자 얼굴 영상을 촬영하는 사용자 얼굴 촬영부 와, 사용자 얼굴 영상으로부터 얼굴 주요점들의 좌표(X2)를 추출하고 얼굴 주요점 좌표를 이용하여 2D 특 징 이미지 2(I2)를 생성하는 얼굴 특징 추출부와, 2D 특징 이미지 2(I2)를 학습하여 사용자의 얼굴 표정을 인식하고, 분류하는 AI 표정 분석부를 포함하여 구성된다. 사용자 음성 인식부는, 사용자 음성을 녹음하여 음성 파일을 생성하는 사용자 음성 취득부와, 사용자 음성 파일을 인공지능으로 분석하여 사용자의 언어를 인식하는 AI 음성 인식부를 포함하여 구성된다. 도 3에 도시된 바와 같이, 본 발명의 일실시예에 따른 상대방의 언어 표정 몸짓 인식이 가능한 메타버스용 인공 지능 비서에 있어서, 얼굴 특징 추출부는, 사용자 얼굴 영상으로부터 눈 주위 주요점들, 코 주요점들, 입 (입술) 주요점들, 인중 주요점, 턱 주요점에 대한 좌표(X2)를 생성한 후, 횡축을 눈 주위 주요점들, 코 주요점 들, 입(입술) 주요점들, 인중 주요점, 턱 주요점으로 하고, 종축을 횡축과 같은 순서로 눈 주위 주요점들, 코 주요점들, 입(입술) 주요점들, 인중 주요점, 턱 주요점으로 한다. 그리고, 각 주요점 사이의 거리(또는 거리의 비율)를 연산한 후 이를 RGB 색상화 하여 2D 이미지로 생성하여 상기 AI 표정 분석부에 입력(학습) 데이터 로 제공한다. 도시된 바와 같이, 본 발명의 일실시예에 따른 상대방의 언어 표정 몸짓 인식이 가능한 메타버스용 인공지능 비 서에 있어서, 얼굴 특징 추출부는, 입력층과 은닉층과 출력층을 구비하는 컨벌류션 뉴럴 네트워크(CNN) 이 고, 2D 특징 이미지 2(I2)를 인식하여 미리 학습되어진 표정 분류 중 하나로 분류 하는 것이 바람직하다. 본 발명은 상기에서 언급한 바람직한 실시예와 관련하여 설명됐지만, 본 발명의 범위가 이러한 실시예에 한정되 는 것은 아니며, 본 발명의 범위는 이하의 특허청구범위에 의하여 정하여지는 것으로 본 발명과 균등 범위에 속 하는 다양한 수정 및 변형을 포함할 것이다. 아래의 특허청구범위에 기재된 도면부호는 단순히 발명의 이해를 보조하기 위한 것으로 권리범위의 해석에 영향 을 미치지 아니함을 밝히며 기재된 도면부호에 의해 권리범위가 좁게 해석되어서는 안될 것이다."}
{"patent_id": "10-2021-0176292", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 상대방의 언어 표정 몸짓 인식이 가능한 메타버스용 인공지능 비서 시스템 전체 구성도. 도 2은 사용자 몸짓 촬영부를 이용한 좌표 생성 설명도. 도 3은 사용자 얼굴 촬영부를 이용한 좌표 생성 설명도."}
