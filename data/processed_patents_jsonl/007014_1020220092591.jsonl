{"patent_id": "10-2022-0092591", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0136502", "출원번호": "10-2022-0092591", "발명의 명칭": "전자 기기를 촬영하는 촬영 박스 및 이를 포함하는 무인 매입 장치", "출원인": "민팃", "발명자": "지창환"}}
{"patent_id": "10-2022-0092591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 기기를 촬영하는 촬영 박스(photographing box)에 있어서,상기 전자 기기가 상기 촬영 박스 내로 투입되게 하는 투입부;상기 전자 기기가 안착되는 안착부;상기 안착된 전자 기기를 정해진 위치에 정렬시키는 정렬부;상기 전자 기기에 설치된 어플리케이션과 연동하여 상기 전자 기기에 단색 화면이 표시되도록 하는 앱 연동부;주어진 촬영 환경에서 상기 정해진 위치에 정렬된 전자 기기를 촬영하는 촬영부; 및상기 안착된 전자 기기가 상기 정해진 위치에 정렬하도록 상기 정렬부를 제어하고, 상기 안착된 전자 기기가 상기 정해진 위치에 정렬한 경우 상기 정렬된 전자 기기의 외관이 촬영되도록 상기 촬영부를 제어하며, 상기 정렬된 전자 기기의 화면 검사를 위해 상기 정렬된 전자 기기에 상기 단색 화면이 표시되도록 상기 앱 연동부를 제어하고, 상기 단색 화면이 촬영되도록 상기 촬영부를 제어하는 제어부를 포함하는,촬영 박스."}
{"patent_id": "10-2022-0092591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 촬영부는,상기 정렬된 전자 기기의 전면을 촬영하는 제1 카메라;상기 정렬된 전자 기기의 후면을 촬영하는 제2 카메라;상기 정렬된 전자 기기의 측면들을 촬영하는 복수의 제3 카메라들; 및조명을 제공하는 하나 이상의 광원을 포함하는, 촬영 박스."}
{"patent_id": "10-2022-0092591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 정렬부는,이동 가능한 이동바(bar)를 포함하고,상기 제어부는,상기 안착된 전자 기기가 상기 정해진 위치로 이동하도록 상기 이동바를 제어하고, 상기 안착된 전자 기기가 상기 정해진 위치로 이동한 경우 상기 이동바를 복귀시키는,촬영 박스.공개특허 10-2023-0136502-3-청구항 4 제3항에 있어서, 상기 제어부는,상기 안착된 전자 기기의 크기를 이용하여 상기 안착된 전자 기기가 상기 정해진 위치로 이동해야 하는 거리를계산하고, 상기 계산된 거리를 기초로 상기 이동바를 제어하는,촬영 박스."}
{"patent_id": "10-2022-0092591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 촬영부는,복수의 광원들; 및상기 광원들 중 제1 광원에 의해 출력된 빛이 상기 정렬된 전자 기기의 전면의 일 측에 제1 라인 조명으로 형성되도록 하고 상기 광원들 중 제2 광원에 의해 출력된 빛이 상기 전면의 다른 일 측에 제2 라인 조명으로 형성되도록 하는 제1 구조물을 포함하는,촬영 박스."}
{"patent_id": "10-2022-0092591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 제어부는,상기 제1 광원을 턴 온하고 상기 제2 광원을 턴 오프하여 상기 제1 라인 조명이 상기 전면의 상기 일 측에 형성된 경우 상기 전면이 촬영되도록 상기 촬영부를 제어하고, 상기 제1 광원을 턴 오프하고 상기 제2 광원을 턴 온하여 상기 제2 라인 조명이 상기 전면의 상기 다른 일 측에 형성된 경우 상기 전면이 촬영되도록 상기 촬영부를제어하는, 촬영 박스."}
{"patent_id": "10-2022-0092591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "무인 매입 장치에 있어서,전자 기기를 촬영하는 촬영 박스; 상기 전자 기기가 촬영되어 획득된 이미지들 및 상기 전자 기기의 내부 상태의 평가 결과를 서버에 전송하고,상기 이미지들 및 상기 평가 결과를 통해 결정된 상기 전자 기기의 가치를 상기 서버로부터 수신하는 시스템 제어부; 및상기 수신된 가치를 표시하는 디스플레이를 포함하고,상기 촬영 박스는,상기 전자 기기가 상기 촬영 박스 내로 투입되게 하는 투입부;상기 전자 기기가 안착되는 안착부;공개특허 10-2023-0136502-4-상기 안착된 전자 기기를 정해진 위치에 정렬시키는 정렬부;상기 전자 기기에 설치된 어플리케이션과 연동하여 상기 전자 기기에 단색 화면이 표시되도록 하는 앱 연동부;주어진 촬영 환경에서 상기 정해진 위치에 정렬된 전자 기기를 촬영하는 촬영부; 및상기 안착된 전자 기기가 상기 정해진 위치에 정렬하도록 상기 정렬부를 제어하고, 상기 안착된 전자 기기가 상기 정해진 위치에 정렬한 경우 상기 정렬된 전자 기기의 외관이 촬영되도록 상기 촬영부를 제어하며, 상기 정렬된 전자 기기의 화면 검사를 위해 상기 정렬된 전자 기기에 상기 단색 화면이 표시되도록 상기 앱 연동부를 제어하고, 상기 단색 화면이 촬영되도록 상기 촬영부를 제어하는 제어부를 포함하는,무인 매입 장치."}
{"patent_id": "10-2022-0092591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 촬영부는,상기 안착된 전자 기기의 전면을 촬영하는 제1 카메라;상기 안착된 전자 기기의 후면을 촬영하는 제2 카메라;상기 안착된 전자 기기의 측면들을 촬영하는 복수의 제3 카메라들; 및하나 이상의 광원을 포함하는, 무인 매입 장치."}
{"patent_id": "10-2022-0092591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 정렬부는,이동 가능한 이동바(bar)를 포함하고,상기 제어부는,상기 안착된 전자 기기가 상기 정해진 위치로 이동하도록 상기 이동바를 제어하고, 상기 안착된 전자 기기가 상기 정해진 위치로 이동한 경우 상기 이동바를 복귀시키는,무인 매입 장치."}
{"patent_id": "10-2022-0092591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 제어부는,상기 안착된 전자 기기의 크기를 이용하여 상기 안착된 전자 기기가 상기 정해진 위치로 이동해야 하는 거리를계산하고, 상기 계산된 거리를 기초로 상기 이동바를 제어하는,무인 매입 장치.공개특허 10-2023-0136502-5-청구항 11 제9항에 있어서, 상기 촬영부는,복수의 광원들; 및상기 광원들 중 제1 광원에 의해 출력된 빛이 상기 정렬된 전자 기기의 전면의 일 측에 제1 라인 조명으로 형성되도록 하고 상기 광원들 중 제2 광원에 의해 출력된 빛이 상기 전면의 다른 일 측에 제2 라인 조명으로 형성되도록 하는 제1 구조물을 포함하는,무인 매입 장치."}
{"patent_id": "10-2022-0092591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 제어부는,상기 제1 광원을 턴 온하고 상기 제2 광원을 턴 오프하여 상기 제1 라인 조명이 상기 전면의 상기 일 측에 형성된 경우 상기 전면이 촬영되도록 상기 촬영부를 제어하고, 상기 제1 광원을 턴 오프하고 상기 제2 광원을 턴 온하여 상기 제2 라인 조명이 상기 전면의 상기 다른 일 측에 형성된 경우 상기 전면이 촬영되도록 상기 촬영부를제어하는, 무인 매입 장치."}
{"patent_id": "10-2022-0092591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "전자 기기를 촬영하는 촬영 박스의 동작 방법에 있어서,상기 촬영 박스 내에 안착된 전자 기기를 정해진 위치에 정렬시키는 단계;주어진 촬영 환경에서 상기 정해진 위치에 정렬된 전자 기기의 외관을 촬영하는 단계;상기 전자 기기에 설치된 어플리케이션과 연동하여 상기 전자 기기에 단색 화면이 표시되도록 하는 단계;상기 단색 화면을 표시하는 전자 기기를 촬영하는 단계를 포함하는,촬영 박스의 동작 방법."}
{"patent_id": "10-2022-0092591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "컴퓨터 판독 가능한 기록 매체에 저장된 소프트웨어로, 제13항의 동작 방법을 실행시키는, 컴퓨터 판독 가능한기록 매체에 저장된 소프트웨어."}
{"patent_id": "10-2022-0092591", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 기기를 촬영하는 촬영 박스가 개시된다. 일 실시 예는 전자 기기가 상기 촬영 박스 내로 투입되도록 개폐 가능한 투입부, 상기 전자 기기가 안착되는 안착부, 상기 안착된 전자 기기를 정해진 위치에 정렬시키는 정렬부, 상기 전자 기기에 설치된 어플리케이션과 연동하여 상기 전자 기기에 단색 화면이 표시되도록 하는 앱 연동부, 주어진 촬영 환경에서 상기 정해진 위치에 정렬된 전자 기기를 촬영하는 촬영부, 및 상기 안착된 전자 기기가 상 기 정해진 위치에 정렬하도록 상기 정렬부를 제어하고, 상기 안착된 전자 기기가 상기 정해진 위치에 정렬한 경 우 상기 정렬된 전자 기기의 외관이 촬영되도록 상기 촬영부를 제어하며, 상기 정렬된 전자 기기의 화면 검사를 위해 상기 정렬된 전자 기기에 상기 단색 화면이 표시되도록 상기 앱 연동부를 제어하고, 상기 단색 화면이 촬영 되도록 상기 촬영부를 제어하는 제어부를 포함할 수 있다."}
{"patent_id": "10-2022-0092591", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래 실시 예들은 전자 기기를 촬영하는 촬영 박스 및 이를 포함하는 무인 매입 장치에 관한 것이다."}
{"patent_id": "10-2022-0092591", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 중고 전자 기기를 매입하는 여러 방법 중 자동화 기기를 이용한 방법이 있다. 비대면 운영, 운영 인건비 절감, 안정적이고 표준화된 분석을 위해 보다 지능적인 방법의 일환으로 인공지능 외관 분석 기술이 도입되고 있다."}
{"patent_id": "10-2022-0092591", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본원의 개시 내용을 도출하는 과정에서 보유하거나 습득한 것으로서, 반드시 본 출 원 전에 일반 공중에 공개된 공지기술이라고 할 수는 없다."}
{"patent_id": "10-2022-0092591", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "인공지능 외관 분석 알고리즘을 학습하기 위해선 학습 데이터가 필요하고 이러한 학습 데이터는 촬영 박스가 전 자 기기를 촬영함으로써 확보될 수 있다. 실제로 운영되는 자동화 기기(또는 무인 매입 장치)의 촬영 박스가 학 습 데이터의 확보에 이용된 촬영 박스와 다르면, 학습된 인공지능 외관 분석 알고리즘은 전자 기기의 외관을 제 대로 평가하지 못할 수 있다. 실제로 운영될 때의 촬영 박스의 촬영 환경과 동일한 환경에서 획득된 학습 데이 터를 통해 인공지능 외관 분석 알고리즘이 학습될 필요가 있다."}
{"patent_id": "10-2022-0092591", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시 예에 따른 전자 기기를 촬영하는 촬영 박스는 상기 전자 기기가 상기 촬영 박스 내로 투입되게 하는 투 입부; 상기 전자 기기가 안착되는 안착부; 상기 안착된 전자 기기를 정해진 위치에 정렬시키는 정렬부; 상기 전 자 기기에 설치된 어플리케이션과 연동하여 상기 전자 기기에 단색 화면이 표시되도록 하는 앱 연동부; 주어진 촬영 환경에서 상기 정해진 위치에 정렬된 전자 기기를 촬영하는 촬영부; 및 상기 안착된 전자 기기가 상기 정 해진 위치에 정렬하도록 상기 정렬부를 제어하고, 상기 안착된 전자 기기가 상기 정해진 위치에 정렬한 경우 상 기 정렬된 전자 기기의 외관이 촬영되도록 상기 촬영부를 제어하며, 상기 정렬된 전자 기기의 화면 검사를 위해 상기 정렬된 전자 기기에 상기 단색 화면이 표시되도록 상기 앱 연동부를 제어하고, 상기 단색 화면이 촬영되도 록 상기 촬영부를 제어하는 제어부를 포함할 수 있다. 상기 촬영부는 상기 정렬된 전자 기기의 전면을 촬영하는 제1 카메라; 상기 정렬된 전자 기기의 후면을 촬영하 는 제2 카메라; 상기 정렬된 전자 기기의 측면들을 촬영하는 복수의 제3 카메라들; 및 조명을 제공하는 하나 이 상의 광원을 포함할 수 있다. 상기 정렬부는 이동 가능한 이동바(bar)를 포함할 수 있다. 상기 제어부는 상기 안착된 전자 기기가 상기 정해진 위치로 이동하도록 상기 이동바를 제어하고, 상기 안착된 전자 기기가 상기 정해진 위치로 이동한 경우 상기 이동바를 복귀시킬 수 있다. 상기 제어부는 상기 안착된 전자 기기의 크기를 이용하여 상기 안착된 전자 기기가 상기 정해진 위치로 이동해 야 하는 거리를 계산하고, 상기 계산된 거리를 기초로 상기 이동바를 제어할 수 있다. 상기 촬영부는 복수의 광원들; 및 상기 광원들 중 제1 광원에 의해 출력된 빛이 상기 정렬된 전자 기기의 전면 의 일 측에 제1 라인 조명으로 형성되도록 하고 상기 광원들 중 제2 광원에 의해 출력된 빛이 상기 전면의 다른 일 측에 제2 라인 조명으로 형성되도록 하는 제1 구조물을 포함할 수 있다. 상기 제어부는 상기 제1 광원을 턴 온하고 상기 제2 광원을 턴 오프하여 상기 제1 라인 조명이 상기 전면의 상 기 일 측에 형성된 경우 상기 전면이 촬영되도록 상기 촬영부를 제어하고, 상기 제1 광원을 턴 오프하고 상기 제2 광원을 턴 온하여 상기 제2 라인 조명이 상기 전면의 상기 다른 일 측에 형성된 경우 상기 전면이 촬영되도 록 상기 촬영부를 제어할 수 있다. 일 실시 예에 따른 무인 매입 장치는 전자 기기를 촬영하는 촬영 박스; 상기 전자 기기가 촬영되어 획득된 이미 지들 및 상기 전자 기기의 내부 상태의 평가 결과를 서버에 전송하고, 상기 이미지들 및 상기 평가 결과를 통해 결정된 상기 전자 기기의 가치를 상기 서버로부터 수신하는 시스템 제어부; 및 상기 수신된 가치를 표시하는 디 스플레이를 포함할 수 있다. 일 실시 예에 따른 전자 기기를 촬영하는 촬영 박스의 동작 방법은 상기 촬영 박스 내에 안착된 전자 기기를 정 해진 위치에 정렬시키는 단계; 주어진 촬영 환경에서 상기 정해진 위치에 정렬된 전자 기기의 외관을 촬영하는 단계; 상기 전자 기기에 설치된 어플리케이션과 연동하여 상기 전자 기기에 단색 화면이 표시되도록 하는 단계; 및 상기 단색 화면을 표시하는 전자 기기를 촬영하는 단계를 포함한다.상기 동작 방법을 실행시키는 소프트웨어는 컴퓨터 판독 가능한 기록 매체에 저장될 수 있다."}
{"patent_id": "10-2022-0092591", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시 예는 학습 데이터의 확보에 이용된 촬영 박스의 촬영 환경과 실제 운영될 때의 촬영 박스의 촬영 환경 이 동일할 수 있어, 전자 기기의 외관 평가가 보다 정확히 수행되도록 할 수 있다."}
{"patent_id": "10-2022-0092591", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "실시예들에 대한 특정한 구조적 또는 기능적 설명들은 단지 예시를 위한 목적으로 개시된 것으로서, 다양한 형 태로 변경되어 구현될 수 있다. 따라서, 실제 구현되는 형태는 개시된 특정 실시예로만 한정되는 것이 아니며, 본 명세서의 범위는 실시예들로 설명한 기술적 사상에 포함되는 변경, 균등물, 또는 대체물을 포함한다. 제1 또는 제2 등의 용어를 다양한 구성요소들을 설명하는데 사용될 수 있지만, 이런 용어들은 하나의 구성요소 를 다른 구성요소로부터 구별하는 목적으로만 해석되어야 한다. 예를 들어, 제1 구성요소는 제2 구성요소로 명 명될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 설명된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 으로 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들 을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 해당 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되 는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하, 실시예들을 첨부된 도면들을 참조하여 상세하게 설명한다. 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조 부호를 부여하고, 이에 대한 중복되는 설명은 생략하기로 한 다. 도 1a 내지 도 1b는 일 실시 예에 따른 무인 매입 장치와 서버를 설명하는 도면이다. 도 1a와 도 1b를 참조하면, 무인 매입 장치와 서버가 도시된다. 무인 매입 장치는 전자 기기(또는 중고 전자 기기)(예: 스마트폰, 태블릿 PC, 웨어러블 기기 등)를 사용자 로부터 매입 및/또는 사용자에게 전자 기기(또는 중고 전자 기기)를 판매할 수 있다. 전자 기기의 타입은, 예 를 들어, 형태에 따라 바(bar) 타입, 롤러블(rollable) 타입, 또는 폴더블(foldable) 타입 등으로 구분될 수 있 다. 무인 매입 장치는, 예를 들어, 키오스크 형태일 수 있으나 이에 제한되지 않는다. 무인 매입 장치는 촬영 박스, 시스템 제어부, 및 디스플레이를 포함할 수 있다. 무인 매입 장치의 촬영 박스의 도어(door)가 열리면, 사용자는 무인 매입 장치의 케이블(예: USB 타 입 C 케이블, 라이트닝 케이블 등)과 전자 기기를 연결시킬 수 있고, 전자 기기를 촬영 박스 안에 안치시킬 수 있다. 전자 기기는 케이블을 통해 무인 매입 장치의 시스템 제어부와 연결될 수 있다. 실시 예에 따라, 전자 기기는 무선(예: 블루투스, BLE(Bluetooth Low Energy) 등)으로 무인 매입 장치의 시스템 제어부와 연결될 수 있다. 무인 매입 장치의 시스템 제어부는 전자 기기의 내부 상태 검수 및 전자 기기의 정보(예: 모델명, 시리얼 번호, 운영체제 버전 등)를 수집하기 위한 제1 어플리케이션을 전자 기기에 설치할 수 있다. 이에 제한되는 것 은 아니며, 사용자는 전자 기기를 무인 매입 장치에 투입하기 전에 제1 어플리케이션을 전자 기기에 미리 설치할 수 있다. 제1 어플리케이션은 전자 기기에서 실행됨으로써 전자 기기의 정보를 수집할 수 있고, 전자 기기의 내부 상태 (예: 하드웨어 동작 상태 등) 평가(또는 분석)를 수행할 수 있다. 하드웨어 동작 상태는, 예를 들어, 전자 기 기의 하드웨어(예: 센서, 카메라 등)가 정상적으로 동작하는지에 대한 상태를 나타낼 수 있다. 제1 어플리케이 션은 전자 기기의 하드웨어가 정상적으로 동작하는지 여부를 평가(또는 판단)할 수 있다. 촬영 박스에는 복수의 카메라들과 복수의 광원들(예: LED(light emitting diode)들)이 위치할 수 있다. 촬영 박스 내의 제1 카메라는 전자 기기의 전면을 촬영하여 전자 기기의 하나 이상의 전면 이미지를 획득할 수 있다. 촬영 박스 내의 제2 카메라는 전자 기기의 후면을 촬영하여 전자 기기의 하나 이상의 후면 이미지를 획득할 수 있다. 촬영 박스 내의 복수의 제3 카메라들 각각은 전자 기기의 측면(또는 코너)들 각각을 촬영하여 하나 이상 의 측면 이미지(또는 코너 이미지)를 획득할 수 있다. 제1 카메라는 전자 기기의 화면을 촬영하여 하나 이상의 이미지(이하, \"화면 이미지\"라 지칭함)를 획득할 수 있 다. 실시 예에 따라, 제1 어플리케이션은 전자 기기에 단색(예: 흰색, 검은색, 붉은색, 파란색, 녹색 등) 화면 이 표시되도록 할 수 있다. 전자 기기에 단색 화면이 표시된 상태에서, 제1 카메라는 전자 기기의 단색 화면을 촬영하여 이미지(이하, \"단색 화면 이미지\"라 지칭함)를 획득할 수 있다. 예를 들어, 전자 기기에 흰색 화면이 표시된 상태에서, 제1 카메라는 전자 기기의 흰색 화면을 촬영하여 제1 단색 화면 이미지를 획득할 수 있다. 전자 기기에 검은색 화면이 표시된 상태에서 제1 카메라는 전자 기기의 검은색 화면을 촬영하여 제2 단색 화면 이미지를 획득할 수 있다. 전자 기기에 흰색과 검은색 이외의 다른 단색(예: 붉은색, 파란색, 녹색 등) 화면이 표시된 상태에서 제1 카메라는 전자 기기의 다른 단색 화면을 촬영하여 제3 단색 화면 이미지를 획득할 수 있다. 전자 기기 가치 평가 장치는 전자 기기를 촬영하여 획득한 이미지들(예: 하나 이상의 전면 이미지, 하나 이상의 후면 이미지, 하나 이상의 측면 이미지, 하나 이상의 단색 화면 이미지)과 딥러닝 평가 모델들을 기초로 전자 기기에 대한 외관 상태 평가를 수행할 수 있다. 도 1a에 도시된 예에서, 전자 기기 가치 평가 장치는 서버에 포함될 수 있다. 도 1a에 도시된 예에 서, 서버는 무인 매입 장치로부터 전자 기기를 촬영하여 획득한 이미지들을 수신할 수 있고, 수신된 이미지들을 전자 기기 가치 평가 장치로 전달할 수 있다. 앞서 설명한 것과 같이, 전자 기기 내의 제1 어 플리케이션은 전자 기기의 내부 상태 평가를 수행할 수 있고, 무인 매입 장치를 통해 서버에 전자 기 기의 내부 상태 평가의 결과를 전송할 수 있다. 다른 예로, 제1 어플리케이션은 전자 기기가 서버와 연결 되도록 할 수 있고, 전자 기기를 통해 서버에 전자 기기의 내부 상태 평가의 결과를 전송할 수 있다. 전 자 기기 가치 평가 장치는 전자 기기의 외관 상태 평가의 결과와 전자 기기의 내부 상태 평가의 결과(예: 제1 어플리케이션이 전자 기기의 내부 상태 평가를 수행한 결과)를 기초로 전자 기기의 가치(예: 가격)를 결정할 수 있다. 전자 기기 가치 평가 장치는 무인 매입 장치에 전자 기기의 가치를 전송할 수 있고, 무 인 매입 장치는 디스플레이에 전자 기기의 가치를 표시함으로써 사용자에게 전자 기기의 가치를 전달할 수 있다. 사용자는 전자 기기의 가치(예: 가격)를 받아들여 전자 기기를 판매할 것임을 무인 매입 장치에 전 달할 수 있고, 무인 매입 장치는 사용자의 전자 기기 판매 결정이 있으면 촬영 박스 내에 안치된 전자 기 기를 회수 박스(또는 보관 박스)로 이동시킬 수 있다. 실시 예에 따라, 회수 박스는 무인 매입 장치 내부 또는 외부에 위치할 수 있다. 도 1b에 도시된 예에서, 전자 기기 가치 평가 장치는 무인 매입 장치에 포함될 수 있다. 일 실시 예 에 있어서, 무인 매입 장치의 시스템 제어부가 전자 기기 가치 평가 장치의 동작을 수행할 수 있다. 이와 달리, 전자 기기 가치 평가 장치는 무인 매입 장치의 시스템 제어부와 별개로 동작할 수 있다. 도 1b에 도시된 예에서, 전자 기기 가치 평가 장치는 촬영 박스 내의 카메라들로부터 전자 기기를 촬영하 여 획득된 이미지들을 수신할 수 있다. 전자 기기 가치 평가 장치는 제1 어플리케이션으로부터 전자 기기 의 내부 상태 평가의 결과를 수신할 수 있다. 전자 기기 가치 평가 장치는 전자 기기의 외관 상태 평가의 결과와 전자 기기의 내부 상태 평가의 결과를 기초로 전자 기기의 가치(예: 가격)를 결정할 수 있다. 전자 기 기 가치 평가 장치는 디스플레이에 전자 기기의 가치를 표시함으로써 사용자에게 전자 기기의 가치를 전달 할 수 있다. 사용자는 전자 기기의 가치(예: 가격)를 받아들여 전자 기기를 판매할 것임을 무인 매입 장치 에 전달할 수 있고, 무인 매입 장치는 사용자의 전자 기기 판매 결정이 있으면 촬영 박스 내에 안치 된 전자 기기를 회수 박스(또는 보관 박스)로 이동시킬 수 있다. 일 실시 예에 따르면, 무인 매입 장치 내의 촬영 박스와 동일한 환경에서 획득된 학습 이미지를 기초로 딥 러닝 모델들을 트레이닝해야 전자 기기의 외관 평가 결과의 정확도가 향상될 수 있다. 후술하겠지만, 트레이닝 이 완료된 딥러닝 모델들이 딥러닝 평가 모델들로서 전자 기기 가치 평가 장치에 탑재될 수 있다. 촬영 박스의 구조 및 운영 방법 중 중요한 사항이 몇 가지가 있다. 첫째, 딥러닝 모델의 트레이닝을 위해 사용되는 학습 데이터가 확보되기 위해선 촬영 대상(예: 전자 기기)과 무 관하게 촬영 변동성이 없거나 줄어들어야 한다. 촬영 박스는 다양한 전자 기기를 촬영할 때 마다 다양한 전자 기기를 정해진 위치에 정렬하고 다양한 전자 기기를 동일한 각도로 촬영이 가능하도록 하는 촬영 환경을 제공해 야 한다. 둘째, 다양한 전자 기기의 화면이 제어될 경우 동일한 환경이 제공되어야 한다. 촬영 박스(또는 시스템 제어부)는 전자 기기에 설치된 제1 어플리케이션을 통해 전자 기기에 단색 화면이 표시 되도록 할 수 있다. 이 때, 전자 기기의 종류, 제조사 등에 따라 전자 기기의 단색 화면의 밝기 및/또는 색감 이 다를 수 있다. 예를 들어, 전자 기기 A의 흰색 화면은 블루(blue)의 색감을 가질 수 있고, 전자 기기 B의 흰색 화면은 레드(red)의 색감을 가질 수 있다. 촬영 박스(또는 시스템 제어부)는 제1 어플리케이션을 통해 다 양한 전자 기기가 동일한 밝기와 색감을 갖는 흰색 화면을 표시하도록 할 수 있다. 셋째, 촬영 박스의 크기와 무관하게 간접 조명 환경이 제공되어야 한다. 간접 조명은 전자 기기의 외관에 존재하는 미세 결함 또는 미세 스크래치를 보다 잘 검출되게 끔 할 수 있다. 일정 크기의 촬영 박스에서 간접 조명을 제공하는 것이 쉽지 않을 수 있다. 아래에서 설명하겠지만, 촬영 박스 는 라인 타입의 구조물과 광원을 통해 라인 형태의 간접 조명을 제공할 수 있다. 도 2는 일 실시 예에 따른 무인 매입 장치를 설명하는 블록도이다. 도 3은 일 실시 예에 따른 촬영 박스를 설 명하는 블록도이다. 도 2를 참조하면, 일 실시 예에 따른 무인 매입 장치는 촬영 박스, 시스템 제어부, 및 디스플레 이를 포함할 수 있다. 도 3을 참조하면, 일 실시 예에 따른 촬영 박스는 투입부, 안착부, 정렬부, 앱(app) 연동부, 촬영부, 및 제어부를 포함할 수 있다. 일 실시 예에 있어서, 도 2의 시스템 제어부와 도 3의 제어부는 마스터-슬레이브 관계에 있을 수 있 다. 시스템 제어부가 마스터에 해당할 수 있고 제어부가 슬레이브에 해당할 수 있다. 일 실시 예에 있어서, 촬영 박스에서 제어부는 생략될 수 있고, 시스템 제어부가 제어부의 동작을 수행할 수 있다.일 실시 예에 있어서, 촬영 박스에서 앱 연동부는 생략될 수 있고, 제어부가 앱 연동부의 동작을 수행할 수 있다. 시스템 제어부는 무인 매입 장치의 전반적인 동작을 제어할 수 있다. 시스템 제어부는 전자 기기 판매에 대한 가이드 라인 및/또는 주의 사항을 디스플레이에 표시할 수 있다. 시스템 제어부는 사용자로부터 다양한 정보(예: 사용자가 판매할 전자 기기의 OS(operating system) 정보 등)를 입력받기 위한 사용자 인터페이스를 디스플레이에 표시할 수 있다. 판매 준비 과정에서, 전자 기기에 설치된 제1 어플리케이션은 전자 기기의 디스플레이에 일련 번호를 표시할 수 있다. 사용자는 일련 번호를 디스플레이에 입력할 수 있다. 시스템 제어부는 디스플레이를 통 해 입력된 일련 번호를 검증하거나 서버에 검증을 요청할 수 있다. 시스템 제어부는 입력된 일련 번 호가 검증되면 도어(door)를 오픈할 수 있다. 도어가 오픈되면 촬영 박스의 투입부(또는 투입구)와 촬영 박스의 내부 공간이 드러날 수 있다. 사용자는 전자 기기를 촬영 박스 내의 안착부에 안착시킬 수 있다. 실시 예에 따라, 촬영 박스(21 0)는 전자 기기와 연결될 수 있는 유선 케이블을 포함할 수 있다. 사용자는 유선 케이블과 전자 기기를 연결시 킬 수 있으며, 유선 케이블과 연결된 전자 기기를 안착부에 안착시킬 수 있다. 정렬부는 안착된 전자 기기를 정해진 위치에 정렬시킬 수 있다. 전자 기기가 정해진 위치에 정렬되지 않 는 경우 촬영부는 전자 기기의 외관을 제대로 촬영하지 못할 수 있다. 전자 기기가 정해진 위치에 정렬되 지 않는 경우 촬영부에 의해 획득된 이미지의 초점은 맞지 않을 수 있다(out of focus). 일 실시 예에 있어서, 정렬부는 이동 가능한 이동바를 포함할 수 있다. 제어부는 안착된 전자 기기 가 정해진 위치로 이동하도록 이동바를 제어할 수 있고, 안착된 전자 기기가 정해진 위치로 이동한 경우 이동바 를 복귀시킬 수 있다. 앱 연동부는 전자 기기에 설치된 어플리케이션(예: 상술한 제1 어플리케이션)과 연동하여 전자 기기에 단 색 화면(예: 흰색 화면, 검은색 화면 등)이 표시되도록 할 수 있다. 앱 연동부는 전자 기기에 설치된 제1 어플리케이션으로부터 전자 기기의 내부 상태에 대한 평가 결과를 수 신할 수 있다. 앱 연동부는 제어부를 통해 시스템 제어부에 전자 기기의 내부 상태에 대한 평 가 결과를 전달하거나 직접 시스템 제어부에 전자 기기의 내부 상태에 대한 평가 결과를 전달할 수 있다. 촬영부는 정해진 위치에 정렬된 전자 기기를 촬영할 수 있다. 촬영부는 정렬된 전자 기기의 전면을 촬영하는 제1 카메라, 정렬된 전자 기기의 후면을 촬영하는 제2 카메라, 및 정렬된 전자 기기의 측면들(또는 코 너들)을 촬영하는 복수의 제3 카메라들, 및 조명을 제공하는 복수의 광원들을 포함할 수 있다. 제어부는 투입부, 정렬부, 앱 연동부, 및 촬영부 중 적어도 하나를 제어할 수 있다. 제어부는 안착된 전자 기기가 정해진 위치에 정렬한 경우 정렬된 전자 기기의 외관이 촬영되도록 촬영부 를 제어할 수 있다. 제어부는 정렬된 전자 기기의 화면 검사를 위해 정렬된 전자 기기에 단색 화면이 표시되도록 앱 연동부 를 제어할 수 있고, 전자 기기의 단색 화면이 촬영되도록 촬영부를 제어할 수 있다. 시스템 제어부는 촬영 박스로부터 전자 기기를 촬영하여 획득된 이미지들(예: 하나 이상의 전면 이미 지, 하나 이상의 후면 이미지, 하나 이상의 측면(또는 코너) 이미지, 하나 이상의 화면 이미지)를 수신할 수 있 다. 시스템 제어부는 수신된 이미지들과 전자 기기의 내부 상태의 평가 결과를 서버에 전송할 수 있다. 서버는 수신된 이미지들 및 전자 기기의 내부 상태의 평가 결과를 통해 전자 기기의 가치를 결정할 수 있 다. 일례로, 서버는 수신된 이미지들과 복수의 딥러닝 평가 모델들을 통해 전자 기기의 외관 상태를 평가 할 수 있고, 전자 기기의 외관 상태의 평가 결과와 내부 상태의 평가 결과를 이용하여 전자 기기의 가치를 결정 할 수 있다. 서버는 결정된 가치를 무인 매입 장치(또는 시스템 제어부)로 전송할 수 있다.디스플레이는 수신된 가치를 표시할 수 있다. 일 실시 예에 있어서, 시스템 제어부, 앱 연동부, 및 제어부는 하나의 프로세서에 의해 구현될 수 있다. 이에 제한되는 것은 아니고, 시스템 제어부, 앱 연동부, 및 제어부 각각은 별개의 프 로세서에 의해 구현될 수 있다. 또는, 시스템 제어부는 하나 이상의 프로세서에 의해 구현될 수 있고 앱 연동부 및 제어부는 하나 이상의 프로세서에 의해 구현될 수 있다. 도 4 내지 도 5는 일 실시 예에 따른 촬영 박스의 안착부와 정렬부를 설명하는 도면이다. 도 4를 참조하면, 제1 카메라, 전자 기기, 및 플레이트가 도시된다. 무인 매입 장치의 도 어가 오픈되면 사용자는 투입부를 통해 촬영 박스의 내부로 전자 기기를 집어넣을 수 있고, 안착부 에 전자 기기를 안착시킬 수 있다. 이 때, 사용자는 전자 기기와 유선 케이블을 연결시킨 채로 안착부에 전자 기기를 안착시킬 수 있다. 또는, 사용자가 전자 기기를 안착부에 안착시키는 경 우, 제어부(또는 시스템 제어부)는 전자 기기의 안착을 감지하여 전자 기기와 무선 통신 링크(예: 와이파이, 블루투스 링크 등)를 형성할 수 있다. 정렬부는 촬영 박스 내에 전자 기기가 안착되는 경우, 전자 기기가 정해진 위치에 정렬시 킬 수 있다. 안착부는 플레이트를 포함할 수 있고, 정렬부는 안착된 전자 기기의 센터가 플레이트의 센터에 위치하도록 안착된 전자 기기를 이동시킬 수 있다. 도 5에 도시된 예에서, 정렬부는 이동바를 포함할 수 있다. 전자 기기가 안착되면, 제어부는 안착된 전자 기기가 정해진 위치(예: 플레이트 상의 센터 위치)로 이동하도록 이동바를 제어할 수 있다. 이동바가 이동함으로써 전자 기기는 플레이트 상의 센터 위치로 이동할 수 있다. 실시 예에 따라, 제어부는 안착된 전자 기기의 크기를 알 수 있다. 예를 들어, 제어부는 안착된 전자 기기의 모델명을 알 수 있고, 모델명을 통해 안착된 전 자 기기의 크기를 알 수 있다. 제어부는 안착된 전자 기기의 크기를 이용하여 안착된 전자 기 기가 정해진 위치로 이동해야 하는 거리를 계산할 수 있다. 제어부는 이동바가 계산된 거리만 큼 이동하도록 이동바를 제어할 수 있다. 제어부는 전자 기기가 플레이트 상의 정해진 위치에 있으면(다시 말해, 전자 기기가 정렬 되면), 이동바를 원위치로 복귀시킬 수 있고, 촬영부가 전자 기기를 촬영하도록 촬영부를 제어할 수 있다. 도 4에 도시된 예에서, 제1 카메라가 전자 기기의 전면을 촬영할 수 있고, 전자 기 기에 단색 화면이 표시된 경우 전자 기기의 단색 화면을 촬영할 수 있다. 도 4에 도시되지 않았으나, 플레이트는 투명할 수 있고, 제2 카메라가 전자 기기의 후면을 촬영할 수 있다. 복수의 제3 카메라들 각각은 전자 기기의 측면들(또는 코너들) 각각을 촬영할 수 있다. 도 6은 일 실시 예에 따른 촬영 박스의 촬영부를 설명하는 도면이다. 도 6을 참조하면, 촬영부는 복수의 카메라들(610-1 내지 610-n), 복수의 광원들(620-1 내지 620-m), 카메 라 제어부, 조명 제어부, 및 촬영 제어부를 포함할 수 있다. 일 실시 예에 따르면, 촬영부에서 카메라 제어부와 조명 제어부가 생략될 수 있고, 촬영 제어부 가 카메라 제어부와 조명 제어부 각각의 동작을 수행할 수 있다. 일 실시 예에 따르면, 촬영부에서 카메라 제어부, 조명 제어부, 및 촬영 제어부는 생략될 수 있고, 제어부(또는 시스템 제어부)가 카메라 제어부, 조명 제어부, 및 촬영 제어부 각각의 동작을 수행할 수 있다. 촬영 제어부는 제어 신호를 카메라 제어부와 조명 제어부 각각에 전달할 수 있다. 카메라 제어부는 제어 신호를 카메라 1(또는 제1 카메라)(610-1)에 전달하여 카메라 1(610-1)이 전자 기기 의 전면을 촬영하도록 할 수 있다. 조명 제어부는 카메라 1(610-1)과 대응되는 광원 1(620-1)에 파워 온 (power on) 신호를 전달하여 광원 1(620-1)이 턴 온되도록 할 수 있다. 턴 온된 광원 1(620-1)은 직접 조명 또 는 간접 조명을 수행할 수 있다. 앞서, 하나의 광원 1(620-1)이 카메라 1(610-1)과 대응되는 것으로 설명하였으나 이는 예시적인 사항일 뿐, 둘 이상의 광원들이 카메라 1(610-1)과 대응될 수 있다. 카메라 1(610-1)에 대 응되는 복수의 광원들이 턴 온되어 카메라 1(610-1)이 전자 기기의 전면을 촬영하기 위한 조명이 제공될 수 있 다. 카메라 제어부는 카메라 1(610-1)의 촬영 데이터(예: 하나 이상의 전면 이미지)를 카메라 1(610-1)로 부터 수신할 수 있고, 카메라 1(610-1)의 촬영 데이터를 제어부(또는 시스템 제어부)로 전달할 수 있 다. 카메라 제어부는 제어 신호를 카메라 2(또는 제2 카메라)(610-2)에 전달하여 카메라 2(610-2)가 전자 기기 의 후면을 촬영하도록 할 수 있다. 조명 제어부는 카메라 2(610-2)와 대응되는 광원 2(620-2)에 파워 온 신호를 전달하여 광원 2(620-2)가 턴 온되도록 할 수 있다. 턴 온된 광원 2(620-2)는 직접 조명 또는 간접 조 명을 수행할 수 있다. 앞서, 하나의 광원 2(620-2)이 카메라 2(610-2)와 대응되는 것으로 설명하였으나 이는 예시적인 사항일 뿐, 둘 이상의 광원들이 카메라 2(610-2)와 대응될 수 있다. 카메라 2(610-1)에 대응되는 광 원들이 턴 온되어, 카메라 2(610-1)가 전자 기기의 후면을 촬영하기 위한 조명이 제공될 수 있다. 카메라 제어 부는 카메라 2(610-2)의 촬영 데이터(예: 하나 이상의 후면 이미지)를 카메라 2(610-2)로부터 수신할 수 있고, 카메라 2(610-2)의 촬영 데이터를 제어부(또는 시스템 제어부)로 전달할 수 있다. 카메라 제어부는 전자 기기의 측면들(또는 코너들)을 촬영하기 위한 카메라들(또는 제3 카메라들)에 전달 하여 카메라들 각각이 전자 기기의 측면들(또는 코너들) 각각을 촬영하도록 할 수 있다. 조명 제어부는 카메라들과 대응되는 광원들에 파워 온 신호를 전달하여 광원들이 턴 온되도록 할 수 있다. 턴 온된 광원들은 직접 조명 또는 간접 조명을 수행할 수 있다. 카메라 제어부는 전자 기기의 측면들(또는 코너들)을 촬영 한 카메라들로부터 촬영 데이터(예: 전자 기기의 측면(코너) 이미지들)를 수신할 수 있고, 촬영 데이터를 제어 부(또는 시스템 제어부)로 전달할 수 있다. 전자 기기의 전면, 후면, 및 측면들(또는 코너들)에 대한 촬영은 동시에 수행될 수 있다. 이에 제한되지 않고, 전자 기기의 전면, 후면, 및 측면들(또는 코너들)에 대한 촬영은 순차적으로 수행될 수 있다. 예를 들어, 촬영 제어부는 전자 기기의 전면을 촬영하고자 하는 경우, 제어 신호를 카메라 제어부와 조명 제어부(64 0)에 전달할 수 있다. 카메라 제어부는 제어 신호를 카메라 1(610-1)에 전달하여 카메라 1(610-1)이 전자 기기의 전면을 촬영하도록 할 수 있다. 조명 제어부는 카메라 1(610-1)과 대응되는 하나 이상의 광원에 파워 온 신호를 전달하여 카메라 1(610-1)과 대응되는 하나 이상의 광원이 턴 온되도록 할 수 있다. 전자 기기 의 전면이 촬영된 경우, 촬영 제어부는 전자 기기의 후면을 촬영하기 위한 제어 신호를 카메라 제어부 와 조명 제어부에 전달할 수 있다. 카메라 제어부는 제어 신호를 카메라 2(610-2)에 전달하여 카메라 2(610-2)가 전자 기기의 후면을 촬영하도록 할 수 있다. 조명 제어부는 카메라 2(610-2)와 대응되 는 하나 이상의 광원에 파워 온 신호를 전달하여 카메라 2(610-2)와 대응되는 하나 이상의 광원이 턴 온되도록 할 수 있다. 조명 제어부는 전자 기기의 전면을 촬영하기 위해 턴 온하였던 하나 이상의 광원에 파워 오 프 신호를 전달할 수 있다. 전자 기기의 후면이 촬영된 경우, 촬영 제어부는 전자 기기의 측면들(또는 코 너들)을 촬영하기 위한 제어 신호를 카메라 제어부와 조명 제어부에 전달할 수 있다. 카메라 제어부 는 제어 신호를 측면 촬영(또는 코너 촬영)을 위한 카메라들에 전달하여 카메라들이 전자 기기의 측면들 (또는 코너들)을 촬영하도록 할 수 있다. 조명 제어부는 측면 촬영을 위한 카메라들에 대응되는 광원들에 파워 온 신호를 전달하여 광원들이 턴 온되도록 할 수 있다. 조명 제어부는 전자 기기의 후면을 촬영하기 위해 턴 온하였던 하나 이상의 광원에 파워 오프 신호를 전달할 수 있다. 앱 연동부는 전자 기기에 설치된 제1 어플리케이션과 연동하여 전자 기기의 화면에 단색 화면이 표시되도 록 할 수 있다. 앱 연동부는 촬영 제어부에 화면 촬영 요청을 전달할 수 있다. 촬영 제어부는 앱 연동부의 화면 촬영 요청에 따라 제어 신호를 카메라 제어부 및 조명 제어부에 전달할 수 있 다. 카메라는 카메라 1(610-1)에 제어 신호를 전달하여 카메라 1(610-1)이 전자 기기의 단색 화면을 촬영 하도록 할 수 있다. 조명 제어부는 제어 신호를 카메라 1(610-1)과 대응되는 광원 1(620-1)에 전달하여 광원 1(620-1)이 턴 온되도록 할 수 있다. 카메라 제어부는 카메라 1(610-1)의 촬영 데이터(예: 하나 이 상의 화면 이미지)를 카메라 1(610-1)로부터 수신할 수 있고, 카메라 1(610-1)의 촬영 데이터를 제어부(또 는 시스템 제어부)로 전달할 수 있다. 도 7 내지 도 9는 일 실시 예에 따른 촬영 박스의 촬영부의 라인 조명을 설명하는 도면이다. 도 7을 참조하면, 촬영부는 광원들(710-1 및 710-2), 제1 카메라, 및 제1 구조물을 포함할 수 있다. 제1 구조물은 제1 광원(710-1)에 의해 출력된 빛이 전자 기기의 전면의 일 측에 제1 라인 조명으로 형성되도록 할 수 있고, 제2 광원(710-2)에 의해 출력된 빛이 전자 기기의 전면의 다른 일 측에 제 2 라인 조명으로 형성되도록 할 수 있다. 도 8에 도시된 이미지들(801, 803, 805)은 전자 기기의 전면 이미지의 예시이다. 이미지를 참조하면, 전 자 기기의 전면에는 라인 조명이 형성되어 있지 않아, 이미지에서 전자 기기의 전면에 결함이 있는지 여부 가 확인되는 것이 어려울 수 있다. 다시 말해, 서버는 이미지로부터 전자 기기의 전면에 결함이 있는지 여부를 판단하는 것이 어려울 수 있다. 이미지를 참조하면, 제2 광원(710-2)에 의해 출력된 빛이 제1 구 조물에 의해 전자 기기의 전면의 다른 일 측에 제2 라인 조명으로 형성될 수 있다. 이미지를 참조하면, 제1 광원(710-1)에 의해 출력된 빛이 제1 구조물에 의해 전자 기기의 전면의 일 측에 제1 라인 조명으로 형성될 수 있다. 제1 라인 조명과 제2 라인 조명에 의해 전자 기기의 전면에 결함이 없는 것이 보다 명확히 확인될 수 있다. 다시 말해, 서버는 이미지 및 이미지로부터 전자 기기의 전 면에 결함이 없는 것을 판단할 수 있다. 도 9에 도시된 이미지들(901, 903, 905)은 전자 기기의 전면 이미지의 예시이다. 이미지를 참조하면, 전 자 기기의 전면에는 라인 조명이 형성되어 있지 않아, 서버는 이미지로부터 전자 기기의 전면에 결함이 존 재하는지 여부를 판단하는 것이 어려울 수 있다. 이미지를 참조하면, 제2 광원(710-2)에 의해 출력된 빛 이 제1 구조물에 의해 전자 기기의 전면의 다른 일 측에 제2 라인 조명으로 형성될 수 있다. 이미지 와 비교할 때, 이미지에서 결함들(930-1 및 930-2)이 제2 라인 조명에 의해 관찰될 수 있다. 서버는 이미지로부터 전자 기기의 전면에 존재하는 결함들(930-1 및 930-2)을 검출할 수 있다. 이미지 를 참조하면, 제1 광원(710-1)에 의해 출력된 빛이 제1 구조물에 의해 전자 기기의 전면의 일 측에 제1 라인 조명으로 형성될 수 있다. 이미지와 비교할 때, 이미지에서 결함들(940-1 내지 940- 4)이 제1 라인 조명에 의해 관찰될 수 있다. 서버는 이미지로부터 전자 기기의 전면에 존재하는 결 함들(940-1 및 940-2)을 검출할 수 있다. 도 10은 일 실시 예에 따른 촬영 박스 내에서 전자 기기의 위치에 따른 카메라 초점 깊이를 설명하는 도면이다. 도 10을 참조하면, 카메라의 초점 깊이 포인트(a)가 도시된다. a ± a'의 범위(도 10의 focus limit) (이하, \"카메라 초점 범위\"라 지칭함) 이내에 전자 기기의 평가 영역(예: 측면 등)이 위치되어야 아웃 포 커싱되지 않은 이미지가 획득될 수 있다. 여기서, a'는 허용 오차를 나타낼 수 있다. 일례로, 도 10에 도시된 예에서, 전자 기기가 위치 x에 있으면, 전자 기기의 측면은 카메라 초점 범위 내에 위치할 수 있고, 이에 따라, 카메라가 전자 기기의 측면을 촬영한 이미지는 아웃 포커싱되지 않을 수 있다. 전자 기기가 위치 y에 있으면, 전자 기기의 측면은 카메라 초점 범위 내에 위치하지 않을 수 있고, 이에 따라, 카메라가 전자 기기의 측면을 촬영한 이미지는 아웃 포커싱될 수 있다. 아웃 포커싱되지 않은 이미지가 획득되지 않도록 하는 다양한 방식이 있을 수 있다. 일례로, 위에서 설명한 것 과 같이, 정렬부는 전자 기기가 정해진 위치에 있지 않으면 전자 기기를 정해진 위치로 이동 시킬 수 있다. 다른 예로, 전자 기기가 정해진 위치에 있지 않으면 촬영부는 카메라의 오토 포커싱 을 수행할 수 있다. 또 다른 예로, 카메라는 팬(pan) 동작 및/또는 틸트(tilt) 동작이 가능할 수 있고, 촬영부 는 카메라가 팬 동작 및/또는 틸트 동작을 수행하도록 할 수 있다. 또 다른 예로, 카메라는 촬영 박스 내에서 고정되어 있지 않을 수 있고, 촬영 박스 내에서 x축, y축, z축 방향으로 이동할 수 있다. 촬영부는 전자 기기의 안착 위치에 따라 카메라의 적절한 위치를 결정할 수 있고, 결정된 위치로 카 메라를 이동시킬 수 있다. 실시 예에 따라, 촬영 박스는 후술할 딥러닝 평가 모델의 학습 데이터를 확보할 수 있다. 학습 데이터를 확보하기 위한 촬영 박스 환경 구성에 있어 조명과 카메라의 위치 및 세팅 값(예: 조명 세기, 조명 파장, 촬영 각도 등)이 주요할 수 있고, 전자 기기가 물리적으로 안착되는 위치와 허용 오차(a')도 주요할 수 있다. 전자 기기가 허용 공간(또는 정해진 위치, 카메라 초점 범위)을 벗어난 경우, 촬영 박스는 전자 기 기를 허용 공간으로 이동시킬 수 있다. 또는, 촬영 박스는 전자 기기가 허용 공간을 벗어난 경우 카메라와 조명을 전자 기기의 안착 위치에 맞추어 조정을 해서 전자 기기의 외관을 촬영할 수 있다. 도 11은 일 실시 예에 따른 전자 기기의 상태바를 설명하는 도면이다. 도 11을 참조하면, 전자 기기의 화면은 제1 상태바와 제2 상태바를 포함할 수 있다. 제1 상 태바는 화면의 상단에 위치할 수 있고, 제2 상태바는 화면의 하단에 위치할 수 있다. 전자 기기가 흰색 화면을 표시하게 되면 제1 상태바의 아이콘의 잔상 및/또는 제2 상태바의 아이콘의 잔상이 존재할 수 있다. 이러한 잔상은 화면 결함에 해당할 수 있다. 전자 기기에 따라 전자 기기의 흰색 화면의 밝기 및 색감(color tone)이 달라질 수 있다. 일례로, 전자 기기의 디스플레이 모듈의 제조사에 따라 디폴트로 설정된 RGB값이 다를 수 있고, 이에 따라 전자 기기의 흰색 화면의 밝기 및/또는 색감이 달라질 수 있다. 앱 연동부(또는 제어부)는 전자 기기의 제조사, 전자 기기의 디스플레이 모듈의 종류, 및 디폴트로 설정된 RCB값 중 적어도 하나를 통해 전자 기기마다 일관된 밝기와 색감 을 갖는 흰색 화면을 표시하도록 할 수 있다. 도 12 내지 도 15는 일 실시 예에 따른 전자 기기 가치 평가 장치의 동작을 설명하는 도면이다. 도 12를 참조하면, 전자 기기 장치 평가 장치는 메모리, 외관 상태 평가 모듈, 및 가치 결정 모듈을 포함할 수 있다. 일 실시 예에 있어서, 외관 상태 평가 모듈 및 가치 결정 모듈은 하나의 프로세서로 구현될 수 있 다. 일 실시 예에 있어서, 외관 상태 평가 모듈 및 가치 결정 모듈 각각은 별개의 프로세서로 구현될 수 있다. 예를 들어, 제1 프로세서가 외관 상태 평가 모듈을 구현할 수 있고, 제2 프로세서가 가치 결정 모 듈을 구현할 수 있다. 메모리는 복수의 딥러닝 평가 모델들을 저장할 수 있다. 예를 들어, 메모리는 전자 기기의 제1 평 가 영역(예: 전면)의 결함을 검출하고 검출된 결함(또는 제1 평가 영역)의 등급을 결정하는 제1 딥러닝 평가 모 델, 전자 기기의 제2 평가 영역(예: 후면)의 결함을 검출하고 검출된 결함(또는 제2 평가 영역)의 등급을 결정 하는 제2 딥러닝 평가 모델, 전자 기기의 제3 평가 영역(예: 측면(또는 코너))의 결함을 검출하고 검출된 결함 (또는 제3 평가 영역)의 등급을 결정하는 제3 딥러닝 평가 모델, 및 전자 기기의 제4 평가 영역(예: 화면)의 결 함을 검출하고 검출된 결함(또는 제4 평가 영역)의 등급을 결정하는 제4 딥러닝 평가 모델을 포함할 수 있다. 아래 표 1은 평가 영역들(예: 화면, 전면, 측면(또는 코너), 후면) 각각의 결함의 종류와 등급의 예시를 보여준 다. 표 1 등급 화면 (디스플레이)전면 측면(또는 코 너)후면 모델 출력 D백화 3개 이상화면 줄감, 얼룩- - - 7 흑점 총알 파손 DL LCD급 잔상, LCD급 백화- - - 6 C - 파손,액정 들뜸(예: 강화유리 들뜸)- 파손, 후면 들뜸, 카메라 유리(또는 렌즈) 파손5 CL강잔상, 백화 2개 이하- - - 4 B 중잔상 전면 파손급 흠 집,전면 흠집- - 3 B+ - - 몸체 흠집- 2 A 깨끗 깨끗 깨끗 깨끗 1 위 표 1에서, 중잔상은, 예를 들어, 전자 기기가 흰색 화면을 표시하지만 사용자에게 화면의 특정 영역(예: 화 면 상단의 상태 표시 영역)이 흰색이 아닌 색으로 보여지고 특정 영역에 아이콘이 보여지는 현상을 나타낼 수 있다. 강잔상은, 예를 들어, 전자 기기가 흰색 화면을 표시하지만 사용자에게 화면 전체적으로 흰색이 아닌 다 른 색이 보여지는 현상을 나타낼 수 있다. LCD급 잔상은 강잔상보다 잔상의 정도가 심한 상태로, 예를 들어, 전자 기기가 흰색 화면을 표시하지만 사용자에게 화면 전체적으로 흰색이 아닌 다른 색이 보여지고 화면에 아이콘이 보여지는 현상을 나타낼 수 있다. 제1 내지 제4 딥러닝 평가 모델들 각각은 주어진 입력 이미지에 이미지 세그멘테이션(image segmentation)을 수 행할 수 있다. 도 13에 딥러닝 평가 모델들 각각의 기반이 되는 딥 뉴럴 네트워크(Neural Network)의 개략적인 구조가 도시된 다. 이하, 설명의 편의를 위하여 딥 뉴럴 네트워크의 구조를 예로 들어 설명하지만, 반드시 이에 한정되는 것 은 아니며 다양한 구조의 뉴럴 네트워크들이 딥러닝 평가 모델에 사용될 수 있다. 딥 뉴럴 네트워크는 뉴럴 네트워크를 구현하는 하나의 방식으로서, 복수의 레이어들(layers)을 포함한다. 딥 뉴럴 네트워크는, 예를 들어, 입력 데이터가 인가되는 입력 레이어(Input Layer), 트레이닝을 바탕으로 입력 데이터에 기반한 예측을 통해 도출된 결과 값을 출력하는 출력 레이어(Output Layer), 및 입력 레이 어와 출력 레이어 사이의 다중의 은닉 레이어(Hidden Layer)들(1320, 1330)을 포함할 수 있다. 딥 뉴럴 네트워크는 정보를 처리하기 위해 이용되는 알고리즘에 따라, 컨볼루션 신경망(Convolutional Neural Network), 및 리커런트 신경망(Recurrent Neural Network) 등으로 분류될 수 있다. 이하, 뉴럴 네트워크 분야 의 일반적인 관행에 따라 입력 레이어를 최하위 레이어, 출력 레이어를 최상위 레이어라고 부르며, 최상위 레이 어인 출력 레이어부터 최하위 레이어인 입력 레이어까지 순차적으로 레이어들의 순위를 지정하여 명명할 수 있 다. 도 13에서, 은닉 레이어 2는 은닉 레이어 1 및 입력 레이어보다 상위 레이어이고, 출력 레이어보다는 하위 레이어에 해당할 수 있다. 딥 뉴럴 네트워크에서 인접한 레이어들 사이에서는 상대적으로 상위인 레이어가, 상대적으로 하위인 레이어의 출력 값에 가중치를 곱하고 바이어스를 적용한 값을 인가 받아 소정의 연산 결과를 출력할 수 있다. 이 때, 출 력되는 연산 결과는 해당 레이어에 인접한 상위 레이어에 유사한 방식으로 인가될 수 있다. 뉴럴 네트워크를 트레이닝하는 방식을 예를 들어, 딥러닝(Deep Learning)이라 하며, 상술한 바와 같이 딥러닝에 는 컨볼루션 뉴럴 네트워크, 리커런트 뉴럴 네트워크와 같이 다양한 알고리즘이 이용될 수 있다. \"뉴럴 네트워크를 트레이닝한다\"는 것은 레이어들 간의 가중치(들) 및 바이어스(들)를 결정하고 갱신하는 것, 및/또는 인접한 레이어들 중 서로 다른 레이어에 속하는 복수의 뉴런들 간의 가중치(들) 및 바이어스(들)를 결 정하고 갱신하는 것을 모두 포괄하는 의미로 이해될 수 있다. 복수의 레이어들, 복수의 레이어들 간의 계층적 구조, 뉴런들 간의 가중치 및 바이어스를 모두 총칭하여 뉴럴 네트워크의 \"연결성(connectivity)\"이라 표현할 수 있다. 이에 따라, \"뉴럴 네트워크를 트레이닝한다\"는 것은 연결성을 구축하고 트레이닝하는 것으로도 이해될 수 있다. 뉴럴 네트워크에서 복수의 레이어들 각각은 복수의 노드들(nodes)을 포함할 수 있다. 노드는 뉴럴 네트워크의 뉴런(neuron)에 해당할 수 있다. 용어 \"뉴런\"은 \"노드\"라는 용어와 동일한 의미로 사용될 수 있다. 도 13의 딥 뉴럴 네트워크에서 어느 한 레이어에 포함된 복수의 노드들과 인접한 레이어에 포함된 복수의 노드 들의 조합들 간에 모두 연결 관계가 형성된 것을 볼 수 있다. 이와 같이 뉴럴 네트워크의 인접한 레이어들에 포함된 모든 노드들의 조합들이 모두 서로 연결된 것을 \"완전 연결(fully-connected)\"이라 부를 수 있다. 도 13에 도시된 은닉 레이어 2의 노드 3-1은 은닉 레이어 1의 모든 노드들, 즉, 노드 2-1 내지 노드 2-4 모두와 연결되어 각각의 노드들의 출력 값에 대하여 소정의 가중치를 곱한 값을 입력 받을 수 있다. 입력 레이어에 입력된 데이터가 복수의 은닉 레이어들(1230, 1330)을 거쳐 처리됨으로써 출력 레이어 를 통해 출력 값이 출력될 수 있다. 이때, 각 노드의 출력 값에 대해 곱해지는 가중치가 클수록 대응하 는 두 개의 노드들 간의 연결성이 강화됨을 의미하고, 가중치가 작을수록 두 개의 노드들 간의 연결성이 약화됨 을 의미할 수 있다. 가중치가 0인 경우, 두 노드들 간의 연결성이 없음을 의미할 수 있다. 도 12로 돌아와서, 외관 상태 평가 모듈은 전자 기기를 촬영하여 획득된 복수의 이미지들 및 딥러닝 평가 모델들을 기초로 전자 기기에 대한 외관 상태 평가를 수행할 수 있다. 예를 들어, 외관 상태 평가 모듈 은 딥러닝 평가 모델들을 통해 이미지들로부터 전자 기기의 제1 내지 제4 평가 영역 각각의 결함 상태를 예측한 마스크를 생성할 수 있다. 외관 상태 평가 모듈은 생성된 각 마스크를 기초로 제1 내지 제4 평가 영역 각각의 결함의 등급을 결정할 수 있다. 외관 상태 평가 모듈은 결정된 각 등급을 통해 전자 기기의 외관 상태에 대한 최종 등급을 결정할 수 있다. 도 14에 도시된 예에서, 제1 딥러닝 평가 모델은 전면 이미지를 입력 받을 수 있다. 제1 딥러닝 평가 모 델은 전면 이미지를 통해 전자 기기의 전면의 결함 상태(예: 결함의 위치, 결함의 종류, 및 결함의 정도 중 적어도 하나)를 예측한 제1 마스크를 생성할 수 있다. 여기서, 결함의 정도는 결함 유형과 관련될 수 있다. 예를 들어, 제1 딥러닝 평가 모델은 전면 이미지에 이미지 세그멘테이션을 수행하여 전면 이미지의 픽셀 들 각각을 제1 클래스들 중 어느 하나로 분류할 수 있고, 이러한 분류에 따라 제1 마스크를 생성할 수 있다. 아래 표 2는 제1 클래스들의 예시를 보여준다. 표 2 제1-1 클래스(예: 전면 흠집, 전면 파손급 흠집 등) 제1-2 클래스(예: 전면 파손, 액정 들뜸 등) 제1-3 클래스(예: 전자 기기가 아닌 부분) 제1-4 클래스(예: 전자 기기의 전면) 앞서 촬영 박스 내의 제1 카메라는 전자 기기의 전면 뿐 아니라 전면의 주변을 촬영할 수 있어, 전면 이미 지에는 전자 기기가 아닌 부분을 포함할 수 있다.제1 딥러닝 평가 모델은 전면 이미지의 일부 픽셀들을 제1-1클래스로 분류할 수 있고, 나머지 픽셀들 각각을 제1-2 클래스, 제1-3 클래스, 또는 제1-4 클래스로 분류 할 수 있다. 이러한 분류를 통해 제1 딥러닝 평가 모델은 제1 마스크를 생성할 수 있다. 제1 마스크를 시각적으로 표현한 이미지의 예시가 도 15에 도시된다. 도 15에 도시된 예에서, 검은색 영역들(1510-1, 1510-2, 1510-3, 1510-4)은 제1 딥러닝 평가 모델이 전 면 이미지의 일부 픽셀들을 제1-3 클래스로 분류한 결과(또는 제1 딥러닝 평가 모델이 전면 이미지의 일 부 픽셀들이 전자 기기에 해당하지 않는 것으로 예측한 결과)를 나타낼 수 있다. 영역은 제1 딥러닝 평 가 모델이 전면 이미지의 일부 픽셀들을 제1-2 클래스로 분류한 결과(또는 제1 딥러닝 평가 모델이 전면 이미지로부터 전자 기기의 전면에 파손이 있는 것으로 예측한 결과)를 나타낼 수 있다. 영역은 제1 딥러닝 평가 모델이 전면 이미지의 일부 픽셀들을 제1-1 클래스로 분류한 결과(또는 제1 딥러닝 평가 모 델이 전면 이미지로부터 전자 기기의 전면에 흠집이 있는 것으로 예측한 결과)를 나타낼 수 있다. 영역 은 제1 딥러닝 평가 모델이 전면 이미지의 일부 픽셀들을 제1-4 클래스로 분류한 결과(또는 제1 딥 러닝 평가 모델이 전면 이미지에서 전자 기기의 전면을 예측한 결과)를 나타낼 수 있다. 제1 딥러닝 평가 모델은 제1 마스크를 기초로 전면의 결함에 대한 등급을 결정할 수 있다. 예를 들어, 제1 딥러닝 평가 모델은 전면 이미지를 통해 전자 기기의 전면에 파손과 액정 들뜸 중 적어도 하나가 있 는 것으로 예측한 경우, 전자 기기의 전면의 결함의 등급을 C 등급(예: 위 표 1의 C 등급)으로 결정할 수 있다. 제1 딥러닝 평가 모델은 C 등급에 대응되는 점수 5를 출력할 수 있다. 제1 딥러닝 평가 모델은 전 면 이미지를 통해 전자 기기의 전면에 파손과 흠집이 있는 것으로 예측한 경우, 전자 기기의 전면의 결함의 등 급을 C 등급(예: 위 표 1의 C 등급)으로 결정할 수 있다. 제1 딥러닝 평가 모델은 C 등급에 대응되는 점 수 5를 출력할 수 있다. 제1 딥러닝 평가 모델은 전면 이미지를 통해 전자 기기의 전면에 흠집 및 전면 파손급 흠집 중 적어도 하나가 있는 것으로 예측한 경우, 전자 기기의 전면의 결함의 등급을 B 등급(예: 위 표 1의 B 등급)으로 결정할 수 있다. 제1 딥러닝 평가 모델은 B 등급에 대응되는 점수 3을 출력할 수 있다. 제1 딥러닝 평가 모델은 전면 이미지를 통해 전자 기기의 전면이 깨끗한 것(또는 전면에 결함이 없는 것)으로 예측한 경우, 전자 기기의 전면의 결함의 등급을 A 등급(예: 위 표 1의 A 등급)으로 결정할 수 있다. 제1 딥러닝 평가 모델은 A 등급에 대응되는 점수 1을 출력할 수 있다. 제2 딥러닝 평가 모델은 후면 이미지를 입력받을 수 있다. 제2 딥러닝 평가 모델은 후면 이미지를 통해 전자 기기의 후면의 결함 상태(예: 결함의 위치, 결함의 정류, 및 결함의 정도 중 적어도 하나)를 예측한 제2 마스크를 생성할 수 있다. 예를 들어, 제2 딥러닝 평가 모델은 후면 이미지에 이미지 세그멘테이션 을 수행할 수 있고, 후면 이미지의 픽셀들 각각을 제2 클래스들 중 어느 하나로 분류할 수 있으며, 이러한 분류 를 통해 제2 마스크를 생성할 수 있다. 아래 표 3은 제2 클래스들의 예시를 보여준다. 표 3 제2-1 클래스(예: 파손, 후면 들뜸, 카메라 유지(또는 렌즈) 파손 등) 제2-2 클래스(예: 전자 기기가 아닌 부분) 제2-3 클래스(예: 전자 기기의 후면)제2 딥러닝 평가 모델은 제2 마스크를 기초로 후면의 결함에 대한 등급을 결정할 수 있다. 예를 들어, 제2 딥러닝 평가 모델은 후면 이미지를 통해 전자 기기의 후면에 파손, 후면 들뜸, 및 카메라 렌즈 파손 중 적어도 하나가 있는 것으로 예측한 경우, 전자 기기의 후면의 결함의 등급을 C 등급(예: 위 표 1의 C 등급) 으로 결정할 수 있다. 제2 딥러닝 평가 모델은 C 등급에 대응되는 점수 5를 출력할 수 있다. 제2 딥러 닝 평가 모델은 후면 이미지를 통해 전자 기기의 후면이 깨끗한 것으로 예측한 경우, 전자 기기의 후면의 결함의 등급을 A 등급(예: 위 표 1의 A 등급)으로 결정할 수 있다. 제2 딥러닝 평가 모델은 A 등급에 대 응되는 점수 1을 출력할 수 있다. 제3 딥러닝 평가 모델은 측면 이미지들(또는 코너 이미지들)을 입력받 을 수 있다. 제3 딥러닝 평가 모델은 측면 이미지들(또는 코너 이미지들)을 통해 전자 기기의 측면들(또 는 코너들)의 결함 상태(예: 결함의 위치, 결함의 종류, 및 결함의 정도 중 적어도 하나)를 예측한 제3 마스크 를 생성할 수 있다. 예를 들어, 제3 딥러닝 평가 모델은 측면 이미지들(또는 코너 이미지들)에 이미지 세그멘테이션을 수행할 수 있고, 각 측면 이미지의 픽셀들 각각을 제3 클래스들 중 어느 하나로 분류할 수 있으 며, 이러한 분류를 통해 제3 마스크를 생성할 수 있다. 아래 표 4는 제3 클래스들의 예시를 보여준다. 표 4 제3-1 클래스(예: 흠집) 제3-2 클래스(예: 전자 기기가 아닌 부분) 제3-3 클래스(예: 전자 기기의 측면(또는 코너)) 제3 딥러닝 평가 모델은 제3 마스크를 기초로 측면들(또는 코너들)의 결함의 등급을 결정할 수 있다. 예 를 들어, 제3 딥러닝 평가 모델은 측면 이미지들(또는 코너 이미지들)을 통해 전자 기기의 제1 측면(또는 제1 코너) 에 흠집이 있는 것으로 예측한 경우, 전자 기기의 측면들(또는 코너들)의 결함에 대한 등급을 B+ 등 급(예: 위 표 1의 B+ 등급)으로 결정할 수 있다. 제3 딥러닝 평가 모델은 B+ 등급에 대응되는 점수 2를 출력할 수 있다. 제3 딥러닝 평가 모델은 측면 이미지들(또는 코너 이미지들)을 통해 전자 기기의 측면 들(또는 코너들)이 깨끗한 것으로 예측한 경우, 전자 기기의 측면들(또는 코너들)의 결함에 대한 등급을 A 등급 (예: 위 표 1의 A 등급)으로 결정할 수 있다. 제3 딥러닝 평가 모델은 A 등급에 대응되는 점수 1을 출력 할 수 있다. 제4 딥러닝 평가 모델은 전자 기기에 화면 이미지(예: 단색 화면 이미지)를 입력 받을 수 있다. 제4 딥러닝 평가 모델은 화면 이미지를 통해 전자 기기의 화면의 결함 상태(예: 결함의 위치, 결 함의 종류, 및 결함의 정도 중 적어도 하나)를 예측한 제4 마스크를 생성할 수 있다. 예를 들어, 제4 딥러닝 평가 모델은 화면 이미지에 이미지 세그멘테이션을 수행할 수 있고, 화면 이미지의 픽셀들 각각을 제4 클 래스들 중 어느 하나로 분류할 수 있으며, 이러한 분류를 통해 제4 마스크를 생성할 수 있다. 아래 표 5는 제4 클래스들의 예시를 보여준다. 표 5 제4-1 클래스(예: 백화 3개 이상, 화면 줄감, 얼룩, 흑점, 총알 파손 등) 제4-2 클래스(예: LCD급 잔상, LCD급 백화 등) 제4-3 클래스(예: 강잔상, 백화 2개 이하 등) 제4-4 클래스(예: 중잔상 등) 제4-5 클래스(예: 전자 기기가 아닌 부분) 제4-6 클래스(예: 전자 기기의 화면) 제4 딥러닝 평가 모델은 제4 마스크를 기초로 전자 기기의 화면의 결함에 대한 등급을 결정할 수 있다. 예를 들어, 제4 딥러닝 평가 모델은 화면 이미지를 통해 전자 기기의 화면에 백화 3개 이상, 화면 줄감, 흑점, 총알 파손 중 적어도 하나가 있는 것으로 예측한 경우, 전자 기기의 화면의 결함의 등급을 D 등급(예: 위 표 1의 D 등급)으로 결정할 수 있다. 제4 딥러닝 평가 모델은 D 등급에 대응되는 점수 7을 출력할 수 있 다. 제4 딥러닝 평가 모델은 화면 이미지를 통해 전자 기기의 화면에 LCD급 잔상 및 LCD급 백화 중 적어 도 하나가 있는 것으로 예측한 경우, 전자 기기의 화면의 결함의 등급을 DL 등급(예: 위 표 1의 DL 등급)으로 결정할 수 있다. 제4 딥러닝 평가 모델은 DL 등급에 대응되는 점수 6을 출력할 수 있다. 제4 딥러닝 평 가 모델은 화면 이미지를 통해 전자 기기의 화면에 강잔상 및 백화 2개 이하 중 적어도 하나가 있는 것으 로 예측한 경우, 전자 기기의 화면의 결함에 대한 등급을 CL 등급(예: 위 표 1의 CL 등급)으로 결정할 수 있다. 제4 딥러닝 평가 모델은 CL 등급에 대응되는 점수 4를 출력할 수 있다. 제4 딥러닝 평가 모델은화면 이미지를 통해 전자 기기의 화면에 중잔상이 있는 것으로 예측한 경우, 전자 기기의 화면의 결함의 등급을 B 등급(예: 위 표 1의 B 등급)으로 결정할 수 있다. 제4 딥러닝 평가 모델은 B 등급에 대응되는 점수 3 을 출력할 수 있다. 제4 딥러닝 평가 모델은 화면 이미지를 통해 전자 기기의 화면이 깨끗한 것으로 예 측한 경우, 전자 기기의 화면의 결함의 등급을 A 등급(예: 위 표 1의 A 등급)으로 결정할 수 있다. 제4 딥러닝 평가 모델은 A 등급에 대응되는 점수 1을 출력할 수 있다. 도 12로 돌아와서, 가치 결정 모듈은 전자 기기의 외관 상태 평가의 결과 및/또는 전자 기기의 내부 상태 평가의 결과를 기초로 전자 기기의 가치를 결정할 수 있다. 일 실시 예에 있어서, 가치 결정 모듈은 제1 내지 제4 딥러닝 평가 모델(1410 내지 1440) 각각에 의해 결 정된 등급 중 최소 등급을 전자 기기의 외관 상태에 대한 최종 등급으로 결정할 수 있다. 등급 A가 가장 높고 등급 B+는 등급 A보다 낮고 등급 B보다는 높을 수 있다. 등급 CL은 등급 B보다 낮고 등급 C보다 높을 수 있다. 등급 D가 가장 낮을 수 있다. 일례로, 제1 딥러닝 평가 모델에 의해 결정된 등급이 C 등급이고, 제2 딥 러닝 평가 모델에 의해 결정된 등급이 B+ 등급이며, 제3 딥러닝 평가 모델에 의해 결정된 등급이 C 등급이고, 제4 딥러닝 평가 모델에 의해 결정된 등급이 CL 등급일 수 있다. 제1 내지 제4 딥러닝 평가 모 델(1410 내지 1440) 각각에 의해 결정된 등급 중 제1 딥러닝 평가 모델에 의해 결정된 C 등급이 최소 등 급일 수 있어, 가치 결정 모듈은 전자 기기의 외관 상태에 대한 최종 등급을 C 등급으로 결정할 수 있다. 실시 예에 따라, 등급이 낮을수록 제1 내지 제4 딥러닝 평가 모델(1410 내지 1440) 각각에 의해 출력되는 점수 는 높을 수 있다. 가치 결정 모듈은 제1 내지 제4 딥러닝 평가 모델(1410 내지 1440) 각각에 의해 출력 된 점수 중 최대 점수를 전자 기기의 외관 평가에 대한 최종 점수로 결정할 수 있다. 일 실시 예에 있어서, 가치 결정 모듈은 제1 내지 제4 딥러닝 평가 모델(1410 내지 1440) 각각에 의해 결 정된 등급(또는 점수)에 가중치를 적용할 수 있고, 각 가중치가 적용된 등급(또는 점수)을 이용하여 전자 기기 의 외관 상태에 대한 최종 등급(또는 최종 점수)을 결정할 수 있다. 일례로, 가치 결정 모듈은 제1 딥러 닝 평가 모델에 의해 결정된 등급(또는 점수)에 제1 가중치를 적용할 수 있고, 제2 딥러닝 평가 모델 에 의해 결정된 등급(또는 점수)에 제2 가중치를 적용할 수 있으며, 제3 딥러닝 평가 모델에 의해 결정된 등급(또는 점수)에 제3 가중치를 적용할 수 있고, 제4 딥러닝 평가 모델에 의해 결정된 등급에 제 4 가중치를 적용할 수 있다. 여기서, 제1 가중치 내지 제4 가중치 각각은 0보다 크고 1보다 작을 수 있다. 가 치 결정 모듈은 제1 내지 제4 가중치 각각이 적용된 등급(또는 점수)을 합산하여 전자 기기의 외관 상태 에 대한 최종 등급(또는 최종 점수)을 결정할 수 있다. 가치 결정 모듈은 전자 기기의 외관 상태 평가의 결과(예: 전자 기기의 외관 상태에 대한 최종 등급(또는 최종 점수))를 기초로 제1 금액을 결정할 수 있고, 전자 기기의 내부 상태 평가의 결과를 기초로 제2 금액을 결 정할 수 있다. 가치 결정 모듈은 전자 기기의 기준 가격(예: 전자 기기와 동일 종류의 전자 기기의 가장 높은 중고 가격)에서 제1 금액과 제2 금액을 차감하여 전자 기기의 가격을 산출할 수 있다. 일례로, 가치 결정 모듈은 중고 시세 데이터베이스와 연동하여 전자 기기의 기준 가격을 획득할 수 있다. 가치 결정 모듈 은 외관 상태의 등급과 금액이 서로 맵핑된 제1 테이블로부터, 전자 기기의 외관 상태에 대한 최종 등급 과 맵핑된 제1 금액을 획득할 수 있다. 가치 결정 모듈은 내부 상태의 등급과 금액이 서로 맵핑된 제2 테이블로부터, 전자 기기의 내부 상태 평가의 결과와 맵핑된 제2 금액을 획득할 수 있다. 가치 결정 모듈 은 기준 금액에서 제1 금액 및 제2 금액을 차감하여 전자 기기의 가격을 산출할 수 있다. 가치 결정 모듈은, 도 1a에 도시된 예의 경우, 무인 매입 장치로 전자 기기의 가치(예: 가격)를 전 송할 수 있다. 무인 매입 장치는 디스플레이를 통해 전자 기기의 가치(예: 가격)를 사용자에게 보여 줄 수 있다. 가치 결정 모듈은, 도 1b에 도시된 예의 경우, 무인 매입 장치의 디스플레이에 전자 기기의 가 치(예: 가격)를 표시할 수 있다. 일 실시 예에 있어서, 전자 기기 가치 평가 장치는 전처리 모듈을 포함할 수 있다. 전처리 모듈은 이미지 들(예: 전면 이미지, 후면 이미지, 측면 이미지들, 화면 이미지) 각각에 결함으로 오인될 하나 이상의 객체가 포함되어 있는지 여부를 판단할 수 있다. 여기서, 객체는 전자 기기의 화면 상의 플로팅 아이콘에 대응되는 객 체, 전자 기기에 부착된 스티커에 대응되는 객체, 및 전자 기기에 묻어있는 이물질에 대응되는 객체 중 적어도 하나를 포함할 수 있다. 플로팅 아이콘에 대응되는 객체는 전자 기기의 화면 상의 플로팅 아이콘이 촬영됨으로 써 이미지에 포함된 객체를 나타낼 수 있다. 전자 기기에 부착된 스티커에 대응되는 객체는 전자 기기에 부착 된 스티커가 촬영됨으로써 이미지에 포함된 객체를 나타낼 수 있다. 전자 기기에 묻어있는 이물질에 대응되는객체는 전자 기기에 묻어있는 이물질이 촬영됨으로써 이미지에 포함된 객체를 나타낼 수 있다. 플로팅 아이콘 은, 예를 들어, 보조 터치(assistive touch)의 플로팅 아이콘, 특정 태스크를 트리거링 하기 위한 플로팅 아이 콘 등을 포함할 수 있으나 이에 제한되지 않는다. 전처리 모듈은 결함으로 오인될 객체가 포함된 이미지가 있는 경우, 객체에 대한 처리를 수행할 수 있다. 일 례로, 전처리 모듈은 객체에 마스킹(masking) 처리를 수행할 수 있으나 이에 제한되지 않는다. 외관 상태 평가 모듈은 객체가 처리된 이미지, 객체가 포함되지 않은 나머지 이미지들, 및 제1 내지 제4 딥러닝 평가 모 델들(1410 내지 1440)을 기초로 외관 상태 평가를 수행할 수 있다. 외관 상태 평가 모듈은 제1 내지 제4 딥러닝 평가 모델들(1410 내지 1440)을 통해 객체가 처리된 이미지 및 객체가 포함되지 않은 나머지 이미지들로 부터 전자 기기의 평가 영역들 각각의 결함 상태를 예측한 마스크를 생성할 수 있고, 생성된 각 마스크를 기초 로 평가 영역들 각각의 결함에 대한 등급을 결정할 수 있으며, 결정된 각 등급을 통해 전자 기기의 외관 상태에 대한 최종 등급을 결정할 수 있다. 전처리 모듈은 전자 기기를 촬영하여 획득된 이미지들 중에서 상술한 객체가 포함된 이미지가 없는 것으로 판단 할 수 있다. 이 경우, 위에서 설명한 것과 같이, 외관 상태 평가 모듈은 이미지들과 제1 내지 제4 딥러 닝 평가 모델들(1410 내지 1440)을 기초로 외관 상태 평가를 수행할 수 있다. 전처리 모듈은 전자 기기를 촬영하여 획득된 이미지들 중 제1 내지 제 4 딥러닝 평가 모델들(1410 내지 1440) 중 하나 이상이 분석하지 못할 정도의 이미지(이하, \"모델 분석 불가 이미지\"라 지칭함)가 있는지 여부를 판단 할 수 있다. 일례로, 전처리 모듈은 전자 기기를 촬영하여 획득된 이미지들 중 빛 반사가 일정 수준 이상 존재 하는 이미지, 카메라 초점이 맞지 않는 이미지 등을 모델 분석 불가 이미지로 결정할 수 있다. 전처리 모듈은 모델 분석 불가 이미지가 있는 경우, 운영자에게 전자 기기의 외관 상태 평가를 요청할 수 있다. 일 실시 예에 있어서, 전자 기기 가치 평가 장치는 바(bar) 타입의 전자 기기의 가치를 평가할 수 있다. 이 경우, 앞서 설명한 것과 같이, 전자 기기 가치 평가 장치(또는 외관 상태 평가 모듈)는 바 타입 의 전자 기기를 촬영하여 획득된 복수의 이미지들 및 제1 내지 제4 딥러닝 평가 모델들(1410~1440)을 기초로 바 타입의 전자 기기에 대한 외관 상태 평가를 수행할 수 있다. 전자 기기 가치 평가 장치는 형태가 변경 가능한 전자 기기(예: 폴더블, 롤러블 등)의 가치를 평가할 수 있다. 형태가 변경 가능한 전자 기기는 제1 형태(예: 언폴드(unfolded) 형태 또는 축소(contraction) 형태)를 가질 수 있고, 조작에 의해 제2 형태(예: 접힌(folded) 형태 또는 확장(expansion) 형태)로 변경될 수 있다. 일례로, 폴더블 전자 기기는 언폴드 형태에 있을 수 있고, 조작에 의해 형태가 접힌 형태로 변경될 수 있다. 롤러블 전자 기기는 축소 형태에 있을 수 있고, 조작에 의해 형태가 확장 형태로 변경될 수 있다. 축소 형태는 롤러블 디스플레이이가 기기 안으로 롤인(roll in)되는 상태를 나타낼 수 있고 확장 형태는 롤러블 디스플레이 가 기기로부터 롤아웃(roll out)되는 상태를 나타낼 수 있다. 예를 들어, 전자 기기 가치 평가 장치(또는 외관 상태 평가 모듈)는 언폴드 형태에 있는 폴더블 전 자 기기를 촬영하여 획득한 복수의 이미지들 및 제1 내지 제4 딥러닝 평가 모델들(1410~1440)을 기초로 언폴드 형태에 있는 폴더블 전자 기기의 각 평가 영역의 결함의 등급을 결정할 수 있다. 무인 매입 장치는 촬영 박스 내에 있는 폴더블 전자 기기를 언폴드 형태에서 접힌 형태로 변경할 수 있다. 또는 무인 매입 장치는 사용자에게 폴더블 전자 기기를 언폴드 형태에서 접힌 형태로 변경한 뒤 접힌 형태 에 있는 전자 기기를 무인 매입 장치에 재투입할 것을 요청할 수 있다. 폴더블 전자 기기가 언폴드 형태 에서 접힌 형태로 변경되면 접힌 부분이 측면을 형성할 수 있고, 폴더블 전자 기기의 서브 화면이 활성화될 수 있다. 무인 매입 장치는 촬영 박스 내의 복수의 제3 카메라들 중 하나 이상을 통해 폴더블 전자 기기의 접힌 부분에 해당하는 측면을 촬영함으로써 이미지(이하, 접힌 측면의 이미지)를 획득할 수 있다. 무인 매입 장치는 촬영 박스 내의 제1 카메라를 통해 폴더블 전자 기기의 서브 화면을 촬영함으로써 이미지(이하, 서 브 화면 이미지)를 획득할 수 있다. 전자 기기 가치 평가 장치(또는 외관 상태 평가 모듈)는 접힌 측면의 이미지와 제5 딥러닝 평가 모 델을 기초로 폴더블 전자 기기의 제5 평가 영역(예: 접힌 부분에 해당하는 측면)을 평가할 수 있다. 여기서, 제5 딥러닝 평가 모델은 폴더블 전자 기기의 제5 평가 영역의 결함을 검출하고 검출된 결함(또는 제5 평가 영역)의 등급을 결정하는 딥러닝 평가 모델일 수 있다. 일례로, 전자 기기 가치 평가 장치(또는 외관 상 태 평가 모듈)는 접힌 측면의 이미지를 제5 딥러닝 평가 모델에 입력할 수 있다. 제5 딥러닝 평가 모델 은 접힌 측면의 이미지를 통해 폴더블 전자 기기의 제5 평가 영역의 결함 상태(예: 결함의 위치, 결함의 종류,및 결함의 정도 중 적어도 하나)를 예측한 제5 마스크를 생성할 수 있다. 제5 딥러닝 평가 모델은 제5 마스크 를 기초로 폴더블 전자 기기의 제5 평가 영역의 결함에 대한 등급을 결정할 수 있다. 전자 기기 가치 평가 장치(또는 외관 상태 평가 모듈)는 서브 화면 이미지와 제6 딥러닝 평가 모델 을 기초로 폴더블 전자 기기의 제6 평가 영역(예: 서브 화면)을 평가할 수 있다. 여기서, 제6 딥러닝 평가 모 델은 폴더블 전자 기기의 제6 평가 영역의 결함을 검출하고 검출된 결함(또는 제6 평가 영역)의 등급을 결정하 는 딥러닝 평가 모델일 수 있다. 일례로, 전자 기기 가치 평가 장치(또는 외관 상태 평가 모듈)는 서브 화면 이미지를 제6 딥러닝 평가 모델에 입력할 수 있다. 제6 딥러닝 평가 모델은 서브 화면 이미지를 통 해 폴더블 전자 기기의 제6 평가 영역의 결함 상태(예: 결함의 위치, 결함의 종류, 및 결함의 정도 중 적어도 하나)를 예측한 제6 마스크를 생성할 수 있다. 제6 딥러닝 평가 모델은 제6 마스크를 기초로 폴더블 전자 기기 의 제6 평가 영역의 결함에 대한 등급을 결정할 수 있다. 실시 예에 따라, 전자 기기 가치 평가 장치(또 는 외관 상태 평가 모듈)는 서브 화면 이미지와 위에서 설명한 제4 딥러닝 평가 모델을 기초로 전 자 기기의 제6 평가 영역(예: 서브 화면)의 결함의 등급을 결정할 수 있다. 전자 기기 가치 평가 장치(또는 가치 결정 모듈)은 폴더블 전자 기기의 외관 상태 평가의 결과(예: 제1 내지 제6 딥러닝 평가 모델 각각에 의해 결정된 등급) 및/또는 폴더블 전자 기기의 내부 상태 평가의 결과 를 기초로 폴더블 전자 기기의 가치를 결정할 수 있다. 다른 예를 들어, 전자 기기 가치 평가 장치(또는 외관 상태 평가 모듈)는 축소 형태의 롤러블 전자 기기를 촬영하여 획득한 복수의 이미지들 및 제1 내지 제4 딥러닝 평가 모델들(1410~1440)을 기초로 축소 형태 의 롤러블 전자 기기의 각 평가 영역의 결함의 등급을 결정할 수 있다. 무인 매입 장치는 촬영 박스 내에 있는 롤러블 전자 기기를 축소 형태에서 확장 형태로 변경할 수 있다. 또는 무인 매입 장치는 사용자에게 롤러블 전자 기기를 축소 형태에서 확장 형태로 변경한 뒤 확장 형태에 있는 전자 기기를 무인 매입 장치에 재투입할 것을 요청할 수 있다. 롤러블 전자 기기가 축소 형태에서 확장 형태로 변경되면, 화면과 측면이 확장될 수 있다. 무인 매입 장치는 촬영 박스 내의 복수의 제3 카메 라들 중 하나 이상을 통해, 확장된 측면을 촬영함으로써 이미지(이하, 확장된 측면의 이미지)를 획득할 수 있다. 무인 매입 장치는 촬영 박스 내의 제1 카메라를 통해 전자 기기의 확장된 화면을 촬영함으로써 이 미지(이하, 확장된 화면의 이미지)를 획득할 수 있다. 전자 기기 가치 평가 장치(또는 외관 상태 평가 모듈)는 확장된 측면의 이미지와 제7 딥러닝 평가 모델을 기초로 롤러블 전자 기기의 제7 평가 영역(예: 확장된 측면)을 평가할 수 있다. 여기서, 제7 딥러닝 평 가 모델은 롤러블 전자 기기의 제7 평가 영역의 결함을 검출하고 검출된 결함(또는 제7 평가 영역)의 등급을 결 정하는 딥러닝 평가 모델일 수 있다. 일례로, 전자 기기 가치 평가 장치(또는 외관 상태 평가 모듈 )는 확장된 측면의 이미지를 제7 딥러닝 평가 모델에 입력할 수 있다. 제7 딥러닝 평가 모델은 확장된 측면의 이미지를 통해 롤러블 전자 기기의 제7 평가 영역의 결함 상태(예: 결함의 위치, 결함의 종류, 및 결함 의 정도 중 적어도 하나)를 예측한 제7 마스크를 생성할 수 있다. 제7 딥러닝 평가 모델은 제7 마스크를 기초 로 롤러블 전자 기기의 제7 평가 영역의 결함에 대한 등급을 결정할 수 있다. 실시 예에 따라, 전자 기기 가치 평가 장치(또는 외관 상태 평가 모듈)는 확장된 측면의 이미지와 제3 딥러닝 평가 모델을 기 초로 롤러블 전자 기기의 제7 평가 영역(예: 확장된 측면)을 평가할 수 있다. 전자 기기 가치 평가 장치(또는 외관 상태 평가 모듈)는 확장된 화면의 이미지와 제4 딥러닝 평가 모델을 기초로 롤러블 전자 기기의 제8 평가 영역(예: 확장된 화면)을 평가할 수 있다. 일례로, 전자 기 기 가치 평가 장치(또는 외관 상태 평가 모듈)는 확장된 화면의 이미지를 제4 딥러닝 평가 모델 에 입력할 수 있다. 위에서 설명한 것과 같이, 제4 딥러닝 평가 모델은 주어진 화면 이미지에서 화면의 결함 상태를 예측한 마스크를 생성하고 생성된 마스크를 기초로 화면의 결함의 등급을 결정하는 딥러닝 평가 모델일 수 있다. 제4 딥러닝 평가 모델은 확장된 화면의 이미지를 통해 롤러블 전자 기기의 제8평 가 영역의 결함 상태(예: 결함의 위치, 결함의 종류, 및 결함의 정도 중 적어도 하나)를 예측한 제8 마스크를 생성할 수 있다. 제4 딥러닝 평가 모델은 제8 마스크를 기초로 롤러블 전자 기기의 제8 평가 영역의 결 함에 대한 등급을 결정할 수 있다. 전자 기기 가치 평가 장치(또는 가치 결정 모듈)은 롤러블 전자 기기의 외관 상태 평가의 결과(예: 제1 내지 제4 딥러닝 평가 모델 및 제7 딥러닝 평가 모델 각각에 의해 결정된 등급) 및/또는 롤러블 전자 기기 의 내부 상태 평가의 결과를 기초로 롤러블 전자 기기의 가치를 결정할 수 있다.일 실시 예에 있어서, 무인 매입 장치는 사용자로부터 웨어러블 기기(예: 스마트 워치)를 투입받을 수 있 다. 전자 기기 가치 평가 장치는 웨어러블 기기의 외관(예: 전면, 후면, 측면, 화면)을 평가할 수 있는 딥러닝 평가 모델들을 저장할 수 있다. 전자 기기 가치 평가 장치는 웨어러블 기기를 촬영하여 획득한 이 미지들 및 딥러닝 평가 모델들을 기초로 웨어러블 기기에 대한 외관 상태 평가를 수행할 수 있다. 전자 기기 가치 평가 장치는 웨어러블 기기의 외관 상태 평가의 결과 및 웨어러블 기기의 내부 상태 평가의 결과를 기초로 웨어러블 기기의 가치를 결정할 수 있다. 도 16은 일 실시 예에 따른 딥러닝 모델을 트레이닝하는 컴퓨팅 장치의 구성을 설명하는 블록도이다. 도 16을 참조하면, 딥러닝 모델을 트레이닝하는 컴퓨팅 장치는 메모리 및 프로세서를 포함할 수 있다. 메모리는 하나 이상의 딥러닝 모델을 저장할 수 있다. 딥러닝 모델은 위에서 설명한 딥 뉴럴 네트워크에 기반할 수 있다. 딥러닝 모델은 주어진 입력 이미지에 이미지 세그멘테이션을 수행할 수 있다. 프로세서는 딥러닝 모델을 트레이닝할 수 있다. 프로세서는 결함에 대한 학습 이미지를 딥러닝 모델에 입력할 수 있고, 딥러닝 모델을 통해 학습 이미지 로부터 결함의 상태를 예측한 마스크를 생성할 수 있다. 학습 이미지는, 예를 들어, 촬영 박스가 결함이 있는 전자 기기를 촬영하여 획득된 이미지를 포함할 수 있다. 프로세서는 생성된 마스크와 결함에 대한 레이블 마스크(labeled mask) 사이의 유사도를 연산할 수 있다. 도 17a 내지 도 17c에 생성된 마스크와 레이블 마스크 각각의 일례가 도시된다. 도 9a에서 타겟 마스크는 레이 블 마스크를 나타낼 수 있고 예측 마스크는 딥러닝 모델에 의해 생성된 마스크를 나타낼 수 있다. 프로세서는 연산된 유사도가 임계값 미만인 경우 딥러닝 모델 내의 적어도 하나의 파라미터를 업데이트할 수 있다. 프로세서는 연산된 유사도가 임계값 이상인 경우, 딥러닝 모델에 대한 트레이닝을 종료할 수 있다. 실시 예에 따라, 프로세서는 제1 학습 이미지(예: 제1 결함이 있는 전면이 촬영된 전면 이미지)를 제1 딥 러닝 모델에 입력한 경우, 제1 딥러닝 모델을 이용하여 제1 학습 이미지로부터 전자 기기의 전면의 결함 상태를 예측한 제1 마스크를 생성할 수 있다. 촬영 박스가 전면에 제1 결함이 있는 전자 기기를 제1 카메라를 통 해 촬영함으로써 획득된 이미지가 제1 학습 이미지에 해당할 수 있다. 제1 딥러닝 모델은 제1 학습 이미지에 이미지 세그멘테이션을 수행하여 제1 학습 이미지로부터 전자 기기의 전면의 결함 상태를 예측한 제1 마스크를 생성할 수 있다. 프로세서는 제1 마스크와 제1 결함에 대한 레이블 마스크 사이의 제1 유사도를 연산할 수 있다. 프로세서는 연산된 제1 유사도가 임계값 미만인 경우 제1 딥러닝 모델 내의 적어도 하나의 파 라미터를 업데이트할 수 있다. 프로세서는 연산된 제1 유사도가 임계값 이상인 경우, 제1 딥러닝 모델에 대한 트레이닝을 종료할 수 있다. 트레이닝이 완료된 제1 딥러닝 모델은 제1 딥러닝 평가 모델로서 전자 기기 가치 평가 장치에 탑재될 수 있다. 프로세서는 제2 학습 이미지(예: 제2 결함이 있는 후면을 촬영한 후면 이미지)를 제2 딥러닝 모델에 입력 한 경우, 제2 딥러닝 모델을 이용하여 제2 학습 이미지로부터 전자 기기의 후면의 결함 상태를 예측한 제2 마스 크를 생성할 수 있다. 촬영 박스가 후면에 제2 결함이 있는 전자 기기를 제2 카메라를 통해 촬영함으로써 획득된 이미지가 제2 학습 이미지에 해당할 수 있다. 제2 딥러닝 모델은 제2 학습 이미지에 이미지 세그멘테이 션을 수행하여 제2 학습 이미지로부터 전자 기기의 후면의 결함 상태를 예측한 제2 마스크를 생성할 수 있다. 프로세서는 제2 마스크와 제2 결함에 대한 레이블 마스크 사이의 제2 유사도를 연산할 수 있다. 프로세 서는 연산된 제2 유사도가 임계값 미만인 경우 제2 딥러닝 모델 내의 적어도 하나의 파라미터를 업데이트 할 수 있다. 프로세서는 연산된 제2 유사도가 임계값 이상인 경우, 제2 딥러닝 모델에 대한 트레이닝을 종료할 수 있다. 트레이닝이 완료된 제2 딥러닝 모델은 제2 딥러닝 평가 모델로서 전자 기기 가치 평가 장치에 탑재될 수 있다. 프로세서는 제3 학습 이미지(예: 제3 결함이 있는 측면(또는 코너)가 촬영된 측면(또는 코너) 이미지)를 제3 딥러닝 모델에 입력한 경우, 제3 딥러닝 모델을 이용하여 제3 학습 이미지로부터 전자 기기의 측면(또는 코 너)의 결함 상태를 예측한 제3 마스크를 생성할 수 있다. 촬영 박스가 측면(또는 코너)에 제3 결함이 있 는 전자 기기를 제3 카메라를 통해 촬영함으로써 획득된 이미지가 제3 학습 이미지에 해당할 수 있다. 제3 딥러닝 모델은 제3 학습 이미지에 이미지 세그멘테이션을 수행하여 제3 학습 이미지로부터 전자 기기의 측면(또는 코너)의 결함 상태를 예측한 제3 마스크를 생성할 수 있다. 프로세서는 제3 마스크와 제3 결함에 대한 레이블 마스크 사이의 제3 유사도를 연산할 수 있다. 프로세서는 연산된 제3 유사도가 임계값 미만인 경 우 제3 딥러닝 모델 내의 적어도 하나의 파라미터를 업데이트할 수 있다. 프로세서는 연산된 제3 유사도 가 임계값 이상인 경우, 제3 딥러닝 모델에 대한 트레이닝을 종료할 수 있다. 트레이닝이 완료된 제3 딥러닝 모델은 제3 딥러닝 평가 모델로서 전자 기기 가치 평가 장치에 탑재될 수 있다. 프로세서는 제4 학습 이미지(예: 제4 결함이 있는 화면이 촬영된 화면 이미지)를 제4 딥러닝 모델에 입력 한 경우, 제4 딥러닝 모델을 이용하여 제4 학습 이미지로부터 전자 기기의 화면의 결함 상태를 예측한 제4 마스 크를 생성할 수 있다. 촬영 박스가 제4 결함이 있는 화면을 제1 카메라를 통해 촬영함으로써 획득된 이미 지가 제4 학습 이미지에 해당할 수 있다. 제4 딥러닝 모델은 제4 학습 이미지에 이미지 세그멘테이션을 수행하 여 제4 학습 이미지로부터 전자 기기의 화면의 결함 상태를 예측한 제4 마스크를 생성할 수 있다. 프로세서 는 제4 마스크와 제4 결함에 대한 레이블 마스크 사이의 제4 유사도를 연산할 수 있다. 프로세서 는 연산된 제4 유사도가 임계값 미만인 경우 제4 딥러닝 모델 내의 적어도 하나의 파라미터를 업데이트할 수 있 다. 프로세서는 연산된 제4 유사도가 임계값 이상인 경우, 제4 딥러닝 모델에 대한 트레이닝을 종료할 수 있다. 트레이닝이 완료된 제4 딥러닝 모델은 제4 딥러닝 평가 모델로서 전자 기기 가치 평가 장치 에 탑재될 수 있다. 일 실시 예에 있어서, 프로세서는 제5 학습 이미지(예: 제5 결함이 있는 접힌 측면이 촬영된 이미지)를 제5 딥러닝 모델에 입력한 경우, 제5 딥러닝 모델을 이용하여 제5 학습 이미지로부터 폴더블 전자 기기의 접힌 부분에 해당하는 측면의 결함 상태를 예측한 제5 마스크를 생성할 수 있다. 촬영 박스가 접힌 측면에 제5 결함이 있는 전자 기기를 제3 카메라를 통해 촬영함으로써 획득된 이미지가 제5 학습 이미지에 해당할 수 있다. 프로세서는 제5 마스크와 제5 결함에 대한 레이블 마스크 사이의 제5 유사도를 연산할 수 있다. 프로세 서는 연산된 제5 유사도가 임계값 미만인 경우 제5 딥러닝 모델 내의 적어도 하나의 파라미터를 업데이트 할 수 있다. 프로세서는 연산된 제5 유사도가 임계값 이상인 경우, 제5 딥러닝 모델에 대한 트레이닝을 종료할 수 있다. 트레이닝이 완료된 제5 딥러닝 모델은 제5 딥러닝 평가 모델로서 전자 기기 가치 평가 장치 에 탑재될 수 있다. 일 실시 예에 있어서, 프로세서는 제6 학습 이미지(예: 제6 결함이 있는 서브 화면이 촬영된 이미지)를 제6 딥러닝 모델에 입력한 경우, 제6 딥러닝 모델을 이용하여 제6 학습 이미지로부터 폴더블 전자 기기의 서브 화면의 결함 상태를 예측한 제6 마스크를 생성할 수 있다. 촬영 박스가 제6 결함이 있는 서브 화면을 제1 카메라를 통해 촬영함으로써 획득된 이미지가 제6 학습 이미지에 해당할 수 있다. 프로세서는 제6 마스 크와 제6 결함에 대한 레이블 마스크 사이의 제6 유사도를 연산할 수 있다. 프로세서는 연산된 제6 유사 도가 임계값 미만인 경우 제6 딥러닝 모델 내의 적어도 하나의 파라미터를 업데이트할 수 있다. 프로세서 는 연산된 제6 유사도가 임계값 이상인 경우, 제6 딥러닝 모델에 대한 트레이닝을 종료할 수 있다. 트레 이닝이 완료된 제6 딥러닝 모델은 제6 딥러닝 평가 모델로서 전자 기기 가치 평가 장치에 탑재될 수 있다. 일 실시 예에 있어서, 프로세서는 제7 학습 이미지(예: 제7 결함이 있는 확장된 측면이 촬영된 이미지)를 제7 딥러닝 모델에 입력한 경우, 제7 딥러닝 모델을 이용하여 제7 학습 이미지로부터 롤러블 전자 기기의 확장 된 측면의 결함 상태를 예측한 제7 마스크를 생성할 수 있다. 촬영 박스가 제7 결함이 있는 확장된 측면 을 제3 카메라를 통해 촬영함으로써 획득된 이미지가 제7 학습 이미지에 해당할 수 있다. 프로세서는 제 7 마스크와 제7 결함에 대한 레이블 마스크 사이의 제7 유사도를 연산할 수 있다. 프로세서는 연산된 제 7 유사도가 임계값 미만인 경우 제7 딥러닝 모델 내의 적어도 하나의 파라미터를 업데이트할 수 있다. 프로세 서는 연산된 제7 유사도가 임계값 이상인 경우, 제7 딥러닝 모델에 대한 트레이닝을 종료할 수 있다. 트 레이닝이 완료된 제7 딥러닝 모델은 제7 딥러닝 평가 모델로서 전자 기기 가치 평가 장치에 탑재될 수 있 다. 구현에 따라, 프로세서는 제7 학습 이미지를 통해 위 제3 딥러닝 모델을 트레이닝하여 제3 딥러닝 모델이 제7 마스크를 생성하도록 할 수 있다. 일 실시 예에 있어서, 프로세서는 위에서 설명한 트레이닝 방식과 유사하게, 외관에 결함이 있는 웨어러 블 기기를 촬영한 학습 이미지들을 기초로 딥러닝 모델들 각각을 트레이닝하여 웨어러블 기기의 외관(예: 전면, 후면, 측면, 화면)을 평가할 수 있는 딥러닝 평가 모델들을 생성할 수 있다. 도 18은 일 실시 예에 따른 컴퓨팅 장치의 딥러닝 모델 트레이닝 방법을 설명하는 흐름도이다. 도 18을 참조하면, 단계 1810에서, 컴퓨팅 장치는 결함에 대한 학습 이미지를 딥러닝 모델에 입력할 수 있다. 단계 1820에서, 컴퓨팅 장치는 딥러닝 모델을 통해 학습 이미지로부터 결함의 상태를 예측한 마스크를 생 성할 수 있다. 단계 1830에서, 컴퓨팅 장치는 생성된 마스크와 결함에 대한 레이블 마스크 사이의 유사도를 연산할 수 있다. 단계 1840에서, 컴퓨팅 장치는 연산된 유사도가 임계값보다 작은지 여부를 판단할 수 있다. 컴퓨팅 장치는 연산된 유사도가 임계값 미만인 경우 단계 1050에서 딥러닝 모델 내의 적어도 하나의 파라 미터를 업데이트할 수 있다. 컴퓨팅 장치는 단계 1810 내지 단계 1840을 반복 수행할 수 있다. 컴퓨팅 장치는 연산된 유사도가 임계값 이상인 경우, 단계 1860에서, 딥러닝 모델에 대한 트레이닝을 종 료할 수 있다. 도 16을 통해 설명한 실시 예는 도 18의 컴퓨팅 장치의 딥러닝 모델 트레이닝 방법에 적용될 수 있어, 상 세한 설명을 생략한다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리 케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처 리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2022-0092591", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하 나의 프로세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단 독으로 또는 조합하여 저장할 수 있으며 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구 성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 위에서 설명한 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 또는 복수의 소프트웨어 모듈로서 작동하 도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2022-0092591", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 이를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 청구범위와 균등한 것들도 후술하는 청구범위의 범위에 속한다."}
{"patent_id": "10-2022-0092591", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a 내지 도 1b는 일 실시 예에 따른 무인 매입 장치와 서버를 설명하는 도면이다. 도 2는 일 실시 예에 따른 무인 매입 장치를 설명하는 블록도이다. 도 3은 일 실시 예에 따른 촬영 박스를 설명하는 블록도이다. 도 4 내지 도 5는 일 실시 예에 따른 촬영 박스의 안착부와 정렬부를 설명하는 도면이다. 도 6은 일 실시 예에 따른 촬영 박스의 촬영부를 설명하는 도면이다. 도 7 내지 도 9는 일 실시 예에 따른 촬영 박스의 촬영부의 라인 조명을 설명하는 도면이다. 도 10은 일 실시 예에 따른 촬영 박스 내에서 전자 기기의 위치에 따른 카메라 초점 깊이를 설명하는 도면이다. 도 11은 일 실시 예에 따른 전자 기기의 상태바를 설명하는 도면이다. 도 12 내지 도 15는 일 실시 예에 따른 전자 기기 가치 평가 장치의 동작을 설명하는 도면이다. 도 16은 일 실시 예에 따른 딥러닝 모델을 트레이닝하는 컴퓨팅 장치의 구성을 설명하는 블록도이다. 도 17a 내지 도 17c는 일 실시 예에 따른 타겟 마스크와 예측 마스크를 설명하는 도면이다. 도 18은 일 실시 예에 따른 컴퓨팅 장치의 딥러닝 모델 트레이닝 방법을 설명하는 흐름도이다."}
