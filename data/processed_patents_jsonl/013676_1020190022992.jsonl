{"patent_id": "10-2019-0022992", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0106115", "출원번호": "10-2019-0022992", "발명의 명칭": "이미지 캡션 자동 생성 장치 및 방법", "출원인": "한국전력공사", "발명자": "한승호"}}
{"patent_id": "10-2019-0022992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "클라이언트로부터 수신한 이미지에 딥러닝 알고리즘을 적용하여 캡션을 생성하는 자동 캡션 생성 모듈;상기 자동 캡션 생성 모듈로부터 수신한 상기 캡션 내의 중요 단어들에 대하여, 상기 클라이언트로부터 수신한이미지 내의 일부 영역을 매핑시켜 상기 캡션에 대한 근거를 생성하는 캡션 근거 생성 모듈; 및 상기 자동 캡션 생성 모듈로부터 수신한 상기 캡션 및 상기 캡션 근거 생성 모듈로부터 수신한 상기 캡션에 대한 근거를 시각화 처리하여 상기 클라이언트로 반환하는 시각화 모듈;을 포함하는, 이미지 캡션 자동 생성장치."}
{"patent_id": "10-2019-0022992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 상기 자동 캡션 생성 모듈은,상기 클라이언트로부터 수신한 이미지에 대해 CNN(convolutional neural network) 알고리즘을 사용하여 이미지특징 벡터를 추출하는 이미지 특징 추출 모듈; 및사전에 정의된 이미지 특징 벡터와 그에 대한 실제 캡션(ground truth)을 사전에 트레이닝하고, 상기 이미지 특징 추출 모듈에서 추출한 상기 이미지 특징 벡터에 대하여 상기 트레이닝의 결과에 대응하는 상기 캡션을 생성하는 언어 생성 모듈;을 포함하는, 이미지 캡션 자동 생성 장치."}
{"patent_id": "10-2019-0022992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서, 상기 캡션 근거 생성 모듈은,상기 클라이언트로부터 수신한 이미지 내에 포함된 하나 이상의 오브젝트를 인식하고, 하나 이상의 오브젝트 영역을 추출하는 오브젝트 인식 모듈; 상기 자동 캡션 생성 모듈이 생성한 상기 캡션 내의 단어들과 상기 오브젝트 인식 모듈이 추출한 상기 오브젝트영역 각각에 대한 관련성을 딥러닝 알고리즘을 이용하여 학습하고, 상기 학습의 결과로 가중치 행렬을 출력하는이미지 영역-단어 맵핑 모듈; 및상기 이미지 영역-단어 맵핑 모듈로부터 수신한 상기 가중치 행렬로부터 상기 오브젝트 영역 각각에 대해서 가장 높은 가중치를 갖는 단어를 추출하고, 상기 단어 각각에 대해 사후 확률(post probability)을 계산하는 해석강화 모듈;을 포함하는, 이미지 캡션 자동 생성 장치."}
{"patent_id": "10-2019-0022992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서, 상기 시각화 모듈은,상기 클라이언트로부터 수신한 이미지 내에 하나 이상의 상기 오브젝트 영역과 상기 캡션을 표시하고, 상기 캡션에 대한 근거로서 상기 오브젝트 영역에 대응하는 상기 캡션 내의 단어는 상기 오브젝트 영역과 같은 색상으로 표시하고 상기 오브젝트 영역과 같은 색을 갖는 상기 단어 사이의 관련도 값을 표시한 출력 이미지를 상기클라이언트로 반환하는, 이미지 캡션 자동 생성 장치."}
{"patent_id": "10-2019-0022992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "자동 캡션 생성 모듈에 의해, 클라이언트로부터 수신한 이미지에 딥러닝 알고리즘을 적용하여 캡션을 생성하는단계;캡션 근거 생성 모듈에 의해, 상기 자동 캡션 생성 모듈로부터 수신한 상기 캡션 내의 중요 단어들에 대하여,상기 클라이언트로부터 수신한 이미지 내의 일부 영역을 매핑시켜 상기 캡션에 대한 근거를 생성하는 단계; 및 시각화 모듈에 의해, 상기 자동 캡션 생성 모듈로부터 수신한 상기 캡션 및 상기 캡션 근거 생성 모듈로부터 수신한 상기 캡션에 대한 근거를 시각화 처리하여 상기 클라이언트로 반환하는 단계;을 포함하는, 이미지 캡션 자공개특허 10-2020-0106115-3-동 생성 방법."}
{"patent_id": "10-2019-0022992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5항에 있어서, 상기 캡션을 생성하는 단계는,이미지 특징 추출 모듈에 의해, 상기 클라이언트로부터 수신한 이미지에 대해 CNN(convolutional neuralnetwork) 알고리즘을 사용하여 이미지 특징 벡터를 추출하는 단계; 및언어 생성 모듈에 의해, 사전에 정의된 이미지 특징 벡터와 그에 대한 실제 캡션(ground truth)을 사전에 트레이닝하고, 상기 이미지 특징 추출 모듈에서 추출한 상기 이미지 특징 벡터에 대하여 상기 트레이닝의 결과에 대응하는 상기 캡션을 생성하는 단계;를 포함하는, 이미지 캡션 자동 생성 방법."}
{"patent_id": "10-2019-0022992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 5항에 있어서, 상기 근거를 생성하는 단계는,오브젝트 인식 모듈에 의해, 상기 클라이언트로부터 수신한 이미지 내에 포함된 하나 이상의 오브젝트를 인식하고, 하나 이상의 오브젝트 영역을 추출하는 단계; 이미지 영역-단어 맵핑 모듈에 의해, 상기 자동 캡션 생성 모듈이 생성한 상기 캡션 내의 단어들과 상기 오브젝트 인식 모듈이 추출한 상기 오브젝트 영역 각각에 대한 관련성을 딥러닝 알고리즘을 이용하여 학습하고, 상기학습의 결과로 가중치 행렬을 출력하는 단계; 및해석 강화 모듈에 의해, 상기 이미지 영역-단어 맵핑 모듈로부터 수신한 상기 가중치 행렬로부터 상기 오브젝트영역 각각에 대해서 가장 높은 가중치를 갖는 단어를 추출하고, 상기 단어 각각에 대해 사후 확률(postprobability)을 계산하는 단계;를 포함하는, 이미지 캡션 자동 생성 방법."}
{"patent_id": "10-2019-0022992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서, 상기 반환하는 단계는,상기 시각화 모듈에 의해, 상기 클라이언트로부터 수신한 이미지 내에 하나 이상의 상기 오브젝트 영역과 상기캡션을 표시하고, 상기 시각화 모듈에 의해, 상기 캡션에 대한 근거로서 상기 오브젝트 영역에 대응하는 상기캡션 내의 단어는 상기 오브젝트 영역과 같은 색상으로 표시하고 상기 오브젝트 영역과 같은 색을 갖는 상기 단어 사이의 관련도 값을 표시한 출력 이미지를 상기 클라이언트로 반환하는 단계;를 포함하는, 이미지 캡션 자동생성 방법."}
{"patent_id": "10-2019-0022992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "컴퓨터를 이용하여 제 5항 내지 제 8항의 방법 중 어느 한 항의 방법을 실행시키기 위하여 상기 컴퓨터로 판독가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2019-0022992", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 딥러닝 알고리즘을 기반으로 하여 이미지 영역-단어 맵핑 모듈과 베이즈 추론을 이용한 설명 가능한 이미지 캡션 자동 생성 장치 및 방법에 관한 것이다. 본 발명의 일 실시 예에 따른 이미지 캡션 자동 생성 장치는 클라이언트로부터 수신한 이미지에 딥러닝 알고리즘 을 적용하여 캡션을 생성하는 자동 캡션 생성 모듈과, 자동 캡션 생성 모듈로부터 수신한 캡션 내의 중요 단어들 에 대하여, 클라이언트로부터 수신한 이미지 내의 일부 영역을 매핑시켜 캡션에 대한 근거를 생성하는 캡션 근거 생성 모듈과, 자동 캡션 생성 모듈로부터 수신한 캡션 및 캡션 근거 생성 모듈로부터 수신한 캡션에 대한 근거를 시각화 처리하여 클라이언트로 반환하는 시각화 모듈을 포함한다."}
{"patent_id": "10-2019-0022992", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥러닝 알고리즘을 기반으로 하여 이미지 영역-단어 맵핑 모듈과 베이즈 추론을 이용한 설명 가능한 이미지 캡션 자동 생성 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2019-0022992", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이미지 캡셔닝(또는 이미지 주석 달기)이란, 사용자로부터 수신한 이미지에 대하여 그 이미지를 설명하는 캡션 을 생성하는 것을 말할 수 있다. 인공지능의 다양한 기술이 발전하기 이전에는 이미지 캡셔닝을 사람이 직접 수행했었지만 최근 컴퓨팅 파워 증가, 기계학습과 같은 인공지능 기술의 발전으로 기계를 이용하여 자동으로 캡 션을 생성하는 기술이 개발되고 있다. 이전의 자동 캡션 생성 기술은 기존의 존재하는 많은 이미지와 각 이미지에 대한 라벨 정보를 이용하여 같은 라 벨을 갖는 같은 이미지를 검색하거나, 유사한 이미지들의 라벨들을 하나의 이미지에 할당하여 이미지에 대해 복 수의 라벨을 이용하여 이미지 설명을 시도하였다.기계를 이용한 캡션 생성의 일 예로서, 이미지 주석 달기라는 명칭의 국내 공개 특허 제10-2011-033179호(이하 선행기술1이라 표기함)에서는 입력 이미지에 대해 해당 이미지와 이미지 라벨이 연관된 하나 이상의 최 근접 이 웃 이미지를 저장된 이미지들의 집합 중에서 찾고, 선택된 각 이미지들의 라벨을 입력 이미지에 대한 복수 라벨 로 할당함으로써 주석을 달게 된다. 입력 이미지와 연관된 최 근접 이웃 이미지의 경우, 모든 이미지의 특징을 추출하고 추출된 각 특징 간의 거리를 거리 유도 알고리즘을 학습하여 계산하며, 최종적으로 입력 이미지에 대 한 관련된 복수의 라벨들을 생성하게 된다. 그러나 선행기술1에서는 생성된 이미지에 대한 주석이 완전한 문장 형태를 취하는 것이 아니라, 단순히 관련된 단어들의 나열이 되어 주어진 입력 이미지에 대한 설명이라고 보기 어렵다. 캡션 자동 생성과 관련된 다른 일 예로는, 맥락 정보를 사용하여 스트리트 뷰 이미지에 주석을 다는 기술이라는 명칭의 국내 공개 특허 제10-2013-0127458호(이하 선행기술2라 표기함)를 들 수 있다. 선행기술2에서는 사용자 로 하여금 스트리트 레벨에서 한 특정 위치의 주변환경을 볼 수 있도록 해주는 스트리트 뷰(street view)에 대 해, 스트리트 뷰 내의 오브젝트들에 대한 메타데이터를 이용하여 하나 이상의 오브젝트를 가지는 스트리트 뷰 이미지에 대해 수직 정렬 상태로 배치되는 오브젝트 메타데이터를 생성하여, 최종적으로 주석이 달린 스트리트 뷰 이미지를 생성하고 이를 사용자에게 제공한다. 그러나 선행기술2의 경우 선행기술1과 유사하게 입력 이미지 전체를 설명하는 하나의 완전한 문장 형태가 아닌 스트리트 뷰 이미지 내의 각 오브젝트에 대한 라벨을 생성하 며, 입력 이미지 또한 스트리트 뷰 이미지에 한정된다는 한계를 갖는다."}
{"patent_id": "10-2019-0022992", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다."}
{"patent_id": "10-2019-0022992", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제점 및/또는 한계를 해결하기 위해 안출된 것으로, 일 측면에 따른 본 발명의 목적은 사용 자로부터 제공되는 새로운 이미지에 대해, 이미지 내부의 오브젝트 정보를 활용하여 이미지를 설명하는 완전한 캡션을 생성하는데 있다. 또한 본 발명의 다른 목적은 딥러닝 알고리즘을 이용한 학습 모델에서 나타나는 결과 해석의 어려움에 대한 문 제를 해결하기 위해, 자동 이미지 캡션 생성 모델의 결과에 대한 설명을 같이 사용자에게 제공하여, 사용자가 학습된 딥러닝 모델이 생성한 결과들에 대한 이유를 알 수 있도록 하는데 있다."}
{"patent_id": "10-2019-0022992", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 이미지 캡션 자동 생성 장치는, 클라이언트로부터 수신한 이미지에 딥러닝 알고리 즘을 적용하여 캡션을 생성하는 자동 캡션 생성 모듈; 상기 자동 캡션 생성 모듈로부터 수신한 상기 캡션 내의 중요 단어들에 대하여, 상기 클라이언트로부터 수신한 이미지 내의 일부 영역을 매핑시켜 상기 캡션에 대한 근 거를 생성하는 캡션 근거 생성 모듈; 및 상기 자동 캡션 생성 모듈로부터 수신한 상기 캡션 및 상기 캡션 근거 생성 모듈로부터 수신한 상기 캡션에 대한 근거를 시각화 처리하여 상기 클라이언트로 반환하는 시각화 모듈;을 포함할 수 있다. 상기 자동 캡션 생성 모듈은, 상기 클라이언트로부터 수신한 이미지에 대해 CNN(convolutional neural network) 알고리즘을 사용하여 이미지 특징 벡터를 추출하는 이미지 특징 추출 모듈; 및 사전에 정의된 이미지 특징 벡터 와 그에 대한 실제 캡션(ground truth)을 사전에 트레이닝하고, 상기 이미지 특징 추출 모듈에서 추출한 상기 이미지 특징 벡터에 대하여 상기 트레이닝의 결과에 대응하는 상기 캡션을 생성하는 언어 생성 모듈;을 포함할 수 있다. 상기 캡션 근거 생성 모듈은, 상기 클라이언트로부터 수신한 이미지 내에 포함된 하나 이상의 오브젝트를 인식 하고, 하나 이상의 오브젝트 영역을 추출하는 오브젝트 인식 모듈; 상기 자동 캡션 생성 모듈이 생성한 상기 캡 션 내의 단어들과 상기 오브젝트 인식 모듈이 추출한 상기 오브젝트 영역 각각에 대한 관련성을 딥러닝 알고리 즘을 이용하여 학습하고, 상기 학습의 결과로 가중치 행렬을 출력하는 이미지 영역-단어 맵핑 모듈; 및 상기 이 미지 영역-단어 맵핑 모듈로부터 수신한 상기 가중치 행렬로부터 상기 오브젝트 영역 각각에 대해서 가장 높은 가중치를 갖는 단어를 추출하고, 상기 단어 각각에 대해 사후 확률(post probability)을 계산하는 해석 강화 모 듈;을 포함할 수 있다.상기 시각화 모듈은, 상기 클라이언트로부터 수신한 이미지 내에 하나 이상의 상기 오브젝트 영역과 상기 캡션 을 표시하고, 상기 캡션에 대한 근거로서 상기 오브젝트 영역에 대응하는 상기 캡션 내의 단어는 상기 오브젝트 영역과 같은 색상으로 표시하고 상기 오브젝트 영역과 같은 색을 갖는 상기 단어 사이의 관련도 값을 표시한 출 력 이미지를 상기 클라이언트로 반환할 수 있다. 본 발명의 일 실시 예에 따른 이미지 캡션 자동 생성 방법은, 자동 캡션 생성 모듈에 의해, 클라이언트로부터 수신한 이미지에 딥러닝 알고리즘을 적용하여 캡션을 생성하는 단계; 캡션 근거 생성 모듈에 의해, 상기 자동 캡션 생성 모듈로부터 수신한 상기 캡션 내의 중요 단어들에 대하여, 상기 클라이언트로부터 수신한 이미지 내 의 일부 영역을 매핑시켜 상기 캡션에 대한 근거를 생성하는 단계; 및 시각화 모듈에 의해, 상기 자동 캡션 생 성 모듈로부터 수신한 상기 캡션 및 상기 캡션 근거 생성 모듈로부터 수신한 상기 캡션에 대한 근거를 시각화 처리하여 상기 클라이언트로 반환하는 단계;을 포함할 수 있다. 상기 캡션을 생성하는 단계는, 이미지 특징 추출 모듈에 의해, 상기 클라이언트로부터 수신한 이미지에 대해 CNN(convolutional neural network) 알고리즘을 사용하여 이미지 특징 벡터를 추출하는 단계; 및 언어 생성 모 듈에 의해, 사전에 정의된 이미지 특징 벡터와 그에 대한 실제 캡션(ground truth)을 사전에 트레이닝하고, 상 기 이미지 특징 추출 모듈에서 추출한 상기 이미지 특징 벡터에 대하여 상기 트레이닝의 결과에 대응하는 상기 캡션을 생성하는 단계;를 포함할 수 있다. 상기 근거를 생성하는 단계는, 오브젝트 인식 모듈에 의해, 상기 클라이언트로부터 수신한 이미지 내에 포함된 하나 이상의 오브젝트를 인식하고, 하나 이상의 오브젝트 영역을 추출하는 단계; 이미지 영역-단어 맵핑 모듈에 의해, 상기 자동 캡션 생성 모듈이 생성한 상기 캡션 내의 단어들과 상기 오브젝트 인식 모듈이 추출한 상기 오 브젝트 영역 각각에 대한 관련성을 딥러닝 알고리즘을 이용하여 학습하고, 상기 학습의 결과로 가중치 행렬을 출력하는 단계; 및 해석 강화 모듈에 의해, 상기 이미지 영역-단어 맵핑 모듈로부터 수신한 상기 가중치 행렬로 부터 상기 오브젝트 영역 각각에 대해서 가장 높은 가중치를 갖는 단어를 추출하고, 상기 단어 각각에 대해 사 후 확률(post probability)을 계산하는 단계;를 포함할 수 있다. 상기 반환하는 단계는, 상기 시각화 모듈에 의해, 상기 클라이언트로부터 수신한 이미지 내에 하나 이상의 상기 오브젝트 영역과 상기 캡션을 표시하고, 상기 시각화 모듈에 의해, 상기 캡션에 대한 근거로서 상기 오브젝트 영역에 대응하는 상기 캡션 내의 단어는 상기 오브젝트 영역과 같은 색상으로 표시하고 상기 오브젝트 영역과 같은 색을 갖는 상기 단어 사이의 관련도 값을 표시한 출력 이미지를 상기 클라이언트로 반환하는 단계;를 포함 할 수 있다. 이 외에도, 본 발명을 구현하기 위한 다른 방법, 다른 시스템 및 상기 방법을 실행하기 위한 컴퓨터 프로그램이 더 제공될 수 있다. 전술한 것 외의 다른 측면, 특징, 이점이 이하의 도면, 특허청구범위 및 발명의 상세한 설명으로부터 명확해질 것이다."}
{"patent_id": "10-2019-0022992", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시 예들에 따르면, 새로운 이미지에 대해 이미지 및 캡션 데이터베이스만을 기반으로 하여 캡션을 생성하는 것이 아니라, 입력 이미지 내의 중요 오브젝트 정보를 잘 반영하여 캡션을 생성하도록 언어 생성 모듈이 학습할 때 이미지-문장 관련성 손실 값을 정의하고 이를 통해 학습 피드백을 줌으로써 새로운 이미지에 대한 캡션 생성 의 성능을 향상시킬 수 있다. 또한 딥러닝 알고리즘과 베이즈 추론을 이용하여 이미지 영역-단어 맵핑 모듈을 통해 생성된 캡션에 대한 근거 를 제시함으로써 결과 해석이 어려운 딥러닝 알고리즘 모델의 한계점을 해결할 수 있다."}
{"patent_id": "10-2019-0022992", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0022992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 설명되는 실시 예들 을 참조하면 명확해질 것이다. 그러나 본 발명은 아래에서 제시되는 실시 예들로 한정되는 것이 아니라, 서로 다른 다양한 형태로 구현될 수 있고, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물 을 포함하는 것으로 이해되어야 한다. 아래에 제시되는 실시 예들은 본 발명의 개시가 완전하도록 하며, 본 발"}
{"patent_id": "10-2019-0022992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되 는 경우 그 상세한 설명을 생략한다. 본 출원에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포 함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들은 상기 용어들에 의해 한정되 어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 이하, 본 발명에 따른 실시 예들을 첨부된 도면을 참조하여 상세히 설명하기로 하며, 첨부 도면을 참조하여 설 명함에 있어, 동일하거나 대응하는 구성 요소는 동일한 도면번호를 부여하고 이에 대한 중복되는 설명은 생략하 기로 한다. 도 1은 본 발명의 일 실시 예에 따른 이미지 캡션 자동 생성 장치를 개략적으로 설명하기 위하여 도시한 도면이 다. 도 1을 참조하면, 이미지 캡션 자동 생성 장치는 클라이언트, 캡션 생성 장치 및 통신망 을 포함할 수 있다. 클라이언트는 처리할 이미지를 제공하는 사용자로서, 사용자 디바이스를 통해 이미지를 제공할 수 있 다. 본 실시 예에서 사용자 디바이스는 사용자가 조작하는 데스크 탑 컴퓨터, 스마트폰, 노트북, 태블릿 PC, 스마트 TV, 휴대폰, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레 이어, 디지털 카메라, 가전기기 및 기타 모바일 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 또한, 사용자 디바이스는 통신 기능 및 데이터 프로세싱 기능을 구비한 시계, 안경, 헤어 밴드 및 반지 등의 웨어러블 단말기 일 수 있다. 캡션 생성 장치는 클라이언트로부터 제공 받은 이미지를 처리하고 결과를 다시 클라이언트에게 반환해 줄 수 있으며, 제공 받은 이미지에 대한 캡션과 그에 대한 이유를 함께 출력할 수 있다. 본 실시 예에 서 캡션 생성 장치는 자동 캡션 생성 모듈, 캡션 근거 생성 모듈, 시각화 모듈 및 데이터 베이스를 포함할 수 있다. 자동 캡션 생성 모듈은 클라이언트로부터 수신한 이미지에 딥러닝 알고리즘을 적용하여 캡션을 생성 할 수 있다. 캡션 근거 생성 모듈은 캡션 문장 내 중요 단어들에 대하여, 클라이언트로부터 수신한 이미지 내의 일부 영역을 매핑시켜, 자동 캡션 생성 모듈이 생성한 캡션에 대한 근거를 제시할 수 있다. 시각화 모듈은 자동 캡션 생성 모듈로부터 수신한 캡션과 캡션 근거 생성 모듈로부터 수신한 캡 션에 대한 근거를 시각화 처리하여 상기 클라이언트로 반환할 수 있다. 통신망은 클라이언트와 캡션 생성 장치를 연결하는 역할을 수행한다. 즉, 통신망은 클라 이언트가 캡션 생성 장치에 접속한 후 소정의 정보 송수신할 수 있도록 접속 경로를 제공하는 통신망 을 의미할 수 있다. 통신망은 예컨대 LANs(Local Area Networks), WANs(Wide Area Networks), MANs(Metropolitan Area Networks), ISDNs(Integrated Service Digital Networks) 등의 유선 네트워크나, 무선 LANs, CDMA, 블루투스, 위성 통신 등의 무선 네트워크를 망라할 수 있으나, 본 발명의 범위가 이에 한정되는 것 은 아니다. 또한 통신망은 근거리 통신 및/또는 원거리 통신을 이용하여 정보를 송수신할 수 있다. 여기 서 근거리 통신은 블루투스(bluetooth), RFID(radio frequency identification), 적외선 통신(IrDA, infrared data association), UWB(ultra-wideband), ZigBee, Wi-Fi (wireless fidelity) 기술을 포함할 수 있고, 원거리 통신은 CDMA(code division multiple access), FDMA(frequency division multiple access), TDMA(time division multiple access), OFDMA(orthogonal frequency division multiple access), SC-FDMA(single carrier frequency division multiple access) 기술을 포함할 수 있다. 도 2는 도 1에 도시된 캡션 생성 장치의 구성을 포함하여 최종 결과 생성의 절차를 도시한 흐름도이다. 이하의 설명에서 도 1에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 2를 참조하면, 캡션 생성 장치는 클라이언트로부터 입력 이미지를 수신할 수 있다. 자동 캡션 생성 모듈은 클라이언트로부터 수신한 입력 이미지에 대해 딥러닝 알고리즘을 적용하 여 캡션을 생성할 수 있다. 본 실시 예에서 자동 캡션 생성 모듈은 이미지 특징 추출 모듈 및 언어 생성 모듈을 포함할 수 있다. 이미지 특징 추출 모듈은 입력 이미지에 대해 CNN(convolutional neural network) 알고리즘을 사용 하여 벡터 형식의 이미지 특징을 추출할 수 있다. 언어 생성 모듈은 이미지 특징 추출 모듈에서 추출한 벡터 형식의 이미지 특징에 대한 캡션 문장을 생성할 수 있다. 언어 생성 모듈이 캡션 문장을 생성하기 위해서는 사전에 정의된 많은 이미지 특징 벡터 와 그에 대한 실제 캡션 문장(ground truth)을 기반으로 모듈의 파라미터가 트레이닝을 선행해야 한다. 따라서 언어 생성 모듈은 이미지 특징 추출 모듈에서 추출한 벡터 형식의 이미지 특징에 대하여 트레이닝 결 과에 대응하는 캡션 문장을 생성할 수 있다 캡션 근거 생성 모듈은 캡션 문장 내 중요 단어들에 대하여, 클라이언트로부터 수신한 이미지 내의 일부 영역을 매핑시켜, 자동 캡션 생성 모듈이 생성한 캡션 문장에 대한 근거를 제시할 수 있다. 본 실시 예에서, 캡션 근거 생성 모듈은 오브젝트 인식 모듈, 이미지 영역-단어 맵핑 모듈 및 해석 강화 모듈을 포함할 수 있다. 오브젝트 인식 모듈은 입력 이미지 내에 포함된 하나 이상의 오브젝트(예를 들어, 사람, 물건 등)를 인식하고 오브젝트 영역을 추출할 수 있다. 이미지 영역-단어 맵핑 모듈은 언어 생성 모듈이 생성한 캡션 내의 일부 단어들과 오브젝트 인식 모 듈이 추출한 입력 이미지 내의 오브젝트 영역 각각에 대한 관련성을 딥러닝 알고리즘을 이용하여 학 습하고, 학습의 결과를 가중치 행렬로 출력할 수 있다. 본 실시 예에서 이미지 영역-단어 맵핑 모듈이 상 술한 기능을 수행하기 위해서는 사전에 미리 학습이 선행되어야 한다. 해석 강화 모듈은 이미지 영역-단어 맵핑 모듈에서 생성된 벡터 행렬로부터 오브젝트 영역 각각에 대 해서 가장 관련된 단어(모든 단어들에 대해서 가장 높은 가중치를 갖는 단어)를 추출하고, 단어 각각에 대해 데 이터베이스에 정의된 사전 확률(priori probability) 분포와 가능성(likelihood) 확률 분포를 이용하여 베이즈 추론을 통한 사후 확률(post probability)를 계산할 수 있다. 시각화 모듈은 언어 생성 모듈로부터 출력된 캡션과 이미지 영역-단어 맵핑 모듈로부터 출력된 오브젝트 영역과 단어의 관련도 벡터 행렬을 이용하여, 각 오브젝트 영역에 대해 관련도가 가장 높다고 판단된 단어를 벡터 행렬에서 찾고, 선택된 오브젝트 영역과 단어에 대하여 오브젝트 영역은 색칠된 테두리 박스를 이 미지에 표시하고, 단어는 테두리 박스와 같은 색으로 색칠하여 표시할 수 있다. 따라서 시각화 모듈의 최 종 출력 결과는 각 오브젝트 영역에 대해 관련된 단어들에 대해 같은 색의 테두리 박스와 색칠된 단어가 포함된 캡션을 함께 보여줄 수 있다.도 3은 도 2에 도시된 이미지 영역-단어 맵핑 모듈의 트레이닝 방법을 도시한 흐름도이다. 이하의 설명에 서 도 1 및 도 2에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 3을 참조하면, S310단계에서, 이미지 영역-단어 맵핑 모듈은 데이터베이스로부터 사전에 정의된 이미지에 대한 캡션 데이터와 이미지에서 추출된 오브젝트 영역 데이터를 수신한다. 본 실시 예에서 데이터베 이스는 사전에 정의된 이미지와, 이미지에 대한 오브젝트 영역과, 이미지에 대한 캡션 데이터가 저장되어 있을 수 있다. S320단계에서, 이미지 영역-단어 맵핑 모듈은 오브젝트 영역에 대하여 CNN 알고리즘을 이용하여 벡터 형태 의 특징 즉, 오브젝트 영역의 특징 벡터를 추출하고, 이와 동시에 S330단계에서, 이미지 영역-단어 맵핑 모듈 은 캡션 데이터 내의 단어들에 대하여 BiRNN(bidirectional recurrent neural network) 알고리즘을 이용 하여, 오브젝트 영역에 대한 벡터 형태의 특징과 같은 차원의 벡터 형태의 특징 즉, 단어의 특징 벡터를 추출한 다. 여기서, 이미지 영역-단어 맵핑 모듈이 캡션 데이터 내의 단어들에 대한 벡터 형태의 특징 추출 시에 사용되는 단어들은 관사 또는 대명사 등을 제거하는 전처리 단계를 거치고 남은 단어들을 포함할 수 있다. S340단계에서, 이미지 영역-단어 맵핑 모듈은 오브젝트 영역의 특징 벡터와 단어의 특징 벡터를 딥러닝 학 습 모델에 입력한다. S350단계에서, 이미지 영역-단어 맵핑 모듈에 포함된 딥러닝 학습 모델은 오브젝트 영역의 특징 벡터와 단 어의 특징 벡터에 전 방향 전파(forward propagation)를 수행하여 오브젝트 영역의 특징 벡터와 단어의 특징 벡 터 및 모델 가중치가 곱해진 가중치 행렬을 생성한다. S360단계에서, 이미지 영역-단어 맵핑 모듈에 포함된 딥러닝 학습 모델은 생성한 가중치 행렬에 대해 softmax 함수를 통해 단어의 특징 벡터들에 대한 관련도 값을 추론한다. 여기서, 관련도 값은 0-1 사이의 값이 며, 모든 단어의 특징 벡터들에 할당된 관련도 값의 총 합은 1이 될 수 있다. 또한 관련도 값이 1에 가까울수 록 오브젝트 영역의 특징 벡터와 관련도가 높다는 것을 의미할 수 있다. 예를 들어, 도 2의 입력 이미지 에 대하여 오브젝트 영역에 대한 라벨이 <모니터>이고, 입력된 단어들이 <모니터>, <옆에>, <노트북>, <키보 드>라면, 이미지 영역-단어 맵핑 모듈은 가장 관련성이 높은 <모니터>라는 단어에 높은 값(예를 들어, 0.9)를 주고, 나머지 단어들은 0.1을 나눠서 할당할 수 있다. S370단계에서, 이미지 영역-단어 맵핑 모듈에 포함된 딥러닝 학습 모델은 추론한 단어의 특징 벡터들에 대 한 관련도 값을 이용하여 손실 값을 계산한다. 손실 값은 딥러닝 학습 모델이 추론한 관련도 값들과, 오브젝트 영역의 특징 벡터의 실제 카테고리와, 단어의 특징 벡터 사이의 워드 임베딩을 값 사이의 평균 제곱근 편차를 이용하여 계산한다. 여기서 워드 임베딩은 사전에 정의된 모든 가능한 영역 카테고리와 데이터베이스의 모든 캡션을 구성하는 단어들을 이용하여 사전에 학습될 수 있다. S380단계에서, 이미지 영역-단어 맵핑 모듈에 포함된 딥러닝 학습 모델은 계산된 손실 값에 따라 역 전파 (back propagation)를 통해 딥러닝 학습 모델의 파라미터를 업데이트 한다. 이미지 영역-단어 맵핑 모듈 은 딥러닝 모델의 파라미터 최적화를 위해 S310단계 내지 S380단계를 반복 수행할 수 있다. 도 4는 도 2에 도시된 이미지 영역-단어 맵핑 모듈의 처리 예를 도시한 도면이다. 이하의 설명에서 도 1 내지 도 3에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 4를 참조하면, 클라이언트로부 터의 입력 이미지에 대하여 이미지 특징 추출 모듈이 추출한 제1 오브젝트 영역(R1), 제2 오브젝트 영역(R2) 및 제3 오브젝트 영역(R3)을 수신한 이미지 영역-단어 맵핑 모듈은 제1 오브젝트 영역(R1) 내지 제3 오브젝트 영역(R3) 각각을 특징 벡터로 변환할 수 있다. 또한 클라이언트로부터의 입력 이미지 에 대하여 언어 생성 모듈이 생성한 캡션을 수신한 이미지 영역-단어 맵핑 모듈은 캡션을 전처리 한 후 남은 단어들에 대하여 특징 벡터로 변환할 수 있다. 이미지 영역-단어 맵핑 모듈은 딥러닝 학습을 통 하여 각 오브젝트 영역에 대한 각 단어의 관련도, 즉 단어 주의도(attention score)를 계산하여 가중치 행렬을 출력할 수 있다. 도 5는 도 1에 도시된 캡션 생성 장치의 트레이닝 방법을 도시한 흐름도이다. 이하의 설명에서 도 1 내지 도 4 에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 5를 참조하면, S510단계에서, 캡션 생성 장치는 데이터베이스로부터 사전에 정의된 이미지와 이미 지에 대한 캡션 데이터를 수신한다. 본 실시 예에서 데이터베이스는 사전에 정의된 이미지와, 이미지에 대한 캡션 데이터가 저장되어 있을 수 있다. S520단계에서, 캡션 생성 장치는 수신한 이미지에 대해 CNN 알고리즘을 이용하여 벡터 형태의 특징 즉, 이 미지에 대한 특징 벡터를 추출한다. 여기서 이미지에 대한 특징 벡터 추출은 이미지 특징 추출 모듈에서 수행될 수 있다. 동시에 S530단계에서, 캡션 생성 장치는 수신한 이미지에 대해 Mask R-CNN 알고리즘을 사용하여 이미지 내 중요 오브젝트 영역을 추출한다. 여기서, 이미지 내 중요 오브젝트 영역의 추출은 오브젝트 인식 모듈에 수행될 수 있다. S540단계에서, 캡션 생성 장치는 추출된 이미지 특징 벡터를 이용하여 특징 벡터에 대한 캡션을 생성한다. 여기서 캡션 생성은 언어 생성 모듈에서 수행될 수 있으며, 이미지 특징 벡터를 이용하여 생성한 캡션은 실제 캡션이 아닌 예측 캡션일 수 있다. S550단계에서, 캡션 생성 장치는 예측 캡션과 추출된 오브젝트 영역에 딥러닝 알고리즘을 적용하여 가중치 행렬(도 4)을 출력한다. 여기서 가중치 행렬은 이미지 영역-단어 맵핑 모듈에서 수행될 수 있다. 캡션 생성 장치의 파라미터 학습을 위해, S560단계에서, 캡션 생성 장치는 예측 캡션에 대해 실제 캡 션 데이터와 비교하여 캡션 손실값(Lossg)을 계산한다. 또한 S570단계에서, 캡션 생성 장치는 가중치 행렬로부터 관련도(주의도)가 가장 높은 오브젝트 영역-단어 쌍을 각 영역 당 최소 하나 이상 선택하고, 실제 데이터베이스의 영역-단어 분포에 기반하여 이미지-캡션 손실값(Losse)을 계산한다. 여기서, 캡션 생성 장치는 각 오브젝트 영역-단어 쌍에 대해 실제 데이터베이 스에서 어떤 단어가 주어졌을 때의 어떤 오브젝트 영역이 있을 조건부 확률 값을 계산하고, 모든 오브젝트 영역-단어 쌍에 대한 확률값을 더하여 이미지-캡션 손실값(Losse)을 계산할 수 있다. 또한 각 단어에 대한 각 오브젝트 영역이 데이터베이스 분포에 있을 확률을 계산하는 것은 딥러닝 알고리 즘을 사용하여 모델링 될 수 있다(이하 해석 강화 모델(해석 강화 모듈에서 수행)이라 표기함). 해석 강 화 모델은 이미지 영역-단어 맵핑 모듈로루터 출력된 가중치 행렬에서 관련이 있다고 판단된 영역-단어 쌍 특징 벡터를 입력으로 하여, 베이즈 이론에 기반하여 단어가 주어졌을 때 영역이 있을 조건부 확률 값 출력한다. 또한 각 단어에 대한 각 오브젝트 영역이 데이터베이스 분포에 있을 확률을 계산하는 것은 딥러닝 알고리 즘을 사용하여 모델링 될 수 있다(이하 해석 강화 모델(해석 강화 모듈에서 수행)이라 표기함). 해석 강 화 모델은 이미지 영역-단어 맵핑 모듈로루터 출력된 가중치 행렬에서 관련이 있다고 판단된 영역-단어 쌍 특징 벡터를 입력으로 하여, 베이즈 이론에 기반하여 단어가 주어졌을 때 영역이 있을 조건부 확률 값 출력한다. 이를 수식으로 표현하면, 사후 확률 이며, 해석 강화 모듈은 사후 확률값을 얻기 위해 베이즈 추론을 이용하여 추론하게 된다. 따라서 사전에 정의된 데이터베이스로부터 얻을 수 있는 사전 확 률 의 분포와 가능성 확률 의 분포를 이용하여 사후 확률 의 분포를 베이즈 추론을 이용하여 해석 강화 모델이 출력하도록 파라미터를 미리 학습 시키고, 캡션 생성 장치가 트레이닝 하는 과정에서 주 어진 모든 오브젝트 영역-단어 쌍에 대해 각각의 사후 확률 값을 구하고, 1을 뺀 값을 모두 더하여 이미지-캡션 손실값(Losse)을 계산할 수 있다. 이미지-문장 손실값(Losse)을 식으로 표현하면 수학식1과 같다. 수학식 1"}
{"patent_id": "10-2019-0022992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이미지-캡션 손실값(Losse)의 의미는 언어 생성 모듈이 생성한 캡션 내의 중요 단어들이 실제 이미지 내의 오브젝트 정보를 잘 반영했는지를 평가하여 이를 수치화 한 것이다. 즉, 만약 이미지에 대해 생성한 캡션이 이미지 내의 오브젝트 정보를 잘 반영하지 못하였으면, 해석 강화 모듈에서 각 단어에 대한 영역의 사후 확 률 값이 낮아지고, 이미지-캡션 손실값(Losse)은 높아지게 되어 결론적으로 캡션 생성 장치의 학습을 가속 화한다. 반대의 경우, 이미지-캡션 손실값(Losse)은 낮아지게 되고, 캡션 생성 장치의 학습이 완화될 수 있다. 최종적으로 S580단계에서 캡션 손실값(Lossg)과 이미지-캡션 손실값(Losse)을 더하여 캡션 생성 장치 내의 언어 생성 모듈의 파라미터를 손실값의 합이 최소가 되도록 업데이트 한다. 도 6은 도 1에 도시된 캡션 생성 장치가 클라이언트로 반환하는 출력 이미지를 도시한 도면이다. 이하의 설명 에서 도 1 내지 도 5에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 6을 참조하면, 시각화 모듈은 출력 이미지결과에 중요 오브젝트 영역을 표시하고, 오브젝트 영역의 정보를 반영하여 생성한 캡션을 출력 표시할 수 있다. 이때, 오브젝트 영역의 정보를 직접적으로 반영한 캡션 내의 단어는 오브젝트 영역과 같은 색으로 표시하여 해당 단어가 생성된 근거를 제시할 수 있다. 또한 해당 오브젝트 영역과 같은 색을 갖는 단어 사이의 관련도 값(0~1 사이 값, 0: 관련 없음, 1: 관련 많음) 을 오른쪽 작은 박스에 표시해줌으로써 오브젝트 영역-단어 사이에 관련도가 얼마인지 수치화 해서 보여줄 수 있다. 도 7은 본 발명의 일 실시 예에 따른 이미지 캡션 자동 생성 방법을 도시한 흐름도이다. 이하의 설명에서 도 1 내지 도 6에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 7을 참조하면, S710단계에서, 캡션 생성 장치는 클라이언트로부터 수신한 이미지에 딥러닝 알고리 즘을 적용하여 캡션을 생성한다. 캡션 생성 장치는 클라이언트로부터 수신한 이미지에 대해 CNN(convolutional neural network) 알고리즘을 사용하여 이미지 특징 벡터를 추출할 수 있다. 캡션 생성 장 치는 사전에 정의된 이미지 특징 벡터와 그에 대한 실제 캡션(ground truth)을 사전에 트레이닝하고, 추출 한 이미지 특징 벡터에 대하여 트레이닝의 결과에 대응하는 캡션을 생성할 수 있다. S720단계에서, 캡션 생성 장치는 수신한 캡션 내의 중요 단어들에 대하여, 클라이언트로부터 수신한 이미지 내의 일부 영역을 매핑시켜 캡션에 대한 근거를 생성한다. 캡션 생성 장치는 클라이언트로 부터 수신한 이미지 내에 포함된 하나 이상의 오브젝트를 인식하고, 하나 이상의 오브젝트 영역을 추출할 수 있 다. 캡션 생성 장치는 S710단계에서 생성한 캡션 내의 단어들과 추출한 오브젝트 영역 각각에 대한 관련 성을 딥러닝 알고리즘을 이용하여 학습하고, 학습의 결과로 가중치 행렬을 출력할 수 있다. 캡션 생성 장치 는 가중치 행렬로부터 오브젝트 영역 각각에 대해서 가장 높은 가중치를 갖는 단어를 추출하고, 단어 각각 에 대해 사후 확률(post probability)을 계산할 수 있다. S730단계에서, 캡션 생성 장치는 캡션 및 캡션에 대한 근거를 시각화 처리하여 클라이언트로 반환한 다. 캡션 생성 장치는 클라이언트로부터 수신한 이미지 내에 하나 이상의 오브젝트 영역과 캡션을 표시하고, 캡션에 대한 근거로서 오브젝트 영역에 대응하는 캡션 내의 단어는 오브젝트 영역과 같은 색상으로 표시하고 오브젝트 영역과 같은 색을 갖는 단어 사이의 관련도 값을 표시한 출력 이미지를 클라이언트로 반환할 수 있다. 선택적 실시 예로서, 이미지로부터의 특징 벡터는 CNN(convolution neural network) 알고리즘을 이용하여 특정 차원을 갖도록 변환되어 추출할 수 있다. 선택적 실시 예로서, 캡션 생성은 상기에서 추출된 이미지 특징을 이용하여 RNN(recurrent neural network) 알 고리즘을 통해 생성될 수 있으며, 이미지 및 이미지에 대한 캡션 데이터와 해석 강화 모듈을 통해 학습하는 단 계와 새로운 이미지에 대한 설명 문장을 추론하는 단계를 포함할 수 있다. 선택적 실시 예로서, 입력 이미지 내의 특정 오브젝트 영역 인식에는 Mask R-CNN이라는 오브젝트 인식 모델이 이용될 수 있다. 선택적 실시 예로서, 가중치 행렬 생성 시에 상기에서 인식된 오브젝트 영역들과 상기에서 생성된 캡션 문장 내 단어들에 대해서 각각 BiRNN(bidirectional recurrent neural network) 알고리즘과 CNN 알고리즘을 이용하여 같은 차원의 벡터 표현으로 변환하는 단계와 변환된 벡터 표현들을 이용하여 각 영역에 대한 단어 주의도 (attention score)를 계산하는 단계를 더 포함할 수 있다. 이상 설명된 본 발명에 따른 실시 예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그 램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이 때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 발명의 명세서(특히 특허청구범위에서)에서 \"상기\"의 용어 및 이와 유사한 지시 용어의 사용은 단수 및 복수 모두에 해당하는 것일 수 있다. 또한, 본 발명에서 범위(range)를 기재한 경우 상기 범위에 속하는 개별적인 값을 적용한 발명을 포함하는 것으로서(이에 반하는 기재가 없다면), 발명의 상세한 설명에 상기 범위를 구성하 는 각 개별적인 값을 기재한 것과 같다. 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 발명이 한정되는 것은 아니 다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위 가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물 의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한 다고 할 것이다."}
{"patent_id": "10-2019-0022992", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 이미지 캡션 자동 생성 장치를 개략적으로 설명하기 위하여 도시한 도면이 다. 도 2는 도 1에 도시된 캡션 생성 장치의 구성을 포함하여 최종 결과 생성의 절차를 도시한 흐름도이다.도 3은 도 2에 도시된 이미지 영역-단어 맵핑 모듈의 트레이닝 방법을 도시한 흐름도이다. 도 4는 도 2에 도시된 이미지 영역-단어 맵핑 모듈의 처리 예를 도시한 도면이다. 도 5는 도 1에 도시된 캡션 생성 장치의 트레이닝 방법을 도시한 흐름도이다. 도 6은 도 1에 도시된 캡션 생성 장치가 클라이언트로 반환하는 출력 이미지를 도시한 도면이다. 도 7은 본 발명의 일 실시 예에 따른 이미지 캡션 자동 생성 방법을 도시한 흐름도이다."}
