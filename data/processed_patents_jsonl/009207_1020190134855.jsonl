{"patent_id": "10-2019-0134855", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0006826", "출원번호": "10-2019-0134855", "발명의 명칭": "전자 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "변동남"}}
{"patent_id": "10-2019-0134855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,센서;카메라;객체를 식별하도록 학습된 제1 인공 지능 모델(Artificial Intelligence Model) 및 객체에 의해 일부가 가려진위험 객체를 식별하도록 학습된 제2 인공 지능 모델을 저장하는 스토리지;상기 센서 및 상기 스토리지와 연결되는 제1 프로세서; 및상기 카메라, 상기 스토리지 및 상기 제1 프로세서와 연결되는 제2 프로세서;를 포함하고,상기 제2 프로세서는,상기 스토리지에서 상기 제1 및 제2 인공 지능 모델을 로드하고, 상기 카메라를 통해 획득된 이미지를 상기 제1인공 지능 모델에 입력하여 상기 이미지에서 객체를 식별하고, 상기 카메라를 통해 획득된 이미지를 상기 제2인공 지능 모델에 입력하여 상기 이미지에서 상기 객체에 의해 일부가 가려진 위험 객체를 식별하고, 상기 식별된 객체에 대한 정보 및 상기 식별된 위험 객체에 대한 정보를 상기 제1 프로세서로 전송하고,상기 제1 프로세서는,상기 센서로부터 수신된 센싱 데이터에 기초하여 상기 객체와 상기 위험 객체 간의 거리를 판단하며, 상기 판단된 거리에 기초하여 상기 전자 장치가 상기 객체의 주변을 주행하도록 상기 전자 장치를 제어하는, 전자 장치."}
{"patent_id": "10-2019-0134855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,구동부;를 더 포함하고,상기 제1 프로세서는,상기 객체와 상기 위험 객체 간의 거리가 기설정된 값 이상이면, 상기 전자 장치가 상기 객체에 근접하여 주행하도록 상기 구동부를 제어하고,상기 객체와 상기 위험 객체 간의 거리가 기설정된 값 미만이면, 상기 전자 장치가 상기 객체 주변에 위치한 상기 위험 객체로부터 기설정된 거리 이상 떨어진 영역에서 주행하도록 상기 구동부를 제어하는, 전자 장치."}
{"patent_id": "10-2019-0134855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제1 프로세서는,상기 전자 장치가 상기 위험 객체로부터 상기 기설정된 거리 이상 떨어진 영역에서 주행하는 동안 상기 카메라를 통해 획득된 이미지에서 상기 위험 객체가 식별되지 않으면, 상기 전자 장치가 상기 객체에 근접하여 주행하도록 상기 구동부를 제어하는, 전자 장치."}
{"patent_id": "10-2019-0134855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제1 프로세서는,상기 센서로부터 수신된 센싱 데이터에 기초하여 상기 전자 장치 및 상기 객체 간의 제1 거리 및 상기 전자 장공개특허 10-2021-0006826-3-치 및 상기 위험 객체 간의 제2 거리를 판단하고, 상기 제1 및 제2 거리에 기초하여 상기 객체 및 상기 위험 객체 간의 거리를 판단하는, 전자 장치."}
{"patent_id": "10-2019-0134855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 스토리지는, 맵에 대한 정보, 및 맵에 포함된 복수의 구역 각각에 대응되는, 객체의 식별을 위한 상기 제1인공지능 모델 및 위험 객체의 식별을 위한 상기 제2 인공지능 모델을 저장하고, 상기 제1 프로세서는,상기 센서로부터 수신된 센싱 데이터를 기반으로 상기 맵에 포함되는 복수의 구역 중 상기 전자 장치가 위치하는 구역을 판단하고, 상기 판단된 구역에 대한 정보를 상기 제2 프로세서로 전송하고,상기 제2 프로세서는,상기 스토리지에 저장된 복수의 제1 인공지능 모델 중 상기 판단된 구역에 대응되는 제1 인공지능 모델에 상기이미지를 입력하여 상기 객체를 식별하고,상기 스토리지에 저장된 복수의 제2 인공지능 모델 중 상기 판단된 구역에 대응되는 제2 인공지능 모델에 상기이미지를 입력하여 상기 위험 객체를 식별하는, 전자 장치."}
{"patent_id": "10-2019-0134855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 위험 객체는, 상기 전자 장치와의 충돌에 의해 파손될 수 있는 객체, 상기 전자 장치의 흡입구에 스턱을 될 수 있는 객체 및동물의 배설물 중 적어도 하나를 포함하는, 전자 장치."}
{"patent_id": "10-2019-0134855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "전자 장치의 제어 방법에 있어서,카메라를 통해 이미지를 획득하는 단계;상기 카메라를 통해 획득된 이미지를 제1 인공 지능 모델에 입력하여 상기 이미지에서 객체를 식별하고, 상기카메라를 통해 획득된 이미지를 제2 인공 지능 모델에 입력하여 상기 이미지에서 상기 객체에 의해 일부가 가려진 위험 객체를 식별하는 단계;센서로부터 수신된 센싱 데이터에 기초하여 상기 객체와 상기 위험 객체 간의 거리를 판단하는 단계; 및상기 판단된 거리에 기초하여 상기 전자 장치가 상기 객체의 주변을 주행하도록 상기 전자 장치를 제어하는 단계;를 포함하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0134855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제어하는 단계는,상기 객체와 상기 위험 객체 간의 거리가 기설정된 값 이상이면, 상기 전자 장치가 상기 객체에 근접하여 주행하도록 상기 전자 장치를 제어하고,상기 객체와 상기 위험 객체 간의 거리가 기설정된 값 미만이면, 상기 전자 장치가 상기 객체 주변에 위치한 상기 위험 객체로부터 기설정된 거리 이상 떨어진 영역에서 주행하도록 상기 전자 장치를 제어하는, 전자 장치의제어 방법."}
{"patent_id": "10-2019-0134855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,공개특허 10-2021-0006826-4-상기 제어하는 단계는,상기 전자 장치가 상기 위험 객체로부터 상기 기설정된 거리 이상 떨어진 영역에서 주행하는 동안 상기 카메라를 통해 획득된 이미지에서 상기 위험 객체가 식별되지 않으면, 상기 전자 장치가 상기 객체에 근접하여 주행하도록 상기 전자 장치를 제어하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0134855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 거리를 판단하는 단계는,상기 센서로부터 수신된 센싱 데이터에 기초하여 상기 전자 장치 및 상기 객체 간의 제1 거리 및 상기 전자 장치 및 상기 위험 객체 간의 제2 거리를 판단하고, 상기 제1 및 제2 거리에 기초하여 상기 객체 및 상기 위험 객체 간의 거리를 판단하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0134855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,상기 전자 장치는, 맵에 대한 정보, 및 맵에 포함된 복수의 구역 각각에 대응되는, 객체의 식별을 위한 상기 제1 인공지능 모델 및위험 객체의 식별을 위한 상기 제2 인공지능 모델을 저장하고, 상기 식별하는 단계는,상기 센서로부터 수신된 센싱 데이터를 기반으로 상기 맵에 포함되는 복수의 구역 중 상기 전자 장치가 위치하는 구역을 판단하고, 상기 전자 장치에 저장된 복수의 제1 인공지능 모델 중 상기 판단된 구역에 대응되는 제1 인공지능 모델에 상기이미지를 입력하여 상기 객체를 식별하고,상기 전자 장치에 저장된 복수의 제2 인공지능 모델 중 상기 판단된 구역에 대응되는 제2 인공지능 모델에 상기이미지를 입력하여 상기 위험 객체를 식별하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0134855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서,상기 위험 객체는, 상기 전자 장치와의 충돌에 의해 파손될 수 있는 객체, 상기 전자 장치의 흡입구에 스턱을 될 수 있는 객체 및동물의 배설물 중 적어도 하나를 포함하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0134855", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 본 전자 장치는 센서, 카메라, 객체를 식별하도록 학습된 제1 인공 지능 모델(Artificial Intelligence Model) 및 객체에 의해 일부가 가려진 위험 객체를 식별하도록 학습된 제2 인공 지능 모델을 저장 하는 스토리지, 센서 및 스토리지와 연결되는 제1 프로세서 및 카메라, 스토리지 및 제1 프로세서와 연결되는 제 (뒷면에 계속)"}
{"patent_id": "10-2019-0134855", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 그 제어 방법에 관한 것으로, 보다 상세하게는 위험 객체를 식별할 수 있는 전자 장치 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2019-0134855", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 전자 기술의 발달로 다양한 전자 장치가 개발되고 있다. 특히, 최근에는 전자 장치 주변의 객체를 식별하 고, 객체를 회피하여 주행하는 전자 장치가 개발되고 있다. 일 예로, 최근에 개발된 로봇 청소기는 바닥에 놓인 컵을 식별하고, 컵과의 충돌을 방지하기 위해 컵을 회피하여 주행할 수 있다. 한편, 경우에 따라 객체는 다른 객체에 의해 일부가 가려질 수 있다. 예를 들어, 테이블의 다리 등에 컵의 일부 가 가려진 경우 등이다. 이 경우, 종래의 전자 장치는 컵을 식별하지 못하여, 컵과 충돌하는 문제가 있었다."}
{"patent_id": "10-2019-0134855", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2019-0134855", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 문제점을 해결하기 위해 안출된 것으로서, 본 개시의 목적은 다른 객체에 의해 일부가 가려진 위험 객체를 식별하고, 위험 객체를 회피하여 주행할 수 있는 전자 장치 및 그 제어 방법을 제공함에 있다."}
{"patent_id": "10-2019-0134855", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 개시의 일 실시 예에 따른 전자 장치는, 센서, 카메라, 객체를 식별하도록 학습 된 제1 인공 지능 모델(Artificial Intelligence Model) 및 객체에 의해 일부가 가려진 위험 객체를 식별하도록 학습된 제2 인공 지능 모델을 저장하는 스토리지, 상기 센서 및 상기 스토리지와 연결되는 제1 프로세서 및 상 기 카메라, 상기 스토리지 및 상기 제1 프로세서와 연결되는 제2 프로세서;를 포함하고, 상기 제2 프로세서는, 상기 스토리지에서 상기 제1 및 제2 인공 지능 모델을 로드하고, 상기 카메라를 통해 획득된 이미지를 상기 제1 인공 지능 모델에 입력하여 상기 이미지에서 객체를 식별하고, 상기 카메라를 통해 획득된 이미지를 상기 제2 인공 지능 모델에 입력하여 상기 이미지에서 상기 객체에 의해 일부가 가려진 위험 객체를 식별하고, 상기 식별 된 객체에 대한 정보 및 상기 식별된 위험 객체에 대한 정보를 상기 제1 프로세서로 전송하고, 상기 제1 프로세 서는, 상기 센서로부터 수신된 센싱 데이터에 기초하여 상기 객체와 상기 위험 객체 간의 거리를 판단하며, 상 기 판단된 거리에 기초하여 상기 전자 장치가 상기 객체의 주변을 주행하도록 상기 전자 장치를 제어할 수 있다. 그리고, 본 개시의 전자 장치는 구동부를 더 포함하고, 상기 제1 프로세서는, 상기 객체와 상기 위험 객체 간의 거리가 기설정된 값 이상이면, 상기 전자 장치가 상기 객체에 근접하여 주행하도록 상기 구동부를 제어하고, 상 기 객체와 상기 위험 객체 간의 거리가 기설정된 값 미만이면, 상기 전자 장치가 상기 객체 주변에 위치한 상기 위험 객체로부터 기설정된 거리 이상 떨어진 영역에서 주행하도록 상기 구동부를 제어할 수 있다. 그리고, 상기 제1 프로세서는, 상기 전자 장치가 상기 위험 객체로부터 상기 기설정된 거리 이상 떨어진 영역에 서 주행하는 동안 상기 카메라를 통해 획득된 이미지에서 상기 위험 객체가 식별되지 않으면, 상기 전자 장치가 상기 객체에 근접하여 주행하도록 상기 구동부를 제어할 수 있다. 그리고, 상기 제1 프로세서는, 상기 센서로부터 수신된 센싱 데이터에 기초하여 상기 전자 장치 및 상기 객체 간의 제1 거리 및 상기 전자 장치 및 상기 위험 객체 간의 제2 거리를 판단하고, 상기 제1 및 제2 거리에 기초 하여 상기 객체 및 상기 위험 객체 간의 거리를 판단할 수 있다. 그리고, 상기스토리지는, 맵에 대한 정보, 및 맵에 포함된 복수의 구역 각각에 대응되는, 객체의 식별을 위한 상기 제1 인공지능 모델 및 위험 객체의 식별을 위한 상기 제2 인공지능 모델을 저장하고, 상기 제1 프로세서는, 상기 센서로부터 수신된 센싱 데이터를 기반으로 상기 맵에 포함되는 복수의 구역 중 상기 전자 장 치가 위치하는 구역을 판단하고, 상기 판단된 구역에 대한 정보를 상기 제2 프로세서로 전송하고, 상기 스토리 지에 저장된 복수의 제1 인공지능 모델 중 상기 판단된 구역에 대응되는 제1 인공지능 모델에 상기 이미지를 입 력하여 상기 객체를 식별하고, 상기 스토리지에 저장된 복수의 제2 인공지능 모델 중 상기 판단된 구역에 대응 되는 제2 인공지능 모델에 상기 이미지를 입력하여 상기 위험 객체를 식별할 수 있다. 그리고, 상기 위험 객체는, 상기 전자 장치와의 충돌에 의해 파손될 수 있는 객체, 상기 전자 장치의 흡입구에 스턱을 될 수 있는 객체 및 동물의 배설물 중 적어도 하나를 포함할 수 있다. 한편, 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법은, 카메라를 통해 이미지를 획득하는 단계, 상기 카 메라를 통해 획득된 이미지를 제1 인공 지능 모델에 입력하여 상기 이미지에서 객체를 식별하고, 상기 카메라를 통해 획득된 이미지를 제2 인공 지능 모델에 입력하여 상기 이미지에서 상기 객체에 의해 일부가 가려진 위험 객체를 식별하는 단계, 센서로부터 수신된 센싱 데이터에 기초하여 상기 객체와 상기 위험 객체 간의 거리를 판 단하는 단계 및 상기 판단된 거리에 기초하여 상기 전자 장치가 상기 객체의 주변을 주행하도록 상기 전자 장치 를 제어하는 단계;를 포함할 수 있다. 그리고, 상기 제어하는 단계는, 상기 객체와 상기 위험 객체 간의 거리가 기설정된 값 이상이면, 상기 전자 장 치가 상기 객체에 근접하여 주행하도록 상기 전자 장치를 제어하고, 상기 객체와 상기 위험 객체 간의 거리가 기설정된 값 미만이면, 상기 전자 장치가 상기 객체 주변에 위치한 상기 위험 객체로부터 기설정된 거리 이상 떨어진 영역에서 주행하도록 상기 전자 장치를 제어할 수 있다. 그리고, 상기 제어하는 단계는, 상기 전자 장치가 상기 위험 객체로부터 상기 기설정된 거리 이상 떨어진 영역 에서 주행하는 동안 상기 카메라를 통해 획득된 이미지에서 상기 위험 객체가 식별되지 않으면, 상기 전자 장치 가 상기 객체에 근접하여 주행하도록 상기 전자 장치를 제어할 수 있다. 그리고, 상기 거리를 판단하는 단계는, 상기 센서로부터 수신된 센싱 데이터에 기초하여 상기 전자 장치 및 상 기 객체 간의 제1 거리 및 상기 전자 장치 및 상기 위험 객체 간의 제2 거리를 판단하고, 상기 제1 및 제2 거리 에 기초하여 상기 객체 및 상기 위험 객체 간의 거리를 판단할 수 있다. 그리고, 상기 전자 장치는, 객체를 식별하도록 학습된 제1 인공지능 모델, 및 위험 객체 및 상기 객체에 의해 일부가 가려진 상기 위험 객체를 식별하도록 학습된 제2 인공지능 모델을 저장하고, 상기 식별하는 단계는, 상 기 카메라를 통해 획득된 이미지를 상기 제1 인공지능 모델에 입력하여 상기 이미지에서 상기 객체를 식별하고, 상기 카메라를 통해 획득된 이미지를 상기 제2 인공지능 모델에 입력하여 상기 이미지에서 상기 객체에 의해 일 부가 가려진 상기 위험 객체를 식별할 수 있다. 그리고, 상기 전자 장치는, 맵에 대한 정보, 및 맵에 포함된 복수의 구역 각각에 대응되는, 객체의 식별을 위한 상기 제1 인공지능 모델 및 위험 객체의 식별을 위한 상기 제2 인공지능 모델을 저장하고, 상기 식별하는 단계 는, 상기 센서로부터 수신된 센싱 데이터를 기반으로 상기 맵에 포함되는 복수의 구역 중 상기 전자 장치가 위 치하는 구역을 판단하고, 상기 전자 장치에 저장된 복수의 제1 인공지능 모델 중 상기 판단된 구역에 대응되는 제1 인공지능 모델에 상기 이미지를 입력하여 상기 객체를 식별하고, 상기 전자 장치에 저장된 복수의 제2 인공 지능 모델 중 상기 판단된 구역에 대응되는 제2 인공지능 모델에 상기 이미지를 입력하여 상기 위험 객체를 식 별할 수 있다. 그리고, 상기 위험 객체는, 상기 전자 장치와의 충돌에 의해 파손될 수 있는 객체, 상기 전자 장치의 흡입구에 스턱을 될 수 있는 객체 및 동물의 배설물 중 적어도 하나를 포함할 수 있다."}
{"patent_id": "10-2019-0134855", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상과 같은 본 개시의 다양한 실시 예에 따르면, 위험 객체의 일부가 다른 객체에 의해 가려진 경우에도 위험 객체를 식별할 수 있고, 그 위험 객체를 회피하여 주행할 수 있는 전자 장치 및 그 제어 방법이 제공될 수 있다."}
{"patent_id": "10-2019-0134855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "먼저, 본 명세서 및 청구범위에서 사용되는 용어는 본 개시의 기능을 고려하여 일반적인 용어들을 선택하였다. 하지만, 이러한 용어들은 당 분야에 종사하는 기술자의 의도나 법률적 또는 기술적 해석 및 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 일부 용어는 출원인이 임의로 선정한 용어도 있다. 이러한 용어에 대해서는 본 명세서에서 정의된 의미로 해석될 수 있으며, 구체적인 용어 정의가 없으면 본 명세서의 전반적인 내용 및 당해 기술 분야의 통상적인 기술 상식을 토대로 해석될 수도 있다. 또한, 본 개시를 설명함에 있어서, 관련된 공지 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필 요하게 흐릴 수 있다고 판단되는 경우, 그에 대한 상세한 설명은 축약하거나 생략한다. 나아가, 이하 첨부 도면들 및 첨부 도면들에 기재된 내용들을 참조하여 본 개시의 실시 예를 상세하게 설명하지 만, 본 개시가 실시 예들에 의해 제한되거나 한정되는 것은 아니다. 이하, 첨부된 도면을 참조하여 본 개시를 상세히 설명한다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치의 동작을 개략적으로 설명하기 위한 도면이다. 전자 장치는 실내 공간을 주행하면서 전자 장치에 구비된 카메라를 통해 이미지를 획득할 수 있다. 여기에서, 카메라를 통해 획득된 이미지에는 소파, TV, 침대, 테이블, 옷장, 에어컨, 냉장고 등의 다양한 객체 가 포함될 수 있다. 또한, 카메라를 통해 획득된 이미지에는 위험 객체가 포함될 수도 있다. 여기에서, 위험 객체란 전자 장치(10 0)와의 충돌에 의해 파손될 수 있는 객체로서 컵, 화분 등이 될 수 있다. 다만, 이는 일 실시 예로서, 위험 객 체는 전자 장치의 흡입구에 스턱을 될 수 있는 객체로서 양말, 이어폰, 전선 등이 될 수도 있고, 실내 공 간을 오염시킬 수 있는 객체로서 동물의 배설물 등이 될 수도 있다. 전자 장치는 이미지에 포함된 객체 및/또는 위험 객체를 식별할 수 있다. 구체적으로, 전자 장치는 카메라를 통해 획득된 이미지를, 객체 식별을 수행하는 제1 인공 지능 모델에 입 력함으로써 이미지에 포함된 객체를 식별할 수 있고, 카메라를 통해 획득된 이미지를, 위험 객체 식별을 수행하 는 제2 인공 지능 모델에 입력함으로써 이미지에 포함된 위험 객체를 식별할 수 있다. 여기에서, 제1 인공 지능 모델은 이미지에 포함된 소파, TV, 침대, 테이블, 옷장, 에어컨, 냉장고 등의 객체를 식별하기 위해 학습된 모델이고, 제2 인공 지능 모델은 이미지에 포함된 컵, 양말 등의 위험 객체를 식별하기 위해 학습된 모델로서 제1 및 제2 인공 지능 모델 각각은 CNN(Convolutional Neural Network)으로 구현될 수 있다. 전자 장치는 이미지에 객체 및/또는 위험 객체가 포함되어 있는지 여부에 기초하여, 전자 장치의 주 행을 제어할 수 있다. 구체적으로, 전자 장치는 이미지에 객체가 포함되어 있는 경우이면, 객체에 근접하여 주행할 수 있다. 여 기에서, 근접하여 주행이란 객체로부터 제1 기설정된 거리만큼 떨어진 영역에서의 주행이 될 수 있다. 일 실시 예로, 제1 기설정된 거리가 1cm로 설정된 경우이면, 전자 장치는 객체로부터 1cm만큼 떨어진 영역까지 객체에 근접하여 주행할 수 있다. 또는, 근접하여 주행이란 객체에 접촉할 때까지의 주행이 될 수도 있다. 일 실시 예로, 전자 장치는 이미 지에 객체가 포함되어 있는 경우, 객체에 접촉할 때까지 객체를 향해 주행하고, 객체와 접촉되면 주행 방향을 변경할 수 있다. 한편, 전자 장치는 이미지에 위험 객체가 포함되어 있는 경우이면, 위험 객체를 회피하여 주행할 수 있다. 여기에서, 회피하여 주행이란 위험 객체로부터 제2 기설정된 거리만큼 떨어진 영역에서의 주행이 될 수 있다. 제2 기설정된 거리는 상술한 제1 기설정된 거리보다 클 수 있다. 일 실시 예로, 제2 기설정된 거리는 30cm로 설 정될 수 있고, 이 경우 전자 장치는 위험 객체로부터 30cm만큼 떨어진 영역까지 위험 객체에 근접하여 주 행하고, 전자 장치 및 위험 객체간의 거리가 제2 기설정된 거리에 도달하면, 전자 장치의 주행 방향 을 변경할 수 있다. 이에 따라, 본 개시의 전자 장치는 이미지 상에서 소파 등의 객체가 식별된 경우이면, 소파에 근접하여 주행하 고, 이미지 상에서 컵 등의 위험 객체가 식별되면, 컵을 회피하여 주행할 수 있다. 한편, 경우에 따라 위험 객체는 객체에 의해 일부가 가려질 수 있다. 예를 들어, 도 1을 참조하면, 위험 객체인 컵은 객체인 소파에 의해 일부가 가려질 수 있다. 이 경우, 종래의 전자 장치는 객체에 의해 가려진 위험 객체를 식별하지 못하여, 객체에 근접하여 주행하는 문 제가 있었다. 이에 따라, 종래의 전자 장치는 객체에 근접하여 주행하는 중에 위험 객체와 접촉 또는 충돌함으 로써, 위험 객체를 파손하는 등의 문제를 발생하였다. 이와 같은 문제를 방지하기 위해서, 본 개시의 전자 장치는 객체에 의해 일부가 가려진 위험 객체를 식별하고, 그 위험 객체를 회피하여 주행하는 동작을 수행할 수 있다. 이하, 도 2를 참조하여 이에 대해 상세히 설명한다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치를 설명하기 위한 블록도이다. 본 개시의 일 실시 예에 따른 전자 장치는 이동 가능한 전자 장치가 될 수 있다. 일 예로, 전자 장치(10 0)는 가정 내 공간을 주행하면서 청소 작업을 수행할 수 있는 로봇 청소기, 사람을 대신해 운전을 수행하는 자 동 주행 차량 또는 목적지까지 물품을 이동시킬 수 있는 자동 경로 차량(Automated Guided Vehicle) 중 하나가 될 수 있다. 다만, 이에 한정되는 것은 아니고, 전자 장치는 건물 내 공간을 주행하면서 공기 정화 작업을 수행할 수 있는 로봇, 가정 내 공간을 주행하며 의류 정리, 설거지 등의 작업을 수행할 수 있는 가사 지원형 로봇 또는 빌 딩 내 공간을 주행하며 경비를 수행할 수 있는 경비형 로봇 등과 같은 다양한 전자 장치로 구현될 수 있다. 또한, 전자 장치는 상술한 이동 가능한 전자 장치에 연결 또는 부착될 수 있는 디바이스로 구현될 수도 있 다. 도 2를 참조하면, 본 개시의 일 실시 예에 따른 전자 장치는 카메라, 센서, 스토리지 및 프로세서를 포함한다. 여기에서, 프로세서는 센서 및 스토리지와 연결되는 제1 프로세서 (140-1) 및, 카메라, 스토리지 및 제1 프로세서(140-1)와 연결되는 제2 프로세서(140-2)를 포함할 수 있다. 그리고, 제1 프로세서(140-1)는 CPU, AP 등과 같은 범용 프로세서 또는 GPU. VPU 등과 같은 그래픽 전용 프로세 서가 될 수 있고, 제2 프로세서(140-2)는 NPU와 같은 인공지능 전용 프로세서일 수 있으나, 반드시 이에 한정되 는 것은 아니다. 제2 프로세서(140-2)는 카메라를 통해 이미지를 획득할 수 있다. 구체적으로, 제2 프로세서(140-2)는 촬영 을 수행하도록 카메라를 제어하고, 카메라에 의해 촬영된 이미지를 카메라로부터 획득할 수 있 다. 여기에서, 촬영은 전자 장치의 주행 중에 수행될 수 있음은 물론, 전자 장치가 정지된 상태에서 수행될 수도 있다. 한편, 카메라는 RGB 카메라로 구현될 수 있으나, 반드시 이에 한정되는 것은 아니다. 제2 프로세서(140-2)는 카메라를 통해 획득된 이미지에서 객체 및/또는 위험 객체를 식별할 수 있다. 구체적으로, 제2 프로세서(140-2)는 스토리지에 저장된 제1 및 제2 인공 지능 모델을 제2 프로세서 (140-2)의 휘발성 메모리에 로드하고, 카메라를 통해 획득된 이미지를, 객체 식별을 수행하는 제1 인 공 지능 모델에 입력함으로써 이미지에 포함된 객체를 식별할 수 있고, 카메라를 통해 획득된 이미지를,위험 객체 식별을 수행하는 제2 인공 지능 모델에 입력함으로써 이미지에 포함된 위험 객체를 식별할 수 있다. 여기에서, 제1 인공 지능 모델은 이미지에 포함된 소파, TV, 침대, 테이블, 옷장, 에어컨, 냉장고 등의 객체를 식별하기 위해 학습된 모델이 될 수 있다. 일 예로, 제1 인공 지능 모델은 소파, TV, 침대, 테이블, 옷장, 에어 컨 또는 냉장고 등을 포함하는 이미지가 입력되면, 이미지의 특징 정보를 추출하는 컨볼루션 레이어 (Convolutional Layer) 및 추출된 특징 정보에 기초하여 이미지에 포함된 객체를 식별하도록 학습된 풀리-커넥 티드 레이어(Fully-connected Layer)를 포함하는 CNN Convolutional Neural Network)이 될 수 있다. 그리고, 제2 인공 지능 모델은 이미지에 포함된 위험 객체(가령, 컵, 화분, 양말, 배설물 등)를 식별하기 위해 학습된 모델이 될 수 있다. 일 예로, 제2 인공 지능 모델은 위험 객체를 포함하는 이미지가 입력되면, 이미지의 특징 정보를 추출하는 컨볼루션 레이어 및 추출된 특징 정보에 기초하여 이미지에 포함된 위험 객체를 식별하도 록 학습된 풀리-커넥티드 레이어를 포함하는 CNN이 될 수 있다. 또한, 제2 인공 지능 모델은 객체에 의해 일부가 가려진 위험 객체를 식별하기 위해 학습된 모델이 될 수도 있 다. 일 예로, 제2 인공 지능 모델은 객체에 의해 일부가 가려진 위험 객체를 포함하는 이미지가 입력되면, 이미 지의 특징 정보를 추출하는 컨볼루션 레이어 및 추출된 특징 정보에 기초하여 이미지에 포함된, 객체에 의해 일 부가 가려진 위험 객체를 식별하도록 학습된 풀리-커넥티드 레이어를 포함하는 CNN이 될 수 있다. 이와 관련된 보다 상세한 설명은 도 6a 내지 도 6c를 참조하여 후술한다. 그리고, 제2 프로세서(140-2)는 식별된 객체에 대한 정보 및 식별된 위험 객체에 대한 정보를 제1 프로세서 (140-1)로 전송할 수 있다. 제1 프로세서(140-1)는 이미지에 객체 및/또는 위험 객체가 포함되어 있는지를 판단할 수 있다. 구체적으로, 제 1 프로세서(140-1)는 제2 프로세서(140-2)로부터 객체에 대한 정보가 수신되면, 이미지에 객체가 포함된 것으로 판단하고, 제2 프로세서(140-2)로부터 위험 객체에 대한 정보가 수신되면, 이미지에 위험 객체가 포함된 것으로 판단할 수 있다. 그리고, 제1 프로세서(140-1)는 이미지에 객체 및/또는 위험 객체가 포함되어 있는지 여부에 기초하여, 전자 장 치의 주행을 제어할 수 있다. 구체적으로, 제1 프로세서(140-1)는 이미지에 객체가 포함되어 있는 경우이면, 객체에 근접하여 주행하도록 전 자 장치의 구동부(미도시)를 제어할 수 있다. 여기에서, 구동부는 바퀴로 구현될 수 있으나, 반드시 이에 한정되는 것은 아니고 구동부는 전자 장치를 이동시킬 수 있는 체인 등 다양한 형태로 구현될 수 있다. 한편, 근접하여 주행이란 객체로부터 제1 기설정된 거리만큼 떨어진 영역에서의 주행이 될 수 있다. 일 실시 예 로, 제1 기설정된 거리가 1cm로 설정된 경우이면, 제1 프로세서(140-1)는 전자 장치가 객체로부터 1cm만큼 떨어진 영역까지 근접하여 주행하도록 구동부를 제어할 수 있다. 또는, 근접하여 주행이란 객체에 접촉할 때까지의 주행이 될 수도 있다. 일 실시 예로, 제1 프로세서(140-1)는 이미지에 객체가 포함되어 있는 경우, 전자 장치가 객체에 접촉할 때까지 객체를 향해 주행하도록 구동부 를 제어하고, 객체와 접촉되면 전자 장치의 주행 방향을 변경하도록 구동부를 제어할 수 있다. 한편, 제1 프로세서(140-1)는 이미지에 위험 객체가 포함되어 있는 경우이면, 전자 장치가 위험 객체를 회 피하여 주행하도록 구동부를 제어할 수 있다. 여기에서, 회피하여 주행이란 위험 객체로부터 제2 기설정된 거리 만큼 떨어진 영역에서의 주행이 될 수 있다. 제2 기설정된 거리는 상술한 제1 기설정된 거리보다 클 수 있다. 일 실시 예로, 제2 기설정된 거리는 30cm로 설 정될 수 있고, 이 경우 제1 프로세서(140-1)는 전자 장치가 위험 객체로부터 30cm만큼 떨어진 영역까지 위 험 객체에 근접하여 주행하도록 구동부를 제어하고, 전자 장치 및 위험 객체간의 거리가 제2 기설정된 거 리에 도달하면, 제1 프로세서(140-1)는 전자 장치가 주행 방향을 변경하도록 구동부를 제어할 수 있다. 한편, 상술한 바와 같이, 제2 인공 지능 모델은 객체에 의해 일부가 가려진 위험 객체를 식별하기 위해 학습된 모델이 될 수 있다. 따라서, 도 1과 같이 위험 객체의 일부가 객체에 의해 가려진 경우에도, 제2 프로세서(140-2)는 제2 인 공 지능 모델을 이용하여 이미지에 포함된 위험 객체를 식별할 수 있다. 이 경우, 제1 프로세서(140-1)는 객체 및 위험 객체간의 거리에 기초하여, 구동부를 제어할 수 있다. 구체적으로, 제1 프로세서(140-1)는 객체와 위험 객체 간의 거리가 기설정된 값 이상이면, 전자 장치 가 객체에 근접하여 주행하도록 구동부를 제어할 수 있다. 즉, 제1 프로세서(140-1)는 객체와 위험 객체 간의 거리가 먼 것으로 판단되면, 전자 장치가 객체 에 근접하여 주행하도록 구동부를 제어할 수 있다. 이는, 카메라를 통해 획득된 이미지에 객체에 의해 일부가 가려진 위험 객체가 포함되어 있으나, 객체 및 위험 객체 간의 거리가 기설정된 값 이상인 경우이면, 객체에 근접하여 주행하더라도, 전 자 장치가 위험 객체에 충돌 또는 접촉할 염려가 없음을 고려한 것이다. 일 예로, 기설정된 값이 50cm인 경우, 제1 프로세서(140-1)는 객체와 위험 객체 간의 거리가 70cm로 판 단되면, 전자 장치가 객체에 근접하여 주행하도록 구동부를 제어할 수 있다. 이와 같이, 본 개시의 전자 장치는 이미지 상에서 위험 객체가 식별되더라도, 전자 장치가 위험 객체에 충돌 또는 접촉할 염려가 없는 경우이면, 객체에 근접하여 주행함로써, 객체 주변의 오염 물질을 흡입할 수 있다. 한편, 제1 프로세서(140-1)는 객체와 위험 객체 간의 거리가 기설정된 값 미만이면, 전자 장치가 객체 주변에 위치한 위험 객체로부터 기설정된 거리 떨어진 영역에서 주행하도록 구동부를 제어할 수 있다. 즉, 제1 프로세서(140-1)는 객체와 위험 객체 간의 거리가 가까운 것으로 판단되면, 전자 장치가 위험 객체에 근접하지 않도록 구동부를 제어할 수 있다. 이는, 객체 및 객체에 의해 일부가 가려진 위험 객체가 가까이 붙어 있는 경우이면, 전자 장치 가 객체에 근접하여 주행할 경우, 위험 객체에 전자 장치가 충돌 또는 접촉할 염려가 있음을 고려한 것이다. 일 예로, 기설정된 값이 50cm인 경우, 제1 프로세서(140-1)는 객체와 위험 객체 간의 거리가 40cm로 판 단되면, 전자 장치가 위험 객체를 회피하여 주행하도록 구동부를 제어할 수 있다. 이에 따라, 본 개시는 객체에 의해 일부가 가려진 위험 객체도 식별할 수 있고, 전자 장치가 위험 객체에 충돌 또는 접촉하지 않도록 전자 장치를 주행할 수 있다. 한편, 제1 프로세서(140-1)는 상술한 객체 및 위험 객체간의 거리를 센서로부터 수신한 센싱 데이 터에 기초하여 판단할 수 있다. 여기에서, 센싱 데이터는 센서의 종류에 따라 상이할 수 있다. 일 실시 예로, 센서가 3D 카메라 또는 뎁스 카메라로 구현되는 경우, 제1 프로세서(140-1)는 센서로부터 깊이 정보를 포함하는 이미지를 수신할 수 있다. 이 경우, 제1 프로세서(140-1)는 깊이 정보를 이용하여 전자 장치 및 객체 간의 제1 거리 및 전자 장치 및 위험 객체 간의 제2 거리를 판단하고, 제1 및 제2 거리의 차이를 객체 및 위험 객체 간의 거리로 판단할 수 있다. 또는, 센서가 라이다 센서로 구현되는 경우, 센서는 객체 및 위험 객체로 광을 조사하고, 그 광의 반사광이 수신된 시간에 기초하여 전자 장치 및 객체 간의 제1 거리 및 전자 장치 및 위험 객체 간의 제2 거리를 판단할 수 있다. 이 경우, 제1 프로세서(140-1)는 센서로부터 제1 및 제2 거리 에 관한 정보를 수신하고, 제1 및 제2 거리의 차이를 객체 및 위험 객체 간의 거리로 판단할 수 있다. 한편, 상술한 센서의 예는 일 실시 예로서, 본 개시는 거리를 산출할 수 있는 다양한 센서(가령, 이미지 센서)를 통해 객체 및 위험 객체 간의 거리를 판단할 수 있다고 볼 것이다. 상술한 바와 같이, 본 개시의 전자 장치는 카메라를 통해 획득된 이미지에 객체가 포함되어 있거 나, 객체로부터 기설정된 거리 이상 떨어진 위험 객체가 포함된 경우이면 객체에 근접하여 주행함 으로서 청소 작업 등을 효율적으로 수행하고, 카메라를 통해 획득된 이미지에 객체로부터 기설정된 거 리 미만으로 떨어진 위험 객체가 포함된 경우이면, 객체에 근접하지 않고, 위험 객체로부터 기설정 된 거리 이상 떨어진 영역에서 주행함으로서 위험 객체의 파손 등을 방지할 수 있다. 도 3a 및 도 3b는 본 개시의 일 실시 예에 따른 카메라를 통해 획득된 이미지에 객체가 포함된 경우, 전자 장치 의 주행 동작을 설명하기 위한 예시이다.제2 프로세서(140-2)는 카메라를 통해 획득된 이미지를, 객체 식별을 수행하는 제1 인공 지능 모델에 입력 함으로써 이미지에 포함된 객체를 식별할 수 있다. 여기에서, 제1 인공 지능 모델은 이미지에 포함된 소파, TV, 침대, 테이블, 옷장, 에어컨, 냉장고 등의 객체를 식별하기 위해 학습된 모델이 될 수 있다. 예를 들어, 제2 프로세서(140-2)는 카메라를 통해 획득된 도 3a에 도시된 바와 같은 이미지를, 제1 인공 지능 모델에 입력함으로써 이미지에 포함된 객체를 식별할 수 있다. 이와 같이, 전자 장치 주변에 객체는 존재하나 위험 객체는 존재하지 않는 경우, 제1 프로세서(140- 1)는 전자 장치가 객체에 근접하여 주행하도록 구동부를 제어할 수 있다. 구체적으로, 도 3b를 참조하면, 제1 프로세서(140-1)는 전자 장치가 객체로부터 제1 기설정된 거리만 큼 떨어진 영역(도면 부호 30의 외부)에서 주행하도록 구동부를 제어할 수 있다. 일 실시 예로, 제1 기설정된 거리가 1cm로 설정된 경우이면, 제1 프로세서(140-1)는 전자 장치가 객체로부 터 1cm만큼 떨어진 영역까지 근접하여 주행하도록 구동부를 제어할 수 있다. 또는, 제1 프로세서(140-1)는 전자 장치가 객체에 접촉할 때까지 객체를 향해 주행하도록 구동부를 제어하고, 전자 장치와 객체가 접촉되면 전자 장치의 주행 방향을 변경하도록 구동부를 제어할 수도 있다. 도 4a 및 도 4b는 본 개시의 일 실시 예에 따른 카메라를 통해 획득된 이미지에 위험 객체가 포함된 경우, 전자 장치의 주행 동작을 설명하기 위한 예시이다. 제2 프로세서(140-2)는 카메라를 통해 획득된 이미지를, 위험 객체 식별을 수행하는 제2 인공 지능 모델에 입력함으로써 이미지에 포함된 객체를 식별할 수 있다. 여기에서, 제2 인공 지능 모델은 이미지에 포함된 위험 객체(가령, 컵, 화분, 양말, 배설물 등)를 식별하기 위해 학습된 모델이 될 수 있다. 예를 들어, 제2 프로세서(140-2)는 카메라를 통해 획득된 도 4a에 도시된 바와 같은 이미지를, 제2 인공 지능 모델에 입력함으로써 이미지에 포함된 위험 객체를 식별할 수 있다. 이와 같이, 전자 장치 주변에 위험 객체가 존재하는 경우, 제1 프로세서(140-1)는 위험 객체를 회피하 여 주행하도록 구동부를 제어할 수 있다. 여기에서, 회피하여 주행이란 위험 객체로부터 제2 기설정된 거리만큼 떨어진 영역에서의 주행이 될 수 있다. 그리고, 제2 기설정된 거리는 상술한 제1 기설정된 거리보다 클 수 있다. 구체적으로, 도 4b를 참조하면, 제1 프로세서(140-1)는 전자 장치가 위험 객체로부터 제2 기설정된 거 리만큼 떨어진 영역(도면 부호 40의 외부)에서 주행하도록 구동부를 제어할 수 있다. 일 실시 예로, 제2 기설정된 거리가 30cm로 설정된 경우이면, 제1 프로세서(140-1)는 전자 장치가 위험 객 체로부터 30cm만큼 떨어진 영역까지 근접하여 주행하도록 구동부를 제어할 수 있다. 도 5a 내지 도 5d는 본 개시의 일 실시 예에 따른 카메라를 통해 획득된 이미지에 객체에 의해 일부가 가려진 위험 객체가 포함된 경우, 전자 장치의 주행 동작을 설명하기 위한 예시이다. 제2 프로세서(140-2)는 카메라를 통해 획득된 이미지를, 객체 식별을 수행하는 제1 인공 지능 모델에 입력 함으로써 이미지에 포함된 객체를 식별할 수 있고, 카메라를 통해 획득된 이미지를, 위험 객체 식별을 수 행하는 제2 인공 지능 모델에 입력함으로써 이미지에 포함된 위험 객체를 식별할 수 있다. 여기에서, 제2 인공 지능 모델을 이용하여 식별한 위험 객체는, 객체에 의해 일부가 가려진 위험 객체가 될 수 있다. 예를 들어, 제2 프로세서(140-2)는 카메라를 통해 획득된 도 5a 및 도 5c에 도시된 바와 같은 이미지(510, 520)를, 제1 인공 지능 모델에 입력함으로써 이미지에 포함된 객체를 식별할 수 있고, 카메라를 통해 획득된 이미지(510, 520)를, 제2 인공 지능 모델에 입력함으로써 이미지에 포함된 객체에 의해 일부가 가려 진 위험 객체를 식별할 수 있다. 이와 같이, 객체에 의해 일부가 가려진 위험 객체가 존재하는 경우, 제1 프로세서(140-1)는 객체 및 위험 객체 간의 거리를 센서로부터 수신한 센싱 데이터에 기초하여 판단할 수 있다. 일 예로, 센서가 3D 카메라 또는 뎁스 카메라로 구현되는 경우, 제1 프로세서(140-1)는 센서로부터 깊이 정보를 포함하는 이미지를 수신할 수 있다. 그리고, 제1 프로세서(140-1)는 깊이 정보를 이용하여 전자 장 치 및 객체 간의 제1 거리 및 전자 장치 및 위험 객체 간의 제2 거리를 판단하고, 제1 및 제2 거리의 차이를 객체 및 위험 객체 간의 거리로 판단할 수 있다. 한편, 이는 일 실시 예로서, 제1 프 로세서(140-1)는 라이다 센서 등 다양한 센서를 이용하여 객체 및 위험 객체 간의 거리를 판단할 수 있 다. 제1 프로세서(140-1)는 객체와 위험 객체 간의 거리가 기설정된 값 미만이면, 전자 장치가 객체 주변에 위치한 위험 객체로부터 기설정된 거리 떨어진 영역에서 주행하도록 구동부를 제어할 수 있다. 여기에서, 기설정된 값은 50cm가 될 수 있으나, 반드시 이에 한정되는 것은 아니다. 일 예로, 도 5a에 도시된 바와 같이, 객체 및 위험 객체간의 거리가 기설정된 값 미만이면, 제1 프로세 서(140-1)는 도 5b에 도시된 바와 같이, 전자 장치가 객체 주변에 위치한 위험 객체로부터 기설정 된 거리 이상 떨어진 영역(도면 부호 40의 외부)에서 주행하도록 구동부를 제어할 수 있다. 이와 같이, 본 개시는 객체에 의해 일부가 가려진 위험 객체도 식별할 수 있고, 전자 장치가 위험 객체에 충돌 또는 접촉하지 않도록 전자 장치의 주행을 제어할 수 있다. 한편, 제1 프로세서(140-1)는 전자 장치가 위험 객체로부터 기설정된 거리 이상 떨어진 영역에서 주행 하는 동안, 카메라를 통해 획득된 이미지에서 위험 객체가 더 이상 식별되지 않으면, 전자 장치 가 객체에 근접하여 주행하도록 구동부를 제어할 수 있다. 즉, 제1 프로세서(140-1)는 객체를 기준으로 설정된 영역 중에서, 위험 객체를 기준으로 설정된 영 역과 겹치는 영역에서는, 전자 장치가 위험 객체를 기준으로 설정된 영역 이상인 영역에서 주 행하도록 구동부를 제어하고, 객체를 기준으로 설정된 영역 중에서, 위험 객체를 기준으로 설정된 영역과 겹쳐지지 않는 영역에서는, 전자 장치가 객체를 기준으로 설정된 영역에 근접하여 주 행하도록 구동부를 제어할 수 있다. 이는, 카메라를 통해 획득한 이미지에서 더 이상 위험 객체가 식별되지 않는 경우이면, 객체에 근 접하여 주행하면서 청소 작업 등을 수행할 필요가 있기 때문이다. 한편, 제1 프로세서(140-1)는 객체와 위험 객체 간의 거리가 기설정된 값 이상이면, 전자 장치가 객체에 근접하여 주행하도록 구동부를 제어할 수 있다. 일 예로, 도 5c에 도시된 바와 같이, 객체 및 위험 객체 간의 거리가 기설정된 값 이상이면, 제1 프로 세서(140-1)는 전자 장치가 객체로부터 제1 기설정된 거리만큼 떨어진 영역까지 근접하여 주행하 도록 구동부를 제어할 수 있다. 이는, 카메라를 통해 획득된 이미지에 객체에 의해 일부가 가려진 위험 객체가 포함되어 있으나, 객체 및 위험 객체 간의 거리가 기설정된 값 이상인 경우이면, 객체에 근접하여 주행하더라도, 위 험 객체에 전자 장치가 충돌 또는 접촉할 염려가 없음을 고려한 것이다. 일 예로, 기설정된 값이 50cm인 경우, 제1 프로세서(140-1)는 객체와 위험 객체 간의 거리가 70cm로 판 단되면, 전자 장치가 객체에 근접하여 주행하도록 구동부를 제어할 수 있다. 이와 같이, 본 개시는 이미지 상에서 위험 객체가 식별되더라도, 전자 장치가 위험 객체에 충돌 또는 접촉할 염려가 없는 경우이면, 객체에 근접하여 주행함으로써, 객체 주변의 오염 물질을 흡입할 수 있다. 도 6a 내지 도 6c는 본 개시의 일 실시 예에 따른 제1 및 제2 인공 지능 모델을 설명하기 위한 도면이다. 본 개시의 일 실시 예에 따른 제1 및 제2 인공 지능 모델은 복수의 신경망 레이어들로 구성될 수 있다. 그리고, 각 레이어는 복수의 가중치(weight values)를 가지고 있으며, 이전(previous) 레이어의 연산 결과 및 복수의 가 중치에 기초하여 연산을 수행할 수 있다. 일 실시 예로, 제1 및 제2 인공 지능 모델은, CNN (Convolutional Neural Network)이 될 수 있으나, 반드시 이에 한정되는 것은 아니고, DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크 (Deep Q-Networks)과 같은 다양한 인공 지능 모델로 구현될 수 있다. 제1 및 제2 인공지능 모델은, 다양한 학습 알고리즘을 통해 전자 장치 또는 별도의 서버/시스템을 통해 학 습된 것일 수 있다. 학습 알고리즘은, 다수의 학습 데이터들을 이용하여 소정의 대상 기기(예컨대, 로봇)를 훈 련시켜 소정의 대상 기기 스스로 결정을 내리거나 예측을 할 수 있도록 하는 알고리즘이다. 본 개시의 일 실시예에 따른 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 될 수 있으 나, 반드시 이에 한정되는 것은 아니다. 제1 및 제2 인공지능 모델 각각은, 컨볼루션 레이어 및 컨볼루션 레이어를 통해 추출된 특징 정보에 기초하여 적어도 하나의 객체를 식별하도록 학습된 풀리-커넥티드 레이어를 포함할 수 있다. 여기에서, 컨볼루션 레이어는 제1 및 제2 인공지능 모델에 공통된 레이어이고, 풀리-커넥티드 레이어는 제1 및 제2 인공지능 모델 각각에 개별적으로 마련되는 레이어일 수 있다. 제1 및 제2 인공지능 모델 각각을 구성하는 풀리-커넥티드 레이어 각각은, 컨볼루션 레이어로부터 출력된 특징 정보로부터 적어도 하나의 객체를 식별하도록 학습된 레이어일 수 있다. 일 예로, 제1 인공 지능 모델의 풀리- 커넥티드 레이어는 객체를 식별하도록 학습된 레이어가 될 수 있고, 제2 인공 지능 모델의 풀리-커넥티드 레이 어는 위험 객체를 식별하도록 학습된 레이어가 될 수 있다. 예를 들어, 제1 인공 지능 모델은, 도 6a를 참조하면, 소파, 테이블, 침대 등의 이미지가 입력되면, 컨볼루션 레이어를 통해 이미지의 특징 정보를 추출하고, 컨볼루션 레이어로부터 출력된 특징 정보로부터 객체를 식별하 도록 풀리-커넥티드 레이어의 복수의 가중치를 학습한 모델이 될 수 있다. 그리고, 제2 인공 지능 모델은, 도 6b를 참조하면, 컵, 양말, 강아지 배설물 등의 이미지가 입력되면, 컨볼루션 레이어를 통해 이미지의 특징 정보를 추출하고, 컨볼루션 레이어로부터 출력된 특징 정보로부터 위험 객체를 식 별하도록 풀리-커넥티드 레이어의 복수의 가중치를 학습한 모델이 될 수 있다. 또한, 제2 인공 지능 모델은, 도 6c를 참조하면, 소파에 의해 일부가 가려진 컵을 포함하는 복수의 이미지가 입 력되면, 컨볼루션 레이어를 통해 이미지의 특징 정보를 추출하고, 컨볼루션 레이어로부터 출력된 특징 정보로부 터 위험 객체를 식별하도록 풀리-커넥티드 레이어의 복수의 가중치를 학습한 모델이 될 수 있다. 그리고, 풀리-커넥티드 레이어 각각은, 적어도 하나의 객체가 해당 이미지에 포함될 확률 값을 객체 별로 출력 할 수도 있다. 한편, 여기서는 제2 인공 지능 모델이 위험 객체를 포함하는 이미지 및, 객체에 의해 일부가 가려진 위험 객체 를 포함하는 이미지를 입력으로 학습을 수행하는 것으로 설명하였으나, 이는 일 실시 예일 뿐이다. 일 예로, 객체에 의해 일부가 가려진 위험 객체를 포함하는 이미지를 입력으로 학습을 수행하는 모델은, 제1 및 제2 인공 지능 모델과는 별개의 제3 인공 지능 모델이 될 수도 있다. 이 경우, 제2 프로세서(140-2)는 제1 인공 지능 모델을 이용하여 이미지에서 객체를 식별하고, 제2 인공 지능 모델을 이용하여 이미지에서 위험 객체를 식별하며, 제3 인공 지능 모델을 이용하여, 이미지에서 객체에 의해 일부가 가려진 위험 객체를 식별할 수 있다. 또한, 여기서는 복수의 인공 지능 모델을 이용하여, 객체 및 위험 객체를 식별하는 것으로 설명하였으나, 실시 예에 따라 본 개시는 하나의 인공 지능 모델을 이용하여 이미지에 포함된 객체 및 위험 객체를 식별할 수도 있 다. 이 경우, 인공 지능 모델은 객체를 포함하는 이미지, 위험 객체를 포함하는 이미지 및 객체에 의해 일부가 가려 진 위험 객체를 포함하는 이미지를 입력 데이터로, 이미지에서 객체, 위험 객체 및 객체에 의해 일부가 가려진 위험 객체를 식별하도록 학습된 모델이 될 수 있다. 전자 장치가 컨볼루션 레이어 및 풀리-커넥티드 레이어를 포함하는 인공지능 모델을 이용하여 객체 인식을 수행하는 구체적인 예로, 제2 프로세서(140-2)는 컨볼루션 레이어에 카메라를 통해 획득된 이미지를 입력 할 수 있다. 그리고, 컨볼루션 레이어를 통해 출력된 특징 정보가 풀리-커넥티드 레이어에 입력되면, 제2 프로 세서(140-2)는 풀리-커넥티드 레이어를 통해 출력되는 데이터를 이용하여 객체 또는 위험 객체가 이미지에 포함 되는 확률을 획득할 수 있다. 그리고, 제2 프로세서(140-2)는, 획득된 확률을 임계 값과 비교하여, 획득된 확률이 임계 값보다 큰 경우 입력 된 이미지에 객체 또는 위험 객체가 포함되어 있다고 식별할 수 있다. 한편, 상술한 객체를 식별하도록 학습된 제1 인공지능 모델 및, 위험 객체 및/또는 객체에 의해 일부가 가려진 위험 객체를 식별하도록 학습된 제2 인공지능 모델은 전자 장치의 스토리지에 기저장되어 있을 수 있음은 물론, 외부 장치(가령, 서버)와의 통신을 통해 외부 장치로부터 수신되어 스토리지에 저장될 수도 있 다. 도 7a 내지 도 7c는 본 개시의 일 실시 예에 따른 전자 장치가 구역별로 상이한 인공 지능 모델을 이용하여 객 체 및/또는 위험 객체를 식별하는 실시 예를 설명하기 위한 도면이다. 전자 장치의 스토리지는 맵에 대한 정보를 저장할 수 있다. 여기에서, 맵은 복수의 구역을 포함 하고, 맵에 대한 정보는 복수의 구역 각각의 구조에 대한 정보를 포함할 수 있다. 일 예로, 도 7a를 참조하면, 맵은 거실(1-1), 침실(1-2) 및 주방을 포함하고, 맵에 대한 정보는 거실(1-1)의 구조에 대한 정보, 침실 (1-2)의 구조에 대한 정보 및 주방의 구조에 대한 정보를 포함할 수 잇다. 여기에서, 각 구역의 구조에 대한 정보는, 각 구역의 모양, 형태, 크기 또는 해당 구역에 위치하는 가구의 모양, 배치 상태 등에 기초하여 결정될 수 있다. 일 예로, 거실(1-1)의 구조에 대한 정보는, 거실(1-1) 자체의 모양, 형태 또는 크기와 거실(1-1)에 위치한 TV, 소파 등의 모양 및 배치 상태 등에 기초하여 결정될 수 있다. 제1 프로세서(140-1)는 센서로부터 수신된 센싱 데이터를 기반으로 맵에 포함되는 복수의 구역 중 전자 장 치가 위치하는 구역을 판단할 수 있다. 일 예로, 센서가 라이다 센서인 경우, 제1 프로세서(140-1)는 센서로부터 전자 장치가 위치한 구역의 구조에 대한 정보를 포함하는 센싱 데이터를 수신할 수 있다. 그리고, 제1 프로세서(140-1)는 센싱 데이 터에 포함된 구조에 대한 정보를, 스토리지에 기저장된 각 구역의 구조에 대한 정보와 비교하고, 기저장된 복수의 구조에 대한 정보 중에서, 센싱 데이터에 포함된 구조에 대한 정보와 기설정된 임계 값 이상 일치하는 구조에 대한 정보를 판단할 수 있다. 그리고, 제1 프로세서(140-1)는 판단된 구조에 대한 정보에 매칭된 구역을, 전자 장치가 위치하는 구역으로 판단할 수 있다. 한편, 센서가 3D 카메라 또는 뎁스 카메라로 구현되는 경우, 제1 프로세서(140-1)는 3D 카메라 또는 뎁스 카메라를 통해 획득된 이미지를 이용하여, 전자 장치가 위치하는 구역을 판단할 수도 있다. 이 경우, 기저 장된 맵에 대한 정보에는 복수의 구역 각각의 3D 이미지에 대한 정보가 포함될 수 있다. 구체적으로, 제1 프로세서(140-1)는 센서로부터 3D 이미지에 대한 정보를 포함하는 센싱 데이터를 수신할 수 있다. 그리고, 제1 프로세서(140-1)는 센싱 데이터에 포함된 3D 이미지에 대한 정보를, 스토리지에 기저장된 각 구역의 3D 이미지에 대한 정보와 비교하고, 기저장된 복수의 3D 이미지에 대한 정보 중에서, 센싱 데이터에 포함된 3D 이미지에 대한 정보와 기설정된 임계 값 이상 일치하는 3D 이미지에 대한 정보를 판단할 수 있다. 그 리고, 제1 프로세서(140-1)는 판단된 3D 이미지에 대한 정보에 매칭된 구역을, 전자 장치가 위치하는 구역 으로 판단할 수 있다. 한편, 상술한 실시 예는 일 실시 예일 뿐, 본 개시의 전자 장치는 다양한 방법을 통해 전자 장치가 위치하는 구역을 판단할 수 있다. 일 예로, 전자 장치는 복수의 구역 별로, 각 구역에 위치하는 객체에 대 한 정보를 저장하고, 제1 프로세서(140-1)는 카메라를 통해 획득된 이미지에서 식별된 객체가 위치하는 구 역에 기초하여, 전자 장치의 위치를 판단할 수 있다. 예를 들어, 전자 장치가 거실에는 소파에 대한 정보를 매칭하여 저장하고, 침실에는 침대에 대한 정보를 매칭하여 저장하는 경우, 제1 프로세서(140-1)는 카메 라를 통해 획득된 이미지에서 소파가 식별되면, 전자 장치는 거실에 위치하는 것으로 판단할 수 있다. 그리고, 제1 프로세서(140-1)는 판단된 구역에 대한 정보를 제2 프로세서(140-2)로 전송할 수 있다. 한편, 도 7b를 참조하면, 전자 장치는 복수의 구역 별로, 서로 다른 제1 인공 지능 모델(즉, 객체 인식 모 델) 및 제2 인공 지능 모델(즉, 위험 객체 인식 모델)을 저장할 수 있다. 여기에서, 제1 구역에 매칭된 제1 인공 지능 모델은 제1 구역에 위치할 수 있는 객체를 식별하도록 학습된 모델 이고, 제1 구역에 매칭된 제2 인공 지능 모델은 위험 객체 및/또는 제1 구역에 위치할 수 있는 객체에 의해 일 부가 가려진 위험 객체를 식별하도록 학습된 모델이 될 수 있다. 마찬가지로, 제2 구역에 매칭된 제1 인공 지능 모델은 제2 구역에 위치할 수 있는 객체를 식별하도록 학습된 모델이고, 제2 구역에 매칭된 제2 인공 지능 모델 은 위험 객체 및/또는 제2 구역에 위치할 수 있는 객체에 의해 일부가 가려진 위험 객체를 식별하도록 학습된 모델이 될 수 있다. 그리고, 제3 구역에 매칭된 제1 인공 지능 모델은 위험 객체 및/또는 제3 구역에 위치할 수 있는 객체를 식별하도록 학습된 모델이고, 제3 구역에 매칭된 제2 인공 지능 모델은 제3 구역에 위치할 수 있는 객체에 의해 일부가 가려진 위험 객체를 식별하도록 학습된 모델이 될 수 있다. 일 예로, 제1 구역이 거실인 경우, 제1 구역에 매칭된 제1 인공 지능 모델은 거실에 위치할 수 있는 소파, TV, 에어컨 등의 객체를 식별하도록 학습된 모델이고, 제1 구역에 매칭된 제2 인공 지능 모델은 위험 객체 및/또는 거실에 위치할 수 있는 객체에 의해 일부가 가려진 컵, 양말 등의 위험 객체를 식별하도록 학습된 모델이 될 수 있다. 그리고, 제2 구역이 침실인 경우, 제2 구역에 매칭된 제1 인공 지능 모델은 침실에 위치할 수 있는 침대, 옷장, 화장대 등의 객체를 식별하도록 학습된 모델이고, 제1 구역에 매칭된 제2 인공 지능 모델은 위험 객체 및 /또는 침실에 위치할 수 있는 객체에 의해 일부가 가려진 컵, 양말 등의 위험 객체를 식별하도록 학습된 모델이 될 수 있다. 그리고, 제3 구역이 주방인 경우, 제3 구역에 매칭된 제1 인공 지능 모델은 거실에 위치할 수 있는 식탁, 의자, 냉장고 등의 객체를 식별하도록 학습된 모델이고, 제3 구역에 매칭된 제2 인공 지능 모델은 위험 객체 및/또는 주방에 위치할 수 있는 객체에 의해 일부가 가려진 컵, 양말 등의 위험 객체를 식별하도록 학습된 모델이 될 수 있다. 한편, 상술한 제1 내지 제3 구역은 일 실시 예로, 각 구역의 명칭은 실시 예에 따라 상이할 수 있고, 각 구역의 개수는 다양할 수 있다. 제2 프로세서(140-2)는 스토리지에 저장된 복수의 제1 인공 지능 모델 중에서, 전자 장치가 위치하는 구역 에 대응되는 제1 인공 지능 모델 및, 스토리지에 저장된 복수의 제2 인공 지능 모델 중에서, 전자 장치가 위치하는 구역에 대응되는 제2 인공 지능 모델을 판단할 수 있다. 일 예로, 제2 프로세서(140-2)는 전자 장치가 거실(1-1)에 위치하는경우, 복수의 제1 인공 지능 모델 중에 서 거실에 위치할 수 있는 소파, TV, 에어컨 등의 객체를 식별하도록 학습된 제1 인공 지능 모델 및, 복수의 제 2 인공 지능 모델 중에서 위험 객체 및/또는 거실에 위치할 수 있는 객체에 의해 일부가 가려진 컵, 양말 등의 위험 객체를 식별하도록 학습된 제2 인공 지능 모델을 판단할 수 있다. 그리고, 제2 프로세서(140-2)는 판단된 제1 인공 지능 모델에 카메라를 통해 획득된 이미지를 입력하여, 이미지에 포함된 객체를 식별하고, 판단된 제2 인공지능 모델에 카메라를 통해 획득된 이미지를 입력하여, 이미지에 포함된 위험 객체 및/또는 객체에 의해 일부가 가려진 위험 객체를 식별할 수 있다. 일 예로, 도 7c를 참조하면, 제2 프로세서(140-2)는 전자 장치가 거실(1-1)에 위치하는 것으로 판단되면, 복수의 제1 및 제2 인공 지능 모델 중에서 거실(1-1)에 대응되는 제1 및 제2 인공 지능 모델을 판단하고, 제1 인공 지능 모델을 이용하여 이미지에 포함된 객체를 식별하고, 제2 인공 지능 모델을 이용하여 이미지에 포함된 위험 객체 및/또는 또는 객체에 의해 일부가 가려진 위험 객체를 식별할 수 있다. 이와 같이, 각 구역에 특화된 인공 지능 모델을 이용하여 객체 및/또는 위험 객체를 식별함으로써, 본 개시의 전자 장치는 이미지에 포함된 객체 및/또는 위험 객체를 보다 정확하게 식별할 수 있다. 또한, 각 구역의 인공 지능모델은 각 구역에 위치할 수 있는 객체 또는 그 객체에 의해 일부가 가려질 수 있는 위험 객체를 식별 하기 위해 학습된 모델로서, 장소와 상관 없이 모든 객체를 식별하도록 학습된 인공 지능 모델에 비하여 경량화 된 인공 지능 모델이 될 수 있고, 이에 따라 본 개시는 메모리 부담 및 프로세서의 연산 부담을 최소화 시킬 수 있다. 도 8은 본 개시의 일 실시 예에 따른 전자 장치를 설명하기 위한 블록도이다. 이상에서는, 프로세서는 제1 프로세서(140-1) 및 제2 프로세서(140-2)를 포함하고, 제1 프로세서(140-1)는 전자 장치가 위치하는 구역을 판단하는 등의 동작을 수행하고, 제2 프로세서(140-2)는 인공 지능 모델을 이용하여 객체 또는 위험 객체를 식별하는 등의 동작을 수행하는 것으로 설명하였다. 다만, 실시 예에 따라, 상 술한 일련의 동작들은 하나의 프로세서에 의해 수행될 수도 있다. 도 8을 참조하면, 본 개시의 일 실시 예에 따른 전자 장치는 카메라, 센서, 스토리지, 구 동부, 및 프로세서를 포함할 수 있다 여기에서, 스토리지는 장소 스캔 모듈, 모델 로딩 모듈, 객체 식별 모듈, 위험 객체 식별부, 객체 거리 계산 모듈 및 수행 동작 판단 모듈을 저장할 수 있다. 그리고, 각 모듈은 프로세서에 의해 RAM(Random Access Memory)과 같은 비휘발성 메모리에 로딩될 수 있으며, 프로 세서는 로딩된 모듈에 대응하는 인스트럭션을 실행할 수 있다. 프로세서는 장소 스캔 모듈을 로딩하여, 전자 장치가 위치하는 장소를 판단할 수 있다. 구체적으로, 프로세서는 장소 스캔 모듈을 로딩하고, 장소 스캔 모듈에 대응하는 인스트럭션을 실행함으로써, 센서 로부터 센싱 데이터를 수신하고, 센싱 데이터에 기초하여 맵에 포함된 복수의 구역 중에서, 전자 장치 가 위치하는 구역을 판단할 수 있다. 여기에서, 센싱 데이터는 일 예로, 라이다 센서에 의해 획득된 데이 터 2D 카메라에 의해 획득된 데이터 또는 3D 카메라에 의해 획득된 데이터가 될 수 있으나, 반드시 이에 한정되는 것은 아니다. 프로세서는 모델 로딩 모듈을 로딩하여, 전자 장치가 위치하는 구역에 대응되는 인공 지능 모델을 로 딩할 수 있다. 구체적으로, 프로세서는 모델 로딩 모듈을 로딩하고, 모델 로딩 모듈에 대응하는 인스트럭 션을 실행함으로써, 스토리지에 저장된 복수의 제1 및 제2 인공 지능 모델 중에서, 전자 장치가 위치 하는 구역에 대응되는 제1 및 제2 인공 지능 모델을 로딩할 수 있다. 일 예로, 프로세서는 전자 장치(10 0)가 거실에 위치하는 경우, 거실에 포함될 수 있는 객체를 식별하도록 학습된 제1 인공 지능 모델 및 그 객체 에 의해 일부가 가려진 위험 객체를 식별하도록 학습된 제2 인공 지능 모델을 로딩할 수 있다. 프로세서는 객체 식별 모듈을 로딩하고, 객체 식별 모듈에 대응하는 인스트럭션을 실행함으로써, 카메라 를 통해 획득된 이미지를 제1 인공 지능 모델에 입력하고, 이미지에 포함된 객체를 식별할 수 있다. 그리 고, 프로세서는 위험 객체 식별 모듈을 로딩하고, 위험 객체 식별 모듈에 대응하는 인스트럭션을 실행함으 로써, 카메라를 통해 획득된 이미지를 제2 인공 지능 모델에 입력하고, 이미지에 포함된 위험 객체를 식별 할 수 있다. 여기에서, 위험 객체는 객체에 의해 일부가 가려진 위험 객체가 될 수 있음은 물론, 객체에 의해 가려지지 않은 위험 객체가 될 수도 있다. 프로세서는 객체 거리 계산 모듈을 로딩하여, 객체 및 위험 객체간의 거리를 판단할 수 있다. 구체적으로, 프로세서는 객체 거리 계산 모듈을 로딩하고, 객체 거리 계산 모듈에 대응하는 인스트럭션을 실행함으로써, 센서로부터 센싱 데이터를 수신하고, 수신된 센싱 데이터에 기초하여, 객체 및 위험 객체간 의 거리를 판단할 수 있다. 구체적으로, 프로세서는 센서로부터 전자 장치 및 객체간의 제1 거 리에 대한 정보 및 전자 장치 및 위험 객체간의 제2 거리에 대한 정보를 수신하고, 제1 및 제2 거리 간의 차이를 계산할 수 있다. 그리고, 프로세서는 그 차이를 객체 및 위험 객체간의 거리로 판단할 수 있다. 한 편, 여기에서 센싱 데이터는 일 예로, 라이다 센서에 의해 획득된 데이터 또는 3D 카메라에 의해 획득된 데이터 가 될 수 있으나, 반드시 이에 한정되는 것은 아니다. 프로세서는 수행 동작 판단 모듈을 로딩하여, 구동부를 제어할 수 있다. 구체적으로, 프로세서 는 수행 동작 판단 모듈을 로딩하고, 수행 동작 판단 모듈에 대응하는 인스트럭션을 실행함으로써, 전자 장치 의 주행을 제어할 수 있다. 일 예로, 프로세서는 카메라를 통해 획득된 이미지에 객체가 포 함되어 있거나, 객체로부터 기설정된 거리 이상 떨어진 위치에 위험 객체가 포함된 것으로 판단되면, 전자 장치가 객체에 근접하여 주행하도록 구동부를 제어할 수 있다. 또는, 프로세서는 카메 라를 통해 획득된 이미지에 객체로부터 기설정된 거리 미만으로 떨어진 위험 객체가 포함된 것으 로 판단되면, 전자 장치가 객체에 근접하지 않고, 위험 객체로부터 기설정된 거리 이상 떨어진 영 역에서 주행하도록 구동부를 제어할 수 있다. 스토리지는 전자 장치의 구성요소의 전반적인 동작을 제어하기 위한 운영체제(Operating System: OS) 및 전자 장치의 구성요소와 관련된 명령 또는 데이터를 저장할 수 있다. 이에 따라, 프로세서는 스토리지에 저장된 다양한 명령 또는 데이터 등을 이용하여 전자 장치의 다수의 하드웨어 또는 소프트웨어 구성요소들을 제어할 수 있고, 다른 구성요소들 중 적어도 하나로부터 수신된 명령 또는 데이터를 휘발성 메모리에 로드(load)하여 처리하고, 다양한 데이터를 비휘발성 메모리에 저장 (store)할 수 있다. 특히, 스토리지는 제1 및 제2 인공 지능 모델을 저장할 수 있다. 전술한 바와 같이, 여기에서 제1 인공 지 능 모델은 이미지에 포함된 객체를 식별하기 위한 모델이 될 수 있고, 제2 인공 지능 모델은 이미지에 포함된 위험 객체 및/또는 객체에 의해 일부가 가려진 위험 객체를 식별하기 위한 모델이 될 수 있다. 또한, 스토리지 는 복수의 구역 별로, 제1 및 제2 인공 지능 모델을 저장할 수도 있다. 도 9a 및 도 9b는 본 개시의 일 실시 예에 따른 인공 지능 모델의 업데이트를 설명하기 위한 도면이다. 전자 장치는 외부 장치와 통신을 수행하여 다양한 데이터를 송수신할 수 있다. 이를 위해, 전자 장치는 외부 장치와 통신을 수행하기 위한 통신부를 더 포함할 수 있고, 여기에서 통신부는 블루투스 칩, 와이파이 칩 또는 무선 통신 칩으로 구현될 수 있다. 한편, 외부 장치는 도 9a에 도시된 바와 같이 스마트 폰이 될 수 있으나, 반드시 이에 한정되는 것은 아니 고, PC, 노트북, 태블릿 등과 같이 디스플레이를 구비한 다양한 전자 장치로 구현될 수 있다. 프로세서는 카메라를 통해 획득된 이미지를 인공 지능 모델에 입력할 수 있다. 이 경우, 제1 인공 지 능 모델은 이미지에 객체가 포함되어 있을 확률을 출력하고, 제2 인공 지능 모델은 이미지에 위험 객체가 포함 되어 있을 확률을 출력할 수 있다. 일 예로, 도 9b에 도시된 바와 같이, 전선을 포함하는 이미지를 제2 인공 지능 모델에 입력할 경우, 제2 인공 지능 모델은 이미지에 전선이 포함되어 있을 확률을 출력할 수 있다. 이 경우, 프로세서는 인공 지능 모델에 의해 출력된 데이터를 통신부를 통해 외부 장치로 전송할 수 있다. 여기에서, 외부 장치로 전송되는 데이터는 인공 지능 모델에 의해 판단된, 이미지 내에서 객체 및/ 또는 위험 객체가 위치하는 영역에 대한 정보 및 이미지에 객체 및/또는 위험 객체가 포함되어 있을 확률에 대 한 정보를 포함할 수 있다. 여기에서, 영역에 대한 정보는, 이미지 내의 객체 및/또는 위험 객체에 대응되는 바 운딩 박스의 좌표에 대한 정보를 포함할 수 있다. 다만, 반드시 이에 한정되는 것은 아니고, 영역에 대한 정보 는 이미지 내의 객체 및/또는 위험 객체에 대응되는 세그먼테이션(segmentation) 정보를 포함할 수도 있다. 외부 장치는 전자 장치로부터 수신한 데이터에 기초하여, 이미지 내에서 객체 및/또는 위험 객체가 위치하는 영역 및 이미지에 객체 및/또는 위험 객체가 포함되어 있을 확률을 디스플레이 할 수 있다. 일 예로, 도 9b를 참조하면, 외부 장치는 전자 장치로부터 수신한 바운딩 박스의 좌표에 대한 정보에 기초하여, 이미지 내에서 전선이 위치하는 영역에 바운딩 박스를 디스플레이 하고, 해당 이미지에서 전선이 포 함되어 있을 확률로 0.3을 디스플레이 할 수 있다. 외부 장치는 이미지 내에서 객체 및/또는 위험 객체가 위치하는 영역을 변경하기 위한 사용자 입력 또는 인공 지능 모델에 의해 판단된 객체 및/또는 위험 객체의 변경을 위한 사용자 입력을 수신할 수 있다. 일 예로, 도 9b를 참조하면, 외부 장치는 디스플레이 된 바운딩 박스의 사이즈 또는 위치를 변경하기 위한 사용자 입력을 수신할 수 있다. 또는, 실제로 이미지에 전선이 아닌, 실이 포함된 경우이면, 외부 장치 는 전선을 실로 변경하기 위한 사용자 입력을 수신할 수도 있다. 외부 장치는 사용자 입력에 따라 변경된, 이미지 내에서 객체 및/또는 위험 객체가 위치하는 영역에 대한 정보를 전자 장치로 전송할 수 있다. 또한, 외부 장치는 사용자 입력에 따라 변경된, 객체 및/또는 위험 객체에 대한 정보를 전자 장치로 전송할 수도 있다. 물론, 외부 장치는 변경된 영역에 대한 정 보 및 변경된 객체 및/또는 위험 객체에 대한 정보를 함께 전자 장치로 전송할 수도 있다. 프로세서는 외부 장치로부터 수신한 변경된 영역에 대한 정보를 인공 지능 모델에 입력하여, 인공 지 능 모델을 업데이트 할 수 있다. 이 경우, 인공 지능 모델은 이미지 내에서 변경된 영역에 객체 및/또는 위험 객체가 위치하는 것으로 판단하기 위해, 복수의 레이어의 가중치를 업데이트 할 수 있다. 또는, 프로세서 는 변경된 객체 및/또는 위험 객체에 대한 정보를 인공 지능 모델에 입력하여, 인공 지능 모델을 업데이트 할 수 있다. 이 경우, 인공 지능 모델은 이미지 내에는 변경된 객체 및/또는 위험 객체가 포함된 것으로 판단하기 위해, 복수의 레이어의 가중치를 업데이트 할 수 있다. 이에 따라, 본 개시의 전자 장치는 보다 정확하게 객체 및/또는 위험 객체를 식별할 수 있다. 한편, 프로세서는 이미지에 객체 및/또는 위험 객체가 포함되어 있을 확률이 기설정된 확률보다 낮은지를 판단하고, 기설정된 확률보다 낮은 경우 인공 지능 모델에 의해 출력된 데이터를 통신부를 통해 외부 장치(20 0)로 전송할 수도 있다. 여기에서, 기설정된 확률은 0.4가 될 수 있으나, 반드시 이에 한정되는 것은 아니고, 이는 다양하게 설정될 수 있다. 일 예로, 프로세서는 제2 인공 지능 모델에 의해, 이미지에는 전선이 포함될 확률이 0.3으로 출력된 경우 이면, 상술한 바와 같이 제2 인공 지능 모델에 의해 출력된 데이터를 통신부를 통해 외부 장치로 전송하고, 제2 인공 지능 모델에 의해, 이미지에는 전선이 포함될 확률이 0.5로 출력된 경우이면, 제2 인공 지 능 모델에 의해 출력된 데이터를 외부 장치로 전송하지 않을 수 있다. 이는, 충분히 높은 확률인 경우이면, 인공 지능 모델의 업데이트를 수행할 필요가 없음을 고려한 것으로서, 이 에 따라 본 개시는 프로세서의 불필요한 연산을 방지할 수 있다. 도 10은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 순서도이다. 전자 장치는, 카메라를 통해 획득된 이미지에서 객체 및 객체에 의해 일부가 가려진 위험 객체를 식별(S1010)할 수 있다. 구체적으로, 전자 장치는 카메라를 통해 획득된 이미지를 제1 인공지능 모델에 입력하여 이미지에서 객체를 식별하고, 카메라를 통해 획득된 이미지를 제2 인공지능 모델에 입력하여 이미지에서 객체에 의해 일부 가 가려진 위험 객체를 식별할 수 있다. 전자 장치는, 센서로부터 수신된 센싱 데이터에 기초하여 객체와 위험 객체 간의 거리를 판단(S1020)할 수 있다. 구체적으로, 전자 장치는 센서로부터 수신된 센싱 데이터에 기초하여 전자 장치 및 객체 간의 제1 거리 및 전자 장치 및 위험 객체 간의 제2 거리를 판단하고, 제1 및 제2 거리에 기초하여 객체 및 위험 객체 간의 거 리를 판단할 수 있다. 전자 장치는, 판단된 거리에 기초하여 전자 장치가 객체의 주변을 주행하도록 전자 장치를 제어(S1030)할 수 있 다. 구체적으로, 전자 장치는 객체와 위험 객체 간의 거리가 기설정된 값 이상이면, 전자 장치가 객체에 근접하 여 주행하도록 전자 장치를 제어하고, 객체와 위험 객체 간의 거리가 기설정된 값 미만이면, 전자 장치가 객체 주변에 위치한 위험 객체로부터 기설정된 거리 이상 떨어진 영역에서 주행하도록 전자 장치를 제어할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 설치 가능한 소프트웨어 또는 어 플리케이션 형태로 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 대한 소프트웨어 업그레이드, 또 는 하드웨어 업그레이드만으로도 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들은 전자 장치에 구비된 임베디드 서버, 또는 전자 장치 외부의 서버를 통해 수행되는 것도 가능하다. 한편, 본 개시에 따른 전자 장치의 제어 방법을 순차적으로 수행하는 프로그램이 저장된 비일시적 판독 가능 매 체(non-transitory computer readable medium)가 제공될 수 있다. 한편, 비일시적 판독 가능 매체란 레지스터, 캐시, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있다. 또한, 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시의 기술적 사상은 상술"}
{"patent_id": "10-2019-0134855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한 특정의 실시 예에 한정되지 아니하며, 당해 발명이 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양 한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술적 사상이나 전망으로부터 개별적으 로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2019-0134855", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 전자 장치의 동작을 개략적으로 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치를 설명하기 위한 블록도이다. 도 3a는 본 개시의 일 실시 예에 따른 전자 장치 주변에 객체가 위치하는 경우를 도시한 도면이다. 도 3b는 본 개시의 일 실시 예에 따른 전자 장치 주변에 객체가 위치하는 경우, 전자 장치의 주행 동작을 설명 하기 위한 예시이다. 도 4a는 본 개시의 일 실시 예에 따른 전자 장치 주변에 위험 객체가 위치하는 경우를 도시한 도면이다. 도 4b는 본 개시의 일 실시 예에 따른 전자 장치 주변에 위험 객체가 위치하는 경우, 전자 장치의 주행 동작을 설명하기 위한 예시이다. 도 5a는 본 개시의 일 실시 예에 따른 객체에 근접하여 위험 객체가 위치하는 경우를 도시한 도면이다. 도 5b는 본 개시의 일 실시 예에 따른 객체에 근접하여 위험 객체가 위치하는 경우, 전자 장치의 주행 동작을 설명하기 위한 예시이다. 도 5c는 본 개시의 일 실시 예에 따른 객체로부터 기설정된 거리 이상 떨어진 영역에 위험 객체가 위치하는 경 우를 도시한 도면이다. 도 5d는 본 개시의 일 실시 예에 따른 객체로부터 기설정된 거리 이상 떨어진 영역에 위험 객체가 위치하는 경 우, 전자 장치의 주행 동작을 설명하기 위한 예시이다. 도 6a는 본 개시의 일 실시 예에 따른 제1 인공 지능 모델을 설명하기 위한 도면이다. 도 6b는 본 개시의 일 실시 예에 따른 제2 인공 지능 모델을 설명하기 위한 도면이다.도 6c는 본 개시의 일 실시 예에 따른 제2 인공 지능 모델을 설명하기 위한 도면이다. 도 7a는 본 개시의 일 실시 예에 따른 맵에 대한 정보를 설명하기 위한 도면이다. 도 7b는 본 개시의 일 실시 예에 따른 각 구역에 따라 구분되는 제1 및 제2 인공 지능 모델을 설명하기 위한 도 면이다. 도 7c는 본 개시의 일 실시 예에 따른 제1 및 제2 인공 지능 모델을 이용하여 객체 및/또는 위험 객체를 식별하 는 실시 예를 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시 예에 따른 전자 장치를 설명하기 위한 블록도이다. 도 9a는 본 개시의 일 실시 예에 따른 전자 장치 및 외부 장치를 도시한 도면이다. 도 9b는 본 개시의 일 실시 예에 따른 인공 지능 모델의 업데이트를 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 순서도이다."}
