{"patent_id": "10-2022-0082459", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0005403", "출원번호": "10-2022-0082459", "발명의 명칭": "항공기 파트 제조환경의 화재감시시스템", "출원인": "한국항공우주산업 주식회사", "발명자": "이종수"}}
{"patent_id": "10-2022-0082459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "항공기 파트 제조환경에 대한 이미지를 머신러닝 모델에 적용하여 화재발생 유무를 판단하는 연산처리부를 포함하며,상기 연산처리부는상기 이미지를 특징추출 모델에 입력하여 상기 이미지로부터 화재발생, 분진발생 및 작업수행에 대한 특징을 각각 추출하고,상기 특징으로 화재발생 유무를 판단하는 분류모델을 학습시키고,상기 항공기 파트 제조환경에 배치되는 카메라로부터 실시간으로 획득되는 실측이미지를 기학습된 객체인식모델에 적용하여 상기 실측이미지로부터 분석영역을 추출하고,상기 분석영역을 상기 분류모델에 입력하여 결과값을 생성하고,상기 결과값을 기반으로 상기 항공기 파트 제조환경에 대한 화재발생 유무에 대한 정보를 생성하는 항공기 파트제조환경의 화재감시시스템."}
{"patent_id": "10-2022-0082459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 분류모델은군집화모델과 신경망모델을 포함하며,상기 군집화모델 및 상기 신경망모델 각각에 상기 결과값에 영향을 주는 비중을 결정하는 가중치를 적용하여 상기 군집화모델 및 상기 신경망모델 각각이 예측값을 산출하도록 하고,상기 예측값을 종합하여 결과값을 생성하는 것을 특징으로 하는 항공기 파트 제조환경의 화재감시시스템."}
{"patent_id": "10-2022-0082459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 연산처리부는상기 예측값과 상기 결과값의 편차를 산출하고,상기 편차에 따라 상기 군집화모델 및 상기 신경망모델에 적용되는 상기 각각의 가중치를 조정하는 것을 특징으로 하는 항공기 파트 제조환경의 화재감시시스템."}
{"patent_id": "10-2022-0082459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 신경망모델은상기 실측이미지 및 상기 군집화모델의 예측값으로 재학습되고,상기 연산처리부는공개특허 10-2024-0005403-3-상기 신경망모델의 예측값이 상기 군집화모델의 예측값보다 상기 결과값에 더 높은 영향을 주도록 상기 각각의가중치를 조정하는 것을 특징으로 하는 항공기 파트 제조환경의 화재감시시스템."}
{"patent_id": "10-2022-0082459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 객체인식모델은상기 실측이미지 상에 서로 다른 크기를 가지는 복수 개의 박스를 생성하고,상기 분석영역을 인식하기 위한 기설정된 속성값을 이용하여 상기 각각의 박스 내에 인식하려는 객체가 존재할확률을 산출하여 신뢰도를 획득하고,상기 복수 개의 박스 중 상기 신뢰도가 가장 높은 박스를 선정하여, 상기 분석영역을 추출하는 것을 특징으로하는 항공기 파트 제조환경의 화재감시시스템."}
{"patent_id": "10-2022-0082459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 화재감시시스템은상기 이미지와 및 상기 이미지 내에 발생한 상황정보를 기반으로 생성되는 화재데이터 저장하는 저장부를 더 포함하고,상기 화재데이터는상기 실측이미지 및 상기 화재발생 유무에 대한 정보로 업데이트되는 것을 특징으로 하는 항공기 파트 제조환경의 화재감시시스템."}
{"patent_id": "10-2022-0082459", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 모델을 이용하여, 제조환경에서 화재로 오인 가능한 상황을 정확하게 구분하기 위한 항공기 파트 제조환경의 화재감시시스템을 제공하기 위해, 본 발명에 따른 항공기 파트 제조환경의 화재감시시스템은 항 공기 파트 제조환경에 대한 이미지를 머신러닝 모델에 적용하여 화재발생 유무를 판단하는 연산처리부를 포함하 (뒷면에 계속)"}
{"patent_id": "10-2022-0082459", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 화재감시시스템에 관한 것으로, 보다 상세하게는 항공기 파트 제조환경의 화재감시시스템에 관한 것 이다."}
{"patent_id": "10-2022-0082459", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 항공기 제조환경에서 발생하는 화재발생은 작업자가 제조환경에 설치되는 CCTV를 이용하여 확인하고 있다. 다만, 화재발생은 특정한 순간에 발생하여, 작업자가 직접 문제의 순간을 포착하는 것은 어려움이 있다. 이에, 현재에는 제조공정에서 이미지 분석을 통한 화재감시기술이 사용되고 있다. 이러한 화재감시기술은 이미 \"대한민국 등록특허공고 제10-0851601호(화재 발생 감시 방법 및 시스템, 2008.08.05.)\"에 의해 공개되어 있다. 상기 등록발명은 적외선 카메라를 활용하여 감시구역의 온도분포를 분석하고, 분석결과와 영상정보를 활용하여 감시구역의 화재발생 유무에 대한 정보를 제공한다. 다만, 종래의 화재감시기술은 단순히 온도분포를 기반으로 화재발생 유무를 판단한다. 그러나 제조환경에서는 다양한 공작기구가 이용됨에 따라 작업 중 발생하는 열, 분진 및 스파크 등으로 인해 온도분포만으로는 정확한 화재발생을 판단하기 어려운 문제점이 있었다. 선행기술문헌 특허문헌(특허문헌 0001) 대한민국 등록특허공고 제10-0851601호(화재 발생 감시 방법 및 시스템, 2008.08.05.)"}
{"patent_id": "10-2022-0082459", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 인공지능 모델을 이용하여, 제조환경에서 화재로 오인 가능한 상황을 정확하게 구분하기 위한 항공기 파트 제조환경의 화재감시시스템을 제공하기 위한 것이다."}
{"patent_id": "10-2022-0082459", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 항공기 파트 제조환경의 화재감시시스템은 항공기 파트 제조환경에 대한 이미지를 머신러닝 모 델에 적용하여 화재발생 유무를 판단하는 연산처리부를 포함하며, 상기 연산처리부는 상기 이미지를 특징추출 모델에 입력하여 상기 이미지로부터 화재발생, 분진발생 및 작업수행에 대한 특징을 각각 추출하고, 상기 특징 으로 화재발생 유무를 판단하는 분류모델을 학습시키고, 상기 항공기 파트 제조환경에 배치되는 카메라로부터 실시간으로 획득되는 실측이미지를 기학습된 객체인식모델에 적용하여 상기 실측이미지로부터 분석영역을 추출 하고, 상기 분석영역을 상기 분류모델에 입력하여 결과값을 생성하고, 상기 결과값을 기반으로 상기 항공기 파 트 제조환경에 대한 화재발생 유무에 대한 정보를 생성한다. 상기 분류모델은 군집화모델과 신경망모델을 포함하며, 상기 군집화모델 및 상기 신경망모델 각각에 상기 결과 값에 영향을 주는 비중을 결정하는 가중치를 적용하여 상기 군집화모델 및 상기 신경망모델 각각이 예측값을 산 출하도록 하고, 상기 예측값을 종합하여 결과값을 생성할 수 있다. 상기 연산처리부는 상기 예측값과 상기 결과값의 편차를 산출하고, 상기 편차에 따라 상기 군집화모델 및 상기 신경망모델에 적용되는 상기 각각의 가중치를 조정할 수 있다. 상기 신경망모델은 상기 실측이미지 및 상기 군집화모델의 예측값으로 재학습되고, 상기 연산처리부는 상기 신 경망모델의 예측값이 상기 군집화모델의 예측값보다 상기 결과값에 더 높은 영향을 주도록 상기 각각의 가중치 를 조정할 수 있다. 상기 객체인식모델은 상기 실측이미지 상에 서로 다른 크기를 가지는 복수 개의 박스를 생성하고, 상기 분석영 역을 인식하기 위한 기설정된 속성값을 이용하여 상기 각각의 박스 내에 인식하려는 객체가 존재할 확률을 산출 하여 신뢰도를 획득하고, 상기 복수 개의 박스 중 상기 신뢰도가 가장 높은 박스를 선정하여, 상기 분석영역을 추출할 수 있다. 상기 화재감시시스템은 상기 이미지와 및 상기 이미지 내에 발생한 상황정보를 기반으로 생성되는 화재데이터 저장하는 저장부를 더 포함하고, 상기 화재데이터는 상기 실측이미지 및 상기 화재발생 유무에 대한 정보로 업 데이트될 수 있다."}
{"patent_id": "10-2022-0082459", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 항공기 파트 제조환경의 화재감시시스템 및 화재감시방법은 다음과 같은 효과를 포함한다. 첫째, 본 발명은 화재발생으로 오인될 수 있는 상황을 고려하여 화재발생에 대한 판단을 수행함으로써, 보다 정 확한 화재발생 정보를 제공할 수 있는 효과가 있다. 둘째, 본 발명은 원격으로 화재감시가 가능하여, 화재감시에 소요되는 공수 및 비용을 절감하도록 하는 효과가 있다. 셋째, 본 발명은 기존의 설치된 영상수집장치와 연동되도록 구비되어, 타 산업 분야에 확대 적용 가능한 효과가 있다. 이상과 같은 본 발명의 기술적 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급되지 않은 또 다른 기술적 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0082459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명의 실시예를 상세히 설명한다. 그러나 본 실시예는 이하에서 개시되는 실 시예에 한정되는 것이 아니라 서로 다양한 형태로 구현될 수 있으며, 단지 본 실시예는 본 발명의 개시가 완전 하도록 하며, 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 도면에서의 요소의 형상 등은 보다 명확한 설명을 위하여 과장되게 표현된 부분이 있을 수 있으며, 도면 상에서 동일 부호 로 표시된 요소는 동일 요소를 의미한다. 도 1은 본 실시예에 따른 항공기 파트 제조공정의 화재감시시스템을 나타낸 흐름도이다. 도 1에 도시된 바와 같이, 본 실시예에 따른 항공기 파트 제조환경의 화재감시시스템(100, 이하 화재감시시스템 이라 한다)은 항공기 파트 제조환경(1, 이하 제조환경이라 한다)으로부터 카메라에 의해 획득되는 이미지를 머신러닝 모델에 입력하여 화재발생 유무를 판단한다. 그리고 화재감시시스템은 화재발생 유무에 대한 정 보를 생성하여 외부장치에 제공할 수 있다. 제조환경에서는 작업자가 항공기 파트를 제조하기 위해 다양한 작업이 수행한다. 여기서, 작업자는 용접 및 절삭 등을 포함하는 작업을 수행할 수 있다. 이에 따라, 제조환경은 작업자가 수행하는 작업에 따라 복수 개 의 구역을 포함할 수 있다. 카메라는 제조환경의 다양한 구역에 설치될 수 있다. 카메라는 각각이 기설정된 구역을 촬영한다. 이에, 카메라는 제조환경의 다양한 이미지를 수집하며, 각각의 카메라에 의해 수집된 이미지는 중앙서버 에 제공될 수 있다. 중앙서버는 제공받은 이미지를 외부장치 및 화재감시시스템에 제공한다. 외부장치는 컴퓨터 및 휴대용 단말기 등으로 구비될 수 있다. 이에, 외부장치는 제공받은 정보를 출력 하여 사용자에게 제공하도록 한다. 그리고 외부장치는 이미지, 소리 및 진동 등의 알람을 이용하여 사용자 에게 정보를 제공할 수 있다. 화재감시시스템은 제공받은 제조환경에 대한 이미지를 머신러닝 모델에 적용하여 화재발생 유무를 판단 한다. 그리고 화재감시시스템은 제조환경의 화재발생 유무를 판단하여 관련된 정보를 외부장치에 제공한다. 따라서, 외부장치는 화재발생 유무에 대한 정보를 출력하고, 이에 대한 알람을 수행하여 작업자 에게 제조환경의 화재발생정보를 제공하도록 한다. 한편, 이하에서는 도 2를 참조하여 본 실시예에 따른 항공기 파트 제조환경의 화재감시시스템의 구성에 대하여 설명하도록 한다. 도 2는 본 실시예에 따른 항공기 파트 제조공정의 화재감시시스템을 나타낸 구성도이다. 도 2에 도시된 바와 같이, 본 실시예에 따른 화재감시시스템은 통신부, 저장부 및 연산처리부 를 포함할 수 있다. 먼저, 통신부는 중앙서버 및 외부장치와 연동되어 정보를 송수신한다. 한편, 저장부는 과거의 수집된 이미지 및 이미지에 대한 정보로 생성된 화재데이터와, 화재발생을 판단하 기 위한 머신러닝 모델을 저장한다. 여기서, 이미지는 제조환경 및 제조환경과는 상이하거나 유사한 환경에서 수집한 이미지를 포함할 수 있 다. 그리고 이미지에 대한 정보는 이미지 내에 발생한 상황에 대한 정보 즉, 화재발생, 분진발생 및 작업수행 등에 대한 정보를 포함한다. 이에, 화재데이터는 이미지에 대한 정보로 라벨링된 이미지를 포함한다. 그리고 머신러닝 모델은 특징추출모델, 객체인식모델 및 분류모델을 포함할 수 있다. 여기서, 특징추출모델은 사전에 학습되어 저장될 수 있다. 이에, 특징추출모델은 상기 이미지로부터 화재발생, 분진발생 및 작업수행 등 이미지 내에 발생한 상황의 특징을 각각 추출한다.그리고 객체인식모델은 사전에 학습되어 저장될 수 있다. 이에, 객체인식모델은 기설정된 속성값을 기반으로 제 조환경으로부터 실시간으로 수집되는 실측이미지로부터 화재발생 유무에 대한 분석이 필요할 것으로 판단되 는 분석영역을 추출한다. 그리고 분류모델은 상기 특징추출모델이 화재데이터와 추출된 특징으로 학습될 수 있다. 학습된 분류모델은 상 기 인식된 객체가 입력되어, 객체가 나타내는 특징을 분류하도록 한다. 저장부는 후술할 연산처리부의 연산과정에 따라 특징추출모델, 객체인식모델 및 분류모델 각각 제공 할 수 있다. 한편, 연산처리부는 연산처리를 통해, 특징추출모델, 객체인식모델 및 분류모델을 이용하여 화재발생 유무 를 판단한다. 이때, 특징추출모델은 일 예시로써, 합성곱 신경망 네트워크(Convolution Neural Network; CNN)을 포함할 수 있 다. 합성곱 신경망 네트워크는 이미지에 대한 합성곱 연산을 수행하여, 이미지 내에 상황의 특징을 추출할 수 있다. 이러한 합성곱 신경망 네트워크는 합성곱과정 및 풀링과정을 포함하는 연산과정을 통해 특징추출을 할 수 있다. 합성곱 신경망 네트워크는 합성곱과정에서 기설정된 크기의 블록으로 생성된 합성곱필터가 입력된 이미지를 순 회하도록 한다. 이때, 합성곱필터는 복수 개의 블록을 포함할 수 있으며, 블록 내에는 기설정된 가중치가 입력 될 수 있다. 이에, 합성곱필터는 이미지의 각 영역을 순회하면서, 이미지의 각 영역에 상기 가중치를 적용시킨 다. 따라서, 합성곱필터는 이미지의 각 영역에 대한 특징값을 산출하도록 한다. 이러한 연산과정을 통해, 합성 곱 신경망 네트워크는 이미지의 화소를 축소시킬 수 있으며, 이미지의 각 영역이 나타내는 특징을 강화시킬 수 있다. 그리고 합성곱 신경망 네트워크는 풀링과정에서 산출된 특징값을 추출하여 기설정된 크기의 블록 형태에 특징맵 을 생성하도록 한다. 이때, 합성곱 신경망 네트워크는 축소된 이미지의 각 영역에서 상대적으로 가장 높은 값으 로 산출된 특징값을 추출할 수 있다. 그리고 특징추출모델은 추출한 특징값을 기설정된 크기의 블록에 입력하여 특징맵을 생성하도록 한다. 합성곱 신경망 네트워크는 상술한 합성곱과정 및 풀링과정을 반복수행하며, 이에 따라 이미지가 의 크기를 가지는 특징맵을 추출할 수 있다. 특징추출모델은 특징맵의 각 특징값을 추출하여 이미지 내의 발생한 상황에 대한 특징을 추출할 수 있다. 일례로, 객체인식모델은 실측이미지에 서로 다른 크기로 생성되도록 하는 복수 개의 박스를 생성한다. 그리고 객체인식모델은 상술한 속성값을 이용하여 각각의 박스의 신뢰도를 산출한다. 여기서, 신뢰도는 박스 내에 인식 하려는 객체가 존재할 확률을 의미한다. 이에, 객체인식모델은 각각의 박스에 대한 신뢰도를 비교하고, 신뢰도 가 가장 높게 산출된 박스를 선정하여 분석영역을 추출할 수 있다. 일례로, 객체인식모델은 실측이미지에 합성곱 연산을 적용하여, 분석영역추출에 대한 연산속도를 향상시킬 수 있다. 이때, 객체인식모델은 실측이미지 및 박스에 합성곱연산을 수행하여 각각 소정의 크기로 축소시킬 수 있 다. 이때, 실측이미지는 각 영역이 나타내는 특징이 강화될 수 있다. 이에, 객체인식모델은 축소된 실측이미지 에 비교적 적은 박스를 생성할 수 있다. 이러한 객체인식모델은 객체인식을 위해 생성되는 박스의 개수를 저감 시켜, 객체인식에 대한 연산속도를 향상시킬 수 있다. 한편, 분류모델은 군집화모델 및 신경망모델을 포함할 수 있다. 여기서, 군집화모델은 신경망모델에 비해 비교 적 짧은 연산시간으로 예측값을 산출할 수 있다. 그러나 군집화모델은 각 모델의 학습량에 따라 신경망모델에 비해 예측값의 정확도가 낮아질 수 있다. 반면, 신경망모델은 학습량이 적은 상태에서 오분류를 초래할 수 있다. 이에, 분류모델은 앙상블 기법을 적용하여 군집화모델과 신경망모델이 상호보완하도록 하는 것이 바람직 하다. 이때, 분류모델은 군집화모델 및 신경망모델 각각에 가중치를 부여하고, 각 모델이 산출하는 예측값을 종합하여 결과값을 생성할 수 있다. 여기서, 가중치는 각 예측값이 결과값에 영향을 주는 비중을 결정한다. 이에, 분류모 델은 각 모델에 적용되는 가중치를 조정함으로써, 각 예측값이 결과값에 영향을 주는 비중을 조정할 수 있다. 이러한 분류모델은 상기 특징추출모델에 의해 추출된 특징을 기반으로 학습될 수 있다. 이때, 분류모델은 군집 화모델 및 신경망모델에 이미지를 입력하고, 상기 추출된 특징으로 분류하도록 학습시킬 수 있다. 이때, 분류모델은 군집화모델에 신경모델보다 높은 가중치를 부여하도록 한다. 이에, 분류모델은 결과값에 군집화모델의 예 측값이 더 높은 영향을 주도록 할 수 있다. 추가적으로, 분류모델은 신경망모델이 실측데이터 및 군집화모델의 예측값으로 재학습하도록 한다. 이때, 분류 모델은 재학습된 신경망모델의 예측값에 대한 정확도를 산출하도록 한다. 여기서, 분류모델은 결과값 및 신경망 모델의 예측값과의 편차를 산출하여 정확도를 산출한다. 이에, 분류모델은 신경망모델의 예측값에 대한 정확도 에 따라 상기 가중치를 조정할 수 있다. 구체적으로, 재학습된 신경망모델의 예측값의 정확도가 기준치에 도달할 경우에는 분류모델이 신경망모델의 예 측값이 결과값에 영향을 미치는 비중이 높아지도록 가중치를 조정할 수 있다. 추가적으로, 가중치 조정은 작업 자가 판단하여, 임의로 조정될 수 있다. 따라서, 분류모델은 실측이미지로부터 신경망모델을 재학습 및 가중치조정을 반복수행할 수 있다. 최종적으로, 분류모델은 신경망모델의 예측값의 비중이 군집화모델의 예측값보다 상대적으로 높도록 가중치를 조정할 수 있 다. 분류모델은 군집화모델 및 신경망모델을 통해 결과값을 산출함으로써, 실측이미지 내에 분석영역이 나타내는 특 징을 분류하도록 한다. 따라서, 연산처리부는 상기 결과값에 따라 화재발생 유무를 판단한다. 그리고 연산 처리부는 화재발생 유무에 대한 정보를 생성하며, 화재발생 유무에 대한 정보를 통신부에 제공하여 외부장치로 송신하도록 한다. 한편, 이하에서는 도 3 및 4를 참조하여 본 실시예에 따른 항공기 파트 제조환경의 화재감시시스템의 화재감시 방법에 대하여 설명하도록 한다. 다만, 상술된 구성요소에 대해서는 상세한 설명을 생략하고, 동일한 참조부호 를 부여하여 설명하도록 한다. 도 3은 본 실시예에 따른 항공기 파트 제조공정의 화재감시방법을 나타낸 순서도이고, 도 4는 본 실시예에 따른 항공기 파트 제조공정의 화재감시방법 중 화재감시 단계를 나타낸 순서도이다. 도 3에 도시된 바와 같이, 본 실시예에 따른 화재감시시스템은 이미지 획득단계(S100), 특징추출단계 (S200), 분류모델 학습단계(S300) 및 화재감시단계(S400)을 수행하여, 제조환경의 화재발생 유무에 대한 정 보를 생성한다. 먼저, 이미지획득단계(S100)에서는 연산처리부가 저장부로부터 이미지를 획득한다. 그리고 특징추출단계(S200)에서는 연산처리부가 획득한 이미지를 특징추출모델에 입력하여 이미지 내에 발 생한 상황의 특징을 추출하도록 한다. 이때, 연산처리부는 추출된 특징을 이미지에 대한 정보로 라벨링할 수 있다. 이에, 연산처리부는 이미지로부터 화재발생, 분진발생 및 작업수행 등의 특징을 각각 추출할 수 있다. 그리고 분류모델 학습단계(S300)에서는 연산처리부가 추출된 특징으로 분류모델을 학습시킨다. 이때, 연산 처리부는 추출된 특징을 군집화모델 및 신경망모델 각각에 대한 적절한 데이터 형태로 변화시킬 수 있다. 그리고 연산처리부는 변환된 특징을 이용하여, 군집화모델 및 신경망모델이 각 특징으로 분류를 수행하도 록 학습시킨다. 따라서, 연산처리부는 군집화모델 및 신경망모델 각각이 분류의 결과로써, 예측값을 산출 하도록 한다. 또한, 연산처리부는 분류모델이 앙상블방법을 적용하여 군집화모델 및 신경망모델 각각의 예측값을 종합하 도록 한다. 이때, 연산처리부는 군집화모델 및 신경망모델 각각의 가중치를 산정하여 적용시킬 수 있다. 여기서, 연산처리부는 군집화모델이 신경망모델 보다 상대적으로 높은 가중치가 적용되도록 할 수 있다. 따라서, 연산처리부는 각 모델의 예측값을 합하여 종합할 수 있으며, 이에 따라 결과값을 획득할 수 있다. 그리고 연산처리부는 결과값을 이미지 내에 상황과 비교하여 정확도를 평가할 수 있다. 일례로, 연산처리 부는 결과값으로써, 이미지의 분류된 특징이, 저장부에 저장된 이미지 내에 상황에 있는 특징과 비교 하여, 일치여부를 판단할 수 있다. 그리고 연산처리부는 학습된 분류모델을 저장부에 입력하여 저장하도록 한다. 화재감시단계(S400)에서는 화재감시시스템이 중앙서버로부터 실시간으로 획득되는 제조환경에 대한 실측이미지를 머신러닝 모델에 입력하여, 화재발생유무를 판단하도록 한다. 도 4를 참조하여 설명하면, 화재감 시시스템은 실측이미지 획득단계(S410), 분석영역 추출단계(S420), 화재발생 유무 정보 생성단계(S430) 및화재발생 유무 정보 제공단계(S440)를 수행할 수 있다. 먼저, 실측이미지 획득단계(S410)에서는 통신부가 중앙서버로부터 실측이미지를 실시간으로 제공받을 수 있다. 그리고 통신부는 제공받은 실측이미지를 저장부에 제공하여 저장하도록 한다. 그리고 분석영역 추출단계(S420)에서는 연산처리부가 저장부로부터 실측이미지를 획득한다. 그리고 연산처리부는 획득된 실측이미지를 객체인식모델에 입력하여 분석영역을 추출할 수 있다. 그리고 화재발생 유무 정보 생성단계(S430)에서는 연산처리부가 추출된 분석영역을 분류모델에 입력하여, 화재발생, 분진발생 및 작업수행 등으로 분류하도록 한다. 이때, 연산처리부는 저장부로부터 분류모델을 불러올 수 있다. 그리고 연산처리부는 분류모델에 분석영역을 입력하도록 한다. 분류모델은 분석영역을 군집화모델 및 신경망모델 각각에 입력한다. 이에, 군집화 모델 및 신경망모델 각각은 예측값을 산출하며, 분류모델은 산출된 예측값을 종합하여, 결과값을 생성한다. 이 때, 연산처리부는 신경망모델의 예측값과 결과값을 비교하여 비교결과에 따라 재학습을 수행할 수 있다. 그리고 연산처리부는 생성된 결과값으로 실측이미지의 화재발생 유무에 대한 정보를 생성한다. 이때, 화재 발생 유무에 대한 정보는 화재발생, 분진발생 및 작업수행을 포함하는 특징 중 적어도 어느 하나의 특징 정보를 포함할 수 있다. 여기서, 연산처리부는 생성된 화재발생 유무에 대한 정보를 저장부에 입력하여 화재데이터를 업데이 트하도록 한다. 화재발생 유무 정보 제공단계(S440)에서는 연산처리부가 생성된 화재발생 유무에 대하 정보를 무선신호로 변환하여 화재알람신호를 생성할 수 있다. 일례로, 화재알람신호는 연산처리부가 제조환경에 화재가 발 생한 것으로 판단될 때에 생성하도록 할 수 있다. 통신부는 화재알람신호를 외부장치로 제공할 수 있다. 이때, 중앙서버는 실측이미지를 외부장치 에 송신할 수 있다. 이에, 외부장치는 중앙서버 및 화재감시시스템 각각으로부터 실측이미지 및 화재알람신호를 동시에 제공받을 수 있다. 외부장치는 실측이미지를 출력하여 작업자에게 제공하며, 동시에 화재발생 유무에 대한 정보를 제공할 수 있다. 화재발생 유무에 대한 정보가 화재발생에 대한 정보를 포함하는 경우, 외부장치는 이미지, 소리 및 진동으로 알람하여 작업자에게 알람할 수 있다. 이에, 작업자는 외부장치에 출력되는 실측이미지 및 화재발 생 유무에 대한 정보를 확인하여 제조환경에 대한 화재감시를 원격으로 수행할 수 있다. 이와 같이, 본 발명에 따른 항공기 파트 제조환경의 화재감시시스템은 제조환경으로부터 실시간으로 수집되는 실측이미지를 머신러닝모델에 입력하여 제조환경에 대한 화재발생 판단정보를 생성할 수 있다. 이때, 머신러닝 모델은 화재발생으로 오인될 수 있는 상황의 특징을 포함한 데이터로 학습되어, 화재발생뿐만 아니라 분진발생 및 작업수행 등과 같은 상황으로 분류하여 판단하도록 한다. 그리고 화재감시시스템은 생성된 판단정보를 작업 자에게 제공함으로써 화재원격감시가 가능하도록 한다. 이에, 본 발명은 화재발생으로 오인될 수 있는 상황을 고려하여 화재발생에 대한 판단을 수행함으로써, 보다 정 확한 화재발생 정보를 제공할 수 있는 효과가 있다. 또한, 본 발명은 원격으로 화재감시가 가능하여, 화재감시에 소요되는 공수 및 비용을 절감하도록 하는 효과가 있다. 또한, 본 발명은 기존의 설치된 영상수집장치와 연동되도록 구비되어, 타 산업 분야에 확대 적용 가능한 효과가 있다. 앞에서 설명되고, 도면에 도시된 본 발명의 일 실시예는 본 발명의 기술적 사상을 한정하는 것으로 해석되어서"}
{"patent_id": "10-2022-0082459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 안 된다. 본 발명의 보호범위는 청구범위에 기재된 사항에 의하여만 제한되고, 본 발명의 기술분야에서 통상 의 지식을 가진 자는 본 발명의 기술적 사상을 다양한 형태로 개량 변경하는 것이 가능하다. 따라서 이러한 개 량 및 변경은 통상의 지식을 가진 자에게 자명한 것인 한 본 발명의 보호범위에 속하게 될 것이다.도면 도면1 도면2 도면3 도면4"}
{"patent_id": "10-2022-0082459", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 실시예에 따른 항공기 파트 제조공정의 화재감시시스템을 나타낸 흐름도이다. 도 2는 본 실시예에 따른 항공기 파트 제조공정의 화재감시시스템을 나타낸 구성도이다. 도 3은 본 실시예에 따른 항공기 파트 제조공정의 화재감시방법을 나타낸 순서도이다. 도 4는 본 실시예에 따른 항공기 파트 제조공정의 화재감시방법 중 화재감시 단계를 나타낸 순서도이다."}
