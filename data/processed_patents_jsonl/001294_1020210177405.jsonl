{"patent_id": "10-2021-0177405", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0089059", "출원번호": "10-2021-0177405", "발명의 명칭": "인공지능 악기 연주 시스템", "출원인": "이모션웨이브 주식회사", "발명자": "장순철"}}
{"patent_id": "10-2021-0177405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "악기에 배치되어 악기를 연주하는 악기 액추에이터를 구동시켜 악기의 연주를 제어하는 적어도 하나의 악기 제어 장치, 그리고원시 데이터를 수집하고 전처리하여 연주 데이터를 구축하고, 수집된 미디데이터를 복수의 단계로 분해하여 기존 음악의 패턴을 학습하고, 학습된 데이터를 기초로 사용자 맞춤형 연주 데이터를 악기별로 생성하여 상기 제어 장치에 송신하는 인공지능 연주 서버를 포함하는 인공지능 악기 연주 시스템."}
{"patent_id": "10-2021-0177405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에서,상기 악기 제어 장치는,미디 신호를 모터 제어 신호로 변환하는 신호 변환부, 그리고PWM 제어를 통해 상기 액추에이터의 동작속도를 조절하여 연주의 세기를 조절하는 연주세기 조절부를 포함하는 인공지능 악기 연주 시스템."}
{"patent_id": "10-2021-0177405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에서,상기 악기 제어 장치는,상기 인공지능 연주 서버와 연주 데이터를 송수신하여 상호 간의 딜레이를 측정하는 딜레이 측정부를 더 포함하는 인공지능 악기 연주 시스템."}
{"patent_id": "10-2021-0177405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에서,상기 인공지능 연주 서버는,사용자로부터 획득된 음악파일의 소스를 분리하여 상기 연주 데이터를 구축하거나 새로운 음악 작곡을 위한 메타데이터를 생성하는 데이터 구축 모듈을 포함하는 인공지능 악기 연주 시스템."}
{"patent_id": "10-2021-0177405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에서,상기 데이터 구축 모듈은,음악파일의 소스를 분리하여 PCM 기반 데이터 및 미디 데이터를 획득하되, 상기 PCM 기반 원시 데이터를 미디데이터로 컨버팅하여 전처리하는 데이터 획득 및 정제부, 그리고전처리된 미디 데이터의 장르 및 유형을 구분하여 메타데이터를 생성하되, 상기 전처리된 미디 데이터의 박자,곡의 길이, 곡의 빠르기, 장르, 마디 구성, 곡제목, 및 아티스트 정보가 태깅된 메타데이터를 생성하는 데이터라벨링부를 포함하는 인공지능 악기 연주 시스템.공개특허 10-2023-0089059-3-청구항 6 제1항에서,상기 인공지능 연주 서버는,악기 연주를 위한 리듬을 생성하되, 수집된 미디 데이터를 복수의 단계로 분해하여 패턴을 학습하고, 학습된 데이터를 기초로 사용자 맞춤형 연주 데이터를 악기별로 생성하는 인공지능 작곡 엔진 모듈을 포함하는 인공지능악기 연주 시스템."}
{"patent_id": "10-2021-0177405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에서,상기 인공지능 작곡 엔진 모듈은,미디 데이터를 복수의 단계로 분해하는 데이터 분석부,분해된 미디 데이터를 문자열 데이터를 변환하고, 변환된 문자열 데이터를 숫자 데이터를 인코딩하여 딥러닝에적합한 학습 데이터셋을 구성하고, 인공지능 알고리즘을 통해서 상기 학습 데이터셋을 기초로 기존음악의 패턴을 분석하여 학습하는 학습부, 그리고상기 학습부의 학습 결과를 기초로 사용자의 기호에 맞는 주제 및 음악을 생성하는 음악 생성부를 포함하는 인공지능 악기 연주 시스템."}
{"patent_id": "10-2021-0177405", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제3항에서,상기 악기 연주 제어 장치는,상기 악기 제어 장치와 연주 데이터를 송수신하여 딜레이를 측정하고, 측정된 딜레이를 기초로 상기 악기 제어장치까지 최단거리를 갖게되는 노도를 선택하여 데이터 전송 루트를 생성하는 딜레이 측정 모듈을 더 포함하는인공지능 악기 연주 시스템."}
{"patent_id": "10-2021-0177405", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따른 인공지능 악기 연주 시스템은 악기에 배치되어 악기를 연주하는 악기 액추에이터를 구동시켜 악 기의 연주를 제어하는 적어도 하나의 악기 제어 장치, 그리고 원시 데이터를 수집하고 전처리하여 연주 데이터를 구축하고, 수집된 미디데이터를 복수의 단계로 분해하여 기존 음악의 패턴을 학습하고, 학습된 데이터를 기초로 사용자 맞춤형 연주 데이터를 악기별로 생성하여 상기 제어 장치에 송신하는 인공지능 연주 서버를 포함한다. 이 를 통해서, 본 발명은 연주자가 없이도 필요할 때 즉시 연주가 가능한 무인 자동 연주 환경을 제공하고, 초보자 도 쉽게 악기 연주를 구현하고, 사용자 맞춤형의 연주를 구현할 수 있는 환경을 제공한다."}
{"patent_id": "10-2021-0177405", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 악기를 연주하기 위한 연주 데이터를 생성하고 악기 액추에이터를 통해 원격으로 악기를 연주할 수 있는 인공지능 악기 연주 시스템에 관한 것이다."}
{"patent_id": "10-2021-0177405", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "엔터테인먼트 로봇은 사람과 상호 작용을 하는 로봇으로써 소비자의 수요와 연계된 제품의 상용화가 다른 로봇 분야에 비해 빠르게 진행되어 콘텐츠를 통한 시장 확대가 큰 분야이다. 엔터테인먼트 로봇은 전문 서비스 분야로서 문화 및 공연 콘텐츠를 이용하여 공공장소에서 공연, 연주, 연극 등 을 통해 여러 사람들에게 즐거움을 줄 수 있는 오락 기능을 갖고 있다. 최근에는 음악과 로봇을 결합하려는 시도가 많이 있었지만, 대부분이 기존의 악기를 조금 더 사용하게 편리하게 도와주는 방식으로 진행되었고, 현재 존재하고 있는 자동 연주 악기같은 경우에는 제한도 많고 비효율적인 문제 들이 있었다. 또한, 기존의 악기들로 라이브 공연을 진행하기 위해서는 연주자가 필요하다. 하지만 언제 있을지 모를 연주를 위해 연주자가 항시 대기할 수 없다. 따라서, 연주자가 없이도 필요할 때 즉시 악기 연주가 가능한 무인 자동 연주 기술이 필요한 실정이다. 그리고, 최근에는 연주 세기를 조절하여 연주 해상도를 향상시켜 보다 완벽한 연 주가 가능한 시킬 수 있는 기술이 필요한 실정이다."}
{"patent_id": "10-2021-0177405", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "이 배경기술 부분에 기재된 사항은 발명의 배경에 대한 이해를 증진하기 위하여 작성된 것으로서, 이 기술이 속"}
{"patent_id": "10-2021-0177405", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 3, "content": "하는 분야에서 통상의 지식을 가진 자에게 이미 알려진 종래기술이 아닌 사항을 포함할 수 있다.발명의 내용"}
{"patent_id": "10-2021-0177405", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 수집된 연주 데이터를 딥러닝을 통해 학습을 시켜 스스로 노래의 음원정보와 BPM, 박자 등을 분석하 고, 기존의 리듬 연주 데이터를 바탕으로 다양한 리듬 연주패턴을 생성하여 연주할 수 있는 인공지능 악기 연주 시스템을 제안하고자 한다."}
{"patent_id": "10-2021-0177405", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 인공지능 악기 연주 시스템은 악기에 배치되어 악기를 연주하는 악기 액추에이터를 구동시켜 악기의 연주를 제어하는 적어도 하나의 악기 제어 장치, 그리고 원시 데이터를 수집하고 전처리하여 연주 데이터를 구 축하고, 수집된 미디데이터를 복수의 단계로 분해하여 기존 음악의 패턴을 학습하고, 학습된 데이터를 기초로 사용자 맞춤형 연주 데이터를 악기별로 생성하여 상기 제어 장치에 송신하는 인공지능 연주 서버를 포함한다. 상기 악기 제어 장치는, 미디 신호를 모터 제어 신호로 변환하는 신호 변환부, 그리고 PWM 제어를 통해 상기 액 추에이터의 동작속도를 조절하여 연주의 세기를 조절하는 연주세기 조절부를 포함할 수 있다. 상기 악기 제어 장치는, 상기 인공지능 연주 서버와 연주 데이터를 송수신하여 상호 간의 딜레이를 측정하는 딜 레이 측정부를 더 포함할 수 있다. 상기 인공지능 연주 서버는, 사용자로부터 획득된 음악파일의 소스를 분리하여 상기 연주 데이터를 구축하거나 새로운 음악 작곡을 위한 메타데이터를 생성하는 데이터 구축 모듈을 포함할 수 있다. 상기 데이터 구축 모듈은, 음악파일의 소스를 분리하여 PCM 기반 데이터 및 미디 데이터를 획득하되, 상기 PCM 기반 원시 데이터를 미디 데이터로 컨버팅하여 전처리하는 데이터 획득 및 정제부, 그리고 전처리된 미디 데이 터의 장르 및 유형을 구분하여 메타데이터를 생성하되, 상기 전처리된 미디 데이터의 박자, 곡의 길이, 곡의 빠 르기, 장르, 마디 구성, 곡제목, 및 아티스트 정보가 태깅된 메타데이터를 생성하는 데이터 라벨링부를 포함할 수 있다. 상기 인공지능 연주 서버는, 악기 연주를 위한 리듬을 생성하되, 수집된 미디 데이터를 복수의 단계로 분해하여 패턴을 학습하고, 학습된 데이터를 기초로 사용자 맞춤형 연주 데이터를 악기별로 생성하는 인공지능 작곡 엔진 모듈을 포함할 수 있다. 상기 인공지능 작곡 엔진 모듈은, 미디 데이터를 복수의 단계로 분해하는 데이터 분석부, 분해된 미디 데이터를 문자열 데이터를 변환하고, 변환된 문자열 데이터를 숫자 데이터를 인코딩하여 딥러닝에 적합한 학습 데이터셋 을 구성하고, 인공지능 알고리즘을 통해서 상기 학습 데이터셋을 기초로 기존음악의 패턴을 분석하여 학습하는 학습부, 그리고 상기 학습부의 학습 결과를 기초로 사용자의 기호에 맞는 주제 및 음악을 생성하는 음악 생성부 를 포함할 수 있다. 상기 악기 연주 제어 장치는, 상기 악기 제어 장치와 연주 데이터를 송수신하여 딜레이를 측정하고, 측정된 딜 레이를 기초로 상기 악기 제어 장치까지 최단거리를 갖게되는 노도를 선택하여 데이터 전송 루트를 생성하는 딜 레이 측정 모듈을 더 포함할 수 있다."}
{"patent_id": "10-2021-0177405", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 연주 데이터로부터 악기를 연주하기 위한 모터 제어 신호를 생성하고, 상기 모터 제어 신호 로 악기에 체결된 악기 액추에이터를 구동시켜 원격으로 악기를 연주함으로써, 연주자가 없이도 필요할 때 즉시 연주가 가능한 무인 자동 연주 환경을 제공한다. 또한, 본 발명은 원시 데이터를 획득하고, 미디 데이터를 전처리하며, 전처리된 미디 데이터를 라벨링하여 메타 데이터를 생성함으로써, 인공지능으로 음악을 생성할 수 있는 학습 데이터셋을 효과적으로 구축할 수 있는 환경 을 제공한다. 또한, 본 발명은 기존 음악들의 미디 데이터를 수집하여 복수의 단계로 분해하고, 이를 기초로 학습 데이터셋을 구성하며, 구성된 학습 데이터셋을 바탕으로 기존 음악들의 패턴을 학습한 후 새로운 음악을 생성함으로써, 사 용자 맞춤형의 음악을 효과적으로 작곡할 수 있는 환경을 제공한다.또한, 본 발명은 본 발명은 악기를 연주하는 악기 액추에이터, 악기 연주를 제어하는 연주 제어 장치 및 사용자 의 클라이언트 사이의 노드 간의 딜레이를 측정하고, 연주 데이터의 무결성 및 손실율을 검증하여 연주 데이터 의 최단거리 데이터 전송 루트를 설정함으로써, 연주 데이터 전송시의 지연시간을 최소화하여 실시간에 가까운 초저지연으로 악기 연주를 구현할 수 있는 환경을 제공한다."}
{"patent_id": "10-2021-0177405", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 바람직한 실시예를 첨부한 도면에 의거하여 상세하게 설명하면 다음과 같다. 이에 앞서, 본 명세서에 기재된 실시예와 도면에 도시된 구성은 본 발명의 가장 바람직한 일 실시예에 불과할 뿐이고 본 발명의 기술적 사상을 모두 대변하는 것은 아니므로, 본 출원시점에 있어서 이들을 대체할 수 있는 다양한 균등물과 변형예들이 있을 수 있음을 이해하여야 한다. 아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위 해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도면에서 나타난 각 구성의 크기 및 두께는 설명의 편의를 위해 임의로 나타내었으므로, 본 발명이 반드시 도면 에 도시된 바에 한정되지 않으며, 여러 부분 및 영역을 명확하게 표현하기 위하여 두께를 확대하여 나타내었다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재 된 \"…부\", \"…기\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드 웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 실시예가 속 하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의미 를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 또한, 실시예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 실시예의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 이제 도 1 내지 도 13을 참고하여 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템에 대하여 상세하게 설명한다. 도 1은 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템의 개략적인 구성을 나타낸 도면이고, 도 2는 본 발명의 한 실시예에 따른 악기 제어 장치의 구성을 간략히 도시한 도면이다. 이때, 인공지능 악기 연주 시스템 은 본 발명의 실시예에 따른 설명을 위해 필요한 개략적인 구성만을 도시할 뿐 이러한 구성에 국한되는 것 은 아니다. 도 1 및 도 2를 참조하면, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 악기 제어 장치 가 모터 제어 신호를 생성하고, 상기 모터 제어 신호를 통해 악기에 체결된 악기 액추에이터를 구동 시켜 악기을 연주하는 시스템을 포함한다. 그리고, 상기 악기 연주 제어 장치는 인공지능 연주 서버 및 클라이언트의 단말 또는 앱 등에서 악기를 연주를 위한 데이터를 전송받아 악기를 연주하도록 악기 액추에이터의 구동을 제어할 수 있다. 상기 악기 연주 제어 장치는 미디(MIDI) 신호를 각 채널별 모터 제어 신호로 변환하고, 각 채널별로 모터 드라이브를 사용하여 12V, 2A의 정격출력을 발생시킬 수 있다.. 상기 악기 연주 제어 장치는 클라이언트로부터 사용자가 연주를 재생하고자 하는 곡을 입력받고 이를 서버와의 통신을 하여 악기 연주를 위한 미디 데이터를 받아올 수도 있다. 그리고, 악기 연주 제어 장치는 받아온 미디 데이터를 기초로 모터 제어 신호를 생성하고, 상기 모터 제어 신호로 상기 상기 악기 액추에이터 를 구동시켜 실시간으로 악기를 연주할 수 있다. 그리고, 악기 연주 제어 장치는 상기 악기 액추에이 터에 의한 악기의 연주파일을 클라이언트에 전송할 수 있다 상기 인공지능 연주 서버는 클라이언트에서 획득된 음악 데이터를 학습하여 사용자 맞춤형의 음악을 작곡할 수 있다. 또한, 상기 인공지능 연주 서버는 인공지능 알고리즘을 통해서 악기연주를 위한 새로운 미디 데이터를 창작할 수 있다. 상기 인공지능 알고리즘은 LSTM 기반의 RNN을 통해 미디 신호를 스트림하고, 악 기연주를 위한 리듬을 생성할 수 있다. 예를 들어, 악기 연주 제어 장치는 킥, 스네어, 하이햇, 탐 3종, 심벌 2종을 기본 셋으로 한 리듬 연주를 생성하고, 표준 악기 MIDI의 키(Key) 값에 맞춰서 각 노트를 출력할 수 있다. 그리고, 상기 인공지능 연주 서버는 PCM 데이터에서 악기의 데이터를 추출하여 악기용 MIDI 데이터로 변환 할 수 있다. 이때, 상기 인공지능 연주 서버는 dB 변화 및 멜로디(Melody), 베이스 라인(Bass Line), 화음 (Chords) 등을 추가로 추출하고 이를 참고하여 악기의 MIDI 노트의 속도를 다이나믹하게 출력하고, RNN을 통해 생성된 리듬데이터들과 마디별 비교를 통해 추출된 연주 데이터의 적합성을 판단하고 보완하여 악기 연주를 위 한 새로운 미디 데이터를 생성할 수 있다. 도 2를 참조하면, 본 발명의 한 실시예에 따른 악기 연주 제어 장치는 통신부, 딜레이 측정부, 채널부, 신호변환부, 연주세기 조절부, 그리고 제어부을 포함한다. 상기 통신부는 상기 인공지능 연주 서버 또는 클라이언트와 연결되어 각종 데이터를 송수신할 수 있다. 상기 통신부는 상기 인공지능 연주 서버 및 클라이언트로부터 악기 연주를 위한 연주 데이터 및 미디 데이터를 수신하고, 악기 액추에이터의 악기 연주에 따른 음향 데이터를 상기 인공지능 연 주 서버 및 상기 클라이언트에 송신할 수 있다. 상기 딜레이 측정부는 초저지연 연주정보를 전송하여 실시간에 가까운 초전지연으로 연동시켜 협연 및 합 주를 진행할 수 있도록 상기 인공지능 연주 서버 또는 상기 클라이언트와 연주 데이터를 송수신하여 상호 간의 딜레이를 측정할 수 있다. 상기 채널부는 복수의 악기 액추에이터를 동시에 제어하여 음악을 연주할 수 있도록 복수개의 채널을 설정할 수 있다.상기 신호변환부는 악기 연주를 위한 미디 신호를 채널별 모터 제어 신호로 변환할 수 있다. 상기 인공지 능 연주 서버 또는 클라이언트의 PC, 전용 APP 등에서 악기를 연주를 위한 데이터를 전송받으면 이를 각 채널별 제어신호로 변환하고 악기 액추에이터를 구동시키는 모터 제어 신호를 발생시킬 수 있다. 상기 연주세기 조절부는 PWM 제어를 통해 상기 악기 액추에이터의 동작속도를 조절하여 연주의 세기를 조 절할 수 있다. 상기 제어부는 상기 인공지능 연주 서버 또는 클라이언트에서 수신된 연주 데이터를 기초로 악 기를 연주하도록 제어하거나, 상기 인공지능 연주 서버에서 새롭게 생성된 음악을 기초로 악기를 연주하도 록 상기 각부의 동작을 제어할 수 있다. 도 3은 본 발명의 한 실시예에 따른 인공지능 연주 서버의 구성을 간략히 도시한 도면이다. 이때, 인공지능 연 주 서버는 본 발명의 실시예에 따른 설명을 위해 필요한 개략적인 구성만을 도시할 뿐 이러한 구성에 국한 되는 것은 아니다. 도 3을 참조하면, 본 발명의 한 실시예에 따른 인공지능 연주 서버는 제어 모듈, 데이터 구축 모듈 , 인공지능 작곡 엔진 모듈, 딜레이 측정 모듈, 그리고 연주 정보 전송 모듈을 포함한다. 상기 제어 모듈은 악기 연주 제어 장치가 악기를 실시간으로 연주하도록 연주 데이터를 송신하거나, 악기를 연주하기 위한 미디 데이터를 직접 작곡하여 생성하고, 생성된 미디 데이터를 기초로 상기 악기 연주 제 어 장치에 송신하여 악기 액추에이터가 악기를 연주하도록 상기 각부의 동작을 제어할 수 있다. 상기 데이터 구축 모듈은 원시데이터를 수집하고, 수집된 원시데이터를 가공하여 학습용 데이터를 생성할 수 있다. 상기 데이터 구축 모듈은 사용자로부터 획득된 음악파일의 소스를 분리하여 연주용 MIDI 데이터 로 컨버팅할 수 있다. 그리고, 상기 데이터 구축 모듈은 사용자로부터 획득된 음악파일의 소스를 분리하여 PCM 기반 데이터 및 MIDI 데이터를 획득하고, 이를 기초로 음악 창작을 위한 학습용의 메타데이터를 생성할 수 있다. 상기 데이터 구축 모듈은 본 발명의 한 실시예에 따라 원시데이터 획득 및 정제부, 그리고 데이터 라 벨링부를 포함할 수 있다. 상기 원시데이터 획득 및 정제부는 음악파일의 소스를 분리하여 PCM 기반 데이터 및 MIDI 데이터를 획득하 고, 상기 PCM 기반 원시 데이터를 학습용 MIDI 데이터로 컨버팅하여 전처리할 수 있다. 여기서, 상기 음악파일 은 연주곡과 가창곡을 포함할 수 있다. 상기 데이터 라벨링부는 컨버팅된 상기 MIDI 데이터의 장르 및 유형을 구분하여 앨범, 곡, 라이선스, 장르, 길이 국가를 포함하는 메타데이터를 생성할 수 있다. 또한, 상기 데이터 라벨링부는 데이터 식별자, 데이터 이름, 데이터 위치, 악기, 장르, 및 타입 정보를 매 칭시켜 상기 MIDI 데이터를 라벨링한 메타데이터를 생성할 수 있다. 여기서, 상기 메타데이터는 상기 MIDI 데이 터의 박자, 곡의 길이, 곡의 빠르기, 장르, 마디 구성, 곡제목, 및 아티스트 정보가 태깅된 데이터를 포함할 수 있다. 상기 인공지능 작곡 엔진 모듈은 상기 데이터 구축 모듈에서 구축된 학습용 MIDI 데이터 및 메타데이 터를 기초로 RNN 및 LSTM 방식으로 음악을 창작하고, 악기 연주를 위한 리듬을 생성할 수 있다. 또한, 상기 인공지능 작곡 엔진 모듈은 사용자로부터 수집된 미디 데이터를 복수의 단계로 분해하여 패턴 을 학습하고, 학습된 데이터를 기초로 사용자 맞춤형 연주 데이터를 악기별로 생성할 수 있다. 그리고, 상기 인공지능 작곡 엔진 모듈은 분석한 음악과 생성된 연주패턴 중 유사도가 높은 리듬연주를 찾 고, 이를 기존의 연주 데이터와 매칭시켜 연주 데이터가 없는 새로운 곡을 생성할 수 있다. 상기 인공지능 작곡 엔진 모듈은 본 발명의 한 실시예에 따라 데이터 분석부, 학습부, 그리고 음악 생성부를 포함할 수 있다. 상기 데이터 분석부는 미디 데이터를 복수의 단계로 분해할 수 있다. 예를 들어, 상기 데이터 분석부(43 2)는 악기별, 트랙별, 마디별, 및 음악의 구조별로 순차적으로 분해할 수 있다. 예를 들어, 상기 데이터 분석부는 드럼, 피아노, 기타 등의 악기별로 미디 데이터를 분해하고, 악기별로 분해된 미디데이터를 프로그램 이름, 번호, 악기이름을 통해 트랙별로 분해할 수 있다.또한, 상기 데이터 분석부는 악기별 및 트랙별로 분해된 미디데이터를 시간 배열로 변환 후 마디별로 분해 할 수 있다. 또한, 상기 데이터 분석부는 곡의 구조에 대한 정보를 미디파일 내부에 Marker로 표시하고, 이것을 이용하여 이벤트의 절대 시간을 계산해 음악의 구조별로 분해하여 저장할 수 있다. 그리고, 상기 학습부는 상기 데이터 분석부에서 분해된 데이터를 기초로 딥러닝에 적합한 학습 데이 터셋을 구성하고, 학습의 효율을 위해 데이터를 재가공할 수 있다. 예를 들어, 상기 학습부는 상기 데이터 분석부에서 분해된 미디 데이터를 문자열 데이터를 변환하고, 변환된 문자열 데이터를 숫자 데이터를 인코딩하여 딥러닝에 적합한 학습 데이터셋을 구성할 수 있다. 그리고, 상기 학습부는 인공지능 알고리즘을 통해서 상기 학습 데이터셋을 기초로 기존음악의 패턴을 분석하여 학 습할 수 있다. 또한, 상기 학습부는 인공지능 알고리즘을 통해 음악패턴을 분석하여 학습하고, 이를 기초로 새로운 음악 을 작곡할 수 있다. 여기서, 상기 인공지능 알고리즘은 LSTM 알고리즘을 포함할 수 있다. 그리고, 상기 LSTM 알 고리즘은 순환신경망(Recurrent Neural Network) 알고리즘의 한 종류로 순차적인 정보를 통해 일정 패턴을 분석 하고 하나의 출력에 대해 이전 정보들과 가능성 등을 고려하여 다음 정보를 예측할 수 있다. 또한, 상기 LSTM 알고리즘은 순환신경망 레이어인 LSTM 레이어, 모델 학습 시 오버피팅(예를 들어, 특정 데이터 에만 지나치게 학습되어 그 외의 다른 데이터를 참조하지 못하는 현상)을 방지하는 레이어인 Dropout 레이어, 이전 레이어와 모든 뉴런을 결합시킨 레이어인 Dense 레이어, 및 출력을 계산하기 위한 활성화 레이어인 Activation 레이어를 포함할 수 있다. 여기서, 본 발명의 인공지능 알고리즘은 LSTM 레이어 3개, Dense 레이어 2개, Activation 레이어 1개로 구성될 수 있다. 상기 음악 생성부는 상기 학습부에서 학습된 결과물을 기초로 음악을 생성할 수 있다. 상기 음악 생 성부는 학습에 사용된 모델과 동일한 네트워크 모델을 사용해 음악을 생성할 수 있다. 그리고, 상기 음악 생성부는 학습을 통해 예측된 데이터를 토대로 숫자 형식으로 인코딩된 데이터를 문자열 시퀀스로 디코딩 을 진행할 수 있다. 그리고, 상기 음악 생성부는 가장 높은 가능성의 인덱스를 추출하여 다음 노트(note)를 예측하여 결정하고, 노트를 생성할 때 마다 오프셋을 증가시켜 음악을 생성할 수 있다. 여기서, 상기 노트(note)는 음표 를 포함하며, 특정한 음 또는 특정한 음고를 포함할 수 있다. 따라서, 본 발명은 기존 음악들의 미디 데이터를 수집하여 복수의 단계로 분해하고, 이를 기초로 학습 데이터셋 을 구성하며, 구성된 학습 데이터셋을 바탕으로 기존 음악들의 패턴을 학습한 후 새로운 음악을 생성함으로써, 사용자 맞춤형의 음악을 효과적으로 작곡할 수 있는 환경을 제공한다. 상기 딜레이 측정 모듈은 악기 연주 제어 장치 및 복수의 악기 액추에이터들을 네트워크에 연결하고 초저지연 연주정보를 전송하여 실시간에 가까운 초전지연으로 연동시켜 협연 및 합주를 진행할 수 있도록 상기 악기 연주 제어 장치, 복수의 악기 액추에이터 및 클라이언트들과의 딜레이를 측정한다. 그리고, 상기 딜레이 측정 모듈은 측정된 딜레이를 기초로 상기 악기 연주 제어 장치 또는 클라이언 트들까지 가장 짧은 시간에 도달이 가능한 최단거리 시간을 연산을 수행하고, 최단거리를 갖게되는 노드를 선택하여 연주 데이터를 송수신하도록 최단거리의 데이터 전송 루트를 생성할 수 있다. 여기서, 초저지연 연주 정보는 MIDI와 같은 디지털화된 악보 정보나 실시간으로 발생하는 byte 단위의 디지털 정보 패킷을 포함할 수 있다. 상기 딜레이 측정 모듈은 연주정보 및 연주 데이터를 목적지 디바이스에 전송하기 전에 해당 목적지 디바 이스와의 상호 딜레이를 측정하고, 가장 짧은 시간에 도달이 가능한 최단거리 시간 연산을 수행할 수 있다. 여 기서, 목적지 디바이스는 악기 연주 제어 장치, 상기 복수의 악기 액추에이터 또는 상기 클라이언트 를 포함할 수 있다. 상기 딜레이 측정 모듈은 드럼, 기타, 및 피아노 등에 배치되어 악기를 연주를 제어하는 악기 연주 제어 장치와 연결되며, 상기 악기 연주 제어 장치와의 딜레이를 측정할 수 있다. 또한, 상기 측정부 는 클라이언트와 연결되며, 클라이언트와의 딜레이를 측정할 수도 있다. 상기 딜레이 측정 모듈은 측정 결과를 기초로 상기 목적지 디바이스까지 최단거리를 갖게되는 노드를 선택 하고, 음악정보 byte 데이터를 송수신하도록 노드간 연결을 완성할 수 있다.또한, 상기 딜레이 측정 모듈 또는 상기 악기 연주 제어 장치는 실시간으로 송신하는 연주 데이터의 무결성을 파악하기 위해서 드럼, 기타, 및 피아노 등의 악기 액추에이터에서 연주시 실시간으로 바로바로 악보 를 만들어 각 음표간 시간적 거리를 측정하여 16진법으로 데이터 체크섬을 생성할 수 있다. 그리고, 상기 딜레이 측정 모듈은 상기 데이터 체크섬을 5초에 한번씩 연결된 노드를 통해 클라이언트들에 전송하며, 클라이언트별로 과거 데이터와 비교하여 연주 정확도와 시간 딜레이를 측정하여 연주 데이터의 무결 성과 손실율을 검토할 수 있다. 이때, 상기 딜레이 측정 모듈은 손실율이 설정값(예를들어, 20%) 이상 손실 또는 지연이 발생할 경우 최단 거리 연산을 재수행하여 최단거리 데이터 전송 루트를 재생성하여 새로운 라우트 연결을 구축할 수 있다. 그리고, 상기 딜레이 측정 모듈은 다음 이벤트에서부터는 다시 합의된 새로운 라우트 연결을 통해서 더 손 실 없는 더 빠른 연주 전송에 대한 유지가 가능하도록 상기 루틴을 지속적으로 반복할 수 있다. 상기 연주 정보 전송 모듈은 악기 연주를 위한 연주 데이터 및 미디 데인터를 상기 악기 연주 제어 장치 에 송신하고, 상기 악기 연주 제어 장치로부터 악기 연주에 따른 음향 데이터를 수신할 수 있다. 따라서, 본 발명은 악기를 연주하는 악기 액추에이터, 악기 연주를 제어하는 연주 제어 장치 및 사용자의 클라 이언트 사이의 노드 간의 딜레이를 측정하고, 연주 데이터의 무결성 및 손실율을 검증하여 연주 데이터의 최단 거리 데이터 전송 루트를 설정함으로써, 연주 데이터 전송시의 지연시간을 최소화하여 실시간에 가까운 초저지 연으로 악기 연주를 구현할 수 있는 환경을 제공한다. 도 4는 본 발명의 한 실시예에 따라 원시 데이터를 획득하고, 미디 데이터를 전처리하며, 전처리된 미디 데이터 를 라벨링하고, 데이터 감사를 통해 연주 데이터를 생성하는 과정을 간략히 도시한 흐름도이다. 이때, 이하의 흐름도는 도 1 내지 도 3의 구성과 연계하여 동일한 도면부호를 사용하여 설명한다. 도 4를 참조하면, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 인공지능으로 음악을 학습하여 창작 또는 연주, 변주, 콘텐츠 추천을 위해서 데이터를 구축할 수 있도록 데이터 속성의 포맷을 정의한다 (S102). 여기서, 원시 데이터 중 PCM 데이터는 wav, mp3, aiff, flac, wma, ogg, acc 데이터 포맷을 포함하고, 미디 데이터는 mid, midi 데이터 포맷을 포함할 수 있다. 그리고, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 PCM 기반의 원시데이터 및 MIDI 원시 데 이터를 획득할 수 있다(S104). 이때, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 PCM 기반의 원시데이터로부터 악기별로 미디 데이터를 추출할 수도 있다. 도 5는 본 발명의 한 실시예에 따라 원시 데이터를 획득하여 학습을 위한 미디 데이터를 구축하고, 미디 데이터 를 가공하여 악기별로 연주 데이터를 생성하는 과정을 도시한 도면이고, 도 6은 본 발명의 한 실시예에 따라 원 시 데이터인 PCM 데이터 및 미디 데이터의 예를 도시한 도면이고, 도 7은 본 발명의 한 실시예에 따라 PCM 데이 터에서 악기별로 미디 데이터를 추출하는 예를 도시한 도면이다. 그리고, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 악기 연주에 부적합하거나 중복된 데이 터를 선별하여 제외하고, PCM 기반 데이터를 컨버팅하여 MIDI 데이터로 전처리할 수 있다(S106). 그리고, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 데이터 라벨링을 통해 연주 데이터의 장 르 및 유형을 구분할 수 있다(S108). 예를 들어, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 MIDI 데이터의 장르 및 유형을 구분하여 앨범, 곡, 라이선스, 장르, 길이 국가를 포함하는 메타데이터를 생성하 되, 상기 MIDI 데이터를 박자, 곡의 길이, 곡의 빠르기, 장르, 마디 구성, 곡제목, 및 아티스트 정보가 태깅된 메타데이터를 생성할 수 있다. 도 8은 본 발명의 한 실시예에 따라 메타데이터를 생성하기 위한 라벨링 항목을 도시한 도면이다. 도 8을 참조하면, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 데이터 식별자, 데이터 이름, 데이터 위치, 악기, 장르, 및 타입 정보를 매칭시켜 상기 MIDI 데이터를 라벨링한 메타데이터를 생성할 수 있다. 또한, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 전처리된 미디 데이터를 가공하여 각종 연 주 데이터를 생성하고, 데이터 검사를 통해 로보틱스 연주 IOT 시스템(예를 들어, 드럼, 기타, 베이스, 마림바, 피아노, 퍼커션 등의 악기)에 부합하는 음악 연주 데이터를 구축할 수 있다(S110).따라서, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 원시 데이터를 획득하고, 미디 데이터를 전처리하며, 전처리된 미디 데이터를 라벨링하여 메타데이터를 생성함으로써, 인공지능으로 음악을 생성할 수 있는 학습 데이터셋을 효과적으로 구축할 수 있는 환경을 제공한다. 도 9는 본 발명의 한 실시예에 따라 미디 데이터를 수집하여 분해하고, 학습 데이터셋을 구성하여 음악 패턴을 학습하며, 학습된 음악 패턴을 기초로 사용자 맞춤형의 음악을 작곡하는 과정을 간략히 도시한 흐름도이다. 이 때, 이하의 흐름도는 도 1 내지 도 3의 구성과 연계하여 동일한 도면부호를 사용하여 설명한다. 도 9를 참조하면, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 인공지능으로 미디 데이터를 학습하여 음악을 생성할 수 있도록 미디(MIDI) 데이터를 수집할 수 있다(S202). 예를 들어, 본 발명의 한 실시 예에 따른 인공지능 악기 연주 시스템은 상기 데이터 구축 모듈에서 구축된 데이터를 수집하여 음악을 생성할 수 있다. 또한, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 클라이언트로부터 수집된 미디 데이터를 학습하여 사용자 맞춤형의 음악을 생성할 수도 있다. 그리고, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 수집된 미디 데이터를 복수의 단계로 분 해할 수 있다(S204). 예를 들어, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 악기별, 트랙별, 마디별, 및 음악의 구조별로 수집된 미디 데이터를 순차적으로 분해할 수 있다. 또한, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 딥러닝에 적합한 학습데이터셋을 구성하고 학습의 효율을 위해 데이터를 재가공할 수 있다(S206). 도 10은 본 발명의 한 실시예에 따라 미디 데이터를 문자열 데이터로 변환하는 예를 도시한 도면이고, 도 11은 본 발명의 한 실시예에 따라 문자열 데이터를 숫자 데이터로 인코딩하는 예를 도시한 도면이다. 도 10 및 도 11을 참조하면, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 상기 데이터 분석부 에서 분해된 미디 데이터를 문자열 데이터를 변환하고, 변환된 문자열 데이터를 숫자 데이터를 인코딩하여 딥러닝에 적합한 학습 데이터셋을 구성할 수 있다. 그리고, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 인공지능 알고리즘을 통해서 상기 학습 데이터셋을 기초로 기존음악의 패턴을 분석하여 학습할 수 있다(S208). 도 12는 본 발명의 한 실시예에 따라 학습 데이터셋을 학습하는 학습 진행도 및 학습 데이터 목록의 예를 간략 히 도시한 도면이다. 도 12를 참조하면, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 LSTM 알 고리즘을 통해서 학습 데이터셋의 음악패턴을 분석하고 학습할 수 있다. 또한, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 학습된 결과물을 기초로 숫자 형식으로 인 코딩된 데이터를 문자열 시퀀스로 디코딩을 진행하여 음악을 생성할 수 있다(S210). 도 13은 본 발명의 한 실시 예에 따라 학습된 결과물을 토대로 숫자 형식으로 인코딩된 데이터를 문자열 시퀀스로 디코딩하여 노트를 예측 하고 결정하는 예를 도시한 도면이다. 도 13을 참조하면, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 가장 높은 가능성의 인덱스를 추출하여 다음 노트(note)를 예측하여 결정하고, 노트를 생성할 때 마다 오프셋을 증가시켜 음악을 생성할 수 있다. 여기서, 상기 노트(note)는 음표를 포함하며, 특정한 음 또는 특정한 음고를 포함할 수 있다. 이와 같이, 본 발명의 한 실시예에 따른 인공지능 악기 연주 장치는 모터 제어 신호에 따라 악기에 체결된 악기 액추에이터의 복수개의 서보모터를 구동시켜 악기 목부분의 악기 현을 누르고 악기 몸통부분의 악기 현을 진동 시켜 악기를 연주함으로써, 연주자가 없이도 필요할 때 즉시 연주가 가능한 무인 자동 연주 환경을 제공한다. 또한, 본 발명은 연주 데이터를 수집하고 분석하여 패턴을 학습하고, 악기를 연주하기 위한 미디 데이터를 생성 하며, 생성된 미디 데이터를 기초로 악기 액추에이터의 구동을 제어함으로써, 초보자도 쉽게 악기 연주를 구현 하고, 사용자 맞춤형의 연주를 구현할 수 있는 환경을 제공한다. 또한, 본 발명은 PWM 제어를 통해 악기 액추에이터의 동작속도를 조절하여 연주의 세기를 조절함으로써, 연주 해상도를 향상시킬 수 있는 환경을 제공한다. 이와 같이, 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템은 연주 데이터로부터 악기를 연주하기 위한 모터 제어 신호를 생성하고, 상기 모터 제어 신호로 악기에 체결된 악기 액추에이터를 구동시켜 원격으로 악기 를 연주함으로써, 연주자가 없이도 필요할 때 즉시 연주가 가능한 무인 자동 연주 환경을 제공한다.또한, 본 발명은 원시 데이터를 획득하고, 미디 데이터를 전처리하며, 전처리된 미디 데이터를 라벨링하여 메타 데이터를 생성함으로써, 인공지능으로 음악을 생성할 수 있는 학습 데이터셋을 효과적으로 구축할 수 있는 환경 을 제공한다. 또한, 본 발명은 기존 음악들의 미디 데이터를 수집하여 복수의 단계로 분해하고, 이를 기초로 학습 데이터셋을 구성하며, 구성된 학습 데이터셋을 바탕으로 기존 음악들의 패턴을 학습한 후 새로운 음악을 생성함으로써, 사 용자 맞춤형의 음악을 효과적으로 작곡할 수 있는 환경을 제공한다. 또한, 본 발명은 본 발명은 악기를 연주하는 악기 액추에이터, 악기 연주를 제어하는 연주 제어 장치 및 사용자 의 클라이언트 사이의 노드 간의 딜레이를 측정하고, 연주 데이터의 무결성 및 손실율을 검증하여 연주 데이터 의 최단거리 데이터 전송 루트를 설정함으로써, 연주 데이터 전송시의 지연시간을 최소화하여 실시간에 가까운 초저지연으로 악기 연주를 구현할 수 있는 환경을 제공한다. 이상에서 설명한 본 발명의 실시예는 장치 및 방법을 통해서만 구현이 되는 것은 아니며, 본 발명의 실시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있다. 이러한 기록 매체는 서버뿐만 아니라 사용자 단말에서도 실행될 수 있다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다."}
{"patent_id": "10-2021-0177405", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 한 실시예에 따른 인공지능 악기 연주 시스템의 개략적인 구성을 나타낸 도면이다. 도 2는 본 발명의 한 실시예에 따른 악기 제어 장치의 구성을 간략히 도시한 도면이다. 도 3은 본 발명의 한 실시예에 따른 인공지능 연주 서버의 구성을 간략히 도시한 도면이다. 도 4는 본 발명의 한 실시예에 따라 원시 데이터를 획득하고, 미디 데이터를 전처리하며, 전처리된 미디 데이터 를 라벨링하고, 데이터 감사를 통해 연주 데이터를 생성하는 과정을 간략히 도시한 흐름도이다. 도 5는 본 발명의 한 실시예에 따라 원시 데이터를 획득하여 학습을 위한 미디 데이터를 구축하고, 미디 데이터 를 가공하여 악기별로 연주 데이터를 생성하는 과정을 도시한 도면이다. 도 6은 본 발명의 한 실시예에 따라 원시 데이터인 PCM 데이터 및 미디 데이터의 예를 도시한 도면이다. 도 7은 본 발명의 한 실시예에 따라 PCM 데이터에서 악기별로 미디 데이터를 추출하는 예를 도시한 도면이다. 도 8은 본 발명의 한 실시예에 따라 메타 데이터를 생성하기 위한 라벨링 항목을 도시한 도면이다. 도 9는 본 발명의 한 실시예에 따라 미디 데이터를 수집하여 분해하고, 학습 데이터셋을 구성하여 음악 패턴을 학습하며, 학습된 음악 패턴을 기초로 사용자 맞춤형의 음악을 작곡하는 과정을 간략히 도시한 흐름도이다. 도 10은 본 발명의 한 실시예에 따라 미디 데이터를 문자열 데이터로 변환하는 예를 도시한 도면이다. 도 11은 본 발명의 한 실시예에 따라 문자열 데이터를 숫자 데이터로 인코딩하는 예를 도시한 도면이다. 도 12는 본 발명의 한 실시예에 따라 학습 데이터셋을 학습하는 학습 진행도 및 학습 데이터 목록의 예를 간략 히 도시한 도면이다. 도 13은 본 발명의 한 실시예에 따라 학습된 결과물을 토대로 숫자 형식으로 인코딩된 데이터를 문자열 시퀀스 로 디코딩하여 노트를 예측하고 결정하는 예를 도시한 도면이다."}
