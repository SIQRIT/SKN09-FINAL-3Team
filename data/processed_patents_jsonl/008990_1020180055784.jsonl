{"patent_id": "10-2018-0055784", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0131207", "출원번호": "10-2018-0055784", "발명의 명칭": "센서 품질 저하에 강인한 딥러닝 기반 카메라, 라이더 센서 융합 인지 방법 및 시스템", "출원인": "한양대학교 산학협력단", "발명자": "최준원"}}
{"patent_id": "10-2018-0055784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인지 시스템에 의하여 수행되는 인지 방법에 있어서, 서로 다른 데이터를 각각의 딥 뉴럴 네트워크에 입력하여 각각의 특징맵을 획득하는 단계; 상기 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계; 및상기 융합 네트워크를 통하여 융합된 새로운 특징맵에 기반하여 객체를 검출하는 단계 것을 특징으로 하는 인지 방법."}
{"patent_id": "10-2018-0055784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 서로 다른 데이터를 각각의 딥 뉴럴 네트워크에 입력하여 각각의 특징맵을 획득하는 단계는,상기 서로 다른 데이터가 라이더와 카메라와 관련된 데이터일 경우, 상기 라이더에 대하여 전처리 과정을 수행함에 따라 변환된 2차원의 3채널 이미지와 상기 카메라에 대한 카메라 이미지를 각각의 CNN에 통과시키는 단계를 포함하는 인지 방법."}
{"patent_id": "10-2018-0055784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 서로 다른 데이터를 각각의 딥 뉴럴 네트워크에 입력하여 각각의 특징맵을 획득하는 단계는,상기 라이더로부터 취득한 3차원 포인트 정보를 상기 카메라의 2차원 영상에 매핑하되, 상기 3차원 포인트 정보의 위치 정보를 라이더 좌표에서 카메라 좌표로 변환하는 행렬을 곱하여 2차원 영상의 좌표로 생성하는 전처리과정을 수행하는 단계를 포함하는 인지 방법."}
{"patent_id": "10-2018-0055784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계는,상기 각각의 특징맵에 대한 품질을 판별함에 따라 상기 각각의 특징맵 중 어느 하나 이상의 특징맵에 가중치를부여한 후, 각각의 특징맵을 융합 네트워크를 통하여 융합시키는 단계 를 포함하는 인지 방법."}
{"patent_id": "10-2018-0055784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계는,상기 획득된 각각의 특징맵이 카메라의 특징맵과 라이더의 특징맵일 경우, 상기 카메라의 특징맵과 상기 라이더의 특징맵을 상기 융합 네트워크에 통과시킴에 따라 각각의 특징맵을 병렬로 융합하여 새로운 특징맵을 생성하는 단계를 포함하는 인지 방법."}
{"patent_id": "10-2018-0055784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2019-0131207-3-제5항에 있어서,상기 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계는,상기 카메라의 특징맵과 상기 라이더의 특징맵을 병렬로 1차 융합하고, 상기 1차 융합된 특징맵을 복수의 3X3크기의 커널을 가진 딥 뉴럴 네트워크와 복수의 sigmoid 함수를 통과하여 상기 라이더 또는 상기 카메라의 강인성을 판단하는 단계를 포함하는 인지 방법."}
{"patent_id": "10-2018-0055784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계는,상기 1차 융합된 특징맵을 복수의 3X3 크기의 커널을 가진 딥 뉴럴 네트워크와 sigmoid 함수를 통과시킴에 따라상기 카메라 및 상기 라이더의 데이터에 대한 신뢰도로서 픽셀별로 0 내지 1 사이의 값으로 출력하는 단계 를 포함하는 인지 방법."}
{"patent_id": "10-2018-0055784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계는,상기 카메라에 대한 신뢰도를 카메라의 특징맵에 곱한 값과 상기 라이더에 대한 신뢰도를 상기 라이더의 특징맵에 곱한 값을 다시 병렬로 2차 융합하고, 상기 2차 융합된 특징맵을 1x1 크기의 커널의 딥 뉴럴 네트워크를 통과하여 3차 융합하여 상기 카메라의 특징맵과 라이더의 특징맵에 대한 새로운 특징맵을 도출하는 단계를 포함하는 인지 방법."}
{"patent_id": "10-2018-0055784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 융합 네트워크를 통하여 융합된 새로운 특징맵에 기반하여 객체를 검출하는 단계는,상기 서로 다른 데이터 중 일부의 데이터의 품질을 저하시키기 위한 데이터를 생성하고, 상기 품질이 저하된 데이터를 학습하도록 제어하는 단계 를 포함하는 인지 방법."}
{"patent_id": "10-2018-0055784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 융합 네트워크를 통하여 융합된 새로운 특징맵에 기반하여 객체를 검출하는 단계는, 상기 딥 뉴럴 네트워크와 상기 센서 융합 네트워크를 동시에 학습함에 따라 상기 새로운 특징맵을 처리하여 객체와 관련된 위치와 종류를 동시에 판별하는 단계를 포함하는 인지 방법."}
{"patent_id": "10-2018-0055784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "인지 시스템에 있어서, 서로 다른 데이터를 각각의 딥 뉴럴 네트워크에 입력하여 제1 특징맵 및 제2 특징맵을 획득하는 특징맵 획득부; 상기 획득된 제1 특징맵 및 제2 특징맵을 융합 네트워크를 통하여 융합하는 융합부; 및상기 융합 네트워크를 통하여 융합된 새로운 특징맵에 기반하여 객체를 검출하는 검출부를 포함하는 인지 시스템.공개특허 10-2019-0131207-4-청구항 12 제11항에 있어서,상기 특징맵 획득부는,상기 서로 다른 데이터로서 제1 데이터와 제2 데이터가 입력됨에 따라 상기 제1 데이터에 대하여 전처리 과정을수행함에 따라 변환된 2차원의 3채널 이미지와 상기 제2 데이터에 대한 이미지를 각각의 CNN에 통과시키는 것을 특징으로 하는 인지 시스템."}
{"patent_id": "10-2018-0055784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 융합부는, 상기 제1 특징맵 및 상기 제2 특징맵에 대한 품질을 판별함에 따라 각각의 특징맵 중 어느 하나 이상의 특징맵에 가중치를 부여한 후, 각각의 특징맵을 융합 네트워크를 통하여 융합시키는 것을 특징으로 하는 인지 시스템."}
{"patent_id": "10-2018-0055784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 융합부는, 상기 제1 특징맵과 제2 특징맵을 병렬로 1차 융합하고, 상기 1차 융합된 특징맵을 복수의 3X3 크기의 커널을 가진 딥 뉴럴 네트워크와 sigmoid 함수를 통과시킴에 따라 상기 카메라 및 상기 라이더의 데이터에 대한 신뢰도로서 픽셀별로 0 내지 1 사이의 값으로 출력하는 것을 특징으로 하는 인지 시스템."}
{"patent_id": "10-2018-0055784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 융합부는, 상기 카메라에 대한 신뢰도를 카메라의 특징맵에 곱한 값과 상기 라이더에 대한 신뢰도를 상기 라이더의 특징맵에 곱한 값을 다시 병렬로 2차 융합하고, 상기 2차 융합된 특징맵을 1x1 크기의 커널의 딥 뉴럴 네트워크를 통과하여 3차 융합하여 상기 카메라의 특징맵과 라이더의 특징맵에 대한 새로운 특징맵을 도출하는것을 특징으로 하는 인지 시스템."}
{"patent_id": "10-2018-0055784", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "센서 품질 저하에 강인한 딥러닝 기반 카메라, 라이더 센서 융합 인지 방법 및 시스템이 개시된다. 일 실시예에 따른 인지 시스템에 의하여 수행되는 인지 방법은, 서로 다른 데이터를 각각의 딥 뉴럴 네트워크에 입력하여 각 각의 특징맵을 획득하는 단계; 상기 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계; 및 상기 융 합 네트워크를 통하여 융합된 새로운 특징맵에 기반하여 객체를 검출하는 단계를 포함할 수 있다."}
{"patent_id": "10-2018-0055784", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 서로 다른 데이터를 융합하여 물체를 인지하기 위한 딥러닝 기술에 관한 것이다."}
{"patent_id": "10-2018-0055784", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상 정보를 통한 물체 인지 기법은 기존 컴퓨터 비전 분야에서 다양한 접근 방식으로 활발히 연구되어 왔던 분 야이다. 대표적으로 영상 내에 물체를 인지하는 데 도움을 줄 수 있는 특징들을 영상으로부터 추출하고 분류기 를 통해 물체의 위치와 종류를 판별하는 방법이 있다. 최근에는 딥 뉴럴 네트워크 구조를 활용하는 딥러닝 기 술의 발전으로 인해 대용량의 영상 데이터로부터 특징들을 학습하고 이를 통해 매우 높은 수준의 정확도로 물체 를 검출하는 방법이 제안되었다. 일례로, 영상의 선의 구조나 형태 등의 특징들을 알아내고 이를 이미 알고있는 템플릿과 비교하여 물체를 인지하거나 검출하는 기술로서, 대표적인 특징 추출 기술로 SIFT(Scale invariant feature transform)과 HOG(Historgram of oriented gradients) 표현자 등이 있다. SIFT는 영상에서 코너점 등 식별이 용이한 특징점들을 선택한 후에 각 특징점을 중심으로 한 로컬 패치에 대해 방향성을 갖는 특징 벡터를 추출하는 방법이다. 이는 주변의 밝기 변화의 방향 및 밝기 변화의 급격한 정도를 표현하는 특징을 이용한 방 법이다. HOG는 대상 영역을 일정 크기의 셀로 분할하고, 각 셀마다 경계 픽셀들의 방향에 대한 히스토그램을 구한 후 이들 히스토그램 bin 값들을 일렬로 연결한 벡터를 이용한 방법이다. HOG는 경계의 방향정보를 이용하 기 때문에 일종의 경계기반 템플릿 매칭 방법으로도 볼 수 있다. 또한 물체의 실루엣 정보를 이용하므로 사람, 자동차 등과 같이 내부 패턴이 복잡하지 않으면서도 고유의 독특한 윤곽선 정보를 갖는 물체를 식별하는데 적합 한 방법이다. 이러한 기술들은 미리 엣지나 형태에 대한 물체의 알려진 정보들만을 활용하기 때문에 영상 데이 터에 다양한 조도 변화나 형태 왜곡, 노이즈, 가림등이 발생하는 경우에 특징값이 예측된 분포에서 벗어나게 되 면 인식 성능이 크게 떨어지는 단점이 있다. 최근에 많은 연구가 되고 있는 딥러닝 기술은 방대한 양의 데이터로부터 데이터의 표현 방법 즉 특징 추출을 직 접 학습하는 방법을 사용하여 다양한 환경이나 변화에 좋은 성능을 유지할 수 장점을 갖고 있다. 특히 Convolutional neural network(CNN) 구조는 2차원 영상의 로컬한 특징을 계층적으로 추출하여 영상 인식에 필요 한 고차원 의미 정보를 효과적으로 얻을 수 있다. 최근에 병렬 계산을 할 수 있는 컴퓨터 기술이 발달하고 대 용량 데이터를 활용할 수 있는 인프라가 가능해지면서 이러한 딥러닝 기술이 매우 효과적인 인식 기술로 활용되 고 있다. 한편, 센서융합 기술이란 다양한 센서로부터 취득된 데이터를 결합하여 활용하는 기술을 의미한다. 서로 다른 특성을 갖는 다양한 종류의 센서를 사용하여 인지의 성능과 신뢰성을 높이는 것이 가능하기 때문에 센서 융합은 자율주행이나 영상인지 분야에 있어 중요한 기술이다. 다양한 분포의 센서 데이터를 융합하기 위해서는 여러 가지 융합 기술이 가능한데 일반적으로 초기 단계 융합, 중간 단계 융합, 후기 단계 융합 방식이 존재한다. 초 기 단계 융합은 하나 이상이 데이터를 미리 결합하여 동시에 처리하는 융합 방법이고 후기 단계 융합은 각각의 데이터를 모두 처리하여 최종적인 인지 결과를 얻은 후에 이를 결합하는 기술이다. 중간 단계 융합은 이러한 두 가지 방법의 중간에 위치한 방법이다. 초기 단계 융합은 서로 이질적인 데이터 특성에 의하여 좋은 융합 성 능을 얻기가 어렵고 후기 단계 융합은 데이터의 고차 의미적 상관도를 잘 활용하지 못하는 단점이 있다. 최근 에 딥러닝 기법에 의한 센서융합 기술이 등장하면서 각각의 센서 신호를 별도의 CNN을 통과시킨 뒤에 이를 중간 에서 결합하고 마지막 단계에서의 결합된 특징값을 CNN을 통해 처리하는 중단 단계 융합 기법이 좋은 성능을 나 타내고 있다. 이러한 다양한 센서들로부터 같은 환경에 대해 서로 다른 분포를 갖는 센서 측정 데이터를 얻을 수 있기 때문에 이러한 다른 형태의 센서 데이터를 어떻게 융합하여 센서 성능을 최적화할 것인가의 문제가 중 요해지고 있다. 기본적으로 각각의 센서 데이터를 별도로 처리하여 결과를 반영하는 것 보다는 각 센서 성능의 특성을 반영해 데이터를 효과적으로 결합하는 센서 융합(sensor fusion) 기술이 개발될 필요가 있다. 최근 자율주행 분야에서 센서 융합 기반의 인지 기술에 딥러닝 기술이 적용되고 있다. 특히 자동차에 장착되는 카메라와 라이더 센서를 융합하여 인지 성능의 신뢰성을 높이는 연구가 활발히 진행되고 있다. 이러한 카메라 와 라이더 센서 융합을 위해 딥러닝을 적용하는 기술로서, 라이더 포인트로 탑-뷰 이미지를 만들어 카메라 이미 지와 네트워크 안에서 Fully connected layer를 이용하여 융합하는 방법과, 둘째, 라이더 포인트로 만든 탑-뷰 이미지를 전방 이미지로 변환하여 융합한 방법이 존재한다. 그러나 센서 융합을 통한 물체 인지 기술은 다음과 같은 문제점이 발생할 수 있다. CNN을 이용하여 각각 센서 데이터의 특징맵을 추출한 후에 카메라와 라이더 센서를 네트워크 단에서 융합하는 기술의 경우, 다양한 데이터 를 통해 이미 학습이 되고 나면 고정된 네트워크 계수를 사용하게 된다. 이러한 경우에 두 센서 데이터가 모두 온전한 경우에는 좋은 성능을 나타내지만 하나의 센서 데이터의 품질의 저하가 발생할 경우는 네트워크가 이러 한 상황을 잘 처리하지 못해 성능이 떨어지게 되는 문제가 발생한다. 이에 따라 센서 데이터에 저하가 자주 발 생하는 자율주행 환경의 경우 치명적인 문제의 요인이 될 수 있다. 참고자료: KR10-2018-0003535(2018.01.09.), KR10-1714233(2017.03.02.), KR10-2016-0096460(2016.08.16)"}
{"patent_id": "10-2018-0055784", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "서로 다른 데이터를 딥 뉴럴 네트워크에 입력시킴에 따라 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합 하여 구성된 새로운 특징맵에 기반하여 객체를 검출하는 방법 및 시스템을 제공할 수 있다. 또한, 센서 품질의 저하에 강인한 딥 러닝 기반의 융합 인지 기술을 제공할 수 있다. 다시 말해서, 서로 다른 형태의 센서 성능의 특성을 반영하여 데이터를 효과적으로 결합하는 센서 융합 방법 및 시스템을 제공할 수 있 다. 구체적으로, 카메라의 영상 데이터와 라이더의 포인트 데이터를 융합하기 위한 딥 뉴럴 네트워크를 통하여 물체의 인지 성능을 향상시키며 카메라 혹은 라이더 센서 중 일부 데이터가 저하될지라도 높은 수준의 물체 인 지 성능을 발휘하는 방법 및 시스템을 제공할 수 있다."}
{"patent_id": "10-2018-0055784", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "인지 시스템에 의하여 수행되는 인지 방법은, 서로 다른 데이터를 각각의 딥 뉴럴 네트워크에 입력하여 각각의 특징맵을 획득하는 단계; 상기 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계; 및 상기 융합 네트워크를 통하여 융합된 새로운 특징맵에 기반하여 객체를 검출하는 단계를 포함할 수 있다. 상기 서로 다른 데이터를 각각의 딥 뉴럴 네트워크에 입력하여 각각의 특징맵을 획득하는 단계는, 상기 서로 다 른 데이터가 라이더와 카메라와 관련된 데이터일 경우, 상기 라이더에 대하여 전처리 과정을 수행함에 따라 변 환된 2차원의 3채널 이미지와 상기 카메라에 대한 카메라 이미지를 각각의 CNN에 통과시키는 단계를 포함할 수 있다. 상기 서로 다른 데이터를 각각의 딥 뉴럴 네트워크에 입력하여 각각의 특징맵을 획득하는 단계는, 상기 라이더 로부터 취득한 3차원 포인트 정보를 상기 카메라의 2차원 영상에 매핑하되, 상기 3차원 포인트 정보의 위치 정 보를 라이더 좌표에서 카메라 좌표로 변환하는 행렬을 곱하여 2차원 영상의 좌표로 생성하는 전처리 과정을 수 행하는 단계를 포함할 수 있다. 상기 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계는, 상기 각각의 특징맵에 대한 품질을 판 별함에 따라 상기 각각의 특징맵 중 어느 하나 이상의 특징맵에 가중치를 부여한 후, 각각의 특징맵을 융합 네 트워크를 통하여 융합시키는 단계를 포함할 수 있다. 상기 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계는, 상기 획득된 각각의 특징맵이 카메라의 특징맵과 라이더의 특징맵일 경우, 상기 카메라의 특징맵과 상기 라이더의 특징맵을 상기 융합 네트워크에 통과 시킴에 따라 각각의 특징맵을 병렬로 융합하여 새로운 특징맵을 생성하는 단계를 포함할 수 있다. 상기 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계는, 상기 카메라의 특징맵과 상기 라이더의 특징맵을 병렬로 1차 융합하고, 상기 1차 융합된 특징맵을 복수의 3X3 크기의 커널을 가진 딥 뉴럴 네트워크와 복수의 sigmoid 함수를 통과하여 상기 라이더 또는 상기 카메라의 강인성을 판단하는 단계를 포함할 수 있다. 상기 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계는, 상기 1차 융합된 특징맵을 복수의 3X3 크기의 커널을 가진 딥 뉴럴 네트워크와 sigmoid 함수를 통과시킴에 따라 상기 카메라 및 상기 라이더의 데이터 에 대한 신뢰도로서 픽셀별로 0 내지 1 사이의 값으로 출력하는 단계를 포함할 수 있다. 상기 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계는, 상기 카메라에 대한 신뢰도를 카메라의 특징맵에 곱한 값과 상기 라이더에 대한 신뢰도를 상기 라이더의 특징맵에 곱한 값을 다시 병렬로 2차 융합하고, 상기 2차 융합된 특징맵을 1x1 크기의 커널의 딥 뉴럴 네트워크를 통과하여 3차 융합하여 상기 카메 라의 특징맵과 라이더의 특징맵에 대한 새로운 특징맵을 도출하는 단계를 포함할 수 있다. 상기 융합 네트워크를 통하여 융합된 새로운 특징맵에 기반하여 객체를 검출하는 단계는, 상기 서로 다른 데이 터 중 일부의 데이터의 품질을 저하시키기 위한 데이터를 생성하고, 상기 품질이 저하된 데이터를 학습하도록 제어하는 단계를 포함할 수 있다. 상기 융합 네트워크를 통하여 융합된 새로운 특징맵에 기반하여 객체를 검출하는 단계는, 상기 딥 뉴럴 네트워 크와 상기 센서 융합 네트워크를 동시에 학습함에 따라 상기 새로운 특징맵을 처리하여 객체와 관련된 위치와 종류를 동시에 판별하는 단계를 포함할 수 있다. 인지 시스템은, 서로 다른 데이터를 각각의 딥 뉴럴 네트워크에 입력하여 제1 특징맵 및 제2 특징맵을 획득하는 특징맵 획득부; 상기 획득된 제1 특징맵 및 제2 특징맵을 융합 네트워크를 통하여 융합하는 융합부; 및 상기 융합 네트워크를 통하여 융합된 새로운 특징맵에 기반하여 객체를 검출하는 검출부를 포함할 수 있다. 상기 특징맵 획득부는, 상기 서로 다른 데이터로서 제1 데이터와 제2 데이터가 입력됨에 따라 상기 제1 데이터 에 대하여 전처리 과정을 수행함에 따라 변환된 2차원의 3채널 이미지와 상기 제2 데이터에 대한 이미지를 각각 의 CNN에 통과시킬 수 있다. 상기 융합부는, 상기 제1 특징맵 및 상기 제2 특징맵에 대한 품질을 판별함에 따라 각각의 특징맵 중 어느 하나 이상의 특징맵에 가중치를 부여한 후, 각각의 특징맵을 융합 네트워크를 통하여 융합시킬 수 있다. 상기 융합부는, 상기 제1 특징맵과 제2 특징맵을 병렬로 1차 융합하고, 상기 1차 융합된 특징맵을 복수의 3X3 크기의 커널을 가진 딥 뉴럴 네트워크와 sigmoid 함수를 통과시킴에 따라 상기 카메라 및 상기 라이더의 데이터 에 대한 신뢰도로서 픽셀별로 0 내지 1 사이의 값으로 출력할 수 있다. 상기 융합부는, 상기 카메라에 대한 신뢰도를 카메라의 특징맵에 곱한 값과 상기 라이더에 대한 신뢰도를 상기 라이더의 특징맵에 곱한 값을 다시 병렬로 2차 융합하고, 상기 2차 융합된 특징맵을 1x1 크기의 커널의 딥 뉴럴 네트워크를 통과하여 3차 융합하여 상기 카메라의 특징맵과 라이더의 특징맵에 대한 새로운 특징맵을 도출할 수 있다."}
{"patent_id": "10-2018-0055784", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시예에 따른 인지 시스템은 서로 다른 데이터를 각각의 딥 뉴럴 네트워크에 입력함에 따라 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합된 새로운 특징맵에 기반하여 객체를 인지함으로써 객체의 인지 및 검출 성능을 향상시킬 수 있다. 또한, 융합 네트워크에서 서로 다른 특징맵에 가중치를 부여하여 결합하기 때문에 품질이 저하된 특징맵에 대한 기여도를 조절하여 최적의 센서 융합을 가능하게 한다. 다시 말해서, 종래의 융합 네트워크(GFU)가 없이 트레 이닝이 종료된 네트워크를 적용 시 둘 중의 하나의 센서 데이터에 밝기 변화, 가림, 노이즈, 고장 등의 센서 품 질 저하가 발생할 경우 결합된 특징맵에 영향을 주어 전체적인 인지 성능이 떨어지는 문제가 발생하는 것을 해 결할 수 있다. 또한, 라이더와 카메라에 포함된 정보를 딥 러닝 기법을 이용하여 딥 러닝의 뛰어난 분류 및 일반화 성능을 그 대로 활용할 수 있다는 장점이 있다."}
{"patent_id": "10-2018-0055784", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 실시예를 첨부한 도면을 참조하여 상세히 설명한다. 도 1은 일 실시예에 따른 인지 시스템의 개괄적인 동작을 설명하기 위한 도면이다. 자율주행 또는 스마트 가정을 위한 사물인터넷 환경에서 카메라와 라이더 센서를 융합하여 사물을 인지하고 환 경을 이해할 수 있는 딥 러닝 기반의 물체 인지 알고리즘에 대하여 제안하고자 한다. 딥 러닝 기반의 물 체 인지 알고리즘은 인지 시스템에 의하여 동작될 수 있다. 이때, 서로 다른 특성/구조를 갖는 데이터가 딥 러닝 기반의 물체 인지 알고리즘을 수행함으로써 객체(예를 들면, 물체, 사물 등)를 인지할 수 있다. 아래 의 실시예에서는 카메라의 데이터와 라이더 센서(이하, '라이더'로 기재)의 데이터를 이용하여 객체를 인지하는 방법을 예를 들어 설명하기로 한다. 아래의 실시예에서는 딥 뉴럴 네트워크의 입력으로 라이더로부터 획득한 2차원 포인트 이미지 정보와 카메라를 통해 획득한 영상 정보를 동시에 활용하기 위한 센서 융합 딥 러닝 기술에 대하여 설명하고자 한다. 또한, 라 이더 혹은 카메라 중 하나의 센서 데이터에 저하가 발생하여도 나머지 하나의 센서 데이터를 기반으로 좋은 성 능을 나타내도록 한다. 인지 시스템은 카메라와 라이더의 데이터를 획득함에 따라 데이터 전처리 과정을 수행하여 딥 러닝 기반의 물체 인지 알고리즘을 기반으로 하여 객체를 인지할 수 있다. 카메라로부터 획득한 카메라 데이터를 딥 러닝 기반의 물체 인지 알고리즘에 기반하여 객체를 인지할 수 있다. 이때, 카메라 데이터는 2차원의 영상으로서, RGB 이미지로 구성될 수 있다. 라이더로부터 취득한 3차원 포인트 데이터(3차 원 포인트 클라우드)를 2차원 영상(Front-view 이미지)으로 변환하여 딥 러닝 기반의 물체 인지 알고 리즘에 기반하여 객체를 인지할 수 있다. 구체적으로, 데이터 전처리 과정은 카메라 또는/및 라이더에 수 행될 수 있다. 이에, 라이더로부터 획득된 데이터에 대한 전처리 과정을 설명하기로 한다. 예를 들면, 라이더 로부터 획득된 3차원 공간 정보를 2차원 깊이, 높이 또는 반사율 중 적어도 하나 이상의 정보를 포함하는 영상 으로 변환하여 3채널로 이미지화할 수 있다. 이러한 전처리 과정이 수행된2차원의 3채널 이미지를 RGB 이미지 와 같이 이용하여 각각 두 개의 Convolutional neural network(CNN)의 입력으로 이용할 수 있다. 두 개 의 CNN으로부터 획득된 특징맵을 결합하고, 결합된 특징맵을 이용하여 객체 검출에 관련된 최종적인 정보를 추 출하게 된다. 두 개의 CNN으로부터 획득된 각각의 특징맵을 결합할 때 열악한 상황에서 하나의 센서 신호의 품 질이 저하되는 경우에 강인한 성능을 얻기 위하여 카이더와 카메라의 센서 신호로부터 획득된 특징맵에 적절한 가중치 값을 부여하여 융합하는 센서융합 기법이 적용된다. 이러한 가중치 값은 특징맵을 입력으로 하여 자동 으로 계산이 되고 트레이닝 단계에서 가중치를 계산하는 융합 네트워크를 앞의 두 CNN 네트워크와 함께 동시에 학습시키게 된다. 인지 시스템은 이러한 카메라의 데이터 및 라이더의 데이터를 딥 러닝 기반의 물체 인지 알고리즘에 기반 하여 학습함에 따른 인지 결과, 객체를 검출할 수 있다. 이에 따라, 기존에 라이더 센서와 카메라 센서 융합 기술에 비하여 모두 온전한 데이터뿐만 아니라 특정 센서의 데이터에 품질 저하가 발생하였을 때에도 좋은 인식 성능을 획득할 수 있다. 도 2는 일 실시예에 따른 인지 시스템의 구성을 설명하기 위한 블록도이고, 도 3은 일 실시예에 따른 인지 시스 템의 객체 인지 방법을 설명하기 위한 흐름도이다. 인지 시스템은 특징맵 획득부, 융합부 및 검출부를 포함할 수 있다. 이러한 구성요소들은 인지 시스템에 저장된 프로그램 코드가 제공하는 제어 명령에 따라 프로세서에 의해 수행되는 서로 다른 기능들(different functions)의 표현들일 수 있다. 구성요소들은 도 3의 객체 인지 방법이 포함하는 단계들 (310 내지 330)을 수행하도록 인지 시스템을 제어할 수 있다. 이때, 구성요소들은 메모리가 포함하는 운 영체제의 코드와 적어도 하나의 프로그램의 코드에 따른 명령(instruction)을 실행하도록 구현될 수 있다. 인지 시스템의 프로세서는 객체 인지 방법을 위한 프로그램의 파일에 저장된 프로그램 코드를 메모리에 로 딩할 수 있다. 예를 들면, 인지 시스템에서 프로그램이 실행되면, 프로세서는 운영체제의 제어에 따라 프 로그램의 파일로부터 프로그램 코드를 메모리에 로딩하도록 인지 시스템을 제어할 수 있다. 이때, 프로세서 및 프로세서가 포함하는 특징맵 획득부, 융합부 및 검출부 각각은 메모리에 로딩된 프로그램 코드 중 대응하는 부분의 명령을 실행하여 이후 단계들(310 내지 330)을 실행하기 위한 프로세서의 서로 다른 기능적 표현들일 수 있다. 단계에서 특징맵 획득부는 서로 다른 데이터를 각각의 딥 뉴럴 네트워크에 입력하여 각각의 특징맵을 획득할 수 있다. 특징맵 획득부는 서로 다른 데이터로서 제1 센서와 제2 센서가 입력됨에 따라 제1 센서 의 데이터에 대하여 전처리 과정을 수행함에 따라 변환된 2차원의 3채널 이미지와 제2 센서에 대한 이미지를 각각의 CNN에 통과시킬 수 있다. 예를 들면, 특징맵 획득부는 서로 다른 데이터가 라이더와 카메라와 관련 된 데이터일 경우, 라이더에 대하여 전처리 과정을 수행함에 따라 변환된 2차원의 3채널 이미지와 카메라에 대 한 카메라 이미지를 각각의 CNN에 통과시킬 수 있다. 이때, 특징맵 획득부는 라이더로부터 취득한 3차원 포인트 정보를 카메라의 2차원 영상에 매핑하되, 3차원 포인트 정보의 위치 정보를 라이더 좌표에서 카메라 좌 표로 변환하는 행렬을 곱하여 2차원 영상의 좌표로 생성하는 전처리 과정을 수행할 수 있다. 단계에서 융합부는 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합할 수 있다. 융합부는 각각의 특징맵에 대한 품질을 판별함에 따라 각각의 특징맵 중 어느 하나 이상의 특징맵에 가중치를 부여한 후, 각각의 특징맵을 융합 네트워크를 통하여 융합시킬 수 있다. 융합부는 획득된 각각의 특징맵이 카메라의 특징맵과 상기 라이더의 특징맵일 경우, 카메라의 특징맵과 라이더의 특징맵을 융합 네트워크에 통과시킴에 따 라 각각의 특징맵을 병렬로 융합하여 새로운 특징맵을 생성할 수 있다. 융합부는 카메라의 특징맵과 상기 라이더의 특징맵을 병렬로 1차 융합하고, 1차 융합된 특징맵을 복수의 3X3 크기의 커널을 가진 딥 뉴럴 네트워 크와 복수의 sigmoid 함수를 통과하여 라이더 또는 상기 카메라의 강인성을 판단할 수 있다. 융합부는 1 차 융합된 특징맵을 복수의 3X3 크기의 커널을 가진 딥 뉴럴 네트워크와 sigmoid 함수를 통과시킴에 따라 카메 라 및 라이더의 데이터에 대한 신뢰도로서 픽셀별로 0 내지 1 사이의 값으로 출력시킬 수 있다. 융합부는 카메라에 대한 신뢰도를 카메라의 특징맵에 곱한 값과 라이더에 대한 신뢰도를 라이더의 특징맵에 곱한 값을 다 시 병렬로 2차 융합하고, 2차 융합된 특징맵을 1x1 크기의 커널의 딥 뉴럴 네트워크를 통과하여 3차 융합하여 카메라의 특징맵과 라이더의 특징맵에 대한 새로운 특징맵을 도출할 수 있다. 단계에서 검출부는 융합 네트워크를 통하여 융합된 새로운 특징맵에 기반하여 객체를 검출할 수 있다. 검출부는 딥 뉴럴 네트워크와 센서 융합 네트워크를 동시에 학습함에 따라 새로운 특징맵을 처리하 여 객체와 관련된 위치와 종류를 동시에 판별할 수 있다. 검출부는 서로 다른 데이터 중 일부의 데이터의 품질을 저하시키기 위한 데이터를 생성하고, 품질이 저하된 데이터를 학습하도록 제어할 수 있다. 딥 러닝 기반 물체 인지 알고리즘은 라이더와 카메라에 포함된 정보를 딥 러닝 기법을 이용하여 딥러닝의 뛰어 난 분류 및 일반화 성능을 그대로 활용할 수 있다는 장점이 있다. 도 4는 일 실시예에 따른 인지 시스템의 딥 러닝 기반의 물체 인지 알고리즘의 구조를 설명하기 위한 도면이다. 도 4를 참고하면, 딥 러닝 기반의 물체 인지 알고리즘의 구조를 나타낸 것이다. 카메라와 라이더의 센서 데이터를 복수의 딥 뉴럴 네트워크(예를 들면, CNN)에 각각 먼저 통과시킴에 따라 각 데이터의 품질을 판별한 후, 두 데이터를 융합하여 객체를 인지할 수 있다. 다시 말해서, 카메라의 RGB 이미지(이하, 카메라 이미 지)와 라이더의 라이다 이미지가 각각의 딥 뉴럴 네트워크에 입력될 수 있다. 이때, 센서 융합 기술 을 위하여 라이더의 데이터에 전처리 과정이 수행될 수 있다. 라이더를 통하여 취득한 3차원 포인트 정보를 카 메라의 2차원의 영상에 매핑할 수 있다. 3차원 포인트의 좌표 정보 p=(x, y, z)에 라이더 좌표에서 카메라 좌 표로 변환하는 행렬을 곱하여 2차원의 영상 좌표 를 도출할 수 있다. 영상 좌표는 영상의 각 픽 셀의 위치에 해당하게 되고, 픽셀값은 깊이, 높이, 반사율 정보 값으로부터 획득될 수 있다. 예를 들면, 매우 가까이 있는 포인트에 대해서는 255에 가까운 밝기로, 매우 먼 경우에 있는 포인트에 대해서는 0에 가까운 밝기 로 변환될 수 있다. 이 경우, 포인트를 이용하여 2차원 공간을 모두 채울 수 없기 때문에 포인트가 이미지 상 에 생긴 형태로 드문드문(sparse) 나타나게 된다. 포인트가 존재하지 않는 픽셀의 경우 0으로 채울 수 있다. 이미 카메라의 좌표와 라이더의 좌표가 정합이 되어 있을 경우, 앞서 설명한 바와 같은 방법으로 라이더의 데이 터를 변환하여 새로운 2차원의 3채널 이미지를 추가적으로 획득할 수 있다. 이와 같이, 라이더에 대하여 전처 리 과정을 수행함에 따라 변환된 라이더에 대한 2차원의 3채널 이미지와 카메라의 카메라 이미지를 각각의 딥 뉴럴 네트워크(예를 들면, CNN)에 통과시킬 수 있다. 도 4와 같이, 딥 뉴럴 네트워크의 입력 부분 에는 라이더의 3채널 이미지와 카메라의 카메라 이미지를 각각 독립적인 CNN을 통과시킨 후, 어느 시점 이후의 네트워크 노드에서 획득되는 특징맵(feature map)을 융합 네트워크(GFU)를 통하여 융합하여 새로운 특징맵 을 구성할 수 있다. 이러한 특징맵을 처리함에 따라 객체의 위치와 종류를 동시에 판별할 수 있다. 이때, 예를 들면, Single Shot Detector(SSD) 방법을 통하여 객체가 검출될 수 있으며, SSD 방법 이외에도 다양 한 방법을 통하여 객체를 검출할 수도 있다. 도 5를 참고하면, 카메라의 특징맵과 라이더의 특징맵의 융합을 위한 GFU의 구조를 설명하기 위한 도 면이다. 각각의 특징맵에 대한 품질을 판별함에 따라 각각의 특징맵 중 어느 하나 이상의 특징맵에 가중치를 부여한 후, 각각의 특징맵을 융합 네트워크(GFU)를 통과시켜 융합할 수 있다. 구체적으로, 우선, 카메라 의 특징맵과 라이더의 특징맵이 병렬로 합치게 된다. 그 후, 병렬로 합쳐진 특징맵(1차 융합특징맵)은 각각 3X3 크기의 커널을 가진 CNN과 sigmoid 함수를 통과하게 된다. 이러한 과정을 통하여 카메라와 라이더의 데이터 중 어느 데이터가 더 신뢰성 있는 데이터인지 강인성을 판단할 수 있다. 이때, 병렬로 합쳐진 특징맵(1차 융합 특징맵)이 3X3 크기의 커널을 가진 CNN과 sigmoid 함수를 통과함에 따라 픽셀별로 데이터에 대 한 신뢰도로서 0 내지 1 사이의 값으로 매핑하여 출력 데이터를 출력할 수 있다. 다시 말해서, 3X3 크기의 커 널을 가진 CNN과 sigmoid 함수를 통과한 출력이 데이터에 대한 신뢰도로서 0부터 1 사이의 값으로 픽섹별로 도 출될 수 있다. 이러한 신뢰도는 다시 카메라와 라이더의 각 특징맵에 곱해질 수 있고, 곱해진 특징맵은 다시 병렬로 합쳐지는 과정이 수행될 수 있다. 그리고 나서, 1X1크기의 커널을 가진 CNN을 통과하여 최종적으로 카 메라의 특징맵과 라이더의 특징맵이 융합된다. 구체적으로, 카메라에 대한 신뢰도를 카메라의 특징맵에 곱한 값 과 라이더에 대한 신뢰도를 라이더의 특징맵에 곱한 값을 다시 병렬로 2차 융합하고, 2차 융합된 특징맵을 1X1 크기의 커널의 딥 뉴럴 네트워크(예를 들면, CNN)를 통과하여 3차 융합하여 카메라의 특징맵과 라이더의 특징맵 에 대한 새로운 특징맵이 구성될 수 있다. 마지막으로, GFU 계수와 각 센서에 해당하는 CNN, 융합된 특징맵으 로부터 검출 결과를 추출하는 네트워크의 계수를 동시에 학습시키게 된다. 이에 따라 새로운 특징맵에 기반하 여 객체가 검출될 수 있다. 이때, 카메라와 라이더의 센서 품질이 저하될 경우, 이에 적합한 가중치를 부여하는 기능을 학습하기 위하여 카 메라와 라이더 중 하나에 품질의 저하를 적용하는 데이터 augmentation 기법이 필요하다. 예를 들면, 도 6을 참고하면, 실시예에서 제안된 딥 러닝 기반의 물체인지 알고리즘의 성능을 평가하기 위하여 카메라의 이미지에 성능 저하를 시킨 것을 나타낸 예이다. 도 6(a)는 밝기가 조작된 영상 데이터이고, 도 6(b)는 일부분이 가려진 영상 데이터이고, 도 6(c)는 노이즈가 포함된 영상 데이터이고, 도 6(d)는 원본의 영상 데이터이다. 영상 데이 터의 부분적으로 가림이 있다거나 밝기를 조절한다든지 둘 중 하나의 데이터를 제거하는 등의 조작을 통해서 강 인성을 주기 위한 추가적인 데이터 생성을 수행하고 이를 통해 해당 네트워크를 학습시킬 수 있다. 이러한 일 부 데이터의 품질을 저하시켜 데이터를 학습하도록 함으로써 영상의 품질에 따라 적응적으로 네트워크의 구조뿐 만 아니라 가중치를 부여하도록 할 수 있다. 일 실시예에 따른 인지 시스템은 딥 러닝을 통해서 센서 융합을 하는 경우에 CNN을 통하여 획득된 특징맵을 결 합하여 새로운 특징맵을 획득하고, 획득된 새로운 특징맵을 추가적으로 CNN 계층을 더 적용하여 센서 융합 기반 의 물체 검출을 수행하게 된다. 이때, 융합 네트워크(GFU)에서 각각의 특징맵에 적절한 가중치를 부여하여 결 합하기 때문에 품질이 저하된 특징맵에 대한 기여를 조절함으로써 최적의 센서 융합이 이루어지게 된다. 또한, 라이더와 카메라에 대한 데이터의 장점을 이용한 융합을 발휘할 수 있고, 하나의 센서 데이터에 저하가 발생한 경우도 최적의 융합을 가능하게 한다. 도 7은 일 실시예에 따른 인지 시스템의 성능을 설명하기 위한 표이다. 카메라와 라이더의 데이터의 융합을 위한 딥 러닝 기법을 통하여 물체 인지 및 검출 성능을 향상시킬 수 있다. 일례로, KITTI 벤치마크 데이터 셋을 이용하여, 라이더 좌표와 카메라 좌표를 정합한 후 라이더 센서의 3차원 포인트 데이터를 2차원 영상으로 변환한 후, 라이더 센서의 2차원 영상과 카메라의 영상을 CNN에 각각 입력할 수 있다. 이때, 융합 네트워크(GFU)를 통하여 센서 데이터의 품질 판단 및 융합을 하여 객체를 인지하게 된다. 도 7에서 GFU에 대한 성능을 베이스 네트워크에 GFU가 포함된 경우와, GFU가 포함되지 않은 경우를 비교한 결과 를 나타낸 것이다. 예를 들면, 성능을 비교하기 위하여 카메라 이미지가 비었거나, 일부 가려지거나, 일부분이 밝게 되거나, 노이즈가 섞인 경우에서 진행될 수 있고, 이외에도 라이더 이미지가 비었거나, 일부 가려진 환경 에서도 진행될 수 있다. 이에 따라, 비교 결과 모든 항목에서 GFU가 존재하는 네트워크가 더 좋은 성능을 나타 내었으며, 특히, 노이즈가 섞인 경우에는 보다 큰 성능 차이를 보이는 것을 확인할 수 있다. 일 실시예에 따른 인지 시스템은 최근 자율주행에서 라이더와 카메라 센서가 동시에 활용될 것으로 예상되는 자 율주행에 적용될 수 있고, 자율주행뿐만 아니라 환경이나 물체를 인식하는 다양한 인공지능 분야에도 적용이 가 능하다. 대표적인 적용 가능 분야로는 자율주행자동차, 로봇공학 및 차량 모니터링 시스템이 있다. 첫째로, 자율주행자 동차에서 물체 인지는 가장 먼저 수반되어야 하는 기술로, 주변의 물체 및 보행자가 어느 위치에 존재하는지 위 험한 요소는 없는지 판단하는 역할을 하며 이를 통해 안전한 주행을 할 수 있고 사고를 미연에 방지할 수 있다. 또한 주행 보조를 위해 신호등이나 표지판 등 주행 시 필요한 도로 정보를 확인하는 데에 사용된다. 둘째로, 로봇 공학에서 물체 인지는 사람의 눈처럼 로봇의 시각적 활동을 돕는다. 물체 인지를 통해 로봇이 주변 상황 및 물체를 확인하여 이를 바탕으로 목적에 맞는 기능을 수행할 수 있도록 한다. 또한 물체 인지 기술은 차량 모니터링 시스템에도 적용 가능하다. 주차 관리 시스템을 예로 들면, 주차장으로 입차하는 차의 종류 및 차량번호를 인지하고 더 나아가 현재 빈자리 상황까지 확인하여 주차를 도울 수 있다. 이 기술을 적용하기 위해서는 카메라, 라이더 센서를 이용하여 데이터를 실시간으로 취득하고 이를 그래픽 프로 세서 유닛(GPU) 등을 장착한 임베디드 시스템에서 물체 인식 알고리즘을 수행하는 방법이 있다. 이를 위해서는 미리 다양한 환경에 대한 데이터들을 확보하고 이를 통해 딥 뉴럴 네트워크의 구조를 학습시키게 된다. 학습된 딥 뉴럴 네트워크는 최적화된 네트워크 계수로 저장되게 되고 이를 임베디드 시스템에 적용하여 실시간으로 입 력되는 테스트 데이터에 대해 물체인지 알고리즘을 수행하여 그 결과를 획득하도록 한다. 또한, 카메라, 라이더 센서 기반의 물체 인지 알고리즘은 현재 자율주행이나 모바일 로봇등에 응용될 수 있으며 향후 인지를 넘어 객체 추적 및 미래 예측 등 좀 더 복잡한 기능을 수행할 것으로 예상된다. 예를 들면 자동화 된 감시, 교통 모니터링 및 차량 탐색 또는 도로 위의 교통상황을 고려한 신호등 제어 등도 가능해 질 것이다. 더불어 객체 인식은 주변 환경을 이해하는데 중요한 역할을 하며 이를 IoT를 결합한 가전제품에 적용 가능하다. 이와 같이 딥 러닝 기반의 물체 인지 알고리즘은 미래 기술에 기초가 되는 기술로 대표적인 인공지능 기술 중의 하나라고 할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2018-0055784", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2018-0055784", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2018-0055784", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 인지 시스템의 개괄적인 동작을 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 인지 시스템의 구성을 설명하기 위한 블록도이다. 도 3은 일 실시예에 따른 인지 시스템의 객체 인지 방법을 설명하기 위한 흐름도이다. 도 4는 일 실시예에 따른 인지 시스템에서 딥 러닝 기반의 물체 인지 알고리즘의 구조를 설명하기 위한 도면이 다. 도 5는 일 실시예에 따른 인지 시스템에서 서로 다른 데이터의 융합을 위한 GFU의 구조를 설명하기 위한 도면이 다. 도 6은 일 실시예에 따른 인지 시스템의 성능을 평가하기 위하여 카메라 이미지의 성능을 저하시킨 것을 나타낸 예이다. 도 7은 일 실시예에 따른 인지 시스템의 성능을 설명하기 위한 표이다."}
