{"patent_id": "10-2021-0007191", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0117917", "출원번호": "10-2021-0007191", "발명의 명칭": "데이터의 특징점을 취합하여 기계 학습하는 방법 및 장치", "출원인": "주식회사 루닛", "발명자": "이정훈"}}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 장치로 동작하는 인공지능 모델의 동작 방법에 있어서, 서로 다른 복수의 데이터 세트 각각에서 학습된 복수의 인공지능 모델을 획득하는 단계;상기 획득된 복수의 인공지능 모델을 병합한 통합 인공지능 모델을 생성하는 단계;상기 서로 다른 복수의 데이터 세트에 포함된 적어도 일부의 데이터를 상기 생성된 통합 인공지능 모델에 입력하여 상기 통합 인공지능 모델에서 출력되는 출력 데이터를 획득하는 단계; 및상기 획득된 출력 데이터를 이용하여 상기 적어도 일부의 데이터에 대한 학습 데이터 세트를 생성하는 단계를포함하는인공지능 모델의 동작 방법."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 출력 데이터는상기 통합 인공지능 모델에 포함된 복수의 레이어 중 적어도 하나의 레이어에서 출력되는 특징 데이터인인공지능 모델의 동작 방법."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 특징 데이터는상기 입력된 데이터의 민감 정보가 식별되지 않는인공지능 모델의 동작 방법."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 복수의 인공지능 모델 각각은입력된 데이터에서 특징(feature)을 추출하는 특징 추출기를 포함하는인공지능 모델의 동작 방법."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 특징 추출기는CNN(Convolution Neural Network) 기반의 특징 추출기인공개특허 10-2021-0117917-3-인공지능 모델의 동작 방법."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 학습 데이터 세트를 생성하는 단계는상기 획득된 출력 데이터 및, 상기 적어도 일부의 데이터에 대응하는 레이블(label) 정보를 포함하는 학습 데이터 세트를 생성하는 단계를 포함하는인공지능 모델의 동작 방법."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 생성된 학습 데이터 세트를 이용하여, 목적 인공지능 모델을 학습시키는 단계를 더 포함하는인공지능 모델의 동작 방법."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 출력 데이터는상기 통합 인공지능 모델에 포함된 상기 복수의 인공지능 모델 각각에서 출력되는 복수의 서브 출력 데이터를포함하는 인공지능 모델의 동작 방법."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 서로 다른 복수의 데이터 세트 각각은서로 다른 환경에서 획득된 데이터를 포함하는 데이터 세트인인공지능 모델의 동작 방법."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "적어도 하나의 프로세서; 및상기 프로세서에 의해 실행되는 명령어들을 저장하는 메모리를 포함하고, 상기 프로세서는 실행 시에, 서로 다른 복수의 데이터 세트 각각에서 학습된 복수의 인공지능 모델을 획득하고, 상기 획득된 복수의 인공지능 모델을 병합한 통합 인공지능 모델을 생성하고, 상기 서로 다른 복수의 데이터 세트에 포함된 적어도 일부의 데이터를 상기 생성된 통합 인공지능 모델에 입력하여 상기 통합 인공지능 모델에서 출력되는 출력 데이터를 획득하고,공개특허 10-2021-0117917-4-상기 획득된 출력 데이터를 이용하여 상기 적어도 일부의 데이터에 대한 학습 데이터 세트를 생성하는전자 장치."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 출력 데이터는상기 통합 인공지능 모델에 포함된 복수의 레이어 중 적어도 하나의 레이어에서 출력되는 특징 데이터인전자 장치."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 특징 데이터는상기 입력된 데이터의 민감 정보가 식별되지 않는전자 장치."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서,상기 복수의 인공지능 모델 각각은입력된 데이터에서 특징(feature)을 추출하는 특징 추출기를 포함하는전자 장치."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 특징 추출기는CNN(Convolution Neural Network) 기반의 특징 추출기인전자 장치."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,상기 프로세서는 실행 시에, 상기 획득된 출력 데이터 및, 상기 적어도 일부의 데이터에 대응하는 레이블(label) 정보를 포함하는 학습 데이터 세트를 생성하는전자 장치."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "공개특허 10-2021-0117917-5-제15항에 있어서,상기 프로세서는 실행 시에, 상기 생성된 학습 데이터 세트를 이용하여, 목적 인공지능 모델을 학습시키는전자 장치."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항에 있어서,상기 출력 데이터는상기 통합 인공지능 모델에 포함된 상기 복수의 인공지능 모델 각각에서 출력되는 복수의 서브 출력 데이터를포함하는 전자 장치."}
{"patent_id": "10-2021-0007191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항에 있어서,상기 서로 다른 복수의 데이터 세트 각각은서로 다른 환경에서 획득된 데이터를 포함하는 데이터 세트인전자 장치."}
{"patent_id": "10-2021-0007191", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 의료 데이터의 특징점을 취합하여 기계 학습하는 방법 및 장치에 대한 것으로서, 서로 독립적인 복수 의 학습 데이터 세트에 각각 기계학습을 수행하여 획득된 복수의 서브 기계학습모델을 수신하는 단계 및 복수의 서브 기계학습모델에 기초하여 통합기계학습모델을 획득하는 단계를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2021-0007191", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 데이터의 특징점을 취합하여 기계 학습하는 방법 및 장치에 대한 것이다. 보다 구체적으로 본 개시는 데이터와 관련된 민감 정보를 보호하면서도 기계학습장치의 성능을 높이기 위한 기계 학습 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2021-0007191", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최상의 기계학습모델을 획득하기 위해서는 최대한 많은 데이터를 입력에 기초하여 기계학습을 수행하는 것이 필 요하다. 하지만, 데이터를 저장하고 있는 물리적인 환경 또는 보안적인 문제로 인해, 데이터 센터에서 데이터를 반출하는 것이 어려운 경우가 있다. 예를 들어 데이터 센터의 대상 데이터가 의료 데이터인 경우, 민감한 개인 정보로 분류되므로 데이터의 공유에 큰 제약조건이 따르게 된다. 의료 데이터는 환자의 신상정보, 환자가 앓고 있는 질환 정보, 환자가 걸릴 가능성이 높은 질환 정보 또는 환자의 가족력 등과 같이 개인정보와 관련된 민감 정보를 포함하기 때문이다. 따라서, 각 센터의 데이터 세트를 모두 이용하여 기계학습모델의 성능을 높이는 다 양한 방법에 대한 연구가 계속되고 있다. 일 예로, 최근 연합 학습(Federated learning)이라는 기법이 각광을 받고 있다. 이 기법은 각 기관에 독립적인 딥러닝 모델을 설치하여, 마스터 서버(Master server)와 함께 동기화하여 통합된 데이터처럼 딥러닝 모델을 학 습할 수 있도록 하는 알고리즘이다. 이는 민감데이터를 공유하지 않으면서도 공유한 효과를 낼 수 있는 알고리 즘이다. 하지만 연합 학습은 기관의 협조가 필요하다. 각 독립적인 모델이 병원에서 제공한 데이터에 접근이 가능하여야 하며, 학습된 모델이 외부의 마스터 서버에 존재하는 모델과 동기화가 될 수 있는 상황이 구현되어야 한다. 하 지만 개인정보보호를 중시하는 의료기관들은 의료기관 안에서만 데이터 공유가 이루어지는 인트라 네트워크를"}
{"patent_id": "10-2021-0007191", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "사용하고 있다. 따라서 외부와 단절된 상황에서 연합모델을 구현하기 위해서는 많은 어려움이 있는 실정이다.발명의 내용"}
{"patent_id": "10-2021-0007191", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시에 따른 기계학습방법은, 서로 독립적인 복수의 학습 데이터 세트에 각각 기계학습을 수행하여 획득된 복수의 서브 기계학습모델을 수신하는 단계 및 복수의 서브 기계학습모델에 기초하여 통합기계학습모델을 획득 하는 단계를 포함한다. 본 개시에 따른 기계학습방법의 복수의 서브 기계학습모델을 수신하는 단계는, 복수의 학습 데이터 세트에 포함 되는 제 1 학습 데이터 세트에 기초하여 기계학습된 제 1 서브 기계학습모델을 수신하는 단계 및 복수의 학습 데이터 세트에 포함되는 제 2 학습 데이터 세트에 기초하여 기계학습된 제 2 서브 기계학습모델을 수신하는 단 계를 포함하고, 통합기계학습모델을 획득하는 단계는 제 1 서브 기계학습모델 및 제 2 서브 기계학습모델을 병 합하여 통합기계학습모델을 획득하는 단계를 포함한다. 본 개시에 따른 기계학습방법은, 제 1 학습 데이터 세트에 포함된 제 1 분석 대상 데이터에 통합기계학습모델을 적용하여 획득된 제 1 특징 데이터를 수신하는 단계, 제 2 학습 데이터 세트에 포함된 제 2 분석 대상 데이터에 통합기계학습모델을 적용하여 획득된 제 2 특징 데이터를 수신하는 단계 및 제 1 특징 데이터 및 제 1 학습 데 이터 세트에 포함된 제 1 분석 결과 데이터의 상관 관계 그리고 제 2 특징 데이터 및 제 2 학습 데이터 세트에 포함된 제 2 분석 결과 데이터의 상관 관계를 기계학습하여 최종기계학습모델을 획득하는 단계를 더 포함한다. 본 개시에 따른 기계학습방법은, 테스트 데이터에 통합기계학습모델을 적용하여 획득된 예측 특징 데이터를 수 신하는 단계, 예측 특징 데이터에 최종기계학습모델을 적용하여 테스트 데이터에 대응하는 예측 결과 데이터를 획득하는 단계를 더 포함한다. 본 개시에 따른 기계학습방법의 복수의 학습 데이터 세트는 서로 다른 환경에서 획득된 의료 영상과 관련된 데 이터이다. 본 개시에 따른 기계학습방법의 제 1 특징 데이터, 제 2 특징 데이터 및 예측 특징 데이터는 제 1 분석 대상 데 이터, 제 2 분석 대상 데이터 및 테스트 데이터를 손실 압축한 데이터이다. 본 개시에 따른 기계학습방법의 제 1 분석 대상 데이터, 제 2 분석 대상 데이터 및 테스트 데이터는 개인정보가 포함되고, 제 1 특징 데이터, 제 2 특징 데이터 및 예측 특징 데이터는 개인정보가 식별되지 않는다. 본 개시에 따른 기계학습방법의 복수의 서브 기계학습모델은 CNN(Convolution Neural Network)를 이용하여 획득 된다. 본 개시에 따른 기계학습방법의 제 1 학습 데이터 세트에 포함된 제 1 분석 결과 데이터는 제 1 학습 데이터 세 트에 포함된 제 1 분석 대상 데이터를 사용자가 분석한 결과이고, 제 2 학습 데이터 세트에 포함된 제 2 분석 결과 데이터는 제 2 학습 데이터 세트에 포함된 제 2 분석 대상 데이터를 사용자가 분석한 결과이다. 본 개시에 따른 기계학습방법의 제 1 특징 데이터는 제 1 분석 대상 데이터를 제 1 서브 기계학습모델에 적용하 여 획득되는 제 1 복수의 특징 레이어들 중 적어도 하나의 특징 레이어 및 제 1 분석 대상 데이터를 제 2 서브 기계학습모델에 적용하여 획득되는 제 2 복수의 특징 레이어들 중 적어도 하나의 특징 레이어를 결합한 데이터 이고, 제 2 특징 데이터는 제 2 분석 대상 데이터를 제 1 서브 기계학습모델에 적용하여 획득되는 제 3 복수의 특징 레이어들 중 적어도 하나의 특징 레이어 및 제 2 분석 대상 데이터를 제 2 서브 기계학습모델에 적용하여 획득되는 제 4 복수의 특징 레이어들 중 적어도 하나의 특징 레이어를 결합한 데이터이다. 본 개시에 따른 기계학습방법의 제 1 복수의 특징 레이어들, 제 2 복수의 특징 레이어들, 제 3 복수의 특징 레 이어들 및 제 4 복수의 특징 레이어들에서 동일 위치의 레이어를 선택하여, 제 1 특징 데이터 및 제 2 특징 데 이터가 획득된다. 본 개시에 따른 기계학습방법은, 통합기계학습모델을 획득하는 단계, 통합기계학습모델을 서로 독립적인 복수의 학습 데이터 세트에 포함된 복수의 분석 대상 데이터에 적용하여 획득된 복수의 특징 데이터를 수신하는 단계 및 복수의 특징 데이터와 복수의 학습 데이터 세트에 포함된 복수의 분석 결과 데이터 사이의 관계를 기계학습하여 최종기계학습모델을 획득하는 단계를 포함한다. 본 개시에 따른 기계학습방법은, 테스트 데이터를 통합기계학습모델에 적용하여 획득된 예측 특징 데이터를 수 신하는 단계 및 예측 특징 데이터를 최종기계학습모델에 적용하여 테스트 데이터에 관련된 예측 결과 데이터를 획득하는 단계를 포함한다. 본 개시에 따른 기계학습방법의 통합기계학습모델을 획득하는 단계는, 복수의 학습 데이터 세트에 포함되고, 제 1 분석 대상 데이터 및 제 1 분석 결과 데이터를 포함하는 제 1 학습 데이터 세트를 기계학습한 제 1 서브 기계 학습모델을 수신하는 단계, 복수의 학습 데이터 세트에 포함되고, 제 1 학습 데이터 세트와 독립적이고, 제 2 분석 대상 데이터 및 제 2 분석 결과 데이터를 포함하는 제 2 데이터 세트를 기계학습한 제 2 서브 기계학습모 델을 수신하는 단계 및 제 1 서브 기계학습모델 및 제 2 서브 기계학습모델을 병합하여 통합기계학습모델을 획 득하는 단계를 포함한다. 본 개시에 따른 기계학습장치는 프로세서 및 메모리를 포함하고, 프로세서는 메모리에 저장된 명령어에 기초하 여, 서로 독립적인 복수의 학습 데이터 세트에 각각 기계학습을 수행하여 획득된 복수의 서브 기계학습모델을 수신하고, 복수의 서브 기계학습모델에 기초하여 통합기계학습모델을 획득한다. 본 개시에 따른 기계학습장치는 프로세서는 메모리에 저장된 명령어에 기초하여, 복수의 학습 데이터 세트에 포 함되는 제 1 학습 데이터 세트에 기초하여 기계학습된 제 1 서브 기계학습모델을 수신하고, 복수의 학습 데이터 세트에 포함되는 제 2 학습 데이터 세트에 기초하여 기계학습된 제 2 서브 기계학습모델을 수신하고, 제 1 서브 기계학습모델 및 제 2 서브 기계학습모델을 병합하여 통합기계학습모델을 획득한다. 본 개시에 따른 기계학습장치는 프로세서는 메모리에 저장된 명령어에 기초하여, 제 1 학습 데이터 세트에 포함 된 제 1 분석 대상 데이터에 통합기계학습모델을 적용하여 획득된 제 1 특징 데이터를 수신하고, 제 2 학습 데 이터 세트에 포함된 제 2 분석 대상 데이터에 통합기계학습모델을 적용하여 획득된 제 2 특징 데이터를 수신하 고, 제 1 특징 데이터 및 제 1 학습 데이터 세트에 포함된 제 1 분석 결과 데이터의 상관 관계 그리고 제 2 특 징 데이터 및 제 2 학습 데이터 세트에 포함된 제 2 분석 결과 데이터의 상관 관계를 기계학습하여 최종기계학 습모델을 획득한다. 본 개시에 따른 기계학습장치는 프로세서는 메모리에 저장된 명령어에 기초하여, 테스트 데이터에 통합기계학습 모델을 적용하여 획득된 예측 특징 데이터를 수신하고, 예측 특징 데이터에 최종기계학습모델을 적용하여 테스 트 데이터에 대응하는 예측 결과 데이터를 획득한다. 본 개시에 따른 기계학습장치의 복수의 학습 데이터 세트는 서로 다른 환경에서 획득된 의료 영상과 관련된 데 이터이다. 본 개시에 따른 기계학습장치의 제 1 특징 데이터, 제 2 특징 데이터 및 예측 특징 데이터는 제 1 분석 대상 데 이터, 제 2 분석 대상 데이터 및 테스트 데이터를 손실 압축한 데이터이다. 본 개시에 따른 기계학습장치의 제 1 분석 대상 데이터, 제 2 분석 대상 데이터 및 테스트 데이터는 개인정보가 포함되고, 제 1 특징 데이터, 제 2 특징 데이터 및 예측 특징 데이터는 개인정보가 식별되지 않는다. 본 개시에 따른 기계학습장치의 복수의 서브 기계학습모델은 CNN(Convolution Neural Network)를 이용하여 획득 된다. 본 개시에 따른 기계학습장치의 제 1 학습 데이터 세트에 포함된 제 1 분석 결과 데이터는 제 1 학습 데이터 세 트에 포함된 제 1 분석 대상 데이터를 사용자가 분석한 결과이고, 제 2 학습 데이터 세트에 포함된 제 2 분석 결과 데이터는 제 2 학습 데이터 세트에 포함된 제 2 분석 대상 데이터를 사용자가 분석한 결과이다. 본 개시에 따른 기계학습장치의 제 1 특징 데이터는 제 1 분석 대상 데이터를 제 1 서브 기계학습모델에 적용하 여 획득되는 제 1 복수의 특징 레이어들 중 적어도 하나의 특징 레이어 및 제 1 분석 대상 데이터를 제 2 서브 기계학습모델에 적용하여 획득되는 제 2 복수의 특징 레이어들 중 적어도 하나의 특징 레이어를 결합한 데이터 이고, 제 2 특징 데이터는 제 2 분석 대상 데이터를 제 1 서브 기계학습모델에 적용하여 획득되는 제 3 복수의 특징 레이어들 중 적어도 하나의 특징 레이어 및 제 2 분석 대상 데이터를 제 2 서브 기계학습모델에 적용하여 획득되는 제 4 복수의 특징 레이어들 중 적어도 하나의 특징 레이어를 결합한 데이터이다. 본 개시에 따른 기계학습장치의 제 1 복수의 특징 레이어들, 제 2 복수의 특징 레이어들, 제 3 복수의 특징 레 이어들 및 제 4 복수의 특징 레이어들에서 동일 위치의 레이어를 선택하여, 제 1 특징 데이터 및 제 2 특징 데이터가 획득된다. 본 개시에 따른 기계학습장치는 프로세서 및 메모리를 포함하고, 프로세서는 메모리에 저장된 명령어에 기초하 여, 통합기계학습모델을 획득하고, 통합기계학습모델을 서로 독립적인 복수의 학습 데이터 세트에 포함된 복수 의 분석 대상 데이터에 적용하여 획득된 복수의 특징 데이터를 수신하고, 복수의 특징 데이터와 복수의 학습 데 이터 세트에 포함된 복수의 분석 결과 데이터 사이의 관계를 기계학습하여 최종기계학습모델을 획득한다. 본 개시에 따른 기계학습장치의 프로세서는 메모리에 저장된 명령어에 기초하여, 테스트 데이터를 통합기계학습 모델에 적용하여 획득된 예측 특징 데이터를 수신하고, 예측 특징 데이터를 최종기계학습모델에 적용하여 테스 트 데이터에 관련된 예측 결과 데이터를 획득한다. 본 개시에 따른 기계학습장치의 프로세서는 메모리에 저장된 명령어에 기초하여, 복수의 학습 데이터 세트에 포 함되고, 제 1 분석 대상 데이터 및 제 1 분석 결과 데이터를 포함하는 제 1 학습 데이터 세트를 기계학습한 제 1 서브 기계학습모델을 수신하고, 복수의 학습 데이터 세트에 포함되고, 제 1 학습 데이터 세트와 독립적이고, 제 2 분석 대상 데이터 및 제 2 분석 결과 데이터를 포함하는 제 2 데이터 세트를 기계학습한 제 2 서브 기계학 습모델을 수신하고, 제 1 서브 기계학습모델 및 제 2 서브 기계학습모델을 병합하여 통합기계학습모델을 획득한 다. 또한, 상술한 바와 같은 기계학습장치의 동작 방법을 구현하기 위한 프로그램은 컴퓨터로 판독 가능한 기록 매 체에 기록될 수 있다."}
{"patent_id": "10-2021-0007191", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "개시된 실시예의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 후술되어 있는 실시예 들을 참조하면 명확해질 것이다. 그러나 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 개시가 완전하도록 하고, 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것일 뿐이다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 개시된 실시예에 대해 구체적으로 설명하기로 한다. 본 명세서에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들 을 선택하였으나, 이는 관련 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서의 단수의 표현은 문맥상 명백하게 단수인 것으로 특정하지 않는 한, 복수의 표현을 포함한다. 또 한 복수의 표현은 문맥상 명백하게 복수인 것으로 특정하지 않는 한, 단수의 표현을 포함한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에서 사용되는 \"부\"라는 용어는 소프트웨어 또는 하드웨어 구성요소를 의미하며, \"부\"는 어떤 역할 들을 수행한다. 그렇지만 \"부\"는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. \"부\"는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 \"부\"는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태 스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레 이들 및 변수들을 포함한다. 구성요소들과 \"부\"들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 \"부\"들 로 결합되거나 추가적인 구성요소들과 \"부\"들로 더 분리될 수 있다. 본 개시의 일 실시예에 따르면 \"부\"는 프로세서 및 메모리로 구현될 수 있다. 용어 \"프로세서\" 는 범용 프로세 서, 중앙 처리 장치 (CPU), 마이크로프로세서, 디지털 신호 프로세서 (DSP), 제어기, 마이크로제어기, 상태 머 신 등을 포함하도록 넓게 해석되어야 한다. 몇몇 환경에서는, \"프로세서\" 는 주문형 반도체 (ASIC), 프로그램가 능 로직 디바이스 (PLD), 필드 프로그램가능 게이트 어레이 (FPGA) 등을 지칭할 수도 있다. 용어 \"프로세서\" 는, 예를 들어, DSP 와 마이크로프로세서의 조합, 복수의 마이크로프로세서들의 조합, DSP 코어와 결합한 하나 이상의 마이크로프로세서들의 조합, 또는 임의의 다른 그러한 구성들의 조합과 같은 처리 디바이스들의 조합을 지칭할 수도 있다. 용어 \"메모리\" 는 전자 정보를 저장 가능한 임의의 전자 컴포넌트를 포함하도록 넓게 해석되어야 한다. 용어 메 모리는 임의 액세스 메모리 (RAM), 판독-전용 메모리 (ROM), 비-휘발성 임의 액세스 메모리 (NVRAM), 프로그램 가능 판독-전용 메모리 (PROM), 소거-프로그램가능 판독 전용 메모리 (EPROM), 전기적으로 소거가능 PROM (EEPROM), 플래쉬 메모리, 자기 또는 광학 데이터 저장장치, 레지스터들 등과 같은 프로세서-판독가능 매체의 다양한 유형들을 지칭할 수도 있다. 프로세서가 메모리로부터 정보를 판독하고/하거나 메모리에 정보를 기록할 수 있다면 메모리는 프로세서와 전자 통신 상태에 있다고 불린다. 프로세서에 집적된 메모리는 프로세서와 전자 통신 상태에 있다. 아래에서는 첨부한 도면을 참고하여 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략한다. 도 1은 본 개시의 일 실시예에 따른 기계학습장치의 블록도이다. 도 1을 참조하면, 일 실시예에 따른 기계학습장치는 데이터 학습부 또는 데이터 인식부 중 적어 도 하나를 포함할 수 있다. 상술한 바와 같은 기계학습장치는 프로세서 및 메모리를 포함할 수 있다. 데이터 학습부는 데이터 세트를 이용하여 타겟 태스크(target task)를 수행하기 위한 기계학습모델을 학습 할 수 있다. 데이터 학습부는 데이터 세트 및 타겟 태스크와 관련된 레이블 정보를 수신할 수 있다. 데이 터 학습부는 데이터 세트와 레이블 정보의 관계에 대해 기계학습을 수행하여 기계학습모델을 획득할 수 있 다. 데이터 학습부가 획득한 기계학습모델은 데이터 세트를 이용하여 레이블 정보를 생성하기 위한 모델일 수 있다. 데이터 인식부는 데이터 학습부의 기계학습모델을 수신하여 저장하고 있을 수 있다. 데이터 인식부 는 입력 데이터에 기계학습모델을 적용하여 레이블 정보를 출력할 수 있다. 또한, 데이터 인식부는 입력 데이터, 레이블 정보 및 기계학습모델에 의해 출력된 결과를 기계학습모델을 갱신하는데 이용할 수 있다. 데이터 학습부 및 데이터 인식부 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전 자 장치에 탑재될 수 있다. 예를 들어, 데이터 학습부 및 데이터 인식부 중 적어도 하나는 인공 지능 (AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서 (예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 이미 설명한각종 전자 장치에 탑재될 수도 있다. 또한 데이터 학습부 및 데이터 인식부는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 학습부 및 데이터 인식부 중 하나는 전자 장치에 포함되고, 나머지 하나는 서버에 포함될 수 있다. 또한, 데이터 학습부 및 데이터 인식부는 유선 또는 무선으로 통하여, 데이터 학습부가 구축한 기계학습모델 정보를 데이터 인식부로 제공할 수도 있고, 데이터 인식부로 입력된 데이터가 추가 학습 데이터로써 데이터 학습부로 제공될 수도 있다. 한편, 데이터 학습부 및 데이터 인식부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 학습부 및 데이터 인식부 중 적어도 하나가 소프트웨어 모듈(또는, 인스트럭션(instruction)을 포함 하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 메모리 또는 컴퓨터로 읽을 수 있는 판독 가능한 비 일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어 도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 본 개시의 일 실시예에 따른 데이터 학습부는 데이터 획득부, 전처리부, 학습 데이터 선택부 , 모델 학습부 및 모델 평가부를 포함할 수 있다. 데이터 획득부는 기계학습에 필요한 데이터를 획득할 수 있다. 학습을 위해서는 많은 데이터가 필요하므로, 데이터 획득부는 복수의 데이터를 포함하는 데이터 세트를 수신할 수 있다. 복수의 데이터 각각에 대하여 레이블 정보가 할당될 수 있다. 레이블 정보는 복수의 데이터의 각각을 설명하는 정보일 수 있다. 레이블 정보는 타겟 태스크(target task)가 도출하고자 하는 정보일 수 있다. 레이블 정보는 사용자 입력으로부터 획득되거나, 메모리로부터 획득되거나, 기계학습모델의 결과로부터 획득될 수 있다. 예를 들어 타겟 태스크가 영상으로부터 특정 물체의 존재 여부를 결정하는 것이라면, 복수의 데이터는 복수의 영상 데이터가 될 것이며 레이블 정보는 복수의 영상 각각에 특정 물체가 있는지 여부가 될 것이다. 전처리부는 수신된 데이터가 기계학습에 이용될 수 있도록, 획득된 데이터를 전처리할 수 있다. 전처리부 는 후술할 모델 학습부가 이용할 수 있도록, 획득된 데이터 세트를 미리 설정된 포맷으로 가공할 수 있다. 학습 데이터 선택부는 전처리된 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 선택된 데이터는 모델 학습부에 제공될 수 있다. 학습 데이터 선택부는 기 설정된 기준에 따라, 전처리된 데이터 중에 서 학습에 필요한 데이터를 선택할 수 있다. 또한, 학습 데이터 선택부는 후술할 모델 학습부에 의한 학습에 의해 기 설정된 기준에 따라 데이터를 선택할 수도 있다. 모델 학습부는 데이터 세트에 기초하여 어떤 레이블 정보를 출력할 지에 관한 기준을 학습할 수 있다. 또 한, 모델 학습부는 데이터 세트 및 데이터 세트에 대한 레이블 정보를 학습 데이터로써 이용하여 기계학습 을 수행할 수 있다. 또한 모델 학습부는 기존에 획득된 기계학습모델을 추가적으로 이용하여 기계학습을 수행할 수 있다. 이 경우, 기존에 획득된 기계학습모델은 미리 구축된 모델일 수 있다. 예를 들어, 기계학습모 델은 기본 학습 데이터를 입력 받아 미리 구축된 모델일 수 있다. 기계학습모델은, 학습모델의 적용 분야, 학습의 목적 또는 장치의 컴퓨터 성능 등을 고려하여 구축될 수 있다. 기계학습모델은, 예를 들어, 신경망(Neural Network)을 기반으로 하는 모델일 수 있다. 예컨대, Deep Neural Network (DNN), Recurrent Neural Network (RNN), Long Short-Term Memory models (LSTM), BRDNN (Bidirectional Recurrent Deep Neural Network), Convolutional Neural Networks (CNN)과 같은 모델이 기계 학습모델로써 사용될 수 있으나, 이에 한정되지 않는다. 다양한 실시예에 따르면, 모델 학습부는 미리 구축된 기계학습모델이 복수 개가 존재하는 경우, 입력된 학 습 데이터와 기본 학습 데이터의 관련성이 큰 기계학습모델을 학습할 기계학습모델로 결정할 수 있다. 이 경우, 기본 학습 데이터는 데이터의 타입 별로 기 분류되어 있을 수 있으며, 기계학습모델은 데이터의 타입 별로 미리 구축되어 있을 수 있다. 예를 들어, 기본 학습 데이터는 학습 데이터가 생성된 장소, 학습 데이터가 생성된 시 간, 학습 데이터의 크기, 학습 데이터의 생성자, 학습 데이터 내의 오브젝트의 종류 등과 같은 다양한 기준으로 기 분류되어 있을 수 있다. 또한, 모델 학습부는, 예를 들어, 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient descent)을 포함하는 학습 알고리즘 등을 이용하여 기계학습모델을 학습시킬 수 있다. 또한, 모델 학습부는, 예를 들어, 학습 데이터를 입력 값으로 하는 지도 학습(supervised learning)을 통 하여, 기계학습모델을 학습할 수 있다. 또한, 모델 학습부는, 예를 들어, 별다른 지도없이 타겟 태스크 (target task)을 위해 필요한 데이터의 종류를 스스로 학습함으로써, 타겟 태스크를 위한 기준을 발견하는 비지 도 학습(unsupervised learning)을 통하여, 기계학습모델을 획득할 수 있다. 또한, 모델 학습부는, 예를 들어, 학습에 따른 타겟 태스크의 결과가 올바른 지에 대한 피드백을 이용하는 강화 학습(reinforcement learning)을 통하여, 기계학습모델을 학습할 수 있다. 또한, 기계학습모델이 학습되면, 모델 학습부는 학습된 기계학습모델을 저장할 수 있다. 이 경우, 모델 학 습부는 학습된 기계학습모델을 데이터 인식부를 포함하는 전자 장치의 메모리에 저장할 수 있다. 또 는, 모델 학습부는 학습된 기계학습모델을 전자 장치와 유선 또는 무선 네트워크로 연결되는 서버의 메모 리에 저장할 수도 있다. 학습된 기계학습모델이 저장되는 메모리는, 예를 들면, 전자 장치의 적어도 하나의 다른 구성요소에 관계된 명 령 또는 데이터를 함께 저장할 수도 있다. 또한, 메모리는 소프트웨어 및/또는 프로그램을 저장할 수도 있다. 프로그램은, 예를 들면, 커널, 미들웨어, 어플리케이션 프로그래밍 인터페이스(API) 및/또는 어플리케이션 프로 그램(또는 \"어플리케이션\") 등을 포함할 수 있다. 모델 평가부는 기계학습모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 결과가 소정 기준을 만족하지 못하는 경우, 모델 학습부로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가 데이터는 기계 학습모델을 평가하기 위한 기 설정된 데이터일 수 있다. 예를 들어, 모델 평가부는 평가 데이터에 대한 학습된 기계학습모델의 결과 중에서, 인식 결과가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정된 임계치를 초과하는 경우 소정 기준을 만족하지 못한 것으로 평가할 수 있다. 예컨대, 소정 기준이 비율 2%로 정의되는 경우, 학습된 기계학습모델이 총 1000개의 평가 데이 터 중의 20개를 초과하는 평가 데이터에 대하여 잘못된 인식 결과를 출력하는 경우, 모델 평가부는 학습된 기계학습모델이 적합하지 않은 것으로 평가할 수 있다. 한편, 학습된 기계학습모델이 복수 개가 존재하는 경우, 모델 평가부는 각각의 학습된 기계학습모델에 대 하여 소정 기준을 만족하는지를 평가하고, 소정 기준을 만족하는 모델을 최종 기계학습모델로써 결정할 수 있다. 이 경우, 소정 기준을 만족하는 모델이 복수 개인 경우, 모델 평가부는 평가 점수가 높은 순으로 미 리 설정된 어느 하나 또는 소정 개수의 모델을 최종 기계학습모델로써 결정할 수 있다. 한편, 데이터 학습부 내의 데이터 획득부, 전처리부, 학습 데이터 선택부, 모델 학습부 및 모델 평가부 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 획득부, 전처리부, 학습 데이터 선택부, 모델 학습부 및 모델 평가부 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작 될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 또한, 데이터 획득부, 전처리부, 학습 데이터 선택부, 모델 학습부 및 모델 평가부는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이 터 획득부, 전처리부, 학습 데이터 선택부, 모델 학습부 및 모델 평가부 중 일부는 전자 장치에 포함되고, 나머지 일부는 서버에 포함될 수 있다. 또한, 데이터 획득부, 전처리부, 학습 데이터 선택부, 모델 학습부 및 모델 평가부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부, 전처리부, 학습 데이터 선택부 , 모델 학습부 및 모델 평가부 중 적어도 하나가 소프트웨어 모듈(또는, 인스트럭션 (instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능 한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공 될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 본 개시의 일 실시예에 따른 데이터 인식부는 데이터 획득부, 전처리부, 인식 데이터 선택부 , 인식 결과 제공부 및 모델 갱신부를 포함할 수 있다. 데이터 획득부는 입력 데이터를 수신할 수 있다. 전처리부는 획득된 입력 데이터가 인식 데이터 선택 부 또는 인식 결과 제공부에서 이용될 수 있도록, 획득된 입력 데이터를 전처리할 수 있다. 인식 데이터 선택부는 전처리된 데이터 중에서 필요한 데이터를 선택할 수 있다. 선택된 데이터는 인식 결 과 제공부에게 제공될 수 있다. 인식 데이터 선택부는 기 설정된 기준에 따라, 전처리된 데이터 중에 서 일부 또는 전부를 선택할 수 있다. 또한, 인식 데이터 선택부는 모델 학습부에 의한 학습에 의해 기 설정된 기준에 따라 데이터를 선택할 수도 있다. 인식 결과 제공부는 선택된 데이터를 기계학습모델에 적용하여 결과 데이터를 획득할 수 있다. 기계학습모 델은 모델 학습부에 의하여 생성된 기계학습모델일 수 있다. 인식 결과 제공부는 결과 데이터를 출력 할 수 있다. 모델 갱신부는 인식 결과 제공부에 의해 제공되는 인식 결과에 대한 평가에 기초하여, 기계학습모델 이 갱신되도록 할 수 있다. 예를 들어, 모델 갱신부는 인식 결과 제공부에 의해 제공되는 인식 결과 를 모델 학습부에게 제공함으로써, 모델 학습부가 기계학습모델을 갱신하도록 할 수 있다. 한편, 데이터 인식부 내의 데이터 획득부, 전처리부, 인식 데이터 선택부, 인식 결과 제공 부 및 모델 갱신부 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재 될 수 있다. 예를 들어, 데이터 획득부, 전처리부, 인식 데이터 선택부, 인식 결과 제공부 및 모델 갱신부 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형 태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프 로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 또한, 데이터 획득부, 전처리부, 인식 데이터 선택부, 인식 결과 제공부 및 모델 갱신부 는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들 어, 데이터 획득부, 전처리부, 인식 데이터 선택부, 인식 결과 제공부 및 모델 갱신부 중 일부는 전자 장치에 포함되고, 나머지 일부는 서버에 포함될 수 있다. 또한, 데이터 획득부, 전처리부, 인식 데이터 선택부, 인식 결과 제공부 및 모델 갱신부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부, 전처리부, 인식 데이터 선택부, 인식 결과 제공부 및 모델 갱신부 중 적어도 하나가 소프트웨어 모듈(또는, 인스트럭션 (instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능 한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공 될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 아래에서는 데이터 학습부가 데이터 세트들을 순차적으로 기계학습하는 방법 및 장치에 대하여 보다 자세 히 설명한다. 도 2는 본 개시의 일 실시예에 따른 기계학습장치를 나타낸 도면이다. 기계학습장치는 프로세서 및 메모리를 포함할 수 있다. 프로세서는 메모리에 저장된 명령어들을 수행할 수 있다. 상술한 바와 같이 기계학습장치는 데이터 학습부 또는 데이터 인식부 중 적어도 하나를 포함할 수 있다. 데이터 학습부 또는 데이터 인식부 중 적어도 하나는 프로세서 및 메모리에 의하 여 구현될 수 있다. 도 3은 본 개시의 일 실시예에 따른 기계학습장치의 동작을 나타내는 흐름도이다. 기계학습장치는 서로 독립적인 복수의 학습 데이터 세트에 각각 기계학습을 수행하여 획득된 복수의 서브 기계학습모델을 수신하는 단계를 수행할 수 있다. 학습 데이터 세트는 분석 대상 데이터 및 분석 결과 데 이터를 포함할 수 있다. 분석 대상 데이터는 환자에 대한 의료 영상 또는 환자에 대한 다양한 측정 데이터 중 적어도 하나를 포함할 수 있다. 분석 대상 데이터는 개인 정보들이 포함되어 있으므로 민감한 데이터일 수 있다. 따라서 자유롭게 공유되지 못할 수 있다.분석 결과 데이터는 분석 대상 데이터에 대한 의료인의 진단 결과를 나타낼 수 있다. 예를 들어, 제 1 분석 결 과 데이터는 제 1 분석 대상 데이터를 사용자가 분석한 결과이고, 제 2 분석 결과 데이터는 제 2 분석 대상 데 이터를 사용자가 분석한 결과일 수 있다. 복수의 서브 기계학습모델은 Deep Neural Network (DNN), Recurrent Neural Network (RNN), Long Short-Term Memory models (LSTM), BRDNN (Bidirectional Recurrent Deep Neural Network), Convolutional Neural Networks 중 적어도 하나를 이용하여 획득될 수 있다. 복수의 서브 기계학습모델은 모두 동일한 알고리즘을 이 용하여 획득될 수 있다. 복수의 서브 기계학습모델 각각은 서로 다른 데이터 센터에서 수행된 기계학습모델일 수 있다. 복수의 서브 기 계학습모델은 학습 데이터 세트에 포함된 분석 대상 데이터 및 레이블에 해당하는 분석 결과 데이터를 이용하여 생성될 수 있다. 복수의 서브 기계학습모델 각각은 적어도 하나의 가중치를 포함할 수 있다. 적어도 하나의 가 중치는 분석 대상 데이터에 적용되어 예측 레이블을 생성하기 위해 사용될 수 있다. 복수의 서브 기계학습모델 에 포함된 적어도 하나의 가중치는 순전파 및 역전파에 포함된 연산을 통하여 갱신되고, 테스트 데이터로부터 예측하고자 하는 레이블을 추론하기 위한 최적의 적어도 하나의 가중치가 획득될 수 있다. 복수의 서브 기계학 습모델에 포함된 적어도 하나의 가중치들로부터, 복수의 학습 데이터 세트에 포함된 민감 정보, 예를 들면 개인 정보가 역추적되지 않을 수 있다. 따라서 데이터 센서 외부에 있는 기계학습장치는 복수의 서브 기계학습 모델을 복수의 데이터 센터로부터 수신할 수 있다. 한편, 민감 정보는 개인 정보를 포함할 수 있고, 이하 설명 에서는 민감 정보와 개인 정보가 혼용하여 설명될 수 있다. 기계학습장치는 복수의 서브 기계학습모델에 기초하여 통합기계학습모델을 획득하는 단계를 수행할 수 있다. 예를 들어, 기계학습장치는 복수의 서브 기계학습모델을 병합하여 통합기계학습모델을 획득할 수 있다. 이하에서는 단계 및 단계를 보다 자세히 설명하기 위하여 도 4 및 도 5를 참조한다. 도 4는 본 개시의 일 실시예에 따라 통합기계학습모델을 획득하는 과정을 나타낸 도면이다. 제 1 데이터 센터 내지 제 k 데이터 센터는 서로 다른 의료 기관일 수 있다. 도 4에서 제 1 서버 내지 제 k 서버는 제 1 데이터 센터 내지 제 k 데이터 센터에 포함된 서버를 의미할 수 있다. 제 1 서버 내지 제 k 서버는 서로 다른 위치에 있을 수 있다. 예를 들어, 제 1 서버 내지 제 k 서버는 물리적으 로, 서로 다른 위치에 있을 수 있고, 기능적 또는 구조적으로 서로 다른 위치에 있을 수 있다. 또한 제 1 서버 내지 제 k 서버 간에 데이터의 직접적인 공유는 이루어지지 않을 수 있다. 제 1 서버 내지 제 k 서버는 각각 제 1 데이터 센터 내지 제 k 데이터 센터에서 수집된 데이터를 보관하거나 처리할 수 있다. 제 1 서버 내지 제 k 서버는 서로 데이터를 공유하지 않을 수 있다. 또는 제 1 서버 내지 제 k 서버는 일부의 데이터만 공유할 수 있다. 예를 들어 제 1 서버 내지 제 k 서버는 개인 정보가 포함된 민감한 데이터를 공유하지 않을 수 있다. 하지만 제 1 서버 내지 제 k 서버는 민감하지 않은 데이터를 공유할 수 있다. 복수의 학습 데이터 세트는 서로 개별적으로 획득될 수 있다. 즉, 복수의 학습 데이터 세트에 포함된 제 1 학습 데이터 세트는 제 1 서버에서 획득된 데이터이고, 복수의 학습 데이터 세트에 포함된 제 2 학습 데이 터 세트는 제 2 서버에서 획득된 데이터이고, 복수의 학습 데이터 세트에 포함된 제 k 학습 데이터 세트는 제 k 서버에서 획득된 데이터일 수 있다. 복수의 학습 데이터 세트는 민감한 정보가 포함되어 공유되기 어려울 수 있다. 제 1 학습 데이터 세트는 제 1 서버에서만 처리될 수 있다. 제 2 학습 데이터 세트는 제 2 서버에서만 처리될 수 있다. 제 k 학습 데이터 세트는 제 k 서버에서만 처리될 수 있다. 따라서 서버들은 복수의 학습 데이터 세 트를 공유하기 위하여 복수의 학습 데이터 세트를 변형시키기 위한 처리를 할 수 있다. 복수의 학습 데이터 세트는 서로 독립적일 수 있다. 제 1 서버에서 획득된 제 1 학습 데이터 세트는 제 2 서버에서 획득된 제 2 학습 데이터 세트에 영향을 미치지 않을 수 있다. 반대로 제 2 서버(43 0)에서 획득된 제 2 학습 데이터 세트는 제 1 서버에서 획득된 제 1 학습 데이터 세트에 영향을 미치지 않을 수 있다. 제 1 학습 데이터 세트에 포함된 제 1 분석 대상 데이터 및 제 1 분석 결과 데이터 는 제 2 학습 데이터 세트에 포함된 제 2 분석 대상 데이터 및 제 2 분석 결과 데이터와 서로 독립적일 수 있다.이는 복수의 서버들이 포함된 데이터 센터는 독립적인 방식으로 데이터를 획득하기 때문이다. 즉, 복수의 학습 데이터 세트는 서로 다른 환경에서 획득된 의료 영상과 관련된 데이터일 수 있다. 예를 들어, 제 1 서버 내지 제 k 서버는 각각 제 1 데이터 센서 내지 제 k 데이터 센터에 위치할 수 있다. 복수 의 데이터 센터들은 서로 다른 장소에 위치할 수 있다. 복수의 데이터 센터의 각각의 데이터 획득 장비들은 서 로 다를 수도 있고 동일할 수도 있다. 복수의 데이터 센터들은 서로 독립적인 시간에 데이터를 획득할 수 있다. 데이터 센터들은 서로 독립적인 대상으로부터 데이터를 획득할 수 있다. 데이터 센터들은 서로 독립적인 의료인 으로부터 분석 결과를 획득할 수 있다. 또한 복수의 데이터 센터들은 같은 장비를 이용하더라도 독립적인 데이터 획득 설정값 또는 데이터 출력 설정값 을 사용하여 데이터를 생성할 수 있다. 데이터가 의료 영상인 경우, 의료 영상 촬영 장치는 다양한 설정값으로 의료 영상을 획득할 수 있다. 또한 의료 영상 표시 장치는 다양한 설정값으로 의료 영상을 출력할 수 있다. 데 이터 획득 설정값과 데이터 출력 설정값에 따라 데이터가 달라질 수 있다. 하지만, 복수의 학습 데이터 세트(421, 431, 441)는 서로 호환될 수 있다. 이미 설명한 바와 같이 학습 데이터 세트는 분석 대상 데이터 및 분석 결과 데이터를 포함할 수 있다. 복수의 학습 데이터 세트(421, 431, 441)는 동일한 종류의 분석 대상 데이터를 포함할 수 있다. 예를 들어, 분석 대상 데이터는 CT, MRI, X-RAY, Mammography 또는 초음파 영상일 수 있다. 또한, 복수의 학습 데이터 세트(421, 431, 441)는 동일한 종류의 분 석 결과 데이터를 포함할 수 있다. 예를 들어, 분석 결과 데이터는 분석 대상 데이터에 기초하여 의료인이 진단 한 병변에 관련된 정보를 포함할 수 있다. 복수의 학습 데이터 세트들 간에 호환성이 없는 경우, 복수의 서버들(420, 430, 440)은 복수의 학습 데이터 세 트 간에 호환성이 있도록 표준화하는 전처리 과정을 수행할 수 있다. 제 k 서버는 제 k 학습 데이터 세트를 기계학습하여 제 k 서브 기계학습모델을 생성할 수 있다. 예를 들어, 제 1 서버는 제 1 학습 데이터 세트를 기계학습하여 제 1 서브 기계학습모델을 생성 할 수 있다. 제 2 서버는 제 2 학습 데이터 세트를 기계학습하여 제 2 서브 기계학습모델을 생 성할 수 있다. 이를 보다 자세히 설명하기 위하여 도 5를 참조한다. 도 5는 본 개시의 일 실시예에 따라 서브 기계학습모델을 생성하는 과정을 설명하기 위한 도면이다. 이미 설명한 바와 같이 제 k 학습 데이터 세트는 제 k 분석 대상 데이터 및 제 k 분석 결과 데이터 를 포함할 수 있다. 예를 들어, 제 k 분석 대상 데이터는 환자에 대한 의료 영상 및 환자의 상태에 관련된 각종 측정 데이터 중 적어도 하나를 포함할 수 있다. 제 k 분석 대상 데이터는 민감한 정보가 포 함될 수 있다. 제 k 분석 결과 데이터는 제 k 분석 대상 데이터에 기초하여 전문 의료인이 진단한 결과일 수 있다. 제 k 분석 결과 데이터는 실제(ground-truth) 데이터 또는 실제 레이블(ground-truth label) 일 수 있다. 제 k 분석 결과 데이터는 제 k 분석 대상 데이터에 대응할 수 있다. 제 k 서버는 데이터 학습부를 포함할 수 있다. 제 k 서버는 제 k 분석 대상 데이터 및 제 k 분석 결과 데이터의 관계를 기계학습하여 제 k 서브 기계학습모델을 생성할 수 있다. 제 k 서버 는 심층신경망을 기반으로 기계학습을 수행할 수 있다. 제 k 서버는 제 k 분석 대상 데이터 및 제 k 분석 결과 데이터를 이용하여 순전파(forward propagation) 및 역전파(back propagation)을 수행하 면서 제 k 서브 기계학습모델의 정확도를 높일 수 있다. 이상에서는 제 k 서버를 기준으로 제 k 서브 기계학습모델을 생성하는 과정을 설명하였다. 제 1 서버 가 제 1 서브 기계학습모델을 생성하는 과정과 제 2 서버가 제 2 서브 기계학습모델을 생 성하는 과정은 제 k 서버가 제 k 서브 기계학습모델을 생성하는 과정과 유사하므로 중복되는 설명은 생략한다. 제 k 서브 기계학습모델은 분석 대상 데이터와 분석 결과 데이터의 관계를 학습한 기계학습모델일 수 있다. 따라서, 기계학습이 완료된 제 k 서브 기계학습모델은 새로운 분석 대상 데이터를 입력받고, 예측 결과 데이터를 출력할 수 있다. 구체적으로, 제 k 서버는 데이터 인식부를 포함할 수 있다. 제 k 서 버의 데이터 인식부는 제 k 학습데이터 세트에 포함되지 않은, 새로운 분석 대상 데이터를 획득하여 제 k 서브 기계학습모델에 적용할 수 있다. 제 k 서브 기계학습모델은 새로운 분석 대상 데이터에 대 응하는 예측 결과 데이터를 출력할 수 있다. 여기서 분석 대상 데이터를 서브 기계학습모델에 적용한다는 것은분석 대상 데이터를 입력으로 하여 서브 기계학습모델의 순전파가 수행됨을 의미한다. 예측 결과 데이터는 제 k 서브 기계학습모델이 예측한 결과로서 실제(ground-truth) 데이터와 유사할 수 있다. 예측 결과 데이터는 예측 레이블이라고도 하며, 기계학습모델에 의하여 예측된 정보이다. 실제 레이블 또는 실제 데이터는 기계학습 모델이 예측한 정보가 아닌, 사용자가 실제로 분석하여 도출한 정보라는 점에서 차이가 있다. 제 k 서브 기계학습모델은 제 k 학습데이터 세트에 최적화된 기계학습모델일 수 있다. 제 k 서버는 제 k 서브 기계학습모델을 이용하여 제 k 서버가 획득한 분석 대상 데이터를 분석하여 높은 정확도의 예측 결과 데이터를 출력할 수 있다. 하지만 제 k 서브 기계학습모델은 제 k 서버가 아닌 서버가 획득한 분석 대상 데이터에 대하여 상대적으로 낮은 정확도의 예측 결과 데이터를 출력할 수 있다. 마찬가지로, 제 1 서브 기계학습모델은 제 1 학습데이터 세트에 특화된 기계학습모델일 수 있다. 따라서, 제 1 서브 기계학 습모델은 제 2 서버 또는 제 k 서버가 획득한 분석 대상 데이터에 대하여 상대적으로 낮은 정확 도의 예측 결과 데이터를 출력할 수 있다. 다시 도 4를 참조하면, 제 1 서버 내지 제 k 서버는 생성된 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델을 기계학습장치에 송신할 수 있다. 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델은 제 1 학습 데이터 세트 내지 제 k 학습 데이터 세트에 포함되어 있는 민감 정보, 예를 들면 개인 정보를 포함하지 않으므로 자유롭게 공유될 수 있다. 송신은 유무선 통신 장치를 이용하 여 이루어질 수 있다. 또한 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델은 기록매체에 저장 되어 기계학습장치로 전달될 수 있다. 기계학습장치는 복수의 서브 기계학습모델을 수신하는 단계를 수행할 수 있다. 복수의 서브 기계학습 모델은 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델을 포함할 수 있다. 구체적으로, 기계학습장치는, 복수의 서브 기계학습모델을 수신하기 위하여, 복수의 학습 데이터 세트에 포함되는 제 1 학습 데이터 세트에 기초하여 기계학습된 제 1 서브 기계학습모델을 수신하는 단계를 수행할 수 있다. 또한 기계학습장치는 복수의 학습 데이터 세트에 포함되는 제 2 학습 데이터 세트에 기초하여 기계학습된 제 2 서브 기계학습모델을 수신하는 단계를 수행할 수 있다. 제 1 서브 기계학습모델 및 제 2 서브 기계학습모델은 각각 제 1 서버 및 제 2 서버에서 독립적으로 생성될 수 있 다. 또한 기계학습장치는 복수의 서브 기계학습모델에 기초하여 통합기계학습모델을 획득하는 단계 를 수행할 수 있다. 기계학습장치는 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델을 병 합하여 통합기계학습모델을 생성할 수 있다. 즉, 통합기계학습모델은 k개의 기계학습모델의 그룹일 수 있다. 예를 들어, 기계학습장치가 제 1 서브 기계학습모델 및 제 2 서브 기계학습모델을 수 신하였다면, 기계학습장치는 제 1 서브 기계학습모델 및 제 2 서브 기계학습모델을 병합하여 통 합기계학습모델을 획득하는 단계를 수행할 수 있다. 이 경우 모든 데이터 센터의 학습 데이터 세트를 이용 하여 기계학습장치가 통합기계학습모델을 생성하므로, 통합기계학습모델에 기초하여 생성되는 최종기계학습모델의 정확도도 높아지는 효과가 있다. 즉 최종기계학습모델은 새로운 분석 대상 데이터를 정확하 게 분석하여 예측 결과 데이터를 생성할 수 있다. 기계학습장치는 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델 중 하나의 서브 기계학습 모델을 통합기계학습모델로 결정할 수 있다. 예를 들어 복수의 데이터 센터들 중 하나의 데이터 센터가 가 장 포괄적인 데이터를 포함하고 있는 경우 사용자 또는 기계학습장치는 하나의 데이터 센터의 서브 기계학 습모델을 통합기계학습모델로 결정할 수 있다. 왜냐하면 하나의 데이터 센터가 복수의 데이터 센터들을 대 표할 수 있기 때문이다. 또한 통합기계학습모델은 임의의 데이터 센터의 서브 기계학습모델로 결정될 수 있다. 예를 들어, 제 1 서 버는 제 1 분석 대상 데이터 및 제 1 분석 결과 데이터를 포함하는 제 1 학습 데이터 세트를 기계학 습하여 제 1 서브 기계학습모델을 획득할 수 있다. 기계학습장치는 제 1 서브 기계학습모델을 통합기계학습모델로 결정할 수 있다. 통합기계학습모델은 특징 데이터와 같은 중간 단계의 데이터를 획득하기 위한 구성이다. 따라서 기계학습장치는 임의의 서브 기계학습모델을 이용하여 본 개시의 최종기 계학습모델을 획득할 수 있다. 기계학습장치는 도 3과 같은 과정을 거치지 않고, 위와 같이 하나의 서버에서 생성된 서브 기계학습모델을 수신할 수 있다. 이 경우, 기계학습장치는 유무선 통신으로 전송할 데이터의 양을 줄이고 서버의 처리 능력을 절약할 수 있다. 또한, 기계학습장치는 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델 중 적어도 하나를 이용하여 통합기계학습모델을 생성할 수 있다. 기계학습장치는 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델의 유사도를 결정할 수 있다. 기계학습장치는 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델 중 2개의 서브 기계학습모델을 임의로 선택하여 유사도를 측정할 수 있다. 기계학 습장치는 유사도가 미리 결정된 임계값 이상인 경우, 2 개의 서브 기계학습모델 중 하나를 제거하여 통합 기계학습모델을 생성할 수 있다. 예를 들어, 2개의 데이터 센터들이 아주 유사한 환경에 있다면 각각의 데 이터 센터들에 포함된 서버들이 도출한 서브 기계학습모델들은 서로 유사할 수 있다. 기계학습장치는 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델에서 선택된 2개의 서브 기계학습모델의 모든 조합에 대하여 위와 같은 과정을 수행하여 통합기계학습모델을 생성할 수 있다. 이렇게 기계학습장치는 중복 되는 서브 기계학습모델을 제거함으로써 프로세서의 데이터 처리량을 줄이고, 데이터의 송수신 부담을 줄일 수 있다. 또한, 기계학습장치는 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델 중 적어도 하나를 이용하지 않고 통합기계학습모델을 생성할 수 있다. 기계학습장치는 임의의 기본모델을 통합기계학습 모델으로 생성할 수 있다. 이 경우, 기계학습장치는 도 3 과 같은 과정을 수행하지 않을 수 있으므로, 프로세서의 데이터 처리량을 줄이고, 데이터의 송수신 부담을 줄일 수 있다. 도 6은 본 개시의 일 실시예에 따라 최종기계학습모델을 생성하는 방법을 나타낸 흐름도이다. 도 7은 본 개시의 일 실시예에 따른 최종기계학습모델을 생성하는 방법을 설명하기 위한 도면이다. 도 6을 참조하면, 기계학습장치는 통합기계학습모델을 획득하는 단계를 수행할 수 있다. 통합기 계학습모델을 획득하는 단계에 대해서는 위에서 이미 설명한 바 있으므로 중복되는 설명은 생략한다. 기계학습장치는 통합기계학습모델을 제 1 서버 내지 제 k 서버로 송신할 수 있다. 제 1 서 버 내지 제 k 서버는 통합기계학습모델을 이용하여 복수의 분석 대상 데이터(711, 712, 713)를 암호화할 수 있다. 암호화된 복수의 분석 대상 데이터에서 개인정보와 같은 민감정보가 식별되지 않을 수 있다. 또한 암호화된 복수의 분석 대상 데이터에서 다시 복수의 분석 대상 데이터(711, 712, 713)로 복원되는 것은 불 가능할 수 있다. 제 1 특징 데이터 내지 제 k 특징 데이터는 제 1 분석 대상 데이터 내지 제 k 분석 대상 데이터를 손실 압축한 데이터일 수 있다. 제 1 특징 데이터 내지 제 k 특징 데이터는 손실 압축되 데이터이므로, 민감 정보, 예를 들면 개인정보가 식별되지 않을 수 있다. 또한, 제 1 특징 데이터 내지 제 k 특징 데이터는 제 1 분석 대상 데이터 내지 제 k 분석 대상 데이터로 복원 가 능하지 않을 수 있다. 복수의 분석 대상 데이터(711, 712, 713)는 개인정보를 포함하므로 공유가능하지 않을 수 있다. 하지만 제 1 특징 데이터 내지 제 k 특징 데이터는 개인정보가 식별되지 않으므로 공유가능할 수 있다. 또한, 제 1 특징 데이터 내지 제 k 특징 데이터는 제 1 분석 대상 데이터 내지 제 k 분석 대상 데이터보다 데이터의 양이 적으므로 프로세서가 처리할 데이터의 양을 줄일 수 있다. 제 1 서버는 제 1 분석 대상 데이터를 통합기계학습모델에 적용하여 제 1 특징 데이터를 획득할 수 있다. 제 2 서버는 제 2 분석 대상 데이터를 통합기계학습모델에 적용하여 제 2 특징 데이터를 획득할 수 있다. 제 k 서버는 제 k 분석 대상 데이터를 통합기계학습모델에 적용 하여 제 k 특징 데이터를 획득할 수 있다. 제 1 서버 내지 제 k 서버는 제 1 특징 데이터 내지 제 k 특징 데이터를 기계학습장치로 송신할 수 있다. 복수의 분석 결과 데이터는 복수의 분석 대상 데이터(711, 712, 713)에 각각 대응될 수 있다. 하지만, 복수의 분석 대상 데이터(711, 712, 713)가 암호화되는 경우, 복수의 분석 결과 데이터가 누구에 대한 것인지 특정되지 않는다. 따라서 제 1 서버 내지 제 k 서버는 분석 결과 데이터를 별도로 암호화하지 않을 수 있다. 제 1 서버 내지 제 k 서버는 분석 결과 데이터를 기계학습장치로 송신할 수 있다. 제 1 특징 데이터 내지 제 k 특징 데이터는 예측 결과 데이터가 아닐 수 있다. 즉, 제 1 특징 데이터 내지 제 k 특징 데이터는 제 1 서버 내지 제 k 서버가 통합기계학습모델을 이용하여 도출한 복수의 분석 대상 데이터(711, 712, 713)에 대응하는 분석 결과가 아닐 수 있다. 하지만 이에 한정되는 것은 아니며, 제 1 특징 데이터 내지 제 k 특징 데이터는 제 1 서버 내지 제 k 서버가 통 합기계학습모델을 이용하여 도출한 복수의 분석 대상 데이터(711, 712, 713)에 대응하는 분석 결과일 수도 있다.제 1 특징 데이터 내지 제 k 특징 데이터를 도 8 내지 도 10과 함께 보다 자세히 설명한다. 도 8은 본 개시의 일 실시예에 따른 특징 데이터를 설명하기 위한 도면이다. 도 8은 도 7의 제 k 서버에서 이루어지는 데이터 처리 과정을 나타낸 도면이다. 도 8을 참조하면, 통합기계학습모델은 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델을 포함할 수 있다. 도 8에서 통합기계학습모델은 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델 을 포함하는 것으로 표현되어 있으나 이에 한정 해석되어서는 안된다. 상술한 바와 같이 기계학습장치 는 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델 중 적어도 하나를 이용하여 통합기계 학습모델을 생성할 수 있다. 또한 통합기계학습모델은 미리 정해진 기본 모델일 수 있다. 제 k 서버는 제 k 분석 대상 데이터를 통합기계학습모델에 적용할 수 있다. 제 k 서버는 제 k 분석 대상 데이터를 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델에 적용하여 제 1 서브 특징 데이터 내지 제 k 서브 특징 데이터를 획득할 수 있다. 제 k 서버는 제 k 분석 대상 데이터를 제 1 서브 기계학습모델에 적용하여 제 1 서브 특징 데이 터를 획득할 수 있다. 제 k 서버는 제 k 분석 대상 데이터를 제 2 서브 기계학습모델에 적 용하여 제 2 서브 특징 데이터를 획득할 수 있다. 제 k 서버는 제 k 분석 대상 데이터를 제 k 서브 기계학습모델에 적용하여 제 k 서브 특징 데이터를 획득할 수 있다. 제 k 특징 데이터는 제 1 서브 특징 데이터 내지 제 k 서브 특징 데이터를 포함할 수 있다. 제 k 분석 대상 데이터 에는 데이터는 개인정보가 포함되고, 제 k 특징 데이터는 암호화되어 있으므로 개인정보가 식별되지 않을 수 있다. 따라서 제 k 특징 데이터는 외부로 전송이 가능할 수 있다. 제 1 서버는 제 k 서버와 동일한 과정을 수행하여 제 1 분석 대상 데이터로부터 제 1 특징 데이 터를 획득할 수 있다. 제 1 서버는 제 1 분석 대상 데이터를 제 1 서브 기계학습모델에 적 용하여 제 1-1 서브 특징 데이터를 획득할 수 있다. 제 1 서버는 제 1 분석 대상 데이터를 제 2 서브 기계학습모델에 적용하여 제 1-2 서브 특징 데이터를 획득할 수 있다. 제 1 서버는 제 1 분석 대상 데이터를 제 k 서브 기계학습모델에 적용하여 제 1-k 서브 특징 데이터를 획득할 수 있다. 제 1 특징 데이터는 제 1-1 서브 특징 데이터, 제 1-2 서브 특징 데이터 및 제 1-k 서브 특징 데이터를 포함할 수 있 다. 또한 제 2 서버는 제 k 서버와 동일한 과정을 수행하여 제 2 분석 대상 데이터로부터 제 2 특징 데이터를 획득할 수 있다. 제 2 서버는 제 2 분석 대상 데이터를 제 1 서브 기계학습모델 에 적용하여 제 2-1 서브 특징 데이터를 획득할 수 있다. 제 2 서버는 제 2 분석 대상 데이터를 제 2 서브 기계학습모델에 적용하여 제 2-2 서브 특징 데이터를 획득할 수 있다. 제 2 서버는 제 2 분석 대상 데이터를 제 k 서브 기계학습모델에 적용하여 제 2-k 서브 특징 데이터를 획득할 수 있다. 제 2 특징 데이터는 제 2-1 서브 특징 데이터, 제 2-2 서브 특징 데이터 및 제 2-k 서브 특징 데이터를 포함할 수 있다. 제 1 분석 대상 데이터 및 제 2 분석 대상 데이터 개인정보가 포함될 수 있다. 또한, 제 1 특징 데이 터 및 제 2 특징 데이터는 암호화되어 있으므로 개인정보가 식별되지 않을 수 있다. 따라서 제 1 특 징 데이터 및 제 2 특징 데이터는 외부로 전송이 가능할 수 있다. 제 1 서버 내지 제 k 서버 는 제 1 특징 데이터 내지 제 k 특징 데이터를 기계학습장치로 송신할 수 있다. 위에서는 통합기계학습모델이 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델을 포함하는 것을 설명하였으나 이에 한정 해석되어서는 안된다. 통합기계학습모델은 제 1 서브 기계학습모델 내 지 제 k 서브 기계학습모델 중 적어도 하나를 이용하여 생성될 수 있다. 또한 통합기계학습모델은 미 리 정해진 기본 모델일 수 있다. 이하에서는 암호화된 특징 데이터를 생성하는 과정을 보다 자세히 설명하기 위하여 도 9 및 도 10을 참조하여 설명한다. 도 9는 본 개시의 일 실시예에 따라 특징 데이터를 생성하는 과정을 설명하기 위한 도면이다. 도 9는 도 8의 제 k 서버가 제 k 분석 대상 데이터를 제 k 서브 기계학습모델에 적용하여 제 k 서브 특징 데이터를 생성하는 과정을 나타낸 도면이다.이미 설명한 바와 같이 제 k 분석 대상 데이터를 통합기계학습모델에 적용한다는 것은 제 k 분석 대상 데 이터를 통합기계학습모델에 포함된 서브 기계학습모델에 입력하여 순전파(forward propagation)한다는 것 이다. 제 k 서버가 제 k 분석 대상 데이터를 제 k 서브 기계학습모델로 순전파하는 경우, 복수의 레이 어의 특징 데이터가 생성될 수 있다. 복수의 레이어의 특징 데이터의 각 레이어는 제 k 분석 대상 데 이터를 손실 압축하는 생성될 수 있다. 또한 복수의 레이어의 특징 데이터는 제 k 분석 대상 데이터 를 사용자가 인식할 수 없게 변형한 데이터일 수 있다. 즉 복수의 레이어의 특징 데이터는 제 k 분석 대상 데이터를 암호화한 데이터일 수 있다. 복수의 레이어의 특징 데이터에 포함된 레이어는 제 k 분 석 대상 데이터로 복원이 불가능할 수 있다. 또한 제 k 서버는 제 k 분석 대상 데이터를 제 k 서브 기계학습모델로 순전파하는 경우 최종적 으로 제 k 예측 데이터를 생성할 수 있다. 제 k 예측 데이터는 제 k 분석 대상 데이터를 분석한 예측 정보일 수 있다. 도 8의 제 k 서브 특징 데이터는 제 k 예측 데이터와 다를 수 있다. 하지만 이에 한 정되는 것은 아니며, 도 8의 제 k 서브 특징 데이터는 제 k 예측 데이터와 동일할 수 있다. 제 k 서버는 복수의 레이어의 특징 데이터 중 적어도 하나의 레이어의 특징 데이터를 선택할 수 있다. 제 k 서버는 미리 정해진 방식에 따라 복수의 레이어 중 중간 레이어 또는 최종 레이어를 제 k 서브 특징 데이터로 결정할 수 있다. 제 k 서버는 통합기계학습모델에 포함된 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델 모두에 대하여 위와 동일한 과정을 수행할 수 있다. 또한 제 k 서버는 제 k 분석 대상 데이터에 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모 델을 적용하여 생성된 복수의 레이어의 특징 데이터 중 동일 위치에서 특징 데이터를 선택하여 제 1 서브 특징 데이터 내지 제 k 서브 특징 데이터를 획득할 수 있다. 하지만 이에 한정되는 것은 아니며 제 k 서버는 제 k 분석 대상 데이터에 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델을 적용하여 생성된 복수의 레이어의 특징 데이터 중 서로 다른 방식으 로 결정된 위치에서 특징 데이터를 선택할 수 있다. 제 k 서버는 서브 기계학습모델에 기초하여 획득된 복 수의 레이어 중 선택할 레이어의 위치를 미리 결정된 방식에 기초하여 결정할 수 있다. 이상에서는 제 k 서버를 기준으로 설명하였으나, 제 1 서버 및 제 2 서버에 대해서도 동일한 과 정이 수행될 수 있으므로 중복되는 설명은 생략한다. 이하에서는 도 9를 보다 구체적으로 도시한 도 10을 참조하여 보다 자세하게 설명한다. 도 10은 본 개시의 일 실시예에 따라 특징 데이터를 생성하는 과정을 설명하기 위한 도면이다. 도 10에서 INPUT은 제 k 분석 대상 데이터를 나타낼 수 있다. 제 k 서버는 다음과 같은 과정을 통하 여 제 k 분석 대상 데이터에 제 k 서브 기계학습모델을 적용할 수 있다. 제 k 서버는 제 k 분석 대상 데이터에 제 1 컨볼루션(Conv_1)을 수행하여 24x24xn1크기의 제 1 레이 어를 획득할 수 있다. 제 k 서버는 제 1 레이어에 맥스 풀링을 수행하여 12 x 12 x n1크기의 제 2 레이어를 획득할 수 있다. 제 k 서버는 제 2 레이어에 제 2 컨볼루션(Conv_2)을 수행하 여 8 x 8 x n2 크기의 제 3 레이어를 획득할 수 있다. 제 k 서버는 제 3 레이어에 맥스 풀링 을 수행하여 4 x 4 x n2 크기의 제 4 레이어를 획득할 수 있다. 제 k 서버는 제 4 레이어에 제 1 풀리 커넥티드 신경망(fc_3)을 적용하여 n3 크기의 최종 레이어를 획득할 수 있다. 또한 제 k 서버 는 최종 레이어에 제 2 풀리 커넥티드 신경망(fc_4)을 적용하여 OUTPUT을 출력할 수 있다. OUTPUT은 제 k 서브 기계학습모델에 기초하여 예측된 INPUT에 대응하는 예측 레이블 또는 예측된 분 석 결과일 수 있다. 여기서 제 1 레이어 내지 제 4 레이어 및 최종 레이어는 제 k 분석 대상 데이터를 제 k 서브 기계학습모델로 순전파하는 경우, 생성된 복수의 레이어에 포함될 수 있다. 제 k 서버는 미리 결정된 방식에 기초하여 복수의 특징 레이어(1010, 1020, 1030, 1040, 922) 중 적어도 하나의 레이어를 선택하 여 제 k 서브 특징 데이터를 획득할 수 있다. 예를 들어 제 k 서버는 미리 결정된 위치에서 적어도 하나의 레이어를 선택하여 제 k 서브 특징 데이터를 획득할 수 있다. 여기서 위치는 복수의 특징 레이어(1010, 1020, 1030, 1040, 922)에 대한 하나의 레이어의 위치를 의미한다. 제 1 컨볼루션, 제 2 컨볼루션, 맥스 풀링, 제 1 풀리 커넥티드 신경망(fc_3) 및 제 2 풀리 커넥티드 신경망 (fc_4)은 제 k 서브 기계학습모델에 포함되는 구성요소일 수 있다. 도 10은 일 실시예로서, 제 k 기계학습 모델은 다양한 구성 요소를 더 포함할 수도 있고, 도 10에서 일부 구성요소를 삭제한 모델일 수 있다. 또한 제 k 기계학습모델의 기계학습과정에서 순전파 및 역전파를 통하여 제 1 컨볼루션, 제 2 컨볼루션, 제 1 풀리 커넥 티드 신경망(fc_3) 및 제 2 풀리 커넥티드 신경망(fc_4)에 관련된 복수의 가중치들이 업데이트되어 최적화된 제 k 기계학습모델이 획득될 수 있다. 도 9 및 도 10에서는 일반화를 위하여 제 k 서버가 제 k 분석 대상 데이터를 제 k 서브 기계학습모델 로 순전파하는 경우에 대하여 설명하였으나, 제 k 서버가 제 k 분석 대상 데이터를 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델로 순전파하는 경우에도 동일하게 복수의 레이어가 생성될 수 있다. 또한, 제 k 서버는 미리 결정된 방식에 기초하여 복수의 레이어 중 적어도 하나의 레이어를 선택 하여 제 1 서브 특징 데이터 내지 제 k 서브 특징 데이터를 획득할 수 있다. 제 k 서버는 복수 의 레이어 중 동일한 위치의 레이어를 선택하여 제 1 서브 특징 데이터 내지 제 k 서브 특징 데이터 를 획득할 수 있다. 예를 들어, 제 k 서버는 복수의 레이어 중 최종 레이어를 선택하여 제 1 서브 특 징 데이터 내지 제 k 서브 특징 데이터를 획득할 수 있다. 제 k 서버는 제 1 서브 특징 데이터 내지 제 k 서브 특징 데이터 중 적어도 하나에 기초하여 제 k 특징 데이터를 획득할 수 있다. 또한, 제 1 서버 및 제 2 서버도 제 k 서버와 동일하게 동작할 수 있다. 예를 들어, 제 1 서버 가 제 1 분석 대상 데이터를 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델로 순전 파하는 경우에도 동일하게 복수의 레이어가 생성될 수 있다. 제 1 서버는 미리 결정된 방식에 기초하여 적 어도 하나의 레이어를 선택하여 제 1-1 서브 특징 데이터 내지 제 1-k 서브 특징 데이터를 획득할 수 있다. 또 한 제 1 서버는 제 1-1 서브 특징 데이터 내지 제 1-k 서브 특징 데이터 중 적어도 하나에 기초하여 제 1 특징 데이터를 획득할 수 있다. 제 2 서버가 제 2 분석 대상 데이터를 제 1 서브 기계학습모델 내지 제 k 서브 기계학습모델 로 순전파하는 경우에도 동일하게 복수의 레이어가 생성될 수 있다. 제 2 서버는 미리 결정된 방식에 기초하여 적어도 하나의 레이어를 선택하여 제 2-1 서브 특징 데이터 내지 제 2-k 서브 특징 데이터를 획득할 수 있다. 또한 제 2 서버는 제 2-1 서브 특징 데이터 내지 제 2-k 서브 특징 데이터 중 적어도 하나에 기 초하여 제 2 특징 데이터를 획득할 수 있다. 제 1 서버 내지 제 k 서버는 생성된 제 1 특징 데 이터 내지 제 k 특징 데이터를 기계학습장치로 전송할 수 있다. 이하에서는 미리 결정된 방식에 기초하여 적어도 하나의 레이어를 선택하는 과정을 보다 자세히 설명한다. 또한 설명의 편의를 위해 제 1 서버 및 제 2 서버만 있는 경우에 대하여 설명한다. 도 7을 참조하면, 제 1 특징 데이터는 통합기계학습모델에 포함된 적어도 하나의 서브 기계학습모델 을 이용하여 획득될 수 있다. 제 1 특징 데이터는 제 1 분석 대상 데이터를 제 1 서브 기계학습모델 에 적용하여 획득되는 제 1 복수의 특징 레이어들 중 적어도 하나의 특징 레이어를 포함할 수 있다. 제 1 복수 의 특징 레이어들 중 선택된 적어도 하나의 특징 레이어는 제 1-1 서브 특징 데이터일 수 있다. 또한, 제 1 특 징 데이터는 제 1 분석 대상 데이터를 제 2 서브 기계학습모델에 적용하여 획득되는 제 2 복수의 특징 레 이어들 중 적어도 하나의 특징 레이어를 포함할 수 있다. 제 2 복수의 특징 레이어들 중 선택된 적어도 하나는 제 1-2 서브 특징 데이터일 수 있다. 제 1 특징 데이터는 제 1-1 서브 특징 데이터 및 제 1-2 서브 특징 데이터를 결합한 데이터일 수 있다. 예를 들어, 제 1-1 서브 특징 데이터가 a 개의 특징 레이어를 포함하고, 제 1-2 서브 특징 데이터가 b 개의 특징 레이어를 포함하는 경우, 제 1 특징 데이터는 a+b개의 특징 레이어를 포함할 수 있다. 또한, 제 1 특징 데이터는 제 1-1 서브 특징 데이터 및 제 1-2 서브 특징 데이터에 오퍼레이션을 취한 데 이터일 수 있다. 오퍼레이션은 AND, OR 또는 XOR와 같은 비트 연산자 또는 덧셈, 뺄셈, 곱셈 또는 나눗셈과 같 은 사칙연산을 포함할 수 있다. 서버는 제 1-1 서브 특징 데이터 및 제 1-2 서브 특징 데이터에 포함된 요소들 간에 오퍼레이션을 취하여 제 1 특징 데이터를 획득할 수 있다. 동일한 과정이 수행되어 제 2 특징 데이터 내지 제 k 특징 데이터가 획득될 수 있다. 또한, 도 7을 참조하면, 제 2 특징 데이터는 통합기계학습모델에 적어도 하나의 서브 기계학습모델을 이용하여 획득될 수 있다. 제 2 특징 데이터는 제 2 분석 대상 데이터를 제 1 서브 기계학습모델에 적용하여 획득되는 제 3 복수의 특징 레이어들 중 적어도 하나의 특징 레이어를 포함할 수 있다. 제 3 복수의 특징 레이어들 중 적어도 하나의 특징 레이어는 제 2-1 서브 특징 데이터일 수 있다. 또한, 제 2 특징 데이터는 제 2 분석 대상 데이터를 제 2 서브 기계학습모델에 적용하여 획득되는 제 4 복수의 특징 레이어들 중 적어도 하나의 특징 레이어를 포함할 수 있다. 제 4 복수의 특징 레이어들 중 적어도 하나는 제 2-2 서브 특징 데이터일 수 있다. 제 2 특징 데이터는 제 2-1 서브 특징 데이터 및 제 2-2 서브 특징 데이터를 결합한 데이터일 수 있다. 이 때, 기계학습장치 또는 서버는 제 1 복수의 특징 레이어들, 제 2 복수의 특징 레이어들, 제 3 복수의 특징 레이어들 및 제 4 복수의 특징 레이어들에서 동일 위치의 레이어를 선택하여 제 1 특징 데이터 및 제 2 특 징 데이터를 획득할 수 있다. 도 9를 참조하면, 기계학습장치 또는 서버는 미드 레이어 또는 최종 레 이어 중 하나를 이용하여 제 1 특징 데이터 및 제 2 특징 데이터를 획득할 수 있다. 예를 들어, 최종 레이어를 선택하여 제 1 특징 데이터 및 제 2 특징 데이터를 획득하는 경우가 아래에서 설명된 다. 제 1 복수의 특징 레이어들은 도 10의 복수의 특징 레이어(1010, 1020, 1030, 1040, 922)를 포함할 수 있 다. 기계학습장치 또는 제 1 서버는 제 1 복수의 특징 레이어들 중 최종 레이어를 선택하여 제 1-1 서브 특징 레이어를 획득할 수 있다. 또한 제 2 복수의 특징 레이어들은 도 10의 복수의 특징 레이어(1010, 1020, 1030, 1040, 922)를 포함할 수 있다. 기계학습장치 또는 제 1 서버는 제 2 복수의 특징 레이 어들 중 최종 레이어를 선택하여 제 1-2 서브 특징 레이어를 획득할 수 있다. 제 1 특징 데이터는 제 1-1 서브 특징 레이어 및 제 1-2 서브 특징 레이어를 포함할 수 있다. 제 3 복수의 특징 레이어들은 도 10의 복수의 특징 레이어(1010, 1020, 1030, 1040, 922)를 포함할 수 있다. 기계학습장치 또는 제 2 서버는 제 3 복수의 특징 레이어들 중 최종 레이어를 선택하여 제 2-1 서브 특징 레이어를 획득할 수 있다. 또한 제 4 복수의 특징 레이어들은 도 10의 복수의 특징 레이어(1010, 1020, 1030, 1040, 922)를 포함할 수 있다. 기계학 습장치 또는 제 2 서버는 제 4 복수의 특징 레이어들 중 최종 레이어를 선택하여 제 2-2 서브 특징 레이어를 획득할 수 있다. 제 2 특징 데이터는 제 2-1 서브 특징 레이어 및 제 2-2 서브 특징 레이어를 포 함할 수 있다. 이하에서는 기계학습장치가 수신하는 데이터의 양을 살펴본다. 각 서버가 a개의 분석 대상 데이터를 포함 하고, 서버의 개수가 b이라고 가정하자. 서버의 개수가 b라고 가정한다. 통합기계학습모델에 포함된 서브 기계학습모델의 개수는 서버의 개수와 동일하므로 b개일 수 있다. 하나의 서버의 a개의 분석 대상 데이터에 대 하여 b개의 서브 기계학습모델이 적용되면, 하나의 서버에서 a x b개의 서브 특징 데이터가 생성될 수 있다. 또 한 b개의 서버에 대하여 동일한 개수의 서브 특징 데이터가 생성되므로 총 a x b x b개의 서브 특징 데이터가 생성될 수 있다. 위에서는 통합기계학습모델에 포함된 서브 기계학습모델의 개수를 서버의 개수와 동일하 게 가정하였으나 이에 한정되는 것은 아니다. 통합기계학습모델에 포함된 서브 기계학습모델은 1개 이상일 수 있다. 통합기계학습모델은 하나의 기본모델이거나, 복수의 서브 기계학습모델 중 선택된 적어도 하나의 서브 기계학습모델일 수 있기 때문이다. 이 경우 서브 특징 데이터는 a x b x b보다 작거나 같을 수 있다. 다시 도 6 및 도 7을 참조하면, 제 1 서버 내지 제 k 서버는 제 1 특징 데이터 내지 제 k 특징 데이터를 기계학습장치로 송신할 수 있다. 또한, 제 1 서버 내지 제 k 서버는 분석 결과 데이터를 기계학습장치로 송신할 수 있다. 기계학습장치는 통합기계학습모델을 서로 독립적인 복수의 학습 데이터 세트에 포함된 복수의 분석 대상 데이터(711, 712, 713)에 적용하여 획득된 복수의 특징 데 이터(721, 722, 723)를 수신하는 단계를 수행할 수 있다. 예를 들어, 기계학습장치는 제 k 분석 대상 데이터에 통합기계학습모델을 적용하여 획득된 제 k 특징 데이터를 수신하는 단계를 수행할 수 있다. 제 k 특징 데이터는 제 k 분석 대상 데이터에 서 식별 가능한 개인 정보가 암호화될 수 있다. 따라서 제 k 특징 데이터는 개인 정보가 식별되지 않을 수 있다. 유사하게, 기계학습장치는 제 1 분석 대상 데이터에 통합기계학습모델을 적용하여 획득된 제 1 특징 데이터를 수신하는 단계를 수행할 수 있다. 또한, 기계학습장치는 제 2 분석 대상 데이터에 통합기계학습 모델을 적용하여 획득된 제 2 특징 데이터를 수신하는 단계를 수행할 수 있다. 이미 설명한 바와 같이 학습 데이터 세트는 분석 대상 데이터 및 분석 결과 데이터를 포함할 수 있다. 하지만 분석 대상 데이터는 데이터 센터에서 반출이 불가능하므로, 기계학습장치는 제 1 서버 내지 제 k 서버로부 터 복수의 분석 대상 데이터(711, 712, 713) 대신 복수의 특징 데이터(721, 722, 723)를 수신할 수 있다. 복수 의 특징 데이터(721, 722, 723)는 개인정보가 식별되지 않고, 분석 대상 데이터로 복원될 수 없기 때문이다. 또 한 기계학습장치는 제 1 서버 내지 제 k 서버로부터 복수의 특징 데이터(721, 722, 723)에 각각 대응하는복수의 분석 결과 데이터를 수신할 수 있다. 복수의 분석 결과 데이터는 암호화되어 있지 않을 수 있다. 복수의 분석 결과 데이터는 실제(ground-truth) 데이터 또는 실제 레이블로 사용될 수 있다. 또한, 복수의 분석 결과 데이터에는 복수의 특징 데이터(721, 722, 723)에 각각 대응하고, 복수의 특징 데이터(721, 722, 723)에서 개인 정보가 식별되지 않으므로 복수의 분석 결과 데이터가 누구에 대한 것인지 식별되지 않을 수 있다. 기계학습장 치는 복수의 특징 데이터(721, 722, 723) 및 복수의 분석 결과 데이터를 최종데이터세트로써 획득할 수 있다. 기계학습장치는 복수의 특징 데이터(721, 722, 723)와 복수의 학습 데이터 세트에 포함된 복수의 분석 결 과 데이터 사이의 관계를 기계학습하여 최종기계학습모델을 획득하는 단계를 수행할 수 있다. 보다 구체적으로 기계학습장치는 제 1 특징 데이터 및 제 1 분석 결과 데이터의 상관 관계, 제 2 특 징 데이터 및 제 2 분석 결과 데이터의 상관 관계 또는 제 k 특징 데이터 및 제 k 분석 결과 데이터 의 상관 관계를 기계학습하여 최종기계학습모델을 획득하는 단계를 수행할 수 있다. 도 11은 본 개시의 일 실시예에 따라 최종기계학습모델을 생성하는 과정을 나타낸 도면이다. 이미 설명한 바와 같이 최종데이터세트는 특징 데이터 및 분석 결과 데이터를 포함할 수 있다. 특징 데이터는 도 7의 제 1 특징 데이터 내지 제 k 특징 데이터를 포함할 수 있다. 제 1 특징 데이터 내지 제 k 특징 데이터는 제 1 분석 대상 데이터 내지 제 k 분석 대상 데이터(71 3)에 일대일로 대응될 수 있다. 분석 결과 데이터는 실제(ground-truth) 데이터 또는 실제 레이블 일 수 있다. 분석 결과 데이터는 제 1 분석 결과 데이터 내지 제 k 분석 결과 데이터를 포함할 수 있다. 제 1 분석 결과 데이터 내지 제 k 분석 결과 데이터는 제 1 분석 대상 데이터 내지 제 k 분석 대상 데이터에 일대일 로 대응될 수 있다. 또한, 제 1 분석 결과 데이터 내지 제 k 분석 결과 데이터는 제 1 특징 데이터 내지 제 k 특징 데이터에 일대일로 대응될 수 있다. 기계학습장치는 데이터 학습부를 포함할 수 있다. 기계학습장치는 특징 데이터 및 분석 결과 데이터의 관계를 기계학습하여 최종기계학습모델을 생성할 수 있다. 기계학습장치는 심층 신경망을 기반으로 기계학습을 수행할 수 있다. 기계학습장치는 특징 데이터 및 분석 결과 데이터 를 이용하여 순전파(forward propagation) 및 역전파(back propagation)을 수행하면서 최종기계학습모델 의 정확도를 높일 수 있다. 최종기계학습모델은 특징 데이터와 분석 결과 데이터의 관계를 학습한 기계학습모델일 수 있 다. 따라서, 기계학습이 완료된 최종기계학습모델은 새로운 특징 데이터를 입력받고, 예측 결과 데이터를 출력할 수 있다. 최종기계학습모델이 새로운 특징 데이터를 분석하는 과정에 대해서는 도 12 및 도 13과 함께 보다 자세히 설명한다. 도 12는 본 개시의 일 실시예에 따른 기계학습장치의 동작을 나타내는 흐름도이다. 도 13은 본 개시의 일 실시 예에 따라 기계학습장치의 동작을 설명하기 위한 도면이다. 구체적으로, 기계학습장치는 데이터 인식부를 포함할 수 있다. 서버는 테스트 데이터를 통합기 계학습모델에 적용하여 예측 특징 데이터를 획득하는 단계를 수행할 수 있다. 여기서 서버는 제 1 서버 내지 제 k 서버 중 어느 하나일 수 있다. 테스트 데이터는 서버가 새롭게 획득한 분석 대상 데이터일 수 있다. 서버는 새롭게 획득한 분석 대상 데이터에 대응되는 분석 결과 데이터를 가지고 있지 않을 수 있다. 테스트 데이터에는 개인 정보가 포함되어 있을 수 있다. 서버는 테스트 데이터를 통합기계학습모델에 적용하여 예측 특징 데이터를 획득할 수 있다. 통합기계학습모델은 최종기계학습모델을 생성할 때 사용되었던 통합기계학습모델과 동일할 수 있다. 예측 특징 데이터는 테스트 데이터를 손실압축한 데이터일 수 있다. 예측 특징 데이터는 테 스트 데이터를 통합기계학습모델에 적용하였을 때 생성되는 복수의 레이어 중 적어도 하나의 레이어일 수 있다. 예측 특징 데이터는 도 8 내지 도 10과 같은 과정에 의하여 생성될 수 있다. 예를 들어 테스트 데 이터는 도 8의 제 k 분석 대상 데이터에 대응되고, 예측 특징 데이터는 도 8의 제 k 특징 데 이터에 대응될 수 있다. 예측 특징 데이터는 암호화되어 있을 수 있다. 따라서 예측 특징 데이터 는 개인정보가 식별되지 않을 수 있다. 예측 특징 데이터에서 개인정보가 식별되지 않으므로 서버는 예측 특징 데이터를 자유롭게 반출할 수 있다. 서버는 예측 특징 데이터를 기계학습장치로 송신 할 수 있다. 반출된 예측 특징 데이터는 외부의 고성능 장치를 이용하여 신속하고 정확하게 처리될 수 있 다. 외부의 고성능 장치는 기계학습장치일 수 있다. 기계학습장치는 테스트 데이터를 통합기계학습모델에 적용하여 획득된 예측 특징 데이터를 수 신하는 단계를 수행할 수 있다. 또한 기계학습장치는 예측 특징 데이터를 최종기계학습모델 에 적용하여 테스트 데이터에 관련된 예측 결과 데이터를 획득하는 단계를 수행할 수 있다. 예측 결과 데이터는 테스트 데이터를 최종기계학습모델에 의하여 분석한 결과일 수 있 다. 예측 결과 데이터는 테스트 데이터에 대한 기계학습장치의 분석결과이다. 예측 결과 데이 터는 사용자의 도움 없이 기계학습장치가 자동으로 도출한 데이터일 수 있다. 제 1 서버 내지 제 k 서버의 데이터를 모두 활용한 최종기계학습모델에 의한 결과 데이터이므로, 높은 확률로 실제 (ground truth) 데이터와 유사할 수 있다. 또한, 본 개시에 따르면, 제 1 서버 내지 제 k 서버의 데 이터를 모두 활용한 최종기계학습모델에 의한 결과 데이터이므로, 제 1 서버 내지 제 k 서버의 어떤 데이 터를 이용하더라도 정확도 높은 예측 결과 데이터를 획득할 수 있다. 또한 제 1 서버 내지 제 k 서 버 보다 고성능의 외부의 기계학습장치를 이용하여 대용량의 예측 특징 데이터를 처리하므로, 예측 결과 데이터는 빠르고 정확하게 획득될 수 있다. 사용자는 기계학습장치가 도출한 예측 결과 데이터를 참조하여 테스트 데이터에 대한 최종 분 석 결과를 도출할 수 있다. 사용자는 기계학습장치의 도움을 받으므로, 보다 정확하게 최종 분석 결과를 도출할 수 있다. 위에서는 기계학습장치가 제 1 서브 기계학습모델 내지 제 K 서브 기계학습모델 중 적어도 하나 를 이용하여 통합기계학습모델을 생성하고, 통합기계학습모델을 이용하여 최종기계학습모델을 생성하는 구성을 설명하였다. 하지만 이미 설명한 바 있듯이, 통합기계학습모델은 미리 결정된 기본모델을 포함할 수 있다. 기계학습장치는 통합기계학습모델을 생성하는 과정을 수행하지 않고, 미리 결정된 기본모델에 기초하여 최종기계학습모델을 생성할 수 있다. 즉, 도 6 내지 도 13의 통합기계학습모델 은 기본모델로 대체될 수 있다. 이하에서는 도 7과 함께, 통합기계학습모델에 포함된 기본모델에 기초하여 최종기계학습모델을 생성하는 과정을 간략하게 설명한다. 도 7을 참조하면, 기계학습장치는 제 1 분석 대상 데이터에 기본모델을 적용하여 획득된 제 1 특징 데이터를 수신하는 단계를 수행할 수 있다. 또한, 기계학습장치는 제 2 분석 대상 데이터에 기 본모델을 적용하여 획득된 제 2 특징 데이터를 수신하는 단계를 수행할 수 있다. 여기서, 제 1 분석 대상 데이터 및 제 2 분석 대상 데이터는 서로 다른 환경에서 획득된 의료 영상과 관련된 데이터일 수 있다. 기본모델은 영상을 분류하기 위한 일반적인 기계학습모델이 이용될 수 있다. 기본모 델은 미리 학습된 모델일 수 있다. 기본모델은 예를 들어 이미지넷이 사용될 수 있다. 제 1 분석 결과 데이터는 제 1 분석 대상 데이터를 사용자가 분석한 결과이고, 제 2 분석 결과 데이터는 제 2 분석 대상 데이터 를 사용자가 분석한 결과일 수 있다. 제 1 분석 결과 데이터 및 제 2 분석 결과 데이터는 실제(ground truth) 데이터 또는 실제 레이블일 수 있다. 제 1 분석 대상 데이터 및 제 1 분석 결과 데이터는 제 1 학 습 데이터 세트에 포함될 수 있다. 제 2 분석 대상 데이터 및 제 2 분석 결과 데이터는 제 2 학습 데 이터 세트에 포함될 수 있다. 제 1 특징 데이터 및 제 2 특징 데이터는 제 1 분석 대상 데이터 및 제 2 분석 대상 데이터 를 손실 압축한 데이터일 수 있다. 제 1 특징 데이터 및 제 2 특징 데이터는 제 1 분석 대상 데 이터 및 제 2 분석 대상 데이터를 암호화한 데이터일 수 있다. 제 1 특징 데이터 및 제 2 특징 데이터는 제 1 분석 대상 데이터 및 제 2 분석 대상 데이터로 복원되지 못할 수 있다. 제 1 분 석 대상 데이터 및 제 2 분석 대상 데이터는 개인정보가 포함되고, 제 1 특징 데이터 및 제 2 특징 데이터는 개 인정보가 식별되지 않을 수 있다. 따라서 개인정보보호를 위하여 서버들(420, 430, 440)은 제 1 분석 대상 데이 터 및 제 2 분석 대상 데이터를 기계학습장치로 송신할 수 없다. 하지만 서버들(420, 430, 44 0)은 제 1 특징 데이터 및 제 2 특징 데이터를 기계학습장치로 송신할 수 있다. 제 1 특징 데이터는 제 1 분석 대상 데이터를 기본모델에 적용하여 획득되는 제 1 복수의 특징 레이 어들 중 적어도 하나의 레이어이고, 제 2 특징 데이터는 제 2 분석 대상 데이터를 기본모델에 적용하여 획득되는 제 2 복수의 특징 레이어들 중 적어도 하나의 레이어일 수 있다. 기계학습장치는 제 1 복수의 특징 레이어들 및 제 2 복수의 특징 레이어들에서 동일 위치의 레이어를 선택하여 제 1 특징 데이터 및 제 2 특징 데이터를 각각 획득할 수 있다. 기계학습장치는 제 1 특징 데이터, 제 1 분석 결과 데이터, 제 2 특징 데이터 및 제 2 분석 결 과 데이터를 서버들(420, 430, 440)로부터 수신할 수 있다. 기계학습장치는 제 1 특징 데이터 및 제 1 분석 결과 데이터의 상관 관계 그리고 제 2 특징 데이터 및 제 2 분석 결과 데이터의 상관 관계를 기계학습하여 최종기계학습모델을 획득하는 단계를 수행할 수 있다. 도 13을 참조하면 서버는 테스트 데이터에 기본모델을 적용하여 예측 특징 데이터를 획득할 수 잇 다. 기계학습장치는 테스트 데이터에 기본모델을 적용하여 획득된 예측 특징 데이터를 수신하 는 단계를 수행할 수 있다. 기계학습장치는 예측 특징 데이터에 최종기계학습모델을 적용하여 테스트 데이터에 대응하는 예측 결과 데이터를 획득하는 단계를 수행할 수 있다. 여기서, 예측 특징 데이터는 테스트 데이터를 손실 압축한 데이터일 수 있다. 테스트 데이터는 개인정보가 포함 되고, 예측 특징 데이터는 개인정보가 식별되지 않을 수 있다. 예측 결과 데이터는 테스트 데이터에 대한 기계학습장치의 분석결과이다. 예측 결과 데이터 는 사용자의 도움 없이 기계학습장치가 자동으로 도출한 데이터일 수 있다. 제 1 서버 내지 제 k 서버의 데이터를 모두 활용한 최종기계학습모델에 의한 결과 데이터이므로, 예측 결과 데이터 는 높은 확률로 실제(ground truth) 데이터와 유사할 수 있다. 또한, 본 개시에 따르면, 제 1 서버 내지 제 k 서버의 데이터를 모두 활용한 최종기계학습모델에 의한 결과 데이터이므로, 제 1 서버 내 지 제 k 서버의 어떤 데이터를 이용하더라도 정확도 높은 예측 결과 데이터를 획득할 수 있다. 또한 제 1 서버 내지 제 k 서버 보다 고성능의 외부의 기계학습장치를 이용하여 대용량의 예측 특징 데이 터를 처리하므로, 예측 결과 데이터는 빠르고 정확하게 획득될 수 있다. 이제까지 다양한 실시예들을 중심으로 살펴보았다. 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자는 본 발명이 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있 을 것이다. 그러므로 개시된 실시예들은 한정적인 관점이 아니라 설명적인 관점에서 고려되어야 한다. 본 발명 의 범위는 전술한 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동등한 범위 내에 있는 모든 차이점은 본 발명에 포함된 것으로 해석되어야 할 것이다. 한편, 상술한 본 발명의 실시예들은 컴퓨터에서 실행될 수 있는 프로그램으로 작성가능하고, 컴퓨터로 읽을 수 있는 기록매체를 이용하여 상기 프로그램을 동작시키는 범용 디지털 컴퓨터에서 구현될 수 있다. 상기 컴퓨터로 읽을 수 있는 기록매체는 마그네틱 저장매체(예를 들면, 롬, 플로피 디스크, 하드디스크 등), 광학적 판독 매체 (예를 들면, 시디롬, 디브이디 등)와 같은 저장매체를 포함한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13"}
{"patent_id": "10-2021-0007191", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 기계학습장치의 블록도이다. 도 2는 본 개시의 일 실시예에 따른 기계학습장치를 나타낸 도면이다. 도 3은 본 개시의 일 실시예에 따른 기계학습장치의 동작을 나타내는 흐름도이다. 도 4는 본 개시의 일 실시예에 따라 통합기계학습모델을 획득하는 과정을 나타낸 도면이다. 도 5는 본 개시의 일 실시예에 따라 서브 기계학습모델을 생성하는 과정을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시예에 따라 최종기계학습모델을 생성하는 방법을 나타낸 흐름도이다. 도 7은 본 개시의 일 실시예에 따른 최종기계학습모델을 생성하는 방법을 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시예에 따른 특징 데이터를 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시예에 따라 특징 데이터를 생성하는 과정을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시예에 따라 특징 데이터를 생성하는 과정을 설명하기 위한 도면이다. 도 11은 본 개시의 일 실시예에 따라 최종기계학습모델을 생성하는 과정을 나타낸 도면이다. 도 12는 본 개시의 일 실시예에 따른 기계학습장치의 동작을 나타내는 흐름도이다. 도 13은 본 개시의 일 실시예에 따라 기계학습장치의 동작을 설명하기 위한 도면이다."}
