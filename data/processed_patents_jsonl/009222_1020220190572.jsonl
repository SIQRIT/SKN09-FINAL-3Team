{"patent_id": "10-2022-0190572", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0107691", "출원번호": "10-2022-0190572", "발명의 명칭": "멀티모달 기타 연주 채보 방법 및 장치", "출원인": "서울대학교산학협력단", "발명자": "이교구"}}
{"patent_id": "10-2022-0190572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "기타의 코드 연주를 캡쳐한 음성 신호로부터 다중음 피치(polyphonic pitch)와 운지 배열(fingeringarrangement) 정보를 추정하여 출력하는 음성분석기(audio analyzer)와;동일한 코드 연주 장면을 캡쳐한 영상 신호를 입력 받아 지판의 형태와 손 형태를 추정하고 그를 기초로 지판상의 손 위치를 추정하여 출력하는 영상분석기(video analyzer)와;상기 음성분석기와 영상분석기의 출력으로부터 태블랫 운지 배열(tablature fingering arrangement) 정보를 출력하는 센서융합부(sensor fusion unit)를 포함하는 기타 자동채보장치."}
{"patent_id": "10-2022-0190572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 음성분석기는 :기타의 코드 연주를 캡쳐한 음성 신호로부터 각 프렛에서의 손가락의 운지 여부 정보와 그 확률 정보를 출력하는 심층신경망회로(Deep Neural Network)를 포함하는 기타 자동채보장치."}
{"patent_id": "10-2022-0190572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서, 영상분석기는 : 코드 연주 장면을 캡쳐한 영상 신호를 입력 받아 손의 골격(skeleton)을 추정하는 골격추정부와;코드 연주 장면을 캡쳐한 영상 신호를 입력 받아 지판을 탐지하는 지판탐지부와(fingerboard detection unit);상기 지판탐지부의 출력과 골격추정부의 출력으로부터 손의 지판 상의 위치를 계산하여 출력하는 손가락위치추정부(finger position estimation unit);를 포함하는 기타 자동채보장치."}
{"patent_id": "10-2022-0190572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서, 골격추정부는 손가락 골격의 관절점별 좌표를 출력하는 심층신경망으로 구현되는 자동채보장치."}
{"patent_id": "10-2022-0190572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서, 지판탐지부는 전이학습된 심층신경망으로 구현되는 자동채보장치."}
{"patent_id": "10-2022-0190572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 2에 있어서, 상기 장치가 : 음성분석기에서 출력한 각 프렛에서의 손가락의 운지 여부 정보와 그 확률 정보로부터 운지 여부가 모호할 경우영상분석기를 실행하는 실행제어기;를 더 포함하는 기타 자동채보장치."}
{"patent_id": "10-2022-0190572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서, 센서융합부는 음성분석기에서 출력된 운지 배열 후보들중에서 영상분석기에서 출력된 지판상의 손위치 정보를 기반으로 가장 확률이 높은 운지 배열을 태블랫 운지 배열로 결정하여 출력하는 기타 자동채보장치."}
{"patent_id": "10-2022-0190572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2024-0107691-3-기타 연주자의 연주 음성과 연주 영상을 정보처리요소에 의해 처리하여 태블랫 운지 배열 정보를 자동으로 생성하는 자동채보방법에 있어서, 상기 방법이 : 기타의 코드 연주를 캡쳐한 음성 신호로부터 다중음 피치(polyphonic pitch)와 운지 배열(fingeringarrangement) 정보를 추정하여 출력하는 음성분석 단계와;코드 연주 장면을 캡쳐한 영상 신호를 입력 받아 지판의 형태와 손 형태를 추정하고 그를 기초로 지판 상의 손위치를 추정하여 출력하는 영상분석 단계와;상기 음성분석 단계와 영상분석 단계의 출력들로부터 태블랫 운지 배열(tablature fingering arrangement) 정보를 출력하는 센서융합 단계(sensor fusion unit)를 포함하는 기타 자동채보 방법."}
{"patent_id": "10-2022-0190572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서, 음성분석 단계는 심층신경망회로(Deep Neural Network)를 통해 각 프렛에서의 손가락의 운지 여부 정보와 그 확률 정보를 출력하는 기타 자동채보방법."}
{"patent_id": "10-2022-0190572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 8에 있어서, 영상분석 단계는 : 코드 연주 장면을 캡쳐한 영상 신호를 입력 받아 손의 골격(skeleton)을 추정하는 골격추정 단계와;코드 연주 장면을 캡쳐한 영상 신호를 입력 받아 지판을 탐지하는 지판탐지 단계와(fingerboard detectionunit);상기 지판탐지 단계의 출력과 골격추정 단계의 출력으로부터 손의 지판 상의 위치를 계산하여 출력하는 손가락위치추정 단계;를 포함하는 기타 자동채보방법."}
{"patent_id": "10-2022-0190572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 10에 있어서, 골격추정 단계는 심층신경망을 통해 손가락 골격의 관절점별 좌표를 출력하는 자동채보방법."}
{"patent_id": "10-2022-0190572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서, 지판탐지 단계는 전이학습된 심층신경망을 이용하는 자동채보방법."}
{"patent_id": "10-2022-0190572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 9에 있어서, 상기 방법이 : 음성분석 단계에서 출력한 각 프렛에서의 손가락의 운지 여부 정보와 그 확률 정보로부터 운지 여부가 모호할경우 영상분석 단계를 실행하는 실행제어단계;를 더 포함하는 기타 자동채보방법."}
{"patent_id": "10-2022-0190572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 8에 있어서, 센서융합 단계는 음성분석 단계에서 출력된 운지 배열 후보들중에서 영상분석 단계에서 출력된 지판 상의 손위치 정보를 기반으로 가장 확률이 높은 운지 배열을 태블랫 운지 배열로 결정하여 출력하는기타 자동채보방법."}
{"patent_id": "10-2022-0190572", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "기타의 코드 연주를 캡쳐한 음성 신호로부터 다중음 피치 정보와 운지 배열 정보가 추정된다. 동일한 코드 연주 의 장면을 캡쳐한 영상신호로부터 지판의 형태와 손 형태를 추정하고 그를 기초로 지판 상의 손 위치가 추정된다. 음성 신호로부터 추정된 다중음 피치 정보와, 운지 배열 정보 및 영상 신호로부터 추정된 지판 상의 손 위치를 이용하여 가능한 태블랫 운지 배열 정보가 결정된다. 지판 상의 손 위치 정보는 각 프렛에서의 손가 락의 운지 여부 정보로 표현되고, 심층신경망 회로를 통해 추정될 수 있다."}
{"patent_id": "10-2022-0190572", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "음성 신호 처리 기술, 그 중에서 자동 채보(AMT : Automatic Music Transcription) 혹은 음악 정보 추출(MIR : music information retrieval), 특히 기타 연주(Guitar Performance)로부터 코드와 멜로디를 자동으로 채보하는 기술이 개시된다."}
{"patent_id": "10-2022-0190572", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성 신호 처리 분야 중 자동채보분야에서 건반에 의존하는 피아노에 비해 손가락(finger)으로 현을 튕겨서 연 주하는 기타 연주의 채보 기술은 어려운 것으로 알려져 있다. 이러한 어려움은 부분적으로는, 동일한 음을 낼 수 있는 운지법이 여러가지라는 모호성이 다중음(polyphonic) 연주와 결합되는 기타 연주의 특이성에 기인하고 있다. GuitarSet 데이터는 Xi, Qingyang, et al. \"GuitarSet: A Dataset for Guitar Transcription.\" ISMIR. 2018. 를 통해 공개된 것으로, 어쿠스틱 기타에 헥사포닉 픽업 (hexaphonic pickup)을 장착하고 일반 컨덴서 마이크를 포함하여 총 7채널로 녹음한 다성음 음악 60곡, 총 30분 연주음과, 각각의 여섯 줄의 음고를 pYIN 알고리즘을 통해 추정하여 채보한 데이터를 제공한다. Wiggins, Andrew, and Youngmoo Kim. \"Guitar Tablature Estimation with a Convolutional Neural Network.\" ISMIR. 2019. 에는 이 GuitarSet 데이터를 이용하여 기타 의 여섯 개 줄에 대해 연주한 프렛 번호를 추정하는 기술이 개시되어 있다. TabCNN이라고 불리는 이 기술은 입 력 음성을 Constant-Q transform (CQT)으로 변환시킨 다음 합성곱신경망 (Convolutional Neural Networks, CNN)을 통과시켜 각각의 여섯 개 줄에 대해 몇 번 프렛을 연주했는지를 예측한다. Kun Su, Xiulong Liu, Eli Shlizerman “Audeo: Audio Generation for a Silent Performance Video”, 2020. 는 음원이 없는 피아노 연주 영상으로부터 연주 MIDI를 추정하여 최종적으로 음성으로 변환하는 기술을 개시하 고 있다. 또 상용화된 기타 교습 싸이트를 운영하는 회사로 유명한 Yousician은 그 소유한 미국특허 US10,482,862에 개시된 바와 같이 기타를 연주하는 손의 골격(skeleton)을 추정하여 올바른 연주를 유도하는 AR(Augmented Reality) 그래픽 사용자 인터페이스 기술을 교습에 활용하고 있다. Paleari, Marco, et al. \"A multimodal approach to music transcription.\" 2008 15th IEEE international conference on image processing. IEEE, 2008.은 음성 채보 기술을 보완하기 위해 영상 분석을 사용하는 멀티 모달 기타연주 채보기술을 개시하고 있다. 이 종래기술은 프렛에서 손가락이 차지하는 면적에 기초하여 손가락 의 위치를 추정하는 방식을 채택하고 있는데 이로 보듯이 이 종래 기술은 단일 음의 연주를 추정하는 수준에 머 무르고 있으며, 동시에 여러 음이 연주되는 일반적인 다중음(polyphonic) 기타 연주를 분석하는 수준에 미치지 못하고 있다. 이와 같이 채보기술의 주류는 음성 신호를 캡쳐하는데 의존해왔으며, 영상을 활용하는 기술은 피아노 분야에서 제한적으로 적용되거나 올바른 운지법을 AR을 통해 표시하기 위해 활용되었을 뿐이다. 그러나 오랫동안의 연구 에도 불구하고 다중음, 즉 코드 연주를 캡쳐한 음성 신호로부터 채보하는 기술의 신뢰도는 한계를 보여왔다."}
{"patent_id": "10-2022-0190572", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "제안된 발명은 기타 연주 채보의 성능을 개선하는 것을 목적으로 한다. 나아가 제안된 발명은 기타 연주를 캡쳐함에 있어서 캡쳐된 음성 신호에 의존하는 기술의 한계를 극복하는 것을 목적으로 한다. 더 나아가 제안된 발명은 기타 연주로부터 태블랫 운지 배열을 자동으로 획득하는 신뢰성 있는 방법을 제시하는 것을 목적으로 한다. 더 나아가 제안된 발명은 기타 연주로부터 태블랫 운지 배열을 효율적으로 획득하는 것을 목적으로 한다."}
{"patent_id": "10-2022-0190572", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "제안된 발명의 일 양상에 따르면, 캡쳐된 음성 신호에 추가로 이 음성 신호에 동기화되어 캡쳐된 영상 신호를 활용하여 채보하는 기술이 제안된다. 일 양상에 따르면, 기타의 코드 연주를 캡쳐한 음성 신호로부터 다중음 피치 정보와 운지 배열 정보가 추정된다. 코드 연주 장면을 캡쳐한 영상신호로부터 지판의 형태와 손 형태를 추정하고 그를 기초로 지판 상의 손 위치가 추정된다. 음성 신호에서 추정된 다중음 피치 정보와 운지 배열 정 보, 그리고 영상신호로부터 추정된 지판 상의 손 위치를 이용하여 가능한 태블랫 운지 배열 정보가 결정된다. 추가적인 양상에 따라, 지판 상의 손 위치 정보는 각 프렛에서의 손가락의 운지 여부 정보로 표현되고, 심층신 경망 회로를 통해 추정될 수 있다. 추가적인 양상에 따라, 음성분석을 통해 코드의 음들을 추정한 다음, 영상분석을 통해 코드음으로부터의 운지 추정의 모호성을 제거할 수 있다. 또 다른 양상에 따르면, 코드 연주 장면을 캡쳐한 영상에서 지판(fingerboard)과 손의 골격을 추정한 후 지판 상의 손의 위치를 추정함으로써 운지 배열 정보가 생성될 수 있다."}
{"patent_id": "10-2022-0190572", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "제안된 발명에 따라, 기타의 코드 연주 음성과 영상으로부터 태블랫 운지 배열이 추정될 수 있다. 기존에 음성 분석을 통한 추정의 한계를 극복하여 신뢰성 있는 태블랫 운지 배열 추정이 가능하다. 또 검증된 기술을 적용 하여 음성 분석으로부터 코드의 음들과 운지 배열을 예측하고, 이후에 영상 분석을 통해 운지 배열 추정의 모호 성을 제거함으로써, 운지의 모호성이 없는 프레임들의 경우 영상 분석을 생략할 수 있다."}
{"patent_id": "10-2022-0190572", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "전술한, 그리고 추가적인 양상들은 첨부된 도면을 참조하여 설명하는 실시예들을 통해 구체화된다. 각 실시예 들의 구성 요소들은 다른 언급이나 상호간에 모순이 없는 한 실시예 내에서 또는 타 실시예의 구성 요소들과 다 양한 조합이 가능한 것으로 이해된다. 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명하기 위해 용어의 개념을 적절하게 정의할 수 있다는 원칙에 입각하여 본 명세서 및 청구범위에 사용된 용어는 기재 내용 혹은 제 안된 기술적 사상에 부합하는 의미와 개념으로 해석되어야만 한다. 이하 첨부된 도면을 참조로 본 발명의 바람 직한 실시예를 상세히 설명하기로 한다. <청구항 1 발명의 설명> 제안된 발명의 일 양상에 따르면, 캡쳐된 음성 신호에 추가로 이 음성 신호에 동기화되어 캡쳐된 영상 신호를 활용하여 채보하는 기술이 제안된다. 일 양상에 따르면, 기타의 코드 연주를 캡쳐한 음성 신호로부터 다중음 피치 정보와 운지 배열 정보가 추정된다. 코드 연주 장면을 캡쳐한 영상신호로부터 지판의 형태와 손 형태를 추정하고 그를 기초로 지판 상의 손 위치가 추정된다. 음성 신호에서 추정된 다중음 피치 정보와 운지 배열 정 보, 그리고 영상신호로부터 추정된 지판 상의 손 위치를 이용하여 가능한 태블랫 운지 배열 정보가 결정된다. 여기서 운지 배열은 지판 상의 프렛별로 특정한 프렛이 손가락이 온셋(onset)되었는지 여부의 정보를 말한다. 예를 들어 운지배열정보는 프렛 번호순으로 1 또는 0의 값을 가지는 배열(array)로 표현될 수 있다. 이에 대 하여 본 명세서에서 태블랫 운지 배열(tablature fingering arrangement)은 운지 배열 중 물리적으로 연주가 가 능한 것을 말한다. 물리적으로 기타 연주가 가능한 운지 조합의 조건들이나 그 연주 난이도를 계산하는 다양한 방법이 알려져 있으므로 이에 대해서는 자세한 설명은 생략한다. 도 1은 이러한 양상이 적용된 일 실시예에 따른 자동채보장치의 구성을 도시한 블록도이다. 도면에서 각각의 블록들은 적어도 하나의 디지털신호처리기나 적어도 하나의 전용의 인공지능반도체, 그리고 이들 중 하나 혹은 전부와 연결된 적어도 하나의 마이크로프로세서와, 이들 각각에서 실행되는 컴퓨터 프로그램 명령어들을 포함하 는 시스템으로 구현될 수 있다. 예를 들어 도 1의 장치에서 음성분석기와 영상분석기는 디지털신호처리기에서 프로그램 명령어들로 구현되고, 센서융합부는 마이크로프로세서와 그 실행되는 프로그램 명령어들로 구현될 수 있다. 기타 연주는 예를 들면 헥사포닉 픽업 (hexaphonic pickup)을 통해 캡쳐될 수 있다. 일 실시예에 따른 자동채 보장치에서 기타 연주는 연주자의 스마트폰과, 예를 들면 블루투쓰 근거리 통신을 통해 연결되고 기타의 울림통 에 근접하여 설치된 마이크를 통해 캡쳐된다. 일 실시예에 따른 자동채보장치는 음성분석기와, 영상분석 기와, 센서융합부를 포함한다. 음성분석기는 기타의 코드 연주를 캡쳐한 음성 신호로부터 다중음 피치(polyphonic pitch)와 운지 배열 (fingering arrangement) 정보를 추정하여 출력한다. 음성 분석기는 알려진 공지의 기술 중 하나를 채용할 수 있다. 예를 들면 캡쳐된 음성에서 다중 이진 분류기들(multiple binary classifiers)을 이용하여 각각의 피치 의 존재를 추정함으로써 동시에 울리는 다중음(multipitch)를 파악하고, 이후에 이 다중음의 연주에 물리적으로 가장 적합한 태블랫 운지 배열을 결정하는 방법을 적용할 수 있다. 영상분석기는 코드 연주 장면을 캡쳐한 영상 신호를 입력 받아, 코드 연주 장면을 캡쳐한 영상 신호를 입 력 받아 지판의 형태와 손 형태를 추정하고 그를 기초로 지판 상의 손 위치를 추정하여 출력한다. 프렛 위치는 캡쳐된 영상에서 기타의 넥(neck) 윤곽을 인식한 후 넥에서 인식 가능한 프렛들의 위치를 결정한 다음 인식된 프렛들의 위치 정보를 이용하여 전체적인 프렛의 배치를 결정할 수 있다. 손 위치는 왼손 손가락의 관절점들을 인식하고, 인식 가능한 관절점들의 위치를 기초로 왼손 손가락 끝점들의 위치와 방향들을 추정하며 그 위치와 방향이 추정된 프렛 평면에 투사한 위치를 추정함에 의해 고전적인 방법으로 추정할 수 있다. 센서융합부는 음성분석기와 영상분석기의 출력으로부터 태블랫 운지 배열 정보를 출력한다. 예를 들어 센 서융합부는 음성분석기에서 인식된 다중피치 중 기준 크기 이상으로 인식된 피치음들을 기준으로 영 상분석기에서 추정된 손위치들을 검증할 수 있다. 또 음성분석기에서 인식된 다중피치 중 기준 크기 미만으로 인식된 피치음들의 경우 영상분석기에서 추정된 손위치들을 통해 상호간에 유효성을 검증할 수 있다. 이를 통해 센서융합부는 음성분석기에서 출력된 다중음 피치 정보를 영상분석기에서 추정된 운지배 열정보를 검증할 수 있고, 또 영상분석기에서 추정된 운지배열정보를 기초로 음성분석기에서 출력된 다중음 피 치 정보를 검증할 수 있다. 이를 통해 센서융합부는 검증된 태블랫 운지 배열 정보를 출력할 수 있다. <청구항 2 발명의 설명> 도 2는 또 다른 실시예에 따른 자동채보장치의 구성을 도시한 블록도이다. 도면에서 각각의 블록들은 적어도 하나의 디지털신호처리기나 적어도 하나의 전용의 인공지능반도체, 그리고 이들 중 하나 혹은 전부와 연결된 적 어도 하나의 마이크로프로세서와, 이들 각각에서 실행되는 컴퓨터 프로그램 명령어들을 포함하는 시스템으로 구 현될 수 있다. 예를 들어 도 2의 장치에서 음성분석기와 영상분석기는 각각 적어도 하나의 전용의 인공지능 반 도체를 포함하여 구현될 수 있다. 인공지능 반도체는 내부에 복수의 계산요소(computing element)와 기억요소 (storage element)를 포함할 수 있다. 또 음성분석기와 영상분석기의 일부 그리고 실행제어기와 센서융합부는 디지털신호처리기와 메모리, 그리고 그 메모리에 저장되고 디지털신호처리기에 의해 실행되는 프로그램 명령어 들로 구현될 수 있다. 예를 들어 음성분석기의 심층신경망과 영상분석기의 골격추정부, 지판탐지부는 각각 별도의 인공지능반도체로 구현될 수 있다. 또 음성분석기의 공간피처추출부, 영상분석기의 손 위치추정부, 실행제어기 그리고 센서융합부는 단일의 디지털신호처리기에서 실행되는 프로그램 명령어들의 기능적인 블록들로 구현될 수 있다. 본 명세서에서는 각각의 기능을 수행하는 이러한 정보처리장치 들의 구성을 '정보처리요소'라고 부르기로 한다. 기타 연주는 예를 들면 헥사포닉 픽업 (hexaphonic pickup)을 통해 캡쳐될 수 있다. 일 실시예에 따른 자동채 보장치에서 기타 연주는 연주자의 스마트폰과, 예를 들면 블루투쓰 근거리 통신을 통해 연결되고 기타의 울림통 에 근접하여 설치된 마이크를 통해 캡쳐된다. 일 실시예에 따른 자동채보장치는 음성분석기와, 영상분석 기와, 센서융합부를 포함한다. 음성분석기는 기타의 코드 연주를 캡쳐한 음성 신호로부터 다중음 피치(polyphonic pitch)와 운지 배열 (fingering arrangement) 정보를 추정하여 출력한다. 추가적인 양상에 따라, 운지 배열 정보는 각 프렛에서의 손가락의 운지 여부 정보로 표현되고, 심층신경망 회로, 예를 들면 영상의 분석에 널리 채용되는 합성곱신경망 (CNN : Convolutional Neural Network)을 통해 추정될 수 있다. 도 2에 도시된 바와 같이, 일 실시예에 따른 음성분석기는 공간피처추출부와 심층신경망을 포함할 수 있다. 음성 신호는 샘플링율과 대역폭 을 제한한 후 영상 형태(image representation)로 변환된다. 공간피처추출부는 캡쳐된 음성 신호를 영상 형태로 변환을 위해 피치에 따라 선형적으로 이격된 주파수 축을 가진 형식으로 변환하기 위해 CQT(constant-Q transform) 변환된다. 홉크기(hopsize) 만큼씩 중첩되면서 슬라이딩하는 윈도우(sliding contest window)를 사용하여 CQT가 적용될 수 있다. 심층신경망을 통한 음성분석에는 예를 들면, 전술한 Wiggins에 기재된 바와 같은 구조를 가진 합성 곱신경망이 적용될 수 있다. 도시된 실시예에서, 어쿠스틱 기타의 19개 프렛들과 스트링이 울리지 않는 경우 및 개방현음을 포함하여 21개의 상이한 프렛 클라스들(fret classes)이 정의되고, 6개의 현이 있으므로 프레임마다 모두 6 × 21개의 라벨(labels)을 정의할 수 있다. 도시된 실시예에서, 합성곱신경망은 각각이 ReLU(Rectified Linear Unit)에 직접 연결된 3개의 연속된 합 성곱층(a series of three convolutional layers)을 가지며, 결과적인 피처맵(feature map)은 2×2의 최대풀링 층(max pooling layer)에 의해 서브샘플링되고 소프트맥스 활성화(softmax activation)가 적용된 구조를 가진 다. 각 합성곱층의 필터들의 파라메터는 경험적으로 결정될 수 있다. 이 합성곱신경망은 6개의 기타현마다 21 개의 상이한 프렛 클라스들의 할당 정보를 그 확률과 함께 출력한다. <청구항 3,4,5 발명의 설명> 영상분석기는 코드 연주 장면을 캡쳐한 영상 신호를 입력 받아, 코드 연주 장면을 캡쳐한 영상 신호를 입 력 받아 지판의 형태와 손 형태를 추정하고 그를 기초로 지판 상의 손 위치를 추정하여 출력한다. 또 다른 양 상에 따르면, 코드 연주 장면을 캡쳐한 영상에서 지판(fingerboard)과 손의 골격을 추정한 후 지판 상의 손의 위치를 추정함으로써 운지 배열 정보가 생성될 수 있다. 이러한 양상에 따라, 도시된 실시예에서 영상분석기 는 골격추정부와, 지판탐지부와, 손위치추정부를 포함할 수 있다. 골격추정부는 코드 연주 장면을 캡쳐한 영상 신호를 입력 받아 손의 골격(skeleton)을 추정한다. 일 실시 예에서, 골격추정부는 심층신경망, 예를 들면 구글에서 제공하는 미디어파이프(MediaPipe)로 구현될 수 있 다. 미디어파이프(MediaPipe)는 학습까지 완료된 AI 모델을 라이브러리 형태로 모듈화하여 제공되고 있으며, 인체를 대상으로 하는 비전인식기능들을 제공한다. 이 미디어파이프 라이브러리를 이용하여 손가락의 골격의 각 관절점의 인덱싱된 좌표값을 획득할 수 있다. 지판탐지부는 코드 연주 장면을 캡쳐한 영상 신호를 입력 받아 지판을 탐지한다. 일 실시예에서, 지판탐 지부는 심층신경망, 예를 들면 HRNet으로 구현될 수 있다. 여기서는 ImageNet에서 학습된 HRNet을 기타 연주 영상 프레임들에서 지판의 모서리 키포인트 4개를 라벨링한 데이터로 전이 학습(Transfer Learning)시켜 사용한 다. ImageNet은 심층 학습(Deep Learning)에 활용하도록 제공되는 공개된 영상 데이터베이스이다. 손위치추정부는 지판탐지부의 출력과 골격추정부의 출력으로부터 손의 지판 상의 위치를 계산하 여 출력한다. 예를 들어 골격추정부에서 손가락 끝쪽 관절점 2개의 좌표들로부터 위치와 방향을 가진 손 가락 끝점 벡터를 구한다. 또 지판탐지부에서 탐지된 키포인트 좌표 4개로부터 지판 평면 및 윤곽정보를 계산한다. 이후에 지판 상에 손가락 끝점 벡터를 투사(projection)하여 운지점 좌표를 계산할 수 있다. 지판 상의 프렛의 배열은 알려져 있으므로 이러한 과정을 통해 개략적인 운지 배열 정보를 계산할 수 있다. <청구항 6 발명의 설명> 추가적인 양상에 따라, 음성분석을 통해 코드의 음들을 추정한 다음, 영상분석을 통해 코드 음으로부터의 운지 추정의 모호성을 제거할 수 있다. 선행기술들에서 보듯이, 음성 분석을 통해 코드의 음들은 상당히 정확하게 예측할 수 있지만 그로부터 운지 배열을 추정하는 것은 한계가 있다. 영상 분석으로부터 운지 배열을 먼저 추 정한 후, 그 결과를 음성 분석에 반영하는 접근을 할 수도 있지만, 제안된 발명에서는 그 반대의 접근을 취한다. 즉, 먼저 검증된 기술을 적용하여 음성 분석으로부터 코드의 음들과 운지 배열을 예측하고, 이후에 영 상 분석을 통해 운지 배열 추정의 모호성을 제거한다. 운지의 모호성이 없는 프레임들의 경우 영상 분석은 불필 요할 수도 있다. 이러한 양상에 따라, 도시된 실시예는 실행제어기를 더 포함할 수 있다. 실행제어기는 음성분석기 에서 출력한 각 프렛에서의 손가락의 운지 여부 정보와 그 확률 정보로부터 운지 여부가 모호할 경우 영상 분석기를 실행한다. 예를 들어 심층신경망의 출력에서 확률이 기준치 이하인 운지배열이 있는 프레 임은 그 동기화된 캡쳐 영상을 분석하여 운지 배열 추정의 모호성을 제거하도록 시도할 수 있다. 음성분석기 에서 대부분의 프렛의 운지 여부가 높은 확률로 결정되므로, 이러한 실행제어기를 부가함에 의해 계 산량을 크게 줄일 수 있다. <청구항 7 발명의 설명>도시된 실시예에서, 센서융합부는 음성분석기와 영상분석기의 출력으로 부터 태블랫 운지 배열 정보를 출력한다. 도시된 실시예에서, 센서융합부는 음성분석기에서 출력된 운지 배열 후보들 중에서 영상분석기에서 출력된 지판 상의 손위치 정보를 기반으로 가장 확률이 높은 운 지 배열을 태블랫 운지 배열로 결정하여 출력할 수 있다. 기타 연주에서 코드는 지판 상의 여러 위치에서 여러가지 손가락 모양, 즉 운지배열로 연주될 수 있다. 도시된 실시예에서, 음성분석기는 캡쳐된 음성신호에 기초하여 운지 배열을 추정하므로 한계가 있다. 일 양상에따라, 음성분석기에서 출력된 운지 배열 중 특정한 프렛의 온셋 확률이 일정 이상인 것들을 대상으로 영상 분석기에서 출력된 지판 상의 손위치 정보를 기초로 특정한 줄의 운지를 결정할 수 있다. 이와 같은 과정 을 모든 줄에 대해 반복하여 운지 배열을 결정한 후 실제 연주에서의 운지의 어려움 내지 제한 조건을 고려하여 최종적인 태블렛 운지 배열을 결정할 수 있다. 또 다른 예로, 전술한 합성곱신경망을 채택한 음성분석기는 복수의 셋의 운지 배열과 그 확률을 출력할 수 있다. 이 경우 센서융합부는 영상분석기의 분석 결과로부터 음성분석기가 출력한 복수의 셋의 운지배열, 즉 태블랫 운지배열 후보들 중 하나를 태블랫 운지배열로 결정하여 출력할 수 있다. <청구항 8 이하 방법 발명의 설명> 도 3은 일 실시예에 따른 자동채보방법의 구성을 도시한 블록도이다. 일 실시예에 따른 자동채보방법은 기타 연주자의 연주 음성과 연주 영상을 정보처리요소에 의해 처리하여 태블랫 운지 배열 정보를 자동으로 생성한다. 도시된 바와 같이, 먼저 기타 연주자의 음성과 영상을 각각 동기화하여 캡쳐한 미디어 데이터에서 새로운 음성 프레임과 영상 프레임이 입력된다(단계 810). 도시된 바와 같이, 일 실시예에 따른 자동채보방법은 음성분석 단 계와, 영상분석 단계, 그리고 센서융합 단계를 포함한다. 음성분석 단계에서 정보처리요 소는 기타의 코드 연주를 캡쳐한 음성 신호로부터 다중음 피치(polyphonic pitch)와 운지 배열(fingering arrangement) 정보를 추정하여 출력한다. 추가적인 양상에 따라, 음성 분석 단계에서 정보처리요소는 심 층신경망회로(Deep Neural Network)를 통해 각 프렛에서의 손가락의 운지 여부 정보와 그 확률 정보를 계산하여 출력한다. 음성 분석 단계에서 정보처리요소의 구체적인 동작은 도 1 및 도 2의 음성분석기를 참조 하여 설명한 바와 유사하므로 상세한 설명은 생략한다. 영상분석 단계에서 정보처리요소는 코드 연주 장면을 캡쳐한 영상 신호를 입력 받아 지판의 형태와 손 형 태를 추정하고 그를 기초로 지판 상의 손 위치를 추정하여 출력한다. 추가적인 양상에 따라, 영상분석 단계 는 골격추정 단계와, 지판탐지 단계와, 손가락위치추정 단계를 포함할 수 있다. 골격추정 단계에서 정보처리요소는 코드 연주 장면을 캡쳐한 영상 신호를 입력 받아 손의 골격(skeleton)을 추정한 다. 일 양상에 따라, 골격추정 단계에서 정보처리요소는 심층신경망을 통해 손가락 골격의 관절점별 좌표 를 출력할 수 있다. 지판탐지 단계에서 정보처리요소는 코드 연주 장면을 캡쳐한 영상 신호를 입력 받아 지판을 탐지한다. 일 양상에 따라, 지판탐지 단계는 전이학습된 심층신경망으로 구현될 수 있다. 손가락 위치추정 단계에서 정보처리요소는 지판탐지 단계의 출력과 골격추정 단계의 출력으로부터 손의 지판 상의 위치를 계산하여 출력한다. 이러한 영상분석 단계에서 정보처리요소의 구체적인 동작은 도 1 및 도 2의 영상분석기를 참조하여 설명한 바와 유사하므로 상세한 설명은 생략한다. 센서융합 단계에서 정보처리요소는 음성분석 단계와 영상분석 단계의 출력들로부터 태블랫 운지 배열(tablature fingering arrangement) 정보를 출력한다. 추가적인 양상에 따라, 센서융합 단계에서 정 보처리요소는 음성분석 단계에서 출력된 운지 배열 후보들에서 영상분석 단계에서 출력된 지판 상의 손위치 정보를 기반으로 태블랫 운지 배열을 결정하여 출력할 수 있다. 이러한 센서융합 단계에서 정보처 리요소의 구체적인 동작은 도 1 및 도 2의 센서융합부를 참조하여 설명한 바와 유사하므로 상세한 설명은 생략한다. 추가적인 양상에 따라, 일 실시예에 따른 자동채보방법은 실행제어단계를 더 포함할 수 있다. 실행제어단 계에서 정보처리요소는 음성분석 단계에서 출력한 각 프렛에서의 손가락의 운지 여부 정보와 그 확률 정보로부터 운지 여부가 모호할 경우 영상분석 단계를 실행할 수 있다. 도시된 실시예에서, 정보처리요소는 심 층신경망의 출력에서 확률이 기준치 이하인 운지배열이 있는지 체크하여 영상 분석 단계를 실행하여 운지 배열 추정의 모호성을 제거하도록 시도할 수 있다. 이러한 실행제어단계에서 정보처리요소의 구체적인 동 작은 도 1 및 도 2의 실행제어기를 참조하여 설명한 바와 유사하므로 상세한 설명은 생략한다. 이상에서 본 발명을 첨부된 도면을 참조하는 실시예들을 통해 설명하였지만 이에 한정되는 것은 아니며, 이들로 부터 당업자라면 자명하게 도출할 수 있는 다양한 변형예들을 포괄하도록 해석되어야 한다. 특허청구범위는 이 러한 변형예들을 포괄하도록 의도되었다."}
{"patent_id": "10-2022-0190572", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 자동채보장치의 구성을 도시한 블록도이다. 도 2는 또 다른 실시예에 따른 자동채보장치의 구성을 도시한 블록도이다. 도 3은 일 실시예에 따른 자동채보방법의 구성을 도시한 블록도이다."}
