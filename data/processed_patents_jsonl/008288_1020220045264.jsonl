{"patent_id": "10-2022-0045264", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0069784", "출원번호": "10-2022-0045264", "발명의 명칭": "객체 포즈 및 모델을 추정하는 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "오바울"}}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "입력 이미지의 글로벌 특징 및 템플릿 모델에서의 객체의 위치 코드를 획득하는 단계, 상기 위치 코드는 객체의관절 포인트에 대한 위치 정보와 모델 정점에 대한 위치 정보를 포함함;상기 입력 이미지의 글로벌 특징과 상기 템플릿 모델에서의 상기 객체의 위치 코드에 기반하여 상기 객체의 로컬 영역 특징을 결정하는 단계; 및상기 객체의 로컬 영역 특징에 기반하여 상기 입력 이미지에서의 상기 객체의 관절 포인트에 대한 위치 정보 및상기 입력 이미지에서의 모델 정점에 대한 위치 정보를 결정하는 단계;를 포함하는, 객체 포즈 및 모델 추정 방법."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 입력 이미지의 글로벌 특징과 상기 템플릿 모델에서의 객체의 위치 코드에 기반하여 상기 객체의 로컬 영역 특징을 결정하는 단계는:상기 객체의 로컬 영역에 기반하여 글로벌 특징을 서로 교차하지 않는 다수 개의 하위 특징으로 분할하는 단계;및상기 다수 개의 하위 특징과 상기 템플릿 모델에서의 상기 객체의 위치 코드에 기반하여 상기 객체의 로컬 영역특징을 결정하는 단계;를 포함하는, 객체 포즈 및 모델 추정 방법."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 로컬 영역 특징은 상기 로컬 영역의 관절 포인트 및 상기 모델 정점의 특징 표시를 포함하는, 객체 포즈및 모델 추정 방법."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 다수 개의 하위 특징과 상기 템플릿 모델에서의 객체의 위치 코드에 기반하여 상기 객체의 로컬 영역 특징을 결정하는 단계는:상기 다수 개의 하위 특징 중 각각의 하위 특징을 대응되는 상기 로컬 영역 내의 관절 포인트와 상기 모델 정점의 좌표와 연결하여, 상기 객체의 로컬 영역 특징을 획득하는 단계를 포함하는, 객체 포즈 및 모델 추정 방법."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 객체의 로컬 영역 특징에 기반하여 상기 입력 이미지에서의 상기 객체의 관절 포인트에 대한 위치 정보와상기 입력 이미지에서의 상기 모델 정점에 대한 위치 정보를 결정하는 단계는:상기 객체의 로컬 영역 사이의 위치 관계에 기반하여 상기 로컬 영역 특징을 그룹화하는 단계; 및그룹화 결과에 기반하여 인코딩을 실시함으로써 상기 입력 이미지에서의 객체의 관절 포인트에 대한 위치 정보및 상기 입력 이미지에서의 모델 정점에 대한 위치 정보를 결정하는 단계;를 포함하는, 객체 포즈 및 모델 추정방법."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2023-0069784-3-제5항에 있어서, 상기 객체의 로컬 영역 사이의 위치 관계에 기반하여 로컬 영역 특징을 그룹화하는 단계는:제1 트랜스포머 네트워크를 통하여 각 로컬 영역 특징을 인코딩하는 단계; 및상기 객체의 로컬 영역 사이의 관계에 기반하여, 인코딩된 로컬 영역 특징을 그룹화하여 다수 개 그룹의 특징을획득하는 단계;를 포함하는, 객체 포즈 및 모델 추정 방법."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 객체의 로컬 영역 사이의 위치 관계에 기반하여, 인코딩된 로컬 영역 특징을 그룹화하는 단계는:상기 객체의 로컬 영역 간의 위치 관계에 기반한 소정의 그룹화 규칙에 따라, 인코딩된 로컬 영역 특징을 그룹화하거나 또는,상기 객체의 로컬 영역 간의 위치 관계에 기반한 그룹화 네트워크를 통하여, 인코딩된 로컬 영역 특징을 그룹화하는 단계;를 포함하는, 객체 포즈 및 모델 추정 방법."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서, 상기 그룹화 결과를 기반으로 인코딩을 실시하여 상기 입력 이미지에서의 객체의 관절 포인트에 대한 위치 정보와 상기 입력 이미지에서의 모델 정점에 대한 위치 정보를 획득하는 단계는:제2 트랜스포머 네트워크를 통하여 그룹화 결과물 중의 각 그룹 특징을 인코딩하는 단계; 및제3 트랜스포머 네트워크를 통하여, 인코딩된 다수 개 그룹의 특징을 인코딩하여, 상기 입력 이미지에서의 객체의 적어도 하나의 관절 포인트와 상기 입력 이미지에서의 적어도 하나의 모델 정점에 대한 위치 정보를 획득하는 단계;를 포함하는, 객체 포즈 및 모델 추정 방법."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 객체는 인체, 동물, 인체의 일부, 동물의 일부 중 적어도 하나를 포함하는, 객체의 포즈 및 모델 추정 방법."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 인체의 일부는 인체의 손 부위를 포함하며, 로컬 영역은 손바닥, 엄지손가락, 집게손가락, 가운뎃손가락,약손가락, 새끼손가락 중 적어도 하나를 포함하는, 객체의 포즈 및 모델 추정 방법."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "입력 이미지의 글로벌 특징, 템플릿 모델에서의 객체의 위치 코드를 획득하도록 구성되는 데이터 획득 유닛, 상기 위치 코드는 객체의 관절 포인트에 대한 위치 정보와 모델 정점에 대한 위치 정보를 포함함;상기 입력 이미지의 글로벌 특징, 상기 템플릿 모델에서의 객체의 위치 코드에 기반하여 객체의 로컬 영역 특징을 결정하도록 구성되는 특징 구성 유닛; 및상기 객체의 로컬 영역 특징에 기반하여 상기 입력 이미지에서 객체의 관절 포인트에 대한 위치 정보 및 상기입력 이미지에서 모델 정점의 위치 정보를 획득하도록 구성되는 추정 유닛;을 포함하는, 객체 포즈 및 모델 추정 장치."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 공개특허 10-2023-0069784-4-상기 특징 구성 유닛은:상기 객체의 로컬 영역에 기반하여 글로벌 특징을 서로 교차하지 않는 다수 개의 하위 특징으로 분할하고,상기 다수 개의 하위 특징과 템플릿 모델에서의 상기 객체의 위치 코드에 기반하여 객체의 로컬 영역 특징을 구성하도록 구성되는, 객체 포즈 및 모델 추정 장치."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 로컬 영역 특징은 상기 로컬 영역에서의 관절 포인트 및 상기 모델 정점의 특징 표시를 포함하는, 객체 포즈 및 모델 추정 장치."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 특징 구성 유닛은:상기 다수 개의 하위 특징 중 각각의 하위 특징을 대응되는 상기 로컬 영역 내의 관절 포인트와 상기 모델 정점의 좌표와 연결하여, 상기 객체의 로컬 영역 특징을 획득하도록 구성되는, 객체 포즈 및 모델 추정 장치."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서, 상기 추정 유닛은:상기 객체의 로컬 영역 사이의 위치 관계에 기반하여 상기 로컬 영역 특징을 그룹화하고,그룹화 결과에 기반하여 인코딩을 실시함으로써 상기 입력 이미지에서의 상기 객체의 관절 포인트에 대한 위치정보 및 상기 입력 이미지에서의 상기 모델 정점에 대한 위치 정보를 결정하도록 구성되는, 객체 포즈 및 모델추정 장치."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 추정 유닛은:제1 트랜스포머 네트워크를 통하여 각 로컬 영역 특징을 인코딩하고,상기 객체의 로컬 영역 사이의 관계에 기반하여, 인코딩된 로컬 영역 특징을 그룹화하여 다수 개 그룹의 특징을획득하도록 구성되는, 객체 포즈 및 모델 추정 장치."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서, 상기 추정 유닛은:상기 객체의 로컬 영역 사이의 위치 관계에 기반한 소정의 그룹화 규칙에 따라, 인코딩된 로컬 영역 특징을 그룹화하거나 또는,상기 객체의 로컬 영역 사이의 위치 관계에 기반한 그룹화 네트워크를 통하여, 인코딩된 로컬 영역 특징을 그룹화하도록 구성되는, 객체 포즈 및 모델 추정 장치."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서, 상기 추정 유닛은:제2 트랜스포머 네트워크를 통하여 그룹화 결과물 중의 각 그룹 특징을 인코딩하고,공개특허 10-2023-0069784-5-제3 트랜스포머 네트워크를 통하여, 인코딩된 다수 개 그룹의 특징을 인코딩하여, 상기 입력 이미지에서의 상기객체의 적어도 하나의 관절 포인트와 적어도 하나의 모델 정점에 대한 위치 정보를 획득하도록 구성되는, 객체포즈 및 모델 추정 장치."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서, 상기 객체는 인체, 동물, 인체의 일부, 동물의 일부 중 적어도 하나를 포함하는, 객체 포즈 및 모델 추정 장치."}
{"patent_id": "10-2022-0045264", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 인체의 일부는 인체의 손 부위를 포함하며, 로컬 영역은 손바닥, 엄지손가락, 집게손가락, 가운뎃손가락,약손가락, 새끼손가락 중 적어도 하나를 포함하는, 객체 포즈 및 모델 추정 장치."}
{"patent_id": "10-2022-0045264", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "객체 포즈 및 모델을 추정하는 방법 및 장치가 제공된다. 상기 객체 포즈 및 모델을 추정하는 방법은: 입력 이미 지의 글로벌 특징, 템플릿 모델 내의 객체의 관절 포인트에 대한 위치 정보와 모델 정점에 대한 위치 정보를 포 함하는 객체의 위치 코드를 획득하는 단계; 입력 이미지의 글로벌 특징, 템플릿 모델에서의 객체의 위치 코드를 기반으로 하여 객체의 로컬 영역 특징을 결정하는 단계; 객체의 로컬 영역 특징을 기반으로 하여 입력 이미지 내 의 객체의 관절 포인트에 대한 위치 정보와 입력 이미지 내의 모델 정점에 대한 위치 정보를 획득하는 단계를 포 함하여, 추정되는 객체 포즈 및 모델의 정확도를 향상시킨다. 또한, 인공지능 모델을 사용하여, 전자 장치에 의 해 실행되는 상기 객체 포즈 및 모델 추정 방법을 실행할 수 있다."}
{"patent_id": "10-2022-0045264", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 컴퓨터 시각 기술 분야에 관한 것으로, 보다 구체적으로는 객체 포즈 및 모델을 추정하는 방법 및 장 치에 관한 것이다."}
{"patent_id": "10-2022-0045264", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재, 사람 손의 포즈 및 모델 추정과 관련된 기술은 주로 공유되는 글로벌 특징 및 데이터 구동 방식에 의하여 손 부위 관절 포인트와 모델의 정점 또는 정점과 정점 사이의 연결을 학습하는 것이다. 관련 기술에서, 글로벌 특징은 손 부위의 모든 영역을 설명하나, 글로벌 특징으로 관절 포인트 및 모델 정점과 같은 손 부위의 일부 위치를 설명하는 것은 적절하지 않은데, 이는 주로 상기 글로벌 특징이 위치 정보를 포함 하지 않아 특징 정보에 대한 부분적 식별력을 가지지 않기 때문이다."}
{"patent_id": "10-2022-0045264", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 실시예는 추정되는 객체의 포즈 및 모델의 정확도를 향상시키기 위하여 객체 포즈 및 모델 추정을 위 한 방법 및 장치를 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2022-0045264", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 예시적 실시예에 따르면, 입력 이미지의 글로벌 특징, 템플릿 모델에서 객체의 관절 포인트와 모델 정점의 좌표를 포함하는 객체의 위치 코드를 획득하는 단계; 입력 이미지의 글로벌 특징과 템플릿 모델에서의 객체의 위치 코드에 기반하여 객체의 로컬 특징을 결정하는 단계; 객체의 로컬 영역 특징에 기반하여 입력 이미 지에서 객체의 관절 포인트에 대한 위치 정보 및 입력 이미지에서 모델 정점에 대한 위치 정보를 획득하는 단계 를 포함하는, 객체 포즈 및 모델 추정 방법이 제공된다. 선택적으로, 입력 이미지의 글로벌 특징, 템플릿 모델에서의 객체의 위치 코드에 기반하여 객체의 로컬 영역을 결정하는 단계는; 객체의 로컬 영역에 기반하여 글로벌 특징을 서로 교차하지 않는 다수 개의 하위 특징으로 분 할하는 단계; 상기 다수 개의 하위 특징과 템플릿 모델에서의 객체의 위치 코드에 기반하여 객체의 로컬 영역 특징을 결정하는 단계를 포함할 수 있다. 선택적으로, 로컬 영역 특징은 로컬 영역 내의 관절 포인트와 모델 정점의 특징 표시를 포함한다. 선택적으로, 상기 다수 개의 하위 특징과 템플릿 모델에서의 객체의 위치 코드에 기반하여 객체의 로컬 영역 특 징을 결정하는 단계는, 상기 다수 개의 하위 특징 중 각각의 하위 특징을 이에 대응되는 로컬 영역 내의 관절 포인트 및 모델 정점의 좌표와 연결하여 객체의 로컬 영역 특징을 획득하는 단계를 포함할 수 있다. 선택적으로, 객체의 로컬 영역 특징을 기반으로 입력 이미지에서의 객체의 관절 포인트에 대한 위치 정보와 입 력 이미지에서의 모델 정점에 대한 위치 정보를 결정하는 단계는: 객체의 로컬 영역 사이의 위치 관계를 기반으 로 로컬 영역 특징을 그룹화하는 단계; 그룹화 결과를 기반으로 인코딩을 실시하여 입력 이미지에서의 객체의 관절 포인트에 대한 위치 정보 및 입력 이미지에서의 모델 정점에 대한 위치 정보를 획득하는 단계;를 포함할 수 있다. 선택적으로, 객체의 로컬 영역 사이의 위치 관계를 기반으로 로컬 영역 특징을 그룹화하는 단계는: 제1 트랜스 포머 네트워크를 사용하여 각각의 로컬 영역을 인코딩하는 단계; 객체의 로컬 영역 사이의 위치 관계를 기반으 로, 인코딩된 로컬 영역 특징을 그룹화함으로써 다수 개 그룹의 특징을 획득하는 단계;를 포함할 수 있다. 선택적으로, 객체의 로컬 영역 사이의 위치 관계를 기반으로, 인코딩된 로컬 영역 특징을 그룹화하는 단계는: 객체의 로컬 영역 사이의 위치 관계를 기반으로 하는 소정의 그룹화 규칙에 따라 인코딩된 로컬 영역 특징을 그 룹화하거나, 또는 객체의 로컬 영역 사이의 위치 관계를 기반으로 한 그룹화 네트워크를 통하여, 인코딩된 로컬 영역 특징을 그룹화할 수 있다. 선택적으로, 그룹화 결과를 기반으로 인코딩을 진행하여 입력 이미지 내의 관절 포인트의 위치 정보와 입력 이 미지 내의 모델 정점의 위치 정보를 결정하는 단계는: 제2 트랜스포머 네트워크를 통하여 그룹화 결과의 각 그 룹 특징을 인코딩하는 단계; 제3 트랜스포머 네트워크를 통하여, 인코딩된 다수 개 그룹의 특징을 인코딩함으로 써, 입력 이미지에서 객체의 적어도 하나의 관절 포인트 및 적어도 하나의 모델 정점에 대한 위치 정보를 획득 하는 단계;를 포함할 수 있다. 일 실시예에서, 객체는 인체, 동물, 인체의 일부, 동물의 일부 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 인체의 일부는 인체의 손 부위를 포함하며, 객체가 인체의 손 부위일 경우, 로컬 영역은 손바닥, 엄지손가락, 집게손가락, 가운뎃손가락, 약손가락, 새끼손가락 중 적어도 하나를 포함한다. 본 개시의 예시적 실시예에 따르면, 객체의 위치 코드를 획득하도록 구성되는 데이터 획득 유닛, 상기 위치 코 드는 입력 이미지의 로컬 특징, 템플릿 모델에서의 객체의 관절 포인트에 대한 위치 정보와 모델 정점에 대한 위치 정보를 포함함; 입력 데이터의 로컬 특징과 템플릿 모델에서의 객체의 위치 코드를 기반으로 객체의 로컬 영역을 결정하도록 구성되는 특징 구성 유닛; 및 객체의 로컬 영역 특징을 기반으로 입력 이미지에서의 객체의 관절 포인트에 대한 위치 정보 및 입력 이미지에서의 모델 정점에 대한 위치 정보를 결정하도록 구성되는 추정 유닛;을 포함하는 객체 포즈 및 모델 추정 장치가 제공된다. 일 실시예에서, 특징 구성 유닛은 객체의 로컬 영역을 기반으로 글로벌 특징을 서로 교차하지 않는 다수 개의 하위 특징으로 분할하고, 상기 다수 개의 하위 특징, 템플릿 모델에서의 객체의 위치 코드에 기반하여 객체의 로컬 영역 특징을 구성하도록 구성될 수 있다. 선택적으로, 로컬 영역 특징은 로컬 영역 내의 관절 포인트와 모델 정점의 특징 표시를 포함한다. 선택적으로, 특징 구성 유닛은 상기 다수 개의 하위 특징 중 각각의 하위 특징을 대응되는 로컬 영역의 관절 포 인트 및 모델 정점의 좌표와 연결하여 객체의 로컬 영역 특징을 획득하도록 구성될 수 있다. 일 실시예에서, 추정 유닛은 객체의 로컬 영역 사이의 위치 관계를 기반으로 로컬 영역 특징을 그룹화하고, 그 룹화 결과를 기반으로 인코딩을 실시하여 입력 이미지에서의 객체의 관절 포인트에 대한 위치 정보 및 입력 이 미지 내의 모델 정점에 대한 위치 정보를 결정하도록 구성될 수 있다. 일 실시예에서, 추정 유닛은 제1 트랜스포머 네트워크를 통해 각각의 로컬 영역 특징을 인코딩하고, 객체의 로 컬 영역 사이의 위치 관계를 기반으로 인코딩된 로컬 영역 특징을 그룹화하여 여러 개 그룹의 특징을 획득하도 록 구성될 수 있다. 일 실시예에서, 추정 유닛은 객체의 로컬 영역 사이의 위치 관계를 기반으로 한 소정의 그룹화 규칙에 따라, 인 코딩된 로컬 영역 특징을 그룹화하거나, 또는 객체의 로컬 영역 사이의 위치 관계를 기반으로 한 그룹화 네트워 크에 따라, 인코딩된 로컬 영역 특징을 그룹화하도록 구성될 수 있다. 일 실시예에서, 추정 유닛은: 제2 트랜스포머 네트워크를 통하여 그룹화 결과의 각 그룹의 특징을 인코딩하고, 제3 트랜스포머 네트워크를 통하여, 인코딩된 다수 개 그룹의 특징을 인코딩하여 입력 이미지에서의 적어도 하 나의 관절 포인트와 적어도 하나의 모델 정점에 대한 위치 정보를 획득하도록 구성될 수 있다. 일 실시예에서, 객체는 인체, 동물, 인체의 일부, 동물의 일부 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 인체의 일부는 인체의 손 부위를 포함하며, 객체가 인체의 손 부위일 경우, 로컬 영역은 손바닥, 엄지손가락, 집게손가락, 가운뎃손가락, 약손가락, 새끼손가락 중 적어도 하나를 포함한다. 본 개시의 예시적 실시예에 따르면, 실행되었을 때 본 개시의 예시적 실시예에 따른 객체 포즈 및 모델 추정 방 법을 구현할 수 있는 컴퓨터 프로그램이 저장된 컴퓨터 판독 가능 저장 매체가 제공된다. 본 개시의 예시적 실시예에 따르면, 적어도 하나의 프로세서; 상기 적어도 하나의 프로세서에 의하여 실행되었 을 때 본 개시의 예시적 실시예에 따른 객체 포즈 및 모델 추정 방법을 구현할 수 있는 컴퓨터 프로그램이 저장 된 적어도 하나의 메모리;를 포함하는 컴퓨터 장치가 제공된다. 본 개시의 예시적 실시예에 따르면, 컴퓨터 장치의 프로세서에 의해 실행되어 본 개시의 예시적 실시예에 따른 객체 포즈 및 모델 추정 방법을 완성할 수 있는 명령어를 포함하는 컴퓨터 프로그램 제품이 제공된다. 본 개시의 예시적 실시예에 따른 객체의 포즈 및 모델 추정 방법 및 장치에서, 먼저 입력 이미지의 글로벌 특징, 템플릿 모델에서 객체의 관절 포인트와 모델 정점의 위치 정보를 포함하는 객체의 위치 코드를 획득하고, 입력 이미지의 글로벌 특징과 템플릿 모델에서의 객체의 위치 코드에 기반하여 객체의 로컬 특징을 결정한 다음, 객체의 로컬 특징에 기반하여 입력 이미지에서의 객체의 관절 포인트에 대한 위치 정보 및 입력 이미지에 서의 모델 정점에 대한 위치 정보를 획득함으로써 객체의 포즈 및 모델 추정에 있어서의 정확도를 향상시킨다. 후술되는 설명을 통하여 본 개시의 전체적인 사상과 그 밖의 측면 및/또는 이점이 부분적으로 설명될 것인 바, 일부는 설명에 의하여 자명해질 수 있고, 또는 본 개시의 전체적 구상에 대한 실행을 통하여 알려질 것이다."}
{"patent_id": "10-2022-0045264", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면에 도시된 본 개시의 실시예를 참조하며, 동일한 표시부호는 시종 동일한 구성요소를 나타낸다. 이하, 본 개시의 설명상 편의를 위하여, 도면을 참조하여 본 개시를 설명한다. 본 개시는 객체의 상이한 영역을 상이한 특징으로 인코딩하고, 글로벌 특징을 연속적인 서브 벡터로 분할하고 이를 손의 로컬 위치와 대응시키는 방법을 제시한다. 채널 방향을 따라 서브 벡터와 위치 코드를 연결하여 각 관절 포인트와 모델 정점의 특징 표시를 획득한다. 손의 각 로컬에 대한 표시를 각각 제1 레이어 상의 6개의 상 이한 트랜스포머(transformer) 네트워크로 전송하여 취합된 특징을 획득한다. 또한, 손 부위 영역 사이의 연결 관계를 강화하기 위하여, 본 개시에서는 데이터 구동을 기반으로 하는 그룹화 방법을 제시하였다. 이 새로운 그 룹화 방법에 기반하여, 취합된 특징을 각각 제2 레이어 트랜스포머(transformer) 네트워크에 입력하여 각 관절포인트와 모델 정점의 특징을 획득하고, 마지막으로 이 모든 특징을 최종 트랜스포머(transformer) 네트워크에 전송하여 적어도 하나의 관절 포인트와 적어도 하나의 모델 정점의 3D 좌표를 획득한다. 도 1은 본 개시의 예시적 실시예에 따른, 객체 포즈 및 모델 추정 방법을 나타낸 흐름도이다. 도 2는 본 개시의 예시적 실시예에 따른, 손 포즈 및 모델 추정 방법을 나타낸 흐름도이다. 도 3은 전체 구역 특징과 손 부분 구 역의 대응 관계를 나타내는 도면이다. 도 4a는 본 개시의 예시적 실시예에 따른, 로컬 영역 특징을 그룹화하는 네트워크의 개략도이다. 도 4b는 본 개시의 예시적 실시예에 따른, 학습 가능한 그룹화의 시각화 과정을 도시한 도면이다. 도 1을 참조하면, 단계 S101에서, 입력 이미지의 글로벌 특징(또는 '전역 특징') 및 템플릿 모델에서의 객체의 위치 코드를 획득한다. 여기서, 위치 코드는 객체의 관절 포인트의 위치 정보 및 모델 정점의 위치 정보를 포함 한다(예컨대, 위치 정보는 3차원 좌표를 포함할 수 있다). 입력 이미지는 단안 컬러 센서를 사용하여 획득한 이 미지일 수 있으며, 템플릿 모델은 예컨대 기존의 파라미터화 모형, 예를 들어, 관절 및 비강성 변형이 있는 손 모델(hand Model with Articulated and Non-rigid deformations, 간략히 MANO라 칭함)에 의하여 포즈가 0이며 형상이 0인 시각에 획득되는 것일 수 있다. 본 개시의 예시적 실시예에서, 객체는 인체, 동물, 인체의 일부, 동물의 일부 중 적어도 하나를 포함할 수 있다. 예컨대, 객체는 손일 수 있다. 객체가 손일 때, 템플릿 모델은 손의 템플릿 모델이다. 본 개시의 예시적 실시예에서는 손을 예로 들어 설명할 것이지만, 본 개시는 이에 제한되지 아니한다. 본 개시의 예시적 실시예에서, 인체의 일부는 인체의 손 부위를 포함하며, 객체가 인체의 손 부위일 경우, 로컬 영역은 손바닥, 엄지손가락, 집게손가락, 가운뎃손가락, 약손가락 및 새끼손가락 중 적어도 하나를 포함한다. 본 개시의 예시적 실시예에서, 입력 이미지의 글로벌 특징, 템플릿 모델에서의 객체의 위치 코드를 획득할 때, 먼저 입력 이미지와 객체의 템플릿 모델을 획득한 다음 입력 이미지의 글로벌 특징을 추출하고 객체의 템플릿 모델에 기반하여 템플릿 모델에서의 객체의 위치 코드를 결정할 수 있다. 예컨대, 컨볼루션 뉴럴 네트워크 (Convolutional Neural Network, 간략히 CNN으로 칭함)을 통하여 입력 이미지의 글로벌 특징을 추출하거나 백본 네트워크를 통하여 입력 이미지의 글로벌 특징을 추출할 수 있다. 예컨대, 도 2에 도시된 바와 같이, 객체의 포즈 및 모델을 추정할 때, 입력되는 것은 단안 컬러 이미지와 손의 템플릿 모델로서, 이는 각각 입력된 단안 컬러 이미지와 손의 템플릿 모델로부터 획득된 입력 이미지의 글로벌 특징(CNN을 통하여 추출될 수 있음), 및 템플릿 모델에서의 손의 위치 코드가 학습 가능한 그룹화에 기반한 계 층적 트랜스포머 네트워크에 입력된 것일 수 있다. 도 2에서, 학습 가능한 그룹화에 기반한 계층적 트랜스포머 네트워크는 주로 두 개의 부분을 포함하는데, 이 중 제1 부분은 손의 로컬 영역 특징을 구성하기 위한 모듈을 포함하고, 제2 부분은 학습 가능한 그룹화 네트워크를 포함한다. 도 2의 트랜스포머 네트워크의 각 레이어는 마 스크 네트워크 모델을 포함하여 객체의 가려진 부분의 포즈 및 모델을 추정할 수 있다. 단계 S102에서, 입력 이미지의 글로벌 특징, 템플릿 모델에서의 객체의 위치 코드에 기반하여 객체의 로컬 영역 특징을 결정할 수 있다. 예컨대, 도 2에 도시된 바와 같이, 손의 로컬 영역에 대하여 각각 상이한 특징을 구성 할 수 있다. 관련 기술에서, 모든 손 부위 관절 포인트와 모형의 정점을 트랜스포머 네트워크에 입력할 때, 데이터 구동 방 식으로 정점과 관절 포인트 또는 정점 및 정점 사이의 연결을 학습할 뿐, 손가락의 완전성과 같은 손의 기하학 적 구조는 고려되지 않는다. 본 개시의 예시적 실시예에서, 로컬 영역 특징은 로컬 영역 내의 관절 포인트 및 모델 정점의 특징 표시를 포함 할 수 있다. 본 개시의 예시적 실시예에서, 입력 이미지의 글로벌 특징, 템플릿 모델에서의 객체의 위치 코드에 기반하여 객 체의 로컬 영역 특징을 결정할 때, 먼저 객체의 로컬 영역에 기반하여 글로벌 특징을 서로 교차하지 않는 다수 개의 하위 특징으로 분할한 후 상기 다수 개의 하위 특징과 템플릿 모델에서의 객체의 위치 코드에 기반하여 객 체의 로컬 영역 특징을 결정할 수 있다. 예컨대, 객체가 손일 경우, 로컬 영역은 손바닥, 엄지손가락, 집게손가 락, 가운뎃손가락, 약손가락, 새끼손가락 등을 포함할 수 있다. 본 개시의 예시적 실시예에서, 상기 다수 개의 하위 특징과 템플릿 모델에서의 객체의 위치 코드에 기반하여 객 체의 로컬 영역 특징을 결정할 때, 상기 다수 개의 하위 특징 중 각각의 하위 특징을 대응되는 로컬 영역 내의 관절 포인트 및 모델 정점의 좌표와 연결하여 객체의 로컬 영역 특징을 획득할 수 있다.예컨대, 도 3에 도시된 바와 같이, 상기 다수 개의 하위 특징 중 각각의 하위 특징은 각각 손바닥, 엄지손가락, 집게손가락, 가운뎃손가락, 약손가락, 새끼손가락과 대응된다. 손의 기하학적 구조에 따라 손을 6개의 서로 교 차하지 않는 부분, 즉 손바닥, 엄지손가락, 집게손가락, 가운뎃손가락, 약손가락, 새끼손가락 분할할 수 있다. 손의 글로벌 특징으로도 손의 로컬 부위를 설명할 수 있도록, 글로벌 특징 또한 서로 교차하지 않는 6개 부분의 하위 특징으로 분할하며, 각 부분의 특징은 손의 로컬 영역과 대응된다. 또한, 템플릿 모델 상의 각 관절 포인 트와 모델 정점의 위치 코드를 사용하여, 하위 특징과 위치 코드를 채널 방향을 따라 연결한다. 이와 같이, 손 부위의 하위 영역에서 각 관절 포인트와 모델 정점의 특징과 위치에 대한 설명을 획득한다. 이로써, 하위 영역 에 포함된 관절 포인트와 모델 정점의 개수가 상이할 수 있으며, 이는 기하학적 위치에 의하여 결정되는 것임을 알 수 있다. 예컨대, 손의 각 부분은 각자 56개, 32개, 35개, 35개, 31개, 27개의 관절 포인트 및 모델 정점을 포함할 수 있 다. 각 점은 344차원의 특징 벡터 표시를 가지며, 앞선 341차원은 의미 특징이고, 이후의 3차원은 위치 코드이 다. 각 부분의 벡터는 트랜스포머 네트워크 구조에 입력되며, 이 때 트랜스포머 네트워크 구조는 가중치를 공유 하지 않는다. 인체 구조의 경우에도, 초기에 머리, 왼팔, 오른팔, 흉부, 왼쪽 다리 및 오른쪽 다리의 6개 부분 으로 분할된다. 예컨대, 인체의 템플릿으로는 기존의 파라미터화 인체 모델을 사용할 수 있다. 단계 S103에서, 객체의 로컬 영역 특징에 기반하여 입력 이미지에서의 객체의 관절 포인트의 위치 정보 및 입력 이미지에서의 모델 정점의 위치 정보를 획득한다. 본 개시의 예시적 실시예에서, 객체의 로컬 영역 특징에 기반하여 객체의 포즈 및 모델을 결정할 때, 먼저 객체 의 로컬 영역 사이의 위치 관계에 기반하여 로컬 영역 특징을 그룹화한 다음 그룹화 결과에 기반하여 코딩을 실 시함으로써 입력 이미지에서의 객체의 관절 포인트의 위치 정보 및 입력 이미지에서의 모델 정점의 위치 정보를 결정할 수 있다. 본 개시의 예시적 실시예에서, 객체의 로컬 영역 사이의 위치 관계에 기반하여 로컬 영역 특징을 그룹화할 때, 먼저 제1 트랜스포머 네트워크를 사용하여 각각의 로컬 영역 특징을 인코딩한 후, 객체의 로컬 영역 사이의 위 치 관계에 기반하여 코딩된 로컬 영역 특징을 그룹화함으로써 다수 그룹의 특징을 획득할 수 있다. 본 개시의 예시적 실시예에서, 객체의 로컬 영역 사이의 위치 관계에 기반하여 코딩된 로컬 영역 특징을 그룹화 할 때, 객체의 로컬 영역 사이의 위치 관계에 기반한 소정의 그룹화 규칙에 따라 인코딩된 로컬 영역 특징을 그 룹화하거나, 또는 객체의 로컬 영역 사이의 위치 관계에 기반한 그룹화 네트워크를 통하여, 인코딩된 로컬 영역 특징을 그룹화할 수 있다. 본 개시의 예시적 실시예에서, 그룹화 결과에 따라 인코딩을 진행하여 입력 이미지에서의 객체의 관절 포인트의 위치 정보와 입력 이미지에서의 모델 정점의 위치 정보를 결정할 때, 먼저 제2 트랜스포머 네트워크를 통하여 그룹화 결과의 각 그룹 특징을 인코딩하고, 제3 트랜스포머 네트워크를 통하여 인코딩된 다수 그룹의 특징을 인 코딩함으로써, 객체의 적어도 하나의 관절 포인트 및 입력 이미지에서의 적어도 하나의 모델 정점에 관한 위치 정보를 획득할 수 있다. 도 2에 도시된 바와 같이, 손의 로컬 영역에 대해 각각 구성한 상이한 특징을 각자 트랜스포머 네트워크 구조 (도 2의 제1 레이어 트랜스포머 네트워크 코드에 대응됨)에 입력하여 취합된 로컬 영역 특징을 획득한다. 로컬 영역 사이의 위치 관계를 강화하기 위하여, 도 2에 도시된 바와 같이 학습 가능한 그룹화 모듈을 구성하였으며, 학습된 그룹화 특징을 제2 레이어 트랜스포머 네트워크(도 2의 제2 레이어 트랜스포머 네트워크 코드에 대응 됨)에 입력하여 각 관절 포인트와 모델 정점의 특징들을 획득하였다. 마지막으로, 이 모든 특징들(또는 이 특징 들 중 적어도 하나)을 마지막 트랜스포머 네트워크(도 2의 제3 레이어 트랜스포머 네트워크 코드에 대응됨)에 전송하여 적어도 하나의 관절 포인트와 적어도 하나의 모델 정점에 대한 3D 좌표를 획득하였다. 예컨대, 도 2에 도시된 바와 같이, 학습 가능한 그룹화에 기반한 계층적 트랜스포머 네트워크의 출력은 손의 3D 포즈 및 모델이 다. 본 개시에서, 트랜스포머 네트워크는 transformer 네트워크일 수 있으나 이에 제한되지 아니한다. 또한, 객체의 로컬 영역 사이의 위치 관계에 기반하여 인코딩된 로컬 영역 특징을 그룹화할 때, 학습 가능한 그 룹화가 아닌 소정의 그룹화 규칙에 기반한 계층적 트랜스포머 네트워크를 사용할 수도 있다. 도 4a의 (a)는 그룹화되지 않은 계층적 트랜스포머 네트워크의 개략도이며, 도 4a의 (b)와 (c)는 소정의 그룹화 규칙에 기반한 계층적 트랜스포머 네트워크의 개략도이고, 도 4a의 (d)는 학습 가능한 그룹화에 기반한 계층적 트랜스포머 네트워크의 개략도이다. 도 4a의 (a)에 도시된 바와 같이, 적어도 하나의 관절 포인트와 모델 정점을 입력으로 하여 세 개 레이어의 트 랜스포머 네트워크로 전송하여 3차원 좌표를 예측한다. 도 4a의 (b)에 도시된 바와 같이, 손바닥과 엄지손가락이 하나의 그룹이 되고, 검지손가락과 가운뎃손가락이 하 나의 그룹이 되며, 약손가락과 새끼손가락이 하나의 그룹이 된다. 도 4a의 (c)에 도시된 바와 같이, 손바닥과 엄지손가락이 하나의 그룹이 되고, 나머지 네 개의 손가락이 하나의 그룹이 된다. 마지막 하나의 도면은 학습에 기반한 병합 방법이다. 도 4a의 (d)에 도시된 바와 같이, 학습 가능한 그룹화 네트워크를 통해 그룹화를 실시한다. 예컨대, 이 제1 레이어 트랜스포머 네트워크 구조의 출력이며, Gi는 손의 i 번째 하 위 영역을 나타내는 것으로서, 상기 하위 영역 내의 모든 손 관절 포인트 및 모든 모델 정점을 포함하는 것으로 가정한다. 각각의 점은 모두 C차원의 특징 벡터로 표시된다. 학습 가능한 그룹화 모듈의 목표는 이 6개의 하위 영역을 K개 영역 , 즉 으로 병합하는 것이다. 여기서, K<6이다. 은 하나의 바이너리 선택기( )와 하위 영역( )으로 구성되며, 새로 구성된 하위 영역은 서로 교차할 수 없 다. 모든 는 를 구성하며, 새로운 하위 영역은 수학식 1 조건을 만족한다. 수학식 1"}
{"patent_id": "10-2022-0045264", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서 은 임의의 를 지칭할 수 있다. 바이너리 선택기는 수학식 2의 조건을 만족하여야 한다. 수학식 2"}
{"patent_id": "10-2022-0045264", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "바이너리 선택기가 미분을 실시할 수 있도록 하기 위해, 기존의 Gumbel-softmax 방법을 사용하여 를 다시 파 라미터화할 수 있다. 예컨대, 하기의 수학식 3 의하여 을 다시 파라미터화할 수 있다. 이와 같이 샘플링 결과 가 미분 가능하며, 네트워크 훈련 과정에서 기울기를 리턴시킬 수 있다. 수학식 3"}
{"patent_id": "10-2022-0045264", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 3에서 은 샘플링 변수를, 는 샘플링 결과를, 는 하이퍼 파라미터 온도를 나타낸다. 도 4b에 도시된 바와 같이, 6개의 하위 영역을 3개 그룹으로 나누고 임의로 6*3 행렬을 생성한다고 가정하면, 행렬 내의 각 요소의 초기값은 0.5이며, 이는 위 등식에서의 의 값에 해당된다. 다음으로, 1개의 변량인gij를 임의로 생성하는데, 이 변량은 Gumbel(0,1) 극단값 분포를 따르고, 하이퍼 파라미터 온도( )는 하나의 고 정값으로 정의되며, 은 0에 가깝고, 샘플링 결과는 이산 분포에 더 가까워지며, 가 클수록, 샘플링 결과는 평 균값 분포에 더 가까워진다. 여기서, Θ11 내지 Θ63은 하위 영역의 파라미터이다. 본 개시의 예시적 실시예에 따른 객체의 포즈 및 모델 추정 방법에서, 먼저 입력 이미지의 글로벌 특징, 템플릿 모델에서의 객체의 위치 코드를 획득하고, 입력 이미지의 글로벌 특징, 템플릿 모델에서의 객체의 위치 코드에 기반하여 객체의 로컬 영역 특징을 구성한 후, 객체의 로컬 영역 특징에 기반하여 객체의 포즈와 모델을 결정함 으로써, 추정되는 객체의 포즈 및 모델의 정확도를 향상시키고, 계산 파라미터를 감소시키며, 계산 비용을 절감 할 수 있다. 본 개시의 예시적 실시예에 따른 객체 포즈 및 모델 추정 방법은 증강 현실(Augmented Reality, 약칭 AR), 가상 현실(virtual reality, 약칭 VR), 객체 상호 작용 등에 사용될 수 있다. 또한, 본 개시의 예시적 실시예에 따르면, 실행되었을 때 본 개시의 예시적 실시예에 따른 객체의 포즈 및 모델 추정 방법을 구현할 수 있는 컴퓨터 프로그램이 저장된 컴퓨터 판독 가능 매체가 더 제공된다. 본 개시의 예시적 실시예에서, 상기 컴퓨터 판독 가능 매체에는 하나 또는 두 개의 프로그램이 탑재되며, 상기 컴퓨터 프로그램이 실행되었을 때 입력 이미지의 글로벌 특징, 템플릿 모델에서의 객체의 관절 포인트와 모델 정점의 좌표를 포함하는 객체의 위치 코드를 획득하는 단계, 입력 이미지의 글로벌 특징, 템플릿 모델에서의 객 체의 위치 코드에 기반하여 객체의 로컬 영역 특징을 구성하는 단계, 객체의 로컬 영역 특징에 기반하여 객체의 포즈 및 모델을 결정하는 단계가 구현될 수 있다. 컴퓨터 판독 가능 매체는 예컨대 전기, 자기, 광학, 전자기, 적외선, 또는 반도체 시스템, 장치 또는 소자, 또 는 이들의 임의의 조합일 수 있으나, 이에 제한되지 아니한다. 컴퓨터 판독 가능 매체의 보다 구체적인 예시로 는 하나 또는 다수의 도선을 가지는 전기 연결, 휴대용 컴퓨터 디스크, 하드디스크, 랜덤 액세스 메모리(RAM; random access memory), 읽기 전용 메모리(ROM; read-only memory, 소거 가능/프로그램 가능 읽기 전용 메모리 (EPROM; erasable programmable read-only memory 또는 플래시 메모리), 광섬유, 휴대용 콤팩트 디스크 읽기 전용 메모리(CD-ROM; compact disk-read-only memory), 광 메모리 소자, 자기 메모리 소자, 또는 전술한 내용 들의 임의의 적절한 조합을 포함할 수 있으나 이에 제한되지 아니한다. 본 개시의 실시예에서, 컴퓨터 판독 가 능 매체는 컴퓨터 프로그램을 포함 또는 저장하고 있는 임의의 유형의 매체일 수 있으며, 상기 컴퓨터 프로그램 은 명령 실행 시스템, 장치, 또는 소자에 의해 사용되거나 또는 이들과 결합되어 사용될 수 있다. 컴퓨터 판독 가능 저장 매체에 포함된 컴퓨터 프로그램을 전송할 수 있는 임의의 적당한 매체는 전선, 광 케이블, RF(주파수) 등, 또는 전술한 내용의 임의의 적합한 조합을 포함할 수 있으나 이에 제한되지 아니한다. 컴퓨터 판독 가능 저장 매체는 임의의 장치에 포함될 수도 있고, 상기 장치에 포함되지 않고 별도로 존재할 수도 있다. 또한, 본 개시의 예시적 실시예에 따르면, 본 개시의 예시적 실시예에 따른 객체 포즈 및 모델 추정 방법을 완 성하도록 실행될 수 있는 명령어를 포함하는 컴퓨터 프로그램 제품이 더 제공된다. 상기와 같이, 도 1 내지 도 4를 참조하여 본 개시의 예시적 실시예에 따른 객체 포즈 및 모델 추정 방법을 설명 하였다. 이하에서는, 도 5를 참조하여 본 개시의 예시적 실시예에 따른 객체 포즈 및 모델 추정 장치 및 이의 유닛에 대해 설명한다. 도 5는 본 개시의 예시적 실시예에 따른 객체 포즈 및 모델 추정 장치를 도시한 블록도이다. 도 5를 참조하면, 객체 포즈 및 모델 추정 장치는 데이터 획득 유닛, 특징 구성 유닛 및 추정 유닛(5 3)을 포함한다. 데이터 획득 유닛은 입력 이미지의 글로벌 특징과 템플릿 모델에서의 객체의 위치 코드를 획득하도록 구성 된다. 여기서, 위치 코드는 객체의 관절 포인트에 대한 위치 정보 및 모델 정점에 대한 위치 정보일 수 있다. 본 개시의 예시적 실시예에서, 객체는 인체, 동물, 인체의 일부, 동물의 일부 중 적어도 하나를 포함할 수 있다. 본 개시의 예시적 실시예에서, 인체의 일부는 인체의 손 부위를 포함하며, 객체가 인체의 손 부위일 경우, 로컬 영역은 손바닥, 엄지손가락, 집게손가락, 가운뎃손가락, 약손가락 및 새끼손가락 중 적어도 하나를 포함한다. 본 개시의 예시적 실시예에서, 데이터 획득 유닛은 입력 이미지와 객체의 템플릿 모델을 획득하고, 입력 이 미지의 글로벌 특징을 추출하고, 객체의 템플릿 모델에 기반하여 템플릿 모델에서의 객체의 위치 코드를 결정할 수 있다. 특징 구성 유닛은 입력 이미지의 글로벌 특징, 템플릿 모델에서의 객체의 위치 코드에 따라 객체의 로컬 영 역 특징을 결정하도록 구성된다. 본 개시의 예시적 실시예에서, 특징 구성 유닛은 객체의 로컬 영역에 기반하여 글로벌 특징을 서로 교차하 지 않는 다수 개의 하위 특징으로 분할하고, 상기 다수 개의 하위 특징, 템플릿 모델에서의 객체의 위치 코드에 기반하여 객체의 로컬 영역 특징을 구성하도록 구성될 수 있다. 본 개시의 예시적 실시예에서, 로컬 영역 특징은 로컬 영역 내의 관절 포인트 및 모델 정점의 특징 표시를 포함 할 수 있다. 본 개시의 예시적 실시예에서, 특징 구성 유닛은 상기 다수 개의 하위 특징 중 각각의 하위 특징과 대응되 는 로컬 영역의 관절 포인트와 모델 정점의 좌표를 연결하여 객체의 로컬 영역 특징을 획득하도록 구성될 수 있 다. 추정 유닛은 객체의 로컬 영역 특징에 기반하여 입력 이미지에서의 객체의 관절 포인트의 위치 정보 및 입 력 이미지에서의 모델 정점의 위치 정보를 획득하도록 구성된다. 본 개시의 예시적 실시예에서, 추정 유닛은 객체의 로컬 영역 사이의 위치 관계에 기반하여 로컬 영역 특징 을 그룹화하고, 그룹화 결과에 기반하여 인코딩을 실시하여 입력 이미지에서의 객체의 관절 포인트에 대한 위치 정보 및 입력 이미지에서의 모델 정점에 대한 위치 정보를 결정하도록 구성될 수 있다. 본 개시의 예시적 실시예에서, 추정 유닛은 제1 트랜스포머 네트워크를 통해 각각의 로컬 영역 특징을 인코 딩하고, 객체의 로컬 영역 사이의 위치 관계에 기반하여 인코딩된 로컬 영역 특징을 그룹화하여 여러 개 그룹의 특징을 획득하도록 구성될 수 있다. 본 개시의 예시적 실시예에서, 추정 유닛은 객체의 로컬 영역 사이의 위치 관계에 기반한 소정의 그룹화 규 칙에 따라, 인코딩된 로컬 영역 특징을 그룹화하거나, 또는 객체의 로컬 영역 사이의 위치 관계에 기반한 그룹 화 네트워크에 따라, 인코딩된 로컬 영역 특징을 그룹화하도록 구성될 수 있다. 본 개시의 예시적 실시예에서, 추정 유닛은 제2 트랜스포머 네트워크를 통하여 그룹화 결과의 각 그룹의 특 징을 인코딩하고, 제3 트랜스포머 네트워크를 통하여 인코딩된 다수 개 그룹의 특징을 인코딩하여 입력 이미지 에서의 적어도 하나의 관절 포인트와 적어도 하나의 모델 정점에 대한 위치 정보를 획득하도록 구성될 수 있다. 상기와 같이 도 5를 참조하여 본 개시의 예시적 실시예에 따른 객체의 포즈 및 모델 추정 장치를 설명하였다. 이어서, 도 6을 참조하여 본 개시의 예시적 실시예에 따른 컴퓨터 장치를 설명한다. 도 6은 본 개시의 예시적 실시예에 따른 컴퓨터 장치를 도시한 도면이다. 도 6을 참조하면, 본 개시의 예시적 실시예에 따른 컴퓨터 장치는 메모리와 프로세서를 포함하는데, 상기 메모리 상에는 프로세서에 의하여 실행되었을 때 본 개시의 예시적 실시예에 따른 객체 포즈 및 모델 추정 방법을 구현할 수 있는 컴퓨터 프로그램이 저장된다. 본 개시의 예시적 실시예에서, 상기 컴퓨터 프로그램이 프로세서에 의하여 실행될 때, 입력 이미지의 로컬 특징, 템플릿 모델에서의 객체의 관절 포인트와 모델 정점의 좌표를 포함하는 객체의 위치 코드를 획득하는 단 계, 입력 이미지의 로컬 특징과 템플릿 모델에서의 객체의 위치 코드에 기반하여 객체의 로컬 영역 특징을 구성 하는 단계 및 객체의 로컬 영역 특징에 기반하여 객체 포즈 및 모델을 결정하는 단계가 구현될 수 있다. 본 개시의 실시예에서, 컴퓨터 장치는 이동전화, 노트북 컴퓨터, 개인용 정보 단말기(PDA; personal digital assistants), 태블릿 컴퓨터(PAD), 데스크탑 컴퓨터, 웨어러블 전자 장치(예: AR glass) 등의 장치를 포함할 수 있으나 이에 제한되지 아니한다. 도 6에 도시된 컴퓨터 장치는 예시일 뿐이며, 본 개시의 실시예의 기능과 사용 범위에 어떠한 제한도 하지 아니한다. 상기와 같이, 도 1 내지 도 6을 참조하여 본 개시의 예시적 실시예에 따른 객체 포즈 및 모델 추정 방법 및 장 치를 설명하였다. 그러나, 도 4 내지 도 5에 도시된 객체 포즈 및 모델 추정 장치와 이의 유닛이 각각 특정 기 능을 가지는 소프트웨어, 하드웨어, 펌웨어 또는 상기 항목의 임의의 조합을 실행하도록 구성될 수 있으며, 도 6에 도시된 컴퓨터 장치가 상기에 나타낸 요소들을 포함하도록 제한되지 아니하고 필요에 따라 일부 요소가 추가 또는 제거될 수 있으며, 이상의 요소와 조합될 수도 있음은 물론이다. 이하에서는 도 7 내지 도 9를 참조하여, 앞선 도 1 내지 도 6의 객체 포즈 및 모델 추정 방법 또는 장치가 적용 된 웨어러블 전자 장치에 대하여 살펴보도록 한다. 도 7은 본 개시의 일 실시예에 따라, 웨어러블 전자 장치에 적용된 객체 포즈 및 모델 추정 장치를 나타내는 사 시도이다. 도 7을 참조하면, 일 실시예에 따른 웨어러블 전자 장치는 렌즈, 웨어러블 전자 장치를 사용자 의 신체의 일부(예: 머리 등)에 고정시키기 위한 연결부, 센서 및 프로세서를 포함할 수 있다. 일 실시예에 따른 웨어러블 전자 장치는 도 6의 컴퓨터 장치의 일 예시일 수 있으며, 이하에서 중복되는 설명은 생략하도록 한다. 일 실시예에 따르면, 웨어러블 전자 장치는 도 7에 도시된 바와 같이 사용자의 귀에 착용 가능한 안경 타 입의 전자 장치일 수 있으나, 이에 한정되는 것은 아니다. 다른 예시에서, 웨어러블 전자 장치는 사용자의 머리에 착용 가능한 헤드 마운트 타입(head-mount type)의 전자 장치일 수도 있다. 센서는 웨어러블 전자 장치의 주변 환경에 대한 데이터를 센싱할 수 있으며, 센서에서 센싱된 데이터(또는 '센싱 데이터')는 센서와 전기적 또는 작동적으로 연결된 프로세서로 전달될 수 있다. 이 때, 센서는 도 5의 데이터 획득 유닛의 적어도 일부일 수 있다. 일 예시에서, 센서는 웨어러블 전자 장치의 주변 객체에 대한 이미지 데이터를 획득하기 위한 카메라, 컬러 센서 및 깊이 센서(예: LiDAR) 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 다른 예시에서, 센서는 관성 측정 유닛(IMU: Inertial Measurement Unit), GPS(Global Positioning System), 및 주행거리계(odometer) 중 적어도 하나를 더 포함할 수도 있다. 프로세서는 센서와 전기적 또는 작동적으로 연결되며, 센서에서 센싱된 데이터에 기초하여 웨어 러블 전자 장치의 주변에 위치한 객체의 포즈 및 모델을 결정할 수 있다. 일 실시예에 따르면, 프로세서는 센서로부터 센싱된 주변 객체(예: 인체의 손 부위)에 대한 이미지 데이터를 입력 이미지로 활용하여, 입력 이미지에서의 주변 객체의 관절 포인트에 대한 위치 정보 및 모델 정점 에 대한 위치 정보를 획득할 수 있다. 이 때, 프로세서는 도 5의 특징 구성 유닛 및/또는 추정 유닛 의 역할을 수행할 수 있다. 프로세서는 센서에서 획득된 입력 이미지로부터 글로벌 특징(또는 '전역 특징')을 획득하고, 메모리 (미도시)에 저장된 템플릿 모델로부터 주변 객체의 위치 코드를 획득할 수 있다. 예를 들어, 메모리에는 파라미 터화 모형(예: MAMO)을 포함하는 템플릿 모델이 저장되어 있을 수 있으며, 프로세서는 메모리와 전기적 또 는 작동적으로 연결되어 메모리에 저장된 템플릿 모델로부터 주변 객체의 관절 포인트의 위치 정보 및 모델 정 점의 위치 정보를 포함하는 위치 코드를 획득할 수 있다. 메모리는 프로세서와 구별되는 별개의 구성일 수 있으나, 이에 한정되는 것은 아니다. 실시예에 따라, 메모리는 프로세서와 일체로 형성되거나, 프로세서 에 내장된 구성일 수 있다. 이 때, 프로세서의 상술한 입력 이미지로부터 글로벌 특징을 획득하고, 템플릿 모델로부터 객체의 위치 코 드를 획득하는 동작은 도 1의 S101 단계와 실질적으로 동일 또는 유사할 수 있으며, 이하에서 중복되는 설명은 생략하도록 한다. 또한, 프로세서는 입력 이미지의 글로벌 특징 및 템플릿 모델에서의 주변 객체의 위치 코드에 기반하여, 주변 객체의 로컬 영역 특징을 결정할 수 있다. 예를 들어, 프로세서는 입력 이미지의 글로벌 특징 및 템 플릿 모델에서의 주변 객체의 위치 코드를 활용하여 주변 객체의 로컬 영역 내의 관절 포인트 및 모델 정점의 특징 표시를 포함하는 주변 객체의 로컬 영역 특징을 결정할 수 있다. 이 때, 프로세서의 주변 객체의 로컬 영역 특징을 결정하는 동작은 도 1의 S102 단계와 실질적으로 동일 또는 유사할 수 있으며, 이하에서 중복되는 설명은 생략하도록 한다. 또한, 프로세서는 주변 객체의 로컬 영역 특징에 기반하여 입력 이미지에서의 주변 객체의 관절 포인트의 위치 정보 및 모델 정점의 위치 정보를 획득할 수 있다. 예를 들어, 프로세서는 주변 객체의 로컬 영역 사 이의 위치 관계에 기반하여 로컬 영역 특징을 그룹화한 다음 그룹화 결과에 기반하여 코딩을 실시함으로써 입력 이미지에서의 주변 객체의 관절 포인트의 위치 정보 및 입력 이미지에서의 모델 정점의 위치 정보를 결정할 수있다. 이 때, 프로세서의 주변 객체의 관절 포인트의 위치 정보 및 모델 정점의 위치 정보를 획득하는 동작은 도 1의 S103 단계와 실질적으로 동일 또는 유사할 수 있으며, 이하에서 중복되는 설명은 생략하도록 한다. 일 실시예에 따르면, 웨어러블 전자 장치는 상술한 프로세서의 동작들을 통해 결정된 주변 객체의 관 절 포인트의 위치 정보 및 모델 정점의 위치 정보에 기반하여 증강 현실 이미지(AR image, augmented reality image)를 생성하고, 렌즈(또는 '디스플레이(display)')를 통해 생성된 증강 현실 이미지를 표시할 수 있다. 본 개시에서 '증강 현실 이미지'는 웨어러블 전자 장치의 주변의 현실 세계(real world)의 이미지와 가상 의 이미지가 조합된 이미지를 의미할 수 있다. 예를 들어, 증강 현실 이미지는 현실 세계의 이미지에 가상의 이 미지가 오버레이(overlay)된 이미지를 의미할 수 있으나, 이에 한정되는 것은 아니다. 이 때, 현실 세계의 이미지는 사용자가 전자 장치를 통해 볼 수 있는 실제 장면(real scene)을 의미하며, 현실 세계의 이미지에는 현실 객체(real world object)가 포함될 수 있다. 또한, 가상의 이미지는 그래픽스 프 로세싱에 의해 형성되는 현실 세계에 존재하지 않는 이미지를 의미하며, 가상의 이미지에는 디지털 또는 가상의 객체(AR object)가 포함될 수 있다. 일 실시예에 따르면, 센서 및 프로세서가 도 7에 도시된 바와 같이 연결부에 배치될 수 있으나, 센서 및 프로세서의 배치 구조가 이에 한정되는 것은 아니다. 다른 실시예(미도시)에서, 센서 및/또는 프로세서는 렌즈의 주변 영역(예: 테두리)에 배치될 수도 있다. 도면 상에 도시되지 않았으나, 웨어러블 전자 장치는 증강 현실 이미지에 대한 데이터가 포함된 광을 방출 하고, 방출된 광의 이동 경로를 조절하기 위한 광학 부품들(미도시)을 더 포함할 수 있다. 프로세서는 광 학 부품들을 통해 증강 현실 이미지에 대한 데이터가 포함된 광을 방출하고, 방출된 광이 렌즈에 도달하도 록 할 수 있다. 증강 현실 이미지에 대한 데이터가 포함된 광이 렌즈에 도달함에 따라 렌즈에는 증강 현실 이미지가 표시될 수 있으며, 웨어러블 전자 장치는 상술한 과정을 통해 사용자(또는 '착용자')에게 증강 현실 이미 지를 제공할 수 있다. 도 8은 본 개시의 다른 실시예에 따라, 웨어러블 전자 장치에 적용된 객체 포즈 및 모델 추정 장치를 나타내는 사시도이다. 도 8을 참조하면, 다른 실시예에 따른 웨어러블 전자 장치는 렌즈, 웨어러블 전자 장치를 사용 자의 신체의 일부(예: 머리 등)에 고정시키기 위한 연결부 및 센서를 포함할 수 있다. 다른 실시예에 따른 웨어러블 전자 장치의 구성 요소들 중 적어도 하나는 도 7의 웨어러블 전자 장치의 구성 요소들 중 적어도 하나와 동일 또는 유사할 수 있으며, 이하에서 중복되는 설명은 생략하도록 한다. 일 실시예에 따르면, 웨어러블 전자 장치는 외부 장치(예: 모바일 전자 장치)와 전기적 또는 작동적 으로 연결될 수 있다. 예를 들어, 웨어러블 전자 장치는 인터페이스를 통해 외부 장치와 유선으 로 연결될 수 있으나, 이에 한정되는 것은 아니다. 다른 예시에서, 웨어러블 전자 장치는 무선 통신을 통 해 외부 장치와 무선으로 연결될 수도 있다. 외부 장치는 프로세서를 포함할 수 있으며, 프로세서는 웨어러블 전자 장치의 센서로 부터 웨어러블 전자 장치의 주변 환경에 대한 센싱 데이터를 수신할 수 있다. 예를 들어, 프로세서는 인터페이스를 통해 센서로부터 웨어러블 전자 장치의 주변 객체에 대한 이미지 데이터를 수신할 수 있다. 외부 장치의 프로세서는 센서로부터 수신한 주변 객체(예: 인체의 손 부위)에 대한 이미지 데이 터를 입력 이미지로 활용하여, 입력 이미지에서의 주변 객체의 관절 포인트에 대한 위치 정보 및 모델 정점에 대한 위치 정보를 획득할 수 있다. 이 때, 외부 장치의 프로세서는 도 5의 특징 구성 유닛 및/또 는 추정 유닛의 역할을 수행할 수 있다. 프로세서는 웨어러블 전자 장치의 센서에서 획득된 입력 이미지로부터 글로벌 특징을 획득하고, 메모리(미도시)에 저장된 템플릿 모델로부터 주변 객체의 위치 코드를 획득할 수 있다. 이 때, 메모리는 프로세 서와 구별되는 별개의 구성으로 MAMO와 같은 파라미터화 모형을 포함하는 템플릿 모델을 저장할 수있으나, 이에 한정되는 것은 아니다. 실시예에 따라, 메모리는 프로세서와 일체로 형성되거나, 프로세서 에 내장된 구성일 수 있다. 이 때, 프로세서의 상술한 입력 이미지로부터 글로벌 특징을 획득하고, 템플릿 모델로부터 객체의 위치 코 드를 획득하는 동작은 도 1의 S101 단계와 실질적으로 동일 또는 유사할 수 있으며, 이하에서 중복되는 설명은 생략하도록 한다. 또한, 프로세서는 입력 이미지의 글로벌 특징 및 템플릿 모델에서의 주변 객체의 위치 코드에 기반하여, 주변 객체의 로컬 영역 특징을 결정할 수 있다. 예를 들어, 프로세서는 입력 이미지의 글로벌 특징 및 템 플릿 모델에서의 주변 객체의 위치 코드를 활용하여 주변 객체의 로컬 영역 내의 관절 포인트 및 모델 정점의 특징 표시를 포함하는 주변 객체의 로컬 영역 특징을 결정할 수 있다. 이 때, 프로세서의 주변 객체의 로컬 영역 특징을 결정하는 동작은 도 1의 S102 단계와 실질적으로 동일 또는 유사할 수 있으며, 이하에서 중복되는 설명은 생략하도록 한다. 또한, 프로세서는 주변 객체의 로컬 영역 특징에 기반하여 입력 이미지에서의 주변 객체의 관절 포인트의 위치 정보 및 모델 정점의 위치 정보를 획득할 수 있다. 예를 들어, 프로세서는 주변 객체의 로컬 영역 사 이의 위치 관계에 기반하여 로컬 영역 특징을 그룹화한 다음 그룹화 결과에 기반하여 코딩을 실시함으로써 입력 이미지에서의 주변 객체의 관절 포인트의 위치 정보 및 입력 이미지에서의 모델 정점의 위치 정보를 결정할 수 있다. 이 때, 프로세서의 주변 객체의 관절 포인트의 위치 정보 및 모델 정점의 위치 정보를 획득하는 동작은 도 1의 S103 단계와 실질적으로 동일 또는 유사할 수 있으며, 이하에서 중복되는 설명은 생략하도록 한다. 일 실시예에 따르면, 외부 장치의 프로세서의 동작들을 통해 결정된 주변 객체의 관절 포인트의 위치 정보 및 모델 정점의 위치 정보에 기반하여 증강 현실 이미지를 생성하고, 생성된 증강 현실 이미지를 웨어러블 전자 장치로 전송할 수 있다. 예를 들어, 프로세서는 인터페이스를 통해 웨어러블 전자 장치 의 주변 객체의 관절 포인트의 위치 정보 및 모델 정점의 위치 정보에 기반하여 생성된 증강 현실 이미지 를 웨어러블 전자 장치로 전송할 수 있다. 웨어러블 전자 장치는 렌즈(또는 '디스플레이(display)')를 통해 외부 장치로부터 수신된 증강 현실 이미지를 표시할 수 있다. 도면 상에 도시되지 않았으나, 웨어러블 전자 장치는 증강 현실 이미지에 대한 데이터가 포함된 광을 방출하고, 방출된 광의 이동 경로를 조절하기 위한 광학 부품들(미도시)을 더 포함 할 수 있다. 웨어러블 전자 장치는 광학 부품들을 통해 외부 장치로부터 수신된 증강 현실 이미지에 대한 데이터가 포함된 광을 방출하고, 방출된 광이 렌즈에 도달하도록 할 수 있다. 증강 현실 이미지에 대한 데이터가 포함된 광이 렌즈에 도달함에 따라 렌즈에는 증강 현실 이미지가 표시될 수 있으며, 웨어러블 전자 장치는 상술한 과정을 통해 사용자(또는 '착용자')에게 증강 현실 이미 지를 제공할 수 있다. 도 9는 본 개시의 또 다른 실시예에 따라, 웨어러블 전자 장치에 적용된 객체 포즈 및 모델 추정 장치를 나타내 는 사시도이다. 도 9를 참조하면, 또 다른 실시예에 따른 웨어러블 전자 장치는 렌즈, 웨어러블 전자 장치를 사 용자의 신체의 일부(예: 머리 등)에 고정시키기 위한 연결부 및 센서를 포함할 수 있다. 또 다른 실 시예에 따른 웨어러블 전자 장치의 구성 요소들 중 적어도 하나는 도 8의 웨어러블 전자 장치의 구성 요소들 중 적어도 하나와 동일 또는 유사할 수 있으며, 이하에서 중복되는 설명은 생략하도록 한다. 일 실시예에 따르면, 웨어러블 전자 장치는 외부 서버와 전기적 또는 작동적으로 연결될 수 있다. 예 를 들어, 웨어러블 전자 장치는 무선 통신을 통해 외부 서버와 전기적 또는 작동적으로 연결될 수 있 으며, 이를 통해 웨어러블 전자 장치와 외부 서버의 사이에서 데이터가 전송될 수 있다. 외부 서버는 웨어러블 전자 장치의 센서로부터 웨어러블 전자 장치의 주변 환경에 대한 센 싱 데이터를 수신할 수 있다. 예를 들어, 프로세서는 인터페이스를 통해 센서로부터 웨어러블 전자 장치의 주변 객체에 대한 이미지 데이터를 수신할 수 있다. 일 실시예에 따르면, 외부 서버는 웨어러블 전자 장치의 센서로부터 수신한 주변 객체(예: 인체 의 손 부위)에 대한 이미지 데이터를 입력 이미지로 활용하여, 입력 이미지에서의 주변 객체의 관절 포인트에대한 위치 정보 및 모델 정점에 대한 위치 정보를 획득할 수 있다. 이 때, 외부 서버는 도 5의 특징 구성 유닛 및/또는 추정 유닛의 역할을 수행할 수 있다. 외부 서버는 웨어러블 전자 장치의 센서에서 획득된 입력 이미지로부터 글로벌 특징을 획득하고, 외부 서버의 메모리 내에 저장된 템플릿 모델로부터 주변 객체의 위치 코드를 획득할 수 있다. 이 때, 외부 서버의 상술한 입력 이미지로부터 글로벌 특징을 획득하고, 템플릿 모델로부터 객체의 위치 코드를 획득하는 동작은 도 1의 S101 단계와 실질적으로 동일 또는 유사할 수 있으며, 이하에서 중복되는 설명 은 생략하도록 한다. 또한, 외부 서버는 입력 이미지의 글로벌 특징 및 템플릿 모델에서의 주변 객체의 위치 코드에 기반하여, 주변 객체의 로컬 영역 특징을 결정할 수 있다. 예를 들어, 외부 서버는 입력 이미지의 글로벌 특징 및 템 플릿 모델에서의 주변 객체의 위치 코드를 활용하여 주변 객체의 로컬 영역 내의 관절 포인트 및 모델 정점의 특징 표시를 포함하는 주변 객체의 로컬 영역 특징을 결정할 수 있다. 이 때, 외부 서버의 주변 객체의 로컬 영역 특징을 결정하는 동작은 도 1의 S102 단계와 실질적으로 동일 또는 유사할 수 있으며, 이하에서 중복되는 설명은 생략하도록 한다. 또한, 외부 서버는 주변 객체의 로컬 영역 특징에 기반하여 입력 이미지에서의 주변 객체의 관절 포인트의 위치 정보 및 모델 정점의 위치 정보를 획득할 수 있다. 예를 들어, 외부 서버는 주변 객체의 로컬 영역 사이의 위치 관계에 기반하여 로컬 영역 특징을 그룹화한 다음 그룹화 결과에 기반하여 코딩을 실시함으로써 입 력 이미지에서의 주변 객체의 관절 포인트의 위치 정보 및 입력 이미지에서의 모델 정점의 위치 정보를 결정할 수 있다. 이 때, 외부 서버의 주변 객체의 관절 포인트의 위치 정보 및 모델 정점의 위치 정보를 획득하는 동작은 도 1의 S103 단계와 실질적으로 동일 또는 유사할 수 있으며, 이하에서 중복되는 설명은 생략하도록 한다. 일 실시예에 따르면, 외부 서버는 상술한 동작들을 통해 결정된 주변 객체의 관절 포인트의 위치 정보 및 모델 정점의 위치 정보에 기반하여 증강 현실 이미지를 생성하고, 생성된 증강 현실 이미지를 웨어러블 전자 장 치로 전송할 수 있다. 예를 들어, 외부 서버는 무선 통신을 통해 웨어러블 전자 장치의 주변 객 체의 관절 포인트의 위치 정보 및 모델 정점의 위치 정보에 기반하여 생성된 증강 현실 이미지를 웨어러블 전자 장치로 전송할 수 있다. 웨어러블 전자 장치는 렌즈(또는 '디스플레이(display)')를 통해 외부 장치로부터 수신된 증강 현실 이미지를 표시할 수 있다. 도면 상에 도시되지 않았으나, 웨어러블 전자 장치는 증강 현실 이미지에 대한 데이터가 포함된 광을 방출하고, 방출된 광의 이동 경로를 조절하기 위한 광학 부품들(미도시)을 더 포함 할 수 있다. 웨어러블 전자 장치는 광학 부품들을 통해 외부 장치로부터 수신된 증강 현실 이미지에 대한 데이터가 포함된 광을 방출하고, 방출된 광이 렌즈에 도달하도록 할 수 있다. 증강 현실 이미지에 대한 데이터가 포함된 광이 렌즈에 도달함에 따라 렌즈에는 증강 현실 이미지가 표시될 수 있으며, 웨어러블 전자 장치는 상술한 과정을 통해 사용자(또는 '착용자')에게 증강 현실 이미 지를 제공할 수 있다. 본 개시의 예시적 실시예에 따른 객체 포즈 및 모델 추정 방법 및 장치에서, 먼저 입력 이미지의 글로벌 특징, 템플릿 모델에서의 객체의 객체의 관절 포인트와 모델 정점의 좌표를 포함하는 위치 코드를 획득하고, 입력 이 미지의 글로벌 특징과 템플릿 모델에서의 객체의 위치 코드에 기반하여 객체의 로컬 특징을 결정한 다음, 객체 의 로컬 특징에 기반하여 입력 이미지에서의 객체의 관절 포인트에 대한 위치 정보 및 입력 이미지에서의 모델 정점에 대한 위치 정보를 획득함으로써 객체 포즈 및 모델 추정에 있어서의 정확도를 향상시킨다. 본 개시의 예시적 실시예에서, 객체의 포즈 및 모델 추정 방법에서는 입력 이미지의 글로벌 특징, 템플릿 모델 에서의 객체의 위치 코드를 인공지능 모델의 입력 데이터로 하여, 출력되는 객체의 포즈 및 모델을 획득할 수 있다. 인공지능 모델은 트레이닝을 통해 획득될 수 있다. 여기서, \"트레이닝을 통해 획득\"이라 함은 알고리즘 트레이 닝을 통하여 다수의 트레이닝 데이터를 가지는 기본 인공지능 모델을 트레이닝함으로써 소정의 작동 규칙 또는 인공지능 모델을 획득하는 것으로서, 상기 작동 규칙 또는 인공지능 모델은 필요한 특징(또는 목적)을 실행하도 록 구성된다. 그 예로, 인공지능 모델은 다수 개의 뉴럴 네트워크 레이어를 포함할 수 있다. 상기 다수 개의 뉴럴 네트워크 레이어 각각은 다수 개의 가중치를 포함하며, 이전 레이어의 계산 결과와 상기 다수 개의 가중치 사이의 계산을 통하여 뉴럴 네트워크 계산을 수행한다. 시각적 이해는 인간의 시각과 동일한 것으로서, 사물을 식별 및 처리하는 기술이며, 예컨대 물체 식별, 물체 추 적, 이미지 검색, 인간 식별, 장면 식별, 3차원 재구성/위치 결정 또는 이미지 증강 등을 포함한다. 이미 예시적인 실시예를 통하여 본 개시를 구체적으로 도시하고 설명하였으나, 당업자들은 청구범위에 한정된 본 개시의 사상과 범위를 벗어나지 않으면서 이를 다양하게 변형할 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2022-0045264", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이하, 실시예를 예시적으로 도시한 도면을 참조하여 본 개시를 설명한다. 본 개시의 예시적 실시예에서 전술된 것 이외의 목적과 특징이 보다 명확해질 것이다. 도 1은 본 개시의 예시적 실시예에 따른, 객체의 포즈 및 모델 추정 방법을 나타낸 흐름도이다. 도 2는 본 개시의 예시적 실시예에 따른, 손의 포즈 및 모델 추정 방법을 나타낸 흐름도이다. 도 3은 전체 특징과 손 부분 구역의 대응 관계를 나타내는 도면이다. 도 4a는 본 개시의 예시적 실시예에 따른, 로컬 영역 특징을 그룹화하는 네트워크의 개략도이다. 도 4b는 본 개시의 예시적 실시예에 따른, 학습 가능한 그룹화의 시각화 과정을 도시한 도면이다. 도 5는 본 개시의 예시적 실시예에 따른, 객체 포즈 및 모델 추정 장치를 도시한 블록도이다. 도 6은 본 개시의 예시적 실시예에 따른 연산 장치를 도시한 도면이다. 도 7은 본 개시의 일 실시예에 따라, 웨어러블 전자 장치에 적용된 객체 포즈 및 모델 추정 장치를 나타내는 사 시도이다. 도 8은 본 개시의 다른 실시예에 따라, 웨어러블 전자 장치에 적용된 객체 포즈 및 모델 추정 장치를 나타내는 사시도이다. 도 9는 본 개시의 또 다른 실시예에 따라, 웨어러블 전자 장치에 적용된 객체 포즈 및 모델 추정 장치를 나타내 는 사시도이다."}
