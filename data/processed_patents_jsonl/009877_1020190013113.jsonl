{"patent_id": "10-2019-0013113", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0095254", "출원번호": "10-2019-0013113", "발명의 명칭": "멀티 라벨 분류를 통한 의료 이미지 태깅 및 분류 시스템 및 방법", "출원인": "(주)엔에스데블", "발명자": "이언주"}}
{"patent_id": "10-2019-0013113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "CT, X-ray, 실제 사진을 포함하는 의료 이미지들을 입력받아 사전에 미리 머신 러닝에 의해 기계 학습된 이미지의 특징과 비교하여 사진의 종류를 분류하고, 신체 부위, 의과대학 과목으로 분류하는 분류기1,2,3(classifier1,2,3)들을 구비하는 멀티 라벨 분류기; 및상기 멀티 라벨 분류기에 의해 분류된 의료 이미지에 대하여 k개의 태그로 태깅하는 이미지 태깅 시스템을 포함하는, 멀티 라벨 분류를 통한 의료 이미지 태깅 및 분류 시스템."}
{"patent_id": "10-2019-0013113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 k개의 tag는 3개의 tag를 사용하며, 1번 tag는 10개의 '신체부위' 태그로써, 입, 눈, 귀, 심장, 폐, 근육, 피부, 위장, 혈액세포, 심혈관계를 포함하며, 2번 tag는 7개의 '의과대학 과목' 태그로써, 심장학, 피부과학, 감각기학, 소화기병학, 혈액학, 근골격학, 호흡기학을 포함하며, 3번 tag는 3개의 '사진 종류' 태그로써, CT, X-ray, 실제 사진을 포함하는 멀티 라벨 분류를 통한 의료 이미지태깅 및 분류 시스템."}
{"patent_id": "10-2019-0013113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 멀티 라벨 분류기는 상기 의료 이미지에 대하여 신체부위, 의과대학 과목, 사진 종류에 대하여 각각 태그1- 신체부위 학습 분류기, 태그2- 의과대학 과목 학습 분류기2, 태그3- 사진 종류 학습 분류기3를 사용하여 각각 학습하여 분류하며, 상기 3개의 분류기(classifier)를 입력된 하나의 이미지에 대하여 모두 다 적용하는, 멀티 라벨 분류를 통한 의료 이미지 태깅 및 분류 시스템."}
{"patent_id": "10-2019-0013113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 멀티 라벨 분류기는 '신체부위'를 학습하여 분류하는 신체부위 학습 분류기1와,'의과대학 과목'를 학습하여 분류하는 의과대학 과목 학습 분류기2와, '사진 종류'를 학습하여 분류하는 신체부위 학습 분류기3를 포함하며,3개의 분류기(classifier)에서 추론한 결과들을 합해 이미지의 tag가 결정되며, 입력된 하나의 의료 이미지에대해 각각 분류기1로 분류하고, 분류기2로 분류하며, 분류기3로 분류하는 3 과정을 모두 거쳐 신체 부위, 영상종류, 의과대학 과목 3가지에 대한 태그가 분류되고 태깅되는, 멀티 라벨 분류를 통한 의료 이미지 태깅 및 분류 시스템."}
{"patent_id": "10-2019-0013113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 분류기1, 상기 분류기2, 상기 분류기3는 딥러닝의 이미지 분류 모델 인 inception resnet v2를 사용하여사전에 미리 의료 이미지를 학습하여 분류하는, 멀티 라벨 분류를 통한 의료 이미지 태깅 및 분류 시스템.공개특허 10-2020-0095254-3-청구항 6 제1항에 있어서, 상기 분류기(Classifier)의 정확도 향상을 위해 pretrained 모델의 특정 layer를 다시 학습하는 방법인imagenet dataset으로 학습된 Fine-tuning과 Gradient descent 알고리즘을 최적화하는 방법인 옵티마이저(Optimizer)를 사용하였으며, Fine-tuning 여부에 따른 결과는 크게 차이는 없었지만 학습 속도가 더 빠르다는장점이 있으며, 이미지 Auto-Tagging 시스템의 성능 테스트를 위해 사용한 옵티마이저(optimizer)는 RMSprop, Adadelta 그리고Adam을 사용하였으며, Adagrad optimizer를 개선한 RMSprop와 Adadelta를 사용하였을시 같은 성능을 나타냈고,RMSprop 발전시킨 Adam을 사용하였을 때 가장 좋은 성능을 제공하는, 멀티 라벨 분류를 통한 의료 이미지 태깅및 분류 시스템."}
{"patent_id": "10-2019-0013113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "(a) CT, X-ray, 실제 사진에 대하여 m개의 신체 부위, n개의 의과대학 과목, k개의 사진 종류에 따라, 상기 CT,X-ray, 실제 사진을 포함하는 의료 이미지의 사진의 종류를 분류하고, 상기 CT, X-ray, 실제 사진을 포함하는의료 이미지들을 신체 부위, 의과대학 과목으로 분류하는 3개의 분류기(classifier)를 갖는 멀티 라벨 분류기로입력하는 단계; 및 (b) '사진 종류', '신체 부위', '의과대학 과목'에 따라 각각 분류하는 3개의 분류기(classifier)를 갖는 멀티라벨 분류기에 의해 상기 CT, X-ray, 실제 사진을 포함하는 의료 이미지에 대하여 각각 사진 종류, 신체 부위와의과대학 과목으로 분류하고, 분류된 의료 이미지에 대하여 해당하는 태그1,2,3 중 어느 하나의 태그로 태깅하는 단계; 를 포함하는 멀티 라벨 분류를 통한 의료 이미지 태깅 및 분류 방법."}
{"patent_id": "10-2019-0013113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 k개의 tag는 3개의 tag를 사용하며, 1번 tag는 10개의 '신체부위' 태그로써, 입, 눈, 귀, 심장, 폐, 근육, 피부, 위장, 혈액세포, 심혈관계를 포함하며, 2번 tag는 7개의 '의과대학 과목' 태그로써, 심장학, 피부과학, 감각기학, 소화기병학, 혈액학, 근골격학, 호흡기학을 포함하며, 3번 tag는 3개의 '사진 종류' 태그로써, CT, X-ray, 실제 사진을 포함하는 멀티 라벨 분류를 통한 의료 이미지태깅 및 분류 방법."}
{"patent_id": "10-2019-0013113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 멀티 라벨 분류기는 상기 의료 이미지에 대하여 신체부위, 의과대학 과목, 사진 종류에 대하여 각각 태그1- 신체부위 학습 분류기, 태그2- 의과대학 과목 학습 분류기2, 태그3- 사진 종류 학습 분류기3를 사용하여 각각 학습하여 분류하며, 상기 3개의 분류기(classifier)를 입력된 하나의 이미지에 대하여 모두 다 적용하는, 멀티 라벨 분류를 통한 의료 이미지 태깅 및 분류 방법."}
{"patent_id": "10-2019-0013113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 멀티 라벨 분류기는, 상기 의료 이미지에 대하여 신체부위 학습 분류기1에 의해 '신체부위'를 학습하여 분류하는 단계; 공개특허 10-2020-0095254-4-상기 의료 이미지에 대하여 의과대학 과목 학습 분류기2에 의해 '의과대학 과목'를 학습하여 분류하는 단계; 및상기 의료 이미지에 대하여 신체부위 학습 분류기3에 의해 '사진 종류'를 학습하여 분류하는 단계를 포함하며, 3개의 분류기(classifier)에서 추론한 결과들을 합해 이미지의 tag가 결정되며, 입력 의료 이미지에 대해 신체부위, 영상 종류, 의과대학 과목 3가지에 대한 태그가 태깅되어 출력되는, 멀티 라벨 분류를 통한 의료 이미지태깅 및 분류 방법."}
{"patent_id": "10-2019-0013113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 멀티 라벨 분류기는 딥러닝의 이미지 분류 모델 인 inception resnet v2를 사용하여 사전에 미리 의료 이미지를 학습하여 분류하는, 멀티 라벨 분류를 통한 의료 이미지 태깅 및 분류 방법."}
{"patent_id": "10-2019-0013113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서, 상기 분류기(Classifier)의 정확도 향상을 위해 pretrained 모델의 특정 layer를 다시 학습하는 방법인imagenet dataset으로 학습된 Fine-tuning과 Gradient descent 알고리즘을 최적화하는 방법인 옵티마이저(Optimizer)를 사용하였으며, Fine-tuning 여부에 따른 결과는 크게 차이는 없었지만 학습 속도가 더 빠르다는장점이 있으며, 이미지 Auto-Tagging 시스템의 성능 테스트를 위해 사용한 옵티마이저(optimizer)는 RMSprop, Adadelta 그리고Adam을 사용하였으며, Adagrad optimizer를 개선한 RMSprop와 Adadelta를 사용하였을시 같은 성능을 나타냈고,RMSprop 발전시킨 Adam을 사용하였을 때 가장 좋은 성능을 제공하는, 멀티 라벨 분류를 통한 의료 이미지 태깅및 분류 방법."}
{"patent_id": "10-2019-0013113", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "멀티 라벨 분류(Multi-label classification)를 통한 의료 이미지 태깅 및 분류 시스템 및 방법이 개시된다. 상 기 시스템은 CT, X-ray, 실제 사진을 포함하는 의료 이미지들을 입력받아 사전에 미리 머신 러닝에 의해 기계 학 습된 이미지의 특징과 비교하여 사진의 종류를 분류하고, 신체 부위, 의과대학 과목으로 분류하는 분류기1,2,3들 (뒷면에 계속)"}
{"patent_id": "10-2019-0013113", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 멀티 라벨 분류(Multi-label classification)를 통한 의료 이미지 태깅 및 분류 시스템 및 방법에 관 한 것으로, 보다 상세하게는 인공지능 모듈 인 멀티 레벨 분류기와 Auto-Tagging 시스템이 서버에 설치 운용되 며, CT, X-ray, 실제 사진을 포함하는 의료 이미지에 대하여 '사진 종류' 분류기1, '신체부위' 분류기2, '의과 대학 과목' 분류기3의 멀티 레벨 분류기(classifier)에 의해 10개의 신체 부위(입, 눈, 귀, 심장, 폐, 근육, 피 부, 위장, 혈액세포, 심혈관계), 7개의 의과대학 과목(심장학, 피부과학, 감각기학, 소화기병학, 혈액학, 근골 격학, 호흡기학), 3개의 사진 종류(CT, X-ray, 실제 사진)에 따라, 상기 CT, X-ray, 실제 사진의 의료 이미지들 을 사진 종류, 신체 부위, 의과대학 과목으로 분류하여 tagging하며, 분류 태깅된 의료 이미지들을 의과대학 과 목의 대분류/중분류/소분류로 구분하여 이미지 DB에 저장한다. 본 연구는 과학기술정보통신부 및 정보통신기술진흥센터의 SW 중심대학사업의 연구결과로 수행되었습니다(2016- 0-00019)."}
{"patent_id": "10-2019-0013113", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재 생물학, 의학, 컴퓨터 공학 등 여러 분야에서 이미지의 분류나 분석에 대한 방법론 연구가 활발히 진행되 고 있다. 더불어 ImageNet Large Scale Visual Recognition Challenge나 Grand Challenge등의 이미지 분류, 분 석에 대한 대회도 상당히 많이 개최되고 있는 것으로 보아 이미지의 분류 문제는 상당히 중요한 문제라는 것을 알 수 있다. 현재 1개의 이미지에 1개의 class를 구분하는 single class classification이나 multi class classification에 대한 연구는 상당히 많이 진행되어 왔다. 하지만 1개의 이미지가 여러 class에 속할 수 있는 multi label classification의 문제는 여러개의 single label classification 문제로 바꾸는 방법이 일반적이다. 하지만 classifier의 개수가 많아짐에 따라 최적화를 위한 비용이 많이 들고, dataset의 성질에 따라 접근 방법이 다를수 있다. 의과 대학에서 배우는 과목에 사용되는 의료 이미지를 과목의 대분류, 중분류, 소분류 등을 다중으로 tag 하기 위한 방법론이 필요하다. 이와 관련된 선행기술1로써, 특허등록번호 10-13118250000 에서는 \"사진 자동 분류 시스템 및 방법\"이 공개되어 있다. 사진 촬영이 가능한 촬영 단말에서 촬영된 이미지를 유, 무선 네트워크를 통해 사용자가 원하는 장치로 자동 분 류되어 저장할 수 있는 사진 자동 분류 방법은, 수신되는 다수의 촬영 이미지를 촬영 순서에 따라 순차적으로 스캔하여 분류기준용 이미지를 검출하는 1단계; 분류기준용 이미지가 검출되면, 검출된 분류기준용 이미지로부 터 분류기준정보를 추출하는 2단계; 추출된 분류기준정보를 폴더명으로 하는 사진 폴더를 생성하는 3단계; 및 생성된 사진 폴더에 다른 분류기준용 이미지가 검출되기 전까지의 촬영 이미지들을 저장하는 4단계;를 포함한다. 그러나, 기존의 사진 분류 시스템은 머신 러닝의 지도 학습법(Supervised-Learning)을 사용하는 인공 지능 모듈 의 기계학습된 분류기에 의해 학습된 의과대학 과목의 의료 이미지들을 분류, 태깅하는 시스템이 존재하지 않았 다. 선행기술문헌 특허문헌 (특허문헌 0001) 특허 등록번호 10-13118250000 (등록일자 2015년 10월 07일), \"사진 자동 분류 시스템 및 방 법\", (주)엠팩토리 비특허문헌 (비특허문헌 0001) Jesse Read, Bernhard Pfahringer, Geoff Holmes, Eibe Frank, Machine Learning, Springer, pp. 333-359, 2011. (비특허문헌 0002) Christian Szegedy, Sergey Ioffe, Alexander A Alemi, Vincent Vanhoucke, “ Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning”, Thirty-First AAAI Conference on Artificial Intelligence, pp. 1-7, 2017."}
{"patent_id": "10-2019-0013113", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기한 문제점을 해결하기 위한 본 발명의 목적은 인공지능 모듈 인 멀티 레벨 분류기와 Auto-Tagging 시스템이 서버에 설치 운용되며, CT, X-ray, 실제 사진을 포함하는 의료 이미지에 대하여 '사진 종류' 분류기1, '신체부 위' 분류기2, '의과대학 과목' 분류기3의 멀티 레벨 분류기(classifier)에 의해 10개의 신체 부위(입, 눈, 귀, 심장, 폐, 근육, 피부, 위장, 혈액세포, 심혈관계), 7개의 의과대학 과목(심장학, 피부과학, 감각기학, 소화기 병학, 혈액학, 근골격학, 호흡기학), 3개의 사진 종류(CT, X-ray, 실제 사진)에 따라, 상기 CT, X-ray, 실제 사 진의 의료 이미지들을 사진 종류, 신체 부위, 의과대학 과목으로 분류하여 tagging하며, 의료 이미지들을 의과 대학 과목의 대분류, 중분류, 소분류로 구분하여 이미지 DB에 저장하는, 멀티 라벨 분류를 통한 의료 이미지 태 깅 및 분류 시스템을 제공한다. 본 발명의 다른 목적은 멀티 라벨 분류를 통한 의료 이미지 태깅 및 분류 방법을 제공한다."}
{"patent_id": "10-2019-0013113", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 목적을 달성하기 위해, 멀티 라벨 분류를 통한 의료 이미지 태깅 및 분류 시스템은 CT, X-ray, 실제 사진을 포함하는 의료 이미지들을 입력받아 사전에 미리 머신 러닝에 의해 기계 학습된 이미지의 특징과 비교하 여 사진의 종류를 분류하고, 신체 부위, 의과대학 과목으로 분류하는 분류기1,2,3(classifier 1,2,3)들을 구비하는 멀티 라벨 분류기; 및 상기 멀티 라벨 분류기에 의해 분류된 의료 이미지에 대하여 k개의 태그로 태깅하는 이미지 태깅 시스템을 포함한다. 본 발명의 다른 목적을 달성하기 위해, 멀티 라벨 분류를 통한 의료 이미지 태깅 및 분류 방법은 (a) CT, X- ray, 실제 사진에 대하여 m개의 신체 부위, n개의 의과대학 과목, k개의 사진 종류에 따라, 상기 CT, X-ray, 실 제 사진을 포함하는 의료 이미지의 사진의 종류를 분류하고, 상기 CT, X-ray, 실제 사진을 포함하는 의료 이미 지들을 신체 부위, 의과대학 과목으로 분류하는 3개의 분류기(classifier)를 갖는 멀티 라벨 분류기로 입력하는 단계; 및 (b) '사진 종류', '신체 부위', '의과대학 과목'에 따라 각각 분류하는 3개의 분류기(classifier)를 갖는 멀티 라벨 분류기에 의해 상기 CT, X-ray, 실제 사진을 포함하는 의료 이미지에 대하여 각각 사진 종류, 신체 부위와 의과대학 과목으로 분류하고, 분류된 의료 이미지에 대하여 해당하는 태그1,2,3 중 어느 하나의 태 그로 태깅하는 단계를 포함한다."}
{"patent_id": "10-2019-0013113", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 멀티 라벨 분류를 통한 의료 이미지 태깅 및 분류 시스템 및 방법은 연구 개발된 인공지능 모듈 인 멀티 레벨 분류기와 Auto-Tagging 시스템이 서버에 설치 운용되며, CT, X-ray, 실제 사진을 포함하는 의료 이미지에 대하여 '사진 종류' 분류기1, '신체부위' 분류기2, '의과대학 과목' 분류기3의 멀티 레벨 분류기 (classifier)에 의해 10개의 신체 부위(입, 눈, 귀, 심장, 폐, 근육, 피부, 위장, 혈액세포, 심혈관계), 7개의 의과대학 과목(심장학, 피부과학, 감각기학, 소화기병학, 혈액학, 근골격학, 호흡기학), 3개의 사진 종류(CT, X-ray, 실제 사진)에 따라, 상기 CT, X-ray, 실제 사진의 의료 이미지들을 사진 종류, 신체 부위, 의과대학 과 목으로 분류하여 tagging하며, 의료 이미지들을 의과대학 과목의 대분류/중분류/소분류로 구분하여 이미지DB에 저장하여 실제적으로 사용가능하게 되었다."}
{"patent_id": "10-2019-0013113", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 바람직한 실시예를 첨부된 도면을 참조하여 발명의 구성 및 동작을 상세하게 설명한다. 도 2는 본 발명에 따른 CT, X-ray, 실제 사진을 포함하는 의료 이미지에 대하여 '사진 종류' 분류기1, '신체부 위' 분류기2, '의과대학 과목' 분류기3를 포함하는 인공 지능 모듈 인 멀티 레벨 분류기(classifier)와 tagging 시스템을 구비하는 의료 이미지 태깅 및 분류 시스템 구성도이다. 도 3은 의과대학 교과과정과 학습에 사용된 신체부위 Ontology 구축 그림이다. 본 발명의 멀티 라벨 분류를 통한 의료 이미지 태깅 및 분류 시스템 및 방법은 연구 개발된 인공지능 모듈 인 멀티 레벨 분류기와 Auto-Tagging 시스템이 서버에 설치 운용되며, CT, X-ray, 실제 사진을 포함하는 의료 이미 지에 대하여 '사진 종류' 분류기1, '신체부위' 분류기2, '의과대학 과목' 분류기3의 멀티 레벨 분류기 (classifier)에 의해 10개의 신체 부위(입, 눈, 귀, 심장, 폐, 근육, 피부, 위장, 혈액세포, 심혈관계), 7개의 의과대학 과목(심장학, 피부과학, 감각기학, 소화기병학, 혈액학, 근골격학, 호흡기학), 3개의 사진 종류(CT,X-ray, 실제 사진)에 따라, 상기 CT, X-ray, 실제 사진의 의료 이미지들을 사진 종류, 신체 부위, 의과대학 과 목으로 분류하여 tagging하며, 분류 태깅된 의료 이미지들을 의과대학 과목의 대분류, 중분류, 소분류로 구분하 여 분류한다. 본 연구는 의과 대학에서 배우는 과목에 사용되는 의료 이미지(medical image)를 과목의 대분류, 중분류, 소분 류로 분류하여 멀티로 tagging하기 위한 방법론을 연구하였다. 본 발명의 멀티 라벨 분류(Multi-label classification)를 통한 의료 이미지 태깅 및 분류 시스템은 CT, X- ray, 실제 사진을 포함하는 의료 이미지들을 입력받아 사전에 미리 머신 러닝의 지도 학습법(Supervised- Learning)을 사용하여 기계 학습된 이미지의 특징과 비교하여 사진의 종류를 분류하고, 신체 부위, 의과대학 과 목으로 분류하는 분류기1,2,3(classifier 1,2,3)들을 구비하는 멀티 라벨 분류기; 및 상기 멀티 라벨 분류기에 의해 분류된 의료 이미지에 대하여 k개의 태그로 태깅하는 이미지 태깅 시스템을 포함한다. 또한, 본 발명의 멀티 라벨 분류(Multi-label classification)를 통한 의료 이미지 태깅 및 분류 방법은 (a) CT, X-ray, 실제 사진에 대하여 m개의 신체 부위(10개의 신체 부위: 입, 눈, 귀, 심장, 폐, 근육, 피부, 위장, 혈액세포, 심혈관계), n개의 의과대학 과목(7개의 의과대학 과목: 심장학, 피부과학, 감각기학, 소화기병학, 혈 액학, 근골격학, 호흡기학), k개의 사진 종류(3개의 사진 종류: CT, X-ray, 실제 사진)에 따라, 상기 CT, X- ray, 실제 사진을 포함하는 의료 이미지의 사진의 종류를 분류하고, 상기 CT, X-ray, 실제 사진을 포함하는 의 료 이미지들을 신체 부위, 의과대학 과목으로 분류하는 3개의 분류기(classifier)를 갖는 멀티 라벨 분류기로 입력하는 단계; 및 (b) '사진 종류', '신체 부위', '의과대학 과목'에 따라 각각 분류하는 3개의 분류기 (classifier)를 갖는 멀티 라벨 분류기에 의해 상기 CT, X-ray, 실제 사진을 포함하는 의료 이미지에 대하여 각 각 사진 종류, 신체 부위와 의과대학 과목으로 분류하고, 분류된 의료 이미지에 대하여 해당하는 태그1,2,3 중 어느 하나의 태그로 태깅(tagging)하는 단계를 포함한다. 상기 k개의 tag는 3개의 tag를 사용하며, 1번 tag는 10개의 '신체부위' 태그로써, 입, 눈, 귀, 심장, 폐, 근육, 피부, 위장, 혈액세포, 심혈관계를 포함 하며, 2번 tag는 7개의 '의과대학 과목' 태그로써, 심장학, 피부과학, 감각기학, 소화기병학, 혈액학, 근골격학, 호흡 기학을 포함하며, 3번 tag는 3개의 '사진 종류' 태그로써, CT, X-ray, 실제 사진을 포함한다. 상기 멀티 라벨 분류기는 신체부위-태그1, 의과대학 과목-태그-2, 사진 종류-태그3에 대하여 각각 태그1 분류기, 태그2 분류기, 태그3 분류기를 사용하여 각각 의료 이미지를 학습하여 분류하며, 상기 3개의 분류기 (classifier)를 입력된 하나의 의료 이미지에 대하여 각각 모두 다 적용한다. 상기 멀티 라벨 분류기는 '신체부위'를 학습하여 분류하는 신체부위 학습 분류기1와, '의과대학 과목'를 학습하여 분류하는 의과대학 과목 학습 분류기2와, '사진 종류'를 학습하여 분류하는 신체부위 학습 분류기3를 포함하며, 3개의 분류기(classifier)에서 추론한 결과들을 합해 이미지의 tag가 결정되며, 입력 이미지에 대해 태그 1 분 류기로 분류하고, 태그 2 분류기로 분류하며, 태그 3 분류기로 분류하는 3 과정을 모두 거쳐 신체 부위, 영상 종류, 의과대학 과목 3가지에 대한 태그가 태깅되어 출력된다. 2. 이미지 Multi-Tagging 방법 CT, X-ray, 실제 사진 등의 의료 이미지의 분류 Tagging 방법은 일반적으로, multi-label classification의 label 별로 여러 개의 Single Class Classification 문제로 바꾸는 방법과 1개의 이미지를 여러 부분으로 나눠 각 부분별로 Label을 찾는 방법이 있다. 우리가 사용한 방법은 첫 번째와 유사한 방법이다. 먼저, Tag의 개수를 정해 여러 개의 multi Class Classification으로 나누는 방법을 사용했다. CT, X-ray, 실제 사진의 의료 이미지에 tagging될 3개의 Tag field를 선정하였다. 각 Tagging Field별로 각각 의 분류기(classifier 1, classifier 2, classifier 3)를 사용하였으며, 머신 러닝의 Supervised Learning에 따라 '사진 종류', '신체 부위', '의과대학 과목'에 따라 사전에 미리 의료 이미지들을 기계학습시켜 학습된 결과에 따라 의료 이미지들을 분류하는 3개의 분류기(Classifier1,2,3)들을 사용하였다. 각 classifier들은 Tensorflow slim에서 지원하는 모델 중 가장 성능이 좋은 Inception-resnet-v2[2] CNN모델 을 사용하여 학습시켰다. 3. 구현 상위, 하위 카테고리와 신체부위 정보로 신체 부위 10 부분을 선정하여 총 1500여개의 이미지를 수집하였고, 이 미지 tag정보들의 관계를 위해 임의로 구축한 도 3에 도시된 바와 같이 의과대학 교과과정의 신체부위 ontology 를 바탕으로 각 classifier들이 분류하는 class를 선정하였다. train data와 validation data는 3:1의 비율로 나누어 학습을 진행하였다. 각 classifier들은 Tensorflow slim에서 지원하는 모델 중 가장 성능이 좋은 Inception-resnet-v2[2] CNN모델 을 사용하여 학습시켰다. 3개의 classifier 중 CNN모델의 초기 설정으로 학습하였을 때 성능이 가장 낮았던 첫 번째 classifier의 성능을 기준으로 최적화를 진행하였다. 최적화를 위한 시도로 fine tuning, optimizer변경, layer수 변경을 하였다. 표 1은 fine tuning의 여부와 optimizer의 변경에 따른 accuracy와 recall top 5를 비교한 표이다. Fine- tuning 여부에 따라 accuracy와 recall top 5에서 2%씩의 향상이 있었다. 표 1"}
{"patent_id": "10-2019-0013113", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "성능 테스트를 위해 사용한 optimizer는 RMSprop, Adadelta 그리고 Adam이다. Adagrad optimizer를 개선한 RMSprop와 Adadelta를 사용하였을 시 같은 성능을 보였고, RMSprop 발전시킨 Adam을 사용하였을 때 가장 좋은 성능을 확인할 수 있었다. 다음으로 layer의 수를 조정하여 성능을 높이는 시도를 하였다. 사용된 train data가 적었기 때문에 layer를 줄 이는 방향으로 수정하였다. layer 구조에서 중간에 inception resnet A, B, C layer가 각각 10번, 20번, 10번 반복되는데 이 반복횟수를 5번에 걸쳐 절반까지 줄인 결과에서는 성능의 차이가 없었다. 다음으로 모델의 가장 앞부분에 있는 stem layer에서 3부분의 convolutional layer를 제거하여 accuracy 74%와 recall top 5 95%의 결과를 얻을 수 있었다."}
{"patent_id": "10-2019-0013113", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "시스템 구현 시에, '사진 종류', '신체 부위', '의과대학 과목'에 따라 의료 이미지들을 각각 분류하는 3개의 분류기(classifier)를 갖는 멀티 라벨 분류기에 의해 CT, X-ray, 실제 사진을 포함하는 의료 이미지에 대하여 3 개의 사진 종류, 7개의 신체부위와 10개의 의과대학 과목에 따라 분류하며, 분류된 의료 이미지에 tagging될 3 개의 tag로 태깅한다. 이미지 분류 모델은 딥러닝의 inception resnet v2를 사용하였다. 상기 k개의 tag는 3개의 tag를 사용하며, 1번 tag는 10개의 '신체부위' 태그로써, 입, 눈, 귀, 심장, 폐, 근육, 피부, 위장, 혈액세포, 심혈관계를 포함 하며, 2번 tag는 7개의 '의과대학 과목' 태그로써, 심장학, 피부과학, 감각기학, 소화기병학, 혈액학, 근골격학, 호흡 기학을 포함하며, 3번 tag는 3개의 '사진 종류' 태그로써, CT, X-ray, 실제 사진을 포함한다. Tag 1,2,3 - 1번 tag : 신체부위(10 클래스) 입, 눈, 귀, 심장, 폐, 근육, 피부, 위장, 혈액세포, 심혈관계 - 2번 tag : 의과대학 과목(7 클래스) 심장학, 피부과학, 감각기학, 소화기병학, 혈액학, 근골격학, 호흡기학 - 3번 tag : 사진 종류(3 클래스) CT, X-ray, 실제 사진 1번 태그 값을 중심으로 3번 태그 값의 이미지를 확보(1500여 개의 이미지)하였다. 이를 Train data와 Validation data를 3:1 비율로 나누어 TFRecord로 변환하였다. 사용한 이미지 분류 모델은 inception resnet v2라는 모델이다. Tensorflow Slim에서 제공하는 모델 중 성능이 높아 선택하게 되었다. 분류기(Classifier)의 정확도 향상을 위해 pretrained 모델의 특정 layer를 다시 학습하는 방법인 imagenet dataset으로 학습된 Fine-tuning과 Gradient descent 알고리즘을 최적화하는 방법인 옵티마이저(Optimizer)를 사용하였다. Fine- tuning 여부에 따른 결과는 크게 차이는 없었지만 학습 속도가 빠르다는 장점이 있었다. 본 연구에서는, 이미지 Auto-Tagging 시스템의 성능 테스트를 위해 사용한 옵티마이저(optimizer)는 RMSprop, Adadelta 그리고 Adam를 사용하였다. Adagrad optimizer를 개선한 RMSprop와 Adadelta를 사용하였을시 같은 성 능을 나타냈고 RMSprop 발전시킨 Adam을 사용하였을 때 가장 좋은 성능을 확인할 수 있었다. RMSProp에서 진화한 것으로 learning rate 뿐만 아니라 loss function 기울기의 방향의 관성을 고려하여 학습하 는 Adam을 사용하였다. layer의 수의 조정에서는 data의 수가 적고 앞선 결과에서 underfitting 되었기 때문에, 모델 하단의 stem layer의 수를 줄이는 방법으로 조정하여 성능을 높였다. 도 5와 도 6은 이미지 분류와 태깅을 위해 태그1 분류기, 태그2 분류기, 태그3 분류기를 각각 학습하여 분류하 는 하나의 멀티 라벨 분류기와, 3개의 분류기를 입력된 하나의 이미지에 대해 각각 모두 다 적용하는 개념을 보 인 그림이다. 분류기(classifier) 의료 이미지가 입력되면, 각각의 분류기(classifier)는 정해진 태그에 대한 정해진 클래스로 분류한다. '신체부 위', '의과대학 과목', '사진 종류'에 대하여, 멀티 라벨 분류기는 의료 이미지에 대하여 신체부위, 의과대학 과목, 사진 종류에 대하여 각각 태그1- 신체부위 학습 분류기, 태그2- 의과대학 과목 학습 분류기2, 태그3- 사 진 종류 학습 분류기3를 사용하여 각각 학습하여 분류하며, 상기 3개의 분류기(classifier)를 입력된 하나의 이 미지에 대하여 모두 다 적용한다. 각각의 분류기는 모두 딥러닝의 이미지 분류 모델 inception resnet v2을 사용하여 특징점을 기계 학습시켰으며 적용하였다. 상기 멀티 라벨 분류기는, 상기 의료 이미지에 대하여 신체부위 학습 분류기1에 의해 '신체부위'를 학습하여 분 류하는 단계; 상기 의료 이미지에 대하여 의과대학 과목 학습 분류기2에 의해 '의과대학 과목'를 학습하여 분류 하는 단계; 및 상기 의료 이미지에 대하여 신체부위 학습 분류기3에 의해 '사진 종류'를 학습하여 분류하는 단 계를 포함하며, 3개의 분류기(classifier)에서 추론한 결과들을 합해 이미지의 tag가 결정되며, 입력된 하나의 의료 이미지에 대해 각각 분류기1로 분류하고, 분류기2로 분류하며, 분류기3로 분류하는 3 과정을 모두 거쳐 신체 부위, 영상 종류, 의과대학 과목 3가지에 대한 태그가 분류되고 태깅된다. 태그1 분류기(classifier)를 통해 '신체부위'의 추론이 진행된다. 머신 러닝의 기계 학습 시에는 의료 이미지들 을 입, 눈 귀 등 신체부위에 따라 나눈 뒤, 분류기(classfier)가 학습한다. 이미지를 태그1 분류기(classifie r)가 분류하는 경우 어느 신체부위 인지 최종적으로 출력된다. 태그2 분류기(classifier)를 통해 '의과대학 과목'의 추론이 진행된다. 학습 시에는 의료이미지들을 피부과학, 감각기학 등 의과대학 과목에 따라 나눈 뒤 분류기(classfier)가 학습한다. 이미지를 태그2 분류기(classifie r)가 분류하는 경우 어느 과목에 해당하는 이미지인지 최종적으로 출력된다. 태그3 분류기(classifier)를 통해 사진 이미지의 종류에 대한 추론이 진행된다. 학습 시에는 의료이미지들을 CT, X-ray, 실제 사진 등 영상종류에 따라 나눈 뒤 분류기(classfier)를 사용하여 학습한다. 이미지를 태그3 분 류기(classifier)가 분류하는 경우 어떤 종류의 영상인지 최종적으로 출력된다. 3개의 분류기(classifier)에서 추론한 결과들을 합해 이미지의 tag가 결정된다. 입력 이미지에 대해 태그1 분류 기로 분류하고, 태그2 분류기로 분류하며, 태그3 분류기로 분류하는 3가지 과정을 모두 거쳐 신체 부위, 의대 과목, 영상 종류 3가지에 대한 태그가 출력된다. 사용된 옵티마이저 본 연구는 여러개의 옵티마이저(optimizer)에 대한 실험을 진행하였으나 실제로 사용되는 옵티마이저는 adam 옵 티마이저를 사용하였다. 옵티마이저는 딥러닝 모델 학습시 경사하강법을 통해 손실함수의 최저값을 찾아가는 과 정에 사용된다. * Rmsprop RMSProp은 딥러닝의 대가 제프리 힌톤이 제안한 방법으로서, Adagrad의 단점을 해결하기 위한 방법이다. Adagrad의 식에서 gradient의 제곱값을 더해나가면서 구한 Gt 부분을 합이 아니라 지수평균으로 바꾸어 대체한 방법이다. 이렇게 대체를 할 경우 Adagrad처럼 Gt가 무한정 커지지 않으면서 최근 변화량의 변수 간 상대적인 크기 차이는 유지할 수 있다. 식으로 나타내면 다음과 같다."}
{"patent_id": "10-2019-0013113", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, G는 다차원 벡터로 time step t까지 각 변수가 이동한 의 제곱의 합을 저장한 값이다. θ는 딥러닝 모델의 파라미터, γ는 momentum을 얼마나 줄 것이에 대한 momentum term이다. 는 딥러닝 결과값과 실제 결과값의 차이를 정의하는 손실함수이다. 는 손실 함수의 변화량(기울기)이다. ε은 0으로 나누는 것을 방지하기 위한 값으로 이다. 은 미리 정해진 걸음의 크기 step size이다. 0.01~0.001의 값이다. t는 time step으로 딥러닝 파라미터 업데이트가 일어날 때 마다 1씩 증가한다. - Adagrad 식"}
{"patent_id": "10-2019-0013113", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "* AdaDelta AdaDelta (Adaptive Delta)는 RMSProp과 유사하게 AdaGrad의 단점을 보완하기 위해 제안된 방법이다. AdaDelta 는 RMSProp과 동일하게 G를 구할 때 합을 구하는 대신에 지수평균을 구한다. 다만, 여기에서는 step size를 단 순하게 η으로 사용하는 대신에 step size의 변화값의 제곱을 가지고 지수평균 값을 사용한다. s는 step size 변화값의 제곱이다. * Adam Adam (Adaptive Moment Estimation)은 지금까지 계산해온 기울기의 지수평균과 제곱 값의 지수평균을 저장한다. Adam에서는 m과 v가 처음에 0으로 초기화되어 있기 때문에 학습의 초반부에서는 , 가 0에 가깝게 bias 되 어있을 것이라고 판단하여 이를 unbiased 하게 만들어주는 작업을 거친다. 기울기의 지수평균 와 기울기의 제곱 평균 의 식을 ∑ 형태로 펼친 후 양변에 expectation을 씌워 정리해보면, 다음과 같은 보정을 통해 unbiased 된 expectation을 얻을 수 있다. 는 계산하는 기울기의 지수평균이다. 와 는 바이어스를 보정한 값이다."}
{"patent_id": "10-2019-0013113", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, 는 계산하는 기울기의 지수평균, 는 기울기의 제곱평균이다. 와 는 바이어스를 보정한 값이다. 이 보정된 expectation들을 가지고 다음 식과 같이 과 의 계산을 한다. 보통 β1 는 0.9, β2는 0.999, ε는 정도의 값을 사용한다."}
{"patent_id": "10-2019-0013113", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, β는 moment 추정을 위한 지수 감소율, β1는 를 위한 moment 추정을 위한 지수 감소율, β2는"}
{"patent_id": "10-2019-0013113", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "를 위한 moment 추정을 위한 지수 감소율이다. , 는 각각 타임 스텝에 따른 β1,β2값이다. ε은 0으로 나누는 것을 방지하기 위한 값으로 이다. 도 7은 사용된 딥러닝의 이미지 분류 모델은 inception resnet v2의 동작을 보인 그림이다. 사용된 딥러닝 모델 딥러닝 모델 : inception resnet v2[1] 가장 하단의 stem layer부터 시작해서 inception resnet A,B,C layer가 각각 10번, 20번씩 10번 반복이 된다. 그리고 stem layer와 inception resnet A,B,C layer사이에 reduction layer는 input의 사이즈를 줄이는 역할을 한다. inception resnet v2 사용시에, 빨간색, 주황색, 파란색 배경의 layer들은 각각 inception resnet A,B,C layer 이다. 이미지 가장 오른쪽의 layer부터 가장 왼쪽의 softmax까지 layer들을 통과하면서 학습된 결과에 따라 convolution 연산이 수행된다. convolution 연산의 결과가 각 classifier들이 분류하는 태그 값이 된다. 이미지가 가장 처음 통과하는 layer(stem layer)이며, Input Layer에서는 입력된 이미지를 299 x 299 크기로 변환한다. 입력 이미지는 R,G,B 칼라의 3가지 채널로 이루어져 있다. conv(convolution) 레이어에서는 깊이 32의 3x3 필터를 이용하여 분류를 위한 특징들을 찾는다. V는 valid padding을 의미한다. 레이어의 크기가 필터 크기에 따라 줄어든다. V가 없으면 이미지 크기가 그대로 유지되는 same padding를 의미한다. max pooling 레이어에서는 3x3 크기에 있는 픽셀들 중 최대값을 대표 값으 로 정해 이미지의 크기를 줄인다. 도 4는 신체 부위(입, 눈, 귀, 심장, 폐, 근육, 피부, 위장, 혈액세포, 심혈관계)별 정확도를 5장 정확도의 평 균을 통계적으로 표시한 막대 그래프이다. 정확도 측정을 위한 테스트를 위해 train data와 validation data에 포함되지 않은 신체부위별 5장의 이미지를 확보하였다. 각 이미지에 tag되는 3개의 tag값의 정확도를 평균 낸 값을 정확도로 정의하였다. 예를 들면, 3개 의 tag중 2개가 맞으면 66%, 1개만 맞으면 33%로 정확도가 측정된다. 도 4는 신체부위별 정확도를 나타낸 차트 이다. 해당 차트를 통해 알 수 있듯이 81.1%의 전체 정확도를 기록하였다. 4. 결과 제안된 이미지 Auto-Tagging 시스템의 성능을 분석하기 위해 3개 tag값 각각의 정확도를 평균내서 1개의 이미지 에 대한 정확도로 정의하였다. 예를 들면 tag값 3개중 1개만 맞은 경우 : 33% / 2개의 tag가 맞는 경우 : 66% 성능이 나왔다. Test data로는 1번째 tag값인 신체부위가 10개의 클래스로 수가 가장 많아서 신체부위별로 5장 씩 전체 50장의 이미지를 테스트 데이터로 사용하였다. 10종의 신체 부위에 따른 이미지 인식 정확도 측정 결과, 위와 같은 정확도 평균이 산출되었다. 명확한 이미지 들을 Test data로 선택한 것이 가장 큰 요인이라고 여겨진다. 태그1 분류기1(Classifier)의 정확도가 74%로 가 장 낮았는데 테스트 데이터에 대해 태그1 분류기1(Classifier)가 정확도가 높게 나왔기 때문이라고 보인다. 하 지만 CT 사진에서는 정확도가 다소 낮게 나왔다. 도 1을 참조하면 위, 심장, 폐의 CT(Computed Tomography) 사진, 4종의 CT 사진을 서로 비교하면 거의 차이가 없음을 알 수 있다. 학습 데이터를 살펴본 결과, 복부에 있는 부위의 CT 사진은 차이를 구별하기 힘든 것들이 많았다. 따라서, CT 사진의 구별에 있어서는 분류의 한계가 있다고 판단된다. 대분류, 중분류, 소분류는 담당 의료진이 눈으로 일일이 확인하여 분류한다. 결과적으로, CT, X-ray, 실제 사진의 의료 이미지에 tagging될 3개의 Tag field를 선정하였다. 각 Tagging Field별로 각각의 분류기(classifier 1, classifier 2, classifier 3)를 사용하였으며, 머신 러닝의 Supervised Learning에 따라 '사진 종류', '신체 부위', '의과대학 과목'에 따라 사전에 미리 의료 이미지들을 기계학습시켜 학습된 결과에 따라 의료 이미지들을 분류하는 3개의 분류기(Classifier1,2,3)들을 사용하였다. 본 연구는 CT, X-ray, 실제 사진의 의료 이미지에 대하여 각 classifier들은 딥러닝의 Tensorflow slim에서 지 원하는 모델 중 가장 성능이 좋은 Inception-resnet-v2[2] CNN모델을 사용하여 신경망 모델을 사용하여 학습시 켰다. CT, X-ray, 실제 사진의 의료 이미지에 대하여 '사진 종류', '신체 부위', '의과대학 과목'에 따라 이미지를 분 류하는 3개의 분류기(classifier 1,2,3)를 사용하여 이미지를 분류, 태깅하는 이미지 분류기와 Auto-Tagging 시 스템을 개발하였다. 이미지 분류 및 태깅을 위해, 신경망 모델을 사용하여 이미지를 학습하여 인식하고 분류하 며. 자동적으로 태그 정보를 저장하게 하였다. 이상에서 설명한 바와 같이, 본 발명의 방법은 프로그램으로 구현되어 컴퓨터의 소프트웨어를 이용하여 읽을 수 있는 형태로 기록매체(CD-ROM, RAM, ROM, 메모리 카드, 하드 디스크, 광자기 디스크, 스토리지 디바이스 등)에저장될 수 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행 하도록 구성된 모든 형태의 하드웨어 장치가 포함될 수 있다. 프로그램 명령의 예에는 컴파일러에 의해 만들어 지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해 실행될 수 있는 고급 언어 코 드를 포함할 수 있다. 이러한 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로 서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야에서 통상의 지식을 가진자가 하기의 특허 청구범위에 기재된 본 발명의 기술적 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수 정 또는 변형하여 실시할 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2019-0013113", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 머신 러닝의 기계 학습을 위한 위, 심장, 폐의 CT(Computed Tomography) 사진이다. 도 2는 본 발명에 따른 CT, X-ray, 실제 사진을 포함하는 의료 이미지에 대하여 '사진 종류' 분류기1, '신체부 위' 분류기2, '의과대학 과목' 분류기3를 포함하는 인공 지능 모듈 인 멀티 레벨 분류기(classifier)와 tagging 시스템을 구비하는 의료 이미지 태깅 및 분류 시스템 구성도이다. 도 3은 의과대학 교과과정과 학습에 사용된 신체부위 Ontology 구축 그림이다. 도 4는 신체 부위(입, 눈, 귀, 심장, 폐, 근육, 피부, 위장, 혈액세포, 심혈관계)별 정확도를 5장 정확도의 평 균을 통계적으로 표시한 막대 그래프이다. 도 5와 도 6은 이미지 분류와 태깅을 위해 태그1 분류기, 태그2 분류기, 태그3 분류기를 각각 학습하여 분류하 는 하나의 멀티 라벨 분류기와, 3개의 분류기를 입력된 하나의 이미지에 대해 각각 모두 다 적용하는 개념을 보 인 그림이다. 도 7은 사용된 딥러닝의 이미지 분류 모델은 inception resnet v2의 동작을 보인 그림이다."}
