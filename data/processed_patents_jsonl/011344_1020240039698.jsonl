{"patent_id": "10-2024-0039698", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0143968", "출원번호": "10-2024-0039698", "발명의 명칭": "웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 장치 및 방법", "출원인": "주식회사 툰스퀘어", "발명자": "이호영"}}
{"patent_id": "10-2024-0039698", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "웹툰 제작을 위한 웹툰 구성 요소를 입력하도록 입력 인터페이스를 제공하고, 상기 웹툰 제작의 과정을 표시하는 표시부; 및상기 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성과 관련된 동작을 제어하는 프로세서; 를 포함하고,상기 프로세서는,상기 입력 인터페이스를 통해 입력된 웹툰 구성 요소를 기반으로, 상기 웹툰 구성 요소에 연계되어 기 설정된적어도 하나의 캐릭터, 헤어, 의상 및 움직임을 포함하는 3D 에셋을 추출하며,상기 캐릭터, 헤어, 의상 및 움직임에 해당되는 제1 UI를 선택하도록, 상기 제1 UI를 상기 표시부 상에 표시하고,상기 선택된 캐릭터, 헤어, 의상 및 움직임을 기반으로, 3D 렌더링된 3D 이미지를 생성하며,상기 생성된 3D 이미지를 상기 표시부 상에 표시하는 것을 특징으로 하는, 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 장치."}
{"patent_id": "10-2024-0039698", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 3D 이미지를 생성할 때, 상기 캐릭터 중 제1 캐릭터의 특징점을 추출하고,상기 캐릭터 중 제2 캐릭터에 상기 제1 캐릭터의 특징점을 적용하기 위한 프리셋을 더 생성하며,상기 프리셋을 기반으로, 상기 제1 캐릭터의 특징점과 상기 제2 캐릭터의 특징점간의 유사도를 더 판단하고,상기 유사도가 기 설정된 높은 수준인 경우, 상기 제2 캐릭터에 상기 제1 캐릭터의 특징점을 적용하여 3D 이미지를 더 생성하며,상기 유사도가 기 설정된 낮은 수준인 경우, 상기 제2 캐릭터의 특징점을 추출하여 3D 이미지를 더 생성하는 것을 특징으로 하는, 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 장치."}
{"patent_id": "10-2024-0039698", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는,상기 3D 이미지를 기 설정된 Convolution filter를 적용하여 2D 이미지로 더 변환하고,상기 변환된 2D 이미지를 더 생성하는 것을 특징으로 하는, 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성장치."}
{"patent_id": "10-2024-0039698", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프로세서는,상기 2D 이미지를 생성할 때, 상기 변환된 2D 이미지의 픽셀 값을 더 산출하고,상기 2D 이미지의 픽셀 값에 연계되어 기 설정된 텍스처 매핑 정보와 라이팅 효과 정보를 더 추출하며,상기 텍스처 매핑 정보와 상기 라이팅 효과 정보를 상기 2D 이미지에 적용하여 최종 2D 이미지를 더 생성하는공개특허 10-2024-0143968-3-것을 특징으로 하는, 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 장치."}
{"patent_id": "10-2024-0039698", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 프로세서는,상기 2D 이미지를 생성할 때, 상기 변환된 2D 이미지의 객체 패턴과, 이전에 생성된 2D 이미지의 객체 패턴간의유사도를 더 판단하고,상기 유사도가 기 설정된 높은 수준인 경우, 상기 이전에 생성된 2D 이미지를 더 출력하며,상기 유사도가 기 설정된 낮은 수준인 경우, 상기 변환된 2D 이미지를 더 생성하는 것을 특징으로 하는, 웹툰제작을 위한 3D 에셋 기반의 이미지 생성 장치."}
{"patent_id": "10-2024-0039698", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 프로세서는,상기 3D 이미지를 생성할 때, 상기 입력 인터페이스를 통해 자연어 처리 모델 기반의 웹툰 구성 요소가 입력된경우, 상기 입력된 웹툰 구성 요소에 해당되는 사용자의 입력 문장을 더 획득하고,상기 입력 문장으로부터 문장의 인물 요소 및 동작 요소를 더 분할하며,상기 인물 요소 및 동작 요소를 기반으로, 상기 3D 렌더링된 3D 이미지를 더 생성하는 것을 특징으로 하는, 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 장치."}
{"patent_id": "10-2024-0039698", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 프로세서는,상기 동작 요소를 기반으로, 상기 인물 요소의 표정 및 포즈를 더 추정하고,상기 인물 요소의 표정 및 포즈를 기반으로, 상기 인물 요소의 위치 정보 및 방향 정보를 더 결정하며,상기 인물 요소의 위치 정보 및 방향 정보를 기반으로, 상기 3D 렌더링된 3D 이미지를 더 생성하는 것을 특징으로 하는, 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 장치."}
{"patent_id": "10-2024-0039698", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 프로세서는,상기 사용자의 입력 문장을 생성형 인공 지능 모델에 더 입력하고,상기 생성형 인공 지능 모델을 통해 생성된 캐릭터, 헤어, 의상 및 움직임에 해당되는 제2 UI를 더 선택하도록,상기 제2 UI를 상기 표시부 상에 더 표시하는 것을 특징으로 하는, 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 장치."}
{"patent_id": "10-2024-0039698", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "이미지 생성 장치에 의해 수행되는 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 방법에 있어서,상기 웹툰 제작을 위한 웹툰 구성 요소를 입력하도록 입력 인터페이스를 제공하는 단계;상기 입력 인터페이스를 통해 입력된 웹툰 구성 요소를 기반으로, 상기 웹툰 구성 요소에 연계되어 기 설정된적어도 하나의 캐릭터, 헤어, 의상 및 움직임을 포함하는 3D 에셋을 추출하는 단계;상기 캐릭터, 헤어, 의상 및 움직임에 해당되는 제1 UI를 선택하도록, 상기 제1 UI를 표시하는 단계;공개특허 10-2024-0143968-4-상기 선택된 캐릭터, 헤어, 의상 및 움직임을 기반으로, 3D 렌더링된 3D 이미지를 생성하는 단계; 및상기 생성된 3D 이미지를 표시하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2024-0039698", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터와 결합되어, 제9항의 방법을 실행시키기 위한 프로그램이 저장된 컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2024-0039698", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 웹툰 제작을 위한 웹툰 구성 요소를 입력하도록 입력 인터페이스를 제공하고, 웹툰 제작의 과정을 표 시하는 표시부; 및 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성과 관련된 동작을 제어하는 프로세서; 를 포함 하고, 프로세서는 입력 인터페이스를 통해 입력된 웹툰 구성 요소를 기반으로, 웹툰 구성 요소에 연계되어 기 설 정된 적어도 하나의 캐릭터, 헤어, 의상 및 움직임을 포함하는 3D 에셋을 추출하며, 캐릭터, 헤어, 의상 및 움직 임에 해당되는 제1 UI를 선택하도록, 제1 UI를 표시부 상에 표시하고, 선택된 캐릭터, 헤어, 의상 및 움직임을 기반으로, 3D 렌더링된 3D 이미지를 생성하며, 생성된 3D 이미지를 표시부 상에 표시하는 것을 특징으로 할 수 있다."}
{"patent_id": "10-2024-0039698", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2024-0039698", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 들어, AI(Artificial Intelligence) 기술의 발전으로, GAN(Generative Adversarial Networks), VAE(Variational AutoEncoder), Transformer 등의 이미지나 영상을 생성하는 모델이 개발되고 있다. 이를 통하여, 많은 업체들이 웹툰이나 그림, 동영상 등을 생성해주는 서비스를 제공하고 있다. 그런데, 종래 이미지 생성 장치는, 웹툰 제작에 필요한 시간과 노력을 줄이면서 고퀄리티의 작품을 제공하는데 에 한계가 있었다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허공보 10-2022-0120082(2022.08.30.공개)"}
{"patent_id": "10-2024-0039698", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에 개시된 실시예는, 장소에 구애받지 않고, 언제, 어디서나, 누구든지 웹툰을 손쉽고 빠르게 제작할 수 있는 것을 제공하는데 그 목적이 있다. 또한, 본 개시에 개시된 실시예는, 웹툰 제작에 필요한 시간과 노력을 줄이면서 고퀄리티의 작품을 제공할 수 있는 것을 제공하는데 그 목적이 있다. 또한, 본 개시에 개시된 실시예는, 캐릭터나 배경을 일일이 그리는 작업이 대거 줄어들어 생산성을 높일 수 있 는 것을 제공하는데 그 목적이 있다. 본 개시가 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0039698", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 본 개시의 일 측면에 따른 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 장치는, 웹툰 제작을 위한 웹툰 구성 요소를 입력하도록 입력 인터페이스를 제공하고, 상기 웹툰 제작의 과정을 표시하는 표시부; 및 상기 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성과 관련된 동작을 제어하는 프로세서; 를 포함하고, 상기 프로세서는 상기 입력 인터페이스를 통해 입력된 웹툰 구성 요소를 기반으로, 상기 웹툰 구 성 요소에 연계되어 기 설정된 적어도 하나의 캐릭터, 헤어, 의상 및 움직임을 포함하는 3D 에셋을 추출하며, 상기 캐릭터, 헤어, 의상 및 움직임에 해당되는 제1 UI를 선택하도록, 상기 제1 UI를 상기 표시부 상에 표시하 고, 상기 선택된 캐릭터, 헤어, 의상 및 움직임을 기반으로, 3D 렌더링된 3D 이미지를 생성하며, 상기 생성된 3D 이미지를 상기 표시부 상에 표시하는 것을 특징으로 할 수 있다. 또한, 상기 프로세서는 상기 3D 이미지를 생성할 때, 상기 캐릭터 중 제1 캐릭터의 특징점을 추출하고, 상기 캐 릭터 중 제2 캐릭터에 상기 제1 캐릭터의 특징점을 적용하기 위한 프리셋을 더 생성하며, 상기 프리셋을 기반으로, 상기 제1 캐릭터의 특징점과 상기 제2 캐릭터의 특징점간의 유사도를 더 판단하고, 상기 유사도가 기 설정 된 높은 수준인 경우, 상기 제2 캐릭터에 상기 제1 캐릭터의 특징점을 적용하여 3D 이미지를 더 생성하며, 상기 유사도가 기 설정된 낮은 수준인 경우, 상기 제2 캐릭터의 특징점을 추출하여 3D 이미지를 더 생성하는 것을 특 징으로 할 수 있다. 또한, 상기 프로세서는 상기 3D 이미지를 기 설정된 Convolution filter를 적용하여 2D 이미지로 더 변환하고, 상기 변환된 2D 이미지를 더 생성하는 것을 특징으로 할 수 있다. 또한, 상기 프로세서는 상기 2D 이미지를 생성할 때, 상기 변환된 2D 이미지의 픽셀 값을 더 산출하고, 상기 2D 이미지의 픽셀 값에 연계되어 기 설정된 텍스처 매핑 정보와 라이팅 효과 정보를 더 추출하며, 상기 텍스처 매 핑 정보와 상기 라이팅 효과 정보를 상기 2D 이미지에 적용하여 최종 2D 이미지를 더 생성하는 것을 특징으로 할 수 있다. 또한, 상기 프로세서는 상기 2D 이미지를 생성할 때, 상기 변환된 2D 이미지의 객체 패턴과, 이전에 생성된 2D 이미지의 객체 패턴간의 유사도를 더 판단하고, 상기 유사도가 기 설정된 높은 수준인 경우, 상기 이전에 생성 된 2D 이미지를 더 출력하며, 상기 유사도가 기 설정된 낮은 수준인 경우, 상기 변환된 2D 이미지를 더 생성하 는 것을 특징으로 할 수 있다. 또한, 상기 프로세서는 상기 3D 이미지를 생성할 때, 상기 입력 인터페이스를 통해 자연어 처리 모델 기반의 웹 툰 구성 요소가 입력된 경우, 상기 입력된 웹툰 구성 요소에 해당되는 사용자의 입력 문장을 더 획득하고, 상기 입력 문장으로부터 문장의 인물 요소 및 동작 요소를 더 분할하며, 상기 인물 요소 및 동작 요소를 기반으로, 상기 3D 렌더링된 3D 이미지를 더 생성하는 것을 특징으로 할 수 있다. 또한, 상기 프로세서는 상기 동작 요소를 기반으로, 상기 인물 요소의 표정 및 포즈를 더 추정하고, 상기 인물 요소의 표정 및 포즈를 기반으로, 상기 인물 요소의 위치 정보 및 방향 정보를 더 결정하며, 상기 인물 요소의 위치 정보 및 방향 정보를 기반으로, 상기 3D 렌더링된 3D 이미지를 더 생성하는 것을 특징으로 할 수 있다. 또한, 상기 프로세서는 상기 사용자의 입력 문장을 생성형 인공 지능 모델에 더 입력하고, 상기 생성형 인공 지 능 모델을 통해 생성된 캐릭터, 헤어, 의상 및 움직임에 해당되는 제2 UI를 더 선택하도록, 상기 제2 UI를 상기 표시부 상에 더 표시하는 것을 특징으로 할 수 있다. 또한, 본 개시의 다른 측면에 따른 이미지 생성 장치에 의해 수행되는 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 방법은, 상기 웹툰 제작을 위한 웹툰 구성 요소를 입력하도록 입력 인터페이스를 제공하는 단계; 상기 입 력 인터페이스를 통해 입력된 웹툰 구성 요소를 기반으로, 상기 웹툰 구성 요소에 연계되어 기 설정된 적어도 하나의 캐릭터, 헤어, 의상 및 움직임을 포함하는 3D 에셋을 추출하는 단계; 상기 캐릭터, 헤어, 의상 및 움직 임에 해당되는 제1 UI를 선택하도록, 상기 제1 UI를 표시하는 단계; 상기 선택된 캐릭터, 헤어, 의상 및 움직임 을 기반으로, 3D 렌더링된 3D 이미지를 생성하는 단계; 및 상기 생성된 3D 이미지를 표시하는 단계; 를 포함할 수 있다. 이 외에도, 본 개시를 구현하기 위한 실행하기 위한 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램이 더 제공될 수 있다. 이 외에도, 본 개시를 구현하기 위한 방법을 실행하기 위한 컴퓨터 프로그램을 기록하는 컴퓨터 판독 가능한 기 록 매체가 더 제공될 수 있다."}
{"patent_id": "10-2024-0039698", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 전술한 과제 해결 수단에 의하면, 장소에 구애받지 않고, 언제, 어디서나, 누구든지 웹툰을 손쉽고 빠르게 제작할 수 있다. 또한, 본 개시의 전술한 과제 해결 수단에 의하면, 웹툰 제작에 필요한 시간과 노력을 줄이면서 고퀄리티의 작 품을 제공할 수 있다. 또한, 본 개시의 전술한 과제 해결 수단에 의하면, 캐릭터나 배경을 일일이 그리는 작업이 대거 줄어들어 생산 성을 높일 수 있다. 본 개시의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0039698", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 개시가 실시예들의 모든 요소들을 설명하"}
{"patent_id": "10-2024-0039698", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 것은 아니며, 본 개시가 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한다. 명세서에서 사용되는 '부, 모듈, 부재, 블록' 이라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실 시예들에 따라 복수의 '부, 모듈, 부재, 블록'이 하나의 구성요소로 구현되거나, 하나의 '부, 모듈, 부재, 블록'이 복수의 구성요소들을 포함하는 것도 가능하다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐 아니라, 간접적으로 연결되어 있는 경우를 포함하고, 간접적인 연결은 무선 통신망을 통해 연결되는 것을 포함 한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\" 위치하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존재하는 경우도 포함한다. 제 1, 제 2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 본 개시의 작용 원리 및 실시예들에 대해 설명한다. 본 개시는, 입력 인터페이스를 통해 입력된 웹툰 구성 요소를 기반으로, 웹툰 구성 요소에 연계되어 기 설정된 적어도 하나의 캐릭터, 헤어, 의상 및 움직임을 포함하는 3D 에셋을 추출하며, 캐릭터, 헤어, 의상 및 움직임에 해당되는 제1 UI를 선택하도록, 제1 UI를 표시부 상에 표시하고, 선택된 캐릭터, 헤어, 의상 및 움직임을 기반 으로, 3D 렌더링된 3D 이미지를 생성하며, 생성된 3D 이미지를 표시부 상에 표시할 수 있다. 이러한, 본 개시는, 장소에 구애받지 않고, 언제, 어디서나, 누구든지 웹툰을 손쉽고 빠르게 제작할 수 있다. 또한, 본 개시는, 웹툰 제작에 필요한 시간과 노력을 줄이면서 고퀄리티의 작품을 제공할 수 있다. 또한, 본 개 시는, 캐릭터나 배경을 일일이 그리는 작업이 대거 줄어들어 생산성을 높일 수 있다. 이하에서는, 본 개시의 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 장치를 자세하게 살펴보기로 한다. 도 1은 본 개시의 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 장치를 나타낸 도면이다. 도 1을 참조하면, 이미지 생성 장치는 표시부, 메모리, 프로세서를 포함할 수 있다. 표시부는 웹툰 제작을 위한 웹툰 구성 요소를 입력하도록 입력 인터페이스를 제공하고, 웹툰 제작의 과정 을 표시할 수 있다. 제어부는 본 장치 내의 구성요소들의 동작을 제어하기 위한 알고리즘 또는 알고리즘을 재현한 프로그램에 대한 데이터를 저장하는 메모리, 및 메모리에 저장된 데이터를 이용하여 전술한 동작을 수행하는 적어도 하나의 프로세서로 구현될 수 있다. 여기에서, 메모리와 프로세서는 각각 별개의 칩으로 구현될 수 있다. 또한, 메모리와 프로세서는 단일 칩으로 구현될 수도 있다. 메모리는 본 장치의 다양한 기능을 지원하는 데이터와, 제어부의 동작을 위한 프로그램을 저장할 수 있고, 입/출력되는 데이터들을 저장할 있고, 본 장치에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 본 장치의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 이러한, 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), SSD 타입 (Solid State Disk type), SDD 타입(Silicon Disk Drive type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(random access memory; RAM), SRAM(static random access memory), 롬(read-only memory; ROM), EEPROM(electrically erasable programmable read-only memory), PROM(programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스 크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 또한, 메모리는 본 장치와는 분리되어 있으나, 유선 또는 무선으로 연결된 데이터베이스가 될 수도 있다. 메모리는 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성과 관련된 데이터를 저장할 수 있다. 프로세서 는 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성과 관련된 동작을 제어할 수 있다. 프로세서는 입력 인터페이스를 통해 입력된 웹툰 구성 요소를 기반으로, 웹툰 구성 요소에 연계되어 기 설 정된 적어도 하나의 캐릭터, 헤어, 의상 및 움직임을 포함하는 3D 에셋을 추출할 수 있다. 이때, 프로세서(13 0)는 캐릭터, 헤어, 의상 및 움직임에 해당되는 제1 UI를 선택하도록, 제1 UI를 표시부 상에 표시할 수 있 다. 또한, 프로세서는 선택된 캐릭터, 헤어, 의상 및 움직임을 기반으로, 3D 렌더링된 3D 이미지를 생성할 수 있다. 이때, 프로세서는 생성된 3D 이미지를 표시부 상에 표시할 수 있다. 프로세서는 3D 이미지를 생성할 때, 캐릭터 중 제1 캐릭터의 특징점을 추출할 수 있다. 이때, 프로세서 는 캐릭터 중 제2 캐릭터에 제1 캐릭터의 특징점을 적용하기 위한 프리셋을 더 생성할 수 있다. 또한, 프로세서는 프리셋을 기반으로, 제1 캐릭터의 특징점과 제2 캐릭터의 특징점간의 유사도를 더 판단 할 수 있다. 여기에서, 프로세서는 유사도가 기 설정된 높은 수준인 경우, 제2 캐릭터에 제1 캐릭터의 특 징점을 적용하여 3D 이미지를 더 생성할 수 있다. 이때, 프로세서는 유사도가 기 설정된 낮은 수준인 경우, 제2 캐릭터의 특징점을 추출하여 3D 이미지를 더 생성할 수 있다. 프로세서는 3D 이미지를 기 설정된 Convolution filter를 적용하여 2D 이미지로 더 변환하고, 변환된 2D 이미지를 더 생성할 수 있다. 프로세서는 2D 이미지를 생성할 때, 변환된 2D 이미지의 픽셀 값을 더 산출할 수 있다. 여기에서, 프로세 서는 2D 이미지의 픽셀 값에 연계되어 기 설정된 텍스처 매핑 정보와 라이팅 효과 정보를 더 추출할 수 있 다. 이때, 프로세서는 텍스처 매핑 정보와 라이팅 효과 정보를 2D 이미지에 적용하여 최종 2D 이미지를 더 생성할 수 있다. 프로세서는 2D 이미지를 생성할 때, 변환된 2D 이미지의 객체 패턴과, 이전에 생성된 2D 이미지의 객체 패 턴간의 유사도를 더 판단할 수 있다. 여기에서, 프로세서는 유사도가 기 설정된 높은 수준인 경우, 이전에 생성된 2D 이미지를 더 출력할 수 있다. 이때, 프로세서는 유사도가 기 설정된 낮은 수준인 경우, 변환된 2D 이미지를 더 생성할 수 있다. 프로세서는 3D 이미지를 생성할 때, 입력 인터페이스를 통해 자연어 처리 모델 기반의 웹툰 구성 요 소가 입력된 경우, 입력된 웹툰 구성 요소에 해당되는 사용자의 입력 문장을 더 획득할 수 있다. 여기에서, 프 로세서는 입력 문장으로부터 문장의 인물 요소 및 동작 요소를 더 분할할 수 있다. 이때, 프로세서는 인물 요소 및 동작 요소를 기반으로, 3D 렌더링된 3D 이미지를 더 생성할 수 있다. 프로세서는 동작 요소를 기반으로, 인물 요소의 표정 및 포즈를 더 추정할 수 있다. 여기에서, 프로세서 는 인물 요소의 표정 및 포즈를 기반으로, 동작 요소를 수행하는 인물 요소의 위치 정보 및 방향 정보를 더 결정할 수 있다. 이때, 인물 요소의 위치 정보 및 방향 정보를 기반으로, 3D 렌더링된 3D 이미지를 더 생성 할 수 있다. 프로세서는 사용자의 입력 문장을 생성형 인공 지능 모델에 더 입력할 수 있다. 이때, 프로세서(13 0)는 생성형 인공 지능 모델을 통해 생성된 캐릭터, 헤어, 의상 및 움직임에 해당되는 제2 UI를 더 선택하 도록, 제2 UI를 표시부 상에 더 표시할 수 있다. 도 2 내지 도 7을 참조하면, 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 방법은, 제공 단계(S210), 추출 단 계(S220), 표시 단계(S230, S250), 생성 단계(S240)를 포함할 수 있다.프로세서는 웹툰 제작을 위한 웹툰 구성 요소를 입력하도록 입력 인터페이스를 제공할 수 있다(S210). 이 때, 웹툰 구성 요소는 웹툰 제작을 위한 캐릭터, 캐릭터의 헤어, 캐릭터의 의상, 캐릭터의 움직임, 캐릭터의 말 풍선 및 캐릭터 주변의 배경 효과 등일 수 있다. 프로세서는 입력 인터페이스를 통해 입력된 웹툰 구성 요소를 기반으로, 웹툰 구성 요소에 연계되어 기 설 정된 적어도 하나의 캐릭터, 헤어, 의상 및 움직임을 포함하는 3D 에셋을 추출할 수 있다(S220). 또한, 프로세 서는 웹툰 구성 요소에 연계되어 기 설정된 말풍선 및 주변의 배경 효과를 포함하는 3D 에셋을 추출할 수 도 있다. 이때, 프로세서는 캐릭터, 헤어, 의상 및 움직임에 해당되는 제1 UI를 선택하도록, 제1 UI를 표시부 상에 표시할 수 있다(S230). 또한, 프로세서는 말풍선 및 주변의 배경에 해당되는 제1 UI를 선택하도록, 제1 UI를 표시부 상에 표시할 수 있다. 예를 들어, 도 3 내지 도 6에 도시된 바와 같이 프로세서는 캐릭터에 해당되는 제11 UI(D1)를 선택하도록, 제11 UI(D1)를 표시부 상에 표시할 수 있다. 또한, 프로세서는 헤어에 해당되는 제12 UI(D2)를 선택 하도록, 제12 UI(D2)를 표시부 상에 표시할 수 있다. 또한, 프로세서는 의상에 해당되는 제13 UI(D 3)를 선택하도록, 제13 UI(D3)를 표시부 상에 표시할 수 있다. 또한, 프로세서는 움직임에 해당되는 제14 UI(D4)를 선택하도록, 제14 UI(D4)를 표시부 상에 표시할 수 있다. 또한, 프로세서는 배경 효과 에 해당되는 제15 UI(D5)를 선택하도록, 제15 UI(D5)를 표시부 상에 표시할 수 있다. 프로세서는 선택된 캐릭터, 헤어, 의상 및 움직임을 기반으로, 3D 렌더링된 3D 이미지를 생성할 수 있다 (S240). 이때, 프로세서는 생성된 3D 이미지(C1 내지 C3)를 표시부 상에 표시할 수 있다(S250). 또 다른 예를 들어, 도 5 및 도 6에 도시된 바와 같이 프로세서는 캐릭터(C2, C3)의 움직임 및 각도 등을 확인하고 조절하도록, 스크롤 바에 해당되는 제16 UI(D6)를 표시부 상에 표시할 수 있다. 또 다른 예를 들어, 도 7에 도시된 바와 같이 프로세서는 캐릭터(C3)의 말풍선 도구에 해당되는 제17 UI(D7)를 표시부 상에 표시할 수 있다. 이때, 프로세서는 제17 UI(D7)를 통해 말풍선의 대사가 선택 된 경우, 캐릭터(C3)의 주변에 말풍선에 해당되는 제18 UI(D8)를 표시할 수 있다. 이때, 제18 UI(D8)는 말풍선 의 대사를 편집할 수 있도록 제공될 수 있다. 도 8을 참조하면, 프로세서는 3D 이미지를 생성할 때, 캐릭터 중 제1 캐릭터의 특징점을 추출할 수 있다 (S241a). 프로세서는 캐릭터 중 제2 캐릭터에 제1 캐릭터의 특징점을 적용하기 위한 프리셋을 생성할 수 있다 (S241b). 여기에서, 프리셋은 웹툰을 손쉽게 제작하기 위해, 사용자가 복수개의 캐릭터에 대해 각각의 헤어, 각 각의 의상, 각각의 움직임, 각각의 말풍선 및 각각의 주변의 배경 효과 등을 미리 저장해둔 후, 나중에 불러와 서 사용하는 기능이다. 프로세서는 프리셋을 기반으로, 제1 캐릭터의 특징점과 제2 캐릭터의 특징점간의 유사도를 판단할 수 있다 (S241c). 예를 들어, 프로세서는 제1 캐릭터 및 제2 캐릭터에 대해 각각의 헤어 특징점, 각각의 의상 특징 점, 각각의 움직임 특징점, 각각의 말풍선 특징점 및 각각의 배경 효과 특징점 중 적어도 하나의 유사도를 판단 할 수 있다. 프로세서는 유사도가 기 설정된 높은 수준인 경우, 제2 캐릭터에 제1 캐릭터의 특징점을 적용하여 3D 이미 지를 생성할 수 있다(S241d). 예를 들어, 프로세서는 제2 캐릭터에 대해 제1 캐릭터의 헤어 특징점, 의상 특징점, 움직임 특징점, 말풍선 특징점 및 배경 효과 특징점 중 적어도 하나를 적용하여 3D 이미지를 생성할 수 있다. 이러한, 본 개시는 제1 캐릭터의 특징점과 제2 캐릭터의 특징점간의 유사도를 기반으로, 제2 캐릭터에 제1 캐릭 터의 특징점을 적용할 수 있으므로, 웹툰을 손쉽고 빠르게 제작할 수 있다. 프로세서는 유사도가 기 설정된 낮은 수준인 경우, 제2 캐릭터의 특징점을 추출하여 3D 이미지를 생성할 수 있다(S241e). 예를 들어, 프로세서는 제2 캐릭터의 헤어 특징점, 의상 특징점, 움직임 특징점, 말풍선 특징점 및 배경 효과 특징점 중 적어도 하나를 추출하여 3D 이미지를 생성할 수 있다. 도 9를 참조하면, 프로세서는 3D 이미지를 기 설정된 Convolution filter를 적용하여 2D 이미지로 변환할 수도 있다(S261). 이러한, Convolution filter는 3D 이미지를 2D 이미지로 변환시에, 사용자의 위치나 취향에따라 2D 이미지의 왜곡을 달리하여 변화를 줄 수 있으므로, 다양한 2D 이미지 효과를 연출할 수 있다. 프로세서는 변환된 2D 이미지를 생성하고(S262), 생성된 2D 이미지를 표시부 상에 표시할 수도 있다 (S263). 이때, 표시부는 Convolution filter를 통해 필터링된 다양한 2D 이미지 효과를 표시할 수 있다. 도 10을 참조하면, 프로세서는 2D 이미지를 생성할 때, 변환된 2D 이미지의 객체 패턴과, 이전에 생성된 2D 이미지의 객체 패턴을 추출할 수 있다(S262a). 예를 들어, 객체 패턴은 헤어, 의상, 움직임, 말풍선 및 배경 효과 중 적어도 하나를 포함할 수 있다. 프로세서는 변환된 2D 이미지의 객체 패턴과, 이전에 생성된 2D 이미지의 객체 패턴간의 유사도를 판단할 수 있다(S262b). 예를 들어, 프로세서는 변환된 2D 이미지의 헤어, 의상, 움직임, 말풍선 및 배경 효과 중 적어도 하나와, 이전에 생성된 2D 이미지의 헤어, 의상, 움직임, 말풍선 및 배경 효과 중 적어도 하나간의 유사 도를 판단할 수 있다. 프로세서는 유사도가 기 설정된 높은 수준인 경우, 이전에 생성된 2D 이미지를 출력할 수 있다(S262c). 예 를 들어, 프로세서는 이전에 생성된 헤어, 의상, 움직임, 말풍선 및 배경 효과 중 적어도 하나가 포함된 2D 이미지를 출력할 수 있다. 프로세서는 유사도가 기 설정된 낮은 수준인 경우, 변환된 2D 이미지를 생성할 수 있다(S262d). 예를 들어, 프로세서는 헤어, 의상, 움직임, 말풍선 및 배경 효과 중 적어도 하나가 포함된 2D 이미지를 생성할 수 있다. 이러한, 본 개시는 변환된 2D 이미지의 객체 패턴과, 이전에 생성된 2D 이미지의 객체 패턴간의 유사도를 기반 으로, 이전에 생성된 2D 이미지를 활용할 수 있으므로, 웹툰을 손쉽고 빠르게 제작할 수 있다. 도 11을 참조하면, 프로세서는 2D 이미지를 생성할 때, 변환된 2D 이미지의 픽셀 값을 산출할 수 있다 (S271). 프로세서는 2D 이미지의 픽셀 값에 연계되어 기 설정된 텍스처 매핑 정보와 라이팅 효과 정보를 추출할 수 있다(S272). 이때, 텍스처 매핑 정보는 2D 이미지 내의 객체에 색이나 질감 등을 표현한 것이고, 라이팅 효과 정보는 2D 이미지 내의 객체 또는 배경에 조명 효과를 적용한 것일 수 있다. 프로세서는 텍스처 매핑 정보와 라이팅 효과 정보를 2D 이미지에 적용하여 최종 2D 이미지를 생성하고 (S273), 생성된 최종 2D 이미지를 표시부 상에 표시할 수도 있다(S274). 이러한, 본 개시는 텍스처 매핑과 라이팅 효과가 효율적으로 적용된 다양한 2D 이미지 효과를 제공할 수 있다. 도 12를 참조하면, 프로세서는 3D 이미지를 생성할 때, 입력 인터페이스를 통해 자연어 처리 모델(Natural Language Processing, 131) 기반의 웹툰 구성 요소가 입력된 경우(S242a), 입력된 웹툰 구성 요소에 해당되는 사용자의 입력 문장을 획득할 수 있다(S242b). 예를 들어, 사용자의 입력 문장은 컷트 및 파마 등의 헤어일 수 있고, 치마 및 바지 등의 의상일 수 있으며, 손들기 및 걷기 등의 움직임일 수 있고, 빨리 소식을 전해줘야지 등의 말풍선일 수 있으며, 그림자 및 윤곽선 등의 배경 효과일 수 있다. 프로세서는 입력 문장으로부터 문장의 인물 요소, 동작 요소 및 배경 효과 요소를 분할할 수 있다(S242c). 예들 들어, 문장의 인물 요소는 남자, 여자, 컷트, 파마, 치마 및 바지 등을 포함할 수 있고, 문장의 동작 요소 는 손드는 동작 및 걷는 동작 등을 포함할 수 있으며, 문장의 배경 효과 요소는 그림자 및 윤곽선 등을 포함할 수 있다. 프로세서는 인물 요소, 동작 요소 및 배경 효과 요소를 기반으로, 3D 렌더링된 3D 이미지를 생성할 수 있 다(S242d). 예를 들어, 프로세서는 남자, 컷트, 바지, 걷는 동작, 그림자를 기반으로, 3D 렌더링된 3D 이 미지를 생성할 수 있다. 이러한, 본 개시는 자연어 처리 모델을 기반으로, 입력된 웹툰 구성 요소에 해당되는 사용자의 입력 문장 을 획득하고, 문장의 인물 요소, 동작 요소 및 배경 효과 요소를 분할하여 3D 렌더링된 3D 이미지를 생성할 수 있으므로, 웹툰을 손쉽고 빠르게 제작할 수 있다. 도 13을 참조하면, 프로세서는 인물 요소, 동작 요소 및 배경 효과 요소에 연계되어 기 설정된 3D 이미지 의 밝기, 색, 대사가 기재된 말풍선을 포함하는 3D 에셋을 추출할 수 있다(S242e). 프로세서는 3D 이미지 의 밝기, 색, 대사가 기재된 말풍선을 기반으로, 3D 렌더링된 3D 이미지를 최종 생성할 수 있다(S242f).이러한, 본 개시는 인물 요소, 동작 요소 및 배경 효과 요소에 연계되어 기 설정된 3D 이미지의 밝기, 색, 대사 가 기재된 말풍선을 포함하는 3D 에셋을 추출하여 3D 렌더링된 3D 이미지를 최종 생성할 수 있으므로, 웹툰을 손쉽고 빠르게 제작할 수 있다. 도 14를 참조하면, 프로세서는 동작 요소를 기반으로, 인물 요소의 표정 및 포즈를 추정할 수 있다 (S242d1). 여기에서, 프로세서는 표정 추정 알고리즘 및 포즈 추정 알고리즘을 이용하여, 분할된 인물 요 소의 표정 및 포즈를 추정할 수 있다. 이때, 프로세서는 표정 추정 알고리즘 및 포즈 추정 알고리즘을 이 용하여 인물 요소의 표정 형태 및 관절 위치를 파악할 수 있다. 프로세서는 인물 요소의 표정 및 포즈를 기반으로, 동작 요소를 수행하는 인물 요소의 위치 및 방향 정보 를 결정할 수 있다(S242d2). 프로세서는 인물 요소의 위치 및 방향 정보를 기반으로, 3D 렌더링된 3D 이미 지를 생성할 수 있다(S242d3). 여기에서, 프로세서는 LSTM(Long Short-Term Memory)을 이용하여 입력 문 장에 포함된 인물 요소의 현재 위치, 이동 위치, 현재 자세, 이동 자세, 이동 거리를 기반으로, 3D 렌더링된 3D 이미지를 생성할 수 있다. 도 15를 참조하면, 프로세서는 사용자의 입력 문장을 생성형 인공 지능 모델(Generative AI, 132)에 입력 할 수 있다. 이때, 생성형 인공 지능 모델은 원하는 이미지를 생성할 수 있다. 여기에서, 프로세서는 생성형 인공 지능 모델을 통해 생성된 캐릭터, 헤어, 의상 및 움직임에 해당되는 제2 UI를 선택하도록, 제 2 UI를 표시부 상에 표시할 수 있다. 이때, 프로세서는 생성된 캐릭터에 해당되는 제21 UI(D9)를 선택하도록, 제21 UI(D9)를 표시부 상에 표시할 수 있다. 또한, 프로세서는 생성된 헤어에 해당되는 제22 UI(D10)를 선택하도록, 제22 UI(D10)를 표시부 상에 표시할 수 있다. 또한, 프로세서는 생성된 의상에 해당되는 제23 UI(D11)를 선택하도록, 제23 UI(D11)를 표시부 상에 표시할 수 있다. 또한, 프로세서는 생성된 움직임에 해당되는 제24 UI(D12)를 선택하도록, 제24 UI(D12)를 표시부 상에 표시할 수 있다. 예를 들어, 프로세서는 사용자의 입력 문장에 남자 추가, 파마머리 추가, 바지 추가, 손흔들기 추가 등이 포함된 경우, 생성형 인공 지능 모델을 통해 생성된 남자 캐릭터, 파마머리, 바지, 손흔들기에 해당되는 각각의 제21 UI(D9) 내지 제24 UI(D12)를 선택하도록, 각각의 제21 UI(D9) 내지 제24 UI(D12)를 표시부 상에 표시할 수 있다. 이러한, 본 개시는 생성형 인공 지능 모델을 통해 생성된 캐릭터, 헤어, 의상 및 움직임에 해당되는 제2 UI를 선택하도록, 제2 UI를 표시부 상에 표시할 수 있으므로, 웹툰을 더욱 손쉽고 빠르게 제작할 수 있다. 본 개시는, 캐릭터의 맞춤형 헤어, 의상, 움직임, 말풍선 및 배경 효과에 해당되는 제3 UI를 더 선택하도록, 제 3 UI를 표시부 상에 더 표시할 수도 있다. 이러한, 본 개시는 맞춤형으로 캐릭터의 헤어, 의상, 움직임, 말풍선 및 배경 효과를 동시에 제공할 수 있으므로, 웹툰을 더욱 손쉽고 빠르게 제작할 수 있다. 본 개시는, 사용자가 웹툰으로 완성하게 될 3D 캐릭터, 배경, 소품 등을 선택하고 자유롭게 배치할 수 있다. 본 개시는, 3D 에셋 기반의 웹툰 제작을 위한 필수 도구와 기능을 제공함으로써, 사용자가 3D 캐릭터를 선택하 고 이를 배치할 수 있는 캔버스 영역에서, 캐릭터의 헤어, 의상, 동작, 움직임, 효과 및 화면의 앵글, 각도 조 절 등을 자유롭게 조작할 수 있으므로, 웹툰 제작을 보다 손쉽고 편리하게 제공할 수 있다. 이때, 본 개시는, 웹툰의 각 장면에 대한 카메라 각도와 이동, 캐릭터의 포즈 및 애니메이션, 대화 말풍선 및 캡션 등을 직관적으 로 편집할 수 있다. 또한, 본 개시는, 웹툰 이미지 파일 외에도 다양한 문서 형식(pdf, ppt) 및 gif 파일로 내 보내는 기능을 제공할 수 있다. 본 개시에서, 각 3D 에셋은 다양한 스타일과 디자인으로 편집 가능하며, 사용자가 선택한 에셋으로 웹툰의 분위 기와 스토리를 구성할 수 있으므로, 웹툰 작가들 뿐만 아니라 그림 실력이 없는 일반인도 3D 에셋을 활용하여 높은 퀄리티의 웹툰을 보다 빠르고 쉽게 제작할 수 있다. 본 개시는, 3D 에셋을 이용해 활용도가 높고 단순 반복적인 작업을 줄이며 이미지를 창작하므로, 작가들이 캐릭 터나 배경을 일일이 그리는 작업이 대거 줄어들어 생산성을 높일 수 있다. 본 개시는, 사용자가 만든 웹툰을 저장하고 관리할 수 있는 클라우드 기반의 서비스를 제공하여 사용자가 자신 의 작품을 클라우드에 저장하고 언제 어디서든 쉽게 접근할 수 있다. 본 개시는, 공유 기능을 통해 여러 작가들이 협업하여 웹툰을 제작할 수 있고, 웹툰 작가들과 일반 사용자들에 게 웹툰 제작에 필요한 시간과 노력을 줄이면서 고퀄리티의 작품을 만들 수 있으며, 클라우드 기반의 서비스를 통해 보다 편리하게 작품을 관리하고 공유할 수 있다. 본 개시에서, 사용자가 선택한 기본 3D 에셋은 화면 설정 기능을 통해 고급 3D 콘텐츠 또는 웹툰형 2D 이미지로 실시간으로 렌더링되어 출력 가능하며, 장면 편집 과정에서 필터 기능을 통해 다양한 웹툰형 2D 이미지로 편집 가능하다. 도 1, 도 3 내지 도 7, 도 15에 도시된 구성 요소들의 성능에 대응하여 적어도 하나의 구성요소가 추가되거나 삭제될 수 있다. 또한, 구성 요소들의 상호 위치는 시스템의 성능 또는 구조에 대응하여 변경될 수 있다는 것은 당해 기술 분야에서 통상의 지식을 가진 자에게 용이하게 이해될 것이다. 도 2, 도 8 내지 도 14는 복수의 단계를 순차적으로 실행하는 것으로 기재하고 있으나, 이는 본 실시예의 기술"}
{"patent_id": "10-2024-0039698", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술분야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 도 2, 도 8 내지 도 14에 기재된 순서를 변경하여 실행 하거나 복수의 단계 중 하나 이상의 단계를 병렬적으로 실행하는 것으로 다양하게 수정 및 변형하여 적용 가능 할 것이므로, 도 2, 도 8 내지 도 14는 시계열적인 순서로 한정되는 것은 아니다. 한편, 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 기록매체의 형태로 구현될 수 있다. 명 령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽을 수 있는 기록매체로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록매체로는 컴퓨터에 의하여 해독될 수 있는 명령어가 저장된 모든 종류의 기록 매체 를 포함한다. 예를 들어, ROM(Read Only Memory), RAM(Random Access Memory), 자기 테이프, 자기 디스크, 플 래쉬 메모리, 광 데이터 저장장치 등이 있을 수 있다."}
{"patent_id": "10-2024-0039698", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 개시가 속하는 기술분야에서 통상 의 지식을 가진 자는 본 개시의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 개시가 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다."}
{"patent_id": "10-2024-0039698", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 장치를 나타낸 도면이다. 도 2 내지 도 15는 본 개시의 웹툰 제작을 위한 3D 에셋 기반의 이미지 생성 과정을 나타낸 도면들이다."}
