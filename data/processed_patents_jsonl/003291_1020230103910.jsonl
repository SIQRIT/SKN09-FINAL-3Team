{"patent_id": "10-2023-0103910", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0022995", "출원번호": "10-2023-0103910", "발명의 명칭": "인공지능을 이용한 테더 드론 기반의 안전관리 방법 및 시스템", "출원인": "주식회사 만물공작소", "발명자": "정봉현"}}
{"patent_id": "10-2023-0103910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "단말의 적어도 하나의 프로세서에 의하여 실행되는 관제 애플리케이션이 수행하는 인공지능을 이용한 테더 드론기반의 안전관리 방법으로서,상기 테더 드론으로부터 관제 대상 지역에 대한 제1 모니터링 영상을 실시간으로 획득하는 단계;딥러닝 뉴럴 네트워크를 기초로 상기 제1 모니터링 영상에 대한 인파 밀집도를 산출하는 단계;상기 산출된 인파 밀집도에 따른 인파 사고 가능성을 예측하는 단계;상기 인파 밀집도 및 상기 인파 사고 가능성을 표시하는 비주얼 콘텐츠를 생성하는 단계;상기 생성된 비주얼 콘텐츠를 상기 제1 모니터링 영상에 적용한 제1 가공 모니터링 영상을 제공하는 단계; 및상기 제1 가공 모니터링 영상에 따라 상황별 솔루션을 제공하는 단계;를 포함하는인공지능을 이용한 테더 드론 기반의 안전관리 방법."}
{"patent_id": "10-2023-0103910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 제1 모니터링 영상을 실시간으로 획득하는 단계는,적어도 하나 이상의 촬영 스팟 중 제1 촬영 스팟을 결정하는 단계와,상기 제1 촬영 스팟에서 테더 드론이 관제 대상 지역을 촬영하도록 테더 드론 어셈블리의 장력 제어부를 제어하는 단계와,상기 결정된 제1 촬영 스팟에서 촬영된 제1 모니터링 영상을 획득하는 단계를 포함하는인공지능을 이용한 테더 드론 기반의 안전관리 방법."}
{"patent_id": "10-2023-0103910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 제1 모니터링 영상에 대한 인파 밀집도를 산출하는 단계는,제1 딥러닝 뉴럴 네트워크를 기초로 상기 관제 대상 지역의 실제 면적을 획득하는 단계와,제2 딥러닝 뉴럴 네트워크를 기초로 상기 관제 대상 지역 내의 사람 수를 획득하는 단계와,상기 획득된 관제 대상 지역의 실제 면적 대비 사람 수를 기초로 인파 밀집도를 산출하는 단계를 포함하는인공지능을 이용한 테더 드론 기반의 안전관리 방법."}
{"patent_id": "10-2023-0103910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 관제 대상 지역의 실제 면적을 획득하는 단계는,복수 개의 모니터링 영상을 상기 제1 딥러닝 뉴럴 네트워크에 입력하는 단계와,상기 제1 딥러닝 뉴럴 네트워크로부터 출력된 관제 대상 지역의 실제 면적을 획득하는 단계를 포함하는 인공지능을 이용한 테더 드론 기반의 안전관리 방법."}
{"patent_id": "10-2023-0103910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2025-0022995-3-제3 항에 있어서,상기 관제 대상 지역 내의 사람 수를 획득하는 단계는,상기 제1 모니터링 영상을 상기 제2 딥러닝 뉴럴 네트워크에 입력하는 단계와,상기 제2 딥러닝 뉴럴 네트워크로부터 출력된 관제 대상 지역 내의 실제 사람 수를 획득하는 단계를 포함하는인공지능을 이용한 테더 드론 기반의 안전관리 방법."}
{"patent_id": "10-2023-0103910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 인파 사고 가능성을 예측하는 단계는,상기 산출된 인파 밀집도의 값 별로 소정의 파라미터를 할당한 적어도 하나 이상의 단계를 기 설정하는 단계와,각각의 상기 단계별로 인파 사고 가능성을 값으로 기 매칭하는 단계를 포함하는인공지능을 이용한 테더 드론 기반의 안전관리 방법."}
{"patent_id": "10-2023-0103910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 비주얼 콘텐츠를 생성하는 단계는,상기 제1 모니터링 영상에서 관제 대상 지역을 감지하는 단계와,상기 감지된 관제 대상 지역에 면적 마크를 매칭하는 단계와,상기 제1 모니터링 영상의 상기 관제 대상 지역 내의 사람을 감지하는 단계와,상기 감지된 사람에 사람 마크를 매칭하는 단계를 포함하는인공지능을 이용한 테더 드론 기반의 안전관리 방법."}
{"patent_id": "10-2023-0103910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 제1 가공 모니터링 영상을 제공하는 단계는,상기 제1 모니터링 영상에 상기 면적 마크 및 상기 사람 마크를 표시한 영상 영역과,상기 영상 영역에 대한 인파 밀집도를 설명하기 위한 텍스트를 표시한 설명 영역을 포함하는 제1 모니터링 영상을 제공하는 단계인인공지능을 이용한 테더 드론 기반의 안전관리 방법."}
{"patent_id": "10-2023-0103910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항에 있어서,상기 상황별 솔루션을 제공하는 단계는,상기 인파 밀집도의 단계 별로 연계 기관에 전송할 소정의 솔루션을 기 매칭하는 단계와,상기 산출된 인파 밀집도 및 상기 인파 사고 가능성에 기 매칭된 소정의 솔루션을 추출하는 단계와,상기 추출된 제1 솔루션과, 상기 모니터링 영상 및 상기 가공 모니터링 영상의 일부 및 전부 중 적어도 하나를상기 연계 기관으로 전송하는 단계를 포함하는인공지능을 이용한 테더 드론 기반의 안전관리 방법."}
{"patent_id": "10-2023-0103910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2025-0022995-4-드론;상기 드론이 구동되도록 지원하는 베이스 스테이션; 및 상기 드론과 상기 베이스 스테이션을 연결하는 케이블;을 포함하는 테더 드론 어셈블리;상기 테더 드론 어셈블리를 제어하고, 적어도 하나 이상의 메모리, 적어도 하나 이상의 프로세서를 포함하고,상기 메모리에 저장되고 상기 프로세서에 의해 실행되어 인공지능을 이용한 테더 드론 기반의 안전관리 방법을제공하는 적어도 하나의 애플리케이션으로서 상기 적어도 하나의 애플리케이션은,상기 테더 드론으로부터 관제 대상 지역에 대한 제1 모니터링 영상을 실시간으로 획득하고,딥러닝 뉴럴 네트워크를 기초로 상기 제1 모니터링 영상에 대한 인파 밀집도를 산출하고,상기 산출된 인파 밀집도에 따른 인파 사고 가능성을 예측하고,상기 인파 밀집도 및 상기 인파 사고 가능성을 표시하는 비주얼 콘텐츠를 생성하고,상기 생성된 비주얼 콘텐츠를 상기 제1 모니터링 영상에 적용한 제1 가공 모니터링 영상을 제공하고,상기 가공 모니터링 영상에 따라 상황별 솔루션을 제공하는인공지능을 이용한 테더 드론 기반의 안전관리 시스템."}
{"patent_id": "10-2023-0103910", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시예에 따른 인공지능을 이용한 테더 드론 기반의 안전관리 방법은, 단말의 적어도 하나의 프로세서 에 의하여 실행되는 관제 애플리케이션이 테더 드론을 기초로 안전관리 서비스를 제공하는 방법으로서, 상기 테 더 드론으로부터 관제 대상 지역에 대한 제1 모니터링 영상을 실시간으로 획득하는 단계; 딥러닝 뉴럴 네트워크 를 기초로 상기 제1 모니터링 영상에 대한 인파 밀집도를 산출하는 단계; 상기 산출된 인파 밀집도에 따른 인파 사고 가능성을 예측하는 단계; 상기 인파 밀집도 및 상기 인파 사고 가능성을 표시하는 비주얼 콘텐츠를 생성하 는 단계; 상기 생성된 비주얼 콘텐츠를 상기 제1 모니터링 영상에 적용한 제1 가공 모니터링 영상을 제공하는 단 계; 및 상기 제1 가공 모니터링 영상에 따라 상황별 솔루션을 제공하는 단계;를 포함한다."}
{"patent_id": "10-2023-0103910", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 테더 드론 기반의 안전관리 방법 및 시스템에 관한 것이다. 보다 자세하게는, 인 파 밀집이 예상되는 지역을 상시 모니터링하면서 딥러닝(AI)을 통해 인파 밀집도를 분석하여 해당 지역의 인파 를 관리하는 인공지능을 이용한 테더 드론 기반의 안전관리 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0103910", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인파가 많이 몰리는 장소(예컨대, 콘서트장, 축제현장) 및 일시(예컨대, 공휴일, 기념일, 출퇴근시간)에 해당 지역에서의 안전관리 시스템은 스마트 시티 기술 채택 증가 및 공공안전에 대한 우려로 증가하는 추세이다. 현재로서는 인파 밀집 지역 또는 안전관리 소홀 지역에 대한 신고가 접수되면 경찰이 자체적으로 판단하여 인력 및 장비를 미리 투입하거나, 신고에 따라 현장으로 출동하게 된다. 그러나, 비식별화 및 단순모니터링에 따라 현장에 대한 상황판단 오류 및 정보손실로 필요분석에 한계가 있어, 예상 지역에 인파가 밀집되지 않아 불필요한 인력 낭비가 일어나거나 혹은 인파 과밀로 인해 교통 혼잡 등으로 진입이 불가하여 안전관리 자원이 투입되지 못할 가능성은 여전히 존재한다. 이에 따라, CCTV 및 무선 드론을 활용하여 축제 안전관리를 진행하는 관제 시스템이 도입되었다. 이러한 관제 시스템은 인력 감소 효과 및 안전관리 효율성이 입증되었고, 무선 드론을 활용한 축제현장 안전관리 시스템은 CCTV에 비해 넓고 유연한 시야를 제공할 수 있으며 넓은 지역을 빠르고 쉽게 커버할 수 있다는 장점이 있다. 그러나, 드론을 이용한 관제 시스템의 경우, 체공 시간의 제한으로 인한 기술적 한계가 명확하여 매우 제한적인 관제만 수행하고 있다. 이에 따라, 기존의 통합 관제에 사용되는 단순 모니터링만이 가능한 CCTV의 단점 및 체공 시간이 제한된 무선 드론의 단점을 보완하면서 스마트 시티로의 도약을 위한 상시 통합 관제 서비스 구축이 필요한 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-2021-0030183 A"}
{"patent_id": "10-2023-0103910", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2023-0103910", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은, 상기와 같은 종래 기술의 문제점을 해결하기 위해 안출된 것으로, 장기 체공형 테더 드론을 통해 획 득되는 실시간 영상 및 임무 데이터를 실시간으로 AI(인공지능) 기반 분석하는 인공지능을 이용한 테더 드론 기 반의 안전관리 방법 및 시스템을 제공하는데 그 목적이 있다. 또한, 본 발명은, 카메라가 장착된 드론에 연속적인 전원과 통신을 공급하는 인공지능을 이용한 테더 드론 기반 의 안전관리 방법 및 시스템을 제공하는데 그 목적이 있다. 또한, 본 발명은, 다중 네트워킹 시스템을 기초로 실시간 드론 영상을 전송하는 인공지능을 이용한 테더 드론 기반의 안전관리 방법 및 시스템을 제공하는데 그 목적이 있다. 또한, 본 발명은, 실시간 드론 영상을 분석 가공하여 각 상황별 솔루션을 제공하는 인공지능을 이용한 테더 드 론 기반의 안전관리 방법 및 시스템을 제공하고자 한다. 다만, 본 발명 및 본 발명의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되 지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2023-0103910", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 인공지능을 이용한 테더 드론 기반의 안전관리 방법은, 단말의 적어도 하나의 프로세 서에 의하여 실행되는 관제 애플리케이션이 수행하는 인공지능을 이용한 테더 드론 기반의 안전관리 방법으로서, 상기 테더 드론으로부터 관제 대상 지역에 대한 제1 모니터링 영상을 실시간으로 획득하는 단계; 딥러닝 뉴럴 네트워크를 기초로 상기 제1 모니터링 영상에 대한 인파 밀집도를 산출하는 단계; 상기 산출된 인 파 밀집도에 따른 인파 사고 가능성을 예측하는 단계; 상기 인파 밀집도 및 상기 인파 사고 가능성을 표시하는 비주얼 콘텐츠를 생성하는 단계; 상기 생성된 비주얼 콘텐츠를 상기 제1 모니터링 영상에 적용한 제1 가공 모니 터링 영상을 제공하는 단계; 및 상기 제1 가공 모니터링 영상에 따라 상황별 솔루션을 제공하는 단계;를 포함한 다. 또한, 상기 제1 모니터링 영상을 실시간으로 획득하는 단계는, 적어도 하나 이상의 촬영 스팟 중 제1 촬영 스팟 을 결정하는 단계와, 상기 제1 촬영 스팟에서 테더 드론이 관제 대상 지역을 촬영하도록 테더 드론 어셈블리의 장력 제어부를 제어하는 단계와, 상기 결정된 제1 촬영 스팟에서 촬영된 제1 모니터링 영상을 획득하는 단계를 포함한다. 또한, 상기 제1 모니터링 영상에 대한 인파 밀집도를 산출하는 단계는, 제1 딥러닝 뉴럴 네트워크를 기초로 상 기 관제 대상 지역의 실제 면적을 획득하는 단계와, 제2 딥러닝 뉴럴 네트워크를 기초로 상기 관제 대상 지역 내의 사람 수를 획득하는 단계와, 상기 획득된 관제 대상 지역의 실제 면적 대비 사람 수를 기초로 인파 밀집도 를 산출하는 단계를 포함한다. 또한, 상기 관제 대상 지역의 실제 면적을 획득하는 단계는, 복수 개의 모니터링 영상을 상기 제1 딥러닝 뉴럴 네트워크에 입력하는 단계와, 상기 제1 딥러닝 뉴럴 네트워크로부터 출력된 관제 대상 지역의 실제 면적을 획득 하는 단계를 포함한다. 또한, 상기 관제 대상 지역 내의 사람 수를 획득하는 단계는, 상기 제1 모니터링 영상을 상기 제2 딥러닝 뉴럴 네트워크에 입력하는 단계와, 상기 제2 딥러닝 뉴럴 네트워크로부터 출력된 관제 대상 지역 내의 실제 사람 수 를 획득하는 단계를 포함한다. 또한, 상기 인파 사고 가능성을 예측하는 단계는, 상기 산출된 인파 밀집도의 값 별로 소정의 파라미터를 할당 한 적어도 하나 이상의 단계를 기 설정하는 단계와, 각각의 상기 단계별로 인파 사고 가능성을 값으로 기 매칭 하는 단계를 포함한다. 또한, 상기 비주얼 콘텐츠를 생성하는 단계는, 상기 제1 모니터링 영상에서 관제 대상 지역을 감지하는 단계와, 상기 감지된 관제 대상 지역에 면적 마크를 매칭하는 단계와, 상기 제1 모니터링 영상의 상기 관제 대상 지역 내의 사람을 감지하는 단계와, 상기 감지된 사람에 사람 마크를 매칭하는 단계를 포함한다. 또한, 상기 제1 가공 모니터링 영상을 제공하는 단계는, 상기 제1 모니터링 영상에 상기 면적 마크 및 상기 사 람 마크를 표시한 영상 영역과, 상기 영상 영역에 대한 인파 밀집도를 설명하기 위한 텍스트를 표시한 설명 영 역을 포함하는 제1 모니터링 영상을 제공하는 단계이다.또한, 상기 상황별 솔루션을 제공하는 단계는, 상기 인파 밀집도의 단계 별로 연계 기관에 전송할 소정의 솔루 션을 기 매칭하는 단계와, 상기 산출된 인파 밀집도 및 상기 인파 사고 가능성에 기 매칭된 소정의 솔루션을 추 출하는 단계와, 상기 추출된 제1 솔루션과, 상기 모니터링 영상 및 상기 가공 모니터링 영상의 일부 및 전부 중 적어도 하나를 상기 연계 기관으로 전송하는 단계를 포함한다. 한편, 본 발명의 실시예에 따른 인공지능을 이용한 테더 드론 기반의 안전관리 시스템은, 드론; 상기 드론이 구 동되도록 지원하는 베이스 스테이션; 및 상기 드론과 상기 베이스 스테이션을 연결하는 케이블;을 포함하는 테 더 드론 어셈블리; 상기 테더 드론 어셈블리를 제어하고, 적어도 하나 이상의 메모리, 적어도 하나 이상의 프로 세서를 포함하고, 상기 메모리에 저장되고 상기 프로세서에 의해 실행되어 인공지능을 이용한 테더 드론 기반의 안전관리 방법을 제공하는 적어도 하나의 애플리케이션으로서 상기 적어도 하나의 애플리케이션은, 상기 테더 드론으로부터 관제 대상 지역에 대한 제1 모니터링 영상을 실시간으로 획득하고, 딥러닝 뉴럴 네트워크를 기초 로 상기 제1 모니터링 영상에 대한 인파 밀집도를 산출하고, 상기 산출된 인파 밀집도에 따른 인파 사고 가능성 을 예측하고, 상기 인파 밀집도 및 상기 인파 사고 가능성을 표시하는 비주얼 콘텐츠를 생성하고, 상기 생성된 비주얼 콘텐츠를 상기 제1 모니터링 영상에 적용한 제1 가공 모니터링 영상을 제공하고, 상기 가공 모니터링 영 상에 따라 상황별 솔루션을 제공한다."}
{"patent_id": "10-2023-0103910", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따른 인공지능을 이용한 테더 드론 기반의 안전관리 방법 및 시스템은, 장기 체공형 테더 드론을 통해 획득되는 실시간 영상 및 임무 데이터를 실시간으로 AI(인공지능) 기반 분석함으로써, 언제 발생할 지 모르는 위험 상황(예컨대, 대기열 발생, 유동인구 급증, 폭력상황 발생 등)을 감지하여 축제·행사에 참여하 는 국민의 안전을 확보하여 자연스러운 축제·행사 참여를 유도하고, 이를 통해 경제의 선순환, 새로운 인프라 개선, 국민 삶의 질 향상, 신뢰할 수 있는 정부 등 국가·국민·지자체 모두 win-win 할 수 있는 선순환 구조를 만드는 효과가 있다. 또한, 본 발명의 실시예에 따른 인공지능을 이용한 테더 드론 기반의 안전관리 방법 및 시스템은, 카메라가 장 착된 드론에 연속적인 전원과 통신을 공급함으로써, 갑작스러운 전원공급 중단으로 인한 추락 문제점 및 드론- 송수신기간의 교란 문제점을 보완하여 드론을 활용한 시스템의 신뢰성을 높이는 효과가 있다. 또한, 본 발명의 실시예에 따른 인공지능을 이용한 테더 드론 기반의 안전관리 방법 및 시스템은, 다중 네트워 킹 시스템을 기초로 실시간 드론 영상을 전송함으로써, 지연성이 감소되어 실제 현장 및 관제 영상간의 영상 딜 레이(delay)가 최소화되는 효과가 있다. 또한, 본 발명의 실시예에 따른 인공지능을 이용한 테더 드론 기반의 안전관리 방법 및 시스템은, 실시간 드론 영상을 분석 가공하여 각 상황(예컨대, 이상행동 감지, 대기열 감지 등)별 솔루션을 제공함으로써, 인파, 주차 관리 등의 사고 예방 및 삶의 질 향상에 대한 AI 기술의 핵심요소로 시장 전반의 기술이 향상되고, ICT 전문가 양성, 축제현장 인파관리 전문가 및 AI 학습데이터 수집인력, 드론 파일럿 등 양질의 미래를 선도할 수 있는 일 자리를 창출하는 효과가 있다. 다만, 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효 과들은 아래의 기재로부터 명확하게 이해될 수 있다."}
{"patent_id": "10-2023-0103910", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변환을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고"}
{"patent_id": "10-2023-0103910", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상세한 설명에 상세하게 설명하고자 한다. 본 발명의 효과 및 특징, 그리고 그것들을 달성하는 방법은 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 다양한 형태로 구현될 수 있다. 이하의 실시예에서, 제1, 제2 등의 용어는 한정적 인 의미가 아니라 하나의 구성 요소를 다른 구성 요소와 구별하는 목적으로 사용되었다. 또한, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 또한, 포함하다 또는 가지다 등의 용어는 명 세서상에 기재된 특징, 또는 구성요소가 존재함을 의미하는 것이고, 하나 이상의 다른 특징들 또는 구성요소가 부가될 가능성을 미리 배제하는 것은 아니다. 또한, 도면에서는 설명의 편의를 위하여 구성 요소들이 그 크기가 과장 또는 축소될 수 있다. 예컨대, 도면에서 나타난 각 구성의 크기 및 두께는 설명의 편의를 위해 임의로 나 타내었으므로, 본 발명이 반드시 도시된 바에 한정되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동일 하거나 대응하는 구성 요소는 동일한 도면부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 도 1은 본 발명의 실시예에 따른 안전관리 시스템의 개념도이다. 도 1을 참조하면, 본 발명의 실시예에 따른 안전관리 시스템은, 인파 밀집이 예상되는 지역을 테더 드론을 기초 로 상시 모니터링하여 통합 관제하고, 인파 밀집도가 소정 범위 이상이면 적합한 대응을 수행하도록 하는 서비 스(이하, 안전관리 서비스)를 제공할 수 있다. 실시예에서, 위와 같은 안전관리 시스템은, 테더 드론 어셈블리, 단말, 스마트 관제 서버 및 네트 워크(10: Network)를 통하여 연결될 수 있다. 도 2는 본 발명의 실시예에 따른 테더 드론 어셈블리의 일례를 나타낸 도면이다. 도 2를 참조하면, 본 발명의 실시예에 따른 테더 드론 어셈블리는, 이동가능한 박스(box) 형태로 구현되어 지면 등에 배치되는 베이스 스테이션(100: Base station) 및 상기 베이스 스테이션(100: Base Station)과 케이 블(330: Cable)을 통해 연결되는 테더 드론(200: Tether Drone)을 포함할 수 있다. 상기 베이스 스테이션은, 테더 드론을 조종하는 조종사의 입력 또는 기 설정된 드론 제어 프로세스 (process)에 따라서 테더 드론을 제어할 수 있다. 상기 베이스 스테이션은, 케이블을 통해 전원을 공급하고 케이블을 통한 유선 통신 방식으로 테 더 드론의 비행 및 촬영을 제어할 수 있다. 또한, 상기 베이스 스테이션은, 테더 드론의 위치에 따라 케이블의 길이를 단축하거나 연장하여 테더 드론이 안정적으로 비행할 수 있도록 지원할 수 있다. 또한, 본 발명의 안전관리 시스템은 테더 드론을 유선 비행모드에서 무선 비행모드로 전환할 수 있도록 테 더 드론에 비행모드 전환장치와, 케이블과 테더 드론을 분리하거나 체결할 수 있는 커넥팅 장치 를 포함할 수 있다. 또한, 본 발명의 안전관리 시스템은 테더 드론이 유선 비행모드에서 무선 비행모드로 전환할 때, 분리된 케이블을 보호하기 위한 보호장치를 포함할 수 있다. 여기서, 실시예에 따른 상기 네트워크는, 상기 테더 드론 어셈블리, 단말 및/또는 스마트 관제 서버 등과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 이러한 네트워크의 일례에는 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, WIMAX(World Interoperability for Microwave Access) 네트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), 블루투스(Bluetooth) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 이하, 첨부된 도면을 참조하여 안전관리 시스템을 구현하는 테더 드론 어셈블리, 단말 및 스마트 관 제 서버에 대해 상세히 설명한다. - 테더 드론 어셈블리(1: Tether Drone Assembly) 본 발명의 실시예에 따른 테더 드론 어셈블리는, 지상에 배치되는 베이스 스테이션, 테더 드론 및 케이블을 포함할 수 있다. 도 3은 본 발명의 실시예에 따른 테더 드론 어셈블리의 블록도이다. 도 3을 참조하면, 실시예에 따른 테더 드론 어셈블리는, 베이스 스테이션, 테더 드론 및 상기 베 이스 스테이션과 테더 드론을 연결하는 케이블을 포함할 수 있다. 먼저, 본 발명의 실시예에서 베이스 스테이션은, 조종사의 입력 또는 기 설정된 드론 제어 프로세스를 기 반으로 베이스 스테이션과 케이블로 연결되어 있는 테더 드론을 기초로 한 비행 제어, 촬영 및 비행모드 전환 등을 컨트롤할 수 있다. 또한, 베이스 스테이션은, 테더 드론에 연결된 케이블을 통해 전원을 공급함으로써, 무제한 비 행을 지원할 수 있다. 또한, 베이스 스테이션은, 테더 드론에 연결된 케이블을 통해 유선 통신하여, 조종관련 신호를 송수신하거나, 테더 드론에서 센싱된 정보 및 촬영된 영상 등을 수신할 수 있다. 이러한 베이스 스테이션은, 이동이 용이한 박스 형상으로 외관이 형성될 수 있으며, 내외부에 베이스 스테 이션의 구동에 필요한 각종 구성요소를 구비할 수 있다. 또한, 베이스 스테이션은, 이러한 박스를 개폐할 수 있는 캡(cap)을 포함하여 구현될 수 있다. 이때, 베이스 스테이션이 포함하는 각 구성요소는, 박스 내에 수납될 수 있는 형태로 구현되어 베이스 스 테이션 내부에 보관될 수 있고, 베이스 스테이션의 사용시 베이스 스테이션 기반의 안전관리 서 비스를 제공하기 적합한 형태로 재배치되어 동작될 수 있다. 다시 도 2를 참조하면, 실시예에 따른 베이스 스테이션은, 전원 공급부, 장력 제어부, 케이블 가이드, 모니터링부, 지상 통신부 및/또는 제어부를 포함할 수 있다. 전원공급부는, 제어부의 컨트롤에 의하여 외부의 전원 및/또는 내부의 전원을 인가받아 각 구성요소 들에게 동작에 필요한 전원을 공급할 수 있다. 자세히, 실시예에서 전원공급부는, 배터리 및 전원부를 포함하여 구현될 수 있다. 또한, 전원공급부의 전원부는, AC-DC 컨버터 및 전력모듈를 포함할 수 있다. 여기서, AC-DC 컨버터는, 배터리 또는 외부로부터 공급되는 전원이 교류(AC) 전력인 경우, 교류(AC) 전력을 직 류(DC) 전력으로 변환하여 케이블을 통해 테더 드론으로 공급하도록 구성될 수 있다. 이는, 교류(AC) 전력 보다 고전압인 직류(DC) 전력으로 전원을 송신하는 것이 보다 효율적이기 때문이다. 이때, 변환된 직류(DC) 전력을 획득한 테더 드론의 전원유닛은, 수급된 직류(DC)를 동체에 탑재체들이 사 용할 수 있는 전압 수준으로 변환하도록 DC/DC 컨버터가 더 포함될 수 있다. 또한, 전력모듈은, 전압계나 전류계 등의 전력계가 포함될 수 있으며, 이러한 전력모듈을 포함하는 베이스 스테 이션의 제어부는, 일정 시간마다 상기 전력계에서 측정되는 전압, 전류 또는 전력을 수신 받을 수 있 다. 여기서, 베이스 스테이션의 제어부 상에는 전원의 공급량을 조절하기 위한 기준 데이터가 기설정되어 있을 수 있으며, 해당 기준 데이터가 기설정된 제어부는, 상기 DC/DC 컨버터를 거친 이후에 측정되는 전압 을 기반으로 케이블을 통한 전원공급부로부터의 전원 공급량을 조절할 수 있다. 또한, 장력제어부는, 테더 드론과 베이스 스테이션을 연결하는 케이블에 인가되는 장력이 일정 하게 유지되도록 케이블의 길이를 조절할 수 있고, 이를 통해 테더 드론의 안정적 비행을 가능하게 할 수 있다. 또한, 장력제어부는, 테더 드론의 수평 또는/및 수직 이동을 지원하기 위하여, 케이블을 권취하거나 권출할 수 있다. 이때, 케이블은, 일단이 테더 드론의 전원유닛에 연결되고 타단이 베이스 스테이션의 지상 통신부 에 연결되어, 테더 드론에 베이스 스테이션으로부터 출력되는 전원을 공급할 수 있다. 또한, 케 이블은, 장력제어부에 감기거나 풀리면서 길이가 단축 또는 연장될 수 있다. 또한, 케이블 가이드는, 장력제어부와 테더 드론 사이에 배치되는 케이블의 적어도 일부를 소정 의 높이 이상까지 가이드할 수 있다. 자세히, 케이블 가이드는, 케이블의 적어도 일부를 수용하여 소정의 높이 이상에 고정시킬 수 있으며, 소 정의 높이 이상의 특정 지점에서 케이블을 다양한 방향으로 권출할 수 있도록 가이드할 수 있다. 이러한 케이블 가이드는, 테더 드론을 소정의 높이 이상에 고정시키기 위한 가이드 샤프트 및 테더 드론의 회전 방향이나 각도를 고정시키기 위한 가이드 헤더를 포함할 수 있다. 또한, 모니터링부는, 디스플레이부 및 컨트롤러(controller)를 포함할 수 있다. 이때, 상기 모니터링부는, 테더 드론 어셈블리로 제공되는 안전관리 서비스와 관련된 다양한 정보를 그 래픽 이미지로 출력할 수 있다. 실시예로, 디스플레이부는, 테더 드론이 촬영한 영상 화면, 케이블 가이드 제어영상 화면 등을 출력 해 제공할 수 있다. 이러한 디스플레이부는, 액정 디스플레이(liquid crystal display, LCD), 박막 트랜지스터 액정 디스플레이 (thin film transistor-liquid crystal display, TFT LCD), 유기 발광 다이오드(organic light-emitting diode, OLED), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전자잉크 디스플레이 (e-ink display) 중에서 적어도 하나를 포함할 수 있다. 또한, 컨트롤러는, 테더 드론을 지원하는 베이스 스테이션 및 이를 포함하는 안전관리 서비스와 관련 된 사용자의 입력을 감지할 수 있다. 실시예로, 컨트롤러는, 테더 드론의 비행 방향 및/또는 속도를 조종하는 입력, 테더 드론의 촬영을 제어하는 입력 등을 감지할 수 있다. 또한, 상기 디스플레이부 및 컨트롤러는, 결합되어 터치 스크린으로 구현될 수도 있다. 더하여, 상기 디스플레이부 및 컨트롤러는, 실시예에 따라서 베이스 스테이션에 포함되거나 또는 별도의 장치로서 구현될 수 있다. 다음으로, 지상 통신부는, 테더 드론을 지원하는 베이스 스테이션 및 이를 포함하는 안전관리 서비스를 제공하기 위한 각종 데이터 및/또는 정보 등을 송수신할 수 있다. 자세히, 지상 통신부는, 유선 통신부 및 무선 통신부를 포함할 수 있다. 이때, 유선 통신부 는, 테더 드론과 베이스 스테이션을 연결하는 케이블을 기반으로 구현될 수 있으며, 케이블에 기반한 데이터, 정보 및/또는 전원 등의 송수신을 수행할 수 있다. 실시예로, 유선 통신부는, 테더 드론 인터페이스부의 유선 통신유닛과 통신하여 베이스 스테이션 의 전원공급부로부터 출력되는 전원을 테더 드론의 전원유닛으로 송신할 수 있다. 또한, 무선 통신부는, 이동통신을 위한 기술표준들 또는 통신방식(예를 들어, GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced) 등)에 따라 구축된 이동 통신망 상에서 테더 드론, 기지국, 외부의 단말, 임의의 서버 중 적어도 하나와무선 신호를 송수신할 수 있다. 실시예로, 무선 통신부는, 테더 드론의 무선 통신유닛과 통신하여 테더 드론의 비행을 컨트롤하 는 비행제어 신호, 테더 드론의 촬영을 컨트롤하는 촬영제어 신호 등을 송신할 수 있다. 마지막으로, 제어부는, 테더 드론을 지원하는 베이스 스테이션 및 이를 포함하는 안전관리 서비 스를 제공하기 위하여 전술한 각 구성요소의 전반적인 동작을 제어할 수 있다. 실시예에서, 제어부는, 장력 제어부의 모터를 제어하여 베이스 스테이션과 테더 드론을 연 결하는 케이블의 장력을 조절할 수 있다. 또한, 제어부는, 베이스 스테이션으로부터 테더 드론으로 공급되는 전원의 공급량을 조절할 수 있다. 또한, 제어부는, 테더 드론을 통해 감지된 지상 구조물과 비행고도를 기반으로, 케이블 가이드 를 기초로 케이블의 고도 및/또는 각도를 제어하여 테더 드론의 이동반경과 자세(stance)를 컨트롤할 수 있다. 또한, 이러한 제어부는, ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세스 (microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 다시 도 3을 참조하면, 실시예에 따른 테더 드론은, 베이스 스테이션으로부터 권출된 케이블과 연결 되어 전원을 공급받으며, 베이스 스테이션 및/또는 외부 단말로부터 획득되는 드론 조종사의 입력 또 는 기 설정된 드론 제어 프로세스에 의해 컨트롤되어 비행 및/또는 촬영을 수행할 수 있다. 이러한 테더 드론은, 인터페이스부, 전원유닛, 구동부, 센서부, 카메라 및 프로 세서를 포함할 수 있다. 먼저, 인터페이스부는, 테더 드론의 프로세서와 테더 드론을 지원하는 베이스 스테이션 및 이를 포함하여 안전관리 서비스를 구현하기 위한 주변기기들을 연결할 수 있다. 자세히, 실시예에서 인터페이스부는, 유선 통신유닛과 무선 통신유닛을 포함할 수 있다. 여기서, 유선 통신유닛은, 테더 드론과 베이스 스테이션을 연결하는 케이블을 기반으로 구현될 수 있으며, 케이블에 기반한 데이터, 정보 및/또는 전원 등의 송수신을 수행할 수 있다. 실시예에서, 유선 통신유닛는, 베이스 스테이션 지상 통신부의 유선 통신부와 통신하여 베 이스 스테이션의 전원공급부로부터 출력되는 전원을 전원유닛으로 수신할 수 있다. 또한, 무선 통신유닛은, 이동통신을 위한 기술표준들 또는 통신방식(예를 들어, GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced) 등)에 따라 구축된 이동 통신망 상에서 베이스 스테이션, 기지국, 외부의 단말, 임의의 서버 중 적어도 하 나와 무선 신호를 송수신할 수 있다. 또한, 무선 통신유닛은, 블루투스(Bluetooth)나 와이파이(Wi-Fi) 등 과 같은 근거리 무선 통신 모듈을 포함할 수도 있다. 실시예에서, 무선 통신유닛은, 베이스 스테이션 지상 통신부의 무선 통신부와 통신하여 테 더 드론의 비행을 컨트롤하는 비행제어 신호, 테더 드론의 촬영을 컨트롤하는 촬영제어 신호 등을 수 신할 수 있다. 또한, 이러한 인터페이스부는, 외부 충전기 포트(port), 유/무선 데이터 포트(port), 메모리 카드(memory card) 포트, 식별 모듈이 구비된 장치를 연결하는 포트(port), 오디오 I/O(Input/Output) 포트(port), 비디오 I/O(Input/Output) 포트(port), 이어폰 포트(port) 중 적어도 하나를 더 포함할 수 있다. 다음으로, 전원유닛은, 프로세서의 컨트롤에 의하여 외부의 전원 및/또는 내부의 전원을 인가받아 각 구성요소들에게 동작에 필요한 전원을 공급할 수 있다. 또한, 전원유닛은, 베이스 스테이션으로부터 수급된 전원을 동체에 탑재체들이 사용할 수 있는 전압 수준으로 변환할 수 있는 DC/DC 컨버터를 더 포함할 수 있다. 다음으로, 구동부는, 테더 드론의 추진력을 확보하는 프로펠러(propeller)를 구동하는 구동모터로 구 현될 수 있다. 이때, 구동부는, 복수의 프로펠러를 구동하는 복수의 구동모터를 포함할 수 있으며, 프로세 서의 컨트롤에 의해 동작할 수 있다. 여기서, 구동부는, 일반적으로 25V ~ 33V의 직류(DC) 전원을 사용하며, 테더 드론의 전원을 가장 많 이 소모하는 에너지 싱크에 해당할 수 있다. 다음으로, 센서부는, 테더 드론을 지원하는 베이스 스테이션 및 이를 포함하는 안전관리 서비스 와 관련된 각종 데이터 및/또는 정보 등을 센서를 통하여 획득할 수 있다. 자세히, 실시예로 센서부는, 주변환경을 감지하는 거리센서(예컨대, 근접센서, 적외선 센서, 레이저 센서 등), 위치센서, 자이로센서 및/또는 가속센서 중 적어도 하나 이상을 포함할 수 있다. 또한, 센서부는, 적어도 하나 이상의 센서를 기반으로 테더 드론의 주변환경에 대한 각종 데이터(예 컨대, 테더 드론과 지상 구조물 간의 거리 데이터, 테더 드론의 위치 데이터, 테더 드론의 속도 데이터 등)를 센싱할 수 있다. 다음으로, 카메라는, 테더 드론을 지원하는 베이스 스테이션 및 이를 포함하는 안전관리 서비스 와 관련된 촬영 영상을 획득할 수 있다. 자세히, 카메라는, 테더 드론의 일측에 배치되어 배치된 방향측에 기준한 주변환경을 촬영할 수 있다. 또한, 본 발명의 실시예에 따른 카메라는, 테더 드론의 비행과 연동하여 목표지점을 촬영한 영 상을 획득할 수 있다. 또한, 실시예에서 카메라는, 렌즈의 수평 이동, 수직 이동 및 초점 거리 조정이 가능한 PTZ(Pan-Tilt- zoom) 카메라일 수 있다. 이러한 카메라는, 센서부를 지지하면서 자세를 유지시키는 짐벌(Gimbal)을 포함할 수 있다. 실시예에서 짐벌은, 소정의 프로세스에 따라 결정된 드론의 카메라의 각도 및/또는 스탠스를 유지시키기 위해, 다양한 자세(roll, pitch and yaw) 변화로 인한 x, y, z축의 변형된 자세변화 벡터값을 감지할 수 있다. 예를 들어, 테더 드론은 내부 장치의 진동, 바람, 비 등에 의한 영향으로 흔들릴 수 있는데, 이때 짐벌이 자세변화 벡터값을 감지하여 상기 테더 드론에 장착된 카메라의 각도 및/또는 스탠스를 유지시킬 수 있다. 또한, 카메라는, 카메라 위치 제어 모듈을 기초로 방향 및 각도가 제어될 수 있다. 자세히, 실시예에서 프 로세서는 제어 신호에 기초하여 카메라 위치 제어 모듈을 제어함으로써, 상기 카메라 위치 제어 모듈에 포 함된 소정의 모터 동력을 이용하여 상기 테더 드론의 카메라의 위치 및 촬영 방향을 조정할 수 있다. 또한, 카메라는, 이미지 센서와 영상 처리 모듈을 포함할 수 있다. 자세히, 카메라는, 이미지 센서(예를 들면, CMOS 또는 CCD)를 통해 정지영상 및/또는 동영상을 포함하는 촬영 영상을 획득할 수 있고, 획득된 촬영 영상을 영상 처리 모듈을 기반으로 처리할 수 있다. 예를 들어, 카메라는, 영상 처리 모듈을 이용하여 이미지 센서를 통해 획득된 정지영상 또는 동영상을 가 공해 필요한 정보를 추출하고, 추출된 정보를 프로세서에 전달할 수 있다. 이때, 테더 드론의 프로세서는, 카메라를 통해 획득된 촬영 영상을 인터페이스부를 통하여 베이스 스테이션으로 제공할 수 있다. 마지막으로, 프로세서는, 전술한 각 유닛의 전반적인 동작을 컨트롤하고 구동할 수 있다. 자세히, 실시예에서 프로세서는, 상기 각 유닛의 전반적인 동작을 제어하고 구동함으로써 테더 드론 과 베이스 스테이션 간의 연동을 가능하게 하며, 이를 통해 원활한 안전관리 서비스가 제공되게 할 수 있 다. 이러한 프로세서는, ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세스(microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 실시예에서 테더 드론 어셈블리의 테더 드론은, 베이스 스테이션, 외부 단말 및/또는 서버 중 적 어도 하나에 의해 제어될 수 있다. 또한, 실시예에서 테더 드론은, 카메라를 기초로 소정의 관제 대상 지역을 모니터링 및/또는 촬영할 수 있다. 또한, 실시예에서 테더 드론은, 소정의 관제 대상 지역을 촬영한 모니터링 영상을 베이스 스테이션, 외부 단말 및/또는 서버 중 적어도 하나로 송신할 수 있다. 후술되는 단말은, 상기 테더 드론 어셈블리와 연동되어 상기 테더 드론 어셈블리의 구성 요소 전반 을 제어할 수 있다. - 단말(400: Terminal) 본 발명의 실시예에 따른 단말은, 안전관리 서비스를 제공하는 애플리케이션(이하, 관제 애플리케이션)이 설치된 소정의 컴퓨팅 디바이스일 수 있다. 자세히, 하드웨어적 관점에서 단말은, 애플리케이션이 설치된 모바일 타입 컴퓨팅 장치(400-1) 및/또는 데 스크탑 타입 컴퓨팅 장치(400-2) 등을 포함할 수 있다. 여기서, 모바일 타입 컴퓨팅 장치(400-1)는, 애플리케이션이 설치된 스마트 폰이나 태블릿 PC와 같은 모바일 장 치일 수 있다. 예를 들어, 모바일 타입 컴퓨팅 장치(400-1)는, 스마트 폰(smart phone), 휴대폰, 디지털방송용 디바이스, PDA(personal digital assistants), PMP(portable multimedia player), 태블릿 PC(tablet PC) 등이 포함될 수 있다. 또한, 데스크탑 타입 컴퓨팅 장치(400-2)는, 애플리케이션이 설치된 고정형 데스크탑 PC, 노트북 컴퓨터(laptop computer), 울트라북(ultrabook)과 같은 퍼스널 컴퓨터 등과 같이 유/무선 통신을 기반으로 안전관리 서비스를 실행하기 위한 프로그램이 설치된 장치 등을 포함할 수 있다. 또한, 실시예에 따라서 단말은, 안전관리 서비스 환경을 제공하는 소정의 서버(Server) 컴퓨팅 디바이스를 더 포함할 수도 있다. 도 4는 본 발명의 실시예에 따른 단말의 내부 블록도이다. 도 4를 참조하면, 기능적 관점에서 단말은, 메모리, 프로세서 어셈블리, 통신 프로세서, 인터페이스 모듈, 입력 시스템, 센서 시스템 및 디스플레이 시스템을 포함할 수 있다. 이 러한 구성요소들은 단말의 하우징 내에 포함되도록 구성될 수 있다. 자세히, 메모리에는, 애플리케이션이 저장되며, 애플리케이션은 안전관리 서비스 환경을 제공하 기 위한 각종 응용 프로그램, 데이터 및 명령어 중 어느 하나 이상을 저장할 수 있다. 즉, 메모리는, 안전관리 서비스 환경을 생성하기 위하여 사용될 수 있는 명령 및 데이터 등을 저장할 수 있다. 또한, 상기 메모리는, 프로그램 영역과 데이터 영역을 포함할 수 있다. 여기서, 실시예에 따른 프로그램 영역은, 단말을 부팅하는 운영체제(OS: Operating System) 및 기능요소들 사이에 연계될 수 있으며, 데이터 영역은, 단말의 사용에 따라 발생하는 데이터가 저장될 수 있다. 또한, 메모리는, 적어도 하나 이상의 비일시적 컴퓨터 판독 가능 저장매체와, 일시적 컴퓨터 판독 가능 저 장매체를 포함할 수 있다. 예를 들어, 메모리는, ROM, EPROM, 플래시 드라이브, 하드 드라이브 등과 같은 다양한 저장기기일 수 있고, 인터넷(internet) 상에서 상기 메모리의 저장 기능을 수행하는 웹 스토리지(web storage)를 포함할 수 있다. 프로세서 어셈블리는, 안전관리 서비스 환경을 생성하기 위한 다양한 작업을 수행하기 위해, 메모리 에 저장된 애플리케이션의 명령들을 실행할 수 있는 적어도 하나 이상의 프로세서를 포함할 수 있다. 실시예에서 프로세서 어셈블리는, 안전관리 서비스를 제공하기 위하여 메모리의 애플리케이션을 통해 구성요소의 전반적인 동작을 컨트롤할 수 있다. 이러한 프로세서 어셈블리는, 중앙처리장치(CPU) 및/또는 그래픽처리장치(GPU) 등이 포함된 단말에 적합한 시스템 온 칩(SOC)일 수 있으며, 메모리에 저장된 운영체제(OS) 및/또는 응용 프로그램 등을 실행 할 수 있고, 단말에 탑재된 각 구성요소들을 제어할 수 있다. 또한, 프로세서 어셈블리는, 각 구성요소와 내부적으로 시스템 버스(System Bus)에 의해 통신을 수행할 수 있고, 로컬 버스(Local Bus)를 비롯한 소정의 버스 구조들을 하나 이상 포함할 수 있다. 또한, 프로세서 어셈블리는, ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세스 (microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 포함하여 구현될 수 있다. 통신 프로세서는, 외부의 장치와 통신하기 위한 하나 이상의 장치를 포함할 수 있다. 이러한 통신 프로세 서는, 무선 네트워크를 통해 통신할 수 있다. 자세히, 통신 프로세서는, 안전관리 서비스 환경을 구현하기 위한 콘텐츠 소스를 저장한 단말과 통신 할 수 있으며, 유저 입력을 받는 컨트롤러와 같은 다양한 유저 입력 컴포넌트와 통신할 수 있다. 실시예에서, 통신 프로세서는, 안전관리 서비스와 관련된 각종 데이터를 타 단말 및/또는 외부의 서 버 등과 송수신할 수 있다. 이러한 통신 프로세서는, 이동통신을 위한 기술표준들 또는 통신방식(예를 들어, LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced), 5G NR(New Radio), WIFI) 또는 근거리 통신방식 등을 수행 할 수 있는 통신장치를 통해 구축된 이동 통신망 상에서 기지국, 외부의 단말, 임의의 서버 중 적어도 하나와 무선으로 데이터를 송수신할 수 있다. 인터페이스 모듈은, 단말을 하나 이상의 다른 장치와 통신 가능하게 연결할 수 있다. 자세히, 인터페 이스 모듈은, 하나 이상의 상이한 통신 프로토콜과 호환되는 유선 및/또는 무선 통신 장치를 포함할 수 있 다. 이러한 인터페이스 모듈을 통해 단말은, 여러 입출력 장치들과 연결될 수 있다. 예를 들어, 인터페이스 모듈은, 헤드셋 포트나 스피커와 같은 오디오 출력장치와 연결되어, 오디오를 출력 할 수 있다. 예시적으로 오디오 출력장치가 인터페이스 모듈을 통해 연결되는 것으로 설명하였으나, 단말 내부에 설치되는 실시예도 포함될 수 있다. 또한, 예를 들면 인터페이스 모듈은, 키보드 및/또는 마우스와 같은 입력장치와 연결되어, 유저 입력을 획 득할 수도 있다. 이러한 인터페이스 모듈은, 유/무선 헤드셋 포트(port), 외부 충전기 포트(port), 유/무선 데이터 포트 (port), 메모리 카드(memory card) 포트, 식별 모듈이 구비된 장치를 연결하는 포트(port), 오디오 I/O(Input/Output) 포트(port), 비디오 I/O(Input/Output) 포트(port), 이어폰 포트(port), 전력 증폭기, RF 회로, 송수신기 및 기타 통신 회로 중 적어도 하나를 포함하여 구성될 수 있다. 입력 시스템은 안전관리 서비스와 관련된 유저의 입력(예를 들어, 제스처, 음성 명령, 버튼의 작동 또는 다른 유형의 입력)을 감지할 수 있다. 자세히, 입력 시스템은 소정의 버튼, 터치 센서 및/또는 유저 모션 입력을 수신하는 이미지 센서 등 을 포함할 수 있다. 또한, 입력 시스템은, 인터페이스 모듈을 통해 외부 컨트롤러와 연결되어, 유저의 입력을 수신할 수 있다. 센서 시스템은, 이미지 센서, 위치 센서(IMU, 463), 오디오 센서, 거리 센서, 근접 센서, 접촉 센서 등 다양한 센서를 포함할 수 있다. 여기서, 이미지 센서는, 단말 주위의 물리적 공간에 대한 이미지 및/또는 영상을 캡처할 수 있다. 실시예에서, 이미지 센서는, 안전관리 서비스와 관련된 각종 이미지 및/또는 영상 등을 촬영하여 획득할 수 있다. 또한, 이미지 센서는, 단말의 전면 또는/및 후면에 배치되어 배치된 방향측을 촬영하여 영상을 획득 할 수 있으며, 단말의 외부를 향해 배치된 카메라를 통해 물리적 공간을 촬영할 수 있다. 이러한 이미지 센서는, 이미지 센서장치와 영상 처리 모듈을 포함할 수 있다. 자세히, 이미지 센서는, 이미지 센서장치(예를 들면, CMOS 또는 CCD)에 의해 얻어지는 정지영상 또는 동영상을 처리할 수 있다. 또한, 이미지 센서는, 이미지 인식 프로세스(예컨대, OCR 등) 및/또는 영상 처리 모듈을 이용하여 이미지 센서장치를 통해 획득된 정지영상 또는 동영상을 가공해 필요한 정보를 추출하고, 추출된 정보를 프로세서에 전 달할 수 있다. 이러한 이미지 센서는, 적어도 하나 이상의 카메라를 포함하는 카메라 어셈블리일 수 있다. 카메라 어셈블 리는, 가시광선 대역을 촬영하는 일반 카메라를 포함할 수 있으며, 적외선 카메라, 스테레오 카메라 등의 특수 카메라를 더 포함할 수 있다. 또한, 위와 같은 이미지 센서는, 실시예에 따라서 단말에 포함되어 동작할 수도 있고, 외부의 장치 (예컨대, 외부의 서버 등)에 포함되어 상술된 통신 프로세서 및/또는 인터페이스 모듈에 기초한 연동 을 통하여 동작할 수도 있다. 위치 센서(IMU, 463)는, 단말의 움직임 및 가속도 중 적어도 하나 이상을 감지할 수 있다. 예를 들어, 가 속도계, 자이로스코프, 자력계와 같은 다양한 위치 센서의 조합으로 이루어질 수 있다. 또한, 위치 센서(IMU, 463)는, 통신 프로세서의 GPS와 같은 위치 통신 프로세서과 연동하여, 단말 주변의 물리적 공간에 대한 공간 정보를 인식할 수 있다. 오디오 센서는, 단말 주변의 소리를 인식할 수 있다. 자세히, 오디오 센서는, 단말을 사용하는 유저의 음성 입력을 감지할 수 있는 마이크로폰을 포함할 수 있다. 실시예에서 오디오 센서는 안전관리 서비스를 위해 필요한 음성 데이터를 유저로부터 입력 받을 수 있다. 디스플레이 시스템은, 안전관리 서비스와 관련된 다양한 정보를 그래픽 이미지로 출력할 수 있다. 실시예로, 디스플레이 시스템은, 안전관리 서비스를 위한 각종 사용자 인터페이스(실시예로, 스마트 관제 설정 인터페이스 및/또는 인파 모니터링 인터페이스 등) 등을 표시할 수 있다. 이러한 디스플레이는, 액정 디스플레이(liquid crystal display, LCD), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display, TFT LCD), 유기 발광 다이오드(organic light-emitting diode, OLED), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전자잉크 디스플레이(e-ink display) 중에서 적어도 하나를 포함할 수 있다. 이러한 단말의 하우징 내에는 상기 구성요소들이 배치될 수 있으며, 사용자 인터페이스는 유저 터치 입력 을 수신하도록 구성된 디스플레이 상에 터치 센서를 포함할 수 있다. 자세히, 디스플레이 시스템은, 이미지를 출력하는 디스플레이와, 유저의 터치 입력을 감지하는 터치 센서를 포함할 수 있다. 예시적으로 디스플레이는 터치 센서와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써, 터치 스크린으로 구현될 수 있다. 이러한 터치 스크린은, 단말과 유저 사이의 입력 인터페이스를 제공하는 유저 입력부로써 기능함과 동시에, 단말과 유저 사이의 출력 인터페이스를 제공할 수 있다. 상술한 구성요소를 포함하는 단말은, 실시예에 따라 메모리에 적어도 하나 이상의 관제 대상 지역, 관제 시간, 촬영 스팟, CCTV 스팟, 모니터링 영상, 인파 밀집도, 인파 사고 가능성, 비주얼 콘텐츠, 가공 모니 터링 영상 및/또는 상황별 솔루션을 저장할 수 있다.또한, 실시예에서 단말은, 테더 드론 어셈블리와 유무선 통신을 수행함으로써 테더 드론을 제어할 수 있다. 또한, 실시예에서 단말은, 테더 드론이 획득한 비행 관련 정보 및/또는 관제 대상 지역에 대한 촬영 정보를 포함하는 각종 정보를 수신할 수 있다. 또한, 실시예에서 단말은, 수신한 정보를 기초로 소정의 딥러닝 모델을 기초로 인파 밀집도를 분석할 수 있다. 실시예에서 단말은, 분석된 인파 밀집도를 기초로 상황별 솔루션(예컨대, 대피 방송, 구조인력 배치 등)을 제공할 수 있다. 또한, 실시예에서 단말은, 인파 밀집도 분석에 따른 비주얼 콘텐츠를 생성할 수 있다. 또한, 실시예에서 단말은, 생성된 비주얼 콘텐츠를 모니터링 영상에 적용시킨 가공 모니터링 영상을 제공 할 수 있다. 한편, 실시예에 따라서 단말은, 후술되는 스마트 관제 서버에서 수행하는 기능 동작의 적어도 일부를 더 수행할 수도 있다. - 스마트 관제 서버(500: Smart Control Server) 한편, 본 발명의 실시예에 따른 스마트 관제 서버는, 안전관리 서비스를 제공하기 위한 일련의 프로세스를 수행할 수 있다. 자세히, 실시예에서 스마트 관제 서버는, 단말과 같은 외부의 장치에서 안전관리 서비스 프로세스가 구동되게 하기 위해 필요한 데이터를 상기 외부의 장치와 교환함으로써, 상기 안전관리 서비스를 제공할 수 있 다. 보다 상세히, 실시예에서 스마트 관제 서버는, 외부의 장치(실시예에서, 모바일 타입 컴퓨팅 장치(400-1) 및/또는 데스크탑 타입 컴퓨팅 장치(400-2) 등)에서 애플리케이션이 동작할 수 있는 환경을 제공할 수 있 다. 이를 위해, 스마트 관제 서버는, 애플리케이션이 동작하기 위한 응용 프로그램, 데이터 및/또는 명령 어 등을 포함할 수 있고, 이에 기초한 각종 데이터를 상기 외부의 장치와 송수신할 수 있다. 또한, 실시예에서 스마트 관제 서버는, 딥러닝 뉴럴 네트워크(Deep-learning Neural Network)와 연동하여 안전관리 서비스를 위한 각종 딥러닝(Deep Learning)을 수행할 수 있다. 여기서, 실시예에 따른 상기 딥러닝 뉴럴 네트워크는, 컨볼루션 뉴럴 네트워크(CNN, Convolution Neural Network), R-CNN(Regions with CNN features), Fast R-CNN, Faster R-CNN, Mask R-CNN, Yolo-v3 등을 포함할 수 있으며, 후술되는 실시예를 수행할 수 있는 알고리즘을 포함하는 딥러닝 뉴럴 네트워크라면 어떠한 것이든 포함할 수 있으며, 본 발명의 실시예에서는 이러한 딥러닝 뉴럴 네트워크 자체를 한정하거나 제한하지는 않는다. 자세히, 실시예에서 스마트 관제 서버는, 딥러닝 뉴럴 네트워크를 기초로 모니터링 영상에 대한 인파 밀집 도를 분석할 수 있다. 이때, 실시예에 따라서 상기 딥러닝 뉴럴 네트워크는, 스마트 관제 서버에 직접 설치되거나, 스마트 관제 서버와는 별개의 장치로서 동작하여 상기 안전관리 서비스를 위한 딥러닝을 수행할 수 있다. 이하의 실시예에서는, 딥러닝 뉴럴 네트워크가 스마트 관제 서버에 직접 설치되어 딥러닝을 수행하는 실시 예를 기준으로 설명한다. 또한, 실시예에서 스마트 관제 서버는, 상기 딥러닝을 수행하기 위해 구축되어 있는 소정의 딥러닝 뉴럴 네트워크 구동 프로그램을 메모리로부터 독출하여, 상기 독출된 소정의 딥러닝 뉴럴 네트워크 시스템에 따라 하 기 기술하는 딥러닝을 수행할 수 있다. 실시예에서 스마트 관제 서버는, 테더 드론 어셈블리 및 단말과 통신할 수 있다. 또한, 실시예에서 스마트 관제 서버는, 테더 드론이 획득한 비행 관련 정보 및 모니터링 영상을 전송 받아 데이터베이스에 저장할 수 있다. 또한, 실시예에서 스마트 관제 서버는, AI(인공지능), 딥러닝 모델을 기초로 모니터링 영상에 대한 인파 밀집도를 분석할 수 있다. 또한, 실시예에서 스마트 관제 서버는, 분석된 인파 밀집도를 기초로 생성된 비주얼 콘텐츠를 모니터링 영 상에 적용하여 제공할 수 있다. 또한, 실시예에서 스마트 관제 서버는, 안전관리 서비스를 구현하기 위한 각종 응용 프로그램, 명령어 및/ 또는 데이터 등을 저장하고 관리할 수 있다. 실시예로, 스마트 관제 서버는, 관제 대상 지역, 관제 시간, 촬영 스팟, CCTV 스팟, 모니터링 영상, 인파 밀집도, 인파 사고 가능성, 비주얼 콘텐츠, 가공 모니터링 영상, 상황별 솔루션, 스마트 관제 설정 인터페이스 및/또는 인파 모니터링 인터페이스 등을 저장 및 관리할 수 있다. 다만, 본 발명의 실시예에서 스마트 관제 서버가 수행할 수 있는 기능 동작은 상술된 바에 한정되지 않으 며, 또 다른 기능 동작을 더 수행할 수도 있다. 한편, 도 1을 더 참조하면, 실시예에서 위와 같은 스마트 관제 서버는, 데이터 처리를 위한 적어도 하나 이상의 프로세서 모듈(310: Processor Module)과, 외부의 장치와의 데이터 교환을 위한 적어도 하나 이상의 커 뮤니케이션 모듈(320: Communication Module)과, 안전관리 서비스의 제공을 위한 각종 응용 프로그램, 데이터 및/또는 명령어들을 저장하는 적어도 하나 이상의 메모리 모듈(330: Memory Module)을 포함하는 소정의 컴퓨팅 장치로 구현될 수 있다. 여기서, 상기 메모리 모듈은, 안전관리 서비스를 제공하기 위한 운영체제(OS), 각종 응용 프로그램, 데이 터 및 명령어 중 어느 하나 이상을 저장할 수 있다. 또한, 상기 메모리 모듈은, 프로그램 영역과 데이터 영역을 포함할 수 있다. 여기서, 실시예에 따른 프로그램 영역은, 서버를 부팅하는 운영체제(OS: Operating System) 및 기능요소들 사이 에 연계될 수 있으며, 데이터 영역은, 서버의 사용에 따라 발생하는 데이터가 저장될 수 있다. 실시예에서, 이러한 메모리 모듈은, ROM, RAM, EPROM, 플래시 드라이브, 하드 드라이브 등과 같은 다양한 저장기기일 수 있고, 인터넷(internet)상에서 상기 메모리 모듈의 저장 기능을 수행하는 웹 스토리지(web storage)일 수도 있다. 또한, 메모리 모듈은, 서버 상에 탈착 가능한 형태의 기록매체일 수 있다. 한편, 상기 프로세서 모듈은, 안전관리 서비스를 구현하기 위하여 전술한 각 유닛(unit)의 전반적인 동작 을 컨트롤할 수 있다. 이러한 프로세서 모듈은, 중앙처리장치(CPU) 및/또는 그래픽처리장치(GPU) 등이 포함된 서버에 적합한 시 스템 온 칩(SOC)일 수 있으며, 메모리 모듈에 저장된 운영체제(OS) 및/또는 응용 프로그램 등을 실행할 수 있고, 서버에 탑재된 각 구성요소들을 제어할 수 있다. 또한, 프로세서 모듈은, 각 구성요소와 내부적으로 시스템 버스(System Bus)에 의해 통신을 수행할 수 있 고, 로컬 버스(Local Bus)를 비롯한 소정의 버스 구조들을 하나 이상 포함할 수 있다. 또한, 프로세서 모듈은, ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세스 (microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 이상의 설명에서는, 본 발명의 실시예에 따른 스마트 관제 서버가 상술된 바와 같은 기능 동작을 수행한다 고 설명하였으나, 실시예에 따라서 스마트 관제 서버에서 수행하는 기능 동작의 적어도 일부를 외부의 장 치(예컨대, 단말 등)에서 수행할 수도 있고, 상기 외부의 장치에서 수행하는 기능 동작의 적어도 일부를 상기 스마트 관제 서버에서 더 수행할 수도 있는 등 다양한 실시예가 가능할 수 있다.- 인파 밀집이 예상되는 지역을 모니터링하는 방법 이하, 본 발명의 실시예에 따른 단말의 적어도 하나 이상의 프로세서에 의하여 실행되는 애플리케이션 이 안전관리 서비스를 제공하기 위해 인파 밀집이 예상되는 지역을 모니터링하는 방법을 첨부된 도 5 내지 도 8을 참조하여 상세히 설명한다. 본 발명의 실시예에서 상기 단말의 적어도 하나 이상의 프로세서는, 적어도 하나 이상의 메모리에 저 장된 적어도 하나 이상의 애플리케이션을 실행하거나 백그라운드 상태로 동작하게 할 수 있다. 이하, 상기 적어도 하나 이상의 프로세서가 상기 애플리케이션의 명령어를 실행하기 위해 동작하여 상술된 인파 밀집이 예상되는 지역을 모니터링하는 방법을 수행하는 것을 상기 애플리케이션이 수행하는 것으로 단축하여 설명한다. 도 5는 본 발명의 실시예에 따른 인파 밀집이 예상되는 지역을 모니터링하는 방법을 설명하기 위한 흐름도이다. 도 5를 참조하면, 실시예에서 애플리케이션은, 관제 대상 지역 및 관제 시간을 설정할 수 있다. (S101) 자세히, 실시예에서 애플리케이션은, 지도, 상시 CCTV 영상 및/또는 로드뷰 사진 중 적어도 하나를 기초로 관제 대상 지역을 설정할 수 있는 스마트 관제 설정 인터페이스를 기초로 관제 대상 지역 및 관제 시간을 설정 할 수 있다. 여기서, 실시예에 따른 관제 대상 지역이란, 일시적 또는 상시적으로 인구 밀집 현상이 자주 일어나 통제가 필 요한 실제 구간을 의미하며, 예컨대 유동 인구가 많은 유흥 거리, 출퇴근 거리, 교통 혼잡 도로 등을 포함할 수 있다. 이러한 관제 대상 지역은, 테더 드론 어셈블리의 베이스 스테이션이 고정된 상태에서 테더 드론이 최대로 움직일 수 있는 범위(이하, 제1 레인지)보다 크거나 작을 수 있다. 실시예에 따른 관제 대상 지역이 상기 제1 레인지보다 작으면, 베이스 스테이션의 위치는 고정될 수 있다. 그러나, 관제 대상 지역이 상기 제1 레인지보다 크면, 베이스 스테이션의 위치를 변경해가며 대상 지역을 관제해야 하므로 실시예에서 애플리케이션은 베이스 스테이션의 이동 위치를 추가적으로 결정할 수 있다. 또한, 상기 관제 대상 지역을 모니터링 할 시간을 관제 시간으로 설정할 수 있다. 이때, 상기 관제 시간은, 인 구 밀집 현상이 발생하는 시간대(예컨대, 출퇴근시간대)일 수 있다. 이때, 실시예에서 애플리케이션은, 상기 설정된 관제 대상 지역 및 관제 시간에 대해 항공안전법 제127조 등에 따른 드론비행 승인 허가를 신청할 수 있다. 이를 위해, 실시예에서 애플리케이션은, 상기 드론비행 승인 허가를 수행하는 담당 기관의 전화번호 및/또 는 웹 사이트로 연결되는 링크를 제공할 수 있다. 상기 신청에 따른 허가가 완료되면, 실시예에서 애플리케이션은, 상기 관제 대상 지역에 대해 적어도 하나 이상의 촬영 스팟을 결정할 수 있다. (S103) 자세히, 실시예에서 애플리케이션은, 스마트 관제 설정 인터페이스를 기초로 상기 관제 대상 지역에 대해 적어도 하나 이상의 촬영 스팟을 결정할 수 있다. 여기서, 실시예에 따른 촬영 스팟이란, 관제 대상 지역을 다양한 높이 및 각도에서 촬영하여 해당 관제 대상 지 역이 테더 드론의 카메라 앵글에 포함될 수 있도록 하는 촬영 지점을 의미할 수 있다. 이러한 촬영 스팟은, 테더 드론 기체(機體)의 비행 위치 및/또는 베이스 스테이션의 위치를 의미할 수 있다. 통상적으로 가장 이상적인 촬영 스팟은, 관제 대상 지역의 중심부로부터 상기 관제 대상 지역이 소정의 높이만 큼 상공으로 수직한 위치일 수 있다. 이러한 수직 위치에서 드론은 제자리 비행(호버링, hovering)하며 관제 대 상 지역을 촬영할 수 있다. 그러나, 촬영 방해 시설물(예컨대, 건물, 전봇대, 전선줄 등)에 의해 수직한 위치에서 드론 촬영이 불가하면, 관제 대상 지역으로부터 소정의 범위만큼 측면인 위치에서 상기 관제 대상 지역을 촬영할 수 있다. 이와 같이, 실시예에서 애플리케이션은, 관제 대상 지역을 촬영하기 위한 적어도 하나 이상의 촬영 스팟을 산출할 수 있다.도 6은 본 발명의 실시예에 따른 스마트 관제 설정 인터페이스의 일례이다. 도 6을 참조하면, 실시예에서 애플리케이션은, 스마트 관제 설정 인터페이스(SI)를 기초로 관제 대상 지역 및/또는 적어도 하나의 촬영 스팟(701, 702, 703)을 결정할 수 있다. 실시예에서 애플리케이션은, 단말 사용자의 입력을 기초로 관제 대상 지역을 선택할 수 있다. 이때, 상기 관제 대상 지역은 사용자의 자동 및/또는 수동 선택 입력을 통해 결정될 수 있다. 또한, 실시예에서 애플리케이션은, 관제 대상 지역이 결정되면, 촬영 스팟 결정을 위해 상기 결정된 관제 대상 지역을 확대하여 표시할 수 있다. 이때, 상기 촬영 스팟은, 자동 프로세스 및/또는 사용자의 수동 선택 입력을 통해 결정될 수 있다. 상기 자동 프로세스는, 상기 관제 대상 지역으로부터 기 설정된 거리 이내에 적어도 둘 이상의 CCTV가 존재하는 경우 추천 촬영 스팟을 제공하는 프로세스를 의미할 수 있다. 이때, 상기 추천 촬영 스팟에는, CCTV 스팟이 미리 포함되어 있을 수 있다. 왜냐하면, 상기 CCTV 스팟은, 관제 대상 지역 전체를 관제하기에 적합한 촬영 스팟이 될 수 있기 때문이다. 상기 추천 촬영 스팟을 제공하기 위하여, 실시예에서 애플리케이션은, 자동 프로세스를 실행하여 CCTV가 기 설치된 적어도 둘 이상의 CCTV 스팟을 산출할 수 있다. 또한, 실시예에서 애플리케이션은, 산출된 CCTV 스팟을 기초로 중간 지점을 결정할 수 있다. 이때, 예를 들어 상기 중간 지점은, 산출된 CCTV 스팟을 서로 직선으로 연결하였을 때 상기 직선이 접하는 지점일 수 있다. 또한, 실시예에서 애플리케이션은, 결정된 중간 지점을 추천 촬영 스팟에 추가할 수 있다. 또한, 실시예에서 애플리케이션은, 상기 중간 지점 및 상기 적어도 둘 이상의 CCTV 스팟을 추천 촬영 스팟 으로 제공할 수 있다. 이때, 실시예에서 애플리케이션은, CCTV 관제 시스템과 연동하여, 상기 CCTV로 촬영되고 있는 화면을 단말 의 디스플레이로 제공할 수 있다. 이에 따라, 상기 CCTV 스팟이 관제 대상 지역 전체를 관제하기에 적합한 촬영 스팟인지를 디스플레이를 통해 확인할 수 있다. 또한, 실시예에서 애플리케이션은, 기 설정된 거리 이내에 CCTV가 미존재하는 경우에는, 촬영 스팟을 선택 하는 단말 사용자의 수동 입력을 감지할 수 있다. 정리하자면, 상기 자동 프로세스를 통해 제공된 추천 촬영 스팟 중 제1 추천 촬영 스팟을 결정하는 단말 사용자 입력 및/또는 단말 사용자의 수동 촬영 스팟 결정 입력을 통해 실시예에서 애플리케이션은 촬 영 스팟을 결정할 수 있다. 이러한 촬영 스팟은, 관제 대상 지역 내부로 결정될 수도 있고, 관제 대상 지역 전체를 촬영하기 위하여 관제 대상 지역 외부로 결정될 수도 있다. 예컨대, 도 6을 참조하면, 제2 촬영 스팟은 관제 대상 지역 내 부로 결정될 수 있다. 또한, 제1 및 제3 촬영 스팟(701, 703)은 관제 대상 지역 외부로 결정될 수 있다. 이때, 상기 제2 촬영 스팟은, 상기 자동 프로세스에 따라 산출된 중간 지점일 수 있다. 또한, 실시예에서 애플리케이션은, 상기 결정된 촬영 스팟에서 테더 드론이 촬영하도록 제어할 수 있다. (S105) 자세히, 실시예에서 애플리케이션은, 테더 드론 어셈블리의 베이스 스테이션 및/또는 테더 드론 와의 데이터 송수신을 기초로 상기 결정된 적어도 하나 이상의 촬영 스팟에서 테더 드론이 촬영하도 록 제어할 수 있다. 이에 따라, 테더 드론의 카메라는, 짐벌을 기초로 외력(예컨대, 바람, 비 등)에도 흔들림 없이 촬영 스팟에서 관제 대상 지역을 촬영할 수 있다. 도 7은 본 발명의 실시예에 따른 드론이 중간 지점에서 관제 대상 지역을 촬영하는 모습의 일례이다. 도 7을 참조하면, 실시예에서 애플리케이션은, 중간 지점인 제2 촬영 스팟에서 관제 대상 지역 을 촬영할 수 있다. 상기 촬영된 관제 대상 지역은, 적어도 하나 이상의 사람(M)을 포함할 수 있다. 또한, 실시예에서 애플리케이션은, 촬영되는 관제 대상 지역을 격자로 나누어 소정의 블록(SA1, SA 2)으로 구분할 수 있다. 이때 각 블록은 1제곱미터일 수 있고, 이에 따라 각 블록에서 감지된 사람의 수를 평균 계산하여 추후에 인파 밀집도를 산출할 수 있다. 이상적으로는 상기 중간 지점인 제2 촬영 스팟에서 항공뷰로 관제 대상 지역을 촬영하면 관제 대상 지역의 인파 밀집도를 산출할 수 있으나, 적어도 하나의 촬영 스팟에서 실제로 촬영을 진행할 시, 애플리 케이션만으로는 파악할 수 없는 현장 정보(예컨대, 새로운 건축물에 의한 시야 제한 등)로 인해 관제 대상 지역이 부적절하게 촬영될 수 있다. 그러므로, 실시예에서 애플리케이션은, 촬영 방해 시설물에 의한 쉐이드 영역(shaded area, 가려지는 영역)이 최소화되도록 테더 드론의 자세(stance)(실시예로, 드론이 비행하는 높이(고도) 및/또는 드론의 각도 등)를 결정하기 위한 스탠스 결정 프로세스를 수행할 수 있다. 실시예에서 애플리케이션은, 베이스 스테이션의 장력 제어부를 제어함으로써 제1 촬영 스팟에서 테더 드론의 높이를 조정할 수 있다. 이때, 실시예에서 애플리케이션은, 테더 드론의 카메라가 촬영하고 있는 모니터링 영상을 실시 간으로 수신하여 디스플레이에 표시할 수 있다. 또한, 실시예에서 애플리케이션은, 자동 및/또는 수동 제어에 따라 제1 체공 높이를 결정할 수 있다. 도 8은 본 발명의 실시예에 따른 스탠스 결정 프로세스를 기초로 드론의 체공 높이를 결정하는 모습을 나타낸 일례이다. 도 8을 참조하면, 실시예에서 애플리케이션은, 실시간으로 수신하는 모니터링 영상(MV) 내에 촬영된 관제 대상 지역의 면적을 계산할 수 있다. 자세히, 상기 도 8에는 제1 높이에서 촬영된 모니터링 영상인 제1 영 상(MV-1)이, 제2 높이에서 촬영된 모니터링 영상인 제2 영상(MV-2)이 도시되어 있다. 이때, 상기 모니터링 영상에 포함된 관제 대상 지역의 면적 계산은 딥러닝 뉴럴 네트워크를 기초로 수행될 수 있다. 상기 면적은, 실제 면적이거나 상기 모니터링 영상에 대한 비중 면적일 수 있다. 또한, 실시예에서 애플리케이션은, 테더 드론의 체공 높이를 실시간으로 변경해가며 상기 모니터링 영상(MV)을 촬영할 수 있다. 예시로, 제1 높이에서의 관제 대상 지역의 제1 면적(A) 및 제2 높이에서의 관제 대상 지역의 제2 면 적(B)은 상이할 수 있다. 왜냐하면, 제1 높이가 제2 높이보다 낮으므로, 드론의 카메라와 지면이 더 가깝기 때 문에 관제 대상 지역이 더 확대되어 보이기 때문이다. 이때, 실시예에서 애플리케이션은, 모니터링 영상(MV) 내에 촬영된 관제 대상 지역의 면적(A, B)이 기 설 정된 면적으로부터 오차범위 이내이면, 테더 드론의 상승 및/또는 하강을 멈추고 해당 높이를 제1 체공 높 이로 결정하는 자동 제어를 수행할 수 있다. 예컨대, 상기 기 설정된 면적은 모니터링 영상(MV) 대비 40%의 비 율일 수 있다. 이는, 관제 대상 지역 전체를 총괄할 수 있을 정도의 체공 높이를 정하기 위함일 수 있다. 상기 예시를 다시 들 면, 제1 면적(A)은 지면과 가까워 관제 대상 지역 전체를 확인할 수 없으므로, 제2 면적(B)을 촬영할 당시 의 제2 높이가 관제 대상 지역을 확인하기에 적합한 체공 높이일 수 있다. 즉, 상기 예시에서는 기 설정된 면적으로부터 오차범위 이내의 면적이 감지된 당시의 높이인 제2 높이가 제1 체 공 높이로 결정될 수 있다. 또한, 실시예에서 애플리케이션은, 결정된 제1 체공 높이에서 테더 드론을 제어하여 테더 드론 의 카메라 앵글 각도를 조정할 수 있다. 또한, 실시예에서 애플리케이션은, 자동 및/또는 수동 제어에 따라 제1 체공 각도를 결정할 수 있다. 도 9는 본 발명의 실시예에 따른 스탠스 결정 프로세스를 기초로 드론의 체공 각도를 결정하는 모습을 나타낸 일례이다. 도 9를 참조하면, 마찬가지로 실시예에서 애플리케이션은, 실시간으로 수신하는 모니터링 영상(MV) 내에 촬영된 관제 대상 지역의 면적을 계산할 수 있다. 자세히, 상기 도 9에는 제1 각도에서 촬영된 모니터링영상인 제3 영상(MV-3)이, 제2 각도에서 촬영된 모니터링 영상인 제4 영상(MV-4)이 도시되어 있다. 예시로, 제1 각도에서의 관제 대상 지역의 제3 면적(C) 및 제2 각도에서의 관제 대상 지역의 제4 면 적(D)은 상이할 수 있다. 왜냐하면, 제1 각도가 제2 각도보다 소정 각도 편향되어있어, 관제 대상 지역 인 근 건축물 등에 상기 관제 대상 지역의 일부를 가리기 때문이다. 이때, 실시예에서 애플리케이션은, 모니터링 영상(MV) 내에 촬영된 관제 대상 지역의 면적(C, D)이 기 설 정된 면적으로부터 오차범위 이내이면, 테더 드론의 각도 조정을 멈추고 해당 각도를 제1 체공 각도로 결 정하는 자동 제어를 수행할 수 있다. 예컨대, 상기 기 설정된 면적은 모니터링 영상(MV) 대비 40%의 비율일 수 있다. 이는, 관제 대상 지역 전체를 총괄하기 위해 해당 관제 대상 지역을 촬영하는 데에 방해물 등의 영향을 받지 않 도록 하기 위함일 수 있다. 상기 예시를 다시 들면, 제3 면적(C)은 소정의 건축물 등이 관제 대상 지역의 일부를 가려 관제 대상 지역 전체를 확인할 수 없으므로 제4 면적(D)을 촬영할 당시의 제2 각도가 관제 대 상 지역을 확인하기에 적합한 체공 각도일 수 있다. 즉, 상기 예시에서는 기 설정된 면적으로부터 오차범위 이내의 면적이 감지된 당시의 각도인 제2 각도가 제1 체 공 각도로 결정될 수 있다. 이에 따라, 실시예에서 애플리케이션은, 결정된 제1 체공 높이 및 제1 체공 각도를 상기 제1 촬영 스팟에 서의 제1 스탠스로 결정할 수 있다. 실시예에서 상기 스탠스는, 테더 드론의 높이 및 각도를 포함하는 드 론 기체의 자세를 의미할 수 있다. 실시예에서 애플리케이션은, 상기 제1 스탠스가 결정되면, 테더 드론 어셈블리의 장력 제어부를 제어하여 상기 제1 스탠스로 세팅되도록 상기 테더 드론의 비행을 제어할 수 있다. 이를 위해, 실시예에서 애플리케이션은, 체공 높이별로 케이블의 장력을 기 설정할 수 있다. 즉, 실시예에서 애플리케이션은, 결정된 제1 스탠스에 따라 해당 체공 높이에 기 설정된 케이블의 장력으 로 세팅되도록 테더 드론의 장력 제어부의 모터를 자동 제어함으로써 테더 드론의 높이를 조절 할 수 있다. 실시예에서 애플리케이션은, 상기 제1 스탠스가 결정되면, 결정된 제1 스탠스를 유지하며 제1 촬영 스팟에 서의 촬영을 진행할 수 있다. 상기 제1 촬영 스팟에서 관제 대상 지역을 촬영한 시간이 기 설정된 소정의 시간을 초과하면, 실시예에서 애플 리케이션은, 상기 테더 드론이 제2 촬영 스팟으로 이동하도록 제어할 수 있다. 이때, 상기 제1 촬영 스팟 및 제2 촬영 스팟은, 테더 드론의 케이블 길이에 따라 이동 가능한 거리일 수 있다. 필요에 따라, 테더 드론 어셈블리의 베이스 스테이션을 이동시킬 수 있다. 상술한 스탠스 결정 프로세스를 기초로, 상기 제2 촬영 스팟에 대한 제2 스탠스를 결정하여 기 설정된 소정의 시간동안 촬영을 진행할 수 있다. 이러한 방법으로, 복수 개의 촬영 스팟에 대하여 순환 비행하며 관제 대상 지역을 측면뷰 촬영할 수 있다. 또한, 실시예에서 애플리케이션은, 적어도 하나 이상의 촬영 스팟 각각별로 모니터링 영상을 획득할 수 있 다. (S107) 자세히, 실시예에서 애플리케이션은, 제1 촬영 스팟에서는 제1 모니터링 영상을 매칭 및 획득하고, 제2 촬 영 스팟에서는 제2 모니터링 영상을 각각 매칭 및 획득할 수 있다. 실시예에서 상기 제1 내지 제n 모니터링 영상은, 동일한 관제 대상 지역을 다각도에서 촬영한 영상이므로, 해당 모니터링 영상들을 종합하여 관제 대상 지역에 대한 정확한 분석을 수행할 수 있다. 실시예에서 애플리케이션은, 기 설정된 소정의 시간동안 해당 촬영 스팟을 촬영함으로써, 사람 수, 차량 수, 이상행동 중 적어도 하나를 포함하는 모니터링 영상을 획득할 수 있다. 이하에서는, 설명의 편의를 위해 모 니터링 영상이 사람 수를 포함하는 것에 기준하여 설명하도록 한다. 또한, 실시예에서 애플리케이션은, 획득된 적어도 하나 이상의 모니터링 영상에 대하여 각각 인파 밀집도 를 실시간으로 분석할 수 있다. (S109)예컨대, 상기 애플리케이션은, Cascade Mask R-CNN 및/또는 Yolo-v3을 포함하는 딥러닝 모델을 기초로 관 제 대상 영상에 포함된 적어도 한 명 이상의 사람 및/또는 대상을 카운팅(counting)할 수 있다. 또한, 실시예에서 애플리케이션은, 상기 분석된 인파 밀집도에 따라 제n 촬영 스팟을 결정할 수 있다. (S111) 이때, 상기 제n 촬영 스팟은, 복수 개의 촬영 스팟 중 인파 밀집도가 가장 높게 분석된(다시 말해, 카운팅된 사 람 수의 값이 가장 큰) 촬영 스팟일 수 있다. 다시 말해, 상기 제n 촬영 스팟은, 관제 대상 지역을 다양한 각도에서 촬영하였을 때, 해당 관제 대상 지역에 포함된 인파를 누락 없이 반영한 촬영 스팟일 수 있다. 또한, 실시예에서 애플리케이션은, 상기 제n 촬영 스팟으로 테더 드론을 이동하도록 제어하여 촬영을 수행할 수 있다. 이에 따라, 실시예에서 애플리케이션은, 상기 제n 촬영 스팟에서 고정하여 지속적으로 관제 대상 지역 을 실시간 모니터링할 수 있다. 추가적으로, 다른 실시예에서 애플리케이션은, 적어도 하나 이상의 모니터링 영상에 대한 인파 밀집도를 산출하면서, 주변 지역 정보를 산출할 수 있다. 상기 주변 지역 정보란, 관제 대상 지역으로부터 기 설정된 소정의 거리 이내에 위치한 대피 가능한 건물, 해당 건물의 입구, 비상구, 샛길 등을 포함하는 정보일 수 있다. 다른 실시예에서 애플리케이션은, 산출된 주변 지역 정보를 기초로 모니터링 영상에 대한 솔루션을 제공할 수 있다. 이에 대한 설명은 후술되는 제2 실시예에서 설명하도록 한다. 또한, 실시예에서 애플리케이션은, 실시간으로 촬영되는 제n 모니터링 영상을 베이스 스테이션, 단말 및/또는 스마트 관제 서버로 전송할 수 있다. 이에 따라, 상기 베이스 스테이션, 단말 및/또는 스마트 관제 서버 중 적어도 하나는, 테더 드 론으로부터 수신되는 모니터링 영상을 기초로 인파 사고 가능성을 예측할 수 있다. 이하에서는, 단말(40 0)의 애플리케이션이 수행하는 것으로 간주하여 설명한다. - 모니터링 영상을 기초로 인파 사고 가능성을 예측하는 방법 이하, 본 발명의 실시예에 따른 단말의 적어도 하나 이상의 프로세서에 의하여 실행되는 애플리케이션 이 모니터링 영상을 기초로 인파 사고 가능성을 예측하는 인파 사고 예방 서비스를 제공하는 방법을 첨부 된 도 10 및 도 11을 참조하여 상세히 설명한다. 도 10은 본 발명의 실시예에 따른 모니터링 영상을 기초로 인파 사고 가능성을 예측하는 방법을 설명하기 위한 흐름도이다. 도 10을 참조하면, 실시예에서 애플리케이션은, 테더 드론으로부터 제1 모니터링 영상을 실시간으로 획득할 수 있다. (S301) 이때, 상기 제1 모니터링 영상은, 상술한 S111 단계에서 결정된 제n 촬영 스팟에서 테더 드론의 카메라 를 기초로 관제 대상 지역을 촬영한 영상일 수 있다. 또한, 실시예에서 애플리케이션은, 딥러닝 뉴럴 네트워크를 기초로 상기 제1 모니터링 영상에 대한 인파 밀집도를 산출할 수 있다. (S303) 실시예에서 애플리케이션은, 상기 인파 밀집도를 산출하기 위해, 상기 제1 모니터링 영상에서 자동 및/또 는 수동으로 관제 대상 지역에 해당되는 영역을 지정할 수 있다. 이때, 상기 관제 대상 지역의 실제 면적은, 적어도 하나 이상의 촬영 스팟에서 촬영된 복수 개의 모니터링 영상 을 기초로 예측되어 결정되거나, 제1 모니터링 영상에 감지된 관제 대상 지역의 실제 면적을 입력하는 단말 사용자의 수동 입력으로 결정될 수 있다. 상기 제1 모니터링 영상 내의 실제 면적을 예측하기 위해, 실시예에서 애플리케이션은, 복수 개의 모니터 링 영상에 대한 딥러닝을 수행함으로써 관제 대상 지역의 실제 면적을 획득할 수 있다.실시예에서 애플리케이션은, 복수 개의 모니터링 영상을 딥러닝 뉴럴 네트워크에 입력할 수 있다. 상기 딥 러닝 뉴럴 네트워크는 예컨대 Mask R-CNN일 수 있으며, 이미지 인식 기술에 관한 기술이라면 어떠한 것이든 활 용될 수 있다. 이때, 복수 개의 모니터링 영상을 입력받은 딥러닝 뉴럴 네트워크는, 상기 입력된 복수 개의 모니터링 영상에 따른 관제 대상 지역의 실제 면적을 출력 데이터로 제공할 수 있다. 즉, 실시예에서 애플리케이션은, 상기 딥러닝 뉴럴 네트워크로부터 출력되는 상기 관제 대상 지역의 실제 면적을 수신함으로써 복수 개의 모니터링 영상에 기초하는 관제 대상 지역의 실제 면적을 획득할 수 있다. 이어서, 실시예에서 애플리케이션은, 상기 제1 모니터링 영상에 대한 딥러닝을 수행함으로써 상기 제1 모 니터링 영상의 관제 대상 지역 내에서 감지된 실제 사람 수를 획득할 수 있다. 실시예에서 애플리케이션은, 상기 제1 모니터링 영상을 딥러닝 뉴럴 네트워크에 입력할 수 있다. 상기 딥 러닝 뉴럴 네트워크는 예컨대 Cascade Mask R-CNN 및/또는 Yolo-v3일 수 있으며, 영상 기반 인원 계수에 관한 기술이라면 어떠한 것이든 활용될 수 있다. 이때, 상기 제1 모니터링 영상을 입력받은 딥러닝 뉴럴 네트워크는, 상기 입력된 제1 모니터링 영상에 따른 관 제 대상 지역 내의 실제 사람 수를 출력 데이터로 제공할 수 있다. 즉, 실시예에서 애플리케이션은, 상기 딥러닝 뉴럴 네트워크로부터 출력되는 상기 관제 대상 지역 내의 실 제 사람 수를 수신함으로써 상기 제1 모니터링 영상에 기초하는 관제 대상 지역 내 실제 사람 수를 획득할 수 있다. 이에 따라, 실시예에서 애플리케이션은, 제1 모니터링 영상에 포함된 관제 대상 지역의 실제 면적 및 해당 관제 대상 지역 내에서 감지된 실제 사람 수를 획득할 수 있다. 이어서, 실시예에서 애플리케이션은, 획득된 관제 대상 지역의 실제 면적 및 실제 사람 수를 기초로 인파 밀집도를 산출할 수 있다. 이때, 실시예에 따른 인파 밀집도는, 1제곱미터(m2) 당 사람 수를 의미할 수 있다. 또한, 실시예에서 애플리케이션은, 산출된 인파 밀집도에 따른 인파 사고 가능성을 예측할 수 있다. (S305) 이를 위해, 실시예에서 애플리케이션은, 인파 밀집도의 값 별로 소정의 파라미터를 기 설정할 수 있다. 예를 들어, 애플리케이션은, 인파 밀집도에 따른 단계를 '안전-주의-경계-위험-심각' 이라는 5단계로 분류 할 수 있다. 자세히, 1제곱미터(m2) 당 사람 수가 1~2명일 때가 '안전' 단계, 2~3명일 때가 '주의' 단계, 3~4명 일 때가 '경계' 단계, 4~5명일 때가 '위험' 단계, 5명 이상일 때가 '심각' 단계로 분류될 수 있다. 또한, 실시예에서 애플리케이션은, 인파 밀집도에 따른 각 단계별로 인파 사고 가능성(실시예로, 퍼센트 (%))을 기 매칭할 수 있다. 예를 들어, '안전' 단계에는 10%, '주의' 단계에는 30%, '경계' 단계에는 50%, '위험' 단계에는 70%, '심각' 단 계에는 90% 전후의 인파 사고 가능성이 기 매칭될 수 있다. 또한, 실시예에서 애플리케이션은, 상기 인파 밀집도 및 인파 사고 가능성을 표시하는 비주얼 콘텐츠를 생 성할 수 있다. (S307) 여기서, 실시예에 따른 비주얼 콘텐츠란, 제1 모니터링 영상 상에 시각적으로 표시되는 소정의 콘텐츠로, 이를 통해 단말 사용자가 관제 대상 지역의 인파 밀집을 용이하게 확인할 수 있다. 이러한 비주얼 콘텐츠는, 면적 마크, 사람 마크 및/또는 텍스트 박스를 포함할 수 있다. 상기 면적 마크를 생성하기 위하여, 실시예에서 애플리케이션은, 상기 제1 모니터링 영상에서 관제 대상 지역을 감지할 수 있다. 또한, 상기 감지된 관제 대상 지역과 매칭되는 영역에 면적 마크를 생성할 수 있다. 상기 사람 마크를 생성하기 위하여, 실시예에서 애플리케이션은, 상기 관제 대상 지역 내의 적어도 하나 이상의 사람을 감지할 수 있다. 또한, 상기 감지된 사람의 머리와 매칭되는 영역에 사람 마크를 생성할 수 있다. 예컨대, 상기 면적 마크는 한 개일 수 있고, 상기 면적 마크에 포함되는 사람 마크는 사람 수에 대응되는 수로 복수 개일 수 있다. 실시예에서 애플리케이션은, 상기 생성된 비주얼 콘텐츠를 적용한 가공 모니터링 영상을 제공할 수 있다. (S309) 여기서, 실시예에 따른 가공 모니터링 영상이란, 상기 제1 모니터링 영상에 상기 생성된 비주얼 콘텐츠가 적용 된 영상을 의미할 수 있다. 이때, 실시예에서 애플리케이션은, 상기 생성된 비주얼 콘텐츠를 적용한 가공 모니터링 영상을 인파 모니 터링 인터페이스를 기초로 제공할 수 있다. 도 11은 본 발명의 실시예에 따른 비주얼 콘텐츠가 적용된 가공 모니터링 영상의 일례를 나타낸 것이다. 도 11을 참조하면, 실시예에서 애플리케이션은, 비주얼 콘텐츠를 포함하는 가공 모니터링 영상(PMV)를 제 공할 수 있다. 이때, 상기 가공 모니터링 영상(PMV)은, 영상 영역 및/또는 설명 영역을 포함할 수 있다. 또한, 실시예에서 비주얼 콘텐츠는, 상기 영상 영역 상에 표시된 면적 마크, 사람 마크와, 설명 영역 상에 표시된 복수 개의 텍스트 박스(2100, 2200, 2300)들을 포함할 수 있다. 영상 영역은, 테더 드론으로 실시간 촬영되는 관제 대상 지역의 실제 모습을 포함하는 영역일 수 있다. 면적 마크는, 관제 대상 지역에 해당하는 면적을 색깔 및/또는 소정의 도형으로 표시한 요소일 수 있다. 사람 마크는, 관제 대상 지역에 포함되어 있는 적어도 하나 이상의 사람(예컨대, 사람 머리)에 해당 하는 면적을 색깔 및/또는 소정의 도형으로 표시한 요소일 수 있다. 설명 영역은, 실시간으로 촬영되는 영상 영역에 대한 인파 밀집도를 설명하기 위한 영역일 수 있다. 제1 텍스트 박스는, 분석 대상의 종류에 대해 표시된 텍스트를 포함하는 콘텐츠일 수 있다. 본 발명에서 는 사람 수를 기초로 하는 인파 밀집도에 관한 실시예에 기준하여 설명하므로 상기 분석 대상은 '사람'일 수 있 으나, 다른 실시예에서는 예컨대 '자동차', '자전거', '수하물', '위험 상황' 등을 더 포함할 수 있다. 이때, 단말 사용자가 상기 분석 대상을 재선택하는 입력을 감지하면, 다른 실시예에서 애플리케이션은 해당 분석 대상으로 관제 대상 영역에 대한 재분석을 수행할 수 있다. 제2 텍스트 박스는, 밀집도를 텍스트로 표시하는 콘텐츠일 수 있다. 또한, 상기 제2 텍스트 박스는, 관제 대상 지역의 실제 면적, 산출된 인파 밀집도, 인파 밀집도에 따른 단계 및/또는 인파 사고 가능성 중 적어도 하나를 포함할 수 있다. 제3 텍스트 박스는, 밀집도 예측을 텍스트로 표시하는 콘텐츠일 수 있다. 실시예에서 애플리케이션 은, 외부 서버와 연동하여 유동인구 데이터 및 주변지역 인구이동 데이터를 획득할 수 있다. 또한, 실시예에서 애플리케이션은, 유동인구 데이터 및/또는 인구이동 데이터를 활용 및 분석하여 관제 대상 지역의 특정 시 간대의 밀집도를 예측하여 표시할 수 있다. 또한, 실시예에 따른 설명 영역은, 솔루션으로 즉각 연결되는 링크 버튼을 더 포함할 수 있다. 실 시예에서 단말 사용자가 상기 링크 버튼을 누르는 입력을 수행하면, 애플리케이션은 인파 밀집 도에 따른 솔루션을 제공하는 링크로 연결할 수 있다. 또한, 실시예에 따른 설명 영역은, 촬영 스팟을 변경하기 위한 스팟 변경 버튼을 더 포함할 수 있 다. 실시예에서 단말 사용자가 상기 스팟 변경 버튼을 누르는 입력을 수행하면, 애플리케이션 은 기 설정된 다른 촬영 스팟을 표시하고, 제n 촬영 스팟이 선택되면 해당 스팟으로 테더 드론을 움직이도 록 제어할 수 있다. 또한, 실시예에서 애플리케이션은, 제공된 가공 모니터링 영상에 따라 상황별 솔루션을 제공할 수 있다. (S311) 여기서, 실시예에 따른 상황별 솔루션이란, 관제 대상 지역에서 관찰된 인파 밀집도에 따른 단계 및/또는 분석 대상에 따라 실제 관제 대상 지역에 투입되는 해결 방법을 의미할 수 있다. 자세히, 실시예에서 애플리케이션은, 가공 모니터링 영상의 인파 밀집도에 따른 단계가 '경계' 이상이면, 연계 기관(예컨대, 경찰 및/또는 소방 등 관제 대상 지역의 인원을 통솔하거나 소정의 인원을 구조가 가능한 기 관 등) 및/또는 연결된 단말로 인파 밀집도를 즉각 보고하는 제1 솔루션을 제공할 수 있다. 이때, 상기 제1 솔루션에 따라 상기 인파 밀집도를 연계 기관 및/또는 연결된 단말로 보고할 시에, 모니터링 영 상(MV) 및/또는 가공 모니터링 영상(PMV)의 캡처 이미지, 일부 및/또는 전부를 첨부하여 전송할 수 있다. 또한, 실시예에서 애플리케이션은, 인파 밀집도에 따른 단계가 '위험' 이상이면, 인원 통제를 지시하는 제 2 솔루션을 제공할 수 있다. 또한. 실시예에서 애플리케이션은, 인파 밀집도에 따른 단계가 '심각' 이상이면, 주변 지역에서 관제 대상 지역으로의 진입을 원천 봉쇄하고 대피 방송을 송출하는 제3 솔루션을 제공할 수 있다. 또한, 다른 실시예에서 애플리케이션은, 가공 모니터링 영상(PMV)에 있어 분석 대상의 종류가 자동차이고, 분석 대상에 따른 교통 체증도가 기 설정된 소정의 기준 이상이면, 연계 기관 및/또는 연결된 단말로 교통 체증 도를 즉각 보고하고 교통 관리를 위한 인력을 투입하는 제4 솔루션을 제공할 수 있다. 추가적으로, 다른 실시예에서 애플리케이션은, 적어도 하나 이상의 모니터링 영상을 기초로 주변 지역 정 보를 산출할 수 있다. 또한, 다른 실시예에서 애플리케이션은, 주변 지역 정보를 기초로 제5 솔루션을 제 공할 수 있다. 예를 들어, 상기 제5 솔루션은, 관제 대상 지역으로부터 기 설정된 소정의 거리 이내에 위치한 대피 가능 한 건물, 해당 건물의 입구, 비상구, 샛길 중 적어도 하나로의 길을 안내하는 콘텐츠일 수 있다. 또한, 주변 지 역으로 연락을 취할 수 있는 링크를 제공할 수도 있다. 이러한 상황별 솔루션에 따라 관제 대상 지역에 적절한 조치가 취해지므로, 해당 관제 대상 지역 및 주변지역에 서 발생할 수 있는 사고 발생 가능성을 감소시키고 위험 요소에 대한 발빠른 대처가 가능하다는 장점이 있다. 이상, 본 발명의 실시예에 따른 인공지능을 이용한 테더 드론 기반의 안전관리 방법 및 시스템은, 장기 체공형 테더 드론을 통해 획득되는 실시간 영상 및 임무 데이터를 실시간으로 AI(인공지능) 기반 분석함으로써, 언제 발생할 지 모르는 위험 상황(예컨대, 대기열 발생, 유동인구 급증, 폭력상황 발생 등)을 감지하여 축제·행사에 참여하는 국민의 안전을 확보하여 자연스러운 축제·행사 참여를 유도하고, 이를 통해 경제의 선순환, 새로운 인프라 개선, 국민 삶의 질 향상, 신뢰할 수 있는 정부 등 국가·국민·지자체 모두 win-win 할 수 있는 선순환 구조를 만드는 효과가 있다. 또한, 본 발명의 실시예에 따른 인공지능을 이용한 테더 드론 기반의 안전관리 방법 및 시스템은, 카메라가 장 착된 드론에 연속적인 전원과 통신을 공급함으로써, 갑작스러운 전원공급 중단으로 인한 추락 문제점 및 드론- 송수신기간의 교란 문제점을 보완하여 드론을 활용한 시스템의 신뢰성을 높이는 효과가 있다. 또한, 본 발명의 실시예에 따른 인공지능을 이용한 테더 드론 기반의 안전관리 방법 및 시스템은, 다중 네트워 킹 시스템을 기초로 실시간 드론 영상을 전송함으로써, 지연성이 감소되어 실제 현장 및 관제 영상간의 영상 딜 레이(delay)가 최소화되는 효과가 있다. 또한, 본 발명의 실시예에 따른 인공지능을 이용한 테더 드론 기반의 안전관리 방법 및 시스템은, 실시간 드론 영상을 분석 가공하여 각 상황(예컨대, 이상행동 감지, 대기열 감지 등)별 솔루션을 제공함으로써, 인파, 주차 관리 등의 사고 예방 및 삶의 질 향상에 대한 AI 기술의 핵심요소로 시장 전반의 기술이 향상되고, ICT 전문가 양성, 축제현장 인파관리 전문가 및 AI 학습데이터 수집인력, 드론 파일럿 등 양질의 미래를 선도할 수 있는 일 자리를 창출하는 효과가 있다. 이상 설명된 본 발명에 따른 실시예는 다양한 컴퓨터 구성요소를 통하여 실행될 수 있는 프로그램 명령어의 형 태로 구현되어 컴퓨터 판독 가능한 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체는 프로그 램 명령어, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판독 가능한 기록 매체에 기록되는 프로그램 명령어는 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨 어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크 (floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같은, 프 로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령어의 예에는, 컴파일러에 의하여 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함된다. 하드웨어 장치는 본 발명에 따른 처리를 수행하기 위하여 하나 이 상의 소프트웨어 모듈로 변경될 수 있으며, 그 역도 마찬가지이다. 본 발명에서 설명하는 특정 실행들은 일 실시 예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아 니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어 시스템들, 소프트웨어, 상기 시스템들의 다른 기 능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재들 은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가 능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, “필 수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요소 가 아닐 수 있다. 또한 설명한 본 발명의 상세한 설명에서는 본 발명의 바람직한 실시 예를 참조하여 설명하였지만, 해당 기술 분"}
{"patent_id": "10-2023-0103910", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "야의 숙련된 당업자 또는 해당 기술분야에 통상의 지식을 갖는 자라면 후술할 특허청구범위에 기재된 본 발명의 사상 및 기술 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다. 따라서, 본 발명의 기술적 범위는 명세서의 상세한 설명에 기재된 내용으로 한정되는 것이 아 니라 특허청구범위에 의해 정하여져야만 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2023-0103910", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 스마트 관제 시스템의 개념도이다. 도 2는 본 발명의 실시예에 따른 테더 드론 어셈블리의 일례를 나타낸 도면이다. 도 3은 본 발명의 실시예에 따른 테더 드론 어셈블리의 블록도이다. 도 4는 본 발명의 실시예에 따른 단말의 내부 블록도이다. 도 5는 본 발명의 실시예에 따른 인파 밀집이 예상되는 지역을 모니터링하는 방법을 설명하기 위한 흐름도이다. 도 6은 본 발명의 실시예에 따른 스마트 관제 설정 인터페이스의 일례이다. 도 7은 본 발명의 실시예에 따른 드론이 중간 지점에서 관제 대상 지역을 촬영하는 모습의 일례이다. 도 8은 본 발명의 실시예에 따른 스탠스 결정 프로세스를 기초로 드론의 체공 높이를 결정하는 모습을 나타낸일례이다. 도 9는 본 발명의 실시예에 따른 스탠스 결정 프로세스를 기초로 드론의 체공 각도를 결정하는 모습을 나타낸 일례이다. 도 10은 본 발명의 실시예에 따른 모니터링 영상을 기초로 인파 사고 가능성을 예측하는 방법을 설명하기 위한 흐름도이다. 도 11은 본 발명의 실시예에 따른 비주얼 콘텐츠가 적용된 가공 모니터링 영상의 일례를 나타낸 것이다."}
