{"patent_id": "10-2021-0075591", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0008754", "출원번호": "10-2021-0075591", "발명의 명칭": "시간 동기화된 스토리지 전달을 위한 시스템들, 방법들, 및 장치들", "출원인": "삼성전자주식회사", "발명자": "리, 로날드 씨."}}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 컴퓨팅 장치가 제1 인공 지능 모델 처리부(AI PU; artificial intelligence model processing unit)로부터제1 입/출력(IO; input/output) 커맨드를 수신하되, 상기 제1 IO 커맨드는 제1 AI 모델 트레이닝 동작과 관련되는 단계;상기 제1 컴퓨팅 장치가 제2 AI PU로부터 제2 IO 커맨드를 수신하되, 상기 제2 IO 커맨드는 제2 AI 모델 트레이닝 동작과 관련되는 단계;상기 제1 AI 모델 트레이닝 동작에 할당된 제1 대역폭에 기반하여 제1 타임스탬프를 상기 제1 IO 커맨드에 할당하는 단계; 및상기 제2 AI 모델 트레이닝 동작에 할당된 제2 대역폭에 기반하여 제2 타임스탬프를 상기 제2 IO 커맨드에 할당하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 제1 IO 커맨드는 상기 제1 AI 모델 트레이닝 동작을 식별하는 제1 전역 흐름 식별자(GFID; global flowidentifier)를 포함하고, 및 상기2 IO 커맨드는 상기 제2 AI 모델 트레이닝 동작을 식별하는 제2 GFID를 포함하고,상기 제1 GFID에 기반하여 데이터베이스로부터 상기 제1 AI 모델 트레이닝 동작과 관련된 상기 제1 대역폭의 인디케이션을 검색하는 단계; 및상기 제2 GFID에 기반하여 상기 데이터베이스로부터 상기 제2 AI 모델 트레이닝 동작과 관련된 상기 제2 대역폭의 인디케이션을 검색하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 제1 IO 커맨드에 기반하여 데이터의 제1 청크에 대한 제1 요청을 제1 스토리지 장치에 전송하되, 상기 제1요청은 상기 제1 타임스탬프를 포함하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서, 상기 제1 IO 커맨드에 기반하여 데이터의 제2 청크에 대한 제2 요청을 제2 스토리지 장치에 전송하되, 상기 제2요청은 상기 제1 타임스탬프를 포함하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 상기 제2 IO 커맨드에 기반하여 데이터의 제3 청크에 대한 제3 요청을 제3 스토리지 장치에 전송하되, 상기 제3요청은 상기 제2 타임스탬프를 포함하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 3 항에 있어서, 상기 제1 IO 커맨드는 데이터 오브젝트를 식별하고, 및 상기 제1 청크는 상기 데이터 오브젝트의 제1 이레이저코디드 청크(erasure coded chunk)와 대응되고 상기 제2 청크는 상기 데이터 오브젝트의 제2 이레이저 코디드공개특허 10-2022-0008754-3-청크와 대응되는 방법."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 3 항에 있어서, 상기 제1 스토리지 장치는 NVMe-oF(non-volatile memory express over fabric) 타겟과 대응되는 방법."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "스토리지 장치가 제1 데이터 청크에 대한 제1 요청을 수신하되, 상기 제1 요청은 제1 타임스탬프와 제1 전역 흐름 식별자(GFID; global flow identifier)를 포함하는 단계;상기 스토리지 장치가 제2 데이터 청크에 대한 제2 요청을 수신하되, 상기 제2 요청은 제2 타임스탬프와 제2GFID를 포함하는 단계;상기 스토리지 장치가 상기 제1 GFID를 기반으로 제1 인공 지능(AI; artificial intelligence) 모델 처리부를식별하는 단계:상기 스토리지 장치가 상기 제2 GFID를 기반으로 제2 AI AI 모델 처리부를 식별하는 단계;상기 스토리지 장치로부터 상기 제1 데이터 청크를 상기 제1 AI 모델 처리부로 전송하되, 상기 제1 데이터 청크의 전송 타이밍은 상기 제1 타임스탬프에 기반하는 단계; 및상기 스토리지 장치로부터 상기 제2 데이터 청크를 상기 제2 AI 모델 처리부로 전송하되, 상기 제2 데이터 청크의 전송 타이밍은 상기 제2 타임스탬프에 기반하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서, 상기 스토리지 장치는 NVMe-oF(non-volatile memory express over fabric) 타겟을 포함하고, 및 상기 NVMe-oF타겟은 복수의 솔리드 스테이트 드라이브들(SSDs; solid state drives)을 포함하는 방법."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 8 항에 있어서, 상기 제1 AI 모델 처리부는 그래픽 처리부(graphics processor unit)를 포함하는 방법."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 8 항에 있어서, 상기 제1 AI 모델 처리부는 프로세서상에서 실행되는 어플리케이션을 포함하는 방법."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 8 항에 있어서, 상기 제1 데이터 청크는 데이터 오브젝트의 이레이저 코디드 청크(erasure coded chunk)에 대응되는 방법."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 8 항에 있어서, 상기 제1 데이터 청크는 상기 제2 타임스탬프에 선행하는 상기 제1 타임스탬프에 응답하여 상기 제2 데이터 청크전에 전송되는 방법."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 8 항에 있어서, 상기 제1 AI 모델 처리부를 식별하는 단계는 상기 제1 GFID를 식별하는 쿼리(query)를 GFID 데이터베이스에 전공개특허 10-2022-0008754-4-송하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "네트워크 인터페이스; 및제1 인공 지능 모델 처리부(AI PU; artificial intelligence model processing unit)로부터 제1 입/출력(IO;input/output) 커맨드를 수신하되, 상기 제1 IO 커맨드는: 제1 AI 모델 트레이닝 동작과 관련되고; 제2 AI PU로부터 제2 IO 커맨드를 수신하되, 상기 제2 IO 커맨드는 제2 AI 모델 트레이닝 동작과 관련되고; 상기 제1 AI 모델 트레이닝 동작에 할당된 제1 대역폭에 기반하여 제1 타임스탬프를 상기 제1 IO 커맨드에 할당하고; 및 상기 제2 AI 모델 트레이닝 동작에 할당된 제2 대역폭에 기반하여 제2 타임스탬프를 상기 제2 IO 커맨드에 할당하도록 설정된 프로세서부를 포함하는 컴퓨팅 장치."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서, 상기 제1 IO 커맨드는 상기 제1 AI 모델 트레이닝 동작을 식별하는 제1 전역 흐름 식별자(GFID; global flowidentifier)를 포함하고 및 상기 제2 IO 커맨드는 상기 제2 AI 모델 트레이닝 동작을 식별하는 제2 GFID를 포함하고, 및 상기 프로세서는 상기 제1 GFID에 기반하여 데이터베이스로부터 상기 제1 AI 모델 트레이닝 동작과 관련된 상기제1 대역폭의 인디케이션을 검색하고; 및 상기 제2 GFID에 기반하여 상기 데이터베이스로부터 상기 제2 AI 모델트레이닝 동작과 관련된 상기 제2 대역폭의 인디케이션을 검색하도록 더 설정되는 컴퓨팅 장치."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 15 항에 있어서, 상기 프로세서는 상기 제1 IO 커맨드에 기반하여 제1 스토리지 장치로의 데이터의 제1 청크에 대한 제1 요청의상기 네트워크 인터페이스를 통한 전송을 개시하되, 상기 제1 요청은 상기 제1 타임스탬프를 포함하도록 더 설정된 컴퓨팅 장치."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서, 상기 프로세서는 상기 제1 IO 커맨드에 기반하여 제2 스토리지 장치로의 데이터의 제2 청크에 대한 제2 요청의상기 네트워크 인터페이스를 통한 전송을 개시하되, 상기 제2 요청은 상기 제1 타임스탬프를 포함하도록 더 설정되는 컴퓨팅 장치."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18 항에 있어서, 상기 프로세서는 상기 제2 IO 커맨드에 기반하여 제3 스토리지 장치로의 데이터의 제3 청크에 대한 제3 요청의상기 네트워크 인터페이스를 통한 전송을 개시하되, 상기 제3 요청은 상기 제2 타임스탬프를 포함하도록 더 설정되는 컴퓨팅 장치."}
{"patent_id": "10-2021-0075591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "네트워크 인터페이스; 및제1 데이터 청크에 대한 제1 요청을 수신하되, 공개특허 10-2022-0008754-5-상기 제1 요청은: 제1 타임스탬프와 제1 전역 흐름 식별자(GFID; global flow identifier)를 포함하고; 제2 데이터 청크에 대한 제2 요청을 수신하되, 상기 제2 요청은 제2 타임스탬프와 제2 GFID를 포함하고; 상기 제1 GFID를 기반으로 제1 인공 지능(AI; artificial intelligence) 모델 처리부를 식별하고; 상기 제2 GFID를 기반으로 제2 AI 모델 처리부를 식별하고; 상기 네트워크 인터페이스를 통한 상기 제1 AI 모델 처리부로의 상기 제1 데이터 청크의 전송을 개시하되, 상기제1 데이터 청크의 전송 타이밍은 상기 제1 타임스탬프에 기반하고; 및 상기 네트워크 인터페이스를 통한 상기 제2 AI 모델 처리부로의 상기 제2 데이터 청크의 전송을 개시하되, 상기제2 데이터 청크의 전송 타이밍은 상기 제2 타임스탬프에 기반하도록 설정된 프로세서부를 포함하는 스토리지장치."}
{"patent_id": "10-2021-0075591", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 시간 동기화된 스토리지 전달을 위한 시스템들, 방법들, 및 장치에 관한 것으로, 본 개시에 따른 시간 동기화된 스토리지 전달을 위한 방법은 제1 컴퓨팅 장치가 제1 인공지능 모델 처리부(AI PU; artificial intelligence model processing unit)로부터 제1 입/출력(IO; input/output) 커맨드를 수신하되, 상기 제1 IO 커맨드는 제1 AI 모델 트레이닝 동작과 관련되는 단계를 포함한다. 상기 방법은 상기 제1 컴퓨팅 장치가 제2 AI PU로부터 제2 IO 커맨드를 수신하되, 상기 제2 IO 커맨드는 제2 AI 모델 트레이닝 동작과 관련되는 단계를 더 포 함한다. 상기 방법은 상기 제1 AI 모델 트레이닝 동작에 할당된 제1 대역폭에 기반하여 제1 타임스탬프를 상기 제1 IO 커맨드에 할당하는 단계를 더 포함한다. 상기 방법은 상기 제2 AI 모델 트레이닝 동작에 할당된 제2 대역 폭에 기반하여 제2 타임스탬프를 상기 제2 IO 커맨드에 할당하는 단계를 더 포함한다."}
{"patent_id": "10-2021-0075591", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서에 개시된 본 발명은 시간 동기화된 스토리지 전달을 수행하기 위한 스토리지 시스템들과 방법들에 관 한 것이다."}
{"patent_id": "10-2021-0075591", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능 (AI; Artificial intelligence) 모델들(예: 변분 오토-인코더들)은 대용량 데이터 셋을 이용하여 훈 련된다. AI 시스템은 하나 또는 그 이상의 AI 모델들을 적절하게 훈련시키도록 병렬로 대용량 데이터 셋을 처 리하도록 구성된 수천의 그래픽 처리 장치들(GPUs; graphics processing units)을 포함할 수 있다."}
{"patent_id": "10-2021-0075591", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 시간 동기화된 스토리지 전달을 수행하기 위한 스토리지 시스템들과 방법들을 제공하는데 있 다."}
{"patent_id": "10-2021-0075591", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "시간 동기화된 스토리지 전달을 수행하기 위한 스토리지 시스템들과 방법들이 개시된다. 이 시스템들과 방법들 은 인공 지능 모델들의 트레이닝 동안 대용량 데이터 셋들을 처리하는 것을 지원하도록 사용될 수 있다. 방법은 제1 컴퓨팅 장치가 제1 인공 지능 모델 처리부(AI PU; artificial intelligence model processing unit)로부터 제1 입/출력(IO; input/output) 커맨드를 수신하되, 상기 제1 IO 커맨드는 제1 AI 모델 트레이닝 동작과 관련되는 단계를 포함한다. 상기 방법은 상기 제1 컴퓨팅 장치가 제2 AI PU로부터 제2 IO 커맨드를 수신 하되, 상기 제2 IO 커맨드는 제2 AI 모델 트레이닝 동작과 관련되는 단계를 더 포함한다. 상기 방법은 상기 제1 AI 모델 트레이닝 동작에 할당된 제1 대역폭에 기반하여 제1 타임스탬프를 상기 제1 IO 커맨드에 할당하는 단계 를 더 포함한다. 상기 방법은 상기 제2 AI 모델 트레이닝 동작에 할당된 제2 대역폭에 기반하여 제2 타임스탬프 를 상기 제2 IO 커맨드에 할당하는 단계를 더 포함한다. 방법은 스토리지 장치가 제1 데이터 청크에 대한 제1 요청을 수신하되, 상기 제1 요청은 제1 타임스탬프와 제1 전역 흐름 식별자(GFID; global flow identifier)를 포함하는 단계를 포함한다. 상기 방법은 상기 스토리지 장 치가 제2 데이터 청크에 대한 제2 요청을 수신하되, 상기 제2 요청은 제2 타임스탬프와 제2 GFID를 포함하는 단 계를 더 포함한다. 상기 방법은 상기 스토리지 장치가 상기 제1 GFID를 기반으로 제1 인공 지능(AI. artificial intelligence) 모델 처리부를 식별하는 단계를 더 포함한다. 상기 방법은 상기 스토리지 장치가 상기 제2 GFID 를 기반으로 제2 AI 모델 처리부를 식별하는 단계를 더 포함한다. 상기 방법은 상기 스토리지 장치로부터 상기 제1 데이터 청크를 상기 제1 AI 모델 처리부로 전송하되, 상기 제1 데이터 청크의 전송 타이밍은 상기 제1 타임스탬프에 기반하는 단계를 더 포함한다. 상기 방법은 상기 스토리지 장치로부터 상기 제2 데이터 청크를 상기 제2 AI 모델 처리부로 전송하되, 상기 제2 데이터 청크의 전송 타이밍은 상기 제2 타임스탬프에 기반하는 단계 를 더 포함한다. 컴퓨팅 장치는 네트워크 인터페이스 및 프로세서부를 포함한다. 상기 프로세서는 제1 인공 지능 모델 처리부(AI PU; artificial intelligence model processing unit)로부터 제1 입/출력(IO; input/output) 커맨드를 수신하 되, 상기 제1 IO 커맨드는 제1 AI 모델 트레이닝 동작과 관련되도록 설정된다. 상기 프로세서부는 제2 AI PU로 부터 제2 IO 커맨드를 수신하되, 상기 제2 IO 커맨드는 제2 AI 모델 트레이닝 동작과 관련되도록 더 설정된다. 상기 프로세서부는 상기 제1 AI 모델 트레이닝 동작에 할당된 제1 대역폭에 기반하여 제1 타임스탬프를 상기 제 1 IO 커맨드에 할당하도록 더 설정된다. 상기 프로세서부는 상기 제2 AI 모델 트레이닝 동작에 할당된 제2 대역 폭에 기반하여 제2 타임스탬프를 상기 제2 IO 커맨드에 할당하도록 더 설정된다. 스토리지 장치는 네트워크 인터페이스 및 프로세서부를 포함한다. 상기 프로세서부는 제1 데이터 청크에 대한 제1 요청을 수신하되, 상기 제1 요청은 제1 타임스탬프와 제1 전역 흐름 식별자(GFID; global flow identifier)를 포함하도록 설정된다. 상기 프로세서부는 제2 데이터 청크에 대한 제2 요청을 수신하되, 상기 제 2 요청은 제2 타임스탬프와 제2 GFID를 포함하도록 더 설정된다. 상기 프로세서부는 상기 제1 GFID를 기반으로 제1 인공 지능(AI; artificial intelligence) 모델 처리부를 식별하도록 더 설정된다. 상기 프로세서부는 상기 제2 GFID를 기반으로 제2 AI 모델 처리부를 식별하도록 더 설정된다. 상기 프로세서부는 상기 네트워크 인터페 이스를 통한 상기 제1 AI 모델 처리부로의 상기 제1 데이터 청크의 전송을 개시하되, 상기 제1 데이터 청크의 전송 타이밍은 상기 제1 타임스탬프에 기반하도록 더 설정된다. 상기 프로세서부는 상기 네트워크 인터페이스를 통한 상기 제2 AI 모델 처리부로의 상기 제2 데이터 청크의 전송을 개시하되, 상기 제2 데이터 청크의 전송 타 이밍은 상기 제2 타임스탬프에 기반하도록 더 설정된다."}
{"patent_id": "10-2021-0075591", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시 예들에 따르면, 상기 시스템들과 방법들은 인공 지능 모델들의 트레이닝 동안 대용량 데이터 셋들을 처리 하는 것을 지원하도록 사용될 수 있다."}
{"patent_id": "10-2021-0075591", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1를 참조하면, 시간 동기화된 스토리지 전달을 위한 시스템의 도면이 도시된다. 시스템은 인공 지능(AI; artificial intelligence) 호스트 장치를 포함한다. AI 호스트 장치는 하나 또는 그 이상 의 컴퓨팅 장치들에 대응될 수 있다. AI 호스트 장치는 AI 어플리케이션과 데이터 로더를 포함 한다. AI 어플리케이션과 데이터 로더은 AI 호스트 장치의 프로세서(미도시)에 의해 실행될 수 있는 소프트웨어에 대응될 수 있다. AI 호스트 장치는 네트워크 인터페이스 컨트롤러(NIC; network interface controller), 디램(DRAM; dynamic random access memory), 및 복수의 AI 모델 처리부(AI PU; AI model processing unit)들(112a-112h)를 더 포함한다. The NIC는 무선 또는 유선 NIC와 대응될 수 있다. 복수의 AI PU들은 제1 AI PU(112a), 제2 AI PU(112b), 제3 AI PU(112c), 제4 AI PU(112d), 제5 AIPU(112e), 제6 AI PU(112f), 제7 AI PU(112g), 및 제8 AI PU(112h). 여덟 개의 AI PU들(112a-112h)이 이 예시 적인 실시예에서 도시되었지만, 임의의 수가 사용될 수 있다. 복수의 AI PU들(112a-112h)은 하나 또는 그 이상 의 그래픽 처리부(GPU; graphics processor unit)들, 프로세서에 의해 실행될 수 있는 하나 또는 그 이상의 어 플리케이션들, 필드 프로그래밍 게이트 어레이(FPGA; field programmable gate array), 어플리케이션 특정 집 적 회로(ASIC; application specific integrated circuit), 중앙 처리 장치(CPU; central processor unit), 다른 프로세싱 구성요소, 또는 이들의 조합을 포함할 수 있다. 일부 예들에서, AI PU들(112a-112h)은 AI 동작들 과 관련된 작업량들(workloads)을 처리하도록 구성될 수 있다. 일부 예들에서, 상기 작업량들은 행렬 곱셈 (matrix multiplication) 및/또는 컨볼루션 인텐시브 동작들(convolution intensive operations)을 포함할 수 있다. AI 호스트 장치는 (예: 클라우드 컴퓨팅 시스템(cloud computing system)에 의해 구현되는) 물리적 장치 또는 가상 장치에 대응될 수 있다. 일부 실시예들(some implementations)에서, AI 호스트 장치는 도 1에 도시된 예와 다르게 구성된다. 예 를 들어, DRAM은 다른 종류의 메모리 장치(예: 정적 램(SRAM; static random access memory))와 교체될 수 있다. 다른 예로, NIC는 다른 종류의 네트워크 어댑터(network adapter)와 교체될 수 있다. 또 다른 예 로, AI 호스트 장치는 도시된 것 다른 수의 GPU들을 포함할 수 있다. 또한, AI 호스트 장치는 도 1 에 도시되지 않은 추가의 구성요소들 포함할 수 있다. 예를 들어, AI 호스트 장치는 AI 어플리케이션 , 데이터 로더, AI PU들(112a-112h), 또는 그들의 조합과 대응되는 인스트럭션들 실행하도록 구성되 는 하나 또는 그 이상의 프로세서들을 포함할 수 있다. 시스템은 오브젝트 스토리지 시스템을 더 포함한다. 오브젝트 스토리지 시스템는 하나 또는 그 이상의 컴퓨팅 장치들에 대응될 수 있다. 일부 실시예들에서, 오브젝트 스토리지 시스템은 서버(예: 오브 젝트 스토리지 서버)와 대응될 수 있다. 그러한 서버는 (예: 클라우드 컴퓨팅 시스템(cloud computing system) 에 의해 구현되는) 물리적 장치 또는 가상 장치에 대응될 수 있다. 오브젝트 스토리지 시스템은 NIC, 프로세서부, 및 메모리 버퍼들(124a-124h)을 포함한다. 일부 실시예들에서, 오브젝트 스토리지 시스템은 AI 호스트 장치에 포함되는 다수의 AI PU들과 동일한 다 수의 버퍼들(124a-124h)을 포함할 수 있다. 다른 실시예들에서, 오브젝트 스토리지 시스템은 다른 수의 버 퍼들을 포함할 수 있다. 프로세서부는 상기 언급된 동작들(actions)을 수행하도록 구성된 필드 프로그래밍 게이트 어레이, 상기 언급된 동작들을 수행하기 위해 메모리 장치(미도시)에 저장된 인스트럭션들 (instructions)을 실행하도록 구성된 중앙 처리 장치, 상기 언급된 동작들을 수행하도록 구성된 어플리케이션 특정 집적 회로, 또는 다른 처리장치에 대응될 수 있다. NIC는 무선 또는 유선 NIC에 대응될 수 있다. 메 모리 버퍼들(124a-124h)은 하나 또는 그 이상의 메모리 장치들내의 메모리 공간들에 대응될 수 있다. 그러한 메모리 장치들은 DRAM, SRAM, 다른 종류의 메모리, 또는 이들의 조합을 포함할 수 있다. 도시된 예에서, 메모리 버퍼들(124a-124h)은 제1 메모리 버퍼(124a), 제2 메모리 버퍼(124b), 제3 메모리 버퍼(124c), 제4 메모리 버 퍼(124d), 제5 메모리 버퍼(124e), 제6 메모리 버퍼(124f), 제7 메모리 버퍼(124g), 및 제8 메모리 버퍼(124 h)를 포함한다. 메모리 버퍼들(124a-124h)의 각각은 다른 우선순위와 관련될 수 있다. 예를 들어, 제1 메모리 버퍼(124a)는 제1 우선순위와 관련될 수 있고, 제2 메모리 버퍼(124b)는 제2 우선순위와 관련될 수 있다. 다른 예들에서, 오브젝트 스토리지 시스템은 다른 수의 버퍼들을 포함할 수 있다. AI PU들(112a-112h)의 각각은 NIC에 대한 별도의 연결을 갖는다. 일부 실시예들에서, 이들의 연결들은 AI 호스트 장치의 NIC를 통해 유지될 수 있다. 다른 실시예들에서, 상기 연결들은 AI PU들(112a-112h)의 별도의 네트워크 어댑터들을 통해 유지될 수 있다. 상기 연결들은 직접 연결되거나 또는 공용 네트워크(public network)(예: 인터넷), 사설 네트워크(private network), 또는 이들의 조합을 통해서 연결될 수 있다. AI PU 들(112a-112h)은 입/출력(IO; input/output) 커맨드들(commands)을 상기 연결들을 통해 오브젝트 스토리지 시 스템에 전송하도록 구성된다. 예를 들어, 제1 AI PU(112a)는 제1 데이터 오브젝트를 요청하는 제1 IO 커 맨드를 오브젝트 스토리지 시스템에 전송할 수 있다. AI PU들(112a-112h)은 검색된 데이터 오브젝트들을 기반하여 하나 또는 그 이상의 AI 데이터 모델들을 트레이닝시킬 수 있다. 예를 들어, 상기 제1 데이터 오브젝 트를 수신하는 것에 응답하여, 제1 AI PU(112a)는 AI 모델(또는 그의 일부)을 트레이닝시킬 수 있고, 상기 트레 이닝된 모델(trained model)(또는 그의 일부)를 AI 어플리케이션에 반환할 수 있다. 본 명세서에 언급된 바와 같이, 오브젝트 스토리지 시스템의 프로세서부는 수신된 IO 커맨드들에 포 함되는 전역 흐름 식별자(GFID; global flow identifier)들을 기반하여 메모리 버퍼들(124a-124h)에 상기 수신 된 커맨드들을 버퍼링하도록 구성된다. 오브젝트 스토리지 시스템의 프로세서부는 IO 커맨드들을 검 색하고 메모리 버퍼들(124a-124h)의 우선순위에 기반하여 관련 데이터 동작들을 개시하도록 구성된다. 예를 들어, 오브젝트 스토리지 시스템의 프로세서부는 제1 및 제2 메모리 버퍼들(124a, 124b)의 상대적인 우 선순위들에 기반하여 제2 메모리 버퍼(124b) 보다 더 자주 제1 메모리 버퍼(124a)로부터 IO 커맨드들을 검색할 수 있다. 오브젝트 스토리지 시스템의 프로세서부는 데이터 오브젝트들(126a, 126b)을 관리한다. 도 1에서, 제 1 데이터 오브젝트(126a)와 제2 데이터 오브젝트(126b)는 라베링된다. 상기 수신된 IO 커맨드들은 (예: 키 값 들에 의해) 데이터 오브젝트들을 식별할 수 있다. 본 명세서에 언급된 바와 같이, 오브젝트 스토리지 시스템 의 프로세서부는 하나 또는 그 이상의 AI PU들로의 둘 또는 그 이상의 데이터 오브젝트들의 시간 동 기화된 전달을 개시하도록 구성될 수 있다. 오브젝트 스토리지 시스템에 의해 관리되는 데이터 오브젝트 들(126a, 126b)은 하나 또는 그 이상의 스토리지 장치들에 저장될 수 있다. 이 스토리지 장치들은 NIC를 통해 오브젝트 스토리지 시스템에 연결될 수 있다. 따라서, 데이터 오브젝트의 전달을 개시하는 것은 상기 오브젝트(또는 그의 일부)를 오브젝트 스토리지 시스템 또는 요청하는 AI PU에 전달하도록 요청을 스토리 지 장치에 전송하는 것을 포함할 수 있다. 일부 실시예들에서, 오브젝트 스토리지 시스템의 프로세서부는 데이터 이레이저 코딩 방식(data erasure coding scheme)을 구현하도록 구성될 수 있다. 오브젝트 스토리지 시스템의 프로세서부는 데이터 오브젝트들에 대해 데이터 이레이저 코딩 방식을 수행하여 하나 또는 그 이상의 이레이저 코디드 청크들 (erasure coded (EC) chunks)을 생성하고 상기 EC 청크들을 하나 또는 그 이상의 스토리지 장치들에 저장할 수 있다. 데이터 오브젝트를 참조하는 IO 커맨드에 응답하여, 오브젝트 스토리지 시스템의 프로세서부 는 어느 스토리지 장치 또는 스토리지 장치들이 데이터 오브젝트에 대한 EC 청크들을 저장하는 지 판단하고 이 스토리지 장치들에 IO 요청들을 발급하도록 구성될 수 있다. 일부 실시예들에서, 상기 스토리지 장치들은 비휘발성 메모리 익스프레스 (NVMe; non-volatile memory express) 장치들, NVMe-oF (NVMe over fabric) 타겟들, 다른 스토리지 장치들, 또는 이들의 조합을 포함할 수 있다. 도 2는 하나 또는 그 이상의 데이터 오브젝트들의 EC 코디드 청크들을 저장할 수 있는 스토리지 장치(예: NVMe-oF 타겟)의 예를 나타낸다. 스토리지 장치는 NIC과 프로세서부를 포함한다. NIC는 무선 또는 유선 NIC에 대응될 수 있다. 프로세서부는 상기 언급된 동작들(actions)을 수행하도록 구성된 필드 프로그래밍 게이트 어레이, 상기 언급된 동작들을 수행하기 위해 메모리 장치(미도시)에 저장된 인스트럭 션들(instructions)을 실행하도록 구성된 중앙 처리 장치, 상기 언급된 동작들을 수행하도록 구성된 어플리케이 션 특정 집적 회로, 또는 다른 처리장치에 대응될 수 있다. 스토리지 장치는 제1 드라이브(drive)(208a), 제2 드라이브(208b), 제3 드라이브(208c), 및 제4 드라이브(208d)를 포함한다. 드라이브들(208a-208d)의 각각 은 솔리드 스테이트 드라이브, 하드 디스크 드라이브, 다른 종류의 컴퓨터 스토리지 드라이브, 또는 이들의 조 합을 포함할 수 있다. 드라이브들(208a-208d)은 데이터(예: EC 코디드 데이터 청크들)를 저장하도록 구성된다. 일부 실시예들에서, 스토리지 장치는 도 2에 도시된 것과 다른 수의 드라이브들을 포함할 수 있다. 스토리지 장치는 제1 스테이징 버퍼(staging buffer)(202a), 제2 스테이징 버퍼(202b), 제3 스테이징 버 퍼(202c), 및 제4 스테이징 버퍼(202d)를 포함한다. 다른 실시예들은 다른 수의 스테이징 버퍼들을 포함할 수 있다. 그러한 스테이징 버퍼들(202a-202d)은 DRAM, SRAM, 다른 종류의 메모리, 또는 이들의 조합을 포함할 수 있다. 스테이징 버퍼들(202a-202d)은 NIC를 통해 오브젝트 스토리지 시스템으로부터 수신된 IO 요청 들을 저장하고, 드라이브들(208a-208d)로부터 검색된 데이터(예: EC 코디드 데이터 청크들)를 저장하고, 또는 이들의 조합을 저장하도록 구성된다. 예를 들어, 스테이징 버퍼들(202a-202d)의 전부는 오브젝트 스토리지 시 스템으로부터 수신된 IO 요청들을 저장하도록 구성되고, 스테이징 버퍼들(202a-202d)의 전부는 드라이브들 로부터 데이터 청크들을 저장하도록 구성되고, 또는 스테이징 버퍼들(202a-202d)의 제1 서브셋은 데이터 청크들 을 저장하도록 구성되고 스테이징 버퍼들(202a-202d)의 제2 서브셋은 IO 요청들을 저장하도록 구성될 수 있다. 일부 실시예들에서, 스토리지 장치는 스토리지 장치에 포함되는 드라이브 당 하나의 버퍼를 포함할 수 있다. 다른 실시예들에서, 스토리지 장치는 다른 수의 버퍼들(예: 하나 또는 그 이상의 출력 버퍼들뿐 만 아니라 드라이브당 하나의 버퍼)을 포함할 수 있다. 본 명세서에 언급된 바와 같이, 상기 스테이징 버퍼들의 하나 또는 그 이상이 IO 요청들을 수신하도록 구성된, 실시예들에서, 프로세서부는 상기 IO 요청에 관련된 GFID에 기반하여 특정 IO 요청을 스테이징 버퍼들 (202a-202d)의 특정 하나에 할당할 수 있다. 스테이징 버퍼들(202a-202d)은 관련된 우선 순위들을 갖을 수 있고, 스테이징 버퍼들(202a-202d)에 저장된 IO 요청들은 상기 우선순위들에 기반하여 결정된 순서로 스테이징 버퍼들(202a-202d)로부터 처리될 수 있다. 본 명세서에 언급된 바와 같이, 유사하게, 상기 스테이징 버퍼들의하나 또는 그 이상이 드라이브들(208a-208d)로부터 데이터를 수신하도록 구성된 실시예들에서, 프로세서부(20 5)는 상기 특정 데이터의 검색에 관련된 IO 요청에 관련된 GFID에 기반하여 특정 데이터(예: 특정 청크)를 스테 이징 버퍼들(202a-202d)의 특정 하나에 할당할 수 있다. 상기에서 나타낸 바와 같이, 스테이징 버퍼들(202a- 202d)은 관련된 우선순위들을 갖을 수 있다. 스테이징 버퍼들(202a-202d)에 저장된 데이터는 상기 우선순위들 에 기반하여 결정된 순서로 스테이징 버퍼들(202a-202d)로부터(예: 오브젝트 스토리지 시스템 또는 AI PU 들(112a-112h)의 하나 또는 그 이상으로) 전송될 수 있다. 스토리지 장치는 버스(bus)를 더 포함한다. 버스는 PCIe(peripheral component interconnect express) 버스 또는 다른 종료의 버스를 포함할 수 있다. 버스는 드라이브들(208a-208d)를 스테이징 버퍼 들(202a-202d)과 연결할 수 있다. NIC 및/또는 프로세서부도 또한 버스에 연결될 수 있다. 도 2는 드라이브들(208a-208d)과 스테이징 버퍼들(202a-202d) 사이에서 유입되는 IO들(204a-204d)를 나타낸다. 이 IO들(204a-204d)은 데이터 청크들, IO 요청들, 또는 이들의 조합을 포함할 수 있다. 일부 실시예들에서, 스토 리지 장치는 버스에 더 연결될 수 있는 추가 구성요소들을 포함할 수 있다. 도 3을 참조하면, 시간 동기화된 스토리지 전달을 위한 시스템의 동작을 나타내는 도면이 도시된다. 도 3의 예 에서, 도 1의 오브젝트 스토리지 시스템과 AI PU들(112a-112h)은 스토리지 장치들(200a-200d)에 연결 (e.g., 직접적으로 또는 하나 또는 그 이상의 네트워크들을 통해)된다. 네 개의 스토리 장치들(200a-200d)이 도 시되었지만, 다른 예들에서, 스토리지 시스템 및/또는 AI PU들(112a-112h)은 다른 수의 스토리지 장치들에 연결될 수 있다. 또한, 상기 도시된 예와 다른 수의 AI PU들은 일부 예에 포함될 수 있다. 스토리지 장치들 (200a-200d)의 각각은 도 2에 도시된 스토리지 장치의 예이다. 스토리지 장치들(200a-200d)은 스토리지 장치의 예들이지만, 스토리지 장치들(200a-200d)은 동일하지 않을 수 있음에 유의해야한다. 예를 들어, 위 에서 설명한 바와 같이, 스토리지 장치는 다른 구성들(예: 다른 수들 또는 이용들의 스테이징 버퍼들 등) 을 구비할 수 있고, 상기 제1 스토리지 장치(200a)는 이러한 구성들중 하나를 갖을 수 있는 반면에 제2 스토리 지 장치(200b)는 이러한 구성들중 두 번째 것을 갖는다. 또한, 오브젝트 스토리지 시스템, AI PU들(112a-112h), 및 스토리지 장치들(200a-200d)은 GFID 데이터베 이스(예: NIC와 NIC에 각각)에 연결된다. GFID 데이터베이스는 컴퓨팅 장치상에 구현된다. 일부 예들에서, GFID 데이터베이스는 도 1의 AI 호스트 장치(예: AI PU들(112a-112h)중 하나 또는 AI 호스트 장치의 다른 프로세서)상에 구현될 수 있다. 일부 예들에서, GFID 데이터베이스는 오브젝 트 스토리지 시스템상에 또는 스토리지 장치들(200a-200d)중 하나상에 구현될 수 있다. 일부 예들에서, GFID 데이터베이스는 AI PU들(112a-112h), 스토리지 장치들(200a-200d), 및 오브젝트 스토리지 시스템 외부에 있는 컴퓨팅 장치 상에 구현될 수 있다. GFID 데이터베이스는 AI 트레이닝 세션(training session)과 관련된 리소스들을 식별하는 메타데이터를 저 장하도록 구성된다. 예를 들어, GFID 데이터베이스는 GFID, AI PU와 관련된 데이터, 하나 또는 그 이상의 스토리지 장치들과 관련된 데이터, 및 하나 또는 그 이상의 오브젝트 스토리지 시스템들과 관련된 데이터 사이 의 연관성(association)를 저장할 수 있다. 상기 AI PU와 관련된 상기 데이터는 상기 AI PU의 식별자, 상기 AI PU와 관련된 연결 식별자, 상기 AI PU와 관련된 대역폭, 또는 이들의 조합을 포함할 수 있다. 상기 하나 또는 그 이상의 오브젝트 스토리지 시스템들과 관련된 상기 데이터는 오브젝트 스토리지 시스템별 오브젝트 스토리지 시스템 식별자, 오브젝트 스토리지 시스템별 연결 식별자, 각 오브젝트 스토리지 시스템과 관련된 대역폭, 또는 이들의 조합을 포함할 수 있다. 상기 하나 또는 그 이상의 스토리지 장치들과 관련된 상기 데이터는 각 스토리 지 장치의 식별자, 각 스토리지 장치와 관련된 연결 식별자, 각 스토리지 장치와 관련된 대역폭, 또는 이들의 조합을 포함할 수 있다. 도 4를 참조하면, GFID 데이터베이스내의 예시적인 엔트리를 나타내는 도면이 도시된다. 도 4의 예 에서, 엔트리는 전역 흐름 ID(global flow ID), AI PU와 관련된 데이터, 하나 또는 그 이상의 오브젝트 스토리지 시스템들과 관련된 데이터, 및 하나 또는 그 이상의 스토리지 장치들과 관련된 데이터 를 포함한다. 상기 전역 흐름 ID는 AI 트레이닝 세션(또는 다른 데이터 흐름)을 식별하는 고유의 식 별자일 수 있다. 상기 AI PU와 관련된 상기 데이터는 상기 AI 트레이닝 세션(또는 다른 데이터 흐름)에 수반되는 AI PU를 기술한다. 상기 AI PU와 관련된 상기 데이터는 주체 식별자 또는 이름(entity identifier or name) 을 포함한다. 엔트리 식별자 또는 이름은 네트워크 주소(예: 인터넷 프로토콜 주소), 호스트네임, 다른 식 별자, 또는 이들의 조합을 포함할 수 있다. 데이터는 상기 AI PU와 관련된 연결 식별자을 더 포함한다. 연결 식별자는 소켓 식별자(socket identifier), 다른 종류의 연결 식별자, 또는 주체 식별자 또는 이 름에 의해 식별된 상기 AI PU가 데이터를 송신 및/또는 수신하는 연결을 식별하는 이들의 조합을 포함할 수 있다. 상기 AI PU와 관련된 데이터는 대역폭 인디케이터을 더 포함한다. 대역폭 인디케이터(41 2)는 상기 AI 트레이닝 세션(또는 다른 데이터 흐름) 동안 데이터를 수신하기 위해서 상기 AI PU가 이용할 수 있는 대역폭을 나타낸다. 상기 하나 또는 그 이상의 오브젝트 스토리지 시스템들과 관련된 데이터는 상기 AI 트레이닝 세션(또는 다 른 데이터 흐름)과 관련된 오브젝트 스토리지 시스템별 오브젝트 스토리지 시스템 식별자을 포함한다. 오 브젝트 스토리지 시스템 식별자은 네트워크 주소(예: 인터넷 프로토콜 주소), 호스트네임, 다른 식별자, 또는 이들의 조합을 포함할 수 있다. 상기 하나 또는 그 이상의 오브젝트 스토리지 시스템들과 관련된 데이터 는 상기 AI 트레이닝 세션(또는 다른 데이터 흐름)과 관련된 오브젝트 스토리지 시스템별 연결 식별자 을 더 포함한다. 연결 식별자는 소켓 식별자, 다른 종류의 연결 식별자, 또는 오브젝트 스토리지 시 스템 식별자에 의해 식별된 상기 오브젝트 스토리지 시스템이 데이터를 송신 및/또는 수신할 수 있는 연결 을 식별하는 이들의 조합을 포함할 수 있다. 상기 하나 또는 그 이상의 오브젝트 스토리지 시스템들과 관련된 데이터는 상기 AI 트레이닝 세션(또는 다른 데이터 흐름)과 관련된 오브젝트 스토리지 시스템별 대역폭 인 디케이터을 더 포함한다. 대역폭 인디케이터는 상기 AI 트레이닝 세션(또는 다른 데이터 흐름) 동안 데이터를 송신 및/또는 수신하기 위해서 상기 오브젝트 스토리지 시스템이 이용할 수 있는 대역폭을 나타낸다. 상기 하나 또는 그 이상의 오브젝트 스토리지 시스템들과 관련된 데이터는 상기 AI 트레이닝 세션(또는 다 른 데이터 흐름)과 관련된 스토리지 장치별 타겟 식별자(target identifier)을 포함한다. 타겟 식별자 은 네트워크 주소(예: 인터넷 프로토콜 주소), 호스트네임, 다른 식별자, 또는 이들의 조합을 포함할 수 있다. 상기 하나 또는 그 이상의 스토리지 장치들과 관련된 데이터는 상기 AI 트레이닝 세션(또는 다른 데 이터 흐름)과 관련된 스토리지 장치별 연결 식별자을 더 포함한다. 연결 식별자는 소켓 식별자, 다 른 종류의 연결 식별자, 또는 타겟 식별자에 의해 식별된 상기 오브젝트 스토리지 시스템이 데이터를 송신 및/또는 수신할 수 있는 연결을 식별하는 이들의 조합을 포함할 수 있다. 상기 하나 또는 그 이상의 스토리지 장치들과 관련된 데이터는 상기 AI 트레이닝 세션(또는 다른 데이터 흐름)과 관련된 스토리지 장치별 대역 폭 식별자을 더 포함한다. 대역폭 식별자는 상기 AI 트레이닝 세션(또는 다른 데이터 흐름) 동안 데 이터를 송신 및/또는 수신하기 위해서 상기 스토리지 장치가 이용할 수 있는 대역폭을 나타낸다. 따라서, 도 4는 전역 흐름 식별자와 AI 트레이닝 세션(또는 다른 데이터 흐름) 동안에 사용되는 다양한 리소스 들 설명하는 메타데이터를 연관시키는 전역 흐름 식별자 데이터베이스에서의 엔트리의 예를 나타낸다. 도 3을 다시 참조하면, AI 트레이닝 세션(또는 다른 데이터 흐름) 동안, 제1 AI PU(112a)(또는 임의의 다른 AI PU)는 IO 커맨드(예: 읽기 요청)를 오브젝트 스토리지 시스템에 발급할 수 있다. 제1 AI PU(112a)는 상기 IO 커맨드에서 상기 AI 트레이닝 세션(또는 다른 데이터 흐름)과 관련된 GFID를 포함할 수 있다. 일부 실시예들 에서, 제1 AI PU(112a)는 GFID 데이터베이스에 의해 식별됨에 따라 오브젝트 스토리지 시스템과 관련 된 대역폭 인디케이터에 기반하여 IO 커맨드들이 오브젝트 스토리지 시스템에 전송되는 비율을 제한 할 수 있다. 상기 IO 커맨드를 수신하는 것에 응답하여, 오브젝트 스토리지 시스템의 프로세서부는 타임스탬프 (timestamp)를 상기 IO 커맨드에 할당할 수 있고, 이어서 상기 IO 커맨드를 메모리 버퍼들(124a-124h)중 하나에 위치시킬 수 있다. 타임스탬프(timestamp)를 IO 커맨드에 할당하는 것은 상기 IO 커맨드과 관련된 레코드(예: 커맨드 제어 블록)에 상기 타임스탬프를 부가하는 것을 포함할 수 있다. 상기 레코드는 상기 IO 커맨드와 관련 된 메타데이터의 블록과 대응될 수 있다. 일부 예들에서, 오브젝트 스토리지 시스템의 프로세서부는 GFID 데이터베이스내에서 상기 IO 커맨드에서 GFID를 조회하고 상기 GFID와 관련된 데이터에 기반하여 상 기 IO 커맨드를 위치시키기 위해 메모리 버퍼를 결정할 수 있다. 예를 들어, 오브젝트 스토리지 시스템의 프로세서부는 GFID 데이터베이스에서 식별된 바와 같이, 제1 AI PU(112a)와 관련된 대역폭(예: 대역 폭 인디케이터로 나타낸 대역폭)에 기반하여 제1 메모리 버퍼(124a)내에 상기 IO 커맨드를 위치시킬 수 있 다. 일부 예들에서, 오브젝트 스토리지 시스템의 프로세서부는 대역폭 범위들에 대한 우선순위들의 매핑을 유지할 수 있다(예: 제1 대역폭 범위는 제1 우선순위에 매핑될 수 있고, 제2 대역폭 범위는 제2 우선순 위에 매핑될 수 있으며, 등). 오브젝트 스토리지 시스템의 프로세서부는 상기 IO 커맨드에 의해 식별 된 상기 GFID에 관련된 상기 AI PU의 대역폭이 떨어지는 대역폭을 식별하고, 그 다음 상기 대역폭 범위에 매핑 되는 우선순위에 대응되는 메모리 버퍼들(124a-124h)중 하나에 상기 IO 커맨드를 부가할 수 있다. 일부 예들에서, 오브젝트 스토리지 시스템의 프로세서부에 의해 상기 IO 커맨드에 할당된 상기 타임 스탬프는 상기 GFID(예: 상기 GFID에 관련된 대역폭)에 기반한다. 예를 들어, 오브젝트 스토리지 시스템의 프로세서부는 GFID 데이터베이스에서 상기 GFID를 조회하여 상기 GFID에 관련된 AI PU에 관련된 대역 폭을 식별하고 그 다음 TKDRL 대역폭에 기반하여 상기 타임스탬프를 할당할 수 있다. 예를 들어, 상기 할당된 타임스탬프는 상기 대역폭에 기반하여 선택된 오프셋뿐만 아니라, 상기 IO 커맨드가 오브젝트 스토리지 시스템 에 의해 수신된 시간에 대응될 수 있다. 설명하자면, 오브젝트 스토리지 시스템은 제1 GFID를 포함하 는 제1 IO 커맨드와 제2 GFID를 포함하는 제2 IO 커맨드를 NIC를 통해 수신할 수 있다. 상기 제1 GFID는 GFID 데이터베이스에서 제1 AI PU(112a)와 관련될 수 있고, 상기 제2 GFID는 GFID 데이터베이스에서 제2 AI PU(112b)와 관련될 수 있다. 상기 제1 GFID에 위한 상기 엔트리는 제1 AI PU(112a)와 관련된 상기 대 역폭이 X인 것을 더 나타낼 수 있는 반면에 상기 제2 GFID를 위한 상기 엔트리는 제2 AI PU(112b)와 관련된 상 기 대역폭이 Y인 것을 나타낼 수 있다. 오브젝트 스토리지 시스템은 대역폭들과 오프셋들 사이에서의 연관 성들(예: 매핑들)을 (예: 외부 또는 내부 메모리에) 유지할 수 있다. 오브젝트 스토리지 시스템의 프로세 서부는 X를 기반으로 제1 오프셋(예: +5 밀리세컨드(milliseconds)(ms))을 설정하고, Y를 기반으로 제2 오 프셋(예: +3ms)을 설정할 수 있다. 다른 실시예에서, 프로세서부는 GFID에 대한 상기 대역폭과 상기 GFID 에 관련된 이전 IO 커맨드에 대한 이전 타임스탬프(n-1)를 기반하여 상기 GFID와 관련된 특정의 IO 커맨드에 대 한 타임스탬프(n)를 할당할 수 있다. 설명하자면, 프로세서부는 타임스탬프 n-1과 타임스탬프 n 사이의 시 간이 상기 GFID와 관련된 상기 대역폭으로 나타낸 데이터 전송률을 만족하도록 타임스탬프 n을 할당할 수 있다. 일부 실시예들에서, (예: IO 커맨드들이 오브젝트 스토리지 시스템에 의해 수신된 경우에 상관없이) GFID 에 대한 타임스탬프들 사이의 평균 시간이 상기 GFID와 관련된 대역폭을 만족하도록 상기 GFID와 관련된 상기 IO 커맨드들에 대한 타임스탬프들을 할당할 수 있다. 아래에 자세히 설명한 바와 같이, 스토리지 장치들은 명령 들에 대한 응답을 예약할 상기 타임스탬프를 사용하도록 구성될 수 있다. 따라서, AI 트레이닝 세션에 관련된 GFID에 기반한 IO 커맨드의 타임스탬프를 설정하는 것은 데이터가 여러 장치들 사이에서 교환되는 AI 트레이닝 세션들에 대한 우선순위 기반 스케쥴링(priority based scheduling)을 제공할 수 있다. 이 우선순위 방식은 시 스템이 대역폭(예: AP PU가 데이터를 수신하는 비율)과 AI 트레이닝 세션의 레이턴시(레이턴시는 AI PU가 커맨드를 전송하는 시점과 응답이 스토리지 장치에 의해 전송되는 시점 사이의 시간을 의미한다) 요구사항 을 보장하도록 사용될 수 있다. 오브젝트 스토리지 시스템의 프로세서부는 메모리 버퍼들(124a-124h)로부터 IO 커맨드를 제거하고 상 기 IO 커맨드로 나타낸 데이터(예: 데이터 청크)를 저장하는 스토리지 장치들중 어느 것을 식별함으로써 메모리 버퍼들(124a-124h)중 하나로부터 상기 IO 커맨드를 처리하도록 구성된다. 오브젝트 스토리지 시스템의 프 로세서부는 각 데이터 청크에 대한 요청을 생성하고 상기 해당하는 스토리지 장치들에 대한 상기 요청들을 전송하도록 구성된다. 상기 요청들은 상기 IO 커맨드로부터의 상기 GFID, 상기 요청된 데이터 청크의 식별자, 및 상기 IO 커맨드에 할당된 상기 타임스탬프를 포함할 수 있다. 상기 IO 커맨드가 GFID 데이터베이스내의 상기 GFID와 관련되지 않은 스토리지 장치에 저장된(또는 부분적으로 저장된) 오브젝트를 식별하는 상황들에서, 오브젝트 스토리지 시스템의 프로세서부는 에러 메시지를 상기 AI PU에 (예: NIC를 통해) 반환 할 수 있다. 오브젝트 스토리지 시스템의 프로세서부는 메모리 버퍼들(124a-124h)과 관련된 우선순위 들에 기반하여 결정된 순서로 메모리 버퍼들(124a-124h)로부터 IO 커맨드들을 처리할 수 있다. 또한, 일부 실시 예들에서, 오브젝트 스토리지 시스템의 프로세서부는 GFID 데이터베이스에 의해 식별된 바와 같 이, 상기 스토리지 장치에 관련된 대역폭에 기반하여 요청들이 스토리지 장치들(200a-200d)중 특정 하나에 전송되는 비율을 제한할 수 있다. 스토리지 장치들(200a-200d)(예: 스토리지 장치들(200a-200d)의 프로세서부들)은 관련 요청들에 포함된 타 임스탬프들에 기반하여 결정된 순서로 데이터(예: 데이터 청크들)를 전송하도록 구성될 수 있다. 스토리지 장치 들(200a-200d)은 상기 데이터를, NIC를 통해, 요청하는 AI PU 또는 오브젝트 스토리지 시스템으로 직 접적으로 전송할 수 있다. 예를 들어, 제1 스토리지 장치(200a)는 제1 스토리지 장치(200a)의 NIC를 통해 제1 데이터 청크에 대한 요청을 수신할 수 있다. 제1 스토리지 장치(200a)의 프로세서부는 상기 요청에서 의 타임스탬프에 기반하여 상기 요청을 스테이징 버퍼들(202a-202d)중 하나에 삽입할 수 있다. 예를 들어, 상기 요청이 스테이징 버퍼에 부가되는 위치는 상기 스테이징 버퍼에 포함되는 요청들이 타임스탬프 순서로 분류되도 록 타임스탬프에 기반하여 결정될 수 있다. 또한, 상기 요청이 삽입된 상기 스테이징 버퍼는 상기 요청에서의 상기 GFID에 관련된 대역폭(예: 대역폭(42 8))에 기반하여 프로세서부에 의해 선택될 수 있다. 상기 요청은 상기 스테이징 버퍼(예: 상기 스테이징버퍼의 우선순위에 기반하는 순서로)로부터 처리되고 버스로 전송되어, 상기 요청되는 데이터(예: 데이터 청크)를 저장하는 상기 드라이브(예: 드라이브들(208a-208d)중 하나)에 의해 수신되도록 전송될 수 있다. 상기 드라이브는 상기 데이터를 버스에 반환하여 스토리지 장치에 의해 NIC를 통해 상기 GFID과 관련되는 상기 AI PU로 출력되도록 할 수 있다. 예를 들어, 프로세서부는 어느 AI PU가 상기 요청과 관련 되는 지 확인하기 위해 NIC을 통해 상기 GFID 데이터베이스에 대한 쿼리의 전송을 개시하고 이어서 NIC를 통해 그 AI PU에 대한 상기 드라이브에 의해 출력된 데이터의 전송을 개시할 수 있다. 일부 실시예 들에서, 스토리지 장치는 상기 AI PU에 전달하기 위해 오브젝트 스토리지 시스템에 상기 데이터(예: 상기 데이터 청크)를 전송할 수 있다. 일부 실시예들에서, 상기 프로세서부는 상기 데이터를 출력을 버퍼링하는 것과 관련된 스테이징 버퍼들 (202a-202d)중 하나에 부가할 수 있다. 상기 데이터는 상기 요청과 관련된 상기 GFID 및/또는 타임스탬프에 기 반하여 상기 스테이징 버퍼에 부가될 수 있다. 또한, 일부 실시예들에서, 프로세서부는 GFID 데이터베이 스에 의해 식별된 바와 같이 상기 AI PU와 관련된 대역폭 식별자에 기반하여 데이터가 상기 AI PU에 반환되는 비율을 제한할 수 있다. 상기 스토리지 장치들은 요청들을 처리하고 타임스탬프 순서로 데이터를 출력하기 때문에, 오브젝트들은 동기화 된 방식으로 검색될 수 있다. 또한, 상기 타임스탬프들은 AI 트레이닝 세션들을 식별하는 GFID들과 대응되는 우 선순위들(예: 대역폭들)에 기반하여 할당될 수 있다. 따라서, AI 트레이닝 세션들은 우선순위가 정해질 수 있다. 또한, AI 트레이닝 세션내에서 구성요소들 사이의 데이터 전송률들은 상기 AI 트레이닝 세션의 GFID에 링크된 대역폭들에 기반하여 관리될 수 있다. 도 5를 참조하면, AI 트레이닝 세션을 위한 스토리지 쿼리 계획을 생성하는 방법을 나타내는 도면이 도시 된다. 방법은 도 1의 AI 호스트 장치에 의해 수행될 수 있다. 502에서, 방법은 다음 스토리지 서비스 세션 파라미터들(storage service session parameters)을 판독하 는 단계를 포함한다. 예를 들어, AI 호스트 장치는 AI 트레이닝 세션(예: 입력 파일 또는 다른 소스로부터)과 관련된 파라미터들(예: 작업량 파라미터들)을 판독할 수 있다. 이러한 파라미터들은 상기 AI 트 레이닝 세션을 위한 타겟 대역폭, 데이터셋, 트레이닝 시간, GPU당 대역폭, 판독할 오브젝트들/데이터, 다수의 GPU들, 프리-페치 버퍼의 사이즈, 다른 파라미터들, 또는 이들의 조합을 포함할 수 있다. 상기 파라미터들은 데 이터 로더에 의해 입력될 수 있다. 504에서, 방법은 시스템과 네트워크 토폴로지 정보를 판독하는 단계를 더 포함한다. 예를 들어, AI 호스트 장치는 도 3에 도시된 시스템의 네트워크 토폴로지를 결정할 수 있다. AI 호스트 장치는 인터넷 제 어 메시지 프로토콜(ICMP; Internet control message protocol), 링크 계층 탐색 프로토콜(LLDP; link layer discovery protocol), 다른 도구, 또는 이들의 조합을 이용하여 상기 네트워크 토폴로지를 결정할 수 있다. 상 기 네트워크 토폴로지 정보를 결정하는 단계는 상기 네트워크에서 다양한 장치에서 사용할 수 있는 대역폭을 결 정하는 단계를 더 포함할 수 있다. 예를 들어, AI 호스트 장치는 스토리지 장치들의 사용 가능한 대 역폭들, 오브젝트 스토리지 시스템의 사용 가능한 대역폭, AI PU들(112a-112h)의 사용 가능한 대역폭들, 또는 이들의 조합을 결정할 수 있다. 506에서, 방법은 스토리지 능력 정보를 판독하는 단계를 더 포함한다. 예를 들어, AI 호스트 장치는 스토리지 장치들(200a-200d), 오브젝트 스토리지 시스템, 또는 이들의 조합을 조회하여 상기 AI 트레이닝 세션 동안 사용 가능한 스토리지 용량을 결정할 수 있다. 508에서, 방법은 상기 네트워크 정보와 상기 스토리지 능력 정보를 분석하고 GFID를 상기 AI 트레이닝 세 션과 관련된 리소스들에 연관시키는 전역 흐름 데이터베이스 엔트리를 생성하는 단계를 더 포함한다. 510에서 상기 토폴로지와 스토리지 능력이 상기 스토리지 시스템 파라미터들을 지원하지 않는 것으로 판단하는 것에 응답하여, 502에서, 방법은 다음 스토리지 서비스 세션 파라미터들을 판독하는 단계를 포함한다. 510에서 상기 토폴로지와 스토리지 능력이 상기 스토리지 시스템 파라미터들을 지원하는 것으로 판단하는 것에 응답하여, 512에서, 방법은 상기 전역 흐름 데이터베이스 엔트리를 분배하는 단계를 포함한다. 예를 들어, AI 호스트 장치는 상기 데이터베이스 엔트리를 GFID 데이터베이스에 분배할 수 있다. 514에서, 방법은 스토리지 쿼리들과 관련 흐름들을 설정하고 초기화하는 단계를 더 포함한다. 예를 들어, AI 호스트 장치는 오브젝트 스토리지 시스템과의 연결을 초기화할 수 있다. 이 연결은 GFID 데이터베이스에 저장된 상기 엔트리로 나타낸 대역폭을 갖을 수 있다. AI 호스트 장치는 상기 GFID 데이터베 이스 엔트리에 식별된 하나 또는 그 이상의 스토리지 장치들과의 연결들을 더 초기화할 수 있다. 516에서, 방법은 어플리케이션을 시작하는 단계를 포함한다. 예를 들어, AI 호스트 장치는 상기 AI 트레이닝 세션의 일부로서 AI 어플리케이션를 시작하고 오브젝트 스토리지 시스템으로 IO 커맨드들을 발급하기 시작할 수 있다. 도 6을 참조하면, 시간 동기화된 요청들을 스토리지 장치에 전송하는 방법을 나타내는 도면이 도시된다. 방법은 오브젝트 스토리지 시스템과 같은 오브젝트 스토리지 시스템 또는 또는 다른 종류의 스토리지 시스템에 의해 수행될 수 있다. 606에서, 방법은 제1 AI PU로부터 제1 입/출력(IO; input/output) 커맨드를 수신하는 단계를 포함하되, 상기 제1 IO 커맨드는 제1 AI 모델 트레이닝 동작과 관련된다. 예를 들어, 오브젝트 스토리지 시스템은 NIC를 통해 제1 AI PU(112a)로부터 제1 IO 커맨드를 수신할 수 있다. 상기 제1 IO 커맨드는 제1 AI PU(112a)에 의해 수행되는 제1 AI 트레이닝 세션과 관련된 제1 GFID를 포함할 수 있다. 608에서, 방법은 제2 AI PU로부터 제2 IO 커맨드를 수신하는 단계를 포함하되, 상기 제2 IO 커맨드는 제2 AI 모델 트레이닝 동작과 관련된다. 예를 들어, 오브젝트 스토리지 시스템은 NIC를 통해 제2 AI PU(112b)로부터 제2 IO 커맨드를 수신할 수 있다. 상기 제2 IO 커맨드는 제2 AI PU(112b)에 의해 수행되는 제2 AI 트레이닝 세션과 관련된 제2 GFID를 포함할 수 있다. 610에서, 방법은 상기 제1 AI 모델 트레이닝 동작에 할당된 제1 대역폭에 기반하여 제1 타임스탬프를 상기 제1 IO 커맨드에 할당하는 단계를 포함한다. 예를 들어, 오브젝트 스토리지 시스템의 프로세서부는 GFID 데이터베이스를 조회하여 상기 제1 IO 커맨드에 포함된 상기 GFID와 관련된 제1 대역폭 인디케이터 를 결정할 수 있다. 오브젝트 스토리지 시스템의 프로세서부는 상기 식별된 제1 대역폭에 기반 하여 제1 타임스탬프를 상기 제1 IO 커맨드에 할당할 수 있다. 일부 예들에서, 상기 제1 타임스탬프는 상기 제1 대역폭에 기반하여 결정된 오프셋뿐만 아니라 오브젝트 스토리지 시스템에서의 상기 제1 IO 커맨드의 수신 시간에 대응될 수 있다. 612에서, 방법은 상기 제2 AI 모델 트레이닝 동작에 할당된 제2 대역폭에 기반하여 제2 타임스탬프를 상기 제2 IO 커맨드에 할당하는 단계를 더 포함한다. 예를 들어, 오브젝트 스토리지 시스템은 GFID 데이터베이 스를 조회하여 상기 제2 IO 커맨드에 포함된 상기 GFID와 관련된 제2 대역폭 인디케이터를 결정할 수 있다. 오브젝트 스토리지 시스템의 프로세서부는 상기 식별된 제2 대역폭에 기반하여 제2 타임스탬프 를 상기 제1 IO 커맨드에 할당할 수 있다. 일부 예들에서, 상기 제2 타임스탬프는 상기 제2 대역폭에 기반하여 결정된 오프셋뿐만 아니라 오브젝트 스토리지 시스템에서의 상기 제1 IO 커맨드의 수신 시간에 대응될 수 있다. IO 커맨드에 기반하여 오브젝트 스토리지 시스템의 의해 전송된 데이터 요청들은 상기 IO 커맨드에 할당된 상기 타임스탬프를 포함할 수 있다. 상기 데이터 요청들을 수신한 스토리지 장치들은 상기 타임스탬프들에 기반 하여 결정된 순서로 데이터를 출력할 수 있다. 따라서, 데이터는 시간 동기화된 방식으로 상기 스토리지 장치들 에 의해 출력될 수 있다. 도 7을 참조하면, 시간 동기화된 방식으로 스토리지 장치로부터 데이터를 전송하는 방법을 나타내는 도면 이 도시된다. 702에서, 방법은 제1 데이터 청크에 대한 제1 요청을 수신하는 단계를 포함한다. 상기 제1 요청은 제1 타 임스탬프와 제1 전역 흐름 식별자(GFID; global flow identifier)를 포함한다. 예를 들어, 제1 스토리지 장치 (200a)는 NIC를 통해 제 오브젝트 스토리지 시스템로부터 상기 제1 요청을 수신할 수 있다. 상기 제1 요청은 제1 데이터 청크를 요청하고, 제1 타임스탬프를 포함하고, 및 제1 GFID를 포함할 수 있다. 704에서, 방법은 제2 데이터 청크에 대한 제2 요청을 수신하는 단계를 포함하되, 상기 제2 요청은 제2 타 임스탬프와 제2 GFID를 포함한다. 예를 들어, 제1 스토리지 장치(200a)는 NIC를 통해 오브젝트 스토리지 시스템로부터 상기 제2 요청을 수신할 수 있다. 상기 제2 요청은 제2 데이터 청크를 요청하고, 제2 타임스 탬프를 포함하고, 및 제2 GFID를 포함할 수 있다. 706에서, 방법은 상기 제1 GFID를 기반으로 제1 AI PU를 식별하는 단계를 더 포함한다. 제1 스토리지 장치 (200a)의 프로세서부는 NIC를 통해 GFID 데이터베이스를 조회하여 제1 AI PU(112a)가 상기 제1GFID와 관련되는 것으로 판단할 수 있다. 708에서, 방법은 상기 제2 GFID를 기반으로 제2 AI PU를 식별하는 단계를 더 포함한다. 예를 들어, 제1 스 토리지 장치(200a)의 프로세서부는 NIC를 통해 GFID 데이터베이스를 조회하여 제2 AI PU(112 b)가 상기 제2 GFID와 관련되는 것으로 판단할 수 있다. 710에서, 방법은 상기 제1 데이터 청크를 상기 제1 AI PU에 전송하는 단계를 더 포함하되, 여기서 상기 제 1 데이터 청크의 전송 타이임은 상기 제1 타임스탬프에 기반한다. 예를 들어, 제1 스토리지 장치(200a)의 프로 세서부는 NIC를 통한 제1 AI PU(112a)로의 상기 제1 데이터 청크의 전송을 개시할 수 있다. 제1 스토 리지 장치(200a)의 프로세서부는 스테이징 버퍼들(202a-202d)중 하나로부터 상기 제1 요청의 처리를 예약 하고, 상기 제1 타임스탬프에 기반하여 제1 AI PU(112a)에 대한 상기 제1 데이터 청크의 전송을 예약할 수 있다. 일부 실시예들에서, 제1 스토리지 장치(200a)의 프로세서부는 상기 제1 타임스탬프로 나타낸 시간까 지 기다려서 상기 제1 데이터 청크를 제1 AI PU(112a)로 전송할 수 있다. 712에서, 방법은 상기 제2 데이터 청크를 상기 제2 AI PU에 전송하는 단계를 더 포함하되, 여기서 상기 제 2 데이터 청크의 전송 타이임은 상기 제2 타임스탬프에 기반한다. 예를 들어, 제1 스토리지 장치(200a)의 프로 세서부는 NIC를 통한 제2 AI PU(112b)로의 상기 제2 데이터 청크의 전송을 개시할 수 있다. 제1 스토 리지 장치(200a)의 프로세서부는 스테이징 버퍼들(202a-202d)중 하나로부터 상기 제2 요청의 처리를 예약 하고, 상기 제2 타임스탬프에 기반하여 제1 AI PU(112a)에 대한 상기 제1 데이터 청크의 전송을 예약할 수 있다. 일부 실시예들에서, 제1 스토리지 장치(200a)의 프로세서부는 상기 제2 타임스탬프로 나타낸 시간까 지 기다려서 상기 제2 데이터 청크를 제1 AI PU(112a)로 전송할 수 있다. 또한, 방법은 스토리지 장치에 의해 사용되어 시간 동기화된 방식으로 데이터 청크들을 전송할 수 있다. 전송을 동기화하기 위해 상기 스토리지 장치에 의해 사용된 상기 타임스탬프들은 AI 트레이닝 세션 우선순위에 기반될 수 있기 때문에서, 데이터의 전송은 AI 트레이닝 세션들의 상대적 우선순위들을 고려할 수 있다. 도 8를 참조하면, 제1 AI PU(112a)가 특정의 AI 타이임 세션 동안 세 개의 IO 커맨드들을 발급하는 예를 나타낸 순서도가 도시된다. 상기 순서도는 제1 내지 제n 스토리지 장치들(200a-200n)을 나타낸다. 위에서 설명한 바와 같이, 도 3의 시스템은 도시된 4개와 다른 수의 스토리지 장치들을 포함할 수 있다. 802에서, 상기 순서도는 오브젝트 스토리지 시스템에 연결된 제1 AI PU(112a)를 포함한다. 제1 AI PU(112a)는 AI 트레이닝 세션 동안 스토리지 쿼리 계획이 성공적으로 수립되고 상기 스토리지 쿼리 계획이 오브 젝트 스토리지 시스템을 상기 AI 트레이닝 세션에 할당하는 것으로 판단하는 것에 응답하여 이 연결을 개 시할 수 있다. 도시된 예에서, 상기 AI 트레이닝 세션은 “”의 GFID를 갖는다. 따라서, GFID 데이터베이스 는 GFID “”를 오브젝트 스토리지 시스템에 연관시키는 GFID 데이터베이스 엔트리를 저장한다. 804에서, 상기 순서도는 제1 스토리지 장치(200a)에 연결되는 제1 AI PU(112a)를 포함한다. 제1 AI PU(112a)는 상기 스토리지 쿼리 계획이 제1 스토리지 장치(200a)를 상기 AI 트레이닝 세션에 할당하는 것으로 판단하는 것에 응답하여 이 연결을 개시할 수 있다. 상기 GFID 데이터베이스 엔트리는 GFID “”를 제1 스토리 지 장치(200a)에 연관시킨다. 806에서, 상기 순서도는 제2 스토리지 장치(200b)에 연결되는 제1 AI PU(112a)를 포함한다. 제1 AI PU(112a)는 상기 스토리지 쿼리 계획이 제2 스토리지 장치(200b)를 상기 AI 트레이닝 세션에 할당하는 것으로 판단하는 것에 응답하여 이 연결을 개시할 수 있다. 상기 GFID 데이터베이스 엔트리는 GFID “”를 제2 스토리 지 장치(200b)에 연관시킨다. 808에서, 상기 순서도는 제n 스토리지 장치(200n)에 연결되는 제1 AI PU(112a)를 포함한다. 제1 AI PU(112a)는 상기 스토리지 쿼리 계획이 제n 스토리지 장치(200n)를 상기 AI 트레이닝 세션에 할당하는 것으로 판단하는 것에 응답하여 이 연결을 개시할 수 있다. 상기 GFID 데이터베이스 엔트리는 GFID “”를 제n 스토리 지 장치(200n)에 연관시킨다. 상기 순서도는 810에서 제1 IO 커맨드를 오브젝트 스토리지 시스템에 전송하고, 812에서 제2 IO 커맨 드를 오브젝트 스토리지 시스템에 전송하고, 814에서 제3 IO 커맨드를 오브젝트 스토리지 시스템에 전송하는 제1 AI PU(112a)를 더 포함한다. 도시된 예에서, 상기 제1, 제2, 및 제3 IO 커맨드들은 GET 커맨드들 이다. 상기 제1 IO 커맨드는 제1 데이터 오브젝트를 (예: 키 값에 의해) 식별하고, 상기 제2 IO 커맨드는 제2 데이터 오브젝트를 식별하고, 및 상기 제3 IO 커맨드는 제3 데이터 오브젝트를 식별한다. 오브젝트 스토리지 시 스템은 제1 타임스탬프를 상기 제1 IO 커맨드에 할당하고, 제2 타임스탬프를 상기 제2 IO 커맨드에 할당하며, 제3 타임스탬프를 상기 제3 IO 커맨드에 할당한다. 상기 타임스탬프들은 GFID 데이터베이스에서의 상 기 GFID “”와 관련된 우선순위(예: 대역폭)에 기반하여 생성될 수 있다. 각 커맨드의 경우, 오브젝트 스토리지 시스템은 상기 IO 커맨드에 의해 식별된 상기 오브젝트와 관련된 데 이터 청크들에 대한 요청들을 이어서 생성한다. 상기 요청들은 상기 IO 커맨드에 할당된 상기 타임스탬프를 포 함하고, 상기 GFID “”와 관련됨에 따라 오브젝트 스토리지 시스템에 의해 GFID 데이터베이스에서 식별된 스토리지 장치들로 전송된다. 상기 도 8의 도시된 예에서, 오브젝트 스토리지 시스템은 상기 제1 IO 커맨드에 기반하여 데이터 청크에 대한 제1 요청, 데이터 청크에 대한 제2 요청, 및 데이터 청크에 대한 제3 요청을 생성한다. 이러한 요청들의 각각은 상기 제1 IO 커맨드에 할당된 상기 제1 타임스탬프를 포함한다. 오브젝트 스토리지 시스템은 상기 제2 IO 커맨드에 기반하여 데이터 청크에 대한 제4 요청, 데이터 청크에 대한 제5 요청, 및 데이터 청크에 대한 제6 요청을 더 생성한다. 이러한 요청들의 각각은 상기 제2 IO 커맨드에 할당된 상기 제2 타임스탬프를 포함한 다. 오브젝트 스토리지 시스템은 상기 제3 IO 커맨드에 기반하여 데이터 청크에 대한 제7 요청, 데이터 청 크에 대한 제8 요청, 및 데이터 청크에 대한 제9 요청을 더 생성한다. 이러한 요청들의 각각은 상기 제3 IO 커 맨드에 할당된 상기 제3 타임스탬프를 포함한다. 순서도에서, 오브젝트 스토리지 시스템은 816에서 상기 제1 요청을 제1 스토리지 장치(200a)에 전송 하고, 818에서 상기 제7 요청을 제1 스토리지 장치(200a)에 전송하고, 820에서 상기 제8 요청을 제2 스토리지 장치(200b)에 전송하고, 822에서 상기 제4 요청을 제1 스토리지 장치(200a)에 전송하고, 824에서 상기 제2 요청 을 제2 스토리지 장치(200b)에 전송하고, 826에서 상기 제3 요청을 제n 스토리지 장치(200n)에 전송하고, 828에 서 상기 제9 요청을 제n 스토리지 장치(200n)에 전송하고, 830에서 상기 제5 요청을 제2 스토리지 장치(200b)에 전송하고, 및 832에서 상기 제6 요청을 제n 스토리지 장치(200n)에 전송한다. 이에 따라, 상기 요청들은 고장 난 오브젝트 스토리지 시스템에 의해 전송될 수 있다 (및 스토리지 장치들(200a-200n)에 의해 수신될 수 있다). 스토리지 장치들(200a-200n)은 상기 요청들에 포함된 상기 타임스탬프들에 기반하여 결정된 순서로 데이터 청크 들을 출력하도록 구성된다. 예를 들어, 제1 스토리지 장치(200a)는 상기 제1 요청, 상기 제4 요청, 및 상기 제7 요청을 수신하고, (상기 해당하는 요청들이 수신되는 순서와 다를 수 있는) 상기 각 타임스탬프들에 기반한 순 서(sequence)로 제1 스테이징 버퍼(202a)에서 상기 제1 요청, 상기 제4 요청, 및 상기 제7 요청을 삽입하고, 이 어서 상기 순서(sequence)에 기반하는 순서(order)로 제1 스테이징 버퍼(202a)로부터의 요청들을 처리할 수 있 다. 추가적으로 또는 대체적으로, 제1 스토리지 장치(200a)는 상기 타임스탬프들에 기반하는 순서(sequence)로 상기 제1 요청과 관련된 데이터, 상기 제4 요청과 관련된 데이터, 및 상기 제7 요청에 관련된 데이터를 제2 스 테이징 버퍼(202b)에 삽입하고, 이어서 상기 순서(sequence)에 기반한 순서(order)로 제2 스테이징 버퍼(202b) 로부터의 상기 데이터 청크들 전송할 수 있다. 일부 실시예들에서, 데이터 청크는 스테이징 버퍼(202b)로부터 제거되어 상기 데이터 청크와 관련된 상기 타임스탬프로 나타난 시점(또는 대략 시점(예: 3 ms 이내))에 제1 AI PU(112a)로 전송된다. 따라서, 도시된 순서도에서, 834에서 상기 제1 요청에 대응되는 데이터 청크는 제1 AI PU(112a)에 출력되 고, 836에서 상기 제2 요청과 관련된 데이터 청크는 제1 AI PU(112a)에 출력되고, 838에서 상기 제3 요청과 관 련된 데이터 청크는 제1 AI PU(112a)에 출력되고, 840에서 상기 제4 요청과 관련된 데이터 청크는 제1 AI PU(112a)에 출력되고, 842에서 상기 제5 요청과 관련된 데이터 청크는 제1 AI PU(112a)에 출력되고, 844에서 상 기 제6 요청과 관련된 데이터 청크는 제1 AI PU(112a)에 출력되고, 846에서 상기 제7 요청과 관련된 데이터 청 크는 제1 AI PU(112a)에 출력되고, 848에서 상기 제8 요청과 관련된 데이터 청크는 제1 AI PU(112a)에 출력되고, 및 850에서 상기 제9 요청과 관련된 데이터 청크는 제1 AI PU(112a)에 출력된다. 데이터가 반환되는 순서를 결정하는 외에, 오브젝트 스토리지 시스템에 의해 설정된 상기 타임스탬프들이 데이터가 상기 AI PU들에 전달되는 비율을 결정함을 유의해야 한다. 따라서, 제1 AI PU(112a)에 반환되는 데이터 청크들은 시간 동기화되거나 적절한 전송 속도들로 전달될 수 있다. 도시된 예에서, 오브젝트 스토리지 시스템은 852에서 제1 완료 통지를 제1 AI PU(112a)에 전송하고, 854에 서 제2 완료 통지를 제1 AI PU(112a)에 전송하고, 및 856에서 제3 완료 통지를 제1 AI PU(112a)에 전송한다. 상기 완료 통지들은 상기 타임스탬프들과 관련된 시간들에 기반하여 전송될 수 있다. 예를 들어, 상기 제1 완료 통지는 상기 제1 타임스탬프로 나타낸 시점에서 오브젝트 스토리지 시스템에 의해 전송될 수 있다. 따라서, 제1 AI PU(112a)는 상기 제1 IO 커맨드와 관련된 모든 데이터 청크들이 전송되어야 함을 통지받을 수있다. 위에서 언급된 상기 예들은 하나의 AI 호스트 장치가 하나의 오브젝트 스토리지 시스템과 상호 작용하는 실시예 들을 언급한다. 그러나, 시스템은 둘 이상의 AI 호스트 장치와 둘 이상의 오브젝트 스토리지 시스템들을 포함할 수 있다. 둘 이상의 AI 호스트 장치들은 오브젝트 스토리지 시스템과 상호 작용을 할 수 있다. 또한, AI 호스트 장치는 둘 이상의 오브젝트 스토리지 시스템들과 상호 작용을 할 수 있다. 많은 AI 호스트 장치들과 많은 오브 젝트 스토리지 시스템들을 포함하는 예시적인 시스템이 도 9에 도시된다. 도 9의 시스템의 구성 및 동작은 도 1 내지 8를 참조하여 위에서 설명한 상기 시스템들과 동작들과 유사할 수 있다. 상술한 설명은 예시적인 실시 예를 설명하기 위한 것이며, 본 발명을 제한하는 것으로 해석되어서는 안된다. 비록 몇몇 예시적인 실시 예가 설명되었지만, 당업자는 예시적인 실시 예의 신규한 교시 및 이점으로부터 실질 적으로 벗어나지 않고도 예시적인 실시 예에서 많은 변형이 가능하다는 것을 용이하게 이해할 것이다. 따라서, 이러한 모든 수정은 청구항에 정의된 예시적인 실시 예들의 범위 내에 포함되도록 의도된다. 청구 범위에서, 수단-플러스-기능(means-plus-function) 절은 구조적 등가물뿐만 아니라 등가의 구조를 열거하여 여기에 설명된 구조를 포함하도록 의도되었다. 따라서, 상술한 설명은 예시적인 실시 예를 설명하기 위한 것이며, 개시된 특 정 실시 예에 한정되는 것으로 해석되어서는 안되며, 첨부된 청구범위의 범주 내에서 개시된 예시적인 실시 예 및 다른 예시적인 실시 예에 대한 수정이 포함되는 것으로 이해되어야 한다. 본 명세서에서 사용된 용어는 특정 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니 다. 본 명세서에 사용된 바와 같이, 단수 형태 “a”and “”는 문맥상 명백하게 다르게 뜻하지 않는 복수형도 포함하는 것으로 의도된다. 또한 명세서에 사용된 \"구성한다\"(comprises), \"구성하는\"(comprising), “갖는다 ”(have), “갖는”(having) \"포함한다\"(includes),\"포함하는\"(including) 용어들은, 언급된 특징들, 숫자들, 단계들, 동작들, 구성 요소들, 및/혹은 성분들의 존재를 상세하게 하고, 이들의 하나 이상의 다른 특징들, 숫자 들, 단계들, 동작들, 구성 요소들, 및/혹은 성분들의 추가를 배제하지 않는다고 이해되어야 할 것이다. 본 명 세서에서 사용된 바와 같이, 용어 \"및/혹은\"는 관련된 열거 항목의 하나 이상의 임의의 모든 조합을 포함한다. 본 명세서에서 사용된 바와 같이, 본 발명의 실시예들을 설명하는 경우에 \"할 수 있다\"(may)의 사용은 \"본 발명 의 하나 또는 그 이상의 실시 예들\"로 언급한다. 본 명세서에서 사용된, \"사용하다\"(use), \"사용하는\"(using), 및 \"사용된\"(used) 이라는 용어들은, 각각 \"이용하다\"(utilize), \"이용하는\"(utilizing), 및 \"이용 된\"(utilized) 용어들로 동의어로 간주될 것이다. 또한, \"예시적인\"(exemplary)이라는 용어는 예시(example) 혹 은 도면(illustration)으로 간주된다. 어떤 실시예가 다르게 구현되는 경우, 특정 프로세스 순서는 상기 언급된 순서와 다르게 수행될 수 있다. 예를 들어, 2 개의 연속적으로 설명된 프로세스들 또는 방법 단계들이 실질적으로 동시에 수행되거나 설명된 순서와 다른 순서로 수행 될 수 있다. 본 명세서에서 기술된 본 발명의 실시 예에 따른 전자 또는 전기 장치들 그리고/또는 다른 임의의 관련된 장치 들 또는 요소들은 임의의 적합한 하드웨어, 펌웨어(예: asic; application-specific integrated circuit), 소 프트웨어, 또는 소프트웨어, 펌웨어, 그리고 하드웨어의 조합을 이용하여 구현될 수 있다. 예를 들어, 이러한 장치들의 다양한 요소들은 하나의 집적 회로(IC; integrated circuit) 칩 또는 분리된 IC 칩들로 형성될 수 있 다. 또한, 이러한 장치들의 다양한 요소들은 유연한 인쇄 회로 필름(flexible printed circuit film), TCP(tape carrier package), 인쇄 회로 기판(PCB; printed circuit board) 위에 구현되거나 하나의 기판 위에 서 형성될 수 있다. 또한, 이러한 장치들의 다양한 요소들은 컴퓨터 프로그램 명령들을 실행하고 본 명세서에 서 설명된 다양한 기능들을 수행하기 위한 다른 시스템 요소들과 상호 작용하는 하나 이상의 컴퓨팅 장치들에서 또는 하나 이상의 프로세서들에서 수행되는 프로세스 또는 스레드(thread)일 수 있다. 컴퓨터 프로그램 명령들 은 예를 들면 RAM(random access memory)과 같은 표준 메모리 장치를 이용하는 컴퓨팅 장치에서 구현되는 메모 리내에 저장된다. 컴퓨터 프로그램 명령들은 또한 예를 들면 CD-ROM, 플래시 드라이브(flash drive), 또는 그 와 같은 다른 일시적이지 않은 컴퓨터 읽기 가능한 미디어(non-transitory computer readable media)에 저장될 수도 있다. 또한, 본 발명의 당업자는 본 발명의 예시적인 실시 예들의 사상 및 범위를 벗어나지 않고 다양한 컴퓨팅 장치들의 기능은 단일 컴퓨팅 장치에 통합되거나 집적되고, 특정 컴퓨팅 장치의 기능이 하나 또는 그 이 상의 다른 컴퓨팅 장치들에 분산될 수 있음을 인식해야 한다. 다르게 정의되지 않는 한, 본 명세서에서 사용된 모든 용어들(기술적이거나 과학적인 용어를 포함하는)은 일반 적으로 본 발명이 속하는 당업자에 의해 이해되는 동일한 의미를 갖는다. 이는 일반적으로 사용되는 사전에 정의되어 있는 용어들은 관련 기술 및/ 혹은 본 명세서의 문맥에서 그들의 의미와 일치하는 의미를 가지는 것으로 해석되도록 이해되며, 본 출원에서 명백하게 정의하지 않는 한, 이상화된 혹은 지나치게 형식적인 감각으로 해 석되지 말아야 한다."}
{"patent_id": "10-2021-0075591", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 시간 동기화된 스토리지 전달을 수행하기 위한 시스템의 도면이다. 도 2는 시간 동기화된 스토리지 전달을 수행하기 위한 스토리지 장치의 도면이다. 도 3은 도 2의 다수의 스토리지 장치들을 포함하는 시간 동기화된 스토리지 전달을 수행하기 위한 시스템의 도 면이다. 도 4는 전역 흐름 식별자 데이터베이스 엔트리(global flow identifier database entry)의 도면이다. 도 5는 스토리지 쿼리 계획(storage query plan)을 구축하기 위한 방법을 나타낸 흐름도이다. 도 6은 타임스탬프들을 IO 요청들에 할당하기 위한 방법을 나타낸 흐름도이다. 도 7은 IO 요청들에 응답하여 데이터를 출력하기 위한 방법을 나타낸 흐름도이다. 도 8은 IO 커맨드들의 동기화된 처리(synchronized processing)를 나타낸 순서도이다. 도 9는 다중 인공 지능 호스트 장치들과 다중 객체 스토리지 시스템들을 포함하는 시스템을 나타낸 도면이다."}
