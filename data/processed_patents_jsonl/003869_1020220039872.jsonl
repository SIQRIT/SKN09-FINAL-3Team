{"patent_id": "10-2022-0039872", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0009806", "출원번호": "10-2022-0039872", "발명의 명칭": "영상 처리 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "박재성"}}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 처리 장치에 있어서, 하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 제1 영상으로부터 상기 제1 영상에 포함된 중요 객체에 대한 객체 정보를 획득하고, 화질 처리를 위한 제어 정보를 획득하고,상기 객체 정보 및 상기 제어 정보를 기반으로, 상기 중요 객체에 대한 화질 처리를 수행하여 제2 영상을 획득하는, 영상 처리 장치."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 객체 정보는 상기 중요 객체의 종류, 위치, 및 크기 중 적어도 하나에 대한 정보를 포함하는, 영상 처리 장치."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 영상으로부터 복수 객체를 검출하고, 상기 복수 객체를 가리키는 객체 식별 정보를 출력하고, 상기 객체 식별 정보 출력에 상응하여 사용자로부터 선택된 객체를 상기 중요 객체로 식별하는, 영상 처리장치."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서, 상기 제어 정보는 객체의 확대 여부, 객체의 확대 정도, 윤곽선 처리, 및 평탄화 처리 중 적어도 하나에 대한 제어 정보를 포함하는, 영상 처리 장치."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제어 정보에 따라, 상기 객체의 업스케일링, 상기 객체 주위의 윤곽선 처리, 및 상기 객체 내부 평탄화 처리 중 적어도 하나를 수행하는, 영상 처리 장치."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서, 상기 제어 정보는 추론 제어 정보 및 실시간 사용자 제어 정보 중 적어도 하나를 포함하고, 상기 추론 제어 정보는 이전 영상에 대한 상기 사용자의 이전 제어 이력 정보로부터 획득되고, 상기 실시간 사용자 제어 정보는 상기 제1 영상에 대한 상기 사용자의 실시간 제어 정보를 포함하는, 영상 처리장치."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 뉴럴 네트워크를 이용하여,상기 제1 영상으로부터 상기 제2 영상을 획득하고, 공개특허 10-2023-0009806-3-상기 뉴럴 네트워크는 입력 영상, 상기 입력 영상에서 사용자가 관심을 갖는 객체 영역, 및 상기 사용자가 관심을 갖는 객체 영역을 화질 처리한 그라운드 트루쓰(ground thruth) 영상을 학습 데이터 셋으로 학습한 뉴럴 네트워크인, 영상 처리 장치."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서, 상기 뉴럴 네트워크는 상기 제1 영상, 상기 제어 정보, 및 상기 객체 정보 중 적어도 하나로부터, 상기 객체가 화질 처리된 제2 영상을 획득하는, 영상 처리 장치."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7 항에 있어서, 상기 뉴럴 네트워크는 상기 제1 영상, 상기 사용자 제어 정보, 및 상기 객체 정보 중 적어도하나로부터, 상기 객체에 대한 화질 처리를 위한 평탄화 파라미터 및 윤곽선 파라미터를 획득하고, 상기 프로세서는 사용자 제어 신호에 따라 상기 평탄화 파라미터에 따라 화질 처리된 영상 및 상기 윤곽선 파라미터에 따라 화질 처리된 영상의 블렌딩 정도를 조절하여 화질 처리된 제2 영상을 획득하는, 영상 처리 장치."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8 항 또는 제9 항에 있어서, 상기 화질 처리는 상기 객체의 윤곽선 처리, 상기 객체 내부의 평탄화 처리, 및상기 객체를 업스케일링하는 것 중 적어도 하나를 포함하고, 상기 객체의 윤곽선 처리는 상기 객체의 윤곽선의 디테일, 강도, 색상 중 적어도 하나에 대한 처리를 포함하고, 상기 객체 내부의 평탄화 처리는 상기 객체 내부의 평탄화 정도를 조절하는 처리를 포함하고, 상기 객체를 업스케일링하는 것은 상기 객체의 해상도를 유지하면서 상기 객체의 크기를 확대하는 처리를 포함하는, 영상 처리 장치."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "영상 처리 장치에서 수행하는 영상 처리 방법에 있어서, 제1 영상으로부터 상기 제1 영상에 포함된 중요 객체에 대한 객체 정보를 획득하는 단계;화질 처리에 대한 제어 정보를 획득하는 단계; 및상기 객체 정보 및 상기 사용자 제어 정보를 기반으로, 상기 제1 영상으로부터 상기 중요 객체에 대한 화질 처리를 수행하여 제2 영상을 획득하는 단계를 포함하는, 영상 처리 방법."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서, 상기 객체 정보는 상기 중요 객체의 종류, 위치, 및 크기 중 적어도 하나에 대한 정보를 포함하는, 영상 처리 방법."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11 항에 있어서, 상기 제1 영상으로부터 복수 객체를 검출하는 단계;상기 복수 객체를 가리키는 객체 식별 정보를 출력하는 단계; 및상기 객체 식별 정보 출력에 상응하여 사용자로부터 선택된 객체를 상기 중요 객체로 식별하는 단계를 더 포함하는, 영상 처리 방법."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11 항에 있어서, 상기 제어 정보는 객체의 확대 여부, 객체의 확대 정도, 윤곽선 처리, 및 평탄화 처리 중 적어도 하나에 대한 제어 정보를 포함하는, 영상 처리 방법."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14 항에 있어서, 상기 중요 객체에 대한 화질 처리를 수행하는 단계는 상기 제어 정보에 따라, 상기 객체의업스케일링, 상기 객체 주위의 윤곽선 처리, 및 상기 객체 내부 평탄화 처리 중 적어도 하나를 수행하는 것을공개특허 10-2023-0009806-4-포함하는, 영상 처리 방법."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11 항에 있어서, 상기 제어 정보는 추론 제어 정보 및 실시간 사용자 제어 정보 중 적어도 하나를 포함하고, 상기 추론 제어 정보는 이전 영상에 대한 상기 사용자의 이전 제어 이력 정보로부터 획득되고, 상기 실시간 사용자 제어 정보는 상기 제1 영상에 대한 상기 사용자의 실시간 제어 정보를 포함하는, 영상 처리방법."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11 항에 있어서, 상기 제1 영상으로부터 상기 제2 영상을 획득하는 단계는 뉴럴 네트워크를 이용하여 수행되고, 상기 뉴럴 네트워크는 입력 영상, 상기 입력 영상에서 사용자가 관심을 갖는 객체 영역, 및 상기 사용자가 관심을 갖는 객체 영역을 화질 처리한 그라운드 트루쓰(ground thruth) 영상을 학습 데이터 셋으로 학습한 뉴럴 네트워크인, 영상 처리 방법."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17 항에 있어서, 상기 뉴럴 네트워크는 상기 제1 영상, 상기 제어 정보, 및 상기 객체 정보 중 적어도 하나로부터, 상기 객체가 화질 처리된 제2 영상을 획득하는, 영상 처리 방법."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17 항에 있어서, 상기 뉴럴 네트워크는 상기 제1 영상, 상기 사용자 제어 정보, 및 상기 객체 정보 중 적어도하나로부터, 상기 객체에 대한 화질 처리를 위한 평탄화 파라미터 및 윤곽선 파라미터를 획득하고, 상기 제1 영상으로부터 상기 제2 영상을 획득하는 단계는 사용자 제어에 따라 상기 평탄화 파라미터에 따라 화질 처리된 영상 및 상기 윤곽선 파라미터에 따라 화질 처리된 영상의 블렌딩 정도를 조절하여 화질 처리된 제2영상을 획득하는 단계를 포함하는, 영상 처리 방법."}
{"patent_id": "10-2022-0039872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1 영상으로부터 상기 제1 영상에 포함된 중요 객체에 대한 객체 정보를 획득하는 단계;화질 처리에 대한 제어 정보를 획득하는 단계; 및상기 객체 정보 및 상기 사용자 제어 정보를 기반으로, 상기 제1 영상으로부터 상기 중요 객체에 대한 화질 처리를 수행하여 제2 영상을 획득하는 단계를 포함하는, 영상 처리 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2022-0039872", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "제1 영상으로부터 제1 영상에 포함된 중요 객체에 대한 객체 정보를 획득하는 단계, 화질 처리에 대한 제어 정보 를 획득하는 단계 및 객체 정보 및 사용자 제어 정보를 기반으로, 제1 영상으로부터 중요 객체에 대한 화질 처리 를 수행하여 제2 영상을 획득하는 단계를 포함하는, 영상 처리 방법이 개시된다."}
{"patent_id": "10-2022-0039872", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시된 다양한 실시 예들은 영상 처리 장치 및 그 동작 방법에 관한 것으로, 보다 상세하게는 사용자 특성에 맞 게 영상을 렌더링하는 영상 처리 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2022-0039872", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "시각장애인은 영상을 볼 때 영상에 포함된 객체를 정확히 인지하기 어렵다. 이에, 시각장애인은 영상을 감상하 기 위해 확대 기능을 사용하는 경우가 많다. 그러나, 확대 기능이 사용될 때, 영상의 해상도 또한 떨어지므로, 시각 장애인의 시청 욕구를 만족시킬 수 없다는 문제가 있다. 또한, 시각장애인은 영상 전체의 세밀함에 치중하지 않고 영상 내에서 사물의 전체적인 윤곽선이나 사물 내의 성분이 무엇인지를 인지하는 것에 집중하는 경향이 있다.이에, 시각장애인의 장애 특성에 따라, 영상에 포함된 객체가 보다 정확히 인지될 수 있는 영상을 제공함으로써, 시각장애인이 콘텐츠를 즐길 수 있도록 하는 기술이 요구된다."}
{"patent_id": "10-2022-0039872", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "다양한 실시 예들은 영상에 포함된 중요 객체에 대해 화질 처리를 수행하는 영상 처리 장치 및 그 동작 방법을 제공하기 위한 것이다. 다양한 실시 예들은 영상에 포함된 중요 객체를 사용자의 선호도에 맞게 화질 처리를 수행하는 영상 처리 장치 및 그 동작 방법을 제공하기 위한 것이다."}
{"patent_id": "10-2022-0039872", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시 예에 따른 영상 처리 장치는 하나 이상의 인스트럭션을 저장하는 메모리 및 상기 메모리에 저장된 상기 하 나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행 함으로써, 제1 영상으로부터 상기 제1 영상에 포함된 중요 객체에 대한 객체 정보를 획득하고, 화질 처리를 위 한 제어 정보를 획득하고, 상기 객체 정보 및 상기 제어 정보를 기반으로, 상기 중요 객체에 대한 화질 처리를 수행하여 제2 영상을 획득할 수 있다. 실시 예에서, 상기 객체 정보는 상기 중요 객체의 종류, 위치, 및 크기 중 적어도 하나에 대한 정보를 포함할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 영상으로부터 복수 객체 를 검출하고, 상기 복수 객체를 가리키는 객체 식별 정보를 출력하고, 상기 객체 식별 정보 출력에 상응하여 사 용자로부터 선택된 객체를 상기 중요 객체로 식별할 수 있다. 실시 예에서, 상기 제어 정보는 객체의 확대 여부, 객체의 확대 정도, 윤곽선 처리, 및 평탄화 처리 중 적어도 하나에 대한 제어 정보를 포함할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제어 정보에 따라, 상기 객 체의 업스케일링, 상기 객체 주위의 윤곽선 처리, 및 상기 객체 내부 평탄화 처리 중 적어도 하나를 수행할 수 있다. 실시 예에서, 상기 제어 정보는 추론 제어 정보 및 실시간 사용자 제어 정보 중 적어도 하나를 포함하고, 상기 추론 제어 정보는 이전 영상에 대한 상기 사용자의 이전 제어 이력 정보로부터 획득되고, 상기 실시간 사용자 제어 정보는 상기 제1 영상에 대한 상기 사용자의 실시간 제어 정보를 포함할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 뉴럴 네트워크를 이용하여, 상기 제1 영상으로부터 상기 제2 영상을 획득하고, 상기 뉴럴 네트워크는 입력 영상, 상기 입력 영상에서 사용자가 관심을 갖는 객체 영역, 및 상기 사용자가 관심을 갖는 객체 영역을 화질 처리한 그라운드 트루쓰(ground thruth) 영상을 학습 데이터 셋으로 학습한 뉴럴 네트워크일 수 있다. 실시 예에서, 상기 뉴럴 네트워크는 상기 제1 영상, 상기 제어 정보, 및 상기 객체 정보 중 적어도 하나로부터, 상기 객체가 화질 처리된 제2 영상을 획득할 수 있다. 실시 예에서, 상기 뉴럴 네트워크는 상기 제1 영상, 상기 사용자 제어 정보, 및 상기 객체 정보 중 적어도 하나 로부터, 상기 객체에 대한 화질 처리를 위한 평탄화 파라미터 및 윤곽선 파라미터를 획득하고, 상기 프로세서는 사용자 제어 신호에 따라 상기 평탄화 파라미터에 따라 화질 처리된 영상 및 상기 윤곽선 파라미터에 따라 화질 처리된 영상의 블렌딩 정도를 조절하여 화질 처리된 제2 영상을 획득할 수 있다. 실시 예에서, 상기 화질 처리는 상기 객체의 윤곽선 처리, 상기 객체 내부의 평탄화 처리, 및 상기 객체를 업스 케일링하는 것 중 적어도 하나를 포함하고, 상기 객체의 윤곽선 처리는 상기 객체의 윤곽선의 디테일, 강도, 색 상 중 적어도 하나에 대한 처리를 포함하고, 상기 객체 내부의 평탄화 처리는 상기 객체 내부의 평탄화 정도를 조절하는 처리를 포함하고, 상기 객체를 업스케일링하는 것은 상기 객체의 해상도를 유지하면서 상기 객체의 크 기를 확대하는 처리를 포함할 수 있다. 실시 예에 따른, 영상 처리 장치에서 수행하는 영상 처리 방법은 제1 영상으로부터 상기 제1 영상에 포함된 중 요 객체에 대한 객체 정보를 획득하는 단계, 화질 처리에 대한 제어 정보를 획득하는 단계 및 상기 객체 정보 및 상기 사용자 제어 정보를 기반으로, 상기 제1 영상으로부터 상기 중요 객체에 대한 화질 처리를 수행하여 제 2 영상을 획득하는 단계를 포함할 수 있다. 실시 예에 따른 컴퓨터로 읽을 수 있는 기록 매체는 제1 영상으로부터 상기 제1 영상에 포함된 중요 객체에 대 한 객체 정보를 획득하는 단계, 화질 처리에 대한 제어 정보를 획득하는 단계 및 상기 객체 정보 및 상기 사용 자 제어 정보를 기반으로, 상기 제1 영상으로부터 상기 중요 객체에 대한 화질 처리를 수행하여 제2 영상을 획 득하는 단계를 포함하는, 영상 처리 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록 매체 일 수 있다."}
{"patent_id": "10-2022-0039872", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시 예에 따른 영상 처리 장치 및 그 동작 방법은 영상에 포함된 중요 객체에 대해 화질 처리를 수행할 수 있다. 일 실시 예에 따른 영상 처리 장치 및 그 동작 방법은 영상에 포함된 중요 객체를 사용자의 선호도에 맞게 화질 처리를 수행할 수 있다."}
{"patent_id": "10-2022-0039872", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에서, \"a, b 또는 c 중 적어도 하나\" 표현은 \" a\", \" b\", \" c\", \"a 및 b\", \"a 및 c\", \"b 및 c\", \"a, b 및 c 모두\", 혹은 그 변형들을 지칭할 수 있다. 아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시 예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시에서 사용되는 용어는, 본 개시에서 언급되는 기능을 고려하여 현재 사용되는 일반적인 용어로 기재되었 으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 다양한 다른 용어를 의미할 수 있다. 따라서 본 개시에서 사용되는 용어는 용어의 명칭만으로 해석되어서는 안되며, 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 해석되어야 한다. 또한, 본 개시에서 사용된 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것이며, 본 개시를 한정하려는 의도로 사용되는 것이 아니다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 본 명세서, 특히, 특허 청구 범위에서 사용된 “상기” 및 이와 유사한 지시어는 단수 및 복수 모두를 지시하는 것일 수 있다. 또한, 본 개시에 따른 방법을 설명하는 단계들의 순서를 명백하게 지정하는 기재가 없다면, 기재 된 단계들은 적당한 순서로 행해질 수 있다. 기재된 단계들의 기재 순서에 따라 본 개시가 한정되는 것은 아니 다. 본 명세서에서 다양한 곳에 등장하는 \"일부 실시 예에서\" 또는 \"일 실시 예에서\" 등의 어구는 반드시 모두 동일 한 실시 예를 가리키는 것은 아니다. 본 개시의 일부 실시 예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술 을 채용할 수 있다. “매커니즘”, “요소”, “수단” 및 “구성”등과 같은 용어는 넓게 사용될 수 있으며, 기계적이고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 명세서에서 “사용자”라는 용어는 영상 처리 장치를 이용하는 사람을 의미하며, 소비자, 평가자, 시청자, 관리자 또는 설치 기사를 포함할 수 있다. 여기서, 소비자는 영상 처리 장치를 이용하여 영상을 감상하 는 사람으로, 시각장애인을 포함할 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 실시 예에 따라, 영상 처리 장치가 화질 처리된 영상을 출력하는 것을 설명하기 위한 도면이다. 도 1을 참조하면, 영상 처리 장치는 영상을 처리하여 출력할 수 있는 전자 장치일 수 있다. 일 예에 따라 영상 처리 장치는 디스플레이를 포함하는 다양한 형태의 전자 장치로 구현될 수 있다. 영상 처리 장치 는 고정형 또는 이동형일 수 있으며, 디지털 방송 수신이 가능한 디지털 TV일 수 있으나, 이에 한정되지 않는다. 영상 처리 장치는 비디오를 출력할 수 있다. 실시 예에서, 영상 처리 장치는 화질 처리 모듈을 포함할 수 있다. 화질 처리 모듈은 시청 보조 기능을 제 공할 수 있다. 시청 보조 기능은 시각 장애가 있는 사용자가 콘텐츠를 보다 잘 인지할 수 있도록 하기 위해 비 디오 및/또는 프레임의 화질을 처리하는 것을 의미할 수 있다. 화질 처리 모듈은 적어도 하나의 하드웨어 칩 형태로 제작되어 영상 처리 장치에 탑재되거나, 또는 칩 형 태나 장치 형태로 영상 처리 장치에 포함될 수 있다. 또는 화질 처리 모듈은 영상 처리 장치에서 소 프트웨어 모듈로 구현될 수도 있다. 실시 예에 따라, 영상 처리 장치는 화질 처리 모듈을 이용하여 화질 처리를 수행할 수 있다. 영상 처리 장 치는 비디오에 포함된 제1 영상을 디스플레이를 통해 출력하기 전에, 화질 처리 모듈을 이용하여 제1 영상에 대한 화질 처리를 먼저 수행할 수 있다. 영상 처리 장치는 비디오에 포함된 복수의 프레임들각각에 대해 화질 처리를 수행할 수 있다. 실시 예에서, 영상 처리 장치는 하나 이상의 인스트럭션을 저장하는 메모리 및 메모리에 저장된 하나 이상 의 인스트럭션을 실행하는 프로세서를 포함하고, 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 객체 정 보 및 제어 정보를 기반으로, 중요 객체에 대한 화질 처리를 수행할 수 있다. 이를 위해, 영상 처리 장치는 제1 영상으로부터 제1 영상에 포함된 중요 객체에 대한 객체 정보 를 획득할 수 있다. 실시 예에서, 중요 객체는 사용자의 주의를 끄는 관심 대상이 되는 객체로, 화질 처리를 할 대상이 되는 객체를 의미할 수 있다. 실시 예에서, 객체 정보는 중요 객체의 종류, 위치, 및 크기 중 적어도 하나에 대한 정보를 포함할 수 있다. 영상에 복수개의 객체가 포함되어 있는 경우, 영상 처리 장치는 다양한 방법을 이용하여 영상에서 중요 객 체를 식별할 수 있다. 예컨대, 영상 처리 장치는 복수개의 객체 중 해당 영상이 포함된 비디오에 가장 많 이 등장하는 객체를 중요 객체로 식별할 수 있다. 또는, 영상 처리 장치는 현재 발화하는 객체를 중요 객 체로 식별할 수 있다. 또는, 영상 처리 장치는 영상의 중앙에 위치하고, 크기가 기준치 이상 큰 객체를 중 요 객체로 식별할 수 있다. 실시 예에서, 영상 처리 장치는 사용자가 선택한 객체를 중요 객체로 식별할 수도 있다. 예컨대, 영상 처 리 장치는 영상에서 복수개의 객체를 검출하면, 검출된 객체를 각각 표시하는 객체 식별 정보를 객체 주변 에 출력할 수 있다. 사용자는 객체 식별 정보가 화면에 출력된 것에 상응하여 복수개의 객체 식별 정보 중 하나 를 선택할 수 있다. 영상 처리 장치는 사용자가 선택한 객체 식별 정보에 대응하는 객체를 중요 객체로 식 별할 수 있다. 실시 예에서, 영상 처리 장치는 화질 처리를 위한 제어 정보를 획득할 수 있다. 실시 예에서, 제어 정보는 중요 객체의 화질 처리에 대한 사용자 제어 명령을 나타내는 정보일 수 있다. 제어 정보는 중요 객체의 확대 여 부 및 확대 정도, 윤곽선 처리, 및 평탄화 처리 중 적어도 하나에 대한 제어 정보를 포함할 수 있다. 실시 예에서, 영상 처리 장치는 제어 정보에 따라 중요 객체에 대해 화질 처리를 수행할 수 있다. 실시 예에서, 영상 처리 장치는 시각 장애가 있는 사용자가 콘텐츠를 더 잘 인지할 수 있도록 하기 위해 중요 객체를 화질 처리할 수 있다. 실시 예에서, 화질 처리는 객체의 업스케일링, 객체 주위의 윤곽선 처리, 및 객체 내부 평탄화 처리 중 적어도 하나를 수행할 수 있다. 실시 예에서, 제어 정보는 추론 제어 정보 및 실시간 사용자 제어 정보 중 적어도 하나를 포함할 수 있다. 실시 예에서, 추론 제어 정보는 시각 장애가 있는 사람들이나 또는 사용자의 성향을 고려하여 추론한 제어 정보 를 의미할 수 있다. 실시 예에서, 추론 제어 정보는 시각 장애가 있는 사람들의 일반적인 인지 특성이나 선호도를 기반으로 획득될 수 있다. 시각 장애 정도에 따라 다를 수 있지만, 일반적으로, 시각 장애가 있는 사람들은 중요 객체를 크게 보 고 싶어하고, 객체 내부의 디테일한 표현은 생략되는 것을 선호하고, 객체의 윤곽선은 더 뚜렷하게 강조된 영상 을 선호하는 경향이 있다. 따라서, 영상 처리 장치는 시각 장애가 있는 사람들의 인지 특성이나 선호도 등 을 고려하여, 현재 화면에 출력되는 영상, 즉, 도 1의 제1 영상에 포함된 중요 객체에 대해 확대 여부, 윤 곽선 처리, 디테일 처리 등을 어떻게 처리할 것인가에 대한 제어 정보를 추론할 수 있다. 경우에 따라, 사용자는 일반적인 시각 장애가 있는 사람들과는 일정 부분 다른 취향이나 선호도를 가질 수 있다. 따라서, 실시 예에서, 추론 제어 정보는 시각 장애가 있는 사람들이 아닌, 영상 처리 장치를 사용하 는 사용자의 과거의 제어 이력만을 기반으로 획득될 수도 있다. 영상 처리 장치는 어떤 영상이 출력되었을 때 사용자가 어떤 제어 명령을 했는지에 대한 정보를 누적하고, 이로부터 사용자의 선호도나 취향을 추론할 수 있다. 또는 실시 예에서, 추론 제어 정보는 사용자가 영상 처리 장치를 이용하여 미리 입력한, 사용자 선호도에 대한 정보를 기반으로 획득될 수도 있다. 실시 예에서, 실시간 사용자 제어 정보는 현재 화면에 출력되는 영상에 대한 사용자의 제어 정보를 의미할 수 있다. 실시간 사용자 제어 정보는 현재 화면에 출력되는 제1 영상에 대한 사용자의 실시간 제어 정보를 나 타낸다는 점에서 추론 제어 정보와는 구별될 수 있다. 사용자는 현재 출력되는 제1 영상에 포함된 중요 객 체에 대해서는, 과거와는 다르게 제어하고 싶은 경우가 있을 수 있다. 예컨대, 사용자는 제1 영상에 포함 된 중요 객체를 이전과는 달리 더 크게 확대해서 보고 싶어할 수 있다. 이 경우, 사용자는 리모컨 등을 이용하 여 영상 처리 장치에 실시간으로 사용자 제어 정보를 입력할 수 있다. 영상 처리 장치는 사용자로부 터 실시간 사용자 제어 정보를 입력 받고, 이에 따라 중요 객체를 더 크게 업스케일링하여 출력할 수 있다. 실시 예에서, 영상 처리 장치는 제1 영상으로부터 중요 객체가 화질 처리된 제2 영상을 획득할 수 있다. 실시 예에서, 화질 처리는 중요 객체의 윤곽선 처리, 중요 객체 내부의 평탄화 처리, 및 중요 객체를 업스케일 링하는 것 중 적어도 하나를 포함할 수 있다. 실시 예에서, 영상 처리 장치는 인공지능 기술(Artificial Intelligence, AI)을 이용하여 제1 영상 으로부터 제2 영상을 획득할 수 있다. AI 기술은 기계학습(딥 러닝) 및 기계 학습을 활용한 요소 기술들로 구성될 수 있다. AI 기술은 알고리즘을 활용하여 구현될 수 있다. 여기서, AI 기술을 구현하기 위한 알고리즘 또는 알고리즘의 집합을 신경망(Neural Network, 뉴럴 네트워크)이라 한다. 신경망은 입력 데이터를 입력 받고, 분석 및 분류를 위한 연산을 수행하여, 결과 데이터를 출력할 수 있다. 실시 예에서, 영상 처리 장치는 뉴럴 네트워크를 이용하여, 제1 영상에 포함된 중요 객체에 대한 화 질 처리를 수행할 수 있다. 실시 예에서, 뉴럴 네트워크는 입력 영상, 입력 영상에서 사용자가 관심을 갖는 객체 영역, 화질 처리에 대한 사용자의 제어 정보, 및 사용자가 관심을 갖는 객체 영역을 화질 처리한 그라운드 트루쓰(Ground Truth) 영상을 학습 데이터 셋으로 학습한 뉴럴 네트워크일 수 있다. 실시 예에서, 뉴럴 네트워크는 제1 영상, 제어 정보, 및 객체 정보 중 적어도 하나로부터, 중요 객체가 화 질 처리된 제2 영상을 획득할 수 있다. 실시 예에서, 뉴럴 네트워크는 중요 객체를 업스케일링하거나, 객체 윤곽선 두께를 더 두껍게 표시하거나, 객체 윤곽선의 색상을 특정 색상으로 처리하거나, 또는 객체 내부의 평탄화 처리를 수행하는 것 중 적어도 하나를 수 행하여 제2 영상을 획득할 수 있다. 실시 예에서, 제1 영상 전체가 중요 객체로 선택되어 화질 처리된 경우, 제2 영상은 제1 영상 전체에 대해 화질 처리된 영상일 수 있다. 또는 제1 영상 전체가 아닌, 중요 객체 영역만이 화질 처리된 경우, 제2 영상은 화질 처리된 중요 객체 영역만을 포함하는 영상일 수 있다. 또는 제2 영상은 제1 영상에서 중요 객체 영역만 화질 처리되어 포함되고 중요 객체 영역 외의 나머지 영역은 제1 영상과 동일한 영상일 수 있다. 실시 예에서, 뉴럴 네트워크는 제1 영상, 사용자 제어 정보, 및 객체 정보 중 적어도 하나로부터, 객체에 대한 화질 처리를 위한 평탄화 파라미터 및 윤곽선 파라미터를 획득할 수 있다. 영상 처리 장치는 사용자 로부터 파라미터 간 블렌딩을 위한 제어 신호를 선택 받고, 그에 따라 평탄화 파라미터에 따라 처리된 영상 및 윤곽선 파라미터에 따라 처리된 영상의 블렌딩 정도를 조절하여 화질 처리된 제2 영상을 획득할 수 있다. 또는, 다른 실시 예에서, 뉴럴 네트워크는 객체에 대한 화질 처리를 위한 평탄화 파라미터 및 윤곽선 파라미터 를 획득한 후 평탄화 파라미터 및 윤곽선 파라미터의 블렌딩 정도를 자동으로 조절하여 화질 처리된 제2 영상을 결과물로 획득할 수도 있다. 이와 같이, 실시 예에 의하면, 영상 처리 장치는 사용자 특성에 맞게 중요 객체를 화질 처리할 수 있다. 영상 처리 장치는 중요 객체에 대한 객체 정보 및 화질 처리를 위한 제어 정보를 기반으로, 영상에 포함된 중요 객체를 렌더링할 수 있다. 따라서, 사용자는 관심 대상이 되는 중요 객체 영역이 화질 처리된 영상을 시청 할 수 있게 되어, 영상에 대한 시청 만족도가 향상될 수 있다. 다만, 이는 하나의 실시 예로, 화질 처리 모듈은 영상 처리 장치에 포함되지 않고, 영상 처리 장치와 별개의 장치로 구현될 수도 있다. 즉, 영상 처리 장치는 통신망(미도시)를 통해 화질 처리 모듈이 포함된 외부 장치나 서버와 통신할 수 있다. 이 경우, 영상 처리 장치는 통신망을 통해 외부 장치나 서버로 비디 오를 전송할 수 있다. 또한, 영상 처리 장치는 외부 장치나 서버로 제어 명령을 전송할 수 있다. 외부 장 치나 서버는 영상 처리 장치로부터 복수의 프레임들을 포함하는 비디오를 수신하고, 화질 처리 모듈을 이용하여 영상으로부터 중요 객체 영역을 검출할 수 있다. 화질 처리 모듈은 중요 객체 영역에 대해 제어 명령에 따른 화질 처리를 수행할 수 있다. 화질 처리 모듈은 뉴럴 네트워크를 이용하여, 프레임에 포함된 중요 객체에 대해 화질 처리를 수행할 수 있다. 외부 장치나 서버는 화질 처리된 영상을 통신망을 통해 다시 영상 처리 장치 로 전송할 수 있다. 영상 처리 장치는 화질 처리된 영상을 화면을 통해 출력할 수 있다. 이와 같이, 실시 예에 의하면, 영상 처리 장치는 비디오에서 중요 객체 영역이 화질 처리된 영상을 사용자 에게 출력할 수 있다. 도 2는 실시 예에 따른 영상 처리 장치의 내부 블록도이다. 도 2에 도시된 영상 처리 장치는 도 1의 영상 처리 장치일 수 있다. 실시 예에서, 영상 처리 장치는 데스크톱, 스마트 폰(smartphone), 태블릿 PC(tablet personal computer), 이동 전화기(mobile phone), 화상 전화기, 전자 북 리더기(e-book reader), 랩톱 PC(laptop personal computer), 넷북 컴퓨터(netbook computer), 디지털 카메라, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 캠코더, 네비게이션, 웨어러블 장치(wearable device), 스마트 와치(smart watch), 홈 네트워크 시스템, 보안 시스템, 의료 장치 중 적어도 하나를 포함할 수 있다. 영상 처리 장치는 평면(flat) 디스플레이 장치뿐 아니라, 곡률을 가지는 화면인 곡면(curved) 디스플레이 장치 또는 곡률을 조정 가능한 가변형(flexible) 디스플레이 장치로 구현될 수 있다. 영상 처리 장치의 출 력 해상도는 예를 들어, HD(High Definition), Full HD, Ultra HD, 또는 Ultra HD 보다 더 선명한 해상도 등과 같이 다양한 해상도를 가질 수 있다. 영상 처리 장치는 비디오를 출력할 수 있다. 비디오는 복수의 프레임들로 구성될 수 있다. 비디오는, 콘텐 츠 프로바이더들(contents providers)이 제공하는 텔레비전 프로그램이나 VOD 서비스를 통한 각종 영화나 드라 마 등의 아이템을 포함할 수 있다. 콘텐츠 프로바이더는 소비자에게 비디오를 포함한 각종 콘텐츠를 제공하는 지상파 방송국이나 케이블 방송국, 또는 OTT 서비스 제공자, IPTV 서비스 제공자를 의미할 수 있다. 도 2를 참조하면, 영상 처리 장치는 프로세서 및 메모리를 포함할 수 있다. 실시 예에 따른 메모리는, 적어도 하나의 인스트럭션을 저장할 수 있다. 메모리는 프로세서가 실행하는 적어도 하나의 프로그램을 저장하고 있을 수 있다. 메모리에는 적어도 하나의 뉴럴 네트워크 및/ 또는 기 정의된 동작 규칙이나 AI 모델이 저장될 수 있다. 또한 메모리는 영상 처리 장치로 입력되거 나 영상 처리 장치로부터 출력되는 데이터를 저장할 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 실시 예에서, 메모리에는 영상 처리를 수행하기 위한 하나 이상의 인스트럭션이 저장될 수 있다. 실시 예에서, 메모리에는 영상에 포함된 중요 객체에 대한 객체 정보를 획득하기 위한 하나 이상의 인스트 럭션이 저장될 수 있다. 실시 예에서, 메모리에는 화질 처리를 위한 제어 정보를 획득하기 위한 하나 이상의 인스트럭션이 저장될 수 있다. 실시 예에서, 메모리에는 객체 정보 및 제어 정보를 기반으로, 중요 객체에 대한 화질 처리를 수행하기 위 한 하나 이상의 인스트럭션이 저장될 수 있다. 실시 예에서, 메모리에는 적어도 하나의 뉴럴 네트워크 및/또는 기 정의된 동작 규칙이나 AI 모델이 저장 될 수 있다. 실시 예에서, 메모리에 저장된 뉴럴 네트워크는 입력 영상, 입력 영상에서 사용자가 관심을 갖는 객체 영 역, 및 사용자가 관심을 갖는 객체 영역을 화질 처리한 그라운드 트루쓰(ground thruth) 영상을 학습 데이터 셋 으로 학습한 뉴럴 네트워크일 수 있다. 실시 예에서, 메모리에 저장된 뉴럴 네트워크는 제1 영상으로부터 중요 객체 영역을 화질 처리하여 제2 영 상을 획득할 수 있다. 프로세서는 영상 처리 장치의 전반적인 동작을 제어한다. 프로세서는 메모리에 저장된 하 나 이상의 인스트럭션을 실행함으로써, 영상 처리 장치가 기능하도록 제어할 수 있다. 실시 예에서, 프로세서는 영상으로부터 영상에 포함된 중요 객체에 대한 객체 정보를 획득할 수 있다. 실시 예에서, 프로세서는 영상에 포함된 객체가 복수개인 경우, 복수 객체 중 비디오에 가장 많이 등장하 는 객체, 또는, 현재 발화하는 객체, 또는 관심 영역에 위치하는 객체를 중요 객체로 식별할 수 있다. 또는, 실시 예에서, 프로세서는 복수 객체를 가리키는 객체 식별 정보가 화면에 출력되도록 하고, 사용자 로부터 선택된 객체 식별 정보에 대응하는 객체를 중요 객체로 식별할 수 있다. 실시 예에서, 프로세서는 화질 처리를 위한 제어 정보를 획득할 수 있다. 실시 예에서, 프로세서는 객체 정보 및 제어 정보를 기반으로, 중요 객체에 대한 화질 처리를 수행하여 화 질 처리된 영상을 획득할 수 있다. 실시 예에서, 프로세서는, 뉴럴 네트워크를 이용하여, 제1 영상, 제어 정보, 및 객체 정보 중 적어도 하나 로부터, 중요 객체를 화질 처리할 수 있다. 실시 예에서, 뉴럴 네트워크는 중요 객체의 업스케일링, 중요 객체 주위의 윤곽선 처리, 및 중요 객체 내부 평 탄화 처리 중 적어도 하나를 수행할 수 있다. 도 3은 실시 예에 따라, 사용자가 영상 처리 장치를 이용하여 시각 장애 정보를 입력하는 것을 설명하기 위한 도면이다. 실시 예에서, 영상 처리 장치는 시청 보조 기능을 제공하기 위해서 사용자의 시각 장애 정도를 미리 파악 할 수 있다. 영상 처리 장치가 뉴럴 네트워크를 이용하여 추론 제어 정보를 획득하는 경우, 뉴럴 네트워크 는 사용자의 인터랙션 히스토리를 파악하기까지 시간이 소요된다. 즉, 뉴럴 네트워크가 학습을 통해 최적화된 모델이 되기까지는 신뢰도 있는 제어 정보를 추론하지 못하게 된다. 따라서, 영상 처리 장치는 사용자로부 터 입력된 시각 장애 정보를 기반으로 학습 모델을 더 빨리 학습 시킴으로써 보다 신뢰도 있는 추론 제어 정보 를 빠른 시간 안에 획득할 수 있다. 실시 예에서, 영상 처리 장치는 사용자의 시각 장애 정도를 파악하기 위해, 시각 장애가 있는 사용자에게 시각 장애 정보를 직접 입력하게 할 수 있다. 또는, 실시 예에서, 영상 처리 장치는 사용자에게 예시 화면을 제공하여 사용자가 선호하는 예시를 선택하 게 함으로써 사용자의 시각 장애 수준을 파악할 수도 있다. 실시 예에서, 사용자가 시청 보조 기능을 활성화한 것을 선택하면, 영상 처리 장치는 사용자의 시각 장애 정도를 파악하기 위해, 사용자에게 다양한 영상을 보여줄 수 있다. 사용자는 영상 처리 장치가 제공하는 다양한 기능이 적용된 효과 영상을 보면서 사용자 인터랙션을 제공할 수 있다. 예컨대, 사용자는 객체의 크기, 윤곽선 처리, 평탄화 처리 등에 대해 사용자가 선호하는 화질 처리에 대한 정보를 입력할 수 있다. 도 3a는 영상 처리 장치가 제1 기본 영상 및 제1 기본 영상에 포함된 객체에 대해 윤곽선을 처 리하여 생성한 복수 영상들(301, 303, 305)을 출력한 것을 도시한다. 실시 예에서, 영상 처리 장치는 제1 기본 영상에 포함된 객체의 윤곽선에 대해, 윤곽선의 보존 여부, 객체 내부의 텍스처(texture)의 처리 여부, 노이즈 제거 여부, 윤곽선의 강도, 윤곽선의 디테일 정도 등에 따라, 기본 영상에 포함된 객체의 윤곽선을 다양하게 변형할 수 있다. 윤곽선의 강도는 윤곽선의 두꺼운 정도나 진한 정도를 의미할 수 있다. 사용자는 도 3a에 도시된 복수 영상들(301, 303, 305)을 보고, 이 중 인지하기 용이하거나 또는 사용자가 선호 하는 윤곽선을 가진 영상을 선택할 수 있다. 영상 처리 장치는 사용자가 선택한 영상에 대해 수행된 윤곽선 처리에 대한 정보를 저장하고, 이를 추론 제어 정보로 이용하여, 향후 영상에 포함된 객체에 대한 윤곽선 처리 시 이용할 수 있다. 시각 장애가 있는 사용자는 영상에 포함된 미세한 디테일보다 객체의 윤곽선이나 객체의 형체만 보존되는 것을 더 선호하는 경향이 있다. 실시 예에서, 영상 처리 장치는 사용자로부터 객체 내부의 디테일함을 없애는정도, 즉, 평탄화 정도를 선택 받을 수 있다. 객체 내부를 평탄화한다는 것은 객체 내부의 텍스처나 디테일한 표현을 제거하여 객체 내부가 블러링(blurring)해지거나 뭉개지도록 하는 것을 의미할 수 있다. 평탄화 정도가 크다는 것은 텍스처나 디테일한 표현이 더 많이 제거되어 객체 내부가 더 많이 뭉개진 것을 의미할 수 있다. 영상 처리 장치는 사용자가 선택한 평탄화 정도에 따라 제2 기본 영상에 대해 평탄화 처리를 수행하 고, 그 결과 영상을 사용자에게 출력할 수 있다. 도 3b는 영상 처리 장치가 제2 기본 영상 및 제2 기본 영상에 포함된 객체에 대해 사용자가 선 택한 평탄화 정도에 따라 평탄화 처리를 수행한 영상을 출력한 것을 도시한다. 도 3b를 참조하면, 제2 기본 영상과 달리, 평탄화 처리를 수행한 영상은 꽃잎 내부의 텍스쳐나 무늬 가 제거된 것을 알 수 있다. 사용자는 평탄화 처리를 수행한 영상을 보고, 평탄화 정도를 컨펌하거나, 또는 평탄화 정도를 다시 선택할 수 있다. 영상 처리 장치는 사용자가 평탄화 정도를 다시 선택할 경우, 사용자가 선택한 평탄화 정도에 따 라 제2 기본 영상에 대해 다시 평탄화 처리를 수행하고, 결과 영상을 사용자에게 출력할 수 있다. 영상 처리 장치는 사용자가 선택한 평탄화 정도에 대한 정보를 저장하고, 이를 추론 제어 정보로 이용할 수 있다. 영상 처리 장치는 향후 영상을 화질 처리 할 때, 사용자가 선택한 평탄화 정도에 대한 정보를 이 용하여 영상에 포함된 객체에 대해 평탄화를 수행할 수 있다. 도 3에는 도시하지 않았으나, 실시 예에서, 영상 처리 장치는 기본 영상에 포함된 중요 객체를 어느 정도 의 크기로 확대할지를 사용자로부터 선택 받을 수 있다. 영상 처리 장치는 사용자가 선택한 확대 정도에 대한 정보를 저장하고, 이를 추론 제어 정보로 이용하여, 향후 영상에 포함된 중요 객체를 화질 처리할 때 사용 자가 선택한 크기로 중요 객체를 업스케일링할 수 있다. 이와 같이, 실시 예에 의하면, 영상 처리 장치는 사용자로부터 시각 장애 정도나 선호도를 입력 받고, 사 용자로부터 입력된 정보를 기반으로 제어 정보를 생성할 수 있다. 도 4는 실시 예에 따른 도 2의 프로세서의 내부 블록도이다. 도 4를 참조하면, 프로세서는 객체 정보 획득부, 제어 정보 획득부 및 화질 처리부를 포함 할 수 있다. 실시 예에서, 객체 정보 획득부, 제어 정보 획득부 및 화질 처리부는 모듈 형태로 프로세서 에 포함될 수 있다. 모듈이라 함은, 본 개시의 기술적 사상을 수행하기 위한 하드웨어 및 상기 하드웨어를 구동하기 위한 소프트웨어의 기능적, 구조적 결합을 의미할 수 있다. 예컨대, 모듈은 소정의 코드와 소정의 코 드가 수행되기 위한 하드웨어 리소스의 논리적인 단위를 의미할 수 있으며, 반드시 물리적으로 연결된 코드를 의미하거나, 한 종류의 하드웨어로 한정되지 않는다. 실시 예에서, 객체 정보 획득부는 입력 영상을 분석하여 객체를 검출하고, 객체에 대한 객체 정보를 획득 할 수 있다. 실시 예에서, 객체 정보는 중요 객체의 종류, 위치, 및 크기 중 적어도 하나에 대한 정보를 포함할 수 있다. 중요 객체는 관심 대상이 되는 객체이므로, 주로 사용자의 주의를 끄는 관심 영역에 위치할 수 있다. 관심 영역 은 사용자의 시각 특성 등에 따라 달라질 수 있다. 예컨대, 사람은 일반적으로 화면의 중앙 부분을 가장자리 부 분보다 더 많이 보는 경향이 있기 때문에 통상 화면의 중앙 부분이 관심 영역이 될 수 있다. 또한, 사람은 일반 적으로 전경(foreground)에 위치한 객체를 배경(background)에 위치한 객체보다 중요하게 여기는 경향이 있다. 또한, 사람은 정지된 물체보다 움직임이 큰 물체에 더 집중하는 경향이 있다. 실시 예에서, 객체 정보 획득부는 입력 영상의 가운데 영역에 위치한 객체를 중요 객체로 식별할 수 있다. 실시 예에서, 객체 정보 획득부는 전경의 객체를 배경의 객체보다 중요 객체로 식별할 수 있다. 실시 예에서, 객체 정보 획득부는 복수의 프레임들을 기반으로 객체가 움직이는 지 여부를 고려하여, 정지 된 객체보다 움직임이 큰 객체를 중요 객체로 식별할 수 있다. 입력 영상에 객체가 하나만 포함되어 있는 경우, 객체 정보 획득부는 하나의 객체를 중요 객체로 식별할 수 있다. 입력 영상에 복수개의 객체가 포함되어 있는 경우, 객체 정보 획득부는 복수개의 객체 중에서 중요 객체를 식별할 수 있다. 중요 객체는 입력 영상에 포함된 복수개의 객체들 중에 일부일 수 있다. 중요 객체는 하나일 수도 있으나, 이에 한정되는 것은 아니며, 영상의 종류나 특성, 사용자의 선택 등에 따라 복수개가 될 수도 있 다. 관심 영역은 영상의 종류에 따라 달라질 수 있다. 실시 예에서, 객체 정보 획득부는 입력 영상을 분석하여 입력 영상의 장르를 식별할 수 있다. 실시 예에서, 객체 정보 획득부는 입력 영상의 장르에 따라 관심 영 역을 다르게 식별할 수 있다. 예컨대, 영상이 드라마나 영화와 같은 장르인 경우, 사용자는 주인공이나 또는 현재의 발화자를 관심있게 보는 경향이 있으므로, 주인공 또는 발화자가 중요 객체일 수 있다. 또한, 영상에 사람이 나오는 경우, 사람은 영상 에 포함된 사람의 얼굴 형체를 인지하고자 하는 욕구가 크기 때문에 얼굴 영역을 관심 영역으로 식별할 수 있다. 실시 예에서, 객체 정보 획득부는 입력 영상이 영화나 드라마인 경우, 입력 영상에 가장 많이 나오는 인물 을 중요 객체로 식별할 수 있다. 또는, 실시 예에서, 객체 정보 획득부는 영상에 포함된 객체의 움직임, 예컨대, 얼굴에 포함된 입술의 움직임으로부터 발화자를 식별하고, 발화자를 중요 객체로 식별할 수 있다. 입력 영상이 뉴스인 경우, 사용자는 보통 뉴스 화면 하단에 표시되는 자막을 주의 깊게 보는 경향이 있다. 따라 서, 실시 예에서, 객체 정보 획득부는 입력 영상의 장르가 뉴스이거나, 입력 영상에 자막이 포함되어 있는 경우, 화면의 하단 영역이나, 자막이 포함된 영역을 관심 영역으로 식별하고, 관심 영역에 포함된 문자를 중요 객체로 식별할 수 있다. 실시 예에서, 객체 정보 획득부는 중요 객체의 유형이나 객체가 속한 부류가 무엇인지에 대한 정보를 객체 정보로 획득할 수 있다. 실시 예에서, 객체 정보는 중요 객체의 위치에 대한 정보를 포함할 수 있다. 예컨대, 객체 정보는 중요 객체가 화면 중앙에 위치하는지, 화면 하단에 위치하는지, 또는 화면의 우측 상단에 위치하는 지 등에 대한 정보를 포 함할 수 있다. 중요 객체의 위치는 화면 내의 좌표 값 등으로 획득될 수 있다. 실시 예에서, 객체 정보는 중요 객체의 크기에 대한 정보를 포함할 수 있다. 중요 객체의 크기는 영상에서 중요 객체가 차지하는 비중이나 중요 객체의 가로, 세로 길이, 또는 대각선 길이나 지름(diameter)의 길이 등을 의미 할 수 있다. 실시 예에서, 객체 정보 획득부는 객체 정보를 제어 정보 획득부 및 화질 처리부로 전송할 수 있다. 실시 예에서, 제어 정보 획득부는 제어 정보를 획득할 수 있다. 실시 예에서, 제어 정보는 추론 제어 정보 및 실시간 사용자 제어 정보 중 적어도 하나를 포함할 수 있다. 실시 예에서, 추론 제어 정보는 시각 장애가 있는 사람들이나 또는 사용자의 성향을 고려하여 추론한 제어 정보 를 의미할 수 있다. 추론 제어 정보는 시각 장애가 있는 사람들, 및/또는 사용자의 성향에 따라 현재 화면에 출 력할 영상에 포함된 중요 객체에 대해 어떻게 화질 처리를 수행할 것인가를 추론하여 획득한 제어 정보일 수 있 다. 실시 예에서, 제어 정보 획득부는 시각 장애가 있는 사람들의 인지 특성이나 선호도를 기반으로 추론 제어 정보를 획득할 수 있다. 예컨대, 제어 정보 획득부는 시각 장애가 있는 사람들의 인지 특성에 대한 정보를 미리 저장하고 있을 수 있다. 제어 정보 획득부는 기 저장된 시각 장애인의 인지 특성에 대한 정보를 기반 으로, 현재 화면에 출력할 입력 영상에 대한 제어 정보를 추론할 수 있다. 시각 장애가 있는 사람들은 시각 장애가 없는 일반 사람들이 갖고 있는 일반적인 시각 특성 외에도 시각 장애인 특유의 시각 특성을 가지고 있을 수 있다. 예컨대, 시각 장애가 있는 사람들은 영상 전체의 세밀함에 치중하지 않고 영상 내에서 사물의 전체적인 윤곽선이나 사물 내의 성분을 인지하는 것에 집중하는 경향이 있다. 또한, 시각 장애가 있는 사람들은 영상 전체를 함께 보는 것보다는 특정 객체만을 더 크게 보고 싶어하는 경향이 있다. 또한, 시각 장애가 있는 사람들은 색 대비가 큰 객체를 더 관심 있게 보는 경향이 있다. 예컨대, 녹색 잔 디밭 위에 빨간 단풍잎이 떨어져 있는 영상이 있는 경우, 시각 장애가 있는 사람들은 색 대비가 큰 객체를 보다 자세히 보고 싶어하는 욕구가 크다. 따라서, 제어 정보 획득부는 시각 장애가 있는 사람들이 선호하는 제어 정보를 추론 제어 정보로 획득할 수 있다. 실시 예에서, 제어 정보 획득부는 사용자의 인터랙션 히스토리로부터 추론 제어 정보를 획득할 수도 있다. 사용자는 일반적인 시각 장애가 있는 사람들과는 일정 부분 다른 취향이나 선호도를 가질 수 있다. 일반적으로, 시각 장애가 있는 사용자는 영상 처리 장치를 사용자 혼자 단독으로 사용하는 경우가 많다. 즉, 시각 장애 가 있는 사용자는 영상 처리 장치를 개인화된 기기로 이용하는 경우가 많다. 따라서, 영상 처리 장치(10 0)는 사용자가 객체에 대한 화질 처리를 위해 입력한 제어 명령 이력을 기반으로 사용자의 선호도나 취향을 추 론할 수 있다. 제어 정보 획득부는 사용자의 제어 이력을 영상과 연계하여, 어떤 영상이 출력되었을 때 사용자가 어떤 제 어 명령을 했는지에 대한 정보를 누적하고, 이로부터 사용자의 선호도나 취향을 추론할 수 있다. 제어 정보 획 득부는 복수의 프레임들이나 복수의 비디오에 대해 입력된 사용자의 과거 제어 명령 이력을 시계열적으로 누적하여 사용자 제어 명령의 패턴을 식별하고, 이로부터 사용자의 선호도나 취향을 추론할 수 있다. 제어 정보 획득부는 통상의 시각 장애가 있는 사람들의 인지 특성 및 선호도와 함께, 사용자의 제어 이력 을 함께 고려하여, 중요 객체에 대한 화질 처리 명령을 추론할 수 있다. 또는, 제어 정보 획득부는 통상의 시각 장애가 있는 사람들의 인지 특성은 배제하고, 사용자의 제어 이력만을 고려하여, 중요 객체에 대한 화질 처리 명령을 추론할 수 있다. 또는 실시 예에서, 제어 정보 획득부는 사용자가 영상 처리 장치를 이용하여 미리 입력한, 사용자 선 호도에 대한 정보를 기반으로 추론 제어 정보를 획득할 수도 있다. 사용자는 영상 처리 장치를 이용하여 사용자의 시각 장애 정도나, 사용자가 선호하는 화질 처리 정도에 대한 정보를 미리 입력할 수 있다. 영상 처리 장치는 사용자가 미리 입력한 사용자 선호도에 대한 정보로부터, 현재 영상에 대해 적용할 제어 정보를 추 론하여, 추론 제어 정보를 획득할 수 있다. 실시 예에서, 제어 정보 획득부는 사용자로부터 실시간 사용자 제어 정보를 입력 받을 수 있다. 실시간 사 용자 제어 정보는 현재 화면에 출력되는 입력 영상에 대한 사용자의 실시간 제어 정보를 의미할 수 있다. 제어 정보 획득부는 사용자로부터 입력된 실시간 사용자 제어 정보를 이용하여 기 저장된 제어 정보를 업데이트 할 수 있다. 실시 예에서, 제어 정보 획득부는 업데이트된 제어 정보를 화질 처리부로 전송할 수 있 다. 실시 예에서, 화질 처리부는 객체 정보 획득부로부터 객체 정보를 수신하고, 제어 정보 획득부 로부터 제어 정보를 수신할 수 있다. 실시 예에서, 화질 처리부는 객체 정보 및 제어 정보를 기반으로, 중요 객체에 대한 화질 처리를 수행하여 제2 영상을 획득할 수 있다. 실시 예에서, 화질 처리부는 중요 객체의 윤곽선 처리를 수행할 수 있다. 중요 객체의 윤곽선 처리는 윤곽 선의 디테일, 윤곽선의 강도, 윤곽선의 색상, 윤곽선과 다른 영역 간의 대비 정도 중 적어도 하나에 대한 처리 를 수행하는 것을 포함할 수 있다. 실시 예에서, 화질 처리부는 중요 객체 내부의 평탄화 처리를 수행할 수 있다. 평탄화 처리는 중요 객체의 윤곽선을 제외한 중요 객체 내부 영역의 평탄화 정도를 조절하는 처리를 포함할 수 있다. 실시 예에서, 화질 처리부는 중요 객체를 업스케일링할 수 있다. 화질 처리부는 중요 객체의 크기를 늘릴 뿐 아니라, 중요 객체에 대해 선명도 처리를 함께 수행할 수 있다. 즉, 화질 처리부는 중요 객체에 대한 업스케일링을 통해 중요 객체의 크기를 확대하면서 동시에 해상도도 향상되도록 할 수 있다. 실시 예에서, 화질 처리부는 객체 정보로부터 획득된 중요 객체의 장르, 위치, 크기에 대한 정보를 기반으 로, 화질 처리를 수행할 대상을 식별하고, 식별된 영역에 제어 정보를 정합하여, 제어 정보에 맞게 식별된 영역 을 화질 처리할 수 있다. 예컨대, 화질 처리부는 중요 객체가 자막이고, 자막의 위치가 화면 하단이고, 자막의 크기가 영상에서 어 느 정도를 차지하는지에 대한 정보를 획득할 수 있다. 화질 처리부는 제어 정보로부터 획득된 화질 처리에 대한 제어 명령을 기반으로, 자막 영역을 식별하고, 자막 영역에 대해 화질 처리를 수행할 수 있다. 예컨대, 화 질 처리부는 자막의 위치를 찾고, 자막이 포함된 영역을 크롭핑하고, 크로핑된 영역을 소정 크기로 업스케 일링할 수 있다. 화질 처리부는 자막의 테두리는 사용자가 선호하는 색상인 보라색으로, 일정 강도 이상으로 두껍고 진하게 표시하는 처리를 수행함으로써, 중요 객체에 대한 화질 처리를 수행할 수 있다. 도 5는 실시 예에 따라, 객체 정보 획득부가 입력 영상으로부터 객체 정보를 획득하는 것을 설명하기 위한 도면이다. 실시 예에서, 객체 정보 획득부는 입력 영상으로부터 객체 정보를 획득하는 기능을 수행할 수 있는 적절한 로직, 회로, 인터페이스, 및/또는 코드를 포함할 수 있다. 실시 예에서, 객체 정보 획득부는 룰 기반으로(rule based) 입력 영상을 분석하여 입력 영상에 포함된 객체에 대한 객체 정보를 획득할 수 있다. 영상 처리 장치의 데이터 처리 성능이나 운영 체제, CPU 처리 속도 등이, 많은 연산량을 빠른 시간 안에 수행하기 어려운 장치인 경우, 객체 정보 획득부는 룰 기반으로 입력 영상을 분석하 여 입력 영상으로부터 객체 정보를 획득하도록 설계될 수 있다. 또는, 실시 예에서, 객체 정보 획득부는 뉴럴 네트워크를 이용하여 입력 영상으로부터 객체 정보 를 획득할 수도 있다. 실시 예에서, 객체 정보 획득부에 포함된 뉴럴 네트워크를 제1 뉴럴 네트워크 로 호칭하기로 한다. 실시 예에서, 제1 뉴럴 네트워크는 2개 이상의 히든 레이어들을 포함하는 딥 뉴럴 네트워크(DNN)일 수 있 다. 제1 뉴럴 네트워크는 입력 데이터를 받고, 입력된 데이터가 히든 레이어들을 통과하여 처리됨으로써, 처리된 데이터가 출력되는 구조를 포함할 수 있다. 도 5에서는 제1 뉴럴 네트워크의 숨은 층(hidden layer)이 2개의 심도(depth)를 가지는 딥 뉴럴 네트워크 (DNN)인 경우를 예로 들어 도시하였다. 객체 정보 획득부는 제1 뉴럴 네트워크를 통한 연산을 수행하여 입력 영상을 분석할 수 있다. 제1 뉴럴 네트워크는 학습 데이터를 통한 학습을 수행할 수 있다. 여기서, 제1 뉴럴 네트워크는 모델 의 구현 방식이나 결과의 정확도, 결과의 신뢰도, 프로세서의 연산 처리 속도 및 용량 등에 따라 매우 다양하게 설계될 수 있다. 제1 뉴럴 네트워크는 입력 계층, 숨은 계층(hidden layer) 및 출력 계층을 포함 하여, 장 르 결정 및 객체 검출을 위한 연산을 수행할 수 있다. 제1 뉴럴 네트워크는 입력 계층과 제1 숨은 계 층(HIDDEN LAYER1) 간에 형성되는 제1 계층(Layer 1), 제1 숨은 계층(HIDDEN LAYER1)과 제2 숨은 계층 (HIDDEN LAYER2) 간에 형성되는 제2 계층(Layer 2), 및 제2 숨은 계층(HIDDEN LAYER2)과 출력 계층 (OUTPUT LAYER) 간에 형성되는 제3 계층(Layer 3)으로 형성될 수 있다. 제1 뉴럴 네트워크를 형성하는 복수개의 계층들 각각은 하나 이상의 노드를 포함할 수 있다. 예를 들어, 입력 계층은 데이터를 수신하는 하나 이상의 노드(node)들을 포함할 수 있다. 도 5에서는 입력 계층 이 복수개의 노드들을 포함하는 경우를 예로 들어 도시하였다. 그리고, 복수개의 노드로 입력 영상 이 입력될 수 있다. 여기서, 인접한 두 개의 계층들은 도시된 바와 같이 복수개의 엣지(edge)들(예를 들어, 540)로 연결된다. 각각의 노드들은 대응되는 가중치값을 가지고 있어서, 제1 뉴럴 네트워크는 입력 된 신호와 가중치 값을 연산, 예를 들어, 곱하기 연산한 값에 근거하여, 출력 데이터를 획득할 수 있다. 제1 뉴럴 네트워크는 복수의 학습 데이터에 근거하여 학습되어, 입력 영상으로부터 객체 정보를 추론하는 모델로서 구축될 수 있다. 실시 예에서, 제1 뉴럴 네트워크는 지도형 학습(supervised learning) 방법으로 소정의 데이터셋 (dataset)을 학습하여 훈련된 뉴럴 네트워크일 수 있다. 뉴럴 네트워크는 학습한 데이터셋과 같거나 유사한 객 체 정보 영역을 검출하도록 훈련될 수 있다. 실시 예에서, 제1 뉴럴 네트워크는 복수의 학습 데이터를 입력 값으로 하여 입력 데이터를 분석 및 분류하 여 특징을 추출하는 알고리즘일 수 있다. 제1 뉴럴 네트워크는 입력된 데이터로부터 객체 정보를 추출하도 록 학습된 모델일 수 있다. 이를 위해, 제1 뉴럴 네트워크는 영상에서 중요 객체를 검출하는 방법을 학습 할 수 있다. 제1 뉴럴 네트워크는 다양한 장르의 영상 및 각 영상의 레이블, 각 영상에 포함된 중요 객체 의 종류나 위치, 크기를 학습 데이터 셋으로 이용하여 훈련될 수 있다. 실시 예에서, 제1 뉴럴 네트워크는 영상에서 사람들이 중요하게 여기는 객체를 분석하고, 그 객체의 종류 를 분석할 수 있다. 보다 구체적으로, 제1 뉴럴 네트워크는 영상에서 시각 장애가 있는 사람들이 강조 기 능을 활용한 중요 객체에 대한 정보 및 그 객체의 종류를 학습 데이터로 훈련할 수 있다. 실시 예에서, 제1 뉴럴 네트워크는 관심 영역을 찾기 위해, 세일리언시 데이터 셋(saliency dataset)을 학 습할 수 있다. 세일리언시 데이터 셋은 세일리언시 맵으로도 호칭될 수 있다. 세일리언시 맵은 사람들의 관심을 끄는 세일리언시 영역을 다른 영역과 구별하여 표현하는 맵을 의미할 수 있다. 실시 예에서, 제1 뉴럴 네트워크 는 시각 장애가 있는 사람들이 주로 관심을 갖는 세일리언시 영역에 대한 정보를 학습할 수 있다. 세일리 언시 영역은 비디오 프레임에서 시각 장애가 있는 사람들의 관심을 끄는 영역, 즉, 시각적 집중도가 높은 영역 을 나타낼 수 있다. 예컨대, 제1 뉴럴 네트워크는 시각 장애가 있는 사람들의 시선을 추적하여 얻어진 세 일리언시 영역을 미리 학습한 모델일 수 있다. 제1 뉴럴 네트워크는 입력된 비디오 프레임에 포함된 픽셀 들 각각 또는 유사한 특징을 갖는 복수 픽셀들을 포함하는 픽셀 그룹의 색 변화나 분포, 엣지(edges), 공간 주 파수, 구조, 분포, 히스토그램, 텍스쳐(texture) 등을 고려하여 입력된 비디오 프레임에 대한 세일리언시 맵을 획득하도록 학습될 수 있다. 실시 예에서, 제1 뉴럴 네트워크는 세일리언시 맵 영역에 높은 웨이트를 부여 함으로써 중요 객체에 대한 객체 정보를 획득할 수 있다. 실시 예에서, 제1 뉴럴 네트워크는 세일리언시 데이터 셋 외에도, 세그멘테이션 데이터 셋(segmentation dataset)을 학습 데이터로 학습할 수 있다. 제1 뉴럴 네트워크는 객체의 시맨틱(semantic) 정보를 고려하 여, 영상에 포함된 중요 객체의 종류를 식별할 수 있다. 제1 뉴럴 네트워크는 중요 객체의 종류에 따라 다 른 웨이트를 부여함으로써 중요 객체에 대한 객체 정보를 획득할 수 있다. 또한, 제1 뉴럴 네트워크는 이미지 이해 데이터 셋(image understanding dataset)을 학습 데이터로 이용 하여 훈련될 수 있다. 제1 뉴럴 네트워크는 객체나 객체의 영역을 해석하여 객체가 무엇인지, 또한, 객체 간의 공간적 관계가 어떠한지 등을 학습할 수 있다. 제1 뉴럴 네트워크는 이미지 이해 데이터 셋에 따라 중요 객체에 대한 객체 정보를 획득할 수 있다. 실시 예에서, 제1 뉴럴 네트워크는 영상과 각 영상의 레이블, 시각 장애가 있는 사람들이 화질 처리, 예컨 대, 강조 기능을 활용한 영상인지 여부에 대한 정보, 영상에서 화질 처리된, 예컨대, 강조된 오브젝트에 대한 정보 등을 학습할 수 있다. 실시 예에서, 제1 뉴럴 네트워크는 시각 장애가 있는 사람들이 강조 기능을 활 용한 영상 및 그 영상에서 화질 처리된 객체에 대한 객체 정보간의 관련성을 학습하고, 영상으로부터 객체 정보 를 획득하도록 훈련될 수 있다. 실시 예에서, 제1 뉴럴 네트워크는 시각 장애가 있는 사람들이 화질 처리를 수행한 객체의 종류나 그러한 객체가 포함된 영역을 정답 셋으로 이용하여 훈련될 수 있다. 제1 뉴럴 네트워크는 입력 영상으로부터 객 체의 종류나 위치, 크기를 추론/예측하고, 예측한 결과가 정답 셋과 같아지도록 반복하여 훈련될 수 있다. 구체적으로, 제1 뉴럴 네트워크를 통하여 출력되는 결과의 정확도를 높이기 위해서, 복수의 학습 데이터에 근거하여 출력 계층에서 입력 계층 방향으로 학습(training)을 반복적으로 수행하며 출력 결과의 정 확도가 높아지도록 가중치 값들을 수정할 수 있다. 그리고, 최종적으로 수정된 가중치 값들을 가지는 제1 뉴럴 네트워크는 객체 정보를 모델로 이용될 수 있 다. 구체적으로, 제1 뉴럴 네트워크는 입력 데이터인 입력 영상에 포함되는 정보를 분석하여 객체 정 보를 결과로 출력할 수 있다. 학습이 끝난 제1 뉴럴 네트워크는 객체 정보 획득부에 장착되어, 입력 영상으로부터 객체 정보 를 획득하는 데 이용될 수 있다. 제1 뉴럴 네트워크는 입력 영상이 입력되면, 그로부터 입력 영 상의 레이블 및 입력 영상에 포함된 중요 객체를 검출하고, 중요 객체의 종류, 위치, 크기 중 적어도 하나에 대한 정보를 포함하는 객체 정보를 획득할 수 있다. 실시 예에서, 객체 정보 획득부는 제1 뉴럴 네트워크를 이용하여 획득한 객체 정보를 제어 정보 획득 부 및 화질 처리부로 전송할 수 있다. 실시 예에서, 객체 정보 획득부가 제어 정보 획득부로 전송하는 객체 정보와 화질 처리부로 전 송하는 객체 정보는 서로 다를 수 있다. 객체 정보 획득부가 제어 정보 획득부로 전송하는 객체 정보 를 제1 객체 정보라고 하면, 제1 객체 정보는 입력 영상, 즉, 하나의 프레임으로부터 획득되는 정보일 수 있다. 제어 정보 획득부는 영상의 장르와 사용자 제어 명령 간의 연관성으로부터 제어 정보를 획득하기 때 문에, 객체 정보 획득부는 제어 정보 획득부로 각 프레임에서 획득된 프레임의 장르에 대한 정보만을 전송할 수 있다. 예컨대, 제1 객체 정보는 입력 영상의 장르에 대한 정보, 예컨대, 입력 영상이 뉴스 인지, 드라마인지 등에 대한 정보만을 포함할 수 있다. 실시 예에서, 객체 정보 획득부가 화질 처리부로 전송하는 객체 정보를 제2 객체 정보라고 하면, 제2 객체 정보는 입력 영상뿐 아니라, 입력 영상이 포함된 복수 프레임이나 비디오를 분석하여 획득된 정 보를 포함할 수 있다. 제2 정보는 입력 영상의 장르에 따라 식별된 관심 영역 내의 중요 객체의 장르 및 중요 객체의 위치, 크기에 대한 정보를 포함할 수 있다. 화질 처리부는 입력 영상에 포함된 중요 객 체에 대해 화질 처리를 하기 때문에, 중요 객체의 종류, 위치, 크기 등과 같은 정보가 필요하다. 따라서, 실시 예에서, 객체 정보 획득부는 입력 영상이 포함된 비디오를 분석하여, 그로부터 중요 객체에 대한 객 체 정보를 획득하고, 이를 화질 처리부로 전송할 수 있다. 예컨대, 입력 영상의 장르가 뉴스인 경우, 제2 객체 정보는 중요 객체의 장르가 자막이라는 정보, 입력 영상에서 자막의 위치가 어디인지에 대한 정 보, 자막의 크기가 얼마인지에 대한 정보 등을 포함할 수 있다. 다만, 이는 하나의 실시 예로, 객체 정보 획득부가 제어 정보 획득부로 전송하는 객체 정보와 화질 처리부로 전송하는 객체 정보는 서로 동일한 정보일 수도 있다. 예컨대, 객체 정보 획득부는 제어 정 보 획득부와 화질 처리부 모두에게, 영상의 장르 및 객체 정보, 즉, 객체의 종류나 위치, 크기에 대 한 정보를 전송할 수 있다. 도 6은 실시 예에 따라, 제어 정보 획득부가 추론 제어 정보를 획득하는 것을 설명하기 위한 도면이다. 실시 예에서, 제어 정보 획득부는 입력 데이터로부터 추론 제어 정보를 획득하는 기능을 수행할 수 있는 적절한 로직, 회로, 인터페이스, 및/또는 코드를 포함할 수 있다. 실시 예에서, 제어 정보 획득부는 다양한 알고리즘을 이용하여 사용자 제어 정보 및 입력 영상에 대한 객 체 정보로부터, 입력 영상에 대한 제어 정보를 추론할 수 있다. 실시 예에서, 제어 정보 획득부는 프로그램이나 인스트럭션과 같은 룰 기반으로 제어 정보를 추론하거나, 뉴럴 네트워크를 이용하여 추론 제어 정보를 획득할 수 있다. 실시 예에서, 도 6은, 제어 정보 획득부가 뉴럴 네트워크를 이용하여 추론 제어 정보를 획득하는 경우를 도시한다. 제어 정보 획득부에 포함된 뉴럴 네트워크를 제2 뉴럴 네트워크로 호칭하면, 실시 예에서, 제2 뉴럴 네트워크는 중요 객체에 대한 사용자의 인터랙션 히스토리를 학습할 수 있다. 실시 예에서, 제2 뉴럴 네트워크는 RNN으로 구현될 수 있다. 실시 예에서, 제2 뉴럴 네트워크는 시각 장애가 있는 사람들이 특정 영상에 대해 주로 이용한 화질 처리에 대한 정보를 학습할 수 있다. 제2 뉴럴 네트워크는 시각 장애가 있는 사람들이 영상에 대해 화질 처리와 관련하여 입력한 제어 명령의 종류, 제어 정도, 제어 빈도 등을 학습 데이터로 이용하여 훈련할 수 있다. 제2 뉴럴 네트워크가 기존의 일반적인 시각 장애인의 데이터를 학습한 상태에서, 영상 처리 장치의 사용 자가 영상에 대해 화질 처리와 관련하여 입력한 제어 명령의 종류, 제어 정도, 제어 빈도 등을 추가로 학습하는 경우, 제2 뉴럴 네트워크는 준지도형 학습(semi-supervised learning) 알고리즘일 수 있다. 또는, 다른 실시 예에서, 제2 뉴럴 네트워크는 영상 처리 장치의 사용자가 영상에 대해 화질 처리와 관련하여 입력한 제어 명령의 종류, 제어 정도, 제어 빈도 등 만을 학습할 수 있다. 이 경우, 제2 뉴럴 네트워 크는 사용자만의 인터랙션 히스토리를 가지고 사용자의 패턴을 학습하는 비지도형 학습(unsupervised learning) 알고리즘일 수 있다. 실시 예에서, 사용자의 인터랙션 히스토리는 중요 객체에 대한 윤곽선 처리, 평탄화 처리, 업스케일링 처리 중 적어도 하나에 대한 제어 정보 히스토리를 포함할 수 있다. 사용자의 인터랙션은 리모컨이나 영상 처리 장치 에 구비된 키패드 등의 사용자 인터페이스를 통해 입력될 수 있다. 실시 예에서, 제2 뉴럴 네트워크는 사용자 인터랙션 히스토리를 축적하고, 이로부터 사용자의 선호도나 습 관, 사용 패턴 등을 학습할 수 있다. 사용자 인터랙션 히스토리는 사용자가 화질 처리를 선택한 영상의 종류, 그 영상에서 화질 처리 대상이 된 객체의 종류, 객체의 크기, 객체의 위치, 및 사용자가 선택한 화질 처리의 종 류나 정도, 화질 처리 기능을 이용한 시점에 대한 정보 중 적어도 하나에 대한 히스토리를 포함할 수 있다. 사용자가 선택한 화질 처리의 종류나 정도는 사용자가 요청한 객체의 윤곽선 두께나 디테일 정도, 윤곽선의 색 상, 객체 내부의 평탄화 정도 등에 대한 정보, 객체를 어느 크기로 확대했는지 여부 등에 대한 정보 등을 포함 할 수 있다. 화질 처리 기능을 이용한 시점에 대한 정보는 사용자가 비디오 재생 전에 화질 처리 기능을 이용했 는지, 또는 비디오가 재생된 후, 일정 시점 경과 후, 또는 특정한 영상이 출력될 때만 화질 처리 기능을 이용했는지 여부 등과 같은 정보를 포함할 수 있다. 실시 예에서, 제2 뉴럴 네트워크는 사용자가 새로 제어 명령을 입력한 경우, 사용자의 제어 명령을 추가로 학습할 수 있다. 실시 예에서, 제2 뉴럴 네트워크는 객체 정보 획득부로부터 입력 영상에 대한 객체 정보를 수신할 수 있다. 입력 영상에 대한 객체 정보는 입력 영상의 종류에 대한 정보를 포함할 수 있다. 실시 예에서, 제2 뉴럴 네트워크는 해당 영상에 대한 사용자 제어 정보를 입력 받을 수 있다. 실시 예에서, 제2 뉴럴 네트워크는 입력 영상에 대한 객체 정보로부터, 입력 영상의 종류를 파악하고, 그 입력 영상에 대한 사용자 제어 정보를 이용하여, 사용자가 그 입력 영상에 대해 화질 처리 기능을 이용했는지 여부, 입력 영상에 대해 사용자가 어떤 제어 명령을 했는지에 대한 정보를 학습할 수 있다. 실시 예에서, 제2 뉴럴 네트워크는 사용자 인터랙션 히스토리를 통계적으로 학습하여 획득한 사용 패턴으 로부터 추론 제어 정보를 출력할 수 있다. 추론 제어 정보는 사용자의 인터랙션 히스토리를 기반으로, 현재 영 상에 대해 어떤 화질 처리를 수행할 것인지를 추론한 제어 정보일 수 있다. 제2 뉴럴 네트워크로부터 획득 된 제어 정보는 화질 처리부로 전송될 수 있다. 도 7은 실시 예에 따라, 화질 처리부가 입력 영상으로부터 화질 처리된 출력 영상을 획득하는 것을 설명하 기 위한 도면이다. 도 7을 참조하면, 화질 처리부는 뉴럴 네트워크를 이용하여 입력 데이터로부터 출력 데이터를 획득할 수 있다. 화질 처리부가 이용하는 뉴럴 네트워크를 제3 뉴럴 네트워크라고 하면, 실시 예에서, 제3 뉴럴 네트 워크는 CNN(Convolution Neural Network), DCNN(Deep Convolution Neural Network) 또는 캡스넷 (Capsnet) 기반의 신경망일 수 있다. 실시 예에서, 제3 뉴럴 네트워크는 다양한 데이터들을 입력 받고, 입력된 데이터들을 분석하는 방법, 입력 된 데이터들을 분류하는 방법, 및/또는 입력된 데이터들에서 결과 데이터 생성에 필요한 특징을 추출하는 방법 등을 스스로 발견 또는 터득할 수 있도록 훈련될 수 있다. 제3 뉴럴 네트워크는 다수의 학습 데이터들에 학습 알고리즘을 적용하여, 원하는 특성의 인공지능 모델로 만들어질 수 있다. 이러한 학습은 영상 처리 장치 자체에서 이루어질 수도 있고, 별도의 서버/시스템을 통해 이루어 질 수도 있다. 여기서, 학습 알고리즘 은, 다수의 학습 데이터들을 이용하여 소정의 대상 기기(예컨데, 로봇)를 훈련시켜 소정의 대상 기기 스스로 결 정을 내리거나 예측을 할 수 있도록 하는 방법이다. 실시 예에서, 제3 뉴럴 네트워크는 학습 데이터를 입력 값으로 하는 지도 학습(supervised learning)을 통 하여, 데이터 추론 모델로 학습될 수 있다. 도 7을 참조하면, 제3 뉴럴 네트워크는 입력 계층, 숨은 계층, 및 출력 계층을 포함할 수 있다. 실시 예에서, 숨은 계층은 복수개의 히든 레이어들을 포함할 수 있다. 제3 뉴럴 네트워크는 하 나 이상의 히든 레이어를 포함할 수 있다. 예컨대, 제3 뉴럴 네트워크는 두 개 이상의 히든 레이어들을 포 함하는 딥 제3 뉴럴 네트워크(DNN)일 수 있다. 딥 뉴럴 네트워크(DNN)는 복수의 계층들을 통한 연산을 수 행하는 뉴럴 네트워크로, 연산을 수행하는 내부의 계층(layer)의 개수에 따라서 네트워크의 심도(depth)가 증가 할 수 있다. 딥 뉴럴 네트워크(DNN) 연산은 컨볼루션 뉴럴 네트워크(CNN: Convolution Neural Network) 연산 등을 포함할 수 있다. 제3 뉴럴 네트워크는 입력 계층과 출력 계층 간에 숨은 계층이 복수개의 층으로 형성될 수 있다. 제3 뉴럴 네트워크의 계층의 심도나 형태는 결과의 정확도, 결과의 신뢰도, 프로세서의 연산 처리 속도 및 용량 등을 고려하여 다양하게 설계될 수 있다. 제3 뉴럴 네트워크를 형성하는 복수개의 계층들 각각은 하나 이상의 노드를 포함할 수 있다. 예를 들어, 입력 계층은 데이터를 수신하는 하나 이상의 노드(node)들을 포함할 수 있다. 여기서, 제3 뉴럴 네트워크 의 입력 계층에 포함된 노드의 수는 출력 계층에 포함된 노드의 수와 동일할 수 있다. 도 7에서 는 제3 뉴럴 네트워크에 포함된 제1 숨은 계층의 노드 개수가 50개이고, 제2 숨은 계층의 노드 개수가 100 개이고, 제3 숨은 계층의 노드 수가 50개인 경우를 나타낸다. 그러나 이는 하나의 실시 예로, 제3 뉴럴 네트워 크의 노드의 개수는 다양하게 설계될 수 있다.실시 예에서, 입력 계층에 포함된 복수개의 노드들로 입력 데이터가 입력될 수 있다. 시각 장애가 있는 사람들은, 하이 프리퀀시 텍스쳐(high frequency textures)를 인지하지 못하기 때문에 그러한 영상을 필요로 하지 않는다. 시각 장애가 있는 사람들은 큰 객체 위주의 큰 윤곽선을 인지하는 것을 더 중요하 게 생각하기 때문에, 중요 객체의 크기가 크고, 중요 객체 내부는 평탄하고, 중요 객체의 윤곽선은 강조된 영상 을 생성하는 것이 요구된다. 따라서, 실시 예에서, 제3 뉴럴 네트워크는 다양한 장르의 영상, 각 영상에서 시각 장애가 있는 사람들이 관심을 갖는 영역이나 객체에 대한 객체 정보, 시각 장애가 있는 사람들이 화질 처리를 위해 입력한 제어 정보, 시각 장애인의 시각 특성을 반영한 정답 셋을 학습 데이터로 이용할 수 있다. 실시 예에서, 제3 뉴럴 네트워크는 객체 정보 획득부로부터 객체 정보를 수신하고, 제어 정보 획득부 로부터 제어 정보를 수신할 수 있다. 제3 뉴럴 네트워크는 다양한 장르를 갖는 영상, 각 영상에 대해 객체 정보 획득부가 획득한 객체 정보 및 제어 정보 획득부가 획득한 제어 정보를 입력 데이터로 입 력 받을 수 있다. 인접한 두 개의 계층들의 노드들은 복수개의 엣지(edge)들로 연결될 수 있다. 각각의 엣지들은 대응되는 가중치 값 및 곱하기나 더하기 등과 같은 연산 정보를 가지고 있다. 제3 뉴럴 네트워크는 입력된 데이터에 엣지의 가중치 값을 곱하거나 더하여 연산을 수행하고 그 결과 값을 엣지와 연결된 다음 계층의 노드 값으로 출력할 수 있다. 실시 예에서, 제3 뉴럴 네트워크에 포함된 계층들은 이전 레이어의 모든 노드가 다음 레이어의 모든 노드에 연결되는 완전 연결 계층(Fully Connected layer)으로 형성될 수 있다. 제3 뉴럴 네트워크는 노드에 입력된 값들을 함수에 통과시킨 후 다음 레이어로 전달하는데, 이 때 다음 레 이어의 출력을 결정하는 함수를 활성화 함수(Activation Function)라고 한다. 활성화 함수는 입력 데이터를 다 음 레이어로 어떻게 전달할 것인지를 결정하는 함수일 수 있다. 실시 예에서, 제3 뉴럴 네트워크는 히든 레이어에서 사용하는 활성화 함수로 ReLU(Rectified Linear Unit)를 사용할 수 있다. ReLU는 비선형 활성화 함 수의 하나로, 학습이 빠르고 구현이 간단하다는 장점이 있다. 다만, 이에 한정되는 것은 아니며, 제3 뉴럴 네트 워크는 Sigmoid 또는 Hyperbolic tangent/Tang 함수와 같은 다른 비선형 활성화 함수를 이용할 수도 있다. 또는 제3 뉴럴 네트워크는 활성화 함수로 비선형 함수가 아닌, 이진 활성화 함수나 선형 활성화 함 수를 이용할 수도 있다. 실시 예에서, 제3 뉴럴 네트워크는 입력 계층에 포함된 노드들로 입력 데이터를 입력 받고, 입력 데 이터에 대해 각 계층들 간의 연산을 수행하고 그 결과 값을 출력 데이터로 획득할 수 있다. 즉, 제3 뉴럴 네트 워크는 입력 데이터를 분석 및 분류하고 화질 처리를 수행하는 데 필요한 특징을 추출하고 처리하여, 화질 처리된 결과 데이터를 출력 데이터로 획득할 수 있다. 실시 예에서, 제3 뉴럴 네트워크는 입력 영상에 대해, 객체 정보를 기반으로 중요 객체 영역을 식별할 수 있다. 실시 예에서, 제3 뉴럴 네트워크는 사용자 제어 정보를 기반으로, 중요 객체에 대해 윤곽선 처리, 중요 객체 내부의 평탄화 처리, 및 중요 객체를 업스케일링하는 것 중 적어도 하나를 수행함으로써, 중요 객체 영역에 대해 화질 처리를 수행할 수 있다. 실시 예에서, 제3 뉴럴 네트워크는 다양한 장르를 갖는 영상, 사용자 제어 정보, 및 객체 정보 중 적어도 하나로부터, 객체에 대한 화질 처리를 위한 파라미터를 획득할 수 있다. 화질 처리를 위한 파라미터는 평탄화 파라미터, 윤곽선 파라미터, 업스케일링 파라미터 중 적어도 하나를 포함할 수 있다. 실시 예에서, 제3 뉴럴 네트워크는 사용자 제어 정보를 이용하여 파라미터 값을 조절하고, 그에 따라 중요 객체가 화질 처리되도록 할 수 있다. 실시 예에서, 제3 뉴럴 네트워크는 윤곽선 파라미터에 따라 중요 객체의 윤곽선 처리를 수행할 수 있다. 제3 뉴럴 네트워크는 사용자 제어 정보를 기반으로 중요 객체의 윤곽선의 디테일을 어느 정도로 유지할지, 윤곽선의 강도, 즉, 두께나 진한 정도를 어느 정도로 할 지, 윤곽선의 색상을 무슨 색으로 할지, 배경 영역과 윤곽선의 색상 간의 색 대비를 어느 정도로 할지 등을 결정할 수 있다. 실시 예에서, 제3 뉴럴 네트워크는 평탄화 파라미터에 따라 중요 객체 내부를 평탄화 처리할 수 있다. 제3 뉴럴 네트워크는 사용자 제어 정보에 따라 사용자가 선호하는 방법으로, 중요 객체의 윤곽선을 제외한 중 요 객체 내부 영역의 평탄화 정도를 조절하는 처리를 수행할 수 있다. 실시 예에서, 제3 뉴럴 네트워크는 업스케일링 파라미터에 따라 중요 객체를 업스케일링할 수 있다. 제3 뉴럴 네트워크는 사용자 제어 정보에 따라 사용자가 선호하는 크기로 중요 객체의 크기를 확대 수 있다. 동시에, 제3 뉴럴 네트워크는 크기가 커진 중요 객체에 대해 선명도 처리를 수행할 수 있다. 실시 예에서, 제3 뉴럴 네트워크는 픽셀의 크기를 단순히 복사해서 픽셀 수를 늘리는 대신, 픽셀 사이에 새로운 픽셀을 생성함으로써 중요 객체의 크기를 업스케일링할 수 있다. 제3 뉴럴 네트워크는 다양한 방법 으로 새로운 픽셀을 생성할 수 있다. 제3 뉴럴 네트워크는 nearest 방식, bilinear 방식, joint bilateral 방식 등과 같이 다양한 업샘플링 방식을 이용하여 픽셀 사이에 새로운 픽셀을 생성할 수 있다. 즉, 제3 뉴럴 네트워크는 중요 객체에 대해 해상도를 조절하면서 중요 객체의 크기를 늘리는 처리를 동시에 수 행함으로써, 중요 객체의 크기가 늘어남과 동시에 해상도 또한 향상되도록 할 수 있다. 실시 예에서, 제3 뉴럴 네트워크는 사용자 제어 정보를 기반으로 평탄화 파라미터가 적용된 결과와 윤곽선 파라미터가 적용된 결과의 블렌딩 정도를 학습할 수 있다. 제3 뉴럴 네트워크는 제어 정보를 학습하여 사 용자가 선호하는 블렌딩 정도를 학습하고, 그에 따라 평탄화 파라미터와 윤곽선 파라미터가 적용된 결과들을 블 렌딩함으로써 중요 객체 내부는 평탄화되고, 중요 객체의 윤곽선은 윤곽선 처리가 수행된 최종 결과물을 획득할 수 있다. 다른 실시 예에서, 제3 뉴럴 네트워크는 중요 객체에 대해 화질 처리한 결과를 출력 데이터로 획득하는 대 신, 중요 객체에 대한 평탄화 파라미터와 윤곽선 파라미터를 출력 데이터로 출력할 수도 있다. 이 경우, 화질 처리부는 평탄화 파라미터가 적용된 결과와 윤곽선 파라미터가 적용된 결과에 대한 블렌딩 정보를 추가로 사용자로부터 입력 받을 수 있다. 사용자는 평탄화 정도가 너무 세고, 윤곽선 처리가 너무 약하다고 느끼는 경 우, 사용자 인터페이스를 이용하여 평탄화 파라미터와 윤곽선 파라미터의 블렌딩 정보를 조절할 수 있다. 화질 처리부는 사용자로부터의 제어 신호에 따라 파라미터의 블렌딩 정도를 조절하여 최종적으로 화질 처리된 영상을 획득할 수 있다. 실시 예에서, 제3 뉴럴 네트워크는 결과의 정확도를 높이기 위해서, 복수의 학습 데이터에 근거하여 출력 계층에서 입력 계층 방향으로 학습(training)을 반복적으로 수행하여 출력 결과의 정확도가 높아지도 록 가중치 값들을 수정할 수 있다. 실시 예에서, 제3 뉴럴 네트워크는 출력 계층에서 출력되는 화질 처리된 결과 데이터를 그라운드 트 루쓰(ground truth) 간의 차이를 손실 함수로 획득할 수 있다. 그라운드 트루쓰는 영상에서 사용자가 관심을 갖 는 중요 객체를 사용자가 선호하는 화질 처리 방법에 따라 화질 처리한 데이터일 수 있다. 제3 뉴럴 네트워크 는 손실 함수를 다시 입력 받고, 손실 함수가 최소가 되도록 히든 레이어에 포함된 엣지들의 가중치 값을 계속 수정할 수 있다. 엣지들의 가중치 값은 반복적인 학습을 통하여 최적화될 수 있으며, 결과의 정확도 가 소정의 신뢰도를 만족할 때까지 반복적으로 수정될 수 있다. 제3 뉴럴 네트워크는 최종적으로 설정된 엣지들의 가중치 값들에 의해서 형성될 수 있다. 실시 예에 따르면, 제3 뉴럴 네트워크를 이용하여 영상에 포함된 중요 객체에 대해 화질 처리를 수행하는 방법을 학습하는 동작은, 영상 처리 장치에 장착되기 전에 미리 수행될 수 있다. 복수의 학습 데이터 중 일부가 변경되는 경우, 학습 모델 또한 업데이트될 수 있다. 소정의 주기 단위로, 새로운 학습 데이터가 사용되 거나 추가될 경우, 제3 뉴럴 네트워크는 새로운 학습 데이터로부터 화질 처리를 수행하는 방법을 다시 학 습할 수 있으며, 이에 따라 학습 모델이 업데이트될 수 있다. 실시 예에서, 제3 뉴럴 네트워크를 이용하여 화질 처리를 수행하는 방법을 학습하는 동작은, 외부의 컴퓨 팅 장치(미도시)에서 수행될 수 있다. 제3 뉴럴 네트워크를 이용하여 영상에 포함된 객체에 대해 화질 처 리를 수행하는 방법을 학습하는 동작은, 상대적으로 복잡한 연산량을 필요로 할 수 있다. 이에 따라, 컴퓨팅 장 치가 학습하는 동작을 수행하고, 영상 처리 장치는 통신망을 통해 컴퓨팅 장치로부터 학습 모델을 수신할 수 있다. 또는, 영상 처리 장치를 제조하는 제조사는 컴퓨팅 장치가 학습시킨 제3 뉴럴 네트워크를 영상 처리 장치에 장착하여, 학습 모델이 영상 처리 장치에서 화질 처리된 영상을 획득하는 데 이용 되도록 할 수 있다. 또는, 본 개시의 다른 실시 예에서, 컴퓨팅 장치가 아닌, 영상 처리 장치가 제3 뉴럴 네트워크를 통 한 학습 동작을 직접 수행할 수도 있다. 이 경우, 영상 처리 장치는 학습 데이터를 획득하고, 학습 데이터 로 제3 뉴럴 네트워크를 학습시켜 학습 모델을 결정할 수 있으며, 결정된 학습 모델을 통하여 화질 처리된 영상을 획득할 수 있다. 실시 예에서, 학습이 끝난 제3 뉴럴 네트워크는 입력 데이터로, 실시간 영상, 객체 정보 및 제어 정보를 입력 받을 수 있다. 제3 뉴럴 네트워크는 실시간으로 입력되는 입력 영상에 대해 객체 정보 획득부로 부터 객체 정보를 입력 받을 수 있다. 제3 뉴럴 네트워크는 객체 정보를 기반으로 실시간 영상에서 중요 객체의 종류나 위치, 크기를 식별할 수 있다. 제3 뉴럴 네트워크는 제어 정보 획득부로부터 사용자의 인터랙션 히스토리를 기반으로 생성된, 실시간 영상에 적용할 제어 정보를 수신하고, 제어 정보에 따라, 실시간 영상에 포함된 중요 객체를 화질 처리함으로써 중요 객체가 화질 처리된 영상을 출력 데이터로 획득할 수 있다. 도 8은 실시 예에 따라, 영상 처리 장치가 사용자로부터 중요 객체를 선택 받는 것을 설명하기 위한 도면 이다. 실시 예에서, 영상 처리 장치는 입력 영상에서 객체를 검출할 수 있다. 입력 영상에 복수개의 객체가 포함 되어 있는 경우, 영상 처리 장치는 복수개의 객체 중에서 중요 객체를 식별할 수 있다. 중요 객체는 입력 영상에 포함된 복수개의 객체들 중에 일부일 수 있다. 실시 예에서, 영상 처리 장치는 복수 객체 중 중요 객체로 처리할 대상을 사용자로부터 직접 선택 받을 수 있다. 이를 위해, 영상 처리 장치는 복수개의 객체 각각을 식별하기 위한 객체 식별 정보를 복수개의 객체 주변에 각각 출력할 수 있다. 도 8은, 영상 처리 장치가 영상에서 복수개의 객체를 검출한 경우, 이 중 어느 객체를 중요 객체로 결정할 지를 사용자로부터 선택 받기 위해 객체 식별 정보를 화면에 출력한 것을 도시한다. 도 8a는 현재 화면에서 출력된 영상이 정지 영상일 때, 객체 식별 정보가 화면에 출력된 것을 도시한다. 영상 처리 장치는 사용자가 비디오를 시청하려고 하면, 해당 비디오에 등장하는 복수 인물들을 포함하는 정지 영상을 출력하고, 정지 영상에 객체 식별 정보를 출력할 수 있다. 영상 처리 장치는 복수개의 객체 각각에 대한 객체 식별 정보(811, 812, 8123, 814)를 객체 주변에 출력할 수 있다. 사용자는 리모컨 등의 사용자 인터 페이스를 이용하여, 복수개의 객체 식별 정보 중 하나를 선택할 수 있다. 예컨대, 사용자가 객체 식별 정보 812 를 선택한 경우, 영상 처리 장치는 사용자가 선택한 객체 식별 정보 812의 색상이나 두께, 투명도 등을, 선택 받지 못한 다른 객체 식별 정보와는 다르게 표시하여, 사용자에게 특정 객체가 선택되었음을 알려줄 수 있 다. 도 8b, 도 8c는 영상 처리 장치가 비디오를 재생하는 중에 발화자를 식별하고, 발화자에 대응하는 객체 식 별 정보를 발화자 주변에 출력한 것을 도시한 도면이다. 영상 처리 장치는 현재 출력되는 영상을 분석하여, 영상에서 발화자를 식별할 수 있다. 예컨대, 영상 처리 장치는 현재 재생 중인 비디오에 포함된 객체가 사람인 경우, 사람의 얼굴을 분석하여, 입술이 움직이는 대상을 발화자로 식별할 수 있다. 또는, 영상 처리 장치는 비디오 프레임과 오디오 프레임을 함께 입력 받고 입력된 비디오 프레임과 오디오 프레임의 특징을 분석 및 분류하여, 현재 발화자의 위치를 식별함으로써 발화자를 검출할 수도 있다. 도 8a는 영상 처리 장치가 특정 시점, 예컨대, t0 시점에, 발화자를 나타내기 위한 객체 식별 정보를 발화자 주변에 출력한 것을 도시한다. 사용자는 리모컨 등을 이용하여 발화자 주변의 객체 식별 정보를 선 택함으로써, 발화자가 중요 객체로 식별되도록 할 수 있다. 영상 처리 장치는 사용자가 t0 시점에 출력된 객체 식별 정보를 선택하지 않은 경우, t1 시점에, t0 시점의 발화자와는 다른 발화자를 표시하기 위한 객체 식별 정보를 화면에 출력할 수 있다. 도 8c는 영상 처리 장치가 t1 시점의 발화자를 나타내기 위한 객체 식별 정보를 화면에 출력된 것을 도시한다. 사 용자는 t1 시점에 화면에 출력된 객체 식별 정보를 선택함으로써, t1 시점에 출력된 객체 식별 정보 에 대응하는 객체를 중요 객체로 선택할 수 있다. 이와 같이, 실시 예에 의하면, 영상 처리 장치는 복수개의 객체 중 화질 처리를 수행할 중요 객체를 사용 자로부터 직접 선택 받을 수 있다. 따라서, 영상 처리 장치는 사용자가 선택한 중요 객체에 대해 화질 처 리를 수행함으로써, 사용자가 원하는 대상이 사용자에게 보다 잘 인지되도록 할 수 있다. 도 9는 실시 예에 따른 영상 처리 장치(100a)의 내부 블록도이다. 도 9의 영상 처리 장치(100a)는 도 2의 영상 처리 장치의 일 예일 수 있다. 이하, 도 2에서 설명한 내용과 중복되는 설명은 생략한다. 도 9를 참조하면, 영상 처리 장치(100a)는 프로세서 및 메모리 외에, 튜너부, 통신부, 감 지부, 입/출력부, 비디오 처리부, 디스플레이부, 오디오 처리부, 오디오 출력부및 사용자 인터페이스를 더 포함할 수 있다. 튜너부는 유선 또는 무선으로 수신되는 방송 콘텐츠 등을 증폭(amplification), 혼합(mixing), 공진 (resonance)등을 통하여 많은 전파 성분 중에서 영상 처리 장치(100a)에서 수신하고자 하는 채널의 주파수만을 튜닝(tuning)시켜 선택할 수 있다. 튜너부를 통해 수신된 콘텐츠는 디코딩되어 오디오, 비디오 및/또는 부 가 정보로 분리된다. 분리된 오디오, 비디오 및/또는 부가 정보는 프로세서의 제어에 의해 메모리에 저장될 수 있다. 통신부는 프로세서의 제어에 의해 영상 처리 장치(100a)를 주변 기기나 외부 장치, 서버, 이동 단말 기 등과 연결할 수 있다. 통신부는 무선 통신을 수행할 수 있는 적어도 하나의 통신 모듈을 포함할 수 있 다. 통신부는 영상 처리 장치(100a)의 성능 및 구조에 대응하여 무선랜 모듈, 블루투스 모듈, 유선 이더넷(Ethernet) 중 적어도 하나를 포함할 수 있다. 블루투스 모듈은 블루투스 통신 규격에 따라서 주변 기기로부터 전송된 블루투스 신호를 수신할 수 있다. 블루투스 모듈은 BLE(Bluetooth Low Energy) 통신 모듈이 될 수 있으며, BLE 신호를 수신할 수 있다. 블 루투스 모듈은 BLE 신호가 수신되는지 여부를 감지하기 위해서 상시적으로 또는 일시적으로 BLE 신호를 스 캔할 수 있다. 무선랜 모듈은 와이파이(Wi-Fi) 통신 규격에 따라서 주변 기기와 와이파이 신호를 송수신할 수 있다. 감지부는 사용자의 음성, 사용자의 이미지, 또는 사용자의 인터랙션을 감지하며, 마이크, 카메라부 , 광 수신부, 센싱부를 포함할 수 있다. 마이크는 사용자의 발화(utterance)된 음성이나 노이즈를 포함하는 오디오 신호를 수신할 수 있고 수신된 오디오 신호를 전기 신호로 변환하여 프로세서로 출력할 수 있다. 카메라부는 센서(미도시) 및 렌즈(미도시)를 포함하고, 화면에 맺힌 이미지를 촬영하여 캡쳐하고 이를 프 로세서로 전송할 수 있다. 광 수신부는, 광 신호(제어 신호를 포함)를 수신할 수 있다. 광 수신부는 리모컨이나 핸드폰 등과 같 은 제어 장치로부터 사용자 입력(예를 들어, 터치, 눌림, 터치 제스처, 음성, 또는 모션)에 대응되는 광 신호를 수신할 수 있다. 입/출력부는 프로세서의 제어에 의해 영상 처리 장치(100a)의 외부 기기 등으로부터 비디오(예를 들 어, 동적 이미지 신호나 정지 이미지 신호 등), 오디오(예를 들어, 음성 신호나, 음악 신호 등) 및 부가 정보 등을 수신할 수 있다. 입/출력부는 HDMI 포트(High-Definition Multimedia Interface port, 941), 컴포넌트 잭(component jack, 942), PC 포트(PC port, 943), 및 USB 포트(USB port, 944) 중 하나를 포함할 수 있다. 입/출력부는 HDMI 포트, 컴포넌트 잭, PC 포트, 및 USB 포트의 조합을 포함할 수 있다. 비디오 처리부는, 디스플레이부에 의해 표시될 이미지 데이터를 처리하며, 이미지 데이터에 대한 디 코딩, 렌더링, 스케일링, 노이즈 필터링, 프레임 레이트 변환, 및 해상도 변환 등과 같은 다양한 이미지 처리 동작을 수행할 수 있다. 실시 예에서, 비디오 처리부는 제어 정보에 따라 중요 객체에 대한 화질 처리를 수행할 수 있다. 비디오 처리부는 중요 객체의 크기를 늘리고, 해상도를 변환하고, 중요 객체 내부를 평탄화하고, 중요 객체의 윤 곽선을 처리하는 등의 화질 처리를 수행할 수 있다. 디스플레이부는 방송국으로부터 수신하거나 외부 서버, 또는 외부 저장 매체 등으로부터 수신한 콘텐츠를 화면에 출력할 수 있다. 콘텐츠는 미디어 신호로, 비디오 신호, 이미지, 텍스트 신호 등을 포함할 수 있다. 실시 예에서, 디스플레이부는 비디오 처리부에 의해 중요 객체가 화질 처리된 영상을 화면에 출력할 수 있다. 실시 예에서, 디스플레이부는 객체 주변에 객체 식별 정보가 포함된 화면을 출력할 수 있다. 실시 예에서, 디스플레이부는 사용자로부터 시청 보조 기능을 선택 받기 위한 인터페이스 화면을 출력할 수 있다. 오디오 처리부는 오디오 데이터에 대한 처리를 수행한다. 오디오 처리부에서는 오디오 데이터에 대한 디코딩이나 증폭, 노이즈 필터링 등과 같은 다양한 처리가 수행될 수 있다. 오디오 출력부는 프로세서의 제어에 의해 튜너부를 통해 수신된 콘텐츠에 포함된 오디오, 통신 부 또는 입/출력부를 통해 입력되는 오디오, 메모리에 저장된 오디오를 출력할 수 있다. 오디오 출력부는 스피커, 헤드폰 또는 S/PDIF(Sony/Philips Digital Interface: 출력 단자) 중 적어도 하나를 포함할 수 있다. 사용자 인터페이스는 영상 처리 장치(100a)를 제어하기 위한 사용자 입력을 수신할 수 있다. 사용자 인터 페이스는 사용자의 터치를 감지하는 터치 패널, 사용자의 푸시 조작을 수신하는 버튼, 사용자의 회전 조작 을 수신하는 휠, 키보드(key board), 및 돔 스위치 (dome switch), 음성 인식을 위한 마이크, 모션을 센싱하는 모션 감지 센서 등을 포함하는 다양한 형태의 사용자 입력 디바이스를 포함할 수 있으나 이에 제한되지 않는다. 리모컨이나 기타 이동 단말기가 영상 처리 장치(100a)를 제어하는 경우, 사용자 인터페이스는 이동 단말기 로부터 수신되는 제어 신호를 수신할 수 있다. 실시 예에서, 사용자 인터페이스는 사용자로부터 화질 처리 기능 사용 여부를 선택 받을 수 있다. 실시 예 에서, 사용자 인터페이스는 화질 처리 기능 중 어떤 기능을 어느 정도로 사용할지를 선택 받을 수 있다. 실시 예에서, 사용자 인터페이스는 사용자로부터 화면에서 객체 식별 정보를 선택 받을 수 있다. 도 10은 실시 예에 따라, 영상 처리 장치가 입력 영상에 대해 수행하는 화질 처리에 대해 설명하기 위한 도면이다. 도 10을 참조하면, 영상 처리 장치는 입력 영상을 입력 받고, 이를 각각 처리하여 제1 처리 영상 및 제2 처리 영상를 획득할 수 있다. 실시 예에서, 영상 처리 장치는 입력 영상에 포함된 객체의 내부의 평탄화 정도를 조절할 수 있다. 영상 처리 장치는 사용자의 인터랙션 히스토리나, 실시간 제어 정보에 따라, 입력 영상에 포함된 객 체 내부의 디테일을 어느 정도 삭제할지를 결정할 수 있다. 영상 처리 장치는 제3 뉴럴 네트워크를 이용하여 영상, 사용자 제어 정보, 및 객체 정보 중 적어도 하나로부터, 중요 객체에 대한 화질 처리를 위한 평 탄화 파라미터를 획득할 수 있다. 평탄화 파라미터는 평탄화 처리 정도를 나타내는 파라미터일 수 있다. 실시 예에서, 영상 처리 장치는 다양한 필터를 이용하여, 입력 영상에 포함된 객체의 내부를 평탄화 처리할 수 있다. 예컨대, 영상 처리 장치는 edge preserving smoothing filter를 이용하여 입력 영상 에 포함된 객체의 내부의 디테일의 뭉개짐 정도를 조절할 수 있다. 실시 예에서, 영상 처리 장치는 사용자 제어 정보를 기반으로 필터의 평탄화 파라미터를 조절하여, 중요 객체의 평탄화 정도를 조절할 수 있다. 실시 예에서, 제1 처리 영상은 입력 영상에 포함된 객체에 대해 평탄화가 수행된 영상을 도시한다. 제1 처리 영상을 보면, 꽃잎 내부의 무늬나 꽃술, 꽃가루 등의 디테일한 표현들이 모두 사라지고 평평하 게 뭉개진 것을 알 수 있다. 실시 예에서, 영상 처리 장치는 입력 영상에 포함된 객체의 윤곽선을 처리할 수 있다. 실시 예에서, 영상 처리 장치는 제3 뉴럴 네트워크를 이용하여 영상, 사용자 제어 정보, 및 객체 정보 중 적어도 하나로부터, 중요 객체에 대한 화질 처리를 위한 윤곽선 파라미터를 획득할 수 있다. 윤곽선 파라미터는 윤곽선 의 보존 정도, 주변의 노이즈 제거, 윤곽선의 두께, 진하기, 윤곽선의 디테일 제거 여부 등에 대한 파라미터일 수 있다. 실시 예에서, 영상 처리 장치는 사용자 제어 정보를 기반으로 윤곽선 파라미터를 조절하여, 중요 객체의 윤곽선을 처리할 수 있다. 실시 예에서, 제2 처리 영상은 입력 영상에 포함된 객체에 대해 윤곽선이 처리된 영상을 도시한다. 제2 처리 영상을 보면, 꽃잎의 형태만이 두꺼운 윤곽선으로 포함되어 있고, 주변의 다른 디테일한 표현들 은 모두 제거되었음을 알 수 있다. 또한, 윤곽선의 색상이 배경이나 객체 내부와는 다르다는 것을 알 수 있다. 실시 예에서, 영상 처리 장치에 포함된 제3 뉴럴 네트워크는 사용자 제어 정보를 기반으로 평탄화 처 리된 영상과 윤곽선 처리된 영상의 블렌딩 정도를 학습할 수 있다. 제3 뉴럴 네트워크는 사용자 제어 정보 를 학습하여 사용자가 선호하는 블렌딩 정도를 학습하고, 그에 따라 평탄화 파라미터가 적용된 영상과 윤곽선 파라미터가 적용된 영상을 블렌딩함으로써 중요 객체 내부는 평탄화되고, 중요 객체의 윤곽선은 윤곽선 처리가수행된 최종 결과물을 획득할 수 있다. 즉, 도 10에서, 제3 뉴럴 네트워크는 제1 처리 영상과 제2 처리 영상의 블렌딩 정도를 자동으로 조절하고, 그에 따라 최종 영상을 획득할 수 있다. 다른 실시 예에서, 영상 처리 장치는 사용자로부터 평탄화 파라미터가 적용된 영상 및 윤곽선 파라미터가 적용된 영상의 블렌딩 정도에 대한 제어 명령을 수신할 수 있다. 실시 예에서, 영상 처리 장치는 사용자의 제어 명령에 따라, 평탄화 파라미터와 윤곽선 파라미터가 적용된 영상 간의 블렌딩 정도를 조절하여, 평탄화된 정도의 강약, 윤곽선 처리 정도의 강약을 조절하여 최종 결과물을 획득할 수 있다. 이 경우, 제3 뉴럴 네트워크는 중요 객체에 대해 화질 처리한 결과를 출력 데이터로 출력하는 대신, 중요 객체에 대해 평탄화 처리만 수행하여 획득한 제1 처리 영상과 윤곽선 처리만 수행하여 획득한 제2 처리 영상을 출력 데이터로 출력할 수 있다. 영상 처리 장치는 평탄화 처리만 수행된 영상과 윤곽선 처리만 수행된 영상 간의 블렌딩 정보를 추가로 사 용자로부터 입력 받을 수 있다. 사용자는 평탄화 정도가 너무 세고, 윤곽선 처리가 너무 약하다고 느끼는 경우, 사용자 인터페이스를 이용하여 평탄화 처리된 영상과 윤곽선 처리된 영상 간의 블렌딩 정도를 조절할 수 있다. 화질 처리부는 사용자로부터의 제어 신호에 따라 영상 간 블렌딩 정도를 조절하여 최종적으로 화질 처리된 영상을 획득할 수 있다. 도 11은 실시 예에 따라, 화질 처리 기능을 포함하는 사용자 인터페이스 화면을 도시한 도면이다. 사용자는 영상을 시청하기 전에, 미리, 시청 보조 기능을 선택하여, 화질 처리 여부나 화질 처리 정도를 선택할 수 있다. 또는, 사용자는 영상을 시청하는 중에, 특정 객체에 대해 화질 처리를 수행하기를 원하는 경우, 시청 보조 기능이 활성화되도록 선택하여, 특정 객체에 대해 실시간으로 화질 처리가 수행되도록 할 수 있다. 영상 처리 장치는 시청 보조 기능을 제공하기 위한 인터페이스 화면을 출력할 수 있다. 실시 예에서, 영상 처리 장치는 다양한 설정 기능 중, 화면의 다양한 기능을 설정하기 위한 화면 설정 인터페이스 화면을 출 력할 수 있다. 도 11(a)를 참조하면, 화면 설정 인터페이스 화면은 시청 보조 기능 선택을 위한 메뉴를 포함할 수 있다. 시청 보조 기능 선택을 위한 메뉴는 시청 보조 기능 적용 여부나 시청 보조 기능 적용 정도를 조절 하기 위한 막대기 형태의 메뉴바를 포함할 수 있다. 다만, 이는 하나의 실시 예로, 화면 설정 인터페이스 화면 이나 시청 보조 기능 선택을 위한 메뉴는 다양한 구조나 배치, 형태 등을 가질 수 있음은 물론이다. 도 11(b)는 또 다른 화면 설정 인터페이스 화면의 예를 도시한다. 또 다른 화면 설정 인터페이스 화면 에는 윤곽선 처리를 위한 메뉴, 크기 조절을 위한 메뉴, 평탄화 처리를 위한 메뉴가 포함될 수 있다. 사용자는 또 다른 화면 설정 인터페이스 화면을 보고, 중요 객체에 대해 수행할 화질 처 리의 종류를 선택할 수 있다. 또한, 도 11에는 도시하지 않았으나, 영상 처리 장치는 사용자가 화질 처리 종류를 선택한 경우, 선택된 종류의 화질 처리를 어느 정도로 수행할지에 대한 정보를 입력할 수 있는 사용자 인터페이스 화면을 출력할 수 있다. 사용자는 윤곽선 처리, 평탄화 정도, 확대 정도를 선택하여 입력할 수 있다. 도 12는 실시 예에 따라, 영상 처리 장치가 입력 영상에 대해 화질 처리를 수행하여 획득한 결과 영상을 도시한 도면이다. 도 12를 참조하면, 영상 처리 장치는 입력 영상을 분석하여, 입력 영상에 포함된 중요 객체를 검출할 수 있다. 영상 처리 장치는 중요 객체를 분석하여, 중요 객체가 사람이라는 것을 식별할 수 있다. 실시 예에서, 영상 처리 장치는 사람 전체에 대해 화질 처리를 수행할 수 있다. 영상 처리 장치는 사 용자의 제어 정보를 기반으로, 즉, 사용자의 과거 이력이나 취향에 따라, 객체를 확대하지 않고 크기를 유지한 채, 객체의 평탄화와 윤곽선 처리만을 수행할 수 있다. 예컨대, 영상 처리 장치는 사용자 인터랙션 히스토 리를 기반으로, 사용자가 중요 객체의 크기가 일정 크기 이상인 경우에는 확대 기능을 이용하지 않았음을 식별 하고, 입력 영상에 포함된 객체의 크기에 따라 확대 기능 이용 여부를 결정할 수 있다. 영상 처리 장치 는 객체의 크기가 일정 크기보다 큰 경우, 입력 영상에 포함된 객체를 확대하지 않고, 다른 화질 처 리만을 수행할 수 있다. 실시 예에서, 영상 처리 장치는 객체 전체를 평탄화하고, 윤곽선을 처리하여, 제1 결과 영상을 획득 할 수 있다. 제1 결과 영상에 포함된 객체는 입력 영상 내에서의 객체와 동일한 크기를 갖는 것을 알 수 있다. 또한, 제1 결과 영상에 포함된 객체는 입력 영상에 포함된 객체의 윤곽선 및 평탄화 처리가 수행되었음을 알 수 있다. 또는 다른 실시 예에서, 영상 처리 장치는 입력 영상에 포함된 객체가 사람인 경우, 사람의 얼굴만 을 중요 객체로 식별할 수 있다. 예컨대, 영상 처리 장치는 사용자 인터랙션 히스토리를 기반으로, 사용자 가 사람의 얼굴만을 확대하여 시청하는 것을 선호하는 경우, 입력 영상에서 사람의 얼굴 영역만을 중요 객체 영역으로 식별할 수 있다. 영상 처리 장치는 중요 객체 영역인 얼굴 영역을 크랍(crop)하고, 크 랍된 중요 객체 영역에 대해서 화질 처리를 수행할 수 있다. 영상 처리 장치는 크랍된 중요 객체 영역을 입력 영상의 크기만큼 확대하고, 동시에, 중요 객체 영역의 해상도를 조절할 수 있다. 또한, 영상 처리 장치는 중요 객체 영역에 대해 사용자가 선호하는 평탄화 처리 및 윤곽선 처리를 수행할 수 있다. 실시 예에서, 영상 처리 장치는 중요 객체만을 화질 처리하여, 제2 결과 영상을 획득할 수 있다. 제 2 결과 영상은 입력 영상에 포함된 객체 중 얼굴 영역만을 포함하는 것을 알 수 있다. 또한, 입력 영상에 포함된 객체의 얼굴의 윤곽선이 처리되고, 얼굴 내부 중 눈, 코, 입을 제외한 나머지 영역은 평탄 화되었음을 알 수 있다. 도 13은, 실시 예에 따라 제1 영상으로부터 중요 객체가 화질 처리 된 제2 영상을 획득하는 방법을 도시한 순서 도이다. 도 13을 참조하면, 영상 처리 장치는 제1 영상을 입력 받고, 제1 영상에 포함된 중요 객체에 대한 객체 정 보를 획득할 수 있다(단계 1310). 실시 예에서, 영상 처리 장치는 제1 영상을 분석하고, 제1 영상으로부터 중요 객체를 검출할 수 있다. 영 상 처리 장치는 중요 객체의 종류, 위치, 크기 중 적어도 하나에 대한 정보를 객체 정보로 획득할 수 있다. 실시 예에서, 영상 처리 장치는 화질 처리를 위한 사용자 제어 정보를 획득할 수 있다(단계 1320). 실시 예에서, 사용자 제어 정보는 객체의 확대 여부, 객체의 확대 정도, 윤곽선 처리, 및 평탄화 처리 중 적어 도 하나에 대한 제어 정보를 포함할 수 있다. 실시 예에서, 영상 처리 장치는 객체 정보 및 제어 정보를 기반으로, 중요 객체에 대한 화질 처리를 수행 하여 제2 영상을 획득할 수 있다(단계 1330). 실시 예에서, 영상 처리 장치 객체 정보를 기반으로 획득한 객체의 위치, 크기, 종류 등에 대해, 사용자의 제어 정보를 참조하여, 제1 영상에 포함된 객체에 대한 화질 처리를 수행할 수 있다. 도 14는 실시 예에 따라, 사용자 제어 정보에 따라 화질 처리를 수행하는 것을 도시한 순서도이다. 실시 예에서, 사용자 제어 정보는, 추론 제어 정보 및 실시간 사용자 제어 정보 중 적어도 하나를 포함할 수 있 다. 실시 예에서, 영상 처리 장치는 영상 처리 장치 내부에 기 저장되어 있는 사용자의 인터랙션 히스토 리를 기반으로 추론 제어 정보를 획득할 수 있다. 실시 예에서, 영상 처리 장치는 추론 제어 정보에 따라, 중요 객체에 대한 화질 처리를 수행할 수 있다(단 계 1410). 실시 예에서, 영상 처리 장치는 사용자의 실시간 제어 정보가 수신되었는지 여부를 식별할 수 있다(단계 1420). 실시 예에서, 영상 처리 장치는 사용자의 실시간 제어 정보가 입력된 경우, 실시간 제어 정보에 따라, 객 체에 대한 화질 처리를 추가로 수행할 수 있다(단계 1430). 사용자의 실시간 제어 정보가 추론 제어 정보와 상 반되는 경우, 영상 처리 장치는 사용자의 실시간 제어 정보에 따라 객체에 대한 화질 처리를 수행할 수 있 다. 영상 처리 장치는 화질 처리된 영상을 출력할 수 있다. 일부 실시 예에 따른 영상 처리 장치의 동작 방법 및 장치는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴 퓨터에 의해 실행 가능한 명령어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비 휘발성 매체, 분리형 및 비 분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저 장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비 휘발성, 분리형 및 비 분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈, 또는 반송파와 같은 변조된 데 이터 신호의 기타 데이터, 또는 기타 전송 메커니즘을 포함하며, 임의의 정보 전달 매체를 포함한다. 또한, 전술한 본 개시의 실시 예에 따른 영상 처리 장치 및 그 동작 방법은 제1 영상으로부터 상기 제1 영상에 포함된 중요 객체에 대한 객체 정보를 획득하는 단계, 화질 처리에 대한 사용자 제어 정보를 획득하는 단계, 상 기 객체 정보 및 상기 사용자 제어 정보를 기반으로, 상기 제1 영상으로부터 상기 중요 객체에 대한 화질 처리 를 수행하여 제2 영상을 획득하는 단계를 포함하는 영상 처리 방법을 구현하기 위한 프로그램이 기록된 컴퓨터 로 판독 가능한 기록 매체/저장 매체를 포함하는 컴퓨터 프로그램 제품으로 구현될 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적(non-transitory) 저장 매체의 형태로 제공될 수 있다. 여기서,‘비 일시적 저장 매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의 미할 뿐이며, 이 용어는 데이터가 저장 매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분 하지 않는다. 예로, '비일시적 저장 매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래 될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD- ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간 에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품 (예:다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버 , 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시 적으로 생성될 수 있다."}
{"patent_id": "10-2022-0039872", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 설명은 예시를 위한 것이며, 발명이 속하는 기술분야의 통상의 지식을 가진 자는 발명의 기술적 사상이 나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시 예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한 다. 예를 들어, 단일 형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다.도면 도면1 도면2 도면3a 도면3b 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14"}
{"patent_id": "10-2022-0039872", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시 예에 따라, 영상 처리 장치가 화질 처리된 영상을 출력하는 것을 설명하기 위한 도면이다. 도 2는 실시 예에 따른 영상 처리 장치의 내부 블록도이다. 도 3은 실시 예에 따라, 사용자가 영상 처리 장치를 이용하여 시각 장애 정보를 입력하는 것을 설명하기 위한 도면이다. 도 4는 실시 예에 따른 도 2의 프로세서 내부 블록도이다. 도 5는 실시 예에 따라, 객체 정보 획득부가 입력 영상으로부터 객체 정보를 획득하는 것을 설명하기 위한 도면 이다. 도 6은 실시 예에 따라, 제어 정보 획득부가 추론 제어 정보를 획득하는 것을 설명하기 위한 도면이다. 도 7은 실시 예에 따라, 화질 처리부가 입력 영상으로부터 화질 처리된 출력 영상을 획득하는 것을 설명하기 위 한 도면이다. 도 8은 실시 예에 따라, 영상 처리 장치가 사용자로부터 중요 객체를 선택 받는 것을 설명하기 위한 도면이다. 도 9는 실시 예에 따른 영상 처리 장치의 내부 블록도이다. 도 10은 실시 예에 따라, 영상 처리 장치가 입력 영상에 대해 수행하는 화질 처리에 대해 설명하기 위한 도면이 다. 도 11은 실시 예에 따라, 화질 처리 기능을 포함하는 사용자 인터페이스 화면을 도시한 도면이다. 도 12는 실시 예에 따라, 영상 처리 장치가 입력 영상에 대해 화질 처리를 수행하여 획득한 결과 영상을 도시한 도면이다. 도 13은, 실시 예에 따라 제1 영상으로부터 중요 객체가 화질 처리 된 제2 영상을 획득하는 방법을 도시한 순서 도이다. 도 14는 실시 예에 따라, 사용자 제어 정보에 따라 화질 처리를 수행하는 것을 도시한 순서도이다."}
