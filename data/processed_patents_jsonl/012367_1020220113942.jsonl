{"patent_id": "10-2022-0113942", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0035013", "출원번호": "10-2022-0113942", "발명의 명칭": "뉴럴 네트워크의 파라미터 양자화 방법 및 장치", "출원인": "한양대학교 산학협력단", "발명자": "최정욱"}}
{"patent_id": "10-2022-0113942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "뉴럴 네트워크의 파라미터들을 양자화하는 방법에 있어서,(a) 미리 훈련된(pre-trained) 뉴럴 네트워크에 포함된 파라미터 값들의 에너지 분포 함수를 상기 뉴럴 네트워크의 레이어(layer) 별로 추출하는 단계;(b) 상기 에너지 분포 함수에 기초한 미리 설정된 제1 바이어스(bias) 값 및 상기 제1바이어스 값에서 미리 설정된 값을 더하거나 차감시킨 값을 제2바이어스 값으로 결정하는 바이어스 결정 단계;(c) 상기 제1바이어스 값 및 상기 제2바이어스 값에 대한 상기 확률 밀도 함수의 SQNR(Signal to QuantizationNoise Ratio Quantization) 값을 산출하는 SQNR 산출 단계; (d) 상기 제1바이어스에 대한 제1 SQNR 값 및 상기 제2바이어스에 대한 제2 SQNR 값들을 비교한 결과에 기초하여 상기 에너지 분포 함수수에 대한 최종 바이어스 값을 결정하는 최종 바이어스 결정 단계; 및(e) 상기 최종 바이어스 값에 기초하여 상기 레이어별로 파라미터 양자화를 수행하는 양자화 수행 단계;를 포함하는, 뉴럴 네트워크의 파라미터 양자화 방법."}
{"patent_id": "10-2022-0113942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서상기 (d) 단계는,상기 제1 SQNR 값이 상기 제2 SQNR 값보다 같거나 큰 경우, 상기 제1 바이어스 값을 상기 레이어의 최종 바이어스로 결정하는 단계;를 포함하는, 뉴럴 네트워크의 파라미터 양자화 방법."}
{"patent_id": "10-2022-0113942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 (d) 단계는,상기 제1 SQNR 값이 상기 제2 SQNR값들 중 어느 하나보다 작은 경우, 상기 레이어에 대해 미리 설정되어 있는마스터 바이어스(Master Bias) 값에서 미리 설정된 값만큼 차감시킨 값을 상기 레이어의 마스터 바이어스 값으로 재결정하는 (f) 단계를 포함하는, 뉴럴 네트워크의 파라미터 양자화 방법."}
{"patent_id": "10-2022-0113942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 미리 설정된 값은, 0.1 내지 0.9의 값을 포함하는, 뉴럴 네트워크의 파라미터 양자화 방법."}
{"patent_id": "10-2022-0113942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서,상기 (d) 단계는,상기 재결정된 마스터 바이어스 값을 기초로 상기 레이어의 상기 제1바이어스 값 및 상기 제2바이어스 값을 재결정하고, 재결정된 상기 제1바이어스 값 및 상기 제2바이어스 값을 기초로 상기 (c) 단계 및 상기 (d) 단계를다시 수행하는 (g) 단계;를 포함하는, 뉴럴 네트워크의 파라미터 양자화 방법."}
{"patent_id": "10-2022-0113942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5항에 있어서,공개특허 10-2024-0035013-3-상기 (d) 단계는,상기 제1 SQNR 값이 상기 SQNR 값들보다 같거나 큰 경우, 상기 제1 바이어스 값을 상기 에너지 분포 함수의 최종 바이어스로 결정하는 단계;를 포함하는, 뉴럴 네트워크의 파라미터 양자화 방법."}
{"patent_id": "10-2022-0113942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 5항에 있어서,상기 (d) 단계는,상기 제1 SQNR 값이 상기 제2 SQNR 값들보다 작은 경우, 상기 제1 SQNR 값이 상기 제2 SQNR 값들보다 이상이 될때까지, 상기 (f) 단계 및 상기 (g) 단계를 반복적으로 수행하는 (h) 단계를 반복적으로 수행하는, 뉴럴 네트워크의 파라미터 양자화 방법."}
{"patent_id": "10-2022-0113942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서상기 양자화 수행 단계는, FP 32비트를 FP 6비트로 변환하는 단계이며,상기 (e) 단계 이후,상기 FP 6 비트로 변환함에 있어서 발생되는 패딩 비트를 기초로 상기 최종 바이어스 값에 대해 파인 튜닝을 진행하는 (f) 단계를 더 포함하는, 뉴럴 네트워크의 파라미터 양자화 방법."}
{"patent_id": "10-2022-0113942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 뉴럴 네트워크는,BERT(Bidirectional Encoder Representations from Transformers) 모델로 구현되는, 뉴럴 네트워크의 파라미터양자화 방법."}
{"patent_id": "10-2022-0113942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 뉴럴 네트워크는, 8비트 이하의 파라미터를 가지는, 뉴럴 네트워크의 파라미터 양자화 방법."}
{"patent_id": "10-2022-0113942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "미리 훈련된(pre-trained) 뉴럴 네트워크에 포함된 파라미터 값들에 대한 에너지 분포 함수를 상기 뉴럴 네트워크의 레이어(layer) 별로 추출하는 에너지 분포 함수 생성 모듈;상기 에너지 분포 함수에 기초한 미리 설정된 제1 바이어스(bias) 값 및 상기 제1바이어스 값에서 미리 설정된값을 더하거나 차감시킨 값을 제2바이어스 값으로 결정하는 바이어스 결정 모듈;상기 제1바이어스 값 및 상기 제2바이어스 값에 대한 상기 에너지 분포 함수의 SQNR(Signal to QuantizationNoise Ratio Quantization) 값을 산출하는 SQNR 산출 모듈; 및 최종 바이어스 값에 기초하여 상기 레이어별로 파라미터 양자화를 수행하는 양자화 수행 모듈;을 포함하고,상기 바이어스 결정 모듈은,상기 제1바이어스에 대한 제1 SQNR 값 및 상기 제2바이어스에 대한 제2 SQNR 값들을 비교한 결과에 기초하여 상기 에너지 분포 함수에 대한 상기 최종 바이어스 값을 결정하는, 뉴럴 네트워크의 파라미터 양자화 장치."}
{"patent_id": "10-2022-0113942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서상기 바이어스 결정 모듈은,공개특허 10-2024-0035013-4-상기 제1 SQNR 값이 상기 제2 SQNR 값보다 같거나 큰 경우, 상기 제1 바이어스 값을 상기 레이어의 최종 바이어스로 결정하는, 뉴럴 네트워크의 파라미터 양자화 장치."}
{"patent_id": "10-2022-0113942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서상기 제1 SQNR 값이 상기 제2 SQNR값들 중 어느 하나보다 작은 경우, 상기 레이어에 대해 미리 설정되어 있는마스터 바이어스(Master Bias) 값에서 미리 설정된 값만큼 차감시킨 값을 상기 레이어의 마스터 바이어스 값으로 재결정하는 마스터 바이어스 결정 모듈;을 더 포함하고상기 바이어스 결정 모듈은, 상기 재결정된 마스터 바이어스 값을 기초로 상기 레이어의 상기 제1바이어스 값 및 상기 제2바이어스 값을 재결정하는, 뉴럴 네트워크의 파라미터 양자화 장치."}
{"patent_id": "10-2022-0113942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서,상기 SQNR 모듈은,상기 재결정된 제1바이어스 값 및 상기 제2바이어스 값에 대한 SQNR 값을 재산출하고, 상기 바이어스 결정 모듈은,상기 재산출된 제1 SQNR 값이 상기 SQNR 값들보다 같거나 큰 경우, 상기 재결정된 제1 바이어스 값을 상기 에너지 분포 함수의 최종 바이어스로 결정하는, 뉴럴 네트워크의 파라미터 양자화 장치."}
{"patent_id": "10-2022-0113942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "미리 훈련된(pre-trained) 뉴럴 네트워크에 포함된 파라미터 값들에 대한 에너지 분포 함수를 상기 뉴럴 네트워크의 레이어(layer) 별로 추출하는 에너지 분포 함수 생성 모듈;상기 에너지 분포 함수에 기초한 미리 설정된 제1 바이어스(bias) 값 및 상기 제1바이어스 값에서 미리 설정된값을 더하거나 차감시킨 값을 제2바이어스 값으로 결정하는 바이어스 결정 모듈;상기 제1바이어스 값 및 상기 제2바이어스 값에 대한 상기 에너지 분포 함수의 SQNR(Signal to QuantizationNoise Ratio Quantization) 값을 산출하는 SQNR 산출 모듈; 상기 SQNR 값들의 비교 결과에 기초하여 상기 레이어의 마스터 바이어스를 결정하는 마스터 바이어스 결정모듈;최종 바이어스 값에 기초하여 상기 레이어별로 파라미터 양자화를 수행하는 양자화 수행 모듈;을 포함하고,상기 바이어스 결정 모듈은,상기 제1바이어스에 대한 제1 SQNR 값 및 상기 제2바이어스에 대한 제2 SQNR 값들을 비교한 결과에 기초하여 상기 에너지 분포 함수에 대한 마스터 바이어스를 결정하는, 뉴럴 네트워크의 파라미터 양자화 장치."}
{"patent_id": "10-2022-0113942", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에 따른 뉴럴 네트워크의 파라미터들을 양자화하는 방법은, 미리 훈련된(pre-trained) 뉴럴 네트워크에 포함된 파라미터 값들의 에너지 분포 함수를 상기 뉴럴 네트워크의 레이어(layer) 별로 추출하는 단계, 상기 에 너지 분포 함수에 기초한 미리 설정된 제1 바이어스(bias) 값 및 상기 제1바이어스 값에서 미리 설정된 값을 더 하거나 차감시킨 값을 제2바이어스 값으로 결정하는 바이어스 결정 단계, 상기 제1바이어스 값 및 상기 제2바이 어스 값에 대한 상기 확률 밀도 함수의 SQNR(Signal to Quantization Noise Ratio Quantization) 값을 산출하는 SQNR 산출 단계, 상기 제1바이어스에 대한 제1 SQNR 값 및 상기 제2바이어스에 대한 제2 SQNR 값들을 비교한 결 과에 기초하여 상기 에너지 분포 함수수에 대한 최종 바이어스 값을 결정하는 최종 바이어스 결정 단계 및 상기 최종 바이어스 값에 기초하여 상기 레이어별로 파라미터 양자화를 수행하는 양자화 수행 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0113942", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 뉴럴 네트워크의 파라미터 양자화 방법 및 장치에 관한 발명으로서, 보다 구체적으로 인공신경망의 레이어마다 최적화된 바이어스를 찾아 이를 기초로 뉴럴 네트워크의 파라미터를 효과적으로 양자화하는 기술에 관한 발명이다."}
{"patent_id": "10-2022-0113942", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능(Artificial Intelligence, AI) 기술은, 인간의 학습능력과 추론능력, 지각능력, 자연언어의 이해능력 등을 컴퓨터 프로그램으로 실현한 기술을 의미하며, 종래의 룰(Rule) 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템을 의미한다. 인공지능 기술은 기계학습(딥 러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계 학습은 입력 데이터들 의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소 기술은 딥 러닝 등의 기계학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동 작 제어 등의 기술 분야로 구성된다. 인공지능을 구현하는 인공신경망은 뉴럴 네트워크(neural network)는 생물학적 뇌를 모델링한 컴퓨터 과학적 아 키텍쳐(computational architecture) 구조를 기초로 구현된다. 최근 뉴럴 네트워크 기술이 발전함에 따라, 다양 한 종류의 전자 시스템에서 뉴럴 네트워크 장치를 사용하여 입력 데이터를 분석하고 유효한 정보를 추출하는 연 구가 활발히 진행되고 있다. 뉴럴 네트워크 장치는 복잡한 입력 데이터를 처리하고 가공하기 위해서는 대한 많은 양의 연산을 필요로 한다. 따라서, 뉴럴 네트워크 장치가 입력을 실시간으로 분석하고, 정보를 추출하기 위해서 뉴럴 네트워크 연산을 효 율적으로 처리할 수 있는 기술이 요구된다. 특히, 스마트폰과 같은, 저전력 고성능 임베디드 시스템은 제한된 리소스를 가지므로, 복잡한 입력 데이터를 처리하는데 필요한 연산량을 감소시키면서도 정확도 손실을 최소화할 수 있는 기술이 요구되는 실정이다. 이에 따라 뉴럴 네트워크를 최적화하는 방법들이 제안되고 있는데 그 중에 하나로 인공신경망을 학습시킨 후 파 라미터를 양자화하는 학습 후 양자화(post-training Quantization, PTQ) 방법이 제안되고 있다. PTQ 방법은 32비트 부동 소수점 값(FP32 네트워크 및 FP 모델)을 사용하는 기학습된 신경망을 분석해, 모델의 재훈련이나 미세 조정 없이 최적의 양자화 매개변수를 찾아 추천하는 기술을 의미하는데, PTQ 방식은 데이터가 필요하지 않을 수도 있고(즉, 데이터 세트가 필요하지 않음), 소규모 보정 데이터 세트(calibration dataset)를 활용해 양자화된 추론에 모델을 최적화할 수는 장점이 존재한다. 한편, PTQ 방식의 경우 그 특성상 바이어스(Bias)의 값을 정하는 것이 매우 중요한데, 대표적으로 부동 소수점 (Floating-point, FP) 방식이 제안되는데, 부동 소수점 방식의 경우 바이어스를 고정시키는 방법(Fixed-Bias) 또는 입력의 최대값에 맞춰 바이어스를 정하는 방법(Max-Bias) 등이 사용되고 있는데, 두 가지 모두 여러 가지 모델에서 8비트모두 작은 비트수로 부동 수수점 방식으로 양자화를 진행하는 경우, 성능 열화가 큰 단점이 존재 하는 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허공보 10-2021-0136700 - 콘볼루션 신경망 양자화 추론 장치 및 방법"}
{"patent_id": "10-2022-0113942", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일 실시예에 따른 뉴럴 네트워크의 파라미터 양자화 방법 및 장치는 상기 설명한 문제점을 설명하기 위한 고안 된 발명으로서, 뉴럴 네트워크의 파라미터를 효율적으로 양자화하는 방법 및 이에 따른 장치를 제공하는데 그 목적이 있다. 구체적으로, 뉴럴 네트워크 연산이 수행되는데 필요한 메모리 용량과 대역폭(bandwidth) 및 네트워크 연산에 필 요한 하드웨어의 크기를 줄이거나 더 많은 수의 데이터를 병렬 처리할 수 있도록 하기 위해 큰 비트 폭 (bitwidth)을 가지는 FP 넘버를 작은 비트 폭을 가지는 FP number로 변환하고자 할 때, 뉴럴 네트워크의 각 레 이어의 데이터들의 에너지 분포를 고려하여 오프셋(E_offset) 값을 효율적으로 결정하고, 변환 과정에서 발생하 는 에너지 값의 포화(saturation)으로 인한 성능 저하를 최소화하고 이러한 오프셋 값을 빠르게 결정할 수 있는 방법을 제공하는데 목적이 있다. 또한, 인공신경망의 레이어마다 최적화된 바이어스를 찾아 이를 기초로 뉴럴 네트워크의 파라미터를 효과적으로 양자화하여, 트랜스포머(transformer) 모델을 포함한 다양한 인공신경망 모델에 열화를 방지할 수 있는 기술을제공하는데 그 목적이 있다."}
{"patent_id": "10-2022-0113942", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 뉴럴 네트워크의 파라미터들을 양자화하는 방법은, 미리 훈련된(pre-trained) 뉴럴 네트워크 에 포함된 파라미터 값들의 에너지 분포 함수를 상기 뉴럴 네트워크의 레이어(layer) 별로 추출하는 단계, 상기 에너지 분포 함수에 기초한 미리 설정된 제1 바이어스(bias) 값 및 상기 제1바이어스 값에서 미리 설정된 값을 더하거나 차감시킨 값을 제2바이어스 값으로 결정하는 바이어스 결정 단계, 상기 제1바이어스 값 및 상기 제2바 이어스 값에 대한 상기 확률 밀도 함수의 SQNR(Signal to Quantization Noise Ratio Quantization) 값을 산출 하는 SQNR 산출 단계, 상기 제1바이어스에 대한 제1 SQNR 값 및 상기 제2바이어스에 대한 제2 SQNR 값들을 비교 한 결과에 기초하여 상기 에너지 분포 함수에 대한 최종 바이어스 값을 결정하는 최종 바이어스 결정 단계 및 상기 최종 바이어스 값에 기초하여 상기 레이어별로 파라미터 양자화를 수행하는 양자화 수행 단계를 포함할 수 있다. 상기 (d) 단계는, 상기 제1 SQNR 값이 상기 제2 SQNR 값보다 같거나 큰 경우, 상기 제1 바이어스 값을 상기 레 이어의 최종 바이어스로 결정하는 단계를 포함할 수 있다. 상기 (d) 단계는, 상기 제1 SQNR 값이 상기 제2 SQNR값들 중 어느 하나보다 작은 경우, 상기 레이어에 대해 미 리 설정되어 있는 마스터 바이어스(Master Bias) 값에서 미리 설정된 값만큼 차감시킨 값을 상기 레이어의 마스 터 바이어스 값으로 재결정하는 (f) 단계를 포함할 수 있다. 상기 미리 설정된 값은, 0.1 내지 0.9의 값을 포함할 수 있다. 상기 (d) 단계는, 상기 재결정된 마스터 바이어스 값을 기초로 상기 레이어의 상기 제1바이어스 값 및 상기 제2 바이어스 값을 재결정하고, 재결정된 상기 제1바이어스 값 및 상기 제2바이어스 값을 기초로 상기 (c) 단계 및 상기 (d) 단계를 다시 수행하는 (g) 단계를 포함할 수 있다. 상기 (d) 단계는, 상기 제1 SQNR 값이 상기 SQNR 값들보다 같거나 큰 경우, 상기 제1 바이어스 값을 상기 에너 지 분포 함수의 최종 바이어스로 결정하는 단계를 포함할 수 있다. 상기 (d) 단계는, 상기 제1 SQNR 값이 상기 제2 SQNR 값들보다 작은 경우, 상기 제1 SQNR 값이 상기 제2 SQNR 값들보다 이상이 될 때까지, 상기 (f) 단계 및 상기 (g) 단계를 반복적으로 수행하는 (h) 단계를 반복적으로 수 행할 수 있다. 상기 양자화 수행 단계는, FP 32비트를 FP 6비트로 변환하는 단계이며, 상기 (e) 단계 이후, 상기 FP 6 비트로 변환함에 있어서 발생되는 패딩 비트를 기초로 상기 최종 바이어스 값에 대해 파인 튜닝을 진행하는 (f) 단계를 더 포함할 수 있다. 상기 뉴럴 네트워크는, BERT(Bidirectional Encoder Representations from Transformers) 모델로 구현될 수 있다. 상기 뉴럴 네트워크는, 8비트 이하의 파라미터를 가질 수 있다. 일 실시예에 따른 뉴럴 네트워크의 파라미터 양자화 장치는, 미리 훈련된(pre-trained) 뉴럴 네트워크에 포함된 파라미터 값들에 대한 에너지 분포 함수를 상기 뉴럴 네트워크의 레이어(layer) 별로 추출하는 에너지 분포 함 수 생성 모듈, 상기 에너지 분포 함수에 기초한 미리 설정된 제1 바이어스(bias) 값 및 상기 제1바이어스 값에 서 미리 설정된 값을 더하거나 차감시킨 값을 제2바이어스 값으로 결정하는 바이어스 결정 모듈, 상기 제1바이 어스 값 및 상기 제2바이어스 값에 대한 상기 에너지 분포 함수의 SQNR(Signal to Quantization Noise Ratio Quantization) 값을 산출하는 SQNR 산출 모듈 및 최종 바이어스 값에 기초하여 상기 레이어별로 파라미터 양자 화를 수행하는 양자화 수행 모듈을 포함하고, 상기 바이어스 결정 모듈은 상기 제1바이어스에 대한 제1 SQNR 값 및 상기 제2바이어스에 대한 제2 SQNR 값들을 비교한 결과에 기초하여 상기 에너지 분포 함수에 대한 상기 최종 바이어스 값을 결정할 수 있다. 상기 바이어스 결정 모듈은, 상기 제1 SQNR 값이 상기 제2 SQNR 값보다 같거나 큰 경우, 상기 제1 바이어스 값 을 상기 레이어의 최종 바이어스로 결정할 수 있다. 상기 뉴럴 네트워크 파라미터 양자화 장치는 상기 제1 SQNR 값이 상기 제2 SQNR값들 중 어느 하나보다 작은 경 우, 상기 레이어에 대해 미리 설정되어 있는 마스터 바이어스(Master Bias) 값에서 미리 설정된 값만큼 차감시 킨 값을 상기 레이어의 마스터 바이어스 값으로 재결정하는 마스터 바이어스 결정 모듈을 더 포함하고 상기 바 이어스 결정 모듈은, 상기 재결정된 마스터 바이어스 값을 기초로 상기 레이어의 상기 제1바이어스 값 및 상기제2바이어스 값을 재결정할 수 있다. 상기 SQNR 모듈은, 상기 재결정된 제1바이어스 값 및 상기 제2바이어스 값에 대한 SQNR 값을 재산출하고, 상기 바이어스 결정 모듈은, 상기 재산출된 제1 SQNR 값이 상기 SQNR 값들보다 같거나 큰 경우, 상기 재결정된 제1 바이어스 값을 상기 에너지 분포 함수의 최종 바이어스로 결정할 수 있다. 일 실시예에 따른 뉴럴 네트워크의 파라미터 양자화 장치는 미리 훈련된(pre-trained) 뉴럴 네트워크에 포함된 파라미터 값들에 대한 에너지 분포 함수를 상기 뉴럴 네트워크의 레이어(layer) 별로 추출하는 에너지 분포 함 수 생성 모듈, 상기 에너지 분포 함수에 기초한 미리 설정된 제1 바이어스(bias) 값 및 상기 제1바이어스 값에 서 미리 설정된 값을 더하거나 차감시킨 값을 제2바이어스 값으로 결정하는 바이어스 결정 모듈, 상기 제1바이 어스 값 및 상기 제2바이어스 값에 대한 상기 에너지 분포 함수의 SQNR(Signal to Quantization Noise Ratio Quantization) 값을 산출하는 SQNR 산출 모듈, 상기 SQNR 값들의 비교 결과에 기초하여 상기 레이어의 마스터 바이어스를 결정하는 마스터 바이어스 결정 모듈 및 최종 바이어스 값에 기초하여 상기 레이어별로 파라미터 양 자화를 수행하는 양자화 수행 모듈을 포함하고, 상기 바이어스 결정 모듈은, 상기 제1바이어스에 대한 제1 SQNR 값 및 상기 제2바이어스에 대한 제2 SQNR 값들을 비교한 결과에 기초하여 상기 에너지 분포 함수에 대한 마스터 바이어스를 결정할 수 있다."}
{"patent_id": "10-2022-0113942", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시예에 따른 뉴럴 네트워크의 파라미터 양자화 방법 및 장치는, SQNR을 극대화하는 방법으로 바이어스를 선택하기 때문에, 자연어 처리 업무 등에서 다른 기법들에 비해 대비 성능 열화가 크지 않는 장점이 존재한다. 또한, 본 발명의 경우 바이어스 탐색 과정을 통해 바이어스를 고정하기 때문에, 매 입력마다 모든 바이어스를 탐색해 찾는 과정(SQNR-Bias-opt)이나 매 입력의 최댓값을 탐색해야하는 Max-Bias에 비해 추론시 양자화 오버헤 드가 작은 장점이 존재한다."}
{"patent_id": "10-2022-0113942", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래 의 기재들로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0113942", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 기재된 실시 예와 도면에 도시된 구성은 개시된 발명의 바람직한 일 예이며, 본 출원의 출원 시점 에 있어서 본 명세서의 실시 예와 도면을 대체할 수 있는 다양한 변형 예들이 있을 수 있다. 또한, 본 명세서에서 사용한 용어는 실시 예를 설명하기 위해 사용된 것으로, 개시된 발명을 제한 및/또는 한정 하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\", \"구비하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 작동, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 작동, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않 는다. 또한, 본 명세서에서 사용한 \"제 1\", \"제 2\" 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는 데 사용될 수 있지만, 상기 구성 요소들은 상기 용어들에 의해 한정되지는 않는다. 아래에서는 첨부한 도면을 참고하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략한다. 한편, 본 발명에서 설명되는 아키텍처는 뉴럴 네트워크의 아키텍처에 해당될 수 있으나, 이 밖에도 다양한 모델 들을 표현 할 수 있다. 여기서, 뉴럴 네트워크는 딥 뉴럴 네트워크(Deep Neural Network, DNN) 또는 n-계층 뉴 럴 네트워크(n-layers neural networks)의 아키텍처일 수 있다. DNN 또는 n-계층 뉴럴 네트워크는 컨볼루션 뉴 럴 네트워크(Convolutional Neural Networks, CNN), 리커런트 뉴럴 네트워크(Recurrent Neural Networks, RNN), Deep Belief Networks, Restricted Boltzman Machines 등에 해당될 수 있다. 예를 들어, 뉴럴 네트워크 는 컨볼루션 뉴럴 네트워크(CNN)로 구현될 수 있으나, 이에 제한되지 않는다 한편, 본 발명에 따른 뉴럴 네트워크가 적용되어 구현되는 모델은 특정 모델에 한하지는 않으나 대표적으로 기 공지되어 있는 트랜스포머(tranmsformer) 모델 중 하나인 BERT(Bidirectional Encoder Representations from Transformers) 모델이 적용될 수 있다. 도 1은 일 실시예에 따른 뉴럴 네트워크 양자화 장치의 하드웨어 구성을 도시한 블록도이다. 도 1을 참조하면, 뉴럴 네트워크 양자화 장치는 프로세서 및 메모리를 포함할 수 있다. 도 1에는 뉴럴 네트워크 양자화 장치에는 본 실시예들과 관련된 구성요소들만이 도시되어 있다. 따라서, 뉴 럴 네트워크 양자화 장치에는 도 1에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있 음은 당업자에게 자명하다. 뉴럴 네트워크 양자화 장치는 뉴럴 네트워크를 생성하거나, 뉴럴 네트워크를 훈련(train)(또는 학습 (learn))하거나, 부동 소수점 타입의 뉴럴 네트워크의 바이어스(bias) 값을 레이어별로 결정하거나 또는 뉴럴 네트워크를 재훈련(retrain)하는 기능들과 같은 다양한 프로세싱 기능들을 갖는 컴퓨팅 디바이스에 해당된다. 예를 들어, 뉴럴 네트워크 양자화 장치는 PC(Personal Computer), 서버 디바이스, 모바일 디바이스 등 의 다양한 종류의 디바이스들로 구현될 수 있다. 프로세서는 뉴럴 네트워크 양자화 장치를 제어하기 위한 전반적인 기능을 수행하는 역할을 한다. 예를 들어, 프로세서는 뉴럴 네트워크 양자화 장치 내의 메모리에 저장된 프로그램들을 실행함으로써, 뉴럴 네트워크 양자화 장치를 전반적으로 제어한다. 프로세서는 뉴럴 네트워크 양자화 장치 내에 구비된 CPU(Central Processing Unit), GPU(Graphics Processing Unit), AP(Application Processor) 등으로 구현될 수 있으나, 이에 제한되지 않는다. 메모리는 뉴럴 네트워크 양자화 장치 내에서 처리되는 각종 데이터들을 저장하는 하드웨어로서, 예를 들어, 메모리는 뉴럴 네트워크 양자화 장치에서 처리된 데이터들 및 처리될 데이터들을 저장할 수 있 다. 또한, 메모리는 뉴럴 네트워크 양자화 장치에 의해 구동될 애플리케이션들, 드라이버들 등을 저장 할 수 있다. 메모리는 DRAM일 수 있으나, 이에 한정되는 것은 아니다. 메모리는 휘발성 메모리(volatile memory) 또는 불휘발성 메모리(nonvolatile memory) 중 적어도 하나를 포함할 수 있다. 불휘발성 메모리는 ROM (Read Only Memory), PROM (Programmable ROM), EPROM (Electrically Programmable ROM), EEPROM (Electrically Erasable and Programmable ROM), 플래시 메모리, PRAM (Phase-change RAM), MRAM (Magnetic RAM), RRAM(Resistive RAM), FRAM (Ferroelectric RAM) 등을 포함할 수 있다. 휘발성 메모리는 DRAM (Dynamic RAM), SRAM(Static RAM), SDRAM (Synchronous DRAM), PRAM (Phase-change RAM), MRAM (Magnetic RAM), RRAM (Resistive RAM), FeRAM (Ferroelectric RAM) 등을 포함할 수 있다. 실시예 에 있어서, 메모리는 HDD(Hard Disk Drive), SSD(Solid State Drive), CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), MiniSD(mini secure digital), xD(extreme digital) 또는 Memory Stick 중 적어도 하나를 포함할 수 있다.프로세서는 초기 뉴럴 네트워크를 반복적으로 훈련(학습)시킴으로써, 훈련된 뉴럴 네트워크를 생성할 수 있다. 예를 들어, 초기 뉴럴 네트워크가 훈련됨에 따라 미리 훈련된(pre-trained) 뉴럴 네트워크가 생성될 수 있다. 이때, 초기 뉴럴 네트워크는, 뉴럴 네트워크의 처리의 정확도를 확보하는 차원에서, 부동 소수점 타입(floating point type)의 파라미터들, 예를 들어, 32비트 부동 소수점 정밀도(32bit floating pointprecision)의 파라미 터들을 가질 수 있다. 여기서, 파라미터들은, 예를 들어 뉴럴 네트워크의 입/출력 액티베이션들, 웨이트들, 바이어스들 등 뉴럴 네트 워크에 입/출력되는 다양한 종류의 데이터를 포함할 수 있다. 뉴럴 네트워크의 반복적인 훈련이 진행됨에 따라, 뉴럴 네트워크의 부동 소수점 파라미터들은 주어진 입력에 대해 보다 정확한 출력을 연산하기 위해 조정될 (tuned) 수 있다. 다만, 부동 소수점의 연산은 고정 소수점의 연산에 비해 상대적으로 많은 연산량과 많은 메모리 액세스 빈도가 요구된다. 특히, 뉴럴 네트워크의 처리에 소요되는 연산량의 대부분은 다양한 파라미터들의 연산을 수행하는 컨 볼루션 연산으로 알려져 있다. 따라서, 비교적 처리 성능이 낮은 스마트폰, 태블릿, 웨어러블 디바이스 등과 같 은 모바일 디바이스, 임베디드(embedded) 디바이스 등에서는 부동 소수점 타입의 파라미터들을 갖는 뉴럴 네트 워크의 처리가 원활하지 않을 수 있다. 이와 같은 디바이스들에서 연산량을 충분히 감소시키면서 허용 가능한 정확도 손실 내에서 뉴럴 네트워크를 구 동시키기 위해서는, 레이어별로 최적화된 바이어스 값을 정해야 한다. 일반적으로 부동 소수점 방식에서는 현재 까지 바이어스를 고정시키는 방법(Fixed-Bias) 또는 입력의 최대값에 맞춰 바이어스를 정하는 방법(Max-Bias) 등이 사용되고 있는데, 두 가지 모두 여러 가지 모델에서 8비트 보다 작은 비트수로 부동 소수점 방식으로 양자 화를 진행하는 경우, 성능 열화가 큰 단점이 존재한다. 또한, 뉴럴 네트워크에서 사용되는 데이터의 비트 폭(bit width)이 클수록 더 넓은 범위의 값을 표현할 수 있기 때문에 연산 결과의 정밀도가 높지만, 개별 데이터의 비트 폭이 커질 수록 더 많은 메모리 공간을 필요로 하고 이로 인해 메모리 접근에 많은 시간이 소요되게 되며, 해당 데이터를 이용해서 연산을 수행하는 연산 로직의 크 기도 커지게 되는 문제가 존재한다. 이러한 문제를 해결하기 위해서 뉴럴 네트워크의 학습 단계에서는 개별 데이터를 큰 비트 폭을 가지는 number format을 사용해서 학습을 진행하고, 추론 과정에서 연산 속도를 높이기 위해 작은 비트 폭을 가지는 숫자 포맷 (number format)으로 변경하여 사용하는 방식이 사용되고 있다.(일 예로 FP32로 학습한 후, FP16 또는 FP8로 변 환하여 사용) 구체적으로, FP 숫자 포맷의 경우 sign bit (S), exponent bit(E), mantisa bit(M) 으로 구성되게 되며, 작은 비트 폭을을 가지는 FP 숫자 포맷으로 변경하게 되는 경우, 지수부(Exponent field)의 비트 폭도 줄어들게 되어 서 표현할 수 있는 exponent 값의 범위가 좁아지게 되며, 변환하기 전의 exponent 값이 이 범위를 벗어나는 경 우 그 값이 수렴(saturation) 되거나, 무한한 값으로 매핑되어서 변환하게 되기 때문에 뉴럴 네트워크의 성능이 저하되는 문제가 존재한다. 따라서, 본 발명에 따른 뉴럴 네트워크의 파라미터 양자화 방법 및 장치는 상기 설명한 문제점을 해결하기 위해 고안된 발명으로 인공신경망의 레이어마다 최적화된 바이어스를 찾아 이를 기초로 뉴럴 네트워크의 파라미터를 효과적으로 양자화하여, 트랜스포머(tramsformaer) 모델을 포함한 다양한 인공신경망 모델에 열화를 방지할 수 있는 기술을 제공하는데 그 목적이 있다. 이러한 본 발명의 특징에 대해서는 후술할 도 4에서부터 구체적으로 설명하도록 한다. 뉴럴 네트워크 양자화 장치는 뉴럴 네트워크가 채용될(deployed) 디바이스(이하, '채용될 디바이스'라고 함)의 처리 성능을 고려하여, 훈련된 뉴럴 네트워크의 파라미터들을 소정 비트들로 표현되는 고정 소수점 타입 으로 변환하는 양자화를 수행할 수 있다. 한편, 채용될 디바이스는 뉴럴 네트워크 양자화 장치일 수도 있고, 뉴럴 네트워크 양자화 장치와 구별 되는 다른 디바이스일 수도 있다. 뉴럴 네트워크 양자화 장치는, 양자화된 뉴럴 네트워크를, 채용될 디바이 스에 전달한다. 예를 들어, 채용될 디바이스는 모바일 디바이스, 임베디드 디바이스일 수 있다. 구체적으로, 채 용될 디바이스는 뉴럴 네트워크를 이용한 음성 인식, 영상 인식 등을 수행하는 자율주행 자동차, 로보틱스, 스 마트폰, 태블릿 디바이스, AR(Augmented Reality) 디바이스, IoT(Internet of Things) 디바이스 등일 수 있으나, 이에 제한되지 않는다. 한편, 초기 뉴럴 네트워크가 반복적으로 훈련됨으로써 미리 훈련된(pre-trained) 뉴럴 네트워크가 생성되는 동 작은 프로세서에 의해 수행되지 않을 수도 있다. 예를 들어, 뉴럴 네트워크 양자화 장치가 아닌 다른 디바이스에 의해 미리 훈련된 뉴럴 네트워크가 생성될 수 있고, 프로세서는 외부 디바이스로부터 미리 훈련된 뉴럴 네트워크를 수신할 수 있다. 일 예에서, 프로 세서는 서버에 의해 생성된, 미리 훈련된 뉴럴 네트워크를 서버로부터 수신할 수 있다. 프로세서는 미리 훈련된 뉴럴 네트워크를 메모리에 저장할 수 있다. 예를 들어, 메모리에 저장 되는 뉴럴 네트워크는 프로세서에 의하여 훈련된 뉴럴 네트워크일 수도 있고, 다른 디바이스에 의하여 훈 련된 뉴럴 네트워크일 수도 있다. 프로세서는 미리 훈련된 뉴럴 네트워크(예를 들어, 부동 소수점들을 이용하여 미리 훈련된 뉴럴 네트워 크)의 데이터를 메모리로부터 획득한다. 미리 훈련된 뉴럴 네트워크는 부동 소수점 타입의 파라미터들로 반복적으로 훈련된 데이터일 수 있다. 뉴럴 네트워크의 훈련은, 훈련 데이터 세트(training dataset)를 입력으로 하여 먼저 반복적으로 훈련되고, 이 어서 테스트 데이터 세트(test dataset)로 다시 반복적으로 훈련된 것일 수 있으나, 반드시 이에 제한되는 것은 아니다. 훈련 데이터 세트는 뉴럴 네트워크를 훈련시키기 위한 입력 데이터이고, 테스트 데이터 세트는 훈련 데 이터 세트와 겹치지 않는 입력 데이터로서, 훈련 데이터 세트로 훈련된 뉴럴 네트워크의 성능을 측정하면서 훈 련시키기 위한 데이터를 의미할 수 있다. 프로세서는 미리 훈련된 뉴럴 네트워크 데이터로부터, 피처 맵들 및 커널들 각각에 포함된 각 채널에서 이 용된 부동 소수점 타입의 파라미터 값들에 대한 채널 별 통계적 분포를 분석한다. 이때, 프로세서는 뉴럴 네트워크가 미리 훈련되는 동안 각 채널에서 이용되었던 부동 소수점 타입의 액티베이션들, 웨이트들 및 바이어 스들의 파라미터 값들에 대한 채널 별 통계량을 구함으로써, 통계적 분포를 분석할 수 있다. 메모리는 프로세서에 의해 처리될 또는 처리된 뉴럴 네트워크 관련 데이터 세트를 저장할 수 있다. 예를 들어, 메모리는 예를 훈련되지 않은 초기 뉴럴 네트워크 데이터, 훈련 과정에서 생성된 뉴럴 네트워 크 데이터, 모든 훈련이 완료된 뉴럴 네트워크 데이터, 양자화된 뉴럴 네트워크 데이터 등을 저장할 수 있다. 또한, 메모리는 프로세서에 의해 실행될 뉴럴 네트워크의 훈련 알고리즘, 양자화 알고리즘 등에 관련 된 다양한 프로그램들이 함께 저장될 수 있다. 도 2는 일 실시예에 따른 미리 훈련된 뉴럴 네트워크를 양자화하여 하드웨어 가속기에 채용하는 것을 설명하기 위한 도면이다. 도 2를 참조하면, PC, 서버 등과 같은 외부 디바이스의 프로세서는 부동 소수점 타입(예를 들어, 8비트 이하 부 동 소수점 타입)의 뉴럴 네트워크를 훈련한 뒤, 훈련된 뉴럴 네트워크를 뉴럴 네트워크 양자화 장치 로 전달할 수 있다. 다만, 이에 제한되는 것은 아니며, 앞서 도 1을 참조하여 설명한 바와 같이, 훈련된 뉴 럴 네트워크는 뉴럴 네트워크 양자화 장치의 프로세서에 의해 생성될 수도 있다. 미리 훈련된 뉴럴 네트워크 자체는 부동 소수점 타입의 파라미터들로 인하여 저전력 또는 저성능의 하드웨 어 가속기에서 효율적으로 처리되지 않을 수 있다, 하드웨어 가속기는 뉴럴 네트워크의 구동을 위한 전용 하드웨어로서, 비교적 저전력 또는 저성능으로 구현 되기 때문에 부동 소수점 연산 보다는 고정 소수점 연산에 보다 적합하게 구현될 수 있다. 하드웨어 가속기는 예를 들어, 뉴럴 네트워크 구동을 위한 전용 모듈인 NPU(neural processing unit), TPU(Tensor Processing Unit), Neural Engine 등에 해당될 수 있으나, 이에 제한되지 않는다. 양자화된 뉴럴 네트워크를 구동하는 하드웨어 가속기는, 뉴럴 네트워크 양자화 장치와 동일한 장치 내 에 구현될 수 있다. 하지만, 이에 제한되지 않고, 하드웨어 가속기는 뉴럴 네트워크 양자화 장치와는 별도 의 독립적인 디바이스에 구현될 수도 있다. 도 3은 본 발명의 일 실시예에 따른 프로세스의 일부 구성 요소를 도시한 블록도이다. 도 3을 참조하면, 일 실시예에 따른 뉴럴 네트워크의 파라미터들을 양자화 장치의 프로세서는 에너지 분포 함수 생성 모듈, 바이어스 결정 모듈, SQNR 산출 모듈, 마스터 바이어스 결정 모듈 및 양자화수행 모듈을 포함할 수 있다. 도 3에서는 설명의 편의를 위해 각각의 구성요소를 하는 역할에 따라 분리하여 설명하였지만, 본 발명의 실시예 가 이로 한정되는 것은 아니고 각각의 모듈이 하는 역할을 하나 또는 2개의 모듈이 나누어서 실행할 수 도 있으 며, 도 3에서 도시한 구성 요소 말고도, 바이어스를 결정하고 양자화를 수행할 때 필요한 다른 구성 요소들도 포함될 수 있다. 에너지 분포 함수 생성 모듈은 훈련된(pre-trained) 뉴럴 네트워크에 포함된 파라미터 값들에 대한 에너지 값의 분포에 대한 정보를 가지고 있는 함수 또는 통계적 분포를 정규화하는 확률 밀도 함수(Probability Density Function: PDF)를 뉴럴 네트워크의 레이어(layer) 별로 추출하여 생성할 수 있다. 본 명세서에서 의미하는 에너지는, 뉴럴 네트워크의 특정 파리미터가 가지고 있는 값을 의미할 수 있는데, 일 예로 부동 소수점 방식에서 사용되는 지수부(Exponent field)를 의미할 수 있다. 또한, 에너지 분포 함수 생성 모듈이 생성하는 에너지 분포 함수는 뉴럴 네트워크가 가지고 있는 다양한 파리미터들에 대한 에너지 분포 함수를 의미할 수 있다. 이하 명세서에서는 설명의 편의를 위해 에너지 분포 함 수 생성 모듈이 생성하는 함수는 확률 밀도 함수를 기준으로 설명하나, 본 발명의 실시예가 이로 한정되는 것은 아니다. 본 발명에서 의미하는 확률 밀도 함수(PDF)들은 라플라스(LaPlace) 분포, 하이퍼 시컨트(Hyp. Secant) 분포, 로 지스틱(Logistic) 분포, 정규(Gaussian) 분포, 레이즈드-코사인(Raised-Cosine) 분포, 위그너(Wigner) 분포 또 는 균등(Uniform) 분포를 포함할 수 있다. 다만, 이에 제한되는 것은 아니며, 복수의 확률 밀도 함수(PDF)들 은 슈퍼 코시(Super Cauchy) 분포 등과 같은 다양한 확률적 분포들을 더 포함할 수 있다. 한편, 이하 설명의 편의 를 위해 이하 설명되는 확률 밀도 함수는 파라미터 값들의 통계적 분포가 정규 분포라고 가정한 경우를 기준으 로 설명한다. 바이어스 결정 모듈은 에너지 분포 함수 생성 모듈이 생성한 확률 밀도 함수에 기초한 미리 설정된 제1 바이어스(bias) 값 및 제1바이어스 값에서 미리 설정된 값을 더하거나 차감시킨 값을 제2바이어스 값으로 결정할 수 있다. 본 발명에서 의미하는 바이어스는, 부동소수점(Floating-point, FP)에 사용되는 바이어스로서, 부동 소수점은 일반적으로 동적 범위(dynamic range)를 결정하는 exponent bit(e)와 resolution을 결정하는 mantissa bit(m), 부호를 결정하는 sign bit(s) 및 상기 exponent를 얼마나 이동(shift)할 지 결정하는 바이어스(bias)가 존재하 는데, 이하 설명되는 바이어스는 상기 바이어스를 의미한다. 제1바이어스 값은 각 레이어를 기초로 미리 설정되어 있는 초기 바이어스 값을 의미하며, 제2바이어스 값은 상 기 제1바아어스 값에서 미리 설정된 값만큼 더하거나 차감시킨 바이어스를 의미한다. 바이어스는 정수로 표현되기 때문에 제1바이어스 값 및 제2바이어스는 모두 정수이며, 상기 미리 설정된 값은 -3 내지 3의 값을 가질 수 있는데 대표적인 예로 1을 가질 수 있다. 즉, 상기 미리 설정된 값이 1이고 제1바이 어스 값이 1인 경우 제2바이어스 값은 0 과 2가 될 수 있다. 한편 바이어스 결정 모듈은 SQNR 산출 모듈 및 마스터 바이어스 결정 모듈에서 산출한 결과 값 들을 기초로 뉴럴 네트워크의 파라미터 양자화를 수행할 기준이 되는 최종 바이어스를 결정할 수 있다. 이에 대 한 자세한 설명은 후술하도록 한다. SQNR 산출 모듈은 상기 제1바이어스 값 및 상기 제2바이어스 값에 대한 상기 확률 밀도 함수의 SQNR 값을 각각 산출할 수 있다. SQNR(Signal to Quantization Noise Ratio)은 신호 대 잡음비를 의미하는 용어로서, SQNR이 작을수록 양자화 의 부정확성은 증가하고, SQNR이 클수록 양자화의 정확성은 증가하는 것으로 판단한다. 구체적으로, SQNR 산출 모듈은 에너지 분포 함수 생성 모듈이 인공신경망을 구성하는 모든 레이어 (layer)들에 생성한 확률 밀도 함수에 대해 SQNR 값을 산출할 수 있으며, 제1바이어스 값을 기초로 생성한 SQNR 값은 제1SQNR이 되며, 제2바이어스 값을 기초로 생성한 SQNR 값은 제2SQNR이 된다. 마스터 바이어스 결정 모듈은 제1바이어스에 대한 제1 SQNR 값 및 제2바이어스에 대한 제2 SQNR 값들을 비 교한 결과에 기초하여 확률 밀도 함수에 대한 마스터 바이어스 값을 결정할 수 있다.마스터 바이어스 값은 바이어스 값과 달리 소수점으로도 표현할 수 있는 값으로서, 바이어스의 값은 마스터 바 이어스 값을 반올림 값으로 정의된다. 마스터 바이어스 값은 또한 각각의 레이어별로 초기 설정되어 있는 값이 존재한다. 따라서, 각각의 레이어별로 마스터 바이어스 값은 초기 설정되어 있으며, 마스터 바이어스 값의 반올림으로 정의되는 바이어스 값의 특성상, 마스터 바이어스 값이 변하는 경우 올림이 되어 같이 변하거나, 바이어스 값이 변해도 올림이 되지 않 아 마스터 바이어스 값은 변하지 않을 수 도 있는 특징을 가지고 있다. 양자화 수행 모듈은 마스터 바이어스 결정 모듈이 결정한 최종 마스터 바이어스 값을 기초로 해당 레 이어별로 파라미터의 양자화를 진행할 수 있다. 지금까지 도면을 통해 본 발명에 따라 뉴럴 네트워크의 파라미터 양자화 방법에 대하 알아보았다. 이하 도면을 통해 뉴럴 네트워크의 파라미터 양자화 방법에 대해 구체적으로 알아본다. 도 4는 본 발명의 일 실시예에 따른 뉴럴 네트워크의 양자화 장치의 작동 순서를 도시한 순서도이고, 도 5는 본 발명의 일 실시예에 따른 부동 소수점의 바이어스 값을 결정하는 방법을 설명하기 위한 도면이다. 도 4를 참조하면, 뉴럴 네트워크의 파라미터 양자화 장치는 훈련된(pre-trained) 뉴럴 네트워크에 포함된 파라미터 값들의 통계적 분포를 정규화하는 확률 밀도 함수를 뉴럴 네트워크의 레이어(layer) 별로 생성할 수 있다. (S110) 레이어별로 확률 밀도 함수가 추출되었으면 뉴럴 네트워크의 파라미터 양자화 장치는 레이어별로 확수 밀도 함수에 기초한 제1바이어스 값과 제2바이어스 값을 결정한다. (S120) 제1바이어스 값과 제2바이어스 값을 설정하는 방법에 대해서는 전술하였는바 생략하도록 하며, 이하 설명의 편 의를 위해 제1바이어스 값은 1로, 제2바이어스 값은 1에서 1을 더하거나 차감한 0과 2임을 전제로 설명하도록 한다. 뉴럴 네트워크의 파라미터 양자화 장치는 제1바이어스 값 및 상기 제2바이어스 값에 대한 상기 확률 밀도 함수의 SQNR 값을 각각 산출한다.(S130) 앞서 설명한 바와 같이 제1바이어스 값을 기초로 생성한 SQNR 값은 제1SQNR이 되며, 제2바이어스 값을 기초로 생성한 SQNR 값은 제2SQNR이 된다. 다만, 제2바이어스 값은 0과 2로 총 2개가 있으므로 제2 SQNR 값은 2개가 된 다. 따라서, 총 산출된 SQNR 값은 도 5의 (a)에 도시된 바와 같이 총 3개의 SQNR 값이 산출될 수 있다. 총 3개의 SQNR 값이 산출되면, 뉴럴 네트워크의 파라미터 양자화 장치는 제 1SQNR 값과 제 2SQNR 값들과의 크기를 비교한다. (S140) 구체적으로, 제1 SQNR 값이 제2 SQNR 값보다 같거나 큰 경우, 현재 바이어스 값이 SQNR 면에서 가장 좋은 상태 이므로, 초기 설정되어 있는 현재 바이어스 값을 최종 바이어스 값으로 결정한다. (S150) 최종 바이어스가 결정되면 뉴럴 네트워크의 파라미터 양자화 장치는 최종 바이어스를 기초로 뉴럴 네트워크 의 파라미터에 대해 양자화를 진행한다. (S160) 만약, S140에서 제1 SQNR 값이 제2 SQNR값들 중 어느 하나보다 작은 경우에는 현재 바이어스 값이SQNR면에서 가 장 좋은 바이어스가 아니기 때문에 새로운 바이어스 값을 찾아야 한다. 따라서, 현재 레이어의 마스터 바이어스 값에서 미리 설정된 값만큼 차감시킨 값을 상기 레이어의 마스터 바이어스 값으로 새롭게 다시 결정한 후, 이를 기초로 상기 레이어의 제1바이어스 값 및 제2바이어스 값을 다시 결정한다. (S170, S120) 일 예로, 도 6 (a)에 도시된 바와 같이 레이어의 미리 설정되어 있는 바이어스 값과 마스터 바이어스 값이 모두 1인 상태에서, 제1 SQNR 값이 제2 SQNR 값들 중 어느 하나보다 작은 경우, 도 6의 (b)에 표현된 바와 같이 현재 마스터 바이어스 값(=1)에서 미리 설정된 값(=0.3) 만큼 차감한 값(=0.7)을 새로운 마스터 바이어스 값으로 결 정한다. S170에서 설명한 미리 설정된 값인 0.3은 일 예시로서, 본 발명의 실시예가 이로 한정되는 것은 아니고, 설계 목적에 따라 미리 설정된 값은 0.1 내지 0.9 범위의 수 중에서 자유롭게 설정될 수 있다. 마스터 바이어스 값이 새롭게 결정되면, 바이어스 값은 마스터 바이어스 값의 반올림으로 정의되므로, 앞서 설 명한 바와 같이 바이어스 값이 변하거나 변하지 않을 수 있다. 도 6의 (b)의 경우 새롭게 결정된 마스터 바이어 스 값은 0.7이므로 제1바이어스 값은 1로 여전히 동일하며, 제1바이어스 값이 동일한 이상 제2바이어스 값은 동 일하다. 따라서, S120 단계로 S130, S140 단계를 다시 거쳐도 앞선 결과와 동일하게 나오므로 다시 S170단계에 의해 마 스터 바이어스 값은 재결정된다. 첫번째로 재결정된 마스터 바이어스 값은 0.7이었으므로, 2번째로 재결정된 마 스터 바이어스어스 값은 도 6의 (C)에 도시된 바와 같이 0.7에서 미리 설정된 값인 0.3을 차감한 0.4가 된다. 따라서, 제1바이어스 값은 0이 되고, 제2바이어스 값은 0과 -1이 된다. 그리고 이렇게 2번째로 재결정된 제1바이어스 값과 제2바이어스 값에 대해 S130과 S140을 다시 수행하면, 도 6 의 (c)에 도시된 바와 같이 제1 SQNR 값이 제2 SQNR 값들보다 크므로, 현재의 바이어스 값이 0을 최종 바이어스 값으로 결정하고 이를 기초로 뉴럴 네트워크의 파라미터의 양자화 과정을 진행할 수 있다. 또한, 상기 설명한 최적의 바이어스를 결정하는 과정들은 인공신경망을 구성하는 레이어들에 대해 모두 레이어 별로 진행하여, 뉴럴 네트워크 전체의 레이어들에 대해 레이어별로 최적화된 바이어스 및 마스터 바이어스를 찾 을 수 있다. 일반적으로 뉴럴 네트워크를 학습 시킨 후 개별 데이터가 FP32와 같은 넓은 범위의 FP 넘버(number)로 표현되는 경우, 하나의 데이터가 32비트로 표현되기 때문에 연산량이 많이 발생한다. 따라서, 이를 해결하기 위해, FP 넘 버의 범위를 좁히기 위한 변환(일 예로 6비트-FP6) 과정을 수행하는데, 이 경우 Exp 범위(range)의 감소로 인해 표현할 수 있는 값의 범위가 좁아져서 클리핑(clipping) 현상이 발생할 수 있다. 그러나, 본 발명의 경우 뉴럴 네트워크의 각 레이어 별로 데이터(또는 에너지)의 분포를 보고 바이어스 값을 조 절하면서, 최종 마스터 바이어스 값을 결정하여 최적의 마스터 바이어스 값을 설정하기 때문에, 8비트보다 작은 비트(일 예로 6 비트)로 PTQ를 진행하는 경우, 성능의 열화 없이 양자화 과정이 진행할 수 있는 장점이 존재한 다. 도 6은 본 발명의 다른 실시예에 따라 뉴럴 네트워크 양자화 장치가 SQNR을 진행한 후, 파인 튜닝(Fine Tunin g)을 진행하는 과정을 설명하기 위한 표이다. 일반적으로 뉴럴 네트워크가 탑재되는 하드웨어에서는, 메모리의 배치나 버스 상에서 데이터 전송이 용이하도록 하기 위해 메모리에 저장되는 데이터가 보통 8의 배수가 되도록 데이터를 정렬(얼라이먼트)해서 사용하는 방식 을 취하고 있다. 따라서, 뉴럴 네트워크가 탑재된 프로세스가 메모리에 접근을 할 때 보통 8 의 배수 단위로 접근을 하기 때문에, 앞서 도 4와 도 5에서 설명하였던 방식으로 FT6가 진행되는 경우 비트들의 여유분이 발생하게 된다. 따 라서, 이렇게 여유분의 비트들을 활용하면, 레이어별로 설정해놓은 바이어스 값을 조금 더 세부적으로 튜닝 할 수 있는 장점이 존재한다. 이를 도 6의 표를 통해 설명하면, 도 6의 표는 뉴럴 네트워크 양자화 장치가 SQNR을 진행한 후, 파인 튜닝(Fine Tunning)을 진행하는 과정을 설명하기 위한 표로서, 표의 k는 메모리 버스(bus) width의 폭을 B 비트라 하고, 변환하고자 하는 타켓 FP 넘버(target FP number) 의 bitwidth를 N이라 할 때 k = floor (B/N)로 정의될 수 있 다. 그리고 도 6의 표의 왼쪽 항목부터 각각의 항목은 FP 데이터의 개수(k), FP 데이터의 개수(k)에 따른 FP 6 데이터의 비트 수, FP 데이터의 개수(k)에 따라 8비트로 정렬된 데이터의 비트 수, FP 데이터의 개수(k)에 따라 발생하는 패딩 비트(여유분 비트), 패딩 비트에 따라 발생하는 오프셋의 범위를 의미한다. 일 예로, k의 개수가 1인 경우, FP 6 데이터의 비트 수는 6이 되고, 이는 8 비트를 기준으로 데이터가 정렬된 경우 8 비트의 크기를 가지게 된다. 따라서, 2 비트의 패딩 비트가 남게 되므로, 남은 2비트를 기초로 오프셋의 레인지 범위를 -2, -1, 0 및 1로 범위를 정하고, 정해진 범위에 기초하여 클리핑 에러(clipping error)를 최소 화 하는 방법으로 파인 튜닝을 수행할 수 있다. 파인 튜닝을 수행하는 방법은, 도 4와 도 5를 통해서 결정된 최종 바이어스 값에 -2 부터 1까지의 값을 각각 더 한 값들에 대해 각각 FP6 변환을 진행한 후, 각각의 경우에 발생하는 클리핑 에러를 체크하고, 클리핑 에러가 최소가 되는 값을 기초로 파인 튜닝에 대한 최종 값으로 결정할 수 있다. 또 다른 예로, k의 개수가 2인 경우, FP 6 데이터의 비트 수는 12가 되고, 이는 8 비트를 기준으로 데이터가 정 렬된 경우 16 비트의 크기를 가지게 된다. 따라서, 4 비트의 패딩 비트가 남게 되므로, 남은 4비트를 기초로 오 프셋의 레인지 범위를 -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6 및 7로 범위를 정하고, 정해진 범위에 기초하여 클리핑 에러를 최소화 할 수 있는 방법으로 파인 튜닝을 수행할 수 있다. 파인 튜닝을 수행하는 방법은, 도 4와 도 5를 통해서 결정된 최종 바이어스 값에 -8 부터 7까지의 값을 각각 더 한 값들에 대해 각각 FP6 변환을 진행한 후, 각각의 경우에 발생하는 클리핑 에러를 체크하고, 클리핑 에러가최소가 되는 값을 기초로 파인 튜닝에 대한 최종 값으로 결정할 수 있다. 즉, 본 발명과 같이 파인 튜닝값을 결정하고 이를 이용해서 FP6로 변환하면, 뉴럴 네트워크의 각각의 레이어 내 에서 다양한 E_offset 값을 데이터에 적용 가능하기 때문에 SQNR 값을 좀 더 세밀하고 정확하게 결정할 수 있는 장점이 존재한다. 도 7은 본 발명의 일 실시예에 따른 전자 시스템의 구성을 나타내는 블록도이다. 도면을 참조하면, 전자 시스템은 뉴럴 네트워크를 기초로 입력 데이터를 실시간으로 분석하여 유효한 정보 를 추출하고, 추출된 정보를 기초로 상황 판단을 하거나 또는 전자 시스템이 탑재되는 전자 디바이스의 구 성들을 제어할 수 있다. 예컨대 전자 시스템은 드론(drone), 첨단 운전자 보조 시스템(Advanced Drivers Assistance System; ADAS) 등과 같은 로봇 장치, 스마트 TV, 스마트폰, 의료 디바이스, 모바일 디바이스, 영상 표시 디바이스, 계측 디바이스, IoT 디바이스 등에 적용될 수 있으며, 이 외에도 다양한 종류의 전자 디바이스 들 중 적어도 하나에 탑재될 수 있다. 전자 시스템은 프로세서, RAM, 뉴럴 네트워크 장치, 메모리, 센서 모듈 및 통 신 모듈을 포함할 수 있다. 전자 시스템은 입출력 모듈, 보안 모듈, 전력 제어 장치 등을 더 포함할 수 있다. 전자 시스템의 하드웨어 구성들 중 일부는 적어도 하나의 반도체 칩에 탑재될 수 있다. 뉴럴 네트워크 장 치는 앞서 설명된 뉴럴 네트워크 전용 하드웨어 가속기 자체 또는 이를 포함하는 장치일 수 있다. 프로세서는 전자 시스템의 전반적인 동작을 제어할 수 있다. 프로세서는 하나의 프로세서 코어 (Single Core)를 포함하거나, 복수의 프로세서 코어들(Multi-Core)을 포함할 수 있다. 프로세서는 메모리 에 저장된 프로그램들 및/또는 데이터를 처리 또는 실행할 수 있다. 일부 실시예에 있어서, 프로세서는 메모리에 저장된 프로그램들을 실행함으로써, 뉴럴 네트워크 장치 의 기능을 제어할 수 있다. 프로세서는 CPU, GPU, AP 등으로 구현될 수 있다. RAM은 프로그램들, 데이터, 또는 명령들(instructions)을 일시적으로 저장할 수 있다. 예컨대 메모리(94 0)에 저장된 프로그램들 및/또는 데이터는 프로세서의 제어 또는 부팅 코드에 따라 RAM에 일시적으로 저장될 수 있다. RAM은 DRAM(Dynamic RAM) 또는 SRAM(Static RAM) 등의 메모리로 구현될 수 있다. 뉴럴 네트워크 장치는 수신되는 입력 데이터를 기초로 뉴럴 네트워크의 연산을 수행하고, 수행 결과를 기 초로 정보 신호를 생성할 수 있다. 뉴럴 네트워크는 CNN, RNN, Deep Belief Networks, Restricted Boltzman Machines 등을 포함할 수 있으나 이에 제한되지 않는다. 뉴럴 네트워크 장치는 앞서 설명된 뉴럴 네트워크 의 파라미터를 양자화를 수행하는 하드웨어로서, 앞서 설명된 뉴럴 네트워크 전용 하드웨어 가속기에 해당될 수 있다. 정보 신호는 음성 인식 신호, 사물 인식 신호, 영상 인식 신호, 생체 정보 인식 신호 등과 같은 다양한 종류의 인식 신호 중 하나를 포함할 수 있다. 예를 들어, 뉴럴 네트워크 장치는 비디오 스트림에 포함되는 프레임 데이터를 입력 데이터로서 수신하고, 프레임 데이터로부터 프레임 데이터가 나타내는 이미지에 포함된 사물에 대한 인식 신호를 생성할 수 있다. 그러나, 이에 제한되는 것은 아니며, 전자 시스템이 탑재된 전자 장치 의 종류 또는 기능에 따라 뉴럴 네트워크 장치는 다양한 종류의 입력 데이터를 수신할 수 있고, 입력 데이 터에 따른 인식 신호를 생성할 수 있다. 메모리는 데이터를 저장하기 위한 저장 장소로서, OS(Operating System), 각종 프로그램들, 및 각종 데이 터를 저장할 수 있다. 실시예에 있어서, 메모리는 뉴럴 네트워크 장치의 연산 수행 과정에서 생성되 는 중간 결과들, 예컨대 출력 피처 맵을 출력 피처 리스트 또는 출력 피처 매트릭스 형태로 저장할 수 있다. 실 시예에 있어서, 메모리에는 압축된 출력 피처 맵이 저장될 수 있다. 또한, 메모리는 뉴럴 네트워크 장치에서 이용되는 양자화된 뉴럴 네트워크 데이터, 예컨대, 파라미터들, 웨이트 맵 또는 웨이트 리스트를 저장할 수 있다. 메모리는 DRAM일 수 있으나, 이에 한정되는 것은 아니다. 메모리는 휘발성 메모리 또는 불휘발성 메 모리 중 적어도 하나를 포함할 수 있다. 불휘발성 메모리는 ROM, PROM, EPROM, EEPROM, 플래시 메모리, PRAM,MRAM, RRAM, FRAM 등을 포함한다. 휘발성 메모리는 DRAM, SRAM, SDRAM, PRAM, MRAM, RRAM, FeRAM 등을 포 함할 수 있다. 실시예에 있어서, 메모리는 HDD, SSD, CF, SD, Micro-SD, Mini-SD, xD 또는 Memory Stick중 적어도 하나를 포함할 수 있다. 센서 모듈은 전자 시스템이 탑재되는 전자 장치 주변의 정보를 수집할 수 있다. 센서 모듈은 전 자 장치의 외부로부터 신호(예컨대 영상 신호, 음성 신호, 자기 신호, 생체 신호, 터치 신호 등)를 센싱 또는 수신하고, 센싱 또는 수신된 신호를 데이터로 변환할 수 있다. 이를 위해, 센서 모듈은 센싱 장치, 예컨대 마이크, 촬상 장치, 이미지 센서, 라이더(LIDAR; light detection and ranging) 센서, 초음파 센서, 적외선 센서, 바이오 센서, 및 터치 센서 등 다양한 종류의 센싱 장치 중 적어도 하나를 포함할 수 있다. 센서 모듈은 변환된 데이터를 뉴럴 네트워크 장치에 입력 데이터로서 제공할 수 있다. 예를 들어, 센 서 모듈은 이미지 센서를 포함할 수 있으며, 전자 장치의 외부 환경을 촬영하여 비디오 스트림을 생성하고, 비디오 스트림의 연속하는 데이터 프레임을 뉴럴 네트워크 장치에 입력 데이터로서 순서대로 순 차적으로 제공할 수 있다. 그러나 이에 제한되는 것은 아니며 센서 모듈은 다양한 종류의 데이터를 뉴럴 네트워크 장치에 제공할 수 있다. 통신 모듈은 외부 디바이스와 통신할 수 있는 다양한 유선 또는 무선 인터페이스를 구비할 수 있다. 예컨 대 통신 모듈은 유선 근거리통신망(Local Area Network; LAN), Wi-fi(Wireless Fidelity)와 같은 무선 근 거리 통신망 (Wireless Local Area Network; WLAN), 블루투스(Bluetooth)와 같은 무선 개인 통신망(Wireless Personal Area Network; WPAN), 무선 USB (Wireless Universal Serial Bus), Zigbee, NFC (Near Field Communication), RFID (Radio-frequency identification), PLC(Power Line communication), 또는 3G (3rd Generation), 4G (4th Generation), LTE (Long Term Evolution), 5G (5th Generation) 등 이동 통신망(mobile cellular network)에 접속 가능한 통신 인터페이스 등을 포함할 수 있다. 실시 예에 있어서, 통신 모듈은 외부 디바이스로부터 양자화된 뉴럴 네트워크에 관한 데이터를 수신할 수 있다. 여기서, 외부 디바이스는 도 3의 뉴럴 네트워크 양자화 장치와 같이 방대한 양의 데이터를 기초로 훈 련을 수행하고, 훈련된 뉴럴 네트워크를 고정 소수점 타입으로 양자화하고, 양자화된 뉴럴 네트워크 데이터를 전자 시스템에 제공하는 디바이스일 수 있다. 수신된 양자화된 뉴럴 네트워크 데이터는 메모리에 저 장될 수 있다. 도 8은 본 발명의 실제 실험 결과를 종래 기술과 효능면에서 비교 설명한 도면이다. 도 8에서 SQNR-Bias가 본 발명에 따른 기술을 의미하고, 그 외 Fixed-Bias, Max-Bias, SQNR-Bias-opt는 종래 기술을 의미하며, 도 7의 (a)는 추론 성능 점수에 대한 그래프이고, 도 7의 (b)는 양자화 오버헤드 (quantization overhead)에 대한 실험결과이다. 도 8의 (a)를 통해 본 발명이 종래 기술보다 좋은 추론 성능 점수를 발휘하는 것을 알 수 있고, 도 8의 (b)를 통해 본 발명이 종래 기술보다 양자화 프로세서를 빠르고 정확하게 수행하는 것을 알 수 있다. 지금까지 도면을 통해 본 발명의 일 실시예에 따른 뉴럴 네트워크의 파라미터 양자화 방법에 대해 자세히 알아 보았다. 일 실시예에 따른 뉴럴 네트워크의 파라미터 양자화 방법 및 장치는, SQNR을 극대화하는 방법으로 바이어스를 선택하기 때문에, 자연어 처리 업무 등에서 다른 기법들에 비해 대비 성능 열화가 크지 않는 장점이 존재한다. 또한, 본 발명의 경우 바이어스 탐색 과정을 통해 바이어스를 고정하기 때문에, 매 입력마다 모든 바이어스를 탐색해 찾는 과정(SQNR-Bias-opt)이나 매 입력의 최댓값을 탐색해야하는 Max-Bias에 비해 추론시 양자화 오버헤 드가 작은 장점이 존재한다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세 서, 컨트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨 터, FPA(field programmable array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 운영 체제 상에서 수행되는 하나 이상의 소 프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근,"}
{"patent_id": "10-2022-0113942", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD- ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disK)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2022-0113942", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범 위에 속한다."}
{"patent_id": "10-2022-0113942", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 상세한 설명에서 인용되는 도면을 보다 충분히 이해하기 위하여 각 도면의 간단한 설명이 제공된다. 도 1은 일 실시예에 따른 뉴럴 네트워크 양자화 장치의 하드웨어 구성을 도시한 블록도이다. 도 2는 일 실시예에 따른 미리 훈련된 뉴럴 네트워크를 양자화하여 하드웨어 가속기에 채용하는 것을 설명하기 위한 도면이다. 도 3은 본 발명의 일 실시예에 따른 프로세스의 일부 구성 요소를 도시한 블록도이다. 도 4는 본 발명의 일 실시예에 따른 뉴럴 네트워크의 양자화 장치의 작동 순서를 도시한 순서도이다. 도 5는 본 발명의 일 실시예에 따른 부동 소수점의 바이어스 값을 결정하는 방법을 설명하기 위한 도면이다. 도 6은 본 발명의 다른 실시예에 따라 뉴럴 네트워크 양자화 장치가 SQNR을 진행한 후, 파인 튜닝(Fine Tunin g)을 진행하는 과정을 설명하기 위한 표이다. 도 7은 일 실시예에 따른 전자 시스템의 구성을 나타내는 블록도이다. 도 8은 본 발명의 실제 실험 결과를 종래 기술에 따른 효능과 비교 설명한 도면이다."}
