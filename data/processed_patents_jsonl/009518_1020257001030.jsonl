{"patent_id": "10-2025-7001030", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0023514", "출원번호": "10-2025-7001030", "발명의 명칭": "기계 학습 모델의 추론 동작 난독화", "출원인": "구글 엘엘씨", "발명자": "파르하디 갈라티 나히드"}}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "방법으로서,하드웨어 디바이스에 의해, 추론 동작(inference operation)을 위한 복수의 모델 파라미터를 포함하는 기계 학습 모델을 나타내는 데이터를 수신하는 단계-상기 하드웨어 디바이스는 하나 이상의 프로세싱 엘리먼트에 배열된 계산 유닛의 세트를 포함함-;상기 기계 학습 모델이 상기 하나 이상의 프로세싱 엘리먼트에 의해 실행될 때 상기 기계 학습 모델의 하나 이상의 측정가능한 특성을 난독화하도록 구성된 난독화 동작(obfuscating operation)을 수행하기 위한 명령어를획득하는 단계;상기 계산 유닛의 세트의 제1 부분으로 하여금 상기 기계 학습 모델의 상기 추론 동작을 수행하게 하는 단계;및상기 계산 유닛의 세트의 제2 부분으로 하여금 상기 추론 동작을 수행하는 상기 계산 유닛의 세트의 상기 제1부분과 동시에 상기 난독화 동작을 수행하게 하는 단계를 포함하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 기계 학습 모델은 신경망이고, 상기 난독화 동작은 상기 신경망의 네트워크 계층의 수,상기 신경망의 상기 네트워크 계층의 노드 수, 상기 신경망의 상기 네트워크 계층의 노드에 대한 노드 동작 또는 상기 신경망의 상기 네트워크 계층의 노드와 연관된 가중치 값 중 적어도 하나를 난독화하도록 구성되는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서, 상기 기계 학습 모델의 상기 하나 이상의 측정가능한 특성은 전력 프로파일, 전자기 프로파일 또는 시간 프로파일 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서, 상기 계산 유닛의 세트의 상기 제1 부분의 적어도 서브세트와 상기계산 유닛의 세트의 상기 제2 부분의 대응하는 서브세트는 공통 프로세싱 엘리먼트 내에 위치하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서, 상기 계산 유닛의 세트의 상기 제1 부분의 적어도 서브세트는 제1프로세싱 엘리먼트에 위치하고, 상기 계산 유닛의 세트의 상기 제2 부분의 적어도 서브세트는 상기 제1 프로세싱 엘리먼트와 다른 제2 프로세싱 엘리먼트에 위치하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항 내지 제5항 중 어느 한 항에 있어서, 상기 난독화 동작은 특정 노드에 대한 대응하는 노드 동작과 동시에수행될 네트워크 계층의 상기 특정 노드에 대한 난독화 노드 동작을 포함하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 난독화 노드 동작은 상기 특정 노드의 실제 활성화 함수와 다른 상기 특정 노드에 대한활성화 함수를 지정하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서, 상기 계산 유닛의 세트의 상기 제2 부분으로 하여금 상기 추론 동작을 수행하는 상기 계산 유닛의 세트의 상기 제1 부분과 동시에 상기 난독화 동작을 수행하게 하는 단계는 상기공개특허 10-2025-0023514-3-난독화 동작을 수행하는 전용 프로세싱 엘리먼트에 상기 난독화 동작을 할당하는 단계를 포함하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 전용 프로세싱 엘리먼트는 상기 하드웨어 디바이스에 추가로 통합되고 실질적으로 대응하는 난독화 동작만 수행하도록 구성된 하나 이상의 프로세싱 엘리먼트 또는 계산 유닛을 포함하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항 내지 제9항 중 어느 한 항에 있어서, 상기 계산 유닛의 세트의 상기 제2 부분으로 하여금 상기 추론 동작을 수행하는 상기 계산 유닛의 세트의 상기 제1 부분과 동시에 상기 난독화 동작을 수행하게 하는 단계는:하나 이상의 기계 학습 모델에 대한 추론 동작을 또한 수행하는 하나 이상의 프로세싱 엘리먼트에 난독화 동작을 할당하는 단계; 및상기 하나 이상의 프로세싱 엘리먼트로부터 상기 추론 동작의 서브세트를 상기 하드웨어 디바이스의 다른 프로세싱 엘리먼트로 재할당하는 단계를 포함하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제2항 내지 제10항 중 어느 한 항에 있어서, 상기 신경망은 디바이스 잠금해제를 위한 인간 안면 인식 작업을수행하도록 구성되는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "하나 이상의 컴퓨터와 명령어를 저장하는 하나 이상의 저장 디바이스를 포함하는 시스템으로서, 상기 명령어는하나 이상의 컴퓨터에 의해 실행될 때 상기 하나 이상의 컴퓨터로 하여금 개별의 동작들을 수행하게 하고, 상기동작들은 제1항 내지 제11항 중 어느 한 항의 방법을 포함하는, 시스템."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "명령어를 저장하는 하나 이상의 컴퓨터 판독가능 저장 매체로서, 상기 명령어는 하나 이상의 컴퓨터에 의해 실행될 때 상기 하나 이상의 컴퓨터로 하여금 개별의 동작들을 수행하게 하고, 상기 동작들은 제1항 내지 제11항중 어느 한 항의 방법을 포함하는, 하나 이상의 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "방법으로서,프로세서에서, 기계 학습 모델로 추론 동작을 수행하기 위한 명령어의 세트를 수신하는 단계-상기 명령어의 세트는 상기 추론 동작과 동시에 난독화 동작을 수행하기 위한 적어도 하나의 명령어를 포함함-;상기 프로세서에서, 상기 기계 학습 모델로 상기 추론 동작을 수행하는 단계; 및상기 프로세서에서, 상기 추론 동작과 동시에 난독화 동작을 수행하는 단계를 포함하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 난독화 동작은 상기 난독화 동작이 상기 추론 동작과 동시에 수행될 때 상기 기계 학습모델의 하나 이상의 측정가능한 특성을 난독화하도록 구성되는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항 또는 제15항에 있어서, 상기 기계 학습 모델의 상기 하나 이상의 측정가능한 특성은 전력 프로파일, 전자기 프로파일 또는 시간 프로파일 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항 내지 제16항 중 어느 한 항에 있어서, 상기 기계 학습 모델은 신경망이고, 상기 난독화 동작은 상기 신경망의 네트워크 계층의 수, 상기 신경망의 네트워크 계층의 노드의 수, 상기 신경망의 네트워크 계층의 노드에대한 노드 동작 또는 상기 신경망의 네트워크 계층의 노드와 연관된 가중치 값 중 적어도 하나를 난독화하도록공개특허 10-2025-0023514-4-구성되는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 신경망은 디바이스 잠금해제를 위한 인간 안면 인식 작업을 수행하도록 구성되는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항 또는 제18항에 있어서, 상기 난독화 동작은 특정 노드에 대한 대응하는 노드 동작과 동시에 수행될 네트워크 계층의 상기 특정 노드에 대한 난독화 노드 동작을 포함하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 난독화 노드 동작은 상기 특정 노드의 실제 활성화 함수와 다른 상기 특정 노드에 대한 활성화 함수를 지정하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제14항 내지 제20항 중 어느 한 항에 있어서, 상기 프로세서는 상기 기계 학습 모델의 상기 추론 동작을 수행하기 위해 상기 프로세서의 계산 유닛의 세트의 제1 부분을 할당하고 상기 추론 동작을 수행하는 상기 계산 유닛의 세트의 상기 제1 부분과 동시에 상기 난독화 동작을 수행하기 위해 상기 프로세서의 상기 계산 유닛의 세트의 제2 부분을 할당하도록 구성되는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서, 상기 계산 유닛의 세트의 상기 제1 부분의 적어도 서브세트는 상기 프로세서의 제1 프로세싱엘리먼트에 위치하고, 상기 계산 유닛의 세트의 상기 제2 부분의 적어도 서브세트는 동일한 프로세싱 엘리먼트에 위치하거나 상기 제1 프로세싱 엘리먼트와 다른 제2 프로세싱 엘리먼트에 위치하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제21항 또는 제22항에 있어서, 상기 계산 유닛의 세트의 상기 제2 부분은 상기 난독화 동작을 수행하는 상기 프로세서의 전용 프로세싱 엘리먼트에 위치한 하나 이상의 계산 유닛을 포함하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 상기 전용 프로세싱 엘리먼트는 상기 프로세서에 추가로 통합되고 실질적으로 대응하는 난독화 동작만 수행하도록 구성된 하나 이상의 프로세싱 엘리먼트 또는 계산 유닛을 포함하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제14항 내지 제24항 중 어느 한 항에 있어서, 상기 추론 동작과 동시에 상기 난독화 동작을 수행하는 단계는:상기 난독화 동작을 하나 이상의 기계 학습 모델에 대한 추론 동작을 또한 수행하는 상기 프로세서의 하나 이상의 프로세싱 엘리먼트에 할당하는 단계; 및 상기 추론 동작의 서브세트를 상기 하나 이상의 프로세싱 엘리먼트로부터 상기 프로세서의 다른 프로세싱 엘리먼트로 재할당하는 단계를 포함하는, 방법."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "하나 이상의 컴퓨터와 명령어를 저장하는 하나 이상의 저장 디바이스를 포함하는 시스템으로서, 상기 명령어는하나 이상의 컴퓨터에 의해 실행될 때 상기 하나 이상의 컴퓨터로 하여금 개별의 동작들을 수행하게 하고, 상기동작들은 제14항 내지 제25항 중 어느 한 항의 방법을 포함하는, 시스템."}
{"patent_id": "10-2025-7001030", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "명령어를 저장하는 하나 이상의 컴퓨터 판독가능 저장 매체로서, 상기 명령어는 하나 이상의 컴퓨터에 의해 실행될 때 상기 하나 이상의 컴퓨터로 하여금 개별의 동작들을 수행하게 하고, 상기 개별의 동작들은 제14항 내지제25항 중 어느 한 항의 방법을 포함하는, 하나 이상의 컴퓨터 판독가능 저장 매체.공개특허 10-2025-0023514-5-"}
{"patent_id": "10-2025-7001030", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "컴퓨터 저장 매체에 인코딩된 컴퓨터 프로그램을 포함하여 기계 학습 모델의 추론 동작을 수행하기 위한 방법, 시스템 및 장치. 방법 중 하나는 하드웨어 디바이스에 의해 추론 동작을 위한 복수의 모델 파라미터를 포함하는 기계 학습 모델을 나타내는 데이터를 수신하는 단계를 포함한다. 하드웨어 디바이스는 하나 이상의 프로세싱 엘 리먼트에 배열된 계산 유닛의 세트를 포함한다. 기계 학습 모델이 하나 이상의 프로세싱 엘리먼트에 의해 실행될 때, 기계 학습 모델의 하나 이상의 측정가능한 특성을 난독화하도록 구성된 난독화 동작을 수행하기 위한 명령어 가 획득된다. 계산 유닛의 세트의 제1 부분은 기계 학습 모델의 추론 동작을 수행하게 되고, 계산 유닛의 세트의 제2 부분은 추론 동작을 수행하는 계산 유닛의 세트의 제1 부분과 동시에 난독화 동작을 수행하게 된다."}
{"patent_id": "10-2025-7001030", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서는 일반적으로 기계 학습 모델(machine learning model)의 추론 동작(inference operation)을 수행하 도록 구성된 하드웨어 디바이스에 관한 것이다. 특히, 본 명세서는 하드웨어 디바이스에서 컴파일된(compiled) 기계 학습 모델의 추론 동작을 난독화(obfuscating)하기 위한 기술을 설명한다."}
{"patent_id": "10-2025-7001030", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(AI)은 기계가 보여주는 지능이며 컴퓨터 프로그램이나 기계가 생각하고 학습하는 능력을 나타낸다. 하 나 이상의 컴퓨터를 사용하여 개별의 작업에 대한 기계 학습 모델을 트레이닝하기 위한 계산을 수행할 수 있다. 신경망은 기계 학습 모델의 하위 분야에 속한다. 신경망은 여러 동작, 예를 들어, 벡터 또는 행렬 동작을 나타내는 노드의 하나 이상의 계층을 사용할 수 있다. 하나 이상의 컴퓨터를 구성하여 신경망의 동작 또는 계산을 수행하여 출력, 예를 들어, 수신된 입력에 대한 분 류, 예측 또는 세그먼트화를 생성할 수 있다. 일부 신경망은 출력 계층 외에도 하나 이상의 숨겨진(hidden) 계 층을 포함한다. 각각의 숨겨진 계층의 출력은 네트워크의 다음 계층, 즉 다음 숨겨진 계층 또는 출력 계층에 대 한 입력으로 사용된다. 네트워크의 각각의 계층은 네트워크 파라미터의 개별의 세트의 현재 값에 따라 수신된 입력으로부터 출력을 생성한다. 특별히 설계된 하드웨어 가속기는 신경망에 지정된 동작이나 계산을 포함하여 특정 기능 및 동작을 범용 중앙 프로세싱 유닛(CPU)에 의해 실행되는 동작에 비해 더 빠르고 효율적으로 수행할 수 있다. 하드웨어 가속기는 그 래픽 프로세싱 유닛(GPU), 텐서 프로세싱 유닛(TPU), 비디오 프로세싱 유닛(VPU), 필드 프로그래밍가능 게이트 어레이(FPGA) 또는 주문형 집적 회로(ASIC)를 포함할 수 있다."}
{"patent_id": "10-2025-7001030", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "기계 학습 모델(예를 들어, 신경망)은 적절하게 트레이닝된 후 입력 데이터를 프로세싱하기 위한 추론 동작을 수행하도록 구성된 하드웨어 디바이스에 컴파일 및 전개될 수 있다. 추론 동작은 트레이닝 프로세스 동안 업데 이트되는 신경망의 파라미터에 의해 정의된다. 파라미터는 (i) 신경망의 각각의 네트워크 계층에 있는 노드에 대한 노드 동작(예를 들어, 선형 및 비선형 동작)과 (ii) 신경망의 구조를 정의한다. 예를 들어, 노드 동작을 정의하는 파라미터는 각각의 네트워크 계층에 대한 활성화 함수를 정의하는 파라미터와 네트워크 계층의 노드에 대한 노드 가중치를 정의하는 파라미터를 포함한다. 또 다른 예로, 구조를 정의하는 파라미터(하이퍼 파라미터 라고도 함)는 네트워크 계층의 노드의 수, 기계 학습 모델(예를 들어, 신경망)의 네트워크 계층의 수 또는 이웃 계층 간의 노드 연결(예를 들어, 완전 연결 계층, 컨볼루션 계층 또는 전치 컨볼루션 계층) 중 적어도 하나를 포함한다. 단순화를 위해, 다음 상세한 설명은 신경망에 대해 설명되지만 다른 유형의 기계 학습 모델에도 적용 될 수 있다. 트레이닝된 신경망의 파라미터를 비밀로 유지하는 것이 중요하다. 우선, 신경망, 특히 예측을 생성하는 데 만족 스러운 정확도를 가진 딥 신경망을 트레이닝하려면 상당한 계산 비용과 시간이 필요하다. 또한, 일부 신경망은 얼굴 인식을 통해 장치를 편리하게 잠금 해제하도록 신경망이 구성된 안면 잠금해제 작업과 같은 보안에 민감한 인증과 관련된 애플리케이션을 갖는다. 따라서 악의적인 행위자가 파라미터를 학습하고 이러한 파라미터를 무단 으로 장치 잠금해제하는 데 사용하지 못하도록 신경망의 구조와 파라미터를 해독할 수 없거나 적어도 해독하기 어렵게 유지하는 것이 중요하다. 그러나 트레이닝된 신경망을 \"디코딩\"하는 데는 다양한 기술이 적용될 수 있으며, 특히 신경망이 제3자에 의해 액세스가능한 하드웨어 디바이스(예를 들어, 스마트폰, 스마트워치, 스마트 태블릿 또는 기타 에지 디바이스와 같은 에지 디바이스)에 구현된 경우 더욱 그러하다. 예를 들어, 한 가지 기술은 하드웨어 디바이스가 트레이닝 된 신경망의 추론 동작을 수행할 때 트레이닝된 신경망의 특성을 측정할 수 있다. 보다 구체적으로, 기술은 하 드웨어 디바이스가 추론 동작을 수행할 때 데이터, 예를 들어, 전력 소비, 전자파 또는 시간을 수집하고, 수집 된 데이터를 기반으로 생성된 특성 프로파일을 분석함으로써 신경망 파라미터 및 구조를 결정할 수 있다. 이러 한 기술을 사이드 채널 공격이라고도 한다.본 명세서에 설명된 기술은 하드웨어 디바이스, 예를 들어 에지 하드웨어 디바이스에 구현된 신경망의 보안을 강화할 수 있다. 예를 들어, 설명된 기술은 전개된 신경망의 난독화 동작과 추론 동작을 동시에 수행하도록 구 성된 특수 하드웨어 디바이스를 사용하여 사이드 채널 공격으로부터 방어한다. 이런 방식으로, 설명된 기술은 사이드 채널 공격을 방지하거나 적어도 사이드 채널 공격을 사용하여 전개된 신경망을 해독하는 데 필요한 계산 및/또는 시간 비용을 높일 수 있다. 본 명세서에서 사용되는 용어 \"난독화 동작\"은 일반적으로 하드웨어 디바이스에 의해 전개된 신경망의 기계 학 습 작업(예를 들어, 추론 동작)과 동시에 수행될 때 신경망의 하나 이상의 측정가능한 특성에 변화를 야기시켜 신경망의 하나 이상의 파라미터, 예를 들어 신경망의 네트워크 계층의 수, 네트워크 계층의 노드의 수, 네트워 크 계층의 노드에 대한 노드 동작 또는 네트워크 계층의 노드와 연관된 가중치 중 적어도 하나가 가려지는 동작 을 지칭한다. 다양한 유형의 기계 학습 모델은 모델을 정의하는 다양한 유형의 파라미터를 포함한다는 점에 유 의한다. 본 문서에 설명된 기술은 기계 학습 모델의 측정가능한 특성에 영향을 미치는 임의의 유형의 파라미터 를 난독화할 수 있다. 신경망의 하나 이상의 측정가능한 특성은 일반적으로 하드웨어 디바이스가 신경망에서 추론 동작을 수행할 때 측정가능한 데이터를 지칭한다. 측정가능한 데이터에는 위에서 설명된 바와 같이, 전력 소비량, 시간, 전자기파 방출 또는 기타 측정가능한 데이터와 관련된 데이터 또는 프로파일을 포함할 수 있다. 본 명세서에서 사용되는 용어 \"동시에\"는 일반적으로 하드웨어 디바이스에 의해 난독화 동작과 추론 동작이 모 두 수행되는 공통 기간을 지칭한다. 예를 들어, 공통 기간은 정확히 동일한 기간, 실질적으로 동일한 기간(예를 들어, 서로의 임계 시간 내) 또는 중첩 영역을 갖는 두 개의 서로 다른 기간일 수 있다. 난독화 동작의 예는 신경망에서 노드 동작과 동시에 수행되는 동작일 수 있으며, 신경망에서 실제 동작과 다른 적절한 유형의 선형 또는 비선형 동작을 포함할 수 있다. 일부 구현예에서, 난독화 동작은 때때로 실제 동작을 모방할 수 있다. 예를 들어, 특정 노드의 노드 선형 동작과 동시에 수행되는 난독화 동작은 덧셈, 곱셈 및 이진 동작과 같은 선형 동작일 수도 있다. 또 다른 예로, 특정 노드의 노드 비선형 동작과 동시에 수행되는 난독화 동작은 활성화 함수, 예를 들어 ReLU, Sigmoid, Tanh 또는 기타 적합한 비선형 동작과 같은 비선형 동작일 수도 있다. 또 다른 예로, 난독화 동작은 네트워크 계층의 작동-가중치 곱셈을 모방하는 텐서 감소 동작을 포함할 수 있다. 난독화 동작의 추가 예는 아래에 설명되어 있다. 일반적으로 특수 하드웨어 디바이스는 호스트 또는 기타 디바이스로부터 명령어 데이터를 수신한다. 명령어 데 이터는 추론 동작을 위한 여러 모델 파라미터를 갖는 컴파일된 기계 학습 모델을 포함한다. 명령어 데이터는 컴 파일된 기계 학습 모델로 추론 동작을 수행하도록 하드웨어 디바이스(예를 들어, 하드웨어 디바이스의 하나 이 상의 프로세서)에 지시하는 명령어의 세트를 포함할 수 있다. 명령어의 세트는 일반적으로 기계 학습 모델에 의 해 지정된 추론 동작과 하드웨어 디바이스의 대응하는 계산 컴포넌트에 대한 개별의 명령어를 포함하여 추론 동 작의 적어도 일부를 수행한다. 일부 상황에서, 명령어는 하드웨어 디바이스가 추론 동작과 동시에 난독화 동작 을 수행하도록 하는 적어도 하나의 명령어를 더 포함할 수 있다. 수신된 명령어는 난독화 동작과 난독화 동작의 스케줄링을 포함하지 않을 수 있다는 점에 유의한다. 이러한 예에서, 하드웨어 디바이스는 호스트로부터 명령어 의 세트를 수신하는 것에 대한 응답으로 하드웨어 디바이스의 계산 유닛에 걸쳐 난독화 동작을 수행하기 위한 난독화 동작과 대응하는 스케줄을 생성할 수 있다. 하드웨어 디바이스는 추론 동작의 일부를 프로세싱하도록 구성된 하나 이상의 프로세싱 엘리먼트를 포함할 수 있다. 프로세싱 엘리먼트의 각각은 예를 들어 기계 학습 동작의 성능을 가속화하는 방식으로 기계 학습 계산을 수행하도록 특별히 배열된 여러 계산 유닛을 포함한다. 계산 유닛의 배열의 세부사항은 아래에서 더 자세히 설 명된다. 하드웨어 디바이스는 수신된 명령어를 기반으로 하드웨어 디바이스에 의해 실행될 때 하나 이상의 프로세싱 엘 리먼트로 하여금 기계 학습 모델의 추론 동작과 난독화 동작을 동시에 수행하게 하는 새로운 명령어를 결정할 수 있다. 예를 들어, 하드웨어 디바이스는 (i) 호스트로부터 수신된 명령어를 수정하거나 (ii) 수신된 명령어에 통합될 추가 명령어를 생성함으로써 명령어를 결정하도록 구성될 수 있다. 하드웨어 디바이스는 온-칩 스케줄러, 제어기, 코어 관리자 또는 명령어를 결정하도록 구성된 다른 적합한 관리 컴포넌트와 같은 관리 컴포넌트를 포함할 수 있다. 결정된 명령어는 하나 이상의 프로세싱 엘리먼트에 의해 실 행될 때 계산 유닛의 세트의 제1 부분으로 하여금 신경망의 추론 동작을 수행하게 하는 명령어를 포함할 수 있 다. 또한, 결정된 명령어는 하나 이상의 프로세싱 엘리먼트에 의해 실행될 때 계산 유닛의 세트의 제2 부분으로하여금 추론 동작의 수행과 동시에 난독화 동작을 수행하게 하는 명령어를 포함할 수 있다. 관리 컴포넌트가 호스트로부터 수신된 명령어를 수정하도록 구성된 상황에서, 호스트에 의해 생성된 명령어는 추론 동작의 다른 부분을 다른 프로세싱 엘리먼트에 할당하는 스케줄 데이터를 포함한다. 관리 컴포넌트는 일반 적으로 추론 동작과 난독화 동작을 다른 계산 유닛에 재할당한다. 예를 들어, 서버로부터 수신된 명령어에 의해 표시된 추론 동작의 제1 부분을 수행하도록 할당된 16개의 계산 유닛이 있는 프로세싱 엘리먼트의 경우, 관리 컴포넌트는 수신된 명령어를 수정하고, 예를 들어, 16개의 계산 유닛 중 하나 이상을 난독화 동작을 수행하도록 할당하고, 대응하는 추론 동작을 예를 들어 하나 이상의 다른 프로세싱 엘리먼트에 위치한 다른 계산 유닛에 재 할당한다. 또 다른 예로, 프로세싱 엘리먼트는 수신된 명령어를 수정하여 프로세싱 유닛과 상이한 다른 컴포넌 트(예를 들어, 전용 프로세싱 엘리먼트)에게 난독화 동작을 수행하도록 지시할 수 있다. 관리 컴포넌트가 호스트로부터 수신된 명령어에 통합될 새로운 명령어를 생성하도록 구성된 상황에서. 수신된 명령어는 추론 동작 할당과 관련된 스케줄 데이터를 포함하지 않는다. 오히려, 관리 컴포넌트는 예를 들어 신경 망의 추론 동작을 수행하기 위한 프로세싱 엘리먼트의 계산 유닛의 제1 부분과 난독화 동작을 수행하기 위한 프 로세싱 엘리먼트의 계산 유닛의 제1 부분과 다른 제2 부분을 나타내는 새로운 명령어를 생성하도록 구성된다. 일부 구현예에서, 새로운 명령어는 해당 추론 동작을 수행하기 위한 프로세싱 엘리먼트와 난독화 동작을 수행하 기 위한 프로세싱 엘리먼트와 다른 컴포넌트를 나타낸다. 명령어를 수정하는 세부사항은 아래에 설명되어 있다. 본 명세서에 설명된 주제는 다음 이점 중 하나 이상을 실현하도록 특정 실시예에서 구현될 수 있다. 난독화 동 작과 추론 동작을 동시에 수행하기 위한 특수 하드웨어 디바이스를 사용하면 하드웨어 디바이스에 전개된 신경 망의 파라미터가 해독되는 것을 효율적으로 방지할 수 있다. 보다 구체적으로, 난독화 동작은 하드웨어 디바이 스에 의해 실행되는 신경망의 하나 이상의 측정가능한 특성에 변화를 일으킬 수 있으므로, 측정가능한 특성에 기초하여 대응하는 신경망 파라미터를 해독하는 것이 어려워지고 시간과 리소스가 더 많이 소모된다. 따라서 설 명된 기술은 잠재적으로 민감한 기계 학습 데이터의 누출을 방지하여 데이터 보안을 강화한다. 본 명세서에 설명된 주제는 모델 컴파일 관점에서 더욱 유리하다. 예를 들어, 설명된 기술은 기존 컴파일 동작 을 변경하지 않습니다. 시스템 또는 호스트는 기존 신경망을 수정하거나 및/또는 이전에 컴파일된 신경망을 다 시 컴파일할 필요가 없다. 오히려 이전에 컴파일된 신경망(예를 들어, 기계 판독가능 이진 프로파일) 및 대응하 는 명령어가 하드웨어 디바이스에 직접 제공될 수 있다. 특수 하드웨어 디바이스에서 난독화 동작을 스케줄링하 고 수행하기 위해 하드웨어 디바이스는, 런타임에서, 하드웨어 디바이스의 컴포넌트를 조정하기 위한 명령어를 조정하여 추론 동작과 난독화 동작을 동시에 수행할 수 있다. 이런 방식으로, 설명된 기술은 신경망 모델을 업 데이트하고 컴파일하기 위한 상당한 연구 및 개발 시간을 절약한다. 또한 개발 프로세스에서 난독화 동작을 포 함하도록 도입될 수 있는 기계 학습 모델의 오류를 방지한다. 이러한 양태 및 기타 양태의 다른 구현예는 컴퓨터 저장 디바이스에 인코딩된 방법의 동작을 수행하도록 구성된 대응하는 시스템, 장치 및 컴퓨터 프로그램을 포함한다. 하나 이상의 컴퓨터의 시스템은 동작 시 시스템이 작동 을 수행하게 하는 시스템에 설치된 소프트웨어, 펌웨어, 하드웨어 또는 이들의 조합으로 인해 구성될 수 있다. 하나 이상의 컴퓨터 프로그램은 데이터 프로세싱 장치에 의해 실행될 때 장치로 하여금 작동을 수행하게 하는 명령어로 인해 구성될 수 있다. 본 명세서에 기술된 주제의 하나 이상의 구현예의 세부사항은 첨부 도면 및 아래 설명에 명시되어 있다. 본 주 제의 다른 잠재적인 피처, 양태 및 이점은 설명, 도면 및 청구항에서 명확해질 것이다."}
{"patent_id": "10-2025-7001030", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 설명된 주제는 기계 학습 동작, 예를 들어 기계 학습 모델에 대한 추론 동작을 가속화하고 추론 동 작을 수행할 때 난독화 동작을 동시에 수행함으로써 추론 동작을 난독화하도록 구성된 여러 컴퓨팅 유닛을 갖는 특수 하드웨어 디바이스에 관한 것이다. 설명된 하드웨어 디바이스는 스마트폰, 스마트 태블릿, 스마트 워치 또 는 기타 적합한 에지 디바이스와 같은 에지 장치에 전개된 하드웨어 프로세서(processor), 예를 들어 하드웨어 가속기일 수 있다. 하드웨어 디바이스는 하나 이상의 프로세싱 엘리먼트를 포함할 수 있으며, 각각의 프로세싱 엘리먼트는 하나 이상의 계산 유닛을 포함할 수 있다. 하드웨어 디바이스는 하드웨어 디바이스의 다른 프로세싱 엘리먼트 또는 각각의 프로세싱 엘리먼트의 계산 유닛의 다른 부분에 의해 수행되도록 난독화 동작 및 추론 동 작을 스케줄링할 수 있다. 하드웨어 컴퓨팅 시스템의 각각의 컴퓨팅 유닛은 자체 포함되며 다층 신경망의 주어 진 계층에 필요한 계산의 적어도 일부를 독립적으로 실행할 수 있다. 하나의 예시적 기계 학습 모델은 추론 동작을 수행하도록 트레이닝된 신경망일 수 있다. 트레이닝된 신경망은 신경망을 정의하는 여러 파라미터와 신경망의 추론 동작을 포함한다. 신경망의 파라미터는 신경망의 네트워크 계층의 수, 신경망의 노드의 수, 각각의 노드에 대한 노드 동작 및/또는 각각의 노드의 노드 가중치를 포함할 수 있다. 신경망은 신경망의 추론 동작을 수행함으로써 입력을 프로세싱하기 위한 추론을 계산한다. 특히, 신경 망의 계층은 각각 개별의 노드 동작과 가중치를 갖는 여러 노드를 갖는다. 노드 동작은 선형 동작(예를 들어, 곱셈 및 덧셈) 또는 비선형 동작(예를 들어, ReLu 활성화 함수, Tanh 함수 및 시그모이드 함수를 포함한 활성화 동작)을 포함할 수 있다. 일부 구현예에서, 파라미터는 이웃 네트워크 계층 사이의 노드 연결, 예를 들어 완전 연결 계층, 컨볼루션 계층 또는 전치 컨볼루션 계층을 결정하는 데이터를 더 포함한다. 하드웨어 디바이스는 추론 동작의 상이한 부분을 여러 계산 유닛에 걸쳐 분산하거나 할당함으로써 신경망의 추 론 계산을 수행할 수 있다. 계산 유닛의 하나의 예는 각각 계산 유닛 또는 프로세싱 엔진 및/또는 하나 이상의 캐시 및 스위치를 갖는 타일(tile)이다. 신경망 계층에 대해 수행되는 예시적 계산 프로세스에는 입력 활성화를 포함하는 입력 텐서와 가중치를 포함하는 파라미터 텐서의 곱을 포함할 수 있다. 이러한 계산은 하나 이상의 사 이클에서 입력 활성화를 가중치와 곱하고 많은 사이클에 걸쳐 곱의 누적을 수행하는 것을 포함한다. 네트워크 계층에 대한 계산 결과는 출력 버스에 기록되고 메모리에 저장될 수 있다. 전개된 신경망의 추론 동작을 수행할 때, 하드웨어 디바이스는 신경망의 하나 이상의 측정가능한 특성을 생성한 다. 사이드 채널 공격과 같은 다양한 기술을 사용하여 트레이닝된 신경망의 파라미터를 역엔지니어링할 수 있다. 스마트폰, 스마트 워치, 스마트 태블릿 또는 기타 적합한 에지 장치와 같은 에지 장치에 하드웨어 디바이 스가 포함된 일부 상황에서, 하드웨어 디바이스를 사용하여 테스트 동작을 반복적으로 수행하고 신경망의 파라 미터를 결정할 수 있다. 신경망 파라미터를 기밀로 유지하는 것은 여러 가지 이유로 바람직하다. 하나의 예는 보안 관점에서이다. 신경 망은 장치를 편리하게 잠금해제(unlocking)하기 위해 안면 인식 작업을 수행하도록 구성될 수 있다. 제3자가 신 경망을 성공적으로 역 엔지니어링하고 안면 잠금해제 메커니즘을 속이는 방법을 알아낸 경우 안면 잠금 해제 메 커니즘을 사용하는 것은 안전하지 않다. 예를 들어, 악의적인 행위자(malicious actor)는 적대적 공격을 사용하 여 행위자에게 권한이 없는 장치의 잠금을 해제하기 위해 신경망을 속일 수 있다. 설명된 기술은 신경망의 추론 동작을 난독화함으로써 상기 언급된 보안 문제를 해결할 수 있다. 보다 구체적으 로, 하드웨어 디바이스는 하드웨어 디바이스에 의해 실행될 때 하드웨어 디바이스의 상이한 컴포넌트로 하여금 신경망에서 추론 동작과 난독화 동작을 동시에 수행하게 하는 명령어를 발행하도록 구성된다. 동시에 난독화 동 작을 수행함으로써, 하드웨어 디바이스는 신경망의 여러 측정가능한 특성 중 적어도 하나를 변경할 수 있다. 이 런 식으로, 하드웨어는 하드웨어 디바이스에 의해 수행되는 실제 기계 학습 동작의 측정가능한 특성을 효율적으 로 숨기거나 마스크할 수 있고, 마스크되거나 변경된 측정가능한 특성을 분석함으로써 복호화(deciphering) 프 로세스를 불가능하거나 비실용적이거나, 마지막으로 훨씬 더 어렵게 만들 수 있다. 난독화 동작을 수행하는 세 부사항이 아래에 설명되어 있다. 도 1은 하드웨어 디바이스를 포함하는 예시적 시스템 100의 블록도이다. 하드웨어 디바이스는 예를 들어 하나 이상의 네트워크를 통해 호스트와 통신가능하게 결합된다. 일반적으로, 하드웨어 디바이스(10 2)는 호스트로부터 명령어 또는 데이터를 수신하고 데이터를 호스트에 다시 제공하도록 구성된다. 일 반적으로, 호스트는 트레이닝된 기계 학습 모델을 기계 판독가능 프로그램(예를 들어, 이진 코드)으로 컴파일하 도록 구성된다. 이진 코드는 일반적으로 트레이닝된 기계 학습 모델을 정의하는 모든 파라미터를 포함한다. 예를 들어, 이진 코드는 컴파일된 신경망의 네트워크 계층 수, 각각의 네트워크 계층의 유형, 각각의 네트워크 계 층의 노드 수, 각각의 네트워크 계층의 각각의 노드에 대한 노드 동작, 각각의 네트워크 계층의 각각의 노드에 대해 결정된 노드 가중치 및 계층 간 연결을 지정한다. 이진 코드는 기계 학습 모델의 다른 파라미터를 포함할 수 있다. 호스트는 또한 하드웨어 디바이스에 의해 실행될 때 하드웨어 디바이스로 하여금 이진 코드에 의해 지정된 추론 동작을 수행하게 하는 명령어를 생성한다. 일부 구현예에서, 호스트는 추론 동작을 수행 하기 위한 스케줄, 예를 들어, 하드웨어 디바이스의 다른 계산 컴포넌트에 대한 추론 동작의 할당을 나타 내는 데이터 및 추론 동작을 수행하기 위한 시퀀스를 생성할 수 있다. 일반적으로, 호스트에 의해 생성된 명령어는 기계 학습 모델의 파라미터를 난독화하기 위한 특정 난독화 동작을 포함하지 않을 수 있다. 대신, 난 독화 동작은 하드웨어 디바이스에 의해 결정, 스케줄링 및 수행되며, 호스트로부터 수신된 명령어를 수정하거나 추론 동작과 동시에 수행될 난독화 동작을 포함하는 새로운 명령어를 생성하는 것은 하드웨어 디바 이스다. 일부 구현예에서, 호스트에 의해 생성되어 하드웨어 디바이스로 발송되는 명령어 데이터는 하드웨어 디바이스가 추론 동작과 동시에 난독화 동작을 수행하도록 하는 적어도 하나의 명령어를 포함하는 명령어의 세 트를 포함할 수 있다. 예를 들어, 적어도 하나의 명령어는 하드웨어 디바이스에 \"보안 모드\"에서 기계 학습 모 델의 추론 동작을 수행하도록 지시할 수 있으며, 여기서 하드웨어 디바이스는 하드웨어 디바이스에 의해 수행되 는 추론 동작과 동시에 하나 이상의 난독화 동작을 수행한다. 또 다른 예로, 적어도 하나의 명령어를 수신한 후, 하드웨어 디바이스는 하드웨어 디바이스에 전개된 기계 학습 모델을 사용하는 하나 이상의 애플리케이션이 기계 학습 모델의 추론 동작이 보안 모드에서 수행되도록 요청할 수 있다는 통지받을 수 있다. 하드웨어 디바이 스는 애플리케이션의 요청을 수신하면 특정 난독화 동작을 결정할 수 있다. 일부 구현예에서, 호스트에 의해 생성되고 하드웨어 디바이스로 발송되는 명령어 데이터는 난독화 동 작을 수행하라는 명령어 없이 기계 학습 모델을 포함할 수 있다. 이러한 예에서, 하드웨어 디바이스는 본 명세서에 설명된 바와 같이 추론 동작과 동시에 난독화 동작을 수행할지 여부를 결정할 수 있다. 호스트로부터 수신된 명령어에 의해 지정된 추론 동작을 수행한 후, 하드웨어 디바이스는 호스트 에 계산 결과와 같은 데이터를 제공할 수 있다. 계산 결과는 네트워크 계층의 계층 출력의 일부 또는 두 개 이상의 네트워크 계층에 대한 계층 출력을 포함할 수 있다. 하드웨어 디바이스는 하드웨어 프로세서, 예를 들어 그래픽 프로세싱 유닛(GPU), 비전 프로세싱 유닛(VPU), 텐 서 프로세싱 유닛(TPU) 또는 기타 적절한 하드웨어 가속기와 같은 하드웨어 가속기일 수 있다. 추론 동작 수행 을 가속화하기 위해, 하드웨어 디바이스는 하나 이상의 프로세싱 엘리먼트(104A-N)를 포함하고, 각각의 프 로세싱 엘리먼트(104A-N)는 하나 이상의 계산 유닛(106A-N)을 포함하는데, 이는 간결하게 계산 유닛이라고 도 한다. 계산 유닛은 각각 할당된 추론 동작(예를 들어, 네트워크 계층의 노드 또는 네트워크 계층을 통 한 노드에 대한 선형 또는 비선형 동작)을 수행하기 위한 독립형 유닛이다. 각각의 프로세싱 엘리먼트에 대한 프로세싱 엘리먼트(104A-N) 및 대응하는 계산 유닛의 수는 상이한 계산 요구사항에 따라 달라질 수 있다. 예를 들어, 하드웨어 디바이스는 각각 4, 8, 16개 이상의 계산 유닛을 갖는 4, 8, 16개 이상의 프로세싱 엘리먼 트를 포함할 수 있다. 또한, 상이한 하드웨어 디바이스는 프로세싱 엘리먼트(104A-N)에 대해 상이한 배열 및 상호연결을 가질 수 있다. 호스트로부터 명령어 및/또는 데이터를 수신한 후, 하드웨어 디바이스는 신경망에서 할당된 추론 동 작의 파라미터를 나타내는 데이터를 메모리에 저장할 수 있다. 메모리의 세부사항은 아래에 설명되어 있다. 파라미터는 하드웨어 디바이스에 할당된 노드의 수와 네트워크 계층의 수, 노드 가중치 및 이전 네 트워크 계층으로부터의 대응하는 입력 활성화를 포함할 수 있다. 일부 구현예에서, 하드웨어 디바이스는 메모리에 명령어를 저장할 수 있다. 관리 컴포넌트는 \"표준 모드(standard mode)\" 또는 \"보안 모드(secured mode)\"에서 추론 동작을 수행할지 여부를 결정하도록 구성된다. 관리 컴포넌트는 신경망의 특성 또는 애플리케이션에 따라 동작을 수행하기 위한 다양한 모드를 결정할 수 있다. 다시 말해, 관리 컴포넌트는 기계 학습 모델에 대해 보안 모드 또는 일반 모드를 사용하여 기계 학습 모드의 동작을 수행하도록 선택할 수 있다. 예를 들어, 관리 컴포넌트는 신경망이 상당한 시간과 비용(예를 들어, 트레이닝을 위한 계산 비용)이 필요한 거대한 딥 신경망이고 하드웨어 디바이스가 에지 디바이스 내부에 있는 경우 보안 모드에서 동작을 수행하도록 결정할 수 있다. 이러한 예 에서, 관리 컴포넌트는 크기(예를 들어, 모델의 크기를 임계치와 비교함으로써) 및/또는 트레이닝 시간(예를 들어, 모델을 학습하는 데 걸리는 시간을 임계값과 비교)에 기초하여 모드를 선택할 수 있다(예를 들어, 모 델을 트레이닝하는 데 걸리는 시간을 임계치와 비교함으로써, 이러한 정보는 예를 들어 관리 컴포넌트로 송신되는 메타데이터에 포함될 수 있음). 또 다른 예로, 관리 컴포넌트는 신경망이 보안에 민감한 애플리 케이션, 예를 들어 얼굴 잠금해제, 음성 잠금해제, 서명 확인, 개인 정보 액세스 또는 기계 학습 모델을 사용한 예측 또는 기타 보안에 민감한 애플리케이션에 사용되는 경우 보안 모드에서 신경망의 동작을 수행하도록 결정 할 수 있다. 이러한 예에서, 보안에 민감한 기계 학습 모델을 사용하는 애플리케이션은 이러한 기계 학습 모델 의 동작을 수행할 때 하드웨어 디바이스에 보안 모드에서 동작하도록 요청할 수 있다. 일부 구현예에서, 관리 컴포넌트에 발송된 요청은 기계 학습 모델이 민감한지 여부를 나타내거나 기계 학습 모델의 동작을 수행하 는 데 사용될 모드(예를 들어, 보안 또는 일반)를 나타내는 라벨 또는 메타데이터를 포함할 수 있다. 반면, 관 리 컴포넌트는 요청을 수신하고 하나 이상의 기계 학습 모델의 동작을 수행하기 위한 모드(예를 들어, 보 안 또는 일반)를 결정하도록 구성된 애플리케이션 프로그래밍 인터페이스(API)를 포함할 수 있다. 본 명세서에서 사용되는 용어 \"표준 모드\"는 일반적으로 하드웨어 디바이스가 신경망의 할당된 부분의 측 정가능한 특성을 숨기거나 마스크하기 위해 난독화 동작을 수행하지 않는 모드를 지칭한다. 본 명세서에서 사용 되는 용어 \"보안 모드\"는 일반적으로 하드웨어 디바이스가 신경망의 할당된 부분의 측정가능한 특성을 숨 기거나 마스크하기 위해 난독화 동작을 수행하는 모드를 지칭한다. 난독화 동작의 예는 도 3과 관련하여 설명된 다. 관리 컴포넌트가 표준 모드에서 추론 동작을 수행하기로 결정하는 경우, 관리 컴포넌트는 수신된 명 령어(예를 들어, 수신된 명령어에 대한 수정 없이)를 다른 프로세싱 엘리먼트(104A)에 브로드캐스트할 수 있다. 추론 동작에 대한 명령어 및 파라미터는 데이터 버스를 따라 각각의 프로세싱 엘리먼트(104A)의 각각의 계산 유 닛에 브로드캐스트된다. 프로세싱 엘리먼트(104A-N)에서 상이한 계산 유닛(106A-N)을 통해 명령어와 데이 터를 송신하는 세부사항은 도 2와 관련하여 설명되어 있다. 일반적으로, 프로세싱 엘리먼트에서 이용가능 한 모든 계산 유닛은 일반적으로 프로세싱 엘리먼트의 계산 능력(computation power)과 동작이 수행되는 속도를 최대화하기 위해 추론 동작의 개별의 부분을 수행한다. 그러나 일부 구현예에서, 호스트(또는 관리 컴포넌트)로부터의 명령어 또는 스케줄은 하나 이상의 프로세싱 엘리먼트에서 계산 유닛의 일부 (예를 들어, 하나 이상)를 지정하여 추론 동작을 수행할 수 있다. 관리 컴포넌트가 \"보안 모드\"에서 추론 동작을 수행하기로 결정하는 경우, 관리 컴포넌트는 수신된 명령어를 수정하여 수정된 명령어를 생성할 수 있으며, 이는 하드웨어 디바이스에 의해 실행될 때 하드웨 어 디바이스의 하나 이상의 계산 유닛으로 하여금 난독화 동작을 수행하게 한다. 수신된 명령어를 수정하 기 위해, 관리 컴포넌트는 먼저 호스트로부터 수신된 명령어에 스케줄이 있는지 결정할 수 있다. 스케줄이 존재하지 않는다고 결정하는 것에 대한 응답하여, 관리 컴포넌트는 할당된 추론 동작을 수행하기 위한 프로세싱 엘리먼트의 계산 유닛의 제1 부분과 난독화 동작을 수행하기 위한 프로세싱 엘리먼트 의 계산 유닛의 제2 부분을 지정하는 스케줄을 생성할 수 있다. 일부 구현예에서, 관리 컴포넌트 에 의해 생성된 스케줄은 난독화 동작을 수행하기 위해 계산 유닛과 다른 상이한 계산 컴포넌트를 지정할 수 있다. 다른 계산 컴포넌트는 멀티플렉서, 로직 유닛, 덧셈기, 곱셈 유닛 또는 다른 계산 컴포넌트일 수 있다. 수신된 명령어에 기존 스케줄이 존재한다고 결정하는 것에 응답하여, 관리 컴포넌트는 수신된 명령어에 따 라 대응하는 추론 동작을 수행하도록 원래 스케줄링된 하나 이상의 계산 유닛을 난독화 동작을 수행하도록 재할당하고, 다른 계산 유닛에 의해 하나 이상의 다른 프로세싱 엘리먼트에서 수행될 대응하는 추론 동작을 재할당함으로써 일정을 수정할 수 있다. 일부 구현예에서, 프로세싱 엘리먼트 또는 프로세싱 엘리먼트의 계산 유닛은 하드웨어 디바이스 또는 하드웨어 디바이스를 포함하고 난독화 동작을 수행하는 데 전용인 에지 디 바이스에 추가된 추가 엘리먼트일 수 있다. \"전용된\"이라는 용어는 일반적으로 하드웨어 디바이스에 추가로 통 합되고(예를 들어, 추론 동작을 수행하기 위한 하드웨어 디바이스의 다른 엘리먼트 또는 유닛에 추가하여) 실질 적으로 난독화 동작만 수행하고 전개된 기계 학습 모델과 연관된 추론 동작은 수행하지 않도록 구성된 하나 이 상의 프로세싱 엘리먼트 또는 계산 유닛을 의미한다. 난독화 동작을 수행하기 위한 전용으로 프로세싱 엘리먼트 또는 계산 유닛은 예를 들어 프로세서, 곱셈 유닛, 멀티플렉서, 벡터 감산 유닛, 로직 게이트 또는 기타 적합한 프로세싱 엘리먼트 또는 계산 유닛을 포함할 수 있다. 수정된 명령어는 관리 컴포넌트에 의해 대응하는 프로세싱 엘리먼트(104A-N)에 브로드캐스트된다. 수정된 명령어는, 프로세싱 엘리먼트(104A-N)의 대응하는 계산 유닛(106A-N)에 의해 실행될 때, 계산 유닛의 제1 부분이 추론 동작을 수행하게 하고 계산 장치의 제2 부분이 추론 동작을 수행하는 계산 유닛의 세트의 제1 부분과 동시에 난독화 동작을 수행하게 할 수 있다. 일반적으로 난독화 동작은 신경망의 측정가능한 특성을 숨기거나 마스크할 수 있는 임의의 동작일 수 있다. 다 시 말해, 난독화 동작은 하드웨어 디바이스 및/또는 하드웨어 디바이스를 포함하는 에지 디바이스가 하나 이상의 측정가능한 특성을 생성하거나 조정하도록 하는 동작을 포함할 수 있다. 측정가능한 특성은 하나 이상의 추론 동작에 대한 전자기 프로파일, 하나 이상의 추론 동작을 수행하기 위한 시 간 프로파일 또는 추론 동작을 수행하는 계산 유닛에 대한 전력 소비 프로파일을 포함한다. 일부 구현예에서, 측정가능한 특성은 하나 이상의 추론 동작을 수행하기 위한 소리 프로파일 및/또는 온도 프로파일을 포함할 수 있다. 전자기 프로파일은 예를 들어 하드웨어 디바이스가 기계 학습 모델의 동작을 수행할 때 하드웨어 디바이 스의 커패시터 전하에 대한 전자기 복사 측정치를 나타낼 수 있다. 일부 구현예에서, 특성 프로파일은 수평 축 이 시간을 나타내고 수직 축이 특정 특성(예를 들어, 전자기 복사, 전력 소비, 소리 또는 온도)을 나타내는 그 래프로 표현될 수 있다. 기계 학습 모델을 실행하는 동안 시간에 따른 이러한 특성의 변화에 대한 다른 표현이 또한 예를 들어, 표, 벡터 등의 형태로 프로파일을 나타내는 데 사용될 수 있다. 일부 구현예에서, 난독화 동작은 시간 기간 동안 동시에 수행되는 대응하는 추론 동작을 모방할 수 있다. 예를 들어, 하나 이상의 할당된 계산 유닛이 노드 활성화 함수를 사용하여 기계 학습 모델의 출력 활성화를 계산하는 경우, 수정된 명령어는 하나 이상의 다른 계산 유닛에 기계 학습 모델의 출력 활성화를 계산하는 계산 유닛의 측정가능한 특성을 난독화하기 위해 동시에 상이한 난독화 활성화 함수를 수행하도록 지시할 수 있다. 추론 동 작과 난독화 동작은 모두 다른 활성화 함수와 관련이 있으므로, 조합된 데이터 프로파일(예를 들어, 전력 소비 프로파일)은 추론 동작만 수행하는 경우와 다르다. 따라서 측정가능한 특성은 신경망의 진정한 측정가능한 특성 과 상이하며, 역엔지니어링된 신경망 파라미터는 진정한 신경망 파라미터와 다를 수 있다. 일부 구현예에서, 난독화 동작은 시간 기간 동안 동시에 수행되는 대응하는 추론 동작과 무관할 수 있지만(예를 들어, 독립적일 수 있음), 난독화 동작을 수행하면 하드웨어 디바이스의 측정가능한 모든 데이터가 무의미 해질 수 있다. 예를 들어, 추론 동작이 행렬 축소와 관련된 경우, 난독화 동작은 특정 로직 동작 또는 스칼라 덧셈 또는 곱셈이 될 수 있으므로 진정한 측정가능한 프로파일이 변경되어 패턴이나 피처가 손실되고, 이는 신 경망의 진정한 파라미터를 결정하는 데 무의미해진다. 추론 동작의 계산 결과는 메모리에 저장되고, 계산 결과에 의존하는 다른 추론 동작을 위해 호스트에 제공된다. 그러나 난독화 동작에 대한 계산 결과는 어떠한 추론 동작에서도 사용되지 않는다. 일부 구현예에서, 난독화 결과는 어떠한 메모리에도 기록되지 않고 폐기된다. 대안적으로, 난독화 결과는 추론 동작을 위한 다른 계산 컴포넌트가 메모리 유닛에 저장된 데이터를 수신하지 않도록 메모리 유닛에 기록된다. 도 2는 하드웨어 디바이스의 예시적인 프로세싱 엘리먼트를 예시한다. 프로세싱 엘리먼트는 컴파일된 신경망의 추론 동작의 적어도 일부를 프로세싱하도록 구성된다. 도 2에 도시된 바와 같이, 프로세싱 엘리먼트는 일반적으로 관리 컴포넌트(예를 들어, 제어기/스케줄 러/코어 관리자) 및 제1 타일 세트와 제2 타일 세트를 포함하는 여러 타일(220 내지 234)을 포함한다. 관리 컴포넌트는 호스트로부터 수신된 명령어를 실행하고, 선택적으로 수신된 명령어를 실행되 도록 수정하도록 구성된다. 관리 컴포넌트는 도 1의 관리 컴포넌트와 동일할 수 있다. 관리 컴포넌트 는 도 1에 도시된 바와 같이 하드웨어 디바이스에 있는 모든 계산 컴포넌트에 대한 명령어를 결정하는 마 스터 관리 컴포넌트가 될 수 있다. 대안적으로 또는 이에 추가하여, 각각의 프로세싱 엘리먼트(예를 들어, 프로 세싱 엘리먼트)는 프로세싱 엘리먼트에서 수행될 동작을 스케줄링하기 위한 명령어를 결정하도록 구성된 개별의 제어기를 가질 수 있다. 간단히 하기 위해, 관리 컴포넌트는 다음 설명에서 제어기라고도 한 다. 다수의 타일(220 내지 234)은 시퀀스에 따라 데이터 버스에 의해 서로 통신가능하게 결합된다. 데이터 버 스는 서로 다른 타일에서 수행되는 서로 다른 동작을 나타내는 개별의 명령어, 서로 다른 타일에서 동작을 수행하는 데 사용되는 입력 데이터, 서로 다른 타일에서 생성된 입력 데이터에 대한 결과를 통신하기 위한 서로 다른 유형의 데이터 버스를 포함한다. 예를 들어, 데이터 버스는 제어기로부터 시작하여 타일(112, 114)을 링 형태로 순차적으로 제어기로 연결하는 버스 데이터 경로를 통해 통신 커플링을 제공하는 링 버 스를 포함할 수 있다. 일부 구현예에서, 데이터 버스은 수평 및 수직 차원에서 각각의 타일을 대응하는 이 웃 타일에 결합하거나 연결하는 통신 경로를 제공하는 메시 버스를 포함할 수 있다. 메시 버스는 인접한 타일의하나 이상의 메모리 유닛 사이에 입력 활성화 양을 전송하는 데 사용될 수 있습니다. 일반적으로 타일(220, 222, 224, 226, 228, 230, 232 또는 234)은 프로세싱 엘리먼트 내의 코어 컴포넌트 이며 추론 계산을 수행하기 위한 초점이다. 각각의 타일은 할당된 추론 동작을 수행하기 위한 자체 포함형 계산 컴포넌트다. 프로세싱 엘리먼트의 이러한 타일 중 하나 이상은 수신된 명령어에 따라 프로세싱 엘리먼트 에 할당된 추론 동작을 수행한다. 예를 들어, 프로세싱 엘리먼트에서 계산 유닛을 최대한 활용하기 위해, 각각의 타일은 프로세싱 엘리먼트의 다른 타일과 협력하여 다중 계층 신경망의 하나 이상의 계층에 걸쳐 계산을 가속화한다. 도 2에 도시된 바와 같이 프로세싱 엘리먼트는 예시를 쉽게 하기 위해 데이터 버스 에 의해 서로 결합된 8개의 계산 유닛(예를 들어, 타일(220, 222, 224, 226, 228, 230, 232, 234))을 갖 지만, 프로세싱 엘리먼트는 서로 결합된 다른 수의 계산 유닛, 예를 들어 4, 16, 32 또는 다른 적절한 수 를 포함할 수 있다. 제어기는 수신된 명령어를 수정하거나 수신된 명령어에 통합될 새로운 명령어를 추가하도록 구성되어, 수 정된 명령어가 프로세싱 엘리먼트에 의해 실행될 때, 일부 프로세싱 엘리먼트의 하나 이상의 계산 유닛(예 를 들어, 타일)이 난독화 동작을 수행하고 하나 이상의 다른 계산 유닛이 신경망에서 추론 동작을 수행하도록 한다. 예를 들어, 제1 타일 세트의 타일(220, 224)은 제어기에 의해 난독화 동작을 수행하도록 지시 받을 수 있고, 다른 타일(222, 226, 228, 230, 232 및 234)은 제어기에 의해 신경망의 추론 동작을 수행 하도록 지시받을 수 있다. 난독화 동작을 수행하기 위해 계산 컴포넌트(예를 들어, 타일 또는 기타 컴포넌트)를 할당하는 것은 도 3 내지 5와 관련하여 더 자세히 설명되어 있다. 일부 구현예에서, 호스트에 의해 생성된 명령어는 상이한 컴포넌트 유닛(예를 들어, 다른 타일)을 사용하여 추 론 동작을 수행하기 위한 스케줄을 포함한다. 예를 들어, 수신된 명령어는 추론 동작의 겹치지 않는 부분의 세 트와 대응하는 겹치지 않는 부분을 수행하도록 할당된 프로세싱 유닛 및 대응하는 계산 유닛의 세트를 포함할 수 있다. 이러한 상황에서, 제어기는 수신된 명령어에 의해 원래 할당되어 난독화 동작을 수행하기 위한 대응하는 추론 동작을 수행하는 특정 프로세싱 엘리먼트의 하나 이상의 타일을 결정할 수 있다. 제어기는 또한 하나 이상의 타일에 원래 할당된 대응하는 추론 동작을 수행하기 위해 특정 프로세싱 엘리먼트와 다른 하 나 이상의 프로세싱 엘리먼트의 다른 유휴 타일을 더 결정할 수 있다. 예를 들어, 제어기는 타일(228 내지 23 4)을 재할당하여 난독화 동작을 수행하고, 다른 프로세싱 엘리먼트에서 유휴 타일을 할당하여 원래 타일(228 내 지 234)에 할당된 대응하는 추론 동작을 수행한다. 대안적으로, 제어기는 수신된 명령어에 의해 원래 할당 되어 난독화 동작을 수행하기 위한 추론 동작을 수행하는 타일을 재할당하지 않는다. 오히려, 제어기는 유휴 프로세싱 엘리먼트, 곱셈 유닛, 로직 유닛 또는 기타 적합한 유닛과 같은 유휴 계산 컴포넌트를 결정하여 난독화 동작을 수행한다. 예를 들어, 타일(220 내지 234)은 추론 동작을 계속 수행하고, 하드웨어 디바이스는 다른 계산 컴포넌트에 난독화 동작을 수행하도록 지시한다. 일부 구현예에서, 호스트에 의해 생성된 명령어는 스케줄링 정보, 예를 들어, 어떤 계산 유닛이 어떤 추론 동작 을 언제 수행하는지에 대한 정보를 포함하지 않는다. 이러한 상황에서, 제어기는 타일을 스케줄링하여 대 응하는 동작을 수행하기 위한 새로운 명령어를 생성할 수 있다. 제어기는 호스트로부터 수신된 명령어와 새로운 명령어를 통합하고 데이터 버스를 따라 다른 타일에 명령어를 발행할 수 있다. 예를 들어, 위에서 설명된 바와 같이, 수정된 명령어는, 실행될 때, 타일의 제1 부분을 재할당하여 난독화 동작을 수행하고 다른 유휴 타일을 결정하여 타일의 제1 부분에 원래 할당된 대응하는 추론 동작을 수행할 수 있다. 대안적으로 또는 추가적으로, 수정된 명령어는, 실행될 때, 타일이 할당된 추론 동작을 계속 수행하도록 할 수 있으며, 다른 유 휴 계산 컴포넌트(예를 들어, 덧셈기, 곱셈 유닛, 로직 유닛 또는 기타 프로세싱 엘리먼트)가 난독화 동작을 수 행하도록 할 수 있다. 프로세싱 엘리먼트는 또한 하나 이상의 메모리 유닛을 포함한다. 예를 들어, 메모리 유닛은 도 2에 도시된 바와 같이 데이터 메모리 및 명령어 메모리를 포함할 수 있다. 명령어 메모리은 제어기의 하나 이상의 프로세서에 의해 실행 가능한 하나 이상의 기계 판독 가능 명령어를 저장할 수 있다. 데이터 메모 리는 예를 들어, 할당된 추론 동작을 수행하기 위한 신경망의 파라미터 및 특정 입력을 프로세싱하기 위한 하나 이상의 계산 결과와 같은 시스템 프로세싱 엘리먼트 내에서 발생하는 계산과 관련된 다양한 데이터를 저장하고 이후 액세스하기 위한 다양한 데이터 저장 매체 중 하나일 수 있다. 일부 구현예에서, 데이터 메모리 및 명령어 메모리는 휘발성 메모리 유닛 또는 유닛들이다. 일부 다른 구현예에서, 데이터 메모리 및 명령어 메모리는 비휘발성 메모리 유닛 또는 유닛들이다. 데이터 메모리 및 명령어 메모리 는 플로피 디스크 디바이스, 하드 디스크 디바이스, 광학 디스크 디바이스 또는 테이프 디바이스, 플래시 메모리 또는 기타 유사한 솔리드 스테이트 메모리 디바이스 또는 스토리지 영역 네트워크 또는 기타 구성의 디바이스를 포함한 디바이스의 어레이와 같은 다른 형태의 컴퓨터 판독가능 매체일 수도 있다. 도 3은 추론 동작과 난독화 동작을 동시에 수행하기 위한 계산 유닛의 예시적 할당을 예시한다. 할당(30 0)은 하나 이상의 다른 위치에 있는 하나 이상의 컴퓨터에 의해 결정될 수 있다. 단순화를 위해, 할당은 관리 컴포넌트, 예를 들어, 도 1의 관리 컴포넌트에 의해 결정될 수 있으며, 적절하게 프로그래밍되면, 할 당을 결정하기 위한 명령어를 생성할 수 있다. 도 3에 도시된 바와 같이, 수정된 명령어는, 하드웨어 디바이스(예를 들어, 도 1에 도시된 하드웨어 디바이스 )에 의해 실행될 때, 프로세싱 엘리먼트의 계산 유닛의 제1 부분(예를 들어, 도 2에 도시된 타일(220 내지 234))이 추론 동작을 수행하고 프로세싱 엘리먼트의 계산 유닛의 제2 부분이 추론 동작의 수행과 동시에 난독화 동작을 수행하도록 할 수 있다. 하나의 예시적 할당은 프로세싱 엘리먼트(302A)의 계산 유닛(306A-J)의 제1 부분이 대응하는 추론 동 작을 수행하도록 지시되고, 프로세싱 엘리먼트(302A)의 계산 유닛(306K-306N)의 제2 부분이 계산 유닛 (306A-J)의 제1 부분에 의해 수행되는 추론 동작과 동시에 난독화 동작을 수행하도록 지시됨을 나타낸다. 일부 구현예에서, 할당은 하나 이상의 프로세싱 엘리먼트(302A-302N)와 하나 이상의 프로세싱 엘리먼트(302A- 302N)의 각각에서 계산 유닛(306A-306N)의 다른 부분이 난독화 동작을 수행하도록 나타낼 수 있다. 예를 들어, 계산 유닛(306A-306G)의 제1 부분은 대응하는 추론 동작을 수행하도록 지시받고, 계산 유닛(306H-306N)의 제2 부분은 난독화 동작을 동시에 수행하도록 지시받고, 계산 유닛(306A-306E)의 제1 부분은 대응하 는 추론 동작을 수행하도록 지시받고, 계산 유닛(306F-306N)의 제2 부분은 난독화 동작을 동시에 수행하도 록 지시받는다. 난독화 동작을 수행하는 계산 유닛의 수와 추론 동작을 수행하는 계산 유닛의 수는 상이한 프로 세싱 엘리먼트(302A-302N)에 따라 다를 수 있다. 명령어는 난독화 동작을 수행하도록 지시받은 계산 유닛의 일 부로부터 다른 프로세싱 엘리먼트의 다른 유휴 계산 유닛으로 대응하는 추론 동작을 추가로 재할당할 수 있다. 프로세싱 엘리먼트(302A-N)의 수, 각각의 프로세싱 엘리먼트(302A-N)의 계산 유닛(306A-N)의 수, 각각의 부분의 계산 유닛(306A-N)의 수는 도 3에 예시되어 있다. 계산 유닛과 프로세싱 엘리먼트의 이러한 수 및/또는 배열은 다른 난독화 요구사항에 따라 달라질 수 있음을 이해해야 한다. 예를 들어, 임의의 수의 프로세싱 엘리먼트의 임의의 수의 계산 유닛이 난독화 동작을 수행하도록 할당될 수 있다. 도 4는 추론 동작과 난독화 동작을 동시에 수행하기 위한 계산 유닛의 또 다른 예시적 할당을 예시한다. 할당은 하나 이상의 다른 위치에 있는 하나 이상의 컴퓨터에 의해 결정될 수 있다. 단순화를 위해, 할당 은 관리 컴포넌트, 예를 들어 도 1의 관리 컴포넌트에 의해 결정될 수 있으며, 적절하게 프로그래밍 되면, 할당을 결정하기 위한 명령어를 생성할 수 있다. 도 4에 도시된 바와 같이, 수정된 명령어는, 하드웨어 디바이스(예를 들어, 도 1에 도시된 하드웨어 디바이스 )에 의해 실행될 때, 프로세싱 엘리먼트(402A-K)의 제1 부분이 추론 동작을 수행하고 프로세싱 엘리 먼트(402L-N)의 제2 부분이 추론 동작의 수행과 동시에 난독화 동작을 수행하게 할 수 있다. 이러한 상황에서, 프로세싱 엘리먼트(402A-K)의 제1 부분의 하나 이상의 계산 엘리먼트(406A-N)가 추론 동작을 수행하고, 제 1 부분의 계산 엘리먼트는 난독화 동작을 수행하지 않는다. 호스트로부터 수신된 명령어가 추론 동작을 계산 유 닛에 할당하기 위한 스케줄을 포함하는 상황에서, 제1 부분의 이러한 계산 유닛은 할당된 추론 동작을 계속 수 행한다. 관리 컴포넌트는 제1 부분과 상이한 다른 프로세싱 엘리먼트(예를 들어, 제2 부분)의 계산 유닛이 난독화 동작을 수행하도록 결정한다. 예시적 할당은 계산 유닛에 개별의 동작을 수행하도록 지시하기 위해 예시적 할당과 조합될 수 있다. 예를 들어, 명령어는 하나 이상의 제1 프로세싱 유닛이 난독화 동작을 수행하게 하고, 하나의 제1 프로세싱 유 닛과 다른 하나 이상의 제2 프로세싱 유닛이 난독화 동작과 추론 동작을 모두 수행하게 할 수 있다. 예를 들어, 하나 이상의 제2 프로세싱 유닛의 계산 유닛의 제1 부분은 대응하는 추론 동작을 수행하도록 지시되고, 하나 이 상의 제2 프로세싱 유닛의 계산 유닛의 제2 부분은 대응하는 난독화 동작을 수행하도록 지시된다. 다시 한번, 프로세싱 엘리먼트(402A-N)의 수, 각각의 프로세싱 엘리먼트(402A-N)의 계산 유닛(406A-N)의 수, 그 리고 각각의 부분의 계산 유닛(406A-N)의 수가 도 4에 예시되어 있음을 주목한다. 계산 유닛과 프로세싱 엘리먼 트의 이러한 수 및/또는 배열은 다른 난독화 요구사항에 따라 달라질 수 있음을 이해해야 한다. 도 5는 추론 동작과 난독화 동작을 동시에 수행하기 위한 계산 유닛의 또 다른 예시적 할당을 예시한다. 할당은 하나 이상의 다른 위치에 있는 하나 이상의 컴퓨터에 의해 결정될 수 있다. 단순화를 위해, 할당 은 관리 컴포넌트, 예를 들어 도 1의 관리 컴포넌트에 의해 결정될 수 있으며, 적절하게 프로그래밍되면, 할당을 결정하기 위한 명령어를 생성할 수 있다. 도 5에 도시된 바와 같이, 수정된 명령어는, 하드웨어 디바이스(예를 들어, 도 1에 도시된 하드웨어 디바이스 )에 의해 실행될 때, 프로세싱 엘리먼트(402A-K)의 제1 부분이 추론 동작을 수행하게 하고 다른 계산 컴포넌트(508A-N)를 갖는 제2 컴포넌트 그룹이 추론 동작의 수행과 동시에 난독화 동작을 수행하게 할 수 있다. 일부 구현예에서, 특수 하드웨어 디바이스는 서로 다른 유형의 난독화 동작을 수행하기 위한 하나 이상의 계산 컴포넌트(508A-N)를 포함하도록 설계된다. 하나 이상의 계산 컴포넌트는 로직 유닛, 곱셈기-누산기 유닛, 멀티플렉서 또는 서로 다른 유형 및 배열의 계산 유닛, 예를 들어, GPU 유닛을 갖는 다른 유형의 프로세싱 엘리 먼트와 같은 서로 다른 유형의 유닛을 포함할 수 있다. 다시 한번, 프로세싱 엘리먼트(502A-N)의 수, 각각의 프로세싱 엘리먼트(502A-N)의 계산 유닛(506A-N)의 수, 각 각의 부분의 계산 유닛(506A-N)의 수, 그리고 다른 계산 컴포넌트(508A-N)의 수가 도 5에 예시되어 있음을 주목 한다. 계산 유닛, 프로세싱 엘리먼트 및 계산 컴포넌트의 이러한 수 및/또는 배열은 다른 난독화 요구사항에 따 라 달라질 수 있음을 이해해야 한다. 도 6은 기계 학습 모델의 추론 동작을 난독화하기 위한 프로세스의 예시적 흐름도이다. 편의상, 프로세스 는 하나 이상의 위치에 있는 하나 이상의 컴퓨터 시스템에 의해 수행되는 것으로 설명된다. 예를 들어, 프 로세스는 하드웨어 디바이스, 예를 들어 도 1에 도시된 하드웨어 디바이스에 의해 수행될 수 있다. 프로세스의 단계의 순서는 단지 예시일 뿐이며, 다른 순서로 수행될 수 있다. 일부 구현예에서, 프로세스 는 추가 단계, 더 적은 단계를 포함할 수 있거나, 일부 단계를 여러 단계로 나눌 수 있다. 시스템은 하드웨어 디바이스에 의해 기계 학습 모델을 나타내는 데이터를 수신한다. 기계 학습 모델은 추 론 동작을 위한 여러 모델 파라미터를 포함할 수 있다. 위에서 설명된 바와 같이, 기계 학습 모델은 신경망을 정의하는 여러 파라미터를 갖는 신경망을 포함할 수 있다. 이러한 파라미터는 예를 들어 신경망의 네트워크 계 층의 수, 신경망의 각각의 네트워크 계층의 노드의 수, 신경망의 각각의 네트워크 계층의 각각의 노드에 대한 노드 동작 및/또는 신경망의 각각의 네트워크 계층의 각각의 노드와 연관된 가중치 값을 포함할 수 있다. 상이 한 유형의 기계 학습 모델은 모델을 정의하는 상이한 유형의 파라미터를 포함한다. 본 문서에 설명된 기술은 기 계 학습 모델의 측정가능한 특성에 영향을 미치는 임의의 유형의 파라미터를 난독화할 수 있다. 시스템 또는 하드웨어 디바이스는 여러 프로세싱 엘리먼트를 포함할 수 있으며 각각의 프로세싱 엘리먼트는 여 러 계산 유닛을 포함할 수 있다. 하드웨어 디바이스의 계산 유닛의 세트는 하드웨어 디바이스에 전개된 신경망 의 개별의 추론 동작을 프로세싱하도록 구성될 수 있다. 시스템은 난독화 동작을 수행하기 위한 명령어를 획득한다. 하드웨어 디바이스에 의해 수행될 때 난독화 동작은 기계 학습 모델의 하나 이상의 측정가능한 특성을 난독화하도록 구성된다. 보다 구체적으로, 시스템은 \"보안 모드\"에서 신경망의 추론 동작을 수행할지 여부를 결정할 수 있다. 이러한 결정에 대한 기준은 위에서 설명된 바와 같이 신경망의 특성 또는 애플리케이션(예를 들어, 신경망을 트레이닝하는 데 상당한 시간과 리소 스가 필요한지 또는 신경망이 보안에 민감한 애플리케이션에 적용되는지 여부)에 기초할 수 있다. 시스템이 \"보안 모드\"에서 신경망의 추론 동작을 수행할 것이라고 결정할 때, 시스템은 호스트로부터 수신된 명 령어를 수정하거나 수신된 명령어에 새로운 명령어를 추가하여 수정된 명령어를 얻고, 이는 하드웨어 디바이스 에서 실행되면 하드웨어 디바이스가 추론 동작과 난독화 동작을 동시에 수행하게 한다. 일부 상황에서, 시스템 은 난독화 동작을 하나 이상의 기계 학습 모델에 대한 추론 동작도 수행하는 하나 이상의 프로세싱 엘리먼트에 할당하고; 및 하나 이상의 프로세싱 엘리먼트로부터 추론 동작의 서브세트를 하드웨어 디바이스의 다른 프로세 싱 엘리먼트에 재할당한다. 수정된 명령어를 생성하는 세부사항은 위에서 설명되었다. 난독화 동작은 신경망의 하나 이상의 측정가능한 특성을 변경할 수 있다. 측정가능한 특성은 전력 프로파일, 전 자기 프로파일 또는 시간 프로파일 중 적어도 하나를 포함할 수 있다. 측정가능한 특성이 변경되면, 측정가능한 특성을 기초로 신경망의 파라미터를 결정하는 것이 더 어려워진다. 난독화 동작은 공통 기간 동안 수행되는 추 론 동작과 유사한 동작, 예를 들어 활성화 동작, 텐서 곱셈 및 감소를 포함할 수 있다. 예를 들어, 난독화 동작 은 특정 노드에 대한 대응하는 노드 동작과 동시에 수행될 수 있는 네트워크 계층의 특정 노드에 대한 난독화 노드 동작을 포함할 수 있다. 노드 작업은 노드 추가 또는 노드 곱셈일 수 있다. 대안적으로, 난독화 노드 동작 은 난독화 노드 동작과 동시에 수행되는 특정 노드의 실제 활성화 함수와 다른 특정 노드에 대한 활성화 함수를 지정할 수 있다. 일부 구현예에서, 난독화 동작은 공통 기간 동안 수행되는 추론 동작과 무관하거나 및/또는 다른 동작을 포함할 수 있다. 난독화 동작과 관련된 자세한 내용은 위에서 설명되었다. 시스템은 계산 유닛의 세트의 제1 부분이 기계 학습 모델의 추론 동작을 수행하도록 한다. 계산 유닛의 제 1 부분은 하드웨어 디바이스의 하나 이상의 프로세싱 엘리먼트 내에 위치할 수 있다. 시스템은 추론 동작을 수행하는 계산 유닛의 세트의 제1 부분과 동시에 계산 유닛의 세트의 제2 부분이 난독화 동작을 수행하도록 한다. 계산 유닛의 제2 부분은 하드웨어 디바이스의 하나 이상의 프로세싱 엘리먼트 내 에 위치할 수 있다. 일부 구현예에서, 시스템은, 공통 프로세싱 엘리먼트에서, 추론 동작을 수행하기 위한 공통 프로세싱 엘리먼트 내의 계산 유닛의 제1 부분과 대응하는 난독화 동작을 수행하기 위한 공통 프로세싱 엘리먼트 내의 계산 유닛의 제2 부분을 결정할 수 있다. 이러한 구현예의 한 예가 도 3과 관련하여 도시되고 설명된다. 더 일반적으로, 명 령어는 계산 유닛의 세트의 제1 부분의 서브세트와 계산 유닛의 세트의 제2 부분의 대응하는 서브세트가 공통 프로세싱 엘리먼트 내에 위치하도록 지정할 수 있다. 일부 구현예에서, 시스템은 추론 동작을 수행하기 위한 계산 유닛이 제1 프로세싱 엘리먼트에 있고 대응하는 난 독화 동작을 수행하기 위한 계산 유닛이 제2 프로세싱 엘리먼트 내에 위치하도록 결정할 수 있다. 제2 프로세싱 엘리먼트는 제1 프로세싱 엘리먼트와 다르다. 이러한 구현예의 한 예가 도 4와 관련하여 도시되고 설명된다. 더 일반적으로, 명령어는 계산 유닛의 세트의 제1 부분의 적어도 일부가 프로세싱 엘리먼트에 위치하고 계산 유닛 의 세트의 제2 부분의 적어도 일부가 제1 프로세싱 엘리먼트와 다른 제2 프로세싱 엘리먼트에 위치하도록 지정 할 수 있다. 대안적으로, 시스템은 난독화 동작을 수행하기 위한 하나 이상의 다른 계산 컴포넌트를 결정할 수 있다. 하나 이상의 다른 계산 컴포넌트는 처음에는 추론 동작을 수행하도록 할당되지 않는다. 하나 이상의 다른 계산 컴포 넌트는 하드웨어 디바이스가 난독화 동작을 수행하도록 전용으로 설계될 수 있다. 시스템은 난독화 동작을 다른 계산 컴포넌트에 할당하고 신경망에서 추론 동작을 수행하기 위한 대응하는 프로세싱 엘리먼트 및 계산 유닛을 유지할 수 있다. 본 명세서는 시스템, 장치 및 컴퓨터 프로그램 컴포넌트와 관련하여 \"구성된\"이라는 용어를 사용한다. 하나 이 상의 컴퓨터 시스템이 특정 동작이나 작업을 수행하도록 구성되어 있다는 것은 해당 시스템에 소프트웨어, 펌웨 어, 하드웨어 또는 이들의 조합이 설치되어 있어 동작 시 시스템이 해당 동작이나 작업을 수행하도록 한다는 것 을 의미한다. 하나 이상의 컴퓨터 프로그램이 특정 동작이나 작업을 수행하도록 구성되어 있다는 것은 해당 하 나 이상의 프로그램에 데이터 프로세싱 장치에 의해 실행될 때 장치가 해당 동작이나 작업을 수행하도록 하는 명령어가 포함되어 있다는 것을 의미한다. 특수 목적 로직 회로부가 특정 동작이나 작업을 수행하도록 구성되어 있다는 것은 해당 회로부에 해당 동작이나 작업을 수행하는 전자 로직이 있다는 것을 의미한다. 용어 \"데이터 프로세싱 장치\"는 데이터 프로세싱 하드웨어를 지칭하며, 예를 들어 프로그래밍가능 프로세서, 컴 퓨터 또는 다중 프로세서 또는 컴퓨터를 포함하여 데이터를 프로세싱하기 위한 임의의 종류의 장치, 디바이스 및 기계를 포함한다. 장치는 또한 특수 목적 로직 회로부, 예를 들어 FPGA(필드 프로그래밍가능 게이트 어레이) 또는 ASIC(주문형 집적 회로)일 수 있거나 이를 추가로 포함할 수 있다. 장치는 하드웨어 외에도 컴퓨터 프로그 램을 위한 실행 환경을 생성하는 코드, 예를 들어 프로세서 펌웨어, 프로토콜 스택, 데이터베이스 관리 시스템, 운영 체제 또는 이들 중 하나 이상의 조합을 구성하는 코드를 선택적으로 포함할 수 있다. 프로그램, 소프트웨어, 소프트웨어 애플리케이션, 모듈, 소프트웨어 모듈, 스크립트 또는 코드라고도 지칭되거 나 설명될 수 있는 컴퓨터 프로그램은 컴파일된 또는 해석된 언어, 또는 선언적 또는 절차적 언어를 포함한 임 의의 형태의 프로그래밍 언어로 기록될 수 있으며, 독립형 프로그램 또는 모듈, 컴포넌트, 서브루틴 또는 컴퓨 팅 환경에서 사용하기에 적합한 다른 유닛으로서 임의의 형태로 전개될 수 있다. 컴퓨터 프로그램은 파일 시스 템의 파일에 대응할 수 있지만 반드시 그럴 필요는 없다. 프로그램은 다른 프로그램이나 데이터를 보관하는 파 일의 일부, 예를 들어 마크업 언어 문서에 저장된 하나 이상의 스크립트, 해당 프로그램에 전용된 단일 파일 또 는 여러 개의 조정된 파일, 예를 들어 하나 이상의 모듈, 서브 프로그램 또는 코드의 일부를 저장하는 파일에 저장될 수 있다. 컴퓨터 프로그램은 한 컴퓨터 또는 한 사이트에 위치하거나 여러 사이트에 분산되어 통신 네트 워크로 상호 연결된 여러 컴퓨터에서 실행되도록 전개될 수 있다. 본 명세서에 설명된 프로세스 및 로직 흐름은 하나 이상의 프로그래밍가능 컴퓨터에서 하나 이상의 컴퓨터 프로 그램을 실행하여 입력 데이터에서 동작하고 출력을 생성하여 기능을 수행할 수 있다. 프로세스 및 로직 흐름은 또한 FPGA(필드 프로그래밍가능 게이트 어레이) 또는 ASIC(주문형 집적 회로)와 같은 특수 목적 로직 회로부에의해 수행될 수 있으며, 장치는 또한 이 회로부로서 구현될 수 있다. 컴퓨터 프로그램을 실행하기에 적합한 컴퓨터는 예를 들어 일반 또는 특수 목적 마이크로프로세서 또는 둘 모두 또는 다른 종류의 중앙 프로세싱 유닛을 포함한다. 일반적으로 중앙 프로세싱 유닛은 판독 전용 메모리 또는 랜 덤 액세스 메모리 또는 둘 모두로부터 명령어와 데이터를 수신한다. 컴퓨터의 필수 엘리먼트는 명령어를 수행하 거나 실행하기 위한 중앙 프로세싱 유닛과 명령어와 데이터를 저장하기 위한 하나 이상의 메모리 디바이스이다. 일반적으로, 컴퓨터는 또한 데이터를 저장하기 위한 하나 이상의 대용량 저장 디바이스, 예를 들어 자기, 자기 광학 디스크 또는 광학 디스크를 포함하거나 이에 동작가능하게 결합되어 데이터를 수신하거나 데이터를 전송하 거나 둘 모두를 수행한다. 그러나 컴퓨터에는 이러한 디바이스가 필요하지 않다. 더욱이, 컴퓨터는 다른 디바이 스, 예를 들어 모바일 전화, 스마트폰, 개인용 디지털 보조기기(PDA), 모바일 오디오 또는 비디오 플레이어, 게 임 콘솔, 글로벌 포지셔닝 시스템(GPS) 수신기 또는 휴대용 저장 디바이스, 예를 들어, 범용 직렬 버스(USB) 플 래시 드라이브에 내장될 수 있다. 컴퓨터 프로그램 명령어 및 데이터를 저장하는 데 적합한 컴퓨터 판독 가능 매체는 임의의 형태의 비휘발성 메 모리, 매체 및 메모리 디바이스를 포함하며, 이는 예를 들어 반도체 메모리 디바이스, 예를 들어, EPROM, EEPROM 및 플래시 메모리 디바이스; 자기 디스크, 예를 들어, 내부 하드 디스크 또는 이동식 디스크; 자기광학 디스크; 및 CD-ROM과 DVD-ROM 디스크를 포함한다. 프로세서와 메모리는 특수 목적 로직 회로부에 의해 보완되거 나 통합될 수 있다. 본 명세서에 설명된 주제의 실시예는 컴퓨팅 시스템에서 구현될 수 있으며, 컴퓨팅 시스템은 백엔드 컴포넌트, 예를 들어, 데이터 서버를 포함하거나, 미들웨어 컴포넌트, 예를 들어, 애플리케이션 서버를 포함하거나, 프런 트엔드 컴포넌트, 예를 들어, 그래픽 사용자 인터페이스 또는 사용자가 본 명세서에 설명된 주제의 구현예와 상 호작용할 수 있는 웹 브라우저를 갖는 클라이언트 컴퓨터를 포함하거나, 이러한 백엔드, 미들웨어 또는 프런트 엔드 컴포넌트 중 하나 이상을 임의의 조합을 포함한다. 시스템의 컴포넌트는 디지털 데이터 통신의 임의의 형 태 또는 매체, 예를 들어, 통신 네트워크를 통해 상호연결될 수 있다. 통신 네트워크의 예는 근거리 네트워크 (LAN) 및 광역 네트워크(WAN), 예를 들어, 인터넷을 포함한다. 컴퓨팅 시스템은 클라이언트와 서버를 포함할 수 있다. 클라이언트와 서버는 일반적으로 서로 떨어져 있으며 일 반적으로 통신 네트워크를 통해 상호작용한다. 클라이언트와 서버의 관계는 개별의 컴퓨터에서 운영되고 서로 클라이언트-서버 관계를 갖는 컴퓨터 프로그램에 의해 발생한다. 일부 실시예에서, 서버는 예를 들어 데이터를 디스플레이하고 클라이언트 역할을 하는 사용자 디바이스와 상호작용하는 사용자로부터 사용자 입력을 수신하는 목적을 위해 데이터, 예를 들어, 하이퍼텍스트 마크업 언어(HTML) 페이지를 사용자 디바이스로 송신한다. 사용 자 디바이스에서 생성된 데이터, 예를 들어, 사용자 상호작용의 결과는 서버에서 사용자 디바이스로부터 수신될 수 있다. 위에서 설명한 실시예 외에도, 다음 실시예도 혁신적이다: 실시예 1은 방법이며, 상기 방법은 하드웨어 디바이스에 의해 추론 동작을 위한 복수의 모델 파라미터를 포함하 는 기계 학습 모델을 나타내는 데이터를 수신하는 단계-상기 하드웨어 디바이스는 하나 이상의 프로세싱 엘리먼 트에 배열된 계산 유닛의 세트를 포함함-; 상기 기계 학습 모델이 상기 하나 이상의 프로세싱 엘리먼트에 의해 실행될 때 상기 기계 학습 모델의 하나 이상의 측정가능한 특성을 난독화하도록 구성된 난독화 동작을 수행하기 위한 명령어를 획득하는 단계; 상기 계산 유닛의 세트의 제1 부분으로 하여금 상기 기계 학습 모델의 상기 추론 동작을 수행하게 하는 단계; 및 상기 계산 유닛의 세트의 제2 부분으로 하여금 상기 추론 동작을 수행하는 상기 계산 유닛의 세트의 상기 제1 부분과 동시에 상기 난독화 동작을 수행하게 하는 단계를 포함한다. 실시예 2는 실시예 1의 방법으로서, 상기 기계 학습 모델은 신경망이고, 상기 난독화 동작은 상기 신경망의 네 트워크 계층의 수, 상기 신경망의 상기 네트워크 계층의 노드 수, 상기 신경망의 상기 네트워크 계층의 노드에 대한 노드 동작 또는 상기 신경망의 상기 네트워크 계층의 노드와 연관된 가중치 값 중 적어도 하나를 난독화하 도록 구성된다. 실시예 3은 실시예 1 또는 2의 방법으로서, 상기 기계 학습 모델의 상기 하나 이상의 측정가능한 특성은 전력 프로파일, 전자기 프로파일 또는 시간 프로파일 중 적어도 하나를 포함한다. 실시예 4는 실시예 1 내지 3 중 어느 하나의 방법으로서, 상기 계산 유닛의 세트의 상기 제1 부분의 적어도 서 브세트와 상기 계산 유닛의 세트의 상기 제2 부분의 대응하는 서브세트는 공통 프로세싱 엘리먼트 내에 위치한 다.실시예 5는 실시예 1 내지 4 중 어느 하나의 방법으로서, 상기 계산 유닛의 세트의 상기 제1 부분의 적어도 서 브세트는 제1 프로세싱 엘리먼트에 위치하고, 상기 계산 유닛의 세트의 상기 제2 부분의 적어도 서브세트는 상 기 제1 프로세싱 엘리먼트와 다른 제2 프로세싱 엘리먼트에 위치한다. 실시예 6은 실시예 2 내지 5 중 어느 하나의 방법으로서, 상기 난독화 동작은 특정 노드에 대한 대응하는 노드 작업과 동시에 수행될 네트워크 계층의 상기 특정 노드에 대한 난독화 노드 작업을 포함한다. 실시예 7은 실시예 6의 방법으로서, 상기 난독화 노드 작업은 상기 특정 노드의 실제 활성화 함수와 다른 상기 특정 노드에 대한 활성화 함수를 지정한다. 실시예 8은 실시예 1 내지 7 중 어느 하나의 방법으로서, 상기 계산 유닛의 세트의 상기 제2 부분으로 하여금 상기 추론 동작을 수행하는 상기 계산 유닛의 세트의 상기 제1 부분과 동시에 상기 난독화 동작을 수행하게 하 는 단계는 상기 난독화 동작을 수행하는 전용 프로세싱 엘리먼트에 상기 난독화 동작을 할당하는 단계를 포함한 다. 실시예 9는 실시예 8의 방법으로서, 상기 전용 프로세싱 엘리먼트는 상기 하드웨어 디바이스에 추가로 통합되고 실질적으로 대응하는 난독화 동작만 수행하도록 구성된 하나 이상의 프로세싱 엘리먼트 또는 계산 유닛을 포함 한다. 실시예 10은 실시예 1 내지 9 중 어느 하나의 방법으로서, 상기 계산 유닛의 세트의 상기 제2 부분으로 하여금 상기 추론 동작을 수행하는 상기 계산 유닛의 세트의 상기 제1 부분과 동시에 상기 난독화 동작을 수행하게 하 는 단계는: 하나 이상의 기계 학습 모델에 대한 추론 동작을 또한 수행하는 하나 이상의 프로세싱 엘리먼트에 난독화 동작을 할당하는 단계; 및 상기 하나 이상의 프로세싱 엘리먼트로부터 상기 추론 동작의 서브세트를 상 기 하드웨어 디바이스의 다른 프로세싱 엘리먼트로 재할당하는 단계를 포함한다. 실시예 11은 실시예 2 내지 10 중 어느 하나의 방법으로서, 상기 신경망은 디바이스 잠금해제를 위한 인간 안면 인식 작업을 수행하도록 구성된다. 실시예 12는 하나 이상의 컴퓨터와 명령어를 저장하는 하나 이상의 저장 디바이스를 포함하는 시스템으로서, 상 기 명령어는 하나 이상의 컴퓨터에 의해 실행될 때 상기 하나 이상의 컴퓨터로 하여금 개별의 동작들을 수행하 게 하고, 상기 동작들은 실시예 1 내지 11 중 어느 하나의 방법을 포함한다. 실시예 13은 명령어를 저장하는 하나 이상의 컴퓨터 판독가능 저장 매체로서, 상기 명령어는 하나 이상의 컴퓨 터에 의해 실행될 때 상기 하나 이상의 컴퓨터로 하여금 개별의 동작들을 수행하게 하고, 상기 동작들은 실시예 1 내지 11 중 어느 하나의 방법을 포함한다. 실시예 14는 방법이며, 상기 방법은 프로세서에서, 기계 학습 모델로 추론 동작을 수행하기 위한 명령어의 세트 를 수신하는 단계-상기 명령어의 세트는 상기 추론 동작과 동시에 난독화 동작을 수행하기 위한 적어도 하나의 명령어를 포함함-; 상기 프로세서에서, 상기 기계 학습 모델로 상기 추론 동작을 수행하는 단계; 및 상기 프로 세서에서, 상기 추론 동작과 동시에 난독화 동작을 수행하는 단계를 포함한다. 실시예 15는 실시예 14의 방법으로서, 상기 난독화 동작은 상기 난독화 동작이 상기 추론 동작과 동시에 수행될 때 상기 기계 학습 모델의 하나 이상의 측정가능한 특성을 난독화하도록 구성된다. 실시예 16은 실시예 15의 방법으로서, 상기 기계 학습 모델의 상기 하나 이상의 측정가능한 특성은 전력 프로파 일, 전자기 프로파일 또는 시간 프로파일 중 적어도 하나를 포함한다. 실시예 17은 실시예 14 내지 16 중 어느 하나의 방법으로서, 상기 기계 학습 모델은 신경망이고, 상기 난독화 동작은 상기 신경망의 네트워크 계층의 수, 상기 신경망의 네트워크 계층의 노드의 수, 상기 신경망의 네트워크 계층의 노드에 대한 노드 동작 또는 상기 신경망의 네트워크 계층의 노드와 연관된 가중치 값 중 적어도 하나를 난독화하도록 구성된다. 실시예 18은 실시예 17의 방법으로서, 상기 신경망은 디바이스 잠금해제를 위한 인간 안면 인식 작업을 수행하 도록 구성된다. 실시예 19는 실시예 17 또는 18의 방법으로서, 상기 난독화 동작은 특정 노드에 대한 대응하는 노드 동작과 동 시에 수행될 네트워크 계층의 상기 특정 노드에 대한 난독화 노드 동작을 포함한다. 실시예 20은 실시예 19의 방법으로서, 난독화 노드 동작은 상기 특정 노드의 실제 활성화 함수와 다른 상기 특 정 노드에 대한 활성화 함수를 지정한다. 실시예 21은 실시예 14 내지 20 중 어느 하나의 방법으로서, 상기 프로세서는 상기 기계 학습 모델의 상기 추론 동작을 수행하기 위해 상기 프로세서의 계산 유닛의 세트의 제1 부분을 할당하고 상기 추론 동작을 수행하는 상 기 계산 유닛의 세트의 상기 제1 부분과 동시에 상기 난독화 동작을 수행하기 위해 상기 프로세서의 상기 계산 유닛의 세트의 제2 부분을 할당하도록 구성된다. 실시예 22는 실시예 21의 방법으로서, 상기 계산 유닛의 세트의 상기 제1 부분의 적어도 서브세트는 상기 프로 세서의 제1 프로세싱 엘리먼트에 위치하고, 상기 계산 유닛의 세트의 상기 제2 부분의 적어도 서브세트는 동일 한 프로세싱 엘리먼트에 위치하거나 상기 제1 프로세싱 엘리먼트와 다른 제2 프로세싱 엘리먼트에 위치한다. 실시예 23은 실시예 21 또는 22의 방법으로서, 상기 계산 유닛의 세트의 상기 제2 부분은 상기 난독화 동작을 수행하는 상기 프로세서의 전용 프로세싱 엘리먼트에 위치한 하나 이상의 계산 유닛을 포함한다. 실시예 24는 실시예 23의 방법으로서, 상기 전용 프로세싱 엘리먼트는 상기 프로세서에 추가로 통합되고 실질적 으로 대응하는 난독화 동작만 수행하도록 구성된 하나 이상의 프로세싱 엘리먼트 또는 계산 유닛을 포함한다. 실시예 25는 실시예 14 내지 24 중 어느 하나의 방법으로서, 상기 추론 동작과 동시에 상기 난독화 동작을 수행 하는 단계는: 상기 난독화 동작을 하나 이상의 기계 학습 모델에 대한 추론 동작을 또한 수행하는 상기 프로세 서의 하나 이상의 프로세싱 엘리먼트에 할당하는 단계; 및 상기 추론 동작의 서브세트를 상기 하나 이상의 프로 세싱 엘리먼트로부터 상기 프로세서의 다른 프로세싱 엘리먼트로 재할당하는 단계를 포함한다. 실시예 26은 하나 이상의 컴퓨터와 명령어를 저장하는 하나 이상의 저장 디바이스를 포함하는 시스템으로서, 상 기 명령어는 하나 이상의 컴퓨터에 의해 실행될 때 상기 하나 이상의 컴퓨터로 하여금 개별의 동작들을 수행하 게 하고, 상기 동작들은 실시예 14 내지 25 중 어느 하나의 방법을 포함한다. 실시예 27은 명령어를 저장하는 하나 이상의 컴퓨터 판독가능 저장 매체로서, 상기 명령어는 하나 이상의 컴퓨 터에 의해 실행될 때 상기 하나 이상의 컴퓨터로 하여금 개별의 동작들을 수행하게 하고, 상기 개별의 동작들은 실시예 14 내지 25 중 어느 하나의 방법을 포함한다. 본 명세서에는 많은 구체적인 구현 세부사항이 포함되어 있지만, 이는 청구될 수 있는 것의 범위에 대한 제한으 로 해석되어서는 안 되며, 오히려 특정 실시예에 특화될 수 있는 피처에 대한 설명으로 해석되어야 한다. 본 명 세서에서 개별 실시예의 맥락에서 설명된 특정 피처는 단일 실시예에서 조합하여 구현될 수도 있다. 반대로, 단 일 실시예의 맥락에서 설명된 다양한 피처는 여러 실시예에서 개별적으로 또는 적절한 서브 조합으로 구현될 수 도 있다. 더욱이, 피처가 특정 조합으로 작용하는 것으로 위에서 설명되고 심지어 처음에 그렇게 청구될 수 있 지만, 청구된 조합의 하나 이상의 피처는 일부 경우에는 조합으로부터 제거될 수 있으며, 청구된 조합은 서브조 합 또는 서브조합의 변형으로 지시될 수 있다. 마찬가지로, 도면에서 특정 순서로 동작이 묘사되어 있지만, 이는 이러한 동작이 표시된 특정 순서 또는 순차적 순서로 수행되거나, 모든 설명된 동작이 수행되어 바람직한 결과를 달성해야 한다는 것을 요구하는 것으로 이해 되어서는 안 된다. 특정 상황에서 멀티태스킹과 병렬 프로세싱이 유리할 수 있다. 또한, 상기 설명된 실시 예에 서 다양한 시스템 모듈과 컴포넌트를 분리하는 것은 모든 실시 예에서 이러한 분리가 필요한 것으로 이해되어서 는 안 되며, 설명된 프로그램 컴포넌트와 시스템은 일반적으로 단일 소프트웨어 제품에 함께 통합되거나 여러 소프트웨어 제품에 패키징될 수 있다는 것을 이해해야 한다. HTML 파일이 언급되는 각각의 인스턴스에서, 다른 파일 유형 또는 형식이 대체될 수 있다. 예를 들어, HTML 파 일은 XML, JSON, 일반 텍스트 또는 다른 유형의 파일로 대체될 수 있다. 또한, 테이블 또는 해시 테이블이 언급 되는 경우, 다른 데이터 구조(예를 들어, 스프레드시트, 관계형 데이터베이스 또는 구조화된 파일)가 사용될 수 있다. 본 발명의 특정 실시 예가 설명되었다. 다른 실시 예가 다음 청구항의 범위 내에 있다. 예를 들어, 청구항에 언 급되거나, 명세서에 설명되거나, 도면에 묘사된 단계는 다른 순서로 수행되어도 여전히 바람직한 결과를 얻을 수 있다. 일부 경우에, 멀티태스킹과 병렬 프로세싱이 유리할 수 있다. 청구되는 것은 다음과 같다: 도면 도면1 도면2 도면3 도면4 도면5 도면6"}
{"patent_id": "10-2025-7001030", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 하드웨어 디바이스를 포함하는 예시적 시스템의 블록도이다. 도 2는 하드웨어 디바이스의 예시적 프로세싱 엘리먼트(processing element)를 예시한다. 도 3은 추론 동작과 난독화 동작을 동시에 수행하기 위한 계산 유닛의 예시적 할당을 예시한다. 도 4는 추론 동작과 난독화 동작을 동시에 수행하기 위한 계산 유닛의 또 다른 예시적 할당을 예시한다. 도 5는 추론 동작과 난독화 동작을 동시에 수행하기 위한 계산 유닛의 또 다른 예시적 할당을 예시한다. 도 6은 기계 학습 모델의 추론 동작을 난독화하기 위한 프로세스의 예시적 흐름도이다. 다양한 도면의 유사한 참조 번호 및 명칭은 유사한 엘리먼트를 나타낸다."}
