{"patent_id": "10-2022-0032004", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0152378", "출원번호": "10-2022-0032004", "발명의 명칭": "음성 엔드포인트 검출 방법, 장치, 전자 기기 및 기록 매체", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "구오, 치항"}}
{"patent_id": "10-2022-0032004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 엔드포인트 검출 방법(voice endpoint detection method)에 있어서, 시간적으로 정렬된 음성 데이터와 비디오 데이터를 획득하는 단계; 트레이닝된 음성 검출 모델을 사용하여, 상기 음성 데이터에 대해 음성 시작점(起点)(vad_begin)과 음성 끝점(尾点)(vad_end)의 제1 검출을 수행하는 단계; 상기 비디오 데이터에 대해 입술 움직임 시작점(起点)(lip_begin)과 입술 움직임 끝점(尾点)(lip_end)의 제2 검출을 수행하는 단계; 및제2 검출 결과를 사용하여 제1 검출 결과를 보정하고, 보정 후의 결과를 음성 엔드포인트(端点, endpoing) 검출결과로 하는 단계;를 포함하는, 음성 엔드포인트 검출 방법."}
{"patent_id": "10-2022-0032004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 비디오 데이터에 대해 입술 움직임 시작점과 입술 움직임 끝점의 제2 검출을 수행하는 단계는, 트레이닝된 입술 움직임 검출 모델을 사용하여, 상기 비디오 데이터에 대해 상기 제2 검출을 수행하여, 비디오에서의 얼굴의 입술 움직임 시작점과 입술 움직임 끝점을 획득하는 단계를 포함하는, 음성 엔드포인트 검출 방법."}
{"patent_id": "10-2022-0032004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제2 검출 결과를 사용하여 제1 검출 결과를 보정하는 단계는, 음성 검출 상태가 음성있음 상태이고, 입술 움직임 검출 상태가 입술 움직임이 없는 상태일 경우, 입술 움직임시작점이 검출되고, 미리 설정된 시간 요구에 부합될 경우, 검출된 입술 움직임 시작점을 결정된 음성 끝점 및새로운 음성 시작점으로 하는 단계를 포함하고, 상기 음성있음 상태는 음성 시작점이 검출된 후부터 대응하는 음성 끝점이 검출되기 전까지의 시간에 있는 상태이고, 상기 입술 움직임이 없는 상태는 입술 움직임이 있는 상태 이외의 시간에 있는 상태이며, 상기 입술 움직임이 있는 상태는 입술 움직임 시작점이 검출된 후부터 대응하는 입술 움직임 끝점이 검출되기 전까지의 시간에있는 상태인, 음성 엔드포인트 검출 방법."}
{"patent_id": "10-2022-0032004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 미리 설정된 시간 요구에 부합하는 것은, 입술 움직임 시작점이 검출된 시간과 음성 시작점이 최근에 검출된 시간 사이의 차이가 미리 설정된 역치보다큰 것을 포함하는, 음성 엔드포인트 검출 방법."}
{"patent_id": "10-2022-0032004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2022-0152378-3-제1항에 있어서,상기 제2 검출 결과를 사용하여 제1 검출 결과를 보정하는 단계는, 음성 검출 상태가 음성있음 상태이고, 입술 움직임 검출 상태가 입술 움직임이 있는 상태일 경우, 입술 움직임끝점이 검출되면, 검출된 입술 움직임 끝점을 결정된 음성 끝점 및 새로운 음성 시작점으로 하는 단계를 포함하고, 상기 음성있음 상태는 음성 시작점이 검출된 후부터 대응하는 음성 끝점이 검출되기 전까지의 시간에 있는 상태이고, 상기 입술 움직임이 있는 상태는 입술 움직임 시작점이 검출된 후부터 대응하는 입술 움직임 끝점이 검출되기 전까지의 시간에 있는 상태인, 음성 엔드포인트 검출 방법."}
{"patent_id": "10-2022-0032004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항 중 어느 한 항에 있어서,비디오에서의 얼굴의 입술부가 가려지지 않은 것이 결정되었을 경우, 상기 비디오 데이터에 대해 상기 제2 검출을 수행하는 단계를 포함하는, 음성 엔드포인트 검출 방법."}
{"patent_id": "10-2022-0032004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "음성 엔드포인트 검출 장치(voice endpoint detection device)에 있어서, 획득 모듈, 제1 검출 모듈, 제2 검출 모듈 및 보정 모듈을 포함하고, 상기 획득 모듈은 시간적으로 정렬된 음성 데이터와 비디오 데이터를 획득하는데 사용되고, 상기 제1 검출 모듈은 트레이닝된 음성 검출 모델을 사용하여, 상기 음성 데이터에 대해 음성 시작점과 음성 끝점의 제1 검출을 수행하는데 사용되고, 상기 제2 검출 모듈은 상기 비디오 데이터에 대해 입술 움직임 시작점과 입술 움직임 끝점의 제2 검출을 수행하는데 사용되고, 상기 보정 모듈은 제2 검출 결과를 사용하여 제1 검출 결과를 보정하고, 보정 후의 결과를 음성 엔드포인트 검출 결과로 하는데 사용되는, 음성 엔드포인트 검출 장치."}
{"patent_id": "10-2022-0032004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제2 검출 모듈은 트레이닝된 입술 움직임 검출 모델을 사용하여 상기 비디오 데이터에 대해 상기 제2 검출을 수행하여, 비디오에서의 얼굴의 입술 움직임 시작점과 입술 움직임 끝점을 획득하는, 음성 엔드포인트 검출 장치."}
{"patent_id": "10-2022-0032004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 보정 모듈은 음성 검출 상태가 음성있음 상태이고, 입술 움직임 검출 상태가 입술 움직임이 없는 상태일경우, 입술 움직임 시작점이 검출되고, 미리 설정된 시간 요구에 부합될 경우, 검출된 입술 움직임 시작점을 결정된 음성 끝점 및 새로운 음성 시작점으로 하고, 상기 음성있음 상태는 음성 시작점이 검출된 후부터 대응하는 음성 끝점이 검출되기 전까지의 시간에 있는 상태이고, 상기 입술 움직임이 없는 상태는 입술 움직임이 있는 상태 이외의 시간에 있는 상태이며, 상기 입술 움직임이 있는 상태는 입술 움직임 시작점이 검출된 후부터 대응하는 입술 움직임 끝점이 검출되기 전까지의 시간에있는 상태인, 공개특허 10-2022-0152378-4-음성 엔드포인트 검출 장치."}
{"patent_id": "10-2022-0032004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 미리 설정된 시간 요구에 부합하는 것은, 입술 움직임 시작점이 검출된 시간과 음성 시작점이 최근에 검출된 시간 사이의 차이가 미리 설정된 역치보다큰 것을 포함하는, 음성 엔드포인트 검출 장치."}
{"patent_id": "10-2022-0032004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,상기 보정 모듈은 음성 검출 상태가 음성있음 상태이고, 입술 움직임 검출 상태가 입술 움직임이 있는 상태일경우, 입술 움직임 끝점이 검출되면, 검출된 입술 움직임 끝점을 결정된 음성 끝점 및 새로운 음성 시작점으로하고, 상기 음성있음 상태는 음성 시작점이 검출된 후부터 대응하는 음성 끝점이 검출되기 전까지의 시간에 있는 상태이고, 상기 입술 움직임이 있는 상태는 입술 움직임 시작점이 검출된 후부터 대응하는 입술 움직임 끝점이 검출되기 전까지의 시간에 있는 상태인, 음성 엔드포인트 검출 장치."}
{"patent_id": "10-2022-0032004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항 내지 제11항 중 어느 한 항에 있어서,상기 제2 검출 모듈은 또한, 비디오에서의 얼굴의 입술부가 가려지지 않은 것이 결정되었을 경우, 상기 비디오데이터에 대해 상기 제2 검출을 수행하는데 사용되는, 음성 엔드포인트 검출 장치."}
{"patent_id": "10-2022-0032004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "전자 기기에 있어서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서에 통신 연결되는 메모리;를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 수행 가능한 명령이 저장되어 있고, 상기 명령이 상기 적어도 하나의 프로세서에 의해 수행되어, 상기 적어도 하나의 프로세서에 의해 제1항 내지 제6항 중 어느 한 항의 방법이 수행되도록 하는, 전자 기기."}
{"patent_id": "10-2022-0032004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 기록 매체에 있어서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제6항 중 어느 한 항의 방법을 수행하도록 하는, 비일시적 컴퓨터 판독 가능 기록 매체."}
{"patent_id": "10-2022-0032004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "비일시적 컴퓨터 판독 가능 기록 매체에 저장되어 있는 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램은 상기 컴퓨터가 제1항 내지 제6항 중 어느 한 항의 방법을 수행하도록 하는, 비일시적 컴퓨터 판독 가능 기록 매체에 저장되어 있는 컴퓨터 프로그램.공개특허 10-2022-0152378-5-"}
{"patent_id": "10-2022-0032004", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 딥 러닝 및 지능 음성 등의 인공 지능의 분야에 관한 음성 엔드포인트 검출 방법, 장치, 전자 기기 및 기록 매체를 개시한다. 그 중의 방법은, 시간적으로 정렬된 음성 데이터와 비디오 데이터를 획득하는 단계; 트레 이닝된 음성 검출 모델을 사용하여, 음성 데이터에 대해 음성 시작점과 음성 끝점의 제1 검출을 수행하는 단계; 비디오 데이터에 대해 입술 움직임 시작점과 입술 움직임 끝점의 제2 검출을 수행하는 단계; 및 제2 검출 결과를 사용하여 제1 검출 결과를 보정하고, 보정 후의 결과를 음성 엔드포인트 검출 결과로 하는 단계;를 포함할 수 있 다. 본 발명에 기재된 해결 방안을 적용하면, 음성 엔드포인트 검출 결과의 정확도 등을 향상시킬 수 있다."}
{"patent_id": "10-2022-0032004", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공 지능의 기술 분야에 관한 것으로서, 특히, 딥 러닝 및 지능 음성 등 분야의 음성 엔드포인트 검 출 방법, 장치, 전자 기기 및 기록 매체에 관한 것이다."}
{"patent_id": "10-2022-0032004", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 몇 년 동안, 은행 홀, 백화점 및 병원 등에서, 인간-컴퓨터 인터랙션 제품의 응용이 점점 보급되고 있고, 인간-컴퓨터 인터랙션 제품을 흔히 볼 수 있다. 정확한 음성 인터랙션을 하기 위해, 일반적으로, 수집된 음성 데이터에 대해 음성 엔드포인트 검출(VAD, Voice Activity Detection)을 수행할 필요가 있고, 음성 엔드포인트 검출 결과의 정확도는 인간-컴퓨터 인터랙션의 성 공률 등에 직접 영향을 준다. 현재, 일반적으로 트레이닝된 음성 검출 모델을 사용하여 음성 데이터에 대해 음성 엔드포인트(端点) 검출을 수 행하고, 즉 음성 시작점(起点)과 음성 끝점(尾点)의 검출을 수행한다. 그러나, 이러한 방식은 복잡한 소음 환경 에서, 특히, 소음이 주위의 사람 소리(배경의 사람 소리)일 경우, 검출 효과는 일반적으로 좋지 않고, 즉 검출 결과의 정확도가 높지 않다."}
{"patent_id": "10-2022-0032004", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 음성 엔드포인트 검출 방법, 장치, 전자 기기 및 기록 매체를 제공한다."}
{"patent_id": "10-2022-0032004", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "음성 엔드포인트 검출 방법은, 시간적으로 정렬된 음성 데이터와 비디오 데이터를 획득하는 단계; 트레이닝된 음성 검출 모델을 사용하여, 상기 음성 데이터에 대해 음성 시작점과 음성 끝점의 제1 검출을 수행 하는 단계; 상기 비디오 데이터에 대해 입술 움직임 시작점과 입술 움직임 끝점의 제2 검출을 수행하는 단계; 및 제2 검출 결과를 사용하여 제1 검출 결과를 보정하고, 보정 후의 결과를 음성 엔드포인트 검출 결과로 하는 단 계;를 포함한다. 음성 엔드포인트 검출 장치는, 획득 모듈, 제1 검출 모듈, 제2 검출 모듈 및 보정 모듈을 포함하고, 상기 획득 모듈은 시간적으로 정렬된 음성 데이터와 비디오 데이터를 획득하는데 사용되고, 상기 제1 검출 모듈은 트레이닝된 음성 검출 모델을 사용하여, 상기 음성 데이터에 대해 음성 시작점과 음성 끝 점의 제1 검출을 수행하는데 사용되고, 상기 제2 검출 모듈은 상기 비디오 데이터에 대해 입술 움직임 시작점과 입술 움직임 끝점의 제2 검출을 수행하 는데 사용되고, 상기 보정 모듈은 제2 검출 결과를 사용하여 제1 검출 결과를 보정하고, 보정 후의 결과를 음성 엔드포인트 검 출 결과로 하는데 사용된다. 전자 기기는 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서에 통신 연결되는 메모리;를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 수행 가능한 명령이 저장되어 있고, 상기 명령이 상기 적 어도 하나의 프로세서에 의해 수행되어, 상기 적어도 하나의 프로세서에 의해 상술한 방법이 수행되도록 한다. 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 기록 매체를 제공하고, 상기 컴퓨터 명령은 상기 컴퓨 터가 상술한 방법을 수행하도록 한다. 컴퓨터 프로그램 제품은 컴퓨터 프로그램을 포함하고, 상기 컴퓨터 프로그램이 프로세서에 의해 수행될 때, 상 술한 방법을 구현한다."}
{"patent_id": "10-2022-0032004", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기의 개시된 실시예는 하기와 같은 이점 또는 유익한 효과를 가지고, 음성 검출 모델과 입술 움직임 검출 기 술을 결합하고, 입술 움직임 검출 결과를 사용하여 음성 검출 모델에 의해 검출된 음성 시작점과 음성 끝점을 보정함으로써, 음성 엔드포인트 검출 결과의 정확도 등을 향상시킨다. 본 명세서에서 설명된 내용은 본 발명의 실시예의 키 또는 중요한 특징을 식별하려는 것이 아니고, 또한 본 발 명의 범위를 제한하려는 것도 아닌 것을 이해하여야 한다. 본 발명의 다른 특징은 하기의 명세서를 통해 용이하 게 이해할 수 있다."}
{"patent_id": "10-2022-0032004", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "하기는 첨부된 도면을 결부하여 본 발명의 예시적 실시예를 설명하되, 여기에는 이해를 돕기 위한 본 발명의 실"}
{"patent_id": "10-2022-0032004", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "시예의 다양한 세부 사항이 포함되며, 이는 단지 예시적인 것으로 간주되어야 한다. 따라서, 본 기술분야의 통 상의 기술자는 본 발명의 범위와 사상을 벗어나지 않으면서, 여기서 설명되는 실시예에 대한 다양한 변경과 수 정이 이루어질 수 있음을 이해해야 한다. 마찬가지로, 명확성 및 간결성을 위해, 아래의 설명에서 공지된 기능 과 구조에 대한 설명을 생략한다. 또한, 본 명세서의 용어 “및/또는”은 관련 대에서의 관련 관계를 설명하며 3가지 관계가 존재함을 나타낸다. 예를 들어 A 및/또는 B는, A가 단독으로 존재; A와 B가 동시에 존재; B가 단독으로 존재하는 3가지 경우를 표현 할 수 있다. 캐릭터 \"/\"는 일반적으로 전후 관련 대상이 \"또는”의 관계를 가짐을 나타낸다. 도 1은 본 발명의 상기 음성 엔드포인트 검출 방법의 실시예의 흐름도이다. 도 1에 도시된 바와 같이, 하기와 같은 구체적인 구현 방식을 포함한다. 단계 101에서, 시간적으로 정렬된 음성 데이터와 비디오 데이터를 획득한다. 단계 102에서, 트레이닝된 음성 검출 모델을 사용하여, 음성 데이터에 대해 음성 시작점(vad_begin)과 음성 끝 점(尾点)(vad_end)의 제1 검출을 수행한다. 단계 103에서, 비디오 데이터에 대해 입술 움직임 시작점(lip_begin)과 입술 움직임 끝점(尾点)(lip_end)의 제2 검출을 수행한다. 단계 104에서, 제2 검출 결과를 사용하여 제1 검출 결과를 보정하고, 보정 후의 결과를 음성 엔드포인트(端点) 검출 결과로 한다. 알 수 있는 것은, 상기의 방법의 실시예에 기재된 해결 방안에서, 음성 검출 모델과 입술 움직임 검출 기술을 결합하고, 입술 움직임 검출 결과를 사용하여 음성 검출 모델에 의해 검출된 음성 시작점과 음성 끝점을 보정함 으로써, 음성 엔드포인트 검출 결과의 정확도 등을 향상시킨다. 실제 응용에서, 촬영 장치(카메라 등)를 구비한 인간-컴퓨터 인터랙션 제품을 사용하고, 같은 장면에 대해 음성 데이터와 비디오 데이터를 각각 수집할 수 있고, 예를 들어, 사용자 a가 인간-컴퓨터 인터랙션 제품과 음성대화 를 할 경우, 사용자 a의 음성 데이터 및 비디오 데이터를 각각 수집할 수 있다. 수집된 음성 데이터와 비디오 데이터에 대해, 시간적으로 정렬할 수 있다. 또한, 음성 데이터와 비디오 데이터 에 대해, 다른 처리를 각각 수행할 수 있고, 트레이닝된 음성 검출 모델을 사용하여, 음성 데이터에 대해 음성 시작점과 음성 끝점의 제1 검출을 수행하고, 비디오 데이터에 대해 입술 움직임 시작점과 입술 움직임 끝점의 제2 검출을 수행할 수 있다. 제1 검출을 수행하는 방법은, 종래 기술이다. 도 2는 본 발명의 상기 제1 검출에 대응하는 각 키포인트의 위치 개략도이다. 도 2에 도시된 바와 같이, 그 중의 21은 음성 시작점을 나타내고, 22는 실제 음성 시작점(speech_begin)을 나타 내고, 23은 실제 음성 끝점(speech_end)을 나타내고, 24는 음성 끝점을 나타내고, 25는 음성 시작점이 검출된 시간/시각(T_vad_begin_detected)을 나타내고, 26은 음성 끝점이 검출된 시간(T_vad_end_detected)을 나타내고, 음성 시작점과 음성 끝점은, 음성 검출 모델을 사용하여 검출된 음성 시작점과 음성 끝점을 나타내고, 실제 음성 시작점과 비교하면, 검출된 음성 시작점은, 일반적으로, 300∼500ms 더 빠르고, 당해 값보 다 클 경우, 도입된 무효 음성이 많아져, 인터랙션 지연 등이 많아지고, 실제 음성 끝점과 비교하면, 검출된 음 성 끝점은 일반적으로, 600∼800ms 늦고, 당해 값보다 작을 경우, 오판을 초래하기 쉽고, 미리 차단을 초래하고, 당해 값보다 클 경우, 무효 음성이 증가하여, 인터랙션 지연이 커지게 된다. 도 2에 도시된 바와 같이, 실제 응용에서, 음성 시작점이 검출된 시간은, 일반적으로, 실제 음성 시작점에서 약 200ms 좌우 늦고, 이는 검출 결과의 정확도를 확보하기 위해, 일정한 시간의 음성을 축적하여 이에 대해 계속적 으로 분석할 필요가 있고, 음성의 시작점인지 여부를 최종적으로 결정하고, 단시간의 돌발적인 소음을 음성 등 으로 오인하는 것을 피한다. 음성 시작점이 검출된 시간에, 500∼700(300+200~500+200)ms를 백트래킹 하고, 검 출된 음성 시작점으로 출력한다. 또한, 음성 끝점이 검출된 시간에, 검출된 음성 끝점을 출력할 수 있다. 음성 데이터의 헤더에 소음이 존재한다고 가정하고, 당해 소음은 주위의 사람 소리이며, 도 3은 도 2에 도시된 각 키포인트에 대응하는 위치의 개략도이다. 도 3에 도시된 바와 같이, 그 중의 21∼26이 대표하는 의미는 도 2 와 동일하고, 27은 소음(noise)을 나타낸다. 제1 검출에 의해 음성 시작점과 음성 끝점을 획득한 후, 헤더에 주 위의 사람 소리 소음을 도입하고, 그러면, 후속에 음성 시작점에서 음성 끝점까지의 음성 데이터를 인식 엔진에 송신하여 인식할 때, 인식 오류를 초래하고, 인간-컴퓨터 인터랙션 성공률 등에 영향을 줄 수 있다. 이를 위해, 본 발명에 기재된 해결 방안에는 입술 움직임 검출 기술이 도입되어, 음성 검출 모델을 사용하여 음 성 데이터에 대해 음성 시작점과 음성 끝점의 제1 검출을 수행하는 것 외에, 비디오 데이터에 대해 입술 움직임 시작점과 입술 움직임 끝점의 제2 검출을 수행할 수도 있다. 본 발명의 일 실시예에서, 트레이닝된 입술 움직임 검출 모델을 사용하여 비디오 데이터에 대해 제2 검출을 수 행할 수 있고, 비디오에서의 얼굴의 입술 움직임 시작점과 입술 움직임 끝점을 획득할 수 있다. 트레이닝하여 입술 움직임 검출 모델을 획득하는 방법은 한정하지 않는다. 예를 들어, 얼굴 검출 기술 등을 사 용하여, 비디오 데이터 내의 각 프레임 이미지 중의 얼굴 이미지를 잘라낼 수 있고, 일반적으로, 각 프레임 이 미지에는 1개의 얼굴 이미지만이 포함되고, 각 얼굴 이미지 중의 얼굴 입술부의 입술 모양 포인트를 각각 추출 할 수 있고, 각 얼굴 이미지를 각각 라벨링 할 수 있고, 움직이고 있는 입술부를 1로 라벨링하고, 그렇지 않으 면 0으로 라벨링하고, 또한, 각 얼굴 이미지의 입술 모양 포인트 및 대응하는 라벨링 결과를 사용하여 입술 움 직임 검출 모델의 트레이닝을 할 수 있다. 제2 검출을 수행할 때, 마찬가지 방식으로 입술 모양 포인트를 획득할 수 있고, 입술 움직임 검출 모델에 입력 하는 것으로, 출력된 1 또는 0의 검출 결과를 획득할 수 있고, 얼굴 이미지 중의 얼굴 입술부가 움직이는지 여 부를 나타낼 수 있다. 일반적으로, 입술 움직임 시작점을 결정하는 것은 적어도 5프레임 이미지가 필요하고, 제1 검출 처리 방식과 유 사하며, 이는 오판을 방지하기 위한 것이며, 즉 입술 움직임이 일정 시간 지속되어야 진정한 입술 움직임으로 간주되고, 즉 말하는 것으로 인한 입술 움직임은 다른 원인으로 인한 단시간의 입술 움직임으로 인한 검출 오류 를 방지한다. 따라서, 입술 움직임 시작점이 검출된 시간(T_lip_begin_detected)은, 입술 움직임 시작점과 비교하여 일정한 지연이 있으며, 전술한 5프레임을 예로 들어, 프레임율이 20일 경우, 그러면 250ms가 지연되고, 백트래킹을 통해 입술 움직임 시작점을 획득할 수 있다. 상기의 방식을 통해, 입술 움직임 시작점과 입술 움직임 끝점을 정확하고 효율적으로 검출할 수 있고, 후속 처 리에 양호의 기초 등을 마련할 수 있다. 획득된 제1 검출 결과와 제2 검출 결과에 대해, 제2 검출 결과를 사용하여 제1 검출 결과를 보정할 수 있다. 이를 위해, 음성 검출 상태와 입술 움직임 검출 상태 등과 같은 여러개의 상태를 미리 정의할 수 있고, 음성 검 출 상태는 음성있음 상태(State_vad_speech)와 음성없음 상태(State_vad_no_speech)를 더 포함할 수 있고, 입 술 움직임 검출 상태는 입술 움직임이 있는 상태(State_lip)와 입술 움직임이 없는 상태(State_no_lip)를 더 포 함할 수 있다. 구체적으로, 각각 하기와 같다. A, 음성있음 상태: 음성 시작점이 검출된 후부터 대응하는 음성 끝점이 검출되기 전까지의 시간에 있는 상태이 고, B, 음성없음 상태: 음성있음 상태 이외의 시간에 있는 상태, 즉 음성 시작점이 검출되기 전과 음성 끝점이 검출 된 후의 시간에 있는 상태이며, C, 입술 움직임이 있는 상태: 입술 움직임 시작점이 검출된 후부터 대응하는 입술 움직임 끝점이 검출되기 전까 지의 시간에 있는 상태이고, D, 입술 움직임이 없는 상태: 입술 움직임이 있는 상태 이외의 시간에 있는 상태, 즉 입술 움직임 시작점이 검 출되기 전과 입술 움직임 끝점이 검출된 후의 시간에 있는 상태이다. 도 4는 본 발명의 상기 음성있음 상태와 음성없음 상태의 변환 방식의 개략도이다. 도 4에 도시된 바와 같이, 음성 시작점이 검출되었을 경우, 음성없음 상태로부터 음성있음 상태로 변환하고, 음성 끝점이 검출되었을 경우, 음성있음 상태로부터 음성없음 상태로 변환한다. 도 5는 본 발명의 상기 입술 움직임이 있는 상태와 입술 움직임이 없는 상태의 변환 방식의 개략도이다. 도 5에 도시된 바와 같이, 입술 움직임 시작점이 검출되었을 경우, 입술 움직임이 없는 상태로부터 입술 움직임이 있는 상태로 변환하고, 입술 움직임 끝점이 검출되었을 경우, 입술 움직임이 있는 상태로부터 입술 움직임이 없는 상 태로 변환한다. 본 발명의 일 실시예에서, 제2 검출 결과를 사용하여 제1 검출 결과를 보정할 때, 하기의 처리 방식을 사용할 수 있고, 1) 음성 검출 상태가 음성있음 상태이고, 입술 움직임 검출 상태가 입술 움직임이 없는 상태일 경우, 입술 움직 임 시작점이 검출되고, 미리 설정된 시간 요구에 부합될 경우, 검출된 입술 움직임 시작점을 결정된 음성 끝점 및 새로운 음성 시작점으로 할 수 있고, 2) 음성 검출 상태가 음성있음 상태이고, 입술 움직임 검출 상태가 입술 움직임이 있는 상태일 경우, 입술 움직 임 끝점이 검출되면, 검출된 입술 움직임 끝점을 결정된 음성 끝점 및 새로운 음성 시작점으로 할 수 있다. 방식 1)에서, 음성 검출 상태가 음성있음 상태이고, 입술 움직임 검출 상태가 입술 움직임이 없는 상태일 경우, 입술 움직임 시작점이 검출되면, 미리 설정된 시간 요구에 부합되는지 여부를 더 결정할 수 있고, 본 발명의 일 실시예에서, 입술 움직임 시작점이 검출된 시간과, 최근의 음성 시작점 (즉 현재 음성있음 상태에 대응하는 음 성 시작점)이 검출된 시간 사이의 차이가 미리 설정된 역치보다 큰지 여부를 결정할 수 있고, 그럴 경우, 미리 설정된 시간 요구에 부합된다고 결정할 수 있고, 상응하게, 검출된 입술 움직임 시작점을 결정된 음성 끝점 및 새로운 음성 시작점으로 할 수 있다. 즉 강제적으로 분할할 수 있고, 검출된 입술 움직임 시작점을 최근의 검출된 음성 시작점에 대응하는 음성 끝점 및 새로운 음성 시작점으로 할 수 있다. 일반적으로, 상기의 방식을 통해 처리한 후에 획득된 최근의 검출된 음성 시작점에서 대응하는 음성 끝점까지의 음성 데이터는, 인간-컴퓨터 인터랙션을 하는 사람의 목소리 전에 나타나는 소음이며, 소음을 인간-컴퓨터 인터 랙션을 하는 사람의 목소리와 분할하는 것에 상당하고, 음성 시작점을 재결정함으로써, 음성 시작점 검출 결과 의 정확도 등을 향상시킨다. 또한, 입술 움직임 시작점이 검출되기 때문에, 입술 움직임 검출 상태는 입술 움직임이 없는 상태로부터 입술 움직임이 있는 상태로 변환한다. 방식 2)에서, 음성 검출 상태가 음성있음 상태이고, 입술 움직임 검출 상태가 입술 움직임이 있는 상태일 경우, 입술 움직임 끝점이 검출되면, 검출된 입술 움직임 끝점을 결정된 음성 끝점 및 새로운 음성 시작점으로 할 수 있다. 즉 강제적으로 분할하고, 검출된 입술 움직임 끝점을 최신 획득된 음성 시작점에 대응하는 음성 끝점 및 새로운 음성 시작점으로 할 수 있다. 일반적으로, 상기의 방식을 통해 처리한 후에 획득된 최신의 음성 시작점에서 대응하는 음성 끝점까지의 음성 데이터는, 인간-컴퓨터 인터랙션을 하는 사람의 목소리이며, 소음을 인간-컴퓨터 인터랙션을 하는 사람의 목소 리와 분할하는 것에 상당하고, 음성 끝점을 재결정함으로써, 음성 끝점 검출 결과의 정확도 등을 향상시킨다. 방식 1)과 방식 2)의 처리를 통해, 입술 움직임 검출에 의해, 검출된 음성 시작점과 음성 끝점을 보정하고, 헤 더 소음(head noise)과 테일 소음(tail noise)을 제거할 수 있고, 음성 엔드포인트 검출 결과의 정확도 등을 향 상시킬 수 있다. 본 발명에 기재된 해결 방안에서, 제2 검출의 존재는 제1 검출의 정상적인 진행에 영향을 주지 않고, 즉 종래 방식으로 음성 시작점과 음성 끝점의 검출을 할 수 있고, 검출된 음성 시작점과 음성 끝점에 따라 음성 검출 상 태를 결정할 수 있고, 단지 외부 출력의 관점에서, 제2 검출 결과를 사용하여 제1 검출 결과를 보정할 수 있다. 본 발명의 일 실시예에서, 비디오에서의 얼굴의 입술부가 가려지지 않은 것이 결정되었을 경우, 비디오 데이터 에 대해 입술 움직임 시작점과 입술 움직임 끝점의 제2 검출을 수행할 수 있다. 즉, 비디오에서의 얼굴의 입술부가 가려진 것이 결정되었을 경우, 예를 들어, 마스크를 착용하고 있기 때문에 입술부가 가려지면, 제2 검출을 수행하지 않고, 즉 제1 검출만을 수행하고, 제1 검출 결과를 음성 엔드포인트 검출 결과로 할 수 있다. 종래 구현 방식과 잘 호환되고, 다양한 가능한 상황에 유연하게 대응할 수 있고, 인간 -컴퓨터 인터랙션 순서의 진행 등을 확보할 수 있다."}
{"patent_id": "10-2022-0032004", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기의 설명을 요약하면, 도 6은 본 발명의 상기 음성 엔드포인트 검출 방법의 전체적인 구현 프로세스의 개략 도이다. 도 6에 도시된 바와 같이, 그 중의 \"융합 판결”은 즉 제2 검출 결과를 사용하여 제1 검출 결과를 보정 하고, 각 단계의 구체적인 구현은 상기의 관련 설명을 참조하고, 여기에서 설명을 생략한다. 설명해야 하는 바로는, 전술의 각 방법의 실시예에 대해, 간단히 설명하기 위해, 이를 일련의 동작 조합으로 모 두 표현하지만, 당업자는 본 출원이 설명된 동작 순서에 한정되지 않는 것을 이해할 수 있으므로, 본 출원에 따 라, 일부 단계는 다른 순서 또는 동시에 수행할 수 있다. 그 다음에, 당업자는 명세서에 설명된 실시예가 모두 바람직한 실시예에 속하며, 관련된 동작과 모듈은 본 출원에 필요한 것이 아닌 것을 이해할 수 있다. 또한, 일 부 실시예에 설명되지 않은 부분은 다른 실시예의 관련 설명을 참조할 수 있다. 이상은 방법의 실시예에 관한 설명이며, 하기는 장치의 실시예를 통해, 본 발명에 기재된 해결 방안을 더 설명 한다. 도 7은 본 발명의 상기 음성 엔드포인트 검출 장치의 실시예의 구성 구조의 개략도이다. 도 7에 도시된 바 와 같이, 획득 모듈, 제1 검출 모듈, 제2 검출 모듈 및 보정 모듈을 포함한다. 획득 모듈은, 시간적으로 정렬된 음성 데이터와 비디오 데이터를 획득하는데 사용된다. 제1 검출 모듈은, 트레이닝된 음성 검출 모델을 사용하여, 음성 데이터에 대해 음성 시작점과 음성 끝점의 제1 검출을 수행하는데 사용된다. 제2 검출 모듈은, 비디오 데이터에 대해 입술 움직임 시작점과 입술 움직임 끝점의 제2 검출을 수행하는데 사용된다. 보정 모듈은, 제2 검출 결과를 사용하여 제1 검출 결과를 보정하고, 보정 후의 결과를 음성 엔드포인트 검 출 결과로 사용하도록 구성된다. 획득된 음성 데이터와 비디오 데이터에 대해, 다른 처리를 각각 수행할 수 있고, 제1 검출 모듈은, 트레이 닝된 음성 검출 모델을 사용하여, 음성 데이터에 대해 음성 시작점과 음성 끝점의 제1 검출을 수행할 수 있고, 제2 검출 모듈은, 비디오 데이터에 대해 입술 움직임 시작점과 입술 움직임 끝점의 제2 검출을 수행할 수 있다. 즉 입술 움직임 검출 기술을 도입하고, 음성 검출 모델을 사용하여 음성 데이터에 대해 음성 시작점과 음성 끝점의 제1 검출을 수행하는 것 외에, 비디오 데이터에 대해 입술 움직임 시작점과 입술 움직임 끝점의 제2 검출을 수행할 수도 있다. 본 발명의 일 실시예에서, 제2 검출 모듈은, 트레이닝된 입술 움직임 검출 모델을 사용하여 비디오 데이터 에 대해 제2 검출을 수행하고, 비디오에서의 얼굴의 입술 움직임 시작점과 입술 움직임 끝점을 획득할 수 있다. 트레이닝하여 입술 움직임 검출 모델을 획득하는 방법은 한정하지 않는다. 예를 들어, 얼굴 검출 기술 등을 사 용하고, 비디오 데이터 내의 각 프레임 이미지 중의 얼굴 이미지를 잘라낼 수 있고, 일반적으로, 각 프레임 이 미지에는 1개의 얼굴 이미지만이 포함되고, 각 얼굴 이미지 중의 얼굴 입술부의 입술 모양 포인트를 각각 추출 할 수 있고, 각 얼굴 이미지를 각각 라벨링 할 수 있고, 움직이고 있는 입술부를 1로 라벨링하고, 그렇지 않으 면 0으로 라벨링하고, 또한, 각 얼굴 이미지의 입술 모양 포인트 및 대응하는 라벨링 결과를 사용하여 입술 움 직임 검출 모델의 트레이닝을 할 수 있다. 제2 검출을 수행할 때, 마찬가지 방식으로 입술 모양 포인트를 획득할 수 있고, 입술 움직임 검출 모델에 입력 하는 것으로, 출력된 1 또는 0의 검출 결과를 획득할 수 있고, 얼굴 이미지 중의 얼굴 입술부가 움직이는지 여 부를 나타낼 수 있다. 또한, 보정 모듈은, 제2 검출 결과를 사용하여 제1 검출 결과를 보정하고, 소망의 음성 엔드포인트 검출 결과를 획득할 수 있다. 이를 위해, 음성 검출 상태와 입술 움직임 검출 상태 등과 같은 여러개의 상태를 미리 정의할 수 있고, 음성 검 출 상태는 또한, 음성있음 상태와 음성없음 상태를 포함할 수 있고, 입술 움직임 검출 상태는 또한, 입술 움직 임이 있는 상태와 입술 움직임이 없는 상태를 포함할 수 있다. 음성있음 상태는 음성 시작점이 검출된 후부터 대응하는 음성 끝점이 검출되기 전까지의 시간에 있는 상태이고, 음성없음 상태는 음성있음 상태 이외의 시간에 있는 상태, 즉 음성 시작점이 검출되기 전과 음성 끝점이 검출된 후의 시간에 있는 상태이며, 입술 움직임이 있는 상태는 입술 움직임 시작점이 검출된 후부터 대응하는 입술 움 직임 끝점이 검출되기 전까지의 시간에 있는 상태이고, 입술 움직임이 없는 상태는 입술 움직임이 있는 상태 이 외의 시간에 있는 상태, 즉 입술 움직임 시작점이 검출되기 전과 입술 움직임 끝점이 검출된 후의 시간에 있는 상태이다. 상응하게, 본 발명의 일 실시예에서, 보정 모듈은, 음성 검출 상태가 음성있음 상태이고, 입술 움직임 검 출 상태가 입술 움직임이 없는 상태일 경우, 입술 움직임 시작점이 검출되고, 미리 설정된 시간 요구에 부합될 경우, 검출된 입술 움직임 시작점을 결정된 음성 끝점 및 새로운 음성 시작점으로 할 수 있다. 본 발명의 일 실시예에서, 미리 설정된 시간 요구에 부합하는 것은, 입술 움직임 시작점이 검출된 시간과 음성 시작점이 최근에 검출된 시간 사이의 차이가 미리 설정된 역치보다 큰 것을 가리킬 수 있다. 다시 말하면, 음성 검출 상태가 음성있음 상태이고, 입술 움직임 검출 상태가 입술 움직임이 없는 상태일 경우, 입술 움직임 시작점이 검출되면, 입술 움직임 시작점이 검출된 시간과, 최근의 음성 시작점 (즉 현재 음성있음 상태에 대응하는 음성 시작점)이 검출된 시간 사이의 차이가 미리 설정된 역치보다 큰지 여부를 더 결정할 수 있고, 그럴 경우, 미리 설정된 시간 요구에 부합된다고 결정할 수 있고, 상응하게, 검출된 입술 움직임 시작점 을 결정된 음성 끝점 및 새로운 음성 시작점으로 할 수 있다. 즉 강제적으로 분할할 수 있고, 검출된 입술 움직 임 시작점을 최근의 검출된 음성 시작점에 대응하는 음성 끝점 및 새로운 음성 시작점으로 할 수 있다. 본 발명의 일 실시예에서, 보정 모듈은, 또한, 음성 검출 상태가 음성있음 상태이고, 입술 움직임 검출 상 태가 입술 움직임이 있는 상태일 경우, 입술 움직임 끝점이 검출되면, 검출된 입술 움직임 끝점을 결정된 음성 끝점 및 새로운 음성 시작점으로 할 수 있다. 즉 강제적으로 분할하고, 검출된 입술 움직임 끝점을 최신 획득된 음성 시작점에 대응하는 음성 끝점 및 새로운 음성 시작점으로 할 수 있다. 본 발명의 일 실시예에서, 제2 검출 모듈은, 또한, 결정 비디오에서의 얼굴의 입술부가 가려지지 않았을 경우, 비디오 데이터에 대해 제2 검출을 수행할 수 있다. 즉, 비디오에서의 얼굴의 입술부가 가려진 것이 결정 되었을 경우, 예를 들어, 마스크를 착용하고 있기 때문에 입술부가 가려지면, 제2 검출을 수행하지 않고, 즉 제 1 검출만을 수행하고, 제1 검출 결과를 음성 엔드포인트 검출 결과로 할 수 있다. 도 7에 도시된 장치의 실시예가 구체적인 작업 흐름은 전술한 방법의 실시예의 관련 설명을 참조하고, 여기에서 설명을 생략한다. 요컨대, 본 발명의 장치 실시예에 관한 해결 방안을 사용하고, 음성 검출 모델과 입술 움직임 검출 기술을 결합 하고, 입술 움직임 검출 결과를 사용하여 음성 검출 모델에 의해 검출된 음성 시작점과 음성 끝점을 보정함으로 써, 음성 엔드포인트 검출 결과의 정확도 등을 향상시킨다. 본 발명에 기재된 해결 방안은 인공 지능의 분야에 응용될 수 있고, 특히, 인텔리전트 클라우드, 컴퓨터 비전 및 딥 러닝 등의 분야에 관계한다. 인공 지능은 연구하여 인간의 일부 사고 과정과 지능행위(예를 들어, 학습, 추리, 사고, 계획 등)을 컴퓨터로 시뮬레이트하는 것을 연구하는 학과이며, 하드웨어 차원의 기술이 있을 뿐만아니라 소프트웨어 차원의 기술도 있으며, 인공 지능 하드웨어 기술은 일반적으로, 예를 들어, 센서, 전용 인공 지능 칩, 클라우드 컴퓨팅, 분산 스토리지, 빅 데이터 처리 등의 기술을 포함하고, 인공 지능 소프트웨어 기술은 주로, 컴퓨터 비전 기술, 음성 인식 기술, 자연 언어 처리 기술 및 기계학습/딥 러닝, 빅 데이터 처리 기술, 지식 그래프 기술 등의 몇 가지 방향을 포함한다. 본 발명의 실시예에 따르면, 본 발명은 또한, 전자 기기, 판독 가능 기록 매체 및 컴퓨터 프로그램 제품을 제공 한다. 도 8에 도시된 바와 같이, 본 발명의 실시예를 구현할 수 있는 예시적인 전자 기기의 개략적인 블록도이다. 전자 기기는 랩톱 컴퓨터, 데스크톱 컴퓨터, 운영 플랫폼, 서버, 블레이드 서버, 대형 컴퓨터, 및 다른 적합한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 의미한다. 전자 기기는 개인 디지털 처리, 셀룰러폰, 스마트폰, 웨어러블 기기 및 다른 유사한 계산 장치와 같은 다양한 형태의 이동 장치를 의미할 수도 있다. 본문에서 나타낸 부재, 이들의 연결과 관계, 및 이들의 기능은 단지 예시적인 것으로, 본문에서 설명 및/ 또는 요구된 본 발명의 구현을 한정하지 않는다. 도 8에 도시된 바와 같이, 기기는 컴퓨팅 유닛을 포함하고, 컴퓨팅 유닛은 판독 전용 메모리 (ROM)에 저장되어 있는 컴퓨터 프로그램 또는 저장 유닛으로부터 랜덤 액세스 메모리(RAM) 에 로드된 컴퓨터 프로그램에 따라, 다양한 적절한 동작과 처리를 실행할 수 있다. RAM에는 기기가 동작 하는데 필요한 여러가지 프로그램과 데이터도 저장할 수 있다. 컴퓨팅 유닛, ROM 및 RAM는 버스 를 통해 서로 연결된다. 입력/출력 (I/O)인터페이스도 버스에 연결된다. 기기 중의 복수 컴포넌트는 I/O 인터페이스에 연결되고, 키보드, 마우스 등과 같은 입력 유닛; 여러가지 타입의 디스플레이, 스피커 등과 같은 출력 유닛; 디스크, 광디스크 등과 같은 저장 유닛 및 네트워크 카드, 모뎀, 무선통신 트랜시버 등과 같은 통신 유닛을 포함한다. 통신 유닛은 기기 가 인터넷 등과 같은 컴퓨터 네트워크 및 여러가지 통신 네트워크 중의 적어도 하나를 통해 다른 기기와 정보/데이터를 교환할 수 있다. 컴퓨팅 유닛은 여러가지 처리와 계산 능력을 갖춘 범용 처리 컴포넌트 및 전용 처리 컴포넌트 중의 적어도 하나일 수 있다. 컴퓨팅 유닛의 일부 예는, 중앙 처리 유닛(CPU), 그래픽스 처리 유닛(GPU), 다양한 전용 인공지능(AI)계산 팁, 다양한 기계학습 모델 알고리즘을 실행하는 컴퓨팅 유닛, 디지털 신호 프로세서(DSP) 및 임의의 적절한 프로세서, 컨트롤러, 마이크로 컨트롤러 등을 포함하지만, 이에 한정되지 않는다. 컴퓨팅 유닛 은 본 발명에 기재된 방법 등과 같은 상기의 다양한 방법과 처리를 실행한다. 예를 들면, 일부 실시예에서, 본 발명에 기재된 방법은 저장 유닛 등과 같은 기계 판독 가능 매체에 유형적으로 포함되는 컴퓨터 소프트웨어 프로그램으로 구현할 수 있다. 예를 들어, 일부 실시예에서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및 통신 유닛 중의 적어도 하나를 통해 기기에 로드 및/또는 인스톨될 수 있다. 컴 퓨터 프로그램이 RAM에 로드되어 컴퓨팅 유닛에 의해 실행될 경우, 본 발명에 기재된 방법의 하나 또 는 복수의 단계를 실행할 수 있다. 대안적으로, 다른 실시예에서, 컴퓨팅 유닛은 다른 임의의 적절한 방식 (예를 들면, 펌웨어에 의해)을 통해 본 발명에 기재된 방법을 실행하도록 구성될 수 있다. 설명된 시스템 및 기술의 다양한 실시형태는 디지털 전자 회로 시스템, 집적 회로 시스템, 필드 프로그래밍 가 능한 게이트 어레이(FPGA), 특정 용도 대상 집적 회로(ASIC), 특정 용도 대상 표준제품(ASSP), 시스템 온 칩 시 스템(SOC), 부하 프로그래밍 가능 논리 장치(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어, 및/또는 이들의 결 합에서 구현될 수 있다. 이러한 다양한 실시형태는 하나 또는 다수의 컴퓨터 프로그램에서의 구현을 포함할 수 있고, 상기 하나 또는 다수의 컴퓨터 프로그램은 적어도 하나의 프로그램 가능 프로세서를 포함하는 프로그램 가능 시스템에서 실행 및/또는 해석될 수 있으며, 상기 프로그램 가능 프로세서는 전용 또는 범용 프로그램 가능 프로세서일 수 있고, 저장 시스템, 적어도 하나의 입력 장치, 및 적어도 하나의 출력 장치로부터 데이터 및 명령을 수신할 수 있으며, 데이터 및 명령을 상기 저장 시스템, 상기 적어도 하나의 입력 장치, 및 상기 적어도 하나의 출력 장치에 전송할 수 있다. 본 발명의 방법을 실시하기 위한 프로그램 코드는 하나 또는 복수의 프로그래밍 언어의 임의의 결합을 사용하여 작성할 수 있다. 이러한 프로그램 코드는 프로그램 코드가 프로세서 또는 컨트롤러에 의해 실행될 때 흐름도 및 블록도 중의 적어도 하나에 규정된 기능/동작이 실행되도록, 대형 기계(슈퍼 컴퓨터), 전용 컴퓨터 또는 다른 프로그램 가능한 데이터 처리 장치의 프로세서 또는 컨트롤러에 제공할 수 있다. 프로그램 코드는 완전히 기계 에서 실행되거나, 부분적으로 기계에서 실행되거나, 독립된 소프트웨어 패키지로서 부분적으로 기계에서 실행되 고, 부분적으로 리모트 기계에서 실행되거나 또는 완전히 리모트 기계 또는 서버에서 실행될 수 있다. 본 발명의 문맥에서, 기계 판독 가능 매체는 명령 실행 시스템, 장치 또는 기기의 사용, 또는 명령 실행 시스템, 장치 또는 기기와 결합하여 사용되는 프로그램을 포함하거나 저장할 수 있는 유형적인 매체일 수 있다. 기계 판독 가능 매체는 기계 판독 가능 신호 매체 또는 기계 판독 가능 기록 매체일 수 있다. 기계 판독 가능 매체는 전자, 자기, 광학, 전자기, 적외선, 또는 반도체 시스템, 장치 또는 기기, 또는 상술한 내용의 임의의 적절한 결합을 포함하지만, 이에 한정되지 않는다. 기계 판독 가능 기록 매체의 더 구체적인 예는 하나 또는 복 수의 와이어에 기반한 전기 연결, 휴대용 컴퓨터 디스크, 하드 디스크, 랜덤 액세스 메모리(RAM), 판독 전용 메 모리(ROM), 소거 가능 프로그래머블 판독 전용 메모리(EPROM 또는 플래시 메모리), 광섬유, 포터블 컴팩트 디스 크 판독 전용 메모리(CD-ROM), 광학 저장 장치, 자기 저장 장치 또는 상술한 내용의 임의의 적절한 결합을 포함 한다. 사용자와의 인터랙션을 제공하기 위하여, 컴퓨터에서 여기서 설명된 시스템 및 기술을 실시할 수 있고, 상기 컴 퓨터는 사용자에게 정보를 표시하기 위한 표시 장치(예를 들어, CRT(음극선관) 또는 LCD(액정 표시 장치) 모니 터); 및 키보드 및 지향 장치(예를 들어, 마우스 또는 트랙 볼)를 구비하며, 사용자는 상기 키보드 및 상기 지 향 장치를 통해 컴퓨터에 입력을 제공한다. 다른 타입의 장치는 또한 사용자와의 인터랙션을 제공할 수 있는데, 예를 들어, 사용자에게 제공된 피드백은 임의의 형태의 감지 피드백(예를 들어, 시각 피드백, 청각 피드백, 또 는 촉각 피드백)일 수 있고; 임의의 형태(소리 입력, 음성 입력, 또는 촉각 입력)로 사용자로부터의 입력을 수 신할 수 있다. 여기서 설명된 시스템 및 기술은 백엔드 부재를 포함하는 계산 시스템(예를 들어, 데이터 서버로 사용됨), 또는 미들웨어 부재를 포함하는 계산 시스템(예를 들어, 애플리케이션 서버), 또는 프론트 엔드 부재를 포함하는 계 산 시스템(예를 들어, 그래픽 사용자 인터페이스 또는 네트워크 브라우저를 구비하는 사용자 컴퓨터인 바, 사용 자는 상기 그래픽 사용자 인터페이스 또는 상기 네트워크 브라우저를 통해 여기서 설명된 시스템 및 기술의 실 시형태와 인터랙션할 수 있음), 또는 이러한 백엔드 부재, 미들웨어 부재, 또는 프론트 엔드 부재의 임의의 결 합을 포함하는 계산 시스템에서 구현될 수 있다. 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워크)을 통해 시스템의 부재를 서로 연결시킬 수 있다. 통신 네트워크의 예는, 근거리 통신망(LAN), 광역망 (WAN), 인터넷을 포함한다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 고 일반적으로 통신 네트워크를 통해 서로 인터랙션한다. 대응되는 컴퓨터에서 실행되고 또한 서로 클라이언트- 서버 관계를 가지는 컴퓨터 프로그램을 통해 클라이언트 및 서버의 관계를 생성한다. 서버는 클라우드 서버일 수 있고, 클라우드 계산 또는 클라우드 호스트일 수도 있으며, 클라우드 계산 서비스 시스템 중의 하나의 호스 트 제품일 수 있어, 종래의 물리 호스트와 VPS 서비스（VPS）에 존재하는 관리 곤란도가 높고, 업무 확장성이 약한 것을 해결한다. 서버는 분산 시스템의 서버일 수 있거나, 또는 블록 체인을 결합한 서버일 수도 있다. 클 라우드 컴퓨팅은 네트워크 액세스를 통해 탄력적이고 확장 가능한 공유 물리적 또는 가상 리소스 풀을 가리키며, 리소스는 서버, 운영 체제, 네트워크 소프트웨어, 애플리케이션 및 저장 기기 등을 포함할 수 있으며, 온 디맨드 셀프 서비스 방식으로 리소스를 배포하고 관리할 수 있는 기술 체계이고, 클라우드 컴퓨팅 기술을 통해 인공 지능, 블록체인 등 기술 응용, 모델 트레이닝을 위해 고효율적이고 강력한 데이터 처리 능력 을 제공할 수 있다. 위에서 설명된 다양한 형태의 프로세스를 사용하여 단계를 재배열, 추가 또는 삭제할 수 있음을 이해해야 한다. 예를 들어, 본 발명에 기재된 각 단계는 동시에, 순차적으로, 또는 상이한 순서로 수행될 수 있으며, 본 발명에 개시된 기술적 해결수단이 이루고자 하는 결과를 구현할 수 있는 한, 본문은 여기서 한정되지 않는다."}
{"patent_id": "10-2022-0032004", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "상기 구체적인 실시형태는 본 발명의 보호 범위를 한정하지 않는다. 본 기술분야의 통상의 기술자는, 설계 요구 및 다른 요소에 따라 다양한 수정, 결합, 서브 결합 및 대체를 진행할 수 있음을 이해해야 한다. 본 발명의 정 신 및 원칙 내에서 이루어진 임의의 수정, 등가 교체 및 개선 등은 모두 본 발명의 보호 범위 내에 포함되어야 한다."}
{"patent_id": "10-2022-0032004", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부 도면은 본 해결수단을 더 잘 이해하기 위한 것으로, 본 발명에 대해 한정하는 것으로 구성되지 않는다. 도 1은 본 발명의 상기 음성 엔드포인트 검출 방법의 실시예의 흐름도이다. 도 2는 본 발명의 상기 제1 검출에 대응하는 각 키포인트의 위치 개략도이다. 도 3은 도 2에 도시된 각 키포인트에 대응하는 위치의 개략도이다. 도 4는 본 발명의 상기 음성있음 상태와 음성없음 상태의 변환 방식의 개략도이다. 도 5는 본 발명의 상기 입술 움직임이 있는 상태와 입술 움직임이 없는 상태의 변환 방식의 개략도이다. 도 6은 본 발명의 상기 음성 엔드포인트 검출 방법의 전체적인 구현 프로세스의 개략도이다. 도 7은 본 발명의 상기 음성 엔드포인트 검출 장치의 실시예의 구성 구조의 개략도이다. 도 8은 본 발명의 실시예를 실시하는데 사용될 수 있는 예시적인 전자 기기의 개략적인 블록도이다."}
