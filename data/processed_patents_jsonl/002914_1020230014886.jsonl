{"patent_id": "10-2023-0014886", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0050277", "출원번호": "10-2023-0014886", "발명의 명칭": "영상들과 진동들을 학습하는 인공지능을 이용한 제어 장치와 이를 포함하는 침입 경계 시스템", "출원인": "김기설", "발명자": "김기설"}}
{"patent_id": "10-2023-0014886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "촬영 장치;진동을 감지하는 센서; 및인공 지능을 이용한 제어 장치를 포함하고,상기 인공 지능을 이용한 제어 장치는,데이터베이스; 및프로세서를 포함하고,상기 프로세서는,샘플 영상들을 인공지능 알고리즘을 이용하여 학습하여 영상 신호 학습 데이터를 생성하고 상기 영상 신호 학습데이터를 상기 데이터베이스에 저장하고,샘플 진동 신호들을 상기 인공지능 알고리즘을 이용하여 학습하여 진동 신호 학습 데이터를 생성하고 상기 진동신호 학습 데이터를 상기 데이터베이스에 저장하고,상기 촬영 장치로부터 전송된 제1촬영 영상을 수신하고 상기 제1촬영 영상에 포함된 객체를 상기 영상 신호 학습 데이터를 이용하여 식별하고,상기 촬영 장치로부터 전송된 제2촬영 영상을 수신하고 상기 제2촬영 영상에 포함된 상기 객체를 상기 영상 신호 학습 데이터를 이용하여 식별하고,상기 센서로부터 출력된 진동 신호들을 수신하고, 상기 진동 신호들이 인위적인 진동 신호들인지를 상기 진동신호 학습 데이터를 이용하여 판단하고,상기 진동 신호들이 상기 인위적인 진동 신호들로 판단될 때 상기 객체를 울타리를 통한 침입자로 판단하고,상기 객체가 상기 침입자로 판단될 때, 상기 제1촬영 영상과 상기 제2촬영 영상 각각에서 식별된 상기 객체의움직임을 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체의 이동 방법, 이동 속도, 및 방위와 각도범위를 포함하는 이동 방향을 획득하고,상기 이동 방향을 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체가 복수 개의 이동 경로들 중에서어느 하나의 이동 경로를 통해 목적지로 갈 것인지를 예측하고,상기 이동 방법과 상기 이동 속도를 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체가 상기 목적지에 도달할 시간을 예측하고,상기 목적지와 상기 목적지에 도달할 시간을 포함하는 예측 정보를 생성하는 침입 경계 시스템."}
{"patent_id": "10-2023-0014886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 인공 지능을 이용한 제어 장치는,상기 프로세서의 제어에 따라 상기 제1촬영 영상과 상기 제2촬영 영상을 수신하여 디스플레이하는 디스플레이장치를 더 포함하는 침입 경계 시스템."}
{"patent_id": "10-2023-0014886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 촬영 장치는 CCTV 카메라, 네트워크 카메라, 팬-틸트-줌 카메라(pan-tilt-zoom (PTZ) camera), 열화상 카메라, 또는 열상 감시 장비인 침입 경계 시스템.공개특허 10-2023-0050277-3-청구항 4 제1촬영 장치;제2촬영 장치;진동을 감지하는 센서; 및인공 지능을 이용한 제어 장치를 포함하고,상기 인공 지능을 이용한 제어 장치는,데이터베이스; 및프로세서를 포함하고,상기 프로세서는,샘플 영상들을 인공지능 알고리즘을 이용하여 학습하여 영상 신호 학습 데이터를 생성하고 상기 영상 신호 학습데이터를 상기 데이터베이스에 저장하고,샘플 진동 신호들을 상기 인공지능 알고리즘을 이용하여 학습하여 진동 신호 학습 데이터를 생성하고 상기 진동신호 학습 데이터를 상기 데이터베이스에 저장하고,상기 제1촬영 장치로부터 전송된 제1촬영 영상을 수신하고 상기 제1촬영 영상에 포함된 객체를 상기 영상 신호학습 데이터를 이용하여 식별하고,상기 제2촬영 장치로부터 전송된 제2촬영 영상을 수신하고 상기 제2촬영 영상에 포함된 상기 객체를 상기 영상신호 학습 데이터를 이용하여 식별하고,상기 센서로부터 출력된 진동 신호들을 수신하고, 상기 진동 신호들이 인위적인 진동 신호들인지를 상기 진동신호 학습 데이터를 이용하여 판단하고,상기 진동 신호들이 상기 인위적인 진동 신호들로 판단될 때 상기 객체를 울타리를 통한 침입자로 판단하고,상기 객체가 상기 침입자로 판단될 때, 상기 제1촬영 영상과 상기 제2촬영 영상 각각에서 식별된 상기 객체의움직임을 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체의 이동 방법, 이동 속도, 및 방위와 각도범위를 포함하는 이동 방향을 획득하고,상기 이동 방향을 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체가 복수 개의 이동 경로들 중에서어느 하나의 이동 경로를 통해 목적지로 갈 것인지를 예측하고,상기 이동 방법과 상기 이동 속도를 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체가 상기 목적지에 도달할 시간을 예측하고,상기 목적지와 상기 목적지에 도달할 시간을 포함하는 예측 정보를 생성하는 침입 경계 시스템."}
{"patent_id": "10-2023-0014886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "데이터베이스;센서 인터페이스;촬영 장치 인터페이스; 및프로세서를 포함하고,상기 프로세서는,샘플 영상들을 인공지능 알고리즘을 이용하여 학습하여 영상 신호 학습 데이터를 생성하고 상기 영상 신호 학습데이터를 상기 데이터베이스에 저장하고,샘플 진동 신호들을 상기 인공지능 알고리즘을 이용하여 학습하여 진동 신호 학습 데이터를 생성하고 상기 진동신호 학습 데이터를 상기 데이터베이스에 저장하고,촬영 장치로부터 전송된 제1촬영 영상을 수신하고 상기 제1촬영 영상에 포함된 객체를 상기 영상 신호 학습 데공개특허 10-2023-0050277-4-이터를 이용하여 식별하고,상기 촬영 장치로부터 전송된 제2촬영 영상을 수신하고 상기 제2촬영 영상에 포함된 상기 객체를 상기 영상 신호 학습 데이터를 이용하여 식별하고,진동을 감지하는 센서로부터 출력된 진동 신호들을 상기 센서 인터페이스를 통해 수신하고, 상기 진동 신호들이인위적인 진동 신호들인지를 상기 진동 신호 학습 데이터를 이용하여 판단하고,상기 진동 신호들이 상기 인위적인 진동 신호들로 판단될 때 상기 객체를 울타리를 통한 침입자로 판단하고,상기 객체가 상기 침입자로 판단될 때, 상기 제1촬영 영상과 상기 제2촬영 영상 각각에서 식별된 상기 객체의움직임을 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체의 이동 방법, 이동 속도, 및 방위와 각도범위를 포함하는 이동 방향을 획득하고,상기 이동 방향을 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체가 복수 개의 이동 경로들 중에서어느 하나의 이동 경로를 통해 목적지로 갈 것인지를 예측하고,상기 이동 방법과 상기 이동 속도를 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체가 상기 목적지에 도달할 시간을 예측하고,상기 목적지와 상기 목적지에 도달할 시간을 포함하는 예측 정보를 생성하고,상기 센서 인터페이스로부터 상기 진동 신호들을 수신하여 해석하고, 해석 결과에 따라 상기 촬영 장치를 제어하기 위한 제어 신호를 생성하고,상기 촬영 장치 인터페이스는 상기 제어 신호를 상기 프로세서로부터 수신하여 상기 촬영 장치로 전송하는 인공지능을 이용한 제어 장치."}
{"patent_id": "10-2023-0014886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "데이터베이스;센서 인터페이스;촬영 장치 인터페이스; 및프로세서를 포함하고,상기 프로세서는,샘플 영상들을 인공지능 알고리즘을 이용하여 학습하여 영상 신호 학습 데이터를 생성하고 상기 영상 신호 학습데이터를 상기 데이터베이스에 저장하고,샘플 진동 신호들을 상기 인공지능 알고리즘을 이용하여 학습하여 진동 신호 학습 데이터를 생성하고 상기 진동신호 학습 데이터를 상기 데이터베이스에 저장하고,제1촬영 장치로부터 전송된 제1촬영 영상을 수신하고 상기 제1촬영 영상에 포함된 객체를 상기 영상 신호 학습데이터를 이용하여 식별하고,제2촬영 장치로부터 전송된 제2촬영 영상을 수신하고 상기 제2촬영 영상에 포함된 상기 객체를 상기 영상 신호학습 데이터를 이용하여 식별하고,진동을 감지하는 센서로부터 출력된 진동 신호들을 상기 센서 인터페이스를 통해 수신하고, 상기 진동 신호들이인위적인 진동 신호들인지를 상기 진동 신호 학습 데이터를 이용하여 판단하고,상기 진동 신호들이 상기 인위적인 진동 신호들로 판단될 때 상기 객체를 울타리를 통한 침입자로 판단하고,상기 객체가 상기 침입자로 판단될 때, 상기 제1촬영 영상과 상기 제2촬영 영상 각각에서 식별된 상기 객체의움직임을 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체의 이동 방법, 이동 속도, 및 방위와 각도범위를 포함하는 이동 방향을 획득하고,상기 이동 방향을 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체가 복수 개의 이동 경로들 중에서어느 하나의 이동 경로를 통해 목적지로 갈 것인지를 예측하고,공개특허 10-2023-0050277-5-상기 이동 방법과 상기 이동 속도를 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체가 상기 목적지에 도달할 시간을 예측하고,상기 목적지와 상기 목적지에 도달할 시간을 포함하는 예측 정보를 생성하고,상기 센서 인터페이스로부터 상기 진동 신호들을 수신하여 해석하고, 해석 결과에 따라 상기 제1촬영 장치와 상기 제1촬영 장치를 제어하기 위한 제어 신호를 생성하고,상기 촬영 장치 인터페이스는 상기 제어 신호를 상기 프로세서로부터 수신하여 상기 제1촬영 장치와 상기 제2촬영 장치로 전송하는 인공지능을 이용한 제어 장치."}
{"patent_id": "10-2023-0014886", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능을 이용한 제어 장치는 데이터베이스와, 센서 인터페이스와, 촬영 장치 인터페이스와, 프로세서를 포함 하고, 상기 프로세서는 샘플 영상들을 인공지능 알고리즘을 이용하여 학습하여 영상 신호 학습 데이터를 생성하 고 상기 영상 신호 학습 데이터를 상기 데이터베이스에 저장하고, 샘플 진동 신호들을 상기 인공지능 알고리즘을 (뒷면에 계속)"}
{"patent_id": "10-2023-0014886", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 알고리즘을 이용한 침입 경계(또는 침입 예측) 방법에 관한 것으로, 특히 경계지역에서 발 생할 수 있는 복수 개의 샘플들을 상기 인공지능 알고리즘을 이용하여 학습하여 학습 데이터를 생성하고, 영상 신호들, 소리 신호들, 전기 신호들, 및 진동 신호들 중에서 적어도 하나를 수신하고 이를 상기 학습 데이터를 이용하여 분석하고, 분석의 결과에 따라 침입자의 목적지, 및 상기 목적지에 도달할 시간 등을 예측할 수 있는 방법, 상기 방법을 수행하는 저장 매체에 저장된 컴퓨터 프로그램, 및 상기 방법을 수행하는 침입 경계 시스템 에 관한 것이다."}
{"patent_id": "10-2023-0014886", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "주요한 경계지역의 시설물과 상기 시설물에 근무하는 사람들이나 이용자들을 보호하기 위해, 상기 시설물의 주 변 및 상기 시설물에 대한 접근을 제한하는 울타리의 주변에는 센서들, 상기 센서들과 연동하여 작동하는 CCTV 카메라들, 및 상기 센서들과 상기 CCTV 카메라들을 제어하는 제어 장치들을 포함하는 경계 시스템이 설치되어 운용되고 있다. 이러한 경계 시스템은 침입자에 대한 사후적 대응 방법으로 최근에 발생하는 지능적 침입 행위에는 대처하기 어 렵다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록특허공보: 등록번호 10-2021441(2019.11.04.공고) (특허문헌 0002) 등록특허공보: 등록번호 10-1934700(2019.01.03.공고) (특허문헌 0003) 등록특허공보: 등록번호 10-2126498(2020.06.25.공고) (특허문헌 0004) 등록특허공보: 등록번호 10-1951361(2019.02.22.공고)"}
{"patent_id": "10-2023-0014886", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "침입자에 대한 사후적 대응 방법을 해결하기 위해 안출된 본 발명이 이루고자 하는 기술적인 과제는 복수 개의 샘플들을 상기 인공지능 알고리즘을 이용하여 학습하여 학습 데이터를 생성하고, 영상 신호들, 소리 신호들, 전 기 신호들, 및 진동 신호들 중에서 적어도 하나를 수신하고 수신된 신호를 상기 학습 데이터를 이용하여 분석하 고, 분석 결과에 따라 몇 명의 침입자가 언제, 어디로, 무엇을 소지하고 침입하는지를 예측할 수 있는 방법, 상 기 방법을 수행하는 저장 매체에 저장된 컴퓨터 프로그램, 및 상기 방법을 수행하는 침입 경계 시스템을 제공하 는 것이다."}
{"patent_id": "10-2023-0014886", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 침입 경계 시스템은 촬영 장치와, 진동을 감지하는 센서와, 인공 지능을 이용한 제어 장치를 포함하고, 상기 인공 지능을 이용한 제어 장치는 데이터베이스와, 프로세서를 포함하고, 상기 프로세서 는 샘플 영상들을 인공지능 알고리즘을 이용하여 학습하여 영상 신호 학습 데이터를 생성하고 상기 영상 신호 학습 데이터를 상기 데이터베이스에 저장하고, 샘플 신호들을 상기 인공지능 알고리즘을 이용하여 학습하여 진 동 신호 학습 데이터를 생성하고 상기 진동 신호 학습 데이터를 상기 데이터베이스에 저장하고, 상기 촬영 장치 로부터 전송된 제1촬영 영상을 수신하고 상기 제1촬영 영상에 포함된 객체를 상기 영상 신호 학습 데이터를 이 용하여 식별하고, 상기 촬영 장치로부터 전송된 제2촬영 영상을 수신하고 상기 제2촬영 영상에 포함된 상기 객 체를 상기 영상 신호 학습 데이터를 이용하여 식별하고, 상기 센서로부터 출력된 진동 신호들을 수신하고, 상기 진동 신호들이 인위적인 진동 신호들인지를 상기 진동 신호 학습 데이터를 이용하여 판단하고, 상기 진동 신호 들이 상기 인위적인 진동 신호들로 판단될 때 상기 객체를 울타리를 통한 침입자로 판단하고, 상기 객체가 상기 침입자로 판단될 때 상기 제1촬영 영상과 상기 제2촬영 영상 각각에서 식별된 상기 객체의 움직임을 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체의 이동 방법, 이동 속도, 및 방위와 각도 범위를 포함하는 이 동 방향을 획득하고, 상기 이동 방향을 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체가 복수 개 의 이동 경로들 중에서 어느 하나의 이동 경로를 통해 목적지로 갈 것인지를 예측하고, 상기 이동 방법과 상기 이동 속도를 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체가 상기 목적지에 도달할 시간을 예측 하고, 상기 목적지와 상기 목적지에 도달할 시간을 포함하는 예측 정보를 생성한다. 본 발명의 실시 예에 따라 인공지능을 이용한 제어 장치는 데이터베이스와, 센서 인터페이스와, 촬영 장치 인터 페이스와, 프로세서를 포함하고, 상기 프로세서는 샘플 영상들을 인공지능 알고리즘을 이용하여 학습하여 영상 신호 학습 데이터를 생성하고 상기 영상 신호 학습 데이터를 상기 데이터베이스에 저장하고, 샘플 진동 신호들 을 상기 인공지능 알고리즘을 이용하여 학습하여 진동 신호 학습 데이터를 생성하고 상기 진동 신호 학습 데이 터를 상기 데이터베이스에 저장하고, 촬영 장치로부터 전송된 제1촬영 영상을 수신하고 상기 제1촬영 영상에 포 함된 객체를 상기 영상 신호 학습 데이터를 이용하여 식별하고, 상기 촬영 장치로부터 전송된 제2촬영 영상을 수신하고 상기 제2촬영 영상에 포함된 상기 객체를 상기 영상 신호 학습 데이터를 이용하여 식별하고, 진동을 감지하는 센서로부터 출력된 진동 신호들을 상기 센서 인터페이스를 통해 수신하고, 상기 진동 신호들이 인위적 인 진동 신호들인지를 상기 진동 신호 학습 데이터를 이용하여 판단하고, 상기 진동 신호들이 상기 인위적인 진 동 신호들로 판단될 때 상기 객체를 울타리를 통한 침입자로 판단하고, 상기 객체가 상기 침입자로 판단될 때, 상기 제1촬영 영상과 상기 제2촬영 영상 각각에서 식별된 상기 객체의 움직임을 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체의 이동 방법, 이동 속도, 및 방위와 각도 범위를 포함하는 이동 방향을 획득하고, 상기 이동 방향을 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체가 복수 개의 이동 경로들 중에서 어느 하나의 이동 경로를 통해 목적지로 갈 것인지를 예측하고, 상기 이동 방법과 상기 이동 속도를 상기 영상 신호 학습 데이터를 이용하여 분석하여 상기 객체가 상기 목적지에 도달할 시간을 예측하고, 상기 목적지와 상 기 목적지에 도달할 시간을 포함하는 예측 정보를 생성하고, 상기 센서 인터페이스로부터 상기 진동 신호들을 수신하여 해석하고, 해석 결과에 따라 상기 촬영 장치를 제어하기 위한 제어 신호를 생성하고, 상기 촬영 장치 인터페이스는 상기 촬영 장치를 제어하기 위한 상기 제어 신호를 상기 프로세서로부터 수신하여 상기 촬영 장치 로 전송한다."}
{"patent_id": "10-2023-0014886", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "침입자에 대한 사후적 대응 방법을 해결하기 위해 안출된 본 발명의 실시 예에 따른 방법, 상기 방법을 수행하 는 저장 매체에 저장된 컴퓨터 프로그램, 및 상기 방법을 수행하는 침입 경계 시스템은 복수 개의 샘플들을 상 기 인공지능 알고리즘을 이용하여 학습하여 학습 데이터를 생성하고, 영상들, 소리 신호들, 전기 신호들, 및 진 동 신호들 중에서 적어도 하나를 수신하고 수신된 신호를 상기 학습 데이터를 이용하여 분석하고, 분석 결과에 따라 몇 명의 침입자가 언제, 어디로, 무엇을 소지하고 침입하는지를 예측할 수 있는 효과가 있다. 이에 따라 상기 방법, 상기 컴퓨터 프로그램, 및 상기 침입 경계 시스템은 울타리 및 시설물에 대한 침입자의 침입을 예방하고, 상기 침입자의 침입 경로 또는 도주 경로에 미리 도착하여 상기 침입자에 대한 빠른 조치를 취할 수 있는 효과가 있다."}
{"patent_id": "10-2023-0014886", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 인공지능을 이용한 침입 경계 시스템의 블록도이다. 도 1을 참조하면, 인공지능(artificial intelligence(AI))을 이용하여 울타리 또는 시설물에 대한 침입자의 침입 경로 및/또는 도주 경로를 실시간으로 예측하고, 예측의 결과에 따라 예측 정보(IF)를 생성 할 수 있는 침입 경계(이를 '침입 감시', 또는 '침입 예측'이라고도 한다.) 시스템은 인공지능 (또는 인공 지능 프로그램)을 이용한 제어 장치(이를 '인공지능 제어 장치'라 한다. 200), 복수 개의 센서들(311, 321, 331, 341, 351, 361, 371, 381, 및 391), 복수개의 촬영 장치들(313, 323, 333, 343, 353, 363, 373, 383, 및 393), 울타리 , 시설물, 제1객체, 및 단말기를 포함하고, 실시 예들에 따라 침입 경계 시 스템은 카메라가 장착된 드론을 더 포함할 수 있다. 침입 경계 시스템은 (i) 제1객체의 행위에 관련된 입력 신호(예를 들면, 영상 신호(IM), 소리 신호 (SS), 전기 신호(ES), 및 진동 신호(VS) 중에서 적어도 하나), 또는 (ⅱ) 상기 입력 신호와 제1객체가 이 동하는 지역의 지형지물 정보를 학습 데이터를 이용하여 분석하고, 분석의 결과에 따라 제1객체 가 제1위치(P1)로부터 언제(예를 들면, 년월일시분초), 어디로(예를 들면, 울타리의 어느 부분(DT1, DT2, 또 는 DT3), 또는 경계 내부 공간의 어느 부분(예를 들면, DT4 또는 DT5)), 및 어떤 경로(예를 들면, PA1, PA2, PA3, PB1, PB2, 및 PC1))를 통해 울타리 또는 시설물에 무단 침입하고, 그후 언제(예를 들면, 년월일 시분초), 어디로(예를 들면, 울타리의 어느 부분(DT6, 또는 DT7)), 및 어떤 경로(예를 들면, PD1, PD2, 및 PE1))를 통해 도주할지를 실시간으로 예측하고, 예측의 결과(IF)를 단말기로 통보하여 제1객체의 침 입을 예방하거나 제1객체에 대한 빠른 조치를 취하도록 하는 시스템이다. 인공지능 제어 장치는 신경망((Neural Networks) 알고리즘, 머신 러닝 (Machine Learning) 알고리즘, 또 는 딥러닝(Deep Learning) 알고리즘 등을 이용하여 학습을 위한 다양한 샘플들(예를 들면, 샘플 영상 신호들, 샘플 소리 신호들, 샘플 전기 신호들, 및 샘플 진동 신호들 중에서 적어도 하나)을 학습(예를 들면, 다중 인스 턴스 학습(multi-instance learning))하여 학습 데이터(241, 이를 '빅 데이터(bigdata)'라고도 한다.)를 생성 하고, 학습 데이터를 데이터베이스에 저장한다. 실시 예에 따라 인공지능 프로그램이 학습을 위한 다양한 샘플들은 데이터 라벨링된 데이터일 수 있다. 데 이터 라벨링은 수많은 비정형 데이터를 인공지능이 학습할 수 있도록 샘플들(또는 원천 데이터)에 이름(또는 라 벨)을 붙이는 작업을 말한다. 인공지능 제어 장치는 센서들(311, 321, 331, 341, 351, 361, 371, 381, 및 391) 중에서 적어도 하나로부 터 감지 신호(SS, ES, 및 VS 중에서 적어도 하나, 이를 'SS, ES, 및/또는 VS'라 한다.)를 수신하여 분석하고, 분석의 결과에 따라 촬영 장치들(313, 323, 333, 343, 353, 363, 373, 383, 및 393) 중에서 적어도 하나의 작 동을 제어할 수 있다. 각 센서(311, 321, 331, 341, 351, 361, 371, 381, 및 391)는 제1객체의 침입 또는 움직임을 감지하기 위 한 센서이다. 각 센서(311, 321, 331, 341, 351, 361, 371, 381, 및 391)의 타입(type)은 적외선을 감지하는 센서, 레이저를 감지하는 센서, 전파를 감지하는 센서, 열을 감지하는 센서, 움직임을 감지하는 센서, 빛을 감 지하는 광 센서, 압력을 감지하는 센서, 소리를 감지하는 센서, 전기 신호를 감지하는 센서, 진동을 감지하는 센서, 가스를 감지하는 센서, 기상을 감지하는 센서, 및 피사체 이미지 센서 등을 포함한다. 각 센서(311, 321, 331, 341, 351, 361, 371, 381, 및 391)의 주위에는 스피커 또는 사이렌이 설치될 수 있다. 본 명세서에서 각 센서(311, 321, 331, 341, 351, 361, 371, 381, 및 391)는 앞에 열거된 기능들을 수행하는 센서들 중에서 적어도 하나를 포함하는 센서를 통칭한다. 촬영 장치들(313, 323, 333, 343, 353, 363, 373, 383, 및 393) 중에서 적어도 하나는 CCTV 카메라, 네트워크 카메라, 팬-틸트-줌 카메라(pan-tilt-zoom(PTZ) camera), 열화상 카메라(thermographic camera), 또는 열상 감 시 장비(Thermal Observation Device)일 수 있으나 이에 한정되는 것은 아니다. 열화상 카메라는 적외선 복사를 사용하여 영상을 생성하는 장치로서, 적외선 카메라(infrared camera), 열 영상 카메라 (thermal imaging camera) 또는 열 이미저(thermal imager)라고도 불린다. 쌍을 이루는 센서와 촬영 장치(311과 313, 321과 323, 내지 391과 393)는 연동하여 작동할 수 있다. 시설물은 국가 중요 시설(예를 들면, 공공 기관, 공항, 항만, 원자력 발전소, 또는 전력 시설, 등), 군사 시설물, 공공 시설물, 또는 개인 시설물 등과 같이 울타리에 둘러싸여 경계(또는 경비)가 필요한 시설물을 의미한다. 시설물에 접근을 위한 각 이동 경로(PA1, PA2, PA3, PB1, PB2, PB3, 및 PC1)는 침입 경로라 할 수 있고, 시설물로부터 도주를 위한 각 이동 경로 (PD1, PD2, 및 PE1)은 도주 경로라 할 수 있다. 도 1에서는 시설물을 에워싸는 하나의 울타리가 도시되어 있으나, 실시 예들에 따라 시설물을 에워싸는 울타리의 개수는 2개 이상일 수 있다. 제1객체는 움직이는 사람 또는 움직이는 야생 동물일 수 있으나, 본 명세서에서 제1객체는 사람(또는 침입자)이라고 가정한다. 단말기는 인공지능 제어 장치로부터 예측 정보(IF, 예를 들면, 예측된 목적지와 예측된 도달 시간 등 을 포함하는 정보)를 수신할 수 있는 통신 장치를 의미한다. 단말기의 예들은 울타리와 시설물의 경계(또는 경비)를 담당하는 담당자(예를 들면, 경비원, 군 인, 청원 경찰, 및/또는 경찰)이 소지하고 있는 통신 장치, 경계 회사의 통신 장치, 군부대의 통신 장치, 경찰 서의 통신 장치, 또는 소방서의 통신 장치를 의미하나 이에 한정되는 것은 아니다. 단말기가 인공지능 제어 장치로부터 예측 정보(IF)를 수신하면, 울타리를 경계하는 담당자는 예 측 정보(IF)를 이용하여 제1객체보다 해당 위치(DT1 ~ DT8 중에서 적어도 하나)에 먼저 도착하여 제1객체 의 침입을 예방하거나 제1객체의 침입에 대한 빠른 조치(예를 들면, 체포 등)를 취할 수 있는 효과가 있다. 카메라가 장착된 드론은, 인공지능 제어 장치 또는 인공지능 제어 장치의 관리자의 제어에 따라, 제1객체의 영상을 실시간으로 촬영하고, 촬영된 영상들을 인공지능 제어 장치로 무선 통신으로 실시간으로 전송할 수 있다. 도 2는 도 1에 도시된 인공지능을 이용한 제어 장치의 블록도이다. 도 1과 도 2를 참조하면, 인공지능 제어 장치는 입력 장치, 인공지능 알고리즘에 따라 작동하는 인공 지능 프로그램을 실행하는 프로세서 (210, 이를 '서버'라고도 한다.), 메모리 장치, 센서 인터페이스 , 촬영 장치 인터페이스, 데이터베이스, 통신 장치, 디스플레이 장치 , 및 경보 장치 를 포함하고, 실시 예들에 따라 인공지능 제어 장치는 드론 제어 장치을 더 포함할 수 있다. 하드웨어와 결합되어 본 명세서에서 설명되는 인공지능 알고리즘을 이용한 침입 예측 방법을 수행하는 인공지능 프로그램은 프로세서에 의해 액세스가능한 저장 매체(예를 들면, 메모리 장치)에 저장되고, 프 로세서에 의해 실행된다. 센서 인터페이스는 해당 센서(311, 321, 331, 341, 351, 361, 371, 381, 및 391)로부터 출력된 감지 신호 (SS, ES, 및/또는 VS)를 수신하고, 감지 신호 (SS, ES, 및/또는 VS)를 인공지능 프로그램으로 전송한다. 인공지능 프로그램은 감지 신호(SS, ES, 및/또는 VS)를 수신하여 해석하고, 해석 결과에 따라 촬영 장치들 (313, 323, 333, 343, 353, 363, 373, 383, 및 393) 중에서 적어도 하나의 촬영 장치를 제어(예를 들면, 해당 촬영 장치가 PTZ 카메라일 때, 상기 PTZ 카메라의 팬, 틸트, 및 줌 중에서 적어도 하나를 제어)하기 위한 제어 신호(CTL)를 생성하고, 제어 신호(CTL)를 촬영 장치 인터페이스를 통해 상기 적어도 하나의 촬영 장치로 전송한다. 인공지능 프로그램은 상기 적어도 하나의 촬영 장치로부터 촬영 영상들을 촬영 장치 인터페이스를 통 해 수신하고, 도 3, 도 5, 도 6, 및 도 7을 참조하여 설명될 단계들(또는 작동들)을 수행한다. 예를 들면, 제1위치(P1)에 설치된 센서에 의해 제1객체가 감지되면, 인공지능 프로그램은 센서 로부터 출력된 감지 신호(SS, ES, 및/또는 VS)에 응답하여 제어 신호(CTR)를 생성하고, 제어 신호(CTR)를 촬영 장치 인터페이스를 통해 제1위치(P1)에 설치된 촬영 장치로 전송한다. 촬영 장치가 PTZ 카메라일 때 촬영 장치는 제어 신호(CTR)에 응답하여 제1객체를 촬영하기 위해 팬, 틸트, 및 줌 중에서 적어도 하나를 제어하고, 제1객체에 대한 촬영 영상들을 촬영 장치 인터페이스 를 통해 인공지능 프로그램로 전송한다. 또한, 해당 센서(321, 331, 341, 351, 361, 371, 381, 및 391)에 의해 제1객체가 감지되면, 인공지능 프 로그램은 해당 촬영 장치(323, 333, 343, 353, 363, 373, 383, 및 393)를 제어하기 위한 제어 신호(CTR) 를 생성하고, 제어 신호(CTR)를 해당 촬영 장치(323, 333, 343, 353, 363, 373, 383, 및 393)로 전송한다. 실시 예들에 따라, 해당 촬영 장치(313, 323, 333, 343, 353, 363, 373, 383, 및 393)는 제1객체의 특징 (예를 들면, 제1객체의 머리, 얼굴, 또는 발 등)을 실시간으로 트래킹(tracking)하면서 촬영 영상들을 생 성할 수 있다. 또한, 제1위치(P1)에 설치된 센서에 의해 제1객체가 감지되면, 인공지능 프로그램은 센서 로부터 출력된 감지 신호(SS, ES, 및/또는 VS)에 응답하여 두 개의 촬영 장치들(313과 343) 각각을 제어할 수 있는 제어 신호(CTR)을 생성하도 제어 신호(CTR)를 촬영 장치들(313과 343)로 전송할 수 있다. 이에 따라, 촬영 장치들(313과 343) 모두는 제1객체가 존재하는 제3위치(P3)를 포커싱(또는 촬영)할 수 있다. 데이터베이스는 도 3과 도 4를 참조하여 설명될 학습 데이터와 각 촬영 장치(313, 323, 333, 343, 353, 363, 373, 383, 및 393)가 설치된 위치(또는 지역)에 대한 지형지물 정보를 저장할 수 있다. 실시 예 들에 따라, 데이터베이스는 정보(241과 243)를 저장하는 데이터 저장 장치, 또는 상기 데이터 저장 장치에 저장된 정보를 의미할 수 있다. 도 2에 도시된 바와 같이 지형지물 정보는 ID(ID1~ID9)별로 센서(311, 321, 331, 341, 351, 361, 371, 381, 및 391)에 대한 센서 정보(311I, 321I, 331I, 341I, 351I, 361I, 371I, 381I, 및 391I), 촬영 장치(313, 323, 333, 343, 353, 363, 373, 383, 및 393)에 대한 촬영 장치 정보(313I, 323I, 333I, 343I, 353I, 363I, 373I, 383I, 및 393I), 위치 정보(PI1~PI9), 지형 정보(TG1~TG9), 및 지물 정보(FI1~FI9)를 포함한다. 각 센서 정보(311I, 321I, 331I, 341I, 351I, 361I, 371I, 381I, 및 391I)는 해당 센서의 타입에 대한 정보이 고, 각 촬영 장치 정보(313I, 323I, 333I, 343I, 353I, 363I, 373I, 383I, 및 393I)는 해당 촬영 장치의 타입 에 대한 정보이고, 각 위치 정보(PI1~PI9)는 각 촬영 장치(313, 323, 333, 343, 353, 363, 373, 383, 및 393) 가 설치된 위치 정보이고, 예를 들면 GPS(global positioning system) 좌표들일 수 있다. 지형은 땅의 생긴 모양이나 형세를 의미하므로, 지형 정보(TG1~TG9)는 땅이 평지인지, 산지인지, 얼마의 경사도 를 갖는 경사지인지, 습지인지, 기암절벽 지역인지 등에 대한 정보를 포함한다. 지물은 땅 위에 존재하는 천연 또는 인공의 모든 물체를 의미하므로, 지물 정보(FI1~FI9)는 수목, 바위, 가옥, 하천, 계곡, 및 도로 등에 대한 정보를 포함한다. 실시 예들에 따라, 인공지능 프로그램은 촬영 장치들(313, 323, 333, 343, 353, 363, 373, 383, 및 393) 중에서 어떤 촬영 장치로부터 촬영 영상들이 수신되었는지를 판단할 수 있으므로, 제1객체의 목적지와 상 기 목적지에 도달할 시간을 예측할 때 지형지물 정보를 활용할 수 있다. 실시 예들에 따라, 인공지능 프로그램은 촬영 장치들(313, 323, 333, 343, 353, 363, 373, 383, 및 393) 중에서 어떤 촬영 장치로부터 촬영 영상들이 수신되었는지를 판단할 수 있으므로, 제1객체의 목적지와 상 기 목적지에 도달할 시간을 예측할 때 지형지물 학습 데이터(241E)와 지형지물 정보 중에서 적어도 하나를 활용할 수 있다. 실시 예들에 따라, 인공지능 프로그램은 샘플 영상들(SPI) 각각에 포함된 지형 및/또는 지물을 인공지능 알고리즘을 이용하여 학습하고, 학습 결과에 따라 지형지물 학습 데이터(241E)를 생성하고, 지형지물 학습 데이 터(241E)를 데이터베이스에 저장할 수 있다. 통신 장치는 단말기 또는 드론과의 통신을 위한 장치이다. 인공지능 프로그램에 제어에 따라 디스플레이 장치(또는 모니터, 270)는 촬영 장치들(313, 323, 333, 343, 353, 363, 373, 383, 및 393) 중에서 적어도 하나의 촬영 장치로부터 전송된 촬영 영상들을 수신하여 디스플레 이할 수 있다. 예를 들면, 촬영 장치 인터페이스가 각 촬영 장치(313, 323, 333, 343, 353, 363, 373, 383, 및 393)와 서로 다른 통신 채널을 통해 통신하고, 촬영 장치 와 쌍을 이루는 센서에 의해 제1객체가 감지 될 때, 인공지능 프로그램은 센서로부터 출력된 감지 신호(SS, ES, 및/또는 VS)에 기초하여 촬영 장 치 인터페이스와 촬영 장치 사이의 통신 채널을 자동으로 연결한다. 이에 따라, 디스플레이 장치는, 인공지능 프로그램의 제어에 따라, 촬영 장치로부터 출력된 촬 영 영상들을 수신하여 디스플레이 장치에서 디스플레이할 수 있다. 인공지능 프로그램에 의해 제1객체가 침입자로 판단될 때, 인공지능 프로그램는 경보 신호를 경 보 장치로 출력한다. 경보 장치는 청각적 경보 장치, 시각적 경보, 또는 시청각적 경보 장치일 수 있 다. 드론 제어 장치는 드론의 작동을 제어할 수 있다. 인공지능 프로그램에 의해 제1객체가 침 입자로 판단될 때, 인공지능 프로그램은 드론 제어 신호를 생성하여 드론 제어 장치로 출력하면, 상 기 드론 제어 신호는 통신 장치를 통해 드론으로 전송된다. 인공지능 프로그램이 센서로부터 출력된 감지 신호(SS, ES, 및/또는 VS) 또는 촬영 장치로부터 출력된 촬영 영상(IM)에 기초하여 드론 제어 신호를 생성할 때, 상기 드론 제어 신호는 센서의 위치 정보 (PI1) 또는 촬영 장치의 위치 정보(PI1)를 포함한다. 따라서, 드론은 인공지능 제어 장치로부터 전송된 드론 제어 신호에 응답하여 센서의 위치 정보 (PI1) 또는 촬영 장치의 위치 정보(PI1)에 해당하는 위치로 자동으로 날아가 제1객체를 추적하면서 제1객체의 영상을 촬영하고 촬영된 영상을 통신 장치로 전송한다. 인공지능 프로그램은 드론 에 의해 촬영된 제1객체에 대한 촬영 영상을 통신 장치를 통해 수신하여 디스플레이 장치 로 전송한다. 다른 실시 예에 따라, 인공지능 프로그램이 센서로부터 출력된 감지 신호(SS, ES, 및/또는 VS) 또는 촬영 장치로부터 출력된 촬영 영상(IM)에 기초하여 제1객체를 침입자로 판단할 때, 인공지능 제어 장 치의 관리자는 드론 제어 장치를 조작하여 드론을 센서의 위치 정보(PI1) 또는 촬영 장치 의 위치 정보(PI1)에 해당하는 위치로 비행시켜 제1객체를 실시간으로 추적할 수 있다. 드론에 의해 촬영된 제1객체에 대한 촬영 영상은 통신 장치를 통해 인공지능 프로그램으로 전송되고, 인공지능 프로그램은 드론 에 의해 촬영된 제1객체에 대한 촬영 영상을 수신하여 디 스플레이 장치 로 전송한다. 도 3은 도 1에 도시된 침입 경계 시스템의 작동 방법의 실시 예를 설명하는 플로우차트이고, 도 4는 인공지능 알고리즘을 이용하여 학습 데이터를 생성하는 과정을 설명하는 도면이다. 도 1 내지 도 4를 참조하면, 인공지능 프로그램은 각각이 적어도 하나의 객체를 포함하는 샘플 영상들 (SPI), 샘플 소리 신호들(SDS), 샘플 전기 신호들 (ELS), 샘플 진동 신호들(VBS), 또는 이들(SPI, SDS, ELS, 및 VBS) 중에서 적어도 두 개의 조합을 인공지능 알고리즘을 이용하여 학습하고, 학습 결과에 따라 학습 데이터 를 생성하여 데이터베이스에 저장한다(S110). 인공지능 프로그램에 의해 학습 데이터가 생성되는 과정은 도 4를 참조하여 예시적으로 설명된다. 학습 데이터는 샘플 영상들(SPI)의 학습 결과에 따라 생성된 영상 신호 학습 데이터(241A), 샘플 소리 신 호들(SDS)의 학습 결과에 따라 생성된 소리 신호 학습 데이터(241B), 샘플 전기 신호들(ELS)의 학습 결과에 따 라 생성된 전기 신호 학습 데이터(241C), 및 샘플 진동 신호들(VBS)의 학습 결과에 따라 생성된 진동 신호 학습 데이터(241D) 중에서 적어도 하나를 포함한다. 실시 예에 따라, 학습 데이터는 지형지물 학습 데이터 (241E)를 더 포함할 수 있다. 도 4에 도시된 바와 같이 학습을 위한 복수 개의 샘플들(예를 들면, 샘플 영상들(SPI), 샘플 소리 신호들(SDS), 샘플 전기 신호들(ELS), 및 샘플 진동 신호들(VBS) 중에서 적어도 하나)은 입력 장치를 통해 인공지능 프 로그램으로 입력된다. 실시 예들에 따라, 통신 장치를 통해 수신된 학습을 위한 샘플들은 인공지능프로그램으로 입력된다. 인공지능 프로그램은 각 샘플 영상(SPI)에 해당하는 각 영상 신호 (IMS)에 포함된 객체(또는 복수의 객체 들)를 사람 요소(HME), 동물 요소(ANE), 자연 환경 요소(NEE), 인위적 요소(ATE), 및 잡음 요소(NSE)로 학습(또 는 소팅 (sorting))한다. 도 4에 도시된 요소들(HME, ANE, NEE, ATE, 및 NSE)은 설명을 위해 예시된 것에 불과 하다. 예를 들면, 인공지능 프로그램은 각 샘플 영상 신호(IMS)에 해당하는 각 샘플 영상(SPI)에 포함된 적어도 하나의 객체를 아래의 요소로 학습(또는 소팅)한다. 1. 각 샘플 영상(SPI)에 포함된 객체가 사람일 때 인공지능 프로그램은 상기 객체를 사람 요소(HME)로 학 습; 2. 상기 객체가 동물일 때 인공지능 프로그램은 상기 객체를 동물 요소 (ANE)로 학습; 3. 상기 객체가 번개일 때 인공지능 프로그램은 상기 객체를 자연 환경 요소(NEE)로 학습; 4. 상기 객체가 전등 불빛 또는 울타리의 철선을 도구(예를 들면, 절단기)로 자를 때 발생하는 불꽃일 때 인공지능 프로그램은 상기 객체를 인위적 요소(ATE)로 학습; 및 5. 상기 객체가 산불일 때 인공지능 프로그램은 상기 객체를 잡음 요소 (NSE)으로 학습. 또한, 인공지능 프로그램은 샘플 소리 신호들(SDS) 각각을 사람 요소 (HME), 동물 요소(ANE), 자연 환경 요소(NEE), 인위적 요소(ATE), 및 잡음 요소 (NSE)로 학습(또는 소팅)한다. 예를 들면, 인공지능 프로그램은 각 샘플 소리 신호(SDS)를 아래의 요소로 학습(또는 소팅)한다. 1. 인공지능 프로그램은 사람 발자국 소리에 해당하는 각 샘플 소리 신호(SDS)를 사람 요소(HME)로 학습; 2. 인공지능 프로그램은 동물 발자국 소리에 해당하는 각 샘플 소리 신호(SDS)를 동물 요소(ANE)로 학습; 3. 인공지능 프로그램은 바람 소리, 비 소리, 파도 소리, 파도에 돌이 구르는 소리, 또는 물이 흐르는 소 리에 해당하는 각 샘플 소리 신호(SDS)를 자연 환경 요소(NEE)로 학습; 4. 인공지능 프로그램은 총 소리, 차량이 이동하는 소리, 땅을 파는 소리, 사람이 울타리를 기어오를 때 나는 소리, 또는 울타리의 철선을 절단기로 절단할 때 나는 소리에 해당하는 각 샘플 소리 신호(SDS)를 인위적 요소 (ATE)로 학습; 5. 인공지능 프로그램은 천둥 소리에 해당하는 각 샘플 소리 신호 (SDS)를 잡음 요소(NSE)로 학습. 또한, 인공지능 프로그램은 샘플 전기 신호들(ELS) 각각을 자연 환경 요소(NEE), 인위적 요소(ATE), 및 잡 음 요소(NSE)로 학습(또는 소팅)한다. 예를 들면, 인공지능 프로그램은 각 샘플 전기 신호(ELS)를 아래의 요소로 학습(또는 소팅)한다. 1. 인공지능 프로그램은 낙뢰에 의해 발생한 각 샘플 전기 신호(ELS)를 자연 환경 요소(NEE)로 학습; 2. 인공지능 프로그램은 울타리를 절단하기 위해 가해지는 각 전기 신호(ELS), 울타리의 주변에 설치된 전기선 또는 통신선을 무력화하기 위해 가해지는 각 샘플 전기 신호(ELS)를 인위적 요소(ATE)로 학습; 3. 인공지능 프로그램은 정전기에 의해 발생하는 각 샘플 전기 신호 (ELS)를 잡음 요소(NSE)로 학습. 또한, 인공지능 프로그램은 샘플 진동 신호들(VBS) 각각을 사람 요소 (HME), 동물 요소(ANE), 자연 환경 요소(NEE), 인위적 요소(ATE), 및 잡음 요소 (NSE)로 학습(또는 소팅)한다. 예를 들면, 인공지능 프로그램은 각 샘플 진동 신호(VBS)를 아래의 요소로 학습(또는 소팅)한다. 1. 인공지능 프로그램은 사람의 움직임에 의해 발생하는 각 샘플 진동 신호(VBS)를 사람 요소(HME)로 학습; 2. 인공지능 프로그램은 동물의 움직임에 의해 발생하는 각 샘플 진동 신호(VBS)를 동물 요소(ANE)로 학습; 3. 인공지능 프로그램은 낙뢰, 구르는 구름, 또는 쓰러지는 나무에 의해 발생하는 각 샘플 진동 신호(VB S)를 자연 환경 요소(NEE)로 학습; 4. 인공지능 프로그램은 폭파, 도구로 땅을 팔 때 발생하는 진동, 차량의 이동에 의해 발생하는 각 샘플 진동 신호(VBS)를 인위적 요소(ATE)로 학습; 5. 인공지능 프로그램은 지진파에 의해 발생하는 각 샘플 진동 신호(VBS)를 잡음 요소(NSE)로 학습. 인공지능 프로그램은 사람 요소(HME), 동물 요소(ANE), 자연 환경 요소 (NEE), 인위적 요소(ATE), 및 잡음 요소(NSE) 중에서 적어도 하나로 학습된 샘플들을 이용하여 객체(예를 들면, 사람 또는 동물)의 이동 방법(MM), 이동 속도(MV), 이동 방향(MD), 및 침입 유형(IT) 중에서 적어도 하나를 학습하고, 또한 상기 샘플들의 이용하 여 상기 객체가 존재하는 지역의 지형지물(LM)을 학습한다. 예를 들면, 인공지능 프로그램은 학습된 샘플들을 이용하여 객체의 이동 방법(MM)을 학습한다. 예를 들면, 인공지능 프로그램은 샘플 영상들(IMS) 각각에 포함된 동일한 객체의 움직임을 학습하여 상기 객체의 이동 방법(MM)을 학습한다. 여기서, 이동 방법(MM)의 예들은 객체가 포복하여 이동하는지, 상기 객체가 걸어서 이동 하는지, 상기 객체가 뛰어서 이동하는지, 상기 객체가 이동 수단(예를 들면, 차량 또는 보트 등)을 타고 이동하 는지, 및 상기 객체가 수영하여 이동하는지를 포함한다. 인공지능 프로그램은 학습된 샘플들을 이용하여 객체의 이동 속도(MV)를 학습한다. 예를 들면, 인공지능 프로그램은 샘플 영상들(IMS) 각각에 포함된 동일한 객체의 움직임을 학습하여 상기 객체의 이동 속도(M V)를 학습한다. 인공지능 프로그램은 학습된 샘플들을 이용하여 객체의 이동 방향(MV)을 학습한다. 예를 들면, 인공지능 프로그램은 샘플 영상들(IMS) 각각에 포함된 동일한 객체의 움직임의 방향을 학습하여 상기 객체의 이동 방향(MV)을 학습한다. 인공지능 프로그램은 학습된 샘플들(예를 들면, 샘플들(IMS, SDS, ELS, 또는 VBS)에 대한 학습 결과들, 및 상기 학습 결과들 중에서 적어도 두 개의 조합)을 이용하여 객체의 침입 유형(IT)을 학습한다. 예를 들면, 인공지능 프로그램은 샘플 영상들(IMS) 각각에 포함된 동일한 객체의 움직임에 따라 상기 객체 의 침입 유형(IT)을 학습한다. 침입 유형(IT)의 예들은 불법적인 침입을 목적으로 객체가 울타리를 기어오르는지, 울타리를 뛰어넘 는지, 사다리를 이용하여 울타리를 오르는지, 울타리의 아래에 굴을 파는지, 울타리를 넘어뜨리 는지, 또는 울타리 를 절단하여 구멍을 뚫는지를 학습한다. 인공지능 프로그램은 침입 유형(IT)에 대한 판단의 정확성을 높이기 위해 아래의 학습 결과들을 조합할 수 있다. 조합하는 학습 결과들이 많을 수록 침입 유형(IT)에 대한 판단의 정확성은 높아진다. 1. 샘플 영상들(IMS)에 대한 학습 결과와 샘플 소리 신호들(SDS)에 대한 학습 결과의 조합; 2. 샘플 영상들(IMS)에 대한 학습 결과와 샘플 전기 신호들(ELS)에 대한 학습 결과의 조합; 3. 샘플 영상들(IMS)에 대한 학습 결과와 샘플 진동 신호들(VBS)에 대한 학습 결과의 조합; 4. 샘플 영상들(IMS)에 대한 학습 결과, 샘플 소리 신호들(SDS)에 대한 학습 결과, 및 샘플 전기 신호들(ELS)에 대한 학습 결과의 조합; 5. 샘플 영상들(IMS)에 대한 학습 결과, 샘플 소리 신호들(SDS)에 대한 학습 결과, 및 샘플 진동 신호들(VBS)에 대한 학습 결과의 조합; 6. 샘플 영상들(IMS)에 대한 학습 결과, 샘플 소리 신호들(SDS)에 대한 학습 결과, 샘플 전기 신호들(ELS)에 대 한 학습 결과, 및 샘플 진동 신호들(VBS)에 대한 학습 결과의 조합. 물론, 영상 촬영 장치의 고장 또는 의도적인 고장을 대비하여, 인공지능 프로그램은 아래의 예들을 이용하 여 객체의 침입 유형(IT)을 학습할 수 있다. 샘플 소리 신호들(SDS)에 대한 학습 결과; 샘플 전기 신호들(ELS)에 대한 학습 결과; 샘플 진동 신호들(VBS)에 대한 학습 결과; 내지 중에서 적어도 두 개의 조합. 인공지능 프로그램은 학습된 샘플들(예를 들면, 샘플들(IMS, SDS, ELS, 또는 VBS)에 대한 학습 결과들, 및 상기 학습 결과들 중에서 적어도 두 개의 조합)을 이용하여 지형지물(LM)을 학습한다. 예를 들면, 인공지능 프로그램은 샘플 영상들(IMS) 각각에 포함된 객체들에 따라 지형지물(LM)을 학습한다. 예를 들면, 인공지능 프로그램은 샘플 영상들(IMS) 각각에 포함된 수목의 분포, 계곡의 유무, 물이 흐르는지 유무, 비탈길의 유무, 등으로 지형지물(LM)을 학습할 수 있다. 도 5는 촬영 영상들을 이용하여 객체의 이동 방법, 이동 속도, 및 이동 방향을 획득하는 방법을 설명하는 도면 이다. 해당 촬영 영상(FA2, FB2, 및 FC2)에서 점선으로 표시된 제1객체는 이전 영상(FA1, FB1, 및 FC1)에 포함 된 제1객체를 의미하고, 실선으로 표시된 제1객체는 해당 촬영 영상(FA2, FB2, 및 FC2)에 포함된 제1 객체를 의미한다. 본 발명에 대한 이해를 돕기 위해, 현재 촬영 영상(FA2, FB2, 및 FC2)은 이전 촬영 영상(FA1, FB1, 및 FC1)에 포함된 점선으로 표시된 제1객체와, 현재 촬영 영상(FA2, FB2, 및 FC2)에 포함된 실선으로 표시된 제1객체 를 함께 도시한다. 실시 예에 따라 경우1(CASE1)를 참조하면, 학습 데이터가 생성되어 데이터베이스에 저장된 후, 인공 지능 프로그램은 제1시점에 제1촬영 영상 (FA1)을 수신하고 제1촬영 영상(FA1)에 포함된 제1객체를 학습 데이터를 이용하여 식별한다(S115). 그후, 인공지능 프로그램은 제2시점에 제2촬영 영상(FA2)을 수신하고 제2촬영 영상(FA2)에 포함된 제1객체 를 학습 데이터를 이용하여 식별한다(S120). 예를 들면 각 단계(S115와 S120)를 수행할 때, 인공지능 프로그램은 각 촬영 영상(FA1과 FA2)에 몇개의 객 체들이 포함되어 있는지, 객체가 도구(예를 들면, 도검, 총기, 절단기, 또는 사다리 등)를 소지하고 있는지를 학습 데이터를 이용하여 식별할 수도 있다. 인공지능 프로그램은 단계들(S115와 S120)에서 식별된 제1객체들의 움직임(또는 움직임의 변화량)을 학습 데이터를 이용하여 분석하고, 제1객체의 제1이동 방법, 제1이동 속도, 및 제1이동 방향을 획득 한다(S125). 이때, 인공지능 프로그램은 제1객체의 특정 부분(예를 들면, 제1객체의 머리, 발 또는 손 등)을 이용하여 제1객체들의 움직임(또는 움직임의 변화량)을 학습 데이터를 이용하여 분석할 수 있다. 인공지능 프로그램은 제1이동 방향(예를 들면, 북북동, 몇도 내지 몇도)을 학습 데이터를 이용하여 분석하여 제1객체의 제1목적지(DT1)를 예측한다. 예를 들면, 인공지능 프로그램은 제1객체가 제 1이동 경로(PA1)를 통해 제1목적지(DT1)로 갈 것이라고 예측한다. 인공지능 프로그램은 제1이동 방법(예를 들면, 속보)과 제1이동 속도(분당 70미터 내지 80미터)를 학습 데 이터를 이용하여 분석하여 제1객체가 제1목적지(DT1)에 도달할 제1시간을 예측한다(S135). 예측된 제 1시간은 제1객체 가 제1위치(P1)로부터 제1이동 경로(PA1)를 통해 제1목적지(DT1)에 도달할 최소 예측 시 간과 최대 예측 시간을 포함한다. 예를 들면, 경우2(CASE2)를 참조하면 인공지능 프로그램은 제1시점에 제1촬영 영상(FB1)을 수신하고 제1촬 영 영상(FB1)에 포함된 제1객체를 학습 데이터 를 이용하여 식별한다(S115). 그후, 인공지능 프로그램은 제2시점에 제2촬영 영상(FB2)을 수신하고 제2촬영 영상(FB2)에 포함된 제1객체 를 학습 데이터를 이용하여 식별한다(S120). 인공지능 프로그램은 단계들(S115와 S120)에서 식별된 객체들의 움직임(또는 움직임의 변화량)을 학 습 데이터를 이용하여 분석하고, 제1객체 의 제2이동 방법, 제2이동 속도, 및 제2이동 방향을 획득한 다(S125). 인공지능 프로그램은 제2이동 방향(예를 들면, 서북서, 몇도 내지 몇도)을 학습 데이터를 이용하여 분석하여 제1객체의 제2목적지(DT2)를 예측한다. 예를 들면, 인공지능 프로그램은 제1객체가 제 2지점(P2)을 포함하는 제2이동 경로(PA2)를 통해 제2목적지(DT2)로 갈 것이라고 예측한다.인공지능 프로그램은 제2이동 방법(예를 들면, 급보)과 제2이동 속도(예를 들면, 분당 100미터 내지 110미 터)를 학습 데이터를 이용하여 분석하여 제1객체가 제2지점(P2)를 경유하여 제2목적지(DT2)에 도달할 제2시간을 예측한다(S135). 예측된 제2시간은 제1객체가 제1위치(P1)로부터 이동 경로들(PA2와 PB2)을 통 해 제2목적지(DT2)에 도달할 최소 예측 시간과 최대 예측 시간을 포함한다. 예를 들면, 경우3(CASE3)를 참조하면 인공지능 프로그램은 제1시점에 제1촬영 영상(FC1)을 수신하고 제1촬 영 영상(FC1)에 포함된 제1객체를 학습 데이터를 이용하여 식별한다(S115). 그후, 인공지능 프로그램은 제2시점에 제2촬영 영상(FC2)을 수신하고 제2촬영 영상(FC2)에 포함된 제1객체 를 학습 데이터를 이용하여 식별한다(S120). 인공지능 프로그램은 단계들(S115와 S120)에서 식별된 객체들의 움직임(또는 움직임의 변화량)을 학 습 데이터를 이용하여 분석하고, 제1객체의 제3이동 방법, 제3이동 속도, 및 제3이동 방향을 획득한 다(S125). 인공지능 프로그램은 제3이동 방향(예를 들면, 동북동, 몇도 내지 몇도)을 학습 데이터를 이용하여 분석하여 제1객체의 제3목적지(DT3)를 예측한다. 예를 들면, 인공지능 프로그램은 제1객체가 제 3지점(P3)를 포함하는 제3이동 경로(PA3)를 통해 제3목적지(DT3)로 갈 것이라고 예측한다. 인공지능 프로그램은 제3이동 방법(예를 들면, 뛰어서)과 제3이동 속도 (예를 들면, 시속 15km 내지 18k m)를 학습 데이터를 이용하여 분석하여 제1객체가 제3지점(P3)를 경유하여 제3목적지(DT3)에 도달할 제3시간을 예측한다 (S135). 예측된 제3시간은 제1객체가 제1위치(P1)로부터 이동 경로들(PA3와 PB3)을 통 해 제3목적지(DT3)에 도달할 최소 예측 시간과 최대 예측 시간을 포함한다. 도 6은 객체가 침입자로 판단될 때의 작동을 설명하는 플로우차트이다. 도 1 내지 도 6을 참조하여 인공지능 프 로그램이 제3목적지(DT3)에 도달한 제1객체 를 침입자를 판단하는 경우들을 설명한다. 센서는 (i) 소리를 감지하는 센서, (ⅱ) 전기 신호를 감지하는 센서, (ⅲ) 진동을 감지하는 센서, 또는 (ⅳ) 소리, 전기 신호, 및 진동 중에서 적어도 두 개를 감지하는 센서의 집합을 통칭한다. 인공지능 프로그램이 제1객체를 침입자를 판단할 수 있는 예들은 아래와 같다. 촬영 장치에 의해 촬영된 영상들(IM)을 이용하여 침입자로 판단; 소리를 감지하는 센서로부터 출력된 소리 신호들(SS)을 이용하여 침입자로 판단; 전기 신호를 감지하는 센서로부터 출력된 전기 신호들(ES)을 이용하여 침입자로 판단; 진동을 감지하는 센서로부터 출력된 진동 신호들(VS)을 이용하여 침입자로 판단; 내지 중에서 적어도 2개를 조합하여 침입자로 판단. 예를 들면, 인공지능 프로그램은 촬영 장치에 의해 촬영된 제3촬영 영상들 각각을 촬영 장치 인터페 이스를 통해 수신하고, 상기 제3촬영 영상들 각각에 포함된 제1객체와 제2객체를 학습 데이터를 이용하여 식별하고(S115와 S120), 상기 제3촬영 영상들 각각에 포함된 제1객체의 움직임을 학습 데이터 를 이용하여 분석하여 제1객체의 제4이동 방법, 제4이동 속도, 및 제4이동 방향을 획득하고(S125), 상기 제4이동 방향을 이용하여 제1객체의 제4목적지(DT4)를 예측하고(S130), 상기 제4이동 방법과 상기 제 4이동 속도를 이용하여 제1객체가 제4목적지(DT4)에 도달할 제4시간을 예측한다(S135). 예측된 제4시간은 제1객체가 제3목적지(DT3)로부터 제4목적지(DT4)에 도달할 최소 예측 시간과 최대 예측 시간을 포함한다. 인공지능 프로그램에 의해 제2객체가 울타리로 식별될 때, 인공지능 프로그램은 제1객체가 울타리를 통한 침입 행위를 하는지를 판단한다(S137). 제1객체가 사람(즉, 침입자)이고, 침입자가 울타리에 대한 침입 행위를 한다고 판단될 때(S137 의 YES), 인공지능 프로그램은 경보 장치 를 이용하여 경보를 발생하고, 제4목적지(DT4)와 제1객체 가 제4목적지 (DT4)에 도달할 제4시간을 포함하는 예측 정보(IF)를 생성하여 단말기로 전송한다. 단 말기는 예측 정보(IF)에 응답하여 단말기의 경보기를 이용하여 경보(예를 들면, 시각적 경보, 청각적 경보, 또는 시청각적 경보)를 발생할 수 있다. 실시 예에 따라, 인공지능 프로그램이 촬영 장치에 의해 촬영된 제3촬영 영상들을 학습 데이터 를 이용하여 식별하고 분석하고, 분석 결과에 따라 제1객체가 몇명인지, 제1객체가 도구(예를 들면, 도검, 총기, 절단기 또는 사다리 등)를 소지하는지, 및 상기 도구의 종류를 판단할 수 있을 때, 인공지능 프로 그램은 제4목적지(DT4), 제4시간, 제1객체가 몇명인지, 제1객체가 도구를 소지하는지, 및 상기 도구의 종류를 포함하는 예측 정보(IF)를 생성하여 단말기로 전송한다. 이에 따라 단말기의 담당자는 예측 정보(IF)에 따라 침입자인 제1객체 의 침입을 예방 또는 제1객체 의 침입에 대한 조치(또는 대응 방안)을 수립할 수 있다. 조치(또는 대응 방안)은 몇명의 담당자들이 필요 하고 상기 담당자들 각각이 어떤 무기를 가지고 갈지를 포함한다. 실시 예에 따라, 인공지능 프로그램이 촬영 장치에 의해 촬영된 제3촬영 영상들을 학습 데이터 를 이용하여 식별하고 분석하고, 분석 결과에 따라 제1객체가 몇명인지, 제1객체가 도구(예를 들면, 도검, 총기, 또는 절단기)를 소지하는지, 및 상기 도구의 종류를 판단할 수 있을 때, 인공지능 프로그램은 제4목적지(DT4), 제4시간, 제1객체가 몇명인지, 제1객체가 도구를 소지하는지, 상기 도구의 종류, 및 제1객체의 침입을 예방하거나 제1객체를 체포하기 위해 몇 명의 담당자가 필요하고 각 담당자가 어떤 무기를 가지고 갈지를 포함하는 예측 정보(IF)를 생성하여 단말기로 전송한다. 즉, 인공지능 프로그램은 침입자인 제1객체에 대응하기 위한 조치 (또는 대응 방안)을 학습 데이터 를 이용하여 분석하고, 분석 결과에 따라 상기 조치(또는 대응 방안)을 포함하는 예측 정보(IF)를 생성하 여 단말기로 전송할 수 있다. 제1객체의 침입 행위의 예들은 제1객체가 울타리를 무단으로 절단하는 행위, 제1객체가 울 타리에 생긴 구멍을 통과하는 행위, 제1객체가 울타리의 아래에 굴을 파는 행위, 제1객체 가 사다리를 타고 울타리를 오르는지, 및 제1객체가 울타리를 넘는 행위를 포함한다. 인공지능 프로그램은 제3촬영 영상들 각각에 포함된 제1객체의 행위(또는 행동)을 학습 데이터 를 이용하여 분석하고, 분석의 결과에 따라 제1객체가 사람이지만 상기 사람이 울타리에 대한 침입 행위를 하지 않는다고 판단될 때(S137의 NO), 인공지능 프로그램은 센서 인터페이스를 통해 센서 의 주위에 설치된 스피커를 제어하여 경고 방송을 할 수 있다(S139). 실시 예에 따라 제1객체가 동물이고 상기 동물이 울타리에 대한 침입 행위를 하지 않는다고 판단될 때 (S137의 NO), 인공지능 프로그램은 센서 인터페이스를 통해 센서의 주위에 설치된 경광등을 제 어하여 경고를 할 수 있다. 다른 실시 예에 따라 제1객체가 동물이고 울타리가 전기 울타리일 때 (S137의 NO), 인공지능 프로그램은 센서 인터페이스를 통해 전기 울타리 로 전류를 흐르게 하여 상기 동 물을 전기 울타리로부터 퇴치할 수 있다. 실시 예들에 따라 제2객체가 울타리로 식별될 때, 인공지능 프로그램 은 제1객체가 울타리(40 0)를 통한 침입 행위를 소리 신호들(SS)을 이용하여 판단한다(S137). 학습 데이터는 소리 신호 학습 데이터(241B)를 포함하므로, 인공지능 프로그램은 센서로부터 출 력된 소리 신호들(SS)을 센서 인터페이스를 통해 수신하고, 소리 신호들(SS)이 인위적인 소리 신호인지를 소리 신호 학습 데이터(241B)를 이용하여 판단하고, 소리 신호들(SS)이 상기 인위적인 소리 신호들로 판단될 때 제1객체를 울타리를 통한 침입자로 판단하고(S137의 YES), 경보 장치를 이용하여 경보를 발생하 고, 제4목적지(DT4)와 제1객체가 제4목적지(DT4)에 도달할 제4시간을 포함하는 예측 정보(IF)를 생성하여 단말기로 전송한다(S140). 실시 예들에 따라 제2객체가 울타리로 식별될 때, 인공지능 프로그램 은 제1객체가 울타리(40 0)를 통한 침입 행위를 전기 신호들(ES)을 이용하여 판단한다(S137). 학습 데이터는 전기 신호 학습 데이터(241C)를 포함하므로, 인공지능 프로그램은 센서로부터 출 력된 전기 신호들(ES)을 센서 인터페이스를 통해 수신하고, 전기 신호들(ES)이 인위적인 전기 신호들인지 를 전기 신호 학습 데이터(241C)를 이용하여 판단하고, 전기 신호들(ES)이 상기 인위적인 전기 신호들로 판단될 때 제1객체를 울타리를 통한 침입자로 판단하고(S137의 YES), 경보 장치를 이용하여 경보를 발 생하고, 제4목적지(DT4)와 제1객체가 제4목적지(DT4)에 도달할 제4시간을 포함하는 예측 정보(IF)를 생성 하여 단말기로 전송한다(S140). 실시 예들에 따라 제2객체가 울타리로 식별될 때, 인공지능 프로그램 은 제1객체가 울타리(40 0)를 통한 침입 행위를 진동 신호들(VS)을 이용하여 판단한다(S137).학습 데이터는 진동 신호 학습 데이터(241D)를 포함하므로, 인공지능 프로그램은 센서로부터 출 력된 진동 신호들(VS)을 센서 인터페이스를 통해 수신하고, 진동 신호들(VS)이 인위적인 진동 신호들인지 를 진동 신호 학습 데이터(241D)를 이용하여 판단하고, 진동 신호들(VS)이 상기 인위적인 진동 신호들로 판단될 때 제1객체를 울타리를 통한 침입자로 판단하고(S137의 YES), 경보 장치를 이용하여 경보를 발 생하고, 제4목적지(DT4)와 제1객체가 제4목적지(DT4)에 도달할 제4시간을 포함하는 예측 신호(IF)를 생성 하여 단말기로 전송한다(S140). 앞의 실시 예들에서 설명한 바와 같이, 목적지와 상기 목적지에 도달할 시간이 예측된 후, 인공지능 프로그램 은 해당 촬영 장치(353, 363, 373, 383, 또는 393)에 의해 촬영된 영상들 각각에 포함된 제1객체를 식별하고(S145), 제1객체의 움직임을 분석하여 제1객체의 새로운 목적지와 상기 새로운 목적지에 도 달할 새로운 시간을 예측하고, 예측된 목적지와 예측된 시간을 예측된 새로운 목적지와 예측된 새로운 시간으로 실시간 업데이트하고(S150), 상기 예측된 새로운 목적지와 상기 예측된 새로운 시간을 포함하는 새로운 예측 정 보(IF)를 생성하여 통신 장치를 통해 단말기로 전송한다(S140). 인공지능 프로그램이 제1객체의 목적지(DT5, DT6, DT7, 또는 DT8)와 목적지(DT5, DT6, DT7, 또는 DT8)에 도달할 시간을 예측하고 예측된 목적지와 예측된 시간을 포함하는 예측 정보(IF)를 생성하는 과정은, 제 1객체의 목적지 (DT1, DT2, DT3, 또는 DT4)와 목적지(DT1, DT2, DT3, 또는 DT4)에 도달할 시간을 예측하 고 예측된 상기 목적지와 예측된 시간을 포함하는 예측 정보(IF)를 생성하는 과정과 대동소이하다. 도 7은 도 1에 도시된 침입 경계 시스템의 작동 방법을 설명하는 플로우차트이다. 도 1 내지 도 7을 참조하여 인공지능 프로그램이 제1객체가 존재하는 위치에 대한 지형 및/또는 지물 을 식별하고, 식별된 지형 지물을 이용하여 목적지와 상기 목적지에 도달할 시간을 예측하는 방법을 설명한다. 도 5의 각 촬영 영상(FA1, FA2, FB1, FB2, FC1, 및 FC2)에 포함된 객체는 지형 지물에 대한 정보를 획득 하기 위한 객체라고 가정한다. 실시 예들에 따라, 도 5의 경우1(CASE1)를 참조하면. 인공지능 프로그램 은 제1촬영 영상(FA1)에 포함된 제1객체와 제2객체 및 제2촬영 영상(FA2)에 포함된 제1객체와 제2객체를 학습 데이터(24 1)를 이용하여 분석하고, 분석의 결과에 따라 제1객체가 존재하는 위치의 지형 지물 정보를 식별한다 (S210). 인공지능 프로그램은 제1객체의 제1이동 방향과 식별된 지형 지물 (또는 지형지물 정보)를 학습 데이 터를 이용하여 분석하고 제1객체의 제1목적지를 예측한다(S130A). 인공지능 프로그램은 제1이동 방법, 제1이동 속도, 및 식별된 지형 지물을 학습 데이터를 이용하여 분석하고 제1객체가 제1목적지에 도달할 제1시간을 예측한다(S135A). 실시 예들에 따라, 제1촬영 영상(FA1)과 촬영 영상(FA2)은 동일한 촬영 장치로부터 출력되거나 서로 다른 촬영 장치로부터 출력될 수 있다. 실시 예들에 따라, 데이터베이스는 지형 지물 정보를 저장하고 있으므로, 인공지능 프로그램은 제1촬영 영상(FA1)를 출력하는 제1촬영 장치 의 제1위치 정보(PI1)와 제2촬영 영상(FA2)을 출력하는 제2촬 영 장치의 제2위치 정보(PI2)를 지형 지물 정보를 이용하여 분석하고 제1객체가 존재하는 지형 지물(예를 들면, 지형 정보(TG1)와 지물 정보(FI1)에 해당하는 지형 지물)를 식별한다(S210). 동일한 이동 방법으로 제1객체가 평지를 이동할 때의 이동 속도와 제1객체가 경사가 급한 산지를 이 동할 때의 이동 속도는 서로 다르다. 따라서, 인공지능 프로그램이 제1객체의 이동 속도를 예측할 때, 인공지능 프로그램이 식별된 지형 지물 정보를 이용하면 제1객체의 이동 속도를 좀 더 정확하게 예측할 수 있다. 도 7의 단계들(S110~S125, 및 S140~S150)과 도 4의 단계들(S110~S125, 및 S140~S150)은 동일하므로, 단계들 (S110~S125, 및 S140~S150)에 대한 설명은 생략한다. 또한 도 6의 단계들(S137과 S139)은 도 7의 단계들(S135A 와 S140) 사이에 적용된다. 실시 예들에 따라, 제1촬영 영상(FA1)과 촬영 영상(FA2)은 동일한 촬영 장치로부터 출력되거나 서로 다른 촬영 장치로부터 출력될 수 있다. 제1촬영 영상(FA1)과 촬영 영상(FA2)은 드론에 의해 촬영된 영상일 수 있다. 인공지능 알고리즘(또는 인공지능 프로그램)을 이용한 침입 예측 방법은 샘플 영상들(SPI)을 상기 인공지 능 알고리즘을 이용하여 학습하여 학습 데이터 를 생성하고(S110), 제1촬영 영상(FA1, FB1, 또는 FC1)을 수신하고 제1촬영 영상(FA1, FB1, 또는 FC1)에 포함된 제1객체를 학습 데이터를 이용하여 식별하고 (S115), 제2촬영 영상(FA2, FB2, 또는 FC2)을 수신하고 제2촬영 영상(FA2, FB2, 또는 FC2)에 포함된 제1객체 를 학습 데이터를 이용하여 식별하고 (S120), 제1촬영 영상(FA1, FB1, 또는 FC1)과 제2촬영 영상 (FA2, FB2, 또는 FC2) 각각에서 식별된 제1객체의 움직임을 학습 데이터를 이용하여 분석하여 제1객 체의 이동 방법, 이동 속도, 및 이동 방향을 획득하고(S125), 상기 이동 방향을 학습 데이터를 이용 하여 분석하여 제1객체의 목적지를 예측하고 (S130), 상기 이동 방법과 상기 이동 속도를 학습 데이터 를 이용하여 분석하여 제1객체가 상기 목적지에 도달할 시간을 예측한다(S135). 실시 예들에 따라 상기 침입 예측 방법은 제3촬영 영상들을 수신하고 상기 제3촬영 영상들 각각에 포함된 제1객 체와 제2객체를 학습 데이터를 이용하여 식별하고, 상기 제2객체가 울타리로 식별될 때 제1객체 가 울타리를 통한 침입 행위를 하는지를 판단하고(S137), 제1객체가 울타리에 대한 침입 행위를 할 때 경보를 발생하고 예측된 목적지와 예측된 시간을 포함하는 예측 정보(IF)를 생성하여 단말기(60 0)로 전송한다(S140). 실시 예들에 따라 상기 침입 예측 방법은 샘플 소리 신호들(SDS)을 인공지능 알고리즘을 이용하여 더 학습하여 학습 데이터를 생성하고(S110), 소리 신호들(SS)을 수신하고 소리 신호들(SS)이 인위적인 소리 신호들인지 를 학습 데이터 를 이용하여 판단하고, 소리 신호들(SS)이 상기 인위적인 소리 신호들로 판단될 때 제1객 체를 울타리를 통한 침입자로 판단하고(S137의 YES), 경보를 발생하고 예측된 목적지와 예측된 시간 을 포함하는 예측 정보(IF)를 생성하여 단말기로 전송한다(S140). 실시 예들에 따라 상기 침입 예측 방법은 샘플 전기 신호들(ELS)을 인공지능 알고리즘을 이용하여 더 학습하여 학습 데이터를 생성하고(S110), 전기 신호들(ES)을 수신하고 전기 신호들(SS)이 인위적인 전기 신호들인지 를 학습 데이터 를 이용하여 판단하고(S137), 전기 신호들(ES)이 상기 인위적인 전기 신호들로 판단될 때 제1객체를 울타리를 통한 침입자로 판단하고(S137의 YES), 경보를 발생하고 예측된 목적지와 예측된 시간을 포함하는 예측 정보(IF)를 생성하여 단말기로 전송한다(S140). 실시 예들에 따라 상기 침입 예측 방법은 샘플 진동 신호들(VBS)을 인공지능 알고리즘을 이용하여 더 학습하여 학습 데이터를 생성하고(S110), 진동 신호들(VS)을 수신하고 진동 신호들(VS)이 인위적인 진동 신호들인지 를 학습 데이터 를 이용하여 판단하고(S137), 진동 신호들(VS)이 상기 인위적인 진동 신호들로 판단될 때 제1객체를 울타리를 통한 침입자로 판단하고(S137의 YES), 경보를 발생하고 예측된 목적지와 예측된 시간을 포함하는 예측 정보(IF)를 생성하여 단말기로 전송한다(S140). 실시 예에 따라 인공지능 프로그램은 제1촬영 영상(FA1, FB1, 또는 FC1)에 포함된 제2객체와 제2촬영 영상(FA2, FB2, 또는 FC2)에 포함된 제2객체를 학습 데이터를 이용하여 분석하여 제1객체가 존 재하는 위치의 지형지물을 식별하고(S210), 획득된 제1객체의 이동 방향과 식별된 지형지물을 학습 데이터 를 이용하여 분석하여 제1객체의 목적지를 예측한다(S130A). 인공지능 프로그램은 획득된 이동 방법, 획득된 이동 속도, 및 식별된 지형 지물을 학습 데이터를 이 용하여 분석하여 제1객체가 목적지에 도달할 시간을 예측한다(S135A). 실시 예에 따라 인공지능 프로그램은 제1촬영 영상(FA1, FB1, 또는 FC1)과 제2촬영 영상(FA2, FB2, 또는 FC2)을 출력하는 동일한 촬영 장치가 설치된 위치 정보를 분석하여 제1객체가 존재하는 위치의 지형 지물 을 식별하고, 획득된 이동 방향과 식별된 지형 지물을 학습 데이터를 이용하여 분석하여 제1객체의 목적지를 예측한다(S130A). 인공지능 프로그램은 획득된 이동 방법, 획득된 이동 속도, 및 식별된 지형 지물을 학습 데이터를 이 용하여 분석하여 제1객체가 목적지에 도달할 시간을 예측한다(S135A). 실시 예에 따라 인공지능 프로그램은 제1촬영 영상(FA1, FB1, 또는 FC1)를 출력하는 제1촬영 장치의 제1위치 정보(PI1)와 제2촬영 영상(FA2, FB2, 또는 FC2)을 출력하는 제2촬영 장치의 제2위치 정보(PI2)를 분석하여 제1객체가 존재하는 지형 지물을 식별하고, 획득된 이동 방향과 식별된 지형지물을 학습 데이터 를 이용하여 분석하여 제1객체의 목적지를 예측한다 (S130A). 인공지능 프로그램은 획득된 이동 방법, 획득된 이동 속도, 및 식별된 지형 지물을 학습 데이터를 이 용하여 분석하여 제1객체가 목적지에 도달할 시간을 예측한다(S135A).인공지능 프로그램은 제3촬영 영상을 수신하고 상기 제3촬영 영상에 포함된 제1객체를 학습 데이터 를 이용하여 식별하고(S145), 제2촬영 영상 (FA2, FB2, 또는 FC2)과 상기 제3촬영 영역 각각에서 식별된 제1객체의 움직임을 학습 데이터를 이용하여 분석하여 제1객체의 새로운 이동 방법, 새로운 이 동 속도, 및 새로운 이동 방향을 획득하고(S145), 새로운 이동 방향을 학습 데이터를 이용하여 분석하여 제1객체의 새로운 목적지를 예측하고 (S145), 새로운 이동 방법과 새로운 이동 속도를 학습 데이터를 이용하여 분석하여 제1객체가 새로운 목적지에 도달할 시간을 예측한다(S145). 인공지능 프로그램은 이전 목적지를 새로운 목적지로 변경하고, 이전에 예측된 제1시간을 새롭게 예측된 시간으로 변경하고, 새로운 목적지와 상기 새로운 시간을 포함하는 예측 정보를 생성하여 단말기로 전송한 다(S150). 본 발명은 도면에 도시된 실시 예를 참고로 설명되었으나 이는 예시적인 것에 불과하며, 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시 예가 가능하다는 점을 이해할 것이다. 따라서, 본 발명의 진정한 기술적 보호 범위는 첨부된 등록청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2023-0014886", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 상세한 설명에서 인용되는 도면을 보다 충분히 이해하기 위하여 각 도면의 상세한 설명이 제공된다. 도 1은 본 발명의 실시 예에 따른 인공지능을 이용한 침입 경계 시스템의 블록도이다.도 2는 도 1에 도시된 인공지능을 이용한 제어 장치의 블록도이다. 도 3은 도 1에 도시된 침입 경계 시스템의 작동 방법의 실시 예를 설명하는 플로우차트이다. 도 4는 인공지능 알고리즘을 이용하여 학습 데이터를 생성하는 과정을 설명하는 도면이다. 도 5는 촬영 영상들을 이용하여 객체의 이동 방법, 이동 속도, 및 이동 방향을 획득하는 방법을 설명하는 도면 이다. 도 6은 객체가 침입자로 판단될 때 침입 경계 시스템의 작동을 설명하는 플로우차트이다. 도 7은 도 1에 도시된 침입 경계 시스템의 작동 방법의 실시 예를 설명하는 플로우차트이다."}
