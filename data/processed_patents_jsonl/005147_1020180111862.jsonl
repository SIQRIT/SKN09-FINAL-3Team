{"patent_id": "10-2018-0111862", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0032614", "출원번호": "10-2018-0111862", "발명의 명칭": "인공지능을 이용한 텍스트 및 그림 데이터를 동영상 데이터로 생성하는 시스템", "출원인": "이승일", "발명자": "이승일"}}
{"patent_id": "10-2018-0111862", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "글이 포함된 텍스트 문서를 입력받아 대본, 소설, 희곡, 일기, 그림이 있는 글 등 형식에 따라 분류하는 텍스트입력부와;상기 입력받은 텍스트를 동일한 장소, 배경 등을 기준으로 하나의 씬으로 구분하여 전체 텍스트를 순차적으로씬 단위로 분할하는 씬단위분할부와;상기 씬단위분할부에서 분할된 씬 텍스트로부터 문맥에 상응하는 인물, 사물, 장소, 배경 등의 객체를 인식하고각 객체의 동작, 형상, 분위기, 위치 등의 핏쳐를 인식하여 할당하는 객체인식부와; 상기 객체인식부에서 인식된 핏쳐링된 객체와 매칭되는 동영상 객체를 찾아서 반환하거나 정지영상 객체를 학습된 데이터로 핏쳐에 맞게 생성한 동영상 객체를 반환하는 객체영상생성부와;배경에 객체 배치, 텍스트의 순서에 따라 문맥에 맞게 화면을 이동하면서 각 객체를 재생하거나 소리를 재생하여 단위 영상 데이터를 생성하고 복수의 단위 영상 데이터가 생성된 경우 이를 일정 크기로 연결하여 출력하는영상데이터 생성부;를포함하여 구성되는 것을 특징으로 하는 인공지능을 이용한 텍스트를 영상데이터로 생성하는 시스템"}
{"patent_id": "10-2018-0111862", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 기계학습과 같은 인공지능을 이용한 텍스트 및 그림 데이터를 동영상 데이터로 생성하는 시스템에 관 한 것으로, 보다 상세하게는 기계학습된 데이터를 이용하여 대본, 소설, 희곡과 같은 텍스트나 만화와 같은 그림 이 있는 글 데이터를 이해하고 이에 매칭되는 영상 객체들을 사용하여 동영상 데이터를 생성하는 인공지능을 이 용한 텍스트 및 그림 데이터를 동영상 데이터로 생성하는 시스템에 관한 것이다."}
{"patent_id": "10-2018-0111862", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 기계학습과 같은 인공지능을 이용한 텍스트 및 그림 데이터를 영상 데이터로 생성하는 시스템에 관한 것으로, 보다 상세하게는 기계학습된 데이터를 이용하여 대본, 소설, 희곡과 같은 텍스트나 만화와 같은 그림이 있는 글 데이터를 이해하고 이에 매칭되는 영상 객체들을 사용하여 동영상 데이터를 생성하는 인공지능을 이용 한 텍스트 및 그림 데이터를 동영상 데이터로 생성하는 시스템에 관한 것이다."}
{"patent_id": "10-2018-0111862", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기존의 동영상 제작 프로그램은 사람이 손으로 일일히 그려야 하고 타임 슬롯에 따라 수 많은 프레임 작업이 필 요했다. 또한 그 프로그램의 사용법이 복잡하여 일반인들은 접근하기 어려웠다. 그러나 객체인식과 기계학습의 발전으로 사진 이미지의 배경, 장소, 날씨, 사물, 인물, 동물 등과 같은 객체를 인식하고 그 객체의 움직임, 형상, 분위기, 위치, 자세 등의 핏쳐(속성)를 텍스트로 설명할 수 있게 되었다. 그러나 이는 사진 데이터를 텍스트로 표현하는 단계에 머무르고 있으며 이를 그대로 텍스트 데이터를 동영상 데 이터로 표현하기에는 불가능한 문제점이 있다."}
{"patent_id": "10-2018-0111862", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기한 문제점을 해결하기 위하여, 대본, 소설, 희곡, 일기, 그림이 있는 글 등 입력된 텍스트의 형 식 유형을 분류하고 기계학습된 데이터를 이용하여 글 및 손그림 데이터를 이해하며 이에 매칭되는 영상 객체들 을 사용하여 동영상 데이터를 생성하는 인공지능을 이용한 텍스트 및 그림 데이터를 동영상 데이터로 생성하는 시스템을 제공하는 것을 해결하고자 하는 과제로 한다."}
{"patent_id": "10-2018-0111862", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 상기 과제를 해결하기 위하여, 글이 포함된 텍스트 문서를 입력받고 대본, 소설, 희곡, 일기, 그림이 있는 글 등 형식에 따라 분류하는 텍스트 입력부와, 상기 입력받은 텍스트를 동일한 장소, 배경 등을 기준으로 하나의 씬으로 구분하여 전체 텍스트를 순차적으로 씬 단위로 분할하는 씬단위분할부와, 상기 씬단위분할부에서 분할된 씬 텍스트로부터 (바람, 나무, 책상, 학교 등 보통 명사와 목적어 등으로 표현되는) 문맥에 상응하는 인 물, 사물, 장소, 배경 등의 객체를 인식하고 각 객체의 동작, 형상, 분위기, 위치 등의 핏쳐를 인식하여 할당하 는 객체인식부와, 상기 객체인식부에서 인식된 핏쳐링된 객체와 매칭되는 동영상 객체를 찾아서 반환하거나 정 지영상 객체를 학습된 데이터로 핏쳐에 맞게 생성한 동영상 객체를 반환하는 객체영상생성부와, 배경에 객체 배 치, 텍스트의 순서에 따라 문맥에 맞게 화면을 이동하면서 각 객체를 재생하거나 소리를 재생하여 단위 영상 데 이터를 생성하고 복수의 단위 영상 데이터가 생성된 경우 이를 일정 크기로 연결하여 출력하는 영상데이터 생성 부를 포함하여 구성되는 것을 특징으로 하는 인공지능을 이용한 텍스트를 영상데이터로 생성하는 시스템을 과제 의 해결 수단으로 한다."}
{"patent_id": "10-2018-0111862", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 인공지능을 이용한 텍스트 및 그림 데이터를 동영상 데이터로 생성하는 시스템은 기계학습된 데이터 를 이용하여 대본, 소설, 희곡과 같은 텍스트나 만화와 같은 그림이 있는 글 데이터를 이해하고 이에 매칭되는 영상 객체들을 사용하여 동영상 데이터를 생성하는 효용성이 있다."}
{"patent_id": "10-2018-0111862", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은, 글이 포함된 텍스트 문서를 입력받아 전처리 과정을 수행하는 텍스트 입력부와, 상기 입력받은 텍스 트를 동일한 장소, 배경 등을 하나의 씬으로 구분하여 전체 텍스트를 순차적으로 씬 단위로 분할하는 씬단위분 할부와, 상기 씬단위분할부에서 분할된 씬 텍스트로부터 문맥에 상응하는 객체를 인식하고 각 객체의 동작, 형 상 등의 핏쳐를 인식하여 할당하는 객체인식부와, 상기 객체인식부에서 인식된 핏쳐링된 객체와 매칭되는 동영 상 객체 혹은 정지영상 객체를 학습된 데이터로 핏쳐에 맞게 생성한 동영상 객체를 반환하는 객체영상생성부와, 배경에 핏쳐링된 객체를 배치하고 문맥에 맞게 화면을 이동하면서 각 객체를 재생하거나 소리를 재생하여 씬 단 위 영상 데이터를 생성하고 생성된 씬 단위 동영상들을 합쳐서 출력하는 영상데이터 생성부를 포함하여 구성되 는 것을 특징으로 하는 인공지능을 이용한 텍스트를 영상데이터로 생성하는 시스템을 기술구성의 특징으로 한다. 상기 텍스트 입력부는 대본, 소설, 일기, 만화와 같은 그림이 있는 글 등 텍스트가 포함된 데이터를 입력으로 받는다. 사용자로 부터 대본인지 희곡인지 등의 장르를 입력 받을 수도 있고 텍스트 데이터의 포맷으로 장르를 인지할 수 도 있다. 상기 전처리 과정은 동일한 객체이지만 다른 단어로 쓰였거나 다른 객체인데 같은 단어로 쓰이는 경우 등에 대 해 처리한다. 상기 씬 단위 분할부는 텍스트 데이터, 즉 텍스트 문서를 처음부터 순차적으로 씬 단위로 구분한다. 여기서 하 나의 씬은 동일한 장소, 배경, 화면을 의미한다. 이때는 문서의 형식이나 기호를 기준으로 씬을 구분할 수도 있 고, 기계학습을 통해 문장을 이해하며 장면의 전환 시점을 하나의 씬으로 구분할 수 도 있다. 예를 들어 대본의 경우 '#번호' 기호를 하나의 씬으로 구분할 수 있다. 씬은 동영상 생성의 단위로 용이하기 때문에 구분하는 것으로 문서 전체를 하나의 동영상으로 생성할 수 있다. 또한 하나의 씬에서도 몽타주씬, 회상씬, 교차씬 등 배경 의 전환이 이루어 질 수 있다. 만화와 같이 그림이 있는 글의 경우 그림 배경을 장면의 전환으로 기계학습된 모델로 그림을 분석하여 씬을 구분할 수 있다. 상기 객체인식부는 씬 텍스트로 부터 바람, 나무, 책상, 학교 등 일반적으로 명사로 주어나 목적어 등으로 표현 되는 객체를 인식한다. 또한 텍스트에서 각 인식된 객체에 대해 표현하는 동작, 형상, 분위기 등 객체의 핏쳐 (속성)를 인식된 객체에 할당한다. 상기 객체영상생성부는 핏쳐링된 객체와 매칭되는 표현의 동영상 객체를 객체DB에서 찾아서 반환한다. 이 객체 DB는 본 시스템을 수행하기 전에 축적된 데이터이다. 다수의 이미지 및 동영상과 이를 설명한 텍스트로 기계학 습된 모델과 객체 인식을 통해서, 다양한 핏쳐링된 객체를 객체DB에 저장해 놓는다. 객체DB에 적합한 데이터가 없는 경우 웹상에서 동영상 및 정지 이미지를 검색하고 기계학습된 모델을 적용해 적합한 객체DB를 축적할 수 있다. 또한 정지영상 객체를 기반으로 학습된 데이터 핏쳐에 맞게 동영상 객체를 생성하여 반환할 수 도 있다. 상기 영상 데이터 생성부는 배경에 객체 배치, 텍스트의 순서에 따라 문맥에 맞게 화면을 이동하면서 각 객체를 재생하거나 소리를 재생하여 단위 영상 데이터를 생성하고 복수의 단위 영상 데이터가 생성된 경우 이를 일정 크기로 연결하여 출력한다. 또한 텍스트의 각 문장을 표현에 따라 객체의 행동/상황 묘사와 대사, 나레이션, 마음의 소리(Voice over), 음 향효과 등을 구분하여 매칭되는 음향 데이터를 동영상에 포함시킬 수 있다. 한 씬과 다른 씬의 공간이 연결되는 공간이라면 이를 연결된 공간으로 할당하여 씬과 씬이 이어지도록 화면을 구성하 할 수 있다. 동영상 데이타 생성 후 사용자가 객체의 핏쳐를 마우스 등으로 드래그하여 수정할 수 있다. 예를 들어 사람 객 체라면 타임 테이블에 따라 관절 각도, 움직이는 방향 등에 대해 세부적으로 설정할 수 있다."}
{"patent_id": "10-2018-0111862", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 인공지능을 이용한 텍스트 및 그림 동데이터를 영상 데이터로 생성하는 시스템의 전체 구성블록도"}
