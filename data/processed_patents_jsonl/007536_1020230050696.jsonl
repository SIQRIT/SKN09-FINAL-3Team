{"patent_id": "10-2023-0050696", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0149255", "출원번호": "10-2023-0050696", "발명의 명칭": "경계선 지정을 통한 어노테이션 방법", "출원인": "주식회사 인피닉", "발명자": "장소연"}}
{"patent_id": "10-2023-0050696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "어노테이션 장치가, 작업자의 제어에 따라, 인공지능(Artificial Intelligence, AI) 학습을 위한 어노테이션(annotation) 작업의 대상이 되는 이미지에 포함된 서로 중첩되어 배치되는 복수 개의 객체를 포함하는 외곽선을 지정하는 단계;상기 어노테이션 장치가, 상기 지정된 외곽선 내에 포함된 객체들을 서로 구분하기 위한 상기 복수 개의 객체들사이의 경계선을 지정하는 단계; 및상기 어노테이션 장치가, 상기 지정된 경계선을 기준으로 구획된 복수 개의 영역별로 상기 복수 개의 객체들을각각 식별하는 단계; 를 포함하되,"}
{"patent_id": "10-2023-0050696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 외곽선을 지정하는 단계는서로 중첩되어 배치되는 적어도 제1 객체와 제2 객체를 포함하는 복수의 객체의 전체 외곽선을 지정하는 것을특징으로 하고, 상기 경계선을 지정하는 단계는상기 지정된 외곽선 내에서 상기 제1 객체와 상기 제2 객체 사이의 중첩된 경계선을 지정하는 것을 특징으로 하며,상기 경계선은,상기 제1 객체의 제2 객체와 중첩되는 부분의 외곽선을 형성하는 동시에, 상기 제2 객체의 제1 객체와 중첩되는부분의 외곽선을 형성하는 것을 특징으로 하는, 어노테이션 방법."}
{"patent_id": "10-2023-0050696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 경계선을 지정하는 단계는상기 외곽선에 포함된 두 점과 상기 작업자의 제어에 따라 입력된 복수 개의 점들을 연속적으로 연결하여 설정된 복수 개의 간선을 포함시켜 상기 경계선을 지정하는 것을 특징으로 하는, 어노테이션 방법."}
{"patent_id": "10-2023-0050696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서, 상기 외곽선을 지정하는 단계는상기 작업자로부터 상기 복수 개의 객체를 포함하는 외곽선을 따라 복수 개의 점을 입력 받고, 상기 복수 개의점을 연결하여, 상기 복수 개의 객체에 대한 외곽선을 생성하는 것을 특징으로 하는, 어노테이션 방법."}
{"patent_id": "10-2023-0050696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서, 상기 외곽선을 지정하는 단계는공개특허 10-2023-0149255-3-상기 복수 개의 객체를 포함하는 일부 영역을 바운딩 박스(bounding box)로 설정하고, 상기 바운딩 박스 내측영역에서 객체의 엣지를 추출하고, 상기 추출된 엣지를 기준으로 객체(object)와 배경(background)을 구분하고,상기 배경을 삭제하여 상기 복수 개의 객체의 외곽선을 지정하는 것을 특징으로 하는, 어노테이션 방법."}
{"patent_id": "10-2023-0050696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서, 상기 경계선을 지정하는 단계는상기 지정된 외곽선 내부에 위치한 픽셀(pixel)의 RGB(Red, Green, Blue) 값을 기초로 상기 지정된 외곽선 내부에 위치한 객체의 엣지를 추출하고, 상기 복수 개의 간선 각각의 중심점을 기준으로 간선과 수직한 가상선을 생성하며, 상기 생성된 가상선과 상기 추출된 엣지가 교차하는 지점으로부터 상기 중심점 사이의 거리가 사전 설정된 값보다 큰 간선에 포함된 점을 보간(interpolation)하는 것을 특징으로 하는, 어노테이션 방법."}
{"patent_id": "10-2023-0050696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서, 상기 경계선을 지정하는 단계는상기 가상선과 상기 추출된 엣지가 교차하는 지점에 보간을 위한 신규 점을 추가하는, 어노테이션 방법."}
{"patent_id": "10-2023-0050696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6 항에 있어서, 상기 경계선을 지정하는 단계는상기 복수 개의 간선 각각의 길이가 사전 설정된 값을 초과하는 간선에 포함된 점을 보간하는 것을 특징으로 하는, 어노테이션 방법."}
{"patent_id": "10-2023-0050696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항에 있어서, 상기 경계선을 지정하는 단계는상기 작업자의 프로파일을 획득하고, 상기 획득된 프로파일을 기초로 상기 복수 개의 점들을 입력하기 위한 입력 도구 및 상기 입력 도구를 사용하기 위한 주 사용손을 식별하고, 보정 테이블로부터 상기 식별된 입력 도구및 상기 주 사용손에 대응되는 보정 값을 획득하고, 상기 획득된 보정 값을 기초로 작업자로부터 입력된 복수개의 점들을 일괄적으로 보정하는 것을 특징으로 하는, 어노테이션 방법."}
{"patent_id": "10-2023-0050696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항에 있어서, 상기 식별하는 단계는상기 식별된 객체의 외곽선을 기초로 객체의 유형을 추정하고, 상기 추정된 객체의 유형별로 사전에 저장된 3D모델을 추출하고, 상기 추출된 3D 모델을 3D 회전시켜 객체의 촬영 방향을 식별하고, 상기 식별된 촬영 방향에대응하여 사전에 설정된 객체 별 필수 구성요소를 식별하고, 상기 식별된 객체의 폐쇄 영역 내에 필수 구성요소가 존재하는지 판단하여 상기 작업자의 제어에 따라 입력된 점을 검증하는 것을 특징으로 하는, 어노테이션 방법."}
{"patent_id": "10-2023-0050696", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 이미지 속에 포함된 중첩된 객체를 용이하게 지정할 수 있는, 경계선 지정을 통한 어노테이션 방법을 제안한다. 상기 방법은 어노테이션 장치가, 작업자의 제어에 따라, 인공지능(Artificial Intelligence, AI) 학 습을 위한 어노테이션(annotation) 작업의 대상이 되는 이미지에 포함된 서로 중첩되어 배치되는 복수의 객체의 외곽선을 지정하는 단계, 상기 어노테이션 장치가, 상기 지정된 외곽선 내에서 상기 복수의 객체 사이의 경계선 을 지정하는 단계 및 상기 어노테이션 장치가, 상기 지정된 경계선을 기준으로 구획된 복수의 영역을 기준으로 상기 복수의 객체를 각각 식별하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0050696", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능(Artificial Intelligence, AI) 기계 학습용 데이터의 가공에 관한 것이다. 보다 상세하게는, 인공지능(AI) 학습용 데이터를 어노테이션함에 있어서, 이미지 속에 포함된 중첩된 객체를 용이하 게 지정할 수 있는, 경계선 지정을 통한 어노테이션 방법에 관한 것이다."}
{"patent_id": "10-2023-0050696", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(AI)은 인간의 학습능력, 추론능력 및 지각능력 등의 일부 또는 전부를 컴퓨터 프로그램을 이용하여 인 공적으로 구현하는 기술을 의미한다. 인공지능(AI)과 관련하여, 기계 학습(machine learning)은 다수의 파라미 터로 구성된 모델을 이용하여 주어진 데이터로 파라미터를 최적화하는 학습을 의미한다. 이와 같은, 기계 학습 은 학습용 데이터의 형태에서 따라, 지도 학습(supervised learning), 비지도 학습(unsupervised learning) 및 강화 학습(reinforcement learning)으로 구분된다. 일반적으로, 인공지능(AI) 학습용 데이터의 설계는 데이터 구조의 설계, 데이터의 수집, 데이터의 정제, 데이터 의 가공, 데이터의 확장, 및 데이터의 검증 단계로 진행된다. 각각의 단계에서 대하여 보다 구체적으로 설명하면, 데이터 구조의 설계는 온톨로지(ontology) 정의, 분류 체계 의 정의 등을 통해 이루어진다. 데이터의 수집은 직접 촬영, 웹 크롤링(web crawling) 또는 협회/전문 단체 등 을 통해 데이터를 수집하여 이루어진다. 데이터 정제는 수집된 데이터 내에서 중복 데이터를 제거하고, 개인 정 보 등을 비식별화하여 이루어진다. 데이터의 가공은 메타데이터(meta data)를 입력하고 어노테이션(annotatio n)을 수행하여 이루어진다. 데이터의 확장은 온톨로지 매핑(mapping)을 수행하고, 필요에 따라 온톨로지를 보완 하거나 확장하여 이루어진다. 그리고, 데이터의 검증은 다양한 검증 도구를 활용하여 설정된 목표 품질에 따른 유효성을 검증하여 이루어진다. 한편, 차량의 자율주행(automatic driving)은 차량 스스로 판단하여 주행할 수 있는 시스템을 의미한다. 이와 같은, 자율주행은 시스템이 주행에 관여하는 정도와 운전차가 차량을 제어하는 정도에 따라 비자동화부터 완전 자동화까지 점진적인 단계로 구분될 수 있다. 일반적으로, 자율주행의 단계는 국제자동차기술자협회 (SAE(Society of Automotive Engineers) International)에서 분류한 6단계의 레벨로 구분된다. 국제자동차기술 자협회(SAE)가 분류한 6단계에 따르면, 레벨 0단계는 비자동화(no automation), 레벨 1단계는 운전자 보조 (driver assistance), 레벨 2단계는 부분 자동화(partial automation), 레벨 3단계는 조건부 자동화 (conditional automation), 레벨 4단계는 고도 자동화(high automation), 그리고 레벨 5단계는 완전 자동화 (full automation) 단계이다. 차량의 자율주행은 인지(perception), 측위(localization), 경로 계획(path planning) 및 제어(control)의 메 커니즘을 통해 수행된다. 현재 여러 기업체들은 자율주행 메커니즘 중에서 인지 및 경로 계획을 인공지능(AI)을 이용하여 구현하기 위해 개발 중에 있다. 그리고, 자율주행에 사용될 수 있는 인공지능(AI)의 기계 학습에 사 용되는 데이터는 적게는 몇 천개에서, 많게는 수 백만개에 이르는 많은 수로 이루어진다. 이러한, 차량의 자율주행에 사용될 수 있는 인공지능(AI)의 기계 학습에 사용되는 데이터는 차량에 설치된 다양 한 종류의 센서들에 의해 수집된다. 예를 들어, 차량의 자율주행에 사용될 수 있는 인공지능(AI)의 기계 학습에 사용되는 데이터들은 차량에 고정 설치된 라이다(lidar), 카메라(camera), 레이더(radar), 초음파 센서 (ultrasonic sensor) 및 GPS(Global Positioning System) 등에 의해 획득, 촬영 또는 감지된 데이터들이 될 수 있으며, 이에 한정되는 것도 아니다. 일반적으로, 학습 데이터의 수집은 프로젝트(project) 단위로 진행된다. 이때, 각 프로젝트의 컨트롤 타워는 데 이터 수집을 위한 장치가 설치된 복수의 차량으로부터 데이터를 수신하게 된다. 이때, 복수의 차량으로부터 수집된 데이터를 업로드 받는 과정에서는 각 차량으로부터 동일한 이미지가 중복되 어 업로드 되거나, 서로 다른 차량으로부터 동일한 이미지가 중복되어 업로드 되는 문제점이 있었다. 또한, 각 차량의 관리자는 컨트롤 타워로부터 수집 조건이 명시된 가이드에 따라 데이터를 수집하고, 수집된 데 이터를 업로드하게 된다. 이때, 각 차량의 관리자의 주관인 관점, 수집 환경, 수집 장치의 오류 둥에 따라, 기 준에 적합하지 않은 데이터들이 무작위로 업로드 되는 문제점이 있었다. 위와 같은 문제점을 방지하기 위하여, 컨트롤 타워는 업로드 된 데이터를 수동으로 검수하기 위한 검수자를 배 치하고 있다. 그러나, 검수자를 배치함에 따른 불필요한 리소스 낭비를 방지할 수 방안이 필요한 실정이다. 한편, 데이터 가공 단계의 어노테이션 작업은 이미지 속에 포함된 객체에 대하여 바운딩 박스(bounding box), 폴리곤(polygon) 등으로 객체를 식별하고, 식별된 객체의 속성 정보를 입력하여 진행된다. 이와 같은 어노테이 션 작업은 데이터 라벨링(data labeling)이라 지칭되기도 한다. 그리고, 어노테이션 작업 결과물에 해당되는 데 이터셋(dataset)은 JSON(Java Script Object Notation) 파일 형태로 산출된다. 이러한, 어노테이션 작업은 적 게는 몇 천개에서 많게는 수 백만개에 이르는 많은 수의 데이터를 대상으로 이루어지므로, 어노테이션 작업을수행하는 작업자 또한 많은 수의 인원으로 이루어진다. 따라서, 수많은 작업자가 수많은 어노테이션 작업을 수행해야하는 프로젝트의 전체 작업 비용을 산출하는 것은 어려운 작업이다. 종래에는 어노테이션 작업에 관한 프로젝트의 전체 작업 비용은 단순히 작업 대상이 되는 데 이터의 개수, 또는 담당자의 직관에 따라 예측된 작업의 난이도에 의존하여 산출되고 있는 문제점이 있었다. 또한, 어노테이션 작업 중 폴리곤 기법은 작업자가 이미지 내에 포함된 객체의 외곽선을 따라 복수의 점을 생성 하여 객체를 식별하는 방법이다. 이러한 폴리곤 기법은 자동차나 사람과 같은 비정형 객체의 윤곽을 정밀하게 선택할 수 있어, 객체의 크기와 형태를 정확하게 인식할 수 있는 장점이 있다. 그러나, 이미지 내에 객체가 중첩되어 배치되는 경우, 폴리곤 기법으로 각각의 객체를 식별하기 위해서는 이미 지를 확대하여 경계선의 동일한 지점에 이중으로 점을 생성해야 한다. 이때, 경계선의 동일한 지점에 정확히 점 을 생성하지 않는 경우, 중첩된 객체와 객체 사이에 공간이 발생되는 문제점이 있었다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허공보 제10-2020-0042629호, ‘인공지능 학습을 위한 모바일 기기의 터치 기 반 어노테이션과 이미지 생성 방법 및 그 장치’, (2020.04.24. 공개)"}
{"patent_id": "10-2023-0050696", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 목적은 인공지능 학습용 데이터를 어노테이션함에 있어서, 이미지 속에 포함된 중첩된 객체를 용 이하게 지정할 수 있는, 경계선 지정을 통한 어노테이션 방법을 제공하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0050696", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 바와 같은 기술적 과제를 달성하기 위하여, 본 발명은 이미지 속에 포함된 중첩된 객체를 용이하게 지정 할 수 있는, 경계선 지정을 통한 어노테이션 방법을 제안한다. 상기 방법은 어노테이션 장치가, 작업자의 제어 에 따라, 인공지능(Artificial Intelligence, AI) 학습을 위한 어노테이션(annotation) 작업의 대상이 되는 이 미지에 포함된 서로 중첩되어 배치되는 복수의 객체의 외곽선을 지정하는 단계, 상기 어노테이션 장치가, 상기 지정된 외곽선 내에서 상기 복수의 객체 사이의 경계선을 지정하는 단계 및 상기 어노테이션 장치가, 상기 지정 된 경계선을 기준으로 구획된 복수의 영역을 기준으로 상기 복수의 객체를 각각 식별하는 단계를 포함할 수 있 다. 구체적으로, 상기 외곽선을 지정하는 단계는 서로 중첩되어 배치되는 적어도 제1 객체와 제2 객체를 포함하는 복수의 객체의 전체 외곽선을 지정하는 것을 특징으로 하고, 상기 경계선을 지정하는 단계는 상기 지정된 외곽 선 내에서 상기 제1 객체와 상기 제2 객체 사이의 중첩된 경계선을 지정하는 것을 특징으로 하며, 상기 경계선 은, 상기 제1 객체의 제2 객체와 중첩되는 부분의 외곽선을 형성하는 동시에, 상기 제2 객체의 제1 객체와 중첩 되는 부분의 외곽선을 형성하는 것을 특징으로 한다. 상기 외곽선을 지정하는 단계는 상기 작업자로부터 상기 복수 개의 객체를 포함하는 외곽선을 따라 복수 개의 점을 입력 받고, 상기 복수 개의 점을 연결하여, 상기 복수 개의 객체에 대한 외곽선을 생성하는 것을 특징으로 한다. 상기 외곽선을 지정하는 단계는 상기 이미지의 엣지(edge)를 추출하고, 상기 추출된 엣지를 기초로 적어도 하나 의 객체를 식별하고, 상기 작업자로부터 상기 식별된 객체 중 복수의 객체를 선택받고, 상기 추출된 엣지를 기 초로 상기 선택받은 복수의 객체에 대한 외곽선을 생성하는 것을 특징으로 한다. 상기 외곽선을 지정하는 단계는 상기 이미지와 동시에 라이다(lidar)로부터 획득된 점군 데이터를 기초로, 상기 지정된 외곽선 내부에 존재하는 점들 중 거리(depth)가 일정 범위(range)를 갖는 복수의 점군을 식별하고, 상기작업자로부터 상기 복수의 점군 중 복수의 객체를 선택받고, 상기 식별된 복수의 점군을 기초로 상기 선택받은 복수의 객체에 대한 외곽선을 생성하는 것을 특징으로 한다. 상기 외곽선을 지정하는 단계는 상기 복수의 객체를 포함하는 일부 영역을 바운딩 박스(bounding box)로 설정하 고, 상기 바운딩 박스 내측 영역에서 객체의 엣지를 추출하고, 추출된 엣지를 기준으로 객체(object)와 배경 (background)을 구분하고, 상기 배경을 삭제하여 상기 복수의 객체의 외곽선을 지정하는 것을 특징으로 한다. 상기 경계선을 지정하는 단계는 상기 추출된 엣지를 기초로 상기 복수의 객체에 대한 외곽선 내에서 경계선을 식별하는 것을 특징으로 한다. 상기 경계선을 지정하는 단계는 상기 작업자로부터 상기 복수의 객체에 대한 외곽선 내부에 위치한 복수의 점을 입력받고, 상기 입력받은 복수의 점을 연결하여 상기 경계선을 생성하는 것을 특징으로 한다. 상기 경계선을 지정하는 단계는 상기 이미지와 동시에 라이다로부터 획득된 점군 데이터를 기초로, 상기 지정된 외곽선 내부에 존재하는 점들 중 거리가 일정 범위를 갖는 복수의 점군을 식별하고, 상기 복수의 점군 사이의 경계선을 상기 복수의 객체 사이의 경계선으로 지정하는 것을 특징으로 한다. 상기 경계선을 지정하는 단계는 상기 지정된 외곽선 내부에 위치한 픽셀(pixel)의 RGB(Red, Green, Blue) 값을 기초로, 사전 설정된 값보다 유사한 RGB 값을 갖는 그룹을 생성하고, 생성된 그룹을 각각 객체로 인식하고, 상 기 인식된 객체의 경계선을 생성하는 것을 특징으로 한다. 상기 경계선을 지정하는 단계는 상기 이미지와 동시에 라이다로부터 획득된 점군 데이터를 기초로, 상기 지정된 외곽선 내부에 존재하는 점들 중 거리가 일정 범위를 갖는 복수의 점군을 식별하고, 상기 작업자로부터 상기 복 수의 점군 중 하나의 객체를 선택받고, 상기 선택받은 객체의 점군을 기초로 상기 경계선을 생성하는 것을 특징 으로 한다. 상기 경계선을 지정하는 단계는 상기 지정된 외곽선 내부의 엣지를 추출하고, 상기 추출된 엣지를 기초로 적어 도 하나의 객체를 식별하고, 상기 작업자로부터 상기 식별된 객체 중 하나의 객체를 선택받고, 상기 추출된 엣 지를 기초로 상기 경계선을 생성하는 것을 특징으로 한다. 상기 경계선을 지정하는 단계는 상기 생성된 경계선을 따라 사전 설정된 간격을 갖는 복수의 점을 생성하고, 상 기 작업자의 제어에 따라 상기 복수의 점 중 적어도 하나의 점을 이동시켜 상기 경계선을 수정하는 것을 특징으 로 한다. 상술한 바와 같은 기술적 과제를 달성하기 위하여, 본 발명은 이미지 속에 포함된 중첩된 객체를 용이하게 지정 할 수 있는, 경계선 지정을 통한 어노테이션 방법을 실행하기 위하여 기록매체에 기록된 컴퓨터 프로그램을 제 안한다. 상기 컴퓨터 프로그램은 메모리(memory); 및 상기 메모리에 상주된 명령어를 처리하는 프로세서 (processor)를 포함하여 구성된 컴퓨팅 장치와 결합될 수 있다. 그리고, 상기 컴퓨터 프로그램은 상기 프로세서 가, 작업자의 제어에 따라, 인공지능(Artificial Intelligence, AI) 학습을 위한 어노테이션(annotation) 작업 의 대상이 되는 이미지에 포함된 서로 중첩되어 배치되는 복수의 객체의 외곽선을 지정하는 단계, 상기 프로세 서가, 상기 지정된 외곽선 내에서 상기 복수의 객체 사이의 경계선을 지정하는 단계 및 상기 프로세서가, 상기 지정된 경계선을 기준으로 구획된 복수의 영역을 기준으로 상기 복수의 객체를 각각 식별하는 단계를 실행시키 기 위하여, 기록매체에 기록된 컴퓨터 프로그램이 될 수 있다. 기타 실시 예들의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2023-0050696", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들에 따르면, 어노테이션을 수행함에 있어서, 이미지 내에 포함된 서로 중첩되어 배치되는 복 수의 객체를 대상으로, 복수의 객체 전체에 대한 외곽선을 지정한 후에, 각 객체의 경계선을 지정하여 각 객체 를 구분함으로써, 중첩되어 배치되는 개체를 용이하게 식별할 수 있다."}
{"patent_id": "10-2023-0050696", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과로 제한되지 아니하며, 언급되지 않은 또 다른 효과들은 청구범위의"}
{"patent_id": "10-2023-0050696", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 3, "content": "기재로부터 본 발명이 속한 기술분야의 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0050696", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 기술적 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하 려는 의도가 아님을 유의해야 한다. 또한, 본명세서에서 사용되는 기술적 용어는 본 명세서에서 특별히 다른 의 미로 정의되지 않는 한, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 의미로 해석되어야 하며, 과도하게 포괄적인 의미로 해석되거나, 과도하게 축소된 의미로 해석되지 않아야 한다. 또한, 본 명세서에서 사용되는 기술적인 용어가 본 발명의 사상을 정확하게 표현하지 못하는 잘못된 기술 적 용어일 때에는, 당업자가 올바르게 이해할 수 있는 기술적 용어로 대체되어 이해되어야 할 것이다. 또한, 본 발명에서 사용되는 일반적인 용어는 사전에 정의되어 있는 바에 따라, 또는 전후 문맥상에 따라 해석되어야 하 며, 과도하게 축소된 의미로 해석되지 않아야 한다. 또한, 본 명세서에서 사용되는 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"구성된다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 여러 구성 요소들, 또는 여 러 단계들을 반드시 모두 포함하는 것으로 해석되지 않아야 하며, 그 중 일부 구성 요소들 또는 일부 단계들은 포함되지 않을 수도 있고, 또는 추가적인 구성 요소 또는 단계들을 더 포함할 수 있는 것으로 해석되어야 한다. 또한, 본 명세서에서 사용되는 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으 면서 제1 구성 요소는 제2 구성 요소로 명명될 수 있고, 유사하게 제2 구성 요소도 제1 구성 요소로 명명될 수 있다. 어떤 구성 요소가 다른 구성 요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성 요소 에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성 요소가 존재할 수도 있다. 반면에, 어떤 구성 요소가 다른 구성 요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 중간에 다른 구성 요소가 존재하지 않는 것으로 이해되어야 할 것이다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일 하거나 유사한 구성 요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 또한, 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되 는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 발명의 사상을 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 발명의 사상이 제한되는 것으로 해석되어서는 아니 됨을 유의해야 한다. 본 발명의 사상은 첨부된 도면 외에 모든 변경, 균등물 내지 대체물에 까지도 확장되는 것으로 해석되어야 한다. 한편, 학습 데이터의 수집은 프로젝트(project) 단위로 진행된다. 이때, 각 프로젝트의 컨트롤 타워는 데이터 수집을 위한 장치가 설치된 복수의 차량으로부터 데이터를 수신하게 된다. 이때, 복수의 차량으로부터 수집된 데이터를 업로드 받는 과정에서는 각 차량으로부터 동일한 이미지가 중복되 어 업로드 되거나, 서로 다른 차량으로부터 동일한 이미지가 중복되어 업로드 되는 문제점이 있었다. 또한, 각 차량의 관리자는 컨트롤 타워로부터 수집 조건이 명시된 가이드에 따라 데이터를 수집하고, 수집된 데 이터를 업로드하게 된다. 이때, 각 차량의 관리자의 주관인 관점, 수집 환경, 수집 장치의 오류 둥에 따라, 기 준에 적합하지 않은 데이터들이 무작위로 업로드 되는 문제점이 있었다. 위와 같은 문제점을 방지하기 위하여, 컨트롤 타워는 업로드 된 데이터를 수동으로 검수하기 위한 검수자를 배 치하고 있다. 그러나, 검수자를 배치함에 따른 불필요한 리소스 낭비를 방지할 수 방안이 필요한 실정이다. 또한, 수많은 작업자가 수많은 어노테이션 작업을 수행해야하는 프로젝트의 전체 작업 비용을 산출하는 것은 어 려운 작업이다. 종래에는 어노테이션 작업에 관한 프로젝트의 전체 작업 비용은 단순히 작업 대상이 되는 데이 터의 개수, 또는 담당자의 직관에 따라 예측된 작업의 난이도에 의존하여 산출되고 있는 문제점이 있었다. 그리고, 이미지 내에 객체가 중첩되어 배치되는 경우, 폴리곤 기법으로 각각의 객체를 식별하기 위해서는 이미 지를 확대하여 경계선의 동일한 지점에 이중으로 점을 생성해야 한다. 이때, 경계선의 동일한 지점에 정확히 점 을 생성하지 않는 경우, 중첩된 객체와 객체 사이에 공간이 발생되는 문제점이 있었다. 이러한 한계를 극복하고자, 본 발명은 인공지능의 기계 학습용 데이터를 수집하고, 수집된 데이터 중 불필요한 데이터를 정제할 수 있는 다양한 수단을 제안하고자 한다. 또한, 본 발명은 인공지능 학습용 데이터의 어노테이션 작업에 관한 프로젝트의 전체 작업 비용을 합리적으로 예측할 수 있는 다양한 수단을 제안하고자 한다. 그리고, 본 발명은 인공지능 학습용 데이터를 어노테이션함에 있어서, 이미지 속에 포함된 중첩된 객체를 용이 하게 지정할 수 있는 다양한 수단을 제공하고자 한다. 도 1은 본 발명의 일 실시예에 따른 인공지능 학습 시스템의 구성도이다. 도 1에 도시된 바와 같이, 본 발명의 일 실시예에 따른 인공지능 학습 시스템은 복수의 학습 데이터 수집 장치 (100a, 100b, …, 100n; 100), 학습 데이터 생성 장치, 복수의 어노테이션 장치(300a, 300b, …, 300n; 300) 및 인공지능 학습 장치를 포함하여 구성될 수 있다. 이와 같은, 일 실시예에 따른 인공지능 학습 시스템의 구성 요소들은 기능적으로 구분되는 요소들을 나타낸 것 에 불과하므로, 둘 이상의 구성 요소가 실제 물리적 환경에서는 서로 통합되어 구현되거나, 하나의 구성 요소가 실제 물리적 환경에서는 서로 분리되어 구현될 수 있을 것이다. 각각의 구성 요소에 대하여 설명하면, 학습 데이터 수집 장치는 자율주행에 사용될 수 있는 인공지능(AI) 을 기계 학습시키기 위한 데이터를 수집하기 위하여, 차량에 설치된 라이다(lidar), 카메라(camera), 레이더 (radar), 초음파 센서(ultrasonic sensor), 레인 센서(rain sensor), 위치 측정 센서 및 속도 감지 센서 중 하 나 이상으로부터 실시간으로 데이터를 수집하는 장치이다. 이러한, 학습 데이터 수집 장치는 인공지능의 기계 학습을 위한 데이터의 수집을 학습 데이터 생성 장치 로부터 요청받을 수 있다. 이때, 학습 데이터 수집 장치는 데이터의 수집 조건을 포함하는 가이드 정 보를 학습 데이터 생성 장치로부터 수신할 수 있다. 여기서, 가이드 정보는 수집 조건인 객체(object)의 클래스(class), 데이터 확장자(filename extension), 이미 지 해상도(resolution) 등을 포함할 수 있다. 이때, 학습 데이터 수집 장치는 가이드 정보를 샘플 이미지 를 통해 제공받을 수 있다. 이러한, 학습 데이터 수집 장치의 제어 대상이자, 차량에 설치되어 기계 학습용 데이터를 획득, 촬영 또는 감지하는 센서의 종류에는 라이다(lidar), 카메라(camera), 레이더(radar), 초음파 센서(ultrasonic sensor),레인 센서(rain sensor), 위치 측정 센서 및 속도 감지 센서 중 하나 이상이 포함될 수 있으나, 이에 한정되는 것은 아니다. 또한, 학습 데이터 수집 장치의 제어 대상이자, 차량에 설치되어 기계 학습용 데이터를 획득, 촬영 또는 감지하는 센서는 종류별로 하나씩 구비되는 것으로 한정되지 아니하며, 동일한 종류의 센서라 할지라도 복수 개로 구비될 수 있다. 다음 구성으로, 학습 데이터 생성 장치는 차량의 자율주행에 사용될 수 있는 인공지능(AI)을 기계 학습시 키기 위한 데이터를 설계 및 생성하는데 사용될 수 있는 장치이다. 특징적으로, 본 발명의 일 실시예에 따른 학습 데이터 생성 장치는 인공지능(AI)의 기계 학습(machine learning)을 위한 이미지의 수집을 적어도 하나의 학습 데이터 수집 장치에 요청하고, 적어도 하나의 학습 데이터 수집 장치로부터 이미지들을 수신할 수 있다. 학습 데이터 생성 장치는 수신한 이미지들의 컬 러 정보를 추출하고, 이미지들 사이의 컬러 정보를 기준으로 노이즈 이미지를 분류할 수 있다. 또한, 본 발명의 다른 실시예에 따른 학습 데이터 생성 장치는 인공지능의 기계 학습을 위한 이미지의 수 집 조건을 포함하는 가이드 정보를 적어도 하나의 학습 데이터 수집 장치에 전송하고, 적어도 하나의 학습 데이터 수집 장치로부터 이미지들을 수신할 수 있다. 학습 데이터 생성 장치는 수집 조건과 대응하는 이미지 정보를 이미지들로부터 추출하고, 추출한 이미지 정보를 가이드 정보와 비교하여, 수집 환경에 따른 노 이즈 이미지를 분류할 수 있다. 또한, 본 발명의 다른 실시예에 따른 학습 데이터 생성 장치는 인공지능의 기계 학습을 위한 이미지의 수 집 조건을 포함하는 가이드 정보를 적어도 하나의 학습 데이터 수집 장치에 전송하고, 적어도 하나의 학습 데이터 수집 장치로부터 이미지들을 수신할 수 있다. 학습 데이터 생성 장치는 수집 조건과 대응하는 이미지 정보를 이미지들로부터 추출하고, 추출한 이미지 정보를 가이드 정보와 비교하여, 학습 데이터 수집 장 치의 물리적 요인에 따른 노이즈 이미지를 분류할 수 있다. 그리고, 본 발명의 또 다른 실시예에 따른 학습 데이터 생성 장치는 인공지능 학습을 위하여 수행 예정인 어노테이션(annotation) 작업과 관련된 프로젝트를 수행하기 위한 적어도 하나의 샘플 데이터를 수신하고, 기 수행된 복수의 프로젝트에 포함된 기존 데이터를 상기 샘플 데이터와 비교하고, 샘플 데이터와의 유사도가 사전 설정된 값보다 높은 기존 데이터가 포함된 적어도 하나의 프로젝트를 추출할 수 있다. 학습 데이터 생성 장치 는 추출된 적어도 하나의 프로젝트를 기초로 수행 예정인 어노테이션 작업과 관련된 프로젝트를 수행하기 위하여 요구되는 전체 작업 비용을 예측할 수 있다. 이와 같은 특징을 가지는, 학습 데이터 생성 장치는 학습 데이터 수집 장치, 어노테이션 장치 및 인공지능 학습 장치와 데이터를 송수신하고, 송수신된 데이터를 기초로 연산을 수행할 수 있는 장치라 면 어떠한 장치라도 허용될 수 있다. 예를 들어, 학습 데이터 생성 장치는 데스크탑(desktop), 워크스테이 션(workstation) 또는 서버(server)와 같은 고정식 컴퓨팅 장치 중 어느 하나가 될 수 있으나, 이에 한정되는 것은 아니다. 상술한 바와 같은, 학습 데이터 생성 장치에 대한 구체적인 구성 및 동작에 대해서는 추후 도 2 및 도 3을 참조하여 설명하기로 한다. 다음 구성으로, 어노테이션 장치는 학습 데이터 생성 장치로부터 제공된 이미지에 대하여 어노테이션 을 수행하는데 사용될 수 있는 장치이다. 이와 같은, 어노테이션 장치의 사용자는 라벨러(labeler), 리뷰어(reviewer), 인스펙터(inspector) 및 트 레이니(trainee)로 구분될 수 있다. 여기서, 라벨러는 이미지를 대상으로 어노테이션 작업을 수행하는 자에 해당된다. 리뷰어는 상기 어노테이션 작 업이 수행된 이미지를 시각적으로 검증하는 자에 해당된다. 인스펙터는 상기 어노테이션 작업 결과물을 스크립 트(script)를 이용하여 검증하는 자에 해당된다. 그리고, 트레이니는 상기 어노테이션 작업을 수행하기 위한 교 육을 받는 자에 해당된다. 구체적으로, 어노테이션 장치는 라벨러에 해당되는 사용자의 제어에 따라 다음과 같이 어노테이션 작업을 수행할 수 있다. 어노테이션 장치는 사용자의 제어에 따라, 학습 데이터 생성 장치로부터 수신된 이미지를 출력할 수 있다. 어노테이션 장치는 사용자의 제어에 따라, 툴을 선택할 수 있다. 여기서, 툴(tool)은 이미지 속에 포함되 어 있는 하나 이상의 객체를 특정하기 위한 도구이다. 어노테이션 장치는 선택된 툴을 이용한 사용자의 제 어에 따라, 좌표를 입력 받을 수 있다. 어노테이션 장치는 입력된 좌표를 기초로 객체를 식별할 수 있다. 한편, 본 발명의 일 실시예에 따른 어노테이션 장치는 작업자가 이미지 내에 포함된 객체의 외곽선을 따라 복수의 점을 생성하여 객체를 식별하는 폴리곤(polygon) 기법을 통해 이미지 속에 포함된 하나 이상의 객체를 식별할 수 있다. 하지만, 이에 한정된 것은 아니고 어노테이션 장치는 바운딩 박스(bounding box), 폴리라 인(polyline), 포인트(point), 큐보이드(cuboid), 시맨틱 세그멘티이션(semantic segmentation) 등의 기법을 사용할 수도 있다. 특히, 본 발명의 일 실시예에 따른 어노테이션 장치는 작업자의 제어에 따라, 인공지능 학습을 위한 어노 테이션 작업의 대상이 되는 이미지에 포함된 서로 중첩되어 배치되는 복수의 객체 중 제1 객체의 외곽선을 지정 하고, 제1 객체와 중첩되어 배치된 제2 객체 사이의 경계선을 지정하고, 경계선을 상기 제2 객체의 외곽선의 일 부로 설정할 수 있다. 어노테이션 장치는 설정된 경계선을 기준으로 제2 객체의 외곽선을 지정할 수 있다. 또한, 본 발명의 다른 실시예에 따른 어노테이션 장치는 작업자의 제어에 따라, 인공지능 학습을 위한 어 노테이션 작업의 대상이 되는 이미지에 포함된 서로 중첩되어 배치되는 복수의 객체의 외곽선을 지정하고, 지정 된 외곽선 내에서 복수의 객체 사이의 경계선을 지정할 수 있다. 어노테이션 장치는 지정된 경계선을 기준 으로 구획된 복수의 영역을 기준으로 복수의 객체를 각각 식별할 수 있다. 어노테이션 장치는 특정된 객체의 속성 정보를 설정할 수 있다. 여기서, 객체의 속성 정보는 인공지능(AI) 학습의 대상이 되는 객체의 속성을 지정하기 위한 정보이다. 이와 같은, 객체의 속성 정보에는 어노테이션의 종 류(type), 클래스 명(class), 분류 항목(tags), 객체의 잘림 여부(truncated), 대분류, 소분류 또는 상위 레벨 (instance upper)에 관한 정보가 포함될 수 있으며, 이에 한정되는 것은 아니다. 어노테이션 장치는 사용자에 의해 설정된 객체의 위치 및 크기에 따른 좌표와, 설정된 속성 정보를 포함하 여 어노테이션의 작업 결과물을 생성할 수 있다. 이와 같은, 작업 결과물은 JSON(Java Script Object Notation) 파일 형식을 가질 수 있으나, 이에 한정되는 것은 아니다. 그리고, 어노테이션 장치는 생성된 어노테이션 작업 결과물을 학습 데이터 생성 장치에 전송할 수 있 다. 한편, 어노테이션 장치와 관련한 구체적인 설명은 도 4 및 도 5를 참조하여 후술하도록 한다. 이와 같은, 어노테이션 장치는 학습 데이터 생성 장치와 데이터를 송수신하고, 송수신된 데이터를 이 용하여 연산을 수행할 수 있는 장치라면 어떠한 장치라도 허용될 수 있다. 예를 들어, 어노테이션 장치는 데스크탑(desktop), 워크스테이션(workstation) 또는 서버(server)와 같은 고정식 컴퓨팅 장치 중 어느 하나가 될 수 있으나, 이에 한정되지 아니하고, 스마트폰(smart phone), 랩탑 (laptaop), 태블릿(tablet), 패블릿(phablet), 휴대용 멀티미디어 재생장치(Portable Multimedia Player, PMP), 개인용 휴대 단말기(Personal Digital Assistants, PDA) 또는 전자책 단말기(E-book reader)과 같은 이 동식 컴퓨팅 장치 중 어느 하나가 될 수도 있다. 다음 구성으로, 인공지능 학습 장치는 인공지능 학습용 데이터를 기초로, 인공지능의 기계 학습을 수행하 는데 사용될 수 있는 장치이다. 구체적으로, 인공지능 학습 장치는 수행 예정인 프로젝트와 관련된 샘플 데이터를 학습 데이터 생성 장치 에 전송할 수 있다. 여기서, 샘플 데이터는 인공지능 학습을 위하여 수행 예정인 어노테이션 작업과 관련 된 샘플이다. 이와 같은, 샘플 데이터는 어노테이션 작업의 대상이 되는 이미지이거나, 또는 어노테이션 작업 결과물이 될 수 있으며, 이에 한정되는 것도 아니다. 인공지능 학습 장치는 학습 데이터 생성 장치로부터 수행 예정인 프로젝트를 수행하기 위하여 요구되 는 전체 작업 비용을 수신할 수 있다. 인공지능 학습 장치는 수신된 전체 작업 비용을 출력할 수 있다. 이러한, 전체 작업 비용은 인공지능 학습 장치의 운영 주체와 학습 데이터 생성 장치의 운영 주체 사 이에 프로젝트 수행과 관련된 계약을 체결하는데 활용될 수 있다. 인공지능 학습 장치의 운영 주체와 학습 데이터 생성 장치의 운영 주체 사이에 프로젝트 수행과 관련 된 계약이 체결된 이후, 인공지능 학습 장치는 학습 데이터 생성 장치로부터 패키징 된 어노테이션작업 결과물을 수신할 수 있다. 그리고, 인공지능 학습 장치는 수신된 어노테이션 작업 결과물을 기반으로, 인공지능(AI)의 기계 학습을 수행할 수 있다. 이와 같은, 인공지능 학습 장치는 학습 데이터 생성 장치와 데이터를 송수신하고, 송수신된 데이터를 이용하여 연산을 수행할 수 있는 장치라면 어떠한 장치라도 허용될 수 있다. 예를 들어, 인공지능 학습 장치 는 데스크탑, 워크스테이션 또는 서버와 같은 고정식 컴퓨팅 장치 중 어느 하나가 될 수 있으나, 이에 한 정되는 것은 아니다. 상술한 바와 같은, 하나 이상의 학습 데이터 수집 장치, 학습 데이터 생성 장치, 어노테이션 장치 및 인공지능 학습 장치는 장치들 사이에 직접 연결된 보안회선, 공용 유선 통신망 또는 이동 통신망 중 하나 이상이 조합된 네트워크를 이용하여 데이터를 송수신할 수 있다. 예를 들어, 공용 유선 통신망에는 이더넷(ethernet), 디지털가입자선(x Digital Subscriber Line, xDSL), 광동 축 혼합망(Hybrid Fiber Coax, HFC), 광가입자망(Fiber To The Home, FTTH)가 포함될 수 있으나, 이에 한정되 는 것도 아니다. 그리고, 이동 통신망에는 코드 분할 다중 접속(Code Division Multiple Access, CDMA), 와이 드 밴드 코드 분할 다중 접속(Wideband CDMA, WCDMA), 고속 패킷 접속(High Speed Packet Access, HSPA), 롱텀 에볼루션(Long Term Evolution, LTE), 5세대 이동통신(5th generation mobile telecommunication)가 포함될 수 있으나, 이에 한정되는 것은 아니다. 이하, 상술한 바와 같은, 학습 데이터 생성 장치의 구성에 대하여 보다 구체적으로 설명하기로 한다. 도 2는 본 발명의 일 실시예에 따른 학습 데이터 생성 장치의 논리적 구성도이다. 도 2를 참조하면, 학습 데이터 생성 장치는 통신부, 입출력부, 데이터 설계부, 데이터 수 집부, 데이터 전처리부, 데이터 납품부 및 저장부를 포함하여 구성될 수 있다. 이와 같은, 학습 데이터 생성 장치의 구성 요소들은 기능적으로 구분되는 요소들을 나타낸 것에 불과하므 로, 둘 이상의 구성 요소가 실제 물리적 환경에서는 서로 통합되어 구현되거나, 하나의 구성 요소가 실제 물리 적 환경에서는 서로 분리되어 구현될 수 있을 것이다. 구체적으로, 통신부는 인공지능(AI)의 기계 학습을 위한 이미지의 수집 조건을 포함하는 가이드 정보를 적 어도 하나의 학습 데이터 수집 장치에 전송할 수 있다. 또한, 통신부는 학습 데이터 수집 장치로부터, 카메라(camera)에 의해 촬영된 이미지, 라이다(lida r)로부터 획득된 점군 데이터, 위치 측정 센서 및 속도 감지 센서로부터 감지된 데이터를 수신할 수 있다. 또한, 통신부는 어노테이션 작업의 대상이 되는 하나 이상의 이미지를 어노테이션 장치에 전송할 수 있다. 또한, 통신부는 어노테이션 장치로부터 어노테이션 작업 결과물을 수신할 수 있다. 또한, 통신부는 인공지능 학습 장치로부터 적어도 하나의 샘플 데이터를 수신할 수 있다. 통신부 는 데이터 설계부에 의해 예측되거나, 또는 사용자로부터 입력된, 수행 예정인 프로젝트를 수행하기 위하여 요구되는 전체 작업 비용을 인공지능 학습 장치에 전송할 수 있다. 다음 구성으로, 입출력부는 사용자 인터페이스(User Interface, UI)를 통해 사용자로부터 신호를 입력 거 나, 또는 연산된 결과를 외부로 출력할 수 있다. 구체적으로, 입출력부는 사용자로부터 학습 데이터 수집 장치의 수집 조건을 포함하는 가이드 정보를 입력받을 수 있다. 가이드 정보에는 학습 목적, 학습 기간, 학습에 필요한 이미지의 수, 이미지에서 식별하고자 하는 객체의 속성, 이미지의 해상도, 이미지의 확장자 등이 포함될 수 있으나, 이에 한정되는 것은 아니다. 또한, 입출력부는 사용자로부터 샘플 데이터를 입력 받을 수 있다. 또한, 입출력부는 사용자로부터 분해 구성요소, 가중치 및 가이드 정보를 입력 받을 수 있다. 여기서, 분해 구성요소는 어노테이션 작업 결과물 을 구성하고 있는 요소들 중에서, 프로젝트의 전체 작업 비용을 예측하기 위해 사용되는 요소이다. 예를 들어, 분해 구성요소에는 클래스(class)와 툴(tool)이 포함될 수 있으나, 이에 한정되는 것은 아니다. 입출력부는 데이터 설계부에 의해 예측된, 수행 예정인 프로젝트를 수행하기 위하여 요구되는 전체 작업 비용을 출력할 수 있다. 입출력부는 사용자로부터 수정된 전체 작업 비용을 입력 받을 수 있다. 다음 구성으로, 데이터 설계부는 수행 예정인 프로젝트를 수행하기 위하여 요구되는 전체 작업 비용을 예 측하여, 인공지능 학습 장치에 제공할 수 있다. 구체적으로, 데이터 설계부는 인공지능 학습을 위하여 수행 예정인 어노테이션 작업과 관련된 프로젝트를 수행하기 위한 적어도 하나의 샘플 데이터를 인공지능 학습 장치로부터 수신할 수 있다. 여기서, 샘플 데 이터는 인공지능(AI) 학습을 위하여 수행 예정인 어노테이션 작업과 관련된 샘플이다. 이와 같은, 샘플 데이터 는 어노테이션 작업의 대상이 되는 이미지이거나, 또는 어노테이션 작업 결과물이 될 수 있으며, 이에 한정되는 것도 아니다. 데이터 설계부는 기 수행된 복수의 프로젝트에 포함된 기존 데이터를 샘플 데이터와 비교하고, 샘플 데이 터와의 유사도가 사전 설정된 값보다 높은 기존 데이터가 포함된 적어도 하나의 프로젝트를 추출할 수 있다. 이때, 데이터 설계부는 기존 데이터를 대상으로, 기존 데이터를 구성하고 있는 하나 이상의 분해 구성요소 를 식별할 수 있다. 여기서, 분해 구성요소는 어노테이션 작업 결과물을 구성하고 있는 요소들 중에서, 프로젝 트의 전체 작업 비용을 예측하기 위해 사용되는 요소이다. 예를 들어, 분해 구성요소에는 클래스(class)와 툴 (tool)이 포함될 수 있으나, 이에 한정되는 것은 아니다. 일 예를 들어, 샘플 데이터가 어노테이션 작업 대상이 되는 이미지에 해당되는 경우, 데이터 설계부는 샘 플 데이터에 해당되는 이미지를 대상으로, 사용자의 제어에 따라 어노테이션 작업을 수행할 수 있다. 그리고, 데이터 설계부는 어노테이션 작업에 의해 이미지로부터 특정된 객체의 클래스와, 객체를 특정하기 위하여 사용된 툴을 샘플 데이터의 분해 구성요소로 식별할 수 있다 또한, 데이터 설계부는 샘플 데이터와의 유사도가 사전 설정된 값보다 높은 기존 데이터가 포함된 적어도 하나의 프로젝트를 추출할 수 있다. 이때, 데이터 설계부는 인공지능 학습 장치로부터 샘플 이미지의 분해 구성요소에 대한 가중치를 입력 받고, 입력받은 가중치를 고려하여, 기존 이미지와의 유사도를 평가할 수 있다. 예를 들어, 인공지능 학습 장치에 의해 객체의 클래스와, 객체를 특정하기 위하여 사용된 툴 중 객 체의 클래스에 더 높은 가중치를 부여하는 경우, 데이터 설계부는 객체의 클래스를 중점적으로 유사한 기 존 데이터를 추출하고, 해당 기존 데이터가 포함된 프로젝트를 추출할 수 있다. 데이터 설계부는 샘플 이미지의 엣지(edge)를 추출하고, 추출된 엣지를 기초로 샘플 데이터에 포함된 객체 를 검출하고, 객체의 RGB(Red, Green, Blue) 값을 기존 데이터에 포함된 객체의 RGB 값과 비교하여 유사도를 평 가할 수 있다. 예를 들어, 데이터 설계부는 검출된 객체의 픽셀(pixel)에 대한 RGB(Red, Green, Blue) 히스토그램을 생성 하고, 생성된 RGB 히스토그램을 비교하여 유사도를 산출할 수 있다. 여기서 RGB 히스토그램은 이미지에서 각 원 색(RGB)의 밝기 분포를 나타내는 그래프이다. 예를 들어, RGB 히스토그램은 가로축이 컬러의 밝기 레벨을 표시 하며, 세로축이 컬러의 밝기 레벨에 할당된 픽셀 수로 표시되고, 좌측으로 치우친 픽셀 수가 많을수록 색상이 어둡고 덜 선명하게 표현되며, 우측으로 치운 친 픽셀 수가 많을수록 색상이 더 밝고 진하게 표현될 수 있다. 이와 같이, 데이터 설계부는 RGB 히스토그램을 통해 샘플 이미지에 포함된 객체 및 기존 이미지에 포함된 객체의 색상의 채도와 계조 상태, 화이트 밸런스의 성향 등을 비교하여 유사도를 산출할 수 있다. 하지만, 이에 한정된 것은 아니고, 데이터 설계부는 추출된 객체의 엣지에 대한 모멘트(moment)를 비교하여 유사도를 산 출할 수 있다. 또한, 데이터 설계부는 기 수행된 복수의 프로젝트 별로 각각 사전 저장된 대표 이미지를 샘플 이미지와 비교하고, 샘플 이미지와의 유사도가 사전 설정된 값보다 높은 복수의 대표 이미지를 인공지능 학습 장치에 전 송하고, 인공지능 학습 장치로부터 복수의 대표 이미지 중 하나를 선택받을 수 있다. 여기서, 대표 이미지 는 기 수행된 복수의 프로젝트를 수행하는 과정에서 수집된 이미지 중 기 수행된 복수의 프로젝트 각각을 수행 하기 위하여 수신한 샘플 이미지와 유사도가 가장 높은 이미지가 될 수 있다. 이때, 데이터 설계부는 샘플 이미지와의 유사도가 사전 설정된 값보다 높은 복수의 대표 이미지를 인공지 능 학습 장치에 전송하되, 대표 이미지에 포함된 객체를 식별하고, 식별된 객체의 클래스가 기밀 정보로 사전 등록된 경우, 식별된 객체를 비식별(de-identify) 처리하여 인공지능 학습 장치에 전송할 수 있다. 데이터 설계부는 기밀 정보로 등록된 클래스에 해당하는 객체를 블러링(blurring) 처리하여 비식별 처리를 수행할 수 있다. 즉, 각 프로젝트별로 수집된 이미지에는 기밀 정보가 포함될 수 있다. 여기서, 기밀 정보는 각 프로젝트를 의뢰 한 기업으로부터 지정된 각 기업의 기밀 정보이거나, 얼굴, 자동차번호판 등의 개인 정보가 포함될 수 있다. 이 러한, 기밀 정보는 기 수행된 복수의 프로젝트 각각을 요청한 인공지능 학습 장치로부터 설정되거나, 학습데이터 생성 장치에 의해 미리 설정될 수 있다. 데이터 설계부는 기밀 정보로 지정된 객체의 일부를 블러링(blurring) 처리하여 비식별 처리를 수행하되, 식별된 객체에서 랜드 마크(land mark)를 추출하고, 추출된 랜드 마크에 블러링 처리를 수행할 수 있다. 예를 들어, 데이터 설계부는 식별된 객체가 사람일 경우, 사람의 랜드 마크에 해당하는 눈, 코, 입을 추출하고, 추출된 눈, 코, 입만 선택적으로 블러링 처리할 수 있다. 또한, 데이터 설계부는 추출된 적어도 하나의 프로젝트를 기초로 수행 예정인 어노테이션 작업과 관련된 프로젝트를 수행하기 위하여 요구되는 전체 작업 비용을 예측할 수 있다. 이때, 데이터 설계부는 수행 예 정인 어노테이션 작업과 관련된 프로젝트의 데이터 수량을 입력 받고, 추출된 프로젝트의 비용 및 데이터 수량 을 고려하여, 전체 작업 비용을 예측할 수 있다. 예를 들어, 데이터 설계부는 추출된 적어도 하나의 프로젝트에 대한 데이터 수량 및 작업 비용을 검출한다. 그리고, 데이터 설계부는 수행 예정인 프로젝트의 데이터 수량을 입력 받고, 추출된 프로젝트의 데이터 수량 및 작업 비용과 비례하여, 입력받은 데이터 수량에 따른 작업 비용을 가감하여 전체 작업 비용을 예측할 수 있다. 또한, 데이터 설계부는 샘플 데이터와 유사도가 사전 설정된 값보다 높은 기존 데이터가 포함된 복수의 프 로젝트를 추출하고, 추출된 복수의 프로젝트의 작업 비용 평균값을 수행 예정인 프로젝트의 전체 작업 비용으로 예측할 수 있다. 그리고, 데이터 설계부는 예측된 전체 작업 비용을 입출력부를 통하여 출력할 수 있다. 데이터 설계 부는 입출력부를 통해 입력된 사용자의 제어에 따라, 전체 작업 비용을 수정할 수도 있다. 그리고, 데이터 설계부는 예측 또는 수정된 전체 작업 비용을 통신부를 통해 인공지능 학습 장치에 전송 할 수 있다. 다음 구성으로, 데이터 수집부는 인공지능 학습 장치의 운영 주체와 프로젝트 수행과 관련된 계약이 체결되면, 해당 프로젝트를 위하여 인공지능(AI) 학습용 데이터를 수집할 수 있다. 구체적으로, 데이터 수집부는 인공지능의 기계 학습을 위한 이미지의 수집을 적어도 하나의 학습 데이터 수집 장치에 요청할 수 있다. 이를 위해, 데이터 수집부는 이미지의 수집 조건을 포함하는 가이드 정 보를 학습 데이터 수집 장치에 전송할 수 있다. 여기서, 가이드 정보는 수집 조건인 객체의 클래스, 데이 터 확장자, 이미지 해상도 등을 포함할 수 있다. 이때, 데이터 수집부는 가이드 정보를 샘플 이미지를 통 해 제공할 수 있다. 즉, 데이터 수집부는 프로젝트 계약 당시 수신한 샘플 이미지를 학습 데이터 수집 장 치에 전송하여, 학습 데이터 수집 장치 수집 조건을 인지하도록 할 수 있다. 또한, 데이터 수집부는 적어도 하나의 학습 데이터 수집 장치로부터 이미지들을 수신할 수 있다. 이 때, 데이터 수집부는 적어도 하나의 학습 데이터 수집 장치 각각에 식별자(identifier)를 부여하고, 부여된 식별자별로 수신한 이미지들을 저장할 수 있다. 다음 구성으로, 데이터 정제부는 수신한 이미지들의 컬러 정보를 추출할 수 있다. 여기서, 컬러 정보는 픽 셀(pixel)에 대한 RGB(Red, Green, Blue) 값 또는 컬러 코드(color code) 값이 될 수 있다. 데이터 정제부 는 적어도 하나의 학습 데이터 수집 장치 각각에 부여된 식별자(identifier)를 기준으로 이미지들의 파일 명 및 컬러 정보를 저장부에 저장할 수 있다. 데이터 정제부는 이미지들 사이의 컬러 정보를 기준으로 노이즈 이미지를 분류할 수 있다. 즉, 데이터 정 제부는 이미지들 중 컬러 정보의 유사도가 사전 설정된 값보다 높은 이미지들 중 적어도 하나를 노이즈 이 미지로 분류할 수 있다. 이때, 데이터 정제부는 이미지들을 사전 설정된 해상도로 리샘플링(resamping)하고, 리샘플링 된 이미지들 의 동일한 좌표에 존재하는 픽셀의 컬러 정보를 각각 비교하여 이미지들 간 유사도를 평가할 수 있다. 또한, 데이터 정제부는 동일한 식별자에 동일한 파일명을 갖는 이미지가 복수개로 존재하는 경우, 동일한 파일명을 갖는 이미지 중 적어도 하나를 노이즈 이미지로 분류할 수 있다. 데이터 정제부는 식별자가 상이 하나 동일한 파일명이 복수개로 존재하는 경우, 동일한 파일명을 갖는 이미지 중 적어도 하나를 노이즈 이미지 로 분류할 수 있다. 즉, 데이터 정제부는 동일한 식별자에서 같은 이름의 파일이 중복되어 등록되거나, 다 른 식별자로부터 동일한 파일이 중복되어 등록되는 경우를 사전 방지할 수 있다.또한, 데이터 정제부는 이미지들을 시간 순으로 나열하고, 나열된 이미지들을 사전 설정된 개수로 그룹핑 (grouping) 한 시퀀스 데이터를 생성하고, 시퀀스 데이터 별로 포함된 이미지들의 컬러 정보를 각각 비교하여 노이즈 이미지를 분류할 수 있다. 구체적으로, 데이터 정제부는 생성된 시퀀스 데이터의 이미지들 각각에 포함된 객체의 엣지(edge)를 추출 할 수 있다. 데이터 정제부는 시퀀스 데이터 별로 연속된 이미지 사이의 엣지 변화량을 기준으로 이미지들 의 유사도를 평가할 수 있다. 여기서, 엣지는 이미지 안에서 픽셀의 값이 급격하게 변하는 곳이다. 이러한, 데이터 정제부는 이미지를 미분한 그레디언트(gradient) 벡터의 크기로 엣지를 판단할 수 있다. 예를 들어, 데이터 정제부는 소벨 엣 지 검출(sobel edge detection) 알고리즘, 케니 엣지 검출(canny edge detection) 알고리즘 등의 엣지 추출 알 고리즘을 통해 이미지 상의 엣지를 추출할 수 있다. 또한, 데이터 정제부는 이미지들 중 유사도가 사전 설정된 값보다 높은 이미지들의 선명도(sharpness)를 산출하고, 산출된 선명도가 가장 높은 이미지를 제외한 나머지 이미지를 노이즈 이미지로 분류할 수 있다. 즉, 유사한 이미지가 복수개 존재하는 경우, 특정 기준을 통해 복수의 이미지 중 하나를 제외한 나머지 이미지 를 제거해야 한다. 이를 위해, 데이터 정제부는 선정된 이미지들 중 선명도가 가장 높은 이미지를 제외한 나머지 이미지를 노이즈 이미지로 분류하여 삭제할 수 있다. 또한, 데이터 정제부는 시퀀스 데이터 별로 연속된 이미지 사이의 유사도를 산출하고, 산출된 유사도를 기 준으로 시퀀스 데이터 별 초당 프레임 수(frame per second)를 결정할 수 있다. 즉, 데이터 정제부는 하나의 시퀀스 데이터에 연속된 이미지 사이의 유사도가 사전 설정된 값보다 높은 경 우, 해당 이미지를 수집한 차량의 속도로 높은 것으로 판단하고, 해당 시퀀스 데이터 별 초당 프레임 수를 결정 하여, 시퀀스 데이터 내에 포함된 이미지의 부피를 줄일 수 있다. 또한, 데이터 정제부는 수집 조건과 대응하는 이미지 정보를 이미지들로부터 추출할 수 있다. 여기서, 이 미지 정보는 파일 확장자, 이미지 해상도, 픽셀(pixel)에 대한 RGB(Red, Green, Blue) 값 및 컬러 코드(color code) 값 중 적어도 하나를 포함할 수 있다. 여기서, 데이터 정제부는 추출한 이미지 정보를 가이드 정보와 비교하여, 수집 환경 또는 학습 데이터 수 집 장치의 오류에 따른 노이즈 이미지를 분류할 수 있다. 구체적으로, 데이터 정제부는 샘플 이미지의 파일 확장자, 이미지 해상도, 픽셀에 대한 RGB 값 및 컬러 코 드 값 중 적어도 하나를 포함하는 샘플 이미지 정보를 추출하고, 추출된 샘플 이미지 정보를 이미지들로부터 추 출된 이미지 정보와 비교할 수 있다. 이때, 데이터 정제부는 샘플 이미지와 유사도가 사전 설정된 값보다 낮은 이미지를 노이즈 이미지로 분류 할 수 있다. 즉, 데이터 정제부는 샘플 이미지와 파일 확장자 또는 이미지 해상도가 상이하거나, 픽셀 (pixel)에 대한 RGB(Red, Green, Blue) 값 및 컬러 코드(color code) 값의 유사도가 사전 설정된 값보다 낮은 경우, 해당 이미지를 노이즈 이미지로 분류할 수 있다. 데이터 정제부는 이미지들을 시간 순으로 나열하고, 나열된 이미지들을 사전 설정된 개수로 그룹핑 (grouping) 한 시퀀스 데이터를 생성하고, 시퀀스 데이터 별로 노이즈 이미지를 분류할 수 있다. 이때, 데이터 정제부는 시퀀스 데이터 중 특정 이미지를 대상으로 전후 이미지의 유사도를 비교하고, 전후 이미지 사이 의 유사도가 사전 설정된 값보다 높되, 전후 이미지와 상기 특정 이미지 사이의 유사도가 사전 설정된 값보다 낮은 경우, 특정 이미지를 노이즈 이미지로 판단할 수 있다. 즉, 데이터 정제부는 특정 이미지의 전후 이미지를 비교하여 특정 이미지 만 유사도가 낮은 경우, 특정 이 미지가 과속 방지턱을 넘는 과정에서 촬영된 이미지로 판단하고, 해당 이미지를 노이즈 이미지로 분류할 수 있 다. 여기서, 데이터 정제부는 이미지들을 사전 설정된 해상도로 리샘플링하고, 리샘플링 된 이미지들의 동 일한 위치에 존재하는 픽셀의 컬러 정보를 각각 비교하여 이미지들 간 유사도를 평가할 수 있다. 또한, 데이터 정제부는 이미지들 각각에 포함된 객체의 엣지를 추출하고, 이미지들 각각에 포함된 객체를 검출하고, 검출된 객체의 위치 변화 값이 사전 설정된 값보다 높은 이미지를 노이즈 이미지로 분류할 수 있다. 즉, 데이터 정제부는 이미지에 포함된 객체의 움직임의 정도를 통해 특정 이미지가 과속 방지턱을 넘는 과 정에서 촬영된 이미지 인지를 판단할 수 있다.또한, 데이터 정제부는 통신부를 통해 적어도 하나의 학습 데이터 수집 장치로부터 이미지들 각 각의 메타 정보를 함께 수신할 수 있다. 여기서, 메타 정보는 이미지들 각각의 촬영 시점에서 학습 데이터 수집 장치의 위치 정보 및 속도 정보를 포함할 수 있다. 학습 데이터 수집 장치로부터 제공받은 메타 정보를 활용하여, 데이터 정제부는 학습 데이터 수집 장 치가 이동한 경로를 포함하는 지도 정보에 포함된 과속 방지턱의 위치 정보를 기준으로 메타 정보와 비교 하여, 과속 방지턱의 위치에서 촬영된 이미지를 노이즈 이미지로 분류할 수 있다. 또한, 데이터 정제부는 학습 데이터 수집 장치가 이동한 경로를 포함하는 지도 정보에 포함된 커브 (curve)길의 위치 정보를 기준으로 메타 정보와 비교하여, 커브길의 위치에서 생성된 이미지를 노이즈 이미지로 분류할 수 있다. 또한, 데이터 정제부는 시퀀스 데이터에서 연속된 이미지 사이의 유사도를 비교하고, 유사도가 사전에 설 정된 값보다 낮은 이미지가 연속적으로 검출된 경우, 검출된 이미지들이 커브길에서 촬영된 이미지들로 판단하 고, 검출된 이미지들을 노이즈 이미지로 분류할 수 있다. 또한, 데이터 정제부는 시퀀스 데이터 별 연속된 이미지의 유사도를 기초로 노이즈 이미지를 분류하고, 분 류된 노이즈 이미지 각각의 오류 종류를 추정할 수 있다. 구제적으로, 데이터 정제부는 시퀀스 데이터 중 연속된 이미지 사이의 유사도를 비교하고, 제1 이미지와 연속된 제2 이미지 사이의 유사도가 사전 설정된 값보다 낮고, 제2 이미지와 연속된 제3 이미지와 제2 이미지의 유사도가 사전 설정된 값보다 높은 경우, 시퀀스 데이터에 포함된 이미지를 촬영한 카메라의 카메라 앵글 (camera angle)이 변경된 오류로 판단할 수 있다. 즉, 데이터 정제부는 이미지가 급격하게 변화된 후 변화 된 상태의 이미지가 지속적으로 수집되는 경우, 이미지가 변화된 이후의 데이터를 카메라 앵글이 변경된 오류에 따른 노이즈 데이터로 판단할 수 있다. 또한, 데이터 정제부는 시퀀스 데이터 중 연속된 이미지 사이의 유사도를 비교하고, 유사도가 사전에 설정 된 값보다 낮은 이미지가 사전 설정된 개수를 초과하는 경우, 시퀀스 데이터에 포함된 이미지를 촬영한 카메라 의 결속 불량에 따른 오류로 판단할 수 있다. 즉, 데이터 정제부는 이미지가 지속적으로 변화되는 경우, 카메라의 결속 불량에 따른 오류로 판단할 수 있다. 데이터 정제부는 추정된 오류에 해당하는 데이터를 삭제하거나, 추정된 오류의 종류를 메타 정보에 포함시 켜 검수자가 확인할 수 있도록 할 수 있다. 또한, 데이터 정제부는 GPS(global positioning system) 좌표를 기초로 수신한 이미지들 및 사전 저장된 이미지를 매칭하고, 매칭된 이미지 사이의 유사도를 비교하여, 노이즈 이미지를 분류할 수 있다. 즉, 데이터 정 제부는 기 수행된 프로젝트 중 해당 위치에서 이전에 수집된 이미지와, 현재 수집된 이미지들을 매칭하고, 매칭된 이미지 사이의 유사도를 비교하여 유사도가 사전 설정된 값보다 낮은 경우, 해당 이미지를 노이즈 이미 지로 분류할 수 있다. 또한, 데이터 정제부는 각 이미지의 제1 변(side)을 구성하는 픽셀들과 제2 변을 구성하는 픽셀들 사이의 RGB 값의 유사도를 기준으로 제1 변 및 제2 변으로부터 각각 하나의 정점(vertex)을 식별하고, 제1 변 및 상기 제2 변으로부터 각각 식별된 두 정점을 연결한 선분을 추출할 수 있다. 즉, 데이터 정제부는 이미지 내에서 도로, 방음벽, 가드레일 등의 정적으로 존재하는 객체를 식별하기 위 하여, 이미지 내에서 양단부에 존재하는 픽셀의 유사도를 평가하여 이미지의 양단부를 연결하는 객체를 식별할 수 있다. 그리고, 이미지의 양단부를 연결하는 객체를 정적으로 존재하는 객체로 인식할 수 있다. 데이터 정제부는 매칭된 이미지 각각에서 추출된 선분의 길이 및 각도 중 적어도 하나를 기준으로 사전 설 정된 오차 범위를 벗어나는 경우, 카메라 앵글이 변경된 오류로 판단할 수 있다. 하지만 이에 한정된 것은 아니고, 데이터 정제부는 매칭된 이미지 각각에서 엣지(edge)를 추출하고, 추출 된 엣지를 기초로 매칭된 이미지 각각에 포함된 객체를 식별하고, 식별된 객체의 위치 변화 값을 기초로 노이즈 이미지를 분류할 수 있다. 또한, 데이터 정제부는 통신부를 통해 이미지들과 동시에 획득된 라이다(lidar)를 통해 획득된 3D 점 군(3D points group) 데이터를 더 수신할 수 있다. 데이터 정제부는 3D 점군 데이터에 포함된 거리 정보를 기초로 매칭된 이미지 각각에 검출된 객체의 유형이 유동 객체 또는 정적 객체 인지 여부를 판단하고, 검출된객체 중 정적 객체의 위치 변화 값을 기초로 상기 노이즈 이미지를 분류할 수 있다. 즉, 이미지에 포함된 객체 중에는 자동차, 자전거, 사람 등과 같은 유동 객체와, 도로, 건물, 가이드레일 등과 같은 정적 객체가 존재할 수 있다. 이에 따라, 데이터 정제부는 샘플 이미지와 매칭되는 이미지 사이의 정 적 객체의 위치 변화 값이 사전 설정된 값보다 높은 이미지를 노이즈 이미지로 분류할 수 있다. 다음 구성으로, 데이터 납품부는 어노테이션 장치들에 대하여 하나 이상의 어노테이션 작업 대상물 (즉, 이미지)을 분배할 수 있다. 또한, 데이터 납품부는 어노테이션 작업 결과물을 검증한 후, 인공지능 학습 장치에 납품할 수 있다. 다음 구성으로, 저장부는 학습 데이터 생성 장치의 동작에 필요한 데이터를 저장할 수 있다. 저장부 는 인공지능(AI) 학습을 위한 데이터 설계하는데 필요한 데이터를 저장할 수 있다. 구체적으로, 저장부는 어노테이션 작업의 대상이 되는 이미지들을 저장할 수 있다. 저장부는 프로젝 트의 속성, 이미지의 속성 또는 작업자의 속성을 저장할 수 있다. 이하, 상술한 바와 같은 학습 데이터 생성 장치의 논리적 구성요소를 구현하기 위한 하드웨어에 대하여 보 다 구체적으로 설명한다. 도 3은 본 발명의 일 실시예에 따른 학습 데이터 생성 장치의 하드웨어 구성도이다. 학습 데이터 생성 장치는 프로세서(Processor, 250), 메모리(Memory, 255), 송수신기(Transceiver, 260), 입출력장치(Input/output device, 265), 데이터 버스(Bus, 270) 및 스토리지(Storage, 275)를 포함하여 구성될 수 있다. 프로세서는 메모리에 상주된 소프트웨어(280a)에 따른 명령어를 기초로, 학습 데이터 생성 장치(20 0)의 동작 및 기능을 구현할 수 있다. 메모리에는 본 발명에 따른 방법이 구현된 소프트웨어(280a)가 상주 (loading)될 수 있다. 송수신기는 학습 데이터 수집 장치, 어노테이션 장치 및 인공지능 학습 장치와 데이터를 송수신할 수 있다. 입출력장치는 학습 데이터 설계 장치의 동작에 필요한 데이 터를 입력 받고, 분류된 노이즈 이미지, 예측된 전체 작업 비용 등을 출력할 수 있다. 데이터 버스는 프로 세서, 메모리, 송수신기, 입출력장치 및 스토리지와 연결되어, 각각의 구성 요소 사 이가 서로 데이터를 전달하기 위한 이동 통로의 역할을 수행할 수 있다. 스토리지는 본 발명에 다른 방법이 구현된 소프트웨어(280a)의 실행을 위해 필요한 애플리케이션 프로그래 밍 인터페이스(Application Programming Interface, API), 라이브러리(library) 파일, 리소스(resource) 파일 등을 저장할 수 있다. 스토리지는 본 발명에 따른 방법이 구현된 소프트웨어(280b)를 저장할 수 있다. 또 한, 스토리지는 인공지능 학습용 데이터 생성 방법의 수행에 필요한 정보들을 저장할 수 있다. 특히, 스토 리지는 프로젝트의 속성, 이미지의 속성, 작업자의 속성, 기존에 수행된 복수 개의 프로젝트에 관한 정보 및 작업자들의 풀을 저장하는 데이터베이스를 포함할 수 있다. 본 발명의 일 실시예에 따르면, 메모리에 상주되거나 또는 스토리지에 저장된 소프트웨어(280a, 280b)는 프로세서가 인공지능(Artificial Intelligence, AI)의 기계 학습(machine learning)을 위한 이미 지의 수집을 적어도 하나의 학습 데이터 수집 장치에 요청하는 단계, 프로세서가, 적어도 하나의 학습 데 이터 수집 장치로부터 이미지들을 수신하는 단계, 프로세서가, 수신한 이미지들의 컬러 정보를 추출하는 단계 및 프로세서가, 이미지들 사이의 컬러 정보를 기준으로 노이즈 이미지를 분류하는 단계를 실행시키기 위하여, 기록매체에 기록된 컴퓨터 프로그램이 될 수 있다. 본 발명의 다른 실시예에 따르면, 메모리에 상주되거나 또는 스토리지에 저장된 소프트웨어(280a, 280b)는 프로세서가, 인공지능(Artificial Intelligence, AI)의 기계 학습(machine learning)을 위한 수 집 조건을 포함하는 가이드 정보를 적어도 하나의 수집 장치에 전송하는 단계, 프로세서가, 적어도 하나의 학습 데이터 수집 장치로부터 이미지들을 수신하는 단계, 프로세서가, 수집 조건과 대응하는 이미지 정보 를 이미지들로부터 추출하는 단계 및 프로세서가, 이미지 정보를 가이드 정보와 비교하여, 수집 환경에 따 른 노이즈 이미지를 분류하는 단계를 실행시키기 위하여, 기록매체에 기록된 컴퓨터 프로그램이 될 수 있다. 본 발명의 다른 실시예에 따르면, 메모리에 상주되거나 또는 스토리지에 저장된 소프트웨어(280a, 280b)는 프로세서가, 인공지능(Artificial Intelligence, AI)의 기계 학습(machine learning)을 위한 이미지의 수집 조건을 포함하는 가이드 정보를 적어도 하나의 학습 데이터 수집 장치에 전송하는 단계, 프로세서 가, 적어도 하나의 학습 데이터 수집 장치로부터 이미지들을 수신하는 단계, 프로세서가, 수집 조건 과 대응하는 이미지 정보를 이미지들로부터 추출하는 단계 및 프로세서가, 추출한 이미지 정보를 상기 가 이드 정보와 비교하여, 이미지들 중 수집 장치 오류에 따른 노이즈 이미지를 분류하는 단계를 실행시키기 위하 여, 기록매체에 기록된 컴퓨터 프로그램이 될 수 있다. 본 발명의 또 다른 실시예에 따르면, 메모리에 상주되거나 또는 스토리지에 저장된 소프트웨어(280a, 280b)는 프로세서가, 인공지능(Artificial Intelligence, AI) 학습을 위하여 수행 예정인 어노테이션 (annotation) 작업과 관련된 프로젝트를 수행하기 위한 적어도 하나의 샘플 데이터를 인공지능 학습 장치로부터 수신하는 단계, 프로세서가, 기 수행된 복수의 프로젝트에 포함된 기존 데이터를 샘플 데이터와 비교하고, 샘플 데이터와의 유사도가 사전 설정된 값보다 높은 기존 데이터가 포함된 적어도 하나의 프로젝트를 추출하는 단계 및 프로세서가, 추출된 적어도 하나의 프로젝트를 기초로 수행 예정인 어노테이션 작업과 관련된 프 로젝트를 수행하기 위하여 요구되는 전체 작업 비용을 예측하는 단계를 실행시키기 위하여, 기록매체에 기록된 컴퓨터 프로그램이 될 수 있다. 보다 구체적으로, 프로세서는 ASIC(Application-Specific Integrated Circuit), 다른 칩셋(chipset), 논 리 회로 및/또는 데이터 처리 장치를 포함할 수 있다. 메모리는 ROM(Read-Only Memory), RAM(Random Access Memory), 플래쉬 메모리, 메모리 카드, 저장 매체 및/또는 다른 저장 장치를 포함할 수 있다. 송수신기 는 유무선 신호를 처리하기 위한 베이스밴드 회로를 포함할 수 있다. 입출력장치는 키보드 (keyboard), 마우스(mouse), 및/또는 조이스틱(joystick) 등과 같은 입력 장치 및 액정표시장치(Liquid Crystal Display, LCD), 유기 발광 다이오드(Organic LED, OLED) 및/또는 능동형 유기 발광 다이오드(Active Matrix OLED, AMOLED) 등과 같은 영상 출력 장치 프린터(printer), 플로터(plotter) 등과 같은 인쇄 장치를 포 함할 수 있다. 본 명세서에 포함된 실시 예가 소프트웨어로 구현될 경우, 상술한 방법은 상술한 기능을 수행하는 모듈(과정, 기능 등)로 구현될 수 있다. 모듈은 메모리에 상주되고, 프로세서에 의해 실행될 수 있다. 메모리 는 프로세서의 내부 또는 외부에 있을 수 있고, 잘 알려진 다양한 수단으로 프로세서와 연결될 수 있다. 도 3에 도시된 각 구성요소는 다양한 수단, 예를 들어, 하드웨어, 펌웨어(firmware), 소프트웨어 또는 그것들의 결합 등에 의해 구현될 수 있다. 하드웨어에 의한 구현의 경우, 본 발명의 일 실시예는 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 프로세서, 콘트롤러, 마이크로 콘트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 또한, 펌웨어나 소프트웨어에 의한 구현의 경우, 본 발명의 일 실시예는 이상에서 설명된 기능 또는 동작들을 수행하는 모듈, 절차, 함수 등의 형태로 구현되어, 다양한 컴퓨터 수단을 통하여 판독 가능한 기록매체에 기록 될 수 있다. 여기서, 기록매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함 할 수 있다. 기록매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨 터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 예컨대 기록매체는 하드 디스크, 플로피 디스 크 및 자기 테이프와 같은 자기 매체(Magnetic Media), CD-ROM(Compact Disk Read Only Memory), DVD(Digital Video Disk)와 같은 광 기록 매체(Optical Media), 플롭티컬 디스크(Floptical Disk)와 같은 자기-광 매체 (Magneto-Optical Media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치를 포함한다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 이러한, 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어로서 작동하도록 구 성될 수 있으며, 그 역도 마찬가지이다. 이하, 본 발명의 일 실시예에 따른 어노테이션 장치의 논리적 구성에 대하여 상세히 설명하도록 한다. 도 4는 본 발명의 일 실시예에 따른 어노테이션 장치의 논리적 구성도이다. 도 4를 참조하면, 본 발명의 일 실시예에 따른 어노테이션 장치는 통신부, 입출력부, 저장부 , 객체 식별부, 객체 속성 설정부 및 결과물 생성부를 포함하여 구성될 수 있다.이와 같은, 어노테이션 장치의 구성 요소들은 기능적으로 구분되는 요소들을 나타낸 것에 불과하므로, 둘 이상의 구성 요소가 실제 물리적 환경에서는 서로 통합되어 구현되거나, 하나의 구성 요소가 실제 물리적 환경 에서는 서로 분리되어 구현될 수 있을 것이다. 각각의 구성 요소에 대하여 설명하면, 통신부는 학습 데이터 생성 장치와 데이터를 송수신할 수 있다. 구체적으로, 통신부는 학습 데이터 생성 장치로부터 이미지를 수신할 수 있다. 여기서, 이미지는 인공지능(AI) 학습을 위한 어노테이션 작업의 대상이 되는 이미지이다. 이와 같은, 이미지는 학습 데이터 생성 장치가 설계한 데이터 가공 계획에 따라, 어노테이션 작업의 대상이 되는 이미지를 개별 적으로 수신하거나, 또는 복수 개의 이미지를 일괄적으로 수신할 수 있다. 또한, 통신부는 어노테이션의 작업 결과물을 학습 데이터 생성 장치에 전송할 수 있다. 여기서, 작업 결과물은 작업자의 제어에 따라 설정된 바운딩 박스의 좌표 및 객체의 속성 정보가 포함될 수 있 다. 또한, 작업 결과물은 JSON 파일 형식을 가질 수 있으나, 이에 한정되는 것은 아니다. 그리고, 통신부는 학습 데이터 생성 장치로부터 프로젝트의 속성, 이미지의 속성 또는 작업자의 속성 을 수신할 수 있다. 여기서, 프로젝트의 속성에는 인공지능(AI)의 학습과 관련된 프로젝트에 대한 학습 목적, 학습 기간, 학습에 필 요한 이미지의 수, 이미지에서 식별하고자 하는 객체의 속성, 폴리곤 설정 규칙 등이 포함될 수 있으나, 이에 한정되는 것은 아니다. 이미지의 속성에는 이미지의 파일명, 이미지의 크기(너비, 높이), 해상도, 비트 수준, 압축 형식, 촬영 장치명, 노출 시간, ISO 감도, 초점 거리, 조리개 개방 값, 촬영 장소 좌표(GPS 위도, 경도), 촬영 시각 등이 포함될 수 있으나, 이에 한정되는 것은 아니다. 작업자의 속성에는 작업자의 명칭, 식별번호, 할당된 작업량, 작업에 따른 비용, 작업 결과 평가 등이 포함될 수 있으나, 이에 한정되는 것은 아니다. 다음 구성으로, 입출력부는 사용자 인터페이스(User Interface, UI)를 통해 작업자로부터 신호를 입력 거 나, 또는 연산된 결과를 외부로 출력할 수 있다. 여기서, 작업자는 어노테이션 작업을 수행하는 자를 의미한다. 이와 같은, 작업자는 사용자, 수행자, 라벨러 또 는 데이터 라벨러 등으로 지칭될 수 있으며, 이에 한정되는 것은 아니다. 구체적으로, 입출력부는 어노테이션 작업의 대상이 되는 이미지를 출력할 수 있다. 입출력부는 객체 를 지정하기 위한 제어 신호를 작업자로부터 입력 받을 수 있다. 그리고, 입출력부는 이미지 위에 사용자 가 지정한 영역을 오버레이(overlay)하여 출력할 수 있다. 또한, 입출력부는 객체의 속성 정보를 설정하기 위한 제어 신호를 작업자로부터 입력 받을 수 있다. 객체의 속성 정보는 인공지능(AI) 학습의 대상이 되는 객체의 속성을 지정하기 위한 정보이다. 이와 같은, 객체 의 속성 정보에는 어노테이션의 종류(type), 클래스 명(class), 분류 항목(tags), 객체의 잘림 여부 (truncated), 대분류, 소분류 또는 상위 레벨(instance upper)에 관한 정보가 포함될 수 있으며, 이에 한정되는 것은 아니다. 다음 구성으로, 저장부는 통신부를 통해 수신된 이미지를 저장할 수 있다. 저장부는 통신부 를 통해 수신된 프로젝트의 속성, 이미지의 속성 또는 작업자의 속성을 저장할 수 있다. 다음 구성으로, 객체 식별부는 인공지능(AI) 학습을 위한 어노테이션(annotation) 작업의 대상이 되는 이 미지에 포함된 서로 중첩되어 배치되는 복수의 객체 중 제1 객체의 외곽선을 지정할 수 있다. 이때, 객체 식별부는 작업자로부터 제1 객체의 외곽선을 따라 복수의 점을 입력 받고, 복수의 점을 연결하 여 제1 객체의 외곽선을 형성할 수 있다. 즉, 객체 식별부는 작업자가 지정한 점을 연결하여 폴리곤 (polygon) 형태의 영역을 생성할 수 있다. 이때, 객체 식별부는 작업자로부터 상기 복수의 점 중 임의의 제1 점 및 제2 점을 선택받고, 제1 점 및 제 2 점 사이에 적어도 하나의 새로운 제3 점을 지정 받는 경우, 제1 점, 제2 점 및 상기 제3 점을 연결하여, 제1객체의 외곽선을 수정할 수 있다. 즉, 객체 식별부는 복수의 점을 지정받은 후에 수정이 필요한 영역에 해 당하는 두개의 점을 선택받고, 두개의 점 사이에 새로운 점을 지정하는 경우, 기존에 지정했던 점을 삭제하고, 새로운 점을 기준으로 복수의 점을 연결하여 새로운 영역을 생성할 수 있다. 하지만, 이에 한정된 것은 아니고, 객체 식별부는 작업자의 제어에 따라, 복수의 점 중 임의의 점을 드레 그(drag)하여 이동시키는 경우, 이동시킨 점을 기준으로 제1 객체의 외곽선을 수정할 수 있다. 또한, 객체 식별부는 이미지의 엣지(edge)를 추출하고, 추출된 엣지를 기초로 적어도 하나의 객체를 식별 하고, 작업자로부터 하나의 점을 입력 받으면, 입력 받은 점을 포함하는 객체의 엣지를 제1 객체의 외곽선으로 지정할 수 있다. 즉, 객체 식별부는 작업자로부터 복수의 점을 입력 받아 객체의 외곽선을 생성하지 않고, 자동으로 객체를 식별하여 객체의 외곽선을 지정할 수 있다. 즉, 엣지를 기초로 객체를 식별하는 경우, 이미지 내에 여러 개의 객체가 식별될 수 있다. 이때, 객체 식별부는 작업자가 특정 점을 선택하게 되면, 해당 점이 포함된 엣지 를 식별하고자 하는 객체의 엣지로 판단하고, 해당 객체의 엣지를 외곽선으로 인식할 수 있다. 제1 객체의 외곽선을 지정한 후에, 객체 식별부는 제1 객체와 중첩되어 배치된 제2 객체 사이의 경계선을 지정할 수 있다. 구체적으로, 객체 식별부는 제1 객체의 외곽선을 따라 사전 설정된 간격을 갖는 복수의 점을 생성하고, 생 성된 복수의 점 중 적어도 하나의 점을 선택받고, 선택받은 적어도 하나의 점을 기초로 상기 경계선을 지정할 수 있다. 이때, 사용자에게 경계선에 해당하는 모든 점을 입력받는 것이 아니고, 객체 식별부는 복수의 점 중 임의 의 두개의 점을 선택받고, 선택받은 두개의 점 사이에 존재하는 적어도 하나의 점을 연결하는 선을 생성하고, 생성된 선을 경계선으로 지정할 수 있다. 여기서, 객체 식별부는 복수의 점 중 임의의 제1 점 및 제2 점을 선택받고, 제1 점 및 제2 점 사이에 존재 하는 제3 점을 선택받는 경우, 제1 점, 제2 점 및 제3 점을 연결하는 선을 생성할 수 있다. 즉, 두개의 점을 선 택받는 경우, 선택받은 두개의 점을 기준으로 객체의 외곽선을 이루는 두개의 선이 존재한다. 이에 따라, 객체 식별부는 두개의 점 사이에 다른 한점을 선택받아, 경계선을 명확히 인식할 수 있다. 경계선을 지정한 후에 객체 식별부는 경계선을 제2 객체의 외곽선의 일부로 설정할 수 있다. 이때, 객체 식별부는 경계선이 제1 객체의 외곽선과 구분되도록 색상을 달리하여 출력할 수 있다. 또한, 객체 식별부는 설정된 경계선을 기준으로 제2 객체의 외곽선을 지정할 수 있다. 이때, 객체 식별부는 이미지의 엣지를 추출하고, 추출된 엣지를 기초로 적어도 하나의 객체를 식별하고, 식별된 적어도 하나의 객체 중 경계선을 포함하는 객체 중 제1 객체를 제외한 나머지 객체의 엣지를 제2 객체의 외곽선으로 지정할 수 있다. 또한, 객체 식별부는 작업자로부터 제2 객체의 외곽선을 따라 복수의 점을 입력 받고, 경계선 및 복수의 점을 연결하여 제2 객체의 외곽선을 형성할 수 있다. 그리고, 객체 식별부는 제1 객체의 외곽선 및 제2 객체의 외곽선의 너비를 합산한 너비로 경계선의 너비를 변경하고, 너비가 변경된 경계선을 인접(adjacent)한 두개의 선으로 구분하고, 구분된 두개의 선 각각을 제1 객 체의 외곽선 및 제2 객체의 외곽선과 연결할 수 있다. 즉, 객체 식별부는 입력받은 하나의 경계선을 서로 밀착되어 배치되는 두개의 경계선으로 생성하고, 생성된 두개의 경계선을 각 객체에 연결할 수 있다. 한편, 객체 식별부는 상술한 방법 이외에 하기와 같이 객체를 식별할 수 있다. 구체적으로, 객체 식별부는 인공지능(AI) 학습을 위한 어노테이션 작업의 대상이 되는 이미지에 포함된 서 로 중첩되어 배치되는 복수의 객체의 외곽선을 지정할 수 있다. 이때, 객체 식별부는 작업자로부터 복수의 객체를 포함하는 외곽선을 따라 복수의 점을 입력 받고, 복수의 점을 연결하여, 복수의 객체에 대한 외곽선을 생성할 수 있다. 또한, 객체 식별부는 이미지의 엣지(edge)를 추출하고, 추출된 엣지를 기초로 적어도 하나의 객체를 식별 하고, 작업자로부터 식별된 객체 중 복수의 객체를 선택받고, 추출된 엣지를 기초로 경계선을 제외한 선택받은 복수의 객체에 대한 외곽선을 생성할 수 있다.또한, 객체 식별부는 통신부를 통해 이미지와 동시에 라이다(lidar)로부터 획득된 점군 데이터를 수 신할 수 있다. 객체 식별부는 이미지와 동시에 라이다로부터 획득된 점군 데이터를 기초로, 지정된 외곽선 내부에 존재하는 점들 중 거리(depth)가 일정 범위(range)를 갖는 복수의 점군을 식별하고, 작업자로부터 복수 의 점군 중 복수의 객체를 선택받고, 식별된 복수의 점군을 기초로 선택받은 복수의 객체에 대한 외곽선을 생성 할 수 있다. 그리고, 객체 식별부는 복수의 객체를 포함하는 일부 영역을 바운딩 박스(bounding box)로 설정하고, 바운 딩 박스 내측 영역에서 객체의 엣지를 추출하고, 추출된 엣지를 기준으로 객체(object)와 배경(background)을 구분하고, 배경을 삭제하여 복수의 객체의 외곽선을 지정할 수 있다. 복수의 객체에 대한 외곽선을 지정한 후에, 객체 식별부는 지정된 외곽선 내에서 복수의 객체 사이의 경계 선을 지정할 수 있다. 여기서, 객체 식별부는 추출된 엣지를 기초로 복수의 객체에 대한 외곽선 내에서 경계선을 식별할 수 있다. 또한, 객체 식별부는 작업자로부터 복수의 객체에 대한 외곽선 내부에 위치한 복수의 점을 입력 받고, 입 력받은 복수의 점을 연결하여 경계선을 생성할 수 있다. 또한, 객체 식별부는 이미지와 동시에 라이다로부터 획득된 점군 데이터를 기초로, 지정된 외곽선 내부에 존재하는 점들 중 거리가 일정 범위를 갖는 복수의 점군을 식별하고, 복수의 점군 사이의 경계선을 복수의 객체 사이의 경계선으로 지정할 수 있다. 또한, 객체 식별부는 지정된 외곽선 내부에 위치한 픽셀(pixel)의 RGB(Red, Green, Blue) 값을 기초로, 사전 설정된 값보다 유사한 RGB 값을 갖는 그룹을 생성하고, 생성된 그룹을 각각 객체로 인식하고, 인식된 객체 의 경계선을 생성할 수 있다. 또한, 객체 식별부는 이미지와 동시에 라이다로부터 획득된 점군 데이터를 기초로, 지정된 외곽선 내부에 존재하는 점들 중 거리가 일정 범위를 갖는 복수의 점군을 식별하고, 작업자로부터 복수의 점군 중 하나의 객체 를 선택받고, 선택받은 객체의 점군을 기초로 경계선을 생성할 수 있다. 그리고, 객체 식별부는 지정된 외곽선 내부의 엣지를 추출하고, 추출된 엣지를 기초로 적어도 하나의 객체 를 식별하고, 작업자로부터 식별된 객체 중 하나의 객체를 선택받고, 추출된 엣지를 기초로 경계선을 생성할 수 있다. 이때, 객체 식별부는 생성된 경계선을 따라 사전 설정된 간격을 갖는 복수의 점을 생성하고, 작업자 의 제어에 따라 복수의 점 중 적어도 하나의 점을 이동시켜 경계선을 수정할 수 있다. 경계선을 지정한 후에, 객체 식별부는 지정된 경계선을 기준으로 구획된 복수의 영역을 기준으로 복수의 객체를 각각 식별할 수 있다. 다음 구성으로, 객체 속성 설정부는 입출력부를 통해 작업자로부터 객체의 속성 정보를 설정하기 위 한 제어 신호를 입력받을 수 있다. 객체 속성 설정부는 작업자의 제어에 의해 추천 정보의 목록 중에서 하나의 정보가 선택되면, 선택된 정보 에 대응하는 객체의 유형에 따라 피드백(feedback)을 제공할 수 있다. 일 실시예로, 객체 속성 설정부는 선택된 정보에 대응하는 객체의 유형에 따라 서로 다르게 설정된 색상 또는 투명도를 반영하여, 객체 내부의 영역과 관련된 사용자 인터페이스(User Interface, UI)를 변경할 수 있다. 다음 구성으로, 결과물 생성부는 어노테이션의 작업 결과물을 생성하여, 학습 데이터 생성 장치에 전 송할 수 있다. 이하, 상술한 바와 같은 어노테이션 장치의 논리적 구성요소를 구현하기 위한 하드웨어에 대하여 보다 구 체적으로 설명한다. 도 5는 본 발명의 일 실시예에 따른 어노테이션 장치의 하드웨어 구성도이다. 도 5에 도시된 바와 같이, 어노테이션 장치는 프로세서(Processor, 350), 메모리(Memory, 355), 송수신기 (Transceiver, 360), 입출력장치(Input/output device, 365), 데이터 버스(Bus, 370) 및 스토리지(Storage, 375)를 포함하여 구성될 수 있다. 프로세서는 메모리에 상주된 어노테이션 방법이 구현된 소프트웨어(380a)에 따른 명령어를 기초로, 어노테이션 장치의 동작 및 기능을 구현할 수 있다. 메모리에는 어노테이션 방법이 구현된 소프트웨 어(380a)가 상주(loading)될 수 있다. 송수신기는 학습 데이터 생성 장치 와 데이터를 송수신할 수 있다. 입출력장치는 어노테이션 장치의 동작에 필요한 데이터를 입력 받고, 이미지를 출력할 수 있다. 데이터 버스는 프로세서, 메모리, 송수신기, 입출력장치 및 스토리지와 연결되어, 각각의 구성 요소 사이가 서로 데이터를 전달하기 위한 이동 통로의 역할을 수행할 수 있다. 스토리지는 어노테이션 방법이 구현된 소프트웨어(180a)의 실행을 위해 필요한 애플리케이션 프로그래밍 인터페이스(Application Programming Interface, API), 라이브러리(library) 파일, 리소스(resource) 파일 등 을 저장할 수 있다. 스토리지는 어노테이션 방법이 구현된 소프트웨어(380b)를 저장할 수 있다. 또한, 스 토리지는 어노테이션 방법의 수행에 필요한 정보들을 저장할 수 있다. 특히, 스토리지는 어노테이션 작업의 대상이 되는 이미지를 저장하는 데이터베이스를 포함할 수 있다. 본 발명의 일 실시예에 따르면, 메모리에 상주되거나 또는 스토리지에 저장된 어노테이션 방법을 구 현하기 위한 소프트웨어(380a, 380b)는 프로세서가 작업자의 제어에 따라, 인공지능(Artificial Intelligence, AI) 학습을 위한 어노테이션(annotation) 작업의 대상이 되는 이미지에 포함된 서로 중첩되어 배 치되는 복수의 객체 중 제1 객체의 외곽선을 지정하는 단계, 프로세서가, 제1 객체와 중첩되어 배치된 제2 객체 사이의 경계선을 지정하는 단계, 프로세서가, 경계선을 제2 객체의 외곽선의 일부로 설정하는 단계 및 프로세서가, 경계선을 기준으로 제2 객체의 외곽선을 지정하는 단계를 실행시키기 위하여, 기록매체에 기록된 컴퓨터 프로그램이 될 수 있다. 본 발명의 다른 실시예에 따르면, 메모리에 상주되거나 또는 스토리지에 저장된 어노테이션 방법을 구현하기 위한 소프트웨어(380a, 380b)는 프로세서가 작업자의 제어에 따라, 인공지능학습을 위한 어노테 이션 작업의 대상이 되는 이미지에 포함된 서로 중첩되어 배치되는 복수의 객체의 외곽선을 지정하는 단계, 프 로세서가, 지정된 외곽선 내에서 복수의 객체 사이의 경계선을 지정하는 단계 및 프로세서가, 지정된 경계선을 기준으로 구획된 복수의 영역을 기준으로 복수의 객체를 각각 식별하는 단계를 실행시키기 위하여, 기 록매체에 기록된 컴퓨터 프로그램이 될 수 있다. 보다 구체적으로, 프로세서는 ASIC(Application-Specific Integrated Circuit), 다른 칩셋(chipset), 논 리 회로 및/또는 데이터 처리 장치를 포함할 수 있다. 메모리는 ROM(Read-Only Memory), RAM(Random Access Memory), 플래쉬 메모리, 메모리 카드, 저장 매체 및/또는 다른 저장 장치를 포함할 수 있다. 송수신기 는 유무선 신호를 처리하기 위한 베이스밴드 회로를 포함할 수 있다. 입출력장치는 키보드 (keyboard), 마우스(mouse), 및/또는 조이스틱(joystick) 등과 같은 입력 장치 및 액정표시장치(Liquid Crystal Display, LCD), 유기 발광 다이오드(Organic LED, OLED) 및/또는 능동형 유기 발광 다이오드(Active Matrix OLED, AMOLED) 등과 같은 영상 출력 장치 프린터(printer), 플로터(plotter) 등과 같은 인쇄 장치를 포 함할 수 있다. 본 명세서에 포함된 실시 예가 소프트웨어로 구현될 경우, 상술한 방법은 상술한 기능을 수행하는 모듈(과정, 기능 등)로 구현될 수 있다. 모듈은 메모리에 상주되고, 프로세서에 의해 실행될 수 있다. 메모리 는 프로세서의 내부 또는 외부에 있을 수 있고, 잘 알려진 다양한 수단으로 프로세서와 연결될 수 있다. 도 5에 도시된 각 구성요소는 다양한 수단, 예를 들어, 하드웨어, 펌웨어(firmware), 소프트웨어 또는 그것들의 결합 등에 의해 구현될 수 있다. 하드웨어에 의한 구현의 경우, 본 발명의 일 실시예는 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 프로세서, 콘트롤러, 마이크로 콘트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 또한, 펌웨어나 소프트웨어에 의한 구현의 경우, 본 발명의 일 실시예는 이상에서 설명된 기능 또는 동작들을 수행하는 모듈, 절차, 함수 등의 형태로 구현되어, 다양한 컴퓨터 수단을 통하여 판독 가능한 기록매체에 기록 될 수 있다. 여기서, 기록매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함 할 수 있다. 기록매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 예컨대 기록매체는 하드 디스크, 플로피 디스 크 및 자기 테이프와 같은 자기 매체(Magnetic Media), CD-ROM(Compact Disk Read Only Memory), DVD(Digital Video Disk)와 같은 광 기록 매체(Optical Media), 플롭티컬 디스크(Floptical Disk)와 같은 자기-광 매체 (Magneto-Optical Media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치를 포함한다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 이러한, 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어로서 작동하도록 구 성될 수 있으며, 그 역도 마찬가지이다. 이하, 본 발명의 일 실시예에 따른 데이터 분류 방법을 설명하도록 한다. 도 6은 본 발명의 일 실시예에 따른 데이터 분류 방법을 설명하기 위한 순서도이다. 도 6을 참조하면, 먼저 S110 단계에서 학습 데이터 생성 장치는 적어도 하나의 학습 데이터 수집 장치에 이미지 수집을 요청할 수 있다. 다음으로, S120 단계에서 학습 데이터 생성 장치는 적어도 하나의 학습 데이터 수집 장치로부터 이미지들을 수 신할 수 있다. 다음으로, S130 단계에서 학습 데이터 생성 장치는 수신한 이미지들의 컬러 정보를 추출할 수 있다. 여기서, 컬 러 정보는 픽셀(pixel)에 대한 RGB(Red, Green, Blue) 값 또는 컬러 코드(color code) 값이 될 수 있다. 여기서, 학습 데이터 생성 장치는 적어도 하나의 학습 데이터 수집 장치 각각에 부여된 식별자(identifier)를 기준으로 이미지들의 파일명 및 컬러 정보를 저장할 수 있다. 다음으로, S140 단계에서 학습 데이터 생성 장치는 이미지들 사이의 컬러 정보를 기준으로 노이즈 이미지를 분 류할 수 있다. 즉, 학습 데이터 생성 장치는 이미지들 중 컬러 정보의 유사도가 사전 설정된 값보다 높은 이미 지들 중 적어도 하나를 노이즈 이미지로 분류할 수 있다. 구체적으로, 학습 데이터 생성 장치는 동일한 식별자에 동일한 파일명을 갖는 이미지가 복수개로 존재하는 경우, 동일한 파일명을 갖는 이미지 중 적어도 하나를 노이즈 이미지로 분류할 수 있다. 또한, 학습 데이터 생성 장치는 식별자가 상이하나 동일한 파일명이 복수개로 존재하는 경우, 동일한 파일명을 갖는 이미지 중 적어도 하나를 노이즈 이미지로 분류할 수 있다. 즉, 학습 데이터 생성 장치는 동일한 식별자에서 같은 이름의 파일이 중복되어 등록되거나, 다른 식별자로부터 동일한 파일이 중복되어 등록되는 경우를 사전 방지할 수 있다. 또한, 학습 데이터 생성 장치는 이미지들을 시간 순으로 나열하고, 나열된 이미지들을 사전 설정된 개수로 그룹 핑(grouping) 한 시퀀스 데이터를 생성하고, 시퀀스 데이터 별로 포함된 이미지들의 컬러 정보를 각각 비교하여 노이즈 이미지를 분류할 수 있다. 구체적으로, 학습 데이터 생성 장치는 생성된 시퀀스 데이터의 이미지들 각각에 포함된 객체의 엣지(edge)를 추 출할 수 있다. 학습 데이터 생성 장치는 시퀀스 데이터 별로 연속된 이미지 사이의 엣지 변화량을 기준으로 이 미지들의 유사도를 평가할 수 있다. 또한, 학습 데이터 생성 장치는 이미지들 중 유사도가 사전 설정된 값보다 높은 이미지들의 선명도(sharpness) 를 산출하고, 산출된 선명도가 가장 높은 이미지를 제외한 나머지 이미지를 노이즈 이미지로 분류할 수 있다. 또한, 학습 데이터 생성 장치는 시퀀스 데이터 별로 연속된 이미지 사이의 유사도를 산출하고, 산출된 유사도를 기준으로 시퀀스 데이터 별 초당 프레임 수(frame per second)를 결정할 수 있다. 그리고, S150 단계에서 학습 데이터 생성 장치는 S140 단계에서 분류된 노이즈 이미지를 리스트화 하여 출력하 거나, 노이즈 이미지로 분류된 이미지를 삭제할 수 있다. 이하, 본 발명의 다른 실시예에 따른 데이터 분류 방법을 설명하도록 한다. 도 7은 본 발명의 다른 실시예에 따른 데이터 분류 방법을 설명하기 위한 순서도이다. 도 7을 참조하면, 먼저, S210 단계에서 학습 데이터 생성 장치는 적어도 하나의 학습 데이터 수집 장치에 이미 지 수집을 요청할 수 있다. 이때, 학습 데이터 생성 장치는 수집 조건을 포함하는 가이드 정보를 적어도 하나의 학습 데이터 수집 장치에 전송할 수 있다. 다음으로, S220 단계에서 학습 데이터 생성 장치는 적어도 하나의 학습 데이터 수집 장치로부터 이미지들을 수 신할 수 있다. 다음으로, S230 단계에서 학습 데이터 생성 장치는 수집 조건과 대응하는 이미지 정보를 이미지들로부터 추출할 수 있다. 여기서, 이미지 정보는 파일 확장자, 이미지 해상도, 픽셀(pixel)에 대한 RGB(Red, Green, Blue) 값 및 컬러 코드(color code) 값 중 적어도 하나를 포함할 수 있다. 다음으로, S240 단계에서 학습 데이터 생성 장치는 추출한 이미지 정보를 가이드 정보와 비교하여, 수집 환경 또는 학습 데이터 수집 장치의 오류에 따른 노이즈 이미지를 분류할 수 있다. 구체적으로, 학습 데이터 생성 장치는 샘플 이미지의 파일 확장자, 이미지 해상도, 픽셀에 대한 RGB 값 및 컬러 코드 값 중 적어도 하나를 포함하는 샘플 이미지 정보를 추출하고, 추출된 샘플 이미지 정보를 이미지들로부터 추출된 이미지 정보와 비교할 수 있다. 이때, 학습 데이터 생성 장치는 샘플 이미지와 유사도가 사전 설정된 값 보다 낮은 이미지를 노이즈 이미지로 분류할 수 있다. 즉, 학습 데이터 생성 장치는 샘플 이미지와 파일 확장자 또는 이미지 해상도가 상이하거나, 픽셀(pixel)에 대한 RGB(Red, Green, Blue) 값 및 컬러 코드(color code) 값의 유사도가 사전 설정된 값보다 낮은 경우, 해당 이미지를 노이즈 이미지로 분류할 수 있다. 또한, 학습 데이터 생성 장치는 이미지들을 시간 순으로 나열하고, 나열된 이미지들을 사전 설정된 개수로 그룹 핑(grouping) 한 시퀀스 데이터를 생성하고, 시퀀스 데이터 별로 노이즈 이미지를 분류할 수 있다. 이때, 학습 데이터 생성 장치는 시퀀스 데이터 중 특정 이미지를 대상으로 전후 이미지의 유사도를 비교하고, 전후 이미지 사이의 유사도가 사전 설정된 값보다 높되, 전후 이미지와 상기 특정 이미지 사이의 유사도가 사전 설정된 값보다 낮은 경우, 특정 이미지를 노이즈 이미지로 판단할 수 있다. 또한, 학습 데이터 생성 장치는 이미지들 각각에 포함된 객체의 엣지(edge)를 추출하고, 이미지들 각각에 포함 된 객체를 검출하고, 검출된 객체의 위치 변화 값이 사전 설정된 값보다 높은 이미지를 노이즈 이미지로 분류할 수 있다. 즉, 학습 데이터 생성 장치는 이미지에 포함된 객체의 움직임의 정도를 통해 특정 이미지가 과속 방지 턱을 넘는 과정에서 촬영된 이미지인지를 판단할 수 있다. 또한, 학습 데이터 생성 장치는 적어도 하나의 학습 데이터 수집 장치로부터 이미지들 각각의 메타 정보를 함께 수신할 수 있다. 여기서, 메타 정보는 이미지들 각각의 촬영 시점에서 학습 데이터 수집 장치의 위치 정보 및 속도 정보를 포함할 수 있다. 학습 데이터 생성 장치는 학습 데이터 수집 장치가 이동한 경로를 포함하는 지도 정보에 포함된 과속 방지턱의 위치 정보를 기준으로 메타 정보와 비교하여, 과속 방지턱의 위치에서 촬영된 이미지를 노이즈 이미지로 분류할 수 있다. 또한, 학습 데이터 생성 장치는 학습 데이터 수집 장치가 이동한 경로를 포함하는 지도 정보에 포함된 커브 (curve)길의 위치 정보를 기준으로 메타 정보와 비교하여, 커브길의 위치에서 생성된 이미지를 노이즈 이미지로 분류할 수 있다. 또한, 학습 데이터 생성 장치는 시퀀스 데이터에서 연속된 이미지 사이의 유사도를 비교하고, 유사도가 사전에 설정된 값보다 낮은 이미지가 연속적으로 검출된 경우, 검출된 이미지들이 커브길에서 촬영된 이미지들로 판단 하고, 검출된 이미지들을 노이즈 이미지로 분류할 수 있다. 또한, 학습 데이터 생성 장치는 시퀀스 데이터 별 연속된 이미지의 유사도를 기초로 노이즈 이미지를 분류하고, 분류된 노이즈 이미지 각각의 오류 종류를 추정할 수 있다. 구제적으로, 학습 데이터 생성 장치는 시퀀스 데이터 중 연속된 이미지 사이의 유사도를 비교하고, 제1 이미지 와 연속된 제2 이미지 사이의 유사도가 사전 설정된 값보다 낮고, 제2 이미지와 연속된 제3 이미지와 제2 이미 지의 유사도가 사전 설정된 값보다 높은 경우, 시퀀스 데이터에 포함된 이미지를 촬영한 카메라의 카메라 앵글 (camera angle)이 변경된 오류로 판단할 수 있다. 또한, 학습 데이터 생성 장치는 시퀀스 데이터 중 연속된 이미지 사이의 유사도를 비교하고, 유사도가 사전에 설정된 값보다 낮은 이미지가 사전 설정된 개수를 초과하는 경우, 시퀀스 데이터에 포함된 이미지를 촬영한 카메라의 결속 불량에 따른 오류로 판단할 수 있다. 또한, 학습 데이터 생성 장치는 GPS(global positioning system) 좌표를 기초로 수신한 이미지들 및 사전 저장 된 이미지를 매칭하고, 매칭된 이미지 사이의 유사도를 비교하여, 노이즈 이미지를 분류할 수 있다. 또한, 학습 데이터 생성 장치는 각 이미지의 제1 변(side)을 구성하는 픽셀들과 제2 변을 구성하는 픽셀들 사이 의 RGB 값의 유사도를 기준으로 제1 변 및 제2 변으로부터 각각 하나의 정점(vertex)을 식별하고, 제1 변 및 상 기 제2 변으로부터 각각 식별된 두 정점을 연결한 선분을 추출할 수 있다. 학습 데이터 생성 장치는 매칭된 이미지 각각에서 추출된 선분의 길이 및 각도 중 적어도 하나를 기준으로 사전 설정된 오차 범위를 벗어나는 경우, 카메라 앵글이 변경된 오류로 판단할 수 있다. 하지만 이에 한정된 것은 아니고, 학습 데이터 생성 장치는 매칭된 이미지 각각에서 엣지(edge)를 추출하고, 추 출된 엣지를 기초로 매칭된 이미지 각각에 포함된 객체를 식별하고, 식별된 객체의 위치 변화 값을 기초로 노이 즈 이미지를 분류할 수 있다. 또한, 학습 데이터 생성 장치는 이미지들과 동시에 획득된 라이다(lidar)를 통해 획득된 3D 점군(3D points group) 데이터를 더 수신할 수 있다. 학습 데이터 생성 장치는 3D 점군 데이터에 포함된 거리 정보를 기초로 매 칭된 이미지 각각에 검출된 객체의 유형이 유동 객체 또는 정적 객체 인지 여부를 판단하고, 검출된 객체 중 정 적 객체의 위치 변화 값을 기초로 상기 노이즈 이미지를 분류할 수 있다. 그리고, S250 단계에서 학습 데이터 생성 장치는 분류된 노이즈 이미지를 리스트화 하여 출력하거나, 노이즈 이 미지로 분류된 이미지를 삭제할 수 있다. 이하, 본 발명의 일 실시예에 따른 작업 비용 예측 방법에 대하여 설명하도록 한다. 도 8는 본 발명의 일 실시예에 따른 작업 비용 예측 방법을 설명하기 위한 순서도이다. 도 8을 참조하면, S310 단계에서 학습 데이터 생성 장치는 인공지능 학습을 위하여 수행 예정인 어노테이션 작 업과 관련된 프로젝트를 수행하기 위한 적어도 하나의 샘플 데이터를 인공지능 학습 장치로부터 수신할 수 있다. 다음으로, S320 단계에서 학습 데이터 생성 장치는 기 수행된 복수의 프로젝트에 포함된 기존 데이터를 샘플 데 이터와 비교하고, 샘플 데이터와의 유사도가 사전 설정된 값보다 높은 기존 데이터가 포함된 적어도 하나의 프 로젝트를 추출할 수 있다. 이때, 학습 데이터 생성 장치는 기존 데이터를 대상으로, 기존 데이터를 구성하고 있는 하나 이상의 분해 구성 요소를 식별할 수 있다. 구체적으로, 샘플 데이터가 어노테이션 작업 대상이 되는 이미지에 해당되는 경우, 학습 데이터 생성 장치는 샘 플 데이터에 해당되는 이미지를 대상으로, 사용자의 제어에 따라 어노테이션 작업을 수행할 수 있다. 그리고, 학습 데이터 생성 장치는 어노테이션 작업에 의해 이미지로부터 특정된 객체의 클래스와, 객체를 특정하기 위하 여 사용된 툴을 샘플 데이터의 분해 구성요소로 식별할 수 있다 또한, 학습 데이터 생성 장치는 샘플 데이터와의 유사도가 사전 설정된 값보다 높은 기존 데이터가 포함된 적어 도 하나의 프로젝트를 추출할 수 있다. 이때, 학습 데이터 생성 장치는 인공지능 학습 장치로부터 샘플 이미지 의 분해 구성요소에 대한 가중치를 입력 받고, 입력 받은 가중치를 고려하여, 기존 이미지와의 유사도를 평가할 수 있다. 또한, 학습 데이터 생성 장치는 샘플 이미지의 엣지(edge)를 추출하고, 추출된 엣지를 기초로 샘플 데이터에 포 함된 객체를 검출하고, 객체의 RGB(Red, Green, Blue) 값을 기존 데이터에 포함된 객체의 RGB 값과 비교하여 유 사도를 평가할 수 있다. 또한, 학습 데이터 생성 장치는 기 수행된 복수의 프로젝트 별로 각각 사전 저장된 대표 이미지를 샘플 이미지 와 비교하고, 샘플 이미지와의 유사도가 사전 설정된 값보다 높은 복수의 대표 이미지를 인공지능 학습 장치에 전송하고, 인공지능 학습 장치로부터 복수의 대표 이미지 중 하나를 선택받을 수 있다. 이때, 학습 데이터 생성 장치는 샘플 이미지와의 유사도가 사전 설정된 값보다 높은 복수의 대표 이미지를 인공 지능 학습 장치에 전송하되, 대표 이미지에 포함된 객체를 식별하고, 식별된 객체의 클래스가 기밀 정보로 사전등록된 경우, 식별된 객체를 비식별(de-identify) 처리하여 인공지능 학습 장치에 전송할 수 있다. 그리고, S330 단계에서 학습 데이터 생성 장치는 추출된 적어도 하나의 프로젝트를 기초로 수행 예정인 어노테 이션 작업과 관련된 프로젝트를 수행하기 위하여 요구되는 전체 작업 비용을 예측할 수 있다. 이때, 학습 데이 터 생성 장치는 수행 예정인 어노테이션 작업과 관련된 프로젝트의 데이터 수량을 입력 받고, 추출된 프로젝트 의 비용 및 데이터 수량을 고려하여, 전체 작업 비용을 예측할 수 있다. 또한, 학습 데이터 생성 장치는 샘플 데이터와 유사도가 사전 설정된 값보다 높은 기존 데이터가 포함된 복수의 프로젝트를 추출하고, 추출된 복수의 프로젝트의 작업 비용 평균값을 수행 예정인 프로젝트의 전체 작업 비용으 로 예측할 수 있다. 그리고, 학습 데이터 생성 장치는 예측된 전체 작업 비용을 출력할 수 있다. 학습 데이터 생성 장치는 사용자의 제어에 따라, 전체 작업 비용을 수정할 수도 있다. 그리고, 학습 데이터 생성 장치는 예측 또는 수정된 전체 작 업 비용을 인공지능 학습 장치에 전송할 수 있다. 이하, 본 발명의 일 실시예에 따른 어노테이션 방법에 대하여 설명하도록 한다. 도 9는 본 발명의 일 실시예에 따른 어노테이션 방법을 설명하기 위한 순서도이고, 도 10 내지 도 16은 본 발명 의 일 실시예에 따른 어노테이션 방법을 설명하기 위한 예시도이다. 먼저, 도 10에 도시된 바와 같이, S410 단계에서 어노테이션 장치는 작업자의 제어에 따라, 인공지능(AI) 학습 을 위한 어노테이션(annotation) 작업의 대상이 되는 이미지에 포함된 서로 중첩되어 배치되는 복수의 객체(A, B) 중 제1 객체(A)의 외곽선을 지정할 수 있다. 이때, 도 11에 도시된 바와 같이, 어노테이션 장치는 작업자로부터 제1 객체(A)의 외곽선을 따라 복수의 점 (point)을 입력 받고, 복수의 점을 연결하여 제1 객체(A)의 외곽선을 형성할 수 있다. 즉, 어노테이션 장치는 작업자가 지정한 점을 연결하여 폴리곤(polygon) 형태의 영역을 생성할 수 있다. 다음으로, S420 단계에서 어노테이션 장치는 제1 객체(A)의 외곽선을 지정한 후에, 제1 객체(A)와 중첩되어 배 치된 제2 객체(A) 사이의 경계선(borderline)을 지정할 수 있다. 구체적으로, 어노테이션 장치는 제1 객체(A)의 외곽선을 따라 생성된 복수의 점 중 적어도 하나의 점을 선택받 고, 선택받은 적어도 하나의 점을 기초로 경계선을 지정할 수 있다. 이때, 사용자에게 경계선에 해당하는 모든 점을 입력받는 것이 아니고, 도 12에 도시된 바와 같이, 어노테이션 장치는 복수의 점 중 임의의 두개의 점을 선택받고, 도 13에 도시된 바와 같이, 선택받은 두개의 점 사이에 존 재하는 적어도 하나의 점을 연결하는 선을 생성하고, 생성된 선을 경계선으로 지정할 수 있다. 다음으로, 도 14에 도시된 바와 같이, S430 단계에서 어노테이션 장치는 경계선을 지정한 후에 경계선을 제2 객 체(B)의 외곽선의 일부로 설정할 수 있다. 이때, 어노테이션 장치는 경계선이 제1 객체(A)의 외곽선과 구분되도 록 출력할 수 있다. 다음으로, 도 15에 도시된 바와 같이, S440 단계에서 어노테이션 장치는 설정된 경계선을 기준으로 제2 객체 (B)의 외곽선을 지정할 수 있다. 이때, 어노테이션 장치는 작업자로부터 제2 객체(B)의 외곽선을 따라 복수의 점을 입력 받고, 경계선 및 복수의 점을 연결하여 제2 객체(B)의 외곽선을 형성할 수 있다. 또한, 어노테이션 장치는 이미지의 엣지를 추출하고, 추출된 엣지를 기초로 적어도 하나의 객체를 식별하고, 식 별된 적어도 하나의 객체 중 경계선을 포함하는 객체 중 제1 객체(A)를 제외한 나머지 객체의 엣지를 제2 객체 (B)의 외곽선으로 지정할 수 있다. 그리고, 도 16에 도시된 바와 같이, S450 단계에서 어노테이션 장치는 지정된 제1 객체(A) 및 제2 객체(B)를 각 각 식별할 수 있다. 이하, 본 발명의 다른 실시예에 따른 어노테이션 방법에 대하여 설명하도록 한다. 도 17은 본 발명의 다른 실시예에 따른 어노테이션 방법을 설명하기 위한 순서도이고, 도 18 내지 도 21은 본 발명의 다른 실시예에 따른 어노테이션 방법을 설명하기 위한 예시도이다. 먼저, 도 18에 도시된 바와 같이, S510 단계에서 어노테이션 장치는 인공지능(AI) 학습을 위한 어노테이션 작업 의 대상이 되는 이미지에 포함된 서로 중첩되어 배치되는 복수의 객체(A, B)의 외곽선을 지정할 수 있다. 이때, 복수의 객체의 외곽선은 경계선을 제외한 외곽선이 될 수 있다. 이때, 어노테이션 장치는 작업자로부터 복수의 객체를 포함하는 외곽선을 따라 복수의 점을 입력 받고, 복수의 점을 연결하여, 복수의 객체에 대한 외곽선을 생성할 수 있다. 또한, 어노테이션 장치는 이미지의 엣지(edge)를 추출하고, 추출된 엣지를 기초로 적어도 하나의 객체를 식별하 고, 작업자로부터 식별된 객체 중 복수의 객체를 선택받고, 추출된 엣지를 기초로 경계선을 제외한 선택받은 복 수의 객체에 대한 외곽선을 생성할 수 있다. 또한, 어노테이션 장치는 이미지와 동시에 라이다(lidar)로부터 획득된 점군 데이터를 기초로, 지정된 외곽선 내부에 존재하는 점들 중 거리(depth)가 일정 범위(range)를 갖는 복수의 점군을 식별하고, 작업자로부터 복수 의 점군 중 복수의 객체를 선택받고, 식별된 복수의 점군을 기초로 선택받은 복수의 객체에 대한 외곽선을 생성 할 수 있다. 그리고, 어노테이션 장치는 복수의 객체를 포함하는 일부 영역을 바운딩 박스(bounding box)로 설정하고, 바운 딩 박스 내측 영역에서 객체의 엣지를 추출하고, 추출된 엣지를 기준으로 객체(object)와 배경(background)을 구분하고, 배경을 삭제하여 복수의 객체의 외곽선을 지정할 수 있다. 다음으로, 도 19에 도시된 바와 같이, 어노테이션 장치는 지정된 외곽선 내에서 복수의 객체 사이의 경계선을 지정할 수 있다. 여기서, 어노테이션 장치는 S510 단계에서 추출된 엣지를 기초로 복수의 객체에 대한 외곽선 내에서 경계선을 식별할 수 있다. 또한, 어노테이션 장치는 작업자로부터 복수의 객체에 대한 외곽선 내부에 위치한 복수의 점을 입력 받고, 입력 받은 복수의 점을 연결하여 경계선을 생성할 수 있다. 또한, 어노테이션 장치는 이미지와 동시에 라이다로부터 획득된 점군 데이터를 기초로, 지정된 외곽선 내부에 존재하는 점들 중 거리가 일정 범위를 갖는 복수의 점군을 식별하고, 복수의 점군 사이의 경계선을 복수의 객체 사이의 경계선으로 지정할 수 있다. 또한, 어노테이션 장치는 지정된 외곽선 내부에 위치한 픽셀(pixel)의 RGB(Red, Green, Blue) 값을 기초로, 사 전 설정된 값보다 유사한 RGB 값을 갖는 그룹을 생성하고, 생성된 그룹을 각각 객체로 인식하고, 인식된 객체의 경계선을 생성할 수 있다. 또한, 어노테이션 장치는 이미지와 동시에 라이다로부터 획득된 점군 데이터를 기초로, 지정된 외곽선 내부에 존재하는 점들 중 거리가 일정 범위를 갖는 복수의 점군을 식별하고, 작업자로부터 복수의 점군 중 하나의 객체 를 선택받고, 선택받은 객체의 점군을 기초로 경계선을 생성할 수 있다. 그리고, 어노테이션 장치는 지정된 외곽선 내부의 엣지를 추출하고, 추출된 엣지를 기초로 적어도 하나의 객체 를 식별하고, 작업자로부터 식별된 객체 중 하나의 객체를 선택받고, 추출된 엣지를 기초로 경계선을 생성할 수 있다. 이때, 어노테이션 장치는 생성된 경계선을 따라 사전 설정된 간격을 갖는 복수의 점을 생성하고, 작업자 의 제어에 따라 복수의 점 중 적어도 하나의 점을 이동시켜 경계선을 수정할 수 있다. 그리고, 도 20에 도시된 바와 같이, 어노테이션 장치는 지정된 경계선을 기준으로 구획된 복수의 영역을 기준으 로 복수의 객체를 각각 식별할 수 있다. 도 21은 본 발명의 일 실시예에 따른 데이터 분류 방법을 설명하기 위한 예시도이다. 도 21을 참조하면, 학습 데이터 생성 장치는 이미지들을 시간 순으로 나열하고, 나열된 이미지들을 사전 설정된 개수로 그룹핑(grouping) 한 시퀀스 데이터(sequence data)를 생성하고, 시퀀스 데이터 별로 포함된 이미지들의 컬러 정보를 각각 비교하여 노이즈 이미지를 분류할 수 있다. 구체적으로, 학습 데이터 생성 장치는 연속하는 제1 이미지(image A) 및 제2 이미지(image B) 각각의 RGB 값에 대한 컬러 히스토그램을 생성하고, 생성된 컬러 히스토그램을 기준으로 제1 이미지(image A) 및 제2 이미지(image B)의 유사도를 판단할 수 있다. 학습 데이터 생성 장치는 제1 이미지(image A) 및 제2 이미지(image B)의 유사도가 사전 설정된 값보다 높은 경 우, 제1 이미지(image A) 및 제2 이미지(image B) 중 적어도 하나를 노이즈 이미지로 판단할 수 있다. 이때, 학습 데이터 생성 장치는 이미지들 중 유사도가 사전 설정된 값보다 높은 이미지들의 선명도(sharpness) 를 산출하고, 산출된 선명도가 가장 높은 이미지를 제외한 나머지 이미지를 노이즈 이미지로 분류할 수 있다. 즉, 제1 이미지(image A) 및 제2 이미지(image B)의 유사도가 높게 판단된 경우, 특정 기준을 통해 제1 이미지 (image A) 및 제2 이미지(image B) 중 하나를 제거해야 한다. 이를 위해, 학습 데이터 생성 장치는 선정된 제1 이미지(image A) 및 제2 이미지(image B) 중 선명도가 높은 이미지를 제외한 나머지 이미지를 노이즈 이미지로 분류하여 삭제할 수 있다. 도 22는 본 발명의 다른 실시예에 따른 데이터 분류 방법을 설명하기 위한 예시도이다. 도 22를 참조하면, 학습 데이터 생성 장치는 GPS(global positioning system) 좌표를 기초로 수신한 이미지들 및 사전 저장된 이미지를 매칭하고, 매칭된 이미지 사이의 유사도를 비교하여, 노이즈 이미지를 분류할 수 있다. 즉, (A)에 도시된 바와 같이, 학습 데이터 생성 장치는 사전 저장된 이미지의 제1 변을 구성하는 픽셀들과 제2 변을 구성하는 픽셀들 사이의 RGB 값의 유사도를 기준으로 제1 변 및 제2 변으로부터 각각 하나의 정점(point A, B)을 식별할 수 있다. 이때, 식별된 각각 하나의 정점은 정적 객체인 가이드 레일이 될 수 있다. 학습 데이터 생성 장치는 제1 변 및 제2 변으로부터 각각 식별된 두 정점(point A, B)을 연결한 선분(line A)을 추출할 수 있다. 그리고, (B)에 도시된 바와 같이, 학습 데이터 생성 장치는 사전 저장된 이미지와 동일한 위치에 존재하는 이미 지에서 제1 변을 구성하는 픽셀들과 제2 변을 구성하는 픽셀들 사이의 RGB 값의 유사도를 기준으로 제1 변 및 제2 변으로부터 각각 하나의 정점(point A, C)을 식별할 수 있다. 학습 데이터 생성 장치는 제1 변 및 제2 변으로부터 각각 식별된 두 정점(point A, C)을 연결한 선분(line B)을 추출할 수 있다. 그리고, 학습 데이터 생성 장치는 추출된 선분의 길이 및 각도 중 적어도 하나를 기준으로 사전 설정된 오차 범 위를 벗어나는 경우, 카메라 앵글이 변경된 오류로 판단할 수 있다. 도 23 및 도 24는 본 발명의 또 다른 실시예에 따른 어노테이션 방법을 설명하기 위한 예시도이다. 도 23 및 도 24를 참조하면, 본 발명의 또 다른 실시예에 따른 어노테이션 장치는 외곽선에 포함된 두 점과 작 업자의 제어에 따라 입력된 복수 개의 점(point)들을 연속적으로 연결하여 설정된 복수 개의 간선을 포함시켜 경계선(borderline)을 지정할 수 있다. 객체 사이의 경계선을 지정함에 있어서, 어노테이션 장치는 작업자로부터 입력된 복수 개의 점들을 연결하는 간 선을 기초로 객체 사이의 경계선을 지정하되, 객체의 엣지를 기초로 작업자로부터 지정된 경계선 사이의 점에 대한 보간(interpolation)을 수행할 수 있다. 구체적으로, 도 24에 도시된 바와 같이, 어노테이션 장치는 지정된 외곽선 내부에 위치한 픽셀(pixel)의 RGB(Red, Green, Blue) 값을 기초로 지정된 외곽선 내부에 위치한 객체의 엣지(edge)를 추출하고, 간선(line)의 중심점을 기준으로 간선과 수직한 가상선을 생성할 수 있다. 그리고, 어노테이션 장치는 생성된 가상선과 추출된 엣지가 교차하는 지점(c)으로부터 중심점 사이의 거리(x)가 사전 설정된 값보다 큰 간선에 포함된 점을 보간할 수 있다. 하지만, 이에 한정된 것은 아니고, 어노테이션 장치는 복수 개의 간선 각각의 길이가 사전 설정된 값을 초과하 는 간선에 포함된 점을 보간할 수도 있다. 즉, 어노테이션 장치는 간선의 길이를 기준으로, 길이가 사전 설정된 값보다 긴 간선에 대하여 보간이 필요한 간선으로 판단하고, 해당 간선에 포함된 점에 대한 보간을 수행할 수 있다.일 실시예로, 어노테이션 장치는 가상선과 추출된 엣지가 교차하는 지점(c)에 보간을 위한 신규 점을 추가할 수 있다. 또한, 어노테이션 장치는 사용자의 프로파일을 기초로 작업자로부터 입력된 점에 대한 보정을 수행할 수 있다. 여기서, 사용자의 프로파일은 작업자가 점을 입력하기 위한 입력 도구 및 입력 도구를 사용하기 위한 작업자의 주 사용손에 대한 정보를 포함할 수 있다. 구체적으로, 어노테이션 장치는 작업자의 프로파일을 획득하고, 획득된 프로파일을 기초로 복수 개의 점들을 입 력하기 위한 입력 도구 및 입력 도구를 사용하기 위한 주 사용손을 식별할 수 있다. 예를 들어, 어노테이션 장치는 해당 작업자가 입력 도구로 마우스(mouse)를 사용하고, 오른손을 주 사용손으로 사용하는 것으로 식별할 수 있다. 어노테이션 장치는 입력 도구 및 주 사용손에 따른 사전 저장된 보정 테이블로부터 식별된 입력 도구 및 주 사 용손에 대응되는 보정 값을 획득하고, 획득된 보정 값을 기초로 작업자로부터 입력된 복수 개의 점들을 일괄적 으로 보정할 수 있다. 예를 들어, 작업자가 마우스를 사용하고 오른손을 주 사용손으로 사용하는 경우, 해당 작업자에 의해 입력된 점 은 마우스의 버튼을 입력하는 과정에서 왼쪽 아래 방향으로 치우치는 경향을 보인다. 이에 따라, 어노테이션 장치는 프로파일에 따른 보정 테이블을 사전 저장하고, 식별된 프로파일에 따라 입력된 복수 개의 점들을 일괄적으로 보정할 수 있다. 또한, 어노테이션 장치는 작업자를 대상으로 누적 기록된 보정 히스토리를 기초로 작업자로부터 입력된 복수 개 의 점들을 일괄적으로 보정할 수 있다. 예를 들어, 어노테이션 장치는 프로파일에 따른 보정 테이블을 기초로 입력된 복수 개의 점들을 보정하되, 누적 기록된 보정 히스토리를 기초로 가중치를 부여하여 보정 강도를 조절할 수 있다. 그리고, 어노테이션 장치는 식별된 객체의 유형에 대응되는 3D 모델을 추출하여 작업자로부터 입력된 복수 개의 점을 검증할 수 있다. 구체적으로, 어노테이션 장치는 식별된 객체의 외곽선을 기초로 객체의 유형을 추정하고, 추정된 객체의 유형별 로 사전에 저장된 3D 모델을 추출할 수 있다. 예를 들어, 어노테이션 장치는 식별된 객체의 외곽선의 형태를 기초로 객체의 유형을 특정 자동차로 추정하고, 특정 자동차에 해당하는 3D 모델을 추출할 수 있다. 어노테이션 장치는 추출된 3D 모델을 3D 회전시켜 객체의 촬영 방향을 식별하고, 식별된 촬영 방향에 대응하여 사전에 설정된 객체 별 필수 구성요소를 식별할 수 있다. 예를 들어, 어노테이션 장치는 추출된 3D 모델을 3D 회전시키면서 식별된 객체와의 외곽선에 대한 유사도가 사 전 설정된 값보다 높은 시점을 객체의 촬영 방향으로 식별할 수 있으며, 식별된 객체가 자동차의 경우, 타이어, 본네트, 사이드 미러, 트렁크 등을 필수 구성요소로 식별할 수 있다. 이후, 어노테이션 장치는 식별된 객체의 폐쇄 영역 내에 필수 구성요소가 존재하는지 판단하여 작업자의 제어에 따라 입력된 점을 검증할 수 있다. 이때, 어노테이션 장치는 식별된 객체에 필수 구성요소가 존재하지 않는 경우, 해당 영역에 특정 기호를 표시하 여 해당 영역을 작업자가 직관적으로 인지하여 해당 영역에 입력된 점을 보정할 수 있도록 할 수 있다. 예를 들어, 어노테이션 장치는 3D 모델에서 식별된 필수 구성요소에 대한 외곽선을 인식된 객체에 이식하되 색 상 또는 굵기를 달리하여 표시할 수 있다. 도 25 및 도 26은 중첩된 복수 개의 객체의 외곽선을 설명하기 위한 예시도이다. 먼저, 도 25에 도시된 바와 같이, S510 단계에서 어노테이션 장치는 인공지능(AI) 학습을 위한 어노테이션 작업 의 대상이 되는 이미지에 포함된 서로 중첩되어 배치되는 복수 개의 객체의 외곽선을 지정할 수 있다. 이때, 복 수 개의 객체의 외곽선은 경계선(borderline)을 제외한 외곽선이 될 수 있다.이하에서는, 제1 객체(A), 제2 객체(B) 및 제3 객체(C)의 적어도 일부가 서로 중첩되어 배치된 것을 예로 설명 하기로 한다. 다음으로, 어노테이션 장치는 지정된 외곽선 내에서 제1 객체(A), 제2 객체(B) 및 제3 객체(C) 사이의 중첩된 경계선(borderline)을 지정할 수 있다. 도 25를 참조하여 구체적으로 설명하면, 어노테이션 작업의 대상이 되는 이미지에 서로 중첩된 제1 객체(A), 제 2 객체(B), 제3 객체(C)가 존재할 경우, S510 단계는 제1 객체(A), 제2 객체(B), 제3 객체(C)를 포함하는 굵은 선(외곽선)을 지정하고, S520 단계는 굵은 선 내에서 제1 객체(A), 제2 객체(B), 제3 객체(C)의 중첩된 얇은 선 (경계선, borderline)을 지정할 수 있다. 여기서, 얇은 선(경계선, borderline)은, 도 26에 도시된 바와 같이, 제1 객체(A)와 제3 객체(C)가 중첩되는 부 분의 쇄선 경계선(BL1), 제1 객체(A)와 제2 객체(B)가 중첩되는 부분의 실선 경계선(BL2), 제2 객체(B)와 제3 객체(C)가 중첩되는 부분의 점선 경계선(BL3)으로 지정될 수 있으며, 이와 같이 지정된 각 경계선(BL1, BL2, BL3) 중 하나는 적어도 두 개의 객체의(A,B,C) 외곽선으로 형성된다. 즉, 쇄선 경계선(BL1)은, 제1 객체(A)의 외관선을 형성하는 동시에 제3 객체(C)의 외곽선을 형성할 수 있고, 실 선 경계선(BL2)은, 제1 객체(A)의 외곽선을 형성하는 동시에 제2 객체(B)의 외곽선을 형성할 수 있으며, 점선 경계선(BL3)은, 제2 객체(B)의 외곽선을 형성하는 동시에 제3 객체(C)의 외곽선을 형성할 수 있다. 이를 통해, 본 발명은 폴리곤 기법으로 복수의 객체의 사이에 중첩된 경계선을 복수 개 생성(예, 제1 객체(A)와 제2 객체(B)의 경계선인 실선 경계선(BL2)를 각 객체의 외곽선으로 두 번 지정)했을 경우 두 번 지정된 실선 경 계선(BL2)이 일치하지 않는 문제점을 해결할 수 있다. 이상과 같이, 본 명세서와 도면에는 본 발명의 바람직한 실시예에 대하여 개시하였으나, 여기에 개시된 실시예 외에도 본 발명의 기술적 사상에 바탕을 둔 다른 변형 예들이 실시 가능하다는 것은 본 발명이 속하는 기술 분 야에서 통상의 지식을 가진 자에게 자명한 것이다. 또한, 본 명세서와 도면에서 특정 용어들이 사용되었으나, 이는 단지 본 발명의 기술 내용을 쉽게 설명하고 발명의 이해를 돕기 위한 일반적인 의미에서 사용된 것이지, 본 발명의 범위를 한정하고자 하는 것은 아니다. 따라서, 상술한 상세한 설명은 모든 면에서 제한적으로 해석되 어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적해석에 의해 선정 되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2023-0050696", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 인공지능 학습 시스템의 구성도이다. 도 2는 본 발명의 일 실시예에 따른 학습 데이터 생성 장치의 논리적 구성도이다. 도 3은 본 발명의 일 실시예에 따른 학습 데이터 생성 장치의 하드웨어 구성도이다. 도 4는 본 발명의 일 실시예에 따른 어노테이션 장치의 논리적 구성도이다. 도 5는 본 발명의 일 실시예에 따른 어노테이션 장치의 하드웨어 구성도이다. 도 6은 본 발명의 일 실시예에 따른 데이터 분류 방법을 설명하기 위한 순서도이다. 도 7은 본 발명의 다른 실시예에 따른 데이터 분류 방법을 설명하기 위한 순서도이다. 도 8는 본 발명의 일 실시예에 따른 작업 비용 예측 방법을 설명하기 위한 순서도이다. 도 9는 본 발명의 일 실시예에 따른 어노테이션 방법을 설명하기 위한 순서도이다. 도 10 내지 도 16은 본 발명의 일 실시예에 따른 어노테이션 방법을 설명하기 위한 예시도이다. 도 17은 본 발명의 다른 실시예에 따른 어노테이션 방법을 설명하기 위한 순서도이다. 도 18 내지 도 20은 본 발명의 다른 실시예에 따른 어노테이션 방법을 설명하기 위한 예시도이다. 도 21은 본 발명의 일 실시예에 따른 데이터 분류 방법을 설명하기 위한 예시도이다. 도 22는 본 발명의 다른 실시예에 따른 데이터 분류 방법을 설명하기 위한 예시도이다. 도 23 및 도 24는 본 발명의 또 다른 실시예에 따른 어노테이션 방법을 설명하기 위한 예시도이다. 도 25 및 도 26은 중첩된 복수 개의 객체의 외곽선을 설명하기 위한 예시도이다."}
