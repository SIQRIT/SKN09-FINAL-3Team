{"patent_id": "10-2024-0087404", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0008688", "출원번호": "10-2024-0087404", "발명의 명칭": "인공지능 학습 기반 사용자 맞춤형 감정 관리 장치 및 방법", "출원인": "이화여자대학교 산학협력단", "발명자": "안순태"}}
{"patent_id": "10-2024-0087404", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자로부터 입력된 텍스트 데이터 및 음성 데이터 그리고 상기 사용자로부터 인식되는 얼굴 표정 이미지 및행동 자세 이미지에 대한 이미지 데이터를 인공지능 학습 처리하여 사용자 감정을 인식하는 다중 감정 인식 처리부;상기 인식된 사용자 감정에 따라 복수의 시각적 요소 및 청각적 요소를 나타내는 아바타를 생성하고, 상기 인식된 사용자 감정의 변화를 모니터링하여 상기 복수의 시각적 요소 및 상기 청각적 요소가 변경되도록 상기 생성된 아바타를 업데이트하는 아바타 관리부; 및증강 현실 및 가상 현실 환경에서 상기 업데이트된 아바타를 통해 상기 사용자의 감정 관리를 위한 피드백을 제공하여 상기 감정 관리를 위한 상기 사용자와 상기 아바타 간의 상호 작용을 구현하는 감정 관리 처리부를 포함하는 것을 특징으로 하는 사용자 맞춤형 감정 관리 장치."}
{"patent_id": "10-2024-0087404", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 다중 감성 인식 처리부는 상기 텍스트 데이터를 구성하는 단어들 각각에 대하여 미리 구축된 기준 감정 지수에 기반하여 부정 감정 및 긍정 감정 중 어느 하나의 감정으로 상기 인공지능 학습을 처리하여 제1 분류 데이터를 생성하고, 상기 음성 데이터에 대하여 텍스트로 구성된 챗(chat) 데이터로 변환하고, 상기 챗 데이터를 구성하는 단어들 각각에 대하여 상기 미리 구축된 기준 감정 지수에 기반하여 부정 감정 및 긍정 감정 중 어느 하나의 감정으로 상기 인공지능 학습 처리하여 제2 분류 데이터를 생성하며, 상기 이미지 데이터에 대하여 표정및 자세에 따른 감정 구분 이미지에 기반하여 부정 감정 및 긍정 감정 중 어느 하나의 감정으로 상기 인공지능학습 처리하여 제3 분류 데이터를 생성하며, 상기 제1 분류 데이터 내지 상기 제3 분류 데이터를 융합하여 융합데이터를 생성하고, 상기 생성된 융합 데이터에 대하여 사용자 피드백을 적용하여 상기 사용자의 감정을 감정지수로 인식하는 것을 특징으로 하는 사용자 맞춤형 감정 관리 장치."}
{"patent_id": "10-2024-0087404", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 아바타 관리부는 상기 인식된 사용자 감정의 변화를 모니터링에 기반하여 실시간으로 상기 사용자의 감정이 부정 감정 및 긍정 감정 중 어느 하나의 감정을 나타내는 상기 감정 지수로 인식함에 따라 상기 복수의 시각적 요소를 구성하는 얼굴 표정, 신체 자세, 신체 행동 및 색상 중 적어도 하나를 변경하면서, 상기 청각적 요소를 부정 감정 및 긍정 감정 중 어느 하나와 관련된 소리 출력으로 변경하는 것을 특징으로 하는 사용자 맞춤형 감정 관리 장치."}
{"patent_id": "10-2024-0087404", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 감정 관리 처리부는 상기 증강 현실 및 가상 현실 환경에서 상기 업데이트된 아바타를 트래커 어플리케이션(tracker application) 기능, 위젯(widget) 기능 및 푸쉬 알림 기능 중 적어도 하나의 기능을 통해서 상기 사용자에게 제공하고, 상기 아바타를 통해 상기 부정 감정을 상기 긍정 감정으로 전환하기 위한 긍정 및 고무적사고를 증진 시키는 메시지와 관련하여 복수의 시각적 요소와 청각적 요소를 전달하는 것을 특징으로 하는 사용자 맞춤형 감정 관리 장치.공개특허 10-2025-0008688-3-청구항 5 제2항에 있어서,상기 감정 관리 처리부는 상기 증강 현실 및 가상 현실 환경에서 상기 부정 감정을 상기 긍정 감정으로 전환하기 위해 상기 아바타를 통해 포옹, 손잡기, 간지럽히기 중 적어도 하나의 감정적 터치 기능을 제공하면서 상기감정적 터치와 관련된 복수의 촉각 피드백을 제공하는 것을 특징으로 하는 사용자 맞춤형 감정 관리 장치."}
{"patent_id": "10-2024-0087404", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 다중 감정 인식 처리부는 상기 텍스트 데이터 및 상기 음성 데이터 중 어느 하나의 데이터에 기반하여 감정 측정용 단어를 분류하고, 상기 분류된 감정 측정용 단어에 대하여 기준 감정 지수에 따른 매칭 단어에 기반하여 상기 매칭 단어에 따른 매칭 감정 지수 점수를 결정하고, 상기 결정된 매칭 감정 지수에 기반하여 부정감정 지수 및 긍정 감정 지수 중 어느 하나의 감정 지수를 결정하는 것을 특징으로 하는 사용자 맞춤형 감정 관리 장치."}
{"patent_id": "10-2024-0087404", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "다중 감정 인식 처리부에서, 사용자로부터 입력된 텍스트 데이터 및 음성 데이터 그리고 상기 사용자로부터 인식되는 얼굴 표정 이미지 및 행동 자세 이미지에 대한 이미지 데이터를 인공지능 학습 처리하여 사용자 감정을인식하는 단계;아바타 관리부에서, 상기 인식된 사용자 감정에 따라 복수의 시각적 요소 및 청각적 요소를 나타내는 아바타를생성하고, 상기 인식된 사용자 감정의 변화를 모니터링하여 상기 복수의 시각적 요소 및 상기 청각적 요소가 변경되도록 상기 생성된 아바타를 업데이트하는 단계; 및감정 관리 처리부에서, 증강 현실 및 가상 현실 환경에서 상기 업데이트된 아바타를 통해 상기 사용자의 감정관리를 위한 피드백을 제공하여 상기 감정 관리를 위한 상기 사용자와 상기 아바타 간의 상호 작용을 구현하는단계를 포함하는 것을 특징으로 하는 사용자 맞춤형 감정 관리 방법."}
{"patent_id": "10-2024-0087404", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 사용자 감정을 인식하는 단계는, 상기 텍스트 데이터를 구성하는 단어들 각각에 대하여 미리 구축된 기준 감정 지수에 기반하여 부정 감정 및 긍정 감정 중 어느 하나의 감정으로 상기 인공지능 학습을 처리하여 제1 분류 데이터를 생성하고, 상기 음성 데이터에 대하여 텍스트로 구성된 챗(chat) 데이터로 변환하는 단계;상기 챗 데이터를 구성하는 단어들 각각에 대하여 상기 미리 구축된 기준 감정 지수에 기반하여 부정 감정 및긍정 감정 중 어느 하나의 감정으로 상기 인공지능 학습 처리하여 제2 분류 데이터를 생성하는 단계;상기 이미지 데이터에 대하여 표정 및 자세에 따른 감정 구분 이미지에 기반하여 부정 감정 및 긍정 감정 중 어느 하나의 감정으로 상기 인공지능 학습 처리하여 제3 분류 데이터를 생성하는 단계; 및 상기 제1 분류 데이터 내지 상기 제3 분류 데이터를 융합하여 융합 데이터를 생성하고, 상기 생성된 융합 데이터에 대하여 사용자 피드백을 적용하여 상기 사용자의 감정을 감정 지수로 인식하는 단계를 포함하는 것을 특징으로 하는 사용자 맞춤형 감정 관리 방법."}
{"patent_id": "10-2024-0087404", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,공개특허 10-2025-0008688-4-상기 인식된 사용자 감정의 변화를 모니터링하여 상기 복수의 시각적 요소 및 상기 청각적 요소가 변경되도록상기 생성된 아바타를 업데이트하는 단계는, 상기 인식된 사용자 감정의 변화를 모니터링에 기반하여 실시간으로 상기 사용자의 감정이 부정 감정 및 긍정감정 중 어느 하나의 감정을 나타내는 상기 감정 지수로 인식함에 따라 상기 복수의 시각적 요소를 구성하는 얼굴 표정, 신체 자세, 신체 행동 및 색상 중 적어도 하나를 변경하면서, 상기 청각적 요소를 부정 감정 및 긍정감정 중 어느 하나와 관련된 소리 출력으로 변경하는 단계를 포함하는 것을 특징으로 하는 사용자 맞춤형 감정 관리 방법."}
{"patent_id": "10-2024-0087404", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 증강 현실 및 가상 현실 환경에서 상기 업데이트된 아바타를 통해 상기 사용자의 감정 관리를 위한 피드백을 제공하여 상기 감정 관리를 위한 상기 사용자와 상기 아바타 간의 상호 작용을 구현하는 단계는, 상기 증강 현실 및 가상 현실 환경에서 상기 업데이트된 아바타를 트래커 어플리케이션(tracker application)기능, 위젯(widget) 기능 및 푸쉬 알림 기능 중 적어도 하나의 기능을 통해서 상기 사용자에게 제공하고, 상기아바타를 통해 상기 부정 감정을 상기 긍정 감정으로 전환하기 위한 긍정 및 고무적 사고를 증진 시키는 메시지와 관련하여 복수의 시각적 요소와 청각적 요소를 전달하는 단계를 포함하는 것을 특징으로 하는 사용자 맞춤형 감정 관리 방법."}
{"patent_id": "10-2024-0087404", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치 및 방법에 관한 것으로, 본 발명의 일실시예에 따 른 사용자 맞춤형 감정 관리 장치는 사용자로부터 입력된 텍스트 데이터 및 음성 데이터 그리고 상기 사용자로부 터 인식되는 얼굴 표정 이미지 및 행동 자세 이미지에 대한 이미지 데이터를 인공지능 학습 처리하여 사용자 감 정을 인식하는 다중 감정 인식 처리부, 상기 인식된 사용자 감정에 따라 복수의 시각적 요소 및 청각적 요소를 나타내는 아바타를 생성하고, 상기 인식된 사용자 감정의 변화를 모니터링하여 상기 복수의 시각적 요소 및 상기 청각적 요소가 변경되도록 상기 생성된 아바타를 업데이트하는 아바타 관리부 및 증강 현실 및 가상 현실 환경에 서 상기 업데이트된 아바타를 통해 상기 사용자의 감정 관리를 위한 피드백을 제공하여 상기 감정 관리를 위한 상기 사용자와 상기 아바타 간의 상호 작용을 구현하는 감정 관리 처리부를 포함할 수 있다."}
{"patent_id": "10-2024-0087404", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치 및 방법에 관한 것으로, 보다 구체적으로, 멀티모 달 기분 인식을 수행하여 사용자의 기분을 인식하고, 인식된 기분 인식을 반영한 아바타를 통해 사용자 맞춤형 상호 작용하여 사용자의 기분을 관리하는 기술에 관한 것이다."}
{"patent_id": "10-2024-0087404", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래 연구는 스마트폰 중독 등 역기능에 초점을 두었지만, 모바일이 일상화된 상황에서 순기능을 극대화하는 창 의적인 실용기술 개발이 시급하다. 또한, 모바일과 함께 하는 건강한 생태계 구축이 필요하다. 기존의 질병 및 치료 중심의 모바일 헬스 패러다임을 벗어나 예방 초점의 모바일 헬스 관점이 요청된다. 본 융합연구는 개인화되고 체화된(embodied) 모바일 기술과 사용자 빅데이터를 활용하여 사용자를 케어하는 맞 춤형 기분관리 장치 및 방법을 구축하여 기술 및 지식 제품이 연계될 수 있는 혁신적 및 실용적 접근이 필요하 다. 모바일을 활용한 정신건강 증진은 한국 문화적 상황과 코로나 19 여파로 큰 잠재력을 지닌 영역이다. 모바일 AI(artificial intelligence) 기술을 통한 기분 관리를 통해서 예방적 접근으로 맞춤형 건강 서비스 및 의료비 절감을 통한 사회 경제적인 효과를 제공하는 기술 개발이 필요하다. 실시간 다중 모달 피드백 및 인터랙티브 디자인을 활용하여 보다 몰입적이고, 개인화된 사용자 경험을 제공함으 로써 기존의 기분 인식 시스템과 차별화된다. 전통적인 기분 인식 시스템은 이러한 높은 수준의 상호작용이나 사용자 기분 변화에 맞춘 실시간 업데이트 제공 하지 않는다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 제10-2023-0151156호, \"화자별 음성 및 얼굴 영상에 동기되는 아바타 스피치 서 비스 제공 장치\" (특허문헌 0002) 한국등록특허 제10-2298070호, \"모바일 디바이스 기반 능동형 인공지능 영상 캐릭터 시스템\" (특허문헌 0003) 한국등록특허 제10-2233700호, \"전자 메시지들 내의 커스터마이즈된 아바타들의 생성 및 디스 플레이\""}
{"patent_id": "10-2024-0087404", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 멀티모달 기분 인식을 수행하여 사용자의 기 분을 인식하고, 인식된 기분 인식을 반영한 아바타를 통해 사용자 맞춤형 상호 작용하여 사용자의 기분 관리를 구현하는 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치 및 방법을 제공하는 것을 목적으로 한다. 본 발명은 모바일 인공지능 기술을 통해서 사용자의 기분을 관리하는 예방적 접근의 맞춤형 건강서비스로, 의료 비 절감을 통한 사회경제적 효과는 물론 모바일 기술을 활용하여 사용자의 정신건강을 증진시키는 기술을 구현 하는 것을 목적으로 한다. 본 발명은 사용자와의 상호작용으로 사용자 기분 변화에 맞춘 실시간 업데이트를 제공하고, 심리적 맥락의 통합 과 촉각 피드백을 통해 몰입형 상호작용을 제공하는 기술을 구현하는 것을 목적으로 한다."}
{"patent_id": "10-2024-0087404", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일실시예에 따른 사용자 맞춤형 감정 관리 장치는 사용자로부터 입력된 텍스트 데이터 및 음성 데이 터 그리고 상기 사용자로부터 인식되는 얼굴 표정 이미지 및 행동 자세 이미지에 대한 이미지 데이터를 인공지 능 학습 처리하여 사용자 감정을 인식하는 다중 감정 인식 처리부, 상기 인식된 사용자 감정에 따라 복수의 시 각적 요소 및 청각적 요소를 나타내는 아바타를 생성하고, 상기 인식된 사용자 감정의 변화를 모니터링하여 상 기 복수의 시각적 요소 및 상기 청각적 요소가 변경되도록 상기 생성된 아바타를 업데이트하는 아바타 관리부 및 증강 현실 및 가상 현실 환경에서 상기 업데이트된 아바타를 통해 상기 사용자의 감정 관리를 위한 피드백을 제공하여 상기 감정 관리를 위한 상기 사용자와 상기 아바타 간의 상호 작용을 구현하는 감정 관리 처리부를 포 함할 수 있다. 상기 다중 감성 인식 처리부는 상기 텍스트 데이터를 구성하는 단어들 각각에 대하여 미리 구축된 기준 감정 지 수에 기반하여 부정 감정 및 긍정 감정 중 어느 하나의 감정으로 상기 인공지능 학습을 처리하여 제1 분류 데이 터를 생성하고, 상기 음성 데이터에 대하여 텍스트로 구성된 챗(chat) 데이터로 변환하고, 상기 챗 데이터를 구 성하는 단어들 각각에 대하여 상기 미리 구축된 기준 감정 지수에 기반하여 부정 감정 및 긍정 감정 중 어느 하 나의 감정으로 상기 인공지능 학습 처리하여 제2 분류 데이터를 생성하며, 상기 이미지 데이터에 대하여 표정 및 자세에 따른 감정 구분 이미지에 기반하여 부정 감정 및 긍정 감정 중 어느 하나의 감정으로 상기 인공지능 학습 처리하여 제3 분류 데이터를 생성하며, 상기 제1 분류 데이터 내지 상기 제3 분류 데이터를 융합하여 융합 데이터를 생성하고, 상기 생성된 융합 데이터에 대하여 사용자 피드백을 적용하여 상기 사용자의 감정을 감정 지수로 인식할 수 있다. 상기 아바타 관리부는 상기 인식된 사용자 감정의 변화를 모니터링에 기반하여 실시간으로 상기 사용자의 감정 이 부정 감정 및 긍정 감정 중 어느 하나의 감정을 나타내는 상기 감정 지수로 인식함에 따라 상기 복수의 시각 적 요소를 구성하는 얼굴 표정, 신체 자세, 신체 행동 및 색상 중 적어도 하나를 변경하면서, 상기 청각적 요소 를 부정 감정 및 긍정 감정 중 어느 하나와 관련된 소리 출력으로 변경할 수 있다. 상기 감정 관리 처리부는 상기 증강 현실 및 가상 현실 환경에서 상기 업데이트된 아바타를 트래커 어플리케이 션(tracker application) 기능, 위젯(widget) 기능 및 푸쉬 알림 기능 중 적어도 하나의 기능을 통해서 상기 사 용자에게 제공하고, 상기 아바타를 통해 상기 부정 감정을 상기 긍정 감정으로 전환하기 위한 긍정 및 고무적 사고를 증진 시키는 메시지와 관련하여 복수의 시각적 요소와 청각적 요소를 전달할 수 있다. 상기 감정 관리 처리부는 상기 증강 현실 및 가상 현실 환경에서 상기 부정 감정을 상기 긍정 감정으로 전환하 기 위해 상기 아바타를 통해 포옹, 손잡기, 간지럽히기 중 적어도 하나의 감정적 터치 기능을 제공하면서 상기 감정적 터치와 관련된 복수의 촉각 피드백을 제공할 수 있다. 상기 다중 감정 인식 처리부는 상기 텍스트 데이터 및 상기 음성 데이터 중 어느 하나의 데이터에 기반하여 감 정 측정용 단어를 분류하고, 상기 분류된 감정 측정용 단어에 대하여 기준 감정 지수에 따른 매칭 단어에 기반 하여 상기 매칭 단어에 따른 매칭 감정 지수 점수를 결정하고, 상기 결정된 매칭 감정 지수에 기반하여 부정 감정 지수 및 긍정 감정 지수 중 어느 하나의 감정 지수를 결정할 수 있다. 본 발명의 일실시예에 따른 사용자 맞춤형 감정 관리 방법은 다중 감정 인식 처리부에서, 사용자로부터 입력된 텍스트 데이터 및 음성 데이터 그리고 상기 사용자로부터 인식되는 얼굴 표정 이미지 및 행동 자세 이미지에 대 한 이미지 데이터를 인공지능 학습 처리하여 사용자 감정을 인식하는 단계, 아바타 관리부에서, 상기 인식된 사 용자 감정에 따라 복수의 시각적 요소 및 청각적 요소를 나타내는 아바타를 생성하고, 상기 인식된 사용자 감정 의 변화를 모니터링하여 상기 복수의 시각적 요소 및 상기 청각적 요소가 변경되도록 상기 생성된 아바타를 업 데이트하는 단계 및 감정 관리 처리부에서, 증강 현실 및 가상 현실 환경에서 상기 업데이트된 아바타를 통해 상기 사용자의 감정 관리를 위한 피드백을 제공하여 상기 감정 관리를 위한 상기 사용자와 상기 아바타 간의 상 호 작용을 구현하는 단계를 포함할 수 있다. 상기 사용자 감정을 인식하는 단계는, 상기 텍스트 데이터를 구성하는 단어들 각각에 대하여 미리 구축된 기준 감정 지수에 기반하여 부정 감정 및 긍정 감정 중 어느 하나의 감정으로 상기 인공지능 학습을 처리하여 제1 분 류 데이터를 생성하고, 상기 음성 데이터에 대하여 텍스트로 구성된 챗(chat) 데이터로 변환하는 단계, 상기 챗 데이터를 구성하는 단어들 각각에 대하여 상기 미리 구축된 기준 감정 지수에 기반하여 부정 감정 및 긍정 감정 중 어느 하나의 감정으로 상기 인공지능 학습 처리하여 제2 분류 데이터를 생성하는 단계 상기 이미지 데이터에 대하여 표정 및 자세에 따른 감정 구분 이미지에 기반하여 부정 감정 및 긍정 감정 중 어느 하나의 감정으로 상 기 인공지능 학습 처리하여 제3 분류 데이터를 생성하는 단계 및 상기 제1 분류 데이터 내지 상기 제3 분류 데 이터를 융합하여 융합 데이터를 생성하고, 상기 생성된 융합 데이터에 대하여 사용자 피드백을 적용하여 상기 사용자의 감정을 감정 지수로 인식하는 단계를 포함할 수 있다. 상기 인식된 사용자 감정의 변화를 모니터링하여 상기 복수의 시각적 요소 및 상기 청각적 요소가 변경되도록 상기 생성된 아바타를 업데이트하는 단계는, 상기 인식된 사용자 감정의 변화를 모니터링에 기반하여 실시간으 로 상기 사용자의 감정이 부정 감정 및 긍정 감정 중 어느 하나의 감정을 나타내는 상기 감정 지수로 인식함에 따라 상기 복수의 시각적 요소를 구성하는 얼굴 표정, 신체 자세, 신체 행동 및 색상 중 적어도 하나를 변경하 면서, 상기 청각적 요소를 부정 감정 및 긍정 감정 중 어느 하나와 관련된 소리 출력으로 변경하는 단계를 포함 할 수 있다. 상기 증강 현실 및 가상 현실 환경에서 상기 업데이트된 아바타를 통해 상기 사용자의 감정 관리를 위한 피드백 을 제공하여 상기 감정 관리를 위한 상기 사용자와 상기 아바타 간의 상호 작용을 구현하는 단계는, 상기 증강 현실 및 가상 현실 환경에서 상기 업데이트된 아바타를 트래커 어플리케이션(tracker application) 기능, 위젯 (widget) 기능 및 푸쉬 알림 기능 중 적어도 하나의 기능을 통해서 상기 사용자에게 제공하고, 상기 아바타를 통해 상기 부정 감정을 상기 긍정 감정으로 전환하기 위한 긍정 및 고무적 사고를 증진 시키는 메시지와 관련하 여 복수의 시각적 요소와 청각적 요소를 전달하는 단계를 포함할 수 있다."}
{"patent_id": "10-2024-0087404", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 멀티모달 기분 인식을 수행하여 사용자의 기분을 인식하고, 인식된 기분 인식을 반영한 아바타를 통 해 사용자 맞춤형 상호 작용하여 사용자의 기분 관리를 구현하는 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치 및 방법을 제공할 수 있다. 본 발명은 모바일 인공지능 기술을 통해서 사용자의 기분을 관리하는 예방적 접근의 맞춤형 건강서비스로, 의료 비 절감을 통한 사회경제적 효과는 물론 모바일 기술을 활용하여 사용자의 정신건강을 증진시키는 기술을 구현 할 수 있다. 본 발명은 사용자와의 상호작용으로 사용자 기분 변화에 맞춘 실시간 업데이트를 제공하고, 심리적 맥락의 통합 과 촉각 피드백을 통해 몰입형 상호작용을 제공하는 기술을 구현할 수 있다."}
{"patent_id": "10-2024-0087404", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 문서의 다양한 실시 예들이 첨부된 도면을 참조하여 기재된다. 실시 예 및 이에 사용된 용어들은 본 문서에 기재된 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 해당 실시 예의 다양한 변경, 균등물, 및/또는 대체물을 포함하는 것으로 이해되어야 한다. 하기에서 다양한 실시 예들을 설명에 있어 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 다양한 실시 예들에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 본 문서에서, \"A 또는 B\" 또는 \"A 및/또는 B 중 적어도 하나\" 등의 표현은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\" 등의 표현들은 해당 구성요소들을, 순서 또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤(예: 제1) 구성요소가 다른(예: 제2) 구성요소에 \"(기능적으로 또는 통신적으로) 연결되어\" 있다거나 \"접속 되어\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요 소(예: 제3 구성요소)를 통하여 연결될 수 있다. 본 명세서에서, \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, 하드웨어적 또는 소 프트웨어적으로 \"~에 적합한,\" \"~하는 능력을 가지는,\" \"~하도록 변경된,\" \"~하도록 만들어진,\" \"~를 할 수 있 는,\" 또는 \"~하도록 설계된\"과 상호 호환적으로(interchangeably) 사용될 수 있다. 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으 로써, 해당 동작들을 수행할 수 있는 범용 프로세서(예: CPU 또는 application processor)를 의미할 수 있다. 또한, '또는' 이라는 용어는 배타적 논리합 'exclusive or' 이기보다는 포함적인 논리합 'inclusive or' 를 의 미한다. 즉, 달리 언급되지 않는 한 또는 문맥으로부터 명확하지 않는 한, 'x가 a 또는 b를 이용한다' 라는 표현은 포함 적인 자연 순열들(natural inclusive permutations) 중 어느 하나를 의미한다. 이하 사용되는 '..부', '..기' 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하 드웨어나 소프트웨어, 또는, 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 도 1은 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치를 설명하는 도면이다. 도 1은 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치의 구성 요소를 예시한다. 도 1을 참고하면, 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치는 다중 감정 인식 처리부, 아바타 관리부 및 감정 관리 기능 처리부를 포함한다. 일례로, 다중 감정 인식 처리부는 사용자로부터 입력된 텍스트 데이터 및 음성 데이터 그리고 사용자로부 터 인식되는 얼굴 표정 이미지 및 행동 자세 이미지에 대한 이미지 데이터를 인공지능 학습 처리하여 사용자 감 정을 인식할 수 있다. 다중 감성 인식 처리부는 텍스트 데이터를 구성하는 단어들 각각에 대하여 미리 구축된 기준 감정 지수에 기반하여 부정 감정 및 긍정 감정 중 어느 하나의 감정으로 인공지능 학습을 처리하여 제1 분류 데이터를 생성 한다. 또한, 다중 감성 인식 처리부는 음성 데이터에 대하여 텍스트로 구성된 챗(chat) 데이터로 변환하고, 챗 데이터를 구성하는 단어들 각각에 대하여 미리 구축된 기준 감정 지수에 기반하여 부정 감정 및 긍정 감정 중 어느 하나의 감정으로 인공지능 학습 처리하여 제2 분류 데이터를 생성할 수 있다. 또한, 다중 감성 인식 처리부는 이미지 데이터에 대하여 표정 및 자세에 따른 감정 구분 이미지에 기반하 여 부정 감정 및 긍정 감정 중 어느 하나의 감정으로 인공지능 학습 처리하여 제3 분류 데이터를 생성한다. 또한, 다중 감성 인식 처리부는 제1 분류 데이터 내지 제3 분류 데이터를 융합하여 융합 데이터를 생성하 고, 생성된 융합 데이터에 대하여 사용자 피드백을 적용하여 사용자의 감정을 감정 지수로 인식할 수 있다. 다중 감정 인식 처리부는 텍스트 데이터 및 음성 데이터 중 어느 하나의 데이터에 기반하여 감정 측정용 단어를 분류하고, 분류된 감정 측정용 단어에 대하여 기준 감정 지수에 따른 매칭 단어에 기반하여 매칭 단어에 따른 매칭 감정 지수 점수를 결정하고, 결정된 매칭 감정 지수에 기반하여 부정 감정 지수 및 긍정 감정 지수 중 어느 하나의 감정 지수를 결정할 수 있다. 아바타 관리부는 다중 감정 인식 처리부에서 인식된 사용자 감정에 따라 복수의 시각적 요소 및 청각 적 요소를 나타내는 아바타를 생성하고, 인식된 사용자 감정의 변화를 모니터링하여 복수의 시각적 요소 및 청 각적 요소가 변경되도록 생성된 아바타를 업데이트할 수 있다. 아바타 관리부는 상기 인식된 사용자 감정의 변화를 모니터링에 기반하여 실시간으로 상기 사용자의 감정 이 부정 감정 및 긍정 감정 중 어느 하나의 감정을 나타내는 상기 감정 지수로 인식함에 따라 상기 복수의 시각적 요소를 구성하는 얼굴 표정, 신체 자세, 신체 행동 및 색상 중 적어도 하나를 변경하면서, 상기 청각적 요소 를 부정 감정 및 긍정 감정 중 어느 하나와 관련된 소리 출력으로 변경할 수 있다. 감정 관리 처리부는 증강 현실 및 가상 현실 환경에서 업데이트된 아바타를 통해 사용자의 감정 관리를 위 한 피드백을 제공하여 감정 관리를 위한 사용자와 아바타 간의 상호 작용을 구현할 수 있다. 감정 관리 처리부는 증강 현실 및 가상 현실 환경에서 업데이트된 아바타를 트래커 어플리케이션(tracker application) 기능, 위젯(widget) 기능 및 푸쉬 알림 기능 중 적어도 하나의 기능을 통해서 사용자에게 제공하 고, 아바타를 통해 부정 감정을 긍정 감정으로 전환하기 위한 긍정 및 고무적 사고를 증진 시키는 메시지와 관 련하여 복수의 시각적 요소와 청각적 요소를 전달할 수 있다. 감정 관리 처리부는 증강 현실 및 가상 현실 환경에서 부정 감정을 긍정 감정으로 전환하기 위해 아바타를 통해 포옹, 손잡기, 간지럽히기 중 적어도 하나의 감정적 터치 기능을 제공하면서 감정적 터치와 관련된 복수의 촉각 피드백을 제공할 수 있다. 따라서, 본 발명은 멀티모달 기분 인식을 수행하여 사용자의 기분을 인식하고, 인식된 기분 인식을 반영한 아바 타를 통해 사용자 맞춤형 상호 작용하여 사용자의 기분 관리를 구현하는 인공지능 학습 기반 사용자 맞춤형 감 정 관리 장치 및 방법을 제공할 수 있다. 도 2는 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치에서의 다중 감정 인식 처 리부를 설명하는 도면이다. 도 2는 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치에서의 다중 감정 인식 처 리부의 다중 감정 인식 처리 구성을 예시한다. 도 2를 참고하면, 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치에서의 다중 감 정 인식 처리부는 텍스트 데이터 학습부, 음성 데이터 학습부, 이미지 데이터 학습부, 융 합 학습부 및 감정 인식부를 포함한다. 텍스트 데이터 학습부는 텍스트 데이터를 전처리하여 텍스트 피쳐를 추출하고, 추출된 텍스트 피쳐를 인공 지능 학습하여 학습 결과로 제1 분류 데이터를 출력한다. 음성 데이터 학습부는 음성 데이터를 전처리하여 음성 피쳐를 추출하고, 추출된 음성 피쳐를 인공지능 학 습하여 학습 결과로 제2 분류 데이터를 출력한다. 텍스트 데이터 학습부는 텍스트를 학습하여 감정 인식 결과를 분류할 수 있고, 음성 데이터 학습부는 음성을 텍스트로 변환하여 텍스트를 학습하거나 음성 데이터를 반복적으로 학습하여 감정 인식 결과를 분류할 수 있다. 텍스트 데이터 학습부 및 음성 데이터 학습부 감정 카테고리별로 분류된 감정 측정용 단어가 그룹화 된 데이터를 이용하여 감정과 관련하여 세밀하게 분류할 수 있다. 텍스트 데이터 학습부 및 음성 데이터 학습부는 포괄하여 감정 학습부로 지칭할 수 있다. 아래 표 1은 부정적인 감정과 관련하여 단어를 분류한 결과에 대하여 예시한다. [표 1]"}
{"patent_id": "10-2024-0087404", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "감정 학습부는 부정적인 감정과 관련하여 단어를 분류한 결과의 예시와 같이 긍정적인 감정과 관련하여 단어를 분류할 수 있다. 아래 표 2는 단어별 심각도를 산출하기 위해서 사용되는 측정 문항을 예시한다. [표 2]"}
{"patent_id": "10-2024-0087404", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "감정 학습부는 감정 측정용 단어가 분노 카테고리에 포함되는 경우에는 느낌의 강도, 민감성 및 압도 및 지배감 항목별로 평균 점수를 산출할 수 있다. 감정 학습부는 온라인 또는 오프라인을 통해 설문 조사에 참여하는 복수의 참가자들을 대상으로 네 가지의 기분 카테고리 중 하나의 카테고리에 포함되는 단어 목록을 제시하고, 참가자로부터 제시된 기분 측정용 단어에 대한 느낌을 평가받은 결과를 수신할 수 있다. 이때 참가자들은 기분 측정용 단어에 대한 느낌을 5점 Likert 척도(0 점: 전혀 그렇지 않다, 4점: 매우 그렇다)로 측정한 결과에 대하여 데이터를 활용하여 학습하고, 감정에 대한 학습 결과를 도출 및 제시할 수 있다. 감정 학습부는 각 기분 카테고리별로 심각도를 산출함에 있어 참가자들에 의해 측정된 모든 항목별 점수를 각각 합산한 후 항목별 평균 점수를 산출하고, 산출된 항목별 평균 점수를 합산함으로써 해당 기분 측정용 단어에 대 한 심각도를 기분 측정용 단어별로 산출할 수 있다. 예를 들면, 분노 카테고리에 포함되는 기분 측정용 단어 중 \"열 받는다\"의 심각도는 느낌의 강도인 제1 항목의 평균 점수, 압도감에 해당하는 제2 항목의 평균 점수 및 민감성에 해당하는 제3 항목의 평균 점수의 합산으로 산출될 수 있다. 이와 마찬가지로 슬픔 카테고리에 포함되는 기분 측정용 단어 중 \"멍하다\"의 심각도는 느낌의 강도인 제1 항목의 평균 점수, 피로도에 해당하는 제3 항목의 평균 점수 및 압도감에 해당하는 제2 항목의 평균 점수의 합으로 산출될 수 있다. 또한, 자괴감 카테고리에 포함되는 기분 측정용 단어 중 \"접고싶다\"의 심각도는 느낌의 강도인 제1 항목의 평균 점수, 무력감에 해당하는 제3 항목의 평균 점수 및 압도감에 해당하는 제2 항목의 평균 점수의 합으로 산출될 수 있다. 또한, 불안 카테고리에 포함되는 기분 측정용 단어 중 \"초조하다\"의 심각도는 느낌의 강도인 제1 항목의 평균 점수, 불안정성에 해당하는 제3 항목의 평균 점수 및 압도감에 해당하는 제2 항목의 평균 점수의 합으로 산출될 수 있다. 이렇게 단어별 항목의 평균값을 이용해 심각도를 산출한 후 기분 카테고리별로 생성된 일정 개수(예를 들어 20 개)의 단어를 심각도에 따라 일정 개수(예를 들어 4개)의 그룹으로 분류하여 그룹화할 수 있으며, 이러한 과정 을 통해 그룹화된 기분 측정용 단어는 표 3과 같이 정리할 수 있다. [표 3]"}
{"patent_id": "10-2024-0087404", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "기분 측정용 단어에 대한 기분의 정도를 측정할 수 있는 기준으로써 기분 카테고리마다 사전에 설정된 복수의 항목별로 평균 점수를 산출한 후 각각의 평균 점수를 합산하여 최종적으로 기분 측정용 단어별로 심각도를 산출 할 수 있다. 그룹화를 위해 사전에 설정되는 복수의 항목은 각각의 카테고리마다 제1 항목, 제2 항목 및 제3 항목으로 나뉠 수 있다. 여기서 제1 항목은 느낌의 강도를 측정하기 위한 항목으로 해당 기분 측정용 단어가 강렬한 느낌을 주는지, 느 낌의 강도가 센지 약한지를 측정하기 위한 항목이다. 제2 항목은 압도 및 지배감의 정도를 측정하기 위한 항목으로 해당 기분 측정용 단어가 통제가 안되는 느낌에 해당하는 단어인지, 해당 기분 측정용 단어가 주는 느낌이 본인을 지배하는 느낌인지를 측정하기 위한 항목이다. 이러한 느낌의 강도 측정을 위한 제1 항목 및 압도 및 지배감의 정도를 측정하는 제2 항목은 모든 기분 카테고 리에 적용될 수 있다. 한편 제3 항목은 기분 카테고리마다 다르게 부여되는데, 제3 항목은 기분 카테고리가 분노 카테고리인 경우에는 해당 기분 측정용 단어로부터 느끼는 민감성을 측정하기 위한 항목이다. 슬픔 카테고리인 경우에는 해당 기분 측정용 단어로부터 느끼는 피로도 및 동기저하의 정도를 측정하기 위한 항 목이며, 자괴감 카테고리인 경우에는 해당 기분 측정용 단어로부터 느끼는 무가치 및 무력감의 정도를 측정하기 위한 항목이고, 그리고 불안 카테고리인 경우에는 해당 기분 측정용 단어로부터 느끼는 불안정성의 정도를 측정 하기 위한 항목일 수 있다. 본 발명의 일실시예에 따른 감정 학습부는 심각도가 낮은 순서대로 그룹화할 수 있고, 심각도가 가장 낮은 그룹 1에 해당하는 단어를 표 4와 같이 1점으로 심각도가 가장 높은 그룹은 그룹 4에 해당하는 4점이 매칭되도록 할 수 있다. 또한, 감정 학습부는 표 4와 같이 기분지수를 산출 할 수 있다. 본 발명의 일 실시예에 따른 감정 학습부는 분노 지수, 슬픔 지수, 자괴감 지수, 불안 지수 및 일상적 부정 기 분 지수를 포함하는 총 5가지의 지수를 산출할 수 있다. 여기서 일상적 부정 기분 지수는 분노 지수, 슬픔 지수, 자괴감 지수 및 불안 지수를 합산한 지수일 수 있다. 감정 학습부는 기분 카테고리별 3개의 단어를 선택하는 경우에는 세부 지수인 분노 지수, 슬픔 지수, 자괴감 지 수 및 불안 지수는 각각 최소 3점에서 최대 12점까지 산출할 수 있으며, 일상적 부정 기분 지수는 최소 12점에 서 최대 45점까지 산출할 수 있다. 또한, 감정 학습부는 이러한 일상적 부정 기분 지수를 구간별로 분류하여 12점에서 20점 구간은 레벨 1로 Mildew 단계, 24점에서 36점 구간은 레벨 2로 Moderate 단계, 그리고 40점에서 48점 구간은 레벨 3으로 Severe 단계로 사용자의 일상 기분을 예측할 수 있다. [표 4]"}
{"patent_id": "10-2024-0087404", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이미지 데이터 학습부는 이미지 데이터를 전처리하여 이미지 피쳐를 추출하고, 추출된 이미지 피쳐를 인공 지능 학습하여 학습 결과로 제3 분류 데이터를 출력한다. 융합 학습부는 제1 분류 데이터 내지 제3 분류 데이터를 융합하여 다중 감정 인식 분류 데이터를 추출하여 출력한다. 감정 인식부는 다중 감정 인식 분류 데이터를 확인하여 감정을 부정 감정 또는 긍정 감정 중 어느 하나로 분류하고, 사용자로부터 분류된 감정에 대하여 피드백을 받아서 피드백 결과에 따라서 감정 인식 결과를 출력한 다. 다중 감정 인식 처리부는 음성, 얼굴 표정, 신체 자세와 같이 다양한 입력을 통합하여 사용자의 감정(기분)을 인식한다. 도 3은 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치에서의 아바타 관리부를 설명하는 도면이다. 도 3은 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치에서의 아바타 관리부의 구성에 따라 아바타를 관리하는 구성을 예시한다. 도 3을 참고하면, 본 발명의 일실시예에 따른 아바타 관리부는 감정 맵핑 처리부, 디스플레이 처리부 및 실시간 업데이트 처리부를 포함한다. 일례로, 아바타 관리부는 사용자의 기분에 따라 실시간으로 변화하는 디지털 아바타를 설정한다. 아바타는 다양한 감정과 각성 수분을 표현할 수 있고, 얼굴 표정, 신체 자세 및 색상 등과 같이 시각 요소를 실 시간으로 변화한다. 본 발명은 기존 기술에서 실시간 반응형 아바타를 제공하지 않는 제한 범위에 대하여 해소하는 기술을 구현한다. 감정 맵핑 처리부는 사용자의 감정(기분) 지수를 아바타의 외관을 실시간으로 연동한다. 예를 들어, 긍정적인 기분 지수는 웃는 아바타와 밝은 색상으로 표현하고, 부정적인 기분 지수는 찡그린 아바타 와 어두운 색상으로 나타낸다. 본 발명은 실시간으로 사용자의 감정 변화를 인식하고, 기존 기술에서는 기분 변화를 실시간으로 반영하지 않거 나 반영 속도가 느릴 수 있으나 본 발명은 해당 문제점을 해소한다. 디스플레이 처리부는 앱, 위젯, 푸시 알림 등을 통해서 다양한 스마트폰 인터페이스를 통합적으로 제공하 도록 디스플레이를 처리한다. 이에 따라, 사용자는 언제 어디서나 자신의 기분 상태를 쉽게 확인하고, 무드 아바타와 상호작용을 구현할 수 있다. 실시간 업데이트 처리부는 사용자 프로필, 과거 기분 데이터, 상황 정보를 바탕으로 맞춤형 기분 관리 권 장사항을 제공한다. 실시간 업데이트 처리부는 사용자의 기분 상태 분석에 따른 최적의 자기 대화 메시지 및 기분 개선 방법을 아바타를 통해서 제공한다. 실시간 업데이트 처리부는 실시간 피드백 메시지를 하기 표 5 및 표 6과 같이 제공할 수 있다. [표 5]"}
{"patent_id": "10-2024-0087404", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "[표 6]"}
{"patent_id": "10-2024-0087404", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "감정 맵핑 처리부는 사용자의 감정 지수와 아바타의 시각적 요소를 매핑한다. 예를 들어, 긍정적인 감정 지수가 높을수록 생생한 색상의 웃는 아바타가 표시되도록 한다. 또한, 부정적인 감정 지수가 낮을수록 은은한 색상의 찡그린 아바타가 표시되도록 할 수 있다. 디스플레이 처리부는 감정 트래커 어플리케이션, 감정 위젯, 푸시 알림과 같은 스마트폰 인터페이스에 대 화형 기분 아바타를 표시하도록 제어한다. 실시간 업데이트 처리부 사용자의 감정 지수를 지속적으로 모니터링하고 모니터링에 따라서 아바타의 상태 를 실시간으로 업데이트 한다. 도 4는 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치에서의 감정 관리 기능 처 리부를 설명하는 도면이다. 도 4는 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치에서의 감정 관리 기능 처 리부의 구성 요소를 예시한다. 도 4를 참고하면, 본 발명의 일실시예에 따른 감정 관리 기능 처리부는 메시지 피드백 처리부, 개인 화 처리부 및 상호작용 처리부를 포함한다. 감정 관리 기능 처리부는 사용자가 아바타와 상호작용하여 기분 상태와 관련된 피드백이나 입력을 제공할 수 있도록 한다. 감정 관리 기능 처리부는 상호작용에 따라 기분 상태에 따라 개인화된 셀프 토크 메시지를 받을 수 있도록 제어한다. 메시지 피드백 처리부는 혼잣말은 기분을 관리하고 긍정적인 사고를 촉진하는 강력한 도구가 될 수 있음에 각 기분에 따라 미리 정의된 자기 대화 메시지 라이브러리를 만든다. 메시지 피드백 처리부는 이러한 메시지는 긍정적이고 격려적이어야 하며 특정 기분 상태에 맞게 조정한다. 메시지 피드백 처리부는 사용자의 기분 상태의 분석에 기반하여 적합한 자기 대화 메시지를 선정하여 실시 간으로 자기대화를 전달한다. 개인화 처리부는 개별 사용자에 맞게 조정하는 개인화 기술을 구현한다. 개인화 처리부는 사용자 프로필, 역사적 분위기 사용을 포함하고, 기분 관리 개입에 대한 맞춤형 권장사항 을 제공하도록 데이터 및 상황 정보를 처리한다. 상호작용 처리부는 사용자와의 상호작용을 증강 현실 및 가상 현실 환경에서 구현한다. 상호작용 처리부는 증강 현실 모드 및 가상 현실 모드의 무드 아바타를 통해 사용자가 실제로 존재하는 것 처럼 느껴지는 상호작용을 제공한다. 상호작용 처리부는 증강 현실 모드 및 가상 현실 모드를 통해 몰입감 있는 3차원 환경을 제공한다. 상호작용 처리부는 사용자와의 상호작용 시 심리적 맥락을 고려하여 맞춤화된 경험을 제공한다. 상호작용 처리부는 아바타를 통해 사용자에게 감정적 터치(예: 포옹, 손잡기, 간지럽히기 등)을 제공하여 심리적 안정감을 제공한다. 상호작용 처리부는 감정적 터치와 관련된 다양한 촉각 피드백 제공하여 사용자의 체험을 더욱 풍부하게 한 다. 상호작용 처리부는 아바타를 통해서 상호작용르 구현하고, 상호작용을 통해 사용자의 감정 조절 및 기분 개선을 도모한다. 예를 들어, 상호작용 처리부는 사용자가 스트레스 받을 시 아바타를 통해 위로의 말을 건네거나 편안한 동 작을 구현하도록 한다. 도 5는 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치에서의 아바타 구현을 설 명하는 도면이다. 도 5는 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치에서의 아바타 구현 결과 에 대한 이미지를 예시한다. 도 5를 참고하면, 이미지는 가상현실을 통해 아바타를 구현하고, 사용자의 감정이 긍정적이 경우를 나타내 면서 함께 긍정적인 감정을 공유하는 경우를 예시한다. 이미지는 증강현실을 통해 아바타를 구현하고, 사용자의 감정이 긍정적이 경우를 나타내면서 함께 긍정적 인 감정을 공유하는 경우를 예시한다. 이미지 및 이미지는 긍정적인 경우를 예시하고 있으나, 구현되는 아바타는 부정적인 감정 상태인 경 우에는 부정적인 감정 상태를 긍정적인 감정 상태로 전환하기 위한 표현으로 실시간 변화될 수 있다. 이미지 및 이미지의 아바타는 도 4에서 설명된 상호작용 처리부에 의한 실시간 아바타 상태 전환이 구현되는 대상일 수 있다. 예를 들어, 아바타는 사용자와 상호작용 시에 손을 잡거나 포옹하는 느낌에 해당하는 햅틱 피드백을 제공할 수 있다. 따라서, 본 발명은 사용자와의 상호작용으로 사용자 기분 변화에 맞춘 실시간 업데이트를 제공하고, 심리적 맥 락의 통합과 촉각 피드백을 통해 몰입형 상호작용을 제공하는 기술을 구현할 수 있다. 도 6은 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 방법을 설명하는 도면이다. 도 6은 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 방법이 사용자 단말을 통해 입 력되는 사용자의 음성, 텍스트 및 표정을 다중 분석 및 인공지능 학습하여 사용자 기분을 인식하고, 인식된 기 분을 관리하기 위한 기분 관리를 구현하는 절차를 예시한다. 도 6을 참고하면, 단계(S601)에서 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 방 법은 인공지능 학습 기반 사용자 감정을 인식을 수행한다. 즉, 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 방법은 사용자로부터 입력된 텍스 트 데이터 및 음성 데이터 그리고 사용자로부터 인식되는 얼굴 표정 이미지 및 행동 자세 이미지에 대한 이미지 데이터를 인공지능 학습 처리하여 사용자 감정을 인식한다. 단계(S602)에서 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 방법은 아바타 생성 및 아바타 상태를 업데이트 한다. 즉, 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 방법은 인식된 사용자 감정에 따 라 복수의 시각적 요소 및 청각적 요소를 나타내는 아바타를 생성하고, 인식된 사용자 감정의 변화를 모니터링 하여 복수의 시각적 요소 및 청각적 요소가 변경되도록 아바타의 상태를 업데이트한다. 단계(S603)에서 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 방법은 아바타를 통해 감정 관리를 위한 상호작용을 구현한다. 즉, 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 방법은 증강 현실 및 가상 현실 환경에서 업데이트된 아바타를 통해 사용자의 감정 관리를 위한 피드백을 제공하여 감정 관리를 위한 사용자와 아바타 간의 상호 작용을 구현할 수 있다. 따라서, 본 발명은 사용자와의 상호작용으로 사용자 기분 변화에 맞춘 실시간 업데이트를 제공하고, 심리적 맥 락의 통합과 촉각 피드백을 통해 몰입형 상호작용을 제공하는 기술을 구현할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPA(field programmable array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2024-0087404", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분포되어서, 분포된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매 체에 저장될 수 있다."}
{"patent_id": "10-2024-0087404", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또 는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2024-0087404", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치를 설명하는 도면이다. 도 2는 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치에서의 다중 감정 인식 처 리부를 설명하는 도면이다. 도 3은 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치에서의 아바타 관리부를 설명하는 도면이다. 도 4는 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치에서의 감정 관리 기능 처 리부를 설명하는 도면이다. 도 5는 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 장치에서의 아바타 구현을 설 명하는 도면이다. 도 6은 본 발명의 일실시예에 따른 인공지능 학습 기반 사용자 맞춤형 감정 관리 방법을 설명하는 도면이다."}
