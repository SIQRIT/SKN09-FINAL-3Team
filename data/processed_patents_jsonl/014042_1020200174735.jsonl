{"patent_id": "10-2020-0174735", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0084849", "출원번호": "10-2020-0174735", "발명의 명칭": "전자기파 데이터의 AI 기계학습을 위한 어노테이션 방법", "출원인": "이기현", "발명자": "이기현"}}
{"patent_id": "10-2020-0174735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "자율주행을 위해 주행환경을 인공지능 기계학습 시키기 위한 기계학습데이터 제작방법으로서, 레이더 센서에 의해 획득된 조감도 형태의 레이더 센서 주행환경 데이터; 및상기 레이더 센서 주행환경 데이터와 시간 동기화되고 동일 영역을 촬영한 영상 주행환경 데이터;를 준비하고,레이더 센서 주행환경 데이터에 나타난 객체에 대해 어노테이션 하고,상기 영상 주행환경 데이터에 나타난 객체에 대해 어노테이션하고,상기 레이더 센서 주행환경 데이터에 어노테이션된 객체와 영상 주행환경 데이터에 어노테이션 된 객체를 서로매칭하여 어노테이션 되고, 매칭된 레이더 센서 주행환경 데이터와 영상 주행환경 데이터가 병존된 것을 특징으로 하는 기계학습데이터 제작방법."}
{"patent_id": "10-2020-0174735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 영상 주행환경 데이터에 어노테이션된 박스 사이즈와 레이더 센서 주행환경 데이터에 어노테이션된 객체별 반사량을 대비하여 어노테이션 된 객체를 서로 매칭하는 것을 특징으로 하는 기계학습데이터 제작방법."}
{"patent_id": "10-2020-0174735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 레이더 센서 주행환경 데이터에 대해 객체를 어노테이션하고, 어노테이션 된 객체마다 식별번호를 부여하고, 영상 주행환경 데이터의 객체들을 어노테이션 한 후, 육안으로 파악되는 원근감과 방위감에 의해 양 데이터에서의 객체들을 매칭시키고, 레이더 센서 주행환경 데이터에 포함된 객체별 반사량과 속도 데이터를 참조하여 매칭의 정확성을 검토하고 수정할 필요가 있는 경우 수정하는 것을 특징으로 하는 기계학습데이터 제작방법."}
{"patent_id": "10-2020-0174735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 어노테이션되고 식별번호가 부여된 객체에 대해 카(car), 트럭(truck), 사인(sign), 중장비(heavy equipment), 또는 구조물(Structure) 중 어느 하나로 객체에 명사를 붙여 명명하는 것을 특징으로 하는기계학습데이터 제작방법."}
{"patent_id": "10-2020-0174735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 명명 작업에서 레이더 센서 주행환경 데이터에 나타난 객체별 반사량을 참조하는 것을 특징으로 하는 기계학습데이터 제작방법."}
{"patent_id": "10-2020-0174735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "자율주행을 위한 인공지능 기계학습에 제공될 학습데이터로서, 영상 주행환경 데이터와 레이더 센서 주행환경데이터를 영역과 시간을 동기시키고 영상 주행환경 데이터와 레이더 센서 주행환경 데이터에 나타난 객체들을각각 어노테이션 하고, 영상 주행환경 데이터와 레이더 센서 주행환경 데이터에서 각각 어노테이션된 객체들을서로 동일한 것끼리 매칭하여 어노테이션된 영상 주행환경 데이터와 레이더 센서 주행환경 데이터를 병용한 것을 특징으로 하는 자율주행용 기계학습데이터."}
{"patent_id": "10-2020-0174735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 영상 주행환경 데이터를 기반으로 하여, 영상 주행환경 데이터에 어노테이션 된 객체에 식별번공개특허 10-2022-0084849-3-호와 명사를 부여하고, 해당 식별번호에 (r, θ) 좌표, 속도와 반사량을 기입하여 하나로 통합된 것을 특징으로하는 자율주행용 기계학습데이터."}
{"patent_id": "10-2020-0174735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 통합된 영상 주행환경 데이터를 3차원 조감도 형태로 제작하고 속도 값으로 이동하는 동영상형태로 제작된 것을 특징으로 하는 자율주행용 기계학습데이터."}
{"patent_id": "10-2020-0174735", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 영상기반의 어노테이션 방법과 별도로 전자기파 센서의 어노테이션 방법을 제안하고, 양자를 병용 내 지 통합한 자율주행 기계학습 데이토를 제공함으로써 향후 AI의 학습용 데이터의 영역을 확장시켜 좀더 안전한 자율주행 기술을 확보하고자 한다."}
{"patent_id": "10-2020-0174735", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 전자기파 데이터의 인공지능 기계학습을 위한 어노테이션 방법에 대한 것이다."}
{"patent_id": "10-2020-0174735", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자율주행 구현을 위해 주로 사용되는 센서는 주로 카메라센서와 레이더(Radar) 그리고 라이다(Lidar)센서이다. 카메라는 가시광선을 이용함으로 사람이 직관적으로 물체를 인식하는데 용이하지만 조명과 악천후에 영향을 받 으며 물체의 속도나 위치, 거리에 대한 정확도는 레이더와 라이다 센서에 비해 떨어진다. 따라서 안전한 자율주 행을 실현하기 위해서는 기본적으로 이러한 센서의 장단점을 활용한 퓨전이 중요하다. 자율주행을 위해서는 차 량내 설치된 카메라, 레이더, 라이더와 같은 센서로 부터 수집된 데이터를 기반으로 차량 스스로 가속, 감속, 차선 변경 등을 판단하여 목적지 까지 이동해야 되는데 이러한 주행 판단의 역할은 AI가 수행한다. 알파고 이후 기계학습을 통한 AI 기술 발전은 괄목할 만하다. 이러한 AI의 기술발전은 자율주행에도 접목되고 있다. 현재 자 율주행을 위한 AI 기술은 주로 카메라 영상 기반의 기계학습 데이터가 사용되고 있다. AI가 자율주행을 위해 필 요한 데이터는 주행 중 녹화된 영상 데이터 자체가 아니다. AI의 기계학습을 위해서는 주행 중 녹화된 영상 데 이터를 기반으로 차량, 차선, 사람, 신호등, 표지판, 횡단보도 등 차량의 운행에 판단기준이 되는 중요한 요소 들을 찾아내어 표시하고 종류별로 분류하는 등 기계학습을 위해 정제된 데이터를 생성하는 어노테이션 과정이 필수적이다(도 1 및 도 2 참조). 이러한 정제된 데이터를 통해 AI 기계학습이 진행된 이후에 자율주행의 판단용 으로 활용될 수 있는 것이다. 안전한 자율주행을 위해서 AI에게 매우 다양한 주행환경을 학습시켜야 한다. 이는 수 많은 양의 어노테이션 과정이 필수적이며, 많은 시간과 사람의 노고가 필요하다. 이러한 어노테이션 작업은 주로 사람의 수작업으로 이루어지고 있지만 최근에는 어노테이션 작업 자체를 또 다른 AI가 수행하게 하는 기술 도 연구되고있다. 이렇게 수많은 노고가 필요한 영상데이터라 하더라도 영상데이터는 조명이나 악천후에 영향을 많이 받을 수 밖에 없어 실제 자율주행을 위해서는 악천후에 상황에서도 영향을 거의 받지않는 전자기파 센서가 필수적이다. 그러나 전자기파 센서는 카메라에 비해 해상도가 떨어짐으로 인해 완전한 물체인식에는 한계가 있 다. 테슬라의 경우 자율주행을 위해 카메라센서와 레이더 센서를 사용하고 있으며 구글 자회사인 웨이모의 경우 카메라, 레이더, 라이더 센서를 모두 사용하고 있다. 레이더 센서는 눈에 보이지않은 전자기파의 반사 신호를 기반으로 복잡하고 다양한 SW 기법(신호처리)을 거쳐 최종적으로 도 3에서와 같이 물체 또는 객체로 인지할 수 있다. 여기서 취득되는 객체정보는 레이더센서에서 수신된 전자기파의 정보만을 이용하여 계산된 것임으로 만일 신호처리 SW 알고리즘의 오류가 있다면 심각한 문제가 발생 할 수도 있어 현재는 주로 보조적인 센서로 사용되 고 있다. 이러한 문제로 인해 자율주행 판단을 위한 AI 기계학습은 영상기반의 어노테이션 데이터가 주로 사용 되며 레이더와 라이더와 같은 보조센서는 AI 학습용 데이터를 통하지 않고 단순 급정차 위험, 차선변경시 사각 지역 위험 감지 등 이벤트성 위험 감지 역할에 한정되어 사용되고 있는 실정이다. 관련기술로서 출원번호 1020180128013 호가 있다. 상기 출원은 자율주행용 영상데이터의 분석에 대해서 기재한 다."}
{"patent_id": "10-2020-0174735", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명에서는 영상기반의 어노테이션 방법과 별도로 전자기파 센서의 어노테이션 방법을 제안 함으로서 향후 AI의 학습용 데이터의 영역을 확장시켜 좀더 안전한 자율주행 기술을 확보하고자 한다."}
{"patent_id": "10-2020-0174735", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은, 자율주행을 위해 주행환경을 인공지능 기계학습 시키기 위한 기계학습데이터 제작방법으로서, 레이더 센서에 의해 획득된 조감도 형태의 레이더 센서 주행환경 데이터; 및 상기 레이더 센서 주행환경 데이터와 시간 동기화되고 동일 영역을 촬영한 영상 주행환경 데이터;를 준비하고, 레이더 센서 주행환경 데이터에 나타난 객체에 대해 어노테이션 하고, 상기 영상 주행환경 데이터에 나타난 객체에 대해 어노테이션하고, 상기 레이더 센서 주행환경 데이터에 어노테이션된 객체와 영상 주행환경 데이터에 어노테이션 된 객체를 서로 매칭하여 어노테이션 되고, 매칭된 레이더 센서 주행환경 데이터와 영상 주행환경 데이터가 병존된 것을 특징으 로 하는 기계학습데이터 제작방법을 제공한다. 상기에 있어서, 영상 주행환경 데이터에 어노테이션된 박스 사이즈와 레이더 센서 주행환경 데이터에 어노테이 션된 객체별 반사량을 대비하여 어노테이션 된 객체를 서로 매칭하는 것을 특징으로 하는 기계학습데이터 제작 방법을 제공한다. 상기에 있어서, 레이더 센서 주행환경 데이터에 대해 객체를 어노테이션하고, 어노테이션 된 객체마다 식별번호 를 부여하고, 영상 주행환경 데이터의 객체들을 어노테이션 한 후, 육안으로 파악되는 원근감과 방위감에 의해 양 데이터에서 의 객체들을 매칭시키고, 레이더 센서 주행환경 데이터에 포함된 객체별 반사량과 속도 데이터를 참조하여 매칭의 정확성을 검토하고 수 정할 필요가 있는 경우 수정하는 것을 특징으로 하는 기계학습데이터 제작방법을 제공한다. 상기에 있어서, 어노테이션되고 식별번호가 부여된 객체에 대해 카(car), 트럭(truck), 사인(sign), 중장비 (heavy equipment), 또는 구조물(Structure) 중 어느 하나로 객체에 명사를 붙여 명명하는 것을 특징으로 하는 기계학습데이터 제작방법을 제공한다. 상기에 있어서, 명명 작업에서 레이더 센서 주행환경 데이터에 나타난 객체별 반사량을 참조하는 것을 특징으로 하는 기계학습데이터 제작방법을 제공한다. 또한, 본 발명은, 자율주행을 위한 인공지능 기계학습에 제공될 학습데이터로서, 영상 주행환경 데이터와 레이더 센서 주행환경 데이터를 영역과 시간을 동기시키고 영상 주행환경 데이터와 레이더 센서 주행환경 데이터에 나타난 객체들을 각각 어노테이션 하고, 영상 주행환경 데이터와 레이더 센서 주행환경 데이터에서 각각 어노테이션된 객체들을 서로 동일한 것끼리 매칭하여 어노테이션된 영상 주행환경 데이터와 레이더 센서 주행환경 데이터를 병용한 것 을 특징으로 하는 자율주행용 기계학습데이터를 제공한다. 상기에 있어서, 영상 주행환경 데이터를 기반으로 하여, 영상 주행환경 데이터에 어노테이션 된 객체에 식별번 호와 명사를 부여하고, 해당 식별번호에 (r, θ) 좌표, 속도와 반사량을 기입하여 하나로 통합된 것을 특징으로 하는 자율주행용 기계학습데이터를 제공한다. 상기에 있어서, 통합된 영상 주행환경 데이터를 3차원 조감도 형태로 제작하고 속도 값으로 이동하는 동영상 형 태로 제작된 것을 특징으로 하는 자율주행용 기계학습데이터를 제공한다."}
{"patent_id": "10-2020-0174735", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "현재 영상기반의 AI 기계학습은 HW의 발전 뿐 아니라 SW알고리즘이나 데이터의 양적으로도 매우 빠른 속도로 발전하고 있다. 하지만 영상이 갖고 있는 물리적인 한계로 인한 악천후 또는 조명에 따른 화질 문제는 해결될 수 없는 딜레마이다. 또한 영상기반 데이터가 가지고 있는 문제는 원근감이 없는 상태에서 물체의 크기를 판단 할 수 없다는 것이다. 영상기반 데이터는 카메라와 근접할 수록 급격하게 객체 크기가 커지는 현상이 있고, 이 러한 문제는 자동차의 자율주행에 심각한 오류를 발생시키는 원인이 될 수 있다."}
{"patent_id": "10-2020-0174735", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "안전하고 완전한 자율주행을 위해서는 영상이외의 추가적인 학습용 데이터 확보가 필수적이다. 본 발명의 효과 는 레이더 센서와 영상데이터의 관계를 AI 학습을 통해 규명할 수 있다는 것이다. 이러한 상관관계 데이터가 축적되면 결과적으로 영상데이터 없이도 레이더센서 데이터 만으로 자율주행이 가능해 질 수 있다. 이는 악천후나 야간, 안개 상황 등 앞을 볼 수 없는 상황에서도 안전한 자율주행이 가능해 진다는 것으로 매우 의미 있는 시도 가 될 것이다."}
{"patent_id": "10-2020-0174735", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부도면을 참조하여 본 발명의 바람직한 실시예에 대해 상세히 설명한다. 전자기파 데이터의 어노테이션 방법 1. 영상자료와 동기화된 전자기파 데이터 저장 레이더센서는 눈에 보이지 않는 전자기파의 반사 신호를 복잡하고 다양한 SW기법(신호처리)을 거쳐 최종적으로 객체로 인지하는데 이러한 신호처리는 자신이 전파를 송신하고 수신하는 매순간마다 이루어지며 센서의 종류에 따라 1초에 20회 ~ 30회 정도 일정한 간격으로 지속적이고 순차적으로 처리된다. 이러한 과정은 일반적인 디지 털 카메라가 영상을 녹화하는 방식과 동일하며 이는 동일한 시간부터 동일한 간격으로 2개의 센서를 동기화하여 데이터를 저장하는 것도 가능하다는 것이다. 이렇게 저장된 2개의 데이터는 같은 시각으로 레이블링 되어 저장 되어야 하며 특정 시간대 영상데이터를 선택한다면 같은 시간대의 레이더 데이터가 조회 될 수 있도록 해야 하 며 반대로 특정시간대의 레이더 데이터를 선택한다면 같은 시간대 영상데이터가 조회 될 수 있어야 한다. 도 3 은 레이더 센서 객체감지 영상과 이와 시간 동기화된 영상을 보여준다. 레이더센서로부터 주로 취득하는 데이터는 감지된 물체에 대하여 X, Y좌표로 표시되는 위치정보, 물체의 반사량, 물체의 속도정보 등이다. 최근 이미지 레이더라고 하는 고정밀 레이더센서의 경우 X,Y 평면좌표 뿐 아 니라, 라이다와 같이 물체의 X, Y, Z 정보에 취득 할 수 있어 물체의 높이까지 판단할 수 있게 되었다. 본 발명에서는 2D레이더 센서를 어노테이션하는 방법에 대해 설명하지만, 3D 레이더센서의 어노테이션 방법도 2D 어노테이션 결과에 물체의 높이(Z값)만 추가하면 된다. 2. 영상 데이터에서 AI 학습용 어노테이션 데이터 취득 일반적으로 영상데이터에서 취득할 수 있는 데이터는 객체 이미지와 직관적인 객체 분류, 원근감에 따른 객체 종류별 사이즈가 될 것이다. 영상 데이터의 어노테이션 방법은 수작업 또는 자동화 툴 등을 이용하여 기존 방식 대로 생성할 수 있다. 실제 AI가 인식할 수 있는 정제된 어노테이션 데이터는 도 5의 그림처럼 이미지 위에 타 이핑 되어 표시되는 형태가 아닐 수 있으며 JSON이나 XML 타입의 AI가 의미를 학습할 수 있는 데이터 형식이다. 3. 레이더센서 데이터에서 AI 학습용 어노테이션 데이터 취득 레이더센서는 눈에 보이지 않는 전자기파의 반사 신호를 이용하여 복잡하고 다양한 SW 기법을 거쳐 최종적으로 도 6과 같은 물체의 위치를 계산 할 수 있으며 추가적으로 반사량과 도플러 효과를 통해 속도정보도 얻을 수 있 다. 영상데이터와 동일한 시간대의 레이더 센서로 부터 취득한 데이터는 동일 시간대의 영상 어노테이션 데이터의 추가적인 속성값으로 볼 수 있으며 반대 경우도 마찬가지이다. 여기서는 반대의 경우를 예를 들어, 전자기파 데 이터 값이 영상 어노테이션 데이터를 추가하는 것으로 한다. 4. 영상데이터와 레이더센서 데이터의 매칭 앞에서 영상기반의 정제된 어노테이션 데이터와 레이더센서의 어노테이션 데이터는 1:1로 매칭시킬 수 있다. 도 7의 왼쪽 영상 데이터를 기반으로 객체에 대해 순서대로 번호를 붙여 일치시킬 수 도 있고 도 7의 화살표 처럼 해당 영상을 마우스로 끌어서 매칭 시키는 방법도 있을 수 있다. 이를 통해 레이더 센서 기반의 AI 학습용 데이터는 레이더센서에 나타난 객체들의 위치정보, 속도정보, 반사량 정보에 추가적으로 객체의 분류정보, 크기정보, 색상정보 등을 추가할 수 있다. 이때 레이더 센서의 경우는 센서로부터 물체의 상대적인 거리를 이용하면 도 7의 이미지와 같이 조감도로 표시 할 수 있지만 카메라 영상의 경우는 물체의 상대적인 거리 또는 속도 정보를 얻을 수 없음으로 조감도로 표시하 는데 한계가 있어, 특히 원거리 물체의 경우 카메라와 레이더 2개 센서의 객체를 서로 매칭하는게 쉽지 않다. 이때 영상 어노테이션의 박스 사이즈와 레이더 센서의 객체별 반사량을 비교하면 레이더 센서의 조감도와 매치 하는게 가능해진다. 트럭의 경우 멀리 있어도 박스사이즈가 크고 반사량도 크며, 일반차량의 경우는 같은 위치 에서도 박스사이즈가 작고 반사량도 작음으로 이러한 상관관계를 이용하면 쉽게 영상의 객체와 레이더센서의 객 체를 매칭 시킬 수 있다. 어노테이션 방법의 구체적인 예를 들면 다음과 같다. 레이더 센서 주행환경 데이터는 반경과 방위각(r, θ)에 따른 객체별 위치가 조감도와 같이 나타나고, 객체별 반사량과 속도를 포함한다. 영상 주행환경 데이터는 레이더와 동일영역에 대하여 시간동기화 된 2차원 영상으로 차량이나 표지판, 구조물 등을 시각적으로 인식하고 원근에 대한 것도 육안으로(시각적으로) 인식되지만, 거리 가 먼 것일수록 원근 감에 대한 파악은 불명해진다. 따라서 조감도와 같이 객체가 분명한 거리 및 방위를 갖고 나타나는 레이더 센서 주행환경 데이터에 대해 객체를 어노테이션하고 식별번호를 부여하고, 영상 주행환경 데 이터의 객체들을 어노테이션 한 후, 육안으로 파악되는 원근감과 방위감에 의해 양 데이터에서의 객체들을 매칭 시키고, 레이더 센서 주행환경 데이터에 포함된 객체별 반사량과 속도 데이터를 참조하여 매칭의 정확성을 검토 하고 수정할 필요가 있는 경우 수정한다. 또한, 어노테이션되고 식별번호가 부여된 객체에 대해 카(car), 트럭 (truck), 사인(sign), 중장비(heavy equipment), 구조물(Structure) 등으로 객체에 명사를 붙여 명명한다. 영 상 주행환경 데이터에서 육안 외 어노테이션된 박스 사이즈도 명명 작업에서 하나의 판단 요인이 된다. 상술한 바와 같이 레이더 센서 주행환경 데이터에 나타난 객체별 반사량 또한 명명 작업에서 유력한 단서가 된다. 자율주행을 위한 인공지능 기계학습에 제공될 학습데이터는 영상 주행환경 데이터와 레이더 센서 주행환경 데이 터를 동기시키고 어노테이션 하여 양자를 병기한 것으로 제작될 수 있다. 또한, 영상 주행환경 데이터에 어노테 이션하고, 어노테이션 된 객체에 식별번호와 명사를 부여하고, 해당 식별번호에 (r, θ) 좌표, 속도와 반사량을 기입하여 하나의 통합된 학습데이터로 제작될 수 있다. 즉, 영상 주행환경 데이터를 기반으로하고 레이더 센서 주행환경 데이터를 여기에 통합시키는 것이다. 또한, 통합된 영상 주행환경 데이터를 3차원 조감도 형태로 제작 하고 속도 값으로 이동하는 동영상 형태로 제작될 수 있다. 한편, 상기 실시 예들에서 제시한 구체적인 수치들은 예시적인 것으로 필요에 따라 변형 가능함은 물론이며, 본"}
{"patent_id": "10-2020-0174735", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "발명이 속하는 기술분야의 당업자는 본 발명이 그 기술적 사상이나 필수적 특징을 변경하지 않고서 다른 구체적 인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시 예는 모든 면에서 예 시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범위는 상기 상세한 설명보다는 후술 하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 등가개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2020-0174735", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 및 도 2는 어노테이션 실시예를 보여주는 사진이다. 도 3은 자율주행용 센서의 해상도를 대비한 사진이다. 도 4는 레이더 센서의 감지결과를 보여주는 이미지 샘플과 여기에 시간동기된 카메라 영상 사진이다. 도 5는 JSON 타입의 어노테이션 데이터 샘플을 보여준다. 도 6은 레이더 센서 감지결과에 대한 어노테이션 데이터 샘플을 보여준다. 도 7은 영상 어노테이션 데이터와 레이더 센서 감지결과에 대한 어노테이션 데이터의 매칭 예를 보여준다."}
