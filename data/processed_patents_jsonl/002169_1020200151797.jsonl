{"patent_id": "10-2020-0151797", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0065370", "출원번호": "10-2020-0151797", "발명의 명칭": "전자장치 및 그 제어방법", "출원인": "삼성전자주식회사", "발명자": "박민규"}}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자장치에 있어서,컨텐츠에 포함된 비디오신호에 기초하여 디스플레이에 복수의 객체를 포함하는 영상이 표시되도록 제어하고,복수의 마이크로 획득된 상기 컨텐츠에 포함된 복수의 오디오신호로부터 주파수특성에 따라 복수의 음원성분을획득하고, 상기 컨텐츠의 재생 중에 상기 오디오신호와 상기 음원성분 간의 주파수특성의 연관성에 기초하여 상기 복수의마이크 중 상기 음원성분에 대응하는 오디오신호를 획득한 마이크를 식별하고, 상기 복수의 마이크의 배치에 기초하여, 상기 표시되는 영상 내의 복수의 객체 중에서, 상기 식별된 마이크의위치에 대응하는 어느 하나의 객체에 관하여 상기 컨텐츠와 관련된 동작을 수행하는 프로세서를 포함하는 전자장치."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 프로세서는, 상기 복수의 음원성분 중에서, 상기 오디오신호의 주파수성분과 동일한 주파수대역에서 주파수성분의 크기가 큰 어느 하나의 음원성분을 상기 오디오신호에 대응하는 음원성분으로 식별하는 전자장치."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 프로세서는, 상기 식별된 마이크에 대응하는 상기 영상 내 위치를 식별하고,상기 영상에 표시된 복수의 객체 중에서, 상기 식별된 위치에 가까운 어느 하나의 객체를 상기 마이크의 위치에대응하는 객체로 식별하는 전자장치."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 프로세서는, 상기 마이크의 위치에 대응하는 객체를 다른 객체와 구분 가능하도록 표시하는 전자장치."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 프로세서는, 상기 음원성분에 대응하는 객체를 다른 객체와 구분 가능하도록 표시하는 전자장치."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 프로세서는, 상기 식별된 마이크와, 상기 마이크의 위치에 대응하는 객체 간의 상호 위치 관계를 나타내는사용자인터페이스를 표시하는 전자장치."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서, 상기 프로세서는, 상기 복수의 음원성분 중 사용자입력에 따라 선택된 음원성분에 대응하는 객체를 다른 객체와공개특허 10-2022-0065370-3-구분 가능하도록 표시하는 전자장치."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 프로세서는, 상기 복수 객체 중 사용자입력에 따라 선택된 객체에 대응하는 상기 음원성분의 크기를 조정하는 동작을 수행하는 전자장치."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 프로세서는, 상기 오디오신호의 프레임에 기초하여 상기 마이크 및 상기 음원성분 간의 대응관계를 업데이트 하는 전자장치."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "전자장치의 제어방법에 있어서,컨텐츠에 포함된 비디오신호에 기초하여 복수의 객체를 포함하는 영상을 표시하는 단계;복수의 마이크로 획득된 상기 컨텐츠에 포함된 복수의 오디오신호로부터 주파수특성에 따라 복수의 음원성분을획득하는 단계;상기 컨텐츠의 재생 중에 상기 오디오신호와 상기 음원성분 간의 주파수특성의 연관성에 기초하여 상기 복수의마이크 중 상기 음원성분에 대응하는 오디오신호를 획득한 마이크를 식별하는 단계; 및상기 복수의 마이크의 배치에 기초하여, 상기 표시되는 영상 내의 복수의 객체 중에서, 상기 식별된 마이크의위치에 대응하는 어느 하나의 객체에 관하여 상기 컨텐츠와 관련된 동작을 수행하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 음원성분에 대응하는 오디오신호를 획득한 마이크를 식별하는 단계는, 상기 복수의 음원성분 중에서, 상기오디오신호의 주파수성분과 동일한 주파수대역에서 주파수성분의 크기가 큰 어느 하나의 음원성분을 상기 오디오신호에 대응하는 음원성분으로 식별하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 컨텐츠와 관련된 동작을 수행하는 단계는, 상기 식별된 마이크에 대응하는 상기 영상 내 위치를 식별하는 단계; 및상기 영상에 표시된 복수의 객체 중에서, 상기 식별된 위치에 가까운 어느 하나의 객체를 상기 마이크의 위치에대응하는 객체로 식별하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서, 상기 컨텐츠와 관련된 동작을 수행하는 단계는, 상기 마이크의 위치에 대응하는 객체를 다른 객체와 구분 가능하도록 표시하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서,공개특허 10-2022-0065370-4-상기 컨텐츠와 관련된 동작을 수행하는 단계는, 상기 음원성분에 대응하는 객체를 다른 객체와 구분 가능하도록표시하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서, 상기 컨텐츠와 관련된 동작을 수행하는 단계는, 상기 식별된 마이크와, 상기 마이크의 위치에 대응하는 객체 간의 상호 위치 관계를 나타내는 사용자인터페이스를 표시하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서, 상기 다른 객체와 구분 가능하도록 표시하는 단계는, 상기 복수의 음원성분 중 사용자입력에 따라 선택된 음원성분에 대응하는 객체를 다른 객체와 구분 가능하도록 표시하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항에 있어서,상기 컨텐츠와 관련된 동작을 수행하는 단계는, 상기 복수 객체 중 사용자입력에 따라 선택된 객체에 대응하는상기 음원성분의 크기를 조정하는 동작을 수행하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항에 있어서, 상기 컨텐츠와 관련된 동작을 수행하는 단계는, 상기 오디오신호의 프레임에 기초하여 상기 마이크 및 상기 음원성분 간의 대응관계를 업데이트 하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0151797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "컴퓨터가 읽을 수 있는 코드로서, 전자장치의 제어방법을 수행하는 코드를 포함하는 컴퓨터 프로그램이 저장된기록매체에 있어서, 상기 전자장치의 제어방법은, 컨텐츠에 포함된 비디오신호에 기초하여 복수의 객체를 포함하는 영상을 표시하는 단계;복수의 마이크로 획득된 상기 컨텐츠에 포함된 복수의 오디오신호로부터 주파수특성에 따라 복수의 음원성분을획득하는 단계;상기 컨텐츠의 재생 중에 상기 오디오신호와 상기 음원성분 간의 주파수특성의 연관성에 기초하여 상기 복수의마이크 중 상기 음원성분에 대응하는 오디오신호를 획득한 마이크를 식별하는 단계; 및상기 복수의 마이크의 배치에 기초하여, 상기 표시되는 영상 내의 복수의 객체 중에서, 상기 식별된 마이크의위치에 대응하는 어느 하나의 객체에 관하여 상기 컨텐츠와 관련된 동작을 수행하는 단계를 포함하는 것을 특징으로 하는 컴퓨터가 읽을 수 있는 프로그램이 기록된 기록매체."}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 컨텐츠에 포함된 비디오신호에 기초하여 복수의 객체를 포함하는 영상을 표시하고, 복수의 마이크로 획득된 컨텐츠에 포함된 복수의 오디오신호로부터 주파수특성에 따라 복수의 음원성분을 획득하고, 컨텐츠의 재 생 중에 음원성분 및 마이크의 오디오신호 간에 기초하여 복수의 마이크 중 음원성분에 대응하는 오디오신호를 획득한 마이크를 식별하고, 복수의 마이크의 배치에 기초하여, 영상 내의 복수의 객체 중에서, 마이크의 위치에 대응하는 어느 하나의 객체에 관하여 컨텐츠와 관련된 동작을 수행하는 전자장치에 관한 발명이다."}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 전자장치 및 그 제어방법에 관한 것으로서, 상세하게는, 객체를 포함하는 영상을 표시하고, 음원성분 에 대응하는 객체를 식별하는 전자장치 및 그 제어방법에 관한 것이다."}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근에 음원추적 기능이 각광받고 있다. 음원추적 기능은 음원에 대응하는 신호가 마이크에 수신되면, 수신된 신호에 대한 분석을 통해 음원의 위치를 추적하는 기술이다. 음원추적 기능은 음성인식 등 다양한 분야에 적용 되고 있으며, 음성인식 등의 편의성을 향상시킬 수 있으므로, 음원추적 기능을 활용 분야가 점점 증가하고 있는 추세이다. 다만, 종래의 음원추적 기능은 단일 음원에 대하여 수행되거나, 복수의 음원 중 단일 대표 음원에 대하여 수행 되는데 그치므로, 복수의 음원에 대한 통합적 추적이 불가능할 뿐만 아니라, 음원의 이동에 대응하여 적응적 추 적이 불가능한 문제점이 있다. 이러한 문제점은 음원추적 기능에 대한 불편함으로 초래하여, 활용성을 저하시키 는 원인되고 있다. 따라서, 복수의 음원에 대한 통합적 추적 및 음원의 이동에 대응한 적응적 추적이 가능하도록 하여, 음원추적 기능에 대한 효율성 및 활용성을 향상시킬 수 있는 방안이 요구되고 있다."}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은, 복수의 음원에 대한 통합적 추적 및 음원의 이동에 대응한 적응적 추적이 가능하도록 하여, 음원추적 기능에 대한 효율성 및 활용성을 향상시킬 수 있는 전자장치 및 그 제어방법을 제공하는 것이다."}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 본 발명의 목적은, 컨텐츠에 포함된 비디오신호에 기초하여 디스플레이에 복수의 객체를 포함하는 영상 이 표시되도록 제어하고, 복수의 마이크로 획득된 상기 컨텐츠에 포함된 복수의 오디오신호로부터 주파수특성에 따라 복수의 음원성분을 획득하고, 상기 컨텐츠의 재생 중에 상기 오디오신호와 상기 음원성분 간의 주파수특성 의 연관성에 기초하여 상기 복수의 마이크 중 상기 음원성분에 대응하는 오디오신호를 획득한 마이크를 식별하 고, 상기 복수의 마이크의 배치에 기초하여, 상기 표시되는 영상 내의 복수의 객체 중에서, 상기 식별된 마이크 의 위치에 대응하는 어느 하나의 객체에 관하여 상기 컨텐츠와 관련된 동작을 수행하는 프로세서를 포함하는 전 자장치에 의해 달성될 수 있다. 상기 프로세서는, 상기 복수의 음원성분 중에서, 상기 오디오신호의 주파수성분과 동일한 주파수대역에서 주파 수성분의 크기가 큰 어느 하나의 음원성분을 상기 오디오신호에 대응하는 음원성분으로 식별한다. 상기 프로세서는, 상기 식별된 마이크에 대응하는 상기 영상 내 위치를 식별하고, 상기 영상에 표시된 복수의 객체 중에서, 상기 식별된 위치에 가까운 어느 하나의 객체를 상기 마이크의 위치에 대응하는 객체로 식별한다. 상기 프로세서는, 상기 마이크의 위치에 대응하는 객체를 다른 객체와 구분 가능하도록 표시한다. 상기 프로세서는, 상기 음원성분에 대응하는 객체를 다른 객체와 구분 가능하도록 표시한다. 상기 프로세서는, 상기 식별된 마이크와, 상기 마이크의 위치에 대응하는 객체 간의 상호 위치 관계를 나타내는 사용자인터페이스를 표시한다. 상기 프로세서는, 상기 복수의 음원성분 중 사용자입력에 따라 선택된 음원성분에 대응하는 객체를 다른 객체와 구분 가능하도록 표시한다. 상기 프로세서는, 상기 복수 객체 중 사용자입력에 따라 선택된 객체에 대응하는 상기 음원성분의 크기를 조정 한다. 상기 프로세서는, 상기 오디오신호의 프레임에 기초하여 상기 마이크 및 상기 음원성분 간의 대응관계를 업데이 트 한다. 상기한 본 발명의 목적은, 컨텐츠에 포함된 비디오신호에 기초하여 복수의 객체를 포함하는 영상을 표시하는 단 계; 복수의 마이크로 획득된 상기 컨텐츠에 포함된 복수의 오디오신호로부터 주파수특성에 따라 복수의 음원성 분을 획득하는 단계; 상기 컨텐츠의 재생 중에 상기 오디오신호와 상기 음원성분 간의 주파수특성의 연관성에 기초하여 상기 복수의 마이크 중 상기 음원성분에 대응하는 오디오신호를 획득한 마이크를 식별하는 단계; 및 상기 복수의 마이크의 배치에 기초하여, 상기 표시되는 영상 내의 복수의 객체 중에서, 상기 식별된 마이크의 위치에 대응하는 어느 하나의 객체에 관하여 상기 컨텐츠와 관련된 동작을 수행하는 단계를 포함하는 전자장치 의 제어방법에 의해서도 달성될 수 있다. 상기 음원성분에 대응하는 오디오신호를 획득한 마이크를 식별하는 단계는, 상기 복수의 음원성분 중에서, 상기 오디오신호의 주파수성분과 동일한 주파수대역에서 주파수성분의 크기가 큰 어느 하나의 음원성분을 상기 오디 오신호에 대응하는 음원성분으로 식별하는 단계를 더 포함한다. 상기 컨텐츠와 관련된 동작을 수행하는 단계는, 상기 식별된 마이크에 대응하는 상기 영상 내 위치를 식별하는 단계; 및 상기 영상에 표시된 복수의 객체 중에서, 상기 식별된 위치에 가까운 어느 하나의 객체를 상기 마이크 의 위치에 대응하는 객체로 식별하는 단계를 더 포함한다. 상기 컨텐츠와 관련된 동작을 수행하는 단계는, 상기 마이크의 위치에 대응하는 객체를 다른 객체와 구분 가능 하도록 표시하는 단계를 더 포함한다. 상기 컨텐츠와 관련된 동작을 수행하는 단계는, 상기 음원성분에 대응하는 객체를 다른 객체와 구분 가능하도록 표시하는 단계를 더 포함한다. 상기 컨텐츠와 관련된 동작을 수행하는 단계는, 상기 식별된 마이크와, 상기 마이크의 위치에 대응하는 객체 간 의 상호 위치 관계를 나타내는 사용자인터페이스를 표시하는 단계를 더 포함한다. 상기 다른 객체와 구분 가능하도록 표시하는 단계는, 상기 복수의 음원성분 중 사용자입력에 따라 선택된 음원 성분에 대응하는 객체를 다른 객체와 구분 가능하도록 표시하는 단계를 더 포함한다. 상기 컨텐츠와 관련된 동작을 수행하는 단계는, 상기 복수 객체 중 사용자입력에 따라 선택된 객체에 대응하는 상기 음원성분의 크기를 조정하는 동작을 수행하는 단계를 더 포함한다. 상기 컨텐츠와 관련된 동작을 수행하는 단계는, 상기 오디오신호의 프레임에 기초하여 상기 마이크 및 상기 음 원성분 간의 대응관계를 업데이트 하는 단계를 더 포함한다. 상기한 본 발명의 목적은, 컴퓨터가 읽을 수 있는 코드로서, 전자장치의 제어방법을 수행하는 코드를 포함하는 컴퓨터 프로그램이 저장된 기록매체에 있어서, 컨텐츠에 포함된 비디오신호에 기초하여 복수의 객체를 포함하는 영상을 표시하는 단계; 복수의 마이크로 획득된 상기 컨텐츠에 포함된 복수의 오디오신호로부터 주파수특성에 따라 복수의 음원성분을 획득하는 단계; 상기 컨텐츠의 재생 중에 상기 오디오신호와 상기 음원성분 간의 주파 수특성의 연관성에 기초하여 상기 복수의 마이크 중 상기 음원성분에 대응하는 오디오신호를 획득한 마이크를 식별하는 단계; 및 상기 복수의 마이크의 배치에 기초하여, 상기 표시되는 영상 내의 복수의 객체 중에서, 상기 식별된 마이크의 위치에 대응하는 어느 하나의 객체에 관하여 상기 컨텐츠와 관련된 동작을 수행하는 단계를 포 함하는 것을 특징으로 하는 컴퓨터가 읽을 수 있는 프로그램이 기록된 기록매체에 의해서도 달성될 수 있다."}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 복수의 음원에 대한 통합적 추적 및 음원의 이동에 대응한 적응적 추적이 가능하도록 하여, 음원추적 기능에 대한 효율성 및 활용성을 향상시킬 수 있는 전자장치 및 그 제어방법을 제공한다."}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 전자장치를 도시한다. 도 1에 도시된 바와 같이, 전자장치는 TV, 스마트폰, 태블릿, 휴대용 미디어 플레이어, 웨어러블 디바이스, 비디오 월, 전자액자 등과 같은 영상표시장치뿐만 아니라, 디스플레이를 구비하지 않는 셋탑박스 등의 영상 처리장치, 냉장고, 세탁기 등의 생활가전, 컴퓨터 본체와 같은 정보처리장치 등 다양한 종류의 장치로 구현된다. 또한, 전자장치는 인공지능 (Artificial Intelligence, AI) 기능을 탑재한 AI 스피커, AI 로봇 등으로 구현된다. 전자장치의 종류는 이에 한정되는 것은 아니며, 이하에서는 설명의 편의를 위해 전자장치 가 TV로 구현되는 경우를 가정한다. 전자장치는 비디오신호에 기초하여 영상을 표시한다. 영상은 디스플레이를 통해 출력된다. 비디 오신호는 다양한 컨텐츠의 비디오신호를 포함한다. 컨텐츠는 뉴스, 드라마, 영화 등과 같이 다양한 종류의 멀티 미디어 컨텐츠를 포함하나, 이에 한정되지 않는다. 영상 내에는 복수의 객체(1, 2, 3)가 포함된다. 객체는 사람, 동물, 사물 등을 포함하나, 이에 한정되지 않는다. 전자장치는 오디오신호에 기초한 오디오를 출력한다. 오디오는 스피커를 통해 출력된다. 스피커는 디스플레이장치에 마련된 내장 스피커 또는 외부에 마련된 외부 스피커를 포함한다. 다만, 설명의 편의를 위해 스피커는 내장 스피커인 것으로 가정한다. 오디오신호는 컨텐츠의 비디오신호에 대응하는 컨텐츠의 오 디오신호를 포함한다. 따라서, 오디오신호에 기초한 오디오는 비디오신호에 기초한 영상에 대응하여 출력된 다. 오디오신호는 다양한 종류의 컨텐츠의 오디오신호를 포함한다. 오디오신호에는 복수의 음원성분이 포함될 수 있다. 복수의 음원성분은 영상 내 복수의 객체(1, 2, 3)에 대 응되는 것일 수 있다. 전자장치는 오디오신호로부터 복수의 음원성분을 추출하고, 추출된 복수의 음원성분 및 복수의 객체(1, 2, 3) 간의 관계를 식별한다. 일 예로, 오디오신호로부터 추출된 제1음원성분, 제2음원성분 및 제3음원성분이 영상 내 제1객체, 제2객체 및 제3객체에 각각 대응됨을 식별할 수 있다. 전자장치는 음원성분 및 객체 간의 관계를 파악하기 위해서, 음원성분 및 오디오신호를 수신한 복수의 마이 크(도 6의 60) 간의 관계를 식별한다. 설명의 편의를 위해 도 6을 함께 참조하면, 전자장치는 복수의 마이 크로 획득된 오디오신호로부터 제1음성성분 내지는 제3음성성분를 추출하고, 추출된 제1음성성분 내지는 제 3음성성분이 복수의 마이크의 제1마이크(도 6의 61) 내지 제3마이크(도 6의 63)에 각각 대응됨을 식별할 수 있다. 좀더 구체적으로, 음원성분 및 마이크 간의 대응관계는, 음원성분 및 마이크로 획득된 오디오신호 간의 연관성 여부에 기초하여 식별될 수 있다. 일 예로, 제1음원성분 및 제1마이크로 획득된 오디오신호 간의 연관성이 높은 경우, 제1음원성분이 제1마이크에 대응하는 것으로 식별될 수 있다. 연관성 여부 식별에 대해서는 도 5를 참조하여 좀더 자세히 설명하기로 한다. 이와 같은 방법으로, 복수의 음원성분 및 복수의 마이크 간의 대응 관계가 식별될 수 있다. 전자장치는 마이크의 위치에 대응하는 객체를 식별함으로써, 음원성분 및 객체 간의 관계를 식별한다. 설명 의 편의를 위해 제1음원성분이 제1마이크에 대응하고, 제1객체가 제1마이크의 위치에 대응하는 것으 로 가정하면, 제1음성성분이 제1객체에 대응하는 것으로 식별될 수 있다. 마이크의 위치에 대응하는 객체를 식별함으로써, 음성성분 및 객체 간의 관계를 식별하는 과정에 대해서는, 도 3 및 6을 참조하여 좀더 자세히 설 명하기로 한다. 전자장치는 마이크의 위치에 대응하는 것으로 식별된 객체에 관하여 컨텐츠와 관련된 동작을 수행한다. 일 예로, 전자장치는 제1음원성분 및 제1객체 간의 대응관계가 식별된 경우, 제1음원성분 및 제1객체 간 의 대응관계를 나타내는 사용자인터페이스를 표시할 수 있다. 다만, 객체에 관하여 컨텐츠와 관련된 동작은상기한 바에 한정되는 것은 아니므로, 다양하게 구현될 수 있다. 이에 대해서는, 도 7 및 8을 참조하여 좀더 자 세히 설명하기로 한다. 이와 같이, 전자장치는 복수의 객체(1, 2, 3)를 포함된 영상을 표시하고, 복수의 마이크로 획득된 오디오신호에 기초하여 음원성분 별로 대응하는 객체를 식별하고, 식별된 객체에 관하여 컨텐츠와 관련된 다양 한 동작을 수행할 수 있다. 특히, 오디오신호를 획득한 복수의 마이크의 위치에 기초하여 음원성분 별로 대응하는 객체를 식별할 수 있 으므로, 음원성분에 대한 통합적 음원추적이 가능할 뿐만 아니라, 음원성분 및 객체 간의 관계에 대해 통합적 식별이 가능하다. 따라서, 단일 음원에 대한 개별적 음원추적에 비하여, 음원추적 기능에 대한 효율성 및 활용 성을 향상시킬 수 있다. 도 2는 도 1의 전자장치에 관한 구성의 일 예를 도시한다. 이하에서는 도 2를 참조하여, 전자장치의 구성에 관해 자세히 설명한다. 본 실시예서는 전자장치가 TV 인 경우에 관해 설명하지만, 전자장치는 다양한 종류의 장치로 구현될 수 있으므로, 본 실시예가 전자장치 의 구성을 한정하는 것은 아니다. 전자장치가 TV와 같은 디스플레이장치로 구현되지 않는 경우도 가능 하며, 이 경우 전자장치는 디스플레이와 같은 영상 표시를 위한 구성요소들을 포함하지 않을 수 있다. 예를 들면 전자장치가 셋탑박스로 구현되는 경우에, 전자장치는 인터페이스부를 통해 외부의 TV에 영상 신호를 출력한다. 전자장치는 인터페이스부를 포함한다. 인터페이스부는 외부장치 등과 연결하여 데이터를 송수 신한다. 다만 이에 한정되는 것은 아니므로, 인터페이스부는 네트워크로 연결된 다양한 장치와 연결한다. 인터페이스부는 유선 인터페이스부를 포함한다. 유선 인터페이스부는 지상파/위성방송 등 방송규격에 따른 방송신호를 수신할 수 있는 안테나가 연결되거나, 케이블 방송 규격에 따른 방송신호를 수신할 수 있는 케이블 이 연결될 수 있는 커넥터 또는 포트를 포함한다. 다른 예로서, 전자장치는 방송신호를 수신할 수 있는 안 테나를 내장할 수도 있다. 유선 인터페이스부는 HDMI 포트, DisplayPort, DVI 포트, 썬더볼트, 컴포지트 (Composite) 비디오, 컴포넌트(Component) 비디오, 슈퍼 비디오(Super Video), SCART 등과 같이, 비디오 및/또 는 오디오 전송규격에 따른 커넥터 또는 포트 등을 포함한다. 유선 인터페이스부는 USB 포트 등과 같은 범용 데 이터 전송규격에 따른 커넥터 또는 포트 등을 포함한다. 유선 인터페이스부는 광 전송규격에 따라 광케이블이 연결될 수 있는 커넥터 또는 포트 등을 포함한다. 유선 인터페이스부는 내부 오디오 수신부를 포함한다. 유선 인터페이스부는 유선 인터페이스부는 오디오 수신부 를 구비한 외부 오디오기기가 연결되며, 오디오기기로부터 오디오신호를 수신 또는 입력할 수 있는 커넥터 또는 포트 등을 포함한다. 유선 인터페이스부는 헤드셋, 이어폰, 외부 스피커 등과 같은 오디오기기가 연결되며, 오 디오기기로 오디오신호를 전송 또는 출력할 수 있는 커넥터 또는 포트 등을 포함한다. 유선 인터페이스부는 이 더넷 등과 같은 네트워크 전송규격에 따른 커넥터 또는 포트를 포함한다. 일 예로, 유선 인터페이스부는 라우터 또는 게이트웨이에 유선 접속된 랜카드 등으로 구현된다. 유선 인터페이스부는 상기 커넥터 또는 포트를 통해 셋탑박스, 광학미디어 재생장치와 같은 외부기기, 또는 외 부 디스플레이장치나, 스피커, 서버 등과 1:1 또는 1:N(N은 자연수) 방식으로 유선 접속됨으로써, 해당 외부기 기로부터 비디오/오디오신호를 수신하거나 또는 해당 외부기기에 비디오/오디오신호를 송신한다. 유선 인터페이 스부는, 비디오/오디오신호를 각각 별개로 전송하는 커넥터 또는 포트를 포함할 수도 있다. 유선 인터페이스부는 전자장치에 내장되거나, 동글(Dongle) 또는 모듈(Module) 형태로 구현되어 전자장치 의 커넥터에 착탈될 수도 있다. 인터페이스부는 무선 인터페이스부를 포함한다. 무선 인터페이스부는 전자장치의 구현 형태에 대응하여 다양한 방식으로 구현된다. 예컨대, 무선 인터페이스부는 통신방식으로 RF(Radio Frequency), 지그비(Zigbee), 블루투스(Bluetooth), 와이파이(Wi-Fi), UWB(Ultra-Wideband) 및 NFC(Near Field Communication) 등 무선통신 을 사용한다. 무선 인터페이스부는 와이파이 방식에 따라서 AP와 무선통신을 수행하는 무선통신모듈이나, 블루 투스 등과 같은 1대 1 다이렉트 무선통신을 수행하는 무선통신모듈 등으로 구현된다. 무선 인터페이스부는 네트워크 상의 외부장치와 무선 통신함으로써, 데이터 패킷을 송수신한다. 무선 인터 페이스부는 적외선 통신규격에 따라 IR(Infrared) 신호를 송신 및/또는 수신할 수 있는 IR송신부 및/또는 IR수 신부를 포함한다. 무선 인터페이스부는 IR송신부 및/또는 IR수신부를 통해 리모트 컨트롤러 또는 다른 외부기기로부터 리모트 컨 트롤러신호를 수신 또는 입력하거나, 리모트 컨트롤러 또는 다른 외부기기로 리모트 컨트롤러신호를 전송 또는 출력한다. 다른 예로서, 전자장치는 와이파이, 블루투스 등 다른 방식의 무선 인터페이스부를 통해 리모트 컨트롤러 또는 다른 외부기기와 리모트 컨트롤러신호를 송수신한다. 리모트 컨트롤러는 스마트폰 등을 포함하며, 스마트폰 등에는 리모트 컨트롤러 어플리케이션이 설치된다. 스마 트폰 등은 설치된 어플리케이션을 통해 리모트 컨트롤러의 기능, 예컨대, 전자장치를 제어하는 기능을 수행 한다. 이러한 리모트 컨트롤러 어플리케이션은 AI 스피커, AI 로봇 등 다양한 외부 장치에 설치된다. 전자장치는 인터페이스부를 통해 수신하는 비디오/오디오신호가 방송신호인 경우, 수신된 방송신호를 채널 별로 튜닝하는 튜너(Tuner)를 더 포함한다. 전자장치는 통신부를 포함한다. 통신부는 외부장치 등과 연결되어 비디오/오디오 신호를 전송 한다. 통신부는 설계 방법에 따라 유선 인터페이스부 또는 무선 인터페이스 중 적어도 하나의 구성을 포함 하며, 유선 인터페이스부 또는 무선 인터페이스 중 적어도 하나의 기능을 수행한다. 전자장치는 디스플레이를 포함한다. 디스플레이는 화면 상에 영상을 표시할 수 있는 디스플레이 패 널을 포함한다. 디스플레이 패널은 다양한 화면 크기를 가질 수 있다. 예컨대, 세로형, 가로형 등 서로 다른 화 면 크기를 갖는 다양한 형태로 마련될 수 있다. 디스플레이 패널은 액정 방식과 같은 수광 구조 또는 OLED 방식 과 같은 자발광 구조로 마련된다. 디스플레이는 디스플레이 패널의 구조에 따라서 부가적인 구성을 추가로 포함할 수 있는데, 예컨대, 디스플레이 패널이 액정 방식이라면, 디스플레이는 액정 디스플레이 패널과, 광 을 공급하는 백라이트유닛과, 액정 디스플레이 패널의 액정을 구동시키는 패널구동기판을 포함한다. 다만, 앞서 설명한 바와 같이, 디스플레이는 전자장치가 셋탑박스 등으로 구현되는 경우 생략된다. 전자장치는 사용자입력부를 포함한다. 사용자입력부는 사용자입력을 수신하기 위해 사용자가 조작 할 수 있도록 마련된 다양한 종류의 입력 인터페이스 관련 회로를 포함한다. 사용자입력부는 전자장치 의 종류에 따라서 여러 가지 형태의 구성이 가능하며, 예컨대, 전자장치의 기계적 또는 전자적 버튼부, 터 치패드, 디스플레이에 설치된 터치스크린 등이 있다. 전자장치는 스피커를 포함한다. 스피커는 오디오신호에 기초하여 오디오를 출력하는 스피커로 구현 될 수 있다. 스피커는 내부 스피커 또는 외부기기에 마련된 외부 스피커를 포함한다. 외부 스피커를 통해 오디 오가 출력되는 경우, 오디오신호가 인터페이스부를 통해 외부기기로 전송될 수 있다. 통신부, 디스플레이, 사용자입력부, 스피커 등은 인터페이스부와 별도의 구성으로 기재되 었으나, 설계 방법에 따라 인터페이스부에 포함되도록 구성될 수 있다. 전자장치는 저장부를 포함한다. 저장부는 디지털화된 데이터를 저장한다. 저장부는 전원의 제 공 유무와 무관하게 데이터를 보존할 수 있는 비휘발성 속성의 스토리지(Storage)를 포함한다. 스토리지는 플래 시메모리(Flash-Memory), HDD(Hard-Disc Drive), SSD(Solid-State Drive), ROM(Read Only Memory) 등을 포함 한다. 저장부는 프로세서에 의해 처리되기 위한 데이터 등이 로드 되며, 전원이 제공되지 않으면 데이터를 보 존할 수 없는 휘발성 속성의 메모리(Memory)를 포함한다. 메모리는 버퍼(Buffer), 램(Random Access Memory) 등을 포함한다. 전자장치는 프로세서를 포함한다. 프로세서는 인쇄회로기판 상에 장착되는 CPU, 칩셋, 버퍼, 회로 등 으로 구현되는 하나 이상의 하드웨어 프로세서를 포함하며, 설계 방식에 따라서는 SOC(System on Chip)로 구현 될 수도 있다. 프로세서는 전자장치가 디스플레이장치로 구현되는 경우에 디멀티플렉서, 디코더, 스케일 러, 오디오 DSP(Digital Signal Processor), 앰프 등의 다양한 프로세스에 대응하는 모듈들을 포함한다. 여기서, 이러한 모듈들 중 일부 또는 전체가 SOC로 구현된다. 예컨대, 디멀티플렉서, 디코더, 스케일러 등 영상 처리와 관련된 모듈이 영상처리 SOC로 구현되고, 오디오 DSP는 SOC와 별도의 칩셋으로 구현되는 것이 가능하다. 전자장치의 구성은 도 2에 도시된 바에 한정되는 것은 아니므로, 설계 방법에 따라 상기한 구성 중 일부를 제외하거나, 상기한 구성 이외의 구성을 포함한다. 일 예로, 전자장치는 카메라를 포함할 수 있다. 카메라는 전자장치의 전방을 촬영한다. 카메라에 의해 촬영된 영상에 사용자의 유무, 움직임 등이 식별될 수 있다. 카메라는 CMOS(Complementary Metal Oxide Semiconductor) 또는 CCD(Charge Coupled Device) 방식의 카메라로 구현된다. 카메라는 내부 카메라에 한정되는 것은 아니므로, 외부기기에 마련된 카메라를 포함한다. 이 경우, 인터페이스부를 통해 외부기기로부터 카메라에 의해 획득된 이미지신호가 수신 또는 입력될 수 있다. 전자장치는 오디오수신부를 구비할 수 있다. 오디오수신부는 전자장치의 본체 마련될 수 있지만, 이에 한정되는 것은 아니므로, 외부에 마련될 수도 있다. 오디오수신부를 통해 수신된 음성 명령에 대하여 음성인식 기능이 수행될 수 있다. 음성인식 기능은 음성 명령에 대하여 음성인식 처리를 수행하여, 인식 결과를 획득하고, 획득된 인식 결과에 대응하는 동작을 포함한다. 음성인식 처리는 음성 명령을 텍스트 데이터로 변환 하는 STT(Speech-to-Text) 처리 과정과, 텍스트 데이터가 나타내는 커맨드를 식별하여, 식별된 커맨드가 지시하 는 동작을 수행하는 커맨드 식별 및 수행 과정을 포함한다. 음성인식 처리는 전자장치에서 모두 실행될 수 있으나, 시스템 부하 및 소요 저장용량을 고려하여, 적어도 일부의 과정은 네트워크를 통해 전자장치와 통 신 가능하게 접속되는 적어도 하나의 서버에 의해 수행된다. 일 예로, 적어도 하나의 서버가 STT 처리 과정을 수행하고, 전자장치가 커맨드 식별 및 수행 과정을 수행한다. 또는, 적어도 하나의 서버가 STT 처리 과정과, 커맨드 식별 및 수행 과정을 모두 수행하고, 전자장치는 단지 적어도 하나의 서버로부터 결과를 수 신하기만 할 수도 있다. 한편, 음성 명령의 수신은 오디오수신부에 의해 수행될 수도 있지만, 본체와 분리된 리모트 컨트롤러를 통해 음 성 명령을 수신할 수도 있다. 리모트 컨트롤러은 앞서 설명한 바와 같이, 스마트폰을 포함한다. 리모트 컨트롤 러를 활용하는 경우, 리모트 컨트롤러로부터 음성 명령에 대응하는 음성 신호를 전달받고, 전달받은 음성 신호 에 대한 음성인식 처리를 수행한다. 전자장치의 프로세서는 상기한 동작들을 위한 데이터 분석, 처리, 및 결과 정보 생성 중 적어도 일부에 대하여, 규칙 기반 또는 AI 알고리즘을 이용한 AI 기술을 적용함으로써, AI 시스템을 구축한다. AI 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템으로서 기계가 스스로 학습하고 판단하며, 사용할수록 인식률이 향상되는 시스템이며, AI 알고리즘은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘이다. AI 기술은 기계학습, 신경망 네트워크(Neural Network), 또는 딥러닝 알고리즘 중 적어도 하나를 이용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 요소 기술들로 구성된다. 요소기술들은 인간의 언어/문자를 인식하는 언어적 이해 기술, 사물을 인간의 시각처럼 인식하는 시각적 이해 기술, 정보를 판단하여 논리적으로 추론하고 예측하는 추론/예측 기술, 인간의 경험 정보를 지식데이터로 처리 하는 지식 표현 기술 및 차량의 자율 주행, 로봇의 움직임을 제어하는 동작 제어 기술 중 적어도 하나를 포함할 수 있다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질 의 응답, 음성인식/합성 등을 포함한다. 시각적 이해는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험정보를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이 터 생성/분류), 지식 관리(데이터 활용) 등을 포함한다. 이하에서는 상기한 AI 알고리즘을 이용한 AI 기술이 전자장치의 프로세서에 의해 구현되는 일 예를 설명 한다. 프로세서는 학습부 및 인식부의 기능을 함께 수행한다. 학습부는 학습된 신경망 네트워크를 생성하는 기능을 수행하고, 인식부는 학습된 신경망 네트워크를 이용하여 데이터를 인식, 추론, 예측, 추정, 판단하는 기능을 수 행한다. 학습부는 신경망 네트워크를 생성하거나 갱신한다. 학습부는 신경망 네트워크를 생성하기 위해서 학습 데이터를 획득한다. 일 예로, 학습부는 학습 데이터를 저장부로부터 획득하거나, 외부로부터 획득한다. 학습 데이터 는, 신경망 네트워크의 학습을 위해 이용되는 데이터일 수 있으며, 상기한 동작을 수행한 데이터를 학습데이터 로 이용하여 신경망 네트워크를 학습시킬 수 있다. 학습부는 학습 데이터를 이용하여 신경망 네트워크를 학습시키기 전에, 획득된 학습 데이터에 대하여 전처리 작 업을 수행하거나, 또는 복수 개의 학습 데이터들 중에서 학습에 이용될 데이터를 선별한다. 일 예로, 학습부는 학습 데이터를 기 설정된 포맷으로 가공하거나, 필터링하거나, 또는 노이즈를 추가/제거하여 학습에 적절한 데 이터의 형태로 가공한다. 학습부는 전처리된 학습 데이터를 이용하여 상기한 동작을 수행하도록 설정된 신경망네트워크를 생성한다. 학습된 신경망 네트워크는, 복수의 신경망 네트워크 또는 레이어들로 구성된다. 복수의 신경망 네트워크의 노드 들은 가중치를 가지며, 복수의 신경망 네트워크들은 일 신경망 네트워크의 출력 값이 다른 신경망 네트워크의 입력 값으로 이용되도록 서로 연결된다. 신경망 네트워크의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN (Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크 (Deep Q- Networks)과 같은 모델을 포함한다. 한편, 인식부는 상기한 동작을 수행하기 위해, 타겟 데이터를 획득한다. 타겟 데이터는 저장부로부터 획득 하거나, 외부로부터 획득한다. 타겟 데이터는 신경망 네트워크의 인식 대상이 되는 데이터일 수 있다. 인식부는 타겟 데이터를 학습된 신경망 네트워크에 적용하기 전에, 획득된 타겟 데이터에 대하여 전처리 작업을 수행하거 나, 또는 복수 개의 타겟 데이터들 중에서 인식에 이용될 데이터를 선별한다. 일 예로, 인식부는 타겟 데이터를 기 설정된 포맷으로 가공하거나, 필터링 하거나, 또는 노이즈를 추가/제거하여 인식에 적절한 데이터의 형태로 가공한다. 인식부는 전처리된 타겟 데이터를 신경망 네트워크에 적용함으로써, 신경망 네트워크로부터 출력되는 츨력값을 획득한다. 인식부는 출력값과 함께, 확률값 또는 신뢰도값을 획득한다. 도 3은 도 1의 전자장치에 관한 구성의 구체적인 예를 도시한다. 이하에서는 도 3을 참조하여, 전자장치의 구성의 구체적인 예에 관해 자세히 설명한다. 이하에서 설명되는 각 구성의 동작은 프로세서가 저장부에 저장된 프로그램을 실행하는 과정을 역할 별로 구분한 동작일 수 있다. 전자장치는 주파수 분석부를 포함한다. 주파수 분석부는 컨텐츠의 오디오신호에 대한 주파수분석을 수행한다. 오디오신호는 컨텐츠의 비디오신호에 대응하는 오디오신호로서, 제1마이크 내지 제3마이크를 포함하는 복수의 마이크를 통해 획득된 것일 수 있다. 주파수분석은 오디오신호에 대한 주파수특성에 대한 분석을 포함한다. 주파수특성은 오디오신호의 주파수성분에 대한 패턴, 파형, 주기, 세기 등을 포함한다. 주파 수 분석부는 오디오신호에 대한 주파수분석 결과를 음원성분 분석부에 제공한다. 주파수 분석부는 복수의 마이크 별로 획득된 오디오신호에 대해 주파수분석을 수행한다. 일 예로, 주파 수 분석부는 제1마이크로 수신된 오디오신호, 제2마이크로 수신된 오디오신호 및 제3마이크로 수신된 오디오신호에 대하여 주파수분석을 수행한다. 주파수분석은 복수의 마이크 별로 획득된 오디오신호 의 주파수성분에 대한 패턴, 파형, 주기, 세기 등에 대한 분석을 포함한다. 주파수분석 결과는 복수의 마이크 별 오디오신호에 대한 게인, 세기 등이 적절하게 조정된 것일 수 있으며, 필요에 따라 샘플링 처리된 것일 수 있다. 복수의 마이크 별 오디오신호에 대한 주파수분석 결과를 연관성 분석부에 제공한다. 전자장치는 음원성분 분석부를 포함한다. 음원성분 분석부는 주파수 분석부로부터 오디오신호 에 대한 주파수분석 결과를 수신한다. 음원성분 분석부는 오디오신호에 대한 주파수분석 결과에 기초하여 오디오신호로부터 복수의 음원성분을 분리한다. 음원성분 분석부는 복수의 음원성분 별로 주파수특성이 서 로 다를 수 있는 점을 고려하여, 예컨대, 특정 주파수성분에 대응되는지 여부에 따라 복수의 음원성분을 분리할 수 있다. 음원성분의 분리를 위해 인디펜던트 콤포넌트 아날리시스(Independent Component Analysis: ICA), 지 오메트릭 소스 세퍼레이션(Geometric Source Separation: GSS) 등과 같은 브라인드 소스 세퍼레이션(Blind Source Separation: BBS) 알고리즘이 사용될 수 있으나, 이에 한정되는 것은 아니다. 음원성분 분석부는 분 리된 복수의 음원성분에 관한 정보를 연관성 분석부에 제공한다. 전자장치는 연관성 분석부를 포함한다. 연관성 분석부는 주파수 분석부로부터 복수의 마이크 별 오디오신호에 대한 주파수분석 결과를 수신하고, 음원성분 분석부로부터 복수의 음원성분에 관한 정보를 수신한다. 연관성 분석부는 복수의 마이크 별 오디오신호에 대한 주파수분석 결과 및 복수의 음 원성분에 관한 정보를 활용하여, 음원성분 및 마이크의 오디오신호 간의 연관성을 분석한다. 연관성 분석은, 예 컨대, 제1마이크의 오디오신호에 대하여 제1음원성분이 가장 주요하거나(dominant), 주요한 영향을 미친다 면, 제1음원성분이 제1마이크의 오디오신호에 대하여 주파수특성에 있어서 관련성, 유사성 등이 가장 높을 것이라는 원리에 기초한다. 이러한 연관성 분석은 하기의 수학식[1]에 기초하여 수행될 수 있다. 수학식[1] 수학식[1]은 (t)번째 마이크의 오디오신호와 (n)번째 음원성분 간의 연관계수(R)를 의미하고, (*)는 오디오신호 가 복소수인 경우, 공액 복소수를 의미한다. 연관계수(R)의 계산은 주파수대역 별로 수행될 수 있다. 연관성 분석부는 수학식[1]을 활용하여 연관계수(R)를 계산하고, 각 마이크의 오디오신호에 대하여 연관계 수(R)가 가장 높은 음원성분을 식별한다. 설명의 편의를 위해 제1마이크의 오디오신호에 대하여 연관계수 (R)가 가장 높은 음원성분은 제1음원성분인 것으로 가정한다. 제1마이크의 오디오신호 및 제1음원성분 간의 연관계수(R)가 가장 높다는 것은, 제1마이크의 오디오신호에서 제1음원성분이 가장 주요한 음원성분이므로, 제1음원성분 및 제1마이크의 오디오신호 간의 연관성이 가장 높음을 의미한다. 연관성 분석부는 수학식"}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "[1]을 통해 계산된 제1음원성분 및 제1마이크의 오디오신호 간의 연관계수(R)에 기초하여 제1음원성분 및 제1마이크의 오디오신호 간의 관계를 식별할 수 있다. 연관성 분석부는 연관계수(R)를 계산함에 있어서, 하기의 수학식[2]를 활용하여 수학식[1]에 대한 표준화를 수행할 수 있다. 수학식[2]"}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식[2]를 수학식[1]로 나누면, 수학식[1]에 대한 표준화가 수행된 연관계수(N)가 얻어질 수 있다. 연관계수 (N)를 활용하면, 복수의 마이크 별 오디오신호에서 특정 음원성분이 편향되어 식별되는 현상을 방지할 수 있다. 특정 음원성분은 주파수의 크기, 세기 등이 다른 음원성분보다 큰 음원성분을 포함할 수 있다. 복수의 마 이크 별 오디오신호에서 음원성분의 편향 현상이 방지됨으로써, 음원성분 및 마이크의 오디오신호 간의 관 계에 대한 식별 정확도가 향상될 수 있다. 연관성 분석부는 연관성 분석을 통해 음원성분 및 마이크의 오디오신호 간의 관계를 식별하고, 음원성분 및 마이크의 오디오신호 간의 관계에 따라 음원성분 및 마이크 간의 관계를 식별한다. 일 예로, 연관성 분석부(3 3)는 제1음원성분 및 제1마이크의 오디오신호 간의 관계에 따라 제1음원성분 및 제1마이크의 관계를 식 별할 수 있다. 연관성 분석부는 음원성분 및 마이크 간의 관계에 관한 정보를 위치 추적부에 제공한다. 전자장치는 위치 추적부를 포함한다. 위치 추적부는 연관성 분석부로부터 음원성분 및 마이크 간의 관계에 관한 정보를 수신한다. 위치 추적부는 음원성분 및 마이크 간의 관계에 관한 정보 및 마이크의 위치에 관한 정보를 활용하여 음원성분에 대응하는 객체를 식별한다. 마이크의 위치에 관한 정보는 오디오신호 와 함께 또는 별도로 수신된 것일 수 있다. 이하에서는 도 6을 함께 참조하여, 위치 추적부가 제1음원성분에 대응하는 제1객체를 식별하는 과정에 대해 설명한다. 다만, 이는 설명의 편의를 위한 것이므로, 이하에서 설명하는 방법과 동일한 방법으로 복수의 음원성분 및 복수의 객체(1, 2, 3) 간의 관계가 식별될 수 있다. 도 6에 도시된 바와 같이, 복수의 실제 객체(도 6의 71, 72, 73)를 촬영한 영상이 디스플레이에 표시될 수 있다. 영상에는 복수의 실제 객체(71, 72, 73)에 대응하는 복수의 객체(1, 2, 3)가 표시된다. 복수의 실 제 객체(71, 72, 73)가 발화한 제1음원성분 내지 제3음원성분의 오디오는 복수의 마이크를 통해 오디오신호 로 수신된다. 위치 추적부는 복수의 마이크의 배치 환경 정보에 기초하여 복수의 마이크 중 제1마이크의 위 치를 식별한다. 복수의 마이크의 배치 환경 정보는 앞서 설명한 마이크의 위치에 관한 정보에 포함된 것일 수 있다. 위치 추적부는 복수의 마이크의 배치 환경 정보에 기초하여 복수의 마이크가 동일한 각도 를 가지고 원형으로 배치되고, 제1마이크가 복수의 마이크 중에서 가장 좌측에 위치한다고 식별될 수 있다. 위치 추적부는 제1음원성분 내지 제3음원성분을 발화한 실제 복수의 객체(71, 72, 73)의 위치를 식별하고, 실제 복수의 객체(71, 72, 73) 중 제1마이크의 위치로부터 가장 가까운 위치에 있는 제1실제 객체를 식 별할 수 있다. 위치 식별은 거리 또는 방향 중 적어도 하나에 대한 식별을 포함한다. 위치 추적부는 실제 제1객체의 위치를 식별하기 위해 하기의 수학식[3]를 활용한다. 수학식[3]"}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식[3]에서, 은 제1마이크로 획득된 오디오신호의 주파수영역의 신호이고, 는 제2마 이크로 획득된 오디오신호의 주파수영역의 신호이다. 소정 주파수대역에서 을 최대로 만드는 t 의 값이 제1마이크 및 제2마이크에 도달하는 오디오신호의 시간차이다. 수학식[3]은 실제 제1객체의 위치 추적을 위해 통상적으로 활용되는 상호상관함수 (Genaralized Cross- Correlation: GCC)의 GCC-PHAT 값과 관련된다. 따라서, 소정 주파수대역 별로 t의 값을 변화시켜가면서 수학식"}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "[3]의 값이 최대가 되는 t의 값을 계산한다. 주파수대역마다 t의 값이 다를 수 있는데, 이는 주파수대역마다 잡 음, 그 외에 측정 오차 등의 외부 요인에 의한 것이다. 따라서, 주파수대역 별로 t의 값의 변화에 따라 GCC- PHAT 값의 변화를 살펴보면서, GCC-PHAT 값이 최대가 되는 t의 값을 계산한다. 실제 제1객체의 위치는 계산된 t의 값에 따른 시간차에 기초하여 식별될 수 있다. 실제 제1객체에 좀더 가까운 제1마이크로 실제 제1객체의 오디오신호가 먼저 수신되고, 제2마이크로 t의 값만큼 늦게 수 신된다고 가정한다. 실제 제1객체의 위치는 제1마이크 및 제2마이크와, 실제 제1객체 간의 각 도 θ를 계산함으로써 알아낼 수 있다. 실제 제1객체로부터 제1마이크까지의 거리와 실제 제1객체 로부터 제2마이크까지의 거리의 차(△S)는 하기의 수학식[4]와 같이 표현될 수 있다. 수학식[4]"}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "(v)는 오디오신호의 속도이고, (d)는 제1마이크 및 제2마이크의 배치 거리를 나타낸다. 복수의 마이크 의 배치 형태는 제1마이크 및 제2마이크가 동일한 각도를 가지고 원형으로 배치된 형태를 가정한 바 있으나, 이에 한정되는 것은 아니므로, 동일한 간격으로 가지고 직선으로 배치된 형태를 포함한다. 따라서, 제1마이크 및 제2마이크와, 실제 제1객체 간의 각도 θ는 하기의 수학식[5]를 통해 계산될 수 있다. 수학식[5]"}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식[5]에 의해 계산된 각도 θ에 기초하여 실제 제1객체의 위치를 추정할 수 있다. 마찬가지의 방법으로 실제 제2객체 및 실제 제3객체의 위치를 추정할 수 있다. 위치 추적부는 수학식[3] 내지 수학식"}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "[5]를 활용함으로써, 복수의 실제 객체(71, 72, 73)의 위치를 식별할 수 있다. 이상의 위치 추적 원리는 3차원 공간 상에서 적용 가능하다. 마이크의 개수를 늘리면 3차원 공간 상에서 각 객체의 위치를 추정할 수 있다. 위치 추적부는 영상 내 복수의 객체(1, 2, 3) 중에서 제1실제 객체에 대응하는 제1객체를 식별할 수 있다. 이를 위해, 위치 추적부는 영상 내에서 복수의 마이크에 대응하는 가상 마이크의 위치 를 식별한다. 가상 마이크의 위치에 관한 정보는 마이크의 위치에 관한 정보에 포함될 수 있다. 설계 방법 에 따라, 가상 마이크의 위치는 영상이 표시된 화면의 중앙 하측으로 설정될 수 있으나, 이에 한정되는 것은 아니다. 설명의 편의를 위해 가상 마이크의 위치가 도 6에 도시된 바와 같다고 가정하면, 위치 추적부는 가상 마이크 중 제1마이크에 대응하는 제1가상 마이크의 위치로부터 가장 가까운 위치에 있는 제1객체 가 제1실제 객체에 대응하는 것으로 식별할 수 있다. 위치 추적부는 제1실제 객체에 대응하는 제1객체를, 제1음원성분에 대응하는 제1객체로 식별할 수 있다. 음원성분 및 객체 간의 관계는 업데이트될 수 있다. 일 예로, 실제 제1객체가 이동함에 따라 제1객체에 대응하는 제1음원성분과 연관성이 높은 마이크의 오디오신호가 변하는 경우에, 제1음원성분 및 제1객체 간의 관계가 업데이트될 수 있다. 좀더 구체적으로, 연관성 분석부는 오디오신호의 프레임 별로 연관성 분석을 수행하고, 연관성 분석을 통해 제1음원성분 및 제1마이크 간의 관계를 제1음원성분 및 제3마이크로 업 데이트 할 수 있다. 연관성 분석부는 업데이트된 제1음원성분 및 제3마이크의 관계에 관한 정보를 위치추적부에 제공할 수 있다. 위치 추적부는, 앞서 제1마이크의 위치에 기초하여 제1음원성분에 대응하는 실제 제1객체의 위치를 식별한 것처럼, 제3마이크의 위치에 기초하여 제1음원성분에 대응하는 실제 제1객체의 업데이트된 위치 를 식별할 수 있다. 위치 추적부는 제1실제 객체의 업데이트된 위치를 식별하기 위해 하기의 수학식"}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "[6]을 활용한다. 수학식[6]"}
{"patent_id": "10-2020-0151797", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "수학식[6]에 따라, 위치 추적부는 오디오신호의 이전 프레임에 기초한 실제 객체의 위치를 새로운 프레임에 기초하여 업데이트된 실제 객체의 위치를 식별할 수 있다. 수학식[6]에서 (α)는 잡음, 외부 요인 등을 고려하 기 위함이다. 위치 추적부는 음원추적 모델을 활용하여 실제 객체의 위치를 식별할 수 있다. 음원추적 모델은 음원성분 별로 마련될 수 있으며, 수학식[6]에 기초하여 마련될 수 있다. 일 예로, 위치 추적부는 제1음원성분에 대 응하는 제1음원추적 모델을 생성하고, 제1음원추적 모델에 기초하여 제1음원성분에 대응하는 실제 제1객체 의 업데이트된 위치를 추적할 수 있다. 위치 추적부는 실제 제1객체의 업데이트된 위치를 식별하고, 업데이트된 제1음원성분 및 제3마이크(6 3)의 관계에 기초하여 제3마이크에 가장 가까운 실제 제1객체가 제1음원성분에 대응함을 식별할 수 있 다. 위치 추적부는 가상 마이크 중 제3마이크에 대응하는 제3가상 마이크의 위치로부터 가장 가까 운 위치에 있는 제1객체가 제1실제 객체에 대응하는 것으로 식별할 수 있다. 위치 추적부는 제1실제 객체가 이동하더라도, 제1음원성분 및 제1실제 객체 간의 관계에 기초하여 제1음원성분에 대응하는 제1 객체를 식별할 수 있다. 전자장치는 동작 수행부를 포함한다. 동작 수행부는 식별된 객체에 관하여 컨텐츠와 관련된 동작 을 수행한다. 일 예로, 제1음원성분의 오디오가 스피커를 통해 출력되는 경우, 동작 수행부는 출력되는 오디오의 제1음원성분이 제1객체에 대응하는 것임을 나타내는 사용자인터페이스를 표시할 수 있다. 다만, 이에 한정되는 것은 아니므로, 동작 수행부는 제1음원성분 및 제1객체 간의 관계에 기초한 다양한 동작 을 수행할 수 있다. 이와 같이, 전자장치는 복수의 객체(1, 2, 3)를 포함된 영상을 표시하고, 복수의 마이크로 획득된 오디오신호에 기초하여 음원성분 별로 대응하는 객체를 식별하고, 식별된 객체에 관하여 컨텐츠와 관련된 다양 한 동작을 수행할 수 있다. 전자장치는 오디오신호를 획득한 복수의 마이크의 위치에 기초하여 음원성분 별로 대응하는 객체를 식 별할 수 있으므로, 음원성분 및 객체 간의 관계에 대해 통합적 식별이 가능할 뿐만 아니라, 객체의 이동에 따라 음원성분 및 객체 간의 관계에 대해 적응적 식별이 가능하다. 도 4는 도 1의 전자장치에 대한 제어방법의 일 예를 도시한다. 프로세서는 컨텐츠에 포함된 비디오신호에 기초하여 복수의 객체를 포함하는 영상을 표시한다(S41). 일 예로, 영상 내에는 복수의 객체(1, 2, 3)가 포함될 수 있다. 프로세서는 복수의 마이크로 획득된 컨텐츠에 포함된 복수의 오디오신호로부터 주파수특성에 따라 복수 의 음원성분을 획득한다(S42). 프로세서는 컨텐츠의 재생 중에 음원성분 및 마이크의 오디오신호 간에 기초하여 복수의 마이크 중 음원 성분에 대응하는 오디오신호를 획득한 마이크를 식별한다(S43). 일 예로, 프로세서는 연관성 분석을 통해 연 관계수가 가장 높은 제1음원성분 및 제1마이크의 오디오신호 간의 관계를 식별할 수 있다. 프로세서는 복수 마이크의 배치에 기초하여, 영상 내의 복수의 객체(1, 2, 4) 중에서, 식별된 음원성 분에 대응하는 마이크의 위치에 대응하는 어느 하나의 객체에 관하여 컨텐츠와 관련된 동작을 수행한다(S44). 일 예로, 프로세서는 복수의 마이크의 배치 환경에 기초하여 영상 내에서 제1마이크의 위치에 대 응하는 제1객체를 식별한다. 이와 같이, 전자장치는 오디오신호를 획득한 복수의 마이크의 위치에 기초하여 음원성분 별로 대응하는 객체를 식별할 수 있으므로, 음원성분 및 객체 간의 관계에 대해 통합적 식별이 가능할 뿐만 아니라, 객체의 이 동에 따라 음원성분 및 객체 간의 관계에 대해 적응적 식별이 가능하다. 도 5는 도 4의 동작 S43과 관련하여, 음원성분 및 마이크의 오디오신호 간에 기초하여 음원성분 및 마이크 간의 대응관계를 식별하는 구체적인 예를 도시한다. 프로세서는 복수의 마이크를 통해 수신된 오디오신호로부터 복수의 음원성분을 추출하고, 복수의 음원성 분 및 복수의 마이크의 오디오신호 간의 연관성을 분석한다. 설명의 편의를 위해 오디오신호로부터 추출된 제1음원성분 내지 제3음원성분의 주파수성분이 도 5에 도시된 바와 같다고 가정한다. 프로세서는 복수의 음원성분 중에서 제1마이크로 획득된 오디오신호의 주파수성분과 유사한 주파수성분 을 가진 제1음원성분을 식별한다. 프로세서는 주파수성분 간의 유사도뿐만 아니라, 주파수성분의 크기에 기 초하여 제1마이크의 오디오신호에 대응하는 제1음원성분을 식별할 수 있다. 일 예로, 프로세서는 제1마 이크의 오디오신호의 주파수성분과 동일한 주파수대역에서 주파수성분의 크기가 큰 제1음원성분을 식별할 수 있다. 프로세서는 연관성 분석을 통해 제1음원성분이 제1마이크의 오디오신호에 대응하는 것으로 식별하면, 제 1음원성분이 제1마이크에 대응하는 것으로 식별할 수 있다. 동일한 방법으로, 프로세서는 제2음원성분이 제2마이크에 대응하고, 제3음원성분이 제3마이크에 대응하는 것으로 식별할 수 있다. 이와 같이, 프로세서는 음원성분 및 마이크로 수신된 오디오신호 간의 주파수특성의 연관성에 기초하여 음원 성분 및 마이크 간의 대응관계를 식별할 수 있다. 따라서, 이하에서 도 6을 참조하여 설명할 음원성분 및 객체 간의 관계를 식별할 수 있는 여건을 마련할 수 있다. 도 6은 도 4의 동작 S44와 관련하여, 음원성분에 대응하는 마이크의 위치에 기초하여 음원성분 및 객체 간의 관 계를 식별하는 구체적인 예를 도시한다. 프로세서는 복수의 객체(1, 2, 3)을 포함하는 영상을 디스플레이에 표시한다. 설명의 편의를 위해 도 6에 도시된 바와 같이, 실제 해변을 촬영한 영상이 디스플레이에 표시되고, 실제 해변에는 실제 복수의 객 체(71, 72, 73)가 있다고 가정한다. 또한, 실제 제1객체는 실제 해변의 좌측에, 실제 제2객체는 중앙 상측에, 실제 제3객체는 우측에 있다고 가정한다. 실제 해변 촬영 시 실제 복수의 객체(71, 72, 73)로부터 발화된 오디오의 오디오신호는 복수의 마이크를 통 해 수신된다. 복수의 마이크는 제1마이크, 제2마이크 및 제3마이크가 동일한 각도로 배치된 마 이크 어레이를 포함하며, 실제 해변의 중앙 하측에 있다. 제1마이크, 제2마이크 및 제3마이크는 실 제 제1객체, 실제 제2객체 및 제3객체에 각각 근접하도록 배치된 것으로 가정한다. 프로세서는 오디오신호와 함께 또는 별도로 복수의 마이크의 배치 환경 정보를 수신할 수 있다. 앞서 도 5를 참조하여 설명한 바와 같이, 프로세서는 음원성분 및 마이크의 오디오신호 간의 연관성 분석을 통해 음원성분 및 마이크 간의 관계를 식별한다. 일 예로, 프로세서는 제1음원성분이 제1마이크에 대응 하고, 제2음원성분이 제2마이크에 대응하고, 제3음원성분이 제3마이크에 대응하는 것으로 식별할 수 있 다. 프로세서는 복수의 마이크의 배치 환경 정보 및 연관성 분석을 통해 식별된 음원성분 및 마이크 간의 관 계에 관한 정보에 기초하여 음원성분에 대응하는 영상 내의 객체를 식별한다. 좀더 구체적으로, 프로세서 는 복수의 마이크의 배치 환경 정보에 기초하여 복수의 마이크 중 제1마이크의 위치를 식별한다. 일 예로, 프로세서는 제1마이크가 복수의 마이크 중에서 가장 좌측에 위치한다고 식별될 수 있다. 프로세서는 제1음원성분 내지 제3음원성분을 발화한 실제 복수의 객체(71, 72, 73)의 위치를 식별하고, 실제 복수의 객체(71, 72, 73) 중 제1마이크의 위치로부터 가장 가까운 위치에 있는 제1실제 객체를 식별할 수 있다. 프로세서는 제1음원성분이 제1실제 객체로부터 발화된 것임을 식별할 수 있다. 프로세서는 영상 내 복수의 객체(1, 2, 3) 중에서 제1실제 객체에 대응하는 제1객체를 식별한다. 이를 위해, 프로세서는 영상 내에서 복수의 마이크에 대응하는 가상 마이크의 위치를 식별한다. 설계 방법에 따라, 가상 마이크의 위치는 복수의 마이크의 위치에 대응하도록, 영상이 표시된 화면 의 중앙 하측으로 설정될 수 있으나, 이에 한정되는 것은 아니다. 가상 마이크의 위치가 도 6에 도시된 바와 같다고 가정하면, 프로세서는 가상 마이크 중 제1마이크 에 대응하는 제1가상 마이크의 위치로부터 가장 가까운 위치에 있는 제1객체가 제1실제 객체에 대응하는 것으로 식별할 수 있다. 프로세서는 제1음원성분 및 제1실제 객체 간의 관계에 기초하여 제1음 원성분에 대응하는 제1객체를 식별할 수 있다. 동일한 방법으로, 프로세서는 제3음원성분은 제3마이크에 대응하고, 제3마이크의 위치에 가장 근접 한 제3실제 객체가 영상 내 제3객체에 대응하고, 결과적으로 제3객체가 제3음원성분에 대응함을 식별할 수 있다. 이와 같이, 프로세서는 오디오신호를 획득한 복수의 마이크의 위치에 기초하여 음원성분 별로 대응하는 객체를 식별할 수 있으므로, 음원성분 및 객체 간의 관계에 대해 통합적 식별이 가능하다. 도 7은 도 4의 동작 S44와 관련하여, 마이크의 위치에 대응하는 객체에 관하여 컨텐츠와 관련된 동작의 일 예로 서, 음원성분에 대응하는 객체를 구분하여 표시하는 구체적인 예를 도시한다. 설명의 편의를 위해 도 7에 도시된 바와 같이, 영상 내 제1객체가 제1음원성분에 대응하는 것으로 가정한 다. 프로세서는 제1객체를 영상 내 다른 객체인 제2객체 및 제3객체와 구별되도록 표시할 수 있 다. 제2객체 및 제3객체는 제1음원성분에 대응하지 않으며, 제2음원성분 및 제3음원성분에 각각 대응할 수 있다. 프로세서는 제1객체를 강조하는 효과를 적용함으로써, 제1객체가 다른 객체와 구별되도록 할 수 있다. 마찬가지로, 프로세서는 제2음원성분에 대응하는 제2객체 또는 제3음원성분에 대응하는 제3객체 에 대해서도 영상 내 다른 객체와 구별되도록 표시할 수 있다. 프로세서는 복수의 객체(1, 2, 3) 별로 서로 다른 효과가 적용되도록 함으로써, 복수의 객체(1, 2, 3) 상호 간에 구별이 가능하도록 할 수 있다. 일 예로, 프로세서는 상호 간에 적용되는 색상, 크기, 그라데이션, 블 러링 등을 다르게 함으로써, 상호 간에 구별이 가능하도록 할 수 있다. 프로세서는 제1객체가 제1음원성분에 대응하는 제1마이크에 의해서도 구별 가능하도록 표시할 수 있 다. 일 예로, 프로세서는 영상 내 복수의 객체(1, 2, 3) 중에서 제1객체가 제1마이크에 대응하는 것으로 식별하고, 제1객체가 다른 객체와 구별되도록 표시함으로써, 제1객체를 제1마이크에 대응하지 않는 제2객체 및 제3객체와 구별할 수 있다. 이와 같이, 프로세서는 음원성분 및 객체 간의 관계에 기초하여 음원성분에 대응하는 객체를 다른 객체와 구 별되도록 표시할 수 있다. 따라서, 음원성분 및 객체 간의 관계에 대한 통합적 식별 및 적응적 식별 여부를 시 각적 정보로 제공할 수 있다. 도 8은 도 4의 동작 S44와 관련하여, 마이크의 위치에 대응하는 객체에 관하여 컨텐츠와 관련된 동작의 다른 예 로서, 마이크 및 객체 간의 상호 위치 관계를 나타내는 구체적인 예를 도시한다. 앞서 도 6을 참조하여, 프로세서가 복수의 마이크의 위치에 관한 정보를 활용하여, 복수의 마이크 및 복수의 실제 객체(71, 72, 73) 간의 관계를 식별하고, 복수의 마이크 및 영상 내 복수의 객체(1, 2, 3) 간의 관계를 식별할 수 있음을 설명한 바 있다. 이 경우, 프로세서는 복수의 마이크 및 복수의 실제 객체(71, 72, 73) 간의 상호 위치 관계를 식별할 수 있다. 일 예로, 프로세서는 제1실제 마이크의 위치는 제1객체의 위치와 가장 근접함을 식별할 수 있 다. 프로세서는 복수의 마이크 및 복수의 실제 객체(71, 72, 73) 간의 상호 위치 관계에 기초하여 복수의 마 이크 및 복수의 객체(1, 2, 3) 간의 상호 위치 관계를 식별할 수 있다. 일 예로, 프로세서는 제1실제 마 이크에 대응하는 영상 내의 가상 제1마이크의 위치는 제1실제 객체에 대응하는 제1객체의 위 치와 가장 근접함을 식별할 수 있다. 프로세서는 영상 내의 가상 제1마이크 및 제1객체 간의 상호 위치를 나타내는 사용자인터페이스 를 표시할 수 있다. 일 예로, 프로세서는 화살표 등을 통하여 영상 내의 가상 제1마이크의 위치에 제1객체의 위치가 가장 근접함을 나타낼 수 있다. 이와 같이, 프로세서는 객체에 관하여 컨텐츠와 관련된 동작으로서, 마이크 및 객체 간의 상호 위치 관계를 나타내는 사용자인터페이스를 표시할 수 있다. 따라서, 마이크 및 객체 간의 관계에 대한 통합적 식별 및 적 응적 식별 여부를 시각적 정보로 제공할 수 있다. 도 9는 도 4의 동작 S44와 관련하여, 음원성분에 대한 이벤트에 대응하여 컨텐츠와 관련된 동작을 수행하는 구 체적인 예를 도시한다. 프로세서는 음원성분에 대한 이벤트 여부를 식별한다. 일 예로, 복수의 음원성분 중 적어도 하나를 선택할 수 있는 사용자인터페이스를 표시하고, 사용자입력에 따라 음원성분이 선택되면, 이를 음원성분에 대한 이벤트 로 식별할 수 있다. 다만, 음원성분에 대한 이벤트가 사용자입력에 따른 음원성분의 선택에 한정되는 것은 아니 다. 프로세서는 음원성분에 대한 이벤트에 대응하여, 음원성분에 기초한 동작을 수행한다. 일 예로, 음원성분에 기초하여 오디오를 출력할 수 있다. 설명의 편의를 위해 사용자입력에 따라 제1음원성분이 선택된 경우를 가정 하면, 제1음원성분에 기초한 오디오가 스피커를 통해 출력될 수 있다. 음원성분에 기초한 동작은 음원성분에 대응하는 객체에 관한 동작을 포함한다. 일 예로, 도 7을 참조하여 설명 한 바와 같이, 프로세서는 제1음원성분에 대응하는 제1객체가 다른 객체와 구별되도록 제1객체을 강조 하는 효과를 적용하거나, 도 8을 참조하여 설명한 바와 같이, 제1음원성분에 대응하는 제1객체 및 제1마 이크 간의 상호 위치 관계를 나타내는 사용자인터페이스를 표시할 수 있다. 이와 같이, 프로세서는 음원성분에 대한 이벤트에 대응하여 음원성분에 대응하는 객체에 관하여 다양한 동작 을 수행할 수 있다. 따라서, 음원성분 및 객체 간의 관계에 대한 통합적 식별 및 적응적 식별 여부를 더욱 다양 한 시각적 정보로 제공할 수 있다. 도 10은 도 4의 동작 S44와 관련하여, 객체에 대한 이벤트에 대응하여 컨텐츠와 관련된 동작을 수행하는 구체적 인 예를 도시한다. 앞서 도 9를 참조하여 음원성분에 대한 이벤트에 대응하여 수행되는 동작에 대해 설명하였으나, 이하에서는 도 10을 참조하여, 객체에 대한 이벤트에 대응하여 수행되는 동작에 대해 설명한다. 프로세서는 객체에 대한 이벤트 여부를 식별한다. 일 예로, 영상 내 복수의 객체(1, 2, 3) 중 적어도 하 나를 선택할 수 있는 사용자인터페이스를 표시하고, 사용자입력에 따라 객체가 선택되면, 이를 객체에 대한 이 벤트롤 식별할 수 있다. 다만, 객체에 대한 이벤트가 사용자입력에 따른 객체의 선택에 한정되는 것은 아니다. 프로세서는 식별된 이벤트에 따라 음원성분에 관한 동작을 수행한다. 일 예로, 선택된 객체에 대응하는 음원 성분에 기초한 오디오를 출력한다. 설명의 편의를 위해 사용자입력에 따라 제1객체가 선택된 경우를 가정하 면, 제1객체에 대응하는 제1음원성분을 식별하고, 제1음원성분에 기초한 오디오를 스피커를 통해 출력할 수 있다. 제1객체의 위치가 화면의 좌측이므로, 화면의 좌측에 대응하도록 오디오의 출력 방향이 설정될 수 있다. 또는, 프로세서는 선택된 제1객체에 대응하는 제1음원성분을 식별하고, 제1음원성분의 크기를 조정할 수 있다. 일 예로, 프로세서는 제1음원성분의 크기를 다른 객체에 대응하는 음원성분의 크기보다 커지도록 조정 할 수 있다. 또는, 도 7 및 8을 참조하여 설명한 바와 같이, 프로세서는 제1객체가 다른 객체와 구별되도록 효과 를 표시하거나, 제1객체 및 제1마이크 간의 상호 위치 관계를 나타내는 사용자인터페이스를 표시할 수 있다. 이와 같이, 프로세서는 객체에 대한 이벤트에 대응하여 다양한 동작을 수행할 수 있다. 따라서, 음원성분 및 객체 간의 관계에 대한 통합적 식별 및 적응적 식별 여부를 더욱 다양한 시각적 정보로 제공할 수 있다. 도 11은 도 4의 동작 S43과 관련하여, 음원성분 및 마이크 간의 대응관계를 업데이트 하는 구체적인 예를 도시 한다. 앞서 설명한 바와 같이, 프로세서는 오디오신호에 기초하여 음원성분 및 마이크 간의 대응관계를 식별한다. 오디오신호는 복수의 프레임으로 구성되며, 프로세서는 프레임 별로 음원성분 및 마이크 간의 대응관계를 식 별할 수 있다. 프레임 별로 대응관계를 식별한다는 것은, 단일 프레임 별로 대응관계를 식별하는 경우뿐만 아니 라, 소정 개수의 프레임 별로 대응관계를 식별하는 경우를 포함한다. 즉, 주기적 또는 비주기적으로 적어도 하 나의 프레임에 대하여 대응관계를 식별하는 경우를 포함한다. 일 예로, 프로세서는 오디오신호의 복수의 프레임 중 제1프레임에 기초하여 제1음원성분이 제1마이크에 대응하는 것으로 식별할 수 있다. 일정 시간 경과 후, 오디오신호의 제2프레임에 기초하여 제1음원성분이 제2마 이크에 대응하는 것으로 식별할 수 있다. 이 경우, 앞서 도 3을 참조하여 설명한 바와 같이, 제1프레임에 기초하여 식별된 제1마이크 및 제1음원성분 간의 대응관계는 제2마이크 및 제1음원성분의 대응관계로 업데이트될 수 있다. 마찬가지로, 제3프레임에 기초하여 제1음원성분이 제3마이크에 대응하는 것으로 식별 할 수 있으며, 이 경우, 제3마이크 및 제1음원성분의 대응관계로 업데이트될 수 있다. 이와 같이, 오디오신호의 프레임 별로 음원성분 및 마이크 간의 대응관계를 업데이트할 수 있으므로, 음원성분 및 객체 간의 관계에 대해 적응적 식별이 가능하다. 도 12는 도 11의 음원성분 및 마이크 간의 업데이트된 대응관계에 따라 컨텐츠와 관련된 동작을 업데이트 하는 구체적인 예를 도시한다. 도 11을 참조하여 설명한 바와 같이, 프로세서는 오디오신호의 프레임 별로 음원성분 및 마이크 간의 대응관 계를 업데이트할 수 있다. 일 예로, 도 12에 도시된 바와 같이, 제1프레임에서는 제1객체가 영상의 화면 좌측에 표시되고, 제2프레임에서는 화면 우측으로 이동한 경우를 가정한다. 이 경우, 프로세서는 제1객체 의 이동에 따라, 제1음원성분에 대응하는 마이크가 변경됨을 식별한다. 즉, 제1음원성분이 제1마이크, 제2마이크 및 제3마이크에 순차적으로 대응함을 식별하고, 제1음원성분 및 제1마이크 간의 대응관 계를 제1음원성분 및 제3마이크 간의 대응관계로 업데이트할 수 있다. 프로세서는 제1음원성분 및 마이크 간의 대응관계를 업데이트함에 따라, 제1음원성분 및 제1객체 간의 관 계에 기초한 동작을 업데이트할 수 있다. 도 8을 참조하여 설명한 바와 같이, 상호 위치 관계를 나타내는 화살 표 등의 사용자인터페이스를 예로 들면, 프로세서는 제1음원성분이 제1마이크, 제2마이크 및 제3 마이크에 순차적으로 대응함에 따라, 제1마이크의 위치, 제2마이크의 위치 및 제3마이크의 위 치에 대응하도록 사용자인터페이스를 순차적으로 업데이트할 수 있다. 이와 같이, 프로세서는 음원성분 및 마이크 간의 업데이트된 대응관계에 대응하여, 객체에 관하여 컨텐츠와 관련된 동작을 업데이트할 수 있다. 따라서, 음원성분 및 객체 간의 관계에 대해 적응적 식별이 가능할 뿐만 아 니라, 사용자에게 적응적 식별에 대한 정보를 제공할 수 있다. 본 문서에 개시된 다양한 실시예들은 전자장치와 같은 기기(Machine)가 읽을 수 있는 저장 매체(Storage Medium)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨어로서 구현된다. 일 예로, 전자장치의 프로세 서는 저장 매체로부터 저장된 하나 이상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행한다. 이것은 전자장치와 같은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도 록 운영되는 것을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터 에 의해 실행될 수 있는 코드를 포함한다. 기기로 읽을 수 있는 저장매체는, 비일시적(Non-transitory) 저장매 체의 형태로 제공된다. 여기서, ‘비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(예컨대, 전자기 파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 일 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함한다. 일 예로, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(Computer Program Product)에 포함되어 제공된다. 본 개시에 의한 컴퓨터 프로그램 제품은, 앞서 언급된 바와 같은, 프로세서에 의해 실행되 는 소프트웨어의 명령어들을 포함한다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래된다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예컨대, CD-ROM)의 형태로 배포되거나, 또는 어플리케 이션 스토어(예컨대, 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들(예컨대, 스마트폰들) 간에 직접, 온 라인으로 배포(예컨대, 다운로드 또는 업로드)된다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더 블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메 모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성된다. 이상, 바람직한 실시예를 통하여 본 발명에 관하여 상세히 설명하였으나, 본 발명은 이에 한정되는 것은 아니며 특허청구범위 내에서 다양하게 실시된다."}
{"patent_id": "10-2020-0151797", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 전자장치를 도시한다. 도 2는 도 1의 전자장치에 관한 구성의 일 예를 도시한다. 도 3은 도 1의 전자장치에 관한 구성의 구체적인 예를 도시한다. 도 4는 도 1의 전자장치에 대한 제어방법의 일 예를 도시한다. 도 5는 도 4의 동작 S43과 관련하여, 음원성분 및 마이크의 오디오신호 간에 기초하여 음원성분 및 마이크 간의 대응관계를 식별하는 구체적인 예를 도시한다. 도 6은 도 4의 동작 S44와 관련하여, 음원성분에 대응하는 마이크의 위치에 기초하여 음원성분 및 객체 간의 관 계를 식별하는 구체적인 예를 도시한다. 도 7은 도 4의 동작 S44와 관련하여, 마이크의 위치에 대응하는 객체에 관하여 컨텐츠와 관련된 동작의 일 예로 서, 음원성분에 대응하는 객체를 구분하여 표시하는 구체적인 예를 도시한다. 도 8은 도 4의 동작 S44와 관련하여, 마이크의 위치에 대응하는 객체에 관하여 컨텐츠와 관련된 동작의 다른 예 로서, 마이크 및 객체 간의 상호 위치 관계를 나타내는 구체적인 예를 도시한다. 도 9는 도 4의 동작 S44와 관련하여, 음원성분에 대한 이벤트에 대응하여 컨텐츠와 관련된 동작을 수행하는 구 체적인 예를 도시한다. 도 10은 도 4의 동작 S44와 관련하여, 객체에 대한 이벤트에 대응하여 컨텐츠와 관련된 동작을 수행하는 구체적 인 예를 도시한다. 도 11은 도 4의 동작 S43과 관련하여, 음원성분 및 마이크 간의 대응관계를 업데이트 하는 구체적인 예를 도시 한다. 도 12는 도 11의 음원성분 및 마이크 간의 업데이트된 대응관계에 따라 컨텐츠와 관련된 동작을 업데이트 하는 구체적인 예를 도시한다."}
