{"patent_id": "10-2023-0041719", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0146754", "출원번호": "10-2023-0041719", "발명의 명칭": "그룹 응집력 및 그룹 감정예측을 위한 멀티모달 멀티태스킹 학습 시스템", "출원인": "전남대학교산학협력단", "발명자": "양형정"}}
{"patent_id": "10-2023-0041719", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "그룹 관련 비디오에서 비디오 프레임과 음성을 추출하는 추출부,비디오 프레임에서 추출된 비주얼 피처들과 음성에서 추출된 음성 피처들을 기초로 해당 그룹의 응집력과 감정을 예측하는 태스크를 수행하는 태스크부 및 태스크의 수행에 따른 손실을 기초로 학습을 수행하는 학습부를 포함하는 것을 특징으로 하는 그룹응집력 및 그룹감정예측을 위한 멀티모달 멀티태스킹 학습 시스템."}
{"patent_id": "10-2023-0041719", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 추출부는 비디오 녹화에서 특징을 추출하기 전에 비디오의 시각적 프레임과 오디오의 파형을 분리하여,시각적 특징을 추출하기 위해 얼굴 추출기로 각 프레임에서 얼굴사진을 잘라낸 다음 얼굴속성과 얼굴 표정의 표현을 추출하고,오디오 특징을 추출하기 위해 언어의 정서적 특성을 통합하기 위해 각성(Arousal), 정서(Valence), 통제감(Dominance) 특징을 추출하는 것을 특징으로 하는 그룹응집력 및 그룹감정예측을 위한 멀티모달 멀티태스킹 학습 시스템."}
{"patent_id": "10-2023-0041719", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 태스크부는,비디오 프레임에서 추출된 비주얼 피처들과 음성에서 추출된 음성 피처들을 기초로 해당 그룹의 응집력과 감정을 예측하는 태스크를 수행하되,시각적 시간 인코더에 입력되어 글로벌 평균풀링 레이어로 압축된 후, 시간차원을 통해 얼굴속성에 대한 특징벡터와 얼굴 표정에 대한 특징벡터를 생성하여 인코딩을 수행하는 인코딩모듈,상기 특징벡터의 표현을 융합하여 시각적 및 청각적 표현을 융합 특징벡터로 구체화하는 MHA융합모듈 및상기 융합 특징벡터를 감정상태와 응집력 수준을 예측하기 위해 완전 연결계층에 입력하여 감정상태와 응집력수준을 예측하는 예측모듈을 포함하는 것을 특징으로 하는 그룹응집력 및 그룹감정예측을 위한 멀티모달 멀티태스킹 학습 시스템."}
{"patent_id": "10-2023-0041719", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 학습부는 그룹응집력과 그룹감정 예측이라는 두 가지 작업에 결합된 손실함수(loss function)를 사용하여,그룹응집력와 그룹감정 예측사이의 차이를 최소화하기 위해, 평균제곱 오차 손실을 사용하는 것을 특징으로 하는 그룹응집력 및 그룹감정예측을 위한 멀티모달 멀티태스킹 학습 시스템.손실함수 L : 공개특허 10-2024-0146754-3-여기서, N은 샘플수, 및 는 실제 그룹 응집도 및 예측 응집도 점수, 는 감정상태의 예측 확률, 및 는 초점요소이다."}
{"patent_id": "10-2023-0041719", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 그룹응집력 및 그룹감정예측을 위한 멀티모달 멀티태스킹 학습 시스템에 관한 것으로써, 비디오에서 오디오 및 시각적 특징을 추출하기 위한 그룹응집력 및 그룹감정예측을 위한 멀티모달 멀티태스킹 학습 시스템에 관한 것이다. 본 발명에 따르면, 그룹 관련 비디오에서 비디오 프레임과 음성을 추출하는 추출부, 비디오 프레임 에서 추출된 비주얼 피처들과 음성에서 추출된 음성 피처들을 기초로 해당 그룹의 응집력과 감정을 예측하는 태 스크를 수행하는 태스크부 및 태스크의 수행에 따른 손실을 기초로 학습을 수행하는 학습부를 포함하여 비디오에 나타나는 그룹의 응집력 수준뿐만 아니라 감정 상태까지 정확하게 예측될 수 있는 효과가 있다."}
{"patent_id": "10-2023-0041719", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 그룹 응집력 및 그룹 감정예측을 위한 멀티모달 멀티태스킹 학습 시스템에 관한 것으로써, 보다 상세 하게는 비디오에서 오디오 및 시각적 특징을 추출하기 위한 그룹 응집력 및 그룹 감정예측을 위한 멀티모달 멀 티태스킹 학습 시스템에 관한 것이다."}
{"patent_id": "10-2023-0041719", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "서로의 상호작용과 사회적 연결을 통해 사람들은 생존과 번영에 대한 욕구를 충족시킬 수 있다. 따라서, 개인은 각자의 필요와 목표를 달성하기 위해 서로 관계를 만들고 유지한다. 그룹 응집력은 그룹 구성원들이 공동의 목 표를 달성하기 위해 함께 일할 수 있는 정도라고 정의할 수 있다. 그룹 감정은 그룹 구성원이 공유하는 감정, 태도 및 성향을 설명하는 용어이다. 개별 구성원의 감정상태에 하향식 영향을 미치는 감정적 실체로 볼 수도 있고, 구성원의 감정상태의 집합체로 볼 수도 있다. 결과적으로 그룹 구성원들의 사회적, 정서적 상호작용은 그룹 구성원들 간의 유대를 강화해주는 역할을 한다. 따라서, 그룹 감정과 그룹 응집력에 대한 연구가 중요하다. 그룹응집력의 역학에 대한 지식은 그룹 구성원이 공 유하는 감정에 대한 인식에 의해 크게 도움이 될 수 있어 감성 컴퓨팅 분야에서 가장 중요한 연구주제 중 하나 이다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허 2022-0063816(2022.05.18.)"}
{"patent_id": "10-2023-0041719", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제를 해결하고자, 비디오에서 오디오 및 시각적 특징을 추출하기 위한 그룹응집력 및 그룹 감정예측을 위한 멀티모달 멀티태스킹 학습 시스템을 제공함에 목적이 있다."}
{"patent_id": "10-2023-0041719", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위하여 본 발명은 그룹 관련 비디오에서 비디오 프레임과 음성을 추출하는 추출부, 비디 오 프레임에서 추출된 비주얼 피처들과 음성에서 추출된 음성 피처들을 기초로 해당 그룹의 응집력과 감정을 예 측하는 태스크를 수행하는 태스크부 및 태스크의 수행에 따른 손실을 기초로 학습을 수행하는 학습부를 포함한 다. 추출부는 비디오 녹화에서 특징을 추출하기 전에 비디오의 시각적 프레임과 오디오의 파형을 분리하여, 시각적 특징을 추출하기 위해 얼굴 추출기로 각 프레임에서 얼굴사진을 잘라낸 다음 얼굴속성과 얼굴 표정의 표현을 추 출하고, 오디오 특징을 추출하기 위해 언어의 정서적 특성을 통합하기 위해 각성(Arousal), 정서(Valence), 통 제감(Dominance) 특징을 추출한다. 태스크부는 비디오 프레임에서 추출된 비주얼 피처들과 음성에서 추출된 음성 피처들을 기초로 해당 그룹의 응 집력과 감정을 예측하는 태스크를 수행하되, 시각적 시간 인코더에 입력되어 글로벌 평균풀링 레이어로 압축된 후, 시간차원을 통해 얼굴속성에 대한 특징벡터와 얼굴 표정에 대한 특징벡터를 생성하여 인코딩을 수행하는 인 코딩모듈, 상기 특징벡터의 표현을 융합하여 시각적 및 청각적 표현을 융합 특징벡터로 구체화하는 MHA융합모듈 및 상기 융합 특징벡터를 감정상태와 응집력 수준을 예측하기 위해 완전 연결계층에 입력하여 감정상태와 응집 력 수준을 예측하는 예측모듈을 포함한다. 학습부는 그룹응집력과 그룹감정 예측이라는 두 가지 작업에 결합된 손실함수(loss function)를 사용하여, 그룹 응집력와 그룹감정 예측사이의 차이를 최소화하기 위해, 평균제곱 오차 손실을 사용하는 것을 특징으로 하는 그 룹응집력 및 그룹감정예측을 위한 멀티모달 멀티태스킹 학습 시스템. 손실함수 L :"}
{"patent_id": "10-2023-0041719", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "여기서, N은 샘플수, 및 는 실제 그룹 응집도 및 예측 응집도 점수, 는 감정상태의 예측 확률, 및 는 초점요소이다."}
{"patent_id": "10-2023-0041719", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 비디오에 나타나는 그룹의 응집력 수준뿐만 아니라 감정 상태까지 정확하게 예측될 수 있다. 또한, 본 발명은 관심 그룹을 모니터링하는 등의 용도로 다양한 분야/장소(e.g., 회사, 학교 등)에 폭넓게 활용 될 수 있다."}
{"patent_id": "10-2023-0041719", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면들에 기재된 내용들을 참조하여 본 발명을 상세히 설명한다. 다만, 본 발명이 예시적 실시 예 들에 의해 제한되거나 한정되는 것은 아니다. 각 도면에 제시된 동일 참조부호는 실질적으로 동일한 기능을 수 행하는 부재를 나타낸다. 본 발명의 목적 및 효과는 하기의 설명에 의해서 자연스럽게 이해되거나 보다 분명해질 수 있으며, 하기의 기재 만으로 본 발명의 목적 및 효과가 제한되는 것은 아니다. 또한, 본 발명을 설명함에 있어서 본 발명과 관련된 공지 기술에 대한 구체적인 설명이, 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하기로 한다. 본 발명은 비디오에서 오디오 및 시각적 특징을 추출하기 위한 융합 딥러닝 기술과, 비디오 내 구성원들의 대화 를 기반으로 그룹의 응집력 수준과 그룹감정상태를 동시에 예측하기 위해 데이터의 오디오 및 시각적 특징을 추 출하여 융합한 감정인식모델로서, 그룹의 응집력과 감정을 예측하는 시스템에 관한 것이다. 이에, 본 발명은 그 룹 관련 비디오에서 비디오 프레임과 음성을 추출하고, 비디오 프레임에서 추출된 다양한 비주얼 피처들과 음성 에서 추출된 다양한 음성 피처들을 기초로 해당 그룹의 응집력과 감정을 예측하는 태스크를 수행하며, 태스크의 수행에 따른 손실을 기초로 학습을 수행하는 것을 특징으로 한다. 즉, 본 발명은 멀티모달 피처들(=비주얼 피처+음성 피처)을 기초로 멀티 태스크(=응집력 예측+감정 예측) 기반 의 학습을 수행한다.도 1은 본 발명의 일 실시예에 따른 그룹응집력 및 그룹감정예측을 위한 멀티모달 멀티태스킹 학습 시스템을 나 타낸 구성도이고, 도 2는 그룹 응집력 및 그룹 감정 예측을 위한 기본 아키텍처이다. 도 1에 도시된 바와 같이, 본 실시예에 따른 그룹응집력 및 그룹감정예측을 위한 멀티모달 멀티태스킹 학습 시 스템은 추출부, 태스크부, 학습부를 포함한다. 추출부는 그룹 관련 비디오에서 비디오 프레임과 음성을 추출하는 구성이다. 이러한 추출부는 특징추출 (Feature Extraction)을 하는 것으로, 비디오 녹화에서 특징을 추출하기 전에 먼저 비디오의 시각적 프레임과 오디오의 파형을 분리한다. 시각적 특징을 추출하는 프로세스를 시작하기 위해 얼굴 추출기를 사용하여 각 프레임에서 얼굴사진을 잘라낸다. 그런 다음 얼굴속성과 얼굴 표정이라는 두 가지 고유한 유형의 표현을 추출한다. 얼굴 특징벡터를 생성하기 위해 사전 훈련된 모델을 사용한다. 단일 프레임에서 모든 얼굴 속성의 평균을 구한 다음 윈도우 슬라이드를 사용하여 전체 비디오에서 프레임을 샘플링한다. 마지막으로 각각 얼굴 속성과 얼굴감정에 대해 인코딩 기능 시퀀스를 수집한다. 얼굴 특징 추출 외에도 비디오 콘텐츠의 포괄적인 표현을 추출한다. 오디오 특징은 음성 및 감성 컴퓨팅에 유용한 88개의 특성을 추출한다. 음성 특징(Prosodic, excitation, vocal tract, spectral 및 cepstral MFCC)은 모두 GeMAPS에 통합되어 있으며, 하위 MFCC(Mel-frequency cepstrum)도 포함되어 있다. 언어의 정서적 특성을 통합하기 위해 각성(Arousal), 정서(Valence), 통제감(Dominance) 특징을 추출한다. 1024개의 특성은 헤드 레이어가 프로세스에서 무시된 후 각 오디오 샘플에서 수집되며, 이외에도 오디오 파형을 128 Mel 밴드, 2048 길이의 FFT(고속 푸리에 변환) 윈도우, 프레임 간 512 샘플 및 8kHz의 최대 주파수가 있는 로그 멜스펙트로그램의 그림으로 변환한다. 스펙트로그램이 수용할 수 있는 최종 이미지 크기는 128x1292이다. 태스크부는 비디오 프레임에서 추출된 다양한 비주얼 피처들과 음성에서 추출된 다양한 음성 피처들을 기 초로 해당 그룹의 응집력과 감정을 예측하는 태스크를 수행하는 구성이다. 이러한 태스크부는 인코딩모듈 , MHA 융합모듈, 예측모듈을 포함한다. 인코딩 모듈은 비디오 프레임에서 추출된 비주얼 피처들과 음성에서 추출된 음성 피처들을 기초로 해당 그 룹의 응집력과 감정을 예측하는 태스크를 수행하되, 시각적 시간 인코더에 입력되어 글로벌 평균풀링 레이어로 압축된 후, 시간차원을 통해 얼굴속성에 대한 특징벡터와 얼굴 표정에 대한 특징벡터를 생성하여 인코딩을 수행 한다. MHA 융합모듈은 특징벡터의 표현을 융합하여 시각적 및 청각적 표현을 융합 특징벡터로 구체화한다. 이때, 구체화는 MHA 융합모듈을 구성하는 입력주위(Input Attention), 교차주의(Corss Attention) 및 자기주의(Self- Attention)의 3개 계층으로 구체화하며, 아래에서 설명하기로 한다. 예측모듈은 MHA 융합모듈의 융합 특징벡터를 감정상태와 응집력 수준을 예측하기 위해 완전 연결계층 에 입력하여 감정상태와 응집력 수준을 예측한다. 본 실시예에 따른 태스크부는 멀티태스크 다중 특징융합 프레임워크(Multi-task Multi-Feature Fusion Framework)이다. 다중 특징융합을 통해 그룹응집력 및 그룹감정을 예측하기 위한 베이스라인 모델의 일반적인 아키텍처는 도 2와 같다. 프로세스의 첫 번째 단계에서 얼굴표현의 두 시퀀스 각각은 다음을 수행하기 위해 시각적 시간 인코더에 입력되며, 시간차원을 통해 정보를 활용한다. 시간적 차원은 글로벌 평균풀링 레이어를 사용하여 압축된 후 얼굴속성에 대한 100개의 특징벡터와 얼굴 표정에 대한 200개 특징 벡터를 얻는다. 이러한 각 표현의 특징 차원을 압축하기 위해 SlowFast, OpenSMILE 및 Wave2vec에서 추출된 특징표현에 완전연"}
{"patent_id": "10-2023-0041719", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "결계층을 적용한다. 요약하면 SlowFast 및 Wave2vec표현에 대해 100개 특징벡터가 나오지만 openSMILE 표현은 입력크기가 더 작기 때문에 32개 특징벡터만 생성된다. 다음으로 SE(Squeeze-and-Excitation) 네트워크를 사용하여 log-melspectrogram 이미지를 인코딩한다. 또한 MHA(Multi-Head Attention) 접근방식을 사용하여 융합모듈을 구성한다. MHA 융합모듈을 구성하는 3개의 계층은 입력주위(Input Attention), 교차주의(Corss Attention) 및 자기주의(Self-Attention)이다. MHA는 h(머리의 수)를 독립적으로 학습한 선형프로젝션을 사용하여 변환할 입력으로 쿼리, 키 및 값의 집합이 필요하다. 이러한 표현을 융합하기 전에 입력주의 레벨을 사용하여 동일한 도메인 내에서 다양한 특성을 정렬한 다. Cross-Attention은 하나의 양식이 다른 양식에 대한 유인 맵 생성을 용이하게 하는 쌍을 이루는 양식의 기능을 혼합하는데 사용된다. M이 모달리티의 수라고 하면 M(M-1)은 교차주의 블록의 수이다. 그런 다음 Self-Attention은 각 양식에 대한 교차양식 데이터를 결합하여 표현을 구체화한다. 도 3은 이중양식 및 삼중양식을 포함한 시나리오에 대한 MHA 융합모듈을 나타낸다. 도 3에서 a)는 MHA 융합모듈 에서 이중 양식(by-modality)의 경우이고, b)는 삼중양식(tri-modality)의 경우이다. MHA 융합을 사용하기 위해, 먼저 세 가지 시각적 및 청각적 표현 각각에 대해 삼중 모드 MHA 융합 모듈을 사용하고 각 분기에 대한 융합된 특성을 획득한다. 그럼 다음 바이모달 MHA융합모듈이 이러한 융합 기능에 사용되며, 그 결과로 생성된 융합 특징벡터는 감정상태 와 응집력 수준을 예측하기 위해 완전 연결계층에 입력된다. 학습부는 태스크의 수행에 따른 손실을 기초로 학습을 수행하는 구성이다. 이러한 학습부는 모델 수렴을 최적화하기 위해 그룹응집력과 그룹감정 예측이라는 두 가지 작업에 결합된 손실함수(loss function)를 사용한 다. 그룹응집도 수준과 모델 예측사이의 차이를 최소화하기 위해, 평균제곱 오차 손실을 사용한다. 클래스의 불 균형으로 인해 분류문제에 초점을 둔 손실함수를 사용하며, 최종 손실함수 L은 다음과 같이 표현될 수 있다."}
{"patent_id": "10-2023-0041719", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, N은 샘플수, 및 는 실제 그룹 응집도 및 예측 응집도 점수, 는 감정상태의 예측 확률, 및 는 초점요소이다. 사회과학 및 심리학의 결과에 기반한 수많은 연구는 특정 그룹 구성원 간의 역학을 식별하고 분류하는 것을 목 표로 한다. 그룹응집력은 그룹 구성원들의 동기부여와 목적의식을 모두 포함하므로 그룹을 유지하고 구성하는데 중요한 역할을 한다. 본 발명에서는 인공지능 딥러닝 모델을 활용하여 그룹응집력과 그룹감정 예측을 위해 멀티모달 멀티태스킹 시스 템을 제안한다. 첫째, 시각적 데이터는 얼굴특징, 얼굴감정 및 전체 비디오 환경에 대한 세 가지 표현 유형을 추출하였다. 또한 OpenSMILE, Wave2vec 2.0 및 스펙트로그램 인코딩을 이용하여 세 가지 유형의 오디오 특징을 추출하였다. 그런 다음 MHA 퓨전 모듈을 사용하여 이러한 특징표현을 결합하고 그룹 응집성 점수와 그룹감정 확률을 모두 예 측하기 위해 퓨전 출력을 완전연결계층에 입력한다. 이러한 예측에 따라 그룹 구성원들의 응집력이 얼마나 강한 지 더 잘 이해할 수 있는 효과가 있다. 그룹 구성원들의 응집력을 예측하고 이래하면 조직의 관리자가 조직을 효율적으로 이끌어 갈 수 있도록 도울 수 있다. 응집력이 강한 그룹에 속한 사람들은 비즈니스 성과에 중대한 영향을 미칠 수 있으며, 조직의 성과를 달 성하는데 큰 기여를 할 수 있다. 사회구성원으로 살아가는데 어려움이 있는 사람들은 그룹심리상담을 통해 그룹활동을 하고, 그룹심리상담의 효 과를 확인하기 위해 전과 후의 그룹응집도를 확인한다. 이때, 본 발명에서 개발한 그룹응집 예측 인공지능 모델 을 사용하면, 촬영한 영상을 통해 객관적이고 정확하게 그룹응집도를 파악할 수 있다. 그룹구성원들은 응집력 뿐만 아니라, 감정도 그룹을 유지하는데 중요한 요소로 작용한다. 그룹구성들의 감정을 파악하고, 이를 분석하면 어떠한 계기를 통해 그룹 구성원의 감정이 변화되는지 파악이 가능하며 그룹의 전전성 에 중요한 지표가 될 수 있다."}
{"patent_id": "10-2023-0041719", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 그룹응집력 및 그룹감정예측을 위한 멀티모달 멀티태스킹 학습 시스템을 나 타낸 구성도이고, 도 2는 그룹 응집력 및 그룹 감정 예측을 위한 기본 아키텍처이다. 도 3은 이중양식 및 삼중양식을 포함한 시나리오에 대한 MHA 융합모듈을 나타낸다."}
