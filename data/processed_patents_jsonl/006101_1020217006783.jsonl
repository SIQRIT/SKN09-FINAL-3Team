{"patent_id": "10-2021-7006783", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0059712", "출원번호": "10-2021-7006783", "발명의 명칭": "이미지 향상을 위한 인공지능 기법", "출원인": "블링크에이아이 테크놀로지스, 아이엔씨.", "발명자": "주, 보"}}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이미지를 향상시키기 위해 기계 학습 시스템을 트레이닝(training)하기 위한 시스템으로서,프로세서; 및프로세서-실행가능 명령어를 저장하는 비일시적 컴퓨터-판독가능 저장 매체 - 상기 프로세서-실행가능 명령어는상기 프로세서에 의해 실행될 때, 상기 프로세서가:상기 기계 학습 시스템을 트레이닝하는 데 사용될 트레이닝 이미지의 세트를 획득하는 것 - 상기 획득하는것은: 장면의 입력 이미지를 획득하는 것; 및 상기 장면의 복수의 이미지를 평균냄으로써 상기 장면의 타겟 출력 이미지를 획득하는 것 - 상기 타겟 출력 이미지는 상기 입력 이미지의 타겟 향상을 나타냄 -을 포함함 -; 및상기 트레이닝 이미지의 세트를 사용하여 상기 기계 학습 시스템을 트레이닝하는 것을 수행하게 함 -를 포함하는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 명령어는 상기 프로세서가:입력 이미지의 세트를 획득하는 것 - 상기 입력 이미지의 세트에서 각 입력 이미지는 대응하는 장면의 것임 -;및상기 대응하는 장면의 복수의 이미지를 평균냄으로써 상기 입력 이미지의 세트에서 각 입력 이미지에 대해 상기대응하는 장면의 타겟 출력 이미지를 획득하는 것을 포함하는 타겟 출력 이미지의 세트를 획득하는 것; 및상기 입력 이미지의 세트 및 상기 타겟 출력 이미지의 세트를 사용하여 상기 기계 학습 시스템을 트레이닝하는것을 더 하게 하는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 입력 이미지를 획득하는 것은 미리 결정된 ISO 임계치를 초과하는 ISO 설정에서 상기 입력 이미지를 획득하는 것을 포함하는, 방법."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 ISO 임계치는 대략 1500 내지 500,000의 ISO 범위로부터 선택되는, 방법."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 복수의 이미지를 평균내는 것은 상기 복수의 이미지에서 각 픽셀 위치에 걸쳐 산술 평균을 계산하는 것을 포함하는, 방법."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 트레이닝 이미지의 세트를 획득하는 것은 복수의 이미지 캡처 설정에 대해 트레이닝 이미지의 세트를 획득하는 것을 포함하는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 트레이닝 이미지의 세트를 획득하는 것은 상기 이미지의 입력 세트 및 상기 이미지의 출력 세트를 캡처하는 데 사용되는 이미징 디바이스의 잡음을 캡처하는 하나 이상의 이미지를 획득하는 것을 포함공개특허 10-2021-0059712-3-하는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 명령어는 상기 프로세서가 트레이닝 이미지의 제2 세트를 획득하는 것을 수행하고, 상기트레이닝 이미지의 제2 세트를 사용하여 상기 기계 학습 시스템을 재트레이닝하는 것을 더 하게 하는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 명령어는 상기 프로세서가:각각의 이미징 디바이스로부터 상기 트레이닝 이미지의 세트를 획득하는 것; 및 상기 각각의 디바이스에 대해 상기 기계 학습 시스템에 의한 향상을 최적화하기 위해 상기 각각의 디바이스로부터 이미지의 제1 트레이닝 세트를 기초로 상기 기계 학습 시스템을 트레이닝하는 것을 더 하게 하는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 기계 학습 시스템은 신경망을 포함하는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 기계 학습 시스템을 트레이닝하는 것은 다수의 손실 함수의 선형 조합을 최소화하는 것을포함하는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서, 상기 기계 학습 시스템을 트레이닝하는 것은 인간이 지각 가능한 주파수 범위에서의 성능을 위해 상기 기계 학습 시스템을 최적화하는 것을 포함하는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 기계 학습 시스템을 트레이닝하는 것은: 각각의 입력 이미지에 대응하는 상기 기계 학습 시스템에 의해 생성된 향상된 이미지를 획득하는 것;상기 각각의 입력 이미지에 대응하는 상기 타겟 출력 이미지의 세트의 각각의 타겟 출력 이미지를 획득하는 것;상기 향상된 이미지 및 상기 타겟 출력 이미지를 대역 통과 필터를 통해 통과시키는 것; 및상기 필터링된 향상된 이미지 및 필터링된 타겟 출력 이미지를 기초로 상기 기계 학습 시스템을 트레이닝하는것을 포함하는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항에 있어서, 상기 기계 학습 시스템을 트레이닝하는 것은:상기 트레이닝 이미지의 세트를 캡처하는 데 사용되는 이미징 디바이스와 연관된 잡음 이미지를 획득하는 것 -상기 잡음 이미지는 상기 이미징 디바이스에 의해 생성된 잡음을 캡처함 -; 및상기 잡음 이미지를 상기 기계 학습 시스템으로의 입력으로서 포함시키는 것을 포함하는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항에 있어서, 상기 기계 학습 시스템을 트레이닝하는 데 사용될 상기 트레이닝 이미지의 세트를 획득하는 것은:중립 밀도 필터(neutral density filter)를 사용하여 입력 이미지의 세트를 획득하는 것 - 상기 입력 이미지의세트의 각 이미지는 대응하는 장면의 것임 -; 및상기 입력 이미지의 세트에서 각 입력 이미지에 대해, 상기 중립 밀도 필터 없이 캡처되는 상기 대응하는 장면의 타겟 출력 이미지를 획득하는 것을 포함하는 타겟 출력 이미지의 세트를 획득하는 것 - 상기 타겟 출력 이미지는 상기 입력 이미지의 타겟 향상을 나타냄 -을 포함하는, 시스템.공개특허 10-2021-0059712-4-청구항 16 이미지를 자동으로 향상시키기 위한 시스템으로서, 상기 시스템은:프로세서; 및상기 프로세서에 의해 구현되는 기계 학습 시스템 - 상기 기계 학습 시스템은:입력 이미지를 수신하는 것; 및상기 입력 이미지를 기초로, 상기 입력 이미지에서보다 더 조명되는(illuminated) 상기 입력 이미지의 적어도일부를 포함하는 출력 이미지를 생성하는 것을 하도록 구성됨 - 을 포함하고;상기 기계 학습 시스템은 트레이닝 이미지의 세트를 기초로 트레이닝되고, 상기 트레이닝 이미지의 세트는:장면의 입력 이미지; 및상기 장면의 타겟 출력 이미지 - 상기 타겟 이미지는 상기 장면의 복수의 이미지를 평균냄으로써 획득되고, 상기 타겟 출력 이미지는 상기 입력 이미지의 타겟 향상을 나타냄 -를 포함하는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 트레이닝 이미지의 세트의 하나 이상의 입력 이미지는 중립 밀도 필터로 캡처되고; 및상기 트레이닝 이미지의 세트의 하나 이상의 출력 이미지는 상기 중립 밀도 필터 없이 캡처되는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서, 상기 프로세서는:제1 이미지를 수신하는 것;상기 제1 이미지를 제1 복수의 이미지 부분으로 나누는 것;상기 제1 복수의 이미지 부분을 상기 기계 학습 시스템 내로 입력하는 것;상기 기계 학습 시스템으로부터 제2 복수의 이미지 부분을 수신하는 것; 및출력 이미지를 생성하기 위해 상기 제2 복수의 이미지를 결합하는 것을 하도록 구성되는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 기계 학습 시스템은:상기 제1 복수의 이미지 부분의 각각의 것에 대해:상기 각각의 이미지 부분의 일부를 자르는 것(crop) - 상기 각각의 이미지 부분의 상기 일부는 상기 각각의 이미지 부분의 픽셀의 서브셋을 포함함 -을 하도록 구성되는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에 있어서, 상기 프로세서는:상기 제1 복수의 부분의 크기를 결정하는 것; 및상기 제1 이미지를 상기 제1 복수의 부분으로 나누는 것 - 제1 복수의 부분의 각각은 상기 크기를 가짐 -을 하도록 구성되는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제11항에 있어서, 상기 기계 학습 시스템은 컨볼루션 신경망(convolutional neural network) 또는 밀집하게 연결된 컨볼루션 신경망을 포함하는 신경망을 포함하는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "공개특허 10-2021-0059712-5-제16항에 있어서, 상기 프로세서는:제1 이미지를 획득하는 것;양자화된 이미지를 획득하기 위해 상기 제1 이미지를 양자화하는 것;상기 양자화된 이미지를 상기 기계 학습 시스템으로 입력하는 것; 및상기 기계 학습 시스템으로부터, 각각의 출력 이미지를 수신하는 것을 하도록 구성되는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "이미지를 향상시키기 위해 기계 학습 시스템을 트레이닝하기 위한 컴퓨터화된 방법으로서, 상기 방법은:상기 기계 학습 시스템을 트레이닝하는 데 사용될 트레이닝 이미지의 세트를 획득하는 것 - 상기 획득하는것은:장면의 입력 이미지를 획득하는 것; 및상기 장면의 복수의 이미지를 평균냄으로써 상기 장면의 타겟 출력 이미지를 획득하는 것 - 상기 타겟 출력 이미지는 상기 입력 이미지의 타겟 향상을 나타냄 -을 포함함 -; 및상기 트레이닝 이미지의 세트를 사용하여 상기 기계 학습 시스템을 트레이닝하는 것을 포함하는, 컴퓨터화된 방법."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "이미지를 향상시키기 위해 기계 학습 모델을 트레이닝하는 방법으로서, 상기 방법은:디스플레이된 비디오 프레임의 타겟 이미지에 액세스하는 것 - 상기 타겟 이미지는 상기 기계 학습 모델의 타겟출력을 나타냄 -;상기 디스플레이된 비디오 프레임의 입력 이미지에 액세스하는 것 - 상기 입력 이미지는 상기 타겟 이미지에 대응하고 상기 기계 학습 모델에 대한 입력을 나타냄 -; 및트레이닝된 기계 학습 모델을 획득하기 위해, 상기 타겟 이미지 및 상기 타겟 이미지에 대응하는 상기 입력 이미지를 사용하여 상기 기계 학습 모델을 트레이닝하는 것을 수행하도록, 적어도 하나의 컴퓨터 하드웨어 프로세서를 사용하는 것을 포함하는, 방법."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제24항에 있어서,이미징 디바이스를 사용하여, 제1 노출 시간을 사용하여 상기 디스플레이된 비디오 프레임의 상기 타겟 이미지를 캡처하는 것; 및상기 이미징 디바이스를 사용하여, 제2 노출 시간을 사용하여 상기 디스플레이된 비디오 프레임의 상기 입력 이미지를 캡처하는 것 - 상기 제2 노출 시간은 상기 제1 노출 시간보다 짧음 -을 더 포함하는, 방법."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제24항에 있어서,이미징 디바이스를 사용하여, 중립 밀도 필터를 통해 상기 디스플레이된 비디오 프레임의 상기 입력 이미지를캡처하는 것; 및상기 이미징 디바이스를 사용하여, 중립 밀도 필터 없이 상기 디스플레이된 비디오 프레임의 상기 타겟 이미지를 캡처하는 것을 더 포함하는, 방법."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제24항에 있어서,이미징 디바이스를 사용하여, 상기 디스플레이된 비디오 프레임의 상기 입력 이미지를 캡처하는 것; 및공개특허 10-2021-0059712-6-상기 이미징 디바이스를 사용하여, 상기 비디오 프레임의 다수의 정적 캡처의 각 픽셀 위치를 평균냄으로써 상기 디스플레이된 비디오 프레임의 상기 타겟 이미지를 캡처하는 것을 더 포함하는, 방법."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제24항에 있어서,이미징 디바이스를 사용하여, 제1 노출 시간을 사용하여 상기 디스플레이된 비디오 프레임의 상기 타겟 이미지를 캡처하는 것 - 상기 디스플레이된 비디오 프레임은 제1 밝기로 디스플레이됨 -; 및상기 이미징 디바이스를 사용하여, 상기 제1 노출 시간을 사용하여 상기 디스플레이된 비디오 프레임의 상기 입력 이미지를 캡처하는 것 - 상기 디스플레이된 비디오 프레임은 상기 제1 밝기보다 어두운 제2 밝기로 디스플레이됨 -을 더 포함하는, 방법."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제24항에 있어서,상기 입력 이미지 및 타겟 이미지가 상기 디스플레이된 비디오 프레임과 연관된 상기 데이터와 상이한 제2 데이터를 포함하도록, 상기 입력 이미지 및 상기 타겟 이미지는 연관된 내부 부분에서 상기 디스플레이된 비디오 프레임을 각각 포함하고; 및상기 방법은 상기 제1 데이터를 포함시키고 상기 제2 데이터를 배제하기 위해 상기 입력 이미지 및 상기 타겟이미지의 각각을 자르는 것을 더 포함하는, 방법."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제29항에 있어서, 상기 입력 이미지 및 상기 타겟 이미지는 상기 비디오 프레임을 디스플레이하는 상기 디스플레이 디바이스의 제2 개수의 픽셀보다 적은 동일한 제1 개수의 픽셀을 각각 포함하는, 방법."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제24항에 있어서,이미지에 액세스하는 것;상기 이미지에 대해 업데이트된 픽셀 값을 나타내는 대응하는 출력을 획득하기 위해 상기 트레이닝된 기계 학습모델에 대한 입력으로서 상기 이미지를 제공하는 것; 및상기 트레이닝된 기계 학습 모델로부터 상기 출력을 사용하여 상기 이미지를 업데이트하는 것을 더 포함하는,방법."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제24항에 있어서,복수의:추가적인 타겟 이미지 - 상기 추가적인 타겟 이미지의 각 타겟 이미지는: 연관된 디스플레이된 비디오 프레임의 것이고; 및 상기 연관된 디스플레이된 비디오 프레임에 대한 상기 기계 학습 모델의 연관된 타겟 출력을 나타냄 -; 및추가적인 입력 이미지 - 상기 추가적인 입력 이미지의 각 입력 이미지는: 상기 입력 이미지가 상기 대응하는 타겟 이미지와 동일한 디스플레이된 비디오 프레임의 것이도록 상기 추가적인 타겟 이미지의 타겟 이미지에 대응하고; 및 상기 대응하는 타겟 이미지에 대한 상기 기계 학습 모델에 대한 입력을 나타냄 -에 액세스하는 것; 및트레이닝된 기계 학습 모델을 획득하기 위해 (a) 상기 타겟 이미지 및 상기 타겟 이미지에 대응하는 상기 입력공개특허 10-2021-0059712-7-이미지, 및 (b) 상기 복수의 추가적인 타겟 이미지 및 상기 복수의 추가적인 연관된 입력 이미지를 사용하여 상기 기계 학습 모델을 트레이닝하는 것을 더 포함하는, 방법."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "이미지를 향상시키기 위해 기계 학습 모델을 트레이닝하기 위한 시스템으로서, 상기 시스템은:비디오의 비디오 프레임을 디스플레이하기 위한 디스플레이;상기 디스플레이된 비디오 프레임의 타겟 이미지를 캡처하는 것 - 상기 타겟 이미지는 상기 기계 학습 모델의타겟 출력을 나타냄 -; 및상기 디스플레이된 비디오 프레임의 입력 이미지를 캡처하는 것 - 상기 입력 이미지는 상기 타겟 이미지에 대응하고, 상기 기계 학습 모델에 대한 입력을 나타냄 -을 하도록 구성되는 디지털 이미징 디바이스; 및적어도 하나의 하드웨어 프로세서 및 프로세서-실행가능 명령어를 저장하는 적어도 하나의 비일시적 컴퓨터-판독가능 저장 매체를 포함하는 컴퓨팅 디바이스 - 상기 프로세서-실행가능 명령어는 상기 적어도 하나의 하드웨어 프로세서에 의해 실행될 때 상기 적어도 하나의 하드웨어 프로세서가:상기 타겟 이미지 및 상기 입력 이미지에 액세스하는 것; 및트레이닝된 기계 학습 모델을 획득하기 위해, 상기 타겟 이미지 및 상기 타겟 이미지에 대응하는 상기 입력 이미지를 사용하여 상기 기계 학습 모델을 트레이닝하는 것을 수행하게 함 - 를 포함하는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제33항에 있어서, 상기 디스플레이는 텔레비전, 프로젝터 또는 이의 일부 조합을 포함하는, 시스템."}
{"patent_id": "10-2021-7006783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "프로세서-실행가능 명령어를 저장하는 적어도 하나의 컴퓨터 판독가능 저장 매체로서, 상기 프로세서-실행가능명령어는 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서가:디스플레이된 비디오 프레임의 타겟 이미지에 액세스하는 것 - 상기 타겟 이미지는 기계 학습 모델의 타겟 출력을 나타냄 -;상기 디스플레이된 비디오 프레임의 입력 이미지에 액세스하는 것 - 상기 입력 이미지는 상기 타겟 이미지에 대응하고 상기 기계 학습 모델에 대한 입력을 나타냄 -; 및트레이닝된 기계 학습 모델을 획득하기 위해, 상기 타겟 이미지 및 상기 타겟 이미지에 대응하는 상기 입력 이미지를 사용하여 상기 기계 학습 모델을 트레이닝하는 것을 수행하게 하는, 적어도 하나의 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2021-7006783", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이미징 디바이스에 의해 저조도 조건에서 캡처된 이미지는 캡처된 이미지가 열악한 대비, 흐려짐을 갖고, 다른 방식으로 이미지에 하나 이상의 객체를 명확하게 디스플레이하지 못하게 할 수 있다. 다양한 양상에 따라, 저조 도 조건에서 캡처된 이미지를 향상시키기 위한 시스템 및 방법이 제공된다."}
{"patent_id": "10-2021-7006783", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련된 출원 본 출원은 2018년 8월 7일에 출원되고, 명칭이 \"이미지 향상을 위한 인공지능 기법(Artificial Intelligence Techniques for Image Enhancement)\"인 미국 가출원 제62/715,732호에 대한 35 USC § 119(e) 하의 우선권을 주장하며, 이는 그 전체가 본원에 참조로 통합된다."}
{"patent_id": "10-2021-7006783", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "기술분야 본원에서 설명된 기법은 일반적으로 이미지를 향상시키기 위해 인공지능(artificial intelligence, AI) 기법을 사용하기 위한 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2021-7006783", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이미지(예를 들어, 디지털 이미지, 비디오 프레임 등)는 다수의 상이한 타입의 디바이스에 의해 캡처될 수 있다. 예를 들어, 비디오 기록 디바이스, 디지털 카메라, 이미지 센서, 의료 이미징 디바이스, 전자기장 감지및/또는 음향 모니터링 디바이스가 이미지를 캡처(capture)하는 데 사용될 수 있다. 캡처된 이미지는 이미지가 캡처된 환경 또는 조건의 결과로서 품질이 열악할 수 있다. 예를 들어, 어두운 환경에서 및/또는 열악한 조명 조건 하에 캡처된 이미지는 품질이 열악할 수 있어서, 이미지의 대부분이 상당히 어둡거나 및/또는 잡음이 있을 수 있다. 캡처된 이미지는 또한, 저비용 및/또는 저품질의 이미징 센서를 사용하는 디바이스와 같은, 디바이스 의 물리적인 제약에 기인하여 품질이 열악할 수 있다. 다양한 양상에 따라, 저조도 조건(low light conditions) 및/또는 잡음이 있는 이미지(noisy images)에서 캡처 되는 이미지와 같은 열악한 품질의 이미지를 향상시키기 위한 시스템 및 방법이 제공된다. 저조도 조건에서 이 미징 디바이스에 의해 캡처된 이미지는 캡처된 이미지가 예를 들어, 열악한 대비(contrast), 흐려짐(blurring), 잡음 아티팩트를 갖거나 및/또는 다르게 이미지에서 하나 이상의 객체를 명확하게 디스플레이 하지 못하게 할 수 있다. 본원에서 설명된 기법은 선명한 이미지를 생성하기 위해 이들 및 다른 타입의 이미지를 향상시키기 위 한 인공지능(AI) 접근법을 사용한다. 일부 실시예는 이미지를 향상시키기 위해 기계 학습 시스템을 트레이닝하기 위한 시스템에 관련된다. 시스템은 프로세서, 및 프로세서-실행가능 명령어를 저장하는 비일시적 컴퓨터-판독가능 저장 매체를 포함하고, 상기 프 로세서-실행가능 명령어는 프로세서에 의해 실행될 때, 프로세서가: 기계 학습 시스템을 트레이닝하는 데 사용 될 트레이닝 이미지의 세트를 획득하는 것 - 획득하는 것은: 장면의 입력 이미지를 획득하는 것; 및 장면의 복 수의 이미지를 평균냄으로써 장면의 타겟 출력 이미지를 획득하는 것 - 타겟 출력 이미지는 입력 이미지의 타겟 향상을 나타냄 -을 포함함 -; 및 트레이닝 이미지의 세트를 사용하여 기계 학습 시스템을 트레이닝하는 것을 수 행하게 한다. 일부 예시에서, 시스템은 입력 이미지의 세트를 획득하는 것 - 입력 이미지의 세트에서 각 입력 이미지는 대응 하는 장면의 것임 -, 입력 이미지의 세트에서 각 입력 이미지에 대해, 대응하는 장면의 복수의 이미지를 평균냄 으로써 대응하는 장면의 타겟 출력 이미지를 획득하는 것을 포함하는 타겟 출력 이미지의 세트를 획득하는 것, 및 입력 이미지의 세트 및 타겟 출력 이미지의 세트를 사용하여 기계 학습 시스템을 트레이닝하도록 더 구성된 다. 일부 예시에서, 입력 이미지를 획득하는 것은 미리 결정된 ISO 임계치를 초과하는 ISO 설정에서 입력 이미지를 획득하는 것을 포함한다. 일부 예시에서, ISO 임계치는 대략 1500 내지 500,000의 ISO 범위로부터 선택된다. 일부 예시에서, 복수의 이미지를 평균내는 것은 복수의 이미지에서 각 픽셀 위치에 걸쳐 산술 평균을 계산하는 것을 포함한다. 일부 예시에서, 트레이닝 이미지의 세트를 획득하는 것은 복수의 이미지 캡처 설정에 대한 트레이닝 이미지의 세트를 획득하는 것을 포함한다. 일부 예시에서, 트레이닝 이미지의 세트를 획득하는 것은 이미지의 입력 세트 및 이미지의 출력 세트를 캡처하 는 데 사용되는 이미징 디바이스의 잡음을 캡처하는 하나 이상의 이미지를 획득하는 것을 포함한다. 일부 예시에서, 명령어는 프로세서가 트레이닝 이미지의 제2 세트를 획득하는 것을 수행하고, 트레이닝 이미지 의 제2 세트를 사용하여 기계 학습 시스템을 재트레이닝하는 것을 더 하게 한다. 일부 예시에서, 명령어는 프로세서가: 각각의 이미징 디바이스로부터 트레이닝 이미지의 세트를 획득하는 것, 및 각각의 디바이스에 대해 기계 학습 시스템에 의한 향상을 최적화하기 위해 각각의 디바이스로부터 이미지의 제1 트레이닝 세트를 기초로 기계 학습 시스템을 트레이닝하는 것을 더 하게 한다. 일부 예시에서, 기계 학습 시스템은 신경망을 포함한다. 일부 예시에서, 기계 학습 시스템을 트레이닝하는 것은 다수의 손실 함수의 선형 조합을 최소화하는 것을 포함 한다. 일부 예시에서, 기계 학습 시스템을 트레이닝하는 것은 인간이 지각 가능한 주파수 범위에서의 성능을 위해 기 계 학습 시스템을 최적화하는 것을 포함한다. 일부 예시에서, 기계 학습 시스템을 트레이닝하는 것은 각각의 입력 이미지에 대응하는 기계 학습 시스템에 의 해 생성된 향상된 이미지를 획득하는 것, 각각의 입력 이미지에 대응하는 타겟 출력 이미지의 세트의 각각의 타 겟 출력 이미지를 획득하는 것, 향상된 이미지 및 타겟 출력 이미지를 대역 통과 필터를 통해 통과시키는 것, 및 필터링된 향상된 이미지 및 필터링된 타겟 출력 이미지를 기초로 기계 학습 시스템을 트레이닝하는 것을 포 함한다. 일부 예시에서, 기계 학습 시스템을 트레이닝하는 것은 트레이닝 이미지의 세트를 캡처하는 데 사용되는 이미징 디바이스와 연관된 잡음 이미지를 획득하는 것 - 잡음 이미지는 이미징 디바이스에 의해 생성된 잡음을 캡처함 -, 및 잡음 이미지를 기계 학습 시스템으로의 입력으로서 포함시키는 것을 포함한다. 일부 예시에서, 기계 학습 시스템을 트레이닝하는 데 사용될 트레이닝 이미지의 세트를 획득하는 것은 중립 밀 도 필터(neutral density filter)를 사용하여 입력 이미지의 세트를 획득하는 것 - 입력 이미지의 세트의 각 이 미지는 대응하는 장면의 것임 -; 및 입력 이미지의 세트에서 각 입력 이미지에 대해, 중립 밀도 필터 없이 캡처 되는 대응하는 장면의 타겟 출력 이미지를 획득하는 것을 포함하는 타겟 출력 이미지의 세트를 획득하는 것 - 타겟 출력 이미지는 입력 이미지의 타겟 향상을 나타냄 -을 포함한다. 일부 실시예는 이미지를 자동으로 향상시키기 위한 시스템에 관한 것이다. 시스템은 프로세서 및 프로세서에 의 해 구현된 기계 학습 시스템을 포함하며, 상기 기계 학습 시스템은 입력 이미지를 수신하고 입력 이미지를 기초 로, 입력 이미지에서보다 더 조명되는(illuminated) 입력 이미지의 적어도 일부를 포함하는 출력 이미지를 생성 하도록 구성된다. 기계 학습 시스템은 장면의 입력 이미지 및 장면의 타겟 출력 이미지를 포함하는 트레이닝 이 미지의 세트를 기초로 트레이닝되고, 타겟 이미지는 장면의 복수의 이미지를 평균냄으로써 획득되며, 타겟 출력 이미지는 입력 이미지의 타겟 향상을 나타낸다. 일부 예시에서, 트레이닝 이미지의 세트의 하나 이상의 입력 이미지는 중립 밀도 필터로 캡처되고, 트레이닝 이 미지의 세트의 하나 이상의 출력 이미지는 중립 밀도 필터 없이 캡처된다. 일부 예시에서, 프로세서는 제1 이미지를 수신하고, 제1 이미지를 제1 복수의 이미지 부분으로 나누고, 제1 복 수의 이미지 부분을 기계 학습 시스템에 입력하고, 기계 학습 시스템으로부터 제2 복수의 이미지 부분을 수신하 고, 출력 이미지를 생성하기 위해 제2 복수의 이미지를 결합하도록 구성된다. 일부 예시에서, 기계 학습 시스템은 제1 복수의 이미지 부분의 각각의 것에 대해, 각각의 이미지 부분의 일부를 자르도록(crop) 구성되고, 각각의 이미지 부분의 일부는 각각의 이미지 부분의 픽셀의 서브셋을 포함한다. 일부 예시에서, 프로세서는 제1 복수의 부분의 크기를 결정하고, 제1 이미지를 제1 복수의 부분으로 나누도록 구성되고, 제1 복수의 부분의 각각은 크기를 갖는다. 일부 예시에서, 기계 학습 시스템은 컨볼루션 신경망(convolutional neural network) 또는 밀집하게 연결된 컨 볼루션 신경망을 포함하는 신경망을 포함한다. 일부 예시에서, 프로세서는 제1 이미지를 획득하고, 양자화된 이미지를 획득하기 위해 제1 이미지를 양자화하고, 양자화된 이미지를 기계 학습 시스템에 입력하고, 기계 학습 시스템으로부터 각각의 출력 이미지를 수신하도록 구성된다. 일부 실시예는 이미지를 향상시키기 위해 기계 학습 시스템을 트레이닝하기 위한 컴퓨터화된 방법에 관한 것이다. 방법은 기계 학습 시스템을 트레이닝하는 데 사용될 트레이닝 이미지의 세트를 획득하는 것을 포함하고, 획 득하는 것은 장면의 입력 이미지를 획득하는 것 및 장면의 복수의 이미지를 평균냄으로써 장면의 타겟 출력 이 미지를 획득하는 것을 포함하며, 타겟 출력 이미지는 입력 이미지의 타겟 향상을 나타낸다. 방법은 트레이닝 이 미지의 세트를 사용하여 기계 학습 시스템을 트레이닝하는 것을 포함한다. 일부 실시예는 이미지를 향상시키기 위해 기계 학습 모델을 트레이닝하는 방법에 관한 것이다. 방법은 디스플레 이된 비디오 프레임의 타겟 이미지에 액세스하는 것 - 타겟 이미지는 기계 학습 모델의 타겟 출력을 나타냄 -, 디스플레이된 비디오 프레임의 입력 이미지에 액세스하는 것 - 입력 이미지는 타겟 이미지에 대응하고 기계 학 습 모델에 대한 입력을 나타냄 -, 및 트레이닝된 기계 학습 모델을 획득하기 위해, 타겟 이미지 및 타겟 이미지 에 대응하는 입력 이미지를 사용하여 기계 학습 모델을 트레이닝하는 것을 수행하도록, 적어도 하나의 컴퓨터 하드웨어 프로세서를 사용하는 것을 포함한다. 일부 예시에서, 방법은 이미징 디바이스를 사용하여, 제1 노출 시간을 사용하여 디스플레이된 비디오 프레임의 타겟 이미지를 캡처하는 것 및 이미징 디바이스를 사용하여 제2 노출 시간을 사용하여 디스플레이된 비디오 프레임의 입력 이미지를 캡처하는 것을 더 포함하고, 제2 노출 시간은 제1 노출 시간보다 짧다. 일부 실시예에서, 방법은 이미징 디바이스를 사용하여, 중립 밀도 필터를 통해 디스플레이된 비디오 프레임의 입력 이미지를 캡처하는 것, 및 이미징 디바이스를 사용하여 중립 밀도 필터 없이 디스플레이된 비디오 프레임 의 타겟 이미지를 캡처하는 것을 더 포함한다. 일부 예시에서, 방법은 이미징 디바이스를 사용하여 디스플레이된 비디오 프레임의 입력 이미지를 캡처하는 것, 및 이미징 디바이스를 사용하여, 비디오 프레임의 다수의 정적 캡처의 각 픽셀 위치를 평균냄으로써 디스플레이 된 비디오 프레임의 타겟 이미지를 캡처하는 것을 포함한다. 일부 예시에서, 방법은 이미징 디바이스를 사용하여, 제1 노출 시간을 사용하여 디스플레이된 비디오 프레임의 타겟 이미지를 캡처하는 것 - 디스플레이된 비디오 프레임은 제1 밝기로 디스플레이됨 -, 및 이미징 디바이스를 사용하여, 제1 노출 시간을 사용하여 디스플레이된 비디오 프레임의 입력 이미지를 캡처하는 것 - 디스플레이된 비디오 프레임은 제1 밝기보다 어두운 제2 밝기로 디스플레이됨 -을 포함한다. 일부 예시에서, 입력 이미지 및 타겟 이미지가 디스플레이된 비디오 프레임과 연관된 데이터와 상이한 제2 데이 터를 포함하도록, 입력 이미지 및 타겟 이미지는 연관된 내부 부분에서 디스플레이된 비디오 프레임을 각각 포 함하고, 및 방법은 제1 데이터를 포함하고 제2 데이터를 배제하도록 입력 이미지 및 타겟 이미지의 각각을 자르 는 것을 더 포함한다. 일부 예시에서, 입력 이미지 및 타겟 이미지는 비디오 프레임을 디스플레이하는 디스플레이 디바이스의 제2 개 수의 픽셀보다 적은 동일한 제1 개수의 픽셀을 각각 포함한다. 일부 예시에서, 방법은 이미지에 액세스하는 것, 이미지에 대해 업데이트된 픽셀 값을 나타내는 대응하는 출력 을 획득하기 위해 트레이닝된 기계 학습 모델에 대한 입력으로서 이미지를 제공하는 것, 및 트레이닝된 기계 학 습 모델로부터 출력을 사용하여 이미지를 업데이트하는 것을 포함한다. 일부 예시에서, 방법은 복수의 추가적인 타겟 이미지에 액세스하는 것을 포함하고, 추가적인 타겟 이미지의 각 타겟 이미지는 연관된 디스플레이된 비디오 프레임의 것이고, 연관된 디스플레이된 비디오 프레임에 대한 기계 학습 모델의 연관된 타겟 출력을 나타낸다. 방법은 추가적인 입력 이미지에 액세스하는 것을 포함하고, 추가적 인 입력 이미지의 각 입력 이미지는 입력 이미지가 대응하는 타겟 이미지와 동일한 디스플레이된 비디오 프레임 의 것이도록 추가적인 타겟 이미지의 타겟 이미지에 대응하고, 및 대응하는 타겟 이미지에 대한 기계 학습 모델 에 대한 입력을 나타낸다. 방법은 트레이닝된 기계 학습 모델을 획득하기 위해 (a) 타겟 이미지 및 타겟 이미지 에 대응하는 입력 이미지, 및 (b) 복수의 추가적인 타겟 이미지 및 복수의 추가적인 연관된 입력 이미지를 사용 하여 기계 학습 모델을 트레이닝하는 것을 포함한다. 일부 실시예는 이미지를 향상시키기 위해 기계 학습 모델을 트레이닝하기 위한 시스템에 관한 것이다. 시스템은 비디오의 비디오 프레임을 디스플레이하기 위한 디스플레이, 및 디스플레이된 비디오 프레임의 타겟 이미지를 캡처하는 것 - 타겟 이미지는 기계 학습 모델의 타겟 출력을 나타냄 -, 및 디스플레이된 비디오 프레임의 입력 이미지를 캡처하는 것 - 입력 이미지는 타겟 이미지에 대응하고, 기계 학습 모델에 대한 입력을 나타냄 -을 하 도록 구성되는 디지털 이미징 디바이스를 포함한다. 시스템은 적어도 하나의 하드웨어 프로세서 및 프로세서-실 행가능 명령어를 저장하는 적어도 하나의 비일시적 컴퓨터 판독가능 저장 매체를 포함하는 컴퓨팅 디바이스를 포함하고, 상기 프로세서-실행가능 명령어는 적어도 하나의 하드웨어 프로세서에 의해 실행될 때, 적어도 하나 의 하드웨어 프로세서가 타겟 이미지 및 입력 이미지에 액세스하는 것, 및 트레이닝된 기계 학습 모델을 획득하 기 위해, 타겟 이미지 및 타겟 이미지에 대응하는 입력 이미지를 사용하여 기계 학습 모델을 트레이닝하는 것을 수행하게 한다. 일부 예시에서, 디스플레이는 텔레비전, 프로젝터 또는 이들의 일부 조합을 포함한다. 일부 실시예는 프로세서-실행가능 명령어를 저장하는 적어도 하나의 컴퓨터 판독가능 저장 매체에 관련되고, 상 기 프로세서-실행가능 명령어는 적어도 하나의 프로세서에 의해 실행될 때, 적어도 하나의 프로세서가 디스플레 이된 비디오 프레임의 타겟 이미지에 액세스하는 것 - 타겟 이미지는 기계 학습 모델의 타겟 출력을 나타냄 -, 디스플레이된 비디오 프레임의 입력 이미지에 액세스하는 것 - 입력 이미지는 타겟 이미지에 대응하고 기계 학 습 모델에 대한 입력을 나타냄 -, 및 트레이닝된 기계 학습 모델을 획득하기 위해 타겟 이미지 및 타겟 이미지 에 대응하는 입력 이미지를 사용하여 기계 학습 모델을 트레이닝하는 것을 수행하게 한다. 따라서, 후속하는 본원의 상세한 설명이 더 잘 이해될 수 있고, 상기 기술에 대한 현재의 기여가 더 잘 인식될 수 있도록, 개시된 주제의 특징은 오히려 폭넓게 나타난다. 물론, 이하에서 설명되고 이에 첨부된 청구범위의 주제를 형성할 개시된 주제의 추가적인 특징이 있다. 본원에서 사용된 어법 및 용어는 설명을 위한 것이며 제한 하는 것으로 간주되지 않아야 한다는 것이 이해되어야 한다."}
{"patent_id": "10-2021-7006783", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명자는 저조도에서 캡처된 이미지와 같이 잡음이 있는 이미지를 캡처할 때 이미징 디바이스(예를 들어, 디 지털 카메라, 이미지 센서, 의료 이미징 디바이스 및/또는 전자기장 센서)가 열악하게 수행될 수 있음을 인식하 였다. 예를 들어, 디지털 카메라는 통상적으로, 색상 필터 어레이(color filter array, CFA)를 통해 이후에 필 터링되는, 광학 렌즈를 통해 광파를 수신하고, 수신된 광파를 전기 신호로 변환하는 이미지 센서를 가질 수 있 다. 그 후, 전기 신호는 이미지 신호 처리(image signal processing, ISP) 알고리즘의 체인을 통해 하나 이상의 디지털 값(예를 들어, 적색, 청색 및 녹색(RGB) 채널 값)으로 변환된다. 조명량(amount of lighting)이 적은 조 건에서는 이미징 디바이스에 의해 캡처된 이미지의 품질이 열악할 수 있다. 예를 들어, 디지털 카메라에서 이미 지 센서는 조도량(amount of light)이 낮을 때, 이미지에서 하나 이상의 객체를 구분하기에 충분한 정보를 캡처 할만큼 충분히 민감하지 않을 수 있다. 따라서, 저조도는 열악한 대비의 이미지, 잡음 아티팩트 및/또는 이미지 에서 흐려진 객체로 이어질 수 있다. 저조도에서 이미지를 캡처하기 위한 종래의 해결책은 저조도에서 성능에 특화된 이미징 센서의 사용을 수반할 수 있다. 하지만, 이러한 센서는 다른 이미징 센서에 비해 더욱 큰 크기를 가질 수 있다. 예를 들어, 스마트폰 용 디지털 카메라는 크기 제한에 기인하여, 이러한 특수 센서를 스마트폰에 통합하지 못할 수 있다. 특수 센서 는 또한, 더욱 많은 전력 및 다른 리소스를 요구할 수 있으며, 따라서 디바이스(예를 들어, 스마트폰)의 효율을 감소시킬 수 있다. 나아가, 이러한 특수 센서는 저조도에서 동작하는 데 특화되지 않은 이미징 센서에 비해, 종종 상당히 비용이 더욱 많이 든다. 다른 해결책은 종종, 상이한 애플리케이션에 걸쳐 구현될 수 없는 좁은 사용 사례를 갖는다. 예를 들어, 적외선 또는 열 센서, 라이다(LIDAR) 등의 추가는 저조도에서 캡처된 이미지를 개선 하는 데 사용될 수 있다. 하지만, 이는 종종 추가적인 하드웨어 및 리소스를 요구한다. 다수의 리소스가 제한된 디바이스는 이러한 해결책을 통합하지 못할 수 있다. 본 발명자는 디바이스의 기존의 하드웨어의 추가 또는 변경을 요구하지 않으면서, 더욱 높은 품질의 이미지를 획득하기 위해 저조도 조건에서 캡처된 것과 같은, 잡음이 있는 이미지를 향상시키기 위한 기술을 개발하였다. 이 기술은 또한, 전통적인 ISP 알고리즘과 같은, 다른 종래의 기법보다 더 나은 성능을 제공할 수 있다. 향상된 이미지는 이미지 분할(image segmentation), 객체 검출, 안면 인식 및/또는 다른 애플리케이션과 같은 이미지를 이용하는 다른 애플리케이션의 개선된 성능을 더 제공할 수 있다. 지도 학습(supervised learning)은 일반적으로, 입력-출력 트레이닝 데이터 세트를 사용하여 기계 학습 모델을 트레이닝하는 프로세스를 지칭한다. 기계 학습 모델은 변환을 적절하게 수행하기 위해 (예를 들어, 가중치 및/ 또는 바이어스와 같은) 적절한 모델 파라미터를 검색하도록 가령, 신경망을 사용함으로써 트레이닝 데이터의 입 력-출력 쌍 간에 어떻게 매핑할지를 학습하며, 기계 학습 모델이 새로운 데이터를 처리하는 것을 허용한다. 기 계 학습 기법은 디바이스의 기존의 하드웨어의 추가 또는 변경을 요구하지 않으면서, 이미징 디바이스에 의해 캡처된 이미지 및/또는 비디오를 향상시키는 데 사용될 수 있다. 예를 들어, 디지털 카메라에 의해 캡처된 이미 지 또는 비디오는 이미지 또는 비디오의 향상된 버전의 출력을 획득하기 위해 트레이닝된 기계 학습 모델에 대 한 입력으로서 제공될 수 있다. 본 발명자는 새로운 입력 이미지 또는 비디오 프레임을 향상시키는데 사용되는 기계 학습 모델을 트레이닝하는데 사용될 수 있는 이미지의 입력-출력 세트의 제어된 생성을 위한 기법을 개발 하였다. 일부 실시예에서, 기계 학습 모델은 선명하고 고품질의 타겟 이미지를 생성하기 위해 어두운 입력 이미 지의 저조도 향상을 수행하는데 사용될 수 있다. 일부 실시예에서, 기계 학습 모델은 잡음 제거된(denoised) 타 겟 이미지를 생성하기 위해 (예를 들어, 높은 ISO 값에서 취해진) 입력 이미지의 잡음 제거를 수행하는데 사용 될 수 있다. 설명의 편의를 위해, 제한하려는 의도 없이, 입력 이미지는 또한, 본원에서 \"어두운 이미지(dark images)\"로 지칭될 수 있고, 출력 이미지는 본원에서 \"타겟 이미지\" 및/또는 \"선명한 이미지(bright images)\"로 지칭될 수 있다. 타겟 이미지는 기계 학습 모델에 의해 생성될 타겟 조명된 출력의 양상을 나타낼 수 있다. 본원에서 \"어두운 이미지\" 및 \"선명한 이미지\"란 용어가 설명의 편의를 위해 사용되었지만, 이들은 밝기만을 지 칭하거나, 또는 밝기에 관련되지 않은 이미지의 특성을 배제하는 것으로 의도되지 않는다는 것이 이해되어야 한 다. 예를 들어, 상기 기법은 더 나은 신호 대 잡음비를 갖는 이미지를 생성하기 위해 잡음이 있는 이미지를 처 리하는데 사용될 수 있다. 그러므로, 본원에서 설명된 일부 예시가 어두운 이미지 및 선명한 이미지를 지칭하지 만, 상기 기법은 잡음, 밝기, 대비, 흐려짐, 아티팩트 및/또는 다른 잡음 아티팩트를 포함하는 입력 이미지의 다양한 타입의 바람직하지 않은 양상을 처리하는데 사용될 수 있음이 인식되어야 한다. 따라서, 본원에서 설명 된 기법을 사용하여 처리된 입력 이미지는 바람직하지 않은 양상이 있는 임의의 타입의 이미지일 수 있으며, 출 력 이미지는 바람직하지 않은 양상이 완화되거나 및/또는 제거된 (예를 들어, 본원에서 설명된 기계 학습 기법 을 사용하여 생성될 수 있는) 이미지를 나타낼 수 있다. 본 발명자는 (예를 들어, 신경망을 통한) 지도 학습을 사용한 원시 이미징 데이터의 향상이 동일한 객체 또는 장면의 어두운 이미지 및 대응하는 선명한 타겟 이미지의 쌍과 같은, 어두운 이미지 및 선명한 이미지의 입력- 타겟, 트레이닝 쌍으로 또한 본원에서 지칭되는 입력-출력을 사용하여 달성될 수 있음을 발견하고 인식하였다. 입력-타겟 이미지를 캡처하는데 사용되는 일부 기법은 저조도로 실세계 객체 또는 장면을 촬영하는 것을 포함하 고, 이에 의해 어두운 이미지는 짧은 노출(예를 들어, 1/15 또는 1/30초)로 캡처되고, 선명한 이미지는 긴 노출 (예를 들어, 1초, 2초, 10초 또는 그 이상)로 캡처될 수 있다. 긴 노출을 사용함으로써, 결과적인 선명한 이미 지가 상당히 더 밝아지고, 장면에 다른 것보다 상당히 더 많은 주변광이 존재하는 것처럼 보인다. 저조도 장면 을 캡처하는 입력-타겟 이미지를 사용하는 것은 기계 학습 모델을 사용하여 처리될 예상된 입력 이미지와 유사 한 조도 하에 캡처된 입력 이미지를 사용하여 기계 학습 모델을 트레이닝할 수 있으며, 이는 저조도 조건에서 사용될 때 상기 기계 학습 모델이 이미징 디바이스의 잡음 특성을 캡처하게 할 수 있다. 하지만, 본 발명자는 디바이스에 의해 캡처된 이미지를 향상시키는데 있어서 기계 학습 모델의 성능이 기계 학 습 모델을 트레이닝하는데 사용되는 트레이닝 데이터(예를 들어, 입력 이미지 및/또는 대응하는 타겟 출력 이미 지)의 품질에 의해 제한된다는 것을 인식하였다. 디바이스에 의해 저조도에서 캡처될 이미지를 더 정확하게 나 타내는 입력 이미지를 사용하여 트레이닝된 기계 학습 모델은 디바이스에 의해 저조도에서 캡처된 이미지의 더 나은 향상을 제공할 것이다. 본 발명자는 또한, 다양한 실세계 장면 및 위치에 대해 수집된 데이터를 포함하는, 광범위한 실세계 트레이닝 데이터를 제공하는 것이 바람직하다는 것을 인식하였다. 하지만, 이러한 방식으로 선명한 이미지를 캡처하는 것은 트레이닝 목적으로 바람직할 수 있는, 움직임이 있는 장면이 선명한 이미지에 흐 려짐을 유발할 수 있다는 사실에 의해 복잡해질 수 있다. 다수의 실세계 장면이 움직임을 포함하기 때문에, 기 존의 기법은 이러한 장면의 입력-타겟 이미지 쌍을 충분히 캡처하는데 사용될 수 없다. 특히, 비디오 향상의 목 적으로 모션이 있는 선명한 연속적인 장면 프레임을 캡처하는 것은 불가능하지는 않더라도 어려울 수 있다. 예 를 들어, 장면을 촬영할 때, 사진이 움직임에 기인한 흐려짐을 나타낼 수 있다. 유사하게, 장면의 비디오를 캡 처할 때, 이는 장면의 (예를 들어, 1/30초의 길이인) 선명한 프레임을 캡처하는 것이 바람직할 수 있지만, 장면 의 어두운 이미지 또한 캡처하기 위해 어두운 환경을 사용할 때와 같이, 이러한 이미지를 캡처하는 것은 어려울 수 있다. 추가적으로, 트레이닝 목적으로 또한 바람직할 수 있는 상이한 장면의 이미지를 갖는 광범위한 데이터 세트를 캡처하기 위해, 작업자는 카메라를 각 위치로 및/또는 각 위치의 다양한 이미징 지점 주위로 물리적으로 이동시 켜야 하며, 이는 충분한 트레이닝 데이터를 적절하게 수집하는데 있어서 실용성(practicality)을 더 제한한다. 예를 들어, 장면의 충분한 수의 입력-타겟 이미지 쌍을 캡처하기 위해서는, 카메라를 장면의 수백 또는 수천개 의 위치뿐만 아니라 수십만 개의 상이한 위치로 이동시키는 것을 요구할 수 있다. 이러한 기법이 카메라가 각 위치에 물리적으로 존재하도록 요구하기 때문에, 이는 시간, 이동 등에 대한 실질적인 제약에 기인하여, 트레이 닝 데이터의 강인함을 상당히 제한할 수 있다. 본 발명자는 사전 캡처된 비디오를 사용하여 실세계 데이터를 시뮬레이션하기 위한 컴퓨터 기법을 개발하였다. 이 기법은 프레임 단위로 비디오 프레임을 디스플레이하는 디스플레이 디바이스(예를 들어, 텔레비전 또는 프로 젝터)를 사용하는 것을 포함한다. 일부 실시예에서, 사전 캡처된 비디오는 이미징 디바이스가 동일한 비디오 프 레임의 어두운 이미지 및 선명한 이미지 모두를 캡처하는 것을 가능하게 하기 위해, 프레임이 충분한 기간 및/ 또는 충분한 밝기로 디스플레이되는 것을 허용한다. 그러므로, 타겟 이미지는 정상적인 조명 조건 하에 이미징 디바이스에 의해 캡처된 것처럼 비디오 프레임의 장면을 나타낼 수 있으며, 입력 이미지는 이미징 디바이스에 의해 저조도에서 캡처된 것처럼 비디오 프레임의 장면을 나타낼 수 있다. 일부 실시예에서, 이미징 디바이스는 짧은 노출 시간을 사용하여 프레임의 어두운 이미지를 캡처하고, 긴 노출 시간을 사용하여 프레임의 선명한 이 미지를 캡처할 수 있다. 일부 실시예에서, 디스플레이의 밝기는 통상적으로 사용되는 것보다 더 짧은 노출 시간 으로 및/또는 어두운 이미지를 캡처하는데 사용되는 것과 유사한 노출 시간을 사용하여, 선명한 이미지가 캡처 되는 것을 허용하도록 조정될 수 있다. 그러므로, 본원에서 설명된 기법은 각 비디오 프레임의 어두운 이미지 및 선명한 이미지의 제어된 생성을 제공한다. 이미지를 프레임 단위로 캡처함으로써, 상기 기법은 개별적인 입 력-타겟 이미지 쌍이 흐려짐에 기인한 아티팩트를 나타내지 않도록, 움직임이 있는 장면의 입력-타겟 이미지 쌍 을 생성하는데 사용될 수 있다. 상기 기법은 이미징 디바이스가 충분한 트레이닝 데이터를 수집하기 위해 수천 개의 실제 위치에 물리적으로 존재하는 것(및 이에 물리적으로 이동되는 것)을 요구하는 대신에, 다양한 장면에 걸쳐 빠른 데이터 수집을 가능하게 할 수 있다. 다음의 설명에서, 개시된 주제의 철저한 이해를 제공하기 위해, 개시된 주제의 시스템 및 방법 및 이러한 시스 템 및 방법이 작동할 수 있는 환경 등에 관한 다수의 특정한 세부사항이 제시된다. 덧붙여, 아래에 제공된 예시 는 예시적인 것이며, 개시된 주제의 범주 내에 있는 다른 시스템 및 방법이 있는 것으로 고려된다는 것이 이해 될 것이다. 일 양상에 따라, 저조도 조건에서 캡처된 이미지와 같이, 잡음이 있는 이미지를 향상시키기 위한 시스템이 제공 된다. 시스템은 이미지를 향상시키기 위해 사용될 기계 학습 시스템을 트레이닝하기 위해 트레이닝 이미지의 세 트를 사용한다. 시스템은 저조도 조건에서 캡처된 이미지(예를 들어, 코의 일부 부분을 나타내는 \"어두운\" 이미 지)를 나타내는 트레이닝 이미지의 입력 세트를 사용한다. 이 입력 이미지의 세트는 예를 들어, 향상을 위해 기 계 학습 시스템에 입력될 저조도 이미지를 나타낼 수 있다. 시스템은 트레이닝 이미지의 제1 세트에 대응하는 트레이닝 이미지의 출력 세트를 사용한다. 이미지의 출력 세트는 입력 이미지(예를 들어, 입력 이미지보다 적은 잡음을 포함하는 \"밝은(light)\" 또는 \"선명한(bright)\" 이미지)를 처리한 이후에 기계 학습 시스템에 의해 출력 될 이미지의 제1 세트의 타겟 버전일 수 있다. 일부 실시예에서, 이미지의 제1 및 제2 세트는 기계 학습 시스템 을 트레이닝하기 위한 지도 학습 스킴(scheme)에서 트레이닝 데이터의 입력 및 출력으로서 각각 사용될 수 있다. 일부 실시예에서, 시스템은 입력 이미지에서 휘도(luminance)의 수준을 증가시키도록 트레이닝될 수 있다. 일부 실시예에서, 시스템은 증가된 휘도를 갖는 출력 이미지를 생성하도록 구성될 수 있다. 일부 실시예에서, 시스템 은 입력 이미지의 휘도를 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19 및/또는 20배로 증가시킬 수 있다. 일부 실시예에서, 시스템은 입력 이미지의 하나 이상의 다른 부분에 대해 상이한 양만큼 입력 이미지의 하나 이상의 부분의 휘도를 증가시키도록 구성될 수 있다. 일부 실시예에서, 시스템은 입력 이미지 의 휘도를 5 내지 15배 증가시키도록 구성될 수 있다. 일부 실시예에서, 시스템은 입력 이미지의 휘도를 6 내지 13배 증가시키도록 구성될 수 있다. 일부 실시예에서, 시스템은 입력 이미지의 휘도를 적어도 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19 또는 20배 증가시키도록 구성될 수 있다. 일부 실시예에서, 시스템은 밝기, 대비, 흐려짐 등과 같은 입력 이미지를 손상시키는(corrupting) 잡음 아티팩 트를 제거하도록 트레이닝될 수 있다. 입력 이미지를 손상시키는 잡음 아티팩트를 제거함으로써, 상기 기법은 이미지의 신호 대 잡음비를 증가시킬 수 있다. 예를 들어, 상기 기법은 신호 대 잡음비를 예를 들어 대략 2- 20dB만큼 증가시킬 수 있다. 일부 실시예에서, 이미지의 입력 세트는 중립 밀도 필터(neutral density filter)를 사용하는 이미징 디바이스 로 이미지를 캡처함으로써 획득된다. 중립 밀도 필터는 이미징 디바이스의 렌즈에 들어오는 광의 강도를 감소시 키거나 또는 수정하는 광학 필터이다. 본 발명자는 트레이닝 세트에서 입력 이미지의 세트를 생성하기 위해 중 립 밀도 필터를 사용하는 것이 저조도에서 촬영된 이미지의 특성을 정확하게 반영할 수 있다는 것을 인식하였다. 예를 들어, 중립 밀도 필터에 의해 캡처된 이미지는 저조도 조건에서 캡처된 이미지의 것과 유사한 잡음 특성을 갖는다. 트레이닝 세트의 각각의 입력 이미지에 대응하는 출력 이미지는 중립 밀도 필터를 사용하 지 않으면서, 이미징 디바이스로 동일한 이미지를 캡처함으로써 획득될 수 있다. 출력 이미지는 기계 학습 시스 템이 트레이닝될 수 있는 것에 기초하여 각각의 입력 이미지의 타겟 향상된 버전을 나타낸다. 본 발명자는 중립 밀도 필터의 사용이 저조도 조건에서 캡처된 이미지에 있을 잡음 특성을 반영하는 이미지의 트레이닝 세트를 제 공하는 한편, 다른 카메라 설정을 사용하는 것(예를 들어, ISO 설정을 변경하는 것, 광원 강도를 감소시키는 것 및/또는 노출 시간을 감소시키는 것)으로부터 초래될 입력 세트와 출력 세트 사이의 변화를 감소시키는 것을 인 식하였다. 일부 실시예에서, 이미지의 입력 세트는 예를 들어, 디지털 샘플링 프로세스에서 저-강도 픽셀 값의 양자화 정 확도를 개선하거나 및/또는 최대화할 수 있는 높은 ISO 값으로 이미지를 캡처함으로써 획득된다. 일부 실시예에 서, ISO 값은 대략 1600-500,000의 범위 내에 있는 ISO 값일 수 있다. 예를 들어, 고급(high-end) 소비자 카메 라는 최대 500,000의 ISO를 가질 수 있다. 일부 실시예에서, 값은 500,000보다 높을 수 있으며, 예를 들어 특수 하드웨어 구현에 대해 최대 5백만일 수 있다. 일부 실시예에서, ISO 값은 ISO 임계치를 초과하도록 선택될 수 있다. 트레이닝 세트에서 각각의 입력 이미지에 대응하는 출력 이미지는 입력 이미지의 다수의 캡처를 (예를 들 어, 이미지의 입력 세트를 캡처하는데 사용되는 동일하거나 및/또는 유사한 ISO 설정으로) 생성하고, 후속적으 로 다수의 캡처에 걸쳐 각 픽셀에 대한 강도를 평균내는 것과 같이, 입력 이미지의 세트를 처리함으로써 획득될 수 있다. 출력 이미지는 기계 학습 시스템이 트레이닝될 수 있는 것에 기초하여 각각의 입력 이미지의 타겟 향 상된 버전을 나타낸다. 본 발명자는 일부 실시예에서, 단일 및/또는 몇 개의 긴 노출이 출력 이미지를 캡처하는 데 사용될 수 있는 한편, 긴 노출을 사용하는 것은 예를 들어, 열 잡음을 증가시킴으로써 센서의 잡음 특성을 변경할 수 있음을 인식하였다. 쿨링 간격(cooling intervals)(예를 들어, 순차적인 캡처 사이의 1초 쿨링 간 격)으로 촬영된 짧은 노출의 세트(예를 들어, 50, 100, 200 등과 같은 짧은 노출의 더 큰 세트)에 걸쳐 픽셀 강 도를 평균내는 것은 입력 프레임의 것과 일치하는 출력의 열 잡음 특성을 유지하거나, 신경망이 더 간단한 변환 함수를 학습하는 것을 가능하게 하거나, 및/또는 더 압축 가능한 신경망 모델을 허용할 수 있다. 다른 양상에 따라, 입력 이미지를 다수의 이미지 부분으로 나누기 위한 시스템이 제공된다. 그 후, 시스템은 기 계 학습 시스템에 개별적인 입력으로서 부분을 공급할 수 있다. 시스템은 최종 향상된 이미지를 생성하기 위해 개별적인 향상된 출력 부분을 함께 스티칭하도록(stitch) 구성될 수 있다. 본 발명자는 이미지를 부분으로 나누 는 것이 시스템이 전체 이미지를 한 번에 처리하는 것보다 빠르게 트레이닝 및 이미지 향상을 수행하는 것을 허 용한다는 것을 인식하였다. 다른 양상에 따라, 기계 학습 시스템을 트레이닝하기 위한 이미지의 트레이닝 세트에서의 입력 이미지로서, 카 메라의 센서로부터의 잡음만을 포함하는 하나 이상의 이미지(또한, 본원에서 \"잡음 이미지\"로 지칭됨)를 포함하 는 시스템이 제공된다. 이미지(들)는 이미지의 픽셀 값만이 이미징 디바이스의 구성요소(예를 들어, 이미징 센 서)로부터 생성된 잡음으로부터 초래되도록 거의 영의 노출(zero exposure)로 캡처될 수 있다. 시스템은 기계 학습 시스템을 사용하여 수행되는 이미지 향상에 대한 센서 잡음의 영향을 감소시키기 위해 잡음 이미지(들)를 사용하도록 구성될 수 있다. 이는 다양한 이미징 디바이스 설정(예를 들어, ISO 설정 및 노출 시간)에 걸쳐 AI 시스템의 이미지 향상 성능을 정규화할 수 있다. 다른 양상에 따라, 기계 학습 시스템이 인간이 지각 가능한 이미지 특징을 향상시키기 위해 최적화되도록, 기계 학습 시스템을 트레이닝하기 위한 시스템이 제공된다. 일부 실시예에서, 시스템은 인간이 지각 가능한 주파수에 대해 기계 학습 시스템을 최적화하도록 구성될 수 있다. 시스템은 주파수에 대해 최적으로 수행하도록 기계 학 습 시스템을 트레이닝하도록 구성될 수 있다. 본원에서는 이미지 향상을 위해 기계 학습 모델을 트레이닝하는데 사용될 수 있는 트레이닝 데이터의 제어된 생 성을 위한 시스템 및 컴퓨터 기법이 설명된다. 텔레비전 또는 프로젝터와 같은 디스플레이 디바이스는 디스플레 이된 프레임이 트레이닝 데이터를 생성하는데 사용될 수 있도록, 제어된 방식으로 비디오의 프레임을 디스플레 이할 수 있다. 이미징 디바이스(예를 들어, 디지털 카메라)는 디스플레이된 비디오 프레임의 타겟 이미지 및 입 력 이미지를 캡처하도록 구성될 수 있다. 타겟 및 입력 이미지는 상이한 노출 시간을 사용하여 및/또는 디스플 레이의 밝기를 조정함으로써 캡처될 수 있다. 일부 실시예에서, 타겟 이미지는 정상적인 조명 조건 하에서 이미 징 디바이스에 의해 캡처된 것처럼 비디오 프레임의 장면을 나타내는 비디오 프레임의 캡처된 이미지(예를 들어, 본원에서 \"선명한 이미지\"로 지칭됨)일 수 있고, 입력 이미지는 이미징 디바이스에 의해 저조도에서 캡처 된 것처럼 비디오 프레임의 장면을 나타내는 비디오 프레임의 캡처된 이미지(예를 들어, 본원에서 \"어두운 이미 지\"로 지칭됨)일 수 있다. 입력-타겟 이미지 생성 프로세스는 복수의 입력 이미지 및 연관된 타겟 이미지를 포 함하는 트레이닝 데이터 세트를 생성하기 위해 반복될 수 있다. 그 후, 입력 이미지 및 타겟 이미지는 기계 학습 모델을 트레이닝하는데 사용될 수 있다. 일부 실시예에서, 기 계 학습 모델은 대응하는 선명한 이미지를 생성하기 위해 어두운 이미지를 처리하는데 사용될 수 있다. 타겟 이 미지는 어두운 이미지의 조도(illumination)를 향상시킴으로써 생성될 타겟 조명된 출력(target illuminated output)(예를 들어, 가령, 적색, 녹색 및/또는 청색 값, 원시 베이어 패턴 값(raw Bayer pattern values), 열/ 적외선 센서 데이터 등)을 나타낼 수 있다. 따라서, 어두운 이미지 및 대응하는 타겟 이미지의 세트를 포함하는 트레이닝 데이터는 이미지를 조명함으로써 저조도 조건에서 캡처된 이미지를 향상시키는데 사용될 수 있는 기계 학습 모델을 트레이닝하는데 사용될 수 있다. 일부 실시예에서, 생성된 어두운 입력 이미지 및 대응하는 잘 조명된 타겟 이미지의 세트를 포함하는 데이터 세 트는 이미징 디바이스에 의해 캡처된 이미지(예를 들어, 저조도 조건에서 캡처된 이미지)를 조명하도록 기계 학 습 모델을 트레이닝하는데 사용될 수 있다. 예를 들어, 기계 학습 모델은 대응하는 어두운 이미지를 기초로 타 겟 선명한 이미지를 생성하도록 트레이닝될 수 있다. 그러므로, 트레이닝 프로세스는 새로운 어두운 이미지를 기초로, 어두운 이미지의 조도(예를 들어, 각 픽셀에 대한 원시 픽셀 데이터, 각 픽셀에 대한 RGB 값 등)를 기 초로 선명한 이미지에 대응하는 출력 조도(예를 들어, 각 픽셀에 대한 원시 픽셀 데이터, 각 픽셀에 대한 적색, 녹색, 청색(RGB) 값 등)을 생성하도록 기계 학습 모델을 트레이닝할 수 있다. 이미지는 사진일 수 있다. 예를 들어, 이미지는 이미징 디바이스(예를 들어, 디지털 카메라)에 의해 캡처된 사 진일 수 있다. 이미지는 또한, 비디오의 일부일 수 있다. 예를 들어, 이미지는 비디오를 구성하는 하나 이상의 프레임일 수 있다. 본원에서 설명된 일부 실시예는 본 발명자가 종래의 이미지 향상 시스템으로 인식한 상술한 문제를 다룬다. 하 지만, 본원에서 설명된 모든 실시예가 이들 문제의 모두를 다루는 것은 아니라는 것이 인식되어야 한다. 또한, 본원에서 설명된 기술의 실시예가 이미지 향상에서 위에서 논의된 문제를 해결하는 것 이외의 목적으로 사용될 수 있음이 인식되어야 한다. 도 1a는 파라미터(102A)의 세트를 갖는 기계 학습 시스템을 도시한다. 일부 실시예에서, 기계 학습 시스템 은 입력 이미지를 수신하고 향상된 출력 이미지를 생성하도록 구성된 시스템일 수 있다. 기계 학습 시스템 은 트레이닝 이미지의 세트를 기초로 트레이닝 단계 동안 파라미터(102A)의 값을 학습할 수 있 다. 트레이닝 단계 이후에, 학습된 파라미터 값(112A)으로 구성된 트레이닝된 기계 학습 시스템이 획 득된다. 트레이닝된 기계 학습 시스템은 다양한 이미징 디바이스(114A-B)에 의해 캡처된 하나 이상의 이미 지를 향상시키기 위해 이미지 향상 시스템에 의해 사용된다. 이미지 향상 시스템은 이미지 (들)를 수신하고 하나 이상의 향상된 이미지를 출력한다. 일부 실시예에서, 기계 학습 시스템은 저조도 조건에서 캡처된 이미지를 향상시키기 위한 기계 학습 시스 템일 수 있다. 일부 실시예에서, 저조도 조건에서 캡처된 이미지는 이미지에서 하나 이상의 객체를 캡처하는데 충분한 양의 광 강도가 존재하지 않는 이미지일 수 있다. 일부 실시예에서, 저조도 조건에서 캡처된 이미지는 50 럭스 미만의 광원으로 캡처된 이미지일 수 있다. 일부 실시예에서, 저조도 조건에서 캡처된 이미지는 1 럭스 이하의 광원으로 캡처된 이미지일 수 있다. 일부 실시예에서, 저조도 조건에서 캡처된 이미지는 2 럭스, 3 럭스, 4 럭스, 또는 5 럭스 이하의 광원으로 캡처된 이미지일 수 있다. 기계 학습 시스템은 저조도 설정에서 캡처된 입력 이미지를 수신하고, 더 높은 강도의 광원으로 캡처된 것처럼 객체를 디스플레이하는 대응하는 출력 이미지를 생성하도록 구성될 수 있다. 일부 실시예에서, 기계 학습 시스템은 하나 이상의 파라미터(102A)를 갖는 신경망을 포함할 수 있다. 신경 망은 다수의 계층으로 구성될 수 있으며, 이들의 각각은 하나 이상의 노드를 갖는다. 신경망의 파라미터(102A) 는 신경망의 계층에서 노드에 의해 사용되는 계수, 가중치, 필터, 또는 다른 타입의 파라미터일 수 있다. 노드 는 노드의 활성화 함수(activation function)로 전달되는 출력 값을 생성하기 위해 계수를 사용하여 입력 데이 터를 결합한다. 활성화 함수는 신경망의 다음 계층으로 전달되는 출력 값을 생성한다. 신경망의 최종 출력 계층 에 의해 생성된 값은 작업을 수행하는데 사용될 수 있다. 일부 실시예에서, 신경망의 최종 출력 계층은 입력 이 미지의 향상된 버전을 생성하는데 사용될 수 있다. 예를 들어, 출력 계층의 값은 신경망에 의해 출력될 이미지 에 대한 픽셀 값을 생성하기 위한 함수에 대한 입력으로서 사용될 수 있다. 일부 실시예에서, 신경망의 출력 계 층은 입력 이미지의 향상된 버전을 포함할 수 있다. 예를 들어, 신경망의 출력 계층은 입력 이미지의 향상된 버 전의 값 픽셀을 지정할 수 있다. 일부 실시예에서, 기계 학습 시스템은 컨볼루션 신경망(convolutional neural network, CNN)을 포함할 수 있다. CNN은 다수의 계층의 노드로 구성될 수 있다. 파라미터(102A)는 CNN의 각 계층에 적용되는 필터를 포함할 수 있다. CNN의 각 계층은 계층에 대한 입력이 컨볼루션된(convolved) 하나 이상의 학습 가능한 필터의 세트일 수 있다. 필터(들)의 각각의 컨볼루션 결과는 계층의 출력을 생성하는데 사용된다. 그 후, 계층의 출력은 후속 하는 계층의 하나 이상의 필터에 의해 수행될 컨볼루션 연산의 다른 세트에 대한 후속 계층으로 전달될 수 있다. 일부 실시예에서, CNN의 최종 출력 계층은 입력 이미지의 향상된 버전을 생성하는데 사용될 수 있다. 예 를 들어, 출력 계층의 값은 신경망에 의해 출력될 이미지에 대한 픽셀 값을 생성하는 함수에 대한 입력으로서 사용될 수 있다. 일부 실시예에서, 신경망의 출력 계층은 입력 이미지의 향상된 버전을 포함할 수 있다. 예를 들어, CNN의 출력 계층은 향상된 이미지의 픽셀에 대한 값을 지정할 수 있다. 일부 실시예에서, 컨볼루션 신경 망은 U-Net이다. 일부 실시예에서, 기계 학습 시스템은 인공 신경망(artificial neural network, ANN)을 포함할 수 있다. 일부 실시예에서, 기계 학습 시스템은 순환 신경망(recurrent neural network, RNN)을 포함할 수 있다. 일부 실시예에서, 기계 학습 시스템은 결정 트리를 포함할 수 있다. 일부 실시예에서, 기계 학습 시스템 은 지원 벡터 기계(support vector machine, SVM)를 포함할 수 있다. 일부 실시예에서, 기계 학습 시스템 은 유전 알고리즘을 포함할 수 있다. 일부 실시예는 특정한 타입의 기계 학습 모델로 제한되지 않는다. 일부 실 시예에서, 기계 학습 시스템은 하나 이상의 기계 학습 모델의 조합을 포함할 수 있다. 예를 들어, 기계 학 습 시스템은 하나 이상의 신경망, 하나 이상의 결정 트리 및/또는 하나 이상의 지원 벡터 기계를 포함할 수 있다. 트레이닝 단계 동안 기계 학습 시스템이 트레이닝된 이후에, 트레이닝된 기계 학습 시스템이 획득된 다. 트레이닝된 기계 학습 시스템은 트레이닝 이미지에 기초하여 기계 학습 시스템에 의해 수행 되는 이미지 향상의 성능을 최적화하는 학습된 파라미터(112A)를 가질 수 있다. 학습된 파라미터(112A)는 기계 학습 시스템의 하이퍼-파라미터의 값, 기계 학습 시스템의 계수 또는 가중치의 값, 및 기계 학습 시스템의 다른 파라미터의 값을 포함할 수 있다. 학습된 파라미터(112A)의 일부 파라미터는 트레이닝 단계 동안 수동으로 결정될 수 있는 한편, 다른 것은 트레이닝 단계 동안 수행되는 자동화된 트레이닝 기법에 의해 결정될 수 있다. 일부 실시예에서, 이미지 향상 시스템은 하나 이상의 이미징 디바이스(114A-B)로부터 수신된 하나 이상의 이미지의 이미지 향상을 수행하기 위해, 트레이닝된 기계 학습 시스템을 사용한다. 예를 들어, 이미 징 디바이스(들)는 카메라(114A) 및 스마트폰(114B)의 디지털 카메라를 포함할 수 있다. 기계 학습 시스템(11 2)이 상이한 이미징 디바이스로부터 수신된 이미지를 향상시킬 수 있기 때문에, 일부 실시예는 본원에서 설명된 이미징 디바이스로부터의 이미지로 제한되지 않는다. 이미지 향상 시스템은 트레이닝된 기계 학습 시스템에 대한 입력을 생성하기 위해 수신된 이미지 (들)를 사용한다. 일부 실시예에서, 이미지 향상 시스템은 하나 이상의 기계 학습 모델(예를 들어, 신경망(들))에 대한 입력으로서 이미지(들)의 픽셀 값을 사용하도록 구성될 수 있다. 일부 실시예에서, 이 미지 향상 시스템은 이미지(들)를 부분으로 나누고, 각 부분의 픽셀 값을 입력으로서 기계 학습 시스 템에 개별적으로 공급하도록 구성될 수 있다. 일부 실시예에서, 수신된 이미지(들)는 다수의 채널에 대한 값을 가질 수 있다. 예를 들어, 수신된 이미지(들)는 적색 채널, 녹색 채널 및 청색 채널에 대한 값을 가질 수 있다. 이들 채널은 또한, 본원에서 \"RGB 채널\"로 지칭될 수 있다. 수신된 이미지(들)를 향상시킨 이후에, 이미지 향상 시스템은 향상된 이미지(들)를 출력한다. 일부 실시예에서, 향상된 이미지(들)는 이미지(들)가 수신된 디바이스로 출력될 수 있다. 예를 들어, 향상된 이미지(들)는 이미지(들)가 수신된 모바일 디바이스(114B)로 출력될 수 있다. 모바일 디바이 스(114B)는 디바이스(114B)의 디스플레이에 향상된 이미지(들)를 디스플레이하고, 향상된 이미지(들)(11 8)를 저장할 수 있다. 일부 실시예에서, 이미지 향상 시스템은 생성된 향상된 이미지(들)를 저장하도 록 구성될 수 있다. 일부 실시예에서, 이미지 향상 시스템은 이미지 향상 시스템의 성능의 후속 평가 및/또는 기계 학습 시스템의 재트레이닝을 위해 향상된 이미지(들)를 사용하도록 구성될 수 있다. 일부 실시예에서, 이미지 향상 시스템은 이미지(들)가 수신된 디바이스에 배치(deployed)될 수 있다. 예를 들어, 이미지 향상 시스템은 모바일 디바이스(114B)에 의해 실행될 때, 수신된 이미지(들)의 향 상을 수행하는 모바일 디바이스(114B)에 설치된 애플리케이션의 일부일 수 있다. 일부 실시예에서, 이미지 향상 시스템은 하나 이상의 별도의 컴퓨터 상에서 구현될 수 있다. 이미지 향상 시스템은 통신 인터페이스 를 통해 이미지(들)를 수신할 수 있다. 통신 인터페이스는 무선 네트워크 연결 또는 유선 연결일 수 있다. 예를 들어, 이미지 향상 시스템은 서버에서 구현될 수 있다. 서버는 네트워크를 통해(예를 들어, 인터넷을 통해) 이미지(들)를 수신할 수 있다. 다른 예시에서, 이미지 향상 시스템은 디바이스(114A-B) 중 하 나 이상으로부터 유선 연결(예를 들어, USB)을 통해 이미지(들)를 수신하는 데스크탑 컴퓨터일 수 있다. 일부 실시예는 이미지 향상 시스템이 이미지(들)를 어떻게 획득하는 지에 의해 제한되지 않는다. 도 1b는 이미징 디바이스(예를 들어, 이미징 디바이스(114A 또는 114B))에 의해 캡처된 이미지의 이미지 향상을 수행하기 위한 이미지 향상 시스템의 예시적인 구현을 예시한다. 객체로부터의 광파는 이미징 디바이 스의 광학 렌즈를 통과하고, 이미징 센서에 도달한다. 이미징 센서는 광학 렌즈로부터 광 파를 수신하고, 수신된 광파의 강도를 기초로 대응하는 전기 신호를 생성한다. 그 후, 전기 신호는 전기 신호를 기초로 객체의 이미지의 디지털 값(예를 들어, 수치 RGB 픽셀 값)을 생성하는 아날로그-디지털(A/D) 변환 기로 송신된다. 이미지 향상 시스템은 이미지를 수신하고, 이미지를 향상시키기 위해 트레이닝된 기 계 학습 시스템을 사용한다. 예를 들어, 객체의 이미지가 객체가 흐려지거나 및/또는 열악한 대비가 있는 저조도 조건에서 캡처된 경우, 이미지 향상 시스템은 객체를 디블러링하거나(de-blur) 및/또는 대비 를 개선시킬 수 있다. 이미지 향상 시스템은 객체를 인간의 눈으로 더욱 명확하게 식별할(discernible) 수 있게 하면서 이미지의 밝기를 더욱 개선시킬 수 있다. 이미지 향상 시스템은 추가적인 이미지 처리를 위해 향상된 이미지를 출력할 수 있다. 예를 들어, 이미징 디바이스는 이미지에 대해 추가적인 처리(예를 들어, 밝기, 백색, 선명도, 대비)를 수행할 수 있다. 그 후, 이미지가 출력될 수 있다. 예를 들어, 이미지는 이 미징 디바이스의 디스플레이(예를 들어, 모바일 디바이스의 디스플레이)로 출력될 수 있거나 및/또는 이미징 디 바이스에 의해 저장될 수 있다. 일부 실시예에서, 이미지 향상 시스템은 특정한 타입의 이미징 센서와의 동작을 위해 최적화될 수 있 다. 이미징 디바이스에 의해 수행되는 추가적인 이미지 처리 이전에 이미징 센서로부터 수신된 원시 값에 대한 이미지 향상을 수행함으로써, 이미지 향상 시스템은 디바이스의 이미징 센서에 대해 최적화될 수 있다. 예를 들어, 이미징 센서는 광을 캡처하는 상보성 금속-산화물 반도체(Complementary Metal-Oxide Semiconductor, CMOS) 실리콘 센서일 수 있다. 센서는 입사광 광자를 전자로 변환하는 다수의 픽셀을 가질 수 있으며, 이는 결국 A/D 변환기로 공급되는 전기 신호를 생성한다. 다른 예시에서, 이미징 센서는 전하 결합 디바이스(charge-coupled device, CCD) 센서일 수 있다. 일부 실시예는 특정한 타입의 센서로 제한되 지 않는다. 일부 실시예에서, 이미지 향상 시스템은 특정한 타입 또는 모델의 이미징 센서를 사용하여 캡처된 트레이 닝 이미지를 기초로 트레이닝될 수 있다. 이미징 디바이스에 의해 수행되는 이미지 처리는 디바이스의 특 정한 구성 및/또는 설정을 기초로 사용자 간에 상이할 수 있다. 예를 들어, 상이한 사용자는 선호도 및 용도를 기초로 상이하게 설정된 이미징 디바이스 설정을 가질 수 있다. 이미지 향상 시스템은 이미징 디바이스에 의해 수행되는 이미지 처리로부터 초래되는 변화를 제거하기 위해 A/D 변환기로부터 수신된 원시 값에 대 한 향상을 수행할 수 있다. 일부 실시예에서, 이미지 향상 시스템은 A/D 변환기로부터 수신된 수치 픽셀 값의 포맷을 변환하도록 구성될 수 있다. 예를 들어, 값은 정수 값일 수 있고, 이미지 향상 시스템은 픽셀 값을 플로트 값(float values)으로 변환하도록 구성될 수 있다. 일부 실시예에서, 이미지 향상 시스템은 각 픽셀로부터 블랙 수준(black level)을 감산하도록 구성될 수 있다. 블랙 수준은 이미징 디바이스에 의해 캡처된 이미지의 픽셀 값 일 수 있으며, 이는 색상이 없음을 나타낸다. 따라서, 이미지 향상 시스템은 수신된 이미지의 픽셀로부터 임계치를 감산하도록 구성될 수 있다. 일부 실시예에서, 이미지 향상 시스템은 이미지 내의 센서 잡음을 감소시키기 위해 각 픽셀로부터 상수 값을 감산하도록 구성될 수 있다. 예를 들어, 이미지 향상 시스템은 이미지의 각 픽셀로부터 60, 61, 62 또는 63을 감산할 수 있다. 일부 실시예에서, 이미지 향상 시스템은 픽셀 값을 정규화하도록 구성될 수 있다. 일부 실시예에서, 이미 지 향상 시스템은 픽셀 값을 상기 픽셀 값을 정규화하기 위한 값으로 나누도록 구성될 수 있다. 일부 실시 예에서, 이미지 향상 시스템은 최대 가능한 픽셀 값과 블랙 수준에 대응하는 픽셀 값(예를 들어, 60, 61, 62, 63) 사이의 차이로 각 픽셀 값을 나누도록 구성될 수 있다. 일부 실시예에서, 이미지 향상 시스템은 각각의 픽셀 값을 캡처된 이미지의 최대 픽셀 값 및 캡처된 이미지의 최소 픽셀 값으로 나누도록 구성될 수 있 다. 일부 실시예에서, 이미지 향상 시스템은 수신된 이미지에 대한 데모자이싱(demosaicing)을 수행하도록 구 성될 수 있다. 이미지 향상 시스템은 A/D 변환기로부터 수신된 픽셀 값을 기초로 색상 이미지를 구성 하기 위해 데모자이싱을 수행할 수 있다. 시스템은 각 픽셀에 대한 다수의 채널의 값을 생성하도록 구성될 수 있다. 일부 실시예에서, 시스템은 네 개의 색상 채널의 값을 생성하도록 구성될 수 있다. 예를 들어, 시스템은 적색 채널, 두 개의 녹색 채널 및 청색 채널(RGGB)에 대한 값을 생성할 수 있다. 일부 실시예에 서, 시스템은 각 픽셀에 대해 세 개의 색상 채널의 값을 생성하도록 구성될 수 있다. 예를 들어, 시스템 은 적색 채널, 녹색 채널 및 청색 채널에 대한 값을 생성할 수 있다. 일부 실시예에서, 이미지 향상 시스템은 이미지를 다수의 부분으로 나누도록 구성될 수 있다. 이미지 향상 시스템은 각 부분을 개별적으로 향상시키고, 그 후, 각 부분의 향상된 버전을 출력 향상된 이미지로 결합 하도록 구성될 수 있다. 이미지 향상 시스템은 수신된 입력의 각각에 대해 기계 학습 시스템에 대한 입력을 생성할 수 있다. 예를 들어, 이미지는 500x500 픽셀의 크기를 가질 수 있고, 시스템은 이미지를 100x100 픽셀 부분으로 나눌 수 있다. 그 후, 시스템은 기계 학습 시스템에 각 100x100 부분을 입력 하고 대응하는 출력을 획득할 수 있다. 그 후, 시스템은 최종 이미지 출력을 생성하기 위해 각 100x100 부 분에 대응하는 출력을 결합할 수 있다. 일부 실시예에서, 시스템은 입력 이미지와 동일한 크기인 출력 이 미지를 생성하도록 구성될 수 있다. 도 2a는 일부 실시예에 따른, 기계 학습 시스템을 트레이닝하기 위한 프로세스를 도시한다. 프로세스(20 0)는 도 1a-b를 참조로 위에서 설명된 트레이닝 단계의 일부로서 수행될 수 있다. 예를 들어, 프로세스 는 학습된 파라미터(112A)로 트레이닝된 기계 학습 시스템을 획득하기 위해 파라미터(102A)로 기계 학습 시스템을 트레이닝하기 위해 수행될 수 있다. 프로세스는 기술의 양상이 이 점으로 제한되지 않 기 때문에, 하나 이상의 하드웨어 프로세서를 포함하는 임의의 컴퓨팅 디바이스(들)를 사용하여 수행될 수 있다. 프로세스는 프로세스를 실행하는 시스템이 트레이닝 이미지의 세트를 획득하는 블록에서 시작한 다. 시스템은 기계 학습 시스템에 의해 수행될 것으로 예상되는 이미지의 향상을 나타내는 트레이닝 이미지를 획득할 수 있다. 일부 실시예에서, 시스템은 입력 이미지의 세트 및 출력 이미지의 대응하는 세트를 획득하도록 구성될 수 있다. 출력 이미지는 트레이닝 중인 기계 학습 시스템에 의해 생성될 입력 이미지에 대한 타겟 향상 된 출력을 제공한다. 일부 실시예에서, 입력 이미지는 저조도 조건에서 캡처된 이미지를 나타내는 이미지일 수 있다. 입력 이미지는 또한, 본원에서 \"어두운 이미지\"로 지칭될 수 있다. 출력 이미지는 이미지의 조도를 증가 시킨 어두운 이미지의 향상된 버전을 나타내는 대응하는 출력 이미지일 수 있다. 출력 이미지는 본원에서 \"밝은 이미지(light images)\"로 지칭될 수 있다. 시스템은 본원에서 설명된 바와 같이, 디지털 카메라, 비디오 기록 디바이스 등을 포함하는 하나 이상의 이미징 디바이스에 의해 캡처된 트레이닝 이미지를 획득할 수 있다. 예를 들어, 일부 실시예에서 이미지는 본원에서 설명된 기법을 사용하여 처리될 수 있는 비디오 프레임일 수 있다. 시스템은 유선 연결을 통해 또는 무선으로(예를 들어, 네트워크 연결을 통해) 이미지를 수신하도록 구성될 수 있다. 일부 실시예에서, 시스템은 어두운 이미지를 획득하도록 구성될 수 있다. 어두운 이미지는 저조도 조건을 모방 하는 메커니즘을 사용하여 하나 이상의 장면을 캡처할 수 있다. 일부 실시예에서, 시스템은 이미지를 캡처하는 데 사용되는 이미징 디바이스의 노출 시간을 감소시킴으로써 어두운 이미지를 획득할 수 있다. 그 후, 이미징 디바이스에 의해 사용되는 노출 시간을 증가시킴으로써 대응하는 밝은 이미지가 캡처될 수 있다. 일부 실시예에서, 시스템은 객체(들)에 조명을 제공하는 광원의 강도를 감소시키고, 그 후 이미지를 캡처함으로써 어두운 이 미지를 획득할 수 있다. 그 후, 광원의 강도를 증가시킴으로써 대응하는 밝은 이미지가 캡처될 수 있다. 본 발 명자는 중립 밀도 필터의 사용이 다른 기법보다 더 정확하게 저조도 조건을 나타낼 수 있음을 인식하였다. 예를 들어, 신경 밀도 필터(neural density filter)는 카메라 설정 중 나머지가 이미지가 보통의 광을 사용하여 캡처 된 것처럼 동일하게 유지되는 것을 허용할 수 있다. 그러므로, 신경 밀도 필터는 트레이닝 데이터에서 이들 카 메라 설정을 중립화(neutralize)할 수 있다. 노출 시간을 감소시키는 것과 같은 다른 기법을 사용하여 어두운 이미지를 캡처할 때, 어두운 이미지는 이미지 센서의 잡음 특성을 정확하게 캡처하지 못할 수 있다. 예를 들어, 노출 시간을 감소시키는 것은 센서의 전자 잡음(예를 들어, 열 잡음, 암전류 등)의 시간을 감소시킬 수 있다. 그러므로, 이러한 잡음 감소는 캡처된 이미지가 데이터 세트의 전자 잡음을 현실적으로 반영하지 못하게 할 수 있으며, 이는 이미지를 처리하는 것의 중요한 부분일 수 있다(예를 들어, 이는 어두운 이미지에 내재된 잡음을 어떻게 없애는지 및/또는 억제하는지를 학습하기 위한 트레이닝 프로세스의 중요한 부분일 수 있기 때문이다). 다른 예시로서, 광원 강도를 감소시킬 때, 이미지는 (예를 들어, 일부 부분이 트레이닝 단계에 영향을 미칠 수 있는, 다른 것보다 더 많이 조명되도록) 여전히 강도의 균일한 분포를 갖지 않을 수 있다. 중립 밀도 필터를 사 용하여 트레이닝 이미지를 획득하기 위한 예시적인 프로세스는 도 2b를 참조하여 아래에서 설명된다. 일부 실시예는 접근법의 조합을 사용하여 어두운 이미지 및 밝은 이미지를 획득할 수 있다. 예를 들어, 일부 중 립 밀도 필터는 필터가 조정될 때마다 광의 양을 절반으로 줄이는 방식으로 신경 밀도 필터 인자를 두 배로 늘 릴 수 있도록, 이산화될 수 있다(discretized). 그러므로, 카메라 시스템의 다른 양상은 시스템의 단계적인 조 정을 개선하기(refine) 위해 조정될 수 있다. 예를 들어, 노출 시간은 더 개선된 방식으로 광을 감소시키는 조 정을 허용하도록 조정될 수 있다(예를 들어, 필터를 조정함으로써 행해지는 것처럼 광을 반으로 줄이지 않음). 일부 실시예에서, 시스템은 특정한 디바이스를 사용하여 캡처된 트레이닝 이미지를 획득하도록 구성될 수 있다. 일부 실시예에서, 시스템은 특정한 타입의 이미진 센서(imagine sensor)를 사용하여 캡처된 트레이닝 이미지를 획득하도록 구성될 수 있다. 예를 들어, 시스템은 특정한 타입의 이미징 센서(예를 들어, 특정한 모델)로부터 캡처된 트레이닝 이미지를 수신할 수 있다. 그 후, 획득된 이미지는 특정한 타입의 이미징 센서를 이용하는 이 미징 디바이스에 의해 캡처될 이미지를 나타낼 수 있다. 따라서, 기계 학습 시스템은 특정한 타입의 이미징 센 서에 대한 성능에 대해 최적화될 수 있다. 일부 실시예에서, 트레이닝 이미지의 세트는 트레이닝된 기계 학습 시스템에 의한 향상을 위해 수신될 이미지를 일반화하도록 선택될 수 있다. 트레이닝 세트는 상이한 이미징 디바이스 설정에 따라 달라지는 이미지의 세트를 포함할 수 있다. 일부 실시예에서, 시스템은 이미지 디바이스 캡처 설정의 상이한 값에 대한 트레이닝 이미지의 별도의 세트를 획득하도록 구성될 수 있다. 일부 실시예에서, 시스템은 이미징 디바이스의 상이한 광 감도 수준 을 나타내기 위해 이미징 디바이스의 상이한 ISO 설정에 대한 트레이닝 이미지를 획득하도록 구성될 수 있다. 예를 들어, 시스템은 50과 2000 사이의 상이한 ISO 설정에 대한 트레이닝 이미지를 획득할 수 있다. 높은 ISO는 가능한 많은 신호를 제공할 수 있기 때문에 일부 애플리케이션에서 바람직할 수 있지만, 더 높은 ISO는 추가적 인 잡음을 가질 수 있다. 그러므로, 상이한 ISO 설정은 상이한 잡음 특성을 가질 수 있다. 본원에서 더 논의된 바와 같이, 하나 이상의 신경망은 ISO를 다루도록 트레이닝될 수 있다. 예를 들어, 각 ISO 설정에 대해 상이한 신경망이 트레이닝되거나, 또는 ISO 설정의 세트를 커버하는 하나의 신경망이 트레이닝되거나, 또는 이들의 일 부 조합이 있을 수 있다. 트레이닝 이미지의 세트를 획득한 이후에, 프로세스는 시스템이 획득된 트레이닝 이미지를 사용하여 기계 학습 시스템을 트레이닝하는 동작으로 진행한다. 일부 실시예에서, 시스템은 입력이 획득된 어두운 이미지 이고, 대응하는 출력이 어두운 이미지에 대응하는 획득된 밝은 이미지인 자동화된 지도 학습을 수행하도록 구성 될 수 있다. 일부 실시예에서, 시스템은 기계 학습 시스템의 하나 이상의 파라미터의 값을 결정하기 위해 지도 학습을 수행하도록 구성될 수 있다. 일부 실시예에서, 기계 학습 시스템은 이미지 향상을 수행하도록 트레이닝될 하나 이상의 신경망을 포함할 수 있다. 일부 실시예에서, 기계 학습 시스템은 하나 이상의 컨볼루션 신경망(CNN)을 포함할 수 있다. 컨볼루션 신 경망은 주어진 입력 이미지에 대해 일련의 컨볼루션 연산을 수행한다. 컨볼루션 연산은 각 계층에서 하나 이상 의 필터를 사용하여 수행된다. 필터에 사용될 값은 트레이닝 프로세스 중에 결정될 것이다. 일부 실시예에서, CNN은 노드를 갖는 하나 이상의 계층을 더 포함할 수 있고, 이는 각각의 가중치에 의해 이전의 계층으로부터의 다수의 입력이 있고, 그 후 값을 생성하기 위해 곱을 함께 합산할 수 있다. 그 후, 상기 값은 노드 출력을 생성 하기 위해 활성화 함수로 공급될 수 있다. 필터의 값 및/또는 컨볼루션 신경망의 계수 값은 트레이닝 프로세스중에 학습될 수 있다. 일부 실시예에서, 시스템은 손실 함수를 최적화함으로써 기계 학습 시스템의 파라미터를 트레이닝하도록 구성될 수 있다. 손실 함수는 기계 학습 시스템에 의해 생성된 출력과 타겟 출력 사이의 차이(예를 들어, 오차)를 지정 할 수 있다. 예를 들어, 각각의 어두운 이미지에 대해, 손실 함수는 어두운 이미지의 입력에 응답하여 기계 학 습 시스템에 의해 생성된 향상된 이미지와 트레이닝 세트에서 각각의 어두운 이미지에 대응하는 밝은 이미지의 차이를 지정할 수 있다. 일부 실시예에서, 시스템은 트레이닝 이미지의 획득된 세트에 대한 손실 함수를 최소화 하기 위해 트레이닝을 수행하도록 구성될 수 있다. 입력 어두운 이미지에 대한 기계 학습 시스템의 출력으로부 터 계산된 손실 함수의 값을 기초로, 시스템은 기계 학습 시스템의 하나 이상의 파라미터를 조정할 수 있다. 일 부 실시예에서, 시스템은 손실 함수의 값을 기초로 기계 학습 시스템의 파라미터(들)를 만들기 위한 조정을 계 산하기 위해 최적화 함수를 사용하도록 구성될 수 있다. 일부 실시예에서, 시스템은 손실 함수에 의해 나타난 바와 같이 테스팅 이미지에 대한 정확도의 임계 수준에 도달할 때까지 기계 학습 시스템의 파라미터에 대한 조 정을 수행하도록 구성될 수 있다. 예를 들어, 시스템은 트레이닝 이미지에 대한 손실 함수의 최소값이 획득될 때까지 트레이닝 동안 파라미터를 조정하도록 구성될 수 있다. 일부 실시예에서, 시스템은 경사 하강 알고리즘 (gradient descent algorithm)에 의해 조정을 결정하도록 구성될 수 있다. 일부 실시예에서, 시스템은 배치 경 사 하강(batch gradient descent), 확률적 경사 하강(stochastic gradient descent), 및/또는 미니-배치 경사 하강(mini-batch gradient descent)을 수행하도록 구성될 수 있다. 일부 실시예에서, 시스템은 경사 하강을 수 행하는데 있어서 적응형 학습율(adaptive learning rate)을 사용하도록 구성될 수 있다. 예를 들어, 시스템은 경사 하강에서 적응형 학습율을 구현하기 위해 RMSprop 알고리즘을 사용하도록 구성될 수 있다. 일부 실시예에서, 시스템은 상이한 및/또는 다수의 손실 함수를 사용하도록 구성될 수 있다. 일부 실시예에서, 시스템은 다수의 손실 함수의 조합을 사용하도록 구성될 수 있다. 예를 들어, 시스템은 평균 절대 오차(mean absolute error, MAE), 구조 유사성(structure similarity, SSIM) 인덱스, 색차 손실 함수(color difference loss functions) 및/또는 다른 손실 함수(예를 들어, 도 4와 관련하여 논의된 대역 통과 이미지에 적용되는 손 실 함수) 중 하나 이상을 사용하도록 구성될 수 있다. 일부 실시예에서, 색차는 픽셀 사이의 유클리드 거리를 사용하여 계산될 수 있다. 일부 실시예에서, 색차는 픽셀 사이의 델타-E 94 거리 메트릭을 사용하여 계산될 수 있다. 일부 실시예는 특정한 색차 메트릭으로 제한되지 않는다. 일부 실시예에서, 시스템은 하나 이상의 개별적 인 채널(예를 들어, 적색 채널, 녹색 채널, 청색 채널)에 손실 함수를 적용하도록 구성될 수 있다. 일부 실시예에서, 시스템은 아래의 도 4를 참조로 설명된 바와 같이 주파수의 특정한 범위에 대해 기계 학습 시 스템의 성능을 최적화하기 위해 기계 학습 시스템의 필터링된 출력에 손실 함수를 적용하도록 구성될 수 있다. 일부 실시예에서, 시스템은 다수의 손실 함수의 선형 조합을 사용하도록 구성될 수 있다. 일부 실시예에서, 시 스템은 이미지의 하나 이상의 채널의 MAE, 필터링된 출력의 MAE 및 SSIM의 선형 조합을 사용하도록 구성될 수 있다. 예를 들어, 다수의 손실 함수의 조합은 아래 수학식 1로 나타날 수 있다. 수학식 1: 오차 = 1.6 * 적색 채널의 MAE + 1.0 * 녹색 채널의 MAE + 1.6 * 청색 채널의 MAE + 1.4SSIM + 1.5 * 주파수 필터링 된 MAE 일부 실시예에서, 시스템은 기계 학습 시스템의 하나 이상의 하이퍼-파라미터를 설정하도록 구성될 수 있다. 일 부 실시예에서, 시스템은 자동화된 트레이닝 프로세스를 시작하기 전에 하이퍼-파라미터(들)의 값을 설정하도록 구성될 수 있다. 하이퍼-파라미터는 신경망(여기서는 또한 \"네트워크 깊이\"로 지칭됨)의 다수의 계층, CNN에 의 해 사용될 필터의 커널 크기, CNN에서 얼마나 많은 필터가 사용될 지의 카운트, 및/또는 컨볼루션 프로세스에서 취해질 스텝(steps)의 크기를 지정하는 스트라이드 길이(stride length)를 포함할 수 있다. 일부 실시예에서, 시스템은 신경망의 각 계층의 출력이 후속 계층에 입력되기 전에 정규화되는 배치 정규화를 이용하도록 기계 학 습 시스템을 구성할 수 있다. 예를 들어, 제1 계층으로부터의 출력은 제1 계층에서 생성된 값의 평균을 감산하 고 각 값을 값의 표준 편차로 나눔으로써 정규화될 수 있다. 일부 실시예에서, 배치 정규화의 사용은 신경망의 계층에 트레이닝 가능한 파라미터를 추가할 수 있다. 예를 들어, 시스템은 각 단계에서 정규화에 사용되는 감마 및 베타 파라미터를 추가할 수 있다. 기계 학습 시스템은 계층의 각 출력으로부터 베타 값을 감산하고, 그 후 각 출력을 감마 값으로 나눌 수 있다. 일부 실시예에서, 신경망 공간은 양자화를 사용하여 압축될 수 있다. 일부 실시예에서, 기계 학습 시스템의 하이퍼-파라미터는 수동으로 구성될 수 있다. 일부 실시예에서, 기계 학 습 시스템의 하이퍼-파라미터는 자동으로 결정될 수 있다. 예를 들어, 대규모 컴퓨팅 기법은 상이한 파라미터를사용하여 모델을 트레이닝하는데 사용될 수 있고, 그 결과는 공유된 저장소 내에 저장된다. 공유된 저장소는 최 선의 모델을 결정하기 위해, 및 결국 자동화된 방식으로 최선의 파라미터(또는 파라미터 값의 범위)를 결정하기 위해 질의를 받을 수 있다(queried). 일부 실시예에서, 시스템은 하나 이상의 하이퍼-파라미터 값과 연관된 성 능을 나타내는 하나 이상의 값을 저장하도록 구성될 수 있다. 시스템은 상기 시스템의 성능을 개선하기 위해 하 이퍼-파라미터 값(들)에 대한 조정을 자동으로 결정하도록 구성될 수 있다. 일부 실시예에서, 시스템은 데이터 베이스에서 각각의 하이퍼 파라미터 값으로 구성될 때 기계 학습 시스템의 성능을 나타내는 값(들)을 저장하도 록 구성될 수 있다. 시스템은 특정한 하이퍼-파라미터 값으로 구성될 때 기계 학습 시스템의 성능을 나타내는 값(들)에 대해 데이터베이스에 질의하도록 구성될 수 있다. 일부 실시예에서, 기계 학습 시스템은 CNN을 포함할 수 있다. 일부 실시예에서, 기계 학습 시스템은 기계 학습 시스템이 트레이닝되는데 요구되는 시간을 감소시키고, 이미지의 향상을 후속적으로 수행하기 위해, 깊이-별 분 리 가능한 컨볼루션(depth-wise separable convolutions) 및 전체 컨볼루션의 혼합을 사용하도록 구성될 수 있 다. 일부 실시예에서, 깊이 별 분리 가능한 컨볼루션 및 전체 컨볼루션의 혼합이 기계 학습 시스템에 대해 요구 되는 공간을 감소시키는데 사용될 수 있다. 예를 들어, 기계 학습 시스템의 파라미터 수를 감소시키기 위해. 블록에서 기계 학습 시스템을 트레이닝한 이후에, 프로세스는 기계 학습 시스템이 이미지 향상을 위 해 사용되는 블록으로 진행한다. 예를 들어, 트레이닝된 기계 학습 시스템은 하나 이상의 수신된 이미지의 향상을 수행하기 위해 이미지 향상 시스템에 의해 사용될 수 있다. 일부 실시예에서, 시스템은 이미 지를 획득하고, 기계 학습 시스템의 학습되고 구성된 파라미터에 따라 대응하는 밝은 이미지를 생성하도록 구성 될 수 있다. 도 2b는 일부 실시예에 따른 트레이닝 이미지의 세트를 획득하기 위한 예시적인 프로세스를 도시한다. 프 로세스는 도 2를 참조하여 위에서 설명된 프로세스의 일부로서 수행될 수 있다. 예를 들어, 프로세스 가 이미지의 트레이닝 세트에 대한 어두운 이미지 및 대응하는 밝은 이미지의 세트를 획득하기 위해 수행 될 수 있다. 프로세스는 상기 기술의 양상이 이 점으로 제한되지 않기 때문에, 하나 이상의 하드웨어 프로 세서를 포함하는 임의의 컴퓨팅 디바이스(들)를 사용하여 수행될 수 있다. 프로세스는 프로세스를 실행하는 시스템이 중립 밀도 필터를 사용하여 캡처된 이미지의 트레이닝 세 트에 대한 하나 이상의 입력 이미지를 획득하는 동작에서 시작한다. 입력 이미지(들)는 저조도 조건에서 캡처된 장면의 이미지(들)를 나타내는 어두운 이미지(들)일 수 있다. 일부 실시예에서, 중립 밀도(ND) 필터를 갖는 이미징 디바이스(예를 들어, 디지털 카메라)가 이미지(들)를 캡처하기 위해 사용될 수 있다. 일부 실시예 에서, 시스템은 이미징 디바이스에 의해 캡처된 입력 이미지(들)를 수신할 수 있다. 예를 들어, 시스템은 네트 워크(예를 들어, 인터넷)를 통한 무선 송신을 통해 입력 이미지(들)를 수신할 수 있다. 다른 예시에서, 시스템 은 이미징 디바이스와의 유선 연결(예를 들어, USB)을 통해 입력 이미지(들)를 수신할 수 있다. 또 다른 예시에 서, 입력 이미지(들)는 이미징 디바이스에 의해 캡처된 입력 이미지(들)가 저장되는 다른 시스템(예를 들어, 클 라우드 저장소)으로부터 수신될 수 있다. ND 필터는 ND 필터가 이미징 디바이스의 이미징 센서에 도달하는 광의 강도를 감소시킴에 따라 이미지가 캡처되 는 저조도 조건을 시뮬레이션할 수 있다. ND 필터의 동작은 아래의 수학식 2로 설명될 수 있다. 수학식 2:"}
{"patent_id": "10-2021-7006783", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 2에서 I0은 ND 필터에 입사되는 광의 강도이고, d는 ND 필터의 밀도이고, I은 ND 필터를 통과한 이후의 광의 강도이다. 일부 실시예에서, ND 필터는 이미징 센서에 도달하기 전에 이를 통과하는 광의 강도를 변경하는 재료를 포함할 수 있다. 예를 들어, ND 필터는 광이 이미징 디바이스에 도달하기 전에 유리 또는 수지의 부분 (piece)을 통과하도록 이미징 디바이스에 들어가는 광의 경로에서 이미징 센서 앞에 배치된 유리 또는 수지의 어두운 부분일 수 있다. 일부 실시예에서, ND 필터는 필터의 밀도의 변화를 허용하는 가변 ND 필터일 수 있다. 이는 광 강도가 감소될 양을 설정하기 위해 ND 필터가 조정되는 것을 허용한다. 일부 실시예에서, ND 필터는 전 자적으로 제어되는 ND 필터일 수 있다. 전자적으로 제어되는 ND 필터는 제어된 전기 신호를 기초로 이미징 디바 이스에, 이미징 센서에 도달하기 전에 ND 필터가 광의 강도를 감소시키는 가변량을 제공할 수 있다. 예를 들어, 전자적으로 제어되는 ND 필터는 전압의 인가를 기초로 광 강도가 감소되는 양을 변경하는 액정 소자를 포함할 수 있다. 전압은 이미징 디바이스에 의해 제어될 수 있다. 일부 실시예에서, 입력 이미지(들)는 다양한 수준의 저조도 조건을 시뮬레이션하기 위해 다수의 상이한 ND 필터 밀도 설정을 사용하여 블록에서 획득될 수 있다. 예를 들어, ND 필터에 대해 상이한 밀도 설정을 사용하여 장면의 다수의 이미지가 캡처될 수 있다. 일부 실시예에서, 이미지(들)는 단일 ND 필터 밀도 설정을 사용하여 획득될 수 있다. 일부 실시예에서, 입력 이미지(들)는 이미징 디바이스의 상이한 이미지 캡처 설정에 걸쳐 블록에서 ND 필 터를 사용하여 획득될 수 있다. 예를 들어, 입력 이미지(들)는 이미징 디바이스의 노출 시간, ISO 설정, 셔터 속도 및/또는 조리개(aperture)의 상이한 설정에 대해 ND 필터를 사용하여 캡처될 수 있다. 따라서, 이미지의 트레이닝 세트는 이미지가 캡처될 수 있는 광범위한 이미징 디바이스 구성을 반영할 수 있다. 블록에서 입력 이미지(들)를 캡처한 이후에, 프로세스는 시스템이 블록에서 획득된 입력 이미지 (들)에 대응하는 하나 이상의 출력 이미지를 획득하는 블록으로 진행한다. 입력 이미지(들)를 캡처하는데 사용된 이미징 디바이스는 ND 필터 없이 출력 이미지(들)를 캡처하는데 사용될 수 있다. 따라서 출력 이미지(들)는 입력 이미지(들)의 향상된 버전을 나타낼 수 있다. 일부 실시예에서, 출력 이미지(들)는 이미징 디바이스의 상이한 이미지 캡처 설정에 걸쳐 캡처될 수 있다. 예를 들어, 입력 이미지(들)를 캡처하기 위해 사 용된 각 이미징 디바이스 구성에 대해 출력 이미지가 캡처될 수 있다. 따라서, 트레이닝 세트에서의 출력 이미 지(들)는 이미지가 캡처될 수 있는 이미징 디바이스 구성의 범위를 반영할 수 있다. 그 다음, 프로세스는 시스템이 이미지의 트레이닝 세트에 포함될 모든 장면에 대한 입력 이미지(들) 및 대 응하는 출력 이미지(들)가 캡처되었는지를 결정하는 블록으로 진행한다. 일부 실시예에서, 시스템은 임계 개수의 장면이 캡처되었는지를 결정하도록 구성될 수 있다. 예를 들어, 시스템은 기계 학습 시스템을 트레이닝 하기 위한 적절한 다양성을 제공하는 임계 개수의 장면이 캡처되었는지를 결정할 수 있다. 일부 실시예에서, 시 스템은 장면의 충분한 다양성이 획득되었는지를 결정하도록 구성될 수 있다. 일부 실시예에서, 시스템은 트레이 닝 세트의 이미지 내의 객체의 충분한 수의 다양성에 대한 이미지가 획득되었는지를 결정하도록 구성될 수 있다. 일부 실시예에서, 시스템은 트레이닝 세트의 이미지에서 충분한 색상의 다양성에 대해 이미지가 획득되었 는지를 결정하도록 구성될 수 있다. 블록에서, 시스템이 이미지의 트레이닝 세트의 모든 장면에 대한 이미지(들)가 획득된 것으로 결정하면, 프로세스는 시스템이 기계 학습 시스템을 트레이닝하기 위해 획득된 입력 및 출력 이미지를 사용하는 블록 으로 진행한다. 입력 및 출력 이미지는 도 2a를 참조하여 상술한 바와 같이 기계 학습 시스템의 하나 이상 의 기계 학습 모델을 트레이닝하는데 사용될 수 있다. 예를 들어, 획득된 입력 및 출력 이미지는 도 1a-b를 참 조로 상술한 이미지 향상 시스템에 의해 이미지를 향상시키는데 사용되는 하나 이상의 신경망을 트레이닝 하기 위해 시스템에 의해 사용될 수 있다. 블록에서, 시스템이 이미지의 트레이닝 세트의 모든 장면에 대한 이미지(들)가 획득되지 않은 것으로 결정 하면, 프로세스는 시스템이 다른 장면에 대한 하나 이상의 이미지(들)를 획득하는 블록으로 진행한다. 그 후, 시스템은 이미지의 트레이닝 세트에 추가될 장면의 입력 이미지(들) 및 대응하는 출력 이미지 (들)의 다른 세트를 획득하기 위해 블록(212 내지 214에서)의 단계를 다시 수행할 수 있다. 도 2c는 일부 실시예에 따른 트레이닝 이미지의 세트를 획득하기 위한 다른 예시적인 프로세스를 도시한다. 프로세스(210 및 230)가 별도의 도면과 함께 설명되지만, 하나 및/또는 두 프로세스 모두의 기법이 트레이닝 이미지를 획득하는데 사용될 수 있다는 것이 인식되어야 한다. 예를 들어, 일부 실시예는 본원에서 더 설명된 기계 학습 시스템을 트레이닝하기 위해 사용될 수 있는, 프로세스와 함께 설명된 중립 밀도 기법, 프로세스와 함께 설명된 평균화 기법, 및/또는 트레이닝 이미지를 획득하기 위한 다른 기법을 사용할 수 있다. 프로세스와 마찬가지로, 프로세스는 도 2를 참조하여 위에서 설명된 프로세스의 일부로서 수행될 수 있다. 예를 들어, 프로세스는 이미지의 트레이닝 세트에 대한 어두운 이미지 및 대응하는 밝은 이미지의 세트를 획득하기 위해 수행될 수 있다. 프로세스는 상기 기술의 양상이 이 점으로 제한되지 않기 때문에, 하나 이상의 하드웨어 프로세서를 포함하는 임의의 컴퓨팅 디바이스(들)를 사용하여 수행될 수 있다. 프로세스는 프로세스를 실행하는 시스템이 이미지의 트레이닝 세트에 대한 하나 이상의 입력 이미지 를 획득하는 동작에서 시작한다. 일부 실시예에서, 입력 이미지는 정상적인 노출 시간(예를 들어, 장면에 서 잡음 및/또는 광을 증가 및/또는 감소시키도록 설계된 수정된 노출 시간이 아님)을 사용하여 촬영된 잡음이 있는 이미지 및/또는 어두운 이미지일 수 있다. 일부 실시예에서, 입력 이미지는 상대적으로 높은 ISO 값을 사 용하여 캡처될 수 있다. 높은 ISO 값은 예를 들어, 디지털 샘플링 프로세스에서 저-강도 픽셀 값의 양자화 정확 도를 개선하거나 및/또는 최대화하는데 도움을 줄 수 있다. 일부 실시예에서, 입력 이미지는 예를 들어, 대략 1,500-500,000 범위의 ISO 및/또는 높은 ISO 값(예를 들어, 이미지가 더욱 선명하게 보이게 하는 충분히 높은ISO 값 및 또한, 이미지에서의 잡음을 증가시킬 수 있음)으로 간주되는 다른 ISO 값을 사용하여 캡처될 수 있다. 일부 실시예에서, ISO 값은 대략 1,500-500,000 등의 범위에 있는 임계치와 같은 ISO 임계치보다 높을 수 있다. 프로세스는 동작으로부터 동작으로 진행하고, 시스템은 각 입력 이미지에 대해, 입력 이미지에 의해 캡처된 동일한 장면의 대응하는 출력 이미지를 획득한다. 일부 실시예에서, 시스템은 (예를 들어, 단계 에서 획득된 입력 이미지 및/또는 별도의 이미지를 포함하는) 복수의 개별적으로 캡처된 이미지를 사용하 여 출력 이미지를 획득하고, 출력 이미지를 결정하기 위해 복수의 이미지를 사용할 수 있다. 일부 실시예에서, 출력 이미지를 결정하는데 사용되는 이미지의 세트는 동작에서 입력 이미지를 캡처하는데 사용되는 동일하 거나 및/또는 유사한 설정(들)(예를 들어, 노출 시간, ISO 등)으로 캡처될 수 있다. 일부 실시예에서, 동작(232 및 234)이 개별적인 동작인 것으로 도시되지만, 상기 동작은 이미지의 단일 세트를 캡처함으로써 수행될 수 있 다. 예를 들어, 시스템은 다수의 이미지를 캡처하도록 구성될 수 있고, 시스템은 캡처된 이미지 중 어느 하나를 입력 프레임으로 선택할 수 있으며, 출력 이미지는 세트의 나머지 이미지를 및/또는 세트의 모든 이미지(입력 이미지로 선택된 이미지를 포함함)를 기초로 생성될 수 있다. 일부 실시예에서, 시스템은 대응하는 출력 이미지를 결정하도록 사용하기 위해, 미리 결정된 수의 이미지를 사 용하거나 및/또는 캡처하도록 구성될 수 있다. 예를 들어, 시스템은 50개의 이미지, 100개의 이미지, 1,000개의 이미지 등을 캡처하도록 구성될 수 있다. 예를 들어, 캡처된 이미지의 수는 더 많은 이미지에서 평균낸 지점이 신호 대 잡음비에 대해 작은 개선만을 제공하는 수일 수 있다. 일부 실시예에서, 시스템은 상이한 수의 이미지 를 사용하도록 구성될 수 있다. 일부 실시예에서, 이미지의 세트에서 각 이미지는 이미징 디바이스가 쿨링되는 것을 허용하기 위해(예를 들어, 출력 이미지를 결정하는데 사용되는 이미지의 세트를 캡처하면서, 이미징 디바이스의 온도를 완화시키거나 및/ 또는 제어하는데 도움을 주기 위해) 연속적인 캡처 사이의 휴지 기간(rest periods)을 사용하여 캡처될 수 있다. 예를 들어, 짧은 노출(예를 들어, 입력 이미지(들)를 캡처하는데 사용되는 것)은 이미지의 세트에서 이미 지의 각각을 캡처하는데 사용될 수 있고, 쿨링 간격(예를 들어, 0.25초, 0.5초, 1초, 2초 등의 휴지 기간)은 동 작에서 결정된 입력 프레임을 캡처할 때, 이들과 일치하는 이미징 디바이스의 잡음 특성을 유지하도록 도 움을 주는데 사용될 수 있다. 그러므로, 동작에서 입력 이미지를 캡처하는데 사용되는 동일한 설정 하에 캡처된 이미지의 세트를 사용함으로써, 동일하거나 및/또는 유사한 잡음 특성을 나타내는 출력 이미지가 생성될 수 있다. 일부 실시예에서, 시스템은 다수의 이미지에 걸쳐 각 픽셀에 대한 강도를 평균냄으로써 출력 이미지를 결정할 수 있다. 예를 들어, 일부 실시예에서 시스템은 각 픽셀 위치에서 이미지의 세트에 대한 산술 평균을 결정할 수 있다. 일부 실시예에서, 선형 조합을 결정하는 것, 및/또는 입력 이미지의 잡음이 제거된 버전과 유사한 출력 이미지를 생성하기 위해 이미지의 세트를 처리하는 임의의 다른 기능과 같은 다른 기법이 사용될 수 있다. 일부 실시예에서, 출력 이미지는 잡음 제거 후-처리 기법을 사용하여 처리된다. 그 다음, 프로세스는 시스템이 이미지의 트레이닝 세트에 포함될 모든 장면에 대한 입력 이미지(들) 및 대 응하는 출력 이미지(들)가 캡처되었는지를 결정하는 블록으로 진행한다. 일부 실시예에서, 프로세스 와 관련하여 설명된 바와 같이, 시스템은 임계 개수의 장면이 캡처되었는지를 결정하도록 구성될 수 있다. 블록에서, 시스템이 이미지의 트레이닝 세트의 모든 장면에 대한 이미지(들)가 획득된 것으로 결정하면, 프로세스는 시스템이 기계 학습 시스템을 트레이닝하기 위해 획득된 입력 및 출력 이미지를 사용하는 블록 로 진행한다. 입력 및 출력 이미지는 도 2a를 참조하여 위에서 설명된 바와 같이 기계 학습 시스템의 하나 이상의 기계 학습 모델을 트레이닝하는데 사용될 수 있다. 예를 들어, 획득된 입력 및 출력 이미지는 도 1a-b를 참조로 위에서 설명된 이미지 향상 시스템에 의해 이미지를 향상시키는데 사용되는 하나 이상의 신경망을 트레이닝하기 위해 시스템에 의해 사용될 수 있다. 이미지의 세트를 기초로 출력 이미지를 결정함으로써(예를 들어, 본원에서 설명된 바와 같이 캡처 사이의 쿨링 간격으로 촬영된 짧은 노출을 평균냄으로써), 상기 기법은 기계 학습 시스템이 (예를 들어, 입력 이미지와 상이한 잡음 특성을 나타내는 출력 이미지를 사용하는 것에 비 해) 더 간단한 변환 함수를 학습하는 것을 가능하게 하거나, 더 압축 가능한 기계 학습 모델을 허용하는 등이 있을 수 있다. 블록에서, 시스템이 이미지의 트레이닝 세트의 모든 장면에 대한 이미지(들)가 획득되지 않았다고 결정하 면, 프로세스는 시스템이 다른 장면에 대한 하나 이상의 이미지(들)를 획득하는 블록으로 진행한다. 그 후, 시스템은 이미지의 트레이닝 세트에 추가될 장면의 입력 이미지(들) 및 대응하는 출력 이미지(들)의 다른 세트를 획득하기 위해 블록(232 내지 234)에서의 단계를 다시 수행할 수 있다. 도 3a는 일부 실시예에 따라 입력 및 출력 이미지의 일부를 사용하여 기계 학습 시스템을 트레이닝하기 위한 프 로세스를 도시한다. 프로세스는 도 2를 참조하여 위에서 설명된 프로세스의 일부로서 수행될 수 있다. 예를 들어, 프로세스는 저조도 조건에서 캡처된 이미지를 향상시키기 위해 이미지 향상 시스템(11 1)에 의해 사용될 기계 학습 시스템을 트레이닝하는 것의 일부로서 수행될 수 있다. 프로세스는 상기 기술 의 양상이 이 점으로 제한되지 않기 때문에, 하나 이상의 하드웨어 프로세서를 포함하는 임의의 컴퓨팅 디바이 스(들)를 사용하여 수행될 수 있다. 본 발명자는 기계 학습 시스템에 대한 입력의 크기가 감소되는 경우, 기계 학습 시스템이 더욱 빠르게 만들어질 수 있음을(예를 들어, 시스템이 \"어두운\" 이미지로부터 \"밝은\" 이미지로 변환하는 처리 속도) 인식하였다. 입력 크기가 작을수록, 기계 학습 시스템은 더 적은 파라미터 및 수행할 더 적은 작업을 가질 수 있으며, 따라서 더 빠르게 실행될 수 있다. 더욱 작은 입력 크기는 또한, 기계 학습 시스템의 하나 이상의 파라미터를 트레이닝하 는데 요구되는 트레이닝 시간을 감소시킬 수 있다. 입력 크기가 작을수록, 기계 학습 시스템은 값이 학습되어야 하는 더 적은 파라미터를 가질 수 있다. 이는 결국, 트레이닝 중에 시스템에 의해 수행될 계산의 수를 감소시킨 다. 따라서, 기계 학습 시스템에 대한 더 작은 입력은 시스템이 기계 학습 시스템을 더 효율적으로 트레이닝하 는 것을 허용한다. 프로세스는 프로세스를 수행하는 시스템이 트레이닝 세트의 입력 이미지의 각각을 다수의 이미지 부 분으로 나누는 블록에서 시작한다. 입력 이미지는 예를 들어, 원시 고해상도 이미지일 수 있다. 일부 실시 예에서, 시스템은 각각의 입력 이미지를 동일한 크기의 부분의 그리드(grid)로 나누도록 구성될 수 있다. 제한 하려는 것으로 의도되지 않는 단순하고 설명적인 예시로서, 500x500 크기의 입력 이미지는 100x100 이미지 부분 의 그리드로 나누어질 수 있다. 일부 실시예에서, 시스템은 입력 이미지가 나누어질 이미지 부분의 크기를 동적 으로 결정하도록 구성될 수 있다. 예를 들어, 시스템은 이미지에서 객체를 식별하기 위해 이미지를 분석하도록 구성될 수 있다. 시스템은 이미지 부분이 완전한 객체를 포함하는 것을 보장하는 이미지 부분의 크기를 결정할 수 있다. 일부 실시예에서, 시스템은 트레이닝 시간 및/또는 이미지 향상에 요구되는 시간을 최소화하기 위해 이미지 부분의 크기를 결정하도록 구성될 수 있다. 예를 들어, 시스템은 이미지 부분의 크기의 입력을 처리하는 기계 학습 시스템을 트레이닝하기 위한 예상된 시간을 기초로 이미지 부분의 크기를 결정할 수 있다. 다른 예시 에서, 시스템은 기계 학습 시스템이 이미지 향상을 수행하기 위해 사용될 때 크기를 갖는 입력을 처리하기 위해 예상되는 시간을 기초로 이미지 부분의 크기를 결정할 수 있다. 일부 실시예에서, 시스템은 모든 입력 이미지를 동일한 크기의 부분으로 나누도록 구성될 수 있다. 일부 실시예에서, 시스템은 입력 이미지를 상이한 크기의 부 분으로 나누도록 구성될 수 있다. 그 다음, 프로세스는 시스템이 대응하는 출력 이미지를 이미지 부분으로 나누는 블록으로 진행한다. 일부 실시예에서, 시스템은 대응하는 입력 이미지가 나누어지는 것과 동일한 방식으로 출력 이미지를 부분으로 나누도록 구성될 수 있다. 예를 들어, 500x500 입력 이미지가 100x100 이미지 부분으로 나누어진 경우, 트레이 닝 세트에서 대응하는 출력 이미지는 또한, 100x100 이미지 부분으로 나누어질 수 있다. 그 다음, 프로세스는 시스템이 기계 학습 시스템을 트레이닝하기 위해 입력 이미지 부분 및 출력 이미지 부분을 사용하는 블록으로 진행한다. 일부 실시예에서, 시스템은 기계 학습 시스템을 트레이닝하기 위한 지도 학습을 수행하기 위한 개별적인 입력 및 대응하는 출력으로서 입력 이미지 부분 및 출력 이미지 부분을 사 용하도록 구성될 수 있다. 일부 실시예에서, 입력 이미지 부분은 어두운 이미지의 세트를 형성할 수 있고, 출력 이미지 부분은 기계 학습 시스템이 트레이닝되는 것에 따라 대응하는 밝은 이미지의 세트를 형성할 수 있다. 도 3b는 일부 실시예에 따라 이미지를 부분으로 나눔으로써 이미지를 향상시키기 위한 프로세스를 도시한 다. 프로세스는 이미지를 향상시키는 것의 일부로서 수행될 수 있다. 예를 들어, 프로세스는 이미징 디바이스로부터 획득된 이미지를 향상시키는 것의 일부로서 이미지 향상 시스템에 의해 수행될 수 있다. 프로세스는 상기 기술의 양상이 이 점으로 제한되지 않기 때문에, 하나 이상의 하드웨어 프로세서를 포함 하는 임의의 컴퓨팅 디바이스(들)를 사용하여 수행될 수 있다. 프로세스는 프로세스를 실행하는 시스템이 입력 이미지를 수신하는 블록에서 시작한다. 일부 실 시예에서, 시스템은 이미진 디바이스(예를 들어, 디지털 카메라)에 의해 캡처된 이미지를 획득할 수 있다. 예를 들어, 시스템은 이미징 디바이스로부터 이미지를 수신할 수 있다. 다른 예시에서, 시스템은 이미징 디바이스 상 의 애플리케이션의 일부로서 실행될 수 있고, 이미징 디바이스의 저장소로부터 이미징 디바이스에 의해 캡처된 이미지에 액세스할 수 있다. 또 다른 예시에서, 시스템은 이미징 디바이스와 별도의 다른 시스템(예를 들어, 클라우드 저장소)으로부터 캡처된 이미지를 획득할 수 있다. 그 다음, 프로세스는 시스템이 이미지를 다수의 이미지 부분으로 나누는 블록으로 진행한다. 일부 실 시예에서, 시스템은 기계 학습 시스템을 트레이닝할 때 이미지의 트레이닝 세트에서 입력 이미지가 나누어지는 동일한 크기의 입력 부분으로 이미지를 나누도록 구성될 수 있다. 일부 실시예에서, 시스템은 이미지를 다수의 동일한 크기의 부분으로 나누도록 구성될 수 있다. 일부 실시예에서, 시스템은 부분의 크기를 결정하기 위해 이 미지를 분석하고, 그 후 이미지를 결정된 크기를 갖는 부분으로 나누도록 구성될 수 있다. 예를 들어, 시스템은 이미지에서 하나 이상의 객체를 식별하고, 객체(들)의 식별을 기초로 이미지 부분의 크기를 결정하도록 구성될 수 있다. 일부 실시예에서, 시스템은 부분에서의 대비 변경의 효과를 완화하기 위해 이미지 부분의 크기를 결정 하도록 구성될 수 있다. 예를 들어, 100x100 크기의 이미지 부분이 그 사이에 큰 대비가 있는 객체들을 갖는 경 우, 이미지 부분은 이미지 부분에서 대비 차이의 영향을 감소시키기 위해 확장될 수 있다. 그 다음, 프로세스는 시스템이 블록에서 획득된 다수의 이미지 부분 중 하나를 선택하는 블록으 로 진행한다. 일부 실시예에서, 시스템은 이미지 부분 중 하나를 무작위로 선택하도록 구성될 수 있다. 일부 실 시예에서, 시스템은 원래의 이미지에서 이미지 부분의 위치를 기초로 순차적으로 이미지 부분 중 하나를 선택하 도록 구성될 수 있다. 예를 들어, 시스템은 이미지의 특정한 지점(예를 들어, 특정한 픽셀 위치)으로부터 시작 하는 이미지 부분을 선택할 수 있다. 그 다음, 프로세스는 시스템이 기계 학습 시스템에 대한 입력으로서 선택된 이미지 부분을 사용하는 블록 으로 진행한다. 일부 실시예에서, 기계 학습 시스템은 저조도 조건에서 캡처된 이미지에 대한 이미지 향상 을 수행하기 위한 트레이닝된 기계 학습 시스템일 수 있다. 예를 들어, 기계 학습 시스템은 도 1a-b를 참조하여 위에서 설명된 트레이닝된 기계 학습 시스템일 수 있고 도 2를 참조로 설명된 프로세스에 따라 트레 이닝될 수 있다. 기계 학습 시스템은 선택된 이미지 부분이 입력으로서 사용될 수 있는 하나 이상의 모델(예를 들어, 신경망 모델)을 포함할 수 있다. 시스템은 선택된 이미지 부분을 기계 학습 모델로 입력할 수 있다. 그 다음, 프로세스는 시스템이 대응하는 출력 이미지 부분을 획득하는 블록으로 진행한다. 일부 실시 예에서, 시스템은 기계 학습 시스템의 출력을 획득할 수 있다. 예를 들어, 시스템은 이미지 부분이 입력된 트레 이닝된 신경망 모델의 출력을 획득할 수 있다. 기계 학습 시스템의 출력은 입력 이미지 부분의 향상된 버전일 수 있다. 예를 들어, 입력 이미지 부분은 저조도 조건에서 촬영되었을 수 있다. 결과적으로, 이미지 부분의 하 나 이상의 객체가 보이지 않거나 흐릿하거나(blurry), 또는 이미지 부분이 열악한 대비를 가질 수 있다. 대응하 는 출력 이미지는 객체(들)가 가시적이고, 선명하고, 이미지 부분이 개선된 대비를 갖도록 증가된 조도를 가질 수 있다. 그 다음, 프로세스는 시스템이 원래의 수신된 이미지가 나누어진 이미지 부분의 모두가 처리되었는지를 결 정하는 블록으로 진행한다. 예를 들어, 원래의 이미지가 500x500의 크기를 갖고 100x100 이미지 부분으로 나누어진 경우, 시스템은 100x100 이미지 부분의 각각이 처리되었는지를 결정할 수 있다. 시스템은 100x100 이 미지 부분의 각각이 기계 학습 시스템으로 입력되었는지, 그리고 대응하는 출력 부분이 각 입력 부분에 대해 획 득되었는지를 결정할 수 있다. 블록에서, 시스템이 처리되지 않은 수신된 이미지의 부분이 있는 것으로 결정하면, 프로세스는 시스 템이 다른 이미지 부분을 선택하고, 블록(318-320)을 참조로 위에서 설명한 바와 같이 이미지 부분을 처리하는 블록으로 진행한다. 블록에서 시스템이 모든 이미지 부분이 처리된 것으로 결정하면, 프로세스 는 시스템이 출력 이미지를 생성하기 위해 획득된 출력 이미지 부분을 결합하는 블록으로 진행한다. 일부 실시예에서, 시스템은 출력 이미지를 획득하기 위해 기계 학습 시스템의 출력으로부터 생성된 출력 이미지 부분 을 결합하도록 구성될 수 있다. 예를 들어, 원래의 이미지가 100x100 부분으로 나누어진 500x500 이미지인 경우, 시스템은 100x100 이미지의 기계 학습 시스템으로부터의 출력을 결합할 수 있다. 시스템은 출력 이미지를 획득하기 위해 원래 획득된 이미지에서 대응하는 입력 이미지 부분의 위치에 100x100 출력 이미지 부분의 각각 을 위치시키도록 구성될 수 있다. 출력 이미지는 블록에서 획득된 이미지의 향상된 버전일 수 있다. 예를 들어, 원래의 이미지는 저조도 조건에서 이미징 디바이스에 의해 캡처되었을 수 있다. 획득된 출력 이미지는 원 래의 이미지에서 캡처된 장면의 디스플레이를 개선하는 캡처된 이미지의 향상된 버전(예를 들어, 개선된 대비 및/또는 감소된 흐려짐)일 수 있다. 도 2a를 참조로 위에서 설명된 바와 같이, 일부 실시예에서, 기계 학습 시스템은 기계 학습 시스템에 입력되는 이미지 부분에 대해 하나 이상의 컨볼루션 연산을 수행하도록 구성될 수 있다. 컨볼루션 연산은 필터 커널과 입 력 이미지 부분의 픽셀 값 사이에 수행될 수 있다. 컨볼루션 연산은 컨볼루션이 수행되는 이미지 부분에서 픽셀위치를 둘러싸는 픽셀 값의 선형 조합을 취함으로써 대응하는 컨볼루션 출력의 값을 결정하는 것을 수반할 수 있다. 예를 들어, 필터 커널이 3x3 행렬인 경우, 컨볼루션 연산은 각각의 픽셀 위치 주변의 3x3 행렬에서 픽셀 의 픽셀 값을 커널의 가중치로 곱하는 것, 및 컨볼루션 연산의 출력에서 각각의 픽셀 위치에 대한 값을 획득하 기 위해 이들을 합산하는 것을 수반할 수 있다. 컨볼루션 연산을 수행할 때 발생하는 하나의 문제점은 이미지 부분의 가장자리에서의 픽셀 위치가 상기 위치의 모든 측면에서 각각의 픽셀 위치를 둘러싸는 픽셀을 갖지 않을 수 있다는 것이다. 예를 들어, 3x3 커널 행렬을 통한 컨볼루션 연산의 경우, 이미지 부분의 좌측 가장자리 상의 픽셀 위치가 커널이 컨볼루션될 수 있는 그의 좌측에 대해 임의의 픽셀을 갖지 않을 것이다. 이를 해결하기 위 해, 종래의 시스템은 0 값 픽셀로 이미지 부분을 패딩(pad)할 수 있다. 하지만, 이는 0 값 픽셀이 이미징 디바 이스에 의해 캡처된 이미지로부터의 정보를 나타내지 않기 때문에, 이미지 부분의 가장자리에 왜곡을 야기할 수 있다. 도 3c는 일부 실시예에 따라 기계 학습 시스템에 의해 수행되는 필터링 동작 동안 위에서 설명된 가장자리 왜곡 의 문제를 완화하기 위한 프로세스를 도시한다. 프로세스는 기계 학습 시스템의 트레이닝 및/또는 이 미지 향상 동안 수행될 수 있다. 예를 들어, 프로세스는 저조도 조건에서 캡처된 이미지를 향상시키기 위 해 이미지 향상 시스템에 의해 사용될 기계 학습 시스템을 트레이닝하는 것의 일부로서 수행될 수 있고, 이미지 향상 중에 향상 시스템에 의해 후속적으로 수행될 수 있다. 프로세스는 상기 기술의 양상이 이 점으로 제한되지 않기 때문에, 하나 이상의 하드웨어 프로세서를 포함하는 임의의 컴퓨팅 디바이스(들)를 사 용하여 수행될 수 있다. 프로세스는 프로세스를 수행하는 시스템이 이미지 부분을 획득하는 블록에서 시작한다. 이미지 부분은 도 3a-b를 참조로 프로세스(300 및 310)에서 상술한 바와 같이 획득될 수 있다. 그 다음, 프로세스는 시스템이 이미지 부분의 잘린 부분을 결정하는 블록으로 진행한다. 일부 실시예 에서, 시스템은 잘린 부분의 가장자리 주위에 다수의 픽셀을 갖는 이미지 부분의 잘린 부분을 결정할 수 있다. 예를 들어, 이미지 부분이 100x100 이미지인 경우, 시스템은 100x100 이미지의 중앙에 98x98 이미지인 이미지 부분의 잘린 부분을 결정할 수 있다. 따라서, 이미지 부분의 잘린 부분은 이미지 부분의 가장자리를 둘러싸는 픽셀을 갖는다. 이는 잘린 부분의 가장자리에서의 픽셀이 컨볼루션 연산을 위한 주변 픽셀을 가짐을 보장할 수 있다. 그 다음, 프로세스는 시스템이 기계 학습 시스템에 대한 입력으로서 이미지 부분의 잘린 부분을 사용하는 블록으로 진행한다. 일부 실시예에서, 시스템은 전체 원래의 이미지 부분을 입력으로서 전달하지만, 이미 지 부분의 잘린 부분에 필터 연산(예를 들어, 컨볼루션)을 적용하도록 구성될 수 있다. 이는 기계 학습 시스템 의 출력으로부터 생성되는 향상된 출력 이미지 부분의 가장자리에서의 왜곡을 제거할 수 있다. 예를 들어, 100x100 이미지 부분의 98x98 잘린 부분에서 3x3 필터 커널을 통해 컨볼루션 연산이 수행되는 경우, 98x98 잘린 부분의 가장자리에서 픽셀에 대해 수행된 컨볼루션은 3x3 필터 커널에서 위치의 각각과 정렬되는 픽셀을 가질 것이다. 이는 0 값의 픽셀로 이미지 부분을 패딩하는 것과 같은 종래의 기법에 비해 가장자리 왜곡을 줄일 수 있다. 일부 실시예에서, 시스템은 시스템에 의해 수행될 후속 자르기 동작을 고려하기 위해 추가적인 픽셀을 포함하는 이미지 부분 크기를 결정할 수 있다(예를 들어, 시스템은 전체 향상된 이미지를 생성하기 위해 결과적인 처리된 부분을 함께 스티칭하기(stitching) 전에 이미지의 향상된 부분을 자를 수 있다. 예를 들어, 시스템은 상기 시 스템이 이미지 부분의 잘린 100x100 부분에 대해 필터링 동작을 후속적으로 수행할 수 있기 때문에, 102x102 크 기의 이미지 부분을 획득하도록 구성될 수 있다. 필터링 동작 중에 추가적인 픽셀을 제거함으로써, 잘린 부분은 위에서 논의된 가장자리 효과가 없을 수 있다. 도 4는 일부 실시예에 따른 기계 학습 시스템을 트레이닝하기 위한 프로세스를 도시한다. 프로세스는 이미지의 특정한 주파수 범위에 대해 기계 학습 시스템을 최적화하기 위해 수행될 수 있다. 예를 들어, 기계 학 습 시스템이 사람이 인식할 수 있는 주파수 범위에서 최선으로 수행됨을 보장하기 위해. 프로세스는 (예를 들어, 도 2a를 참조로 위에서 설명된 프로세스의 일부로서) 이미지 향상을 수행하기 위해 사용될 기계 학 습 시스템을 트레이닝하는 일부로서 수행될 수 있다. 프로세스는 상기 기술의 양상이 이 점으로 제한되지 않기 때문에, 하나 이상의 하드웨어 프로세서를 포함하는 임의의 컴퓨팅 디바이스(들)를 사용하여 수행될 수 있 다. 프로세스는 프로세스를 수행하는 시스템이 기계 학습 시스템을 트레이닝하는데 사용되는 이미지의 트 레이닝 세트로부터의 타겟 이미지 및 기계 학습 시스템에 의해 생성된 대응하는 출력 이미지를 획득하는 블록에서 시작한다. 타겟 이미지는 기계 학습 시스템이 트레이닝되는 것에 따른 대응하는 어두운 이미지의 타 겟 향상된 출력을 나타내는 밝은 이미지일 수 있다. 기계 학습 시스템에 의해 생성된 출력 이미지는 기계 학습 시스템의 트레이닝 중에 기계 학습 시스템에 의해 생성된 실제 출력 이미지일 수 있다. 그 다음, 프로세스는 시스템이 출력 이미지 및 타겟 이미지에 필터를 적용하는 블록으로 진행한다. 일부 실시예에서, 시스템은 각각 하나 이상의 특정한 범위의 주파수를 포함하는 필터링된 타겟 이미지 및 필터 링된 출력 이미지를 획득하기 위해 출력 이미지 및 타겟 이미지에 주파수 필터를 적용할 수 있다. 일부 실시예 에서, 필터는 특정한 범위의 주파수를 통과시키고 범위 밖의 주파수를 감쇠시키는 대역 통과 필터를 포함할 수 있다. 일부 실시예에서, 주파수 범위는 인간이 지각 가능한 주파수의 범위일 수 있다. 예를 들어, 대역 통과 필 터는 430THz 내지 770THz 범위의 주파수를 통과시킬 수 있다. 일부 실시예에서, 필터를 출력 이미지 또는 타겟 이미지의 각각에 적용하기 위해, 시스템은 각각의 이미지를 주 파수 도메인으로 변환할 수 있다. 예를 들어, 시스템은 주파수 도메인에서 대응하는 이미지를 획득하기 위해 각 각의 이미지를 푸리에 변환(Fourier transform)할 수 있다. 필터는 주파수 도메인에서 함수로서 정의될 수 있다. 변환된 이미지에 필터를 적용하기 위해, 시스템은 필터링된 출력을 획득하기 위해 필터 함수에 푸리에 변 환된 이미지를 곱하도록 구성될 수 있다. 그 후, 시스템은 필터링된 이미지를 획득하기 위해 필터링된 출력의 결과를 역 푸리에 변환할 수 있다. 그 다음, 프로세스는 시스템이 필터링된 타겟 이미지 및 출력 이미지를 기초로 기계 학습 시스템을 트레이 닝하는 블록으로 진행한다. 트레이닝 중에, 기계 학습 시스템에 의해 출력된 실제 이미지는 기계 학습 시 스템의 성능을 결정하기 위해 트레이닝 세트로부터의 타겟 이미지에 비교될 수 있다. 예를 들어, 시스템은 하나 이상의 오차 메트릭에 따라 타겟 이미지와 출력 이미지 사이의 오차를 결정할 수 있다. 오차 메트릭의 결과는 트레이닝 중에 기계 학습 시스템의 하나 이상의 파라미터를 만들기 위한 조정을 결정하는데 사용될 수 있다. 블 록에서, 시스템은 대응하는 필터링된 출력 이미지와 필터링된 타겟 이미지 사이의 차이를 기초로 출력 이 미지와 타겟 이미지 사이의 오차를 결정할 수 있다. 일부 실시예에서, 시스템은 필터링된 이미지를 기초로 하나 이상의 오차 메트릭의 값을 결정하도록 구성될 수 있다. 일부 실시예에서, 시스템은 필터링된 출력 이미지와 필 터링된 타겟 이미지 사이의 채널-별 평균 절대 오차(mean absolute error, MAE)를 결정하도록 구성될 수 있다. 일부 실시예에서, 시스템은 필터링된 이미지 사이의 평균 제곱근 오차(root mean squared error, RMSE)를 결정 하도록 구성될 수 있다. 일부 실시예는 추가적으로 또는 대안적으로, 하나 이상의 다른 오차 메트릭을 사용할 수 있다. 그 후, 시스템은 결정된 오차에 기초하여 기계 학습 시스템의 파라미터(들)에 대한 조정을 결정할 수 있다. 예를 들어, 시스템은 기계 학습 시스템을 트레이닝하기 위해 시스템이 실행 중인 경사 하강 알고리즘에서 결정된 오차를 사용하여 조정을 결정하도록 구성될 수 있다. 필터링된 타겟 이미지와 필터링된 출력 이미지 간의 오차를 기초로 기계 학습 시스템을 트레이닝함으로써, 시스 템은 특정한 주파수 범위에 대해 기계 학습 시스템의 성능을 최적화할 수 있다. 일부 실시예에서, 시스템은 인 간이 지각 가능한 주파수 범위에 대해 기계 학습 시스템을 최적화하도록 구성될 수 있다. 예를 들어, 기계 학습 시스템은 인간이 지각 가능한 광파 또는 주파수에 대해 이미지를 더 정확하게 향상시키도록 트레이닝될 수 있다. 도 5는 일부 실시예에 따라 기계 학습 시스템을 트레이닝하기 위한 이미지의 트레이닝 세트의 이미지를 생성하 기 위한 프로세스를 도시한다. 프로세스는 기계 학습 시스템의 성능에 대한 이미징 디바이스의 구성 요소로부터의 잡음의 효과를 감소시키기 위해 수행될 수 있다. 프로세스는 이미지 향상을 수행하기 위해 사용될 기계 학습 시스템을 트레이닝하는 것의 일부로서(예를 들어, 도 2a를 참조로 위에서 설명된 프로세스 의 일부로서) 수행될 수 있다. 프로세스는 상기 기술의 양상이 이 점으로 제한되지 않기 때문에, 하 나 이상의 하드웨어 프로세서를 포함하는 임의의 컴퓨팅 디바이스(들)를 사용하여 수행될 수 있다. 프로세스는 프로세스를 수행하는 시스템이 이미징 디바이스에 대응하는 하나 이상의 잡음 이미지를 획득하는 블록에서 시작한다. 잡음 이미지(들)는 이미징 디바이스의 구성요소에 의해 생성된 잡음을 특징 지을 수 있다. 예를 들어, 이미지의 잡음은 이미징 디바이스의 전기 회로의 무작위적인 변화에 의해 야기될 수 있다. 일부 실시예에서, 잡음 이미지(들)는 거의 영의 노출에서 이미징 디바이스에 의해 캡처된 이미지(들)일 수 있다. 거의 영의 노출에서 캡처된 이미지(들)의 픽셀 값은 이미징 디바이스에 의해 생성된 잡음에 의해 야기 될 수 있다. 일부 실시예에서, 거의 영의 노출 이미지는 1000, 1050, 1100, 1150, 1200, 1250, 1300, 1350, 1400, 1450 및/또는 1500의 ISO 설정을 사용함으로써 캡처될 수 있다. 일부 실시예에서, 거의 영의 노출 이미지 는 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69 또는 70ms의 노출 시간을 사용함으로써 캡처될 수 있다. 일부 실시예에서, 거의 영의 노출 이미지는 50ms, 55ms, 60ms, 65ms, 70ms, 75ms 또는 80ms 미만의 노출 시간을 사용하여 캡처될 수 있다. 일부 실시예에서, 거의 영의 노출 이미지는 광이 렌즈(lends)에 들어가는 것을 방지함으로써 캡처될 수 있다. 일부 실시예에서, 거의 영의 노출 이미지는 본원에 서 설명된 기법의 조합을 사용하여 캡처될 수 있다. 일부 실시예에서, 시스템은 이미징 디바이스의 특정한 설정에 대응하는 하나 이상의 잡음 이미지를 획득하도록 구성될 수 있다. 일부 실시예에서, 잡음 이미지(들)는 이미징 디바이스의 특정한 ISO 설정에 대응할 수 있다. 잡음 이미지(들)는 특정한 ISO 설정으로 구성될 때 이미징 디바이스에 의해 캡처될 수 있다. 이러한 방식으로, 시스템은 기계 학습 시스템이 상이한 ISO 설정에 대해 정확하게 수행할 수 있도록 다양한 상이한 ISO 설정에 대 한 기계 학습 시스템을 일반화할 수 있는 트레이닝 세트에 이미지를 포함시킬 수 있다. 그 다음, 프로세스는 시스템이 잡음 이미지(들)에 대응하는 하나 이상의 출력 타겟 이미지를 생성하는 블 록으로 진행한다. 타겟 이미지(들)는 기계 학습 시스템이 향상을 위해 기계 학습 시스템에 입력되는 이미 지의 잡음을 다루는 방법을 나타내는 이미지(들)일 수 있다. 일부 실시예에서, 시스템은 0의 값을 갖는 모든 픽 셀을 갖는 이미지로서 타겟 출력 이미지(들)를 생성하도록 구성될 수 있다. 이는 차후에, 향상을 위해 처리된 이미지에서 검출된 센서 잡음의 효과를 제거하도록 기계 학습 시스템을 트레이닝할 수 있다. 그 다음, 프로세스는 시스템이 기계 학습 시스템을 트레이닝하기 위해 잡음 이미지(들) 및 대응하는 출력 타겟 이미지(들)를 사용하는 블록으로 진행한다. 일부 실시예에서, 시스템은 지도 학습 스킴에서 기계 학 습 시스템을 트레이닝하기 위한 이미지의 트레이닝 세트의 일부로서 입력 이미지(들) 및 출력 타겟 이미지(들) 를 사용하도록 구성될 수 있다. 일부 실시예에서, 시스템은 향상을 위해 기계 학습 시스템에 의해 처리된 이미 지에 존재하는 잡음의 효과를 중화시키도록 기계 학습 시스템을 트레이닝할 수 있다. 일부 실시예에서, 시스템은 잡음 이미지를 트레이닝 세트의 하나 이상의 입력 이미지와 결합하도록 구성될 수 있다. 일부 실시예에서, 시스템은 잡음 이미지를 입력 이미지(들)와 연결함으로써 트레이닝 세트의 입력 이미지 (들)와 잡음 이미지를 결합하도록 구성될 수 있다. 시스템은 잡음 이미지 픽셀 값을 입력 이미지(들)의 별도의 채널로 추가함으로써(appending) 잡음 이미지를 연결할 수 있다. 예를 들어, 입력 이미지(들)는 하나의 적색, 두 개의 녹색 및 하나의 청색 채널을 가질 수 있다. 잡음 이미지는 또한, 하나의 적색, 두 개의 녹색 및 하나의 청색 채널을 가질 수 있다. 잡음 이미지의 채널은 따라서, 총 여덟 개의 채널(즉, 원래의 하나의 적색, 두 개의 녹색 및 하나의 청색 채널과, 잡음 이미지의 추가된 하나의 적색, 두 개의 녹색 및 하나의 청색 채널)을 입력 이미지(들)에 제공하는 추가적인 채널로서 추가될 수 있다. 일부 실시예에서, 잡음 이미지의 채널은 입력 이미 지(들)의 것과 상이할 수 있다. 일부 실시예에서, 시스템은 입력 이미지(들)의 픽셀 값을 잡음 이미지의 것과 결합함으로써 잡음 이미지를 트레 이닝 세트의 하나 이상의 입력 이미지와 결합하도록 구성될 수 있다. 예를 들어, 잡음 이미지의 픽셀 값은 입력 이미지(들)의 픽셀 값에 가산되거나 또는 이로부터 감산될 수 있다. 다른 예시에서, 잡음 이미지의 픽셀 값은 가중될 수 있고, 그 후 입력 이미지(들)의 픽셀 값과 결합될 수 있다. 도 6은 본원에서 설명된 기술의 일부 실시예에 따라, 본원에서 설명된 기술의 양상이 구현될 수 있는 예시적인 시스템을 도시한다. 시스템은 디스플레이, 이미징 디바이스 및 트레이닝 시스템을 포 함한다. 디스플레이는 비디오 데이터의 프레임을 디스플레이하는데 사용된다. 이미징 디바이스 는 디스플레이에 의해 디스플레이된 비디오 프레임의 이미지를 캡처하도록 구성된다. 이미징 디바이스 는 도 1a와 함께 논의된 바와 같이, 독립형 디지털 카메라(114A) 또는 스마트폰(114B)의 디지털 카메라와 같은 임의의 이미징 디바이스일 수 있다. 트레이닝 시스템은 예를 들어, 도 1a에 도시된 트레이닝 시스템 일 수 있고, 트레이닝 시스템과 함께 설명된 기계 학습 모델을 트레이닝하는데 사용되는 트레이닝 이미지를 생성할 수 있다. 비디오 데이터는 셋톱박스, 비디오 재생 디바이스(예를 들어, 컴퓨터, DVD 플레이어, 재생 기능을 갖는 비디오 레코더 등), 컴퓨팅 디바이스(예를 들어, 트레이닝 시스템 및/또는 별 도의 컴퓨팅 디바이스) 등을 통해 디스플레이에 제공될 수 있다. 디스플레이는 비디오 프레임을 디스플레이할 수 있는 임의의 광 투영 메커니즘일 수 있다. 예를 들어, 디 스플레이는 발광 다이오드(LED) TV, 유기 LED(OLED) TV, 양자점을 갖는 액정 디스플레이(LCD) TV(QLED), 플라즈마 TV, 음극선 관(cathode ray tube, CRT) TV 및/또는 다른 타입의 TV와 같은 텔레비전(TV) 및/또는 스 마트 TV일 수 있다. 일부 실시예에서, HD TV, 4K TV, 8K TV 등과 같은 고해상도 TV가 사용될 수 있다. 다른 예 시로서, 디스플레이는 프로젝터 스크린, 벽 및/또는 다른 영역에 광을 투사하는 프로젝터와 같은 프로젝터 일 수 있다.이미징 디바이스는 입력 이미지 및 타겟 이미지를 캡처하도록 구성될 수 있다. 예를 들어, 이미징 디바이 스는 저조도 조건을 시뮬레이션하기 위해, 어두운 입력 이미지를 캡처할 수 있다. 일부 실시예에서, 기준 객체 (reference object)의 이미지는 저조도 조건을 시뮬레이션하는 노출 시간으로 캡처될 수 있다. 예를 들어, 기준 객체의 이미지는 대략 1ms, 10ms, 20ms, 30ms, 40ms, 50ms, 60ms, 70ms, 80ms, 90ms 또는 100ms의 노출 시간으 로 캡처될 수 있다. 일부 실시예에서, 기준 객체의 이미지는 선명한 광 조건을 시뮬레이션하는 노출 시간으로 캡처될 수 있다. 예를 들어, 기준 객체의 이미지는 대략 1분, 2분 또는 10분의 노출 시간으로 캡처될 수 있다. 일부 실시예에서, 비디오 데이터는 저조도 조건 및/또는 선명한 조건 하에서 장면을 캡처할 수 있다. 예를 들어, 일부 실시예에서, 비디오 데이터는 저조도 조건에서 장면의 비디오를 캡처할 수 있다. 예를 들어, 비디오 는 50럭스 미만의 조도를 제공하는 광원으로 장면을 캡처할 수 있다. 다른 예시로서, 비디오 데이터는 임계 양 의 조명으로(예를 들어, 적어도 200 럭스의 광원으로) 하나 이상의 장면의 하나 이상의 비디오를 캡처하고, 타 겟 이미지로서 캡처된 비디오(들)의 프레임을 사용함으로써 선명한 타겟 이미지를 캡처할 수 있다. 일부 실시예 에서, 비디오는 트레이닝 데이터를 생성하는 것 이외의 다른 목적으로 촬영된 비디오일 수 있고, 입력 및 타겟 이미지 쌍을 생성하기 위해 본원에서 설명된 기법을 사용하여 처리될 수 있다. 일부 실시예에서, 비디오 데이터는 압축되거나 및/또는 압축되지 않은 비디오 데이터일 수 있다. 예를 들 어, 일부 실시예에서 압축되지 않은 비디오 데이터는 하나 이상의 압축 아티팩트(예를 들어, 차단(blocking) 등)를 포함할 수 있는 데이터를 사용하는 것을 피하기 위해 사용될 수 있다. 일부 실시예에서, 압축된 비디오에 서 키 프레임 및/또는 I-프레임을 사용하는 것과 같이 압축된 비디오가 사용될 수 있다. 도 7은 본원에서 설명된 기술의 일부 실시예에 따른 트레이닝 데이터의 제어된 생성을 위한 예시적인 프로세스 의 흐름도를 도시한다. 방법은 디스플레이 디바이스(예를 들어, 도 6의 디스플레이)가 비디오 데이터의 비디오 프레임(예를 들어, 도 6의 비디오 데이터)을 디스플레이하는 단계에서 시작한다. 방 법은 단계로 진행하고, 이미징 디바이스(예를 들어, 도 6의 이미징 디바이스)는 디스플레이된 비디오 프레임의 타겟 이미지(예를 들어, 선명한 이미지)를 캡처하며, 이는 트레이닝 시스템에 의해 트레 이닝될 기계 학습 모델의 타겟 출력을 나타낸다. 방법은 단계로 진행하고, 이미징 디바이스는 디스플 레이된 비디오 프레임의 입력 이미지(예를 들어, 어두운 이미지)를 캡처하며, 이는 캡처된 타겟 이미지에 대응 하고 트레이닝 시스템에 의해 트레이닝될 기계 학습 모델에 대한 입력을 나타낸다. 단계(704 및 706)가 방 법에서 특정한 순서로 도시되지만, 이는 단지 예시적인 목적이며, 입력 및 타겟 이미지를 캡처하기 위해 임의의 순서가 사용될 수 있다(예를 들어, 입력 이미지는 타겟 이미지 이전에 캡처될 수 있고, 입력 이미지 및 타겟 이미지는 동일한 및/또는 복수의 이미징 디바이스 등을 사용하여 동시에 캡처될 수 있다). 방법은 단계로 진행하고, 컴퓨팅 디바이스(예를 들어, 도 6에 도시된 트레이닝 시스템)는 타겟 이미지 및 입력 이미지에 액세스하고, 트레이닝된 기계 학습 모델을 획득하기 위해 타겟 이미지 및 입력 이미지 를 사용하여 기계 학습 모델을 트레이닝한다. 일부 실시예에서, 시스템은: 블록에서 캡처된 입력 이미 지를 트레이닝 데이터 세트의 입력으로 사용하고; 블록에서 캡처된 타겟 이미지를 트레이닝 데이터 세트의 타겟 출력으로서 사용하고; 및 트레이닝 데이터에 지도 학습 알고리즘을 적용하도록 구성될 수 있 다. 각각의 입력 이미지에 대응하는 타겟 이미지는 트레이닝된 기계 학습 모델이 출력할 입력 이미지의 타겟 향 상된 버전을 나타낼 수 있다. 블록에서 기계 학습 모델을 트레이닝한 이후에, 프로세스가 종료된다. 일부 실시예에서, 시스템은 트 레이닝된 기계 학습 모델을 저장하도록 구성될 수 있다. 시스템은 기계 학습 모델의 하나 이상의 트레이닝된 파 라미터의 값(들)을 저장할 수 있다. 예시로서, 기계 학습 모델은 하나 이상의 신경망을 포함할 수 있고, 시스템 은 신경망(들)의 트레이닝된 가중치 값을 저장할 수 있다. 다른 예시로서, 기계 학습 모델은 컨볼루션 신경망을 포함하고, 시스템은 컨볼루션 신경망의 하나 이상의 트레이닝된 필터를 저장할 수 있다. 일부 실시예에서, 시스 템은 (예를 들어, 이미징 디바이스에 의해 저조도 조건에서 캡처된) 이미지를 향상시키는데 사용하기 위해 (예 를 들어, 이미지 향상 시스템에) 트레이닝된 기계 학습 모델을 저장하도록 구성될 수 있다. 도 7에서 단계로부터 단계로 점선 화살표로 도시된 바와 같이, 복수의 타겟 이미지 및 대응하는 입력 이미지는 비디오의 상이한 프레임으로 캡처될 수 있다. 트레이닝 세트를 구축하기 위해 동일한 비디오 및/또는 복수의 비디오로부터 포함하는, 복수의 타겟 이미지 및 입력 이미지를 캡처하는 것이 바람직할 수 있다. 그러므 로, 일부 실시예에서, 기법은 복수의 및/또는 모든 비디오의 프레임의 타겟 및 입력 이미지를 캡처할 수 있거나, 및/또는 복수의 비디오의 프레임의 타겟 및 입력 이미지를 캡처할 수 있다. 일부 실시예에서, 기법은 실내(room)의 유일한 광이 디스플레이 디바이스에 의해 생성된 광이도록, 제어된 실내 또는 환경에서 구현될 수 있다. 일부 실시예에서, 이미징 디바이스는 디스플레이 디바이스로부터 방출된 광(예 를 들어, TV로부터 방출된 광)을 캡처하도록 구성될 수 있다. 일부 실시예에서, 이미징 디바이스는 프로젝터로 부터 프로젝터 스크린 또는 다른 표면 상에 투사된 광과 같이, 표면으로부터 반사된 광을 캡처하도록 구성될 수 있다. 일부 실시예에서, 이미징 디바이스는 디스플레이 디바이스의 프레임 속도를 기초로 타겟 및 입력 이미지를 캡처 하도록 구성될 수 있다. 예를 들어, 디스플레이는 60Hz, 120Hz 등과 같은 상이한 프레임 속도를 가질 수 있다. 보상되지 않은 경우, 이미징 디바이스는 앨리어싱(aliasing)을 야기하는 방식으로 이미지를 캡처할 수 있다. 예 를 들어, 롤링 셔터(rolling shutter)를 사용할 때, 일부 프레임 속도로 롤링 셔터는 앨리어싱을 초래하도록 TV 프레임 속도(예를 들어, 나이퀴스트 주파수(Nyquist frequency)를 만족하는 프레임 속도)와 상호작용할 수 있다. 기법은 앨리어싱 효과를 회피하는 샘플링 속도로 이미지를 캡처하는 것을 포함할 수 있다. 일부 실시예에서, 시스템은 기계 학습 모델이 이미지 캡처 기술(예를 들어, 카메라 모델 또는 이미징 센서 모델)에 의해 캡처된 이미지를 향상시키기 위해 트레이닝될 수 있도록, 특정한 이미지 캡처 기술에 의해 캡처된 입력-타겟 이미지를 사용하도록 구성될 수 있다. 예를 들어, 기계 학습 모델은 저조도에서 이미지 캡처 기술을 사용하여 캡처된 이미지를 조명하도록 트레이닝될 수 있다. 기계 학습 모델은 상기 기계 학습 모델이 이미지 캡 처 기술의 오차 특성을 보정하기 위해 최적화될 수 있도록, 이미지 캡처 기술의 오차 프로파일에 대해 트레이닝 될 수 있다. 일부 실시예에서, 시스템은 이미징 센서의 타입으로부터 획득된 데이터에 액세스하도록 구성될 수 있다. 예시로서, 시스템은 CMOS 이미징 센서의 특정한 모델에 의해 캡처된 타겟 이미지에 액세스할 수 있다. 일 부 실시예에서, 시스템은 특정한 카메라 모델에 의해 캡처된 트레이닝 이미지에 액세스하도록 구성될 수 있다. 본원에서 설명된 바와 같이, 예를 들어, 시스템은 Canon EOS Rebel T7i EF-S 18-135 카메라 및/또는 임의의 다 른 타입의 카메라에 의해 캡처된 타겟 이미지에 액세스할 수 있다. 일부 실시예는 본원에서 설명된 특정한 타입 의 이미지 캡처 기술로 제한되지 않는다. 이미징 디바이스는 상이한 노출 시간을 사용하거나 및/또는 상이한 밝기 설정에서 디스플레이를 캡처하는 것과 같은 다양한 기법을 사용하여 디스플레이된 비디오 프레임의 타겟 및 입력 이미지를 캡처할 수 있다. 일부 실시 예에서, 이미징 디바이스는 상이한 노출 시간을 사용하여 타겟 및 입력 이미지를 캡처할 수 있다. 예를 들어, 이미징 디바이스는 제1 노출 시간을 사용하여 타겟 이미지를 캡처할 수 있고, 제1 노출 시간보다 짧은 제2 노출 시간을 사용하여 디스플레이된 비디오 프레임의 입력 이미지를 캡처할 수 있다. 일부 실시예에서, 이미징 디바 이스는 임계 양의 조명(예를 들어, 적어도 200 럭스)로 디스플레이된 비디오 프레임의 이미지를 캡처하기에 충 분히 긴 제1 노출 시간을 사용함으로써 타겟 이미지를 캡처할 수 있다. 일부 실시예에서, 이미징 디바이스는 특 정한 저조도 기준(예를 들어, 50 럭스 미만)으로 입력 이미지 또는 어두운 이미지를 캡처할 수 있다. 일부 실시예에서, 이미징 디바이스는 디스플레이의 상이한 밝기 설정을 사용하여 디스플레이된 비디오 프레임의 타겟 및 입력 이미지를 캡처할 수 있다. 예를 들어, 이미징 디바이스는 디스플레이가 비디오 프레임을 제1 밝기 로 디스플레이할 때 타겟 이미지를 캡처할 수 있고, 제1 밝기보다 어두운 제2 밝기로 입력 이미지를 캡처할 수 있다. 일부 실시예에서, 디스플레이의 밝기는 이미징 디바이스가 동일한 노출 시간을 사용하여 타겟 및 입력 이 미지를 캡처할 수 있도록 조정될 수 있다. 일부 실시예에서, 디스플레이의 노출 시간 및/또는 밝기는 기본 비디 오가 어떻게 캡처되었는지를 기초로(예를 들어, 비디오 데이터가 저조도 조건 또는 정상/선명한 광 조건 하에서 캡처되었는지에 의존하여) 조정될 수 있다. 일부 실시예에서, TV의 밝기는 정확한 색상으로 연관된 럭스 값을 각각 반영하는 밝기 값을 결정하도록 프로파 일링될 수 있다(profiled). 예를 들어, TV는 0 내지 100, 0 내지 50 등과 같이 미리 결정된 범위로부터 조정될 수 있는 밝기 값만을 가질 수 있다. 밝기가 증가될 때, 각 색상 유사도의 럭스가 선형 방식으로 증가하도록, 밝 기가 0으로부터 100까지 변할 때 디스플레이의 RGB 값의 럭스가 본질적으로 선형적으로 증가하는 것으로 예상될 수 있다. 하지만, 본 발명자는 TV에서 밝기 값을 변경할 때, 다양한 밝기 수준에 대한 RGB 값이 상이한 프로파 일을 가질 수 있고, 수준마다 선형적으로 변경되지 않을 수 있음을 발견하고 인식하였다. 그러므로, 일부 TV에 대해, 밝기 설정에 따라 선형적으로 증가하는 대신에, RGB 럭스 값은 일부 지점에서 빠르게, 그 후 다른 지점에 서 느리게 증가할 수 있다. 예를 들어, 낮은 밝기 설정(예를 들어, 5, 7, 10 등)에 대해, 디스플레이는 상기 밝 기 수준에 대한 TV의 특정한 색상을 (정확하게) 표현하지 못할 수 있어서, 0.5 럭스로 디스플레이되는 어두운 장면이 실제 광의 0.5 럭스에서의 장면과 동일하지 않을 수 있다. 다른 예시로서, 높은 밝기 설정(예를 들어, 60, 70, 80)에 대해, 디스플레이는 또한 특정한 색상을 정확하게 표현하지 못할 수도 있다. 일부 실시예에서, 다양한 트레이닝 이미지를 캡처하기 위해 사용할 TV의 밝기 수준을 결정하기 위해 교정 (calibration) 프로세스가 사용될 수 있다. 예를 들어, 럭스계(lux meter)가 밝기 수준을 교정하는데 사용될 수 있다. 일부 실시예에서, 디스플레이 디바이스는 특정한 밝기/럭스 수준이 정확한 RGB 값(예를 들어, 동일한 수 준의 럭스 조도 하에 장면을 보는 것과 유사한 RGB 값)을 출력하는지를 결정하기 위해 교정 프로세스의 일부로 서 색상 차트를 디스플레이할 수 있다. 색상 차트는 예를 들어, 0부터 100까지 범위의 적색, 청색, 녹색 및 검 은색(대 흰색) 바(bars)와 같은 다양한 바를 포함할 수 있다. 결정된 교정 프로파일은 어두운 이미지를 캡처하 기 위한 적절한 밝기 설정(들) 및 선명한 이미지를 캡처하기 위한 적절한 밝기 설정(들)과 같은 다양한 타입의 이미지를 캡처할 때 TV에 대해 적합한 밝기 설정을 결정하기 위해 저장되고 사용될 수 있다. 도 8은 본원에서 설명된 기술의 일부 실시예에 따라 이미지를 향상시키기 위해 프로세스로부터 획득된 트 레이닝된 기계 학습 모델을 사용하기 위한 예시적인 프로세스를 도시한다. 프로세스는 임의의 적합한 컴퓨팅 디바이스에 의해 수행될 수 있다. 예시로서, 프로세스는 도 1a-1b를 참조로 설명된 이미지 향상 시 스템에 의해 수행될 수 있다. 프로세스는 시스템이 향상시키기 위한 이미지에 액세스하는 블록에서 시작한다. 일부 실시예에서, 시 스템은 이미징 디바이스(예를 들어, 디지털 카메라 또는 그의 이미징 센서)에 의해 캡처된 이미지에 액세스하도 록 구성될 수 있다. 예를 들어, 시스템은 디바이스가 장면의 사진을 캡처하는데 사용될 때 캡처된 이미지에 액 세스할 수 있다. 다른 예시로서, 시스템은 디바이스가 비디오를 캡처하는데 사용될 때 비디오의 프레임에 액세 스할 수 있다. 일부 실시예에서, 시스템은 (예를 들어, 도 1b를 참조로 위에서 설명된 바와 같이) 디바이스가 캡처된 이미지에 이미지 처리를 적용하기 전에 이미지에 액세스하도록 구성될 수 있다. 일부 실시예에서, 시스 템은 디바이스에 의해(예를 들어, 스마트폰의 디지털 카메라에 의해) 캡처된 이미지에 액세스하는 디바이스(예 를 들어, 스마트폰)에 설치된 애플리케이션을 포함할 수 있다. 애플리케이션은 캡처된 이미지가 사용자에게 디 스플레이되기 전에 이미지에 액세스할 수 있다. 그 다음, 프로세스는 시스템이 블록에서 액세스된 이미지를 트레이닝된 기계 학습 모델에 제공하는 블록으로 진행한다. 예를 들어, 시스템은 블록에서 액세스된 이미지를 도 7을 참조하여 본원에서 설 명된 프로세스를 사용하여 트레이닝된 기계 학습 모델에 제공할 수 있다. 일부 실시예에서, 시스템은 기계 학습 모델에 대한 입력으로서 이미지 픽셀 값을 제공함으로써 기계 학습 모델에 대한 입력으로서 이미지를 제공 하도록 구성될 수 있다. 예를 들어, 이미지는 1000x1000 픽셀 이미지일 수 있다. 시스템은 기계 학습 모델에 대 한 입력으로서 픽셀의 각각에서의 픽셀 값을 제공할 수 있다. 일부 실시예에서, 시스템은 이미지를 픽셀 값의 세트로 평면화하도록(flatten) 구성될 수 있다. 예를 들어, 시스템은: 500x500 픽셀 이미지를 250,000x1 픽 셀 값 어레이로 평면화하고; 기계 학습 모델에 대한 입력으로 어레이를 제공할 수 있다. 예시를 위해, 기 계 학습 모델(예를 들어, CNN)은 다수의 입력을 가질 수 있다. 시스템은 다수의 입력으로서 이미지로부터 픽셀 값을 제공하도록 구성될 수 있다. 일부 실시예에서, 시스템은 이미지를 다수의 부분으로 나누고, 기계 학습 모델에 대한 입력으로서 각 부분을 제공함으로써, 기계 학습 모델에 대한 입력으로서 이미지를 제공하도록 구성될 수 있다. 예를 들어, 시 스템은 기계 학습 모델에 대한 입력으로서 이미지의 부분의 각각의 픽셀 값을 제공할 수 있다. 시스템은 이미지 의 부분의 픽셀 값을 기계 학습 모델에 어레이로서 입력할 수 있다. 일부 실시예에서, 시스템은 기계 학습 모델에 제공된 입력 이미지에 대응하는 향상된 출력 이미지를 획득하도록 구성될 수 있다. 일부 실시예에서, 시스템은 향상될 이미지의 픽셀 값을 기계 학습 모델에 제공하는 것에 응답하여 다수의 픽셀 값을 획득하고; 및 획득된 픽셀 값으로부터 향상된 이미지를 생성함으로써, 향상된 출력 이미지를 획득하도록 구성될 수 있다. 예를 들어, 기계 학습 모델은 본원에서 설명된 바와 같이 CNN일 수 있다. 이 예시에서, 픽셀 값은 CNN의 제1 컨볼루션 층에 대한 입력으로서 제공될 수 있다. 블록에서 기계 학습 모델에 대한 입력으로서 이미지를 제공한 이후에, 프로세스는 시스템이 기계 학 습 모델의 출력으로부터 향상된 이미지를 획득하는 블록으로 진행한다. 일부 실시예에서, 시스템은 기계 학습 모델로부터, 향상된 이미지의 픽셀 값을 획득하도록 구성될 수 있다. 예를 들어, 기계 학습 모델은 500x500 출력 이미지의 픽셀에서 픽셀 값을 지정하는 250,000x1 픽셀 값 어레이를 출력할 수 있다. 일부 실시예 에서, 시스템은: 기계 학습 모델로부터, 입력 이미지의 다수의 부분의 향상된 버전을 획득하고; 향상 된 이미지를 생성하기 위해 향상된 이미지 부분을 결합하도록 구성될 수 있다. 기계 학습 모델에 대한 입력으로 서 이미지 부분을 제공하고 입력 이미지 부분에 대응하는 출력을 결합하기 위한 예시적인 프로세스가 도 5b-c를 참조로 본원에서 설명된다. 일부 실시예에서, 시스템이 기계 학습 모델의 출력으로부터 향상된 이미지를 획득한 이후에, 프로세스가 종료된다. 예를 들어, 시스템은 향상된 이미지를 출력할 수 있다. 일부 실시예에서, 시스템은 향상된 이미지를 저장하도록 구성될 수 있다. 예를 들어, 시스템은 디바이스(예를 들어, 스마트폰)의 하드 드라이브 상에 향상된 이미지를 저장할 수 있다. 일부 실시예에서, 시스템은 추가적인 이미지 처리를 위해 향상된 이미지를 전달하도 록 구성될 수 있다. 예를 들어, 디바이스는 기계 학습 모델로부터 획득된 향상된 이미지에 적용될 수 있는 사진 에 적용되는 추가적인 이미지 향상 처리를 가질 수 있다. 일부 실시예에서, 기계 학습 모델의 출력으로부터 향상된 이미지를 획득한 이후에, 프로세스는 시스템이 향상시키기 위한 다른 이미지에 액세스하는 블록(블록으로부터 블록으로 점선으로 표시됨)로 돌 아간다. 예를 들어, 시스템은 이미징 디바이스에 의해 캡처되는 비디오 또는 이전에 캡처된 비디오로부터 비디 오 프레임 시퀀스를 수신할 수 있다. 시스템은 비디오의 각 프레임에 대해 블록(802-806)의 단계를 수행하도록 구성될 수 있다. 일부 실시예에서, 시스템은 비디오의 피드를 보는 디바이스의 사용자가 향상된 비디오 프레임 을 볼 수 있도록 각 비디오 프레임을 실시간으로 향상시킬 수 있다. 비디오가 저조도(예를 들어, 일몰 후 실 외)에서 캡처되는 경우, 시스템은 이미징 디바이스의 디스플레이 상에서 보여지는 비디오가 향상되도록(예를 들 어, 색상이 밝아지도록(lit up)) 캡처되는 비디오의 각 프레임을 향상시킬 수 있다. 다른 예시로서, 시스템은 이미징 디바이스에 의해 캡처된 일련의 사진에 대해 블록(802 내지 806)의 단계를 수행할 수 있다. 도 9는 다양한 양상들이 구현될 수 있는 특수하게 구성된 분산된 컴퓨터 시스템의 블록도를 도시한다. 도 시된 바와 같이, 분산된 컴퓨터 시스템은 정보를 교환하는 하나 이상의 컴퓨터 시스템을 포함한다. 더욱 구체적으로, 분산된 컴퓨터 시스템은 컴퓨터 시스템(902, 904 및 906)을 포함한다. 도시된 바와 같이, 컴 퓨터 시스템(902, 904 및 906)은 통신 네트워크에 의해 상호연결되고, 이를 통해 데이터를 교환할 수 있다. 네트워크는 컴퓨터 시스템이 데이터를 교환할 수 있는 임의의 통신 네트워크를 포함할 수 있다. 네 트워크를 사용하여 데이터를 교환하기 위해, 컴퓨터 시스템(902, 904 및 906) 및 네트워크는 그중에 서도 광섬유 채널, 토큰 링, 이더넷, 무선 이더넷, 블루투스, IP, IPV6, TCP/IP, UDP, DTN, HTTP, FTP, SNMP, SMS, MMS, SS6, JSON, SOAP, CORBA, REST 및 웹 서비스를 포함하는 다양한 방법, 프로토콜 및 표준을 사용할 수 있다. 데이터 전송이 안전한지 보장하기 위해, 컴퓨터 시스템(902, 904 및 906)은 예를 들어, SSL 또는 VPN 기술을 포함하는 다양한 보안 수단(security measures)을 사용하여 네트워크를 통해 데이터를 송신할 수 있다. 분산된 컴퓨터 시스템이 세 개의 네트워크 컴퓨터 시스템을 예시하지만, 분산된 컴퓨터 시스템(90 0)은 그에 제한되지 않으며, 임의의 매체 및 통신 프로토콜을 사용하여 네트워크화된 임의의 수의 컴퓨터 시스 템 및 컴퓨팅 디바이스를 포함할 수 있다. 도 9에 도시된 바와 같이, 컴퓨터 시스템은 프로세서, 메모리, 상호연결 요소, 인터페이 스 및 데이터 저장 요소를 포함한다. 본원에 개시된 양상, 기능 및 프로세스 중 적어도 일부를 구현 하기 위해, 프로세서는 조작된 데이터를 초래하는 일련의 명령어를 수행한다. 프로세서는 임의의 타 입의 프로세서, 멀티 프로세서 또는 제어기일 수 있다. 예시적인 프로세서는 인텔 제온(Intel Xeon), 아이태니 엄(Itanium), 코어(Core), 셀러론(Celeron) 또는 펜티엄(Pentium) 프로세서; AMD 옵테론(Opteron) 프로세서; 애플(Apple) A10 또는 A5 프로세서; 선 울트라스파크(Sun UltraSPARC) 프로세서; IBM Power5 + 프로세서; IBM 메인프레임 칩(mainframe chip); 또는 양자 컴퓨터와 같은 상업적으로 이용 가능한 프로세서를 포함할 수 있다. 프로세서는 상호연결 요소에 의해 하나 이상의 메모리 디바이스를 포함하는 다른 시스템 구성요소에 연결된다. 메모리는 컴퓨터 시스템의 동작 중에 프로그램(예를 들어, 프로세서에 의해 실행 가능하도록 코 딩된 명령어의 시퀀스) 및 데이터를 저장한다. 따라서, 메모리는 동적 랜덤 액세스 메모리(\"DRAM\") 또는 정적 메모리(\"SRAM\")와 같은 상대적으로 높은 성능의 휘발성 랜덤 액세스 메모리일 수 있다. 하지만, 메모리 는 디스크 드라이브(disk drive) 또는 다른 비휘발성 저장 디바이스와 같은 데이터를 저장하기 위한 임의 의 디바이스를 포함할 수 있다. 다양한 예시는 본원에 개시된 기능을 수행하기 위해, 메모리를 특정화되고, 일부 경우에서 고유한 구조로 구성할 수 있다. 이들 데이터 구조는 특정한 데이터 및 데이터의 타 입에 대한 값을 저장하도록 크기가 조정되고 구성될 수 있다. 컴퓨터 시스템의 구성요소는 상호연결 메커니즘과 같은 상호연결 요소에 의해 결합된다. 상호연결 요 소는 IDE, SCSI, PCI 및 InfiniBand와 같은 특수화된 또는 표준 컴퓨팅 버스 기술에 부합하는 하나 이상의 물리적인 버스와 같은 시스템 구성요소 간의 임의의 통신 결합을 포함할 수 있다. 상호연결 요소는 컴퓨터 시스템의 시스템 구성요소 사이에서 교환될, 명령어 및 데이터를 포함하여, 통신을 가능하게 한다. 컴퓨터 시스템은 또한, 입력 디바이스, 출력 디바이스 및 입력/출력 디바이스의 조합과 같은 하나 이상의 인터페이스 디바이스를 포함한다. 인터페이스 디바이스는 입력을 수신하거나 출력을 제공할 수 있다. 특히, 출력 디바이스는 외부 프리젠테이션(presentation)을 위한 정보를 렌더링할 수 있다. 입력 디바이스는 외 부 소스로부터 정보를 받을 수 있다. 인터페이스 디바이스의 예시는 키보드, 마우스 디바이스, 트랙볼, 마이크, 터치 스크린, 인쇄 디바이스, 디스플레이 화면, 스피커, 네트워크 인터페이스 카드 등을 포함한다. 인터페이스 디바이스는 컴퓨터 시스템이 정보를 교환하고 사용자 및 다른 시스템과 같은 외부 엔티티와 통신하는 것을 허용한다. 데이터 저장 요소는 프로세서에 의해 실행되는 프로그램 또는 다른 객체를 정의하는 명령어가 저장되 는 컴퓨터 판독가능 및 기록가능 비휘발성 또는 비일시적 데이터 저장 매체를 포함한다. 데이터 저장 요소(91 8)는 또한, 매체 상에 또는 매체에 기록되고 프로그램의 실행 동안 프로세서에 의해 처리되는 정보를 포함 할 수 있다. 더욱 구체적으로, 정보는 저장 공간을 보존하거나 데이터 교환 성능을 증가시키도록 특수하게 구성 된 하나 이상의 데이터 구조에 저장될 수 있다. 명령어는 인코딩된 신호로서 지속적으로 저장될 수 있으며, 명 령어는 프로세서가 본원에서 설명된 기능 중 임의의 것을 수행하게 할 수 있다. 매체는 예를 들어, 그중에 서도 광 디스크, 자기 디스크 또는 플래시 메모리일 수 있다. 동작 중에, 프로세서 또는 일부 다른 제어기 는 데이터가 비휘발성 기록 매체로부터, 데이터 저장 요소에 포함된 저장 매체인 것보다, 프로세서에 의해 정보에 대한 더욱 빠른 액세스를 허용하는 메모리와 같은 다른 메모리로 판독되게 한다. 메모리는 데 이터 저장 요소 또는 메모리에 위치될 수 있지만, 프로세서는 메모리 내의 데이터를 조작하고 그 후, 처리가 완료된 이후에 데이터를 데이터 저장 요소와 연관된 저장 매체에 복사한다. 다양한 구성요 소가 저장 매체와 다른 메모리 요소 사이의 데이터 이동을 관리할 수 있으며, 예시는 특정한 데이터 관리 구성 요소로 제한되지 않는다. 나아가, 예시는 특정한 메모리 시스템 또는 데이터 저장 시스템으로 제한되지 않는다. 컴퓨터 시스템이 예시로서 다양한 양상 및 기능이 실시될 수 있는 하나의 타입의 컴퓨터 시스템으로서 도 시되었지만, 양상 및 기능은 도 9에 도시된 컴퓨터 시스템상에서 구현되는 것으로 제한되지 않는다. 다양 한 양상 및 기능은 도 9에 도시된 것과 상이한 아키텍처 또는 구성요소를 갖는 하나 이상의 컴퓨터에서 실시될 수 있다. 예를 들어, 컴퓨터 시스템은 본원에 개시된 특정한 동작을 수행하도록 맞춤화된 애플리케이션-집 적 회로(\"application-specific integrated circuit, ASIC\")와 같은 특수하게 프로그래밍된 특수-목적 하드웨 어를 포함할 수 있다. 다른 예시는 모토로라(Motorola) 파워PC(PowerPC) 프로세서와 함께 MAC OS 시스템 X를 실 행하는 여러 범용 컴퓨팅 디바이스 및 독점 하드웨어 및 운영체제를 실행하는 여러 특수 컴퓨팅 디바이스의 그 리드를 사용하여 동일한 기능을 수행할 수 있다. 컴퓨터 시스템은 컴퓨터 시스템에 포함된 하드웨어 요소의 적어도 일부를 관리하는 운영체제를 포함 하는 컴퓨터 시스템일 수 있다. 일부 예시에서, 프로세서와 같은 프로세서 또는 제어기는 운영체제를 실행 한다. 실행될 수 있는 특정한 운영체제의 예시는 마이크로소프트 주식회사로부터 상용화된 윈도우 NT, 윈도우 2000(윈도우 ME), 윈도우 XP, 윈도우 비스타(Windows Vista) 또는 윈도우 6, 8 또는 6 운영체제와 같은 윈도우 기반 운영체제, 애플 컴퓨터로부터 상용화된 MAC OS 시스템 X 운영체제 또는 iOS 운영체제, 다수의 리눅스 기반 운영체제 배포, 예를 들어, 레드 햇 Inc(Red Hat Inc)로부터 상용화된 엔터프라이즈 리눅스(Enterprise Linux) 운영체제, 오라클 주식회사로부터 상용화된 솔라리스(Solaris) 운영체제, 또는 다양한 소스로부터 상용화된 유 닉스(UNIX) 운영체제 중 하나를 포함한다. 다수의 다른 운영체제가 사용될 수 있으며, 예시는 임의의 특정한 운 영체제로 제한되지 않는다. 프로세서 및 운영체제는 고수준의 프로그래밍 언어의 애플리케이션 프로그램이 기록된 컴퓨터 플랫폼을 함 께 정의한다. 이들 구성요소 애플리케이션은 통신 프로토콜 예를 들어, TCP/IP를 사용하여 통신 네트워크 예를 들어, 인터넷을 통해 통신하는 실행 가능한 중간 바이트코드(bytecode) 또는 해석된 코드(interpreted code)일 수 있다. 마찬가지로, 양상은 .Net, 스몰토크(SmallTalk), 자바(Java), C++, Ada, C#(C-샵(Sharp)), 파이선 (Python) 또는 자바스크립트(JavaScript)와 같은 객체 지향 프로그래밍 언어를 사용하여 구현될 수 있다. 다른 객체-지향 프로그래밍 언어가 또한, 사용될 수 있다. 대안적으로, 기능적인 스크립팅(scripting) 또는 논리적 프로그래밍 언어가 사용될 수 있다. 추가적으로, 다양한 양상 및 기능이 프로그래밍되지 않은 환경에서 구현될 수 있다. 예를 들어, HTML, XML 또는 다른 포맷으로 생성된 문서는 브라우저 프로그램의 윈도우에서 볼 때, 그래픽 사용자 인터페이스의 양상을 렌더 링하거나 또는 다른 기능을 수행할 수 있다. 나아가, 다양한 예시는 프로그래밍된 또는 프로그래밍되지 않은 요 소, 또는 이들의 임의의 조합으로 구현될 수 있다. 예를 들어, 웹 페이지는 HTML을 사용하여 구현될 수 있는 한 편, 웹 페이지 내에서 호출되는 데이터 객체는 C++로 기록될 수 있다. 따라서, 예시는 특정한 프로그래밍 언어 로 제한되지 않으며 임의의 적합한 프로그래밍 언어가 사용될 수 있다. 따라서, 본원에 개시된 기능적인 구성요소는 본원에 설명된 기능을 수행하도록 구성된 매우 다양한 요소(예를 들어, 특수 하드웨어, 실행 가능한 코드, 데이터 구조 또는 객체)를 포함할 수 있다. 일부 예시에서, 본원에 개시된 구성요소는 구성요소에 의해 수행되는 기능에 영향을 미치는 파라미터들을 판독 할 수 있다. 이들 파라미터는 (RAM과 같은) 휘발성 메모리 또는 (자기 하드 드라이브와 같은) 비휘발성 메모리 를 포함하는 임의의 형태의 적합한 메모리에 물리적으로 저장될 수 있다. 덧붙여, 파라미터는 (사용자 공간 애 플리케이션에 의해 정의된 데이터베이스 또는 파일과 같은) 적절한 데이터 구조 또는 (운영체제에 의해 정의된 애플리케이션 레지스트리과 같은) 보통 공유되는 데이터 구조로 논리적으로 저장될 수 있다. 덧붙여, 일부 예시 는 외부 엔티티가 파라미터를 수정하고, 그로 인해 구성요소의 행동을 구성하는 것을 허용하는 시스템 및 사용 자 인터페이스 모두를 제공한다. 전술한 개시를 기초로, 통상의 기술자에게는 본원에 개시된 실시예가 특정한 컴퓨터 시스템 플랫폼, 프로세서, 운영체제, 네트워크 또는 통신 프로토콜로 제한되지 않는다는 것이 명백해야 한다. 또한, 본원에 개시된 실시예 는 특정한 아키텍처로 제한되지 않음이 명백해야 한다. 본원에 설명된 방법 및 장치의 실시예는 다음의 설명에서 제시되거나 또는 첨부 도면에서 예시된 구성요소의 구 성 및 배열의 세부사항에 대한 응용으로 제한되지 않는다는 것이 인식될 것이다. 방법 및 장치는 다른 실시예에 서 구현될 수 있고, 다양한 방식으로 실시되거나 수행될 수 있다. 특정한 구현의 예시는 단지 예시의 목적으로 본원에 제공되며, 제한하려는 것으로 의도되지 않는다. 특히, 임의의 하나 이상의 실시예와 관련하여 설명된 동 작, 요소 및 특징은 임의의 다른 실시예에서 유사한 역할로부터 배제되는 것으로 의도되지 않는다. \"대략\", \"실질적으로\" 및 \"약\"이란 용어는 일부 실시예에서 타겟 값의 ±20% 이내, 일부 실시예에서 타겟 값의 ±10% 이내, 일부 실시예에서 타겟 값의 ±5% 이내, 및 일부 실시예에서 타겟 값의 ± 2% 이내를 의미하는 것으 로 사용될 수 있다. \"대략\" 및 \"약\"이란 용어는 타겟 값을 포함할 수 있다. 따라서, 본 발명의 적어도 하나의 실시예의 여러 양상을 설명하였지만, 다양한 변경, 수정 및 개선이 통상의 기 술자에게 쉽게 일어날 수 있음이 인식될 것이다. 이러한 변경, 수정 및 개선은 본 개시의 일부인 것으로 의도되 고, 본 발명의 사상 및 범주 내에 있는 것으로 의도된다. 따라서, 전술한 설명 및 도면은 단지 예시일 뿐이다.도면 도면1a 도면1b 도면2a 도면2b 도면2c 도면3a 도면3b 도면3c 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2021-7006783", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면에서, 다양한 도면에 도시된 각각의 동일하거나 또는 거의 동일한 구성요소는 유사한 참조부호로 나타난다. 명료함을 위해, 모든 도면에 모든 구성요소가 라벨링되지는 않을 수 있다. 도면은 축적대로 도시된 것은 아니고, 그 대신에 본원에서 설명된 기법 및 디바이스의 다양한 양상을 예시하는 데 중점을 둔다. 도 1a-b는 일부 실시예에 따른 이미지 향상 시스템의 동작을 예시하는 블록도를 도시한다. 도 2a는 일부 실시예에 따른, 기계 학습 시스템을 트레이닝하기 위한 프로세스를 도시한다. 도 2b는 일부 실시예에 따른, 트레이닝 이미지의 세트를 획득하기 위한 예시적인 프로세스를 도시한다. 도 2c는 일부 실시예에 따른, 트레이닝 이미지의 세트를 획득하기 위한 다른 예시적인 프로세스를 도시한다. 도 3a는 일부 실시예에 따른, 입력 및 출력 이미지의 일부를 사용하여 기계 학습 시스템을 트레이닝하기 위한 프로세스를 도시한다. 도 3b는 일부 실시예에 따른, 이미지를 부분으로 나눔으로써 이미지를 향상시키기 위한 프로세스를 도시한다. 도 3c는 일부 실시예에 따른, 기계 학습 시스템에 의해 수행되는 필터링 동작에서 가장자리 왜곡을 완화하기 위 한 프로세스를 도시한다. 도 4는 일부 실시예에 따른, 기계 학습 시스템을 트레이닝하기 위한 프로세스를 도시한다. 도 5는 일부 실시예에 따른, 기계 학습 시스템을 트레이닝하기 위한 이미지의 트레이닝 세트의 이미지를 생성하 기 위한 프로세스를 도시한다. 도 6은 본원에서 설명된 기술의 일부 실시예에 따라, 본원에서 설명된 기술의 양상이 구현될 수 있는 예시적인 시스템을 도시한다. 도 7은 본원에서 설명된 기술의 일부 실시예에 따른, 트레이닝 데이터의 제어된 생성을 위한 예시적인 프로세스 의 흐름도를 도시한다. 도 8은 본원에서 설명된 기술의 일부 실시예에 따른, 이미지를 향상시키기 위한 도 7의 프로세스로부터 획득된 트레이닝된 기계 학습 모델을 사용하기 위한 예시적인 프로세스를 도시한다. 도 9는 일부 실시예에 따른, 다양한 양상들이 구현될 수 있는 분산된 컴퓨터 시스템의 블록도를 도시한다."}
