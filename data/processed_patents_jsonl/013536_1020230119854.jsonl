{"patent_id": "10-2023-0119854", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0037243", "출원번호": "10-2023-0119854", "발명의 명칭": "합성 비디오 생성 장치 및 합성 비디오 생성 방법", "출원인": "엔에이치엔 주식회사", "발명자": "윤다혜"}}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 비디오 및 소스 이미지를 기초로 더미 프레임을 생성하고, 상기 더미 프레임을 상기 제1 비디오에 추가하여제2 비디오를 생성하는 전처리부; 및상기 제2 비디오의 프레임들의 모션(motion)에 상기 소스 이미지의 객체를 합성하여 제1 합성 비디오를 생성하는 이미지 합성부를 포함하는 합성 비디오 생성 장치."}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 제2 비디오의 첫 번째 프레임은 상기 더미 프레임인 것을 특징으로 하는 합성 비디오생성 장치."}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 이미지 합성부는 상기 제1 합성 비디오의 프레임들 중 상기 더미 프레임에 상응하는 프레임을 삭제하여 제2 합성 비디오를 생성하는 것을 특징으로 하는 합성 비디오 생성 장치."}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 전처리부는 상기 제1 비디오의 프레임들 중 상기 소스 이미지와의 유사도가 가장 높은프레임으로 상기 더미 프레임을 생성하는 것을 특징으로 하는 합성 비디오 생성 장치."}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 상기 전처리부는 상기 제1 비디오의 상기 프레임들 각각의 제1 랜드마크(landmark)들을 결정하고, 상기 소스 이미지의 제2 랜드마크들을 결정하며, 상기 제1 랜드마크들 및 상기 제2 랜드마크들을 기초로상기 유사도를 결정하는 것을 특징으로 하는 합성 비디오 생성 장치."}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서, 상기 유사도는 상기 제1 랜드마크들 중 서로 연결된 랜드마크들 사이의 각도 및 거리 및 상기 제2 랜드마크들 중 서로 연결된 랜드마크들 사이의 각도 및 거리를 비교하여 결정되는 것을 특징으로 하는합성 비디오 생성 장치."}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서, 상기 전처리부는 인공지능 모델을 사용하여 상기 더미 프레임을 생성하는 것을 특징으로 하는 합성 비디오 생성 장치."}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서, 상기 전처리부는 상기 제1 비디오의 프레임들 중 적어도 하나 및 상기 소스 이미지를 기초로상기 더미 프레임을 생성하고,상기 더미 프레임은 상기 소스 이미지의 객체의 상태를 모방하는 상기 제1 비디오의 상기 프레임들 중 상기 적어도 하나의 객체를 포함하는 것을 특징으로 하는 합성 비디오 생성 장치."}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서, 상기 전처리부는 상기 제1 비디오의 상기 프레임들 중 상기 적어도 하나의 제1 랜드마크들을결정하고, 상기 소스 이미지의 제2 랜드마크들을 결정하며,상기 인공지능 모델은 상기 제1 랜드마크들 및 상기 제2 랜드마크들을 기초로 상기 더미 프레임을 생성하는 것공개특허 10-2025-0037243-3-을 특징으로 하는 합성 비디오 생성 장치."}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서, 상기 인공지능 모델은상기 제1 랜드마크들 및 상기 제2 랜드마크들을 입력받아 상기 더미 프레임의 랜드마크들을 추론하여 추론 랜드마크들을 생성하는 제1 인공지능 모델; 및상기 추론 랜드마크들 및 상기 제1 비디오의 상기 프레임들 중 상기 적어도 하나를 입력받아 상기 더미 프레임을 생성하는 제2 인공지능 모델을 포함하는 것을 특징으로 하는 합성 비디오 생성 장치."}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서, 상기 제1 인공지능 모델은상기 제1 랜드마크들 및 상기 제2 랜드마크들을 입력받아 잠재 벡터(latent vector)를 생성하는 인코더; 및상기 잠재 벡터를 입력받아 상기 추론 랜드마크들을 생성하는 디코더를 포함하는 것을 특징으로 하는 합성 비디오 생성 장치."}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서, 상기 제2 인공지능 모델은 상기 추론 랜드마크들, 상기 잠재 벡터, 및 상기 제1 비디오의상기 프레임들 중 상기 적어도 하나를 입력받아 상기 더미 프레임을 생성하는 것을 특징으로 하는 합성 비디오생성 장치."}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 8 항에 있어서, 상기 인공지능 모델은 학습 비디오의 제1 프레임의 랜드마크들 및 상기 학습 비디오의 제2프레임의 랜드마크들을 입력받아 상기 제1 프레임의 객체의 상태를 모방하는 상기 제2 프레임의 객체를 포함하는 학습 더미 프레임을 생성하도록 학습되는 것을 특징으로 하는 합성 비디오 생성 장치."}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서, 상기 인공지능 모델은상기 제1 프레임의 상기 랜드마크들 및 상기 제2 프레임의 상기 랜드마크들을 입력받아 잠재 벡터를 생성하는인코더 및 상기 잠재 벡터를 입력받아 추론 랜드마크들을 생성하는 디코더를 포함하는 제1 인공지능 모델; 및상기 추론 랜드마크들 및 상기 제1 프레임을 입력받아 상기 학습 더미 프레임을 생성하는 제2 인공지능 모델을포함하고,상기 인공지능 모델은 상기 제2 프레임의 상기 랜드마크들과 상기 추론 랜드마크들 사이의 일관성 손실(consistency loss) 및 상기 제2 프레임과 상기 학습 더미 프레임 사이의 일관성 손실의 합이 감소되도록 학습되는 것을 특징으로 하는 합성 비디오 생성 장치."}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 1 항에 있어서, 상기 이미지 합성부는 상기 제2 비디오의 제1 키포인트들을 결정하고, 상기 소스 이미지의제2 키포인트들을 결정하며, 상기 제1 키포인트들의 이동을 상기 제2 키포인트들에 반영하여 상기 제1 합성 비디오를 생성하는 것을 특징으로 하는 합성 비디오 생성 장치."}
{"patent_id": "10-2023-0119854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1 비디오 및 소스 이미지를 기초로 더미 프레임을 생성하는 단계;상기 더미 프레임을 상기 제1 비디오에 추가하여 제2 비디오를 생성하는 단계; 및상기 제2 비디오의 프레임들의 모션(motion)에 상기 소스 이미지의 객체를 합성하여 제1 합성 비디오를 생성하는 단계를 포함하는 합성 비디오 생성 방법.공개특허 10-2025-0037243-4-"}
{"patent_id": "10-2023-0119854", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "합성 비디오 생성 장치는 제1 비디오 및 소스 이미지를 기초로 더미 프레임을 생성하고, 더미 프레임을 제1 비디 오에 추가하여 제2 비디오를 생성하는 전처리부, 및 제2 비디오의 프레임들의 모션(motion)에 소스 이미지의 객 체를 합성하여 제1 합성 비디오를 생성하는 이미지 합성부를 포함한다."}
{"patent_id": "10-2023-0119854", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 전자 장치에 관한 것이다. 보다 상세하게는, 본 발명은 합성 비디오 생성 장치 및 합성 비디오 생성 방법에 관한 것이다."}
{"patent_id": "10-2023-0119854", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "소스 이미지의 사람 얼굴에 비디오의 사람 얼굴 모션을 합성하는 페이스 애니메이션(face animation)(또는, 말 하는 얼굴 비디오 생성(talking face video generation), 비디오 합성(video synthesis)이라고도 불림.) 기술 이 다양한 분야에서 활용되고 있다. 페이스 에니메이션 기술에서, 소스 이미지의 사람 얼굴의 상태(예를 들어, 표정, 머리 방향 등)와 비디오의 첫 번째 프레임의 사람 얼굴의 상태(예를 들어, 표정, 머리 방향 등)가 상이한 경우, 비디오의 모션이 합성된 비디 오에 제대로 반영되지 않는 문제가 있다."}
{"patent_id": "10-2023-0119854", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 목적은 비디오의 모션이 적절하게 반영되는 합성 비디오를 생성하는 합성 비디오 생성 장치를 제 공하는 것이다. 본 발명의 다른 목적은 비디오의 모션이 적절하게 반영되는 합성 비디오를 생성하는 합성 비디오 생성 방법을 제공하는 것이다."}
{"patent_id": "10-2023-0119854", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 목적을 달성하기 위하여, 본 발명의 실시예들에 따른 합성 비디오 생성 장치는 제1 비디오 및 소 스 이미지를 기초로 더미 프레임을 생성하고, 상기 더미 프레임을 상기 제1 비디오에 추가하여 제2 비디오를 생 성하는 전처리부, 및 상기 제2 비디오의 프레임들의 모션(motion)에 상기 소스 이미지의 객체를 합성하여 제1 합성 비디오를 생성하는 이미지 합성부를 포함할 수 있다. 일 실시예에 있어서, 상기 제2 비디오의 첫 번째 프레임은 상기 더미 프레임일 수 있다. 일 실시예에 있어서, 상기 이미지 합성부는 상기 제1 합성 비디오의 프레임들 중 상기 더미 프레임에 상응하는 프레임을 삭제하여 제2 합성 비디오를 생성할 수 있다. 일 실시예에 있어서, 상기 전처리부는 상기 제1 비디오의 프레임들 중 상기 소스 이미지와의 유사도가 가장 높 은 프레임으로 상기 더미 프레임을 생성할 수 있다. 일 실시예에 있어서, 상기 전처리부는 상기 제1 비디오의 상기 프레임들 각각의 제1 랜드마크(landmark)들을 결 정하고, 상기 소스 이미지의 제2 랜드마크들을 결정하며, 상기 제1 랜드마크들 및 상기 제2 랜드마크들을 기초 로 상기 유사도를 결정할 수 있다. 일 실시예에 있어서, 상기 유사도는 상기 제1 랜드마크들 중 서로 연결된 랜드마크들 사이의 각도 및 거리 및 상기 제2 랜드마크들 중 서로 연결된 랜드마크들 사이의 각도 및 거리를 비교하여 결정될 수 있다. 일 실시예에 있어서, 상기 전처리부는 인공지능 모델을 사용하여 상기 더미 프레임을 생성할 수 있다. 일 실시예에 있어서, 상기 전처리부는 상기 제1 비디오의 프레임들 중 적어도 하나 및 상기 소스 이미지를 기초 로 상기 더미 프레임을 생성하고, 상기 더미 프레임은 상기 소스 이미지의 객체의 상태를 모방하는 상기 제1 비 디오의 상기 프레임들 중 상기 적어도 하나의 객체를 포함할 수 있다. 일 실시예에 있어서, 상기 전처리부는 상기 제1 비디오의 상기 프레임들 중 상기 적어도 하나의 제1 랜드마크들 을 결정하고, 상기 소스 이미지의 제2 랜드마크들을 결정하며, 상기 인공지능 모델은 상기 제1 랜드마크들 및 상기 제2 랜드마크들을 기초로 상기 더미 프레임을 생성할 수 있다. 일 실시예에 있어서, 상기 인공지능 모델은 상기 제1 랜드마크들 및 상기 제2 랜드마크들을 입력받아 상기 더미 프레임의 랜드마크들을 추론하여 추론 랜드마크들을 생성하는 제1 인공지능 모델, 및 상기 추론 랜드마크들 및 상기 제1 비디오의 상기 프레임들 중 상기 적어도 하나를 입력받아 상기 더미 프레임을 생성하는 제2 인공지능 모델을 포함할 수 있다. 일 실시예에 있어서, 상기 제1 인공지능 모델은 상기 제1 랜드마크들 및 상기 제2 랜드마크들을 입력받아 잠재 벡터(latent vector)를 생성하는 인코더, 및 상기 잠재 벡터를 입력받아 상기 추론 랜드마크들을 생성하는 디코 더를 포함할 수 있다. 일 실시예에 있어서, 상기 제2 인공지능 모델은 상기 추론 랜드마크들, 상기 잠재 벡터, 및 상기 제1 비디오의 상기 프레임들 중 상기 적어도 하나를 입력받아 상기 더미 프레임을 생성할 수 있다. 일 실시예에 있어서, 상기 인공지능 모델은 학습 비디오의 제1 프레임의 랜드마크들 및 상기 학습 비디오의 제2 프레임의 랜드마크들을 입력받아 상기 제1 프레임의 객체의 상태를 모방하는 상기 제2 프레임의 객체를 포함하 는 학습 더미 프레임을 생성하도록 학습될 수 있다. 일 실시예에 있어서, 상기 인공지능 모델은 상기 제1 프레임의 상기 랜드마크들 및 상기 제2 프레임의 상기 랜 드마크들을 입력받아 잠재 벡터를 생성하는 인코더 및 상기 잠재 벡터를 입력받아 추론 랜드마크들을 생성하는 디코더를 포함하는 제1 인공지능 모델, 및 상기 추론 랜드마크들 및 상기 제1 프레임을 입력받아 상기 학습 더 미 프레임을 생성하는 제2 인공지능 모델을 포함하고, 상기 인공지능 모델은 상기 제2 프레임의 상기 랜드마크 들과 상기 추론 랜드마크들 사이의 일관성 손실(consistency loss) 및 상기 제2 프레임과 상기 학습 더미 프레 임 사이의 일관성 손실의 합이 감소되도록 학습될 수 있다. 일 실시예에 있어서, 상기 이미지 합성부는 상기 제2 비디오의 제1 키포인트들을 결정하고, 상기 소스 이미지의 제2 키포인트들을 결정하며, 상기 제1 키포인트들의 이동을 상기 제2 키포인트들에 반영하여 상기 제1 합성 비 디오를 생성할 수 있다. 본 발명의 다른 목적을 달성하기 위하여, 본 발명의 실시예들에 따른 합성 비디오 생성 방법은 제1 비디오 및 소스 이미지를 기초로 더미 프레임을 생성하는 단계, 상기 더미 프레임을 상기 제1 비디오에 추가하여 제2 비디 오를 생성하는 단계, 및 상기 제2 비디오의 프레임들의 모션(motion)에 상기 소스 이미지의 객체를 합성하여 제 1 합성 비디오를 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0119854", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들에 따른 합성 비디오 생성 장치는 더미 프레임을 생성함으로써, 비디오와 이미지의 객체의 상태를 일치시킬 수 있다. 이에 따라, 합성 비디오에 비디오의 모션이 적절하게 반영될 수 있다."}
{"patent_id": "10-2023-0119854", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "다만, 본 발명의 효과는 상술한 효과에 한정되는 것이 아니며, 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위에서 다양하게 확장될 수 있을 것이다."}
{"patent_id": "10-2023-0119854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명에 따른 바람직한 실시예를 첨부한 도면을 참조하여 상세히 설명한다. 하기의 설명에서는 본 발명 에 따른 동작을 이해하는데 필요한 부분만이 설명되며 그 이외 부분의 설명은 본 발명의 요지를 모호하지 않도 록 하기 위해 생략될 것이라는 것을 유의하여야 한다. 또한 본 발명은 여기에서 설명되는 실시예에 한정되지 않"}
{"patent_id": "10-2023-0119854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "고 다른 형태로 구체화될 수도 있다. 단지, 여기에서 설명되는 실시예는 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 본 발명의 기술적 사상을 용이하게 실시할 수 있을 정도로 상세히 설명하기 위하여 제공되 는 것이다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"간접적으로 연결\"되어 있는 경우도 포함한다. 여기에서 사용된 용 어는 특정한 실시예들을 설명하기 위한 것이며 본 발명을 한정하기 위한 것이 아니다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. \"X, Y, 및 Z 중 적어도 어느 하나\", 그리고 \"X, Y, 및 Z로 구성된 그룹으로부터 선택된 적어도 어느 하나\"는 X 하나, Y 하나, Z 하나, 또는 X, Y, 및 Z 중 둘 또는 그 이상의 어떤 조합 (예를 들면, XYZ, XYY, YZ, ZZ) 으로 해석될 수 있다. 여기에서, \"및/또는\"은 해 당 구성들 중 하나 또는 그 이상의 모든 조합을 포함한다. 여기에서, 제1, 제2 등과 같은 용어가 다양한 구성 요소들을 설명하기 위해 사용될 수 있지만, 이러한 구성 요 소들은 이러한 용어들에 한정되지 않는다. 이러한 용어들은 하나의 구성 요소를 다른 구성 요소와 구별하기 위 해 사용된다. 따라서, 제1 구성 요소는 여기에 개시된 바를 벗어나지 않는 범위 내에서 제2 구성 요소를 칭할 수 있다. \"아래\", \"위\" 등과 같이 공간적으로 상대적인 용어가 설명의 목적으로 사용될 수 있으며, 그렇게 함으로써 도면 에서 도시된 대로 하나의 소자 또는 특징과 다른 소자(들) 또는 특징(들)과의 관계를 설명한다. 공간적으로 상 대적인 용어는 도면에 묘사된 방향에 더하여, 사용 시, 동작 시, 및/또는 제조 시의 상이한 방향들도 포함하도 록 의도된 것이다. 예를 들면, 도면에 도시된 장치가 뒤집히면, 다른 소자들 또는 특징들의 \"아래\"에 위치하는 것으로 묘사된 소자들은 다른 소자들 또는 특징들의 \"위\"의 방향에 위치한다. 따라서, 일 실시예에서 \"아래\"라 는 용어는 위와 아래의 양 방향을 포함할 수 있다. 뿐만 아니라, 장치는 그 외 다른 방향을 향할 수 있고(예를 들어, 90도 회전된 혹은 다른 방향에서), 이에 따라, 여기에서 사용되는 공간적으로 상대적인 용어들은 그에 따 라 해석된다. 다양한 실시예들이 이상적인 실시예들을 도식화한 도면들을 참조하여 설명된다. 이에 따라, 예를 들면 허용 오 차들 및/또는 제조 기술들에 따라 그 형상들이 변화할 수 있음이 예상될 것이다. 따라서, 여기에 개시된 실시예 들은 도시된 특정 형상들에 한정되는 것으로 해석될 수 없으며, 예를 들면 제조의 결과로 발생하는 형상들의 변 화들을 포함하는 것으로 해석되어야 한다. 이와 같이, 도면들에 도시된 형상들은 장치의 영역들의 실제 형상들 을 도시하지 않을 수 있으며, 본 실시예들은 여기에 한정되지 않는다. 도 1은 본 발명의 실시예들에 따른 합성 비디오 생성 장치를 나타내는 블록도이다. 도 1을 참조하면, 합성 비디오 생성 장치는 전처리부 및 이미지 합성부를 포함할 수 있다. 전처리부는 제1 비디오(VD1) 및 소스 이미지(SI)를 입력받아 제2 비디오(VD2)를 생성하고, 이미지 합성부 는 제2 비디오(VD2) 및 소스 이미지(SI)를 입력받아 제2 합성 비디오(SVD2)를 생성할 수 있다. 본 실시예에서, 이미지 합성부가 제2 합성 비디오(SVD2)를 출력하는 것을 예시하였으나, 본 발명은 이에 한정되지 않는다. 예를 들어, 이미지 합성부는 제1 합성 비디어(SVD1)를 출력할 수 있다. 제1 비디오(VD1) 및 소스 이미지(SI)는 사용자에 의해 입력되는 비디오 및 이미지이다. 비디오는 복수의 프레임 들로 구성되고, 각 프레임은 하나의 이미지로 구성될 수 있다.제2 비디오(VD2)는 소스 이미지(SI)의 객체가 제1 비디오(VD1)의 모션을 모방하는 비디오(예를 들어, 제1 비디 오(VD1)의 모션에 소스 이미지(SI)의 객체를 합성한 비디오)일 수 있다. 여기서, 객체는 사람의 얼굴, 사람의 신체 등이고, 모션은 비디오 내의 객체의 움직임일 수 있다. 도 2 내지 도 8은 객체가 사람의 얼굴인 것을 나타내지만, 본 발명은 객체의 종류에 한정되지 않는다. 본 발명의 다양한 실시예들에서, 전처리부 및 이미지 합성부는 하드웨어, 소프트웨어, 펌웨어 또는 주문형 집적회로(ASIC)의 한 형태로 구현될 수 있다. 이하, 도 2 내지 도 5를 참조하여 구체적으로 설명한다. 도 2는 도 1의 전처리부의 일 예를 나타내는 도면이고, 도 3은 랜드마크를 설명하기 위한 도면이며, 도 4는 랜 드마크들 사이의 각도 및 거리를 설명하기 위한 도면이다. 도 2를 참조하면, 전처리부는 제1 비디오(VD1) 및 소스 이미지(SI)를 기초로 더미 프레임(DF)을 생성하고, 더미 프레임(DF)을 제1 비디오(VD1)에 추가하여 제2 비디오(VD2)를 생성할 수 있다. 전처리부는 특징 추출부 및 더미 프레임 생성부를 포함할 수 있다. 도 2 및 도 3을 참조하면, 특징 추출부는 제1 비디오(VD1)의 프레임들 각각의 제1 랜드마크들을 결정하고, 소스 이미지(SI)의 제2 랜드마크들을 결정할 수 있다. 예를 들어, 객체가 사람의 얼굴인 경우, 랜드마크(LM)는 사람의 얼굴에서 입술 영역, 눈 영역 등을 식별하기 위한 지점을 의미할 수 있다. 예를 들어, 도 3에 나타난 바 와 같이, 객체가 사람의 얼굴인 경우, 랜드마크(LM)는 입술 영역, 눈 영역 등 사람의 얼굴을 복수의 영역으로 나누도록 결정 및 연결될 수 있다. 일 실시예에서, 랜드마크(LM)는 사전에 정의될 수 있다. 일 실시예에서, 랜드마크(LM)는 학습된 모델에 의해 결 정될 수 있다. 특징 추출부는 제1 랜드마크들의 좌표 및 제1 랜드마크들 사이의 연결 관계에 대한 제1 특징 데이터(FD1) 를 생성할 수 있다. 특징 추출부는 제2 랜드마크들의 좌표 및 제2 랜드마크들 사이의 연결 관계에 대한 제 2 특징 데이터(FD2)를 생성할 수 있다. 예를 들어, 제1 및 제2 특징 데이터(FD1, FD2)는 특징 맵 또는 벡터의 형태를 가질 수 있다. 다만, 본 발명은 제1 및 제2 특징 데이터(FD1, FD2)의 형태에 한정되지 않는다. 더미 프레임 생성부는 제1 특징 데이터(FD1) 및 제2 특징 데이터(FD2)를 입력받아 더미 프레임(DF)을 생성 할 수 있다. 일 실시예에서, 더미 프레임 생성부는 제1 비디오(VD1)의 프레임들 중 소스 이미지(SI)와의 유사도가 가장 높은 프레임으로 더미 프레임(DF)을 생성할 수 있다. 일 실시예에서, 더미 프레임 생성부는 제1 랜드마크들(LM1) 및 제2 랜드마크들(LM2)을 기초로 유사도를 결 정할 수 있다. 예를 들어, 상기 유사도는 제1 랜드마크들(즉, 제1 비디오(VD1)에 대한 랜드마크들(LM)) 중 서로 연결된 랜드마크들(LM) 사이의 각도(AG) 및 거리(DI) 및 제2 랜드마크들(즉, 소스 이미지(SI)에 대한 랜드마크 들(LM)) 중 서로 연결된 랜드마크들(LM) 사이의 각도(AG) 및 거리(DI)를 비교하여 결정될 수 있다. 예를 들어, 더미 프레임 생성부는 제1 특징 데이터(FD1)로부터 제1 랜드마크들 중 서로 연결된 랜드마크들 (LM) 사이의 각도(AG) 및 거리(DI)를 계산하고, 계산 결과를 정규화하여 기하학적 특성 데이터를 생성할 수 있 다. 그리고, 더미 프레임 생성부는 제2 특징 데이터(FD2)로부터 제2 랜드마크들 중 서로 연결된 랜드마크 들(LM) 사이의 각도(AG) 및 거리(DI)를 계산하고, 계산 결과를 정규화하여 기하학적 특성 데이터를 생성할 수 있다. 더미 프레임 생성부는 제1 랜드마크들에 대한 기하학적 특성 데이터와 제2 랜드마크들에 대한 기하 학적 특성 데이터를 비교하여 유사도가 가장 높은 프레임을 결정할 수 있다. 전처리부는 더미 프레임(DF)을 제1 비디오(VD1)에 추가하여 제2 비디오(VD2)를 생성할 수 있다. 제2 비디 오(VD2)의 첫 번째 프레임은 더미 프레임(DF)일 수 있다. 따라서, 제2 비디오(VD2)의 첫 번째 프레임의 객체의 상태(예를 들어, 표정, 머리 방향 등)와 소스 이미지(SI) 의 객체의 상태(예를 들어, 표정, 머리 방향 등)가 유사해질 수 있다. 이에 따라, 제1 비디오(VD1)의 모션이 적 절하게 반영되는 합성 비디오가 생성될 수 있다. 도 5는 도 1의 이미지 합성부의 일 예를 나타내는 도면이다. 도 2 및 도 5를 참조하면, 이미지 합성부는 제2 비디오(VD2)의 프레임들의 모션에 소스 이미지(SI)의 객체 를 합성하여 제1 합성 비디오(SVD1)를 생성할 수 있다. 이미지 합성부는 제1 합성 비디오(SVD1)의 프레임들 중 더미 프레임(DF)에 상응하는 프레임을 삭제하여 제2 합성 비디오(SVD2)를 생성할 수 있다. 이미지 합성부는 키포인트 결정부, 합성 비디오 생성부, 및 더미 프레임 제거부를 포함할 수 있다. 키포인트 결정부는 제2 비디오(VD2)의 제1 키포인트들(KP1)을 결정하고, 소스 이미지(SI)의 제2 키포인트 들(KP2)을 결정할 수 있다. 키포인트(KP1, KP2)는 객체의 모션이 반영되는 포인트일 수 있다. 예를 들어, 객체 가 사람의 얼굴인 경우, 키포인트들(KP1, KP2)은 사람의 눈 영역, 코 영역, 귀 영역, 및 입 영역 등을 나타내는 포인트들로 결정될 수 있다. 예를 들어, 객체가 사람의 신체인 경우, 키포인트들(KP1, KP2)은 사람의 팔 영역, 다리 영역, 및 몸통 영역 등을 나타내는 포인트들로 결정될 수 있다. 다만, 본 발명은 키포인트(KP1, KP2)의 위 치에 한정되지 않는다. 일 실시예에서, 키포인트 결정부는 키포인트들(KP1, KP2)을 추출하도록 학습된 인공지능 모델을 통하여 키 포인트들(KP1, KP2)을 결정할 수 있다. 다만, 본 발명은 사용되는 인공지능 모델에 한정되지 않는다. 합성 비디오 생성부는 제1 키포인트들(KP1)의 이동을 제2 키포인트들(KP2)에 반영하여 제1 합성 비디오 (SVD1)를 생성할 수 있다. 예를 들어, 합성 비디오 생성부는 제1 키포인트들(KP1) 각각에 상응하는 제2 키 포인트들(KP2)을 제1 키포인트들(KP1)에 상응하게 이동시켜 제1 합성 비디오(SVD1)의 각 프레임을 생성할 수 있 다. 이에 따라, 제1 합성 비디오(SVD1)는 제2 비디오(VD2)의 모션(즉, 제1 비디오(VD1)의 모션)이 반영된 소스 이미지(SI)의 객체를 나타낼 수 있다. 더미 프레임 제거부는 제1 합성 비디오(SVD1)의 프레임들 중 더미 프레임(DF)에 상응하는 프레임을 삭제하 여 제2 합성 비디오(SVD2)를 생성할 수 있다. 더미 프레임(DF)은 제2 비디오(VD2)의 첫 번째 프레임의 객체의 상태(예를 들어, 표정, 머리 방향 등)와 소스 이미지(SI)의 객체의 상태(예를 들어, 표정, 머리 방향 등)를 일 치시키기 위한 프레임이므로, 더미 프레임 제거부는 더미 프레임(DF)에 상응하는 프레임을 삭제시킬 수 있 다. 도 6은 본 발명의 실시예들에 따른 합성 비디오 생성 장치의 전처리부가 학습되는 것을 나타내는 도면이고, 도 7은 도 6의 제1 인공지능 모델의 일 예를 나타내는 도면이며, 도 8은 도 6의 전처리부가 더미 프레임을 생성하 는 것을 나타내는 도면이다. 본 실시예들에 따른 합성 비디오 생성 장치는 전처리부를 제외하고, 도 1의 합성 비디오 생성 장치의 구성 과 실질적으로 동일하므로, 동일 또는 유사한 구성 요소에 대해서는 동일한 참조 번호 및 참조 기호를 사용하고, 중복되는 설명은 생략한다. 도 6 내지 도 8을 참조하면, 전처리부는 인공지능 모델(320, 330)을 사용하여 더미 프레임(DF)을 생성할 수 있다. 이하, 도 6 및 도 7을 참조하여 학습 단계에서의 전처리부의 동작을 설명한다. 도 6 및 도 7을 참조하면, 전처리부는 특징 추출부를 포함할 수 있다. 특징 추출부는 도 2의 특 징 추출부와 실질적으로 동일하므로, 중복되는 설명은 생략한다. 특징 추출부는 학습 비디오(LVD)의 제1 프레임(F1)의 랜드마크들을 결정하고, 학습 비디오(LVD)의 제2 프 레임(F2)의 랜드 마크들을 결정할 수 있다. 제1 프레임(F1) 및 제2 프레임(F2)은 동일한 비디오(즉, 학습 비디 오(LVD))내에서 임의로 선택될 수 있다. 특징 추출부는 제1 프레임(F1)의 랜드마크들의 좌표 및 제1 프레임(F1)의 랜드마크들 사이의 연결 관계에 대한 제3 특징 데이터(FD3)를 생성할 수 있다. 특징 추출부는 제2 프레임(F2)의 랜드마크들의 좌표 및 제2 프레임(F2)의 랜드마크들 사이의 연결 관계에 대한 제4 특징 데이터(FD4)를 생성할 수 있다. 예를 들어, 제3 및 제4 특징 데이터(FD3, FD4)는 특징 맵 또는 벡터의 형태를 가질 수 있다. 다만, 본 발명은 제3 및 제4 특징 데 이터(FD3, FD4)의 형태에 한정되지 않는다. 인공지능 모델(320, 330)은 학습 비디오(LVD)의 제1 프레임(F1)의 랜드마크들 및 학습 비디오(LVD)의 제2 프레 임(F2)의 랜드마크들을 입력받아 제1 프레임(F1)의 객체의 상태(예를 들어, 표정, 머리 방향 등)를 모방하는 제 2 프레임(F2)의 객체를 포함하는 학습 더미 프레임(LDF)을 생성하도록 학습될 수 있다. 인공지능 모델(320, 330)은 제1 프레임(F1)의 랜드마크들 및 제2 프레임(F2)의 랜드마크들을 입력받아 잠재 벡 터(latent vector; LV)를 생성하는 인코더 및 잠재 벡터(LV)를 입력받아 추론 랜드마크들을 생성하는 디코더를 포함하는 제1 인공지능 모델, 및 추론 랜드마크들 및 제1 프레임(F1)을 입력받아 학습 더미 프 레임(LDF)을 생성하는 제2 인공지능 모델을 포함할 수 있다. 제1 인공지능 모델은 제1 프레임(F1)의 랜드마크들 및 제2 프레임(F2)의 랜드마크들을 입력받아 학습 더미 프레임(LDF)의 랜드마크들(즉, 추론 랜드마크들)을 추론할 수 있다. 제1 인공지능 모델은 추론 랜드마크들 의 좌표 및 추론 랜드마크들 사이의 연결 관계에 대한 제5 특징 데이터(FD5)를 출력할 수 있다. 예를 들어, 제5 특징 데이터(FD5)는 특징 맵 또는 벡터의 형태를 가질 수 있다. 다만, 본 발명은 제5 특징 데이터(FD5)의 형태 에 한정되지 않는다. 제2 인공지능 모델은 잠재 벡터(LV) 및 추론 랜드마크들(즉, 제5 특징 데이터(FD5))를 입력받아 학습 더미 프레임(LDF)을 생성할 수 있다. 제1 프레임(F1) 및 제2 프레임(F2)은 모두 학습 비디오(LVD)에 포함된 프레임이 므로, 제1 프레임(F1) 및 제2 프레임(F2)의 객체가 동일할 수 있다. 따라서, 학습 더미 프레임(LDF)은 이상적으 로 제2 프레임(F2)과 동일할 수 있다. 즉, 인공지능 모델(320, 330)은 학습 더미 프레임(LDF)이 제2 프레임(F 2)과 동일하도록 학습될 수 있다. 일 실시예에서, 인공지능 모델(320, 330)은 제2 프레임(F2)의 랜드마크들과 추론 랜드마크들 사이의 일관성 손 실(consistency loss) 및 제2 프레임(F2)과 학습 더미 프레임(LDF) 사이의 일관성 손실의 합이 감소되도록 학습 될 수 있다. 일 실시예에서, 인공지능 모델(320, 330)은 제2 프레임(F2)의 랜드마크들과 추론 랜드마크들 사이의 일관성 손 실과 제1 가중치의 곱 및 제2 프레임(F2)과 학습 더미 프레임(LDF) 사이의 일관성 손실과 제2 가중치의 곱의 합 이 감소되도록 학습될 수 있다. 제1 가중치 및 제2 가중치는 사용자에 의해 또는 실험적으로 설정될 수 있다. 이하, 도 8을 참조하여 더미 프레임 생성 단계에서의 전처리부의 동작을 설명한다. 도 8을 참조하면, 전처리부는 제1 비디오(VD1)의 프레임들 중 적어도 하나 및 소스 이미지(SI)를 기초로 더미 프레임(DF)을 생성하고, 더미 프레임(DF)은 소스 이미지(SI)의 객체의 상태(예를 들어, 표정, 머리 방향 등)를 모방하는 제1 비디오(VD1)의 상기 프레임들 중 상기 적어도 하나의 객체를 포함할 수 있다. 특징 추출부는 제1 비디오(VD1)의 프레임들 중 적어도 하나의 제1 랜드마크들을 결정하고, 소스 이미지 (SI)의 제2 랜드마크들을 결정할 수 있다. 특징 추출부는 제1 랜드마크들의 좌표 및 제1 랜드마크들 사이의 연결 관계에 대한 제6 특징 데이터(FD6) 를 생성할 수 있다. 특징 추출부는 제2 랜드마크들의 좌표 및 제2 랜드마크들 사이의 연결 관계에 대한 제 7 특징 데이터(FD7)를 생성할 수 있다. 예를 들어, 제6 및 제7 특징 데이터(FD6, FD7)는 특징 맵 또는 벡터의 형태를 가질 수 있다. 다만, 본 발명은 제6 및 제7 특징 데이터(FD6, FD7)의 형태에 한정되지 않는다. 인공지능 모델(320, 330)은 제1 랜드마크들 및 제2 랜드마크들을 기초로 더미 프레임(DF)을 생성할 수 있다. 인 공지능 모델(320, 330)은 제1 랜드마크들 및 제2 랜드마크들을 입력받아 더미 프레임(DF)의 랜드마크들을 추론 하여 추론 랜드마크들을 생성하는 제1 인공지능 모델, 및 추론 랜드마크들 및 제1 비디오(VD1)의 상기 프 레임들 중 상기 적어도 하나를 입력받아 더미 프레임(DF)을 생성하는 제2 인공지능 모델을 포함할 수 있다. 일 실시예에서, 제2 인공지능 모델은 추론 랜드마크들, 잠재 벡터(LV), 및 제1 비디오(VD1)의 상기 프레임들 중 상기 적어도 하나를 입력받아 더미 프레임(DF)을 생성할 수 있다. 제1 인공지능 모델은 제1 랜드마크들 및 제2 랜드마크들을 입력받아 잠재 벡터(LV)를 생성하는 인코더(도 7의 321), 및 잠재 벡터(LV)를 입력받아 추론 랜드마크들을 생성하는 디코더(도 7의 322)를 포함할 수 있다. 도 7은 학습 단계이므로 디코더(도 7의 322)가 제5 특징 데이터(도 7의 FD5)를 출력하는 것으로 나타냈으나, 더미 프레임 생성 단계에서 디코더(도 7의 322)는 제8 특징 데이터(FD8)를 출력할 수 있다. 제1 인공지능 모델은 제1 랜드마크들 및 제2 랜드마크들을 입력받아 더미 프레임(DF)의 랜드마크들(즉, 추 론 랜드마크들)을 추론할 수 있다. 제1 인공지능 모델은 추론 랜드마크들의 좌표 및 추론 랜드마크들 사이 의 연결 관계에 대한 제8 특징 데이터(FD8)를 출력할 수 있다. 예를 들어, 제8 특징 데이터(FD8)는 특징 맵 또 는 벡터의 형태를 가질 수 있다. 다만, 본 발명은 제8 특징 데이터(FD8)의 형태에 한정되지 않는다. 도 9는 제1 비디오 및 소스 이미지의 객체가 사람의 신체인 것을 나타내는 도면이고, 도 10은 제1 비디오의 객 체가 사람의 얼굴이고 소스 이미지의 객체가 사람의 얼굴과 유사한 형태를 갖는 사물인 것을 나타내는 도면이다.도 9를 참조하면, 객체는 사람의 신체일 수 있다. 이 경우, 제1 비디오(VD1)의 사람의 신체의 모션을 모방하는 소스 이미지(SI)의 사람의 신체가 포함되는 제1 합성 비디오(SVD1)(또는, 제2 합성 비디오(SVD2))가 생성될 수 있다. 이 경우, 키포인트들은 사람의 팔 영역, 다리 영역, 및 몸통 영역 등을 나타내는 포인트들로 결정될 수 있다. 도 1 및 도 10을 참조하면, 제1 비디오(VD1)의 객체는 사람의 얼굴이고, 소스 이미지(SI)의 객체는 사람의 얼굴 과 유사한 형태를 갖는 사물일 수 있다. 예를 들어, 소스 이미지(SI)의 객체는 눈, 코, 입과 같은 형태를 갖는 사물일 수 있다. 이와 같이, 제1 비디오(VD1) 및 소스 이미지(SI)의 객체는 사람이여야 하는 것은 아니고, 제1 비디오(VD1) 및 소스 이미지(SI)의 객체가 반드시 동일하여야 하는 것은 아니다. 다만, 본 발명의 객체는 사람의 얼굴, 사람의 신체, 및 사람의 얼굴과 유사한 형태를 갖는 사물에 한정되지 않 는다. 도 11은 본 발명의 실시예들에 따른 합성 비디오 생성 방법을 나타내는 순서도이다. 도 11을 참조하면, 도 11의 합성 비디오 생성 방법은 제1 비디오 및 소스 이미지를 기초로 더미 프레임을 생성 (S100)하고, 더미 프레임을 제1 비디오에 추가하여 제2 비디오를 생성(S200)하며, 제2 비디오의 프레임들의 모 션에 소스 이미지의 객체를 합성하여 제1 합성 비디오를 생성(S300)할 수 있다. 도 11의 합성 비디오 생성 방법은 도 1 내지 도 10을 참조하여 설명한 합성 비디오 생성 장치를 통하여 구현될 수 있다. 도 12는 합성 비디오를 생성하는 합성 비디오 생성 시스템을 나타내는 블록도이다. 도 12를 참조하면, 합성 비디오 생성 시스템은 도 1 내지 도 10을 참조하여 설명한 합성 비디오 생성 장 치와 실질적으로 동일한 방법으로 합성 비디오를 생성할 수 있다. 합성 비디오 생성 시스템은 서버와, 네트워크를 통해 서버와 연결되는 복수의 단말기 들(2300, 2400)을 포함할 수 있다. 서버는 합성 비디오 생성 서비스를 제공하기 위한 모델(즉, 합성 비디오 생성 모델)이 저장될 수 있다. 예를 들어, 서버는 합성 비디오 생성 서비스를 제공하는 컴퓨터 장치일 수 있다. 예를 들어, 각 단말기 (2300, 2400)는 합성 비디오 생성 모델을 서버로부터 다운로드 할 수 있다. 이 경우, 서버는 합성 비디오 생성 모델이 저장되는 메모리를 포함할 수 있다. 일 실시예에서, 서버는 합성 비디오 생성 장치일 수 있다. 예를 들어, 서버는 단말기들(2300, 2400)로부터 비디오 및 이미지를 제공받고, 단말기들(2300, 2400)에 합성 비디오를 제공할 수 있다. 일 실시예에서, 각 단말기(2300, 2400)는 합성 비디오 생성 장치일 수 있다. 예를 들어, 각 단말기(2300, 240 0)는 서버와의 통신이 필요없을 수 있다. 합성 비디오 생성 장치는 합성 비디오 생성 모델을 포함하는 전자 장치일 수 있다. 네트워크는 서버와 다른 단말기들(2300, 2400)과의 연결을 가능하게 하는 구성일 수 있다. 네트워 크는 인터넷 등을 이용한 온라인 네트워크, 오프라인 회선 등을 통한 오프라인 네트워크 등을 포함할 수 있다. 복수의 단말기들(2300, 2400)은 합성 비디오 생성 서비스의 사용자 단말기의 형태로 제공될 수 있다. 복수의 단 말기들(2300, 2400)은 네트워크를 통해 서버와 연결될 수 있으면 족하며, 그 종류가 제한되지 않는 다. 예를 들어, 단말기는 휴대폰, 스마트폰, 태블릿, 노트북 등을 포함하는 이동식 전자 장치일 수 있고, 데스 크톱을 포함하는 고정식 전자 장치일 수 있다. 그러나, 본 개시의 실시예들이 이에 제한되는 것은 아니다. 도 13은 도 12의 서버의 일 예를 나타내는 블록도이다. 도 13을 참조하면, 본 개시의 실시예들에 따른 서버는 프로세서, 시스템 메모리, 전원 , 저장 매체, 저장 매체 인터페이스 및 버스 등을 포함할 수 있다. 서버는 일례로, 하나 이상의 컴퓨터 장치를 포함할 수 있다. 서버는 일례로, 네트워크(도 12의 2200)와 온라인 및/또는 오프 라인으로 연결될 수 있다. 프로세서는 범용 혹은 전용 프로세서 중 어느 하나일 수 있다. 프로세서는 서버의 제반 동작 들을 제어할 수 있다. 프로세서는 실행될 때 다양한 기능들을 제공하는 프로그램 코드들 및 명령어들을 시스템 메모리에 로딩하고, 로딩된 프로그램 코드들 및 명령어들을 처리하도록 구성된다. 시스템 메모리는 프로세서의 워킹 메모리 및/또는 버퍼 메모리로서 제공될 수 있다. 실시 예로서, 시스템 메모리는 램(RAM: Random Access Memory), 롬(ROM: Read Only Memory), 및 다른 타입의 컴퓨터에 의해 판독 가능한 매체 중 적어도 하나를 포함할 수 있다. 시스템 메모리에는 운영 체제가 저장될 수 있다. 프로세서는 합성 비디오 생성 모델을 시스템 메모리에 로딩할 수 있다. 프로그램 코드들 및/또는 명령어들은 서버에 의해 판독 가능한 기록 매체인 저장 매체로부터 시 스템 메모리에 로딩될 수 있다. 또는, 프로그램 코드들 및/또는 명령어들은 서버의 외부로부터 통 신기(미도시)를 통해 시스템 메모리에 로드될 수도 있다. 프로세서는 운영 체제를 실행할 수 있다. 예를 들어, 프로세서는 합성 비디오 생성 모델 이 실행되기에 적합한 환경을 제공하기 위한 운영 체제를 시스템 메모리에 로딩하고, 로딩된 합성 비디오 생성 모델을 실행할 수 있다. 운영 체제는, 합성 비디오 생성 모델 등이 서버의 저장 매체 인터페이스와 같은 구성 요소들을 이용할 수 있도록 인터페이싱할 수 있다. 본 개시의 실시예들에서, 저장 매체 인터페이스의 적어도 일부 기능은 운영 체제에 의해 수행될 수 있다. 시스템 메모리는 프로세서와 구분된 구성으로 도시되어 있으나, 시스템 메모리의 적어도 일 부는 프로세서에 포함될 수도 있다. 시스템 메모리는 실시 예들에 따라 물리적 및/또는 논리적으로 서로 분리된 복수의 메모리들로서 제공될 수 있다. 전원은 프로세서, 시스템 메모리, 저장 매체 및 저장 매체 인터페이스 중 하나 이상의 구성 요소가 구동하기 위한 전압을 제공할 수 있다. 저장 매체는 데이터를 저장하기 위해 구성된다. 저장 매체는 전원이 차단되더라도 저장된 데이터 를 유지하는 다양한 타입들의 비휘발성 저장 매체들을 포함할 수 있다. 비휘발성 저장 매체들은, 일례로, 비휘 발성 메모리(non-volatile memory)를 포함할 수 있다. 비휘발성 메모리는 일례로, 플래시 메모리(flash memory), 하드 디스크(hard disk) 등을 포함할 수 있다. 저장 매체 인터페이스는 저장 매체에 연결된다. 저장 매체 인터페이스는 버스에 연결 된 프로세서 및 시스템 메모리와 같은 구성 요소들과 저장 매체 사이를 인터페이싱할 수 있 다. 버스는 서버의 다양한 구성 요소들에 연결되어 데이터, 신호, 및 정보를 전달할 수 있다. 도 14는 도 12의 단말기가 합성 비디오 생성 모델을 실행하는 일 예를 나타내는 도면이다. 도 1 및 도 14를 참조하면, 단말기(2300, 2400)는 사용자로부터 제1 비디오(VD1)를 입력받을 수 있다. 예를 들 어, 사용자는 합성 비디오 생성 모델에 기저장된 비디오들 중 하나를 제1 비디오(VD1)로 선택하거나, 제1 비디 오(VD1)를 직접 촬영하거나, 저장된 비디오를 제1 비디오(VD1)로서 업로드할 수 있다. 단말기(2300, 2400)는 사용자에 의해 선택, 촬영, 또는 업로드된 제1 비디오(VD1)를 다시 한 번 사용자에게 확 인시킬 수 있다. 그리고, 사용자는 제1 비디오(VD1)를 다른 비디오로 수정할 수 있다. 단말기(2300, 2400)는 제1 비디오(VD1)가 결정되면 사용자에게 소스 이미지(SI)를 입력받을 수 있다. 예를 들어, 사용자는 소스 이미지(SI)를 직접 촬영하거나, 저장된 이미지를 소스 이미지(SI)로서 업로드할 수 있다. 단말기(2300, 2400)는 사용자에 의해 촬영 또는 업로드된 소스 이미지(SI)를 다시 한 번 사용자에게 확인시킬 수 있다. 그리고, 사용자는 소스 이미지(SI)를 다른 이미지로 수정할 수 있다. 사용자는 단말기(2300, 2400)에 제1 비디오(VD1)와 소스 이미지(SI)를 합성할 것을 명령할 수 있다. 단말기 (2300, 2400)는 제1 비디오(VD1)와 소스 이미지(SI)가 합성된 제2 합성 비디오(SVD2)를 사용자에게 제공할 수 있다. 사용자는 제2 합성 비디오(SVD2)를 저장하거나, 다양한 플랫폼, 단말기 등에 공유할 수 있다.비록 특정 실시 예들 및 적용 례들이 여기에 설명되었으나, 이는 본 발명의 보다 전반적인 이해를 돕기 위해서 제공된 것일 뿐, 본 발명은 상기의 실시예에 한정되는 것은 아니며 본 발명이 속하는 분야에서 통상적인 지식을 가진 자라면 이러한 기재로부터 다양한 수정들 및 변형들이 가능하다. 따라서, 본 발명의 사상은 설명된 실시예에 국한되어 정해져서는 아니되며, 후술하는 특허청구범위뿐 아니라 이 특허청구범위와 균등하거나 등가적 변형이 있는 모든 것들은 본 발명 사상의 범주에 속한다고 할 것이다."}
{"patent_id": "10-2023-0119854", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예들에 따른 합성 비디오 생성 장치를 나타내는 블록도이다. 도 2는 도 1의 전처리부의 일 예를 나타내는 도면이다. 도 3은 랜드마크를 설명하기 위한 도면이다. 도 4는 랜드마크들 사이의 각도 및 거리를 설명하기 위한 도면이다. 도 5는 도 1의 이미지 합성부의 일 예를 나타내는 도면이다. 도 6은 본 발명의 실시예들에 따른 합성 비디오 생성 장치의 전처리부가 학습되는 것을 나타내는 도면이다. 도 7은 도 6의 제1 인공지능 모델의 일 예를 나타내는 도면이다. 도 8은 도 6의 전처리부가 더미 프레임을 생성하는 것을 나타내는 도면이다. 도 9는 제1 비디오 및 소스 이미지의 객체가 사람의 신체인 것을 나타내는 도면이다. 도 10은 제1 비디오의 객체가 사람의 얼굴이고 소스 이미지의 객체가 사람의 얼굴과 유사한 형태를 갖는 사물인 것을 나타내는 도면이다.도 11은 본 발명의 실시예들에 따른 합성 비디오 생성 방법을 나타내는 순서도이다. 도 12는 합성 비디오를 생성하는 합성 비디오 생성 시스템을 나타내는 블록도이다. 도 13은 도 12의 서버의 일 예를 나타내는 블록도이다. 도 14는 도 12의 단말기가 합성 비디오 생성 모델을 실행하는 일 예를 나타내는 도면이다."}
