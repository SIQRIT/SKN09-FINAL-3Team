{"patent_id": "10-2021-0192602", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0102450", "출원번호": "10-2021-0192602", "발명의 명칭": "딥러닝에 효과적인 SIMT 구조를 갖는 GPU", "출원인": "서경대학교 산학협력단", "발명자": "이광엽"}}
{"patent_id": "10-2021-0192602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "4개의 쓰레드를 동시에 처리하고 관리하는 크기 4를 갖는 warp와,제1뱅크, 제2뱅크, 제3뱅크 및 제4뱅크로 이루어진 레지스터 뱅크를 가지며 딥러닝에 효과적인 SIMT 구조를 갖는 GPU."}
{"patent_id": "10-2021-0192602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 레지스터 뱅크 및상기 각 뱅크(제1뱅크, 제2뱅크, 제3뱅크 및 제4뱅크)와 다자간(multi-to-multi) 인터페이스 구조로 연결되는네 개의 스트림 프로세서(SP, Stream Process)를 포함하는 스트리밍 멀티 프로세서(SM, StreamingMultiprocessor)를 구비하는 것을 특징으로 하는 딥러닝에 효과적인 SIMT 구조를 갖는 GPU."}
{"patent_id": "10-2021-0192602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 각각의 스트림 프로세서는 4x4 kernel의 하나의 행과 입력 데이터의 각 행의 직렬연산 컨볼루션(convolution)을 동시에 수행하는 것을 특징으로 하는 딥러닝에 효과적인 SIMT 구조를 갖는 GPU."}
{"patent_id": "10-2021-0192602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 각각의 스트림 프로세서의 직렬연산 컨볼루션 결과가 각 뱅크에 저장되는 것을 특징으로 하는 딥러닝에 효과적인 SIMT 구조를 갖는 GPU."}
{"patent_id": "10-2021-0192602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,라운드로빈 방식으로 운영되는 warp scheduler를 더 포함하는 것을 특징으로 하는 딥러닝에 효과적인 SIMT 구조를 갖는 GPU."}
{"patent_id": "10-2021-0192602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서, 메모리 지연 발생 쓰레드를 대개열에 대기시키고, 메모리 지연 없는 쓰레드를 먼저 처리하는 딥러닝에 효과적인SIMT 구조를 갖는 GPU."}
{"patent_id": "10-2021-0192602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2023-0102450-3-제1 warp 스케쥴러, 제2 warp 스케쥴러, 제3 warp 스케쥴러 및 제4 warp 스케쥴러와,상기 각 warp 스케쥴러에 연결되어 명령어를 페치(fetch)하는 네 개의 명령어 페치(intruction fetch)와,상기 각 warp 스케쥴러(제1 warp 스케쥴러, 제2 warp 스케쥴러, 제3 warp 스케쥴러 및 제4 warp 스케쥴러)와 각각 연결되는 제1 디코더, 제2 디코더, 제3디코더 및 제4 디코더 및- 제1 warp 스케쥴러는 제1 디코더와 연결되며, 제2 warp 스케쥴러는 제2 디코더와 연결되며, 제3 warp 스케쥴러는 제3 디코더와 연결되며, 제4 warp 스케쥴러는 제4 디코더와 연결됨 - 상기 복수 개 디코더와 다자간(multi-to-multi) 인터페이스 구조로 연결되는 네 개의 스트리밍 멀티 프로세서(제1SM, 제2SM, 제3SM, 제4SM)를 포함하고,상기 각 스트리밍 멀티 프로세서는제1뱅크, 제2뱅크, 제3뱅크 및 제4뱅크로 이루어진 레지스터 뱅크와,상기 각 뱅크(제1뱅크, 제2뱅크, 제3뱅크 및 제4뱅크)와 다자간(multi-to-multi) 인터페이스 구조로 연결되는네 개의 스트림 프로세서(SP, Stream Process)를 포함하는 것을 특징으로 하는 딥러닝에 효과적인 SIMT 구조를 갖는 GPU."}
{"patent_id": "10-2021-0192602", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 딥러닝에 효과적인 SIMT 구조를 갖는 GPU에 관한 것이다. 본 발명에서는 4개의 쓰레드를 동시에 처리하고 관리하는 크기 4를 갖는 warp와, 제1뱅크, 제2뱅크, 제3뱅크 및 제4뱅크로 이루어진 레지스터 뱅크를 가지며 딥러닝에 효과적인 SIMT 구조를 갖는 GPU가 개시된다. 본 발명에서 제안하는 데이터 재사용과 메모리 접근 지연시간을 줄이는 SIMT GPU는 convolution 연산에 효율적인 구조로 설계되어 있어 일반적인 GPU보다 크게 성능을 개선할 수 있다."}
{"patent_id": "10-2021-0192602", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥러닝에 효과적인 SIMT 구조를 갖는 GPU에 관한 것으로서, 보다 구체적으로는 하나의 커널을 입력데 이터와 컨볼루션을 수행할 때 메모리로부터 커널 및 입력데이터를 페치한 이후에 내부 레지스터에서 컨볼루션 연산이 수행되는 딥러닝에 효과적인 SIMT 구조를 갖는 GPU에 관한 것이다."}
{"patent_id": "10-2021-0192602", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "Multi-thread는 Multi-core를 사용하여 공유자원의 갯수를 늘리게 되면 자원의 효율을 최대로 사용하며 thread 와 thread의 전환에 필요한 지연시간이 없기 때문에 속도를 빠르게 할 수 있다. GPU는 기존의 데이터 병렬처리 개념인 SIMD(Single Instruction Multiple Data)에 Multi-thread의 장점을 활용 한 SIMT(Single Instruction Multiple Thread) 기술을 사용한다. 도 1은 SIMD와 SIMT의 차이를 설명하는 설명 도이다. GPU의 SIMT는 명령어별로 각각 별도의 데이터를 사용하기 때문에 병렬처리에서 SIMD에 비하여 더욱 성 능을 개선할 수 있다. SIMT구조 GPU에서 Multi-thread를 관리하기 위해 Warp Scheduler를 두게 된다. Warp Scheduler는 Instruction Cache, Instruction Fetch, Stream Processor 사이에서 thread간의 자원충돌을 회피하기 위해 중재 (arbitration) 역할을 하게 된다. GPU에서 처리할 데이터가 메모리로부터 전달되는데 소요되는 시간이 메모리 지연시간이다. GPU와 같이 SIMT구조 에서는 다수의 쓰레드(Multi-thread)가 메모리를 공유하는 구조(shared-memory architecture)이기 때문에 각 쓰레드들이 동시에 메모리에 있는 데이터를 필요로 할 때 충돌로 인하여 GPU 성능이 크게 감소하는 문제가 발생 한다. 메모리 접근(access) 충돌은 각 쓰레드가 메모리 접근시 자기 순서가 될 때까지 동작이 정지(stall)하여 메모리 접근 지연시간 증가로 인한 메모리 명령어 실행 성능이 크게 감소된다. 이 문제를 해결하기 위해 GPU와 메모리 사이에 캐시(cache) 메모리를 두어 빠르게 메모리 접근하여 정지(stal l)시간을 최소화하고 있지만 메모리 지연시간은 여전히 존재한다. 멀티 쓰레드 구조에서는 긴 메모리 지연시간 이 발생할 때 쓰레드 교체하는 방법으로 대응하게 된다. 합성곱이라고 하는 convolution 연산은 이미지에서 특징을 추출하는데 널리 사용되는 kernel 연산 방법이다. 도 2에 도시된 바와 같이 입력 이미지에 kernel를 적용하여 픽셀별로 곱을 한 후 모두 합을 하면 한 개의 출력을 만드는 elementwise-sum 연산이 반복된다. 한 번의 convolution 연산이 완료되면 kernel를 stride만큼 우측으 로 이동하여 다음 convolution 연산을 수행하고 또 하나의 출력값을 만들게 된다. 이와같이 stride수 만큼 반복 적으로 우측으로 이동하면서 출력값을 하나씩 만들어내며 kernel이 입력 이미지의 오른쪽 가장자리에 도달하면kernel은 stride 만큼 아래줄(row) 맨 왼쪽으로 이동하고 다시 오른쪽으로 이동하면서 convolution 연산이 진행 되고 입력 이미지 전체에 대해 연산이 끝나면 입력 이미지 한 장(frame)에 대한 convolution이 완료되고 출력 이미지 한 장의 출력값도 만들어지게 된다. 인공지능 기술의 하나인 딥러닝(Deep Learning)은 신경망(Neural Network) 구조의 특성상 많은 수의 노드 (Node)가 병렬 연산이 가능하여 다량의 쓰레드를 병렬로 처리할 때 GPU가 CPU보다 더욱 높은 성능을 나타내기 때문에 딥러닝 처리에 GPU가 널리 사용된다. 그러나, GPU는 다량의 하드웨어 코어(core)를 갖고 쓰레드를 병렬 처리하기 때문에 하드웨어의 크기가 크고 소모되는 전력(power)이 커서 발열(heat)의 문제가 크기 때문에 배터 리로 동작해야 하는 모바일 제품에서 사용이 매우 제한적이다. 모바일 제품에서 요구되는 작은 크기의 하드웨어와 저 소비전력에서 딥러닝을 고성능으로 동작시키는 GPU는 메 모리 접근(access) 횟수를 최소화 해야 한다. 메모리 접근시 가장 많은 전력이 소비되면서 지연시간 발생으로 성능이 낮아지기 때문이다. 선행기술문헌 비특허문헌 (비특허문헌 0001) 1. Gwang Bok Kim, Jong Myon Kim, Cheol Hong Kim, \"Latency Hiding based Warp Scheduling Policy for High Performance GPUs.\" Journal of The Society of Computer and Information, Vol.24, No. 4, pp.1-9, April 2019. (비특허문헌 0002) 2. Cheal Won Jo, Kwang Yeob Lee, Chi Yong Kim, \"Low-area DNN Core using data reuse technique.\" J.inst.Korean.electr.electron.eng, Vol.25, No.1, pp.229-233, March 2021. (비특허문헌 0003) 3. Kwang Yeob Lee, \"Design of a High-Performance Mobile GPGPU with SIMT Architecture based on a Small-size Warp Scheduler.\" J.inst.Korean. electr.electron.eng, Vol.25, No.3, pp.479-484, September 2021."}
{"patent_id": "10-2021-0192602", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하고자 하는 것으로서, 모바일 환경에서도 사용할 수 있는 작은 크기의 하 드웨어와 저 소비전력에서 딥러닝을 고성능으로 동작시키는 딥러닝에 효과적인 SIMT 구조를 갖는 GPU를 제시하 는 것을 목적으로 한다."}
{"patent_id": "10-2021-0192602", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 상기 목적은 4개의 쓰레드를 동시에 처리하고 관리하는 크기 4를 갖는 warp와, 제1뱅크, 제2뱅크, 제 3뱅크 및 제4뱅크로 이루어진 레지스터 뱅크를 가지며 SIMT 방식으로 쓰레드를 처리하는 GPU에 의해서 달성 가 능하다. 레지스터 뱅크 및 각 뱅크(제1뱅크, 제2뱅크, 제3뱅크 및 제4뱅크)와 다자간(multi-to-multi) 인터페이스 구조 로 연결되는 네 개의 스트림 프로세서(SP, Stream Process)를 포함하는 스트리밍 멀티 프로세서(SM, Streaming Multiprocessor)를 구비하는 것이 좋다. 각각의 스트림 프로세서는 4x4 kernel의 하나의 행과 입력 데이터의 각 행의 직렬연산 컨볼루션(convolution)을 동시에 수행하도록 구현하였다. 4x4 커널을 사용하고 각 스트림 프로세서에서는 커널의 한 행과 입력데이터를 직렬연산 컨볼루션 수행하고 각 뱅크에 저장함으로써 컨볼루션 수행시 내부 레지스터를 이용하여 수행할 수 있게 되었다. 메모리 지연 시간을 숨기는 기술(latency hiding)을 위해 라운드로빈 방식으로 운영되는 warp scheduler를 더 포함하도록 구현하였으며, 메모리 latency hiding을 위해 지연 발생 쓰레드를 대개열에 대기시키고, 메모리 지연 없는 쓰레드를 먼저 처리하도록 구현하였다. 본 발명의 상기 목적은 제1 warp 스케쥴러, 제2 warp 스케쥴러, 제3 warp 스케쥴러 및 제4 warp 스케쥴러와, 각 warp 스케쥴러에 연결되어 명령어를 페치(fetch)하는 네 개의 명령어 페치(intruction fetch)와, 각 warp 스케 쥴러(제1 warp 스케쥴러, 제2 warp 스케쥴러, 제3 warp 스케쥴러 및 제4 warp 스케쥴러)와 각각 연결되는 제1 디코더, 제2 디코더, 제3디코더 및 제4 디코더 및 - 제1 warp 스케쥴러는 제1 디코더와 연결되며, 제2 warp 스 케쥴러는 제2 디코더와 연결되며, 제3 warp 스케쥴러는 제3 디코더와 연결되며, 제4 warp 스케쥴러는 제4 디코 더와 연결됨 - 복수 개 디코더와 다자간(multi-to-multi) 인터페이스 구조로 연결되는 네 개의 스트리밍 멀티 프로세서(제1SM, 제2SM, 제3SM, 제4SM)를 포함하고, 각 스트리밍 멀티 프로세서는 제1뱅크, 제2뱅크, 제3뱅크 및 제4뱅크로 이루어진 레지스터 뱅크와, 상기 각 뱅크(제1뱅크, 제2뱅크, 제3뱅크 및 제4뱅크)와 다자간 (multi-to-multi) 인터페이스 구조로 연결되는 네 개의 스트림 프로세서(SP, Stream Process)를 포함하는 것을 특징으로 하는 SIMT 방식으로 쓰레드를 처리하는 GPU에 의해서도 달성 가능하다."}
{"patent_id": "10-2021-0192602", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "딥러닝을 이용하여 인공지능을 구현하는데 합성곱 신경망(CNN : Convolution Neural Network)이 가장 널리 사용 되고 있다. 합성곱 신경망은 여러 종류의 신경망으로 구성되지만 convolution 계층이 가장 많은 연산 시간 및 메모리 사용량이 가장 크기 때문에 전체 성능의 대부분을 차지한다. 본 발명에서 제안하는 데이터 재사용과 메 모리 접근 지연시간을 줄이는 SIMT GPU는 convolution 연산에 효율적인 구조로 설계되어 있어 일반적인 GPU보다 크게 성능을 개선할 수 있게 되었다. 최근 딥러닝은 server computer 위주의 활용에서 edge형 단말기에서 활용되는 사례가 크게 증가하고 있다. 특히, 모바일 단말기 기술이 발전하면서 대부분의 모바일 기기에서 딥러닝을 기반으로 하는 기능이 필수적이 되 어가고 있다. 모바일 기기의 핵심은 긴 시간의 배터리 사용이 필요하며 이를 위해서는 딥러닝을 처리하는 GPU (또는 CPU)에서 소비 전력을 최소화 하는 것이 필수적인 기술이다. 본 발명은 적은 규모 warp과 레지스터를 이 용한 데이터 재사용, 메모리 지연시간 최소화 등의 기술은 전력 소비를 가장 많이 낮출 수 있는 기술로써 모바 일 기기에서 딥러닝을 구현하는데 효용성이 매우 높일 수 있게 되었다."}
{"patent_id": "10-2021-0192602", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에서 사용하는 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서,\"포함하다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들 을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요 소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 또한, 본 명세서에서, \"~ 상에 또는 ~ 상부에\" 라 함은 대상 부분의 위 또는 아래에 위치함을 의미하는 것이며, 반드시 중력 방향을 기준으로 상 측에 위치하는 것을 의미하는 것은 아니다. 또한, 영역, 판 등의 부분이 다른 부분 \"상에 또는 상부에\" 있다고 할 때, 이는 다른 부분 \"바로 상에 또는 상부에\" 접촉하여 있거나 간격을 두고 있는 경우뿐 아니라 그 중간에 또 다른 부분이 있는 경우도 포함한다. 또한, 본 명세서에서, 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것이다. 또한, 본 명세서에서, 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하 는 목적으로만 사용된다. 딥러닝을 GPU에서 실행할 때 메모리 접근 횟수를 낮추는 방법은 데이터의 재사용(reuse)이다. 딥러닝의 convolution layer에서 convolution 연산에 사용되는 입력 특징맵(input feature map)과 커널(kernel)값을 내 부 레지스터에 두고 재사용 함으로써 메모리에 접근하는 횟수를 줄이는 방법이 필요하다. convolution연산은 GPU에서 쓰레드 단위로 이루어지기 때문에 GPU가 데이터 재사용에 효과적으로 대응할 수 있 도록 쓰레드 관리가 이루어져야 한다. 또한, 입력 특징맵이나 커널값을 교체할 때는 메모리에 접근해야 하는데 이때 메모리 지연시간이 발생하여 쓰레드의 병렬실행에 성능 저하가 있기 때문에 이 문제를 해결하는 방안이 필 요하다. 딥러닝의 convolution 연산을 구성하는 kernel 값과 입력 데이터 값, 그리고 연산의 결과 값을 GPU 내부 레지스 터 저장함으로써 convolution 연산이 종료될 때 까지 GPU 외부 메모리 접근을 하지 않도록 warp 크기, 레지스터 구조, 직렬 convolution 연산 방법을 개선한다. GPU는 SIMT 구조로 되어 있어 thread 단위의 병렬처리를 하게 되고 thread를 관리하기 위한 묶음 단위를 warp으 로 하며 warp당 관리하고 동시에 처리할 수 있는 tread의 갯수를 warp 크기로 한다. 이때, warp 크기를 결정할 때 딥러닝 convolution을 실행할 때 데이터 재사용 효율을 최대화 할 수 있도록 kernel의 크기를 최대 4x4(4행, 4열)로 정한다. 4x4로 정하여도 1x1, 2x2, 3x3, 4x4 의 크기를 지원하여 유연성을 높인다. 딥러닝 convolution은 GPU 명령어로 실행되며 명령어들은 thread 단위로 병렬 실행되는데 명령어는 데이터를 캐 시메모리로부터 레지스터로 옮겨와서 사용한다. 캐시메모리로부터 옮겨진 데이터를 레지스터에서 convolution 연산이 종료될 때까지 재사용한다. 이때, 병렬 실행하는 thread의 한 묶음인 4이기 때문에 레지스터 구조도 이 와 동일하게 4개의 뱅크로 구성하면 4x4 kernel의 데이터 재사용을 효과적으로 지원한다. 딥러닝에서는 많은 양의 kernel과 연속되는 입력 데이터를 사용하기 때문에 kernel과 입력 데이터는 자주 교체 가 된다. 따라서, 레지스터 내의 데이터 재사용에도 한계가 있기 때문에 kernel과 입력 데이터 교체시 메모리 접근이 불가피하다. 딥러닝의 convolution 연산을 고성능으로 유지하기 위해서는 레지스터 기반의 데이터 재사 용 이외에 메모리 접근 지연시간을 최소화 하는 메모리 latency hiding 기술이 적용되어야 한다. 메모리 접근시 지연시간이 발생하는 thread는 대기 시키고 지연 발생이 없는 thread로 순서를 대체하는 방법이 필요하다. 딥러닝 convolution 연산을 GPU 내부 레지스터를 이용하여 최대한 데이터 재사용을 하기 위해 직렬연산(serial operation)을 적용한다. 직렬연산은 도 4와 같이 입력 데이터와 kernel을 한 행(row)씩 convolution 연산을 수 행하며 한 행의 연산은 한 warp의 한 줄의 thread들에 할당한다. Kernel의 빨간색 row는 입력 데이터의 빨간색 부분과 한 행씩 연산을 하게 되며 이 부분은 빨간색으로 표시된 warp에 할당된다. Kernel의 파란색 row는 입력 데이터의 파란색 부분과 한 행씩 연산을 하며 파란색 warp에 할당한다. 이 방법으로 4줄의 kernel을 차례대로warp에 할당함으로써 warp마다 갖고 있는 레지스터를 이용하여 행단위로 convolution을 하게 되면 kernel 데이 터와 입력 데이터를 메모리 접근없이 레지스터 내부에서 재사용이 된다. 위와 같은 kernel과 입력 데이터의 행단위 직렬 convolution 연산을 위해서는 kernel의 크기를 도 4와 같이 4x4(row 4개, column 4개) 크기로 고정한다. 딥러닝 convolution에서 kernel 크기는 다양할 수 있지만 주로 3x3과 4x4를 사용하기 때문에 4x4로 고정해도 3x3과 4x4에 모두 위와 같은 방법을 적용할 수 있어 대부분의 딥 러닝 convolution 연산의 데이터 재사용 방법에 적용이 가능하다. SIMT구조 GPU에서 Multi-thread를 관리하기 위해 도 5와 같이 Warp Scheduler를 두게 된다. Warp Scheduler는 Instruction Cache, Instruction Fetch, Stream Processor 사이에서 thread간의 자원충돌을 회피하기 위해 중 재(arbitration) 역할을 하게 된다. Warp Scheduler는 Host CPU로부터 warp mask, thread mask 정보를 받아 어떤 warp이 활성화 되었는지 확인하고 활성화된 warp은 명령어 페치를 위한 PC(Program Counter)주소를 전달하고 이 주소는 명령어 캐시로 전달되어 실행 명령어를 페치 하게 된다. 이때, warp scheduler는 여러 개의 thread를 묶음으로 하기 때문에 warp단위 활성화를 찾게 된다. Nvidia사의 GPGPU에서는 Fermi, Kepler 구조 모두 Threads/ Warp =32로 설계되어 있다. 본 발명에서는 Threads/ Warp=4로 설계하여 딥러닝 convolution의 데이터 재사용을 위한 4x4 kernel 크기를 지 원하도록 하였다. 한 개의 warp이 한 개 kernel의 convolution을 할당 받게 되어 warp에 배정된 레지스터 내에 서 데이터 재사용 기법으로 convolution 연산이 가능하게 하였다. 도 5에서 GPU는 SM(Streaming Multiprocessor, 스트리밍 멀티 프로세서)은 네 개를 가진다. SM 내의 SP(Stream Processor, 스트림 프로세서)를 네 개를 가지며, SP들은 동시에 수행된다. GPU는 총 256개의 쓰레드를 처리할 수 있도록 설계했다. GPU는 각 SM에서 64개의 쓰레드를 처리해야 하며, SP에서는 총 16개의 쓰레드를 처리해야 한다. 디코더에서 발행된 명령어는 하나의 SM에 전달된 뒤 다음 사이클에 다음 SM에 전달되며, 다음 사이클에 그 다음 SM에 전달되도록 설계했다. 예를 들어 t0에 시간에서 디코딩된 명령어 #0가 SM #0에 전달되면, t1에서는 명령어 #0이 SM #1에 전달되고, 명령어 #1은 SM #0에 전달된다. IF(Instrcution Fetch)는 명령어를 명령어 캐시로부터 가져와 디코더로 보내는 역할로, 하나의 IF가 늘어남에 따라 16개의 쓰레드가 증가하도록 설계했다. 네 개의 IF와 하나의 스케줄러를 묶어 하나의 WG(Warp Group)이라 는 모듈로 부른다. 딥러닝 convolution 연산에서 kernel과 입력 데이터의 재사용을 위해 행(row) 단위로 직렬연산이 warp의 한 개 SP에 할당된다. kernel의 각 행은 각각의 SP에 한 개씩 할당된 후 warp 단위의 병렬 연산을 하게 된다. 4x4 kernel은 4개의 행을 갖고 있기 때문에 4개의 warp에서 kernel 4개 행의 연산이 동시에 처리된다. 그런 후 이 값들은 모두 합산을 해야 1개 kernel의 convolution 연산이 완료된다. 따라서, 레지스터에 저장되어 있는 4개 행의 연산결과를 모두 합하기 위해서 레지스터를 네 개의 뱅크로 나누었다. 본 발명에서는 도 6에 도시된 바와 같이 레지스터를 네 개 뱅크(Register #0, #1, #2, #3)로 나누고 각 뱅크를 4개 warp에서 공유하게 된다. 예를 들어 kernel 4개 행의 convolution 연산을 병렬연산하기 위해서 첫 번째 행은 SP#0, 두 번째 행은 SP#1, 세 번 째 행은 SP#2, 네 번째 행은 SP#3에 할당되고 SP#0, SP#1, SP#2, SP#3은 모두 Register #0 뱅크를 사용하고 동 일한 명령어(IF#0)를 사용한다. 이와 같이 kernel 4개 행 연산이 끝난 후 합산을 할 때는 Register #1 뱅크를 사용하되 합산에 필요한 데이터는 Register #0의 데이터를 사용하기 때문에 딥러닝 convolution 연산이 레지스 터 내부에서 데이터 재사용이 가능하다. 도 7과 같이 레지스터 뱅크와 convolution 연산을 수행하는 SP가 다자 간 인터페이스 구조로 구성되어 있어 뱅크와 SP는 어떤 것이든 선택할 수 있다. 딥러닝 convolution은 kernel과 입력 데이터를 한 행(row)과 한 열(column)단위로 연산하기 때문에 연속된 데이 터의 연속된 연산이기 때문에 warp에서 thread를 교체하는 warp scheduling 방법이 convolution의 데이터 재사용에 적합해야 한다. Warp 기반의 Multi-threading에서는 여러 개의 warp이 동시에 명령어 요청을 하게 되고 warp scheduler는 그중 하나를 선택하여 명령어 페치 유닛에 전달하게 되는데 본 발명에서는 활성화된 warp들을 라운드 로빈(Round Robin)방식으로 선택한다. 라운드 로빈 방식을 채택한 이유는 어느 한쪽의 warp만 연속해서 수행하게 될 때 해당 warp에 포함된 thread간에 dependency가 존재할 때 stream processor 내부 pipeline stall에 의한 idle cycle이 발생한다. 이에 대한 해결방안은 도 8과 같이 idle 발생이 감지되면 해당 warp은 비 활성화 되고 warp scheduler는 라운드 로빈 방식으로 다음 활성 warp으로 명령어 페치 권한을 넘기게 된다. 딥러닝 convolution 연산에서 GPU 내부 레지스터를 사용한 데이터 재사용 방법을 적용하더라도 kernel이나 입력 데이터를 교체하기 위해서는 메모리 접근이 필요하다. 메모리 접근 명령어가 처리될 때 캐시 miss시 stream processor의 pipeline stall이 발생하며 이때 miss penalty를 처리하기 위한 cycle수는 경우에 따라 수백 cycle이 될 수 있다. 본 발명에서는 이러한 문제를 작은 크기의 warp scheduling으로 도 9와 같이 해결하였다. 한 warp의 쓰레드 중 캐시 miss가 발생하면 데이터가 hit 될 때까지 그 warp은 대기열에 대기하고 다음 warp 의 메모리 요청을 처리한다. 대기열에는 아직 thread의 miss가 처리되지 않은 warp들이 대기하고 있다. 다른 warp의 명령어를 처리하는 중에 대기하고 있는 warp들을 라운드로빈 방식으로 해당 warp의 thread가 hit 되었는 지 검사한다. Thread의 miss가 모두 처리된 warp은 write back 모듈로 보내진다. 한 Warp에서 Miss가 발생해도 다음 Warp의 명령어를 처리하므로 파이프라인이 정지되지 않고 연속해서 수행될 수 있다. 또한, 긴 싸이클을 소 모하는 메모리 접근 지연 시간을 숨길 수 있다. 본 발명에서 제시하는 바와 같은 작은 크기 warp를 사용하는 대 신 큰 크기의 warp을 사용하는 경우 miss시 대기시간이 길어져 memory latency를 숨기지 못하는 경우가 발생하 여 전체적으로 GPU의 성능 저하를 막지 못하게 된다. 실험 결과 1. 본 발명 GPU의 부동소수점 연산능력(FLOPS) 측정 딥러닝 convolution 연산은 kernel값과 입력 데이터를 이용하는데 이 값들은 부동소수점(floating point) 형식 으로 되어 있어 GPU에서는 부동소수점 연산 방법으로 convolution을 처리 해야 한다. 본 발명에서는 warp의 크 기가 4인 작은 크기의 warp을 이용하여 딥러닝 연산에 필요한 부동소수점 연산 능력을 갖추고 있으며 능력 측정 은 다음과 같이 진행하였다. 부동소수점 연산능력은 부동소수점(Floating Point Operation)만으로 구성된 프로 그램 실행 시 단위 시간(sec)당 수행되는 부동소수점명령어의 연산 Operation 수를 측정하며 파이프라인 클럭 사이클 당 연산 Operation수에 실행 주파수를 곱하여 얻는다. 테스트 프로그램은 thread 번호(thread identification : tid)를 초기 주소값으로 받아 Buffer메모리에 있는 값을 ‘1’씩 증가 하는 과정을 반복하는 부동소수점 덧셈능력 측정과 Buffer메모리에 있는 값을 ‘3.0’씩 곱셈 하는 과정을 반복하는 부동소수점 곱셈능력을 측정했다. 측정 결과 분석은 다음 순서와 같으며 최종 결과 는 8GFlops의 성능을 얻었다. - Outputs result of an addition(fadd, faddi) or a multiplication (fmul, fmuli ) per clock cycle (Applied pipeline structure) - One core of GPGPU consists of 16 ALUs, and 16 ALUs per clock cycle are simultaneously calculated and output. - When a GPGPU core is operated in 500 MHz clock, the floating point addition calculation amount for 1 second. = 16(ALU) x 500MHz(the number of clock cycle per second) = 8G Flops 2. 딥러닝에 직렬구조의 convolution 방법을 적용하였을 때 종래 직렬방식 convolution 연산에 필요한 연산 횟 수와 본 발명의 GPU구조에서 convolution연산에 필요한 연산 횟수를 비교하였다. 종래 방식에서는 도 10과 같이 kernel의 행(row)으로 입력 데이터에 convolution을 진행한 후 kernel의 열(column)로 중간 출력 특징맵 (output feature map)에 convolution 연산을 하는 방법으로 28x28 크기의 입력 데이터에 4x4 크기 kernel을 적 용하였을 때 100,352번 연산횟수가 소요된다. 본 발명의 방식에서는 도 11과 같이 4x4 kernel과 입력 데이터를한 개의 warp에서 병렬 convolution 연산을 수행한 후 한 장의 중간 출력 특징맵에 1x1 convolution을 수행하여 종래 방식과 같은 출력을 나타내는데 25,088번 연산횟수를 사용하여 종래 방식에 비하여 약 4배의 성능 개선을 보였다. 상기에서 본 발명의 바람직한 실시예가 특정 용어들을 사용하여 설명 및 도시되었지만 그러한 용어는 오로지 본 발명을 명확히 설명하기 위한 것일 뿐이며, 본 발명의 실시예 및 기술된 용어는 다음의 청구범위의 기술적 사상 및 범위로부터 이탈되지 않고서 여러가지 변경 및 변화가 가해질 수 있는 것은 자명한 일이다. 이와 같이 변형 된 실시예들은 본 발명의 사상 및 범위로부터 개별적으로 이해되어져서는 안되며, 본 발명의 청구범위 안에 속 한다고 해야 할 것이다."}
{"patent_id": "10-2021-0192602", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 SIMD와 본 발명의 SIMT 구조 비교 설명도. 도 2는 딥러닝 convolution의 연산 방식(Image가 입력 데이터, Filter가 kernel에 해당). 도 3은 딥러닝에서 4x4 kernel을 이용한 convolution 연산 과정 개념도. 도 4는 본 발명에서 제안하는 kernel과 입력 데이터의 직렬 convolution 연산을 할당된 warp에서 병렬처리하는 과정 도 5는 본 발명의 GPU구조로 한 개의 warp이 관리하는 SM속에 SP 4개를 갖고 있어 warp의 크기가 4 임을 나타냄 도 6은 레지스터 뱅크별로 warp을 구성하는 SP 4개가 할당된 구조 도 7은 레지스터 뱅크와 SP가 다대다(many-to-many) 연결구조로 데이터 재사용 지원 구조 도 8은 warp scheduling방법으로 사용하고 있는 Round-Robin구조 도 9는 Memory latency hiding 방법 도 10은 기존 방식의 직렬 convolution 연산 과정 도 11은 본 발명에서 제안하는 직렬 convolution 연산 과정"}
