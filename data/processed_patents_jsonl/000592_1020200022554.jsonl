{"patent_id": "10-2020-0022554", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0107480", "출원번호": "10-2020-0022554", "발명의 명칭": "전자장치 및 그 제어방법", "출원인": "삼성전자주식회사", "발명자": "박별"}}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자장치에 있어서, 인터페이스부;디스플레이; 및상기 인터페이스부를 통해 복수의 채널 중 어느 한 채널의 방송신호를 수신하고, 상기 수신된 방송신호에 기초하여 컨텐츠의 영상을 상기 디스플레이에 표시하고, 상기 컨텐츠의 타입에 대응하여 정의된 비디오 특성의 변화에 기초하여 상기 컨텐츠가 제1컨텐츠에서 상기 제1컨텐츠와 타입이 다른 제2컨텐츠로 전환되는 시점을 식별하고, 상기 식별된 시점에 기초하여 상기 제2컨텐츠에 관한 동작을 수행하는 프로세서를 포함하는 전자장치."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 프로세서는, 상기 컨텐츠의 타입에 대응하여 정의된 상기 표시된 영상의 RGB 특성의 변화에 기초하여 상기비디오 특성의 변화를 식별하는 전자장치."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 프로세서는, 상기 표시된 영상 내의 대상에 관한 인식을 통해 상기 비디오 특성을 식별하는 전자장치."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 영상 내의 대상은, 인물, 로고, 브랜드, 또는 제목 중 적어도 하나를 포함하는 전자장치."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 프로세서는, 상기 컨텐츠의 사운드를 스피커를 통해 출력하고, 상기 컨텐츠의 타입에 대응하여 정의된 상기 사운드 특성의 변화에 기초하여 상기 전환되는 시점을 식별하는 전자장치."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 프로세서는, 상기 출력되는 사운드를 수신하는 마이크를 통하여 수신되는 피드백 사운드에 기초하여 상기사운드 특성을 식별하는 전자장치."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 공개특허 10-2021-0107480-3-상기 식별되는 사운드 특성은, 상기 사운드의 타입 또는 크기 중 적어도 하나를 포함하는 전자장치."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 프로세서는, 상기 제1컨텐츠에서 상기 제2컨텐츠로의 비디오 특성의 변화에 대한 학습을 통하여 얻어지며상기 컨텐츠의 타입 별로 그룹화된 정보에 기초하여 동작을 수행하는 전자장치."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 프로세서는, 상기 전환되는 시점에 관한 정보를 저장하고, 상기 전환되는 시점과 다른 시점에 상기 제1컨텐츠에서 상기 제2컨텐츠로 전환되는 것으로 식별되면, 상기 저장된 정보를 상기 다른 시점에 관한 정보로 업데이트 하는 전자장치."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 프로세서는, 상기 전환되는 시점에 관한 정보에 기초하여 상기 전환되는 시점을 포함하는 시간 구간 동안상기 컨텐츠의 비디오 특성의 변화를 식별하는 전자장치."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 프로세서는, 상기 전환되는 시점과 다른 시점에 상기 제1컨텐츠에서 상기 제2컨텐츠로 전환되는 것으로 식별되면, 상기 시간 구간이 상기 다른 시점을 포함하도록 조정하는 전자장치."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서, 상기 프로세서는, 상기 시점에 전환된 제2컨텐츠에 대한 사용자의 시청 시간에 기초하여 상기 제2컨텐츠에 대한사용자 선호 여부를 식별하는 전자장치."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 프로세서는, 상기 시청 시간에 기초하여 식별된 상기 제2컨텐츠에 대한 사용자 선호 여부에 따라 상기 컨텐츠의 타입 별로 그룹화된 정보를 획득하는 전자장치."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서, 상기 프로세서는, 상기 식별된 제2컨텐츠에 대한 사용자 선호 여부에 기초하여, 상기 전환되는 시점 이후 상기제2컨텐츠와 다른 제3컨텐츠의 영상을 표시하는 전자장치."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "전자장치의 제어방법에 있어서, 복수의 채널 중 어느 한 채널의 방송신호를 수신하는 단계;상기 수신된 방송신호에 기초하여 컨텐츠의 영상을 표시하는 단계; 상기 컨텐츠의 타입에 대응하여 정의된 비디오 특성의 변화에 기초하여 상기 컨텐츠가 제1컨텐츠에서 상기 제1공개특허 10-2021-0107480-4-컨텐츠와 타입이 다른 제2컨텐츠로 전환되는 시점을 식별하는 단계; 및상기 식별된 시점에 기초하여 상기 제2컨텐츠에 관한 동작을 수행하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 제2컨텐츠로 전환되는 시점을 식별하는 단계는, 상기 컨텐츠의 타입에 대응하여 정의된 상기 표시된 영상의 RGB 특성의 변화에 기초하여 상기 비디오 특성의 변화를 식별하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서, 상기 제2컨텐츠로 전환되는 시점을 식별하는 단계는, 상기 표시된 영상 내의 대상에 관한 인식을 통해 상기 비디오 특성을 식별하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 영상 내의 대상은, 인물, 로고, 브랜드, 또는 제목 중 적어도 하나를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항에 있어서, 상기 컨텐츠의 사운드를 출력하는 단계를 더 포함하고, 상기 제2컨텐츠로 전환되는 시점을 식별하는 단계는, 상기 컨텐츠의 타입에 대응하여 정의된 상기 사운드 특성의 변화에 기초하여 상기 전환되는 시점을 식별하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0022554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨터가 읽을 수 있는 코드로서, 전자장치의 제어방법을 수행하는 코드를 포함하는 컴퓨터 프로그램이 저장된기록매체에 있어서, 상기 전자장치의 제어방법은, 복수의 채널 중 어느 한 채널의 방송신호를 수신하는 단계;상기 수신된 방송신호에 기초하여 컨텐츠의 영상을 표시하는 단계; 상기 컨텐츠의 타입에 대응하여 정의된 비디오 특성의 변화에 기초하여 상기 컨텐츠가 제1컨텐츠에서 상기 제1컨텐츠와 타입이 다른 제2컨텐츠로 전환되는 시점을 식별하는 단계; 및상기 식별된 시점에 기초하여 상기 제2컨텐츠에 관한 동작을 수행하는 단계를 포함하는 것을 특징으로 하는 컴퓨터가 읽을 수 있는 프로그램이 기록된 기록매체."}
{"patent_id": "10-2020-0022554", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 전자장치에 관한 것으로서, 전자장치는 복수의 채널 중 어느 한 채널의 방송신호를 수신하고, 수신된 방송신호에 기초하여 컨텐츠의 영상을 표시하고, 컨텐츠의 타입에 대응하여 정의된 비디오 특성의 변화에 기초하 여 컨텐츠가 제1컨텐츠에서 제1컨텐츠와 타입이 다른 제2컨텐츠로 전환되는 시점을 식별하고, 식별된 시점에 기 초하여 제2컨텐츠에 관한 동작을 수행할 수 있다."}
{"patent_id": "10-2020-0022554", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 전자장치 및 그 제어방법에 관한 것으로서, 상세하게는, 컨텐츠 간의 전환 시점을 식별하는 전자장치 및 그 제어방법에 관한 것이다."}
{"patent_id": "10-2020-0022554", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "TV 방송국과 같은 컨텐츠 제공장치(Content Provider)는 광고주로부터 거두는 소정의 광고료를 통해 운영되기 마련이다. 방송 프로그램 전후에 삽입되는, 전후 광고에 대해서는 수 천만원에 이르는 광고료가 책정되어 있고, 방송 프로그램 중간에 삽입되는 중간 광고에 대해서는 전후 광고보다 비싼 광고료가 책정되어 있으므로, 컨텐츠 제공장치는 광고료를 통해 상당한 수익 개선을 이루고 있다. 이와 같이 방송 프로그램에 광고를 삽입하는 것이 수익 측면에서 컨텐츠 제공장치에게 유리하나, 반대로, 사용 자 입장에서는 원하는 방송 프로그램을 시청하기 위해 자신의 선호와 무관하게 삽입된 광고를 시청해야 하기 때 문에, 방송 프로그램을 시청하기도 전에 불편함 또는 불쾌감을 느낄 수밖에 없는 상황에 있다. 따라서, TV에 표시되는 광고에 대한 사용자의 선호를 파악하고, 사용자의 선호에 따른 광고를 제공함으로써, 사 용자에게 최적화된 컨텐츠 서비스를 제공할 필요성이 대두되고 있다."}
{"patent_id": "10-2020-0022554", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은, 컨텐츠 간의 전환 시점을 정확하게 식별함으로써, 전환 시점에 기반하여 식별된 컨텐츠에 대 한 사용자의 선호 여부에 따라 최적화된 컨텐츠 서비스를 제공할 수 있는 전자장치 및 그 제어방법을 제공하는 것이다."}
{"patent_id": "10-2020-0022554", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 본 발명의 목적은, 인터페이스부; 디스플레이; 및 상기 인터페이스부를 통해 복수의 채널 중 어느 한 채 널의 방송신호를 수신하고, 상기 수신된 방송신호에 기초하여 컨텐츠의 영상을 상기 디스플레이에 표시하고, 상 기 컨텐츠의 타입에 대응하여 정의된 비디오 특성의 변화에 기초하여 상기 컨텐츠가 제1컨텐츠에서 상기 제1컨 텐츠와 타입이 다른 제2컨텐츠로 전환되는 시점을 식별하고, 상기 식별된 시점에 기초하여 상기 제2컨텐츠에 관 한 동작을 수행하는 프로세서를 포함하는 전자장치에 의해 달성될 수 있다. 상기 프로세서는, 상기 컨텐츠의 타입에 대응하여 정의된 상기 표시된 영상의 RGB 특성의 변화에 기초하여 상기 비디오 특성의 변화를 식별할 수 있다. 상기 프로세서는, 상기 표시된 영상 내의 대상에 관한 인식을 통해 상기 비디오 특성을 식별할 수 있다. 상기 영상 내의 대상은, 인물, 로고, 브랜드, 또는 제목 중 적어도 하나를 포함할 수 있다. 상기 프로세서는, 상기 컨텐츠의 사운드를 스피커를 통해 출력하고, 상기 컨텐츠의 타입에 대응하여 정의된 상 기 사운드 특성의 변화에 기초하여 상기 전환되는 시점을 식별할 수 있다. 상기 프로세서는, 상기 출력되는 사운드를 수신하는 마이크를 통하여 수신되는 피드백 사운드에 기초하여 상기 사운드 특성을 식별할 수 있다. 상기 식별되는 사운드 특성은, 상기 사운드의 타입 또는 크기 중 적어도 하나를 포함할 수 있다. 상기 프로세서는, 상기 제1컨텐츠에서 상기 제2컨텐츠로의 비디오 특성의 변화에 대한 학습을 통하여 얻어지며 상기 컨텐츠의 타입 별로 그룹화된 정보에 기초하여 동작을 수행할 수 있다. 상기 프로세서는, 상기 전환되는 시점에 관한 정보를 저장하고, 상기 전환되는 시점과 다른 시점에 상기 제1컨 텐츠에서 상기 제2컨텐츠로 전환되는 것으로 식별되면, 상기 저장된 정보를 상기 다른 시점에 관한 정보로 업데 이트 할 수 있다. 상기 프로세서는, 상기 전환되는 시점에 관한 정보에 기초하여 상기 전환되는 시점을 포함하는 시간 구간 동안 상기 컨텐츠의 비디오 특성의 변화를 식별할 수 있다. 상기 프로세서는, 상기 전환되는 시점과 다른 시점에 상기 제1컨텐츠에서 상기 제2컨텐츠로 전환되는 것으로 식 별되면, 상기 시간 구간이 상기 다른 시점을 포함하도록 조정할 수 있다. 상기 프로세서는, 상기 시점에 전환된 제2컨텐츠에 대한 사용자의 시청 시간에 기초하여 상기 제2컨텐츠에 대한 사용자 선호 여부를 식별할 수 있다. 상기 프로세서는, 상기 시청 시간에 기초하여 식별된 상기 제2컨텐츠에 대한 사용자 선호 여부에 따라 상기 컨 텐츠의 타입 별로 그룹화된 정보를 획득할 수 있다. 상기 프로세서는, 상기 식별된 제2컨텐츠에 대한 사용자 선호 여부에 기초하여, 상기 전환되는 시점 이후 상기 제2컨텐츠와 다른 제3컨텐츠의 영상을 표시할 수 있다. 상기한 본 발명의 목적은, 복수의 채널 중 어느 한 채널의 방송신호를 수신하는 단계; 상기 수신된 방송신호에 기초하여 컨텐츠의 영상을 표시하는 단계; 상기 컨텐츠의 타입에 대응하여 정의된 비디오 특성의 변화에 기초하 여 상기 컨텐츠가 제1컨텐츠에서 상기 제1컨텐츠와 타입이 다른 제2컨텐츠로 전환되는 시점을 식별하는 단계; 및 상기 식별된 시점에 기초하여 상기 제2컨텐츠에 관한 동작을 수행하는 단계를 포함하는 전자장치의 제어방법 에 의해서도 달성될 수 있다. 상기 제2컨텐츠로 전환되는 시점을 식별하는 단계는, 상기 컨텐츠의 타입에 대응하여 정의된 상기 표시된 영상 의 RGB 특성의 변화에 기초하여 상기 비디오 특성의 변화를 식별하는 단계를 포함할 수 있다. 상기 제2컨텐츠로 전환되는 시점을 식별하는 단계는, 상기 표시된 영상 내의 대상에 관한 인식을 통해 상기 비 디오 특성을 식별하는 단계를 포함할 수 있다. 상기 영상 내의 대상은, 인물, 로고, 브랜드, 또는 제목 중 적어도 하나를 포함할 수 있다. 상기 컨텐츠의 사운드를 출력하는 단계를 더 포함하고, 상기 제2컨텐츠로 전환되는 시점을 식별하는 단계는, 상 기 컨텐츠의 타입에 대응하여 정의된 상기 사운드 특성의 변화에 기초하여 상기 전환되는 시점을 식별하는 단계 를 포함할 수 있다. 상기한 본 발명의 목적은, 컴퓨터가 읽을 수 있는 코드로서, 전자장치의 제어방법을 수행하는 코드를 포함하는 컴퓨터 프로그램이 저장된 기록매체에 있어서, 복수의 채널 중 어느 한 채널의 방송신호를 수신하는 단계; 상기 수신된 방송신호에 기초하여 컨텐츠의 영상을 표시하는 단계; 상기 컨텐츠의 타입에 대응하여 정의된 비디오 특 성의 변화에 기초하여 상기 컨텐츠가 제1컨텐츠에서 상기 제1컨텐츠와 타입이 다른 제2컨텐츠로 전환되는 시점 을 식별하는 단계; 및 상기 식별된 시점에 기초하여 상기 제2컨텐츠에 관한 동작을 수행하는 단계를 포함하는 것을 특징으로 하는 컴퓨터가 읽을 수 있는 프로그램이 기록된 기록매체에 의해서도 달성될 수 있다."}
{"patent_id": "10-2020-0022554", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 컨텐츠 간의 전환 시점을 정확하게 식별함으로써, 전환 시점에 기반하여 식별된 컨텐츠에 대 한 사용자의 선호 여부에 따라 최적화된 컨텐츠 서비스를 제공할 수 있는 전자장치 및 그 제어방법을 제공하는 것이다."}
{"patent_id": "10-2020-0022554", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부도면을 참조하여 본 발명에 따른 실시예들에 관해 상세히 설명한다. 이하 실시예들의 설명에서 는 첨부된 도면들에 기재된 사항들을 참조하는 바, 각 도면에서 제시된 동일한 참조번호 또는 부호는 실질적으 로 동일한 동작을 수행하는 구성요소를 나타낸다. 본 명세서에서의 복수의 구성 중 적어도 하나(at least one) 는, 복수의 구성 전부뿐만 아니라, 복수의 구성 중 나머지를 배제한 각 하나 혹은 이들의 조합 모두를 지칭한다. 도 1은 본 발명의 일 실시예에 따른 전자장치를 도시한다. 도 1에 도시된 바와 같이, 전자장치는 디스플레이 를 포함할 수 있다. 전자장치는 컨텐츠의 비디오신호에 기초하여 디스플레이를 통해 컨텐츠의 영상 을 표시할 수 있다. 전자장치는 TV, 스마트폰, 태블릿, 휴대용 미디어 플레이어, 웨어러블 디바이스, 비디오 월, 전자액자 등과 같이 영상표시장치뿐만 아니라, 디스플레이를 구비하지 않는 셋탑박스 등의 비디오처리 장치, 냉장고, 세탁기 등의 생활가전, 컴퓨터본체와 같은 정보처리장치 등 다양한 종류의 장치로 구현될 수 있 다. 전자장치가 디스플레이를 구비하지 않는 경우, 컨텐츠의 비디오신호를 외부 TV로 전송할 수 있다. 또한, 전자장치는 인공지능 기능을 탑재한 인공지능 스피커, 인공지능 로봇 등으로 구현될 수 있다. 다만, 전자장치의 종류는 이에 한정되는 것은 아니지만, 이하에서는 설명의 편의를 위해 전자장치가 TV로 구현 되는 경우를 가정한다. 전자장치는 컨텐츠 제공장치로부터 컨텐츠의 비디오신호를 수신할 수 있다. 컨텐츠 제공장치는 지상파, 케이 블, 위성파 등에 기반하여 컨텐츠를 제공하는 방송국을 포함할 수 있다. 이 경우, 전자장치는 방송국으로부 터 복수의 채널 중 어느 한 채널의 방송신호를 수신할 수 있다. 컨텐츠 제공장치는 방송국에 한정되는 것은 아 니므로, 인터넷 등을 이용하여 디지털화된 정보를 제공하는, 포털 사이트(Portal Site), 이동통신사, 컨텐츠 제공 서버, 컨텐츠 플랫폼 등을 포함할 수 있다. 다만 이하에서는 설명의 편의를 위해 전자장치가 방송국으 로부터 컨텐츠의 방송신호를 수신하는 경우를 가정한다. 전자장치는 다양한 타입의 컨텐츠를 표시할 수 있다. 전자장치는 방송국으로부터 수신되는 방송신호에 기 초하여 뉴스, 시사토론, 다큐멘터리, 드라마, 코미디, 가요, 영화, 스포츠 등과 같은 프로그램의 영상을 표시할 수 있다. 전자장치는 방송국으로부터 제1컨텐츠 및 제3컨텐츠에 대한 방송신호를 수신하고, 도 1에 도시된 바와 같이, 순차적으로 제1컨텐츠 및 제3컨텐츠의 영상을 표시할 수 있다. 제1컨텐츠 및 제3컨텐츠는 EPG(Electronic Program Guide)에 기초하여 식별된 방송순서에 따라 표시될 수 있다. 또한, 전자장치는 방송국으로부터 수신되는 방송신호에 기초하여 광고의 영상을 표시할 수 있다. 광고는 프 로그램 전후에 삽입되는 전후 광고와, 하나의 프로그램 중간에 삽입되는 중간 광고를 포함할 수 있다. 일 예로, 도 1에 도시된 바와 같이, 제2컨텐츠는 방송 순서에 따라 제1컨텐츠에서 후속하는 제3컨텐츠로 방송되는 중에 삽입되어 표시될 수 있다. 이러한 제2컨텐츠에 대해서는 EPG가 제공되지 않을 수 있다. 도 2는 도 1의 전자장치에 관한 구성의 일 예를 도시한다. 이하에서는 도 2를 참조하여, 전자장치의 구성에 관해 자세히 설명한다. 본 실시예서는 전자장치가 TV인 경우에 관해 설명하지만, 전자장치는 다양한 종류 의 장치로 구현될 수 있으므로, 본 실시예가 전자장치의 구성을 한정하는 것은 아니다. 전자장치가 TV와 같은 디스플레이장치로 구현되지 않는 경우도 가능하며, 이 경우의 전자장치는 디스플레이와 같은 영상 표시를 위한 구성요소들을 포함하지 않을 수 있다. 예를 들면 전자장치가 셋탑박스로 구현되는 경우에, 전자 장치는 인터페이스부를 통해 외부의 TV에 비디오신호를 출력할 수 있다. 전자장치는 인터페이스부를 포함한다. 인터페이스부는 유선 인터페이스부를 포함할 수 있다. 유 선 인터페이스부는 지상파, 위성 방송 등 방송규격에 따른 방송신호를 수신할 수 있는 안테나가 연결되거나, 케이블 방송 규격에 따른 방송신호를 수신할 수 있는 케이블이 연결될 수 있는 커넥터 또는 포트를 포함한다. 다른 예로서, 전자장치는 방송신호를 수신할 수 있는 안테나를 내장할 수도 있다. 유선 인터페이 스부는 HDMI 포트, DisplayPort, DVI 포트, 썬더볼트, 컴포지트(Composite) 비디오, 컴포넌트(Component) 비디오, 슈퍼 비디오(Super Video), SCART 등과 같이, 비디오 및/또는 오디오 전송규격에 따른 커넥터 또는 포 트 등을 포함할 수 있다. 유선 인터페이스부는 USB 포트 등과 같은 범용 데이터 전송규격에 따른 커넥터 또 는 포트 등을 포함할 수 있다. 유선 인터페이스부는 광 전송규격에 따라 광케이블이 연결될 수 있는 커넥터 또는 포트 등을 포함할 수 있다. 유선 인터페이스부는 외부 마이크 또는 마이크를 구비한 외부 오디오기기가 연결되며, 오디오기기로부터 오디오신호를 수신 또는 입력할 수 있는 커넥터 또는 포트 등을 포함할 수 있다. 유선 인터페이스부는 헤드셋, 이어폰, 외부 스피커 등과 같은 오디오기기가 연결되며, 오디오기기로 오디오신호를 전송 또는 출력할 수 있는 커넥터 또는 포트 등을 포함할 수 있다. 유선 인터페이스부는 이더 넷 등과 같은 네트워크 전송규격에 따른 커넥터 또는 포트를 포함할 수 있다. 예컨대, 유선 인터페이스부는 라우터 또는 게이트웨이에 유선 접속된 랜카드 등으로 구현될 수 있다. 유선 인터페이스부는 상기 커넥터 또는 포트를 통해 셋탑박스, 광학미디어 재생장치와 같은 외부기기, 또는 외부 디스플레이장치나, 스피커, 서버 등과 1:1 또는 1:N(N은 자연수) 방식으로 유선 접속됨으로써, 해당 외부 기기로부터 비디오 및 오디오신호를 수신하거나 또는 해당 외부기기에 비디오 및 오디오신호를 송신한다. 유선 인터페이스부는, 비디오 및 오디오신호를 각각 별개로 전송하는 커넥터 또는 포트를 포함할 수도 있다. 그리고, 본 실시예에 따르면 유선 인터페이스부는 전자장치에 내장되나, 동글(Dongle) 또는 모듈 (Module) 형태로 구현되어 전자장치의 커넥터에 착탈될 수도 있다. 인터페이스부는 무선 인터페이스부를 포함할 수 있다. 무선 인터페이스부는 전자장치의 구현 형 태에 대응하여 다양한 방식으로 구현될 수 있다. 예를 들면, 무선 인터페이스부는 통신방식으로 RF(Radio Frequency), 지그비(Zigbee), 블루투스(Bluetooth), 와이파이(Wi-Fi), UWB(Ultra-Wide Band) 및 NFC(Near Field Communication) 등 무선통신을 사용할 수 있다. 무선 인터페이스부는 와이파이 방식에 따라서 AP와 무선통신을 수행하는 무선통신모듈이나, 블루투스 등과 같은 1대 1 다이렉트 무선통신을 수행하는 무선통신모듈 등으로 구현될 수 있다. 무선 인터페이스부는 네트워크 상의 서버와 무선 통신함으로써, 적어도 하나의 서 버와의 사이에 데이터 패킷을 송수신할 수 있다. 무선 인터페이스부는 적외선 통신규격에 따라 IR(Infrared) 신호를 송신 및/또는 수신할 수 있는 IR송신부 및/또는 IR수신부를 포함할 수 있다. 무선 인터페 이스부는 IR송신부 및/또는 IR수신부를 통해 리모컨 또는 다른 외부기기로부터 리모컨신호를 수신 또는 입력하거나, 리모컨 또는 다른 외부기기로 리모컨신호를 전송 또는 출력할 수 있다. 다른 예로서, 전자장치 는 와이파이, 블루투스 등 다른 방식의 무선 인터페이스부를 통해 리모컨 또는 다른 외부기기와 리모 컨신호를 송수신할 수 있다. 전자장치는 인터페이스부를 통해 수신하는 비디오 및 오디오신호가 방송신호인 경우, 수신된 방송신호를 채널 별로 튜닝하는 튜너(Tuner)를 더 포함할 수 있다. 전자장치는 디스플레이를 포함한다. 디스플레이는 화면 상에 영상을 표시할 수 있는 디스플레이 패 널을 포함한다. 디스플레이 패널은 액정 방식과 같은 수광 구조 또는 OLED 방식과 같은 자발광 구조로 마련된다. 디스플레이는 디스플레이 패널의 구조에 따라서 부가적인 구성을 추가로 포함할 수 있는데, 예를 들면, 디스플레이 패널이 액정 방식이라면, 디스플레이는 액정 디스플레이 패널과, 광을 공급하는 백라이트 유닛과, 액정 디스플레이 패널의 액정을 구동시키는 패널구동기판을 포함한다. 다만, 디스플레이는 전자장 치가 셋탑박스 등으로 구현되는 경우 생략될 수 있다. 전자장치는 사용자입력부를 포함한다. 사용자입력부는 사용자의 입력을 수행하기 위해 사용자가 조 작할 수 있도록 마련된 다양한 종류의 입력 인터페이스 관련 회로를 포함한다. 사용자입력부는 전자장치 의 종류에 따라서 여러 가지 형태의 구성이 가능하며, 예를 들면 전자장치의 기계적 또는 전자적 버튼부, 터치패드, 디스플레이에 설치된 터치스크린 등이 있다. 전자장치는 저장부를 포함한다. 저장부는 디지털화된 데이터를 저장한다. 저장부는 전원의 제공 유무와 무관하게 데이터를 보존할 수 있는 비휘발성 속성의 스토리지(storage)와, 프로세서에 의해 처리되기 위한 데이터가 로딩되며 전원이 제공되지 않으면 데이터를 보존할 수 없는 휘발성 속성의 메모리(memory)를 포 함한다. 스토리지에는 플래시메모리(flash-memory), HDD(hard-disc drive), SSD(solid-state drive) ROM(Read Only Memory) 등이 있으며, 메모리에는 버퍼(buffer), 램(RAM; Random Access Memory) 등이 있다. 전자장치는 마이크를 포함한다. 마이크는 사용자로부터의 발화 음성, 주변환경의 소음, 소리 등 다 양한 종류의 사운드를 수신할 수 있다. 또한, 마이크는 스피커로부터 출력되는 사운드를 수신할 수 있 다. 마이크는 수신되는 사운드의 신호를 프로세서로 전달할 수 있다. 마이크는 전자장치의 본체에 설치된 내장 마이크로 구현될 수 있다. 또한, 마이크는 전자장치의 외부에 마련된 외장 마이크로 구현될 수 있다. 외장 마이크는 독립적 장치 또는 다른 전자장치의 구성일 수 있 다. 일 예로, 외장 마이크는 전자장치의 본체와 분리된 리모컨, 스마트폰 등에 설치될 수 있다. 이 경우, 리모컨, 스마트폰 등에 마련된 외장 마이크를 통해 수집된 사운드의 신호는 디지털화 되어 인터페이스부를 통해 수신될 수 있다. 전자장치는 스피커를 포함한다. 스피커는 오디오신호에 기초하여 사운드를 출력할 수 있다. 일 예로, 스피커는 방송국으로부터 수신되는 컨텐츠의 오디오신호에 기초하여 컨텐츠의 영상에 대응하는 컨텐 츠의 사운드를 출력할 수 있다. 스피커는 적어도 하나 이상의 스피커로 구현될 수 있다. 스피커는 전자장치에 설치될 수도 있고, 외 부에 마련되는 외부 스피커로 구현될 수도 있다. 이 경우, 전자장치는 오디오신호를 외부 스피커로 인터페이 스부를 통해 전송할 수 있다. 전자장치는 프로세서를 포함한다. 프로세서는 인쇄회로기판 상에 장착되는 CPU, 칩셋, 버퍼, 회로 등 으로 구현되는 하나 이상의 하드웨어 프로세서를 포함하며, 설계 방식에 따라서는 SOC(system on chip)로 구현 될 수도 있다. 프로세서는 전자장치가 디스플레이장치로 구현되는 경우에 컨텐츠의 비디오신호에 대한 비디오처리를 위 해 비디오신호 처리부를 포함할 수 있다. 비디오신호 처리부는 디멀티플렉서, 디코더, 스케일러 등을 포함할 수 있으며, 비디오처리 프로세서로 구현될 수 있다. 프로세서는 오디오신호에 대한 오디오처리를 위해 오디오신 호 처리부를 포함할 수 있다. 오디오신호 처리부는 오디오처리 프로세서로 구현될 수 있으며, 오디오 DSP(Digital Signal Processor), 앰프 등을 포함할 수 있다. 다만, 프로세서는 비디오처리 프로세서 및 오디오처리 프로세서를 포함하도록 마련되는 것에 한정되지 않으 므로, 설계 방법에 따라 비디오처리 프로세서 또는 오디오처리 프로세서는 프로세서와 별개의 구성으로 마련 될 수 있다. 프로세서는 상기한 다양한 처리 프로세서에 대응하는 모듈들을 포함할 수 있다. 여기서, 이러한 모듈들 중 일부 또는 전체가 SOC로 구현될 수 있다. 예를 들면, 디멀티플렉서, 디코더, 스케일러 등 비디오처리와 관련된 모듈이 비디오처리 SOC로 구현되고, 오디오 DSP는 SOC와 별도의 칩셋으로 구현되는 것이 가능하다. 다만, 전자장치의 구성은 도 2에 도시된 바에 한정되는 것은 아니므로, 설계 방법에 따라 상기한 구성 중 일 부를 제외하거나, 상기한 구성 이외의 구성을 포함할 수 있다. 일 예로, 전자장치는 센서부를 포함한다. 센서부는 사용자를 식별하거나, 사용자의 움직임, 위치 등을 감지 하기 위한 적어도 하나의 센서를 포함할 수 있다. 센서부는 전자장치의 전면을 촬상 또는 촬영하기 위한 이 미지획득부를 더 포함할 수 있으며, 이미지획득부를 통해 획득한 이미지에 기초하여 사용자를 식별하거나, 사용 자의 움직임, 위치 등을 감지할 수 있다. 이미지획득부는 적어도 하나의 카메라로 구현될 수 있다. 다만 이에 한정되는 것은 아니므로, 센서부는 사용자의 움직임, 위치 등을 감지하기 위한 거리센서를 포함할 수 있다. 거 리센서는, 예컨대, 적외선, 초음파 등을 방사하고, 적외선, 초음파 등이 방사된 시간과 사용자 등에 의해 반사 되어 되돌아오는 시간 간의 차이에 기초하여 사용자의 움직임, 위치 등을 측정할 수 있다. 한편, 전자장치의 프로세서는 인터페이스부를 통해 복수의 채널 중 어느 한 채널의 방송신호를 수신 하고, 수신된 방송신호에 기초하여 컨텐츠의 영상을 상기 디스플레이에 표시하고, 컨텐츠의 타입에 대응하 여 정의된 비디오 특성의 변화에 기초하여 컨텐츠가 제1컨텐츠에서 제1컨텐츠와 타입이 다른 제2컨텐츠로 전환 되는 시점을 식별하고, 식별된 시점에 기초하여 제2컨텐츠에 관한 동작을 수행할 수 있다. 프로세서는 각각 의 동작을 수행하기 위한 데이터 분석, 처리, 및 결과 정보 생성 중 적어도 일부를 규칙 기반 또는 인공지능 알 고리즘으로서 기계학습, 신경망 네트워크(Neural Network), 또는 딥러닝 알고리즘 중 적어도 하나를 이용하여 수행할 수 있다. 일 예로, 프로세서는 학습부 및 인식부의 기능을 함께 수행할 수 있다. 학습부는 학습된 신경망 네트워크를 생성하는 기능을 수행하고, 인식부는 학습된 신경망 네트워크를 이용하여 데이터를 인식(또는, 추론, 예측, 추 정, 판단)하는 기능을 수행할 수 있다. 학습부는 신경망 네트워크를 생성하거나 갱신할 수 있다. 학습부는 신경 망 네트워크를 생성하기 위해서 학습 데이터를 획득할 수 있다. 일 예로, 학습부는 학습 데이터를 저장부 또는 서버 저장부로부터 획득하거나, 외부로부터 획득할 수 있다. 학습 데이터는, 신경망 네트워크의 학습을 위 해 이용되는 데이터일 수 있으며, 상기한 동작을 수행한 데이터를 학습데이터로 이용하여 신경망 네트워크를 학 습시킬 수 있다. 학습부는 학습 데이터를 이용하여 신경망 네트워크를 학습시키기 전에, 획득된 학습 데이터에 대하여 전처리 작 업을 수행하거나, 또는 복수 개의 학습 데이터들 중에서 학습에 이용될 데이터를 선별할 수 있다. 일 예로, 학습부는 학습 데이터를 기 설정된 포맷으로 가공하거나, 필터링하거나, 또는 노이즈를 추가/제거하여 학습에 적 절한 데이터의 형태로 가공할 수 있다. 학습부는 전처리된 학습 데이터를 이용하여 상기한 동작을 수행하도록 설정된 신경망 네트워크를 생성할 수 있다. 학습된 신경망 네트워크는, 복수의 신경망 네트워크(또는, 레이어)들로 구성될 수 있다. 복수의 신경망 네트워 크의 노드들은 가중치를 가지며, 복수의 신경망 네트워크들은 일 신경망 네트워크의 출력 값이 다른 신경망 네 트워크의 입력 값으로 이용되도록 서로 연결될 수 있다. 신경망 네트워크의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN (Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네 트워크 (Deep Q-Networks)과 같은 모델을 포함할 수 있다. 한편, 인식부는 상기한 동작을 수행하기 위해, 타겟 데이터를 획득할 수 있다. 타겟 데이터는 저장부 또는 서버 저장부로부터 획득하거나, 외부로부터 획득할 수 있다. 타겟 데이터는 신경망 네트워크의 인식 대상이 되 는 데이터일 수 있다. 인식부는 타겟 데이터를 학습된 신경망 네트워크에 적용하기 전에, 획득된 타겟 데이터에 대하여 전처리 작업을 수행하거나, 또는 복수 개의 타겟 데이터들 중에서 인식에 이용될 데이터를 선별할 수 있 다. 일 예로, 인식부는 타겟 데이터를 기 설정된 포맷으로 가공하거나, 필터링 하거나, 또는 노이즈를 추가/제 거하여 인식에 적절한 데이터의 형태로 가공할 수 있다. 인식부는 전처리된 타겟 데이터를 신경망 네트워크에 적용함으로써, 신경망 네트워크로부터 출력되는 츨력값을 획득할 수 있다. 인식부는 출력값과 함께, 확률값 또 는 신뢰도값을 획득할 수 있다. 도 3은 도 1의 전자장치에 대한 제어방법의 일 예를 도시한다. 도 3의 각 동작은 전자장치의 프로세서에 의해 실행될 수 있다. 도 1을 참조하여 설명한 바와 같이, 프로세서는 복수의 채널 중 어느 한 채널의 방송 신호를 수신할 수 있으며(S31), 수신된 방송신호에 기초하여 컨텐츠의 영상을 표시할 수 있다(S32). 프로세서는 컨텐츠의 타입에 대응하여 정의된 비디오 특성의 변화에 기초하여 컨텐츠가 제1컨텐츠에서 제1컨 텐츠와 타입이 다른 제2컨텐츠로 전환되는 시점을 식별할 수 있다(S33). 프로세서는 식별된 시점에 기초하여 제2컨텐츠에 관한 동작을 수행할 수 있다(S34). 이와 같이, 프로세서는 컨텐츠의 타입에 대응하여 정의된 비디오 특성의 변화에 기초하여 컨텐츠의 전환 시 점을 정확하게 식별할 수 있으므로, 전환 시점에 기반하여 식별된 컨텐츠에 대한 사용자의 선호 여부에 따라 최 적화된 컨텐츠 서비스를 제공할 할 수 있다. 도 4는 도 3의 단계 S33과 관련하여, RGB 특성의 변화에 기초하여 컨텐츠 간의 전환 여부를 식별하는 일 예를 도시한다. 프로세서는 방송국과 같은 컨텐츠 제공장치로부터 수신된 방송신호에 기초하여 제1컨텐츠 및 제2 컨텐츠의 영상을 디스플레이부에 표시할 수 있다. 제1컨텐츠 및 제2컨텐츠는 순차적으로 표시되는 것으로 가정한다. 프로세서는 제1컨텐츠 및 제2컨텐츠의 영상 중 적어도 하나의 영상 프레임에 대한 RGB 특성을 식별할 수 있 다. 도 4에 도시된 바와 같이, 제1컨텐츠 및 제2컨텐츠의 영상은 복수의 영상 프레임을 포함할 수 있다. 프로세 서는 제1컨텐츠 및 제2컨텐츠 각각의 복수의 영상 프레임 중 적어도 하나의 영상 프레임을 획득하고, 획득된 적어도 하나의 영상 프레임에 대하여 RGB 특성을 식별할 수 있다. 일 예로, 프로세서는 디스플레이부에 표시된 각 컨텐츠의 영상에 대하여 캡처를 수행하고, 캡처된 영상 프레임에 대하여 RGB 특성을 식별할 수 있다. RGB 특성은, 예컨대, 각 컨텐츠의 프레임에 대한 히스토그램 분석을 통해 식별될 수 있으나, 이에 한정되는 것 은 아니므로, 프로세서는 설계 방법에 따라 다양한 비디오처리를 통해 RGB 특성을 식별할 수 있다. 프로세서는 제1컨텐츠의 적어도 하나의 영상 프레임에 대하여 RGB 특성을 식별한 결과, 제1컨텐츠의 색감이 웜 톤(Warm Tone)인 것으로 식별할 수 있고, 제2컨텐츠의 복수의 영상 프레임 중 적어도 하나의 영상 프레임에 대하여 RGB 특성을 식별한 결과, 제2컨텐츠의 색감이 쿨 톤(Cool Tone)인 것으로 식별할 수 있다. 다만 RGB 특 성은 색감에 한정되는 것은 아니므로, 프로세서는 색상, 명도, 채도 등과 같이 RGB 특성을 나타내는 다양한 팩터 별로 컨텐츠의 RGB 특성을 식별할 수 있다. 프로세서는 제1컨텐츠 및 제2컨텐츠 각각의 색감이 웜 톤 및 쿨 톤인 것으로 식별하고, 제1컨텐츠 및 제2컨 텐츠 간에 색감이 웜 톤에서 쿨 톤으로 변화됨을 식별할 수 있다. 즉, 프로세서는 색감의 변화를 통해 제1컨 텐츠 및 제2컨텐츠 간의 전환 여부를 식별할 수 있다. RGB 특성은, 앞서 설명한 바와 같이, 히스토그램 분석 등 적은 연산량으로 식별될 수 있으므로, 프로세서는 컨텐츠 간의 전환 여부를 식별함에 있어서 자원을 효율적으로 활용할 수 있다. 한편 프로세서는 컨텐츠의 타입 별로 미리 정의된 RGB 특성을 나타내는 RGB 특성표를 참조하여, RGB 특성 의 변화를 식별할 수 있다. RGB 특성표는 룩업 테이블의 형태로 저장부에 저장된 것일 수 있으나, 이에 한정되지 않으므로, 외부 서버 또는 다른 전자장치로부터 수신한 것일 수 있다. RGB 특성표에는, 도 4에 도시된 바와 같이, 컨텐츠가 타입 별로 분류될 수 있다. 일 예로, 컨텐츠의 타입은 드라마, 뉴스 등과 같은 비광고와 광고로 분류될 수 있다. 또한, RGB 특성표에는 다양한 RGB 특성 팩터 별로 컨텐츠의 타입에 대응하는 고유한 RGB 특성이 그룹화될 수 있다. 일 예로, RGB 특성 중 색감 팩터와 관련하여, 비광고 중 드라마의 색감은 웜 톤인 반면에, 광고의 색감은 쿨 톤이 될 수 있다. 다만 이에 한정되는 것은 아니 므로, RGB 특성표에는 설계 방법에 따라 다양한 RGB 특성 팩터가 포함될 수 있으며, 각 RGB 특성 팩터 별로 컨텐츠의 타입에 대응하는 고유한 RGB 특성이 그룹화될 수 있다. 프로세서는 RGB 특성표를 참조하여, 색감이 웜 톤인 것으로 식별된 제1컨텐츠의 타입이 드라마인 것으로 식별할 수 있으며, 색감이 쿨 톤인 것으로 식별된 제2컨텐츠의 타입이 광고인 것으로 식별할 수 있다. 즉, 프로 세서는 RGB 특성의 변화를 통해 컨텐츠의 타입이 드라마에서 광고로 전환된 것으로 식별할 수 있다. 이와 같이, 프로세서는 RGB 특성표를 참조하여 RGB 특성의 변화를 식별할 수 있으므로, 앞서 설명한 바와 같이, 자원을 효율적으로 활용할 수 있을 뿐만 아니라, 보다 용이하게 컨텐츠 간의 전환 여부를 식별할 수 있다. 다른 실시예로서, 프로세서는 RGB 특성의 변화에 기초하여 제1컨텐츠 및 제2컨텐츠 간의 전환 여부를 식별할 수 있으며, 제1컨텐츠 및 제2컨텐츠 간의 제1전환 시점(t1)을 식별할 수 있다. 프로세서는 제1전환 시점(t 1)에 대한 식별 정확도를 향상시키기 위해 다양한 동작 또는 처리를 추가적으로 수행할 수 있다. 예컨대, RGB 특성의 변화가 있는 것으로 식별된 제1컨텐츠 및 제2컨텐츠에 대하여 비디오 특성의 변화 여부를 추가적으로 식 별할 수 있다. 이하에서는 도 5 및 6, 그리고 도 7을 참조하여, RGB 특성의 변화가 있는 것으로 식별된 제1컨텐 츠 및 제2컨텐츠에 대하여 비디오 특성의 변화가 있는지 여부를 추가적으로 식별함으로써, 제1전환 시점(t1)을 보다 정밀하게 식별하는 과정에 대해 자세히 설명한다. 도 5는 도 3의 단계 S33과 관련하여, 컨텐츠의 비디오 특성에 기초하여 컨텐츠의 타입을 식별하는 일 예를 도시 한다. 도 4를 참조하여 설명한 바와 같이, 프로세서는 RGB 특성의 변화가 있는 것으로 식별된 제1컨텐츠 및 제2컨텐츠의 영상에 대하여 비디오 특성을 식별할 수 있다. 일 예로, 도 5에 도시된 바와 같이, 프로세서는 제1컨텐츠의 영상 프레임에 대하여 비디오 특성을 식별할 수 있다. 비디오 특성은, 캡처된 영상 내에 포함된 대상, 예컨대, 인물, 로고(Logo), 제목, 브랜드 등 다양한 팩터를 포 함할 수 있다. 인물 팩터는 영상 내의 출연자의 얼굴 자체의 형태, 형상 등을 포함할 뿐만 아니라, 출연자의 몸 매, 체격, 실루엣(silhouette), 그림자, 고유한 신체 특징 내지는 포즈 등을 포함할 수 있다. 또한, 인물 팩터 는 배역 상의 이름 내지는 별명을 포함할 뿐만 아니라, 출연자의 실제 이름 내지는 별명을 포함할 수 있다. 로 고 팩터는 방송국과 같은 컨텐츠 제공장치를 나타내는 방송국 로고, 컨텐츠 자체를 식별하기 위한 컨텐츠 로고 등을 포함할 수 있으며, 제목 팩터는 컨텐츠 자체의 제목을 포함할 수 있다. 브랜드 팩터는, 예컨대, 영상 내에 서 노출되는 사업체 브랜드, 자동차 브랜드, 의복 브랜드 등을 포함할 수 있다. 다만 이에 한정되는 것은 아니 므로, 비디오 특성은 다양한 팩터를 포함할 수 있다. 프로세서는 제1컨텐츠의 영상 프레임에 대하여 광학 문자 인식(Optical Character Recognition), 광학 물체 인식(Optical Object Recognition) 등의 인식 방법을 통해 제1컨텐츠에 대한 비디오 특성을 식별할 수 있다. 다 만 광학 인식 방법에만 한정되는 것은 아니므로, 프로세서는 설계 방법에 따라 다양한 방법으로 비디오 특성 을 식별할 수 있다. 일 예로, 도 5에 도시된 바와 같이, 프로세서는 제1컨텐츠의 영상 프레임에 대하여 광학 인식을 수행함으로 써, 제1컨텐츠의 비디오 특성의 인물 팩터와 관련하여 출연자 이름은 \"존\"이고, 배역 이름은 \"찰스\"임 을 식별할 수 있다. 또한, 로고 팩터와 관련하여 방송국 로고는 \"A TV\"이고, 컨텐츠 로고는 \"치즈 그림\"임을 식별할 수 있고, 제목 팩터와 관련하여 컨텐츠 제목은 \"치즈\"임을 식별할 수 있다. 또한, 브랜드 팩터와 관련하여 상호명, 브랜드 로고 내지는 브랜드 명을 식별할 수 있다. 프로세서는 비디오 특성표를 참조하여, 제1컨텐츠의 타입을 식별할 수 있다. 비디오 특성표에는 컨텐 츠의 타입에 대응하여 미리 정의된 비디오의 특성이 컨텐츠의 타입 별로 그룹화될 수 있다. 비디오 특성표는 룩업 테이블의 형태로 저장부에 저장된 것일 수 있으나, 이에 한정되는 것은 아니므로 외부 서버로부터 수신되거나, 다른 전자장치로부터 수신된 것일 수 있다. 도 5에 도시된 바와 같이, 비디오 특성표에는 드라마의 경우, 비디오 특성의 인물 팩터와 관련하여 출연자 이름으로 \"존\" 등이 포함되고, 배역 이름으로 \"찰스\" 등이 포함될 수 있다. 또한, 로고 팩터와 관련하여 방송국 로고로 \"A TV\" 등이 포함되고, 컨텐츠 로고로 \"치즈 그림\" 등이 포함되고, 제목 팩터와 관련하여 컨텐츠 제목으 로 \"치즈\" 등이 포함될 수 있다. 프로세서는 제1컨텐츠의 영상으로부터 식별된 비디오 특성과 비디오 특성표의 비디오 특성을 팩터 별로 비교할 수 있다. 일 예로, 프로세서는 인물 팩터와 관련하여 제1컨텐츠의 영상으로부터 식별된 출연자 얼굴 내지는 이름인 \"존\"이, 비디오 특성표의 출연자 얼굴 내지는 이름에 포함됨을 식별할 수 있으며, 제1컨텐츠 의 영상으로부터 식별된 배역 이름인 \"찰스\"가, 비디오 특성표의 배역 이름에 포함됨을 식별할 수 있다. 마 찬가지로, 프로세서는 로고, 제목, 브랜드 팩터 등과 관련하여 제1컨텐츠의 영상으로부터 식별된 비디오 특 성이 비디오 특성표의 비디오 특성에 포함됨을 식별할 수 있다. 프로세서는 양 비디오 특성 간의 비교를 통해 제1컨텐츠의 타입이 드라마인 것으로 식별할 수 있다. 한편 프로세서는 각 팩터 간에 가중치를 다르게 부여할 수 있다. 일 예로, 프로세서는 인물 팩터에 대부 분의 가중치를 부여하고, 다른 팩터에는 나머지 가중치를 나눠서 부여한 경우를 가정하면, 나머지 팩터와 관련 하여 비디오 특성이 동일하지 않거나 포함되지 않더라도, 인물 팩터와 관련하여 비디오 특성이 동일하거나 포함 된다면, 예컨대, 제1컨텐츠의 타입이 드라마인 것으로 식별할 수 있다. 다만 각 팩터 별로 부여되는 가중치는 설계 방법에 따라 다양하게 마련될 수 있다. 이와 같이 프로세서는 비디오 특성표를 참조하여 제1컨텐츠의 타입을 식별할 수 있으므로, 제1컨텐츠의 타입에 대한 식별 정확도를 향상시킬 수 있다. 도 6은 도 3의 단계 S33과 관련하여, 컨텐츠의 비디오 특성에 기초하여 컨텐츠의 타입을 식별하는 다른 예를 도 시한다. 도 5를 참조하여, 제1컨텐츠의 영상에 기초하여 드라마 등과 같은 비광고의 타입을 식별하는 예를 설명 하였으나, 이하에서는 도 6을 참조하여 제2컨텐츠의 영상에 기초하여 광고를 식별하는 일 예에 대해 자세히 설 명한다. 다만 설명의 편의를 위해 도 5에서의 설명과 중복된 부분을 제외하고, 상이한 부분 위주로 설명한다. 프로세서는, 도 4에서 설명한 바와 같이, RGB 특성의 변화가 있는 것으로 식별된 제2컨텐츠의 영상에 대하여 비디오 특성을 식별할 수 있다. 프로세서는 제2컨텐츠의 영상 프레임에 대하여 광학 문자 인식, 광학 물체 인식 등을 수행함으로써, 제2컨텐츠의 비디오 특성의 인물 팩터와 관련하여 출연자 이름은 \"맥\"임을 식별할 수 있다. 또한, 로고 팩터와 관련하여 방송국 로고는 \"A TV\"이고, 컨텐츠 로고는 알파벳 \"d\"가 포함된 그림임을 식별할 수 있고, 제목 팩터와 관련하여 컨텐츠 제목은 \"d 콜라\"임을 식별할 수 있다. 또한, 브랜 드 팩터와 관련하여 상호명, 브랜드 로고 내지는 브랜드 명을 식별할 수 있다. 프로세서는 비디오 특성표를 참조하여, 제2컨텐츠의 타입을 식별할 수 있다. 도 6에 도시된 바와 같이, 비디오 특성표에는 광고의 경우, 비디오 특성의 인물 팩터와 관련하여 출연자 이름 및 배역 이름으로 \"맥\" 등이 포함될 수 있다. 또한, 로고 팩터와 관련하여 방송국 로고로 \"A TV\" 등이 포함되고, 컨텐츠 로고로 알파벳 \"d\"가 포함된 그림 등이 포함되고, 제목 팩터와 관련하여 컨텐츠 제목으로 \"d 콜라\" 등이 포함될 수 있다. 프로세서는 제2컨텐츠의 영상 프레임으로부터 식별된 비디오 특성과 비디오 특성표의 비디오 특성에 대하 여 팩터 별로, 동일 여부 내지는 포함 여부를 식별할 수 있다. 일 예로, 프로세서는 인물 팩터와 관련하여 제2컨텐츠의 영상으로부터 식별된 출연자 얼굴 내지는 이름인 \"맥\"이, 비디오 특성표의 출연자 얼굴 내지는 이름에 포함됨을 식별할 수 있다. 마찬가지로, 프로세서는 로고, 제목, 브랜드 팩터 등과 관련하여 제2컨텐 츠의 영상으로부터 식별된 비디오 특성이 비디오 특성표의 비디오 특성에 포함됨을 식별할 수 있다. 프로세 서는 양 비디오 특성 간의 비교를 통해 제2컨텐츠의 타입이 광고인 것으로 식별할 수 있다. 한편 프로세서는 각 팩터 간에 가중치를 다르게 부여할 수 있으며, 예컨대, 나머지 팩터와 관련하여 비디오 특성이 동일하지 않거나 포함되지 않더라도, 인물 팩터와 관련하여 비디오 특성이 동일하거나 포함된다면, 제2 컨텐츠의 타입이 광고인 것으로 식별할 수 있다. 이와 같이 프로세서는 비디오 특성표를 참조하여 제2컨텐츠의 타입을 식별할 수 있으므로, 제2컨텐츠의 타입에 대한 식별 정확도를 향상시킬 수 있다. 도 5 및 6를 참조하여 설명한 바와 같이, 프로세서는 RGB 특성의 변화가 있는 것으로 식별된 제1컨텐츠 및 제2컨텐츠에 대하여, 비디오 특성에 따라 타입을 식별함으로써, 타입에 대한 식별 정확도를 향상시킬 수 있다.따라서, 프로세서는 제1컨텐츠에서 제2컨텐츠로 전환되는 제1전환 시점(t1)를 정밀하게 식별할 수 있다. 다시 말해, 도 1을 참조하여 설명한 바와 같이, 방송 순서에 따라 제1컨텐츠에 후속하여 제3컨텐츠가 방송되는 중에 제2컨텐츠가 삽입된 경우, 프로세서는 제1컨텐츠에서 제2컨텐츠로 전환되는 제1전환 시점(t1)뿐만 아니 라, 제2컨텐츠에서 제3컨텐츠로 전환되는 제2전환 시점(t2)도 정밀하게 식별할 수 있다. 즉, 프로세서는 제1 전환 시점(t1) 및 제2전환 시점(t2)에 기반하여, 광고인 제2컨텐츠의 광고 시간을 정밀하게 식별할 수 있다. 도 7은 도 3의 단계 S33과 관련하여, 컨텐츠의 사운드 특성에 기초하여 컨텐츠의 타입을 식별하는 일 예를 도시 한다. 프로세서는 컨텐츠의 오디오신호에 기초하여 스피커를 통해 컨텐츠의 영상에 대응하는 컨텐츠의 사운드를 출력할 수 있다. 스피커는 전자장치에 내장된 것일 수 있으나, 이에 한정되는 것은 아니므로, 외장 스피커를 통해 컨텐츠의 사운드를 출력할 수 있다. 다만 이하에서는 설명의 편의를 위해 내장된 스피 커를 통해 컨텐츠의 사운드가 출력된 경우를 가정한다. 또한, 프로세서는 스피커로부터 출력된 사운드의 신호를 전자장치에 내장된 마이크를 통해 수신 할 수 있으나, 이에 한정되는 것은 아니므로, 리모컨에 마련된 마이크 또는 스마트폰 등에 마련된 마이 크를 통해 사운드의 신호를 수신할 수 있다. 다만 이하에서는, 설명의 편의를 위해 내장된 마이크를 통해 사운드의 신호를 수신한 경우를 가정한다. 프로세서는 마이크를 통해 수신된 사운드의 신호에 기초하여 컨텐츠의 사운드 특성을 식별할 수 있다. 사운드 특성은, 컨텐츠의 사운드에 포함된 배경사운드, 데시벨, 크기 등 다양한 팩터를 포함할 수 있다. 배경사 운드 팩터는 컨텐츠의 사운드에 포함된 배경사운드의 타입, 지속시간, 배경사운드 재생 중 나레이션(Narration) 삽입 여부 등을 포함할 수 있다. 데시벨 팩터는 배경사운드의 최대, 최소, 평균 데시벨, 데시벨의 변동 횟수 등 을 포함할 수 있다. 다만 이에 한정되는 것은 아니므로, 사운드 특성은 다양한 팩터를 포함할 수 있다. 프로세서는 마이크를 통해 수신된 사운드신호에 대하여 다양한 사운드 처리를 통해 사운드 특성을 식별 할 수 있다. 프로세서는 사운드 처리를 수행함에 있어서, 사운드 인식을 위한 다양한 알고리즘, 예컨대, 사 운드 인식 모델을 사용할 수 있다. 사운드 인식 모델은 사운드의 신호에 대한 사운드 인식을 위한 하드웨어/소 프트웨어 컴포넌트를 포함할 수 있으며, 예컨대, 마르코프 모델(Hidden Markov Model; HMM), 동적 시간 왜곡 (Dynamic Time Warping; DTW) 등의 알고리즘에 따라서 사운드에 대한 통계적 모델링을 통해 구현되는 음향 모델 (Acoustic Model), 말뭉치(언어 연구를 위하여 컴퓨터가 텍스트를 가공, 처리, 분석할 수 있는 형태로 모아 놓 은 자료의 집합) 수집을 통해 구현되는 언어 모델(Language Model) 등을 포함할 수 있다. 프로세서는 컨텐츠의 사운드신호에 대한 사운드 처리를 통해, 예컨대, 제1컨텐츠에 관한 사운드 특성의 배경 사운드 팩터와 관련하여 지속시간이 \"1분30초 이상\"이고, 나레이션이 \"미삽입\"됨을 식별할 수 있다. 또한, 프로 세서는 데시벨 팩터와 관련하여, 최대 데시벨이 \"F 데시벨\"에 이르고, 데시벨의 변동 횟수가 \"소정 횟수 이 상\"임을 식별할 수 있다. 반면에, 프로세서는 제2컨텐츠에 관한 사운드 특성의 배경사운드 팩터와 관련하여 지속시간이 \"1분30초 미만\"이고, 나레이션이 \"삽입\"됨을 식별할 수 있다. 또한, 프로세서는 데시벨 팩터와 관련하여, 최대 데시벨이 \"G 데시벨\"에 이르고, 데시벨의 변동 횟수가 \"소정 횟수 이하\"임을 식별할 수 있다. 프로세서는 컨텐츠의 타입에 대응하는 사운드 특성이 팩터 별로 미리 정의된 사운드 특성표를 참조하여, 컨텐츠의 타입을 식별할 수 있다. 사운드 특성표는 룩업 테이블의 형태로 저장부에 저장된 것일 수 있으 나, 이에 한정되는 것은 아니므로 외부 서버로부터 수신되거나, 다른 전자장치로부터 수신된 것일 수 있다. 도 7에 도시된 바와 같이, 사운드 특성표는 드라마의 경우, 사운드 특성의 배경사운드 팩터와 관련하여 지속 시간이 \"1분30초 이상\"이고, 나레이션이 \"미삽입\"된 것으로 마련될 수 있다. 또한, 데시벨 팩터와 관련하여, 최 대 데시벨이 \"F 데시벨\"에 이르고, 데시벨의 변동 횟수가 \"소정 횟수 이상\"인 것으로 마련될 수 있다. 반면에, 사운드 특성표는 광고의 경우, 사운드 특성의 배경사운드 팩터와 관련하여 지속시간이 \"1분30초 미만\"이고, 나레이션이 \"삽입\"된 것으로 마련될 수 있다. 또한, 데시벨 팩터와 관련하여, 최대 데시벨이 \"G 데시벨\"에 이르 고, 데시벨의 변동 횟수가 \"소정 횟수 이하\"인 것으로 마련될 수 있다. 프로세서는 제1컨텐츠의 사운드의 신호부터 식별된 사운드 특성과 사운드 특성표의 사운드 특성을 팩터 별로 비교할 수 있다. 일 예로, 프로세서는 배경사운드 팩터와 관련하여 제1컨텐츠의 지속시간인 \"1분 30초 이상\"이, 사운드 특성표의 드라마의 배경사운드의 지속시간인 \"1분 30초 이상'에 대응됨을 식별할 수 있으며, 제2컨텐츠의 사운드로부터 식별된 지속시간인 \"1분 30초 미만\"이, 사운드 특성표의 광고의 배경사운 드의 지속시간인 \"1분 30초 미만\"에 대응됨을 식별할 수 있다. 즉, 프로세서는 양 사운드 특성 간의 비교를 통해 제1컨텐츠의 타입이 드라마이고, 제2컨텐츠의 타입이 광고인 것으로 식별할 수 있다. 한편 프로세서는각 팩터 간에 가중치를 다르게 부여할 수 있으며, 각 팩터 별로 부여되는 가중치는 설계 방법에 따라 다양하게 마련될 수 있다. 이와 같이 프로세서는 사운드 특성표를 참조하여 제1컨텐츠 및 제2컨텐츠의 타입을 식별할 수 있으므로, 각 컨텐츠에 대한 식별 정확도를 향상시킬 수 있다. 도 5 및 6를 참조하여 설명한 바와 같이, 프로세서는 RGB 특성의 변화가 있는 것으로 식별된 제1컨텐츠 및 제2컨텐츠에 대하여, 사운드 특성에 따라 타입을 식별함으로써, 타입에 대한 식별 정확도를 향상시킬 수 있다. 따라서, 프로세서는 제1컨텐츠에서 제2컨텐츠로 전환되는 제1전환 시점(t1)를 정밀하게 식별할 수 있을 뿐만 아니라, 동일한 방법으로 제2컨텐츠에서 제3컨텐츠로 전환되는 제2전환 시점(t2)도 정밀하게 식별할 수 있다. 도 8은 도 3의 단계 S34와 관련하여, 컨텐츠의 타입에 대응하여 정의된 비디오 특성을 학습하는 일 예를 도시한 다. 이하에서는, 도 8을 참조하여 프로세서가 제1컨텐츠의 타입이 드라마이고, 제2컨텐츠의 타입이 광고인 것으로 식별된 경우를 가정하여, 비디오 특성을 학습하는 과정에 대해 자세히 설명한다. 도 5를 참조하여 설명한 바와 같이, 프로세서는 제1컨텐츠의 타입이 드라마인 것으로 식별할 수 있다. 이 경 우, 프로세서는 드라마인 것으로 식별된 제1컨텐츠에 대한 비디오 특성을 식별할 수 있다. 일 예로, 프로세 서는 제1컨텐츠의 배경색 팩터와 관련하여 배경색의 타입이 \"회색\"이고, 배경색이 소정 시간 동안 '미변경\" 됨을 식별할 수 있다. 프로세서는 광학 인식 등을 수행함으로써, 배경색 팩터와 관련된 비디오 특성을 식별 할 수 있다. 프로세서는 배경색 팩터와 관련된 비디오 특성을 새로 식별한 경우, 예컨대, 비디오 특성표에 드라마에 대응하는 배경색과 관련된 팩터가 있는지 여부를 식별할 수 있다. 만일 드라마에 대응하는 배경색과 관련된 팩 터가 있는 경우, 프로세서는 해당 팩터와 관련된 비디오 특성에 배경색의 타입이 \"회색\"임을 반영하거나, 소 정 시간 동안 배경색의 변경 여부가 \"미변경\"임을 반영할 수 있다. 반면에, 드라마에 대응하는 배경색과 관련된 팩터가 없는 경우, 프로세서는 비디오 특성표에 드라마에 대응하는 새로운 팩터로서 배경색 팩터를 추가 하고, 드라마에 대응하는 배경색의 타입이 \"회색\"임을 반영하거나, 소정 시간 동안 배경색의 변경 여부가 \"미변 경\"임을 반영할 수 있다. 다른 예로서, 도 6을 참조하여 설명한 바와 같이, 프로세서는 제2컨텐츠의 타입이 광고인 것으로 식별한 경 우, 제2컨텐츠의 배경색의 타입이 \"핑크색\"임을 식별할 수 있으며, 배경색이 소정 시간 동안 \"다수 변경\"됨을 식별할 수 있다. 만일 비디오 특성표에 광고에 대응하는 배경색과 관련된 팩터가 있는 경우, 프로세서는 해당 팩터와 관련된 비디오 특성에 배경색의 타입이 \"핑크색\"임을 반영하거나, 소정 시간 동안 배경색의 변경 여부가 \"다수 변경\"임을 반영할 수 있다. 반면에, 광고에 대응하는 배경색과 관련된 팩터가 없는 경우, 프로세 서는 비디오 특성표에 광고에 대응하는 새로운 팩터로서 배경색 팩터를 추가하고, 광고에 대응하는 배경 색의 타입이 \"핑크색\"임을 반영하거나, 소정 시간 동안 배경색의 변경 여부가 \"다수 변경\"임을 반영할 수 있다. 사운드 특성의 경우에도, 프로세서는 드라마로 식별된 제1컨텐츠 및 광고로 식별된 제2컨텐츠의 사운드신호 로부터 새로 식별된 사운드 특성이 있는 경우, 드라마 또는 광고 각각에 대응하는 사운드 팩터 또는 사운드 특 성을 사운드 특성표에 추가하거나, 반영할 수 있다. 이와 같이, 프로세서는 컨텐츠의 비디오 특성 내지는 사운드 특성에 대하여 능동적으로 학습할 수 있으므로, 좀더 다양한 컨텐츠의 타입을 적응적으로 식별할 수 있다. 도 9는 도 3의 단계 S33과 관련하여, 컨텐츠 간의 전환 시점을 식별하는 일 예를 도시한다. 프로세서는 방송 국으로부터 수신되는 방송신호에 기초하여, 예컨대, 컨텐츠의 영상을 디스플레이부에 표시할 수 있다. 방송 신호에는 컨텐츠의 비디오신호 및 오디오신호뿐만 아니라, 컨텐츠와 관련된 정보인 EPG가 포함될 수 있다. EPG는 컨텐츠와 관련된 정보, 예컨대, 채널, 제목, 시작/종료 시각 등에 관한 정보가 포함될 수 있으며, 프 로세서는 EPG에 기초하여 컨텐츠와 관련된 채널, 제목, 시작/종료 시각 등을 식별할 수 있다. 다만 이에 한정되는 것은 아니므로, EPG에는 컨텐츠와 관련된 다양한 정보가 포함될 수 있다. 도 9에 도시된 바와 같이, 프로세서는 EPG에 기초하여 프로그램인 드라마에서 뉴스로 전환되는 예상전환 시점(te1)을 식별할 수 있다. 예상전환 시점(te1)은 EPG로부터 획득한 프로그램 시작/종료 시각에 관한 정 보에 기초하여 식별된 것일 수 있다. EPG에는 광고에 관한 정보, 예컨대, 전후 광고 또는 중간 광고의 삽입 여부, 광고의 시작/종료 시각 등에 관한 정보가 포함되지 않을 수 있다. 따라서, 프로그램인 드라마와 뉴스 사 이 삽입되는 광고로 인해 드라마가 광고로 전환되는 제1전환 시점(t1) 및 광고가 뉴스로 전환되는 제2전환 시점(t2)은 예상전환 시점(te1)과 다를 수 있다. 이러한 점을 고려하여, 프로세서는 디스플레이부에 표시되는 컨텐츠에 대한 비디오 특성의 변화를 식별 하고, 식별된 비디오 특성의 변화에 기초하여 컨텐츠 간의 전환 시점을 식별할 수 있다. 즉, 프로세서는 RGB 특성의 변화가 있는 컨텐츠의 영상 프레임에 대하여 비디오 특성에 따라 컨텐츠의 타입을 식별하고, 컨텐츠의 비디오 특성의 변화에 기초하여 컨텐츠의 타입 간의 전환 시점, 예컨대, 드라마가 광고로 전환되는 제1전환 시 점(t1) 및 광고가 뉴스로 전환되는 제2전환 시점(t2)을 식별할 수 있다. 프로세서는 식별된 전환 시점에 관한 정보를 포함하는 전환 시점표를 생성할 수 있다. 전환 시점표 는 룩업 테이블의 형태로 저장부에 저장된 것일 수 있다. 전환 시점표는, 예컨대, 컨텐츠 제공장치 별 로 프로그램 및 광고 간의 전환 시점에 관한 정보를 포함하도록 마련되거나, 채널 별로 프로그램 및 광고 간의 전환 시점에 관한 정보를 포함하도록 마련될 수 있다. 프로세서는 전환 시점표를 컨텐츠 제공장치 또는 다른 전자장치에 제공할 수 있다. 다른 실시예로서, 전환 시점표는 다른 전자장치에 의해 생성되어 제공된 것일 수 있다. 프로세서는 그 전자장치로부터 수신된 전환 시점표에 기초하여 기존에 저장하던 전환 시점표를 업데이트 할 수 있다. 이와 같이, 프로세서는, 예컨대, 디스플레이부에 표시되는 드라마가 광고로 전환되는 제1전환 시점(t1) 및 광고가 뉴스로 전환되는 제2전환 시점(t2)을 직접 식별할 수 있으므로, 전환 시점의 식별 정확도를 향상시킬 수 있으며, 전환 시점의 식별 정확도에 기반하여 관련 동작을 수행할 수 있는 환경을 조성할 수 있다. 이하에서는, 전환 시점의 식별과 관련하여 보다 효율적인 자원 활용 및 식별 정확도 향상을 위해 타임 블록 (Time Block, tb)에 기반하여 전환 시점을 식별하는 과정에 대해 도 10을 참조하여 자세히 설명한다. 도 10은 도 3의 단계 S33과 관련하여, 타임 블록에 기반하여 전환 시점을 식별하는 일 예를 도시한다. 도 10에 도시된 바와 같이, 타임 블록(tb)은 프로세서가 컨텐츠 간의 전환 시점을 식별하는 시간 구간을 나타낼 수 있다. 즉, 프로세서는 타임 블록(tb)의 시작 시점부터 타임 블록(tb)의 종료 시점이 도래하기까지 컨텐츠의 RGB 특성을 식별할 수 있다. 좀더 구체적으로, 프로세서는 예상전환 시점(te1)을 포함하는 소정 시간 구간을 제1타임 블록(tb1)으로 설정 할 수 있다. 예상전환 시점(te1)은, 도 9를 참조하여 설명한 바와 같이, EPG에 따라 제1컨텐츠에서 제3컨텐 츠로 전환될 것으로 예상되는 시점을 의미할 수 있다. 여기서, 제1컨텐츠 및 제3컨텐츠는, 드라마, 뉴스, 영화 등과 같은 프로그램을 포함할 수 있다. 프로세서는 제1타임 블록(tb1)을 최초로 설정하는 경우, 제1타임 블 록(tb1)이 예상전환 시점(te1)을 포함하는 소정 시간 구간을 갖도록 설정할 수 있다. 제1타임 블록(tb1)에 의한 시간 구간은 설계 방법에 따라 다양하게 설정될 수 있다. 다만 이하에서는 설명의 편의를 위해 예상전환 시점 (te1)을 기준으로 전후 각 20분 동안이 제1타임 블록(tb1)으로 설정된 경우를 가정한다. 제1타임 블록(tb1)이 설정된 경우, 프로세서는 제1컨텐츠의 영상을 디스플레이부에 표시하다가 제1타임 블록(tb1)의 시작 시점이 도래하면, 도 4를 참조하여 설명한 바와 같이, 제1타임 블록(tb1)의 시작 시점에 대응 하는 제1컨텐츠의 영상 프레임부터 제1타임 블록(tb1)의 종료 시점에 대응하는 제3컨텐츠의 영상 프레임까지 RGB 특성을 식별할 수 있다. 프로세서는 제1타임 블록(tb1) 동안 영상 프레임에 대한 RGB 특성을 식별하는 중 제1컨텐츠에서 제2컨텐츠로 전환됨에 따른 RGB 특성의 변화를 식별하거나, 제2컨텐츠에서 제3컨텐츠로 전환 됨에 따른 RGB 특성의 변화를 식별할 수 있다. 제1타임 블록(tb1) 동안 RGB 특성의 변화가 있는 것으로 식별된 제1컨텐츠, 제2컨텐츠 및 제3컨텐츠의 영상 프 레임에 대하여, 도 5 및 6을 참조하여 설명한 바와 같이, 프로세서는 비디오 특성을 식별할 수 있다. 프로세 서는 제1컨텐츠, 제2컨텐츠 및 제3컨텐츠의 비디오 특성에 기초하여 제1컨텐츠, 제2컨텐츠 및 제3컨텐츠의 타입을 식별하고, 식별된 타입의 변화 여부에 기초하여 제1컨텐츠, 제2컨텐츠 및 제3컨텐츠 간의 전환 여부를 식별할 수 있다. 프로세서는 제1컨텐츠, 제2컨텐츠 및 제3컨텐츠 간의 전환 여부에 기초하여 제1컨텐츠 및 제2컨텐츠 간의 제1전환 시점(t1)과, 제2컨텐츠 및 제3컨텐츠 간의 제2전환 시점(t2)를 식별할 수 있다. 경우에 따라서, 프로세서는 EPG로부터의 예상전환 시점(te1)을 참조하여 설정된 제1타임 블록(tb1) 동안 제1전환 시점(t1) 및 제2전환 시점(t2)을 식별한 경우, 도 9를 참조하여 설명한 바와 같이, 식별된 제1전환 시 점(t1) 및 제2전환 시점(t2)을 나타내는 전환 시점표를 생성할 수 있다. 이와 같이, 프로세서는 EPG로부터의 예상전환 시점(te1)을 참조하여 제1타임 블록(tb1)을 설정하고, 제1 타임 블록(tb1) 동안 RGB 특성의 변화 및 비디오 특성의 변화에 기초하여 컨텐츠 간의 전환 시점을 식별할 수있다. 따라서, 프로세서는 컨텐츠 간의 전환 시점의 식별과 관련하여 보다 효율적으로 자원을 활용하고, 식 별 정확도를 향상시킬 수 있다. 다른 실시예로서, 프로세서는 제1타임 블록(tb1) 동안에 식별된 제1전환 시점(t1) 및 제2전환 시점(t2)을 포 함하는 소정 시간 구간을 제2타임 블록(tb2)으로 설정할 수 있다. 제2타임 블록(tb2)은 앞서 예상전환 시점 (te1)을 기준으로 전후 각 20분 동안을 시간 구간으로 갖는 제1타임 블록(tb1)보다 짧은 시간 구간을 가질 수 있다. 일 예로, 제2타임 블록(tb2)은 제1타임 블록(tb1)보다 짧은 시간 구간으로서, 제1전환 시점(t1)을 기준으 로 이전 5분 및 제2전환 시점(t2)을 기준으로 이후 5분 동안의 시간 구간을 가질 수 있다. 다만 이에 한정되는 것은 아니므로, 제2타임 블록(tb2)은 설계 방법에 따라 다양한 시간 구간을 가질 수 있다. 프로세서는, 앞서 제1타임 블록(tb1)과 관련하여 설명한 바와 마찬가지로, 제2타임 블록(tb2) 동안 RGB 특성 의 변화 여부를 식별하고, RGB 특성의 변화가 있는 것으로 식별된 제1컨텐츠, 제2컨텐츠 및 제3컨텐츠의 영상 프레임에 대하여 비디오 특성을 식별할 수 있다. 프로세서는 제1컨텐츠, 제2컨텐츠 및 제3컨텐츠 간의 비디 오 특성의 변화 여부에 기초하여 제1컨텐츠, 제2컨텐츠 및 제3컨텐츠 간의 전환 여부를 식별할 수 있으며, 제1 컨텐츠 및 제2컨텐츠 간의 제1전환 시점(t1) 및 제2컨텐츠 및 제3컨텐츠 간의 제2전환 시점(t2)를 식별할 수 있 다. 경우에 따라서, 프로세서는 제2타임 블록(tb2) 동안 식별된 제1전환 시점(t1) 및 제2전환 시점(t2)과, 앞서 제1타임 블록(tb1) 동안 식별된 제1전환 시점(t1) 및 제2전환 시점(t2) 간의 동일 여부를 식별할 수 있다. 만일 각각의 전환 시점이 동일하지 않은 경우, 예컨대, 전환 시점표에 제2타임 블록(tb2) 동안 식별된 제1전환 시점(t1) 및 제2전환 시점(t2)를 반영할 수 있다. 이와 같이, 프로세서는 제1타임 블록(tb1) 동안 식별된 전환 시점에 기반하여 제2타임 블록(tb2)을 설정하고, 제2타임 블록(tb2) 동안 전환 시점을 식별할 수 있으므로, 제1타임 블록(tb1) 동안 컨텐츠 간의 전환 시점을 식별하는 경우에 비해, 더욱 효율적으로 자원을 활용하고, 식별 정확도를 향상시킬 수 있다. 또 다른 실시예로서, 프로세서는 전환시점을 학습할 수 있다. 앞서 제2타임 블록(tb2)의 설정과 관련하여 설 명한 예를 참조하여 이어서 설명하면, 프로세서는 제2타임 블록(tb2) 동안 제1전환 시점(t1) 및 제2전환 시 점(t2)을 식별한 경우, 식별된 제1전환 시점(t1) 및 제2전환 시점(t2)을 포함하는 소정 시간 구간을 제3타임 블 록(tb3)으로 재설정할 수 있다. 제3타임 블록(tb3)은 앞서 제2타임 블록(tb2)보다 짧은 시간 구간을 가질 수 있 다. 일 예로, 제3타임 블록(tb3)은 제2타임 블록(tb2)보다 짧은 시간 구간으로서, 제2타임 블록(tb2) 동안 식별 된 제1전환 시점(t1)을 기준으로 이전 3분 및 제2전환 시점(t2)을 기준으로 이후 3분 동안의 시간 구간을 가질 수 있다. 다만 이에 한정되는 것은 아니므로, 제3타임 블록(tb3)은 설계 방법에 따라 다양한 시간 구간을 가질 수 있다. 프로세서는 재설정된 제3타임 블록(tb3) 동안 컨텐츠에 대한 RGB 특성의 변화 여부 및 비디오 특성의 변화 여부를 식별함으로써, 제1전환 시점(t1) 및 제2전환 시점(t2)를 식별할 수 있다. 프로세서는 제3타임 블록 (tb3) 동안 식별된 제1전환 시점(t1) 및 제2전환 시점(t2)과, 앞서 제2타임 블록(tb2) 동안 식별된 제1전환 시 점(t1) 및 제2전환 시점(t2) 간의 동일 여부를 판단할 수 있다. 만일 상호 동일하지 않은 경우, 프로세서는 제3타임 블록(tb3) 동안 새로 식별된 제1전환 시점(t1) 및 제2전환 시점(t2)를 전환 시점표에 반영할 수 있 다. 이와 같이, 프로세서는 이전 타임 블록(tb)에 기반하여 식별된 전환 시점 대비 새로운 타임 블록(tb)에 기반 하여 식별된 전환 시점을 비교하는 과정을 통해, 전환 시점에 대해 학습할 수 있다. 따라서, 프로세서는 컨 텐츠 전환 시점에 대한 보다 효율적이고, 환경 적응적인 식별을 수행할 수 있다. 도 11은 도 2에 도시된 프로세서의 구성의 일 예를 도시한다. 이하에서는, 도 11을 참조하여 프로세서의 각 구성에 대해 자세히 설명한다. 프로세서는 인식기 실행부를 포함할 수 있다. 인식기 실행부는 컨텐츠의 전환 시점을 식별할 지 여부를 결정할 수 있다. 일 예로, 인식기 실행부는, 도 9 및 10을 참조하여 설명한 바와 같이, EPG를 참조하여 제1타임 블록(tb1)을 설정하고, 설정된 제1타임 블록(tb1)의 시점이 도래하면, 디스플레이부에 표 시된 컨텐츠의 영상에 대한 RGB 특성의 변화 여부를 식별할 수 있다. 또한, 컨텐츠 간의 전환 시점이 식별됨에 따라 인식기 학습부에 의해 제1타임 블록(tb1)과 서로 다른 시간 구간을 갖는 제2타임 블록(tb2), 제3타임 블록(tb3) 등으로 재설정되는 경우, 인식기 실행부는 재설정된 제2타임 블록(tb2), 제3타임 블록(tb3) 등 의 시점이 도래하면, 디스플레이부에 표시된 컨텐츠의 영상에 대한 RGB 특성의 변화 여부를 식별할 수있다. 인식기 실행부는 RGB 특성의 변화 여부를 식별하기 위한 RGB 특성 식별 모듈 등을 포함할 수 있다. 일 예 로, 재설정된 제2타임 블록(tb2), 제3타임 블록(tb3) 등의 시점이 도래하면, 디스플레이부에 표시된 컨텐츠 의 영상에 대한 RGB 특성 식별 모듈 등을 구동함으로써, RGB 특성의 변화 여부를 식별할 수 있다. 이와 같이, 인식기 실행부는 타임 블록(tb)에 기반하여 RGB 특성의 변화 여부를 식별할 수 있으므로, 자원 을 효율적으로 활용할 수 있다. 프로세서는 인식기 학습부를 포함할 수 있다. 인식기 학습부는 컨텐츠 간의 전환 시점이 인식된 경우, 인식된 전환 시점을 학습하고, 학습된 전환 시점에 기반하여 타임 블록(tb)을 재설정할 수 있다. 좀더 구 체적으로, 인식기 실행부에 의해 설정된 제1타임 블록(tb1) 동안 RGB 특성의 변화가 있는 경우, RGB 특성 의 변화가 있는 컨텐츠에 대하여 화면 분석부가 비디오 특성의 변화 여부를 식별하고, 식별된 비디오 특성 의 변화 여부에 기초하여 광고 판단부가 컨텐츠 간의 타입 전환에 따른 컨텐츠 간의 전환 시점을 식별할 수 있다. 일 예로, 인식기 학습부는 광고 판단부에 의해 식별된 전환 시점을 학습하고, 학습된 전환 시점에 기반하여, 제1타임 블록(tb1)보다 시간 구간이 작은 제2타임 블록(tb2)을 학습하고, 제2타임 블록(tb2) 보다 시간 구간이 작은 제3타임 블록(tb3)을 학습을 할 수 있다. 이 경우, 인식기 학습부는 학습된 제2타 임 블록(tb2), 제3타임 블록(tb3) 등에 관한 정보를 인식기 실행부로 제공하여, 인식기 실행부가 학 습된 제2타임 블록(tb2), 제3타임 블록(tb3) 등에 따라 RGB 특성의 변화 여부를 식별하도록 할 수 있다. 이와 같이, 인식기 학습부는 컨텐츠 간의 전환 시점을 학습할 수 있으므로, 컨텐츠 간의 전환 시점을 적응 적으로 식별할 수 있는 환경을 조성할 수 있다. 프로세서는 화면 분석부를 포함할 수 있다. 화면 분석부는, 앞서 설명한 바와 같이, 인식기 실행 부에 의해 설정된 타임 블록(tb) 동안 RGB 특성의 변화가 있는 것으로 식별된 컨텐츠에 대하여 비디오 특 성을 식별할 수 있다. 일 예로, 화면 분석부는 컨텐츠의 영상 프레임에 대하여 다양한 광학 인식 방법을 통해 영상 프레임 내에 포함된 인물, 문자 등과 같은 비디오 특성을 식별할 수 있다. 한편 RGB 특성의 변화가 있는 것으로 식별된 컨텐츠에 대하여 비디오 특성뿐만 아니라 컨텐츠의 사운드에 대한 사운드 특성도 식별될 수 있다. 이 경우, 설계 방법에 따라 화면 분석부가 사운드 특성을 함께 식별하거나, 별도의 사운드 분석부가 사운드 특성을 식별할 수 있다. 다만 이하에서는 설명의 편의를 위해 RGB 특성의 변화가 있는 것으로 식별된 컨텐츠에 대하여 비디오 특성이 식별된 경우를 가정한다. 이와 같이, 화면 분석부는 RGB 특성의 변화가 있는 것으로 식별된 컨텐츠에 대하여 비디오 특성을 식별할 수 있으므로, 광고 판단부로 하여금 좀더 정확하게 컨텐츠의 타입, 즉, 비광고인지 또는 광고인지 여부를 판단할 수 있도록 한다. 프로세서는 광고 판단부를 포함할 수 있다. 광고 판단부는 화면 분석부에 의해 식별된 비디 오 특성에 기초하여 컨텐츠의 타입을 식별할 수 있으며, 비디오 특성의 변화에 기초하여 서로 다른 타입의 컨텐 츠 간의 전환에 따른 전환 시점을 식별할 수 있다. 좀더 구체적으로, 광고 판단부는 비디오 특성에 기초하 여 컨텐츠가 드라마, 뉴스 등과 같은 비광고인지, 아니면 광고인지를 식별할 수 있다. 필요에 따라, 광고 판단 부는 컨텐츠의 타입에 대응하는 비디오 특성이 팩터 별로 분류된 비디오 특성표를 참조하여 컨텐츠의 타입을 식별할 수 있다. 이와 같이, 광고 판단부는 컨텐츠 간의 비디오 특성의 변화 여부에 기초하여 컨텐츠 간의 전환 시점을 식 별할 수 있으므로, 좀더 정확하게 전환 시점을 식별할 수 있다. 프로세서는 광고 학습부를 포함할 수 있다. 광고 학습부는 컨텐츠의 타입 별로 가지고 있는 비디 오 특성을 학습할 수 있다. 일 예로, 광고 판단부가 비디오 특성에 기초하여 컨텐츠의 타입이 광고인 것으 로 식별한 경우, 광고 학습부는 광고의 비디오 특성 중, 예컨대, 비디오 특성표에 광고에 대응하는 비 디오 특성으로 포함되지 않는 비디오 특성을 학습할 수 있다. 일 예로, 광고 학습부는 광고에 대응하여 학 습된 비디오 특성을 비디오 특성표에 반영함으로써, 광고 판단부가 비디오 특성표를 참조하여 컨텐 츠에 대한 비디오 특성의 변화 여부를 식별하는 경우, 학습된 비디오 특성에 기초하여 컨텐츠에 대한 비디오 특 성의 변화 여부를 식별하도록 할 수 있다. 다만 광고 판단부는 광고에 한정되어 비디오 특성을 학습하는 것은 아니므로, 드라마, 뉴스 등과 같은 비 광고로 식별된 컨텐츠에 대해서도 비디오 특성을 학습하고, 학습 결과를 광고 판단부가 활용하도록, 예컨대, 비디오 특성표에 반영할 수 있다. 이와 같이, 광고 학습부는 컨텐츠의 타입에 대응하는 비디오 특성을 학습할 수 있으므로, 다양한 컨텐츠의 타입을 적응적으로 식별할 수 있는 환경을 조성할 수 있다. 프로세서는 서비스 실행부를 포함할 수 있다. 서비스 실행부는 광고 판단부에 의해 식별된 컨텐츠 간의 전환 시점에 기반하여 다양한 서비스를 제공할 수 있다. 일 예로, 전후 광고 또는 중간 광고의 시 작/종료 시각에 기반하여 해당 광고에 대한 사용자의 선호 여부를 식별할 수 있으며, 식별된 선호에 기초하여, 예컨대, 사용자가 선호에 부합하는 광고를 제공할 수 있다. 다만 이에 한정되는 것은 아니므로, 서비스 실행부 는 컨텐츠 간의 전환 시점에 관한 정보를 다른 전자장치와 공유하거나, 컨텐츠 제공장치에게 판매하여 수 익을 창출할 수도 있다. 이와 같이, 서비스 실행부는 사용자에게 최적화된 컨텐츠 서비스를 제공할 수 있다. 도 12는 본 발명의 일 실시예에 따라 타임 블록의 시간 구간을 학습하는 전자장치의 제어방법의 일 예를 도시한 다. 이하에서는 프로세서의 동작으로 간략히 설명한다. 도 12에 도시된 바와 같이, 프로세서는 타임 블록의 시간 구간 동안 컨텐츠 간의 전환 시점이 인식되는지 여 부를 식별할 수 있다(S121). 컨텐츠 간의 전환 시점 인식은 앞서 도 10 등을 참조하여 설명한 방법으로 수행될 수 있다. 타임 블록은 최초 설정되거나, 기 설정된 타임 블록에서 시간 구간이 조정된 것일 수 있다. 예컨대, 타임 블록은, 도 10을 참조하여 설명한 바와 같이, 예상전환 시점(te1)을 포함하는 시간 구간을 갖도록 설정된 제1타임 블록(tb1)이거나, 혹은 제1타임 블록(tb1)으로부터 조정된 제2타임 블록(tb2) 또는 제3타임 블록(tb3) 일 수 있다. 만일 단계 S121에서, 현재의 타임 블록의 시간 구간 동안 컨텐츠 간의 전환 시점이 인식되는 경우(단계 S121의 YES), 프로세서는, 현재의 타임 블록의 시간 구간보다 작고, 이전에 컨텐츠 전환 시점의 인식에 실패한 타임 블록보다 큰 시간 구간을 갖도록 새로운 타임 블록을 설정할 수 있다(S122). 일 예로, 프로세서는 현재의 타 임 블록의 시간 구간보다 20분, 10분, 5분 등을 더 줄일 수 있다. 여기서, 20분, 10분, 5분 등은 설명의 편의를 위한 것이므로, 설계 방법에 따라 다양하게 정해질 수 있다. 또한, 프로세서는 현재의 타임 블록의 시점 또 는 종점에 대해서 어느 하나만을 줄이거나, 모두 줄일 수 있다. 다만, 프로세서는 현재의 타임 블록의 시간 구간을 줄이더라도, 최소한 이전에 컨텐츠 전환 시점의 인식에 실패한 타임 블록의 시간 구간 보다는 크도록 설 정한다. 한편, 프로세서는 조정되는 타임 블록의 시작 시점이 이전 컨텐츠의 시작 시점보다는 이후이고, 타 임블록의 종료 시점이 다음 컨텐츠의 종료 시점 이전이 되도록 타임블록의 시간 구간을 설정한다. 만일 단계 S121에서, 현재의 타임 블록의 시간 구간 동안 컨텐츠 간의 전환 시점이 인식되지 않는 경우(단계 S121의 NO), 프로세서는, 현재의 타임 블록의 시간 구간보다 크고, 이전에 컨텐츠 전환 시점의 인식에 성공 한 타임 블록보다 작은 시간 구간을 갖는 새로운 타임 블록을 설정할 수 있다(S123). 일 예로, 프로세서는 현재의 타임 블록의 시간 구간보다 20분, 10분, 5분 등을 더 늘릴 수 있다. 여기서, 20분, 10분, 5분 등은 설명 의 편의를 위한 것이므로, 설계 방법에 따라 다양하게 정해질 수 있다. 또한, 프로세서는 현재의 타임 블록 의 시점 또는 종점에 대해서 어느 하나만을 늘리거나, 모두 늘릴 수 있다. 다만, 프로세서는 현재의 타임 블 록의 시간 구간을 늘리더라도, 적어도 이전에 컨텐츠 전환 시점의 인식에 성공한 타임 블록의 시간 구간 보다는 크도록 설정한다. 다음으로, 프로세서는, 타임블록의 시간 구간 설정이 완료되는지를 식별한다(S124). 즉, 프로세서는, 현 재의 타임블록의 시간 구간이 더 이상 조정되지 않는 상황인지를 확인한다. 예컨대, 현재의 타임블록의 시간 구 간이 인식된 컨텐츠 전환 시점을 중심으로 하는 최소한의 구간까지 줄어든 경우이다. 이러한 최소한의 구간의 크기는, 전환되는 컨텐츠의 시점 혹은 종점이 방송 상황 등에 따라 가변될 수 있음을 고려하여 미리 정해질 수 있다. 프로세서는, 현재의 타임블록에서 컨텐츠 전환 시점이 인식되었고, 그 시간 구간이 최소한의 구간에 도달하였다고 식별하면, 타임블록의 시간 구간 설정을 완료한 것으로 식별하는 경우(단계 S124의 YES), 절차를 종료할 수 있다. 만일 단계 S124에서, 시간 구간 설정이 완료되지 않은 것으로 식별된 경우, 프로세서는 다시 단계 S121로 돌 아가서, 타임 블록의 시간 구간 설정이 완료될 때까지 각 단계를 반복적으로 수행한다. 이와 같이, 프로세서는 컨텐츠 전환 시점의 인식 여부에 따라 타임 블록의 시간 구간을 조정할 수 있으므로, 전환 시점에 대한 식별 정확성 및 효율성을 향상시킬 수 있다. 도 13은 도 3의 단계 S34와 관련하여, 제2컨텐츠에 관한 동작의 일 예를 도시한다. 앞서 설명한 바와 같이, 프 로세서는 드라마에서 광고로의 제1전환 시점(t1) 및 광고에서 뉴스로의 제2전환 시점(t2)를 식별할 수 있다. 일 예로, 프로세서는 전환 시점표를 참조하여 광고가 디스플레이부에 표시되는 광고 시간(t1-t2)을 식별할 수 있다. 프로세서는 광고 시간(t1-t2)에 기초하여 광고에 대한 사용자의 선호 여부를 식별할 수 있다. 프로세서는 디스플레이부에 광고가 표시된 경우, 예컨대, 카메라 등과 같은 이미지획득부를 통하여 전자장치의 전면 을 촬영 또는 촬상하고, 촬영 또는 촬상된 이미지로부터 획득된 정보에 기초하여 사용자가 누구인지를 식별할 수 있다. 프로세서는 사용자 인식을 위해 다양한 인식 알고리즘을 사용할 수 있다. 다만 이미지에 기초하여 사용자를 인식하는 것에 한정되는 것은 아니므로, 프로세서는 마이크를 통해 수신되는 사용자의 발화 음 성에 기초하여 사용자를 식별할 수 있다. 프로세서는 표시된 광고에 대하여 식별된 사용자의 사용자입력에 기초하여 광고에 대한 사용자의 선호 여부 를 식별할 수 있다. 일 예로, 프로세서는 제1사용자가 표시된 광고에 대한 전체 광고 시간(t1-t2) 중 90%를 시청한 후 다른 채널로 변경한 경우, 전체 광고 시간(t1-t2) 중 90%를 시청한 이력에 기초하여 제1사용자가 해 당 광고를 선호하는 것으로 식별할 수 있다. 반면에, 제2사용자가 동일한 광고에 대한 전체 광고 시간(t1-t2) 중 25%만을 시청한 후 다른 채널로 변경한 경우, 프로세서는 제2사용자가 해당 광고를 선호하지 않는 것으로 식별할 수 있다. 다만 각 사용자의 선호 여부는 선호 또는 비선호 만으로 식별되는 것은 아니므로, 설계 방법에 따라 광고 시청 시간에 비례하여 여러 선호 단계로 식별될 수 있다. 이와 같이, 프로세서는 광고의 전환 시점(t1, t2)에 기초하여 광고에 대한 사용자의 선호 여부를 식별할 수 있으며, 선호 여부에 대한 식별 정확도를 향상시킬 수 있다. 도 14는 도 3의 단계 S34와 관련하여, 제2컨텐츠에 관한 동작의 다른 예를 도시한다. 도 13에서 설명한 바와 같 이, 프로세서는 제1사용자가 디스플레이부에 표시된 광고를 선호하는 것으로 식별한 경우, 사용자의 선 호에 부합하는 관련 광고를 디스플레이부에 표시할 수 있다. 좀더 구체적으로, 도 6을 참조하여 설명한 바와 같이, 프로세서는 디스플레이부에 표시된 광고에 대한 광학 문자 인식, 광학 물체 인식 등을 수행함으로써, 광고의 비디오 특성을 식별할 수 있다. 예컨대, 식별된 광 고의 비디오 특성은 컨텐츠 로고는 알파벳 \"d\"가 포함된 그림임을 식별할 수 있고, 제목 팩터와 관련하여 컨텐 츠 제목은 \"d 콜라\"임을 식별할 수 있다. 프로세서는 식별된 컨텐츠 로고, 컨텐츠 제목 등에 대응하는 비디 오 특성을 갖는 관련 광고를 식별할 수 있다. 일 예로, 프로세서는 제목 팩터와 관련하여 컨텐츠 제목 이 \"e 콜라\"인 관련 광고를 식별할 수 있다. 프로세서는 식별된 관련 광고를, 예컨대, 광고 시간 (t1-t2) 동안 PIP(Picture In Picture) 방식으로 표시할 수 있다. 프로세서는 관련 광고를 식별함에 있어서 비디오 특성뿐만 아니라, 표시된 광고에 대한 사용자의 이력 을 추가적으로 고려할 수 있다. 일 예로, 도 13을 참조하여 설명한 바와 같이, 제1사용자의 광고 시청 시간, 제 1사용자가 광고에 노출된 횟수, 제1사용자가 전자장치를 이용하여 광고된 상품을 구매한 이력 등을 종합적으 로 고려하여, 광고에 대한 제1사용자의 선호 여부를 식별할 수 있으며, 식별된 선호 여부에 따라 관련 광고 를 식별할 수 있다. 이와 같이, 프로세서는 표시된 광고의 비디오 특성에 따라 컨텐츠 서비스를 제공할 수 있으므로, 사용자에게 최적화된 컨텐츠 서비스를 제공할 할 수 있다. 본 문서에 개시된 다양한 실시예들은 전자장치와 같은 기기(Machine)가 읽을 수 있는 저장 매체(Storage Medium)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨어로서 구현될 수 있다. 일 예로, 전자장치의 프로세서는 저장 매체로부터 저장된 하나 이상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행 할 수 있다. 이것은 전자장치와 같은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능 을 수행하도록 운영되는 것을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(Non- transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(예컨대, 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 일 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 예로, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(Computer Program Product)에 포함되어 제공될 수 있다. 본 개시에 의한 컴퓨터 프로그램 제품은, 앞서 언급된 바와 같은, 프로세서에 의해 실행되는 소프트웨어의 명령어들을 포함할 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예컨대, CD-ROM)의 형태로 배포되거나, 또는 어플리케이션 스토어(예컨대, 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들(예컨대, 스마트폰들) 간에 직접, 온라인으로 배포(예컨대, 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴 퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토 어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적 으로 생성될 수 있다. 이상, 바람직한 실시예를 통하여 본 발명에 관하여 상세히 설명하였으나, 본 발명은 이에 한정되는 것은 아니며 특허청구범위 내에서 다양하게 실시될 수 있다."}
{"patent_id": "10-2020-0022554", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 전자장치를 도시한다. 도 2는 도 1의 전자장치에 관한 구성의 일 예를 도시한다. 도 3은 도 1의 전자장치에 대한 제어방법의 일 예를 도시한다. 도 4는 도 3의 단계 S33과 관련하여, RGB 특성의 변화에 기초하여 컨텐츠 간의 전환 여부를 식별하는 일 예를 도시한다. 도 5는 도 3의 단계 S33과 관련하여, 컨텐츠의 비디오 특성에 기초하여 컨텐츠의 타입을 식별하는 일 예를 도시 한다. 도 6은 도 3의 단계 S33과 관련하여, 컨텐츠의 비디오 특성에 기초하여 컨텐츠의 타입을 식별하는 다른 예를 도 시한다. 도 7은 도 3의 단계 S33과 관련하여, 컨텐츠의 사운드 특성에 기초하여 컨텐츠의 타입을 식별하는 일 예를 도시 한다. 도 8은 도 3의 단계 S34와 관련하여, 컨텐츠의 타입에 대응하여 정의된 비디오 특성을 학습하는 일 예를 도시한 다. 도 9는 도 3의 단계 S33과 관련하여, 컨텐츠 간의 전환 시점을 식별하는 일 예를 도시한다. 도 10은 도 3의 단계 S33과 관련하여, 타임 블록에 기반하여 전환 시점을 식별하는 일 예를 도시한다. 도 11은 도 2에 도시된 프로세서의 구성의 일 예를 도시한다. 도 12는 본 발명의 일 실시예에 따라 타임 블록의 시간 구간을 학습하는 전자장치의 제어방법의 일 예를 도시한 다. 도 13은 도 3의 단계 S34와 관련하여, 제2컨텐츠에 관한 동작의 일 예를 도시한다. 도 14는 도 3의 단계 S34와 관련하여, 제2컨텐츠에 관한 동작의 다른 예를 도시한다."}
