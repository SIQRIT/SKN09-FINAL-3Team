{"patent_id": "10-2019-0028524", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0109467", "출원번호": "10-2019-0028524", "발명의 명칭": "전자 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "김재원"}}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,디스플레이; 및MRC(Machine Reading Comprehension) 모델에 기초하여 사용자 입력에 대응되는 텍스트를 획득하고,상기 텍스트를 상기 전자 장치의 동작 단위로 구분하여 복수의 동작 정보를 획득하고,상기 복수의 동작 정보 및 상기 획득된 텍스트에 기초하여 상기 복수의 동작 정보의 시퀀스 정보를 획득하고,상기 시퀀스 정보에 따라 상기 복수의 동작을 순차적으로 수행하기 위한 가이드 UI를 제공하도록 상기 디스플레이를 제어하는 프로세서;를 포함하는, 전자 장치."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 동작 단위는,사용자의 터치 입력이 요구되는 컨텍스트에 기초한 단위인, 전자 장치."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는,상기 전자 장치의 현재 설정 상태 정보를 획득하고,상기 현재 설정 상태 정보에 기초하여 상기 복수의 동작 정보 중 상기 전자 장치에서 기 수행된 적어도 하나의동작 정보를 식별하고, 상기 식별된 동작 정보를 제외한 나머지 동작 정보에 기초하여 상기 시퀀스 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 프로세서는,상기 전자 장치의 현재 설정 상태 정보를 획득하고,상기 현재 설정 상태 정보에 기초하여 상기 복수의 동작 정보 외에 상기 획득된 텍스트에 대응되는 기능을 실행하는데 요구되는 추가 동작 정보를 획득하고, 상기 복수의 동작 정보 및 상기 추가 동작 정보에 기초하여 상기 시퀀스 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 프로세서는, 상기 시퀀스 정보에 따라 상기 복수의 동작 정보 중 제1 동작 정보를 수행하는데 요구되는 터치 입력과 관련된정보에 기초하여 제1 가이드 UI를 제공하고,상기 제1 가이드 UI에 대응되는 터치 입력에 기초하여 상기 전자 장치의 컨텍스트가 변경되면, 상기 변경된 컨텍스트 및 상기 시퀀스 정보에 기초하여 상기 복수의 동작 정보 중 제2 동작 정보를 수행하는데 요구되는 터치공개특허 10-2020-0109467-3-입력과 관련된 정보에 기초하여 제2 가이드 UI를 제공하도록 상기 디스플레이를 제어하는, 전자 장치."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 터치 입력과 관련된 정보는, 상기 터치 입력의 위치 또는 터치 형태 중 적어도 하나를 포함하는, 전자 장치."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 MRC 모델은,상기 전자 장치의 매뉴얼에 포함된 복수의 문장에 기초하여 NLP를 수행하여 질문을 획득하는 QG(QuestionGeneration) 모델 및 상기 획득된 질문에 대응되는 답변을 획득하는 QA(Question Answer) 모델을 포함하는, 전자 장치."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,통신부;를 더 포함하고,상기 프로세서는,상기 사용자 입력을 서버로 전송하도록 상기 통신부를 제어하고, 상기 사용자 입력에 대응되는 텍스트가 상기 서버로부터 수신되면, 상기 수신된 텍스트에 기초하여 상기 복수의동작 정보 및 상기 시퀀스 정보를 획득하고,상기 텍스트는, 상기 전자 장치의 매뉴얼 및 상기 MRC 모델에 기초하여 획득되는, 전자 장치."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 프로세서는,상기 사용자의 터치 입력의 위치 또는 상기 터치 형태 중 적어도 하나가 상기 가이드 UI에 대응하지 않는 것으로 식별되면, 비주얼 피드백 또는 사운드 피드백 중 적어도 하나를 제공하는, 전자 장치."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 프로세서는,수동 모드 또는 자동 모드 중 어느 하나를 선택하기 위한 UI를 제공하고,상기 자동 모드가 선택되면, 상기 가이드 UI에 대응되는 터치 입력 기능을 수행하여 상기 복수의 동작을 순차적으로 수행하는, 전자 장치."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 프로세서는,상기 가이드 UI에 대응되는 터치 입력 기능을 수행하고 상기 터치 입력 기능이 수행되었음을 나타내는 시각적피드백을 제공하는, 전자 장치. 공개특허 10-2020-0109467-4-청구항 12 전자 장치의 제어 방법에 있어서,MRC(Machine Reading Comprehension) 모델에 기초하여 사용자 입력에 대응되는 텍스트를 획득하는 단계;상기 텍스트를 상기 전자 장치의 동작 단위로 구분하여 복수의 동작 정보를 획득하는 단계;상기 복수의 동작 정보 및 상기 획득된 텍스트에 기초하여 상기 복수의 동작 정보의 시퀀스 정보를 획득하는 단계; 및상기 시퀀스 정보에 따라 상기 복수의 동작을 순차적으로 수행하기 위한 가이드 UI를 제공하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 동작 단위는,사용자의 터치 입력이 요구되는 컨텍스트에 기초한 단위인, 제어 방법."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 전자 장치의 현재 설정 상태 정보를 획득하는 단계;를 포함하고,상기 시퀀스 정보를 획득하는 단계는,상기 현재 설정 상태 정보에 기초하여 상기 복수의 동작 정보 중 상기 전자 장치에서 기 수행된 적어도 하나의동작 정보를 식별하는 단계; 및상기 식별된 동작 정보를 제외한 나머지 동작 정보에 기초하여 상기 시퀀스 정보를 획득하는 단계;를 포함하는,제어 방법."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 전자 장치의 현재 설정 상태 정보를 획득하는 단계; 및상기 현재 설정 상태 정보에 기초하여 상기 복수의 동작 정보 외에 상기 획득된 텍스트에 대응되는 기능을 실행하는데 요구되는 추가 동작 정보를 획득하는 단계;를 포함하고,상기 시퀀스 정보를 획득하는 단계는,상기 복수의 동작 정보 및 상기 추가 동작 정보에 기초하여 상기 시퀀스 정보를 획득하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,상기 가이드 UI를 제공하는 단계는,상기 시퀀스 정보에 따라 상기 복수의 동작 정보 중 제1 동작 정보를 수행하는데 요구되는 터치 입력과 관련된정보에 기초하여 제1 가이드 UI를 제공하는 단계; 및상기 제1 가이드 UI에 대응되는 터치 입력에 기초하여 상기 전자 장치의 컨텍스트가 변경되면, 상기 변경된 컨텍스트 및 상기 시퀀스 정보에 기초하여 상기 복수의 동작 정보 중 제2 동작 정보를 수행하는데 요구되는 터치입력과 관련된 정보에 기초하여 제2 가이드 UI를 제공하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "공개특허 10-2020-0109467-5-제16항에 있어서,상기 터치 입력과 관련된 정보는,상기 터치 입력의 위치 또는 터치 형태 중 적어도 하나를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에 있어서,상기 MRC 모델은,상기 전자 장치의 매뉴얼에 포함된 복수의 문장에 기초하여 NLP를 수행하여 질문을 획득하는 QG(QuestionGeneration) 모델 및 상기 획득된 질문에 대응되는 답변을 획득하는 QA(Question Answer) 모델을 포함하는, 제어 방법."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서,상기 텍스트를 획득하는 단계는,상기 사용자 입력을 서버로 전송하는 단계;를 포함하고,상기 텍스트는,상기 전자 장치의 매뉴얼 및 상기 MRC 모델에 기초하여 획득되는, 제어 방법."}
{"patent_id": "10-2019-0028524", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제12항에 있어서,상기 사용자의 터치 입력의 위치 또는 상기 터치 형태 중 적어도 하나가 상기 가이드 UI에 대응하지 않는 것으로 식별되면, 비주얼 피드백 또는 사운드 피드백 중 적어도 하나를 제공하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0028524", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 전자 장치는, 디스플레이 및 MRC(Machine Reading Comprehension) 모델에 기초하여 사용 자 입력에 대응되는 텍스트를 획득하고, 텍스트를 전자 장치의 동작 단위로 구분하여 복수의 동작 정보를 획득하 고, 복수의 동작 정보 및 획득된 텍스트에 기초하여 복수의 동작 정보의 시퀀스 정보를 획득하고, 시퀀스 정보에 따라 복수의 동작을 순차적으로 수행하기 위한 가이드 UI를 제공하도록 디스플레이를 제어하는 프로세서를 포함 한다."}
{"patent_id": "10-2019-0028524", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 제어 방법들에 대한 것으로, 더욱 상세하게는 MRC(Machine Reading Comprehension) 모 델을 이용하는 전자 장치 및 그 제어 방법에 대한 것이다."}
{"patent_id": "10-2019-0028524", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자 기술이 발달함에 따라, 다양한 유형의 전자 장치가 개발 및 보급되고 있는 실정이다. 전자 장치의 유형뿐만 아니라, 전자 장치가 수행할 수 있는 기능, 동작도 다양해지고 있다. 다만, 전자 장치의 다양한 기능, 동작 등은 실행 방법이 다소 복잡하므로, 최신 전자 장치에 친숙하지 않은 실 버 세대 또는 전자 장치를 다루는데 서툰 사용자에게는 다양한 기능 및 동작에 대한 접근성이 떨어지는 문제가 있다. 사용자에게 전자 장치에 대한 매뉴얼에만 기초하여 다양한 기능 및 동작에 대한 실행 방법, 접근 방법을 고정적 이고 형식적으로 제공하는데 그치는 것이 아니라, 기계 학습(Machine Learning) 알고리즘을 통해 유동적이고 능 동적으로 전자 장치의 사용 방법(예를 들어, 기능 및 동작에 대한 실행 방법, 제어 방법 또는 접근 방법)이 제 공되어야 할 필요성이 있었다."}
{"patent_id": "10-2019-0028524", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 필요성에 따라 안출된 것으로, 본 발명의 목적은 전자 장치의 매뉴얼에 기초하여 사용 방법을 가이드하는 UI를 제공하는 전자 장치 및 그 제어 방법을 제공함에 있다."}
{"patent_id": "10-2019-0028524", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이상과 같은 목적을 달성하기 위한 본 발명의 일 실시 예에 따른 전자 장치는, 디스플레이 및 MRC(Machine Reading Comprehension) 모델에 기초하여 사용자 입력에 대응되는 텍스트를 획득하고, 상기 텍스트를 상기 전자 장치의 동작 단위로 구분하여 복수의 동작 정보를 획득하고, 상기 복수의 동작 정보 및 상기 획득된 텍스트에 기초하여 상기 복수의 동작 정보의 시퀀스 정보를 획득하고, 상기 시퀀스 정보에 따라 상기 복수의 동작을 순차 적으로 수행하기 위한 가이드 UI를 제공하도록 상기 디스플레이를 제어하는 프로세서를 포함한다. 여기서, 상기 동작 단위는, 사용자의 터치 입력이 요구되는 컨텍스트에 기초한 단위일 수 있다. 또한, 상기 프로세서는, 상기 전자 장치의 현재 설정 상태 정보를 획득하고, 상기 현재 설정 상태 정보에 기초 하여 상기 복수의 동작 정보 중 상기 전자 장치에서 기 수행된 적어도 하나의 동작 정보를 식별하고, 상기 식별 된 동작 정보를 제외한 나머지 동작 정보에 기초하여 상기 시퀀스 정보를 획득할 수 있다. 또한, 상기 프로세서는, 상기 전자 장치의 현재 설정 상태 정보를 획득하고, 상기 현재 설정 상태 정보에 기초 하여 상기 복수의 동작 정보 외에 상기 획득된 텍스트에 대응되는 기능을 실행하는데 요구되는 추가 동작 정보 를 획득하고, 상기 복수의 동작 정보 및 상기 추가 동작 정보에 기초하여 상기 시퀀스 정보를 획득할 수 있다. 또한, 상기 프로세서는, 상기 시퀀스 정보에 따라 상기 복수의 동작 정보 중 제1 동작 정보를 수행하는데 요구 되는 터치 입력과 관련된 정보에 기초하여 제1 가이드 UI를 제공하고, 상기 제1 가이드 UI에 대응되는 터치 입 력에 기초하여 상기 전자 장치의 컨텍스트가 변경되면, 상기 변경된 컨텍스트 및 상기 시퀀스 정보에 기초하여 상기 복수의 동작 정보 중 제2 동작 정보를 수행하는데 요구되는 터치 입력과 관련된 정보에 기초하여 제2 가이 드 UI를 제공하도록 상기 디스플레이를 제어할 수 있다. 여기서, 상기 터치 입력과 관련된 정보는, 상기 터치 입력의 위치 또는 터치 형태 중 적어도 하나를 포함할 수 있다. 또한, 상기 MRC 모델은, 상기 전자 장치의 매뉴얼에 포함된 복수의 문장에 기초하여 NLP를 수행하여 질문을 획 득하는 QG(Question Generation) 모델 및 상기 획득된 질문에 대응되는 답변을 획득하는 QA(Question Answer) 모델을 포함할 수 있다. 또한, 통신부를 더 포함하고, 상기 프로세서는, 상기 사용자 입력을 서버로 전송하도록 상기 통신부를 제어하고, 상기 사용자 입력에 대응되는 텍스트가 상기 서버로부터 수신되면, 상기 수신된 텍스트에 기초하여 상기 복수의 동작 정보 및 상기 시퀀스 정보를 획득하고, 상기 텍스트는, 상기 전자 장치의 매뉴얼 및 상기 MRC 모델에 기초하여 획득될 수 있다. 또한, 상기 프로세서는, 상기 사용자의 터치 입력의 위치 또는 상기 터치 형태 중 적어도 하나가 상기 가이드 UI에 대응하지 않는 것으로 식별되면, 비주얼 피드백 또는 사운드 피드백 중 적어도 하나를 제공할 수 있다. 또한, 상기 프로세서는, 수동 모드 또는 자동 모드 중 어느 하나를 선택하기 위한 UI를 제공하고, 상기 자동 모 드가 선택되면, 상기 가이드 UI에 대응되는 터치 입력 기능을 수행하여 상기 복수의 동작을 순차적으로 수행할 수 있다. 여기서, 상기 프로세서는, 상기 가이드 UI에 대응되는 터치 입력 기능을 수행하고 상기 터치 입력 기능이 수행 되었음을 나타내는 시각적 피드백을 제공할 수 있다. 한편, 본 발명의 일 실시 예에 따른 전자 장치의 제어 방법은, MRC(Machine Reading Comprehension) 모델에 기 초하여 사용자 입력에 대응되는 텍스트를 획득하는 단계, 상기 텍스트를 상기 전자 장치의 동작 단위로 구분하 여 복수의 동작 정보를 획득하는 단계, 상기 복수의 동작 정보 및 상기 획득된 텍스트에 기초하여 상기 복수의 동작 정보의 시퀀스 정보를 획득하는 단계 및 상기 시퀀스 정보에 따라 상기 복수의 동작을 순차적으로 수행하 기 위한 가이드 UI를 제공하는 단계를 포함한다. 여기서, 상기 동작 단위는, 사용자의 터치 입력이 요구되는 컨텍스트에 기초한 단위일 수 있다. 또한, 상기 전자 장치의 현재 설정 상태 정보를 획득하는 단계를 포함하고, 상기 시퀀스 정보를 획득하는 단계 는, 상기 현재 설정 상태 정보에 기초하여 상기 복수의 동작 정보 중 상기 전자 장치에서 기 수행된 적어도 하 나의 동작 정보를 식별하는 단계 및 상기 식별된 동작 정보를 제외한 나머지 동작 정보에 기초하여 상기 시퀀스정보를 획득하는 단계를 포함할 수 있다. 또한, 상기 전자 장치의 현재 설정 상태 정보를 획득하는 단계 및 상기 현재 설정 상태 정보에 기초하여 상기 복수의 동작 정보 외에 상기 획득된 텍스트에 대응되는 기능을 실행하는데 요구되는 추가 동작 정보를 획득하는 단계를 포함하고, 상기 시퀀스 정보를 획득하는 단계는, 상기 복수의 동작 정보 및 상기 추가 동작 정보에 기초 하여 상기 시퀀스 정보를 획득하는 단계를 포함할 수 있다. 또한, 상기 가이드 UI를 제공하는 단계는, 상기 시퀀스 정보에 따라 상기 복수의 동작 정보 중 제1 동작 정보를 수행하는데 요구되는 터치 입력과 관련된 정보에 기초하여 제1 가이드 UI를 제공하는 단계 및 상기 제1 가이드 UI에 대응되는 터치 입력에 기초하여 상기 전자 장치의 컨텍스트가 변경되면, 상기 변경된 컨텍스트 및 상기 시 퀀스 정보에 기초하여 상기 복수의 동작 정보 중 제2 동작 정보를 수행하는데 요구되는 터치 입력과 관련된 정 보에 기초하여 제2 가이드 UI를 제공하는 단계를 포함할 수 있다. 여기서, 상기 터치 입력과 관련된 정보는, 상기 터치 입력의 위치 또는 터치 형태 중 적어도 하나를 포함할 수 있다. 또한, 상기 MRC 모델은, 상기 전자 장치의 매뉴얼에 포함된 복수의 문장에 기초하여 NLP를 수행하여 질문을 획 득하는 QG(Question Generation) 모델 및 상기 획득된 질문에 대응되는 답변을 획득하는 QA(Question Answer) 모델을 포함할 수 있다. 또한, 상기 텍스트를 획득하는 단계는, 상기 사용자 입력을 서버로 전송하는 단계를 포함하고, 상기 텍스트는, 상기 전자 장치의 매뉴얼 및 상기 MRC 모델에 기초하여 획득될 수 있다. 또한, 상기 사용자의 터치 입력의 위치 또는 상기 터치 형태 중 적어도 하나가 상기 가이드 UI에 대응하지 않는 것으로 식별되면, 비주얼 피드백 또는 사운드 피드백 중 적어도 하나를 제공하는 단계를 포함할 수 있다."}
{"patent_id": "10-2019-0028524", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 다양한 실시 예에 따르면, 사용자는 사용자 입력에 대응되는 전자 장치의 제어 방법에 대한 직관적인 가이드 UI를 제공받을 수 있고, 전자 장치의 현재 설정 상태를 고려한 사용 방법을 제공받을 수 있게 된다."}
{"patent_id": "10-2019-0028524", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수 치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. A 또는/및 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다. 본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 본 명세서에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전자 장치)를 지칭할 수 있다. 이하 첨부된 도면들을 참조하여 본 개시의 일 실시예를 보다 상세하게 설명한다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치의 구성을 도시한 블록도이다. 본 명세서의 다양한 실시 예들에 따른 전자 장치는 TV, 스마트폰, 태블릿 PC, PMP, PDA, 노트북 PC, 스마 트 워치, HMD(Head mounted Display), NED(Near Eye Display) 등과 같이 디스플레이 기능을 갖춘 장치로 구현 될 수 있다. 전자 장치는 디스플레이 기능을 제공하기 위해 LCD(liquid crystal display), OLED(organic light-emitting diode), LCoS(Liquid Crystal on Silicon), DLP(Digital Light Processing), Micro LED, QD(quantum dot) 디스플레이 패널 등과 같은 다양한 형태의 디스플레이를 구비할 수 있다. 다만, 본 개시에 따른 다양한 실시 예는 디스플레이 기능이 구비되지 않은 전자 장치를 통해서도 구현할 수도 있다. 예를 들어, 블루레이 플레이어(Blu Ray Player), DVD(Digital Versatile Disc) 플레이어, 스트리밍 컨텐츠 출력 장치, 셋탑 박스 등과 같이 컨텐츠를 디스플레이 장치로 제공하는 다양한 유형의 전자 장치가 본 개시의 다양한 실시 예를 구현할 수 있다. 다른 예로, 스피커, 냉장고, 세탁기, 에어컨, 공기 청정기, 각종 사 물 인터넷 장치(internet of things) 등과 같은 다양한 형태의 가전 제품(home appliance)이 본 개시의 다양한 실시 예를 구현할 수도 있음은 물론이다. 이하에서는, 설명의 편의를 위해 전자 장치를 디스플레이가 구비된 사용자 단말 장치로 상정하여 설명하도록 한다. 도 1은 참조하면, 디스플레이 장치는 디스플레이 및 프로세서를 포함한다. 디스플레이는 전자 장치을 통해 제공 가능한 다양한 컨텐츠 화면을 제공할 수 있다. 여기서, 컨텐츠 화면은 어플리케이션 실행 화면, 이미지, 동영상, 텍스트, 음악 등과 같은 다양한 컨텐츠, GUI(Graphic User Interface) 화면 등을 포함할 수 있다. 특히, 디스플레이는 후술하는 바와 같이 전자 장치의 매뉴얼(또는, 사용설명서)에 기초하여 획득된 사용자 입력에 대응되는 텍스트 및 가이드 UI를 디스플레이할 수 있다. 프로세서는 디지털 신호를 처리하는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프 로세서(microprocessor), TCON(Time controller)으로 구현될 수 있다. 다만, 이에 한정되는 것은 아니며, 중앙처리장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), 컨트롤 러(controller), 어플리케이션 프로세서(application processor(AP)), GPU(graphics-processing unit) 또는 커 뮤니케이션 프로세서(communication processor(CP)), ARM 프로세서 중 하나 또는 그 이상을 포함하거나, 해당 용어로 정의될 수 있다. 또한, 프로세서는 프로세싱 알고리즘이 내장된 SoC(System on Chip), LSI(large scale integration)로 구현될 수도 있고, FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 프 로세서는 메모리에 저장된 컴퓨터 실행가능 명령어(computer executable instructions)를 실행함으로써 다양한 기능을 수행할 수 있다. 특히, 프로세서는 MRC(Machine Reading Comprehension) 모델에 기초하여 사용자 입력에 대응되는 텍스트 를 획득할 수 있다. 여기서, MRC 모델은 AI(Artificial Intelligence) 알고리즘에 기초하여 전자 장치에 관한 문서, 매뉴얼을 읽고 해석하는 기계 독해 모델을 의미할 수 있다. 예를 들어, MRC 모델은 RNN(Recurrent Neural Network), CNN(Convolution Neural Network) 등 다양한 유형의 딥 러닝에 기초하여 학습된 NLP(Natural Language Processing, 자연어 처리) 알고리즘을 이용하여 문서를 분석할 수 있다. 한편, 전자 장치에 관한 문서, 매뉴얼 등은 전자 장치의 제조사에 의해 배포되는 사용설명서에 한정되지 않으며, 전자 장치에 포함된 복수의 기능에 대한 조작 방법 또는 이용 방법이 기재된 다양한 형태의 데이터를 포함할 수 있음은 물론 이다. 본 개시의 일 실시 예에 따른 MRC 모델은, GLUE(General Language Understanding Evaluation) 또는 SQuAD(Stanford Question Answering Dataset) 등과 같은 자연어 평가 지표에 적용 가능한 기계 독해 모델일 수 있다. 일 실시 예에 따른 MRC 모델은 문서를 읽고 해석한 뒤, 사용자의 입력(예를 들어, 질문)에 대응되는 텍스 트(예를 들어, 질문에 대응되는 답변)을 해당 문서에 기초하여 찾아내는 모델일 수 있다. 한편, 본 개시의 일 실시 예에 따른 MRC 모델은 Recurrent, Convolution 외에 Transformer 기반 신경망을 이용하여 학습된 모델일 수도 있음은 물론이다. 일 실시 예에 따른 MRC 모델은 전자 장치의 매뉴얼에 포함된 복수의 문장에 기초하여 NLP를 수행하여 질문 을 획득하는 QG(Question Generation) 모델 및 획득된 질문에 대응되는 답변을 획득하는 GA(Question Answer) 모델을 포함할 수 있다. 일 예로, MRC 모델에 포함된 QG 모델은 매뉴얼에 포함된 문장에 기초하여 해당 문장의 키워드(또는, 주제 (subject))를 획득할 수 있다. 이어서, MRC 모델은 해당 문장에서 생성 가능한 복수의 질문 중 최상의 형태의 질문(the best form of question)을 획득할 수 있다. 또한, GA 모델을 해당 문장을 획득된 질문에 대응되는 답 변으로 식별할 수 있다. 한편, 본 개시의 일 실시 예에 따른 프로세서는 전자 장치의 매뉴얼에 포함된 복수의 문장에 전(前) 처리를 수행하여 키워드 별 복수의 질문 및 복수의 질문 각각에 대응되는 답변을 획득할 수 있다. 이에 대한 구 체적인 설명은 도 3을 참조하여 하도록 한다. 도 3은 본 개시의 일 실시 예에 따른 전자 장치 및 사용자 입력을 설명하기 위한 도면이다. 도 3을 참조하면, 본 개시의 일 실시 예에 따른 전자 장치는 사용자 입력을 수신할 수 있다. 예를 들어, 전자 장치는 전자 장치에 구비된 마이크(미도시)를 통해 사용자의 발화 음성을 수신할 수 있다. 다른 예로, 전자 장치는 전자 장치에 구비된 다양한 형태의 인터페이스(예를 들어, 터치 패드) 등을 통해 사용자 입력을 수신할 수 있다. 이하에서는 설명의 편의를 위해 마이크를 통해 사용자의 발화 음성을 사용자 입 력으로 수신하는 경우를 상정하여 설명하도록 한다. 도 3에 도시된 바와 같이, 프로세서는 사용자 입력으로 ‘Wi-Fi랑 블루투스(Bluetooth) 켜줘’가 수신되면, 사용자 입력에 대응되는 텍스트를 획득할 수 있다. 일 예로, 프로세서는 사용자 입력에 NLP 알 고리즘에 기초하여 질문을 식별할 수 있다. 예를 들어, 프로세서는 사용자 입력에 포함된 키워드를 식별할 수 있고, 식별된 키워드에 기초하여 QG 모델로부터 획득된 키워드 별 복수의 질문 중 어느 하나를 선택할 수 있 다. 도 3을 참조하면, 프로세서는 사용자 입력에 구문 파싱(syntactic parsing)을 수행할 수 있다. 이어서, 프 로세서는 파싱된 데이터의 의미 분석(semantic analyzing)을 수행하여 사용자 입력에 포함된 키워드(예를 들어, Wi-Fi, 블루투스 및 켜다)를 식별할 수 있다. 이어서, 프로세서는 복수의 질문 중 식별된 키워드에 대응되는 질문을 획득할 수 있다. 예를 들어, 프로세서는 ‘Wi-Fi 켜는 방법은?’ 및 ‘블루투스 켜는 방 법은?’을 획득할 수 있다.본 개시의 일 실시 예에 따른 프로세서는 획득된 질문에 대응되는 답변을 획득할 수 있다. 일 예로, 프로 세서는 MRC 모델에 기초하여 전자 장치의 매뉴얼에 포함된 문장으로부터 질문을 생성할 수 있고, 해 당 문장을 생성된 질문에 대한 대답으로 획득할 수 있다. 예를 들어, 프로세서는 ‘Wi-Fi 켜는 방법은?’ 이 획득된 문장을 해당 질문에 대한 답변으로 획득할 수 있다. 한편, 이는 일 실시 예에 불과하며 프로세서 는 매뉴얼에 전처리를 수행하여 획득된 복수의 질문 및 복수의 질문 각각에 대한 답변 외에도 사용자 입력 에 NLP를 수행하여 키워드를 식별하고, 식별된 키워드에 대응되는 답변을 획득할 수도 있음을 물론이다. 예를 들어, 프로세서는 ‘어플리케이션 A 설치하는 방법 알려줘’가 수신되면, NLP 알고리즘에 기초하여 어플리 케이션 A 및 설치 방법을 식별할 수 있다. 이어서, 프로세서는 어플리케이션 A를 설치하는 방법에 대한 검 색을 수행하여 서버로부터 답변을 획득할 수도 있음은 물론이다. 한편, 설명의 편의를 위해 이하에서는 사용자 입력에 대응되는 질문에 대한 답변을 사용자 입력에 대응되는 텍스트로 통칭하도록 한다. 한편, 본 개시의 일 실시 예에 따른 프로세서는 MRC 모델에 기초하여 사용자 입력에 대응되는 질문을 출력 할 수도 있다. 일 예로, 프로세서는 사용자 입력에 따라 ‘Wi-Fi 켜는 방법은?’ 및 ‘블루투스 켜는 방법 은?’이 획득되면, ‘Wi-Fi 켜는 방법 및 블루투스 켜는 방법이 궁금하신가요?’등과 같이 사용자의 입력이 제 대로 인식되었는지 여부를 UI로 출력할 수 있다. 해당 UI에 대한 사용자의 확인 입력이 수신되면, 해당 질문에 대응되는 텍스트(또는, 답변)을 획득할 수 있다. 도 1로 돌아와서, 본 개시의 일 실시 예에 따른 프로세서는 사용자 입력에 대응되는 텍스트를 획득하고, 획득된 텍스트에 NLP를 수행하여 텍스트를 전자 장치의 동작 단위로 구분하여 복수의 동작 정보를 획득할 수 있다. 이어서, 프로세서는 복수의 동작 정보 및 획득된 텍스트에 기초하여 복수의 동작 정보의 시퀀스 정보를 획득할 수 있다. 이에 대한 구체적인 설명은 도 4를 참조하여 하도록 한다. 도 4는 본 개시의 일 실시 예에 따른 동작 정보 및 시퀀스 정보를 설명하기 위한 도면이다. 도 4를 참조하면, 본 개시의 일 실시 예에 따른 프로세서는 사용자 입력으로 ‘Wi-Fi 랑 블루투스 켜줘’ 가 수신되면, 전자 장치의 매뉴얼에 포함된 복수의 문장에 기초하여 생성된 복수의 질문 중 ‘Wi-Fi 네트 워크 연결하는 방법은?’ 및 ‘블루투스 연결하는 방법은?’ 질문을 식별할 수 있다. 이어서, 프로세서는 식별된 질문에 대응하는 문장을 해당 질문에 대한 답변(또는, 텍스트)으로 획득할 수 있다. 일 예로, 프로세서 는 전자 장치의 매뉴얼에 포함된 문장 ‘설정 화면에서 연결 버튼을 눌러주세요. → Wi-Fi 토글 버튼 을 왼쪽으로 슬라이딩 해주세요.’를 획득할 수 있다. 또한, 프로세서는 ‘설정 화면에서 연결 버튼을 눌 러주세요. → 블루투스 토글 버튼을 왼쪽으로 슬라이딩 해주세요.’를 사용자 입력에 대응되는 텍스트로 획득할 수 있다. 이어서, 프로세서는 획득된 텍스트에 NLP를 수행하여 전자 장치의 동작 단위로 구분할 수 있다. 여기 서, 전자 장치의 동작 단위는 사용자의 터치 입력이 요구되는 컨텍스트에 기초한 단위일 수 있다. 다만, 전자 장치의 동작 단위는 사용자의 터치 입력이 요구되는지 여부 외에도, 사용자의 터치 입력에 따라 전자 장치의 설정이 변경되거나, 디스플레이를 통해 제공되는 화면이 변경되거나 또는 전자 장치의 상태가 변경되는지 여부에 기초한 단위일 수 있다. 일 예로, 프로세서는 사용자 입력에 대응되는 텍스트 ‘설정 화면에서 연결 버튼을 눌러주세요. → Wi-Fi 토글 버튼을 왼쪽으로 슬라이딩 해주세요.’가 수신되면, 해당 텍스트를 전자 장치의 동작 단위로 구분하 여 설정 버튼, 연결 버튼, Wi-Fi 토글 버튼과 같이 복수의 동작 정보를 획득할 수 있다. 이어서, 프로세서는 복수의 동작 정보 및 해당 텍스트에 기초하여 시퀀스 정보를 획득할 수 있다. 일 예로, 프로세서는 해당 텍스트에 기초하여 복수의 동작 정보 각각에 순서를 설정할 수 있다. 예를 들어, 프로세서는 복수의 동작이 텍스트에 포함된 순서에 기초하여 설정 버튼 → 연결 버튼 → Wi-Fi 토글 버튼 순서로 정렬할 수 있다. 이어서, 프로세서는 복수의 동작에 대한 시퀀스 정보를 획득할 수 있다. 일 실시 예에 따른 프로세서는 시퀀스 정보에 기초하여 복수의 동작 각각에 Fn1, Fn2, …, Fn4를 부여할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는 시퀀스 정보에 따라 복수의 동작을 순차적으로 수행하기 위한 가 이드 UI를 제공할 수 있다. 도 4를 참조하면, 프로세서는 사용자 입력 ‘Wi-Fi랑 블루투스 켜줘’에 대응되는 텍스트에 기초하여 설정 버튼, 연결 버튼, Wi-Fi 토글 버튼, 블루투스 토글 버튼을 복수의 동작으로 획득할 수 있다. 이어서, 프로세서 는 복수의 동작 각각에 순서를 부여하여 시퀀스 정보를 획득할 수 있다. 예를 들어, 프로세서는 설정 버튼 → 연결 버튼 → Wi-Fi 토글 버튼 → 블루투스 토글 버튼 순서로 정렬된 시퀀스 정보를 획득할 수 있다.도 4에 도시된 바와 같이, 프로세서는 시퀀스 정보에 따라 복수의 동작 정보 중 제1 동작 정보(Fn1)를 수 행하는데 요구되는 터치 입력과 관련된 정보에 기초하여 제1 가이드 UI를 디스플레이를 통해 제공할 수 있 다. 예를 들어, 시퀀스 정보에 기초하여 제1 동작 정보(Fn1)가 설정 버튼이면, 프로세서는 설정 버튼에 대 한 터치 입력을 유도하기 위한 가이드 UI를 제공할 수 있다. 일 예로, 프로세서는 디스플레이를 통해 제공되는 화면에서 설정 버튼의 위치에 기 설정된 크기 및 색상의 가이드 UI를 디스플레이할 수 있다. 이어서, 본 개시의 일 실시 예에 따른 프로세서는 제1 가이드 UI에 대응되는 터치 입력에 기초하여 전자 장치의 컨텍스트가 변경되면, 변경된 컨텍스트 및 시퀀스 정보에 기초하여 복수의 동작 정보 중 제2 동작 정보(Fn2)를 수행하는데 요구되는 터치 입력과 관련된 정보에 기초하여 제2 가이드 UI를 제공하도록 디스플레이 를 제어할 수 있다. 여기서, 전자 장치의 컨텍스트의 변경은 터치 입력 수신, 화면의 변경 또는 전자 장치의 설정 변경 중 적어도 하나를 포함할 수 있다. 도 4를 참조하면, 프로세서는 제1 가이드 UI에 대한 터치 입력이 수신됨에 따라 설정 화면이 디스플레이되 면, 시퀀스 정보에 기초하여 제2 동작 정보(Fn2)에 따라 화면 상에서 연결 버튼의 위치에 터치 입력을 유도하기 위한 제2 가이드 UI를 제공할 수 있다. 한편, 터치 입력과 관련된 정보는 터치 입력의 위치에 한정되지 않으며, 터치 형태를 포함할 수도 있음은 물론이다. 예를 들어, 프로세서는 화면 상의 특정 위치에 사용자의 탭 (tap) 터치 입력을 유도하기 위한 가이드 UI를 디스플레이할 수도 있고, 드래그(Drag) 터치, 플릭(Flick) 터치, 핀치(Pinch) 터치, 스프레드(Spread) 터치 등 다양한 터치 형태에 대응하는 가이드 UI를 제공할 수 있다. 이에 대한 구체적인 설명은 도 8에서 하도록 한다. 한편, 본 개시의 일 실시 예에 따른 프로세서는 가이드 UI 외에 스크립트를 제공할 수도 있다. 도 4를 참조하면, 프로세서는 획득된 텍스트에 기초하여 각 동작 정보에 대한 스크립트, 설명을 화면 상 의 일 영역에 제공할 수 있다. 예를 들어, 프로세서는 설정 버튼의 터치를 유도하는 가이드 UI와 함께 ‘설정 버튼을 눌러주세요’와 스크립트를 제공할 수 있다. 다른 예로, 프로세서는 획득된 텍스트 ‘ 설정 화면에서 연결 버튼을 눌러주세요. → Wi-Fi 토글 버튼을 왼쪽으로 슬라이딩 해주세요.’에서 제2 동작 정 보(Fn2)에 대응하는 스크립트 ‘설정 화면에서 연결 버튼을 눌러주세요’를 제2 동작 정보(Fn2)를 수행하는 데 요구되는 터치 입력을 유도하기 위한 제2 가이드 UI와 함께 제공할 수 있다. 또 다른 예로, 제3 동작 정보 (Fn3)에 대응하는 스크립트 ‘Wi-Fi 토글 버튼을 왼쪽으로 슬라이딩 해주세요.’를 제3 동작 정보(Fn3)를 수행하는데 요구되는 터치 입력을 유도하기 위한 제3 가이드 UI와 함께 제공할 수 있다. 한편, 본 개시의 일 실시 예에 따른 프로세서는 화면 상에 가이드 UI와 함께 제공되는 스크립트를 사 운드 신호로 출력할 수도 있다. 예를 들어, 프로세서는 해당 스크립트에 TTS(Text to Speech)를 수행 하여 스크립트에 대응되는 사운드 신호를 획득하고, 해당 사운드 신호를 가이드 UI와 함께 출력할 수도 있다. 도 1로 돌아와서, 본 개시의 일 실시 예에 따른 프로세서는 전자 장치의 현재 설정 상태 정보를 획득 할 수 있다. 여기서, 현재 설정 상태 정보는 전자 장치에 포함된 복수의 기능 각각에 대한 설정 값(예를 들어, 기능 온 / 오프 여부), 전자 장치에 설치된 어플리케이션에 대한 정보(예를 들어, 어플리케이션 설 치 유무, 어플리케이션 버전 정보, 어플리케이션을 실행시키기 위한 아이콘의 위치), 디스플레이를 통해 디스플레이 중인 화면 등을 포함할 수 있다. 일 실시 예에 따른 프로세서는 시스템 레벨에서 현재 설정 상 태 정보를 획득할 수도 있고, API 호출을 통해 현재 설정 상태 정보를 획득할 수도 있다. 본 개시의 일 실시 예에 따른 프로세서는 전자 장치의 현재 설정 상태 정보에 기초하여 텍스트로부터 획득된 복수의 동작 정보 중 일부 동작 정보를 제외시켜 시퀀스 정보를 획득할 수 있다. 다른 예로, 프로세서 는 현재 설정 상태 정보에 기초하여 복수의 동작 정보 외에 다른 동작 정보를 추가하여 시퀀스 정보를 획 득할 수도 있다. 이에 대한 구체적인 설명은 도 5 내지 도 7에 기초하여 하도록 한다. 도 5는 본 개시의 일 실시 예에 따른 현재 설정 상태 정보를 설명하기 위한 도면이다. 도 5를 참조하면, 본 개시의 일 실시 예에 따른 프로세서는 현재 설정 상태 정보에 기초하여 텍스트를 전 자 장치의 동작 단위로 구분하여 획득된 복수의 동작 정보 중 기 수행된 적어도 하나의 동작 정보를 식별 할 수 있다. 일 예로, 사용자 입력(Wi-Fi 랑 블루투스 켜줘)에 대응되는 텍스트 ‘설정 화면에서 연결 버튼을 눌러주세요. → Wi-Fi 토글 버튼을 왼쪽으로 슬라이딩 해주세요.’ 및 ‘설정 화면에서 연결 버튼을 눌러주세요. → 블루투 스 토글 버튼을 왼쪽으로 슬라이딩 해주세요.’를 획득할 수 있다.이어서, 프로세서는 획득된 텍스트를 동작 단위로 구분하여 설정 버튼, 연결 버튼, Wi-Fi 토글 버튼 및 블 루투스 토글 버튼을 복수의 동작 정보로 획득할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는 전자 장치의 현재 설정 상태 정보에 기초하여 복수의 동작 정보 중 기 수행된 동작 정보를 식별할 수 있다. 일 예로, 프로세서는 디스플레이를 통해 제공 중인 화면이 설정 화면이면, 설정 버튼을 터치하는 동작이 기 수행된 것으로 식별할 수 있다. 이 경우, 프로세서는 복수의 동작 정보 중 설정 버튼을 제외시킨 뒤, 나머지 동작 정보에 기초하여 시퀀스 정보를 획득할 수 있다. 다른 예로, 프로세서는 현재 설정 상태 정보 에 기초하여 전자 장치의 Wi-Fi 기능이 온(On) 상태인 것으로 식별되면, 복수의 동작 정보 중 Wi-Fi 토글 버튼을 제외시킨 뒤, 나머지 동작 정보에 기초하여 시퀀스 정보를 획득할 수 있다. 사용자의 입력이 동일하게 ‘Wi-Fi 랑 블루투스 켜줘’임에도 도 5를 참조하면 도 4에 도시된 바와 달리, 프로 세서는 기 수행된 동작 정보로 판단된 Wi-Fi 토글 버튼에 대한 터치 입력을 가이드하는 UI를 제공하지 않 고, 블루투스 토글 버튼에 대한 터치 입력을 가이드하는 UI만을 제공할 수 있다. 도 6은 본 개시의 다른 실시 예에 따른 현재 설정 상태 정보를 설명하기 위한 도면이다. 본 개시의 다양한 실시 예에 따른 프로세서는 사용자 입력에 기초하여 질문을 식별하고, 질문에 대응되는 텍스트(예를 들어, 답변)을 획득할 수 있다. 도 6을 참조하면, 사용자 입력이 ‘내비게이션(Navigation) 사용 방법 알려줘’이면, 프로세서는 MRC 모델에 기초하여 내비게이션을 키워드로 하는 복수의 질문 중 사용자 입력에 가장 근접한 것으로 판단된 어느 하나의 질문 및 답변을 획득할 수 있다. 여기서, 키워드는 반드시 해당 단어가 질문 또는 답변에 포함되어야 함을 의미하지는 않음은 물론이다. 예를 들어, 프로세서는 주제 (Subject)별 복수의 질문 중 사용자 입력에 대응되는 어느 하나의 질문 및 해당 질문에 대응되는 답변을 획득할 수도 있음은 물론이다. 도 6을 참조하면, 일 실시 예에 따른 프로세서는 사용자 입력 ‘내비게이션(Navigation) 사용 방법 알려줘 ’에 대응되는 텍스트 ‘지도 어플리케이션을 눌러주세요. → 마이크 버튼을 누른 뒤 목적지를 말씀해주세요.’ 를 획득할 수 있다. 이어서, 프로세서는 지도 어플리케이션(Fn1), 마이크 버튼(Fn2)에 대한 터치 입력을 순차적으로 유도하기 위한 시퀀스 정보를 획득하고, 시퀀스 정보에 기초하여 가이드 UI 및 스크립트를 제공할 수 있다. 한편, 본 개시의 다른 실시 예에 따른 프로세서는 전자 장치의 현재 설정 상태 정보에 기초하여 추가 동작 정보를 포함하는 시퀀스 정보를 획득할 수도 있다. 여기서, 추가 동작 정보는, 텍스트를 동작 단위로 구분 하여 획득된 복수의 동작 정보 외의 다른 동작 정보를 의미할 수 있다. 이에 대한 구체적인 설명은 도 7에서 하 도록 한다. 도 7은 본 개시의 다른 실시 예에 따른 추가 동작 정보를 설명하기 위한 도면이다. 도 7을 참조하면, 프로세서는 현재 설정 상태 정보에 기초하여 복수의 동작 정보 외에 텍스트에 대응되는 기능을 실행하는데 요구되는 추가 동작 정보를 획득할 수 있다. 예를 들어, 프로세서가 지도 어플리케이션 (Fn1), 마이크 버튼(Fn2)에 대한 터치 입력을 순차적으로 유도하기 위한 시퀀스 정보를 획득한 경우를 상정할 수 있다. 일 실시 예에 따라, 프로세서는 사용자 입력에 대응되는 텍스트 ‘지도 어플리케이션을 눌러주세 요. → 마이크 버튼을 누른 뒤 목적지를 말씀해주세요.’를 수행하기 위해, 현재 설정 상태 정보에 기초하여 지 도 어플리케이션의 설치 유무를 식별할 수 있다. 다른 예로, 프로세서는 전자 장치에 마이크 구비 여 부를 식별할 수도 있다. 본 개시의 일 실시 예에 따라 프로세서는 현재 설정 상태 정보에 기초하여 지도 어플리케이션이 전자 장치 상에 설치되지 않은 것으로 식별되면, 복수의 동작 정보(예를 들어, 지도 어플리케이션(Fn1), 마이크 버 튼(Fn2)) 외에 지도 어플리케이션을 설치하기 위한 동작 정보를 추가 동작 정보로 획득할 수 있다. 이어서, 프 로세서는 복수의 동작 정보 및 추가 동작 정보에 기초하여 시퀀스 정보를 획득할 수 있다. 사용자의 입력이 동일하게 ‘내비게이션(Navigation) 사용 방법 알려줘’임에도 도 7을 참조하면 도 6에 도시된 바와 달리, 프로세서는 스토어 버튼을 누르는 터치 입력을 유도하는 가이드 UI 및 지도 어플리케이션 의 설치를 위한 터치 입력을 유도하는 가이드 UI를 추가적으로 제공할 수 있다. 다른 예로, 본 개시의 일 실시 예에 따른 프로세서는 현재 설정 상태 정보에 기초하여 복수의 동작 정보 외에 텍스트에 대응되는 기능을 실행하는데 요구되는 추가 동작 정보를 획득할 수 있다. 일 예로, 프로세서 는 현재 설정 상태 정보에 전자 장치가 사용자 입력에 대응되도록 동작하기 위해 추가적으로 요구되는 동작을 식별할 수 있다. 예를 들어, 사용자 입력이 ‘내비게이션 사용 방법 알려줘’이면, 프로세서는 지도 어플리케이션(Fn1), 마이크 버튼(Fn2)을 동작 정보로 획득할 수 있다. 이어서, 프로세서는 전자 장치 의 현재 설정 상태 정보에 기초하여 지도 어플리케이션(Fn1)을 실행하기에 적절한 설정 상태인지 식별할 수 있다. 예를 들어, 전자 장치의 GPS 기능이 Off 상태이면, 프로세서는 GPS를 On 시키는 동작(Fn 1- 1)을 MRC 모델에 기초하여 획득할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는 각 동작 별 서브 동작을 식별할 수 있다. 상술한 바와 같이 지도 어플리케이션을 실행시키는 동작(Fn1)에 대응되는 서브 동작은 GPS 기능을 On 시키는 동작(Fn 1-1), 지도 어플 리케이션이 전자 장치의 현지 위치를 식별하는 동작(Fn 1-2) 등을 포함할 수 있다. 이어서, 프로세서(12 0)는 전자 장치의 현재 설정 상태 정보에 기초하여 복수의 서브 동작 중 적어도 하나의 서브 동작을 추가 동작 정보로 식별할 수 있다. 이어서, 프로세서는 복수의 동작 정보 및 추가 동작 정보에 기초하여 시퀀스 정보를 획득할 수 있다. 예를 들어, GPS 기능이 Off 상태이면, 프로세서는 사용자 입력 ‘내비게이션 사용 방법 알려줘’에 대응되는 텍스트에 기초하여 지도 어플리케이션을 실행시키는 동작(Fn1) 및 마이크 버튼을 누 르고 목적지의 발화를 유도하는 동작(Fn2) 외에 GPS 기능을 On 시키는 동작(Fn 1-1)를 추가 동작 정보로 획득할 수 있다. 이어서, 프로세서는 Fn1 → Fn 1-1 → Fn2 순서로 각 동작에 대응되는 가이드 UI를 제공할 수 있 다. 또 다른 예로, 본 개시의 일 실시 예에 따른 프로세서는 복수의 동작 중 어느 하나의 동작을 수행하기 위 해 선행하여 수행될 필요가 있는 추가 동작을 식별할 수도 있음은 물론이다. 예를 들어, 사용자 입력 텍스트가 ‘사전 기능 이용 방법을 알려줘’이면, 프로세서는 검색할 단어 누르기(Fn1), 옵션 목록에서 사전 누르기 (Fn2) 및 검색 결과 확인하기(Fn3)을 복수의 동작 정보로 획득할 수 있다. 한편, 프로세서는 옵션 목록에 서 사전 누르기(Fn2) 동작을 수행하기 위해 선행하여 수행될 필요가 있는 추가 동작으로 ‘사전 어플리케이션 설치하기(Fn 2-1)’를 식별할 수 있다. 이어서, 식별된 추가 동작이 선행하여 배치되도록 시퀀스 정보를 조정할 수 있다. 예를 들어, 동작 정보 및 추가 동작에 기초하여 검색할 단어 누르기(Fn 1) → 사전 어플리케이션 설치 하기(Fn 2-1) → 옵션 목록에서 사전 누르기(Fn 2) → 검색 결과 확인하기(Fn 3) 순서로 각 동작에 대응되는 가 이드 UI를 제공할 수 있다. 한편, 본 개시의 일 실시 예에 따른 프로세서는 전자 장치의 현재 설정 상태 정보에 기초하여 선행 동작을 시퀀스 정보에 포함시키지 않을 수 있음은 물론이다. 예를 들어, 프로세서 는 현재 설정 상태 정보에 기초하여 사전 어플리케이션이 기 설치되어 있는 것으로 식별되면, 사전 어플리 케이션 설치하기(Fn 2-1)가 옵션 목록에서 사전 누르기(Fn 2)에 선행하여 추가되지 않도록 시퀀스 정보를 생성 할 수 있음은 물론이다. 또 다른 실시 예로, 본 개시의 일 실시 예에 따른 프로세서는 가이드 UI를 제공하지 않고, 백그라운드 (background) 상태에서 일부 동작을 자체적으로 수행할 수도 있다. 예를 들어, 사용자 입력이 ‘사전 사용 방법 을 알려줘’ 이고, 프로세서는 이에 대응되는 텍스트에 기초하여 동작 정보 및 추가 동작에 기초하여 검색 할 단어 누르기(Fn 1) → 사전 어플리케이션 설치하기(Fn 2-1) → 옵션 목록에서 사전 누르기(Fn 2) → 검색 결 과 확인하기(Fn 3)를 시퀀스 정보로 획득한 경우를 상정할 수 있다. 이 경우, 프로세서는 선행 동작인 사 전 어플리케이션 설치하기(Fn 2-1)에 대응되는 가이드 UI를 제공하는 대신, 백그라운드 상태에서 프로세서(12 0)가 자체적으로 사전 어플리케이션을 설치할 수도 있다. 이 경우, 사용자에게 제공되는 가이드 UI는 Fn1 → Fn 2 → Fn 3 순서일 수 있다. 도 8은 본 개시의 일 실시 예에 따른 가이드 UI를 설명하기 위한 도면이다. 본 개시의 일 실시 예에 따른 가이드 UI는 사용자의 터치 입력의 위치를 가이드할 수도 있고, 터치 형태를 가이 드할 수도 있다. 일 예로, 프로세서는 획득된 텍스트에 NLP를 수행하여 획득된 복수의 동작 정보 중 어느 하나의 동작 정보를 수행하기 위해 요구되는 터치 형태를 식별할 수 있다. 예를 들어, 도 8에 도시된 바와 같이 사용자 입력이 ‘사진을 어떻게 확대해?’이고, 프로세서는 사용자 입력에 대응하는 텍스트 ‘화면 확대 비율을 조절하려면 화면을 두 손가락으로 누르고 바깥쪽으로 벌려보세요. ’를 획득한 경우를 상정할 수 있다. 이 경우, 프로세서는 스프레드(Spread) 터치 입력을 가이드하는 가이 드 UI를 제공할 수 있다. 도 8에 도시된 바와 같이, 프로세서는 가이드 UI에 포함된 제1 및 제2 오브젝트가 서로 멀어지는 것 같은 애니메이션 효과를 포함하는 가이드 UI를 제공할 수 있다. 또 다른 예로, 사용자 입력이 ‘화면을 어떻게 확대해?’이고, 프로세서는 사용자 입력에 대응하는 텍스트 ‘확대할 화면 영역을 빠르게 세 번 눌러 확대할 수 있습니다.’를 획득할 수 있다. 이 경우, 프로세서는 화면의 일 영역에 세 번의 탭(tap) 터치 입력이 수행되는 것 같은 애니메이션 효과를 포함하는 가이드 UI를제공할 수 있다. 이는 일 실시 예로 이에 한정되지 않는다. 한편, 본 개시의 일 실시 예에 따른 프로세서는 수동 모드 또는 자동 모드 중 어느 하나를 선택하기 위한 UI를 제공할 수 있다. 여기서, 수동 모드는 가이드 UI에 따라 사용자의 터치 입력이 수신되면, 시퀀스 정보 에 기초하여 다음 순서의 동작 정보에 대응되는 가이드 UI를 제공하는 모드일 수 있다. 자동 모드는 가이드 UI에 대응되는 사용자의 터치 입력이 수신되지 않아도, 획득된 텍스트에 따라 전자 장치의 컨텍스트를 변경시키는 모드일 수 있다. 일 예로, 프로세서는 자동 모드에서 사용자의 터치 입력이 수신되지 않았음에도, 가이드 UI에 대응되 는 터치 입력 기능을 수행하고, 터치 입력 기능이 수행되었음을 나타내는 시각적 피드백을 제공할 수 있다. 예 를 들어, 프로세서는 가이드 UI에 대한 터치 입력이 수신된 것과 같은 애니메이션 효과를 제공함과 동 시에 전자 장치의 컨텍스트를 변경시키고, 시퀀스 정보에 기초하여 다음 동작 정보에 대응되는 가이드 UI를 제공할 수 있다. 한편, 이는 일 실시 예로 반드시 이에 한정되지 않는다. 일 예로, 프로세서는 디스플레이를 통해 제 공되는 화면의 변경 없이, 백그라운드에서 시퀀스 정보에 기초하여 전자 장치의 컨텍스트를 순차적으로 변 경시킬 수도 있음은 물론이다. 예를 들어, 사용자 입력에 대응되는 텍스트가 ‘화면을 밝게 조절하려면, 조절 바 위에서 + 방향으로 드래그하세요’이면, 드래그 터치 입력을 가이드하는 UI를 제공할 수도 있고(예를 들어, 수동 모드), 백그라운드로 프로세서가 자체적으로 화면의 밝기를 밝게 조절할 수도 있다(예를 들어, 자동 모드). 도 1로 돌아와서, 본 개시의 일 실시 예에 따른 프로세서는 사용자의 터치 입력의 위치 또는 터치 형태 중 적어도 하나가 가이드 UI에 대응하지 않는 것으로 식별되면, 비주얼 피드백 또는 사운드 피드백 중 적어도 하나를 제공할 수 있다. 이에 대한 구체적인 설명은 도 9를 참조하여 하도록 한다. 도 9는 본 개시의 일 실시 예에 따른 피드백을 설명하기 위한 도면이다. 일 실시 예에 따른 프로세서는 사용자의 터치 입력의 위치가 가이드 UI에 대응하는 것으로 식별되 면, 시퀀스 정보에 기초하여 다음 동작 정보에 대응되는 가이드 UI를 순차적으로 제공할 수 있다. 다른 예로, 프로세서는 사용자의 터치 입력의 위치가 가이드 UI에 대응하지 않는 것으로 식별되면, 피드백을 제공하여 터치 입력을 다시 수행하도록 유도할 수 있다. 도 9를 참조하면, 일 실시 예에 따 라 가이드 UI가 디스플레이에 대한 탭 터치 입력을 유도함에도 불구하고, 사용자의 터치 입력의 위치가 소리 및 진동에 대응되면, 프로세서는 비주얼 피드백 또는 사운드 피드백 중 적어도 하나를 제공할 수 있 다. 여기서, 비주얼 피드백은 가이드 UI의 크기 또는 색상 중 적어도 하나를 변경하는 피드백일 수 있다. 다만, 이는 일 실시 예로 다양한 형태의 비주얼 피드백이 제공될 수 있음은 물론이다. 일 실시 예에 따른 사운드 피드백은 효과음, 비프음 등을 포함할 수 있다. 다른 예로, 사운드 피드백은 가이드 UI에 대응하는 스크립트에 기초한 사운드 신호로 출력하는 피드백일 수 있다. 예를 들어, 도 9를 참조 하면 프로세서는 ‘연결 버튼을 다시 눌러주세요’를 사운드 신호로 출력하는 사운드 피드백을 제공할 수 있다. 도 1로 돌아와서, 본 개시의 일 실시 예에 따른 전자 장치는 통신부(미도시)를 더 포함하고, 프로세서 는 사용자 입력을 서버로 전송하도록 통신부를 제어할 수 있다. 이어서, 프로세서는 사용자 입력에 대응되는 텍스트가 서버로부터 수신되면, 텍스트에 기초하여 복수의 동작 정보 및 시퀀스 정보를 획득할 수 있 다. 여기서, 텍스트는 전자 장치의 매뉴얼 및 MRC 모델에 기초하여 획득될 수 있다. 이에 대한 구체적인 설명은 도 10에 기초하여 설명하도록 한다. 도 10은 본 개시의 일 실시 예에 따른 서버와 통신을 수행하는 전자 장치를 설명하기 위한 도면이다. 도 10을 참조하면, 전자 장치는 서버와 통신을 수행할 수 있다. 프로세서는 사용자 입력을 서버 로 전송하고, 서버부터 사용자 입력에 대응되는 텍스트를 수신할 수 있다. 여기서, 서버는 전자 장치에 관한 문서, 매뉴얼 또는 사용설명서 등에 기초하여 MRC 모델에 따른 복수의 질문 및 답변 데이터 셋(dataset)을 포함할 수 있다. 한편, 이는 일 실시 예로, 질문과 해당 질문에 대응되는 답변이 하나의 쌍으로 존재하여야만 하는 것은 아니다. 일 예로, 서버는 사용자 입력에 NLP를 수행하여 키워드, 주제 등을 획득 하고, 획득된 키워드, 주제 등에 기초한 검색 결과로부터 사용자 입력에 대응되는 텍스트(또는, 답변)를 획득할 수도 있음은 물론이다.도 2는 도 1에 도시된 전자 장치의 세부 구성을 나타내는 블록도이다. 도 2를 참조하면, 본 개시의 일 실시 예의 전자 장치는 디스플레이, 프로세서, 통신부, 스 토리지, 사용자 인터페이스, 입출력 인터페이스, 마이크 및 스피커를 포함할 수 있다. 도 2에 도시된 구성 중 도 1에 도시된 구성과 중복되는 구성에 대해서는 자세한 설명을 생략하도록 한다. 프로세서는 스토리지에 저장된 각종 프로그램을 이용하여 전자 장치의 동작을 전반적으로 제어 한다. 구체적으로, 프로세서는 RAM, ROM, 메인 CPU, 제1 내지 n 인터페이스(134-1 ~ 134-n), 버 스를 포함한다. RAM, ROM, 메인 CPU, 제1 내지 n 인터페이스(134-1 ~ 134-n) 등은 버스를 통해 서로 연결 될 수 있다. ROM에는 시스템 부팅을 위한 명령어 세트 등이 저장된다. 턴온 명령이 입력되어 전원이 공급되면, 메인 CPU는 ROM에 저장된 명령어에 따라 스토리지에 저장된 O/S를 RAM에 복사하고, O/S를 실행 시켜 시스템을 부팅시킨다. 부팅이 완료되면, 메인 CPU는 스토리지에 저장된 각종 어플리케이션 프로 그램을 RAM에 복사하고, RAM에 복사된 어플리케이션 프로그램을 실행시켜 각종 동작을 수행한다. 메인 CPU는 스토리지에 액세스하여, 스토리지에 저장된 O/S를 이용하여 부팅을 수행한다. 그리 고, 스토리지에 저장된 각종 프로그램, 컨텐츠 데이터 등을 이용하여 다양한 동작을 수행한다. 제1 내지 n 인터페이스(134-1 내지 134-n)는 상술한 각종 구성 요소들과 연결된다. 인터페이스들 중 하나는 네 트워크를 통해 외부 장치와 연결되는 네트워크 인터페이스가 될 수도 있다. 한편, 프로세서는 그래픽 처리 기능(비디오 처리 기능)을 수행할 수 있다. 예를 들어, 프로세서는 연 산부(미도시) 및 렌더링부(미도시)를 이용하여 아이콘, 이미지, 텍스트 등과 같은 다양한 객체를 포함하는 화면 을 생성할 수 있다. 여기서, 연산부(미도시)는 수신된 제어 명령에 기초하여 화면의 레이아웃에 따라 각 객체들 이 표시될 좌표값, 형태, 크기, 컬러 등과 같은 속성값을 연산할 수 있다. 그리고, 렌더링부(미도시)는 연산부 (미도시)에서 연산한 속성값에 기초하여 객체를 포함하는 다양한 레이아웃의 화면을 생성할 수 있다. 또한, 프 로세서는 비디오 데이터에 대한 디코딩, 스케일링, 노이즈 필터링, 프레임 레이트 변환, 해상도 변환 등과 같은 다양한 이미지 처리를 수행할 수 있다. 한편, 프로세서는 오디오 데이터에 대한 처리를 수행할 수 있다. 구체적으로, 프로세서는 오디오 데 이터에 대한 디코딩이나 증폭, 노이즈 필터링 등과 같은 다양한 처리가 수행될 수 있다. 통신부는 다양한 유형의 통신방식에 따라 다양한 유형의 외부 장치와 통신을 수행하는 구성이다. 통신부 는 와이파이 모듈, 블루투스 모듈, 적외선 통신 모듈 및 무선 통신 모듈 등을 포함한 다. 여기서, 각 통신 모듈은 적어도 하나의 하드웨어 칩 형태로 구현될 수 있다. 프로세서는 통신부를 이용하여 각종 외부 장치와 통신을 수행할 수 있다. 여기서, 외부 장치는 TV와 같은 디스플레이 장치, set-top box와 같은 영상 처리 장치, 외부 서버, 리모컨과 같은 제어 장치, 블루투스 스 피커와 같은 음향 출력 장치, 조명 장치, 스마트 청소기, 스마트 냉장고와 같은 가전 기기, IOT 홈 매니저 등과 같은 서버 등을 포함할 수 있다. 와이파이 모듈, 블루투스 모듈은 각각 WiFi 방식, 블루투스 방식으로 통신을 수행한다. 와이파이 모 듈이나 블루투스 모듈을 이용하는 경우에는SSID 및 세션 키 등과 같은 각종 연결 정보를 먼저 송수신 하여, 이를 이용하여 통신 연결한 후 각종 정보들을 송수신할 수 있다. 적외선 통신 모듈은 시 광선과 밀리미터파 사이에 있는 적외선을 이용하여 근거리에 무선으로 데이터를 전 송하는 적외선 통신(IrDA, infrared Data Association)기술에 따라 통신을 수행한다. 무선 통신 모듈은 상술한 통신 방식 이외에 지그비(zigbee), 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), LTE-A(LTE Advanced), 4G(4th Generation), 5G(5th Generation)등과 같은 다양한 무선 통신 규격에 따라 통신을 수행하는 적어도 하나의 통신 칩을 포함할 수 있다. 그 밖에 통신부는LAN(Local Area Network) 모듈, 이더넷 모듈, 또는 페어 케이블, 동축 케이블 또는 광섬 유 케이블 등을 이용하여 통신을 수행하는 유선 통신 모듈 중 적어도 하나를 포함할 수 있다. 일 예에 따라 통신부는 리모컨과 같은 외부 장치 및 외부 서버와 통신하기 위해 동일한 통신 모듈(예를 들 어, Wi-Fi 모듈)을 이용할 수 있다. 다른 예에 따라 통신부는 리모컨과 같은 외부 장치 및 외부 서버와 통신하기 위해 상이한 통신 모듈(예를 들어, Wi-Fi 모듈)을 이용할 수 있다. 예를 들어, 통신부는 외부 서버와 통신하기 위해 이더넷 모듈 또는 WiFi 모듈 중 적어도 하나를 이용할 수 있고, 리모컨과 같은 외부 장치와 통신하기 위해 BT 모듈을 이용할 수도 있다. 다만 이는 일 실시 예에 불과하며 통신부는 복수의 외부 장치 또는 외부 서버와 통신하는 경우 다양 한 통신 모듈 중 적어도 하나의 통신 모듈을 이용할 수 있다. 한편, 전자 장치는 구현 예에 따라 튜너 및 복조부를 추가적으로 포함할 수 있다. 튜너(미도시)는 안테나를 통해 수신되는 RF(Radio Frequency) 방송 신호 중 사용자에 의해 선택된 채널 또는 기 저장된 모든 채널을 튜닝하여 RF 방송 신호를 수신할 수 있다. 복조부(미도시)는 튜너에서 변환된 디지털 IF 신호(DIF)를 수신하여 복조하고, 채널 복호화 등을 수행할 수도 있다. 스토리지는 프로세서에 포함된 롬(ROM)(예를 들어, EEPROM(electrically erasable programmable read-only memory)), 램(RAM) 등의 내부 메모리로 구현되거나, 프로세서와 별도의 메모리로 구현될 수도 있다. 이 경우, 스토리지는 데이터 저장 용도에 따라 전자 장치에 임베디드된 메모리 형태로 구현되 거나, 전자 장치에 탈부착이 가능한 메모리 형태로 구현될 수도 있다. 예를 들어, 전자 장치의 구동 을 위한 데이터의 경우 전자 장치에 임베디드된 메모리에 저장되고, 전자 장치의 확장 기능을 위한 데이터의 경우 전자 장치에 탈부착이 가능한 메모리에 저장될 수 있다. 한편, 전자 장치에 임베디드 된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나로 구현되고, 전자 장치에 탈부착 이 가능한 메모리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포 트에 연결가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구현될 수 있다. 사용자 인터페이스는 버튼, 터치 패드, 마우스 및 키보드와 같은 장치로 구현되거나, 상술한 디스플레이 기능 및 조작 입력 기능도 함께 수행 가능한 터치 스크린으로도 구현될 수 있다. 여기서, 버튼은 전자 장치 의 본체 외관의 전면부나 측면부, 배면부 등의 임의의 영역에 형성된 기계적 버튼, 터치 패드, 휠 등과 같 은 다양한 유형의 버튼이 될 수 있다. 입출력 인터페이스는 HDMI(High Definition Multimedia Interface), MHL (Mobile High-Definition Link), USB (Universal Serial Bus), DP(Display Port), 썬더볼트(Thunderbolt), VGA(Video Graphics Array) 포트, RGB 포트, D-SUB(D-subminiature), DVI(Digital Visual Interface) 중 어느 하나의 인터페이스일 수 있 다. 입출력 인터페이스는 오디오 및 비디오 신호 중 적어도 하나를 입출력 할 수 있다. 구현 예에 따라, 입출력 인터페이스는 오디오 신호만을 입출력하는 포트와 비디오 신호만을 입출력하는 포 트를 별개의 포트로 포함하거나, 오디오 신호 및 비디오 신호를 모두 입출력하는 하나의 포트로 구현될 수 있다. 전자 장치는 디스플레이를 포함하지 않는 장치로 구현되어, 별도의 디스플레이 장치로 영상 신호를 전송할 수 있다. 한편, 전자 장치는 마이크를 포함하는 외부 장치로부터 사용자 음성 신호를 수신할 수 있다. 이 경우, 수 신된 사용자 음성 신호는 디지털 음성 신호일 수 있으나, 구현 예에 따라 아날로그 음성 신호일 수 있다. 일 예 로, 전자 장치는 Bluetooth 또는 Wi-Fi 등의 무선 통신 방법을 통해 사용자 음성 신호를 수신할 수 있다. 여기서, 외부 장치는 원격 제어 장치 또는 스마트폰으로 구현될 수 있다. 전자 장치는 외부 장치로부터 수신된 음성 신호의 음성 인식을 위해, 외부 서버로 해당 음성 신호를 전송 할 수 있다. 이 경우, 외부 장치 및 외부 서버와의 통신을 위한 통신 모듈은 하나로 구현되거나, 별개로 구현될 수 있다. 예 를 들어, 외부 장치와는 Bluetooth 모듈을 이용하여 통신하고, 외부 서버와는 이더넷 모뎀 또는 Wi-Fi모듈을 이 용하여 통신할 수 있다. 본 개시의 일 실시 예에 따른 전자 장치는 음성 인식 서버로 수신된 사용자 입력을 전송할 수 있다. 이 경 우, 음성 인식 서버는 STT(Speech To Text)를 이용하여 사용자 입력을 텍스트 정보로 변환할 수 있다. 이 경우, 음성 인식 서버는 텍스트 정보에 대응되는 검색을 수행하기 위하여 다른 서버 또는 전자 장치로 텍스트 정보를 전송할 수 있으며, 경우에 따라서는 직접 검색을 수행하는 것도 가능하다. 한편, 본 개시의 다른 실시 예에 따른 전자 장치는 사용자 입력에 직접 STT(Speech To Text) 기능을 적용 하여 텍스트 정보로 변환하고 변환된 텍스트 정보를 외부 서버에 전송할 수도 있다. 한편, 전자 장치는 마이크를 더 포함할 수 있다. 마이크는 사용자 음성이나 기타 소리를 입력받아 오 디오 데이터로 변환하기 위한 구성이다. 마이크는 활성화 상태에서 사용자의 음성을 수신할 수 있다. 예를 들어, 마이크는 전자 장치의 상측 이나 전면 방향, 측면 방향 등에 일체화된 일체형으로 형성될 수 있다. 마이크는 아날로그 형태의 사용자 음성 을 수집하는 마이크, 수집된 사용자 음성을 증폭하는 앰프 회로, 증폭된 사용자 음성을 샘플링하여 디지털 신호 로 변환하는 A/D 변환회로, 변환된 디지털 신호로부터 노이즈 성분을 제거하는 필터 회로 등과 같은 다양한 구 성을 포함할 수 있다. 한편, 다른 실시 예에 따라, 전자 장치는 마이크를 구비하는 외부 장치(미도시)로부터 사용자 음성을 수신 할 수 있다. 예를 들어, 외부 장치는 마이크를 포함하는 원격 제어 장치(리모컨)로 구현될 수 있으나 이에 한정 되는 것은 아니다. 여기서, 원격 제어 장치(리모컨)가 사용자의 아날로그 음성 신호를 마이크를 통해 수신하면, 원격 제어 장치(리모컨)는 아날로그 음성 신호를 디지털 음성 신호로 변환할 수 있다. 그리고 원격 제어 장치 (리모컨)는 적외선, 와이파이 또는 블루투스 통신 방식 중 적어도 하나를 이용하여 변환된 디지털 음성 신호를 전자 장치로 전송할 수 있다. 전자 장치는 디지털 음성 신호가 외부 장치로부터 수신되면, 수신된 디 지털 음성 신호에 기초하여 음성 인식을 수행하고, 음성 인식 결과에 기초하여 제어 동작을 수행할 수 있다. 다 만 다른 실시 예에 따르면, 원격 제어 장치(리모컨)가 디지털 음성 신호에 대한 음성 인식 동작을 수행하고, 음 성 인식 결과에 대응되는 정보를 전자 장치에 전송하는 형태로 구현될 수 있다. 여기서, 음성 인식 결과에 대응되는 정보는, 음성 인식 결과 그 자체 또는 음성 인식 결과에 대응되는 제어 명령 중 적어도 하나일 수 있 다. 한편, 또 다른 실시 예에 따라, 외부 장치는 마이크를 포함하는 스마트폰으로 구현될 수 있다. 이 경우, 스마트 폰은 기 설치된 원격 제어 기능을 수행하는 원격 제어 어플리케이션을 이용하여 전자 장치를 원격으로 제 어할 수 있다. 스마트 폰은 사용자의 아날로그 음성 신호가 마이크를 통해 수신되면, 아날로그 음성 신호를 디지털 음성 신호 로 변환할 수 있다. 이 경우, 스마트폰은 음성 인식 어플리케이션을 이용하여 디지털 음성 신호에 대한 음성 인 식을 수행할 수 있다. 여기서, 음성 인식 어플리케이션은 상술한 원격 제어 어플리케이션과 동일하거나, 상이한 어플리케이션일 수 있다. 스마트폰은 디지털 음성 신호에 대한 음성 인식 인식이 수행되면, 음성 인식 결과에 기초하여 원격 제어 어플리케이션을 이용하여 전자 장치를 원격으로 제어할 수 있다. 다만 다른 실시 예에 따르면, 스마트 폰은 적외선, 와이파이 또는 블루투스 통신 방식 중 적어도 하나를 이용하여 변환된 디지털 음 성 신호를 전자 장치로 전송할 수 있다. 이 경우, 전자 장치는 디지털 음성 신호가 외부 장치로부터 수신되면, 수신된 디지털 음성 신호에 기초하여 음성 인식을 수행하고, 음성 인식 결과에 기초하여 제어 동작을 수행할 수 있다. 스피커는 입출력 인터페이스에서 처리된 각종 오디오 데이터뿐만 아니라 각종 알림 음이나 음성 메시 지 등을 출력하는 구성요소일 수 있다. 도 11은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 본 발명의 일 실시 예에 따른 디스플레이 장치의 제어 방법은, 우선, MRC(Machine Reading Comprehension) 모 델에 기초하여 사용자 입력에 대응되는 텍스트를 획득한다(S1110).이어서, 텍스트를 전자 장치의 동작 단위로 구분하여 복수의 동작 정보를 획득한다(S1120). 이어서, 복수의 동작 정보 및 획득된 텍스트에 기초하여 복수의 동작 정보의 시퀀스 정보를 획득한다(S1130). 이어서, 시퀀스 정보에 따라 복수의 동작을 순차적으로 수행하기 위한 가이드 UI를 제공한다(S1140). 여기서, 동작 단위는, 사용자의 터치 입력이 요구되는 컨텍스트에 기초한 단위일 수 있다. 또한, 본 개시의 일 실시 예에 따른 제어 방법은, 전자 장치의 현재 설정 상태 정보를 획득하는 단계를 포함하 고, 시퀀스 정보를 획득하는 S1130 단계는, 현재 설정 상태 정보에 기초하여 복수의 동작 정보 중 전자 장치에 서 기 수행된 적어도 하나의 동작 정보를 식별하는 단계 및 식별된 동작 정보를 제외한 나머지 동작 정보에 기 초하여 시퀀스 정보를 획득하는 단계를 포함할 수 있다. 본 개시의 일 실시 예에 따른 제어 방법은, 전자 장치의 현재 설정 상태 정보를 획득하는 단계 및 현재 설정 상 태 정보에 기초하여 복수의 동작 정보 외에 획득된 텍스트에 대응되는 기능을 실행하는데 요구되는 추가 동작 정보를 획득하는 단계를 포함하고, 시퀀스 정보를 획득하는 S1130 단계는, 복수의 동작 정보 및 추가 동작 정보 에 기초하여 시퀀스 정보를 획득하는 단계를 포함할 수 있다. 또한, 가이드 UI를 제공하는 S1140 단계는, 시퀀스 정보에 따라 복수의 동작 정보 중 제1 동작 정보를 수행하는 데 요구되는 터치 입력과 관련된 정보에 기초하여 제1 가이드 UI를 제공하는 단계 및 제1 가이드 UI에 대응되는 터치 입력에 기초하여 전자 장치의 컨텍스트가 변경되면, 변경된 컨텍스트 및 시퀀스 정보에 기초하여 복수의 동작 정보 중 제2 동작 정보를 수행하는데 요구되는 터치 입력과 관련된 정보에 기초하여 제2 가이드 UI를 제공 하는 단계를 포함할 수 있다. 여기서, 터치 입력과 관련된 정보는, 터치 입력의 위치 또는 터치 형태 중 적어도 하나를 포함할 수 있다. 본 개시의 일 실시 예에 따른 MRC 모델은, 전자 장치의 매뉴얼에 포함된 복수의 문장에 기초하여 NLP를 수행하 여 질문을 획득하는 QG(Question Generation) 모델 및 획득된 질문에 대응되는 답변을 획득하는 QA(Question Answer) 모델을 포함할 수 있다. 또한, 텍스트를 획득하는 S1110 단계는, 사용자 입력을 서버로 전송하는 단계를 포함하고, 여기서, 텍스트는, 전자 장치의 매뉴얼 및 MRC 모델에 기초하여 획득될 수 있다. 본 개시의 일 실시 예에 따른 제어 방법은, 사용자의 터치 입력의 위치 또는 터치 형태 중 적어도 하나가 가이 드 UI에 대응하지 않는 것으로 식별되면, 비주얼 피드백 또는 사운드 피드백 중 적어도 하나를 제공하는 단계를 포함할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 설치 가능한 어플리케이션 형태 로 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 대한 소프트웨어 업그레이드, 또 는 하드웨어 업그레이드 만으로도 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들은 전자 장치에 구비된 임베디드 서버, 또는 전자 장치 및 디스플레이 장치 중 적어도 하나의 외부 서버를 통해 수행되는 것도 가능하다. 한편, 본 개시의 일시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기 기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 전자 장치(예: 전자 장치(A))를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 프로세서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임 시적으로 저장됨을 구분하지 않는다. 또한, 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품 (computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read onlymemory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있 다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 상술한 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구 성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요 소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로 그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동 작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2019-0028524", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2019-0028524", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 전자 장치의 구성을 도시한 블록도이다. 도 2는 도 1에 도시된 전자 장치의 세부 구성을 나타내는 블록도이다. 도 3은 본 개시의 일 실시 예에 따른 전자 장치 및 사용자 입력을 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시 예에 따른 동작 정보 및 시퀀스 정보를 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따른 현재 설정 상태 정보를 설명하기 위한 도면이다. 도 6은 본 개시의 다른 실시 예에 따른 현재 설정 상태 정보를 설명하기 위한 도면이다. 도 7은 본 개시의 다른 실시 예에 따른 추가 동작 정보를 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시 예에 따른 가이드 UI를 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시 예에 따른 피드백을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시 예에 따른 서버와 통신을 수행하는 전자 장치를 설명하기 위한 도면이다. 도 11은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다."}
