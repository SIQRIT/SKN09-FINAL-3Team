{"patent_id": "10-2023-0125735", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0042521", "출원번호": "10-2023-0125735", "발명의 명칭": "학습 장치, 학습 방법 및 이를 이용한 테스트 장치 및 테스트 방법", "출원인": "현대자동차주식회사", "발명자": "박진호"}}
{"patent_id": "10-2023-0125735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "타겟 이미지 및 적어도 하나의 소스 이미지를 획득하는 획득부;상기 타겟 이미지에 기반하여 추정 뎁스 맵을 생성하는 추정 뎁스 맵 생성 네트워크;상기 타겟 이미지 및 상기 소스 이미지 간 포즈 변화에 대응되는 포즈 변화 정보를 생성하는 포즈 변화 정보 생성 네트워크;상기 추정 뎁스 맵, 상기 포즈 변화 정보 및 상기 소스 이미지를 이용하여 상기 타겟 이미지에 대응되는 합성이미지를 생성하는 합성 이미지 생성부;상기 합성 이미지 및 상기 타겟 이미지에 기반하여 제1 로스를 산출하고, 상기 타겟 이미지에 대응되는 의사(pseudo) 뎁스 맵 및 상기 추정 뎁스 맵에 기반하여 제2 로스를 산출하는 로스 산출부; 및상기 제1 로스 및 상기 제2 로스를 백프로퍼게이션(back-propagation)하여, 상기 추정 뎁스 맵 생성 네트워크의파라미터 및 상기 포즈 변화 정보 생성 네트워크의 파라미터를 업데이트하는 파라미터 업데이트부를 포함하는학습 장치."}
{"patent_id": "10-2023-0125735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 로스 산출부는,상기 의사 뎁스 맵 및 상기 추정 뎁스 맵 각각의 휘도(luminance) 정보, 대비(contrast) 정보 및 구조(structure) 정보 중 적어도 일부를 참조하여 상기 제2 로스를 산출하는 것을 특징으로 하는 학습 장치."}
{"patent_id": "10-2023-0125735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 휘도 정보에 대응되는 제1 가중치는 상기 대비 정보에 대응되는 제2 가중치 및 상기 구조 정보에 대응되는제3 가중치보다 작은 것을 특징으로 하는 학습 장치."}
{"patent_id": "10-2023-0125735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 타겟 이미지는 특정 시점에 특정 이미지 센서에 의해 생성되고, 상기 소스 이미지는 상기 특정 시점에 대응되는 주변 시점에 상기 특정 이미지 센서에 의해 생성되는 것을 특징으로 하는 학습 장치."}
{"patent_id": "10-2023-0125735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,상기 포즈 변화 정보 생성 네트워크는,상기 특정 이미지 센서의 상기 특정 시점에서의 제1 포즈 및 상기 주변 시점에서의 제2 포즈에 기반하여 상기포즈 변화 정보를 생성하는 것을 특징으로 하는 학습 장치."}
{"patent_id": "10-2023-0125735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 4에 있어서,상기 합성 이미지 생성부는,상기 추정 뎁스 맵에 기반하여 상기 특정 시점에서의 3차원 포인트 클라우드 정보를 획득하고, 상기 포즈 변화공개특허 10-2025-0042521-3-정보에 기반하여 상기 특정 시점에서의 3차원 포인트 클라우드 정보를 상기 주변 시점에서의 3차원 포인트 클라우드 정보로 변환하며, 상기 특정 이미지 센서에 대응되는 이미지 센서 파라미터에 기반하여 상기 주변 시점에서의 3차원 포인트 클라우드 정보를 2차원 이미지 좌표로 변환하고, 상기 2차원 이미지 좌표에 대응되는 상기소스 이미지의 픽셀값에 기반하여 상기 합성 이미지를 생성하는 것을 특징으로 하는 학습 장치."}
{"patent_id": "10-2023-0125735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서,상기 타겟 이미지에 기반하여 상기 의사 뎁스 맵을 생성하는 의사 뎁스 맵 생성 네트워크를 더 포함하는 것을특징으로 하는 학습 장치."}
{"patent_id": "10-2023-0125735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서,상기 의사 뎁스 맵 생성 네트워크의 파라미터는 고정(freezing)된 상태인 것을 특징으로 하는 학습 장치."}
{"patent_id": "10-2023-0125735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 1 내지 청구항 8 중 어느 한 항의 학습 방법을 수행하여 업데이트된 파라미터를 이용하는 테스트 장치에있어서,테스트용 타겟 이미지를 획득하는 획득부; 및테스트용 타겟 이미지에 기반하여 테스트용 추정 뎁스 맵을 생성하는 추정 뎁스 맵 생성 네트워크를 포함하는테스트 장치."}
{"patent_id": "10-2023-0125735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "에 있어서,상기 타겟 이미지는 특정 시점에 특정 이미지 센서에 의해 생성되고, 상기 소스 이미지는 상기 특정 시점에 대응되는 주변 시점에 상기 특정 이미지 센서에 의해 생성되는 것을 특징으로 하는 학습 방법."}
{"patent_id": "10-2023-0125735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 10에 있어서,상기 제2 로스를 산출하는 단계에서,상기 의사 뎁스 맵 및 상기 추정 뎁스 맵 각각의 휘도(luminance) 정보, 대비(contrast) 정보 및 구조(structure) 정보 중 적어도 일부를 참조하여 상기 제2 로스를 산출하는 것을 특징으로 하는 학습 방법."}
{"patent_id": "10-2023-0125735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서,상기 휘도 정보에 대응되는 제1 가중치는 상기 대비 정보에 대응되는 제2 가중치 및 상기 구조 정보에 대응되는제3 가중치보다 작은 것을 특징으로 하는 학습 방법.공개특허 10-2025-0042521-4-청구항 13"}
{"patent_id": "10-2023-0125735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 13에 있어서,상기 포즈 변화 정보를 출력하는 단계에서,상기 특정 이미지 센서의 상기 특정 시점에서의 제1 포즈 및 상기 주변 시점에서의 제2 포즈에 기반하여 상기포즈 변화 정보를 생성하는 것을 특징으로 하는 학습 방법."}
{"patent_id": "10-2023-0125735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 13에 있어서,상기 합성 이미지를 생성하는 단계는,상기 추정 뎁스 맵에 기반하여 상기 특정 시점에서의 3차원 포인트 클라우드 정보를 획득하는 단계;상기 포즈 변화 정보에 기반하여 상기 특정 시점에서의 3차원 포인트 클라우드 정보를 상기 주변 시점에서의 3차원 포인트 클라우드 정보로 변환하는 단계;상기 특정 이미지 센서에 대응되는 이미지 센서 파라미터에 기반하여 상기 주변 시점에서의 3차원 포인트 클라우드 정보를 2차원 이미지 좌표로 변환하는 단계; 및상기 2차원 이미지 좌표에 대응되는 상기 소스 이미지의 픽셀값에 기반하여 상기 합성 이미지를 생성하는 단계를 포함하는 것을 특징으로 하는 학습 방법."}
{"patent_id": "10-2023-0125735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 10에 있어서,상기 제2 로스를 산출하는 단계 이전에,기학습된 의사 뎁스 맵 생성 네트워크가 상기 타겟 이미지에 기반하여 상기 의사 뎁스 맵을 생성하는 단계를 더포함하는 것을 특징으로 하는 학습 방법."}
{"patent_id": "10-2023-0125735", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 학습 장치, 학습 방법 및 이를 이용한 테스트 장치 및 테스트 방법에 관한 것으로, 타겟 이미지 및 적 어도 하나의 소스 이미지를 획득하는 획득부; 상기 타겟 이미지에 기반하여 추정 뎁스 맵을 생성하는 추정 뎁스 맵 생성 네트워크; 상기 타겟 이미지 및 상기 소스 이미지 간 포즈 변화에 대응되는 포즈 변화 정보를 생성하는 (뒷면에 계속)"}
{"patent_id": "10-2023-0125735", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 문서에 개시되는 실시예들은 학습 장치, 학습 방법 및 이를 이용한 테스트 장치 및 테스트 방법에 관한 것으 로, 구체적으로는, 자기 지도 학습에 기반하는 학습 장치, 학습 방법 및 이를 이용한 테스트 장치 및 테스트 방 법에 관한 것이다."}
{"patent_id": "10-2023-0125735", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 자율 주행 기술에서 심층 신경망 기반의 컴퓨터 비전 기술이 발전함에 따라 객체 인식(object detection), 시멘틱 세그멘테이션(semantic segmentation), 깊이 영상 추출(depth map estimation), 차선 감지(lane detection) 등 다양한 인공지능 모델이 연구되었다. 가령, 깊이 영상 추출(depth map estimation)은, 자율 주행 상황에서 카메라를 이용하여 주변 객체 및 자유 공 간(free space) 등에 대한 주변 상황 및 공간을 인지하기 위해 다양하게 활용되고 있는데, 일반적으로 뎁스 맵 을 생성하는 네트워크를 학습하기 위해서는 레이블이 부여된 대량의 학습용 데이터(가령, 학습용 뎁스 맵)이 필 요하다. 하지만 상기와 같은 학습용 데이터를 구축하기 위해서는 대량의 이미지 각각에 레이블을 부여한 후 이를 검수하 는 과정이 필수적으로 수행되어야 하는 바. 뎁스 맵 생성 네트워크를 학습시키기 위한 학습용 데이터를 확보하 는 단계에서부터 막대한 시간 및 비용이 소모되는 문제점이 존재하였다."}
{"patent_id": "10-2023-0125735", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 문서에 개시된 실시예들은 자기 지도 학습에 기반하는 학습 장치, 학습 방법 및 이를 이용한 테스트 장치 및 테스트 방법을 제공하고자 한다. 본 문서에 개시된 실시예들은 뎁스 맵 생성 네트워크를 학습시키기 위한 학습용 데이터를 확보하는데 소모되는 시간 및 비용을 절감하기 위한 학습 장치, 학습 방법 및 이를 이용한 테스트 장치 및 테스트 방법을 제공하고자 한다. 본 문서에 개시된 실시예들은 뎁스 맵 생성 네트워크가 이미지 시퀀스에 기반하여 깊이 정보를 정확하게 추정하 기 위한 학습 장치, 학습 방법 및 이를 이용한 테스트 장치 및 테스트 방법을 제공하고자 한다. 본 문서에 개시된 실시예들은 이미지 내 동적 객체 또는 가려진 객체에 대한 깊이 정보를 정확하게 추정하기 위 한 학습 장치, 학습 방법 및 이를 이용한 테스트 장치 및 테스트 방법을 제공하고자 한다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재들로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0125735", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 문서에 개시된 일 실시예에 따른 학습 장치는, 타겟 이미지 및 적어도 하나의 소스 이미지를 획득하는 획득 부; 상기 타겟 이미지에 기반하여 추정 뎁스 맵을 생성하는 추정 뎁스 맵 생성 네트워크; 상기 타겟 이미지 및 상기 소스 이미지 간 포즈 변화에 대응되는 포즈 변화 정보를 생성하는 포즈 변화 정보 생성 네트워크; 상기 추 정 뎁스 맵, 상기 포즈 변화 정보 및 상기 소스 이미지를 이용하여 상기 타겟 이미지에 대응되는 합성 이미지를 생성하는 합성 이미지 생성부; 상기 합성 이미지 및 상기 타겟 이미지에 기반하여 제1 로스를 산출하고, 상기 타겟 이미지에 대응되는 의사(pseudo) 뎁스 맵 및 상기 추정 뎁스 맵에 기반하여 제2 로스를 산출하는 로스 산 출부; 및 상기 제1 로스 및 상기 제2 로스를 백프로퍼게이션(back-propagation)하여, 상기 추정 뎁스 맵 생성 네트워크의 파라미터 및 상기 포즈 변화 정보 생성 네트워크의 파라미터를 업데이트하는 파라미터 업데이트부를 포함할 수 있다. 일 실시예에 있어서, 상기 로스 산출부는, 상기 의사 뎁스 맵 및 상기 추정 뎁스 맵 각각의 휘도(luminance) 정 보, 대비(contrast) 정보 및 구조(structure) 정보 중 적어도 일부를 참조하여 상기 제2 로스를 산출할 수 있다. 일 실시예에 있어서, 상기 휘도 정보에 대응되는 제1 가중치는 상기 대비 정보에 대응되는 제2 가중치 및 상기 구조 정보에 대응되는 제3 가중치보다 작을 수 있다. 일 실시예에 있어서, 상기 타겟 이미지는 특정 시점에 특정 이미지 센서에 의해 생성되고, 상기 소스 이미지는 상기 특정 시점에 대응되는 주변 시점에 상기 특정 이미지 센서에 의해 생성될 수 있다. 일 실시예에 있어서, 상기 포즈 변화 정보 생성 네트워크는, 상기 특정 이미지 센서의 상기 특정 시점에서의 제 1 포즈 및 상기 주변 시점에서의 제2 포즈에 기반하여 상기 포즈 변화 정보를 생성할 수 있다. 일 실시예에 있어서, 상기 합성 이미지 생성부는, 상기 추정 뎁스 맵에 기반하여 상기 특정 시점에서의 3차원 포인트 클라우드 정보를 획득하고, 상기 포즈 변화 정보에 기반하여 상기 특정 시점에서의 3차원 포인트 클라우 드 정보를 상기 주변 시점에서의 3차원 포인트 클라우드 정보로 변환하며, 상기 특정 이미지 센서에 대응되는 이미지 센서 파라미터에 기반하여 상기 주변 시점에서의 3차원 포인트 클라우드 정보를 2차원 이미지 좌표로 변 환하고, 상기 2차원 이미지 좌표에 대응되는 상기 소스 이미지의 픽셀값에 기반하여 상기 합성 이미지를 생성할 수 있다. 일 실시예에 있어서, 상기 타겟 이미지에 기반하여 상기 의사 뎁스 맵을 생성하는 의사 뎁스 맵 생성 네트워크 를 더 포함할 수 있다. 일 실시예에 있어서, 상기 의사 뎁스 맵 생성 네트워크의 파라미터는 고정(freezing)된 상태일 수 있다. 본 문서에 개시된 일 실시예에 따른 테스트 장치는, 테스트용 타겟 이미지를 획득하는 획득부; 및 테스트용 타 겟 이미지에 기반하여 테스트용 추정 뎁스 맵을 생성하는 추정 뎁스 맵 생성 네트워크를 포함할 수 있다. 본 문서에 개시된 일 실시예에 따른 학습 방법은 타겟 이미지 및 적어도 하나의 소스 이미지를 획득하는 단계; 상기 타겟 이미지에 기반하여 추정 뎁스 맵을 생성하는 단계; 상기 타겟 이미지 및 상기 소스 이미지 간 포즈 변화에 대응되는 포즈 변화 정보를 생성하는 단계; 상기 추정 뎁스 맵, 상기 포즈 변화 정보 및 상기 소스 이미 지를 이용하여 상기 타겟 이미지에 대응되는 합성 이미지를 생성하는 단계; 상기 합성 이미지 및 상기 타겟 이 미지에 기반하여 제1 로스를 산출하는 단계; 상기 타겟 이미지에 대응되는 의사(pseudo) 뎁스 맵 및 상기 추정 뎁스 맵에 기반하여 제2 로스를 산출하는 단계; 및 상기 제1 로스 및 상기 제2 로스를 백프로퍼게이션(back- propagation)하여, 상기 추정 뎁스 맵을 생성하는 추정 뎁스 맵 생성 네트워크의 파라미터 및 상기 포즈 변화 정보를 생성하는 포즈 변화 정보 생성 네트워크의 파라미터를 업데이트하는 단계를 포함할 수 있다. 일 실시예에 있어서, 상기 제2 로스를 산출하는 단계에서, 상기 의사 뎁스 맵 및 상기 추정 뎁스 맵 각각의 휘 도(luminance) 정보, 대비(contrast) 정보 및 구조(structure) 정보 중 적어도 일부를 참조하여 상기 제2 로스 를 산출하는 것을 특징으로 하는 학습 방법. 일 실시예에 있어서, 상기 휘도 정보에 대응되는 제1 가중치는 상기 대비 정보에 대응되는 제2 가중치 및 상기 구조 정보에 대응되는 제3 가중치보다 작을 수 있다. 일 실시예에 있어서, 상기 타겟 이미지는 특정 시점에 특정 이미지 센서에 의해 생성되고, 상기 소스 이미지는 상기 특정 시점에 대응되는 주변 시점에 상기 특정 이미지 센서에 의해 생성될 수 있다. 일 실시예에 있어서, 상기 포즈 변화 정보를 출력하는 단계에서, 상기 특정 이미지 센서의 상기 특정 시점에서 의 제1 포즈 및 상기 주변 시점에서의 제2 포즈에 기반하여 상기 포즈 변화 정보를 생성할 수 있다. 일 실시예에 있어서, 상기 합성 이미지를 생성하는 단계는, 상기 추정 뎁스 맵에 기반하여 상기 특정 시점에서 의 3차원 포인트 클라우드 정보를 획득하는 단계; 상기 포즈 변화 정보에 기반하여 상기 특정 시점에서의 3차원 포인트 클라우드 정보를 상기 주변 시점에서의 3차원 포인트 클라우드 정보로 변환하는 단계; 상기 특정 이미지 센서에 대응되는 이미지 센서 파라미터에 기반하여 상기 주변 시점에서의 3차원 포인트 클라우드 정보를 2차원 이미지 좌표로 변환하는 단계; 및 상기 2차원 이미지 좌표에 대응되는 상기 소스 이미지의 픽셀값에 기반하여 상기 합성 이미지를 생성하는 단계를 포함할 수 있다. 일 실시예에 있어서, 상기 제2 로스를 산출하는 단계 이전에, 기학습된 의사 뎁스 맵 생성 네트워크가 상기 타 겟 이미지에 기반하여 상기 의사 뎁스 맵을 생성하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2023-0125735", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 기술은 자기 지도 학습에 기반하는 학습 장치, 학습 방법 및 이를 이용한 테스트 장치 및 테스트 방법을 제 공하고자 한다. 본 기술은 뎁스 맵 생성 네트워크를 학습시키기 위한 학습용 데이터를 확보하는데 소모되는 시간 및 비용을 절 감하기 위한 학습 장치, 학습 방법 및 이를 이용한 테스트 장치 및 테스트 방법을 제공하고자 한다. 본 기술은 뎁스 맵 생성 네트워크가 이미지 시퀀스에 기반하여 깊이 정보를 정확하게 추정하기 위한 학습 장치, 학습 방법 및 이를 이용한 테스트 장치 및 테스트 방법을 제공하고자 한다. 본 기술은 이미지 내 동적 객체 또는 가려진 객체에 대한 깊이 정보를 정확하게 추정하기 위한 학습 장치, 학습 방법 및 이를 이용한 테스트 장치 및 테스트 방법을 제공하고자 한다. 이 외에, 본 문서를 통해 직접적 또는 간접적으로 파악되는 다양한 효과들이 제공될 수 있다."}
{"patent_id": "10-2023-0125735", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 일부 실시예들을 예시적인 도면을 통해 상세하게 설명한다. 각 도면의 구성요소들에 참조부호 를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명의 실시예를 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 실시예에 대한 이해를 방해한다고 판단되는 경우에는 그 상세한 설명은 생략한 다. 본 발명의 실시예의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소 의 본질이나 차례 또는 순서 등이 한정되지 않는다. 또한, 다르게 정의되지 않는 한, 기술적이거나 과학적인 용 어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들 은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정 의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하, 도 1 내지 도 8을 참조하여, 본 발명의 실시예들을 구체적으로 설명하기로 한다. 도 1은 본 문서에 개시된 일 실시예에 따른 학습 장치의 구성을 나타내는 블록도이다. 도 1을 참조하면, 학습 장치는 획득부, 추정 뎁스 맵 생성 네트워크, 포즈 변화 정보 생성 네트워크, 합 성 이미지 생성부, 로스 산출부 및 파라미터 업데이트부를 포함할 수 있다. 또한, 학습 장치는 의사 뎁스 맵 생성 네트워크를 추가로 포함할 수 있다. 다만, 후술하겠지만, 의사 뎁스 맵 생성 네트워크는 본 문서에 개시된 일 실시예에 따른 학습 장치의 필수적인 구성은 아니다. 아래에서는 본 문서에 개시된 일 실시예에 따른 학습 장치의 동작에 대해서 도 2를 참조하여 좀 더 구체적으로 설명하기로 한다. 먼저, 획득부는, 타겟 이미지 및 적어도 하나의 소스 이미지를 획득할 수 있다. 일례로, 타겟 이미지는 특정 시점에 특정 이미지 센서에 의해 생성될 수 있으며, 소스 이미지는 특정 시점에 대 응되는 주변 시점에 특정 이미지 센서에 의해 생성될 수 있다. 이때, 주변 시점은, 특정 시점을 기준으로 하는 임계 시구간 내의 시점들 중, 특정 시점을 제외한 나머지 시점 중 적어도 하나의 시점일 수 있다. 일례로, 타겟 이미지 및 소스 이미지는 특정 시점을 포함하는 시구간에 획득되는 이미지 시퀀스일 수 있다. 또한, 추정 뎁스 맵 생성 네트워크는, 타겟 이미지에 기반하여 추정 뎁스 맵을 생성할 수 있다. 일례로, 추정 뎁스 맵 생성 네트워크는 인코더 및 디코더를 포함하는 유-넷(U-net)구조의 네트워크일 수 있다. 이때, 인코더는 ResNet 모델이고, 디코더는 시그모이드 출력을 뎁스 맵으로 변환하는 동작을 수행하는 모델일 수 있다. 또한, 포즈 변화 정보 생성 네트워크는, 타겟 이미지 및 소스 이미지 간 포즈 변화에 대응되는 포즈 변화 정보 를 생성할 수 있다. 일례로, 포즈 변화 정보 생성 네트워크는, 특정 이미지 센서의 특정 시점에서의 제1 포즈 및 주변 시점에서의 제2 포즈에 기반하여 포즈 변화 정보를 생성할 수 있다. 일례로, 포즈 변화 정보는, 특정 시점에서의 카메라 포즈 및 주변 시점에서의 카메라 포즈 간 관계를 나타내는 정보로서, 회전(rotation) 및 변환(translation) 행렬에 대응되는 정보일 수 있다. 또한, 합성 이미지 생성부는, 추정 뎁스 맵, 포즈 변화 정보 및 소스 이미지를 이용하여 타겟 이미지에 대응되 는 합성 이미지를 생성할 수 있다.일례로, 합성 이미지 생성부는, 추정 뎁스 맵에 기반하여 특정 시점에서의 3차원 포인트 클라우드 정보를 획득 할 수 있다. 그리고, 합성 이미지 생성부는, 포즈 변화 정보에 기반하여 특정 시점에서의 3차원 포인트 클라우드 정보를 주 변 시점에서의 3차원 포인트 클라우드 정보로 변환할 수 있다. 그리고, 합성 이미지 생성부는, 특정 이미지 센서에 대응되는 이미지 센서 파라미터(intrinsic parameter)에 기 반하여 주변 시점에서의 3차원 포인트 클라우드 정보를 2차원 이미지 좌표로 변환할 수 있다. 그리고, 합성 이미지 생성부는, 2차원 이미지 좌표에 대응되는 소스 이미지의 픽셀값에 기반하여 합성 이미지를 생성할 수 있다. 일례로, 합성 이미지 생성부는, 추정 뎁스 맵의 (10, 20)에 대응되는 특정 시점에서의 3차원 포인트 클라우드 정보를 포즈 변화 정보에 기반하여 주변 시점에서의 3차원 포인트 클라우드 정보로 변환할 수 있다. 그리고, 합 성 이미지 생성부는, 이미지 센서 파라미터에 기반하여 추정 뎁스 맵의 (10, 20)에 대응되는 주변 시점에서의 3 차원 포인트 클라우드 정보를 2차원 이미지 좌표(가령, (15,18))로 변환할 수 있다. 그리고, 합성 이미지 생성부는, 주변 시점에서의 2차원 이미지 좌표(15, 18)에 대응되는 소스 이미지의 픽셀 값 (가령, 218)을 (10, 20)에 부여함으로써 합성 이미지를 생성할 수 있다. 만약, 포즈 변화 정보가 정확하다면, 합성 이미지의 각각의 픽셀(가령, (30,50))에 부여되는 소스 이미지의 픽 셀 값은 타겟 이미지의 동일한 위치의 픽셀(가령, (30, 50))에 부여되는 픽셀 값(가령, 251)과 동일/유사 할 것이며, 포즈 변화 정보가 부정확하다면, 합성 이미지의 각각의 픽셀(가령, (30,50))에 부여되는 소스 이미 지의 픽셀 값은 타겟 이미지의 동일한 위치의 픽셀(가령, (30, 50))에 부여되는 픽셀 값(가령, 89)과 큰 차이를 가질 것이다. 또한, 로스 산출부는, 합성 이미지 및 타겟 이미지에 기반하여 제1 로스를 산출하고, 타겟 이미지에 대응되는 의사(pseudo) 뎁스 맵 및 추정 뎁스 맵에 기반하여 제2 로스를 산출할 수 있다. 참고로, 합성 이미지 및 타겟 이미지에 기반하는 제1 로스만을 이용하여 학습된 추정 뎁스 맵 생성 네트워크는, 동적인 객체(dynamic object) 또는 일부가 가려진 객체(occlusion)에 대해서 객체 경계가 흐릿하게 표현되는 추 정 뎁스 맵을 생성할 수 있다. 따라서, 동적인 객체 또는 일부가 가려진 객체에 대해서도 객체 경계가 선명하게 표현되는 추정 뎁스 맵을 생성 하기 위하여, 제1 로스뿐만 아니라, 의사 뎁스 맵 및 추정 뎁스 맵 간 오차에 기반하는 제2 로스를 추정 뎁스 맵 생성 네트워크의 학습에 추가로 이용할 수 있다. 이때, 의사 뎁스 맵은 의사 뎁스 맵 생성 네트워크로부터 획득될 수 있는데, 본 문서에 개시된 일 실시예에 따 른 학습 장치는 의사 뎁스 맵 생성 네트워크에 의해 생성된 의사 뎁스 맵을 획득할 수도 있으나, 이에 한정되는 것은 아니다. 일례로, 학습 장치는 의사 뎁스 맵(pseudo depth map) 생성 네트워크를 추가로 포함할 수 있다. 이때, 의사 뎁스 맵 생성 네트워크는 타겟 이미지에 기반하여 의사 뎁스 맵을 생성할 수 있다. 참고로, 의사 뎁 스 맵 생성 네트워크의 파라미터는 고정(freezing)된 상태일 수 있다. 일례로, 의사 뎁스 맵 생성 네트워크는 사전에 대량의 학습 데이터 셋을 이용하여 학습된 네트워크로서, 본 문 서에 개시된 일 실시예에 따른 추정 뎁스 맵 생성 네트워크에 비하여 더 많은 개수의 레이어를 포함하고, 더 많 은 개수의 파라미터를 포함하는 대용량 네트워크일 수 있다. 참고로, 의사 뎁스 맵 생성 네트워크는 대용량 네트워크라는 점에서, 한정된 자원을 가지는 장치(가령, 차량)에 는 상기와 같은 대용량 네트워크가 탑재되기 어려운 문제점이 존재한다. 한편, 의사 뎁스 맵 생성 네트워크로부 터 출력되는 뎁스 맵은, 본 문서에 개시된 일 실시예에 따른 추정 뎁스 맵 생성 네트워크로부터 출력되는 뎁스 맵보다 그 정확도가 높다. 따라서, 실제 탑재되는 네트워크(즉, 추정 뎁스 맵 생성 네트워크)의 정확도를 높이고, 학습 데이터를 구축하는 데 필요한 비용을 절감하기 위해서 이러한 대용량 네트워크의 장점(즉, 높은 정확도)만을 이용할 수 있다. 즉, 추정 뎁스 맵 생성 네트워크의 학습을 위한 정답 데이터로서, 의사 뎁스 맵 생성 네트워크의 출력이 이용될 수 있다.참고로, 의사 뎁스 맵 생성 네트워크의 의사 뎁스 맵 정확도는 추정 뎁스 맵 생성 네트워크의 추정 뎁스 맵 정 확도보다 상대적으로 높기는 하지만, 검수자가 수동으로 일일히 검수하는 과정을 거쳐 생성되는 GT(ground truth) 뎁스 맵의 정확도보다는 낮을 수 있다. 따라서, 의사 뎁스 맵 및 추정 뎁스 맵에 대응되는 리그레션 기반 손실 함수에 기반하여 생성되는 로스만을 단 순히 이용하여 추정 뎁스 맵 생성 네트워크를 학습할 경우, 추정 뎁스 맵 생성 네트워크의 정확도가 낮을 수 있 다. 다만, 도 3의 의사 뎁스 맵(도 3의 두번째 행에 위치하는 이미지들)에서 확인할 수 있듯이, 기학습된 대용량 네 트워크로부터 생성되는 의사 뎁스 맵은, 원본 이미지와 형태(shape) 또는 구조(structure)적인 면에서 매우 유 사한 정보를 포함한다. 따라서, 이러한 장점을 추정 뎁스 맵 생성 네트워크의 학습에 이용할 수 있는데, 즉, GT 뎁스 맵보다 정확도가 상대적으로 낮기는 하지만, 원본 이미지의 형태 또는 구조에 대한 정보는 GT 뎁스 맵만큼 정확한 정보를 포함하 는 의사 뎁스 맵에 기반하는 제2 로스를 이용하여 추정 뎁스 맵 생성 네트워크를 학습할 수 있다. 즉, 이미지 시퀀스에 기반하는 제1 로스를 이용하여 비지도학습(자기 지도 학습)을 수행하는 동시에, 의사 뎁스 맵 생성 네트워크로부터의 의사 GT 맵(의사 뎁스 맵)에 기반하는 제2 로스를 이용하여 지도 학습을 수행하여 추 정 뎁스 맵 생성 네트워크의 성능을 대폭 상승시킬 수 있다. 일례로, 로스 산출부는, 합성 이미지 및 타겟 이미지에 기반하여 제1 로스를 산출할 수 있다. 일례로, 로스 산출부는, 합성 이미지 및 타겟 이미지 각각의 휘도(luminance) 정보, 대비(contrast) 정보 및 구 조(structure) 정보 중 적어도 일부를 참조하여 제1 로스를 산출할 수 있다. 참고로, 제1 로스의 수식은 아래와 같다. [수식 1]"}
{"patent_id": "10-2023-0125735", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이때, pe(Ia, Ib)는 제1 로스, Ia는 타겟 이미지, Ib는 합성 이미지, SSIM(Ia, Ib)는 Ia 및 Ib 간 유사도(휘도 정 보, 대비 정보 및 구조 정보 중 적어도 일부의 유사도), ||Ia - Ib||1는 Ia 및 Ib 간 픽셀별 픽셀 값의 리그레션 로스(L1 로스), a는 SSIM(구조적 유사도 인덱스 맵; Structural Similarity Index Map) 및 L1 로스의 가중합 비율 조정 파라미터일 수 있다. 참고로, 참고로, 수식 1의 제1 로스는 이해를 돕기 위한 예시일 뿐, 본 문서에 개시된 일 실시예에 따른 제1 로스가 상기 수식 1로 한정되는 것은 아니다. 가령, 제1 로스는, ||Ia - Ib||1 및 a를 포함하지 않을 수 있다. 참고로, SSIM의 수식은 아래와 같다. [수식 2] SSIM(Ia, Ib) = [l(Ia, Ib)]α * [c(Ia, Ib)]β * [s(Ia, Ib)]γ 이때, α, β, γ는 기설정된 값을 가질 수 있다. 가령, α, β, γ의 값은 1일 수 있다. 또한, l(휘도; luminance), c(대비; contrast) 및 s(구조; structural) 각각의 수식은 아래와 같다. [수식 3]"}
{"patent_id": "10-2023-0125735", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이때, c1, c2, c3는 기설정되는 상수이며, μ는 평균값, σ는 표준편차일 수 있다. 또한, 로스 산출부는 타겟 이미지에 대응되는 의사 뎁스 맵 및 추정 뎁스 맵에 기반하여 제2 로스를 산출할 수 있다. 일례로, 로스 산출부는, 의사 뎁스 맵 및 추정 뎁스 맵 각각의 휘도 정보, 대비 정보 및 구조 정보 중 적어도 일부를 참조하여 제2 로스를 산출할 수 있다. 참고로, 제2 로스의 수식은 아래와 같다. [수식 4]"}
{"patent_id": "10-2023-0125735", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이때, pe(Ia, Ib)는 제2 로스, Ia는 의사 뎁스 맵, Ib는 추정 뎁스 맵, SSIM(Ia, Ib)는 Ia 및 Ib 간 유사도(휘도 정보, 대비 정보 및 구조 정보 중 적어도 일부의 유사도)일 수 있다. 참고로, SSIM의 수식은 수식 2를 통해 설 명한 바 있으므로, 중복되는 설명은 생략하기로 한다. 이때, 휘도 정보에 대응되는 제1 가중치(α)는, 대비 정보에 대응되는 제2 가중치(β) 및 구조 정보에 대응되는 제3 가중치(γ)보다 작을 수 있다. 가령, α의 값은 0이고, β의 값 및 γ의 값은 1일 수 있다. 다만, 이는 이해를 돕기 위한 예시일 뿐, 본 발명 이 상기 예시에 한정되는 것은 아니다. 일례로, 제1 가중치(α) 및 제2 가중치(β)는 제3 가중치(γ)보다 작을 수 있다. 또한, 파라미터 업데이트부는, 제1 로스 및 제2 로스를 백프로퍼게이션(back-propagation)하여, 추정 뎁스 맵 생성 네트워크의 파라미터 및 포즈 변화 정보 생성 네트워크의 파라미터를 업데이트할 수 있다. 도 5는 학습 장치의 동작을 도시한 흐름도이다. 도 5를 참조하면, 동작 510에서, 학습 장치는 타겟 이미지 및 적어도 하나의 소스 이미지를 획득할 수 있다. 그리고, 동작 520_1에서, 학습 장치는 타겟 이미지에 기반하여 추정 뎁스 맵을 생성하며, 동작 520_2에서, 학습 장치는 타겟 이미지 및 소스 이미지 간 포즈 변화에 대응되는 포즈 변화 정보를 생성할 수 있다. 그리고, 동작 530에서, 학습 장치는 추정 뎁스 맵, 포즈 변화 정보 및 소스 이미지를 이용하여 타겟 이미지에 대응되는 합성 이미지를 생성할 수 있다. 그리고, 동작 540_1에서, 학습 장치는 합성 이미지 및 타겟 이미지에 기반하여 제1 로스를 산출하며, 동작 540_2에서, 학습 장치는 타겟 이미지에 대응되는 의사 뎁스 맵 및 추정 뎁스 맵에 기반하여 제2 로스를 산출할 수 있다. 그리고, 동작 550에서, 학습 장치는 제1 로스 및 제2 로스를 백프로퍼게이션(back-propagation)하여, 추정 뎁스 맵을 생성하는 추정 뎁스 맵 생성 네트워크의 파라미터 및 포즈 변화 정보를 생성하는 포즈 변화 정보 생성 네 트워크의 파라미터를 업데이트할 수 있다. 한편, 상기에서 설명한 학습 장치를 이용하여 파라미터가 업데이트된 추정 뎁스 맵 생성 네트워크를 포함 하는 테스트 장치에 대해서 도 6 내지 도 8을 참조하여 아래에서 설명하기로 한다. 참고로, 학습 장치와 동일/유사한 설명에 대해서는 중복되는 설명을 생략하기로 한다. 도 6은 본 문서에 개시된 일 실시예에 따른 테스트 장치의 구성을 나타내는 블록도이다. 도 6을 참조하면, 본 문서에 개시된 일 실시 예에 따른 테스트 장치는, 획득부 및 추정 뎁스 맵 생성 네 트워크를 포함할 수 있다. 참고로, 포즈 변화 정보 생성 네트워크, 합성 이미지 생성부, 로스 산출부, 파라미터 업데이트부 및 의사 뎁스 맵 생성 네트워크는, 추정 뎁스 맵 생성 네트워크의 정확도를 높이기 위해 학습 단계에서 필요한 구성에 해당하 므로, 도 1에서 도시한 학습 장치의 구성과 비교할 때, 테스트 장치는, 포즈 변화 정보 생성 네트워크, 합성 이 미지 생성부, 로스 산출부, 파라미터 업데이트부 및 의사 뎁스 맵 생성 네트워크를 포함하지 않는 것을 확인할 수 있다. 아래에서는 본 문서에 개시된 일 실시예에 따른 테스트 장치의 동작에 대해서 도 7을 참조하여 좀 더 구체적으 로 설명하기로 한다. 먼저, 획득부는, 테스트용 타겟 이미지를 획득할 수 있다. 전술한 바와 같이, 추정 뎁스 맵 생성 네트워크의 학 습이 완료된 상태이므로, 추정 뎁스 맵 생성 네트워크를 학습하기 위해 추가로 필요한 소스 이미지는 추정 뎁스 맵 생성 네트워크의 추론(inference)에 필요하지 않을 수 있다. 그리고, 추정 뎁스 맵 생성 네트워크는, 테스트용 타겟 이미지에 기반하여 테스트용 추정 뎁스 맵을 생성할 수 있다. 도 8은 테스트 장치의 동작을 도시하는 도면이다. 도 8을 참조하면, 동작 810에서, 테스트 장치는 테스트용 타겟 이미지를 획득할 수 있다. 그리고, 동작 820에서, 테스트 장치는 테스트용 타겟 이미지에 기반하여 테스트용 추정 뎁스 맵을 생성할 수 있 다. 한편, (i) 본 문서에 개시된 일 실시예에 따라 제1 로스 및 제2 로스를 이용하여 학습된 뎁스 맵 추정 네트워크 및 (ii) 제1 로스만을 이용하여 학습된 네트워크의 성능을 비교하였다. 이때, 2개 네트워크의 성능 비교를 위해 서, 전방 카메라를 통해 획득된 이미지 및 이에 대응되는 라이다 데이터를 이용하였다. 동일한 데이터를 이용하여 a1 스코어를 통해 성능을 확인한 결과, 제1 로스만을 이용하여 학습된 네트워크의 경 우 72.34%의 정확도를 나타낸 반면에, 제1 로스 및 제2 로스를 이용하여 학습된 네트워크는 87.93%의 정확도를 나타낸 것으로 확인된 바, 본 문서에 개시된 일 실시예에 따라 제1 로스 및 제2 로스를 이용하여 학습된 추정 뎁스 맵 생성 네트워크의 정확도가 훨씬 우수한 점을 확인할 수 있었다. 이에 대해서는 도 4a 및 도 4b를 통해서도 확인할 수 있다. 참고로, 왼쪽 열은 입력 이미지이고, 가운데 열은 제1 로스만을 이용하여 학습된 네트워크가 상기 입력 이미지에 대해 생성한 출력 뎁스 맵이며, 오른쪽 열은 본 문서에 개시된 일 실시예에 따라 제1 로스 및 제2 로스를 이용하여 학습된 추정 뎁스 맵 생성 네트워크가 상기 입력 입력 이미지에 대해 생성한 출력 뎁스 맵이다. 도 4a 및 도 4b를 참조하면, 제1 로스만을 이용하여 학습된 네트워크에 비해, 본 문서에 개시된 일 실시예에 따 라 제1 로스 및 제2 로스를 이용하여 학습된 추정 뎁스 맵 생성 네트워크가 생성한 뎁스 맵의 정확도가 훨씬 높 은 것을 확인할 수 있다. 구체적으로, 깊이 정보뿐만 아니라, 객체의 형태 및/또는 구조에 대한 정보에 있어서, 본 문서에 개시된 일 실 시예에 따른 추정 뎁스 맵 생성 네트워크의 정확도가 훨씬 높은 것을 확인할 수 있다. 특히, 도 4a와 같이 이미지 내 동적인 객체(dynamic object)가 포함된 경우에도, 추정 뎁스 맵 상에서 객체의 형태가 뭉개지지 않은 점을 확인할 수 있다. 이를 통해, 단안 카메라로부터 획득되는 이미지 시퀀스만으로도 정확도가 높은 추정 뎁스 맵 생성 네트워크를 학습시킬 수 있게 된다. 또한, 제2 로스를 통해 추정 뎁스 맵 네트워크를 학습시킴으로써, 동적인 객체(dynamic object) 또는 일부가 가 려진 객체(occlusion)에 대해서도 객체 경계가 선명하게 표현되는 추정 뎁스 맵을 생성할 수 있게 된다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위 에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4a 도면4b 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2023-0125735", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 문서에 개시된 일 실시예에 따른 학습 장치의 구성을 나타내는 블록도이다. 도 2 내지 도 4b는 본 문서에 개시된 일 실시예에 따른 학습 장치의 동작을 설명하기 위한 도면이다. 도 5는 본 문서에 개시된 일 실시예에 따른 학습 방법을 설명하기 위한 흐름도이다. 도 6은 본 문서에 개시된 일 실시예에 따른 테스트 장치의 구성을 나타내는 블록도이다.도 7은 본 문서에 개시된 일 실시예에 따른 테스트 장치의 동작을 설명하기 위한 도면이다. 도 8은 본 문서에 개시된 일 실시예에 따른 테스트 방법을 설명하기 위한 흐름도이다. 도면의 설명과 관련하여, 동일 또는 유사한 구성요소에 대해서는 동일 또는 유사한 참조 부호가 사용될 수 있다."}
