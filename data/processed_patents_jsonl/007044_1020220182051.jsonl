{"patent_id": "10-2022-0182051", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0100020", "출원번호": "10-2022-0182051", "발명의 명칭": "로봇 및 로봇의 추종 방법", "출원인": "주식회사 힐스로보틱스", "발명자": "박명규"}}
{"patent_id": "10-2022-0182051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "로봇을 이동시키는 구동부;적어도 1대의 카메라를 포함하는 센서부; 상기 적어도 1대의 카메라를 통해 단위 시간당 n개(n은 1보다 큰 자연수)의 프레임의 영상들을 촬영하고, 촬영된 둘 이상의 영상들에 포함된 물체들의 특장점 및 마커 중 적어도 하나를 추출하는 영상처리부; 및상기 적어도 1대의 카메라를 통해 물체들에 대해 촬영된 상기 영상들을 이용하여 상기 물체들의 거리 정보를 계산하고, 추출된 상기 특장점 및 마커 중 적어도 하나를 이용하여 상기 물체들 중 목표물을 선택하고, 계산된 상기 거리 정보를 이용하여 상기 목표물까지 이격 거리를 추정하고, 상기 이격 거리에 기초하여 상기 목표물을 향해 최적의 이격 거리로 추종 이동하도록 상기 구동부를 제어하는 제어부를 포함하는 로봇."}
{"patent_id": "10-2022-0182051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 특장점은 상기 물체들의 신체적 비율 및 색깔 중 적어도 하나이고, 상기 목표물은 인간인 로봇."}
{"patent_id": "10-2022-0182051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 목표물인 인간인 경우, 상기 인간의 신체적 비율은 키와 어깨의 비율 또는 키와 머리의 비율이고,상기 제어부는 상기 인간의 신체적 비율 및 상기 색깔, 마커에 대해 학습을 통해 최적의 조합을 선택하여 필터링 순서를 결정하는 로봇."}
{"patent_id": "10-2022-0182051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,추종 명령을 입력받은 경우, 상기 제어부는 상기 센서부가 상기 목표물을 촬영하도록 제어하고, 상기 영상처리부가 상기 촬영된 영상에서 상기 목표물을 추출하도록 제어하는 로봇."}
{"patent_id": "10-2022-0182051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 제어부는 상기 물체들의 외곽선 내에 특정 부분의 색깔이나 외곽선 내에 색깔들의 패턴으로 상기 목표물을특정하고, 다른 목표물과 구분하는데 사용하는 로봇."}
{"patent_id": "10-2022-0182051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제어부는, 추종 이동 중 상기 목표물을 상실한 경우, 일단 정지한 후 상기 목표물을 상실했다는 신호를 제공하는 로봇."}
{"patent_id": "10-2022-0182051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 n개는 상기 목표물의 이동 속도나 상기 목표물의 주변환경에 따라 가변인 로봇."}
{"patent_id": "10-2022-0182051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2024-0100020-3-단위 시간당 n개(n은 1보다 큰 자연수)의 프레임의 영상들을 촬영하고, 촬영된 둘 이상의 영상들에 포함된 물체들의 특장점 및 마커 중 적어도 하나를 추출하는 단계; 촬영된 상기 영상들을 이용하여 상기 물체들의 거리 정보를 계산하고, 추출된 상기 특장점 및 마커 중 적어도하나를 이용하여 상기 물체들 중 목표물을 선택하는 단계; 및계산된 상기 거리 정보를 이용하여 상기 목표물까지 이격 거리를 추정하고 상기 이격 거리에 기초하여 상기 목표물을 향해 최적의 이격 거리로 추종 이동하는 단계를 포함하는 로봇의 추종 방법."}
{"patent_id": "10-2022-0182051", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 명세서는, 로봇을 이동시키는 구동부, 적어도 1대의 카메라를 포함하는 센서부, 적어도 1대의 카메라를 통해 단위 시간당 n개(n은 1보다 큰 자연수)의 프레임의 영상들을 촬영하고 촬영된 둘 이상의 영상들에 포함된 물체들 의 특장점 및 마커 중 적어도 하나를 추출하는 영상처리부 및 적어도 1대의 카메라를 통해 물체들에 대해 촬영된 영상들을 이용하여 물체들의 거리 정보를 계산하고 추출된 특장점 및 마커 중 적어도 하나를 이용하여 물체들 중 목표물을 선택하고 계산된 거리 정보를 이용하여 목표물을 향해 최적의 이격 거리로 추종 이동하도록 구동부를 제어하는 제어부를 포함하는 로봇을 제공한다."}
{"patent_id": "10-2022-0182051", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 실시예들은 로봇 및 로봇의 추종 방법에 관한 것이다."}
{"patent_id": "10-2022-0182051", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 로봇에서 얻어진 영상 정보를 이용하여 얼굴 검출이나 얼굴 인식 및 양안 정합과 같은 고도한 프로 세서의 연산능력이 필요한 알고리즘을 실행하기 위해서는 아래 2가지 방법으로 시스템을 구성한다. 첫째 영상 처리를 위해 처리 능력이 뛰어난 컴퓨터를 이용하여 로봇 자체에서 실행하거나, 둘째 취득한 영상 정 보를 네트워크 서버로 전송하여 서버에서 영상처리가 실행되도록 하는 방법이 있다. 전자는 고성능의 컴퓨터를 이용한 로봇으로 가격이 비싸 상용화가 어려웠다. 후자는 네트워크 서버와 접속해야 하므로 음영지역 등에서 동작하지 않을 수 있었다. 이에 따라 네트워크 서버와 접속하지 않고 가격이 싸면서 동시에 목표물을 정확하게 추종하는 로봇이 필요한 상 황이었다."}
{"patent_id": "10-2022-0182051", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 실시예들은 네트워크 서버와 접속하지 않고 가격이 싸고 목표물을 정확하게 추종하는 로봇 및 그 로봇의 추 종 방법을 제공할 수 있다."}
{"patent_id": "10-2022-0182051", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 측면에서, 본 실시예들은 로봇을 이동시키는 구동부, 적어도 1대의 카메라를 포함하는 센서부, 적어도 1대의 카메라를 통해 단위 시간당 n개(n은 1보다 큰 자연수)의 프레임의 영상들을 촬영하고 촬영된 둘 이상의 영상들 에 포함된 물체들의 특장점 및 마커 중 적어도 하나를 추출하는 영상처리부 및 적어도 1대의 카메라를 통해 물 체들에 대해 촬영된 영상들을 이용하여 상기 물체들의 거리 정보를 계산하고 추출된 상기 특장점 및 마커 중 적 어도 하나를 이용하여 상기 물체들 중 목표물을 선택하고 계산된 거리 정보를 이용하여 목표물을 향해 최적의 이격 거리로 추종 이동하도록 구동부를 제어하는 제어부를 포함하는 로봇을 제공할 수 있다. 다른 측면에서, 본 실시예들은 단위 시간당 n개(n은 1보다 큰 자연수)의 프레임의 영상들을 촬영하고, 촬영된 둘 이상의 영상들에 포함된 물체들의 특장점 및 마커 중 적어도 하나를 추출하는 단계, 촬영된 영상들을 이용하 여 물체들의 거리 정보를 계산하고 추출된 특장점 및 마커 중 적어도 하나를 이용하여 물체들 중 목표물을 선택 하는 단계 및 계산된 거리 정보를 이용하여 목표물까지 이격 거리를 추정하고 이격 거리에 기초하여 목표물을 향해 최적의 이격 거리로 추종 이동하는 단계를 포함하는 로봇의 추종 방법을 제공한다."}
{"patent_id": "10-2022-0182051", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 실시예들에 의하면, 네트워크 서버와 접속하지 않고 가격이 싸고 목표물을 정확하게 추종하는 로봇 및 그 로 봇의 추종 방법을 제공할 수 있다."}
{"patent_id": "10-2022-0182051", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 일부 실시예들을 예시적인 도면을 참조하여 상세하게 설명한다. 각 도면의 구성 요소들에 참조 부호를 부가함에 있어서, 동일한 구성 요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가질 수 있다. 또한, 본 실시예들을 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명 이 본 기술 사상의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략할 수 있다. 본 명세서 상 에서 언급된 \"포함한다\", \"갖는다\", \"이루어진다\" 등이 사용되는 경우 \"~만\"이 사용되지 않는 이상 다른 부분이 추가될 수 있다. 구성 요소를 단수로 표현한 경우에 특별한 명시적인 기재 사항이 없는 한 복수를 포함하는 경 우를 포함할 수 있다. 또한, 본 개시의 구성 요소를 설명하는 데 있어서, 제1, 제2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이 러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질, 차례, 순서 또는 개수 등이 한정되지 않는다. 구성 요소들의 위치 관계에 대한 설명에 있어서, 둘 이상의 구성 요소가 \"연결\", \"결합\" 또는 \"접속\" 등이 된다 고 기재된 경우, 둘 이상의 구성 요소가 직접적으로 \"연결\", \"결합\" 또는 \"접속\" 될 수 있지만, 둘 이상의 구성 요소와 다른 구성 요소가 더 \"개재\"되어 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다. 여 기서, 다른 구성 요소는 서로 \"연결\", \"결합\" 또는 \"접속\" 되는 둘 이상의 구성 요소 중 하나 이상에 포함될 수 도 있다. 구성 요소들이나, 동작 방법이나 제작 방법 등과 관련한 시간적 흐름 관계에 대한 설명에 있어서, 예를 들어, \"~후에\", \"~에 이어서\", \"~다음에\", \"~전에\" 등으로 시간적 선후 관계 또는 흐름적 선후 관계가 설명되는 경우, \"바로\" 또는 \"직접\"이 사용되지 않는 이상 연속적이지 않은 경우도 포함할 수 있다. 한편, 구성 요소에 대한 수치 또는 그 대응 정보(예: 레벨 등)가 언급된 경우, 별도의 명시적 기재가 없더라도, 수치 또는 그 대응 정보는 각종 요인(예: 공정상의 요인, 내부 또는 외부 충격, 노이즈 등)에 의해 발생할 수 있는 오차 범위를 포함하는 것으로 해석될 수 있다. 이하 도면들을 참조하여 실시예들을 상세히 설명한다. 도 1은 일 실시예에 따른 로봇의 사시도이다. 도 1을 참조하면, 일 실시예에 따른 로봇은 목표물을 인식하여 목표물의 동선을 따르며 이동하는 목표물 추종 기능을 갖추고 있다. 로봇은 자기 위치 인식(localization), 지도 구축(map building) 및 이를 바탕 으로 한 네비게이션(navigation) 등을 통해 자율 주행을 수행할 수도 있다. 일 실시예에 따른 로봇은 목표물 추종 기능을 갖추고 있는 다양한 종류의 로봇일 수 있다. 예를 들어, 이 로봇은 대형 (할인) 매장, 창고형 매장, 물류 보관창고 등 의 실내외에서 운영 가능한 지능형 무인자율주 행 로봇일 수 있다. 로봇은 프레임 하부에 복수의 휠(미도시)이 장착되어 이동할 수 있다. 로봇은 미리 구분 적재될 수 있도록 선반 또는 적재함이 복수 층으로 구획되어 있거나 물리적으로 하 나의 선반이 복수의 영역으로 구획되어 있다. 예를 들어, 로봇은 도 2에 도시한 바와 같이 2층의 선 반들(120a, 120b)이 구비될 수 있다. 로봇은 영상을 표시하는 출력부가 장착될 수 있다. 예를 들어, 도 2에 도시된 바와 같이, 로봇 은 2개 이상의 출력부가 장착될 수 있다. 물론 하나의 출력부만을 구비하되 표시영역을 구획 영역별로 구분하여 서로 영상들을 표시할 수 있다. 예를 들어, 출력부는 터치스크린으로 영상을 표시할 뿐만 아니라 터치입력을 수신할 수도 있다. 출력부 는 음성을 출력하는 스피커를 포함할 수도 있다. 예를 들어, 출력부는 터치스크린과 스피커를 포함 하므로, 영상을 표시함과 동시에 음성/음향을 출력할 수도 있다. 로봇는 출력부에 포함되는 터치스크린과 별도로 다양한 형태의 입력부(미도시)를 추가로 포함할 수 있다. 이 입력부는 입력버튼이나 키보드, 마우스와 같은 일반적인 입력장치이거나, 마이크와 같은 음성/음향 입력 장치 등일 수 있다. 로봇은 적어도 1대의 카메라를 포함하고 있다. 카메라는 두개 이상의 CCD(Charge Coupled Device)와 CMOS 이미지 센서들을 포함하는 RGB 카메라일 수 있다. 로봇은 후술하는 바와 같이 카메라 의 두개의 센서들 사이의 고정된 거리(df)와 두개의 센서들과 물체 사이의 거리들(l1, l2)을 통해 로봇 과 목표물 사이(d)의 거리를 계산할 수 있다. 카메라는 예를 들어 설명한 RGB 카메라로 제한되지 않고 다양한 종류의 카메라, 예를 들어 스테레오 카메 라일 수도 있다. 카메라는 고성능 엣지 인공지능 비젼 알고리즘 등을 탑재한 카메라와 같이 GPU에 의해 지 원되는 고성능 카메라일 수도 있으나, 이에 제한되지 않는다. 도 2는 도 1의 로봇을 구성도이다. 도 2를 참조하면, 로봇은 구동부와, 센서부, 영상처리부, 제어부를 포함한다. 구동부는 로봇을 이동시킨다. 구동부는 전술한 프레임 하부에 복수의 휠(미도시)을 이용 하여 로봇을 앞뒤 이동하거나 회전시킬 수 있다. 센서부는 전술한 적어도 1대의 카메라을 포함한다. 센서부는 카메라뿐만 아니라 일반적으 로 로봇의 센서들로 사용하는 레이더나 라이더, 적외선/자외선 센서, 열감지 센서 등 중 적어도 하나를 포 함할 수 있으나, 이에 제한되지 않는다. 영상처리부는 적어도 1대의 카메라를 통해 단위 시간당 n개(n은 1보다 큰 자연수)의 프레임의 영상들 을 촬영하고 촬영된 둘 이상의 영상들에 포함된 물체들의 특장점 및 마커 중 적어도 하나를 추출한다. 제어부는 구동부, 센서부 및 영상처리부와 기타 로봇을 구성하는 다른 구성요소들의 동작과 기능을 전반적으로 제어한다. 제어부는 영상처리부 및 적어도 1대의 카메라를 통해 물체들에 대해 촬영된 영상들을 이용하여 물체들의 거리 정보를 계산하고, 추출된 특장점 및 마커 중 적어도 하나를 이용하여 물체들 중 목표물을 선택하 고, 계산된 거리 정보를 이용하여 목표물을 향해 최적의 이격 거리로 추종 이동하도록 구동부를 제어한다. 도 3는 도 1의 카메라의 센서들을 이용해 로봇과 물체 사이 거리를 계산하는 원리를 도시하고 있다. 도 3을 참조하면, 제어부는 전술한 바와 같이 후술하는 바와 같이 카메라의 두개의 센서들(142, 144) 사이의 고정된 거리(df)와 두개의 센서들(142, 144) 과 물체 사이의 거리들(l1, l2)을 통해 로봇과 물체들 사이의 거리(D)를 계산할 수 있다. 예를 들어, 특장점은 물체들의 신체적 비율 및 색깔 중 적어도 하나일 수 있다. 다른 예를 들어, 특장점은 물체 들의 외곽선, 물체들의 3차원 영상, 적외선 열상 영상 등 물체들의 특징을 표현할 수 있는 물리적인 특징일 수 있다. 특장점은 시각적인 특징뿐만 아니라 청각적이거나 후각적인 오감의 특징일 수도 있다. 또한, 목표물은 인간일 수 있으나, 이에 제한되지 않는다. 목표물은 인간 이외에 동물일 수도 있고, 다른 로봇 이나 자동차와 같은 다양한 종류의 이동체일 수 있다. 목표물인 인간인 경우, 인간의 신체적 비율은 키와 어깨의 비율 또는 키와 머리의 비율일 수 있다. 추종 명령을 입력받은 경우, 제어부는 센서부가 목표물을 촬영하도록 제어하고, 영상처리부가 촬영된 영상에서 목표물을 추출하도록 제어할 수 있다. 추종 명령을 입력받은 경우, 센서부의 카메라는 특정 시간 후에 특정 장소에 위치한 인간을 촬영할 수 있다. 영상처리부는 촬영된 영상에 포함된 인간의 키(a)와 어깨(b)의 비율(b/a) 또는 키(a)와 머리(c)의 비율(c/a)을 추출할 수 있다. 추종 명령을 입력받은 경우, 센서부의 카메라가 특정 시간 후에 특정 장소에 위치한 인간을 촬영할 수 있다. 예를 들어, 도 4에 도시한 바와 같이, 센서부의 카메라가 특정한 장소에 위치한 인간의 뒷모습을 촬 영할 수 있다. 목표물 추종시 인간의 뒷모습을 촬영하는 것을 고려하여 목표물을 설정할 때 센서부의 카메 라가 인간의 뒷모습을 촬영할 수 있으나, 이에 제한되지 않는다. 영상처리부는 촬영된 영상에 포함된 인간의 키(a)와 어깨(b)의 비율(b/a) 또는 키(a)와 머리(c)의 비율 (c/a)을 추출하거나, 인간의 키와 다른 신체 부분의 비율이나, 서로 다른 신체 부위들의 비율을 추출할 수도 있 다. 특히, 목표물이 인간이 아닌 경우, 예를 들어 목표물이 강아지인 경우 영상처리부는 촬영된 영상에 포함된 강아지의 머리끝부터 허리까지의 길이와 다리에서 허리까지 길이의 비율을 추출할 수도 있다. 추정 명령을 입력받는 다른 방법들로, 추종 버튼을 누른 자를 센서부의 카메라가 촬영하여 목표물로 특정하거나, 미리 등록된 사람을 목표물로 특정하거나, 지문이나 패스워드, 홍채, 카드키 등에 의해 지시된 특 정인을 목표물로 특정할 수 있다. 관제 센터와 네트워크로 연결된 경우, 관제 센터에 등록된 특정인을 관제 센 터에 추종 여부를 문의한 후 승인시 목표물로 특정할 수도 있으나, 이에 제한되지 않는다. 예를 들어, 제어부는 추출된 인간의 키와 어깨의 비율 또는 키와 머리의 비율로 표현된 목표물을 특정할 수 있다. 센서부는 목표물을 특정한 후에도 계속해서 영상을 촬영하고, 도 5에 도시한 바와 같이, 영상처리부 는 촬영된 둘 이상의 영상들에 포함된 인간의 키(a')와 어깨(b')의 비율(b'/a') 또는 키(a')와 머리(c')의 비율 (c'/a')을 추출하고, 제어부는 특정된 목표물의 인간의 키(a)와 어깨(b)의 비율(b/a) 또는 키(a)와 머리 (c)의 비율(c/a)과 새로 추출된 인간의 키(a')와 어깨(b')의 비율(b'/a') 또는 키(a')와 머리(c')의 비율 (c'/a')을 비교하여, 목표물의 추적을 계속할 수 있다. 제어부는 목표물을 특정할 때와 목표물과 새로 추출된 인간의 영상을 비교할 때 인간의 신체적 비율 및 색 깔, 마커를 모두 사용할 수도 있지만, 제어부는 인간의 신체적 비율 및 색깔, 마커에 대해 학습을 통해 최 적의 조합을 선택하여 필터링 순서를 결정할 수도 있다. 예를 들어, 제어부는 마커만으로 목표물을 특정하고, 특정된 목표물과 영상의 물체를 비교할 수 있으면 양 자의 마커만을 비교할 수 있다. 다른 예로, 제어부는 인간의 색깔만으로 목표물을 특정하고, 특정된 목표물과 영상의 물체를 비교할 수 있 으면 양자의 색깔만을 비교할 수 있다. 또 다른 예로, 제어부는 인간의 신체적 비율만으로 목표물을 특정하고, 특정된 목표물과 영상의 물체를 비 교할 수 있으면 양자의 인간의 신체적 비율만을 비교할 수 있다. 제어부는 인간의 신체적 비율 및 색깔, 마커 중 하나만으로 목표물을 특정하는 것이 정확도나 신뢰도가 떨 어질 경우, 이들 중 최적의 조합을 선택하여 필터링 순서를 결정할 수 있다. 예를 들어, 제어부는 마커 색깔 인간의 신체적 비율의 순서로 최적의 조합을 선택할 수 있다. 제어부는 물체들의 외곽선 내에 특정 부분의 색깔이나 외곽선 내에 색깔들의 패턴으로 목표물을 특정하고, 다른 목표물과 구분하는데 사용할 수도 있다. 일예로, 제어부는, 추종 이동 중 목표물을 상실한 경우, 일단 정지한 후 목표물을 상실했다는 신호를 제공 할 수 있다. 신호는 음성/음향일 수도 있고 빛일 수도 있고 이들의 조합일 수도 있으나, 이에 제한되지 않는다. 다른 예로, 제어부는, 추종 이동 중 목표물을 상실한 경우, 목표물을 재확인하는 절차를 진행할 수 있다. 이때 제어부는 목표물의 이동 속도나 목표물의 주변환경을 고려하여 목표물의 이동 경로를 예측하고, 예측 한 이동 경로로 이용하여 센서부와 영상처리부을 통해 추출된 영상들로 목표물을 재확인할 수도 있다. 다른 예로, 제어부는 관제 센터와 유무선통신으로 연결된 경우 관제 센터에 목표물의 이동 및 위치를 요청 할 수 있다. 제어부는 관제 센터로부터 수신한 목표물의 이동 정보나 위치 정보를 이용하여 목표물의 위치로 이동하도록 구동부를 제어할 수도 있다. 제어부는, 도 3을 참조하여 설명한 계산된 거리 정보(D)를 이용하여 목표물을 향해 최적의 이격 거리로 추 종 이동하도록 구동부를 제어한다. 예를 들어, 제어부는 계산된 거리 정보(D)가 최적의 이격 거리보다 짧은 경우 목표물이 이동을 시작한 후 추종 이동하도록 구동부를 제어한다. 반대로, 제어부는 계산된 거리 정보(D)가 최적의 이격 거리보다 긴 경우 목표물의 이동 속도보다 빠른 속 도로 이동하도록 구동부를 제어한다. 제어부는 계산된 거리 정보(D)가 최적의 이격 거리를 유지한 상태에서 목표물이 정지한 경우, 최적의 이격 거리에서 멈추도록 구동부를 제어한다. 영상처리부는 적어도 1대의 카메라를 통해 단위 시간당 n개(n은 1보다 큰 자연수)의 프레임의 영상들 을 촬영하는데, n개는 목표물의 이동 속도나 목표물의 주변환경에 따라 가변일 수 있다. 예를 들어, 이동 속도나 목표물이 위치한 주변환경이 정상상태인 경우, 영상처리부는 카메라를 통해 단위 시간당 20개(n은 1보다 큰 자연수)의 프레임의 영상들을 촬영할 수 있다. 그러나, 이동 속도나 목표물이 위치한 주변환경이 정상상태가 아닌 경우, 예를 들어 목표물의 이동 속도가 증가 한 경우, 영상처리부는 카메라를 통해 단위 시간당 20개를 초과하는 프레임의 영상들을 촬영하게 할 수 있다. 또한, 목표물이 위치한 주변환경이 복잡하거나 특이한 경우, 영상처리부는 카메라를 통해 단위 시간 당 20개를 초과하는 프레임의 영상들을 촬영하게 할 수 있다. 제어부는 영상처리부의 촬영된 영상들의 프레임수가 증가하면 목표물과 물체의 비교 횟수를 늘리므로, 목표물을 상실하지 않도록 하거나, 목표물을 상실하더라도 목표물의 상실 사실을 신호로 제공하거나 목표물을 재확인하는 절차를 신속하게 수행할 수 있다. 만약, 로봇이 목표물을 추종 이동 중에 촬영된 영상에 포함된 인간들이 둘 이상인 경우, 영상처리부 는 촬영된 영상에 포함된 둘 이상의 인간들의 키(a', a'')와 어깨(b', b'')의 비율(b'/a', b''/a'') 또는 키 (a', a'')와 머리(c', c'')의 비율(c'/a', c''/a'')을 추출하고, 제어부는 특정된 목표물의 인간의 키 (a)와 어깨(b)의 비율(b/a) 또는 키(a)와 머리(c)의 비율(c/a)과 새로 추출된 인간들의 키(a', a'')와 어깨 (b', b'')의 비율(b'/a', b''/a'') 또는 키(a', a'')와 머리(c', c'')의 비율(c'/a', c''/a'')을 비교하여, 목 표물을 특정할 수 있다. 이상, 목표물 추종 기능을 갖는 로봇에 대해 상세히 설명하였다. 이하, 다른 실시예에 따른 로봇의 추종 방법 에 대해 상세히 설명한다. 도 6은 다른 실시예에 따른 로봇의 추종 방법의 흐름도이다. 도 1 및 도 6을 참조하면, 다른 실시예에 따른 로봇의 추종 방법은 단위 시간당 n개(n은 1보다 큰 자연 수)의 프레임의 영상들을 촬영하고, 촬영된 둘 이상의 영상들에 포함된 물체들의 특장점 및 마커 중 적어도 하 나를 추출하는 단계(S310), 촬영된 영상들을 이용하여 물체들의 거리 정보를 계산하고 추출된 특장점 및 마커 중 적어도 하나를 이용하여 물체들 중 목표물을 선택하는 단계(S320) 및 계산된 거리 정보를 이용하여 목표물까 지 이격 거리를 추정하고 이격 거리에 기초하여 목표물을 향해 최적의 이격 거리로 추종 이동하는 단계(S330)를 포함한다. 영상 촬영 및 특장점 등 추출 단계(S310)에서, 로봇은 적어도 1대의 카메라를 통해 단위 시간당 n개 (n은 1보다 큰 자연수)의 프레임의 영상들을 촬영하고 촬영된 둘 이상의 영상들에 포함된 물체들의 특장점 및 마커 중 적어도 하나를 추출한다. 목표물 선택 단계(S320)에서, 로봇은 적어도 1대의 카메라를 통해 물체들에 대해 촬영된 영상들을 이 용하여 물체들의 거리 정보를 계산하고, 추출된 특장점 및 마커 중 적어도 하나를 이용하여 물체들 중 목표물을 선택한다. 추적 이동 단계(S330)에서, 로봇은 계산된 거리 정보를 이용하여 목표물을 향해 최적의 이격 거리로 추종 이동하도록 구동부를 제어한다. 로봇은 카메라의 두개의 센서들(142, 144) 사이의 고정된 거리(df)와 두개의 센서들(142, 144) 과 물 체 사이의 거리들(l1, l2)을 통해 로봇과 물체들 사이의 거리(D)를 계산할 수 있다. 예를 들어, 특장점은 물체들의 신체적 비율 및 색깔 중 적어도 하나일 수 있다. 다른 예를 들어, 특장점은 물체 들의 외곽선, 물체들의 3차원 영상, 적외선 열상 영상 등 물체들의 특징을 표현할 수 있는 물리적인 특징일 수 있다. 특장점은 시각적인 특징뿐만 아니라 청각적이거나 후각적인 오감의 특징일 수도 있다. 또한, 목표물은 인간일 수 있으나, 이에 제한되지 않는다. 목표물은 인간 이외에 동물일 수도 있고, 다른 로봇 이나 자동차와 같은 다양한 종류의 이동체일 수 있다. 목표물인 인간인 경우, 인간의 신체적 비율은 키와 어깨의 비율 또는 키와 머리의 비율일 수 있다. 추종 명령을 입력받은 경우, 로봇은 센서부가 목표물을 촬영하도록 제어하고, 촬영된 영상에서 목표 물을 추출할 수 있다. 추종 명령을 입력받은 경우, 로봇은 특정 시간 후에 특정 장소에 위치한 인간을 촬영할 수 있다. 로봇 은 촬영된 영상에 포함된 인간의 키(a)와 어깨(b)의 비율(b/a) 또는 키(a)와 머리(c)의 비율(c/a)을 추출 할 수 있다. 예를 들어, 도 4에 도시한 바와 같이, 카메라가 특정한 장소에 위치한 인간의 뒷모습을 촬영할 수 있다. 목표물 추종시 인간의 뒷모습을 촬영하는 것을 고려하여 목표물을 설정할 때 카메라가 인간의 뒷모습을 촬 영할 수 있으나, 이에 제한되지 않는다. 예를 들어, 로봇은 추출된 인간의 키와 어깨의 비율 또는 키와 머리의 비율로 표현된 목표물을 특정할 수 있다. 로봇은 목표물을 특정한 후에도 계속해서 영상을 촬영하고, 도 5에 도시한 바와 같이, 촬영된 둘 이상의 영상들에 포함된 인간의 키(a')와 어깨(b')의 비율(b'/a') 또는 키(a')와 머리(c')의 비율(c'/a')을 추출하고, 특정된 목표물의 인간의 키(a)와 어깨(b)의 비율(b/a) 또는 키(a)와 머리(c)의 비율(c/a)과 새로 추출된 인간의 키(a')와 어깨(b')의 비율(b'/a') 또는 키(a')와 머리(c')의 비율(c'/a')을 비교하여, 목표물의 추적을 계속할 수 있다. 로봇은 목표물을 특정할 때와 목표물과 새로 추출된 인간의 영상을 비교할 때 인간의 신체적 비율 및 색깔, 마커를 모두 사용할 수도 있지만, 인간의 신체적 비율 및 색깔, 마커에 대해 학습을 통해 최적의 조합을 선택하여 필터링 순서를 결정할 수도 있다. 로봇은 인간의 신체적 비율 및 색깔, 마커 중 하나만으로 목표물을 특정하는 것이 정확도나 신뢰도가 떨어 질 경우, 이들 중 최적의 조합을 선택하여 필터링 순서를 결정할 수 있다. 예를 들어, 로봇은 마커 색깔 인간의 신체적 비율의 순서로 최적의 조합을 선택할 수 있다. 일예로, 로봇은, 추종 이동 중 목표물을 상실한 경우, 일단 정지한 후 목표물을 상실했다는 신호를 제공할 수 있다. 신호는 음성/음향일 수도 있고 빛일 수도 있고 이들의 조합일 수도 있으나, 이에 제한되지 않는다. 다른 예로, 로봇은, 추종 이동 중 목표물을 상실한 경우, 목표물을 재확인하는 절차를 진행할 수 있다. 이 때 로봇은 목표물의 이동 속도나 목표물의 주변환경을 고려하여 목표물의 이동 경로를 예측하고, 예측한 이동 경로로 이용하여 추출된 영상들로 목표물을 재확인할 수도 있다. 로봇은, 도 3을 참조하여 설명한 계산된 거리 정보(D)를 이용하여 목표물을 향해 최적의 이격 거리로 추종 이동하도록 구동부를 제어한다. 로봇은 적어도 1대의 카메라를 통해 단위 시간당 n개(n은 1보다 큰 자연수)의 프레임의 영상들을 촬 영하는데, n개는 목표물의 이동 속도나 목표물의 주변환경에 따라 가변일 수 있다. 로봇은 촬영된 영상들의 프레임수가 증가하면 목표물과 물체의 비교 횟수를 늘리므로, 목표물을 상실하지 않도록 하거나, 목표물을 상실하더라도 목표물의 상실 사실을 신호로 제공하거나 목표물을 재확인하는 절차를 신속하게 수행할 수 있다. 전술한 실시예들에 따른 로봇 및 그 로봇의 추종 방법은 네트워크 서버와 접속하지 않고 가격이 싸고 목표물을 정확하게 추종할 수 있다. 이상 도면을 참조하여 실시예들을 상세히 설명하였으나, 본 발명은 이에 제한되지 않는다. 이상의 설명은 본 개시의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 개시가 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 기술 사상의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형 이 가능할 것이다. 또한, 본 실시예들은 본 개시의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이 므로 이러한 실시예에 의하여 본 기술 사상의 범위가 한정되는 것은 아니다. 본 개시의 보호 범위는 아래의 청 구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 개시의 권리 범위에 포함 되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0182051", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 로봇의 사시도이다. 도 2는 도 1의 로봇을 구성도이다. 도 3는 도 1의 카메라의 센서들을 이용해 로봇과 물체 사이 거리를 계산하는 원리를 도시하고 있다. 도 4 추종 명령을 입력받은 경우, 센서부의 카메라가 특정 시간 후에 특정 장소에 위치한 인간을 촬영하는 상태 를 도시하고 있다. 도 5는 도 1의 로봇이 추종 과정 중 물체를 촬영하는 상태를 도시하고 있다. 도 6은 다른 실시예에 따른 로봇의 추종 방법의 흐름도이다."}
