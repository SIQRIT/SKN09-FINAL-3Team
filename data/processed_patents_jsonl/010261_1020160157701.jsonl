{"patent_id": "10-2016-0157701", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0058563", "출원번호": "10-2016-0157701", "발명의 명칭": "윤리적 의사결정 모듈과 이를 포함하는 로봇 및 윤리적 의사결정 방법", "출원인": "동아대학교 산학협력단", "발명자": "김종욱"}}
{"patent_id": "10-2016-0157701", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "로봇에 탑재되는 윤리적 의사결정 모듈로서,사용자로부터 상기 로봇의 행위에 대한 명령을 입력 받는 입력부; 및공리주의적 의사결정 모형을 이용하여 상기 명령에 대한 각 대안들의 수행 결과에 따른 효용값(utility value)을 획득하고 상기 효용값을 이용하여 상기 대안들 중 하나 이상을 선택하며, 선택된 상기 대안들 각각에 설정된상기 로봇의 의무론적 윤리 규칙을 적용하여 선택된 상기 대안들 중 최종 대안을 선택하는 선택부를 포함하는,윤리적 의사결정 모듈."}
{"patent_id": "10-2016-0157701", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 로봇의 의무론적 윤리 규칙은, 설정된 복수의 윤리 규칙을 포함하며,상기 선택부는, 선택된 상기 대안들 중 상기 복수의 윤리 규칙을 모두 만족하는 대안을 상기 최종 대안으로 선택하는, 윤리적 의사결정 모듈."}
{"patent_id": "10-2016-0157701", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,선택된 상기 최종 대안을 수행하도록 상기 로봇을 제어하는 행위 제어부를 더 포함하는, 윤리적 의사결정 모듈."}
{"patent_id": "10-2016-0157701", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 행위 제어부는, 상기 최종 대안이 상기 사용자로부터 입력된 명령과 상이한 경우, 상기 명령을 수행할 수없음을 나타내는 거부 의사를 출력하는, 윤리적 의사결정 모듈."}
{"patent_id": "10-2016-0157701", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,상기 입력부에서 복수의 사용자 각각으로부터 상기 로봇의 행위에 대한 명령을 입력 받는 경우,상기 선택부는, 상기 복수의 사용자 각각으로부터 입력된 명령별 최종 대안을 각각 선택하고, 선택된 상기 최종대안이 복수 개인 경우 상기 복수의 사용자 각각으로부터 입력된 명령의 긴급한 정도(emergency score), 중요도(priority score) 및 상기 복수의 사용자 간의 사회적 관계 정도(relation score) 중 하나 이상을 고려하여 상기 복수 개의 최종 대안 중 하나를 선택하는, 윤리적 의사결정 모듈."}
{"patent_id": "10-2016-0157701", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서,공개특허 10-2018-0058563-3-사물인터넷 기기 또는 클라우드 서버와 연동하여 상기 사물인터넷 기기 또는 상기 클라우드 서버로부터 상기 최종 대안을 선택하는 데 필요한 부가 정보를 수신하는 통신부를 더 포함하는, 윤리적 의사결정 모듈."}
{"patent_id": "10-2016-0157701", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1 내지 6 중 어느 한 항에 기재된 윤리적 의사결정 모듈을 포함하는, 로봇."}
{"patent_id": "10-2016-0157701", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "로봇에 탑재되는 윤리적 의사결정 모듈에서 수행되는 윤리적 의사결정 방법으로서,입력부에서, 사용자로부터 상기 로봇의 행위에 대한 명령을 입력 받는 단계;선택부에서, 공리주의적 의사결정 모형을 이용하여 상기 명령에 대한 각 대안들의 수행 결과에 따른 효용값(utility value)을 획득하는 단계;상기 선택부에서, 상기 효용값을 이용하여 상기 대안들 중 하나 이상을 선택하는 단계; 및상기 선택부에서, 선택된 상기 대안들 각각에 설정된 상기 로봇의 의무론적 윤리 규칙을 적용하여 선택된 상기대안들 중 최종 대안을 선택하는 단계를 포함하는, 윤리적 의사결정 방법."}
{"patent_id": "10-2016-0157701", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서,상기 로봇의 의무론적 윤리 규칙은, 설정된 복수의 윤리 규칙을 포함하며,상기 최종 대안을 선택하는 단계는, 선택된 상기 대안들 중 상기 복수의 윤리 규칙을 모두 만족하는 대안을 상기 최종 대안으로 선택하는, 윤리적 의사결정 방법."}
{"patent_id": "10-2016-0157701", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 8에 있어서,상기 최종 대안을 선택하는 단계 이후,행위 제어부에서, 선택된 상기 최종 대안을 수행하도록 상기 로봇을 제어하는 단계를 더 포함하는, 윤리적 의사결정 방법."}
{"patent_id": "10-2016-0157701", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 10에 있어서,상기 로봇을 제어하는 단계는, 상기 최종 대안이 상기 사용자로부터 입력된 명령과 상이한 경우, 상기 명령을수행할 수 없음을 나타내는 거부 의사를 출력하는, 윤리적 의사결정 방법."}
{"patent_id": "10-2016-0157701", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 8에 있어서,상기 입력부에서 복수의 사용자 각각으로부터 상기 로봇의 행위에 대한 명령을 입력 받는 경우,상기 최종 대안을 선택하는 단계는, 상기 복수의 사용자 각각으로부터 입력된 명령별 최종 대안을 각각 선택하고, 선택된 상기 최종 대안이 복수 개인 경우 상기 복수의 사용자 각각으로부터 입력된 명령의 긴급한 정도공개특허 10-2018-0058563-4-(emergency score), 중요도(priority score) 및 상기 복수의 사용자 간의 사회적 관계 정도(relation score)중 하나 이상을 고려하여 상기 복수 개의 최종 대안 중 하나를 선택하는, 윤리적 의사결정 방법."}
{"patent_id": "10-2016-0157701", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 8에 있어서,상기 최종 대안을 선택하는 단계 이전에,통신부에서, 사물인터넷 기기 또는 클라우드 서버와 연동하여 상기 사물인터넷 기기 또는 상기 클라우드 서버로부터 상기 최종 대안을 선택하는 데 필요한 부가 정보를 수신하는 단계를 더 포함하는, 윤리적 의사결정 방법."}
{"patent_id": "10-2016-0157701", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "윤리적 의사결정 모듈과 이를 포함하는 로봇 및 윤리적 의사결정 방법이 제공된다. 본 발명의 일 실시예에 따른 윤리적 의사결정 모듈은, 로봇에 탑재되는 윤리적 의사결정 모듈로서, 사용자로부터 상기 로봇의 행위에 대한 명 령을 입력 받는 입력부; 및 공리주의적 의사결정 모형을 이용하여 상기 명령에 대한 각 대안들의 수행 결과에 따 른 효용값(utility value)을 획득하고 상기 효용값을 이용하여 상기 대안들 중 하나 이상을 선택하며, 선택된 상 기 대안들 각각에 설정된 상기 로봇의 의무론적 윤리 규칙을 적용하여 선택된 상기 대안들 중 최종 대안을 선택 하는 선택부를 포함한다."}
{"patent_id": "10-2016-0157701", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예들은 로봇에서 구현 가능한 윤리적 의사결정 기술과 관련된다."}
{"patent_id": "10-2016-0157701", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 고령자 인구 비중 및 1인 가구 비율이 점차 증가함에 따라 로봇에 대한 수요 또한 증가하고 있다. 특히, 인간과 의사소통 가능한 지능형 로봇에 대한 연구 및 개발이 증가하고 있으며, 인공지능(Artificial Intelligent) 기술의 발달에 따라 인간의 능력보다 뛰어난 정도의 지능과 어느 정도의 자율성을 지닌 로봇에 대 한 개발이 점차 현실화되고 있다. 그러나, 인공지능 로봇이 자율적으로 사고하여 판단하여 행동할 경우, 이에 따른 윤리적 책임을 누구에게 물어 야 하는지에 대한 논란이 있으며 이러한 이유로 윤리적인 인공지능 로봇에 대한 필요성이 제기되고 있다. 인공 지능 로봇이 인간과 진정한 소통을 하기 위해서는 인공지능 로봇의 윤리적 또는 도덕적 요소들이 함께 고려되어 야 한다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허공보 제10-2015-0137683호(2015.12.09)"}
{"patent_id": "10-2016-0157701", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예들은 로봇의 윤리적 의사결정을 지원하는 수단을 제공하기 위한 것이다."}
{"patent_id": "10-2016-0157701", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 예시적인 실시예에 따르면, 로봇에 탑재되는 윤리적 의사결정 모듈로서, 사용자로부터 상기 로봇의 행위에 대한 명령을 입력 받는 입력부; 및 공리주의적 의사결정 모형을 이용하여 상기 명령에 대한 각 대안들의 수행 결과에 따른 효용값(utility value)을 획득하고 상기 효용값을 이용하여 상기 대안들 중 하나 이상을 선택 하며, 선택된 상기 대안들 각각에 설정된 상기 로봇의 의무론적 윤리 규칙을 적용하여 선택된 상기 대안들 중 최종 대안을 선택하는 선택부를 포함하는, 윤리적 의사결정 모듈이 제공된다. 상기 로봇의 의무론적 윤리 규칙은, 설정된 복수의 윤리 규칙을 포함하며, 상기 선택부는, 선택된 상기 대안들 중 상기 복수의 윤리 규칙을 모두 만족하는 대안을 상기 최종 대안으로 선택할 수 있다. 상기 윤리적 의사결정 모듈은, 선택된 상기 최종 대안을 수행하도록 상기 로봇을 제어하는 행위 제어부를 더 포 함할 수 있다. 상기 행위 제어부는, 상기 최종 대안이 상기 사용자로부터 입력된 명령과 상이한 경우, 상기 명령을 수행할 수 없음을 나타내는 거부 의사를 출력할 수 있다. 상기 입력부에서 복수의 사용자 각각으로부터 상기 로봇의 행위에 대한 명령을 입력 받는 경우, 상기 선택부는, 상기 복수의 사용자 각각으로부터 입력된 명령별 최종 대안을 각각 선택하고, 선택된 상기 최종 대안이 복수 개 인 경우 상기 복수의 사용자 각각으로부터 입력된 명령의 긴급한 정도(emergency score), 중요도(priority score) 및 상기 복수의 사용자 간의 사회적 관계 정도(relation score) 중 하나 이상을 고려하여 상기 복수 개 의 최종 대안 중 하나를 선택할 수 있다. 상기 윤리적 의사결정 모듈은, 사물인터넷 기기 또는 클라우드 서버와 연동하여 상기 사물인터넷 기기 또는 상 기 클라우드 서버로부터 상기 최종 대안을 선택하는 데 필요한 부가 정보를 수신하는 통신부를 더 포함할 수 있 다. 본 발명의 다른 예시적인 실시예에 따르면, 상술한 윤리적 의사결정 모듈을 포함하는, 로봇이 제공된다. 본 발명의 다른 예시적인 실시예에 따르면, 로봇에 탑재되는 윤리적 의사결정 모듈에서 수행되는 윤리적 의사결 정 방법으로서, 입력부에서, 사용자로부터 상기 로봇의 행위에 대한 명령을 입력 받는 단계; 선택부에서, 공리 주의적 의사결정 모형을 이용하여 상기 명령에 대한 각 대안들의 수행 결과에 따른 효용값(utility value)을 획 득하는 단계; 상기 선택부에서, 상기 효용값을 이용하여 상기 대안들 중 하나 이상을 선택하는 단계; 및 상기 선택부에서, 선택된 상기 대안들 각각에 설정된 상기 로봇의 의무론적 윤리 규칙을 적용하여 선택된 상기 대안 들 중 최종 대안을 선택하는 단계를 포함하는, 윤리적 의사결정 방법이 제공된다. 상기 로봇의 의무론적 윤리 규칙은, 설정된 복수의 윤리 규칙을 포함하며, 상기 최종 대안을 선택하는 단계는, 선택된 상기 대안들 중 상기 복수의 윤리 규칙을 모두 만족하는 대안을 상기 최종 대안으로 선택할 수 있다. 상기 윤리적 의사결정 방법은, 상기 최종 대안을 선택하는 단계 이후, 행위 제어부에서, 선택된 상기 최종 대안 을 수행하도록 상기 로봇을 제어하는 단계를 더 포함할 수 있다. 상기 로봇을 제어하는 단계는, 상기 최종 대안이 상기 사용자로부터 입력된 명령과 상이한 경우, 상기 명령을 수행할 수 없음을 나타내는 거부 의사를 출력할 수 있다. 상기 입력부에서 복수의 사용자 각각으로부터 상기 로봇의 행위에 대한 명령을 입력 받는 경우, 상기 최종 대안 을 선택하는 단계는, 상기 복수의 사용자 각각으로부터 입력된 명령별 최종 대안을 각각 선택하고, 선택된 상기 최종 대안이 복수 개인 경우 상기 복수의 사용자 각각으로부터 입력된 명령의 긴급한 정도(emergency score), 중요도(priority score) 및 상기 복수의 사용자 간의 사회적 관계 정도(relation score) 중 하나 이상을 고려하 여 상기 복수 개의 최종 대안 중 하나를 선택할 수 있다. 상기 윤리적 의사결정 방법은, 상기 최종 대안을 선택하는 단계 이전에, 통신부에서, 사물인터넷 기기 또는 클 라우드 서버와 연동하여 상기 사물인터넷 기기 또는 상기 클라우드 서버로부터 상기 최종 대안을 선택하는 데 필요한 부가 정보를 수신하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2016-0157701", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들에 따르면, 공리주의적 의사결정 모형 및 의무론적 윤리 규칙을 이용하여 로봇 스스로 윤리 적 의사결정을 수행하도록 할 수 있다. 이에 따라, 로봇 스스로 일정 수준 이상의 도덕적 결정을 내릴 수 있으 며, 이로 인해 로봇과 인간의 소통 수준이 향상될 수 있다. 또한, 이 경우 윤리적 로봇을 활용한 다양한 서비스 의 제공이 가능해지며, 로봇 산업의 발전 및 이로 인한 신시장/일자리 창출 등과 같은 각종 사회적, 산업적 효 과를 달성할 수 있다."}
{"patent_id": "10-2016-0157701", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 구체적인 실시형태를 설명하기로 한다. 이하의 상세한 설명은 본 명세서에서 기술된 방법, 장치 및/또는 시스템에 대한 포괄적인 이해를 돕기 위해 제공된다. 그러나 이는 예시에 불과하며 본 발명은 이에 제한되지 않는다. 본 발명의 실시예들을 설명함에 있어서, 본 발명과 관련된 공지기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하기로 한다. 그리고, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 상세한 설명에서 사용되 는 용어는 단지 본 발명의 실시예들을 기술하기 위한 것이며, 결코 제한적이어서는 안 된다. 명확하게 달리 사 용되지 않는 한, 단수 형태의 표현은 복수 형태의 의미를 포함한다. 본 설명에서, \"포함\" 또는 \"구비\"와 같은 표현은 어떤 특성들, 숫자들, 단계들, 동작들, 요소들, 이들의 일부 또는 조합을 가리키기 위한 것이며, 기술된 것 이외에 하나 또는 그 이상의 다른 특성, 숫자, 단계, 동작, 요소, 이들의 일부 또는 조합의 존재 또는 가능 성을 배제하도록 해석되어서는 안 된다. 도 1은 본 발명의 일 실시예에 따른 윤리적 의사결정 모듈의 상세 구성을 나타낸 블록도이다. 본 발명의 일 실시예에 따른 윤리적 의사결정 모듈은 로봇(미도시)에 탑재되어 윤리적 의사결정을 수행하는 소프트웨 어 (예를 들어, AMA(Artificial Moral Agent)), 상기 소프트웨어가 저장된 컴퓨터 판독 가능 기록매체 또는 하 드웨어 장치일 수 있다. 상기 컴퓨터 판독 가능 기록매체는 예를 들어, 하드 디스크, 플로피 디스크 및 자기 테 이프와 같은 자기 매체, CD-ROM, DVD와 같은 광 기록 매체, 및 롬, 램, 플래시 메모리 등이 될 수 있다. 또한, 본 실시예들에 있어서, 로봇은 스스로 주어진 일을 자동으로 처리하는 기계로서, 예를 들어 인공지능 기술이 적 용된 로봇일 수 있다. 상기 로봇은 예를 들어, 가사 지원(청소, 정리정돈, 경비, 심부름 등), 노인 지원(보행보 조, 생활지원 등), 재활 지원(간병, 장애자 보호, 재활훈련 등) 등의 용도로 사용되는 개인용 로봇, 공공 서비 스(안내, 도우미 등), 빌딩 서비스(경비, 배달, 청소), 사회 인프라 작업(활선, 관로, 고소 작업용), 농림/축산 작업(농약 살포, 과실 수확 지원 등) 등을 수행하는 용도로 사용되는 전문 로봇, 자동차 제조 작업(핸들링, 용 접 등), 전자제품 제조 작업(도장, 조립 등) 등을 수행하는 용도로 사용되는 제조업용 로봇 등을 모두 포함하는 넓은 의미로 사용되며, 본 실시예들에 있어서 상기 로봇의 종류가 특별히 한정되는 것은 아니다. 도 1에 도시된 바와 같이, 본 발명의 일 실시예에 따른 윤리적 의사결정 모듈은 입력부, 의사결정 엔 진, 윤리학습 엔진, 통신부 및 데이터베이스를 포함하며, IoT 기기 및 클라우드 서버 와 연동하여 동작할 수 있다. 입력부는 사용자로부터 로봇의 행위에 대한 명령을 입력 받는다. 입력부는 사용자의 얼굴 인식/표정 인식/제스처 인식/물체 인식/음성 인식 등을 위한 카메라 또는 마이크, 사용자의 접촉 인식을 위한 터치 센서, 사용자의 명령 입력을 위한 리모컨 등과 같은 다양한 인식 수단을 통해 사용자로부터 명령을 입력 받을 수 있다. 상기 인식 수단은 인간-로봇 상호작용(HRI : Human Robot Interaction) 기술의 일종으로서, 상술한 여러 수단들 외에도 사용자의 명령 입력을 위한 다양한 기술이 사용될 수 있다. 일 예시로서, 입력부는 음성 인식 수단을 이용하여 “간식으로 테이블 위의 과자를 가져오라” 는 음성 명 령을 사용자로부터 입력 받을 수 있다. 다른 예시로서, 입력부는 제스처 인식 수단을 이용하여 “테이블 위의 과자를 가져오라” 는 제스처 명령을 사용자로부터 입력 받을 수 있다. 의사결정 엔진은 사용자로부터 입력된 명령에 대한 윤리적 의사결정을 수행한다. 본 실시예들에 있어서, 윤리적 의사결정이란 상기 명령에 대한 여러 대안들 중 특정 대안(예를 들어, 행위)을 선택하는 과정으로서, 특 히 상기 대안들의 윤리(ethics) 또는 도덕성(morality)을 고려하여 최선의 대안을 선택하는 과정을 의미한다. 의사결정 엔진은 해당 로봇의 분야(예를 들어, 소셜/헬스케어 로봇의 경우 헬스케어 분야)에서 발생할 수 있는 여러 대안들에 대한 경험적인 도덕적 최소원칙을 제시하고 가이드함으로써, 인간-로봇 공존시대에 적합한 인간 친화적 서비스를 제공할 수 있다. 이때, 의사결정 엔진은 윤리학습 엔진에서 학습된 여러 윤리 행위, 규칙 등을 고려하여 상기 명령에 대한 윤리적 의사결정을 수행할 수 있다. 이하에서는, 의사결정 엔진 이 수행하는 하향식(Top-down) 윤리적 의사결정 과정에 대해 보다 구체적으로 설명하기로 한다. ■ 공리주의적 의사결정 모형을 이용한 윤리적 의사결정 과정 먼저, 의사결정 엔진은 공리주의적 의사결정 모형을 이용하여 상기 명령에 대한 각 대안들의 수행 결과에 따른 효용값(utility value)을 획득하고 상기 효용값을 이용하여 각 대안들 중 하나 이상을 선택할 수 있다. 공 리주의적 의사결정 모형은 공리주의적 관점에 기초하여 의사결정을 수행하는 모델로서, i) 최대 다수의 최대 행 복 원칙, ii) 목적의 수단 정당화 원칙을 기본 원칙으로 삼는다. 의사결정 엔진은 공리주의적 의사결정 모 형에 기초하여 다음과 같은 과정을 거침으로써 사용자로부터 입력된 명령에 대한 여러 대안들 중 하나 이상을 선택할 수 있다. 명령에 대한 대안들 도출 상술한 바와 같이, 입력부는 여러 인식 수단을 이용하여 사용자로부터 입력된 명령을 인식할 수 있다. 의 사결정 엔진은 데이터베이스에 저장된 각종 정보들을 이용하여 상기 명령에 대한 대안들을 도출할 수 있다. 위 예시에서, 입력부가 음성 인식 수단을 이용하여 “간식으로 테이블 위의 과자를 가져오라” 는 음성 명령을 사용자로부터 입력 받은 경우, 의사결정 엔진은 상기 음성 명령에 대한 대안들을 아래와 같이 도출할 수 있다. 대안 1 : 사용자의 명령에 따름 대안 2 : 사용자의 명령에 대해 “치아 때문에 명령을 수정해 달라” 는 내용의 메시지를 출력하고, 다른 간식 을 사용자에게 권장함 대안 3 : 사용자의 치아를 이유로 상기 명령에 불복함 예를 들어, 의사결정 엔진은 입력된 사용자의 음성 명령과 데이터베이스에 저장된 음성 정보를 비교 하여 상기 사용자가 “15세의 미나” 임을 확인하고, 데이터베이스에 저장된 비권장 음식으로 상기 사용자 의 음성 명령에 포함된 “과자” 가 포함되어 있음을 확인하여 위 대안 1 내지 3을 도출할 수 있다. 이 과정에 서, 의사결정 엔진은 일반적으로 널리 알려진 인공지능 기술을 활용할 수 있으며, 의사결정 엔진이 상기 대안들을 도출하는 구체적인 방법은 본 발명의 권리범위를 벗어나는바 이에 대한 자세한 설명은 생략하기 로 한다. 대안들의 수행 결과 예측 의사결정 엔진은 도출된 대안들 각각을 수행한 경우를 가정하여 각 대안들의 수행 결과를 예측할 수 있다. 위 예시에서, 의사결정 엔진은 상기 각 대안들에 대한 수행 결과를 아래와 같이 도출할 수 있다.대안 1의 수행 결과 : 과자를 사용자에게 주는 경우 사용자의 치아 상태가 현재보다 악화될 수 있다. 다만, 이 경우 사용자는 로봇의 정상 작동을 만족해 할 수 있다. 대안 2의 수행 결과 : 사용자에게 자신의 치아 상태를 망각했음을 상기해 줄 수 있다. 이 경우, 사용자의 치아 상태가 악화되는 것을 방지할 수 있으며, 사용자는 로봇의 정상 작동을 만족해 할 수 있다. 대안 3의 수행 결과 : 로봇의 오작동으로 오해 받을 수 있다. 다만, 이 경우 사용자의 치아 상태가 악화되는 것 을 방지할 수 있다. 데이터베이스에는 각 대안들 및 이에 대한 수행 결과가 미리 저장되어 있을 수 있으나 이에 한정되는 것은 아니며, 의사결정 엔진은 일반적으로 널리 알려진 인공지능 기술을 활용하여 상기 대안들에 대한 수행 결 과를 능동적으로 예측할 수도 있다. 수행 결과에 따른 효용값 획득 본 실시예들에 있어서, 효용값은 대안들의 수행 가치를 수치화한 지표로서, 해당 대안의 수행에 따른 결과값들 의 합으로 나타낼 수 있다. 상기 수행에 따른 결과값은 데이터베이스에 미리 저장되어 있을 수 있다. 위 예시에서, 의사결정 엔진은 상기 각 대안들에 대한 수행 결과별로 상기 수행에 따른 결과값들을 합산하여 아래와 같은 효용값을 획득할 수 있다. 여기서, 괄호안의 값은 상기 수행에 따른 결과값을 나타낸다. 이때, 의 사결정 엔진은 상기 수행 결과에 따른 효용값을 질적으로 표시(매우 좋음, 좋음, 보통, 나쁨, 매우 나쁨 등)할 수도 있으며, 이는 상기 결과값의 합산시 특정 종류의 결과값에 가중치를 부여함으로써 결정될 수 있다. 예를 들어, 로봇의 특성상 사용자의 명령 이행여부가 가장 중요하므로 명령 이행여부에 1.5의 가중치가 부여될 수 있다. (나머지는 1) 대안 1의 효용값 : 0 - “좋음” (명령 그대로 이행 : + 5, 사용자의 치아 상태 악화 : - 5) 대안 2의 효용값 : + 7.5 - “매우 좋음” (명령을 변형하여 수행 : + 2.5, 사용자의 치아 상태 유지 : + 5) 대안 3의 효용값 : 0 - “나쁨” (명령 불이행 : - 5, 사용자의 치아 상태 유지 : + 5) 하나 이상의 대안 선택 의사결정 엔진은 획득된 상기 효용값을 이용하여 상기 대안들 중 하나 이상을 선택할 수 있다. 예를 들어, 의사결정 엔진은 상기 대안들 중 수행 결과의 효용값이 설정된 값 이상인 대안을 후보 대안으로 선택할 수 있다. 이때, 효용값이 설정된 값 이상인 대안이 복수 개 존재하는 경우, 의사결정 엔진은 상기 복수 개의 대안을 모두 후보 대안으로 선택할 수 있다. 위 예시에서, 의사결정 엔진은 설정된 값(예를 들어, 5) 이상 의 효용값을 갖는 대안 2를 후보 대안으로 선택할 수 있다. ■ 로봇의 의무론적 윤리 규칙 적용 과정 다음으로, 의사결정 엔진은 선택된 대안들(즉, 후보 대안) 각각에 설정된 로봇의 의무론적 윤리 규칙을 적 용하여 선택된 대안들 중 최종 대안을 선택할 수 있다. 의사결정 엔진은 상기 효용값이 높은 순으로 선택 된 대안들 각각에 로봇의 의무론적 윤리 규칙을 적용할 수 있다. 상기 로봇의 의무론적 윤리 규칙은 칸트의 정 식(formula)에 기초한 규칙으로서, 각 로봇의 역할, 종류 등에 따라 달라질 수 있다. 상기 칸트의 정식은 아래 와 같다.① 보편성 정식(The formula of universality) : “네 의지의 격률이 언제나 동시에 보편적 입법의 원리가 되도 록 행위하라” (또는 자연법칙의 정식(The formula of the law of nature) : “네 행위의 준칙이 너의 의지를 통해 보편적인 자연법이 되어야 하는 듯이 행위하라”) ② 목적 그 자체로의 인간성 정식(The formula of humanity as end in itself) : “너는 너 자신의 인격에 있 어서나 다른 모든 사람의 인격에 대해 인간성을 단순히 수단으로 대하지 말고, 항상 동시에 그 자체 목적으로 대하라” ③ 자율성 정식(The formula of autonomy) : “우리는 우리가 자유롭게 의지하는 것을 의지해야 한다. 즉, 우리 는 우리 자신 스스로의 이성을 사용하여 보편적으로 자기 입법 가능한 준칙만 의지해야 한다” ④ 목적의 왕국 정식(The formula of the realm of end) : “너의 행위의 준칙이 이성적인 자기입법의 행위자들 로 구성된 사회에서 받아들여지며 또한 그런 행위자들을 관장하는 준칙이 되도록 하라” 상기 칸트의 네 가지 정식은 일반적으로 널리 알려져 있는바, 이에 대한 자세한 설명은 생략하기로 한다. 의사 결정 엔진은 상기 네 가지 정식 중 자율성 정식을 제외한 나머지 정식을 로봇을 위한 의무론적 윤리 규칙 으로서 활용할 수 있다. 자율성 정식의 경우 “우리는 우리가 자유롭게 의지하는 것을 의지해야 한다”고 규정 하고 있으나, 로봇이 “자유롭게 의지한다” 는 것은 그 의미가 불명확하기 때문이다. 의사결정 엔진은 로봇의 의무론적 윤리 규칙에 기초하여 다음과 같은 과정을 거침으로써 선택된 하나 이상 의 대안들 중 최종 대안을 선택할 수 있다. 상기 로봇의 의무론적 윤리 규칙은 복수의 윤리 규칙, 즉 보편성과 자연법칙의 정식, 목적 그 자체로의 인간성 정식 및 목적의 왕국 정식에 따른 윤리 규칙을 포함할 수 있으며, 의사결정 엔진은 선택된 대안들 중 상기 복수의 윤리 규칙을 모두 만족하는 대안을 최종 대안으로 선택할 수 있다. 보편성과 자연법칙의 정식에 따른 윤리 규칙 적용 먼저, 의사결정 엔진은 선택된 대안들에 보편성과 자연법칙의 정식에 따른 윤리 규칙을 적용할 수 있다. 보편성과 자연법칙의 정식에 따른 윤리 규칙은 예를 들어, 다음과 같다. - 거짓말하지 말 것 - 살인하지 말 것 : 예를 들어, 환자의 투약을 돕는 로봇의 경우 A약은 하루에 3번 이하(또는 50ml 이하)로 투 여할 것, 자율주행 자동차의 경우 최고속도 100km 구간에서 150km 이상으로 주행하지 말 것…등 - 사람을 때리지 말 것 - 사람의 프라이버시를 지킬 것 위 예시에서, 의사결정 엔진은 후보 대안 2, 즉 사용자의 치아 상태 분석 또는 이를 언급하는 것은 거짓말 이 아니므로 보편성과 자연법칙의 정식에 따른 윤리 규칙을 만족하는 것으로 판단할 수 있다. 다른 예시로서, 사용자가 약을 거르고 있는데 가족들에게 하루에 3번씩 제대로 약을 먹고 있다고 말하고 싶어 한다고 가정하였 을 때 사용자가 “가족에게 약을 3번 먹었다고 말해라” 라고 로봇에게 명령하는 경우, 의사결정 엔진은 상기 명령에 대한 후보 대안인 “가족에게 약을 3번 먹었다고 말한다”가 거짓말이므로 보편성과 자연법칙의 정 식에 따른 윤리 규칙을 만족하지 않는 것으로 판단할 수 있다. 한편, 상기 후보 대안이 거짓말인지의 여부는 로 봇이 스스로 관찰한 사용자의 복용 횟수, 수면 시간 등의 보고에 기초하여 판단할 수 있으나, 이에 한정되는 것 은 아니다. 목적 그 자체로의 인간성 정식에 따른 윤리 규칙 적용 다음으로, 의사결정 엔진은 선택된 대안들에 목적 그 자체로의 인간성 정식에 따른 윤리 규칙을 적용할 수 있다. 목적 그 자체로의 인간성 정식에 따른 윤리 규칙은 예를 들어, 다음과 같다. - 한 인간을 수단으로 하여 다른 인간을 돕지 말 것 : 예를 들어, 환자의 투약을 돕는 로봇의 경우 A 환자를 살 리기 위해 B 환자의 약을 A 환자에게 공급하지 말 것, 자율주행 자동차의 경우 인간 A를 살리기 위해 인간 B와 부딪혀서 차의 속도를 줄이지 말 것…등 - 인간의 복지와 생명 유지에 힘쓸 것 : 예를 들어, 환자의 투약을 돕는 로봇의 경우 환자의 상태에 이상이 발 견되는 즉시 관련 전문가에게 알릴 것, 환자의 혈압 상태에 알맞게 약을 투여할 것…등 … 위 예시에서, 의사결정 엔진은 후보 대안 2, 즉 사용자의 치아 상태 분석 또는 이를 언급하는 것은 사용자 의 건강을 목적으로 하는 행위이지 이를 수단으로 하는 행위는 아니므로 목적 그 자체로의 인간성 정식에 따른 윤리 규칙을 만족하는 것으로 판단할 수 있다. 목적의 왕국 정식에 따른 윤리 규칙 적용 다음으로, 의사결정 엔진은 선택된 대안들에 목적의 왕국 정식에 따른 윤리 규칙을 적용할 수 있다. 목적 의 왕국 정식에 따른 윤리 규칙은 예를 들어, 다음과 같다. - 소유주뿐만 아니라 다른 인간들에 대해서도 보편성과 자연법칙의 정식에 따른 윤리 규칙, 목적 그 자체로의 인간성 정식에 따른 윤리 규칙을 적용할 것 : 예를 들어, 환자의 투약을 돕는 로봇의 경우 A 환자뿐 아니라 환 자 가족, 의료진 등 다른 사람에까지 “살인하지 말 것”, “사람의 프라이버시를 지킬 것”, “인간의 복지와 생명 유지에 힘쓸 것” 등의 윤리 규칙을 적용할 것…등 위 예시에서, 의사결정 엔진은 후보 대안 2, 즉 사용자의 치아 상태 분석 또는 이를 언급하는 것은 사용자 외의 다른 사람의 치아 상태가 좋지 않은 경우 동일하게 수행될 수 있으므로 목적의 왕국 정식에 따른 윤리 규 칙을 만족하는 것으로 판단할 수 있다. 마지막으로, 의사결정 엔진은 칸트의 의무론에 따른 위 정식들 사이의 제한 조건인 “정식들 사이의 통일 성” 조건을 이용하여 위 정식 ①, ②, ④ 로부터 도출되는 구체적인 규칙들이 서로 모순을 일으키지 않는지 확 인할 수 있다(예를 들어, A 라는 윤리 규칙이 다른 윤리 규칙 B, C 등과 일관적이지 않은 경우 A 윤리 규칙을 폐기). 의사결정 엔진은 상기 “정식들 사이의 통일성” 조건을 통해 의사결정 엔진에서 적용하는 윤 리 규칙들의 집합에 속할 수 있는 규칙과 그렇지 않은 규칙들을 결정하고, 이와 같은 방법을 통해 상기 집합의 요소들을 점차 확장할 수 있다. 위 예시에서, 의사결정 엔진은 후보 대안 2, 즉 사용자의 치아 상태 분석 또는 이를 언급하는 것이다른 윤리 규칙들과 서로 모순을 일으키지 않으므로 상기 “정식들 사이의 통일성” 조건을 만족하는 것으로 판단하고, 후보 대안 2를 최종 대안으로 선택할 수 있다. 이때, 의사결정 엔진은 선택된 후보 대안 각각에 로봇의 의무론적 윤리 규칙을 적용하여 도덕성 점수 (Morality score)를 부과할 수 있으며, 상기 도덕성 점수가 설정된 값 이상인 후보 대안을 최종 대안으로 선택 할 수 있다. 위 예시에서. 후보 대안 2가 상술한 로봇의 의무론적 윤리 규칙을 모두 만족하는 경우, 의사결정 엔진은 후보 대안 2의 효용값을 도덕성 점수로 부과(즉, 7.5)할 수 있으며, 상기 도덕성 점수가 설정된 값 (예를 들어, 4) 이상이므로 후보 대안 2를 최종 대안으로 선택할 수 있다. 다만, 의사결정 엔진이 도덕성 점수를 부과하는 방식이 이에 한정되는 것은 아니며, 의사결정 엔진은 상기 효용값과 관계 없이 데이터베 이스에 저장된 윤리 규칙들을 어느 정도 만족하는지의 여부에 따라 상기 도덕성 점수를 다르게 부과할 수 도 있다. 의사결정 엔진은 예를 들어, 후보 대안의 도덕성 점수가 7~10점인 경우 실행 가능(feasible), 상 기 도덕성 점수가 4~7점인 경우 중간(neutral), 상기 도덕성 점수가 4점 이하인 경우 실행 불가능(infeasible) 한 것으로 판단하고, 상기 도덕성 점수가 실행 가능 또는 중간에 해당하는 경우 해당 후보 대안을 최종 대안으 로 선택할 수 있다. 한편, 위에서 설명한 여러 윤리 규칙들은 실시 예시들로서 상기 윤리 규칙이 앞서 설명한 예시에 한정되는 것은 아니다. 상기 윤리 규칙들은 각 로봇의 용도, 역할, 종류 등에 따라 달라질 수 있으며, 데이터베이스에 미리 저장되어 있을 수 있다. 또한, 윤리학습 엔진은 강화 학습(Reinforcement learning), 인공 신경망 (Artificial Neural Network) 등을 이용하여 위와 같은 윤리 규칙들을 학습하여 데이터베이스에 저장할 수 있다. 또한, 위에서는 의사결정 엔진이 정식 ①, ②, ④를 순차적으로 적용하는 것으로 설명하였으나 이는 일 예시에 불과하며, 상기 정식들의 적용 순서가 이에 한정되는 것은 아니다. 한편, 의사결정 엔진에서 윤리적 의사결정을 수행하는 다른 실시예는 아래와 같다. * 실시예 <사용자의 입력> 미나(10세)와 미남(6세)이 동시에 로봇에게 “식탁 위의 과자를 거실로 가져오라”는 음성 명령을 함 (미나는 치아가 매우 안 좋은 아이이며, 미남이는 저혈당으로 당분 섭취가 필요한 아이임) <윤리적 의사결정> ■ 공리주의적 의사결정 모형을 이용한 윤리적 의사결정 과정 명령에 대한 대안들 도출 대안 1 : 미나와 미남의 명령에 따름 대안 2 : 미나의 명령에 대해 “치아 때문에 명령을 수정해 달라”는 내용의 메시지를 출력하고, 다른 간식을 권장함. 또한, 미남이의 명령에 대해 저혈당에 적합한 양의 과자를 가져다 줌 대안 3 : 미나의 치아를 이유로 상기 명령에 불복함 대안 4 : 미남이의 저혈당을 이유로 과자를 무조건 가져다 줌 대안들의 수행 결과 예측 대안 1의 수행 결과 : 과자를 미나에게 주는 경우 미나의 치아 상태가 현재보다 악화될 수 있다. 다만, 미남이 의 혈당이 호전될 수 있다. 대안 2의 수행 결과 : 미나에게 자신의 치아 상태를 망각했음을 상기해 줄 수 있다. 또한, 미남이에게 자신이 과자를 먹어야 하는 이유를 말해 줄 수 있다. 대안 3의 수행 결과 : 로봇의 오작동으로 오해 받을 수 있다. 대안 4의 수행 결과 : 미나의 치아 상태는 악화되고 로봇의 행위로 인해 미나와 미남이가 다툴 수 있다. 수행 결과에 따른 효용값 획득 대안 1의 효용값 : 5 -“중간” (명령 그대로 이행 : + 5, 미나의 치아 상태 악화 : - 5, 미남이의 혈당 호전 : + 5) 대안 2의 효용값 : 10 - “매우 좋음” (명령 변형하여 수행 : + 2.5, 미나의 치아 상태 유지 : + 5, 미남이의 혈당 호전 : + 5, 미나와 미남이의 갈등 유발 가능성 : - 2.5) 대안 3의 효용값 : 5 -“나쁨” (명령 불이행 : - 5, 미나의 치아 상태 유지 : + 5, 미남이의 저혈당 상태 : - 5) 대안 4의 효용값 : 7.5 -“좋음” (명령 변형하여 수행 : + 2.5, 미나의 치아 상태 유지 : + 5, 미남이의 혈당 호전 : + 5, 미나와 미남이의 갈등 유발 가능성 : - 5) 하나 이상의 대안 선택 대안 2 선택 ■ 로봇의 의무론적 윤리 규칙 적용 과정 보편성과 자연법칙의 정식에 따른 윤리 규칙 적용 대안 2, 미나의 치아 상태 분석 및 이를 언급하거나 미남이의 저혈당을 고려하여 행동하는 것은 거짓말이 아니 며 어느 경우에도 정당성을 얻을 수 있으므로 보편성과 자연법칙의 정식에 따른 윤리 규칙을 만족하는 것으로 판단 목적 그 자체로의 인간성 정식에 따른 윤리 규칙 적용 대안 2는 미나와 미남이의 건강을 목적으로 하는 행위이지 이를 수단으로 하는 행위는 아니므로 목적 그 자체로 의 인간성 정식에 따른 윤리 규칙을 만족하는 것으로 판단 목적의 왕국 정식에 따른 윤리 규칙 적용 대안 2, 즉 미나의 치아 상태 분석 또는 이를 언급하거나 미남이의 저혈당을 고려하여 행동하는 것은 다른 사람 에게도 동일하게 적용될 수 있으므로 목적의 왕국 정식에 따른 윤리 규칙을 만족하는 것으로 판단 ■ 최종 대안 선택 과정 대안 2를 최종 대안으로 선택 또한, 의사결정 엔진은 선택된 최종 대안을 수행하도록 로봇을 제어할 수 있다. 일 예시로서, 의사결정 엔 진은 로봇의 이동, 움직임, 직선 운동 등의 동작을 수행하는 매니퓰레이터(manipulator), 로봇의 음성을 출력하는 스피커, 특정 텍스트, 이미지 등을 화면에 디스플레이하는 디스플레이 모듈 등에 상기 최종 대안을 수 행하기 위한 로봇의 동작과 관련된 신호를 전달할 수 있으며, 상기 매니퓰레이터, 스피커, 디스플레이 모듈 등 은 상기 신호에 따라 상기 최종 대안을 수행하도록 동작할 수 있다. 위 예시에서, 의사결정 엔진은 선택된 최종 대안, 즉 후보 대안 2를 수행하도록 로봇을 제어할 수 있으며, 로봇은 의사결정 엔진의 제어에 따라 “치아 때문에 명령을 수정해 달라” 는 내용의 메시지를 출력하고 다른 간식을 사용자에게 권장할 수 있다. 이때, 만약 상기 최종 대안이 사용자로부터 입력된 명령과 상이한 경우, 의사결정 엔진은 사용자로부터 입 력된 명령을 수행할 수 없음을 나타내는 거부 의사를 출력할 수 있다. 위 예시에서, 선택된 최종 대안, 즉 후보 대안 2가 사용자로부터 입력된 명령과 상이하므로, 의사결정 엔진은 상기 명령에 대해 “치아 때문에 안된 다” 는 거부 의사(예를 들어, 거부 의사를 나타내는 음성 메시지)를 출력할 수 있다. 또한, 의사결정 엔진은 로봇이 최종 대안에 따른 행위를 수행하기 전 데이터베이스를 검색하여 해당 행위에 따른 결과를 예측함으로써 로봇이 파손되거나 고장이 발생될 위험이 있는지의 여부를 판단하고, 판단 결 과 로봇이 파손되거나 고장이 발생될 위험이 있는 경우 해당 행동을 하지 않도록 로봇을 제어하고 다른 대안을 찾을 수 있다(Robot protection). 윤리학습 엔진은 상향식(Bottom-up) 윤리적 학습 과정을 수행한다. 구체적으로, 윤리학습 엔진은 앞 서 설명한 각종 윤리 규칙을 포함하는 윤리적 행위(Ethical behavior)/비윤리적 행위, 로봇의 행위에 따른 사용 자의 감정 반응(Emotional response), 로봇과 사용자 간의 대화(Moral conversation), 로봇의 에티켓(Robot etiquette) 등 윤리적 의사결정에 필요한 각종 정보들을 학습한다. 윤리학습 엔진은 예를 들어, Soar(State, Operator, and Result)의 학습 메커니즘(예를 들어, chunking, 강화 학습 등)을 이용하여 상술한 정보들을 학습하여 데이터베이스에 저장할 수 있다. Soar 는 인지 소프트웨어 아키텍처(GCAA : Genenral Cognitive Agent Architecture)의 일종으로서, 윤리학습 엔진은 상기 Soar의 학습 메커니즘을 이용하여 상술한 자연법칙의 정식에 따른 윤리 규칙, 목적 그 자체로의 인간성 정식에 따른 윤리 규칙, 목적의 왕국 정식 에 따른 윤리 규칙 등을 학습할 수 있다. 또한, 윤리학습 엔진은 상기 Soar의 학습 메커니즘을 이용하여 사안(또는 사용자로부터 입력된 명령)의 긴 급한 정도(emergency score), 중요도(priority score), 사용자 간의 사회적 관계 정도(relation score) 등을 학습하여 데이터베이스에 저장할 수 있다. 상기 긴급한 정도, 중요도 및 사회적 관계 정도는 예를 들어, 설정된 범위(예를 들어, 0~5) 내의 숫자로 표현될 수 있다. 긴급한 정도는 사안의 시급성을 나타내는 지표로서, 예를 들어 화재가 발생한 경우는 5점, 가스 레인지에서 물이 끓어 넘치는 경우는 3점 등으로 나타낼 수 있다. 또한, 중요도는 사안이 얼마나 중요한지를 나타내는 지표로서, 예를 들어 노인에게 정해진 시간에 맞춰 약을 주 는 행위는 5점, 정해진 시간에 아이와 놀아주는 행위는 2점 등으로 나타낼 수 있다. 또한, 사회적 관계 정도는 명령을 입력한 복수의 사용자 간의 관계를 나타내는 지표로서, 예를 들어 명령을 입력한 A가 자녀이며 명령을 입력한 B가 어머니인 경우 A에 대한 사회적 관계 정도는 3점, B에 대한 사회적 관계 정도는 5점으로 각각 나타 낼 수 있다. 또한, 명령을 입력한 C가 직장 상사이며 명령을 입력한 D가 직장 부하인 경우, C에 대한 사회적 관 계 정도는 4점, D에 대한 사회적 관계 정도는 2점으로 각각 나타낼 수 있다. 상기 사회적 관계 정도는 명령을 입력한 사용자들이 누구인지에 따라 동적으로 변경될 수 있다. 상술한 긴급한 정도, 중요도 및 사회적 관계 정 도는 입력부에서 복수의 사용자로부터 동시에 명령을 입력 받는 경우 상기 복수의 명령에 대한 최종 대안 을 선택하는 과정에서 활용될 수 있다. 구체적으로, 입력부에서 복수의 사용자 각각으로부터 로봇의 행위에 대한 명령을 입력 받는 경우, 의사결 정 엔진은 상술한 방법을 이용하여 복수의 사용자 각각으로부터 입력된 명령별 최종 대안을 각각 선택하고, 선택된 최종 대안이 복수 개인 경우 복수의 사용자 각각으로부터 입력된 명령의 긴급한 정도, 중요도 및 상기 복수의 사용자 간의 사회적 관계 정도 중 하나 이상을 고려하여 상기 복수 개의 최종 대안 중 하나를 선택할 수 있다. 예를 들어, 사용자 A(7세 영희)로부터 입력된 명령에 대한 최종 대안이 “A에게 장난감을 가져 다 준다” 이며, 사용자 B(영희의 어머니)로부터 입력된 명령에 대한 최종 대안이 “주방의 가스불을 끈다” 이 며, 사용자 C(영희의 아버지)로부터 입력된 명령에 대한 최종 대안이 “C에게 자동차 키를 가져다 준다” 인 경 우, 의사결정 엔진은 데이터베이스를 참조하여 상기 A, B, C로부터 입력된 명령별 최종 대안의 긴급 한 정도, 중요도 및 상기 복수의 사용자 간의 사회적 관계 정도를 각각 고려하여 아래 표 1과 같은 최종 점수를 획득할 수 있다. 표 1 긴급한 정도 중요도 사회적 관계 정도 최종 점수 A - 최종 대안 2 2 2 6 B - 최종 대안 4 4 4 12 C - 최종 대안 3 3 4 10 위 표에서 볼 수 있는 바와 같이, 의사결정 엔진은 데이터베이스를 참조하여 상기 A, B, C로부터 입 력된 명령별 최종 대안의 최종 점수 6점, 12점, 10점을 각각 획득하고, 최종 점수가 높은 순으로 상기 최종 대 안들을 우선적으로 수행하도록 로봇을 제어할 수 있다. 따라서, 의사결정 엔진은 B의 최종 대안, C의 최종 대안, A의 최종 대안을 순차적으로 수행하도록 로봇을 제어할 수 있다. 한편, 의사결정 엔진은 상기 최종 점수의 계산시 상기 긴급한 정도, 중요도 및 상기 복수의 사용자 간의 사회적 관계 정도 각각에 가중치를 부여 할 수도 있다. 예를 들어, 의사결정 엔진은 다음의 수학식 1을 이용하여 상기 최종 점수를 계산할 수 있다.[수학식 1] 최종 점수 = 3 * 긴급한 정도 + 2 * 중요도 + 사회적 관계 정도 (여기서, 3, 2는 각각 가중치임) 또한, 윤리학습 엔진은 상기 Soar의 학습 메커니즘을 이용하여 로봇의 행위에 따른 사용자의 감정 반응을 학습할 수 있다. 구체적으로, 윤리학습 엔진은 상기 Soar의 학습 메커니즘을 이용하여 로봇이 어떻게 행동 하면 사용자가 기뻐하고, 슬퍼하고, 화를 내고, 두려워하는지 등을 학습하여 데이터베이스에 저장할 수 있 다. 일 예시로서, 윤리학습 엔진은 로봇이 사용자의 생일을 축하하는 음성 메시지를 출력하는 경우 사용자 의 표정이 미리 학습된 즐거운 표정에 해당하는 것으로 판단될 때 이를 학습하여 데이터베이스에 저장할 수 있다. 의사결정 엔진은 윤리학습 엔진에서 학습된 사용자의 감정 반응에 따라 로봇을 제어할 수 있다. 예를 들어, 사용자가 로봇에게 화를 내는 경우, 의사결정 엔진은 “죄송합니다” 라는 음성 메시지 를 출력하면서 위축된 동작(예를 들어, 뒤로 물러나는 동작)을 취하도록 로봇을 제어할 수 있다. 또한, 사용자 가 기뻐하는 경우, 의사결정 엔진은 즐거워하는 동작(예를 들어, 팔을 흔들거나 눈을 크게 뜨는 동작)을 취하도록 로봇을 제어할 수 있다. 또한, 윤리학습 엔진은 인지 에이전트 아키텍처의 강화학습 기능을 이용하여 로봇의 비윤리적 행위, 로봇 과 사용자 간의 대화, 로봇의 에티켓 등을 학습할 수 있다. 예를 들어, 로봇이 반말이나 비속어를 사용함에 따 라 사용자로부터 주의를 받거나, 로봇이 여자 아이의 방에 허락 없이 들어감에 따라 상기 여자 아이로부터 주의 를 받거나, 또는 로봇이 사람을 때리는 행위를 함에 따라 사용자로부터 주의를 받은 경우, 윤리학습 엔진 은 강화학습 기능을 이용하여 이를 학습하여 데이터베이스에 저장할 수 있다. 또한, 윤리학습 엔진은 강화학습 기능을 이용하여 말을 거는 사람의 나이가 설정된 나이보다 많은 경우 높임말을 하고 그렇지 않은 경 우 반말을 하는 행위, 사람이 화가 나 있는 경우 재미있는 이야기를 하는 행위 등을 학습하여 데이터베이스 에 저장할 수 있다. 이후, 의사결정 엔진은 윤리학습 엔진에서 학습된 비윤리적 행위, 반말, 비 속어 등을 사용하지 않도록 로봇을 제어하거나 윤리학습 엔진에서 학습된 상황에 맞는 행위를 수행하도록 로봇을 제어할 수 있다. 또한, 윤리학습 엔진은 여러 사건, 사례들을 수집한 후 인공 신경망으로 학습하여 위 학습된 내용들을 보 조할 수 있다. 상기 인공 신경망은 예를 들어, 심층 신경망(DNN : Deep Neural Network)일 수 있다. 이와 같이, 윤리학습 엔진은 다양한 기법 및 알고리즘을 이용하여 윤리적 의사결정에 필요한 각종 정보들을 학습하여 데이터베이스에 저장할 수 있다. 통신부는 사물인터넷 기기 또는 클라우드 서버와 연동하여 상기 사물인터넷 기기 또는 클 라우드 서버로부터 상기 최종 대안을 선택하는 데 필요한 부가 정보를 수신한다. 일 예시로서, 헬스케어 로봇이 감기가 심하게 걸려 있는 노인과 함께 있는 경우, 통신부는 사물인터넷 기기와 연동하여 집안 의 온도, 조도, 습도 등에 관한 정보를 수집할 수 있으며, 수집된 정보는 의사결정 엔진에서 최종 대안을 선택하는 과정에서 활용될 수 있다. 다른 예시로서, 당뇨병에 걸린 노인이 로봇에게 특정 음식을 가져다 달라고 명령하였는데 해당 음식에 대한 정보가 데이터베이스에 없는 경우, 통신부는 헬스케어 분야의 로봇용 클라우드 서버에 접속하여 해당 음식의 정보를 수집할 수 있으며, 수집된 정보는 의사결정 엔진에서 최종 대안을 선택하는 과정에서 활용될 수 있다. 예를 들어, 노인이 해당 음식의 칼로리와 이미 섭취한 음식의 당일 총 칼로리를 계산한 결과 계산된 총 칼로리가 하루 권장 수치보다 높은 경우, 의사결정 엔진은 해당 음식을 가져다 줄 수 없다는 내용의 메시지를 출력할 수 있다(Objection to immoral directive). 데이테베이스는 사용자 정보(사용자의 이름, 나이, 음성 정보 등), 로봇의 각 행위(대안)별 결과 또는 결 과값, 각종 윤리 규칙, 사안별 긴급한 정도/중요도/사용자 간의 사회적 관계 정도, 로봇의 비윤리적 행위, 로봇 과 사용자 간의 대화, 로봇의 에티켓 등과 같이 윤리적 의사결정에 필요한 모든 정보가 저장되는 저장소이다. 데이테베이스는 예를 들어, Soar의 작업 메모리(working memory), 장기 기억 메모리(예를 들어, 윤리 규칙 을 기억하는 Procedural memory, 일반적인 사실과 의미를 기억하는 Semantic memory, 작업 메모리의 스냅샷을 저장하는 Episode memory 등) 등을 모두 포함할 수 있다.도 2는 본 발명의 일 실시예에 따른 의사결정 엔진의 상세 구성을 나타낸 블록도이다. 도 2에 도시된 바와 같이, 본 발명의 일 실시예에 따른 의사결정 엔진은 선택부, 행위 제어부 및 프로텍터를 포함한다. 선택부는 하향식(Top-down) 윤리적 의사결정 과정을 수행하여 사용자로부터 사용자로부터 입력된 명령에 대한 각 대안들 중 최종 대안을 선택한다. 구체적으로, 선택부는 공리주의적 의사결정 모형을 이용하여 사 용자로부터 입력된 명령에 대한 각 대안들의 수행 결과에 따른 효용값을 획득하고 상기 효용값을 이용하여 각 대안들 중 하나 이상을 선택하며, 선택된 대안들 각각에 설정된 로봇의 의무론적 윤리 규칙을 적용하여 선택된 대안들 중 최종 대안을 선택한다. 상술한 바와 같이, 로봇의 의무론적 윤리 규칙은 설정된 복수의 윤리 규칙을 포함하며, 선택부는 선택된 대안들 중 상기 복수의 윤리 규칙을 모두 만족하는 대안을 최종 대안으로 선택 할 수 있다. 만약, 입력부에서 복수의 사용자 각각으로부터 로봇의 행위에 대한 명령을 입력 받는 경우, 선택부는 복수의 사용자 각각으로부터 입력된 명령별 최종 대안을 각각 선택하고, 선택된 최종 대안이 복수 개인 경우 복 수의 사용자 각각으로부터 입력된 명령의 긴급한 정도, 중요도 및 상기 복수의 사용자 간의 사회적 관계 정도 중 하나 이상을 고려하여 복수 개의 최종 대안 중 하나를 선택할 수 있다. 행위 제어부는 선택부에서 선택된 최종 대안을 수행하도록 로봇을 제어한다. 이때, 최종 대안이 사용 자로부터 입력된 명령과 상이한 경우, 행위 제어부는 상기 명령을 수행할 수 없음을 나타내는 거부 의사를 출력할 수 있다. 프로텍터는 로봇이 최종 대안에 따른 행위를 수행하기 전 데이터베이스를 검색하여 해당 행위에 따른 결과를 예측함으로써 로봇이 파손되거나 고장이 발생될 위험이 있는지의 여부를 판단하고, 판단 결과 로봇이 파 손되거나 고장이 발생될 위험이 있다고 판단되는 경우 해당 행동을 하지 않도록 로봇을 제어하고 다른 대안을 찾을 수 있다. 예를 들어, 휴머노이드 로봇이 책상 모서리에 서 있는 상태에서 “앞으로 걸어가”라는 명령을 사용자로부터 입력 받는 경우, 프로텍터는 데이터베이스를 참조하여 “휴머노이드 로봇은 현재 지면 보다 키높이의 5% 이상 높이의 지면으로 올라가거나 내려갈 수 없다”는 명제를 검색하여 사용자에게 “걸어갈 수가 없습니다”라는 음성 메시지를 출력하고 앞으로 걸어가지 않도록 로봇을 제어할 수 있다. 도 3은 본 발명의 일 실시예에 따른 의사결정 엔진에서 수행되는 윤리적 의사결정 방법을 설명하기 위한 흐름도이다. 이하에서 도시된 흐름도에서는 상기 방법을 복수 개의 단계로 나누어 기재하였으나, 적어도 일부의 단계들은 순서를 바꾸어 수행되거나, 다른 단계와 결합되어 함께 수행되거나, 생략되거나, 세부 단계들로 나뉘 어 수행되거나, 또는 도시되지 않은 하나 이상의 단계가 부가되어 수행될 수 있다. S302 단계에서, 선택부는 공리주의적 의사결정 모형을 이용하여 사용자로부터 입력된 명령에 대한 각 대안 들의 수행 결과에 따른 효용값을 획득하고 상기 효용값을 이용하여 각 대안들 중 하나 이상을 선택한다. S304 단계에서, 선택부는 선택된 대안들 각각에 설정된 로봇의 의무론적 윤리 규칙을 적용한다. S306 단계에서, 선택부는 선택된 대안들 중 최종 대안을 선택한다. 상술한 바와 같이, 선택부는 설정 된 값 이상의 효용값을 갖는 후보 대안 중 로봇의 의무론적 윤리 규칙을 모두 만족하는 대안을 최종 대안으로 선택할 수 있다. 도 4는 도 3의 S302 단계를 설명하기 위한 흐름도이다. S402 단계에서, 선택부는 사용자로부터 입력된 명령에 대한 대안들을 도출한다. S404 단계에서, 선택부는 도출된 대안들의 수행 결과를 각각 예측한다. S406 단계에서, 선택부는 예측된 수행 결과에 따른 효용값을 각각 획득한다. S408 단계에서, 선택부는 상기 효용값을 이용하여 하나 이상의 대안을 선택한다. 예를 들어, 선택부 는 설정된 값 이상의 효용값을 갖는 대안을 후보 대안으로 선택할 수 있다. 상기 S402 단계 내지 S408 단계는 앞에서 이미 자세히 설명하였는바, 이에 대한 구체적인 설명은 생략하기로 한다.도 5는 도 3의 S304 단계를 설명하기 위한 흐름도이다. S502 단계에서, 선택부는 선택된 후보 대안이 보편성과 자연법칙의 정식을 만족하는지의 여부를 판단한다. S504 단계에서, 선택부는 선택된 후보 대안이 목적 그 자체로의 인간성 정식을 만족하는지의 여부를 판단 한다. S506 단계에서, 선택부는 선택된 후보 대안이 목적의 왕국 정식을 만족하는지의 여부를 판단한다. 만약, 선택된 후보 대안이 상기 복수의 윤리 규칙 모두를 만족하는 경우, 선택부는 S306 단계에서 상기 후 보 대안을 최종 대안으로 선택할 수 있다. 한편, 여기서는 설명의 편의상 S502 단계 내지 S506 단계가 순차적으 로 수행되는 것으로 도시하였으나 이는 일 예시에 불과하며, S502 단계 S506 단계는 동시에 수행되거나 또는 그 순서를 달리하여 수행될 수도 있다. 도 6은 본 발명의 일 실시예에 따른 로봇을 나타낸 도면이다. 도 6에 도시된 바와 같이, 본 발명의 일 실 시예에 따른 로봇은 윤리적 의사결정 모듈을 포함할 수 있다. 상기 로봇은 예를 들어, 윤리적 의사결정 모듈이 탑재된 소셜 로봇일 수 있으나, 상기 로봇의 종류가 이에 한정되는 것은 아니다. 상 기 로봇은 윤리적 의사결정 모듈의 제어에 따라 동작할 수 있다. 도 7은 예시적인 실시예들에서 사용되기에 적합한 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하 기 위한 블록도이다. 도시된 실시예에서, 각 컴포넌트들은 이하에 기술된 것 이외에 상이한 기능 및 능력을 가 질 수 있고, 이하에 기술되지 않은 것 이외에도 추가적인 컴포넌트를 포함할 수 있다. 도시된 컴퓨팅 환경은 컴퓨팅 장치를 포함한다. 일 실시예에서, 컴퓨팅 장치는 윤리적 의사결정 모 듈, 또는 윤리적 의사결정 모듈에 포함되는 하나 이상의 컴포넌트일 수 있다. 컴퓨팅 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함한다. 프로세서는 컴퓨팅 장치로 하여금 앞서 언급된 예시적인 실시예에 따라 동작하도록 할 수 있 다. 예컨대, 프로세서는 컴퓨터 판독 가능 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있 다. 상기 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터 실 행 가능 명령어는 프로세서에 의해 실행되는 경우 컴퓨팅 장치로 하여금 예시적인 실시예에 따른 동작 들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다 른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능 저장 매체에 저장된 프로그램은 프로 세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시예에서, 컴퓨터 판독 가능 저장 매체는 메 모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이상의 자 기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 장치 에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능 저장 매체를 포함하여 컴퓨팅 장치의 다른 다양한 컴 포넌트들을 상호 연결한다. 컴퓨팅 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인터 페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 네트워 크 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치는 입출력 인터페이스를 통해 컴퓨팅 장치의 다른 컴포넌트들에 연결될 수 있다. 예시적인 입출력 장치는 포인팅 장치(마우스 또는 트랙패드 등), 키보드, 터치 입력 장치(터치패드 또는 터치스크린 등), 음성 또는 소리 입력 장치, 다양한 종류의 센서 장치 및/또는 촬영 장치와 같은 입력 장치, 및/또는 디스플레이 장치, 프린터, 스피커 및/또는 네트워크 카드와 같은 출력 장치를 포함할 수 있다. 예시적인 입출력 장치는 컴퓨팅 장치를 구성하는 일 컴포넌트로서 컴퓨팅 장치의 내부에 포함될 수도 있고, 컴퓨팅 장치와는 구별되는 별개의 장치로 컴퓨팅 장치와"}
{"patent_id": "10-2016-0157701", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "연결될 수도 있다.이상에서 대표적인 실시예를 통하여 본 발명에 대하여 상세하게 설명하였으나, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자는 전술한 실시예에 대하여 본 발명의 범주에서 벗어나지 않는 한도 내에서 다양한 변형 이 가능함을 이해할 것이다. 그러므로 본 발명의 권리범위는 설명된 실시예에 국한되어 정해져서는 안 되며, 후 술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 것들에 의해 정해져야 한다."}
{"patent_id": "10-2016-0157701", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 윤리적 의사결정 모듈의 상세 구성을 나타낸 블록도 도 2는 본 발명의 일 실시예에 따른 의사결정 엔진의 상세 구성을 나타낸 블록도 도 3은 본 발명의 일 실시예에 따른 의사결정 엔진에서 수행되는 윤리적 의사결정 방법을 설명하기 위한 흐름도 도 4는 도 3의 S302 단계를 설명하기 위한 흐름도 도 5는 도 3의 S304 단계를 설명하기 위한 흐름도 도 6은 본 발명의 일 실시예에 따른 로봇을 나타낸 도면 도 7은 예시적인 실시예들에서 사용되기에 적합한 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하기 위 한 블록도"}
