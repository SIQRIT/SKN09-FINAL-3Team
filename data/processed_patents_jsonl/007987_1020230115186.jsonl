{"patent_id": "10-2023-0115186", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0032403", "출원번호": "10-2023-0115186", "발명의 명칭": "의복 패턴 이미지 처리 방법 및 이를 수행하는 장치", "출원인": "(주)씨에이플래닛", "발명자": "안창기"}}
{"patent_id": "10-2023-0115186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "2차원의 의복 패턴 데이터 및 의복 정보 데이터를 포함하는 의복 학습 데이터를 획득하는 단계;상기 의복 학습 데이터로 인공지능 모델을 학습시키는 단계;학습된 상기 인공지능 모델에 2차원의 입력 의복 패턴을 입력하는 단계; 및상기 2차원의 입력 의복 패턴에 대응하는 3차원의 의복 정보를 생성하는 단계를 포함하는, 의복 패턴 이미지 처리 방법."}
{"patent_id": "10-2023-0115186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 의복 학습 데이터를 획득하는 단계는,적어도 하나의 의복 패턴이 포함된 2차원의 이미지로부터 2차원의 패턴 이미지를 추출하는 단계;상기 2차원의 패턴 이미지로부터 상기 2차원의 패턴 이미지에 대응하는 의복 부위 정보를 추출하는 단계; 및 상기 2차원의 패턴 이미지 및 상기 의복 부위 정보를 기초로, 상기 인공지능 모델을 학습시키기 위한 상기 2차원의 의복 패턴 데이터를 생성하는 단계를 포함하는, 의복 패턴 이미지 처리 방법."}
{"patent_id": "10-2023-0115186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 의복 정보 데이터는,의복 이미지, 착장 이미지, 작지 정보, 사이즈 스펙 정보, 패턴 제도 파일 및 패턴별 라벨 어노테이션 중 적어도 하나를 포함하는, 의복 패턴 이미지 처리 방법."}
{"patent_id": "10-2023-0115186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 인공지능 모델을 학습시키는 단계는,하나 이상의 상기 2차원의 의복 패턴 데이터를 3차원 가상 모델에 적용하여, 가상 착장 정보를 생성하는 단계;상기 가상 착장 정보에 기초하여 상기 2차원의 의복 패턴 데이터에 대응하는 패턴착장 대응맵(wearing map)을생성하는 단계; 및상기 패턴착장 대응맵을 상기 인공지능 모델에게 학습시키는 단계를 더 포함하는, 의복 패턴 이미지 처리 방법."}
{"patent_id": "10-2023-0115186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 패턴착장 대응맵(wearing map)을 생성하는 단계는,상기 가상 모델의 신체의 일 지점에 대한 법선 벡터와 상기 가상 착장 정보에 따라 상기 가상 모델에 적용된 패턴과의 교차점의 유무 및 상기 일 지점과 상기 교차점 사이의 거리를, 상기 가상 모델의 신체의 모든 점에 대하공개특허 10-2025-0032403-3-여 산출하는 단계; 및상기 가상 모델의 신체의 모든 점에 대한 상기 교차점의 유무 및 상기 거리를 취합하여, 상기 패턴착장 대응맵을 생성하는 단계를 포함하는, 의복 패턴 이미지 처리 방법."}
{"patent_id": "10-2023-0115186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 패턴착장 대응맵(wearing map)을 생성하는 단계는,상기 패턴착장 대응맵에 대응되는 상기 2차원의 의복 패턴 데이터에 포함된 패턴별로 특성 정보를 부여하는 단계를 포함하는, 의복 패턴 이미지 처리 방법."}
{"patent_id": "10-2023-0115186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 3차원의 의복 정보를 생성하는 단계는,하나 이상의 상기 2차원의 의복 입력 패턴에 기초하여 3차원의 패턴 정보를 추출하는 단계; 및상기 3차원의 패턴 정보를 결합하여 3차원의 의복 이미지 및 3차원의 의복 착장 이미지 중 적어도 하나를 생성하는 단계를 포함하는, 의복 패턴 이미지 처리 방법."}
{"patent_id": "10-2023-0115186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "적어도 하나의 명령어를 저장하는 메모리;상기 적어도 하나의 명령어를 실행하는 프로세서; 및이미지를 획득하는 입력부를 포함하고,상기 프로세서는 상기 적어도 하나의 명령어를 실행함으로써,2차원의 의복 패턴 데이터 및 의복 정보 데이터를 포함하는 의복 학습 데이터를 획득하고, 상기 의복 학습 데이터로 인공지능 모델을 학습시키고, 학습된 상기 인공지능 모델에 2차원의 입력 의복 패턴을 입력하여 상기 입력부에 의해 획득된 2차원의 입력 의복 패턴에 대응하는 3차원의 의복 패턴 정보를 생성하는, 의복 패턴 이미지처리 장치."}
{"patent_id": "10-2023-0115186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 입력부는,카메라 및 촬영 모듈을 포함하는 휴대 단말기 중 적어도 하나를 포함하는, 의복 패턴 이미지 처리 장치."}
{"patent_id": "10-2023-0115186", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 의복 패턴 이미지 처리 방법 및 이를 수행하는 장치에 관한 것으로서, 구체적으로는 의복 패턴 이미지 를 인공지능 모델에 의해 처리하는 방법 및 이를 수행하는 장치에 관한 것이다. 본 발명의 일 실시예에 따른 의 복 패턴 이미지 처리 방법은, 2차원의 의복 패턴 데이터 및 의복 정보 데이터를 포함하는 의복 학습 데이터를 획 득하는 단계, 의복 학습 데이터로 인공지능 모델을 학습시키는 단계, 학습된 인공지능 모델에 2차원의 입력 의복 패턴을 입력하는 단계, 및 2차원의 입력 의복 패턴에 대응하는 3차원의 의복 정보를 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0115186", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 의복 패턴 이미지 처리 방법 및 이를 수행하는 장치에 관한 것으로서, 구체적으로는 의복 패턴 이미 지를 인공지능 모델에 의해 처리하는 방법 및 이를 수행하는 장치에 관한 것이다."}
{"patent_id": "10-2023-0115186", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 컴퓨터 비전 기술과 인공지능 기술이 발달함에 따라 여러 가지 산업 분야에 영향을 미치고 있다. 그러나 의복 제조 생산 및 의복 트렌드 관련 분야, 특히, 의복 패턴 이미지를 처리하여 3차원의 이미지를 형성함에 있 어서 특화된 기술이 미비한 실정이다.이와 관련하여 등록번호 10-2392342 “의류 제조방법(manufacturing method of clothing)”에 따르면, 만들고 자 하는 의류의 용도 및 형태에 맞도록 다수개의 패턴을 도안하고 패턴본을 형성하여 시접함으로써 의류를 제조 하는 방법에 대해 기재하고 있으나 의복 패턴 이미지로 패턴본을 형성하는 데 그칠 뿐, 의복 패턴 이미지를 처 리하는 기술에 대해서는 개시하지 못한다."}
{"patent_id": "10-2023-0115186", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "한편, 전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 등록번호 10-2392342 (2022.04.26)"}
{"patent_id": "10-2023-0115186", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 일 과제는, 다양한 의복 패턴을 처리하여 3차원의 의복 정보를 생성하는 것이다. 본 발명이 해결하고자 하는 일 과제는, 인공지능 모델을 학습시켜 의복 패턴으로부터 3차원의 의복 이미지, 3차 원의 착장 이미지, 3차원의 패턴 이미지, 3차원의 패턴 착장 이미지 등 3차원의 의복 정보를 생성하는 것이다. 본 발명이 해결하고자 하는 일 과제는, 의복 패턴을 처리하여 3차원의 의복 정보를 생성함에 있어서, 의복 특성 을 반영하여 실제에 가까운 3차원의 의복 정보를 생성하는 것이다. 본 발명의 해결하고자 하는 일 과제는, 실제에 가까운 3차원의 의복 정보를 생성하기 위한 인공지능 모델의 학 습 데이터를 생성하는 방법을 제시하는 것이다. 본 발명의 해결하고자 하는 일 과제는, 다양한 방식으로 제공되는 의복 패턴을 가상의 모델에 맞게 세부적으로 패턴의 크기, 디자인, 및 패턴 연결 위치 등을 변경할 수 있는 패턴착장 대응맵을 생성하는 것이다. 본 발명의 해결하고자 하는 일 과제는, 의복의 디자인을 세부적으로 다양하게 변경할 수 있는 패턴착장 대응맵 을 인공지능 모델로 학습하여, 입력된 의복 패턴에 대한 정보와 디자이너의 세부적인 조정에 따라 3차원 의복 정보를 생성하는 것이다. 본 발명의 과제들은 이상에서 언급한 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들은 아래의 기재로 부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0115186", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 바와 같은 과제를 해결하기 위한 본 발명의 일 실시예에 따른 의복 패턴 이미지 처리 방법은, 2차원의 의복 패턴 데이터 및 의복 정보 데이터를 포함하는 의복 학습 데이터를 획득하는 단계, 의복 학습 데이터로 인 공지능 모델을 학습시키는 단계, 학습된 인공지능 모델에 2차원의 입력 의복 패턴을 입력하는 단계, 및 2차원의 입력 의복 패턴에 대응하는 3차원의 의복 정보를 생성하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 따른 의복 학습 데이터를 획득하는 단계는, 적어도 하나의 의복 패턴이 포함된 2차원의 이미지로부터 2차원의 패턴 이미지를 추출하는 단계, 2차원의 패턴 이미지로부터 2차원의 패턴 이미지에 대응하 는 의복 부위 정보를 추출하는 단계, 및 2차원의 패턴 이미지 및 의복 부위 정보를 기초로, 인공지능 모델을 학 습시키기 위한 2차원의 의복 패턴 데이터를 생성하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 따른 의복 정보 데이터는, 의복 이미지, 착장 이미지, 작지 정보, 사이즈 스펙 정보, 패 턴 제도 파일 및 패턴별 라벨 어노테이션 중 적어도 하나를 포함할 수 있다. 본 발명의 일 실시예에 따른 인공지능 모델을 학습시키는 단계는, 하나 이상의 2차원의 의복 패턴 데이터를 3차 원 가상 모델에 적용하여, 가상 착장 정보를 생성하는 단계, 가상 착장 정보에 기초하여 2차원의 의복 패턴 데 이터에 대응하는 패턴착장 대응맵(wearing map)을 생성하는 단계, 및 패턴착장 대응맵을 인공지능 모델에게 학 습시키는 단계를 더 포함할 수 있다.본 발명의 일 실시예에 따른 패턴착장 대응맵을 생성하는 단계는, 가상 모델의 신체의 일 지점에 대한 법선 벡 터와 가상 착장 정보에 따라 가상 모델에 적용된 패턴과의 교차점의 유무 및 일 지점과 교차점 사이의 거리를, 가상 모델의 신체의 모든 점에 대하여 산출하는 단계, 및 가상 모델의 신체의 모든 점에 대한 교차점의 유무 및 거리를 취합하여, 패턴착장 대응맵을 생성하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 따른 패턴착장 대응맵을 생성하는 단계는, 패턴착장 대응맵에 대응되는 2차원의 의복 패 턴 데이터에 포함된 패턴별로 특성 정보를 부여하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 따른 3차원의 의복 정보를 생성하는 단계는, 하나 이상의 2차원의 의복 입력 패턴에 기 초하여 3차원의 패턴 정보를 추출하는 단계, 3차원의 패턴 정보를 결합하여 3차원의 의복 이미지 및 3차원의 의 복 착장 이미지 중 적어도 하나를 생성하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 따른 의복 패턴 이미지 처리 장치는, 하나의 명령어를 저장하는 메모리, 적어도 하나의 명령어를 실행하는 프로세서, 및 이미지를 획득하는 입력부를 포함하고, 프로세서는 적어도 하나의 명령어를 실 행함으로써, 2차원의 의복 패턴 데이터 및 의복 정보 데이터를 포함하는 의복 학습 데이터를 획득하고, 의복 학 습 데이터로 인공지능 모델을 학습시키고, 학습된 인공지능 모델에 2차원의 입력 의복 패턴을 입력하여 입력부 에 의해 획득된 2차원의 입력 의복 패턴에 대응하는 3차원의 의복 정보를 생성한다. 본 발명의 일 실시예에 따른 입력부는, 카메라 및 촬영 모듈을 포함하는 휴대 단말기 중 적어도 하나를 포함할 수 있다."}
{"patent_id": "10-2023-0115186", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 과제 해결 수단 중 어느 하나에 의하면, 본 발명의 일 실시예는, 의복 패턴을 처리하여 3차원의 의복 정보를 생성할 수 있다. 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 본 발명의 일 실시예는, 인공지능 모델을 학습시켜 의복 패 턴으로부터 3차원의 의복 이미지, 3차원의 착장 이미지, 3차원의 패턴 이미지, 3차원의 패턴 착장 이미지 등 3 차원의 의복 정보를 생성할 수 있다. 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 본 발명의 일 실시예는, 의복 패턴을 처리하여 3차원의 의복 정보를 생성함에 있어서, 의복 특성을 반영하여 실제에 가까운 3차원의 의복 정보를 생성할 수 있다. 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 본 발명의 일 실시예는, 실제에 가까운 3차원의 의복 정보를 생성하기 위한 인공지능 모델 학습 데이터 생성 방법을 제시할 수 있다. 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 본 발명의 일 실시예는, 다양한 방식으로 제공되는 의복 패 턴을 가상의 모델에 맞게 세부적으로 패턴의 크기, 디자인, 및 패턴 연결 위치 등을 변경할 수 있는 패턴착장 대응맵을 생성할 수 있다. 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 본 발명의 일 실시예는, 의복의 디자인을 세부적으로 다양하 게 변경할 수 있는 패턴착장 대응맵을 인공지능 모델로 학습하여, 입력된 의복 패턴에 대한 정보와 디자이너의 세부적인 조정에 따라 3차원 의복 정보를 생성할 수 있다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2023-0115186", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0115186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이다. 본 실시예들은 단지 본 발명의 개시가 완전하도록 하여서 본 발명이 속하는"}
{"patent_id": "10-2023-0115186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 즉, 본 발명 은 청구항의 범주에 의해 정의될 뿐이다. 본 발명의 실시예를 설명하기 위한 도면에 개시된 형상, 크기, 비율, 각도, 개수 등은 예시적인 것이므로 본 발 명이 도시된 사항에 한정되는 것은 아니다. 또한, 본 발명을 설명함에 있어서, 관련된 공지 기술에 대한 구체적 인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명은 생략한다. 본 명세서 상에서 언급된 '포함한다', '갖는다', '이루어진다' 등이 사용되는 경우 '~만'이 사용되지 않는 이상 다른 부분 이 추가될 수 있다. 구성요소를 단수로 표현한 경우에 특별히 명시적인 기재 사항이 없는 한 복수를 포함하는 경우를 포함한다. 구성요소를 해석함에 있어서, 별도의 명시적 기재가 없더라도 오차 범위를 포함하는 것으로 해석한다. 비록 제1, 제2 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한 되지 않는다. 이들 용어들은 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라 서, 이하에서 언급되는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있다. 별도로 명시하지 않는 한 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 본 발명의 여러 실시예들의 각각 특징들이 부분적으로 또는 전체적으로 서로 결합 또는 조합 가능하며, 당업자 가 충분히 이해할 수 있듯이 기술적으로 다양한 연동 및 구동이 가능하며, 각 실시예들이 서로에 대하여 독립적 으로 실시 가능할 수도 있고 연관 관계로 함께 실시 가능할 수도 있다. 이하, 첨부된 도면을 참조하여, 본 발명을 상세히 설명하기로 한다. 도 1을 참조하면, 도 1은 본 발명의 일 실시예에 따라 의복 패턴 이미지 처리 방법을 수행하는 의복 패턴 이미 지 처리 장치의 구성을 도시한 블록도이다. 도 1에 따르면, 의복 패턴 이미지 처리 장치는 메모리, 입력부 및 프로세서를 포함할 수 있다. 먼저, 메모리는 의복 패턴 이미지 처리 장치의 적어도 하나의 다른 구성요소에 관계된 명령어 또는 데이터를 저장하는 것으로서 실시예에 따르면, 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리 (flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 메모 리는 프로세서에 의해 액세스되며, 프로세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 본 개시에서 메모리라는 용어는 메모리, 프로세서 내 롬(미도시), 램(미도시) 또는 의복 패턴 이미지 처리 장치에 장착되는 메모리 카드(미도시)(예를 들어, micro SD 카드, 메모 리 스틱)를 포함할 수 있다. 또한, 메모리는 의복 패턴 이미지 처리 방법을 수행하기 위한 데이터, 예를 들면, 의복 패턴에 관한 데이 터나 그를 처리하기 위한 인공지능 모델, 인공지능 모델이 처리한 결과값들을 저장할 수 있다. 그리고 입력부는 다양한 사용자 입력을 수신하여 프로세서로 전달하는 것으로서 실시예에 따라 터치 센서, (디지털) 펜 센서, 압력 센서, 마우스, 키보드 또는 키를 포함할 수 있다. 터치 센서는, 예를 들면, 정전 식, 감압식, 적외선 방식, 또는 초음파 방식 중 적어도 하나의 방식을 사용할 수 있다. (디지털) 펜 센서는, 예 를 들면, 터치 패널의 일부이거나, 별도의 인식용 쉬트를 포함할 수 있다. 키는, 예를 들면, 물리 적인 버튼,광학식 키, 또는 키패드를 포함할 수 있다. 또한, 입력부는 이미지를 획득하는 카메라 및 촬영 모듈을 포함하는 휴대 단말기 등을 포함할 수 있다. 이 를 통해 입력부는 의복 패턴 이미지 처리 방법을 통해 처리하고자 하는 의복 패턴에 관한 이미지를 획득하 거나 그 밖에 의복 패턴 이미지 처리 방법을 수행하는데 있어서 필요한 각종 이미지를 획득할 수 있다. 또한, 입력부는 의복 패턴에 관한 이미지나 의복 패턴 이미지 처리 방법을 수행하는데 필요한 다양한 이미지를 사용자로부터 직접 수신할 수 있다. 나아가, 입력부는 의복 패턴에 관한 이미지나 의복 패턴 이미지 처리 방법을 수행하는데 필요한 다양한 이미지를 인터넷 등과 같은 온라인을 통해 연결된 다른 서버나 전자 장치로부 터 수신할 수도 있다. 그리고 프로세서는 메모리에 저장된 적어도 하나의 명령어를 실행하는 것으로서 CPU, GPU 또는 이들 의 결합으로 구현될 수 있다. 이 같은 프로세서는 입력부를 통한 사용자 입력에 따라 메모리에 저장된 적어도 하나의 명령어 를 실행하여 의복 패턴 이미지 처리 방법을 수행할 수 있다. 이와 관련해서는 도 2를 참조하여 보다 구체적으로 설명한다. 도 2는 의복 패턴 이미지 처리 장치가 수행하는 의복 패턴 이미지 처리 방법을 설명하기 위한 예시도이다. 도 3은 본 발명의 일 실시예에 따라 의복 학습 데이터를 획득하는 방법을 간략히 도시한 예시도이다. 도 2에 따르면, 프로세서는 의복 학습 데이터를 획득하고(A), 이를 인공 지능 모델에 학습시키고(B), 학습된 인공지능 모델에 처리하고자 하는 입력 의복 패턴을 입력하여, 입력 의복 패턴에 대응하는 3차원의 의복 정보를 생성할 수 있다(C). 구체적으로, 프로세서는, 적어도 하나의 2차원 의복 패턴 데이터 및 의복 정보 데이터를 포함하는 의복 학 습 데이터를 획득한다. 프로세서는, 의복 학습 데이터를 3차원 모델링을 통해 3차원 의복 목업 (mock up)을 생성할 수 있다. 프로세서는, 3차원 의복 목업을 기초로 가상 착장 정보를 생성 하고, 이를 통해 적어도 하나의 패턴착장 대응맵(wearing map)을 생성할 수 있다. 패턴착장 대응맵의 구체적인 생성 과정에 대해서는 도 6 및 도 7을 참조하여 후술한다. 도 1 및 도 2를 참조하면, 프로세서는, 이러한 의복 학습 데이터 및 패턴착장 대응맵 중 적어도 하나를 기초로 인공지능 모델을 학습시킨다. 또한, 프로세서는, 입력부를 통해서 학습된 인공지 능 모델에 추론 대상이 되는 2차원의 입력 의복 패턴을 입력 받을 수 있다. 입력된 2차원의 입력 의복 패턴은 인공지능 모델에 의해 추론된다. 인공지능 모델은 2차원 입력 의복 패턴을 추론하여 2 차원의 입력 의복 패턴에 대응하는 3차원의 의복 정보를 생성한다. 3차원의 의복 정보에 대한 구체 적인 설명은 도 8을 참조하여 후술한다. 이때, 인공지능 모델이 학습하는 의복 학습 데이터는 '2차원의 의복 패턴 데이터' 및 '의복 정보 데이터'를 포함할 수 있다. 이와 관련하여 도 2 및 도 3(a)를 참조하면, 프로세서는 적어도 하나의 의복 패턴이 포함된 2차원의 이미 지로부터 '2차원의 의복 패턴 데이터'를 추출할 수 있다. 도 2 및 도 3(b)를 참조하면, 프로세서는 '2차원의 의복 패턴 데이터'에 대응하는 '의복 학습 데이터'를 생성할 수 있다. 여기서, 의복 학습 데 이터는 작업자들이 의복에 대한 정보 데이터인 의복 정보 데이터를 입력한 것일 수 있다. 예를 들어, 의복 정보 데이터는 의복 이미지, 착장 이미지, 작지 정보, 사이즈 스펙 정보, 패턴 제도 파일 및 패 턴별 라벨 어노테이션 중 적어도 하나를 포함할 수 있다. 이때, '2차원의 의복 패턴 데이터'는 2차원의 의복 패턴과 이에 관련된 정보를 포함하는 것으로서, 예를 들 면, '2차원의 패턴 이미지(11a)'를 포함할 수 있다. 도 4는 본 발명의 일 실시예에 따른 '2차원의 패턴 이미지(11a)'의 예시도이다. 도 4에 따르면, '2차원의 패턴 이미지(11a)'는 의복을 이루는 각 조각인 패턴의 형태를 정의하여 시각화한 것으로서 2차원의 패턴 이미지(11 a)에 따라 옷감을 제작하여 결합함으로써 의복을 완성할 수 있다. 도 4에는 하나의 의복을 이루는 모든 패턴을 도시하였으나 실시예에 따라 2차원의 패턴 이미지(11a)에는 하나의 의복을 이루는 모든 패턴 중 일부, 예를 들 면, 하나의 패턴만이 포함될 수도 있다. 실시예에 따르면, 프로세서는 적어도 하나의 의복 패턴이 포함된 2차원의 이미지로부터 2차원의 패턴 이미지(11a)를 추출할 수 있다. 이때, 2차원의 이미지란 3차원의 위치 정보가 매핑되지 않은 이미지를 말하는 것으로서 패턴 제도 이미지뿐만 아니라 실물 패턴을 촬영한 이미지를 포함할 수 있으며, 프로세서는2차 원 이미지로부터 패턴의 경계를 분석하고, 패턴의 경계에 기초한 폐곡선을 생성하여 패턴의 내외부를 구분함 으로써 2차원의 패턴 이미지(11a)를 추출할 수 있다. 또한, 프로세서는 2차원의 패턴 이미지(11a)로부터 2차원의 패턴 이미지(11a)에 대응하는 의복 부위 정보 를 추출할 수 있다. 이때, 의복 부위 정보란 패턴 이미지가 의복을 이루었을 때 적용될 신체 부위를 말한다. 예 를 들면, 프로세서는 패턴 이미지의 형태의 특징을 분석하고, 이에 따라 기존에 분석이 완료된 패턴과의 형태 상 유사점을 분석한 후 유사한 것으로 분류된 기존 패턴에 매칭된 의복 부위 정보를 2차원의 패턴 이미지 (11a)에 포함된 각 의복 패턴의 의복 부위 정보로 추정할 수 있다. 실시예에 따르면 프로세서는, 이와 같은 2차원의 패턴 이미지(11a) 및 의복 부위 정보를 기초로 인공지능 모델을 학습시키기 위한 2차원의 의복 패턴 데이터를 생성할 수 있다. 예를 들면, 프로세서는 2차 원의 패턴 이미지(11a) 및 의복 부위 정보를 매칭하여 학습을 위한 데이터를 생성할 수 있다. 이때, 프로세서 는 패턴 이미지의 오류를 검사하거나 패턴 이미지를 포함하는 데이터를 가공하여 학습 데이터의 품질을 향 상시킬 수 있다. 도 5는 '의복 정보 데이터'의 실시예를 도시한 예시도이다. 도 3(b) 및 도 5에 따르면, '의복 정보 데이터'는 2차원의 의복 패턴 데이터에 대응되는 각종 정보를 포함하는 것으로서 의복 패턴에 대한 정보 및 의복 패턴에 기초하여 제작되는 의복에 대한 정보를 포함할 수 있 다. 예를 들어, 도 5의 (a)와 같은 의복 이미지, 의복을 마네킹 또는 인체가 착장한 착장 이미지(12a), 도 5의 (b) 와 같이 의복을 제작하기 위한 지시 사항을 포함하는 작지 정보(12b), 도 5의 (c)와 같이 사이즈에 따른 의복의 각 부위 별 수치를 포함하는 사이즈 스펙 정보(12c), 도 5의 (d)와 같은 패턴 제도 파일(12d) 및 패턴별 라벨 어노테이션 중 적어도 하나를 포함할 수 있다. 이때, 의복 정보 데이터는 2차원의 의복 패턴 데이터와 매칭되어 의복 학습 데이터에 포함될 수 있으며, 이 같은 작업은 자동화된 장치를 통해 수행되거나 크라우 드 워커와 같은 작업자들을 통해 수행될 수 있다. 그리고 프로세서는 3차원 모델링을 통해 생성한 3차원의 의복 목업을 3차원의 가상 모델에 적용하여 '가상 착장 정보'를 생성할 수 있고, '가상 착장 정보'에 기초하여 2차원의 의복 패턴 데이터에 대응하는 '패턴착장 대응맵'을 생성할 수 있다. 도 6은 본 발명의 일 실시예에 따른 '패턴착장 대응맵'의 생성 과정을 설명하기 위한 예시도이다. 먼저 도 6의 (a)는 2차원의 의복 패턴 데이터의 예시이다. 이어서 도 6의 (b)는 2차원의 의복 패턴 데이터에 대 응하는 '가상 착장 정보'를 시각화한 것이다. 여기서 '가상 착장 정보'란, 2차원의 의복 패턴 데이터에 포함된 패턴을 3차원 가상 모델의 신체에 적용하여 랜더링한 정보로서, 3차원 가상 모델의 신체에 적용되는 위 치에 대한 정보를 포할 수 있다. 도 2 및 도 6의 (b)를 참조하면, 프로세서는 가상 착장 정보를 생성하기 위하여 의복 학습 데이터(1 0)에 포함된 2차원의 의복 패턴 데이터를 입체화하여 3차원 모델링을 수행한다. 이어서, 프로세서는 3차원 의복 목업을 생성한 후, 생성한 3차원 의복 목업에 기초하여 가상 착장 정보를 생성할 수 있다. 이 때, 프로세서는 상술한 의복 학습 데이터를 학습한 인공지능 모델을 통해, 하나 이상의 2차원의 의복 패턴 데이터를 추론하고 입체화하여 3차원으로 모델링한 결과로서 3차원 의복 목업을 생성할 수 있다. 또한, 도 6의 (c)는 가상 착장 정보에 대응하는 패턴착장 대응맵을 시각화한 것이다. 도 6의 (c)의 패 턴착장 대응맵과 관련하여서는 도 7을 참조하여 후술한다. 도 6의 (a), (b) 및 (c)에 도시된 2차원의 의복 패턴 데이터, 가상 착장 정보 및 패턴착장 대응맵은 각각 순서대로 대응한다. 도 7은 본 발명의 일 실시예에 따른 패턴착장 대응맵의 생성을 설명하기 위한 예시도이다. 도 7은 3차원 가 상 모델의 신체 일부(B)와 3차원 가상 모델에 적용되는 패턴의 일부(C1)에 대한 예시를 도시하고 있다. 도 6 및 도 7에 따르면, 프로세서는 3차원 가상 모델의 신체(B)의 일 지점에 대한 법선 벡터(N)를 도출할 수 있다. 구체적으로, 3차원 가상 모델의 신체(B)의 일 지점에 접하는 가상 평면을 연장하고, 가상 모델의 신체 (B)의 일 지점을 지나는 것으로서 가상 평면에 대해 수직한 직선(N)을 연산할 수 있다. 또한, 프로세서는 연산한 직선(N)과 가상 착장 정보에 기초하여 가상 모델에 적용된 패턴(C1)과의 교 차점의 유무를 판단할 수 있다. 구체적으로, 프로세서는 3차원 가상 모델의 신체(B)의 일 지점에 대응하는 직선(N)과 3차원 가상 모델의 신체(B)에 적용된 패턴(C1)과의 교차점이 있다면 1로, 교차점이 없다면 0으로 이 진화하여 표현할 수 있다. 또한, 프로세서는 이 같은 교차점 여부에 따른 값을 3차원 가상 모델의 신체 (B)의 모든 부분에 대해 지정할 수 있다. 또한, 프로세서는 상술한 교차점의 여부에 기초하여 3차원 가상 모델의 신체(B)와 의복의 거리를 설정하고, 이에 따라 패턴착장 대응맵을 생성할 수 있다. 구체적으로, 3차원 가상 모델의 신체(B)의 모든 지점에 대해 설정된 교차점 여부에 따른 값인 0 또는 1에 따라 가상 모델의 신체(B)와 의복의 거리를 설정할 수 있다. 예를 들어, 교차점이 있을 때, 즉, 교차점 여부에 따른 값이 1일 때, 가상 모델의 신체(B)와 의복의 거리 를 0으로 설정할 수 있다. 또한, 교차점이 없을 때, 즉, 교차점 여부에 따른 값이 0일 때, 가상 모델의 신체 (B)와 의복간의 거리를 무한대로 설정할 수 있다. 이에 따라 가상 모델의 신체(B)와 의복이 거리가 0인 부분, 즉, 가상 모델의 신체(B)와 의복이 접한 부분(C2)을 추출할 수 있다. 다시 말해, 프로세서는 이 같은 교차점의 유무 및 이에 따른 가상 모델의 신체(B)와 의복 간의 거리를 3차 원 가상 모델의 신체(B)의 모든 점에 대하여 산출할 수 있고, 이를 취합하여 패턴착장 대응맵을 생성할 수 있다. 즉, 프로세서는 2차원의 의복 패턴 데이터를 3차원 가상 모델(B)에 적용하고, 이에 기초하여 가상 모델의 신체(B)에 패턴(C1)이 적용되는 지점을 파악함으로써 2차원의 패턴을 인체에 적용했을 때에 근사하게 입 체화할 수 있다. 나아가 프로세서는 패턴착장 대응맵에 대하여 패턴별로 특성 정보를 부여할 수 있다. 구체적으로, 프 로세서는 2차원의 의복 패턴 데이터에 포함된 하나 이상의 의복 패턴에 대응하여 패턴착장 대응맵을 생성하고, 이에 대해 패턴별로 특성 정보를 부여할 수 있다. 예를 들면, 프로세서는 패턴착장 대응맵 에 패턴별 색상 정보를 부여하거나 패턴착장 대응맵 각각을 별개의 레이어로 분리함으로써, 다양한 패턴이 섞인 복잡한 패턴착장 대응맵을 보다 용이하게 파악할 수 있다. 실시예에 따르면, 프로세서는 상술한 바와 같이 생성된 패턴착장 대응맵을 인공지능 모델에 학습 시킬 수 있다. 이를 통해, 인공지능 모델은 2차원의 의복 패턴을 입체화함에 있어서, 인체가 착장했을 때에 가까운 모습으로 입체화할 수 있다. 상술한 바와 같이, 프로세서는 2차원의 의복 패턴 데이터 및 의복 정보 데이터를 포함하는 의복 학습 데이 터를 인공지능 모델에 학습시키며, 2차원의 의복 패턴 데이터에 기초하여 생성한 패턴착장 대응맵 을 인공지능 모델에 학습시킬 수 있다. 실시예에 따르면, 프로세서는 2차원의 입력 의복 패턴에 대응하는 3차원의 의복 정보를 생성할 수 있다. 이때, 2차원의 입력 의복 패턴은 하나 이상의 패턴 정보, 하나 이상의 패턴이 포함된 이미지, 패턴 제도 파일 등을 포함할 수 있다. 이때, 2차원의 입력 의복 패턴은 메모리에 기저장된 것일 수 있고, 입력부를 통해 다른 장치로부터 수신한 것일 수 있다. 또한, 실시예에 따라 카메라 및 촬영 모듈을 포함하 는 휴대 단말기 중 적어도 하나를 포함하는 입력부를 통해 획득한 것일 수도 있다 그리고 3차원의 의복 정 보는 3차원의 의복 이미지 및 3차원의 의복 착장 이미지 중 적어도 하나를 포함할 수 있다. 도 8은 3차원의 의복 정보의 실시예를 도시한 예시도이다. 도 8의 (a)에 따르면, 프로세서는 2차원의 입력 의복 패턴에 대응하는 3차원의 의복 정보로서, 3차원의 완성된 의복 이미지를 생성할 수 있다. 또한, 도 8의 (b)에 따르면, 프로세서는 2차원의 입력 의복 패턴에 대응하는 3차원의 의복 정보로서, 완성된 의복을 사람이 착장한 모습을 3차원으로 표시한 이미지를 생성할 수 있다. 즉, 프로세서는 학습된 인공지능 모델을 통해 2차원의 입력 의복 패턴에 대응하여 완성된 의복의 형상을 이미지화하거나 2차원의 입력 의복 패턴에 대응하여 완성된 의복을 사람이 착장한 형상을 이미지화 할 수 있다. 그 밖에도 프로세서는 2차원의 입력 의복 패턴에 포함된 패턴 각각이 입체화됐을 때의 이미지 나 패턴을 사람의 신체에 적용했을 때의 이미지를 생성할 수 있다. 이를 위해 프로세서는 인공지능 모델을 통해 2차원의 의복 입력 패턴에 기초하여 '3차원의 패턴 정 보'를 추출하고, 추출한 3차원의 패턴 정보를 결합하여 3차원의 의복 정보를 생성할 수 있다. 이때, '3차원의 패턴 정보'는 2차원의 입력 의복 패턴을 입체화한 정보로서, 예를 들어, 패턴착장 대응맵 을 포함할 수 있다. 실시예에 따르면, 프로세서는 인공지능 모델을 통해 2차원의 입력 의복 패턴 에 포함된 하나 이상의 의복 패턴에 대응하는 패턴착장 대응맵을 생성하고, 이를 결합한 후 시각화하여 3차원의 의복 정보를 생성할 수 있다. 시각화 단계에서는 컬러 정보를 부여하고, 중력에 따른 의복의 늘어짐을 연산하여 반영하는 등의 데이터 가공을 거쳐 보다 실물에 가까운 3차원의 의복 정보를 생성할 수 있다, 다음으로 도 9 내지 도 13은 본 발명의 일 실시예에 따라 의복 패턴 이미지 처리 장치가 수행하는 의복 패 턴 이미지 처리 방법에 관한 순서도이다. 먼저 도 9에 따르면, 의복 패턴 이미지 처리 장치는 2차원의 의복 패턴 데이터 및 의복 정보 데이터를 포 함하는 의복 학습 데이터를 획득할 수 있다(S901). 이때, 2차원의 의복 패턴 데이터는, 2차원의 의복 패턴과 이에 관련된 정보를 포함하는 것으로서, 예를 들면, 하나 이상의 2차원의 패턴 이미지를 포함할 수 있으며, 의복 정보 데이터는 의복 이미지, 착장 이미지, 작지 정 보, 사이즈 스펙 정보, 패턴 제도 파일 및 패턴별 라벨 어노테이션 중 적어도 하나를 포함할 수 있다. 그리고 의복 패턴 이미지 처리 장치는 의복 학습 데이터로 인공지능 모델을 학습시킬 수 있다 (S902). 또한, 의복 패턴 이미지 처리 장치는 학습된 인공지능 모델에 2차원의 입력 의복 패턴을 입력할 수 있고(S903), 인공지능 모델을 통해 입력된 2차원의 입력 의복 패턴에 대응하는 3차원의 의복 패턴 정보를 생성할 수 있다(S904). 다음으로 도 10을 참조하면, 의복 패턴 이미지 처리 장치는 의복 학습 데이터를 획득함에 있어서 (S901), 적어도 하나의 의복 패턴이 포함된 2차원의 이미지로부터 2차원의 패턴 이미지를 추출할 수 있다 (S1001). 이때, 2차원의 이미지란, 3차원의 위치 정보가 매핑되지 않은 이미지를 말하는 것으로서 패턴 제도 이미지뿐만 아니라 실물 패턴을 촬영한 이미지를 포함할 수 있으며, 2차원의 패턴 이미지란, 의복을 이루는 각 조각인 패턴 의 형태를 정의하여 시각화한 것으로서 의복 패턴 이미지 처리 장치는 하나 이상의 의복 패턴을 포함하는 2차원의 이미지로부터 2차원의 패턴 이미지를 추출할 수 있다. 다음으로 의복 패턴 이미지 처리 장치는 2차원의 패턴 이미지로부터 2차원의 패턴 이미지에 대응하는 의복 부위 정보를 추출할 수 있다(S1002). 여기서 의복 부위 정보란, 패턴 이미지가 의복을 이루었을 때 적용될 신체 부위를 말하며, 의복 패턴 이미지 처 리 장치는 2차원의 패턴 이미지를 분석하여 하나 이상의 2차원의 패턴 이미지 각각에 대응하는 의복 부위 정보를 추출할 수 있다. 그리고 의복 패턴 이미지 처리 장치는 2차원의 패턴 이미지 및 의복 부위 정보를 기초로, 인공지능 모델 을 학습시키기 위한 2차원의 의복 패턴 데이터를 생성할 수 있다(S1003). 예를 들어, 2차원의 패턴 이미지 및 의복 부위 정보를 매칭하여 의복 패턴 데이터를 생성할 수 있다. 그리고 도 11을 참조하면, 인공지능 모델을 학습시키는 단계와 관련하여(S902), 의복 패턴 이미지 처리 장 치는 인공지능 모델을 학습시키기 위하여 하나 이상의 2차원의 의복 패턴 데이터를 3차원 가상 모델에 적용하여, 가상 착장 정보를 생성할 수 있다(S1101). 이때, 가상 착장 정보는, 2차원의 의복 패턴 데이터에 포함된 패턴을 3차원 가상 모델의 신체에 적용하여 랜더링한 정보로서, 3차원 가상 모델의 신체에 적용되는 위치에 대한 정보를 포할 수 있다. 그리고 의복 패턴 이미지 처리 장치는 가상 착장 정보에 기초하여 2차원의 의복 패턴 데이터에 대응하 는 패턴착장 대응맵(wearing map)을 생성하고(S1102), 패턴착장 대응맵을 인공지능 모델에게 학습 시킬 수 있다(S1103). 이때, 패턴착장 대응맵은 가상 모델의 신체에 의복 패턴이 적용되는 위치를 신체 모든 점에 대해 맵핑한 정 보를 포함하는 것으로서 도 12를 참조하여 패턴착장 대응맵을 생성하는 단계(S1102)에 대해 보다 구체적으 로 설명하겠다. 도 12를 참조하면, 의복 패턴 이미지 처리 장치는 가상 모델의 신체의 일 지점에 대한 법선 벡터와 가상 착장 정보에 따라 가상 모델에 적용된 패턴과의 교차점의 유무를, 가상 모델의 신체의 모든 점에 대하여 산 출할 수 있다(S1201). 그리고 가상 모델의 신체의 모든 점에 대한 교차점의 유무를 취합하여 패턴착장 대응맵을 생성할 수 있다 (S1202). 이를 통해, 의복 패턴 이미지 처리 장치는 인공지능 모델을 통해 2차원의 의복 패턴을 입체화함에 있 어서, 인체가 착장했을 때에 가까운 모습으로 입체화할 수 있다. 그리고 패턴착장 대응맵을 생성함에 있어서(S1102), 의복 패턴 이미지 처리 장치는 패턴착장 대응맵 에 대응되는 2차원의 의복 패턴 데이터에 포함된 패턴별로 특성 정보를 부여할 수 있다. 예를 들어, 패턴착장 대응맵에 패턴별 색상 정보를 부여하거나 패턴착장 대응맵 각각을 별개의 레이어 로 분리할 수 있다. 다음으로 도 13을 참조하면, 3차원의 패턴 정보를 생성함에 있어서(S904), 의복 패턴 이미지 처리 장치는 하나 이상의 2차원의 의복 입력 패턴에 기초하여 3차원의 패턴 정보를 추출하고(S1301), 3차원의 패턴 정보를 결합하여 3차원의 의복 이미지 및 3차원의 의복 착장 이미지 중 적어도 하나를 생성할 수 있다(S1302). 이때, 3차원의 패턴 정보는 2차원의 의복 입력 패턴을 입체화한 정보를 포함하며, 3차원의 의복 이미지는 완성 된 의복의 형상, 완성된 의복을 사람이 착장한 형상에 대한 위치 정보 또는 이를 시각화한 이미지, 패턴 각각이 입체화됐을 때의 위치 정보나 패턴을 사람의 신체에 적용했을 때의 위치 정보 또는 이를 시각화한 이미지 등을 포함할 수 있다. 실시예에 따르면, 의복 패턴 이미지 처리 장치는 시각화 단계에서는 컬러 정보를 부여하고, 중력에 따른 의복의 늘어짐을 연산하여 반영하는 등의 데이터 가공을 거쳐 보다 실물에 가까운 3차원의 의복 정보를 생 성할 수 있다. 이상 첨부된 도면을 참조하여 본 발명의 실시예들을 더욱 상세하게 설명하였으나, 본 발명은 반드시 이러한 실 시예로 국한되는 것은 아니고, 본 발명의 기술사상을 벗어나지 않는 범위 내에서 다양하게 변형실시될 수 있다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 그러므로, 이상에서 기 술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위 에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0115186", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따라 의복 패턴 이미지 처리 방법을 수행하는 의복 패턴 이미지 처리 장치의 구 성을 도시한 블록도이다. 도 2는 의복 패턴 이미지 처리 장치가 수행하는 의복 패턴 이미지 처리 방법을 설명하기 위한 예시도이다. 도 3은 본 발명의 일 실시예에 따라 의복 학습 데이터를 획득하는 방법을 간략히 도시한 예시도이다. 도 4는 본 발명의 일 실시예에 따른 2차원의 패턴 이미지의 예시도이다. 도 5는 의복 정보 데이터의 실시예를 도시한 예시도이다.도 6은 본 발명의 일 실시예에 따른 패턴착장 대응맵의 생성 과정을 설명하기 위한 예시도이다. 도 7은 본 발명의 일 실시예에 따른 패턴착장 대응맵의 생성을 설명하기 위한 예시도이다. 도 8은 3차원의 의복 정보의 실시예를 도시한 예시도이다. 도 9 내지 도 13은 실시예에 따라 의복 패턴 이미지 처리 장치가 수행하는 의복 패턴 이미지 처리 방법에 관한 순서도이다."}
