{"patent_id": "10-2023-0136532", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0053386", "출원번호": "10-2023-0136532", "발명의 명칭": "인공지능 기반 동물실험 문헌 정보 자동추출 시스템 및 그 방법", "출원인": "대한민국", "발명자": "주재걸"}}
{"patent_id": "10-2023-0136532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "학술정보 텍스트를 입력하는 입력부, 상기 입력부를 통해 입력된 학술 정보 텍스트 내의 부분 텍스트를 식별하고 부분 텍스트 간의 관계를 식별하여 불연속 엔티티를 포함하는 핵심 정보를 추출하는 NER 모델, 및 상기 NER모델을 통해 추출된 핵심 정보를 출력하는 출력부를 포함하는 인공지능 기반 동물실험 문헌 정보 자동추출 시스템으로서,상기 NER 모델은, 동물실험 문헌 텍스트를 밀집벡터로 변환하는 임베딩부;Conditional Layer Normalization 층, BERT 방식의 표현부, 및 Dilated Convolution 층의 학습부; 및Multilayer Perceptrons(MLP) predictor 층 및 Biaffine predictor 층의 예측부;를 포함하며,상기 NER 모델을 지도학습 방식(Supervised Learning)으로 학습하기 위해 전처리된 데이터에 핵심정보를 레이블링(Labeling)하되, 텍스트로된 학습 데이터로부터 특정 단위 명사를 서치하고, 상기 서치된 특정 단위 명사와더불어 상기 서치된 특정 단위 명사 직전의 숫자 텍스트를 상기 서치된 특정 단위 명사에 대응되는 핵심정보로레이블링하며,상기 레이블링된 문헌 학습 데이터의 핵심 정보는 상기 NER 모델의 학습 시에, 정답(ground truth)으로서 간주되는 인공지능 기반 동물실험 문헌 정보 자동추출 시스템."}
{"patent_id": "10-2023-0136532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 예측부는 서로 상이하게 각각 입력된 상기 MLP predictor 층 및 상기 Biaffine predictor 층의 출력을 합쳐서 최종 예측에 활용하는 인공지능 기반 동물실험 문헌 정보 자동추출 시스템."}
{"patent_id": "10-2023-0136532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 학습부는 상기 Conditional Layer Normalization 층, BERT 방식의 표현부, 및 Dilated Convolution 층의조합으로 이루어진 인공지능 기반 동물실험 문헌 정보 자동추출 시스템."}
{"patent_id": "10-2023-0136532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 NER 모델은 핵심정보 클래스와 문헌 텍스트 시퀀스 내 해당 클래스로 예측되는 여러 불연속 단어로 이루어질 수도 있는 표현 문구를 추출하는 인공지능 기반 동물실험 문헌 정보 자동추출 시스템."}
{"patent_id": "10-2023-0136532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,상기 NER 모델은 손실함수를 최소화하기 위해 하기 식에 의해 모델 파라미터를 결정하는 것으로 학습되는 인공공개특허 10-2025-0053386-3-지능 기반 동물실험 문헌 정보 자동추출 시스템. 여기서, n은 데이터 개수이고, C는 클래스 개수로 추출하고자 하는 핵심정보 종류 개수이며, 는 실제 값이고는 실제 값에 대한 예측 확률값이다."}
{"patent_id": "10-2023-0136532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "학술정보 텍스트를 입력하는 입력부, 상기 입력된 텍스트 내의 핵심 정보를 추출하는 NER 모델, 및 상기 NER 모델을 통해 추출된 핵심 정보를 출력하는 출력부를 포함하는 인공지능 기반 동물실험 문헌 정보 자동추출 시스템에 의한 인공지능 기반 동물실험 문헌 정보 자동추출 방법으로서,수집된 문헌에서 문헌 학습 데이터를 수집하는 단계;상기 수집된 문헌 학습 데이터를 전처리하는 단계;상기 전처리된 문헌 학습 데이터를 레이블링하는 단계; 및 상기 레이블링된 문헌 학습 데이터를 NER 모델을 이용하여 학습하는 단계;를 포함하며,상기 전처리된 문헌 학습 데이터를 레이블링하는 단계에서, 레이블링하기 어려운 숫자와 단위로 구성된 불연속엔티티에 대해서만은, 레이블링 처리 중에 숫자와 단위 엔티티로 세분한 후, 단일 엔티티로 병합하는 인공지능기반 동물실험 문헌 정보 자동추출 방법."}
{"patent_id": "10-2023-0136532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,상기 문헌 학습 데이터를 수집하는 단계는,학습용 문헌 데이터의 어노테이션 대상을 선정하는 단계;상기 어노테이션 대상이 선정된 학습용 문헌 데이터를 PubMed 데이터 베이스로부터 수집하는 단계;상기 PubMed 데이터 베이스로부터 수집된 학습용 문헌 데이터를 데이터 필터링하는 단계;상기 데이터 필터링된 학습용 문헌 데이터로 학습용 문헌 데이터 어노테이션을 준비하는 단계;상기 준빅된 학습용 문헌 데이터의 어노테이션이 어노테이션 일치도를 충족하는 지가 판정되는 단계; 및 상기 학습용 문헌 데이터가 완성되는 단계를 포함하는 인공지능 기반 동물실험 문헌 정보 자동추출 방법."}
{"patent_id": "10-2023-0136532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 6에 있어서,상기 레이블링된 문헌 학습 데이터를 NER 모델을 이용하여 학습하는 단계는,레이블링된 데이터에서 후보 NER 정보 추출 모델을 벡터화하는 단계;상기 벡터화한 후보 NER 정보 추출 모델을 학습하는 단계;상기 학습된 후보 NER 정보 추출 모델이 성능 목표치를 충족하는 지가 판단되는 단계;상기 성능 목표치를 충족한 학습된 후보 NER 정보 추출 모델이 NER 정보 추출 모델로 확정돠는 단계;공개특허 10-2025-0053386-4-상기 확정된 NER 정보 추출 모델로 학습용 데이터 학습을 완료하는 단계;상기 확정된 NER 정보 추출 모델을 문헌정보 추출에 적용하는 단계; 및 상기 문헌 정보를 추출단계를 포함하는 인공지능 기반 동물실험 문헌 정보 자동추출 방법."}
{"patent_id": "10-2023-0136532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서,상기 레이블링(Labeling)된 문헌 학습 데이터의 핵심 정보는 상기 NER 모델의 학습 시에, 정답(ground truth)으로서 간주되는 인공지능 기반 동물실험 문헌 정보 자동추출 방법."}
{"patent_id": "10-2023-0136532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 8에 있어서,상기 핵심 정보는 샘플(Sample), 투여량(Dosage), 투여기간(Duration), 동물(Animal), 표적기관(Anatomy), 결과(Result)인 인공지능 기반 동물실험 문헌 정보 자동추출 방법."}
{"patent_id": "10-2023-0136532", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 구조화되지 않은 동물 실험 문헌 텍스트에서 NER를 활용하여 미리 정의된 유형 및 역할인 엔티티 타입 에 해당하는 텍스트를 식별하고 특정 엔티티 타입으로 분류하는 NER(Named Entity Recoognition) 모델에서 핵심 정보를 자동으로 추출하는 인공지능 기반 동물실험 문헌 정보 자동추출 시스템 및 그 방법에 관한 것으로, 학술 (뒷면에 계속)"}
{"patent_id": "10-2023-0136532", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반 동물실험 문헌 정보 자동추출 시스템 및 그 방법에 관한 것으로, 보다 상세하게는 구 조화되지 않은 동물 실험 문헌 텍스트로부터 자연어 처리 기술 중 하나인 Named Entity Recognition(NER)를 활 용하여 미리 정의된 유형 및 역할인 엔티티 타입에 해당하는 텍스트를 식별하고, 식별된 텍스트를 특정 엔티티 타입으로 분류함으로써, 동물실험 문헌의 핵심 정보를 자동으로 추출하되, 해당 텍스트가 불연속으로 기재되어 있더라도 학습 데이터 구축 및 인공지능 모델 학습을 적용할 수 있는 인공지능 기반 동물실험 문헌 정보 자동추 출 시스템 및 그 방법에 관한 것이다."}
{"patent_id": "10-2023-0136532", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 동물실험은 소재의 독성과 인체 내 안전성을 평가하고 효능을 규명하기 위한 목적으로 생명공학을 포함한 다양한 분야에서 수행되고 있다. 이러한 동물실험은 세포 실험에 비하여 상대적으로 발생하는 비용과 인 력의 소비가 크기 때문에, 수행에 앞서 확인하고자 하는 물질의 선행연구 탐색이 기본적으로 이루어지고 있다. 이처럼 선행연구 탐색은 학술적 연구가 산업적으로 전환되는데 있어 중요한 토대이나, 이러한 선행연구 탐색의 양이 기하급수적으로 증가하였기에, 구조화되지 않은 방대한 텍스트로부터 관련 핵심 실험적 사실을 찾는 데 어 려움이 있다. 최근 인공지능이 발달함에 따라, 장문의 텍스트로부터 핵심정보를 자동으로 추출해주는 자연어 처리 기술이 점 차 발전되고 있다. 장문의 텍스트로부터 핵심정보를 추출하기 위해서 인공지능을 기반으로 해당 기술을 67구현 하는데, 이를 위해서는 적절한 학습 데이터가 요구되나, 대부분의 기존 학습 데이터는 세포 실험에 중요하게 여 겨지고 있는 정보를 추출하기 위한 목적이거나 실험의 특정 단계를 상정하지 않고 만들어졌기에, 동물실험을 중 점적으로 다루고 있는 학습 데이터 구축 및 인공지능 모델 학습은 부재한 실정이다. 또한, 기존의 선행 연구 또는 선행 기술은 미리 정의된 유형 및 역할인 엔티티 타입에 해당하는 연속적인 텍스 트만을 취급하는 경우가 대부분이라, 특정 엔티티 타입인 불연속 엔티티를 식별하는 학습 데이터 구축 및 인공 지능 모델 학습도 소수의 연구가 존재하는 연구 초기 단계에 머물러 있다. 이와 같은 배경하에, 동물실험 문헌으로부터 인공지능을 활용하여 핵심정보를 자동으로 추출하는 기술이 대두되 고 있으며, 본 발명은 동물실험 문헌에서 주로 검토하는 핵심정보 체계를 마련하고, 마련된 해당 핵심정보 체계 가 반영된 학습 데이터를 구축하며, 구축된 학습 데이터로부터 핵심정보를 자동으로 추출하는 것을 구현하고자한다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 한국 등록특허 제10-2346136호 \"유전자와 화합물과 질병의 관련문헌 추출시스템\" (공고일자: 2022. 01. 03.)"}
{"patent_id": "10-2023-0136532", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서 본 발명의 목적은 상기와 같은 문제를 해결하기 위해 안출된 것으로, 동물실험 문헌에서 주로 검토하는 핵심정보 체계를 마련하고, 마련된 해당 핵심정보 체계가 반영된 학습 데이터를 구축하며, 구축된 학습 데이터 로부터 핵심정보를 자동으로 추출하기 위해 NER 모델을 이용하여 불연속 엔티티(Disc-Entity)를 포함하는 엔티 티들을 자동으로 추출하되, 하나의 불연속 엔티티 텍스트에 대하여 여러 개의 부분 텍스트들을 식별한 후 각각 의 부분 텍스트들을 통합하는 지의 여부를 예측함으로써 추출하는 인공지능 기반 동물실험 문헌 정보 자동추출 시스템 및 그 방법을 제공하고자 하는 것이다."}
{"patent_id": "10-2023-0136532", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 시스템은 학술정보 텍스트를 입력하는 입력부, 상 기 입력부를 통해 입력된 학술 정보 텍스트 내의 부분 텍스트를 식별하고 부분 텍스트 간의 관계를 식별하여 불 연속 엔티티를 포함하는 핵심 정보를 추출하는 NER 모델, 및 상기 NER 모델을 통해 추출된 핵심 정보를 출력하 는 출력부를 포함하는 인공지능 기반 동물실험 문헌 정보 자동추출 시스템으로서, 상기 NER 모델은, 동물실험 문헌 텍스트를 밀집벡터로 변환하는 임베딩부; Conditional Layer Normalization, BERT 방식의 표현부, 및 Dilated Convolution의 학습부; 및 Multilayer Perceptrons(MLP) predictor 층 및 Biaffine predictor 층의 예측부;를 포함하며, 상기 NER 모델을 지도학습 방식(Supervised Learning)으로 학습하기 위해 전처리된 데이터 에 핵심정보를 레이블링(Labeling)하되, 텍스트로된 학습 데이터로부터 특정 단위 명사를 서치하고, 상기 서치 된 특정 단위 명사와 더불어 상기 서치된 특정 단위 명사 직전의 숫자 텍스트를 상기 서치된 특정 단위 명사에 대응되는 핵심정보로 레이블링하며, 상기 레이블링된 문헌 학습 데이터의 핵심 정보는 상기 NER 모델의 학습 시 에, 정답(ground truth)으로서 간주되는 것을 특징으로 한다. 또한, 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 방법은 학술정보 텍스트를 입력하는 입력부, 상기 입력된 텍스트 내의 핵심 정보를 추출하는 NER 모델, 및 상기 NER 모델을 통해 추출된 핵심 정보를 출력하 는 출력부를 포함하는 인공지능 기반 동물실험 문헌 정보 자동추출 시스템에 의한 인공지능 기반 동물실험 문헌 정보 자동추출 방법으로서, 수집된 문헌에서 문헌 학습 데이터를 수집하는 단계; 상기 수집된 문헌 학습 데이터 를 전처리하는 단계; 상기 전처리된 문헌 학습 데이터를 레이블링하는 단계; 및 상기 레이블링된 문헌 학습 데 이터를 NER 모델을 이용하여 학습하는 단계;를 포함하며, 상기 전처리된 문헌 학습 데이터를 레이블링하는 단계 에서, 레이블링 하기 어려운 숫자와 단위로 구성된 불연속 엔티티에 대해서만은, 레이블링 처리 중에 숫자 및 단위 엔티티로 세분한 후, 단일 엔티티로 병합하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0136532", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이, 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 시스템 및 그 방법은 방대한 양 의 동물실험 문헌 내용으로부터 핵심정보를 추출하여 제공함으로써, 동물실험을 효과적으로 설계하는 데 시간과 비용을 줄일 뿐만 아니라 불필요한 동물실험을 방지할 수 있다는 이점이 있다."}
{"patent_id": "10-2023-0136532", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "또한, 특정 연구 분야의 여러 문헌으로부터 필요한 정보만을 추출하여 요약, 정리함으로써, 연구 동향을 빠르게 파악하고 선행연구 문헌에 대한 세부 탐색 방향을 수립하는 데 기여할 수 있다는 이점이 있다."}
{"patent_id": "10-2023-0136532", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조한 실시 예들의 상세한 설명을 통하여 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자 동추출 시스템 및 그 방법을 보다 상세히 기술하기로 한다. 본 발명을 설명함에 있어서 관련된 공지기술 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명 은 생략될 것이다. 그리고, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 클라이 언트나 운용자, 사용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 도면 전체에 걸쳐 같은 참조번호는 같은 구성 요소를 가리킨다. 도 1은 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 시스템의 구성 블록도이며, 도 2는 본 발명 에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 방법의 흐름도이며, 도 3은 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 방법 중 학습용 문헌 데이터 구축 프로세스의 흐름도이며, 도 4는 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 방법 중 문헌 정보 추출 프로세스의 흐름도이다. 이제 도 1을 참조하여 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 시스템을 살펴보고자 한다. 도 1에 도시된 바와 같이, 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 시스템은 학술정보 텍스 트를 입력하는 입력부, 입력부를 통해 입력된 학술정보 텍스트 내의 핵심 정보를 추출하는 NER 모델 , NER 모델을 통해 추출된 핵심 정보를 출력하는 출력부를 포함한다. 여기서, 입력부에 입력되는 동물실험 문헌의 학술정보 텍스트는 길이가 N인 하나의 시퀀스(X = { , , })로서 주어지는데, 학술정보의 제목, 초록 또는 본문의 일부가 될 수 있으며, 제목과 초록 등이 동시에 입력으로 주어질 수도 있다. 또한, 동물실험 문헌의 학술정보 텍스트 내 핵심정보는 중첩되거나 산재된 형태로 기재되어 있을 수 있으며, NER 모델은 해당 형태의 핵심정보 또한 추출할 수 있는 모델로서 구현될 수 있다. 또한, 출력부를 통해 핵심정보의 종류와 핵심정보에 해당하는 일부 문헌 텍스트가 함께 출력된다. 예를 들 어, 핵심정보 내의 '5mg'라는 텍스트를 추출함과 동시에, 해당 텍스트가 Dosage(투여량)임을 함께 출력한다. 또한, 출력부를 통해 출력된 텍스트는 입력 텍스트의 연속적인 부분 텍스트( , 일 수도 있고, 불연속 부분 텍스트( , 일 수도 있다."}
{"patent_id": "10-2023-0136532", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "또한, 출력부를 통해 추출된 핵심정보는 핵심정보 산출물 그 자체이거나, 핵심정보가 요약, 정리된 표 등 다양한 형태를 포함할 수 있다. 한편, 도 1을 참조하면, 딥러닝을 이용하는 NER 모델은 동물실험 문헌 텍스트를 밀집 벡터로 변환하는 임 베딩부, Conditional Layer Normalization, BERT 방식의 표현부, 및 Dilated Convolution의 학습부, 및 MLP predictor 층 및 Biaffine predictor 층으로 예시되는 예측부를 포함한다. 여기서, 임베딩부는 자연어 형태의 단어를 컴퓨터가 이해할 수 있는 밀집 벡터 형태로 만든다. 구체적으로 는 토큰 구분(Tokenization) 전처리를 수행하여 문헌 텍스트 시퀀스를 토큰(Token)으로 구분하고, 각 토큰에 대 해 랜덤 초기화(Random Initialization)된 밀집 벡터를 생성한다. 따라서, 입력 텍스트인 X가 토큰 기준으로 길 이가 M인 시퀀스인 X = { , , }로 처리된다. 만약 시퀀스의 길이가 모델의 최대 입력 길이를 초과할 경우, 해당 시퀀스는 분절되어 부분 시퀀스들의 집합이 생성되며 순차적으로 처리된다. 다만 부분 시퀀스들의 집합이 하나의 긴 시퀀스임을 파악할 수 있도록 전체 시 퀀스의 끝에 도달하지 않는 부분 시퀀스의 끝에 특수 토큰으로 명시한다. 예를 들어, {I, ate, some, rice, and, played, the, video, games}란 시퀀스를 {I, ate, some, rice, and, <continue>}, {played, the, video, games}의 2개의 부분 시퀀스들의 집합으로 표현될 수 있으며, 이때, <continue>로 해당 시퀀스가 끝나지 않았음 을 나타낸다. 또한, BioBERT 등의 사전 학습 모델을 이용하게 되면, 랜덤 초기화된 밀집 벡터를 생성하는 대신 사전 훈련되어 해당 토큰에 대한 표현력을 갖춘 임의의 밀집 벡터를 사용한다. 또한, 추가적으로 생성된 밀집 벡터에 대하여 전방향(forward) 진행을 통해 좌측 문맥을 추출하고 역방향 (backward) 진행을 통해 우측 문맥을 추출한 후, 추출된 좌측 문맥과 우측 문맥을 결합하여 밀집 벡터를 생성할 수 있다. 상기 임베딩부를 거쳐 밀집 벡터는 길이 M인 시퀀스에 대응되어 H = { , , } 로 도출 된다. 또한, 사전에 구축한 학습 데이터를 바탕으로 임베딩부를 통해 밀집 벡터로 만들어진 다음에 학습부 와 예측부를 거쳐 학습함으로써, NER 모델을 제공할 수 있다. NER 모델은 본 발명에 따른 동물실험 문헌 텍스트 내 핵심정보 자동추출 인공지능 학습 모델이다. 한편, 학습부는 Conditional Layer Normalization 층, BERT 방식의 표현부, 및 Dilated Convolution 층의 조합으로 이루어진다. 또한, 예측부는 서로 상이하게 각각 입력된 MLP predictor 층 및 Biaffine predictor 층의 출력을 합쳐서 최종 예측에 활용한다. 또 한편, 학습부와 예측부의 목적은 여러 개의 부분 텍스트들을 식별한 후 각각의 부분 텍스트들을 통합하는 지의 여부를 예측함으로써 불연속 엔티티 포함 엔티티들을 식별하고, 식별된 엔티티들이 올바른 엔티 티 타입 클래스로 분류되도록 학습하는 것이다. 이때, 부분 텍스트의 단위는 하기와 같이, 1개의 단어이거나 1 개 이상의 어구일 수 있다. [부분 텍스트 단위가 1개 이상의 어구일 경우] NER 모델은 모델이 다루고자 하는 부분 텍스트의 단위에 따라 모델 구조 및 구체적인 학습 방식이 달라질 수 있다. 부분 텍스트의 단위가 1개의 단어일 경우 W2NER, 1개 이상의 어구일 경우 SpanNER로 표 2에서 후술된 다. 상기 부분 텍스트 학습부(220-1)는 부분 텍스트 단위가 1개 이상의 어구일 경우, 길이 M인 시퀀스 내에서 생성 가능한 모든 어구들을 엔티티 후보군으로서 생성한다. 어구는 어구의 시작 인덱스의 밀집벡터와 어구의 끝 인덱 스의 밀집벡터를 합침으로써 표현된다. 예를 들어, 어구 ( , 는 벡터 [ ; 로 표현 가능하다. 상기 부분 텍스트 예측부(230-1)는 상기 부분 텍스트 학습부(220-1)에서 생성된 모든 어구 후보군에 대하여 MLP predictor 층과 소프트맥스(softmax) 활성화 함수(activation function)를 통해 어구가 속하는 특정 엔티티 타 입 클래스를 예측한다. 상기 관계 학습부(220-2)는 상기 부분 텍스트 예측부(230-1)을 통해 특정 엔티티 타입 클래스로 분류된 어구 집 합을 대상으로 하며, 두 개의 어구 간 관계 유무를 예측하기 위해 두 개의 어구 벡터와 두 개의 어구 벡터를 곱 한 벡터를 합침으로써 표현된다. 상기 관계 예측부(230-2)는 상기 관계 학습부에서 생성된 벡터에 대하여 MLP predictor 층과 소프트맥스 활성화 함수를 통해 두 개의 어구 벡터 간의 관계성을 예측한다. [부분 텍스트 단위가 1개의 단어일 경우] 상기 관계 학습부(230-1)는 부분 텍스트 단위가 1개의 단어일 경우, 열과 행이 모두 밀집 벡터의 길이 M와 동일 한 길이의 2차원 단어-단어 행렬을 공통적으로 이용하며, 하나의 학습부로서 존재한다. 상기 학습부 는 Conditional Layer Normalization 층, BERT 방식의 표현부, Dilated Convolution 층이 존재할 수 있다. BERT 방식의 표현부는 각 토큰을 표현하는 토큰 임베딩(Token Embedding), 각 토큰의 위치를 나타내는 위치 임 베딩(Positional Embedding), 상삼각행렬과 하삼각행렬의 경계를 나타내는 분할 임베딩(Segment Embedding)이 합쳐진다. Dilated Convolution 층은 가깝거나 먼 단어들 간의 문맥을 표현하기 위해 확장비율(dilated rate)을 1,2,3으 로 하여 생성된 3개의 벡터를 합치고 GeLU(Gaussian Error Linear Unit) 활성화 함수(activation function)을 통과함으로써 완성된다. 상기 관계 예측부(230-1)는 2차원 단어-단어 행렬의 일부인 하삼각행렬에 대하여 Biaffine predictor 층과 MLP predictor 층을 각각 통과한 후 각 층을 통과한 벡터를 합치고 해당 벡터가 소프트맥스 활성화 함수를 통과함으 로써, 부분 텍스트의 끝 인덱스에 해당하는 토큰과 부분 텍스트가 속하는 특정 엔티티 타입 클래스를 예측한다. 이때, Biaffine predictor 층의 입력은 상기 임베딩부를 통과한 밀집 벡터이며, MLP predictor 층의 입력 은 상기 학습부을 통과한 2차원 단어-단어 행렬이다. 상기 관계 예측부(230-2)는 2차원 단어-단어 행렬의 일부인 상삼각행렬에 대하여 Biaffine predictor 층과 MLP predictor 층을 각각 통과한 후 각 층을 통과한 벡터를 합치고 해당 벡터가 소프트맥스 활성화 함수를 통과함으 로써, 각 단어 간의 관계성을 예측한다. 부분 텍스트 단위가 1개의 단어일 경우, 부분 텍스트 예측부(230-1)와 관계 예측부(230-2)가 순차적으로 이루어 지는 1개 이상의 어구일 경우와 달리, 부분 텍스트 예측부(230-1)와 관계 예측부(230-2)가 동시에 진행된다 또한, NER 모델은 손실함수를 최소화하는 하기 식에 의해 모델 파라미터를 결정하는 것으로 학습된다. 손 실함수로는 주로 교차 엔트로피(cross entropy) 함수가 사용되나, 이에 한정하지 않으며 별도의 손실함수가 추 가, 대체될 수 있다."}
{"patent_id": "10-2023-0136532", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, n은 데이터 개수이고, C는 클래스 개수로 추출하고자 하는 핵심정보 종류 개수이며, 는 실제 값이고 는 실제 값에 대한 예측 확률값이다. 또한, NER 모델은 불연속 엔티티를 포함하는 엔티티들을 자동으로 추출한다. 여기서 NER 모델은 각 질병, 실험 대상 물질 등에 대해 생물 의학적으로 의미 있는 엔티티를 감지하고 표시하는 데 사용된다. 또한, 학습부는 부분 텍스트 학습부(220-1)와 부분 텍스트 간 관계 학습부(220-2)로 분할된다. 또한, 예측부는 부분 텍스트 예측부(230-1)와 부분 텍스트 간 관계 예측부(230-2)로 분할된다. 이하 표 1을 참조하여, 본 발명에 따른 동물실험 문헌 텍스트 내 핵심정보 체계를 살펴보고자 한다. 표 1에 도시된 바와 같이, 본 발명에 따른 동물실험 문헌 텍스트 내 핵심정보 체계에서 핵심정보의 종류는 크게 9가지 종류로, Sample(샘플), Dosage(투여량), Duration(투여 기간), Animal(동물), Anatomy(표적기관), Result(결과, 주로 문헌의 결과에 해당하는 핵심정보), Sample Administration(샘플 투여), Positive Regulation(긍정 조정), 및 Negative Regulation(부정 조정)이 있다. 그러나 핵심정보는 표 1을 통해 예시될 뿐, 이에 국한되는 것은 아니다. 여기서, Sample(샘플)은 동물실험의 주요 실험 대상 물질이다. 화학물 뿐만 아니라 추출물 등과 같은 화합물 등 도 포함한다. 또한, Dosage(투여량), Duration(투여 기간), Dosage Frequency(투여주기)는 숫자 및 단위를 포함하고 있다. 따라서 숫자와 단위를 함께 추출, 출력하게 된다. 여기서, 투여 기간은 전체 실험 기간, 질병 유도를 위한 유도 제 처리 기간은 해당되지 않는다. 또한, Animal(동물)의 경우, Species(동물종), Strain(동물세부종), Sex(동물성별)은 주요 피실험 대상 동물종, 주요 피실험 대상 동물 세부종, 주요 피실험 대상 동물 성별이다. 또한, Anatomy(표적기관)은 Cell(세포), Tissue(조직), Organ(장기), Organ function(장기 내 기능) 등 신체 내의 기관, 부산물, 기능을 모두 포함한다. 또한, Result(주로 문헌의 결과에 해당하는 핵심정보)는 Disease Name(질환명), Molecular Biomarker(분자 표 지자), Response(생체지표 변화로부터 유발된 생리적 변화)가 있다. 또한, Sample Administration(샘플 투여)는 주사, 경구 투여, 총 적용 등 특정 Sample을 피실험체에게 투여하는 것이다. 또한, Positive Regulation(긍정 조정)은 특정 표적의 활성, 발현 또는 반응을 증가시키는 동물의 생물학적 과 정 또는 시스템의 자극이다. 또한, Negative Regulation(부정 조정)은 동물의 생물학적 과정 또는 시스템을 억압하거나 억제하여 특정 표적 의 활성, 발현 또는 반응을 감소시키는 것이다. 표 1 Entity Category Entity Type Definition Sample Sample Name 실험 대상 물질 Sample Type Dosage Dosage 샘플 투여용량 Dosage Frequency 샘플 투여주기 Duration Duration 샘플 투여 기간 AnimalSpecies 동물종 Strain 동물세부종 Sex 동물성별 Anatomy Anatomy 표적기관 ResultDisease Name 질환명 Molecular Biomarker 분자 표지자 Response 생체지표 변화로부터 유발된 생리적 변화 Sample AdministrationSample Administration주사, 경구 투여, 총 적용 등 특정 샘플을 피실험자에게 투여 Positive RegulationPositive Regulation특정 표적의 활성, 발현 또는 반응을 증가시키는 동물의 생물학적 과정 또는 시스템의 자극 NegativeRegulationNegative Regulation동물의 생물학적 과정 또는 시스템을 억압하거나 억제하여 특정 표적의 활성, 발현 또는 반응의 감소 이하 표 2를 참조하여, 2가지 베이스라인(SpanNER 및 W2NER)에 대한 NER 성능을 정밀도(P), 재현율(R), 및 미세 평균(F1) 스코어로 살펴보고자 한다. 여기서, 모든 스코어는 백분율(%)이다. 표 2는 NER 베이스라인의 정밀도(P), 재현율(R), 및 미세 평균(F1) 스코어를 보여주는데, W2NER는 F1 스코어를 기준으로 SpanNER를 약간 능가한다. 표 2 Baselines P R F1 SpanNER 66.84 71.88 69.27 W2NER 72.24 69.64 70.92 이하, 표 3을 참조하여, 각 엔티티 유형에 대한 W2NER의 정밀도, 재현율 및 F1 스코어를 살펴보고자 한다. 여기 서, 모든 스코어는 백분율(%)이다. 표 3은 각 엔티티 유형에 대한 W2NER의 정밀도, 재현율 및 F1 스코어를 보여 주는데, 롱테일(long-tail) 빈도 분포와 각 엔티티 유형 내의 고유한 표현 수가 성능에 영향을 미치는 것으로 보인다. 표 3 W2NER P R F1 Sample Name 80.67 79.11 79.88 Sample Type 66.67 50.00 57.14 Dosage 77.27 77.27 77.27 Duration 57.14 70.59 63.16 Dosage Frequency 66.00 25.00 35.29 Animal Species 89.39 93.57 91.43 Animal Strain 61.70 90.62 73.41 Animal Sex 1.0 69.23 81.82 Anatomy 71.52 74.27 72.87 Molecular Biomarker 77.06 69.56 73.12 Response 58.99 61.02 59.99 Disease Name 76.35 78.06 77.20 Sample Administration 60.53 56.56 58.48 Positive Regulation 71.06 60.28 65.23 Negative Regulation 82.64 67.34 74.21 이제, 도 2을 참조하여 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 방법을 살펴보고자 한다. 도 2에 도시된 바와 같이, 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 방법은 S210 단계에서 동물실험 문헌 학습 데이터를 수집한다. 여기서 문헌 학습 데이터는 검색 엔진을 사용하며, 검색 엔진에 데이터 크롤링 기법을 적용하고 특정 키워드를 입력하여 문서를 수집하고 처리함으로써 수집된다. 여기서, 데이터 크롤 링 기법은 공개된 웹페이지의 정보를 그대로 가져와서 데이터를 수집해 내는 기술이다. 또한, S210 단계에서 미가공 말뭉치(raw corpus)는 방대한 생의학 문헌 컬렉션을 포함하는 널리 사용되는 온라 인 데이터베이스인 PubMed 등 학술 문헌 데이터베이스 검색 웹페이지에서 수집된다. 또한, S210 단계에서 사용되는 특정 키워드는 동물실험 문헌만을 수집하기 위한 키워드로 구성되며, 다양한 실 험 물질에 관한 문헌 집합을 수집하기 위해 MesH term 등과 같은 바이오메디컬 분야의 용어 체계를 이용할 수 있다. 또한, S210 단계에서 수집하고자 하는 문헌은 최근 5년 이내 게재 여부, 웹페이지에 초록 공개 여부 등의 필터 를 적용하여 문헌의 수집 범위를 보다 명확화 할 수 있다. 한편, S210 단계에서, PubMed 데이터 베이스의 계층적 검색 인덱스 역할을 하는 의학 주제 표제(MesH)는 검색어 를 결정하는 데 사용되는데, 먼저 동물 실험을 수행한 문헌을 검색하기 위해 검색어에 ([MesHTerms] AnimalDiseaseModel OR [MesHTerms] Animals)를 포함하며, 그 후 광범위한 주제에 대한 문헌 컬렉션을 얻기 위 해 검색어를 ([MesHSubheading] Physiopathology OR [MesHSubheading] Chemistry)로 설정하여 생리병리학 또는 화학에 해당하는 문헌을 넓은 범주로 포함하고 리뷰 문헌은 제외한다. 따라서 최종 검색어는 ([MesHTerms] AnimalDiseaseModel OR [MesHTerms] Animals) AND ([MesHSubheading] Physiopathology OR MesHSubheading] Chemistry) AND (Not Review)로 구성되며, 상위 검색 결과에서 문헌의 제목과 초록을 수집한 후, 동물 실험과 직접적인 관련이 없는 문헌을 제거하여 관련 문헌을 획득한다. 또한, S210 단계에서, 학습용 문헌 데이터가 구축되는데, 학습용 문헌 데이터 구축을 위한 프로세스는 도 3과 관련하여 후술된다. S220 단계에서 수집된 데이터가 데이터 전처리되어 수집된 데이터 중 수집 목적에 부합하지 않는 데이터가 포함 되어 있을 경우 이를 제외한다. 예를 들어, 문헌의 주된 내용이 동물실험과 무관한 경우 해당 문헌을 삭제한다. S230 단계에서 동물실험 문헌 텍스트 내 핵심정보를 인식하는 NER 모델을 지도학습 방식(Supervised Learning) 으로 학습하기 위해 전처리된 문헌 학습 데이터에 핵심정보를 레이블링(Labeling)한다. 여기서, 지도학습 방식은 학습 데이터에 대한 레이블(Label)이 주어진 상태에서 NER 모델을 학습시키는 방법을 의미하며, 레이블은 학 습 데이터가 NER 모델에 입력되는 경우 NER 모델이 추론해내야 하는 정답(Ground Truth)을 의미할 수 있다. 또한, S230 단계에서 레이블링은 NER 모델의 학습을 위하여 학습 데이터에 레이블을 설정하는 것을 의미한다. S230 단계에서 레이블링된 핵심정보는 NER 모델의 학습 시에 정답으로서 간주된다. 또한, S230 단계에서 레이블링은 레이블러 간에 레이블링 일관성을 유지하기 위해 레이블링 프로세스는 파일럿 레이블링과 전문가 레이블리의 2 단계로 구성된다. 여기서, 파일럿 레이블링은 실제 레이블링 프로세스를 수행 하기 전에 다양한 수준의 도메인 지식으로 인해 레이블러를 교육하기 위해 수행된다. 예를 들어, 공개적으로 이 용 가능한 생물의학 이벤트 추출 데이터 세트인 MLEE 코퍼스에서 동물 실험 단계와 관련이 있는 경우 추출한 10 개의 문헌에 대해 새로 정의한 체계를 적용하기 위해 수행된다. 그러므로, 레이블링은 전문가의 수작업에만 의존하는 것이 아닌 NER 기반으로 반자동 레이블링을 수행한다. Animal Strain(동물세부종)은 Adult Mouse Anatomy Ontology, Disease(질환명)은 Disease Ontology, Anatomy (표적기관)은 Common Anatomy Reference Ontology에 있는 전문 용어들이 자동으로 레이블링 된다. 또한, Dosage(투여량), Duration(투여 기간), Dosage Frequency(투여 주기)의 경우, 각 핵심정보의 고유 단위 명사 리스트가 존재하므로, 단위 명사를 통해 핵심정보를 자동으로 레이블링할 수 있다. 예를 들어, Dosage는 주로 mg/kg, mg/ml, μg/kg 등이 있으며, Duration은 days, weeks 등이 있다. 따라서, 먼저, 텍스트로된 학습 데이 터로부터 특정 단위 명사를 찾고, 해당 특정 단위 명사와 더불어 해당 특정 단위 명사 직전의 숫자 텍스트를 해 당 특정 단위 명사에 대응되는 핵심정보로 레이블링한다. 이러한 레이블링 방법은, 연속적인 텍스트 범위에 중점을 두어서 동물 실험 문헌의 복잡한 의미론적 특성으로 인해 특정 엔티티에 레이블하기가 어려운 불연속 엔티티로 인한 레이블러의 오류를 최소화하기 위해, 숫자와 단 위를 매핑하기 위한 특수 관계 유형에 대해서만은 불연속 엔티티는 레이블링 처리 중에 숫자(예: \"8\") 및 단위 (예: \"mg/kg\") 엔티티로 세분한 후, 단일 엔티티로 병합한다(예: \"8 mg/kg\"). 이는 숫자는 여러 개나 단위는 하 나이기 때문에 숫자에 대응하는 단위를 매핑하기 위해 단위 엔티티를 별도로 생성해야 하기 때문이다. 이에 반 해, Dosage의 경우 일일 투여량 단위를 설명할 수 있으므로 일시적으로 단위 엔티티를 Dosage Unit(예: \"mg/kg\") 및 Dosage Day Unit(예: \"/day\")의 두 단위 하위 엔티티로 분할하고 나중에 하나로 결합한다(예: \"8mg/kg/day\"). S240 단계에서는 레이블된 데이터로 NER 모델을 학습한다. 이러한 NER 모델의 개략적인 구조는 도 1의 NER 모델 로 구체화된다. 또한, S240 단계에서, 레이블된 데이터로 NER 모델을 학습하여 문헌 정보가 추출되는데, 문헌 정보 추출을 위한 프로세스는 도 4와 관련하여 후술된다. 이제, 도 3을 참조하여 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 방법 중 학습용 문헌 데이 터 구축 프로세스를 살펴보고자 한다. 도 3에 도시된 바와 같이, 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 방법 중 학습용 문헌 데 이터 구축 프로세스는 S311 단계에서 학습용 문헌 데이터의 어노테이션 대상을 선정한다 S312 단계에서 어노테이션 대상이 선정된 학습용 문헌 데이터를 PubMed 데이터 베이스로부터 수집한다. S313 단계에서 PubMed 데이터 베이스로부터 수집된 학습용 문헌 데이터를 데이터 필터링한다. S314 단계에서 데이터 필터링된 학습용 문헌 데이터로 학습용 문헌 데이터 어노테이션을 준비한다. S315 단계에서 학습용 문헌 데이터의 어노테이션이 어노테이션 일치도를 충족하는 지가 판정된다. 여기서, 학습 용 문헌 데이터의 어노테이션이 어노테이션 일치도를 충족하지 못하면 S314 단계로 리턴되고, 학습용 문헌 데이 터의 어노테이션이 어노테이션 일치도를 충족하면 S316 단계로 진행한다. S316 단계에서 학습용 문헌 데이터가 완성된다. 이제, 도 4를 참조하여 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 방법 중 문헌 정보 추출 프 로세스를 살펴보고자 한다. 도 4에 도시된 바와 같이, 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 방법 중 문헌 정보 추출 프로세스는 S341 단계에서 레이블된 데이터에서 후보 NER 정보 추출 모델을 벡터화한다.S342 단계에서 벡터화한 후보 NER 정보 추출 모델을 학습한다. S343 단계에서 학습된 후보 NER 정보 추출 모델이 성능 목표치를 충족하는 지가 판단된다. 여기서, 학습된 후보 NER 정보 추출 모델이 성능 목표치를 충족하지 못하면 S342 단계로 리턴되며, 학습된 후보 NER 정보 추출 모델 이 성능 목표치를 충족하면 S344 단계로 진행한다. S344 단계에서 성능 목표치를 충족한 학습된 후보 NER 정보 추출 모델이 NER 정보 추출 모델로 확정된다. S345 단계에서 확정된 NER 정보 추출 모델로 학습용 데이터 학습을 완료한다. S346 단계에서 확정된 NER 정보 추출 모델을 문헌정보 추출에 적용한다. S347 단계에서 문헌 정보를 추출한다. 여기서, 제목 및 초록 데이터로부터 문헌 정보를 추출하고, 제목, 메타데 이터, 초록, 추출된 문헌 정보 데이터를 액셀 파일 형태로 저장한다. 전술한 바와 같은 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 시스템 및 그 방법은 방대한 양 의 동물실험 문헌 내용으로부터 핵심정보를 추출하여 제공함으로써, 동물실험을 효과적으로 설계하는 데 시간과 비용을 줄일 뿐만 아니라 불필요한 동물실험을 방지할 수 있다. 또한, 특정 연구 분야의 여러 문헌으로부터 필"}
{"patent_id": "10-2023-0136532", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "요한 정보만을 추출하여 요약, 정리함으로써, 연구 동향을 빠르게 파악하고 선행연구 문헌에 대한 세부 탐색 방 향을 수립하는 데 기여할 수 있다. 이상과 같이 본 발명은 양호한 실시 예에 근거하여 설명하였지만, 이러한 실시 예는 본 발명을 제한하려는 것이"}
{"patent_id": "10-2023-0136532", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "아니라 예시하려는 것이므로, 본 발명이 속하는 기술분야의 숙련자라면 본 발명의 기술사상을 벗어남이 없이 위 실시 예에 대한 다양한 변화나 변경 또는 조절이 가능할 것이다. 그러므로, 본 발명의 보호 범위는 본 발명의 기술적 사상의 요지에 속하는 변화 예나 변경 예 또는 조절 예를 모두 포함하는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0136532", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 시스템의 구성 블록도이다. 도 2는 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 방법의 흐름도이다. 도 3은 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 방법 중 학습용 문헌 데이터 구축 프로세스 의 흐름도이다. 도 4는 본 발명에 따른 인공지능 기반 동물실험 문헌 정보 자동추출 방법 중 문헌 정보 추출 프로세스의 흐름도 이다."}
