{"patent_id": "10-2022-0073183", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0103890", "출원번호": "10-2022-0073183", "발명의 명칭": "멀티-모달 비디오 캡셔닝 기반 영상 보안 시스템 및 방법", "출원인": "주식회사 파일러", "발명자": "김세은"}}
{"patent_id": "10-2022-0073183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "비디오 캡션부에 의해, 비디오 데이터를 구성하는 시계열 순의 영상 프레임들을 포함하는 비젼 데이터로부터 상기 비젼 데이터의 시계열 구간별로 상기 비젼 데이터 내 객체의 행동과 관련된 비디오 캡션을 생성하는 단계;및행동 분석부에 의해, 상기 비디오 캡션이 기 설정된 위험 행동과 관련되는지 판단하고, 상기 객체의 행동이 상기 위험 행동과 관련되는 경우, 위험 상황을 알리는 알람을 발생하는 단계;를 포함하는, 영상 보안 방법."}
{"patent_id": "10-2022-0073183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 비디오 캡션을 생성하는 단계는:상기 비디오 데이터를 상기 비젼 데이터와 오디오 데이터로 분할하는 단계; 및인공지능 모델에 의해 상기 시계열 구간별로 상기 비젼 데이터 및 상기 오디오 데이터를 기초로 비젼 모드와 오디오 모드의 멀티-모달 분석을 통해 상기 객체의 행동과 관련된 상기 비디오 캡션을 생성하는 단계;를포함하는, 영상 보안 방법."}
{"patent_id": "10-2022-0073183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 비디오 캡션을 생성하는 단계는:(a) 인코더부에 의해, 상기 비젼 데이터와 상기 오디오 데이터를 기초로 멀티-모달 분석을 통해 비젼 인코더 벡터와, 오디오 인코더 벡터를 생성하는 단계;(b) 디코더부에 의해, 학습된 자막 키 값들을 기초로 상기 비디오 데이터와 관련된 자막 데이터를 셀프 어텐션처리하여 자막 어텐션 벡터를 생성하는 단계; 및(c) 상기 디코더부에 의해, 상기 자막 어텐션 벡터와 상기 비젼 인코더 벡터 및 상기 오디오 인코더 벡터를 멀티-모달 어텐션 처리하여 상기 비디오 캡션을 생성하는 단계;를 포함하는, 영상 보안 방법."}
{"patent_id": "10-2022-0073183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 (a) 단계는:상기 비젼 데이터를 셀프 어텐션 처리하여 비젼 어텐션 벡터를 생성하는 단계;학습된 비젼 키 값들을 기초로 상기 비젼 데이터를 셀프 어텐션 처리하여 비젼 어텐션 벡터를 생성하는 단계;학습된 오디오 키 값들을 기초로 상기 오디오 데이터를 셀프 어텐션 처리하여 오디오 어텐션 벡터를 생성하는단계;상기 비젼 어텐션 벡터 및 상기 오디오 어텐션 벡터를 제1 멀티-모달 어텐션부에 입력하여 상기 비젼 인코더 벡터를 생성하는 단계; 및상기 비젼 어텐션 벡터 및 상기 오디오 어텐션 벡터를 제2 멀티-모달 어텐션부에 입력하여 상기 오디오 인코더벡터를 생성하는 단계;를 포함하는, 영상 보안 방법."}
{"patent_id": "10-2022-0073183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,공개특허 10-2023-0103890-3-상기 알람을 발생하는 단계는 상기 위험 행동의 발생 시점 및 상기 객체의 위험 행동 정보를 관제시스템에 알리는 단계를 포함하는, 영상 보안 방법."}
{"patent_id": "10-2022-0073183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서,상기 비디오 캡션을 생성하는 단계는 상기 비젼 데이터를 기초로 행동 정지점을 설정하여 상기 시계열 구간을결정하는 단계를 더 포함하는, 영상 보안 방법."}
{"patent_id": "10-2022-0073183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1 내지 청구항 6 중 어느 한 항의 영상 보안 방법을 실행시키도록 컴퓨터로 판독 가능한 기록 매체에 기록된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0073183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "비디오 데이터를 구성하는 시계열 순의 영상 프레임들을 포함하는 비젼 데이터로부터 상기 비젼 데이터의 시계열 구간별로 상기 비젼 데이터 내 객체의 행동과 관련된 비디오 캡션을 생성하는 비디오 캡션부; 및상기 비디오 캡션이 기 설정된 위험 행동과 관련되는지 판단하고, 상기 객체의 행동이 상기 위험 행동과 관련되는 경우, 위험 상황을 알리는 알람을 발생하는 행동 분석부;를 포함하는, 영상 보안 시스템."}
{"patent_id": "10-2022-0073183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서,상기 비디오 캡션부는:상기 비디오 데이터를 상기 비젼 데이터와 오디오 데이터로 분할하고;상기 비젼 데이터를 기초로 행동 정지점을 설정하여 상기 시계열 구간을 분할하고; 그리고인공지능 모델에 의해 상기 시계열 구간별로 상기 비젼 데이터 및 상기 오디오 데이터를 기초로 비젼 모드와 오디오 모드의 멀티-모달 분석을 통해 상기 객체의 행동과 관련된 상기 비디오 캡션을 생성하도록 구성되는, 영상보안 시스템."}
{"patent_id": "10-2022-0073183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서,상기 비디오 캡션부는:상기 비젼 데이터와 상기 오디오 데이터를 기초로 멀티-모달 분석을 통해 비젼 인코더 벡터와, 오디오 인코더벡터를 생성하는 인코더부; 및학습된 자막 키 값들을 기초로 상기 비디오 데이터와 관련된 자막 데이터를 셀프 어텐션 처리하여 자막 어텐션벡터를 생성하고, 상기 자막 어텐션 벡터와 상기 비젼 인코더 벡터 및 상기 오디오 인코더 벡터를 멀티-모달 어텐션 처리하여 상기 비디오 캡션을 생성하는 디코더부;를 포함하는, 영상 보안 시스템."}
{"patent_id": "10-2022-0073183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 10에 있어서,상기 인코더부는:학습된 비젼 키 값들을 기초로 상기 비젼 데이터를 셀프 어텐션 처리하여 비젼 어텐션 벡터를 생성하는 비젼 셀프 어텐션부;학습된 오디오 키 값들을 기초로 상기 오디오 데이터를 셀프 어텐션 처리하여 오디오 어텐션 벡터를 생성하는오디오 셀프 어텐션부;상기 비젼 어텐션 벡터 및 상기 오디오 어텐션 벡터를 기초로 멀티-모달 분석을 수행하여 제1 특징 벡터를 생성공개특허 10-2023-0103890-4-하는 제1 멀티-모달 어텐션부;상기 비젼 어텐션 벡터 및 상기 오디오 어텐션 벡터를 기초로 멀티-모달 분석을 수행하여 제2 특징 벡터를 생성하는 제2 멀티-모달 어텐션부;상기 제1 멀티-모달 어텐션부에 의해 생성되는 상기 제1 특징 벡터로부터 비젼 인코더 벡터를 생성하는 제1 완전 연결층; 및상기 제2 멀티-모달 어텐션부에 의해 생성되는 상기 제2 특징 벡터로부터 상기 오디오 인코더 벡터를 생성하는제2 완전 연결층;을 포함하는, 영상 보안 시스템."}
{"patent_id": "10-2022-0073183", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "멀티-모달 비디오 캡셔닝(Multi-Modal Video Captioning) 기반의 비디오 내 광범위한 맥락 분석을 통해 비디오 내 비젼, 오디오 정보를 바탕으로 객체의 행동을 검출하여 자동으로 영상 상황 인지 정보를 제공하는 영상 보안 시스템 및 방법이 개시된다. 본 발명의 실시예에 따른 영상 보안 방법은 비디오 캡션부에 의해, 비디오 데이터를 구성하는 시계열 순의 영상 프레임들을 포함하는 비젼 데이터로부터 상기 비젼 데이터의 시계열 구간별로 상기 비젼 데이터 내 객체의 행동과 관련된 비디오 캡션을 생성하는 단계; 및 행동 분석부에 의해, 상기 비디오 캡션 이 기 설정된 위험 행동과 관련되는지 판단하고, 상기 객체의 행동이 상기 위험 행동과 관련되는 경우, 위험 상 황을 알리는 알람을 발생하는 단계;를 포함한다."}
{"patent_id": "10-2022-0073183", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 CCTV 등을 활용한 영상 보안 시스템 및 방법에 관한 것으로, 보다 상세하게는 멀티-모달 비디오 캡셔 닝(Multi-Modal Video Captioning)을 이용한 영상 보안 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0073183", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상 보안 시스템으로 CCTV가 널리 활용되고 있다. CCTV로 촬영되는 영상은 별도의 기록매체에 저장되므로 사건 발행 후에 확인이 가능하나, 사건이 발생한 즉시 혹은 발생하기 직전에 선제적으로 이를 인식하고 대응하기 위 해서는 CCTV 화면에 문제 행위가 포착되는 즉시 실시간으로 해당 문제 행위를 인지하고 대응할 필요가 있다. 이 로 인해 상시 감시가 필요한 지역의 경우 해당 지역을 감지하는 사람이 24시간 동안 계속 CCTV 화면을 보고 있 어야 하며, 이는 현실적으로 한계가 있다. 또한 CCTV 개수가 기하급수적으로 늘어나면서 수천 대에 달하는 CCTV 를 모두 감시하기 위해서는 적지 않은 인원이 요구된다. 실제로 많은 시 단위에서 5000 ~ 6000여 대의 카메라를 도입하고 있지만, 이를 관리하는 관제 요원은 수십여 명에 불과하다. 이에 따라 최근에 지능형 CCTV를 도입하면서 인공지능의 딥러닝 기술을 활용하여 객체 검출(object detection) 기술과, 이미지 분류(Image Classification) 기술을 통해 실시간 감시를 수행하는 방안이 연구되고 있다. 이러 한 종래의 인공지능 기반 감시 방법은 관심 대상 검출(Object Detection), 관심 영역 검출(Region Localization), 객체 인식 및 추적(Object Identification and Tracking), 추적 물체 분류(Object Classification), 위험 탐지, 경고 발생 등의 순으로 구현될 수 있다. 하지만 인공지능 모델이 특정 대상을 검출하기 위해서는 일정 수준 이상의 화질을 갖추고 있어야 하기 때문에 저화질 CCTV인 경우 정확한 검출이 어렵고, 카테고리별 학습에 방대한 양의 데이터가 필요하다. 종래의 인공지 능 기반 감시 시스템의 경우, 현존하는 지능형 CCTV 특성상, 특정 객체 및 장면에 대해 학습시킨 데이터셋에 대 한 정보들만 검출할 수 있기 때문에 학습되어있지 않은 정보 및 돌발상황에 대한 추론이 어렵다. 또한, 동영상 은 이미지에 비해 학습해야 할 객체의 종류 및 분류 범위를 확정짓기 어려워 종래의 인공지능 모델의 적용에 한 계가 있으며, CCTV 영상이 강도, 절도 등의 특정 범죄 행위가 일어날 가능성이 있는지를 일반화된 개념으로 활 용하기 어렵다."}
{"patent_id": "10-2022-0073183", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 멀티-모달 비디오 캡셔닝(Multi-Modal Video Captioning) 기반의 비디오 내 광범위한 맥락 분석을 통 해 비디오 내 비젼 및 오디오 정보를 바탕으로 객체의 행동을 검출하여 자동으로 상황 인지 정보를 제공하는 멀 티-모달 비디오 캡션 기반 영상 보안 시스템 및 방법을 제공하기 위한 것이다."}
{"patent_id": "10-2022-0073183", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 영상 보안 방법은 비디오 캡션부에 의해, 비디오 데이터를 구성하는 시계열 순의 영상 프레임들을 포함하는 비젼 데이터로부터 상기 비젼 데이터의 시계열 구간별로 상기 비젼 데이터 내 객체의 행동 과 관련된 비디오 캡션을 생성하는 단계; 및 행동 분석부에 의해, 상기 비디오 캡션이 기 설정된 위험 행동과 관련되는지 판단하고, 상기 객체의 행동이 상기 위험 행동과 관련되는 경우, 위험 상황을 알리는 알람을 발생하 는 단계;를 포함한다.상기 비디오 캡션을 생성하는 단계는 상기 비디오 데이터를 상기 비젼 데이터와 오디오 데이터로 분할하는 단계; 및 인공지능 모델에 의해 상기 시계열 구간별로 상기 비젼 데이터 및 상기 오디오 데이터를 기초로 비젼 모드와 오디오 모드의 멀티-모달 분석을 통해 상기 객체의 행동과 관련된 상기 비디오 캡션을 생성하는 단계;를 포함할 수 있다. 상기 비디오 캡션을 생성하는 단계는 (a) 인코더부에 의해, 상기 비젼 데이터와 상기 오디오 데이터를 기초로 멀티-모달 분석을 통해 비젼 인코더 벡터와, 오디오 인코더 벡터를 생성하는 단계; (b) 디코더부에 의해, 학습 된 자막 키 값들을 기초로 상기 비디오 데이터와 관련된 자막 데이터를 셀프 어텐션 처리하여 자막 어텐션 벡터 를 생성하는 단계; 및 (c) 상기 디코더부에 의해, 상기 자막 어텐션 벡터와 상기 비젼 인코더 벡터 및 상기 오 디오 인코더 벡터를 멀티-모달 어텐션 처리하여 상기 비디오 캡션을 생성하는 단계;를 포함할 수 있다. 상기 (a) 단계는 상기 비젼 데이터를 셀프 어텐션 처리하여 비젼 어텐션 벡터를 생성하는 단계; 학습된 비젼 키 값들을 기초로 상기 비젼 데이터를 셀프 어텐션 처리하여 비젼 어텐션 벡터를 생성하는 단계; 학습된 오디오 키 값들을 기초로 상기 오디오 데이터를 셀프 어텐션 처리하여 오디오 어텐션 벡터를 생성하는 단계; 상기 비젼 어 텐션 벡터 및 상기 오디오 어텐션 벡터를 제1 멀티-모달 어텐션부에 입력하여 상기 비젼 인코더 벡터를 생성하 는 단계; 및 상기 비젼 어텐션 벡터 및 상기 오디오 어텐션 벡터를 제2 멀티-모달 어텐션부에 입력하여 상기 오 디오 인코더 벡터를 생성하는 단계;를 포함할 수 있다. 상기 알람을 발생하는 단계는 상기 위험 행동의 발생 시점 및 상기 객체의 위험 행동 정보를 관제시스템에 알리 는 단계를 포함할 수 있다. 상기 비디오 캡션을 생성하는 단계는 상기 비젼 데이터를 기초로 행동 정지점을 설정하여 상기 시계열 구간을 결정하는 단계를 포함할 수 있다. 본 발명의 실시예에 따르면, 상기 영상 보안 방법을 실행시키도록 컴퓨터로 판독 가능한 기록 매체에 기록된 컴 퓨터 프로그램이 제공된다. 본 발명의 실시예에 따른 영상 보안 시스템은 비디오 데이터를 구성하는 시계열 순의 영상 프레임들을 포함하는 비젼 데이터로부터 상기 비젼 데이터의 시계열 구간별로 상기 비젼 데이터 내 객체의 행동과 관련된 비디오 캡 션을 생성하는 비디오 캡션부; 및 상기 비디오 캡션이 기 설정된 위험 행동과 관련되는지 판단하고, 상기 객체 의 행동이 상기 위험 행동과 관련되는 경우, 위험 상황을 알리는 알람을 발생하는 행동 분석부;를 포함한다. 상기 비디오 캡션부는 상기 비디오 데이터를 상기 비젼 데이터와 오디오 데이터로 분할하고; 상기 비젼 데이터 를 기초로 행동 정지점을 설정하여 상기 시계열 구간을 분할하고; 그리고 인공지능 모델에 의해 상기 시계열 구 간별로 상기 비젼 데이터 및 상기 오디오 데이터를 기초로 비젼 모드와 오디오 모드의 멀티-모달 분석을 통해 상기 객체의 행동과 관련된 상기 비디오 캡션을 생성하도록 구성될 수 있다. 상기 비디오 캡션부는 상기 비젼 데이터와 상기 오디오 데이터를 기초로 멀티-모달 분석을 통해 비젼 인코더 벡 터와, 오디오 인코더 벡터를 생성하는 인코더부; 및 학습된 자막 키 값들을 기초로 상기 비디오 데이터와 관련 된 자막 데이터를 셀프 어텐션 처리하여 자막 어텐션 벡터를 생성하고, 상기 자막 어텐션 벡터와 상기 비젼 인 코더 벡터 및 상기 오디오 인코더 벡터를 멀티-모달 어텐션 처리하여 상기 비디오 캡션을 생성하는 디코더부;를 포함할 수 있다. 상기 인코더부는 학습된 비젼 키 값들을 기초로 상기 비젼 데이터를 셀프 어텐션 처리하여 비젼 어텐션 벡터를 생성하는 비젼 셀프 어텐션부; 학습된 오디오 키 값들을 기초로 상기 오디오 데이터를 셀프 어텐션 처리하여 오 디오 어텐션 벡터를 생성하는 오디오 셀프 어텐션부; 상기 비젼 어텐션 벡터 및 상기 오디오 어텐션 벡터를 기 초로 멀티-모달 분석을 수행하여 제1 특징 벡터를 생성하는 제1 멀티-모달 어텐션부; 상기 비젼 어텐션 벡터 및 상기 오디오 어텐션 벡터를 기초로 멀티-모달 분석을 수행하여 제2 특징 벡터를 생성하는 제2 멀티-모달 어텐션 부; 상기 제1 멀티-모달 어텐션부에 의해 생성되는 상기 제1 특징 벡터로부터 비젼 인코더 벡터를 생성하는 제1 완전 연결층; 및 상기 제2 멀티-모달 어텐션부에 의해 생성되는 상기 제2 특징 벡터로부터 상기 오디오 인코더 벡터를 생성하는 제2 완전 연결층;을 포함할 수 있다."}
{"patent_id": "10-2022-0073183", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 의하면, 멀티-모달 비디오 캡셔닝(Multi-Modal Video Captioning) 기반의 비디오 내 광범위 한 맥락 분석을 통해 비디오 내 비젼, 오디오 정보를 바탕으로 객체의 행동을 검출하여 자동으로 상황 인지 정보를 제공하는 멀티-모달 비디오 캡션 기반 영상 보안 시스템 및 방법이 제공된다. 본 발명의 실시예에 의하면, 멀티-모달 비디오 캡셔닝 기술을 기반으로 감시 시스템 내에서 객체의 행동 정보를 실시간 인식하여 감시 시스템을 바라보는 인력을 대체할 수 있으며, 특정 위험 행동이 감지될 때 즉시 경고를 발생함으로써 즉각적인 대응 및 대처가 가능해진다."}
{"patent_id": "10-2022-0073183", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하"}
{"patent_id": "10-2022-0073183", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명 은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 본 명세서에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 사용되는 '~모듈', '~부'는 적어도 하나의 기능이나 동작을 처리하는 단위로서, 예를 들어 소프트웨어, FPGA 또는 하나 이상의 프로세서와 같은 하드웨어 구성요소를 의미할 수 있다. 본 발명의 실시 예를 설명함에 있어서, 관련된 공지의 기능 또는 공지의 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략한다. 본 발명은 멀티-모달 비디오 캡셔닝(Multi-Modal Video Captioning) 기반의 비디오 내 광범위한 맥락 분석을 통 해 비디오 데이터 내 비젼(Vision) 데이터 및 오디오(Audio) 데이터를 바탕으로 비디오 데이터 내 객체의 행동 (Action)을 검출하여 자동으로 영상 상황 인지 정보를 제공하는 감시 시스템 및 방법에 관한 것이다. 본 발명의 실시예에 의하면, 물리보안의 측면에서 여러대의 CCTV들이 해당 모델의 학습을 통해 영상 내에서 어 떠한 범죄가 발생했는지 실시간 추출이 가능하다. 또한 여러 명이 특정 영상 구간 내에서 겹쳐있을 때 각 사람 별 운동(Kinetic) 정보를 바탕으로 학습되기 때문에 사람별로 디테일한 행동 분석이 가능하다. 또한, 본 발명의 실시예에 의하면, 오디오나 발화 정보를 받는 CCTV를 활용하여, 비젼 데이터와 오디오 데이터 를 종합적으로 반영하여 범죄 발생 시점을 분간할 수 있으며, 범죄 발생 시점 및 위험 행동 정보들을 관제시스 템 내에서 관리자에게 실시간 보고하고 경고음을 발생할 수 있다. 본 발명의 실시예에 의하면, 멀티-모달 비디오 캡셔닝 기술을 통해 비젼 데이터와, 오디오 데이터를 모두 활용 하여 행동 발생의 중단점(Breakpoint)을 자동으로 설정하여 구간별 상황 파악이 가능하며, 일반화된 행동 정보 를 바탕으로 즉각적인 상황을 인지해낼 수 있다. 이에 따라 광범위한 정보 및 돌발상황에 대한 추론을 가능케 한다. 본 발명의 실시예에 의하면, 감시 시스템 내에서 관제시스템의 비디오 캡션 서버에 구현된 멀티-모달 비디오 캡 션 모델을 통해 다중 CCTV 영상들을 기초로 시계열 구간별 행동 정보들이 검출되며, 특정 위험 행동 감지시 관 리자에게 보고 및 경보음이 울리면서 범죄 상황에 대한 구체적인 정보 전달이 이루어지게 된다. 도 1은 본 발명의 실시예에 따른 영상 보안 시스템의 구성도이다. 도 1을 참조하면, 본 발명의 실시예에 따른 영상 보안 시스템은 비디오 데이터를 수집하는 하나 이상의 카메라를 포함하는 카메라 시스템과, 카 메라 시스템에 의해 수집된 비디오 데이터를 구성하는 시계열 순의 영상 프레임들을 포함하는 비젼 데이터 와 오디오 데이터로부터 멀티-모달 비디오 캡셔닝을 기반으로 비디오 데이터의 시계열 구간별로 비젼 데이터 내 객체의 행동과 관련된 비디오 캡션(비디오 맥락)을 생성하는 비디오 캡션부, 및 비디오 캡션부에 의해 생성된 비디오 캡션이 기 설정된 위험 행동과 관련되는지 판단하고, 객체의 행동이 위험 행동과 관련되는 경 우 위험 상황을 알리는 알람을 발생하는 행동 분석부 및 위험 행동 분석부를 포함할 수 있다. 카메라 시스템에 의해 수집된 비디오 데이터는 비디오 캡션 서버로 전송될 수 있다. 카메라 시스템 의 카메라는 예를 들어, CCTV 카메라일 수 있으나, 반드시 이에 한정되는 것은 아니다. 비디오 캡션 서버는 비디오 데이터의 비젼 데이터를 수집하는 비젼 서버와, 비디오 데이터의 오디오 데이터를 수집하는 오디오 서버를 포함할 수 있다. 비젼 서버에 의해 수집되는 비젼 데이터와, 오디오 서버에 의해 수집되는 오디오 데이터는 비디오 캡 션부로 전달될 수 있다. 비디오 캡션부는 비디오 데이터를 비젼 데이터와 오디오 데이터로 분할하고, 비젼 데이터를 기초로 행동 정지점을 설정하여 시계열 구간을 분할하고, 인공지능 모델에 의해 시계열 구간별로 비젼 데이터 및 오디오 데이터를 기초로 비젼 모드와 오디오 모드의 멀티-모달 분석을 통해 객체의 행동과 관련 된 비디오 캡션을 생성할 수 있다. 도 2는 본 발명의 실시예에 따른 영상 보안 시스템을 구성하는 비디오 캡션부의 구성도이다. 도 1 및 도 2를 참 조하면, 비디오 캡션부(123, 200)는 VGGish 처리부와, I3D 처리부에 의해 비디오 데이터로부터 도 출된 비젼 데이터와 오디오 데이터를 비디오 캡션 서버에 마련된 인공지능 모델의 인코더부에 입력하 도록 구성될 수 있다. 비디오 캡션부(123, 200)는 비젼 데이터와 오디오 데이터를 기초로 멀티-모달 분석을 통해 비젼 인코더 벡터와, 오디오 인코더 벡터를 생성하는 인코더부, 및 학습된 자막 키 값들을 기초로 비디오 데이터와 관련된 자막 데이터를 셀프 어텐션 처리하여 자막 어텐션 벡터를 생성하고, 자막 어텐션 벡터와 비젼 인코더 벡터 및 오디오 인코더 벡터를 멀티-모달 어텐션 처리하여 비디오 캡션을 생성하는 디코더부를 포함할 수 있다. 인코더부는 학습된 비젼 키 값들을 기초로 비젼 데이터를 셀프 어텐션(self attention) 처리하여 비젼 어 텐션 벡터를 생성하는 비젼 셀프 어텐션부, 학습된 오디오 키 값들을 기초로 오디오 데이터를 셀프 어텐션 처리하여 오디오 어텐션 벡터를 생성하는 오디오 셀프 어텐션부, 비젼 어텐션 벡터 및 오디오 어텐션 벡터 를 기초로 멀티-모달 분석을 수행하여 제1 특징 벡터를 생성하는 제1 멀티-모달 어텐션부, 비젼 어텐션 벡 터 및 오디오 어텐션 벡터를 기초로 멀티-모달 분석을 수행하여 제2 특징 벡터를 생성하는 제2 멀티-모달 어텐 션부, 제1 멀티-모달 어텐션부에 의해 생성되는 제1 특징 벡터로부터 비젼 인코더 벡터를 생성하는 제1 완전 연결층(fully connected layer), 제2 멀티-모달 어텐션부에 의해 생성되는 제2 특징 벡터 로부터 오디오 인코더 벡터를 생성하는 제2 완전 연결층을 포함할 수 있다. 비디오 캡션 서버의 비디오 캡션부를 구성하는 인공지능 모델은 인코더부의 출력 값들을 출력하 는 출력부(220, 230)와, 인공지능 모델을 학습하도록 출력부(220, 230)의 출력 값들을 인코더부의 입력단 으로 피드백하는 피드백부를 포함할 수 있다. 디코더부는 학습된 자막 키 값들을 기초로 비디오 데이터와 관련된 자막 데이터를 셀프 어텐션(self attention) 처리하여 자막 어텐션 벡터를 생성하는 셀프 어텐션부, 셀프 어텐션부에 의해 생성된 자 막 어텐션 벡터와 인코더부에 의해 생성된 비젼 인코더 벡터 및 오디오 인코더 벡터를 멀티-모달 어텐션 처리하는 멀티모달 어텐션부, 멀티-모달 어텐션 처리된 특징 벡터로부터 비디오 캡션을 생성하여 출력하는 완전 연결층을 포함할 수 있다. 비디오 데이터와 관련된 자막 데이터는 캡션부에 의해 획득될 수 있 다. 도 3은 본 발명의 실시예에 따른 인공지능 모델의 신경망을 나타낸 개념도이다. 도 1 내지 도 3을 참조하면, 본 발명의 실시예에 따른 영상 보안 시스템의 신경망은 2D 형태의 신경망을 1024-d Feature의 3D 형태로 확장 시킨 Two-Stream 3D-ConvNet 구조(320, 340)로 제공될 수 있다. 본 발명의 실시예에 따른 인공지능 모델의 신경 망은 ImageNet에서 미리 훈련된 가중치를 가져와 성능을 극대화하도록 구현될 수 있으며, RGB, Optical Flow를 기반으로 비디오 내 행동 및 모션 정보를 파악할 수 있다. 오디오 분석 딥러닝 모델 VGGish는 대규모 Youtube 데이터셋에서 학습된 모델로, 영상 내 오디오를 분석하고 어 떤 카테고리인지 추론할 때 다중 오디오셋(Audioset) 클래스에 대한 분류기를 학습할 수 있으며, 128-d Feature 로 변환하여 다운스트림 분류(Downstream Classification) 모델에 입력으로 제공할 수 있다. I3D 모델과 VGGish 모델의 특징 값들을 Vanilla Transformer 구조 내에서 멀티-모달(Multi-modal) 형태로 구성 하고 Distillation, Pruning 경량화 작업을 거칠 수 있으며, 인공지능 모델에서 자동으로 행동 이벤트(ActionEvent)를 검출하고 비디오 캡션 정보를 생성할 수 있다. 이에 따라 광범위한 맥락 해석과 멀티-모달 분석을 통 해 비젼 및 오디오 정보 모두를 활용하여 중단점(행동 정지점)을 자동으로 설정하여 구간별 맥락을 용이하게 파 악할 수 있다. 비디오를 이해하기 위한 3D를 사용하는 구조인 C3D(3D ConvNet) 구조의 경우, 파라미터가 많아 트레이닝이 어렵 고, 컨볼루션 층들(Convolutional Layers)이 많아 연산량이 압도적으로 높아, 좋은 퍼포먼스를 기대하기 어렵다. 본 발명의 실시예에 따라 사용되는 I3D 구조의 경우, C3D 구조와 달리 옵티컬 플로우(Optical Flow)를 추가하여 2D를 3D로 확장한 개념이기 때문에, ImageNet Pretrained Weight를 그대로 가져올 수 있으며, 이에 따 라 확장성 및 접근성, 정확도 측면에서 성능 향상을 도모할 수 있다. 도 4는 본 발명의 실시예에 따른 영상 보안 방법의 순서도이다. 도 1, 도 2 및 도 4를 참조하면, 본 발명의 실 시예에 따른 영상 보안 방법은 비디오 캡션부에 의해, 비디오 데이터를 구성하는 시계열 순의 영상 프레임 들을 포함하는 비젼 데이터로부터 비젼 데이터의 시계열 구간별로 비젼 데이터 내 객체의 행동과 관련된 비디오 캡션을 생성하는 단계(S10)와, 행동 분석부 및 위험 행동 분석부에 의해, 비디오 캡션이 기 설정된 위험 행동과 관련되는지 판단하고, 객체의 행동이 위험 행동과 관련되는 경우, 알람부를 통해 위험 상황을 알리는 알람을 발생하는 단계(S20)를 포함할 수 있다. 이때, 비디오 캡션을 생성하는 단계(S10)는 비디오 데이터를 비젼 데이터와 오디오 데이터로 분할하는 단계, 및 인공지능 모델에 의해 시계열 구간별로 비젼 데이터 및 오디오 데이터를 기초로 비젼 모드와 오디오 모드의 멀 티-모달 분석을 통해 객체의 행동과 관련된 비디오 캡션을 생성하는 단계를 포함할 수 있다. 도 5는 도 4의 단계 S10을 나타낸 순서도이다. 도 2, 도 4 및 도 5를 참조하면, 비디오 캡션을 생성하는 단계 (S10)는 인코더부에 의해, 비젼 데이터와 오디오 데이터를 기초로 멀티-모달 분석을 통해 비젼 인코더 벡 터와, 오디오 인코더 벡터를 생성하는 단계(S12)와, 디코더부에 의해, 학습된 자막 키 값들을 기초로 비디 오 데이터와 관련된 자막 데이터를 셀프 어텐션 처리하여 자막 어텐션 벡터를 생성하는 단계(S14) 및 디코더부 에 의해, 자막 어텐션 벡터와 비젼 인코더 벡터 및 오디오 인코더 벡터를 멀티-모달 어텐션 처리하여 비디 오 캡션을 생성하는 단계(S16)를 포함할 수 있다. 단계 S12는 비젼 데이터를 셀프 어텐션 처리하여 비젼 어텐션 벡터를 생성하는 단계, 학습된 비젼 키 값들을 기 초로 비젼 데이터를 셀프 어텐션 처리하여 비젼 어텐션 벡터를 생성하는 단계, 학습된 오디오 키 값들을 기초로 오디오 데이터를 셀프 어텐션 처리하여 오디오 어텐션 벡터를 생성하는 단계, 비젼 어텐션 벡터 및 오디오 어텐 션 벡터를 제1 멀티-모달 어텐션부에 입력하여 비젼 인코더 벡터를 생성하는 단계, 및 비젼 어텐션 벡터 및 오 디오 어텐션 벡터를 제2 멀티-모달 어텐션부에 입력하여 오디오 인코더 벡터를 생성하는 단계를 포함할 수 있다. 비디오 캡션을 생성하는 단계(S10)는 비디오 데이터의 비젼 데이터를 기초로 행동 정지점을 설정하여 시계열 구 간을 결정하는 단계를 포함할 수 있다. 알람을 발생하는 단계(S20)는 위험 행동의 발생 시점 및 객체의 위험 행 동 정보를 관제시스템에 알리는 단계를 포함할 수 있다. 이상에서 설명된 실시예들의 구성 중 적어도 일부는 하드웨어 구성요소, 소프트웨어 구성요소, 및/ 또는 하드웨 어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(Arithmetic Logic Unit), 디지털 신호 프로세서(Digital Signal Processor), 마이크로컴퓨터, FPGA(Field Programmable Gate Array), PLU(Programmable Logic Unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제 및 상기 운영 체제 상에서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있 다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만, 해당 기술 분야에서 통 상의 지식을 가진 자는 처리 장치가 복수 개의 처리 요소(Processing Element) 및/또는 복수 유형의 처리요소를 포함할 수 있음을 이해할 것이다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(Parallel Processor) 와 같은, 다른 처리 구성(Processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(Computer Program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로(collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/ 또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하 여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody) 될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분 산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능한 기록 매 체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CDROM, DVD와 같은 광기록 매체(optical media) 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로 그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러 에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트 웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2022-0073183", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 청구범위와 균등한 것들도 후술하는 청구범위의 범위에 속 한다."}
{"patent_id": "10-2022-0073183", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 영상 보안 시스템의 구성도이다. 도 2는 본 발명의 실시예에 따른 영상 보안 시스템을 구성하는 비디오 캡션부의 구성도이다. 도 3은 본 발명의 실시예에 따른 인공지능 모델의 신경망을 나타낸 개념도이다. 도 4는 본 발명의 실시예에 따른 영상 보안 방법의 순서도이다. 도 5는 도 4의 단계 S10을 나타낸 순서도이다."}
