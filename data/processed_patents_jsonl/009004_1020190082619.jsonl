{"patent_id": "10-2019-0082619", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0089125", "출원번호": "10-2019-0082619", "발명의 명칭": "커뮤니케이션 로봇 및 그의 구동 방법", "출원인": "엘지전자 주식회사", "발명자": "김상원"}}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "안마 제공 장치와 연동 가능한 커뮤니케이션 로봇의 구동 방법으로서,상기 안마 제공 장치로부터 기설정된 범위 내에 위치한 사용자의 발화 음성을 획득하는 단계;상기 사용자의 발화 음성으로부터 사용자의 발화 방향을 추적하는 단계;상기 사용자의 발화 방향으로 상기 커뮤니케이션 로봇의 방향을 전환하는 단계;상기 안마 제공 장치의 동작과 관련하여 상기 발화 음성에 포함되는 음성 명령어를 획득하는 단계; 및상기 음성 명령어에 대응하여 상기 안마 제공 장치를 동작시키는 단계를 포함하는,커뮤니케이션 로봇의 구동 방법."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 발화 음성을 획득하는 단계는,기설정된 기동어 및 상기 음성 명령어를 포함하는 상기 발화 음성 중 상기 기동어를 발화한 음성을 획득하는 단계를 포함하는,커뮤니케이션 로봇의 구동 방법."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 음성 명령어를 획득하는 단계는,상기 기동어 발화 이후 상기 음성 명령어를 획득하는 단계를 포함하는,커뮤니케이션 로봇의 구동 방법."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 커뮤니케이션 로봇의 방향을 전환하는 단계는,상기 사용자의 발화 방향으로 상기 커뮤니케이션 로봇의 시선 방향을 전환하는 단계를 포함하는,커뮤니케이션 로봇의 구동 방법."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 안마 제공 장치를 동작시키는 단계는,공개특허 10-2019-0089125-3-상기 커뮤니케이션 로봇의 방향이 상기 음성 명령어에 포함되는 안마 부위를 쳐다보도록 제어하는 단계; 및상기 음성 명령어에 포함되는 안마 부위의 안마를 수행하도록 상기 안마 제공 장치를 동작시키는 단계를 포함하는,커뮤니케이션 로봇의 구동 방법."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 제어하는 단계는,상기 커뮤니케이션 로봇의 방향이 상기 안마 부위를 향하는 시간이 일정 시간을 경과하면, 상기 커뮤니케이션로봇의 방향을 원상 복귀 하도록 제어하는 단계를 포함하는,커뮤니케이션 로봇의 구동 방법."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 안마 제공 장치로부터 기설정된 범위 내에 위치한 사용자의 영상을 획득하는 단계;상기 사용자의 영상으로부터 얼굴 방향을 산출하는 단계; 및상기 사용자의 얼굴 방향으로 상기 커뮤니케이션 로봇의 방향을 전환하는 단계를 더 포함하는,커뮤니케이션 로봇의 구동 방법."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 안마 제공 장치의 동작과 관련하여 안마 부위를 안마하는 상기 사용자의 제스처 영상을 획득하는 단계; 및상기 사용자의 제스처 영상에 대응하여 상기 안마 제공 장치를 동작시키는 단계를 더 포함하는,커뮤니케이션 로봇의 구동 방법."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 사용자의 제스처 영상을 획득하기 전에, 기설정된 기동어 및 상기 음성 명령어를 포함하는 상기 발화 음성중 상기 기동어를 발화한 음성을 획득하는 단계를 포함하는,커뮤니케이션 로봇의 구동 방법."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "안마 제공 장치와 연동 가능한 커뮤니케이션 로봇으로서,상기 안마 제공 장치로부터 기설정된 범위 내에 위치한 사용자의 발화 음성을 획득하고, 상기 안마 제공 장치의동작과 관련하여 상기 발화 음성에 포함되는 음성 명령어를 획득하는 제1 획득부;상기 사용자의 발화 음성으로부터 사용자의 발화 방향을 추적하는 분석부;공개특허 10-2019-0089125-4-상기 사용자의 발화 방향으로 상기 커뮤니케이션 로봇의 방향을 전환하는 제1 동작 제어부; 및 상기 음성 명령어에 대응하여 상기 안마 제공 장치를 동작시키는 제2 동작 제어부를 포함하는,커뮤니케이션 로봇."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 제1 획득부는,기설정된 기동어 및 상기 음성 명령어를 포함하는 상기 발화 음성 중 상기 기동어를 발화한 음성을 획득하는,커뮤니케이션 로봇."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 10 항에 있어서,상기 제1 획득부는,상기 기동어 발화 이후 상기 음성 명령어를 획득하는,커뮤니케이션 로봇."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 10 항에 있어서,상기 제1 동작 제어부는,상기 사용자의 발화 방향으로 상기 커뮤니케이션 로봇의 시선 방향을 전환하는,커뮤니케이션 로봇."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 10 항에 있어서,상기 제1 동작 제어부는,상기 커뮤니케이션 로봇의 방향이 상기 음성 명령어에 포함되는 안마 부위를 쳐다보도록 제어하고,상기 제2 동작 제어부는,상기 음성 명령어에 포함되는 안마 부위의 안마를 수행하도록 상기 안마 제공 장치를 동작시키는,커뮤니케이션 로봇."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서,상기 제1 동작 제어부는,상기 커뮤니케이션 로봇의 방향이 상기 안마 부위를 향하는 시간이 일정 시간을 경과하면, 상기 커뮤니케이션로봇의 방향을 원상 복귀 하도록 제어하는,공개특허 10-2019-0089125-5-커뮤니케이션 로봇."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 10 항에 있어서,상기 안마 제공 장치로부터 기설정된 범위 내에 위치한 사용자의 영상을 획득하는 제2 획득부를 더 포함하고,상기 분석부는,상기 사용자의 영상으로부터 얼굴 방향을 산출하며,상기 제1 동작 제어부는,상기 사용자의 얼굴 방향으로 상기 커뮤니케이션 로봇의 방향을 전환하는,커뮤니케이션 로봇."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16 항에 있어서,상기 제2 획득부는,상기 안마 제공 장치의 동작과 관련하여 안마 부위를 안마하는 상기 사용자의 제스처 영상을 획득하고,상기 제2 동작 제어부는,상기 사용자의 제스처 영상에 대응하여 상기 안마 제공 장치를 동작시키는,커뮤니케이션 로봇."}
{"patent_id": "10-2019-0082619", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 제1 획득부는,상기 사용자의 제스처 영상을 획득하기 전에, 기설정된 기동어 및 상기 음성 명령어를 포함하는 상기 발화 음성중 상기 기동어를 발화한 음성을 획득하는,커뮤니케이션 로봇."}
{"patent_id": "10-2019-0082619", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사물 인터넷을 위해 연결된 5G 환경에서 인공지능(artificial intelligence, AI) 알고리즘 및/또는 기계학습 (machine learning) 알고리즘을 실행하여 안마 제공 장치를 동작시키는 커뮤니케이션 로봇 및 그의 구동 방법이 개시된다. 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇 및 그의 구동 방법은, 안마 제공 장치로부터 기설정 된 범위 내에 위치한 사용자의 발화 음성을 획득하는 단계와, 사용자의 발화 음성으로부터 사용자의 발화 방향을 추적하는 단계와, 사용자의 발화 방향으로 커뮤니케이션 로봇의 방향을 전환하는 단계와, 안마 제공 장치의 동작 과 관련하여 발화 음성에 포함되는 음성 명령어를 획득하는 단계와, 음성 명령어에 대응하여 안마 제공 장치를 동작시키는 단계를 포함할 수 있다."}
{"patent_id": "10-2019-0082619", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 커뮤니케이션 로봇 및 그의 구동 방법에 관한 것으로, 보다 상세하게는 커뮤니케이션 로봇을 이용한 사용자 음성 인식을 통하여 커뮤니케이션 로봇 및 안마 제공 장치의 동작을 제어하는 커뮤니케이션 로봇 및 그 의 구동 방법에 관한 것이다."}
{"patent_id": "10-2019-0082619", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "안마의자는 뭉쳐진 근육을 풀거나 피로 및 스트레스를 해소하기 위하여 특수한 기구로 사용자에게 안마를 제공 하는 것이다. 일반적인 안마의자는 사용자의 목, 팔, 등, 허리, 엉덩이, 다리 등에 대응하는 위치에 안마롤러나 안마돌기를 배치시키고 모터의 동작에 따라 이들을 제어함으로써, 사용자에게 안마를 제공하도록 구성된다. 또한, 안마의자는 일반적인 의자 형태뿐만 아니라 방석 형태로 구현되어 이동 가능하도록 할 수도 있고, 자동차 시트 등에 안마 기구가 내장되는 형태로 구현될 수도 있다. 선행기술 1은 음성 인식 기능 등 다양한 기능을 탑재하여 사용자의 사용상 편의성을 부여할 수 있는 안마 의자 에 대한 기술을 개시하고 있다. 선행기술 2는 사물인터넷 또는 네트워크와 연결된 제어단말기를 사용자가 원하는 안마 패턴으로 조절할 수 있도 록 하는 안마 의자 장치에 대한 기술을 개시하고 있다. 그러나, 선행기술 1 및 선행기술 2의 경우 안마 의자 제어를 위한 리모컨 기능을 음성 인식, 및 사물인터넷 또 는 네트워크와 연결된 제어단말기를 통해 수행하는 것은 가능하나, 사용자와의 커뮤니케이션을 통해 사용자 맞 춤형으로 제어하지 못하는 한계가 있다."}
{"patent_id": "10-2019-0082619", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다. 선행기술문헌 특허문헌 (특허문헌 0001) 국내 등록특허공보 제10-1886627호(2018.08.02. 등록) (특허문헌 0002) 국내 공개특허공보 제10-2018-0100280호(2018.09.10. 공개)"}
{"patent_id": "10-2019-0082619", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 실시 예의 일 과제는, 사용자의 음성인식을 기반으로 한 커뮤니케이션을 통해 안마 제공 장치의 안마 모드를 설정함으로써 사용자에게 최적화된 안마 모드를 제공하여 커뮤니케이션 로봇 및 안마 제공 장치의 성능 을 향상시키는데 있다. 본 개시의 실시 예의 일 과제는, 안마 제공 장치와 연동 가능한 커뮤니케이션 로봇을 통해 안마 제공 장치의 안 마 모드를 설정하고 동작시킴으로써 안마 제공 장치에 대한 사용자의 이용 만족도를 향상시키고, 안마 제공 장 치 이용 시 사용자의 무료함을 해소시키는데 있다. 본 개시의 실시 예의 일 과제는, 사용자 음성 발화 방향 및/또는 얼굴 위치에 따라 커뮤니케이션 로봇의 시선이 향하도록 하여 사용자로 하여금 커뮤니케이션 로봇에 대한 친근감을 느낄 수 있도록 함으로써, 사용자의 이용 만족도를 향상시키는데 있다. 본 개시의 실시 예의 일 과제는, 사용자 음성 인식 및/또는 제스처 인식을 통해 안마 제공 장치의 안마 모드를 설정하고 동작시킴으로써 사용 편의성 및 이용 만족도를 향상시키는데 있다. 본 개시의 실시 예의 일 과제는, 사용자가 안마 제공 장치에 착석하지 않은 상태에서도 커뮤니케이션 로봇을 활 성화시켜 음성 명령에 대응하는 동작을 수행하도록 하여 커뮤니케이션 로봇의 성능을 향상시키고 사용자의 이용 만족도를 향상시키는데 있다. 본 개시의 실시예의 일 과제는, 사용자 헬스케어 정보 및 사용자의 수동 조작 신호를 기반으로 하는 히스토리 정보에 기초하여 사용자 선호도가 반영된 안마 모드를 추천 및 설정함으로써, 사용자에게 보다 최적화된 안마 모드를 제공하여 커뮤니케이션 로봇 및 안마 제공 장치에 대한 사용자의 이용 만족도를 향상시키는데 있다. 본 개시의 실시예의 일 과제는, 사용자 선호도 및 기상 정보를 기반으로 하여 사용자 맞춤형 안마 모드를 추천 함으로써, 사용자의 이용 만족도를 향상시키는데 있다. 본 개시의 실시예의 일 과제는, 자율 주행 차량에서 사용자 선호도, 주행 정보, 교통 정보, 건강 정보 및 기상 정보 중 하나 이상을 기반으로 하여 안마 제공 장치의 안마 모드를 추천함으로써 커뮤니케이션 로봇 및 안마 제 공 장치에 대한 사용자의 이용 만족도를 향상시키고, 커뮤니케이션 로봇 및 안마 제공 장치의 활용성을 향상시 키는데 있다. 본 개시의 실시예의 목적은 이상에서 언급한 과제에 한정되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시 예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발명의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 알 수 있을 것이다."}
{"patent_id": "10-2019-0082619", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 커뮤니케이션 로봇의 구동 방법은, 커뮤니케이션 로봇을 이용한 사용자 음성 인식 을 통하여 커뮤니케이션 로봇 및 안마 제공 장치의 동작을 제어하는 단계를 포함할 수 있다. 구체적으로 본 개시의 일 실시 예에 따른 커뮤니케이션 로봇의 구동 방법은, 안마 제공 장치로부터 기설정된 범 위 내에 위치한 사용자의 발화 음성을 획득하는 단계와, 사용자의 발화 음성으로부터 사용자의 발화 방향을 추 적하는 단계와, 사용자의 발화 방향으로 커뮤니케이션 로봇의 방향을 전환하는 단계와, 안마 제공 장치의 동작 과 관련하여 발화 음성에 포함되는 음성 명령어를 획득하는 단계와, 음성 명령어에 대응하여 안마 제공 장치를 동작시키는 단계를 포함할 수 있다. 본 개시의 일 실시 예에 따른 커뮤니케이션 로봇의 구동 방법을 통하여, 안마 제공 장치와 연동 가능한 커뮤니 케이션 로봇을 통해 안마 제공 장치의 안마 모드를 설정하고 동작시킴으로써 안마 제공 장치에 대한 사용자의 이용 만족도를 향상시킬 수 있다. 또한, 발화 음성을 획득하는 단계는, 기설정된 기동어 및 음성 명령어를 포함하는 발화 음성 중 기동어를 발화 한 음성을 획득하는 단계를 포함할 수 있다. 또한, 음성 명령어를 획득하는 단계는, 기동어 발화 이후 음성 명령어를 획득하는 단계를 포함할 수 있다. 본 개시의 일 실시 예에 따른 발화 음성을 획득하는 단계와 음성 명령어를 획득하는 단계를 통하여, 사용자의 음성인식을 기반으로 한 커뮤니케이션을 통해 안마 제공 장치의 안마 모드를 설정함으로써 사용자에게 최적화된 안마 모드를 제공하여 커뮤니케이션 로봇 및 안마 제공 장치의 성능을 향상시키고 사용자의 이용 만족도를 향상 시킬 수 있다. 또한, 커뮤니케이션 로봇의 방향을 전환하는 단계는, 사용자의 발화 방향으로 커뮤니케이션 로봇의 시선 방향을 전환하는 단계를 포함할 수 있다. 또한, 안마 제공 장치를 동작시키는 단계는, 커뮤니케이션 로봇의 방향이 음성 명령어에 포함되는 안마 부위가 위치되는 방향을 쳐다보도록 제어하는 단계와, 음성 명령어에 포함되는 안마 부위의 안마를 수행하도록 안마 제 공 장치를 동작시키는 단계를 포함할 수 있다. 또한, 제어하는 단계는, 커뮤니케이션 로봇의 방향이 안마 부위를 향하는 시간이 일정 시간을 경과하면, 커뮤니 케이션 로봇의 방향을 원상 복귀 하도록 제어하는 단계를 포함할 수 있다. 본 개시의 일 실시 예에 따른 커뮤니케이션 로봇의 구동 방법은, 커뮤니케이션 로봇의 방향을 전환하는 단계와 안마 제공 장치를 동작시키는 단계와 제어하는 단계를 통하여, 사용자의 위치를 파악하여 커뮤니케이션 로봇의 시선이 사용자를 향하도록 하고, 사용자의 명령에 따라 커뮤니케이션 로봇이 방향을 전환할 수 있도록 함으로써 커뮤니케이션을 통한 상호작용이 가능하도록 할 수 있다. 또한 커뮤니케이션 로봇의 구동 방법은, 안마 제공 장치로부터 기설정된 범위 내에 위치한 사용자의 영상을 획 득하는 단계와, 사용자의 영상으로부터 얼굴 방향을 산출하는 단계와, 사용자의 얼굴 방향으로 커뮤니케이션 로 봇의 방향을 전환하는 단계를 포함할 수 있다. 본 개시의 일 실시 예에 따른 커뮤니케이션 로봇의 구동 방법을 통하여, 사용자 음성 발화 방향 및/또는 얼굴 위치에 따라 커뮤니케이션 로봇의 시선이 향하도록 하여 사용자로 하여금 커뮤니케이션 로봇에 대한 친근감을 느낄 수 있도록 함으로써, 사용자의 이용 만족도를 향상시킬 수 있다. 또한 커뮤니케이션 로봇의 구동 방법은, 안마 제공 장치의 동작과 관련하여 안마 부위를 안마하는 사용자의 제 스처 영상을 획득하는 단계와, 사용자의 제스처 영상에 대응하여 안마 제공 장치를 동작시키는 단계를 포함할 수 있다. 또한 커뮤니케이션 로봇의 구동 방법은, 사용자의 제스처 영상을 획득하기 전에, 기설정된 기동어 및 음성 명령 어를 포함하는 발화 음성 중 기동어를 발화한 음성을 획득하는 단계를 포함할 수 있다. 본 개시의 일 실시 예에 따른 커뮤니케이션 로봇의 구동 방법을 통하여, 사용자 음성 인식 및/또는 제스처 인식 을 통해 안마 제공 장치의 안마 모드를 설정하고 동작시킴으로써 사용 편의성 및 이용 만족도를 향상시킬 수 있 다. 본 개시의 일 실시 예에 따른 커뮤니케이션 로봇은, 안마 제공 장치로부터 기설정된 범위 내에 위치한 사용자의 발화 음성을 획득하고, 안마 제공 장치의 동작과 관련하여 발화 음성에 포함되는 음성 명령어를 획득하는 제1 획득부와, 사용자의 발화 음성으로부터 사용자의 발화 방향을 추적하는 분석부와, 사용자의 발화 방향으로 커뮤 니케이션 로봇의 방향을 전환하는 제1 동작 제어부와, 음성 명령어에 대응하여 안마 제공 장치를 동작시키는 제 2 동작 제어부를 포함할 수 있다. 본 개시의 일 실시 예에 다른 커뮤니케이션 로봇을 통하여, 안마 제공 장치와 연동 가능한 커뮤니케이션 로봇을 이용하여 안마 제공 장치의 안마 모드를 설정하고 동작시킴으로써 안마 제공 장치에 대한 사용자의 이용 만족도 를 향상시키고, 안마 제공 장치 이용 시 사용자의 무료함을 해소시킬 수 있다. 또한, 제1 획득부는, 기설정된 기동어 및 음성 명령어를 포함하는 발화 음성 중 기동어를 발화한 음성을 획득할 수 있다. 또한, 제1 획득부는, 기동어 발화 이후 음성 명령어를 획득할 수 있다. 본 개시의 일 실시 예에 따른 제1 회득부를 통하여, 사용자의 음성인식을 기반으로 한 커뮤니케이션을 통해 안 마 제공 장치의 안마 모드를 설정함으로써 사용자에게 최적화된 안마 모드를 제공하여 커뮤니케이션 로봇 및 안 마 제공 장치의 성능을 향상시키고 이용 편의성을 향상시킬 수 있다. 또한, 제1 동작 제어부는, 사용자의 발화 방향으로 커뮤니케이션 로봇의 시선 방향을 전환할 수 있다. 또한, 제1 동작 제어부는, 커뮤니케이션 로봇의 방향이 음성 명령어에 포함되는 안마 부위를 쳐다보도록 제어하 고, 제2 동작 제어부는, 음성 명령어에 포함되는 안마 부위의 안마를 수행하도록 안마 제공 장치를 동작시킬 수 있다. 또한, 제1 동작 제어부는, 커뮤니케이션 로봇의 시선이 안마 부위를 향하는 시간이 일정 시간을 경과하면, 커뮤 니케이션 로봇의 시선을 원상 복귀 하도록 제어할 수 있다. 본 개시의 일 실시 예에 따른 제1 동작 제어부와 제2 동작 제어부를 통하여, 사용자 음성 발화에 따라 커뮤니케 이션 로봇의 시선이 이동할 수 있도록 함으로써, 커뮤니케이션 성능을 향상시킬 수 있다. 또한 커뮤니케이션 로봇은, 안마 제공 장치로부터 기설정된 범위 내에 위치한 사용자의 영상을 획득하는 제2 획 득부를 포함할 수 있다. 또한, 분석부는, 사용자의 영상으로부터 얼굴 방향을 산출하며, 제1 동작 제어부는, 사 용자의 얼굴 방향으로 커뮤니케이션 로봇의 시선을 전환할 수 있다. 본 개시의 일 실시 예에 따른 제2 획득부, 분석부, 제1 동작 제어부를 통하여, 사용자가 안마 제공 장치에 착석 여부와 상관 없이 커뮤니케이션 로봇을 활성화시켜 음성 명령에 대응하는 동작을 수행하도록 하여 커뮤니케이션 로봇의 성능을 향상시키고 사용자의 이용 만족도를 향상시킬 수 있다. 또한, 제2 획득부는, 안마 제공 장치의 동작과 관련하여 안마 부위를 안마하는 사용자의 제스처 영상을 획득하 고, 제2 동작 제어부는, 사용자의 제스처 영상에 대응하여 안마 제공 장치를 동작시킬 수 있다. 또한, 제1 획득부는, 사용자의 제스처 영상을 획득하기 전에, 기설정된 기동어 및 음성 명령어를 포함하는 발화 음성 중 상기 기동어를 발화한 음성을 획득할 수 있다. 본 개시의 일 실시 예에 따른 제2 회득부, 제2 동작 제어부, 제1 회득부를 통하여, 사용자 음성 인식 및/또는 제스처 인식을 통해 안마 제공 장치의 안마 모드를 설정하고 동작시킴으로써 사용 편의성 및 이용 만족도를 향 상시킬 수 있다. 이 외에도, 본 발명의 구현하기 위한 다른 방법, 다른 시스템 및 상기 방법을 실행하기 위한 컴퓨터 프로그램이 더 제공될 수 있다. 전술한 것 외의 다른 측면, 특징, 이점이 이하의 도면, 특허청구범위 및 발명의 상세한 설명으로부터 명확해질 것이다."}
{"patent_id": "10-2019-0082619", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일 실시 예에 의하면, 사용자의 음성인식을 기반으로 한 커뮤니케이션을 통해 안마 제공 장치의 안마 모드를 설정함으로써 사용자에게 최적화된 안마 모드를 제공하여 커뮤니케이션 로봇 및 안마 제공 장치의 성능 을 향상시킬 수 있다. 또한, 안마 제공 장치와 연동 가능한 커뮤니케이션 로봇을 통해 안마 제공 장치의 안마 모드를 설정하고 동작시 킴으로써 안마 제공 장치에 대한 사용자의 이용 만족도를 향상시키고, 안마 제공 장치 이용 시 사용자의 무료함 을 해소시킬 수 있다. 또한, 사용자 음성 발화 방향 및/또는 얼굴 위치에 따라 커뮤니케이션 로봇의 시선이 향하도록 하여 사용자로 하여금 커뮤니케이션 로봇에 대하여 친근감을 느낄 수 있도록 함으로써, 사용자의 이용 만족도를 향상시킬 수 있다. 또한, 사용자 음성 인식 및/또는 제스처 인식을 통해 안마 제공 장치의 안마 모드를 설정하고 동작시킴으로써 사용 편의성 및 이용 만족도를 향상시킬 수 있다. 또한, 사용자가 안마 제공 장치에 착석하지 않은 상태에서도 커뮤니케이션 로봇을 활성화시켜 음성 명령에 대응 하는 동작을 수행하도록 하여 커뮤니케이션 로봇의 성능을 향상시키고 사용자의 이용 만족도를 향상시킬 수 있 다. 또한, 사용자 헬스케어 정보 및 사용자의 수동 조작 신호를 기반으로 하는 히스토리 정보에 기초하여 사용자 선 호도가 반영된 안마 모드를 추천 및 설정함으로써, 사용자에게 보다 최적화된 안마 모드를 제공하여 커뮤니케이 션 로봇 및 안마 제공 장치에 대한 사용자의 이용 만족도를 향상시킬 수 있다. 또한, 사용자 선호도 및 기상 정보를 기반으로 하여 사용자 맞춤형 안마 모드를 추천함으로써, 사용자의 이용 만족도를 향상시킬 수 있다. 또한, 자율 주행 차량에서 사용자 선호도, 주행 정보, 교통 정보, 건강 정보 및 기상 정보 중 하나 이상을 기반 으로 하여 안마 제공 장치의 안마 모드를 추천함으로써 커뮤니케이션 로봇 및 안마 제공 장치에 대한 사용자의 이용 만족도를 향상시키고, 커뮤니케이션 로봇 및 안마 제공 장치의 활용성을 향상시킬 수 있다. 또한, 커뮤니케이션 로봇 자체는 대량 생산된 획일적인 제품이지만, 사용자는 커뮤니케이션 로봇을 개인화된 장 치로 인식하므로 사용자 맞춤형 제품의 효과를 낼 수 있다."}
{"patent_id": "10-2019-0082619", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0082619", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 설명되는 실시 예들 을 참조하면 명확해질 것이다. 그러나 본 발명은 아래에서 제시되는 실시 예들로 한정되는 것이 아니라, 서로 다른 다양한 형태로 구현될 수 있고, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물 을 포함하는 것으로 이해되어야 한다. 아래에 제시되는 실시 예들은 본 발명의 개시가 완전하도록 하며, 본 발"}
{"patent_id": "10-2019-0082619", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되 는 경우 그 상세한 설명을 생략한다. 본 출원에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, 포함하 다 또는 가지다 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또 는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 이하, 본 발명에 따른 실시 예들을 첨부된 도면을 참조하여 상세히 설명하기로 하며, 첨부 도면을 참조하여 설 명함에 있어, 동일하거나 대응하는 구성요소는 동일한 도면번호를 부여하고 이에 대한 중복되는 설명은 생략하 기로 한다. 도 1은 본 발명의 일 실시 예에 따른 안마 제공 장치, 커뮤니케이션 로봇, 출력장치, 사용자 단말기, 서버 및 이들을 서로 연결하는 네트워크를 포함하는 안마 제공 환경의 예시도이다. 도 1을 참조하면, 안마 제공 환경은 안마 제공 장치, 커뮤니케이션 로봇, 출력장치, 사용자 단말기, 서버 및 네트워크를 포함할 수 있다. 안마 제공 장치는 수동으로 안마를 할 수 있는 소도구, 신체 일부인 팔, 다리, 목 등을 안마해주는 부분 안마기, 신체 전체를 안마해주는 안마 시트 및 안마 의자를 포함할 수 있다. 본 실시 예에서는 안마 의자 형태로 구현되는 안마 제공 장치를 예시로 하며, 이러한 안마 제공 장치(10 0)는 자율 주행 차량 내에도 설치될 수 있다. 또한, 안마 제공 장치는 사용자가 앉았을 때 신체에 맞닿는 시트(미도시)와 시트 내부에 구비되어 사용자 에게 안마를 제공하기 위해 동작하는 안마구동부(미도시)로 크게 구분할 수 있다. 시트는 신체가 안착되는 위치에 따라 상단부, 착좌부 및 하단부로 이루어진다. 즉 시트는 사용자의 머리를 감싸 는 형태의 상단부와, 사용자의 상체를 기대어 앉을 수 있는 형태의 착좌부와, 종아리와 발을 감싸는 형태의 하 단부로 이루어져 사용자에게 안락함과 편안함을 제공할 수 있다. 이때 시트의 각 부분은 사용자의 신체의 특성 에 맞게 크기 및 위치가 수동 또는 자동으로 변경될 수 있다. 또한 안마구동부는 안마 서비스를 제공하는 액츄 에이터를 포함하는 것으로, 안마롤을 동작시키거나 에어를 주입하여 설정된 안마 모드에 따라 위치 및 세기를 다르게 하여 사용자의 전신을 안마할 수 있다. 또한 안마 제공 장치는 센서부(미도시)를 포함하여 안마 제공 장치에 착석한 사용자의 신체 정보를 획득할 수도 있다. 예를 들어, 안마 제공 장치는 센서부를 통해 사용자의 신장, 몸무게, 골격 위치 정보 등을 획득할 수 있다. 또한 지문을 감지하여 사용자의 등록 정보를 획득하여, 해당 사용자에 대응하는 서비스를 제공할 수 있다. 본 실시 예에서 안마 제공 장치는 커뮤니케이션 로봇과 연동되며, 커뮤니케이션 로봇으로부터 제어 명령을 입력 받아 동작할 수 있다. 즉, 커뮤니케이션 로봇은 안마 제공 장치와 연동하여, 안마 제공 장치로부터 기설정된 범위 내 (예를 들어, 1M)에 위치한 사용자의 발화 음성을 획득할 수 있다. 여기서 사용자가 안마 제공 장치로부터 기설정된 범위 내에 위치한다는 것은, 사용자가 안마 제공 장치에 착석한 경우 및 사용자가 안마 제공 장 치에 착석하지 않고 안마 제공 장치 주변에 위치한 경우를 포함할 수 있다. 그리고 커뮤니케이션 로 봇은 사용자의 발화 음성으로부터 사용자의 발화 방향을 추적하여 사용자의 발화 방향으로 방향을 전환하며, 안마 제공 장치의 동작과 관련하여 발화 음성에 포함되는 음성 명령어를 획득해 음성 명령어에 대응하 여 안마 제공 장치를 동작시킬 수 있다. 따라서 본 실시 예에서 커뮤니케이션 로봇은 안마 제공 장치를 제어하기 위한 리모컨의 역할을 대체 할 수 있다. 다만 커뮤니케이션 로봇과 별도로 안마 제공 장치를 제어하기 위한 리모컨이 구비될 수 도 있다. 이때, 커뮤니케이션 로봇은 안마 제공 장치와 유무선으로 연동할 수 있으며, 안마 제공 장 치의 거치 수단을 통해 안마 제공 장치에 장착되거나 설정 범위 내에 위치할 수 있다. 이때, 커뮤니케이션 로봇은 안마 제공 장치 제어를 위해 사용자로부터 서비스 요청 정보를 수신할 수 있다. 커뮤니케이션 로봇이 사용자로부터 서비스 요청 정보를 수신하는 방법은, 사용자로부터 표시부(도 4 의 220)에 대한 터치 신호를 수신하는 경우, 사용자로부터 서비스 요청에 대응하는 발화 음성을 수신하는 경우 및/또는 사용자의 서비스 요청에 대응하는 동작(예를 들어, 커뮤니케이션 로봇의 활성화를 유도하는 제스 처 등)에 대한 촬영 영상을 생성하는 경우 중 하나 이상을 포함할 수 있다. 여기서, 커뮤니케이션 로봇이 사용자로부터 서비스 요청 정보를 수신할 수 있는 조건은, 사용자가 안마 제공 장치로부터 기설정된 범위 내에 위치하고, 커뮤니케이션 로봇이 안마 제공 장치에서 설정 범위 내에 위치하는 경우를 포함할 수 있다. 이때 사용자와 안마 제공 장치 사이의 기설정된 범위 및 커뮤니케이션 로봇과 안마 제공 장치 사이의 일정 범위는 미리 설정되는 값(영역의 크기)을 의미하며, 커뮤니케이션 로봇과 안마 제공 장 치 사이의 설정 범위는 사용자와 안마 제공 장치 사이의 기설정된 범위보다 작은 값으로 설정되거나 같은 값으로 설정될 수 있다. 또한 커뮤니케이션 로봇과 사용자와의 설정 거리는, 사용자와 안마 제공 장 치 사이의 기설정된 범위 내 사용자와 안마 제공 장치간의 최대 거리와, 커뮤니케이션 로봇과 안마 제공 장치 사이의 일정 범위 내 커뮤니케이션 로봇과 안마 제공 장치간의 최대 거리에 따 라 설정될 수 있다. 다만 본 실시 예에서, 커뮤니케이션 로봇과 사용자와의 설정 거리는 사용자와 안마 제 공 장치간의 최대 거리로 설정될 수 있다. 그리고 사용자로부터 서비스 요청 정보를 수신한 커뮤니케이션 로봇은 그에 대응하는 서비스 응답 정보를 생성하고, 표시부 및/또는 오디오 출력부(미도시)를 통하여 서비스 응답 정보를 출력할 수 있다. 더 나아가 커 뮤니케이션 로봇은 서비스 응답 정보를 사용자 단말기로 전송할 수 있다. 커뮤니케이션 로봇은 사용자와 시선, 감정표현, 스킨십 등 감성적 교감으로 소통할 수 있다. 커뮤니케이션 로봇은 사용자의 음성을 수신하거나, 사용자가 커뮤니케이션 로봇의 안면표시부(도 2의 210)를 쓰다 듬는 경우, 그리고 안마 제공 장치에 착석한 사용자의 표정을 감지하고 이에 대응하여 안면표시부의 눈에 해당하는 부분을 통해 기쁨, 슬픔, 화남, 평온 등의 다양한 표정을 디스플레이 할 수 있다. 또한, 커뮤니케이션 로봇은 안면표시부와 몸통부(도 3의 240)의 연결 부분이 앞뒤좌우로 구동 가능하도록 구현되어, 사용자의 음성 및 표정 등에 대응하여 고개를 끄덕이는 모션, 고개를 좌우로 젓는 모션 등을 통해 긍정, 부정 등의 다양 한 감정을 표시할 수 있다. 그리고 커뮤니케이션 로봇은 몸통부 자체도 앞뒤좌우 및 회전 가능하도록 구현 되어 사용자와의 커뮤니케이션을 통해 다양한 모션을 취하도록 할 수 있다. 이때, 사용자와의 커뮤니케이션이란, 사용자와 상호 연결되는 일련의 행위를 의미할 수 있으며, 즉 사용자의 행동에 대응하여 피 드백(feedback) 함으로써, 사용자가 커뮤니케이션 로봇과 감정을 공유하고 있다고 느낄 수 있도록 하는 일 련의 행위를 의미할 수 있다. 또한 본 실시 예에서, 커뮤니케이션 로봇은 사용자의 위치를 파악하여 사용자의 위치 방향으로 시선이 향 하도록 유지할 수 있다. 예를 들어, 커뮤니케이션 로봇은 안면표시부 및 몸통부의 정면 측(안면표시부의 눈에 해당하는 부분 및 표시부가 구비되는 위치)이 사용자를 향하도록 유지할 수 있으며, 사용자의 위치가 변하 는 경우 사용자의 위치를 추적할 수 있다. 또한 커뮤니케이션 로봇은 임의의 제어 명령에 의해 사용자가 아닌 다른 방향으로 시선을 변경한 후에도 일정 시간을 경과하면 사용자가 위치한 방향으로 원상 복귀할 수 있 다. 이때, 커뮤니케이션 로봇은 카메라를 포함할 수 있으며, 카메라는 커뮤니케이션 로봇의 시선과 동일한 방향을 향하도록 배치될 수 있다. 카메라(미도시)는 후술하는 영상인식부(도 4의 233)에 포함될 수도 있 고 별도의 모듈일 수도 있다. 또한 본 실시 예에서, 커뮤니케이션 로봇은 다양한 콘텐츠를 재생할 수 있고, 다양한 정보(예를 들어 날씨, 길 안내, 운세 등)를 제공할 수 있으며, 네트워크를 통하여 다양한 홈 어플라이언스를 원격으로 제 어할 수 있다. 여기서 콘텐츠(content 또는 contents)는, 네트워크를 통하여 접근 가능한, 문자, 부호, 음성, 음향, 음원, 이미지, 동영상(비디오 및 오디오) 등으로 이루어지는 디지털 정보 또는 개별 정보 요소를 통칭하는 개념을 포함할 수 있다. 이러한 콘텐츠는, 예를 들면, 텍스트, 이미지, 동영상, 음원, 링크(예를 들면, 웹 링크) 등 의 데이터 또는 이러한 데이터 중 적어도 두 가지의 조합을 포함하여 구성될 수 있다. 또한 커뮤니케이션 로봇은 안마 제공 장치와 함께 소정의 공간(예를 들어, 가정, 회사, 병원, 자율주 행 차량 등)에 구비될 수 있으며, 커뮤니케이션 로봇과 동일한 공간에 배치되어 오디오 신호 및 비디오 신 호 중 적어도 하나를 출력하는 하나 이상의 출력장치를 검색하고, 동작 모드에 대응하여 검색된 하나 이상 의 출력장치 중 적어도 하나를 선택하고, 선택한 출력장치로 오디오 신호 및 비디오 신호 중 적어도 하나를 전송할 수 있다. 여기서 커뮤니케이션 로봇의 동작 모드는 예를 들어, 사용자 단말기와 연동 된 통화 모드(음성 통화 또는 영상 통화), 콘텐츠를 재생하는 콘텐츠 재생 모드, 안마 제공 장치에서 수행 중인 안마 정보를 출력하는 정보 제공 모드 등을 포함할 수 있다. 여기서, 출력장치를 선택한다는 것은, 커뮤니케이션 로봇의 표시부 및 오디오 출력부를 통하여 사용 자와 호출자 사이에 통화를 수행하는 통화 모드 시에, 호출자의 정보(비디오 신호, 예를 들어, 호출자의 영상, 호출자의 이름, 호출자의 번호 등)를 출력할 어느 한 출력장치를 선택하거나, 호출자의 음성(오디오 신 호)을 출력할 어느 한 출력장치를 선택하거나, 호출자의 정보 및 호출자의 음성을 출력할 어느 한 출력장 치를 선택하는 것을 포함할 수 있다. 또한, 출력장치를 선택한다는 것은, 커뮤니케이션 로봇의 표시부 및 오디오 출력부를 통하여 사용자 가 선택한 임의의 콘텐츠를 재생하는 콘텐츠 재생 모드 시에, 콘텐츠에 포함된 비디오 신호를 출력할 어느 한 출력장치를 선택하거나, 콘텐츠에 포함된 오디오 신호를 출력할 어느 한 출력장치를 선택하거나, 콘 텐츠에 포함된 비디오 신호 및 오디오 신호를 출력할 어느 한 출력장치를 선택하는 것을 포함할 수 있다. 또한, 출력장치를 선택한다는 것은, 커뮤니케이션 로봇의 표시부 및 오디오 출력부를 통하여 안마 제 공 장치에서 수행 중인 안마 정보를 출력하는 정보 제공 모드 시에, 안마 정보(비디오 신호, 예를 들어, 안마 진행 과정, 현재 안마 중인 부위, 사용자 신체 정보 등)를 출력할 어느 한 출력장치를 선택하거나, 안마 정보 음성(오디오 신호)을 출력할 어느 한 출력장치를 선택하거나, 안마 정보 및 안마 정보 음성을 출력할 어느 한 출력장치를 선택하는 것을 포함할 수 있다. 이러한 출력장치는 오디오 신호 및 비디오 신호 중 적어도 하나 이상을 출력하는 전자장치로서, 예를 들어, TV, 2채널 스피커, AI 스피커, 빔 프로젝터, 자체 스피커(미도시) 등을 포함할 수 있다. 본 실시 예에서 출력장치를 상술한 전자장치로 한정하고 있으나, 이에 국한되지 않고 다양한 홈 어 플라이언스(예를 들어, 세탁기, 에어컨, 냉장고, 청소기 등)를 포함할 수 있다. 출력장치 중 적어도 하나는 커뮤니케이션 로봇으로부터 출력 신호의 조정을 포함하는 제어 신호를 수 신하여, 오디오 신호의 출력 음량을 현재보다 더 크게, 또는 현재보다 더 작게, 또는 오프 상태로 조정할 수 있 다. 또한, 출력장치 중 적어도 하나는 커뮤니케이션 로봇으로부터의 비디오 신호 출력 요청에 의해, 커뮤니케이션 로봇으로부터 비디오 신호를 수신하여 출력할 수 있다. 또한, 출력장치 중 적어도 하나 는 커뮤니케이션 로봇으로부터의 오디오 신호 출력 요청에 의해, 커뮤니케이션 로봇으로부터 오디오 신호를 수신하여 출력할 수 있다. 또한, 출력장치 중 적어도 하나는 커뮤니케이션 로봇으로부터의 비 디오 신호 및 오디오 신호 출력 요청에 의해, 커뮤니케이션 로봇으로부터 비디오 신호 및 오디오 신호를 수신하여 출력할 수 있다. 사용자 단말기는 커뮤니케이션 로봇 구동 어플리케이션 또는 커뮤니케이션 로봇 구동 사이트에 접속한 후 인증 과정을 통하여 커뮤니케이션 로봇의 구동 또는 제어를 위한 서비스를 제공받을 수 있다. 본 실시 예 에서 인증 과정을 마친 사용자 단말기는 커뮤니케이션 로봇을 구동하고, 커뮤니케이션 로봇의 동작을 제어할 수 있다. 또한 본 실시 예에서, 사용자 단말기는 안마 제공 장치 구동 어플리케이션 또는 안마 제공 장치 구동 사이트에 접속한 후 인증 과정을 통하여 안마 제공 장치의 구동 또는 제어를 위한 서 비스를 제공받을 수도 있다. 이때, 인증 과정을 마친 사용자 단말기는 안마 제공 장치를 구동하고, 안마 제공 장치의 동작을 제어할 수 있다. 즉, 사용자 단말기에서 안마 제공 장치의 구동 또는 제어를 위한 서비스를 제공받는 경우에는, 커뮤니케이션 로봇과 사용자 단말기를 통해 안마 제공 장 치를 구동하고, 안마 제공 장치의 동작을 제어할 수 있다. 본 실시 예에서 사용자 단말기는 사용자가 조작하는 데스크 탑 컴퓨터, 스마트폰, 노트북, 태블릿 PC, 스 마트 TV, 휴대폰, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지털카메라, 가전기기 및 기타 모바일 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 또한, 사용 자 단말기는 통신 기능 및 데이터 프로세싱 기능을 구비한 시계, 안경, 헤어 밴드 및 반지 등의 웨어러블 단말기 일 수 있다. 사용자 단말기는 상술한 내용에 제한되지 아니하며, 웹 브라우징이 가능한 단말기는 제한 없이 차용될 수 있다. 서버는 각종 인공 지능 알고리즘을 적용하는데 필요한 빅데이터와, 안마 제공 장치 및/또는 커뮤니케 이션 로봇을 동작시키는 데이터를 제공하는 데이터베이스 서버일 수 있다. 그 밖에 서버는 사용자 단 말기에 설치된 안마 제공 장치 구동 어플리케이션 또는 안마 제공 장치 구동 웹 브라우저를 이용하여 안마 제공 장치의 동작을 원격에서 제어할 수 있도록 하는 웹 서버 또는 어플리케이션 서버를 포함할 수 있다. 또한, 서버는 사용자 단말기에 설치된 커뮤니케이션 로봇 또는 커뮤니케이션 로봇 구동 웹 브라우저 를 이용하여 커뮤니케이션 로봇의 동작을 원격에서 제어할 수 있도록 하는 웹 서버 또는 어플리케이션 서 버를 포함할 수 있다. 여기서 인공 지능(artificial intelligence, AI)은, 인간의 지능으로 할 수 있는 사고, 학습, 자기계발 등을 컴 퓨터가 할 수 있도록 하는 방법을 연구하는 컴퓨터 공학 및 정보기술의 한 분야로, 컴퓨터가 인간의 지능적인 행동을 모방할 수 있도록 하는 것을 의미할 수 있다. 또한, 인공 지능은 그 자체로 존재하는 것이 아니라, 컴퓨터 과학의 다른 분야와 직간접적으로 많은 관련을 맺 고 있다. 특히 현대에는 정보기술의 여러 분야에서 인공 지능적 요소를 도입하여, 그 분야의 문제 풀이에 활용 하려는 시도가 매우 활발하게 이루어지고 있다. 머신 러닝(machine learning)은 인공 지능의 한 분야로, 컴퓨터에 명시적인 프로그램 없이 배울 수 있는 능력을 부여하는 연구 분야를 포함할 수 있다. 구체적으로 머신 러닝은, 경험적 데이터를 기반으로 학습을 하고 예측을 수행하고 스스로의 성능을 향상시키는 시스템과 이를 위한 알고리즘을 연구하고 구축하는 기술이라 할 수 있다. 머신 러닝의 알고리즘들은 엄격하게 정해진 정적인 프로그램 명령들을 수행하는 것이라기보다, 입력 데이터를 기반으로 예측이나 결정을 이끌어내기 위해 특정한 모델을 구축하는 방식을 취할 수 있다. 서버는 커뮤니케이션 로봇으로부터 서비스 요청 정보를 수신하여 분석하고, 서비스 요청 정보에 대응 하는 커뮤니케이션 정보 즉, 서비스 응답 정보를 생성하여 커뮤니케이션 로봇으로 전송할 수 있다. 특히, 서버는 커뮤니케이션 로봇으로부터 사용자의 서비스 요청에 대응하는 발화 음성을 수신하고, 음성 인 식 처리를 통하여 발화 음성의 처리 결과를 커뮤니케이션 정보 즉, 서비스 응답 정보로 생성하여 커뮤니케이션 로봇으로 제공할 수 있다. 여기서, 커뮤니케이션 로봇의 프로세싱 능력에 따라, 상술한 사용자의 서 비스 요청에 대응하는 발화 음성을 인식 처리하고 그 처리 결과를 커뮤니케이션 정보 즉, 서비스 응답 정보로 생성할 수도 있다. 또한, 서버는 커뮤니케이션 로봇으로부터 사용자의 서비스 요청에 대응하는 발화 음성을 수신하고, 음성 인식 처리를 통하여 발화 음성의 처리 결과를 커뮤니케이션 정보 즉, 서비스 응답 정보 로 생성하여 안마 제공 장치로 제공할 수도 있다. 또한, 본 실시 예에서 서버는 커뮤니케이션 로봇으로부터 사용자의 서비스 요청에 대응하는 사용자 제스처 영상을 수신하여 분석하고, 사용자 제스처 영상의 분석 결과를 커뮤니케이션 정보 즉, 사용자 제스처에 대응하는 서비스 응답 정보로 생성하여 커뮤니케이션 로봇 및/또는 안마 제공 장치로 제공할 수 있다. 네트워크는 안마 제공 장치와, 커뮤니케이션 로봇과, 출력장치와, 사용자 단말기와, 서버를 연결하는 역할을 수행할 수 있다. 이러한 네트워크는 예컨대 LANs(local area networks), WANs(Wide area networks), MANs(metropolitan area networks), ISDNs(integrated service digital networks) 등의 유선 네트워크나, 무선 LANs, CDMA, 블루투스, 위성 통신 등의 무선 네트워크를 망라할 수 있으나, 본 발 명의 범위가 이에 한정되는 것은 아니다. 또한 네트워크는 근거리 통신 및/또는 원거리 통신을 이용하여 정보를 송수신할 수 있다. 여기서 근거리 통신은 블루투스(bluetooth), RFID(radio frequency identification), 적외선 통신(IrDA, infrared data association), UWB(ultra-wideband), ZigBee, Wi- Fi(Wireless fidelity) 기술을 포함할 수 있고, 원거리 통신은 CDMA(code division multiple access), FDMA(frequency division multiple access), TDMA(time division multiple access), OFDMA(orthogonal frequency division multiple access), SC-FDMA(single carrier frequency division multiple access) 기술을 포함할 수 있다. 네트워크는 허브, 브리지, 라우터, 스위치 및 게이트웨이와 같은 네트워크 요소들의 연결을 포함할 수 있 다. 네트워크는 인터넷과 같은 공용 네트워크 및 안전한 기업 사설 네트워크와 같은 사설 네트워크를 비롯 한 하나 이상의 연결된 네트워크들, 예컨대 다중 네트워크 환경을 포함할 수 있다. 네트워크에의 액세스는 하나 이상의 유선 또는 무선 액세스 네트워크들을 통해 제공될 수 있다. 더 나아가 네트워크는 사물 등 분 산된 구성 요소들 간에 정보를 주고받아 처리하는 IoT(Internet of Things, 사물인터넷) 망 및/또는 5G 통신을 지원할 수 있다. 도 2는 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 외관을 개략적으로 설명하기 위하여 도시한 도면이고, 도 3은 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 기구적 구조를 개략적으로 설명하기 위하 여 도시한 도면이다. 이하의 설명에서 도 1에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 2 및 도 3을 참조하면, 커뮤니케이션 로봇은 상부 바디 및 하부 바디를 포함할 수 있으며, 상부 바디는 커뮤니케이션 로봇의 상부, 즉 얼굴을 형성하고 본 실시 예에서는 안면표시부로 통칭할 수 있다. 또 한 하부 바디는 커뮤니케이션 로봇의 하부, 즉 몸통을 형성하고 본 실시 예에서는 몸통부로 통칭할 수 있다. 안면표시부는 내부 파트를 보호하고 안면표시부의 표면을 덮고 있는 디스플레이 커버와, 사람의 눈 모양과 비슷하게 다양한 표정을 나타낼 수 있도록 하는 PICTO필름을 포함할 수 있다. 그리고 안면표시 부는 발광소자로부터 출력되는 빛의 밝기를 일정하게 하기 위한 확산시트와, 특정한 영역에 광 선을 집중시켜 보내기 위한 반사판의 역할을 하는 리플렉터와, 발광소자를 포함할 수 있다. 이때 발 광소자는 복수 개의 LED 모듈이 격자형으로 배치될 수 있으며, 발광소자의 출력 형태에 따라 PICTO필 름을 통해 다양한 표정이 출력될 수 있다. 몸통부는 표시부, 음성인식부, 영상인식부, 생체인식부 및 구동부를 포함할 수 있다. 이는 몸통부로 통칭할 수 있는 커뮤니케이션 로봇의 본체 위치에 표시부, 음성인식부 , 영상인식부, 생체인식부 및 구동부의 전체 구성 요소 또는 일부 구성 요소가 구비될 수 있다는 것을 의미하는 것으로, 몸통부는 커뮤니케이션 로봇의 몸통을 형성하는 커버만을 의미할 수도 있다. 이때, 커뮤니케이션 로봇은 표시부를 통해 컨트롤 패널을 제공할 수 있고, 다양한 콘텐츠의 재 생, 다양한 정보(예를 들어, 안마 정보, 사용자 정보 등)의 제공, 네트워크를 통하여 안마 제공 장치(10 0)의 원격 제어를 수행할 수 있다. 즉 커뮤니케이션 로봇은 몸통부에 표시부를 구비하여, 안마 제공 장치 제어 모드(예를 들어, 안마 모드, 동작 모드 등) 및/또는 안마 제공 장치 동작 상태 등을 디스플레이 할 수 있다. 음성인식부는 몸통부의 일 측에 구비된 복수 개의 음성 인식 마이크 홀을 포함할 수 있다. 따라서 본 실시 예에서는, 복수 개의 음성 인식 마이크 홀을 통해 음성 발화 방향을 추적할 수 있다. 또한 영상인식부 는 몸통부의 일 측에 구비된 카메라 모듈을 포함할 수 있다. 따라서 본 실시 예에서는, 카메라를 통 해 사용자 얼굴, 제스처 등의 영상을 획득할 수 있다. 그리고 생체인식부는 사용자의 생체 정보를 획득하 기 위한 감지 수단을 의미할 수 있으며, 예를 들어, 지문인식 모듈 등을 포함할 수 있다. 본 실시 예에서는 생 체인식부를 통해 기등록된 사용자를 인식하거나, 안마 수행에 따른 사용자의 생체 변화를 감지하는 등 사 용자 정보를 획득하여 사용자에게 최적화된 안마를 제공하도록 할 수 있다. 또한 구동부는 몸통부가 앞뒤좌우로 접힐 수 있도록 하는 모터와, 360도 회전하여 방향 전환이 가능 하도록 하는 모터를 포함할 수 있다. 또한 도 2 및 도 3에는 도시되어 있지 않으나, 구동부는 안면표시부 와 몸통부의 연결 부위에도 구비되어 안면표시부가 앞뒤좌우로 접힐 수 있도록 하고, 360도 회 전하여 방향 전환이 가능하도록 할 수 있다. 도 4는 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 개략적인 블록도이다. 이하의 설명에서 도 1 내지 도 3에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 4를 참조하면, 커뮤니케이션 로봇은 안면표시부, 표시부, 음성인식부, 영상인식부 , 생체인식부, 구동부, 통신부, 메모리, 처리부 및 제어부를 포함할 수 있다. 안면표시부는 커뮤니케이션 로봇의 상부, 즉 얼굴 형상을 나타내는 것으로, 전면 측에 사용자와 시선, 감정표현 등 감성적 교감을 위해 사람의 눈 모양과 비슷한 타원 또는 원형의 모양을 형성할 수 있다. 또 한 안면표시부는 제어부의 제어 하에 다양한 표정을 디스플레이 할 수 있다. 즉 안면표시부는사용자의 터치, 음성 또는 영상(사용자 표정, 제스처 등)에 반영하여, 사람의 눈 모양과 비슷한 타원 또는 원형 의 모양을 통해 기쁨, 슬픔, 화남, 평온 등의 다양한 표정을 디스플레이 할 수 있다. 또한, 안면표시부는 카메라를 구비하여 사용자 및 주변 영상을 촬영할 수 있다. 예를 들어, 영상 인식 모듈은 사람의 눈 모양과 비 슷한 타원 또는 원형의 모양의 위치에 구비될 수 있다. 제어부는 카메라의 동작을 제어할 수 있다. 이때 카메라는 영상인식부에 포함될 수 있다. 또한 본 실시 예에서는 영상인식부가 몸통부(도 3의 240)에 위치하는 것으로 도시하고 있으나, 안면표시부에 위치할 수도 있고, 안면표시부 및 몸통부에 위치할 수도 있다. 표시부는 커뮤니케이션 로봇의 하부, 즉 몸통 형상에 구비되는 것으로, 제어부의 제어 하에 커 뮤니케이션 로봇의 동작과 관련한 정보를 시각 데이터로 출력할 수 있고, 안마 제공 장치의 작동 상 태를 표시할 수 있다. 도 5에는 표시부에 표시되는 컨트롤 패널의 일 예가 도시되어 있다. 도 5를 참조하면, 컨트롤 패널은 안마 제공 장치의 안마 실행 시간을 표시하는 동작시간 표시부 , 메모리에 저장된 안마 모드를 선택할 수 있는 사용자 모드 선택부를 포함할 수 있다. 이때 본 실시 예에서는, 사용자가 원하는 최적의 자동코스 설정을 메모리에 저장할 수 있으며, 사용자가 메모리 에 저장된 안마 모드를 선택하면 선택된 사용자 모드가 사용자 모드 선택부에 표시될 수 있다. 또한 컨트롤 패널은 안마 위치, 세기 등 자동으로 설정되어 있는 안마 코스를 선택할 수 있는 자동 안마 코스 선택부(224, 225)를 포함할 수 있다. 자동 안마 코스는 예를 들어, 휴식 코스, 활력 코스, 심야 코스, 스트레칭 코스, 긴장완화 코스, 목/어깨 코스, 등/허리 코스 및 다리/발 코스를 포함할 수 있다. 이때, 사용자가 자동 안 마 코스 선택부(224, 225)의 코스 중 원하는 코스를 선택하면 선택된 안마 코스가 자동 안마 코스 선택부(224, 225)에 표시될 수 있다. 또한 컨트롤 패널은 안마 세기 등 안마 옵션을 조절할 수 있는 안마 옵션 조절부, 현재 안마 수행 위 치를 표시하고 사용자가 원하는 위치로 세부적으로 변경할 수 있도록 하는 안마 위치 조절부 및 안마동작 선택이 가능한 수동 안마 코스 선택부를 포함할 수 있다. 이때 안마 옵션 조절부는 예를 들어, 상반 신 에어 강도, 하반신 에어 강도, 등 안마 강도 및 발바닥 롤러 안마 강도 등의 안마 옵션을 조절할 수 있고, 수동 안마 코스 선택부는 예를 들어, 주무르기, 두드리기, 혼합 마사지, 물결 마사지 및 지압 등의 안마 코스를 수동으로 선택할 수 있도록 한다. 한편, 컨트롤 패널이 터치 패널로 구현되는 경우, 동작시간 표시부, 사용자 모드 선택부, 자동 안마 코스 선택부(224, 225), 안마 옵션 조절부, 안마 위치 조절부 및 수동 안마 코스 선택부는 사용자의 터치 입력을 통해 해당 선택에 대응되는 항목이 선택 및 설정되고, 선택된 항목이 표시될 수 있도록 한다. 특히 안마 위치 조절부는 사람 모양의 형태를 출력하여 사용자가 안마 위치를 보다 용이하게 선택할 수 있도록 한다. 또한 표시부는 안마 부위에 따른 효과 정보, 나이 및 성별 등 사용자 특성에 맞는 안마 정보 등 건강에 관 련된 정보를 표시할 수 있다. 본 실시 예에서 표시부는 각종 정보를 표시하는 기능 이외에 안마 제공 장치 의 동작 전반을 사용자가 제어할 수 있도록, 소정의 제어 명령을 입력받는 입력부의 기능을 수행할 수 있 다. 이를 위해 표시부는 터치 인식 디스플레이 제어기 또는 이외의 다양한 입출력 제어기로 구성될 수 있 다. 일 예로, 터치 인식 디스플레이 제어기는 장치와 사용자 사이에 출력 인터페이스 및 입력 인터페이스를 제 공할 수 있다. 터치 인식 디스플레이 제어기는 전기 신호를 제어부와 송수신할 수 있다. 또한, 터치 인식 디스플레이 제어기는 사용자에게 시각적인 출력을 표시하며, 시각적 출력은 텍스트, 그래픽, 이미지, 비디오와 이들의 조합을 포함할 수 있다. 이와 같은 표시부는 예를 들어, 터치 인식이 가능한 OLED(organic light emitting display) 또는 LCD(liquid crystal display) 또는 LED(light emitting display)와 같은 소정의 디스 플레이 부재일 수 있다. 즉 표시부는 터치 센서와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써, 터치 스크린(미도시)으로 구현될 수 있다. 또한 본 실시 예는, 출력부(미도시)를 포함할 수 있다. 출력부는 커뮤니케이션 로봇의 동작과 관련한 정보 를 청각 데이터, 촉각 데이터 등으로 출력할 수 있으며, 오디오 출력부 및 햅틱 출력부(미도시)를 포함할 수 있 다. 오디오 출력부는 커뮤니케이션 로봇의 동작과 관련한 정보를 오디오 데이터로 출력할 수 있는데, 제어 부의 제어에 따라 경고음, 동작모드, 동작상태, 에러상태 등의 알림 메시지와, 사용자의 음성 명령에 대응 하는 정보, 사용자 음성 명령에 대응하는 처리 결과 등을 오디오로 출력할 수 있다. 오디오 출력부는, 제어부 로부터의 전기 신호를 오디오 신호로 변환하여 출력할 수 있다. 이를 위해, 스피커(미도시) 등을 구비할 수 있다. 또한 오디오 출력부는 커뮤니케이션 로봇과 유/무선 통신 가능한 기기로부터의 오디오 신호(예를들어, 음악 재생 등)를 출력할 수 있다. 음성인식부는 오디오 신호, 특히 사용자의 발화 음성을 입력 받을 수 있다. 음성인식부는 복수 개의 음성 인식 마이크 홀을 포함할 수 있으며, 제어부의 제어 하에, 커뮤니케이션 로봇을 향하여 사용자 가 발화한 발화 음성을 입력 받을 수 있다. 복수 개의 음성 인식 마이크 홀은 서로 다른 위치에 이격되어 배치 될 수 있고, 수신한 사용자의 발화 음성을 전기적인 신호로 처리할 수 있다. 여기서 음성인식부는 사용자 의 발화 음성을 수신하는 과정에서 발생하는 노이즈를 제거하기 위한 다양한 노이즈 제거 알고리즘을 사용할 수 있다. 선택적 실시 예로 음성인식부는 사용자의 발화 음성 수신 시에 노이즈를 제거하는 필터(미도시), 필터에서 출력되는 신호를 증폭하여 출력하는 증폭기(미도시) 등 음성 신호 처리를 위한 각종 구성 요소들을 포 함할 수 있다. 본 실시 예에서 음성인식부는 사용자의 발화 음성으로부터 사용자의 발화 방향을 추적하여 사용자의 발화 방향으로 커뮤니케이션 로봇의 방향을 전환하고, 안마 제공 장치의 동작과 관련하여 발화 음성에 포함되는 음성 명령어를 획득해 음성 명령어에 대응하여 안마 제공 장치를 동작시키기 위한 음성을 획득할 수 있다. 영상인식부는 영상 신호, 특히 사용자 영상 및 주변 영상을 입력 받을 수 있다. 영상인식부는 카메라 모듈을 포함할 수 있으며, 제어부의 제어 하에, 커뮤니케이션 로봇의 구동 모드 및/또는 구동 상태에 따라 사용자 영상 및 주변 영상을 촬영할 수 있고, 촬영 효율을 위해 복수 개가 설치될 수도 있다. 예를 들어, 영상인식부는 안면표시부의 디스플레이 커버 내부 및 표시부에 설치되어, 외관적으로는 보 이지 않도록 구현될 수도 있다. 이러한 영상인식부는 적어도 하나의 광학렌즈와, 광학렌즈를 통과한 광에 의해 상이 맺히는 다수개의 광다이오드(photodiode, 예를 들어, pixel)를 포함하여 구성된 이미지센서(예를 들 어, CMOS image sensor)와, 광다이오드들로부터 출력된 신호를 바탕으로 영상을 구성하는 디지털 신호 처리기 (DSP: digital signal processor, 미도시)를 포함할 수 있다. 또한 영상인식부는 정지영상은 물론이고, 정지영상으로 구성된 프레임들로 이루어진 동영상을 생성할 수 있다. 한편, 영상인식부가 획득한 영상은 메모리에 저장될 수 있다. 본 실시 예에서 영상인식부는 사용자의 얼굴 방향을 산출하여 사용자의 얼 굴 방향으로 커뮤니케이션 로봇의 방향을 전환하고, 안마 제공 장치의 동작과 관련하여 안마 부위를 안마하는 사용자의 제스처 영상을 획득하기 위한 영상을 촬영할 수 있다. 생체인식부는 사용자에게 최적화된 안마 모드 및 사용자 맞춤형 서비스를 제공하기 위한 사용자 정보를 감 지하는 감지 수단을 의미할 수 있다. 즉 본 실시 예에서는, 생체인식부를 통해 사용자의 건강 상태, 안마 시 감정 상태 등을 감지 및 분석할 수 있으며, 이를 활용하여 사용자에게 최적화된 안마 모드를 학습하여 제공 하도록 할 수 있다. 예를 들어, 사용자가 안마 제공 장치에 착석하면 생체인식부를 통해 사용자의 체 형을 분석하여 체형에 대응하는 안마 모드를 추천할 수 있고, 안마 시 사용자의 표정을 분석하여 긍정적인 표정 이라고 분류되는 표정일 때의 안마 모드를 추천할 수 있다. 한편, 사용자의 건강 상태 및 사용자 개인 정보에 대한 데이터는 사용자 단말기, 컨트롤 패널 및 음성인식부를 통한 음성 인식 등을 이용하여 사 용자에 의해 직접 입력될 수도 있다. 보다 구체적으로, 생체인식부는 커뮤니케이션 로봇 및 커뮤니케이션 로봇과 연동 가능한 안마 제공 장치에 포함된 각종 생체 인식 센서를 포함할 수 있으며, 이러한 생체인식부의 감지 데이터를 조합 및 분석할 수 있다. 예를 들어, 안마 제공 장치에 구비된 센서는, 무게 감지 센서, 가속도 센서 (acceleration sensor), 중력 센서(G-sensor), 자이로스코프 센서(gyroscope sensor), 모션 센서(motion sensor), 적외선 센서(IR 센서: infrared sensor), 지문인식 센서(finger scan sensor), 초음파 센서 (ultrasonic sensor), 환경 센서(예를 들어, 기압계, 습도계, 온도계, 방사능 감지 센서, 열 감지 센서, 가스 감지 센서 등), 화학 센서(예를 들어, 전자 코, 헬스케어 센서, 생체 인식 센서 등) 중 적어도 하나를 포함할 수 있다. 또한 커뮤니케이션 로봇에 구비된 센서는, 라이다 센서((Lidar sensor) 등), 조도 센서(illumination sensor), 가속도 센서, 중력 센서, 자이로스코프 센서, 모션 센서, RGB 센서, 적외선 센서, 지문인식 센서, 초 음파 센서, 광 센서(optical sensor), 환경 센서, 화학 센서 중 적어도 하나를 포함할 수 있다. 한편, 본 실시 예에서 안마 제공 장치 및 커뮤니케이션 로봇은 이러한 센서들 중 적어도 둘 이상의 센서에서 센싱되 는 정보들을 조합하여 활용할 수 있다. 구동부는 제어부가 필요한 동작, 원하는 동작을 진행하기 위하여 제어부에서 원하는 동작에 대 한 신호를 받아 커뮤니케이션 로봇이 방향을 전환하는 등의 동작을 하도록 할 수 있다. 즉 구동부는 복수 개 구비될 수 있으며, 스텝 모터, BLDC 모터 등을 포함할 수 있다. 통신부는 네트워크와 연동하여 안마 제공 장치, 커뮤니케이션 로봇, 사용자 단말기 및/또는 서버 간의 송수신 신호를 패킷 데이터 형태로 제공하는데 필요한 통신 인터페이스를 제공할 수 있 다. 또한, 통신부는 각종 사물 지능 통신(IoT(internet of things), IoE(internet of everything), IoST(internet of small things) 등)을 지원할 수 있으며, M2M(machine to machine) 통신, V2X(vehicle to everything communication) 통신, D2D(device to device) 통신 등을 지원할 수 있다. 메모리는 커뮤니케이션 로봇의 다양한 기능을 지원하는 정보를 저장할 수 있다. 메모리는 커뮤 니케이션 로봇에서 구동되는 다수의 응용 프로그램(application program 또는 어플리케이션 (application)), 커뮤니케이션 로봇의 동작을 위한 정보들, 명령어들을 저장할 수 있다. 이러한 응용 프로 그램 중 적어도 일부는, 무선 통신 통해 외부 서버로부터 다운로드 될 수 있다. 또한, 메모리는 커뮤니케 이션 로봇과 인터랙션을 수행하려는 한 명 이상의 사용자 정보를 저장할 수 있다. 이러한 사용자 정보는 인식된 사용자가 누구인지 식별하는데 사용될 수 있는 얼굴 정보 및 체형 정보(예를 들어, 영상인식부 또 는 생체인식부에 의해 촬영)와, 음성 정보 등을 포함할 수 있다. 또한, 메모리는 커뮤니케이션 로봇을 구동시킬 수 있는 기동어가 저장되어 있어서, 사용자가 기동어 를 발화하면 처리부에서 이를 인식하여 비활성화 상태였던 커뮤니케이션 로봇을 활성화 상태로 변경 할 수 있다. 또한 메모리는 사용자의 음성 명령(예를 들어, 커뮤니케이션 로봇을 호출하는 발화 음성, 안마 제공 장치를 제어하기 위한 명령어 등)에 대응하여 커뮤니케이션 로봇이 수행해야 할 작 업 정보 등을 저장할 수 있다. 본 실시 예에서 메모리는 커뮤니케이션 로봇을 통해 제어 가능한 안마 제공 장치의 안마 정보와, 출력장치의 성능 정보 및/또는 위치 정보와, 해당 사용자임을 특정할 수 있는 사용자의 특성 정보(예를 들어, 얼굴 정보, 음성 정보 등)와, 특정 사용자의 경우 설정할 안마 모드 및 안 마 옵션 등을 저장할 수 있다. 여기서 출력장치의 성능 정보라 함은, 출력 세기 정보, 채널 수 정보, 그 외 출력 성능을 나타내는 다양한 정보 등을 포함할 수 있다. 본 실시 예에서 메모리는 제어부가 처리하는 데이터를 일시적 또는 영구적으로 저장하는 기능을 수행 할 수 있다. 여기서, 메모리는 자기 저장 매체(magnetic storage media) 또는 플래시 저장 매체(flash storage media)를 포함할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 이러한 메모리는 내장 메모리 및/또는 외장 메모리를 포함할 수 있으며, DRAM, SRAM, 또는 SDRAM 등과 같은 휘발성 메모리, OTPROM(one time programmable ROM), PROM, EPROM, EEPROM, mask ROM, flash ROM, NAND 플래시 메모리, 또는 NOR 플래시 메모리 등과 같은 비휘발성 메모리, SSD, CF(compact flash) 카드, SD 카드, Micro-SD 카드, Mini- SD 카드, Xd 카드, 또는 메모리 스틱(memory stick) 등과 같은 플래시 드라이브, 또는 HDD와 같은 저장 장치를 포함할 수 있다. 또한 본 실시 예는, 도시되지는 않았으나 전원 공급부(미도시)를 포함할 수 있다. 전원 공급부는 제어부의 제어 하에서, 외부의 전원, 내부의 전원을 인가 받아 커뮤니케이션 로봇의 각 구성요소들에 전원을 공급할 수 있다. 이러한 전원 공급부는 배터리를 포함할 수 있으며, 배터리는 내장형 배터리 또는 교체가능한 형태의 배터리로 구성될 수 있다. 배터리는 유선 또는 무선 충전 방식으로 충전될 수 있는데, 무선 충전 방식은 자기 유도 방식 또는 자기 공진 방식을 포함할 수 있다. 본 실시 예에서 배터리는 니켈-카드뮴 전지(nickel-cadmium battery), 납 축전치, 니켈-수소 전지(NiMH: nickel metal hydride battery), 리튬-이온 전지(lithium ion battery), 리튬 폴리머 전지(lithium polymer battery) 등의 충전 가능한 이차 전지를 포함할 수 있으며, 이에 한정되는 것은 아니다. 본 실시 예에서 제어부는 배터리의 충방전을 제어할 수 있고, 배터리의 상태 정보 를 모니터링하여 배터리를 보호할 수 있다. 예를 들어, 제어부는 배터리에 대한 과충전 보호 기능, 과방 전 보호 기능, 과전류 보호 기능, 과전압 보호 기능, 과열 보호 기능, 셀 밸런싱(cell balancing) 기능 등을 수 행할 수 있다. 또한 제어부는 배터리의 전류, 전압, 온도, 잔여 전력량, 수명, 충전 상태(state of charge, SOC)등을 획득할 수 있다. 예를 들어, 제어부는 도시되지 않았으나 센싱부(미도시)를 이용하여 배터리의 전압 및 온도를 측정할 수 있다. 배터리에 과충전, 과방전, 과전류, 및 고온 등과 같은 이상 상황이 발생하였음을 감지하는 경우, 제어부는 배터리의 충방전을 제어하여 배터리를 보호할 수 있다. 처리부는 안마 제공 장치로부터 기설정된 범위 내에 위치한 사용자의 발화 음성을 획득하는 경우, 음 성 인식 처리를 통하여 발화 음성의 처리 결과를 커뮤니케이션 정보 즉, 서비스 응답 정보로 제공하기 위한 일 련의 처리를 수행할 수 있다. 처리부는 음성 인식 처리를 위해 자동 음성 인식 기능을 이용할 수 있다. 또한 처리부는 사용자의 발화 음성으로부터 사용자의 발화 방향을 추적하고, 사용자의 발화 방향으로 커뮤 니케이션 로봇의 방향을 전환할 수 있다. 그리고 처리부는 안마 제공 장치의 동작과 관련하여 발화 음성에 포함되는 음성 명령어를 획득하고 음성 명령어에 대응하여 안마 제공 장치를 동작시킬 수 있다. 또한 처리부는 안마 제공 장치로부터 기설정된 범위 내에 위치한 사용자의 영상을 획득하고 사용 자의 영상으로부터 얼굴 방향을 산출하여 사용자의 얼굴 방향으로 커뮤니케이션 로봇의 방향을 전환할 수 있다. 그리고 처리부는 안마 제공 장치의 동작과 관련하여 안마 부위를 안마하는 사용자의 제스처 영 상을 획득하고, 사용자의 제스처 영상에 대응하여 안마 제공 장치를 동작시킬 수 있다. 예를 들어, 사용자의 제스처 영상이 손으로 어깨를 주무르는 동작이라면, 이를 모방하여 안마 제공 장치의 어깨 부분의 파트들이 구동하여 사용자의 어깨를 주무르는 동작을 수행할 수 있다. 다른 예로, 사용자의 제스처 영상이 손으로 허벅지를 두드리는 동작이라면, 이를 모방하여 안마 제공 장치(10 0)의 허벅지 부분의 파트들이 구동하여 사용자의 허벅지를 두드리는 동작을 수행할 수 있다. 즉, 사용자의 제스처 영상에 대응하여 안마 제공 장치를 동작시킴으로써, 사용자의 제스처에 따라 안마 부 위 및 안마 동작의 형태가 결정될 수 있다. 본 실시 예에서 처리부는 도 4에 도시된 바와 같이 제어부 외부에 구비될 수도 있고, 제어부 내 부에 구비되어 제어부처럼 동작할 수도 있으며, 도 1의 서버 내부에 구비될 수도 있다. 이하 처리부 의 상세한 동작은 도 6을 참조하여 설명하기로 한다. 제어부는 일종의 중앙처리장치로서 메모리에 탑재된 제어 소프트웨어를 구동하여 커뮤니케이션 로봇 및 안마 제공 장치 전체의 동작을 제어할 수 있다. 본 실시 예에서 제어부는 사용자의 발화 음 성에 포함되는 음성 명령어에 대응하여 안마 제공 장치의 안마 모드 및 안마 옵션을 설정하고, 설정한 안 마 모드에 따라 안마 제공 장치가 동작하도록 제어할 수 있다. 이를 위해 메모리에는 음성 인식 알고리즘이 저장될 수 있고, 안마 제공 장치를 구동시킬 수 있는 기 동어가 저장되어 있어서, 사용자가 기동어를 발화하면 제어부가 음성인식부를 동작시키고, 음성인식 부가 이를 인식하여 비활성화 상태였던 커뮤니케이션 로봇을 활성화 상태로 변경할 수 있다. 커뮤니 케이션 로봇이 활성화 상태로 변경된 후, 제어부는 음성 인식 마이크 홀을 통하여 사용자로부터 음성 명령을 인식하고, 음성 명령에 대응하여 커뮤니케이션 로봇 및 안마 제공 장치의 동작을 제어할 수 있다. 본 실시 예에서 음성인식부는 제어부 외부에 독립적으로 구비될 수 있고, 처리부 내부에 포함될 수도 있다. 또한 도 4에 도시된 제어부 외부의 음성인식부는 음성을 획득하기 위한 음성 입력 수단만을 의미하고 음성인식부로부터 획득된 음성의 음성 인식을 수행하는 음성 인식 처리 수단은 처리부 내부에 포함될 수도 있다. 제어부는 설정한 안마 모드에 따라 안마 제공 장치의 안마구동부, 에어조절부, 온도조절부 및 본체구동부 중 하나 이상을 제어할 수 있다. 또한 제어부는 안마 제공 장치의 동작과 관련하여 안마 부위를 안마하는 사용자의 제스처 영상에 대응하여 안마 모드를 설정하고, 설정한 안마 모드에 따라 안마 제공 장치가 동작하도록 제어할 수 있다. 그리고 제어부는 사용자의 발화 음성으로부터 사 용자의 발화 방향을 추적하여 사용자의 발화 방향으로 커뮤니케이션 로봇의 방향이 전환되도록 할 수 있다. 또한 제어부는 사용자의 영상으로부터 얼굴 방향을 산출하여 사용자의 얼굴 방향으로 커뮤니케이션 로봇의 방향을 전환할 수 있다. 또한, 선택적 실시 예로, 제어부는 사용자의 수동 조작 신호 및 생체인식부를 통해 감지한 사용자 정 보에 기초하여 사용자의 선호도를 분석하며, 사용자의 선호도를 분석한 결과를 기반으로 사용자 맞춤형 안마 모 드를 추천할 수 있다. 또한 제어부는 사용자의 선호도를 분석한 결과와 기상 정보를 기반으로 하여 사용자 맞춤형 안마 모드를 추천할 수 있다. 여기서, 제어부는 프로세서(processor)와 같이 데이터를 처리할 수 있는 모든 종류의 장치를 포함할 수 있 다. 여기서, '프로세서(processor)'는, 예를 들어 프로그램 내에 포함된 코드 또는 명령으로 표현된 기능을 수 행하기 위해 물리적으로 구조화된 회로를 갖는, 하드웨어에 내장된 데이터 처리 장치를 의미할 수 있다. 이와 같이 하드웨어에 내장된 데이터 처리 장치의 일 예로써, 마이크로프로세서(microprocessor), 중앙처리장치 (central processing unit: CPU), 프로세서 코어(processor core), 멀티프로세서(multiprocessor), ASIC(application-specific integrated circuit), FPGA(field programmable gate array) 등의 처리 장치를 망 라할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 본 실시 예에서 제어부는 사용자의 발화 방향 추적, 음성 명령어 획득, 음성 명령어에 대응하는 커뮤니케 이션 로봇 및 안마 제공 장치의 동작(안마 이외의 동작 모드도 포함될 수 있음), 사용자 제스처 영상 에 대응하는 커뮤니케이션 로봇 및 안마 제공 장치의 동작(안마 이외의 동작 모드도 포함될 수 있음)및 사용자 맞춤 안마 모드 추천에 대하여 딥러닝(Deep Learning) 등 머신 러닝(machine learning)을 수행할 수 있고, 메모리는, 머신 러닝에 사용되는 데이터, 결과 데이터 등을 저장할 수 있다. 머신 러닝의 일종인 딥러닝(deep learning) 기술은 데이터를 기반으로 다단계로 깊은 수준까지 내려가 학습할 수 있다. 딥러닝은 단계를 높여갈수록 복수의 데이터들로부터 핵심적인 데이터를 추출하는 머신 러닝 알고리즘 의 집합을 나타낼 수 있다. 딥러닝 구조는 인공신경망(ANN)을 포함할 수 있으며, 예를 들어 딥러닝 구조는 CNN(convolutional neural network), RNN(recurrent neural network), DBN(deep belief network) 등 심층신경망(DNN)으로 구성될 수 있다. 본 실시 예에 따른 딥러닝 구조는 공지된 다양한 구조를 이용할 수 있다. 예를 들어, 본 발명에 따른 딥 러닝 구조는 CNN, RNN, DBN 등을 포함할 수 있다. RNN은, 자연어 처리 등에 많이 이용되고 있으며, 시간의 흐름 에 따라 변하는 시계열 데이터(time-series data) 처리에 효과적인 구조로 매 순간마다 레이어를 쌓아올려 인공 신경망 구조를 구성할 수 있다. DBN은 딥러닝 기법인 RBM(restricted boltzman machine)을 다층으로 쌓아 구성 되는 딥러닝 구조를 포함할 수 있다. RBM 학습을 반복하여, 일정 수의 레이어가 되면 해당 개수의 레이어를 가 지는 DBN을 구성할 수 있다. CNN은 사람이 물체를 인식할 때 물체의 기본적인 특징들을 추출한 다음 뇌 속에서 복잡한 계산을 거쳐 그 결과를 기반으로 물체를 인식한다는 가정을 기반으로 만들어진 사람의 뇌 기능을 모사한 모델을 포함할 수 있다. 한편, 인공신경망의 학습은 주어진 입력에 대하여 원하는 출력이 나오도록 노드간 연결선의 웨이트(weight)를 조정(필요한 경우 바이어스(bias) 값도 조정)함으로써 이루어질 수 있다. 또한, 인공신경망은 학습에 의해 웨이 트(weight) 값을 지속적으로 업데이트시킬 수 있다. 또한, 인공신경망의 학습에는 역전파(back propagation) 등 의 방법이 사용될 수 있다. 즉 커뮤니케이션 로봇에는 인공신경망(artificial neural network)이 탑재될 수 있으며, 즉 제어부 는 인공신경망, 예를 들어, CNN, RNN, DBN 등 심층신경망(deep neural network: DNN)을 포함할 수 있다. 따라 서 제어부는 사용자의 발화 방향 추적, 음성 명령어 획득, 음성 명령어에 대응하는 커뮤니케이션 로봇 및 안마 제공 장치의 동작(안마 이외의 동작 모드도 포함될 수 있음), 사용자 제스처 영상에 대응하 는 커뮤니케이션 로봇 및 안마 제공 장치의 동작(안마 이외의 동작 모드도 포함될 수 있음) 및 사용 자 맞춤 안마 모드 추천을 위해 심층신경망을 학습할 수 있다. 이러한 인공신경망의 머신 러닝 방법으로는 자율 학습(unsupervised learning)과 지도학습(supervised learning)이 모두 사용될 수 있다. 제어부는 설정에 따라 학습 후 인공신경망 구조를 업데이트시키도록 제어할 수 있다. 도 6은 도 4의 커뮤니케이션 로봇 중 처리부의 개략적인 블록도이다. 이하의 설명에서 도 1 내지 도 5에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 6을 참조하면, 처리부는 제1 획득부, 제2 획 득부, 분석부, 제1 동작 제어부, 제2 동작 제어부, 사용자정보 획득부, 사용자 분석 부, 수집부 및 제공부를 포함할 수 있다. 제1 획득부는 안마 제공 장치로부터 기설정된 범위 내에 위치한 사용자의 발화 음성을 획득하고, 안 마 제공 장치의 동작과 관련하여 발화 음성에 포함되는 음성 명령어를 획득할 수 있다. 여기서 발화 음성 은 기동어와 사용자 명령어를 포함할 수 있다. 기동어는 커뮤니케이션 로봇의 음성 인식 기능을 활성화 시 키는 특정 명렁어로서, 웨이크업 워드(wake-up word)로 명명될 수 있다. 발화 음성에 기동어가 포함되어 있어야 음성 인식 기능이 활성화 될 수 있고, 발화 음성에 기동어가 포함되어 있지 않은 경우 음성 인식 기능이 비활성 화(예를 들어, 슬립 모드) 상태를 유지할 수 있다. 이러한 기동어는 기설정되어 메모리(도 4의 270)에 저장될 수 있다. 또한 음성 명령어는 안마 제공 장치 및/또는 커뮤니케이션 로봇이 실질적으로 처리하여 출 력을 생성할 수 있는 음성일 수 있다. 예를 들어, 사용자의 발화 음성이 하이 엘지 어깨를 마사지 해줘인 경우, 기동어는 하이 엘지일 수 있고, 음성 명령어는 어깨를 마사지 해줘일 수 있다. 즉, 제1 획득부는 기설정된 기동어 및 음성 명령어를 포함하는 발화 음성 중 기동어를 발화한 음성을 획득한 후 음성 명령어를 획득할 수 있다. 다만, 본 실시 예에서는, 생체인식부(도 4의 235)를 통해 사용자가 안마 제공 장치에 착석한 것을 감지하거나, 지문이 인식된 경우, 기동어 없이 커뮤니케이션 로봇의 음성 인식 기능이 활성화될 수도 있다. 한편, 본 실시 예에서 음성 인식 기능 활성화에 따른 음성 인식 처리 과정은, 음성인식부(도 4의 231) 또는 제1 획득부에서 수행될 수 있다. 또한 음성인식부 및 제1 획득부에서 음성 수집만 수행하는 경우에는 분 석부에서 음성 인식 처리 과정이 수행될 수도 있다. 예를 들어, 음성 인식 처리 과정은, 음성 인식 마이크 홀을 통해 입력되는 발화 음성을 분석하고, 분석 결과에 대응하는 음성 인식 결과를 출력하는 과정을 포함할 수있다. 본 실시 예에서는 자동 음성 인식부(ASR(auto speech recognition) unit)(미도시), 자연어 이해부 (natural language understanding unit)(미도시), 자연어 생성부(natural language generating unit)(미도시) 및 텍스트-음성 변환부(TTS(text-to-speech) unit)(미도시)를 포함하여 음성 인식 처리를 수행할 수 있다. 자동 음성 인식부는 음성 인식 마이크 홀을 통해 입력된 발화 음성을 텍스트로 변환할 수 있다. 예를 들어, 자동 음 성 인식부는 발화 인식부(미도시)를 포함할 수 있다. 발화 인식부는 음향(acoustic) 모델 및 언어(language) 모델을 포함할 수 있다. 예를 들어, 음향 모델은 발성에 관련된 정보를 포함할 수 있고, 언어 모델은 단위 음 소 정보 및 단위 음소 정보의 조합에 대한 정보를 포함할 수 있다. 발화 인식부는 발성에 관련된 정보 및 단위 음소 정보에 대한 정보를 이용하여 발화 음성을 텍스트로 변환할 수 있다. 음향 모델 및 언어 모델에 대한 정 보는, 예를 들어, 자동 음성 인식부 내의 자동 음성 인식 데이터베이스(미도시)에 저장될 수 있다. 자연어 이해부는 자동 음성 인식부에서 출력되는 텍스트에 대하여, 문법적 분석(syntactic analyze) 또는 의미 적 분석(semantic analyze)을 수행하여 발화 음성의 발화 의도를 파악할 수 있다. 여기서, 문법적 분석은 전처 리 텍스트를 문법적 단위(예: 단어, 구, 형태소 등)로 나누고, 나누어진 단위가 어떤 문법적인 요소를 갖는지 파악할 수 있다. 또한 의미적 분석은 의미(semantic) 매칭, 룰(rule) 매칭, 포뮬러(formula) 매칭 등을 이용하 여 수행할 수 있다. 이에 따라, 자연어 이해부는 전처리 텍스트가 어떤 의도(intent)인지 또는 이러한 의도를 표현하는데 필요한 파라미터(parameter)를 얻을 수 있다. 자연어 생성부는 발화 음성의 발화 의도를 반영한 텍 스트를 자연어 발화 형태의 텍스트로 생성할 수 있다. 텍스트 음성 변환부는 자연어 생성부가 생성한 자연어 발 화 형태의 텍스트를 음성 정보로 변환하여 오디오 출력부를 통하여 출력하거나 처리부 및/또는 제어부 에 제공할 수 있다. 제2 획득부는 안마 제공 장치로부터 기설정된 범위 내에 위치한 사용자의 영상을 획득할 수 있다. 또 한 제2 획득부는 안마 제공 장치의 동작과 관련하여 안마 부위를 안마하는 사용자의 제스처 영상을 획득할 수 있다. 특히 제2 획득부는 안마 제공 장치로부터 기설정된 범위의 영상에서 사용자 얼굴 영 역 영상을 획득할 수 있다. 예를 들어, 제2 획득부는 안마 제공 장치로부터 기설정된 범위의 영상에 서 조명을 보정하고 피부색 영역을 검출하여 얼굴 영역을 1차로 추정하고, 눈/입 영역 검출 결과를 통해 얼굴 영역을 확정할 수 있다. 또한 제2 획득부는 안마 제공 장치로부터 기설정된 범위의 영상에서 손의 색 깔, 형태, 밝기 등의 특징점으로 손을 인식한 후, 손의 형태 구분 및 모델링을 통해 손 형태를 검출할 수 있다. 즉 제스처 영상은 손의 위치(좌표), 손의 형태 및 손이 움직이는 이동궤적(동작)에 대한 영상을 포함할 수 있고, 손의 형태는 신체의 골격과 관절점, 가위, 바위, 보와 같이 손가락 일부를 구부리거나 편 형태를 포함할 수 있다. 또한 손의 위치는 안마 제공 장치를 통해 안마 가능한 신체 부위 위치를 포함할 수 있다. 한편, 본 실시 예에서는 제1 획득부를 통해 먼저 사용자의 발화 음성을 획득하고, 제2 획득부를 통해 사용자의 영상을 획득할 수 있으나, 순서를 상술한 내용으로 한정하지는 않는다. 또한, 본 실시 예에서는 제1 획득부를 통해 먼저 기설정된 기동어 및 음성 명령어를 포함하는 발화 음성 중 기동어를 발화한 음성을 획 득한 후, 사용자의 제스처 영상을 획득할 수 있으나, 순서를 상술한 내용으로 한정하지는 않는다. 분석부는 제1 획득부에서 획득한 사용자 발화 음성으로부터 사용자의 발화 방향을 추적할 수 있다. 예를 들어, 분석부는 복수 개의 음성 인식 마이크 홀을 이용하여 사용자 발화 음성의 방향을 탐지하고 추 적할 수 있다. 예를 들어, 2개의 음성 인식 마이크 홀에 도착하는 신호의 차(Time Difference)를 이용하여, 사 용자 발화 음성의 방향을 추정할 수 있다. 그리고 분석부는 제2 획득부에서 획득한 사용자 영상으로부터 얼굴 방향을 산출할 수 있다. 즉 분석 부는 제2 획득부로부터의 사용자 얼굴 영역 영상을 통해 사용자의 얼굴 방향을 산출할 수 있다. 이때 영상인식부(도 4의 233) 및 제2 획득부에서 영상 수집만 수행하는 경우에는, 분석부에서 사용자 얼굴 영역 산출 처리 과정이 수행될 수 있다. 또한 분석부는 제2 획득부에서 획득한 사용자 제스처 영상으 로부터 커뮤니케이션 로봇 및/또는 안마 제공 장치의 동작 제어를 위해 기설정된 제스처 정보에 대응 되는 제스처를 분석할 수 있다. 예를 들어, 분석부는 제2 획득부를 통해 사용자가 어깨를 두드리는 제스처를 획득한 경우, 어깨 부위 안마 수행에 대응되는 제스처라고 분석할 수 있다. 이때, 커뮤니케이션 로봇 및/또는 안마 제공 장치의 동작 제어를 위한 기설정된 제스처 정보는 메모리(도 4의 270)에 저장될 수 있고, 사용자의 입력에 의해 업데이트될 수 있다. 제1 동작 제어부는 커뮤니케이션 로봇의 방향 전환을 제어하는 것으로, 분석부가 추적한 사용자 의 발화 방향으로 커뮤니케이션 로봇의 방향을 전환할 수 있다. 즉 제1 동작 제어부는 사용자의 발화 방향으로 커뮤니케이션 로봇의 시선 방향을 전환할 수 있다. 또한 제1 동작 제어부는 커뮤니케이션로봇의 시선이 음성 명령어에 포함되는 안마 부위를 쳐다보도록 제어할 수 있다. 이때, 제1 동작 제어부 는 커뮤니케이션 로봇의 시선이 안마 부위를 향하는 시간이 일정 시간을 경과하면, 커뮤니케이션 로 봇의 시선을 원상 복귀 하도록 제어할 수 있다. 또한 제1 동작 제어부는, 커뮤니케이션 로봇의 시선이 음성 명령어에 포함되는 안마 부위를 쳐다보도 록 제어한 이후에, 커뮤니케이션 로봇의 시선과 동일한 방향을 향하도록 배치된 카메라를 통해 획득한 영 상을 분석할 수 있다. 그리고 제1 동작 제어부는 카메라를 통해 획득한 영상을 분석하여 안마 부위가 감지 되는지 판단할 수 있다. 또한 제1 동작 제어부는 획득된 영상으로부터 안마 부위가 감지되지 않으면 알람 을 발생시킬 수 있다. 이때 제1 동작 제어부는 오디오 출력부를 통해 알람을 발생시킬 수 있다. 예를 들어, 사용자가 다리 부위의 안마를 요청한 경우, 제1 동작 제어부는 커뮤니케이션 로봇의 시선이 다 리 부위를 쳐다보도록 제어한 이후에, 다리 부위에 사용자의 다리가 감지되지 않으면, 소리나 진동 등을 통한 알람을 발생시켜 사용자가 요청한 안마 부위에 제대로 착석하여 위치할 수 있도록 알려줄 수 있다. 이때, 객체 인식을 위한 영상 분석 알고리즘 등의 공지 기술을 이용하여 영상에서 신체 부위를 검출하여 안마 부위 감지 여 부를 판단할 수 있으며, 구체적으로 한정되지 않는다. 또한 제1 동작 제어부는 분석부가 산출한 사용자의 얼굴 방향으로 커뮤니케이션 로봇의 시선을 전환할 수 있다. 이때 제1 동작 제어부는 사용자의 발화 방향으로 커뮤니케이션 로봇의 시선을 1차로 전환한 후, 사용자의 얼굴 방향으로 커뮤니케이션 로봇의 시선을 2차로 전환할 수 있다. 또한 제1 동작 제 어부는 분석부에서 사용자의 발화 방향과 얼굴 방향을 조합하여 최종 결정한 방향으로 커뮤니케이션 로봇의 시선을 전환할 수도 있다. 예를 들어, 사용자가 발바닥 강도 약하게라고 말하면, 제1 동작 제어부 는 커뮤니케이션 로봇의 시선이 발바닥 방향을 향하도록 하고, 일정 시간을 경과하면, 사용자의 방향 으로 원상 복귀 하도록 제어할 수 있다. 즉, 제1 동작 제어부는 구동부를 통해 커뮤니케이션 로봇의 시선이 사용자 또는 안마 부위를 향 할 수 있도록 할 수 있다. 또한 본 실시 예에서는 커뮤니케이션 로봇이 안마 제공 장치의 거치 수단 을 통해 거치되어 있는 경우 거치 수단이 접히거나 회전 가능하도록 구현하여, 제1 동작 제어부가 거치 수 단을 접거나 회전시켜 커뮤니케이션 로봇의 시선이 사용자 또는 안마 부위를 향하도록 할 수 있다. 제2 동작 제어부는 안마 제공 장치를 동작시키는 것으로, 제1 획득부를 통해 획득한 음성 명령 어에 대응하여 안마 제공 장치를 동작시킬 수 있다. 즉 제2 동작 제어부는 음성 명령어에 포함되는 안마 부위의 안마를 수행하도록 안마 제공 장치를 동작시킬 수 있다. 예를 들어, 사용자가 발바닥 강도 약 하게라고 말하면, 제2 동작 제어부는 안마 제공 장치를 동작시켜 발바닥 부위의 안마가 수행되도록 할 수 있다. 이때 본 실시 예에서는, 사용자가 발바닥 강도 약하게라고 말하면, 제1 동작 제어부가 커뮤니 케이션 로봇의 시선이 발바닥 방향을 향하도록 하고, 제2 동작 제어부가 안마 제공 장치를 동작 시켜 발바닥 부위의 안마가 수행되도록 한 후, 제1 동작 제어부가 커뮤니케이션 로봇의 시선이 원상 복귀 하도록 할 수 있다. 또한 제2 동작 제어부는 제2 획득부를 통해 획득한 사용자의 제스처 영상에 대응하여 안마 제공 장 치를 동작시킬 수 있다. 예를 들어, 사용자가 어깨를 두드리는 제스처를 획득한 경우, 제2 동작 제어부 는 안마 제공 장치를 동작시켜 어깨 부위의 안마가 수행되도록 할 수 있다. 사용자정보 획득부는 영상인식부(도 4의 233) 및 생체인식부(도 4의 235)를 통해 사용자의 감정, 건강 등 의 헬스케어 정보를 획득할 수 있다. 또한 사용자정보 획득부는 사용자의 수동 조작 신호 수신에 의해 설 정한 안마 모드를 포함하는 히스토리 정보를 획득할 수 있다. 즉 사용자정보 획득부는 사용자의 안마 모드 에 대한 사용량 누적치, 사용기간 누적치 및 조작 변경 횟수 누적치 중 하나 이상을 획득할 수 있다. 예를 들어, 사용자정보 획득부는 기설정된 안마 모드가 몇 번 실행되었는지, 해당 안마 모드가 몇 시간 실행되 었는지, 기설정된 안마 모드에서 사용자가 몇 번 변경하였는지 등의 히스토리 정보를 획득할 수 있다. 또한 사 용자정보 획득부는 사용자가 컨트롤 패널을 통해 수동으로 조작하는 경우, 해당되는 안마 모드를 획 득할 수 있다. 사용자 분석부는 사용자정보 획득부가 획득한 헬스케어 정보 및 히스토리 정보를 이용하여 사용자의 선호도를 분석할 수 있다. 즉 사용자 분석부는 영상인식부 및 생체인식부를 통해 획득한 현재 사용자의 감 정, 건강 등의 헬스케어 정보 및 사용자의 수동 조작 신호 수신에 의해 설정한 안마 모드를 포함하는 히스토리 정보에 포함되는 안마 모드에 대한 사용량 누적치, 사용기간 누적치 및 조작 변경 횟수 누적치 중 하나 이상을 기준 값과 비교하여 사용자의 선호도를 분석할 수 있다. 여기서, 기준 값은 선호도 판단을 위한 기준 값을 의미하며, 설계 단계에서 기준 값이 설정되어 메모리에 저장될 수 있고, 사용자에 의해 변경될 수도 있다. 예 를 들어, 사용자 분석부는 사용자가 각각의 안마 모드를 얼마나 많이 이용하였는지, 해당 안마 모드에서 자동으로 설정한 안마 모드에서 수동으로 변경한 항목은 무엇인지, 수동으로 변경한 안마 모드를 얼마나 많이 이용하였는지 등을 분석할 수 있다. 또한 사용자 분석부는 해당 안마 모드 시 사용자의 표정이 긍정적인 표정인지, 긍정적인 신체 변화가 있는지 등을 분석할 수 있다. 이는 사용자의 선호도에 따라 각기 다른 안마 모 드를 설정하여, 개별 사용자의 만족도를 반영해야 함에 기인한 것이다. 또한 본 실시 예에서는, 사용자의 건강 상태, 안마 시 감정 상태 등을 활용함으로써, 사용자의 선호도를 보다 정확하게 분석할 수 있다. 따라서 사용자 분석부는 헬스케어 정보 및 히스토리 정보 중 적어도 하나 이상을 기반으로 사용자의 선호도를 분석함으로 써, 개개인 사용자에게 보다 최적화된 안마 모드를 학습하여 제공할 수 있도록 한다. 또한, 본 실시 예에서는 추천부(미도시)를 포함하여, 사용자 분석부로부터 사용자의 선호도 분석 결과를 수신하여 사용자 맞춤형 안마 모드를 추천할 수 있다. 사용자 맞춤형 안마 모드 추천 시에 추천부는 메모리 에 저장된 헬스케어 정보 및 히스토리 정보를 조합하여 추천할 수 있다. 추천부는 예를 들어, 사용자가 자 주 선택하는 안마 모드를 학습하여 사용자가 좋아하는 안마 스타일을 생성할 수 있다. 즉 추천부는 예를 들어, 사용자의 건강 상태가 좋지 않거나 사용자가 강도가 낮은 안마 세기를 선호하는 안마 스타일을 좋아하는 경우, 상대적으로 정적인 안마 모드를 추천할 수 있다. 또한 추천부는 사용자 맞춤형 안마 모드와 함께, 건강과 관련 한 정보도 추천할 수 있다. 또한 추천부는 표시부에 표시되는 사용자 맞춤형 안마 모드에 대하여 사용자의 피드백(예를 들어, 좋아요, 변경, 안마 실행)을 수신할 수 있고, 이는 제어부의 학습에 이용될 수 있다. 수집부는 기상 정보를 제공하는 기상서버로부터 기상 정보를 수집할 수 있다. 일 실시 예로, 수집부 는 기상서버로부터 수집한 기상 정보를 저장하고 있는 서버에 접속하여 기상 정보를 수집할 수 있다. 여기 서 기상 정보는, 과거, 현재, 미래에 대한 날씨(예를 들어, 흐림, 맑음, 비, 눈 등)와 기온(최저기온, 최고기온, 평균기온 등), 계절 정보(봄, 여름, 가을, 겨울), 미세먼지 지수, 자외선 지수, 습도 지수, 건조 지 수 등을 포함할 수 있다. 추천부는 사용자 분석부로부터의 사용자 선호도 분석 결과와, 수집부가 수 집한 기상 정보를 기반으로 사용자 맞춤형 안마 모드를 추천할 수 있다. 예를 들어, 추천부는 비 오는 날인 경 우 과거 습도가 높은 날 사용자가 선택했던 안마 모드를 추천하거나, 기온에 따라 안마 시 최적 온도를 추천할 수 있다. 또한 수집부는 건강 정보를 제공하는 건강서버로부터 건강 정보를 수집할 수 있다. 일 실시 예로, 수집부 는 건강서버로부터 수집한 건강 정보를 저장하고 있는 서버에 접속하여 건강 정보를 수집할 수 있다. 여기서 건강 정보는, 나이 및 성별에 따른 건강/질병 정보, 증상/증후 정보, 검사/처지 정보 등을 포함할 수 있 다. 추천부는 사용자 분석부로부터의 사용자 선호도 분석 결과와, 수집부가 수집한 건강 정보를 기반 으로 사용자 맞춤형 안마 모드를 추천할 수 있다. 예를 들어, 추천부는 30대 남성에게는 안마 세기가 가장 강한 안마 모드를 추천할 수 있다. 제공부는 표시부에 건강/뷰티 정보와, 음악, 뉴스 등을 제공할 수 있다. 또한 제공부는 메신저 알림, 또는 사용자가 좋아하는 음악이 재생되도록 소정의 정보를 제공할 수도 있고, 사용자의 발화 음성 예를 들어, 오늘 날씨는 어때와 같은 발화 음성에 대응하여 오늘의 날씨를 제공해 줄 수 있다. 도 7은 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 터치 제어를 설명하기 위한 예시도이고, 도 8은 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 방향 전환 동작을 설명하기 위한 예시도이다. 이하의 설명에서 도 1 내지 도 6에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 7을 참조하면, 사용자가 커뮤니케이션 로봇과 연동된 안마 제공 장치에 착석(안마 제공 장치(10 0)로부터 기설정된 범위 내에 위치)하여, 커뮤니케이션 로봇을 통해 안마 제공 장치를 동작시킬 수 있다. 즉 커뮤니케이션 로봇은 안마 제공 장치에 착석한 사용자의 발화 음성을 획득하여 발화 음성에 포함되는 음성 명령어를 획득하고, 음성 명령어에 대응하여 안마 제공 장치를 동작시킬 수 있다. 이때 본 실시 예에서는, 사용자가 표시부의 컨트롤 패널을 터치하여 안마 제공 장치의 동작이 활성화되 도록 할 수 있다. 즉 커뮤니케이션 로봇은 사용자로부터의 컨트롤 패널 터치 입력이 감지되면, 터치 입력에 대응되는 동작 모드를 수행할 수 있다. 예를 들어, 컨트롤 패널에는 안마 부위를 포함하는 사용자 신체 형상이 표시될 수 있으며, 사용자 신체 형상 중 어깨 등 사용자는 원하는 안마 부위를 터치할 수 있다. 이 때 커뮤니케이션 로봇은 안마 제공 장치가 동작되도록 하여 어깨 부위의 안마가 수행되도록 할 수 있 다. 도 8을 참조하면, 커뮤니케이션 로봇은 안마 제공 장치에 착석한 사용자의 발화 음성으로부터 사용자 의 발화 방향을 추적하고, 사용자의 발화 방향으로 커뮤니케이션 로봇의 방향을 전환할 수 있다. 예를 들 어, 사용자가 발바닥 안마 해줘라고 말하는 경우, 커뮤니케이션 로봇은 발바닥 방향으로 시선을 전환할 수 있다. 한편, 선택적 실시 예로, 안마 제공 장치 및 커뮤니케이션 로봇은 자율 주행 차량 내에 설치될 수 있 다. 이때 자율 주행 차량 내에 설치되는 안마 제공 장치는 기존 차량의 시트 내에 안마 기능을 포함할 수 있고, 일반적인 안마 의자 형태의 안마 제공 장치가 구현될 수도 있다. 또한, 선택적 실시 예로, 커뮤니케 이션 로봇은 주행 정보 및 교통 정보를 기반으로 하여 안마 모드를 추천할 수 있다. 이를 위해 커뮤니케이 션 로봇은 차량으로부터 주행 정보를 수집할 수 있고, 교통 정보를 제공하는 교통서버(미도시)로부터 교통 정보를 수집할 수 있다. 이때, 커뮤니케이션 로봇은 교통서버와 네트워크를 통하여 통신할 수 있다. 또한 안마 제공 장치 및 커뮤니케이션 로봇이 자율 주행 차량 내에 구비되는 경우, 커뮤니케이션 로 봇은 동일한 공간에 배치되어 오디오 신호 및 비디오 신호 중 적어도 하나를 출력하는 하나 이상의 출력장 치를 검색하고 선택할 수 있다. 여기서, 출력장치는 오디오 신호 및 비디오 신호 중 적어도 하나 이 상을 출력하는 전자장치로서, 예를 들어, 차량 내 스피커(미도시), AI 스피커와, 네비게이션 및 헤드 업 디스플레이(HUD, head-up display) 등의 AVN 장치(미도시) 등을 포함할 수 있다. 한편, 본 실시 예에서 수집부는 차량으로부터 주행 정보를 수집하고, 교통 정보를 제공하는 교통서버로부 터 교통 정보를 수집할 수 있다. 여기서 주행 정보는, 차량의 주행 속도, 주행 모드, 경로 안내 정보(예를 들어, 도착지까지 남은 시간) 등을 포함할 수 있다. 또한 교통 정보는, 교통 상황 정보, 차량이 주행하고 있는 외부 환경 정보 등을 포함할 수 있다. 이때, 차량이 주행하고 있는 외부 환경 정보는, 주행하고 있는 도로 정보 (고속도로, 국도, 일반도로 등)뿐만 아니라, 기상 정보(날씨, 기온, 계절 정보, 미세먼지 지수, 자외선 지수, 습도 지수, 건조 지수 등)을 포함할 수 있다. 추천부는 사용자 분석부로부터의 사용자 선호도 분석 결과와, 수집부가 수집한 주행 정보 및 교통 정보를 기반으로 사용자 맞춤형 안마 모드를 추천할 수 있다. 예를 들어, 추천부는 교통 체증이 발생한 경우 편안한 안마를 제공하기 위해 휴식 코스를 추천하거나, 반대로 교통 체증에 따른 지루함을 해소하기 위해 활력 코스를 추천할 수 있다. 도 9는 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 구동 방법을 도시한 흐름도이다. 이하의 설명에서 도 1 내지 도 8에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 9를 참조하면, S910단계에서, 커뮤니케이션 로봇은 안마 제공 장치로부터 기설정된 범위 내에 위 치한 사용자 발화 음성을 획득한다. 여기서 발화 음성은 기동어와 사용자 명령어를 포함할 수 있다. 기동어는 커뮤니케이션 로봇의 음성 인식 기능을 활성화 시키는 특정 명렁어로서, 웨이크업 워드(wake-up word)로 명명될 수 있다. 발화 음성에 기동어가 포함되어 있어야 음성 인식 기능이 활성화 될 수 있고, 발화 음성에 기 동어가 포함되어 있지 않은 경우 음성 인식 기능이 비활성화(예를 들어, 슬립 모드) 상태를 유지할 수 있다. 예 를 들어, 사용자의 발화 음성이 하이 엘지 어깨를 마사지 해줘인 경우, 기동어는 하이 엘지일 수 있다. 즉, 커 뮤니케이션 로봇은 기설정된 기동어 및 음성 명령어를 포함하는 발화 음성 중 기동어를 발화한 음성을 획 득한 후 음성 명령어를 획득할 수 있다. S920단계에서, 커뮤니케이션 로봇은 사용자 발화 음성으로부터 사용자 발화 방향을 추척한다. 커뮤니케이 션 로봇은 예를 들어, 복수 개의 음성 인식 마이크 홀을 이용하여 사용자 발화 음성의 방향을 탐지하고 추 적할 수 있다. 예를 들어, 2개의 음성 인식 마이크 홀에 도착하는 신호의 차(Time Difference)를 이용하여, 사 용자 발화 음성의 방향을 추정할 수 있다. S930단계에서, 커뮤니케이션 로봇은 사용자 발화 방향으로 커뮤니케이션 로봇의 시선을 전환한다. 커 뮤니케이션 로봇은 사용자의 발화 방향으로 커뮤니케이션 로봇의 시선 방향을 전환할 수 있다. 또한 커뮤니케이션 로봇은 커뮤니케이션 로봇의 시선이 음성 명령어에 포함되는 안마 부위를 쳐다보도록 제어할 수도 있다. 이때, 커뮤니케이션 로봇은 커뮤니케이션 로봇의 시선이 안마 부위를 향하는 시간 이 일정 시간을 경과하면, 커뮤니케이션 로봇의 방향을 원상 복귀 하도록 제어할 수 있다. 예를 들어, 사 용자가 발바닥 강도 약하게라고 말하면, 커뮤니케이션 로봇은 커뮤니케이션 로봇의 시선이 발바닥 방 향을 향하도록 하고, 일정 시간을 경과하면, 사용자의 방향으로 원상 복귀 하도록 제어할 수 있다. 여기서 커뮤 니케이션 로봇의 방향은, 커뮤니케이션 로봇의 상부(얼굴 형상 부분)만 회전하거나, 하부(몸통 형상 부분)가 회전하여 커뮤니케이션 로봇의 정면 측(시선)이 향하는 방향을 의미할 수 있다. 또한 본 실시 예 에서는 커뮤니케이션 로봇이 안마 제공 장치의 거치 수단을 통해 거치되어 있는 경우 거치 수단이 접 히거나 회전 가능하도록 구현하여, 커뮤니케이션 로봇의 시선이 사용자 또는 안마 부위를 향하도록 할 수있다. S940단계에서, 커뮤니케이션 로봇은 안마 제공 장치의 동작과 관련하여 발화 음성에 포함되는 음성 명령어를 획득한다. 음성 명령어는 안마 제공 장치 및/또는 커뮤니케이션 로봇이 실질적으로 처리하 여 출력을 생성할 수 있는 음성일 수 있다. 예를 들어, 사용자의 발화 음성이 하이 엘지 어깨를 마사지 해줘인 경우, 음성 명령어는 어깨를 마사지 해줘일 수 있다. S950단계에서, 커뮤니케이션 로봇은 음성 명령어에 대응하여 안마 제공 장치 동작을 제어할 수 있다. 즉 커뮤니케이션 로봇은 음성 명령어에 포함되는 안마 부위의 안마를 수행하도록 안마 제공 장치를 동작시킬 수 있다. 예를 들어, 사용자가 발바닥 강도 약하게라고 말하면, 커뮤니케이션 로봇은 안마 제공 장치를 동작시켜 발바닥 부위의 안마가 수행되도록 할 수 있다. 이때 본 실시 예에서, 커뮤니케이션 로봇 은 사용자가 발바닥 강도 약하게라고 말하면, 커뮤니케이션 로봇의 시선이 발바닥 방향을 향하도록 하고, 안마 제공 장치를 동작시켜 발바닥 부위의 안마가 수행되도록 한 후, 커뮤니케이션 로봇의 시 선이 원상 복귀 하도록 할 수 있다. 도 10은 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 음성 및 영상 기반 구동 방법을 도시한 흐름도이다. 이하의 설명에서 도 1 내지 도 9에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 10을 참조하면, S1010단계에서, 커뮤니케이션 로봇은 안마 제공 장치로부터 기설정된 범위 내에 위치한 사용자 발화 음성 및 영상을 획득한다. 특히 커뮤니케이션 로봇은 안마 제공 장치로부터 기설 정된 범위의 영상에서 사용자 얼굴 영역 영상을 획득할 수 있다. 예를 들어, 커뮤니케이션 로봇은 안마 제 공 장치로부터 기설정된 범위의 영상에서 조명을 보정하고 피부색 영역을 검출하여 얼굴 영역을 1차로 추 정하고, 눈/입 영역 검출 결과를 통해 얼굴 영역을 확정할 수 있다. S1020단계에서, 커뮤니케이션 로봇은 사용자 발화 음성으로부터 사용자 발화 방향을 추적하고 사용자 영상 으로부터 얼굴 방향을 산출한다. 커뮤니케이션 로봇은 사용자 얼굴 영역 영상을 통해 사용자의 얼굴 방향 을 산출할 수 있다. S1030단계에서, 커뮤니케이션 로봇은 사용자 발화 방향 및 얼굴 방향으로 커뮤니케이션 로봇의 시선 을 전환한다. 이때 커뮤니케이션 로봇은 사용자의 발화 방향으로 커뮤니케이션 로봇의 시선을 1차로 전환한 후, 사용자의 얼굴 방향으로 커뮤니케이션 로봇의 시선을 2차로 전환할 수 있다. 또한 커뮤니케이 션 로봇은 사용자의 발화 방향과 얼굴 방향을 조합하여 최종 결정한 방향으로 커뮤니케이션 로봇의 시선을 전환할 수 있다. 그리고 커뮤니케이션 로봇은 안마 제공 장치의 동작과 관련하여 발화 음성에 포함되는 음성 명령어를 획득하고, 음성 명령어에 대응하여 안마 제공 장치 동작을 제어할 수 있다. 도 11은 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 사용자 제스처 기반 구동 방법을 도시한 흐름도이다. 이하의 설명에서 도 1 내지 도 10에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 11을 참조하면, S1110단계에서, 커뮤니케이션 로봇은 안마 제공 장치로부터 기설정된 범위 내에 위치한 사용자 발화 음성을 획득한다. S1120단계에서, 커뮤니케이션 로봇은 안마 제공 장치의 동작과 관련하여 안마 부위를 안마하는 사용 자 제스처 영상을 획득한다. 커뮤니케이션 로봇은 안마 제공 장치로부터 기설정된 범위의 영상에서 손의 색깔, 형태, 밝기 등의 특징점으로 손을 인식한 후, 손의 형태 구분 및 모델링을 통해 손 형태를 검출할 수 있다. 즉 제스처 영상은 손의 위치(좌표), 손의 형태 및 손이 움직이는 이동궤적(동작)에 대한 영상을 포함 할 수 있고, 손의 형태는 신체의 골격과 관절점, 가위, 바위, 보와 같이 손가락 일부를 구부리거나 편 형태를 포함할 수 있다. 또한 손의 위치는 안마 제공 장치를 통해 안마 가능한 신체 부위 위치를 포함할 수 있다. S1130단계에서, 커뮤니케이션 로봇은 사용자 제스처 영상에 대응하여 안마 제공 장치의 동작을 제어 한다. 즉 커뮤니케이션 로봇은 사용자 제스처 영상으로부터 커뮤니케이션 로봇 및/또는 안마 제공 장 치의 동작 제어를 위해 기설정된 제스처 정보에 대응되는 제스처를 분석하고, 안마 제공 장치의 동작 을 제어할 수 있다. 예를 들어, 커뮤니케이션 로봇은 사용자가 어깨를 두드리는 제스처를 획득한 경우, 어 깨 부위 안마 수행에 대응되는 제스처라고 분석하고, 안마 제공 장치를 동작시켜 어깨 부위의 안마가 수행 되도록 할 수 있다. 이때, 커뮤니케이션 로봇 및/또는 안마 제공 장치의 동작 제어를 위한 기설정된 제스처 정보는 메모리(도 4의 270)에 저장될 수 있고, 사용자의 입력에 의해 업데이트될 수 있다. 이상 설명된 본 발명에 따른 실시 예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그 램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이 때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명의 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 발명의 명세서(특히 특허청구범위에서)에서 상기의 용어 및 이와 유사한 지시 용어의 사용은 단수 및 복수 모두에 해당하는 것일 수 있다. 또한, 본 발명에서 범위(range)를 기재한 경우 상기 범위에 속하는 개별적인 값 을 적용한 발명을 포함하는 것으로서(이에 반하는 기재가 없다면), 발명의 상세한 설명에 상기 범위를 구성하는 각 개별적인 값을 기재한 것과 같다. 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 발명이 한정되는 것은 아니 다. 본 발명에서 모든 예들 또는 예시적인 용어(예를 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위 가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한 다고 할 것이다."}
{"patent_id": "10-2019-0082619", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 안마 제공 장치, 커뮤니케이션 로봇, 출력장치, 사용자 단말기, 서버 및 이들을 서로 연결하는 네트워크를 포함하는 안마 제공 환경의 예시도이다. 도 2는 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 외관을 개략적으로 설명하기 위하여 도시한 도면이다. 도 3은 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 기구적 구조를 개략적으로 설명하기 위하여 도시한 도면이다. 도 4는 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 개략적인 블록도이다. 도 5는 도 4의 커뮤니케이션 로봇 중 표시부에 표시되는 컨트롤 패널을 도시한 예시도이다. 도 6은 도 4의 커뮤니케이션 로봇 중 처리부의 개략적인 블록도이다. 도 7은 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 터치 제어를 설명하기 위한 예시도이다. 도 8은 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 방향 전환 동작을 설명하기 위한 예시도이다. 도 9는 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 구동 방법을 도시한 흐름도이다. 도 10은 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 음성 및 영상 기반 구동 방법을 도시한 흐름도이다. 도 11은 본 발명의 일 실시 예에 따른 커뮤니케이션 로봇의 사용자 제스처 기반 구동 방법을 도시한 흐름도이다."}
