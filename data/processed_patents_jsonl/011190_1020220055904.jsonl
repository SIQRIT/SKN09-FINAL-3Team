{"patent_id": "10-2022-0055904", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0156482", "출원번호": "10-2022-0055904", "발명의 명칭": "음성으로부터 감정 상태를 추론하는 신경망 기반의 감정 상태 추론 장치 및 방법", "출원인": "주식회사 위스타", "발명자": "조정권"}}
{"patent_id": "10-2022-0055904", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 데이터로부터 복수의 특징벡터를 추출하는 전처리부;상기 복수의 특징벡터를 입력받아서 감정 추론값을 출력하는 신경망 회로; 및상기 감정 추론값에 기초하여 음성 데이터에 내재된 감정을 판단하는 감정 판단부를 구비하는, 음성으로부터 감정 상태를 추론하는 신경망 기반의 감정 상태 추론 장치."}
{"patent_id": "10-2022-0055904", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 감정 추론값은 제1감정에 대한 추론값, 정상감정에 대한 추론값, 제2감정에 대한 추론값을 포함하며, 상기 신경망 회로는 제1감정 상태, 정상 감정 상태, 제2감정 상태 중의 어느 하나의 감정 상태의 음성 데이터를 학습 데이터로 사용하여 학습된 것인, 신경망 기반의 감정 상태 추론 장치."}
{"patent_id": "10-2022-0055904", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,감정 추론은 음성 데이터를 소정 구간으로 분할하여 이루어지며,상기 분할된 감정 추론 대상 구간은 일부분씩 중복되는, 신경망 기반의 감정 상태 추론 장치."}
{"patent_id": "10-2022-0055904", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 감정판단부는,최초의 제1 기간의 음성 구간에 대한 추론값으로부터 초기 감정상태값을 설정하되, 제1감정에 대한 추론값, 제2감정에 대한 추론값, 그리고 정상 감정에 대한 추론값 중에서 가장 높은 추론값을 갖는 감정 상태의 기본 점수를 초기 감정상태값으로 설정하여 출력하고,이후 제2 기간마다 직전의 상기 제1 기간의 음성 데이터에 대한 신경망 회로의 추론값으로부터 가장 높은 추론값을 갖는 감정 상태를 파악하고, 그에 따라 감정상태를 1단계씩 단계를 조정하여 출력하는,신경망 기반의 감정 상태 추론 장치."}
{"patent_id": "10-2022-0055904", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 음성 데이터는 음성 구간과 비음성 구간을 포함하며,상기 신경망 회로는 음성 구간의 음성 데이터를 학습 데이터로 사용하여 학습되어 있어서, 입력되는 음성 데이터가 음성 구간인지 여부를 나타내는 추론값(이하, 'VAD값'이라 함)을 출력하며,상기 감정판단부는 VAD값이 소정의 임계치 이상인 경우에만 감정 상태를 판단하는, 신경망 기반의 감정 상태 추론 장치.공개특허 10-2023-0156482-3-청구항 6 제1항 내지 제5항 중 어느 한 항에 있어서,음성 데이터로부터 음향신호가 포함된 구간을 분리하여 상기 전처리부로 출력하는 음향구간 분리부를 더 구비하는, 신경망 기반의 감정 상태 추론 장치."}
{"patent_id": "10-2022-0055904", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 음향구간 분리부는, 음성 데이터에 소정 시간 이상 음향신호가 포함된 것으로 판정되는 경우에만 음향신호가 포함된 구간을 분리하는, 신경망 기반의 감정 상태 추론 장치."}
{"patent_id": "10-2022-0055904", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제5항 중 어느 한 항에 있어서,상기 특징벡터는 스펙트로그램(Spectrogram), 공분산(Covariance), 스펙트럴 센트로이드(Spectral Centroid)중의 적어도 어느 하나를 포함하는, 신경망 기반의 감정 상태 추론 장치."}
{"patent_id": "10-2022-0055904", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "음성 구간과 비음성 구간을 포함하는 음성 데이터에 기초하여 감정을 판단하는 방법으로서,음성 데이터로부터 복수의 특징벡터를 추출하는 전처리 단계;신경망 회로에서 상기 복수의 특징벡터에 대한 감정 추론값을 추론하는 감정 추론 단계;상기 감정 추론값을 사용하여 해당 음성구간에 내재된 감정을 판단하고 그 결과를 표시하는 감정판단 단계를 구비하는 음성으로부터 감정 상태를 추론하는 신경망 기반의 감정 상태 추론 방법."}
{"patent_id": "10-2022-0055904", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 감정 추론값은 제1감정에 대한 추론값, 정상감정에 대한 추론값, 제2감정에 대한 추론값을 포함하며, 상기 신경망 회로는 제1감정 상태, 정상 감정 상태, 제2감정 상태 중의 어느 하나의 감정 상태의 음성 데이터를 학습 데이터로 사용하여 학습된 것인, 신경망 기반의 감정 상태 추론 방법."}
{"patent_id": "10-2022-0055904", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,감정 추론은 음성 데이터를 소정 구간으로 분할하여 이루어지며,상기 분할된 감정 추론 대상 구간은 일부분씩 중복되는, 신경망 기반의 감정 상태 추론 방법."}
{"patent_id": "10-2022-0055904", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2023-0156482-4-제11항에 있어서, 상기 감정 판단 단계는,최초의 제1 기간의 음성 구간에 대한 추론값으로부터 초기 감정상태값을 설정하되, 제1감정에 대한 추론값, 제2감정에 대한 추론값, 그리고 정상 감정에 대한 추론값 중에서 가장 높은 추론값을 갖는 감정 상태의 기본 점수를 초기 감정상태값으로 설정하여 출력하는 단계와,이후 제2 기간마다 직전의 상기 제1 기간의 음성 데이터에 대한 신경망 회로의 추론값으로부터 가장 높은 추론값을 갖는 감정 상태를 파악하고, 그에 따라 감정상태를 1단계씩 단계를 조정하여 출력하는 단계를 포함하는, 신경망 기반의 감정 상태 추론 방법."}
{"patent_id": "10-2022-0055904", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 감정 추론 단계에서, 상기 신경망 회로는 음성 구간의 음성 데이터를 학습 데이터로 사용하여 학습되어 있어서, 입력되는 음성 데이터가 음성 구간인지 여부를 나타내는 추론값(이하, 'VAD값'이라 함)을 출력하며,상기 감정 판단 단계는 VAD값이 소정의 임계치 이상인 경우에만 수행되는, 신경망 기반의 감정 상태 추론 방법."}
{"patent_id": "10-2022-0055904", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항 내지 제13항 중 어느 한 항에 있어서, 상기 전처리 단계 이전에,음성 데이터로부터 음향신호가 소정 시간 이상 포함된 구간을 분리하여 출력하는 음향구간 분리단계를 더 구비하는, 신경망 기반의 감정 상태 추론 방법."}
{"patent_id": "10-2022-0055904", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항 내지 제13항 중 어느 한 항에 있어서, 상기 특징벡터는 스펙트로그램(Spectrogram), 공분산(Covariance), 스펙트럴 센트로이드(Spectral Centroid)중의 적어도 어느 하나를 포함하는, 신경망 기반의 감정 상태 추론 방법."}
{"patent_id": "10-2022-0055904", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "음성으로부터 감정 상태를 추론하는 신경망 기반의 감정 상태 추론 장치 및 방법이 제공된다. 본 발명의 바람직 한 실시예에 따른 음성으로부터 감정 상태를 추론하는 신경망 기반의 감정 상태 추론 장치는, 음성 데이터로부터 복수의 특징벡터를 추출하는 전처리부; 상기 복수의 특징벡터를 입력받아서 감정 추론값을 출력하는 신경망 회로; 및 상기 감정 추론값에 기초하여 음성 데이터에 내재된 감정을 판단하는 감정 판단부를 구비한다. 특징벡 터로는 스펙트로그램(Spectrogram), 공분산(Covariance), 스펙트럴 센트로이드(Spectral Centroid) 중의 적어도 어느 하나가 포함된다."}
{"patent_id": "10-2022-0055904", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음성으로부터 감정 상태를 추론하는 신경망 기반의 감정 상태 추론 장치 및 방법에 관한 것으로서, 경기도 기술개발 사업(연구과제명: RNN AI 기반의 빔포머 및 잡음제거 칩 모듈 개발, 과제고유번호: F2121003, 과제관리기관: (재)경기도경제과학진흥원)의 연구로부터 도출된 것이다."}
{"patent_id": "10-2022-0055904", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사람의 감정은 목소리에 반영된다. 때문에 얼굴을 보지 않고 전화통화를 하는 경우에도 상대방의 목소리로부터 상대방의 감정을 추측할 수 있다. 한편, 인공지능 기술이 발전하면서 인공지능과 목소리로 통화하는 경우가 많 아지고 있다. 그런데 단순히 정해진 루틴의 대화를 하는 것뿐만 아니라 상대방의 감정을 추측하여 그에 대한 대 응을 할 필요가 있다. 따라서, 음성으로부터 화자의 감정을 추측하려는 많은 시도가 있다. 예를 들면, 등록특허 제10-2148372호에서는 복수의 구간으로 분할된 음성 데이터의 구간 각각에 대한 음성 특징 벡터에 대응하는 복수의 인공신경망 출력값의 평균값에 대한 전연결 레이어의 출력값을 기반으로 하여 음성 데 이터에 대한 감정을 인식하도록 구성하고 있다. 등록특허 제10-2299455호에서는 음성분석을 통한 감정분석 결과 와 문맥분석을 통해 감정분석 결과를 조합하여 감정 분석을 하고 있다. 등록특허 제10-2295860호에서는, 딥러닝 네트워크를 통하여 감정이 잘 드러나는 음성 구간과 주파수 영역에 집중시키거나, 감정을 잘 구분하는 네트워크내부 채널에 집중하여 음성으로부터 감정을 인식하고 있다. 그러나, 이들 방법은 감정의 변화를 감지하는데는 적용하기가 어렵다. 또한, 음성의 감정을 인식하기까지 여러 구간의 평균값을 이용하거나 문맥을 이용하는 등, 실시간 처리가 어려운 문제가 있다."}
{"patent_id": "10-2022-0055904", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 이러한 점을 감안하여 이루어진 것으로서, 화자의 음성으로부터 화자의 감정을 추론하는 방법을 제공 하는 것을 목적으로 한다. 본 발명의 다른 목적은 음성으로부터 감정의 변화를 추론하는 방법을 제공하는 것이다. 본 발명의 다른 목적은 시간에 따른 감정의 변화를 시각화하여 보여주는 방법을 제공하는 것이다. 본 발명 의 다른 목적은 음성에 담긴 감정을 실시간으로 추론하는 방법을 제공하는 것이다."}
{"patent_id": "10-2022-0055904", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 바람직한 실시예에 따른 음성으로부터 감정 상태를 추론하는 신경망 기반의 감정 상태 추론 장치는, 음성 데이터로부터 복수의 특징벡터를 추출하는 전처리부; 상기 복수의 특징벡터를 입력받아서 감정 추론값을 출력하는 신경망 회로; 및 상기 감정 추론값에 기초하여 음성 데이터에 내재된 감정을 판단하는 감정 판단부를 구비한다. 본 발명의 바람직한 실시예에 따른 음성으로부터 감정 상태를 추론하는 신경망 기반의 감정 상태 추론 방법은, 음성 구간과 비음성 구간을 포함하는 음성 데이터에 기초하여 감정을 판단하는 방법으로서, 음성 데이터로부터 복수의 특징벡터를 추출하는 전처리 단계; 신경망 회로에서 상기 복수의 특징벡터에 대한 감정 추론값을 추론하 는 감정 추론 단계; 및 상기 감정 추론값을 사용하여 해당 음성구간에 내재된 감정을 판단하고 그 결과를 표시 하는 감정판단 단계를 구비한다. 상기 감정 추론값은 제1감정에 대한 추론값, 정상감정에 대한 추론값, 제2감정에 대한 추론값을 포함할 수 있다. 신경망 회로는 제1감정 상태, 정상 감정 상태, 제2감정 상태 중의 어느 하나의 감정 상태의 음성 데이터 를 학습 데이터로 사용하여 학습되어, 복수의 특징벡터를 입력으로 하여 제1감정 상태에 대한 추론값, 정상 감 정 상태에 대한 추론값, 제2감정 상태에 대한 추론값을 출력한다. 바람직할 실시예에서, 감정 추론은 음성 데이터를 소정 구간으로 분할하여 이루어진다. 분할된 감정 추론 대상 구간은 일부분씩 중복될 수 있다. 예를 들면, 감정 추론은 2초 구간의 음성 데이터를 대상으로 수행하되, 다음 감정 추론의 대상과 1초만큼 중복될 수 있다. 일 실시예에서, 감정판단부는, 최초의 제1 기간의 음성 구간에 대한 추론값으로부터 초기 감정상태값을 설정하 되, 제1감정에 대한 추론값, 제2감정에 대한 추론값, 그리고 정상 감정에 대한 추론값 중에서 가장 높은 추론값 을 갖는 감정 상태의 기본 점수를 초기 감정상태값으로 설정하여 출력하고, 이후 제2 기간마다 직전의 상기 제1 기간의 음성 데이터에 대한 신경망 회로의 추론값으로부터 가장 높은 추론값을 갖는 감정 상태를 파악하고, 그 에 따라 감정상태를 1단계씩 단계를 조정하여 출력할 수 있다. 일 실시예에서, 신경망 회로는 음성 구간의 음성 데이터를 학습 데이터로 사용하여 학습되어 있어서, 입력되는 음성 데이터가 음성 구간인지 여부를 나타내는 추론값(이하, 'VAD값'이라 함)을 출력할 수 있다. 이 경우에 감 정판단은, VAD값이 소정의 임계치 이상인 경우에만 실행될 수 있다. 일 실시예에서, 음성 데이터로부터 음향신호가 포함된 구간을 분리하여 상기 전처리부로 출력하는 음향구간 분 리부 또는 음향구간 분리단계를 더 구비할 수 있다. 일 실시예에서, 음향구간 분리부는 음성 데이터에 소정 시 간 이상 음향신호가 포함된 것으로 판정되는 경우에만 음향신호가 포함된 구간을 분리한다. 상기 특징벡터는 스펙트로그램(Spectrogram), 공분산(Covariance), 스펙트럴 센트로이드(Spectral Centroid) 중의 적어도 어느 하나를 포함한다."}
{"patent_id": "10-2022-0055904", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 화자의 음성으로부터 화자의 감정을 추론하는 방법이 제공된다. 본 발명에 따르면 화자의 음 성으로부터 감정의 변화를 추론할 수 있다. 본 발명에 따르면 화자의 음성으로부터 감정의 변화를 추론하여 시 간에 따른 감정의 변화를 시각화하여 보여줄 수 있다. 본 발명에 따르면 음성에 담긴 감정을 실시간으로 추론할 수 있다."}
{"patent_id": "10-2022-0055904", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 바람직한 실시예를 상세히 설명한다. 도 1은 본 발명의 일 실시예에 따른 감 정 상태 추론 장치의 구성을 보여주는 블록도이다. 이하의 설명에서 \"음성 데이터\"는 전화통화, 화상회의, 상담 등의 상황에서 입력되는 오디오 신호를 디지털 신 호로 변환한 데이터를 의미하며, 화자의 목소리가 포함된 음성 구간과 화자의 목소리가 포함되지 않은 비음성 구간을 포함할 수 있다. 본 발명에서는 음성 데이터를 처리하여 화자의 감정을 추론한다. 음향구간 분리부는 음성 데이터에 음향신호가 포함되는지 감지하여 음향신호가 포함된 구간을 분리하여 출력한다. 음향신호는 화자의 목소리에 의한 것일 수도 있고, 주변 잡음에 의한 것일 수도 있다. 일 실시예에서, 음향신호의 포함 여부는 신호의 에너지가 소정의 임계치 이상인지 여부로 판단할 수 있다. 다른 실 시예에서 음향신호의 포함 여부는 통상적인 음성활동감지(Voice Activity Detection) 방법을 사용하여 판단할 수 있다. 일 실시예에서 음성 데이터를 음향구간 분리부에 입력하기 전에 잡음제거필터를 통과하도록 구성 할 수도 있다. 전처리부는 음향신호가 포함된 음성 데이터를 신경망에 입력하기 전에 전처리하는 역할을 한다. 전처리부 는 예를 들면 특징벡터를 추출하는 단계와, 추출된 특징벡터를 0에서 255 사이의 값을 갖는 정규 이미지로 변환하는 단계를 포함할 수 있다. 특징벡터로는 예를 들면 스펙트로그램(Spectrogram), 공분산(Covariance), 스 펙트럴 센트로이드(Spectral Centroid) 등이 사용될 수 있다. 특징벡터에 대해서는 후술한다. 신경망 회로는 전처리된 음성 데이터(특징벡터)를 입력받아서 감정 추론값을 출력한다. 일 실시예에서 신 경망 회로에서 출력되는 추론값은 복수의 감정에 대한 추론값일 수 있다. 예를 들면, 제1감정, 예를 들면 우울한 정도를 나타내는 추론값과, 제2감정, 예를 들면 분노의 정도를 나타내는 추론값, 정상을 나타내는 추론 값이 함께 출력될 수 있다. 일 실시예에서 신경망 회로에서 출력되는 추론값은 제1감정과 그와 반대되는 제2감정 사이의 어느 위치인지를 나타내는 추론값일 수 있다. 예를 들면, 감정 추론값은 기쁨과 슬픔 사이, 조 증과 울증 사이, 우울과 분노 사이 등과 같이 서로 대치되는 감정 사이의 어느 위치를 나타낼 수 있다. 신경망 회로로는 예를 들면 콘볼루션 신경망(Convolutional Neural Network), 순환 신경망(Recurrent Neural Network), 콘볼루션 순환 신경망(convolutional recurrent neural network) 등이 사용될 수 있다. 신경 망 회로는 특정 감정 상태의 음성 데이터를 학습 데이터로 사용하여 학습되어 있어서, 입력되는 음성 데이 터로부터 감정 추론값을 출력한다. 일 실시예에서 신경망 회로는 음성 구간의 음성 데이터를 학습 데이터로 사용하여 학습되어 있어서, 입력 되는 음성 데이터가 음성 구간인지 여부를 나타내는 추론값(이하, 'VAD값'이라 함)을 출력하도록 구성할 수 있다. 감정 판단부는 신경망 회로을 출력 신호를 사용하여 음성 데이터에 내재된 감정을 판단한다. 일 실시 예에서, 감정 판단부는 VAD값이 소정의 임계치 이상인 경우에만 감정 판단 알고리즘을 실행하도록 구성될 수 있다. 다음으로, 도 2를 참조하여 본 발명의 일 실시예에 따른 감정 상태 추론 방법의 동작을 설명한다. 음향구간 분리부는 음성 데이터에 음향신호가 포함되는지 감지하여 음향신호가 포함된 구간을 추출한다(단 계 S10). 일 실시예에서 소정 시간 이상 음향신호가 포함된 것으로 판정되는 경우에만 음향신호가 포함된 구간 을 추출할 수 있다. 예를 들면, 2초 이상 음향신호가 포함된 것으로 판정된 경우에 해당 구간을 추출할 수 있다. 예를 들어, 1.5초 동안만 음향신호가 포함된 것으로 판정되면 해당 구간을 추출하지 않고, 4.2초 동안 음 향신호가 포함된 것으로 판정되면 해당 구간은 추출한다. 전처리부는 추출된 음성 데이터로부터 복수의 특 징벡터를 추출한다. 신경망 회로는, 추출된 음향신호 구간이 음성이 포함된 구간인지를 판단한다(단계 S20). 일 실시예에서, 추출된 음향신호 구간에 대해서 신경망 회로에서 음성구간임을 나타내는 추론값이 소정 임계치 이상이면 음성구간 으로 판단한다. 음성구간으로 판단되면 해당 구간의 특징벡터에 대한 신경망 회로의 감정을 추론하는 추론값이 해당 구간 에 대한 감정 추론값이 된다(단계 S30). 단계 S30 및 단계 S40에서 감정 추론 및 이 값을 사용하여 감정을 판단하는 감정인식 알고리즘의 한가지 예를 도 3을 참조하여 설명한다. 감정 추론은 음성 데이터를 소정 구간으로 분할하여 이루어진다. 예를 들면, 2초 단 위로 감정을 추론할 수 있다. 일 실시예에서 감정 추론 대상 구간은 일부분씩 중복되도록 구성할 수 있다. 예를 들면 도 3에 도시한 것처럼 2초 단위로 감정을 추론하되, 다음 추론시에는 1초만큼 시프트하여 이전 2초 구간 중의 뒷부분 1초와 다음의 1초로 이루어지는 2초 구간에 대해서 감정을 추론한다. 이와 같이 구성하면 음성검출 기간이 4.3초인 경우에는 감정 추론이 3회 실행되고, 음성검출기간이 6.9초인 경우에는 감정 추론이 5회 실행된 다. 이와 같이 도 3의 실시예에서 신경망 회로에서는 1초마다 감정 추론값이 출력된다. 감정 판단부는 이 추론값을 사용하여 해당 음성구간에 내재된 감정을 판단하고(단계 S40), 그 결과를 표시 한다(단계 S50). 단계 S40에서 감정 판단을 하는 한가지 예를 설명한다. 이하의 설명에서는 음성에 포함된 감정 상태가 도 4에 도시된 것처럼 제1감정과 제2감정 사이의 어느 한 위치에 있는지를 판단하는 경우를 예로 들어 설명한다. 이하 의 예에서는 제1감정은 우울이고, 제2감정이다. 또한, 본 실시예에서는 신경망 회로에서 우울에 대한 추론 값, 분노에 대한 추론값, 그리고 정상 감정에 대한 추론값의 3가지 추론값을 출력하는 경우를 예로 들어 설명한 다. 먼저, 최초 2초간의 음성 구간에 대한 추론값으로부터 초기 감정상태값을 설정한다. 우울에 대한 추론값, 분노 에 대한 추론값, 그리고 정상 감정에 대한 추론값 중에서 가장 높은 추론값을 갖는 감정 상태의 기본 점수를 초 기 감정상태값으로 설정한다. 초기 감정상태값으로는 도 4의 예에서 우울은 3, 정상감정은 5, 분노는 8의 값을 갖는다. 예를 들어, 우울에 대한 추론값, 분노에 대한 추론값, 그리고 정상 감정에 대한 추론값이 각각 0.1, 0.4, 0.5가 나왔다면, 정상감정에 대한 추론값이 가장 크므로 초기 감정상태는 정상감정으로 하고, 감정상태값 은 5를 설정한다. 이후, 도 3에 도시된 것처럼 1초마다 직전 2초간의 음성 데이터에 대한 신경망 회로의 추론값으로부터 가 장 높은 추론값을 갖는 감정 상태를 파악하고, 그에 따라 1단계씩 단계를 조정한다. 즉, 0초~2초의 음성 데이터 에서 정상감정 상태가 나온 후에 1~3초의 음성 데이터에서 분노가 가장 높은 추론값을 갖는다면 초기값 5에서 한단계 높은 6으로 감정상태값을 조정한다. 2~4초의 음성 데이터에서 다시 분노가 가장 높은 추론값을 갖는다면 6에서 한단계 높은 7로 감정상태값을 조정한다. 즉, 우울상태에서 정상상태 또는 분노 추론값이 나오면 감정상 태값을 한단계 높이고, 분노단계에서 정상상태 또는 우울 추론값이 나오면 감정상태값을 한단계 낮춘다. 정상상 태에서는 분노 추론값이 나오면 감정상태값을 한단계 높이고 우울 추론값이 나오면 감정상태값을 한단계 낮춘다. 감정상태값이 1인 경우에는 단계는 더이상 감소하지 않고, 감정상태값이 10인 경우에는 단계는 더이상 증가하지 않는다. 이렇게 판정된 감정상태의 추이는 숫자로 표시될 수 있다. 즉, 초기값이 5이고 이후 분노, 분노, 분노, 정상으 로 판단되었다면, \"5 -> 6 -> 7 -> 8 -> 7\"과 같이 표시된다. 이러한 추이는 또한 메모리에 저장되어 추후에 확 인하도록 구성할 수도 있다. 또한, 실시간 처리의 경우에는 도 4에 도시된 것과 같은 화면에 현재의 감정상태에 해당하는 숫자에 불이 들어오도록 표시하는 것도 가능하다. 다음으로 감정상태 추론에 사용할 수 있는 특징벡터에 대해서 설명한다. 특징벡터로는 스펙트로그램 (Spectrogram), 스펙트럼 공분산(Spectral Covariance), 스펙트럴 센트로이드(Spectral Centroid) 등이 사용될 수 있다. 스펙트로그램(Spectrogram)은 입력신호에 대하여 i번째 프레임에서 j번째 주파수 성분의 푸리에 계수를 제곱한 값에 대하여 칼라 이미지로 시간축과 주파수축으로 표시한 것을 말하며, 도 5의 (a)에 그 예가 도시되어 있다. 스펙트럼 공분산(Spectral Covariance)은 음성 신호 프레임 사이에 대해서 산출되는 것으로서, 시간지연(time lag)을 갖는 두 프레임 사이의 공분산을 구하여 얻을 수 있다. 수학식 1과 같이 구해지는 값으로 도 6과 같은 행렬을 구성하였을 때 R0는 시간지연 1일 때의 공분산, R1은 시간 지연 2일 때의 공분산, Rl은 시간지연 l일 때의 공분산을 나타낸다. 수학식 1"}
{"patent_id": "10-2022-0055904", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서 Xi,j는 i번째 프레임에서 j번째 주파수 성분의 푸리에 계수를 나타내며, M은 총 프레임의 갯수, l 은 시간지연(time lag), 0 < j < 129인 정수이다. 도 7은 공분산 계산 결과값들의 예시로서, 시간지연이 커질수록 공분산값이 작아지는 것을 알 수 있다. 음성신 호에서 프레임 간의 거리가 멀어질수록 프레임 간의 상관관계는 작아질 수밖에 없다. 빨리 발성되는 음성에 비 해 천천히 발성되는 음성의 R 값이 천천히 작아진다. 스펙트럴 센트로이드(Spectral Centroid)는 스펙트럼의 특성을 나타내는 값으로서, 스펙트럼의 질량중심이 어디 에 있는지를 나타낸다. 스펙트럴 센트로이드는 수학식 2와 같이 구할 수 있다.수학식 2"}
{"patent_id": "10-2022-0055904", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2에서 Xi,j는 i번째 프레임의 j번째 주파수 성분의 푸리에 계수를 나타내며, N은 나이키스트 주파수 인덱 스, f(j)는 j번째 주파수 성분의 중심 주파수이다. f(j) 값은 i번째 프레임에서 모든 주파수 성분 크기의 합의 중간값에 해당하는 주파수를 의미한다. i번째 프레임의 스펙트럴 센트로이드 SCi는 발성된 음성의 특징으로 사용 될 수 있다. 이 값이 시간적으로 빨리 변화하면 발성속도가 빠르다는 것을 의미하게 된다. 이들 특징벡터들은 음성의 여러 특징을 나타내며, 감정에 따라 변하는 음성의 특징이 잘 드러날 수 있다. 감정 상태를 알고 있는 음성 데이터의 특징벡터를 사용하여 신경망 회로를 학습시킨 후에 감정상태를 알고자 하 는 음성 데이터를 입력하여 화자의 감정상태를 추론할 수 있다. 이상, 본 발명을 몇가지 예를 들어 설명하였으나, 본 발명의 실시예를 구성하는 모든 구성 요소들이 하나로 결 합하거나 결합하여 동작하는 것으로 설명되었다고 해서, 본 발명이 반드시 이러한 실시예에 한정되는 것은 아니 다. 즉, 본 발명의 목적 범위 안에서라면, 그 모든 구성 요소들이 하나 이상으로 선택적으로 결합하여 동작할 수도 있다. 또한, 그 모든 구성 요소들이 각각 하나의 독립적인 하드웨어로 구현될 수 있지만, 각 구성 요소들 의 그 일부 또는 전부가 선택적으로 조합되어 하나 또는 복수 개의 하드웨어에서 조합된 일부 또는 전부의 기능 을 수행하는 프로그램 모듈을 갖는 컴퓨터 프로그램으로서 구현될 수도 있다. 그 컴퓨터 프로그램을 구성하는 코드들 및 코드 세그먼트들은 본 발명의 기술 분야의 당업자에 의해 용이하게 추론될 수 있을 것이다. 이러한 컴퓨터 프로그램은 컴퓨터가 읽을 수 있는 저장매체(Computer Readable Media)에 저장되어 컴퓨터에 의하여 읽 혀지고 실행됨으로써, 본 발명의 실시예를 구현할 수 있다. 또한, 주파수 도메인에서 수행되는 것으로 설명된 동작을 시간 도메인에서 수행되도록 수정하거나, 시간 도메인에서 수행되는 것으로 설명된 동작을 주파수 도메 인에서 수행되도록 수정하여 구현하는 것도 가능하다. 이상에서 기재된 \"포함하다\", \"구성하다\" 또는 \"가지다\" 등의 용어는, 특별히 반대되는 기재가 없는 한, 해당 구성 요소가 내재할 수 있음을 의미하는 것이므로, 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것으로 해석되어야 한다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하 기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0055904", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 감정 상태 추론 장치의 구성을 보여주는 블록도이다. 도 2는 본 발명의 일 실시예에 따른 감정 상태 추론 방법의 동작을 보여주는 흐름도이다. 도 3은 본 발명의 일 실시예에서 음성검출 기간에 따른 감정인식 알고리즘의 실행 횟수를 보여주는 도면이다. 도 4는 감정 판단 결과를 표시하는 한가지 예이다. 도 5는 특징 벡터의 예이다. 도 6은 공분산 계산값으로 공분산 행렬을 구성한 예를 보여준다. 도 7은 시간지연(time lag)에 따른 공분산 계산 결과값들을 보여준다."}
