{"patent_id": "10-2022-0160232", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0077871", "출원번호": "10-2022-0160232", "발명의 명칭": "가상 캐릭터 감정 표현 시스템 및 방법", "출원인": "동국대학교 산학협력단", "발명자": "조경은"}}
{"patent_id": "10-2022-0160232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "가상 캐릭터 감정 표현 시스템에 있어서,현실 컨텐츠에서 얼굴을 인식하여 일련의 표정 데이터를 추출하는 표정 추출부;상기 일련의 표정 데이터를 3차원 공간으로 생성하는 동기화부;상기 표정 데이터와 동기화 하기 위한 상태 데이터를 추출하는 상태 추출부; 상기 표정 데이터 및 상태 데이터를 학습 데이터로 생성하는 학습부; 및학습된 상황이 감지될 경우 가상 캐릭터에 상태에 따른 감정 데이터를 출력하는 매칭부를 포함하는 가상 캐릭터감정 표현 시스템."}
{"patent_id": "10-2022-0160232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 동기화부는2차원 표정 데이터에 깊이 값을 생성하여 3차원 공간으로 생성하는 가상 캐릭터 감정 표현 시스템."}
{"patent_id": "10-2022-0160232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 상태 추출부는게임 환경에서 위치, 사용 무기, 캐릭터 상태, 이벤트 또는 사용자 제어 인터페이스 정보 중 어느 하나 이상을포함하여 게임 또는 메타버스 환경을 운영하기 위한 상태 데이터를 추출하는 가상 캐릭터 감정 표현 시스템."}
{"patent_id": "10-2022-0160232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 매칭부는다양한 각도에서의 얼굴 표정을 출력하기 위해 3D 표면에 매칭하는 가상 캐릭터 감정 표현 시스템."}
{"patent_id": "10-2022-0160232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "가상 캐릭터 감정 표현 시스템이 수행하는 가상 캐릭터 감정 표현 방법에 있어서,현실 컨텐츠에서 감정을 표현한 표정 데이터를 추출하는 단계;상기 현실 컨텐츠와 게임 컨텐츠를 동기화 하는 단계;상기 게임 컨텐츠의 게임 환경에서 상태 데이터를 추출하는 단계;상기 표정 데이터 및 상태 데이터를 학습 데이터로 생성하여 인공 지능 학습을 수행하는 단계; 및학습된 상황이 감지될 경우 가상 캐릭터에 상태에 따른 감정 데이터를 출력하는 단계를 포함하는 가상 캐릭터공개특허 10-2024-0077871-3-감정 표현 방법."}
{"patent_id": "10-2022-0160232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서상기 현실 컨텐츠와 게임 컨텐츠를 동기화 하는 단계는2차원 표정 데이터에 깊이 값을 생성하여 3차원 공간으로 생성하는 가상 캐릭터 감정 표현 방법."}
{"patent_id": "10-2022-0160232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 게임 컨텐츠의 게임 환경에서 상태 데이터를 추출하는 단계는게임 환경에서 위치, 사용 무기, 캐릭터 상태, 이벤트 또는 사용자 제어 인터페이스 정보 중 어느 하나 이상을포함하여 게임 또는 메타버스 환경을 운영하기 위한 상태 데이터를 추출하는 가상 캐릭터 감정 표현 방법."}
{"patent_id": "10-2022-0160232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 학습된 상황이 감지될 경우 가상 캐릭터에 상태에 따른 감정 데이터를 출력하는 단계는다양한 각도에서의 얼굴 표정을 출력하기 위해 3D 표면에 매칭하는 가상 캐릭터 감정 표현 시스템."}
{"patent_id": "10-2022-0160232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제5항 내지 제8항 어느 하나에 따른 가상 캐릭터 감정 표현 방법을 실행하는 컴퓨터가 판독 가능한 기록매체에기록된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0160232", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 가상 캐릭터 표현에 관한 기술로, 더욱 상세하게는 상태 또는 이벤트 목적에 맞는 영화 또는 스포츠 중계의 연속된 장면과 같은 현실의 콘텐츠로부터 얼굴을 인식하고 연속된 얼굴 표정 변화를 추출하여 게임 또는 메타버스 내 가상 캐릭터의 감정 표현이 이용하는 가상 캐릭터 감정 표현 시스템 및 방법에 관한 것이다. 본 발 명의 일 실시 예에 따르면, 게임 또는 메타버스 내 캐릭터의 감정을 사용자(플레이어를 컨트롤 하는 이용자)와 의 동기화를 유도하여 콘텐츠의 몰입감을 높이고, 전체 콘텐츠를 풍부하게 함으로써 게임의 수준을 한 단계 높일 수 있다."}
{"patent_id": "10-2022-0160232", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 가상 캐릭터 표현에 관한 기술로, 더욱 상세하게는 상태 또는 이벤트 목적에 맞는 영화 또는 스포츠 중계의 연속된 장면과 같은 현실의 콘텐츠로부터 얼굴을 인식하고 연속된 얼굴 표정 변화를 추출하여 게임 또는 메타버스 내 가상 캐릭터의 감정 표현이 이용하는 가상 캐릭터 감정 표현 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0160232", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능을 이용한 얼굴 인식 및 생성/변형에 사용되는 기술은 대표적으로 GAN(Generative Adversarial Networks)과 같이 이미지에서 특징을 추출하고, 특징간 관계를 통해 전체적인 사물을 인지하여 유사 이미지나 주어진 조건을 기반으로 이미지를 생성하게 되며, (AE)Autoencoder 기술을 함께 사용하여 Encoder 와 Decoder 로 분리하여 다른 인공지능 분야에 활용 되기도 한다. 이러한 기술은 컴퓨터 비전(Computer Vision) 분야로, 수 학적 알고리즘 기반에서 인공지능을 적용하기 까지 이미 오랜 기간 연구된 기술이다. 대표적인 FakeFace 와 같 은 기술은 실시간 얼굴인식과 변형 이미지 생성을 목적으로 스마트 폰의 앱으로 출시되어 사용자 들에게 널리 사용되고 있다. 나아가 얼굴 인식 기술은 워핑(wrapping)기술과 함께 3D 얼굴 인식 및 생성 기술로 발전을 거듭 하고 있다. 인간의 얼굴 형태를 학습한 인공지능을 통해 한 장 또는 적은 수의 사진 또는 이미지에서 3D 얼굴을 생성해 내는 분야로 현재 활발한 연구가 진행되고 있다.이러한 얼굴인식 및 생성/변형 기술은 또한 인간의 감정 표현에 대한 분야에서도 연구되고 있다. 인간의 얼굴을 구성하는 눈, 코, 입의 모양과 위치에 따라 감정이나 나이를 예측하는 분야이다. 하지만, 인간의 감정은 복잡하 여 어떤 대표적인 감정을 예측할 수 있지만, 슬퍼서 우는지, 기뻐서 우는지에 대한 판단 기준을 정하는 것은 아 직도 어려운 문제이며, 주어진 상황에 따라 해석이 달라진다. 따라서, 게임 내 캐릭터의 감정을 표현할 때는 주 어진 상태의 명확성이 필요하며, 게임이나 메타버스에서는 상태 규정이 현실세계보다는 상대적으로 쉽고, 기획 자가 의도적인 이벤트를 정의할 수 있어 감정을 표현하기 위한 기반 상태 데이터로 사용하기 용이하다. 예를 들어 스포츠 게임인 축구에서 골을 획득 했을 때, 게임 제작사는 게임의 재미를 더하기 위해 세레머니 (Ceremony)를 보여주기도 한다. 하지만, 인간의 신체를 이용하여 실제 축구 경기에서의 제스처는 흉내 내지만, 게임 내의 캐릭터 얼굴의 감정 표현은 매우 어색하고 제한되어 있다. 이러한 문제는 게임 뿐만 아니라 최근 다 양한 분야로 활용 범위를 넓히고 있는 메타버스(Metaverse) 내의 캐릭터에서도 마찬가지로 한정된 수의 표정으 로 인해 가상공간에서 다른 사용자에게 감성을 전달하거나 공감대를 표현하기 어렵다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 한국 공개특허공보 제10-2005-0066701호 “감정인식 컴퓨팅을 이용한 게임 방법 및 장치” (공개일자: 2005년05월 30일)"}
{"patent_id": "10-2022-0160232", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 현실의 컨텐츠에서 얼굴 표정을 기반으로 한 감정 데이터를 취득하고, 현실 컨텐츠와 동일한 게임 컨 텐츠 스크립트를 생성하여 게임 컨텐츠를 통해 상태 데이터를 취득하여, 감성 데이터와 상태 데이터를 동기화하 여 상태에 따른 감성 학습 데이터를 생성하여 게임 이나 메타버스 내 캐릭터의 감정을 표현하는 시스템 및 방법 을 제공한다."}
{"patent_id": "10-2022-0160232", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, 가상 캐릭터 감정 표현 시스템을 제공한다. 본 발명의 일 실시 예에 따른 가상 캐릭터 감정 표현 시스템은 현실 컨텐츠에서 얼굴을 인식하여 일련의 표정 데이터를 추출하는 표정 추출부, 일련의 표정 데이터를 3차원 공간으로 생성하는 동기화부, 표정 데이터와 동 기화 하기 위한 상태 데이터를 추출하는 상태 추출부, 표정 데이터 및 상태 데이터를 학습 데이터로 생성하는 학습부 및 학습된 상황이 감지될 경우 가상 캐릭터에 상태에 따른 감정 데이터를 출력하는 매칭부를 포함할 수 있다. 본 발명의 다른 일 측면에 따르면, 가상 캐릭터 감정 표현 방법 및 이를 실행하는 컴퓨터 프로그램을 제공한다. 본 발명의 일 실시 예에 따른 가상 캐릭터 감정 표현 방법 및 이를 실행하는 컴퓨터 프로그램은 현실 컨텐츠에 서 감정을 표현한 표정 데이터를 추출하는 단계, 현실 컨텐츠와 게임 컨텐츠를 동기화 하는 단계, 게임 컨텐츠 의 게임 환경에서 상태 데이터를 추출하는 단계, 표정 데이터 및 상태 데이터를 학습 데이터로 생성하여 인공 지능 학습을 수행하는 단계 및 학습된 상황이 감지될 경우 가상 캐릭터에 상태에 따른 감정 데이터를 출력하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0160232", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시 예에 따르면, 게임 또는 메타버스 내 캐릭터의 감정을 사용자(플레이어를 컨트롤 하는 이용 자)와의 동기화를 유도하여 콘텐츠의 몰입감을 높이고, 전체 콘텐츠를 풍부하게 함으로써 게임의 수준을 한 단계 높일 수 있다. 또한, 본 발명의 일 실시 예에 따르면, 인터렉티브한 상황에서 다른 사용자인 상대 캐릭터에게 감정을 풍부하게 전달함으로써 스포츠 게임에서는 더 현실감 있고, RPG게임이나 메타버스 공간에서는 다른 사용자와의 인터렉티 브 수준을 높일 수 있다. 또한 본 발명의 일 실시 예에 따르면, 학습 데이터 생성을 위해 사용되는 데이터의 고유 특징을 회피하여 저작 권이나 초상권으로부터 자유로운 학습 데이터를 생성할 수 있다. 또한 본 발명의 일 실시 예에 따르면, 학습 데이터 생성이 용이하여 방대한 데이터를 취득할 수 있고, 게임 또 는 메타버스에서 발생하는 다양한 상태 또는 이벤트에 대해 적용할 수 있다."}
{"patent_id": "10-2022-0160232", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시 예를 가질 수 있는 바, 특정 실시 예들을 도면에 예시하 고 이를 상세한 설명을 통해 상세히 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하 려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 발명을 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불 필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 본 명세서 및 청구항에서 사용되는 단수 표현은, 달리 언급하지 않는 한 일반적으로 \"하나 이상\"을 의미하는 것으로 해석되어야 한다. 이하, 본 발명의 바람직한 실시 예를 첨부도면을 참조하여 상세히 설명하기로 하며, 첨부 도면을 참조하여 설명 함에 있어, 동일하거나 대응하는 구성 요소는 동일한 도면번호를 부여하고 이에 대한 중복되는 설명은 생략하기 로 한다. 도 1 내지 도 7은 본 발명의 일 실시 예에 따른 가상 캐릭터 감정 표현 시스템을 설명하기 위한 도면들이다. 도 1을 참조하면, 가상 캐릭터 감정 표현 시스템은 영화 또는 스포츠 중계의 연속된 장면과 같은 현실의 콘텐츠로부터 얼굴을 인식하고 연속된 얼굴 표정 변화를 표정 데이터로 추출할 수 있다. 가상 캐릭터 감정 표현 시스템은 현실 컨텐츠를 게임의 스크립트 형태로 구현하여 게임 컨텐츠에서 흐름에 따른 상태 데이터를 추출할 수 있다. 예를 들면 가상 캐릭터 감정 표현 시스템은 스크립트로 구성된 게임의 환경으로부터 게임의 시간에 따른 일련의 상태 데이터를 추출할 수 있다. 가상 캐릭터 감정 표현 시스템은 게임의 상태를 기반으로 현실 컨텐츠에서 추출한 배우 또는 선수의 연속적 얼굴 표정 변화의 표정 데이터 및 게임의 시간에 따른 일련의 상태 데이터를 인공지능 시계열 데이터로 입력할 수 있다. 가상 캐릭터 감정 표현 시스템은 게임에서의 상태 데이터와 현실 컨텐츠의 표정 데이터를 동기화하여 게임 의 상태에 따른 얼굴 표정 변화 데이터를 생성할 수 있다. 게임 또는 메타버스 내 가상 캐릭터는 주로 3차원으로 구성되어 있지만 가상 캐릭터 감정 표현 시스템이 추 출한 표정 데이터는 2차원으로 그 차원이 상이하다. 가상 캐릭터 감정 표현 시스템은 3차원으로 구성된 게 임 또는 메타버스 내 가상 캐릭터에 사용하기 위해 2D의 표정 데이터에서 깊이 정보를 추출하여 표정 데이터와 상태 데이터를 동기화하여3 차원의 가상 캐릭터의 얼굴에 게임의 상태에 따른 감정 표현을 할 수 있다. 가상 캐릭터 감정 표현 시스템은 3차원 공간 정보를 추출하기 위해 사전에 훈련된 인공지능 모델을 사용할 수 있다. 예를 들면, 가상 캐릭터 감정 표현 시스템은 순환 신경망(RNN; Recurrent Neural Network, 예: LSTM) 기반 또는 합성곱 신경망(CNN, Convolutional Neural Network, 예: Transformer) 기반으로 인공지능 모 델을 통해 일련의 상태에 따른 얼굴 표정을 학습할 수 있다. 최종적으로 게임의 흐름에 따라 표현할 얼굴 표정 을 결정해야 하기 때문에, 가상 캐릭터 감정 표현 시스템은 연속적인 이미지와 다중 시계열 데이터를 함께 학습할 수 있는 복합적인 신경망(Image sequence & Multivariate Time Series)으로 구성할 수 있다. 예를 들면게임이나 메타버스 공간에서 캐릭터의 얼굴 표정으로 나타나는 감정은 단일 이미지가 아닌 연속적인 변화를 요 구한다. 연속 이미지 기반 시계열 데이터 추론(Image-to-image recurrent network) 연구를 이용하면, 상태(이 벤트)에 대한 시계열로 정리된 데이터를 입력하면, 인공지능이 학습된 데이터를 기반으로 일련의 이미지를 예측 할 수 있다. 가상 캐릭터 감정 표현 시스템은 게임의 흐름에 따른 상태를 판단하여 현실 컨텐츠와 흡사한 가상 캐릭터의 표정을 출력할 수 있다. 도 2를 참조하면, 가상 캐릭터 감정 표현 시스템은 표정 추출부, 동기화부, 상태 추출부, 학습부 및 매칭부를 포함할 수 있다. 표정 추출부는 가상 캐릭터의 얼굴 표정을 표현하기 위해 현실 컨텐츠에서 얼굴을 인식하여 일련(시퀜스) 의 표정 데이터를 추출할 수 있다. 자세히 설명하면, 표정 추출부는 현실 컨텐츠에서 일련(시퀜스)의 표정 변화에 대한 학습 데이터를 추출할 수 있다. 표정 추출부는 일련(시퀜스)의 표정 변화에 대한 표정 데이터를 기반으로 감정을 포함할 수 있다. 본 발명은 2차원 데이터에 대해 인공지능 모델을 통한 3차원 공간을 생성하여, 주로 2.5차원~3차원의 상태로 구 성된 게임 또는 메타버스 내 가상 캐릭터의 감정을 자연스럽게 출력할 수 있다. 도 3를 참조하면, 동기화부는 게임 환경과의 동기화를 위해 현실 컨텐츠에서 인식되어 추출된 2차원 표정 데이터를 3차원 공간으로 생성할 수 있다. 동기화부는 3차원 공간 생성을 위해 사전 학습(Pre-Trained)된 인공지능 모델을 적용할 수 있다. 동기화부는 현실 컨텐츠로부터 게임의 스크립트를 구성할 수 있다. 동기화부는 현실 컨텐츠로부터 구 성된 게임의 스크립트로 게임의 시나리오를 생성할 수 있다. 다시 도 2를 참조하면, 상태 추출부는 감정을 포함한 표정 데이터와 동기화 하기 위한 상태 데이터를 추출 할 수 있다. 상태 추출부는 시간에 따른 일련의 상태 데이터를 스크립트로 구성된 게임의 환경으로부터 추출할 수 있다. 자세히 설명하면, 게임 데이터는 각 장면마다 상태 데이터가 표준화 되어 있어 상태 데이터를 추출하기 쉽다. 상태 추출부는 스크립트로 구성된 게임 환경에서 위치, 사용무기, 캐릭터 상태(공격, 이동 등)와 함 께 사용자 제어 인터페이스를 포함하여 게임 또는 메타버스 환경을 운영하기 위한 상태 데이터를 추출할 수 있 다. 도 4 내지 도 5를 참조하면, 학습부는 학습 데이터를 기반으로 감정(일련의 표정 변화에 대한 표정 데이터)과 상황(게임에서 추출되는 각종 상태 데이터)을 인공지능 학습을 통해 매칭된 상태에 따른 감정 데이터 를 추출할 수 있다. 학습부는 표정 데이터 및 상태 데이터를 기반으로 학습 데이터를 생성할 수 있다. 학습부는 게임 기획자가 의도하는 현실 컨텐츠를 기반으로 인공지능 모델을 위한 학습 데이터를 생성할 수 있다. 학습부는 표정의 변화를 학습하기 위해 일련의 연속된 이미지 프레임으로 학습 데이터를 생성할 수 있다. 학습부는 표정 추출부에서 추출한 감정(일련의 표정 변화에 대한 표정 데이터)을 기반으로 인공지능 학습을 위한 시계열 이미지 변환 데이터로 생성할 수 있다. 학습부는 표정 추출부가 추출한 연속된 표정 이미지 데이터의 깊이 값을 추출하여 3차원 공간으로 구 성할 수 있다. 학습부는 상태 추출부에서 추출한 게임 환경에서의 상황(게임 환경에서 추출된 각종 상태 데이터)을 기반으로 인공지능 학습을 위한 시계열 상태 데이터로 생성할 수 있다. 학습부는 게임 내 가상 캐릭터의 움직임을 게임 환경(Env)에서 시간 순으로 나열되어 시계열 상태(state) 데이터로 생성할 수 있다. 이러한 상태는 기획자가 구성한 게임의 환경에 따라 결정되고, 본 발명은 상태의 특 징점을 통해 표정을 전환하는 이벤트를 발생시킬 수 있다. 학습부는 표정 정보를 포함하여 감정을 판단할 수 있는 시계열 이미지 변환 데이터와 현실 컨텐츠의 상황 과 동일하게 구성된 스크립트를 구동하여 게임에서 추출되는 시계열 상태 데이터를 학습 데이터로 이용할 수 있 다. 학습부는 최종적으로 게임의 흐름에 따라 표현할 얼굴 표정을 결정해야 하기 때문에, 연속적인 이미지 변 환 데이터와 다중 시계열 데이터를 함께 학습할 수 있는 복합적인 신경망(Image sequence & Multivariate Time Series)으로 구성할 수 있다. 학습부는 현실 컨텐츠에 따라 게임의 스크립트를 구성하여 학습할 수도 있고, 기획자가 임의로 지정된 게 임 내 상태 이벤트를 지정하여 학습 데이터로 생성할 수 있다. 가상 캐릭터의 감정 표현은 게임의 재미를 부과 하는 요소로 현실적인 묘사도 중요하지만 인간 플레이어에 즐거움을 전달하기 위한 것이므로 학습부는 기 획자가 의도한 현실 컨텐츠와는 다른 상황 또는 이벤트에 대해 학습 데이터를 생성하여 학습할 수 있다. 예를 들면 게임 내 캐릭터가 맞았을 때 현실 컨텐츠와 같이 인상을 쓰거나 화를 내는 것이 아니라 눈이 커지고 정신 없어 하는 표정으로 가상 캐릭터의 감정을 순화하여 표현할 수도 있다. 또한 학습부는 현실에서의 스포츠 중계 방송을 통해 학습 데이터를 쉽게 생성할 수 있다. 예를 들면 학습 부는 선수들이 클로즈업 되거나 하이라이트에 대해 기획자가 게임 내에 비슷한 상황을 구성할 수 있다. 특히 스포츠 중계 방송의 경우 득점 성공 또는 실패, 역전 골과 같은 영상을 자세히 제공하여 학습 데이터 구 축이 용이하다. 학습부는 감정(일련의 표정 변화에 대한 데이터)과 상황(게임에서 추출되는 각종 상태 데이터)을 기반으로 상태-표정이 매칭하여, 이러한 일련의 상태에 대해 어떤 일련의 표정이 적절한지 학습할 수 있다. 학습부 는 상태-표정이 매칭된 상태에 따른 감정 데이터를 결과값으로 추출할 수 있다. 도 6을 참조하면, 매칭부는 실제 게임 환경에 적용되어, 학습된 상황이 감지될 경우 가상 캐릭터에 상태에 따른 감정 데이터를 출력할 수 있다. 매칭부는 구동 중인 가상 캐릭터에 대해 지속적인 생성되는 입력 데이터를 기반으로 입력된 상태에 대해 감지하고, 그에 적합한 얼굴 표정을 상태에 따른 감정 데이터로 출력하여 게임 또는 메타버스 내 가상 캐릭터에 적용할 수 있다. 예를 들면 매칭부는 여러 상태 신호를 시간(t)에 따라 지속적으로 생성되는 시계열 상태 데이터를 입력 데이터로 이용할 수 있다. 예를 들면, 캐릭터의 위치, 캐릭터의 상태(도 6에서는 스파이크-필살 기 사용), 스포츠 게임에서 게임의 스코어와 같은 상태 데이터들이 학습부에서 학습된 인공지능의 입력 데이터로 사용되며, 이는 다중 시계열 데이터를 구성할 수 있다. 매칭부는 시계열 상태 데이터를 입력하여 그에 적합한 상태에 따른 감정 데이터를 가상 캐릭터의 얼굴에 출력할 수 있다. 매칭부는 게임에서 학습된 상태를 판단하여 현실 콘텐츠와 흡사한 캐릭터 표정을 출력할 수 있다. 매칭부은 다양한 각도에서의 얼굴 표정을 출력하기 위해 학습 또는 매칭 시 Warping, Inverse warping, re-warping과 같이 3D 표면에 매칭 시키는 기술 등이 적용할 수 있다. 도 7을 참조하면, 매칭부는 기획자의 윤곽 디자인에 현실 컨텐츠에서 추출한 얼굴 컴포넌트들을 사용하여 일부 데이터 만으로도 전체 얼굴을 구성할 수 있다. 예를 들면 얼굴 컴포넌트는 눈, 코, 입, 귀 등으로 구분된 부위일 수 있다. 매칭부는 시간에 따른 얼굴 컴포넌트 간의 관계, 각 얼굴 컴포넌트의 독자적 특징 만을 추출하며 학습 데 이터로 사용할 수 있다. 매칭부는 기획자가 의도한 얼굴 윤곽을 기반으로 일련의 얼굴 컴포넌트 변화를 적용하여 감정에 따른 가상 캐릭터의 얼굴 표정을 출력할 수 있다. 도 8는 본 발명의 일 실시 예에 따른 가상 캐릭터 감정 표현 방법 도시한 도면이다. 이하 설명하는 각 과정은 단계에서 가상 캐릭터 감정 표현 시스템을 구성하는 각 기능부가 수행하는 과정이나, 본 발명의 간결하고 명확 한 설명을 위해 각 단계의 주체를 가상 캐릭터 감정 표현 시스템으로 통칭하도록 한다. 도8를 참조하면, S810 단계에서 가상 캐릭터 감정 표현 시스템은 영화 또는 스포츠 중계와 같은 현실 컨텐 츠에서 감정을 표현한 인물의 표정 데이터를 추출한다. 가상 캐릭터 감정 표현 시스템은 감정을 표현한 인 물의 표정 데이터를 시간순으로 변화된 표정 데이터를 나열하여 시계열 이미지 변환 데이터를 추출하고, 시계열이미지 변환 데이터는 감정을 표현할 수 있다. S820 단계에서 가상 캐릭터 감정 표현 시스템은 현실 컨텐츠를 기반으로 게임 스크립트를 구성할 수 있다. S830 단계에서 가상 캐릭터 감정 표현 시스템은 현실 컨텐츠와 스크립트로 구성된 게임 컨텐츠를 동기화 할 수 있다. 가상 캐릭터 감정 표현 시스템은 현실 컨텐츠에서 추출한 감정을 표현한 표정 데이터를 3차원 공 간으로 생성하여 동기화할 수 있다. 가상 캐릭터 감정 표현 시스템은 스크립트로 구성된 게임 환경에서 시계열 상태 데이터를 추출할 수 있다. 예를 들면 가상 캐릭터 감정 표현 시스템은 스크립트로 구성된 게임 환경에서 위치, 사용무기, 캐릭터 상태 (공격, 이동 등)와 함께 사용자 제어 인터페이스를 포함하여 게임 또는 메타버스 환경을 운영하기 위한 상태 데 이터를 시간 순으로 나열된 시계열 상태 데이터로 추출할 수 있다. S840 단계에서 가상 캐릭터 감정 표현 시스템은 시계열 이미지 변환 데이터 및 시계열 상태 데이터를 입력 을 하여 인공지능 학습을 수행할 수 있다. 가상 캐릭터 감정 표현 시스템은 상태-표정이 매칭된 상태에 따 른 감정 데이터를 결과 값으로 추출할 수 있다. 자세히 설명하면 가상 캐릭터 감정 표현 시스템은 감정(일 련의 표정 변화에 대한 데이터)과 상황(게임에서 추출되는 각종 상태 데이터)을 기반으로 상태-표정이 매칭하여, 이러한 일련의 상태에 대해 어떤 일련의 표정이 적절한지 학습할 수 있다. S850 단계에서 가상 캐릭터 감정 표현 시스템은 실제 게임 환경에 적용되어, 학습된 상황이 감지될 경우 가 상 캐릭터에 상태에 따른 감정 데이터를 출력할 수 있다. 예를 들면 가상 캐릭터 감정 표현 시스템은 구동 중인 가상 캐릭터에 대해 지속적인 생성되는 입력 데이터를 기반으로 입력된 상태에 대해 감지하고, 그에 적합 한 얼굴 표정에 대한 감정 데이터를 출력하여 게임 또는 메타버스 내 가상 캐릭터 얼굴에 적용할 수 있다. 가상 캐릭터 감정 표현 시스템은 게임에서 학습된 상태를 판단하여 현실 콘텐츠와 흡사한 캐릭터 표정을 출력할 수 있다. 상술한 가상 캐릭터 감정 표현 방법은 컴퓨터가 읽을 수 있는 매체 상에 컴퓨터가 읽을 수 있는 코드로 구현될 수 있다. 상기 컴퓨터로 읽을 수 있는 기록 매체는, 예를 들어 이동형 기록 매체(CD, DVD, 블루레이 디스크, USB 저장 장치, 이동식 하드 디스크)이거나, 고정식 기록 매체(ROM, RAM, 컴퓨터 구비형 하드 디스크)일 수 있 다. 상기 컴퓨터로 읽을 수 있는 기록 매체에 기록된 상기 컴퓨터 프로그램은 인터넷 등의 네트워크를 통하여 다른 컴퓨팅 장치에 전송되어 상기 다른 컴퓨팅 장치에 설치될 수 있고, 이로써 상기 다른 컴퓨팅 장치에서 사 용될 수 있다. 이상에서, 본 발명의 실시 예를 구성하는 모든 구성 요소들이 하나로 결합되거나 결합되어 동작하는 것으로 설 명되었다고 해서, 본 발명이 반드시 이러한 실시 예에 한정되는 것은 아니다. 즉, 본 발명의 목적 범위안에서라 면, 그 모든 구성요소들이 하나 이상으로 선택적으로 결합하여 동작할 수도 있다. 도면에서 동작들이 특정한 순서로 도시되어 있지만, 반드시 동작들이 도시된 특정한 순서로 또는 순차적 순서로 실행되어야만 하거나 또는 모든 도시 된 동작들이 실행되어야만 원하는 결과를 얻을 수 있는 것으로 이해되어서 는 안 된다. 특정 상황에서는, 멀티태스킹 및 병렬 처리가 유리할 수도 있다. 더욱이, 위에 설명한 실시 예 들 에서 다양한 구성들의 분리는 그러한 분리가 반드시 필요한 것으로 이해되어서는 안 되고, 설명된 프로그램 컴 포넌트들 및 시스템들은 일반적으로 단일 소프트웨어 제품으로 함께 통합되거나 다수의 소프트웨어 제품으로 패 키지 될 수 있음을 이해하여야 한다. 이제까지 본 발명에 대하여 그 실시 예들을 중심으로 살펴보았다. 본 발명이 속하는 기술 분야에서 통상의 지식 을 가진 자는 본 발명이 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있을 것이다. 그러므로 개시된 실시 예들은 한정적인 관점이 아니라 설명적인 관점에서 고려되어야 한다. 본 발명의 범위는 전술한 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동등한 범위 내에 있는 모 든 차이점은 본 발명에 포함된 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0160232", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 내지 도 7은 본 발명의 일 실시 예에 따른 가상 캐릭터 감정 표현 시스템을 설명하기 위한 도면들. 도 8는 본 발명의 일 실시 예에 따른 가상 캐릭터 감정 표현 방법 도시한 도면."}
