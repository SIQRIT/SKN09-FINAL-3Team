{"patent_id": "10-2022-0180221", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0098458", "출원번호": "10-2022-0180221", "발명의 명칭": "인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 방법 및 시스템", "출원인": "씨제이올리브네트웍스 주식회사", "발명자": "이한솔"}}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "메모리; 및상기 메모리에 접속된 적어도 하나의 프로세서를 포함하고,상기 프로세서는,섬네일 검출이 선택된 경우, 입력된 영상에서 섬네일을 탐색할 영상 구간을 선택하고, 선택된 영상 구간으로부터 제1 복수의 이미지를 추출한 후, 제1 인공 신경망 모델을 이용하여, 추출된 제1 복수의 이미지 중 주요 대상이 포함된 복수의 제2 이미지를 추출하고, 제2 인공 신경망 모델을 이용하여, 추출된 복수의 제2 이미지 중 자막이 없는 복수의 제3 이미지를 추출하며, 추출된 복수의 제3 이미지를 후처리하여 최종 섬네일 이미지 후보 리스트로 출력하고,하이라이트 검출이 선택된 경우, 입력된 영상을 샷(shot) 단위로 분할한 후, 분할된 샷의 시각 및 음성 정보를복수의 제3 인공 신경망 모델에 입력하여 복수의 하이라이트 후보군을 추출하고, 복수의 제4 인공 신경망 모델을 이용하여 얼굴, 감정, 및 음압(decibel)을 토대로 샷마다의 얼굴 점수, 감정 점수, 및 음압 점수를 포함하는하이라이트 점수를 계산하며, 각 하이라이트 후보군에 포함된 샷들의 하이라이트 점수를 합산하여 총 하이라이트 점수를 계산한 후, 상기 복수의 하이라이트 후보군 중 가장 높은 총 하이라이트 점수를 가지는 하이라이트후보군을 최종 하이라이트 영상으로 출력하는 것을 특징으로 하는 인공지능 기반 동영상 콘텐츠 내 섬네일 및하이라이트 검출 시스템."}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는, 주요 인물의 상반신 및 주요 인물의 얼굴 크기 비율을 고려하여 상기 복수의 제2 이미지를 선별하는 것을 특징으로 하는 인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 시스템."}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는, 상기 복수의 제2 이미지 중 섬네일에 필요없는 요소들을 가진 이미지들을 추가로 제외하는 것을 특징으로 하는 인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 시스템."}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 프로세서는, 상기 복수의 제2 이미지 중 자막이 있는 이미지를 제외하지 않고, 해당 이미지 내의 자막을지우고 재채색하여 상기 복수의 제3 이미지로 출력하는 것을 특징으로 하는 인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 시스템."}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,공개특허 10-2024-0098458-3-상기 프로세서는, 상기 복수의 제3 이미지 각각에 대해 상하 또는 좌우 레터박스를 제거하고, 기설정된 규격에맞게 이미지 포맷을 조절하여 최종 섬네일 이미지 후보 리스트로 출력하는 것을 특징으로 하는 인공지능 기반동영상 콘텐츠 내 섬네일 및 하이라이트 검출 시스템."}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 프로세서는, 상기 복수의 제3 이미지 각각에 대해 세로줄 또는 가로줄의 RGB 합이 0인 영역을 탐지하여 잘라냄으로써 상하 또는 좌우 레터박스를 제거하는 것을 특징으로 하는 인공지능 기반 동영상 콘텐츠 내 섬네일및 하이라이트 검출 시스템."}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 프로세서는, 상기 복수의 제3 이미지 중 컬러 이미지를 흑백 이미지로 전환하고, 전환된 이미지를 앞 이미지 또는 뒤 이미지와 XOR 비트 연산을 행한 후, 두 이미지 내에서 값이 서로 다른 부분을 침식(erode)을 통해깎아냄으로써, 상하 또는 좌우 레터박스를 제거하는 것을 특징으로 하는 인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 시스템."}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 프로세서는, 상기 복수의 제3 이미지 각각을 고정된 비율로 크롭(crop)하여 이미지 크기를 조절하는 것을특징으로 하는 인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 시스템."}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 복수의 제3 인공 신경망 모델은 이벤트가 포함된 장면을 검출하는 액션 인식 모델(Action RecognitionModel), 오디오 파일을 사람의 목소리가 포함된 구간과 사람의 목소리가 포함되지 않은 구간으로 분리하는 소스분리 모델(Source Separation Model), 및 인물들의 대화 장면을 검출하는 음성 분할 모델(Speech SegmentationModel)을 포함하는 것을 특징으로 하는 인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 시스템."}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 프로세서는, 영상에서 추출한 오디오 파일을 상기 소스 분리 모델에 입력하여, 사람의 목소리가 포함된 구간과 사람의 목소리가 포함되지 않은 구간으로 분리된 오디오 파일을 획득하고, 획득된 오디오 파일을 상기 음성 분할 모델에 입력하여 해당 오디오 파일을 음성(speaking), 에너지 무(noEnergy), 잡음(noise), 및 음악(music) 구간으로 분류하며, 기설정된 시간을 초과하는 음악 구간을 BGM 구간으로 검출하는 것을 특징으로 하는인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 시스템."}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,공개특허 10-2024-0098458-4-상기 복수의 제4 인공 신경망은 얼굴을 검출하는 얼굴 검출 모델(Face Detection Model) 및 감정을 분석하는 감정 인식 모델(Emotion Recognition Model)을 포함하는 것을 특징으로 하는 인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 시스템."}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 프로세서는, 샷에 포함된 이미지 중 중간 이미지를 해당 샷을 대표하는 이미지로 지정하고, 상기 얼굴 검출 모델을 이용하여 얼굴을 검출하며, 얼굴이 검출된 샷에는 상기 얼굴 점수로 1점을 부여하고, 얼굴이 검출되지 않은 샷에는 상기 얼굴 점수로 0점을 부여하는 것을 특징으로 하는 인공지능 기반 동영상 콘텐츠 내 섬네일및 하이라이트 검출 시스템."}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 프로세서는, 클러스터링 기법에 기초하여 모든 샷에서 가장 많이 나온 얼굴을 주인공으로 지정하고, 주인공 얼굴에 상기 얼굴 점수로 1점을 추가 부여하는 것을 특징으로 하는 인공지능 기반 동영상 콘텐츠 내 섬네일및 하이라이트 검출 시스템."}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 프로세서는, 얼굴이 검출된 샷들을 상기 감정 인식 모델에 입력하여 감정과 확률을 연관지어 출력하고, 확률이 기설정된 값 이상인 감정의 확률을 해당 샷의 상기 감정 점수로 부여하는 것을 특징으로 하는 인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 시스템."}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 프로세서는, 각 샷마다의 오디오 정보를 추출한 후, 음성 데이터 분석 모듈을 이용하여 상기 오디오 정보의 음압을 측정하고, 측정된 음압을 정규화하여 샷의 상기 음압 점수로 부여하는 것을 특징으로 하는 인공지능기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 시스템."}
{"patent_id": "10-2022-0180221", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "섬네일 검출이 선택된 경우,적어도 하나의 프로세서가, 하나의 입력된 영상에서 섬네일을 탐색할 영상 구간을 선택하고, 선택된 영상 구간으로부터 제1 복수의 이미지를 추출하는 단계;상기 적어도 하나의 프로세서가, 제1 인공 신경망 모델을 이용하여, 추출된 제1 복수의 이미지 중 주요 대상이포함된 복수의 제2 이미지를 추출하는 단계;상기 적어도 하나의 프로세서가, 제2 인공 신경망 모델을 이용하여, 추출된 복수의 제2 이미지 중 자막이 없는복수의 제3 이미지를 추출하는 단계;상기 적어도 하나 이상의 프로세서가, 추출된 복수의 제3 이미지를 후처리하여 최종 섬네일 이미지 후보 리스트로 출력하는 단계;공개특허 10-2024-0098458-5-하이라이트 검출이 선택된 경우,상기 적어도 하나 이상의 프로세서가, 입력된 영상을 샷(shot) 단위로 분할하는 단계;상기 적어도 하나 이상의 프로세서가, 분할된 샷의 시각 및 음성 정보를 복수의 제3 인공 신경망 모델에 입력하여 복수의 하이라이트 후보군을 추출하는 단계;상기 적어도 하나 이상의 프로세서가, 복수의 제4 인공 신경망 모델을 이용하여 얼굴, 감정, 및 음압(decibel)을 토대로 샷마다의 얼굴 점수, 감정 점수, 및 음압 점수를 포함하는 하이라이트 점수를 계산하는 단계;상기 적어도 하나 이상의 프로세서가, 각 하이라이트 후보군에 포함된 샷들의 하이라이트 점수를 합산하여 총하이라이트 점수를 계산하는 단계; 및상기 적어도 하나 이상의 프로세서가, 상기 복수의 하이라이트 후보군 중 가장 높은 총 하이라이트 점수를 가지는 하이라이트 후보군을 최종 하이라이트 영상으로 출력하는 단계;를 포함하는 인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 방법."}
{"patent_id": "10-2022-0180221", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 방법 및 시스템에 관한 것으로서, 섬네일 검출이 선택된 경우, 하나의 입력된 영상에서 섬네일을 탐색할 영상 구간을 선택하고, 선택된 영상 구간으로부터 제1 복수의 이미지를 추출하는 단계; 제1 인공 신경망 모델을 이용하여, 추출된 제1 복수의 이미지 중 주요 대상 (뒷면에 계속)"}
{"patent_id": "10-2022-0180221", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥러닝 기반의 알고리즘들을 이용하여, 영상 콘텐츠 내에서 섬네일로 쓸 수 있는 중요한 이미지 스틸 컷과, 하이라이트와 같이 시청자들에게 흥미를 일으키는 특정 구간들을 자동으로 검출해주는 인공지능 기반 동 영상 콘텐츠 내 섬네일 및 하이라이트 검출 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2022-0180221", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 IPTV 서비스에서는, 콘텐츠 리스트의 이미지로서 세로형의 포스터보다 실제 화면의 스틸컷인 섬네일 이 제공되는 추세이다. 하나의 콘텐츠에서는 수십 개에서 수천 개의 섬네일이 추출될 수 있으며, 콘텐츠 리스트 에는 대표 섬네일이 노출되고 있다. 이러한 대표 섬네일은 섬네일 추출 시스템에서 임의로 선정되거나, 또는 각 OTT(Over The Top) 서비스 플랫폼마다의 섬네일 필수 또는 권장사항을 고려하여 편성자에 의해 수동으로 선택될 수 있다. 콘텐츠 리스트의 대표 섬네일은 해당 콘텐츠를 대표하는 이미지로서, 사용자가 한눈에 어떠한 콘텐츠인지를 확 인할 수 있어야 하고, 가장 인기있는 장면이 제공된다면 콘텐츠가 선택될 확률이 높아진다. 그러나 종래의 섬네일 추출의 경우 영상 내에서 편성자가 고른 이미지를 인풋으로 받아 포맷에 맞게 크기를 조 절하고 이미 만들어진 다양한 텍스트 템플릿을 제공하여 문구를 집어넣어 주는 수준에 불과하며, 섬네일 후보를 추천해주는 기능은 없었다. 한편, 사용자가 관심을 두는 특정 프로그램의 하이라이트 부분을 별도로 구성하기 위해서는 편집자가 직접 편집 기능을 이용해서 전체 프로그램을 재생해 가면서 해당 부분을 따로 편집해야 하는 불편함이 있었다. 선행기술문헌 특허문헌 (특허문헌 0001) 미국공개특허공보 제2019-0026563호 (특허문헌 0002) 국내공개특허공보 제10-2021-0104982호"}
{"patent_id": "10-2022-0180221", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2022-0180221", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 명세서는 상기한 바와 같은 문제점을 해결하기 위하여 안출된 것으로서, 사용자가 영상의 중요 구간을 찾기 위해 영상을 전부 시청하는 수고와 시간을 줄여줄 수 있는 인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이 트 검출 방법 및 시스템을 제공하는 데 그 목적이 있다. 또한, 본 발명의 다른 목적은 사람이 놓칠 수 있는 적절한 섬네일 후보 이미지 또는 하이라이트 구간들을 제시 해 줄 수 있는 인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 방법 및 시스템을 제공한다. 또한, 본 발명의 또 다른 목적은 영상 편집에 필요한 전문적인 프로그램과 인력이 없어도 자동으로 원하는 포맷 에 맞는 결과물을 생성할 수 있으므로 추가적인 후처리가 요구되지 않는 인공지능 기반 동영상 콘텐츠 내 섬네 일 및 하이라이트 검출 방법 및 시스템을 제공한다."}
{"patent_id": "10-2022-0180221", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이와 같은 목적을 달성하기 위한, 본 명세서의 실시예에 따르면, 본 명세서에 따른 인공지능 기반 동영상 콘텐 츠 내 섬네일 및 하이라이트 검출 시스템은, 메모리; 및 상기 메모리에 접속된 적어도 하나의 프로세서를 포함 하고, 상기 프로세서는, 섬네일 검출이 선택된 경우, 입력된 영상에서 섬네일을 탐색할 영상 구간을 선택하고, 선택된 영상 구간으로부터 제1 복수의 이미지를 추출한 후, 제1 인공 신경망 모델을 이용하여, 추출된 제1 복수 의 이미지 중 주요 대상이 포함된 복수의 제2 이미지를 추출하고, 제2 인공 신경망 모델을 이용하여, 추출된 복 수의 제2 이미지 중 자막이 없는 복수의 제3 이미지를 추출하며, 추출된 복수의 제3 이미지를 후처리하여 최종 섬네일 이미지 후보 리스트로 출력하고, 하이라이트 검출이 선택된 경우, 입력된 영상을 샷(shot) 단위로 분할 한 후, 분할된 샷의 시각 및 음성 정보를 복수의 제3 인공 신경망 모델에 입력하여 복수의 하이라이트 후보군을 추출하고, 복수의 제4 인공 신경망 모델을 이용하여 얼굴, 감정, 및 음압(decibel)을 토대로 샷마다의 얼굴 점 수, 감정 점수, 및 음압 점수를 포함하는 하이라이트 점수를 계산하며, 각 하이라이트 후보군에 포함된 샷들의 하이라이트 점수를 합산하여 총 하이라이트 점수를 계산한 후, 상기 복수의 하이라이트 후보군 중 가장 높은 총 하이라이트 점수를 가지는 하이라이트 후보군을 최종 하이라이트 영상으로 출력하는 것을 특징으로 한다. 바람직하게는, 상기 프로세서는, 주요 인물의 상반신 및 주요 인물의 얼굴 크기 비율을 고려하여 상기 복수의 제2 이미지를 선별하는 것을 특징으로 한다. 바람직하게는, 상기 프로세서는, 상기 복수의 제2 이미지 중 섬네일에 필요없는 요소들을 가진 이미지들을 추가 적으로 제외하는 것을 특징으로 한다. 바람직하게는, 상기 프로세서는, 상기 복수의 제2 이미지 중 자막이 있는 이미지를 제외하지 않고, 해당 이미지 내의 자막을 지우고 재채색하여 상기 복수의 제3 이미지로 출력하는 것을 특징으로 한다. 바람직하게는, 상기 프로세서는, 상기 복수의 제3 이미지 각각에 대해 상하 또는 좌우 레터박스를 제거하고, 기 설정된 규격에 맞게 이미지 포맷을 조절하여 최종 섬네일 이미지 후보 리스트로 출력하는 것을 특징으로 한다. 바람직하게는, 상기 프로세서는, 상기 복수의 제3 이미지 각각에 대해 세로줄 또는 가로줄의 RGB 합이 0인 영역 을 탐지하여 잘라냄으로써 상하 또는 좌우 레터박스를 제거하는 것을 특징으로 한다. 바람직하게는, 상기 프로세서는, 상기 복수의 제3 이미지 중 컬러 이미지를 흑백 이미지로 전환하고, 전환된 이 미지를 앞 이미지 또는 뒤 이미지와 XOR 비트 연산을 행한 후, 두 이미지 내에서 값이 서로 다른 부분을 침식 (erode)을 통해 깎아냄으로써, 상하 또는 좌우 레터박스를 제거하는 것을 특징으로 한다. 바람직하게는, 상기 프로세서는, 상기 복수의 제3 이미지 각각을 고정된 비율로 크롭(crop)하여 이미지 크기를 조절하는 것을 특징으로 한다. 바람직하게는, 상기 복수의 제3 인공 신경망 모델은 이벤트가 포함된 장면을 검출하는 액션 인식 모델(Action Recognition Model), 오디오 파일을 사람의 목소리가 포함된 구간과 사람의 목소리가 포함되지 않은 구간으로 분리하는 소스 분리 모델(Source Separation Model), 및 인물들의 대화 장면을 검출하는 음성 분할 모델(Speech Segmentation Model)을 포함하는 것을 특징으로 한다. 바람직하게는, 상기 프로세서는, 영상에서 추출한 오디오 파일을 상기 소스 분리 모델에 입력하여, 사람의 목소 리가 포함된 구간과 사람의 목소리가 포함되지 않은 구간으로 분리된 오디오 파일을 획득하고, 획득된 오디오파일을 상기 음성 분할 모델에 입력하여 해당 오디오 파일을 음성(speaking), 에너지 무(noEnergy), 잡음 (noise), 및 음악(music) 구간으로 분류하며, 기설정된 시간을 초과하는 음악 구간을 BGM 구간으로 검출하는 것 을 특징으로 한다. 바람직하게는, 상기 복수의 제4 인공 신경망은 얼굴을 검출하는 얼굴 검출 모델(Face Detection Model) 및 감정 을 분석하는 감정 인식 모델(Emotion Recognition Model)을 포함하는 것을 특징으로 한다. 바람직하게는, 상기 프로세서는, 샷에 포함된 이미지 중 중간 이미지를 해당 샷을 대표하는 이미지로 지정하고, 상기 얼굴 검출 모델을 이용하여 얼굴을 검출하며, 얼굴이 검출된 샷에는 상기 얼굴 점수로 1점을 부여하고, 얼 굴이 검출되지 않은 샷에는 상기 얼굴 점수로 0점을 부여하는 것을 특징으로 한다. 바람직하게는, 상기 프로세서는, 클러스터링 기법에 기초하여 모든 샷에서 가장 많이 나온 얼굴을 주인공으로 지정하고, 주인공 얼굴에 상기 얼굴 점수로 1점을 추가 부여하는 것을 특징으로 한다. 바람직하게는, 상기 프로세서는, 얼굴이 검출된 샷들을 상기 감정 인식 모델에 입력하여 감정과 확률을 연관지 어 출력하고, 확률이 기설정된 값 이상인 감정의 확률을 해당 샷의 상기 감정 점수로 부여하는 것을 특징으로 한다. 바람직하게는, 상기 프로세서는, 각 샷마다의 오디오 정보를 추출한 후, 음성 데이터 분석 모듈을 이용하여 상 기 오디오 정보의 음압을 측정하고, 측정된 음압을 정규화하여 샷의 상기 음압 점수로 부여하는 것을 특징으로 한다. 본 명세서의 다른 실시예에 따르면, 본 명세서에 따른 인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 방법은, 섬네일 검출이 선택된 경우, 적어도 하나의 프로세서가, 하나의 입력된 영상에서 섬네일을 탐색할 영상 구간을 선택하고, 선택된 영상 구간으로부터 제1 복수의 이미지를 추출하는 단계; 상기 적어도 하나의 프 로세서가, 제1 인공 신경망 모델을 이용하여, 추출된 제1 복수의 이미지 중 주요 대상이 포함된 복수의 제2 이 미지를 추출하는 단계; 상기 적어도 하나의 프로세서가, 제2 인공 신경망 모델을 이용하여, 추출된 복수의 제2 이미지 중 자막이 없는 복수의 제3 이미지를 추출하는 단계; 상기 적어도 하나 이상의 프로세서가, 추출된 복수 의 제3 이미지를 후처리하여 최종 섬네일 이미지 후보 리스트로 출력하는 단계; 하이라이트 검출이 선택된 경우, 상기 적어도 하나 이상의 프로세서가, 입력된 영상을 샷(shot) 단위로 분할하는 단계; 상기 적어도 하나 이상의 프로세서가, 분할된 샷의 시각 및 음성 정보를 복수의 제3 인공 신경망 모델에 입력하여 복수의 하이라 이트 후보군을 추출하는 단계; 상기 적어도 하나 이상의 프로세서가, 복수의 제4 인공 신경망 모델을 이용하여 얼굴, 감정, 및 음압(decibel)을 토대로 샷마다의 얼굴 점수, 감정 점수, 및 음압 점수를 포함하는 하이라이트 점수를 계산하는 단계; 상기 적어도 하나 이상의 프로세서가, 각 하이라이트 후보군에 포함된 샷들의 하이라이 트 점수를 합산하여 총 하이라이트 점수를 계산하는 단계; 및 상기 적어도 하나 이상의 프로세서가, 상기 복수 의 하이라이트 후보군 중 가장 높은 총 하이라이트 점수를 가지는 하이라이트 후보군을 최종 하이라이트 영상으 로 출력하는 단계를 포함한다."}
{"patent_id": "10-2022-0180221", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같이 본 명세서에 의하면, 딥러닝 기반의 알고리즘들을 이용하여, 영상 콘텐츠 내에서 섬 네일로 쓸 수 있는 중요한 이미지 스틸컷과 하이라이트를 자동으로 검출해주는 인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 방법 및 시스템을 제공함으로써, 사용자가 영상의 중요 구간을 찾기 위해 영상을 전 부 시청하는 수고와 시간을 줄일 수 있으며, 사람이 놓칠 수 있는 적절한 섬네일 후보 이미지 또는 하이라이트 구간들을 제시해 줄 수 있다. 또한, 영상 편집에 필요한 전문적인 프로그램과 인력이 없어도 자동으로 원하는 포맷에 맞는 결과물을 생성할 수 있으므로 추가적인 후처리가 요구되지 않는다. 나아가, 영화, 드라마, 예능과 같이 사람이 주로 등장하는 장르뿐만 아니라 애니메이션에서도 중요 장면들을 추 천할 수 있으며 요리, 게임, 스포츠 동영상 등으로도 확장할 수 있다. 또한, 다양한 딥러닝 기반 알고리즘들을 활용하며, 비주얼뿐만 아니라 오디오 정보도 함께 사용하여 더욱 로버 스트한 결과물을 생성할 수 있다."}
{"patent_id": "10-2022-0180221", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 기술적 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하 려는 의도가 아님을 유의해야 한다. 또한, 본 명세서에서 사용되는 기술적 용어는 본 명세서에서 특별히 다른 의미로 정의되지 않는 한, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 의미로 해석되어야 하며, 과도하게 포괄적인 의미로 해석되거나, 과도하게 축소된 의미로 해석되지 않아야 한다. 또한, 본 명세서에서 사용되는 기술적인 용어가 본 발명의 사상을 정확하게 표현하지 못하는 잘못된 기술 적 용어일 때에는, 당업자가 올바르게 이해할 수 있는 기술적 용어로 대체되어 이해되어야 할 것이다. 또한, 본 발명에서 사용되는 일반적인 용어는 사전에 정의되어 있는 바에 따라, 또는 전후 문맥상에 따라 해석되어야 하 며, 과도하게 축소된 의미로 해석되지 않아야 한다. 또한, 본 명세서에서 사용되는 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"구성된다\" 또는 \"포함한다\" 등의 용어는 명세서 상에 기재된 여러 구성 요소들, 또는 여러 단계들을 반드시 모두 포함하는 것으로 해석되지 않아야 하며, 그 중 일부 구성 요소들 또는 일부 단계들 은 포함되지 않을 수도 있고, 또는 추가적인 구성 요소 또는 단계들을 더 포함할 수 있는 것으로 해석되어야 한 다. 또한, 본 명세서에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에서 사용되는 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는 데 사용될 수 있지만, 상기 구성 요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으 면서 제1 구성요소는 제2 구성 요소로 명명될 수 있고, 유사하게 제2 구성 요소도 제1 구성 요소로 명명될 수 있다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일 하거나 유사한 구성 요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 또한, 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 발명의 사상을 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 발명의 사상이 제한되는 것으로 해석되어서는 아니됨을 유의해야 한다. 이하 설명에서 인공지능 기반 동영상 콘텐츠 내 섬네일 및 하이라이트 검출 시스템은 이동통신단말기, PDA(Personal Digital Assistant), 랩탑(Laptop), 스마트폰(Smart Phone), 넷북(Netbook), 텔레비전 (Television), 휴대 인터넷 장치(MID: Mobile Internet Device), 울트라 모바일 PC(UMPC: Ultra Mobile PC), 태블릿 PC(Tablet Personal Computer), 네비게이션 및 MP3 등을 포함한다. 도 1은 본 발명에 따른 섬네일 및 하이라이트 검출 시스템의 블록 구성을 도시하고 있다. 도 1을 참조하면, 섬네일 및 하이라이트 검출 시스템은 메모리, 프로세서 유닛(processor unit), 통신 시스템, 오디오 처리부, 카메라 시스템, 입출력 제어부, 표시부 및 입력 장치를 포함한다. 여기서, 메모리는 다수 개 존재할 수도 있다.각 구성요소에 대해 살펴보면 다음과 같다. 메모리는 섬네일 및 하이라이트 검출 시스템의 동작을 제어하기 위한 프로그램을 저장하는 프로그램 저장부 및 프로그램 수행 중에 발생되는 데이터를 저장하는 데이터 저장부를 포함한다. 예를 들어, 프로그램 저장부는 이미지 추출 프로그램(111a), 얼굴 이미지 검출 프로그램(111b), 이미지 제거 프로그램 (111c), 레터박스 제거 프로그램(111d), 이미지 포맷 조절 프로그램(111e), 섬네일 이미지 리스트 생성 프로그 램(111f), 샷(shot) 분할 프로그램(111g), 후보군 추출 프로그램(111h), 점수 부여 프로그램(111i), 점수 합산 프로그램(111j), 하이라이트 영상 생성 프로그램(111k), 그래픽 사용자 인터페이스 프로그램(111l) 및 적어도 하나의 응용 프로그램(111m)을 포함한다. 여기서, 프로그램 저장부에 포함되는 프로그램은 명령어들의 집 합으로 명령어 세트(instruction set)로 표현될 수도 있다. 다른 예를 들어, 데이터 저장부는 섬네일 이미 지 리스트 생성 프로그램(111f)이 생성한 섬네일 이미지 후보 리스트를 저장한다. 또한, 데이터 저장부는 하이라이트 영상 생성 프로그램(111k)이 생성한 하이라이트 영상을 저장한다. 이미지 추출 프로그램(111a)은 입력된 영상에서 섬네일을 탐색할 영상 구간을 선택하고, 선택된 영상 구간으로 부터 제1 복수의 이미지(프레임)를 추출하기 위한 적어도 하나의 소프트웨어 구성요소를 포함한다. 예를 들어, 이미지 추출 프로그램(111a)은 전체 영상 중 섬네일을 뽑고 싶은 구간을 선택한다. 이때, 이미지 추출 프로그램 (111a)은 영상의 모든 구간에서 섬네일을 탐색할 수 있다. 얼굴 이미지 검출 프로그램(111b)은 Yolo v5와 같은 딥러닝 검출 모델(제1 인공 신경망 모델에 해당)을 이용하 여, 추출된 제1 복수의 이미지 중 주요 대상(예를 들면, 주요 인물 또는 캐릭터(주인공))이 포함된 복수의 제2 이미지를 추출하는 적어도 하나의 소프트웨어 구성요소를 포함한다. 얼굴 이미지 검출 프로그램(111b)은 단순히 인물이 있는 프레임을 찾는 것이 아니라 인물의 상반신, 인물의 얼굴 크기 비율 등의 필터를 적용하여 해당되는 프레임만을 선별할 수 있다. 즉, 얼굴 이미지 검출 프로그램(111b)은 사람이나 캐릭터가 메인으로 등장하는 영 화, 드라마, 예능, 만화 장르뿐만 아니라 게임, 요리, 스포츠 장르에서도 영상에서 메인이 되는 주요 객체를 딥 러닝 기반 모델로 학습하여 검출할 수 있다. 예를 들면, 얼굴 이미지 검출 프로그램(111b)은 게임 영상에서는 게임 속 주요 캐릭터를 검출하고, 요리 영상에서는 음식을 검출하며, 스포츠 영상에서는 골 장면, 드리블 장면 등과 같이 사람이 취하는 동작을 검출할 수 있다. 이미지 제거 프로그램(111c)은 추출된 복수의 제2 이미지 중 자막이 있는 이미지를 제거하여 자막이 있는 복수 의 제3 이미지를 추출하는 적어도 하나의 소프트웨어 구성요소를 포함한다. 이미지 제거 프로그램(111c)은 딥러 닝 기반 모델인 글자 검출 모델(Text Detection Model, CRAFT)(제2 인공 신경망 모델에 해당)을 이용하여 이미 지 하단에서 글자를 검출하여 자막 여부를 확인하고, 자막이 있는 이미지들을 섬네일 후보군에서 제외시킨다. 본 발명의 실시예에서, 이미지 제거 프로그램(111c)은 자막이 포함된 이미지만을 제거하지만 이에 한정되는 것 은 아니며, 섬네일에 필요없는 요소들을 가진 이미지들도 추가로 제외시킬 수 있다. 예를 들면, 이미지 제거 프 로그램(111c)은 예능 등의 좌우 상단에 있는 프로그램 로고, 화면에 비춰지면 곤란한 물체(담배, 브랜드 로고 등)가 있는 이미지를 제외시킬 수 있다. 또한, 본 발명에 따른 이미지 제거 프로그램(111c)은 자막이 있는 이미지를 후보군에서 제외시키지 않고, 해당 이미지 내의 자막을 지우고 재채색할 수도 있다. 이때, 이미지 제거 프로그램(111c)은 자막을 지우기 위해 이미 지 복원 모델(Image Inpainting Model, LAMA)을 사용할 수 있다. 레터박스 제거 프로그램(111d)은 복수의 제3 이미지 각각에 대해 상하 또는 좌우 레터박스를 제거하는 적어도 하나의 소프트웨어 구성요소를 포함한다. 구체적으로는, 레터박스 제거 프로그램(111d)은 복수의 제3 이미지 각 각에 대해 세로줄 또는 가로줄의 RGB 합이 0인 영역(검은색의 RGB가 red=0, green=0, blue=0이므로)을 탐지하여 잘라냄으로써 상하 또는 좌우 레터박스를 제거할 수 있다. 한편, 도 5에 도시된 바와 같이, 이미지 내에 검은색이 아닌 레터박스가 존재할 수 있는데, 이를 해결하기 위해 레터박스 제거 프로그램(111d)은 다음의 방법을 사용할 수 있다. 도 5의 (a)에 도시된 바와 같이, 레터박스 제거 프로그램(111d)은 처리할 이미지를 선택한다. 도 5의 (b)에 도시된 바와 같이, 레터박스 제거 프로그램(111d)은 컬러 이미지를 흑백 이미지로 전환한다. 도 5의 (c)에 도시된 바와 같이, 레터박스 제거 프로그램(111d)은 앞뒤 이미지들에 대해 XOR 비트 연산을 수행 한다. 여기서, 'XOR 비트 연산'이란 두 이미지에서 값이 서로 같으면 검은색, 같지 않으면 흰색을 출력하는 연 산을 나타낸다. 일반적으로 레터박스는 워터마크처럼 색 변화 또는 움직임 변화없이 고정되어 있으므로, XOR 연산을 적용하면, 변화되는 가운데 영상 부분만 도드라지게 된다. 도 5의 (d)에 도시된 바와 같이, 레터박스 제거 프로그램(111d)은 이미지의 경계부분을 침식(erode)시켜 그 영 역을 깎아 낸다. 도 5의 (e)에 도시된 바와 같이, 레터박스 제거 프로그램(111d)은 앞서 이미지 침식을 통해 레터박스가 제거된 이미지를 완성한다. 이미지 포맷 조절 프로그램(111e)은 복수의 제3 이미지 각각에 대해 기설정된 규격에 맞게 이미지 포맷을 조절 하는 적어도 하나의 소프트웨어 구성요소를 포함한다. 예를 들면, 이미지 포맷 조절 프로그램(111e)은 1920× 1080 해상도, 16:9 비율로 복수의 제3 이미지 각각의 이미지 크기를 조절할 수 있다. 이때, 이미지 포맷 조절 프로그램(111e)은 이미지를 늘리는 것이 아니라 고정된 비율로 크롭(crop)한다. 한편, 콘텐츠를 올리려는 OTT(Over The Top)마다 섬네일 규격이 다르므로, 이미지 포맷 조절 프로그램(111e)은 각각의 OTT 권장규격에 맞 는 포맷을 지원할 수 있다. 섬네일 이미지 리스트 생성 프로그램(111f)은 앞서 레퍼박스 제거 및 이미지 포맷 조절을 포함한 후처리 과정을 거친 복수의 제3 이미지에 대한 최종 섬네일 이미지 리스트를 생성하는 적어도 하나의 소프트웨어 구성요소를 포함한다. 샷 분할 프로그램(111g)은 입력된 영상을 샷(shot) 단위로 분할하는 적어도 하나의 소프트웨어 구성요소를 포함 한다. 여기서, 샷 분할 프로그램(111g)은 딥러닝 기반의 샷 경계 검출 모델(Shot Boundary Detection Model)(Transnet V2)을 이용하여 영상을 n개의 샷으로 분할할 수 있다. 후보군 추출 프로그램(111h)은 분할된 샷의 시각 및 음성 정보를 복수의 제3 인공 신경망 모델에 입력하여 복수 의 하이라이트 후보군을 추출하는 적어도 하나의 소프트웨어 구성요소를 포함한다. 여기서, 후보군 추출 프로그 램(111h)은 키스씬, 포옹씬 및 결투씬 등의 중요한 이벤트가 포함된 장면을 검출하기 위해 액션 인식 모델 (Action Recognition Model)(PytorchVideo)을 사용하고, 장면의 분위기를 대변하는 BGM이 깔린 장면을 찾기 위 해 BGM 추출을 사용하며, 인물들의 대화 장면을 검출하기 위해 음성 분할 모델(Speech Segmentation Model)(inaSpeechSegmenter)을 사용할 수 있다. 특히, 후보군 추출 프로그램(111h)은 장면의 분위기를 잘 대변 하는 BGM 구간을 검출하기 위해서, 영상에서 추출한 오디오 파일을 소스 분리 모델(Source Separation Model)(Spleeter)에 입력하여, 사람의 목소리가 포함된 구간과 사람의 목소리가 포함되지 않은 구간으로 분리된 오디오 파일을 획득하고, 획득된 오디오 파일을 음성 분할 모델에 입력하여 해당 오디오 파일을 음성 (speacking), 에너지 무(noEnergy), 잡음(noise) 및 음악(music) 구간으로 분류하며, 기설정된 시간(예컨대, 30초)을 초과하는 음악 구간을 BGM 구간으로 검출한다. 여기서, 액션 인식 모델, 소스 분리 모델 및 음성 분할 모델은 본 발명의 복수의 제3 인공 신경망 모델의 일례에 해당된다. 점수 부여 프로그램(111i)은 얼굴을 검출하는 얼굴 검출 모델(Face Detection Model, Dlib) 및 감정을 분석하는 감정 인식 모델(Emotion Recognition Model, DeepFace)을 포함하는 복수의 제4 인공 신경망 모델을 이용하여 얼굴(face), 감정(emotion) 및 음압(decibel)을 토대로 샷마다의 얼굴 점수, 감정 점수 및 음압 점수를 포함하 는 하이라이트 점수를 계산하는 적어도 하나의 소프트웨어 구성요소를 포함한다. 즉, 점수 부여 프로그램(111 i)은 얼굴 검출 모델을 활용하여 얼굴이 검출된 샷에 얼굴 점수를 부여하고, 감정 인식 모델로 감정 분석을 수 행한 후, 감정 점수를 부여하며, 각 샷마다 음압을 측정하여 음압 점수를 부여한 후, 모든 모듈(얼굴 모듈, 감 정 모듈 및 음압 모듈)로부터 얻어진 점수를 더한 후 0~1 사이의 값으로 정규화하여 하이라이트 점수를 계산한 다. 구체적으로는, 점수 부여 프로그램(111i)은 샷에 포함된 프레임 중 중간 프레임을 해당 샷을 대표하는 프레임으 로 가정하고, 얼굴 검출 모델을 이용하여 얼굴을 검출하며, 얼굴이 검출된 샷에는 얼굴 점수로서 1점을 부여하 고, 얼굴이 검출되지 않은 샷에는 얼굴 점수로서 0점을 부여한다. 추가로, 점수 부여 프로그램(111i)은 클러스 터링(Clustering) 기법으로 모든 샷에서 가장 많이 나온 특정 얼굴을 주인공으로 가정하고, 주인공 얼굴에 얼굴 점수로서 1점을 추가 부여할 수 있다. 그리고 점수 부여 프로그램(111i)은 도 6에 도시된 바와 같이, 앞서 얼굴이 검출된 샷들만을 대상으로 감정 인 식 모델을 통해 감정 분석을 행한 후, 감정 분석 결과로서 감정과 확률(예를 들면, 기쁨=0.9, 분노=0.02, 슬픔 =0.08)을 출력하고, 이 중 0.5 이상의 확률을 가진 감정(도 6에서는 행복)의 확률값을 해당 샷의 감정 점수로 부여한다. 그리고 점수 부여 프로그램(111i)은 각 샷마다 오디오 정보를 추출한 후, 음성 데이터 분석 툴(librosa 모듈)을 이용하여 음압을 측정하고, 영상마다 스케일이 다를 수 있으므로, 측정된 음압을 0~1 사이의 값으로 정규화하여 음압 점수로 부여한다. 끝으로, 점수 부여 프로그램(111i)은 모든 모듈로부터 얻어진 점수를 더한 후 0~1 사이의 값으로 정규화하여 하 이라이트 점수를 계산한다. 점수 합산 프로그램(111j)은 각 하이라이트 후보군에 포함된 샷들의 하이라이트 점수를 합산하여 총 하이라이트 점수를 계산하는 적어도 하나의 소프트웨어 구성요소를 포함한다. 하이라이트 영상 생성 프로그램(111k)은 복수의 하이라이트 후보군 중 가장 높은 총 하이라이트 점수를 가지는 하이라이트 후보군을 최종 하이라이트 영상으로 출력하는 적어도 하나의 소프트웨어 구성요소를 포함한다. 즉, 하이라이트 영상 생성 프로그램(111k)은 기준이 되는 임계값을 정하고, 그 임계값보다 높은 점수를 가진 하이라 이트 후보군을 최종 하이라이트 영상으로 출력한다. 그래픽 사용자 인터페이스 프로그램(111l)은 영상의 섬네일 이미지 후보 리스트 및 하이라이트 영상을 표시부 에 표시하기 위한 소프트웨어 구성 요소를 포함한다. 예를 들어, 그래픽 사용자 인터페이스 프로그램 (111l)은 도 7에 도시된 바와 같이 섬네일 이미지 리스트 생성 프로그램(111f)에 의해 생성된 섬네일 이미지 후 보 리스트를 영상의 섬네일 이미지로 표시부에 표시한다. 응용 프로그램(111m)은 섬네일 및 하이라이트 검출 시스템에 설치된 적어도 하나의 응용 프로그램에 대한 소프트웨어 구성 요소를 포함한다. 프로세서 유닛은 메모리 인터페이스, 적어도 하나의 프로세서(processor) 및 주변 장치 인터페 이스를 포함한다. 여기서, 프로세서 유닛에 포함되는 메모리 인터페이스, 적어도 하나의 프로세 서 및 주변 인터페이스는 적어도 하나의 집적화된 회로로 집적화되거나 별개의 구성 요소로 구현될 수 있다. 메모리 인터페이스는 프로세서 또는 주변 장치 인터페이스와 같은 구성요소의 메모리에 대 한 접근을 제어한다. 주변 장치 인터페이스는 섬네일 및 하이라이트 검출 시스템의 입출력 주변 장치와 프로세서 및 메모리 인터페이스의 연결을 제어한다. 프로세서는 적어도 하나의 소프트웨어 프로그램을 사용하여 섬네일 및 하이라이트 검출 시스템이 다 양한 멀티미디어 서비스를 제공하도록 제어한다. 이때, 프로세서는 메모리에 저장되어 있는 적어도 하나의 프로그램을 실행하여 해당 프로그램에 따라 서비스를 제공하도록 제어한다. 예를 들어, 프로세서는 하기 도 2에 도시된 바와 같이, 이미지 추출 프로그램(111a)을 실행하는 이미지 추출 프로세서, 얼굴 이미 지 검출 프로그램(111b)을 실행하는 얼굴 이미지 검출 프로세서, 이미지 제거 프로그램(111c)을 실행하는 이미지 제거 프로세서, 레터박스 제거 프로그램(111d)을 실행하는 레터박스 제거 프로세서, 이미지 포맷 조절 프로그램(111e)을 실행하는 이미지 포맷 조절 프로세서, 섬네일 이미지 리스트 생성 프로그램 (111f)을 실행하는 섬네일 이미지 리스트 생성 프로세서, 샷 분할 프로그램(111g)을 실행하는 샷 분할 프 로세서, 후보군 추출 프로그램(111h)을 실행하는 후보군 추출 프로세서, 점수 부여 프로그램(111i)을 실행하는 점수 부여 프로세서, 점수 합산 프로그램(111j)을 실행하는 점수 합산 프로세서, 하이라이 트 영상 생성 프로그램(111k)을 실행하는 하이라이트 영상 생성 프로세서 및 그래픽 사용자 인터페이스 프 로그램(111l)을 실행하는 그래픽 사용자 인터페이스 프로세서를 포함한다. 통신 시스템은 음성 통신 및 데이터 통신을 위한 통신 기능을 수행한다. 이때, 통신 시스템은 서로 다른 통신 네트워크를 지원하는 다수 개의 통신 서브 모듈들로 구분될 수도 있다. 여기서, 통신 네트워크는 이 들에 한정하지는 않지만, GSM(Global System for Mobile Communication) 네트워크, EDGE(Enhanced Data GSM Environment) 네트워크, CDMA(Code Division Multiple Access) 네트워크, W-CDMA(W-Code Division Multiple Access) 네트워크, LTE(Long Term Evolution) 네트워크, OFDMA(Orthogonal Frequency Division Multiple Access) 네트워크, 무선랜, Bluetooth 네트워크 및 NFC(Near Field Communication) 등을 포함한다. 오디오 처리부는 스피커 및 마이크로폰을 통해 사용자와 섬네일 및 하이라이트 검출 시스템 사이의 오디오 인터페이스를 제공한다. 카메라 시스템은 동화상(moving picture) 데이터 및 정지 화상(still picture) 데이터를 촬영하는 기능을 수행한다. 입출력 제어부는 표시부 및 입력 장치 등의 입출력 장치와 주변 장치 인터페이스 사이에 인터페이스를 제공한다. 표시부는 섬네일 및 하이라이트 검출 시스템의 상태 정보, 사용자가 입력하는 문자, 동화상(moving picture) 및 정화상(still picture) 등을 표시한다. 표시부는 터치스크린으로 구성될 수도 있다. 이 경우, 표시부는 터치스크린의 터치 정보를 입출력 제 어부를 통해 프로세서 유닛으로 제공한다. 입력 장치는 사용자의 선택에 의해 발생하는 입력 데이터를 입출력 제어부를 통해 프로세서 유닛 으로 제공한다. 예를 들어, 입력 장치는 섬네일 및 하이라이트 검출 시스템의 제어를 위한 제어 버튼만을 포함하여 구성된다. 다른 예를 들어, 입력 장치는 사용자로부터 입력 데이터를 제공받기 위한 키 패드로 구성될 수도 있다. 도 2는 본 발명의 실시예에 따른 프로세서의 상세 블록 구성을 도시하고 있다. 도 2에 도시된 바와 같이, 프로세서는 이미지 추출 프로세서, 얼굴 이미지 검출 프로세서, 이미 지 제거 프로세서, 레터박스 제거 프로세서, 이미지 포맷 조절 프로세서, 섬네일 이미지 리스트 생성 프로세서, 샷 분할 프로세서, 후보군 추출 프로세서, 점수 부여 프로세서, 점수 합산 프로세서, 하이라이트 영상 생성 프로세서 및 그래픽 사용자 인터페이스 프로세서를 포함한다. 이미지 추출 프로세서는 프로그램 저장부의 이미지 추출 프로그램(111a)을 실행하여 입력된 영상에서 섬네일을 탐색할 영상 구간을 선택하고, 선택된 영상 구간으로부터 제1 복수의 이미지를 추출한다. 예를 들어, 이미지 추출 프로세서는 전체 영상 중 섬네일을 뽑고 싶은 구간을 선택한다. 이때, 이미지 추출 프로세서 는 영상의 모든 구간에서 섬네일을 탐색할 수 있다. 얼굴 이미지 검출 프로세서는 프로그램 저장부의 얼굴 이미지 검출 프로그램(111b)을 실행하여 제1 인공 신경망 모델을 이용하여, 추출된 제1 복수의 이미지 중 주요 대상(예를 들면, 주요 인물 또는 캐릭터(주인 공))이 포함된 복수의 제2 이미지를 추출한다. 얼굴 이미지 검출 프로세서는 단순히 인물이 있는 프레임을 찾는 것이 아니라 인물의 상반신, 인물의 얼굴 크기 비율 등의 필터를 적용하여 해당하는 프레임만을 선별할 수 있다. 즉, 얼굴 이미지 검출 프로세서는 사람이나 캐릭터가 메인으로 등장하는 영화, 드라마, 예능, 만화 장르뿐만 아니라 게임, 요리, 스포츠 장르에서도 영상에서 메인이 되는 주요 객체를 딥러닝 기반 모델로 학습하 여 검출할 수 있다. 이미지 제거 프로세서는 프로그램 저장부의 이미지 제거 프로그램(111c)을 실행하여 제2 인공 신경망 모델을 이용하여, 추출된 복수의 제2 이미지 중 자막이 있는 이미지를 제거하여 자막이 없는 복수의 제3 이미지 만을 추출한다. 이미지 제거 프로세서는 제2 인공 신경망 모델을 이용하여 이미지 하단에서 글자를 검출하 여 자막 여부를 확인하고, 자막이 있는 이미지들을 섬네일 후보군에서 제외시킨다. 레터박스 제거 프로세서는 프로그램 저장부의 레터박스 제거 프로그램(111d)을 실행하여 복수의 제3 이미지 각각에 대해 상하 또는 좌우 레터박스를 제거한다. 구체적으로는, 레터박스 제거 프로세서는 복수 의 제3 이미지 각각에 대해 세로줄 또는 가로줄의 RGB 합이 0인 영역(검은색의 RGB가 red=0, green=0, blue=0이 므로)을 탐지하여 잘라냄으로써 상하 또는 좌우 레터박스를 제거할 수 있다. 이미지 포맷 조절 프로세서는 프로그램 저장부의 이미지 포맷 조절 프로그램(111e)을 실행하여 복수 의 제3 이미지 각각에 대해 기설정된 규격에 맞게 이미지 포맷을 조절한다. 예를 들면, 이미지 포맷 조절 프로 세서는 1920×1080 해상도, 16:9 비율로 복수의 제3 이미지 각각의 이미지 크기를 조절할 수 있다. 이때, 이미지 포맷 조절 프로세서는 이미지를 늘리는 것이 아니라 고정된 비율로 크롭한다. 섬네일 이미지 리스트 생성 프로세서는 프로그램 저장부의 섬네일 이미지 리스트 생성 프로그램 (111f)을 실행하여 앞서 레퍼박스 제거 및 이미지 포맷 조절을 포함한 후처리 과정을 거친 복수의 제3 이미지에 대한 최종 섬네일 이미지 리스트를 생성한다. 샷 분할 프로세서는 프로그램 저장부의 샷 분할 프로그램(111g)을 실행하여 입력된 영상을 샷 단위로 분할한다. 여기서, 샷 분할 프로세서는 딥러닝 기반의 샷 경계 검출 모델(Shot Boundary Detection Model)(Transnet V2)을 이용하여 영상을 n개의 샷으로 분할할 수 있다.후보군 추출 프로세서는 프로그램 저장부의 후보군 추출 프로그램(111h)을 실행하여 분할된 샷의 시 각 및 음성 정보를 복수의 제3 인공 신경망 모델에 입력하여 복수의 하이라이트 후보군을 추출한다. 여기서, 후 보군 추출 프로세서는 키스씬, 포옹씬 및 결투씬 등의 중요한 이벤트가 포함된 장면을 검출하기 위해 액션 인식 모델(Action Recognition Model)(PytorchVideo)을 사용하고, 장면의 분위기를 대변하는 BGM이 깔린 장면 을 찾기 위해 BGM 추출을 사용하며, 인물들의 대화 장면을 검출하기 위해 음성 분할 모델(Speech Segmentation Model)(inaSpeechSegmenter)을 사용할 수 있다. 특히, 후보군 추출 프로세서는 장면의 분위기를 잘 대변하 는 BGM 구간을 검출하기 위해서, 영상에서 추출한 오디오 파일을 소스 분리 모델(Source Separation Model)(Spleeter)에 입력하여, 사람의 목소리가 포함된 구간과 사람의 목소리가 포함되지 않은 구간으로 분리된 오디오 파일을 획득하고, 획득된 오디오 파일을 음성 분할 모델에 입력하여 해당 오디오 파일을 음성 (speaking), 에너지 무(noEnergy), 잡음(noise), 및 음악(music) 구간으로 분류하며, 기설정된 시간(예컨대, 30초)을 초과하는 음악 구간을 BGM 구간으로 검출한다. 여기서, 액션 인식 모델, 소스 분리 모델 및 음성 분할 모델은 본 발명의 복수의 제3 인공 신경망 모델의 일례에 해당된다. 점수 부여 프로세서는 프로그램 저장부의 점수 부여 프로그램(111i)을 실행하여 얼굴을 검출하는 얼 굴 검출 모델(Face Detection Model, Dlib) 및 감정을 분석하는 감정 인식 모델(Emotion Recognition Model, DeepFace)을 포함하는 복수의 제4 인공 신경망 모델을 이용하여 얼굴(face), 감정(emotion) 및 음압(decibel) 을 토대로 샷마다의 얼굴 점수, 감정 점수 및 음압 점수를 포함하는 하이라이트 점수를 계산한다. 즉, 점수 부 여 프로세서는 얼굴 검출 모델을 활용하여 얼굴이 검출된 샷에 얼굴 점수를 부여하고, 감정 인식 모델로 감정 분석을 수행한 후, 감정 점수를 부여하며, 각 샷마다 음압을 측정하여 음압 점수를 부여한 후, 모든 모듈 (얼굴 모듈, 감정 모듈 및 음압 모듈)로부터 얻어진 점수를 더한 후 0~1 사이의 값으로 정규화하여 하이라이트 점수를 계산한다. 점수 합산 프로세서는 프로그램 저장부의 점수 합산 프로그램(111j)을 실행하여 각 하이라이트 후보 군에 포함된 샷들의 하이라이트 점수를 합산하여 총 하이라이트 점수를 계산한다. 하이라이트 영상 생성 프로세서는 프로그램 저장부의 하이라이트 영상 생성 프로그램(111k)을 실행하 여 복수의 하이라이트 후보군 중 가장 높은 총 하이라이트 점수를 가지는 하이라이트 후보군을 최종 하이라이트 영상으로 출력한다. 즉, 하이라이트 영상 생성 프로세서는 기준이 되는 임계값을 정하고, 그 임계값보다 높은 점수를 가진 하이라이트 후보군을 최종 하이라이트 영상으로 출력한다. 그래픽 사용자 인터페이스 프로세서는 프로그램 저장부의 그래픽 사용자 인터페이스 프로그램(111l) 을 실행하여 영상의 섬네일 이미지 후보 리스트 및 하이라이트 영상을 표시부에 표시한다. 도 3은 본 발명의 실시예에 따른 인공지능 기반 동영상 콘텐츠 내 섬네일 검출 절차를 도시하고 있다. 사용자는 섬네일 및 하이라이트 검출 시스템에서 섬네일 검출 또는 하이라이트 검출을 선택할 수 있다. 사 용자가 섬네일 검출을 선택한 경우, 본 발명에 따른 섬네일 및 하이라이트 검출 시스템은 이하의 절차를 수행한다. 도 3을 참조하면, 섬네일 및 하이라이트 검출 시스템은 입력된 영상에서 섬네일을 탐색할 영상 구간을 선 택하고, 선택된 영상 구간으로부터 제1 복수의 이미지를 추출한다(S310). 예를 들어, 섬네일 및 하이라이트 검 출 시스템은 전체 영상 중 섬네일을 뽑고 싶은 구간을 선택한다. 이때, 섬네일 및 하이라이트 검출 시스템 은 영상의 모든 구간에서 섬네일을 탐색할 수 있다. 섬네일 및 하이라이트 검출 시스템은 제1 인공 신경망 모델을 이용하여, 추출된 제1 복수의 이미지 중 주 요 대상(예를 들면, 주요 인물 또는 캐릭터(주인공))이 포함된 복수의 제2 이미지를 추출한다(S320). 섬네일 및 하이라이트 검출 시스템은 단순히 인물이 있는 프레임을 찾는 것이 아니라 인물의 상반신, 인물의 얼굴 크 기 비율 등의 필터를 적용하여 해당하는 프레임만을 선별할 수 있다. 섬네일 및 하이라이트 검출 시스템은 제2 인공 신경망 모델을 이용하여, 추출된 복수의 제2 이미지 중 자 막이 있는 이미지를 제거하여 자막이 없는 복수의 제3 이미지만을 추출한다(S330). 이때, 섬네일 및 하이라이트 검출 시스템은 제2 인공 신경망 모델을 이용하여 이미지 하단에서 글자를 검출하여 자막 여부를 확인하고, 자막이 있는 이미지들을 섬네일 후보군에서 제외시킨다. 섬네일 및 하이라이트 검출 시스템은 복수의 제3 이미지 각각에 대해 상하 또는 좌우 레터박스를 제거한다 (S340). 이때, 섬네일 및 하이라이트 검출 시스템은 복수의 제3 이미지 각각에 대해 세로줄 또는 가로줄의RGB 합이 0인 영역(검은색의 RGB가 red=0, green=0, blue=0이므로)을 탐지하여 잘라냄으로써 상하 또는 좌우 레 터박스를 제거할 수 있다. 섬네일 및 하이라이트 검출 시스템은 복수의 제3 이미지 각각에 대해 기설정된 규격에 맞게 이미지 포맷을 조절한다(S350). 이때, 섬네일 및 하이라이트 검출 시스템은 이미지를 늘리는 것이 아니라 고정된 비율로 크롭한다. 예를 들면, 섬네일 및 하이라이트 검출 시스템은 1920×1080 해상도, 16:9 비율로 복수의 제3 이미지 각각의 이미지 크기를 조절할 수 있다. 섬네일 및 하이라이트 검출 시스템은 앞서 단계 S340 및 단계 S350의 후처리 과정을 거친 복수의 제3 이미 지에 대한 최종 섬네일 이미지 리스트를 생성한다(S360). 도 4는 본 발명의 실시예에 따른 인공지능 기반 동영상 콘텐츠 내 하이라이트 검출 절차를 도시하고 있다. 사용자가 하이라이트 검출을 선택한 경우, 본 발명에 따른 섬네일 및 하이라이트 검출 시스템은 이하의 절 차를 수행한다. 섬네일 및 하이라이트 검출 시스템은 입력된 영상을 샷 단위로 분할한다(S410). 이때, 섬네일 및 하이라이 트 검출 시스템은 딥러닝 기반의 샷 경계 검출 모델(Shot Boundary Detection Model)(Transnet V2)을 이 용하여 영상을 n개의 샷으로 분할할 수 있다. 섬네일 및 하이라이트 검출 시스템은 분할된 샷의 시각 및 음성 정보를 복수의 제3 인공 신경망 모델에 입 력하여 복수의 하이라이트 후보군을 추출한다(S420). 이때, 섬네일 및 하이라이트 검출 시스템은 키스씬, 포옹씬 및 결투씬 등의 중요한 이벤트가 포함된 장면을 검출하기 위해 액션 인식 모델(Action Recognition Model)(PytorchVideo)을 사용하고, 장면의 분위기를 대변하는 BGM이 깔린 장면을 찾기 위해 BGM 추출을 사용하 며, 인물들의 대화 장면을 검출하기 위해 음성 분할 모델(Speech Segmentation Model)(inaSpeechSegmenter)을 사용할 수 있다. 특히, 섬네일 및 하이라이트 검출 시스템은 장면의 분위기를 잘 대변하는 BGM 구간을 검 출하기 위해서, 영상에서 추출한 오디오 파일을 소스 분리 모델(Source Separation Model)(Spleeter)에 입력하 여, 사람의 목소리가 포함된 구간과 사람의 목소리가 포함되지 않은 구간으로 분리된 오디오 파일을 획득하고, 획득된 오디오 파일을 음성 분할 모델에 입력하여 해당 오디오 파일을 음성(speacking), 에너지 무(noEnergy), 잡음(noise), 및 음악(music) 구간으로 분류하며, 기설정된 시간(예컨대, 30초)을 초과하는 음악 구간을 BGM 구 간으로 검출한다. 여기서, 액션 인식 모델, 소스 분리 모델 및 음성 분할 모델은 본 발명의 복수의 제3 인공 신 경망 모델의 일례에 해당된다. 섬네일 및 하이라이트 검출 시스템은 얼굴을 검출하는 얼굴 검출 모델(Face Detection Model, Dlib) 및 감 정을 분석하는 감정 인식 모델(Emotion Recognition Model, DeepFace)을 포함하는 복수의 제4 인공 신경망 모 델을 이용하여 얼굴(face), 감정(emotion) 및 음압(decibel)을 토대로 샷마다의 얼굴 점수, 감정 점수 및 음압 점수를 포함하는 하이라이트 점수를 계산한다(S430). 즉, 점수 부여 프로세서는 얼굴 검출 모델을 활용하 여 얼굴이 검출된 샷에 얼굴 점수를 부여하고, 감정 인식 모델로 감정 분석을 수행한 후, 감정 점수를 부여하며, 각 샷마다 음압을 측정하여 음압 점수를 부여한 후, 모든 모듈(얼굴 모듈, 감정 모듈 및 음압 모듈) 로부터 얻어진 점수를 더한 후 0~1 사이의 값으로 정규화하여 하이라이트 점수를 계산한다. 섬네일 및 하이라이트 검출 시스템은 각 하이라이트 후보군에 포함된 샷들의 하이라이트 점수를 합산하여 총 하이라이트 점수를 계산한다(S440). 섬네일 및 하이라이트 검출 시스템은 복수의 하이라이트 후보군 중에 기설정된 임계값을 초과하는 총 하이 라이트 점수를 가진 하이라이트 후보군이 존재하는지 여부를 판단하고(S450), 기설정된 임계값을 초과하는 하이 라이트 후보군이 존재하는 경우, 해당 하이라이트 후보군을 최종 하이라이트 영상으로 출력한다(S460). 전술한 방법은 다양한 수단을 통해 구현될 수 있다. 예를 들어, 본 발명의 실시예들은 하드웨어, 펌웨어 (Firmware), 소프트웨어 또는 그것들의 결합 등에 의해 구현될 수 있다. 하드웨어에 의한 구현의 경우, 본 발명의 실시예들에 따른 방법은 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 프로세서, 컨트롤러, 마이크로컨트롤러 및 마이크로프로세서 등에 의해 구현될 수 있다. 펌웨어나 소프트웨어에 의한 구현의 경우, 본 발명의 실시예들에 따른 방법은 이상에서 설명된 기능 또는 동작 들을 수행하는 모듈, 절차 또는 함수 등의 형태로 구현될 수 있다. 소프트웨어 코드는 메모리 유닛에 저장되어프로세서에 의해 구동될 수 있다. 상기 메모리 유닛은 상기 프로세서 내부 또는 외부에 위치하여, 이미 공지된 다양한 수단에 의해 상기 프로세서와 데이터를 주고 받을 수 있다. 이상에서 본 명세서에 개시된 실시예들을 첨부된 도면들을 참조로 설명하였다. 이와 같이 각 도면에 도시된 실 시예들은 한정적으로 해석되면 아니되며, 본 명세서의 내용을 숙지한 당업자에 의해 서로 조합될 수 있고, 조합 될 경우 일부 구성 요소들은 생략될 수도 있는 것으로 해석될 수 있다. 여기서, 본 명세서 및 청구범위에 사용된 용어나 단어는 통상적이거나 사전적인 의미로 한정해서 해석되어서는 아니 되며, 본 명세서에 개시된 기술적 사상에 부합하는 의미와 개념으로 해석되어야만 한다. 따라서 본 명세서에 기재된 실시예와 도면에 도시된 구성은 본 명세서에 개시된 실시예에 불과할 뿐이고, 본 명 세서에 개시된 기술적 사상을 모두 대변하는 것은 아니므로, 본 출원시점에 있어서 이들을 대체할 수 있는 다양 한 균등물과 변형예들이 있을 수 있음을 이해하여야 한다."}
{"patent_id": "10-2022-0180221", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 섬네일 및 하이라이트 검출 시스템의 블록 구성, 도 2는 본 발명의 실시예에 따른 프로세서의 상세 블록 구성, 도 3은 본 발명의 실시예에 따른 인공지능 기반 동영상 콘텐츠 내 섬네일 검출 절차, 도 4는 본 발명의 실시예에 따른 인공지능 기반 동영상 콘텐츠 내 하이라이트 검출 절차, 도 5는 이미지 내에 검은색이 아닌 레터박스가 존재할 때의 레터박스 제거 방법을 설명하기 위한 도면, 도 6은 감정 인식 모델을 이용하여 샷마다의 감정 점수를 부여하는 방법을 설명하기 위한 도면, 및 도 7은 섬네일 이미지 후보 리스트의 예시화면을 나타낸 도면이다."}
