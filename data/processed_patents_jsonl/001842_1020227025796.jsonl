{"patent_id": "10-2022-7025796", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0130141", "출원번호": "10-2022-7025796", "발명의 명칭": "오류 복구를 위한 시스템 및 방법", "출원인": "마이크로소프트 테크놀로지 라이센싱, 엘엘씨", "발명자": "푸디페디 바라드와지"}}
{"patent_id": "10-2022-7025796", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "시스템으로서, 복수의 인공 지능 프로세서와, 하나 이상의 제어기와, 상기 하나 이상의 제어기 및 상기 복수의 인공 지능 프로세서에 의해 실행가능한 프로그램 코드가 저장되어 있는 메모리를 포함하되, 상기 프로그램 코드는 상기 시스템으로 하여금, 데이터 세트로부터의 데이터의 제1 처리 반복 동안 복수의 인공 지능 프로세서 중 제1 인공 지능 프로세서에서컴퓨팅 오류를 검출하게 하고, 상기 제1 인공 지능 프로세서로부터 상기 오류를 제거하게 하며, 상기 제1 인공 지능 프로세서를 포함하는 상기 인공 지능 프로세서들 중 하나 이상의 인공 지능 프로세서에 모델을 로딩하게 하되, 상기 모델은 상기 데이터 세트로부터의 상기 데이터의 상기 제1 처리 반복 동안 상기 복수의 인공 지능 프로세서에 의해 처리된 동일 모델에 대응하는, 시스템."}
{"patent_id": "10-2022-7025796", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제1 인공 지능 프로세서 이외의 상기 복수의 인공 지능 프로세서는, 상기 제1 인공 지능 프로세서가 상기오류를 제거하는 동안 대기하고, 상기 복수의 프로세서는 동시에 상기 제1 처리 반복 시에 사용된 동일 모델로부터 생성된 제2 동일 모델을 사용하여 다음 처리 반복 시에 상기 데이터 세트로부터의 데이터를 처리하는, 시스템."}
{"patent_id": "10-2022-7025796", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 컴퓨팅 오류는 상기 제1 처리 반복의 결과 집계 단계(result aggregation phase) 동안 검출되고, 상기 복수의 인공 지능 프로세서의 적어도 일부분은 상기 제1 인공 지능 프로세서가 상기 결과 집계 단계를 완료하기전에 상기 집계 단계 동안 유효한 결과(valid result)를 생성하기를 기다리는, 시스템."}
{"patent_id": "10-2022-7025796", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 제1 인공 지능 프로세서는 상기 복수의 인공 지능 프로세서의 상기 적어도 일부분에 무효한 결과 표시자(invalid result indicator)를 전송하여 대기하게 하는, 공개특허 10-2022-0130141-3-시스템."}
{"patent_id": "10-2022-7025796", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 결과 집계 단계는 올 리듀스(All-Reduce)인, 시스템."}
{"patent_id": "10-2022-7025796", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 모델을 로딩하는 것은, 상기 제1 인공 지능 프로세서를 포함하는 상기 하나 이상의 인공 지능 프로세서 내에 상기 모델의 상이한 부분을 로딩하는 것을 포함하고, 상기 시스템은, 상기 제1 인공 지능 프로세서를 포함하는 상기 복수의 인공 지능 프로세서에서, 상기 제1 처리 반복 시에 상기 제1 인공 지능 프로세서에 의해수신된, 상기 데이터의 제1 부분을 처리하는 것을 더 포함하는, 시스템."}
{"patent_id": "10-2022-7025796", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 모델을 로딩하는 것은, 상기 제1 인공 지능 프로세서에 상기 모델을 로딩하는 것을 포함하고, 상기 시스템은 상기 제1 인공 지능 프로세서에서 상기 제1 처리 반복 시에 상기 제1 인공 지능 프로세서에 의해 수신된 상기 데이터의 제1 부분을 더 처리하는, 시스템."}
{"patent_id": "10-2022-7025796", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 모델은 제어기로부터 상기 제1 인공 지능 프로세서에서 수신되는, 시스템."}
{"patent_id": "10-2022-7025796", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 모델은 상기 복수의 인공 지능 프로세서 중 하나 이상의 다른 프로세서로부터 상기 제1 인공 지능 프로세서에서 수신되는, 시스템."}
{"patent_id": "10-2022-7025796", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 모델은 상기 제1 인공 지능 프로세서의 로컬 메모리로부터 상기 제1 인공 지능 프로세서에서 수신되는, 공개특허 10-2022-0130141-4-시스템."}
{"patent_id": "10-2022-7025796", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 모델은 인공 지능 파라미터를 포함하는, 시스템."}
{"patent_id": "10-2022-7025796", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서, 상기 모델은 신경망 가중치를 포함하는, 시스템."}
{"patent_id": "10-2022-7025796", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서, 상기 데이터 세트는 트레이닝 데이터 세트인, 시스템."}
{"patent_id": "10-2022-7025796", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "컴퓨터 시스템에 의해 실행가능한 프로그램 코드가 저장되어 있는 컴퓨터 판독가능 저장 매체로서, 상기 프로그램 코드는 상기 컴퓨터 시스템으로 하여금, 데이터 세트로부터의 데이터의 제1 처리 반복 동안 복수의 인공 지능 프로세서 중 제1 인공 지능 프로세서에서컴퓨팅 오류를 검출하게 하고, 상기 제1 인공 지능 프로세서로부터 상기 오류를 제거하게 하며, 상기 제1 인공 지능 프로세서를 포함하는 상기 인공 지능 프로세서들 중 하나 이상의 인공 지능 프로세서에 모델을 로딩하게 하되, 상기 모델은 상기 데이터 세트로부터의 상기 데이터의 상기 제1 처리 반복 동안 상기 복수의 인공 지능 프로세서에 의해 처리된 동일 모델에 대응하는, 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2022-7025796", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "오류 복구 방법으로서, 데이터 세트로부터의 데이터의 제1 처리 반복 동안 복수의 인공 지능 프로세서 중 제1 인공 지능 프로세서에서컴퓨팅 오류를 검출하는 단계와, 상기 제1 인공 지능 프로세서로부터 상기 오류를 제거하는 단계와, 상기 제1 인공 지능 프로세서를 포함하는 상기 인공 지능 프로세서들 중 하나 이상의 인공 지능 프로세서에 모델을 로딩하는 단계 - 상기 모델은 상기 데이터 세트로부터의 상기 데이터의 상기 제1 처리 반복 동안 상기 복수의 인공 지능 프로세서에 의해 처리된 동일 모델에 대응함 - 를 포함하는, 공개특허 10-2022-0130141-5-오류 복구 방법."}
{"patent_id": "10-2022-7025796", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 실시예는, 컴퓨팅 오류를 검출하는 단계와, 데이터 세트를 처리하는 복수의 인공 지능 프로세서 중 제 1 인공 지능 프로세서를 다시 시작하는 단계와, 인공 지능 프로세서에 모델을 로딩하는 단계를 포함하는 오류 복 구 방법을 포함하되, 이 모델은 데이터 세트로부터의 데이터에 대해 복수의 인공 지능 프로세서에 의한 이전의 처리 반복 동안 복수의 인공 지능 프로세서에 의해 처리된 동일 모델에 대응한다."}
{"patent_id": "10-2022-7025796", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 개시는 컴퓨팅에 관한 것이다. 보다 구체적으로, 본 개시는 인공 지능 처리에서 오류 복구를 위한 기술에 관한 것이다. 인공 지능(AI) 처리는 일반적으로 AI 모델(예컨대, 신경망 모델)의 일부 또는 전부를 하나 이상의 프로세서에 로딩하는 것을 포함한다. 데이터 세트가 AI 모델의 입력에 인가되고 출력이 생성된다. 추론을 위해, 출력은 입력 데이터 세트의 특정 특징의 분류(classification) 또는 인식(recognition)에 대응할 수 있다. 트레이닝을 위해, 출력이 입력 데이터에 대한 알려진 출력과 비교되고, 오류(error)가 모델을 통해 역전파되며, 모델의 파 라미터가 조정된다. 대형 모델 및 데이터 세트의 경우, 더 빠르게 결과를 얻기 위해 처리(processing)가 다수 의 프로세서에 걸쳐 나누어질 수 있다. 이러한 시스템의 한 가지 문제는 멀티프로세서 시스템의 한 노드에서 오류가 발생하는 경우이다. 많은 경우, 계산을 다시 시작하려면 많은 양의 데이터를 다시 계산해야 할 수 있다."}
{"patent_id": "10-2022-7025796", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하의 설명에서, 설명을 위해, 본 개시를 완전히 이해할 수 있도록 여러 예 및 특정 세부사항이 제시된다. 이 러한 예 및 세부사항은 전체적으로 청구범위의 구성요소 또는 청구 대상을 과도하게 제한하는 것으로 해석되어 서는 안 된다. 서로 다른 청구항들의 언어에 기초하여, 청구 대상이 단독으로 또는 조합하여 이들 예의 특징들중 일부 또는 전부를 포함할 수도 있고, 여기에 설명된 특징 및 기술의 변형 및 균등물을 더 포함할 수도 있다 는 것은 당업자에게 분명할 것이다. 인공 지능(AI) 처리 시스템은 흔히 대규모 데이터를 처리하기 위해 요구된다. 분산 처리는 처리 속도를 높인다. 예를 들어, 동기식 또는 하이브리드 데이터 병렬 처리를 이용하는 딥 러닝에서의 분산 트레이닝은 많 은 AI 프로세서에 걸쳐 높은 스루풋 및 정확도로 모델을 모으는 효과적인 방법이다. (예컨대, 트레이닝을 위해) AI 네트워크에서 사용되는 하나의 예시적인 기술을 데이터 병렬 처리(data parallelism)라고 한다. 데이터 병렬 처리는 트레이닝 데이터 세트를 조각들로 나누고, AI 프로세서에 데이터 를 병렬로 처리하는 모델이 로딩된다. 예를 들어, 데이터 병렬 처리의 일 실시예에서, 트레이닝 데이터가 조각 들(일명, 샤드(shards))로 분할될 수 있고, 각각의 샤드는 처리를 위해 복수의 AI 프로세서(일명 작업자 또는 타겟 프로세서)에 걸쳐 분산될 수 있다. 샤드는 차례로 미니배치(minibatch)로 나누어지며, 이는 연속적인 반 복(iteration)에서 복수의 AI 프로세서에 의해 반복적으로 처리된다. 각 반복 동안, AI 프로세서는 미니배치 (예컨대, 트레이닝 데이터)를 수신하고 모델 파라미터(일명 \"그라디언트\" 또는 \"델타\")의 변경 사항을 결정한다. 각 반복이 끝날 때, AI 프로세서는 모델 파라미터를 결합하고 동기화할 수 있으며, 모델은 새로운 파라미커 값으로 업데이트된다. 본 개시의 특징 및 이점은 장애(failure)로부터 복구하기 위한 프로세스를 포함한다. 도 1은 모델(M)을 사용하 여 데이터를 병렬로 처리하도록 구성된 복수의 AI 프로세서를 나타낸다. 이 예에서, AI 프로세서는 복수의 N개 의 작업자 그룹(101-103)으로 구성되는데, 여기서 N은 정수이다. 작업자 그룹은, 예를 들어 하나 이상의 AI 프 로세서를 포함할 수 있다. AI 프로세서는 그래픽 프로세서(GPU), AI 가속기 또는 AI 작업에 최적화된 기타 디 지털 프로세서(예컨대, 행렬 곱셈 대 x86 프로세서와 같은 폰 노이만(Von Neuman) 아키텍처 프로세서)를 포함할 수 있다. 예시적인 AI 프로세서는 GPU(예컨대, 800개의 코어 및 64개의 MultiAccumulators가 있는 NVidia Volta®) 또는 TPU(Tensor Processor Unit)(예컨대, 병렬로 16k 작업이 있는 4개 코어)를 포함할 수 있다. 이 예는 각 작업자 그룹이 입력 데이터(예컨대, 미니배치)를 수신하고 모델(105-107)을 사용하여 데이터를 처리 하는 반복을 예시한다. 이 예에서, 반복은 110에서 시작되며, 여기서 각 작업자 그룹은 실질적으로 동일한 모 델로 시작한다. 예를 들어, 이전 반복의 일부로서, 각 작업자 그룹의 모델(105-107)은 (예컨대, 올 리듀스 (All-Reduce)를 수행함으로써) 파라미터를 동기화했을 수 있다. 일 실시예에서, 모델의 하나 이상의 사본이, 예를 들어, 각 반복 사이클 사이에 모델로서 저장될 수 있다. 111에서, 각 작업자 그룹은, 예를 들어 동 일한 트레이닝 데이터 세트로부터의 미니배치와 같은 상이한 입력 데이터를 처리한다. 그러나, 이 예에서, 작 업자 그룹 중 하나는 오류(예컨대, 하드웨어 장애 또는 소프트웨어 장애)를 경험한다. 유리하게는, 112에 서, 반복의 시작에 사용된 저장된 모델은 작업자 그룹으로 로딩될 수 있고 작업자 그룹은 결과 를 생성하기 위해 처리를 신속하게 다시 시작할 수 있다. 112에서, 모든 작업자 그룹(101-103)의 결과는 결합 되어 업데이트된 모델을 생성할 수 있고, 결과 모델은, 예를 들어 다음 반복을 위해 다시 저장될 수 있다. 아 래에서 더 자세히 설명되는 다양한 실시예에서, 오류를 경험하는 작업자 그룹은, 예를 들어 제어기(아래에 표시 됨), 다른 작업자 그룹, 또는 작업자 그룹에 로컬인 메모리로부터 새 모델을 수신할 수 있다. 도 2는 일 실시예에 따른 오류 복구 방법을 도시한 것이다. 201에서, 컴퓨팅 오류가 감지된다. 예를 들어, 컴 퓨팅 오류는 데이터 세트를 처리하는 복수의 인공지능 프로세서 중 AI 프로세서의 소프트웨어 오류 또는 하드웨 어 오류일 수 있다. 202에서, AI 프로세서가 오류를 제거할 수 있다. 예를 들어, 일부 실시예에서, AI 프로세 서의 일부 또는 모든 요소(예컨대, 하드웨어 또는 소프트웨어 구성요소)가 다시 시작될 수 있다. 아래의 다양 한 실시예에 도시된 바와 같이, AI 프로세서는, 예컨대 AI 프로세서에 결합된 제어기에 의해 재시작될 수 있다. 203에서, 모델이 AI 프로세서에 로딩되며, 여기서 모델은 데이터 세트로부터의 데이터에 대한 복수의 AI 프로세 서에 의한 이전 처리 반복 동안 복수의 AI 프로세서에 의해 처리된 동일한 모델에 대응한다. 본 개시의 특징 및 이점은 작업자 그룹이 신속하게 재시작하기 위해 처리의 각 반복의 초반에 사용되는 모델에 액세스할 수 있는 것을 포함한다. 통상적으로, AI 시스템은, 시스템의 상태 정보가 저장된 글로벌 체크 포인트 (global check point)에 도달하기 전에, 많은 반복을 거쳤을 것이다. 오류로 인해 일부 시스템은 많은 반복을 통해 글로벌 체크 포인트로 돌아가야 했으며, 이는 시간이 많이 소요되었다. 유리하게는, 장애를 경험한 AI 프 로세서는 현재 반복의 시작부로 돌아갈 수 있는 반면, 다른 프로세서는 현재 반복 결과 생성을 완료할 때 기다 릴 수 있다. 실패한 AI 프로세서가 재설정되고 오류가 해결되면, 현재 반복 모델을 다시 로딩하고 재개할 수 있다. 여기서 설명된 바와 같이, 모델은 오류 상태를 경험하는 AI 프로세서에 액세스할 수 있는 여러 다른 위 치에 저장될 수 있다. 예시적인 AI 모델은 특정 AI 토폴로지에 대한 가중치 또는 바이어스와 같은 AI 파라미터의 조합이다. 모델을 처리하는 것은 각 반복 동안 그라디언트를 생성하는 것을 포함할 수 있다. 그라디언트는 현재 파라미터 값(예컨대, 신경망의 특정 가중치에 대한 델타 값)과의 편차(델타)를 포함할 수 있다. 그라디언 트는 각 AI 프로세서에 의해 처리 결과로서 생성되고, 결합(예컨대, 평균, 중간 등을 통해 집계됨)된 다음, 반 복 시작 시 모델 값에 적용될 수 있다. 예를 들어, 신경망 모델의 모든 가중치에 대한 평균 델타를 계산하고, 평균 델타를 적용하여 다음 반복에 사용되는 후속 모델을 생성할 수 있다. 도 3은 일 실시예에 따른, 트레이닝을 수행하는 컴퓨터 처리 시스템에서의 오류 복구를 도시한 것이다. 이 예 에서, 트레이닝 데이터는 신경망의 가중치와 같은 AI 모델의 파라미터를 트레이닝하는 데 사용된다. 트레 이닝 데이터 세트는 조각들(본 명세서에서 슬라이스 또는 \"샤드\"로 지칭됨)(302a-N)로 분할될 수 있다. 샤드는 처리를 위해 다른 작업자 그룹으로 차례로 전달된다. 샤드들 각각은 더 작은 조각들(303a-N)(본 명세서 에서 \"미니배치\" 또는 때른 그저 \"배치\"라고도 함)로 분할될 수 있다. 각 샤드의 미니배치(303a-N)는 한 번에 하나씩 작업자 그룹(304a-N)에 순차적으로 결합된다. 작업자 그룹은 트레이닝 데이터의 미니배치(minibatch)를 수신하고, 모델에 대해 AI 트레이닝을 수행하며, 트레이닝 결과를 생성할 수 있다. 각 작업자 그룹으로부 터의 트레이닝 결과는 350에서 결합되어 업데이트된 모델을 생성할 수 있으며, 이는 예를 들어 다음 미니 배치를 처리하기 위해 각 작업자 그룹에 로딩될 수 있다. 여기서 사용된 \"에포크(epoch)\"는, 모든 작업자 그룹 이 모든 샤드를 처리하고 하나의 전체 트레이닝 데이터 세트가 한 번 처리되었을 때 일어난다. 트레이닝 데이터 세트는, 예를 들어, 모델 파라미터의 최종 트레이닝 세트에 도달하기 위해 다수의 에포크에 걸쳐 처리될 수 있다. 다수의 작업자 그룹에 걸쳐 데이터 세트를 파티셔닝 및 처리하는 다른 방식이 여기에 설 명된 오류 복구 기술을 사용할 수 있음을 이해해야 한다. 이 예에서, 반복은 작업자 그룹(304a-N)에 의해 미니배치를 수신하는 것과, 미니배치를 처리하여 결과를 생성하 는 것과, 결과를 결합하여 업데이트된 모델을 생성하는 것을 포함한다. 반복은 업데이트된 모델을 작업자 그룹 에(예컨대, 반복의 시작 또는 끝에) 로딩하는 것을 더 포함한다. 도 3은 N번째 미니배치(minibatch_i)가 처리 를 위해 N(예컨대, 여기서 N은 정수임)개의 작업자 그룹(304a-N)으로 로딩되는 i번째 반복을 예시한다. 이전 (i-1)번째 반복에서 생성된 i번째 모델(M_i)은 각 작업자 그룹(304a-N)에 로딩된다. 각 minibatch_i를 처리한 결과는 350에서 결합되어 후속(또는 다음) 모델인 model_i+1을 생성하고, 이는 이후 i+1번째 반복 에서 i+1번째 미니배치를 처리하기 위해 작업자 그룹(304a-N) 각각에 로딩된다. 전술한 바와 같이, 작업자 그 룹 중 하나에 오류(예컨대, 하드 또는 소프트 장애)가 발생하는 경우, 각 작업자 그룹이 액세스를 위해 각 반복 에 대한 모델을 사용할 수 있다. 따라서, 작업자 그룹(304b)이, 예를 들어 minibatch_i를 처리하는 동안 실패 하면, i번째 모델(M_i)을 다시 로딩하고 처리를 완료할 수 있다. 다른 시스템은 작업자 그룹(304b)에 오류가 발생했음을 감지하고 기다릴 수 있다. 작업자 그룹(304b)이 오류를 해결하고 결과를 생성하면, 작업자 그룹의 결과들이 결합되고 컴퓨팅이 계속된다. 도 4는 AI 데이터를 처리하기 위한 컴퓨팅 아키텍처를 도시한 것이다. 이 예에서, 복수의 작업자 그룹이 제어 기에 결합되고, 제어기는 네트워크에 결합될 수 있다. 예를 들어, 작업자 그룹(410a-N)은 제어기에 결합 되고 작업자 그룹(411a-M)은 제어기에 결합된다. 제어기(401, 402)는 네트워크를 통해(예컨대, 이더 넷 접속 및 하나 이상의 네트워크 스위치를 통해 - 도시되어 있지 않음) 함께 결합될 수 있다. 작업자 그룹은 또한 링크(451 및 452)와 같은 통신 링크(예컨대, PCIe)를 통해 함께 결합될 수 있다. 이러한 복수의 제어기/ 작업자 그룹은, 예를 들어 트레이닝 데이터에 대해 위에서 설명한 바와 같이 AI 데이터를 병렬로 처리하는 데 사용될 수 있다. 다양한 실시예에서, 위에서 설명된 처리 결과의 결합(예컨대, delta_parameters)은, 예를 들 어, 작업자 그룹 사이에서(예컨대, 올 리듀스(all reduce)를 통해) 제어기에 의해, 또는 이들의 조합을 사용하 여 수행될 수 있다. 전술한 바와 같이, 각 작업자 그룹은 하나 이상의 작업자를 포함할 수 있으며, 각 작업자는 곱셈 및 덧셈 (multiply-accumulate, \"MAC\"), 행렬 곱셈(\"MatMul\") 및 기타 연산을 수행하는 데 최적화된 하나 또는 복수의 GPU, TPU 또는 다른 AI 프로세서일 수 있다. 제어기를 때론 호스트 또는 게이트웨이라고도 한다. 제어기는, 예를 들어 기존 CPU, FPGA, SoC(System on a Chip), ASIC(Application Specific Integrated Circuits) 또는 임베디드 ARM 제어기, 예컨대 소프트웨어를 실행하고 소프트웨어의 명령에 기초하여 작업자 그룹과 통신할 수 있는 기타 프로세서일 수 있다. 시스템은 소프트웨어가 타겟 장치 수행해야 하는 작업을 구성하고 제어할 수 있도록 하는 드라이버를 포함할 수 있다. 전형적인 동기식 데이터 병렬 처리 흐름의 고수준 표현이 도 5에 도시되어 있다. 이 예에서, 모든 반복은 작업 자 그룹(WG)에 걸친 모델의 동기화로 끝난다. 전통적으로, 전역 체크포인트는 작업자 그룹의 오류 또는 실패로 부터 복구하기 위해 주기적으로 수행된다. 일부 이전 시스템에 따른 빈번한 체크포인트는 처리량을 심각하게저하시킬 수 있으므로, 글로벌 체크포인트가 흔히 분산되었다(예컨대, 1시간에 한 번). 그러나 한 가지 잠재적 인 문제는, 이러한 오류로부터의 복구도 도 6에 도시된 바와 같이 느리다는 것이다. 도 6에 도시된 장애로 인 해, 모든 작업자 그룹이 중단되고 글로벌 체크포인트로 스냅백된다. 오류 또는 장애가 충분히 자주 발생하면 (예컨대, 대규모 클러스터의 포이즈닝(poisoning)), 성능에 심각한 영향을 미칠 수 있다. 본 개시의 특징 및 이점은, 전체 그룹을 글로벌 체크포인트로 스냅백할 필요 없이 훨씬 더 빠른 복구(예컨대, 몇 시간이 아닌 몇 초 이내)를 위해 이전 반복으로부터의 모델에 액세스함으로써, 대규모 클러스터 내에서 발생 하는 오류 및 특정 장애를 복구한다. 도 7에 도시된 바와 같이 그리고 전술한 바와 같이, 하나 이상의 작업자 그룹에서 발생하는 오류는 현재 반복 동안 해결될 수 있으며, 여기서 반복 시작 시 사용된 모델을 기반으로 로 컬 재계산이 수행된다. 따라서, 오류가 발생한 작업자 그룹이 신속하게 복구될 수 있으며, 모든 작업자 그룹은, 예를 들어 다수의 이전 반복의 데이터를 다시 처리할 필요 없이 후속 반복을 진행할 수 있다. 본 개시의 실시예는, 복구를 위해 액세스 가능한 빠른 중복 사본(redundant copy)이 있는 한, 상태(예컨대, 모 델)가 이전 상태로부터 재계산될 수 있다는 정보를 활용할 수 있다. 따라서, 일 실시예에서, 현재 모델의 \"마 스터 사본(master copy)\"(예컨대, 작업자 그룹에 의해 반복의 시작에 사용된 신경망 가중치와 같은 파라미터)이 (예컨대, 제어기의) 각 작업자 그룹에 의해 액세스가능한 위치에 저장될 수 있다. 마스터 사본은 재계산에 필 요한 최소 상태 정보만 있으면 되므로 현재 반복의 모델 사본은 일부 재계산 가능한 상태 정보(예컨대, 활성 화)를 갖지 않을 수 있다는 것에 주의한다. 또는, 마스터 사본은 작업자 그룹에 오류가 발생하는 경우 특정 작 업자 그룹이 로컬로 액세스할 수 있도록 작업자 그룹(예컨대, 오류 수정 코드(ECC)로 보호된 로컬 메모리 내)에 직접 상주할 수도 있다. 또 다른 실시예에서, 각 작업자 그룹은 오류 조건을 경험할 수 있는 다른 작업자 그룹 이 사용할 수 있도록 처리 중에 업데이트되지 않는 현재 반복에 대한 모델의 추가 사본을 유지한다. 유리하게 는, 현재 반복에 대한 모델이 각 작업자 그룹에 의해 유지 관리되는 경우, 모델의 상이한 부분들(전체 모델의 상이한 서브세트들)이 다수의 상이한 작업자 그룹에 의해 동시에 실패한 작업자 그룹으로 전송될 수 있는데, 이 는, 예컨대 일부 아키텍처에서, 제어기로부터 실패한 작업자 그룹으로 모델을 전송하는 것보다 훨씬 빠를 수 있 다. 일 실시예에서, 모델의 중복 사본은 작업자 그룹에 걸쳐 분산되어 각 작업자 그룹이 두 사본의 두 개의 상이한 섹션을 얻을 수 있다(예컨대, 두 사본의 동일한 섹션을 운반하는 경우, 작업자 그룹의 장애는 회복할 수 없는 손실을 입을 것이다). 마스터 사본은 반복이 끝날 때마다 자주 업데이트될 수 있다. 또한 로컬 업데이트를 허 용하는 특정 형태의 데이터 병렬 처리에서 더 자주 업데이트될 수 있다. 마지막으로, 일부 실시예에서, 제어기 는 작업자 그룹의 작업자에 의해 복구할 수 없는 오류(예컨대, 패리티 오류)에 대해 또는 예를 들어 글로벌 타 임아웃에서 추정되는 복구 시간보다 훨씬 더 작을 수 있지만 오류를 인식할 만큼 충분히 큰 로컬 타임아웃이 설 정된 경우를 통지받을 수 있다. 타임아웃에 대한 대안으로, 작업자는 제어기에 하트비트(heartbeat)를 전송하 여, 작업자가 오류를 경험한 시점을 제어기에서 확인할 수 있다. 다양한 실시예에서, 복구 방법은 장애 사례에 의존할 수 있다. 패리티 오류(포이즈닝(poisoning))의 경우, 제 어기는 작업자 그룹을 재설정하여 동일한 미니배치 데이터를 사용하여 모델의 마스터 사본에서 다시 실행할 수 있다. 로컬 타임아웃(또는 하트비트 누락)의 경우, 제어기는 실패한 작업자를 강제로 재설정할 수 있다(예컨대, 측파대 동작을 통해). 이것이 성공하면, 위의 패리티 오류 또는 포이즈닝의 경우와 같이 복구가 진행된다. 반복적인 시도 후에도 성공하지 못하면, 제어기는 예를 들어 동일한 작업자 그룹에서 덜 효율적인 모델을 다시 컴파일하거나 전용 예비 작업자 그룹을 사용할 수 있다. 이들 옵션 중 어느 것도 작동하지 않거나 사용 가능하지 않은 경우, 제어기는 고장일 수 있다. 제어기가 고장인 경우, 모든 제어기는 매 반복이 끝날 때마다 모델의 동일한 마스터 사본을 가질 수 있다. 따 라서, 제어기 고장으로 글로벌 타임아웃되더라도, 글로벌 체크포인트로 되돌아갈 필요가 없다. 예를 들어, 제 어기는 소프트웨어가 새로운 클러스터 크기에 대해 동작 가능한 작업자 그룹 및 데이터 샤드를 재조정한 후에 현재 반복 지점에서 계속할 수 있다. 다양한 실시예에서, 이전 반복의 끝에서부터 중복 사본의 복구에 대한 다수의 방법이 있을 수 있다. 한 실시예 에서, 제어기는 메모리에 자체 사본으로부터 사본을 제공한다. 다른 실시예에서, 실패한 작업자 그룹은 로컬 메모리(예컨대, 직접 연결 ECC 보호 메모리)에 마스터 사본을 가질 수 있다. 또 다른 실시예에서, 실패한 작업 자 그룹은 (예컨대, 병렬로) 하나 이상의 동작 가능한 작업자 그룹으로부터 사본을 수집한다. 도 8은 제어기 측이 작업자 그룹의 타겟 장치와 상호작용하는 예시적인 오류 복구 방법을 도시한 것이다. 여기 서, \"장치\"는 작업자 또는 작업자 그룹(예컨대, 모델의 한 사본을 공유하는 장치 그룹)이다. 이 예에서,도시를 단순화하기 위해 하나의 장치만 표시하지만, 제어기는 각 장치에 대한 프로세스를 가질 수 있 다. 화살표(850-857)는, 예컨대 제어기와 인공 지능 프로세서 간의 데이터 및/또는 제어 정보 흐름을 보여준다. 도 8에 도시된 예시적인 방법은 복수의 반복을 보여준다. 801에서, 제어기가 장치를 초 기화할 수 있다. 따라서, 장치는 예를 들어, 820에서 소프트 리셋을 수행할 수 있다. 802에서, 모델이 초기화되고, 장치들이 각각 초기 모델의 사본을 수신할 수 있다. 803 및 804에서, 각각의 제어기 및 관련 장치가 초기 동기화를 수행한다. 반복은 첫 번째 반복을 나타내는 804에서 시작한다(예컨대, iter=1). 805에서, 제어기가 데이터의 미니배치로 하여금 각 장치로 전송되게 한다(예컨대, DevId는 장치 식별자임). 각 장치는 823에서 데이터를 수신하고 824에서 모델에 대해 데이터를 실행한다. 825에 서, 장치는 오류를 검출할 수도 있고 검출하지 않을 수도 있다. 유사하게, 제어기는 처리 동안 오류 에 대해 장치를 폴링할 수 있다. 예를 들어, 825에서 장치에 의해 또는 806에서 제어기에 의해 오류가 검출되 지 않으면, 제어기와 장치는 809 및 829에서 동기화되고, 제어기는, 예를 들어 다음 반복을 시작할 수 있 다. 그러나, 825에서 오류가 장치에 의해 검출되면, 오류가 있는 장치는 826에서 제어기가 이를 재 설정하기를 기다릴 수 있다. 이 예에서, 제어기는 806에서 오류가 있는 장치의 장치 ID(\"devID\")를 검출 하고 807에서 장치의 소프트 리셋을 수행할 수 있다. 808에서, 제어기는 현재 반복 동안 사용된 모델의 사본을 오류가 있는 장치로 전송할 수 있다. 827에서, 장치는 소프트 리셋을 수행하고, 828에서 장치는 모델을 수신하 고 로딩한다. \"RecoverModel\" 박스는, 예를 들어, 복구 기술에 대한 전술한 실시예들 중 하나에 대응할 수 있 다. 그런 다음 장치는 823에서 데이터를 다시 로딩하고, 824에서 다시 로딩된 모델에 대해 데이터를 실행할 수 있다. 오류가 발생하지 않은 다른 장치는 대기 상태에 들어가고 오류가 발생한 장치는 반복 처리를 완료한 후 재개할 수 있다. 본 명에서에 설명된 일부 실시예에서, 다른 장치는 모델의 일부와 데이터의 일부를 수신할 수 있으며, 오류가 발생한 장치에 대한 데이터의 로딩 및 재처리는, 예를 들어 복구 시간을 줄이기 위해 여러 장치 에 의해 수행될 수 있다. 도 9의 장애(제어기-복구)의 일 실시예에서, 제어기는 마스터 사본을 가질 수 있다. 이 예에서, \"n\"개의 제어 기(901-905)가 \"k\"개의 작업자 그룹(예컨대, 하나 이상의 인공 지능 프로세서의 \"k\" 그룹) 및 메모리(911- 914)에 각각 결합될 수 있다. 각 반복에서, 모델의 마스터 사본은, 예를 들어 제어기(901-905)에 결합된 메모 리(911-914)에 저장될 수 있다. 메모리는, 예를 들어 저장된 모델의 무결성을 보장하기 위해 오류 수정 코드 (ECC)로 보호될 수 있다. 제어기가 로컬 타임아웃(또는 하트비트 누락) 또는 포이즈닝을 감지하면 복구가 시작 될 수 있다. 두 경우 모두, 결함이 있는 작업자는 소생할 수 있는 것으로 간주된다. 작업자 자체가 죽는 경우, 제어기는 글로벌 체크포인트로 돌아가 클러스터를 재조정해야만 수정할 수 있는 오류 신호를 보낼 수 있 다. 결함이 있는 작업자가 죽는 다른 시나리오에서, 제어기는 나머지 작업자에 대해 동일한 미니배치를 재조정 할 수 있다(가능한 경우에만). 작업자가 감지 가능한 소프트 오류 포이즈닝만 보고할 수 있지만, 도 9에 도시 된 예시적인 사례는 완전히 복구할 수 있다. 전술한 바와 같이, 제2 실시예(자체 복구)에서, ECC 보호 메모리가 각 작업자에 첨부된다. 작업자가 포이즈닝 을 감지하면 자가 복구를 시도한다. 첨부된 ECC 메모리로부터 모델/그래프/데이터를 다시 시작하고 로딩하여 동일한 미니배치를 다시 시도한다. 포이즈닝은 더 빠른 회복을 위해 범주별로 더 세분화될 수 있다. 예를 들 어, 작업자가 포이즈닝이 발생한 위치(주소 범위별)를 지정하면, 재시작 전에 복구 코드를 사용하여 해당 세그 먼트만 수정한다. 자가 복구의 경우, 작업자가 이 목적을 위한 전용 코어가 하나 있는 경우 가능한 워치독 타 이머 인터럽트(자체 하트비트)를 포함하면, 소프트 행 작업자는 여전히 복구할 수 있다. 제3 실시예(이웃 복구)에서, 제어기가 있거나 없는 k개의 작업자(예컨대, T1 내지 Tk)를 가진 작업자 그룹은 같 은 미니배치에서 여전히 작동 중인 더 작은 그룹으로 재그룹화함으로써 심각한 장애가 발생한 경우에도 복구할 수 있다. 이를 달성하기 위해, 그룹은 모델의 리던던시를 포함할 수 있다. 이는 작업자 그룹이 여러 작업자에 걸쳐 모델을 분할하는 모델 분할(모델 병렬 처리)에서 특히 가능하다(예컨대, 상이한 작업자가 모델의 상이한 부분을 처리함). 이 분할에서, 각 작업자 메모리의 일부는 상호 배타적인 방식으로 다른 작업자 모델 상태의 중복 사본(예컨대, 복구에 필요한 최소 모델 상태만)을 수용한다. 예를 들어, 작업자(T1)가 세그먼트 Seg를 업데이트할 때마다, 작업자(Tk)의 중복 상태도 업데이트한다. 이는 하드웨어 지원 미러링 쓰기, 소프트웨어 쓰 기로 수행하거나, 또는 예를 들어 올 리듀스 후 모델 업데이트 동안 수행될 수 있다.표 1"}
{"patent_id": "10-2022-7025796", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "따라서, 다양한 실시예에서, 중복 사본 배포를 사용하여, 임의의 새로운(또는 재시작된) 타겟이 다른 멤버로부 터의 온전한 사본을 수집할 수 있는 방식으로 둘 이상의 사본이 상호 배타적인 파티션에 배포될 수 있다(즉, 동 일한 타겟이 다른 사본의 동일한 세그먼트를 보유하지 않음). 두 개의 사본이 있으면 하나의 장애 복구를 보장 하고, 세 개의 사본은 두 개의 장애 복구를 보장하는 식이다. 그러나, 큰 클러스터가 소프트 오류를 복구하거 나 또는 다시 시작하는 경우에도 두 개의 사본이 사용될 수도 있다. 따라서, 다양한 실시예에서, 복구는, 제어기에 저장되거나, 작업자 그룹에 로컬로 저장되거나, 또는 작업자 그 룹 내의 다수의 작업자에 대해 동일한 작업자 그룹의 다수의 작업자에 걸쳐 배타적으로 분할(예컨대, 작업자가 모델의 겹치는 섹션을 가지지 않도록 원본 사본에 독점적으로 분할)될 수 있는 현재 반복 모델의 마스터 사본을 사용하는 로컬일 수 있다. 따라서, 마스터 사본은 다수의 작업자가 작업자 그룹에 있을 때 동일한 작업자 그룹에 걸쳐 실행 중인 사본과 상호 배타적으로 분할될 수 있다. 한 가지 예시적인 대안은, 손상되지 않은 사본 중 하나를 다시 시작되는 타 겟 또는 대체 타겟에 수집하여 장애가 복구될 수 있도록 하는 방식으로, 두 개 이상의 사본이 작업자들에 걸쳐 상호 배타적으로 분할될 수 있다. 다른 실시예에서, 사본은 특정 타겟으로부터의 중복 사본일 수 있다. 도 10은 일 실시예에 따른 결과 집계 단계에서 오류가 발생한 경우의 복구를 도시한 것이다. 일부 실시예에서, 각 반복의 결과 집계 단계 동안 발생하는 오류로부터 복구하는 것이 유리할 수 있다. 예를 들어, 도 10에 도시 된 바와 같이, 반복은 1001에서 모든 작업자 그룹에 걸쳐 모델을 동기화하는 것을 포함할 수 있다. 1002에서 미니배치가 수신되고 모델에 적용되어 결과를 생성한다. 결과 집계 단계의 시작인 1003에서 사후 데이터 동기 화가 발생할 수 있다. 경우에 따라, 데이터가 모델에 적용된 후 인공 지능 프로세서 중 하나에서 오류가 발생 할 수 있다. 일반적으로, 각 작업자 그룹은, 예를 들어 데이터의 각 미니배치가 처리된 후, 모델 파라미터의 변경을 나타내는 델타 값(예컨대, 그라디언트)의 고유 벡터를 생성할 수 있다. 도 11은 일 실시예에 따른 예시적인 결과 생성을 도시한 것이다. 여기서, N개의 작업자 그룹(WG0-WGN)(N은 정 수)이 길이가 M인 N개의 벡터를 생성한다(예컨대, 여기서 M은 모델의 신경망 가중치 수와 동일한 정수이다). 예를 들어, 각 벡터에서 델타 값(Δij)는 부동 소수점 숫자일 수 있다. 시스템이 작동 중일 때(예컨대, 오류 없음), 각 작업자 그룹에 의해 생성된 벡터는 다른 모든 작업자 그룹에 전달되고, 각 작업자 그룹은 각 벡터로 부터 필드의 한 서브세트를 집계한다. N개의 작업자 그룹의 경우, N개의 파티션이 있을 수 있으며 각 작업자 그룹은 다른 작업자 그룹으로부터 수신한 벡터의 특정 필드에 대한 결과를 집계한다. 예를 들어, 작업자 그룹 (WG0)은 다른 작업자 그룹으로부터 벡터를 수신하고, Δ1j-Δij 필드를 집계하여, 예를 들어 결과 어레이(R0)를 생성할 수 있다. 집계는, 예를 들어 AI 처리 분야의 당업자에게 알려진 가중치 또는 다른 기능의 평균을 포함 할 수 있다. 그러나, 결과를 처리하는 동안 작업자 그룹 중 하나에 오류가 발생하면, 작업자 그룹이 다른 작업 자 그룹에 무효한 결과 표시자(invalid result indicator)를 보낼 수 있다. 이 예에서, WG0은 가비지 비트(여 기서 \"xxxx\"로 표시됨)를 포함하는 M개의 길이 결과 벡터를 보낸다. 결과를 처리하는 동안, 다른 작업자 그룹 이 나머지 작업자 그룹 중 임의의 작업자 그룹으로부터 무효한 결과 표시자를 수신하면, 해당 작업자 그룹이 대 기 상태로 전환될 수 있다. 따라서, 오류가 발생한 작업자 그룹이 오류를 제거하고 유효한 결과를 처리하는 동 안 작업자 그룹들이 기다릴 수 있다. 도 12는 일 실시예에 따른 결과 집계의 예를 도시한 것이다. 일부 실시예에서, 작업자 그룹은 링으로 구성될 수 있으며, 여기서 작업자 그룹은 그라디언트의 벡터(위에서 설명됨)를 전달한 다음 결과(예컨대, 집계된 그라 디언트)를 다른 작업자 그룹에 전달할 수 있다. 이 예에서, 각 작업자 그룹은 집계된 그라디언트의 결과 어레 이를 수신할 수 있다. 모든 작업자 그룹이 다른 모든 작업자 그룹의 모든 결과를 갖고 있는 경우, 각 작업자 그룹은 모델 버전을 수정하는데 이용할 수 있는 전체 집계 결과 세트를 갖고 있을 것이다. 이 예에서, 모든 작 업자 그룹이 동일한 모델로 시작했기 때문에, 모델을 업데이트할 때마다 모델이 거의 동일하게 유지될 것이다(예컨대, AI 파라미터가 함께 변경되어 각 작업자 그룹이 모든 반복에서 실질적으로 동일한 모델을 갖게 된다). 다시, 작업자 그룹에 오류가 발생하면, 그 작업자 그룹은 무효한 결과 표시자를 출력할 수 있으며, 나머지 다른 작업자 그룹은 오류가 발생한 작업자 그룹이 복구되어 유효한 결과를 보낼 때까지 기다릴 수 있다. 도 13은 일 실시예에 따른, 다중 프로세서 컴퓨팅 환경에서의 오류 복구를 도시한 것이다. 이 예에서, 작업자 그룹은 오류를 경험하고 무효한 결과 표시자(x)를 출력한다. 다른 작업자 그룹(예컨대, 1300, 1302)은 유효한 기울기 벡터 Δ(예컨대, 1310, 1312)를 생성할 수 있다. 이 예에서, 다른 작업자 그룹 각각은 작업자 그룹이 오류를 제거하고 유효한 결과를 생성할 때까지 기다릴 수 있다. 그런 다음 시스템은, 예 를 들어 각 작업자 그룹이 업데이트된 모델을 갖도록 그라디언트의 유효한 벡터를 전달하고, 집계된 결과를 계 산하고, 결과 집계 단계 동안 다른 작업자 그룹에 결과를 전달할 수 있다. 도 14는 일 실시예에 따른, 다수의 프로세서에 걸쳐 고장난 프로세서에 대한 계산을 분배하는 것을 도시한 것이다. 일부 실시예에서, 작업자 그룹이 오류를 검출하고 제거할 때, 모델의 다른 부분이 오류를 경험하는 작업자 그룹을 포함하는 작업자 그룹들에 걸쳐 로딩될 수 있다. 따라서, 오류가 발생한 작업자 그룹에 대해 특정 반복 동안 결과를 다시 계산하는 시간을 줄일 수 있다. 도 14에 도시된 바와 같이, 작업자 그룹(1410-1413)은, 예를 들어 동일한 모델을 사용하여 미니배치를 처리할 수 있다. 여기서, 작업자 그룹에 오류가 발생한다. 그 러나, 이 예에서, 현재 반복에 대한 모델은 작업자 그룹를 포함한 다수의 작업자 그룹에 걸쳐 분할된다. 도 14를 참조하면, 작업자 그룹가 오류를 제거하면, 작업자 그룹이 작업자 그룹(1410-1413) 전체에 걸쳐 모델의 로딩을 트리거할 수 있다. 따라서, 현재 반복에서 작업자 그룹에 의해 처리되도록 의 도된 트레이닝 데이터의 부분은, 예를 들어 복구 시간을 줄이기 위해 다중 작업자 그룹(1410-1413)에서 처리될 수 있다. 추가 실시예들 다양한 실시예에서, 본 개시는 오류 복구 방법을 포함한다. 이 방법은 컴퓨터 컴퓨터 시스템에 의해 실행가능 한 프로그램 코드가 저장되어 있는 비일시적 컴퓨터 판독가능 매체로 구현될 수 있으며, 프로그램 코드는 컴퓨 터 시스템으로 하여금 본 명세서에 설명된 기술들을 수행하게 한다. 일부 실시예에서, 컴퓨터 시스템은 복수의 인공 지능 프로세서 및 하나 이상의 제어기를 포함할 수 있다. 비일시적 컴퓨터 판독가능 저장 매체는, 예를 들면, 하나 이상의 제어기 또는 하나 이상의 인공 지능 프로세서에 결합될 수 있는 메모리일 수 있다. 다음 기술들은 독립적으로 또는 다른 조합으로 구현될 수 있고 또한 본 명세서에 설명된 다른 기술들로 구현될 수도 있다. 예를 들어, 일 실시예에서, 본 개시는 데이터 세트로부터의 데이터의 제1 처리 반복 동안 복수의 인공 지능 프 로세서 중 제1 인공 지능 프로세서에서 컴퓨팅 오류를 검출하는 단계와, 제1 인공 지능 프로세서로부터 오류를 제거하는 단계와, 제1 인공 지능 프로세서를 포함하는 인공 지능 프로세서들 중 하나 이상의 인공 지능 프로세 서에 모델을 로딩하는 단계 - 모델은 데이터 세트로부터의 데이터의 제1 처리 반복 동안 복수의 인공 지능 프로 세서에 의해 처리된 동일 모델에 대응함 - 를 포함하는, 오류 복구 방법을 포함한다. 일 실시예에서, 제1 인공 지능 프로세서 이외의 복수의 인공 지능 프로세서는, 제1 인공 지능 프로세서가 오류 를 제거하는 동안 대기하고, 복수의 프로세서는 동시에 제1 처리 반복 시에 사용된 동일 모델로부터 생성된 제2 동일 모델을 사용하여 다음 처리 반복 시에 데이터 세트로부터의 데이터를 처리한다. 일 실시예에서, 컴퓨팅 오류는 제1 처리 반복의 결과 집계 단계 동안 검출되고, 복수의 인공 지능 프로세서의 적어도 일부분은 제1 인공 지능 프로세서가 결과 집계 단계를 완료하기 전에 집계 단계 동안 유효한 결과(valid result)를 생성하기를 기다린다. 일 실시예에서, 제1 인공 지능 프로세서는 복수의 인공 지능 프로세서의 적어도 일부분에 무효한 결과 표시자 (invalid result indicator)를 전송하여 대기하게 한다. 일 실시예에서, 결과 집계 단계는 올 리듀스(All-Reduce)이다. 일 실시예에서, 모델을 로딩하는 것은, 제1 인공 지능 프로세서를 포함하는 하나 이상의 인공 지능 프로세서 내 에 모델의 상이한 부분을 로딩하는 것을 포함하고, 시스템은, 제1 인공 지능 프로세서를 포함하는 하나 이상의 인공 지능 프로세서에서, 제1 처리 반복 시에 제1 인공 지능 프로세서에 의해 수신된, 데이터의 제1 부분을 처 리하는 것을 더 포함한다. 일 실시예에서, 모델을 로딩하는 것은, 제1 인공 지능 프로세서에 모델을 로딩하는 것을 포함하고, 시스템은 제 1 인공 지능 프로세서에서 제1 처리 반복 시에 제1 인공 지능 프로세서에 의해 수신된 데이터의 제1 부분을 더 처리한다. 일 실시예에서, 모델은 제어기로부터 제1 인공 지능 프로세서에서 수신된다. 일 실시예에서, 모델은 복수의 인공 지능 프로세서 중 하나 이상의 다른 프로세서로부터 제1 인공 지능 프로세 서에서 수신된다. 일 실시예에서, 모델은 제1 인공 지능 프로세서의 로컬 메모리로부터 제1 인공 지능 프로세서에서 수신된다. 일 실시예에서, 모델은 인공 지능 파라미터를 포함한다. 일 실시예에서, 모델은 신경망 가중치를 포함한다. 일 실시예에서, 데이터 세트는 트레이닝 데이터 세트이다. 위 설명은 특정 실시예의 특징들이 구현될 수 있는 방법의 예들과 함께 본 개시의 다양한 실시예를 예시한 것이다. 위 예들은 유일한 실시예로 간주되어서는 안 되며, 첨부된 청구범위에 의해 정의된 특정 실시예의 융통성 및 이점을 예시하기 위해 제시된다. 위 개시내용 및 첨부한 청구범위에 기초하여, 청구범위에 의해 정의된 본 개시의 범위로부터 벗어나지 않고 다른 배치, 실시예, 구현 및 균등물이 실시될 수 있다."}
{"patent_id": "10-2022-7025796", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 다양한 실시예는 첨부 도면에 예로서 제시되며 제한이 아니다. 도 1은 일 실시예에 따른, 다중 프로세서 컴퓨팅 환경에서의 오류 복구를 도시한 것이다. 도 2는 일 실시예에 따른, 다중 프로세서 컴퓨팅 환경에서 프로세서 오류로부터 복구하는 방법을 도시한 것이다. 도 3은 일 실시예에 따른, 다중 프로세서 컴퓨팅 환경에서 트레이닝 동안 모델을 리로딩(reloading)하는 것을 도시한 것이다. 도 4는 일 실시예에 따른 다중 프로세서 컴퓨팅 아키텍처를 도시한 것이다. 도 5는 다양한 실시예에 따른, 글로벌 체크포인트 및 각 반복 동안의 동기화를 도시한 것이다. 도 6은 다양한 실시예에 따른 글로벌 체크포인트로의 복귀를 도시한 것이다. 도 7은 다양한 실시예에 따른, 이전 반복으로부터 모델을 리로딩하는 것을 도시한 것이다. 도 8은 예시적인 일 실시예에 따른 제어기 및 처리 장치 동작을 도시한 것이다. 도 9는 다른 실시예에 따른, 오류 복구를 위한 예시적인 아키텍처를 도시한 것이다. 도 10은 일 예시적 실시예에 따른 결과 집계 단계에서 오류가 발생한 경우의 복구를 도시한 것이다. 도 11은 일 실시예에 따른 예시적인 결과 생성을 도시한 것이다. 도 12는 일 실시예에 따른 결과 생성의 예를 도시한 것이다. 도 13은 일 실시예에 따른, 다중 프로세서 컴퓨팅 환경에서의 오류 복구를 도시한 것이다. 도 14는 일 실시예에 따른, 다수의 프로세서에 걸쳐 고장난 프로세서에 대한 계산을 분배하는 것을 도시한 것이다."}
