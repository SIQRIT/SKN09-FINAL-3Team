{"patent_id": "10-2023-0126065", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0042949", "출원번호": "10-2023-0126065", "발명의 명칭": "인공지능 모델을 사용한 음성 인식 방법 및 장치", "출원인": "현대자동차주식회사", "발명자": "김병열"}}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 모델을 트레이닝하는 방법으로서, 제1 키워드 데이터셋 및 제2 키워드 데이터셋을 생성하는 단계,상기 제1 키워드 데이터셋을 사용하여 상기 인공지능 모델을 사전 트레이닝하는 단계, 그리고상기 제2 키워드 데이터셋을 사용하여 사전 트레이닝된 인공지능 모델을 미세 조정하는 단계를 포함하고, 상기 제1 키워드 데이터셋에 포함된 키워드의 개수는 상기 제2 키워드 데이터셋에 포함된 키워드의 개수보다 상대적으로 더 많은, 방법."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에서,상기 제1 키워드 데이터셋 및 제2 키워드 데이터셋을 생성하는 단계는,인공 신경망 기반의 특징 추출기를 사용하여 제1 음성 말뭉치의 단어 및 발화 데이터를 정렬하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에서,상기 인공 신경망 기반의 특징 추출기는 상기 제1 음성 말뭉치의 단어로부터 정렬된 단어를 출력하고, 상기 정렬된 단어는 상기 단어의 선행 음소 및/또는 후행 음소를 포함하는, 방법."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에서,상기 인공 신경망 기반의 특징 추출기는 상기 제1 음성 말뭉치의 단어로부터 정렬된 단어를 출력하고, 상기 정렬된 단어는 상기 단어보다 미리 결정된 길이의 마진을 더 포함하는, 방법."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에서,상기 제1 키워드 데이터셋 및 제2 키워드 데이터셋을 생성하는 단계는,상기 인공 신경망 기반의 특징 추출기를 사용하여 정렬된 발화 데이터에서 단어를 인식하는 단계, 그리고인식된 단어를 필터링하여 상기 제1 키워드 데이터셋을 결정하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에서,상기 인식된 단어를 필터링하여 상기 제1 키워드 데이터셋을 결정하는 단계는,상기 인식된 단어와 목표 단어 사이의 편집 거리에 기반하여 상기 필터링을 수행하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2025-0042949-3-제6항에서,상기 인식된 단어와 목표 단어 사이의 편집 거리에 기반하여 상기 필터링을 수행하는 단계는,상기 인식된 단어의 글자수에 기반하여 결정되는 편집 거리의 허용 범위에 따라 상기 인식된 단어를 필터링하는단계를 포함하는, 방법."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제2항에서,상기 제1 키워드 데이터셋 및 제2 키워드 데이터셋을 생성하는 단계는,제2 음성 말뭉치의 일부 클래스를 사용하여 상기 제2 키워드 데이터셋을 생성하는 단계를 더 포함하고, 상기 제2 음성 말뭉치는 상기 제1 음성 말뭉치보다 더 적은 클래스를 포함하는, 방법."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에서,상기 제1 키워드 데이터셋을 사용하여 상기 인공지능 모델을 사전 트레이닝하는 단계는,상기 제1 키워드 데이터셋으로부터 입력되는 데이터를 사용하여 배치를 구성하는 단계포함하는, 방법."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에서,상기 배치는, 동일한 키워드의 서로 다른 오디오 데이터의 포지티브 쌍 및 서로 다른 키워드의 오디오 데이터의네거티브 쌍을 포함하는, 방법."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "인공지능 모델을 사용하여 음성을 인식하는 장치로서, 제1 키워드 데이터셋 및 제2 키워드 데이터셋을 생성하는 데이터셋 생성부, 및 상기 제1 키워드 데이터셋을 사용하여 사전 트레이닝이 수행되고, 상기 제2 키워드 데이터셋을 사용하여 사전트레이닝된 인공지능 모델의 미세 조정이 수행되는 인공지능 모델을 포함하고, 상기 제1 키워드 데이터셋에 포함된 키워드의 개수는 상기 제2 키워드 데이터셋에 포함된 키워드의 개수보다 상대적으로 더 많은, 장치."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에서,상기 데이터셋 생성부는,인공 신경망 기반의 특징 추출기를 사용하여 제1 음성 말뭉치의 단어 및 발화 데이터를 정렬하는, 장치."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에서,상기 인공 신경망 기반의 특징 추출기는 상기 제1 음성 말뭉치의 단어로부터 정렬된 단어를 출력하고, 상기 정렬된 단어는 상기 단어의 선행 음소 및/또는 후행 음소를 포함하는, 장치."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에서,공개특허 10-2025-0042949-4-상기 인공 신경망 기반의 특징 추출기는 상기 제1 음성 말뭉치의 단어로부터 정렬된 단어를 출력하고, 상기 정렬된 단어는 상기 단어보다 미리 결정된 길이의 마진을 더 포함하는, 장치."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에서,상기 데이터셋 생성부는,상기 인공 신경망 기반의 특징 추출기를 사용하여 정렬된 발화 데이터에서 단어를 인식하고, 인식된 단어를 필터링하여 상기 제1 키워드 데이터셋을 결정하는, 장치."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에서,상기 데이터셋 생성부는,상기 인식된 단어와 목표 단어 사이의 편집 거리에 기반하여 상기 필터링을 수행하는, 장치."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에서,상기 데이터셋 생성부는,상기 인식된 단어의 글자수에 기반하여 결정되는 편집 거리의 허용 범위에 따라 상기 인식된 단어를필터링하는, 장치."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에서,상기 데이터셋 생성부는,제2 음성 말뭉치의 일부 클래스를 사용하여 상기 제2 키워드 데이터셋을 생성하고, 상기 제2 음성 말뭉치는 상기 제1 음성 말뭉치보다 더 적은 클래스를 포함하는, 장치."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에서,상기 제1 키워드 데이터셋으로부터 입력되는 데이터를 사용하여 배치를 구성하는 배치 구성부를 더 포함하는, 장치."}
{"patent_id": "10-2023-0126065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에서,상기 배치 구성부는, 동일한 키워드의 서로 다른 오디오 데이터의 포지티브 쌍 및 서로 다른 키워드의 오디오데이터의 네거티브 쌍을 포함하도록 상기 배치를 구성하는, 장치."}
{"patent_id": "10-2023-0126065", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "제1 키워드 데이터셋 및 제2 키워드 데이터셋을 생성하는 단계, 제1 키워드 데이터셋을 사용하여 인공지능 모델 을 사전 트레이닝하는 단계, 그리고 제2 키워드 데이터셋을 사용하여 사전 트레이닝된 인공지능 모델을 미세 조 정하는 단계를 통해 음성을 인식하는 장치 및 방법이 제공된다."}
{"patent_id": "10-2023-0126065", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 기재는 인공지능 모델을 사용하여 음성을 인식하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0126065", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "키워드 스포팅(keyword spotting, KWS)은 오디오 스트림에서 키워드를 식별하는 기술로서, 로봇 상호작용 및 스 마트 기기 제어 등 다양한 분야에 적용되고 있다. KWS 시스템은 많은 음성 지원 시스템의 시작점으로서, 그 성능은 만족스러운 사용자 경험을 제공하는 데 매우 중요하다. 대부분의 기존 KWS 시스템은 사전 정의된 키워드 세트에 기반하지만, 사용자 지정 키워드에 기반한 KWS 시스템은 사용자 경험을 크게 개선할 수 있다. 예를 들어, 기기마다 서로 다른 키워드가 적용되면 실수로 주변의 다른 기기를 깨우는 것을 방지하고 낯선 사람의 접 근을 차단하여 보안을 강화할 수 있다."}
{"patent_id": "10-2023-0126065", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "한 실시예는, 음성 인식을 위한 인공지능 모델을 트레이닝하는 방법을 제공한다. 다른 실시예는, 인공지능 모델을 사용하여 음성을 인식하는 장치를 제공한다."}
{"patent_id": "10-2023-0126065", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "한 실시예에 따르면, 인공지능 모델을 트레이닝하는 방법이 제공된다. 상기 방법은, 제1 키워드 데이터셋 및 제 2 키워드 데이터셋을 생성하는 단계, 제1 키워드 데이터셋을 사용하여 인공지능 모델을 사전 트레이닝하는 단계, 그리고 제2 키워드 데이터셋을 사용하여 사전 트레이닝된 인공지능 모델을 미세 조정하는 단계를 포함한 다. 여기서 제1 키워드 데이터셋에 포함된 키워드의 개수는 제2 키워드 데이터셋에 포함된 키워드의 개수보다 상대적으로 더 많을 수 있다. 한 실시예에서, 제1 키워드 데이터셋 및 제2 키워드 데이터셋을 생성하는 단계는, 인공 신경망 기반의 특징 추 출기를 사용하여 제1 음성 말뭉치의 단어 및 발화 데이터를 정렬하는 단계를 포함할 수 있다. 한 실시예에서, 인공 신경망 기반의 특징 추출기는 제1 음성 말뭉치의 단어로부터 정렬된 단어를 출력하고, 정 렬된 단어는 단어의 선행 음소 및/또는 후행 음소를 포함할 수 있다. 한 실시예에서, 인공 신경망 기반의 특징 추출기는 제1 음성 말뭉치의 단어로부터 정렬된 단어를 출력하고, 정 렬된 단어는 단어보다 미리 결정된 길이의 마진을 더 포함할 수 있다. 한 실시예에서, 제1 키워드 데이터셋 및 제2 키워드 데이터셋을 생성하는 단계는, 인공 신경망 기반의 특징 추 출기를 사용하여 정렬된 발화 데이터에서 단어를 인식하는 단계, 그리고 인식된 단어를 필터링하여 제1 키워드 데이터셋을 결정하는 단계를 더 포함할 수 있다. 한 실시예에서, 인식된 단어를 필터링하여 제1 키워드 데이터셋을 결정하는 단계는, 인식된 단어와 목표 단어 사이의 편집 거리에 기반하여 필터링을 수행하는 단계를 포함할 수 있다. 한 실시예에서, 인식된 단어와 목표 단어 사이의 편집 거리에 기반하여 필터링을 수행하는 단계는, 인식된 단어 의 글자수에 기반하여 결정되는 편집 거리의 허용 범위에 따라 인식된 단어를 필터링하는 단계를 포함할 수 있 다. 한 실시예에서, 제1 키워드 데이터셋 및 제2 키워드 데이터셋을 생성하는 단계는, 제2 음성 말뭉치의 일부 클래 스를 사용하여 제2 키워드 데이터셋을 생성하는 단계를 더 포함하고, 제2 음성 말뭉치는 제1 음성 말뭉치보다 더 적은 클래스를 포함할 수 있다. 한 실시예에서, 제1 키워드 데이터셋을 사용하여 인공지능 모델을 사전 트레이닝하는 단계는, 제1 키워드 데이 터셋으로부터 입력되는 데이터를 사용하여 배치를 구성하는 단계를 포함할 수 있다. 한 실시예에서, 배치는, 동일한 키워드의 서로 다른 오디오 데이터의 포지티브 쌍 및 서로 다른 키워드의 오디 오 데이터의 네거티브 쌍을 포함할 수 있다. 다른 실시예에 따르면, 인공지능 모델을 사용하여 음성을 인식하는 장치가 제공된다. 상기 장치는, 제1 키워드 데이터셋 및 제2 키워드 데이터셋을 생성하는 데이터셋 생성부 및 제1 키워드 데이터셋을 사용하여 사전 트레이 닝이 수행되고, 제2 키워드 데이터셋을 사용하여 사전 트레이닝된 인공지능 모델의 미세 조정이 수행되는 인공 지능 모델을 포함한다. 여기서 제1 키워드 데이터셋에 포함된 키워드의 개수는 제2 키워드 데이터셋에 포함된 키워드의 개수보다 상대적으로 더 많을 수 있다. 다른 실시예에서, 데이터셋 생성부는, 인공 신경망 기반의 특징 추출기를 사용하여 제1 음성 말뭉치의 단어 및 발화 데이터를 정렬할 수 있다.다른 실시예에서, 인공 신경망 기반의 특징 추출기는 제1 음성 말뭉치의 단어로부터 정렬된 단어를 출력하고, 정렬된 단어는 단어의 선행 음소 및/또는 후행 음소를 포함할 수 있다. 다른 실시예에서, 인공 신경망 기반의 특징 추출기는 제1 음성 말뭉치의 단어로부터 정렬된 단어를 출력하고, 정렬된 단어는 단어보다 미리 결정된 길이의 마진을 더 포함할 수 있다. 다른 실시예에서, 데이터셋 생성부는, 인공 신경망 기반의 특징 추출기를 사용하여 정렬된 발화 데이터에서 단 어를 인식하고, 인식된 단어를 필터링하여 제1 키워드 데이터셋을 결정할 수 있다. 다른 실시예에서, 데이터셋 생성부는, 인식된 단어와 목표 단어 사이의 편집 거리에 기반하여 필터링을 수행할 수 있다. 다른 실시예에서, 데이터셋 생성부는, 인식된 단어의 글자수에 기반하여 결정되는 편집 거리의 허용 범위에 따 라 인식된 단어를 필터링할 수 있다. 다른 실시예에서, 데이터셋 생성부는, 제2 음성 말뭉치의 일부 클래스를 사용하여 제2 키워드 데이터셋을 생성 하고, 제2 음성 말뭉치는 제1 음성 말뭉치보다 더 적은 클래스를 포함할 수 있다. 다른 실시예에서, 상기 장치는, 제1 키워드 데이터셋으로부터 입력되는 데이터를 사용하여 배치를 구성하는 배 치 구성부를 더 포함할 수 있다. 다른 실시예에서, 배치 구성부는, 동일한 키워드의 서로 다른 오디오 데이터의 포지티브 쌍 및 서로 다른 키워 드의 오디오 데이터의 네거티브 쌍을 포함하도록 배치를 구성할 수 있다."}
{"patent_id": "10-2023-0126065", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "서로 다른 말뭉치로부터 각각 생성된 키워드 데이터셋을 사용하여 인공지능 모델의 사전 트레이닝 및 미세 조정 이 각각 수행됨으로써, 판별가능 임베딩 공간에서의 음성 키워드에 대한 추론 성능이 향상될 수 있다."}
{"patent_id": "10-2023-0126065", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 기재의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 기재는 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 기재를 명확하게 설명하기 위 해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함 께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. 본 명세서에서 단수로 기재된 표현은 \"하나\" 또는 \"단일\" 등의 명시적인 표현을 사용하지 않은 이상, 단수 또는 복수로 해석될 수 있다.본 명세서에서 \"및/또는\"은 언급된 구성 요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 본 명세서에서, 제1, 제2 등과 같이 서수를 포함하는 용어들은 다양한 구성요소들을 설명하는데 사용될 수 있지 만, 상기 구성요소들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요 소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 개시의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 본 명세서에서 도면을 참고하여 설명한 흐름도에서, 동작 순서는 변경될 수 있고, 여러 동작들이 병합되거나, 어느 동작이 분할될 수 있고, 특정 동작은 수행되지 않을 수 있다. 본 개시의 인공지능 모델(Artificial Intelligence model, AI model)은 적어도 하나의 태스크(task)를 학습하 는 기계학습모델로서, 프로세서에 의해 실행되는 컴퓨터 프로그램으로 구현될 수 있다. 인공지능 모델에 의해 학습되는 태스크는, 기계 학습을 통해 해결하고자 하는 과제 또는 기계 학습을 통해 수행하고자 하는 작업을 지 칭할 수 있다. 인공지능 모델은 컴퓨팅 장치에서 실행되는 컴퓨터 프로그램으로 구현될 수 있고, 네트워크를 통 해 다운로드되거나, 제품 형태로 판매될 수 있다. 또는 인공지능 모델은 네트워크를 통해 다양한 장치들과 연동 할 수 있다. 도 1은 한 실시예에 따른 음성 인식 장치를 나타낸 도면이고, 도 2는 한 실시예에 따른 음성 인식을 위한 인공 지능 모델의 트레이닝 방법을 나타낸 흐름도이다. 한 실시예에 따른 음성 인식 장치는 데이터셋 생성부, 배치 구성부, 특징 추출부, 및 인공 지능 모델을 포함할 수 있다. 데이터셋 생성부는 인공지능 모델의 사전 트레이닝(pre-training)을 위한 대규모 데이터셋(large scale dataset) 및 사전 트레이닝된 인공지능 모델의 미세 조정(fine-tuning)을 위한 소규모 데이터셋 (small scale dataset)을 생성할 수 있다. 인공지능 모델의 사전 트레이닝을 위한 대규모 데이터셋은 메트 릭 학습을 위해 상대적으로 많은 개수의 트레이닝 클래스를 포함할 수 있다. 인공지능 모델의 사전 트레이닝을 위한 대규모 데이터셋은 도메인 외부(out-of-domain)의 키워드 데이터로 부터 생성될 수 있고, 이후 도메인 내(intra-domain)의 키워드 데이터로부터 인공지능 모델의 미세 조정을 위한 소규모 데이터셋이 생성될 수 있다. 여기서 도메인은, 인공지능 모델에 대한 테스트가 수행되는 임베 딩 공간이다. 즉, 도메인 바깥의 데이터를 사용하여 키워드 스포팅을 위한 인공지능 모델의 사전 트레이닝 이 수행되고, 도메인 내의 데이터를 사용하여 키워드 스포팅을 위한 인공지능 모델의 미세 조정이 수행될 수 있다. 여기서 인공지능 모델의 미세 조정을 위한 데이터셋은 도메인 내이지만 테스트를 위한 데이터셋 과 중복되지 않을 수 있다. 한 실시예에서, 대규모 데이터셋(large-scale out-of-domain corpus)은 LibriSpeech 말뭉치로부터 추출된 1,000개의 키워드를 포함할 수 있다. 또한 소규모 데이터셋은 구글 음성 명령(google speech command, GSC) 말 뭉치로부터 추출된 25개의 키워드를 포함할 수 있다. 데이터셋 생성부는 대규모 데이터셋 및 소규모 데이 터셋에서 사용자 정의 키워드(user-defined keywords)를 배제할 수 있다. 배치 구성부는, 대규모 데이터셋으로부터 인공지능 모델의 사전 트레이닝을 위한 배치를 구성할 수 있다. 인공지능 모델의 사전 트레이닝에는 메트릭 학습이 적용될 수 있다. 도 1을 참조하면, 배치 구성에서 di,j는 대규모 데이터셋에서 획득되는 단일 오디오 데이터를 나타내고, N은 미 니 배치의 크기를 나타낼 수 있다. di,j의 연결에서 실선은 포지티브 쌍을 나타내고 점선은 네거티브 쌍을 나타 낸다. 즉, 포지티브 쌍은 동일한 키워드의 서로 다른 오디오 데이터를 포함하고, 네거티브 쌍은 하나의 미니 배 치 내의 서로 다른 키워드의 오디오 데이터를 포함할 수 있다. 프로토타입 네트워크에서, 각 미니 배치에는 각 키워드에 대응하는 적어도 2개의 샘플(오디오 데이터)을 포함할 수 있다. 특징 추출부는, 인공지능 모델로 입력되는 데이터의 외형을 정규화할 수 있다. 한 실시예에서, 특징 추출부는 16kHz 파형의 최대 길이를 1초로 제한할 수 있다. 예를 들어, 오디오 데이터가 1초보다 길면 특 징 추출부는 1초 길이로 오디오 데이터를 자르고, 오디오 데이터가 1초보다 짧으면 특징 추출부는 오 디오 데이터에 제로 패딩을 수행할 수 있다. 한 실시예에서, 특징 추출부는 정규화된 오디오 데이터로부터 소리의 특징값을 추출할 수 있다. 예를 들어, 특징 추출부는 멜주파수 켑스트럴 계수(Mel-Frequency Cepstral Coefficient, MFCC)를 정규화된 오디오 데이터로부터 추출할 수 있다. 특징 추출부는 30ms의 윈도우 및 10ms의 프레임 시프트를 사용하여 40 차원의 MFCC를 정규화된 오디오 데이터로부터 추출할 수 있다. 인공지능 모델은 사람의 음성 내에서 키워드(예를 들어, 웨이크업 단어(wakeup word))를 인식할 수 있도록, 데이터셋 생성부에 의해 생성된 데이터셋을 사용하여 트레이닝될 수 있다. 한 실시예에서, 인공지 능 모델은 대규모 데이터셋을 사용하여 사전 트레이닝되고, 이후 사전 트레이닝된 인공지능 모델은 데이터셋 생성부에 의해 생성된 소규모 데이터셋을 사용하여 미세 조정될 수 있다. 인공지능 모델은 목적 함수의 출력이 최소가 되도록 인공지능 모델의 가중치 및 파라미터를 업데이트함으로써 트레이닝(사 전 트레이닝 및 미세 조정이 포함됨)을 수행할 수 있다. 인공지능 모델의 트레이닝을 위해 소프트맥스(Softmax) 함수 및 메트릭 러닝 기반 목적 함수(metric learning-based objective function) 중 적어도 하나가 사용될 수 있다. 메트릭 러닝 기반 목적 함수는 가산 마진 소프트맥스(additive margin softmax, AM-Softmax) 함수 및 앵귤러 프로토타입(angular prototypical, AP) 함수를 포함할 수 있다. 도 2를 참조하면, 데이터셋 생성부는 인공지능 모델의 사전 트레이닝 및 미세 조정 각각을 위한 제1 키워 드 데이터셋 및 제2 키워드 데이터셋을 생성할 수 있다(S100). 배치 구성부는 제1 키워드 데이터셋으로부터 인공지능 모델의 사전 트레이닝을 위한 배치를 구성할 수 있다(S200). 인공지능 모델은 제1 키워드 데이터셋을 사용하여 사전 트레이닝될 수 있다(S300). 한 실시예에서, 인공지 능 모델의 트레이닝을 위해 메트릭 학습(metric learning)이 수행될 수 있다. 이후 인공지능 모델은 제2 키워드 데이터셋을 사용하여 사전 트레이닝된 인공지능 모델을 미세 조정할 수 있다(S400). 인공지능 모델 은, 소프트맥스 함수, AM-소프트맥스 함수, 및 AP 함수 중 적어도 나를 사용하여 인공지능 모델의 사 전 트레이닝 및 미세 조정을 수행할 수 있다. 인공지능 모델의 미세 조정은 소규모 키워드 데이터셋을 사용하여 소규모 키워드 데이터셋의 음성 말뭉치 에 대해 향상된 구분력(representation)을 갖도록 수행될 수 있다. 즉, 소규모 키워드 데이터셋을 사용하여 인 도메인(in-domain)의 채널 특성을 구분력에 반영할 수 있도록 미세 조정이 수행될 수 있다. 도 3은 한 실시예에 따른 키워드 데이터셋을 생성하는 방법을 나타낸 흐름도이다. 한 실시예에 따른 데이터셋 생성부는 음성 말뭉치(speech corpus)(예를 들어, LibriSpeech corpus 등의 영어 말뭉치, 한국어 음성 명령(Korean Speech Commands, KSC))로부터 인공지능 모델의 사전 트레이닝을 위한 제1 키워드 데이터셋을 생성할 수 있다. LibriSpeech 말뭉치 내에는 16kHz로 샘플링된 1,000 시간의 음성 데이 터 및 키워드가 포함되어 있다. 한 실시예에서, 인공지능 모델에 대해 메트릭 학습이 수행됨으로써, 보이지 않는 데이터 샘플의 공간에 식 별 특징(discriminative feature)이 포함될 수 있다. 메트릭 학습에 의해 효과적인 표상(representations)이 학습되기 위해 많은 수의 트레이닝 클래스(예를 들어, 키워드 또는 단어)가 필요할 수 있다. 한 실시예에서, 데 이터셋 생성부는 LibriSpeech 말뭉치에서 1,000여개의 키워드를 추출하고 추출된 키워드를 사용하여 제1 키워드 데이터셋을 생성할 수 있다. 도 3을 참조하면, 데이터셋 생성부는 음성 말뭉치의 개별 단어 및 발화 데이터에 대한 강제 정렬(개별 단 어 및 발화 데이터의 세그먼트화)을 수행할 수 있다(S110). 한 실시예에서, 데이터셋 생성부는 음성 말뭉치 내의 개별 단어에 대한 강제 정렬을 위해 인공 신경망 기 반의 특징 추출기를 사용할 수 있다. 한 실시예에서, 데이터셋 생성부 인공 신경망 기반의 특징 추출기를 사용하여 발화 수준의 레이블에서 개별 단어를 강제 정렬할 수 있다. 인공 신경망 기반의 특징 추출기는 음성으 로부터 특징 벡터를 생성하는 Wav2Vec, SincNet, 및 Problem-Agnostic Speech Encoder(PASE) 중 적어도 하나를 포함할 수 있다. 강제 정렬된 단어는 실제 시나리오에서 키워드의 전후로 발생할 수 있는 잡음 또는 발화를 포함할 수 있도록 미 리 결정된 길이의 마진을 더 포함할 수 있다. 미리 결정된 길이의 마진은 단어에 대응하는 오디오의 길이의 6% 일 수 있다. 강제 정렬된 단어에 마진이 포함됨으로써, 인공 신경망 기반의 특징 추출기에서 출력되는 오디오는 강제 정렬된 단어의 선행 음소(preceding phonemes) 및/또는 후행 음소(proceeding phonemes)를 더 포함할 수 있다. 예를 들어, 인공 신경망 기반의 특징 추출기는 'love'에 마진을 더하여 'I love you' 등을 강제 정렬된단어로서 출력할 수 있다. 이후, 데이터셋 생성부는 강제 정렬된 단어의 품질을 향상시킬 수 있도록 편집 거리(edit distance)에 기 반한 필터링을 수행할 수 있다. 편집 거리는 단어의 인식 결과와 목표 단어(키워드) 사이의 거리를 나타낼 수 있다. 한 실시예에서, 데이터셋 생성부는 인공 신경망 기반의 특징 추출기를 사용하여 세그먼트화된 발화 데이터 에서 단어를 인식할 수 있다(S120). 그리고 데이터셋 생성부는 모델 학습에 적합한 데이터가 아닌 것으로 간주되는 단어, 즉 정렬이 잘못된 단어를 편집 거리에 기반하여 필터링할 수 있다(S130). 한 실시예에서, 데이 터셋 생성부는 인식된 단어의 글자수에 기반하여 결정되는 편집 거리의 허용 범위에 따라 인식된 단어를 필터링할 수 있다. 한 실시예에서, 데이터셋 생성부는 단어의 글자가 2개 이하일 때는 편집 거리를 1까지 허용하고, 단어의 글자가 2개 보다 많으면 편집 거리를 3까지 허용할 수 있다. 예를 들어, 세그먼트화된 발화가 'love'이고, 'love'의 음성 인식 결과가 LEOVE일 때, 데이터셋 생성부는 편집 거리를 3까지 허용할 수 있고 LEOVE와 love의 편집 거리가 1이므로, LEOVE를 필터링하지 않을 수 있다. 도 3을 참조하면, 데이터셋 생성부는 필터링된 단어들에서 가장 빈번히 등장하는 단어(최빈 단어)를 일부 제거하여 제1 키워드 데이터셋을 결정할 수 있다(S140). 한 실시예에서, 데이터셋 생성부는 음성 말뭉치 내의 최빈 단어를 관사 및/또는 전치사로 간주하고 필터링된 단어들에서 제거할 수 있다. 예를 들어, 데이터셋 생성부는 필터링된 단어들에서 최빈 단어 17개를 제거하고 남은 단어 중 미리 결정된 개수의 단어(예를 들 어, 1,000개)를 제1 키워드 데이터셋으로서 결정할 수 있다. 한 실시예에서, 제1 키워드 데이터셋의 1000개의 단어에 대응하는 발화 데이터는 1,601,226개일 수 있다. 데이터셋 생성부는 제1 키워드 데이터셋을 생성하는데 사용된 음성 말뭉치와 다른 음성 말뭉치를 사용하여 사전 트레이닝된 인공지능 모델의 미세 조정을 위한 제2 키워드 데이터셋을 생성할 수 있다. 다른 음성 말뭉치 는 제1 키워드 데이터셋을 생성하는데 사용된 음성 말뭉치보다 더 적은 클래스(또는 키워드)를 포함할 수 있다. 한 실시예에서, 제2 키워드 데이터셋을 생성하는데 사용된 다른 음성 말뭉치는 GSC일 수 있다. GSC는 35개 키워 드에 대한 105,829개(각 키워드 당 약 2,000개 이상)의 발화 데이터를 포함하고, 공개적으로 사용 가능한 KWS 데이터 세트이다. 아래 표 1은 3개의 그룹으로 나뉜 GSC에 포함된 키워드를 나타낸다. 표 1 데이터셋 클래스의 개수 키워드 트레이닝 세트 사전 정의 10 'Yes', 'No', 'Up', 'Down', 'Left', 'Right', 'On', 'Off', 'Stop', 'Go' 알려지지 않음 15 'Bed', 'Bird', 'Cat', 'Dog', 'Wow', 'House', 'Learn', 'Sheila', 'Tree', 'Happy', 'Marvin', 'Backward', 'Follow', 'Forward', 'Visual' 테스트 세트 사용자 정의 10 'Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine' 표 1을 참조하면, 데이터셋 생성부는 3개의 그룹으로 나뉜, GSC의 35개의 키워드 중 트레이닝 세트를 사용 하여 인공지능 모델을 미세 조정할 수 있다. 트레이닝 세트 내의 알려지지 않은 키워드(unknown)는 실제 환경에서 발생할 수 있는 발화의 집합일 수 있다. 즉, 인공지능 모델의 미세 조정에는 사전 정의 키워드 및 알려지지 않은 키워드(25개)가 사용되고, 사용자 정의 키워드는 트레이닝된 인공지능 모델의 테스트 시 에 사용될 수 있다. 따라서, 테스트 세트 내의 10개 키워드는 제1 키워드 데이터셋에서 삭제될 수 있다. 한 실시예에서, 데이터셋 생성부는 영어가 아닌 다른 언어의 음성 말뭉치에 대해서 위의 키워드 데이터셋 생성 과정을 수행하고, 다른 언어의 키워드 데이터셋을 제1 키워드 데이터셋과 함께 인공지능 모델의 사전 트레이닝에 사용할 수 있다. 예를 들어, 데이터셋 생성부는 KSC 말뭉치에 대해 한국어 키워드 데이터셋을 생성하고, 제1 키워드 데이터셋 및 한국어 키워드 데이터셋을 인공지능 모델의 사전 트레이닝을 위해 함께 사용할 수 있다. KSC 말뭉치는 48kHz로 샘플링된 4,000 시간의 음성 데이터를 포함할 수 있다. 도 4a는 한 실시예에 따른 인공지능 모델의 사전 트레이닝을 위한 미니 배치를 나타낸 도면이고, 도 4b는 한 실 시예에 따른 인공지능 모델의 사전 트레이닝 결과를 나타낸 도면이다. 도 4a를 참조하면, 배치의 크기는 16이고, 각 미니 배치에는 20개의 클래스(키워드)가 포함될 수 있다. 각 클래 스는 앵커(anchor)와 포지티브(positive)의 쌍을 포함할 수 있다. 도 4b를 참조하면, 인공지능 모델의 사전 트레이닝의 결과를 통해, 인공지능 모델은 입력되는 모든 키워드 간의 구분력을 가질 수 있게 된다. 사전 트레이닝의 손실 함수로서 코사인 유사도(cosine similarity) 기반의 메트릭 및 앵귤러 프로토타입(angular prototypical, AP) 함수가 사용될 수 있다. 아래 수학식 1은 AP 함수를 나타낸다. 수학식 1"}
{"patent_id": "10-2023-0126065", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서 일반적인 프로토타입 손실 함수의 제곱 유클리드 거리 메트릭은 코사인 거리로 대체되어 있다. 각 미니 배치에는 지원 세트 S 및 쿼리 세트 Q가 포함될 수 있고, 쿼리는 모든 키워드로부터의 M번째 발화라고 가 정될 수 있다. 아래 수학식 2는 이때의 프로토타입을 나타낼 수 있고, 수학식 3은 학습 가능한 스케일 (learnable scale) 및 편향(bias)를 갖는 코사인 기반 유사도 메트릭을 나타낼 수 있다. 수학식 2"}
{"patent_id": "10-2023-0126065", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 3"}
{"patent_id": "10-2023-0126065", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "사전 트레이닝 중 각 쿼리 예제는 각 키워드 프로토타입과의 거리에 따른 소프트맥스 출력에 기반하여 N개의 클 래스에 대해 분류될 수 있다. 한 실시예에서, 인공지능 모델의 사전 트레이닝 및/또는 미세 조정을 위해 AP 함수와는 서로 다른 손실 함 수가 AP 함수와 함께 또는 AP 함수 없이 단독으로 사용될 수 있다. 한 실시예에서, 소프트맥스 함수 및/또는 AM-소프트맥스 함수가 인공지능 모델의 사전 트레이닝 및/또는 미세 조정을 위해 사용될 수 있다. 소프트맥스 손실 함수는 분류 네트워크를 훈련하기 위해 사용될 수 있다. 한 실시예에서, 소프트맥스 손실 함수 가 기준 목적 함수로서 사용될 수 있다. 소프트맥스 손실 함수는 소프트맥스 함수 및 다중 클래스 교차 엔트로 피 손실 함수로 구성될 수 있다. 아래 수학식 4는 소프트맥스 손실 함수를 나타낸다. 수학식 4"}
{"patent_id": "10-2023-0126065", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 4에서 W 및 b는 학습 가능한 파라미터이다. 소프트맥스 손실 함수는 클래스 내 소형화(intra-class compactness) 및 클래스 간 분리성(interclass separation)을 명시적으로 강제하지 않는다. 가산 마진 소프트맥스(AM-Softmax) 손실 함수는 소프트맥스 손실 함수에 마진을 도입한 손실 함수이다. 소프트 맥스 손실 함수에 도입된 마진은 클래스 내 소형화 및 클래스 간 분리성을 강화하여 소수 샷(fewshot) 학습 작 업에서 성능을 향상시킬 수 있다. 먼저, 가중치와 입력 벡터는 소프트맥스 손실에서 정규화됨으로써, 사후 확률(posterior probability)은 가중치 및 입력 벡터 사이의 각도의 코사인 값에만 의존될 수 있다. 수학식 5"}
{"patent_id": "10-2023-0126065", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 5에서, 는 정규화된 가중치 벡터 Wj 및 입력 xi의 내적으로부터 계산될 수 있다. 수학식 5에서, 분 류 오류에만 불이익이 주어지기 때문에, 수학식 5에 따른 임베딩은 여전히 충분히 변별력이 없다. 이 문제를 해 결하기 위해 코사인 마진 m이 아래와 수학식 6과 같이 부가될 수 있다. 수학식 6"}
{"patent_id": "10-2023-0126065", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 6에서, s는 트레이닝 단계에서 기울기가 너무 작아지는 것을 방지하기 위한 고정 스케일 계수이다. 한 실시예에서, 인공지능 모델의 사전 트레이닝에서 AP 손실 함수가 사용되고, 인공지능 모델의 미세 조정을 위해 소프트맥스 손실 함수, AM-소프트맥스 손실 함수, 및 AP 손실 함수 중 적어도 하나가 사용될 수 있 다. 한 실시예에서, 사용자 정의 데이터 세트를 사용하여 트레이닝된 인공지능 모델이 테스트될 수 있다. 사용 자 정의 데이터 세트는 GSC의 일부로서, 트레이닝 세트와 중복되지 않는다. 음성 인식 장치의 트레이닝된 인공지능 모델은 사용자 정의 데이터 세트가 입력되면, 입력된 데이터 세트의 발화 데이터가 나타내는 키워드를 추론함으로써, 키워드 스포팅 성능을 테스트할 수 있다. 아래 표 2는 다양한 손실 함수를 사전 트레이닝 및 미세 조정에 적용한 경우에 측정된 음성 인식 장치의 추론 성능을 나타낸다. 표 2 표 2를 참조하면, 대규모 도메인 외부 데이터에 대한 사전 트레이닝이 음성 인식 장치의 추론 성능을 향상 시킴을 알 수 있다. 사전 트레이닝 및 미세 조정 모두에서 AP 손실 함수에 의해 학습이 진행되면, EER(Equal Error Rate)은 3.20%로 가장 좋은 성능을 보이고, 음성 인식의 정확도도 95.57%로 가장 좋은 성능을 보인다. 또 한 FRR(False Rejection Rate)@FAR(False Alarm Rate)도 AP 손실 함수에 의한 사전 트레이닝 및 미세 조정의 경우 가장 좋은 성능을 보인다. 표 3은 제1 키워드 데이터셋의 종류에 따른 음성 인식 장치의 성능 비교를 나타낸다. 표 3"}
{"patent_id": "10-2023-0126065", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "표 3을 참조하면, 키워드(클래스)당 샘플 개수가 줄어들거나 또는 샘플 당 키워드 개수가 줄어들면, 음성 인식 장치의 키워드 스포팅 성능이 저하될 수 있다. 클래스 개수가 줄어들면 샘플 개수만이 줄어드는 경우에 비 해 음성 인식 장치의 키워드 스포팅 성능이 더 저하되었으므로, 보이지 않는 사용자 정의 키워드에 대해 인공지능 모델이 성공적으로 추론을 수행하기 위해 클래스의 개수가 샘플의 개수보다 더 중요한 요소일 수 있다. 또한, 영어 음성 말뭉치로부터 생성된 제1 키워드 데이터셋에 한국어 음성 말뭉치로부터 생성된 제2 키워드 데 이터셋을 더하여 클래스 개수가 증가하면, 음성 인식 장치의 키워드 스포팅 성능이 더욱 향상될 수 있다. 위에서 설명한 대로, 도메인 외부의 말뭉치 및 도메인 내의 말뭉치로부터 각각 생성된 키워드 데이터셋을 사용 하여 인공지능 모델의 사전 트레이닝 및 미세 조정이 각각 수행됨으로써, 판별가능 임베딩 공간에서의 음성 키 워드에 대한 추론 성능이 향상될 수 있다. 도 5는 한 실시예에 따른 인공지능 모델을 실행하는 인공 신경망을 나타낸 도면이다. 도 5를 참조하면, 한 실시예에 따른 인공 신경망(Artificial Neural Network, ANN)은 입력층, 은닉 층, 및 출력층를 포함할 수 있다. 입력층, 은닉층, 및 출력층은 각각 복수의 노드를 포함하고, 각 노드 간의 연결의 강도는 가중치에 대응할 수 있다(weight connection). 입력층, 은닉층 , 및 출력층에 포함되는 복수의 노드는 서로 완전 연결형(fully connected)으로 연결될 수 있다. 한 실시예에서, 파라미터(가중치 및 편향)의 개수는 인공 신경망 내의 가중치 연결의 개수와 동일할 수 있다. 입력층은 복수의 입력 노드(x1 내지 xi)를 포함할 수 있고, 입력 노드(x1 내지 xi)의 개수는 독립변수의 개 수에 대응할 수 있다. 인공 신경망의 훈련을 위해 입력층으로 훈련 데이터셋이 입력되고, 훈련된 인 공 신경망의 입력층으로 테스트 데이터셋이 입력되면 훈련된 인공 신경망의 출력층에서 추 론 결과가 출력될 수 있다. 은닉층은 입력층과 출력층 사이에 위치하고, 적어도 하나의 은닉층(521 내지 72n)을 포함할 수 있다. 출력층은 적어도 하나의 출력 노드(y1 내지 yj)를 포함할 수 있다. 은닉층 및 출력층에는 활성화 함수가 사용될 수 있다. 한 실시예에서, 인공 신경망은 은닉층에 포함된 히든 노드의 가중치 를 조절하는 방식으로 학습될 수 있다. 도 6은 다른 실시예에 따른 음성 인식 장치를 나타낸 블록도이다. 한 실시예에 따른 음성 인식 장치는, 컴퓨터 시스템, 예를 들어 컴퓨터 판독 가능 매체로 구현될 수 있다. 도 6 을 참조하면, 컴퓨터 시스템은, 버스를 통해 통신하는 프로세서, 메모리, 입력 인터페이스 장치, 출력 인터페이스 장치, 및 저장 장치 중 적어도 하나를 포함할 수 있다. 컴퓨터 시스템 은 또한 네트워크에 결합된 통신 장치를 포함할 수 있다. 프로세서는 중앙 처리 장치(central processing unit, CPU)이거나, 또는 메모리 또는 저장 장치에 저장된 명령을 실행하는 반도체 장치일 수 있다. 메모리 및 저장 장치는 다양한 형태의 휘발성 또는 비휘발성 저장 매체를 포함할 수 있다.예를 들어, 메모리는 ROM(read only memory) 및 RAM(random access memory)를 포함할 수 있다. 본 기재의 실시 예에서 메모리는 프로세서의 내부 또는 외부에 위치할 수 있고, 메모리는 이미 알려진 다양한 수단을 통해 프로 세서와 연결될 수 있다. 메모리는 다양한 형태의 휘발성 또는 비휘발성 저장 매체이며, 예를 들어, 메모리는 읽 기 전용 메모리(read-only memory, ROM) 또는 랜덤 액세스 메모리(random access memory, RAM)를 포함할 수 있 다. 따라서, 본 발명의 실시예는 컴퓨터에 구현된 방법으로서 구현되거나, 컴퓨터 실행 가능 명령이 저장된 비일시 적 컴퓨터 판독 가능 매체로서 구현될 수 있다. 한 실시예에서, 프로세서에 의해 실행될 때, 컴퓨터 판독 가능 명령은 본 기재의 적어도 하나의 양상에 따른 방법을 수행할 수 있다. 통신 장치는 유선 신호 또는 무선 신호를 송신 또는 수신할 수 있다. 한편, 본 발명의 실시예는 지금까지 설명한 장치 및/또는 방법을 통해서만 구현되는 것은 아니며, 본 발명의 실 시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있으며, 이러한 구현은 상술한 실시예의 기재로부터 본 발명이 속하는 기술 분야의 통상의 기술자라면 쉽게 구 현할 수 있는 것이다. 구체적으로, 본 발명의 실시예에 따른 방법(예, 네트워크 관리 방법, 데이터 전송 방법, 전송 스케줄 생성 방법 등)은 다양한 컴퓨터 수단을 통해 수행될 수 있는 프로그램 명령 형태로 구현되어, 컴퓨 터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구 조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판독 가능 매체에 기록되는 프로그램 명령은, 본 발명의 실시예를 위해 특별히 설계되어 구성된 것이거나, 컴퓨터 소프트웨어 분야의 통상의 기술자에게 공지 되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체는 프로그램 명령을 저장하고 수행하도록 구성 된 하드웨어 장치를 포함할 수 있다. 예를 들어, 컴퓨터 판독 가능 기록 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광 기록 매체(optical media), 플롭티 컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 롬(ROM), 램(RAM), 플래시 메모리 등일 수 있다. 프로그램 명령은 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라, 인터프리터 등을 통해 컴퓨터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다."}
{"patent_id": "10-2023-0126065", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 한 실시예에 따른 음성 인식 장치를 나타낸 도면이고, 도 2는 한 실시예에 따른 음성 인식을 위한 인공 지능 모델의 트레이닝 방법을 나타낸 흐름도이다. 도 3은 한 실시예에 따른 키워드 데이터셋을 생성하는 방법을 나타낸 흐름도이다. 도 4a는 한 실시예에 따른 인공지능 모델의 사전 트레이닝을 위한 미니 배치를 나타낸 도면이고, 도 4b는 한 실 시예에 따른 인공지능 모델의 사전 트레이닝 결과를 나타낸 도면이다. 도 5는 한 실시예에 따른 인공지능 모델을 실행하는 인공 신경망을 나타낸 도면이다. 도 6은 다른 실시예에 따른 음성 인식 장치를 나타낸 블록도이다."}
