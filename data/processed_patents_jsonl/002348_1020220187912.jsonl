{"patent_id": "10-2022-0187912", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0105071", "출원번호": "10-2022-0187912", "발명의 명칭": "딥러닝 기반의 인체 동작 인식 장치 및 방법", "출원인": "경기대학교 산학협력단", "발명자": "유현"}}
{"patent_id": "10-2022-0187912", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 딥러닝 모델을 통해 입력된 영상에서 샘플링된 단일 이미지 프레임으로부터 인체를 검출하고 인체의 모션을분류하는 객체 및 모션 검출부;제2 딥러닝 모델을 통해 복수의 이미지 프레임들에서 객체 및 모션 검출부가 검출한 인체의 선형성과 동일성을판단하여 동일인의 위치를 추적하는 객체 추적부; 및제3 딥러닝 모델을 통해 동일인으로 판단된 인체의 연속된 모션 패턴으로부터 인체의 동작을 분류하는 패턴 분석부;를 포함하는, 딥러닝 기반의 인체 동작 인식 장치."}
{"patent_id": "10-2022-0187912", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 제1 딥러닝 모델은 원샷 객체 검출(One-Shot Object Detection) 모델이며, 인체 검출과 함께 인체의 모션을 분류하도록 학습된 모델인, 딥러닝 기반의 인체 동작 인식 장치."}
{"patent_id": "10-2022-0187912", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 객체 추적부는 객체 및 모션 검출부의 인체 검출 결과에 따라 인체 부분만 추출하여 제2 딥러닝 모델의 입력 데이터로 사용하는, 딥러닝 기반의 인체 동작 인식 장치."}
{"patent_id": "10-2022-0187912", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 제2 딥러닝 모델은 SORT(Simple Online and Realtime Tracking) 알고리즘을 기반으로 하는 모델인, 딥러닝 기반의 인체 동작 인식 장치."}
{"patent_id": "10-2022-0187912", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,패턴 분석부는 객체 및 모션 검출부의 모션 인식 결과와 객체 추적부의 동일인 추적 결과에 기초하여 연속적인이미지 프레임에서 인체의 모션 변화 패턴을 수집하여 제3 딥러닝 모델의 입력 데이터로 제공하는 모션 변화 패턴 수집부를 포함하는, 딥러닝 기반의 인체 동작 인식 장치."}
{"patent_id": "10-2022-0187912", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4 항에 있어서,공개특허 10-2024-0105071-3-제3 딥러닝 모델은 시계열 예측 알고리즘을 기반으로 하는 모델인, 딥러닝 기반의 인체 동작 인식 장치."}
{"patent_id": "10-2022-0187912", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "하나 이상의 프로세서와, 상기 프로세서에 의해 실행 가능한 프로그램 명령어들을 저장하는 메모리를 포함하는컴퓨팅 장치에서 수행되는 방법으로,입력된 영상에서 단일 이미지 프레임을 설정된 주기로 샘플링하는 샘플링 단계;제1 딥러닝 모델을 통해 단일 이미지 프레임으로부터 인체를 검출하고 인체의 모션을 분류하는 객체 및 모션 검출 단계;제2 딥러닝 모델을 통해 복수의 이미지 프레임들에서 객체 및 모션 검출 단계에서 검출한 인체의 선형성과 동일성을 판단하여 동일인의 위치를 추적하는 객체 추적 단계; 및제3 딥러닝 모델을 통해 동일인으로 판단된 인체의 연속된 모션 패턴으로부터 인체의 동작을 분류하는 패턴 분석 단계;를 포함하는, 딥러닝 기반의 인체 동작 인식 방법."}
{"patent_id": "10-2022-0187912", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서, 객체 추적 단계는 객체 및 모션 검출 단계의 인체 검출 결과에 따라 인체 부분만 추출하여 제2 딥러닝 모델의입력 데이터로 제공하는 인체 추출 단계를 포함하는, 딥러닝 기반의 인체 동작 인식 방법."}
{"patent_id": "10-2022-0187912", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7 항에 있어서,패턴 분석 단계는 객체 및 모션 검출 단계의 모션 인식 결과와 객체 추적 단계의 동일인 추적 결과에 기초하여연속적인 이미지 프레임에서 인체의 모션 변화 패턴을 수집하여 제3 딥러닝 모델의 입력 데이터로 제공하는 모션 변화 패턴 수집 단계를 포함하는, 딥러닝 기반의 인체 동작 인식 방법."}
{"patent_id": "10-2022-0187912", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 인체 동작 인식 장치는 단일 이미지 프레임에서 인체를 검출하고 인체의 모션을 분류한 후, 복수의 이 미지 프레임들에서 각각 검출된 인체를 선형성과 동일성에 기초하여 동일인의 위치를 추적하고 동일인으로 판단 된 인체의 연속된 모션 패턴으로부터 인체의 동작을 분류한다."}
{"patent_id": "10-2022-0187912", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 컴퓨터 비전 기술에 관한 것으로, 보다 구체적으로 영상 데이터 내의 2D 영상에서 빠른 응답속도로 인체를 검출하고 그 동작을 인식하는 기술에 관한 것이다."}
{"patent_id": "10-2022-0187912", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술은 다양한 분야에 성공적으로 적용되어 활용되고 있다. 특히, 딥러닝 기반의 영상분석 기술은 이 미지 인식과 분류 분야에서 높은 정확도를 보여주고 있으며, 의료, 교통, 범죄 등 다양한 분야에 적용되어 사용 되고 있다. 산업현장에서 영상분석은 스트리밍으로 구성된 다량의 동영상 데이터를 빅데이터로 취급한다. 따라서 영상에서 인간의 행위를 분류하는 연구 분야 또한 매우 큰 데이터를 취급하는 분야이며, 이로 인하여 느린 응답 속도를 갖는 특징이 있다. 동작을 감지하는 모션인식 분야는 인체의 동작을 분석하며, 일반적으로 복잡한 인간 관절의 움직임과 다양한 객 체의 연관 관계를 분석하고 이해해야 하는 등 해석의 난이도가 어려운 분야이다. 대표적으로 딥러닝 기반의 Human Skeleton Detection 알고리즘이 이에 해당하며, Skeleton Detection 알고리즘은 인체의 자세추정에 대한 근본적인 해결을 위해 연구되었다. 이 알고리즘은 영상 딥러닝 기술을 이용하여 이미지에서 신체의 관절에 해당하는 좌표를 추출하는 방식으로 이루어진다. 이 과정에서 실제 관절의 방향과 위치를 확률로 나타내어 가장 높 은 값을 선택하며, 이후 별도의 알고리즘을 추가하여 관절의 좌표의 형태에 따라 자세를 추정한다. 따라서, 이 알고리즘은 영상 내의 모든 인체 관절을 포착해야 하는 근본적인 문제로 인하여 매우 느리게 작동하는 문제가 있다. 이와는 별도로 최근에 뛰어난 성과를 보이는 동작 분석 모델로 Two stream networks구조의 알고리즘인 SlowFast Network 모델이 있다. SlowFast Network 모델은 연속된 2D 이미지로 구성된 영상 데이터에서 다양한 상황과 행 동 탐지를 목적으로 한다. SlowFast Network 모델은 다수의 앞뒤로 연관된 프레임을 모아 연결하여 학습하며, 상황을 이해하는 Slow 모델과 동작을 이해하는 Fast 모델로 불리우는 두 개의 컨볼루션 네트워크를 연결하여 분 석한다. 사용되는 SlowFast Network 모델의 구조는 Slow pathway와 Fast pathway로 불리는 두 개의 알고리즘을 결합하는 Two stream networks형태를 동일하게 사용한다. 따라서, Slow pathway는 영상의 전반적인 환경과 상황 을 분석하고 Fast pathway는 동적 움직임을 포착한다. 각 pathway의 내부구조는 컨볼루션 네트워크로 구성되며, Fast pathway는 높은 프레임 레이트(High frame rate)를 사용하여 픽셀의 변화를 감지하고, 영상의 채널 수를 줄여 계산 비용을 감소시킨다. SlowFast Network 모델은 하나의 객체로 분리된 연속 이미지 영상을 분석하게 됨 으로써 보다 효과적으로 작동한다. 이러한 복합적인 딥러닝 알고리즘을 통하여 영상내의 다수의 인체 객체에서 불필요한 배경을 제외하게 되며, Two stream networks기반의 동작분석 알고리즘을 통하여 하나 또는 두 개의 인 체 객체로 분리된 연속 이미지 영상을 분석하게 됨으로서 Divide-and-conquer 알고리즘 효과를 나타내게 되며, 비교적 빠르게 동작한다. 하지만, 복수의 인원이 다수의 프레임에 연속되어 추출되는 경우 매우 느린 응답 속도 를 보여준다. 이와 같이 기존의 동작 분류알고리즘은 연속된 이미지 데이터를 한번에 분석해야 하므로 상대적으 로 큰 크기의 데이터를 분석해야 하는 근본적인 문제가 있다."}
{"patent_id": "10-2022-0187912", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 CCTV 영상 데이터 등의 빅데이터를 처리하면서도 낮은 연산 비용으로 인체 동작을 분석할 수 있는 장 치 및 방법을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2022-0187912", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 양상에 따르는 딥러닝 기반의 인체 동작 인식 장치는 객체 및 모션 검출부와, 객체 추적부와, 패 턴 분석부를 포함한다. 객체 및 모션 검출부는 제1 딥러닝 모델을 통해 입력된 영상에서 샘플링된 단일 이미지 프레임으로부터 인체를 검출하고 인체의 모션을 분류한다. 객체 추적부는 제2 딥러닝 모델을 통해 복수의 이미지 프레임들에서 객체 및 모션 검출부가 검출한 인체의 선형 성과 동일성을 판단하여 동일인의 위치를 추적한다. 패턴 분석부는 제3 딥러닝 모델을 통해 동일인으로 판단된 인체의 연속된 모션 패턴으로부터 인체의 동작을 분 류한다. 이때, 제1 딥러닝 모델은 원샷 객체 검출(One-Shot Object Detection) 모델이며, 인체 검출과 함께 인체의 모션 을 분류하도록 학습된 모델일 수 있다. 구체적으로, 객체 추적부는 객체 및 모션 검출부의 인체 검출 결과에 따라 인체 부분만 추출하여 제2 딥러닝 모 델의 입력 데이터로 사용할 수 있다. 또한, 제2 딥러닝 모델은 SORT(Simple Online and Realtime Tracking) 알고리즘을 기반으로 모델인, 딥러닝 기 반의 인체 동작 인식 장치. 본 발명의 추가적 양상에 따르면, 패턴 분석부는 객체 및 모션 검출부의 모션 인식 결과와 객체 추적부의 동일 인 추적 결과에 기초하여 연속적인 이미지 프레임에서 인체의 모션 변화 패턴을 수집하여 제3 딥러닝 모델의 입 력 데이터로 제공하는 모션 변화 패턴 수집부를 포함할 수 있다. 또한, 제3 딥러닝 모델은 시계열 예측 알고리즘을 기반으로 하는 모델일 수 있다. 본 발명의 일 실시 예에 따르는 딥러닝 기반의 인체 동작 인식 방법은 하나 이상의 프로세서와, 상기 프로세서 에 의해 실행 가능한 프로그램 명령어들을 저장하는 메모리를 포함하는 컴퓨팅 장치에서 수행되는 방법으로, 샘 플링 단계와, 객체 및 모션 검출 단계와, 객체 추적 단계와, 패턴 분석 단계를 포함한다. 샘플링 단계는 입력된 영상에서 단일 이미지 프레임을 설정된 주기로 샘플링한다. 객체 및 모션 검출 단계는 제1 딥러닝 모델을 통해 단일 이미지 프레임으로부터 인체를 검출하고 인체의 모션을 분류한다. 객체 추적 단계는 제2 딥러닝 모델을 통해 복수의 이미지 프레임들에서 객체 및 모션 검출부가 검출한 인체의 선형성과 동일성을 판단하여 동일인의 위치를 추적한다. 패턴 분석 단계는 제3 딥러닝 모델을 통해 동일인으로 판단된 인체의 연속된 모션 패턴으로부터 인체의 동작을 분류한다. 본 발명의 또 다른 실시 예에 따르면, 객체 추적 단계는 객체 및 모션 검출 단계의 인체 검출 결과에 따라 인체 부분만 추출하여 제2 딥러닝 모델의 입력 데이터로 제공하는 인체 추출 단계를 포함할 수 있다. 본 발명의 또 다른 실시 예에 따르면, 패턴 분석 단계는 객체 및 모션 검출 단계의 모션 인식 결과와 객체 추적 단계의 동일인 추적 결과에 기초하여 연속적인 이미지 프레임에서 인체의 모션 변화 패턴을 수집하여 제3 딥러 닝 모델의 입력 데이터로 제공하는 모션 변화 패턴 수집 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0187912", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면 CCTV 영상 데이터 등의 빅데이터를 처리하면서도 낮은 연산 비용으로 인체 동작을 분석할 수 있다."}
{"patent_id": "10-2022-0187912", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "전술한, 그리고 추가적인 양상들은 첨부된 도면을 참조하여 설명하는 실시 예들을 통해 구체화된다. 각 실시 예들의 구성 요소들은 다른 언급이나 상호간에 모순이 없는 한 실시 예 내에서 다양한 조합이 가능한 것으로 이 해된다. 블록도의 각 블록은 어느 경우에 있어서 물리적인 부품을 표현할 수 있으나 또 다른 경우에 있어서 하 나의 물리적인 부품의 기능의 일부 혹은 복수의 물리적인 부품에 걸친 기능의 논리적인 표현일 수 있다. 때로 는 블록 혹은 그 일부의 실체는 프로그램 명령어들의 집합(set)일 수 있다. 이러한 블록들은 전부 혹은 일부가 하드웨어, 소프트웨어 혹은 이들의 결합에 의해 구현될 수 있다. 도 1은 본 발명의 일 양상에 따른 인체 동작 인식 장치의 블록도이다. 본 발명의 일 양상에 따르는 딥러닝 기반 의 인체 동작 인식 장치는 하나 이상의 프로세서와, 프로세서와 연결되고 프로세서에 의해 실행 가능한 프 로그램 명령어들을 저장하는 메모리를 포함하는 컴퓨팅 장치이다. 인체 동작 인식 장치는 프로세서와, 메모리 외에 추가적으로 저장 장치, 디스플레이, 입력 장치 등을 더 포 함하는 컴퓨터 장치일 수 있다. 프로세서는 인체 동작 인식 장치를 구현하는 프로그램 명령어들을 실행하는 프로세서이고, 메모리는 프로세서와 연결되고 프로세서에 의해 실행 가능한 프로그램 명령어들과 프로세서가 연 산에 사용할 데이터와 프로세서에 의해 처리된 데이터 등을 저장한다. 본 발명의 일 양상에 따르는 딥러닝 기반의 인체 동작 인식 장치는 객체 및 모션 검출부와, 객체 추적 부와, 패턴 분석부를 포함한다. 본 발명의 인체 동작 인식 장치는 CCTV를 비롯한 영상 감시 장치 등으로부터 수집되는 영상 데이터를 분석 하여 실시간으로 인체의 동작을 검출하는 장치이다.객체 및 모션 검출부는 샘플링부와 제1 딥러닝 모델을 포함한다. 객체 및 모션 검출부와, 샘플링부와, 제1 딥러닝 모델은 적어도 그 기능의 일부가 프로세서에 실행되는 컴퓨터 프로그램 명령 어 세트로 구현될 수 있다. 샘플링부는 영상 감시 장치 등으로부터 입력되는 동영상인 영상 데이터에서 설정된 샘플링 간격으로 이미 지 프레임들을 생성한다. 샘플링부에 의해 샘플링되는 이미지 프레임은 입력된 영상 데이터에서 캡처된 이 미지 데이터이다. 이 이미지 데이터 즉, 단일 이미지 프레임이 제1 딥러닝 모델에 입력 데이터로 전달된다. 제1 딥러닝 모델은 이미지 데이터에서 객체를 인식하여 경계 상자(bounding box)를 표시하여 객체의 종류 를 표시하며 객체의 종류가 사람인 경우 해당 인체의 모션을 분류(예, 걷기, 달리기, 빠르게 걷기)까지 하도록 학습된 딥러닝 모델이다. 제1 딥러닝 모델을 학습시키기 위해서는 인체와 모션으로 분류된 이미지 데이터 가 필요하며, 이 이미지 데이터를 이용하여 학습시켜 종료의 객체의 위치(영상 내 좌표)와 종류를 분류하는 종 류의 객체 검출 모델과 달리 제1 딥러닝 모델은 객체의 위치(좌표)와 그 객체의 모션까지 분류할 수 있다. 발명의 양상에 따라서는 제1 딥러닝 모델은 이미지 데이터 내에 검출되는 객체 중 사람 즉, 인체만 검출하 도록 학습될 수도 있다. 다만, 이에 제한되는 것은 아니다. 객체 및 모션 검출부는 학습된 제1 딥러닝 모델을 통해 입력된 영상에서 샘플링된 단일 이미지 프레 임으로부터 인체를 검출하고 인체의 모션을 분류한다. 이때, 제1 딥러닝 모델은 원샷 객체 검출(One-Shot Object Detection) 모델이며, 인체 검출과 함께 인체 의 모션을 분류하도록 학습된 모델일 수 있다. 제1 딥러닝 모델은 YOLO 모델, SSD 모델, RetinaNet 모델 등과 같은 CNN기반의 원샷 객체 검출 모델일 수 있다. 제1 딥러닝 모델은 사전에 인체-모션에 따라 구분된 영상 빅데이터를 학습하여야 한다. 제1 딥러닝 모델을 학습시키는 학습 데이터는 인체의 각 모션에 대하여 다양한 카메라 각도와 높이, 인체의 연령, 인 체의 성별, 복작 등 다양한 형태를 학습할 수 있도록 구성되어야 한다. YOLO 모델, SSD 모델, RetinaNet 모델은 공지된 기술로 간단하게 설명한다. YOLO(You Only Look Once) 모델은 객체 검출 분야에서 가장 대중적으로 사용되는 실시간 객체 검출 모델이다. YOLO 모델은 카메라 영상에서 각 개체의 절대적인 크기와 위치를 좌표의 형태로 추출한다. YOLO 모델은 카메라 영상에서 2차원 이미지 데이터를 입력 받아 컨볼루션 계층(Convolution Layer)을 이용하여 객체의 절대적인 크 기와 위치를 좌표의 형태로 추출하고 객체의 종류를 판별할 수 있다. 일반적으로 YOLO는 다수의 컨볼루션 계층 과 완전 연결층(Fully Connected Layer)으로 구성되어 이미지의 특징을 추출한다. 완전 연결층은 추출된 결과로 부터 객체의 위치와 종류를 판별한다. SSD(Single Shot Multibox Detector) 모델은 VGG-16을 백본으로 사용하되 일부 컨볼루션 계층만 사용하여 특징 을 추출하며 추출된 특징은 여러 보조 검출기들을 거치며 객체 검출을 수행한다. YOLO는 최종 특징맵에만 경계 상자와 분류 정보가 있는데 비해 SSD는 여러 히든 레이어에 정보가 분산되어 있다. SSD는 크기가 다른 특징맵에 해당하는 레이어가 6개 있으며 큰 특징맵은 작은 객체를 검출하고 작은 특징맵은 큰 객체를 검출할 수 있다. SSD는 한 개의 객체에 대하여 다양한 크기의 경계상자를 이용하여 예측하는 알고리즘이다. RetinaNet 모델은 크로스 엔트로피 손실함수에서 변형된 초점 손실(Focal loss) 함수를 사용한다. RetinaNet 모 델은 ResNet을 백본으로 사용하며, FPN(Feature Pyramid Networks)을 적용한다. 백본 네트워크인 ResNet은 입 력된 전체 이미지에 대해서 특징맵을 계산하는 역할을 수행한다. RetinaNet 모델은 두 개의 서브네트워크를 포 함하며, 첫번째 서브네트워크는 ResNet의 결과에서 객체 분류를 수행하며, 두번째 서브네트워크는 경계상자 회 귀(bounding box regression)를 수행한다. 발명의 양상에 따라서는 제1 딥러닝 모델은 Faster R-CNN 모델, R-FCN 모델 등을 포함하는 이단계 방식 알 고리즘을 사용할 수 있다. 이단계 방식 알고리즘은 정확도 측면에서는 단일 단계 방식 알고리즘보다 좋은 성능 을 낸다. Faster R-CNN 모델, R-FCN 모델, FPN-FRCN 모델은 공지된 기술로 간단하게 설명한다. Faster R-CNN 모델은 후보 영역 추출을 위해 사용되는 선택적 검색(Selective Search) 알고리즘으로 인해 발생 하는 병목현상을 해결하고자 후보 영역 추출 작업을 수행하는 RPN(Region Proposal Network)을 추가한구조이다. Faster R-CNN은 RPN과 Fast R-CNN이 합쳐진 모델이다. Faster R-CNN 모델은 원본 이미지를 사전 학 습된 CNN 모델에 입력하여 특징 맵을 얻고, 특징 맵을 RPN에 전달되어 적절한 후보 영역을 산출(region proposals)한다. 후보 영역 산출 과정과 CNN 모델을 통해 얻은 특징 맵에 대하여 RoI 풀링(Pooling)을 수행하여 고정된 크기의 특징 맵을 얻은 후 Fast R-CNN 모델에 고정된 크기의 특징 맵을 입력하여 객체 분류와 경계상자 예측을 수행한다. R-FCN 모델은 RPN을 통해 추출한 관심 영역(RoI)끼리 연산을 공유하며 위치에 대한 정보를 포함하는 특징 맵을 사용하는 구조를 갖는다. R-FCN 모델은 Faster R-CNN 모델에서 RPN 이후 단계의 서브 네트워크를 FCN(Fully Convolutional Network)으로 수정하여 사용한다. 객체 추적부는 객체 추출부와 제2 딥러닝 모델을 포함한다. 객체 추적부와, 객체 추출부 와 제2 딥러닝 모델은 적어도 그 기능의 일부가 프로세서에 실행되는 컴퓨터 프로그램 명령어 세트로 구현될 수 있다. 객체 추적부는 제2 딥러닝 모델을 통해 복수의 이미지 프레임들에서 객체 및 모션 검출부가 검 출한 인체의 선형성과 동일성을 판단하여 동일인의 위치를 추적한다. 제2 딥러닝 모델은 복수의 객체를 동시에 추적하는 Multi-Object Tracking 알고리즘을 사용한다. 객체 및 모션 검출부가 출력한 복수의 이미지 프레임들에 대한 검출 결과(객체 및 모션 검출부의 출력 결과는 연속적이나 실제 영상 데이터는 일정한 샘플링 간격으로 샘플링된 이미지에 대한 검출 결과)를 입력 데이터로 하여 개별 객체들을 추적한다. 발명의 양상에 따라서는 제2 딥러닝 모델은 인식된 인체에 대하여만 객체 추적을 할 수도 있다. 이때도 이미지 프레임에서 위치 정보는 그대로 유지한다. 구체적으로, 객체 추적부는 객체 및 모션 검출부의 인체 검출 결과에 따라 인체 부분만 추출하여 제2 딥러닝 모델의 입력 데이터로 사용할 수 있다. 객체 추출부는 이미지 프레임에서 객체 및 모션 검출 부의 출력 중 경계 상자에 관한 정보 즉, 객체의 좌표 정보를 이용하여 이미지 프레임에서 해당 부분만 추 출하여 이 추출된 데이터만 제2 딥러닝 모델의 입력 데이터로 제공할 수 있다. 또한, 제2 딥러닝 모델은 SORT(Simple Online and Realtime Tracking) 알고리즘을 기반으로 모델일 수 있 다. 특히 제2 딥러닝 모델은 SORT 알고리즘을 보완 확장한 DeepSORT 알고리즘을 기반으로 하는 모델일 수 있다. DeepSORT는 이전 프레임에 등장한 개체를 이용하여 다음 프레임의 개체의 위치를 예측할 때 사용하는 칼 만 필터(Kalman filter)를 기본으로 딥러닝 피쳐(Re-Id)를 추가로 반영하여 이전 프레임에서 발견한 객체와 다 음 프레임에서 발견한 객체의 동일성을 판단하기 위해 헝가리안 알고리즘(Hungarian Algorithm)을 사용한다. 패턴 분석부는 모션 변화 패턴 수집부와 제3 딥러닝 모델을 포함한다. 패턴 분석부와, 모 션 변화 패턴 수집부와 제3 딥러닝 모델은 적어도 그 기능의 일부가 프로세서에 실행되는 컴퓨터 프 로그램 명령어 세트로 구현될 수 있다. 패턴 분석부는 제3 딥러닝 모델을 통해 동일인으로 판단된 인체의 연속된 모션 패턴으로부터 인체의 동작을 분류한다. 패턴 분석부는 영상의 변화에 따라 동일인으로 판별된 인체의 누적된 모션의 패턴을 분 석하여 인체의 동작을 분류한다. 모션 변화 패턴 수집부는 객체 및 모션 검출부의 모션 인식 결과와 객체 추적부의 동일인 추적 결과에 기초하여 연속적인 이미지 프레임에서 인체의 모션 변화 패턴을 수집하여 제3 딥러닝 모델의 입력 데이터로 제공할 수 있다. 모션 변화 패턴 수집부는 객체 및 모션 검출부가 출력하는 결과와 객체 추 적부의 동일인의 추적 결과에 따라 그 인체의 모션 패턴을 연속적으로 수집하여 인식된 인체 별로 모션 패 턴 데이터를 생성하고 이를 제3 딥러닝 모델의 입력 데이터로 제공한다. 제3 딥러닝 모델은 인체의 모션 패턴 데이터로부터 인체의 동작을 분류하는 모델로 표준 동작 모델을 위하 여 연속적인 인체-모션 패턴 학습 데이터로 학습된다. 인체-모션 패턴 학습 데이터의 예를 들어, 인체#1로 인식 된 사람이 복수의 이미지 프레임에서 인식된 모션 패턴이 걷기-뛰기-걷기로 수집되면 제3 딥러닝 모델은 이를 빠르게 걷기로 해당 인체의 동작을 분류할 수 있다. 각 동작 별로 패턴의 길이가 다를 수 있다. 따라서, 제3 딥러닝 모델은 LSTM, RNN과 같은 시계열 예측 알 고리즘을 기반으로 하는 모델일 수 있다. 다만, 이에 제한되는 것은 아니며 DNN과 같은 간단한 모델일 수도 있 다. 도 2는 본 발명의 일 양상에 따른 인체 동작 인식 장치의 인체 동작 인식의 원리를 개념적으로 도시한 것이다. 도 2는 연속된 3장의 프레임 또는 연속적으로 샘플링된 3장의 이미지 프레임을 보여주고 있다. 이 이미지 프레 임에서 객체 및 모션 검출부는 첫번째와, 두번째 프레임에서 총 3명의 인체 객체를 검출하였고, 세번째 프 레임에서는 2명을 검출하였다. 이때, 객체 및 모션 검출부의 제1 딥러닝 모델은 인체의 좌표와 객체의 종 류(인체)와 인체의 모션(예, Run, Walk)을 검출하고 분류하였다. 도 2에서 첫번째 프레임의 중앙에 위치한 인체 는 미리 학습된 Walk포즈로 탐지된 것을 나타내었다. 객체 및 모션 검출부는 이미지 프레임이 입력될 때마 다 인체를 검출한 경계 상자(bounding box)와 인체의 모션을 출력하고 이를 Multi-Object Tracking 알고리즘을 사용하는 객체 추적부에 입력한다. 객체 추적부는 검출된 각각의 인체 객체에 임의의 유니크한 숫자 인 객체 번호를 부여하고, 다음 이미지 프레임에서 검출된 인체 객체와의 동일성을 판별하여 이전과 동일한 객 체인 경우 이전의 부여된 동일한 객체 번호를 통지한다. 예를 들어 도 2에서 첫번째 프레임에서 중앙에 위치한 인체 이미지는 2번 객체 번호가 부여된 것을 보여준다. 패턴 분석부는 연속된 프레임의 진행에 따른 동일 객체의 포즈를 결합하여 비교한다. 예를 들어 도 2에서 2번 객체 번호가 부여된 인체의 경우 프레임의 진행에 따라 Walk포즈, Run포즈, Walk포즈로 패턴이 변화하고 있다. 이러한 패턴 변화를 수집하고 패턴 분석부는 이를 기초로 2번 객체 번호의 인체가 빨리 걷기(Fast Walk) 행동을 하는 것으로 판별할 수 있다. 도 3은 본 발명의 일 양상에 따른 인체 동작 인식 장치가 사용하는 딥러닝 모델의 예시적 구성을 도시한 것이다. 도 3에 도시된 예는 YOLO를 제1 딥러닝 모델로 구성하고, DeepSORT을 제2 딥러닝 모델로 구 성하고, DNN은 제3 딥러닝 모델로 구성한 예이다. 도 3은 하나의 예시에 불과하므로 각각의 딥러닝 모델은 다른 모델로 구성될 수 있다. 예를 들어, LSTM이 제3 딥러닝 모델로 구성될 수 있다. 도 4는 본 발명의 인체 동작 인식 방법의 절차도이다. 본 발명의 일 실시 예에 따르는 딥러닝 기반의 인체 동작 인식 방법은 하나 이상의 프로세서와, 상기 프로세서에 의해 실행 가능한 프로그램 명령어들을 저장하는 메모리 를 포함하는 컴퓨팅 장치에서 수행되는 방법이다. 이 컴퓨팅 장치가 인체 동작 인식 장치이며, 앞서 설명한 바 있다. 본 발명의 일 실시 예에 따르는 딥러닝 기반의 인체 동작 인식 방법은 샘플링 단계와, 객체 및 모션 검출 단계 와, 객체 추적 단계와, 패턴 분석 단계를 포함하며, 각 단계는 프로세서 에서 실행되는 프로그램 명령어 세트로 구현될 수 있다. 샘플링 단계는 인체 동작 인식 장치인 컴퓨팅 장치가 입력된 영상에서 단일 이미지 프레임을 설정된 주기로 샘플링한다. 샘플링 단계는 영상 감시 장치 등으로부터 입력되는 동영상인 영상 데이터에서 설정된 샘플링 간격으로 이미지 프레임들을 생성(S4000)한다. 샘플링 단계에서 샘플링되는 이미지 프레임은 입력된 영상 데이터에서 캡처된 이 미지 데이터이다. 이 이미지 데이터 즉, 단일 이미지 프레임이 제1 딥러닝 모델에 입력 데이터로 전달된다. 객체 및 모션 검출 단계는 인체 동작 인식 장치가 제1 딥러닝 모델을 통해 단일 이미지 프레임으로부 터 인체를 검출하고 인체의 모션을 분류(S4020)한다. 제1 딥러닝 모델은 이미지 데이터에서 객체를 인식하여 경계 상자(bounding box)를 표시하여 객체의 종류 를 표시하며 객체의 종류가 사람인 경우 해당 인체의 모션을 분류(예, 걷기, 달리기, 빠르게 걷기)까지 하도록 학습된 딥러닝 모델이다. 제1 딥러닝 모델을 학습시키기 위해서는 인체와 모션으로 분류된 이미지 데이터 가 필요하며, 이 이미지 데이터를 이용하여 학습시켜 종료의 객체의 위치(영상 내 좌표)와 종류를 분류하는 종 류의 객체 검출 모델과 달리 제1 딥러닝 모델은 객체의 위치(좌표)와 그 객체의 모션까지 분류할 수 있다. 발명의 양상에 따라서는 제1 딥러닝 모델은 이미지 데이터 내에 검출되는 객체 중 사람 즉, 인체만 검출하 도록 학습될 수도 있다. 다만, 이에 제한되는 것은 아니다. 이때, 제1 딥러닝 모델은 원샷 객체 검출(One-Shot Object Detection) 모델이며, 인체 검출과 함께 인체 의 모션을 분류하도록 학습된 모델일 수 있다. 제1 딥러닝 모델은 YOLO 모델, SSD 모델, RetinaNet 모델 등과 같은 CNN기반의 원샷 객체 검출 모델일 수 있다. 객체 추적 단계는 인체 동작 인식 장치가 제2 딥러닝 모델을 통해 복수의 이미지 프레임들에서 객체 및 모션 검출부가 검출한 인체의 선형성과 동일성을 판단하여 동일인의 위치를 추적(S4060)한다. 제2 딥러닝 모델은 복수의 객체를 동시에 추적하는 Multi-Object Tracking 알고리즘을 사용한다. 객체 및 모션 검출부가 출력한 복수의 이미지 프레임들에 대한 검출 결과(객체 및 모션 검출부의 출력 결과는연속적이나 실제 영상 데이터는 일정한 샘플링 간격으로 샘플링된 이미지에 대한 검출 결과)를 입력 데이터로 하여 개별 객체들을 추적한다. 발명의 실시 예에 따라서는 제2 딥러닝 모델은 인식된 인체에 대하여만 객 체 추적을 할 수도 있다. 이때도 이미지 프레임에서 위치 정보는 그대로 유지한다. 본 발명의 또 다른 실시 예에 따르면, 객체 추적 단계는 객체 및 모션 검출 단계의 인체 검출 결과에 따라 인체 부분만 추출하여 제2 딥러닝 모델의 입력 데이터로 제공(S4040)하는 인체 추출 단계를 포함할 수 있다. 또한, 제2 딥러닝 모델은 SORT(Simple Online and Realtime Tracking) 알고리즘을 기반으로 모델일 수 있 다. 특히 제2 딥러닝 모델은 SORT 알고리즘을 보완 확장한 DeepSORT 알고리즘을 기반으로 하는 모델일 수 있다. DeepSORT는 이전 프레임에 등장한 개체를 이용하여 다음 프레임의 개체의 위치를 예측할 때 사용하는 칼 만 필터(Kalman filter)를 기본으로 딥러닝 피쳐(Re-Id)를 추가로 반영하여 이전 프레임에서 발견한 객체와 다 음 프레임에서 발견한 객체의 동일성을 판단하기 위해 헝가리안 알고리즘(Hungarian Algorithm)을 사용한다. 구체적으로, 제2 딥러닝 모델은 객체 및 모션 검출부의 인체 검출 결과에 따라 인체 부분만 추출하여 입력 데이터로 사용할 수 있다. 인체 추출 단계는 이미지 프레임에서 객체 및 모션 검출부의 출력 중 경계 상자에 관한 정보 즉, 객체의 좌표 정보를 이용하여 이미지 프레임에서 해당 부분만 추출하여 이 추출된 데이터 만 제2 딥러닝 모델의 입력 데이터로 제공할 수 있다. 인체 부분만 추출되더라도 추출된 부분은 이미지 프 레임 내에서의 위치 정보는 그대로 포함하여야 한다. 패턴 분석 단계는 인체 동작 인식 장치가 제3 딥러닝 모델을 통해 동일인으로 판단된 인체의 연속된 모션 패턴으로부터 인체의 동작을 분류(S4100)한다. 패턴 분석 단계에서 인체 동작 인식 장치는 영상의 변 화에 따라 동일인으로 판별된 인체의 누적된 모션의 패턴을 분석하여 인체의 동작을 분류한다. 본 발명의 또 다른 실시 예에 따르면, 패턴 분석 단계는 객체 및 모션 검출 단계의 모션 인식 결과와 객체 추적 단계의 동일인 추적 결과에 기초하여 연속적인 이미지 프레임에서 인체의 모션 변화 패턴을 수집하여 제3 딥러 닝 모델의 입력 데이터로 제공(S4080)하는 모션 변화 패턴 수집 단계를 포함할 수 있다. 모션 변화 패턴 수집 단계는 제1 딥러닝 모델이 출력하는 결과와 제2 딥러닝 모델의 동일인의 추적 결과에 따라 그 인체의 모션 패턴을 연속적으로 수집하여 인식된 인체 별로 모션 패턴 데이터를 생성하고 이를 제3 딥러닝 모델의 입력 데이터로 제공하는 단계이다. 제3 딥러닝 모델은 인체의 모션 패턴 데이터로부터 인체의 동작을 분류하는 모델로 표준 동작 모델을 위하 여 연속적인 인체-모션 패턴 학습 데이터로 학습된다. 인체-모션 패턴 학습 데이터의 예를 들어, 인체#1로 인식 된 사람이 복수의 이미지 프레임에서 인식된 모션 패턴이 걷기-뛰기-걷기로 수집되면 제3 딥러닝 모델은 이를 빠르게 걷기로 해당 인체의 동작을 분류할 수 있다. 각 동작 별로 패턴의 길이가 다를 수 있다. 따라서, 제3 딥러닝 모델은 LSTM, RNN과 같은 시계열 예측 알 고리즘을 기반으로 하는 모델일 수 있다. 다만, 이에 제한되는 것은 아니며 DNN과 같은 간단한 모델일 수도 있 다. 이상에서 본 발명을 첨부된 도면을 참조하는 실시 예들을 통해 설명하였지만 이에 한정되는 것은 아니며, 이들 로부터 당업자라면 자명하게 도출할 수 있는 다양한 변형 예들을 포괄하도록 해석되어야 한다. 특허청구범위는 이러한 변형 예들을 포괄하도록 의도되었다."}
{"patent_id": "10-2022-0187912", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 양상에 따른 인체 동작 인식 장치의 블록도이다. 도 2는 본 발명의 일 양상에 따른 인체 동작 인식 장치의 인체 동작 인식의 원리를 개념적으로 도시한 것이다. 도 3은 본 발명의 일 양상에 따른 인체 동작 인식 장치가 사용하는 딥러닝 모델의 예시적 구성을 도시한 것이다. 도 4는 본 발명의 인체 동작 인식 방법의 절차도이다."}
