{"patent_id": "10-2023-0051975", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0156478", "출원번호": "10-2023-0051975", "발명의 명칭": "시설 작물에 대한 병충해를 탐지하기 위한 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "박준용"}}
{"patent_id": "10-2023-0051975", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "시설 작물에 대한 시설 작물 이미지를 캡처하는 이미지 캡처 장치; 및상기 시설 작물 이미지를 분석하여 시맨틱 분할 이미지를 출력하는 인공 신경망 모델을 실행하는 프로세서를 포함하고,상기 인공 신경망 모델은,제1 합성곱 신경망을 이용하여, 상기 시설 작물 이미지로부터 상기 시설 작물의 잎 모양과 상기 잎 모양의 위치에 대한 공간 특징 데이터를 추출하는 공간 추출 모듈;제2 합성곱 신경망을 이용하여, 상기 시설 작물 이미지로부터 상기 잎 모양에 대한 병충해 종류를 나타내는 시맨틱 특징 데이터를 추출하는 시맨틱 추출 모듈; 및제3 합성곱 신경망을 이용하여, 상기 공간 특징 데이터와 상기 시맨틱 특징 데이터를 융합하여 획득한 데이터를기반으로 상기 잎 모양에 대한 상기 시맨틱 분할 이미지를 출력하는 특징 융합 모듈을 포함하고,상기 제2 합성곱 신경망은 히든 레이어들(hidden layers)에서 상기 시맨틱 특징 데이터를 출력하는 조기 종료(early exiting) 구조로 설계된 것을 특징으로 하는 이동 로봇."}
{"patent_id": "10-2023-0051975", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에서, 상기 히든 레이어들은,사전에 공개된(pre-published) 백본 모델(Backbone Model)로부터 추출한 레이어들로서, 상기 백본 모델에서 스킵 커넥션(skip connection) 구조로 연결된 레이어들을 제외한 나머지 레이어들인 것인 이동 로봇."}
{"patent_id": "10-2023-0051975", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에서,상기 제2 합성곱 신경망은,동일한 개수의 상기 히든 레이어들을 포함하도록 구성되고, 상기 시설 작물 이미지에 대한 특징 데이터를 순차적으로 출력하는 N개의 히든 블록들(Feat Block 1~N); 및상기 N개의 히든 블록들에 1:1로 연결되고, 상기 조기 종료(early exiting) 구조에 따라, 상기 N개의 히든 블록들에서 순차적으로 출력되는 상기 특징 데이터에 대한 분류 작업을 순차적으로 수행하여 획득한 상기 시맨틱 특징 데이터를 선택적으로 출력하는 N개의 브랜치 모듈들(branch modules)을 포함하는 이동 로봇."}
{"patent_id": "10-2023-0051975", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에서,상기 N개의 브랜치 모듈들 중에서 K(N보다 작은 자연수)번째 브랜치 모듈은,K번째 히든 블록으로부터 출력되는 상기 특징 데이터에 대한 분류 작업을 수행하여 획득한 상기 시맨틱 특징 데이터에 대한 신뢰도를 계산하고, 상기 신뢰도가 목표 신뢰도 이상인 경우, 상기 시맨틱 특징 데이터를출력하고,상기 K번째 브랜치 모듈이 상기 시맨틱 특징 데이터를 출력하면, K번째 이후의 상기 히든 블록들과 브랜치 모듈들은 연산 동작을 조기에 중지(early stop)하는 것인 이동 로봇."}
{"patent_id": "10-2023-0051975", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2024-0156478-3-제4항에서, 1개의 나머지 블록을 더 포함하고,상기 히든 레이어들의 전체 개수를 상기 N으로 나눈 몫이 Q이고, 나머지가 R일 때, 각 히든 블록은 Q개의 상기히든 레이어들을 포함하도록 구성되고, 상기 1개의 나머지 블록은 R개의 히든 레이어들을 포함하도록 구성된 것인 이동 로봇."}
{"patent_id": "10-2023-0051975", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에서, 스마트 팜 내에서 상기 시설 작물의 위치 데이터를 측정하는 작물 측위 장치; 및사용자 장치에서 상기 시맨틱 분할 이미지와 상기 위치 데이터를 시각적으로 표시하기 위해, 상기 시맨틱 분할이미지와 상기 위치 데이터를 무선 통신 방식으로 상기 사용자 장치로 송신하는 통신 장치를 더 포함하는 이동로봇."}
{"patent_id": "10-2023-0051975", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에서,상기 작물 측위 장치는,상기 이동 로봇의 현재 위치를 나타내는 GPS 좌표를 획득하는 GPS 수신기;스마트 팜 지도를 저장하는 메모리; 및상기 이동 로봇의 GPS 좌표를 상기 스마트 팜 지도에 맵핑하고 상기 스마트 팜 지도에 맵핑된 상기 GPS 좌표에대응하는 지도 좌표를 기반으로 상기 시설 작물의 위치 데이터를 산출하는 프로세서를 포함하는 이동 로봇."}
{"patent_id": "10-2023-0051975", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "저장소, 프로세서 및 통신 장치를 포함하는 서버에서 시설 작물에서 발생한 병충해를 탐지하기 위한 인공 지능모델의 생성 방법에서,상기 프로세서가, 시설 작물 이미지로부터 상기 시설 작물의 잎 모양에 대한 공간 특징 데이터를 추출하는 제1합성곱 신경망을 생성하는 단계;상기 프로세서가, 상기 시설 작물 이미지로부터 상기 시설 작물의 잎 모양에 대한 병충해의 종류를 나타내는 시맨틱 특징 데이터를 추출하는 제2 합성곱 신경망을 생성하는 단계;상기 프로세서가, 상기 공간 특징 데이터와 상기 시맨틱 특징 데이터를 융합하고, 상기 융합된 데이터를 분석하여 상기 잎 모양에 대한 시맨틱 분할 이미지를 출력하는 제3 합성곱 신경망을 생성하는 단계; 및상기 프로세서가, 상기 제1 내지 제3 합성곱 신경망을 연결하여 상기 인공 지능 모델을 생성하는 단계를 포함하고,상기 제2 합성곱 신경망은, 히든 레이어들(hidden layers)에서 상기 시맨틱 특징 데이터를 출력하는 조기 종료(early exiting) 구조를 갖도록 설계된 것인 인공 지능 모델의 생성 방법."}
{"patent_id": "10-2023-0051975", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에서, 상기 제2 합성곱 신경망을 생성하는 단계는,상기 프로세서에 의해 실행되는 로더(loader)가 상기 저장소에 저장된 백본 모델(Backbone Model)을 메모리에로딩하는 단계;상기 프로세서에 의해 실행되는 마크 모듈(mark module)이, 상기 메모리에 로딩된 백본 모델로부터 분리 가능한상기 히든 레이어들을 추출하는 단계; 및공개특허 10-2024-0156478-4-상기 프로세서에 의해 실행되는 재구성 모듈(reconstruction module)이, 상기 추출된 히든 레이어들을 재구성하고, 상기 재구성된 히든 레이어들을 포함하는 상기 제2 합성곱 신경망을 생성하는 단계를 포함하는 인공 지능 모델의 생성 방법."}
{"patent_id": "10-2023-0051975", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에서,상기 백본 모델로부터 분리 가능한 상기 히든 레이어들을 추출하는 단계는,상기 백본 모델에서 스킵 커넥션(skip connection) 구조로 연결된 레이어들을 제외한 나머지 레이어들을 상기히든 레이어들로서 추출하는 단계인 것인 인공 지능 모델의 생성 방법."}
{"patent_id": "10-2023-0051975", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에서, 상기 백본 모델로부터 분리 가능한 상기 히든 레이어들을 추출하는 단계는,상기 백본 모델에서 메인 경로에 배치된 레이어들과 상기 메인 경로를 우회하는 서브 경로에 배치된 레이어들을제외한 나머지 레이어들을 상기 히든 레이어들로서 추출하는 단계인 것인 인공 지능 모델의 생성 방법."}
{"patent_id": "10-2023-0051975", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에서,상기 재구성된 히든 레이어들을 포함하는 상기 제2 합성곱 신경망을 생성하는 단계는,상기 추출된 히든 레이어들의 전체 개수를 기설정된 N으로 나눈 몫이 Q이고, 나머지가 R일 때, 상기 추출된 히든 레이어들을 Q개씩 묶어서 N개의 히든 블록들로 재구성하고, 상기 추출된 히든 레이어들을 Q개씩 묶은 후 남은 R개의 히든 레이어들을 1개의 나머지 블록으로 재구성하는 단계;상기 N개의 히든 블록들과 상기 N개의 브랜치 모듈을 1:1로 연결하는 단계; 및상기 1:1로 연결된 상기 N개의 히든 블록들과 상기 N개의 브랜치 모듈을 포함하는 상기 제2 합성곱 신경망을 생성하는 단계를 포함하는 인공 지능 모델의 생성 방법."}
{"patent_id": "10-2023-0051975", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에서, 상기 N개의 브랜치 모듈들 중에서 K(N보다 작은 자연수)번째 브랜치 모듈은,K번째 히든 블록에서 출력한 특징 데이터에 대한 분류 작업을 수행하여 획득한 상기 시맨틱 특징 데이터의 신뢰도를 계산하고, 상기 신뢰도가 목표 신뢰도 이상인 경우, 상기 시맨틱 특징 데이터를 출력하고, 상기 K째 브랜치 모듈이 상기 시맨틱 특징 데이터를 출력하면, 상기 K번째 이후의 히든 블록들과 브랜치 모듈들은 연산 동작을 조기에 중지(early stop)하는 것인 인공 지능 모델의 생성 방법."}
{"patent_id": "10-2023-0051975", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에서, 상기 인공 지능 모델을 생성하는 단계 이후,상기 프로세서가 병충해와 관련된 샘플 데이터를 이용하여 상기 생성된 인공 지능 모델을 학습시키는 단계; 및통신 장치가, 상기 학습된 인공 지능 모델을 이동 로봇으로 송신하는 단계를 더 포함하는 인공 지능 모델의 생성 방법.공개특허 10-2024-0156478-5-"}
{"patent_id": "10-2023-0051975", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "시설 작물에 대한 병충해를 탐지하는 이동 로봇이 개시된다. 이 이동 로봇은, 시설 작물에 대한 시설 작물 이미 지를 캡처하는 이미지 캡처 장치; 및 상기 시설 작물 이미지를 분석하여 시맨틱 분할 이미지를 출력하는 인공 신 경망 모델을 실행하는 프로세서를 포함하고, 상기 인공 신경망 모델은, 제1 합성곱 신경망을 이용하여, 상기 시 (뒷면에 계속)"}
{"patent_id": "10-2023-0051975", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 시설 작물(facility crops)의 병충해(diseases and pests)를 탐지하는 기술에 관한 것으로서, 보다 구체적으로, 이동형 또는 고정형 엣지 장치(mobile or fixed edge devices) 장치 기반의 인공 신경망을 이용하 여 스마트 팜 시설 작물(Smart farm facility crops)의 병충해를 탐지하는 기술에 관한 것이다."}
{"patent_id": "10-2023-0051975", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 스마트 팜 기술의 보급이 확대되면서 스마트 팜에서 재배되는 시설 작물(facility crops)에 대한 병충해를 자동으로 탐지하는 이동 로봇 기술에 대한 관심이 고조되고 있다. 특히 이동 로봇이 시설 작물에 대한 수확 작 업을 자동으로 수행하는 환경에서는, 병충해 탐지 기능을 갖는 이동 로봇에 대한 개발이 매우 중요하다. 시설 작물에 대한 병충해를 탐지하기 위한 기술 중에 하나로 컴퓨터 비전 및 인공 신경망 기술이 활용될 수 있 다, 하지만, 이러한 기술들은, 빠른 처리속도와 정확한 병충해 탐지 결과를 위해, 충분한 하드웨어 자원을 보유 한 높은 성능의 컴퓨팅 장치를 필요로 하며, 이러한 높은 성능의 컴퓨팅 장치를 이동 로봇에 탑재하는 하는데 한계가 있다."}
{"patent_id": "10-2023-0051975", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상술한 문제점을 해결하기 위한 본 발명은 저사양의 엣지 장치(예, 이동 로봇)에서 빠른 처리 속도와 정확한 탐 지 결과를 제공하도록 설계된 인공 신경망 모듈을 기반으로 시설 작물에 대한 병충해를 탐지할 수 있는 방법 및 장치를 제공하는데 그 목적이 있다."}
{"patent_id": "10-2023-0051975", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 목적을 달성하기 위한 본 발명의 일면에 따른 이동 로봇은, 시설 작물에 대한 시설 작물 이미지를 캡처 하는 이미지 캡처 장치; 및 상기 시설 작물 이미지를 분석하여 시맨틱 분할 이미지를 출력하는 인공 신경망 모 델을 실행하는 프로세서를 포함하고, 상기 인공 신경망 모델은, 제1 합성곱 신경망을 이용하여, 상기 시설 작물 이미지로부터 상기 시설 작물의 잎 모양과 상기 잎 모양의 위치에 대한 공간 특징 데이터를 추출하는 공간 추출 모듈; 제2 합성곱 신경망을 이용하여, 상기 시설 작물 이미지로부터 상기 잎 모양에 대한 병충해 종류를 나타내 는 시맨틱 특징 데이터를 추출하는 시맨틱 추출 모듈; 및 제3 합성곱 신경망을 이용하여, 상기 공간 특징 데이 터와 상기 시맨틱 특징 데이터를 융합하여 획득한 데이터를 기반으로 상기 잎 모양에 대한 상기 시맨틱 분할 이 미지를 출력하는 특징 융합 모듈을 포함하고, 상기 제2 합성곱 신경망은 히든 레이어들(hidden layers)에서 상 기 시맨틱 특징 데이터를 출력하는 조기 종료(early exiting) 구조로 설계된다. 실시 예에서, 상기 히든 레이어들은 사전에 공개된(pre-published) 백본 모델(Backbone Model)로부터 추출한 레 이어들로서, 상기 백본 모델에서 스킵 커넥션(skip connection) 구조로 연결된 레이어들을 제외한 나머지 레이 어들이다. 실시 예에서, 상기 제2 합성곱 신경망은, 동일한 개수의 상기 히든 레이어들을 포함하도록 구성되고, 상기 시설 작물 이미지에 대한 특징 데이터를 순차적으로 출력하는 N개의 히든 블록들; 및 상기 N개의 히든 블록들에 1:1 로 연결되고, 상기 조기 종료(early exiting) 구조에 따라, 상기 N개의 히든 블록들에서 순차적으로 출력되는 상기 특징 데이터에 대한 분류 작업을 순차적으로 수행하여 획득한 상기 시맨틱 특징 데이터를 선택적으로 출력 하는 N개의 브랜치 모듈들(branch modules)을 포함한다. 실시 예에서, 상기 N개의 브랜치 모듈들 중에서 K(N보다 작은 자연수)번째 브랜치 모듈은, K번째 히든 블록으로 부터 출력되는 상기 특징 데이터에 대한 분류 작업을 수행하여 획득한 상기 시맨틱 특징 데이터에 대한 신뢰도 를 계산하고, 상기 신뢰도가 목표 신뢰도 이상인 경우, 상기 시맨틱 특징 데이터를 출력하고, 상기 K번째 브랜치 모듈이 상기 시맨틱 특징 데이터를 출력하면, K번째 이후의 상기 히든 블록들과 브랜치 모듈들은 연산 동작 을 조기에 중지(early stop)한다. 실시 예에서, 상기 제2 합성곱 신경망은 1개의 나머지 블록을 더 포함하고, 상기 히든 레이어들의 전체 개수를 상기 N으로 나눈 몫이 Q이고, 나머지가 R일 때, 각 히든 블록은 Q개의 상기 히든 레이어들을 포함하도록 구성되 고, 상기 1개의 나머지 블록은 R개의 히든 레이어들을 포함한다. 실시 예에서, 상기 이동 로봇은 스마트 팜 내에서 상기 시설 작물의 위치 데이터를 측정하는 작물 측위 장치; 및 사용자 장치에서 상기 시맨틱 분할 이미지와 상기 위치 데이터를 시각적으로 표시하기 위해, 상기 시맨틱 분 할 이미지와 상기 위치 데이터를 무선 통신 방식으로 상기 사용자 장치로 송신하는 통신 장치를 더 포함한다. 실시 예에서, 상기 작물 측위 장치는, 상기 이동 로봇의 현재 위치를 나타내는 GPS 좌표를 획득하는 GPS 수신기; 스마트 팜 지도를 저장하는 메모리; 및 상기 이동 로봇의 GPS 좌표를 상기 스마트 팜 지도에 맵핑하고 상기 스마트 팜 지도에 맵핑된 상기 GPS 좌표에 대응하는 지도 좌표를 기반으로 상기 시설 작물의 위치 데이터를 산출하는 프로세서를 포함한다. 본 발명의 다른 일면에 따른 서버에서 시설 작물에서 발생한 병충해를 탐지하기 위한 인공 지능 모델의 생성 방 법은, 상기 프로세서가, 시설 작물 이미지로부터 상기 시설 작물의 잎 모양에 대한 공간 특징 데이터를 추출하 는 제1 합성곱 신경망을 생성하는 단계; 상기 프로세서가, 상기 시설 작물 이미지로부터 상기 시설 작물의 잎 모양에 대한 병충해의 종류를 나타내는 시맨틱 특징 데이터를 추출하는 제2 합성곱 신경망을 생성하는 단계; 상 기 프로세서가, 상기 공간 특징 데이터와 상기 시맨틱 특징 데이터를 융합하고, 상기 융합된 데이터를 분석하여 상기 잎 모양에 대한 시맨틱 분할 이미지를 출력하는 제3 합성곱 신경망을 생성하는 단계; 및 상기 프로세서가, 상기 제1 내지 제3 합성곱 신경망을 연결하여 상기 인공 지능 모델을 생성하는 단계를 포함하고, 상기 제2 합성 곱 신경망은, 히든 레이어들(hidden layers)에서 상기 시맨틱 특징 데이터를 출력하는 조기 종료(early exiting) 구조를 갖도록 설계된다. 실시 예에서, 상기 제2 합성곱 신경망을 생성하는 단계는, 상기 프로세서에 의해 실행되는 로더(loader)가 상기 저장소에 저장된 백본 모델(Backbone Model)을 메모리에 로딩하는 단계; 상기 프로세서에 의해 실행되는 마크 모듈(mark module)이, 상기 메모리에 로딩된 백본 모델로부터 분리 가능한 상기 히든 레이어들을 추출하는 단계; 및 상기 프로세서에 의해 실행되는 재구성 모듈(reconstruction module)이, 상기 추출된 히든 레이어들을 재구성하고, 상기 재구성된 히든 레이어들을 포함하는 상기 제2 합성곱 신경망을 생성하는 단계를 포함한다. 실시 예에서, 상기 백본 모델로부터 분리 가능한 상기 히든 레이어들을 추출하는 단계는, 상기 백본 모델에서 스킵 커넥션(skip connection) 구조로 연결된 레이어들을 제외한 나머지 레이어들을 상기 히든 레이어들로서 추 출한다. 실시 예에서, 상기 백본 모델로부터 분리 가능한 상기 히든 레이어들을 추출하는 단계는, 상기 백본 모델에서 메인 경로에 배치된 레이어들과 상기 메인 경로를 우회하는 서브 경로에 배치된 레이어들을 제외한 나머지 레이 어들을 상기 히든 레이어들로서 추출하는 단계이다. 실시 예에서, 상기 재구성된 히든 레이어들을 포함하는 상기 제2 합성곱 신경망을 생성하는 단계는, 상기 추출 된 히든 레이어들의 전체 개수를 기설정된 N으로 나눈 몫이 Q이고, 나머지가 R일 때, 상기 추출된 히든 레이어 들을 Q개씩 묶어서 N개의 히든 블록들로 재구성하고, 상기 추출된 히든 레이어들을 Q개씩 묶은 후 남은 R개의 히든 레이어들을 1개의 나머지 블록으로 재구성하는 단계; 상기 N개의 히든 블록들과 상기 N개의 브랜치 모듈을 1:1로 연결하는 단계; 및 상기 1:1로 연결된 상기 N개의 히든 블록들과 상기 N개의 브랜치 모듈을 포함하는 상 기 제2 합성곱 신경망을 생성하는 단계 를 포함한다. 실시 예에서, 상기 N개의 브랜치 모듈들 중에서 K(N보다 작은 자연수)번째 브랜치 모듈은, K번째 히든 블록에서 출력한 특징 데이터에 대한 분류 작업을 수행하여 획득한 상기 시맨틱 특징 데이터의 신뢰도를 계산하고, 상기 신뢰도가 목표 신뢰도 이상인 경우, 상기 시맨틱 특징 데이터를 출력하고, 상기 K째 브랜치 모듈이 상기 시맨틱 특징 데이터를 출력하면, 상기 K번째 이후의 히든 블록들과 브랜치 모듈들은 연산 동작을 조기에 중지(early stop)한다. 실시 예에서, 상기 인공 지능 모델을 생성하는 단계 이후, 상기 프로세서가 병충해와 관련된 샘플 데이터를 이 용하여 상기 생성된 인공 지능 모델을 학습시키는 단계; 및 통신 장치가, 상기 학습된 인공 지능 모델을 이동 로봇으로 송신하는 단계를 더 포함한다."}
{"patent_id": "10-2023-0051975", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 조기 종료 방식(early exiting)으로 설계된 인공 지능 모델을 이용하여 시설 작물의 병충해 를 탐지함으로써, 추론 작업의 정확도를 유지하면서 불필요한 추론 연산을 생략할 수 있고, 궁극적으로 충분한 하드웨어 자원을 보유하지 못한 이동 로봇에서 병충해 탐지를 위한 추론 작업의 가속화를 달성할 수 있다."}
{"patent_id": "10-2023-0051975", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 문서의 다양한 실시 예들이 첨부된 도면을 참조하여 기재된다. 실시 예 및 이에 사용된 용어들은 본 문서에 기재된 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 해당 실시 예의 다양한 변경, 균등물, 및/또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유 사한 참조 부호가 사용될 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함 할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및/또는 B 중 적어도 하나\" 또는 \"A/B\" 등의 표현은 함께 나열된 항 목들의 모든 가능한 조합을 포함할 수 있다. \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째, \"등의 표현들은 해당 구성요소 들을, 순서 또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요 소들을 한정하지 않는다. 어떤(예: 제1) 구성요소가 다른(예: 제2) 구성요소에 \"(기능적으로 또는 통신적으로) 연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다. 본 문서에서, \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, 하드웨어적 또는 소프 트웨어적으로 \"~에 적합한,\" \"~하는 능력을 가지는,\" \"~하도록 변경된,\" \"~하도록 만들어진,\" \"~를 할 수 있 는,\" 또는 \"~하도록 설계된\"과 상호 호환적으로(interchangeably) 사용될 수 있다. 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로 세서(예: 임베디드 프로세서), 또는 메모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써,해당 동작들을 수행할 수 있는 범용 프로세서(예: CPU 또는 application processor)를 의미할 수 있다. 도 1은 본 발명의 실시 예에 따른 시설 작물의 병충해를 탐지하기 위한 전체 시스템을 나타내는 블록도이고, 도 2는 본 발명의 실시 예에 따른 시설 작물의 병충해를 탐지하기 위한 인공 지능 모델을 학습하기 위한 샘플 데이 터의 예를 설명하기 위한 도면이다. 그리고 도 3은 본 발명의 실시 예에 따른 인공 지능 모델에서 추론하여 생 성한 손상된 시설 작물의 잎에 대한 다양한 시맨틱 분할 이미지의 예들을 보여주는 도면이다. 도 1을 참조하면, 본 발명의 실시 예에 따른 시스템은, 시설 작물들의 병충해를 탐지하기 위해, 서버, 엣 지 장치 및 사용자 장치를 포함할 수 있다. 서버는 샘플 데이터 셋을 이용하여 스마트 팜 시설들(Smart farm facilities)에서 재배중인 시설 작물들 (예, 토마토, 파프리카, 딸기 등)의 병충해(Pests and Diseases)를 탐지하기 위한 인공 지능 모델을 학습시 킨 후, 그 학습된 인공 지능 모델을 엣지 장치에 제공한다. 상기 샘플 데이터셋(sample datasets)은 상기 인공 지능 모델을 학습시키기 위한 '훈련 데이터' 또는 '학습 데이터'를 의미하며, 병충해의 종류(이름)를 설명하는 질병 데이터, 상기 병충해(Pests and Diseases)에 의해 손상된 시설 작물의 잎 이미지 데이터(leaf image data) 및 상기 건강한 작물의 잎 이미지 데이터를 포함한다. 상기 샘플 데이터셋의 예가 도 2에 도시된다. 도 2에 도시된 샘플 데이터셋은 8개의 클래스(Class0~ Class7)로 분류된 이미지 데이터와 질병 데이터를 포함한다. 도 2에 도시된 샘플 데이터셋의 예에서, 병충해 및 시설 작물 과 무관한 배경 이미지가 클래스 0(Class 0)로 분류되고, 아메리카 입 굴파리로 정의되는 질병 데이터와 이 에 의해 손상된 잎 이미지 데이터가 클래스 3(Class 3)으로 분류되고, 건강한 작물의 잎 이미지 데이터가 클래 스 7(Class 7)로 분류된다. 상기 서버는 상기 인공 지능 모델을 학습시키는 서버급 컴퓨팅 장치일 수 있으며, 이를 위해, 서버 는 도 1에서는 도시하지 않았으나, 상기 샘플 데이터셋을 저장하는 저장 장치와 상기 저장 장치로부터 입 력된 상기 샘플 데이터셋을 입력 데이터로 이용하여 인공 지능 모델을 기계 학습 방식 및/또는 딥러닝 학습 방식으로 학습시키는 프로세서를 포함할 수 있다. 여기서, 프로세서는, 적어도 하나의 CPU, 적어도 하나의 GPU, 적어도 하나의 MCU, 이들 중 적어도 하나를 포함하는 시스템 온 칩, 반도체 칩 등으로 구현될 수 있다. 추가로, 상기 서버는 도 1에서는 도시하지 않았으나, 상기 학습된 인공 지능 모델을 상기 엣지 장치 , 보다 구체적으로, 엣지 장치 내의 추론 장치에 장착(로딩)하기 위해, 상기 엣지 장치와 의 유선 및/또는 무선 통신을 지원하는 통신 장치를 더 포함할 수 있다. 여기서, 상기 무선 통신은, 예를 들면, LTE, LTE-A(LTE Advance), CDMA(code division multiple access), WCDMA(wideband CDMA), UMTS(universal mobile telecommunications system), WiBro(Wireless Broadband), WiFi(wireless fidelity), 블루투스, 블루 투스 저전력(BLE), 지그비(Zigbee), NFC(near field communication) 중 적어도 하나를 포함할 수 있다. 상기 유선 통신은, 예를 들면, USB(universal serial bus), HDMI(high definition multimedia interface), RS- 232(recommended standard232), 전력선 통신, 또는 POTS(plain old telephone service) 등 중 적어도 하나를 포함할 수 있다. 서버의 통신 장치는 이러한 유 및/또는 무선 통신을 지원하기 다양한 하드웨어 부품들, 예를 들어, 안테나, 증폭기, 변조기, 복조기, 네트워크 인터페이스 카드(NIC) 등을 포함할 수 있다. 상기 엣지 장치는 상기 서버로부터 다운로딩된 인공 지능 모델을 이용하여 스마트 팜 내에서 재배되 고 있는 시설 작물들의 병충해를 분석하여, 시설 작물들에 대한 시맨틱 분할 이미지, 상기 시맨틱 분할 이미지 에 대한 클래스 라벨 및 스마트 팜 내에서 병충해가 발견된 시설 작물이 위치 데이터를 생성하고, 이를 사 용자 장치로 제공한다. 이렇게 함으로써, 스마트 팜의 관리자 또는 사용자는 사용자 장치를 통해 시 설 작물들에 대한 병충해를 용이하게 모니터링하고 관리할 수 있다. 이하, 추론 결과 데이터는 시맨틱 분할 이미지와 클래스 라벨을 포함하는 용어로 사용한다. 또한 상기 엣지 장치는 상기 추론 결과 데이터를 상기 서버로도 제공하며, 상기 서버는 상 기 추론 결과 데이터를 상기 인공 지능 모델의 재학습을 수행하는데 활용한다. 이러한 재학습을 통해, 상기 인공 지능 모델은 보다 개선된 추론 성능을 갖도록 업데이트 될 수 있다. 이를 위해, 상기 엣지 장치는 통신 장치, 추론 장치, 이미지 캡처 장치, 작물 측위 장치 및 데이터 수집 장치를 포함하며, 이들(210~250)을 전반적인 동작 및 실행을 제어 및 관리하는 중앙 제어 장치를 더 포함할 수 있다.통신 장치 먼저, 통신 장치는, 상기 중앙 제어 장치의 제어에 따라, 유선 또는 무선 통신 방식으로 상기 서버 로부터 상기 인공 지능 모델을 수신하고, 이를 추론 장치에 로딩한다. 추론 장치 상기 추론 장치는, 상기 중앙 제어 장치의 제어에 따라, 상기 통신 장치를 통해 상기 서버(10 0)로부터 다운로딩한 상기 인공 지능 모델을 이용하여 상기 이미지 캡처 장치에 의해 캡처된 시설 작 물 이미지 데이터(facility crop image data, 이하 '시설 작물 이미지'라 함), 보다 구체적으로 시설 작물에 대 한 잎 이미지 데이터(leaf image data, 이하, '잎 이미지'라 함)를 분석하여, 상기 시설 작물(facility crop) 의 잎에서 발생한 병충해(diseases and pests)를 분석 및 추론한다. 상기 추론 장치는 상기 시설 작물의 잎에서 발생한 병충해를 분석 및 추론하여 시맨틱 분할 이미지와 이에 대한 클래스 라벨을 포함하는 상기 추론 결과 데이터를 생성하는데, 여기서, 클래스 라벨은 상기 시맨틱 분 할 이미지에 포함된 잎 모양으로부터 추론된 병충해 종류를 나타내는 예측 라벨(predicted label), 정답을 나타 내는 그라운드 라벨(ground label), 추론에 대한 신뢰도(confidence) 및 픽셀 정확도(pixel accuracy)를 포함 한다. 상기 시맨틱 분할 이미지는 시맨틱 분할 기법(semantic segmentation techniques)으로 알려진 이미지 처리를 통 해 획득되며, 본 발명의 상기 인공 지능 모델은 상기 시맨틱 분할 기법을 수행하도록 학습된 심층 신경망, 더 바람직하게는 합성곱 신경망으로 구성될 수 있다. 이러한 시맨틱 분할 이미지의 다양한 예들이 도 3에 도시 된다. 도 3의 예에서 볼 수 있듯이, 시맨틱 분할 이미지들(31, 32, 33 및 34)은 상기 이미지 캡처 장치에 의해 캡처된 시설 작물 이미지에서 목표 객체인 잎을 분할하여(segment) 그 분할된 잎을 동일한 픽셀값들로 표현하기 때문에, 상기 시설 작물의 잎 모양의 현재 상태, 예를 들면, 상기 병충해에 의해 손상된 부위를 쉽게 인식할 수 있다. 이러한 시그맨틱 분할 이미지는 상기 사용자 장치의 표시 장치에서 제공하는 GUI 화면을 통해 사용자에게 실시간으로 제공되고, 이를 통해, 상기 사용자는 상기 시설 작물의 잎 모양의 현재 상태를 시각적으로 및 직관 적으로 빠르게 인식할 수 있다. 상기 추론 장치는, 예를 들면, 중앙 제어 장치에 제어되거나 실행되는 하드웨어 모듈 또는 소프트웨 어 모듈로 설계될 수 있다. 상기 하드웨어 모듈은, 예를 들면, 적어도 하나의 프로세서로 구성되거나 적어도 하나의 프로세서를 포함하는 반도체 칩으로 설계될 다운 로딩한 인공 지능 모델로 구성되거나, 상기 인공 지능 모델을 포함하는 수 있다. 상 기 소프트웨어 모듈은, 예를 들면, 상기 서버로부터 소프트웨어 프로그램으로 설계될 수 있다. 이미지 캡처 장치 상기 이미지 캡처 장치는, 상기 중앙 제어 장치의 제어에 따라, 상기 시설 작물을 촬영하여 캡처된 상기 시설 작물 이미지, 특히 상기 시설 작물에 대한 잎 이미지를 상기 추론 장치로 입력하는 장치로서, 예를 들면, 수직방향으로 이동하고 동시에 수평방향으로 회전할 수 있도록 설계된 카메라 장치일 수 있다. 작물 측위 장치 상기 작물 측위 장치는, 상기 중앙 제어 장치의 제어 및/또는 실행에 따라, 상기 시설 작물 이미지에 포함된 상기 시설 작물의 위치 데이터를 측정하는 장치이다. 이를 위해 상기 작물 측위 장치는 사전에 제작된 상기 스마트 팜의 지도 데이터(이하, '스마트 팜 지도'라 함) 상에서 상기 추론 장치에 의해 병충해를 갖는 것으로 추론된 상기 시설 작물의 위치 데이터를 산 출한다. 보다 구체적으로, 상기 작물 측위 장치는 상기 엣지 장치의 현재 위치를 나타내는 GPS 좌표를 상기 지도에 맵핑한다. 이때, 상기 시설 작물들은 상기 스마트 팜 내에서 복수의 섹션들로 구획되고, 상기 스마트 팜 지도는 각 섹션의 위치 데이터를 포함한다. 후술하겠지만 상기 엣지 장치는 이동 로봇으로 구현될 수 있으며, 이 경우, 상기 작물 측위 장치는 상기 이동 로봇이 현재 위치하는 섹션의 위치 데이터를 상기 시설 작물의 위치 데이터로 산출한다. 예를 들면, 상기 이동 로봇이, 특정 섹션에 진입한 후, 그 특정 섹션 내에서 특정 시설 작물에 대한 시설 작물 이미지를 상기 인공 지능 모델을 이용하여 분석한 결과, 그 특정 시설 작물에서 병충해를 발견한 경우 그 특정 섹션의 위치 데이터를 상기 특정 시설 작물의 위치 데이터로 산출한다. 이때, 상기 특정 시설 작물의 위치 데이터는 상기 스마트팜 지도 상에서 포인트 형태로 표현될 수 있다. 한편, 상기 작물 측위 장치는 상기 이동 로봇의 GPS 좌표를 상기 지도에 맵핑하기 위해, 상기 GPS 좌표를 로봇 좌표계로 변환하는 처리를 더 수행할 수 있다. 이처럼 상기 작물 측위 장치는, 시설 작물의 위치 데이터를 측정하기 위해 도면에 도시하지는 않았으나, 상기 엣지 장치의 현재 위치를 나타내는 GPS 좌표를 획득하기 위한 GPS 수신기, 스마트 팜 지도를 저장하 는 메모리 및 상기 엣지 장치의 GPS 좌표를 상기 스마트 팜 지도에 맵핑하고 상기 스마트 팜 지도에서 상 기 맵핑된 GPS 좌표에 대응하는 지도 좌표를 기반으로 시설 작물의 위치 데이터를 산출하기 위한 적어도 하 나의 프로세서를 포함하도록 설계될 수 있다. 데이터 수집 장치 상기 데이터 수집 장치는 상기 추론 장치로부터 입력된 상기 추론 결과 데이터와 작물 측위 장치 로부터 입력된 병충해를 갖는 시설 작물의 위치 데이터를 수집하는 장치로서, 예를 들면, 메모리 장치 로 설계될 수 있다. 이처럼 상기 데이터 수집 장치에 의해 수집된 상기 추론 결과 데이터와 상기 시설 작물의 위치 데이터 는 상기 통신 장치를 통해 상기 서버와 상기 사용자 장치로 제공된다. 보다 구체적으로, 상 기 추론 결과 데이터는 상기 인공 지능 모델의 재학습을 위해 상기 서버로 송신되고, 상기 추론 결과 데이터와 상기 시설 작물의 위치 데이터는 사용자의 모니터링을 위해 상기 사용자 장치로 송 신된다. 중앙 제어 장치 상기 중앙 제어 장치는 주변 구성들(210~250)의 동작 및/또는 실행을 제어 및 관리하는 장치로서, 적어도 하나의 프로세서로 구성되거나, 상기 적어도 하나의 프로세서 및 상기 프로세서와 연동하는 적어도 하나의 메모 리를 포함하는 반도체 칩으로 설계될 수 있다. 한편, 본 발명의 실시 예에 따른 엣지 장치는 고정형 또는 이동형 컴퓨팅 장치로 설계될 수 있으며, 이동 형 컴퓨팅 장치는, 예를 들면 이동 로봇일 수 있다. 엣지 장치가 이동 로봇으로 설계된 경우, 도 1에는 도시하지 않았으나 상기 이동 로봇은 상기 이동 로봇의 전후좌우 이동을 위한 구동 장치 및 전방 이동 시에 전방 장애물을 감지하기 위한 장애물 감지 장치를 더 포함 하도록 설계될 수 있다. 여기서, 구동 장치는, 바퀴, 바퀴로 회전력을 제공하는 구동 모터 및 상기 구동 모터를 제어하는 모터 컨트롤러를 포함하며, 상기 장애물 감지 장치는 이동 로봇의 전방을 촬영하는 전방 카메라(도 5 의 54) 및 전방 카메라(도 5의 54)에 의해 촬영된 전방 이미지로부터 장애물 객체를 검출하는 객체 검출 모듈을 포함하도록 설계될 수 있다. 여기서, 객체 검출 모듈은 하드웨어 모듈, 소프트웨어 모듈 및 이들의 조합으로 설 계될 수 있으며, 소프트웨어 모듈인 경우, 공지된 다양한 객체 검출 알고리즘들로 구성되거나 객체 검출 알고리 즘들을 포함하는 알고리즘으로 설계될 수 있으며, 하드웨어 모듈인 경우, 이미지를 처리하는 프로세서로 설계될 수 있다. 이하, 엣지 장치는 이동 로봇이란 용어와 혼용하여 사용된다. 사용자 장치 상기 사용자 장치는 이동 로봇으로부터 수신된 상기 시설 작물의 병충해와 관련된 상기 추론 결과 데 이터와 상기 시설 작물의 위치 데이터를 사용자에게 제공하는 장치이다. 상기 사용자는 상기 사용자 장치 를 통해 스마트 팜에서 재배 중인 시설 작물들을 용이하게 모니터링하고 관리할 수 있다. 보다 구체적으로, 상기 사용자는 상기 사용자 장치에 포함된 표시 장치에서 표시하는 그래픽 사용자 인터 페이스(Graphic User Interface: GUI) 화면을 통해 상기 시설 작물의 병충해와 관련된 상기 추론 결과 데이터와 상기 시설 작물의 위치 데이터를 시각적으로 및 직관적으로 인식할 수 있다. 도 4는 본 발명의 실시 예에 따른 상기 사용자 장치에서 표시하는 UI 화면을 나타내는 도면이다. 도 4를 참조하면, 본 발명의 실시 예에 따른 GUI 화면은, 복수의 표시 영역들로 구획되며, 예를 들면, 제1 내지 제4 표시 영역(41, 42, 43 및 44)을 포함한다. 상기 제1 표시 영역은, 예를 들면, 상기 GUI 화면에서 좌측 상단에 위치하며, 상기 제1 표시 영역 에는 상기 이동 로봇이 정상 또는 비정상인 지를 나타내는 상태 정보(41A), 상기 이동 로봇의 이동 또는 정지 중인지를 나타내는 상태 정보(41B), 해충(PEST)을 갖는 것으로 추론된 시설 작물의 위치 데이터 및/또는 이동 로봇의 위치 데이터, 해충(PEST)을 갖는 것으로 추론된 시설 작물의 개수가 텍스트 및 숫자 형태로 표시된 다. 도 4에서는 해충(PEST)을 갖는 것으로 추론된 시설 작물의 개수가 8개인 경우를 도시한 것이다. 상기 제2 표시 영역은, 예를 들면, 상기 UI 화면에서 좌측 하단에 위치하며, 상기 제2 표시 영역에 는 사전에 제작된 스마트 팜 지도가 표시되며, 상기 지도 상에는 실제 이동 로봇을 나타내는 아이콘(42A) 이 표시되면, 상기 아이콘(42A)은 상기 실제 이동 로봇의 이동에 따라 상기 지도 상에서 이동한다. 또한 상기 지도 상에는 해충을 갖는 것으로 추론된 시설 작물들의 위치 데이터들이 포인트 형태로 표시되며, 도 4에 서는 해충을 갖는 것으로 추론된 8개의 시설 작물들의 위치 데이터들에 각각 대응하는 8개의 포인트들(42B)이 도시된다. 상기 제3 표시 영역은, 예를 들면, 상기 UI 화면에서 우측 상단에 위치하며, 상기 제3 표시 영역에 는 상기 이동 로봇에 탑재된 장애물 감지 장치(예, 전방 카메라, 도시하지 않음)에 의해 획득한 전방 이미지가 실시간으로 표시된다. 상기 제4 표시 영역은, 예를 들면, 상기 GUI 화면에서 우측 하단에 위치하며, 상기 제4 표시 영역 에는 상기 이동 로봇의 추론 장치에 의해 생성된 병충해를 갖는 대상 시설 작물에 대한 상기 시맨틱 분할 이미지가 표시되며, 상기 시맨틱 분할 이미지 상에는 추론 신뢰도 값(confidence value), 예측 라벨 (Predicted Label)과 그라운드 라벨(Ground Label)을 포함하는 클래스 라벨(class label), 추론 결과에 대한 정확도 값(pixel accuracy value) 등과 같은 각종 파라미터가 텍스트 및/또는 숫자 형태로 표시된다. 상기 추론 결과 데이터와 상기 시설 작물의 위치 데이터를 UI 화면을 통해 제공하는 상기 사용자 장치는, 예를 들면, 스마트폰, 태블릿 PC, 데스크탑 PC, 랩탑 PC, 넷북 컴퓨터, 워크스테이션, 서버, 웨어러블 장치, 미 디어 박스(예: 삼성 HomeSyncTM, 애플TVTM, 또는 구글 TVTM) 중 적어도 하나로 구현될 수 있다. 도 5는 본 발명의 다양한 실시 예에 따른 이동 로봇의 외관 형상을 간략하게 도시한 측면도이다. 도 5를 참조하면, 본 발명의 실시 예에 따른 이동 로봇은 도 1에 도시된 엣지 장치의 역할을 수행하며, 예 를 들면, 제1 몸체, 제2 몸체 및 제3 몸체를 포함한다. 상기 제1 몸체의 양 측면에는 바퀴들이 회전할 수 있도록 장착되며, 이를 위해, 도시하지는 않았으나, 상기 제1 몸체의 내부에는 상기 바퀴들의 회전을 제어하는 구동 모터 및 상기 구동 모터를 제어하는 모 터 컨트롤러가 제공될 수 있다. 상기 제2 몸체는, 예를 들면, 상기 제1 몸체의 상부면에 장착되며, 상기 제2 몸체의 전면에는 이동 로봇의 전방에 위치하는 장애물들을 탐지하기 위한 전방 카메라가 장착된다. 상기 제2 몸체의 내부에는, 예를 들면, 상기 전방 카메라에 의해 캡쳐된 전방 이미지로부터 장애물 객체를 검출하기 위한 이 미지 처리를 수행하는 객체 검출 모듈(도시하지 않음)이 제공된다. 또한 상기 제2 몸체의 내부에는, 예를 들면, 도 1에 도시된 장치들(210~260)들 제공된다. 상기 제3 몸체는, 예를 들면, 상기 제2 몸체의 상부면에 장착되며, 상기 제2 몸체의 상부면에 대해 수직한 방향으로 길쭉하게 형성될 수 있다. 상기 제3 몸체의 내부에는 상기 제3 몸체의 내부로부터 인 출되고, 상기 제3 몸체의 내부로 인입되는 지지대가 구비된다. 이에, 상기 지지대는 상기 제2 몸체 의 상부면에 대해 수직한 방향으로 이동한다. 상기 지지대의 한쪽 단부에는 시계 방향 또는 반시계 방향으로 회전 가능하도록 이미지 캡처 장치가 장착된다. 또한 상기 이미지 캡처 장치는 상기 지지대가 수직한 방향으로 이동함에 따라 수직한 방향으로 이동할 수 있다. 이에 따라, 상기 이미지 캡처 장치는 수직한 방향으로 이동하는 동시에 시계 또는 반시계 방향으로 회전하면서 상기 시설 작물을 촬영할 수 있다. 이하, 시설 작물에 대한 병충해를 추론하기 위해, 추론 장치에 로딩되는 인공 지능 모델에 대해 상세 히 설명하기로 한다.본 발명의 실시 예에 따른 상기 인공 지능 모델은 상기 엣지 장치로 역할을 하는 이동 로봇에 로딩되 고 상기 시설 작물 이미지로부터 시설 작물의 병충해(Pest and Disease)를 시각적으로 나타내는 시맨틱 분할 이 미지를 추론하는 측면에서, 상기 인공 지능 모델을 \"ESPD(Edge based Segmentation of Pest and Disease) 모델\"이라 지칭한다. 다만, 본 명세서의 청구범위에서는 ESPD 모델을 '인공 지능 모델'로 표기한다. 도 6은 본 발명의 실시 예에 따른 ESPD 모델의 구성을 나타내는 블록도이다. 도 6을 참조하면, 상기 ESPD 모델은 공간 추출 모듈, 시맨틱 추출 모듈 및 특징 융합 모듈 을 포함한다. 각 모듈은 심층 신경망(Deep neural networks), 바람직하게는 합성곱 신경망(Convolutional neural networks)으로 구성될 수 있다. 상기 모듈들은 서로 다른 구조로 설계되고, 학습된 합성곱 신경망으로 구성될 수 있다. 서로 다른 합성곱 신경망으로 설계될 수 있음을 명확히 하기 위해, 본 명세서에서는, 공간 추출 모듈은 제 1 합성곱 신경망으로 설계되고, 시맨틱 추출 모듈은 제2 합성곱 신경망으로 설계되고, 특징 융합 모듈 은 제3 합성곱 신경망으로 설계되는 것으로 가정한다. 상기 공간 추출 모듈은, 상기 제1 합성곱 신경망을 이용하여, 상기 시설 작물 이미지로부터 상기 시설 작 물의 잎 모양과 상기 잎 모양의 위치에 대한 공간 특징 데이터를 추출한다. 상기 시맨틱 추출 모듈은, 상기 제2 합성곱 신경망을 이용하여, 상기 시설 작물 이미지로부터 상기 잎 모 양에 대한 병충해 종류를 나타내는 시맨틱 특징 데이터를 추출한다. 추가로 시맨틱 추출 모듈은 상기 시맨 틱 특징 데이터에 대한 클래스 라벨을 더 추출한다. 상기 특징 융합 모듈은, 상기 제3 합성곱 신경망을 이용하여, 상기 공간 특징 데이터와 상기 시맨틱 특징 데이터를 융합하여 획득한 데이터를 기반으로 상기 잎 모양에 대한 상기 시맨틱 분할 이미지를 출력한다. 공간 추출 모듈은 시설 작물 이미지의 공간 정보를 분석한다. 여기서, 공간 정보 분석은 시설 작물 이미지 에 포함된 잎 모양과 시설 작물 이미지 내에서 상기 잎 모양의 위치를 분석하는 작업을 의미한다. 시맨틱 추출 모듈은 시설 작물 이미지의 객체 정보를 분석한다. 여기서, 객체 정보 분석은 시설 작물 이미 지에 포함된 잎 모양에 대한 병충해 종류(이름)를 분류하는(Classifying) 작업을 의미한다. 공간 정보 분석을 위해, 공간 추출 모듈의 제1 합성곱 신경망은 많은 수의 채널들과 적은 개수로 적층된 레이어들(layers)로 설계될 수 있다. 여기서, 채널은 데이터의 차원을 의미할 수 있다. 이처럼 제1 합성곱 신경 망은 적은 수의 레이어들로 설계되지만, 많은 수의 채널을 사용하기 때문에, 원본 이미지(시설 작물 이미지)의 사이즈가 작아도 정확한 공간 특징 데이터를 추출할 수 있다. 객체 정보 분석을 위해, 상기 시맨틱 추출 모듈의 제2 합성곱 신경망은 제1 합성곱 신경망에 비해 상대적 으로 적은 수의 채널들과 많은 개수로 적층된 레이어들로 설계될 수 있다. 특히, 정확한 객체 정보 분석을 위해, 제2 합성곱 신경망은 사전에 검증되고 공개된 백본 모델들(backbone models)을 지원하도록 설계될 수 있 다. 예를 들면, 제2 합성곱 신경망은 백본 모델들을 재구성(reconstruction)한 것일 수 있다. 백본 모델의 재구 성은 백본 모델들의 확장 또는 축소와 같은 변형을 의미한다. 백본 모델은, 예를 들면, Resnet(Residual neural network), EfficientNet, MobileNet, MobileNet-v1, MobileNet-v2, MobileNet-v3 등을 포함할 수 있다. 이처럼 본 발명에서는 사전에 검증된 백본 모델을 기반으로 설계된 제2 합성곱 신경망을 이용하여 시설 작물 이 미지를 분석함으로써, 시설 작물 이미지로부터 정확한 객체 정보, 즉, 정확한 시맨틱 특징 데이터를 추출할 수 있다. 또한 제1 합성곱 신경망에 비해 상대적으로 많은 개수의 레이어들로 설계됨에 따라 늘어나는 추론 시간을 획기 적으로 줄이기 위해, 제2 합성곱 신경망은 조기 종료(early exiting) 구조로 설계될 수 있다. 조기 종료(early exiting)는 심층 신경망 분야에서 사용되는 기술적 용어로서, 신경망의 히든 레이어들(hidden layers)에 출력값을 출력할 수 있는 복수의 출구들(exits)을 연결하고, 목표 신뢰도를 달성한 출구를 통해 상기 출력값을 출력하고, 그 이후의 출구에 연결된 히든 레이어에서 수행되는 계산 동작을 생략하는 기법이다. 이렇 게 함으로써, 추론 시간을 크게 줄일 수 있다. 이러한 조기 종료(early exiting)에 대한 상세 설명은 공지된 문헌(예, S. Teerapittayanon, B. McDanel, and H. T. Kung, \"BranchyNet: Fast inference via early exiting from deep neural networks,\" in Proc. International Conference on Pattern Recognition (ICPR) 2016, Dec. 2016)으로 대신하고, 그에 대한 상세 설명은 생략하기로 한다. 이처럼 본 발명에서는 상기 시맨틱 추출 모듈의 제2 합성곱 신경망을 사전에 검증된 백본 모델을 재구성하 는 방식으로 설계하고, 또한 조기 종료(early exiting) 구조로 갖도록 설계함으로써, 추론 결과의 정확도를 높 이고 동시에 추론 시간을 획지적으로 줄일 수 있고, 추록 작업의 가속화를 달성할 수 있다. 특징 융합 모듈은 제3 합성곱 신경망을 이용하여 상기 공간 추출 모듈로부터의 공간 특징 데이터와 상기 시맨틱 추출 모듈로부터의 시맨틱 특징 데이터를 융합하고, 그 융합된 데이터를 분석하여 시설물 작 물 이미지에서 잎 모양을 분할하고, 분할된 잎 모양을 동일한 픽셀값을 갖는 픽셀들로 표현한 상기 시맨틱 분할 이미지를 출력한다. 융합은 연결 함수(concatenation function)를 이용하여 상기 공간 특징 데이터와 시맨틱 특징 데이터의 연결 (concatenation)을 의미한다. 연결(concatenation)은 공간 특징 데이터와 시맨틱 특징 데이터의 조합을 위해 공 간 특징 데이터의 데이터 차원과 시맨틱 특징 데이터의 데이터 차원을 동일한 데이터 차원으로 변환함을 의미할 수도 있다. 상기 시맨틱 분할 이미지는 입력 이미지인 시설 작물 이미지와 동일한 사이즈를 가지며, 각 픽셀이 어떤 클래스 에 속하는 지를 동일한 픽셀값으로 나타낸 분할 마스크(segmentation mask)를 포함한다. 또한, 특징 융합 모듈은 상기 시맨틱 분할 이미지에 대한 클래스 라벨을 더 출력한다. 클래스 라벨은 추론 을 통해 예측된 병충해의 이름(종류), 정답(ground label), 추론 신뢰도 및 추론 정확도에 대한 데이터를 포함 한다. 이러한 클래스 정보는 상기 시맨틱 분할 이미지 상에 시각적으로 표시된다. 상기 공간 추출 모듈에 장착되는 제1 합성곱 신경망, 상기 시맨틱 추출 모듈에 장착되는 제2 합성곱 신경망 및 상기 특징 융합 모듈에 장착되는 제3 합성곱 신경망은 설계자에 의해 다양하게 설계될 수 있다. 예를 들면, 제1 내지 제3 합성곱 신경망은 다수의 블록들이 적층된 구조를 가지며, 각 블록은 컨볼루션 레이어 (Convolution layers), 배치 정규화 레이어(batch normalization layers), ReLU(Rectified Linear Units), 풀 링 레이어(pooling layers) 및 풀리 커넥티드 레이어(fully connected layer) 중에서 적어도 하나를 포함하도 록 구성될 수 있다. 특히, 본 발명은, 추론 시간을 크게 줄이기 위해, 상기 시맨틱 추출 모듈에 장착되는 제2 합성곱 신경망을 조기 종료 구조를 갖도록 설계됨에 특징이 있다. 이하, 조기 종료 구조로 설계된 제2 합성곱 신경망의 구조에 대해 상세히 설명하기로 한다. 도 7은 도 6에 도시된 시맨틱 추출 모듈에 장착되는 제2 합성곱 신경망의 구조를 설명하기 위한 블록도이고, 도 8은 본 발명의 실시 예에 따른 심층 신경망의 스킵 커넥션 구조를 설명하기 위한 도면이다. 먼저, 도 7을 참조하면, 제2 합성곱 신경망은 N개의 히든(hidden) 블록들(62_1 ~ 62_N), 1개의 나머지블록 (remaining blocks), 1개의 출구 모듈 및 N개의 히든 블록들(62_1 ~ 62_N)에 1:1로 연결된 N개의 브랜치 모듈들(65_1 ~ 65_N)을 포함한다. 각 히든 블록은 사전에 공개된(pre-published)되고 사전에 검증된 백본 모델(Backbone Model)로부터 추출한 히 든 레이어들을 포함하도록 구성된다. 여기서, 상기 히든 레이어들은, 상기 백본 모델에서 스킵 커넥션(skip connection) 구조(방식)로 연결된 레이어들을 제외한 나머지 레이어들이다. 스킵 커넥션은 레지듀얼 커넥션 (Residual connection)이라 지칭될 수도 있다. 이러한 스킵 커넥션 구조는, 심층 신경망 분야에서 널리 사용되는 기술적 용어로, 그 명칭으로부터 알 수 있듯 이(as the name suggests), 신경망 내에서 한 레이어의 출력이 일부 레이어들(some layers)을 건너뛰고(skip), 다음 레이어에 입력으로서 공급(feed)되는 방식을 의미한다. 예를 들면, 도 8에 도시된 바와 같이, 메인 경로(MP: Main Path)와 상기 메인 경로(MP)를 우회하는 서브 경로 (SP: Sub Path)를 포함하는 신경망 구조를 갖는 백본 모델을 가정할 때, 메인 경로(MP) 상에 배치된 레이어 들(82, 83, 84)과 서브 경로(SP) 상에 배치된 레이어가 스킵 커넥션 구조로 연결된 레이어들로 정의될 수 있다. 또한 스킵 커넥션 구조로 연결된 레이어들은 2개 이상의 다음 레이어들(83, 85)로 출력을 공급하는 레이어 또는 2개 이상의 이전 레이어들(83, 85)로부터 출력은 공급받는 레이어로 정의될 수 있다. 이러한 정의에 따라, 스킵 커넥션 구조(방식)로 연결된 레이어들을 제외한 나머지 레이어들은 참조 번호 81 및 86에 의해 지시되는 레이어들이다. 이러한 레이어들(81 및 86)은 오직 이전 레이어로부터 출력을 받거나 오직 다음 레이어로 출력을 제공하는 측면에서, 추론 작업을 독립적으로 처리하는 레이어들로 정의될 수 있고, 다른 측면에서 백본 모델로부터 분리 가능한 레이어들로 정의될 수 있다. 다시 도 7을 참조하면, 상기 N개의 히든 블록들(62_1~62_N)은 백본 모델로부터 추출된 복수의 히든 레이어들을 포함하도록 구성되고, 이때, 각각 동일한 개수의 상기 히든 레이어들을 포함하도록 구성된다. 상기 N개의 히든 블록들(62_1~62_N)은 추론 작업을 순차적으로 수행하여 상기 시설 작물 이미지에 대한 특징 데이터를 순차적으 로 출력한다. 이때, 상기 추론 작업은 상기 N개의 히든 블록들(62_1~62_N)에서 계산한 신뢰도에 따라, 조기에 종료될 수 있다. 예를 들면, K번째 히든 블록(62_K)에서 출력한 특징 데이터에 대한 신뢰도가 목표 신뢰도 이상인 경우, K번째 이후의 블록들(62_K+1 ~ 63)은 추론 작업을 조기에(early) 종료(stop)한다. 이렇게 함으로써, 추론 시간을 크게 줄일 수 있다. 상기 N개의 브랜치 모듈들(65_1~65_N)은 상기 N개의 히든 블록들(62_1 ~ 62_N)에서 순차적으로 출력되는 상기 특징 데이터에 대한 분류 작업을 순차적으로 수행하고, 그 분류 작업에 따라 획득한 상기 시맨틱 특징 데이터와 클래스 라벨을 선택적으로 출력한다. 이때, 상기 N개의 히든 블록들(62_1~62_N)과 유사하게, 상기 분류 작업은, 상기 시맨틱 특징 데이터에 대한 신뢰도에 따라, 조기에 종료될 수 있다. 예를 들면, 상기 N개의 브랜치 모듈들(65_1 ~ 65_N) 중에서 K(N보다 작은 자연수)번째 브랜치 모듈(65_K)은 K번 째 히든 블록(62_K)으로부터 출력되는 상기 특징 데이터에 대한 분류 작업을 수행하여 획득한 상기 시맨틱 특징 데이터에 대한 신뢰도를 계산하고, 상기 신뢰도가 목표 신뢰도 이상인 경우, 상기 시맨틱 특징 데이터를 출력한 다. 이때, 상기 K번째 브랜치 모듈(65_K)이 신뢰도가 높은 상기 시맨틱 특징 데이터와 클래스 라벨을 출력하면, K번째 이후의 브랜치 모듈들(65_K+1 ~ 65_N)은 분류 작업을 조기에 중지(early stop)한다. 이렇게 함으로써, 분 류 작업에 따른 추론 시간을 크게 줄일 수 있다. 만일, K번째 브랜치 모듈(65_K)에서 계산한 시맨틱 특징 데이터에 대한 신뢰도 값이 목표 신뢰도 값보다 미만인 경우, K번째 브랜치 모듈(65_K)은 상기 시맨틱 특징 데이터와 이에 대한 클래스 라벨을 출력하지 않고, K+1번째 히든 블록(62_K+1)이 추론 작업을 진행한다. 이후, K+1번째 히든 블록(62_K+1)에 연결된 브랜치 모듈(65_K+1)이 K+1번째 히든 블록(62_K+1)의 추론 작업에 따라 계산된 특징 데이터에 대한 분류 작업을 수행하여 획득한 시맨틱 특징 데이터에 대한 신뢰도 값을 계산하 고, 그 신뢰도 값이 목표 신뢰도 값이 이상인 경우, 상기 시맨틱 특징 데이터와 이에 대한 클래스 라벨을 출력 한다. 모든 브랜치 모듈들(65_1 ~ 65_N)에서 계산한 신뢰도 값들이 목표 신뢰도값보다 모두 낮은 경우, 나머지 블록 이 히든 블록들을 거치면서 계산된 특징 데이터에 대한 추론 작업을 수행하고, 그 추론 작업을 수행하여 획 득한 시맨틱 특징 데이터와 이에 대한 클래스 라벨을 출구 모듈을 통해 출력한다. 출구 모듈은 나머지 블록에 연결된 점을 제외하면, 브랜치 모듈과 동일한 기능을 갖는다. 히든 블록들(62_1 ~ 62_N)에 연결된 브랜치 모듈들(65_1 ~ 65_N)은 히든 블록들에서 계산한 결과를 출력시키는 일종의 출구(exit)로 역할을 하며, 추론 작업을 조기에 종료(stop)시키는 역할을 한다. 이러한 측면에서, 시맨 틱 추출 모듈에 장착된 제2 합성곱 신경망은 조기 종료(early exiting) 구조(방식)로 설계된 것으로 볼 수 있다. 이러한 조기 종료 구조(방식)으로 설계된 제2 합성곱 신경망은 서버(도 1의 100)에서 생성 및 학습되고, 그 생 성 및 학습된 제2 합성곱 신경망은 시맨틱 추출 모듈(도 6의 620)에 장착(로딩)된다. 이하, 서버에서 상기 시맨 틱 추출 모듈(도 6의 620)에 장착되는 제2 합성곱 신경망을 생성하는 방법에 대해 상세히 설명하기로 한다. 도 9는 본 발명의 실시 예에 따른 시맨틱 추출 모듈에 장착되는 제2 합성곱 신경망을 생성하기 위한 서버의 구 성도이다. 도 9를 참조하면, 서버는 시설 작물에 대한 병충해를 추론하기 위한 ESPD 모델을 생성하고, 생성된 ESPD 모델을 학습시킨다. 이후, 서버는 학습된 ESPD 모델을 이동형 엣지 장치인 이동 로봇으로 송신한다. 또한 서버는 이동 로봇에서 ESPD 모델을 이용하여 시설 작물에 대한 병충해를 추론하여 획득한 추론 결과인 시맨틱 분할 이미지와 클래스 라벨을 수신하고, 수신된 시맨틱 분할 이미지와 클래스 라벨을 추가 샘플데이터셋으로 이용하여 ESPD 모델에 대한 재학습을 수행한다. 이를 위해, 서버는 저장소, 로더(loader: 120), 메모리, 마크 모듈(mark module: 140), 재구성 모듈, 학습 모듈, 통신 장치 및 프로세서를 포함한다. 프로세서는 주변 구성들에 동작을 제어, 실행 및 관리하는 유닛으로, 적어도 하나의 CPU, 적어도 하나의 GPU 및 이들 중 적어도 하나를 포함하는 반도체 칩으로 구현될 수 있다. 프로세서는 ESPD 모델을 생성 및 학습시키는 핵심 구성이다. 구체적으로, 프로세서는 시설 작물 이미 지로부터 상기 시설 작물의 잎 모양에 대한 공간 특징 데이터를 추출하는 제1 합성곱 신경망을 생성 및 학습시 킨다. 학습된 제1 합성곱 신경망은 상기 공간 추출 모듈(도 6의 610)에 장착된다. 또한 프로세서는 상기 시설 작물 이미지로부터 상기 시설 작물의 잎 모양에 대한 병충해의 종류를 나타내 는 시맨틱 특징 데이터를 추출하는 제2 합성곱 신경망을 생성 및 학습시킨다. 이때, 상기 제2 합성곱 신경망은, 히든 레이어들(hidden layers)에서 상기 시맨틱 특징 데이터를 출력하는 조기 종료(early exiting) 구조를 갖도 록 설계된다. 학습된 제2 합성곱 신경망은 상기 시맨틱 추출 모듈(도 6의 620)에 장착된다. 또한, 프로세서는 상기 공간 특징 데이터와 상기 시맨틱 특징 데이터를 융합하여, 상기 잎 모양에 대한 시 맨틱 분할 이미지를 출력하는 제3 합성곱 신경망을 생성 및 학습시킨다. 학습된 제3 합성곱 신경안은 상기 특정 융합 모듈에 장착된다. 또한, 프로세서는 상기 공간 추출 모듈(도 6의 610), 상기 시맨틱 추출 모듈(도 6의 620) 및 상기 특정 융 합 모듈을 연결하여 상기 ESPD 모델을 구축한 후, 병충해와 관련된 샘플 데이터셋을 이용하여 상기 생성된 인공 지능 모델을 학습시킨다. 이후, 프로세서는 상기 학습된 ESPD 모델을 통신 장치를 통해 이동 로 봇으로 송신한다. 도 10은 도 9에 도시된 서버에서 시맨틱 추출 모듈에 장착되는 제2 합성곱 신경망을 생성하는 방법을 나타내는 흐름도이다. 도 9 및 10을 참조하면, 먼저, S110에서, 프로세서에 의해 실행되는 상기 로더(loader: 120)가, 상기 저장 소에 저장된 백본 모델(Backbone Model: 80)과 설정 파일(112: config file)을 메모리에 로딩하는 작업을 처리한다. 상기 설정 파일에는 합성곱 신경망을 생성하는데 필요한 다양한 설정값들이 기록되어 있으며, 설정값은, 예를 들면, 도 7에 도시된 히든 블록들(62_1~62_N) 또는 브랜치 모듈들(65_1~65_N)의 개수일 수 있다. 이어, S120에서, 상기 프로세서에 의해 실행되는 마크 모듈(mark module: 140)이, 상기 메모리에 로딩된 백본 모델로부터 분리 가능한 상기 히든 레이어들을 추출하는 작업을 처리한다. 이 작업은, 예를 들면, 도 8에 도시된 바와 같이, 상기 백본 모델에서 스킵 커넥션(skip connection) 구조 로 연결된 레이어들(82, 83, 84, 85)을 제외한 나머지 레이어들(81 및 86)을 상기 히든 레이어들로서 추출하는 작업일 수 있다. 더 구체적으로, 상기 작업은, 도 8에 도시된 바와 같이, 상기 백본 모델에서 메인 경로(MP)에 배치된 레이 어들(82, 83, 84)과 상기 메인 경로(MP)를 우회하는 서브 경로(SP)에 배치된 레이어들을 제외한 나머지 레 이어들(81, 86)을 상기 히든 레이어들로서 추출하는 작업일 수 있다. 이어, S130에서, 상기 프로세서에 의해 실행되는 재구성 모듈(reconstruction module)이, 상기 추출된 히든 레 이어들을 재구성하고, 재구성된 히든 레이어들을 포함하는 제2 합성곱 신경망을 생성하는 작업을 처리한다. 이 작업은 상기 추출된 히든 레이어들을 N개의 히든 블록들로 구성하고, 그 히든 블록들을 백본 모델의 신경망 구 조와 최대한 유사하게 재구성함을 목표로 한다. 도 11은 도 10에 도시된 S130의 상세 흐름도이다. 도 11을 참조하면, 상기 백본 모델(도 8의 80)로부터 추출된 히든 레이어들(81 및 86)을 재구성하여 상기 시맨 틱 추출 모듈(도 6의 620)에 장착되는 제2 합성곱 신경망을 생성 및 준비하기 위해, 먼저, S131에서, 프로세서 에 의해 실행되는 재구성 모듈이 상기 추출된 히든 레이어들을 N개씩 묶어서 상기 추출된 히든 레이 어들을 N개의 히든 블록들(도 7의 62_1 ~ 62_N)로 재구성하는 작업을 처리한다. 여기서, 'N'은 설정 파일(도 9 의 112)에 기록된 설정값에 의해 결정될 수 있다. 상기 추출된 히든 레이어들을 N개의 히든 블록들(도 7의 62_1 ~ 62_N)로 재구성하기 위해, 예를 들면, 상기 추출된 히든 레이어들의 전체 개수를 'N'으로 나눈 몫이 'Q'이고,나머지가 'R'일 때, 프로세서(도 9의 180)가 상기 추출된 히든 레이어들을 Q개씩 묶어서 N개의 히든 블록들 (62_1~62_N)로 재구성하고, 상기 추출된 히든 레이어들을 Q개씩 묶은 후 남은 R개의 히든 레이어들을 1개의 나 머지 블록(도 7의 63)으로 재구성하는 작업을 처리한다. 이어, S132에서, 프로세서가 상기 N개의 히든 블록들(62_1~62_N)과 상기 N개의 브랜치 모듈들(65_1~65_ N)을 1:1로 연결하는 작업을 처리한다. 이어, S133에서, 프로세서가 상기 1:1로 연결된 상기 N개의 히든 블록들(62_1~62_N)과 상기 N개의 브랜치 모듈(65_1~65_N)을 포함하도록 구성된 상기 제2 합성곱 신경망을 생성한다. 각 브랜치 모듈은 해당 히든 블록으로 출력된 특징 데이터에 대한 분류(Classification) 작업을 처리하고, 상기 분류 작업에 따라 획득한 시맨틱 특징 데이터에 대한 신뢰도 값(Confidence value)을 계산하고, 이러한 신뢰도 값(Confidence value)을 포함하는 클래스 라벨(Class label)을 생성한다. 여기서, 클래스 라벨은 상기 분류 작 업에 따라 예측된 병충해 이름을 나타내는 예측 라벨(predicted label), 정답을 나타내는 그라운드 라벨(ground label), 픽셀 정확도 값(pixel accuracy value) 등을 더 포함할 수 있다. 신뢰도 값(Confidence value)과 클래 스 라벨을 생성하기 위해, 소프트맥스(softmax) 함수가 이용될 수 있다. 제2 합성곱 신경망의 추론 작업을 조기 종료(early exiting)방식으로 처리하기 위해, 상기 N개의 브랜치 모듈들 (65_1~65_N) 중에서 K(N보다 작은 자연수)번째 브랜치 모듈(65_K)은, K번째 히든 블록(62_K)에서 출력한 특징 데이터에 대한 분류 작업을 수행하여 획득한 상기 시맨틱 특징 데이터의 신뢰도를 계산하고, 상기 신뢰도가 목 표 신뢰도 이상인 경우, 상기 시맨틱 특징 데이터를 출력한 후, 상기 K번째 이후의 히든 블록들(62_K+1~62_N)과 브랜치 모듈들(65_K+1~65_N)은 연산 동작을 조기에 중지(early stop)한다. 이러한 조기 종료(early exiting) 방식에 따르면, 시설 작물 이미지의 객체 식별 난이도가 낮으면, 추론 결과에 대한 신뢰도 값이 목표 신뢰도 값에 빠르게 도달하기 때문에, 추론 작업이 빠르게 종료될 것이다. 반대로 시설 작물 이미지의 객체 식별 난이도가 높으면, 추론 결과에 대한 신뢰도 값이 목표 신뢰도 값에 늦게 도달하기 때 문에, 추론 작업이 늦게 종료될 것이다. 이것은 추론 작업의 정확도를 유지하면서 불필요한 추론 연산을 생략할 수 있음을 의미하고, 궁극적으로 충분한 하드웨어 자원을 보유하지 못한 이동 로봇에서 추론 작업의 가속화를 달성할 수 있음을 의미한다. 이상, 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시 킬 수 있음을 이해할 수 있을 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2023-0051975", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 시설 작물의 병충해를 탐지하기 위한 전체 시스템을 나타내는 블록도이다. 도 2는 본 발명의 실시 예에 따른 시설 작물의 병충해를 탐지하기 위한 인공 지능 모델을 학습하기 위해 사용될 수 있는 샘플 데이터셋의 예를 설명하기 위한 도면이다. 도 3은 본 발명의 실시 예에 따른 인공 지능 모델에서 추론하여 생성한 손상된 시설 작물의 잎에 대한 다양한 시맨틱 분할 이미지의 예들을 보여주는 도면이다. 도 4는 본 발명의 실시 예에 따른 상기 사용자 장치에서 표시하는 UI 화면을 나타내는 도면이다. 도 5는 본 발명의 다양한 실시 예에 따른 엣지 자치가 이동 로봇인 경우 상기 이동 로봇의 외관 형상을 간략히 나타내는 측면도이다. 도 6은 본 발명의 실시 예에 따른 ESPD 모델의 구성을 나타내는 블록도이다. 도 7은 도 6에 도시된 시맨틱 추출 모듈에 장착되는 제2 합성곱 신경망의 구성을 나타내는 블록도이다. 도 8은 본 발명의 실시 예에 따른 심층 신경망의 스킵 커넥션 구조를 설명하기 위한 도면이다. 도 9는 본 발명의 실시 예에 따른 시맨틱 추출 모듈에 장착되는 제2 합성곱 신경망을 생성하기 위한 서버의 구 성도이다. 도 10은 도 9에 도시된 서버에서 시맨틱 추출 모듈에 장착되는 제2 합성곱 신경망을 생성하는 방법을 나타내는 흐름도이다. 도 11은 도 10에 도시된 S130의 상세 흐름도이다."}
