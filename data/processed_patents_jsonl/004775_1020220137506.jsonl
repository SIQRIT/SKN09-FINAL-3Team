{"patent_id": "10-2022-0137506", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0057143", "출원번호": "10-2022-0137506", "발명의 명칭": "인공지능 예측모델을 이용한 실제현실과 가상현실의 동기화 장치 및 방법", "출원인": "한국전자통신연구원", "발명자": "고석갑"}}
{"patent_id": "10-2022-0137506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "실제현실에서 데이터 수집 시각을 측정하고, 사용자 기기에서 가상현실 재현시각을 측정하고, 전체 지연시간을 측정하여 앞으로의 지연시간을 예측하고, 예측한 지연시간 만큼의 미래 데이터를 예측하여 가상객체 공간을 구성하는 것을 포함하는 실제현실과 가상현실의 동기화 장치 및 방법."}
{"patent_id": "10-2022-0137506", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "메타버스, 증강현실, 혼합현실 등 가상현실 구성시에 실제현실과 가상현실과의 시간을 일치(동기화)하는 발명이 다. 가상현실 구축시 실제현실과 가상현실이 시간적으로 일치해 보이도록, 가상현실 공간 구성 과정에서 발생하 는 지연시간을 예측하고, 예상되는 지연시간 만큼의 미래의 장면을 예측하여 가상현실을 구성하도록 한다. 이와 같이, 전체 가상현실 생성 시스템의 지연시간을 예측하고, 그에 맞는 미래의 데이터를 예측하여 가상현실 구성 과정에 반영함으로써, 사용자(뷰어) 입장에서 실제현실과 가상현실을 시간적으로 일치시킨다."}
{"patent_id": "10-2022-0137506", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능, 기계학습, 디지털트윈, 가상현실, 혼합현실, 증강현실, 사이버물리시스템(CPS), 메타버스 에 관한 것으로, 보다 구체적으로는, 인공지능 기계학습 기술을 활용하여, 메타버스 가상현실이 실제현실과 시 간차 없이 일치하도록 하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0137506", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "가상현실 내지는 가상세계를 구현하기 위해서, 실제현실의 데이터를 실시간으로 수집하고, 이를 가상세계에 반 영하기 위하여 사용자가 이를 보거나 체험하기 위한 렌더링 과정을 거치게 된다. 여기서, 실제현실에서 데이터 를 수집하는 과정, 수집한 데이터를 서버로 전송하는 과정, 서버에서 3D 가상세계에 수집한 데이터를 반영하는 과정, 형성된 가상세계에 대한 데이터를 사용자(뷰어) 디바이스 또는 컴퓨터로 전송하는 과정, 사용자 디바이스 또는 컴퓨터에서의 가상세계 데이터 시각화를 위한 렌더링 과정 등에서 지연시간이 발생하게 된다. 이러한 전체 지연시간은 실제현실과 가상현실과의 시간차를 발생시켜, 가상현실 장면은 항상 실제현실과 늦게 나타나는 문제 를 갖게 된다. 도 1은 메타버스, 증강현실, 혼합현실 등 가상현실과 실제현실의 불일치 예를 보인다. 메타버스는 실제현실을 가상세계에 반영한 확장 가상세계를 의미한다. 현장에 형태변경 가능한 기계가 있다고 하자. 이 기계의 상태를 가상공간에 매핑하고자 한다. 현장에 있는 현장장치 또는 게이트웨이는 이 기계의 센서 데이터 를 수집한다. 수집된 센서 데이터에는 기계의 각 관절의 위치, 각도, 속도, 영상 등이 포함된다. 또한 게이트웨이는 기계를 제어하고 있는 제어 데이터 수집도 할 수 있다. 게이트웨이는 이들 현장 데이터(즉 IoT(사물인터넷) 데이터)를 주기적 또는 수시로 수집하여 유무선 네트워크를 통해 메타버스 서버 로 전송한다. 메타버스 서버 내의 현장데이터 수집기는 현장 게이트웨이로부터 현장데이터(1 7)를 수신한다. 3D 객체공간 생성기는 모델링 데이터 및 그 밖의 추가 데이터(미도시)와 상기 수신한 현장데이터를 결합하여 가상공간을 구성한다. 메타버스 서버는 구성된 가상공간(예를 들어, 3D 객체 공 간) 데이터를 클라이언트 장치로 유무선 네트워크를 통해 전송한다. 클라이언트 장치는 사용자(가 상공간을 보거나 체험하고자 하는 사용자)의 기기 또는 컴퓨터일 수 있다. 클라이언트 장치 내의 영상합성 기는 렌더링 과정을 통해 가상공간 데이터를 사용자가 볼 수 있는 2D 또는 3D의 가상현실 영상으로 변환한다. 그러나, 이와 같은 전체 과정에서 시간지연이 발생하며, 사용자에게 보여지는 가상현실은 그 시간지연만큼의 과거 시간의 장면을 나타낸다. 그래서 가상현실과 실제현실의 불일치가 발생한다. 종래에는 이러한 시간지연 문제를 해결하여 가상현실과 실제현실의 동기를 위하여, CPU 처리 및 메모리 처리 시 간을 단축하거나 GPU의 성능을 개선하는 등 지연시간을 줄이려는 노력으로 접근하였다. 그러나, 이러한 접근방 법으로는 지연시간을 완전히 없앨 수 없다."}
{"patent_id": "10-2022-0137506", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 메타버스, 증강현실, 혼합현실 등 가상현실 구성시에 실제현실과 가상현실과의 시간을 일치 (동기화)하는 것이다."}
{"patent_id": "10-2022-0137506", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위하여, 가상현실 구축시 실제현실과 가상현실이 시간적으로 일치해 보이도록, 가상현실 공간 구성 과정에서 발생하는 지연시간을 예측하고, 예상되는 지연시간 만큼의 미래의 장면을 예측하여 가상현 실을 구성하도록 한다. 이와 같이, 본 발명에서는, 전체 가상현실 생성 과정의 지연시간을 예측하고, 그에 맞는 미래의 데이터를 예측하여 가상현실에 반영함으로써, 사용자(뷰어) 입장에서 실제현실과 가상현실을 시간적으로 일치시킨다. 지연시간의 예측은 다음과 같이 이루어질 수 있다. 실제현실에서 데이터 수집 시각을 측정하고, 사용자 기기에 서 가상현실 재현시각을 측정하고, 서버에 전달하여 전체 지연시간을 측정하고 이를 기반으로 앞으로의 지연시 간을 예측하고, 예측한 지연시간 만큼의 미래 데이터를 예측하여 가상객체 공간(예를 들어, 메타버스)을 구성한 다. 상기 지연시간 예측은 인공지능 예측모델에 의해 수행될 수 있다. 상술한 과제 해결 수단은 이후에 도면과 함께 설명하는 발명의 실시예를 통하여 더욱 명확해질 것이다."}
{"patent_id": "10-2022-0137506", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 인공지능 예측모델을 이용하여 실제현실과 메타버스 등 가상현실의 시간지연을 없애도록 한 다. 이를 통해 가상현실과 실제현실이 보다 정확히 결합될 수 있다. 사용자는 실제현실과 가상현실 간의 지연시 간이 없으므로 보다 편안하게 메타버스 등 가상현실 환경을 즐길 수 있다. 본 발명은 증강현실 및 혼합현실에서도 시차 없이 실제현실과 결합될 수 있다. 예를 들면, 실제현실에서 움직이 는 사람의 머리에 가상의 모자를 씌우는 증강현실 응용에서, 실제현실의 움직이는 사람 머리의 궤적을 예측하여, 가상의 모자를 그려줄 수 있어, 일체감 있는 증강현실 응용이 가능하다."}
{"patent_id": "10-2022-0137506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 바람직한 실시예를 첨부 도면을 참조하여 상세히 설명한다. 이하 설명에서 사용된 용어는 본 발명의 바람직한 실시예를 설명하기 위한 것이며 본 발명을 제한하고자 하는 것이 아니다. 본 명세서에서 단수 형에는 특별히 언급하지 않는 한 복수형도 포함한다. 또한 명세서에 사용된 '포함한다(comprise, comprising 등)'라는 용어는 언급된 구성요소, 단계, 동작, 및/또는 소자 이외의 하나 이상의 다른 구성요소, 단계, 동작, 및/또는 소자의 존재 또는 추가를 배제하지 않는 의미로 사용된 것이다. 도 2는 본 발명의 실시예에 따른 메타버스 생성 시스템의 구조를 나타낸다. 현장장치(게이트웨이)는 센서 데이터 수집기와 제어데이터 수집기, 수집시각 측정기, 시간동기화 모듈을 포함한다. 메타 버스 서버는 현장데이터 수집기, 현장데이터 예측기, 지연시간 예측기, 시간동기화 모듈 , 3D객체공간 생성기를 포함한다. 클라이언트 장치는 시간 동기화 모듈, 재현시각 측정기 , 영상 합성기를 포함한다. 현장장치의 센서데이터 수집기는 현장에 있는 객체의 데이터를 수집한다. 현장에 있는 객체 란, 메타버스 상에 적용될 객체로, 어떤 기계, 사물, 시스템, 물체 등 다양한 객체가 될 수 있다. 도 2에서는 현장에 있는 객체의 예로 관절이 있는 기계가 도시되어 있다. 센서데이터 수집기는 메타버스 반영에 필요한 센서 데이터를 수집한다. 센서데이터 수집기가 수집하는 센서데이터는 광의의 센서 데이터로, 객체 의 상태, 위치, 방향, 속도, 각도, 온도, 전력, 영상(이미지), 3D 이미지 등 다양한 정보를 포함한다. 센서데이 터 수집기는 수시로 또는 주기적으로 센서데이터를 수집하고, 메타버스 서버의 현장데이터 수집기 로 유무선 네트워크를 통해 전송한다. 현장장치의 제어데이터 수집기는 현장의 객체에 주어지는 명령 또는 규칙 등의 제어데이터를 수 집한다. 객체 특성에 따라 제어데이터 및 제어데이터 수집기는 없을 수도 있다. 제어데이터 수집기는 수시로 또는 주기적으로 제어데이터를 수집하고, 메타버스 서버의 현장데이터 수집기로 유무선 네트 워크를 통해 전송한다. 현장장치의 수집시각 측정기는 센서데이터 및 제어데이터 수집 시각을 측정한다. 수집시각 측정기 에서 측정된 수집시각은 시간동기화 모듈(140 및 240)을 통해 현재 시각이 메타버스 서버와 정확히 일치되어 있다. 수집시각 측정기가 측정한 수집시각은 메타버스 서버의 지연시간 예측기로 전송 된다. 구현에 따라 '수집시각'은 센서데이터 수집기 및 제어데이터 수집기가 전송하는 IoT(사물인터 넷) 데이터(센서데이터 및 제어데이터)와 함께 전송될 수도 있으며, 이 경우에는 메타버스 서버 내 현장데 이터 수집기가 '수집시각'을 지연시간 예측기로 전달할 수 있다. 시간동기화 모듈(140, 240, 310)은 메타버스 시스템의 기기들, 즉 현장장치, 메타버스 서버, 클라이 언트 장치들 간의 시각을 일치시킨다. 현장장치의 시간동기화 모듈은 서버와 시간동기화 메시지를 주고 받으며 현재시각을 서버와 일치하도록 한다. 시간동기화 메시지는 NTP(Network Time Protocol, IETF RFC 5905), PTP(Precision Time Protocol, IEEE1588) 등 기존 시간동기 프로토콜을 이용할 수 있다. 이러한 프로토콜은 네트워크 지연시간 등을 고려하여, 시스템 간 정확한 시각을 맞출 수 있도록 도와준다. 시간동기화 모듈은 현장장치 또는 수집시각 측정기의 현재시각을 서버와 맞추도 록 한다. 메타버스 서버의 현장데이터 수집기는, 현장장치(게이트웨이)의 센서데이터 수집기 및 제 어데이터 수집기로부터 IoT(사물인터넷) 데이터, 즉 현장데이터를 수신한다. 현장데이터 수집기는 수 집된 현장데이터를 현장데이터 예측기로 전달한다. 메타버스 서버의 현장데이터 예측기는 지연시간 예측기로부터 예측된 지연시간을 받고 현장데이 터 수집기로부터 현장데이터를 받은 후, 예측된 지연시간만큼의 미래의 현장데이터가 어떻게 될 것인지를 예측하여 그 값을 3D객체공간 생성기로 전달한다. 현장데이터 예측기의 예측기능은 후술할 시계열 기 계학습 예측모델 등으로 구현할 수 있다. 메타버스 서버의 지연시간 예측기는 전체 지연시간이 얼마나 될 것인지 지속적으로 예측한다. 지연시 간 예측기는 시간동기화 모듈에 의해 현장장치 및 클라이언트 장치와 일치된 시각을 사용 한다. 지연시간 예측기는 수집시각과 재현시각, 3D객체공간 데이터(가상현실 데이터)를 입력으로 받아, 이 번 장면의 전체 지연시간이 어떻게 될지를 예측한다. 지연시간 예측기의 예측 기능은 후술할 기계학습 예 측모델 등으로 구현할 수 있다. 지연시간 예측기는 전체 지연시간을 측정하기 위하여 수집식별자를 생성할 수 있다. 수집식별자는 클라이언트 장치로부터 재현시각을 받았을 때 어떤 수집시각에 대한 재현시 각인지를 확인하는 데 사용된다. 수집식별자 생성은, 수집시각을 그대로 사용하여 생성할 수도 있고, 순차적으 로 증가하는 값을 사용하거나 수집시각을 키(key)로 하는 해쉬함수(hash function)를 이용하여 생성할 수도 있 다. 메타버스 서버의 3D객체공간 생성기는, 예측된 현장데이터와 모델링 데이터 및 추가 데이터를 이용하 여 가상공간을 구성한다. 3D객체공간 생성기는 구성한 가상공간 데이터를 유무선 네트워크를 통해 클라이 언트 장치의 영상합성기로 전송한다. 이때 수집식별자를 함께 전송할 수 있다. 메타버스 서버의 시간동기화 모듈은, 서버와, 현장장치(게이트웨이), 클라이언트 장치의 시간이 일치하도록 주기적으로 시간동기화 메시지를 교환한다. 클라이언트 장치의 영상합성기는 메타버스 서버로부터 3D객체공간 데이터(가상공간 데이터, 가 상공간 장면 데이터)를 수신한 다음, 사용자가 보거나 체험할 수 있는 영상으로의 변환 작업을 수행한다. 즉 렌더링을 수행한다. 영상합성기는 렌더링이 끝나면 수집식별자를 재현시각 측정기로 전송할 수 있다. 이 가상현실 영상은 시간의 흐름에 따라 변화된 실제현실 영상과 일치하게 된다. 클라이언트 장치의 재현시각 측정기는 영상합성기에서 렌더링이 끝난 시각을 측정한다. 이를 재 현시각이라고 하며, 사용자가 볼 수 있는 화면이 나타난 시각을 의미한다. 재현시각 측정기는 영상합성기 로부터 수집식별자를 수신한다. 재현시각 측정기는 수집식별자와 재현시각을 메타버스 서버의 지연시간 예측기로 전송한다. 클라이언트 장치의 시간동기화 모듈은, 서버와 클라이언트 장치의 시각이 일치하도록 주기 적으로 시간동기화 메시지를 교환한다. 도 3은 메타버스 서버의 지연시간 예측기의 보다 세부적인 구조를 예시한다. 지연시간 예측기의 입력은 3D객체공간 생성기로부터의 3D객체공간 데이터, 현장장치(게이트웨이)의 수집시각 측정기로부터의 수집시각, 클라이언트 장치로부터의 재현시각 및 수집식별자이다. 지연시간 예측기의 출력은 지연시간 예측값(=예측된 지연시간)과 수집식별자이다. 지연시간 예측기의 3D객체공간 데이터 특성 추출기는 3D객체공간 데이터로부터 특성값(feature)을 추 출한다. 특성값은, 객체수, 도형개수, 복잡도, 데이터량 등 한 시점에서의 3D객체공간을 대변하는 값들로, 3D객 체공간 구축 지연시간 및 3D객체공간데이터 전송 지연시간, 영상합성기에서의 렌더링 시간 등에 영향을 미 치는 요소이다. 지연시간 예측기는 이러한 3D객체공간데이터 특성값을 과거의 Nf개 만큼 저장한다. 이는 특성값의 변화의 흐름을 통해 지연시간 예측의 정확도를 높일 수 있다. 여기서 특성값은 하나의 스칼라 값이 아 닌 여러 값이 결합된 벡터(vector)값일 수 있다. 이 3D객체공간 데이터 특성 추출기는 후술할 기계학습 예 측모델의 종류에 따라, 이 기계학습 예측모델에 내장될 수도 있으며 별도 모듈로 구현될 수도 있다. 지연시간 예측기의 수집식별자 생성기는 현장장치(게이트웨이)의 수집시각 측정기로부터 수집시각을 받아 수십식별자를 생성한다. 수집식별자는 전체 지연시간 측정을 위해 수집시각과 재현시각의 짝을 맞추기 위한 용도로 사용된다. 수집식별자는 매 수집을 구분하기 위한 값으로, 순차적으로 증가하는 값이나, 수 집시각을 그대로 사용하거나, 수집시각을 해시함수 등을 통해 변환한 것 등으로 구현할 수 있다. 수집식별자 생 성기는 수집시각 표(테이블)에 새로 생성한 수집식별자와 수집시각을 추가하고, 수집식별자를 3D객체 공간 생성기에 전달한다. 지연시간 예측기는 클라이언트 장치의 재현시각 측정기로부터 재현시각과 수집식별자를 수신한 다음, 수집시각 표(테이블)에서 수집식별자를 이용해 수집시각을 찾아낸다. 재현시각과 수집시각 차이를 구하여, 측정된 지연시간을 구한다. 지연시간 예측기는 측정된 지연시간을 과거의 Nd 개수 만큼 저장한다. 이는 측정된 지연시간의 변화를 이용하여 지연시간 예측의 정확도를 높이는 데 사용될 수 있다. 지연시간 예측기는 기계학습 예측모델을 이용하여 지연시간을 예측한다. 앞에서 언급한 것과 같이, 기계학습 예측모델의 종류에 따라 상기 3D객체공간 데이터 특성 추출기는 기계학습 예측모델에 내장될 수도 있으며 별도 모듈로 구현될 수도 있다. 기계학습 예측모델은 인공신경망, 재귀신경망(RNN, Recurrent Neural Networks), 칼만필터(Kalman filter), ARIMA(Auto-regressive Integrated Moving Average), online ARIMA(논문: Chenghao Liu \"Online ARIMA Algorithms for Time Series Prediction\", AAAI 2016) 등 회 귀(Regression) 예측모델을 사용할 수 있으며, 입력으로는 과거 3D객체공간데이터 특성값들, 현재 3D객체공간 데이터 특성값, 과거 측정된 지연시간들, 현재 측정된 지연시간을 취하며, 출력으로는 예측된 지연시간을 출력 한다. 기계학습 예측모델은 시스템을 가상 또는 실제로 운용하며 누적된 데이터를 이용하여 학습시킨다. 또한 시스템을 운용하며 추가로 누적되는 데이터를 이용하여 추가학습을 수행하므로써 기계학습 예측모델 의 예측 성능(정확도)를 향상시킬 수 있다. 도 4는 상기 기계학습 예측모델의 일례로서 인공신경망을 이용한 구조를 보인다. 지연시간 예측기의 인공신경망의 입력으로 과거 3D객체공간데이터 특성값들, 현재 3D객체공간 데이터 특성 값, 과거 측정된 지연시간들, 현재 측정된 지연시간을 넣으면, 예측된 지연시간을 출력한다. 도 5는 현장데이터 예측기의 구조(실시형태 1)를 보인다. 이 실시형태 1에 따른 현장데이터 예측기의 입력은 수집된 현장데이터와 예측된 지연시간이고, 출력은 예 측된 현장데이터이다. 즉, 상술한 3D객체공간 생성기가 예측된 지연시간 만큼 미래의 장면을 구성할 수 있 도록 미래의 현장데이터를 예측하여 만들어 내는 것이다.현장데이터 예측기는 수집된 현장데이터를 과거의 Nm개 만큼 저장하고 있다. 이는 데이터의 변동을 통해 예측을 수행하기 위함이다. 현장데이터 예측기는 이들 과거 수집된 현장데이터와 현재 수집된 현장데이터 를 시계열 기계학습 예측모델에 입력한다. 시계열 기계학습 예측모델은 재귀신경망(RNN, Recurrent Neural Networks), LSTM(Long Short Term Memory), Transformer(논문: Ashish Vaswani \"Attention Is All You Need\", NIPS, 2017), Informer(논문: Haoyi Zhou \"Informer: Beyond Efficient Transformer for Long Sequence Time Series Forecasting\"), 칼만필터, ARIMA, online ARIMA 등 시계열 예측 모델이 될 수 있다. 시 계열 예측 모델은 미래 시간들에 대한 예측 값들을 출력한다. 도 5에서, 예측된 현장데이터 t1, 예측된 현장데 이터 t2, 예측된 현장데이터 t3, 예측된 현장데이터 t4가 시계열 예측 모델의 출력이다. 본 실시형태 1의 시계 열 기계학습 예측모델의 출력은 등간격의 이산적인(discrete) 시간에서의 예측값을 출력한다. 현장데이터 예측기의 예측데이터 선택기는 입력된 예측된 지연시간에 가장 가까운 예측된 현장 데이 터를 선택한다. 예를 들어, t1=1초, t2=2초, t3=3초, t4=4초이고 예측된 지연시간이 3.1초라면, 가장 가까운 t3 시점의 예측된 현장데이터 t3을 선택한다. 도 6은 도 5의 실시형태 1에 따른 현장데이터 예측기의 시계열 기계학습 예측모델을 Informer로 구현 한 예를 보인다. Informer는 Encoder와 Decoder로 나뉜다. 예측시, Encoder에는 과거 수집된 현장데이터(t-3 시점에서 t-1시점의 현장데이터인 Xt-3~Xt-1)와 그 이전 과거 수집된 현장데이터(t-7시점 부터 t-4시점에서의 현 장데이터인 Xt-7~Xt-4) 그리고 현재 수집된 현장데이터(Xt0)를 넣고, 동시에 Decoder에는 과거 수집된 현장 데이터(Xt-3~Xt-1)와 현재 수집된 현장데이터(Xt0) 그리고 0으로 마스킹된 부분을 입력으로 넣는다. Decoder(221 2)의 Fully Connected Layer에서는 과거 수집된 현장데이터(Xt-3~Xt-1)와 현재 수집된 현장데이터(Xt0) 그 리고 미래의 예측된 현장데이터(Xt+1~Xt+4)를 출력한다. 이로써, 예측된 현장데이터 t1~t4를 얻을 수 있다. 도 7은 실시형태 2에 따른 현장데이터 예측기의 구조를 보인다. 실시형태 2에 따른 현장데이터 예측기에서는 시계열 기계학습 예측모델이 과거 수집된 현장데이터와 현재 수집된 현장데이터에 추가로 예측된 지연시간을 입력으로 취한다. 도 5의 실시형태 1의 경우 시계열 기계 학습 예측모델의 출력이 이산적이라서 정확한 시점의 예측값을 사용할 수 없었으나, 본 실시형태 2의 시계 열 기계학습 예측모델을 통해서는 이산적이지 않은 연속값에서 정확한 시점의 예측값을 구할 수 있다. 실 시형태 2의 시계열 기계학습 예측모델로는 LTC 네트워크(논문1: Ramin Hasani, \"Liquid Time Constant Networks\", AAAI21 / 논문2: Yulia Rubanova, \"Latent Ordinary Differential Equations for Irregularly- Sampled Time Series\", NeurIPS2019), 연속시간RNN(논문: Huaguang Zhang, \"A Comprehensive Review of Stability Analysis of Continous-Time Recurrent Neural Networks) 등을 사용할 수 있다. 도 8은 도 7의 실시형태 2에 따른 현장데이터 예측기의 시계열 기계학습 예측모델을 LTC 네트워크로 구현한 예를 보인다. LTC 네트워크는 RNN Encoder를 통해 Data Space의 값을 Latent Space의 값으로 변환하며, ODE Solve가 Latent Space 상에서의 값의 변화(궤적)를 예측한 다음, 다시 이를 Data Space로 디코드한다. 구체적으로, RNN Encoder 에 과거 수집된 현장데이터(Xt-3~Xt-1) 및 현재 수집된 현장데이터(Xt0)를 넣으면, ODE Solve를 통해 미래의 어떤 시점의 값을 예측할 수 있다. 여기에 예측된 지연시간(tp) 시점에서의 예측값 Xtp를 얻을 수 있다. 이것이 예측 된 현장데이터 tp이다. 이상에서 본 발명의 사상을 구체적으로 구현한 실시예를 설명하였다. 그러나 본 발명의 기술적 범위는 이상에서 설명한 실시예 및 도면에 한정되는 것이 아니라 특허청구범위의 합리적 해석에 의해 정해지는 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2022-0137506", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실제현실과 가상현실의 불일치 설명 예시도 도 2는 예측모델을 이용한 동기화 방법이 적용된 메타버스 생성 시스템 구조 도 3은 메타버스 서버의 지연시간 예측기의 세부 구조 예시도 도 4는 지연시간 예측기의 기계학습 예측모델의 예시 구조 도 5는 실시형태 1에 따른 현장데이터 예측기의 구조 도 6은 Informer를 이용한 도 5의 시계열 기계학습 예측모델의 구조 도 7은 실시형태 2에 따른 현장데이터 예측기의 구조 도 8은 LTC네트워크를 이용한 도 7의 시계열 기계학습 예측모델의 구조"}
