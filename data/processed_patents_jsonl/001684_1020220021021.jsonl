{"patent_id": "10-2022-0021021", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0009280", "출원번호": "10-2022-0021021", "발명의 명칭": "로봇용 인공지능 모델 제공 방법", "출원인": "주식회사 제타뱅크", "발명자": "최동완"}}
{"patent_id": "10-2022-0021021", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 모듈이, 획득된 데이터를 트레이닝 데이터로 사용하여 기계 학습을 수행하는 단계;상기 인공지능 모듈이, 상기 기계 학습의 결과값에 기초하여, 로봇의 적어도 하나의 동작에 관한 예측 모델을생성하는 단계;상기 예측 모델이 GPU(Graphics Processing Unit)에 인스톨되는 단계;상기 GPU가 PCB에 실장된 상태로, 로봇의 바디 내부에 배치되어, 로봇의 센싱부 및 제어부와 전기적으로 연결되는 단계; 및로봇이, 상기 예측 모델에 기초하여 주행 경로를 생성하고, 생성된 경로를 따라 자율 주행하는 단계;를 포함하는 로봇용 인공지능 모델 제공 방법."}
{"patent_id": "10-2022-0021021", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 전기적으로 연결되는 단계는,상기 GPU가, 상기 제어부와 신호를 교환하는 단계;를 포함하는 로봇용 인공지능 모델 제공 방법."}
{"patent_id": "10-2022-0021021", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 GPU가, 상기 센싱부에서 생성된 데이터를 수신하는 단계;를 더 포함하는 로봇용 인공지능 모델 제공 방법."}
{"patent_id": "10-2022-0021021", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 GPU가, 상기 센싱부에서 생성된 데이터에 기초하여, 반복적으로 기계 학습을 수행하는 단계;를 더 포함하는 로봇용 인공지능 모델 제공 방법."}
{"patent_id": "10-2022-0021021", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,로봇이, 상기 예측 모델에 기초하여 기 설정된 동작을 수행하는 단계;를 더 포함하는 로봇용 인공지능 모델 제공 방법."}
{"patent_id": "10-2022-0021021", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 모듈이, 획득된 데이터를 트레이닝 데이터로 사용하여 기계 학습을 수행하는 단계; 상기 인 공지능 모듈이, 상기 기계 학습의 결과값에 기초하여, 로봇의 적어도 하나의 동작에 관한 예측 모델을 생성하는 단계; 상기 예측 모델이 GPU(Graphics Processing Unit)에 인스톨되는 단계; 상기 GPU가 PCB에 실장된 상태로, 로봇의 바디 내부에 배치되어, 로봇의 센싱부 및 제어부와 전기적으로 연결되는 단계; 및 로봇이, 상기 예측 모 델에 기초하여 주행 경로를 생성하고, 생성된 경로를 따라 자율 주행하는 단계;를 포함하는 로봇용 인공지능 모 델 제공 방법에 관한 것이다."}
{"patent_id": "10-2022-0021021", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 로봇용 인공지능 모델 제공 방법에 관한 것이다."}
{"patent_id": "10-2022-0021021", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근에는 산업체에서 이용되는 산업용 로봇뿐만 아니라 일반 가정이나 사무실, 관공서 등 건물내에서 가사일이 나 사무 보조로서 로봇이 실용화되고 있다. 이에 해당하는 대표적인 예로서 청소 로봇, 안내 로봇, 방범 로봇 등을 들 수 있다. 인공 지능 기술의 발전에 따라 로봇에도 인공 지능 기술이 적용된다. 인공 지능 기술이 적용된 로봇은 센싱 데 이터를 이용해 기계 학습하여 주어진 임무를 수행한다. 이러한 인공 지능 기술이 적용된 로봇은 제조 시점에 충분한 센싱 데이터를 확보하지 못한 시점에서는 충분한 학습을 수행하지 못해 주어진 임무를 수행하는데 효율적인 움직임을 보이지 못하는 문제가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록번호 10-1987133"}
{"patent_id": "10-2022-0021021", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기한 문제점을 해결하기 위하여, 로봇 제조 후 소비자에게 인도된 시점부터 주어진 임무를 효율적 으로 수행할 수 있도록 로봇용 인공지능 플랫폼 제공 방법을 제공하는데 목적이 있다. 본 발명의 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제들은 아래의 기재 로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0021021", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 달성하기 위하여, 본 발명의 실시예에 따른 로봇용 인공지능 모델 제공 방법은, 인공지능 모듈이, 획득된 데이터를 트레이닝 데이터로 사용하여 기계 학습을 수행하는 단계; 상기 인공지능 모듈이, 상기 기계 학 습의 결과값에 기초하여, 로봇의 적어도 하나의 동작에 관한 예측 모델을 생성하는 단계; 상기 예측 모델이 GPU(Graphics Processing Unit)에 인스톨되는 단계; 상기 GPU가 PCB에 실장된 상태로, 로봇의 바디 내부에 배 치되어, 로봇의 센싱부 및 제어부와 전기적으로 연결되는 단계; 및 로봇이, 상기 예측 모델에 기초하여 주행 경 로를 생성하고, 생성된 경로를 따라 자율 주행하는 단계;를 포함한다. 상기 전기적으로 연결되는 단계는, 상기 GPU가, 상기 제어부와 신호를 교환하는 단계;를 포함한다. 본 발명의 실시예에 따른 로봇용 인공지능 모델 제공 방법은, 상기 GPU가, 상기 센싱부에서 생성된 데이터를 수 신하는 단계;를 더 포함한다. 본 발명의 실시예에 따른 로봇용 인공지능 모델 제공 방법은, 상기 GPU가, 상기 센싱부에서 생성된 데이터에 기 초하여, 반복적으로 기계 학습을 수행하는 단계;를 더 포함한다. 본 발명의 실시예에 따른 로봇용 인공지능 모델 제공 방법은, 로봇이, 상기 예측 모델에 기초하여 기 설정된 동 작을 수행하는 단계;를 더 포함한다. 기타 실시예들의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2022-0021021", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 다음과 같은 효과가 하나 혹은 그 이상 있다. 첫째, 로봇의 제조 초기부터 추가적인 기계 학습 없이 로봇의 역할을 효율적으로 수행하는 효과가 있다. 둘째, 일정 정도 기계 학습이 된 로봇을 제조하여 납품함으로써 사용자의 편의성이 증대되는 효과가 있다. 셋째, 로봇의 동작에 따라 저사양 GPU 또는 고사양 GPU 중 선택하여 인스톨할 수 있어 합리적인 제조 단가를 형 성할 수 있다."}
{"patent_id": "10-2022-0021021", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 청구범위의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0021021", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 도 1은 본 발명의 실시예에 따른 로봇의 외관을 도시한 도면이다. 도면을 참조하면, 본 발명의 실시예에 따른 인공 지능 알고리즘이 적용된 로봇(이하, 로봇)은, 멀티 동작 을 수행하는 로봇이다. 구체적으로, 로봇은, 대상 공간에서 자율 주행하며, 접객 동작, 방역 동작, 멸균 동작, 공기청정 동작, 청소 동작 등을 수행할 수 있다. 한편, 대상 공간은, 로봇이 자율 주행하면서 각종 동작을 수행하는 공간으로 정의될 수 있다. 한편, 로봇은, 내부에 포함된 배터리로부터 전기 에너지를 공급받는다. 멀티 동작을 수행하는 동안에 전기 에너지를 공급받기 위해서는, 상황에 맞춰 충전이 이루어져야 한다. 로봇은 상술한 동작 외에 충전 동작을 수행 할 수 있다. 한편, 실시예에 따라, 로봇의 범위에는 의료용 배송 로봇, 방역 로봇, 방역 접객 로봇, 이동형 협동 로봇, 청소 로봇, 특정 공간에 설치되는 디바이스(예를 들면, 출입 관리 시스템, 키오스크)까지 포함될 수 있다. 도 2는 본 발명의 실시예에 따른 로봇의 제어 블럭도이다. 도면을 참조하면, 로봇은, 특정 공간에서 스스로 이동하면서 동작을 수행한다. 로봇은, 자율 주행 이 동 로봇으로 명명될 수 있다. 로봇은, 자율 주행할 수 있다. 로봇은, 센싱부 및 인공지능 모듈 에서 생성된 데이터에 기초하여 주행 경로를 생성하고, 생성된 경로를 따라 자율 주행할 수 있다. 로봇은, 센싱부, 인공지능 모듈, 통신부, 입력부, 메모리, 제어부, 구동 부, 동작부 및 충전부를 포함할 수 있다. 센싱부는, 로봇 내부 또는 외부의 상황을 감지할 수 있다. 센싱부는, 적어도 하나의 센서에서 생성된 데이터를 제어부에 제공할 수 있다. 제어부는, 센싱부로부터 수신된 데이터에 기초하여동작을 수행할 수 있다. 센싱부는, 대상 공간에서 사람을 검출할 수 있다. 예를 들면, 센싱부는, 카메라로 촬영된 영상 분석 을 통해, 대상 공간에서 사람을 검출할 수 있다. 센싱부는, 대상 공간의 오염도를 측정할 수 있다. 예를 들면, 센싱부는, 환경 센서에서 생성된 데이 터를 통해, 대상 공간의 오염도를 측정할 수 있다. 한편, 센싱부는, 로봇이 자율 주행하는 도중에 내부 또는 외부의 상황을 감지할 수 있다. 센싱부는, 복수의 센서를 포함한다. 센싱부는, 초음파 센서, 라이다, 레이다, 적외선 센서, 카메라, 환경 센서, IMU(Inertial Measurement Unit)를 포함할 수 있다. 초음파 센서는, 초음파를 이용하여, 로봇 외부의 오브젝트를 감지할 수 있다. 초음파 센서는, 초음파 송신부, 수신부를 포함할 수 있다. 실시예에 따라, 초음파 센서는, 초음파 송신부, 수신 부와 전기적으로 연결되어, 수신되는 신호를 처리하고, 처리된 신호에 기초하여 오브젝트에 대한 데이터를 생성 하는 적어도 하나의 제어부를 더 포함할 수 있다. 초음파 센서의 제어부 기능은 제어부에서 구현될 수도 있다. 초음파 센서는, 초음파를 기초로 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 초음파 센서는, 로봇의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 로봇 외부의 적 절한 위치에 배치될 수 있다. 라이다는, 레이저 광을 이용하여, 로봇 외부의 오브젝트를 감지할 수 있다. 라이다는, 광 송신부 및 광 수신부를 포함할 수 있다. 실시예에 따라, 라이다는, 광 송신부 및 광 수신부와 전 기적으로 연결되어, 수신되는 신호를 처리하고, 처리된 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적 어도 하나의 제어부를 더 포함할 수 있다. 라이다의 제어부 기능은 제어부에서 구현될 수도 있다. 라이다는, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식으로 구현될 수 있다. 라이다는, 구동식 또는 비구동식으로 구현될 수 있다. 구동식으로 구현되는 경우, 라이다는, 모터에 의해 회전되며, 로봇 주변의 오브젝트를 검출할 수 있다. 비구동식으로 구현되는 경우, 라이다는, 광 스티어링에 의해, 로봇을 기준으로 소정 범위 내에 위치하는 오브젝트를 검출할 수 있다. 로봇은 복수의 비구동식 라이다를 포함할 수 있다. 라이다는, 레이저 광 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 라이다는, 로봇의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 로봇 외부의 적절한 위치에 배치될 수 있다. 레이다는, 전자파 송신부, 수신부를 포함할 수 있다. 레이더는 전파 발사 원리상 펄스 레이더(Pulse Radar) 방 식 또는 연속파 레이더(Continuous Wave Radar) 방식으로 구현될 수 있다. 레이더는 연속파 레이더 방식 중에서 신호 파형에 따라 FMCW(Frequency Modulated Continuous Wave)방식 또는 FSK(Frequency Shift Keying) 방식으 로 구현될 수 있다. 레이더는 전자파를 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브 젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 레이더는, 로봇의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 로봇의 외부의 적절한 위치에 배치될 수 있다. 적외선 센서는, 적외선 송신부, 수신부를 포함할 수 있다. 적외선 센서는, 적외선 광을 기초로 오브젝트를 검출 하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 적외선 센서는, 로봇의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 로봇의 외부의 적절한 위치에 배치될 수 있다. 카메라는, 로봇 외부 영상을 촬영할 수 있다. 카메라는, 영상을 이용하여 로봇 외부의 오브젝트에 대한 정보를 생성할 수 있다. 카메라는 적어도 하나의 렌즈, 적어도 하나의 이미지 센서 및 이미지 센서와 전기적으로 연결되어 수신되는 신호를 처리하고, 처리되는 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적어도 하나의 제어부를 포함할 수 있다. 카메라는, 모노 카메라, 스테레오 카메라 중 적어도 어느 하나일 수 있다. 카메라는, 다양한 영상 처리 알고리즘을 이용하여, 오브젝트의 위치 정보, 오브젝트와의 거리 정보 또는 오브젝 트와의 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 획득된 영상에서, 시간에 따른 오브젝트 크기의 변화를 기초로, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 핀홀(pin hole) 모델, 노면 프로파일링 등을 통해, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 스테레오 카메라에서 획득된 스테레오 영상에서 디스패러티(disparity) 정보를 기초로 오 브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 카메라는, 로봇 외부를 촬영하기 위해 FOV(field of view) 확보가 가능한 위치에 장착될 수 있다. 로봇은, 복수의 카메라를 포함할 수 있다. 예를 들면, 로봇은, 전방 카메라, 후방 카메라, 좌측방 카 메라, 우측방 카메라를 구성된 4채널 카메라를 포함할 수 있다. 환경 센서는, 대상 공간에 대한 오염도를 센싱할 수 있다. 예를 들면, 환경 센서는, 대상 공간에서의 방역 대상 이 되는 생화학적 오염 물질의 유무, 농도 등을 센싱할 수 있다. IMU(Inertial Measurement Unit)는, 로봇의 관성을 측정할 수 있다. IMU는, 가속도계와 회전 속도계, 때 로는 자력계의 조합을 사용하여 로봇의 특정한 힘, 각도 비율 및 때로는 로봇을 둘러싼 자기장을 측 정하는 전자 장치로 설명될 수 있다. 제어부는, IMU로부터 수신되는 데이터에 기초하여 로봇의 자세 에 대한 정보를 생성할 수 있다. IMU는, 가속도 센서, 자이로 센서, 자기 센서 중 적어도 어느 하나를 포함할 수 있다. 인공지능 모듈은, 머신 러닝으로 사물, 공간, 로봇의 속성을 학습할 수 있다. 머신 러닝은 컴퓨터에 게 사람이 직접 로직(Logic)을 지시하지 않아도 데이터를 통해 컴퓨터가 학습을 하고 이를 통해 컴퓨터가 알아 서 문제를 해결하게 하는 것을 의미한다. 딥러닝(Deep Learning)은. 인공지능(artificial intelligence)을 구성하기 위한 인공신경망(Artificial Neural Networks: ANN)에 기반으로 해 컴퓨터에게 사람의 사고방식을 가르치는 방법으로 사람이 가르치지 않아도 컴퓨 터가 스스로 사람처럼 학습할 수 있는 인공지능 기술이다. 상기 인공신경망(ANN)은 소프트웨어 형태로 구현되거나 칩(chip) 등 하드웨어 형태로 구현될 수 있다. 인공지능 모듈은 공간의 속성, 장애물 등 사물의 속성이 학습된 소프트웨어 또는 하드웨어 형태의 인공신 경망(ANN)을 포함할 수 있다. 예를 들어, 인공지능 모듈은 딥러닝(Deep Learning)으로 학습된 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), DBN(Deep Belief Network) 등 심층신경망(Deep Neural Network: DNN)을 포함 할 수 있다. 인공지능 모듈은 상기 심층신경망(DNN)에 포함된 노드들 사이의 가중치(weight)들에 기초하여 입력되는 영 상 데이터에 포함되는 공간, 사물의 속성을 판별할 수 있다. 인공지능 모듈은, 머신 러닝(machine learning)으로 기 학습된 데이터에 기초하여 상기 선택된 특정 시점 영상에 포함되는 공간, 장애물의 속성을 인식할 수 있다. 한편, 메모리에는 공간, 사물 속성 판별을 위한 입력 데이터, 상기 심층신경망(DNN)을 학습하기 위한 데이 터가 저장될 수 있다.메모리에는 카메라가 획득한 원본 영상과 소정 영역이 추출된 추출 영상들이 저장될 수 있다. 또한, 실시예에 따라서는, 메모리에는 상기 심층신경망(DNN) 구조를 이루는 웨이트(weight), 바이어스 (bias)들이 저장될 수 있다. 또는, 실시예에 따라서는, 상기 심층신경망 구조를 이루는 웨이트(weight), 바이어스(bias)들은 인공지능 모듈 의 임베디드 메모리(embedded memory)에 저장될 수 있다. 한편, 인공지능 모듈은 센싱부를 통해 수신한 데이터를 트레이닝(training) 데이터로 사용하여 학습 과정을 수행할 수 있다. 로봇은 통신부를 통하여 상기 소정 서버로부터 머신 러닝과 관련된 데이터를 수신할 수 있다. 이 경 우에, 로봇은, 상기 소정 서버로부터 수신된 머신 러닝과 관련된 데이터에 기초하여 인공지능 모듈을 업데이트(update)할 수 있다. 로봇의 동작으로 획득되는 데이터가 서버로 전송될 수 있다. 로봇은, 서버로 공간(space), 사물 (Object), 사용(Usage) 관련 데이터(Data)를 서버로 전송할 수 있다. 여기서, 공간(space), 사물(Object) 관련 데이터는 로봇이 인식한 공간(space)과 사물(Object)의 인식 관련 데이터이거나, 카메라가 획득한 공간 (space)과 사물(Object)에 대한 이미지 데이터일 수 있다. 또한, 사용(Usage) 관련 데이터(Data)는 소정 제품, 예를 들어, 로봇의 사용에 따라 획득되는 데이터로, 사용 이력 데이터, 센싱부에서 획득된 센싱 데이 터 등이 해당될 수 있다. 한편, 로봇의 인공지능 모듈에는 CNN(Convolutional Neural Network) 등 심층신경망 구조(DNN)가 탑 재될 수 있다. 상기 학습된 심층신경망 구조(DNN)는 인식용 입력 데이터를 입력 받고, 입력 데이터에 포함된 사 물, 공간의 속성을 인식하여, 그 결과를 출력할 수 있다. 또한, 상기 학습된 심층신경망 구조(DNN)는 인식용 입 력 데이터를 입력 받고, 로봇의 사용(Usage) 관련 데이터(Data)를 분석하고 학습하여 사용 패턴, 사용 환 경 등을 인식할 수 있다. 한편, 공간(space), 사물(Object), 사용(Usage) 관련 데이터(Data)는 통신부를 통하여 서버로 전송될 수 있다. 서버는 학습된 웨이트(weight)들의 구성을 생성할 수 있고, 서버는 심층신경망(DNN) 구조를 트레이닝 (training) 데이터를 사용하여 학습할 수 있다. 서버는 수신한 데이터에 기초하여, 심층신경망(DNN)을 학습시킨 후, 업데이트된 심층신경망(DNN) 구조 데이터를 로봇으로 전송하여 업데이트하게 할 수 있다. 이에 따라, 로봇은 점점 더 똑똑해지고, 사용할수록 진화되는 사용자 경험(UX)을 제공할 수 있다. 인공지능 모듈은, 센싱부를 통해 수신한 데이터를 트레이닝 데이터로 사용하여 오브젝트를 검출 동작 의 학습 과정을 수행할 수 있다. 여기서, 오브젝트는, 로봇 주변의 사물, 사람, 구조물 등 로봇의 이 동에 직접적 또는 간접적으로 영향을 주는 객체로 정의할 수 있다. 인공지능 모듈은, 센싱부를 통해 수신한 데이터를 트레이닝 데이터로 사용하여 접객 동작, 방역 동작 또는 학습 동작의 학습 과정을 수행할 수 있다. 인공지능 모듈은, 센싱부를 통해 수신한 데이터를 트레이닝 데이터로 사용하여 스케줄링 동작의 학습 과정을 수행할 수 있다. 인공지능 모듈은, GPU(Graphics Processing Unit)로 구현될 수 있다. GPU로 구현된 인공지능 모듈이 로봇에 물리적으로 인스톨되고 로봇 시스템의 일부가 될 수 있다. 인공지능 모듈이 구현된 GPU는, PCB(printed circuit board)에 실장된 상태로, 로봇의 바디 내부에 배치 되어, 로봇의 다른 구성들과 전기적으로 연결될 수 있다. 특히, 인공지능 모듈은, 제어부와 전 기적으로 연결됨으로써, 신호를 교환하여 로봇의 스마트한 제어가 가능하게 된다. 이경우, 인공지능 모듈 로 인해 로봇의 머신 러닝에 기반한 동작 제어가 가능하게 된다. 인공지능 모듈은, 소프트웨어로 구현되거나, 하드웨어 형태로 구현될 수 있다. 인공지능 모듈이 프로 세서(예를 들면, GPU)로 구현되는 경우, 인공지능 모듈이 구현된 프로세서로 명명될 수 있다. 통신부는, 로봇 외부의 전자 장치(예를 들면, 사용자 단말기, 서버, 다른 이동 로봇, 충전 스테이션 등)와 신호를 교환할 수 있다. 통신부는, 외부의 전자 장치와 데이터를 교환할 수 있다. 통신부는, 통신을 수행하기 위해 송신 안테나, 수신 안테나, 각종 통신 프로토콜이 구현 가능한 RF(Radio Frequency) 회로 및 RF 소자 중 적어도 어느 하나를 포함할 수 있다. 입력부는, 사용자로부터 정보를 입력 받기 위한 것으로, 입력부에서 수집한 데이터는, 제어부에 의해 분석되어, 사용자의 제어 명령으로 처리될 수 있다. 입력부는, 음성 입력부, 터치 입력부를 포함할 수 있다. 실시예에 따라, 제스쳐 입력부 또는 기계식 입력 부를 포함할 수 있다. 음성 입력부는, 사용자의 음성 입력을 전기적 신호로 전환할 수 있다. 전환된 전기적 신호는, 제어부에 제 공될 수 있다. 음성 입력부는, 하나 이상의 마이크로 폰을 포함할 수 있다. 터치 입력부는, 사용자의 터치 입력을 전기적 신호로 전환할 수 있다. 전환된 전기적 신호는 제어부에 제 공될 수 있다. 터치 입력부는, 사용자의 터치 입력을 감지하기 위한 터치 센서를 포함할 수 있다. 실시예에 따라, 터치 입력부는 디스플레이와 일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있다. 이 러한, 터치 스크린은, 로봇과 사용자 사이의 입력 인터페이스 및 출력 인터페이스를 함께 제공할 수 있다. 제스쳐 입력부는, 사용자의 제스쳐 입력을 전기적 신호로 전환할 수 있다. 전환된 전기적 신호는 제어부에 제공될 수 있다. 제스쳐 입력부는, 사용자의 제스쳐 입력을 감지하기 위한 적외선 센서 및 이미지 센서 중 적어도 어느 하나를 포함할 수 있다. 기계식 입력부는, 버튼, 돔 스위치(dome switch), 조그 휠 및 조그 스위치 중 적어도 어느 하나를 포함할 수 있 다. 기계식 입력부에 의해 생성된 전기적 신호는, 제어부에 제공될 수 있다. 메모리는, 제어부와 전기적으로 연결된다. 메모리는 유닛에 대한 기본데이터, 유닛의 동작제어 를 위한 제어데이터, 입출력 되는 데이터를 저장할 수 있다. 메모리는, 제어부에서 처리된 데이터를 저장할 수 있다. 메모리는, 하드웨어적으로, ROM, RAM, EPROM, 플래시 드라이브, 하드 드라이브 중 적어도 어느 하나로 구성될 수 있다. 메모리는 제어부의 처리 또는 제어를 위한 프로그램 등, 로봇 전 반의 동작을 위한 다양한 데이터를 저장할 수 있다. 메모리는, 제어부와 일체형으로 구현될 수 있다. 실시예에 따라, 메모리는, 제어부의 하위 구성으로 분류될 수 있다. 동작부는, 로봇에게 주어진 임무에 적합한 동작을 수행할 수 있다. 동작부는, 접객 동작, 방역 동작, 멸균 동작, 공기청정 동작, 청소 동작 중 적어도 어느 하나의 동작을 수행할 수 있다. 접객 동작은, 대상 공간 내에 있는 사람과 인터렉션 하는 동작일 수 있다. 방역 동작은, 방역 기능은 전염병 발생 또는 유행을 미리 막는 동작으로, 대상 공간 내에서 자율 주행하면서 화 학적 소독 및 물리적 소독 동작 중 적어도 어느 하나를 수행하는 동작일 수 있다. 멸균 동작은, 대상 공간 내에서 자율 주행하면서 멸균을 위한 약액을 분사하는 동작일 수 있다. 공기청정 동작은, 대상 공간 내에서 자율 주행하면서, 대상 공간 내의 공기를 깨끗하게 하는 동작일 수 있다. 청소 동작은, 대상 공간 내에서 자율 주행하면서, 이물질을 빨아들이거나 물걸래로 바닥을 닦는 동작일 수 있다. 동작부는, 상술한 각각의 동작을 수행하기 위한 하드웨어 및 소프트웨어를 구비할 수 있다. 충전부는, 충전 스테이션으로부터 전기 에너지를 공급받을 수 있다. 충전부는. 공급받은 전기 에너지 를 배터리에 저장할 수 있다. 제어부는, 로봇의 각 유닛의 전반적인 동작을 제어할 수 있다. 제어부는 ECU(Electronic Control Unit)로 명명될 수 있다. 제어부는, 로봇의 각 유닛과 전기적으로 연결된다. 제어부는, ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processors), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로프로세서(microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 도 3은 본 발명의 실시예에 따른 로봇용 인공지능 플랫폼 제공 방법의 플로우 차트이다. 도면을 참조하면, 인공지능 모듈은, 데이터를 획득할 수 있다(S310). 여기서, 데이터는, 제1 로봇에 포함 된 센싱부에서 획득된 데이터일 수 있다. 또는, 데이터는, 제1 로봇이 센싱부에서 획득한 데이터로 학습한 데이 터일 수 있다. 인공지능 모듈은, 획득된 데이터를 트레이닝 데이터로 사용하여 기계 학습을 수행할 수 있다(S320). 인공지능 모듈은, 기계 학습의 결과값에 기초하여, 로봇의 적어도 하나의 동작에 관한 예측 모델을 생성할 수 있다(S330). 예측 모델은, 적어도 하나의 인공신경망(ANN)을 활용한 모델일 수 있다. 예측 모델은, 과거의 데이터를 학습하여 산출된 결과물로, 시간과 공간에 대한 인풋값을 입력하면 해당 시간과 공간에 대한 예측 데 이터를 출력하는 모델로 이해될 수 있다. 인공지능 모듈은, GPU(Graphics Processing Unit)로 구현될 수 있다(S340). 이경우, 예측 모델은 GPU로 구현되게 된다. 가령, 인공지능 모듈이 소프트웨어로 구현되는 경우, 소프트웨어를 GPU에 인스톨함으로써 인공지능 모듈이 GPU로 구현될 수 있다. 한편, 실시예에 따라, 인공지능 모듈이 하드웨어로 구현되는 경우, S340 단계는 생략될 수 있다. 인공지능 모듈이 GPU로 구현됨으로써, 분산 처리가 가능하게 되어, 연산의 효율성이 증대된다. 한편, S340 단계에서, 로봇 동작의 종류에 기초하여 GPU 사양이 결정될 수 있다. 인공지능 모듈은, 로봇에 인스톨 될 수 있다(S350). 이경우, 예측 모델은 로봇에 인스톨되게 된 다. 인공지능 모듈이 구현된 GPU가 로봇 내부에 장착되고, 로봇에 포함되는 유닛과 전기적으로 연결됨으로써, 인공지능 모듈은, 로봇에 인스톨될 수 있다. 인공지능 모듈은, 센싱부, 통 신부, 입력부, 메모리, 제어부, 구동부, 동작부, 충전부 중 적어도 어느 하나와 직접적 또는 간접적으로 신호를 교환할 수 있다. 한편, 인공지능 모듈이 인스톨되는 로봇은, S310 단계에서 데이터 획득의 근원이 되는 제1 로봇과 다 른 제2 로봇일 수 있다. S350 단계는, 인공지능 모듈이 로봇의 제어부와 전기적으로 연결되어 신호를 교환하는 단계를 포함할 수 있다. 인공지능 모듈이 로봇에 인스톨된 상태에서, 로봇은, 동작을 수행할 수 있다(S360). 로봇 은, 예측 모델에 기초하여 동작을 수행할 수 있다. 인공지능 모듈은, 예측 모델에 예측 모델에 시간과 영역에 대한 데이터를 입력하여, 해당 시간과 해당 영 역에 대한 유동인구와 오염도에 대한 예측 정보를 생성할 수 있다. 한편, 영역은, 대상 공간을 기 설정된 기준 으로 분할하여 구분된 단위 공간으로 설명될 수 있다. 인공지능 모듈은, 예측 정보에 기초하여, 동작 스케줄을 생성할 수 있다. 인공지능 모듈은, 예측 정 보에 기초하여, 접객 동작, 방역 동작, 멸균 동작, 공기청정 동작, 청소 동작, 충전 동작 중 적어도 어느 하나 의 동작에 대한 스케줄을 생성할 수 있다. 제어부는, 생성된 스케줄에 따라 동작을 수행할 수 있다. 인공지능 모듈은, 센싱부에서 생성된 데이터를 수신할 수 있다(S370). 인공지능 모듈은, 센싱부에서 생성된 데이터에 기초하여, 반복적으로 기계 학습을 수행할 수 있다 (S380). 한편, 인공지능 모듈이 로봇에 인스톨됨으로써, ROS(Robot Operating System), Darknet & YOLO, Cloud와 연관된 연산 처리시, 인공지능 모듈이 활용될 수 있게 된다. 도 4는 본 발명의 실시예에 따른 로봇용 인공지능 플랫폼 제공 방법을 설명하는데 참조되는 도면이다. 도면을 참조하면, 인공지능 모듈을 GPU로 구현하는 경우, GPU의 인스톨 대상 로봇에 따라 GPU의 사양 이 정해질 수 있다. 데이터 처리량이 더 많은 기능을 수행하는 로봇에 프로세싱 파워가 더 큰 GPU가 이용될 수 있다.제1 동작을 수행하는 제1 로봇에는 제1 GPU에 인공지능 모듈이 구현되어 인스톨될 수 있다. 제2 동작 을 수행하는 제2 로봇에는 제2 GPU에 인공지능 모듈(200이 구현되어 인스톨될 수 있다. 제1 동작에 필요한 데이터 처리량은 제2 동작에 필요한 데이터 처리량보다 더 많다. 제1 GPU의 프로세싱 파워는 제2 GPU(42 0)의 프로세싱 파워보다 더 크다. 제1 GPU는, 고사양 GPU로 분류되고 제2 GPU는, 저사양 GPU로 분류 될 수 있다. 로봇에 GPU(410, 42)이 인스톨되어, 제어부와 전기적으로 연결되는 경우, GPU(410, 420)와 제어부 는, 연동되어 로봇을 제어할 수 있게 된다. 도 5는 본 발명의 실시예에 따른 로봇의 충전 동작을 설명하는데 참조되는 도면이다. 도면을 참조하면, 충전 스테이션은, 상용 전원으로부터 전기 에너지를 공급받아 로봇에 제공할 수 있 다. 충전 스테이션은, 상용 전원에 연결된 상태로, 로봇이 도킹되면, 로봇에 전기 에너지를 공 급할 수 있다. 로봇과 충전 스테이션은 로봇 시스템의 하위 개념으로 분류될 수 있다. 통신부는, 충전 스테이션과 신호 교환을 할 수 있다. 제어부는, 배터리의 충전 필요 여부를 판단할 수 있다. 예를 들면, 제어부는, 배터리의 잔존 전기 에 너지 양을 기준으로 배터리의 충전 필요 여부를 판단할 수 있다. 예를 들면, 제어부는, 로봇의 임무 대비 잔존 전기 에너지 양을 기준으로 배터리의 충전 필요 여부를 판단할 수 있다. 제어부는, 로봇의 기능을 수행하기 위한 에너지량보다 배터리에 저장된 에너지량이 적은 경우, 배터리의 충전이 필요하다고 판단 할 수 있다. 제어부는, 배터리의 충전이 필요하다고 판단되는 경우, 통신부를 통해, 충전 스테이션에 충전 대기 신호를 전송할 수 있다. 충전 스테이션은, 충전 대기 신호를 수신하는 경우, 대기 모드로 전환될 수 있다. 대기 모드로 전환되면, 충전 스테이션은, 충전 스테이션의 각 유닛에 전원을 공급하여, 시스템을 웨이크업(wake up) 시킬 수 있다. 제어부는, 배터리의 충전이 필요하다고 판단되는 경우, 충전 스테이션을 향해 로봇이 이동하도 록 구동부를 제어할 수 있다. 제어부는, 로봇과 충전 스테이션 사이의 거리가 기준값 이내인지 판단할 수 있다. 예를 들면, 제어부는, 통신 신호의 세기에 기초하여, 로봇과 충전 스테이션 사이의 거리를 산출하고, 거리 가 기준값 이내인지 판단할 수 있다. 예를 들면, 제어부는, 센싱부에서 생성된 데이터에 기초하여, 로봇과 충전 스테이션 사이의 거리를 산출하고, 거리가 기준값 이내인지 판단할 수 있다. 로봇과 충전 스테이션 사이의 거리가 기준값 이내인 것으로 판단되는 경우, 제어부는, 제1 통신 부를 통해, 충전 스테이션에 충전 준비 신호를 전달할 수 있다. 충전 스테이션은, 충전 준비 신호를 수신하는 경우, 준비 모드로 전환될 수 있다. 준비 모드로 전환되면, 충전 스테이션은, 입체 마커를 돌출시킬 수 있다. 제어부는, 로봇이 충전 스테이션에 도킹되도록 구동부를 제어할 수 있다. 제어부는, 충전 스테이션 대비 로봇의 상대적 위치를 판단할 수 있다. 제어부는, 카메라로부터, 충전 스테이션의 마커를 촬영한 영상 데이터를 수신할 수 있다. 제어부 는, 영상 데이터에서 검출된 입체 마커의 상태에 기초하여, 충전 스테이션 대비 로봇의 상대적 위치 를 판단할 수 있다. 한편, 마커는, 로봇이 충전 스테이션에 도킹하는데 도움을 주기 위한 요소로, 충전 스테이션에 배치된다. 마커는 제1 마커, 제2 마커, 제3 마커를 포함할 수 있다. 제1 마커는, 입체 마커로 명명될 수 있다. 제1 마커는, 제공되는 동력에 따라 직선 운동할 수 있다. 제1 마커는, 제공되는 동력에 의해 제1 높이만큼 충 전 스테이션의 표면에서 돌출될 수 있다. 제1 마커는, 제공되는 동력에 의해 수납될 수 있다. 돌출된 상태의 제1 마커는, 위에서 볼 때, 센터라인 상에 위치할 수 있다. 제2 마커는, 제1 마커와 제1 방향으 로 제1 거리만큼 이격된다. 제3 마커는, 제1 마커와 제1 방향과 반대 방향인 제2 방향으로 제1 거리만큼 이격된 다.제어부는, 수신된 영상 데이터에서, 제1 마커 이미지, 제2 마커 이미지 및 제3 마커 이미지를 검출할 수 있다. 제1 마커 이미지가 제2 마커 이미지에 더 근접하거나, 제3 마커 이미지에 더 근접한 경우, 제어부는, 로봇 이 센터 라인에 위치하지 않는 것으로 판단할 수 있다. 제1 마커 이미지가 제2 마커 이미지 및 제3 마커 이미지의 가운데에 위치한 경우, 제어부는, 로봇이 센터 라인에 위치한 것으로 판단할 수 있다. 여기서, 가운데는, 수학적으로 정확한 중심을 의미하지 않고, 작은 수치의 오차를 반영하여, 좌측과 우측으로 소정의 배리언스(variance)를 두는 정도까지 의미한다. 한편, 센터 라인은, 위에서 볼때 바닥에서 제2 마커와 제3 마커의 사이의 중심을 가르면서 충전 스테이션의 적어도 하나의 모서리에 직각되게 형성된 가상의 선으로 정의할 수 있다. 로봇이 센터 라인에 위치하는 것으로 판단되는 경우, 제어부는, 로봇이 충전 스테이션을 향해 직선 이동하도록 구동부를 제어할 수 있다. 제어부는, 로봇의 직선 이동을 통해, 도킹을 시도할 수 있다. 제어부는, 로봇이 충전 스테이션에 도킹 완료 되었는지 판단할 수 있다. 예를 들면, 충전 스테이션은, 준비 모드 상태에서, 충전 스테이션의 충전 단자에 상대적으로 약한 전 류를 유입시킬 수 있다. 제어부는, 충전부의 충전 단자 약한 전류가 유입되는 것이 감지되는 경우, 로봇이 충전 스테이션에 도킹 완료된 것으로 판단할 수 있다. 이를 위해, 충전부는, 전류 감지 기를 포함할 수 있다. 예를 들면, 제어부는, 로봇의 중심이 센터 라인위에 위치하고, 센싱부에서 생성되는 센싱 데이 터에 기초하여 산출된 로봇과 충전 스테이션 사이의 거리가 기 설정 범위 내에 있는 경우, 로봇(10 0)이 충전 스테이션에 도킹 완료된 것으로 판단할 수 있다. 예를 들면, 충전 스테이션은, 로봇이 입체 마커에 접촉하였는지 판단할 수 있다. 로봇이 센터 라인을 따라 충전 스테이션을 향해 직선 이동하면서, 입체 마커에 접촉하면, 입체 마커는, 로봇의 이 동 방향으로 약간의 직선 운동을 한다. 입체 마커의 의도되지 않은 직선 운동이 감지되면, 충전 스테이션 은, 로봇이 충전 스테이션에 도킹 완료된 것으로 판단할 수 있다. 충전 스테이션은, 로봇 에 도킹 완료 상태 정보를 전송할 수 있다. 제어부는, 충전 스테이션에서 수신된 정보에 기초하여, 로봇이 충전 스테이션에 도킹 완료된 것으로 판단할 수 있다. 로봇이 충전 스테이션에 도킹된 것으로 판단되는 경우, 제어부는, 충전 스테이션에 충전 요청 신호를 전달할 수 있다. 제어부는, 로봇과 충전 스테이션 사이의 도킹 여부에 따라, 릴레이의 온(on) 오프(off)를 제어 할 수 있다. 예를 들면, 로봇이 충전 스테이션에 도킹 완료되는 경우, 로봇은 충전 모드로 전환 될 수 있다. 충전 모드로 전환되는 경우, 제어부는, 릴레이를 온(on) 상태로 전환할 수 있다. 로봇이 충전 스테이션에 도킹 완료되는 경우, 충전 스테이션은 충전 모드로 전환될 수 있다. 충전 모드에서 충전 스테이션은, 로봇의 충전부에 전원을 인가하고, 충전 시작 신호를 로봇 에 전송할 수 있다. 제어부는, 충전 스테이션에서 제공되는 전기 에너지로 배터리를 충전할 수 있다. 제어부는, 배터리의 충전이 완료된 것으로 판단되는 경우, 충전 완료 신호를 충전 스테이션에 전달할 수 있다. 충전 완료 신호가 수신되는 경우, 충전 스테이션은, 전기에너지 공급을 중단할 수 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 상기 컴 퓨터는 프로세서 또는 제어부를 포함할 수도 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석 되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2022-0021021", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 로봇의 외관을 도시한 도면이다. 도 2는 본 발명의 실시예에 따른 로봇의 제어 블럭도이다. 도 3은 본 발명의 실시예에 따른 로봇용 인공지능 플랫폼 제공 방법의 플로우 차트이다. 도 4는 본 발명의 실시예에 따른 로봇용 인공지능 플랫폼 제공 방법을 설명하는데 참조되는 도면이다. 도 5는 본 발명의 실시예에 따른 로봇의 충전 동작을 설명하는데 참조되는 도면이다."}
