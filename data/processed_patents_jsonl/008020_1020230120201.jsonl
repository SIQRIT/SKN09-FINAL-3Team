{"patent_id": "10-2023-0120201", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0037867", "출원번호": "10-2023-0120201", "발명의 명칭": "이미지 편집을 위한 사용자 단말, 서버 및 그 동작 방법", "출원인": "이상호", "발명자": "이상호"}}
{"patent_id": "10-2023-0120201", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이미지 및 텍스트 입출력을 위한 인터페이스부;하나 이상의 인공 신경망을 포함하는 서버와 통신을 수행하는 통신부; 및상기 인터페이스부 및 상기 통신부를 제어하는 제어부를 포함하며,상기 제어부는사용자로부터 편집을 수행할 원본 입력 이미지 및 편집에 대한 정보를 포함하는 텍스트 프롬프트를 수신하여 입력된 텍스트 프롬프트에 따라 입력된 이미지를 편집하도록 학습된 제 1 인공 신경망을 포함하는 서버로 전송하며,상기 서버로부터 상기 원본 입력 이미지를 기초로 사용자 맞춤 학습된 상기 제 1 인공 신경망이 상기 텍스트 프롬프트에 따라 편집한 상기 원본 입력 이미지에 대한 출력 이미지를 수신하여 상기 인터페이스부를 통해 출력하는, 사용자 단말."}
{"patent_id": "10-2023-0120201", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 제 1 인공 신경망은사람이 포함된 사진 이미지와 노이즈를 합성하여 생성한 합성 이미지 및 텍스트 데이터를 입력 받아 상기 사진이미지에 대응하는 출력 이미지를 생성하도록 사전 학습되어 있으며,상기 원본 입력 이미지 및 상기 원본 입력 이미지에 대한 하나 이상의 관련 이미지 각각에 대한 합성 이미지와상기 원본 입력 이미지 및 상기 하나 이상의 관련 이미지 각각에 대한 텍스트 데이터를 이용하여 제 1 차 사용자 맞춤 학습을 수행하는, 사용자 단말."}
{"patent_id": "10-2023-0120201", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 텍스트 데이터는 사진 이미지에 포함된 사람의 아이덴티티를 확인할 수 있는 하나 이상의 요소 중 적어도 하나에 대한 정보를 포함하는, 사용자 단말."}
{"patent_id": "10-2023-0120201", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서,하나 이상의 관련 이미지는 상기 인터페이스부를 통해 사용자로부터 입력 받은 이미지 및 상기 원본 입력 이미지를 기초로 데이터 베이스로부터 추출된 이미지 중 적어도 하나인, 사용자 단말."}
{"patent_id": "10-2023-0120201", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,공개특허 10-2025-0037867-3-상기 제 1 인공 신경망은상기 제 1 차 사용자 맞춤 학습이 완료된 후 상기 원본 입력 이미지에 대한 합성 이미지 및 상기 원본 이미지에대한 텍스트 데이터를 기초로 제 2 차 사용자 맞춤 학습을 수행하는, 사용자 단말."}
{"patent_id": "10-2023-0120201", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 제어부는상기 서버로부터 상기 제 2 차 사용자 맞춤 학습이 완료된 제 1 인공 신경망에 상기 원본 입력 이미지와 상기텍스트 프롬프트를 입력하여 상기 텍스트 프롬프트에 따라 편집한 상기 원본 입력 이미지에 대한 출력 이미지를수신하는, 사용자 단말."}
{"patent_id": "10-2023-0120201", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "사용자 단말과 통신을 수행하기 위한 통신부;사람이 포함된 사진 이미지와 노이즈를 합성하여 생성한 합성 이미지 및 텍스트 데이터를 입력 받아 상기 사진이미지에 대응하는 출력 이미지를 생성하도록 학습된 제 1 인공 신경망; 및상기 통신부 및 상기 제 1 인공 신경망의 사용자 맞춤 학습 및 운영을 제어하는 제어부를 포함하며,상기 제어부는사용자 단말로부터 이미지 편집을 수행할 원본 입력 이미지 및 이미지 편집 요청 사항을 포함하는 텍스트 프롬프트를 수신하며,상기 원본 입력 이미지를 기초로 상기 제 1 인공 신경망에 사용자 맞춤 학습을 수행하며, 사용자 맞춤 학습된 제 1 인공 신경망에 상기 원본 입력 이미지 및 상기 텍스트 프롬프트를 입력하여 생성된 상기 원본 입력 이미지를 편집한 출력 이미지를 상기 사용자 단말로 전송하는, 서버."}
{"patent_id": "10-2023-0120201", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 제어부는상기 원본 입력 이미지 및 상기 원본 입력 이미지에 대한 하나 이상의 관련 이미지를 노이즈와 각각 합성하여하나 이상의 합성 이미지를 생성하며, 상기 하나 이상의 합성 이미지, 및 상기 원본 입력 이미지 및 상기 하나이상의 관련 이미지 각각에 대한 텍스트 데이터를 상기 제 1 인공 신경망에 입력하여 상기 제 1 인공 신경망에대한 제 1 차 사용자 맞춤 학습을 수행하는, 서버."}
{"patent_id": "10-2023-0120201", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 제어부는상기 원본 입력 이미지에 노이즈를 합성하여 생성한 합성 이미지 및 상기 합성 이미지에 대한 텍스트 데이터를제 1 차 사용자 맞춤 학습된 제 1 인공 신경망에 입력하여 상기 제 1 인공 신경망에 대한 제 2 차 사용자 맞춤학습을 수행하는, 서버.공개특허 10-2025-0037867-4-청구항 10 제 9 항에 있어서,상기 제어부는 상기 원본 입력 이미지 및 상기 텍스트 프롬프트를 제 2 차 사용자 맞춤 학습된 제 1 인공 신경망에 입력하여상기 원본 입력 이미지를 상기 텍스트 프롬프트에 따라 편집한 출력 이미지를 생성하여 상기 사용자 단말로 전송하는, 서버."}
{"patent_id": "10-2023-0120201", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사전 학습된 인공 신경망에 사용자 맞춤 학습을 수행하여 원본 이미지의 아이덴티티를 보존하며 편집할 수 있는 사용자 단말, 서버 및 그 동작 방법이 개시된다. 일 실시예에 따른 사용자 단말은 이미지 및 텍스트 입출력을 위 한 인터페이스부; 하나 이상의 인공 신경망을 포함하는 서버와 통신을 수행하는 통신부; 및 인터페이스부 및 통 신부를 제어하는 제어부를 포함하며, 제어부는 사용자로부터 편집을 수행할 원본 입력 이미지 및 편집에 대한 정 보를 포함하는 텍스트 프롬프트를 수신하여 입력된 텍스트 프롬프트에 따라 입력된 이미지를 편집하도록 학습된 제 1 인공 신경망을 포함하는 서버로 전송하며, 서버로부터 원본 입력 이미지를 기초로 사용자 맞춤 학습된 제 1 인공 신경망이 텍스트 프롬프트에 따라 편집한 원본 입력 이미지에 대한 출력 이미지를 수신하여 인터페이스부를 통해 출력할 수 있다."}
{"patent_id": "10-2023-0120201", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이미지 편집을 위한 기술로서 특히, 사전 학습된 인공 신경망에 사용자 맞춤 학습을 수행하여 원본 이미지의 아 이덴티티를 보존하며 편집할 수 있는 사용자 단말, 서버 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2023-0120201", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능을 이용한 다양한 이미지 편집 기술이 연구되고 있다. 그 중 프롬프트(Prompt)를 통해 사전 학습 된 확산 모델(diffusion model)이 있다. 확산 모델은 데이터를 만들어내는 생성 모델(generative model) 중 하 나로 데이터에 노이즈(noise)를 조금씩 더해가면서 데이터를 완전한 노이즈로 만드는 정방향 프로세스(forward process) 또는 확산 프로세스(diffusion process)와 이와 반대로 잡음으로부터 조금씩 복원해가면서 데이터를 만들어내는 역방향 프로세스(reverse process)를 수행한다. 그러나, 현재 개발된 생성형 인공지능 기술을 활용 한 이미지의 생성 및 편집 기술은 원본의 이미지를 편집시 원본의 아이덴티티를 충분히 보존하지 못하는 문제가 있다. 대한민국 공개특허 10-2023-0017298는 얼굴 표정 편집 방법 및 전자 디바이스가 제공하고 있다."}
{"patent_id": "10-2023-0120201", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "사전 학습된 인공 신경망에 사용자 맞춤 학습을 수행하여 원본 이미지의 아이덴티티를 보존하며 편집할 수 있는 사용자 단말, 서버 및 그 동작 방법을 제공하는데 목적이 있다."}
{"patent_id": "10-2023-0120201", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 양상에 따르면, 사용자 단말은 이미지 및 텍스트 입출력을 위한 인터페이스부; 하나 이상의 인공 신경망을 포함하는 서버와 통신을 수행하는 통신부; 및 인터페이스부 및 통신부를 제어하는 제어부를 포함하며, 제어부는 사용자로부터 편집을 수행할 원본 입력 이미지 및 편집에 대한 정보를 포함하는 텍스트 프롬프트를 수신하여 입 력된 텍스트 프롬프트에 따라 입력된 이미지를 편집하도록 학습된 제 1 인공 신경망을 포함하는 서버로 전송하 며, 서버로부터 원본 입력 이미지를 기초로 사용자 맞춤 학습된 제 1 인공 신경망이 텍스트 프롬프트에 따라 편 집한 원본 입력 이미지에 대한 출력 이미지를 수신하여 인터페이스부를 통해 출력할 수 있다. 제 1 인공 신경망은 사람이 포함된 사진 이미지와 노이즈를 합성하여 생성한 합성 이미지 및 텍스트 데이터를 입력 받아 사진 이미지에 대응하는 출력 이미지를 생성하도록 사전 학습되어 있으며, 원본 입력 이미지 및 원본 입력 이미지에 대한 하나 이상의 관련 이미지 각각에 대한 합성 이미지와 원본 입력 이미지 및 하나 이상의 관 련 이미지 각각에 대한 텍스트 데이터를 이용하여 제 1 차 사용자 맞춤 학습을 수행할 수 있다. 텍스트 데이터는 사진 이미지에 포함된 사람의 아이덴티티를 확인할 수 있는 하나 이상의 요소 중 적어도 하나 에 대한 정보를 포함할 수 있다. 하나 이상의 관련 이미지는 인터페이스부를 통해 사용자로부터 입력 받은 이미지 및 원본 입력 이미지를 기초로 데이터 베이스로부터 추출된 이미지 중 적어도 하나일 수 있다. 제 1 인공 신경망은 제 1 차 사용자 맞춤 학습이 완료된 후 원본 입력 이미지에 대한 합성 이미지 및 원본 이미 지에 대한 텍스트 데이터를 기초로 제 2 차 사용자 맞춤 학습을 수행할 수 있다.제어부는 서버로부터 제 2 차 사용자 맞춤 학습이 완료된 제 1 인공 신경망에 원본 입력 이미지와 텍스트 프롬 프트를 입력하여 텍스트 프롬프트에 따라 편집한 원본 입력 이미지에 대한 출력 이미지를 수신할 수 있다. 일 양상에 따르면, 서버는 사용자 단말과 통신을 수행하기 위한 통신부; 사람이 포함된 사진 이미지와 노이즈를 합성하여 생성한 합성 이미지 및 텍스트 데이터를 입력 받아 사진 이미지에 대응하는 출력 이미지를 생성하도록 학습된 제 1 인공 신경망; 및 통신부 및 제 1 인공 신경망의 사용자 맞춤 학습 및 운영을 제어하는 제어부를 포 함하며, 제어부는 사용자 단말로부터 이미지 편집을 수행할 원본 입력 이미지 및 이미지 편집 요청 사항을 포함 하는 텍스트 프롬프트를 수신하며, 원본 입력 이미지를 기초로 제 1 인공 신경망에 사용자 맞춤 학습을 수행하 며, 사용자 맞춤 학습된 제 1 인공 신경망에 원본 입력 이미지 및 텍스트 프롬프트를 입력하여 생성된 원본 입 력 이미지를 편집한 출력 이미지를 사용자 단말로 전송할 수 있다. 제어부는 원본 입력 이미지 및 원본 입력 이미지에 대한 하나 이상의 관련 이미지를 노이즈와 각각 합성하여 하 나 이상의 합성 이미지를 생성하며, 하나 이상의 합성 이미지, 및 원본 입력 이미지 및 하나 이상의 관련 이미 지 각각에 대한 텍스트 데이터를 제 1 인공 신경망에 입력하여 제 1 인공 신경망에 대한 제 1 차 사용자 맞춤 학습을 수행할 수 있다. 제어부는 원본 입력 이미지에 노이즈를 합성하여 생성한 합성 이미지 및 합성 이미지에 대한 텍스트 데이터를 제 1 차 사용자 맞춤 학습된 제 1 인공 신경망에 입력하여 제 1 인공 신경망에 대한 제 2 차 사용자 맞춤 학습 을 수행할 수 있다. 제어부는 원본 입력 이미지 및 텍스트 프롬프트를 제 2 차 사용자 맞춤 학습된 제 1 인공 신경망에 입력하여 원 본 입력 이미지를 텍스트 프롬프트에 따라 편집한 출력 이미지를 생성하여 사용자 단말로 전송할 수 있다."}
{"patent_id": "10-2023-0120201", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "사전 학습된 인공 신경망에 사용자 맞춤 학습을 수행하여 원본 이미지의 아이덴티티를 보존하며 이미지를 편집 할 수 있다."}
{"patent_id": "10-2023-0120201", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 일 실시예를 상세하게 설명한다. 본 발명을 설명함에 있어 관련된 공 지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 또한, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이 는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로, 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 이하, 이미지 편집을 위한 사용자 단말, 서버 및 그 동작 방법의 실시예들을 도면들을 참고하여 자세히 설명한 다. 도 1은 일 실시예에 따른 이미지 편집이 수행되는 환경을 설명하기 위한 예시도이다. 도 1을 참조하면, 이미지 편집을 위한 시스템은 사용자 단말 및 서버를 포함할 수 있다. 일 예에 따르면, 사용자 단말은 인터페이스를 통해 사용자로부터 이미지 편집에 대한 요청 및 데이터를 수 신할 수 있으며, 편집된 이미지를 출력할 수 있다. 또한, 사용자 단말은 서버와 통신을 수행할 수 있으며,사용자로부터 수신한 이미지 및 텍스트 프롬프트를 서버로 전달할 수 있다. 사용자 단말은 서버에서 편집 된 이미지를 수신할 수 있으며, 수신한 이미지를 인터페이스를 통해 사용자에게 출력할 수 있다. 일 예에 따르면, 서버는 사용자 단말과 유선 또는 무선 네트워크를 통해 통신을 수행할 수 있다. 서 버는 하나 이상의 인공 신경망을 포함하며, 인공 신경망을 학습 및 제어할 수 있는 제어부를 포함할 수 있 다. 서버는 사용자 단말로부터 수신한 이미지 및 텍스트 프롬프트를 이용하여 인공 신경망에 사용자 맞춤 학습을 수행할 수 있으며, 사용자 맞춤 학습이 된 인공 신경망을 이용하여 이미지를 편집할 수 있다. 일 예에 따르면, 사용자 단말 및 서버에서 이미지를 편집하기 위해 제공되는 기능은 아래에서 설명하 는 실시예와 같이 구분될 수 있다. 그러나, 아래의 실시예는 해당 기능이 수행되는 장치를 한정하는 것이 아니 며, 각각의 기능은 구현 방식에 따라 사용자 단말 및 서버 중 적어도 하나에서 수행될 수 있다. 다시 말해, 사용자 단말에서 수행되는 기능의 일부 또는 전부가 서버에서 수행되거나, 서버 에서 수 행되는 기능의 일부 또는 전부가 사용자 단말에서 수행될 수 있다. 도 2는 일 실시예에 따른 사용자 단말의 구성도이다. 도 2를 참조하면, 사용자 단말은 이미지 및 텍스트 입출력을 위한 인터페이스부, 하나 이상의 인공 신경망을 포함하는 서버와 통신을 수행하는 통신부 및 인터페이스부 및 통신부를 제어하는 제어 부를 포함할 수 있다. 일 예에 따르면, 인터페이스부는 데이터 입출력을 위한 키보드, 마우스, 모니터, 터치스크린, 마이크 및 카메라 중 적어도 하나일 수 있다. 일 예로, 사용자는 인터페이스부를 통해 사진을 촬영하거나 사용자 단 말에 저장되어 있는 사진을 선택할 수 있다. 또한, 사용자는 인터페이스부를 이미지 편집을 위한 텍 스트 데이터 또는 음성 데이터를 입력할 수 있다. 도 3을 참조하면, 인터페이스부는 사용자로부터 편집할 이미지를 입력 받을 수 있으며, 입력된 이미지 를 출력할 수 있다. 또한, 사용자는 인터페이스부를 통해 편집에 대한 정보를 입력할 수 있다. 예를 들어, '머리 색상을 검은색으로 바꿔줘'와 같은 편집 정보를 텍스트 또는 음성으로 입력할 수 있다. 인터페이스 부는 입력된 편집 정보를 텍스트로 출력하여 사용자에게 제공할 수 있다. 일 예로, 사용자는 인터페이스부를 통해 편집에 이용할 수 있는 추가적인 이미지를 입력할 수 있다. 사용자 단말은 사용자로부터 수신한 추가적인 이미지를 서버에 전송할 수 있으며, 서버는 사용자가 입력한 추가적인 이미지를 이용하여 인공 신경망에 사용자 맞춤 학습을 수행할 수 있다. 일 예에 따르며, 사용자 단말은 서버로부터 편집된 이미지를 수신할 수 있으며, 인터페이스부를 통해 편집된 이미지를 출력할 수 있다. 또한, 사용자 단말은 서버가 분석한 원본 이미지에 포함 된 사람의 아이덴티티를 확인할 수 있는 하나 이상의 요소 중 적어도 하나에 대한 정보를 수신하여 인터페 이스부를 통해 출력할 수 있다. 예를 들어, 사용자가 편집을 요청한 이미지에 대한 아이덴티티를 확 인할 수 있는 하나 이상의 요소에 대한 정보로 '20~30대, 여성, 분홍색 입술, 배경 없음, 짧은 머리'와 같은 분 석 결과를 출력할 수 있다. 일 예로, 사람의 아이덴티티를 확인할 수 있는 요소는 성별, 나이, 인종, 피부색, 머리카락색, 표정 및 안경 착용 여부 중 적어도 하나일 수 있다. 일 예에 따르면, 도 3의 인터페이스부에 표시된 이미지 및 텍스트 데이터는 예시적인 것이다. 따라서, 표 시된 이미지 및 텍스트 데이터는 일부만 표시될 수도 있으며, 편집 과정에 따라 인터페이스부를 통해 출력 되는 이미지 또는 텍스트 데이터가 달라질 수 있다. 예를 들어, 이미지 편집 초기 단계에서는 원본 이미지 및 텍스트 프롬프트가 출력되며, 편집이 완료된 후에는 편집된 이미지가 출력될 수 있다. 일 실시예에 따르면, 제어부는 사용자로부터 편집을 수행할 원본 입력 이미지 및 편집에 대한 정보를 포함 하는 텍스트 프롬프트를 수신하여 입력된 텍스트 프롬프트에 따라 입력된 이미지를 편집하도록 학습된 제 1 인 공 신경망을 포함하는 서버로 전송할 수 있다. 일 예로, 원본 입력 이미지는 사람의 얼굴이 포함된 사진, 그림 및 일러스트 중 적어도 하나에 대한 이미지일 수 있으며, 이미지, 사진 이미지 등의 용어로 표현될 수 있다. 도 3을 참조하면, 제어부는 인터페이스부를 통해 사용자로부터 편집을 수행할 원본 입력 이미지 및 편집에 대한 정보를 포함하는 텍스트 프롬프트를 수신할 수 있다. 이후, 제어부는 통신부를 통하여 수신한 원본 입력 이미지 및 텍스트 프롬프트를 서버로 전송할 수 있다. 일 실시예에 따르면, 제어부는 서버로부터 원본 입력 이미지를 기초로 사용자 맞춤 학습된 제 1 인공 신경망이 텍스트 프롬프트에 따라 편집한 원본 입력 이미지에 대한 출력 이미지를 수신하여 인터페이스부를 통해 출력할 수 있다. 일 예로, 제어부는 통신부를 통해 편집된 출력 이미지를 수신할 수 있으며, 인터페이스부를 통 해 수신한 출력 이미지를 출력할 수 있다. 일 실시예에 따르면, 이미지 편집을 수행하는 제 1 인공 신경망은 사람이 포함된 사진 이미지와 노이즈를 합성 하여 생성한 합성 이미지 및 텍스트 데이터를 입력 받아 사진 이미지에 대응하는 출력 이미지를 생성하도록 사 전 학습되어 있을 수 있다. 일 예로, 제 1 인공 신경망은 확산 모델(Diffusion model)일 수 있다. 예를 들어, 확산 모델은 데이터를 만들어 내는 생성 모델(generative model) 중 하나로 데이터에 노이즈(noise)를 조금씩 더해가면서 데이터를 완전한 노 이즈로 만드는 정방향 프로세스(forward process) 또는 확산 프로세스(diffusion process)와 이와 반대로 잡음 으로부터 조금씩 복원해가면서 데이터를 만들어내는 역방향 프로세스(reverse process)를 수행한다. 일 실시예에 따르면, 제 1 인공 신경망은 원본 입력 이미지 및 원본 입력 이미지에 대한 하나 이상의 관련 이미 지 각각에 대한 합성 이미지와 원본 입력 이미지 및 하나 이상의 관련 이미지 각각에 대한 텍스트 데이터를 이 용하여 제 1 차 사용자 맞춤 학습을 수행할 수 있다. 일 예로, 제 1 인공 신경망은 합성 이미지와 합성 이미지에 대한 텍스트 데이터를 입력 받을 수 있으며, 입력된 합성 이미지와 텍스트 데이터를 기초로 사진 이미지를 복원할 수 있다. 이후, 제어부는 입력된 합성 이미 지에 사용된 사진 이미지와 출력 이미지의 차이를 기초로 손실함수를 계산할 수 있으며, 손실함수 값이 소정 범 위로 수렴할 때까지 제 1 차 사용자 맞춤 학습을 반복하여 수행할 수 있다. 일 실시예에 따르면, 텍스트 데이터는 사진 이미지에 포함된 사람의 아이덴티티를 확인할 수 있는 하나 이상의 요소 중 적어도 하나에 대한 정보를 포함할 수 있다. 일 예로, 사람의 아이덴티티를 확인할 수 있는 요소는 성 별, 나이, 인종, 피부색, 머리카락색, 표정 및 안경 착용 여부 중 적어도 하나일 수 있다. 예를 들어, 원본 입 력 이미지를 이용하여 사용자 맞춤 학습을 수행 시에는 텍스트 프롬프트가 아닌 원본 입력 이미지 대한 텍스트 데이터가 이용된다. 따라서, 텍스트 프롬프트와 텍스트 데이터는 다를 수 있다. 일 실시예에 따르면, 하나 이상의 관련 이미지는 인터페이스부를 통해 사용자로부터 입력 받은 이미지 및 원본 입력 이미지를 기초로 데이터 베이스로부터 추출된 이미지 중 적어도 하나일 수 있다. 일 예로, 도 3에서와 같 이, 제어부는 사용자로부터 원본 입력 이미지와 관련된 사진을 입력할 수 있다. 이때 입력한 사진은 원본 입력 이미지에 포함된 사람과 동일인에 대한 사진일 수 있다. 일 예로, 관련 이미지는 서버에서 원본 입력 이미지를 기초로 데이터 베이스를 검색한 이미지일 수 있다. 예를 들어, 서버는 원본 입력 이미지를 분석하여 키워드를 추출할 수 있으며, 추출된 키워드를 이용하여 이미지를 검 색 후 원본 입력 이미지와 소정 기준의 유사도를 가지는 이미지를 추출하여 관련 이미지로 이용할 수 있다. 일 예를 들어, 데이터 베이스는 서버 내부 또는 외부에 구비된 저장 장치일 수 있다. 다른 예로, 데이터 베이스 는 서버와 연결된 하나 이상의 사용자 단말에 포함된 저장 장치일 수 있다. 이 경우, 서버는 사용자 단말의 사 용자가 이용을 동의한 이미지 또는 접근을 동의한 저장 장치에 포함된 이미지를 검색할 수 있다. 일 예로, 서버는 사용자가 입력한 관련 이미지와 데이터 베이스에서 검색한 이미지를 모두 사용할 수 있다. 예 를 들어, 서버가 사용자 단말로부터 수신한 관련 이미지의 개수가 소정 개수 이하인 경우 데이터 베이스를 검색 하여 관련 이미지를 추가할 수 있다. 또 다른 예로, 서버는 사용자가 입력한 텍스트 프롬프트를 분석하여 사용 자가 입력한 관련 이미지 중 텍스트 프롬프트와 관련된 이미지가 없거나 소정 개수 이하인 경우 데이터 베이스 를 검색하여 관련 이미지를 추가할 수 있다. 예를 들어, 사용자가 '웃는 모습'으로 편집할 것을 요청하였지만, 사용자가 입력한 관련 이미지에 웃는 모습과 관련된 이미지가 없는 경우, 서버는 데이터 베이스를 검색하여 웃 는 모습과 관련된 이미지를 검색하여 관련 이미지를 생성할 수 있다. 일 실시예에 따르면, 제 1 인공 신경망은 제 1 차 사용자 맞춤 학습이 완료된 후 원본 입력 이미지에 대한 합성 이미지 및 원본 이미지에 대한 텍스트 데이터를 기초로 제 2 차 사용자 맞춤 학습을 수행할 수 있다. 일 예로, 제 1 차 사용자 맞춤 학습은 원본 입력 이미지와 관련 이미지를 이용하여 제 1 인공 신경망을 학습하는 것인 반 면, 제 2 차 사용자 맞춤 학습은 원본 입력 이미지만을 이용하여 사용자 맞춤 학습을 추가적으로 수행하는 것이다. 일 실시예에 따르면, 제어부는 서버로부터 제 2 차 사용자 맞춤 학습이 완료된 제 1 인공 신경망에 원본 입력 이미지와 텍스트 프롬프트를 입력하여 텍스트 프롬프트에 따라 편집한 원본 입력 이미지에 대한 출력이미지를 수신할 수 있다. 즉, 제어부는 사전 학습된 제 1 인공 신경망이 아닌, 2 단계로 사용자 맞춤 학 습이 완료된 제 1 인공 신경망을 통해 편집된 이미지를 수신하여 사용자에게 제공할 수 있다. 도 2 및 도 3에 대한 실시예는 사용자 단말의 동작에 대한 부분이며, 서버와 관련된 구체적은 동작은 이후 실시예를 통해 설명한다. 이에 따라, 아래에서 설명하는 서버에 대한 실시예는 사용자 단말과 동작하는 서 버에 대한 내용으로 해석될 수 있다. 일 예로, 아래에서 설명하는 서버의 기능 중 일부는 사용자 단말을 통해 구현될 수 있다. 도 4는 일 실시예에 따른 서버의 구성도이다. 도 4를 참조하면, 서버는 사용자 단말과 통신을 수행하기 위한 통신부, 사람이 포함된 사진 이미지와 노이 즈를 합성하여 생성한 합성 이미지 및 텍스트 데이터를 입력 받아 사진 이미지에 대응하는 출력 이미지를 생성 하도록 학습된 제 1 인공 신경망 및 통신부 및 제 1 인공 신경망의 사용자 맞춤 학습 및 운영을 제어하는 제어부를 포함할 수 있다. 이하의 실시예 중 사용자 단말에 대한 실시예와 중복되는 내용은 생략 하였으나 동일하게 적용 가능하다. 일 실시예에 따르면, 제어부는 사용자 단말로부터 이미지 편집을 수행할 원본 입력 이미지 및 이미지 편집 요청 사항을 포함하는 텍스트 프롬프트를 수신할 수 있다. 이후, 제어부는 원본 입력 이미지를 기초로 제 1 인공 신경망에 사용자 맞춤 학습을 수행할 수 있다. 일 예로, 인공 신경망은 프로세서에 의해 제어될 수 있으며, 인공 신경망은 각각은 컴퓨팅 장치의 메모리에 소 프트웨어 형태로 저장되거나 또는 하드웨어적인 회로 형태로 구현될 수 있다. 또한, 인공 신경망은 소프트웨어 및 하드웨어가 결합한 형태로 구현될 수도 있다. 일 실시예에 따르면, 제 1 인공 신경망은 사람이 포함된 사진 이미지와 노이즈를 합성하여 생성한 합성 이 미지 및 텍스트 데이터를 입력 받아 사진 이미지에 대응하는 출력 이미지를 생성하도록 학습된 것일 수 있다. 일 예로, 제 1 인공 신경망은 확산 모델(Diffusion model)일 수 있다. 예를 들어, 확산 모델은 데이터를 만들어내는 생성 모델(generative model) 중 하나로 데이터에 노이즈(noise)를 조금씩 더해가면서 데이터를 완 전한 노이즈로 만드는 정방향 프로세스(forward process) 또는 확산 프로세스(diffusion process)와 이와 반대 로 잡음으로부터 조금씩 복원해가면서 데이터를 만들어내는 역방향 프로세스(reverse process)를 수행한다. 일 실시예에 따르면, 제어부는 제 1 인공 신경망의 사용자 맞춤 학습 및 운영을 제어할 수 있다. 예 를 들어, 제어부는 사전 학습된 제 1 인공 신경망을 사용자의 요청에 맞추어 사용자 맞춤 학습을 추 가적으로 수행할 수 있다. 일 실시예에 따르면, 제어부는 사용자로부터 이미지 편집을 수행할 원본 입력 이미지 및 이미지 편집 요청 사항을 포함하는 텍스트 프롬프트를 수신할 수 있다. 제어부는 수신한 원본 입력 이미지를 기초로 제 1 인 공 신경망에 사용자 맞춤 학습을 수행하며, 사용자 맞춤 학습된 제 1 인공 신경망에 원본 입력 이미지 및 텍스 트 프롬프트를 입력하여 원본 입력 이미지를 편집한 출력 이미지를 생성할 수 있다. 예를 들어, 제어부는 사용자로부터 사람 얼굴이 포함된 사진 이미지와 함께 '웃는 얼굴로 바꿔줘'와 같이 사진 이미지의 편집을 요청하는 텍스트 프롬프트를 입력 받을 수 있다. 이러한 경우, 제어부는 입력 받은 사진 이미지를 기초로 제 1 인공 신경망에 사용자 맞춤 학습을 수행하며, 사용자 맞춤 학습된 제 1 인공 신경망 을 이용하여 텍스트 프롬프트에 따라 사진 이미지에 포함된 사람의 얼굴을 웃는 모습으로 편집한 출력 이미지를 생성할 수 있다. 일 실시예에 따르면, 제어부는 원본 입력 이미지 및 원본 입력 이미지에 대한 하나 이상의 관련 이미지를 노이즈와 각각 합성하여 하나 이상의 합성 이미지를 생성할 수 있다. 일 예로, 합성 이미지는 확산 모델이 노이 즈로부터 데이터를 복원하는 동작에 있어서 확산 모델의 입력이 될 수 있다. 일 실시예에 따르면, 제어부는 원본 입력 이미지 및 원본 입력 이미지에 대한 하나 이상의 관련 이미지를 노이즈와 각각 합성하여 하나 이상의 합성 이미지를 생성하며, 하나 이상의 합성 이미지, 및 원본 입력 이미지 및 하나 이상의 관련 이미지 각각에 대한 텍스트 데이터를 제 1 인공 신경망에 입력하여 제 1 인공 신경망에 대 한 제 1 차 사용자 맞춤 학습을 수행할 수 있다. 도 5를 참조하면, 제어부는 원본 입력 이미지(a)에 노이즈(b)를 합성하여 하나 이상의 합성 이미지(c)를 생성할 수 있다. 또한, 제어부는 원본 입력 이미지에 대한 하나 이상의 관련 이미지(f)를 노이즈와 각각합성하여 하나 이상의 합성 이미지를 생성할 수 있다. 이때, 원본 입력 이미지 및 하나 이상의 관련 이미지와 합성되는 노이즈는 각각 다른 노이즈일 수 있다. 일 예로, 관련 이미지는 원본 입력 이미지에 포함된 사람과 동일한 사람에 대한 이미지일 수 있다. 이때, 관련 이미지는 사용자로부터 입력 받은 사진이거나, 제어부가 데이터 베이스에서 검색한 사진일 수 있다. 이를 위해서, 제어부는 이미지에 포함된 사람에 대한 신원 정보(identity)를 가지고 있을 수 있다. 다른 예로, 관련 이미지는 원본 입력 이미지를 기초로 제어부가 데이터 베이스에서 검색한 이미지일 수 있 다. 이때, 제어부는 소정의 방식으로 데이터 베이스를 검색하며, 검색된 이미지와 원본 입력 이미지의 유 사도를 계산하여 소정 유사도 이상의 사진을 선택할 수 있다. 이에 따라, 선택된 이미지는 원본 입력 이미지에 포함된 사람의 신원과 무관하게 선택될 수 있다. 이에 대한 구체적인 방법은 아래 도면을 참조하여 설명한다. 일 실시예에 따르면, 제어부는 원본 입력 이미지 및 원본 입력 이미지에 대한 하나 이상의 관련 이미지 각 각에 대한 합성 이미지를 제 1 인공 신경망에 입력할 수 있다. 또한, 제어부는 원본 입력 이미지 및 원본 입력 이미지에 대한 하나 이상의 관련 이미지 각각에 대한 텍스트 데이터를 제 1 인공 신경망에 입력할 수 있다. 이를 통하여 제어부는 제 1 인공 신경망에 대한 제 1 차 사용자 맞춤 학습을 수행할 수 있다. 일 예로, 제 1 인공 신경망은 합성 이미지(c)와 합성 이미지에 대한 텍스트 데이터(d)를 입력 받을 수 있 으며, 입력된 합성 이미지(c)와 텍스트 데이터(d)를 기초로 사진 이미지(e)를 복원할 수 있다. 이후, 제어부 는 입력된 합성 이미지에 사용된 사진 이미지(a, f)와 사진 이미지(a, f) 각각에 대한 출력 이미지(e)의 차이를 기초로 손실함수를 계산할 수 있으며, 손실함수 값이 소정 범위로 수렴할 때까지 제 1 차 사용자 맞춤 학습을 반복하여 수행할 수 있다. 일 실시예에 따르면, 텍스트 데이터는 사진 이미지에 포함된 사람의 아이덴티티를 확인할 수 있는 하나 이상의 요소 중 적어도 하나에 대한 정보를 포함할 수 있다. 일 예로, 사람의 아이덴티티를 확인할 수 있는 요소는 성 별, 나이, 인종, 피부색, 머리카락색, 표정 및 안경 착용 여부 중 적어도 하나일 수 있다. 예를 들어, 원본 입 력 이미지를 이용하여 사용자 맞춤 학습을 수행 시에는 텍스트 프롬프트가 아닌 원본 입력 이미지 대한 텍스트 데이터가 이용된다. 따라서, 텍스트 프롬프트와 텍스트 데이터는 다를 수 있다. 일 실시예에 따르면, 제어부는 원본 입력 이미지에 노이즈를 합성하여 생성한 합성 이미지 및 합성 이미지 에 대한 텍스트 데이터를 제 1 차 사용자 맞춤 학습된 제 1 인공 신경망에 입력하여 제 1 인공 신경망에 대한 제 2 차 사용자 맞춤 학습을 수행할 수 있다. 다시 말해, 제어부는 원본 입력 이미지 및 하나 이상의 관련 이미지를 이용하여 제 1 차 사용자 맞춤 학습 을 수행하며, 원본 입력 이미지만을 이용하여 제 2 차 사용자 맞춤 학습을 수행할 수 있다. 도 5를 참조하면, 제어부는 원본 입력 이미지(a)에 대한 합성 이미지와 텍스트 데이터만을 이용하여 제 1 인공 신경망을 학 습시킬 수 있다. 이때, 제어부는 입력된 합성 이미지에 사용된 사진 이미지(a)와 출력 이미지(e)의 차이를 기초로 손실함수를 계산할 수 있으며, 손실함수 값이 소정 범위로 수렴할 때까지 제 2 차 사용자 맞춤 학습을 반복하여 수행할 수 있다. 일 실시예에 따르면, 제어부는 원본 입력 이미지 및 텍스트 프롬프트를 제 2 차 사용자 맞춤 학습된 제 1 인공 신경망에 입력하여 원본 입력 이미지를 텍스트 프롬프트에 따라 편집한 출력 이미지를 생성할 수 있다. 예 를 들어, 제어부는 사용자로부터 사람 얼굴이 포함된 원본 입력 이미지(a)와 함께 '웃는 얼굴로 바꿔줘'와 같이 사진 이미지의 편집을 요청하는 텍스트 프롬프트를 입력 받을 수 있다. 이러한 경우, 제어부는 제 2 차 사용자 맞춤 학습이 완료된 제 1 인공 신경망에 입력 받은 원본 입력 이미지와 텍스트 프롬프트를 입력하여 텍스트 프롬프트에 포함된 사용자의 편집 요청에 따라 사진 이미지에 포함된 사람의 얼굴을 웃는 모습으로 편집 한 출력 이미지를 생성할 수 있다. 일 실시예에 따르면, 서버는 사진 이미지를 분석하여 하나 이상의 텍스트 문장을 생성하도록 학습된 제 2 인공 신경망 및 두 개의 사진 이미지를 입력 받아 사진 이미지에 포함된 사람의 유사도를 계산하도록 학습 된 제 3 인공 신경망 중 적어도 하나를 더 포함할 수 있다. 일 실시예에 따르면, 제 2 인공 신경망은 사진 이미지를 입력 받아 사진 이미지에 포함된 사람의 아이덴티 티를 확인할 수 있는 하나 이상의 요소 중 적어도 하나에 대한 정보를 포함하는 하나 이상의 텍스트 문장을 생 성하도록 학습된 것일 수 있다. 일 예로, 제 2 인공 신경망은 이미지 캡셔닝(image captioning) 모델일 수 있다. 예를 들어, 이미지 캡셔닝 모델은 입력된 이미지를 합성곱신경망(Convolution Neural Network, CNN)을 통 하여 특징을 추출하고, 순환신경망(Recurrent Neural Network, RNN)을 통하여 각 특징에 맞는 단어들을 얻어내고 이미지를 설명하는 문장을 생성할 수 있다. 일 실시예에 따르면, 제어부는 원본 사진 데이터를 제 2 인공 신경망에 입력하여 하나 이상의 텍스트 문장 을 수신할 수 있다. 도 7을 참조하면, 제어부는 입력된 원본 입력 이미지(a)를 제 2 인공 신경망에 입력할 수 있으며, 제 2 인공 신경망은 원본 입력 이미지(a)를 설명하는 \"이 사람은 동양인 남자이다. 검 은색 머리카락에 안경을 쓰고 있다. 30대이다.\"와 같은 하나 이상의 문장을 생성할 수 있다. 일 실시예에 따르면, 제어부는 하나 이상의 텍스트 문장을 파싱(parsing)하여 사람의 아이덴티티를 확인할 수 있는 하나 이상의 요소 중 적어도 하나에 대한 하나 이상의 키워드를 추출할 수 있다. 일 예로, 사람의 아이 덴티티를 확인할 수 있는 요소는 성별, 나이, 인종, 피부색, 머리카락색, 표정 및 안경 착용 여부 중 적어도 하 나일 수 있다. 예를 들어, \"이 사람은 동양인 남자이다. 검은색 머리카락에 안경을 쓰고 있다. 30대이다.\"로부 터 \"동양인, 남자, 검은색 머리카락, 안경씀, 30대\"와 같은 키워드를 추출할 수 있다. 일 실시예에 따르면, 제어부는 텍스트 프롬프트를 파싱(parsing)하여 사람의 아이덴티티를 확인할 수 있는 하나 이상의 요소 중 적어도 하나에 대한 하나 이상의 키워드를 추출할 수 있다. 예를 들어, \"웃는 모습으로 바 꿔줘\"와 같은 텍스트 프롬프트를 입력 받아 \"웃는 표정\"과 같은 키워드를 추출할 수 있다. 일 예에 따르면, 제어부는 사용자가 입력한 관련 이미지를 제 2 인공 신경망에 입력하여 관련 이미지 에 대한 키워드를 추출할 수 있다. 이후, 제어부는 사용자가 입력한 관련 이미지와 사용자가 입력한 텍스 트 프롬프트에서 추출한 키워드를 추출하여 데이터 베이스에서 추가적인 관련 이미지를 검색할지 여부를 판단할 수 있다. 예를 들어, 사용자가 입력한 관련 이미지에서 추출한 키워드 중 사용자가 입력한 텍스트 프롬프트에서 추출된 키워드에 대한 키워드가 없는 경우, 제어부는 누락된 키워드와 관련된 이미지를 데이터 베이스에서 검색하여 관련 이미지를 추가할 수 있다. 일 실시예에 따르면, 제어부는 추출된 하나 이상의 키워드에 기초하여 키워드 또는 키워드의 조합에 따라 데이터 베이스를 검색하여 하나 이상의 샘플 이미지를 추출할 수 있다. 일 예에 따르면, 제어부는 추출된 하나 이상의 키워드에 기초하여 키워드의 조합을 생성할 수 있다. 예를 들어, 제어부는 동일한 문장에서 추출된 키워드를 기준으로 키워드 조합을 만들 수 있다. 다른 예를 들어, 제어부는 제 2 인공 신경망에서 추출된 텍스트 문장과 사용자로부터 입력된 텍스트 프롬프트를 기준 으로 키워드 조합을 만들 수 있다. 일 예에 따르면, 제어부는 키워드 또는 키워드의 조합에 따라 데이터 베이스를 검색하여 하나 이상의 샘플 이미지를 추출할 수 있다. 도 8을 참조하면, 제어부는 '동양인', '웃는 표정'과 같은 키워드를 기준으로 데이터 베이스를 검색하여 하나 이상의 샘플 이미지를 추출할 수 있다. 다른 예로, 제어부는 '남자, 검은 색 머리카락', '안경씀, 30대'와 같은 키워드 조합을 기준으로 데이터 베이스를 검색하여 하나 이상의 샘플 이 미지를 추출할 수 있다. 일 실시예에 따르면, 제어부는 키워드 또는 키워드의 조합에 따라 하나 이상의 샘플 이미지를 분류하여 하 나 이상의 클러스터를 생성할 수 있다. 도 8을 참조하면, 제어부는 키워드 또는 키워드의 조합에 따라 하 나 이상의 샘플 이미지를 분류하여 하나 이상의 클러스터(b)를 생성할 수 있다. 일 실시예에 따르면, 제 3 인공 신경망은 두 개의 사진 이미지를 입력 받아 사진 이미지에 포함된 사람의 유사도를 계산하도록 학습된 것일 수 있다. 일 실시예에 따르면, 제어부는 원본 입력 이미지와 하나 이상의 샘플 이미지를 제 3 인공 신경망에 입력하여 하나 이상의 샘플 이미지 중 원본 입력 이미지와 소정 유사도 이상의 유사도를 가지는 하나 이상의 대 표 샘플 이미지를 추출할 수 있다. 도 8을 참조하면, 제어부는 제 3 인공 신경망에 원본 입력 이미지(a)와 샘플 이미지(b)를 입력하여 두 이미지 간 유사도를 계산할 수 있다. 이때, 샘플 이미지는 각각 입력되거나 클러스터 단위로 입력될 수 있다. 일 예를 들어, 제어부는 제 3 인공 신경망에 샘플 이미지(b)를 각각 입력하여 유사도를 계산할 수 있 다. 이후, 제어부는 소정 기준 이상의 유사도를 가지는 하나 이상의 대표 샘플 이미지를 선택할 수 있다. 일 예를 들어, 제어부는 제 3 인공 신경망에 샘플 이미지(b)를 클러스터 단위로 입력하여 유사도를 계산할 수 있다. 이후, 제어부는 소정 기준 이상의 유사도를 가지는 하나 이상의 대표 샘플 이미지를 선택할 수 있다. 이때, 하나의 클러스터에 소정 개수 이상의 샘플 이미지가 선택된 경우, 제어부는 유사도가 높은 순서로 소정 개수의 대표 샘플 이미지만 선택할 수 있다. 반면, 소정 기준 이상의 유사도를 가지는 샘플 이미지가 없는 클러스터의 경우 해당 클러스터에 포함된 샘플 이미지 및 클러스터에 대응하는 키워드는 사용자 맞춤 학습에 사용되지 않을 수 있다. 일 실시예에 따르면, 제어부는 하나 이상의 대표 샘플 이미지를 기초로 원본 입력 이미지에 대한 하나 이 상의 관련 이미지를 생성할 수 있다. 예를 들어, 제어부는 소정 기준 이상의 유사도를 가지는 샘플 이미지 를 선택하여 하나 이상의 대표 샘플 이미지(c)를 생성할 수 있다. 이후, 제어부는 대표 샘플 이미지(c)를 원본 입력 이미지에 대한 관련 이미지로 이용할 수 있다. 일 실시예에 따르면, 제어부는 하나 이상의 대표 샘플 이미지가 속한 클러스터의 키워드 또는 키워드 조합 에 기초하여 하나 이상의 관련 이미지 각각에 대한 텍스트 데이터를 생성할 수 있다. 도 8을 참조하면, 제어부 는 하나 이상의 샘플 이미지 중에서 선택된 하나 이상의 대표 샘플 이미지가 포함된 클러스터의 분류 기준 인 키워드를 대표 샘플 이미지의 텍스트 데이터로 이용할 수 있다. 예를 들어, '동양인' 클러스터에 포함된 샘 플 이미지가 대표 샘플 이미지로 선택된 경우, 선택된 대표 샘플 이미지의 텍스트 데이터는 '동양인'이 될 수 있다. 도 9를 참조하면, (a) 단계에서 제어부는 원본 입력 이미지와 도 8에서 생성된 대표 샘플 이미지를 관련 이미지로 이용하여 하나 이상의 합성 이미지를 생성할 수 있다. 또한, 제어부는 하나 이상의 합성 이미지 와 합성 이미지의 텍스트 데이터를 제 1 인공 신경망에 입력하여 제 1 차 사용자 맞춤 학습을 수행할 수 있다. 제어부는 각각의 합성 이미지에 대한 손실함수가 소정 범위 내로 수렴할 때 까지 제 1 차 사용자 맞춤 학 습을 반복적으로 수행할 수 있다. 일 예로, 제 1 차 사용자 맞춤 학습이 완료된 경우, (b) 단계에서 제어부는 원본 입력 이미지의 합성 이미 지와 원본 입력 이미지의 텍스트 데이터를 제 1 인공 신경망에 입력하여 제 2 차 사용자 맞춤 학습을 수행할 수 있다. 제어부는 각각의 합성 이미지에 대한 손실함수가 소정 범위 내로 수렴할 때 까지 제 2 차 사용자 맞 춤 학습을 반복적으로 수행할 수 있다. 제 2 차 사용자 맞춤 학습이 완료되면, (c) 단계에서 제어부는 원본 입력 이미지에 대한 합성 이미지와 텍 스트 프롬프트를 제 1 인공 신경망에 입력할 수 있다. 이후, 제어부는 원본 입력 이미지에 대한 합성 이미 지와 텍스트 프롬프트에 의해 출력된 출력 이미지를 원본 입력 이미지를 텍스트 프롬프트에 따라 편집한 이미지 로 출력할 수 있다. 예를 들어, 원본 입력 이미지에 대한 '웃는 모습으로 바꿔줘' 텍스트 프롬프트에 대하여 원 본 입력 이미지에 포함된 사람의 표정을 편집하여 출력할 수 있다. 일 실시예에 따르면, 제어부는 사용자 맞춤 학습된 제 1 인공 신경망에 원본 입력 이미지 및 텍스트 프롬프트를 입력하여 생성된 원본 입력 이미지를 편집한 출력 이미지를 사용자 단말로 전송할 수 있다. 일 예에 따르면, 제어부는 원본 입력 이미지 및 텍스트 프롬프트를 제 2 차 사용자 맞춤 학습된 제 1 인공 신경망 에 입력하여 원본 입력 이미지를 텍스트 프롬프트에 따라 편집한 출력 이미지를 생성하여 사용자 단말로 전송할 수 있다. 이후, 사용자 단말은 도 3에서와 같이 서버로부터 수신한 편집된 이미지를 사용자에게 제공할 수 있다. 도 10은 일 실시예에 따른 사용자 단말의 동작 방법을 도시한 흐름도이다. 일 실시예에 따르면, 사용자 단말은 하나 이상의 프로세서들 및 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치일 수 있다. 일 실시예에 따르면, 사용자 단말은 사용자로부터 편집을 수행할 원본 입력 이미지 및 편집에 대한 정보를 포함 하는 텍스트 프롬프트를 수신할 수 있다. 이후, 사용자 단말은 입력된 텍스트 프롬프트에 따라 입력된 이 미지를 편집하도록 학습된 제 1 인공 신경망을 포함하는 서버로 전송할 수 있다. 사용자 단말은 서버로부 터 원본 입력 이미지를 기초로 사용자 맞춤 학습된 제 1 인공 신경망이 텍스트 프롬프트에 따라 편집한 원본 입 력 이미지에 대한 출력 이미지를 수신할 수 있으며, 수신한 출력 이미지를 인터페이스부를 통해 출력할 수 있다. 도 11은 일 실시예에 따른 서버의 동작 방법을 도시한 흐름도이다. 일 실시예에 따르면, 서버는 하나 이상의 프로세서들 및 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치일 수 있다.일 실시예에 따르면, 서버는 사용자 단말로부터 이미지 편집을 수행할 원본 입력 이미지 및 이미지 편집 요청 사항을 포함하는 텍스트 프롬프트를 수신할 수 있다. 이후, 서버는 원본 입력 이미지를 기초로 제 1 인공 신경망에 사용자 맞춤 학습을 수행하며, 사용자 맞춤 학습된 제 1 인공 신경망에 원본 입력 이미지 및 텍 스트 프롬프트를 입력하여 생성된 원본 입력 이미지를 편집한 출력 이미지를 사용자 단말로 전송할 수 있다 . 도 10 및 도 11에 대한 실시예 중 도 1 내지 도9를 참조하여 설명한 내용과 중복되는 내용은 생략하였다. 본 발명의 일 양상은 컴퓨터로 읽을 수 있는 기록 매체에 컴퓨터가 읽을 수 있는 코드로서 구현될 수 있다. 상 기의 프로그램을 구현하는 코드들 및 코드 세그먼트들은 당해 분야의 컴퓨터 프로그래머에 의하여 용이하게 추 론될 수 있다. 컴퓨터가 읽을 수 있는 기록 매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록 장치를 포함할 수 있다. 컴퓨터가 읽을 수 있는 기록 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 디스크 등을 포함할 수 있다. 또한, 컴퓨터가 읽을 수 있는 기록 매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드로 작성되고 실행될 수 있다. 이제까지 본 발명에 대하여 그 바람직한 실시 예들을 중심으로 살펴보았다. 본 발명이 속하는 기술 분야에서 통 상의 지식을 가진 자는 본 발명이 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있을 것이다. 따라서, 본 발명의 범위는 전술한 실시 예에 한정되지 않고 특허 청구범위에 기재된 내용과 동등한 범위 내에 있는 다양한 실시 형태가 포함되도록 해석되어야 할 것이다."}
{"patent_id": "10-2023-0120201", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 이미지 편집이 수행되는 환경을 설명하기 위한 예시도이다. 도 2는 일 실시예에 따른 사용자 단말의 구성도이다. 도 3은 일 실시예에 따른 인터페이스부를 설명하기 위한 예시도이다. 도 4는 일 실시예에 따른 서버의 구성도이다. 도 5 내지 도 9는 일 예에 따른 서버의 동작을 설명하기 위한 예시도이다. 도 10은 일 실시예에 따른 사용자 단말의 동작 방법을 도시한 흐름도이다. 도 11은 일 실시예에 따른 서버의 동작 방법을 도시한 흐름도이다."}
