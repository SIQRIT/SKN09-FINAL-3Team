{"patent_id": "10-2024-7036702", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0012052", "출원번호": "10-2024-7036702", "발명의 명칭": "뉴럴 토폴로지 순서화", "출원인": "퀄컴 인코포레이티드", "발명자": "라이노네 코라도"}}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "프로세서 구현 방법으로서,수행될 태스크들의 세트를 수신하는 단계;에지들에 의해 연결된 다중의 노드들을 포함하는 그래프에서 상기 태스크들의 세트를 표현하는 단계로서, 각각의 노드는 상기 태스크들의 세트에서의 태스크에 대응하는, 상기 태스크들의 세트를 표현하는 단계;상기 그래프에서의 각각의 노드에 스케줄링 우선순위를 배정하는 단계;배정된 상기 스케줄링 우선순위들 및 상기 그래프의 토폴로지에 적어도 부분적으로 기초하여 잠재적 다음 노드들의 각각의 확률에 따라 상기 잠재적 다음 노드들 중의 다음 노드를 선택하는 단계; 및상기 다음 노드의 선택을 반복함으로써 상기 태스크들의 토폴로지 순서를 생성하는 단계를 포함하는, 프로세서구현 방법."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 태스크들의 세트는 컴파일러에 의해 프로세싱될 동작들의 세트를 포함하는, 프로세서 구현 방법."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 잠재적 다음 노드들의 확률 분포의 그리디 탐색, 상기 잠재적 다음 노드들의 상기 확률분포로부터의 샘플링, 또는 빔 탐색 프로세스 중 하나에 기초하여 상기 다음 노드를 선택하는 단계를 더 포함하는, 프로세서 구현 방법."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 인공 뉴럴 네트워크(ANN)를 통해, 단일 추론으로 상기 다중의 노드들에 상기 스케줄링 우선순위들을 배정하는 단계를 더 포함하는, 프로세서 구현 방법."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 그래프는 방향성 비순환 그래프를 포함하는, 프로세서 구현 방법."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 스케줄링 우선순위는 하나 이상의 토폴로지 변환들에 기초하여 배정되는, 프로세서 구현방법."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 토폴로지 순서에 따라 상기 태스크들의 세트를 수행하는 단계를 더 포함하는, 프로세서구현 방법."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "장치로서,메모리; 및상기 메모리에 커플링된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는,수행될 태스크들의 세트를 수신하고;공개특허 10-2025-0012052-3-에지들에 의해 연결된 다중의 노드들을 포함하는 그래프에서 상기 태스크들을 표현하는 것으로서, 각각의 노드는 상기 태스크들의 세트에서의 태스크에 대응하는, 상기 태스크들을 표현하고;상기 그래프에서의 각각의 노드에 스케줄링 우선순위를 배정하고;배정된 상기 스케줄링 우선순위들 및 상기 그래프의 토폴로지에 적어도 부분적으로 기초하여 잠재적 다음 노드들의 각각의 확률에 따라 상기 잠재적 다음 노드들 중의 다음 노드를 선택하고; 그리고상기 다음 노드의 선택을 반복함으로써 상기 태스크들의 토폴로지 순서를 생성하도록 구성되는, 장치."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 태스크들은 컴파일러에 의해 프로세싱될 동작들의 세트를 포함하는, 장치."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 상기 적어도 하나의 프로세서는 추가로, 상기 잠재적 다음 노드들의 확률 분포의 그리디 탐색,상기 잠재적 다음 노드들의 상기 확률 분포로부터의 샘플링, 또는 빔 탐색 프로세스 중 하나에 기초하여 상기다음 노드를 선택하도록 구성되는, 장치."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 상기 적어도 하나의 프로세서는 추가로, 단일 추론으로 상기 다중의 노드들에 상기 스케줄링우선순위들을 배정하도록 구성되는, 장치."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서, 상기 그래프는 방향성 비순환 그래프를 포함하는, 장치."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서, 상기 적어도 하나의 프로세서는 추가로, 하나 이상의 토폴로지 변환들에 기초하여 상기 다중의노드들에 상기 스케줄링 우선순위들을 배정하도록 구성되는, 장치."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서, 상기 적어도 하나의 프로세서는 추가로, 상기 토폴로지 순서에 따라 상기 태스크들의 세트를수행하도록 구성되는, 장치."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "프로그램 코드가 기록된 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 프로그램 코드는,프로세서에 의해 실행되고, 그리고수행될 태스크들의 세트를 수신하기 위한 프로그램 코드;에지들에 의해 연결된 다중의 노드들을 포함하는 그래프에서 상기 태스크들을 표현하기 위한 프로그램코드로서, 각각의 노드는 상기 태스크들의 세트에서의 태스크에 대응하는, 상기 태스크들을 표현하기 위한 프로그램 코드;상기 그래프에서의 각각의 노드에 스케줄링 우선순위를 배정하기 위한 프로그램 코드;배정된 상기 스케줄링 우선순위들 및 상기 그래프의 토폴로지에 적어도 부분적으로 기초하여 잠재적 다음 노드들의 각각의 확률에 따라 상기 잠재적 다음 노드들 중의 다음 노드를 선택하기 위한 프로그램 코드; 및상기 다음 노드의 선택을 반복함으로써 상기 태스크들의 토폴로지 순서를 생성하기 위한 프로그램 코드를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 태스크들은 컴파일러에 의해 프로세싱될 동작들의 세트를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.공개특허 10-2025-0012052-4-청구항 17 제15항에 있어서, 인공 뉴럴 네트워크(ANN)를 통해, 상기 잠재적 다음 노드들의 확률 분포의 그리디 탐색, 상기잠재적 다음 노드들의 상기 확률 분포로부터의 샘플링, 또는 빔 탐색 프로세스 중 하나에 기초하여 상기 다음노드를 선택하기 위한 프로그램 코드를 더 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서, 인공 뉴럴 네트워크(ANN)를 통해, 단일 추론으로 상기 다중의 노드들에 상기 스케줄링 우선순위들을 배정하기 위한 프로그램 코드를 더 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항에 있어서, 상기 그래프는 방향성 비순환 그래프를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항에 있어서, 하나 이상의 토폴로지 변환들에 기초하여 상기 다중의 노드들에 상기 스케줄링 우선순위들을배정하기 위한 프로그램 코드를 더 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제15항에 있어서, 상기 토폴로지 순서에 따라 상기 태스크들의 세트를 수행하기 위한 프로그램 코드를 더 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "장치로서,수행될 태스크들의 세트를 수신하는 수단;에지들에 의해 연결된 다중의 노드들을 포함하는 그래프에서 상기 태스크들을 표현하는 수단으로서, 각각의 노드는 상기 태스크들의 세트에서의 태스크에 대응하는, 상기 태스크들을 표현하는 수단;상기 그래프에서의 각각의 노드에 스케줄링 우선순위를 배정하는 수단;다음 노드의 선택을 반복함으로써 상기 태스크들의 토폴로지 순서를 선택하는 수단; 및상기 다음 노드의 선택을 반복함으로써 상기 태스크들의 상기 토폴로지 순서를 생성하는 수단을 포함하는,장치."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서, 상기 태스크들은 컴파일러에 의해 프로세싱될 동작들의 세트를 포함하는, 장치."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제22항에 있어서, 인공 뉴럴 네트워크(ANN)를 통해, 잠재적 다음 노드들의 확률 분포의 그리디 탐색, 상기 잠재적 다음 노드들의 상기 확률 분포로부터의 샘플링, 또는 빔 탐색 프로세스 중 하나에 기초하여 상기 다음 노드를 선택하는 수단을 더 포함하는, 장치."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제22항에 있어서, 단일 추론으로 상기 다중의 노드들에 상기 스케줄링 우선순위들을 배정하는 수단을 더 포함하는, 장치."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제22항에 있어서, 상기 그래프는 방향성 비순환 그래프를 포함하는, 장치."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제22항에 있어서, 하나 이상의 토폴로지 변환들에 기초하여 상기 다중의 노드들에 상기 스케줄링 우선순위들을공개특허 10-2025-0012052-5-배정하는 수단을 더 포함하는, 장치."}
{"patent_id": "10-2024-7036702", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제22항에 있어서, 상기 토폴로지 순서에 따라 상기 태스크들의 세트를 수행하는 수단을 더 포함하는, 장치."}
{"patent_id": "10-2024-7036702", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 뉴럴 네트워크(ANN)를 사용하여 토폴로지 순서를 생성하기 위한 프로세서 구현 방법은 수행될 태스크들의 세트를 수신하는 단계를 포함한다. 태스크들은, 에지들에 의해 연결된 다중의 노드들을 포함하는 그래프에서 표 현된다. 각각의 노드는 태스크들의 세트에서의 태스크에 대응한다. 스케줄링 우선순위가 그래프에서의 각각의 노드에 배정된다. 잠재적 다음 노드들 중의 다음 노드가, 배정된 스케줄링 우선순위들 및 그래프의 토폴로지에 기초하여 잠재적 다음 노드들의 각각의 확률에 따라 선택된다. 태스크들의 토폴로지 순서가, 다음 노드의 선택 을 반복함으로써 생성된다."}
{"patent_id": "10-2024-7036702", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원들에 대한 상호참조 본 출원은 \"NEURAL TOPOLOGICAL ORDERING\"의 명칭으로 2022년 5월 19일자로 출원된 미국 가특허출원 제 63/343,961호의 이익을 주장하는, \"NEURAL TOPOLOGICAL ORDERING\"의 명칭으로 2023년 1월 31일자로 출원된 미 국 특허출원 제18/103,757호를 우선권 주장하며, 이들의 개시들은 그들 전체가 참조에 의해 명백히 통합된다."}
{"patent_id": "10-2024-7036702", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "본 개시의 기술분야 본 개시의 양태들은 일반적으로, 뉴럴 토폴로지 순서화에 관한 것이다."}
{"patent_id": "10-2024-7036702", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 뉴럴 네트워크들은 인공 뉴런들(예컨대, 뉴런 모델들)의 상호연결된 그룹들을 포함할 수도 있다. 인공 뉴 럴 네트워크는 연산 디바이스일 수도 있거나, 연산 디바이스에 의해 수행될 방법으로서 표현될 수도 있다. 컨 볼루셔널 뉴럴 네트워크들(CNN들)은 피드-포워드 인공 뉴럴 네트워크의 일 타입이다. 컨볼루셔널 뉴럴 네트워 크들은, 수용 필드를 각각 갖고 그리고 입력 공간을 집합적으로 타일링하는 뉴런들의 집합들을 포함할 수도 있 다. 딥 컨볼루셔널 뉴럴 네트워크들(deep convolutional neural networks; DCN들)과 같은 컨볼루션 뉴럴 네트 워크들은 다수의 어플리케이션들을 갖는다. 특히, 이들 뉴럴 네트워크 아키텍처들은 이미지 인식, 스피치 인식, 음향 장면 분류, 키워드 스폿팅(spotting), 자율 주행, 및 다른 분류 태스크들과 같은 다양한 기술들에서 사용된다. 운영 연구에서의 많은 문제들은 태스크들의 시퀀스를 수행하는 한편, 이들 사이의 우선순위 제약들의 세트를 준 수하는 것 및 관심있는 비용 메트릭을 최적화하는 것 양자 모두를 수반한다. 종래의 접근법들은, 문제 특정 입 력 분포들에 대해 맞춤화되지 않은 일반적인 입력 분포에 대해 설계된 휴리스틱 전략들을 통해 그러한 문제들을 처리한다. 일부 휴리스틱 전략들은, 각각의 인스턴스에 대해 수작업으로 이루어지며, 이는 시간 소모적이고 도 메인 지식을 요구한다. 본 개시는 독립 청구항들에 각각 기재된다. 본 개시의 일부 양태들은 종속 청구항들에서 기술된다. 본 개시의 일 양태에서, 프로세서 구현 방법은 수행될 태스크들의 세트를 수신하는 단계를 포함한다. 프로세서 구현 방법은 에지들에 의해 연결된 다중의 노드들을 포함하는 그래프에서 태스크들의 세트를 표현하는 단계를 더 포함한다. 각각의 노드는 태스크들의 세트에서의 태스크에 대응한다. 프로세서 구현 방법은 그래프에서의 각각의 노드에 스케줄링 우선순위를 배정하는 단계를 더 추가로 포함한다. 프로세서 구현 방법은 또한, 배정된 스케줄링 우선순위들 및 그래프의 토폴로지에 적어도 부분적으로 기초하여 잠재적 다음 노드들의 각각의 확률에 따라 잠재적 다음 노드들 중의 다음 노드를 선택하는 단계를 포함한다. 프로세서 구현 방법은 다음 노드의 선 택을 반복함으로써 태스크들의 토폴로지 순서를 생성하는 단계를 더 포함한다. 본 개시의 다른 양태는 장치에 관한 것이고, 그 장치는 수행될 태스크들의 세트를 수신하는 수단을 포함한다. 그 장치는 에지들에 의해 연결된 다중의 노드들을 포함하는 그래프에서 태스크들의 세트를 표현하는 수단을 더 포함한다. 각각의 노드는 태스크들의 세트에서의 태스크에 대응한다. 그 장치는 그래프에서의 각각의 노드에 스케줄링 우선순위를 배정하는 수단을 더 추가로 포함한다. 그 장치는 또한, 배정된 스케줄링 우선순위들 및 그래프의 토폴로지에 적어도 부분적으로 기초하여 잠재적 다음 노드들의 각각의 확률에 따라 잠재적 다음 노드 들 중의 다음 노드를 선택하는 수단을 포함한다. 그 장치는 다음 노드의 선택을 반복함으로써 태스크들의 토폴 로지 순서를 생성하는 수단을 더 포함한다. 본 개시의 다른 양태에서, 비일시적 프로그램 코드가 기록된 비일시적 컴퓨터 판독가능 매체가 개시된다. 프로 그램 코드는 프로세서에 의해 실행되며, 수행될 태스크들의 세트를 수신하기 위한 프로그램 코드를 포함한다. 프로그램 코드는 에지들에 의해 연결된 다중의 노드들을 포함하는 그래프에서 태스크들의 세트를 표현하기 위한 프로그램 코드를 더 포함한다. 각각의 노드는 태스크들의 세트에서의 태스크에 대응한다. 프로그램 코드는 그 래프에서의 각각의 노드에 스케줄링 우선순위를 배정하기 위한 프로그램 코드를 더 추가로 포함한다. 프로그램 코드는 또한, 배정된 스케줄링 우선순위들 및 그래프의 토폴로지에 적어도 부분적으로 기초하여 잠재적 다음 노 드들의 각각의 확률에 따라 잠재적 다음 노드들 중의 다음 노드를 선택하기 위한 프로그램 코드를 포함한다. 프로그램 코드는 다음 노드의 선택을 반복함으로써 태스크들의 토폴로지 순서를 생성하기 위한 프로그램 코드를 더 포함한다. 본 개시의 다른 양태는, 메모리 및 메모리에 커플링된 하나 이상의 프로세서들을 갖는 장치에 관한 것이다. 프 로세서(들)는 수행될 태스크들의 세트를 수신하도록 구성된다. 프로세서(들)는 추가로, 에지들에 의해 연결된 다중의 노드들을 포함하는 그래프에서 태스크들의 세트를 표현하도록 구성된다. 각각의 노드는 태스크들의 세 트에서의 태스크에 대응한다. 프로세서(들)는 더 추가로, 그래프에서의 각각의 노드에 스케줄링 우선순위를 배 정하도록 구성된다. 프로세서(들)는 또한, 배정된 스케줄링 우선순위들 및 그래프의 토폴로지에 적어도 부분적 으로 기초하여 잠재적 다음 노드들의 각각의 확률에 따라 잠재적 다음 노드들 중의 다음 노드를 선택하도록 구 성된다. 프로세서(들)는 추가로, 다음 노드의 선택을 반복함으로써 태스크들의 토폴로지 순서를 생성하도록 구 성된다. 본 개시의 부가적인 특징들 및 이점들이 이하 설명될 것이다. 본 개시는 본 개시의 동일한 목적들을 실행하는 다른 구조들을 수정 또는 설계하기 위한 기반으로서 용이하게 활용될 수도 있음을 당업자에 의해 인식되어야 한 다. 또한, 그러한 균등의 구성들은 첨부된 청구항들에 기재된 바와 같은 본 개시의 교시들로부터 일탈하지 않 음을 당업자에 의해 인식되어야 한다. 추가의 목적들 및 이점들과 함께 그 구성 및 동작 방법 양자에 관하여 본 개시의 특성인 것으로 사료되는 신규한 특징들은 첨부 도면들과 관련하여 고려될 경우에 다음의 설명으로부 터 더 양호하게 이해될 것이다. 하지만, 도면들의 각각은 오직 예시 및 설명의 목적을 위해서만 제공될 뿐 본 개시의 제한들의 정의로서 의도되지 않는다는 것이 명백히 이해되어야 한다."}
{"patent_id": "10-2024-7036702", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "첨부 도면들과 관련하여 하기에 기재된 상세한 설명은 다양한 구성들의 설명으로서 의도되고, 설명된 개념들이 실시될 수도 있는 유일한 구성들만을 나타내도록 의도되지 않는다. 상세한 설명은 다양한 개념들의 철저한 이 해를 제공할 목적으로 특정 상세들을 포함한다. 하지만, 이들 개념들은 이들 특정 상세들없이도 실시될 수도 있음이 당업자에게 명백할 것이다. 일부 사례들에 있어서, 널리 공지된 구조들 및 컴포넌트들은 그러한 개념들 을 불명료하게 하는 것을 회피하기 위하여 블록 다이어그램 형태로 도시된다.교시들에 기초하여, 당업자는, 본 개시의 임의의 다른 양태와는 독립적으로 구현되든 임의의 다른 양태와 결합 되든, 본 개시의 범위가 본 개시의 임의의 양태를 커버하도록 의도됨을 인식할 것이다. 예를 들어, 기재된 임 의의 수의 양태들을 이용하여 일 장치가 구현될 수도 있거나 또는 일 방법이 실시될 수도 있다. 추가적으로, 본 개시의 범위는, 설명된 본 개시의 다양한 양태들에 부가한 또는 그 이외의 구조 및 기능성, 또는 다른 구조, 기능성을 이용하여 실시되는 그러한 장치 또는 방법을 커버하도록 의도된다. 개시된 본 개시의 임의의 양태는 청구항의 하나 이상의 엘리먼트들에 의해 구현될 수도 있음이 이해되어야 한다. 단어 \"예시적인\"은 \"예, 사례, 또는 예시로서 기능함\"을 의미하도록 사용된다. \"예시적인\" 것으로서 설명된 임 의의 양태는 다른 양태들에 비해 반드시 선호되거나 유리한 것으로서 해석될 필요는 없다. 특정 양태들이 설명되지만, 이들 양태들의 다수의 변형들 및 치환들은 본 개시의 범위 내에 있다. 선호된 양태 들의 일부 이익들 및 이점들이 언급되지만, 본 개시의 범위는 특정 이익들, 사용들, 또는 목적들로 한정되도록 의도되지 않는다. 대신, 본 개시의 양태들은 상이한 기술들, 시스템 구성들, 네트워크들 및 프로토콜들에 널리 적용가능하도록 의도되며, 이들 중 일부는 도면들에서, 그리고 선호된 양태들의 다음의 설명에서 예로써 예시된 다. 상세한 설명 및 도면들은 한정하는 것보다는 본 개시의 단지 예시일 뿐이며, 본 개시의 범위는 첨부된 청 구항들 및 그 균등물들에 의해 정의된다. 컴퓨터 과학에서의 많은 문제들은 일부 우선순위 제약들에 부합하는 오브젝트들의 최상의 시퀀스를 찾는 것을 수반할 수도 있다. 직관적인 예는 라우팅 문제들에서 찾을 수도 있으며, 여기서, 하나의 목적은 도시들 간의 최단 경로를 찾는 것이다. 부가적으로, 도시들이 방문되어야 하는 순서에 대한 (예컨대, 패키지의 픽업 및 후 속 전달에 관한) 경고들이 있을 수 있다. 다른 예는, 동작들의 세트를 실행하기 위한 최단 지속기간을 찾는 것 을 수반하는 컴파일러 파이프라인들에서 발견될 수도 있다. 이전의 예에서의 도시들과 같이 실행될 동작들은 특정 제약들을 받을 수도 있다. 제약들은, 예를 들어, 동작의 결과가 후속 동작의 오퍼랜드(operand)인 경우와 같이, 동작들 사이의 데이터 종속성들로부터 비롯될 수도 있다. 이와 같이, 이전 동작들은 종속 동작을 위한 우선순위 제약들로서 서빙할 수도 있다. 이 예에서, 최적화될 메트릭은, 예를 들어, 컴파일된 프로그램의 런타 임, 프로그램을 실행하도록 명시된 메모리 또는 다른 성능 메트릭들일 수도 있다. 그러한 문제들을 해결하기 위한 하나의 접근법은, 우선순위 제약(예컨대, 실행의 순서)을 인코딩하는 방향성 비순환 그래프(directed acyclic graph; DAG)의 최적의 토폴로지 순서를 찾는다는 관점에서 문제들을 공식화하는 것을 수반한다. 하지 만, 그렇게 하는 것은, 일반적으로 연산적으로 복잡한(예컨대, np-하드) CO(combinatorial optimization) 문제 를 유도한다. CO 문제들에 적용되는 종래의 접근법들은, 수십 년의 개발에 걸쳐, 도메인 특정 및 문제 특정 지식의 광범위한 사용을 수반하는 설계로 휴리스틱 방법을 캡슐화할 수도 있다. 더욱이, 각각의 인스턴스에 대해 수작업으로 또 는 맞춤형으로 이루어지는 휴리스틱 전략들을 통해 그러한 문제들을 처리하는 것은 시간 소모적이다. 이들 및 다른 난제들을 해결하기 위해, 본 개시의 양태들은 인공 뉴럴 네트워크를 사용한 토폴로지 순서화에 관 한 것이다. 본 개시의 양태들에 따르면, 토폴로지 순서화를 위한 엔드-투-엔드 머신 러닝 기반 접근법은 인코 더-디코더 프레임워크를 사용한다. 인코더는, 메시지 전달을 위해 방향성 비순환 그래프(DAG)의 상이한 토폴로 지 변환들을 활용하는 어텐션 기반 그래프 뉴럴 네트워크 아키텍처로서 구성될 수도 있다. DAG는, 직접 사이클 들이 없는 유한한 방향성 그래프이다. 그 그래프는, 에지들에 의해 연결된 노드들의 세트를 포함할 수도 있다. 노드들의 각각은 수행될 태스크를 표현할 수도 있고, 에지들은, 표현된 태스크들을 수행하기 위한 순서를 표시 할 수도 있다. 어텐션 기반 그래프 뉴럴 네트워크 아키텍처의 인코더에 의해 생성된 노드 임베딩들은 노드 우선순위들로 변환 될 수도 있으며, 이는 토폴로지 순서들에 대한 확률 분포를 생성하기 위해 디코더에 의해 사용될 수도 있다. 일부 양태들에서, 어텐션 기반 그래프 뉴럴 네트워크 아키텍처는, 예를 들어, 계층화된 그래프들로 지칭되는 합 성적으로 생성된 그래프들의 데이터세트에 대해 트레이닝될 수도 있다. 이에 따라, 어텐션 기반 그래프 뉴럴 네트워크는 토폴로지 순서를, 일부 양태에서는, 최적의 토폴로지 순서를 결정할 수도 있다. 이와 같이, 본 개시의 양태들은 메모리 및 에너지 소비를 유리하게 감소시킬 수도 있다. 더욱이, 본 개시의 양태들은 토폴로지 순서들의 확률 분포를 파라미터화하기 위해 비-자기회귀(non-auto- regressive) 기법을 채용한다. 즉, 토폴로지 순서가 뉴럴 네트워크의 각각의 순방향 패스로 한번에 하나의 노 드씩 결정되는 자기회귀 접근법을 사용하기보다는, 본 개시의 양태들은 뉴럴 네트워크의 단일 순방향 패스로 토 폴로지 순서를 제공할 수도 있다. 결과적으로, 본 개시의 양태들은 자기회귀 접근법들보다 현저히 더 낮은 런타임으로 성능을 개선할 수도 있다(예컨대, 감소된 메모리 소비). 도 1은, 인공 뉴럴 네트워크를 사용하여 토폴로지 순서를 생성하기 위해 구성된 중앙 프로세싱 유닛(CPU) 또는 멀티-코어 CPU를 포함할 수도 있는 시스템-온-칩(SOC)의 예시적인 구현을 예시한다. 변수들(예컨대, 뉴럴 신호들 및 시냅스 가중치들), 연산 디바이스(예컨대, 가중치들을 갖는 뉴럴 네트워크)와 연관된 시스템 파 라미터들, 지연들, 주파수 빈(bin) 정보, 및 태스크 정보는 뉴럴 프로세싱 유닛(NPU)과 연관된 메모리 블 록에, CPU와 연관된 메모리 블록에, 그래픽스 프로세싱 유닛(GPU)과 연관된 메모리 블록에, 디지털 신호 프로세서(DSP)와 연관된 메모리 블록에, 메모리 블록에 저장될 수도 있거나, 또는 다중의 블록 들에 걸쳐 분산될 수도 있다. CPU에서 실행된 명령들은 CPU와 연관된 프로그램 메모리로부터 로딩될 수도 있거나, 또는 메모리 블록으로부터 로딩될 수도 있다. SOC는 또한, GPU, DSP, 제5 세대(5G) 연결성, 제4 세대 롱 텀 에볼루션(4G LTE) 연결성, Wi-Fi 연결성, USB 연결성, 블루투스 연결성 등등을 포함할 수도 있는 연결성 블록 , 및 예를 들어, 제스처들을 검출 및 인식할 수도 있는 멀티미디어 프로세서와 같은 특정 기능부들에 맞춤화된 추가적인 프로세싱 블록 들을 포함할 수도 있다. 일 구현에서, NPU는 CPU, DSP, 및/또는 GPU에서 구현된다. SOC는 또한, 센서 프로세서, 이미지 신호 프로세서들(ISP들), 및/또는 글로벌 포지셔닝 시스템 을 포함할 수도 있는 내비게이션 모듈을 포함할 수도 있다. SOC는 ARM 명령 세트에 기초할 수도 있다. 본 개시의 양태들에서, 범용 프로세서로 로딩된 명령들은, 수행될 태스크들의 세트를 수신하기 위한 코드를 포함할 수도 있다. 범용 프로세서는 또한, 에 지들에 의해 연결된 다중의 노드들을 포함하는 그래프에서 태스크들을 표현하기 위한 코드를 포함할 수도 있다. 각각의 노드는 태스크들의 세트에서의 태스크에 대응한다. 범용 프로세서는 또한, 그래프에서의 각각의 노드에 스케줄링 우선순위를 배정하기 위한 코드를 포함할 수도 있다. 범용 프로세서는 또한, 배정된 스 케줄링 우선순위들 및 그래프의 토폴로지에 기초하여 잠재적 다음 노드들의 각각의 확률에 따라 잠재적 다음 노 드들 중의 다음 노드를 선택하기 위한 코드를 포함할 수도 있다. 범용 프로세서는 또한, 다음 노드의 선 택을 반복함으로써 태스크들의 토폴로지 순서를 생성하기 위한 코드를 포함할 수도 있다. 딥 러닝 아키텍처들은 각각의 계층에서의 추상화의 연속적으로 더 높은 레벨들에서 입력들을 표현하도록 학습함 으로써 오브젝트 인식 태스크를 수행하고, 이것에 의해, 입력 데이터의 유용한 피처 표현을 구축할 수도 있다. 이러한 방식으로, 딥 러닝은 종래의 머신 러닝의 주요 병목 현상을 다룬다. 딥 러닝의 출현 이전에, 오브젝트 인식 문제에 대한 머신 러닝 접근법은 아마도 얕은 분류기(shallow classifier)와 조합하여, 인간 조작식 피처 들에 과도하게 의존하였을 수도 있다. 얕은 분류기는, 예를 들어, 입력이 어느 클래스에 속하는지를 예측하기 위해, 피처 벡터 컴포넌트들의 가중화된 합이 임계치와 비교될 수도 있는 2클래스 선형 분류기일 수도 있다. 인간 조작식 피처들은 도메인 전문지식을 갖는 공학자들에 의해 특정 문제 도메인에 맞춤화된 템플릿들 또는 커 널들일 수도 있다. 이에 반하여, 딥 러닝 아키텍처들은, 인간 공학자가 설계할 수도 있는 것과 유사한 피처들 을 표현하도록 학습할 수도 있지만, 트레이닝을 통해 학습할 수도 있다. 더욱이, 딥 네트워크는 인간이 고려하 지 않았을 수도 있는 새로운 타입들의 피처들을 표현 및 인식하도록 학습할 수도 있다. 딥 러닝 아키텍처는 피처들의 계위를 학습할 수도 있다. 시각적 데이터가 제시되면, 예를 들어, 제1 계층은 입 력 스트림에서 에지들과 같은 상대적으로 간단한 피처들을 인식하도록 학습할 수도 있다. 다른 예에서, 청각적 데이터가 제시되면, 제1 계층은 특정 주파수들에서의 스펙트럼 전력을 인식하도록 학습할 수도 있다. 제1 계층 의 출력을 입력으로서 취하는 제2 계층은 시각적 데이터를 위한 간단한 형상들 또는 청각적 데이터를 위한 사운 드들의 조합들과 같은 피처들의 조합들을 인식하도록 학습할 수도 있다. 예를 들어, 더 상위 계층들은 시각적 데이터에서의 복잡한 형상들 또는 청각적 데이터에서의 단어들을 표현하도록 학습할 수도 있다. 훨씬 더 상위 계층들은 공통의 시각적 오브젝트들 또는 발화된 어구들을 인식하도록 학습할 수도 있다. 딥 러닝 아키텍처들은, 자연적 계위 구조를 갖는 문제들에 적용될 때에 특히 잘 수행할 수도 있다. 예를 들어, 전동 차량들의 분류는 휠, 윈드실드, 및 다른 피처들을 인식하기 위한 첫번째 학습으로부터 이익을 얻을 수도 있다. 이들 피처들은 자동차, 트럭, 및 비행기를 인식하기 위하여 상이한 방식들로 더 상위 계층들에서 결합될 수도 있다. 뉴럴 네트워크들은 다양한 연결성 패턴들로 설계될 수도 있다. 피드-포워드 네트워크들에 있어서, 정보는 하위 계층으로부터 상위 계층으로 전달되고, 주어진 계층에서의 각각의 뉴런은 더 상위 계층들에서의 뉴런들에 통신 한다. 계위적 표현은, 상기에서 설명된 바와 같이, 피드-포워드 네트워크의 연속적인 계층들에서 구축될 수도 있다. 뉴럴 네트워크들은 또한, 재귀적(recurrent) 또는 피드백(또한 하향식 (top-down)으로 지칭됨) 연결들을가질 수도 있다. 재귀적 연결에 있어서, 주어진 계층에서의 뉴런으로부터의 출력은 동일한 계층에서의 다른 뉴 런에 통신될 수도 있다. 재귀적 아키텍처는, 뉴럴 네트워크에 순차적으로 전달되는 입력 데이터 청크들 중 하 나 초과에 걸쳐 있는 패턴들을 인식하는데 도움이 될 수도 있다. 주어진 계층에서의 뉴런으로부터 더 하위 계 층에서의 뉴런으로의 연결은 피드백(또는 하향식) 연결로 칭해진다. 하이-레벨 개념의 인식이 입력의 특정 로 우-레벨 피처들을 구별하는 것을 보조할 수도 있을 경우, 다수의 피드백 연결들을 갖는 네트워크가 도움이 될 수도 있다. 뉴럴 네트워크의 계층들 사이의 연결들은 완전히 연결될 수도 있거나, 로컬로 연결될 수도 있다. 도 2a는 완전 히 연결된 뉴럴 네트워크의 일 예를 예시한다. 완전히 연결된 뉴럴 네트워크에서, 제1 계층에서의 뉴런은 그의 출력을 제2 계층에서의 모든 뉴런에 통신할 수도 있어서, 제2 계층에서의 각각의 뉴런은 제1 계층 에서의 모든 뉴런으로부터 입력을 수신할 것이다. 도 2b는 로컬로 연결된 뉴럴 네트워크의 일 예를 예시 한다. 로컬로 연결된 뉴럴 네트워크에서, 제1 계층에서의 뉴런은 제2 계층에서의 제한된 수의 뉴런들에 연결될 수도 있다. 더 일반적으로, 로컬로 연결된 뉴럴 네트워크의 로컬로 연결된 계층은, 계층에서의 각 각의 뉴런이 동일한 또는 유사한 연결성 패턴을 가질 것이지만, 상이한 값들(예컨대, 210, 212, 214, 및 216)을 가질 수도 있는 연결 강도들을 갖도록 구성될 수도 있다. 주어진 영역에서의 더 상위 계층 뉴런들이 네트워크 에 대한 총 입력의 한정된 부분의 특성들에 대한 트레이닝을 통해 튜닝되는 입력들을 수용할 수도 있기 때문에, 로컬로 연결된 연결성 패턴은 더 상위 계층에서의 공간적으로 별개의 수용 필드들을 야기할 수도 있다. 로컬로 연결된 뉴럴 네트워크의 일 예는 컨볼루셔널 뉴럴 네트워크이다. 도 2c는 컨볼루셔널 뉴럴 네트워크 의 일 예를 예시한다. 컨볼루셔널 뉴럴 네트워크는, 제2 계층에서의 각각의 뉴런에 대한 입력들과 연관된 연결 강도들이 공유되도록 구성될 수도 있다(예컨대, 208). 컨볼루셔널 뉴럴 네트워크들은, 입력들의 공간적 위치가 의미있는 문제들에 매우 적합할 수도 있다. 컨볼루셔널 뉴럴 네트워크의 하나의 타입은 딥 컨볼루셔널 네트워크(DCN)이다. 도 2d는, 자동차 장착 카메라와 같은 이미지 캡처링 디바이스로부터 입력된 이미지로부터 시각적 피처들을 인식하도록 설계된 DCN의 상세한 예를 예시한다. 본 예의 DCN은 트래픽 사인(sign)들 및 트래픽 사인 상에 제공된 숫자 를 식별하도록 트레이닝될 수도 있다. 물론, DCN은, 차선 마킹들을 식별하는 것 또는 트래픽 신호등들을 식별하는 것과 같은 다른 태스크들에 대해 트레이닝될 수도 있다. DCN은 지도형 학습(supervised learning)으로 트레이닝될 수도 있다. 트레이닝 동안, DCN에는, 속 도 제한 사인의 이미지와 같은 이미지가 제시될 수 있고, 그 다음, 순방향 패스가 컴퓨팅되어 출력을 생성할 수도 있다. DCN은 피처 추출 섹션 및 분류 섹션을 포함할 수도 있다. 이미지를 수신할 시, 컨볼루셔널 계층은 피처 맵들의 제1 세트를 생성하기 위해 컨볼루셔널 커널들(도시되지 않음)을 이미 지에 적용할 수도 있다. 일 예로서, 컨볼루셔널 계층에 대한 컨볼루셔널 커널은 28x28 피처 맵들을 생성하는 5x5 커널일 수도 있다. 본 예에서, 4개의 상이한 피처 맵들이 피처 맵들의 제1 세트에서 생성되 기 때문에, 4개의 상이한 컨볼루셔널 커널들이 컨볼루셔널 계층에서 이미지에 적용되었다. 컨볼루셔 널 커널들은 또한, 필터들 또는 컨볼루셔널 필터들로서 지칭될 수도 있다. 피처 맵들의 제1 세트는 피처 맵들의 제2 세트를 생성하기 위해 최대 풀링(pooling) 계층(도시 안 됨)에 의해 서브샘플링될 수도 있다. 최대 풀링 계층은 피처 맵들의 제1 세트의 사이즈를 감소시킨다. 즉, 14x14와 같은 피처 맵들의 제2 세트의 사이즈는 28x28과 같은 피처 맵들의 제1 세트의 사이즈보 다 작다. 감소된 사이즈는, 메모리 소비를 감소시키면서 후속 계층에 유사한 정보를 제공한다. 피처 맵들의 제2 세트는, 피처 맵들의 하나 이상의 후속 세트들(도시 안됨)을 생성하기 위해 하나 이상의 후속 컨볼루 셔널 계층들(도시 안됨)을 통해 추가로 컨볼루션될 수도 있다. 도 2d의 예에서, 피처 맵들의 제2 세트는 제1 피처 벡터를 생성하도록 컨볼루션된다. 더욱이, 제1 피처 벡터는 제2 피처 벡터를 생성하도록 추가로 컨볼루션된다. 제2 피처 벡터의 각각의 피처 는 \"사인\", \"60\", 및 \"100\"과 같은 이미지의 가능한 피처에 대응하는 숫자를 포함할 수도 있다. 소프트맥 스 함수(softmax function)(도시 안됨)는 제2 피처 벡터에서의 숫자들을 확률로 변환할 수도 있다. 이와 같이, DCN의 출력은, 하나 이상의 피처들을 포함하는 이미지의 확률이다. 본 예에서, \"사인\" 및 \"60\"에 대한 출력에서의 확률들은 \"30\", \"40\", \"50\", \"70\", \"80\", \"90\" 및 \"100\"과 같은 출력의 다른 것들의 확률들보다 높다. 트레이닝 전에, DCN에 의해 생성된 출력은 부정확 할 가능성이 있을 수도 있다. 따라서, 출력과 타겟 출력 사이에서 에러가 계산될 수도 있다. 타겟 출력 은 이미지의 실측 자료(ground truth)(예컨대, \"사인\" 및 \"60\")이다. 그 다음, DCN의 가중치들은,DCN의 출력이 타겟 출력과 더 밀접하게 정렬되도록 조정될 수도 있다. 가중치들을 조정하기 위해, 학습 알고리즘은 가중치들에 대한 그래디언트 벡터를 컴퓨팅할 수도 있다. 그래디 언트는, 가중치가 조정되었으면 에러가 증가 또는 감소할 양을 표시할 수도 있다. 상부 계층에서, 그래디언트 는 마지막에서 두 번째 계층에서의 활성화된 뉴런과 출력 계층에서의 뉴런을 연결하는 가중치의 값에 직접적으 로 대응할 수도 있다. 하위 계층들에 있어서, 그래디언트는 가중치들의 값에, 그리고 상위 계층들의 컴퓨팅된 에러 그래디언트들에 의존할 수도 있다. 그 다음, 가중치들은 에러를 감소시키도록 조정될 수도 있다. 가중치 들을 조정하는 이러한 방식은, 뉴럴 네트워크를 통한 \"역방향(backward) 패스\"를 수반하기 때문에, \"역 전파\"로 서 지칭될 수도 있다. 실제로, 가중치들의 에러 그래디언트는 적은 수의 예들에 걸쳐 계산될 수도 있어서, 계산된 그래디언트는 실제 에러 그래디언트에 근사한다. 이러한 근사화 방법은 확률적 그래디언트 하강으로서 지칭될 수도 있다. 확률적 그래디언트 하강은, 전체 시스템의 달성가능한 에러 레이트가 감소하는 것을 정지하였을 때까지 또는 에러 레이 트가 타겟 레벨에 도달하였을 때까지 반복될 수도 있다. 학습 이후, DCN은 새로운 이미지들을 제시받을 수도 있고, DCN을 통한 순방향 패스는 DCN의 추론 또는 예측으로 고려될 수도 있는 출력을 산출 할 수도 있다. 심층 신뢰 네트워크들(DBN들)은 은닉된 노드들의 다중의 계층들을 포함하는 확률 모델들이다. DBN들은 트레이 닝 데이터 세트들의 계위적 표현을 추출하기 위해 사용될 수도 있다. DBN은 제한된 볼쯔만 머신들(Restricted Boltzmann Machines; RBM들)의 계층들을 적층함으로써 획득될 수도 있다. RBM은 입력들의 세트에 걸친 확률 분 포를 학습할 수 있는 인공 뉴럴 네트워크의 일 타입이다. RBM들은 각각의 입력이 카테고리화되어야 하는 클래 스에 관한 정보의 부존재 시에 확률 분포를 학습할 수 있기 때문에, RBM들은 종종 비지도형(unsupervised) 학습 에서 사용된다. 하이브리드 비지도형 및 지도형 패러다임을 사용하여, DBN의 저부 RBM들은 비지도형 방식으로 트레이닝될 수도 있고 피처 추출기들로서 작용할 수도 있고, 상부 RBM은 (이전의 계층 및 타겟 클래스들로부터 의 입력들의 공동 분포 상에서) 지도형 방식으로 트레이닝될 수도 있고 분류기로서 작용할 수도 있다. DCN들은 추가적인 풀링 및 정규화 계층들로 구성된 컨볼루셔널 네트워크들의 네트워크들이다. DCN들은 다수의 태스크들에 대한 최신 기술의 성능을 달성하였다. DCN들은 입력 및 출력 타겟 양자 모두가 다수의 견본 (exemplar)들에 대해 공지되고 그리고 그래디언트 하강 방법들의 사용에 의해 네트워크의 가중치들을 수정하는 데 이용되는 지도형 학습을 사용하여 트레이닝될 수 있다. DCN들은 피드-포워드 네트워크들일 수도 있다. 부가적으로, 상기에서 설명된 바와 같이, DCN의 제1 계층에서의 뉴런으로부터 다음의 더 상위 계층에서의 뉴런들의 그룹으로의 연결들은 제1 계층에서의 뉴런들에 걸쳐 공유된 다. DCN들의 피드-포워드 및 공유된 연결들은 고속 프로세싱을 위해 활용될 수도 있다. DCN의 연산 부담은, 예를 들어, 재귀적 또는 피드백 연결들을 포함한 유사하게 사이징된 뉴럴 네트워크의 연산 부담보다 훨씬 더 적 을 수도 있다. 컨볼루셔널 네트워크의 각각의 계층의 프로세싱은 공간적으로 불변인 템플릿 또는 베이시스 투영(basis projection)으로 고려될 수도 있다. 입력이 컬러 이미지의 적색, 녹색, 및 청색 채널들과 같은 다중의 채널들 로 먼저 분해되면, 그 입력에 대해 트레이닝된 컨볼루셔널 네트워크는, 이미지의 축들에 따른 2개의 공간 차원 들 및 컬러 정보를 캡처하는 제3의 차원을 갖는 3차원으로 고려될 수도 있다. 컨볼루셔널 연결들의 출력들은 후속 계층에서 피처 맵을 형성하도록 고려될 수도 있고, 피처 맵(예컨대, 220)의 각각의 엘리먼트는 이전의 계 층 (예컨대, 피처 맵들)에서의 뉴런들의 범위로부터, 그리고 다중의 채널들의 각각으로부터 입력을 수신한 다. 피처 맵에서의 값들은, 교정(rectification), max(0,x)와 같이, 비선형성으로 추가로 프로세싱될 수도 있 다. 인접한 뉴런들로부터의 값들은 추가로 풀링될 수도 있는데, 이는 다운 샘플링에 대응하고, 추가적인 로컬 불변성 및 차원성 감소를 제공할 수도 있다. 화이트닝(whitening)에 대응하는 정규화는 또한, 피처 맵에서의 뉴런들 사이의 측방향 억제를 통해 적용될 수도 있다. 딥 러닝 아키텍처들의 성능은, 더 많은 라벨링된 데이터 포인트들이 이용가능해짐에 따라 또는 연산력이 증가함 에 따라 증가할 수도 있다. 최신의 딥 뉴럴 네트워크들은 단지 15년 전에 전형적인 연구자에 의해 이용가능하 였던 것보다 수천배 더 큰 컴퓨팅 리소스들로 일상적으로 트레이닝된다. 새로운 아키텍처들 및 트레이닝 패러 다임들은 딥 러닝의 성능을 추가로 상승시킬 수도 있다. 교정된 선형 유닛들은 소실(vanishing) 그래디언트들 로서 공지된 트레이닝 문제를 감소시킬 수도 있다. 새로운 트레이닝 기법들은 오버-피팅(over-fitting)을 감소 시킬 수도 있고, 따라서, 더 큰 모델들이 더 양호한 일반화를 달성할 수 있게 할 수도 있다. 캡슐화 기법들은 주어진 수용 필드에서 데이터를 추상화할 수도 있고, 전체 성능을 추가로 상승시킬 수도 있다.도 3은 DCN을 예시한 블록 다이어그램이다. 딥 컨볼루셔널 네트워크는 연결성 및 가중치 공유에 기 초한 다중의 상이한 타입들의 계층들을 포함할 수도 있다. 도 3에 도시된 바와 같이, 딥 컨볼루셔널 네트워크 는 컨볼루션 블록들(354A, 354B)을 포함한다. 컨볼루션 블록들(354A, 354B)의 각각은 컨볼루션 계층 (CONV), 정규화 계층(LNorm), 및 최대 풀링 계층(MAX POOL)으로 구성될 수도 있다. 컨볼루션 블록들(354A, 354B) 중 오직 2개만이 도시되어 있지만, 본 개시는 그렇게 제한되지는 않으며, 대신, 임의의 수 의 컨볼루션 블록들(354A, 354B)이 설계 선호도에 따라 딥 컨볼루셔널 네트워크에 포함될 수도 있다. 컨볼루션 계층들은 피처 맵을 생성하기 위해 입력 데이터에 적용될 수도 있는 하나 이상의 컨볼루셔널 필 터들을 포함할 수도 있다. 정규화 계층은 컨볼루션 필터들의 출력을 정규화할 수도 있다. 예를 들어, 정 규화 계층은 화이트닝 또는 측방향 억제를 제공할 수도 있다. 최대 풀링 계층들은 로컬 불변성 및 차원성 감소를 위해 공간에 걸친 다운 샘플링 어그리게이션을 제공할 수도 있다. 예를 들어, 딥 컨볼루셔널 네트워크의 병렬 필터 뱅크들이 고성능 및 저전력 소비를 달성하기 위해 SOC의 CPU 또는 GPU (예컨대, 도 1) 상에 로딩될 수도 있다. 대안적인 실시형태들에 있어서, 병렬 필터 뱅 크들이 SOC의 DSP 또는 ISP 상에 로딩될 수도 있다. 부가적으로, 딥 컨볼루셔널 네트워크(35 0)는, 센서들 및 내비게이션에 각각 전용되는 센서 프로세서 및 내비게이션 모듈과 같은, SOC 상에 존재할 수도 있는 다른 프로세싱 블록들에 액세스할 수도 있다. 딥 컨볼루셔널 네트워크는 또한, 하나 이상의 완전히 연결된 계층들(FC1 및 FC2)을 포함할 수도 있다. 딥 컨볼루셔널 네트워크는 로지스틱 회귀(LR) 계층을 더 포함할 수도 있다. 딥 컨볼루셔널 네트워크의 각각의 계층(356, 358, 360, 362, 364) 사이에는 업데이트될 가중치들(도시 안됨)이 있다. 계 층들(예컨대, 356, 358, 360, 362, 364)의 각각의 출력은, 컨볼루션 블록들(354A) 중 제1 컨볼루션 블록에서 공 급되는 입력 데이터(예컨대, 이미지들, 오디오, 비디오, 센서 데이터 및/또는 다른 입력 데이터)로부터 계 위적 피처 표현들을 학습하기 위해 딥 컨볼루셔널 네트워크에서 계층들(예컨대, 356, 358, 360, 362, 364) 중 후속하는 계층의 하나의 입력으로서 작용할 수도 있다. 딥 컨볼루셔널 네트워크의 출력은 입력 데이터 에 대한 분류 스코어이다. 분류 스코어는 확률들의 세트일 수도 있으며, 여기서, 각각의 확률 은 피처들의 세트로부터의 피처를 포함하는, 입력 데이터의 확률이다. 도 4는 인공 지능(AI) 함수들을 모듈화할 수도 있는 예시적인 소프트웨어 아키텍처를 예시한 블록 다이어 그램이다. 아키텍처를 사용하여, 본 개시의 양태들에 따라, SOC의 다양한 프로세싱 블록들(예를 들 어, CPU, DSP, GPU 및/또는 NPU)(이는 도 1의 SoC와 유사할 수도 있음)로 하여금 AI 어플리케이션에 대한 뉴럴 토폴로지 순서화를 지원하게 할 수도 있는 어플리케이션들이 설계될 수도 있다. 아키텍처는, 예를 들어, 스마트폰과 같은 연산 디바이스에 포함될 수도 있다. AI 어플리케이션은, 예를 들어, 아키텍처를 포함하는 연산 디바이스가 현재 동작하는 위치를 표시하 는 장면의 검출 및 인식을 제공할 수도 있는 사용자 공간에서 정의된 함수들을 호출하도록 구성될 수도 있 다. AI 어플리케이션은, 예를 들어, 인식된 장면이 사무실, 강당, 식당, 또는 호수와 같은 실외 세팅인지 여부에 의존하여 상이하게 마이크로폰 및 카메라를 구성할 수도 있다. AI 어플리케이션은, AI 함수 어플 리케이션 프로그래밍 인터페이스(API)에서 정의된 라이브러리와 연관된 컴파일링된 프로그램 코드에 대한 요청을 행할 수도 있다. 이 요청은, 예를 들어, 비디오 및 포지셔닝 데이터에 기초하여 추론 응답을 제공하도 록 구성된 딥 뉴럴 네트워크의 출력에 궁극적으로 의존할 수도 있다. 런타임 프레임워크의 컴파일링된 코드일 수도 있는 런타임 엔진은 AI 어플리케이션에 추가로 액세스 가능할 수도 있다. AI 어플리케이션은 런타임 엔진으로 하여금, 예를 들어, 특정 시간 인터벌로, 또 는 AI 어플리케이션의 사용자 인터페이스에 의해 검출된 이벤트에 의해 트리거링되는 추론을 요청하게 할 수도 있다. 추론 응답을 제공하도록 야기될 때, 런타임 엔진은, 차례로, SOC 상에서 구동하는 커널 과 같은 오퍼레이팅 시스템(OS) 공간에서의 오퍼레이팅 시스템으로 신호를 전송할 수도 있다. 일부 예들에서, 커널은 리눅스 커널일 수도 있다. 오퍼레이팅 시스템 은, 차례로, 양자화의 지속적 완화 가 CPU, DSP, GPU, NPU, 또는 이들의 일부 조합 상에서 수행되게 할 수도 있다. CPU는 오퍼레이팅 시스템에 의해 직접 액세스될 수도 있고, 다른 프로세싱 블록들은 DSP, GPU, 또는 NPU 각각을 위한 구동기(414, 416, 또는 418)와 같은 구동기를 통해 액세스될 수도 있다. 예시적인 예에서, 딥 뉴럴 네트워크는 CPU, DSP, 및 GPU와 같은 프로세싱 블록들의 조합 상에서 구동하도 록 구성될 수도 있거나, 또는 NPU 상에서 구동될 수도 있다. 어플리케이션(예컨대, AI 어플리케이션)은, 예를 들어, 디바이스가 현재 동작하는 위치를 표시하는 장면의 검출 및 인식을 제공할 수도 있는 사용자 공간에서 정의된 함수들을 호출하도록 구성될 수도 있다. 어플 리케이션은, 예를 들어, 인식된 장면이 사무실, 강당, 식당, 또는 호수와 같은 실외 세팅인지 여부에 의존 하여 상이하게 마이크로폰 및 카메라를 구성할 수도 있다. 어플리케이션은 현재 장면의 추정치를 제공하 기 위해 SceneDetect 어플리케이션 프로그래밍 인터페이스(API)에서 정의된 라이브러리와 연관된 컴파일링 된 프로그램 코드에 대한 요청을 행할 수도 있다. 이 요청은, 예를 들어, 비디오 및 포지셔닝 데이터에 기초하 여 장면 추정치들을 제공하도록 구성된 차동 뉴럴 네트워크의 출력에 궁극적으로 의존할 수도 있다. 런타임 프레임워크의 컴파일링된 코드일 수도 있는 런타임 엔진은 어플리케이션에 추가로 액세스가능 할 수도 있다. 어플리케이션은 런타임 엔진으로 하여금, 예를 들어, 특정 시간 인터벌로, 또는 어플리케 이션의 사용자 인터페이스에 의해 검출된 이벤트에 의해 트리거링되는 장면 추정치를 요청하게 할 수도 있다. 장면을 추정하도록 야기될 때, 런타임 엔진은, 차례로, SOC 상에서 구동하는 리눅스 커널과 같은 오 퍼레이팅 시스템으로 신호를 전송할 수도 있다. 오퍼레이팅 시스템은, 차례로, 연산이 CPU, DSP, GPU, NPU, 또는 이들의 일부 조합 상에서 수행되게 할 수도 있다. CPU는 오퍼레이 팅 시스템에 의해 직접 액세스될 수도 있고, 다른 프로세싱 블록들은 DSP를 위한, GPU를 위한, 또는 NPU를 위한 구동기(414-418)와 같은 구동기를 통해 액세스될 수도 있다. 예시적인 예에서, 차동 뉴럴 네 트워크는 CPU 및 GPU와 같은 프로세싱 블록들의 조합 상에서 구동하도록 구성될 수도 있거나, 또는 NPU 상에서 구동될 수도 있다. 설명된 바와 같이, 본 개시의 양태들은 인공 뉴럴 네트워크를 사용한 토폴로지 순서화에 관한 것이다. 본 개시 의 양태들에 따르면, 태스크들의 시퀀스에 대한 우선순위 제약들은, 예를 들어, 방향성 비순환 그래프와 같은 그래프를 통해 표현될 수도 있다. 방향성 그래프는 튜플 G = (V, E)이며, 여기서, V 는 정점들의 세트이고, E ⊆ V × V는 정점들 사이의 에지들의 세트이다. 튜플은 엘리먼트들의 유한한 순서화된 리스트 또는 시퀀스이다. 사이클은, 적어도 하나의 방향성 에지를 갖는 에지들의 세트( )이다. 따라서, 방향성 비 순환 그래프(DAG)는, 직접 사이클들이 없는 유한한 방향성 그래프이다. 그 그래프는, 에지들에 의해 연결된 노 드들의 세트를 포함할 수도 있다. 노드들의 각각은 수행될 태스크를 표현할 수도 있고, 에지들은, 표현된 태스 크들을 수행하기 위한 순서를 표시할 수도 있다. 부분 순서는 세트(V)의 특정 쌍들 사이의 비반사적 추이적(irreflexive transitive) 관계(<)이다. <에 의해 관 계되는 쌍( V x V)은, 비교가능인 것으로서 지칭되고, 그렇지 않으면, 비교불가능이다. DAG(G = (V, E))는 부분적으로 순서화된 세트(V, <)에 맵핑될 수도 있으며, 여기서, 노드 x로부터 노드 y로의 방향성 경로가 존재하면 x < y이다. 다중의 DAG들이 동일한 부분 순서에 맵핑될 수도 있다. 예를 들어, 정점 세트({x, y, z}) 및 에지 세트들(E = {x → y, y → z} 및 E' = {x → y, y → z, x → z})을 갖는 DAG들 - 여기서, s → t 는 s로부터 t로의 방향성 에지에 대응함 - 은 동일한 부분 순서(x < y < z)에 대응한다. DAG의 추이적 폐포 (transitive closure; TC)는, x < y일 때마다 방향성 에지(x, y)가 존재하도록, 동일한 기본적 부분 순서를 가 지는 최대 에지들을 갖는 그래프로서 정의될 수도 있다. 이에 반하여, 추이적 감소(TR)는, 동일한 부분 순서를 초래하는 최소 에지들을 갖는 그래프로서 정의될 수도 있다. DAG에 의해 유도되는 순서는 <G로 표기된다. DAG(G)의 토폴로지 순서 또는 소팅은, 일 때마다 이도록 전단사함수( )로 간주될 수도 있다. G의 토폴로지 순서들의 세트( )는 정점들의 순열 그룹의 서브세트이며, 부분 순서의 선형 확장들로 지칭되는, <G에 따르는 V에 대한 전체 순서들과 일치한다. 뉴럴 네트워크를 표현하는 연산 그래프에서 동작들의 스케줄을 결정하는 것은 컴파일러들에서 주요 문제이다. DAG는, 노드들이 동작들(\"ops\")을 표현하고 인커밍/아웃고잉 에지들이 이들 동작들의 오퍼랜드들/결과들을 표현 하는 방식으로 연산 그래프와 연관될 수도 있다. 동작이 실행될 때마다, 그 동작에 대한 입력들이 메모리에 저 장되고, 출력들에 대한 메모리가 할당되어야 한다. 따라서, DAG의 각각의 노드는, 그 동작의 출력을 저장하기 위한 메모리를 명시하는 라벨( )을 보유한다. DAG를 스케줄링함에 있어서의 제1 단계는 동작들을 실 행하기 위한 토폴로지 순서들을 식별하는 것이다. 제한된 메모리를 갖는 에지 디바이스들을 위한 컴파일러들은, 피크 메모리 풋프린트를 최소화하는 토폴로지 순서를 선택하는 것을 목표로 할 수도 있다. 일부 양태들에서, 토폴로지 순서는 피크 로컬 메모리 사용량을 감소시키도록 결정될 수도 있다. 예를 들어, 이 태스크는 라벨링된 DAG(G = (V, E, m))에 대해 다음의 조합 최적화 문제로서 공식화될 수도 있다:"}
{"patent_id": "10-2024-7036702", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 다음의 정의들을 가지며,"}
{"patent_id": "10-2024-7036702", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, 시간 t에서의 메모리 사용량은 다운스트림 동작들에 의해 시간 t-1에서 아직 소비되지 않은 출력들의 메모리 사용량( ) 플러스 동작들의 출력( )의 메모리 활용도에 의해 주어진다. 차례로, 값(It)은 로부 터, 아웃고잉 에지들이 이미 스케줄링된 노드들(예컨대, 출력이 이미 스케줄링된 동작들에 의해서만 사용되는 노드들)에만 연결되는 노드들의 메모리 비용들을 감산함으로써 획득된다. 자연스럽게, 이다. 도 5는 본 개시의 양태들에 따른, 토폴로지 순서를 결정하기 위한 예시적인 아키텍처를 예시한 블록 다이 어그램이다. 아키텍처는 인코더 및 디코더를 포함한다. 인코더는 어텐션 기반 그래프 뉴 럴 네트워크로서 구성될 수도 있다. 인코더는, 그래프(G)의 각각의 노드에 대한 임베딩을 도출하는 데 사용될 수도 있는 멀티-헤드 어텐션 계층들의 세트를 포함할 수도 있다. 그래프(G)는, 예를 들어, DAG 를 포함할 수도 있다. 노드 임베딩들은 디코더에 공급될 수도 있고, 시퀀스 공간에서의 분포를 생성하는 데 사용될 수도 있다. 그 분포는, 예를 들어, 샘플링 추론, 그리디(greedy) 추론, 또는 빔 탐색과 같은 추론 방법을 사용하여 시퀀스로 변환될 수도 있다. 그래프 뉴럴 네트워크(GNN)는 그래프(G) 노드들의 임베딩을 통해 스케줄링 문제를 인코딩할 수도 있다. GNN 아 키텍처들은, 일반적으로, 그들 자신의 임베딩의 일부 함수의 형태로, 다른 노드들로부터 전송된 \"메시지들\"의 어그리게이션을 통해 이들 임베딩들을 업데이트함으로써 동작할 수도 있다. 본 개시의 양태들에 따르면, 인코더는 입력 피처들의 벡터()를 취하고, 노드별 선형 변환 ( )을 통해 초기 노드 임베딩(h)을 생성한다. 후속하여, L개의 어텐션 계층들의 연속으로서, 이들의 각각은 멀티-헤드 어텐션(MHA) 서브계층과 뒤이어 이들 임베딩들을 업데이트하는 노드별 다층 퍼셉트론 (MLP)을 포함한다. 토폴로지 유도성 바이어스는, 오리지널 그래프(G)에 의해 유도된 다음의 그래프 들의 각각에 의해 마스킹된 하나 이상의 어텐션 헤드들(예컨대, 508a-g)의 별도의 그룹을 가짐으로써 임베딩 업 데이트들에 적용될 수도 있다. 예를 들어, 도 5의 예에서 도시된 바와 같이, MHA들(508a-d)은, MHA들이 그래프 (G)의 토폴로지 변환들의 순방향 버전들(510a-d)에 대해 각각 어떻게 별도로 동작할 수 있는지를 표시하기 위해 음영처리된다. 한편, MHA들(508e-g)은, MHA들이 그래프(G)의 토폴로지 변환들의 역방향 버전들(510a-c)에 대해 각각 어떻게 별도로 동작할 수 있는지를 표시하기 위해 역음영처리된다. 그렇게 함에 있어서, 인코더는 그래프(G)(예컨대, 516)의 상이한 토폴로지 변환들 상에 메시지들을 전달하 기 위해 노드 임베딩들을 생성할 수도 있다. 토폴로지 변환들은 초기 그래프(G)(예컨대, 516), 추이적 감소(예 컨대, 510a), 추이적 폐포(예컨대, 510c), 및 비교불가능 노드 쌍들(예컨대, 510d)을 포함할 수도 있다. 추이 적 감소(TR)는, TR 에지들(예컨대, 510c)을 제거함으로써 획득된 방향성 그래프를 산출하도록 수행될 수도 있다. 결과적인 방향성 그래프(예컨대, 510c)는, 그래프(G)로부터의 노드들 사이의 도달가능성 관계(예컨대, 부분 순서)에 영향을 주지 않고 가능한 한 많은 에지들을 제거함으로써 생성될 수도 있다: . 추이적 폐 포 변환은, 노드들 사이의 도달가능성 관계(예컨대, 부분 순서)에 영향을 주지 않고 가능한 한 많은 에지들을 추가하는 것을 목표로 한다. 추이적 폐포(TC) 변환을 적용하는 것은, 그의 TC로부터의 그래프(G)의 에지들을 제거함으로써 획득된 방향성 그래프를 산출할 수도 있다: . 비교불가능 노드 쌍 변환은, 우선순위 관계 를 갖지 않는 모든 노드들을 보존한다. 비교불가능 노드 쌍 변환을 적용하면, 모든 비교불가능 노드 쌍들을 결 합함으로써 무방향성 그래프가 획득될 수도 있다. 부가적으로, 토폴로지 변환들은, TR 변환 및 TC 변환으로부터 초래되는 그래프들의 각각의 역을 포함할 수도 있 다. 그래프들(510a-c)의 역 또는 역방향 버전들은, 각각의 그래프(510a-c)의 에지들(예컨대, 노드들을 연결하 는 화살표들의 방향)을 플립핑함으로써 획득될 수도 있다. 이들 토폴로지 변환된 그래프들(예컨대, 510a-d) 및 토폴로지 변환된 그래프들의 역(520a-c)을 가산함으로써, 노드 세트(V)에 대해 완전히 연결된 그래프가 획득될 수도 있으며, 여기서, 모든 노드들은 모든 노드들에 어텐 션한다. 그 다음, 효과적으로, 인코더의 전파 규칙들은 다음이 되도록 될 수도 있다:"}
{"patent_id": "10-2024-7036702", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 는, 헤드(j)(예컨대, MHA(508a-g))가 오직 그의 배정된 그래프(예컨대, 토폴로지 변환된 그래프 (510a-d))에만 어텐션하는 것을 보장하는 마스크이다. 계층 정규화는 MHA(예컨대, 508a-g) 및 MLP(예컨대, 506a-b) 입력들에 적용될 수도 있다. 각각의 토폴로지 변환된 그래프(510a-d)에 배정된 어텐션 헤드들(예컨대, MHA(508a-g))의 수는 독립적으로 선택될 수도 있거나(예컨대, 제로로 설정하는 것은 개별 그래프의 에지들을 따 라 메시지 전달하지 않음을 의미함), 파라미터들은 상이한 MHA들(예컨대, 508a-g) 사이에서 묶이거나 공유될 수 도 있다. 노드들의 각각은 서로의 표현에 영향을 미치는 동안, 또한, 그래프(G)(예컨대, 516) 구조에 기초하여 강한 유도성 바이어스를 주입할 수도 있다. 디코더는 그래프(G)의 유효한 토폴로지 순서들에 대해 확률적 정책( )을 도출할 수도 있다. 예를 들어, 확률적 정책( )은 다음에 의해 주어질 수도 있다:"}
{"patent_id": "10-2024-7036702", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "각각의 단계에서 새로운 노드를 자기회귀적으로 선택함으로써 완전한 시퀀스가 샘플링될 수 있다. 하지만, 그 렇게 하는 것은, 뉴럴 네트워크(NN)가 에 대한 함수 근사자로서 사용될 때 이 NN에 대한 호출들이 수행 될 것을 또한 요구하며 이는 채용된 연산의 양으로 인해 그 실행가능성을 비교적 작은 그래프들로 제한하기 때 문에, 매우 시간 소모적이다. 이에 따라, 큰 그래프들로 스케일링하기 위해, NN 호출들의 수를 그래프 사이즈로부터 디커플링하는 비-자기회 귀(NAR) 접근법이 채용될 수도 있다. 스케줄링 확률들보다는, 스케줄링 우선순위들( )이 노드들에 배정될 수도 있다. 노드(i)에 대한 우선순위가, MLP를 통해 그의 최종 임베딩을 전달함으로써 도출될 수도 있다:"}
{"patent_id": "10-2024-7036702", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "예를 들어, 도 5에 도시된 바와 같이, MHA(508a-g)의 출력들은 MLP(506a)에 공급될 수도 있다. MLP(506a)는 인코더 출력( )을 생성하기 위해 (예컨대, 식 4 및 식 5에 나타낸) 전파 규칙들에 따라 출력들을 프로세싱할 수도 있다. 인코더 출력( )은 그래프(G)의 각각의 노드에 배정하기 위한 스케줄링 우선순위들을 결정하기 위 해 MLP(506b)를 사용하여 프로세싱될 수도 있다. 예를 들어, 그래프는 각각의 노드에 대한 스칼라 시퀀싱 우선순위들을 표현하는 바들을 갖는다. 바의 사이즈는 각각의 노드의 상대적인 스케줄링 우선순위를 표시할 수 도 있다. 디코더는, 시퀀스를 결정하기 위해 각각의 노드에 대한 스칼라 스케줄링 우선순위를 프로 세싱한다. 유리하게, 이들 우선순위들에는, 단일 NN 추론이 배정될 수도 있다. 시퀀스 또는 토폴로지 순서가, 각각의 단 계에서 새로운 노드를 추가함으로써 구성될 수도 있다. 부분 시퀀스( )가 주어지면, 다음 노드는, 그래프 토폴로지 및 시퀀스에서 이전에 행해진 선택들로 인해, 스케줄링가능한 노드들의 서브세트( )로부터만선택될 수 있다. 그 다음, 단계 i에서 추가될 다음 노드의 분포가 다음과 같이 주어진다:"}
{"patent_id": "10-2024-7036702", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "분포( )로부터의 부분 시퀀스에서의 다음 노드는, 예를 들어, 다음을 사용하여 결정될 수도 있다: 1.그리디 탐색: 각각의 단계 t에서, 가장 높은 확률을 갖는 노드를 선택함(예컨대, ). 2.샘플링 추론: 각각의 단계 t에서, 다음 노드 분포로부터 샘플링함(예컨대, ). 3.상태 붕괴를 이용한 빔 탐색: 스코어 함수가 부분 시퀀스의 총 확률인 빔 탐색 방법을 사용함으로써 부분 시 퀀스를 확장함. 빔 탐색 접근법은 다음의 관찰을 사용하여 향상될 수도 있다: 고려 중인 2개의 부분 시퀀스들 이 주어지면, 및 이어서, 양자 모두가 지금까지 노드들의 동일한 세트(예컨대, 하지만 상이한 순서)를 스케줄링하였고 임. 그 다음, 부분 시퀀스( )는 무시되고, 대신, 빔 탐색에서의 부분 시퀀스 ( )만을 사용할 수도 있다. 이는, 양자 모두의 부분 시퀀스들이 나머지 노드들의 동일한 세트를 스케줄링하 고 따라서 미래의 메모리 비용들의 세트가 및 양자 모두에 대해 동일하지만 현재 피크 메모리 비용은 에 대해 더 높기 때문이다. 따라서, 달성가능한 최소 피크 메모리 사용량의 관점에서 는 를 압도한다. 아키텍처는 주어진 DAG(G)에 대해 토폴로지 순서들의 세트에 대한 분포( )를 유도할 수도 있다. 발생하는 예상 비용은 에 의해 주어질 수도 있다. 아키텍처는, 다음과 같은 REINFORCE 그래디언트 추정자를 사용한 그래디언트 하강을 통해 비용( )을 최소화함으로써 트 레이닝될 수도 있다: , 여기서, b(G)는 추정자의 분산을 감소시키도록 의도된 베이스라인이다. 베이스라인(b(G))은 그래프(G)에 대한 베이스라인 정책의 그리디 롤아웃(greedy rollout)의 비용과 동일하게 설정될 수도 있다: . 도 6은 본 개시의 양태들에 따른, 예시적인 그래프 토폴로지 변환들을 예시한 다이어그램이다. 도 6을 참조하 면, 완전히 연결된 그래프가 도시되어 있다. 완전히 연결된 그래프는, 올-투-올(all-to all) 방식으 로 연결되는 8개의 노드들의 세트를 포함한다. 노드들의 각각은, 예를 들어, 수행될 태스크(예컨대, 동작)를 표현할 수도 있다. 완전히 연결된 그래프의 노드들을 연결하는 에지들은 노드들 간의 관계(예컨대, 순 서)를 표시할 수도 있다. 설명된 바와 같이, 그래프 토폴로지에 관한 정보는 인코더(예컨대, 도 5의 502)를 통 해 생성된 노드 임베딩에 포함될 수도 있다. 완전히 연결된 그래프는 토폴로지 변환들(604a-g)을 통해 서 브그래프들(예컨대, 완전히 연결된 그래프의 에지들의 서브세트들을 포함하는 그래프들)로 분해될 수도 있 다. 서브그래프들의 각각은 상이한 타입들의 노드-레벨 상호작용들을 캡처할 수도 있다. 이에 반하여, 변환들 (604a-g)로부터 기인하는 서브그래프들은, 완전히 연결된 그래프를 생성하기 위해 합산될 수도 있다.일부 양태들에서, 트랜스포머 아키텍처가 각각의 서브그래프에 대해 동작할 수도 있다. 예를 들어, 도 5에 도 시된 바와 같이, MHA(예컨대, 508e-g)는 각각의 서브그래프(예컨대, 토폴로지 변환된 그래프들(510a-d))에 배정 될 수도 있다. 각각의 트랜스포머는 독립적일 수도 있다. 일부 양태들에서, 트랜스포머들은 파라미터들을 공 유할 수도 있다. 토폴로지 변환들(604a-g)을 적용함으로써 형성된 서브그래프들은 그래프의 노드들(예컨대, 도 5의 노드 참 조)을 실행하기 위한 우선순위를 결정하는데 사용될 수도 있다. 도 7은 본 개시의 양태들에 따른, 인공 뉴럴 네트워크(ANN)를 사용하여 토폴로지 순서를 생성하기 위한 프로세 서 구현 방법을 예시한 플로우 다이어그램이다. 일부 양태들에서, 프로세서 구현 방법은, 예를 들어, CPU 또는 NPU와 같은 프로세서에 의해 수행될 수도 있다. 도 7에 도시된 바와 같이, 블록 702 에서, 프로세서는 수행될 태스크들의 세트를 수신한다. 일부 양태들에서, 태스크들은, 예를 들어, 컴퓨터 프로 그램에서의 동작들을 포함할 수도 있다. 태스크들은, 예를 들어, 컴파일러에 의해 수행될 수도 있다. 블록 704에서, 프로세서는 에지들에 의해 연결된 다중의 노드들을 포함하는 그래프에서 태스크들의 세트를 표현 한다. 각각의 노드는 태스크들의 세트에서의 태스크에 대응한다. 예를 들어, 도 6을 참조하여 설명된 바와 같 이, 태스크들의 세트는 그래프(예컨대, 그래프(602a))에서 표현될 수도 있다. 그래프는, 예를 들어, DAG 일 수도 있다. 그래프는 에지들에 의해 연결된 다중의 노드들을 포함할 수도 있다. 블록 706에서, 프로세서는 그래프에서의 각각의 노드에 스케줄링 우선순위를 배정한다. 도 5를 참조하여 설명 된 바와 같이, 스케줄링 확률들(예컨대, 512)보다는, 스케줄링 우선순위들( )이 노드들에 배정될 수도 있 다. 더욱이, 배정된 스케줄링 우선순위들은, 토폴로지 변환들을 적용함으로써 형성된 서브그래프들(예컨대, 도 5의 그래프들(510a-d) 참조)에 기초하여 결정될 수도 있다. 일부 양태들에서, 그래프의 노드들에 대한 스케줄 링 우선순위들은 단일 추론에서 배정될 수도 있다. 블록 708에서, 프로세서는 배정된 스케줄링 우선순위들 및 그래프의 토폴로지에 적어도 부분적으로 기초하여 잠 재적 다음 노드들의 각각의 확률에 따라 잠재적 다음 노드들 중의 다음 노드를 선택한다. 예를 들어, 도 5를 참조하여 설명된 바와 같이, 다음 노드(예컨대, 노드)는 잠재적 다음 노드들의 확률 분포의 그리디 탐색, 잠재적 다음 노드들의 확률 분포로부터의 샘플링, 또는 빔 탐색 프로세스에 기초하여 선택될 수도 있다. 블록 710에서, 프로세서는 다음 노드의 선택을 반복함으로써 태스크들의 토폴로지 순서를 생성한다. 도 5를 참 조하여 설명된 바와 같이, 그래프의 노드들은 토폴로지 순서를 생성하기 위해 배정된 우선순위에 기초하여 랭킹 될 수도 있다. 예시적인 양태들 양태 1: 프로세서 구현 방법은, 수행될 태스크들의 세트를 수신하는 단계; 에지들에 의해 연결된 다중의 노드들 을 포함하는 그래프에서 태스크들의 세트를 표현하는 단계로서, 각각의 노드는 태스크들의 세트에서의 태스크에 대응하는, 상기 태스크들의 세트를 표현하는 단계; 그래프에서의 각각의 노드에 스케줄링 우선순위를 배정하는 단계; 배정된 스케줄링 우선순위들 및 그래프의 토폴로지에 적어도 부분적으로 기초하여 잠재적 다음 노드들의 각각의 확률에 따라 잠재적 다음 노드들 중의 다음 노드를 선택하는 단계; 및 다음 노드의 선택을 반복함으로써 태스크들의 토폴로지 순서를 생성하는 단계를 포함한다. 양태 2: 양태 1의 프로세서 구현 방법에 있어서, 태스크들의 세트는 컴파일러에 의해 프로세싱될 동작들의 세트 를 포함한다. 양태 3: 양태 1 또는 양태 2의 프로세서 구현 방법은, 잠재적 다음 노드들의 확률 분포의 그리디 탐색, 잠재적 다음 노드들의 확률 분포로부터의 샘플링, 또는 빔 탐색 프로세스 중 하나에 기초하여 다음 노드를 선택하는 단 계를 더 포함한다. 양태 4: 양태 1 내지 양태 3 중 어느 하나의 프로세서 구현 방법은, 인공 뉴럴 네트워크(ANN)를 통해, 단일 추 론으로 다중의 노드들에 스케줄링 우선순위들을 배정하는 단계를 더 포함한다. 양태 5: 양태 1 내지 양태 4 중 어느 하나의 프로세서 구현 방법에 있어서, 그래프는 방향성 비순환 그래프를 포함한다. 양태 6: 양태 1 내지 양태 5 중 어느 하나의 프로세서 구현 방법에 있어서, 스케줄링 우선순위는 하나 이상의 토폴로지 변환들에 기초하여 배정된다. 양태 7: 양태 1 내지 양태 6 중 어느 하나의 프로세서 구현 방법은, 토폴로지 순서에 따라 태스크들의 세트를 수행하는 단계를 더 포함한다. 양태 8: 장치는, 메모리; 및 메모리에 커플링된 적어도 하나의 프로세서를 포함하고, 적어도 하나의 프로세서는, 수행될 태스크들의 세트를 수신하고; 에지들에 의해 연결된 다중의 노드들을 포함하는 그래프에서 태스크들을 표현하는 것으로서, 각각의 노드는 태스크들의 세트에서의 태스크에 대응하는, 상기 태스크들을 표 현하고; 그래프에서의 각각의 노드에 스케줄링 우선순위를 배정하고; 배정된 스케줄링 우선순위들 및 그래프의 토폴로지에 적어도 부분적으로 기초하여 잠재적 다음 노드들의 각각의 확률에 따라 잠재적 다음 노드들 중의 다 음 노드를 선택하고; 그리고 다음 노드의 선택을 반복함으로써 태스크들의 토폴로지 순서를 생성하도록 구성된 다. 양태 9: 양태 8의 장치에 있어서, 태스크들은 컴파일러에 의해 프로세싱될 동작들의 세트를 포함한다. 양태 10: 양태 8 또는 양태 9의 장치에 있어서, 적어도 하나의 프로세서는 추가로, 잠재적 다음 노드들의 확률 분포의 그리디 탐색, 잠재적 다음 노드들의 확률 분포로부터의 샘플링, 또는 빔 탐색 프로세스 중 하나에 기초 하여 다음 노드를 선택하도록 구성된다. 양태 11: 양태 8 내지 양태 10 중 어느 하나의 장치에 있어서, 적어도 하나의 프로세서는 추가로, 단일 추론으 로 다중의 노드들에 스케줄링 우선순위들을 배정하도록 구성된다. 양태 12: 양태 8 내지 양태 11 중 어느 하나의 장치에 있어서, 그래프는 방향성 비순환 그래프를 포함한다. 양태 13: 양태 8 내지 양태 12 중 어느 하나의 장치에 있어서, 적어도 하나의 프로세서는 추가로, 하나 이상의 토폴로지 변환들에 기초하여 다중의 노드들에 스케줄링 우선순위들을 배정하도록 구성된다. 양태 14: 양태 8 내지 양태 13 중 어느 하나의 장치에 있어서, 적어도 하나의 프로세서는 추가로, 토폴로지 순 서에 따라 태스크들의 세트를 수행하도록 구성된다. 양태 15: 프로그램 코드가 기록된 비일시적 컴퓨터 판독가능 매체로서, 프로그램 코드는 프로세서에 의해 실행 되고, 수행될 태스크들의 세트를 수신하기 위한 프로그램 코드; 에지들에 의해 연결된 다중의 노드들을 포함하 는 그래프에서 태스크들을 표현하기 위한 프로그램 코드로서, 각각의 노드는 태스크들의 세트에서의 태스크에 대응하는, 상기 태스크들을 표현하기 위한 프로그램 코드; 그래프에서의 각각의 노드에 스케줄링 우선순위를 배 정하기 위한 프로그램 코드; 배정된 스케줄링 우선순위들 및 그래프의 토폴로지에 적어도 부분적으로 기초하여 잠재적 다음 노드들의 각각의 확률에 따라 잠재적 다음 노드들 중의 다음 노드를 선택하기 위한 프로그램 코드; 및 다음 노드의 선택을 반복함으로써 태스크들의 토폴로지 순서를 생성하기 위한 프로그램 코드를 포함한다. 양태 16: 양태 15의 비일시적 컴퓨터 판독가능 매체에 있어서, 태스크들은 컴파일러에 의해 프로세싱될 동작들 의 세트를 포함한다. 양태 17: 양태 15 또는 양태 16의 비일시적 컴퓨터 판독가능 매체는, 인공 뉴럴 네트워크(ANN)를 통해, 잠재적 다음 노드들의 확률 분포의 그리디 탐색, 잠재적 다음 노드들의 확률 분포로부터의 샘플링, 또는 빔 탐색 프로 세스 중 하나에 기초하여 다음 노드를 선택하기 위한 프로그램 코드를 더 포함한다. 양태 18: 양태 15 내지 양태 17 중 어느 하나의 비일시적 컴퓨터 판독가능 매체는, 인공 뉴럴 네트워크(ANN)를 통해, 단일 추론으로 다중의 노드들에 스케줄링 우선순위들을 배정하기 위한 프로그램 코드를 더 포함한다. 양태 19: 양태 15 내지 양태 18 중 어느 하나의 비일시적 컴퓨터 판독가능 매체에 있어서, 그래프는 방향성 비 순환 그래프를 포함한다. 양태 20: 양태 15 내지 양태 19 중 어느 하나의 비일시적 컴퓨터 판독가능 매체는, 하나 이상의 토폴로지 변환 들에 기초하여 다중의 노드들에 스케줄링 우선순위들을 배정하기 위한 프로그램 코드를 더 포함한다. 양태 21: 양태 15 내지 양태 20 중 어느 하나의 비일시적 컴퓨터 판독가능 매체는, 토폴로지 순서에 따라 태스 크들의 세트를 수행하기 위한 프로그램 코드를 더 포함한다. 양태 22: 장치는, 수행될 태스크들의 세트를 수신하는 수단; 에지들에 의해 연결된 다중의 노드들을 포함하는 그래프에서 태스크들을 표현하는 수단으로서, 각각의 노드는 태스크들의 세트에서의 태스크에 대응하는, 상기 태스크들을 표현하는 수단; 그래프에서의 각각의 노드에 스케줄링 우선순위를 배정하는 수단; 다음 노드의 선택을 반복함으로써 태스크들의 토폴로지 순서를 선택하는 수단; 및 다음 노드의 선택을 반복함으로써 태스크들의 토폴로지 순서를 생성하는 수단을 포함한다. 양태 23: 양태 22의 장치에 있어서, 태스크들은 컴파일러에 의해 프로세싱될 동작들의 세트를 포함한다. 양태 24: 양태 22 또는 양태 23의 장치는, 인공 뉴럴 네트워크(ANN)를 통해, 잠재적 다음 노드들의 확률 분포의 그리디 탐색, 잠재적 다음 노드들의 확률 분포로부터의 샘플링, 또는 빔 탐색 프로세스 중 하나에 기초하여 다 음 노드를 선택하는 수단을 더 포함한다. 양태 25: 양태 22 내지 양태 24 중 어느 하나의 장치는, 단일 추론으로 다중의 노드들에 스케줄링 우선순위들을 배정하는 수단을 더 포함한다. 양태 26: 양태 22 내지 양태 25 중 어느 하나의 장치에 있어서, 그래프는 방향성 비순환 그래프를 포함한다. 양태 27: 양태 22 내지 양태 26 중 어느 하나의 장치는, 하나 이상의 토폴로지 변환들에 기초하여 다중의 노드 들에 스케줄링 우선순위들을 배정하는 수단을 더 포함한다. 양태 28: 양태 22 내지 양태 27 중 어느 하나의 장치는, 토폴로지 순서에 따라 태스크들의 세트를 수행하는 수 단을 더 포함한다. 일 양태에서, 수신 수단, 표현 수단, 배정 수단, 선택 수단, 생성 수단, 수행 수단 및/또는 결정 수단은 GPU, GPU와 연관된 프로그램 메모리, 완전히 연결된 계층들, NPU 및/또는 기재된 기능들을 수행하도록 구성된 라우팅 연결 프로세싱 유닛일 수도 있다. 다른 구성에 있어서, 전술한 수단들은 전술 한 수단들에 의해 기재된 기능들을 수행하도록 구성된 임의의 모듈 또는 임의의 장치일 수도 있다. 상기에서 설명된 방법들의 다양한 동작들은 대응하는 기능들을 수행 가능한 임의의 적합한 수단들에 의해 수행 될 수도 있다. 그 수단은 회로, 주문형 집적회로 (ASIC), 또는 프로세서를 포함하지만 이에 한정되지 않는 다 양한 하드웨어 및/또는 소프트웨어 컴포넌트(들) 및/또는 모듈(들)을 포함할 수도 있다. 일반적으로, 도면들에 예시된 동작들이 존재하는 경우, 그 동작들은 유사한 넘버링을 갖는 대응하는 상대의 수단-플러스-기능 컴포넌 트들을 가질 수도 있다. 사용된 같이, 용어 \"결정하는 것\"은 매우 다양한 액션들을 포괄한다. 예를 들어, \"결정하는 것\"은 계산하는 것, 컴퓨팅하는 것, 프로세싱하는 것, 도출하는 것, 조사하는 것, 검색하는 것(예컨대, 표, 데이터베이스, 또는 다른 데이터 구조에서 검색하는 것), 확인하는 것 등을 포함할 수도 있다. 부가적으로, \"결정하는 것\"은 수신 하는 것(예컨대, 정보를 수신하는 것), 액세스하는 것(예컨대, 메모리 내 데이터에 액세스하는 것) 등을 포함할 수도 있다. 더욱이, \"결정하는 것\"은 해결하는 것, 선택하는 것, 선출하는 것, 확립하는 것 등을 포함할 수도 있다. 사용된 바와 같이, 아이템들의 리스트 \"중 적어도 하나\"를 지칭하는 어구는 단일 멤버들을 포함하여 그 아이템 들의 임의의 조합을 지칭한다. 일 예로서, \"a, b, 또는 c 중 적어도 하나\"는 a, b, c, a-b, a-c, b-c, 및 a- b-c를 커버하도록 의도된다. 본 개시와 관련하여 설명된 다양한 예시적인 논리 블록들, 모듈들, 및 회로들은 범용 프로세서, 디지털 신호 프 로세서(DSP), 주문형 집적회로(ASIC), 필드 프로그래밍가능 게이트 어레이 신호(FPGA) 또는 다른 프로그래밍가 능 로직 디바이스(PLD), 이산 게이트 또는 트랜지스터 로직, 이산 하드웨어 컴포넌트들, 또는 설명된 기능들을 수행하도록 설계된 이들의 임의의 조합으로 구현 또는 수행될 수도 있다. 범용 프로세서는 마이크로프로세서일 수도 있지만, 대안적으로, 그 프로세서는 임의의 상업적으로 입수가능한 프로세서, 제어기, 마이크로 제어기, 또는 상태 머신일 수도 있다. 프로세서는 또한, 컴퓨팅 디바이스들의 조합, 예컨대, DSP와 마이크로프로세서의 조합, 복수의 마이크로프로세서들, DSP 코어와 결합된 하나 이상의 마이크로프로세서들, 또는 임의의 기타 다른 구성물로서 구현될 수도 있다. 본 개시와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어에서, 프로세서에 의해 실행되는 소프트웨 어 모듈에서, 또는 이들 양자의 조합에서 직접 구현될 수도 있다. 소프트웨어 모듈은, 당업계에 공지된 임의의 형태의 저장 매체에 상주할 수도 있다. 사용될 수도 있는 저장 매체들의 일부 예들은 랜덤 액세스 메모리 (RAM), 판독 전용 메모리(ROM), 플래시 메모리, 소거가능한 프로그래밍가능 판독 전용 메모리(EPROM), 전기적으 로 소거가능한 프로그래밍가능 판독 전용 메모리(EEPROM), 레지스터들, 하드 디스크, 착탈가능 디스크, CD-ROM 등을 포함한다. 소프트웨어 모듈은 단일 명령 또는 다수의 명령들을 포함할 수도 있으며, 수개의 상이한 코드 세그먼트들 상으로, 상이한 프로그램들 사이에, 및 다중의 저장 매체들에 걸쳐 분산될 수도 있다. 저장매체는, 프로세서가 저장 매체로부터 정보를 판독할 수 있고 저장 매체에 정보를 기입할 수 있도록 프로세서에 커플링될 수도 있다. 대안적으로, 저장 매체는 프로세서에 통합될 수도 있다. 개시된 방법들은 설명된 방법을 달성하기 위한 하나 이상의 단계들 또는 액션들을 포함한다. 그 방법 단계들 및/또는 액션들은 청구항들의 범위로부터 일탈함없이 서로 상호교환될 수도 있다. 즉, 단계들 또는 액션들의 특정 순서가 명시되지 않으면, 특정 단계들 및/또는 액션들의 순서 및/또는 그 사용은 청구항들의 범위로부터 일탈함없이 수정될 수도 있다. 설명된 기능들은 하드웨어, 소프트웨어, 펌웨어, 또는 이들의 임의의 조합에서 구현될 수도 있다. 하드웨어에 서 구현되면, 예시적인 하드웨어 구성은 디바이스에 프로세싱 시스템을 포함할 수도 있다. 프로세싱 시스템은 버스 아키텍처로 구현될 수도 있다. 버스는 프로세싱 시스템의 특정 어플리케이션 및 전체 설계 제약들에 의존 하여 임의의 수의 상호접속 버스들 및 브리지들을 포함할 수도 있다. 버스는 프로세서, 머신 판독가능 매체들, 및 버스 인터페이스를 포함하는 다양한 회로들을 함께 링크시킬 수도 있다. 버스 인터페이스는, 다른 것들 중 에서도, 네트워크 어댑터를 버스를 통해 프로세싱 시스템에 접속시키는데 사용될 수도 있다. 네트워크 어댑터 는 신호 프로세싱 기능들을 구현하는데 사용될 수도 있다. 특정 양태들에 대해, 사용자 인터페이스(예컨대, 키 패드, 디스플레이, 마우스, 조이스틱 등)가 또한 버스에 접속될 수도 있다. 버스는 또한, 당업계에 널리 공지 되고 따라서 어떠한 추가로 설명되지 않을 타이밍 소스들, 주변기기들, 전압 레귤레이터들, 전력 관리 회로들 등과 같은 다양한 다른 회로들을 링크시킬 수도 있다. 프로세서는 버스를 관리하는 것, 및 머신 판독가능 매체들 상에 저장된 소프트웨어의 실행을 포함한 일반 프로 세싱을 책임질 수도 있다. 프로세서는 하나 이상의 범용 및/또는 특수목적 프로세서들로 구현될 수도 있다. 예들은 마이크로프로세서들, 마이크로 제어기들, DSP 프로세서들, 및 소프트웨어를 실행할 수 있는 다른 회로부 를 포함한다. 소프트웨어는, 소프트웨어, 펌웨어, 미들웨어, 마이크로코드, 하드웨어 디스크립션 언어, 또는 기타 등등으로서 지칭되든 아니든, 명령들, 데이터, 또는 이들의 임의의 조합을 의미하도록 넓게 해석될 것이다. 머신 판독가능 매체들은, 예로서, 랜덤 액세스 메모리(RAM), 플래시 메모리, 판독 전용 메모리(ROM), 프로그래밍가능 판독 전용 메모리(PROM), 소거가능한 프로그래밍가능 판독 전용 메모리(EPROM), 전기적으로 소 거가능한 프로그래밍가능 판독 전용 메모리(EEPROM), 레지스터들, 자기 디스크들, 광학 디스크들, 하드 드라이 브들, 또는 임의의 다른 적합한 저장 매체, 또는 이들의 임의의 조합을 포함할 수도 있다. 머신 판독가능 매체 들은 컴퓨터 프로그램 제품에서 구현될 수도 있다. 컴퓨터 프로그램 제품은 패키징 재료들을 포함할 수도 있다. 하드웨어 구현에 있어서, 머신 판독가능 매체들은 프로세서와는 분리된 프로세싱 시스템의 부분일 수도 있다. 하지만, 당업자들이 용이하게 인식할 바와 같이, 머신 판독가능 매체들 또는 그 임의의 부분은 프로세싱 시스템 외부에 있을 수도 있다. 예로서, 머신 판독가능 매체들은 송신 라인, 데이터에 의해 변조된 캐리어파, 및/또는 디바이스로부터 분리된 컴퓨터 제품을 포함할 수도 있으며, 이들 모두는 버스 인터페이스를 통해 프로세서에 의 해 액세스될 수도 있다. 대안적으로 또는 부가적으로, 머신 판독가능 매체들 또는 그 임의의 부분은, 캐시 및/ 또는 일반 레지스터 파일들로 있을 수도 있는 경우와 같이, 프로세서에 통합될 수도 있다. 논의된 다양한 컴포 넌트들이 로컬 컴포넌트와 같이 특정 위치를 갖는 것으로서 설명될 수도 있지만, 이들은 또한 특정 컴포넌트들 이 분산 컴퓨팅 시스템의 부분으로서 구성되는 것과 같이 다양한 방식들로 구성될 수도 있다. 프로세싱 시스템은 프로세서 기능성을 제공하는 하나 이상의 마이크로프로세서들 및 머신 판독가능 매체들의 적 어도 일부를 제공하는 외부 메모리를 갖는 범용 프로세싱 시스템으로서 구성될 수도 있고, 이들 모두는 외부 버 스 아키텍처를 통해 다른 지원 회로부와 함께 링크된다. 대안적으로, 프로세싱 시스템은, 설명된 뉴럴 시스템 들의 모델들 및 뉴런 모델들을 구현하기 위한 하나 이상의 뉴로모픽 프로세서들을 포함할 수도 있다. 다른 대 안으로서, 프로세싱 시스템은, 단일 칩으로 집적된 프로세서, 버스 인터페이스, 사용자 인터페이스, 지원 회로 부, 및 머신-판독가능 매체들의 적어도 일부를 갖는 주문형 집적회로(ASIC)로, 또는 하나 이상의 필드 프로그래 밍가능 게이트 어레이들(FPGA들), 프로그래밍가능 로직 디바이스들(PLD들), 제어기들, 상태 머신들, 게이트형 로직, 이산 하드웨어 컴포넌트들, 또는 임의의 다른 적합한 회로부, 또는 본 개시 전반에 걸쳐 설명된 다양한 기능성을 수행할 수 있는 회로들의 임의의 조합으로 구현될 수도 있다. 당업자는 전체 시스템에 부과된 전체 설계 제약들 및 특정 어플리케이션에 의존하여 프로세싱 시스템에 대한 설명된 기능성을 최상으로 구현하기 위 한 방법을 인식할 것이다. 머신 판독가능 매체들은 다수의 소프트웨어 모듈들을 포함할 수도 있다. 소프트웨어 모듈들은, 프로세서에 의 해 실행될 경우, 프로세싱 시스템으로 하여금 다양한 기능들을 수행하게 하는 명령들을 포함한다. 소프트웨어모듈들은 송신 모듈 및 수신 모듈을 포함할 수도 있다. 각각의 소프트웨어 모듈은 단일 저장 디바이스에 상주 할 수도 있거나 또는 다중의 저장 디바이스들에 걸쳐 분산될 수도 있다. 예로서, 소프트웨어 모듈은 트리거링 이벤트가 발생할 때 하드 드라이브로부터 RAM에 로딩될 수도 있다. 소프트웨어 모듈의 실행 동안, 프로세서는 액세스 속도를 증가시키기 위해 명령들의 일부를 캐시에 로딩할 수도 있다. 그 다음, 하나 이상의 캐시 라인들 은 프로세서에 의한 실행을 위해 일반 레지스터 파일에 로딩될 수도 있다. 하기에서 소프트웨어 모듈의 기능성 을 참조할 경우, 그 소프트웨어 모듈로부터의 명령들을 실행할 때 그러한 기능성은 프로세서에 의해 구현됨이 이해될 것이다. 더욱이, 본 개시의 양태들은 프로세서, 컴퓨터, 머신, 또는 그러한 양태들을 구현하는 다른 시 스템의 기능에 대한 개선을 발생시킴이 인식되어야 한다. 소프트웨어에서 구현된다면, 그 기능들은 하나 이상의 명령들 또는 코드로서 컴퓨터 판독가능 매체 상으로 저장 또는 전송될 수도 있다. 컴퓨터 판독가능 매체들은, 일 장소로부터 다른 장소로의 컴퓨터 프로그램의 전송을 용이하게 하는 임의의 매체를 포함하는 통신 매체들 및 컴퓨터 저장 매체들 양자 모두를 포함한다. 저장 매체 는, 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수도 있다. 한정이 아닌 예로서, 그러한 컴퓨터 판독 가능 매체들은 RAM, ROM, EEPROM, CD-ROM 또는 다른 광학 디스크 저장부, 자기 디스크 저장부 또는 다른 자기 저장 디바이스들, 또는 원하는 프로그램 코드를 명령들 또는 데이터 구조들의 형태로 수록 또는 저장하는데 이 용될 수 있고 컴퓨터에 의해 액세스될 수 있는 임의의 다른 매체를 포함할 수 있다. 부가적으로, 임의의 커넥 션이 컴퓨터 판독가능 매체로 적절히 명명된다. 예를 들어, 동축 케이블, 광섬유 케이블, 꼬임쌍선, 디지털 가 입자 라인 (DSL), 또는 적외선 (IR), 무선, 및 마이크로파와 같은 무선 기술들을 이용하여 웹사이트, 서버, 또 는 다른 원격 소스로부터 소프트웨어가 송신된다면, 동축 케이블, 광섬유 케이블, 꼬임쌍선, DSL, 또는 적외선, 무선, 및 마이크로파와 같은 무선 기술들은 매체의 정의에 포함된다. 사용된 바와 같이, 디스크(disk) 및 디스 크(disc)는 컴팩트 디스크(CD), 레이저 디스크, 광학 디스크, 디지털 다기능 디스크(DVD), 플로피 디스크 및 Blu-ray® 디스크를 포함하며, 여기서, 디스크(disk)들은 통상적으로 데이터를 자기적으로 재생하지만 디스크 (disc)들은 레이저들을 이용하여 데이터를 광학적으로 재생한다. 따라서, 일부 양태들에 있어서, 컴퓨터 판독 가능 매체들은 비일시적 컴퓨터 판독가능 매체들(예컨대, 유형의 매체들)을 포함할 수도 있다. 부가적으로, 다 른 양태들에 대해, 컴퓨터 판독가능 매체들은 일시적 컴퓨터 판독가능 매체들(예컨대, 신호)을 포함할 수도 있 다. 상기의 조합들이 또한, 컴퓨터 판독가능 매체들의 범위 내에 포함되어야 한다. 따라서, 특정 양태들은, 제시된 동작들을 수행하기 위한 컴퓨터 프로그램 제품을 포함할 수도 있다. 예를 들어, 그러한 컴퓨터 프로그램 제품은 명령들이 저장된(및/또는 인코딩된) 컴퓨터 판독가능 매체를 포함할 수도 있으며, 그 명령들은, 설명된 동작들을 수행하기 위해 하나 이상의 프로세서들에 의해 실행가능하다. 특정 양 태들에 대해, 컴퓨터 프로그램 제품은 패키징 재료를 포함할 수도 있다. 추가로, 설명된 방법들 및 기법들을 수행하기 위한 모듈들 및/또는 다른 적절한 수단들은, 적용가능할 경우, 사 용자 단말기 및/또는 기지국에 의해 다운로드되고/되거나 그렇지 않으면 획득될 수 있음이 인식되어야 한다. 예를 들어, 그러한 디바이스는 서버에 커플링되어, 설명된 방법들을 수행하는 수단의 전송을 용이하게 할 수 있 다. 대안적으로, 설명된 다양한 방법들은 저장 수단(예컨대, RAM, ROM, 컴팩트 디스크(CD) 또는 플로피 디스크 와 같은 물리적 저장 매체 등)을 통해 제공될 수 있어서, 그 저장 수단을 디바이스에 커플링 또는 제공할 시, 사용자 단말기 및/또는 기지국이 다양한 방법들을 획득할 수 있다. 더욱이, 설명된 방법들 및 기법들을 디바이 스에 제공하기 위한 임의의 다른 적합한 기법이 활용될 수 있다. 청구항들은 상기에서 예시된 정확한 구성 및 컴포넌트들로 한정되지 않음이 이해되어야 한다. 다양한 수정들, 변경들 및 변동들이 청구항들의 범위로부터 일탈함없이, 상기에서 설명된 방법들 및 장치의 배열, 동작 및 상세 들에서 행해질 수도 있다.도면 도면1 도면2a 도면2b 도면2c 도면2d 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2024-7036702", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 특징들, 특성, 및 이점들은 도면들과 함께 취해질 경우에 하기에 기재된 상세한 설명으로부터 더 명 백하게 될 것이며, 도면들에 있어서 동일한 참조 부호들은 전반에 걸쳐 대응하게 식별한다. 도 1은 본 개시의 특정 양태들에 따른, 범용 프로세서를 포함하는 SOC(system-on-a-chip)를 이용한 뉴럴 네트워 크의 예시적인 구현을 예시한다. 도 2a, 도 2b, 및 도 2c는 본 개시의 양태들에 따른 뉴럴 네트워크를 예시한 다이어그램들이다. 도 2d는 본 개시의 양태들에 따른 예시적인 딥 컨볼루셔널 네트워크(DCN)를 예시한 다이어그램이다. 도 3은 본 개시의 양태들에 따른 예시적인 딥 컨볼루셔널 네트워크(DCN)를 예시한 블록 다이어그램이다. 도 4는 본 개시의 양태들에 따른, 인공 지능(AI) 함수들을 모듈화할 수도 있는 예시적인 소프트웨어 아키텍처를 예시한 블록 다이어그램이다. 도 5는 본 개시의 양태들에 따른, 토폴로지 순서를 결정하기 위한 예시적인 아키텍처를 예시한 블록 다이어그램 이다. 도 6은 본 개시의 양태들에 따른, 예시적인 그래프 토폴로지 변환들을 예시한 다이어그램이다. 도 7은 본 개시의 양태들에 따른, 인공 뉴럴 네트워크를 사용하여 토폴로지 순서를 생성하기 위한 프로세서 구 현 방법을 예시한 플로우 다이어그램이다."}
