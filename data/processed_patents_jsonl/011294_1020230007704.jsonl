{"patent_id": "10-2023-0007704", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0115945", "출원번호": "10-2023-0007704", "발명의 명칭": "인공신경 네트워크를 이용한 심리상태 추론장치 및 방법", "출원인": "주식회사 에스알유니버스", "발명자": "김한빈"}}
{"patent_id": "10-2023-0007704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공신경 네트워크를 이용하여 대상자의 심리상태를 분석하기 위한 장치에 있어서,상기 대상자의 동영상을 입력받는 입력부;상기 동영상으로부터, 특징 정보들로서, 상기 대상자의 얼굴 특징, 신체 특징, 움직임 특징 및 음성 특징에 관한 정보를 추출하는 특징 추출부;상기 특징 정보들로부터 상기 대상자의 심리상태를 추론하기 위한 압축된 특징 정보를 추출하는 특징 통합부;및상기 압축된 특징 정보로부터 상기 대상자의 심리상태를 추론하는 추론부를 포함하는, 심리상태 추론장치."}
{"patent_id": "10-2023-0007704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 특징 추출부는,상기 동영상 중 이미지에 해당하는 데이터로부터 상기 얼굴 특징, 상기 신체 특징 및 상기 움직임 특징에 관한정보를 추출하고, 상기 동영상 중 음향에 해당하는 데이터로부터 상기 음성 특징에 관한 정보를 추출하는,심리상태 추론장치."}
{"patent_id": "10-2023-0007704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 특징 추출부는,상기 특징 정보들에 포함되는 정보로서, 상기 음성 특징에 관한 정보로부터 음성을 텍스트로 변환시킨 텍스트정보를 더 추출하는,심리상태 추론장치."}
{"patent_id": "10-2023-0007704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 특징 추출부는, 상기 인공신경 네트워크의 전부 또는 일부로서, 상기 동영상으로부터 각각 분리된 음향과 이미지로부터 상기 특징 정보들을 추출하는 특징 추출 네트워크 및 상기 특징 정보들을 임베딩 벡터로 변환시키는 임베딩 네트워크를각각 포함하는,심리상태 추론장치."}
{"patent_id": "10-2023-0007704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 특징 통합부는,상기 인공신경 네트워크의 전부 또는 일부로서, 상기 압축된 특징 정보를 추출하기 위한 특징 통합 네트워크를포함하고,공개특허 10-2024-0115945-3-상기 특징 통합 네트워크는, 상기 추론부의 추론 결과를 이용한 역전파 학습에 의해, 특징 정보들을 압축한 결과로부터 대상자의 심리상태를 추론하기 위한 특정 정보들만을 상기 압축된 특징 정보로서 추출하도록 학습된네트워크인, 심리상태 추론장치."}
{"patent_id": "10-2023-0007704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 추론부는,상기 인공신경 네트워크의 전부 또는 일부로서 추론 네트워크를 이용하여, 상기 압축된 특징 정보로부터 상기대상자의 심리상태로서, 상기 대상자의 감정을 분류하고 분류된 감정의 강도를 추론하는,심리상태 추론장치."}
{"patent_id": "10-2023-0007704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 추론부는,상기 인공신경 네트워크의 전부 또는 일부로서 추론 네트워크에 의하여, 상기 압축된 특징 정보로부터 각각 인지되는, 상기 대상자의 신체상태, 음성의 어조 및 텍스트의 내용을 기반으로 상기 대상자의 심리상태로서, 상기대상자의 감정의 정도를 추론하는,심리상태 추론장치."}
{"patent_id": "10-2023-0007704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 추론부는,상기 인공신경 네트워크의 전부 또는 일부로서 추론 네트워크에 의하여, 상기 압축된 특징 정보로부터 각각 인지되는, 상기 대상자의 움직임의 정도, 음성의 강도 및 텍스트의 내용을 기반으로, 상기 대상자의 심리상태를나타내는 지표로서 상기 대상자에 관한 적어도 하나의 생리상태 정보를 추론하는,심리상태 추론장치."}
{"patent_id": "10-2023-0007704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "인공신경 네트워크를 포함하는 심리상태 추론장치를 이용하여 대상자의 심리상태를 분석하는 심리상태 추론방법에 있어서,상기 대상자의 동영상을 입력받는 과정;상기 동영상으로부터, 상기 대상자의 얼굴 특징, 신체 특징, 움직임 특징 및 음성 특징에 관한 정보를, 특징 정보들로서 추출하는 과정;상기 특징 정보들로부터 상기 대상자의 심리상태를 추론하기 위한 압축된 특징 정보를 추출하는 과정; 및상기 압축된 특징 정보로부터 상기 대상자의 심리상태를 추론하는 과정을 포함하는, 심리상태 추론방법."}
{"patent_id": "10-2023-0007704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 특징 정보들로서 추출하는 과정은,상기 동영상으로부터 음향과 이미지를 분리하는 과정; 및공개특허 10-2024-0115945-4-분리된 이미지로부터 상기 얼굴 특징, 상기 신체 특징 및 상기 움직임 특징에 관한 정보를 추출하고, 분리된 음향으로부터 상기 음성 특징에 관한 정보를 추출하는 과정을 포함하는, 심리상태 추론방법."}
{"patent_id": "10-2023-0007704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 동영상은, 정답 심리상태가 레이블링된 데이터이고,상기 추론하는 과정 이후에, 추론 결과와 상기 정답 심리상태를 이용하여 상기 인공신경 네트워크의 전부 또는일부를 학습시키는 과정을 더 포함하는, 심리상태 추론방법."}
{"patent_id": "10-2023-0007704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 추론하는 과정 이후에, 상기 인공신경 네트워크의 전부 또는 일부인, 상기 압축된 특징 정보를 추출하기위한 특징 통합 네트워크를, 추론 결과를 이용하여 역전파 학습시키는 과정을 더 포함하되,상기 특징 통합 네트워크는, 상기 특징 정보들을 압축한 결과로부터 상기 대상자의 심리상태를 추론하기 위한특정 정보들만을 상기 압축된 특징 정보로서 추출하도록 학습되는, 심리상태 추론방법."}
{"patent_id": "10-2023-0007704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 입력받는 과정은,상기 동영상으로서, 기준 동영상, 상기 기준 동영상과 동일한 클래스의 동영상(이하, “기준 클래스 동영상”)및 상기 기준 동영상과 다른 클래스의 동영상(이하, “기준과 다른 클래스 동영상”)을 입력받고,상기 특징 정보로서 추출하는 과정은,상기 기준 동영상, 상기 기준 클래스 동영상 및 상기 기준과 다른 클래스 동영상으로부터 특징 정보들을 각각추출하는,심리상태 추론방법."}
{"patent_id": "10-2023-0007704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 압축된 특징 정보를 추출하는 과정은,상기 인공신경 네트워크의 전부 또는 일부인 특징 통합 네트워크에, 상기 추출된 특징 정보들을 입력하여 상기압축된 특징 정보를 추출하는 과정;상기 기준 동영상과 동일한 클래스의 동영상으로부터 추출된 압축된 특징 정보들의 페어는 positive, 상기 기준동영상과 다른 클래스의 동영상으로부터 추출된 압축된 특징 정보들의 페어는 negative로 레이블링 과정; 및Triplet loss를 연산하여 상기 특징 통합 네트워크를 학습시키는 과정을 포함하는, 심리상태 추론방법."}
{"patent_id": "10-2023-0007704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항 내지 제14항 중 어느 한 항에 따른 심리상태 추론방법이 포함하는 각 과정을 실행시키기 위하여 컴퓨터로읽을 수 있는 기록매체에 저장된 컴퓨터 프로그램.공개특허 10-2024-0115945-5-"}
{"patent_id": "10-2023-0007704", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 인공신경 네트워크를 이용한 심리상태 추론장치 및 방법을 제공한다. 본 개시의 일 측면에 의하면, 동 영상이 포함하는 다양한 정보들로부터 심리상태 추론을 위한 압축된 특징 정보를 추출함으로써 기존 방식 대비 정확도가 향상된 심리상태 추론장치 및 방법을 제공한다."}
{"patent_id": "10-2023-0007704", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공신경망을 이용한 심리상태 추론장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0007704", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 배경 정보를 제공할 뿐 종래기술을 구성하는 것은 아니다. 사람은 상대방을 짧은 시간 관찰, 대화하는 것만으로 상대방의 심리상태를 파악한다. 짧은 시간동안 상대방의 얼굴 표정, 신체 동작, 말투, 어조, 대화 내용과 생리 상태(예: 얼굴이 붉어짐, 땀이 남 등) 등 복합적인 정보 를 수용하여 상대방의 심리상태를 파악하는 것이다. 사용자의 심리상태 중 감정을 인식하는 기술은, 사람의 얼굴 영상을 분석하여 특정 얼굴 근육의 움직임을 특정 감정으로 매핑하는 기술 또는 사용자의 음성의 특징을 분석하여 특정 감정으로 매핑하는 기술 또는 사용자의 생 체 신호의 특징을 분석하여 특정 감정으로 매핑하는 기술 등과 같이 주로 사람의 자의 신체적 반응을 분석대상 으로 하는 수준에 머무르고 있다. 이와 같은, 사용자의 신체적 반응을 분석하는 감정 인식 기술은 사용자가 의 도적으로 신체적 반응을 숨길 경우(무표정 등), 사용자 내면의 숨겨진 감정을 파악하기 쉽지 않고, 신체적 반응 을 측정하기 위해 별도의 센서(피부전도도 센서 등)를 신체에 부착해야 하는 불편함을 초래하여 사용상 제약이 존재한다. 그러나 대부분 인간은 얼굴의 동작, 음성 또는 어느 하나의 생체 신호만으로 상대방의 심리상태를 파악하지 않 는다. 한가지 유형의 데이터만으로 심리상태를 판단하는 기존의 방법론은 해당 상황을 벗어나면 정확도가 떨어 지는 한계가 있기 때문이다. 전술한 기술적 한계를 해결하고자, 여러가지 정보를 통합하여 분석하는 멀티모달 방식의 기술이 등장하고 있다. 이러한 멀티모달 기반의 방식은 얼굴 이미지, 음성, 대화내용(테스트)으로부터 정보를 통합, 분석하는 방식이다. 그러나 이러한 멀티모달 데이터는 데이터 통합방식과 분석방식에 따라 잘못된 결과를 추론할 우려가 있다. 이는 심리상태의 관점에서, 각 멀티모달 데이터 간의 연관관계를 고려하지 못한 심 리상태 추론 모델을 고안한 데서 기인한다."}
{"patent_id": "10-2023-0007704", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 인공신경 네트워크를 이용하여 동영상으로부터 대상자의 심리상태를 자동으로 추론하기 위한 장치 및 방법을 제공하는 것을 목적으로 한다. 본 개시의 일 측면에 의하면, 대상자의 얼굴 특징, 신체 특징, 움직임 특징 및 음성 특징을 고려하여 정적 얼굴 이미지, 음성만을 이용하여 대상자의 심리상태를 추론하는 방식 대비 정확하게 심리상태를 추론하는 장치 및 방 법을 제공할 수 있다. 본 개시의 일 측면에 의하면, 동영상이 포함하는 다양한 정보들로부터 심리상태 추론을 위한 압축된 특징 정보 를 추출함으로써 기존 방식 대비 정확도가 향상된 심리상태를 추론하는 장치 및 방법을 제공할 수 있다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제 들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0007704", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 의하면, 인공신경 네트워크를 이용하여 대상자의 심리상태를 분석하기 위한 장치에 있어서, 대상자의 동영상을 입력받는 입력부; 동영상으로부터, 특징 정보들로서, 대상자의 얼굴 특징, 신체 특 징, 움직임 특징 및 음성 특징에 관한 정보를 추출하는 특징 추출부; 특징 정보들로부터 대상자의 심리상태를 추론하기 위한 압축된 특징 정보를 추출하는 특징 통합부; 및 압축된 특징 정보로부터 대상자의 심리상태를 추 론하는 추론부를 포함하는, 심리상태 추론장치를 제공한다. 본 개시의 일 측면에 의하면, 인공신경 네트워크를 이용하여 대상자의 심리상태를 분석하기 위한 장치에 있어서, 특징 추출부는, 인공신경 네트워크의 전부 또는 일부로서, 동영상으로부터 각각 분리된 음향과 이미지 로부터 특징 정보들을 추출하는 특징 추출 네트워크 및 상기 특징 정보들을 임베딩 벡터로 변환시키는 임베딩 네트워크를 각각 포함하는, 심리상태 추론장치를 제공한다. 본 개시의 일 측면에 의하면, 인공신경 네트워크를 포함하는 심리상태 추론장치를 이용하여 대상자의 심리상태 를 분석하는 방법에 있어서, 대상자의 동영상을 입력받는 과정; 동영상으로부터, 대상자의 얼굴 특징, 신체 특 징, 움직임 특징 및 음성 특징에 관한 정보를, 특징 정보들로서 추출하는 과정; 특징 정보들로부터 대상자의 심 리상태를 추론하기 위한 압축된 특징 정보를 추출하는 과정; 및 압축된 특징 정보로부터 대상자의 심리상태를 추론하는 과정을 포함하는, 심리상태 추론방법을 제공한다. 본 개시의 일 측면에 의하면, 인공신경 네트워크를 포함하는 심리상태 추론장치를 이용하여 대상자의 심리상태 를 분석하는 방법에 있어서, 인공신경 네트워크의 전부 또는 일부인 특징 통합 네트워크에, 추출된 특징 정보들 을 입력하여 압축된 특징 정보를 추출하는 과정; 기준 동영상과 동일한 클래스의 동영상으로부터 추출된 압축된 특징 정보들의 페어는 positive, 기준 동영상과 다른 클래스의 동영상으로부터 추출된 압축된 특징 정보들의 페 어는 negative로 레이블링 과정; 및 Triplet loss를 연산하여 상기 특징 통합 네트워크를 학습시키는 과정을 포 함하는, 심리상태 추론방법을 제공한다. 본 개시의 일 측면에 의하면, 전술한 방법을 수행하는 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체 및/ 또는 전술한 방법의 각 과정을 실행시키기 위하여 컴퓨터로 읽을 수 있는 기록매체에 저장된 컴퓨터 프로그램을 제공한다."}
{"patent_id": "10-2023-0007704", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일 측면에 의하면, 대상자의 심리상태를 자동으로 추론하는 효과가 있다. 본 개시의 일 측면에 의하면, 정적 얼굴 이미지, 음성만을 이용하여 대상자의 심리상태를 추론하는 방식 대비 정확한 심리상태 추론이 가능해지는 효과가 있다. 본 개시의 일 측면에 의하면, 동영상이 포함하는 다양한 정보들로부터 심리상태 추론을 위한 압축된 특징 정보 를 추출하는 효과가 있다. 본 개시의 일 측면에 의하면, 심리상태 추론을 위한 인공지능 네트워크의 학습성능을 향상시키는 효과가 있다. 본 개시의 다양한 실시예에 따른 심리상태 추론장치 및 심리상태 추론방법의 효과들은 이상에서 언급한 효과들 에 한하지 않고, 이 분야 통상의 기술자가 본 개시의 심리상태 추론장치 및 심리상태 추론방법의 효과로서 착안 할 수 있는 효과를 포함한다. 예컨대, 본 개시의 다양한 실시예에 따른 심리상태 추론장치 및 심리상태 추론방법은 대상자의 심리적, 신체적 상태 진단이나 치료를 위하여 사용되거나, 대상자의 심리상태에 적합한 상품 또는 서비스를 추천해주기 위해 사 용될 수 있다. 또는, 대상자의 심리상태를 인지하여 상호작용할 수 있는 챗봇을 개발하기 위하여 사용될 수도 있다."}
{"patent_id": "10-2023-0007704", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는, 본 개시의 실시예들을 예시적 도면을 이용하여 설명하나, 이러한 실시예 및 도면은 본 개시를 설명 하기 위한 것일 뿐 청구범위를 한정하지 않는다. 한편, 본 개시의 설명과 관련하여, 공지된 구성이나 기능에 대 하여는 상세한 설명을 생략할 수 있다. 또한, 본 개시의 구성 요소, 기능, 효과 등을 설명하는 데 있어서, 제1, 제2, a, b, A, B, 1), 2) 등의 용어를 사용할 수 있으나, 이는 각 구성 요소를 구별하기 위한 것으로 해당 구성 요소의 본질이나 차례 또는 순서 등을한정하지 않는다. 또한, 명세서에 기재된 '인터페이스', '시스템', '플랫폼', '장치', '부', '모듈' 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합 으로 구현될 수 있다. 한편, 본 개시의 다양한 구성 요소, 모듈, 부, 장치, 인터페이스, 시스템 등은 컴퓨터 하드웨어, 소프트웨어, 애플리케이션 및/또는 이들의 조합으로 구현될 수 있고, 이러한 다양한 구현예들은 프로그래밍 가능한 시스템상 에서 실행 가능한 하나 이상의 컴퓨터 프로그램들로 구현되는 것을 포함할 수 있다. 본 개시의 도면 및 도면부호는, 본 개시의 실시예들을 설명하기 위한 것이고, 본 개시가 실시될 수 있는 유일한 실시형태를 나타내는 것은 아니다. 본 개시의 심리상태 추론방법은, 심리상태 추론장치에 의해 실행되고, 심리상태 추론장치는 컴퓨팅 디바이스 상 에서 실행된다. 심리상태 추론장치는, 컴퓨팅 디바이스가 가용할 수 있는 하나 이상의 프로세서에 의해 각 기능 을 수행하고, 이러한 프로세서와 연결되어 내부에 저장된 명령어들을 가지는 컴퓨터 판독가능 스토리지를 포함 한다. 도 1은 본 개시의 일 실시예에 따른 심리상태 추론장치를 나타내는 개념도이다. 본 개시의 일 실시예에 따른 심리상태 추론장치는 입력부, 특징 추출부, 특징 통합부 및 추 론부를 전부 또는 일부 포함한다. 입력부는 대상자의 동영상을 입력받고, 특징 추출부는 입력된 동영상으로부터 특징 정보들(features)을 추출하며, 특징 통합부는 특징 정보들로부터 압축된 특징 정보를 추출한다. 추론부는 압축된 특징 정보로부터 대상자의 심리상태를 추론하여 제공한다. 본 개시의 심리상태 추론장치는 다양한 실시예에 따라, 도 1이 도시하는 구성 요소의 일부가 변경, 삭제되거나 새로운 구성 요 소가 더 포함된 것일 수 있다. 특징 추출부와 특징 통합부는 내부적으로 두 번의 특징 추출 과정을 수행하여 압축된 특징 정보를 추출하도록 통합될 수 있다. 한편, 도 1에 도시된 심리상태 추론장치는 장치에 한하지 않고, 각 구성(100 내지 160)의 기능을 수행하는 소프트웨어 모듈 또는 프로세서로 구현될 수도 있다. 입력부는 대상자의 동영상을 입력받는다. 이러한 입력은 입력장치를 통해 입력받는 것은 물론, 스토리지/ 메모리로부터 데이터를 로드하여 입력되는 것일 수 있다. 대상자의 동영상이란, 대상자의 얼굴의 전부 또는 일 부, 신체의 전부 또는 일부, 음성, 대상자의 발화, 대상자의 신체적 반응(예: 기침, 콧물 훌쩍임, 심장박동 등) 및/또는 신체 움직임에 의한 소리(예: 고개를 젓는 소리 등)가 기록된 연속적인 영상일 수 있다. 특징 추출부는 동영상으로부터 대상자에 관한 여러 특징 정보들을 추출한다. 특징 추출부는 동영상으 로부터, 특징 정보들로서, 대상자의 얼굴 특징, 신체 특징, 움직임 특징, 음성 특징 및/또는 발화한 텍스트 등 을 추출할 수 있다. 이러한 추출은, 지시된 도메인(예: 얼굴 특징, 신체 특징, 움직임 특징, 음성 특징 등)에 해당하는 정보를 각각 추출해내는 것일 수 있다. 이 경우에 지시된 도메인에는 추출의 우선순위가 있을 수 있다. 특징 추출부는 특정 정보의 추출 성능이 떨어지는 경우에는 해당 정보가 없다는 결과값을 출력함으 로써, 해당 정보를 추출할 수 있다. 예컨대, 동영상에 대상자의 발화가 없거나 유의미하게 추출 내지 구분할 만 큼 기록되지 않은 경우에는 텍스트 정보를 Null/0 등의 '없다'는 결과값으로써 텍스트 정보를 추출할 수 있는 것이다. 또 다른 예로, 동영상에 대상자의 얼굴 움직임이 유의미하게 추출 내지 구분할 만큼 기록되지 않은 경 우에는 움직임 특징에 관한 정보로서, 얼굴 움직임 특징(예: 움직이는 방향, 속도, 벡터의 크기 등)을 Null/0 등의 '없다'는 결과값으로써 추출할 수 있다. 이러한 여러가지 특징에 관한 정보는 예컨대, 인공신경 네트워크 예컨대, 동영상 또는 동영상이 포함하는 연속 된 이미지나 음향으로부터 해당 도메인에 관한 특징을 추출하도록 기학습된 전처리 네트워크를 이용하여 추출된 것일 수 있다. 여기서 얼굴 특징에 관한 정보는 예컨대, 얼굴의 랜드마크, 얼굴의 위치, 얼굴의 면적, 얼굴의 색상, 얼굴의 형 태, 입모양, 눈깜빡임, 표정 등일 수 있다. 신체 특징에 관한 정보는 예컨대, 신체의 위치, 신체의 길이, 신체의 면적, 신체부위에 관한 정보 등일 수 있다. 움직임 특징에 관한 정보는 예컨대, 얼굴의 움직임 특징, 신체 또는 신체부위의 움직임 특징, 자세 등일 수 있 다. 음성 특징에 관한 정보는 예컨대, 음성의 어조, 음성의 강도, 높낮이, 주파수, 음성의 변화, 음성을 mel spectrogram 변환된 정보일 수 있다. 또한 특징 추출부는 음성을 텍스트로 변환시킨 텍스트 정보를 특징 정보들로서 더 추출할 수도 있다. 이러 한 텍스트 정보는 NLP에 의해 만들어진 말뭉치 지식맵의 형태의 데이터일 수 있다. 특징 추출부는 동영상 중 이미지에 해당하는 데이터로부터 얼굴 특징, 상기 신체 특징 및/또는 움직임 특 징에 관한 정보를 추출하고, 음향에 해당하는 데이터로부터 음성 특징에 관한 정보 및/또는 텍스트 정보를 추출 할 수도 있다. 이는 보다 효율적인 특징 추출을 위함이다. 특징 추출부가 추출하는 특징 정보들은 임베딩 벡터의 형태일 수 있다. 특징 통합부는 추출된 특징 정보들로부터 대상자의 심리상태를 추론하기 위한 압축된 특징 정보를 추출한 다. 이는 추출된 음성, 신체, 얼굴, 텍스트 등의 압축된 정보, 즉 특징 정보들을 압축적으로 통합함으로써 인공 신경 네트워크를 짧은 시간동안 통합적으로 학습시키기 위함이다. 특징 통합부는 특징 정보들을 통합하고, 통합된 특징 정보들을 인코더를 통해 추가 압축함으로써 대상자의 심리상태를 추론하기 위해 필수적인 특징 정 보들을 압축된 형식으로 추출할 수 있다. 여기서 필수적인 특징 정보란, 심리상태 추론장치의 성능이 특정 임계값 이상이 되기 위하여 적어도 추론부에 입력되어야 하는 특징 정보들일 수 있다. 추론부는 압축된 특징 정보로부터 대상자의 심리상태를 추론한다. 이때 추론결과는, 감정 분류, 감정의 강 도 및/또는 생리정보(예: 땀, 체온, 심박수, 눈물, 상태의 좋고 나쁨의 이진분류 등)일 수 있다. 즉 심리상태의 추론이란, 감정, 감정의 강도, 생리상태의 정보들로써 나타낼 수 있는 것이다. 추론부는 추론 성능을 고려 하여 분류가능한 감정의 종류, 감정의 강도를 나타내는 값의 범위, 생리정보의 갯수 또는 분류되는 종류(예: 이 진 분류 등)를 달리할 수 있다. 도 2는 본 개시의 일 실시예에 따른 심리상태 추론장치를 나타내는 예시도이다. 심리상태 추론장치는 인공신경 네트워크를 전부 또는 부분적으로 이용함으로써 입력된 영상으로부터 대상자 의 심리상태를 추론할 수 있다. 이러한 인공신경 네트워크는, 전처리 네트워크, 특징 추출 네트워크, 임베딩 네트워크, 특징 통합 네트워크 및 추론 네트워크의 전부 또는 일부를 포함할 수 있으나, 이에 한하지 않는다. 또한 심리상태 추론장치의 각 인공신경 네트워크의 전부 또는 일부는 효율적 추론을 위하여 기 학습된 것일 수 있다. 전처리 네트워크는 입력된 동영상을 이미지와 음향으로 분리한다. 전처리 네트워크는 음향으로부터 음성을 더 분리할 수도 있다. 전처리 네트워크가 분리해내는 이미지와 음향은 반드시 연속적일 필요는 없 으나, 시계열적 순서대로여야 한다. 예컨대, 동영상을 어떤 시간단위로 분리하느냐에 따라 분리되는 이미지의 갯수 등이 달라질 수는 있으나, 이미지 간의 순서는 유지되어야 한다. 특징 추출 네트워크는 동영상 또는 동영상으로부터 분리된 이미지와 음향을 입력받아, 얼굴 특징, 신체 특 징, 움직임 특징 및/또는 음성 특징에 관한 정보들을 추출할 수 있다. 특징 추출 네트워크는 더 나아가 텍 스트 정보 또한 추출할 수 있다. 한편, 추출된 특징 정보들은 임베딩 네트워크를 통해 임베딩 벡터의 형태로 변환 내지 압축될 수 있다. 이 러한 임베딩 네트워크는 1차원 또는 2차원의 CNN Network와 LSTM이 결합된 형태로 구현될 수 있다. 또는 CNN Network, LSTM, 및/또는 Transformer의 전부 또는 일부 네트워크를 통합하여 구현할 수도 있다. 이는 예시 적인 것으로, 임베딩 네트워크에는 그 외에 임베딩이 가능한 네트워크라면 어느 것이든 채용될 수도 있다. 특징 통합 네트워크는 추출된 특징 정보들 또는 이러한 특징 정보들이 임베딩된 데이터들을 입력으로 하여 심리상태를 추론하기 위한 특징 정보들을 추출할 수 있다. 특징 통합 네트워크는 심리상태를 추론하기 위 한 특징 정보들을 '압축' 형태로 추출하는데, 여기서 '압축'은 입력된 정보의 정보량을 감소시키는 방식 내지 심리상태 추론의 성능에 따라 중요도의 우선순위에 따라 특정 특징 정보만을 선별적으로/가중치를 달리하여 추 출하는 방식일 수도 있다. 또는 입력된 임베딩 벡터들의 조합 중 특정 조합들만을 추출하는 방식일 수도 있다. 특징 통합 네트워크가 추출하는 압축된 특징 정보는 네트워크의 학습 방향이나 기학습된 도메인이 반영되 어 추출되는 것이고, 반드시 전술한 방식을 따르는 것은 아니다. 특징 통합 네트워크는 인코더 네트워크이거나, Transformer의 구조가 채용된 네트워크일 수 있다. 특징 통 합 네트워크는 그 외에 CNN, LSTM, Dense Layer 등 다양한 특징 통합 네트워크의 전부 또는 일부 네트워크 를 채용하여 구현되는 것일 수도 있다. 특징 통합 네트워크가 추출한 결과는 임베딩 벡터의 형태일 수 있다. 추론 네트워크는 압축된 특징 정보로부터 대상자의 심리상태를 추론하는 네트워크이다. 추론 네트워크 는 압축된 특징 정보를 입력받아, 대상자의 심리상태로서, 감정 분류, 감정의 강도 및/또는 대상자에 관한 적어도 하나의 생리상태 정보를 추론할 수 있다. 예컨대, 추론 네트워크는, 압축된 특징 정보로부터 각각 인지되는, 대상자의 신체상태, 음성의 어조 및 텍스트의 내용을 기반으로 대상자의 감정의 정도를 추론할 수 있 다. 또 다른 예로, 추론 네트워크는 압축된 특징 정보로부터 각각 인지되는, 대상자의 움직임의 정도, 음 성의 강도 및 텍스트의 내용을 기반으로, 대상자에 관한 적어도 하나의 생리상태 정보를 추론할 수도 있다. 한편, 심리상태 추론장치의 인공신경 네트워크의 전부 또는 일부는 다양한 방식에 의해 학습될 수 있다. 예 컨대, 최종 결과물로서, 추론부의 추론 결과를 정답과 비교하여 Loss를 산출하고, 이러한 Loss를 감소시키 는 방향으로 학습될 수 있다. 이러한 학습은, L1/L2Loss나, 그 외에 Supervised 방식의 손실함수를 적용하여 수 행될 수 있다. 이 경우에 전처리 네트워크는 기학습된 네트워크일 수 있다. 학습 성능의 향상을 위해서는, 추론부 추론 결과와 정답을 비교하는 L1/L2 Loss외에, 압축된 특징 정보(또 는 압축된 특징 임베딩 벡터)의 표현 공간(feature representation space)상에서, 동일한 클래스의 압축된 특징 정보간에는 거리가 가깝고, 다룬 클래스의 정보 거리는 멀게 위치하도록 하여, 압축된 특징 정보의 추출 성능, 나아가 이를 이용한 추론 성능을 높이는 Triplet loss 방식에 의할 수 있다. Triplet loss방식을 적용하기 위하 여는, 클래스가 라벨링된 동영상들로부터 임의의 동영상 한 개를 정하여 기준(Anchor) 동영상으로 정의하고, 해 당 기준 동영상으로부터 압축된 특징 정보를 추출한다. 여기서 클래스란, 추론부가 심리상태로서 추론하는 정보에 관한 분류를 의미한다. 예컨대, 심리상태로서 감정 분류를 하는 경우에 클래스는 세부 감정 분류(예: 기 쁨, 슬픔, 분노, 황당, 호기심 등)일 수 있다. 또 다른 예로, 심리상태로서 감정 강도를 분류하는 경우에 클래 스는 세부 감정 강도 분류(예: 강함, 중간, 약함 등)일 수 있다. Triplet loss 학습은, 기준 동영상과 같은 클래스의 동영상으로부터 추출된 압축된 통합 정보와, 기준 동영상과 다른 클래스의 동영상으로부터 추출된 통합 압축된 통합 정보를 구분하여 2번에 걸친 학습일 수 있다. 학습의 횟수는 클래스 수에 따라 결정될 수 있다. 예컨대, 클래스로서 감정 분류의 개수가 5개라면 5번의 학습을 진행 한다. Triplet loss 학습은 예컨대, 특징 통합 네트워크로부터 추출된, 압축된 특징 정보 가운데, 동일한 클래스 의 동영상으로부터 추출된 압축된 특징 정보의 페어는 positive, 서로 다른 클래스의 동영상으로부터 추출된 압 축된 특징 정보의 페어는 negative로 레이블링하여, Triplet loss를 연산함으로써 수행될 수 있다. 특징 통합 네트워크는 연산된 Triplet loss를 기반으로 학습 성능, 학습 시간 등을 고려하여 학습될 수 있다. 또 다른 학습 방식으로서, 이러한 학습은 추론부의 추론 결과를 이용하여 역전파 방식으로, 추론 네트워크 , 특징 통합 네트워크, 임베딩 네트워크, 특징 추출 네트워크의 순서로, 전술한 네트워크 (222 내지 260)의 전부 또는 일부를 한 사이클에 학습시킬 수도 있다. 이 경우에 학습 효과 샹항을 위해 일부 네트워크들은 학습이 생략될 수 있다. 예컨대, 임베딩 네트워크는 기학습된 네트워크일 수 있다. 도 3은 본 개시의 일 실시예에 따른 심리상태 추론방법을 나타내는 흐름도이다. 심리상태 추론장치가 대상자의 동영상을 입력받는다(S300). 심리상태 추론장치가 입력된 동영상으로부터 특징 정보들을 추출한다(S310). 단계 S310은 예컨대, 동영상으로부 터 음향과 이미지를 분리하는 과정과, 분리된 이미지로부터 얼굴 특징, 신체 특징 및/또는 움직임 특징에 관한 정보를 추출하고, 분리된 음향으로부터 음성 특징에 관한 정보 및/또는 텍스트 정보를 추출하는 과정일 수도 있 다. 이러한 분리에는, 전처리 네트워크가 이용될 수 있다. 또한 이러한 여러가지 특징에 관한 정보의 추출에는, 특징 추출 네트워크가 이용될 수 있다. 단계 S320은 추출된 특징들을 임베딩 네트워크에 통과시키어, 단계 S310 의 추출 결과로서 임베딩 벡터들을 출력할 수도 있다. 심리상태 추론장치가 특징 정보들로부터 대상자의 심리상태를 추론하기 위한 압축된 특징 정보를 추출한다 (S320). 이러한 추출에는, 특징 통합 네트워크가 이용될 수 있다. 심리상태 추론장치가 압축된 특징 정보로부터 대상자의 심리상태를 추론한다(S330). 이러한 추론에는, 추론 네 트워크가 이용될 수 있다. 심리상태 추론장치가 단계 S330의 추론 결과를 이용하여, 인공신경 네트워크의 전부 또는 일부를 학습시킨다 (S340). 예컨대 단계 S300에서 입력받은 동영상은 정답 심리상태가 레이블링된 데이터로서, 단계 S330의 추론 결과와 정답 심리상태를 이용하여 학습이 수행될 수 있다. 예컨대, 인공신경 네트워크의 전부 또는 일부로서, 단계 S320에서 이용될 수 있는 특징 통합 네트워크를 단계 S330 추론 결과를 이용하여 역전파 학습시킬 수 있다. 이 경우에 특징 통합 네트워크는, 특징 정보들을 압축한 결과로부터 대상자의 심리상태를 추론하기 위한 특정 정보들만을 압축된 특징 정보로서 추출하도록 학습될 수 있다. 여기서 특정 정보는, 학습 성능 및/또는 추 론 성능을 향상시키기 위한 기준에 따라 인지적으로 결정되는 것일 수 있다. 도 4는 본 개시의 일 실시예에 따른 심리상태 추론장치의 학습방법을 나타내는 예시도이다. 도 4는 Triplet Learning 방식으로 심리상태 추론장치를 학습시키는 방법을 예시적으로 나타낸다. 심리상태 추론장치는, 심리상태를 나타내기 위한 클래스가 분류된 동영상들로부터, 기준 동영상을 임의로 정한 다(S400). 심리상태 추론장치는 세 가지의 서로 다른 동영상으로서, 기준 동영상, 기준 동영상과 동일한 클래스의 동영상 (이하, “기준 클래스 동영상”), 기준 동영상과 다른 클래스의 동영상(이하, “기준과 다른 클래스 동영상”) 을 입력 받는다(S410) 심리상태 추론장치는 기준 동영상, 기준 클래스 동영상, 기준과 다른 클래스 동영상으로부터 특징 정보들을 각 각 추출한다(S420). 이러한 추출은, 대상자의 심리상태를 추론하기 위하여, 입력된 데이터로부터 특징 정보를 추출하기 위해 구성된 인코더 네트워크로 구현되는 임베딩 네트워크를 이용하여 수행될 수 있다. 심리상태 추론장치는, 특징 통합 네트워크에 추출된 특징 정보들을 입력하여 압축된 특징 정보를 추출한다 (S430). 이러한 특징 통합 네트워크는, 대상자의 심리상태를 추론하기 위하여, 특징 정보들(또는 특징 임베딩 벡터)로부터 특징들을 추출하기 위해 구성된 인코더 네트워크로 구현될 수 있다. 인코더 네트워크에 출력된 결 과는 MLP (Multi-layer perceptrons)를 통해 더 작은 차원의 값으로 변환될 수 있다. 즉, 특징 통합 네트워크는 전술한 인코더 네트워크 및/또는 MLP로 구성된 네트워크일 수 있다. 심리상태 추론장치는 기준 동영상과 동일한 클래스의 동영상으로부터 추출된 통합 특징 정보들의 페어를 positive, 기준 동영상과 다른 클래스의 동영상으로부터 추출된 특징 정보들의 페어를 negative로 레이블링하여 페어들을 구성한다(S440). 심리상태 추론장치는 Triplet loss를 연산하여 심리상태 추론장치의 특징 통합 네트워크를 학습시킨다(S450). 이는 특징 통합 네트워크의 출력이 특징 표현 공간상에서 positive 페어의 임베딩은 가깝게, negative 페어의 임베딩은 멀게 위치하도록(또는 표상되도록) 특징 통합 네트워크를 학습시키는 것이다. 이러한 Triplet loss를 이용한 학습은 데이터의 차원을 축소해주어 기존 차원 축소 기법 대비 데이터 압축에 적 은 연산이 소요되고, 비지도 학습이기에 학습용 데이터셋에 정답 레이블링을 필요로 하지 않는 이점이 있다. 한편, 도 3 및 도 4는 심리상태 추론장치의 동작 방법을 예시적으로 나타내는 것이고, 심리상태 추론장치의 동 작이 반드시 도 3 및 도4의 단계에 따라 순차적으로 실행되는 것은 아니다. 예컨대, 도 3 및 도 4의 각 단계는 본 개시의 심리상태 추론장치의 본질에 반하지 않는 범위 내에서 병렬적이거나, 순서를 달리하거나, 일부 단계 가 생략되어 수행될 수 있다. 예컨대, 도 3의 단계 S340은 생략될 수 있다. 본 개시의 전술한 장치 또는 방법의 다양한 실시예는, 하나 이상의 컴퓨터 프로그램으로 구현되는 것을 포함할 수 있다. 이러한 컴퓨터 프로그램은, 하나 이상의 입력 장치, 하나 이상의 출력 장치, 메모리를 포함하고, 메모 리, 입력 장치, 출력 장치 간 데이터 및 명령을 송수신하도록 결합된 하나 이상의 프로그래밍 가능한 프로세서 를 포함하는 컴퓨터 시스템에 의해 실행, 구동, 작동, 운영될 수 있다. 컴퓨터 시스템은 예컨대, 서버, 네트워 크 기기, 셋톱박스, 내장형 장치, 컴퓨터 확장 모듈, 개인용 컴퓨터, 랩톱, PDA(Personal Data Assistant), 클 라우드 컴퓨팅 시스템 또는 모바일 장치일 수 있으나, 이에 한하지 않는다. 컴퓨터 프로그램들(예: 펌웨어, 미 들웨어, OS, 소프트웨어, 애플리케이션, 소스 코드)은 프로그래밍 가능한 프로세서를 구동 내지 제어하기 위한 명령어들을 포함하며, 컴퓨터가 읽을 수 있는 기록매체에 저장된다. 여기서, 컴퓨터가 읽을 수 있는 기록매체란, 컴퓨터 시스템에 의하여 읽힐 수 있는 데이터가 저장되는 모든 종 류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 기록매체는 예컨대, ROM, 자기 테이프, 플로피 디스크, 메모리 카드, 하드 디스크, 광자기 디스크, 스토리지 디바이스 등일 수 있으나, 이에 한하지 않음은 명확하다. 또 한, 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수도 있다. 이상은 본 개시의 다양한 실시예들을 설명한 것으로, 이 분야 통상의 기술자가 채용할 수 있는 다양한 구성, 물 질, 수단, 방법, 지식에 의해 다양한 변형이 가능하다. 이러한 실시예들은 본 개시의 기술적 사상을 설명하기 위한 것일 뿐, 본 개시의 기술적 사상과 그 범위를 한정하지 않는다."}
{"patent_id": "10-2023-0007704", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 심리상태 추론장치를 나타내는 개념도이다. 도 2는 본 개시의 일 실시예에 따른 심리상태 추론장치를 나타내는 예시도이다. 도 3은 본 개시의 일 실시예에 따른 심리상태 추론방법을 나타내는 흐름도이다. 도 4는 본 개시의 일 실시예에 따른 심리상태 추론장치의 학습방법을 나타내는 예시도이다."}
