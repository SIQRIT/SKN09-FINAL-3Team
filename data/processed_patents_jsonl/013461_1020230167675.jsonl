{"patent_id": "10-2023-0167675", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0044068", "출원번호": "10-2023-0167675", "발명의 명칭": "전통적 의료영상을 초다시점 입체 디스플레이 영상으로 자동 변환하기 위한 장치 및 방법", "출원인": "한국과학기술연구원", "발명자": "한형섭"}}
{"patent_id": "10-2023-0167675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 기반으로 의료 영상으로부터 관심 영역을 예측하여 초다시점 디스플레이 영상으로 변환하기 위한 장치로서,영상 촬영 장비로부터 의료 영상을 획득하도록 구성되는 입력부;상기 의료 영상으로부터 종양 및 종양 주변 조직에 대응하는 관심 영역들을 분할하고 제 1 CNN(ConvolutionalNeural Network) 기반 알고리즘을 이용하여 분할된 관심 영역들을 학습시키도록 구성되는 학습부;상기 학습된 관심 영역들에 기초하여 제 2 CNN 기반 알고리즘을 이용하여 추론된 관심 영역들을 검출하도록 구성되는 추론부;상기 검출된 관심 영역들에 대응하는 오브젝트를 생성하여 저장하도록 구성되는 저장부; 및상기 오브젝트를 초다시점 디스플레이 영상으로 변환하도록 구성되는 출력부를 포함하는,장치."}
{"patent_id": "10-2023-0167675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 학습부는 리전 그로잉(Region Growing) 알고리즘 및 스레스홀드(Threshold) 알고리즘을 이용하여 상기 관심 영역들의 주석처리 및 분할을 수행하고, 분할된 관심 영역들을 레이블링하도록 추가적으로 구성되는,장치."}
{"patent_id": "10-2023-0167675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 제 1 CNN 기반 알고리즘은 SegResNet 알고리즘을 포함하고,상기 학습부는 상기 레이블링된 분할된 관심 영역들을 상기 SegResNet 알고리즘을 이용하여 학습시키도록 추가적으로 구성되는,장치."}
{"patent_id": "10-2023-0167675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 SegResNet 알고리즘을 이용한 학습은 상기 레이블링된 분할된 관심 영역들에 대한 특징 추출(FeatureExtraction) 및 분류(Classification)를 포함하는,장치."}
{"patent_id": "10-2023-0167675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 제 2 CNN 기반 알고리즘은 3D-Unet 모델을 포함하며,상기 추론부는 상기 3D-Unet 모델을 이용한 자동 분할(Automated Segmentation)을 통해 3차원적으로 추론된 관심 영역들을 검출하도록 추가적으로 구성되는,장치.공개특허 10-2025-0044068-3-청구항 6 제 5 항에 있어서,상기 저장부는 상기 3차원적으로 추론된 관심 영역들을 병합하여 하나의 3D 오브젝트로 저장하도록 추가적으로구성되는,장치."}
{"patent_id": "10-2023-0167675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 출력부는 상기 3D 오브젝트를 이용하여 초다시점 홀로그램 디스플레이 영상을 출력하도록 추가적으로 구성되는,장치."}
{"patent_id": "10-2023-0167675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "인공지능 기반으로 의료 영상으로부터 관심 영역을 예측하여 초다시점 디스플레이 영상으로 변환하기 위한 방법으로서,영상 촬영 장비로부터 의료 영상을 획득하는 단계;상기 의료 영상으로부터 종양 및 종양 주변 조직에 대응하는 관심 영역들을 분할하고 제 1 CNN 기반 알고리즘을이용하여 분할된 관심 영역들을 학습시키는 단계;상기 학습된 관심 영역들에 기초하여 제 2 CNN 기반 알고리즘을 이용하여 추론된 관심 영역들을 검출하는 단계;상기 검출된 관심 영역들에 대응하는 오브젝트를 생성하는 단계; 및상기 오브젝트를 초다시점 디스플레이 영상으로 변환하는 단계를 포함하는,방법."}
{"patent_id": "10-2023-0167675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 관심 영역들을 분할하는 단계는,리전 그로잉 알고리즘 및 스레스홀드 알고리즘을 이용하여 상기 관심 영역들의 주석처리 및 분할을 수행하는 단계; 및분할된 관심 영역들을 레이블링하는 단계를 포함하는,방법."}
{"patent_id": "10-2023-0167675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 제 1 CNN 기반 알고리즘은 SegResNet 알고리즘을 포함하고,상기 분할된 관심 영역들을 학습시키는 단계는, 상기 레이블링된 분할된 관심 영역들을 상기 SegResNet 알고리즘을 이용하여 학습시키는 단계를 포함하는,방법."}
{"patent_id": "10-2023-0167675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 SegResNet 알고리즘을 이용한 학습은 상기 레이블링된 분할된 관심 영역들에 대한 특징 추출 및 분류를 포공개특허 10-2025-0044068-4-함하는,방법."}
{"patent_id": "10-2023-0167675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 8 항에 있어서,상기 제 2 CNN 기반 알고리즘은 3D-Unet 모델을 포함하며,상기 추론된 관심 영역들을 검출하는 단계는, 상기 3D-Unet 모델을 이용한 자동 분할을 통해 3차원적으로 추론된 관심 영역들을 검출하는 단계를 포함하는,방법."}
{"patent_id": "10-2023-0167675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,상기 오브젝트를 생성하는 단계는,상기 3차원적으로 추론된 관심 영역들을 병합하여 하나의 3D 오브젝트를 생성하는 단계를 포함하는,방법."}
{"patent_id": "10-2023-0167675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 변환하는 단계는,상기 3D 오브젝트를 이용하여 초다시점 홀로그램 디스플레이 영상을 출력하는 단계를 포함하는,방법."}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시 내용에 따르면, 전통적 의료영상을 초다시점 입체디스플레이 영상으로 자동 변환하기 위한 장치 및 방법 이 제시된다. 상기 장치는, 영상 촬영 장비로부터 의료 영상을 획득하도록 구성되는 입력부; 상기 의료 영상으로 부터 종양 및 종양 주변 조직에 대응하는 관심 영역들을 분할하고 제 1 CNN 기반 알고리즘을 이용하여 분할된 관 심 영역들을 학습시키도록 구성되는 학습부; 상기 학습된 관심 영역들에 기초하여 제 2 CNN 기반 알고리즘을 이 용하여 추론된 관심 영역들을 검출하도록 구성되는 추론부; 상기 검출된 관심 영역들에 대응하는 오브젝트를 생 성하도록 구성되는 저장부; 및 상기 오브젝트를 초다시점 디스플레이 영상으로 변환하도록 구성되는 출력부를 포 함할 수 있다."}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시 내용은 다양한 종양과 종양 주변의 혈관 및 신경 등과 같은 조직 등을 인공지능 기반의 의료영상 분할 기법을 이용하여 검출하고, 검출된 결과를 3차원 초다시점 디스플레이 기술을 이용하여 자동 변환하기 위한 장 치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종양은 임상 전문가들이 CT 및 MRI 검사를 통해서 단면적인 영상을 가지고 판독하게 된다. 이러한 이유로 뇌종 양과 뇌종양 주변에 있는 혈관 및 신경들이 어떻게 얽혀있는지 정확히 확인할 수 없기 때문에 수술할 때 많은 어려움이 있다. 종양, 특히 뇌종양은 뇌 내부에서 비정상적인 세포가 형성될 때 발생하며, 통제되지 않은 방식으로 증식하는 뇌 세포의 성장을 의미한다. 뇌종양은 양성종양(뇌수막종, 두개인두종, 청신경초종, 뇌하수체 종양 등) 및 악성종 양(악성신경교종, 교모세포종, 수모세포종, 뇌전이암 등)과 같은 두 가지의 유형으로 구분할 수 있다. 양성종양 은 원발성으로 성장속도가 느리며 재발 가능성이 낮다. 악성종양은 전이성으로 성장 속도가 빠르며 재발 가능성 이 높다. 뇌종양은 종양의 위치 및 크기에 따라서 뇌 손상으로 인한 장애가 발생하거나 사망할 수 있는 가장 무 서운 질병 중 하나이다. 최근에, 상기 이슈를 해결하기 위하여 많은 임상 전문가들과 의료영상 전문가들이 인공지능 기술을 이용하여 3 차원적으로 뇌종양을 검출하는 연구를 진행하고 있다. 그러나, 인공지능 기반으로 3차원적인 종양 모델을 검출 하지만, 종양과 종양 주변의 혈관 및 신경 조직들의 위치를 모두 보여주지 못하는 문제점이 존재한다. 또한, 종 양 관련 임상 전문가들이 종양 제거 수술을 진행할 때, 본인이 직접 컴퓨터 조작을 하지 않더라도 3차원 입체"}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "디스플레이 영상을 통해서 종양과 종양 주변 조직들의 위치를 확인할 수 있는 기술이 필요하다.발명의 내용"}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이러한 문제점을 해결하기 위한 본 개시 내용은 전통적 의료영상을 초다시점 입체디스플레이 영상으로 자동 변 환하기 위한 장치 및 방법을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시 내용에 따르면, 인공지능 기반의 의료영상 분할 방법으로 검출된 3차원 종양 및 종양 주변 조직(혈관 및 신경 포함) 모델을 초다시점 디스플레이로 자동 변환하기 위한 장치 및 방법이 제공될 수 있다. 본 개시 내용의 일 실시예에 따르면, 인공지능 기반으로 의료 영상으로부터 관심 영역을 예측하여 초다시점 디 스플레이 영상으로 변환하기 위한 장치가 제공될 수 있다. 상기 장치는, 영상 촬영 장비로부터 의료 영상을 획 득하도록 구성되는 입력부; 상기 의료 영상으로부터 종양 및 종양 주변 조직에 대응하는 관심 영역들을 분할하 고 제 1 CNN(Convolutional Neural Network) 기반 알고리즘을 이용하여 분할된 관심 영역들을 학습시키도록 구 성되는 학습부; 상기 학습된 관심 영역들에 기초하여 제 2 CNN 기반 알고리즘을 이용하여 추론된 관심 영역들을 검출하도록 구성되는 추론부; 상기 검출된 관심 영역들에 대응하는 오브젝트를 생성하여 저장하도록 구성되는 저장부; 및 상기 오브젝트를 초다시점 디스플레이 영상으로 변환하도록 구성되는 출력부를 포함할 수 있다. 또한, 상기 학습부는 리전 그로잉(Region Growing) 알고리즘 및 스레스홀드(Threshold) 알고리즘을 이용하여 상 기 관심 영역들의 주석처리 및 분할을 수행하고, 분할된 관심 영역들을 레이블링하도록 추가적으로 구성될 수 있다. 또한, 상기 제 1 CNN 기반 알고리즘은 SegResNet 알고리즘을 포함할 수 있다. 상기 학습부는 상기 레이블링된 분할된 관심 영역들을 상기 SegResNet 알고리즘을 이용하여 학습시키도록 추가적으로 구성될 수 있다. 또한, 상기 SegResNet 알고리즘을 이용한 학습은 상기 레이블링된 분할된 관심 영역들에 대한 특징 추출 (Feature Extraction) 및 분류(Classification)를 포함할 수 있다. 또한, 상기 제 2 CNN 기반 알고리즘은 3D-Unet 모델을 포함할 수 있다. 상기 추론부는 상기 3D-Unet 모델을 이 용한 자동 분할(Automated Segmentation)을 통해 3차원적으로 추론된 관심 영역들을 검출하도록 추가적으로 구 성될 수 있다. 또한, 상기 저장부는 상기 3차원적으로 추론된 관심 영역들을 병합하여 하나의 3D 오브젝트로 저장하도록 추가 적으로 구성될 수 있다. 또한, 상기 출력부는 상기 3D 오브젝트를 이용하여 초다시점 홀로그램 디스플레이 영상을 출력하도록 추가적으 로 구성될 수 있다. 본 개시 내용의 일 실시예에 따르면, 컴퓨팅 장치에 의해 수행가능한, 인공지능 기반으로 의료 영상으로부터 관 심 영역을 예측하여 초다시점 디스플레이 영상으로 변환하기 위한 방법이 제공될 수 있다. 상기 방법은, 영상 촬영 장비로부터 의료 영상을 획득하는 단계; 상기 의료 영상으로부터 종양 및 종양 주변 조직에 대응하는 관심 영역들을 분할하고 제 1 CNN 기반 알고리즘을 이용하여 분할된 관심 영역들을 학습시키는 단계; 상기 학습된 관 심 영역들에 기초하여 제 2 CNN 기반 알고리즘을 이용하여 추론된 관심 영역들을 검출하는 단계; 상기 검출된 관심 영역들에 대응하는 오브젝트를 생성하는 단계; 및 상기 오브젝트를 초다시점 디스플레이 영상으로 변환하 는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시 내용에 따르면, 전통적 의료영상을 초다시점 입체디스플레이 영상으로 자동 변환하기 위한 장치 및 방 법을 제공함으로써 임상 전문가들이 직접 컴퓨터 조작을 하지 않고도 3차원 입체 디스플레이 영상을 통해서 종 양과 종양 주변 조직들의 위치를 확인할 수 있는 기술적 효과를 달성할 수 있다."}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 바람직한 실시예들을 첨부된 도면들을 참조하여 상세히 설명한다. 우선 각 도면의 구성요소들 에 참조부호를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동 일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명을 설명함에 있어, 관련된 공지 구성 또는 기 능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 본 발명의 다양한 양상들이 아래에서 설명된다. 여기에서 제시되는 발명들은 폭넓은 다양한 형태들로 구현될 수 있으며 여기에서 제시되는 임의의 특정한 구조, 기능 또는 이들 모두는 단지 예시적이라는 것을 이해하도록 한 다. 여기에서 제시되는 발명들에 기반하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자는 여기에서 제시되는 하나의 양상이 임의의 다른 양상들과 독립적으로 구현될 수 있으며 둘 이상의 이러한 양상들이 다양한 방식들로 결합될 수 있다는 것을 이해할 것이다. 예를 들어, 여기에서 설명되는 임의의 수의 양상들을 이용하여 장치가 구현될 수 있거나 또는 방법이 실시될 수 있다. 또한, 여기에서 설명되는 하나 이상의 양상들에 더하여 또는 이들 양상들이 아닌 다른 구조, 기능 또는 구조 및 기능을 이용하여 이러한 장치가 구현될 수 있거나 또는 이러한 방법이 실시될 수 있다. 본 개시 내용은 병원, 진료 기관 등에서 운용되는 의료 영상 분석 장비에 적용될 수 있으며, 이에 한정되지 않 고 다양한 종류의 영상들에서 관심 영역을 추론 및 검출하여 3D 디스플레이 영상을 제공하는 애플리케이션들에 이용될 수 있다. 도 1은 본 개시 내용의 일 실시예에 따른 인공지능 기반으로 의료 영상으로부터 관심 영역을 예측하여 초다시점 디스플레이 영상으로 변환하기 위한 컴퓨팅 장치를 나타내는 예시적인 블록도이다. 컴퓨팅 장치는 CT/MRI와 같은 영상 촬영 장비(미도시)로부터 획득되는 의료 영상을 처리하도록 구성될 수 있다. 도 1에 도시된 바와 같이, 컴퓨팅 장치는 프로세서, 저장 매체, 메모리, 네트워크 인터페이스를 포함할 수 있으며, 이들은 시스템 버스를 통해 서로 연결될 수 있다. 저장 매체에는 운영 시스템(OS) 및 컴퓨터 프로그램이 탑재될 수 있다. 저장 매체는 컴퓨 터 프로그램 및 관련 데이터들을 저장할 수 있는 하드디스크, SSD(Solid State Drive) 등과 같은 데이터 저장 장치일 수 있다. 운영 시스템은 컴퓨팅 장치를 동작시키기 위한 Windows, IOS, Linux 등과 같은 운영 체재 소프트웨어일 수 있다. 컴퓨터 프로그램은 본 개시 내용에 따른 인공지능 기반으로 의료 영상으로부 터 관심 영역을 예측하여 초다시점 디스플레이 영상으로 변환하기 위한 기능 모듈들뿐만 아니라 이를 위한 컴퓨 터-실행가능 명령들을 포함할 수 있다. 컴퓨터 프로그램의 컴퓨터-실행가능 명령들은 프로세서에 의 해 실행될 때, 프로세서로 하여금 본 개시 내용의 인공지능 기반으로 의료 영상으로부터 관심 영역을 예측 하여 초다시점 디스플레이 영상으로 변환하기 위한 방법을 수행하게 할 수 있다. 프로세서는 전체 컴퓨팅 장치의 실행을 지원하기 위한 컴퓨팅 및 제어 능력들을 제공하도록 구성될 수 있다. 프로세서는 CPU(Central Processing Unit), MPU(Microprocessor Unit), AP(Application Processor) 등과 같은 데이터 처 리 장치일 수 있으며, 하나의 프로세서 또는 복수개의 프로세서들로 구성될 수 있다. 복수개의 프로세서들로 구 성되는 경우, 프로세서들은 병렬 처리 프로세서들로서 동작할 수 있다. 네트워크 인터페이스는 외부 장치(예를 들어, 영상 촬영 장비, 영상 디스플레이 장치, 네트워크를 통해 연결가능한 다른 유무선 통신 디바이 스 등)와 연결되어 데이터를 통신할 수 있는 인터페이스를 제공할 수 있다. 본 개시 내용에 따른 컴퓨팅 장치는 도 2 내지 도 19와 관련하여 후술할 바와 같이 목표로 하는 의료 영상 을 입력받고, 의료영상 분할방법 및 CNN(Convolutional Neural Network) 기반의 알고리즘을 이용하여 종양 및 종양 주변 조직들(혈관 및 신경 등)의 영역들을 모두 검출 및 학습하고, 자동 분할(Automated Segmentation) 방 법으로 해당 관심 영역을 예측하여 검출하고, 그리고 검출 결과를 3차원 초다시점 입체디스플레이 방식으로 자 동 변환하여 출력하도록 구성될 수 있다. 도 2는 본 개시 내용의 일 실시예에 따른 도 1의 컴퓨팅 장치의 기능 모듈들을 나타내는 예시적인 블록도이다. 도 2에 도시된 바와 같이, 컴퓨팅 장치는 영상 촬영 장비로부터 의료 영상을 획득하도록 구성되는 입력부 ; 의료 영상으로부터 종양 및 종양 주변 조직에 대응하는 관심 영역들을 분할하고 제 1 CNN 기반 알고리즘 을 이용하여 분할된 관심 영역들을 학습시키도록 구성되는 학습부; 학습된 관심 영역들에 기초하여 제 2 CNN 기반 알고리즘을 이용하여 추론된 관심 영역들을 검출하도록 구성되는 추론부; 검출된 관심 영역들에 대응하는 오브젝트를 생성하여 저장하도록 구성되는 저장부; 및 상기 오브젝트를 초다시점 디스플레이 영 상으로 변환하도록 구성되는 출력부를 포함할 수 있다. 도 3에 도시된 바와 같이, 입력부는 영상 촬영 장비에서 획득되는 CT/MRI 영상과 같은 의료 영상을 입력받 을 수 있다. 이러한 의료 영상은 종양 관련 파일을 포함할 수 있으며, 뇌 MRI영상의 경우 이러한 파일은 NIFTI(Neuroimaging Informatics Technology Initiative) 파일일 수 있으나 이에 한정되지 않고 컴퓨팅 장치 에서 영상 분석이 가능한 다른 포맷의 영상 데이터 파일일 수 있다. 도 4에 도시된 바와 같이, 학습부에서 수행되는 인공지능 기반 학습은 1) 리전 그로잉(Region Growing) 알 고리즘 및 스레스홀드(Threshold) 알고리즘을 이용하여 종양(예를 들어, 뇌종양) 및 종양 주변 조직 들(혈관 및 신경)의 주석처리(annotation) 및 분할(segmentation)을 수행하고(410, 420, 430, 440), 2) 주석 처리 후 분할 결과를 레이블링(labeling) 처리하고, 3) 레이블링된 분할 결과를 CNN 기반 알고리즘을 이용하여 학습(Training)시키는 과정을 포함할 수 있다. 1) 리전 그로잉 알고리즘 및 스레드홀드 알고리즘을 이용한 뇌종양 및 뇌종양 주변 조직들(혈관 및 신경)의 주 석처리 및 분할과정은 다음과 같다. 학습부는 의료 영상 분할 방법 중 리전 그로잉 방법을 이용하여 의료 영상에서 각 종양 및 종양 주변 조직 영역들을 전경(Foreground) 및 배경(Background)으로 분류 및 검출할 수 있다. 또한, 학습부는 의료 영상 분할 방법 중 스레드홀드 알고리즘을 이용하여 의료 영상에서 종양 주변 조직들의 내부와 외부 영역들을 (예를들어, 흑과 백으로) 분류하여 검출할 수 있다. 도 8에 예시된 바와 같이, 학습부는 종양 및 종양 주변 조 직들(혈관 및 신경)에 대한 영역은 각각 Foreground 1(뇌종양), Foreground 2(뇌혈관), Foreground 3(뇌신경) 으로 표시하고, 종양 및 종양 주변 조직들(혈관 및 신경)의 영역을 제외한 바깥 영역을 Background로 표시할 수 있다. 리전 그로잉 알고리즘을 이용하여, 학습부는 의료 영상에서 분할을 하고자 하는 종양 및 종양 주변 조직들 (혈관 및 신경)에 대한 영역의 시작점인 시드(seed) 픽셀을 선택하고, 선택한 시드 픽셀 주변의 이웃 픽셀을 탐 색할 수 있다. 학습부는 탐색한 이웃 픽셀 중 시드 픽셀과 유사한 색상 또는 밝기를 가진 픽셀을 선택하여 새로운 시드 픽셀을 생성할 수 있다. 학습부는 새로운 시드 픽셀을 중심으로 다시 이웃 픽셀을 탐색하고, 픽셀을 분류하는 과정을 반복하여 영역을 확장할 수 있다. 여기서, 주변의 이웃 픽셀과 비교하는 유사도 식은 다음과 같다. 수학식 1"}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에 따른 유사도 식은 다음과 같이 풀이될 수 있다. P(Ri)는 특정 영역을 나타내는 집합 Ri의 포인트에 대해 정의된 논리적 술어(logical predicate)이며, Φ는 Null 집합이다. (a) 분할이 완료되어야 한다는 것을 의미한다. 즉, 모든 픽셀이 특정 영역에 있어야 한다. (b) 영역의 포인트가 미리 정의된 방식으로 연결되어야 한다는 것을 요구한다. (c) 영역들이 분리되어야 한다는 것을 나타낸다. (d) 분할된 영역의 픽셀에 의해서 충족해야만 하는 속성을 다룬다. 예를 들어, 모든 픽셀이 동일한 회색조를 가 진다면 P(Ri)=TRUE일 수 있다. (e) 특정 영역 Ri와 Rj는 술어 P의 의미에서 다르다는 것을 나타낸다. 리전 그로잉 알고리즘을 이용하여, 학습부는 이웃의 픽셀에 대한 탐색 다음으로 확장된 영역의 경계를 검 사하여, 경계가 정확하지 않은 경우는 영역을 합치거나 분리할 수 있다. 학습부는 위 과정을 반복하여 모 든 영역을 분할한 후 최종 결과를 출력할 수 있다. 또한, 학습부는 스레드홀드 알고리즘 유형 중 로컬 적 응적 스레드홀드(Locally Adaptive Threshold) 알고리즘을 이용하여 뇌종양의 주변 조직(뇌혈관 및 뇌신경 포함) 영역들을 검출할 수 있다. 이러한 스레드홀드 알고리즘은 여러 값을 어떤 임계값을 기준으로 구별되는 색 상으로(예를 들어, 흑과 백의 색으로) 분류할 수 있으며, 다음과 같은 관련식으로 표현될 수 있다. 수학식 2 수학식 2에 따른 로컬 적응적 스레드홀드 알고리즘 식은 다음과 같이 풀이될 수 있다. b(x,y)는 그레이스케일 (Grayscale) I(x,y)의 이진화된 이미지를 나타내고, T는 임계값(Threshold Value)을 나타낸다. 로컬 적응 기술 에서 범위(Range), 분산(Variance) 또는 이웃 픽셀의 표면 맞춤(Surface-Fitting) 파라미터와 같이 일부 로컬 통계(Local Statistics)를 기반으로 각 픽셀에 대하여 스레스홀드가 계산될 수 있다. 또한, 로컬 적응적 스레드 홀드 알고리즘은 배경 제거, 평균 및 표준 유도 및 로컬 이미지 대비 등과 같은 다양한 방식으로 접근할 수 있 다. 도 9 내지 11은 리전 그로잉 알고리즘 및 스레드홀드 알고리즘을 이용하여 각각의 종양, 동맥 및 정맥 영역을 주석처리 및 분할 과정을 통해서 검출한 결과의 예를 나타낸다. 도 12 내지 14는 리전 그로잉 알고리즘으로 각각의 뇌종양, 뇌동맥 및 뇌정맥에 대한 관심 영역을 검출한 결과 를 3차원 오브젝트(3D Object)로 변환한 예를 나타낸다. 3D 오브젝트 파일들은 저장부에 저장될 수 있다. 2) 관심 영역의 주석 처리 후 분할 결과에 대한 레이블링 처리 과정은 다음과 같다. 학습부는 이전 단계에서 수집한 데이터에 대하여 데이터 레이블링 작업을 수행할 수 있으며, 레이블링은 이미지의 클래스를 나타내는 값을 부여하는 작업이다. 1)에서 처리된 분할 결과에 대한 레이블링 작업이 완료되 면, 저장부에 저장(제출)될 수 있다. 도 15 내지 17은 각각 뇌종양, 뇌동맥 및 뇌정맥 영역을 분할하여 레 이블링된 결과를 나타내는 예시 이미지들이다. 3) 레이블링된 관심 영역들(종양 및 종양 주변 조직들(혈관 및 신경))을 제 1 CNN 기반 알고리즘을 이용하여 학 습시키는 과정은 다음과 같다. 제 1 CNN 기반 알고리즘은 SegResNet 알고리즘을 포함할 수 있으며, 학습부는 SegResNet 알고리즘을 활용 하여 레이블링된 분할된 관심 영역들을 학습시킬 수 있다. SegResNet 알고리즘은 인코더-디코더 기반의 시멘틱 세그멘테이션 네트워크로, 딥 슈퍼비전(Deep Super Vision)을 사용하여 출력값의 정확도를 향상시킬 수 있다. SegResNet을 이용한 학습과정은 레이블링 처리된 데이터 입력, 특징 추출(Feature Extraction), 분류 (Classification), 학습 종료(Training End)로 구성될 수 있다. 특징 추출(Feature Etraction) 과정은 인코더 를 통해 이루어질 수 있다. 인코더는 의료 영상(예를 들어, MRI 이미지)에서 특징을 추출하는 역할을 하는 부분으로, ResNet 블록을 사용하 여 의료 영상을 처리할 수 있다. 각 ResNet 블록은 두 개의 컨볼루션(Convolution)과 정규화(Normalization) 및 ReLU로 구성될 수 있으며, 이후에 추가적인 아이덴티티 스킵(Identity Skip) 연결이 수행될 수 있다. ResNet은 레지듀얼 리프리젠테이션(Residual Representation) 함수를 학습함으로써 신경망이 152개의 레이어 (Layer)까지 만들어질 수 있다. ResNet은 이전 레이어의 입력을 다음 레이어로 전달하기 위해 스킵 커넥션(Skip Connection) 또는 쇼트 커넥션(Short Connection)을 사용할 수 있다. 레지듀얼 리프리젠테이션 함수(F)는 다음 과 같이 표현될 수 있다. 수학식 3"}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, x는 입력 데이터이고, W는 가중치(weight)이며, σ는 ReLu 함수를 의미한다. ResNet 수학식은 다음과 같다. 레지듀얼 블록(Residual Block)의 레이어가 2개이면, 레지듀얼 매핑(Residual Mapping)은 아래의 식과 같이 표현할 수 있다. 수학식 4 수학식 4에서, y=F(x,Wi)는 다중 합성곱층(Multiple Convolutional Layers)을 나타낸다. F식을 레이어의 개수에 무관하게 일반화하고, 아이덴티티 매핑(identity mapping)으로서 x를 더하는 것까지 포함하면 위의 식으로 일반 화하여 적을 수 있다. 다시 말하면, 입력값의 디멘션(Dimension)과 출력값의 디멘션이 동일하다고 하면 위의 식 과 같이 x를 그대로 더하여 아이덴티티 매핑을 수행할 수 있다. 하지만, 입력값과 출력값의 디멘션이 서로 다른 경우, 즉, x에 비해 출력 디멘션이 더 크면, x 디멘션에 있는 하나의 x를 출력 디멘션에 프로젝션(projection)시켜서 그 값을 더해주는 방법으로 아이덴티티 매핑이 가능하다. 즉, 위의 식에서 x에 Ws를 곱해줌으로써 디멘션 값을 매치시킬 수 있으며, 이러한 경우 ResNet 수학 식은 다음과 같이 표현될 수 있다. 수학식 5"}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 는 쇼트컷(shortcut)을 의미한다. 정규화(Normalization)를 위하여, 배치 사이즈(Batch Size)가 작을 때(예를 들어, 배치 사이즈 1), BatchNorm 보다 성능이 더 우수한 그룹 정규화(GN: Group Normalization)을 사용할 수 있다. 그룹 정규화(GN)는 하나의 샘플(Sample)을 갖고 있는 채널을 그룹 지어 평균과 표준편차를 계산한 후에 정규화 를 수행할 수 있으며, 학습이 가능한 파라미터 감마(γ)와 베타(β)도 존재할 수 있다. 정규화는 다음과 같이 수행될 수 있다. 수학식 6"}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "x는 레이어에 의해서 계산된 특징이고, i는 인덱스이다. 여기서, μ와 σ는 다음과 같이 계산된 평균과 표준편 차이다. 수학식 7"}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, ε는 작은 상수로 사용할 수 있다. Si는 평균과 표준편차가 계산된 픽셀의 집합이고, m은 픽셀의 집합 사이즈이다. 많은 유형의 특징 정규화(Feature Normalization) 방법은 Si 집합이 어떻게 정의되는지에 따라 차 이가 있다. Si는 다음과 같이 표현될 수 있다.수학식 8"}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "GN은 하나의 N에 대하여 채널의 그룹 단위로 정규화를 수행할 수 있다. G는 그룹의 개수이며, G는 사전 정의된 하이퍼파라미터(기본적으로 G=32)이다. C/G는 그룹 당 채널의 개수이다. 는 버림 연산(Floor Operation)이 고, 각 채널의 그룹이 C축을 따라 순차적으로 저장되었다고 가정하여, 는 인덱스 i와 k가 동 일한 채널 그룹에 있다는 것을 의미한다. 학습부는 이미지 크기를 2씩 점진적으로 줄이고 특징 크기를 2씩 늘리는 일반적인 CNN 접근방식을 따를 수 있다. 크기를 줄이기 위하여 스트라이드 컨볼루션(Strided Convolution)이 사용될 수 있으며, 모든 컨볼루션 (Convolution)은 초기의 필터 개수는 32개를 포함한 3×3×3이다. 인코더의 종단점은 256x20x24x16 사이즈를 가 지며, 입력 이미지보다 공간적으로 8배 더 작다. 분류(Classification) 과정은 디코더(Decoder) 처리, 손실함수(Loss) 및 최적화(Optimization), 레귤레이션 (Regulation)를 포함할 수 있다. 디코더는 인코더 구조와 비슷하지만, 각 공간 단계(Level)마다 단일 블록이 존재할 수 있다. 각 디코더는 업사 이징(Up-Sizing)으로 시작될 수 있다. 즉, 동등한 공간 차원의 인코더를 추가하여, (1×1×1 컨볼루션을 이용하 여) 특징(Feature)의 수를 2배 줄이고 (3D 이중선형 업샘플링을 이용하여) 공간 차원을 두배로 늘린다는 것을 의미한다. 디코더의 끝은 원래 이미지와 같은 크기의 특징(Feature)을 출력하며, 이를 1×1×1 컨볼루션을 통해 3개의 채널로 변환하고, 시그모이드(Sigmoid) 함수를 적용하여 출력값을 0과 1 사이의 값으로 정규화할 수 있다. 손실함수(Loss) 단계는 학습하는 동안 출력과 실제 값(정답) 사이의 오차를 계산할 수 있다. 이러한 단계는 결 합된 다이스(Dice) + 교차엔트로피(Cross Entropy Loss)를 사용할 수 있다. 모든 심층 지도 하위수준(deep- supervised sublevels)에 대해 동일한 손실이 합쳐질 수 있으며, 손실함수는 다음과 같이 표현될 수 있다. 수학식 9"}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서, 가중치 는 각 하위수준(더 작은 이미지 사이즈) i에 대하여 더 작다. 대상 레이블링(Target Labeling)은 가장 가까운 이웃 보간(Neighbor Interpolation)을 사용하여 해당 출력 크기와 일치하도록 축소될 수 있다. 최적화 단계는 의 초기 학습율(Initial Learning)을 이용하여 아담 옵티마이저(Adam Optimizer) 사용하여 수행될 수 있으며, 아래의 수학식에 따라 점진적으로 감소시킨다.수학식 10"}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서, e는 에포크(epoch) 카운터이고, Ne는 총 에포크의 수이다. 예를 들어, 본 개시 내용에 따른 학습부 는 분할된 뇌종양 및 뇌종양 주변 조직(혈관 및 신경) 영역들에 대하여 epoch=100으로 설정하여 학습을 진 행할 수 있다. 마지막으로, 레귤레이션 단계는 의 가중치 감소 정규화를 사용할 수 있다. 또한, 초기 인코더 컨볼루션 (Encoder Convolution) 이후에 0.2 비율의 공간 드롭아웃(Drop-Out)을 사용할 수 있다. 도 5 및 도 19를 참조하면, 추론부는 학습된 관심 영역들(종양 및 종양 주변 조직들(혈관 및 신경))에 대 한 자동 분할(Automated Segmentation)을 수행하여 추론된 관심 영역들을 검출할 수 있다. 추론부의 수행 과정은 제 2 CNN 기반 알고리즘을 이용한 관심 영역 예측 및 관심 영역 분할을 포함할 수 있다. 제 2 CNN 기반 알고리즘은 3D-UNet 모델을 포함할 수 있으며, 추론부는 3D-UNet 모델을 이용하여 자동 분할을 수행할 수 있다. 3D-UNet 모델은 엔드-투-엔드(End-to-End) 방식의 전-컨벌루션 네트워크 (Fully-Convolutional Network) 모델이며, 모델의 아키텍처가 U자로 구성되어 UNet이라고 표현될 수 있다. 3D- UNet의 구조는 데이터 차원을 축소했다가 다시 확장하는 방식으로 오토인코더(Autoencoder)와도 비슷하다. 3D-UNet은 인코더와 디코더로 구성될 수 있으며, 인코더 구조에서 신경망의 레이어는 두 개의 컨볼루션으로 구 성될 수 있다. 각 컨볼루션에는 BN(Batch Normalization)과 ReLU가 포함될 수 있다. 마지막으로 스트라이드가 2 인 2×2×2 최대 풀링이 구성될 수 있다. 디코더 구조에서 각 레이어는 스트라이드가 2인 2×2×2 업 컨볼루션 과 두 개의 3×3×3 컨볼루션, BN과 ReLU로 구성되어 관심 영역을 추론할 수 있다. 동시에, 인코더의 해당 네트 워크 계층의 결과는 디코더 입력의 일부로 사용되므로 특징 분석에 포함된 고화질의 특징 정보를 수집할 수 있 다. 도 6 및 도 19를 참조하면, 저장부는 학습부 및 추론부에서 3차원적으로 검출된 관심 영역들(종 양 및 종양 주변의 조직들)을 병합하여 하나의 오브젝트로 저장하도록 구성될 수 있다. 예를 들어, 저장부(24 0)는 학습부 및 추론부에서 검출되어 자동 분할된 객체들을 OBJ, FBX, glTF 등의 3D 오브젝트 표준 모델로 저장할 수 있다. 또한, 저장부는 학습부에서 레이블링한 데이터를 저장할 수 있다. 도 7 및 도 19를 참조하면, 출력부는 저장부에 저장된 3차원 종양 및 혈관 오브젝트를 이용하여 초다 시점 입체 디스플레이로 자동 변환하여 3차원 오브젝트의 입체적인 시각화를 제공하도록 구성될 수 있다. 예를 들어, 출력부는 도 18에 도시된 바와 같이 뇌종양, 뇌동맥 및 뇌정맥이 포함된 오브젝트를 초다시점 입체 (예를 들어, 홀로그램) 디스플레이로 자동 렌더링하여 변환된 결과를 출력할 수 있다. 이와 관련하여, 자동 분할된 관심 영역들(종양 및 종양 주변 조직)은 3D 오브젝트 표준 모델로 저장부에 저장되어 각각의 객체로 인식될 수 있다. 출력부는 저장된 오브젝트를 열고 사용자 입력에 의해 각각의 객 체를 제어하여 하나의 3D 씬(scene)으로 구성하고, 이를 초다시점 디스플레이 출력 영상으로 변환하는 자 동 렌더링을 수행하고, 렌더링된 결과 영상을 출력할 수 있다. 이때, 출력부는 시점 수, 시점 간격, 시청 거리 등 사용하는 초다시점 디스플레이의 설계 변수를 반영하여 재현되는 입체영상에서 입체감 왜곡 이 없도록 조정할 수 있으며, 필요에 따라서 키보드, 마우스, 사용자 제스쳐 인식 등을 통해서 입체 영상과 사 용자의 인터랙션이 가능하여 실시간 3D 의료 영상의 실시간 네비게이션이 가능하도록 초다시점 입체 디스플레이 영상을 제공할 수 있다. 도 19는 본 개시 내용의 일 실시예에 따른 인공지능 기반으로 의료 영상으로부터 관심 영역을 예측하여 초다시 점 디스플레이 영상으로 변환하기 위한 방법의 전체 과정들을 도식화한 예시적인 도면이다. 도 19에 도시된 바와 같이, 컴퓨팅 장치는 영상 촬영 장비로부터 입력되는 의료 영상을 획득할 수 있다 . 컴퓨팅 장치는 리전 그로잉 알고리즘 및 스레스홀드 알고리즘을 이용하여 종양 및 종양 주변 조직 에 대응하는 관심 영역들의 주석처리 및 분할을 수행하고, 주석처리 후 분할 결과를 레이블링하고, 레이블링된분할 결과를 제 1 CNN 기반 알고리즘(예를 들어, SegResNet 알고리즘)을 이용하여 학습시킬 수 있다. 컴 퓨팅 장치는 제 2 CNN 기반 알고리즘(예를 들어, 3D-Unet 모델)을 이용하여 자동 분할을 수행하여 3차원적 으로 추론된 관심 영역들을 검출할 수 있다. 컴퓨팅 장치는 단계 1920에서 학습된 레이블링된 관심 영역들뿐만 아니라 단계 1930에서 추론된 관심 영역들에 대한 3D 오브젝트 파일을 생성하여 저장할 수 있다 . 컴퓨팅 장치는 3D 오브젝트 파일의 영상을 초다시점 입체 디스플레이 영상으로 자동 변환하여 출 력시킬 수 있다. 임의의 제시된 프로세스들에 있는 단계들의 임의의 특정한 순서 또는 계층 구조는 예시적인 접근들의 일례임을 이해하도록 한다. 설계 우선순위들에 기반하여, 본 발명의 범위 내에서 프로세스들에 있는 단계들의 특정한 순 서 또는 계층 구조가 재배열될 수 있다는 것을 이해하도록 한다. 첨부된 방법 청구항들은 예시적인 순서로 다양 한 단계들의 엘리먼트들을 제공하지만 제시된 특정한 순서 또는 계층 구조에 한정되는 것을 의미하지는 않는다."}
{"patent_id": "10-2023-0167675", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "본 명세서 사용되는 용어 \"컴포넌트\", \"유닛(또는 부)\", \"모듈\", \"시스템\" 등은 컴퓨터-관련 엔티티, 하드웨어, 펌웨어, 소프트웨어, 소프트웨어 및 하드웨어의 조합, 또는 소프트웨어의 실행을 지칭할 수 있다. 예를 들어, 컴포넌트는 프로세서상에서 실행되는 처리과정, 프로세서, 객체, 실행 스레드, 프로그램, 및/또는 컴퓨터일 수 있지만, 이들로 제한되는 것은 아니다. 예를 들어, 컴퓨팅 장치에서 실행되는 애플리케이션 및 컴퓨팅 장치 모 두 컴포넌트일 수 있다. 하나 이상의 컴포넌트는 프로세서 및/또는 실행 스레드 내에 상주할 수 있고, 일 컴포 넌트는 하나의 컴퓨터 내에 로컬화될 수 있고, 또는 2개 이상의 컴퓨터들 사이에 분배될 수 있다. 또한, 이러한 컴포넌트들은 그 내부에 저장된 다양한 데이터 구조들을 갖는 다양한 컴퓨터 판독가능한 매체로부터 실행할 수 있다. 제시된 실시예들에 대한 설명은 임의의 본 발명의 기술 분야에서 통상의 지식을 가진 자가 본 발명을 이용하거 나 또는 실시할 수 있도록 제공된다. 이러한 실시예들에 대한 다양한 변형들은 본 발명의 기술 분야에서 통상의 지식을 가진 자에게 명백할 것이며, 여기에 정의된 일반적인 원리들은 본 발명의 범위를 벗어남이 없이 다른 실 시예들에 적용될 수 있다. 그리하여, 본 발명은 여기에 제시된 실시예들로 한정되는 것이 아니라, 여기에 제시 된 원리들 및 신규한 특징들과 일관되는 최광의의 범위에서 해석되어야 할 것이다."}
{"patent_id": "10-2023-0167675", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시 내용의 일 실시예에 따른 인공지능 기반으로 의료 영상으로부터 관심 영역을 예측하여 초다시점 디스플레이 영상으로 변환하기 위한 컴퓨팅 장치를 나타내는 예시적인 블록도이다.도 2는 본 개시 내용의 일 실시예에 따른 도 1의 컴퓨팅 장치의 기능 모듈들을 나타내는 예시적인 블록도이다. 도 3은 본 개시 내용의 일 실시예에 따른 입력부의 동작을 나타내는 예시적인 도면이다. 도 4는 본 개시 내용의 일 실시예에 따른 학습부의 동작을 나타내는 예시적인 도면이다. 도 5는 본 개시 내용의 일 실시예에 따른 추론부의 동작을 나타내는 예시적인 도면이다. 도 6은 본 개시 내용의 일 실시예에 따른 저장부의 동작을 나타내는 예시적인 도면이다. 도 7은 본 개시 내용의 일 실시예에 따른 출력부의 동작을 나타내는 예시적인 도면이다. 도 8은 리전 그로잉 방법으로 뇌종양의 위치를 지정하여 전경 및 배경 영역을 구분한 결과 예시를 캡처한 도면 이다. 도 9는 의료 영상 분할 방법 중 리전 그로잉(Region Growing) 방법으로 뇌종양의 검출 결과를 보여주는 예시를 캡처한 도면이다. 도 10은 의료 영상 분할 방법 중 스레스홀드(Threshold) 방법으로 뇌동맥 영역을 구분한 결과 예시를 캡처한 도 면이다. 도 11은 의료 영상 분할 방법 중 스레스홀드 방법으로 뇌정맥 영역을 구분한 결과 예시를 캡처한 도면이다. 도 12는 의료 영상 분할 방법으로 뇌종양을 검출한 결과에 대하여 3차원 오브젝트로 보여주는 예시를 캡처한 도 면이다. 도 13은 의료 영상 분할 방법으로 뇌동맥을 검출한 결과에 대하여 3차원 오브젝트로 보여주는 예시를 캡처한 도 면이다. 도 14는 의료 영상 분할 방법으로 뇌정맥을 검출한 결과에 대하여 3차원 오브젝트로 보여주는 예시를 캡처한 도 면이다. 도 15는 주석 처리된 뇌종양 영역에 대하여 레이블링(Labeling)된 결과를 보여주는 예시를 캡처한 도면이다. 도 16은 주석 처리된 뇌동맥 영역에 대하여 레이블링된 결과를 보여주는 예시를 캡처한 도면이다. 도 17은 주석 처리된 뇌정맥 영역에 대하여 레이블링된 결과를 보여주는 예시를 캡처한 도면이다. 도 18은 뇌종양 및 뇌종양 주변 조직들의 검출 결과를 초다시점 입체 디스플레이 영상으로 출력한 예시를 캡처 한 도면이다. 도 19는 본 개시 내용의 일 실시예에 따른 인공지능 기반으로 의료 영상으로부터 관심 영역을 예측하여 초다시 점 디스플레이 영상으로 변환하기 위한 방법의 전체 과정들을 도식화한 예시적인 도면이다."}
