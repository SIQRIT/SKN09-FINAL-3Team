{"patent_id": "10-2022-0032061", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0110138", "출원번호": "10-2022-0032061", "발명의 명칭": "과소 표현된 데이터를 스스로 진단하고 강조하는 생성적 적대 신경망 설계", "출원인": "한국과학기술원", "발명자": "정혜원"}}
{"patent_id": "10-2022-0032061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 시스템에서 수행되는 데이터 생성 방법에 있어서,상기 컴퓨터 시스템은 메모리에 포함된 컴퓨터 판독가능한 명령들을 실행하도록 구성된 적어도 하나의 프로세서를 포함하고,상기 데이터 생성 방법은,상기 적어도 하나의 프로세서에 의해, 생성적 적대 신경망(GAN, Generative Adversarial Network)의 학습 과정에서 각 학습 데이터의 과소 표현된 정도를 나타내는 과소표현 점수를 측정하는 단계; 및상기 적어도 하나의 프로세서에 의해, 상기 과소표현 점수에 기반한 가중 샘플링(weighted sampling)을 통해 상기 생성적 적대 신경망을 추가 학습하는 단계를 포함하는 데이터 생성 방법."}
{"patent_id": "10-2022-0032061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 측정하는 단계는,상기 학습 데이터에서 데이터 분포와 모델 분포 간의 불일치 점수를 계산함으로써 상기 과소표현 점수를 측정하는 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2022-0032061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 생성적 적대 신경망은 생성기 신경망과 판별기 신경망을 포함하고,상기 측정하는 단계는,상기 판별기 신경망의 출력 값에 기반한 LDR(log density ratio)을 기초로 상기 과소표현 점수를 측정하는 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2022-0032061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 측정하는 단계는,상기 생성적 적대 신경망의 학습 과정에서 계산된 상기 LDR의 평균(mean)과 분산(variance)을 이용하여 상기 과소표현 점수를 측정하는 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2022-0032061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 생성적 적대 신경망은 생성기 신경망과 판별기 신경망을 포함하고,상기 측정하는 단계는,상기 생성적 적대 신경망의 학습 과정에서 계산된 상기 판별기 신경망의 출력 값의 평균과 분산을 이용하여 상공개특허 10-2023-0110138-3-기 과소표현 점수를 측정하는 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2022-0032061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 생성적 적대 신경망의 학습 시 비포화 손실(non-saturating loss) 함수 또는 힌지 손실(hinge loss) 함수가 사용되는 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2022-0032061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 추가 학습하는 단계는,상기 과소표현 점수에 비례하여 상기 학습 데이터의 샘플링 확률을 조정하는 단계를 포함하는 데이터 생성 방법."}
{"patent_id": "10-2022-0032061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 조정하는 단계는,최대 샘플링 확률과 최소 샘플링 확률 사이의 비율이 일정 값을 넘지 않는 범위에서 상기 학습 데이터의 샘플링확률을 조정하는 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2022-0032061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 생성적 적대 신경망은 생성기 신경망과 판별기 신경망을 포함하고,상기 데이터 생성 방법은,상기 적어도 하나의 프로세서에 의해, 상기 판별기 신경망의 출력 값을 이용한 기각 샘플링(rejectionsampling)을 통해 상기 생성적 적대 신경망의 모델 분포를 수정하는 단계를 더 포함하는 데이터 생성 방법."}
{"patent_id": "10-2022-0032061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "데이터 생성 방법을 컴퓨터에 실행시키기 위해 컴퓨터 판독가능한 기록 매체에 저장되는 컴퓨터 프로그램에 있어서,상기 데이터 생성 방법은,생성적 적대 신경망의 학습 과정에서 각 학습 데이터의 과소 표현된 정도를 나타내는 과소표현 점수를 측정하는단계;상기 과소표현 점수에 기반한 가중 샘플링을 통해 상기 생성적 적대 신경망을 추가 학습하는 단계; 및판별기 신경망의 출력 값을 이용한 기각 샘플링을 통해 상기 생성적 적대 신경망의 모델 분포를 수정하는 단계를 포함하는, 컴퓨터 프로그램."}
{"patent_id": "10-2022-0032061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "컴퓨터 시스템에 있어서,공개특허 10-2023-0110138-4-메모리에 포함된 컴퓨터 판독가능한 명령들을 실행하도록 구성된 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는,생성적 적대 신경망의 학습 과정에서 각 학습 데이터의 과소 표현된 정도를 나타내는 과소표현 점수를 측정하는과정; 및상기 과소표현 점수에 기반한 가중 샘플링을 통해 상기 생성적 적대 신경망을 추가 학습하는 과정을 처리하는 컴퓨터 시스템."}
{"patent_id": "10-2022-0032061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는,상기 학습 데이터에서 데이터 분포와 모델 분포 간의 불일치 점수를 계산함으로써 상기 과소표현 점수를 측정하는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2022-0032061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 생성적 적대 신경망은 생성기 신경망과 판별기 신경망을 포함하고,상기 적어도 하나의 프로세서는,상기 판별기 신경망의 출력 값에 기반한 LDR을 기초로 상기 과소표현 점수를 측정하는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2022-0032061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는,최대 샘플링 확률과 최소 샘플링 확률 사이의 비율이 일정 값을 넘지 않는 범위에서 상기 과소표현 점수에 비례하여 상기 학습 데이터의 샘플링 확률을 조정하는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2022-0032061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 적어도 하나의 프로세서는,상기 판별기 신경망의 출력 값을 이용한 기각 샘플링을 통해 상기 생성적 적대 신경망의 모델 분포를 수정하는것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "생성적 적대 신경망(GAN, Generative Adversarial Network)을 기반으로 데이터를 생성하는 기술이 개시된다. 데 이터 생성 방법은, 생성적 적대 신경망의 학습 과정에서 각 학습 데이터의 과소 표현된 정도를 나타내는 과소표 현 점수를 측정하는 단계; 및 상기 과소표현 점수에 기반한 가중 샘플링(weighted sampling)을 통해 상기 생성적 적대 신경망을 추가 학습하는 단계를 포함한다."}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 인공 신경망 모델을 이용하여 다양한 데이터를 생성하는 기술에 관한 것이다."}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술은 다방면의 산업 분야에 활용되고 있으며, 이미지 분류, 이미지 생성, 언어 생성 등 다양한 일을 수행한다. 인공지능 기술 중 생성 모델은 이미지, 언어 등의 학습 데이터가 주어졌을 때 해당 데이터의 분포를 학습하여 학습 데이터와 유사한 가상의 생성 데이터를 만들어내는 것을 목표로 한다. 이러한 생성 모델은 다양한 산업 분야에 활용될 수 있다. 인공지능 모델 학습을 위하여 다량의 데이터가 필요한 실정이고, 데이터의 부족 문제에 대응하기 위하여 생성 모델을 통해 가상 데이터를 생성하는 방안이 효과적으로 활용될 수 있다. 또, 생성 모델을 가상 현실이 대두되는 산업 상황에서 가상 현실 내에 활용할 가상 인물 사진이나 음성 등을 만 드는 데에 활용할 수 있다. 생성 모델 중 생성적 적대 신경망(GAN: Generative Adversarial Networks)은 실제와 같은 품질의 가상 데이터 를 생성할 수 있는 효과적인 성능으로 다양한 산업 분야에서 활용되고 있다. 그러나, 생성적 적대 신경망의 문제점은 생성 데이터의 질이 높음에도 불구하고 학습 데이터의 전체가 아닌 일 부만을 표현하여 생성된 가상 데이터의 다양성이 제한된다는 점에 있다. 특히, 특정 학습 데이터 샘플이 전체 데이터 내에 상대적으로 적게 분포하는 소수 특징을 가지고 있을 경우 해 당 데이터의 생성 성능이 다른 데이터 대비 현저히 낮다는 것이 알려져 있다. 선행기술문헌 1. Goodfellow et al., Generative Adversarial Networks, 2014 2. 한국공개특허 제10-2021-0048100호 (생성적 적대 신경망을 이용한 상태 감시 데이터 생성 방법 및 장치, 공 개일: 2021년 05월 03일)"}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 종래의 생성적 적대 신경망 학습에서 각 학습 데이터 샘플의 과소 표현된 정도를 측정하고 측정으로 얻은 점수를 토대로 과소 표현된 데이터를 감지 및 강조하는 기법을 통해 데이터 표현 능력 및 다양성이 증대된 개선된 생성적 적대 신경망을 제안한다."}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "컴퓨터 시스템에서 수행되는 데이터 생성 방법에 있어서, 상기 컴퓨터 시스템은 메모리에 포함된 컴퓨터 판독가 능한 명령들을 실행하도록 구성된 적어도 하나의 프로세서를 포함하고, 상기 데이터 생성 방법은, 상기 적어도 하나의 프로세서에 의해, 생성적 적대 신경망(GAN, Generative Adversarial Network)의 학습 과정에서 각 학습 데이터의 과소 표현된 정도를 나타내는 과소표현 점수를 측정하는 단계; 및 상기 적어도 하나의 프로세서에 의 해, 상기 과소표현 점수에 기반한 가중 샘플링(weighted sampling)을 통해 상기 생성적 적대 신경망을 추가 학 습하는 단계를 포함하는 데이터 생성 방법을 제공한다. 일 측면에 따르면, 상기 측정하는 단계는, 상기 학습 데이터에서 데이터 분포와 모델 분포 간의 불일치 점수를 계산함으로써 상기 과소표현 점수를 측정할 수 있다. 다른 측면에 따르면, 상기 생성적 적대 신경망은 생성기 신경망과 판별기 신경망을 포함하고, 상기 측정하는 단 계는, 상기 판별기 신경망의 출력 값에 기반한 LDR(log density ratio)을 기초로 상기 과소표현 점수를 측정할 수 있다. 또 다른 측면에 따르면, 상기 측정하는 단계는, 상기 생성적 적대 신경망의 학습 과정에서 계산된 상기 LDR의 평균(mean)과 분산(variance)을 이용하여 상기 과소표현 점수를 측정할 수 있다. 또 다른 측면에 따르면, 상기 생성적 적대 신경망은 생성기 신경망과 판별기 신경망을 포함하고, 상기 측정하는 단계는, 상기 생성적 적대 신경망의 학습 과정에서 계산된 상기 판별기 신경망의 출력 값의 평균과 분산을 이용 하여 상기 과소표현 점수를 측정할 수 있다.또 다른 측면에 따르면, 상기 생성적 적대 신경망의 학습 시 비포화 손실(non-saturating loss) 함수 또는 힌지 손실(hinge loss) 함수가 사용될 수 있다. 또 다른 측면에 따르면, 상기 추가 학습하는 단계는, 상기 과소표현 점수에 비례하여 상기 학습 데이터의 샘플 링 확률을 조정하는 단계를 포함할 수 있다. 또 다른 측면에 따르면, 상기 조정하는 단계는, 최대 샘플링 확률과 최소 샘플링 확률 사이의 비율이 일정 값을 넘지 않는 범위에서 상기 학습 데이터의 샘플링 확률을 조정할 수 있다. 또 다른 측면에 따르면, 상기 생성적 적대 신경망은 생성기 신경망과 판별기 신경망을 포함하고, 상기 데이터 생성 방법은, 상기 적어도 하나의 프로세서에 의해, 상기 판별기 신경망의 출력 값을 이용한 기각 샘플링 (rejection sampling)을 통해 상기 생성적 적대 신경망의 모델 분포를 수정하는 단계를 더 포함할 수 있다. 데이터 생성 방법을 컴퓨터에 실행시키기 위해 컴퓨터 판독가능한 기록 매체에 저장되는 컴퓨터 프로그램에 있 어서, 상기 데이터 생성 방법은, 생성적 적대 신경망의 학습 과정에서 각 학습 데이터의 과소 표현된 정도를 나 타내는 과소표현 점수를 측정하는 단계; 상기 과소표현 점수에 기반한 가중 샘플링을 통해 상기 생성적 적대 신 경망을 추가 학습하는 단계; 및 판별기 신경망의 출력 값을 이용한 기각 샘플링을 통해 상기 생성적 적대 신경 망의 모델 분포를 수정하는 단계를 포함하는, 컴퓨터 프로그램을 제공한다. 컴퓨터 시스템에 있어서, 메모리에 포함된 컴퓨터 판독가능한 명령들을 실행하도록 구성된 적어도 하나의 프로 세서를 포함하고, 상기 적어도 하나의 프로세서는, 생성적 적대 신경망의 학습 과정에서 각 학습 데이터의 과소 표현된 정도를 나타내는 과소표현 점수를 측정하는 과정; 및 상기 과소표현 점수에 기반한 가중 샘플링을 통해 상기 생성적 적대 신경망을 추가 학습하는 과정을 처리하는 컴퓨터 시스템을 제공한다."}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들에 따르면, 생성적 적대 신경망의 학습 과정에서 모델이 잘 표현하지 못한 데이터를 식별하 여 해당 데이터를 강조함으로써 모델이 보다 고르게 각 학습 데이터를 잘 표현할 수 있고 이를 통해 생성 데이 터의 다양성과 데이터 생성 성능을 개선할 수 있다."}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 본 발명의 실시예들은 생성적 적대 신경망을 이용하여 데이터를 생성하는 기술에 관한 것이다. 본 명세서에서 구체적으로 개시되는 것들을 포함하는 실시예들은 생성적 적대 신경망의 학습 과정에서 모델이 잘 표현하지 못한 데이터를 식별하여 해당 데이터를 강조함으로써 생성적 적대 신경망의 생성 데이터 다양성과 데이터 생성 성능을 개선할 수 있다. 도 1은 본 발명의 일실시예에 따른 컴퓨터 시스템의 예를 도시한 블록도이다. 예를 들어, 본 발명의 실시예들에 따른 데이터 생성 시스템은 도 1을 통해 도시된 컴퓨터 시스템에 의해 구현될 수 있다. 도 1에 도시된 바와 같이 컴퓨터 시스템은 본 발명의 실시예들에 따른 데이터 생성 방법을 실행하기 위한 구성요소로서, 메모리, 프로세서, 통신 인터페이스 그리고 입출력 인터페이스를 포함할 수 있다. 메모리는 컴퓨터에서 판독 가능한 기록매체로서, RAM(random access memory), ROM(read only memory) 및 디스크 드라이브와 같은 비소멸성 대용량 기록장치(permanent mass storage device)를 포함할 수 있다. 여기서 ROM과 디스크 드라이브와 같은 비소멸성 대용량 기록장치는 메모리와는 구분되는 별도의 영구 저장 장치로 서 컴퓨터 시스템에 포함될 수도 있다. 또한, 메모리에는 운영체제와 적어도 하나의 프로그램 코드가 저장될 수 있다. 이러한 소프트웨어 구성요소들은 메모리와는 별도의 컴퓨터에서 판독 가능한 기록매체로 부터 메모리로 로딩될 수 있다. 이러한 별도의 컴퓨터에서 판독 가능한 기록매체는 플로피 드라이브, 디스 크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있다. 다른 실시예에서 소프트웨어 구성요소들은 컴퓨터에서 판독 가능한 기록매체가 아닌 통신 인터페이스를 통해 메 모리에 로딩될 수도 있다. 예를 들어, 소프트웨어 구성요소들은 네트워크를 통해 수신되는 파일들에 의해 설치되는 컴퓨터 프로그램에 기반하여 컴퓨터 시스템의 메모리에 로딩될 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리 또는 통신 인터페이스에 의해 프로세서로 제공될 수 있다. 예를 들어 프로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 수신되는 명령을 실행하도 록 구성될 수 있다. 통신 인터페이스은 네트워크를 통해 컴퓨터 시스템이 다른 장치와 서로 통신하기 위한 기능을 제공할 수 있다. 일례로, 컴퓨터 시스템의 프로세서가 메모리와 같은 기록 장치에 저장된 프로 그램 코드에 따라 생성한 요청이나 명령, 데이터, 파일 등이 통신 인터페이스의 제어에 따라 네트워크 를 통해 다른 장치들로 전달될 수 있다. 역으로, 다른 장치로부터의 신호나 명령, 데이터, 파일 등이 네트 워크를 거쳐 컴퓨터 시스템의 통신 인터페이스를 통해 컴퓨터 시스템으로 수신될 수 있다. 통신 인터페이스를 통해 수신된 신호나 명령, 데이터 등은 프로세서나 메모리로 전달될 수 있고, 파일 등은 컴퓨터 시스템이 더 포함할 수 있는 저장 매체(상술한 영구 저장 장치)로 저장될 수 있다. 통신 방식은 제한되지 않으며, 네트워크가 포함할 수 있는 통신망(일례로, 이동통신망, 유선 인터넷, 무선 인터넷, 방송망)을 활용하는 통신 방식뿐만 아니라 기기들간의 근거리 유선/무선 통신 역시 포함될 수 있다. 예 를 들어, 네트워크는, PAN(personal area network), LAN(local area network), CAN(campus area network), MAN(metropolitan area network), WAN(wide area network), BBN(broadband network), 인터넷 등의 네트워크 중 하나 이상의 임의의 네트워크를 포함할 수 있다. 또한, 네트워크는 버스 네트워크, 스타 네트 워크, 링 네트워크, 메쉬 네트워크, 스타-버스 네트워크, 트리 또는 계층적(hierarchical) 네트워크 등을 포함 하는 네트워크 토폴로지 중 임의의 하나 이상을 포함할 수 있으나, 이에 제한되지 않는다. 입출력 인터페이스는 입출력 장치와의 인터페이스를 위한 수단일 수 있다. 예를 들어, 입력 장치는 마이크, 키보드, 카메라 또는 마우스 등의 장치를, 그리고 출력 장치는 디스플레이, 스피커와 같은 장치를 포함 할 수 있다. 다른 예로 입출력 인터페이스는 터치스크린과 같이 입력과 출력을 위한 기능이 하나로 통합된 장치와의 인터페이스를 위한 수단일 수도 있다. 입출력 장치는 컴퓨터 시스템과 하나의 장치로 구성 될 수도 있다. 또한, 다른 실시예들에서 컴퓨터 시스템은 도 1의 구성요소들보다 더 적은 혹은 더 많은 구성요소들을 포 함할 수도 있다. 그러나, 대부분의 종래기술적 구성요소들을 명확하게 도시할 필요성은 없다. 예를 들어, 컴퓨 터 시스템은 상술한 입출력 장치 중 적어도 일부를 포함하도록 구현되거나 또는 트랜시버 (transceiver), 카메라, 각종 센서, 데이터베이스 등과 같은 다른 구성요소들을 더 포함할 수도 있다. 이하에서는 과소 표현된 데이터를 스스로 진단하고 강조하는 생성적 적대 신경망을 기반으로 데이터를 생성하는 기술의 구체적인 실시예를 설명하기로 한다.도 2는 본 발명의 일실시예에 따른 컴퓨터 시스템의 프로세서가 포함할 수 있는 구성요소의 예를 도시한 도면이 고, 도 3은 본 발명의 일실시예에 따른 컴퓨터 시스템이 수행할 수 있는 데이터 생성 방법의 예를 도시한 순서 도이다. 도 2에 도시된 바와 같이, 프로세서는 학습부, 점수 측정부, 추가 학습부, 및 모델 수정부 를 포함할 수 있다. 이러한 프로세서의 구성요소들은 적어도 하나의 프로그램 코드에 의해 제공되는 제어 명령에 따라 프로세서에 의해 수행되는 서로 다른 기능들(different functions)의 표현들일 수 있다. 예를 들어, 프로세서가 생성적 적대 신경망(GAN)을 학습하도록 컴퓨터 시스템을 제어하기 위해 동작 하는 기능적 표현으로서 학습부가 사용될 수 있다. 프로세서 및 프로세서의 구성요소들은 도 3의 데이터 생성 방법이 포함하는 단계들(S310 내지 S340) 을 수행할 수 있다. 예를 들어, 프로세서 및 프로세서의 구성요소들은 메모리가 포함하는 운영 체제의 코드와 상술한 적어도 하나의 프로그램 코드에 따른 명령(instruction)을 실행하도록 구현될 수 있다. 여기서, 적어도 하나의 프로그램 코드는 데이터 생성 방법을 처리하기 위해 구현된 프로그램의 코드에 대응될 수 있다. 데이터 생성 방법은 도시된 순서대로 발생하지 않을 수 있으며, 단계들 중 일부가 생략되거나 추가의 과정이 더 포함될 수 있다. 프로세서는 데이터 생성 방법을 위한 프로그램 파일에 저장된 프로그램 코드를 메모리에 로딩할 수 있다. 예를 들어, 데이터 생성 방법을 위한 프로그램 파일은 메모리와는 구분되는 영구 저장 장치에 저장 되어 있을 수 있고, 프로세서는 버스를 통해 영구 저장 장치에 저장된 프로그램 파일로부터 프로그램 코드 가 메모리에 로딩되도록 컴퓨터 시스템을 제어할 수 있다. 이때, 프로세서 및 프로세서가 포함하는 학습부, 및 미세조정부 각각은 메모리에 로딩된 프로그램 코드 중 대응하는 부분의 명 령을 실행하여 이후 단계들(S310 내지 S340)을 실행하기 위한 프로세서의 서로 다른 기능적 표현들일 수 있다. 단계들(S310 내지 S340)의 실행을 위해, 프로세서 및 프로세서의 구성요소들은 직접 제어 명령 에 따른 연산을 처리하거나 또는 컴퓨터 시스템을 제어할 수 있다. 도 3을 참조하면, 단계(S310)에서 학습부는 인공 신경망의 일종인 생성적 적대 신경망을 학습할 수 있다. 생성적 적대 신경망을 학습하는 방법은 이미 공지된 기술을 적용할 수 있다. 생성적 적대 신경망은 생성기 신경 망(G)과 판별기 신경망(D)을 포함하며, 두 신경망을 아울러 학습 시 사용되는 손실 함수는 수학식 1과 같다. [수학식 1]"}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "단계(S320)에서 점수 측정부는 학습 데이터의 과소표현 정도를 측정할 수 있다. 점수 측정부는 학습 부에서 학습된 생성적 적대 신경망의 판별기 신경망(D)을 이용해 각 학습 데이터 샘플 x의 과소 표현된 정 도를 나타내는 점수(이하, '과소표현 점수'라 칭함)를 측정할 수 있다. 과소표현 점수는 학습 데이터가 과소 표 현될수록 높고, 과대 표현될수록 낮다. 과소표현 점수를 측정할 때에 기준이 되는 LDR(log density ratio) 점수 는 수학식 2와 같다. [수학식 2]"}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "점수 측정부는 임의의 데이터 x에 대해 수학식 2을 통해 LDR 점수를 계산할 수 있다. 이때, D(x)는 x를 판 별기가 받았을 때 내놓는 출력값이다. LDR 점수는 log(pdata(x)/pg(x)) 즉, 실제 데이터 분포 pdata와 생성기 분포 pg의 차이를 각 데이터 값 x에서 비교하는 값을 추정하기 위해 정의된 점수로 판별기의 출력값을 사용하여 계산 된다. LDR 점수를 매 학습 과정에서 측정한 후 여러 스텝을 거치며, LDR 점수의 평균(mean)과 분산(variance)을 계산 함으로써 LDRM 점수와 LDRV 점수를 얻는다. 본 실시예에서 과소표현 점수는 수학식 3과 같이 정의될 수 있다. [수학식 3] 이때, k는 상수를 나타내는 것으로, 이는 학습 데이터의 종류에 따라 조절될 수 있다. 생성적 적대 신경망의 학습 시 손실 함수로 비포화 손실(non-saturating loss) 또는 힌지 손실(hinge loss)을 사용할 수 있다. 생성적 적대 신경망의 학습 시 사용되는 손실 함수가 비포화 손실이 아닌 힌지 손실인 경우, LDR 점수의 평균과 분산을 계산하는 대신 판별기의 결과값인 Dh(x)의 평균과 분산을 계산하여 과소표현 점수를 얻을 수 있다. 단계(S330)에서 추가 학습부는 과소표현 점수를 토대로 과소 표현된 데이터의 생성을 촉진하는 방향으로 생성적 적대 신경망을 추가 학습할 수 있다. 추가 학습부는 모든 학습 데이터에 대해 점수 측정부에 서 측정된 과소표현 점수를 기준으로 데이터를 강조하여 생성적 적대 신경망을 추가 학습할 수 있다. 추가 학습 부는 생성적 적대 신경망의 학습 과정에서 데이터 x가 뽑힐 확률(즉, 샘플링 확률)을 해당 데이터 x의 과 소표현 점수에 비례하도록 조정할 수 있다. 이때, 추가 학습부는 최대 샘플링 확률과 최소 샘플링 확률 사 이의 비율이 일정 값을 넘지 않는 범위로 점수의 격차를 제한하여 안정적으로 데이터를 샘플링할 수 있다. 추가 학습부는 학습 데이터 샘플링 확률을 과소표현 점수에 비례하도록 계산한 후 계산된 학습 데이터 샘 플링 확률을 토대로 생성적 적대 신경망의 학습을 추가로 진행할 수 있다. 실시예에 따라서는 학습 데이터 샘플 링 확률을 LDRM 점수 또는 LDRV 점수에 비례하도록 계산할 수 있다. 단계(S340)에서 모델 수정부는 생성적 적대 신경망의 최종적인 모델 분포를 수정할 수 있다. 모델 수정부 는 추가 학습부를 거쳐 다양성이 보다 강조된 모델 분포가 만들어진 후 판별기 값을 이용한 기각 샘 플링을 통하여 생성적 적대 신경망의 모델 분포를 최종적으로 수정할 수 있다. 따라서, 본 실시예에서는 생성적 적대 신경망의 학습 과정에서 모델이 잘 표현하지 못한 데이터를 식별하여 해 당 데이터를 강조함으로써 보다 고르게 학습 데이터를 잘 표현하는 모델을 구현할 수 있다. 생성적 적대 신경망의 학습 중 과소표현 샘플을 진단하고 강조하는 방법을 구체적으로 설명하기로 한다. 일반적인 생성적 적대 신경망은 학습 데이터의 분포를 모방하여 가짜 데이터를 효과적으로 생성할 수 있다. 그 러나, 도 4에 도시한 바와 같이 생성적 적대 신경망은 학습 데이터의 분포를 온전히 모방하지 못하고 일부 데이 터를 모방함에 따라 소수 특징을 가진 일부 데이터를 표현되지 못하는 경우가 많다. 이에, 본 발명은 학습 데이터를 고르게 잘 표현하기 위한 방안으로, 학습 데이터가 잘 표현되지 못한 정도를 점 수화한 후(과소표현 점수), 도 5에 도시한 바와 같이 과소표현 점수를 토대로 학습 데이터를 강조 학습함을 통 해 덜 표현된 데이터의 표현성을 증대시킬 수 있다. 특히, 프로세서는 가짜 샘플이 아닌, 과소 표현된 실제 샘플을 감지하고 강조할 수 있다. 프로세서는 각 데이터 인스턴스에서 데이터 분포와 모델 분포 간의 불일치 통계를 사용하는 것으로, 과소 표현된 샘플이 평균 불일치 또는 불일치 변동성이 높다는 관찰을 바탕으로 생성적 적대 신경망의 학습 중에 해 당 샘플을 강조할 수 있다. 프로세서는 생성적 적대 신경망의 학습을 진단하여 과소 표현된 샘플을 탐지하기 위해 판별기에서 간단하 게 계산할 수 있고, 생성적 적대 신경망의 학습 중 점수 기반 가중 샘플링을 통해 과소 표현된 데이터를 효과적 으로 강조할 수 있다. 프로세서는 여러 에포크(epoch)에 걸친 경험적 평균과 분산을 사용하여 적게 표현된 마이너 그룹 샘플을 탐지할 수 있고, 평균뿐만 아니라 불일치 추정치의 분산을 과소 표현된 샘플을 탐지하는 데에 이용할 수 있다. 생성적 적대 신경망의 학습 중 과소 표현된 샘플을 검출하기 위한 측정 기준은 다음과 같다. 생성적 적대 신경망 학습은 데이터 분포 pdata(x)와 밀접하게 일치하는 암시적 모델 분포 pg(x)를 가진 생성기를 학습시키는 것을 목표로 한다. pdata(x)와 pg(x) 사이의 불일치는 log(pdata(x)/pg(x))로 측정할 수 있지만 pg(x) 는 알 수 없고 pg(x)는 암시적이기 때문에 생성적 적대 신경망에서 직접 계산할 수 없다. 대신, 본 실시예에서는 판별기 출력을 사용하여 LDR에 대한 추정치를 정의할 수 있다. 생성적 적대 신경망은 손 실 함수(수학식 1)에 대한 최소-최대 최적화 minGmaxDV(D,G)를 해결한다. 생성기 G에 대해서 최적의 판별기 D는와 같이 산출되며, 이것은 수학식 2를 통해 LDR를 정의할 수 있다. D(x) = D*(x)일 때, LDR(x)은 log(pdata(x)= pg(x))와 같다. LDR(x)>0일 때, 데이터 포인트 x는 모델에서 과소 표현된다. 즉, pdata(x)>pg(x)에 해당된다. LDR(x)<0일 때, 데이터는 과대 표현된 것이며, pdata(x)<pg(x)에 해당 된다. 따라서, 각 인스턴스 x의 LDR(x) 값을 활용하여 추정치가 유효한 경우 생성기를 개선하기 위한 피드백을 제공할 수 있다. 본 발명은 학습 중에 과소 표현된 데이터 영역을 탐지하기 위해 훨씬 안정적이고 유익한 지표인 LDR(x)의 통계 를 사용할 수 있다. 각 샘플의 학습 행동을 진단하기 위해 학습 역학(학습 진행에 따른 모델의 동작)을 사용하 는 것이다. 생성 모델을 학습할 때 모델의 정확도를 측정하기 위한 명시적인 참조가 없기 때문에 학습 역학을 진단하기 위한 지표는 명확하지 않다. 본 실시예에서는 학습 단계 T={ts, ,te}에 걸쳐 각 샘플 x에서 생성적 적 대 신경망, LDRM(LDR 평균), LDRV(LDR 분산) 불일치의 평균과 분산을 추정하는 측정 기준을 정의한다. [수학식 4]"}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "[수학식 5]"}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, LDR(x)k는 k번째 학습 단계에서 기록된 LDR 추정치(수학식 2)이다. LDRM(x)는 샘플 포인트 x에서 학습 에 대해 pg(x)에 얼마나 가까운지를 측정하는 반면, LDRV(x)는 그러한 불일치가 학습에 걸쳐 어떻게 변동하는지 측정한다. 직관적으로 잘 학습되고 일반화된 샘플은 이후 지속적으로 작은 LDR(x) 를 가지므로 LDRM과 LDRV가 낮게 나타나는 반면, 학습하기 어려운 샘플은 높은 LDRM 또는 LDRV 값을 나타낸다. LDRV(LDR 분산)는 마이너 그룹으로부터 감지하는데 효과적이다. 생성적 적대 신경망은 마이너 샘플을 모델링하는 데 어려움을 겪는 것으로 알려져 있다. 도 6은 단일 모드 가우시안, MNIST(메이저)와 FMNIST(마이너)의 혼합, 빨간색(메이저)과 녹색(마이 너)의 컬러 MNIST 샘플로 학습된 생성적 적대 신경망에 분석 결과를 도시한 것이다. (a) 내지 (d)는 메이저/마 이너 특징으로 생성된 샘플 예시를 나타낸 것이고, (e)는 각 데이터 세트의 메이저 샘플(점선)과 마이너 샘플 (실선)의 부분 재현율을 나타낸 것이다. 도 6의 (e)를 참조하면, 샘플 품질과 부분 재현율 모두 메이저 그룹에서 더 높다는 것을 알 수 있으며, 메이저 그룹과 마이너 그룹은 리콜 격차가 크고 소수 레벨(minority levels)이 심해질수록 격차가 심해진다. 마이너 그 룹이 불량 품질 문제뿐만 아니라 낮은 커버리지 문제를 겪고 있다는 점에서 마이너 샘플을 감지하여 강조하는 기술의 필요성을 통감할 수 있다. LDRV를 사용하여 마이너 특징, 즉 마이너 그룹의 특징을 가진 샘플을 감지할 수 있는 휴리스틱 인수를 적용할 수 있다. 특히, 마이너 샘플이 더 높은 LDRV 값을 갖는 경향이 있다. 첫째, 판별기를 로지스틱 회귀 모델로 볼 수 있고, 각 입력 xi에 대해 판별기는 특징 벡터 와 마지막 계층의 가중치 벡터 사이의 내적을 사 용하여 실제 점수(샘플 xi가 실제(yi=1)일 확률)를 산출한다(수학식 6). [수학식 6] 베이지안 관점에서, θ의 사전 분포가 이라고 가정하면, θ에 대한 사후 분포는 로 주어진다. 사후 분포에 대한 가우스 근사치를 얻으려면 먼저 가우스 평 균을 정의하는 를 최대화하는 최대 사후 추정 θMAP을 찾는다. 공분산은 수학식 7과 같은 형태를 취하는 음의 로그 우도(negative log likelihood)의 이차 미분 역행렬에 의해 주어진다. [수학식 7]"}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "마지막으로, θ=θMAP에서의 테일러 확장에 의해 수학식 6에서 D(xi;θ))의 근사치, LDRV는 수학식 8과 같이 표 현될 수 있다. [수학식 8]"}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "이는 LDRV와 마이너 특징에 관한 중요한 측면을 보여준다. 수학식 8은 특징 벡터 Φi가 Sn의 주성분(고유값이 가 장 큰 고유 벡터)과 더 많이 상관될수록 LDRV가 더 커진다는 것을 보여준다. Sn의 각 고유값은 의 고유값과 역수이기 때문에 수학식 9의 최소 고유값인 의 고유벡터 v의 특성을 고려한다. [수학식 9]"}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "수학식 9는 y가 D(1-D)>0인 대부분의 특징 벡터 {Φi}들과 정렬하지 않으면(또는 직교) 더 작은 고유값을 갖는 경향이 있음을 보여준다. 마이너 특징 벡터 Φj는 D(1-D)>0을 가지는 대다수에 의해 형성된 고유 공간에 작은 성분을 가질 수 있기 때문에, y=Φj를 수학식 9에 대입하면 합계는 작아진다. 이는 마이너 특징 벡터 Φj가 의 최소 고유 벡터 v와 상관관계가 있으므로 더 높은 LDRV를 가질 것임을 알 수 있다. LDRM(LDR 평균)은 누락 노드(missing modes)를 검출하는 데에 효과적이다. LDRM의 정의(수학식 4)로부터 높은 LDRM 샘플 x는 훈련을 통해 pg(x)보다 작은 경향이 있으므로 과소 표현된다. 학습 중에 학습 샘플의 LDR(x)을 기록하고 윈도우 크기 ITI=50으로 LDRM 값을 계산한다. 학습 중에 각 모드의 샘플에 대해 평균 LDRM 값을 조사한다. 과소 대표 모드의 샘플이 더 높은 평균 LDRM 값을 갖는다는 것은 LDRM 값의 평균을 조사하여 모드 복구를 감지할 수 있음을 의미한다. 생성된 샘플의 모드 복구를 추가로 조사하기 위 해 생성된 각 샘플을 가장 가까운 모드에 할당하고 할당된 모드에서 4개의 표준 편차 내에 있는 경우 고품질 샘 플로 간주한다. 그런 다음, 샘플 중 각 모드의 고품질 샘플 수를 세고 고품질 샘플 수와 LDRM 분포 사이의 상관 관계를 분석한다. 고품질 샘플이 적은 모드는 LDRM이 높은 경향이 있다. 이는 생성된 샘플을 보지 않고도 데이 터 인스턴스의 LDRM을 사용하여 아직 모델에서 다루지 않은 데이터 매니폴드(data manifold) 영역을 감지할 수 있음을 나타낸다. 본 발명에서 과소 표현된 샘플을 강조하기 위한 알고리즘으로 불일치에 의해 샘플링된 SGD(Stochastic Gradient Descent) 알고리즘을 사용할 수 있다. 일례로, 미니 배치 SGD에 점수 기반 가중 샘플링을 사용하여 과소 표현된 샘플을 강조함으로써 생성적 적대 신경망의 학습 절차를 간단하게 수정할 수 있다. D={xi]를 학습 데이터셋으로 설정한다. 훈련 데이터셋에 대한 크기 B의 미니 배치는 에 의해 형성되며, 즉 각 샘플 xi∈D는 특정확률 Ps(i)로 샘플링된다. 본 발명의 목표는 과소 표현된 샘플을 강조할 수 있는 샘플링 빈도 Ps(i)를 설계하는 것이다. 각 샘플의 과소 표현을 반영하는 불일치 점수, 즉 과소표현 점수 s(xi;T)를 수학식 10과 같이 정의할 수 있다. [수학식 10]"}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서, T는 불일치 점수를 계산하는 데 사용되는 단계 셋이고 k는 각 통계량의 기여도를 변조하는 하이퍼 파라 미터이다. 수학식 10은 LDR 추정치의 신뢰 구간의 상한으로 해석될 수 있으며, LDRM의 가중치와 k에 의해 제어 되는 LDRV의 제곱근의 상한으로 해석될 수 있다. 모든 데이터가 최소한 어느 정도의 확률로 샘플링되도록 s(x i)의 최소값을 ε=0.01(min_clip)로 클리핑하고 최대값을 50의 최대-최소 비율 즉, max s(x)/min s(x)=50(max_clip)으로 클리핑한다. 클리핑된 점수 s'(xi;T)=max_clip (min_clip(s(xi;T)))의 경우 최종 가중치 샘플링 주파수는 와 같다. 불일치 점수(과소표현 점수)가 실제로 과소 표현된 샘플을 캡처하는지 확인하기 위해 불일치 점수가 가장 낮거 나 가장 높은 샘플을 분석한다. 예를 들어, 40k 단계에 대해 CIFAR-10에서 SNGAN을 학습하고 각 샘플의 불일치 점수를 측정한다. 도 7을 참조하면, 학습 이미지 중에서 불일치 점수가 가장 낮은 이미지(도 7의 (a) 이미지)와 불일치 점수가 가장 높은 이미지(도 7의 (b) 이미지)를 제시하고 생성된 샘플 이미지(도 7의 (c) 이미지)와 비 교한다. 불일치 점수가 높은 이미지에는 생성된 샘플과 구별되는 특성(예: 비정상적인 배경이나 모양)이 있는 반면, 불일치 점수가 낮은 이미지에는 생성된 샘플에서도 사용할 수 있는 특징이 포함되어 있다. 도 7의 이미지 에 대한 픽셀 강도 히스토그램을 비교하면, 도 8에 도시한 바와 같이 샘플 속성에서 차이가 더 뚜렷하게 나타남 을 알 수 있다. 불일치 점수가 낮은 이미지는 생성된 샘플과 유사한 강도 분포를 보이는 반면, 불일치 점수가 높은 이미지는 매우 다른 경향을 보인다. 또한, 최저/최고 점수 그룹의 부분 FID(Frechet Inception Distance)(학습 샘플의 서브 집합으로 측정된 FID)를 고려하면 불일치 점수가 높은 그룹의 부분 FID 점수가 불 일치 점수가 낮은 그룹보다 높다. 두 그룹 사이의 큰 간격은 생성기가 고득점 그룹과 유사한 샘플을 생성하지 못한다는 것을 나타낸다. 이러한 결과는 불일치 점수가 추가 학습에 강조가 필요할 수 있는 과소 표현된 데이터 를 성공적으로 식별한다는 것을 의미한다. 본 발명에서는 보조 판별기를 이용하여 DRS(discriminator rejection sampling)에 대한 후처리를 수행할 수 있 다. 불일치 점수 기반 가중 샘플링은 학습 중에 과소 표현된 샘플에 대한 바이어스(bias)를 준다. 다양성을 개선하 는 데 효과적이지만, 이는 수정된 데이터 분포 p'data(x)=f(x)pdata(x) 결과가 된다. 여기서, f(·)은 정규화된 샘 플링 빈도이다. 따라서, 학습된 모델 분포 pg는 원본 데이터 분포 pdata와 다를 수 있다. 이를 해결하기 위해, 학 습 후 바이어스를 수정하기 위해 DRS을 활용한다. DRS는 상수 M>0에 대해 확률 로 생성된 샘플을 받 아들인다. DRS를 수행하려면 판별기 출력에 기초하여 계산된 pdata(x)/pg(x)에 대한 추정치가 필요하다. 본 발명 에서 판별기는 편향된 p'data(x)로 학습되기 때문에 DRS에 대한 LDR 추정치(수학식 2)를 얻기 위해 가중 샘플링 절차 동안 보조 판별기를 추가하고 균일한 샘플링(즉, 샘플링 기법을 적용하지 않고)으로 학습하며 생성된 샘플 의 DRS에 사용할 수 있다. 도 9는 본 발명의 일 실시예에 있어서 자가-진단 생성적 적대 신경망에 대한 세부 알고리즘의 예시를 도시한 것 이다. 요컨대, 도 9를 참조하면, 생성적 적대 신경망 기반의 데이터 생성 방법은 생성적 적대 신경망을 학습하고 각 데이터 인스턴스에 대한 불일치 점수(즉, 과소표현 점수)를 평가하는 학습 및 진단 단계(phase 1), 생성적 적대 신경망이 불일치 점수 기반 가중 샘플링을 통해 데이터 매니폴드의 잘 표현되지 않은 영역을 학습하는 점수 기 반 가중 샘플링 단계(phase 2), 및 생성적 적대 신경망의 학습 후 DRS을 통해 모델 분포 pg(x)를 수정하는 DRS 단계(phase 3)를 포함할 수 있다.이처럼 본 발명의 실시예들에 따르면, 생성적 적대 신경망의 학습 과정에서 모델이 잘 표현하지 못한 데이터를 식별하여 해당 데이터를 강조함으로써 모델이 보다 고르게 각 학습 데이터를 잘 표현할 수 있고 이를 통해 생성 데이터의 다양성과 데이터 생성 성능을 개선할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 프로세서, 콘트롤 러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접 근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명"}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되 어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 이때, 매체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것일 수도 있다. 또한, 매체는 단일 또는 수 개의 하드웨어가 결합된 형태의 다 양한 기록수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트워 크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예시로, 어플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어 를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다."}
{"patent_id": "10-2022-0032061", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2022-0032061", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 있어서 컴퓨터 시스템의 내부 구성의 일례를 설명하기 위한 블록도이다. 도 2는 본 발명의 일실시예에 따른 컴퓨터 시스템의 프로세서가 포함할 수 있는 구성요소의 예를 도시한 도면이 다. 도 3은 본 발명의 일실시예에 따른 컴퓨터 시스템이 수행할 수 있는 데이터 생성 방법의 예를 도시한 순서도이 다. 도 4 내지 도 5는 본 발명의 일실시예에 있어서 생성적 적대 신경망의 학습 과정에서 과소 표현된 데이터를 식 별하여 해당 데이터를 강조 학습하는 과정을 설명하기 위한 예시 도면이다. 도 6은 본 발명의 일실시예에 있어서 생성적 적대 신경망에서 생성된 샘플 예시와 해당 샘플의 부분 재현율 분 석 결과를 도시한 것이다. 도 7은 본 발명의 일실시예에 있어서 생성적 적대 신경망의 학습 이미지 예시를 도시한 것이다. 도 8은 본 발명의 일실시예에 있어서 학습 이미지에 대한 픽셀 강도 히스토그램 비교 결과를 도시한 것이다. 도 9는 본 발명의 일 실시예에 있어서 자가-진단 생성적 적대 신경망에 대한 세부 알고리즘의 예시를 도시한 것 이다."}
