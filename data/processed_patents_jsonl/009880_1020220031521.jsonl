{"patent_id": "10-2022-0031521", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0166176", "출원번호": "10-2022-0031521", "발명의 명칭": "딥 뉴럴 네트워크를 양자화하는 방법 및 장치", "출원인": "리벨리온 주식회사", "발명자": "부윤호"}}
{"patent_id": "10-2022-0031521", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서에 의해 수행되는, 추론 시 사용되는 딥 뉴럴 네트워크(deep neural network)를 양자화하는 방법에 있어서,상기 딥 뉴럴 네트워크에 포함된 제1 정규화 레이어의 출력값들에 대한 제1 통계 정보를 추출하는 단계 - 상기딥 뉴럴 네트워크는 학습 데이터를 이용하여 학습된 모델임 -;상기 딥 뉴럴 네트워크에 대한 상기 학습 데이터의 적어도 일부 없이, 상기 추출된 제1 통계 정보로부터 상기제1 정규화 레이어의 출력값들과 연관된 클리핑 값(clipping value)을 산출하는 단계; 상기 산출된 클리핑 값 및 상기 딥 뉴럴 네트워크에서의 추론 시 사용되는 데이터의 비트 수를 이용하여, 상기제1 정규화 레이어의 후속 레이어의 입력값들과 연관된 이산화 간격을 결정하는 단계; 및상기 후속 레이어의 입력값들을 상기 결정된 이산화 간격을 가진 이산화된 값으로 양자화하는 단계를 포함하는,딥 뉴럴 네트워크를 양자화하는 방법."}
{"patent_id": "10-2022-0031521", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 통계 정보를 추출하는 단계는,상기 제1 정규화 레이어의 출력값에 대한 분포를 나타내는 정보로부터 상기 제1 정규화 레이어와 연관된 하나이상의 채널에 대한 제1 기준화 인수(scale factor)를 추출하는 단계를 포함하는,딥 뉴럴 네트워크를 양자화하는 방법."}
{"patent_id": "10-2022-0031521", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 클리핑 값을 산출하는 단계는,상기 추출된 제1 기준화 인수 중에서, 최대 기준화 인수를 선택하는 단계; 및상기 선택된 최대 기준화 인수 및 미리 정해진 기준 이상의 성능에 대응하는 미리 설정된 값을 이용하여, 상기제1 정규화 레이어의 출력값들과 연관된 클리핑 값을 산출하는 단계를 포함하는,딥 뉴럴 네트워크를 양자화하는 방법."}
{"patent_id": "10-2022-0031521", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제1 정규화 레이어의 출력값들은 정규 분포(normal distribution)에 따르는, 딥 뉴럴 네트워크를 양자화하는 방법."}
{"patent_id": "10-2022-0031521", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 딥 뉴럴 네트워크의 학습 시 사용되는 데이터의 비트 수는 상기 딥 뉴럴 네트워크의 추론 시 사용되는 데이터의 비트 수보다 큰,딥 뉴럴 네트워크를 양자화하는 방법.공개특허 10-2022-0166176-3-청구항 6 제1항 내지 제5항 중 어느 한 항에 따른 방법을 컴퓨터에서 실행하기 위해 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0031521", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "적어도 하나의 프로세서에 의해 수행되는, 추론 시 사용되는 딥 뉴럴 네트워크를 양자화하는 방법에 있어서,상기 딥 뉴럴 네트워크에 포함된 제1 정규화 레이어의 출력값들에 대한 제1 통계 정보를 추출하는 단계 - 상기제1 정규화 레이어는 상기 딥 뉴럴 네트워크 상의 메인 경로 상에 배치됨 -;상기 딥 뉴럴 네트워크에 포함된 제2 정규화 레이어의 출력값들에 대한 제2 통계 정보를 추출하는 단계 - 상기제2 정규화 레이어는 딥 뉴럴 네트워크에 포함된 우회(shortcut) 경로 상에 배치됨 -;상기 추출된 제1 통계 정보 및 상기 추출된 제2 통계 정보를 이용하여, 상기 제1 정규화 레이어 및 상기 제2 정규화 레이어의 후속 레이어의 입력값들과 연관된 이산화 간격을 결정하는 단계; 및상기 후속 레이어의 입력값들을 상기 결정된 이산화 간격을 가진 이산화된 값으로 양자화하는 단계를 포함하는, 딥 뉴럴 네트워크를 양자화하는 방법."}
{"patent_id": "10-2022-0031521", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 딥 뉴럴 네트워크는 학습 데이터를 이용하여 학습된 모델이고, 상기 이산화 간격을 결정하는 단계는,상기 딥 뉴럴 네트워크에 대한 상기 학습 데이터의 적어도 일부 없이, 상기 추출된 제1 통계 정보 및 제2 통계정보로부터 상기 제1 정규화 레이어 및 상기 제2 정규화 레이어의 출력값들과 연관된 클리핑 값을 산출하는 단계; 및상기 산출된 클리핑 값 및 상기 딥 뉴럴 네트워크에서의 추론 시 사용되는 데이터의 비트 수를 이용하여, 상기후속 레이어의 입력값들과 연관된 이산화 간격을 결정하는 단계를 포함하는,딥 뉴럴 네트워크를 양자화하는 방법."}
{"patent_id": "10-2022-0031521", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 제1 통계 정보를 추출하는 단계는,상기 제1 정규화 레이어의 출력값에 대한 분포를 나타내는 정보로부터 상기 제1 정규화 레이어와 연관된 하나이상의 채널에 대한 제1 기준화 인수를 추출하는 단계를 포함하고,상기 제2 통계 정보를 추출하는 단계는,상기 제2 정규화 레이어의 출력값에 대한 분포를 나타내는 정보로부터 상기 제2 정규화 레이어와 연관된 하나이상의 채널에 대한 제2 기준화 인수를 추출하는 단계를 포함하는,딥 뉴럴 네트워크를 양자화하는 방법."}
{"patent_id": "10-2022-0031521", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 이산화 간격을 결정하는 단계는,상기 제1 정규화 레이어와 연관된 하나 이상의 채널 및 상기 제2 정규화 레이어와 연관된 하나 이상의 채널의각각에 대해 상기 제1 기준화 인수 및 상기 제2 기준화 인수를 기초로 산출된 중간값들 중에서, 최대값을 선택하는 단계;공개특허 10-2022-0166176-4-상기 선택된 최대값 및 미리 정해진 기준 이상의 성능에 대응하는 미리 설정된 값을 이용하여 클리핑 값을 산출하는 단계; 및상기 산출된 클리핑 값 및 상기 딥 뉴럴 네트워크에서의 추론 시 사용될 데이터의 비트 수를 이용하여 상기 후속 레이어의 입력값들과 연관된 이산화 간격을 결정하는 단계를 포함하는,딥 뉴럴 네트워크를 양자화하는 방법."}
{"patent_id": "10-2022-0031521", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,상기 제1 정규화 레이어의 출력값들 및 상기 제2 정규화 레이어의 출력값들은 정규 분포에 따르는, 딥 뉴럴 네트워크를 양자화하는 방법."}
{"patent_id": "10-2022-0031521", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서, 상기 딥 뉴럴 네트워크의 학습 시 사용되는 데이터의 비트 수는 상기 딥 뉴럴 네트워크의 추론 시 사용되는 데이터의 비트 수보다 큰,딥 뉴럴 네트워크를 양자화하는 방법."}
{"patent_id": "10-2022-0031521", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제7항에 있어서,상기 제2 정규화 레이어는 상기 후속 레이어와 간접적으로 연결되되, 상기 후속 레이어와 상기 제2 정규화 레이어 사이에, 별도의 정규화 레이어가 배치되지 않는,딥 뉴럴 네트워크를 양자화하는 방법."}
{"patent_id": "10-2022-0031521", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제7항 내지 제13항 중 어느 한 항에 따른 방법을 컴퓨터에서 실행하기 위해 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 딥 뉴럴 네트워크를 양자화하는 방법에 관한 것이다. 딥 뉴럴 네트워크를 양자화하는 방법은, 딥 뉴 럴 네트워크에 포함된 제1 정규화 레이어의 출력값들에 대한 제1 통계 정보를 추출하는 단계, 추출된 제1 통계 정보를 이용하여, 제1 정규화 레이어의 후속 레이어의 입력값들과 연관된 이산화 간격을 결정하는 단계 및 후속 레이어의 입력값들을 결정된 이산화 간격을 가진 이산화된 값으로 양자화하는 단계를 포함한다."}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 딥 뉴럴 네트워크(deep neural network)를 양자화하는 방법 및 장치에 관한 것으로서, 구체적으로 정 규화 레이어를 이용하여 딥 뉴럴 네트워크를 양자화하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥 뉴럴 네트워크에서 추론 시 사용되는 데이터의 크기에 따라 많은 연산량이 요구될 수 있으며, 파라미터, 가 중치 등을 위한 방대한 저장 공간이 요구될 수 있다. 이러한 구성 하에서, 딥 뉴럴 네트워크를 저전력 장치에서 동작되는 경우, 딥 뉴럴 네트워크의 연산량을 최대한 낮추고 필요한 저장 공간을 줄이는 것, 즉, 딥 뉴럴 네트 워크의 경량화는 매우 중요한 사항일 수 있다. 예를 들어, 딥 뉴럴 네트워크를 경량화하기 위해 네트워크 양자 화(quantization) 기법이 사용될 수 있다. 여기서, 네트워크 양자화는 딥 뉴럴 네트워크의 파라미터 및 출력값 (예: activation output)의 비트 프리시전(bit precision)을 감소시키는 방법을 지칭할 수 있다. 이러한 양자 화는 PTQ(Post-Training Quantization) 및 QAT(Quantization Aware Training)로 구분될 수 있다. 한편, 출력값 등의 양자화를 위해 딥 뉴럴 네트워크의 학습에 사용된 학습 데이터가 필요할 수 있다. 예를 들 어, PTQ는 네트워크 양자화를 구현하기 위하여 학습 데이터를 캘리브레이션(calibration) 용도로 사용해야만 했 다. 그러나, 학습 데이터를 이용하여 딥 뉴럴 네트워크의 학습을 수행하는 업체는 학습된 딥 뉴럴 네트워크의"}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "양자화를 수행하는 업체에 학습 시 사용된 학습 데이터를 공유하는 것은 매우 어려울 수 있다.발명의 내용"}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상기와 같은 문제점을 해결하기 위한 딥 뉴럴 네트워크를 양자화하는 방법, 기록매체에 저장된 컴퓨 터 프로그램 및 장치(시스템)를 제공한다."}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시는 방법, 장치(시스템) 또는 판독 가능 저장 매체에 저장된 컴퓨터 프로그램을 포함한 다양한 방식으로 구현될 수 있다. 본 개시의 일 실시예에 따르면, 적어도 하나의 프로세서에 의해 수행되는, 추론 시 사용되는 딥 뉴럴 네트워크 를 양자화하는 방법은, 딥 뉴럴 네트워크에 포함된 제1 정규화 레이어의 출력값들에 대한 제1 통계 정보를 추출 하는 단계, 추출된 제1 통계 정보를 이용하여, 제1 정규화 레이어의 후속 레이어의 입력값들과 연관된 이산화 간격을 결정하는 단계 및 후속 레이어의 입력값들을 결정된 이산화 간격을 가진 이산화된 값으로 양자화하는 단 계를 포함한다. 본 개시의 일 실시예에 따르면, 딥 뉴럴 네트워크는 학습 데이터를 이용하여 학습된 모델이다. 이산화 간격을 결정하는 단계는, 딥 뉴럴 네트워크에 대한 학습 데이터의 적어도 일부 없이, 추출된 제1 통계 정보로부터 제1 정규화 레이어의 출력값들과 연관된 클리핑 값을 결정하는 단계 및 결정된 클리핑 값 및 딥 뉴럴 네트워크에서 의 추론 시 사용되는 데이터의 비트 수를 이용하여, 후속 레이어의 입력값들과 연관된 이산화 간격을 결정하는 단계를 포함한다. 본 개시의 일 실시예에 따르면, 제1 정규화 레이어는 딥 뉴럴 네트워크 상의 메인 경로 상에 배치된다. 방법은, 딥 뉴럴 네트워크에 포함된 우회 경로 상에 배치된 제2 정규화 레이어로부터, 제2 정규화 레이어의 출 력값들에 대한 제2 통계 정보를 추출하는 단계를 더 포함한다. 제1 정규화 레이어의 후속 레이어는 제1 정규화 레이어 및 제2 정규화 레이어의 후속 레이어이다. 이산화 간격을 결정하는 단계는, 추출된 제1 통계 정보 및 추출된 제2 통계 정보를 이용하여, 후속 레이어의 입력값들과 연관된 이산화 간격을 결정하는 단계를 포함한다. 본 개시의 일 실시예에 따르면, 제2 정규화 레이어는 후속 레이어와 간접적으로 연결되되, 후속 레이어와 제2 정규화 레이어 사이에, 별도의 정규화 레이어가 배치되지 않는다. 본 개시의 일 실시예에 따르면, 제1 통계 정보를 추출하는 단계는, 제1 정규화 레이어의 출력값에 대한 분포를 나타내는 정보로부터 제1 정규화 레이어와 연관된 하나 이상의 채널에 대한 제1 기준화 인수를 추출하는 단계를 포함한다. 본 개시의 일 실시예에 따르면, 이산화 간격을 결정하는 단계는, 추출된 제1 기준화 인수 중에서, 최대 기준화 인수를 선택하는 단계 및 선택된 최대 기준화 인수 및 미리 정해진 기준 이상의 성능에 대응하는 미리 설정된 값을 이용하여, 제1 정규화 레이어의 출력값들과 연관된 클리핑 값을 산출하는 단계 및 산출된 클리핑 값 및 딥 뉴럴 네트워크에서의 추론 시 사용되는 데이터의 비트 수를 이용하여 후속 레이어의 입력값들과 연관된 이산화 간격을 결정하는 단계를 포함한다. 본 개시의 일 실시예에 따르면, 딥 뉴럴 네트워크에 포함된 우회 경로 상에 배치되고 후속 레이어보다 선행하여 배치된 제2 정규화 레이어의 출력값들에 대한 분포를 나타내는 정보로부터 제2 정규화 레이어와 연관된 하나 이 상의 채널에 대한 제2 기준화 인수를 추출하는 단계를 더 포함한다. 이산화 간격을 결정하는 단계는, 제1 정규 화 레이어와 연관된 하나 이상의 채널 및 제2 정규화 레이어와 연관된 하나 이상의 채널의 각각에 대해 제1 기 준화 인수 및 제2 기준화 인수를 기초로 산출된 중간값들 중에서, 최대값을 선택하는 단계, 선택된 최대값 및 미리 정해진 기준 이상의 성능에 대응하는 미리 설정된 값을 이용하여 클리핑 값을 산출하는 단계 및 산출된 클 리핑 값 및 딥 뉴럴 네트워크에서의 추론 시 사용될 데이터의 비트 수를 이용하여 후속 레이어의 입력값들과 연 관된 이산화 간격을 결정하는 단계를 포함한다. 본 개시의 일 실시예에 따르면, 제1 정규화 레이어의 출력값들은 정규 분포에 따른다. 본 개시의 일 실시예에 따르면, 딥 뉴럴 네트워크의 학습 시 사용되는 데이터의 비트 수는 딥 뉴럴 네트워크의 추론 시 사용되는 데이터의 비트 수보다 크다. 본 개시의 일 실시예에 따른 상술된 방법을 컴퓨터에서 실행하기 위해 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램이 제공된다. 본 개시의 일 실시예에 따른 컴퓨팅 장치는, 하나 이상의 인스트럭션을 저장하는 메모리 및 저장된 하나 이상의 인스트럭션을 실행함으로써, 딥 뉴럴 네트워크에 포함된 제1 정규화 레이어의 출력값들에 대한 제1 통계 정보를 추출하고, 추출된 제1 통계 정보를 이용하여, 제1 정규화 레이어의 후속 레이어의 입력값들과 연관된 이산화 간 격을 결정하고, 후속 레이어의 입력값들을 결정된 이산화 간격을 가진 이산화된 값으로 양자화하도록 구성된 프 로세서를 포함한다."}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일부 실시예에서 학습된 딥 뉴럴 네트워크의 학습 데이터의 적어도 일부가 제공되지 않은 경우에도, 컴퓨팅 장치는 딥 뉴럴 네트워크의 정규화 레이어를 이용하여 양자화를 수행함으로써, 높은 추론 성능을 유지할 수 있다. 본 개시의 일부 실시예에서, 딥 뉴럴 네트워크의 학습 데이터의 일부를 이용하는 경우, 학습 데이터의 일부에 포함되지 않는 범위의 데이터는 무시될 수 있는데 반하여, 정규화 레이어의 분포 정보를 분석하여 양자화를 수 행하는 경우는 보다 넓은 데이터 범위까지 추론 성능이 일정하게 유지될 수 있다. 본 개시의 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급되지 않은 다른 효과들은 청구범위의 기재로부"}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자(\"통상의 기술자\"라 함)에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 실시를 위한 구체적인 내용을 첨부된 도면을 참조하여 상세히 설명한다. 다만, 이하의 설명에 서는 본 개시의 요지를 불필요하게 흐릴 우려가 있는 경우, 널리 알려진 기능이나 구성에 관한 구체적 설명은 생략하기로 한다. 첨부된 도면에서, 동일하거나 대응하는 구성요소에는 동일한 참조부호가 부여되어 있다. 또한, 이하의 실시예 들의 설명에 있어서, 동일하거나 대응되는 구성요소를 중복하여 기술하는 것이 생략될 수 있다. 그러나, 구성 요소에 관한 기술이 생략되어도, 그러한 구성요소가 어떤 실시예에 포함되지 않는 것으로 의도되지는 않는다. 개시된 실시예의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 후술되어 있는 실시예 들을 참조하면 명확해질 것이다. 그러나, 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 개시가 완전하도록 하고, 본 개시가 통상의 기술 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것일 뿐이다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 개시된 실시예에 대해 구체적으로 설명하기로 한다. 본 명세서에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 관련 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서, 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어 가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서의 단수의 표현은 문맥상 명백하게 단수인 것으로 특정하지 않는 한, 복수의 표현을 포함한다. 또한, 복수의 표현은 문맥상 명백하게 복수인 것으로 특정하지 않는 한, 단수의 표현을 포함한다. 명세서 전체 에서 어떤 부분이 어떤 구성요소를 포함한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에서 사용되는 '모듈' 또는 '부'라는 용어는 소프트웨어 또는 하드웨어 구성요소를 의미하며, '모 듈' 또는 '부'는 어떤 역할들을 수행한다. 그렇지만, '모듈' 또는 '부'는 소프트웨어 또는 하드웨어에 한정되 는 의미는 아니다. '모듈' 또는 '부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서, '모듈' 또는 '부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이 크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 또는 변수들 중 적어도 하나를 포 함할 수 있다. 구성요소들과 '모듈' 또는 '부'들은 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '모듈' 또는 '부'들로 결합되거나 추가적인 구성요소들과 '모듈' 또는 '부'들로 더 분리될 수 있다. 본 개시의 일 실시예에 따르면, '모듈' 또는 '부'는 프로세서 및 메모리로 구현될 수 있다. '프로세서'는 범용 프로세서, 중앙 처리 장치(CPU), 마이크로프로세서, 디지털 신호 프로세서(DSP), 제어기, 마이크로제어기, 상태 머신 등을 포함하도록 넓게 해석되어야 한다. 몇몇 환경에서, '프로세서'는 주문형 반도체(ASIC), 프로그램가 능 로직 디바이스(PLD), 필드 프로그램가능 게이트 어레이(FPGA) 등을 지칭할 수도 있다. '프로세서'는, 예를 들어, DSP와 마이크로프로세서의 조합, 복수의 마이크로프로세서들의 조합, DSP 코어와 결합한 하나 이상의 마 이크로프로세서들의 조합, 또는 임의의 다른 그러한 구성들의 조합과 같은 처리 디바이스들의 조합을 지칭할 수 도 있다. 또한, '메모리'는 전자 정보를 저장 가능한 임의의 전자 컴포넌트를 포함하도록 넓게 해석되어야 한 다. '메모리'는 임의 액세스 메모리(RAM), 판독-전용 메모리(ROM), 비-휘발성 임의 액세스 메모리(NVRAM), 프 로그램가능 판독-전용 메모리(PROM), 소거-프로그램가능 판독 전용 메모리(EPROM), 전기적으로 소거가능 PROM(EEPROM), 플래쉬 메모리, 자기 또는 광학 데이터 저장장치, 레지스터들 등과 같은 프로세서-판독가능 매체 의 다양한 유형들을 지칭할 수도 있다. 프로세서가 메모리로부터 정보를 판독하고/하거나 메모리에 정보를 기 록할 수 있다면 메모리는 프로세서와 전자 통신 상태에 있다고 불린다. 프로세서에 집적된 메모리는 프로세서 와 전자 통신 상태에 있다. 본 개시에서, '시스템'은 서버 장치와 클라우드 장치 중 적어도 하나의 컴퓨팅 장치를 포함할 수 있으나, 이에 한정되는 것은 아니다. 예를 들어, 시스템은 하나 이상의 서버 장치로 구성될 수 있다. 다른 예로서, 시스템 은 하나 이상의 클라우드 장치로 구성될 수 있다. 또 다른 예로서, 시스템은 서버 장치와 클라우드 장치가 함 께 구성되어 동작될 수 있다. 본 개시에서, '딥 뉴럴 네트워크(deep neural network)'는 입력층(또는 입력 레이어), 출력층(또는 출력 레이어) 및 복수의 은닉층(또는 은닉 레이어)을 포함하는 임의의 인공신경망을 지칭할 수 있다. 또한, 딥 뉴럴 네트워크는 하나 이상의 정규화 레이어를 포함하는 임의의 학습된 인공신경망을 지칭할 수 있다. 본 개시에서, '인공신경망 모델'은 기계학습 모델의 일 예로서, 주어진 입력에 대한 답을 추론하는 데 사용하는 임의의 모델을 포함할 수 있다. 일 실시예에 따르면, 인공신경망 모델은 입력 레이어(층), 복수 개의 은닉 레 이어 및 출력 레이어를 포함한 딥 뉴럴 네트워크를 포함할 수 있다. 여기서, 각 레이어는 하나 이상의 노드를 포함할 수 있다. 또한, 인공신경망 모델은 인공신경망 모델에 포함된 복수의 노드와 연관된 가중치를 포함할 수 있다. 여기서, 가중치는 인공신경망 모델과 연관된 임의의 파라미터를 포함할 수 있다. 본 개시에서, '양자화(quantization)'는 학습된 딥 뉴럴 네트워크에 대하여 학습된 오리지널 비트 프리시전 (original bit precision)을 타겟 하드웨어에서 실행시키기 위해 해당 하드웨어의 타겟 비트 프리시전(target bit precision)으로 변환시키는 것을 지칭할 수 있다. 예를 들어, 32 비트 부동 소수점 모델을 8 비트 정수 모 델로 양자화하는 경우, 딥 뉴럴 네트워크의 추론 성능은 다소 감소될 수 있으나, 추론 속도는 더욱 향상될 수 있다. 일 실시예에 따르면, 양자화는 PTQ(Post-Training Quantization) 및 QAT(Quantization Aware Trainin g)으로 구분될 수 있다. QAT는 모델의 학습 시 양자화가 수행되는 방법을 나타내며, PTQ는 학습된 모델에 양자 화를 수행하는 방법을 나타낼 수 있다. 일반적으로 양자화 수행 시, QAT는 학습 데이터의 상당량이 필요하고, PTQ는 임의의 레이어의 출력값에 대한 통계(statistics)를 분석하기 위한 캘리브레이션(calibration) 용도로서 학습 데이터의 적어도 일부가 필요할 수 있다. 본 개시에서, '후속 레이어'는 딥 뉴럴 네트워크에 포함된 레이어 중 특정 정규화 레이어를 기준으로 해당 정규 화 레이어 이후에 연결된 레이어를 지칭할 수 있다. 여기서, 후속 레이어는 정규화 레이어의 출력값들을 처리 할 수 있는 임의의 레이어일 수 있으며, 예를 들어, 출력값의 최대값에 대한 제한이 없는 ReLU(Rectified Linear Unit) 레이어, identity 레이어 등일 수 있으나, 이에 한정되지 않는다. 일 실시예에서, 정규화 레이 어는 후속 레이어와 직접 연결될 수 있다. 다른 실시예에서, 후속 레이어는 정규화 레이어에 간접적으로 연결 될 수 있으며, 후속 레이어와 정규화 레이어 사이에 별도의 정규화 레이어가 배치되지 않을 수 있다. 예를 들 어, 정규화 레이어와 후속 레이어 사이에 정규화 레이어의 통계에 영향을 미치지 않거나, 미치는 영향이 미리 정해진 기준 이하인 별도의 레이어가 존재할 수도 있다. 본 개시에서, '인스트럭션(instruction)'이란, 기능을 기준으로 묶인 하나 이상의 명령어들로서, 컴퓨터 프로그 램의 구성 요소이자 프로세서에 의해 실행되는 것을 지칭할 수 있다. 도 1은 본 개시의 일 실시예에 따른 컴퓨팅 장치가 양자화를 수행하는 예시를 나타내는 도면이다. 도시된 바와 같이, 컴퓨팅 장치는 딥 뉴럴 네트워크를 수신하고, 양자화된 딥 뉴럴 네트워크를 생성하 거나 업데이트할 수 있다. 예를 들어, 딥 뉴럴 네트워크는 32 비트 부동 소수점(32-bit floating point) 등의 오리지널 비트 프리시전을 기초로 학습된 인공신경망으로서, 하나 이상의 정규화 레이어를 포함하는 인공 신경망일 수 있다. 본 개시에서, 양자화는 학습된 인공신경망을 기초로 비트 프리시전을 감소시키는(즉, 오리 지널 비트 프리시전을 타겟 비트 프리시전으로 변환하는) PTQ(Post-Training Quantization) 방식의 양자화를 지 칭할 수 있다. 일반적으로, PTQ를 수행하기 위해 학습 데이터 중 적어도 일부가 요구될 수 있다. 예를 들어, 임의의 레이어의 출력값의 통계 정보를 분석하기 위해 학습 데이터 중 적어도 일부가 캘리브레이션(calibration) 용도로 사용될 수 있다. 그러나, 컴퓨팅 장치는 딥 뉴럴 네트워크에 포함된 복수의 정규화 레이어 각각에 대한 통 계적 특성을 이용하기 때문에, 학습에 사용된 학습 데이터의 적어도 일부 없이, 딥 뉴럴 네트워크에 대한 PTQ를 수행할 수 있다. 일 실시예에 따르면, 정규화 레이어와 연결된 이전 레이어(예: 컨볼루션(convolution) 레이어, 덴스(dense) 레 이어 등)로부터 출력된 출력값들이 정규화 레이어에 입력되는 경우, 정규화 레이어는 입력된 값들을 특정 범위 의 값으로 변환하거나 정규화할 수 있다. 예를 들어, 정규화 레이어는 입력된 데이터를 정규화된 값을 출력하 는 임의의 레이어를 지칭할 수 있으며, 예를 들어, 배치 정규화(batch normalization), 레이어 정규화(layer normalization), 인스턴스 정규화(instance normalization) 등을 포함할 수 있으나, 이에 한정되지 않는다. 예를 들어, 정규화 레이어는 다음의 수학식 1과 같이 구성될 수 있다. 수학식 1"}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, i는 정규화 레이어를 구성하는 각 채널을 나타낼 수 있고, 는 채널별 입력값을 나타낼 수 있으며,"}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "는 채널별 정규화된 출력값을 나타낼 수 있다. 또한, 는 채널별 이동 인수(shift factor)를 나타내며, 는 채널별 기준화 인수(scale factor)를 나타낼 수 있다. 여기서, 이동 인수 및/또는 기준화 인수는 딥 뉴럴 네트 워크의 학습 시 결정될 수 있으며, 딥 뉴럴 네트워크의 양자화 시에 사용될 수 있다. 컴퓨팅 장치는 딥 뉴럴 네트워크에 포함된 정규화 레이어(하나 이상의 정규화 레이어의 각각)의 출력 값들에 대한 통계 정보를 추출할 수 있다. 이러한 정규화 레이어의 출력값들은 정규 분포를 따르며, 정규화 레 이어에 포함된 이동 인수 및/또는 기준화 인수는 정규 분포를 따르는 출력값들의 이동 및/또는 기준에 대한 정 보를 포함할 수 있다. 즉, 정규화 레이어(정규화 레이어와 연관된 이동 인수 및/또는 기준화 인수)는 딥 뉴럴 네트워크의 학습 시 사용된 학습 데이터에 대한 통계 정보를 포함할 수 있다. 즉, 컴퓨팅 장치는 이 러한 통계 정보를 이용하여 딥 뉴럴 네트워크에 대한 양자화를 수행하기 때문에, 학습 데이터의 적어도 일 부 없이도 높은 성능을 유지하면서 양자화가 수행될 수 있다. 컴퓨팅 장치는 추출된 통계 정보를 이용하여, 정규화 레이어의 후속 레이어의 입력값들과 연관된 이산화 간격을 결정할 수 있다. 이를 위해, 컴퓨팅 장치는 추출된 통계 정보로부터 정규화 레이어의 출력값들과 연관된 클리핑 값(clipping value)을 결정할 수 있다. 그리고 나서, 컴퓨팅 장치는 결정된 클리핑 값 및 딥 뉴럴 네트워크에서의 추론 시 사용되는 데이터의 비트 수를 이용하여, 후속 레이어의 입력값들과 연관 된 이산화 간격을 결정할 수 있다. 여기서, 클리핑 값은 타겟 비트 프리시전에 기초하여 양자화를 수행하기 위 한 기준이 되는 값이며, 예를 들어, 정규화된 그래프에서 이산화 간격이 적용되는 영역의 최대 값 및/또는 최소 값을 지칭할 수 있다. 이에 따라, 컴퓨팅 장치는 클리핑 값과 0 사이의 영역을 타겟 비트 프리시전을 기 초로 동일한 간격의 특정 개수로 분할하여, 후속 레이어의 입력값들을 매핑하기 위한 비연속적인 값(예를 들어, 정수 값)을 산출할 수 있다. 이 경우, 각각의 비연속적인 값 사이의 간격이 이산화 간격일 수 있다. 이산화 간격을 결정한 이후에, 컴퓨팅 장치는 후속 레이어의 입력값들을 결정된 이산화 간격을 가진 이산 화된 값으로 양자화할 수 있다. 즉, 컴퓨팅 장치는 후속 레이어의 입력값들을 타겟 비트 프리시전에 따른 값으로 변환하여 양자화할 수 있다. 도 1에서는 하나의 정규화 레이어를 기초로 양자화가 수행되는 과정이 상 술되었으나, 이에 한정되지 않으며, 컴퓨팅 장치는 딥 뉴럴 네트워크에 포함된 복수의 정규화 레이어 각각을 기초로 양자화를 수행할 수 있다. 이와 같은 구성에 의해, 학습된 딥 뉴럴 네트워크의 학습 데이 터가 없는 경우에도, 컴퓨팅 장치는 딥 뉴럴 네트워크에 포함된 정규화 레이어를 이용하여 높은 성능 을 유지하면서 양자화를 수행할 수 있다. 도 2는 본 개시의 일 실시예에 따른 클리핑 값을 기초로 이산화 간격을 결정하는 예시를 나타내는 도 면이다. 상술된 바와 같이, 컴퓨팅 장치(예: 도 1의 100)는 딥 뉴럴 네트워크에 포함된 정규화 레이어의 출력 값들에 대한 통계 정보를 추출하고, 추출된 통계 정보로부터 정규화 레이어의 출력값들과 연관된 제1 클리핑 값 및/또는 제2 클리핑 값을 결정할 수 있다. 예를 들어, 또한, 컴퓨팅 장치는 결정된 클리핑 값 들(250, 260)을 기초로 양자화를 수행하기 위한 이산화 간격을 결정할 수 있다. 예를 들어, 제1 클리핑 값은 도 2에서 도시된 바와 같이, 양의 최대 지점(max point)을 나타낼 수 있으며, 제2 클리핑 값은 음의 최대 지점(- max point)을 나타낼 수 있다. 일 실시예에 따르면, 양자화가 수행되기 전의 후속 레이어의 입력값들은 32 비트 부동 소수점 모델 등과 같이 연속된 값일 수 있다. 예를 들어, 딥 뉴럴 네트워크와 연관된 입력값의 분포 및/또는 출력값의 분포를 시 각적으로 나타내기 위한 그래프(graph) 상에서 후속 레이어의 입력값들은 도시된 바와 같이 연속된 그래프 로 표현될 수 있다. 양자화를 수행하기 위해, 컴퓨팅 장치는 클리핑 값들(250, 260)을 기초로 이산화된 값을 결정할 수 있다. 일 실시예에 따르면, 컴퓨팅 장치는 클리핑 값들(250, 260)을 결정하고, 제1 클리핑 값과 제2 클리핑 값 사이의 영역을 미리 정해진 수로 분할할 수 있다. 예를 들어, 8비트 정수 모델로 양자화하는 경우, 컴퓨팅 장 치는 제1 클리핑 값과 제2 클리핑 값 사이의 영역을 255 개의 동일한 간격의 영역으로 분할할 수 있 다. 다른 예에서, 4비트 정수 모델로 양자화하는 경우, 컴퓨팅 장치는 제1 클리핑 값과 제2 클리핑 값 사이의 영역을 15 개의 동일한 간격의 영역으로 분할할 수 있다. 그리고 나서, 컴퓨팅 장치는 분할된 제 1 클리핑 값과 제2 클리핑 값 사이의 입력값들을 이산화된 값으로 변환할 수 있다. 여기서, 이산화된 값 각각의 사이의 간격은 이산화된 간격으로 결정될 수 있다. 이러한 방법 하에서, 클리핑 값들(250, 260)이 더 작을수록 더 작은 영역이 특정 개수의 영역으로 분할되므로, 이산화된 간격은 더 좁아질 수 있 어서, 추론 성능이 상대적으로 더 높게 유지될 수 있으나 클리핑 값들(250, 260)의 바깥에 있는 입력값들이 상 대적으로 많아질 수 있고 이러한 입력값들에 대해서는 높은 추론 성능이 보장될 수 없다. 이와 반대로, 클리핑 값들(250, 260)이 더 커질수록 더 큰 영역이 특정 개수의 영역으로 분할되므로, 이산화 간격은 더 넓어질 수 있어서, 추론 성능은 상대적을 나빠질 수 있으나, 클리핑 값들(250, 260)의 바깥에 있는 입력값들이 상대적 으로 적어질 수 있어서 양자화를 통해 커버할 수 있는 입력값의 범위가 넓어질 수 있다. 본 개시에서는, 두 개의 클리핑 값들(250, 260) 사이의 영역을 미리 정해진 수로 분할함으로써 이산화된 값이 결정된다고 개시되었으나, 이에 한정되지 않으며, 정규화 레이어와 연결된 레이어의 종류에 따라 이산화 값들의 범위가 상이해질 수 있다. 예를 들어, ReLU 계열의 함수가 정규화 레이어와 연결된 경우, 양의 클리핑 값(예를 들어, 250)과 0 사이의 영역 내에서 이산화된 값이 결정될 수 있다. 다른 예로서, Identity, leaky RelU 등의 다른 비선형 함수(non-linear functions)가 정규화 레이어와 연결된 경우, 이산화된 값은 양의 클리핑 값과 음 의 클리핑 값(예: 제1 클리핑 값 및 제2 클리핑 값) 사이의 값을 가질 수 있다. 일 실시예에 따르면, 결정된 이산화된 값에 따라 후속 레이어의 입력값들은 이산화될 수 있다. 예를 들어, 후속 레이어의 입력값들은 다양한 방식의 기준에 기초하여 각각의 입력값과 연관된 이산화된 값으로 이산화될 수 있다. 일 실시예에 따르면, 0과 제1 이산화된 값 사이에 있는 입력값들 중, 0에 더 가까운 입력값은 0으로 이산화하고, 제1 이산화된 값으로 이산화될 수 있다. 이와 마찬가지로, 제1 이산화된 값 과 제2 이산화된 값 사이에 있는 입력값들 중, 제1 이산화된 값에 더 가까운 입력값은 제1 이산 화된 값으로 이산화되고, 제2 이산화된 값에 더 가까운 입력값은 제2 이산화된 값으로 이산화될 수 있다. 또한, 제2 이산화된 값과 제3 이산화된 값 사이에 있는 입력값들 중, 제2 이산화된 값 에 더 가까운 입력값은 제1 이산화된 값으로 이산화되고, 제2 이산화된 값에 더 가까운 입력값 은 제2 이산화된 값으로 이산화될 수 있다. 상술된 과정에 의해, 컴퓨팅 장치는 클리핑 값들(250, 260)을 결정하고, 클리핑 값들(250, 260)을 기초로 이산화된 값을 결정한 후, 후속 레이어의 입력값들을 결정된 이산화된 값으로 변경하거나 변환함으로써, 양자화를 수행할 수 있다. 도 3은 본 개시의 일 실시예에 따른 컴퓨팅 장치의 내부 구성을 나타내는 블록도이다. 컴퓨팅 장치 는 메모리, 프로세서, 통신 모듈 및 입출력 인터페이스를 포함할 수 있다. 도 3에 도시된 바와 같이, 컴퓨팅 장치는 통신 모듈을 이용하여 네트워크를 통해 정보 및/또는 데이터를 통신할 수 있도록 구성될 수 있다. 메모리는 비-일시적인 임의의 컴퓨터 판독 가능한 기록매체를 포함할 수 있다. 일 실시예에 따르면, 메모 리는 RAM(random access memory), ROM(read only memory), 디스크 드라이브, SSD(solid state drive), 플래시 메모리(flash memory) 등과 같은 비소멸성 대용량 저장 장치(permanent mass storage device)를 포함할 수 있다. 다른 예로서, ROM, SSD, 플래시 메모리, 디스크 드라이브 등과 같은 비소멸성 대용량 저장 장치는 메 모리와는 구분되는 별도의 영구 저장 장치로서 컴퓨팅 장치에 포함될 수 있다. 또한, 메모리에는 운 영체제와 적어도 하나의 프로그램 코드(예를 들어, 컴퓨팅 장치에 설치되어 구동되는 정규화 레이어의 출 력값들에 대한 통계 정보 추출, 클리핑 값 결정, 이산화 간격 결정, 양자화 등을 위한 코드)가 저장될 수 있다. 이러한 소프트웨어 구성요소들은 메모리와는 별도의 컴퓨터에서 판독 가능한 기록매체로부터 로딩될 수 있 다. 이러한 별도의 컴퓨터에서 판독 가능한 기록매체는 이러한 컴퓨팅 장치에 직접 연결가능한 기록 매체 를 포함할 수 있는데, 예를 들어, 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있다. 다른 예로서, 소프트웨어 구성요소들은 컴퓨터에서 판독 가능한 기록매체가 아닌 통신 모듈을 통해 메모리에 로딩될 수도 있다. 예를 들어, 적어도 하나의 프로그램은 개발자들 또는 어플리케이션의 설치 파일을 배포하는 파일 배포 시스템이 통신 모듈을 통해 제 공하는 파일들에 의해 설치되는 컴퓨터 프로그램(예를 들어, 정규화 레이어의 출력값들에 대한 통계 정보 추출, 클리핑 값 결정, 후속 레이어의 입력값들과 연관된 이산화 간격 결정, 후속 레이어의 입력값들에 대한 양자화 등을 위한 프로그램 등)에 기반하여 메모리에 로딩될 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리 또는 통신 모듈에 의해 사용자 단말(미도시) 또는 다른 외부 시스템 으로 제공될 수 있다. 예를 들어, 프로세서는 딥 뉴럴 네트워크에 포함된 정규화 레이어의 출력값들에 대 한 통계 정보를 추출할 수 있다. 또한, 프로세서는 추출된 통계 정보를 이용하여, 정규화 레이어에 후속 하는, 즉, 후속 레이어의 입력값들과 연관된 이산화 간격을 결정할 수 있다. 그리고 나서, 프로세서는 후 속 레이어의 입력값들을 결정된 이산화 간격을 가진 이산화된 값으로 양자화할 수 있다. 통신 모듈은 네트워크를 통해 사용자 단말(미도시)과 컴퓨팅 장치가 서로 통신하기 위한 구성 또는 기능을 제공할 수 있으며, 컴퓨팅 장치가 외부 시스템(일례로 별도의 클라우드 시스템 등)과 통신하기 위 한 구성 또는 기능을 제공할 수 있다. 일례로, 컴퓨팅 장치의 프로세서의 제어에 따라 제공되는 제 어 신호, 명령, 데이터 등이 통신 모듈과 네트워크를 거쳐 사용자 단말 및/또는 외부 시스템의 통신 모듈 을 통해 사용자 단말 및/또는 외부 시스템으로 전송될 수 있다. 예를 들어, 컴퓨팅 장치는 양자화된 딥 뉴럴 네트워크, 양자화된 후속 레이어의 입력값들에 대한 정보 등을, 통신 모듈을 통해 사용자 단말 및/또는 외부 시스템에 제공할 수 있다. 또한, 컴퓨팅 장치의 입출력 인터페이스는 컴퓨팅 장치와 연결되거나 컴퓨팅 장치가 포함 할 수 있는 입력 또는 출력을 위한 장치(미도시)와의 인터페이스를 위한 수단일 수 있다. 도 3에서는 입출력 인터페이스가 프로세서와 별도로 구성된 요소로서 도시되었으나, 이에 한정되지 않으며, 입출력 인터 페이스가 프로세서에 포함되도록 구성될 수 있다. 컴퓨팅 장치는 도 3의 구성요소들보다 더 많 은 구성요소들을 포함할 수 있다. 그러나, 대부분의 종래기술적 구성요소들을 명확하게 도시할 필요성은 없다. 컴퓨팅 장치의 프로세서는 복수의 사용자 단말 및/또는 복수의 외부 시스템으로부터 수신된 정보 및/ 또는 데이터를 관리, 처리 및/또는 저장하도록 구성될 수 있다. 일 실시예에 따르면, 프로세서는 사용자 단말 및/또는 외부 시스템으로부터 학습된 딥 뉴럴 네트워크를 수신할 수 있다. 이 경우, 프로세서는 학 습된 딥 뉴럴 네트워크에 포함된 정규화 레이어의 출력값들에 대한 통계 정보를 추출하고, 추출된 통계 정보를 이용하여, 정규화 레이어의 후속 레이어의 입력값들과 연관된 이산화 간격을 결정할 수 있다. 그리고 나서, 프 로세서는 후속 레이어의 입력값들을 결정된 이산화 간격을 가진 이산화된 값으로 양자화할 수 있다. 도 4는 본 개시의 일 실시예에 따른 딥 뉴럴 네트워크를 양자화하는 방법을 나타내는 흐름도이다. 일 실 시예에 따르면, 딥 뉴럴 네트워크를 양자화하는 방법은 프로세서(예를 들어, 컴퓨팅 장치의 적어도 하나의 프로세서)에 의해 수행될 수 있다. 도시된 바와 같이, 딥 뉴럴 네트워크를 양자화하는 방법은 프로세서가 딥 뉴럴 네트워크에 포함된 제1 정규화 레이어의 출력값들에 대한 제1 통계 정보를 추출함으로써 개시될 수 있 다(S410). 예를 들어, 프로세서는 제1 정규화 레이어의 출력값에 대한 분포를 나타내는 정보로부터 제1 정규화 레이어와 연관된 하나 이상의 채널에 대한 제1 기준화 인수를 추출할 수 있다. 여기서, 딥 뉴럴 네트워크는 학 습 데이터를 이용하여 학습된 모델을 나타낼 수 있으며, 제1 정규화 레이어의 출력값들은 정규 분포에 따를 수 있다. 또한, 딥 뉴럴 네트워크의 학습 시 사용되는 데이터의 비트 수는 딥 뉴럴 네트워크의 추론 시 사용되는 데이터의 비트 수보다 클 수 있다. 프로세서는 추출된 제1 통계 정보를 이용하여, 제1 정규화 레이어의 후속 레이어의 입력값들과 연관된 이산화 간격을 결정할 수 있다(S420). 또한, 프로세서는 후속 레이어의 입력값들을, 결정된 이산화 간격을 가진 이산 화된 값으로 양자화할 수 있다(S430). 예를 들어, 프로세서는 딥 뉴럴 네트워크의 학습 시 사용된 학습 데이터 의 적어도 일부 없이, 추출된 제1 통계 정보로부터 제1 정규화 레이어의 복수의 출력값들과 연관된 클리핑 값을 결정할 수 있다. 그리고 나서, 프로세서는 결정된 클리핑 값 및 딥 뉴럴 네트워크에서의 추론 시 사용되는 데 이터의 비트 수를 이용하여, 후속 레이어의 입력값들과 연관된 이산화 간격을 결정할 수 있다. 일 실시예에 따르면, 프로세서는 제1 정규화 레이어의 출력값에 대한 분포를 나타내는 정보로부터 제1 정규화 레이어와 연관된 하나 이상의 채널에 대한 제1 기준화 인수를 추출할 수 있다. 추출된 제1 기준화 인수 중에서, 최대 기준화 인수가 선택될 수 있다. 그리고 나서, 프로세서는 선택된 최대 기준화 인수 및 미리 정해 진 기준 이상의 성능에 대응하는 미리 설정된 값을 이용하여, 제1 정규화 레이어의 출력값들과 연관된 클리핑 값을 산출할 수 있다. 또한, 프로세서는 산출된 클리핑 값 및 딥 뉴럴 네트워크에서의 추론 시 사용되는 데이 터의 비트 수를 이용하여 후속 레이어의 입력값들과 연관된 이산화 간격을 결정할 수 있다. 도 5는 본 개시의 다룬 실시예에 따른 딥 뉴럴 네트워크를 양자화하는 방법을 나타내는 흐름도이다. 딥 뉴럴 네트워크를 양자화하는 방법은 프로세서(예를 들어, 컴퓨팅 장치의 적어도 하나의 프로세서)에 의해 수행될 수 있다. 도시된 바와 같이, 딥 뉴럴 네트워크를 양자화하는 방법은 프로세서가 딥 뉴럴 네트워크 에 포함된 우회 경로 상에 배치된 제2 정규화 레이어로부터, 제2 정규화 레이어의 출력값들에 대한 제2 통계 정 보를 추출함으로써 개시될 수 있다(S510). 여기서, 제2 정규화 레이어는 후속 레이어보다 선행하여 배치된 레 이어를 지칭하고, 우회 경로는, 딥 뉴럴 네트워크에서 메인 경로로 설정된 경로와 상이한 임의의 경로를 지칭할 수 있다. 예를 들어, 프로세서는 제2 정규화 레이어의 출력값들에 대한 분포를 나타내는 정보로부터 제2 정규 화 레이어와 연관된 하나 이상의 채널에 대한 제2 기준화 인수를 추출할 수 있다. 도 4에서 상술된 제1 정규화 레이어는 딥 뉴럴 네트워크 상의 메인 경로 상에 배치될 수 있으며, 제1 정규화 레 이어의 후속 레이어는 제1 정규화 레이어 및 제2 정규화 레이어의 후속 레이어를 나타낼 수 있다. 추가적으로 또는 대안적으로, 제2 정규화 레이어는 이러한 후속 레이어와 간접적으로 연결될 수 있고, 별도의 정규화 레이 어가 후속 레이어와 제2 정규화 레이어 사이에 배치되지 않을 수 있다. 프로세서는 제1 정규화 레이어로부터 추출된 제1 통계 정보 및 제2 정규화 레이어의 출력값들에 대한 제2 통계 정보를 이용하여, 후속 레이어의 입력값들과 연관된 이산화 간격을 결정할 수 있다(S520). 또한, 프로세서는후속 레이어의 입력값들을, 결정된 이산화 간격을 가진 이산화된 값으로 양자화할 수 있다(S530). 프로세서는 제1 정규화 레이어와 연관된 하나 이상의 채널 및 제2 정규화 레이어와 연관된 하나 이상의 채널의 각각에 대해 제1 기준화 인수 및 제2 기준화 인수를 기초로 산출된 중간값들 중에서, 최대값을 선택할 수 있다. 또한, 프로 세서는 선택된 최대값 및 미리 정해진 기준 이상의 성능에 대응하는 미리 설정된 값을 이용하여 클리핑 값을 산 출할 수 있다. 이 경우, 프로세서는 산출된 클리핑 값 및 딥 뉴럴 네트워크에서의 추론 시 사용될 데이터의 비 트 수를 이용하여 후속 레이어의 입력값들과 연관된 이산화 간격을 결정할 수 있다. 도 6은 본 개시의 일 실시예에 따른 순차적으로 연결된 정규화 레이어 및 후속 레이어 사이에서 양자 화가 수행되는 예시를 나타내는 도면이다. 도시된 것과 같이, 정규화 레이어는 후속 레이어와 순차 적으로(sequentially) 연결될 수 있다. 도 6에서는 정규화 레이어와 후속 레이어가 직접 연결된 것으로 도시되었으나, 이에 한정되지 않으며, 정규화 레이어와 후속 레이어 사이에 임의의 레이어가 포 함될 수 있다. 이 경우, 정규화 레이어와 후속 레이어 사이에 포함된 임의의 레이어는 정규화 레이 어의 출력값들에 대한 통계 정보에 영향을 미치지 않거나 미치는 영향이 미리 결정된 기준 이하인 레이어 일 수 있다. 일 실시예에 따르면, 컴퓨팅 장치(예를 들어, 도 1의 100)는 딥 뉴럴 네트워크에 포함된 정규화 레이어의 출력값들에 대한 통계 정보를 추출할 수 있다. 이 경우, 컴퓨팅 장치는 정규화 레이어의 출력값에 대한 분포를 나타내는 정보로부터 정규화 레이어와 연관된 하나 이상의 채널에 대한 기준화 인수(scale facto r)를 추출할 수 있다. 예를 들어, 컴퓨팅 장치는 도 1에서 상술된 수학식 1에서 에 해당하는 기준화 인수를 추출할 수 있다. 컴퓨팅 장치는 추출된 통계 정보를 이용하여, 정규화 레이어의 후속 레이어의 입력값들과 연관된 이 산화 간격을 결정할 수 있다. 상술된 바와 같이, 컴퓨팅 장치는 딥 뉴럴 네트워크의 학습 시 사용된 학습 데이 터의 적어도 일부 없이, 추출된 통계 정보로부터 정규화 레이어의 출력값들과 연관된 클리핑 값을 결정할 수 있다. 그리고 나서, 결정된 클리핑 값 및 딥 뉴럴 네트워크에서의 추론 시 사용되는 데이터의 비트 수를 이 용하여, 후속 레이어의 입력값들과 연관된 이산화 간격이 결정될 수 있다. 일 실시예에 따르면, 컴퓨팅 장치는 추출된 채널별 기준화 인수 중에서, 최대 기준화 인수를 선택할 수 있다. 또한, 컴퓨팅 장치는 선택된 최대 기준화 인수 및 미리 정해진 기준 이상의 성능에 대응하는 미리 설정된 값을 이용하여, 정규화 레이어의 출력값들과 연관된 클리핑 값을 산출할 수 있다. 예를 들어, 클리핑 값(예를 들어, 양의 최대 지점)은 다음의 수학식 2에 의해 산출될 수 있다. 또한, 다른 클리핑 값(예를 들어, 음의 최 대 지점)은 수학식 3에 의해 산출된 클리핑 값을 기초로 결정될 수 있다. 예를 들어, 수학식 2에 의해 산출된 클리핑 값의 마이너스 값이 음의 최대 지점으로 설정될 수 있다. 수학식 2"}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, i는 정규화 레이어를 구성하는 각 채널을 나타낼 수 있고, 는 양자화 성능과 연관된 변수를 나타 낼 수 있으며, 는 클리핑 값을 나타낼 수 있다. 또한, 는 상술된 수학식 1의 채널별 기준화 인수를 나타낼 수 있다. 예를 들어, 수학식 2에 의해, 정규화 레이어의 출력값이 정규 분포를 따른다고 가정할 때, 가 3인 경우, 99.7%의 후속 레이어의 입력값들이 클리핑 값보다 작아지고, 가 4 이상인 경우, 99.99% 이상 의 후속 레이어의 입력값들이 클리핑 값보다 작아질 수 있다. 일 실시예에 따르면, 더 많은 입력값들을 포함하기 위해, 를 4 이상의 더 높은 값으로 설정하는 경우보다,"}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "를 3 과 4 사이로 유지할 때, 안정적으로 높은 양자화 성능을 유지할 수 있다. 즉, 후속 레이어의 입력값 들은 정규분포를 따르므로, 가 3 과 4 사이로 유지될 때, 99.7%에서 99.99%의 입력값들이 클리핑 값보다 작아 지면서도 이산화 간격을 최소화할 수 있어, 높은 성능이 유지될 수 있다. 이에 따라, 정규화 레이어의 기준화 인수를 이용하여 양자화하는 경우에도 높은 딥 뉴럴 네트워크의 성능을 유지할 수 있다.일 실시예에 따르면, 컴퓨팅 장치는 산출된 클리핑 값 및 딥 뉴럴 네트워크에서의 추론 시 사용되는 데이터의 비트 수를 이용하여 후속 레이어의 입력값들과 연관된 이산화 간격을 결정할 수 있다. 그리고 나서, 컴퓨 팅 장치는 후속 레이어의 입력값들을 결정된 이산화 간격을 가진 이산화된 값으로 양자화할 수 있다. 딥 뉴럴 네트워크의 학습 데이터의 일부를 이용하는 경우 학습 데이터의 일부에 포함되지 않는 범위의 데이터는 무시될 수 있는데 반하여, 상술된 통계 정보를 기초로 양자화를 수행하는 경우에, 학습 데이터의 일부에서 포함 하지 않는 영역의 데이터 범위까지 추론 성능이 일정하게 유지될 수 있다. 도 7은 본 개시의 일 실시예에 따른 제1 정규화 레이어, 제2 정규화 레이어 및 후속 레이어 사 이에서 양자화가 수행되는 예시를 나타내는 도면이다. 도시된 것과 같이, 제1 정규화 레이어 및 제2 정규 화 레이어는 후속 레이어와 연결될 수 있다. 예를 들어, 제1 정규화 레이어는 딥 뉴럴 네트워 크 상의 메인 경로 상에 배치되고, 제2 정규화 레이어는 딥 뉴럴 네트워크 상의 우회 경로 상에 배치될 수 있다. 제1 정규화 레이어의 출력값과 제2 정규화 레이어의 출력값은 서로 연관되어 후속 레이어 의 입력값으로 이용될 수 있다. 도 7에서는 제1 정규화 레이어와 후속 레이어 및 제2 정규화 레이어와 후속 레이어가 직접 연결된 것으로 도시되었으나, 이에 한정되지 않으며, 제1 정규화 레이어와 후속 레이어 및/또는 제2 정규화 레이어와 후속 레이어 사이에 임의의 레이어가 포함될 수 있다. 이 경우, 임의의 레이어는 제1 정규화 레이어 및/또는 제2 정규화 레이어의 출력값들에 대한 통계 정보에 영향을 미치지 않거나 미치는 영향이 미리 결정된 기준 이하인 레이어일 수 있다. 컴퓨팅 장치는 딥 뉴럴 네트워크에 포함된 제1 정규화 레이어의 출력값들에 대한 제1 통계 정보를 추출하 고, 제2 정규화 레이어의 출력값들에 대한 제2 통계 정보를 추출할 수 있다. 이 경우, 컴퓨팅 장치는 제1 정규 화 레이어의 출력값에 대한 분포를 나타내는 정보로부터 제1 정규화 레이어와 연관된 하나 이상의 채 널에 대한 제1 기준화 인수를 추출할 수 있다. 이와 마찬가지로, 컴퓨팅 장치는 제2 정규화 레이어의 출 력값에 대한 분포를 나타내는 정보로부터 제2 정규화 레이어와 연관된 하나 이상의 채널에 대한 제2 기준 화 인수를 추출할 수 있다. 컴퓨팅 장치는 추출된 제1 통계 정보 및 추출된 제2 통계 정보를 이용하여, 후속 레이어의 입력값들과 연 관된 이산화 간격을 결정할 수 있다. 상술된 바와 같이, 컴퓨팅 장치는 딥 뉴럴 네트워크의 학습 시 사용된 학 습 데이터의 적어도 일부 없이, 추출된 제1 통계 정보 및 제2 통계 정보로부터 클리핑 값을 결정하고, 결정된 클리핑 값 및 딥 뉴럴 네트워크에서의 추론 시 사용되는 데이터의 비트 수를 이용하여, 후속 레이어의 입 력값들과 연관된 이산화 간격을 결정할 수 있다. 일 실시예에 따르면, 컴퓨팅 장치는 제1 정규화 레이어와 연관된 하나 이상의 채널 및 제2 정규화 레이어 와 연관된 하나 이상의 채널의 각각에 대해 제1 기준화 인수 및 제2 기준화 인수를 기초로 산출된 중간값 들 중에서, 최대값을 선택할 수 있다. 또한, 컴퓨팅 장치는 선택된 최대값 및 미리 정해진 기준 이상의 성능에 대응하는 미리 설정된 값을 이용하여 클리핑 값을 산출할 수 있다. 예를 들어, 클리핑 값(예를 들어, 양의 최 대 지점)은 다음의 수학식 3에 의해 산출될 수 있다. 또한, 다른 클리핑 값(예를 들어, 음의 최대 지점)은 수 학식 3에 의해 산출된 클리핑 값을 기초로 결정될 수 있다. 예를 들어, 수학식 3에 의해 산출된 클리핑 값의 마이너스 값이 음의 최대 지점으로 설정될 수 있다. 수학식 3"}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, i는 제1 정규화 레이어 및/또는 제2 정규화 레이어를 구성하는 각 채널을 나타낼 수 있고, 는 양자화 성능과 연관된 변수를 나타낼 수 있으며, 는 클리핑 값을 나타낼 수 있다. 또한, 는 제1 정규 화 레이어의 채널별 기준화 인수를 나타낼 수 있으며, 는 제2 정규화 레이어의 채널별 기준화 인 수를 나타낼 수 있다. 예를 들어, 수학식 3에 의해, 제1 정규화 레이어 및/또는 제2 정규화 레이어 의 출력값이 정규 분포를 따른다고 가정할 때, 가 3인 경우, 99.7%의 후속 레이어의 입력값들이 클리핑값보다 작아지고, 가 4 이상인 경우, 99.99% 이상의 후속 레이어의 입력값들이 클리핑 값보다 작아질 수 있다. 일 실시예에서, 더 많은 입력값들을 포함하기 위해, 를 4 이상의 더 높은 값으로 설정하는 경우보다, 를 3 과 4 사이로 유지할 때, 안정적으로 높은 양자화 성능을 유지할 수 있다. 즉, 후속 레이어의 입력값들은 정규분포를 따르므로, 가 3 과 4 사이로 유지될 때, 99.7%에서 99.99%의 입력값들이 클리핑 값보다 작아지면 서도 이산화 간격을 최소화할 수 있어, 높은 성능이 유지될 수 있다. 이에 따라, 제1 정규화 레이어 및 제2 정규화 레이어의 기준화 인수들을 이용하여 양자화하는 경우에도 높은 딥 뉴럴 네트워크의 성능이 유 지될 수 있다. 일 실시예에 따르면, 컴퓨팅 장치는 산출된 클리핑 값 및 딥 뉴럴 네트워크에서의 추론 시 사용될 데이터의 비 트 수를 이용하여 후속 레이어의 입력값들과 연관된 이산화 간격을 결정할 수 있다. 그리고 나서, 컴퓨팅 장치는 후속 레이어의 입력값들을 결정된 이산화 간격을 가진 이산화된 값으로 양자화할 수 있다. 도 8은 본 개시의 일 실시예에 따른 제1 정규화 레이어, 간접적으로 연결된 제2 정규화 레이어 및 후 속 레이어 사이에서 양자화가 수행되는 예시를 나타내는 도면이다. 도시된 것과 같이, 제1 정규화 레이어 및 제2 정규화 레이어는 후속 레이어와 연결될 수 있다. 예를 들어, 제1 정규화 레이어 는 딥 뉴럴 네트워크 상의 메인 경로 상에 배치되고, 제2 정규화 레이어는 딥 뉴럴 네트워크 상의 우회 경 로 상에 배치될 수 있다. 도시된 예에서, 제2 정규화 레이어는 제1 정규화 레이어 및 제2 정규화 레이어의 후속 레이어 와 간접적으로 연결되되, 후속 레이어와 제2 정규화 레이어 사이에, 별도의 정규화 레이어가 배 치되지 않을 수 있다. 즉, 제2 정규화 레이어의 출력값들에 대한 통계적 특성은 후속 레이어에 이용 될 때까지 유지될 수 있다. 이에 따라, 각 레이어가 연결된 경우에도, 클리핑 값은 도 7에서 상술된 것과 같이 수학식 3에 의해 산출될 수 있다. 즉, 제1 정규화 레이어 및/또는 제2 정규화 레이어의 출력값이 정 규 분포를 따른다고 가정할 때, 가 3인 경우, 99.7%의 후속 레이어의 입력값들이 클리핑 값보다 작아지 고, 가 4 이상인 경우, 99.99% 이상의 후속 레이어의 입력값들이 클리핑 값보다 작아질 수 있다. 일 실시예에 따르면, 컴퓨팅 장치는 산출된 클리핑 값 및 딥 뉴럴 네트워크에서의 추론 시 사용될 데이터의 비 트 수를 이용하여 후속 레이어의 입력값들과 연관된 이산화 간격을 결정할 수 있다. 그리고 나서, 컴퓨팅 장치는 후속 레이어의 입력값들을 결정된 이산화 간격을 가진 이산화된 값으로 양자화할 수 있다. 도 9는 본 개시의 일 실시예에 따른 인공신경망 모델을 나타내는 예시도이다. 인공신경망 모델은, 기계학습 모델의 일 예로서, 기계학습(Machine Learning) 기술과 인지과학에서, 생물학적 신경망의 구조에 기초 하여 구현된 통계학적 학습 알고리즘 또는 그 알고리즘을 실행하는 구조이다. 일 실시예에 따르면, 인공신경망 모델은, 생물학적 신경망에서와 같이 시냅스의 결합으로 네트워크를 형성 한 인공 뉴런인 노드(Node)들이 시냅스의 가중치를 반복적으로 조정하여, 특정 입력에 대응한 올바른 출력과 추 론된 출력 사이의 오차가 감소되도록 학습함으로써, 문제 해결 능력을 가지는 기계학습 모델을 나타낼 수 있다. 예를 들어, 인공신경망 모델은 기계 학습, 딥러닝 등의 인공지능 학습법에 사용되는 임의의 확률 모델, 뉴 럴 네트워크 모델 등을 포함할 수 있으며, 상술된 딥 뉴럴 네트워크와 연관된 모델을 포함할 수 있다. 인공신경망 모델은 다층의 노드들과 이들 사이의 연결로 구성된 다층 퍼셉트론(MLP: multilayer perceptron)으로 구현된다. 본 실시예에 따른 인공신경망 모델은 MLP를 포함하는 다양한 인공신경망 모델 구조들 중의 하나를 이용하여 구현될 수 있다. 도 9에 도시된 바와 같이, 인공신경망 모델은, 외부로부터 입력 신호 또는 데이터를 수신하는 입력층, 입력 데이터에 대응한 출력 신호 또는 데이터를 출 력하는 출력층, 입력층과 출력층 사이에 위치하며 입력층으로부터 신호를 받아 특성을 추 출하여 출력층으로 전달하는 n개(여기서, n은 양의 정수)의 은닉층(930_1 내지 930_n)으로 구성된다. 여 기서, 출력층은 은닉층(930_1 내지 930_n)으로부터 신호를 받아 외부로 출력한다. 인공신경망 모델의 학습 방법에는, 교사 신호(정답)의 입력에 의해서 문제의 해결에 최적화되도록 학습하 는 지도 학습(Supervised Learning) 방법과, 교사 신호를 필요로 하지 않는 비지도 학습(Unsupervised Learning) 방법이 있다. 예를 들어, 딥 뉴럴 네트워크와 연관된 인공신경망 모델은 학습 데이터를 이용하여 지도 학습 및/또는 비지도 학습된 모델일 수 있다. 이렇게 학습된 인공신경망 모델은 컴퓨팅 장치의 메모리(미도시)에 저장될 수 있으며, 컴퓨팅 장치는 인공신경망 모델에 대한 양자화를 수행할 수 있다. 예를 들어, 컴퓨팅 장치는 32 비트 부동소수점(32-bit floating point)으로 학습된 인공신경망 모델의 가 중치(weight), 출력값 및/또는 입력값을 이산화 값(예를 들어, 정수)으로 양자화할 수 있다. 일 실시예에 따르면, 컴퓨팅 장치는 인공신경망 모델의 학습에 사용된 학습 데이터를 사용하지 않고도, 인 공신경망 모델에 대한 양자화를 수행할 수 있다. 예를 들어, 인공신경망 모델은 복수의 정규화 레이 어를 포함할 수 있으며, 양자화는 각 정규화 레이어의 후속 레이어의 입력값들에 대해 수행될 수 있다. 이 경 우, 컴퓨팅 장치는 정규화 레이어의 통계적 특성(정규화 레이어의 기준화 인수)을 이용하여 출력값(activation output) 등에 대한 양자화를 수행할 수 있다. 다시 말해, 컴퓨팅 장치는 인공신경망 모델의 학습 시 사용 된 학습 데이터의 적어도 일부 없이, 정규화 레이어로부터 추출된 통계 정보로부터 정규화 레이어의 복수의 출 력값들과 연관된 클리핑 값을 결정하고, 결정된 클리핑 값 및 인공신경망 모델에서의 추론 시 사용되는 데 이터의 비트 수를 이용하여, 후속 레이어의 입력값들과 연관된 이산화 간격을 결정할 수 있다. 도 10은 본 개시의 일 실시예에 따른 딥 뉴럴 네트워크의 양자화와 연관된 임의의 컴퓨팅 장치의 구성도 이다. 도시된 바와 같이, 컴퓨팅 장치는 하나 이상의 프로세서, 버스, 통신 인터페이스 , 프로세서에 의해 수행되는 컴퓨터 프로그램을 로드(load)하는 메모리 및 컴퓨터 프 로그램을 저장하는 저장 모듈을 포함할 수 있다. 다만, 도 10에는 본 개시의 실시예와 관련 있는"}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "구성요소들만이 도시되어 있다. 따라서, 본 개시가 속한 기술분야의 통상의 기술자라면 도 10에 도시된 구성요 소들 외에 다른 범용적인 구성 요소들이 더 포함될 수 있음을 알 수 있다. 프로세서는 컴퓨팅 장치의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 개시의 기술 분야에 잘 알려진 임의의 형태의 프로세서를 포함하여 구성될 수 있다. 또한, 프로세서 는 본 개시의 실시예들에 따른 방법을 실행하기 위한 적어도 하나의 애플리케이션 또는 프로그램에 대한 연산을 수행할 수 있다. 컴퓨팅 장치는 하나 이상의 프로세서를 구비할 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장할 수 있다. 메모리는 본 개시의 다양한 실시예 들에 따른 방법/동작을 실행하기 위하여 저장 모듈로부터 하나 이상의 컴퓨터 프로그램을 로드할 수 있다. 메모리는 RAM과 같은 휘발성 메모리로 구현될 수 있으나, 본 개시의 기술적 범위는 이에 한정 되지 아니한다. 버스는 컴퓨팅 장치의 구성 요소 간 통신 기능을 제공할 수 있다. 버스는 주소 버스 (Address Bus), 데이터 버스(Data Bus) 및 제어 버스(Control Bus) 등 다양한 형태의 버스로 구현될 수 있다. 통신 인터페이스는 컴퓨팅 장치의 유무선 인터넷 통신을 지원할 수 있다. 또한, 통신 인터페이스 는 인터넷 통신 외의 다양한 통신 방식을 지원할 수도 있다. 이를 위해, 통신 인터페이스는 본 개 시의 기술 분야에 잘 알려진 통신 모듈을 포함하여 구성될 수 있다. 저장 모듈은 하나 이상의 컴퓨터 프로그램을 비임시적으로 저장할 수 있다. 저장 모듈은 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 개시가 속하는 기술 분 야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 컴퓨터 프로그램은 메모리에 로드될 때 프로세서로 하여금 본 개시의 다양한 실시예들에 따 른 동작/방법을 수행하도록 하는 하나 이상의 인스트럭션들(instructions)을 포함할 수 있다. 즉, 프로세서 는 하나 이상의 인스트럭션들을 실행함으로써, 본 개시의 다양한 실시예들에 따른 동작/방법들을 수행할 수 있다. 예를 들어, 컴퓨터 프로그램은 딥 뉴럴 네트워크에 포함된 제1 정규화 레이어의 출력값들에 대한 제1 통 계 정보를 추출하고, 추출된 제1 통계 정보를 이용하여, 프로세서는 제1 정규화 레이어의 후속 레이어의 입력값 들과 연관된 이산화 간격을 결정하고, 후속 레이어의 입력값들을, 결정된 이산화 간격을 가진 이산화된 값으로 양자화하기 위한 인스트럭션들을 포함할 수 있다. 본 개시의 앞선 설명은 통상의 기술자들이 본 개시를 행하거나 이용하는 것을 가능하게 하기 위해 제공된다. 본 개시의 다양한 수정예들이 통상의 기술자들에게 쉽게 자명할 것이고, 본원에 정의된 일반적인 원리들은 본 개시의 취지 또는 범위를 벗어나지 않으면서 다양한 변형예들에 적용될 수도 있다. 따라서, 본 개시는 본원에설명된 예들에 제한되도록 의도된 것이 아니고, 본원에 개시된 원리들 및 신규한 특징들과 일관되는 최광의의 범위가 부여되도록 의도된다. 비록 예시적인 구현예들이 하나 이상의 독립형 컴퓨터 시스템의 맥락에서 현재 개시된 주제의 양태들을 활용하 는 것을 언급할 수도 있으나, 본 주제는 그렇게 제한되지 않고, 오히려 네트워크나 분산 컴퓨팅 환경과 같은 임 의의 컴퓨팅 환경과 연계하여 구현될 수도 있다. 또 나아가, 현재 개시된 주제의 양상들은 복수의 프로세싱 칩 들이나 디바이스들에서 또는 그들에 걸쳐 구현될 수도 있고, 스토리지는 복수의 디바이스들에 걸쳐 유사하게 영 향을 받게 될 수도 있다. 이러한 디바이스들은 PC들, 네트워크 서버들, 및 핸드헬드 디바이스들을 포함할 수도 있다."}
{"patent_id": "10-2022-0031521", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "본 명세서에서는 본 개시가 일부 실시예들과 관련하여 설명되었지만, 본 발명이 속하는 기술분야의 통상의 기술 자가 이해할 수 있는 본 개시의 범위를 벗어나지 않는 범위에서 다양한 변형 및 변경이 이루어질 수 있다는 점 을 알아야 할 것이다. 또한, 그러한 변형 및 변경은 본 명세서에서 첨부된 특허 청구의 범위 내에 속하는 것으 로 생각되어야 한다."}
{"patent_id": "10-2022-0031521", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 실시예들은, 이하 설명하는 첨부 도면들을 참조하여 설명될 것이며, 여기서 유사한 참조 번호는 유사 한 요소들을 나타내지만, 이에 한정되지는 않는다. 도 1은 본 개시의 일 실시예에 따른 컴퓨팅 장치가 양자화를 수행하는 예시를 나타내는 도면이다. 도 2는 본 개시의 일 실시예에 따른 클리핑 값을 기초로 이산화 간격을 결정하는 예시를 나타내는 도면이다. 도 3은 본 개시의 일 실시예에 따른 컴퓨팅 장치의 내부 구성을 나타내는 블록도이다. 도 4는 본 개시의 일 실시예에 따른 딥 뉴럴 네트워크를 양자화하는 방법을 나타내는 흐름도이다. 도 5는 본 개시의 다른 실시예에 따른 딥 뉴럴 네트워크를 양자화하는 방법을 나타내는 흐름도이다. 도 6은 본 개시의 일 실시예에 따른 순차적으로 연결된 정규화 레이어 및 후속 레이어 사이에서 양자화가 수행 되는 예시를 나타내는 도면이다. 도 7은 본 개시의 일 실시예에 따른 제1 정규화 레이어, 제2 정규화 레이어 및 후속 레이어 사이에서 양자화가 수행되는 예시를 나타내는 도면이다. 도 8은 본 개시의 일 실시예에 따른 제1 정규화 레이어, 간접적으로 연결된 제2 정규화 레이어 및 후속 레이어 사이에서 양자화가 수행되는 예시를 나타내는 도면이다. 도 9는 본 개시의 일 실시예에 따른 인공신경망 모델을 나타내는 예시도이다. 도 10은 본 개시의 일 실시예에 따른 딥 뉴럴 네트워크의 양자화와 연관된 임의의 컴퓨팅 장치의 구성도이다."}
