{"patent_id": "10-2019-0092721", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0014526", "출원번호": "10-2019-0092721", "발명의 명칭": "음성 합성 서비스를 제공하는 서버, 단말 및 방법", "출원인": "주식회사 케이티", "발명자": "박정석"}}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 합성 서비스를 제공하는 서버에 있어서,기등록된 복수의 샘플 스크립트 중 적어도 하나에 대한 복수의 사용자의 음성 녹음 데이터를 수신하는 수신부;상기 수신된 음성 녹음 데이터에 기초하여 각 사용자의 음색과 관련된 피치값에 대한 합성음 예측 모델을 학습시키는 학습부;사용자 단말로부터 샘플 요청 명령을 수신하는 경우, 상기 학습된 합성음 예측 모델에 기초하여 상기 복수의 샘플 스크립트 중 적어도 하나에 대한 샘플 합성 데이터를 생성하는 생성부;상기 샘플 합성 데이터를 상기 사용자 단말로 제공하는 제공부; 및상기 사용자 단말로부터 수신한 상기 샘플 합성 데이터에 대한 품질 만족도 여부에 기초하여 상기 사용자 단말의 사용자에 대한 목소리 정보를 등록하는 목소리 등록부를 포함하는 것인, 음성 합성 서비스 제공 서버."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 목소리 정보는 상기 합성음 예측 모델에 기초하여 도출된 상기 사용자에 대한 피치값을 포함하는 것인, 음성 합성 서비스 제공 서버"}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 상기 생성부는 상기 사용자 단말로부터 컨텐츠 요청 명령을 수신하는 경우, 기등록된 복수의 컨텐츠 스크립트중 상기 컨텐츠 요청 명령에 대응하는 컨텐츠 스크립트에 대한 컨텐츠 합성 데이터를 상기 등록된 목소리 정보에 포함된 피치값에 기초하여 생성하고,상기 제공부는 상기 컨텐츠 합성 데이터를 상기 사용자 단말에게 제공하는 것인, 음성 합성 서비스 제공 서버."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서, 상기 적어도 하나의 샘플 스크립트에 대한 리딩 속도가 기설정된 리딩 속도에 맞게 조절되도록 속도 조절 인터페이스를 사용자 단말로 제공하는 속도 조절부를 더 포함하는 것인, 음성 합성 서비스 제공 서버."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 상기 속도 조절부는 상기 수신한 음성 녹음 데이터에 대한 발성 속도를 각 사용자 별로 측정하고,공개특허 10-2021-0014526-3-상기 목소리 정보는 상기 각 사용자 별로 측정된 발성 속도를 더 포함하는 것인, 음성 합성 서비스 제공 서버."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서, 상기 생성부는 상기 컨텐츠 요청 명령에 대응하는 컨텐츠 스크립트에 대한 컨텐츠 합성 데이터를 상기 등록된목소리 정보에 포함된 피치값 및 발성 속도에 기초하여 생성하는 것인, 음성 합성 서비스 제공 서버."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서, 상기 학습부는 상기 수신한 음성 녹음 데이터를 구성하는 각 음절의 확률값이 상기 피치값과 관련하여 최대가되도록 상기 합성음 예측 모델을 학습시키는 것인, 음성 합성 서비스 제공 서버."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서, 상기 수신한 음성 녹음 데이터에 대한 발음 정확성을 검증하는 검증부를 더 포함하는 것인, 음성 합성 서비스 제공 서버."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 검증부는 상기 수신한 음성 녹음 데이터에 대한 음성 인식을 수행하고, 상기 수신한 음성 녹음 데이터에대한 음성 인식 수행 결과 및 상기 수신한 음성 녹음 데이터에 대응하는 샘플 스크립트 간의 유사도가 기설정된임계값 이하로 나타난 경우, 상기 수신한 음성 녹음 데이터에 대한 발음 정확성이 부정확하다고 판단하는 것인,음성 합성 서비스 제공 서버."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서, 상기 수신한 음성 녹음 데이터에 대한 발음 정확성이 부정확하다고 판단된 경우, 상기 샘플 스크립트에 대한 새로운 음성 녹음 데이터를 재입력받도록 하는 음성 입력부를 더 포함하는 것인, 음성 합성 서비스 제공 서버."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항에 있어서,상기 음성 녹음 데이터으로부터 검출된 적어도 하나의 음성 구간 간 휴지기 추정 신뢰도를 계산하고, 상기 계산된 휴지기 추정 신뢰도에 기초하여 상기 음성 구간 간의 휴지기를 조정하는 휴지기 조정부를 더 포함하는 것인,음성 합성 서비스 제공 서버."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "음성 합성 서비스를 제공받는 사용자 단말에 있어서, 공개특허 10-2021-0014526-4-기등록된 복수의 샘플 스크립트 중 적어도 하나에 대한 사용자의 음성 녹음 데이터를 음성 합성 서비스 제공 서버로 전송하는 전송부;상기 음성 합성 서비스 제공 서버로 음성 합성을 위한 샘플 요청 명령을 전송한 경우, 학습된 합성음 예측 모델에 기초하여 생성된 적어도 하나에 대한 샘플 합성 데이터를 상기 음성 합성 서비스 제공 서버로부터 수신하는수신부; 및상기 샘플 합성 데이터에 대한 품질 만족도 정보를 입력받는 입력부;상기 전송부는 상기 입력된 품질 만족도 정보를 상기 음성 합성 서비스 제공 서버로 전송하고, 상기 합성음 예측 모델은 상기 적어도 하나에 대한 사용자의 음성 녹음 데이터에 기초하여 상기 사용자의 음색과 관련된 피치값에 대하여 학습된 모델이고,상기 샘플 합성 데이터에 대한 품질 만족도 여부에 기초하여 상기 사용자에 대한 목소리 정보가 상기 음성 합성서비스 제공 서버에 등록되는 것인, 사용자 단말."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서, 상기 목소리 정보는 상기 합성음 예측 모델에 기초하여 도출된 상기 사용자에 대한 피치값을 포함하는 것인, 사용자 단말."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서, 상기 전송부는 컨텐츠 요청 명령을 상기 음성 합성 서비스 제공 서버로 전송하고, 상기 수신부는 상기 등록된 사용자에 대한 목소리 정보에 포함된 피치값에 기초하여 생성된 컨텐츠 합성 데이터를 상기 음성 합성 서비스 제공 서버로부터 수신하고,상기 컨텐츠 합성 데이터는 기등록된 복수의 컨텐츠 스크립트 중 상기 컨텐츠 요청 명령에 대응하는 컨텐츠 스크립트에 대한 컨텐츠 합성 데이터인 것인, 사용자 단말."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서, 상기 적어도 하나의 샘플 스크립트에 대한 상기 사용자의 리딩 속도가 기설정된 리딩 속도에 맞게 조절되도록안내하는 속도 조절 인터페이스를 상기 음성 합성 서비스 제공 서버로부터 제공받는 속도 조절 인터페이스 제공부를 더 포함하는 것인, 사용자 단말."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서, 상기 음성 합성 서비스 제공 서버로 전송된 상기 사용자의 음성 녹음 데이터에 대한 발성 속도가 상기 음성 합성 서비스 제공 서버에 의해 측정되고, 상기 목소리 정보는 상기 사용자의 음성 녹음 데이터에 대한 발성 속도를 더 포함하는 것인, 사용자 단말."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "공개특허 10-2021-0014526-5-제 16 항에 있어서, 상기 컨텐츠 합성 데이터는 상기 등록된 사용자의 목소리 정보에 포함된 피치값 및 발성 속도에 기초하여 생성된 것인, 사용자 단말."}
{"patent_id": "10-2019-0092721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "음성 합성 서비스 제공 서버에 의해 음성 합성 서비스를 제공하는 방법에 있어서,기등록된 복수의 샘플 스크립트 중 적어도 하나에 대한 복수의 사용자의 음성 녹음 데이터를 수신하는 단계;상기 수신된 음성 녹음 데이터에 기초하여 각 사용자의 음색과 관련된 피치값에 대한 합성음 예측 모델을 학습시키는 단계;사용자 단말로부터 샘플 요청 명령을 수신하는 경우, 상기 학습된 합성음 예측 모델에 기초하여 상기 복수의 샘플 스크립트 중 적어도 하나에 대한 샘플 합성 데이터를 생성하는 단계;상기 샘플 합성 데이터를 상기 사용자 단말로 제공하는 단계; 및상기 사용자 단말로부터 수신한 상기 샘플 합성 데이터에 대한 품질 만족도 여부에 기초하여 상기 사용자 단말의 사용자에 대한 목소리 정보를 등록하는 단계를 포함하는 것인, 음성 합성 서비스 제공 방법."}
{"patent_id": "10-2019-0092721", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "음성 합성 서비스를 제공하는 서버는 기등록된 복수의 샘플 스크립트 중 적어도 하나에 대한 복수의 사용자의 음 성 녹음 데이터를 수신하는 수신부, 수신된 음성 녹음 데이터에 기초하여 각 사용자의 음색과 관련된 피치값에 대한 합성음 예측 모델을 학습시키는 학습부, 사용자 단말로부터 샘플 요청 명령을 수신하는 경우, 학습된 합성 음 예측 모델에 기초하여 복수의 샘플 스크립트 중 적어도 하나에 대한 샘플 합성 데이터를 생성하는 생성부, 샘 플 합성 데이터를 사용자 단말로 제공하는 제공부 및 사용자 단말로부터 수신한 샘플 합성 데이터에 대한 품질 만족도 여부에 기초하여 사용자 단말의 사용자에 대한 목소리 정보를 등록하는 목소리 등록부를 포함할 수 있다."}
{"patent_id": "10-2019-0092721", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음성 합성 서비스를 제공하는 서버, 단말 및 방법에 관한 것이다."}
{"patent_id": "10-2019-0092721", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성합성(text-to-speech: TTS) 시스템은 음성 합성 방식을 이용하여 입력된 텍스트를 음성으로 변환하여 자 연스럽고 높은 음질의 음성을 합성한다. 이러한, 음성합성 방식에는 코퍼스 방식, HMM (Hidden Markov Mode) 방식 및 딥러닝 방식이 있다. 대용량 코퍼스 기반 음성합성 시스템은 음편을 저장하는 대용량 데이터베이스를 필요로 하기 때문에 비용이 많 이 들고, 인공지능 서비스가 요구되는 다양한 영역에서 성우 녹음을 이용한 음성 합성을 확대하는 것이 불가능 하고, 데이터베이스에 저장되어 있지 않은 음편에 대하여 음성 합성하는 것인 자연스럽지 못하다는 단점이 있다. HMM (Hidden Markov Mode) 기반 음성합성 시스템은 데이터베이스의 음편 저장 유무와 상관없이 고른 음성합성 품질을 제공할 수 있고, 지명처럼 고유 명사가 많은 네비게이션 음성합성에 적합한 반면, 대용량의 단말 기반 임베디드에는 부적합하고, 기계음처럼 부자연스러운 음성 합성을 한다는 단점이 있다. 딥러닝 기반 음성합성 시스템은 짧은 시간 내 녹음된 음성 녹음 데이터로도 자연스러운 음성합성이 가능하여, 다양한 서비스에 활용되고 있다. 최근에는 기존 전문성우 중심의 음성 합성 서비스에서 일반 고객의 목소리를 이용한 음성 합성 서비스로 확대되 고 있다. 일반 고객을 대상으로 하는 음성합성 서비스의 경우, 일반 고객은 전문 성우와 달리, 발성과 읽는 속도를 유지 하기 어렵다. 또한, 일반 고객이 원하는 음성합성 품질을 얻기 위해서는, 일반 고객이 만족할 때까지 반복적인 음성 녹음을 해야 하는 불편함이 있다. 선행기술문헌 특허문헌(특허문헌 0001) 한국등록특허공보 특1996-0007129호 (1996.05.27. 등록)"}
{"patent_id": "10-2019-0092721", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 기등록된 샘플 스크립트에 대한 사용자의 음 성 녹음 데이터를 이용하여 사용자의 음색과 관련한 합성음 예측 모델을 학습시키고, 학습된 합성음 예측 모델 에 기초하여 샘플 합성 데이터를 생성하여 이를 사용자 단말로 제공하고자 한다. 다만, 본 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2019-0092721", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 발명의 제 1 측면에 따른 음성 합성 서비스를 제공 하는 서버는 기등록된 복수의 샘플 스크립트 중 적어도 하나에 대한 복수의 사용자의 음성 녹음 데이터를 수신 하는 수신부; 상기 수신된 음성 녹음 데이터에 기초하여 각 사용자의 음색과 관련된 피치값에 대한 합성음 예측 모델을 학습시키는 학습부; 사용자 단말로부터 샘플 요청 명령을 수신하는 경우, 상기 학습된 합성음 예측 모델 에 기초하여 상기 복수의 샘플 스크립트 중 적어도 하나에 대한 샘플 합성 데이터를 생성하는 생성부; 상기 샘 플 합성 데이터를 상기 사용자 단말로 제공하는 제공부; 및 상기 사용자 단말로부터 수신한 상기 샘플 합성 데 이터에 대한 품질 만족도 여부에 기초하여 상기 사용자 단말의 사용자에 대한 목소리 정보를 등록하는 목소리 등록부를 포함할 수 있다. 본 발명의 제 2 측면에 따른 음성 합성 서비스를 제공받는 사용자 단말은 음성 합성 서비스 제공 서버로 음성 합성을 위한 샘플 요청 명령을 전송하는 전송부; 학습된 합성음 예측 모델에 기초하여 생성된 적어도 하나에 대 한 샘플 합성 데이터를 상기 음성 합성 서비스 제공 서버로부터 수신하는 수신부; 및 상기 샘플 합성 데이터에 대한 품질 만족도 정보를 입력받은 입력부; 상기 전송부는 상기 입력된 품질 만족도 정보를 상기 음성 합성 서 비스 제공 서버로 전송하고, 상기 합성음 예측 모델은 기등록된 복수의 샘플 스크립트 중 적어도 하나에 대한 복수의 사용자의 음성 녹음 데이터에 기초하여 각 사용자의 음색과 관련된 피치값에 대하여 학습된 모델이고, 상기 샘플 합성 데이터에 대한 품질 만족도 여부에 기초하여 상기 사용자 단말의 사용자에 대한 목소리 정보가 상기 음성 합성 서비스 제공 서버에 등록될 수 있다. 본 발명의 제 3 측면에 따른 음성 합성 서비스 제공 서버에 의해 음성 합성 서비스를 제공하는 방법은 기등록된 복수의 샘플 스크립트 중 적어도 하나에 대한 복수의 사용자의 음성 녹음 데이터를 수신하는 단계; 상기 수신된 음성 녹음 데이터에 기초하여 각 사용자의 음색과 관련된 피치값에 대한 합성음 예측 모델을 학습시키는 단계; 사용자 단말로부터 샘플 요청 명령을 수신하는 경우, 상기 학습된 합성음 예측 모델에 기초하여 상기 복수의 샘 플 스크립트 중 적어도 하나에 대한 샘플 합성 데이터를 생성하는 단계; 상기 샘플 합성 데이터를 상기 사용자 단말로 제공하는 단계; 및 상기 사용자 단말로부터 수신한 상기 샘플 합성 데이터에 대한 품질 만족도 여부에 기초하여 상기 사용자 단말의 사용자에 대한 목소리 정보를 등록하는 단계를 포함할 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본 발명을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 기재된 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2019-0092721", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 본 발명은 기등록된 샘플 스크립트에 대한 사용자의 음성 녹음 데이터를 이용하여 사용자의 음색과 관련한 합성음 예측 모델을 학습시키고, 학습된 합성음 예측 모 델에 기초하여 샘플 합성 데이터를 생성하여 이를 사용자 단말로 제공할 수 있다. 이를 통해, 본 발명은 사용 자의 목소리 등록시 예상되는 샘플 합성 데이터에 대한 품질을 사용자가 확인할 수 있기 때문에 기존과 같이 사 용자가 반복해서 스크립트를 녹음해야 하는 수고로움을 덜어줄 수 있다."}
{"patent_id": "10-2019-0092721", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에 있어서 '부(部)'란, 하드웨어에 의해 실현되는 유닛(unit), 소프트웨어에 의해 실현되는 유닛, 양 방을 이용하여 실현되는 유닛을 포함한다. 또한, 1 개의 유닛이 2 개 이상의 하드웨어를 이용하여 실현되어도 되고, 2 개 이상의 유닛이 1 개의 하드웨어에 의해 실현되어도 된다. 본 명세서에 있어서 단말 또는 디바이스가 수행하는 것으로 기술된 동작이나 기능 중 일부는 해당 단말 또는 디 바이스와 연결된 서버에서 대신 수행될 수도 있다. 이와 마찬가지로, 서버가 수행하는 것으로 기술된 동작이나 기능 중 일부도 해당 서버와 연결된 단말 또는 디바이스에서 수행될 수도 있다. 이하, 첨부된 구성도 또는 처리 흐름도를 참고하여, 본 발명의 실시를 위한 구체적인 내용을 설명하도록 한다. 도 1은 본 발명의 일 실시예에 따른, 음성 합성 서비스 제공 시스템의 구성도이다. 도 1을 참조하면, 음성 합성 서비스 제공 시스템은 음성 합성 서비스 제공 서버 및 사용자 단말을 포 함할 수 있다. 다만, 이러한 도 1의 음성 합성 서비스 제공 시스템은 본 발명의 일 실시예에 불과하므로 도 1 을 통해 본 발명이 한정 해석되는 것은 아니며, 본 발명의 다양한 실시예들에 따라 도 1과 다르게 구성될 수도 있다. 일반적으로, 도 1의 음성 합성 서비스 제공 시스템의 각 구성요소들은 네트워크(미도시)를 통해 연결된다. 네 트워크는 단말들 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 근거리 통신망(LAN: Local Area Network), 광역 통신망(WAN: Wide Area Network), 인터넷 (WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통신망 등을 포함한다. 무선 데이터 통신망의 일례에는 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와이파이(Wi-Fi), 블루투스 통신, 적외선 통신, 초음파 통신, 가시 광 통신(VLC: Visible Light Communication), 라이파이(LiFi) 등이 포함되나 이에 한정되지는 않는다. 사용자 단말은 기등록된 복수의 샘플 스크립트 중 적어도 하나의 샘플 스크립트에 대한 사용자의 음성 녹 음 데이터를 녹음한 후, 음성 녹음 데이터를 음성 합성 서비스 제공 서버에게 전송할 수 있다. 음성 합성 서비스 제공 서버는 사용자 단말로부터 수신된 음성 녹음 데이터에 기초하여 사용자의 음 색과 관련된 피치값에 대한 합성음 예측 모델을 학습시킬 수 있다. 사용자 단말은 사용자의 음성 녹음 데이터가 음성 합성 서비스 제공 서버에 등록된 시간으로부터 기 설정된 기간이 지난 후에 사용자의 음성 합성에 대한 샘플 요청 명령을 음성 합성 서비스 제공 서버에게 전송할 수 있다. 음성 합성 서비스 제공 서버는 사용자 단말로부터 샘플 요청 명령을 수신하는 경우, 학습된 사용자 단말의 합성음 예측 모델에 기초하여 복수의 샘플 스크립트 중 적어도 하나에 대한 샘플 합성 데이터를 생 성하고, 생성된 샘플 합성 데이터를 사용자 단말에게 제공할 수 있다. 사용자 단말은 음성 합성 서비스 제공 서버로부터 수신된 샘플 합성 데이터에 대한 품질 만족도를 체 크한 후, 샘플 합성 데이터에 대한 품질 만족도 정보를 음성 합성 서비스 제공 서버에게 전송할 수 있다. 음성 합성 서비스 제공 서버는 사용자 단말로부터 수신한 샘플 합성 데이터에 대한 품질 만족도 여부 에 기초하여 사용자 단말의 사용자에 대한 목소리 정보를 등록할 수 있다. 이후, 음성 합성 서비스 제공 서버는 사용자 단말로부터 컨텐츠 요청 명령을 수신하는 경우, 기등록 된 복수의 컨텐츠 스크립트 중 컨텐츠 요청 명령에 대응하는 컨텐츠 스크립트에 대한 컨텐츠 합성 데이터를 등 록된 사용자의 목소리 정보에 기초하여 생성하고, 생성된 컨텐츠 합성 데이터를 사용자 단말에게 제공할 수 있다. 이하에서는 도 1의 음성 합성 서비스 제공 시스템의 각 구성요소의 동작에 대해 보다 구체적으로 설명한다. 도 2는 본 발명의 일 실시예에 따른, 도 1에 도시된 음성 합성 서비스 제공 서버의 블록도이다. 도 2를 참조하면, 음성 합성 서비스 제공 서버는 수신부, 학습부, 생성부, 제공부, 목소리 등록부, 속도 조절부, 검증부, 휴지기 조정부 및 음성 입력부를 포함할 수 있 다. 다만, 도 2에 도시된 음성 합성 서비스 제공 서버는 본 발명의 하나의 구현 예에 불과하며, 도 2에 도시된 구성요소들을 기초로 하여 여러 가지 변형이 가능하다. 수신부는 기등록된 복수의 샘플 스크립트 중 적어도 하나에 대한 복수의 사용자의 음성 녹음 데이터를 복 수의 사용자의 단말로부터 수신할 수 있다. 수신부는 사용자 목소리가 담긴 동화 컨텐츠의 서비스를 이용하려는 복수의 사용자 각각의 사용자 단말로 부터 기등록된 복수의 샘플 스크립트 중 적어도 하나의 샘플 스크립트에 대하여 사용자의 목소리가 녹음된 음성 녹음 데이터를 수신할 수 있다. 또한, 수신부는 복수의 사용자 단말로부터 각 음성 녹음 데이터 및 각 사 용자 단말에 대한 식별 정보를 함께 수신할 수 있다. 예를 들어, 도 3a를 참조하면, 사용자 단말에게 기 등록된 복수의 샘플 스크립트 중 랜덤으로 추출된 샘플 스크립트(301, 예컨대, '오늘도 어린이는 학교에 일찍 갑니다.')를 사용자 단말에게 제공한 경우, 수신부는 사용자 단말로부터 샘플 스크립트를 리딩한 사용자의 음성 녹음 데이터 및 사용자 단말의 식별 정보를 수신할 수 있다. 검증부는 복수의 사용자 단말로부터 수신한 음성 녹음 데이터에 대한 발음 정확성을 검증할 수 있다. 검증부는 복수의 사용자 단말로부터 수신한 음성 녹음 데이터에 대한 음성 인식을 수행하고, 수신한 음성 녹음 데이터에 대한 음성 인식 수행 결과 및 수신한 음성 녹음 데이터에 대응하는 샘플 스크립트 간의 유사도가 기설정된 임계값 이하로 나타난 경우, 수신한 음성 녹음 데이터에 대한 발음 정확성이 부정확하다고 판단할 수 있다. 예를 들어, 도 3a를 참조하면, 검증부는 사용자 단말로부터 수신된 음성 녹음 데이터에 대한 음성 인식 수행 결과와 샘플 스크립트 간의 유사도가 80% 이상 일치하는 경우, 사용자 단말로부터 수 신된 음성 녹음 데이터의 발음이 정확하다고 판단하고, 유사도가 80% 미만인 경우, 사용자 단말로부터 수 신된 음성 녹음 데이터의 발음이 부정확하다고 판단할 수 있다. 음성 입력부는 복수의 사용자 단말 별 음성 녹음 데이터 대한 발음 정확성이 부정확하다고 판단되는 사용 자 단말에게 샘플 스크립트에 대한 새로운 음성 녹음 데이터를 재입력받도록 안내하고, 해당 사용자 단말로부터 샘플 스크립트에 대한 새로운 음성 녹음 데이터를 재입력받을 수 있다. 예를 들어, 도 3a를 참조하면, 음성 입 력부는 사용자 단말로부터 수신된 음성 녹음 데이터에 대한 음성 인식 수행 결과와 샘플 스크립트 간의 유사도가 80% 이상 일치하지 않는 경우, 사용자 단말로부터 샘플 스크립트에 대한 새로운 음성 녹음 데이터를 재입력받을 수 있다. 만일, 기설정된 횟수(예컨대, 3회) 이상으로 사용자 단말로부 터 재입력받은 음성 녹음 데이터와 해당 음성 녹음 데이터에 대응하는 샘플 스크립트 간의 유사도가 80% 미만으 로 나타난 경우, 음성 입력부는 샘플 스크립트와 다른 새로운 샘플 스크립트를 사용자 단말에게 제공하고, 새로운 샘플 스크립트에 대한 사용자의 음성 녹음 데이터를 재입력받을 수 있다. 속도 조절부는 복수의 샘플 스크립트 중 적어도 하나의 샘플 스크립트에 대한 각 사용자의 리딩 속도가 기 설정된 리딩 속도에 맞게 조절되도록 속도 조절 인터페이스를 사용자 단말에게 제공할 수 있다. 예를 들 어, 도 3a 내지 3b를 함께 참조하면, 속도 조절부는 기설정된 리딩 속도에 맞게 사용자가 샘플 스크립트 를 리딩할 수 있도록 속도 조절 인터페이스(예컨대, 커서)를 사용자 단말에게 제공할 수 있다.이후, 속도 조절부는 샘플 스크립트에 대한 사용자의 리딩 속도를 고려하여 샘플 스크립트의 다 음 문장에 해당하는 샘플 스크립트에 대하여 리딩 속도를 가이드해주는 속도 조절 인터페이스의 이동 속도 를 조절할 수 있다. 음성 입력부는 각 사용자 별로 복수의 샘플 스크립트 중 적어도 하나의 샘플 스크립트에 대한 리딩 속도 및 기설정된 임계치(예컨대, 20%)간의 비교에 따라 사용자로 하여금 샘플 스크립트를 다시 읽도록 요청할 수 있 다. 예를 들면, 음성 입력부는 사용자의 샘플 스크립트에 대한 리딩 속도가 기설정된 임계치를 초과하는 사용자의 사용자 단말에게 샘플 스크립트를 기설정된 리딩 속도에 맞게 다시 리딩하도록 요청할 수 있다. 속도 조절부는 복수의 사용자 단말로부터 수신한 음성 녹음 데이터에 대한 발성 속도를 각 사용자 별로 측 정할 수 있다. 한편, 음성 합성 품질을 향상시키기 위해서는 음성 녹음 데이터 내 음성 구간 간의 휴지기를 최소화하는 것이 중요하다. 휴지기 조정부는 복수의 사용자 단말로부터 수신한 음성 녹음 데이터 각각으로부터 적어도 하나의 음성 구 간을 검출할 수 있다. 예를 들어, 휴지기 조정부는 VAD(Voice Activity Detection) 알고리즘을 이용하여 음성 녹음 데이터로부터 음성 구간을 검출할 수 있다. 휴지기 조정부는 검출된 적어도 하나의 음성 구간 간 휴지기 추정 신뢰도를 계산하고, 계산된 휴지기 추정 신뢰도에 기초하여 음성 구간 간의 휴지기를 조정할 수 있다. 여기서, 휴지기 추정 신뢰도가 높게 나오면, 음 성 구간 간의 휴지기가 길고, 휴지기 추정 신뢰도가 낮게 나오면, 음성 구간 간의 휴지기가 짧다는 것을 의미할 수 있다. 예를 들어, 휴지기 조정부는 음성 구간 간의 휴지기가 최소화되도록 음성 구간 간의 휴지기를 삭제하거나 평균값으로 조정할 수 있다. 학습부는 수신된 복수의 사용자 각각의 음성 녹음 데이터에 기초하여 각 사용자의 목소리 특성과 관련된 합성음 예측 모델을 사용자별로 학습시킬 수 있다. 구체적으로, 학습부는 수신된 복수의 사용자 각각의 음성 녹음 데이터에 기초하여 각 사용자의 음색과 관 련된 피치값에 대한 합성음 예측 모델을 각 사용자별로 학습시킬 수 있다. 예를 들어, 도 3c를 참조하면, 학습 부는 뉴럴 네트워크 알고리즘을 이용하여 사용자의 음성 녹음 데이터로부터 사용자의 음색과 관련된 피치값을 도출하고, 도출된 피치값을 이용하여 합성음 예측 모델을 학습시킬 수 있다. 여기서, 뉴럴 네트워크 알고리즘은 오디오 데이터와 같이 고차원 연속분포를 학습할 수 있는 다층 RNN(Recurrent Neural Networks)을 기반으로 구성되어 있다. 학습부는 수신한 복수의 사용자 각각의 음성 녹음 데이터를 구성하는 각 음절의 확률값이 피치값과 관련하 여 최대가 되도록 합성음 예측 모델을 학습시킬 수 있다. 사용자의 음성 녹음 데이터( )를 구성하는 각 음절의 확률값은 [수학식 1]과 같이 표현될 수 있다. [수학식 1]"}
{"patent_id": "10-2019-0092721", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 2, "content": "도 3d를 참조하면, 학습부는 각 사용자별로 음성 녹음 데이터에 포함된 사용자의 음색과 관련된 피치값, 해당 음성 데이터에 대응하는 샘플 스크립트 및 사용자 아이디를 합성음 예측 모델에 입력하여 음성 녹음 데이 터를 구성하는 각 음절의 확률값이 최대가 되도록 합성음 예측 모델을 학습시킬 수 있다. 생성부는 복수의 사용자 단말(사용자의 음성 녹음 데이터를 음성 합성 서비스 제공 서버로 전송한 단말) 중 적어도 하나의 사용자 단말로부터 샘플 요청 명령을 수신하는 경우, 학습된 사용자 단말의 합성음 예측 모델에 기초하여 복수의 샘플 스크립트 중 적어도 하나에 대한 샘플 합성 데이터를 생성할 수 있다. 예를 들어, 생성부는 학습된 사용자 단말의 합성음 예측 모델에 기초하여 적어도 하나의 샘플 스크립트에 사용자의 피치값 및 속도 조절부에 의해 측정된 사용자의 발성 속도가 반영된 샘플 합성 데이터를 생성할수 있다. 제공부는 생성된 샘플 합성 데이터를 사용자 단말에게 제공할 수 있다. 목소리 등록부는 사용자 단말로부터 수신한 샘플 합성 데이터에 대한 품질 만족도 여부에 기초하여 사용자 단말의 사용자에 대한 목소리 정보를 등록할 수 있다. 예를 들어, 사용자가 샘플 합성 데이터에 대한 품질을 만족함을 의미하는 등록 승인 메시지를 사용자 단말로부터 수신한 경우, 목소리 등록부 는 사용자 단말의 사용자에 대한 목소리 정보를 등록할 수 있다. 만일, 사용자가 샘플 합성 데이터에 대 한 품질의 불만족을 의미하는 등록 미승인 메시지를 사용자 단말로부터 수신한 경우, 학습부는 사용 자 단말로부터 사용자의 음성 녹음 데이터를 다시 입력받아 합성음 예측 모델을 재훈련시킬 수 있다. 여 기서, 목소리 정보는 합성음 예측 모델에 기초하여 도출된 각 사용자에 대한 피치값을 포함하고, 측정된 사용자 의 발성 속도를 더 포함할 수 있다. 생성부는 사용자 단말로부터 컨텐츠 요청 명령(사용자에 의해 선택된 컨텐츠 스크립트에 대한 정보를 포함)을 수신하는 경우, 기등록된 복수의 컨텐츠 스크립트 중 컨텐츠 요청 명령에 대응하는 컨텐츠 스크립트에 대한 컨텐츠 합성 데이터를 등록된 목소리 정보에 포함된 피치값에 기초하여 생성할 수 있다. 생성부는 컨텐츠 요청 명령에 대응하는 컨텐츠 스크립트에 대한 컨텐츠 합성 데이터를 등록된 목소리 정보 에 포함된 피치값 및 발성 속도에 기초하여 생성할 수 있다. 제공부는 컨텐츠 합성 데이터를 사용자 단말에게 제공할 수 있다. 한편, 당업자라면, 수신부, 학습부, 생성부, 제공부, 목소리 등록부, 속도 조절부 , 검증부, 휴지기 조정부 및 음성 입력부 각각이 분리되어 구현되거나, 이 중 하나 이상이 통합되어 구현될 수 있음을 충분히 이해할 것이다. 도 4는 본 발명의 일 실시예에 따른, 도 1에 도시된 사용자 단말의 블록도이다. 도 4를 참조하면, 사용자 단말은 전송부, 수신부, 입력부 및 속도 조절 인터페이스 제공부 를 포함할 수 있다. 다만, 도 5에 도시된 사용자 단말은 본 발명의 하나의 구현 예에 불과하며, 도 5에 도시된 구성요소들을 기초로 하여 여러 가지 변형이 가능하다. 전송부는 기등록된 복수의 샘플 스크립트 중 적어도 하나에 대한 사용자의 음성 녹음 데이터를 음성 합성 서비스 제공 서버에게 전송할 수 있다. 예를 들어, 도 5를 참조하면, 사용자 목소리가 담긴 동화 컨텐츠 의 서비스를 이용하고자 하는 사용자가 '내목소리동화' 어플리케이션을 통해 목소리 녹음을 선택한 경우, 수신부는 음성 합성 서비스 제공 서버로부터 기등록된 복수의 샘플 스크립트 중 랜덤으로 추출된 샘 플 스크립트(도 3a의 도면부호 301, 예컨대, '오늘도 어린이는 학교에 일찍 갑니다.')를 수신하여 사용자 단말 의 화면에 출력할 수 있다. 전송부는 사용자가 해당 샘플 스크립트에 대하여 사용자의 음성을 녹음 한 경우, 사용자의 음성 녹음 데이터와 함께 사용자 단말의 식별 정보를 음성 합성 서비스 제공 서버(10 0)에게 전송할 수 있다. 여기서, 음성 합성 서비스 제공 서버로 전송된 사용자의 음성 녹음 데이터에 대한 발성 속도가 음성 합성 서비스 제공 서버에 의해 측정될 수 있다. 속도 조절 인터페이스 제공부는 사용자 단말로 제공된 적어도 하나의 샘플 스크립트에 대한 사용자의 리딩 속도가 기설정된 리딩 속도에 맞게 조절되도록 안내하는 속도 조절 인터페이스(도 3b의 도면부호 303)를 음성 합성 서비스 제공 서버로부터 제공받을 수 있다. 사용자는 샘플 스크립트에 표시되는 속도 조절 인 터페이스의 속도에 맞춰서 샘플 스크립트를 리딩할 수 있다. 속도 조절 인터페이스 제공부는 사용자의 샘플 스크립트에 대한 리딩 속도를 고려하여 해당 샘플 스크립트 의 제공 이후에 사용자 단말에게 제공되는 다음 문장에 해당하는 샘플 스크립트에 대한 리딩 속도를 속도 조절 인터페이스의 이동 속도를 통해 조절되도록 속도 조절 인터페이스를 제어할 수 있다. 음성 합성 서비스 제공 서버로 사용자의 음성 녹음 데이터가 전송되면, 음성 합성 서비스 제공 서버 는 사용자의 음성 녹음 데이터에 기초하여 사용자의 목소리 특성과 관련된 합성음 예측 모델을 학습시킬 수 있 다. 구체적으로, 음성 합성 서비스 제공 서버는 사용자의 음성 녹음 데이터로부터 사용자의 음색과 관련 된 피치값을 도출하고, 도출된 피치값을 이용하여 합성음 예측 모델을 학습시킬 수 있다. 전송부는 음성 합성 서비스 제공 서버에게 음성 합성을 위한 샘플 요청 명령을 전송할 수 있다. 예 를 들어, 도 5를 참조하면, 사용자가 '내목소리동화' 어플리케이션을 통해 샘플 합성 데이터 듣기를 위한 인터 페이스를 선택한 경우, 전송부는 음성 합성 서비스 제공 서버에게 음성 합성을 위한 샘플 요청 명령을 전송할 수 있다. 이 후, 음성 합성 서비스 제공 서버는 사용자 단말로부터 샘플 요청 명령을 수신하면, 학습된 사용자 단말의 합성음 예측 모델에 기초하여 복수의 샘플 스크립트 중 적어도 하나에 대한 샘플 합성 데이터를 생 성하여 이를 사용자 단말에게 전송할 수 있다. 여기서, 적어도 하나에 대한 샘플 합성 데이터는 사용자의 음색과 관련된 피치값 및 사용자의 발성 속도가 반영된 데이터일 수 있다. 수신부는 학습된 합성음 예측 모델에 기초하여 생성된 적어도 하나에 대한 샘플 합성 데이터를 음성 합성 서비스 제공 서버로부터 수신할 수 있다. 입력부는 샘플 합성 데이터에 대한 품질 만족도 정보를 입력받을 수 있다. 예를 들어, 도 5를 참조하면, 입력부는 샘플 합성 데이터의 출력 음성이 종료되면, '내목소리동화' 어플리케이션을 통해 해당 샘플 합성 데이터에 대한 품질 만족도 정보를 만족 버튼 또는 불만족 버튼을 통해 입력받을 수 있다. 전송부는 샘플 합성 데이터에 대하여 입력된 품질 만족도 정보를 음성 합성 서비스 제공 서버에게 전 송할 수 있다. 샘플 합성 데이터에 대한 품질 만족도 여부에 기초하여 사용자 단말의 사용자에 대한 목소리 정보가 음성 합성 서비스 제공 서버에 등록될 수 있다. 여기서, 목소리 정보는 합성음 예측 모델에 기초하여 도출된 사용자에 대한 피치값을 포함할 수 있다. 또한, 목소리 정보는 사용자의 음성 녹음 데이터에 대한 발성 속도를 더 포함할 수 있다. 예를 들어, 사용자가 샘플 합성 데이터에 대한 품질을 만족하는 경우에는 사용자에 대한 목소리 정보가 음성 합 성 서비스 제공 서버에 등록되나, 사용자가 샘플 합성 데이터에 대한 품질을 만족하지 않은 경우에는 사용 자가 음성 녹음 데이터를 재입력하고, 음성 합성 서비스 제공 서버는 재입력된 음성 녹음 데이터로 합성음 예측 모델을 재훈련시킬 수 있다. 전송부는 컨텐츠 요청 명령을 음성 합성 서비스 제공 서버에게 전송할 수 있다. 예를 들어, 도 5를 참조하면, 샘플 합성 데이터에 대한 품질 만족도로 음성 합성 서비스 제공 서버에 사용자에 대한 목소리 정보가 등록된 이후, 전송부는 기등록된 복수의 컨텐츠 스크립트 중 사용자에 의해 선택된 컨텐츠 스 크립트에 대한 컨텐츠 요청 명령을 음성 합성 서비스 제공 서버에게 전송할 수 있다. 수신부는 등록된 사용자에 대한 목소리 정보에 포함된 피치값에 기초하여 생성된 컨텐츠 합성 데이터를 음 성 합성 서비스 제공 서버로부터 수신할 수 있다. 여기서, 컨텐츠 합성 데이터는 기등록된 복수의 컨텐츠 스크립트 중 컨텐츠 요청 명령에 대응하는 컨텐츠 스크립트에 대한 컨텐츠 합성 데이터일 수 있다. 컨텐츠 합 성 데이터는 등록된 사용자의 목소리 정보에 포함된 피치값 및 발성 속도에 기초하여 생성될 수 있다. 한편, 당업자라면, 전송부, 수신부, 입력부 및 속도 조절 인터페이스 제공부 각각이 분리 되어 구현되거나, 이 중 하나 이상이 통합되어 구현될 수 있음을 충분히 이해할 것이다. 도 6은 본 발명의 일 실시예에 따른, 음성 합성 서비스 제공 방법을 나타낸 흐름도이다. 도 6을 참조하면, 단계 S601에서 음성 합성 서비스 제공 서버는 복수의 사용자 단말로부터 기등록된 복수 의 샘플 스크립트 중 적어도 하나에 대한 복수의 사용자의 음성 녹음 데이터를 수신할 수 있다. 단계 S603에서 음성 합성 서비스 제공 서버는 복수의 사용자 단말 별로 수신된 음성 녹음 데이터에 기초하 여 각 사용자의 음색과 관련된 피치값에 대한 합성음 예측 모델을 학습시킬 수 있다. 단계 S605에서 음성 합성 서비스 제공 서버는 사용자 단말로부터 샘플 요청 명령을 수신하는 경우, 학습된 사용자 단말에 해당하는 합성음 예측 모델에 기초하여 복수의 샘플 스크립트 중 적어도 하나에 대 한 샘플 합성 데이터를 생성할 수 있다. 단계 S607에서 음성 합성 서비스 제공 서버는 생성된 샘플 합성 데이터를 사용자 단말에게 제공할 수 있다. 단계 S609에서 음성 합성 서비스 제공 서버는 사용자 단말로부터 수신한 샘플 합성 데이터에 대한 품 질 만족도 여부에 기초하여 사용자 단말의 사용자에 대한 목소리 정보를 등록할 수 있다. 상술한 설명에서, 단계 S601 내지 S609는 본 발명의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적 은 단계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 본 발명의 일 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어를 포 함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의 의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이 터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다."}
{"patent_id": "10-2019-0092721", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2019-0092721", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른, 음성 합성 서비스 제공 시스템의 구성도이다. 도 2는 본 발명의 일 실시예에 따른, 도 1에 도시된 음성 합성 서비스 제공 서버의 블록도이다. 도 3a 내지 3d는 본 발명의 일 실시예에 따른, 사용자에 대한 목소리 정보를 등록하는 방법을 설명하기 위한 도 면이다. 도 4는 본 발명의 일 실시예에 따른, 도 1에 도시된 사용자 단말의 블록도이다. 도 5는 본 발명의 일 실시예에 따른, 음성 합성 서비스를 제공하는 방법을 설명하기 위한 도면이다. 도 6은 본 발명의 일 실시예에 따른, 음성 합성 서비스 제공 방법을 나타낸 흐름도이다."}
