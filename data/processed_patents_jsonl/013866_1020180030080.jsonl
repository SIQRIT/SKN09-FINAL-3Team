{"patent_id": "10-2018-0030080", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0108711", "출원번호": "10-2018-0030080", "발명의 명칭": "잔향 환경에 강인한 음원 방향 추정을 위한 심화 신경망 기반의 앙상블 음원 방향 추정 방법", "출원인": "한양대학교 산학협력단", "발명자": "장준혁"}}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 단계; 상기 음성 데이터의 잔향 환경에 따라 잔향 환경 확률을 추정하는 단계; 추정된 상기 잔향 환경 확률을 기반으로 가중치 평균 방식을 이용하여, 미리 학습된 잔향 환경에서의 복수 개의심화 신경망들을 앙상블로 결합시켜 앙상블 음원 방향 추정 모델을 생성하는 단계; 및 상기 앙상블 음원 방향 추정 모델을 기반으로 음원 방향을 추정하는 단계를 포함하는, 심화 신경망 기반의 앙상블 음원 방향 추정 방법."}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 단계는, 입력된 상기 음성 데이터로부터 GCC-PHAT(Generalized Cross Correlation-Phase Transform)를 통해 상기 특징벡터를 추출하는 것을 특징으로 하는, 심화 신경망 기반의 앙상블 음원 방향 추정 방법."}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 음성 데이터의 잔향 환경에 따라 잔향 환경 확률을 추정하는 단계는, 상기 음성 데이터의 잔향 환경은 잔향 시간의 추정을 통해 잔향 환경 확률 값들을 산정하는 것을 특징으로 하는, 심화 신경망 기반의 앙상블 음원 방향 추정 방법."}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 미리 학습된 잔향 환경에서의 복수 개의 심화 신경망들은, 잔향 환경에 따라 구별하기 위해 서로 다른 잔향 시간에 대해 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들이 학습을 통해 생성된 것을 특징으로 하는, 심화 신경망 기반의 앙상블 음원 방향 추정 방법."}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 앙상블 음원 방향 추정 모델을 기반으로 음원 방향을 추정하는 단계는, 상기 앙상블 음원 방향 추정 모델을 기반으로 음원 방향의 각도를 추정하는 것을 특징으로 하는, 심화 신경망 기반의 앙상블 음원 방향 추정 방법."}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 학습 단계에서, 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 단계; 공개특허 10-2019-0108711-3-추출된 상기 특징 벡터들을 잔향 환경별로 분류하는 단계; 및 상기 잔향 환경별로 분류된 상기 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을위한 심화 신경망들을 생성하는 단계를 더 포함하고, 상기 미리 학습된 잔향 환경에서의 복수 개의 심화 신경망들을 앙상블로 결합시켜 앙상블 음원 방향 추정 모델을 생성하는 단계는, 상기 복수 개의 음원 방향 추정을 위한 심화 신경망들을 앙상블로 결합시켜 상기 앙상블 음원 방향 추정 모델을생성하는 것을 특징으로 하는, 심화 신경망 기반의 앙상블 음원 방향 추정 방법."}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "학습 단계에서, 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 단계; 추출된 상기 특징 벡터들을 잔향 환경별로 분류하는 단계; 및 상기 잔향 환경별로 분류된 상기 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을위한 심화 신경망들을 생성하는 단계를 포함하고, 상기 복수 개의 음원 방향 추정을 위한 심화 신경망들을 앙상블로 결합시켜 음원 방향을 추정하는 것을 특징으로 하는, 심화 신경망 기반의 앙상블 음원 방향 추정 방법."}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 학습 단계에서, 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 단계는, 입력된 상기 음성 데이터로부터 GCC-PHAT(Generalized Cross Correlation-Phase Transform)를 통해 상기 특징벡터를 추출하는 것을 특징으로 하는, 심화 신경망 기반의 앙상블 음원 방향 추정 방법."}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 특징 벡터들을 잔향 환경별로 분류하는 단계는, 잔향 환경에 따라 구별하기 위해 상기 특징 벡터들을 서로 다른 잔향 시간에 따라 분류하며, 상기 잔향 환경별로 분류된 상기 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을위한 심화 신경망들을 생성하는 단계는, 서로 다른 잔향 시간 상기 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을 위한심화 신경망들을 학습을 통해 생성하는 것을 특징으로 하는, 심화 신경망 기반의 앙상블 음원 방향 추정 방법."}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서, 테스트 단계에서, 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 단계; 상기 음성 데이터의 잔향 환경에 따라 잔향 환경 확률을 추정하는 단계; 추정된 상기 잔향 환경 확률을 기반으로 가중치 평균 방식을 이용하여, 미리 학습된 잔향 환경에서의 복수 개의공개특허 10-2019-0108711-4-심화 신경망들을 앙상블로 결합시켜 앙상블 음원 방향 추정 모델을 생성하는 단계; 및 상기 앙상블 음원 방향 추정 모델을 기반으로 음원 방향을 추정하는 단계를 더 포함하는, 심화 신경망 기반의 앙상블 음원 방향 추정 방법."}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 특징 벡터 추출부; 상기 음성 데이터의 잔향 환경에 따라 잔향 환경 확률을 추정하는 잔향 환경 확률 추정부; 및 추정된 상기 잔향 환경 확률을 기반으로 가중치 평균 방식을 이용하여, 미리 학습된 잔향 환경에서의 복수 개의심화 신경망들을 앙상블로 결합시켜 앙상블 음원 방향 추정 모델을 생성하고, 상기 앙상블 음원 방향 추정 모델을 기반으로 음원 방향을 추정하는 앙상블 음원 방향 추정 모델링부을 포함하는, 심화 신경망 기반의 앙상블 음원 방향 추정 장치."}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 잔향 환경 확률 추정부는, 상기 음성 데이터의 잔향 환경은 잔향 시간의 추정을 통해 잔향 환경 확률 값들을 산정하는 것을 특징으로 하는, 심화 신경망 기반의 앙상블 음원 방향 추정 장치."}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 미리 학습된 잔향 환경에서의 복수 개의 심화 신경망들은, 잔향 환경에 따라 구별하기 위해 서로 다른 잔향 시간에 대해 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들이 학습을 통해 생성된 것을 특징으로 하는, 심화 신경망 기반의 앙상블 음원 방향 추정 장치."}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서, 학습 단계에서, 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 학습 단계 특징 벡터 추출부; 추출된 상기 특징 벡터들을 잔향 환경별로 분류하는 특징 벡터 분류부; 및 상기 잔향 환경별로 분류된 상기 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을위한 심화 신경망들을 생성하는 음원 방향 추정 심화 신경망을 더 포함하고, 상기 복수 개의 음원 방향 추정을 위한 심화 신경망들을 앙상블로 결합시켜 상기 앙상블 음원 방향 추정 모델을생성하는 것을 특징으로 하는, 심화 신경망 기반의 앙상블 음원 방향 추정 장치."}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 특징 벡터 분류부는, 잔향 환경에 따라 구별하기 위해 상기 특징 벡터들을 서로 다른 잔향 시간에 따라 분류하며, 상기 음원 방향 추정 심화 신경망은, 공개특허 10-2019-0108711-5-서로 다른 잔향 시간 상기 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을 위한심화 신경망들을 학습을 통해 생성하는 것을 특징으로 하는, 심화 신경망 기반의 앙상블 음원 방향 추정 장치."}
{"patent_id": "10-2018-0030080", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "학습 단계에서, 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 학습 단계 특징 벡터 추출부; 추출된 상기 특징 벡터들을 잔향 환경별로 분류하는 특징 벡터 분류부; 및 상기 잔향 환경별로 분류된 상기 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을위한 심화 신경망들을 생성하는 음원 방향 추정 심화 신경망을 포함하고, 상기 복수 개의 음원 방향 추정을 위한 심화 신경망들을 앙상블로 결합시켜 음원 방향을 추정하는 것을 특징으로 하는, 심화 신경망 기반의 앙상블 음원 방향 추정 장치."}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "잔향 환경에 강인한 음원 방향 추정을 위한 심화 신경망 기반의 앙상블 음원 방향 추정 방법 및 장치가 제시된다. 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 방법은, 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 단계; 상기 음성 데이터의 잔향 환경에 따라 잔향 환경 확률을 추정하는 단계; 추정된 상 기 잔향 환경 확률을 기반으로 가중치 평균 방식을 이용하여, 미리 학습된 잔향 환경에서의 복수 개의 심화 신경 망들을 앙상블로 결합시켜 앙상블 음원 방향 추정 모델을 생성하는 단계; 및 상기 앙상블 음원 방향 추정 모델을 기반으로 음원 방향을 추정하는 단계를 포함하여 이루어질 수 있다."}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 실시예들은 다양한 잔향 환경에 강인한 음원 방향 추정 기술에 관한 것으로, 더욱 상세하게는 잔향 환경 에 강인한 음원 방향 추정을 위한 심화 신경망 기반의 앙상블 음원 방향 추정 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "대부분의 실생활 속 음향 환경은 발화점에서 발생한 신호가 최단거리를 통해 전달될 뿐만 아니라 반사적인 경로 를 거침으로써 잔향을 형성한다. 이러한 잔향은 음성인식, 음원 방향 추정, 음성의 모델링, 및 음원 위치 추정 등의 음성, 음향 신호처리 과정의 성능을 현저히 떨어뜨린다. 최근 머신러닝 기법인 심화 신경망(Deep Neural Network, DNN)이 다양한 음성 향상 및 음성 인식 연구에서 우수 한 성능을 보이고 있다. 심화 신경망은 다수의 은닉층과 은닉 노드들을 통하여 입력 특징 벡터와 출력 특징 벡 터 사이의 비선형적인 관계를 효과적으로 모델링하여 우수한 성능을 보인다. 아래의 비특허문헌[1] Xiong Xiao, Shengkui Zhao, Xionghu Zhong, Douglas L. Jones, Eng Siong Chng, Haizhou Li, \"A learning-based approach to direction of arrival estimation in noisy and reverberant environments\" IEEE International Conference on Acoustics, Speech and Signal Processing(ICASSP), April. 2015.은 단일 심화 신경망을 기반으로 하여 음원 방향을 추정하는 기술이다. 기존에는 단일 심화 신경망을 이용하여 음원 방향을 추정하였으나, 단일 심화 신경망을 사용하여 다양한 잔향 환경에서 음원 방향을 추정할 경우 각각 잔향 환경에 적합한 음원 방향 추정 모델을 선택하지 못하여 정교한 음 원 방향을 추정할 수가 없다. 즉, 기존의 단일 심화 신경망 기반의 음원 방향 추정 기술의 경우, 다양한 잔향 환경의 데이터들에 대한 음원 방향을 추정할 때에 실생활에서 존재하는 다양한 잔향 환경에 대한 충분한 정보를 가지고 있지 못하기 때문에 해당 잔향에 적합한 음원 방향 추정 모델을 제시하지 못하는 문제점을 가지고 있다. 이러한 문제점은 여러 잔 향 환경이 존재하는 실제 실생활에서 음원 방향 추정의 정확도를 떨어뜨릴 수 있다. 선행기술문헌 비특허문헌 (비특허문헌 0001) Xiong Xiao, Shengkui Zhao, Xionghu Zhong, Douglas L. Jones, Eng Siong Chng, Haizhou Li, \"A learning-based approach to direction of arrival estimation in noisy and reverberant environments\" IEEE International Conference on Acoustics, Speech and Signal"}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "Processing(ICASSP), April. 2015. 발명의 내용"}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예들은 잔향 환경에 강인한 음원 방향 추정을 위한 심화 신경망 기반의 앙상블 음원 방향 추정 방법 및 장 치에 관하여 기술하며, 보다 구체적으로 다양한 잔향 환경에 대한 앙상블 심화 신경망을 구성하여 다채널 마이 크 구조에서의 음원 방향(Direction Of Arrival, DOA)을 추정하는 기술을 제공한다. 실시예들은 각 잔향 환경별로 심화 신경망들을 독립적으로 생성한 뒤, 생성한 여러 개의 심화 신경망들을 앙상 블로 구성하여 각 잔향 환경에 대한 정보들을 활용함으로써, 앙상블 모델을 통해 기존 단일 심화 신경망 기반의 음원 방향 추정 기술에 비해 더 우수한 음원 방향 추정 성능을 갖는 잔향 환경에 강인한 음원 방향 추정을 위한 심화 신경망 기반의 앙상블 음원 방향 추정 방법 및 장치를 제공하는데 있다."}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 방법은, 잔향 환경의 음성 데이터에서 특징 벡터 를 추출하는 단계; 상기 음성 데이터의 잔향 환경에 따라 잔향 환경 확률을 추정하는 단계; 추정된 상기 잔향 환경 확률을 기반으로 가중치 평균 방식을 이용하여, 미리 학습된 잔향 환경에서의 복수 개의 심화 신경망들을 앙상블로 결합시켜 앙상블 음원 방향 추정 모델을 생성하는 단계; 및 상기 앙상블 음원 방향 추정 모델을 기반 으로 음원 방향을 추정하는 단계를 포함하여 이루어질 수 있다. 상기 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 단계는, 입력된 상기 음성 데이터로부터 GCC- PHAT(Generalized Cross Correlation-Phase Transform)를 통해 상기 특징 벡터를 추출할 수 있다. 상기 음성 데이터의 잔향 환경에 따라 잔향 환경 확률을 추정하는 단계는, 상기 음성 데이터의 잔향 환경은 잔 향 시간의 추정을 통해 잔향 환경 확률 값들을 산정할 수 있다. 상기 미리 학습된 잔향 환경에서의 복수 개의 심화 신경망들은, 잔향 환경에 따라 구별하기 위해 서로 다른 잔 향 시간에 대해 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들이 학습을 통해 생성될 수 있다. 상기 앙상블 음원 방향 추정 모델을 기반으로 음원 방향을 추정하는 단계는, 상기 앙상블 음원 방향 추정 모델 을 기반으로 음원 방향의 각도를 추정할 수 있다. 학습 단계에서, 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 단계; 추출된 상기 특징 벡터들을 잔향 환 경별로 분류하는 단계; 및 상기 잔향 환경별로 분류된 상기 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들을 생성하는 단계를 더 포함할 수 있다. 여기서, 상기 미리 학 습된 잔향 환경에서의 복수 개의 심화 신경망들을 앙상블로 결합시켜 앙상블 음원 방향 추정 모델을 생성하는 단계는, 상기 복수 개의 음원 방향 추정을 위한 심화 신경망들을 앙상블로 결합시켜 상기 앙상블 음원 방향 추 정 모델을 생성할 수 있다. 다른 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 방법은, 학습 단계에서, 잔향 환경의 음성 데이 터에서 특징 벡터를 추출하는 단계; 추출된 상기 특징 벡터들을 잔향 환경별로 분류하는 단계; 및 상기 잔향 환 경별로 분류된 상기 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들을 생성하는 단계를 포함하고, 상기 복수 개의 음원 방향 추정을 위한 심화 신경망들을 앙상블로 결합 시켜 음원 방향을 추정할 수 있다. 상기 학습 단계에서, 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 단계는, 입력된 상기 음성 데이터로부 터 GCC-PHAT(Generalized Cross Correlation-Phase Transform)를 통해 상기 특징 벡터를 추출할 수 있다. 상기 특징 벡터들을 잔향 환경별로 분류하는 단계는, 잔향 환경에 따라 구별하기 위해 상기 특징 벡터들을 서로 다른 잔향 시간에 따라 분류하며, 상기 잔향 환경별로 분류된 상기 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들을 생성하는 단계는, 서로 다른 잔향 시간 상기 특징 벡 터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들을 학습을 통해 생성 할 수 있다. 테스트 단계에서, 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 단계; 상기 음성 데이터의 잔향 환경에 따라 잔향 환경 확률을 추정하는 단계; 추정된 상기 잔향 환경 확률을 기반으로 가중치 평균 방식을 이용하여, 미리 학습된 잔향 환경에서의 복수 개의 심화 신경망들을 앙상블로 결합시켜 앙상블 음원 방향 추정 모델을 생 성하는 단계; 및 상기 앙상블 음원 방향 추정 모델을 기반으로 음원 방향을 추정하는 단계를 더 포함할 수 있다. 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 장치는, 잔향 환경의 음성 데이터에서 특징 벡터 를 추출하는 특징 벡터 추출부; 상기 음성 데이터의 잔향 환경에 따라 잔향 환경 확률을 추정하는 잔향 환경 확 률 추정부; 및 추정된 상기 잔향 환경 확률을 기반으로 가중치 평균 방식을 이용하여, 미리 학습된 잔향 환경에 서의 복수 개의 심화 신경망들을 앙상블로 결합시켜 앙상블 음원 방향 추정 모델을 생성하고, 상기 앙상블 음원 방향 추정 모델을 기반으로 음원 방향을 추정하는 앙상블 음원 방향 추정 모델링부를 포함하여 이루어질 수 있 다. 상기 잔향 환경 확률 추정부는, 상기 음성 데이터의 잔향 환경은 잔향 시간의 추정을 통해 잔향 환경 확률 값들 을 산정할 수 있다. 상기 미리 학습된 잔향 환경에서의 복수 개의 심화 신경망들은, 잔향 환경에 따라 구별하기 위해 서로 다른 잔 향 시간에 대해 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들이 학습을 통해 생성될 수 있다. 학습 단계에서, 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 학습 단계 특징 벡터 추출부; 추출된 상기 특징 벡터들을 잔향 환경별로 분류하는 특징 벡터 분류부; 및 상기 잔향 환경별로 분류된 상기 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들을 생성하는 음원 방향 추정 심화 신경망을 더 포함할 수 있다. 여기서, 상기 복수 개의 음원 방향 추정을 위한 심화 신경망들을 앙상블로 결합시켜 상기 앙상블 음원 방향 추정 모델을 생성할 수 있다. 상기 특징 벡터 분류부는, 잔향 환경에 따라 구별하기 위해 상기 특징 벡터들을 서로 다른 잔향 시간에 따라 분 류하며, 상기 음원 방향 추정 심화 신경망은, 서로 다른 잔향 시간 상기 특징 벡터들을 입력 특징 벡터로 사용 하여 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들을 학습을 통해 생성할 수 있다. 다른 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 장치는, 학습 단계에서, 잔향 환경의 음성 데이 터에서 특징 벡터를 추출하는 학습 단계 특징 벡터 추출부; 추출된 상기 특징 벡터들을 잔향 환경별로 분류하는 특징 벡터 분류부; 및 상기 잔향 환경별로 분류된 상기 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들을 생성하는 음원 방향 추정 심화 신경망을 포함하고, 상기 복수 개 의 음원 방향 추정을 위한 심화 신경망들을 앙상블로 결합시켜 음원 방향을 추정할 수 있다. 테스트 단계에서, 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 특징 벡터 추출부; 상기 음성 데이터의 잔향 환경에 따라 잔향 환경 확률을 추정하는 잔향 환경 추정부; 및 추정된 상기 잔향 환경 확률을 기반으로 가 중치 평균 방식을 이용하여, 미리 학습된 잔향 환경에서의 복수 개의 심화 신경망들을 앙상블로 결합시켜 앙상 블 음원 방향 추정 모델을 생성하고, 상기 앙상블 음원 방향 추정 모델을 기반으로 음원 방향을 추정하는 앙상 블 음원 방향 추정 모델링부를 더 포함할 수 있다."}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예들에 따르면 다양한 잔향 환경에 대한 앙상블 심화 신경망 모델을 구성하여 다양한 잔향 환경에서도 강인 한 음원 방향 추정할 수 있다. 실시예들에 따르면 각 잔향 환경별로 심화 신경망들을 독립적으로 생성한 뒤, 생성한 여러 개의 심화 신경망들 을 앙상블로 구성하여 각 잔향 환경에 대한 정보들을 활용함으로써, 앙상블 모델을 통해 기존 단일 심화 신경망 기반의 음원 방향 추정 기술에 비해 더 우수한 음원 방향 추정 성능을 갖는 잔향 환경에 강인한 음원 방향 추정 을 위한 심화 신경망 기반의 앙상블 음원 방향 추정 방법 및 장치를 제공할 수 있다."}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 실시예들을 설명한다. 그러나, 기술되는 실시예들은 여러 가지 다른 형태로 변 형될 수 있으며, 실시예들의 범위가 이하 설명되는 실시예들에 의하여 한정되는 것은 아니다. 또한, 여러 실시"}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예들은 당해 기술분야에서 평균적인 지식을 가진 자에게 실시예들을 더욱 완전하게 설명하기 위해서 제공되는 것이다. 도면에서 요소들의 형상 및 크기 등은 보다 명확한 설명을 위해 과장될 수 있다. 아래의 실시예들은 다양한 잔향 환경에 강인한 음원 방향 추정 기술에 관한 것으로, 다양한 잔향 환경에 대한 앙상블 심화 신경망을 구성하여 다채널 마이크 구조에서의 음원 방향(Direction Of Arrival, DOA)을 추정하는 기술을 제시한다. 기존의 단일 심화 신경망 기반의 음원 방향 추정 기법은 실제 다양한 잔향 환경에서 적합한 잔향 환경에 대한 음원 방향 추정 모델을 선택하지 못하여 성능이 떨어지는 문제점이 존재한다. 이러한 기존의 단일 심화 신경망 기반의 음원 방향 추정 기법을 사용하여 다양한 잔향 환경에서 음원 방향을 추정할 경우, 각각 잔향 환경에 적 합한 음원 방향 추정 모델을 선택하지 못하여 정교한 음원 방향을 추정할 수가 없다. 본 실시예들은 이러한 문제점을 극복하고자 다양한 잔향 환경에 대한 앙상블 심화 신경망 모델을 구성하여 다양 한 잔향 환경에서도 강인한 음원 방향 추정 기술을 제안한다. 앙상블 음원 방향 추정 모델은 학습 단계에서 서로 다른 잔향 시간(Reverberation Time 60, RT60)에 대해 여러 개의 심화 신경망을 생성한다. 이 때, 실내에서 음원을 발생시킨 후 갑자기 정지시켰을 때 소리는 점차 감쇠하 여 완만하게 사라지는데, 최고의 음압 레벨에서 60dB(100만분의 1 크기) 아래로 음압이 떨어질 때까지 걸리는 시간을 잔향 시간(RT60)이라고 할 수 있다. 그리고 테스트 단계에서 앙상블 심화 신경망들은 잔향 시간 추정을 통해 결정된 확률에 의해 가중치 평균 방식을 통하여 결합된다. 실시예들에 따르면 실제 잔향 환경을 추정하여 다양한 잔향 환경에 적합한 음원 방향 추정 모델을 선택할 수 있다. 이러한 실시예들은 다양한 잔향 환경에서 객관적인 성능 평가 기준을 통해 음원 방향 추정의 성능을 평가할 수 있다. 다양한 잔향 환경에서 실험을 진행한 결과, 제시된 잔향 환경별 앙상블 심화 신경망을 이용한 음원 방향 추정 기술이 기존 단일 심화 신경망 기반의 음원 방향 추정 기술에 비하여 모든 잔향 환경에서 우수한 성능을 보이는 것을 확인할 수 있다. 이에, 실시예들에서는 기존의 단일 심화 신경망 기반의 음원 방향 추정 기술에 비해 다양한 잔향 환경에서 강인한 앙상블 심화 신경망 기반의 음원 방향 추정 기술을 제공할 수 있다. 도 1은 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 장치를 설명하기 위한 도면이다. 도 1을 참조하면, 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 장치는 제어부를 포함하여 구성될 수 있다. 실시예에 따라 심화 신경망 기반의 앙상블 음원 방향 추정 장치는 입력부 및 메모리를 더 포함하여 구성될 수 있다. 입력부는 제어부에 대하여 소정의 입력 데이터를 전송하는 부분으로서, 예를 들어, 마이크로폰 (microphone) 등과 같이 소리를 전기 신호로 변환하는 입력 수단을 포함할 수 있다. 예를 들어, 입력부에 제공되는 음성 데이터(즉, 주변 잡음에 의해 오염된 음성 신호)는 제어부에 제공될 수 있다. 제어부는 입력부와 전기적으로 연결될 수 있다. 이러한 제어부는 학습 과정을 통하여 최적화된 심화 신경망 기반의 앙상블 음원 방향 추정을 수행하는 부분으로, 소정의 연산 속도를 갖는 연산 유닛을 포함할 수 있다. 예를 들어, 제어부는 CPU(central processing unit), GPU(graphical processing unit) 등과 같 은 연산 유닛을 포함할 수 있다. 또한, 심화 신경망 기반의 앙상블 음원 방향 추정 장치는 제어부의 소정의 프로세스에 필요한 데이터를 저 장하기 위한 메모리를 더 포함할 수 있다. 실시예들에서는 각 잔향 환경별로 심화 신경망들을 독립적으로 생성한 뒤, 생성한 여러 개의 심화 신경망들을 앙상블로 구성하여 각 잔향 환경에 대한 정보들을 활용함으로써 문제를 해결하고자 한다. 문제 해결을 위한 구 체적인 수단은 다음과 같다. 잔향 시간에 따라 잔향 환경이 구별이 가능하기에 잔향 시간에 따른 각각의 음원 방향 추정을 위한 심화 신경망 들을 학습을 통해 생성할 수 있다. 생성한 각각의 심화 신경망들을 잔향 시간 추정을 통해 구해진 확률 값들을 이용하여 가중치 평균 방식으로 앙상블로 결합할 수 있다. 이렇게 얻어진 앙상블 모델을 통해 기존 단일 심화 신경망 기반의 음원 방향 추정 기술에 비해 더 우수한 음원 방향 추정 성능을 낼 수 있다. 아래에서는 일 실시예에 따른 잔향 환경에 강인한 음원 방향 추정을 위한 심화 신경망 기반의 앙상블 음원 방향 추정 방법 및 장치에 대해 하나의 예를 들어 보다 구체적으로 설명하기로 한다. 도 2는 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 장치를 개략적으로 나타내는 블록도이다. 도 2를 참조하면, 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 장치 다음과 같이 학습 단 계 및 테스트 단계로 구분될 수 있다. 먼저, 학습 단계에서 잔향이 섞여있는 대용량의 음성 데이터를 준비한다. 해당 음성 데이터에 서 특징 벡터를 추출할 수 있다. 예를 들어 특징 벡터는 GCC-PHAT 기법을 통해서 추출할 수 있다. 추출된 특 징 벡터들을 잔향 환경별로 분류할 수 있다. 잔향 환경별로 분류된 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 독립적인 여러 개의 음원 방향 추정을 위한 심화 신경망을 생성할 수 있다. 이 과정을 거치면 앙상블 심화 신경망을 구성하기 위한 각 잔향별 음원 방향 추정을 위한 심화 신경망들이 준비가 된다. 그리고, 테스트 단계에서 준비된 테스트 잔향 음성 데이터로부터 특징 벡터들을 추출한 뒤, 각각의 테스트 음성 데이터들의 잔향 환경 확률을 추정할 수 있다. 추정된 잔향 환경 확률 값들을 기반으로 가중 치 평균 방식을 이용하여 학습 단계에서 생성해 놓은 각각의 독립적인 심화 신경망들을 앙상블로 결합시킬 수 있다. 그리고 결합된 앙상블 심화 신경망 기반의 음원 방향 추정 모델을 기반으로 음원 방향 각도를 추정할 수 있다. 실시예들에 따른 앙상블 심화 신경망 기반의 음원 방향 추정 모델을 적용할 경우, 기존의 단일 심화 신경망 기 반의 음원 방향 추정 기술보다 성능 측면에서 더 우수함을 확인할 수 있다. 아래에서 각각의 학습 단계 및 테스트 단계에 대해 보다 구체적으로 설명한다. 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 장치는 특징 벡터 추출부, 잔향 환경 확률 추정부 및 앙상블 음원 방향 추정 모델링부를 포함하여 이루어질 수 있다. 이는, 앞에서 설명한 테 스트 단계가 될 수 있다. 특징 벡터 추출부는 잔향 환경의 음성 데이터에서 특징 벡터를 추출할 수 있다. 예컨대, 특징 벡터 추출 부는 입력된 음성 데이터로부터 GCC-PHAT(Generalized Cross Correlation-Phase Transform)를 통해 특징 벡터를 추출할 수 있다. 잔향 환경 확률 추정부는 음성 데이터의 잔향 환경에 따라 잔향 환경 확률을 추정할 수 있다. 잔향 환경 확률 추정부는 음성 데이터의 잔향 환경은 잔향 시간의 추정을 통해 잔향 환경 확률 값들을 산 정할 수 있다. 앙상블 음원 방향 추정 모델링부는 추정된 잔향 환경 확률을 기반으로 가중치 평균 방식을 이용하여, 미리 학습된 잔향 환경에서의 복수 개의 심화 신경망들을 앙상블로 결합시켜 앙상블 음원 방향 추정 모델을 생성할 수 있다. 그리고, 앙상블 음원 방향 추정 모델링부는 앙상블 음원 방향 추정 모델을 기반으로 음원 방향 을 추정할 수 있다. 여기서, 미리 학습된 잔향 환경에서의 복수 개의 심화 신경망들은 잔향 환경에 따라 구별하기 위해 서로 다른 잔향 시간에 대해 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들이 학습을 통해 생성될 수 있다. 한편, 학습 단계에서, 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 장치는 학습 단 계 특징 벡터 추출부, 특징 벡터 분류부 및 음원 방향 추정 심화 신경망을 포함하여 이루어질 수 있다. 이러한 학습 단계는 앞에서 설명한 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추 정 장치에 포함되거나 독립적으로 구성될 수 있다. 학습 단계에서, 학습 단계 특징 벡터 추출부는 잔향 환경의 음성 데이터에서 특징 벡터를 추출 할 수 있다. 여기서, 학습 단계 특징 벡터 추출부는 테스트 단계의 특징 벡터 추출부에 포함되거나 별도로 구성될 수 있다. 학습 단계에서, 특징 벡터 분류부는 추출된 특징 벡터들을 잔향 환경별로 분류할 수 있다. 특히, 특 징 벡터 분류부는 잔향 환경에 따라 구별하기 위해 특징 벡터들을 서로 다른 잔향 시간에 따라 분류할 수 있다. 학습 단계에서, 음원 방향 추정 심화 신경망은 잔향 환경별로 분류된 특징 벡터들을 입력 특징 벡터 로 사용하여 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들을 생성할 수 있다. 여기서, 복수 개의 음 원 방향 추정을 위한 심화 신경망들을 앙상블로 결합시켜 앙상블 음원 방향 추정 모델을 생성할 수 있다. 이러한 음원 방향 추정 심화 신경망은 서로 다른 잔향 시간 특징 벡터들을 입력 특징 벡터로 사용하여 각 각의 복수 개의 음원 방향 추정을 위한 심화 신경망들을 학습을 통해 생성할 수 있다. 도 3은 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 방법의 학습 단계를 나타내는 흐름도이다. 도 3을 참조하면, 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 방법은, 학습 단계에서 잔향 환 경의 음성 데이터에서 특징 벡터를 추출하는 단계, 추출된 특징 벡터들을 잔향 환경별로 분류하는 단계 , 및 잔향 환경별로 분류된 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들을 생성하는 단계를 포함하여 이루어질 수 있다. 여기서, 복수 개의 음원 방향 추정을 위한 심화 신경망들을 앙상블로 결합시켜 음원 방향을 추정할 수 있다. 다른 실시예에 따르면, 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 방법은 테스트 단계를 더 포함할 수 있으며, 보다 구체적으로, 테스트 단계에서 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 단계, 음성 데이터의 잔향 환경에 따라 잔향 환경 확률을 추정하는 단계, 추정된 잔향 환경 확률을 기반으로 가 중치 평균 방식을 이용하여, 미리 학습된 잔향 환경에서의 복수 개의 심화 신경망들을 앙상블로 결합시켜 앙상 블 음원 방향 추정 모델을 생성하는 단계, 및 앙상블 음원 방향 추정 모델을 기반으로 음원 방향을 추정하는 단 계를 더 포함할 수 있다. 이러한 테스트 단계는 도 4를 참조하여 보다 구체적으로 설명하기로 한다. 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 방법의 학습 단계는 도 2에서 설명한 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 장치를 이용하여 보다 구체적으로 설명할 수 있다. 학습 단계 에서, 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 장치는 학습 단계 특징 벡터 추출부, 특징 벡터 분류부 및 음원 방향 추정 심화 신경망을 포함하여 이루어질 수 있다. 또한, 실시예에 따라 특징 벡터 추 출부, 잔향 환경 확률 추정부 및 앙상블 음원 방향 추정 모델링부를 더 포함하여 이루어질 수 있으며, 이는 앞 에서 설명한 테스트 단계에 해당될 수 있다. 단계의 학습 단계에서, 학습 단계 특징 벡터 추출부는 잔향 환경의 음성 데이터에서 특징 벡터를 추출할 수 있다. 여기서, 학습 단계 특징 벡터 추출부는 테스트 단계의 특징 벡터 추출부에 포함되거나 별도로 구성될 수 있다. 예컨대, 학습 단계 특징 벡터 추출부는 입력된 음성 데이터로부터 GCC-PHAT(Generalized Cross Correlation- Phase Transform)를 통해 특징 벡터를 추출할 수 있다. 단계에서, 특징 벡터 분류부는 추출된 특징 벡터들을 잔향 환경별로 분류할 수 있다. 특히, 특징 벡터 분 류부는 잔향 환경에 따라 구별하기 위해 특징 벡터들을 서로 다른 잔향 시간에 따라 분류할 수 있다. 단계에서, 음원 방향 추정 심화 신경망은 잔향 환경별로 분류된 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들을 생성할 수 있다. 여기서, 복수 개의 음원 방향 추정 을 위한 심화 신경망들을 앙상블로 결합시켜 음원 방향을 추정할 수 있다. 이러한 음원 방향 추정 심화 신경망은 서로 다른 잔향 시간 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들을 학습을 통해 생성할 수 있다. 도 4는 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 방법의 테스트 단계를 나타내는 흐름도이 다. 도 4를 참조하면, 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 방법은, 잔향 환경의 음성 데이 터에서 특징 벡터를 추출하는 단계, 음성 데이터의 잔향 환경에 따라 잔향 환경 확률을 추정하는 단계 , 추정된 잔향 환경 확률을 기반으로 가중치 평균 방식을 이용하여, 미리 학습된 잔향 환경에서의 복수 개 의 심화 신경망들을 앙상블로 결합시켜 앙상블 음원 방향 추정 모델을 생성하는 단계, 및 앙상블 음원 방 향 추정 모델을 기반으로 음원 방향을 추정하는 단계를 포함하여 이루어질 수 있다. 다른 실시예에 따르면, 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 방법은 학습 단계를 더 포 함할 수 있으며, 보다 구체적으로, 학습 단계에서 잔향 환경의 음성 데이터에서 특징 벡터를 추출하는 단계, 추 출된 특징 벡터들을 잔향 환경별로 분류하는 단계, 및 잔향 환경별로 분류된 특징 벡터들을 입력 특징 벡터로 사용하여 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들을 생성하는 단계를 더 포함할 수 있다. 여기 서, 미리 학습된 잔향 환경에서의 복수 개의 심화 신경망들을 앙상블로 결합시켜 앙상블 음원 방향 추정 모델을 생성하는 단계는 복수 개의 음원 방향 추정을 위한 심화 신경망들을 앙상블로 결합시켜 앙상블 음원 방향 추정 모델을 생성할 수 있다. 이러한 학습 단계는 도 3에서 설명하였으므로 중복되는 설명은 생략하기로 한다. 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 방법의 테스트 단계는 도 2에서 설명한 일 실시예 에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 장치를 이용하여 보다 구체적으로 설명할 수 있다. 테스트 단계에서, 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 장치는 특징 벡터 추출부, 잔향 환경 확률 추정부 및 앙상블 음원 방향 추정 모델링부를 더 포함하여 이루어질 수 있다. 실시예에 따라 학습 단계를 더 포함할 수 있으며, 보다 구체적으로 학습 단계 특징 벡터 추출부, 특징 벡터 분류부 및 음원 방향 추정 심화 신경망을 더 포함하여 이루어질 수 있다. 단계에서, 특징 벡터 추출부는 잔향 환경의 음성 데이터에서 특징 벡터를 추출할 수 있다. 예컨대, 특징 벡터 추출부는 입력된 음성 데이터로부터 GCC-PHAT(Generalized Cross Correlation-Phase Transform)를 통해 특징 벡터를 추출할 수 있다. 단계에서, 잔향 환경 확률 추정부는 음성 데이터의 잔향 환경에 따라 잔향 환경 확률을 추정할 수 있다. 특히, 잔향 환경 확률 추정부는 음성 데이터의 잔향 환경은 잔향 시간의 추정을 통해 잔향 환경 확률 값들을 산 정할 수 있다. 단계에서, 앙상블 음원 방향 추정 모델링부는 추정된 잔향 환경 확률을 기반으로 가중치 평균 방식을 이용 하여, 미리 학습된 잔향 환경에서의 복수 개의 심화 신경망들을 앙상블로 결합시켜 앙상블 음원 방향 추정 모델 을 생성할 수 있다. 여기서, 미리 학습된 잔향 환경에서의 복수 개의 심화 신경망들은 잔향 환경에 따라 구별 하기 위해 서로 다른 잔향 시간에 대해 각각의 복수 개의 음원 방향 추정을 위한 심화 신경망들이 학습을 통해 생성될 수 있다. 단계에서, 앙상블 음원 방향 추정 모델링부는 앙상블 음원 방향 추정 모델을 기반으로 음원 방향을 추정할 수 있다. 즉, 앙상블 음원 방향 추정 모델을 기반으로 음원 방향의 각도를 추정할 수 있다. 아래에서 특징 벡터 추출 및 앙상블 음원 방향 추정 모델의 구성에 대해 하나의 예를 들어 보다 구체적으로 설 명한다. 특징 벡터 추출 학습 단계 특징 벡터 추출부는 다채널 마이크 기반으로 얻어진 입력 음성 신호들에 대해서 특징 벡터를 추 출할 수 있다. 여기서, 학습 단계 특징 벡터 추출부는 테스트 단계의 특징 벡터 추출부에 포함되거나 독 립적으로 구성될 수 있으며, 독립적으로 구성되는 경우 테스트 단계의 특징 벡터 추출부도 아래와 같은 방법에 의해 특징 벡터를 추출할 수 있다. 예컨대, 학습 단계 특징 벡터 추출부는 입력된 음성 신호들로부터 추출할 특징 벡터는 GCC- PHAT(Generalized Cross Correlation-Phase Transform)이라는 특징 벡터가 될 수 있다. 한편, 입력된 음성 신호들로부터 특징 벡터를 추출하기 위해 GCC(Generalized Cross Correlation) 또는 감쇠율의 분산 값(Negative- side variance, NSV) 등이 사용될 수도 있다. 학습 단계 특징 벡터 추출부는 마이크 입력으로 들어오는 두 개의 입력 신호를 각각 x1(t)와 x2(t)라 할 경 우 특징 벡터 GCC-PHAT는 다음 식과 같이 정의될 수 있다. 수학식 1"}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, G12(f)는 두 개의 입력 신호에 대한 GCC-PHAT 값이고, X1(f)와 X2(f)는 각각 입력으로 들어오는 입력 신 호들의 푸리에 변환 값이며, *는 공액(conjugate) 성분을 나타내는 표시이다. 주파수 영역에서 구해진 GCC-PHAT 성분에 역 푸리에 변환을 시켜줌으로써, 다음 식과 같이 시간 영역에서의 입 력 신호들에 대한 상호상관계수(Cross-correlation coefficient) 정보를 알 수 있다. 수학식 2"}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 는 상호상관계수를 나타낸다. 상기의 [수학식 2]로부터 구해진 시간 영역에서의 입력 신호들에 대한 상호상관계수 값이 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 알고리즘에서의 입력 특징 벡터 성분으로 사용될 수 있다. 앙상블 심화 신경망 모델 구성 심화 신경망 모델의 앙상블을 구성하기 위해 다양한 잔향 환경 각각의 특정한 잔향 환경을 나타내는 서로 다른 음원 방향 추정을 위한 심화 신경망 모델을 구성할 수 있다. 각 잔향 환경에 따른 음원 방향 추정을 위한 심화 신경망 모델은 다음과 같이 구성할 수 있다. 예컨대, 입력 특징 벡터의 경우 GCC-PHAT 벡터를 사용할 수 있다. 그리고 입력 음성 신호들을 획득하기 위해 다채널 마이크 가 사용될 수 있으며, 예를 들어 4 채널 구조의 마이크를 사용할 수 있다. 여기에서는, 입력 특징 벡터로써 GCC-PHAT 벡터를 사용하고, 다채널 마이크로써 4 채널 구조의 마이크를 하나의 예로써 설명한다. 4 채널 구조의 마이크 구조에서는 마이크 두 쌍마다 GCC-PHAT 값이 구해지므로 총 = 6 가지의 조합이 나올 수 있다. 또한, GCC-PHAT 특징 벡터를 사용할 때에 두 개의 마이크 입력으로 들어오는 신 호들의 최대 음원 도달 시간 차이 값을 고려해 19 개의 상호상관계수만을 사용할 수 있다. 특히, 음원 도달 시 간 차이(Time Delay Of Arrival, TDOA) 값이 0이 되는 지점을 중심 프레임으로 생각하고 주변의 18 개의 프레임 값을 상호상관계수로 사용할 수 있다. 따라서 4 채널 마이크 구조에서 마이크 두 쌍마다 GCC-PHAT 값이 구해 져 6 가지의 조합이 구해지며, GCC-PHAT 특징 벡터를 사용할 때 두 개의 마이크 입력으로 들어오는 신호들의 최 대 음원 도달 시간 차이 값을 고려해 19 개의 상호상관계수만을 사용할 수 있으므로, 이를 이용하여 입력 특징 벡터로 사용되는 GCC-PHAT 벡터의 총 개수를 구할 수 있다. 즉, 입력 특징 벡터로 사용되는 GCC-PHAT 벡터의 총 개수는 6 X 19 = 114 개의 입력 특징 벡터를 사용하게 된다. 한편, 입력 특징 벡터로 사용되는 GCC-PHAT 벡 터의 총 개수는 6 X 18 = 108 개의 입력 특징 벡터를 사용할 수도 있다. 이는, 음원 도달 시간 차이(TDOA) 값이 0이 되는 지점을 중심 프레임으로 생각하고 주변의 18 개의 프레임 값을 상호상관계수로 사용하는 경우이다. 심화 신경망 구성 시, 음원 방향 추정 심화 신경망에서, 입력 층에는 상술한 바와 같이 획득된 114 개의 입력 특징 벡터를 이용하여 114 차원 특징 벡터를 사용할 수 있다. 타겟 층에서는 일정한 각도 간격으로 학습 을 시킴으로써 72 개의 타겟이 사용되었고, 가속 파라미터는 0.9, 학습률은 0.0001로 설정하였다. 또한 은닉층 (hidden layer)은 총 7 개로 구성되며, 각각의 은닉층은 2048 유닛을 가지고 있다. 앙상블 음원 방향 추정 모델링부는 이렇게 각각 구성된 각각의 심화 신경망들을 앙상블 결합할 수 있다. 여기서, 잔향 환경 확률 추정부는 음성 데이터의 잔향 환경에 따라 잔향 환경 확률을 추정할 수 있다. 예 를 들어, 음원 방향 추정 심화 신경망에서, N 개의 데이터 세트로 N 개의 음원 방향 추정을 위한 심화 신 경망 모델을 생성한다고 가정하면, 잔향 환경 확률 추정부에서의 n 번째 음원 방향 추정을 위한 심화 신경 망 모델에서의 출력 확률은 로 정의될 수 있다. 여기서, x 는 입력 특징 벡터이고, k 는 은닉 마르코프 모델 상태를 나타낸다. 앙상블 음원 방향 추정 모델링부는 앙상블 음원 방향 추정 모델(Ensemble DOA Model, EDM)의 최종 상태의 사후 확률 은 다양한 잔향 환경에 대한 서로 다른 심화 신경망 중 가장 확률이 높은 두 개의 심화 신경망 의 출력에 가중치를 결합하여 계산될 수 있으며, 다음 식과 같이 표현될 수 있다. 수학식 3"}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, 는 각각 심화 신경망 n1 및 n2의 가중치를 나타내며, 는 각각 심화 신 경망 n1 및 n2의 사후 확률을 의미하고, 가중치는 잔향 시간 추정 단계에서 얻어지는 확률의 연산으로 결정된다. 선택된 잔향 환경에서의 심화 신경망 n1 및 n2의 확률을 각각 라고 하면 가중치 는 다음 식과 같이 결정될 수 있다. 수학식 4"}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 5"}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "심화 신경망 모델의 가중치와 사후 확률은 [수학식 3]과 결합될 수 있다. 이와 같이 잔향 환경별 앙상블 음원 방향 추정 모델들의 확률적 결합을 통해 단일 심화 신경망 기반의 음원 방 향 추정 기법보다 적합한 잔향 환경 모델의 정보를 활용할 수 있다. 이렇게 학습된 앙상블 심화 신경망을 기반으로 테스트 시에는 총 31 개의 잔향 환경에 대해서 음원 방향 추정 성능을 절대적 오차 평균(Mean Absolute Estimated Error, MAEE)으로 평가할 수 있다. 기존의 단일 심화 신경망 기반의 음원 방향 추정 기술과 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방 향 추정 기술을 절대적 오차 평균(MAEE)이라는 객관적인 성능 평가 방법을 이용하여 평가하였다. 표 1은 단일 심화 신경망 모델(Single DNN Model)과 앙상블 심화 신경망 모델 (Ensemble DNNs Model)의 객관적 평가 방법(MAEE)의 비교 예를 나타낸다. 여기서, 단일 심화 신경망 모델은 기존의 단일 심화 신경망 기반의 음 원 방향 추정 기술을 나타내며, 앙상블 심화 신경망 모델(Ensemble DNNs Model)은 상술한 일 실시예에 따른 심 화 신경망 기반의 앙상블 음원 방향 추정 기술을 나타낸다. 표 1"}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "절대적 오차 평균(MAEE)의 관점에서 비교한 결과, 모든 잔향 시간(RT60)에 대해서 일 실시예에 따른 심화 신경 망 기반의 앙상블 음원 방향 추정 기술이 기존의 단일 심화 신경망 기반의 음원 방향 추정 기술보다 우수한 성 능을 보였다. 여기서, 절대적 오차 평균(MAEE)은 값이 작을수록 오차율이 적으며 성능이 우수하다고 볼 수 있 다. 실시예들에 따르면 앙상블 심화 신경망 기반의 음원 방향 추정 기술을 사용하여, 다양한 잔향 환경에서도 강인 한 음원 방향 추정을 할 수 있다. 다양한 잔향에 적합한 음원 방향 추정 모델을 적용하여 기존의 단일 심화 신 경망 기반의 음원 방향 추정 기술보다 실제 다양한 잔향 환경에서 더 안정적이고 정교한 수준의 음원 방향 추정 을 가능하게 한다. 한편, IoT(Internet of Things) 기기 및 스마트 스피커 기기들 그리고 스마트 로봇 분야 등에서 원거리 음성인 식과 함께 실제 실내 환경에서의 원거리 음원 방향 추정 기술이 이슈화 되고 있다. 실제 잔향 환경에서의 음원 방향 추정 기술은 원거리 음성인식 환경에서 음성 인식의 정확도를 높이는데 도움을 준다. 또한, IoT 기기 및 스마트 로봇 분야에서도 음원 방향 추정을 통해 기기 및 로봇들이 화자의 방향을 인지할 수 있는 스마트성을 지 닐 수 있다. 실시예들에 따른 기술은 인공지능 스피커, 스마트 로봇, 스마트 IoT 기기 등에 적용 가능하다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 컨트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPA(field programmable array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2018-0030080", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2018-0030080", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 장치를 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 장치를 개략적으로 나타내는 블록도이다. 도 3은 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 방법의 학습 단계를 나타내는 흐름도이다. 도 4는 일 실시예에 따른 심화 신경망 기반의 앙상블 음원 방향 추정 방법의 테스트 단계를 나타내는 흐름도이다."}
