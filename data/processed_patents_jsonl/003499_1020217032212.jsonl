{"patent_id": "10-2021-7032212", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0128491", "출원번호": "10-2021-7032212", "발명의 명칭": "위험 주행 행위 식별 방법, 장치, 전자 설비 및 저장매체", "출원인": "베이징 바이두 넷컴 사이언스 앤 테크놀로지 코.,", "발명자": "왕 커야오"}}
{"patent_id": "10-2021-7032212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "위험 주행 행위 식별 방법으로서,식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모델에 입력하고, 상기 사람 얼굴 검출 모델을 통해 상기 식별될 이미지에 대해 사람 얼굴 검출을 수행하여, 상기 식별될 이미지의 사람 얼굴 검출 프레임을 획득하는단계;상기 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력하고, 상기 위험 주행 행위 식별 모델을 통해 상기 사람 얼굴 검출 프레임에 대해 위험 주행 행위 식별을 수행하여, 상기 사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득하는 단계를 포함하는 것을 특징으로 하는 위험 주행 행위 식별 방법."}
{"patent_id": "10-2021-7032212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력하는 단계 이전에,상기 사람 얼굴 검출 프레임에 대해 이미지 전처리를 수행하여, 이미지 전처리된 사람 얼굴 검출 프레임을 획득하며; 상기 이미지 전처리된 사람 얼굴 검출 프레임을 상기 위험 주행 행위 식별 모델에 입력하는 단계를 더 포함하는 것을 특징으로 하는 위험 주행 행위 식별 방법."}
{"patent_id": "10-2021-7032212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 사람 얼굴 검출 프레임에 대해 이미지 전처리를 수행하여, 이미지 전처리된 사람 얼굴 검출 프레임을 획득하는 단계는,상기 사람 얼굴 검출 프레임을 확대 처리하여, 확대 처리된 사람 얼굴 검출 프레임을 획득하는 단계;상기 확대 처리된 사람 얼굴 검출 프레임을 클리핑 처리하여, 클리핑 처리된 사람 얼굴 검출 프레임을 획득하는단계;상기 클리핑 처리된 사람 얼굴 검출 프레임을 정규화 처리하여, 정규화 처리된 사람 얼굴 검출 프레임을 획득하며; 상기 정규화된 사람 얼굴 검출 프레임을 상기 이미지 전처리된 사람 얼굴 검출 프레임으로 하는 단계를 포함하는 것을 특징으로 하는 위험 주행 행위 식별 방법."}
{"patent_id": "10-2021-7032212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 사람 얼굴 검출 모델을 통해 상기 식별될 이미지에 대해 사람 얼굴 검출을 수행하여, 상기 식별될 이미지의 사람 얼굴 검출 프레임을 획득하는 단계는,상기 사람 얼굴 검출 모델의 첫 번째 계층의 콘볼루션 신경망을 현재 계층의 콘볼루션 신경망으로 하고; 상기식별될 이미지를 상기 현재 계층의 콘볼루션 신경망의 검출 대상으로 하는 단계;상기 현재 계층의 콘볼루션 신경망을 통해 상기 현재 계층의 콘볼루션 신경망의 검출 대상에 대해 이미지 다운샘플링을 수행하여, 상기 현재 계층의 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추출 결과를 획득하고; 상기현재 계층의 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추출 결과를 상기 현재 계층의 콘볼루션 신경망의 다음 계층의 콘볼루션 신경망의 검출 대상으로 하고; 상기 다음 계층의 콘볼루션 신경망을 상기 현재 계층의 콘볼루션 신경망으로 하여, 상기 사람 얼굴 검출 모델의 N 번째 계층의 콘볼루션 신경망의 검출 대상에서 N 번째 계공개특허 10-2021-0128491-3-층의 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추출 결과를 추출할 때까지 상기 조작을 반복하여 수행하는단계로서, N은 1보다 큰 자연수인, 상기 조작을 반복하여 수행하는 단계;상기 첫 번째 계층의 콘볼루션 신경망 내지 상기 N 번째 계층의 콘볼루션 신경망 중의 각 계층의 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추출 결과에 기반하여, 상기 식별될 이미지의 사람 얼굴 검출 프레임을 획득하는단계를 포함하는 것을 특징으로 하는 위험 주행 행위 식별 방법."}
{"patent_id": "10-2021-7032212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력하고, 상기 위험 주행 행위 식별 모델을 통해 상기 사람 얼굴 검출 프레임에 대해 위험 주행 행위 식별을 수행하여, 상기 사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득하는 단계는,상기 사람 얼굴 검출 프레임을 상기 위험 주행 행위 식별 모델 중의 콘볼루션 계층에 입력하고, 상기 콘볼루션계층을 통해 상기 사람 얼굴 검출 프레임에 대해 콘볼루션 연산을 수행하여, 상기 콘볼루션 계층에 대응되는 사람 얼굴 특징 추출 결과를 획득하는 단계;상기 콘볼루션 계층에 대응되는 사람 얼굴 특징 추출 결과를 상기 위험 주행 행위 식별 모델 중의 풀링층에 입력하고, 상기 풀링층을 통해 상기 콘볼루션 계층에 대응되는 사람 얼굴 검출 프레임에 대해 풀링 연산을 수행하여, 상기 풀링층에 대응되는 사람 얼굴 특징 추출 결과를 획득하는 단계;상기 풀링층에 대응되는 사람 얼굴 특징 추출 결과를 상기 위험 주행 행위 모델 중의 완전연결층에 입력하고,상기 완전연결층을 통해 상기 풀링층에 대응되는 사람 얼굴 특징 추출 결과에 대해 분류 연산을 수행하여, 상기사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득하는 단계를 포함하는 것을 특징으로 하는 위험 주행 행위 식별 방법."}
{"patent_id": "10-2021-7032212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모델에 입력하는 단계 이전에,사전에 획득한 첫 번째 사람 얼굴 이미지 샘플을 현재 사람 얼굴 이미지 샘플로 하는 단계;상기 사람 얼굴 검출 모델이 상기 사람 얼굴 검출 모델에 대응되는 미리 설정된 수렴 조건을 충족하지 못하는경우, 상기 현재 사람 얼굴 이미지 샘플을 상기 사람 얼굴 검출 모델에 입력하고, 상기 현재 사람 얼굴 이미지샘플을 사용하여 상기 사람 얼굴 검출 모델에 대해 트레이닝을 수행하며; 상기 현재 사람 얼굴 이미지 샘플의다음 사람 얼굴 이미지 샘플을 상기 현재 사람 얼굴 이미지 샘플로 하여, 상기 사람 얼굴 검출 모델이 상기 사람 얼굴 검출 모델에 대응되는 수렴 조건을 충족할 때까지 상기 조작을 반복하여 수행하는 단계를 더 포함하는 것을 특징으로 하는 위험 주행 행위 식별 방법."}
{"patent_id": "10-2021-7032212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력하는 단계 이전에,사전에 획득한 첫 번째 사람 얼굴 검출 프레임 샘플을 현재 사람 얼굴 검출 프레임 샘플로 하는 단계;상기 위험 주행 행위 식별 모델이 상기 위험 주행 행위 식별 모델에 대응되는 미리 설정된 수렴 조건을 충족하지 못하는 경우, 상기 현재 사람 얼굴 검출 프레임 샘플을 상기 위험 주행 행위 식별 모델에 입력하고, 상기 현재 사람 얼굴 검출 프레임 샘플을 사용하여 상기 위험 주행 행위 식별 모델에 대해 트레이닝을 수행하며; 상기현재 사람 얼굴 검출 프레임 샘플의 다음 사람 얼굴 검출 프레임 샘플을 상기 현재 사람 얼굴 검출 프레임 샘플로 하여, 상기 위험 주행 행위 식별 모델이 상기 위험 주행 행위 식별 모델에 대응되는 수렴 조건을 충족할 때까지 상기 조작을 반복하여 수행하는 단계공개특허 10-2021-0128491-4-를 더 포함하는 것을 특징으로 하는 위험 주행 행위 식별 방법."}
{"patent_id": "10-2021-7032212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "위험 주행 행위 식별 장치로서,사람 얼굴 검출 모듈 및 행위 식별 모듈을 포함하되;상기 사람 얼굴 검출 모듈은 식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모델에 입력하고, 상기 사람 얼굴 검출 모델을 통해 상기 식별될 이미지에 대해 사람 얼굴 검출을 수행하여, 상기 식별될 이미지의 사람 얼굴검출 프레임을 획득하며;상기 행위 식별 모듈은 상기 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력하고,상기 위험 주행 행위 식별 모델을 통해 상기 사람 얼굴 검출 프레임에 대해 위험 주행 행위 식별을 수행하여,상기 사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득하는 것을 특징으로 하는 위험 주행행위 식별 장치."}
{"patent_id": "10-2021-7032212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 사람 얼굴 검출 프레임에 대해 이미지 전처리를 수행하여, 이미지 전처리된 사람 얼굴 검출 프레임을 획득하며; 상기 이미지 전처리된 사람 얼굴 검출 프레임을 상기 위험 주행 행위 식별 모델에 입력하는 전처리 모듈을 더 포함하는 것을 특징으로 하는 위험 주행 행위 식별 장치."}
{"patent_id": "10-2021-7032212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "9항에 있어서,상기 전처리 모듈은 확대 서브 모듈, 클리핑 서브 모듈 및 정규화 서브 모듈을 포함하되;상기 확대 서브 모듈은 상기 사람 얼굴 검출 프레임을 확대 처리하여, 확대 처리된 사람 얼굴 검출 프레임을 획득하고;상기 클리핑 서브 모듈은 상기 확대 처리된 사람 얼굴 검출 프레임을 클리핑 처리하여, 클리핑 처리된 사람 얼굴 검출 프레임을 획득하며;상기 정규화 서브 모듈은 상기 클리핑 처리된 사람 얼굴 검출 프레임을 정규화 처리하여, 정규화 처리된 사람얼굴 검출 프레임을 획득하며; 상기 정규화된 사람 얼굴 검출 프레임을 상기 이미지 전처리된 사람 얼굴 검출프레임으로 하는 것을 특징으로 하는 위험 주행 행위 식별 장치."}
{"patent_id": "10-2021-7032212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 사람 얼굴 검출 모듈은 구체적으로 상기 사람 얼굴 검출 모델의 첫 번째 계층의 콘볼루션 신경망을 현재계층의 콘볼루션 신경망으로 하고; 상기 식별될 이미지를 상기 현재 계층의 콘볼루션 신경망의 검출 대상으로하며;상기 현재 계층의 콘볼루션 신경망을 통해 상기 현재 계층의 콘볼루션 신경망의 검출 대상에 대해 이미지 다운샘플링을 수행하여, 상기 현재 계층의 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추출 결과를 획득하고; 상기현재 계층의 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추출 결과를 상기 현재 계층의 콘볼루션 신경망의 다음 계층의 콘볼루션 신경망의 검출 대상으로 하고; 상기 다음 계층의 콘볼루션 신경망을 상기 현재 계층의 콘볼루션 신경망으로 하여, 상기 사람 얼굴 검출 모델의 N 번째 계층의 콘볼루션 신경망의 검출 대상에서 N 번째 계층의 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추출 결과를 추출할 때까지 상기 조작을 반복하여 수행하되,N은 1보다 큰 자연수이고;상기 첫 번째 계층의 콘볼루션 신경망 내지 상기 N 번째 계층의 콘볼루션 신경망 중의 각 계층의 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추출 결과에 기반하여, 상기 식별될 이미지의 사람 얼굴 검출 프레임을 획득하는것을 특징으로 하는 위험 주행 행위 식별 장치.공개특허 10-2021-0128491-5-청구항 12 제8항에 있어서, 상기 행위 식별 모듈은 구체적으로 상기 사람 얼굴 검출 프레임을 상기 위험 주행 행위 식별 모델 중의 콘볼루션 계층에 입력하고, 상기 콘볼루션 계층을 통해 상기 사람 얼굴 검출 프레임에 대해 콘볼루션 연산을수행하여, 상기 콘볼루션 계층에 대응되는 사람 얼굴 특징 추출 결과를 획득하며; 상기 콘볼루션 계층에 대응되는 사람 얼굴 특징 추출 결과를 상기 위험 주행 행위 식별 모델 중의 풀링층에 입력하고, 상기 풀링층을 통해상기 콘볼루션 계층에 대응되는 사람 얼굴 검출 프레임에 대해 풀링 연산을 수행하여, 상기 풀링층에 대응되는사람 얼굴 특징 추출 결과를 획득하며; 상기 풀링층에 대응되는 사람 얼굴 특징 추출 결과를 상기 위험 주행 행위 모델 중의 완전연결층에 입력하고, 상기 완전연결층을 통해 상기 풀링층에 대응되는 사람 얼굴 특징 추출 결과에 대해 분류 연산을 수행하여, 상기 사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득하는 것을 특징으로 하는 위험 주행 행위 식별 장치."}
{"patent_id": "10-2021-7032212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서,사전에 획득한 첫 번째 사람 얼굴 이미지 샘플을 현재 사람 얼굴 이미지 샘플로 하며; 상기 사람 얼굴 검출 모델이 상기 사람 얼굴 검출 모델에 대응되는 미리 설정된 수렴 조건을 충족하지 못하는 경우, 상기 현재 사람 얼굴 이미지 샘플을 상기 사람 얼굴 검출 모델에 입력하고, 상기 현재 사람 얼굴 이미지 샘플을 사용하여 상기 사람 얼굴 검출 모델에 대해 트레이닝을 수행하며; 상기 현재 사람 얼굴 이미지 샘플의 다음 사람 얼굴 이미지 샘플을 상기 현재 사람 얼굴 이미지 샘플로 하여, 상기 사람 얼굴 검출 모델이 상기 사람 얼굴 검출 모델에 대응되는 수렴 조건을 충족할 때까지 상기 조작을 반복하여 수행하는 사람 얼굴 검출 트레이닝 모듈을 더 포함하는것을 특징으로 하는 위험 주행 행위 식별 장치."}
{"patent_id": "10-2021-7032212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서, 사전에 획득한 첫 번째 사람 얼굴 검출 프레임 샘플을 현재 사람 얼굴 검출 프레임 샘플로 하며; 상기 위험 주행 행위 식별 모델이 상기 위험 주행 행위 식별 모델에 대응되는 미리 설정된 수렴 조건을 충족하지 못하는 경우, 상기 현재 사람 얼굴 검출 프레임 샘플을 상기 위험 주행 행위 식별 모델에 입력하고, 상기 현재 사람 얼굴검출 프레임 샘플을 사용하여 상기 위험 주행 행위 식별 모델에 대해 트레이닝을 수행하며; 상기 현재 사람 얼굴 검출 프레임 샘플의 다음 사람 얼굴 검출 프레임 샘플을 상기 현재 사람 얼굴 검출 프레임 샘플로 하여, 상기 위험 주행 행위 식별 모델이 상기 위험 주행 행위 식별 모델에 대응되는 수렴 조건을 충족할 때까지 상기 조작을 반복하여 수행하는 행위 식별 트레이닝 모듈을 더 포함하는 것을 특징으로 하는 위험 주행 행위 식별장치."}
{"patent_id": "10-2021-7032212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "전자 설비로서,적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서와 통신적으로 연결되는 메모리를 포함하되, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되고, 상기 명령이상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 제1항 내지 제7항 중 어느 한항에 따른 방법을 수행하도록 하는 것을 특징으로 하는 전자 설비."}
{"patent_id": "10-2021-7032212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "컴퓨터 명령이 저장되어 있는 비 일시적 컴퓨터 판독가능 저장매체로서,상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제7항 중 어느 한 항에 따른 방법을 수행하도록 하는 것을 특징으로 하는 비 일시적 컴퓨터 판독가능 저장매체.공개특허 10-2021-0128491-6-"}
{"patent_id": "10-2021-7032212", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 위험 주행 행위 식별 방법, 장치, 전자 설비 및 저장매체를 개시하였고, 인공 지능, 딥러닝 및 이미지 식별분야에 관한 것이며, 자율 주행분야에 응용될 수 있다. 구체적인 방안은 식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모델에 입력하고, 사람 얼굴 검출 모델을 통해 식별될 이미지에 대해 사람 얼굴 검출을 수행하여, 식별될 이미지의 사람 얼굴 검출 프레임을 획득하며; 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력하고, 위험 주행 행위 식별 모델을 통해 사람 얼굴 검출 프레임에 대해 위험 주행 행 위 식별을 수행하여, 사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득한다. 본 출원의 실시 예는 주행자의 위험 주행 행위를 식별하는 정확도를 대폭 향상시킬 수 있으며, 또한 계산 비용을 대폭 감소시킬 수 있어, 위험 주행 행위에 대한 높은 정확도의 실시간 식별 능력을 획득하게 된다."}
{"patent_id": "10-2021-7032212", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 2020년 06월 29일에 중국 특허청에 제출된 출원번호가 202010611370.4인 중국 특허 출원의 우선권을 주장하는 바, 해당 출원의 전부 내용은 참조로서 본 출원에 포함된다."}
{"patent_id": "10-2021-7032212", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "본 출원의 실시예는 컴퓨터 기술분야에 관한 것으로서, 예를 들어, 인공 지능, 딥러닝 및 이미지 식별분야에 관 한 것이며, 자율 주행분야에 응용될 수 있다. 구체적으로, 위험 주행 행위 식별 방법, 장치, 전자 설비 및 저장 매체에 관한 것이다."}
{"patent_id": "10-2021-7032212", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인터넷 및 인공 지능 기술이 나날이 발전함에 따라, 점점 더 많은 분야가 자동화 계산 및 분석에 관련되기 시작 하였으며, 여기서, 감시 및 보안 분야는 가장 중요한 장면 중 하나이다. 택시, 버스, 장거리 버스 등과 같은 공공 운행 차량의 경우, 많은 승객의 안전에 관련되므로, 주행자의 주행 안 전이 특히 중요하다. 따라서, 많은 공공 운행 차량에 차량용 감시 카메라를 설치하여, 대응되는 회사 또는 감독 기관에서 주행자의 주행 행위를 모니터링하는데 편리하도록 한다. 흡연, 전화 통화, 안전벨트 미착용 등 주행자 에게 자주 발생되는 일부 위험 주행 행위를 제때에 발견하여 경고함으로써, 차량의 주행 안전을 최대한 보장해 야 한다. 주행자의 안전벨트 착용에 대한 판단의 경우, 전통적인 방법은 일반적으로 감시 비디오를 추출하여 검사한 다음, 육안으로 판단하는 것이다. 근래 콘볼루션 신경망(Convolutional Neural Networks, CNN)이 등장함에 따 라, 일부 방법은 인공 지능 보조 식별을 도입하였지만, 이러한 방법은 일반적으로 단지 전체 감시 픽처 또는 운 전자의 신체 부위에 대해서만 직접적으로 이진분류하여 판단한다. 종래의 방안에서, 수동 및 육안의 방식은 속 도가 느리고, 오차가 크며, 시간 및 인건 비용이 많이 소요되는 결함이 존재한다. CNN에 기반한 직접적인 분류 법은 흡연, 전화 통화, 드링킹 등 타겟 행위가 이미지에서 비교적 작고, 추출 가능한 특징이 적으며, 아울러 주 위에 대량의 간섭 정보가 존재하기 때문에, 실제 차량 장면에서의 식별 정확도가 비교적 낮으며 식별 효과가 이 상적이지 못하다."}
{"patent_id": "10-2021-7032212", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "하기 내용은 본문에서 상세하게 설명되는 카테고리에 대한 약술이다. 본 약술은 청구항의 보호범위를 한정하기 위한 것이 아니다. 본 출원은 주행자의 위험 주행 행위를 식별하는 정확도를 대폭 향상시킬 수 있으며, 또한 계산 비용을 대폭 감 소시킬 수 있어, 위험 주행 행위에 대한 높은 정확도의 실시간 식별 능력을 획득하게 되는 위험 주행 행위 식별 방법, 장치, 전자 설비 및 저장매체를 제공한다."}
{"patent_id": "10-2021-7032212", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 따라, 위험 주행 행위 식별 방법을 제공하며, 상기 방법은, 식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모델에 입력하고, 상기 사람 얼굴 검출 모델을 통해 상기 식 별될 이미지에 대해 사람 얼굴 검출을 수행하여, 상기 식별될 이미지의 사람 얼굴 검출 프레임을 획득하는 단계; 상기 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력하고, 상기 위험 주행 행위 식 별 모델을 통해 상기 사람 얼굴 검출 프레임에 대해 위험 주행 행위 식별을 수행하여, 상기 사람 얼굴 검출 프 레임에 대응되는 위험 주행 행위 식별 결과를 획득하는 단계; 를 포함한다. 본 개시의 일 측면에 따라, 위험 주행 행위 식별 장치를 제공하며, 상기 장치는 사람 얼굴 검출 모듈 및 행위 식별 모듈을 포함하고; 여기서. 상기 사람 얼굴 검출 모듈은 식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모델에 입력하고, 상기 사람 얼 굴 검출 모델을 통해 상기 식별될 이미지에 대해 사람 얼굴 검출을 수행하여, 상기 식별될 이미지의 사람 얼굴 검출 프레임을 획득하며; 상기 행위 식별 모듈은 상기 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력하고, 상기 위험 주행 행위 식별 모델을 통해 상기 사람 얼굴 검출 프레임에 대해 위험 주행 행위 식별을 수행하여, 상기 사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득한다. 본 개시의 일 측면에 따라, 전자 설비를 제공하며, 해당 전자 설비는, 하나 또는 복수의 프로세서; 하나 또는 복수의 프로그램을 저장하는 메모리; 를 포함하며, 상기 하나 또는 복수의 프로그램이 상기 하나 또는 복수의 프로세서에 의해 실행되어, 상기 하나 또는 복수의 프로세서가 본 출원의 임의의 실시예에 따른 위험 주행 행위 식별 방법을 구현하도록 한다. 본 개시의 일 측면에 따라, 저장매체를 제공하며, 해당 저장매체에는 컴퓨터 프로그램이 저장되어 있고, 해당 프로그램이 프로세서에 의해 실행되는 경우, 본 출원의 임의의 실시예에 따른 위험 주행 행위 식별 방법을 구현 한다."}
{"patent_id": "10-2021-7032212", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 출원의 기술방안에 따르면, CNN에 기반하여 식별될 이미지를 직접 식별하는데, 흡연, 전화 통화, 드링킹 (drinking) 등 타겟 행위가 이미지에서 비교적 작고, 추출 가능한 특징이 적으며, 아울러 주위에 대량의 간섭 정보가 존재하기 때문에, 실제 차량 장면에서의 식별 정확도가 비교적 낮으며 식별 효과가 이상적이지 못한 종 래 기술의 기술적 과제를 해결하였다. 본 출원에서 제공한 기술방안은 주행자의 위험 주행 행위를 식별하는 정 확도를 대폭 향상시킬 수 있으며, 또한 계산 비용을 대폭 감소시킬 수 있어, 위험 주행 행위에 대한 높은 정확 도의 실시간 식별 능력을 획득하게 된다. 해당 부분에서 설명된 내용은 본 개시의 실시예의 핵심적인 특징 또는 중요한 특징을 식별하기 위한 것이 아니 며, 본 개시의 범위를 한정하려는 의도가 아님을 이해하여야 한다. 본 개시의 기타 특징은 하기 명세서를 통해 쉽게 이해될 수 있다. 도면 및 상세한 설명을 읽고 이해하면, 기타 방면도 이해할 수 있다."}
{"patent_id": "10-2021-7032212", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 결합하여 본 출원의 예시적인 실시예를 설명하도록 한다. 여기서 본 출원의 실시예를 포함하는 각 종 상세한 설명은 이해를 돕기 위한 것이며, 이들을 예시적인 것으로 간주하여야 한다. 따라서, 본 분야의 당업 자는 본 출원의 범위 및 요지를 벗어나지 않고 여기서 설명된 실시예에 대하여 다양한 변경 및 수정이 가능함을 이해할 수 있다. 마찬가지로, 명확하고 간결하게 하기 위해, 이하의 설명에서는 공지된 기능 및 구조에 대한 설 명을 생략하도록 한다. 실시예 1 도 1은 본 출원의 실시예에서 제공하는 위험 주행 행위 식별 방법의 흐름 개략도이고, 해당 방법은 위험 주행 행위 식별 장치 또는 전자 설비에 의해 수행될 수 있고, 해당 장치 또는 전자 설비는 소프트웨어 및/또는 하드 웨어의 방식에 의해 구현될 수 있으며, 해당 장치 또는 전자 설비는 네트워크 통신 기능을 구비하는 임의의 스 마트 설비에 통합될 수 있다. 도 1에 도시된 바와 같이, 위험 주행 행위 식별 방법은 아래의 단계를 포함할 수 있다. 단계(S101), 식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모델에 입력하고, 사람 얼굴 검출 모델을 통해 식별될 이미지에 대해 사람 얼굴 검출을 수행하여, 식별될 이미지의 사람 얼굴 검출 프레임을 획득한다. 본 출원의 구체적인 실시예에서, 전자 설비는 식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모델에 입력하 고, 사람 얼굴 검출 모델을 통해 식별될 이미지에 대해 사람 얼굴 검출을 수행하여, 식별될 이미지의 사람 얼굴 검출 프레임을 획득할 수 있다. 구체적으로, 사람 얼굴 검출 모델을 통해 사람 얼굴 검출 프레임의 4개 정점의 좌표를 획득할 수 있으며, 해당 4개 정점의 좌표에 기반하여 사람 얼굴 검출 프레임을 획득할 수 있다. 일 실시 예에서, 전자 설비는 우선 사람 얼굴 검출 모델의 첫 번째 계층의 콘볼루션 신경망을 현재 계층의 콘볼루션 신 경망으로 하고; 식별될 이미지를 현재 계층의 콘볼루션 신경망의 검출 대상으로 하며; 다음 현재 계층의 콘볼루 션 신경망을 통해 현재 계층의 콘볼루션 신경망의 검출 대상에 대해 이미지 다운샘플링을 수행하여, 현재 계층 의 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추출 결과를 획득하고; 계속하여 현재 계층의 콘볼루션 신경망 에 대응되는 사람 얼굴 특징 추출 결과를 현재 계층의 콘볼루션 신경망의 다음 계층의 콘볼루션 신경망의 검출 대상으로 하고; 다음 계층의 콘볼루션 신경망을 현재 계층의 콘볼루션 신경망으로 하여, 사람 얼굴 검출 모델의 N 번째 계층의 콘볼루션 신경망의 검출 대상에서 N 번째 계층의 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추 출 결과를 추출할 때까지 상기 조작을 반복하여 수행하며; 여기서, N은 1보다 큰 자연수이고; 마지막으로 첫 번 째 계층의 콘볼루션 신경망 내지 N 번째 계층의 콘볼루션 신경망 중의 각 계층의 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추출 결과에 기반하여, 식별될 이미지의 사람 얼굴 검출 프레임을 획득할 수 있다. 구체적으로, 전자 설비는 사람 얼굴 검출 모델의 6층 콘볼루션 신경망을 통해 이미지 다운샘플링을 수행하여, 6층 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추출 결과를 획득하며; 마지막 3층 콘볼루션 신경망에 기반하여 고정 개수의 상이한 사이즈의 사람 얼굴 앵커 프레임을 각각 미리 설정함으로써 사람 얼굴 검출 프레임 회귀(regression)를 수행하여, 최종적으로 사람 얼굴 검출 결과를 획득하며, 즉 사람 얼굴 검출 프레임의 4개 정점의 좌표를 획득할 수 있다. 단계(S102), 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력하고, 위험 주행 행위 식별 모델을 통해 사람 얼굴 검출 프레임에 대해 위험 주행 행위 식별을 수행하여, 사람 얼굴 검출 프레임에 대 응되는 위험 주행 행위 식별 결과를 획득한다. 본 출원의 구체적인 실시예에서, 전자 설비는 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력하고, 위험 주행 행위 식별 모델을 통해 사람 얼굴 검출 프레임에 대해 위험 주행 행위 식별을 수행 하여, 사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득할 수 있다. 일 실시예에서, 전자 설 비는 우선 사람 얼굴 검출 프레임을 위험 주행 행위 식별 모델 중의 콘볼루션 계층에 입력하고, 콘볼루션 계층 을 통해 사람 얼굴 검출 프레임에 대해 콘볼루션 연산(convolution operation)을 수행하여, 콘볼루션 계층에 대 응되는 사람 얼굴 특징 추출 결과를 획득하며; 다음 콘볼루션 계층에 대응되는 사람 얼굴 특징 추출 결과를 위 험 주행 행위 식별 모델 중의 풀링층(pooling layer)에 입력하고, 풀링층을 통해 콘볼루션 계층에 대응되는 사 람 얼굴 검출 프레임에 대해 풀링 연산(Pooling operation)을 수행하여, 풀링층에 대응되는 사람 얼굴 특징 추 출 결과를 획득하며; 계속하여 풀링층에 대응되는 사람 얼굴 특징 추출 결과를 위험 주행 행위 모델 중의 완전 연결층에 입력하고, 완전연결층을 통해 풀링층에 대응되는 사람 얼굴 특징 추출 결과에 대해 분류 연산 (classification operation)을 수행하여, 사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득 할 수 있다. 구체적으로, 전자 설비는 8층의 콘볼루션 계층과 5층의 풀링층으로 구성된 위험 주행 행위 식별 모 델을 통해 사람 얼굴 검출 프레임에 대해 특징 추출을 수행하며, 마지막으로 완전연결층을 통해 위험 주행 행위 식별 결과를 출력할 수 있다. 본 출원의 구체적인 실시예에서, 주행 행위는 각각 위험하지 않은 행위, 전화 통화, 흡연, 이팅(eating), 드링 킹 등 다섯 가지 유형으로 정의되며, 숫자 0-4로 각 유형의 주행 행위의 태그를 각각 표시한다. 본 출원의 실시예에서 제출하는 위험 주행 행위 식별 방법은 우선 식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모델에 입력하고, 사람 얼굴 검출 모델을 통해 식별될 이미지에 대해 사람 얼굴 검출을 수행하여, 식별될 이미지의 사람 얼굴 검출 프레임을 획득하며; 다음 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력하고, 위험 주행 행위 식별 모델을 통해 사람 얼굴 검출 프레임에 대해 위험 주행 행위 식별을수행하여, 사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득한다. 즉, 본 출원은 우선 식별 될 이미지에서 사람 얼굴 검출 프레임을 추출하고, 다음 해당 사람 얼굴 검출 프레임에 기반하여 위험 주행 행 위 식별을 수행할 수 있다. 그러나 종래의 위험 주행 행위 식별 방법에서는 CNN에 기반하여 식별될 이미지를 직 접 식별한다. 본 출원은 우선 식별될 이미지에서 사람 얼굴 검출 프레임을 추출한 다음, 해당 사람 얼굴 검출 프레임에 기반하여 위험 주행 행위 식별을 수행하는 기술수단을 채택함으로써, CNN에 기반하여 식별될 이미지를 직접 식별하는데, 흡연, 전화 통화, 드링킹 등 타겟 행위가 이미지에서 비교적 작고, 추출 가능한 특징이 적으 며, 아울러 주위에 대량의 간섭 정보가 존재하기 때문에, 실제 차량 장면에서의 식별 정확도가 비교적 낮으며 식별 효과가 이상적이지 못한 종래 기술의 기술적 과제를 극복한다. 본 출원에서 제공한 기술방안은 주행자의 위험 주행 행위를 식별하는 정확도를 대폭 향상시킬 수 있으며, 또한 계산 비용을 대폭 감소시킬 수 있어, 위험 주행 행위에 대한 높은 정확도의 실시간 식별 능력을 획득하게 된다. 또한, 본 출원의 실시예에 따른 기술방안 은 구현하기 간단하고 편리하며, 보급이 용이하며, 적용 범위가 보다 넓다. 실시예 2 도 2는 본 출원의 실시예에서 제공하는 위험 주행 행위 식별 방법의 흐름 개략도이다. 본 실시예는 상기 실시예 의 기초상에서 제출한 선택 가능한 방안이다. 도 2에 도시된 바와 같이, 위험 주행 행위 식별 방법은 아래의 단 계를 포함할 수 있다. 단계(S201), 식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모델에 입력하고, 사람 얼굴 검출 모델을 통해 식별될 이미지에 대해 사람 얼굴 검출을 수행하여, 식별될 이미지의 사람 얼굴 검출 프레임을 획득한다. 단계(S202), 사람 얼굴 검출 프레임에 대해 이미지 전처리를 수행하여, 이미지 전처리된 사람 얼굴 검출 프레임 을 획득한다. 본 출원의 구체적인 실시예에서, 전자 설비는 사람 얼굴 검출 프레임에 대해 이미지 전처리를 수행하여, 이미지 전처리된 사람 얼굴 검출 프레임을 획득하며; 이미지 전처리된 사람 얼굴 검출 프레임을 위험 주행 행위 식별 모델에 입력할 수 있다. 일 실시예에서, 전자 설비는 우선 사람 얼굴 검출 프레임을 확대 처리하여, 확대 처리 된 사람 얼굴 검출 프레임을 획득하며; 다음 확대 처리된 사람 얼굴 검출 프레임을 클리핑(clipping) 처리하여, 클리핑 처리된 사람 얼굴 검출 프레임을 획득하며; 계속하여 클리핑 처리된 사람 얼굴 검출 프레임을 정규화 (normalization) 처리하여, 정규화 처리된 사람 얼굴 검출 프레임을 획득하며; 정규화된 사람 얼굴 검출 프레임 을 이미지 전처리된 사람 얼굴 검출 프레임으로 할 수 있다. 단계(S203), 이미지 전처리된 사람 얼굴 검출 프레임을 위험 주행 행위 식별 모델에 입력하고, 위험 주행 행위 식별 모델을 통해 전처리된 사람 얼굴 검출 프레임에 대해 위험 주행 행위 식별을 수행하여, 사람 얼굴 검출 프 레임에 대응되는 위험 주행 행위 식별 결과를 획득한다. 본 출원의 구체적인 실시예에서, 전자 설비는 이미지 전처리된 사람 얼굴 검출 프레임을 위험 주행 행위 식별 모델에 입력하고, 위험 주행 행위 식별 모델을 통해 전처리된 사람 얼굴 검출 프레임에 대해 위험 주행 행위 식 별을 수행하여, 사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득할 수 있다. 일 실시예에서, 전자 설비는 우선 전처리된 사람 얼굴 검출 프레임을 위험 주행 행위 식별 모델 중의 콘볼루션 계 층에 입력하고, 콘볼루션 계층을 통해 전처리된 사람 얼굴 검출 프레임에 대해 콘볼루션 연산을 수행하여, 콘볼 루션 계층에 대응되는 사람 얼굴 특징 추출 결과를 획득하며; 다음 콘볼루션 계층에 대응되는 사람 얼굴 특징 추출 결과를 위험 주행 행위 식별 모델 중의 풀링층에 입력하고, 풀링층을 통해 콘볼루션 계층에 대응되는 사람 얼굴 검출 프레임에 대해 풀링 연산을 수행하여, 풀링층에 대응되는 사람 얼굴 특징 추출 결과를 획득하며; 계 속하여 풀링층에 대응되는 사람 얼굴 특징 추출 결과를 위험 주행 행위 모델 중의 완전연결층에 입력하고, 완전 연결층을 통해 풀링층에 대응되는 사람 얼굴 특징 추출 결과에 대해 분류 연산을 수행하여, 사람 얼굴 검출 프 레임에 대응되는 위험 주행 행위 식별 결과를 획득할 수 있다. 본 출원의 실시예에서 제출하는 위험 주행 행위 식별 방법은 우선 식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모델에 입력하고, 사람 얼굴 검출 모델을 통해 식별될 이미지에 대해 사람 얼굴 검출을 수행하여, 식별될 이미지의 사람 얼굴 검출 프레임을 획득하며; 다음 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력하고, 위험 주행 행위 식별 모델을 통해 사람 얼굴 검출 프레임에 대해 위험 주행 행위 식별을 수행하여, 사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득한다. 즉, 본 출원은 우선 식별 될 이미지에서 사람 얼굴 검출 프레임을 추출하고, 다음 해당 사람 얼굴 검출 프레임에 기반하여 위험 주행 행 위 식별을 수행할 수 있다. 그러나 종래의 위험 주행 행위 식별 방법에서는 CNN에 기반하여 식별될 이미지를 직접 식별한다. 본 출원은 우선 식별될 이미지에서 사람 얼굴 검출 프레임을 추출한 다음, 해당 사람 얼굴 검출 프레임에 기반하여 위험 주행 행위 식별을 수행하는 기술수단을 채택함으로써, CNN에 기반하여 식별될 이미지를 직접 식별하는데, 흡연, 전화 통화, 드링킹 등 타겟 행위가 이미지에서 비교적 작고, 추출 가능한 특징이 적으 며, 아울러 주위에 대량의 간섭 정보가 존재하기 때문에, 실제 차량 장면에서의 식별 정확도가 비교적 낮으며 식별 효과가 이상적이지 못한 종래 기술의 기술적 과제를 극복한다. 본 출원에서 제공한 기술방안은 주행자의 위험 주행 행위를 식별하는 정확도를 대폭 향상시킬 수 있으며, 또한 계산 비용을 대폭 감소시킬 수 있어, 위험 주행 행위에 대한 높은 정확도의 실시간 식별 능력을 획득하게 된다. 또한, 본 출원의 실시예에 따른 기술방안 은 구현하기 간단하고 편리하며, 보급이 용이하며, 적용 범위가 보다 넓다. 실시예 3 도 3은 본 출원의 실시예에서 제공하는 위험 주행 행위 식별 방법의 흐름 개략도이다. 본 실시예는 상기 실시예 의 기초상에서 제출한 선택 가능한 방안이다. 도 3에 도시된 바와 같이, 위험 주행 행위 식별 방법은 아래의 단 계를 포함할 수 있다. 단계(S301), 식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모델에 입력하고, 사람 얼굴 검출 모델을 통해 식별될 이미지에 대해 사람 얼굴 검출을 수행하여, 식별될 이미지의 사람 얼굴 검출 프레임을 획득한다. 단계(S302), 사람 얼굴 검출 프레임을 확대 처리하여, 확대 처리된 사람 얼굴 검출 프레임을 획득한다. 본 출원의 구체적인 실시예에서, 전자 설비는 사람 얼굴 검출 프레임을 확대 처리하여, 확대 처리된 사람 얼굴 검출 프레임을 획득할 수 있다. 해당 단계에서, 전자 설비는 사람 얼굴 검출 프레임을 두배로 확대할 수 있다. 컴퓨터 이미지 처리 및 컴퓨터 그래픽스(computer graphics)에서 이미지 스케일링(image scaling)은 디지털 이 미지의 크기를 조절하는 과정을 의미한다. 이미지 스케일링은 처리 효율과 결과의 평활도(smoothness) 및 선명 도(sharpness) 사이의 균형을 유지해야 한다. 하나의 이미지의 크기가 증가되면, 이미지를 구성하는 픽셀의 가 시도가 더 높아져, 이미지가 \"소프트\"하게 표현된다. 반대로, 하나의 이미지를 축소하면 해당 이미지의 평활도 및 선명도가 향상된다. 구체적으로, 이미지를 확대(업샘플링(upsampling) 또는 이미지 보간(interpolating)이라 고 칭함)의 주요 목적은 원래의 이미지를 확대하여, 보다 높은 해상도의 디스플레이 설비에서 디스플레이할 수 있도록 하는 것이다. 단계(S303), 확대 처리된 사람 얼굴 검출 프레임을 클리핑 처리하여, 클리핑 처리된 사람 얼굴 검출 프레임을 획득한다. 본 출원의 구체적인 실시예에서, 전자 설비는 확대 처리된 사람 얼굴 검출 프레임을 클리핑 처리하여, 클리핑 처리된 사람 얼굴 검출 프레임을 획득할 수 있다. 해당 단계에서, 전자 설비는 클리핑된 사람 얼굴 검출 프레임 을 미리 정해진 사이즈의 이미즈로 변환할 수 있으며, 예를 들어, 클리핑된 사람 얼굴 검출 프레임을 140 140의 이미지로 변환할 수 있다. 단계(S304), 클리핑 처리된 사람 얼굴 검출 프레임을 정규화 처리하여, 정규화 처리된 사람 얼굴 검출 프레임을 획득하며; 정규화된 사람 얼굴 검출 프레임을 이미지 전처리된 사람 얼굴 검출 프레임으로 한다. 본 출원의 구체적인 실시예에서, 전자 설비는 클리핑 처리된 사람 얼굴 검출 프레임을 정규화 처리하여, 정규화 처리된 사람 얼굴 검출 프레임을 획득하며; 정규화된 사람 얼굴 검출 프레임을 이미지 전처리된 사람 얼굴 검출 프레임으로 할 수 있다. 해당 단계에서, 정규화 처리된 사람 얼굴 검출 프레임에서 각 픽셀의 픽셀값은 미리 정 해진 범위 내에 있으며, 예를 들어, 각 픽셀의 픽셀값은 [-0.5, 0.5] 사이에 있다. 이미지 정규화는 이미지에 일련의 표준 처리 변환을 수행하여, 이미지가 고정된 표준 형식으로 변환되게 하는 과정을 의미하며, 해당 표준 이미지를 정규화 이미지라고 칭한다. 이미지 정규화는 일련의 변환을 통해(즉, 이미지의 불변 모멘트(Invariant moment)를 이용하여, 이미지 변환에 대한 기타 변환 함수의 영향을 제거할 수 있는 한 세트의 파라미터를 찾 음), 처리될 원본 이미지(original image)를 대응되는 유일한 표준 형식으로 전환하는 것이며, 해당 표준 형식 의 이미지는 평행이동(translation), 회전, 크기조정(scaling) 등 아핀변환에 대해 불변 특성을 갖는다. 단계(S305), 이미지 전처리된 사람 얼굴 검출 프레임을 위험 주행 행위 식별 모델에 입력하고, 위험 주행 행위 식별 모델을 통해 전처리된 사람 얼굴 검출 프레임에 대해 위험 주행 행위 식별을 수행하여, 전처리된 사람 얼 굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득한다. 바람직하게, 본 출원의 구체적인 실시예에서, 전자 설비는 식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모 델에 입력하기 이전에, 먼저 사람 얼굴 검출 모델에 대해 트레이닝을 수행할 수도 있다. 구체적으로, 전자 설비는 우선 사전에 획득한 첫 번째 사람 얼굴 이미지 샘플을 현재 사람 얼굴 이미지 샘플로 하며; 사람 얼굴 검출 모델이 사람 얼굴 검출 모델에 대응되는 미리 설정된 수렴 조건을 충족하지 못하는 경우, 현재 사람 얼굴 이미 지 샘플을 상기 사람 얼굴 검출 모델에 입력하고, 현재 사람 얼굴 이미지 샘플을 사용하여 사람 얼굴 검출 모델 에 대해 트레이닝을 수행하며; 현재 사람 얼굴 이미지 샘플의 다음 사람 얼굴 이미지 샘플을 현재 사람 얼굴 이 미지 샘플로 하여, 사람 얼굴 검출 모델이 사람 얼굴 검출 모델에 대응되는 수렴 조건을 충족할 때까지 상기 조 작을 반복하여 수행한다. 바람직하게, 본 출원의 구체적인 실시예에서, 전자 설비는 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력하기 이전에, 먼저 위험 주행 행위 식별 모델에 대해 트레이닝을 수행할 수도 있다. 구체 적으로, 전자 설비는 우선 사전에 획득한 첫 번째 사람 얼굴 검출 프레임 샘플을 현재 사람 얼굴 검출 프레임 샘플로 하며; 위험 주행 행위 식별 모델이 위험 주행 행위 식별 모델에 대응되는 미리 설정된 수렴 조건을 충족 하지 못하는 경우, 현재 사람 얼굴 검출 프레임 샘플을 위험 주행 행위 식별 모델에 입력하고, 현재 사람 얼굴 검출 프레임 샘플을 사용하여 위험 주행 행위 식별 모델에 대해 트레이닝을 수행하며; 현재 사람 얼굴 검출 프 레임 샘플의 다음 사람 얼굴 검출 프레임 샘플을 현재 사람 얼굴 검출 프레임 샘플로 하여, 위험 주행 행위 식 별 모델이 위험 주행 행위 식별 모델에 대응되는 수렴 조건을 충족할 때까지 상기 조작을 반복하여 수행한다. 본 출원의 실시예에서 제출하는 위험 주행 행위 식별 방법은, 우선 식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모델에 입력하고, 사람 얼굴 검출 모델을 통해 식별될 이미지에 대해 사람 얼굴 검출을 수행하여, 식별될 이미지의 사람 얼굴 검출 프레임을 획득하며; 다음 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력하고, 위험 주행 행위 식별 모델을 통해 사람 얼굴 검출 프레임에 대해 위험 주행 행위 식별을 수행하여, 사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득한다. 즉, 본 출원은 우선 식별 될 이미지에서 사람 얼굴 검출 프레임을 추출하고, 다음 해당 사람 얼굴 검출 프레임에 기반하여 위험 주행 행 위 식별을 수행할 수 있다. 그러나 종래의 위험 주행 행위 식별 방법에서는 CNN에 기반하여 식별될 이미지를 직 접 식별한다. 본 출원은 우선 식별될 이미지에서 사람 얼굴 검출 프레임을 추출한 다음, 해당 사람 얼굴 검출 프레임에 기반하여 위험 주행 행위 식별을 수행하는 기술수단을 채택함으로써, CNN에 기반하여 식별될 이미지를 직접 식별하는데, 흡연, 전화 통화, 드링킹 등 타겟 행위가 이미지에서 비교적 작고, 추출 가능한 특징이 적으 며, 아울러 주위에 대량의 간섭 정보가 존재하기 때문에, 실제 차량 장면에서의 식별 정확도가 비교적 낮으며 식별 효과가 이상적이지 못한 종래 기술의 기술적 과제를 극복한다. 본 출원에서 제공한 기술방안은 주행자의 위험 주행 행위를 식별하는 정확도를 대폭 향상시킬 수 있으며, 또한 계산 비용을 대폭 감소시킬 수 있어, 위험 주행 행위에 대한 높은 정확도의 실시간 식별 능력을 획득하게 된다. 또한, 본 출원의 실시예에 따른 기술방안 은 구현하기 간단하고 편리하며, 보급이 용이하며, 적용 범위가 보다 넓다. 실시예 4 도 4는 본 출원의 실시예에서 제공하는 위험 주행 행위 식별 장치의 제1 구조 개략도이다. 도 4에 도시된 바와 같이, 상기 장치는 사람 얼굴 검출 모듈 및 행위 식별 모듈을 포함하며; 여기서, 상기 사람 얼굴 검출 모듈은 식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모델에 입력하고, 상기 사 람 얼굴 검출 모델을 통해 상기 식별될 이미지에 대해 사람 얼굴 검출을 수행하여, 상기 식별될 이미지의 사람 얼굴 검출 프레임을 획득하며; 상기 행위 식별 모듈은 상기 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력 하고, 상기 위험 주행 행위 식별 모델을 통해 상기 사람 얼굴 검출 프레임에 대해 위험 주행 행위 식별을 수행 하여, 상기 사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득한다. 도 5는 본 출원의 실시예에서 제공하는 위험 주행 행위 식별 장치의 제2 구조 개략도이다. 도 5에 도시된 바와 같이, 상기 장치는 상기 사람 얼굴 검출 프레임에 대해 이미지 전처리를 수행하여, 이미지 전처리된 사람 얼굴 검출 프레임을 획득하며; 상기 이미지 전처리된 사람 얼굴 검출 프레임을 상기 위험 주행 행위 식별 모델 에 입력하는 전처리 모듈을 더 포함한다. 도 6은 본 출원의 실시예 4에서 제공하는 전처리 모듈의 구조 개략도이다. 도 6에 도시된 바와 같이, 상기 전처 리 모듈은 확대 서브 모듈, 클리핑 서브 모듈 및 정규화 서브 모듈을 포함하며; 여기서, 상기 확대 서브 모듈은 상기 사람 얼굴 검출 프레임을 확대 처리하여, 확대 처리된 사람 얼굴 검출 프레 임을 획득하고;상기 클리핑 서브 모듈은 상기 확대 처리된 사람 얼굴 검출 프레임을 클리핑 처리하여, 클리핑 처리된 사 람 얼굴 검출 프레임을 획득하며; 상기 정규화 서브 모듈은 상기 클리핑 처리된 사람 얼굴 검출 프레임을 정규화 처리하여, 정규화 처리된 사람 얼굴 검출 프레임을 획득하며; 상기 정규화된 사람 얼굴 검출 프레임을 상기 이미지 전처리된 사람 얼굴 검출 프레임으로 한다. 나아가, 상기 사람 얼굴 검출 모듈은 구체적으로 상기 사람 얼굴 검출 모델의 첫 번째 계층의 콘볼루션 신 경망을 현재 계층의 콘볼루션 신경망으로 하고; 상기 식별될 이미지를 상기 현재 계층의 콘볼루션 신경망의 검 출 대상으로 하며; 상기 현재 계층의 콘볼루션 신경망을 통해 상기 현재 계층의 콘볼루션 신경망의 검출 대상에 대해 이미지 다운샘플링을 수행하여, 상기 현재 계층의 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추출 결과 를 획득하고; 상기 현재 계층의 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추출 결과를 상기 현재 계층의 콘 볼루션 신경망의 다음 계층의 콘볼루션 신경망의 검출 대상으로 하고; 상기 다음 계층의 콘볼루션 신경망을 상 기 현재 계층의 콘볼루션 신경망으로 하여, 상기 사람 얼굴 검출 모델의 N 번째 계층의 콘볼루션 신경망의 검출 대상에서 N 번째 계층의 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추출 결과를 추출할 때까지 상기 조작을 반복하여 수행하며; 여기서, N은 1보다 큰 자연수이고; 상기 첫 번째 계층의 콘볼루션 신경망 내지 상기 N 번째 계층의 콘볼루션 신경망 중의 각 계층의 콘볼루션 신경망에 대응되는 사람 얼굴 특징 추출 결과에 기반하여, 상 기 식별될 이미지의 사람 얼굴 검출 프레임을 획득한다. 나아가, 상기 행위 식별 모듈은 구체적으로 상기 사람 얼굴 검출 프레임을 상기 위험 주행 행위 식별 모델 중의 콘볼루션 계층에 입력하고, 상기 콘볼루션 계층을 통해 상기 사람 얼굴 검출 프레임에 대해 콘볼루션 연산 을 수행하여, 상기 콘볼루션 계층에 대응되는 사람 얼굴 특징 추출 결과를 획득하며; 상기 콘볼루션 계층에 대 응되는 사람 얼굴 특징 추출 결과를 상기 위험 주행 행위 식별 모델 중의 풀링층에 입력하고, 상기 풀링층을 통 해 상기 콘볼루션 계층에 대응되는 사람 얼굴 검출 프레임에 대해 풀링 연산을 수행하여, 상기 풀링층에 대응되 는 사람 얼굴 특징 추출 결과를 획득하며; 상기 풀링층에 대응되는 사람 얼굴 특징 추출 결과를 상기 위험 주행 행위 모델 중의 완전연결층에 입력하고, 상기 완전연결층을 통해 상기 풀링층에 대응되는 사람 얼굴 특징 추출 결과에 대해 분류 연산을 수행하여, 상기 사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득 한다. 나아가, 상기 장치는 사람 얼굴 검출 트레이닝 모듈(도면에 도시되지 않음)을 더 포함하며, 상기 사람 얼 굴 검출 트레이닝 모듈은 사전에 획득한 첫 번째 사람 얼굴 이미지 샘플을 현재 사람 얼굴 이미지 샘플로 하며; 상기 사람 얼굴 검출 모델이 상기 사람 얼굴 검출 모델에 대응되는 미리 설정된 수렴 조건을 충족하지 못 하는 경우, 상기 현재 사람 얼굴 이미지 샘플을 상기 사람 얼굴 검출 모델에 입력하고, 상기 현재 사람 얼굴 이 미지 샘플을 사용하여 상기 사람 얼굴 검출 모델에 대해 트레이닝을 수행하며; 상기 현재 사람 얼굴 이미지 샘 플의 다음 사람 얼굴 이미지 샘플을 상기 현재 사람 얼굴 이미지 샘플로 하여, 상기 사람 얼굴 검출 모델이 상 기 사람 얼굴 검출 모델에 대응되는 수렴 조건을 충족할 때까지 상기 조작을 반복하여 수행한다. 나아가, 상기 장치는 행위 식별 트레이닝 모듈(도면에 도시되지 않음)을 더 포함하며, 상기 행위 식별 트 레이닝 모듈은 사전에 획득한 첫 번째 사람 얼굴 검출 프레임 샘플을 현재 사람 얼굴 검출 프레임 샘플로 하며; 상기 위험 주행 행위 식별 모델이 상기 위험 주행 행위 식별 모델에 대응되는 미리 설정된 수렴 조건을 충족하지 못하는 경우, 상기 현재 사람 얼굴 검출 프레임 샘플을 상기 위험 주행 행위 식별 모델에 입력하고, 상기 현재 사람 얼굴 검출 프레임 샘플을 사용하여 상기 위험 주행 행위 식별 모델에 대해 트레이닝을 수행하며; 상기 현재 사람 얼굴 검출 프레임 샘플의 다음 사람 얼굴 검출 프레임 샘플을 상기 현재 사람 얼굴 검출 프레임 샘플로 하여, 상기 위험 주행 행위 식별 모델이 상기 위험 주행 행위 식별 모델에 대응되는 수렴 조건을 충족할 때까지 상기 조작을 반복하여 수행한다. 상기 검증 프로세서의 위험 주행 행위 식별 장치는 본 출원의 임의의 실시예에서 제공하는 방법을 수행할 수 있 으며, 수행되는 방법에 대응되는 기능 모듈 및 유리한 효과를 구비한다. 본 실시예에서 상세하게 설명하지 않은 기술적 세부 사항에 대해서는 본 출원의 임의의 실시예에서 제공하는 검증 프로세서의 위험 주행 행위 식별 방 법을 참조할 수 있다. 실시예 5 본 출원의 실시예에서, 본 출원은 전자 설비 및 판독 가능한 저장매체를 더 제공한다. 도 7에 도시된 바와 같이, 도 7은 본 출원의 실시예의 위험 주행 행위 식별 방법에 따른 전자 설비의 블록도이 다. 전자 설비는 각종 형태의 디지털 컴퓨터, 예를 들어, 랩탑 컴퓨터, 데스크톱 컴퓨터, 워크테이블, 개인용 정보 단말기, 서버, 블레이드 서버, 대형 컴퓨터 및 기타 적합한 컴퓨터를 의미한다. 전자 설비는 각종 형태의 모바일 장치, 예를 들어, 개인 디지털 처리, 휴대 전화기, 스마트폰, 웨어러블 설비 및 기타 유사한 컴퓨팅 장 치를 나타낼 수도 있다. 본 문에서 설명된 컴포넌트, 이들의 연결과 관계 및 이들의 기능은 단지 예시적인 것일 뿐, 본 문에서 기술 및/또는 요구한 본 출원의 구현을 한정하지 않는다. 도 7에 도시된 바와 같이, 해당 전자 설비는 하나 또는 복수의 프로세서, 메모리 및 각 컴포넌트를 연결하기 위한 인터페이스를 포함하되, 인터페이스는 고속 인터페이스 및 저속 인터페이스를 포함한다. 각각의 컴포넌트는 서로 다른 버스를 이용하여 서로 연결되고, 공통 메인보드에 장착되거나 수요에 따라 기타 방식으로 장착될 수 있다. 프로세서는 전자 설비 내에서 실행되는 명령을 처리할 수 있고, 메모리에 저장되거나 또는 외 부 입력/출력 장치(예를 들어, 인터페이스에 연결되는 표시설비)에서 GUI의 그래픽 정보를 표시하는 메모리 상 의 명령을 포함한다. 기타 실시형태에서, 필요한 경우, 복수의 프로세서 및/또는 복수의 버스와 복수의 메모리 및 복수의 메모리를 함께 사용할 수 있다. 마찬가지로, 복수의 전자 설비를 연결할 수 있고, 각각의 설비는 일 부 필요한 조작(예를 들어, 서버 어레이, 한 세트의 블레이드 서버, 또는 멀티 프로세서 시스템)을 제공한다. 도 7에서는 하나의 프로세서를 예로 든다. 메모리는 본 출원에서 제공한 비 일시적 컴퓨터 판독가능 저장매체이다. 여기서, 상기 메모리에는 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어, 상기 적어도 하나의 프로세서가 본 출원에서 제공한 위 험 주행 행위 식별 방법을 수행하도록 한다. 본 출원의 비 일시적 컴퓨터 판독가능 저장매체에는 컴퓨터 명령이 저장되고, 해당 컴퓨터 명령은 컴퓨터가 본 출원에서 제공한 위험 주행 행위 식별 방법을 수행하도록 한다. 메모리는 비 일시적 컴퓨터 판독가능 저장매체로서, 비 일시적 소프트웨어 프로그램, 비 일시적 컴퓨터 수 행 가능한 프로그램 및 모듈, 예를 들어, 본 출원의 실시예의 위험 주행 행위 식별 방법에 대응되는 프로그램 명령/모듈(예를 들어, 도 4에 도시된 바와 같은 사람 얼굴 검출 모듈 및 행위 식별 모듈)을 저장할 수 있다. 프로세서는 메모리 내에 저장된 비 일시적 소프트웨어 프로그램, 명령 및 모듈을 실행함으 로써, 서버의 다양한 기능 애플리케이션 및 데이터 처리를 수행하며, 즉 상기 방법 실시예의 위험 주행 행위 식 별 방법을 구현하게 된다. 메모리는 프로그램 저장영역 및 데이터 저장영역을 포함할 수 있고, 여기서, 프로그램 저장영역은 조작 시 스템, 적어도 하나의 기능에 수요되는 응용 프로그램을 저장할 수 있고; 데이터 저장영역은 위험 주행 행위 식 별 방법에 따른 전자 설비를 사용함에 따라 생성된 데이터 등을 저장할 수 있다. 이외, 메모리는 고속 랜 덤 액세스 메모리를 포함할 수 있고, 비 일시적 메모리, 예를 들어 적어도 하나의 자기디스크 메모리 소자, 플 래쉬 메모리 소자 또는 기타 비 일시적 솔리드 스테이트 메모리 소자를 포함할 수도 있다. 일부 실시예에서, 메 모리는 프로세서에 대해 원격으로 설치된 메모리를 선택적으로 포함할 수 있는데, 이러한 원격 메모 리는 네트워크를 통해 위험 주행 행위 식별 방법을 구현하는 전자 설비에 연결될 수 있다. 상기 네트워크의 예 시는 인터넷, 인트라넷, 근거리 통신망, 이동 통신망 및 이들의 조합을 포함하지만 이에 제한되지 않는다. 위험 주행 행위 식별 방법을 구현하는 전자 설비는 입력 장치 및 출력 장치를 더 포함할 수 있다. 프 로세서, 메모리, 입력 장치 및 출력 장치는 버스 또는 기타 방식을 통해 연결될 수 있고, 도 7에서는 버스를 통해 연결되는 경우를 예로 든다. 입력 장치는 입력한 숫자 또는 문자 정보를 수신할 수 있고, 위험 주행 행위 식별 방법을 구현하는 전자 설비의 사용자 설정 및 기능 제어와 관련된 키신호 입력을 생성하며, 예를 들어, 터치 스크린, 키패드, 마우스, 트랙 패드, 터치 패드, 포인팅 스틱, 하나 또는 복수의 마우스 버튼, 트랙볼, 조이스틱 등 입력 장치이다. 출력 장치는 표시설비, 보조 조명장치(예를 들어, LED) 및 촉각 피드백 장치(예를 들어, 진동 모터) 등을 포함 할 수 있다. 해당 표시설비는 액정표시장치(LCD), 발광다이오드(LED) 표시장치 및 플라즈마 표시장치를 포함할 수 있지만 이에 한정되지 않는다. 일부 실시예에서, 표시설비는 터치 스크린일 수 있다. 여기서 설명된 시스템 및 기술의 각종 실시형태는 디지털전자 회로시스템, 집적회로시스템, 전용 ASIC(전용 집 적회로), 컴퓨터 하드웨어, 펌웨어, 소프트웨어, 및/또는 이들의 조합으로 구현될 수 있다. 이러한 각종 실시형 태는 하나 또는 복수의 컴퓨터 프로그램에서 실시되는 것을 포함할 수 있고, 해당 하나 또는 복수의 컴퓨터 프 로그램은 적어도 하나의 프로그래밍 가능한 프로세서를 포함하는 프로그래밍 가능한 시스템에서 실행 및/또는 해석(interpretating)될 수 있으며, 해당 프로그래밍 가능한 프로세서는 전용 또는 범용 프로그래밍 가능한 프 로세서일 수 있고, 저장 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장치로부터 데이터 및 명령을 수신할 수 있으며, 데이터 및 명령을 해당 저장 시스템, 해당 적어도 하나의 입력 장치 및 해당 적어도 하나의출력 장치로 전송한다. 이러한 컴퓨팅 프로그램(프로그램, 소프트웨어, 소프트웨어 애플리케이션 또는 코드로도 칭함)은 프로그래밍 가 능한 프로세서의 기계 명령을 포함하고, 고급 프로세스 및/또는 대상 지향 프로그래밍 언어 및/또는 어셈블리/ 기계 언어를 이용하여 이러한 컴퓨팅 프로그램을 실시한다. 본문에서 사용되는 용어 \"기계 판독가능 매체\" 및 \"컴퓨터 판독가능 매체\"는 기계 명령 및/또는 데이터를 프로그래밍 가능한 프로세서에 제공하기 위한 임의의 컴퓨터 프로그램 제품, 설비 및/또는 장치(예를 들어, 자기디스크, 광디스크, 메모리, 프로그래밍 가능한 로직 장치(PLD))를 의미하며, 기계 판독가능 신호인 기계 명령을 수신하는 기계 판독가능 매체를 포함한다. 용어 \"기 계 판독가능 신호\"는 기계 명령 및/또는 데이터를 프로그래밍 가능한 프로세서에 제공하는 임의의 신호를 의미 한다. 사용자와의 인터랙션을 제공하기 위하여, 컴퓨터에서 여기서 설명된 시스템 및 기술을 실시할 수 있으며, 해당 컴퓨터는 사용자에게 정보를 표시하기 위한 표시장치(예를 들어, CRT(음극선관) 또는 LCD(액정표시장치)모니 터), 키보드 및 방향지시 장치(예를 들어, 마우스 또는 트랙볼)를 구비하며, 사용자는 해당 키보드 및 해당 방 향지시 장치를 통해 컴퓨터에 입력을 제공할 수 있다. 기타 유형의 장치는 사용자와의 인터랙션을 제공할 수도 있으며; 예를 들어, 사용자에게 제공되는 피드백은 임의의 형태의 센싱 피드백(예를 들어, 시각 피드백, 청각 피드백, 또는 촉각 피드백)일 수 있으며; 임의의 형태(사운드 입력, 음성 입력 또는 촉각 입력)로 사용자로부터 의 입력을 수신한다. 여기서 설명된 시스템 및 기술은 백엔드 컴포넌트를 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서버), 또는 미 들웨어 컴포넌트를 포함하는 컴퓨팅 시스템(예를 들어, 애플리케이션 서버), 또는 프런트엔드 컴포넌트를 포함 하는 컴퓨팅 시스템(예를 들어, 그래픽 사용자 인터페이스 또는 웹브라우저를 구비하는 사용자 컴퓨터, 사용자 는 해당 그래픽 사용자 인터페이스 또는 해당 웹브라우저를 통해 여기서 설명된 시스템 및 기술의 실시형태와 인터랙팅함), 또는 이러한 백엔드 컴포넌트, 미들웨어 컴포넌트, 또는 프런트엔드 컴포넌트를 포함하는 임의의 조합의 컴퓨팅 시스템에서 실시할 수 있다. 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트 워크)으로 시스템의 컴포넌트를 서로 연결할 수 있다. 통신 네트워크의 예시는 근거리 통신망(LAN), 광역 네트 워크(WAN), 인터넷 및 블록체인 네트워크를 포함한다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 떨어져 있으며 통상 적으로 통신 네트워크를 통해 인터랙팅한다. 클라이언트와 서버의 관계는 상응하는 컴퓨터에서 작동되고 서로 클라이언트-서버 관계를 갖는 컴퓨터 프로그램에 의해 발생된다. 본 출원의 실시예의 기술방안에 따르면, 우선 식별될 이미지를 사전 트레이닝된 사람 얼굴 검출 모델에 입력하 고, 사람 얼굴 검출 모델을 통해 식별될 이미지에 대해 사람 얼굴 검출을 수행하여, 식별될 이미지의 사람 얼굴 검출 프레임을 획득하며; 다음 사람 얼굴 검출 프레임을 사전 트레이닝된 위험 주행 행위 식별 모델에 입력하고, 위험 주행 행위 식별 모델을 통해 사람 얼굴 검출 프레임에 대해 위험 주행 행위 식별을 수행하여, 사람 얼굴 검출 프레임에 대응되는 위험 주행 행위 식별 결과를 획득한다. 즉, 본 출원은 우선 식별될 이미지에 서 사람 얼굴 검출 프레임을 추출하고, 다음 해당 사람 얼굴 검출 프레임에 기반하여 위험 주행 행위 식별을 수 행할 수 있다. 그러나 종래의 위험 주행 행위 식별 방법에서는 CNN에 기반하여 식별될 이미지를 직접 식별한다. 본 출원은 우선 식별될 이미지에서 사람 얼굴 검출 프레임을 추출한 다음, 해당 사람 얼굴 검출 프레임에 기반 하여 위험 주행 행위 식별을 수행하는 기술수단을 채택함으로써, CNN에 기반하여 식별될 이미지를 직접 식별하 는데, 흡연, 전화 통화, 드링킹 등 타겟 행위가 이미지에서 비교적 작고, 추출 가능한 특징이 적으며, 아울러 주위에 대량의 간섭 정보가 존재하기 때문에, 실제 차량 장면에서의 식별 정확도가 비교적 낮으며 식별 효과가 이상적이지 못한 종래 기술의 기술적 과제를 극복한다. 본 출원에서 제공한 기술방안은 주행자의 위험 주행 행 위를 식별하는 정확도를 대폭 향상시킬 수 있으며, 또한 계산 비용을 대폭 감소시킬 수 있어, 위험 주행 행위에 대한 높은 정확도의 실시간 식별 능력을 획득하게 된다. 또한, 본 출원의 실시예에 따른 기술방안은 구현하기 간단하고 편리하며, 보급이 용이하며, 적용 범위가 보다 넓다. 상술한 각종 형태의 프로세스를 사용하여, 단계의 순서재배정, 추가 또는 삭제를 수행할 수 있음을 이해해야 한 다. 예를 들어, 본 출원에 기재된 각 단계는 병렬로 수행될 수 있거나 순차적으로 수행될 수도 있거나 서로 다 른 순서로 수행될 수도 있으며, 본 출원에서 개시한 기술방안이 희망하는 결과를 달성하기만 하면 되기 때문에, 본문에서는 이에 대해 한정하지 않는다. 상기 구체적인 실시형태는 본 출원의 보호범위를 한정하지 않는다. 본 분야의 당업자는 설계 요구 및 기타 요소 에 따라 다양한 수정, 조합, 부분 조합 및 대체가 가능함을 이해할 수 있을 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2021-7032212", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면은 본 방안을 더 잘 이해하기 위한 것이며, 본 출원을 한정하려는 것이 아니다. 여기서: 도 1은 본 출원의 실시예에서 제공하는 위험 주행 행위 식별 방법의 흐름 개략도이다. 도 2는 본 출원의 실시예에서 제공하는 위험 주행 행위 식별 방법의 흐름 개략도이다. 도 3은 본 출원의 실시예에서 제공하는 위험 주행 행위 식별 방법의 흐름 개략도이다. 도 4는 본 출원의 실시예에서 제공하는 위험 주행 행위 식별 장치의 제1 구조 개략도이다. 도 5는 본 출원의 실시예에서 제공하는 위험 주행 행위 식별 장치의 제2 구조 개략도이다. 도 6은 본 출원의 실시예에서 제공하는 전처리 모듈의 구조 개략도이다. 도 7은 본 출원의 실시예에 따른 위험 주행 행위 식별 방법을 구현하기 위한 전자 설비의 블록도이다."}
