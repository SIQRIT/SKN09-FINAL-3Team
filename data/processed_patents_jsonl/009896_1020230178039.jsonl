{"patent_id": "10-2023-0178039", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0019552", "출원번호": "10-2023-0178039", "발명의 명칭": "생성 모델을 이용한 이미지 편집 방법 및 이를 수행하기 위한 컴퓨팅 장치", "출원인": "삼성전자주식회사", "발명자": "이태미"}}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "생성 모델을 이용하여 이미지를 편집하는 방법에 있어서,입력 이미지에 포함된 적어도 하나의 객체의 이동(movement)을 요청하는 사용자 입력을 수신하는 단계;상기 요청된 객체의 이동에 기초하여 결정되는 방향으로 상기 입력 이미지를 확장하는 단계;상기 확장된 입력 이미지에 기초하여 상기 적어도 하나의 객체에 대한 이미지의 생성이 필요한 영역인 생성 필요 영역(generation required area)을 추론하는 단계; 및적어도 하나의 생성 모델(generative model)을 이용하여 상기 생성 필요 영역에 대한 이미지를 생성하는 단계를포함하는, 방법."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 입력 이미지를 확장하는 단계는,상기 적어도 하나의 객체가 객체의 일부만 표시된 부분 객체(partial object)인지 여부를 판단하는 단계; 및상기 적어도 하나의 객체가 부분 객체인 경우, 상기 요청된 객체의 이동 방향의 반대 방향으로 상기 입력 이미지를 확장하도록 이미지를 생성하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 및 제2항 중 어느 한 항에 있어서,상기 부분 객체인지 여부를 판단하는 단계는,상기 적어도 하나의 객체가 상기 입력 이미지의 테두리(border)들 중에서 적어도 하나의 테두리와 맞닿아 있는지 여부를 확인하는 단계; 및상기 적어도 하나의 객체가 상기 적어도 하나의 테두리와 맞닿아 있다면, 상기 적어도 하나의 객체를 부분 객체로 판단하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,상기 입력 이미지를 확장하도록 이미지를 생성하는 단계는,상기 입력 이미지의 테두리들 중에서 상기 적어도 하나의 객체와 맞닿은 적어도 하나의 테두리를 선택하는단계;상기 요청된 객체의 이동 방향의 반대 방향으로, 상기 선택된 적어도 하나의 테두리를 이동시키는 단계; 및상기 하나 이상의 생성 모델을 이용하여 상기 적어도 하나의 테두리가 이동된 영역까지 이미지를 생성하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서,상기 부분 객체인지 여부를 판단하는 단계는,상기 입력 이미지에 대해 객체 인식을 수행하는 단계; 및상기 적어도 하나의 객체에 대한 인식 결과에 기초하여 상기 객체가 부분 객체인지 여부를 판단하는 단계를 포공개특허 10-2025-0019552-3-함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항 중 어느 한 항에 있어서,상기 생성 필요 영역을 추론하는 단계는,상기 적어도 하나의 객체의 크기 및 상기 적어도 하나의 객체의 방향에 기초하여, 상기 적어도 하나의 객체의이미지의 생성이 필요한 영역을 상기 생성 필요 영역으로 추론하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서,상기 생성 필요 영역을 추론하는 단계는,상기 적어도 하나의 객체를 식별하는 단계; 및상기 식별 결과에 기초하여 상기 적어도 하나의 객체의 이미지의 생성이 필요한 영역을 상기 생성 필요 영역으로 추론하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,상기 생성 필요 영역을 추론하는 단계는,상기 확장된 입력 이미지에서 상기 적어도 하나의 객체를 포함하는 영역을 제1 객체 제안 영역(object proposalarea)으로 추론하는 단계;상기 요청에 따라 상기 적어도 하나의 객체를 이동시키는 단계;상기 제1 객체 제안 영역에 기초하여, 상기 이동된 적어도 하나의 객체에 대응되는 제2 객체 제안 영역을 추론하는 단계; 및상기 제2 객체 제안 영역에 기초하여 상기 생성 필요 영역을 추론하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서,상기 제2 객체 제안 영역에 기초하여 상기 생성 필요 영역을 추론하는 단계는,상기 이동된 적어도 하나의 객체와 상기 제2 객체 제안 영역을 비교함으로써, 상기 이동된 적어도 하나의 객체에 대한 이미지를 추가적으로 생성해야 하는 영역을 제1 생성 필요 영역으로 추론하는 단계; 및상기 객체의 이동으로 인해 배경 이미지를 생성해야 하는 영역을 제2 생성 필요 영역으로 추론하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항 내지 제9항 중 어느 한 항에 있어서,상기 입력 이미지는 제1 생성 모델을 이용하여 확장되고,상기 제1 생성 필요 영역에 대한 이미지는 제2 생성 모델을 이용하여 생성되고,상기 제2 생성 필요 영역에 대한 이미지는 제3 생성 모델을 이용하여 생성되며,상기 제2 생성 모델은 상기 제1 생성 모델 또는 상기 제3 생성 모델에 비해 성능이 높은 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2025-0019552-4-제1항 내지 제10항 중 어느 한 항에 있어서,상기 생성 필요 영역에 대한 이미지를 생성하는 단계는,상기 생성 필요 영역의 위치에 대한 정보, 상기 적어도 하나의 객체의 종류에 대한 정보 및 상기 생성 필요 영역을 포함하는 배경에 대한 정보 중 적어도 하나 이상에 기초하여 프롬프트를 생성하는 단계; 및상기 생성된 프롬프트를 상기 적어도 하나의 생성 모델에 입력하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항 내지 제11항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 비일시적인 기록매체."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "이미지의 처리를 요청하는 사용자 입력을 수신하고, 상기 사용자 입력에 따라 처리된 이미지를 출력하기 위한입출력 인터페이스(1100);이미지를 처리하기 위한 명령들이 저장되는 메모리(1200); 및적어도 하나의 프로세서(1300)를 포함하며,상기 적어도 하나의 프로세서는 상기 명령들을 실행함으로써,입력 이미지에 포함된 적어도 하나의 객체의 이동(movement)을 요청하는 사용자 입력을 수신하면,상기 요청된 객체의 이동에 기초하여 결정되는 방향으로 상기 입력 이미지를 확장하고,상기 확장된 입력 이미지에 기초하여 상기 적어도 하나의 객체에 대한 이미지의 생성이 필요한 영역인 생성 필요 영역(generation required area)을 추론한 후,적어도 하나 이상의 생성 모델(generative model)을 이용하여 상기 생성 필요 영역에 대한 이미지를 생성하는,컴퓨팅 장치."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 적어도 하나의 프로세서(1300)는 상기 입력 이미지를 확장함에 있어서,상기 적어도 하나의 객체가 객체의 일부만 표시된 부분 객체(partial object)인지 여부를 판단한 후,상기 적어도 하나의 객체가 부분 객체인 경우, 상기 요청된 객체의 이동 방향의 반대 방향으로 상기 입력 이미지를 확장하도록 이미지를 생성하는 것을 특징으로 하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항 및 제14항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(1300)는 상기 부분 객체인지 여부를 판단함에 있어서,상기 적어도 하나의 객체가 상기 입력 이미지의 테두리(border)들 중에서 적어도 하나의 테두리와 맞닿아 있는지 여부를 확인한 후,상기 적어도 하나의 객체가 상기 적어도 하나의 테두리와 맞닿아 있다면, 상기 적어도 하나의 객체를 부분 객체로 판단하는 것을 특징으로 하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항 내지 제15항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(1300)는 상기 입력 이미지를 확장하도록 이미지를 생성함에 있어서,상기 입력 이미지의 테두리들 중에서 상기 적어도 하나의 객체와 맞닿은 적어도 하나의 테두리를 선택하고,공개특허 10-2025-0019552-5-상기 요청된 객체의 이동 방향의 반대 방향으로, 상기 선택된 적어도 하나의 테두리를 이동시킨 후,상기 하나 이상의 생성 모델을 이용하여 상기 적어도 하나의 테두리가 이동된 영역까지 이미지를 생성하는 것을특징으로 하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항 내지 제16항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(1300)는 상기 부분 객체인지 여부를 판단함에 있어서,상기 입력 이미지에 대해 객체 인식을 수행한 후,상기 적어도 하나의 객체에 대한 인식 결과에 기초하여 상기 객체가 부분 객체인지 여부를 판단하는 것을 특징으로 하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항 내지 제17항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(1300)는 상기 생성 필요 영역을 추론함에 있어서,상기 적어도 하나의 객체의 크기 및 상기 적어도 하나의 객체의 방향에 기초하여, 상기 적어도 하나의 객체의이미지의 생성이 필요한 영역을 상기 생성 필요 영역으로 추론하는 것을 특징으로 하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제13항 내지 제18항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(1300)는 상기 생성 필요 영역을 추론함에 있어서,상기 적어도 하나의 객체를 식별한 후,상기 식별 결과에 기초하여 상기 적어도 하나의 객체의 이미지의 생성이 필요한 영역을 상기 생성 필요 영역으로 추론하는 것을 특징으로 하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제13항 내지 제19항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(1300)는 상기 생성 필요 영역을 추론함에 있어서,상기 확장된 입력 이미지에서 상기 적어도 하나의 객체를 포함하는 영역을 제1 객체 제안 영역(object proposalarea)으로 추론하고,상기 요청에 따라 상기 적어도 하나의 객체를 이동시키고,상기 제1 객체 제안 영역에 기초하여, 상기 이동된 적어도 하나의 객체에 대응되는 제2 객체 제안 영역을 추론한 후,상기 제2 객체 제안 영역에 기초하여 상기 생성 필요 영역을 추론하는 것을 특징으로 하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제13항 내지 제20항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(1300)는 상기 제2 객체 제안 영역에 기초하여 상기 생성 필요 영역을 추론함에 있어서,상기 이동된 적어도 하나의 객체와 상기 제2 객체 제안 영역을 비교함으로써, 상기 이동된 적어도 하나의 객체에 대한 이미지를 추가적으로 생성해야 하는 영역을 제1 생성 필요 영역으로 추론한 후,상기 객체의 이동으로 인해 배경 이미지를 생성해야 하는 영역을 제2 생성 필요 영역으로 추론하는 것을 특징으로 하는 컴퓨팅 장치.공개특허 10-2025-0019552-6-청구항 22 제13항 내지 제21항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(1300)는,제1 생성 모델을 이용하여 상기 입력 이미지를 확장하고,제2 생성 모델을 이용하여 상기 제1 생성 필요 영역에 대한 이미지를 생성하고,제3 생성 모델을 이용하여 상기 제2 생성 필요 영역에 대한 이미지를 생성하며,상기 제2 생성 모델은 상기 제1 생성 모델 또는 상기 제3 생성 모델에 비해 성능이 높은 것을 특징으로 하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0178039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제13항 내지 제22항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(1300)는 상기 생성 필요 영역에 대한 이미지를 생성함에 있어서,상기 생성 필요 영역의 위치에 대한 정보, 상기 적어도 하나의 객체의 종류에 대한 정보 및 상기 생성 필요 영역을 포함하는 배경에 대한 정보 중 적어도 하나 이상에 기초하여 프롬프트를 생성한 후,상기 생성된 프롬프트를 상기 적어도 하나의 생성 모델에 입력하는 것을 특징으로 하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0178039", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "생성 모델을 이용하여 이미지를 편집하는 방법은, 입력 이미지에 포함된 적어도 하나의 객체의 이동(movement)을 요청하는 사용자 입력을 수신하는 단계, 상기 요청된 객체의 이동에 기초하여 결정되는 방향으로 상기 입력 이미 지를 확장하는 단계, 상기 확장된 입력 이미지에 기초하여 상기 적어도 하나의 객체에 대한 이미지의 생성이 필 요한 영역인 생성 필요 영역(generation required area)을 추론하는 단계 및 적어도 하나의 생성 모델 (generative model)을 이용하여 상기 생성 필요 영역에 대한 이미지를 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0178039", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 생성 모델을 이용하여 이미지를 편집하는 방법에 관한 것으로서, 자세하게는 이미지 내에서 객체의 위치나 크기 등이 변환되는 경우 객체가 변환된 후의 이미지를 편집하는 방법에 관한 것이다."}
{"patent_id": "10-2023-0178039", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "생성형 AI (generative AI) 기술은 방대한 훈련용 데이터의 패턴과 구조를 학습하고, 그에 기초하여 입력 데이 터와 유사한 새로운 데이터를 생성하는 기술을 의미한다. 생성형 AI 기술을 이용하면 텍스트에 대응되는 이미지 를 얻거나, 원본 이미지에는 포함되지 않았던 영역까지 이미지를 확장할 수도 있다. 생성형 AI 기술은 이미지 처리 분야에 적용되어 아웃페인팅(outpainting) 또는 인페인팅(inpainting)을 지원할 수 있다. 이미지의 스타일과 내용을 유지하면서 이미지를 확장하는 것을 아웃페인팅이라고 하고, 이미지 내 특 정 영역에 채워질 이미지를 생성하는 것을 인페인팅이라고 한다. 한편, 최근 사용자 경험을 중시하는 이미지 처리 기술의 발전으로 인해 일부 디바이스나 프로그램은 사용자가 이미지에 포함된 객체들의 위치나 크기를 변환시킬 수 있도록 하는 기능을 지원하기도 한다. 그런데, 객체가 변 환된 후의 이미지에서 객체의 일부가 잘리거나 주변과 어울리지 않게 객체가 표시된다면 사용자의 만족도가 떨 어질 수 있다."}
{"patent_id": "10-2023-0178039", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따른 생성 모델을 이용하여 이미지를 편집하는 방법은, 입력 이미지에 포함된 적어도 하 나의 객체의 이동(movement)을 요청하는 사용자 입력을 수신하는 단계, 상기 요청된 객체의 이동에 기초하여 결 정되는 방향으로 상기 입력 이미지를 확장하는 단계, 상기 확장된 입력 이미지에 기초하여 상기 적어도 하나의 객체에 대한 이미지의 생성이 필요한 영역인 생성 필요 영역(generation required area)을 추론하는 단계 및 적 어도 하나의 생성 모델(generative model)을 이용하여 상기 생성 필요 영역에 대한 이미지를 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 컴퓨팅 장치는 이미지의 처리를 요청하는 사용자 입력을 수신하고, 상기 사용자 입 력에 따라 처리된 이미지를 출력하기 위한 입출력 인터페이스, 이미지를 처리하기 위한 명령들이 저장되는 메모리 및 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는 상기 명령들을 실행함으로써, 입력 이미지에 포함된 적어도 하나의 객체의 이동(movement)을 요청하는 사용자 입력을 수신하면, 상기 요청된 객체 의 이동에 기초하여 결정되는 방향으로 상기 입력 이미지를 확장하고, 상기 확장된 입력 이미지에 기초하여 상 기 적어도 하나의 객체에 대한 이미지의 생성이 필요한 영역인 생성 필요 영역(generation required area)을 추 론한 후, 적어도 하나 이상의 생성 모델(generative model)을 이용하여 상기 생성 필요 영역에 대한 이미지를 생성할 수 있다. 본 개시의 일 실시예에 따른, 컴퓨터로 읽을 수 있는 비일시적인 기록매체는, 개시된 방법의 실시예들 중에서 적어도 하나를 컴퓨터에서 실행시키기 위한 프로그램이 저장된 것일 수 있다. 본 개시의 일 실시예에 따른, 컴퓨터 프로그램은, 개시된 방법의 실시예들 중에서 적어도 하나를 컴퓨터에서 수 행하기 위해 매체에 저장된 것일 수 있다."}
{"patent_id": "10-2023-0178039", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시를 설명함에 있어서 본 개시가 속하는 기술 분야에 익히 알려져 있고 본 개시와 직접적으로 관련이 없는 기술 내용에 대해서는 설명을 생략한다. 이는 불필요한 설명을 생략함으로써 본 개시의 요지를 흐리지 않고 더 욱 명확히 전달하기 위함이다. 그리고 후술되는 용어들은 본 개시에서의 기능을 고려하여 정의된 용어들로서 이 는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 마찬가지 이유로 첨부된 도면에 있어서 일부 구성요소는 과장되거나 생략되거나 개략적으로 도시 되었다. 또한, 각 구성요소의 크기는 실제 크기를 전적으로 반영하는 것이 아니다. 각 도면에서 동일한 또는 대응하는 구성 요 소에는 동일한 참조 번호를 부여하였다. 본 개시의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술 되어 있는 실 시예들을 참조하면 명확해질 것이다. 그러나 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있다. 개시된 실시예들은 본 개시의 개시가 완전하도록 하고, 본 개시가 속하"}
{"patent_id": "10-2023-0178039", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 개시의 범주를 완전하게 알려주기 위해 제공되는 것이다. 본 개시 의 일 실시예는 청구범위에 따라 정의될 수 있다. 명세서 전체에 걸쳐 동일한 참조 부호는 동일한 구성 요소를 나타낸다. 또한, 본 개시의 일 실시예를 설명함에 있어서 관련된 기능 또는 구성에 대한 구체적인 설명이 본 개 시의 요지를 불필요하게 흐릴 수 있다고 판단된 경우 그 상세한 설명은 생략한다. 그리고 후술되는 용어들은 본 개시에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있 다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 일 실시예에서, 흐름도 도면들의 각 블록과 흐름도 도면들의 조합들은 컴퓨터 프로그램 인스트럭션들에 의해 수 행될 수 있다. 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있고, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로 세서를 통해 수행되는 그 인스트럭션들이 흐름도 블록(들)에서 설명된 기능들을 수행하는 수단을 생성할 수 있 다. 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능 하고, 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저장된 인스트럭션들은 흐름도 블록(들)에서 설명된 기 능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생산하는 것도 가능하다. 컴퓨터 프로그램 인스트럭션 들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에 탑재되는 것도 가능하다. 또한, 흐름도 도면의 각 블록은 특정된 논리적 기능(들)을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션 들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 일 실시예에서, 블록들에 언급된 기능들이 순서를 벗어나서 발생하는 것도 가능하다. 예를 들면, 잇달아 도시되어 있는 두 개의 블록들은 실질적으로 동시 에 수행되는 것도 가능하고 또는 기능에 따라 역순으로 수행되는 것도 가능하다. 본 개시의 일 실시예에서 사용되는 '~부'라는 용어는 소프트웨어 또는 FPGA(Field Programmable Gate Array) 또는 ASIC(Application Specific Integrated Circuit)과 같은 하드웨어 구성요소를 나타낼 수 있고, '~부'는 특정한 역할을 수행할 수 있다. 한편, '~부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '~부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구 성될 수도 있다. 일 실시예에서 '~부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구 성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들, 및 변수들을 포함할 수 있다. 특정한 구성요소나 특정한 '~부'를 통해 제공되는 기능은 그 개수를 줄이도록 결합되거나 추가적인 구성요소들로 분리될 수 있다. 또한, 일 실시예에서 ‘~부’는 하나 이상 의 프로세서를 포함할 수 있다. 본 개시의 실시예들은 생성 모델을 이용하여 이미지를 편집하는 방법에 관한 것이다. 구체적인 실시예들을 설명 하기에 앞서 본 명세서에서 자주 사용되는 용어들의 의미를 정의한다. 이미지의 '편집(EDITING)'이란 이미지의 적어도 일부 영역이 변경되도록 이미지를 처리하는 것을 의미할 수 있 다. 본 개시의 실시예들에서는 이미지에 포함된 객체가 변환(이동, 확대, 축소, 회전 등)되면, 이미지 처리를 수행하는 장치는 객체가 변환된 후의 이미지를 생성할 수 있는데, 이를 이미지를 편집한다고 표현할 수 있다. 이미지의 '편집' 대신에 이미지의 '재구성(recomposition)' 등과 같은 용어가 사용될 수도 있다. 객체의 '변환(transformation)'이란 객체의 이동(movement), 객체의 리사이즈(resize)(e.g. 확대 또는 축소), 객체의 회전(rotation) 등을 포함할 수 있다. 본 개시에서는 객체가 이동되는 실시예들을 중심으로 설명한다. 다만, 객체가 이동되는 경우에 대한 실시예들이더라도, 리사이즈 또는 회전 등과 같이 다른 종류의 변환이 객체 에 적용될 수도 있다. 객체의 '변환' 대신에 객체의 '수정(change)' 등과 같은 용어가 사용될 수도 있다. 또한, 객체의 '이동' 대신에 객체의 '옮김(translation)' 등과 같은 용어가 사용될 수도 있다.'부분 객체(partial object)'란 객체의 모습 중 적어도 일부가 이미지상에 표시되지 않은 객체를 의미할 수 있 다. 예를 들어, 객체가 이미지의 가장자리에 위치하여 객체의 일부만 이미지에 표시되고 나머지는 이미지에 표 시되지 않는다면, 해당 객체를 부분 객체라고 할 수 있다. 또는 예를 들어, 객체의 일부분이 다른 객체 또는 배 경에 의해 가려져 표시되지 않는다면, 해당 객체를 부분 객체라고 할 수 있다. 본 개시의 일 실시예에 따르면, 컴퓨팅 장치는 객체가 이미지의 테두리들 중 적어도 하나와 맞닿았는지 여부에 기초하여 객체가 부분 객체인지 를 판단할 수 있다. 또한 본 개시의 일 실시예에 따르면, 컴퓨팅 장치는 이미지에 대해서 객체 인식을 수행하고, 객체를 인식한 결과에 기초하여 객체가 부분 객체인지를 판단할 수도 있다. '부분 객체' 대신에 '불 완전 객체(incomplete object)' 등과 같은 용어가 사용될 수도 있다. '전체 객체(full object)'란 부분 객체의 반대 의미로서, 객체의 전체 모습이 이미지상에 표시되는 객체를 의미 할 수 있다. '전체 객체' 대신에 '완전 객체(complete object)' 또는 '전부 객체(whole object)' 등의 용어가 사용될 수도 있다. '생성형 AI (generative artificial intelligence)'란 입력 데이터(e.g. 텍스트, 이미지 등)에 대응하여 새로 운 텍스트, 이미지 등을 생성할 수 있는 인공지능 기술을 의미할 수 있다. 생성형 AI의 대표적인 예시에 대해서 는 아래의 '생성 모델' 부분에서 설명한다. '생성 모델(generative model)'이란 생성형 AI 기술을 구현하는 신경망 모델(neural network model)을 의미할 수 있다. 생성 모델은 훈련용 데이터의 패턴과 구조를 학습함으로써 입력 데이터와 유사한 특징을 갖는 새로운 데이터 또는 입력 데이터에 대응되는 새로운 데이터를 생성할 수 있다. 예를 들어, 입력 데이터가 이미지이고 생성 모델이 이미지의 확장을 요청받는다면, 생성 모델은 원본 이미지의 내용이나 스타일을 유지하면서 원본 이 미지의 바깥 영역에 새로운 이미지를 생성할 수 있다. 또는 예를 들어, 입력 데이터가 질문을 포함하는 텍스트 라면 생성 모델은 질문에 대한 답변을 생성하여 출력할 수 있다. '객체 제안 영역(object proposal area)'이란 이미지 내에서 객체가 존재하는 것으로 판단 또는 예측되는 영역 을 의미할 수 있다. 일 실시예에 따르면, 이미지 처리를 수행하는 컴퓨팅 장치는 객체를 포함하는 일정 영역 (e.g. 바운딩 박스)을 객체 제안 영역으로 추론(추출)할 수 있다. 또는, 컴퓨팅 장치는 세그멘테이션 (segmentation)을 통해 이미지로부터 객체를 분리하고, 분리된 객체만을 객체 제안 영역으로 추론할 수도 있다. 또는, 컴퓨팅 장치는 세그멘테이션의 수행 결과 분리된 객체뿐만 아니라, 객체 주변의 마진(margin)을 일부 포 함하도록 객체 제안 영역을 추론할 수도 있다. '생성 필요 영역(generation required area)'이란 이미지의 편집을 위해 이미지의 생성이 필요한 영역을 의미할 수 있다. 예를 들어, 이미지 내에서 객체를 이동시킬 경우 원본 이미지에서는 보이지 않던 객체의 부분에 대한 이미지를 생성해야 할 필요가 있는데, 이렇게 새로운 이미지를 생성해야 하는 영역이 생성 필요 영역에 해당될 수 있다. 본 개시의 실시예들에서는 하나 이상의 생성 모델들이 생성 필요 영역에 대한 이미지를 생성할 수 있 다. 본 개시의 실시예들에서는 이미지의 생성이 필요한 최소한의 영역을 생성 필요 영역으로 추론(결정)함으로 써, 생성 모델의 불안정성으로 인해 출력 이미지가 부자연스러워지거나, 이미지의 생성에 많은 시간이 소비되는 것을 방지할 수 있다. '아웃페인팅(outpainting)'이란 이미지의 스타일과 내용을 유지하면서 이미지의 외부 테두리를 확장하는 기술을 의미할 수 있다. 본 개시의 실시예들에서는 역변환을 고려한 입력 이미지의 확장 시 아웃페인팅이 사용될 수 있 다. '인페인팅(inpainting)'이란 이미지 내 특정 영역에 새로운 이미지를 생성하여 채우는 기술을 의미할 수 있다. 본 개시의 일시예들에서는 생성 필요 영역에 대한 이미지 생성 시 인페인팅이 사용될 수 있다. 이하에서는 도면들을 참조하여 본 개시의 실시예들에 따른 생성 모델을 이용하여 이미지를 편집하는 방법 및 이 를 수행하기 위한 컴퓨팅 장치에 대해서 설명한다. 도 1 내지 도 10을 참조하여 설명되는 프로세스들은 이미지 처리 기능을 지원하는 컴퓨팅 장치에 의해 수행된다 고 가정한다. 따라서, 도 1 내지 도 10을 설명함에 있어서 컴퓨팅 장치가 프로세스들을 수행하는 것으로 설명한 다. 일 실시예에 따른 컴퓨팅 장치에 포함되는 세부 구성들은 도 11에 도시하였으며, 해당 구성들에 대해서는 뒤에서 자세히 설명한다. 본 개시의 실시예들에서 컴퓨팅 장치는 이미지를 확장하기 위해 아웃페인팅을 수행하거나, 객체의 변환으로 인 해 이미지 내 새로운 이미지(객체 또는 배경)의 생성이 필요한 경우에는 인페인팅을 수행할 수 있다. 이러한 이미지의 생성은 하나의 생성 모델을 이용해 수행될 수도 있지만, 단계마다 다른 특성을 갖는 생성 모델을 이용함 으로써 효율 및 성능을 높일 수도 있다. 본 개시의 실시예들에서는 다른 특별한 설명이 없는 한 도 12에 도시된 바와 같은 3가지 생성 모델을 이용하여 이미지를 편집한다고 가정한다. 도 12를 참고하면, 제1 생성 모델은 이미지 확장을 위한 아웃페인팅을 수 행하기 위한 모델이다. 제2 생성 모델과 제3 생성 모델은 모두 객체 변환 후 이미지 생성을 위한 인페인팅을 수행하기 위한 모델들인데, 제2 생성 모델은 객체의 이미지를 생성하기 위한 모델이고, 제3 모델은 배경의 이미지를 생성하기 위한 모델이다. 일 실시예에 따르면, 제1 생성 모델은 생성되는 이미지의 품질보다는 생성 속도에 중점을 둔 모델일 수 있다. 객체 제안 영역 추론을 위한 이미지의 확장 시에는 생성되는 이미지의 품질보다 빠른 생성이 중요하기 때 문이다. 이에 반해, 제2 생성 모델은 생성 속도보다는 생성되는 이미지의 품질에 중점을 둔 모델일 수 있 다. 제2 생성 모델에 의해 생성되는 이미지가 출력 이미지에 해당되기 때문이다. 따라서, 제2 생성 모델 은 제1 생성 모델에 비해 성능이 높은 모델일 수 있다. 또한, 제1 생성 모델은 제2 생성 모 델에 비해 생성 속도가 빠른 대신에 출력 데이터의 품질이 낮은 모델일 수 있다. 또한, 배경보다는 객체 의 이미지가 전체 이미지의 품질에 더 많은 영향을 미칠 수 있으므로, 제2 생성 모델은 제3 생성 모델 에 비해 성능이 높은 모델일 수 있다. 물론 이후의 실시예들에서 서로 다른 생성 모델을 이용하는 것으로 설명되는 프로세스들이라도 하나의 동일한 생성 모델을 이용하여 수행될 수도 있음은 자명하다. 도 1은 본 개시의 일 실시예에 따른, 이미지에 포함된 객체 변환 시 생성 모델을 이용하여 이미지를 편집하는 과정을 설명하기 위한 도면이다. 도 1에는 이미지를 처리하는 순서에 따라 제1 단계(1a)에서 제6 단계(1f)에 각 각 대응되는 이미지들을 도시하였다. 도 1을 참고하면, 제1 단계(1a)에서 컴퓨팅 장치는 객체를 포함하는 입력 이미지를 획득할 수 있다. 제2 단 계(1b)에서 컴퓨팅 장치는 객체의 변환(transform)을 요청하는 사용자 입력을 수신할 수 있다. 예를 들어, 사용 자는 입력 이미지가 디스플레이되는 컴퓨팅 장치의 화면에서 객체를 터치하고, 터치를 유지한 상태로 손가 락을 이동시킴으로써 객체의 이동을 요청할 수 있다. 물론, 사용자 입력은 이 밖에도 다양한 형태로 객체 를 선택(특정)하고, 객체의 변환을 요청하도록 구성될 수도 있다. (e.g. 포인터가 객체상에 위치한 상 태에서 마우스의 버튼을 클릭하고, 클릭을 유지한 채로 포인터을 이동시킴) 도 1에 개시된 실시예에서는 사용자가 요청하는 객체의 변환이 객체의 '이동(translation)'인데, 이에 한정 되지 않고 사용자는 객체의 리사이즈(resize)(확대, 축소), 또는 회전(rotation)을 요청할 수도 있다. 제3 단계(1c)에서 컴퓨팅 장치는 사용자가 요청한 변환(이동)을 고려하여, 또는 사용자가 요청한 변환에 대한 역변환을 고려하여 입력 이미지를 확장할 수 있다. 다시 말해, 컴퓨팅 장치는 사용자가 요청한 객체의 이동에 기초하여 결정되는 방향으로 입력 이미지를 확장할 수 있다. 입력 이미지를 확장하기 위해, 컴퓨팅 장치는 앞서 설명한 제1 생성 모델을 이용하여 아웃페인팅을 수행할 수 있다. 제1 생성 모델이 아웃페인팅을 수 행하도록 하기 위해 컴퓨팅 장치는 제1 생성 모델에 아웃페인팅을 지시하는 프롬프트(prompt)를 입력할 수 있다. 예를 들어, 컴퓨팅 장치는 입력 이미지의 테두리들 중 어떤 테두리를 어느 방향으로 얼마의 거리만큼 이동시킴으로써 입력 이미지를 확장하고, 입력 이미지의 특징(e.g. 전체적인 분위기 및 전경과 배경의 내용 등)을 유지하면서 확장된 영역에 대한 이미지를 생성하라는 내용의 프롬프트를 제1 생성 모델에 입력할 수 있다. 컴퓨팅 장치는 사용자 입력(변환 요청)과 입력 이미지에 기초하여 아웃프린팅을 지시하는 프롬프트를 생성할 수 있다. 즉, 컴퓨팅 장치는 이하의 실시예들에서 설명되는 방식에 따라 제1 생성 모델이 아웃프 린팅을 수행하도록 지시하는 프롬프트를 생성할 수 있다. 컴퓨팅 장치가 제3 단계(1c)에서 역변환을 고려하여 입력 이미지를 확장하는 구체적인 방법에 대해서 자세히 설명하면 다음과 같다. 컴퓨팅 장치는 사용자가 변환(이동)을 요청한 객체, 즉 사용자 입력에 의해 선택된 객체가 입력 이미지 의 테두리(border)들 중에서 적어도 하나의 테두리와 맞닿아 있는지 여부를 판단할 수 있다. 도 1을 참고하면, 입력 이미지의 테두리들 중에서 제1 테두리(B1)가 객체와 맞닿아 있음을 알 수 있다. 따라서, 컴퓨팅 장치 는 입력 이미지의 테두리들 중에서, 객체와 맞닿은 제1 테두리(B1)를 선택할 수 있다. 컴퓨팅 장치는 사용자 입력에 따른 변환(이동)에 대한 역변환에 따른 거리 및 방향으로 제1 테두리(B1)를 이동 시킬 수 있다. 다시 말해, 컴퓨팅 장치는 제2 단계(1b)에서 사용자 입력에 의해 요청되는 객체의 이동(거리 및 방향)과 반대로 제1 테두리(B1)를 이동시킬 수 있다. 제2 단계(1b)에서 컴퓨팅 장치가 수신한 사용자 입력은 객체를 좌측 위 대각선 방향으로 이동시키도록 하는 변환 요청을 포함한다. 따라서, 컴퓨팅 장치는 우측 아래 대각선 방향으로 제1 테두리(B1)를 이동시킬 수 있다. 이때, 제1 테두리(B1)가 이동되는 거리는, 제2 단계 (1b)에서 사용자 입력에 의해 객체가 이동되는 거리에 기초하여 결정될 수 있다. 예를 들어, 제1 테두리 (B1)가 이동되는 거리는, 제2 단계(1b)에서 사용자 입력에 의해 객체가 이동되는 거리와 동일할 수 있다. 역변환에 따라 제1 테두리(B1)가 이동되면, 컴퓨팅 장치는 제1 생성 모델을 이용하여 제1 테두리(B1)가 이동된 영역까지 이미지를 생성(아웃페인팅)함으로써 입력 이미지를 확장할 수 있다. 다시 말해, 컴퓨팅 장치는 입력 이미지의 특징을 유지하면서 제1 테두리(B1)가 이동된 영역까지 이미지를 생성하도록 지시하는 프롬프트를 생성 하여 제1 생성 모델에 입력할 수 있다. 컴퓨팅 장치는 이 밖에도 다양한 방법에 따라 입력 이미지를 확장할 수 있다. 또한, 객체에 이동이 아닌 다 른 형태의 변환(리사이즈, 회전 등)이 가해지는 경우에도 컴퓨팅 장치가 입력 이미지를 확장하는 방법은 달라질 수 있다. 이에 대해서는 도 2 내지 도 6을 참조하여 자세히 설명한다. 도 2는 본 개시의 일 실시예에 따른, 이미지에 포함된 객체가 축소되는 경우 역변환을 고려하여 이미지를 확장 하는 방법을 설명하기 위한 도면이다. 도 2에는 이미지를 처리하는 순서에 따라 제1 단계(2a)에서 제3 단계(2 c)에 각각 대응되는 이미지들을 도시하였다. 도 2를 참고하면, 제1 단계(2a)에서 컴퓨팅 장치는 객체를 포함하는 입력 이미지를 획득할 수 있다. 제2 단 계(2b)에서 컴퓨팅 장치는 객체의 축소를 요청하는 사용자 입력을 수신할 수 있다. 예를 들어, 사용자는 입 력 이미지가 디스플레이되는 컴퓨팅 장치의 화면에서 두 손가락으로 객체를 터치하고, 핀치 인(pinch in) 동작을 수행함으로써 객체의 축소를 요청할 수 있다. 제3 단계(2c)에서 컴퓨팅 장치는 사용자가 요청한 변환(축소)에 대한 역변환을 고려하여 입력 이미지를 확장할 수 있다. 구체적으로, 컴퓨팅 장치는 사용자가 축소를 요청한 객체, 즉 사용자 입력에 의해 선택된 객체 가 입력 이미지의 테두리들 중에서 적어도 하나의 테두리와 맞닿아 있는지 여부를 판단할 수 있다. 도 2를 참고하면, 입력 이미지의 테두리들 중에서 제1 테두리(B1)가 객체와 맞닿아 있음을 알 수 있다. 따라서, 컴 퓨팅 장치는 입력 이미지의 테두리들 중에서, 객체와 맞닿은 제1 테두리(B1)를 선택할 수 있다. 컴퓨팅 장치는 사용자 입력에 따른 변환(축소)에 대한 역변환에 따라 제1 테두리(B1)를 이동시킬 수 있다. 다시 말해, 컴퓨팅 장치는 사용자 입력에 의해 객체가 축소되는 비율만큼 입력 이미지가 제1 테두리(B1) 방향으 로 확장되도록 제1 테두리(B1)를 이동시킬 수 있다. (e.g. 사용자 입력에 의해 객체의 크기가 15% 축소된다 면, 컴퓨팅 장치는 제1 테두리 방향(B1)으로 입력 이미지가 15% 확장되도록 제1 테두리(B1)를 이동시킴) 따라서, 제3 단계(2c)에 도시된 바와 같이 컴퓨팅 장치는 객체의 중심에서 멀어지는 방향으로 제1 테두리 (B1)를 이동시키면서, 제1 테두리(B1)의 길이를 연장시킬 수 있다. 역변환에 따라 제1 테두리(B1)가 이동되면, 컴퓨팅 장치는 제1 생성 모델을 이용하여 제1 테두리(B1)가 이동된 영역까지 이미지를 생성함으로써 입력 이미지를 확장할 수 있다. 도 3은 본 개시의 일 실시예에 따른, 이미지에 포함된 객체가 회전되는 경우 역변환을 고려하여 이미지를 확장 하는 방법을 설명하기 위한 도면이다. 도 3에는 이미지를 처리하는 순서에 따라 제1 단계(3a)에서 제3 단계(3 c)에 각각 대응되는 이미지들을 도시하였다. 도 3을 참고하면, 제1 단계(3a)에서 컴퓨팅 장치는 객체를 포함하는 입력 이미지를 획득할 수 있다. 제2 단 계(3b)에서 컴퓨팅 장치는 객체의 회전을 요청하는 사용자 입력을 수신할 수 있다. 예를 들어, 사용자는 입 력 이미지가 디스플레이되는 컴퓨팅 장치의 화면에서 두 손가락으로 객체를 터치하고, 터치를 유지한 채로 객체를 회전시킬 수 있다. 제3 단계(3c)에서 컴퓨팅 장치는 사용자가 요청한 변환(회전)에 대한 역변환을 고려하여 입력 이미지를 확장할 수 있다. 구체적으로, 컴퓨팅 장치는 사용자가 회전을 요청한 객체, 즉 사용자 입력에 의해 선택된 객체 가 입력 이미지의 테두리들 중에서 적어도 하나의 테두리와 맞닿아 있는지 여부를 판단할 수 있다. 도 3을 참고하면, 입력 이미지의 테두리들 중에서 제1 테두리(B1)가 객체와 맞닿아 있음을 알 수 있다. 따라서, 컴 퓨팅 장치는 입력 이미지의 테두리들 중에서, 객체와 맞닿은 제1 테두리(B1)를 선택할 수 있다. 컴퓨팅 장치는 사용자 입력에 따른 변환(회전)에 대한 역변환에 따라 제1 테두리(B1)를 이동시킬 수 있다. 다시 말해, 컴퓨팅 장치는 제2 단계(3b)에서 사용자 입력에 의해 요청되는 객체의 회전(방향 및 각도)과 반대로 제1 테두리(B1)를 이동시킬 수 있다. 제2 단계(3b)에서 수신한 사용자 입력은 객체를 시계 반대 방향으로 회전시키도록 요청하고 있다. 따라서, 제3 단계(3c)에 도시된 바와 같이 컴퓨팅 장치는 제1 테두리(B1)의 왼쪽끝을 축으로 시계 방향으로 제1 테두리(B1)를 회전시킴으로써 제1 테두리(B1)를 이동시킬 수 있다. 이때, 제1 테두리(B1)가 회전하는 각도의 크기는, 제2 단계(3b)에서 사용자 입력에 의해 객체가 회전하는 각도의 크기 에 기초하여 결정될 수 있다. 예를 들어, 제1 테두리(B1)가 회전하는 각도의 크기는, 제2 단계(3b)에서 사용자 입력에 의해 객체가 회전하는 각도의 크기와 동일할 수 있다. 역변환에 따라 제1 테두리(B1)가 이동되면, 컴퓨팅 장치는 제1 생성 모델을 이용하여 제1 테두리(B1)가 이동된 영역까지 이미지를 생성함으로써 입력 이미지를 확장할 수 있다. 일 실시예에 따르면, 컴퓨팅 장치는 사용자 입력에 의해 객체가 선택되면, 객체에 대한 변환 요청이 수 신되기 전이라도 입력 이미지를 확장할 수 있다. 예를 들어, 사용자는 입력 이미지에 포함된 객체를 손가락 으로 일정 시간 이상 터치하고, 터치를 유지한 상태로 손가락을 이동시킴으로써 객체의 이동을 요청할 수 있는데, 컴퓨팅 장치는 사용자가 손가락을 이동시키기 전에 미리 입력 이미지를 확장할 수도 있다. 사용자가 객 체를 선택(일정 시간 이상 터치)한 후 객체를 어떻게 변환시킬지(e.g. 객체를 어디로 이동시킬지) 를 결정하기까지 다소 시간이 걸릴 수 있는데, 컴퓨팅 장치는 사용자가 변환에 대한 결정을 내리기 전에 미리 이미지를 확장해 놓음으로써 이미지가 편집되는 속도를 향상시킬 수 있다. 사용자의 입장에서는 편집된 이미지 가 출력되기까지 걸리는 시간이 단축되므로 사용자 경험이 향상될 수 있다. 일 실시예에 따르면, 컴퓨팅 장치는 객체를 선택하거나 객체의 변환을 요청하는 사용자 입력이 있기도 전에 미리 입력 이미지를 확장시킨 후, 사용자 입력이 수신되면 사용자 입력에 기초하여 객체 제안 영역을 추론 할 수도 있다. 예를 들어, 컴퓨팅 장치는 아웃 페인팅을 통해 원본 이미지를 미리 정해진 비율(e.g. 1.5배)만큼 확장하고, 확장된 원본 이미지를 임시로 저장하고 있다가, 사용자 입력이 수신되면 객체 제안 영역을 추론하기 위한 프로세스를 수행할 수도 있다. 이와 같이 변환될 객체가 선택되기만 하고, 구체적인 변환 요청이 수신되지 않은 상태에서 입력 이미지를 확장한다면 컴퓨팅 장치는 역변환을 고려할 수 없다. 따라서 일 실시예에 따르면, 컴퓨팅 장치는 선택된 객체 의 크기나 위치, 또는 입력 이미지의 크기 등에 기초하여 이미지를 확장할 수 있다. 예를 들어, 컴퓨팅 장 치는 선택된 객체의 길이(테두리의 이동 방향에 평행한 축을 기준으로 측정된 길이)에 따라 결정되는 거리 만큼 입력 이미지의 테두리를 이동시키거나, 또는 선택된 객체가 입력 이미지 내에서 변환 가능한 범위에 기초하여(e.g. 객체가 입력 이미지 내에서 어느 방향으로 얼마만큼 이동이 가능한지에 기초하여) 결정되는 거리만큼 입력 이미지의 테두리를 이동시킬 수 있다. 또는 컴퓨팅 장치는 입력 이미지의 길이(폭 또는 높이)에 기초하여 결정되는 거리만큼 입력 이미지의 테두리를 이동시킬 수도 있다. 이하에서 도 4a, 도 4b 및 도 5를 참 조하여 자세히 설명한다. 도 4a는 본 개시의 일 실시예에 따른, 선택된 객체의 크기에 기초하여 이미지를 확장하는 방법을 설명하기 위한 도면이다. 도 4a에는 이미지를 처리하는 순서에 따라 제1 단계(4aa)에서 제3 단계(4ac)에 각각 대응되는 이미지 들을 도시하였다. 도 4a를 참고하면, 제1 단계(4aa)에서 컴퓨팅 장치는 객체를 포함하는 입력 이미지를 획득할 수 있다. 제2 단계(4ab)에서 컴퓨팅 장치는 객체를 선택하는 사용자 입력을 수신할 수 있다. 예를 들어, 사용자는 제2 단 계(4ab)에서 객체를 일정 시간 이상 손가락으로 터치함으로써 객체를 변환의 대상으로서 선택하지만, 객체의 변환(이동, 리사이즈, 회전 등)을 요청하는 입력은 아직 하지 않은 상태일 수 있다. 또한 일 실시예 에 따르면, 제2 단계(4ab)에서 컴퓨팅 장치는 객체의 변환을 요청하는 사용자 입력을 수신할 수도 있다. 제3 단계(4ac)에서 컴퓨팅 장치는 객체의 크기에 기초하여 입력 이미지를 확장할 수 있다. 입력 이미지를 확장하기 위해, 컴퓨팅 장치는 선택된 객체가 입력 이미지의 테두리들 중에서 적어도 하나의 테두리와 맞닿 아 있는지 여부를 판단할 수 있다. 도 4a를 참고하면, 입력 이미지의 테두리들 중에서 제1 테두리(B1)가 객체 와 맞닿아 있음을 알 수 있다. 따라서, 컴퓨팅 장치는 입력 이미지의 테두리들 중에서, 객체와 맞닿은 제1 테두리(B1)를 선택할 수 있다. 컴퓨팅 장치는 객체의 중심에서 멀어지는 방향으로 제1 테두리(B1)를 이동시킬 수 있으며, 객체의 크기 에 기초하여 제1 테두리(B1)를 이동시킬 거리를 결정할 수 있다. 일 실시예에 따르면, 컴퓨팅 장치는 제1 테두 리(B1)의 이동 방향에 평행한 축을 기준으로 객체의 길이(d1)를 측정할 수 있다. 또한 일 실시예에 따르면, 컴퓨팅 장치는 제1 테두리(B1)에 수직인 축을 기준으로 객체의 길이(d1)를 측정할 수도 있다. 컴퓨팅 장치는 측정된 객체의 길이(d1)에 미리 설정된 비율(e.g. 0.2)을 곱한 거리(d2)만큼 제1 테두리(B 1)를 이동시킬 수 있다. 이때, 거리(d2) 계산 시 사용되는 미리 설정된 비율은 요구되는 이미지의 품질이나 처리 속도 등의 조건에 따라 적절한 값으로 설정될 수 있다. 제1 테두리(B1)가 이동되면, 컴퓨팅 장치는 제1 생성 모델을 이용하여 제1 테두리(B1)가 이동된 영역까지 이미 지를 생성함으로써 입력 이미지를 확장할 수 있다. 도 4b는 본 개시의 일 실시예에 따른, 이미지의 크기에 기초하여 이미지를 확장하는 방법을 설명하기 위한 도면 이다. 도 4b에는 이미지를 처리하는 순서에 따라 제1 단계(4ba)에서 제3 단계(4bc)에 각각 대응되는 이미지들을 도시하였다. 도 4b를 참고하면, 제1 단계(4ba)에서 컴퓨팅 장치는 객체를 포함하는 입력 이미지를 획득할 수 있다. 제2 단계(4bb)에서 컴퓨팅 장치는 객체를 선택하는 사용자 입력을 수신할 수 있다. 예를 들어, 사용자는 제2 단 계(4bb)에서 객체를 일정 시간 이상 손가락으로 터치함으로써 객체를 변환의 대상으로 선택하지만, 객 체의 변환(이동, 리사이즈, 회전 등)을 요청하는 입력은 아직 하지 않은 상태일 수 있다. 또한 일 실시예에 따르면, 제2 단계(4bb)에서 컴퓨팅 장치는 객체의 변환을 요청하는 사용자 입력을 수신할 수도 있다. 제3 단계(4bc)에서 컴퓨팅 장치는 입력 이미지의 크기에 기초하여 입력 이미지를 확장할 수 있다. 예를 들어, 컴퓨팅 장치는 입력 이미지의 길이(폭 또는 높이)에 기초하여 이미지를 확장할 수 있다. 입력 이미지를 확장하 기 위해, 컴퓨팅 장치는 선택된 객체가 입력 이미지의 테두리들 중에서 적어도 하나의 테두리와 맞닿아 있 는지 여부를 판단할 수 있다. 도 4b를 참고하면, 입력 이미지의 테두리들 중에서 제1 테두리(B1)가 객체와 맞닿아 있음을 알 수 있다. 따라서, 컴퓨팅 장치는 입력 이미지의 테두리들 중에서, 객체와 맞닿은 제1 테 두리(B1)를 선택할 수 있다. 컴퓨팅 장치는 객체의 중심에서 멀어지는 방향으로 제1 테두리(B1)를 이동시킬 수 있으며, 입력 이미지의 길이(폭 또는 높이)에 기초하여 제1 테두리(B1)를 이동시킬 거리를 결정할 수 있다. 일 실시예에 따르면, 컴퓨 팅 장치는 제1 테두리(B1)와 수직인 축을 기준으로 입력 이미지의 길이(d1)를 측정할 수 있다. 또한 일 실시예 에 따르면, 컴퓨팅 장치는 제1 테두리(B1)의 이동 방향에 평행한 축을 기준으로 입력 이미지의 길이(d1)를 측정 할 수 있다. 컴퓨팅 장치는 측정된 이미지의 길이(d1)에 미리 설정된 비율(e.g. 0.1)을 곱한 거리(d2)만큼 제1 테두리(B1)를 이동시킬 수 있다. 이때, 거리(d2) 계산 시 사용되는 미리 설정된 비율을 요구되는 이미지의 품질이나 처리 속 도 등의 조건에 따라 적절한 값으로 설정될 수 있다. 제1 테두리(B1)가 이동되면, 컴퓨팅 장치는 제1 생성 모델을 이용하여 제1 테두리(B1)가 이동된 영역까지 이미 지를 생성함으로써 입력 이미지를 확장할 수 있다. 도 5는 본 개시의 일 실시예에 따른, 선택된 객체의 변환 가능한 범위에 기초하여 이미지를 확장하는 방법을 설 명하기 위한 도면이다. 도 5에는 이미지를 처리하는 순서에 따라 제1 단계(5a)에서 제3 단계(5c)에 각각 대응되 는 이미지들을 도시하였다. 도 5를 참고하면, 제1 단계(5a)에서 컴퓨팅 장치는 객체를 포함하는 입력 이미지를 획득할 수 있다. 제2 단 계(5b)에서 컴퓨팅 장치는 객체를 선택하는 사용자 입력을 수신할 수 있다. 예를 들어, 사용자는 제2 단계 (5b)에서 객체를 일정 시간 이상 손가락으로 터치함으로써 객체를 변환의 대상으로서 선택하지만, 객체 의 변환(이동, 리사이즈, 회전 등)을 요청하는 입력을 아직 하지 않은 상태일 수 있다. 또한 일 실시예에 따르면, 제2 단계(5b)에서 컴퓨팅 장치는 객체의 변환을 요청하는 사용자 입력을 수신할 수도 있다. 제3 단계(5c)에서 컴퓨팅 장치는 객체의 변환 가능한 범위에 기초하여 입력 이미지를 확장할 수 있다. 자세 하게는, 컴퓨팅 장치는 객체의 크기 및 위치에 기초하여 객체가 입력 이미지 내에서 변환(e.g. 이동) 가능한 범위를 판단하고, 판단된 범위에 기초하여 입력 이미지를 확장할 수 있다. 입력 이미지를 확장하기 위해, 컴퓨팅 장치는 선택된 객체가 입력 이미지의 테두리들 중에서 적어도 하나의 테두리와 맞닿아 있는지 여부를 판단할 수 있다. 도 5를 참고하면, 입력 이미지의 테두리들 중에서 제1 테두리 (B1)가 객체와 맞닿아 있음을 알 수 있다. 따라서, 컴퓨팅 장치는 입력 이미지의 테두리들 중에서, 객체 와 맞닿은 제1 테두리(B1)를 선택할 수 있다. 컴퓨팅 장치는 객체의 중심에서 멀어지는 방향으로 제1 테두리(B1)를 이동시킬 수 있으며, 객체의 변환 가능한 범위에 기초하여 제1 테두리(B1)를 이동시킬 거리를 결정할 수 있다. 일 실시예에 따르면, 컴퓨팅 장치 는 제3 단계(5c)에서 제1 테두리(B1)의 이동 방향에 평행한 축을 기준으로 객체가 이동 가능한 거리(d1)를 측정할 수 있다. 컴퓨팅 장치는 측정된 거리(d1)에 미리 설정된 비율(e.g. 1)을 곱한 거리(d2)만큼 제1 테두리(B1)를 이동시킬 수 있다. 이때, 거리(d2) 계산 시 사용되는 미리 설정된 비율은 요구되는 이미지의 품질이나 처리 속도 등의 조건에 따라 적절한 값으로 설정될 수 있다. 도 6은 본 개시의 일 실시예에 따른, 역변환 방향에 위치하는 모든 테두리들을 이동시킴으로써 이미지를 확장하 는 방법을 설명하기 위한 도면이다. 도 6에는 이미지를 처리하는 순서에 따라 제1 단계(6a)에서 제3 단계(6c)에 각각 대응되는 이미지들을 도시하였다. 도 6을 참고하면, 제1 단계(6a)에서 컴퓨팅 장치는 객체를 포함하는 입력 이미지를 획득할 수 있다. 제2 단 계(6b)에서 컴퓨팅 장치는 객체의 이동을 요청하는 사용자 입력을 수신할 수 있다. 예를 들어, 사용자는 입 력 이미지가 디스플레이되는 컴퓨팅 장치의 화면에서 객체를 터치하고, 터치를 유지한 상태로 손가락을 이 동시킴으로써 객체의 이동을 요청할 수 있다. 제3 단계(6c)에서 컴퓨팅 장치는 사용자가 요청한 변환(이동)에 대한 역변환을 고려하여 입력 이미지를 확장할 수 있다. 구체적으로, 컴퓨팅 장치는 입력 이미지의 테두리들 중에서 역변환 방향에 위치하는 모든 테두리들을 선택할 수 있다. 제2 단계(6b)에서 컴퓨팅 장치가 수신한 사용자 입력은 객체를 좌측 위 대각선 방향으로 이동시키도록 하는 변환 요청을 포함한다. 역변환 방향은 우측 아래 방향이므로, 컴퓨팅 장치는 하측 및 우측에 위치한 테두리들(B1, B2)을 선택할 수 있다. 컴퓨팅 장치는 사용자 입력에 따른 변환(이동)에 대한 역변환에 따른 거리 및 방향으로 제1 테두리(B1) 및 제2 테두리(B2)를 이동시킬 수 있다. 예를 들어, 컴퓨팅 장치는 제2 단계(6b)에서 수신한 사용자 입력에 의해 객체 가 상측으로 이동되는 거리만큼 제1 테두리(B1)를 하측으로 이동시킬 수 있다. 유사하게 컴퓨팅 장치는 제2 단계(6b)에서 수신한 사용자 입력에 의해 객체가 좌측 방향으로 이동되는 거리만큼 제2 테두리(B2)를 우측 으로 이동시킬 수 있다. 역변환에 따라 제1 테두리(B1) 및 제2 테두리(B2)가 이동되면, 컴퓨팅 장치는 제1 생성 모델을 이용하여 테두리 들(B1, B2)이 이동된 영역까지 이미지를 생성함으로써 입력 이미지를 확장할 수 있다. 지금까지 입력 이미지를 확장하는 다양한 방법들에 대해서 살펴보았다. 다시 도 1로 돌아가서, 제3 단계(1c)에 서 입력 이미지가 확장되면, 컴퓨팅 장치는 제4 단계(1d)에서 객체 제안 영역(100a)을 추론할 수 있다. 한편, 제3 단계(1c)에서 확장된 영역에 포함된 이미지는 이후에 객체 변환 후 인페인팅 수행(e.g. 생성 필요 영역에 대한 이미지 생성) 시 가이드(guide)로서 사용될 수도 있다. 다시 말해, 컴퓨팅 장치는 이후에 객체 변환 후 인 페인팅을 수행할 때, 제3 단계(1c)에서 입력 이미지의 확장 시 생성된 이미지를 참조할 수 있고, 따라서 이미지 생성 효율이 높아질 수 있다. 앞서 설명한 바와 같이 '객체 제안 영역'이란 이미지 내에서 객체가 존재하는 것으로 판단 또는 예측되는 영역을 의미할 수 있다. 컴퓨팅 장치는 확장된 입력 이미지에서 객체를 포함하는 영역을 객체 제안 영역 (100a)으로 추론할 수 있다. 일 실시예에 따르면, 컴퓨팅 장치는 제4 단계(1d)에서 추론한 객체 제안 영역 (100a)에 기초하여, 제5 단계(1e)에서 변환(이동)된 객체에 대응되는 객체 제안 영역(100b)을 추론할 수 있 다. 설명의 편의를 위해, 제4 단계(1d)에서 추론되는 객체 제안 영역(100a)을 제1 객체 제안 영역이라고 하고, 제5 단계(1e)에서 추론되는 객체 제안 영역(100b)을 제2 객체 제안 영역이라고 한다. 제4 단계(1d)에서 컴퓨팅 장치는 바운딩 박스(bounding box) 형태로 제1 객체 제안 영역(100a)을 추론할 수 있 다. 일 실시예에 따르면, 컴퓨팅 장치는 일반적인 보행자 검출 기술에서 사용되는 방식을 통해 객체를 포함 하는 바운딩 박스를 제1 객체 제안 영역(100a)으로 추론할 수 있으며, 그 외 다양한 방식을 통해 제1 객체 제안 영역(100a)을 추론할 수도 있다. 또한 일 실시예에 따르면, 컴퓨팅 장치는 바운딩 박스가 아닌 다른 형태로 제1 객체 제안 영역(100a)을 추론할 수도 있는데, 이에 대해서는 도 7을 참조하여 자세히 설명한다. 도 7은 본 개시의 일 실시예에 따른, 이미지로부터 객체 제안 영역을 추론하는 방법을 설명하기 위한 도면이다. 도 7에는 객체 제안 영역을 추론하는 방식이 서로 다른 3개의 예를 제1 내지 제3화면(7a, 7b, 7c)에 도시하였다. 도 7의 제1 화면(7a)에는 컴퓨팅 장치가 객체를 포함하는 바운딩 박스 형태로 객체 제안 영역(700a)을 추론 하는 예를 도시하였다. 앞서 도 1의 제4 단계(1d)에서 설명한 방식과 동일하다. 도 7의 제2 화면(7b)에는 컴퓨팅 장치가 세그멘테이션(segmentation)을 통해 객체를 분리하고, 분리된 객체 만을 객체 제안 영역(700b)으로 추론하는 예를 도시하였다. 도 7의 제3 화면(7c)에는 컴퓨팅 장치가 세그멘테이션을 통해 객체를 분리하고, 분리된 객체뿐만 아니 라 객체 주변의 마진(margin)을 일부 포함하도록 객체 제안 영역(700c)을 추론하는 예를 도시하였다. 도 1 및 도 8 내지 도 10에 도시된 실시예들에서는 컴퓨팅 장치가 바운딩 박스 형태로 객체 제안 영역을 추론하 지만, 컴퓨팅 장치는 도 7에 도시된 다른 두 가지 방식으로 객체 제안 영역을 추론할 수도 있으며, 그 외 다양 한 방식으로 객체 제안 영역을 추론할 수도 있다. 다시 도 1로 돌아가서, 컴퓨팅 장치는 제4 단계(1d)에서 확장된 입력 이미지로부터 제1 객체 제안 영역(100a)을 추론했으면, 제5 단계(1e)에서 객체를 변환하고 변환된 객체에 대응되는 제2 객체 제안 영역(100b)을 추론할 수 있다. 제5 단계(1e)에서 컴퓨팅 장치가 수행하는 동작을 자세히 설명하면 다음과 같다. 컴퓨팅 장치는, 제2 단계(1b) 에서 수신한 사용자 입력에 포함된 요청에 따라 객체를 변환할 수 있다. 즉, 컴퓨팅 장치는 객체를 입 력 이미지상에서 좌측 위 방향으로 이동시킬 수 있다. 컴퓨팅 장치는 앞서 추론된 제1 객체 제안 영역(100a)에 기초하여, 이동 후 위치에서의 객체에 대응되는 제2 객체 제안 영역(100b)을 추론할 수 있다. 예를 들어, 컴퓨팅 장치는 제1 객체 제안 영역(100a)의 크기 및 형태, 그리고 제1 객체 제안 영역(100a)과 객체 간의 위치 관계 등을 반영하여, 이동된 객체에 대응되는 제2 객체 제안 영역(100b)을 추론할 수 있다. 일 실시예 에 따르면, 제2 객체 제안 영역(100b)에 포함된 객체는 확장되지 않은 입력 이미지로부터 추출된 것이므로 제1 객체 제안 영역(100a)에 포함된 객체보다 작을 수 있다. 그런데 도 1에 도시된 바와 같이, 제2 객체 제 안 영역(100b)은 제1 객체 제안 영역(100a)과 크기가 동일할 수 있으므로, 제2 객체 제안 영역(100b)에는 객체 의 추가적인 이미지의 생성이 필요한 영역이 존재할 수 있다. 컴퓨팅 장치는 이 영역을 생성 필 요 영역(generation required area)으로 추론할 수 있다. 또는 예를 들어, 컴퓨팅 장치는 사용자의 요청에 따라 객체가 이동되는 거리 및 방향으로 제1 객체 제안 영역(100a)을 이동시킴으로써 제2 객체 제안 영역(100b) 을 추론할 수도 있다. 정리하면, 컴퓨팅 장치는 제2 객체 제안 영역(100b)에 기초하여 생성 필요 영역을 추론할 수 있다. 자세하 게는, 컴퓨팅 장치는 변환된 객체와 제2 객체 제안 영역(100b)을 비교함으로써, 변환된 객체에 대한 이 미지를 추가적으로 생성해야 하는 영역을 생성 필요 영역으로 추론할 수 있다. 앞서 설명한 바와 같이 '생성 필요 영역'이란 이미지의 편집을 위해 이미지의 생성이 필요한 영역을 의미할 수 있다. 일 실시예에 따르면, 생성 필요 영역은 객체 부분과 배경 부분으로 구분될 수 있는데, 도 1의 제5 단계 (1e)에서 객체 이미지의 추가적인 생성이 필요한 부분을 제1 생성 필요 영역이라고 하고, 객체의 변환(이동)으로 인해 생기는 빈 공간들(배경 이미지의 추가적인 생성이 필요한 부분)을 제2 생성 필요 영역이라 고 할 수 있다. 즉, 컴퓨팅 장치는 객체의 변환으로 인해 배경 이미지를 생성해야 하는 영역을 제2 생성 필 요 영역으로 추론할 수 있다. 제4 단계(1d) 및 제5 단계(1e)를 정리하면, 컴퓨팅 장치는 확장된 입력 이미지에서 객체를 포함하는 영역을 제1 객체 제안 영역(100a)으로 추론하고, 제2 단계(1b)에서 수신한 사용자 입력에 따라 입력 이미지상에서 객체 를 이동(변환)시킬 수 있다. 이어서, 컴퓨팅 장치는 제1 객체 제안 영역(100a)에 기초하여, 이동된 객체 에 대응되는 제2 객체 제안 영역(100b)을 추론할 수 있다. 마지막으로, 컴퓨팅 장치는 제2 객체 제안 영역 (100b)에 기초하여 제1 생성 필요 영역 및 제2 생성 필요 영역(객체의 이동으로 인해 생기는 빈 공간 들)을 추론할 수 있다. 본 개시의 일 실시예에 따르면, 컴퓨팅 장치는 객체를 고려하여 생성 필요 영역을 추론할 수도 있다. 예를 들어, 컴퓨팅 장치는 객체의 크기 및 객체의 방향(e.g. 객체의 정면이 향하는 방향)에 기초하 여, 객체의 이미지의 생성이 필요한 영역을 결정하고, 결정된 영역을 생성 필요 영역으로 추론할 수도 있다. 또는 예를 들어, 컴퓨팅 장치는 입력 이미지에 대해 객체 인식을 수행함으로써 객체를 식별(e.g. 객 체의 종류를 식별)하고, 객체의 식별 결과(e.g. 객체의 종류)에 기초하여 객체의 이미지의 생성이 필요 한 영역을 결정하고, 결정된 영역을 생성 필요 영역으로 추론할 수도 있다. 제6 단계(1f)에서 컴퓨팅 장치는 제1 생성 필요 영역 및 제2 생성 필요 영역(객체의 이동으로 인해 생 기는 빈 공간들)에 대한 이미지를 생성하여 이미지를 편집하고, 편집된 이미지를 출력할 수 있다. 일 실시예에 따르면 앞서 도 12를 참조하여 설명한 바와 같이, 컴퓨팅 장치는 제2 생성 모델을 이용하여 제1 생성 필요 영역 에 대한 이미지를 생성할 수 있고, 제3 생성 모델을 이용하여 제2 생성 필요 영역에 대한 이미지를 생성할 수 있다. 한편 본 개시의 일 실시예에 따르면, 제5 단계(1e)에서 컴퓨팅 장치는 제2 객체 제안 영역(100b) 전체를 생성 필요 영역으로 추론할 수도 있다. 따라서, 컴퓨팅 장치는 객체 이미지 생성을 위한 제2 생성 모델을 이용하여 제2 객체 제안 영역(100b) 전체에 대해서 새롭게 이미지를 생성할 수도 있다. 이 경우 객체의 변환 후 위치 에서 주변 배경을 반영하여 제2 객체 제안 영역(100b) 전체에 대한 이미지가 생성되므로, 주변 배경과 더 잘 어 울리도록 이미지가 생성되는 효과를 기대할 수 있다. 본 개시의 일 실시예에 따르면, 제6 단계(1f)에서 컴퓨팅 장치는 생성 모델에 생성 필요 영역에 대한 인페인팅 을 지시하는 프롬프트를 입력할 수 있다. 예들 들어, 컴퓨팅 장치는 제5 단계(1e)에서 추론된 제1 생성 필요 영 역에 대해서, 입력 이미지의 특징(e.g. 전체적인 분위기 및 전경과 배경의 내용 등)을 유지하면서 이미지 를 생성하도록 지시하는 프롬프트를 생성하여 제2 생성 모델에 입력할 수 있다. 이를 위해, 컴퓨팅 장치는 사용 자 입력(변환 요청)과 입력 이미지에 기초하여 인페인팅을 지시하는 프롬프트를 생성할 수 있다. 한편, 앞서 설명한 바와 같이 제3 단계(1c)에서 입력 이미지의 확장 시 생성된 이미지는, 제1 생성 필요 영역 에 대한 이미지 생성 시 가이드로 사용될 수 있다. 일 실시예에 따르면, 컴퓨팅 장치는 제3 단계(1c)에서 확장된 입력 이미지에 포함된 객체의 이미지와 유사하게 제1 생성 필요 영역 내 객체의 이미지를 생성하되, 제1 생성 필요 영역 내의 배경과 어울리도록 이미지를 생성할 수 있다. 이를 위해, 컴퓨팅 장치 는 제3 단계(1c)에서 확장된 영역의 이미지의 특징을 유지하면서 제1 생성 필요 영역에 대해서 이미지를 생성하도록 지시하는 프롬프트를 생성하여 제2 생성 모델에 입력할 수 있다. 지금까지는 객체의 변환을 고려하여, 또는 객체의 변환에 대한 역변환을 고려하여 입력 이미지를 확장 한 후 객체 제안 영역을 추론하는 방식의 실시예들에 대해서 설명하였다. 이하에서는 도 8 및 도 9를 참조하여, 입력 이미지를 확장하지 않은 상태에서 객체 제안 영역을 추론하고, 객체의 변환에 대한 역변환을 고려하여 객체 제안 영역을 확장하는 방식의 실시예들에 대해서 설명한다. 이러한 실시예들에 따를 경우, 변환된 객체 의 주변 배경을 반영하여 이미지(객체 제안 영역 내의 이미지)의 확장이 이루어지므로, 앞서 도 1을 참조하 여 설명한 실시예에 비해 객체가 주변 배경과 더 잘 어울리도록 이미지가 생성되는 효과를 기대할 수 있다. 도 8 및 도 9는 입력 이미지를 확장하지 않은 상태에서 객체 제안 영역을 추론하고, 객체의 변환에 대한 역변환 을 고려하여 객체 제안 영역을 확장하는 방식의 실시예들을 설명하기 위한 도면이다. 도 8에는 이미지를 처리하 는 순서에 따라 제1 단계(8a)에서 제8 단계(8h)에 각각 대응되는 이미지들을 도시하였다. 도 9에는 이미지를 처 리하는 순서에 따라 제1 단계(9a)에서 제7 단계(9g)에 각각 대응되는 이미지들을 도시하였다. 도 8을 참고하면, 제1 단계(8a)에서 컴퓨팅 장치는 객체를 포함하는 입력 이미지를 획득할 수 있다. 제2 단 계(8b)에서 컴퓨팅 장치는 객체의 변환을 요청하는 사용자 입력을 수신할 수 있다. 예를 들어, 사용자는 입력 이미지가 디스플레이되는 컴퓨팅 장치의 화면에서 객체를 터치하고, 터치를 유지한 상태로 손가락을 이동시 킴으로써 객체의 이동을 요청할 수 있다. 도 8에 개시된 실시예에서는 사용자가 요청하는 객체의 변환 이 객체의 '이동'인데, 이에 한정되지 않고 사용자는 객체의 리사이즈(확대, 축소), 또는 회전을 요청할 수 도 있다. 제3 단계(8c)에서 컴퓨팅 장치는 입력 이미지에서 객체를 포함하는 영역을 객체 제안 영역(100a)으로 추론 할 수 있다. 일 실시예에 따르면, 컴퓨팅 장치는 제3 단계(8c)에서 추론한 객체 제안 영역(100a)에 기초하여, 제4 단계(8d)에서 변환(이동)된 객체에 대응되는 객체 제안 영역(100b)을 추론할 수 있다. 설명의 편의를 위해, 제3 단계(8c)에서 추론되는 객체 제안 영역(100a)을 제1 객체 제안 영역이라고 하고, 제4 단계(8d)에서 추론되는 객체 제안 영역(100b)을 제2 객체 제안 영역이라고 한다. 제3 단계(8c)에서 컴퓨팅 장치는 바운딩 박스 형태로 제1 객체 제안 영역(100a)을 추론할 수 있다. 일 실시예에 따르면, 컴퓨팅 장치는 일반적인 보행자 검출 기술에서 사용되는 방식을 통해 객체를 포함하는 바운딩 박스 를 제1 객체 제안 영역(100a)으로 추론할 수 있으며, 그 외 다양한 방식을 통해 제1 객체 제안 영역(100a)을 추 론할 수도 있다. 또한 일 실시예에 따르면, 컴퓨팅 장치는 바운딩 박스가 아닌 다른 형태로 제1 객체 제안 영역 (100a)을 추론할 수도 있는데, 이에 대해서는 앞서 도 7을 참조하여 설명한 바와 같다. 컴퓨팅 장치는 제3 단계(8c)에서 입력 이미지로부터 제1 객체 제안 영역(100a)을 추론했으면, 제4 단계(8d)에서 객체를 변환하고 변환된 객체에 대응되는 제2 객체 제안 영역(100b)을 추론할 수 있다. 제4 단계(8d)에서 컴퓨팅 장치가 수행하는 동작을 자세히 설명하면 다음과 같다. 컴퓨팅 장치는, 제2 단계(8b) 에서 수신한 사용자 입력에 포함된 요청에 따라 객체를 변환할 수 있다. 즉, 컴퓨팅 장치는 객체를 입 력 이미지상에서 좌측 위 방향으로 이동시킬 수 있다. 컴퓨팅 장치는 앞서 추출된 제1 객체 제안 영역(100a)에 기초하여, 이동 후 위치에서의 객체에 대응되는 제2 객체 제안 영역(100b)을 추론할 수 있다. 예를 들어,컴퓨팅 장치는 제1 객체 제안 영역(100a)의 크기 및 형태, 그리고 제1 객체 제안 영역(100a)과 객체 간의 위치 관계 등을 반영하여, 이동된 객체에 대응되는 제2 객체 제안 영역(100b)을 추론할 수 있다. 제5 단계(8e)에서 컴퓨팅 장치는 객체의 변환에 대한 역변환을 고려하여 제2 객체 제안 영역(100b)을 확장 할 수 있다. 역변환을 고려하여 제2 객체 제안 영역(100b)을 확장하는 방법은, 앞서 도 1의 제3 단계(1c), 그리 고 도 2 내지 도 6을 참조하여 설명한 방법과 유사할 수 있다. 앞선 실시예들에서 입력 이미지의 테두리들 중에 서 객체와 맞닿은 적어도 하나의 테두리를 역변환에 따른 거리 및 방향으로 이동시켰다. 도 8의 제5 단계 (8e)에서는 제2 객체 제안 영역(100b)의 테두리들 중에서 객체와 맞닿은 적어도 하나의 테두리를 역변환에 따른 거리 및 방향으로 이동시키고, 테두리가 이동된 영역까지 제1 생성 모델을 이용하여 이미지를 생성(아웃페 인팅)할 수 있다. 객체의 변환에 따라서 테두리를 이동시키는 방법은 앞선 실시예들에서 설명한 바와 같을 수 있다. 역변환을 고려하여 확장된 제2 객체 제안 영역(100c)을 제6 단계(8f)에 도시하였다. 제7 단계(8g)에서 컴퓨팅 장치는 확장된 제2 객체 제안 영역(100c)에 기초하여 생성 필요 영역을 추론할 수 있다. 컴퓨팅 장치가 생성 필요 영역을 추론하는 방법에 대해서 자세히 설명하면 다음과 같다. 컴퓨팅 장치는 사용자 입력에 포함된 요청에 따라 객체를 변환(이동)하고, 변환된 객체에 확장된 제2 객체 제 안 영역(100c)을 적용할 수 있다. 컴퓨팅 장치는 변환된 객체와 확장된 제2 객체 제안 영역(100c)을 비교함 으로써, 변환된 객체에 대한 이미지를 추가적으로 생성해야 하는 영역을 생성 필요 영역으로 추론할 수 있다. 제7 단계(8g)에서 확장된 제2 객체 제안 영역(100c)에 포함된 객체는 확장되지 않은 입력 이미지 로부터 추출된 것이므로, 제6 단계(8f)에서 확장된 제2 객체 제안 영역(100c)에 포함된 객체보다 작을 수 있다. 따라서, 확장된 제2 객체 제안 영역(100c)에는 객체의 추가적인 이미지의 생성이 필요한 영역이 존재할 수 있다. 컴퓨팅 장치는 이 영역을 생성 필요 영역으로 추론할 수 있다. 정리하면, 컴퓨팅 장치는 확장된 제2 객체 제안 영역(100c)에 기초하여 생성 필요 영역을 추론할 수 있다. 자세하게는, 컴퓨팅 장치는 변환된 객체와 확장된 제2 객체 제안 영역(100c)을 비교함으로써, 변환된 객체 에 대한 이미지를 추가적으로 생성해야 하는 영역을 생성 필요 영역으로 추론할 수 있다. 일 실시예에 따르면, 생성 필요 영역은 객체 부분과 배경 부분으로 구분될 수 있는데, 도 8의 제7 단계(8g)에서 객체 이미지의 추가적인 생성이 필요한 부분을 제1 생성 필요 영역이라고 하고, 객체의 변환(이동)으로 인해 생기는 빈 공간들(배경 이미지의 추가적인 생성이 필요한 부분)을 제2 생성 필요 영역이라 고 할 수 있다. 즉, 컴퓨팅 장치는 객체의 변환으로 인해 배경 이미지를 생성해야 하는 영역을 제2 생성 필 요 영역으로 추론할 수 있다. 제8 단계(8h)에서 컴퓨팅 장치는 제1 생성 필요 영역 및 제2 생성 필요 영역(객체의 이동으로 인해 생 기는 빈 공간들)에 대한 이미지를 생성하여 이미지를 편집하고, 편집된 이미지를 출력할 수 있다. 일 실시예에 따르면 앞서 도 12를 참조하여 설명한 바와 같이, 컴퓨팅 장치는 제2 생성 모델을 이용하여 제1 생성 필요 영역 에 대한 이미지를 생성할 수 있고, 제3 생성 모델을 이용하여 제2 생성 필요 영역에 대한 이미지를 생성할 수 있다. 이상 설명한 실시예에 따르면, 제5 단계(8e)에서 제2 객체 제안 영역(100b)이 확장됨에 따라, 제6 단계(8f)의 확장된 제2 객체 제안 영역(100c)에는 이미 확장된 객체 이미지가 포함되어 있다. 하지만, 컴퓨팅 장치는 제7 단계(8g)에서 확장 전의 객체(변환으로 인해 위치만 이동된 객체)와 확장된 제2 객체 제안 영역(100c) 을 비교하여 생성 필요 영역을 추론하고, 생성 필요 영역에 대한 이미지를 제2 생성 모델을 이용하여 생성함으로써 객체를 확장한다. 그 이유를 설명하면 다음과 같다. 제6 단계(8f)에서 확장된 제2 객체 제안 영역(100c) 내에 포함된 이미지는 제1 생성 모델을 이용하여 생성된 이 미지이다. 앞서 설명한 바와 같이 제1 생성 모델은 생성 필요 영역을 추론하기 위해 '임시로' 이미지를 확 장할 때 사용되는 모델이다. 그에 반해, 제2 생성 모델은 출력하기 위한 이미지를 생성할 때 사용되는 모델로서, 제1 생성 모델에 비해 정밀한 이미지를 생성할 수 있다. 따라서, 컴퓨팅 장치는 제1 생성 모델을 이 용하여 제2 객체 제안 영역(100b)을 확장한 후 확장된 제2 객체 제안 영역(100c)에 기초하여 생성 필요 영역 을 추론하고, 생성 필요 영역에 대한 이미지는 다시 제2 생성 모델을 이용하여 생성함으로써 출력되 는 이미지의 품질을 향상시킬 수 있다. 일 실시예에 따르면, 제7 단계(8g)에서 생성 필요 영역을 추론하고, 생성 필요 영역에 대한 이미지를 생성하는 과정을 생략하고, 제6 단계(8f)에서 확장된 제2 객체 제안 영역(100c) 내의 이미지를 그대로 사용하여 출력 이미지를 생성할 수도 있다. 이러한 실시예를 도 9에 도시하였다.도 9를 도 8과 비교하면, 도 8의 제7 단계(8g)가 삭제된 것을 제외하면 나머지 단계들은 모두 동일하다. 따라서, 동일한 단계들에 대한 설명은 생략하고 도 9의 제6 단계(9f)에 대해서만 설명한다. 제6 단계(9f)에서 컴퓨팅 장치는 객체의 변환(이동)으로 인해 생기는 빈 공간들(배경 이미지의 추가적인 생 성이 필요한 부분)만을 생성 필요 영역(제2 생성 필요 영역)으로 추론할 수 있다. 제7 단계(9g)에서 컴퓨팅 장 치는 확장된 제2 객체 제안 영역(100c)에 포함된 객체의 이미지를 그대로 사용하고, 제3 생성 모델을 이용 하여 제2 생성 필요 영역에 대한 이미지를 생성함으로써 편집된 이미지를 출력할 수 있다. 이하에서는 도 1에 도시된 실시예에 따른 방법(이하, '제1 방법')과 도 8에 도시된 실시예에 따른 방법(이하, '제2 방법')의 차이점에 대해서 설명한다. 제1 방법의 경우 객체가 변환되기 전의 위치에서 이미지가 확장되므로 객체의 변환 전 위치의 배경을 반영하여 이미지가 생성되고, 그에 따라 객체 제안 영역이 추론될 수 있다. 제2 방법의 경우 객체의 변환된 후의 위치에서 객체 제안 영역이 추론되고, 객체의 변환 후 위치의 배 경을 반영하여 객체 제안 영역이 추론될 수 있다. 따라서, 제1 방법의 객체 제안 영역(도 1의 제4 단계(1d)의 제1 객체 제안 영역(100a))과, 제2 방법의 객체 제 안 영역(도 8의 제6 단계(8f)의 확장된 제2 객체 제안 영역(100c))을 비교하면, 제2 방법의 객체 제안 영역 (100c)이 객체의 변환 후 위치의 주변과 더 잘 어울리도록 추론되고, 따라서 제2 방법에 의할 경우 더 자연 스러운 출력 이미지를 얻는 효과를 기대할 수 있다. 도 10은 객체의 변환에 대한 역변환을 고려하여 입력 이미지를 확장하는 과정에서 생성된 객체 이미지를 그대로 사용하여 이미지를 편집하는 실시예를 설명하기 위한 도면이다. 도 10에는 이미지를 처리하는 순서에 따라 제1 단계(10a)에서 제6 단계(10f)에 각각 대응되는 이미지들을 도시하였다. 도 10을 도 1과 비교하면, 제5 단계(1e, 10e)만이 상이하고 나머지 단계들은 동일하다. 따라서, 동일한 단계들 에 대한 설명은 생략하고 도 10의 제5 단계(10e)에 대해서만 설명한다. 제5 단계(10e)에서 컴퓨팅 장치는 제2 단계(10b)에서 수신한 사용자의 입력에 포함된 요청에 따라 객체를 변환할 수 있다. 즉, 컴퓨팅 장치는 객체를 입력 이미지상에서 좌측 위 방향으로 이동시킬 수 있다. 컴퓨팅 장치는 앞서 추론된 제1 객체 제안 영역(100a)에 기초하여, 이동 후 위치에서의 객체에 대응되는 제2 객체 제안 영역(100b)을 추론할 수 있다. 예를 들어, 컴퓨팅 장치는 제1 객체 제안 영역(100a)의 크기 및 형태, 그리 고 제1 객체 제안 영역(100a)과 객체 간의 위치 관계 등을 반영하여, 이동된 객체에 대응되는 제2 객체 제안 영역(100b)을 추론할 수 있다. 컴퓨팅 장치는 제2 객체 제안 영역(100b)에 들어갈 객체의 이미지를 새롭게 생성하는 대신, 제1 객체 제안 영역(100a)에 포함된 객체의 이미지를 제2 객체 제안 영역(100b)에 삽입할 수 있다. 이어서, 컴퓨팅 장치는 객체의 변환(이동)으로 인해 생기는 빈 공간들(배경 이미지의 추가적인 생성이 필요한 부분)만을 생성 필요 영역(제2 생성 필요 영역)으로 추론할 수 있다. 제6 단계(10f)에서 컴퓨팅 장치는 제3 생성 모델을 이용하여 제2 생성 필요 영역에 대한 이미지를 생성함으로써 편집된 이미지를 출력할 수 있다. 이상 설명한 바와 같이, 도 10에 도시된 실시예에서 컴퓨팅 장치는 객체 제안 영역의 추론을 위한 입력 이미지 의 확장 시 제1 생성 모델에 의해 생성된 객체의 이미지를, 객체의 변환 후 위치에서 그대로 사용함으 로써 처리 속도를 증가시킬 수 있다. 일 실시예에 따르면, 컴퓨팅 장치는 제1 생성 모델에 의해 생성된 객체 의 이미지가, 객체의 변환 후 위치에서의 주변 배경과 잘 어울릴 수 있도록 하기 위해 하모나이저 (harmonizer) 등을 이용하여 객체 이미지의 색상이나 밝기 등을 주변 배경에 따라 조정할 수 있다. 이하에서는 도 11을 참고하여, 지금까지 설명한 이미지 처리 동작들을 수행하기 위한 컴퓨팅 장치의 구성에 대 해서 설명한다. 도 11은 본 개시의 일 실시예에 따른, 생성 모델을 이용한 이미지 편집을 수행하기 위한 컴퓨팅 장치의 구성을 설명하기 위한 도면이다. 도 11을 참고하면, 일 실시예에 따른 컴퓨팅 장치는 입출력 인터페이스, 메모리 및 프로세서 를 포함할 수 있다. 다만, 컴퓨팅 장치의 구성 요소는 전술한 예에 한정되는 것은 아니고, 컴퓨팅 장치는 전술한 구성 요소들보다 더 많은 구성 요소를 포함하거나, 또는 더 적은 구성 요소를 포함할 수 도 있다. 일 실시예에서, 입출력 인터페이스, 메모리 및 프로세서 중 일부 또는 전부는 하나의 칩(chip) 형태로 구현될 수도 있으며, 프로세서는 하나 이상의 프로세서를 포함할 수도 있다. 입출력 인터페이스는 사용자로부터 제어 명령이나 정보 등을 입력받기 위한 입력 인터페이스(e.g. 터치 스크린, 하드 버튼, 마이크 등)와, 사용자의 제어에 따른 동작의 실행 결과나 컴퓨팅 장치의 상태를 표시 하기 위한 출력 인터페이스(e.g. 디스플레이 패널, 스피커 등)를 포함할 수 있다. 메모리는 다양한 프로그램이나 데이터를 저장하기 위한 구성으로서, 롬(ROM), 램(RAM), 하드디스크, CD- ROM 및 DVD 등과 같은 저장 매체 또는 저장 매체들의 조합으로 구성될 수 있다. 메모리는 별도로 존재하 지 않고 프로세서에 포함되도록 구성될 수도 있다. 메모리는 휘발성 메모리, 비휘발성 메모리 또는 휘발성 메모리와 비휘발성 메모리의 조합으로 구성될 수도 있다. 메모리에는 앞서 도 1 내지 도 10을 참 조하여 설명된 실시예들에 따른 동작들을 수행하기 위한 프로그램 또는 명령어들이 저장될 수 있다. 메모리 는 프로세서의 요청에 따라 저장된 데이터를 프로세서에 제공할 수도 있다. 프로세서는 앞서 도 1 내지 도 10을 참조하여 설명된 실시예들에 따라 컴퓨팅 장치가 동작하도록 일련의 과정을 제어하는 구성으로서, 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프 로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 예를 들어, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 프로세서는 메모리에 데이터를 기록하거나, 메모리에 저장된 데이터를 읽을 수 있으며, 특히 메모리에 저장된 프로그램 또는 명령어들을 실행함으로써 미리 정의된 동작 규칙 또는 인공지능 모델에 따라 데이터를 처리할 수 있다. 따라서, 프로세서는 앞서 설명된 실시예들에서 설명되는 동작들을 수행할 수 있으며, 앞서 설명된 실시예들에서 컴퓨팅 장치이 수행한다고 설명된 동작들은 특별한 설명이 없는 한 프로세서가 수행하는 것으로 볼 수 있다. 도 13 내지 도 19는 본 개시의 실시예들에 따른, 생성 모델을 이용하여 이미지를 편집하는 방법을 설명하기 위 한 순서도들이다. 이하에서는 도 13 내지 도 19를 참고하여, 본 개시의 실시예들에 따른 생성 모델을 이용하여 이미지를 편집하는 방법에 대해서 설명한다. 이하에서 설명되는 단계들은 지금까지 설명한 컴퓨팅 장치에 의해 수행되므로, 앞서 설명한 실시예들에서 포함된 내용들은 이하에서 생략되더라도 동일하게 적용될 수 있을 것이다. 도 13을 참고하면, 1301 단계에서 컴퓨팅 장치는 입력 이미지에 포함된 적어도 하나의 객체의 변환을 요청하는 사용자 입력을 수신할 수 있다. 1302 단계에서 컴퓨팅 장치는 사용자의 요청에 따라 적어도 하나의 객체를 변환하고, 변환에 대한 역변환을 고 려하여 이미지의 생성이 필요한 영역인 생성 필요 영역을 추론할 수 있다. 1302 단계는 도 14의 1403 단계와 동 일하므로 이하에서 1403 단계에 대해 설명되는 내용은 1302 단계에도 동일하게 적용될 수 있다. 1303 단계에서 컴퓨팅 장치는 하나 이상의 생성 모델을 이용하여 생성 필요 영역에 대한 이미지를 생성할 수 있 다. 도 14를 참고하면, 1401 단계에서 컴퓨팅 장치는 입력 이미지에 포함된 적어도 하나의 객체의 변환을 요청하는 사용자 입력을 수신할 수 있다. 1402 단계에서 컴퓨팅 장치는 입력 이미지의 테두리들 중에서 적어도 하나의 테두리가 적어도 하나의 객체(변환 요청의 대상이 되는 객체)와 맞닿아 있는지 확인할 수 있다. 판단 결과, 적어도 하나의 테두리가 적어도 하나의 객체와 맞닿아 있지 않다면, 1405 단계로 진행하여 컴퓨팅 장치는 사용자 입력에 포함된 요청에 따라 적어도 하 나의 객체를 변환할 수 있다. 반대로, 판단 결과 적어도 하나의 테두리가 적어도 하나의 객체와 맞닿아 있다면 1403 단계로 진행한다. 1403 단계에서 컴퓨팅 장치는 사용자의 요청에 따라 적어도 하나의 객체를 변환하고, 변환에 대한 역변환을 고 려하여 이미지의 생성이 필요한 영역인 생성 필요 영역을 추론할 수 있다. 1403 단계에 포함되는 세부 단계들을 도 15 및 도 19에 각각 도시하였다. 도 15의 단계들은 앞서 도 1 내지 도 6을 참조하여 설명한 제1 방법에 대응 될 수 있고, 도 19의 단계들은 앞서 도 8 및 도 9를 참조하여 설명한 제2 방법에 대응될 수 있다. 도 15를 참고하면, 1501 단계에서 컴퓨팅 장치는 객체의 변환에 대한 역변환을 고려하여 입력 이미지를 확장할 수 있다. 1501 단계에 포함되는 세부 단계들에 대해서 도 16 내지 도 18을 참조하여 설명한다. 도 16을 참고하면, 1601 단계에서 컴퓨팅 장치는 입력 이미지의 테두리들 중에서 적어도 하나의 객체와 맞닿은 적어도 하나의 테두리를 선택할 수 있다. 1602 단계에서 컴퓨팅 장치는 역변환에 따른 거리 및 방향으로 선택된 적어도 하나의 테두리를 이동시킬 수 있다. 1603 단계에서 컴퓨팅 장치는 하나 이상의 생성 모델을 이용하여 테 두리가 이동된 영역까지 이미지를 생성할 수 있다. 도 17을 참고하면, 1701 단계에서 컴퓨팅 장치는 입력 이미지의 테두리들 중에서 선택된 적어도 하나의 객체와 맞닿은 적어도 하나의 테두리를 선택할 수 있다. 1702 단계에서 컴퓨팅 장치는 선택된 적어도 하나의 테두리를 적어도 하나의 객체의 크기에 따라 결정되는 거리만큼 이동시킬 수 있다. 예를 들어, 컴퓨팅 장치는 선택된 적 어도 하나의 테두리를 적어도 하나의 객체의 길이에 미리 설정된 비율을 곱한 거리만큼 이동시킬 수 있다. 또는 예를 들어, 컴퓨팅 장치는 적어도 하나의 객체가 입력 이미지 내에서 변환 가능한 범위에 기초하여 이동 거리를 결정하고, 선택된 적어도 하나의 테두리를 결정된 이동 거리만큼 이동시킬 수도 있다. 1703 단계에서 컴퓨팅 장치는 하나 이상의 생성 모델을 이용하여 적어도 하나의 테두리가 이동된 영역까지 이미 지를 생성할 수 있다. 도 18을 참고하면, 1801 단계에서 컴퓨팅 장치는 입력 이미지의 테두리들 중에서 선택된 적어도 하나의 객체와 맞닿은 적어도 하나의 테두리를 선택할 수 있다. 1802 단계에서 컴퓨팅 장치는 선택된 적어도 하나의 테두리를, 선택된 적어도 하나의 테두리에 수직인 축을 기준으로 측정된 입력 이미지의 길이에 따라 결정되는 거리만큼 이 동시킬 수 있다. 예를 들어, 컴퓨팅 장치는 선택된 적어도 하나의 테두리를 입력 이미지의 길이에 미리 설정된 비율을 곱한 거리만큼 이동시킬 수 있다. 1803 단계에서 컴퓨팅 장치는 하나 이상의 생성 모델을 이용하여 적어 도 하나의 테두리가 이동된 영역까지 이미지를 생성할 수 있다. 다시 도 15로 돌아와서, 1502 단계에서 컴퓨팅 장치는 확장된 입력 이미지에서 적어도 하나의 객체를 포함하는 영역을 제1 객체 제안 영역으로 추론할 수 있다. 1503 단계에서 컴퓨팅 장치는 1401 단계에서 수신한 사용자 입 력에 포함된 요청에 따라 적어도 하나의 객체를 변환할 수 있다. 1504 단계에서 컴퓨팅 장치는 제1 객체 제안 영역에 기초하여, 변환된 적어도 하나의 객체에 대응되는 제2 객체 제안 영역을 추론할 수 있다. 1505 단계에서 컴퓨팅 장치는 제2 객체 제안 영역에 기초하여 생성 필요 영역을 추론할 수 있다. 도 19를 참고하면, 1901 단계에서 컴퓨팅 장치는 입력 이미지에서 적어도 하나의 객체를 포함하는 영역을 제1 객체 제안 영역으로 추론할 수 있다. 1902 단계에서 컴퓨팅 장치는 1401 단계에서 수신한 사용자 입력에 포함된 요청에 따라 적어도 하나의 객체를 변환할 수 있다. 1903 단계에서 컴퓨팅 장치는 제1 객체 제안 영역에 기초하 여, 변환된 적어도 하나의 객체에 대응되는 제2 객체 제안 영역을 추론할 수 있다. 1904 단계에서 컴퓨팅 장치 는 객체의 변환에 대한 역변환을 고려하여 제2 객체 제안 영역을 확장할 수 있다. 1905 단계에서 컴퓨팅 장치는 확장된 제2 객체 제안 영역에 기초하여 생성 필요 영역을 추론할 수 있다. 다시 도 14로 돌아와서, 1404 단계에서 컴퓨팅 장치는 하나 이상의 생성 모델을 이용하여 생성 필요 영역에 대 한 이미지를 생성할 수 있다. 이하에서는 도 20 내지 도 23을 참조하여 본 개시의 일 실시예에 따른 생성 모델을 이용하여 이미지를 편집하는 방법에 대해서 설명한다. 도 20을 참고하면, 2001 단계에서 컴퓨팅 장치는 입력 이미지에 포함된 적어도 하나의 객체의 이동을 요청하는 사용자 입력을 수신할 수 있다. 앞서 설명한 바와 같이 사용자는 다양한 방식으로 입력 이미지에 포함된 객체의 이동을 요청할 수 있다. 2002 단계에서 컴퓨팅 장치는 요청된 객체의 이동에 기초하여 결정되는 방향으로 입력 이미지를 확장할 수 있다. 컴퓨팅 장치는 요청된 객체의 이동을 고려하여 입력 이미지를 확장할 방향을 결정할 수 있다. 예를 들어, 컴퓨팅 장치는 객체의 이동 방향의 반대 방향을 입력 이미지의 확장 방향으로 결정할 수 있다. 도 21에는 2002 단계에 포함되는 세부 단계들을 도시하였다. 도 21을 참고하면, 2101 단계에서 컴퓨팅 장치는 적어도 하나의 객체가 객체의 일부만 표시된 부분 객체 (partial object)인지 여부를 판단할 수 있다. 본 개시의 일 실시예에 따르면, 컴퓨팅 장치는 입력 이미지에 대 해 객체 인식을 수행한 후, 적어도 하나의 객체에 대한 인식 결과에 기초하여 객체가 부분 객체인지 여부를 판 단할 수 있다. 또는 본 개시의 일 실시예에 따르면, 컴퓨팅 장치는 객체가 입력 이미지의 테두리와 맞닿아 있는 지 여부에 기초하여 부분 객체인지 여부를 판단할 수도 있다. 2101 단계에 포함되는 세부 단계들을 도 22에 도시하였다. 도 22를 참고하면, 2201 단계에서 컴퓨팅 장치는 적어도 하나의 객체가 입력 이미지의 테두리들 중에서 적어도 하나의 테두리와 맞닿아 있는지 여부를 확인할 수 있다. 이어서 2202 단계에서 컴퓨팅 장치는 적어도 하나의 객 체가 적어도 하나의 테두리와 맞닿아 있다면, 적어도 하나의 객체를 부분 객체로 판단할 수 있다. 다시 도 21로 돌아가서, 2102 단계에서 컴퓨팅 장치는 적어도 하나의 객체가 부분 객체인 경우, 요청된 객체의 이동 방향의 반대 방향으로 입력 이미지를 확장하도록 이미지를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 컴퓨팅 장치는 입력 이미지의 테두리들 중에서 적어도 하나의 객체와 맞닿은 적어도 하나의 테두리를 선택하고, 선택된 적어도 하나의 테두리를 요청된 객체의 이동 방향의 반대 방향으로 이동시킨 후, 하나 이상의 생성 모델을 이용하여 적어도 하나의 테두리가 이동된 영역까지 이미지를 생성할 수 있다. 다시 도 20으로 돌아가서, 2003 단계에서 컴퓨팅 장치는 확장된 입력 이미지에 기초하여 적어도 하나의 객체에 대한 이미지의 생성이 필요한 영역인 생성 필요 영역을 추론할 수 있다. 본 개시의 일 실시예에 따르면, 컴퓨팅 장치는 적어도 하나의 객체의 크기 및 적어도 하나의 객체의 방향에 기초하여, 적어도 하나의 객체의 이미지의 생성이 필요한 영역을 생성 필요 영역으로 추론할 수 있다. 또는 본 개시의 일 실시예에 따르면, 컴퓨팅 장치는 입력 이미지에 포함된 적어도 하나의 객체를 식별(e.g. 객체의 종류 파악)한 후, 식별 결과(e.g. 객체의 종류) 에 기초하여 적어도 하나의 객체의 이미지의 생성이 필요한 영역을 생성 필요 영역으로 추론할 수도 있다. 또는 본 개시의 일 실시예에 따르면, 컴퓨팅 장치는 확장된 입력 이미지에서 객체를 포함하는 영역을 객체 제안 영역 으로 추론한 후, 객체 제안 영역에 기초하여 생성 필요 영역을 추론할 수도 있다. 2003 단계에 포함되는 세부 단계들을 도 23에 도시하였다. 도 23을 참고하면, 2301 단계에서 컴퓨팅 장치는 확장된 입력 이미지에서 적어도 하나의 객체를 포함하는 영역 을 제1 객체 제안 영역으로 추론할 수 있다. 2302 단계에서 컴퓨팅 장치는 요청에 따라 적어도 하나의 객체를 이동시킬 수 있다. 2303 단계에서 컴퓨팅 장치는 제1 객체 제안 영역에 기초하여, 이동된 적어도 하나의 객체에 대응되는 제2 객체 제안 영역을 추론할 수 있다. 2304 단계에서 컴퓨팅 장치는 제2 객체 제안 영역에 기초하여 생성 필요 영역을 추론할 수 있다. 본 개시의 일 실시예에 따르면, 컴퓨팅 장치는 이동된 적어도 하나의 객체와 제2 객체 제안 영역을 비교함으로써, 이동된 적 어도 하나의 객체에 대한 이미지를 추가적으로 생성해야 하는 영역을 제1 생성 필요 영역으로 추론하고, 객체의 이동으로 인해 배경 이미지를 생성해야 하는 영역을 제2 생성 필요 영역으로 추론할 수 있다. 컴퓨팅 장치가 제1 객체 제안 영역, 제2 객체 제안 영역 및 생성 필요 영역을 추론하는 구체적인 방법은, 앞서 도 1을 참조하여 설명한 바와 같다. 다시 도 20으로 돌아와서, 2004 단계에서 컴퓨팅 장치는 적어도 하나의 생성 모델을 이용하여 생성 필요 영역에 대한 이미지를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 컴퓨팅 장치는 생성 필요 영역의 위치에 대한 정보, 적어도 하나의 객체의 종류에 대한 정보 및 생성 필요 영역을 포함하는 배경에 대한 정보 중 적어도 하나 이상에 기초하여 프롬프트를 생성하고, 생성된 프롬프트를 적어도 하나의 생성 모델에 입력함으로써 생성 필요 영역에 대한 이미지를 생성할 수 있다. 이상 설명한 실시예들에 따라, 사용자로부터 이미지에 포함된 객체에 대한 변환 요청이 있는 경우, 변환에 대한 역변환을 고려하여 이미지의 생성이 필요한 영역(생성 필요 영역)을 추론하고, 추론된 생성 필요 영역에 대해서 생성 모델을 이용하여 이미지를 생성함으로써 변환된 객체가 주변 배경과 잘 어울리도록 이미지를 편집할 수 있 다. 또한, 이미지의 생성이 필요한 최소한의 영역을 생성 필요 영역으로 추론함으로써 이미지 처리 속도 및 효 율을 향상시킬 수 있다. 편집편집일 실시예에 따른, 생성 모델을 이용하여 이미지를 편집하는 방법은, 입력 이미지에 포함된 적어도 하 나의 객체의 이동(movement)을 요청하는 사용자 입력을 수신하는 단계, 상기 요청된 객체의 이동에 기초하여 결 정되는 방향으로 상기 입력 이미지를 확장하는 단계, 상기 확장된 입력 이미지에 기초하여 상기 적어도 하나의 객체에 대한 이미지의 생성이 필요한 영역인 생성 필요 영역(generation required area)을 추론하는 단계 및 적 어도 하나의 생성 모델(generative model)을 이용하여 상기 생성 필요 영역에 대한 이미지를 생성하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 입력 이미지를 확장하는 단계는, 상기 적어도 하나의 객체가 객체의 일부만 표시된 부분 객체(partial object)인지 여부를 판단하는 단계 및 상기 적어도 하나의 객체가 부분 객체인 경우, 상기 요청된 객체의 이동 방향의 반대 방향으로 상기 입력 이미지를 확장하도록 이미지를 생성하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 부분 객체인지 여부를 판단하는 단계는, 상기 적어도 하나의 객체가 상기 입력 이미 지의 테두리(border)들 중에서 적어도 하나의 테두리와 맞닿아 있는지 여부를 확인하는 단계 및 상기 적어도 하 나의 객체가 상기 적어도 하나의 테두리와 맞닿아 있다면, 상기 적어도 하나의 객체를 부분 객체로 판단하는 단 계를 포함할 수 있다. 일 실시예에 따르면, 상기 입력 이미지를 확장하도록 이미지를 생성하는 단계는, 상기 입력 이미지의 테두리들 중에서 상기 적어도 하나의 객체와 맞닿은 적어도 하나의 테두리를 선택하는 단계, 상기 요청된 객체의 이동 방 향의 반대 방향으로, 상기 선택된 적어도 하나의 테두리를 이동시키는 단계 및 상기 하나 이상의 생성 모델을 이용하여 상기 적어도 하나의 테두리가 이동된 영역까지 이미지를 생성하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 부분 객체인지 여부를 판단하는 단계는, 상기 입력 이미지에 대해 객체 인식을 수행 하는 단계 및 상기 적어도 하나의 객체에 대한 인식 결과에 기초하여 상기 객체가 부분 객체인지 여부를 판단하 는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 생성 필요 영역을 추론하는 단계는, 상기 적어도 하나의 객체의 크기 및 상기 적어도 하나의 객체의 방향에 기초하여, 상기 적어도 하나의 객체의 이미지의 생성이 필요한 영역을 상기 생성 필요 영 역으로 추론할 수 있다. 일 실시예에 따르면, 상기 생성 필요 영역을 추론하는 단계는, 상기 적어도 하나의 객체를 식별하는 단계 및 상 기 식별 결과에 기초하여 상기 적어도 하나의 객체의 이미지의 생성이 필요한 영역을 상기 생성 필요 영역으로 추론하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 생성 필요 영역을 추론하는 단계는, 상기 확장된 입력 이미지에서 상기 적어도 하나 의 객체를 포함하는 영역을 제1 객체 제안 영역(object proposal area)으로 추론하는 단계, 상기 요청에 따라 상기 적어도 하나의 객체를 이동시키는 단계, 상기 제1 객체 제안 영역에 기초하여, 상기 이동된 적어도 하나의 객체에 대응되는 제2 객체 제안 영역을 추론하는 단계 및 상기 제2 객체 제안 영역에 기초하여 상기 생성 필요 영역을 추론하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 제2 객체 제안 영역에 기초하여 상기 생성 필요 영역을 추론하는 단계는, 상기 이동 된 적어도 하나의 객체와 상기 제2 객체 제안 영역을 비교함으로써, 상기 이동된 적어도 하나의 객체에 대한 이 미지를 추가적으로 생성해야 하는 영역을 제1 생성 필요 영역으로 추론하는 단계 및 상기 객체의 이동으로 인해 배경 이미지를 생성해야 하는 영역을 제2 생성 필요 영역으로 추론하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 입력 이미지는 제1 생성 모델을 이용하여 확장되고, 상기 제1 생성 필요 영역에 대한 이미지는 제2 생성 모델을 이용하여 생성되고, 상기 제2 생성 필요 영역에 대한 이미지는 제3 생성 모델을 이용 하여 생성되며, 상기 제2 생성 모델은 상기 제1 생성 모델 또는 상기 제3 생성 모델에 비해 성능이 높을 수 있 다. 일 실시예에 따르면, 상기 생성 필요 영역에 대한 이미지를 생성하는 단계는, 상기 생성 필요 영역의 위치에 대 한 정보, 상기 적어도 하나의 객체의 종류에 대한 정보 및 상기 생성 필요 영역을 포함하는 배경에 대한 정보 중 적어도 하나 이상에 기초하여 프롬프트를 생성하는 단계 및 상기 생성된 프롬프트를 상기 적어도 하나의 생 성 모델에 입력하는 단계를 포함할 수 있다. 일 실시예에 따른 컴퓨팅 장치는, 이미지의 처리를 요청하는 사용자 입력을 수신하고, 상기 사용자 입력에 따라 처리된 이미지를 출력하기 위한 입출력 인터페이스, 이미지를 처리하기 위한 명령들이 저장되는 메모리 및 적어 도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는 상기 명령들을 실행함으로써, 입력 이미지에 포함된 적어도 하나의 객체의 이동(movement)을 요청하는 사용자 입력을 수신하면, 상기 요청된 객체의 이동에 기초하여 결정되는 방향으로 상기 입력 이미지를 확장하고, 상기 확장된 입력 이미지에 기초하여 상기 적어도 하나의 객체에 대한 이미지의 생성이 필요한 영역인 생성 필요 영역(generation required area)을 추론한 후, 적어도 하나 이상의 생성 모델(generative model)을 이용하여 상기 생성 필요 영역에 대한 이미지를 생성할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는 상기 입력 이미지를 확장함에 있어서, 상기 적어도 하나의 객체가 객체의 일부만 표시된 부분 객체(partial object)인지 여부를 판단한 후, 상기 적어도 하나의 객체가 부 분 객체인 경우, 상기 요청된 객체의 이동 방향의 반대 방향으로 상기 입력 이미지를 확장하도록 이미지를 생성 할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는 상기 부분 객체인지 여부를 판단함에 있어서, 상기 적어도 하나의 객체가 상기 입력 이미지의 테두리(border)들 중에서 적어도 하나의 테두리와 맞닿아 있는지 여부를 확 인한 후, 상기 적어도 하나의 객체가 상기 적어도 하나의 테두리와 맞닿아 있다면, 상기 적어도 하나의 객체를 부분 객체로 판단할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는 상기 입력 이미지를 확장하도록 이미지를 생성함에 있어서, 상기 입력 이미지의 테두리들 중에서 상기 적어도 하나의 객체와 맞닿은 적어도 하나의 테두리를 선택 하고, 상기 요청된 객체의 이동 방향의 반대 방향으로, 상기 선택된 적어도 하나의 테두리를 이동시킨 후, 상기 하나 이상의 생성 모델을 이용하여 상기 적어도 하나의 테두리가 이동된 영역까지 이미지를 생성할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는 상기 부분 객체인지 여부를 판단함에 있어서, 상기 입력 이미지에 대해 객체 인식을 수행한 후, 상기 적어도 하나의 객체에 대한 인식 결과에 기초하여 상기 객체가 부 분 객체인지 여부를 판단할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는 상기 생성 필요 영역을 추론함에 있어서, 상기 적어도 하 나의 객체의 크기 및 상기 적어도 하나의 객체의 방향에 기초하여, 상기 적어도 하나의 객체의 이미지의 생성이 필요한 영역을 상기 생성 필요 영역으로 추론할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는 상기 생성 필요 영역을 추론함에 있어서, 상기 적어도 하 나의 객체를 식별한 후, 상기 식별 결과에 기초하여 상기 적어도 하나의 객체의 이미지의 생성이 필요한 영역을 상기 생성 필요 영역으로 추론할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는 상기 생성 필요 영역을 추론함에 있어서, 상기 확장된 입 력 이미지에서 상기 적어도 하나의 객체를 포함하는 영역을 제1 객체 제안 영역(object proposal area)으로 추 론하고, 상기 요청에 따라 상기 적어도 하나의 객체를 이동시키고, 상기 제1 객체 제안 영역에 기초하여, 상기 이동된 적어도 하나의 객체에 대응되는 제2 객체 제안 영역을 추론한 후, 상기 제2 객체 제안 영역에 기초하여 상기 생성 필요 영역을 추론할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는 상기 제2 객체 제안 영역에 기초하여 상기 생성 필요 영역 을 추론함에 있어서, 상기 이동된 적어도 하나의 객체와 상기 제2 객체 제안 영역을 비교함으로써, 상기 이동된 적어도 하나의 객체에 대한 이미지를 추가적으로 생성해야 하는 영역을 제1 생성 필요 영역으로 추론한 후, 상 기 객체의 이동으로 인해 배경 이미지를 생성해야 하는 영역을 제2 생성 필요 영역으로 추론할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 제1 생성 모델을 이용하여 상기 입력 이미지를 확장하고, 제2 생성 모델을 이용하여 상기 제1 생성 필요 영역에 대한 이미지를 생성하고, 제3 생성 모델을 이용하여 상기 제2 생성 필요 영역에 대한 이미지를 생성하며, 상기 제2 생성 모델은 상기 제1 생성 모델 또는 상기 제3 생성 모델에 비해 성능이 높을 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는 상기 생성 필요 영역에 대한 이미지를 생성함에 있어서, 상기 생성 필요 영역의 위치에 대한 정보, 상기 적어도 하나의 객체의 종류에 대한 정보 및 상기 생성 필요 영 역을 포함하는 배경에 대한 정보 중 적어도 하나 이상에 기초하여 프롬프트를 생성한 후, 상기 생성된 프롬프트 를 상기 적어도 하나의 생성 모델에 입력할 수 있다. 일 실시예에 따른, 생성 모델을 이용하여 이미지를 편집하는 방법은, 입력 이미지에 포함된 적어도 하나의 객체 의 변환을 요청하는 사용자 입력을 수신하는 단계, 상기 입력 이미지의 테두리(border)들 중에서 적어도 하나의 테두리가 상기 적어도 하나의 객체와 맞닿아 있는지 여부를 확인하는 단계, 상기 적어도 하나의 테두리가 상기 적어도 하나의 객체와 맞닿아 있다면, 상기 요청에 따라 상기 적어도 하나의 객체를 변환하고, 상기 변환에 대 한 역변환을 고려하여 이미지의 생성이 필요한 영역인 생성 필요 영역(generation required area)을 추론하는 단계 및 하나 이상의 생성 모델(generative model)을 이용하여 상기 생성 필요 영역에 대한 이미지를 생성하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 생성 필요 영역을 추론하는 단계는, 상기 역변환을 고려하여 상기 입력 이미지를 확 장하는 단계, 상기 확장된 입력 이미지에서 상기 적어도 하나의 객체를 포함하는 영역을 제1 객체 제안 영역(object proposal area)으로 추론하는 단계, 상기 요청에 따라 상기 적어도 하나의 객체를 변환하는 단계, 상기 제1 객체 제안 영역에 기초하여, 상기 변환된 적어도 하나의 객체에 대응되는 제2 객체 제안 영역을 추론하는 단계 및 상기 제2 객체 제안 영역에 기초하여 상기 생성 필요 영역을 추론하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 입력 이미지를 확장하는 단계는, 상기 입력 이미지의 테두리(border)들 중에서 상기 적어도 하나의 객체와 맞닿은 적어도 하나의 테두리를 선택하는 단계, 상기 역변환에 따른 거리 및 방향으로, 상기 선택된 적어도 하나의 테두리를 이동시키는 단계 및 상기 하나 이상의 생성 모델을 이용하여 상기 적어도 하나의 테두리가 이동된 영역까지 이미지를 생성하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 입력 이미지를 확장하는 단계는, 상기 입력 이미지의 테두리들 중에서 상기 선택된 적어도 하나의 객체와 맞닿은 적어도 하나의 테두리를 선택하는 단계, 상기 선택된 적어도 하나의 테두리를 상 기 적어도 하나의 객체의 크기에 따라 결정되는 거리만큼 이동시키는 단계 및 상기 하나 이상의 생성 모델을 이 용하여 상기 적어도 하나의 테두리가 이동된 영역까지 이미지를 생성하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 객체의 크기에 따라 결정되는 거리만큼 이동시키는 단계는, 상기 적어 도 하나의 객체의 길이에 미리 설정된 비율을 곱한 거리만큼 상기 선택된 적어도 하나의 테두리를 이동시킬 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 객체의 크기에 따라 결정되는 거리만큼 이동시키는 단계는, 상기 적어 도 하나의 객체가 상기 입력 이미지 내에서 변환 가능한 범위에 기초하여 이동 거리를 결정하고, 상기 결정된 이동 길이만큼 상기 선택된 적어도 하나의 테두리를 이동시킬 수 있다. 일 실시예에 따르면, 상기 입력 이미지를 확장하는 단계는, 상기 입력 이미지의 테두리들 중에서 상기 선택된 적어도 하나의 객체와 맞닿은 적어도 하나의 테두리를 선택하는 단계, 상기 선택된 적어도 하나의 테두리를, 상 기 선택된 적어도 하나의 테두리에 수직인 축을 기준으로 측정된 상기 입력 이미지의 길이에 따라 결정되는 거 리만큼 이동시키는 단계 및 상기 하나 이상의 생성 모델을 이용하여 상기 적어도 하나의 테두리가 이동된 영역 까지 이미지를 생성하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 입력 이미지의 길이에 따라 결정되는 거리만큼 이동시키는 단계는, 상기 입력 이미지 의 길이에 미리 설정된 비율을 곱한 거리만큼 상기 선택된 적어도 하나의 테두리를 이동시킬 수 있다. 일 실시예에 따르면, 상기 제2 객체 제안 영역에 기초하여 상기 생성 필요 영역을 추론하는 단계는, 상기 변환 된 적어도 하나의 객체와 상기 제2 객체 제안 영역을 비교함으로써, 상기 변환된 적어도 하나의 객체에 대한 이 미지를 추가적으로 생성해야 하는 영역을 제1 생성 필요 영역으로 추론하는 단계 및 상기 객체의 변환으로 인해 배경 이미지를 생성해야 하는 영역을 제2 생성 필요 영역으로 추론하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 입력 이미지는 제1 생성 모델을 이용하여 확장되고, 상기 제1 생성 필요 영역에 대한 이미지는 제2 생성 모델을 이용하여 생성되고, 상기 제2 생성 필요 영역에 대한 이미지는 제3 생성 모델을 이용 하여 생성되며, 상기 제2 생성 모델은 상기 제1 생성 모델 또는 상기 제3 생성 모델에 비해 성능이 높을 수 있 다. 일 실시예에 따르면, 상기 생성 필요 영역을 추론하는 단계는, 상기 입력 이미지에서 상기 적어도 하나의 객체 를 포함하는 영역을 제1 객체 제안 영역으로 추론하는 단계, 상기 요청에 따라 상기 적어도 하나의 객체를 변환 하는 단계, 상기 제1 객체 제안 영역에 기초하여, 상기 변환된 적어도 하나의 객체에 대응되는 제2 객체 제안 영역을 추론하는 단계, 상기 역변환을 고려하여 상기 제2 객체 제안 영역을 확장하는 단계 및 상기 확장된 제2 객체 제안 영역에 기초하여 상기 생성 필요 영역을 추론하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 확장된 제2 객체 제안 영역에 기초하여 상기 생성 필요 영역을 추론하는 단계는, 상 기 변환된 적어도 하나의 객체와 상기 확장된 제2 객체 제안 영역을 비교함으로써, 상기 변환된 적어도 하나의 객체에 대한 이미지를 추가적으로 생성해야 하는 영역을 제1 생성 필요 영역으로 추론하는 단계 및 상기 객체의 변환으로 인해 배경 이미지를 생성해야 하는 영역을 제2 생성 필요 영역으로 추론하는 단계를 포함할 수 있다. 일 실시예에 따른 컴퓨팅 장치는, 이미지의 처리를 요청하는 사용자 입력을 수신하고, 상기 사용자 입력에 따라 처리된 이미지를 출력하기 위한 입출력 인터페이스, 이미지를 처리하기 위한 명령들이 저장되는 메모리 및 적어 도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는 상기 명령들을 실행함으로써, 입력 이미지에 포함된 적어도 하나의 객체의 변환을 요청하는 사용자 입력을 수신하면, 상기 입력 이미지의 테두리(border)들 중에서 적어도 하나의 테두리가 상기 적어도 하나의 객체와 맞닿아 있는지 여부를 확인하고, 상기 적어도 하나의 테두리가 상기 적어도 하나의 객체와 맞닿아 있다면, 상기 요청에 따라 상기 적어도 하나의 객체를 변환하고, 상기 변환에 대한 역변환을 고려하여 이미지의 생성이 필요한 영역인 생성 필요 영역(generation required area)을 추론하고, 하나 이상의 생성 모델(generative model)을 이용하여 상기 생성 필요 영역에 대한 이미지를 생성할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는 상기 생성 필요 영역을 추론함에 있어서, 상기 역변환을 고려하여 상기 입력 이미지를 확장하고, 상기 확장된 입력 이미지에서 상기 적어도 하나의 객체를 포함하는 영 역을 제1 객체 제안 영역(object proposal area)으로 추론하고, 상기 요청에 따라 상기 적어도 하나의 객체를 변환하고, 상기 제1 객체 제안 영역에 기초하여, 상기 변환된 적어도 하나의 객체에 대응되는 제2 객체 제안 영 역을 추론하고, 상기 제2 객체 제안 영역에 기초하여 상기 생성 필요 영역을 추론할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는 상기 입력 이미지를 확장함에 있어서, 상기 입력 이미지의 테두리(border)들 중에서 상기 적어도 하나의 객체와 맞닿은 적어도 하나의 테두리를 선택하고, 상기 역변환에 따른 거리 및 방향으로, 상기 선택된 적어도 하나의 테두리를 이동시키고, 상기 하나 이상의 생성 모델을 이용 하여 상기 적어도 하나의 테두리가 이동된 영역까지 이미지를 생성할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는 상기 입력 이미지를 확장함에 있어서, 상기 입력 이미지의 테두리들 중에서 상기 선택된 적어도 하나의 객체와 맞닿은 적어도 하나의 테두리를 선택하고, 상기 선택된 적 어도 하나의 테두리를 상기 적어도 하나의 객체의 크기에 따라 결정되는 거리만큼 이동시키고, 상기 하나 이상 의 생성 모델을 이용하여 상기 적어도 하나의 테두리가 이동된 영역까지 이미지를 생성할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 선택된 적어도 하나의 테두리를 상기 적어도 하나의 객체의 크기에 따라 결정되는 거리만큼 이동시킴에 있어서, 상기 적어도 하나의 객체의 길이에 미리 설정된 비 율을 곱한 거리만큼 상기 선택된 적어도 하나의 테두리를 이동시킬 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 선택된 적어도 하나의 테두리를 상기 적어도 하나의 객체의 크기에 따라 결정되는 거리만큼 이동시킴에 있어서, 상기 적어도 하나의 객체가 상기 입력 이미지 내에 서 변환 가능한 범위에 기초하여 이동 거리를 결정하고, 상기 결정된 이동 길이만큼 상기 선택된 적어도 하나의 테두리를 이동시킬 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는 상기 제2 객체 제안 영역에 기초하여 상기 생성 필요 영역 을 추론함에 있어서, 상기 변환된 적어도 하나의 객체와 상기 제2 객체 제안 영역을 비교함으로써, 상기 변환된 적어도 하나의 객체에 대한 이미지를 추가적으로 생성해야 하는 영역을 제1 생성 필요 영역으로 추론하고, 상기 객체의 변환으로 인해 배경 이미지를 생성해야 하는 영역을 제2 생성 필요 영역으로 추론할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 제1 생성 모델을 이용하여 상기 입력 이미지를 확장하고, 제2 생성 모델을 이용하여 상기 제1 생성 필요 영역에 대한 이미지를 생성하고, 제3 생성 모델을 이용하여 상기 제2 생성 필요 영역에 대한 이미지를 생성하며, 상기 제2 생성 모델은 상기 제1 생성 모델 또는 상기 제3 생성 모델에 비해 성능이 높을 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는 상기 생성 필요 영역을 추론함에 있어서, 상기 입력 이미 지에서 상기 적어도 하나의 객체를 포함하는 영역을 제1 객체 제안 영역으로 추론하고, 상기 요청에 따라 상기 적어도 하나의 객체를 변환하고, 상기 제1 객체 제안 영역에 기초하여, 상기 변환된 적어도 하나의 객체에 대응 되는 제2 객체 제안 영역을 추론하고, 상기 역변환을 고려하여 상기 제2 객체 제안 영역을 확장하고, 상기 확장 된 제2 객체 제안 영역에 기초하여 상기 생성 필요 영역을 추론할 수 있다. 본 개시의 다양한 실시예들은 하나 이상의 컴퓨터 프로그램들에 의해 구현 또는 지원될 수 있고, 컴퓨터 프로그 램들은 컴퓨터 판독 가능한 프로그램 코드(code)로부터 형성되고, 컴퓨터로 판독 가능한 매체에 수록될 수 있다. 본 개시에서, \"애플리케이션(application)\" 및 \"프로그램(program)\"은 컴퓨터 판독 가능한 프로그램 코드 에서의 구현에 적합한 하나 이상의 컴퓨터 프로그램, 소프트웨어 컴포넌트, 명령어 세트, 프로시저(procedure), 함수, 개체(object), 클래스, 인스턴스, 관련 데이터, 또는 그것의 일부를 나타낼 수 있다. \"컴퓨터 판독 가능 한 프로그램 코드\"는, 소스 코드, 목적 코드, 및 실행 가능한 코드를 포함하는 다양한 유형의 컴퓨터 코드를 포 함할 수 있다. \"컴퓨터 판독 가능한 매체\"는, ROM(read only memory), RAM(random access memory), 하드 디스 크 드라이브(HDD), CD(compact disc), DVD(digital video disc), 또는 다양한 유형의 메모리와 같이, 컴퓨터에 의해 액세스(access)될 수 있는 다양한 유형의 매체를 포함할 수 있다. 또한, 기기로 읽을 수 있는 저장 매체는, 비일시적(non-transitory) 저장 매체의 형태로 제공될 수 있다. 여기 서, ‘비일시적 저장 매체'는 실재(tangible)하는 장치이고, 일시적인 전기적 또는 다른 신호들을 전송하는 유 선, 무선, 광학적, 또는 다른 통신 링크들을 배제할 수 있다. 한편, 이 '비일시적 저장 매체'는 데이터가 저장 매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 예를 들어, '비일시적 저 장 매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 컴퓨터 판독 가능한 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포 함할 수 있다. 컴퓨터 판독 가능한 매체는, 데이터가 영구적으로 저장될 수 있는 매체와 데이터가 저장되고 나 중에 덮어쓰기 될 수 있는 매체, 이를테면 재기입 가능한 광 디스크 또는 소거 가능한 메모리 디바이스를 포함 한다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예를 들어, compact disc read only memory (CD- ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두 개의 사용자 장치들(예를 들어, 스마트 폰) 간에 직접, 온라인으로 배포(예를 들어, 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예를 들어, 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스 토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시 적으로 생성될 수 있다."}
{"patent_id": "10-2023-0178039", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 으로 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로 이상에서 기술한 실시 예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결 합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3 도면4a 도면4b 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21 도면22 도면23"}
{"patent_id": "10-2023-0178039", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른, 이미지에 포함된 객체 변환 시 생성 모델을 이용하여 이미지를 편집하는 과정을 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시예에 따른, 이미지에 포함된 객체가 축소되는 경우 역변환을 고려하여 이미지를 확장 하는 방법을 설명하기 위한 도면이다. 도 3은 본 개시의 일 실시예에 따른, 이미지에 포함된 객체가 회전되는 경우 역변환을 고려하여 이미지를 확장 하는 방법을 설명하기 위한 도면이다. 도 4a는 본 개시의 일 실시예에 따른, 선택된 객체의 크기에 기초하여 이미지를 확장하는 방법을 설명하기 위한 도면이다. 도 4b는 본 개시의 일 실시예에 따른, 이미지의 크기에 기초하여 이미지를 확장하는 방법을 설명하기 위한 도면 이다. 도 5는 본 개시의 일 실시예에 따른, 선택된 객체의 변환 가능한 범위에 기초하여 이미지를 확장하는 방법을 설 명하기 위한 도면이다. 도 6은 본 개시의 일 실시예에 따른, 역변환 방향에 위치하는 모든 테두리들을 이동시킴으로써 이미지를 확장하 는 방법을 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시예에 따른, 이미지로부터 객체 제안 영역을 추론하는 방법을 설명하기 위한 도면이다. 도 8 및 도 9는 입력 이미지를 확장하지 않은 상태에서 객체 제안 영역을 추론하고, 객체의 변환에 대한 역변환 을 고려하여 객체 제안 영역을 확장하는 방식의 실시예들을 설명하기 위한 도면이다. 도 10은 객체의 변환에 대한 역변환을 고려하여 입력 이미지를 확장하는 과정에서 생성된 객체 이미지를 그대로 사용하여 이미지를 편집하는 실시예를 설명하기 위한 도면이다. 도 11은 본 개시의 일 실시예에 따른, 생성 모델을 이용한 이미지 편집을 수행하기 위한 컴퓨팅 장치의 구성을 설명하기 위한 도면이다. 도 12는 본 개시의 일 실시예에 따른, 생성 모델들의 종류와 역할을 설명하기 위한 도면이다. 도 13 내지 도 19는 본 개시의 실시예들에 따른, 생성 모델을 이용하여 이미지를 편집하는 방법을 설명하기 위 한 순서도들이다. 도 20 내지 도 23은 본 개시의 실시예들에 따른, 생성 모델을 이용하여 이미지를 편집하는 방법을 설명하기 위 한 순서도들이다."}
