{"patent_id": "10-2021-0113335", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0030999", "출원번호": "10-2021-0113335", "발명의 명칭": "GPU 기반 전력 데이터 고속 분산 처리 시스템 및 방법", "출원인": "한국전력공사", "발명자": "허성오"}}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "다중 사용자(101,102,103,104)에게 동시 접속 서버 환경을 제공하는 워크 벤치부(110);다중 클러스터의 GPU(graphics processing unit)를 활용하여 전력분야와 관련되는 대량의 데이터를 고속 처리하는 데이터 분산 처리부(120);대량의 상기 데이터를 저장하는 스토리지(130); 및대량의 상기 데이터를 처리하도록 상기 GPU의 최대 성능을 위한 가상화(Virtualization) 환경을 제공하는 하드웨어(141)와 트래픽 분산을 위한 네트워크(142)로 구분되는 장치부(140);를 포함하는 것을 특징으로 하는 GPU 기반 전력 데이터 고속 분산 처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 2 항에 있어서,상기 워크 벤치부(110)는 분석할 특정의 서버 자원을 선택하여 생성되는 이미지를 저장하는 사설 이미지 저장소(240);를 포함하는 것을 특징으로 하는 GPU 기반 전력 데이터 고속 분산 처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 동시 접속 서버 환경은, 분석 환경을 위한 분석 코드를 코딩하는 화면인 분석 노트북(800), 상기 분석 환경을 미리 분석 환경 설정 파일(1010) 또는 시스템 변수값으로 중앙에서 관리하는 분석 환경 개인화, 신규 유저가 투입되거나 다른 분석 환경을 설정하기 위한 서비스인 권한 인증 및 서비스 로드, 시스템 자원을 소모하는특정 서비스와 네트워크 지연에 의한 전체 시스템 장애가 발생하지 않도록 하기 위하여 REST(Representationalstate transfer) API(application programming interface)에 TCC(Try-Confirm/Cancel)를 적용하는 부하 관리및 부하 모니터링, 다양한 로그를 저장하고 검색할 수 있는 환경을 제공하는 로그 수집, 상기 이미지 및 패키지정보를 특정 시점의 데이터 전체를 바이너리 파일로 저장하는 백업 관리, 상기 이미지의 분산 및 병렬 배포 기능 중 적어도 하나 이상을 포함하는 것을 특징으로 하는 GPU 기반 전력 데이터 고속 분산 처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 권한 인증 및 서비스 로드는 필요한 상기 이미지와 상기 패키지 정보를 제공하고 빠르게 환경을 구성하기위해, 인증기(1110)를 통해 개별 권한 인증을 하면 API 서비스(API Service)(1120)를 통해 필요한 상기 이미지와 패키지 프로그램을 제공하며, 상기 사설 이미지 저장소(240)는 상기 이미지를 저장하는 이미지 저장소(1140)및 상기 패키지 정보를 저장하는 패키지 저장소(1130)로 이루어지는 것을 특징으로 하는 GPU 기반 전력 데이터고속 분산 처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,공개특허 10-2023-0030999-3-상기 하드웨어(141)는, 작은 단위의 잡(Job)을 처리하기 위해, 작은 단위로 쪼개진 다수의 GPU 자원(1410-1 내지 1410-n)을 파악하고효율적으로 운영될 수 있도록 특정 시점에 반복적으로 낭비되고 있는 가상 GPU를 회수하는 리소스 매니저(510);유저의 요청이 들어올 때마다 필요한 다수의 상기 GPU 자원(1410-1 내지 1410-n)의 크기를 계산하고, 동적으로필요한 만큼 컨테이너를 생성하여 가성 GPU를 제공하는 가상 GPU 매니저(520);다수의 상기 GPU 자원(1410-1 내지 1410-n)에 구성되는 가상 GPU(1401)를 실행하는 GPU 가상화(530);를 포함하는 것을 특징으로 하는 GPU 기반 전력 데이터 고속 분산 처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 하드웨어(141)는 작은 단위 업무(Task)를 처리하기 위해, 하이퍼바이저(1330)의 간섭이 없어서 오버헤드를피하도록 다이렉트 패쓰 쓰루(Direct Pass Through) 기술을 이용하여 실제 GPU(1340)와 가상 머신(1311,1312)을 1:1로 매칭하는 것을 특징으로 하는 GPU 기반 전력 데이터 고속 분산 처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 가상 머신(1311,1312)에 그래픽 구동기(1320)가 위치되고, 상기 그래픽 구동기(1320)는 상기 가상 머신(1311,1312)의 운영체제에 의해 통제되는 것을 특징으로 하는 GPU 기반 전력 데이터 고속 분산 처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 네트워크(142)는, 인피니 밴드 기능을 수행하는 인피니 밴드 모듈(611); 및스파인-리프 아키텍처 기능을 지원하는 스파인-리프 아키텍처 모듈(612);을 포함하는 것을 특징으로 하는 GPU기반 전력 데이터 고속 분산 처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 스파인-리프 아키텍처는 스파인 계층(Spine Layer)과 리프 계층(Leaf Layer)의 2계층(L2 , L3)이며, 상기스파인 계층(Spine Layer)과 상기 리프 계층(Leaf Layer)에는 각각 상기 인피니 밴드 기능을 지원하는 패널이제공되는 것을 특징으로 하는 GPU 기반 전력 데이터 고속 분산 처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 데이터 분산 처리부(120)는,대량의 상기 데이터를 처리하기 위해 전체적인 리소스 관리 및 잡 스케줄링을 하는 MPI(Message PassingInterface)(600); 상기 잡 스케줄링에 따라 다수의 워커(Worker)(330-1 내지 330-n)에게 대량의 상기 데이터를 처리할 작업(Tas공개특허 10-2023-0030999-4-k)을 분배하는 마스터 모듈(320); 및 현재 잡(job)의 내용(Job Descriptor), 현재 처리 중인 잡, 및 현재 남아있는 잡을 체크 포인트 이미지에 기록하여 관리하는 동기 서비스 매니저 모듈(330);을 포함하는 것을 특징으로 하는 GPU 기반 전력 데이터 고속 분산처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,대량의 상기 데이터는 데이터 유형에 따라서 실시간(Real-Time), 배치(Batch), 외부 API로 생성되는데이터이고, 상기 체크 포인트 이미지에 색인을 추가함으로써 중복 데이터가 배제되는 것을 특징으로 하는 GPU기반 전력 데이터 고속 분산 처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 10 항에 있어서,대량의 상기 데이터는 입출력(I/O) 비용을 절감하기 위해 파케이(Parquet) 포맷으로 변환되며, 대량의 상기 데이터 중 빈번하게 사용되는 핫데이터(hot data)는 인메모리에서 실행되는 것을 특징으로 하는 GPU 기반 전력 데이터 고속 분산 처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 1 항에 있어서,상기 스토리지(130)는 GPU 스토리지(432)와 객체(Object) 스토리지(431)로 이루어지는 지며, 상기 객체 스토리지는 대량의 상기 데이터를 고속으로 처리하고 무상태(Stateless)한 컨테이너의 데이터를 외부에 영구적으로 저장하는 것을 특징으로 하는 GPU 기반 전력 데이터 고속 분산 처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 객체 스토리지는 분산된 다수의 스토리지 노드에 대량의 상기 데이터를 저장하기 위해 샤딩(Sharding) 기능 및 복제(Replication) 기능을 이용하여 저장하는 것을 특징으로 하는 GPU 기반 전력 데이터 고속 분산 처리시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 13 항에 있어서,대량의 상기 데이터의 읽기(Read)의 경우, 최초로 저장된 프라이머리(Primary) OSD(2231)를 이용하여 동작을 수행하고, 쓰기(Write)의 경우 복제본(Replica)이 저장될 OSD (Object Storage Daemon) 정보도 같이 보내서 MAP정보가 업데이트되며, 상기 프라이머리(Primary) OSD(2231)는 대량의 상기 데이터의 유실을 대비하기 위하여 세컨더리(secondary) OSD(2232) 및 테르시어리(Tertiary) OSD(2233)에 상기 복제본을 저장하는 것을 특징으로 하는 GPU 기반 전력 데이터 고속 분산 처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 13 항에 있어서,공개특허 10-2023-0030999-5-상기 GPU 스토리지(432)는 브로커(2321)를 통해 실시간으로 테라바이트 이상의 대량의 상기 데이터가 입력되면인메모리(2330)에서 GPU 가속(Accelerated)을 통해 처리하는 것을 특징으로 하는 GPU 기반 전력 데이터 고속 분산 처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 1 항에 있어서,이기종의 데이터베이스에서 같은 SQL(Structured Query Language) 쿼리로 양쪽 결과를 모두 얻을 수 있는 표준질의 프레임워크(420);를 포함하는 것을 특징으로 하는 GPU 기반 전력 데이터 고속 분산 처리 시스템."}
{"patent_id": "10-2021-0113335", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "(a) 워크 벤치부(110)가 다중 사용자(101,102,103,104)에게 동시 접속 서버 환경을 제공하는 단계;(b) 데이터 분산 처리부(120)가 다중 클러스터의 GPU(graphics processing unit)를 활용하여 전력분야와 관련되는 대량의 데이터를 고속 처리하는 단계;(c) 스토리지(130)가 대량의 상기 데이터를 저장하는 단계; 및(d) 상기 GPU의 최대 성능을 위한 가상화(Virtualization) 환경을 제공하는 하드웨어(141)와 트래픽 분산을 위한 네트워크(142)로 구분되는 장치부(140)가 대량의 상기 데이터를 처리하는 단계;를 포함하는 것을 특징으로 하는 GPU 기반 전력 데이터 고속 분산 처리 방법."}
{"patent_id": "10-2021-0113335", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "대량의 전력 데이터를 GPU(graphics processing unit) 기반으로 고속 분산 처리하는 GPU 기반 전력 데이터 고속 분산 처리 시스템을 제공한다. 상기 GPU 기반 전력 데이터 고속 분산 처리 시스템은, 다중 사용자에게 동시 접속 서버 환경을 제공하는 워크 벤치부, 다중 클러스터의 GPU(graphics processing unit)를 활용하여 전력분야와 관 련되는 대량의 데이터를 고속 처리하는 데이터 분산 처리부, 대량의 상기 데이터를 저장하는 스토리지, 및 대량 의 상기 데이터를 처리하도록 상기 GPU의 최대 성능을 위한 가상화(Virtualization) 환경을 제공하는 하드웨어와 트래픽 분산을 위한 네트워크로 구분되는 장치부를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2021-0113335", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 데이터 처리 기술에 관한 것으로서, 더 상세하게는 대량의 전력 데이터를 GPU(graphics processing unit) 기반으로 고속 분산 처리하는 시스템 및 방법에 대한 것이다. 특히, 본 발명은 대량의 전력 데이터를 분석하고자 할 때 협업 분석과 데이터의 고속 처리 및 딥러닝에 있어서 고속 분석을 할 수 있는 시스템 및 방법에 대한 것이다."}
{"patent_id": "10-2021-0113335", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "과거 산업계에서는 전통적인 회사 운영방식에서 데이터 분석이 미치는 영향이 적었다. ICT( Information and Communications Technology) 기술이 발전하면서 사람들의 초개 인화와 스마트 장비의 폭발적인 증가로 인해 데 이터의 중요성이 부각되고 있다. 이로 인해, 데이터 기반의 조직운영으로 산업계 내부 조직이 변화하고 최근에 는 AICBM(AI(인공지능),IoT(사물인터넷),Cloud(클라우드),Big data(빅 데이터), Mobile(모바일)) 열풍이 시작 되는 등 ICT 기술 집약적인 형태를 띠게 되었다. 이러한 근간에는 데이터를 빼놓고는 회사의 운명을 이야기할 수 없는 지경에 이르렀다. 전력분야에서도 다르지 않은 현상이 나타나고 있으며, AI(Artificial Intelligence) 기술을 적용한 다양한 시도가 이루어지고 있다. 예 를 들어, 전력설비 공사장 인부의 안전을 위해 작업자의 모습을 카메라가 촬영하여 작업 복장에 잘못된 점이 있 으면 경고를 발생하거나, 전력설비의 제원을 자동으로 인식하여 PLM(Product Lifecycle Management)과 같은 시 스템에서 전력설비 자산관리에 활용하고 있다. 그런데, 종래의 시스템에서는 데이터 분석가가 데이터를 분석하려면, 자신에게 할당된 PC(Personal Computer)나 가상머신을 활용하여 개별적인 데이터 분석을 진행하였다. 이 경우, 개인적인 로컬 환경은 같은 조직이나 현업 의 데이터 분석가와 협업 분석을 하기 힘들고, 데이터 변환 후 결과물에 기민하게 반응하여 분석에 빠르게 활용 할 수 없다. 결국, 팀원과 협업을 방해하고, 데이터 크기 측면에서 데이터가 커지면 커질수록 데이터의 처리가 느려지며 데 이터 이동을 하기에 힘들어진다. 이러한 일련의 과정은 결과물 및 사람들 사이에서 의사소통에 시간이 더 많이 걸리는 것을 뜻한다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 한국공개특허번호 제10-2020-0104734호"}
{"patent_id": "10-2021-0113335", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 위 배경기술에 따른 문제점을 해소하기 위해 제안된 것으로서, 대량의 전력 데이터를 GPU(graphics processing unit) 기반으로 고속 분산 처리하는 시스템 및 방법을 제공하는데 그 목적이 있다. 또한, 본 발명은 대량의 전력 데이터를 분석하고자 할 때 협업 분석과 데이터의 고속 처리 및 딥러닝에 있어서 고속 분석을 할 수 있는 시스템 및 방법을 제공하는데 다른 목적이 있다."}
{"patent_id": "10-2021-0113335", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 위에서 제시된 과제를 달성하기 위해, 대량의 전력 데이터를 GPU(graphics processing unit) 기반으 로 고속 분산 처리하는 GPU 기반 전력 데이터 고속 분산 처리 시스템을 제공한다. 상기 GPU 기반 전력 데이터 고속 분산 처리 시스템은, 다중 사용자에게 동시 접속 서버 환경을 제공하는 워크 벤치부; 다중 클러스터의 GPU(graphics processing unit)를 활용하여 전력분야와 관련되는 대량의 데이터를 고속 처리하 는 데이터 분산 처리부; 대량의 상기 데이터를 저장하는 스토리지; 및 대량의 상기 데이터를 처리하도록 상기 GPU의 최대 성능을 위한 가상화(Virtualization) 환경을 제공하는 하드 웨어와 트래픽 분산을 위한 네트워크로 구분되는 장치부;를 포함하는 것을 특징으로 한다. 또한, 상기 워크 벤치부는 분석할 특정의 서버 자원을 선택하여 생성되는 이미지를 저장하는 사설 이미지 저장 소;를 포함하는 것을 특징으로 한다. 또한, 상기 동시 접속 서버 환경은, 분석 환경을 위한 분석 코드를 코딩하는 화면인 분석 노트북, 상기 분석 환 경을 미리 분석 환경 설정 파일 또는 시스템 변수값으로 중앙에서 관리하는 분석 환경 개인화, 신규 유저가 투 입되거나 다른 분석 환경을 설정하기 위한 서비스인 권한 인증 및 서비스 로드, 시스템 자원을 소모하는 특정 서비스와 네트워크 지연에 의한 전체 시스템 장애가 발생하지 않도록 하기 위하여 REST(Representational state transfer) API(application programming interface)에 TCC(Try-Confirm/Cancel)를 적용하는 부하 관리 및 부하 모니터링, 다양한 로그를 저장하고 검색할 수 있는 환경을 제공하는 로그 수집, 상기 이미지 및 패키지 정보를 특정 시점의 데이터 전체를 바이너리 파일로 저장하는 백업 관리, 상기 이미지의 분산 및 병렬 배포 기능 중 적 어도 하나 이상을 포함하는 것을 특징으로 한다. 또한, 상기 권한 인증 및 서비스 로드는 필요한 상기 이미지와 상기 패키지 정보를 제공하고 빠르게 환경을 구 성하기 위해, 인증기를 통해 개별 권한 인증을 하면 API 서비스(API Service)를 통해 필요한 상기 이미지와 패 키지 프로그램을 제공하며, 상기 사설 이미지 저장소는 상기 이미지를 저장하는 이미지 저장소 및 상기 패키지 정보를 저장하는 패키지 저장소로 이루어지는 것을 특징으로 한다. 또한, 상기 하드웨어는, 작은 단위의 잡(Job)을 처리하기 위해, 작은 단위로 쪼개진 다수의 GPU 자원을 파악하 고 효율적으로 운영될 수 있도록 특정 시점에 반복적으로 낭비되고 있는 가상 GPU를 회수하는 리소스 매니저; 유저의 요청이 들어올 때마다 필요한 다수의 상기 GPU 자원의 크기를 계산하고, 동적으로 필요한 만큼 컨테이너 를 생성하여 가성 GPU를 제공하는 가상 GPU 매니저; 다수의 상기 GPU 자원에 구성되는 가상 GPU를 실행하는 GPU 가상화;를 포함하는 것을 특징으로 한다.또한, 상기 하드웨어는 작은 단위 업무(Task)를 처리하기 위해, 하이퍼바이저의 간섭이 없어서 오버헤드를 피하 도록 다이렉트 패쓰 쓰루(Direct Pass Through) 기술을 이용하여 실제 GPU와 가상 머신을 1:1로 매칭하는 것을 특징으로 한다. 또한, 상기 가상 머신에 그래픽 구동기가 위치되고, 상기 그래픽 구동기는 상기 가상 머신의 운영체제에 의해 통제되는 것을 특징으로 한다. 또한, 상기 네트워크는, 인피니 밴드 기능을 수행하는 인피니 밴드 모듈; 및스파인-리프 아키텍처 기능을 지원 하는 스파인-리프 아키텍처 모듈;을 포함하는 것을 특징으로 한다. 또한, 상기 스파인-리프 아키텍처는 스파인 계층(Spine Layer)과 리프 계층(Leaf Layer)의 2계층이며, 상기 스 파인 계층(Spine Layer)과 상기 리프 계층(Leaf Layer)에는 각각 상기 인피니 밴드 기능을 지원하는 패널이 제 공되는 것을 특징으로 한다. 또한, 상기 데이터 분산 처리부는, 대량의 상기 데이터를 처리하기 위해 전체적인 리소스 관리 및 잡 스케줄링 을 하는 MPI(Message Passing Interface); 상기 잡 스케줄링에 따라 다수의 워커(Worker)에게 대량의 상기 데 이터를 처리할 작업(Task)을 분배하는 마스터 모듈; 및 현재 잡(job)의 내용(Job Descriptor), 현재 처리 중인 잡, 및 현재 남아있는 잡을 체크 포인트에 기록하여 관리하는 동기 서비스 매니저 모듈;을 포함하는 것을 특징 으로 한다. 또한, 대량의 상기 데이터는 데이터 유형에 따라서 실시간(Real-Time), 배치(Batch), 외부 API로 생성되는 데이 터이고, 체크 포인트에 색인을 추가함으로써 중복 데이터가 배제되는 것을 특징으로 한다. 또한, 대량의 상기 데이터는 입출력(I/O) 비용을 절감하기 위해 파케이(Parquet) 포맷으로 변환되며, 대량의 상 기 데이터 중 빈번하게 사용되는 핫데이터(hot data)는 인메모리에서 실행되는 것을 특징으로 한다. 또한, 상기 스토리지는 GPU 스토리지와 객체(Object) 스토리지로 이루어지는 지며, 상기 객체 스토리지는 대량 의 상기 데이터를 고속으로 처리하고 무상태(Stateless)한 컨테이너의 데이터를 외부에 영구적으로 저장하는 것 을 특징으로 한다. 또한, 상기 객체 스토리지는 분산된 다수의 스토리지 노드에 대량의 상기 데이터를 저장하기 위해 샤딩 (Sharding) 기능 및 복제(Replication) 기능을 이용하여 저장하는 것을 특징으로 한다. 또한, 대량의 상기 데이터의 읽기(Read)의 경우, 최초로 저장된 프라이머리(Primary) OSD를 이용하여 동작을 수 행하고, 쓰기(Write)의 경우 복제본(Replica)이 저장될 OSD(Object Storage Daemon) 정보도 같이 보내서 MAP 정보가 업데이트되는 것을 특징으로 한다. 또한, 상기 프라이머리(Primary) OSD는 대량의 상기 데이터의 유실을 대비하기 위하여 세컨더리(secondary) OSD 및 테르시어리(Tertiary) OSD에 상기 복제본을 저장하는 것을 특징으로 한다. 또한, 상기 GPU 스토리지는 브로커를 통해 실시간으로 테라바이트 이상의 대량의 상기 데이터가 입력되면 인메 모리에서 GPU 가속(Accelerated)을 통해 처리하는 것을 특징으로 한다. 또한, 상기 스토리지는, 이기종의 데이터베이스에서 같은 SQL(Structured Query Language) 쿼리로 양쪽 결과를 모두 얻을 수 있는 표준 질의 프레임워크;를 포함하는 것을 특징으로 한다. 다른 한편으로, 본 발명의 다른 일실시예는, (a) 워크 벤치부가 다중 사용자에게 동시 접속 서버 환경을 제공하 는 단계; (b) 데이터 분산 처리부가 다중 클러스터의 GPU(graphics processing unit)를 활용하여 전력분야와 관 련되는 대량의 데이터를 고속 처리하는 단계; (c) 스토리지가 대량의 상기 데이터를 저장하는 단계; 및 (d) 상 기 GPU의 최대 성능을 위한 가상화(Virtualization) 환경을 제공하는 하드웨어와 트래픽 분산을 위한 네트워크 로 구분되는 장치부가 대량의 상기 데이터를 처리하는 단계;를 포함하는 것을 특징으로 하는 GPU 기반 전력 데 이터 고속 분산 처리 방법을 제공한다."}
{"patent_id": "10-2021-0113335", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, RDMA(Remote Direct Memory Access) 방식으로 메모리에서 메모리로 직접 데이터를 전송하고, 네트워크는 스파인-리프 토폴로지와 인피니 밴드를 지원하여 서버의 추가와 제거가 자유로운 스케일아웃을 지원 하고 네트워크 내에서 데이터 처리율 및 지연율에서 성능이 크게 향상되었다. 이는 대용량 데이터 처리와 파라미터 교환량이 많은 딥러닝 데이터, 모델, 파이프라인 병렬화에서 고성능 처리를 기대할 수 있다. 따라서, 병목 현상이 현저히 줄어들어 고속으로 데이터를 전처리하고 분석이 가능하다. 또한, 다이렉트 패쓰 쓰루(Direct Pass-Through)와 가상 GPU(graphics processing unit), 다중 GPU의 지원으로 GPU의 성능을 효과적으로 사용하여 고속 병렬처리와 대규모 딥러닝 모델을 처리할 수 있는 클러스터 작업을 할 수 있다. 또한, 본 발명의 다른 효과로서는 데이터 분석가가 분석 워크벤치를 통해서 데이터 분석 코드 작성을 직접 할 수 있고 코드의 이동없이 즉석에서 고성능 처리를 할 수 있다는 점을 들 수 있다. 부연하면, 성능 선택은 유저 마다 다양한 자원을 데이터 처리량에 맞게 성능을 선택하여 분석 환경 구축이 가능하고, 분석가들 사이에서 공 유와 수정, 재배포를 통해서 재사용성이 증대된다. 또한, 각각의 환경에서 독립적으로 간편하게 다운타임없이 다양한 형태로 배포가 가능하여, 신규 에너지 사업에 대응할 수 있는 민첩성을 제공한다. 또한, 개인 개발 IDE(Integrated Development Environment)에 비하여 협업 을 하는 팀원들에게 신속한 피드백 주기를 보장하며, 데이터 분석과 개발에 소요되는 시간을 단축할 수 있다. 또한, 본 발명의 또 다른 효과로서는 전력분야의 데이터의 경우, 모두 같은 형태가 아니며 데이터의 유형에 따 라 가져오거나 처리해야 하기 때문에 포맷에 따라 모두 저장할 수 있게 실시간(Real-Time), 배치(Batch), 외부 API(Application Programming Interface) 등을 제공할 수 있다는 점을 들 수 있다. 또한, 압축률이 좋은 데이터 포맷 변환의 기능 지원으로 비용이 절감되며, 데이터 분석가는 통일된 데이터 형태 로 분석이 가능하여 능률이 증대한다. 데이터를 처리하고 중간 결과를 저장하기 위해 스토리지를 선택할 수 있 으며, 고성능이 필요한 경우 GPU 스토리지를 통해 저장하거나 빠르게 추출하여 사용할 수 있다. 이러한 분석 방 식은 데이터 분석가의 분석 이외의 시간을 크게 줄여주고, 작업 속도가 효과적으로 향상된다."}
{"patent_id": "10-2021-0113335", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는바, 특정 실시예들을 도면에 예시하고 상세한 설명에 구체적으로 설명하고자 한다. 그러나 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어 야 한다. 각 도면을 설명하면서 유사한 참조부호를 유사한 구성요소에 대해 사용한다. 제 1, 제 2등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용 된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제 1 구성요소는 제 2 구성요소로 명명될 수 있고, 유사 하게 제 2 구성요소도 제 1 구성요소로 명명될 수 있다. \"및/또는\" 이라는 용어는 복수의 관련된 기재된 항목들 의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미가 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않아야 한다. 이하 첨부된 도면을 참조하여 본 발명의 일실시예에 따른 GPU 기반 전력 데이터 고속 분산 처리 시스템 및 방법 을 상세하게 설명하기로 한다. 본 발명의 일실시예에서는 앞서 설명한 데이터 분석의 어려움을 해결하고자, 대량의 전력 데이터를 분석하고자 할 때 협업 분석과 데이터의 고속 처리 및 딥러닝에 있어서 고속 분석을 할 수 있는 시스템을 제안한다. 주요 기능에는 고속 서버 장치 구축, 서버 장비의 클러스터링, 가상화 분석 환경 구축, 가상환경 공유 및 저장, 대용량 데이터 처리과 딥러닝 분산 훈련을 위한 분석환경 구축 등이 있다. 첫 번째는, 하드웨어 장비의 고속 동작을 위하여 필요한 네트워크 연결 방식과 고속 처리 장비가 있고, 이를 제 어하기 위한 MPI(Message Passing Interface)와 같은 고속 네트워크 인터페이스 소프트웨어를 활용한다. 두 번째는 고속 서버 장비 여러 대를 한곳에 묶어 관리하고 제어하기 위해 컨테이너 시스템을 채택한다. 세 번째는 개별 분석가에게 가상 분석 환경을 제공한다. 각 분석가가 분석 환경을 공유하면서 분석 환경을 재구 축할 때, 시간을 절약하는데 가장 큰 이점이 있다. 네 번째는 대량의 데이터를 처리할 수 있다. 분석하고자 하는 데이터의 용량이 약 5GB 정도라면 비교적 손쉽게 개인 PC(Personal Computer) 장비에서 분석이 가능하지만, 약 50GB만 넘어가도 분석 시간이 대폭 늘어나고 데이 터를 이동시키는 데 한계가 발생하기 시작한다. 본 발명의 일실시예에서는 대량의 데이터 용량을 압축 가공하고 더욱 빠르게 처리한다. 마지막으로 딥러닝 분산 훈련을 하기 위한 시스템 구축 방식이 있다. 본 발명의 일실시예에서 제안된 시스템을 통해 데이터 분석가는 대량의 데이터를 고속 처리하고, 분산 훈련이 가능해지며, 다른 동료와의 협업을 유연하게 만들어 준다.본 발명의 일실시예에서 제안하는 고속 분산 처리 시스템과 기존의 데이터 처리 시스템의 차이점은 아래 표 1과 같다. 표 1 구분 기존 데이터 처리 시스템 고속 분산처리 시스템 하드웨어* GPU(graphics processing unit)가 CPU를 통 해 메모리로 간접 접근하여 속도가 떨어짐* RDMA(Remote direct memory access) 방식으로 메 모리에서 메모리로 직접 데이터 전송하여 속도가 빠름 네트워크* 3계층 모델 * N:M:O 접속으로 간접 접근하여 전송속도가 떨어짐(N<M<O)* 스파인-리프(Spine-leaf) 토폴로지 * N:M 접속으로 직접 접근하여 전송속도가 빠름 데이터 분산처리* CPU를 통한 데이터처리 * GPU를 통한 데이터의 고속 병렬처리 엘라스틱 서비스* 단일(Single)-GPU,단일(Single)-Node 형태 의 단일 작업환경 * GPU 램 용량 한계에 따른 비교적 작은 딥러 닝 모델 처리 가능 * 고속 분산 훈련 불가능 * 유저가 잡(job)을 중단한 후 워커노드 수 증감 가능* 다중(Multi)-GPU, Multi-Node 형태의 클러스터 작업 * 대규모 딥러닝 모델 처리 가능 * Multi-GPU, Multi-Node 형태의 클러스터 작업(task) * 잡(job) 중단없이 실행 중에 워커노드 수 증감가 능 * 분산학습 시 데이터량과 성능요구에 따라 성능을 증감 가능 분석 워크벤치* 분석 워크벤치 활용 안 함 * 개발 IDE(Integrated Development Environment)를 활용* 분석 워크벤치 활용 * 분석 환경 공유 및 재사용성 증대 고속 스토리지* 파일시스템 활용 * 개별적 선호 데이터베이스 채택* 전통 및 GPU 데이터베이스 선택 저장 가능 및 고 속 처리, 저장 가능 위 표1에서 좌측은 기존 분산 처리 시스템이고, 우측은 본 발명의 일실시예에 따른 고속 분산 처리 시스템이다. 여기서, 하나의 작업(task)은 여러개의 잡(job)을 가지고 있는 형태로, 큰 덩어리의 작업을 분할(split)을 통해 작은 단위로 처리하면 속도 향상에 도움이 된다. 고속 분산처리 시스템에서는 이러한 잡(job)들을 동시에 처리 할 수 있기 때문에 더 좋은 성능을 낼 수 있다 이때, 여러노드에 걸친 분산데이터 처리 중 잡이 실패하면 중단 되어 대기 중인 잡을 다른 노드가 대신처리를 맡아 계속 실행하여 완료할 수 있다. 도 1은 본 발명의 일실시예에 따른 GPU(graphics processing unit) 기반 전력 데이터 고속 분산 처리 시스템 의 블럭 구성도이다. 도 1을 참조하면, 전력 데이터 고속 분산 처리 시스템은, 워크 벤치부, 데 이터 분산 처리부, 스토리지, 장치부 등을 포함하여 구성될 수 있다. 워크 벤치부는 다중 유저가 고속 분산 처리 시스템을 동시에 접속할 수 있는 서버 환경을 제공한다. 내부에는 분석 환경을 저장하고 공유할 수 있는 사설 이미지 저장소(Private Image Registry)가 있으며 데이터 분석가들 사이에서 분석 환경을 공유할 수 있다. 또한, 자동화를 위한 푸시/풀(Push/Pull) 기능을 사용할 수 있 는 기본적인 Rest API를 제공한다. 권한 인증, 분석 노트북, 분석 환경 개인화, 백업 관리, 모니터링 등의 기능을 제공하며, 유저가 필요로 하는 대량의 전력 데이터와 도구에 접근할 수 있도록 지원한다. 또한, 유저가 원하는 성능과 서버 자원을 자유롭게 선택하여 병렬 배포하는 기능을 제공한다. 데이터 분산 처리부는 GPU 기반 고속 데이터 처리를 수행한다. 기존의 CPU를 활용한 데이터 처리에서 다중 클러스터의 GPU를 활용하여 데이터를 고속 처리하게 된다. 이때, GPU를 통해 고속 처리된 데이터를 타 시스템에 서 활용하기 위해 데이터를 변환하는 잡(job)이 필요 없이 인메모리에서 단일 형태(Uniformed-format)를 지원하 여 데이터 전처리 부담과 시간을 절감할 수 있다. 데이터 분산 처리부는 인프라 엔지니어에 의해 관 리될 수 있다. 스토리지는 외부 시스템에서 전송된 로(Raw) 데이터나 전처리가 진행된 가공 데이터를 저장하는 저장소로 GPU용 스토리지와 객체(Object)용 스토리지를 각각 제공하여 유저는 원하는 타입을 선택하여 사용이 가능하다. 전통적인 SQL(Structured Query Language)을 지원하여, GPU, 객체 스토리지 간에 공통 SQL 문으로 질의할 수있도록 지원한다. 스토리지는 컨테이너 클러스터 상에서 동작하며, 브로커(Broker)를 통해 데이터 분산 처리에 서 발생한 산출물을 저장한다. 스토리지는 DB(DataBase) 관리자에 의해 관리될 수 있다. 장치부는 고속 분산 처리 시스템의 물리적인 장치의 구성과 대량의 데이터를 유연하고 빠르게 처리할 수 있는 환경 구성으로 하드웨어와 네트워크로 구분하고 있다. 하드웨어는 GPU의 최대 성능을 이끌 어 낼 수 있는 가상화(Virtualization) 환경을 제공하고, 네트워크는 효율적인 트래픽 분산을 위해 인피니 밴드(Infiniband)와 스파인-리프 아키텍처(Spine-Leaf Architecture) 기반을 따르고 있다. 하드웨어 관리자 에 의해 하드웨어가 관리되고, 네트워크 관리자에 의해 네트워크가 관리된다. 도 2는 도 1에 도시된 워크 벤치부의 세부 구성 블럭도이다. 도 2를 참조하면, 내부에는 분석 환경을 저장 하고 공유할 수 있는 사설 이미지 저장소(Private Image Registry)가 있으며 데이터 분석가들 사이에서 분 석 환경을 공유할 수 있다. 또한, 자동화를 위한 푸시/풀(Push/Pull) 기능을 사용할 수 있는 기본적인 Rest(Representational State Transfer) API(Application Programming Interface)를 제공한다. 사설 이미지 저 장소(Private Image Registry)는 패키지 및 이미지를 저장한다. 이외에도 워크 벤치부는 대시보드 모듈, 스포너 모듈, 빌드 모듈 등을 포함하여 구성될 수 있다.빌드모듈은 사용자가 구현한 코드를 실제로 실행하여 산출물이 나올 수 있게 도와주는 기능으로 클러 스터 내부의 성능 또는 라이브러리를 해당 코드가 참조하여 사용할 수 있게 해준다. 대시보드 모듈은 워크벤치 및 대시보드 기능을 수행한다. 워크벤치는 데이터베이스 설계, 생성 그리고 유 지를 위한 단일 개발 통합 환경을 제공하는 비주얼 데이터베이스 설계 도구이다. 대시보드는 시각화된 웹 페이 지를 제공하는 기능을 수행한다. 스포너 모듈는 현재 가지고 있는 서버 자원상에 분석 환경을 적절히 배포해 주는 기능을 수행한다. 따라서, 워크 벤치부는 권한 인증, 분석 노트북, 분석 환경 개인화, 백업 관리, 모니터링 등의 기능을 갖 는 동시 접속 서버 환경을 제공하며, 유저가 필요로 하는 대량의 전력 데이터와 도구에 접근할 수 있도록 지원 한다. 또한, 유저가 원하는 성능과 서버 자원을 자유롭게 선택하여 병렬 배포하는 기능을 제공한다. 도 3은 도 1에 도시된 데이터 분산 처리부의 세부 구성 블럭도이다. 도 3을 참조하면, 데이터 분산 처리부 는 다중 클러스터의 GPU(graphics processing unit)를 관리하는 클러스터 매니저 모듈, 클러스터 매 니저 모듈의 제어에 따라 리소스 관리 및 잡(job) 스케줄링을 통해 최적의 잡(job)을 분배 관리하는 마스 터 모듈, 분배된 잡(job)을 동기화시키는 동기 서비스 매니저 모듈, 새로운 잡(job)이 발생되면 자동 으로 새로운 워커 노드를 추가하는 노드 모듈, API 호출로 외부의 데이터를 가져오도록 하는 API 서비스 모듈, 데이터가 수집될 때마다 잠시 저장할 수 있는 체크포인트(Checkpoint)에 색인(Index)을 추가하는 체 크 포인트 모듈 등을 포함하여 구성될 수 있다. 도 4는 도 1에 도시된 스토리지의 세부 구성 블럭도이다. 도 4를 참조하면, 외부 시스템에서 전송된 로 (Raw) 데이터나 전처리가 진행된 가공 데이터를 저장하는 저장소로 GPU용 스토리지와 객체(Object)용 스토리지 를 각각 제공하여 유저는 원하는 타입을 선택하여 사용이 가능하다. 전통적인 SQL(Structured Query Language) 을 지원하여, GPU, 객체 스토리지 간에 공통 SQL 문으로 질의할 수 있도록 지원한다. 스토리지는 컨테이너 클 러스터 상에서 동작하며, 브로커(Broker)를 통해 데이터 분산 처리에서 발생한 산출물을 저장한다. 이를 위해, 스토리지는 클라이언트와 클러스터 내부의 데이터 전송을 중개해 주는 프록시 역할을 수행하는 게이트웨이 모듈, 게이트웨어 모듈의 제어에 따라 데이터를 분류하는 표준 질의 프레임워크, 분 류된 데이터에 따라 오브젝트 관련 데이터 저장을 위한 오브젝트 스토리지, GUP관련 데이터 저장을 위한 GPU 스토리지, 분산된 다수의 스토리지 노드에 데이터를 저장하는 스토리지 복사 모듈, 클러스터를 관리하고 유지하는 데몬(Daemon)으로 보안을 관리하고 로그를 시각화하여 운영하는 모니터 모듈 등을 포함 하여 구성될 수 있다. 도 5는 도 1에 도시된 하드웨어의 세부 구성 블럭도이다. 도 5를 참조하면, 하드웨어는 GPU의 최대 성능을 이끌어 낼 수 있는 가상화(Virtualization) 환경을 제공한다. 이를 위해, 작은 단위로 쪼개진 가상 GPU 를 파악하고 효율적으로 운영될 수 있도록 적절한 시점에 반복적으로 낭비되고 있는 가상 GPU를 회수하는 리소 스 매니저, 유저의 요청이 들어올 때마다 필요한 자원의 크기를 계산하고, 동적으로 필요한 만큼 컨테이너 를 생성하여 GPU를 제공하는 가상 GPU 매니저, 가상 GPU를 실행하는 GPU 가상화, 가상 GPU를 이용하 여 고속 분산 처리를 실행하는 고속 분산 처리부 등을 포함하여 구성될 수 있다. 도 6은 도 1에 도시된 네트워크의 세부 구성 블럭도이다. 도 6을 참조하면, 네트워크는 효율적인 트 래픽 분산을 위해 인피니밴드(Infiniband)와 스파인-리프 아키텍처(Spine-Leaf Architecture) 기반을 따르고 있다. 이를 위해 네트워크는, 인피니 밴드 기능을 수행하는 인피니 밴드 모듈, 스파인-리프 아키텍처 기능을 지원하는 스파인-리프 아키텍처 모듈, 스파인-리프 아키텍처와 인피니 밴드 기능을 통해 고속 분산 처리를 수행하는 고속 분산처리부 등을 포함하여 구성될 수 있다. 도 7은 본 발명의 일실시예에 따른 유저 관점 워크 벤치 과정을 보여주는 흐름도이다. 도 7을 참조하면, 유저 (101 내지 105)는 개인 계정 또는 관리자 계정으로 워크벤치부에 접속한다(단계 S710). 이후, 유저(101 내지 105)는 사설 이미지 저장소에서 원하는 이미지를 로드하거나, 유저가 원하는 자원의 하드웨어를 선택하여 새로운 이미지를 생성한다(단계 S720). 이후, 유저(101 내지 105)는 사설 이미지 저장소에서 필요한 패키지 프로그램을 설치한후 작성된 코드를 스케줄러로 등록하고 실행한다(단계 S730). 이후, 워크 벤치부는 완성된 모델 또는 이미지를 분산 및 병렬로 배포한다(단계 S740). 이후, 유저(101 내지 105)는 대시보드를 이용하여 배포 현황, 자원, 로그 등을 확인한다(단계 S750). 도 8은 본 발명의 일실시예에 따른 분석 노트북 화면의 구성 예시이다. 도 8을 참조하면, 분석 노트북은 데이터 분석가나 데이터 엔지니어가 웹상에서 구동되는 IDE 화면을 보면서 분석 코드를 코딩하는 화면을 말한다. 분석 노트북에서는 Python, Scala, R 언어로 코드를 작성할 수 있다. 이를 위해, 터미널 입력 윈도우, 코 드 윈도우, 출력 윈도우가 구성될 수 있다. 유저는 프로젝트를 관리하는 프로젝트 메뉴에서 자신이 작성한 코드나 데이터를 직접 업로드하여 웹상에서 편리하게 분석 코드를 작성할 수 있고, 다른 유저를 초대하여 팀이 협업하여 분석할 수 있다. 작성한 코드는 노 트북의 실행(Lunch), 중단(Stop)을 통해 개발 환경을 시스템에 클러스터로 배포 및 실행(Spawn)하고 회수할 수 있다. 한정된 서버 자원을 관리하기 위하여 일정 시간 입력이 없거나, 작업하지 않으면 현재 작업 상황을 체크 포인트 하고 노트북이 자동 중단되어 서버 자원을 회수한다. 유저가 작업을 재개하면, 시스템은 체크 포인트의 내용을 가져오고 이어서 작업할 수 있게 만들어준다. 한정된 서버 자원은 CPU(Central Processing Unit), RAM(Random Access Memory), GPU(graphics processing unit), HDD(Hard Disk Drive 등이 될 수 있다. 도 9는 본 발명의 일실시예에 따른 엔진 단위의 배포 개념도이다. 도 9를 참조하면, 분석 노트북의 클러스 터 기능은 유저가 데이터처리 작업에서 고성능이 요구되나, 한정된 시스템 자원이 부족하여 서버의 처리 성능을 높이기 위한 대안 방법으로 활용할 수 있다. 분석 노트북에서 병렬 서버의 수를 입력하면 워커 노드로 활용될 서버들을 입력한 수만큼 클러스터링하여 시스템에 배포하고 실행해 준다. 유저는 서버 인프라의 환경을 몰라도 시스템이 자동화하여 병렬처리를 활 수 있는 환경을 만들어 준다. 이때, 시스템 관리자가 유저당 할당받는 서버 자원을 제한할 수 있기 때문에 유저는 무한정 서버 자원을 받아서 활용할 수 없다. 이러한 클러스터 작업은 시스템 내의 분산 배포기능을 통해 할당받는다. 분산 배포는 현재 자원의 상황을 보고 유저가 병렬 서버의 수를 지정해서 작업하고 배포할 수 있는 시스템적 기능이다. 시스템은 각각의 서버에 엔진(Engine)의 단위로 작업 서버를 배포하고 엔진은 실제로 코드를 실행하고 결과를 반환(return)하는 서버가 된다. 이러한 작업 단위를 통해 시스템은 여러 개의 엔진을 병렬 서버에 실행 및 배포 가 가능하다. 유저가 잡(job)을 제출(Submit)하면 병렬 배포되어 있는 엔진에 작업이 스케줄러에 의해 공통적 으로 실행되고, 하나의 잡을 병렬 서버의 수만큼 쪼개어 실행함으로써, 더 빠르게 고속 처리가 가능하다. 제어 기(Controller)는 유저와 엔진을 연결해 주는 인터페이스로 유저가 작업할 설정값들과 작업량(데이터 크기 와 수)을 전달하고, 스케줄러(Scheduler)는 잡(Job)을 적절하게 로드밸런싱(Load balancing)하여 엔진이 효율적으로 동작할 수 있게 지원한다. 엔진은 제 1 내지 제 n 엔진(940-1 내지 940-n)이 병렬로 구성되는 집합을 나타낸다. 도 10은 본 발명의 일실시예에 따른 분석 환경 개인화 구성의 개념도이다. 도 10을 참조하면, 분석 환경 개인화 란 분석가가 분석 환경을 사용하고 싶다면, 딥러닝 분산처리 시스템이 분석 환경의 근간이 되는 이미지를 배포및 실행(Spawn)할 서버 자원 공간들을 찾아서 해당 서버 자원들에 대해 실제 실행할 수 있는 분석 환경을 만들 어준다. 각각의 분석 환경에 대한 이미지는 이러한 분석 환경 설정 파일(시스템 라이브러리, 분석 라이브러리 등)이나 시스템 변수 값들을 중앙에서 관리하고 분석가가 원할 때 배포하는 방식으로 설정 파일을 워크벤치 서버 를 통하여 관리한다. 여기서 스포너(Spawner) 모듈은 현재 가지고 있는 서버 자원상에 분석 환경을 적절히 배포해 주는 기능이다. 분석가가 데이터 분산처리와 딥러닝 분산 훈련을 할 때 데이터량에 따라 원하는 서버 자원의 수(CPU, GPU, HDD, 메모리 등)와 이러한 서버를 묶어 쓸 수 있는 클러스터링 기능을 제공하여 분석가가 필요한 서버 자원을 요구하 면 해당 서버를 클러스터로 묶어 자동적으로 분석 환경을 제공해 준다. 도 11은 본 발명의 일실시예에 따른 서비스 로드 구성의 개념도이다. 도 11을 참조하면, 권한 인증 및 서비스 로드란 유저별(1010-1 내지 1010-n)로 신규 유저가 투입되거나 새로운 분석 환경을 설정하기 위한 서비스다. 유저별로 개인화된 공간을 제공하기 위해 인증기를 통해 개별 권한 인증을 하면 API 서비스(API Service)를 통해 필요한 이미지와 패키지 정보들을 제공하고 빠르게 환경을 구성할 수 있다. 사용자가 필 요한 경우 이를 재공유하기 위해 패키지 저장소나 이미지 저장소에 다시 저장하고 공유할 수 있다. 패키지 정보는 프로그램, 데이터 등이 될 수 있다. 유저별로 설정된 권한에 따라 접속, 저장, 공유, 삭제 등이 관리되어 자원낭비를 줄이고 자동으로 해당 패키지 와 가상화 이미지에 저장되어 있는 라이브러리와 시스템 정보(OS, 라이브러리 정보 등)를 사람이 식별할 수 있 는 문서를 해당 이미지와 함께 이미지 저장소(Image Registry)에 개인별로 관리할 수 있다. 사설 이미지 저장소 (도 2의 240)는 이미지를 저장하는 이미지 저장소 및 패키지 정보를 저장하는 패키지 저장소로 이 루어진다. 분석 환경을 만들기 위한 분석 환경을 담고 있는 이미지는 개인 정보나 특정한 시스템 변수들이 내부에 존재할 수 있으므로 암호화 저장되어, 이미지를 불러오거나 저장할 때 보안 이미지로 저장하는 것을 선택할 수 있다. 주석(Annotation) 기능을 활용하여 로그인 사용자별로 설정해 놓은 값들이 쉽게 불러오기 될 수 있도록 편리성 을 제공한다. 또한, 설정된 권한에 따라 접속 범위를 지정할 수 있기 때문에 관리자와 분석가의 권한을 다르게 설정할 수 있다. 한편, 부하 관리 및 모니터링이란 시스템 자원을 소모하는 특정 서비스와 네트워크 지연에 의한 전체 시스템 장 애가 발생하지 않도록 하기 위하여 REST API에 TCC(Try-Confirm/Cancel)를 적용하는 기능이다. TCC는 REST 시 스템들 간의 트랜잭션을 HTTP와 REST 원칙으로 접근하여 정상적으로 작업이 끝나는 구간은 COMMIT, 그렇지 않은 구간은 ROLLBACK 키워드를 사용하는 방식으로 에러가 발생하면 호출을 제한하거나 재시도(Retry)를 조정할 수 있다. 사용자는 해당 결과를 실시간으로 적용되는 웹 형태의 모니터링에 접근해서 볼 수 있다. 도 12는 본 발명의 일실시예에 따른 로그 검색 및 백업 관리의 개념도이다. 도 12를 참조하면, 로그 수집 기능 은 분산 처리 시스템에서 발생하는 시스템 로그, 서버 로그, 에러 로그 등 다양한 로그를 백업 스토리지 에 저장하고 검색할 수 있는 환경을 제공한다. 백업 관리 기능은 이미지와 패키지를 특정 시점의 데이터 전체를 바이너리(Binary) 파일로 저장하는 방식으로 사이즈가 작고 빠른 로드가 가능하여 시스템의 단일 장애점(SPOF, Single Point of Failure)를 제거한 고가용성(High Availability)과 다중 사용자의 접근 및 사용을 뜻하는 멀 티테넌시(Multi-Tenancy)에 강점이 있다. 도 13은 본 발명의 일실시예에 따른 다이렉트 패쓰 쓰루(Direct Pass Through) 기술의 개념도이다. 도 13을 참 조하면, 딥러닝 분산 훈련을 위한 하드웨어는 GPU 가상화가 될 수 있도록 Direct Pass-Through 기술을 이용하여 구성한다. 다이렉트 패쓰 쓰루(Direct Pass Through) 기술은 GPU를 직접적으로 가상머신(VM) 환경에 1:1 로 매핑하는 방식이다. 즉, GPU를 제 1 가상 머신과 1:1로 매핑하거나, GPU를 제 2 가상 머 신과 1:1로 매핑한다. 따라서, GPU 자원을 독점적으로 점유할 수 있어서 효율적인 방법이며, 물리 GPU 제조사의 그래픽 구동기 나 특성을 가감 없이 그대로 사용할 수 있다. 또한, 도 13에 도시된 바와 같이 그래픽 구동기는 각 VM(1311,1312)에 위치하고 VM의 운영체제에 의해 통제되기 때문에 하이퍼바이저의 간섭이 없어서 오버헤 드를 피할 수 있다. 도 14는 도 5에 도시된 리소스 매니저의 개념도이다. 도 14를 참조하면, 작은 단위의 잡(Job)은 가상 GPU를 할 당하는 것이 시스템 전체적인 성능과 사용률에는 더 나을 수 있다. 작은 단위의 업무(Task)에 Direct Pass- Through 기술을 사용하게 된다면, 사용자별로 최대 성능을 발휘할 수 있으나, GPU를 계속 점유하게 되고 다른 사용자는 GPU 할당을 기다릴 수밖에 없다. 그렇기 때문에 데이터 분산처리 시 대용량 데이터를 처리한 후 작은 데이터를 분산처리할 때는 오히려 GPU 자원 의 성능을 그대로 활용할 수 있는 Direct Pass-Throguh보다 가상 GPU 매니저를 통해 가상 GPU 형태로 작은 단위의 GPU 자원(1410-1 내지 1410-n)을 할당받아 처리하는 것이 낫다. 가상 GPU 매니저는 사용자의 요청 이 들어올 때마다 필요한 자원의 크기를 계산하고, 동적으로 필요한 만큼 컨테이너를 생성하여 가상 GPU 를 제공해 준다. 리소스 매니저는 작은 단위로 쪼개진 가상 GPU를 파악하고 효율적으로 운영될 수 있도록 적절한 시점에 반복적으로 낭비되고 있는 가상 GPU를 회수한다. 도 15는 본 발명의 일실시예에 따른 2 계층 구조의 개념도이다. 도 15를 참조하면, 고속 분산 처리를 위한 네트 워크는 스파인-리프 아키텍처와 인피디 밴드 기능을 지원한다. 기존의 3계층 아키텍처는 하나의 서버에서 다른 서버로 데이터를 전송하려면, 중간계층인 집적(Aggregation) 계층을 지나야 하므로, 중간에서 데이터처리 를 한 번 더 해야 한다. 스파인-리프는 3계층이었던 전통적인 구조에서 하나의 레이어(Layer)를 해체하여 2계층(L2,L3)으로 만들어진 아 키텍처로 스위칭 블럭을 이루는 스위치간의 빠른 전송을 제공하고 서버 입장에서는 데이터를 직접 전송하는 효과를 가지게 된다. M:N으로 다중 연결이 가능하여 트래픽 분산이 가능하고 스케일아웃(Scale- Out)을 통해 대규모 네트워크 패브릭 구축이 가능하다. 스파인 계층(Spine Layer)과 리프 계층(Leaf Layer)에는 각각 인피니 밴드를 지원하는 패널이 제공되어 유저는 고성능 처리(High Throughput), 저 지연성(Low Latency), 고 확장성(High Scalability)등의 강점을 활용 가능하다. 도 16은 본 발명의 일실시예에 따른 클러스터 컴퓨팅 프레임워크 구조의 개념도이다. 도 16을 참조하면, 대량의 전력 데이터를 빠르게 처리하기 위한 클러스터 컴퓨팅 프레임워크로 마스터(Master) 모듈은 외부의 요청을 받아들이고 워커(Worker)들(330-1 내지 330-n)에게 처리 작업(Task)을 분배한다. 작업의 성능 요구에 따라서 CPU와 GPU의 사용 점유율을 선택하는 기능을 제공하며, 서버와 클라이언트 간의 네트워크 지연을 줄이기 위해 높은 압축률과 성능을 보이는 이진(binary) 메시지 형식인 gPRC로 통신을 한다. MPI(Message Passing Interface)는 전체적인 리소스 관리 및 잡 스케줄링을 하는 기능을 가지고 있으며, 클러스터 매니저(Cluster Manager) 모듈에게 잡 스케줄링 정보를 제공하고 각 워커들의 리소스를 분석하여 마스터에게 최적의 잡을 분배할 수 있게 도움을 준다. MPI은 MPI 스케줄러, 리소스 매니저, MPI 워크 매니저 으로 구성된다. 워커 내부에서는 CSV, RDB(Relation Database), 데이터프레임(Data frame)과 같은 Row 데이터 포맷과 Columnar 데이터 포맷인 Parquet 형식을 모두 지원하고, 각각 데이터베이스 형태에 맞게 교차 변환 및 접근이 가능하여 사용자가 모든 플랫폼의 언어를 다룰 필요가 없기 때문에 효율적인 사용이 가능하다. 또한, 워커 블럭의 워커들(330-1 내지 330-n)은 논리적으로 분리되지 않은 공간에서 데이터 준비단계(CPU 또는 GPU 활용) 및 딥러닝 모델 훈련(GPU 활용)을 같이 진행하기 때문에 공유 스토리지(Shared Storage)를 만들 지 않아도 되어서 불필요한 자원 낭비를 막아준다. 도 17은 본 발명의 일실시예에 따른 데이터 형태별 처리 구성도이다. 도 17을 참조하면, 전처리할 데이터의 유 형에 따라 실시간(Real-Time), 배치(Batch) 형태로 내부 데이터를 가져오거나 처리할 수 있고, 외부 데이 터를 내부에 있는 것처럼 보이게 만들어 데이터처리에 도움을 주는 외부 데이터 소스(External Data Source)의 기능을 제공한다. API 호출로 외부의 데이터를 가져오고, 스케줄러를 사용하여 자동으로 배치 사이즈 만큼 데이터를 가져올 수 있다. 비디오 또는 오디오 기능을 가진 클라이언트의 데이터를 실시간으로 제공(Serving) 할 때는 실시간 스트리밍 프 로토콜(RTSP) 규약에 따라 안정적인 전송 환경을 제공한다. 데이터가 수집될 때마다 잠시 저장할 수 있는 체크 포인트(Checkpoint) 모듈의 체크 포인트에 색인(Index)을 추가하여 브로커 블럭의 제 1 내지 제 n 브로커(1711-1 내지 1711-n) 및 실시간 제공 모듈이 중복된 데이터를 가져오는 현상을 막아준다. 수집된 데이터는 멀티 스레드(Multi Thread)를 통해 워크플로우 기반의 파이프라인에서 Parquet 포맷 데이터로 변환 및 저장된다. 데이터 파티셔닝(Partitioning)과 칼럼 청크(Column chunk)를 통해 데이터의 필요한 부분과 연속적 데이터 출력을 칼럼 단위로 구성하여 데이터를 활용할 수 있으며, 압축되어 있는 파일을 그대로 읽고 쓸 수 있으므로 입출력(I/O) 비용이 절감된다. 이를 최대한으로 활용하기 위해 본 시스템에서는 모든 데이터를 파케이(Parquet)의 포맷으로 저장한다. 여기서 수시로 입출력되고 자주 처리되어야 하는 핫 데이터(Hot data)는 인메모리(In-memory)에서 디스크에 저장되어 있는 파케이(Parquet)의 데이터 포맷 변환 없이 그대로 실행할 수 있다. 인메모리에서 데이터 변환 없이 바로 실행 가능하기 때문에 보다 빠르게 불러오고 저장할 수 있다. 또한, 다른 시스템에서 바로 활용할 수 있는 단일 형태의 포맷이므로 이 또한 데이터 변환 없이 바로 불러오고 저장할 수 있다. 본 발명의 일실시예의 경우, 엘라스틱 서비스(Elastic service)를 통해 데이터처리나 딥러닝 모델의 분산 훈련 시 현재 작업의 중단 없이 실행 중에 워커 노드 수를 증감할 수 있다. 이를 통해, 비교적 작은 작업이 다수 실 행 중임에도 고성능으로 긴 시간 동안 작업을 요구하는 경우 부족했던 서버 자원을 작은 작업이 끝날 때마다 프 로세스 실행 중에 투입할 수 있다. 프로세스 실행 중에 워커 노드를 증감(추가, 삭제) 하려면, 현재 작업 중인 워커 노드의 잡정보를 동기화(sync) 하여 새로 들어온 워커 노드에게 일정 부분 작업을 맡길 수 있다. 엘라스틱 서비스는 딥러닝 분산 훈련 시 Tensorflow, Pytorch, Keras를 지원한다. 도 18은 도 3에 도시된 동기화 서비스 매니저 모듈의 개념도이다. 도 18을 참조하면, 작업의 동기화는 동 기 서비스 매니저(Synchronization service manager) 모듈이 관리한다. 동기 서비스 매니저 모듈은 현재 잡(job)의 내용(Job Descriptor), 현재 처리 중인 잡, 현재 남아있는 잡을 체크포인트에 기록하여 관리한 다. 현재 남아있는 작업은 워커 노드의 수로 나누어 분할된 상태(Job)로 가지고 있고, 기존 노드(Old wokrernode)가 계속해서 남아있는 작업의 할당분을 수행하다가 다른 작업을 수행하고 리소스를 반납한 새 로운 워커 노드(New wokernode)가 출현하면 현재 남아있는 작업의 일부를 수행시킨다. 도 19는 도 18에 따른 동기화 서비스 매니저의 동기화 과정을 보여주는 흐름도이다. 도 19를 참조하면, 현재 남 아있는 작업은 워커 노드의 수로 나누어 분할된 상태(Distribution Job)로 가지고 있고, 기존 노드(Old wokrernode)가 계속해서 남아있는 작업의 할당분을 수행하다가 다른 작업을 수행하고 리소스를 반납한 새 로운 워커 노드(New wokernode)가 출현하면 현재 남아있는 작업의 일부를 수행시킨다(단계 S1910,S1920,S1930,S1940,S1950,S1960,S1970,S1980). 즉, 새로운 작업의 추가를 기준으로 현재 작업 처리 블럭 또는 새로운 작업 처리 블럭이 실행된다. 이를 통해, 작업의 무중단을 통해 유연한 리소스 관리를 할 수 있으며, 이것은 곧 성능 향상에 영향을 미치게 된다. 작업을 완료한 후에는 동기 서비스 매니저 모듈이 각 워커 노드들의 체크 포인트 이미지를 검사 (Audit)하여 현재 작업의 내용과 남아있는 작업들을 올바르게 수행했는지 확인하고 성공 여부를 사용자에게 알 려준다. 사용자는 검사 부분이 필요 없이 빠르게 작업을 수행하고 싶다면, 이 부분을 건너뛸 수 있다. 작업에 참여한 워커 노드는 작업 클러스터로 관리한다. 만약, 일부 워커 노드가 네트워크 상황이 잘못되어 작업을 처리 하지 못할 경우 상태 검사(Health Check)를 실시한다. 이에 따라 워커 노드는 작업 클러스터에서 제외되고, 작 업이 없는 새로운 워커 노드가 출현하면 해당 작업 클러스터에 등록된다. 도 20은 본 발명의 일실시예에 따른 관리자 관점의 스토리지 워크플로우이다. 도 20을 참조하면, 스토리지(13 0)는 GPU 스토리지와 객체(Object) 스토리지로 구성된다. 객체 스토리지는 파일 단위로 데이터를 쓰고 읽을 수 있는 저장 공간으로 Stateless한 컨테이너의 데이터를 외부에 영구적으로 저장하고 관리할 때 이용하는 서비스 이다. 객체 스토리지의 데이터는 컨테이너에서 원격(Remote) API를 통하여 접근할 수 있다. 도 20을 참조하면, DB 관리자는 스토리지 모니터 모듈에 접속하여 Data 현황과 쿼리 인터페이스를 제공받는다(단계 S2010). 이후, AnsiSQL 규약의 쿼리 작성시 SQL 관리 프레임워크가 GPU 스토리지와 객체(Object) 스토리지에게 쿼리 결 과를 전송한다(단계 S2020). 이후, DB 관리자는 양쪽 DB에서 나온 결과값을 결합할지 또는 따로 받을지를 선택한다(단계 S2030). 이후, 최종 결과값을 추가분석할 수 있는 형태로 저장하거나 모니터에서 그래프로 확인가능하다(단계 S2040). 도 21은 본 발명의 일실시예에 따른 객체 스토리지의 구성도이다. 도 21을 참조하면, 고속으로 데이터를 처리하기 위해서 객체 스토리지를 분산처리 구조로 클러스터링해서 사용해야 한다. 스토리지 브로커 모듈 및 스토리지 게이트웨이(Storage Gateway) 모듈은 클라이언트와 클러스터 내부의 데이터 전송을 중개해 주 는 프록시 역할을 수행한다. 스토리지 매니저(Storage Manager) 모듈은 객체를 저장하고 REST API를 이용 하여 다수의 노드에 분산되어 있는 데이터 파일을 생성, 수정, 삭제, 저장을 한다. 스토리지 모니터(Storage Monitor) 모듈는 클러스터를 관리하고 유지하는 데몬(Daemon)으로 보안을 관리하 고 로그를 시각화하여 운영한다. OSD(Object Storage Daemon) 블럭은 제 1 서브 블럭 및 제 2 서 브 블럭으로 구성되며, 제 1 서브 블럭은 4개의 OSD(2131-1)로 구성되며, 제 2 서브 블럭은 4개의 디스크(2132-1)로 구성된다. 이때, 데이터의 형식을 키(Key), 밸류(Value), 메타데이터(Metadata) 형태로 디스크에 데이터를 저장한다. 도 22a 및 도 22b는 본 발명의 일실시예에 따른 샤딩 및 복제(sharding & Replication)의 개념도이다. 도 22a 를 참조하면, 분산된 다수의 스토리지 노드에 데이터를 저장할 때, 샤딩(Sharding) 기능으로 어느 곳에 배치할지 결정하는 알고리즘이 필요하다. 스토리지 매니저 모듈는 크기에 맞는 최적의 디스크(2132-1)를 찾고 OSD(Object Storage Daemon)(2131-1)에게 샤딩(Sharding) 명령을 내려서 데이터를 분배 저장분산 저장한 다(2221,2222,2223). 여기서 분산저장된 데이터의 저장날짜, 데이터 용량, 나누어진 블록의 수, OSD위치정보 등 의 객체정보를 파일 메타데이터(file metadata)의 형태로 스토리지 모니터 모듈에게 제공한다. 도 22b를 참조하면, 스토리지 모니터 모듈은 이러한 정보를 활용하여 데이터를 읽거나 저장할 때, 파일 메 타데이터를 활용하여 서버 여러 곳에 분산 저장된 데이터들의 위치를 알 수 있다. 데이터를 읽는(Read) 과정의 경우 최초로 저장된 프라이머리(Primary) OSD를 이용하여 동작을 수행하고 쓰기(Write) 과정의 경우 복제 본(Replica)이 저장될 OSD 정보도 같이 보내서 MAP을 업데이트하여 영구적으로 관리한다. OSD의 내부는 프라이머리(Primary) OSD, 세컨더리(secondary) OSD 및 테르시어리(Tertiary) OSD의 형태로 구성되어있다. 여기서 Primary OSD는 데이터의 유실을 대비하기 위하여 Secondary OSD와 Tertiary OSD에 복제본(replica)을 저장하고, 기본값으로 각 1개씩 총 3개의 복제본을 유지한다. 유저(즉 사용자) 설정에 따라 복제본의 수를 조절할 수 있다. 도 23은 본 발명의 일실시예에 따른 GPU(graphics processing unit) 스토리지 구성도이다. 도 23을 참조하면, GPU 스토리지는 GPU를 활용하여 객체 스토리지보다 더 빠르게 데이터를 연산하고 집계할 수 있는 기능을 제공하 며, GPU 병렬 처리 컴퓨팅 파워를 이용하여 고속 데이터 전처리 과정도 가능하다. 브로커(2321,2322)를 통해 실 시간으로 테라바이트 이상의 대량의 데이터를 받아오면 인메모리에서 GPU 가속(Accelerated)을 통해 대용 량 데이터를 처리하고 다음에 설명할 GPU 스토리지나 객체 스토리지에 저장 가능하다(2331,2332,2333). GPU 스토리지에 저장되어 있는 데이터는 브로커를 통해 데이터 분산 처리에서 재사용할 수 있는 API를 제 공한다. GPU 스토리지는 데이터 고속 처리에 특화되어 고속으로 시각적 효과를 보여줄 수 있는 렌더링 기능도 제공한다. 렌더(Render)에서 GPU에서 처리되는 데이터들을 대시보드에 필요한 데이터 포맷으로 전달하여 대용량 의 데이터를 대시보드에서 확인하고 시각화하는 것이 가능하다. 도 24는 본 발명의 일실시예에 따른 SQL(Structured Query Language) 질의 형태의 개념도이다. 도 24를 참조하 면, 표준 질의 프레임워크는 표준 SQL 규약에 맞게 작성된 SQL을 제공한다. 이러한 이유는 이기종의 데이 터베이스들마다 완전히 다르거나 조금씩 다른 형태의 SQL 질의 언어 (Dialect SQL)를 사용한다. 이를 위해서 다 른 SQL 언어에 맞게 공통의 표준 SQL 질의 언어로 변환하는 기능을 제공한다. 사용자 입장에서 질의를 할 때 GPU 스토리지와 객체 스토리지에 각각 직접 접속하지 않아도 하나의 쿼리로 두 가지의 결과를 모두 얻을 수 있 다. 도면 기재된 \"…모듈\" 의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 소프트웨어 및/또는 하드웨어로 구현될 수 있다. 하드웨어 구현에 있어, 상술한 기능을 수행하기 위해 디자인된 ASIC(application specific integrated circuit), DSP(digital signal processing), PLD(programmable logic device), FPGA(field programmable gate array), 프로세서, 마이크로프로세서, 다른 전자 유닛 또는 이들의 조 합으로 구현될 수 있다. 소프트웨어 구현에 있어, 소프트웨어 구성 컴포넌트(요소), 객체 지향 소프트웨어 구성 컴포넌트, 클래스 구성 컴포넌트 및 작업 구성 컴포넌트, 프로세스, 기능, 속성, 절차, 서브 루틴, 프로그램 코 드의 세그먼트, 드라이버, 펌웨어, 마이크로 코드 , 데이터, 데이터베이스, 데이터 구조, 테이블, 배열 및 변수 를 포함할 수 있다. 소프트웨어, 데이터 등은 메모리에 저장될 수 있고, 프로세서에 의해 실행된다. 메모리나 프로세서는 당업자에게 잘 알려진 다양한 수단을 채용할 수 있다. 또한, 여기에 개시된 실시형태들과 관련하여 설명된 방법 또는 알고리즘의 단계들은, 마이크로프로세서, 프로세 서, CPU(Central Processing Unit) 등과 같은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태 로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 (명령) 코드,데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 (명령) 코드는 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소 프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프 등과 같은 자기 매체(magnetic media), CD-ROM, DVD, 블루레이 등과 같 은 광기록 매체(optical media) 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 (명령) 코드를 저장하 고 수행하도록 특별히 구성된 반도체 기억 소자가 포함될 수 있다. 여기서, 프로그램 (명령) 코드의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프 리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가 지이다."}
{"patent_id": "10-2021-0113335", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 GPU 기반 전력 데이터 고속 분산 처리 시스템의 블럭 구성도이다. 도 2는 도 1에 도시된 워크 벤치부의 세부 구성 블럭도이다. 도 3은 도 1에 도시된 데이터 분산 처리부의 세부 구성 블럭도이다. 도 4는 도 1에 도시된 스토리지의 세부 구성 블럭도이다. 도 5는 도 1에 도시된 하드웨어의 세부 구성 블럭도이다. 도 6은 도 1에 도시된 네트워크의 세부 구성 블럭도이다. 도 7은 본 발명의 일실시예에 따른 유저 관점 워크 벤치 과정을 보여주는 흐름도이다. 도 8은 본 발명의 일실시예에 따른 분석 노트북 화면의 구성 예시이다. 도 9는 본 발명의 일실시예에 따른 엔진 단위의 배포 개념도이다. 도 10은 본 발명의 일실시예에 따른 분석 환경 개인화 구성의 개념도이다. 도 11은 본 발명의 일실시예에 따른 서비스 로드 구성의 개념도이다. 도 12는 본 발명의 일실시예에 따른 로그 검색 및 백업 관리의 개념도이다. 도 13은 본 발명의 일실시예에 따른 다이렉트 패쓰 쓰루(Direct Pass Through) 기술의 개념도이다. 도 14는 도 5에 도시된 리소스 매니저의 개념도이다. 도 15는 본 발명의 일실시예에 따른 2 계층 구조의 개념도이다. 도 16은 본 발명의 일실시예에 따른 클러스터 컴퓨팅 프레임워크 구조의 개념도이다. 도 17은 본 발명의 일실시예에 따른 데이터 형태별 처리 구성도이다. 도 18은 도 3에 도시된 동기화 서비스 매니저 모듈의 개념도이다. 도 19는 도 18에 따른 동기화 서비스 매니저의 동기화 과정을 보여주는 흐름도이다.도 20은 본 발명의 일실시예에 따른 관리자 관점의 스토리지 워크플로우이다. 도 21은 본 발명의 일실시예에 따른 객체 스토리지의 구성도이다. 도 22a 및 도 22b는 본 발명의 일실시예에 따른 샤딩 및 복제(sharding & Replication)의 개념도이다. 도 23은 본 발명의 일실시예에 따른 GPU(graphics processing unit) 스토리지 구성도이다. 도 24는 본 발명의 일실시예에 따른 SQL(Structured Query Language) 질의 형태의 개념도이다."}
