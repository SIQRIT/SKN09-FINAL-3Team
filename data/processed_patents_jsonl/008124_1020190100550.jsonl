{"patent_id": "10-2019-0100550", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0020646", "출원번호": "10-2019-0100550", "발명의 명칭": "이미지에 보케 효과를 적용하는 방법 및 기록매체", "출원인": "주식회사 날비컴퍼니", "발명자": "이용수"}}
{"patent_id": "10-2019-0100550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자 단말에서 이미지에 보케 효과를 적용하는 방법에 있어서,이미지를 수신하고, 상기 수신된 이미지를 제1 인공신경망 모델의 입력층으로 입력하여 상기 이미지 내의 픽셀들에 대한 심도 정보를 나타내는 심도 맵(depth map)을 생성하는 단계; 및상기 이미지 내의 픽셀들에 대한 심도 정보를 나타내는 상기 심도 맵에 기초하여 상기 이미지 내의 픽셀들에 상기 보케 효과를 적용하는 단계를 포함하고,상기 제1 인공신경망 모델은 복수의 참조 이미지를 입력층으로 수신하고 상기 복수의 참조 이미지 내에 포함된심도 정보를 추론하도록 기계 학습을 수행함으로써 생성되는,보케 효과를 적용하는 방법."}
{"patent_id": "10-2019-0100550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 수신된 이미지 내에 포함된 객체에 대한 세그멘테이션 마스크(segmentation mask)를 생성하는 단계를 더포함하고,상기 심도 맵을 생성하는 단계는 상기 생성된 세그멘테이션 마스크를 이용하여 상기 심도 맵을 보정하는 단계를포함하는, 보케 효과를 적용하는 방법."}
{"patent_id": "10-2019-0100550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 보케 효과를 적용하는 단계는,상기 세그멘테이션 마스크에 대응되는 기준 심도를 결정하는 단계; 상기 기준 심도와 상기 이미지 내의 상기 세그멘테이션 마스크의 이외의 영역 내의 다른 픽셀들의 심도 사이의차이를 산출하는 단계; 및 상기 산출된 차이에 기초하여 상기 이미지에 상기 보케 효과를 적용하는 단계를 포함하는, 보케 효과를 적용하는 방법."}
{"patent_id": "10-2019-0100550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 복수의 참조 이미지를 입력층으로 수신하고 상기 복수의 참조 이미지 내의 세그멘테이션 마스크를 추론하도록 구성된 제2 인공신경망 모델이 기계 학습을 통해 생성되고, 상기 세그멘테이션 마스크를 생성하는 단계는 상기 수신된 이미지를 상기 제2 인공신경망 모델의 입력층으로 입력하여 상기 수신된 이미지 내에 포함된 객체에 대한 세그멘테이션 마스크를 생성하는 단계를 포함하는,공개특허 10-2020-0020646-3-보케 효과를 적용하는 방법."}
{"patent_id": "10-2019-0100550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 수신된 이미지 내에 포함된 객체를 탐지한 탐지 영역을 생성하는 단계를 더 포함하고,상기 세그멘테이션 마스크를 생성하는 단계는 상기 생성된 탐지 영역 내에서 상기 객체에 대한 세그멘테이션 마스크를 생성하는 단계를 포함하는,보케 효과를 적용하는 방법."}
{"patent_id": "10-2019-0100550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,적용될 보케 효과에 대한 설정 정보를 수신하는 단계를 더 포함하고,상기 수신된 이미지는 복수의 객체를 포함하고, 상기 탐지 영역을 생성하는 단계는, 상기 수신된 이미지 내에 포함된 복수의 객체의 각각을 탐지한 복수의 탐지영역을 생성하는 단계를 포함하고, 상기 세그멘테이션 마스크를 생성하는 단계는, 상기 복수의 탐지 영역의 각각 내에서 상기 복수의 객체의 각각에 대한 복수의 세그멘테이션 마스크를 생성하는 단계를 포함하고, 상기 보케 효과를 적용하는 단계는, 상기 설정 정보가 상기 복수의 세그멘테이션 마스크 중 적어도 하나의 세그멘테이션 마스크에 대한 선택을 나타내는 경우, 상기 이미지 내의 영역 중 상기 선택된 적어도 하나의 세그멘테이션 마스크 외의 영역을 아웃포커스(OUT-OF-FOCUS)시키는 단계를 포함하는, 보케 효과를 적용하는 방법."}
{"patent_id": "10-2019-0100550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서,복수의 참조 세그멘테이션 마스크를 입력층으로 수신하고 상기 복수의 참조 세그멘테이션 마스크의 심도 정보를추론하도록 구성된 제3 인공신경망 모델은 기계학습을 통해 생성되고, 상기 심도 맵을 생성하는 단계는 상기 세그멘테이션 마스크를 상기 제3 인공신경망 모델의 입력층으로 입력하여상기 세그멘테이션 마스크가 나타내는 심도 정보를 결정하는 단계를 포함하고, 상기 보케 효과를 적용하는 단계는, 상기 세그멘테이션 마스크의 심도 정보를 기초하여 상기 세그멘테이션 마스크에 상기 보케 효과를 적용하는 단계를 포함하는,보케 효과를 적용하는 방법."}
{"patent_id": "10-2019-0100550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 심도 맵을 생성하는 단계는 상기 제1 인공신경망 모델의 입력층에 요구되는 데이터를 생성하기 위하여 상기 이미지의 전처리를 수행하는 단계를 포함하는,공개특허 10-2020-0020646-4-보케 효과를 적용하는 방법."}
{"patent_id": "10-2019-0100550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 심도 맵을 생성하는 단계는 상기 제1 인공신경망 모델을 통해 상기 이미지 내의 적어도 하나의 객체를 결정하는 단계를 포함하고, 상기 보케 효과를 적용하는 단계는,상기 결정된 적어도 하나의 객체에 대응되는 기준 심도를 결정하는 단계; 상기 기준 심도와 상기 이미지 내의 다른 픽셀들의 각각의 심도 사이의 차이를 산출하는 단계; 및 상기 산출된 차이에 기초하여 상기 이미지에 보케 효과를 적용하는 단계를 포함하는,보케 효과를 적용하는 방법."}
{"patent_id": "10-2019-0100550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항 내지 제9항 중 어느 한 항에 따른 사용자 단말에서 이미지에 보케 효과를 적용하는 방법을 컴퓨터에서 실행하기 위한 컴퓨터 프로그램이 기록된, 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2019-0100550", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 사용자 단말에서 이미지에 보케 효과를 적용하는 방법에 관한 것이다. 보케 효과를 적용하는 방법은, 이미지를 수신하고, 수신된 이미지를 제1 인공신경망 모델의 입력층으로 입력하여 이미지 내의 픽셀들에 대한 심 도 정보를 나타내는 심도 맵(depth map)을 생성하는 단계 및 이미지 내의 픽셀들에 대한 심도 정보를 나타내는 심도 맵을 기초로 이미지 내의 픽셀들에 보케 효과를 적용하는 단계를 포함할 수 있다. 여기서, 제1 인공신경망 모델은 복수의 참조 이미지를 입력층으로 수신하고 복수의 참조 이미지 내에 포함된 심도 정보를 추론하도록 기 계 학습을 수행함으로써 생성될 수 있다."}
{"patent_id": "10-2019-0100550", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 컴퓨터 비전 기술을 이용하여 이미지에 보케 효과를 제공하는 방법, 기록매체에 관한 것이다."}
{"patent_id": "10-2019-0100550", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 휴대용 단말기가 빠르게 발전하고 널리 보급되어, 휴대용 단말기 장치에 구비된 카메라 장치 등으로 영상 을 촬영하는 것이 보편화되었다. 이는 종래 영상을 촬영하기 위해서 별도의 카메라 장치를 휴대해야 했던 것을 대체하게 된 것이다. 나아가, 최근에는 사용자들로부터, 스마트폰으로부터 단순히 영상을 촬영하여 획득하는 것을 넘어, 고급 카메라 장비에서 제공되는 고품질의 영상 또는 고급 영상 처리 기술이 적용된 이미지 또는 사 진을 획득하는 데에 많은 관심을 갖고 있다. 이미지 촬영기술 중 하나로 보케 효과가 있다. 보케 효과는 촬영 이미지에서 초점이 맞지 않은 부분이 흐려지 는 미학적 양상을 말한다. 초점면은 선명하지만, 초점면의 앞이나 뒤는 흐릿하게 처리하여 초점면을 강조하는 효과이다. 넓은 의미의 보케 효과는 초점이 맞지 않은 부분을 아웃포커싱(흐리게 또는 빛망울로 처리하는 것) 하는 것뿐 아니라, 초점이 맞은 부분을 인포커싱(in-focusing) 또는 하이라이트(highlight)하는 것을 아울러 일 컫는다. 렌즈가 큰 장비, 예를 들면 DSLR의 경우 얕은 심도를 이용하여 극적인 보케 효과를 나타낼 수가 있다. 하지만 휴대용 단말기의 경우 구조적인 문제로 DSLR과 같은 보케 효과를 구현하기에 난점이 있다. 특히 DSLR 카메라에 서 제공하는 보케 효과는 기본적으로 카메라 렌즈에 장착된 조리개의 특정 형상(예를 들어, 하나 이상의 조리개 날의 형상)으로 인해 생성될 수 있는데. 휴대용 단말기의 카메라는 DSLR 카메라와 달리 휴대용 단말기의 제조 비용 및/또는 크기 등으로 인해 조리개날이 없는 렌즈를 사용하므로 보케 효과를 구현하기가 쉽지 않다. 이러한 사정으로 인해, 종래의 휴대용 단말기 카메라는 이러한 보케 효과를 구현하기 위해, RGB 카메라를 두 개"}
{"patent_id": "10-2019-0100550", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "이상 구성하거나, 이미지 촬영 당시 적외선 거리 센서를 이용하여 거리를 측정하는 등의 방식을 이용했다.발명의 내용"}
{"patent_id": "10-2019-0100550", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는, 컴퓨터 비전 기술을 통해, 스마트폰 카메라 등으로부터 촬영된 이미지에, 고품질 카메라에서 구현가 능한 아웃포커싱 및/또는 인포커싱 효과, 즉 보케 효과를 구현하는 장치 및 방법을 개시하는 것을 목적으로 한 다."}
{"patent_id": "10-2019-0100550", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따른 사용자 단말에서 이미지에 보케 효과를 적용하는 방법은, 이미지를 수신하고, 수신 된 이미지를 제1 인공신경망 모델의 입력층으로 입력하여 이미지 내의 픽셀들에 대한 심도 정보를 나타내는 심 도 맵(depth map)을 생성하는 단계 및 이미지 내의 픽셀들에 대한 심도 정보를 나타내는 심도 맵을 기초로 이미 지 내의 픽셀들에 보케 효과를 적용하는 단계를 포함할 수 있고, 제1 인공신경망 모델은 복수의 참조 이미지를 입력층으로 수신하고 복수의 참조 이미지 내에 포함된 심도 정보를 추론하도록 기계 학습을 수행함으로써 생성 될 수 있다. 일 실시예에 따르면, 보케 효과를 적용하는 방법은, 수신된 이미지 내에 포함된 객체에 대한 세그멘테이션 마스 크(segmentation mask)를 생성하는 단계를 더 포함하고, 심도 맵을 생성하는 단계는, 생성된 세그멘테이션 마스 크를 이용하여 심도 맵을 보정하는 단계를 포함할 수 있다. 일 실시예에 따르면, 보케 효과를 적용하는 단계는, 세그멘테이션 마스크에 대응되는 기준 심도를 결정하는 단 계, 기준 심도와 이미지 내의 세그멘테이션 마스크의 이외의 영역 내의 다른 픽셀들의 심도 사이의 차이를 산출 하는 단계 및 산출된 차이에 기초하여 이미지에 보케 효과를 적용하는 단계를 포함할 수 있다. 일 실시예에 따르면, 보케 효과를 적용하는 방법에서, 복수의 참조 이미지를 입력층으로 수신하고 복수의 참조 이미지 내의 세그멘테이션 마스크를 추론하도록 구성된 제2 인공신경망 모델이 기계학습을 통해 생성되고, 세그 멘테이션 마스크를 생성하는 단계는 수신된 이미지를 제2 인공신경망 모델의 입력층으로 입력하여 수신된 이미 지 내에 포함된 객체에 대한 세그멘테이션 마스크를 생성하는 단계를 포함할 수 있다. 일 실시예에 따르면, 보케 효과를 적용하는 방법은, 수신된 이미지 내에 포함된 객체를 탐지한 탐지 영역을 생 성하는 단계를 더 포함하고, 세그멘테이션 마스크를 생성하는 단계는 생성된 탐지 영역 내에서 객체에 대한 세 그멘테이션 마스크를 생성하는 단계를 포함할 수 있다. 일 실시예에 따르면, 보케 효과를 적용하는 방법은, 적용될 보케 효과 적용에 대한 설정 정보를 수신하는 단계 를 더 포함하고, 수신된 이미지는 복수의 객체를 포함하고, 탐지 영역을 생성하는 단계는, 수신된 이미지 내에 포함된 복수의 객체의 각각을 탐지한 복수의 탐지 영역을 생성하는 단계를 포함하고, 세그멘테이션 마스크를 생 성하는 단계는, 복수의 탐지 영역의 각각 내에서 복수의 객체의 각각에 대한 복수의 세그멘테이션 마스크를 생 성하는 단계를 포함하고, 보케 효과를 적용하는 단계는, 설정 정보가 복수의 세그멘테이션 마스크 중 적어도 하 나의 세그멘테이션 마스크에 대한 선택을 나타내는 경우, 이미지 내의 영역 중 선택된 적어도 하나의 세그멘테 이션 마스크 외의 영역을 아웃포커스(OUT-OF-FOCUS)시키는 단계를 포함할 수 있다. 일 실시예에 따르면, 보케 효과를 적용하는 방법에서, 복수의 참조 세그멘테이션 마스크를 입력층으로 수신하고 복수의 참조 세그멘테이션 마스크의 심도 정보를 추론하도록 구성된 제3 인공신경망 모델은 기계학습을 통해 생 성되고, 심도 맵을 생성하는 단계는 세그멘테이션 마스크를 제3 인공신경망 모델의 입력층으로 입력하여 세그멘 테이션 마스크가 나타내는 심도 정보를 결정하는 단계를 포함하고, 보케 효과를 적용하는 단계는, 세그멘테이션 마스크의 심도 정보를 기초하여 세그멘테이션 마스크에 보케 효과를 적용하는 단계를 포함할 수 있다. 일 실시예에 따르면, 심도 맵을 생성하는 단계는 제1 인공신경망 모델의 입력층에 요구되는 데이터를 생성하기 위하여 이미지의 전처리를 수행하는 단계를 포함할 수 있다. 일 실시예에 따르면, 심도 맵을 생성하는 단계는 제1 인공신경망 모델을 통해 이미지 내의 적어도 하나의 객체 를 결정하는 단계를 포함하고, 보케 효과를 적용하는 단계는, 결정된 적어도 하나의 객체에 대응되는 기준 심도 를 결정하는 단계, 기준 심도와 이미지 내의 다른 픽셀들의 각각의 심도 사이의 차이를 산출하는 단계 및 산출된 차이에 기초하여 이미지에 보케 효과를 적용하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 전술한 사용자 단말에서 이미지에 보케 효과를 적용하는 방법을 컴퓨터에서 실행하기 위 한 컴퓨터 프로그램이 기록된, 컴퓨터로 판독 가능한 기록 매체가 제공된다."}
{"patent_id": "10-2019-0100550", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일부 실시예에 따르면, 이미지에 보케 효과를 적용함에 있어서 학습된 인공신경망 모델을 이용하여 생성한 심도 맵의 심도 정보를 기초로 함으로써, 고가의 장비를 필요로 하는 심도 이미지(depth image)나 적외 선 센서가 없이도, 보급형 장비, 예를 들면 스마트폰 카메라로부터 촬영된 이미지에 극적인 보케 효과를 적용할 수 있다. 또한, 촬영 당시에 보케 효과가 부여되지 않아도, 저장된 이미지 파일, 예를 들면 단일 RGB 또는 YUV 포맷의 이미지 파일에도 사후적으로 보케 효과를 적용하는 것이 가능하다. 본 개시의 일부 실시예에 따르면, 이미지 내의 객체에 대한 세그멘테이션 마스크를 이용해 심도 맵을 보정함으 로써, 발생된 심도 맵의 오류 또는 오차를 보완하여 피사체와 배경을 더욱 명확히 구분하여 원하는 보케 효과를 얻을 수 있다. 또한, 단일 객체인 피사체 내부에서도 심도 차이로 인하여 일부가 흐릿하게 처리되는 문제점을 해결하여 더 개선된 보케 효과를 적용할 수 있다. 또한, 본 개시의 일부 실시예에 따르면, 특정 대상을 위한 별도의 학습된 인공신경망 모델을 이용하여, 특정 대 상에 특화된 보케 효과를 적용할 수 있다. 예를 들면, 인물에 대해 별도로 학습된 인공신경망 모델을 이용하여, 인물사진에 있어서, 인물 영역에는 더욱 세밀한 심도 맵을 얻고, 더욱 극적인 보케 효과를 적용할 수 있다. 본 개시의 일부 실시예에 따르면, 터치 스크린과 같은 입력 장치가 구성된 단말기 상에서, 사용자에게 용이하면 서도 효과적으로 보케 효과를 부여할 수 있는 UX(User Experience)가 제공된다."}
{"patent_id": "10-2019-0100550", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 실시를 위한 구체적인 내용을 첨부된 도면을 참조하여 상세히 설명한다. 다만, 이하의 설명에 서는 본 개시의 요지를 불필요하게 흐릴 우려가 있는 경우, 널리 알려진 기능이나 구성에 관한 구체적 설명은 생략하기로 한다. 첨부된 도면에서, 동일하거나 대응하는 구성요소에는 동일한 참조부호가 부여되어 있다. 또한, 이하의 실시예 들의 설명에 있어서, 동일하거나 대응되는 구성요소를 중복하여 기술하는 것이 생략될 수 있다. 그러나 구성요 소에 관한 기술이 생략되어도, 그러한 구성요소가 어떤 실시예에 포함되지 않는 것으로 의도되지는 않는다. 개시된 실시예의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 후술되어 있는 실시예 들을 참조하면 명확해질 것이다. 그러나 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 개시가 완전하도록 하고, 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것일 뿐이다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 개시된 실시예에 대해 구체적으로 설명하기로 한다. 본 명세서에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들 을 선택하였으나, 이는 관련 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에 서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용 어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서의 단수의 표현은 문맥상 명백하게 단수인 것으로 특정하지 않는 한, 복수의 표현을 포함한다. 또한, 복수의 표현은 문맥상 명백하게 복수인 것으로 특정하지 않는 한, 단수의 표현을 포함한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에서 사용되는 \"부\" 또는 \"모듈\"이라는 용어는 소프트웨어 또는 하드웨어 구성요소를 의미하며, \" 부\" 또는 \"모듈\"은 어떤 역할들을 수행한다. 그렇지만 \"부\" 또는 \"모듈\"은 소프트웨어 또는 하드웨어에 한정되 는 의미는 아니다. \"부\" 또는 \"모듈\"은 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 \"부\" 또는 \"모듈\"은 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이 크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들 중 적어도 하나를 포함 할 수 있다. 구성요소들과 \"부\" 또는 \"모듈\"들은 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 \"부\" 또 는 \"모듈\"들로 결합되거나 추가적인 구성요소들과 \"부\" 또는 \"모듈\"들로 더 분리될 수 있다. 본 개시의 일 실시예에 따르면 \"부\" 또는 \"모듈\"은 프로세서 및 메모리로 구현될 수 있다. 용어 \"프로세서\"는 범용 프로세서, 중앙 처리 장치(CPU), 마이크로프로세서, 디지털 신호 프로세서(DSP), 제어기, 마이크로제어기, 상태 머신 등을 포함하도록 넓게 해석되어야 한다. 몇몇 환경에서는, \"프로세서\"는 주문형 반도체(ASIC), 프로 그램가능 로직 디바이스(PLD), 필드 프로그램가능 게이트 어레이(FPGA) 등을 지칭할 수도 있다. 용어 \"프로세 서\"는, 예를 들어, DSP와 마이크로프로세서의 조합, 복수의 마이크로프로세서들의 조합, DSP 코어와 결합한 하 나 이상의 마이크로프로세서들의 조합, 또는 임의의 다른 그러한 구성들의 조합과 같은 처리 디바이스들의 조합을 지칭할 수도 있다. 또한, 용어 \"메모리\"는 전자 정보를 저장 가능한 임의의 전자 컴포넌트를 포함하도록 넓게 해석되어야 한다. 용어 \"메모리\"는 임의 액세스 메모리(RAM), 판독-전용 메모리(ROM), 비-휘발성 임의 액세스 메모리(NVRAM), 프 로그램가능 판독-전용 메모리(PROM), 소거-프로그램가능 판독 전용 메모리(EPROM), 전기적으로 소거가능 PROM(EEPROM), 플래쉬 메모리, 자기 또는 광학 데이터 저장장치, 레지스터들 등과 같은 프로세서-판독가능 매체 의 다양한 유형들을 지칭할 수도 있다. 프로세서가 메모리로부터 정보를 판독하고/하거나 메모리에 정보를 기 록할 수 있다면 메모리는 프로세서와 전자 통신 상태에 있다고 불린다. 프로세서에 집적된 메모리는 프로세서 와 전자 통신 상태에 있다. 본 개시에서, '사용자 단말'은 통신 모듈을 구비하여 네트워크 연결을 통해 서버 또는 시스템에 접속가능하고, 이미지 또는 영상을 출력하거나 표시하는 것이 가능한 임의의 전자 기기(예를 들어, 스마트폰, PC, 태블릿 PC) 등일 수 있다. 사용자는 사용자 단말의 인터페이스(예를 들어, 터치 디스플레이, 키보드, 마우스, 터치펜 또는 스틸러스, 마이크로폰, 동작인식 센서)를 통하여 이미지에 보케 효과 등의 영상 처리를 위한 임의의 명령을 입 력할 수 있다. 본 개시에서, '시스템'은 서버 장치와 클라우드 서버 장치 중 적어도 하나의 장치를 지칭할 수 있지만, 이에 한 정되는 것은 아니다. 또한, '이미지'는, 하나 이상의 픽셀을 포함한 이미지를 가리키며, 전체 이미지를 복수 개의 로컬 패치로 분할 한 경우, 분할된 하나 이상의 로컬 패치를 지칭할 수 있다. 또한, '이미지' 하나 이상의 이미지 또는 영상을 가리킬 수 있다. 또한, '이미지를 수신한다는 것'은, 동일 장치에 부착된 이미지 센서로부터 촬영되어 획득된 이미지를 수신한다 는 것을 포함할 수 있다. 다른 실시예에 따르면, \"이미지를 수신한다는 것\"은 유선 또는 무선 통신장치를 통하 여 외부 장치로부터 이미지를 수신하거나 저장 장치로부터 전송받는 것을 포함할 수 있다. 또한, '심도 맵(depth map)'은 이미지 내의 픽셀들의 심도를 나타내거나 특징화하는 수치들 또는 숫자들의 집합 을 지칭하는 것으로서, 예를 들어, 심도 맵은 심도를 나타내는 복수의 숫자를 행렬 또는 벡터의 형태로 나타낼 수 있다. 또한, 용어는 \"보케 효과\"는 이미지의 적어도 일부분에 적용되는 임의의 심미적인 또는 미적인 효과 를 지칭할 수 있다. 예를 들어, 보케 효과는 초점이 맞지 않은 부분을 아웃포커싱함으로써 생성되는 효과 및/ 또는 초점이 맞은 부분을 강조, 하이라이트(highlight) 또는 인포커싱함으로써 생성되는 효과를 지칭할 수 있다. 나아가, '보케 효과'는 필터(Filter) 효과나 이미지 상에 적용될 수 있는 임의의 효과를 지칭할 수 있다.아래에서는 첨부한 도면을 참고하여 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명 과 관계없는 부분은 생략한다. 컴퓨터 비전 기술(Computer Vision)은 인간의 눈의 기능과 동일한 형태를 컴퓨팅 장치를 통해 행하는 기술로서, 컴퓨팅 장치가 이미지 센서로부터 입력 받은 영상을 분석하여 이미지 내의 객체 및/또는 환경 특징 등의 유용한 정보를 생성하는 기술을 나타낼 수 있다. 인공 신경망을 이용한 기계 학습은 사람 또는 동물 두뇌의 신경망에 착안하여 구현된 임의의 컴퓨팅 시스템을 통해 수행될 수 있으며, 기계 학습(machine learning)의 세부 방법론 중 하나로, 신경 세포인 뉴런(neuron)이 여러 개 연결된 망의 형태를 이용한 기계 학습을 지칭할 수 있다. 본 개시의 일부 실시예에 따르면, 이미지 내의 객체에 대응하는 세그멘테이션 마스크 이용하여 심도 맵을 보정 함으로써, 학습된 인공신경망 모델을 통해 출력되는 결과에서 발생될 수 있는 오류 또는 오차를 보완하여 이미 지 내의 객체(예를 들어, 피사체, 배경 등)을 더욱 명확히 구분하여 더욱 효과적인 보케 효과가 얻어질 수 있다. 나아가, 본 개시의 일부 실시예에 따르면, 단일 객체인 피사체 내부의 심도 차이에 기초하여 보케 효과 가 적용되기 때문에, 단일 객체인 피사체 내에서 보케 효과도 적용하는 것이 가능하다. 도 1은 본 개시의 일 실시예에 따른 사용자 단말이 이미지로부터 심도 맵을 생성하여 이를 기초로 보케 효과를 적용하는 과정을 나타내는 예시도이다. 도 1에 도시된 바와 같이, 사용자 단말은 원본 이미지로부터 보케 효과가 적용된 이미지를 생성할 수 있다. 사용자 단말은 원본 이미지를 수신하여 보케 효과를 적용 할 수 있는데, 예를 들면, 복수의 객체가 포함된 이미지를 수신하여, 특정 객체(예를 들어, 사람)에 초점 을 맞추고 사람을 제외한 나머지 객체들(여기서는, 배경)에 대해서 아웃포커싱 효과를 적용하여 이러한 보케 효 과가 적용된 이미지를 생성할 수 있다. 여기서, 아웃포커싱(OUT-OF-FOCUS) 효과는 영역을 흐리게(Blur) 처리하거나 또는 일부 픽셀을 빛망울로 처리하는 것을 지칭할 수 있으나, 이에 한정되지는 않는다.원본 이미지는 픽셀들로 구성되고 픽셀의 각각이 정보를 가지는 이미지 파일(file)을 포함할 수 있다. 일 실시예에 따르면, 이미지는 단일 RGB 이미지일 수 있다. 여기서 \"RGB 이미지\"는, 각 픽셀마다 빨강(R), 초록(G), 파랑(B)의 수치, 예를 들면, 0-255 사이의 수치로 구성되는 이미지이다. \"단일\" RGB 이미지란 렌즈가 두 개 이상인 이미지 센서로부터 획득된 RGB 이미지와 구별되는 것으로서, 하나의 이미지 센서로부터 촬상된 이 미지를 지칭할 수 있다. 본 실시예에서, 이미지는 RGB 이미지로 설명하였으나, 이에 한정되지 않으며, 알려진 다양한 포맷의 이미지를 나타낼 수 있다. 일 실시예에서, 이미지에 보케 효과를 적용함에 있어서 심도 맵(Depth Map)이 이용될 수 있다. 예를 들어, 이 미지 내의 심도가 낮은 부분은 그대로 두거나 하이라이트 효과를 적용하고, 심도가 높은 부분은 흐릿하게 처리 함으로써 보케 효과를 적용할 수 있다. 여기서, 특정 픽셀 또는 영역의 심도를 기준 심도로 설정하고, 다른 픽 셀들 또는 영역 사이의 상대적인 심도를 결정함으로써, 이미지 내의 픽셀들 또는 영역들 사이의 심도의 높낮이 가 결정될 수 있다. 일 실시예에 따르면, 심도 맵은 일종의 이미지 파일일 수 있다. 심도는 이미지 내의 깊이를 나타낼 수 있는데, 예를 들면, 이미지 센서의 렌즈로부터 각 픽셀이 나타내는 대상까지의 거리를 나타낼 수 있다. 심도 맵을 획득 하는데 있어서 가장 일반적인 것은 심도 카메라를 이용하는 것이지만, 심도 카메라 자체가 고가이고, 휴대용 단 말기에 적용된 사례가 적으므로, 종래에는 휴대용 단말기상에서 심도 맵을 이용하여 보케 효과를 적용하는 데에 한계가 있었다. 일 실시예에 따르면, 심도 맵을 생성하는 방법에 있어서, 이미지를 학습된 인공신경망 모델에 입력 변수로 입력하여 심도 맵을 생성할 수 있다. 일 실시예에 따르면, 이미지로부터 인공신경망 모델을 이용 하여 심도 맵을 생성하고, 이를 기초로 보케 효과 적용된 이미지를 생성할 수 있다. 이미지로부터 이 미지 내의 대상들의 심도, 즉 깊이는 학습된 인공신경망 모델를 통해 획득될 수 있다. 심도 맵을 이용하여 보 케 효과를 적용함에 있어서 일정한 규칙에 따라 적용될 수 있고, 사용자로부터 수신된 정보에 따라 적용될 수도 있다. 도 1에서는 심도 맵을 회색조 이미지로 나타내었으나, 이는 각 픽셀들의 심도들의 차이를 보여주기 위한 예시로서, 심도 맵은 이미지 내의 픽셀들의 심도를 나타내거나 특징화하는 수치들 또는 숫자들의 집합으로 나타낼 수 있다. 보케 효과를 적용함에 있어서 학습된 인공신경망 모델을 이용하여 생성한 심도 맵의 심도 정보를 기초로 함으로 써, 고가의 장비를 필요로 하는 심도 카메라나 적외선 센서가 없이도, 보급형 장비, 예를 들면 스마트폰 카메라 로부터 촬영된 이미지에 극적인 보케 효과를 적용할 수 있다. 또한, 촬영 당시에 보케 효과가 부여되지 않아도, 저장된 이미지 파일, 예를 들면 RGB 이미지 파일에도 사후적으로 보케 효과를 적용할 수 있다. 도 2는 본 개시의 일 실시예에 따른 사용자 단말의 구성을 나타낸 블록도이다. 일 실시예에 따르면, 사용 자 단말은 심도 맵 생성 모듈, 보케 효과 적용 모듈, 세그멘테이션 마스크 생성 모듈, 탐 지 영역 생성 모듈 및 I/O 장치를 포함하도록 구성될 수 있다. 또한, 사용자 단말은 보케 효과 적용 시스템과 통신 가능하도록 구성되며, 보케 효과 적용 시스템의 기계 학습 모듈을 통해 미 리 학습된 이하에서 설명될 제1 인공신경망 모델, 제2 인공신경망 모델, 제3 인공신경망 모델 등을 포함한 학습 된 인공신경망 모델을 제공받을 수 있다. 도 2에서는 기계 학습 모듈이 보케 효과 적용 시스템에 포 함되는 것으로 도시되어 있으나, 이에 한정되지 않으며, 기계 학습 모듈은 사용자 단말에 포함될 수 있다. 심도 맵 생성 모듈은 이미지 센서로부터 촬상된 이미지를 수신하고, 이를 기초로 심도 맵을 생성하도록 구 성될 수 있다. 일 실시예에 따르면, 이러한 이미지는 이미지 센서로부터 촬상된 이후 바로 심도 맵 생성 모듈 에 제공될 수 있다. 다른 실시예에 따르면, 이미지 센서로부터 촬상된 이미지는 사용자 단말에 포함 되거나 접근 가능한 저장 매체에 저장될 수 있으며, 사용자 단말은 이러한 저장 매체에 접근함으로써, 심 도 맵 생성 시 저장된 이미지를 수신할 수 있다. 일 실시예에 따르면, 심도 맵 생성 모듈은 수신된 이미지를 학습된 제1 인공신경망 모델에 입력 변수로 입 력하여 심도 맵(depth map)을 생성하도록 구성될 수 있다. 이러한 제1 인공신경망 모델은 기계 학습 모듈(25 0)을 통해 학습될 수 있다. 예를 들어, 복수의 참조 이미지를 입력변수로 수신하여 각 픽셀별 또는 복수의 픽 셀들을 포함하는 픽셀군 별로 심도를 추론하도록 학습될 수 있다. 이 과정에서, 별도의 장치(예를 들어, depth camera)를 통해 측정된 참조 이미지에 대응되는 심도 맵 정보를 포함한 참조 이미지를 이용하여 학습시킴으로써 제1 인공신경망 모델을 통해 출력된 심도 맵의 오차가 감소되도록 학습될 수 있다. 심도 맵 생성 모듈은 학습된 제1 인공신경망 모델을 통해 이미지로부터 이미지 내에 포함된 심도 정 보를 획득할 수 있다. 일 실시예에 따르면, 심도 정보는 이미지 내의 모든 픽셀마다 부여될 수도 있고, 인접한 수개의 픽셀마다 부여되거나, 인접한 수 개의 픽셀에 동일한 값이 부여될 수 있다. 심도 맵 생성 모듈은 이미지에 대응하는 심도 맵을 실시간으로 생성하도록 구성될 수 있다. 심도 맵 생성 모듈은 세그멘테이션 마스크 생성 모듈에서 생성된 세그멘테이션 마스크를 이용하여 실시간으로 심도 맵을 보정할 수 있다. 심도 맵을 실시간으로 구현하지 않더라도, 심도 맵 생성 모듈은 보케 블러를 다른 강도(예를 들어, kernel size)로 적용한 복수의 블러 이미지를 생성할 수 있다. 예를 들어, 심도 맵 생성 모듈 은 미리 생성된 심도 맵을 재정규화(renormalize)하고 재정규화된 심도 맵의 값에 따라 다른 강도로 블러 한 미리 생성된 블러 이미지들을 보간(interpolate)하여 실시간으로 보케 강도가 달라지는 효과가 구현될 수 있 다. 예를 들어, 터치 스크린 등의 입력 장치를 통해 프로그레스 바를 움직이거나 양손가락으로 줌을 해서 심도 맵의 초점을 연속으로 바꾸는 사용자 입력에 응답하여, 이러한 실시간으로 심도 맵을 보정하거나 보케 강도를 달라지는 효과가 이미지에 적용될 수 있다. 심도 맵 생성 모듈은 RGB 카메라에 의해 촬상된 RGB 이미지와 깊이 카메라로부터 촬상된 심도 이미지를 수 신하고, 주어진 카메라 변수 등을 이용하여 심도 이미지를 RGB 이미지에 매칭시켜서 RGB 이미지에 정렬된 심도 이미지를 생성할 수 있다. 그리고 나서, 심도 맵 생성 모듈은 생성된 심도 이미지에서 신뢰도가 미리 설 정된 값보다 낮은 지점과 홀(hole)이 발생된 지점들의 영역을 도출할 수 있다. 또한, 심도 맵 생성 모듈 은 RGB 이미지로부터 예측된 심도 맵(estimated depth map)을 도출하도록 학습된 인공신경망 모델(예를 들어, 제1 인공신경망 모델)을 이용하여 RGB 이미지로부터 심도 추정 이미지를 도출할 수 있다. 심도 추정 이미지를 이용하여 이미지 내의 신뢰도가 미리 설정된 값보다 낮은 지점과 홀이 발생된 지점들에 대한 심도 정보가 추정 될 수 있고, 심도 이미지에 추정된 심도 정보가 입력되어 완성된 심도 이미지가 도출될 수 있다. 예를 들어, 이미지 내의 신뢰도가 미리 설정된 값보다 낮은 지점과 홀이 발생된 지점들에 대한 심도 정보는 bilinear interpolation, 히스토그램 매칭, 미리 학습된 인공신경망 모델을 사용하여 추정될 수 있다. 또한, 이러한 심 도 정보는 이러한 방법을 이용하여 얻어낸 값들의 중간값(median) 또는 미리 설정된 비율을 적용한 가중 산술 편균으로 도출된 값이 이용되어 추정될 수 있다. 추정된 깊이 이미지는 필요한 높이, 너비보다 작을 경우, 미 리 학습된 인공신경망 모델을 이용하여 필요한 크기로 업스케일링(upscaling)될 수 있다. 보케 효과 적용 모듈은 심도 맵이 나타내는 이미지 내의 픽셀들에 대한 심도 정보를 기초로 이미지 내의 픽셀들에 보케 효과를 적용하도록 구성될 수 있다. 일 실시예에 따르면, 심도를 변수로 하여 적용할 보케 효과 의 강도를 미리 결정된 함수로 지정할 수 있다. 여기서, 미리 결정된 함수란 심도 값을 변수로 하여 보케 효과 의 정도와 모양을 달리하는 것일 수 있다. 다른 실시예에 따르면, 심도의 구간을 나누어 보케 효과를 불연속적 으로 제공할 수도 있다. 또 다른 실시예에서, 추출한 심도 맵의 심도 정보에 따라 아래와 같은 효과, 또는 아 래 효과들의 하나 이상의 조합을 적용할 수 있다. 1. 심도 값에 따라 다른 강도의 보케 효과를 적용한다. 2. 심도 값에 따라 다른 필터효과를 적용한다. 3. 심도 값에 따라 다른 배경으로 치환한다. 예를 들어, 심도 정보를, 가장 가까운 대상을 0으로, 가장 먼 대상을 100으로 할 수 있고, 나아가 0~20 구간은 포토필터 효과를 적용하고 20~40 구간은 아웃포커싱 효과를 적용하며, 40 이상의 구간은 배경을 치환하도록 구 성될 수 있다. 또한, 하나 이상의 세그멘테이션 마스크 중 선택된 마스크를 기준으로 거리가 멀수록 강한 아웃 포커싱 효과(예를 들어, 그라데이션 효과)가 적용될 수 있다. 또 다른 실시예에 따르면, 사용자로부터 입력된 보케 효과 적용에 대한 설정 정보에 따라 다양한 보케 효과가 적용될 수 있다. 보케 효과 적용 모듈은 심도 맵 내의 심도 정보를 이용하여 이미 선정된 필터를 입력 이미지에 적용하여 보케 효과를 생성할 수 있다. 일 실시예에 따르면, 수행 속도의 향상과 메모리의 절약을 위해 입력 이미지가 기 선정된 크기(높이x너비)에 맞춰 축소된 이후 이미 선정된 필터가 축소된 입력 이미지에 적용될 수 있다. 예 를 들어, 필터가 적용된 이미지들과 심도 맵에 대해, 입력 이미지의 매 픽셀에 해당하는 심보 값을 bilinear interpolation을 이용하여 계산하고, 계산된 수치의 영역에 해당하는 필터가 적용된 영상들 또는 입력 영상으로 부터 픽셀 값을 마찬가지로 bilinear interpolation을 이용하여 산출해낼 수 있다. 이미지 내의 객체 영영들에 대해 특정 영역에 보케 효과가 적용되는 경우, 특정 영역의 객체 세그멘테이션 마스크 영역에 대해 산출된 심도 맵 내의 심도 추정 값이 주어진 수치 범위 내에 들도록 해당 영역의 심도 값을 변경한 이후에 이미지가 축소되 고 bilinear interpolation을 이용해 픽셀값이 산출될 수 있다.세그멘테이션 마스크 생성 모듈은 이미지 내의 객체에 대한 세그멘테이션 마스크, 즉 분할된 이미지 영역 을 생성할 수 있다. 일 실시예에서, 세그멘테이션 마스크는 이미지 내의 객체에 해당하는 픽셀들을 분할함으로 써 생성될 수 있다. 예를 들어, 이미지 분할(segmentation) 은 수신된 이미지를 여러 개의 픽셀 집합으로 나누 는 과정을 지칭할 수 있다. 이미지의 분할은 영상의 표현을 좀 더 의미있고 해석하기 쉬운 것으로 단순화하거 나 변환하는 것이고, 예를 들어, 영상에서 객체에 대응되는 물체, 경계(선, 곡선)를 찾는데 사용된다. 이미지 내에서 하나 이상의 세그멘테이션 마스크가 생성될 수 있다. 일 예로서, 의미 경계 추출(semantic segmentation)은 컴퓨터 비전 기술을 이용하여 특정한 사물, 사람 등의 경계를 추출하는 기술로서, 예를 들면 사람 영역의 마스크를 얻는 것을 말한다. 다른 예로서, 개별 경계 추출(instance segmentation)은 컴퓨터 비전 기술을 이용하여 특정한 사물, 사람 등의 경계를 개체 별로 각각 추출하는 기술로서, 예를 들면 사람 영역의 마 스크를 사람 별로 각각 얻는 것을 말한다. 일 실시예에서, 세그멘테이션 마스크 생성 모듈은 세그멘테이 션 기술 분야에서 미리 알려진 임의의 기법을 사용할 수 있는데, 예를 들어, thresholding methods, argmax methods, histogram-based methods region growing methods, split-and-merge methods, Graph partitioning methods 등의 매핑 알고리즘 및/또는 학습된 인공신경망 모델을 이용하여 이미지 내의 하나 이상의 객체에 대한 세그멘테이션 마스크를 생성할 수 있으나, 이에 한정되지는 않는다. 여기서 학습된 인공신경망 모델은 제2 인 공신경망 모델일 수 있으며, 기계 학습 모듈에 의해 학습될 수 있다. 제2 인공신경망 모델의 학습 과정은 도 3을 참조하여 상세히 설명된다. 심도 맵 생성 모듈은, 생성된 세그멘테이션 마스크를 이용하여 심도 맵을 보정하도록 더 구성될 수 있다. 사용자 단말이 보케 효과를 제공하는 과정에서 세그멘테이션 마스크를 생성하고 이를 이용하면 부정확한 심도 맵을 보정하거나, 보케 효과를 부여할 기준 심도를 설정할 수 있다. 또한, 세그멘테이션 마스크를 학습된 인공신경망 모델에 입력하여 정밀한 심도 맵을 생성하고, 특화된 보케 효과를 적용할 수 있다. 여기서 학습된 인공신경망 모델은 제3 인공신경망 모델일 수 있으며, 기계 학습 모듈에 의해 학습될 수 있다. 제3 인공 신경망 모델의 학습 과정은 도 3을 참조하여 상세히 설명된다. 탐지 영역 생성 모듈은 이미지 내의 객체를 탐지하여 탐지된 객체에 대한 특정 영역으로 생성하도록 구성 될 수 있다. 일 실시예에서, 탐지 영역 생성 모듈은 이미지 내의 객체를 식별하여 영역을 개략적으로 생 성할 수 있다. 예를 들면, 이미지 내의 사람을 탐지하여 해당 영역을 직사각형 모양으로 분리할 수 있다. 생성되는 탐지 영역은 이미지 영역 내의 객체의 수에 따라 하나 이상일 수 있다. 이미지로부터 객체를 탐지하 는 방법으로는, RapidCheck, HOG(Histogram of Oriented Gradient), Cascade HoG, ChnFtrs, part-based 모델 및/또는 학습된 인공신경망 모델 등이 있을 수 있으나, 이에 한정되지는 않는다. 탐지 영역 생성 모듈을 통해 탐지 영역이 생성되고, 탐지 영역 내에서 세그멘테이션 마스크이 생성되는 경우, 경계를 추출할 대상이 한 정되고 명확해지므로, 경계를 추출하는 컴퓨팅 장치의 부하가 줄어들 수 있고, 마스크 생성 시간이 단축되며 더 욱 세밀한 세그멘테이션 마스크가 획득될 수 있다. 예를 들면, 이미지 전체로부터 사람의 영역에 대한 마스크 를 추출하도록 명령하는 것보다 사람의 영역을 한정해주고 사람의 영역에 대한 마스크를 추출하는 것이 더욱 효 과적일 수 있다. 일 실시예에 따르면, 탐지 영역 생성 모듈은 입력 이미지에 대해 미리 학습된 객체 탐지 인공신경망을 이 용하여 입력 이미지 내의 객체를 탐지하도록 구성될 수 있다. 탐지된 객체 영역에 대해 미리 학습된 객체 분할 인공신경망이 이용되어 탐지된 객체 영역 내에서 객체가 분할될 수 있다. 탐지 영역 생성 모듈은 분할된 객체 분할 마스크를 포함하는 가장 작은 영역을 탐지 영역으로써 도출해낼 수 있다. 예를 들어, 분할된 객체 분할 마스크를 포함하는 가장 작은 영역은 직사각형 형태의 영역으로 도출될 수 있다. 이렇게 도출된 영역은 입력 이미지 내에 출력될 수 있다. I/O 장치는 장치 사용자로부터 적용될 보케 효과에 관한 설정 정보를 수신하거나 원본이미지 및/또는 영상 처리된 이미지를 출력하거나 표시하도록 구성될 수 있다. 예를 들어, I/O 장치는 터치스크린, 마우스, 키 보드, 디스플레이 등일 수 있으나 이에 한정되지는 않는다. 일 실시예에 따르면, 복수의 세그멘테이션 마스크 로부터 하이라이트를 적용할 마스크를 선택하는 정보를 수신할 수 있다. 다른 실시예에 따르면, 입력 장치인 터치스크린을 통하여 터치 제스처(touch gesture)를 수신하고, 그 정보에 따라 점차적이고 다양한 보케 효과가 부여되도록 구성될 수 있다. 여기서 터치 제스처란, 입력 장치인 터치스크린 상의 사용자의 손가락의 임의의 터치 동작을 지칭할 수 있으며, 예를 들어, 터치 제스처는 길게 터치, 화면 밀기 및 복수의 손가락을 터치하여 벌리거나 줄이는 동작 등을 지칭할 수 있다. 수신된 보케 효과 적용에 대한 정보에 따라 어떠한 보케 효과가 부여될지는 사용자로부터 설정될 수 있도록 구성될 수 있으며, 모듈 내, 예를 들면 보케 효과 적용 모듈 내에 저장되도록 구성될 수 있다. 일 실시예에서, I/O 장치는 원본 이미지를 출력하거나 보케 효과 등의영상 처리가 수행된 이미지를 표시하는 임의의 디스플레이 장치를 포함할 수 있다. 예를 들어, 임의의 디스플 레이 장치는 터치 입력도 가능한 터치-패널 디스플레이를 포함할 수 있다. 도 2에서는 I/O 장치가 사용자 단말 내에 포함되는 것으로 도시되어 있으나, 이에 한정되지 않고, 사용자 단말은 별도의 입력 장치를 통해 적용될 보케 효과에 대한 설정 정보를 수신하거나 보케 효과가 적 용된 이미지를 별도의 출력 장치를 통해 출력할 수 있다. 사용자 단말은 이미지 내의 객체의 왜곡을 보정하도록 구성될 수 있다. 일 실시예에 따르면, 사람의 얼굴 이 포함된 이미지가 촬상된 경우, 곡률을 가진 렌즈 알의 포물면에 기인하여 발생될 수 있는 베럴 왜곡(barrel distortion) 현상이 보정될 수 있다. 예를 들어, 렌즈 왜곡에 기인하여 사람이 렌즈 가까이에서 촬상되었을 때 코가 다른 부위보다 상대적으로 커보이게 되고, 렌즈의 중앙부가 볼록 렌즈처럼 왜곡되어 사람 얼굴이 실제와 상이하게 촬상되는 것을 보정하기 위하여, 사용자 단말은 이미지 내의 객체(예를 들어, 사람 얼굴)을 3차 원으로 인식하여 실제와 동일하거나 유사한 객체가 포함되도록 이미지를 보정할 수 있다. 이 경우, 원래 안보 이던 사람의 얼굴 중 귀 영역은 deep learning GAN 등과 같은 generative model을 사용하여 생성될 수 있다. 이와 달리, deep learning 기법뿐만 아니라 보이지 않는 부분을 자연스럽게 객체에 붙일 수 있는 임의의 기법이 채택될 수 있다. 사용자 단말은 이미지 내의 임의의 객체에 포함된 머리카락 또는 헤어의 색을 블렌딩하도록 구성될 수 있 다. 세그멘테이션 마스크 생성 모듈은 사람, 동물 등이 포함된 입력 이미지에서 머리카락 영역을 도출하 도록 학습된 인공 신경망을 이용하여 입력 이미지에서 머리카락 영역에 대응하는 세그멘테이션 마스크를 생성할 수 있다. 또한, 보케 효과 적용 모듈은 세그멘테이션 마스크에 대응한 영역의 컬러 스페이스를 흑백으로 변경하고 변경된 흑백 영역의 밝기에 대한 히스토그램을 생성할 수 있다. 또한, 다양한 밝기가 있는 변경하고 자 하는 샘플 헤어 컬러가 미리 준비되어 저장될 수 있다. 보케 효과 적용 모듈은 이러한 샘플 헤어 컬러 에 대한 컬러 스페이스를 흑백으로 변경하고 변경된 흑백 영역의 밝기에 대한 히스토그램을 생성할 수 있다. 이 경우, 밝기가 동일한 부분에 대해 유사한 색상이 선택되거나 적용될 수 있도록 히스토그램 매칭이 실시될 수 있다. 보케 효과 적용 모듈은 매칭된 색상을 세그멘테이션 마스크에 대응하는 영역에 대입할 수 있다. 도 3는 본 개시의 일 실시예에 따른 기계 학습 모듈에 의해 인공신경망 모델이 학습되는 방법을 나타 내는 개략도이다. 인공신경망 모델은, 머신러닝(Machine Learning) 기술과 인지과학에서, 생물학적 신경 망의 구조에 기초하여 구현된 통계학적 학습 알고리즘 또는 그 알고리즘을 실행하는 구조이다. 일 실시예에 따 르면, 인공신경망 모델은, 생물학적 신경망에서와 같이 시냅스의 결합으로 네트워크를 형성한 인공 뉴런인 노드(Node)들이 시냅스의 가중치를 반복적으로 조정하여, 특정 입력에 대응한 올바른 출력과 추론된 출력 사이 의 오차가 감소되도록 학습함으로써, 문제 해결 능력을 가지는 머신러닝 모델을 나타낼 수 있다. 예를 들어, 인공신경망 모델은 머신 러닝, 딥러닝 등의 인공지능 학습법에 사용되는 임의의 확률 모델, 뉴럴 네트워크 모델 등을 포함할 수 있다. 또한, 인공신경망 모델은 제1 인공신경망 모델, 제2 인공신경망 모델 및/또는 제3 인공신경망 모델을 포함 한 본 명세서에 기재된 임의의 인공신경망 모델 또는 인공신경망을 지칭할 수 있다. 인공신경망 모델은 다층의 노드들과 이들 사이의 연결로 구성된 다층 퍼셉트론(MLP: multilayer perceptron)으로 구현된다. 본 실시예에 따른 인공신경망 모델은 MLP를 포함하는 다양한 인공신경망 모델 구조들 중의 하나를 이용하여 구현될 수 있다. 도 3에 도시된 바와 같이, 인공신경망 모델은, 외부로부터 입력 신호 또는 데이터를 수신하는 입력층, 입력 데이터에 대응한 출력 신호 또는 데이터를 출 력하는 출력층, 입력층과 출력층 사이에 위치하며 입력층으로부터 신호를 받아 특성을 추 출하여 출력층으로 전달하는 n개(여기서, n은 양의 정수)의 은닉층(330_1 내지 330_n)으로 구성된다. 여 기서, 출력층은 은닉층(330_1 내지 330_n)으로부터 신호를 받아 외부로 출력한다. 인공신경망 모델의 학습 방법에는, 교사 신호(정답)의 입력에 의해서 문제의 해결에 최적화되도록 학습하 는 지도 학습(Supervised Learning) 방법과, 교사 신호를 필요로 하지 않는 비지도 학습(Unsupervised Learning) 방법이 있다. 기계 학습 모듈은 수신된 이미지 내의 피사체, 배경 등의 객체들의 심도 정보를 제공하기 위하여 지도 학습(Supervised Learning)을 이용하여, 입력 이미지에 대한 분석을 수행하고, 이미지에 대응되는 심도 정보를 추출될 수 있도록 인공신경망 모델, 즉 제1 인공신경망 모델을 학습시킬 수 있다. 이렇게 학습된 인공신경망 모델은, 수신된 이미지에 응답하여 심도 정보가 담긴 심도 맵을 생성하여 심도 맵 생성 모듈에 제공될 수 있으며, 보케 효과 적용 모듈이 수신된 이미지에 보케 효과를 적용할 기초 를 제공할 수 있다.일 실시예에 따르면, 도 3에 도시된 바와 같이, 심도 정보를 추출할 수 있는 인공신경망 모델, 즉 제1 인 공신경망 모델의 입력변수는, 이미지가 될 수 있다. 예를 들어, 인공신경망 모델의 입력층에 입력되 는 입력변수는, 이미지를 하나의 벡터 데이터요소로 구성한, 이미지 벡터가 될 수 있다. 한편, 인공신경망 모델, 즉 제1 인공신경망 모델의 출력층에서 출력되는 출력변수는, 심도 맵을 나타 내는 벡터가 될 수 있다. 일 실시예에 따르면, 출력변수는 심도 맵 벡터로 구성될 수 있다. 예를 들어, 심도 맵 벡터는 이미지의 픽셀들의 심도 정보를 데이터 요소로 포함할 수 있다. 본 개시에 있어서 인공신 경망 모델의 출력변수는, 이상에서 설명된 유형에 한정되지 않으며, 심도 맵과 관련된 다양한 형태로 나타 낼 수 있다. 이와 같이 인공신경망 모델의 입력층과 출력층에 복수의 입력변수와 대응되는 복수의 출력변수 를 각각 매칭시켜, 입력층, 은닉층(330_1 내지 330_n) 및 출력층에 포함된 노드들 사이의 시냅스 값 을 조정함으로써, 특정 입력에 대응한 올바른 출력을 추출할 수 있도록 학습할 수 있다. 이러한 학습 과정을 통해, 인공신경망 모델의 입력변수에 숨겨져 있는 특성을 파악할 수 있고, 입력변수에 기초하여 계산된 출 력변수와 목표 출력 간의 오차가 줄어들도록 인공신경망 모델의 노드들 사이의 시냅스 값(또는 가중치)를 조정할 수 있다. 이렇게 학습된 인공신경망 모델, 즉 제1 인공신경망 모델을 이용하여, 입력된 이미지에 응답하여, 수신된 이미지 내의 심도 맵을 생성할 수 있다. 다른 실시예에 따르면, 기계 학습 모듈은 복수의 참조 이미지를 인공신경망 모델, 즉 제2 인공신경망 모델의 입력층의 입력 변수로 수신하고, 제2 인공신경망 모델의 출력층에서 출력되는 출력층에서 출 력되는 출력변수는, 복수의 이미지 내의 포함된 객체에 대한 세그멘테이션 마스크를 나타내는 벡터가 될 수 있 도록 학습될 수 있다. 이렇게 학습된 제2 인공신경망 모델은 세그멘테이션 마스크 생성 모듈에 제공될 수 있다. 또 다른 실시예에 따르면, 기계 학습 모듈은 복수의 참조 이미지의 일부, 예를 들면 복수의 참조 세그멘테 이션 마스크를 인공신경망 모델, 즉 제3 인공신경망 모델의 입력층의 입력변수로 수신할 수 있다. 예를 들어, 제3 인공신경망 모델의 입력변수는, 복수의 참조 세그멘테이션 마스크의 각각을 하나의 벡터 데이터 요소로 구성한, 세그멘테이션 마스크 벡터가 될 수 있다. 또한, 기계 학습 모듈은 제3 인공신경망 모델의 출력층에서 출력되는 출력변수는, 세그멘테이션 마스크의 정밀한 심도 정보를 나타내는 벡터가 될 수 있도 록 제3 인공신경망 모델을 학습시킬 수 있다. 학습된 제3 인공신경망 모델은 보케 효과 적용 모듈에 제공 되어, 이미지 내의 특정 객체에 대한 더욱 정밀한 보케 효과를 적용하는 데에 사용될 수 있다. 일 실시예에서, 기존의 인공신경망 모델에서 사용되는 [0, 1] 범위는 255로 나누어져 산출될 수 있었다. 이와 달리, 본 개시의 인공신경망 모델은 256으로 나누어져 산출된 [0, 255/256] 범위를 포함할 수 있다. 인공신경 만 모델의 학습 시에도 이를 적용하여 학습될 수 있다. 이를 일반화하여 입력을 정규화할 때 2의 제곱승으로 나누는 방식이 이용될 수 있다. 이러한 기법에 따르면, 인공신경망 학습 시 2의 제곱승을 이용하기 때문에, 곱 셈/나눗셈 시 컴퓨터 아키텍쳐의 연산량이 최솨화되고 그러한 연산이 가속화될 수 있다. 도 4는 본 개시의 일 실시예에 따른 사용자 단말이 이미지로부터 생성된 세그멘테이션 마스크를 기초로 심 도 맵을 보정하고, 보정된 심도 맵을 이용하여 보케 효과를 적용하는 방법을 나타내는 흐름도이다. 보케 효과를 적용하는 방법은 심도 맵 생성 모듈이 원본 이미지를 수신하는 단계(S410)를 포함할 수 있다. 사용자 단말은 이미지 센서로부터 촬상된 이미지를 수신하도록 구성될 수 있다. 일 실시예에 따르 면, 이미지 센서는 사용자 단말에 포함되거나 접근 가능한 장치에 장착될 수 있으며, 촬상된 이미지는 사 용자 단말로 제공되거나 저장 장치에 저장될 수 있다. 촬상된 이미지가 저장 장치에 저장된 경우, 사용자 단말은 저장 장치에 접근하여 이미지를 수신하도록 구성될 수 있다. 이 경우, 저장 장치는 사용자 단말 과 하나의 장치에 포함될 수 있거나 별도의 장치로서 사용자 단말과 유무선으로 연결될 수 있다. 세그멘테이션 마스크 생성 모듈은 이미지 내의 객체에 대한 세그멘테이션 마스크를 생성할 수 있다(S420). 일 실시예에 따르면, 세그멘테이션 마스크 생성 모듈이 딥러닝(deep learning) 기법을 사용하는 경우, 인 공신경망 모델의 결과값으로 class 별 확률값을 가지는 2D map을 획득하고, 이를 thresholding 또는 argmax를 적용하여 세그멘테이션 마스크 맵을 생성함으로써, 세그멘테이션 마스크를 생성할 수 있다. 이러한 딥러닝 기 법을 이용하는 경우, 인공신경망 학습 모델의 입력변수로 다양한 이미지를 제공하여 각 이미지 내에 포함된 객 체의 세그멘테이션 마스크가 생성되도록 인공신경망 모델이 학습될 수 있고, 학습된 인공신경망 모델을 통해 수 신된 이미지 내의 객체의 세그멘테이션 마스크가 추출될 수 있다.세그멘테이션 마스크 생성 모듈은 학습된 인공신경망 모델을 통해 이미지의 분할 사전(prior) 정보를 산출 함으로써 세그멘테이션 마스크를 생성하도록 구성될 수 있다. 일 실시예에 따르면, 입력되는 이미지는 인공신 경망 모델에 입력되기 전에 주어진 인공신경망 모델에서 요구되는 데이터 특징에 만족되도록 전처리될 수 있다. 여기서 데이터 특징은, 이미지 내의 특정 데이터의 최소값, 최대값, 평균값, 분산값, 표준편차값, 히스토그램 등이 될 수 있으며, 필요에 따라 입력 데이터의 채널(예를 들어, RGB 채널 또는 YUV 채널)을 함께 처리하거나 별도 처리될 수 있다. 예를 들어, 분할 사전 정보란 이미지 내의 각 픽셀들이 분할되어야 할 객체, 즉 의미있 는(semantic) 객체(예를 들어, 인물, 사물 등)인지 여부를 수치로 나타내는 정보를 지칭할 수 있다. 예를 들어, 이러한 분할 사전 정보는 양자화를 통해 각 픽셀의 사전 정보에 대응하는 수치를 0~1 사이의 값으로 나타 낼 수 있다. 여기서, 0에 가까운 값일수록 배경일 가능성이 높고, 1에 가까운 값일수록 분할되야 할 객체에 해 당된다고 판정될 수 있다. 이러한 동작 중에, 세그멘테이션 마스크 생성 모듈은 미리 결정된 특정 threshold 값을 이용하여 각 픽셀별 또는 복수의 픽셀들이 포함된 군 별로 최종 분할 사전 정보를 0(배경) 또는 1(객체)로 설정할 수 있다. 이에 더하여, 세그멘테이션 마스크 생성 모듈은 이미지 내의 픽셀들에 대응하 는 분할 사전 정보의 분포 및 수치 등을 고려하여 각 픽셀 또는 복수의 픽셀들을 포함한 각 픽셀군들의 분할 사 전 정보에 대한 신뢰도(confidence level)를 결정하고, 각 픽셀 별 또는 각 픽셀군 별 분할 사전 정보 및 신뢰 도를 최종 분할 사전 정보를 설정할 때 함께 이용할 수 있다. 그리고 나서, 세그멘테이션 마스크 생성 모듈 은 1의 값을 갖는 픽셀들을 구분 마스크, 즉 세그멘테이션 마스크를 생성할 수 있다. 예를 들어, 이미지 내의 복수의 의미있는 객체가 있는 경우, 세그멘테이션 마스크 1은 1번 객체, ..., 세그멘테이션 마스크 n은 n 번 객체를 나타낼 수 있다(여기서, n은 2이상인 양수). 이러한 과정을 통하여 이미지 내의 의미있는 객체들에 대응하는 세그멘테이션 마스크 영역은 1, 이러한 마스크의 외부 영역은 0의 값을 가지는 맵을 생성할 수 있다. 예를 들어, 이러한 동작 중에 세그멘테이션 마스크 생성 모듈은 수신된 이미지와 생성된 세그멘테이션 마 스크 맵의 곱을 연산하여 객체별 이미지 혹은 배경 이미지를 구분하여 생성할 수 있다. 다른 실시예에 의하면, 이미지 내의 객체에 대응하는 세그멘테이션 마스크 생성하기 전에, 이미지 내에 포함된 객체를 탐지한 탐지 영역을 생성하도록 구성될 수 있다. 탐지 영역 생성 모듈은 이미지 내의 객체를 식별하여 해당 객체의 영역을 개략적으로 생성할 수 있다. 그리고 나서, 세그멘테이션 마스크 생성 모듈 은 생성된 탐지 영역 내에서 객체에 대한 세그멘테이션 마스크를 생성하도록 구성될 수 있다. 예를 들면, 이미 지 내에 사람을 탐지하여 해당 영역을 직사각형 모양으로 분리할 수 있다. 그리고 나서, 세그멘테이션 마스크 생성 모듈은 탐지 영역 안에서 사람에 대응하는 영역을 추출할 수 있다. 이미지 내에 포함된 객체를 탐지 함으로써 객체에 대응하는 대상 및 영역이 한정되기 때문에, 객체에 대응하는 세그멘테이션 마스크를 생성하는 속도를 증가시키거나, 정확도를 높이거나 및/또는 작업을 수행하는 컴퓨팅 장치의 부하를 낮출 수 있다. 심도 맵 생성 모듈은 이미 학습된 인공신경망 모델을 이용하여 이미지의 심도 맵을 생성할 수 있다(S430). 여기서, 인공신경망 모델은 도 3에 언급된 바와 같이, 복수의 참조 이미지를 입력변수로 수신하여 각 픽셀별 또 는 복수의 픽셀들을 포함하는 픽셀군 별로 심도를 추론하도록 학습될 수 있다. 일 실시예에 따르면, 심도 맵 생성 모듈은 이미지를 입력 변수로 하는 인공신경망 모델에 입력하여, 이미지 내의 각 픽셀 또는 복수의 픽셀을 포함하는 픽셀군에 대한 심도 정보를 가지는 심도 맵을 생성할 수 있다. 심도 맵의 해상도 (resolution)는 이미지와 같을 수도 있고, 이보다 낮을 수도 있는데, 이미지보다 해상도가 낮을 경우 에는 이미지의 수개의 픽셀의 심도를 하나의 픽셀로 표현, 즉 양자화할 수 있다. 예를 들어, 심도 맵 의 해상도가 이미지의 1/4일 경우 이미지의 네 개의 픽셀 당 하나의 심도가 부여되도록 구성될 수 있다. 일 실시예에 따르면 세그멘테이션 마스크를 생성하는 단계(S420)와 심도 맵을 생성하는 단계(S430)는 독립적으로 실행될 수 있다. 심도 맵 생성 모듈은 세그멘테이션 마스크 생성 모듈로부터 생성된 세그멘테이션 마스크를 수신하고, 세그멘테이션 마스크를 이용하여 생성된 심도 맵을 보정할 수 있다(S440). 일 실시예에 따르면, 심도 맵 생성 모듈은 세그멘테이션 마스크에 대응되는 심도 맵 내의 픽셀들을 하나의 객체로서 판정하고 이에 대응되는 픽셀들의 심도를 보정할 수 있다. 예를 들어, 이미지 내의 하나의 객체로 판정된 부분의 픽셀들이 가진 심도의 편차가 크다면, 그러한 편차를 객체 내 픽셀들의 심도를 줄이도록 보정될 수 있다. 또 다른 예로서, 인물이 비 스듬하게 서있을 경우 같은 인물 내에서도 심도가 달라 인물 내의 일 부분에 보케 효과가 적용될 수 있는데, 인 물에 대한 세그멘테이션 마스크에 해당되는 픽셀들에 대해 보케 효과가 적용되지 않도록 인물 내 픽셀에 대한 심도 정보가 보정될 수 있다. 심도 맵이 보정되면, 원치 않는 부분에 아웃포커스 효과가 적용되는 등의 오류를 줄일 수 있는 효과가 있으며, 더 정확한 대상에 보케 효과가 적용될 수 있다 보케 효과 적용 모듈은 수신된 이미지에 보케 효과가 적용된 이미지를 생성할 수 있다(S450). 여기서, 보 케 효과는 도 2의 보케 효과 적용 모듈에서 설명한 다양한 보케 효과들이 적용될 수 있다. 일 실시예에 따르면, 보케 효과는 이미지 내의 심도를 기초로 그 심도에 해당되는 픽셀 또는 픽셀군에 적용될 수 있는데, 마 스크 외부 영역은 아웃포커스 효과를 강하게 부여하고, 마스크 영역은 외부에 비해 상대적으로 약하게 부여하거 나 보케 효과를 부여하지 않을 수 있다. 도 5는 본 개시의 일 실시예에 따른 사용자 단말이 이미지 내에 포함된 인물에 대한 세그멘테이션 마스크 를 생성하고, 보정된 심도 맵을 기초로 이미지에 보케 효과를 적용하는 과정을 나타내는 개략도이다. 본 실시예에서, 도 5에 도시된 바와 같이, 이미지는 실내 복도의 배경에 서 있는 인물을 촬상한 이미지일 수 있다. 일 실시예에 따르면, 탐지 영역 생성 모듈은 이미지를 수신하고 수신된 이미지로부터 사람(51 2)을 탐지할 수 있다. 예를 들어, 도시된 바와 같이, 탐지 영역 생성 모듈은 사람의 영역을 포함한, 직사각형 형태의 탐지 영역을 생성할 수 있다. 나아가, 탐지 영역 내에서 세그멘테이션 마스크 생성 모듈은 탐지 영역으로부터 사람에 대한 세그멘테이션 마스크를 생성할 수 있다. 본 실시예에서, 세그멘테이션 마스크는 도 5에서 흰색으로 써 가상의 영역으로 도시되었으나, 이에 한정되지 않으며, 이미지 상의 세그멘테이션 마스크에 해당 되는 영역을 나타내는 임의의 표시 또는 수치들의 집합으로써 나타낼 수 있다. 예를 들어, 도 5에 도시된 바와 같이, 세그멘테이션 마스크는 이미지 상에서의 객체 내부의 영역을 포함할 수 있다. 심도 맵 생성 모듈은 수신된 이미지로부터 심도 정보를 나타내는 이미지의 심도 맵을 생성할 수 있다. 일 실시예에 따르면, 심도 맵 생성 모듈은 학습된 인공신경망 모델을 이용하여 심도 맵을 생 성할 수 있다. 예를 들면, 도시된 바와 같이, 심도 정보는 가까운 부분은 검정에 가깝도록, 먼 곳은 흰색에 가 깝도록 표현될 수 있다. 이와 달리, 이러한 심도 정보는 수치로 표현될 수 있으며, 심도 수치의 상한과 하한 (예: 가장 가까운 부분은 0, 가장 먼 부분은 100) 내에서 표현될 수 있다. 이러한 과정에서, 심도 맵 생성 모 듈은 세그멘테이션 마스크를 기초로 심도 맵을 보정할 수 있다. 예를 들어, 도 5의 심도 맵 내의 사람에 대해서는 일정한 심도를 부여하도록 할 수 있다. 여기서 일정한 심도는 마스크 내의 심도의 평균값, 중간값, 최빈값, 최소값 또는 최대값이거나 특정 부위, 예를 들면 코 끝 등의 심도로 나타낼 수 있다. 보케 효과 적용 모듈은 심도 맵 및/또는 보정된 심도 맵(미도시)을 기초로 사람 이외의 영역에 보케 효과를 부여할 수 있다. 도 5에서 도시된 바와 같이, 보케 효과 적용 모듈은 이미지 내의 인물 외의 영역 에 블러 효과를 적용하여 아웃포커스 효과를 부여할 수 있다. 이와 달리, 인물에 해당되는 영역은 아무런 효과 를 부여하지 않거나 강조 효과가 적용될 수 있다. 도 6은 본 개시의 일 실시예에 따른 사용자 단말이 이미지로부터 생성된 심도 맵 및 이미지 에 대응하는 세그멘테이션 마스크를 기초로 보정된 심도 맵을 대비하여 보여주는 비교도이다. 여기 서, 이미지는 복수의 사람이 외부 주차장 근처에서 촬상된 이미지일 수 있다. 일 실시예에 따르면, 도 6에 도시된 바와 같이, 이미지로부터 심도 맵을 생성한 경우, 같은 객체라도 위치나 자세에 따라 상당한 심도의 편차를 보일 수 있다. 예를 들면, 비스듬하게 서있는 사람의 어깨에 대응되 는 심도는 사람 객체에 해당되는 심도의 평균값과 큰 차이를 가질 수 있다. 도 6에 도시된 바와 같이, 이미지 으로부터 생성된 심도 맵은 우측 사람의 어깨에 대응되는 심도가 우측 사람 내의 다른 심도 값보다 상대적으로 커서 옅게 표시되었다. 이러한 심도 맵을 기초로 보케 효과를 적용할 경우 이미지 내의 우측 사람이 인포커스를 원하는 객체로 선택된 경우에도 우측사람의 일부, 예를 들면 오른쪽 어깨 부분이 아웃 포커스 처리될 수 있다. 이러한 문제를 해결하기 위해, 이미지 내의 대상에 대응하는 세그멘테이션 마스크를 이용하여 심도 맵의 심도 정보를 보정할 수 있다. 보정은 예를 들면, 평균값, 중간값, 최빈값, 최소값 또는 최대값이거나 특정 부 위의 심도 값으로 수정하는 것일 수 있다. 이와 같은 과정을 거치면 심도 맵에서 우측 사람의 일부, 도 6 의 경우 우측 사람의 오른쪽 어깨부분이 우측 사람과 별도로 아웃포커스 처리되는 문제를 해결할 수 있다. 보 케 효과는 객체 내부와 외부를 구분하여 각 구분된 영역에 상이한 효과를 적용될 수 있다. 심도 맵 생성 모듈 은 사용자가 보케 효과를 적용하기를 원하는 객체에 대응하는 심도를 생성된 세그멘테이션 마스크를 이용 해 보정함으로써, 사용자의 의도에 더욱 부합하고 사용자 의도에 맞는 보케 효과가 적용될 수 있다. 다른 예로 서, 심도 맵 생성 모듈이 객체의 일부를 정확하게 인식하지 못하는 경우가 발생할 수 있는데, 이 때에, 세 그멘테이션 마스크를 이용하여 개선할 수 있다. 예를 들어, 비스듬히 놓쳐진 컵의 손잡이에 대해 심도 정보를올바르게 파악하지 못할 수 있는데, 심도 맵 생성 모듈이 세그멘테이션 마스크를 이용하여 손잡이가 컵의 일부임을 파악하고, 올바른 심도 정보를 획득하도록 보정할 수 있다. 도 7은 본 개시의 일 실시예에 따른 사용자 단말이 이미지 내의 선택된 객체에 대응되는 기준 심도를 결정하고, 기준 심도와 다른 픽셀들의 심도 차이를 산출하여 이를 기초로 이미지에 보케 효과를 적용한 예 시도이다. 일 실시예에 따르면, 보케 효과 적용 모듈은, 선택된 객체에 대응되는 기준 심도를 결정하고, 기준 심도와 이미지 내의 다른 픽셀들의 심도 사이의 차이를 산출하고, 산출된 차이에 기초하여 이미지에 보케 효과를 적용하도록 더 구성될 수 있다. 여기서 기준 심도는 객체에 대응되는 픽셀값들의 심도의 평균값, 중간 값, 최빈값, 최소값 또는 최대값이거나 특정 부위, 예를 들면 코 끝 등의 심도로 나타낼 수 있다. 예를 들어, 도 7의 경우, 보케 효과 적용 모듈은 세 사람(710, 720, 730)에 대응되는 심도의 각각에 대한 기준 심도를 결정하고, 결정된 기준 심도를 기초로 보케 효과를 적용하도록 구성될 수 있다. 도시된 바와 같이, 이미지 내 에서 가운데에 위치된 사람이 포커스되도록 선택된 경우, 다른 사람들(710, 720)에 대해 아웃포커싱 효과 가 적용될 수 있다. 일 실시예에 따르면, 보케 효과 적용 모듈은 이미지 내의 선택된 객체의 기준 심도와 다른 픽셀들 사이의 상대적 심도 차이에 따라 다른 보케 효과를 적용하도록 구성될 수 있다. 예를 들어, 가운데에 위치된 사람 이 포커스되도록 선택된 경우, 가운데에 위치된 사람을 기준으로 볼 때 가장 가까이에 있는 사람 이 가장 멀리 있는 사람보다 상대적으로 멀리 있기 때문에, 도시된 바와 같이, 보케 효과 적용 모듈 은 이미지 내에서 가장 가까이 있는 사람에 적용하는 아웃포커싱 효과를 가장 멀리 있는 사람 에 적용되는 아웃포커싱 효과보다 강하게 처리할 수 있다. 도 8은 본 개시의 일 실시예에 따른 사용자 단말이 이미지로부터 심도 맵을 생성하고, 이미지 내의 객체를 결정하여 이를 기초로 보케 효과를 적용하는 과정을 나타내는 개략도이다. 일 실시예에 따르면, 심도 맵 생성 모듈은 제1 인공신경망 모델을 통해 이미지 내의 적어도 하나의 객체를 결정하도 록 구성될 수 있다. 보케 효과 적용 모듈은, 결정된 적어도 하나의 객체에 대응되는 기준 심도를 결 정하고, 기준 심도와 이미지 내의 다른 픽셀들의 각각의 심도 사이의 차이를 산출하고, 산출된 차이에 기초하여 이미지에 보케 효과를 적용하도록 더 구성될 수 있다. 일 실시예에서, 심도 정보를 추출할 수 있는 인공신경망 모델의 입력변수는, 이미지가 될 수 있고, 인공신경망 모델의 출력층에서 출력되는 출력변수는, 심도 맵과 결정된 적어도 하나의 객체 를 나타내는 벡터가 될 수 있다. 일 실시예에서, 획득된 객체는 균일한 심도가 부여될 수 있다. 예를 들 어, 균일한 심도는 획득된 객체 내의 픽셀들의 심도의 평균 값 등으로 나타낼 수 있다. 이러한 경우 세그멘테 이션 마스크를 생성하는 별도의 과정 없이도 마스크를 생성하여 이용한 것과 유사한 효과를 얻을 수 있다. 획 득된 객체 내를 균일한 심도로 보정할 경우, 보케 효과를 적용하기에 더욱 적합한 심도 맵을 얻도록 심도 맵이 보정될 수 있다. 본 실시예를 통한 보케 효과 적용 방법은 세그멘테이션 마스크를 생성하는 절차를 생략하여 간소화하면서도 유 사한 보케 효과를 적용할 수 있으므로 전체 매커니즘의 속도를 향상시키고 장치의 부하는 줄이는 효과를 얻을 수 있다. 도 9는 본 개시의 일 실시예에 따른 사용자 단말이 이미지 내에 포함된 객체에 대한 세그멘테이션 마스크 를 생성하고 보케 효과를 적용하는 과정에서 생성된 세그멘테이션 마스크를 별도의 학습된 인공신경망 모델의 입력 변수로 입력하고 세그멘테이션 마스크의 심도 정보를 획득하여 이를 기초로 세그멘테이션 마스크에 대응하 는 이미지에 보케 효과를 적용하는 과정을 나타내는 흐름도이다. 도 9의 흐름도에 포함된 단계(S910, S920, S930, S940)은 도 4의 흐름도에 포함된 단계(S410, S420, S430, S440)과 동일 또는 유사한 동작을 포함할 수 있다. 도 9에서, 도 4의 흐름도에서 설명된 내용과 중복되는 내용은 생략된다. 심도 맵 생성 모듈은 원본 이미지로부터 생성된 세그멘테이션 마스크를 별도의 학습된 인공신경망 모델(예 를 들어, 제3 인공신경망 모델)에 입력 변수로 입력하여 세그멘테이션 마스크에 대한 정밀한 심도 정보를 결정 하도록 더 구성될 수 있다(S950). 일 실시예에 따르면, 심도 맵 생성 모듈은 일반 이미지에 보편적으로 사용될 인공 신경망 외에 특정 대상에 특화된 인공신경망 모델을 이용할 수 있다. 예를 들면, 인물을 포함한 이미지를 입력받아 인물 또는 인물의 얼굴에 관한 심도 맵을 추론하도록 제3 인공 신경망 모델을 학습할 수 있 다. 이 과정에서, 보다 정밀한 심도 맵을 추론하기 위하여 미리 측정된 심도를 갖고 있는 인물을 포함한 복수 의 참조 이미지를 이용하여 제3 인공 신경망 모델이 지도 학습될 수 있다.다른 실시예에 따르면, 심도 맵 생성 모듈은 세그멘테이션 마스크에 대응되는 객체에 대한 정밀한 심도 정 보를 얻기 위하여 아래와 같은 방법을 사용할 수 있다. 예를 들어, TOF(Time of flight), Structured light와 같은 촬영장비(depth camera)를 이용하여 세그멘테이션 마스크에 대응하는 객체에 대한 정밀한 심도 정보가 생 성될 수 있다. 또 다른 예로서, Feature matching과 같은 컴퓨터 비전 기술을 이용하여 세그멘테이션 마스크에 대응되는 객체(예를 들어, 사람) 내부의 심도 정보가 생성될 수 있다. 보케 효과 적용 모듈은, 단계 S930 및 S940에서 생성된 원본 이미지에 대응되는 보정된 심도 맵 및 생성된 세그멘테이션 마스크의 정밀한 심도 정보를 기초하여 원본 이미지 내의 보케 효과를 적용하도록 더 구성될 수 있다(S960). 이러한 세그멘테이션에 대응되는 정밀한 심도 정보를 이용함으로써 특정 객체 내부에 대한 더욱 세밀하고 오류가 적은 보케 효과가 적용될 수 있다. 일 실시예에 따르면, 세그멘테이션 마스크 영역은 세그멘 테이션 마스크의 심도 정보를 이용하여 보케 효과가 부여되고, 세그멘테이션 마스크 외의 영역은 심도 맵을 이 용하여 보케 효과가 부여할 수 있다. 이러한 과정에서, 정밀한 심도 정보가 생성된 특정 세그멘테이션 마스크 영역, 예를 들면, 인물의 얼굴은 매우 세밀한 보케 효과가 적용될 수 있고, 나머지 세그멘테이션 영역 및 마스 크 이외의 영역은 덜 세밀한 보케 효과를 부여하도록 하이브리드적 보케 효과가 적용될 수 있다. 이러한 구성 을 통해, 사용자 단말의 컴퓨팅 부하가 최소화되면서도 높은 퀄리티의 결과물가 획득될 수 있다. 도 9에서는 단계 S950에서 생성된 마스크 심도 정보와 함께 단계 S930 및 S940을 통해 생성된 심도 맵을 이용하여 보케 효 과가 적용되는 것으로 도시되어 있으나, 이에 한정되지 않으며, 단계 S940을 거치지 않고, S930에서 생성된 심 도맵과 S950에서 생성된 마스크 심도 정보를 이용하여 단계 S960에서 보케 효과가 적용될 수 있다. 도 10은 본 개시의 일 실시예에 따른 사용자 단말이 이미지 내에 포함된 복수의 객체에 대한 복수의 세그멘테이션 마스크를 생성하고, 이 중 선택된 마스크를 기초로 보케 효과를 적용하는 과정을 나타내는 개략도 이다. 도 10에 도시된 바와 같이, 이미지는 복수의 객체를 포함할 수 있다. 일 실시예에 따르면, 탐지 영역 생성 모듈은, 수신된 이미지 내에 포함된 복수의 객체의 각각을 탐지한 복수의 탐지 영역 (1020_1, 1020_2)을 생성하도록 더 구성될 수 있다. 일 예로, 도시된 바와 같이, 왼쪽 사람과 오른쪽 사람의 영 역이 각각의 네모로 탐지되었다. 세그멘테이션 마스크 생성 모듈은, 객체에 대한 세그멘테이션 마스크를 생성하도록 구성될 있다. 일 실시예에 따르면, 세그멘테이션 마스크 생성 모듈은, 도 10에 도시된 바와 같이, 복수의 탐지 영역의 각각 내에서 복수의 객체의 각각(왼쪽 사람, 오른쪽 사람)에 대한 복수의 세그멘테이션 마스크(1033_1, 1033_ 2)를 생성하도록 더 구성될 수 있다. 심도 맵 생성 모듈은 생성된 세그멘테이션 마스크를 통해 이미지으로부터 생성된 심도 맵을 보정할 수 있는데, 이 과정에서, 세그멘테이션 마스크 전체를 이용하여 보정하지 않고 선택된 적어도 하나의 마 스크만 이용하여 보정할 수 있다. 예를 들어, 도 10에 도시된 바와 같이, 오른쪽 사람의 마스크(1033_2)가 선 택된 경우 해당 마스크를 이용하여 보정된 심도 맵을 얻을 수도 있다. 이와 달리, 왼쪽 사람의 마스크 (1033_1)와 오른쪽 사람의 마스크(1033_2) 모두를 이용하여 심도 맵이 보정될 수 있다. 일 실시예에서, 보케 효과 적용 모듈이 이미지에 보케 효과를 적용함에 있어서, 선택된 마스크는 강 조 효과를 적용하거나, 나머지 마스크는 아웃포커스 효과를 적용할 수 있다. 어떠한 마스크가 선택되느냐에 따 라 아웃포커스가 부여되는 마스크가 상이해질 수 있다. 이 과정에서, 선택되지 않는 마스크의 영역은 마스크가 아닌 영역과 유사하게 취급될 수 있다. 도 10의 보케 효과가 적용된 이미지는 오른쪽 사람의 마스크 (1033_2)가 선택되어, 선택된 세그멘테이션 마스크를 제외하고는 아웃포커싱 효과가 적용된 이미지를 나 타낼 수 있다. 여기서, 왼쪽 사람의 마스크(1033_1)는 탐지되고, 이에 대응하는 객체가 추출되었지만 아웃포커 싱 효과가 부여되었다. 예를 들어, 왼쪽 사람의 마스크(1033_1)가 선택되는 경우에는 오른쪽 사람의 마스크 영 역에 아웃포커싱 효과가 부여될 수 있다. 도 11은 본 개시의 일 실시예에 따른 사용자 단말에 수신되는 보케 효과 적용에 대한 설정 정보에 따라 보 케 효과가 변경되는 과정을 나타내는 개략도이다. 일 실시예에 따르면, 입력 장치는 터치 스크린을 포함 하고, 보케 효과 적용에 대한 설정 정보는 터치 스크린의 터치 입력에 기초하여 결정될 수 있다. 사용자 단말의 입력 장치는 적용할 보케 효과를 설정하는 정보를 수신하도록 구성될 수 있다. 또한, 보케 효과 적용 모듈은 수신한 정보에 따라 보케 효과를 변경하여 이미지의 적어도 일부에 적용할 수 있다. 일 실시예에 따르면, 보케 효과를 적용하는 패턴, 예를 들면 강도나 빛망울 모양을 변화하거나 또는 필 터를 다양하게 적용할 수 있다. 예를 들어, 도 10에 도시된 바와 같이, 터치 스크린을 왼쪽으로 드래그 하면 이미지에 지정된 1번 필터효과를 적용한 이미지를 생성하고, 오른쪽으로 드래그 하면 이미지에 지정된 2번 필터를 적용한 이미지를 생성하고, 드래그 정도가 클수록 강한 보케 효과를 부여할 수 있다. 또 다른 실시예에 따르면, 좌우로 드래그 하는 경우에는 마스크 외의 영역에 아웃포커스 효과를 다변화 하고, 상하로 드래그 하는 경우에는 마스크 영역에 인포커스 효과를 다변화할 수 있다. 여기서 다변화라고 함 은 필터를 다양하게 하거나, 빛망울 모양을 다양하게 하는 등 시각적 효과를 다양하게 변경하는 것을 포함하며 기재된 실시예에 한정되지 않는다. 드래그 또는 확대/축소 등의 터치 제스처(touch gesture)에 따라 어떠한 보 케 효과가 부여될지는 사용자로부터 설정될 수 있도록 구성될 수 있으며, 보케 효과 적용 모듈 내에 저장 되도록 구성될 수 있다. 일 실시예에 따르면, 사용자 단말은 수신된 이미지 내에 포함된 객체에 대한 세그멘테이션 마스크를 생성 하도록 구성될 수 있다. 이에 더하여, 사용자 단말은 이미지 내의 배경 및 생성된 세그멘테이션 마스크에 포함된 객체(예를 들어 사람)를 표시할 수 있다. 그리고 나서, 터치 스크린 등의 입력 장치를 통해 표시된 이 미지에 대한 터치 입력(예를 들어, 접촉)을 수신하고, 수신된 터치 입력이 미리 설정된 제스처에 상응하는 경우 그래픽 요소를 다른 그래픽 요소로 치환할 수 있다. 일 실시예에 따르면, 좌우 스와이프 하는 경우 이미지 내의 배경 또는 배경 부분의 필터가 변경될 수 있다. 또 한, 상하 스와이프의 경우 이미지 내의 사람 부분의 필터가 치환될 수 있다. 이러한 좌우 스와이프 및 상하 스 와이프에 따른 필터 변경 결과는 서로 바뀔 수 있다. 또한, 이미지 내의 터치 입력이 스와이프 후의 홀드를 나 타내는 경우, 이미지 내의 배경이 자동으로 연속적으로 변경될 수 있다. 또한, 스와이프 모션에 있어서 터치 지점에서 스와이프한 길이가 길어짐에 따라 배경치환(필터치환)의 가속도가 증가될 수 있다. 그리고 나서, 이 미지 내의 터치 입력이 끝났다고 판단되는 경우, 이미지 내의 배경 치환이 멈춰질 수 있다. 예를 들어, 이미지 내의 그래픽 요소가 2가지 이상이 있을 경우, 이미지 내의 터치 입력, 즉 하나의 제스처에 따라 하나의 그래픽 요소만이 바뀌도록 구성될 수 있다. 다른 실시예에 따르면, 사용자 단말은 수신된 터치 입력이 미리 설정된 제스처에 상응하는 경우, 이미지 내에 포커싱된 사람이 변경될 수 있다. 예를 들어, 좌우 스와이프하여 포커싱된 사람이 변경될 수 있다. 다른 예로서, 세그멘트된 사람이 탭되는 경우, 포커싱되는 사람이 변경될 수 있다. 또 다른 예로서, 사용자 단말 은 이미지 내의 임의의 부분에 대해 탭에 해당하는 터치 입력을 수신하는 경우, 이미지 내의 포커싱하는 사람이 순서대로 변경될 수 있다. 또한, 이미지 내의 얼굴 세그멘테이션과 인스턴트 세그멘테이션을 이용해서 이미지 내의 면적이 산출될 수 있다. 또한, 인스턴트 세그멘테이션이 포커싱한 사람을 기준으로 얼마나 떨어져 있는지 산출될 수 있다. 이러한 산출된 값을 기초로, 사람 별로 다른 강도의 아웃 포커싱이 적용될 수 있다. 이에 따라, 사용자 단말은 객체 영역에 대응하는 세그멘테이션 마스크를 생성하기 때문에 이미지 내의 객 체에 해당하는 영역이 어딘지 알고 있으며, 이에 따라, 사용자가 이미지 내에서 객체 영역에 대응하는 부분을 터치함이 없이 이미지 내의 아무 부분을 터치하더라도 객체 영역의 포커싱을 변경하는 것이 가능하다. 또 다른 실시예에 따르면, 사용자 단말은 이미지 내의 하나 이상의 객체에 대해 생성된 세그멘테이션 마스 크를 이용하여 이미지 내의 객체(예를 들어, 사람)의 면적을 산출할 수 있다. 또한, 인스턴스 세그멘테이션 기 술을 이용하여 이미지 내의 사람의 수가 산출될 수 있다. 산출된 사람의 면적 및 사람의 수를 통해 최적의 필 터가 적용될 수 있다. 예를 들어, 최적의 필터는 배경치환이 될 그래픽 요소, 이미지의 분위기를 변경할 수 있 는 색상 필터를 포함할 수 있으나, 이에 한정되지 않는다. 이러한 필터 적용에 따르면, 사용자는 이미지에 스 마트하게 사진 필터 효과를 줄 수 있다. 또 다른 실시예에 따르면, 사용자 단말은 이미지 내의 하나 이상의 객체에 대응하는 세그멘테이션 마스크 를 이용하여 이미지 내의 객체(예를 들어, 사람)의 위치를 표시할 수 있다. 이에 따라, 사용자 단말은 이 미지 내에서 표시된 객체에 대응하는 위치 이외의 부분에 컴퓨터 그래픽 기능이 사용가능한 사용자 인터페이스 (Graphic User Interface; GUI)가 표시될 수 있다. 이미지가 영상인 경우, 영상 내의 프레임들에서 사람의 위 치를 추적하여 GUI가 사람을 가리지 않도록 표시될 수 있다. 예를 들어, 영상 내에서 사람이외의 영역에 자막 이 GUI로서 표시될 수 있다. 또 다른 실시예에 따르면, 사용자 단말은 터치 스크린 등의 입력 장치를 통해 이미지 내의 사용자의 터치 입력을 검출할 수 있으며, 이미지 내에서 접촉된 부분은 포커싱하고 접촉되지 않은 부분은 아웃포커싱될 수 있 다. 사용자 단말은 사용자의 두 손가락의 접촉을 검출하도록 구성될 수 있다. 예를 들어, 사용자 단말 은 이미지 내에서 두 손가락의 줌인 및/또는 줌아웃 모션을 검출하여, 이에 따라 이미지 내의 보케 강도를 조절할 수 있다. 이러한 줌인 및/또는 줌아웃 모션 기능을 지원함에 따라, 사용자 단말은 아웃포커싱 강 도의 조절의 한 방식으로서 줌인 및/또는 줌아웃 모션이 사용될 수 있으며, 이미지 내에서 아웃포커싱될 대상은이미지 내의 하나 이상의 객체에 대응하는 세그멘테이션 마스크에 의해 추출될 수 있다. 일 실시예에서, 사용자 단말은 이미지 내의 하나 이상의 객체에 대응하는 세그멘테이션 마스크를 이용하여 사람 객체에서 머리카락 객체를 분리시키도록 구성될 수 있다. 그리고 나서, 사용자 단말은 염색약 리스 트를 사용자에게 제공할 수 있으며, 그 중 하나 이상의 염색약을 사용자로부터 입력받아서, 분리된 머리카락 영 역에 대해 새로운 색상을 입힐 수 있다. 예를 들어, 사용자는 이미지 내의 사람 부분을 스와이프하여 사람의 머리카락 영역에 새로운 색상이 입히도록 할 수 있다. 또 다른 예로서, 사용자 단말은 이미지 내의 머리 카락 영역의 위쪽에 대해 스와이프 입력을 수신할 수 있으며, 이에 따라 머리카락 영역에 적용될 색상이 선택될 수 있다. 이에 더하여, 이미지 내의 머리카락 영역의 아래쪽에 대해 스와이프 입력이 수신될 수 있으며, 이에 따라 머리카락 영역에 적용될 색상이 선택될 수 있다. 또한, 사용자 단말은 머리카락 영역의 위쪽 및 아 래쪽에 입력된 스와이프 입력에 따라 두가지 색상을 선택하고, 선택한 두가지 색상을 조합하여 머라키락 영역에 그라데이션 염색이 적용될 수 있다. 예를 들어, 이미지 내의 사람 영역에 표시된 현재 모발 색상에 따라 염색 색상이 선택되어 적용될 수 있다. 예를 들어, 이미지 내의 사람 영역에 표시된 머리카락 영역이 탈색모, 건강 모, 염색모 등 다양한 염색 모발일 수 있으며, 이러한 모발 형태 또는 색상에 따라 상이한 염색 색상이 적용될 수 있다. 일 실시예에 따르면, 사용자 단말은 수신된 이미지에서 배경 및 사람 영역에 분리하도록 구성될 수 있다. 예를 들어, 세그멘테이션 마스크를 이용하여 배경 및 사람 영역이 이미지 내에서 분리될 수 있다. 먼저, 이미 지 내의 배경 영역에 아웃포커싱될 수 있다. 그리고 나서, 배경은 다른 이미지로 치환 가능하고, 다양한 필터 효과가 적용될 수 있다. 예를 들어, 이미지 내의 배경 영역에 스와이프 입력이 탐지되면, 해당 배경 영역에 다 른 배경이 적용될 수 있다. 또한, 각 배경 마다 상이한 환경의 조명 효과가 이미지 내의 사람 영역과 머리카락 영역에 적용될 수 있다. 예를 들어, 상이한 조명에서 보면 어떤 색상이 각 영역에서 보여질 수 있는지 알 수 있도록 각 배경마다 상이한 환경의 조명 효과가 적용될 수 있다. 이렇게 색상, 보케 또는 필터 효과가 적용된 이미지는 출력될 수 있다. 이러한 기법을 통해 사용자는 미용실이나, 화장품 샵에서 염색 색상을 선택하고, 세 그멘테이션 기술을 이용해 미리 자신의 머리에 염색을 가상으로 입히는 체험, 즉 증강현실(AR) 체험해 볼 수 있 다. 또한, 이미지 내의 배경과 사람이 분리되어 위에 설명드린 다양한 효과가 적용될 수 있다. 일 실시예에 따르면, 사용자 단말은 사용자가 터치한 이미지 내의 객체를 추적해서 자동으로 포커싱하도록 구성될 수 있다. 이미지는 복수의 그래픽 요소로 분리될 수 있다. 예를 들어, 그래픽 요소로 분리하는 방법은 인공신경망 모델을 이용한 알고리즘, 세그멘테이션 및/또는 탐지 기법이 이용될 수 있으나, 이에 제한되지 않는 다. 그리고 나서, 사용자로부터 그래픽 요소 중 적어도 하나의 선택을 입력받으면, 터치된 그래픽 요소이 추적 되면서 자동으로 포커싱될 수 있다. 이와 동시에, 이미지의 선택되지 않은 그래픽 요소는 아웃 포커싱 효과가 적용될 수 있다. 예를 들어, 아웃 포커싱 효과 이외에 필터 적용과 배경 치환 등 다른 이미지 변환 기능이 적 용될 수 있다. 그리고 나서 다른 그래픽 요소가 터치되면 터치된 그래픽 요소로 이미지 내의 포커싱이 바뀔 수 있다. 일 실시예에서, 사용자 단말은 인물이 포함된 입력 이미지에서 인물 영역을 도출하도록 학습된 인공신경망 을 이용하여, 입력 이미지에서 인물 영역을 파트 별로 세그멘테이션 마스크를 생성할 수 있다. 예를 들어, 인 물 파트는, 이에 한정되지 않으나, 머리카락, 얼굴, 피부, 눈, 코, 입, 귀, 옷, 왼팔, 위, 왼팔 아래, 오른팔 위, 오른팔 아래, 상의, 하의, 신발 등 다양한 파트로 나뉠 수 있으며, 나누는 방법도 인물 분할 분야에서 이미 알려진 임의의 알고리즘 또는 기법이 적용될 수 있다. 그리고 나서, 분할된 파트 별로 색상 변경, 필터 적용, 배경 치환 등 다양한 효과가 적용될 수 있다. 예를 들어, 색상을 자연스럽게 변경하는 방법은, 세그멘테이션 마스크에 대응하는 영역에 대해 컬러 스페이스를 흑백으로 변경하고, 변환된 흑백 영역의 밝기에 대한 히스토그 램을 생성하는 단계, 다양한 밝기가 있는, 변경하고자 하는 샘플 컬러를 준비하는 단계; 변경하고자 하는 샘플 에 대해서도 적용하여 밝기에 대한 히스토그램을 생성하는 단계, 히스토그램 매칭 기법을 이용하여 도출된 히스 토그램들을 매칭하여 각 흑백 영역에 적용될 컬러를 도출해낼 수 있다. 예를 들어, 밝기가 동일한 부분에 대해 유사한 색상이 적용되도록 히스토그램 매칭이 될 수 있다. 매칭된 색상은 세그멘테이션 마스크에 해당되는 영 역에 적용될 수 있다. 일 실시예에서, 사용자 단말은 이미지 내의 특정 사람을 강조하기 위해 주변 사람들의 옷을 변경하도록 구 성될 수 있다. 인물이 포함된 이미지에서 가장 다양하고 복잡한 영역은 옷 부분이기 때문에, 옷을 보정하여 특 정 사람이 더 강조되도록 주변 사람들을 눈에 덜 뛰도록 구현될 수 있다. 이를 위해, 인물 이미지에서 인물 영 역을 도출하도록 학습되어 있는 인공신경망 모델을 이용하여, 입력 이미지에서 인물 영역을 인물 별로 세그멘테 이션하여 도출될 수 있다. 그리고 나서 각각의 인물은 다양한 파트로 세그멘테이션될 수 있다. 또한, 이미지내의 강조될 사람이 사용자로부터 선택될 수 있다. 예를 들어, 한명 또는 여러명이 선택될 수 있다. 이미지 내의 강조될 사람 이외의 사람들의 옷의 채도가 낮춰지거나 화려한 패턴의 옷인 경우 그 패턴이 단순하게 변경 될 수 있다. 일 실시예에서, 사용자 단말은 이미지 내의 얼굴을 가상의 얼굴로 대체하도록 구성될 수 있다. 이러한 기 술을 통해 모자이크가 무분별하게 사용될 경우 이미지를 보는데 불편하거나 신경쓰일 수 있는 것을 방지하고, 자연스럽게 가상의 얼굴을 적용하여 초상권에 문제없으면서도 이미지를 보는데 불편함이 없도록 할 수 있다. 이를 위해, 사용자 단말은 인물 이미지에서 얼굴 영역을 도출하도록 학습되어 있는 인공신경망 모델을 이 용하여, 입력 이미지에서 얼굴 영역에 대응하는 세그멘테이션 마스크를 생성할 수 있다. 또한, deep learning GAN 등과 같은 generative model을 이용하여 새로운 가상의 얼굴이 생성될 수 있다. 이와 달리, Face landmark 기술이 이용되어 새롭게 생성된 얼굴이 기존의 얼굴 부분에 합성될 수 있다. 일 실시예에서, CCTV, 블랙 박스 등의 이미지 내의 특정한 행위를 하는 사람이 감지되는 경우 이러한 사실이 통 보되거나 경고 메시지가 전송될 수 있다. 이를 위해, 인물이 포함된 입력 이미지에서 포즈를 예측할 수 있도록 학습되어 있는 인공신경망 모델을 이용하여 입력 이미지로부터 인물의 포즈로 어떠한 행위를 하는지가 감지될 수 있다. 여기서, 행위는 폭력 행위, 절도 행위, 난동 행위 등을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 특정 행위가 감지된 경우 감지된 정보는 필요로 하는 장소로 전송되어 알림을 줄 수 있다. 이에 더하여, 특정 행위가 감지된 경우 고해상도로 설정되어 이미지가 촬영될 수 있다. 그리고 나서, 감지된 정보를 기초로 음성 또는 영상 등의 다양한 방법이 이용되어 경고 메시지가 전달될 수 있다. 예를 들어, 행동에 따라 상황에 맞는 상이한 음성 및/또는 영상 형태의 경고 메시지가 생성되고 전송될 수 있다. 일 실시예에서, 입력 이미지로부터 화재가 발생했을 때, 이미지 내의 온도, 연기뿐만 아니라 다양한 환경을 탐 지하여 이미지로부터 화재가 발생되었음이 감지될 수 있다. 이를 위해, 입력 이미지에서 화재를 예측할 수 있 도록 학습되어 있는 인공신경망을 이용하여, 입력 이미지에서 화재가 발생된 영역이 있는지 감지될 수 있다. 그리고 나서, 화재가 감지되면 경고 음성이 생성될 수 있다. 예를 들어, 화재의 위치, 화재의 규모 등의 정보가 자동적으로 음성이 생성될 수 있다. 화재에 대한 관련 정보가 필요한 장소 및/또는 장비로 전송될 수 있다. 일 실시예에서, 입력 이미지로부터 사람의 동선, 밀집도, 머무는 위치 등이 탐지되어 구매 패턴이 분석될 수 있 다. 예를 들어, 오프라인 매장에서의 사람의 동선, 밀집도, 머무는 위치 등이 분석될 수 있다. 이를 위해, 이 미지로부터 인물 영역이 도출되도록 학습된 인공신경망 모델을 이용하여, 입력 이미지로부터 인물 영역에 대응 하는 세그멘테이션 마스크이 생성되고, 도출된 사람 영역을 기초로 사람의 동선, 사람의 밀집도, 사람이 머무는 위치 등이 파악될 수 있다. 도 12는 본 개시의 일 실시예에 따른 사용자 단말이 보케 블러 강도가 강해짐에 따라 이미지 내의 배경에 서 더 좁은 영역을 추출하여 망원 렌즈 줌하는 효과를 구현하는 과정을 나타내는 예시도이다. 사용자 단말 은 이미지 내의 포커싱하는 영역과 배경 영역이 분리하도록 구성될 수 있다. 일 실시예에 따르면, 도시 된 바와 같이, 분리된 배경 영역이 이미지 내에서 실제보다 더 좁은 영역이 추출될 수 있다. 추출된 배경은 확 대되어 새로운 배경으로 사용될 수 있다. 렌즈 줌 효과 적용에 대한 입력에 응답하여, 사용자 단말은 이 미지가 확대되면서 포커싱 영역과 배경 영역 사이에 발생되는 빈공간이 채워질 수 있다. 예를 들어, 빈 공간을 채우는 방법은, inpainting 알고리즘, reflection padding 또는 방사형으로 resize해서 interpolation하는 방 법이 사용될 수 있으나, 이에 한정되지 않는다. Inpainting 알고리즘의 경우 deep learning 기술이 적용될 수 있으나, 이에 한정되지 않는다. 또한, 줌 효과 적용에 대한 입력이 수신되면, 사용자 단말은 확대된 이미 지 퀄리티가 떨어지는 것을 보정하기 위해 super resolution 기법이 적용될 수 있다. 예를 들어, super resolution 기법은 이미지 처리 분양에서 이미 알려진 기술이 적용될 수 있는데, 예를 들어, 딥러닝 기법이 적 용될 수 있으나, 이에 한정되지 않는다. 일 실시예에 따르면, 줌 효과 적용에 대한 입력을 수신하여 이미지에 줌 효과를 적용하면, 이미지의 화질이 떨어질 수 있는데, 실시간으로 super resolution 기법이 적용되어 줌 효 과 적용이 된 이미지가 보정될 수 있다. 도 13은 본 개시의 일 실시예에 따른 사용자 단말에서 이미지에 보케 효과를 적용하는 방법을 나타내는 순서도 이다. 사용자 단말에서 이미지를 수신하는 단계(S1310)로 개시될 수 있다. 그리고 나서, 사용자 단말은 수신 된 이미지를 제1 인공신경망 모델의 입력층으로 입력하여 이미지 내의 픽셀에 대한 심도 정보를 나타내는 심도 맵을 생성할 수 있다(S1320). 다음으로, 사용자 단말은 이미지 내의 픽셀들에 대한 심도 정보를 나타내는 심도 맵을 기초로 이미지 내의 픽셀들에 대한 보케 효과를 적용할 수 있다(S1330). 여기서, 제1 인공신경망 모델은 복수의 참조 이미지를 입력층으로 수신하고 복수의 참조 이미지 내에 포함된 심도 정보를 추론하도록 기계 학습을 수행함으로써 생성될 수 있다. 예를 들어, 인공신경망 모델은 기계학습 모듈에 의해 학습될 수 있다. 도 14은 본 개시의 일 실시예에 따른 보케 효과 적용 시스템의 블록도이다. 도 14을 참조하면, 일 실시예에 따른 보케 효과 적용 시스템은 데이터 학습부 및 데이터 인식부 를 포함할 수 있다. 도 14의 보케 효과 적용 시스템의 데이터 학습부는 도 2의 보케 효과 적용 시스템의 기계학습 모듈에 대응되고, 도 14의 보케 효과 적용 시스템의 데이터 인식부는 도 2의 사용자 단말의 심도 맵 생성 모듈, 보케 효과 적용 모듈, 세그멘테이션 마스크 생성 모 듈 및/또는 탐지 영역 생성 모듈에 대응될 수 있다. 데이터 학습부는 데이터를 입력하여 기계학습모델을 획득할 수 있다. 또한 데이터 인식부는 데이 터를 기계학습모델에 적용하여 심도 맵/정보 및 세그멘테이션 마스크를 생성할 수 있다. 상술한 바와 같은 보 케 효과 적용 시스템은 프로세서 및 메모리를 포함할 수 있다. 데이터 학습부는 이미지의 영상 처리 또는 효과 등에 대한 합성일 수 있다. 데이터 학습부 이미지 에 따라 어떤 영상 처리 또는 효과를 출력할지에 관한 기준을 학습할 수 있다. 또한, 데이터 학습부는 어떤 이미지의 특징을 이용하여 이미지의 적어도 일부 영역에 대응하는 심도 맵/정보를 생성하거나 이미지 내의 어떤 영역에 세그멘테이션 마스크를 생성할지에 관한 기준을 학습할 수 있다. 데이터 학습부는 학습에 이 용될 데이터를 획득하고, 획득된 데이터를 후술할 데이터 학습모델에 적용함으로써, 이미지에 따른 영상 처리 또는 효과에 대한 학습을 수행할 수 있다. 데이터 인식부는 이미지에 기초하여 이미지의 적어도 일부에 대한 심도 맵/정보를 생성하거나 세그멘테이 션 마스크를 생성할 수 있다. 이미지에 대한 심도 맵/정보 및/또는 세그멘테이션 마스크가 생성되어 출력될 수 있다. 데이터 인식부는 학습된 데이터 학습모델을 이용하여, 소정의 이미지로부터 심도 맵/정보 및/또는 세그멘테이션 마스크를 출력할 수 있다. 데이터 인식부는 학습에 의한 미리 설정된 기준에 따라 소정의 이미지(데이터)를 획득할 수 있다. 또한, 데이터 인식부는 획득된 데이터를 입력 값으로 하여 데이터 학 습모델을 이용함으로써, 소정의 데이터에 기초한 심도 맵/정보 및/또는 세그멘테이션 마스크를 생성할 수 있다. 또한, 획득된 데이터를 입력 값으로 하여 데이터 학습모델에 의해 출력된 결과 값은, 데이터 학습모델을 갱신하 는데 이용될 수 있다. 데이터 학습부 또는 데이터 인식부 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 학습부 또는 데이터 인식부 중 적어도 하나는 인 공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 이미 설명한 각종 전자 장치에 탑재될 수도 있다. 또한 데이터 학습부 및 데이터 인식부는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 학습부 및 데이터 인식부 중 하나는 전자 장치에 포함되고, 나머지 하나는 서버에 포 함될 수 있다. 또한, 데이터 학습부 및 데이터 인식부는 유선 또는 무선으로 통하여, 데이터 학습 부가 구축한 모델 정보를 데이터 인식부로 제공할 수도 있고, 데이터 인식부로 입력된 데이 터가 추가 학습 데이터로써 데이터 학습부로 제공될 수도 있다. 한편, 데이터 학습부 또는 데이터 인식부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 학습부 및 데이터 인식부 중 적어도 하나가 소프트웨어 모듈(또는, 인스트럭션 (instruction)을 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 메모리 또는 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이 션에 의해 제공될 수 있다. 이와 달리, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의 해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 본 개시의 일 실시예에 따른 데이터 학습부는 데이터 획득부, 전처리부, 학습 데이터 선택부 , 모델 학습부 및 모델 평가부를 포함할 수 있다. 데이터 획득부는 기계학습에 필요한 데이터를 획득할 수 있다. 학습을 위해서는 많은 데이터가 필요하므 로, 데이터 획득부는 복수의 참조 이미지 및 그에 대응하는 심도 맵/정보, 세그멘테이션 마스크를 수신할 수 있다.전처리부는 획득된 데이터가 인공 신경망 모델을 통한 기계학습에 이용될 수 있도록, 획득된 데이터를 전 처리할 수 있다. 전처리부는 후술할 모델 학습부가 이용할 수 있도록, 획득된 데이터를 미리 설정 된 포맷으로 가공할 수 있다. 예를 들어 전처리부는 이미지 내의 픽셀별 또는 픽셀군 별로 이미지 특성 을 분석하여 획득할 수 있다. 학습 데이터 선택부는 전처리된 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 선택된 데이터 는 모델 학습부에 제공될 수 있다. 학습 데이터 선택부는 기 설정된 기준에 따라, 전처리된 데이 터 중에서 학습에 필요한 데이터를 선택할 수 있다. 또한, 학습 데이터 선택부는 후술할 모델 학습부 에 의한 학습에 의해 기 설정된 기준에 따라 데이터를 선택할 수도 있다. 모델 학습부는 학습 데이터에 기초하여 이미지에 따라 어떤 심도 맵/정보 및 세그멘테이션 마스크를 출력 할 지에 관한 기준을 학습할 수 있다. 또한, 모델 학습부는 이미지에 따라 심도 맵/정보 및 세그멘테이 션 마스크를 출력하는 학습모델을 학습 데이터로써 이용하여 학습시킬 수 있다. 이 경우, 데이터 학습모델은 미리 구축된 모델을 포함할 수 있다. 예를 들어, 데이터 학습모델은 기본 학습 데이터(예를 들어, 샘플 이미지 등)을 입력 받아 미리 구축된 모델을 포함할 수 있다. 데이터 학습모델은, 학습모델의 적용 분야, 학습의 목적 또는 장치의 컴퓨터 성능 등을 고려하여 구축될 수 있 다. 데이터 학습모델은, 예를 들어, 신경망(Neural Network)을 기반으로 하는 모델을 포함할 수 있다. 예컨대, Deep Neural Network (DNN), Recurrent Neural Network (RNN), Long Short-Term Memory models (LSTM), BRDNN (Bidirectional Recurrent Deep Neural Network), Convolutional Neural Networks (CNN) 등과 같은 모델이 데이터 학습모델로써 사용될 수 있으나, 이에 한정되지 않는다. 다양한 실시예에 따르면, 모델 학습부는 미리 구축된 데이터 학습모델이 복수 개가 존재하는 경우, 입력 된 학습 데이터와 기본 학습 데이터의 관련성이 큰 데이터 학습모델을 학습할 데이터 학습모델로 결정할 수 있 다. 이 경우, 기본 학습 데이터는 데이터의 타입 별로 기 분류되어 있을 수 있으며, 데이터 학습모델은 데이터 의 타입 별로 미리 구축되어 있을 수 있다. 예를 들어, 기본 학습 데이터는 학습 데이터가 생성된 지역, 학습 데이터가 생성된 시간, 학습 데이터의 크기, 학습 데이터의 장르, 학습 데이터의 생성자, 학습 데이터 내의 오 브젝트의 종류 등과 같은 다양한 기준으로 기 분류되어 있을 수 있다. 또한, 모델 학습부는, 예를 들어, 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient descent)을 포함하는 학습 알고리즘 등을 이용하여 데이터 학습모델을 학습시킬 수 있다. 또한, 모델 학습부는, 예를 들어, 학습 데이터를 입력 값으로 하는 지도 학습(supervised learning)을 통 하여, 데이터 학습모델을 학습할 수 있다. 또한, 모델 학습부는, 예를 들어, 별다른 지도없이 상황 판단 을 위해 필요한 데이터의 종류를 스스로 학습함으로써, 상황 판단을 위한 기준을 발견하는 비지도 학습 (unsupervised learning)을 통하여, 데이터 학습모델을 학습할 수 있다. 또한, 모델 학습부는, 예를 들 어, 학습에 따른 상황 판단의 결과가 올바른 지에 대한 피드백을 이용하는 강화 학습(reinforcement learning) 을 통하여, 데이터 학습모델을 학습할 수 있다. 또한, 데이터 학습모델이 학습되면, 모델 학습부는 학습된 데이터 학습모델을 저장할 수 있다. 이 경우, 모델 학습부는 학습된 데이터 학습모델을 데이터 인식부를 포함하는 전자 장치의 메모리에 저장할 수 있다. 또는, 모델 학습부는 학습된 데이터 학습모델을 전자 장치와 유선 또는 무선 네트워크로 연결 되는 서버의 메모리에 저장할 수도 있다. 이 경우, 학습된 데이터 학습모델이 저장되는 메모리는, 예를 들면, 전자 장치의 적어도 하나의 다른 구성요소 에 관계된 명령 또는 데이터를 함께 저장할 수도 있다. 또한, 메모리는 소프트웨어 및/또는 프로그램을 저장할 수도 있다. 프로그램은, 예를 들면, 커널, 미들웨어, 어플리케이션 프로그래밍 인터페이스(API) 및/또는 어플 리케이션 프로그램(또는 '어플리케이션') 등을 포함할 수 있다. 모델 평가부는 데이터 학습모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 결과가 소정 기 준을 만족하지 못하는 경우, 모델 학습부로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가 데이터 는 데이터 학습모델을 평가하기 위한 기 설정된 데이터를 포함할 수 있다. 예를 들어, 모델 평가부는 평가 데이터에 대한 학습된 데이터 학습모델의 결과 중에서, 인식 결과가 정확 하지 않은 평가 데이터의 개수 또는 비율이 미리 설정된 임계치를 초과하는 경우 소정 기준을 만족하지 못한 것으로 평가할 수 있다. 예컨대, 소정 기준이 비율 2%로 정의되는 경우, 학습된 데이터 학습모델이 총 1000개의평가 데이터 중의 20개를 초과하는 평가 데이터에 대하여 잘못된 인식 결과를 출력하는 경우, 모델 평가부 는 학습된 데이터 학습모델이 적합하지 않은 것으로 평가할 수 있다. 한편, 학습된 데이터 학습모델이 복수 개가 존재하는 경우, 모델 평가부는 각각의 학습된 동영상 학습모 델에 대하여 소정 기준을 만족하는지를 평가하고, 소정 기준을 만족하는 모델을 최종 데이터 학습 모델로써 결 정할 수 있다. 이 경우, 소정 기준을 만족하는 모델이 복수 개인 경우, 모델 평가부는 평가 점수가 높은 순으로 미리 설정된 어느 하나 또는 소정 개수의 모델을 최종 데이터 학습 모델로써 결정할 수 있다. 한편, 데이터 학습부 내의 데이터 획득부, 전처리부, 학습 데이터 선택부, 모델 학습 부 또는 모델 평가부 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 획득부, 전처리부, 학습 데이터 선택부, 모델 학습부 또는 모델 평가부 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드 웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래 픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 또한, 데이터 획득부, 전처리부, 학습 데이터 선택부, 모델 학습부 및 모델 평가부 는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 획득부, 전처리부, 학습 데이터 선택부, 모델 학습부 및 모델 평가부 중 일부는 전자 장치에 포함되고, 나머지 일부는 서버에 포함될 수 있다. 또한, 데이터 획득부, 전처리부, 학습 데이터 선택부, 모델 학습부 또는 모델 평가부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부, 전처리부, 학습 데 이터 선택부, 모델 학습부 또는 모델 평가부 중 적어도 하나가 소프트웨어 모듈(또는, 인스 트럭션(instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판 독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 이와 달리, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제 공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 본 개시의 일 실시예에 따른 데이터 인식부는 데이터 획득부, 전처리부, 인식 데이터 선택부 , 인식 결과 제공부 및 모델 갱신부를 포함할 수 있다. 데이터 획득부는 심도 맵/정보 및 세그멘테이션 마스크를 출력하기 위해 필요한 이미지를 획득할 수 있다. 반대로 데이터 획득부는 이미지를 출력하기 위해 필요한 심도 맵/정보 및 세그멘테이션 마스크를 획득할 수 있다. 전처리부는 심도 맵/정보 및 세그멘테이션 마스크를 출력하기 위해 획득된 데이터가 이 용될 수 있도록, 획득된 데이터를 전처리할 수 있다. 전처리부는 후술할 인식 결과 제공부가 심도 맵/정보 및 세그멘테이션 마스크를 출력하기 위해 획득된 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정 된 포맷으로 가공할 수 있다. 인식 데이터 선택부는 전처리된 데이터 중에서 심도 맵/정보 및 세그멘테이션 마스크를 출력하기 위해 필 요한 데이터를 선택할 수 있다. 선택된 데이터는 인식 결과 제공부에게 제공될 수 있다. 인식 데이터 선택부는 심도 맵/정보 및 세그멘테이션 마스크를 출력하기 위한 기 설정된 기준에 따라, 전처리된 데이 터 중에서 일부 또는 전부를 선택할 수 있다. 또한, 인식 데이터 선택부는 모델 학습부에 의한 학 습에 의해 기 설정된 기준에 따라 데이터를 선택할 수도 있다. 인식 결과 제공부는 선택된 데이터를 데이터 학습모델에 적용하여 심도 맵/정보 및 세그멘테이션 마스크 를 출력할 수 있다. 인식 결과 제공부는 인식 데이터 선택부에 의해 선택된 데이터를 입력 값으로 이용함으로써, 선택된 데이터를 데이터 학습모델에 적용할 수 있다. 또한, 인식 결과는 데이터 학습모델에 의 해 결정될 수 있다. 모델 갱신부는 인식 결과 제공부에 의해 제공되는 인식 결과에 대한 평가에 기초하여, 데이터 학습 모델이 갱신되도록 할 수 있다. 예를 들어, 모델 갱신부는 인식 결과 제공부에 의해 제공되는 인 식 결과를 모델 학습부에게 제공함으로써, 모델 학습부가 데이터 학습모델을 갱신하도록 할 수 있 다. 한편, 데이터 인식부 내의 데이터 획득부, 전처리부, 인식 데이터 선택부, 인식 결과 제공부 또는 모델 갱신부 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 획득부, 전처리부, 인식 데이터 선택부, 인식 결 과 제공부 또는 모델 갱신부 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 또한, 데이터 획득부, 전처리부, 인식 데이터 선택부, 인식 결과 제공부 및 모델 갱신 부는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 획득부, 전처리부, 인식 데이터 선택부, 인식 결과 제공부 및 모델 갱신 부 중 일부는 전자 장치에 포함되고, 나머지 일부는 서버에 포함될 수 있다. 또한, 데이터 획득부, 전처리부, 인식 데이터 선택부, 인식 결과 제공부 또는 모델 갱 신부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부, 전처리부, 인식 데이터 선택부, 인식 결과 제공부 또는 모델 갱신부 중 적어도 하나가 소프트웨어 모듈(또는, 인스트럭션(instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 이와 달리, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 일반적으로, 본 명세서에 설명된 보케 효과 적용 시스템 및 이미지에 보케 효과를 적용하는 서비스를 제공하는 사용자 단말은, 무선 전화기, 셀룰러 전화기, 랩탑 컴퓨터, 무선 멀티미디어 디바이스, 무선 통신 PC (personal computer) 카드, PDA, 외부 모뎀이나 내부 모뎀, 무선 채널을 통해 통신하는 디바이스 등과 같은 다양한 타입들 의 디바이스들을 나타낼 수도 있다. 디바이스는, 액세스 단말기 (access terminal; AT), 액세스 유닛, 가입자 유닛, 이동국, 모바일 디바이스, 모바일 유닛, 모바일 전화기, 모바일, 원격국, 원격 단말, 원격 유닛, 유저 디 바이스, 유저 장비 (user equipment), 핸드헬드 디바이스 등과 같은 다양한 이름들을 가질 수도 있다. 본 명세 서에 설명된 임의의 디바이스는 명령들 및 데이터를 저장하기 위한 메모리, 뿐만 아니라 하드웨어, 소프트웨어, 펌웨어, 또는 이들의 조합들을 가질 수도 있다. 본 명세서에 기술된 기법들은 다양한 수단에 의해 구현될 수도 있다. 예를 들어, 이러한 기법들은 하드웨어, 펌웨어, 소프트웨어, 또는 이들의 조합으로 구현될 수도 있다. 본 명세서의 개시와 연계하여 설명된 다양한 예 시 적인 논리적 블록들, 모듈들, 회로들, 및 알고리즘 단계들은 전자 하드웨어, 컴퓨터 소프트웨어, 또는 양자 의 조합들로 구현될 수도 있음을 당업자들은 더 이해할 것이다. 하드웨어 및 소프트웨어의 이러한 상호교환성 을 명확하게 설명하기 위해, 다양한 예시 적인 컴포넌트들, 블록들, 모듈들, 회로들, 및 단계들이 그들의 기능 성의 관점에서 일반적으로 위에서 설명되었다. 그러한 기능이 하드웨어로서 구현되는지 또는 소프트웨어로서 구현되는 지의 여부는, 특정 애플리케이션 및 전체 시스템에 부과되는 설계 제약들에 따라 달라진다. 당업자들 은 각각의 특정 애플리케이션을 위해 다양한 방식들로 설명된 기능을 구현할 수도 있으나, 그러한 구현 결정들 은 본 개시의 범위로부터 벗어나게 하는 것으로 해석되어서는 안된다. 하드웨어 구현에서, 기법들을 수행하는 데 이용되는 프로세싱 유닛들은, 하나 이상의 ASIC들, DSP들, 디지털 신 호 프로세싱 디바이스들 (digital signal processing devices; DSPD들), 프로그램가능 논리 디바이스들 (programmable logic devices; PLD들), 필드 프로그램가능 게이트 어레이들 (field programmable gate arrays; FPGA들), 프로세서들, 제어기들, 마이크로제어기들, 마이크로프로세서들, 전자 디바이스들, 본 명세서에 설명된 기능들을 수행하도록 설계된 다른 전자 유닛들, 컴퓨터, 또는 이들의 조합 내에서 구현될 수도 있다. 따라서, 본 명세서의 개시와 연계하여 설명된 다양한 예시 적인 논리 블록들, 모듈들, 및 회로들은 범용 프로세 서, DSP, ASIC, FPGA나 다른 프로그램 가능 논리 디바이스, 이산 게이트나 트랜지스터 로직, 이산 하드웨어 컴 포넌트들, 또는 본 명세서에 설명된 기능들을 수행하도록 설계된 것들의 임의의 조합으로 구현되거나 수행될 수 도 있다. 범용 프로세서는 마이크로프로세서일 수도 있지만, 대안에서, 프로세서는 임의의 종래의 프로세서, 제어기, 마이크로제어기, 또는 상태 머신일 수도 있다. 프로세서는 또한 컴퓨팅 디바이스들의 조합, 예를 들면, DSP와 마이크로프로세서, 복수의 마이크로프로세서들, DSP 코어와 연계한 하나 이상의 마이크로프로세서 들, 또는 임의의 다른 그러한 구성의 조합으로써 구현될 수도 있다. 펌웨어 및/또는 소프트웨어 구현에 있어서, 기법들은 랜덤 액세스 메모리 (random access memory; RAM), 판독 전용 메모리 (read-only memory; ROM), 불휘발성 RAM (non-volatile random access memory; NVRAM), PROM (programmable read-only memory), EPROM (erasable programmable read-only memory), EEPROM (electricallyerasable PROM), 플래시 메모리, 컴팩트 디스크 (compact disc; CD), 자기 또는 광학 데이터 스토리지 디바이 스 등과 같은 컴퓨터 판독가능 매체 상에 저장된 명령들로써 구현될 수도 있다. 명령들은 하나 이상의 프로세 서들에 의해 실행 가능할 수도 있고, 프로세서(들)로 하여금 본 명세서에 설명된 기능의 특정 양태들을 수행하 게 할 수도 있다. 소프트웨어로 구현되면, 상기 기능들은 하나 이상의 명령들 또는 코드로서 컴퓨터 판독 가능한 매체 상에 저장 되거나 또는 컴퓨터 판독 가능한 매체를 통해 전송될 수도 있다. 컴퓨터 판독가능 매체들은 한 장소에서 다른 장소로 컴퓨터 프로그램의 전송을 용이하게 하는 임의의 매체를 포함하여 컴퓨터 저장 매체들 및 통신 매체들 양자를 포함한다. 저장 매체들은 컴퓨터에 의해 액세스될 수 있는 임의의 이용 가능한 매체들일 수도 있다. 비제한적인 예로서, 이러한 컴퓨터 판독가능 매체는 RAM, ROM, EEPROM, CD-ROM 또는 다른 광학 디스크 스토리지, 자기 디스크 스토리지 또는 다른 자기 스토리지 디바이스들, 또는 소망의 프로그램 코드를 명령들 또 는 데이터 구조들의 형태로 이송 또는 저장하기 위해 사용될 수 있으며 컴퓨터에 의해 액세스될 수 있는 임의의 다른 매체를 포함할 수 있다. 또한, 임의의 접속이 컴퓨터 판독가능 매체로 적절히 칭해진다. 예를 들어, 소프트웨어가 동축 케이블, 광섬유 케이블, 연선, 디지털 가입자 회선 (DSL), 또는 적외선, 무선, 및 마이크로파와 같은 무선 기술들을 사용하여 웹사이트, 서버, 또는 다른 원격 소스로부터 전송되면, 동축 케 이블, 광섬유 케이블, 연선, 디지털 가입자 회선, 또는 적외선, 무선, 및 마이크로파와 같은 무선 기술들은 매 체의 정의 내에 포함된다. 본 명세서에서 사용된 디스크 (disk) 와 디스크 (disc)는, CD, 레이저 디스크, 광 디스크, DVD (digital versatile disc), 플로피디스크, 및 블루레이 디스크를 포함하며, 여기서 디스크들 (disks) 은 보통 자기적으로 데이터를 재생하고, 반면 디스크들 (discs) 은 레이저를 이용하여 광학적으로 데이 터를 재생한다. 위의 조합들도 컴퓨터 판독가능 매체들의 범위 내에 포함되어야 한다. 소프트웨어 모듈은 RAM 메모리, 플래시 메모리, ROM 메모리, EPROM 메모리, EEPROM 메모리, 레지스터들, 하드 디스크, 이동식 디스크, CD-ROM, 또는 공지된 임의의 다른 형태의 저장 매체 내에 상주할 수도 있다. 예시 적 인 저장 매체는, 프로세가 저장 매체로부터 정보를 판독하거나 저장 매체에 정보를 기록할 수 있도록, 프로세서 에 커플링 될 수 있다. 대안으로, 저장 매체는 프로세서에 통합될 수도 있다. 프로세서와 저장 매체는 ASIC 내에 존재할 수도 있다. ASIC은 유저 단말 내에 존재할 수도 있다. 대안으로, 프로세서와 저장 매체는 유저 단말에서 개별 컴포넌트들로써 존재할 수도 있다. 본 개시의 앞선 설명은 당업자들이 본 개시를 행하거나 이용하는 것을 가능하게 하기 위해 제공된다. 본 개시 의 다양한 수정예들이 당업자들에게 쉽게 자명할 것이고, 본 명세서에 정의된 일반적인 원리들은 본 개시의 취 지 또는 범위를 벗어나지 않으면서 다양한 변형예들에 적용될 수도 있다. 따라서, 본 개시는 본 명세서에 설명 된 예들에 제한되도록 의도된 것이 아니고, 본 명세서에 개시된 원리들 및 신규한 특징들과 일관되는 최광의의 범위가 부여되도록 의도된다. 비록 예시적인 구현예들이 하나 이상의 독립형 컴퓨터 시스템의 맥락에서 현재 개시된 주제의 양태들을 활용하 는 것을 언급할 수도 있으나, 본 주제는 그렇게 제한되지 않고, 오히려 네트워크나 분산 컴퓨팅 환경과 같은 임 의의 컴퓨팅 환경과 연계하여 구현될 수도 있다. 또 나아가, 현재 개시된 주제의 양상들은 복수의 프로세싱 칩 들이나 디바이스들에서 또는 그들에 걸쳐 구현될 수도 있고, 스토리지는 복수의 디바이스들에 걸쳐 유사하게 영 향을 받게 될 수도 있다. 이러한 디바이스들은 PC들, 네트워크 서버들, 및 핸드헬드 디바이스들을 포함할 수도 있다. 비록 본 주제가 구조적 특징들 및/또는 방법론적 작용들에 특정한 언어로 설명되었으나, 첨부된 청구항들에서 정의된 주제가 위에서 설명된 특정 특징들 또는 작용들로 반드시 제한되는 것은 아님이 이해될 것이다. 오히려, 위에서 설명된 특정 특징들 및 작용들은 청구항들을 구현하는 예시 적인 형태로서 설명된다. 이 명세서에서 언급된 방법은 특정 실시예들을 통하여 설명되었지만, 컴퓨터로 읽을 수 있는 기록매체에 컴퓨터 가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의해 읽힐 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 기록매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광데이터 저장장치 등이 있다. 또한, 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되 고 실행될 수 있다. 그리고, 실시예들을 구현하기 위한 기능적인(functional) 프로그램, 코드 및 코드 세그먼"}
{"patent_id": "10-2019-0100550", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "트들은 본 발명이 속하는 기술분야의 프로그래머들에 의해 용이하게 추론될 수 있다."}
{"patent_id": "10-2019-0100550", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "본 명세서에서는 본 개시가 일부 실시예들과 관련하여 설명되었지만, 본 발명이 속하는 기술분야의 통상의 기술 자가 이해할 수 있는 본 개시의 범위를 벗어나지 않는 범위에서 다양한 변형 및 변경이 이루어질 수 있다는 점 을 알아야 할 것이다. 또한, 그러한 변형 및 변경은 본 명세서에 첨부된 특허청구의 범위 내에 속하는 것으로 생각되어야 한다."}
{"patent_id": "10-2019-0100550", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 보케 효과 적용 장치가 이미지로부터 심도 맵을 생성하여 이를 기초로 보케 효과를 적용하는 과정을 나타내는 예시도이다. 도 2는 본 개시의 일 실시예에 따른 보케 효과 적용 장치의 구성을 나타내는 블록도이다. 도 3는 본 개시의 일 실시예에 따른 인공신경망 모델이 학습되는 방법을 나타내는 개략도이다. 도 4는 본 개시의 일 실시예에 따른 보케 효과 적용 장치가 이미지로부터 생성된 세그멘테이션 마스크를 기초로 심도 맵을 보정하고, 보정된 심도 맵을 이용하여 보케 효과를 적용하는 방법을 나타내는 흐름도이다. 도 5는 본 개시의 일 실시예에 따른 보케 효과 적용 장치가 이미지 내에 포함된 인물에 대한 세그멘테이션 마스 크를 생성하고, 보정된 심도 맵을 기초로 이미지에 보케 효과를 적용하는 과정을 나타내는 개략도이다. 도 6은 본 개시의 일 실시예에 따른 장치가 이미지로부터 생성된 심도 맵 및 이미지에 대응하는 세그멘테이션 마스크를 기초로 보정된 심도 맵을 대비하여 보여주는 비교도이다. 도 7은 본 개시의 일 실시예에 따른 보케 효과 적용 장치가 이미지 내의 선택된 객체에 대응되는 기준 심도를 결정하고, 기준 심도와 다른 픽셀들의 심도 차이를 산출하여 이를 기초로 이미지에 보케 효과를 적용한 예시도 이다. 도 8은 본 개시의 일 실시예에 따른 보케 효과 적용 장치가 이미지로부터 심도 맵을 생성하고, 학습된 인공신경 망 모델을 이용하여 이미지 내의 객체를 결정하고, 이를 기초로 보케 효과를 적용하는 과정을 나타내는 개략도 이다. 도 9는 본 개시의 일 실시예에 따른 보케 효과 적용 장치가 이미지 내에 포함된 객체에 대한 세그멘테이션 마스 크를 생성하고 보케 효과를 적용하는 과정에서 마스크를 별도로 학습된 인공신경망 모델의 입력층으로 입력하고 마스크의 심도 정보를 획득하여 이를 기초로 마스크에 보케 효과를 적용하는 과정을 나타내는 흐름도이다. 도 10은 본 개시의 일 실시예에 따른 보케 효과 적용 장치가 이미지 내에 포함된 복수의 객체에 대한 세그멘테이션 마스크를 생성하고, 이 중 선택된 세그멘테이션 마스크를 기초로 보케 효과를 적용하는 과정을 나타내는 예시도이다. 도 11은 본 개시의 일 실시예에 따른 보케 효과 적용 장치에 수신되는 보케 효과 적용에 대한 설정 정보에 따라 보케 효과가 변경되는 과정을 나타내는 예시도이다. 도 12는 본 개시의 일 실시예에 따른 보케 효과 적용 장치가 보케 블러 강도가 강해짐에 따라 이미지 내의 배경 에서 더 좁은 영역을 추출하여 망원 렌즈 줌하는 효과를 구현하는 과정을 나타내는 예시도이다. 도 13은 본 개시의 일 실시예에 따른 사용자 단말에서 이미지에 보케 효과를 적용하는 방법을 나타내는 순서도 이다. 도 14은 본 개시의 일 실시예에 따른 보케 효과 적용 시스템의 블록도이다."}
