{"patent_id": "10-2025-0043543", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0053015", "출원번호": "10-2025-0043543", "발명의 명칭": "로봇-휴먼 상호작용을 위한 발화 상황 인식 시스템 및 방법", "출원인": "한국과학기술연구원", "발명자": "채유정"}}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "로봇의 경청 모드 진입을 위한 발화 상황 인식 시스템으로서,사용자의 얼굴을 포함하는 이미지 데이터를 획득하기 위한 촬영부;오디오 데이터를 획득하기 위한 오디오 인터페이스부;상기 이미지 및 상기 오디오 데이터에 기초하여 사용자가 발화 중인지 여부를 결정하는 발화 상황 인식부; 및발화 상황 인식 결과에 기초하여 상기 로봇의 경청 모드 전환을 트리거하는 로봇 행동 제어부를 포함하는, 발화상황 인식 시스템."}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 발화 상황 인식부는, 상기 이미지 데이터에 기초하여 상기 사용자의 입이 발화 상태인지 여부를 판정하는 입 움직임 인식부; 및상기 오디오 데이터에 기초하여 음성의 주체가 상기 사용자인지 여부를 판정하는 음성 인식부을 포함하는 것을특징으로 하는, 발화 상황 인식 시스템."}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 입 움직임 인식부는,상기 이미지에서 사용자의 얼굴을 인식하고,상기 사용자의 얼굴에서 기준이 되는 랜드마크를 추출하고,상기 사용자의 입 움직임에 따른 입의 종횡비를 계산하고,상기 입의 종횡비에 기초하여 상기 입이 발화 상태인지 여부를 판정하도록 구성되는 것을 특징으로 하는, 발화상황 인식 시스템."}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 입 움직임 인식부는 기계학습 모델을 이용하여 학습되며, 학습 결과에 기초하여 사용자의 입 움직임을 인식하는 것을 특징으로 하는, 발화 상황 인식 시스템."}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 음성 인식부는,공개특허 10-2025-0053015-3-상기 오디오 데이터를 소정의 구간으로 나누어 인식하고,상기 오디오 데이터의 주파수 성분 분포를 파악하고, 상기 주파수 성분 분포에 기초하여 상기 오디오 데이터가 사용자의 발화된 음성을 포함하는지 여부를 판정하도록 구성되는 것을 특징으로 하는, 발화 상황 인식 시스템."}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 음성 인식부는 기계학습 모델을 이용하여 학습되며, 학습 결과에 기초하여 사용자의 발화된 음성을 인식하는 것을 특징으로 하는, 발화 상황 인식 시스템."}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서,상기 발화 상황 인식부는, 상기 입 움직임 인식부의 판정 결과와 상기 음성 인식부의 판정 결과를 모두 고려하여, 상기 사용자가 발화 중인지 여부를 결정하는 것을 특징으로 하는, 발화 상황 인식 시스템."}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제2항에 있어서,상기 입 움직임 인식부 및 상기 음성 인식부는, 이동 평균을 통해 입 움직임 인식 결과와 음성 인식 결과의 민감도를 조절할 수 있도록 구성되는 것을 특징으로 하는, 발화 상황 인식 시스템."}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 따른 발화 상황 인식 시스템을 구비하는 상호작용 로봇으로서,사용자가 발화 상황에 있다고 인식할 경우 경청 모드에 진입하고, 상기 경청 모드에서는 경청 모드 전용 동작을표현하는 것을 특징으로 하는, 상호작용 로봇."}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 경청 모드 전용 동작은, 상기 로봇의 음성, 제스처, 표정 또는 이들의 조합으로 구성되는 것을 특징으로하는, 상호작용 로봇."}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "로봇의 경청 모드 진입을 위한 발화 상황 인식 방법으로서,촬영부에서, 사용자의 얼굴을 포함하는 이미지 데이터를 획득하는 단계;오디오 인터페이스부에서, 오디오 데이터를 획득하는 단계;발화 상황 인식부에서, 상기 이미지 및 상기 오디오 데이터에 기초하여 사용자가 발화 중인지 여부를 결정하는단계; 및로봇 행동 제어부에서, 발화 상황 인식 결과에 기초하여 상기 로봇을 경청 모드로 전환하는 단계를 포함하는,공개특허 10-2025-0053015-4-발화 상황 인식 방법."}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 사용자가 발화 중인지 여부를 결정하는 단계는,상기 이미지 데이터에 기초하여 상기 사용자의 입 움직임을 인식하는 단계;상기 오디오 데이터에 기초하여 상기 사용자의 음성을 인식하는 단계; 및상기 사용자의 입 움직임 인식 결과 및 상기 사용자의 음성 인식 결과에 기초하여 상기 사용자가 발화 중인지여부를 결정하는 단계를 포함하는 것을 특징으로 하는, 발화 상황 인식 방법."}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 사용자의 입 움직임을 인식하는 단계는,상기 이미지에서 사용자의 얼굴을 인식하는 단계;상기 사용자의 얼굴에서 기준이 되는 랜드마크를 추출하는 단계;상기 사용자의 입 움직임에 따른 입의 종횡비를 계산하는 단계; 및상기 입의 종횡비에 기초하여 상기 입이 발화 상태인지 여부를 판정하는 단계를 포함하는 것을 특징으로 하는,발화 상황 인식 방법."}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 사용자의 음성을 인식하는 단계는,상기 오디오 데이터를 소정의 구간으로 나누는 단계;상기 오디오 데이터의 주파수 성분 분포를 파악하는 단계; 및상기 주파수 성분 분포에 기초하여 상기 오디오 데이터가 사용자의 발화된 음성을 포함하는지 여부를 판정하는단계를 포함하는 것을 특징으로 하는, 발화 상황 인식 방법."}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 사용자의 입 움직임을 인식하는 단계 및 상기 사용자의 음성을 인식하는 단계는, 이동 평균을 통해 입 움직임 인식 결과와 음성 인식 결과의 민감도를 조절하는 단계를 포함하는 것을 특징으로 하는, 발화 상황 인식방법."}
{"patent_id": "10-2025-0043543", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항 내지 제15항 중 어느 한 항에 따른 발화 상황 인식 방법을 수행하기 위한, 컴퓨터로 판독 가능한 기록매체에 저장된 컴퓨터 프로그램.공개특허 10-2025-0053015-5-"}
{"patent_id": "10-2025-0043543", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 로봇의 경청 모드 진입을 위한 발화 상황 인식 시스템에 관한 것이다. 일 실시예에 따른 발화 상황 인 식 시스템은, 사용자의 얼굴을 포함하는 이미지 데이터를 획득하기 위한 촬영부; 오디오 데이터를 획득하기 위한 오디오 인터페이스부; 상기 이미지 및 상기 오디오 데이터에 기초하여 사용자가 발화 중인지 여부를 결정하는 발 화 상황 인식부; 및 발화 상황 인식 결과에 기초하여 상기 로봇의 경청 모드 전환을 트리거하는 로봇 행동 제어 부를 포함한다. 실시예에 따르면, 주변 환경으로부터 획득한 이미지 데이터 및/또는 오디오 데이터에 기초하여 사용자가 발화 중인지 여부를 결정할 수 있으며, 사용자가 발화 중인 것으로 인식하면, 로봇을 '경청 모드'로 전 환하여 상황에 알맞은 행동들을 출력함으로써 사용자에게 자연스러운 상호작용 경험을 제공할 수 있다."}
{"patent_id": "10-2025-0043543", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 로봇-휴먼 상호작용을 위한 발화 상황 인식 시스템 및 방법에 관한 것으로서, 더욱 상세하게는 주변 환경으로부터 획득한 이미지 데이터 및 오디오 데이터에 기초하여 사용자가 발화 중인지 여부를 결정하고 이에 따라 로봇을 경청 모드로 전환하기 위한 시스템 및 방법에 관한 것이다. [국가지원 연구개발에 대한 설명] 본 연구는 과학기술정보통신부, 국가과학기술연구회연구운영비지원(R&D), [고령세대 치매 조기예측, 치료제 및 환자케어 기술 개발(치매환자 지원 라이프케어 로봇 개발), 세부과제번호: CRC-15-04-KIST]의 지원에 의하여 이 루어진 것이다."}
{"patent_id": "10-2025-0043543", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "소셜 로봇(social robot)은 사람을 위해 물리적인 일을 대신 하는 산업용 로봇(예컨대, 공장 생산 라인에서 정 해진 행동을 반복 수행하는 로봇 팔 등)과 달리 사람처럼 대화하거나 몸짓을 통해 사람과 정서적으로 소통할 수 있는 로봇을 지칭한다. 과거에는 로봇의 역할이 주로 사람의 노동을 대체하거나 빠르고 정확한 연산 기능을 제 공하는데 있었으나, 최근 1인 가구 및 노년층 인구가 증가함에 따라 사람과 소통하면서 정서적인 교감을 나눌 수 있는 소셜 로봇에 대한 수요가 증가하고 있다. 근래 인공지능 기술 분야가 급격히 발전하고 빅데이터, 사물인터넷, 클라우드 컴퓨팅 기술이 융합되면서 이러한 소셜 로봇의 성능이 대폭 향상되었다. 최근 소셜 로봇은 기존의 챗봇(대화 프로토콜에 따라 사용자의 질문에 답 변을 제공하는 프로그램) 기능은 물론, 카메라를 통해 사람의 얼굴을 살펴보고 심리 상태를 분석하면서 대화하 거나 감정 표현을 하는 등 보다 자연스러운 상호작용이 가능하게 되었다. 상호작용 로봇은 사람의 요청이나 명령에 응답하는 과정에서 응답 지연(response delay)이 불가피한데, 이러한 응답 지연은 사용자로 하여금 로봇과의 대화가 자연스럽지 못하다고 느끼게 한다. 응답 지연의 길이는 로봇이 실행할 업무의 종류, 로봇의 성능, 네트워크 연결 상태 등 환경에 따라 달라질 수 있다. 예컨대, 사람의 접근을 인식하고 인사하는 동작에 비해 요청에 응답하여 뉴스를 낭독하는 동작의 경우 응답 지연이 더 길어질 수 있고, 로봇의 처리장치 성능이 부족하거나 네트워크 연결 상태가 좋지 않다면 응답 지연이 더 길어질 수 있다. 소셜 로봇은 단순히 정보를 제공할 뿐만 아니라 대화와 교감에서 오는 정서적인 만족감을 제공하는데 목적이 있 기 때문에 자연스러운 상호작용을 위해 응답 지연 시간을 줄이는 것이 더욱 중요하다. 그러나 전술한 바와 같이 응답 지연은 서비스의 종류, 로봇의 성능, 네트워크 환경에 따라 불가피하게 발생한다. 따라서 응답 지연을 줄 이려는 노력과 동시에, 응답 지연에도 불구하고 사용자로 하여금 로봇과의 대화가 자연스럽다고 느끼게 하는 것 이 중요하다. 대한민국 특허출원 제10-2020-0136545호(\"응답 지연에 대응하기 위한 로봇 행동 제어 시스템\")에 따르면, 로봇 과 사용자의 상호작용 시 발생하는 응답 지연 시간 동안 로봇이 특정 행동(예컨대, 사람을 모사한 표정, 제스처, 간투사 등)을 표현하도록 설정함으로써 자연스러운 상호작용 경험을 제공할 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 특허출원 제10-2020-0136545호 비특허문헌 (비특허문헌 0001) Shiwa, Toshiyuki, et al. \"How quickly should a communication robot respond? Delaying strategies and habituation effects.\" International Journal of Social Robotics 1.2 : 141-155. (비특허문헌 0002) Ohshima, Naoki, et al. \"A conversational robot with vocal and bodily fillers forrecovering from awkward silence at turn-takings.\" 2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN). IEEE, 2015."}
{"patent_id": "10-2025-0043543", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 로봇과의 상호작용에 있어서 사용자의 발화 여부를 정확하게 인식하기 위한 시스템 및 방법을 제공하 는 것을 목적으로 한다. 나아가 사용자가 발화 중인 것으로 인식되면, 발화 중 혹은 지시에 응답하기까지 걸리 는 응답 지연 시간 동안 로봇이 적절한 행동을 표현하는 '경청 모드'에 진입하도록 설정하여 사용자에게 보다 자연스러운 상호작용 경험을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2025-0043543", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 로봇의 경청 모드 진입을 위한 발화 상황 인식 시스템은, 사용자의 얼굴을 포함하 는 이미지 데이터를 획득하기 위한 촬영부; 오디오 데이터를 획득하기 위한 오디오 인터페이스부; 상기 이미지 및 상기 오디오 데이터에 기초하여 사용자가 발화 중인지 여부를 결정하는 발화 상황 인식부; 및 발화 상황 인 식 결과에 기초하여 상기 로봇의 경청 모드 전환을 트리거하는 로봇 행동 제어부를 포함한다. 일 실시예에 따르면, 상기 발화 상황 인식부는, 상기 이미지 데이터에 기초하여 상기 사용자의 입이 발화 상태 인지 여부를 판정하는 입 움직임 인식부; 및 상기 오디오 데이터에 기초하여 음성의 주체가 상기 사용자인지 여 부를 판정하는 음성 인식부을 포함할 수 있다. 일 실시예에 따르면, 상기 입 움직임 인식부는, 상기 이미지에서 사용자의 얼굴을 인식하고, 상기 사용자의 얼 굴에서 기준이 되는 랜드마크를 추출하고, 상기 사용자의 입 움직임에 따른 입의 종횡비를 계산하고, 상기 입의 종횡비에 기초하여 상기 입이 발화 상태인지 여부를 판정하도록 구성될 수 있다. 일 실시예에 따르면, 상기 입 움직임 인식부는 기계학습 모델을 이용하여 학습되며, 학습 결과에 기초하여 사용 자의 입 움직임을 인식할 수 있다. 일 실시예에 따르면, 상기 음성 인식부는, 상기 오디오 데이터를 소정의 구간으로 나누어 인식하고, 상기 오디 오 데이터의 주파수 성분 분포를 파악하고, 상기 주파수 성분 분포에 기초하여 상기 오디오 데이터가 사용자의 발화된 음성을 포함하는지 여부를 판정하도록 구성될 수 있다. 일 실시예에 따르면, 상기 음성 인식부는 기계학습 모델을 이용하여 학습되며, 학습 결과에 기초하여 사용자의 발화된 음성을 인식할 수 있다. 일 실시예에 따르면, 상기 발화 상황 인식부는, 상기 입 움직임 인식부의 판정 결과와 상기 음성 인식부의 판정 결과를 모두 고려하여, 상기 사용자가 발화 중인지 여부를 결정할 수 있다. 일 실시예에 따르면, 상기 입 움직임 인식부 및 상기 음성 인식부는, 이동 평균을 통해 입 움직임 인식 결과와 음성 인식 결과의 민감도를 조절할 수 있도록 구성될 수 있다. 실시예에 따른 발화 상황 인식 시스템을 구비하고, 사용자가 발화 상황에 있다고 인식할 경우 경청 모드에 진입 하고, 상기 경청 모드에서는 경청 모드 전용 동작을 표현하는 상호작용 로봇이 제공될 수 있다. 일 실시예에 따르면, 상기 경청 모드 전용 동작은, 상기 로봇의 음성, 제스처, 표정 또는 이들의 조합으로 구성 될 수 있다. 본 발명의 일 실시예에 따른 로봇의 경청 모드 진입을 위한 발화 상황 인식 방법은, 촬영부에서 사용자의 얼굴 을 포함하는 이미지 데이터를 획득하는 단계; 오디오 인터페이스부에서 오디오 데이터를 획득하는 단계; 발화 상황 인식부에서 상기 이미지 및 상기 오디오 데이터에 기초하여 사용자가 발화 중인지 여부를 결정하는 단계; 및 로봇 행동 제어부에서 발화 상황 인식 결과에 기초하여 상기 로봇을 경청 모드로 전환하는 단계를 포함한다. 일 실시예에 따르면, 상기 사용자가 발화 중인지 여부를 결정하는 단계는, 상기 이미지 데이터에 기초하여 상기 사용자의 입 움직임을 인식하는 단계; 상기 오디오 데이터에 기초하여 상기 사용자의 음성을 인식하는 단계; 및 상기 사용자의 입 움직임 인식 결과 및 상기 사용자의 음성 인식 결과에 기초하여 상기 사용자가 발화 중인지여부를 결정하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 사용자의 입 움직임을 인식하는 단계는, 상기 이미지에서 사용자의 얼굴을 인식하는 단계; 상기 사용자의 얼굴에서 기준이 되는 랜드마크를 추출하는 단계; 상기 사용자의 입 움직임에 따른 입의 종횡비를 계산하는 단계; 및 상기 입의 종횡비에 기초하여 상기 입이 발화 상태인지 여부를 판정하는 단계를 포 함할 수 있다. 일 실시예에 따르면, 상기 사용자의 음성을 인식하는 단계는, 상기 오디오 데이터를 소정의 구간으로 나누는 단 계; 상기 오디오 데이터의 주파수 성분 분포를 파악하는 단계; 및 상기 주파수 성분 분포에 기초하여 상기 오디 오 데이터가 사용자의 발화된 음성을 포함하는지 여부를 판정하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 사용자의 입 움직임을 인식하는 단계 및 상기 사용자의 음성을 인식하는 단계는, 이 동 평균을 통해 입 움직임 인식 결과와 음성 인식 결과의 민감도를 조절하는 단계를 포함할 수 있다. 실시예에 따른 발화 상황 인식 방법을 수행하기 위한 컴퓨터로 판독 가능한 기록매체에 저장된 컴퓨터 프로그램 이 제공될 수 있다."}
{"patent_id": "10-2025-0043543", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 발화 상황 인식 시스템에 의하면, 주변 환경으로부터 획득한 이미지 데이터 및/또 는 오디오 데이터에 기초하여 사용자가 발화 중인지 여부를 결정할 수 있다. 사용자가 발화 중인 것으로 인식하 면, 로봇을 '경청 모드'로 전환하여 상황에 알맞은 행동들(예컨대, 적절한 표정, 제스처, 음성 등)을 출력함으 로써 사용자에게 자연스러운 상호작용 경험을 제공할 수 있다."}
{"patent_id": "10-2025-0043543", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어는 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어를 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 관례 또는 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 명세서의 설명 부분에서 그 의미를 기 재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌 그 용어가 가지는 실질적인 의 미와 본 명세서의 전반에 걸친 내용을 토대로 해석되어야 함을 밝혀두고자 한다. 이하 첨부 도면들 및 첨부 도면들에 기재된 내용들을 참조하여 실시예를 상세하게 설명하지만, 청구하고자 하는 범위는 실시예들에 의해 제한되거나 한정되지 아니한다. 도 1은 일 실시예에 따른 발화 상황 인식 시스템의 구조를 도시한다. 도 1을 참조하면, 일 실시예에 따른 발화 상황 인식 시스템은 로봇, 발화 상황 인식부, 로봇 행동 제어부로 구성될 수 있다. 로봇은 움직이거나 사람과 상호작용할 수 있도록 프로그래밍된 하드웨어 및 소프트웨어로 구성된 장치를 의 미하며, 본 명세서에서는 상호작용 가능한 인터페이스 시스템을 구비한 모든 형태의 로봇을 포함하는 것으로 넓게 해석될 수 있다. 예컨대, 로봇은 이동 및 동작을 위한 구동장치, 사용자로부터 또는 주변 환경으로부터 정보를 입력 받아 대응하는 음성 또는 이미지를 출력하기 위한 입출력장치 등의 구성요소를 포함한다. 일 실시예에 따르면, 로봇은 이미지 데이터를 획득하기 위한 촬영부와 오디오 데이터를 획득하기 위한 오디오 인터페이스부를 포함할 수 있다. 도시하지는 않았으나 로봇의 동작을 위해 필수적이거나 부가적인 다양한 구성요소들이 더 포함될 수 있다. 여기서는 본 발명의 목적에 따라 발화 상황 인식을 위한 구성요소들에 대해서만 설명하기로 한다. 촬영부는 로봇의 전면부에 설치되어 사용자의 얼굴을 포함한 이미지 데이터를 획득하며, 일반적인 RGB 카메라와 같은 광학 장치가 활용될 수 있다. 일 실시예에 따르면, 촬영부는 촬영된 전체 이미지에서 사람 의 얼굴을 인식하고, 특정 부위를 확대 및 추적하여 촬영하는 기능을 구비할 수 있다. 또한, 획득한 이미지 데 이터를 처리하여 사람의 얼굴과 배경을 구분하여 인식하기 위해 딥 러닝 기술이 적용될 수 있다. 오디오 인터페이스부는 주변 환경에서 발생하는 소리를 감지하여 디지털 신호로 전환하며, 일반적인 마이 크로폰 등의 녹음 장치가 활용될 수 있다. 촬영부에서 획득한 이미지 데이터와 오디오 인터페이스부 를 통해 입력된 오디오 데이터는 발화 상황 인식부로 전송된다. 발화 상황 인식부에서는 전송된 이미지 데이터 및 오디오 데이터를 처리하여 사용자가 발화 중인지 여부를 결정한다. 발화 상황 인식부는 로봇 내에 구비된 하나 이상의 프로세서로 구현되거나, 로봇 외부에 존재하 는 별도의 컴퓨팅 장치로 구현될 수도 있다. 발화 상황 인식부는 상기 이미지 데이터에 기초하여 사용자의 입이 발화 상태인지 여부를 판정하는 입 움직임 인식부, 상기 오디오 데이터에 기초하여 음성의 주체가 사 용자인지 여부를 판정하는 음성 인식부를 포함한다. 각 구성요소에서 입 움직임과 음성을 인식하여 발화 상황을 인식하는 과정에 대해서는 후술하기로 한다. 로봇 행동 제어부는 발화 상황 인식 결과에 기초하여 로봇의 경청 모드 전환을 트리거한다. 구체적으로, 입 움직임과 음성 인식 결과 사용자가 현재 발화 중인 것으로 결정되면, 로봇을 경청 모드로 전환하고, 이에 대응하는 행동을 출력하도록 로봇을 제어한다. 예컨대, 현재 진행 중인 로봇의 활동을 일시 중지하고 발화 중인 사용자에게 접근하거나, 사람의 경청 행위를 모방한 제스처를 표현하는 등 사용자의 지시가 로봇에게 적절하게 전달되고 있음을 표현할 수 있다. 이처럼 경청 모드 매뉴얼에 해당하는 로봇 행동 표현을 통해 사용자에게 자연 스러운 상호작용 경험을 제공하는 것이 가능하다. 이하에서는, 로봇의 경청 모드 진입을 위해 이미지 데이터와 오디오 데이터를 처리하여 사용자가 발화 중인지 여부를 인식하는 프로세스에 대해 설명한다. 도 2의 순서도는 발화 상황 인식 시스템을 통해 실행될 수 있는 발화 상황 인식 방법을 나타낸 순서도이다. 도 2를 참조하면, 먼저 사용자의 얼굴을 포함한 이미지 데이터를 획득하는 단계(S100)가 실행되며, 이어서 단계 (S100)에서 획득한 이미지 데이터에 기초하여 사용자의 입 움직임을 인식하는 단계(S200)가 실행된다. 도 3에는 단계(S200)에서 사용자의 입 움직임을 인식하는 세부적인 과정이 도시되어 있다. 단계(S210)에서는, 상기 이미지에서 사용자의 얼굴을 인식한다. 얼굴 인식 프로세스는 배경 이미지와 사람 얼굴 을 구분하도록 학습된 기계학습 모델을 이용하여 수행할 수 있으나, 특정 기술로 한정되는 것은 아니다. 단계(S220)에서는, 사용자의 얼굴에서 기준이 되는 랜드마크를 추출한다. 일 구현예에 따르면, OpenCV_dlib 를 활용하여 얼굴 전면 구성에 대한 68개의 마크를 추출하고, 68개의 마크 중에서 입의 모양을 인식하는 것이 가능 하다. 단계(S230)에서는, 사용자의 입 움직임에 따른 입의 종횡비를 계산한다. 계산된 입의 종횡비는 사용자가 입을 벌린 정도를 인식하여 발화 중인지를 판단하기 위한 근거로 활용된다. 마지막으로, 단계(S240)에서는, 입의 종횡비의 변화에 기초하여 사용자가 발화 상태인지 여부를 판정한다. 예컨 대, 입 모델로부터 계산된 입의 종횡비(즉, 입의 가로 길이 대비 세로 길이의 비율)가 임계치 이상일 경우 사용 자가 입을 벌린 것으로 인식하고, 이러한 입의 종횡비 변화가 반복적으로 나타나면 사용자가 발화 중인 것으로 인식할 수 있다. 도 4와 도 5는 각각 사용자의 입 모양으로부터 입의 종횡비를 계산하기 위한 서로 다른 모델을 나타낸다. 도 4는 단순화된 입 모양 모델을 나타내는데, 먼저 얼굴 이미지에서 입 부위를 박스 형태로 인식한 후, 상기 박 스의 세로 길이를 H, 가로 길이를 L로 설정한다. 입 종횡비 N은 가로 길이에 대한 세로 길이의 비율로 나타낼 수 있다(즉, ). 종횡비 N의 값이 임계치보다 크면 입을 벌리고 있는 것으로 인식할 수 있고, N 값의 크기 나 N 값의 변화 패턴으로부터 사용자의 발화 여부를 유추할 수 있다. 도 5는 더 정확한 인식을 위해 설계된 입 모양 모델을 나타낸다. 도 5를 참조하면, 입 모양을 마크로 인식한 후 입의 안쪽 세로 3구간의 길이 A, B, C를 계산한다. 도 5에서 입의 종횡비 MAR는 상기 A, B, C 값의 평균을 입의 가로 길이 D로 나누어 계산할 수 있다(즉, ). 이와 같은 모델에 의하면, 도 4의 단순화된 모델 에 비해 입의 상태를 세분화할 수 있고, 사용자의 발화 여부를 더 정확하게 유추할 수 있다. 도 6은 추출한 입 모양 모델에 기초하여 입의 종횡비 변화를 나타낸 그래프이다. 그래프에서, 5개의 피크 지점 은 실제 발화 상황이 발생한 시점을 나타낸다. 입 모양 인식부에서 입의 종횡비 변화를 잘 인식하고 있음을 확 인할 수 있다. 일 실시예에 따르면, 발화 상황 인식부는 입의 종횡비뿐만 아니라 입의 종횡비 변화 패턴에 기초하여 발화 여부 를 인식할 수 있다. 이는 발화 여부와 상관 없이 하품 등으로 사용자가 입을 벌리는 상황을 발화 상황으로 오인 식하는 것을 방지하기 위한 것이다. 따라서, 도 6의 그래프와 같이 입의 종횡비가 반복적으로 변화하는 패턴까 지 고려하여 발화 상황을 인식하도록 설정할 수 있다. 다시 도 2를 참조하면, 단계(S100, S200)와 동시에 혹은 순차적으로, 오디오 데이터를 획득하는 단계(S300) 및 상기 오디오 데이터에 기초하여 사용자의 음성을 인식하는 단계(S400)가 실행된다. 실제 오디오 인터페이스를 통해 입력되는 오디오 데이터에는, 사용자의 발화 음성뿐만 아니라 주변 환경 노이즈 도 포함되어 있기 때문에 사용자의 실제 음성이 감지되는지 여부에 기초하여 발화 상황을 인식하도록 한다. 또 한, 사람의 음성이 감지되더라도 TV소리, 전화소리 등 실제 발화와 무관한 음성을 필터링하기 위해 음성의 주체 가 사용자인지 여부를 판정하도록 한다. 도 7은 일 실시예에 따른 발화 상황 인식 방법에 있어서 사용자의 음성을 인식하는 세부적인 과정을 도시한다. 오디오 인터페이스부를 통해 입력 받은 오디오 데이터에는 사용자의 음성뿐만 아니라 다양한 배경음이 포함되어 있다. 일 실시예에 따르면, 이러한 오디오 데이터로부터 사람의 음성을 구분하여 추출할 수 있도록 학습된 기계 학습 모델을 이용하여 사용자의 발화된 음성을 인식할 수 있다. 단계(S410)에서는, 오디오 데이터를 소정의 구간으로 나누어 인식한다. 예컨대, 오디오 데이터를 0.5초 단위의 소리로 구분하여 상기 구간 내에 사용자의 음성이 포함되어 있는지 여부를 판정한다. 구간의 길이가 너무 짧거 나 너무 길면 음성 인식의 정확도가 감소하기 때문에 적절한 시간 구간으로 설정될 수 있다. 단계(S420)에서는, 오디오 데이터의 주파수 성분 분포를 파악한다. 구체적으로, 모델 학습 및 인식을 위한 배열 은 소리를 STFT(Short time Fourier transform) 진행한 결과로서 기준 시간에 소리를 구성하는 각 진동수 성분 의 분포를 확인할 수 있는 형태로 변환한 것이다. 단계(S430)에서는, 상기 주파수 성분 분포에 기초하여 상기 오디오 데이터가 사용자의 발화된 음성을 포함하는 지 여부를 판정한다. 전술한 바와 같이, 음성 인식 부는 오디오 데이터의 주파수 성분 분포로부터 사람의 음성 에 해당하는 성분을 다른 노이즈 성분과 구분하여 추출할 수 있도록 학습된다. 일 실험예에서, 약 1800개의 오 디오 데이터를 활용하여 모델을 학습시켰으며, 약 90.83%의 정확도로 오디오 데이터에서 사용자의 음성을 인식 할 수 있었다. 도 8은 일 실시예에 따른 음성 인식부에서 오디오 데이터의 노이즈를 제거한 결과를 나타낸 것이다. (a)는 모든 음성이 포함된 원본 오디오 데이터의 파형을 나타내고, (b)는 음성 인식부를 이용해 노이즈를 제거한 데이터의 파형을 나타낸다. 도 9는 서로 다른 상황들에 대한 음성 인식 결과를 나타낸 것이다. (a)는 손가락으로 책상을 문지를 때 나는 소 리의 파형을 나타내고, (b)는 주먹으로 책상을 내려칠 때 나는 소리의 파형을 나타내며, (c)는 아무런 상황도 발생하지 않았을 때 입력되는 노이즈의 파형을 나타낸다. 이와 같이, 음성 인식부는 오디오 데이터에 포함된 사 용자의 발화 음성과 그 외의 상황에 따른 노이즈를 구분할 수 있다. 일 실시예에 따르면, 상기 사용자의 입 움직임을 인식하는 단계 및 상기 사용자의 음성을 인식하는 단계는, 이 동 평균을 통해 입 움직임 인식 결과와 음성 인식 결과의 민감도를 조절하는 단계를 포함할 수 있다. 상태 민감 도가 높다는 것은 음성 인식 또는 입 움직임을 인식하는 역치가 낮음을 의미한다. 즉, 민감도가 높게 설정되면 사용자가 조금만 입을 움직이거나 발화가 아닌 소리(하품소리, 기침소리, 혼잣말 등)를 냈을 때도 발화 상황으 로 인식하게 된다. 반대로, 민감도가 낮게 설정되면 실제 발화 상황임에도 로봇이 발화 상황을 인식하지 못하는 문제가 생길 수 있다. 이러한 문제를 해결하기 위해, 입 움직임 인식 단계에 있어서 윈도우 크기(window size) 를 고려하여 상태 민감도 및 변화를 조절할 수 있다. 예컨대, 입의 종횡비가 반복적으로 변화할 때 각 종횡비 변화 값의 구간 평균을 계산하고 이를 기초로 발화 여부를 결정함으로써, 더 정확한 인식이 가능하다. 음성 인 식 단계에서도 같은 원리로 민감도를 조절할 수 있다. 다시 도 2를 참조하면, 사용자의 입 움직임 인식 결과 및 사용자의 음성 인식 결과에 기초하여 사용자가 발화 중인지 여부를 결정하는 단계(S500)가 실행된다. 기존의 음성 인식 시스템은 대부분 사람의 음성 감지 여부만을 고려하여 발화 상황을 인식하였으나, 이러한 방식은 사람이 많은 환경이나 시끄러운 야외 환경에서는 음성 인식 정확도가 떨어진다는 문제가 있었다. 본 발명의 실시예에 따르면, 음성 인식 결과뿐만 아니라 이미지 데이터에 기초한 사용자의 입 움직임 인식 결과 를 종합적으로 고려하여 발화 여부를 판정하므로, 사람이 많은 환경이나 시끄러운 야외 환경에서도 발화 상황을 정확하게 인식할 수 있다. 마지막으로, 발화 상황 인식 결과에 기초하여 로봇을 경청 모드로 전환하는 단계(S600)가 실행된다. 단계(S60 0)는 발화 상황 인식 시스템에 포함된 로봇 행동 제어부(도 1의 30)에 의해 수행될 수 있다. 구체적으로, 입 움 직임과 음성 인식 결과 사용자가 현재 발화 중인 것으로 결정되면, 로봇을 경청 모드로 전환하고, 이에 대응하 는 행동을 출력하도록 로봇을 제어한다. 경청 모드 전용 동작은 로봇의 음성, 제스처, 표정 또는 이들의 조합으 로 구성될 수 있으며, 예컨대, 현재 진행 중인 로봇의 활동을 일시 중지하고 발화 중인 사용자에게 접근하거나, 사람의 경청 행위를 모방한 제스처를 표현하는 등 사용자의 지시가 로봇에게 적절하게 전달되고 있음을 표현할 수 있다. 이처럼 경청 모드 매뉴얼에 해당하는 로봇 행동 표현을 통해 사용자에게 자연스러운 상호작용 경험을 제공하는 것이 가능하다. 실시예에 따른 로봇의 경청 모드 진입을 위한 발화 상황 인식 방법은, 애플리케이션으로 구현되거나 다양한 컴 퓨터 구성요소를 통하여 수행될 수 있는 프로그램 명령어의 형태로 구현되어 컴퓨터 판독 가능한 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체는 프로그램 명령어, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD- ROM, DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 ROM, RAM, 플래시 메모리 등과 같은 프로그램 명령어를 저장하고 수행하도록 특별히 구성된 하드웨 어 장치가 포함된다. 이상에서 설명한 발화 상황 인식 시스템 및 방법에 의하면, 주변 환경으로부터 획득한 이미지 데이터 및/또는 오디오 데이터에 기초하여 사용자가 발화 중인지 여부를 결정할 수 있고, 사용자가 발화 중인 것으로 인식하면, 로봇을 '경청 모드'로 전환하여 상황에 알맞은 행동들(예컨대, 적절한 표정, 제스처, 음성 등)을 출력함으로써 사용자에게 자연스러운 상호작용 경험을 제공할 수 있다. 이상에서는 실시예들을 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2025-0043543", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 발화 상황 인식 시스템의 구조를 나타낸 구성도이다. 도 2는 일 실시예에 따른 발화 상황 인식 방법의 단계들을 나타낸 순서도이다. 도 3은 일 실시예에 따른 발화 상황 인식 방법에 있어서 사용자의 입 움직임을 인식하는 과정을 구체적으로 나 타낸 순서도이다. 도 4는 사용자의 입 모양으로부터 입의 종횡비를 계산하기 위한 일 실시예에 모델을 도시한다. 도 5는 사용자의 입 모양으로부터 입의 종횡비를 계산하기 위한 또 다른 실시예에 모델을 도시한다. 도 6은 추출한 입 모양 모델에 기초하여 입의 종횡비 변화를 나타낸 그래프이다. 도 7은 일 실시예에 따른 발화 상황 인식 방법에 있어서 사용자의 음성을 인식하는 과정을 구체적으로 나타낸 순서도이다. 도 8은 일 실시예에 따른 음성 인식부에서 오디오 데이터의 노이즈를 제거한 결과를 나타낸 것이다. 도 9는 서로 다른 상황들에 대한 음성 인식 결과를 나타낸 것이다."}
