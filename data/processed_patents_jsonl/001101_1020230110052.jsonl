{"patent_id": "10-2023-0110052", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0028875", "출원번호": "10-2023-0110052", "발명의 명칭": "인공 신경망 모델을 실행하는 장치의 성능 및 전력 효율을 예측하는 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "김민제"}}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "벤치 마크 실행 결과를 획득하는 단계;예측 대상이 되는 인공 신경망 모델 및 분석 요구 정보를 포함하는 입력 데이터를 수신하는 단계;상기 인공 신경망 모델이 구동될 장치의 하드웨어 정보를 수신하는 단계;상기 벤치 마크 실행 결과 및 상기 하드웨어 정보에 기초하여, 예측 모델을 구축하는 단계;상기 인공 신경망 모델을 구성하는 복수의 레이어들 각각에 대응하는 레이어 정보를 추출하는 단계; 및상기 예측 모델에 상기 분석 요구 정보 및 상기 레이어 정보를 입력하여, 상기 복수의 레이어들 각각에 대응하는 연산 성능 정보 및 에너지 효율 정보 중 적어도 하나를 예측하는 단계를 포함하는 예측 방법."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 예측하는 단계는상기 복수의 레이어들 각각에 대응하는 상기 연산 성능 정보 및 상기 에너지 효율 정보를 상기 장치를 구성하는구성 요소 별로 예측하는 단계를 포함하는 예측 방법."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 예측하는 단계는상기 복수의 레이어들 별로 해당 레이어에서의 연산량과 메모리 접근량 사이의 가중치를 결정하는 단계; 및상기 가중치에 기초하여, 상기 복수의 레이어들 각각에 대응하는 상기 연산 성능 정보 및 상기 에너지 효율 정보를 예측하는 단계를 포함하는 예측 방법."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 예측하는 단계는상기 복수의 레이어들을 연산량 바운드 레이어 또는 메모리 바운드 레이어로 분류하는 단계; 및상기 분류 결과에 기초하여, 상기 복수의 레이어들 각각에 대응하는 상기 연산 성능 정보 및 상기 에너지 효율정보를 예측하는 단계공개특허 10-2025-0028875-3-를 포함하는 예측 방법."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 레이어 정보를 추출하는 단계는상기 복수의 레이어들 각각에 대응하는 입력 데이터 정보 및 출력 데이터 정보를 추출하는 단계를 포함하는, 예측 방법."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 벤치 마크 실행 결과를 획득하는 단계는사용자 설정 정보를 수신하는 단계상기 사용자 설정 정보에 기초하여, 벤치 마크를 생성하는 단계; 및상기 벤치 마크를 실행하여 상기 벤치 마크 실행 결과를 생성하는 단계를 포함하는, 예측 방법."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,사용자 설정 정보를 수신하는 단계는미리 정의된 동작 주파수 정보, 벤치 마크의 대상이 되는 인공 신경망 모델 정보 및 상기 장치를 구성하는 구성요소 정보를 수신하는 단계를 포함하는, 예측 방법."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 벤치 마크를 생성하는 단계는상기 벤치 마크의 대상이 되는 인공 신경망 모델을 구성하는 복수의 레이어들 별로 해당 레이어의 입력 데이터크기 및 동작 주파수에 기초하여 상기 벤치 마크를 생성하는 단계를 포함하는, 예측 방법."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 벤치 마크를 생성하는 단계는상기 장치를 구성하는 구성 요소에 대응하는 커널에 기초하여 상기 벤치 마크를 생성하는 단계공개특허 10-2025-0028875-4-를 포함하는, 예측 방법."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 벤치 마크 실행 결과를 생성하는 단계는응용 프로그램 인터페이스(API)에 기초하여, 상기 벤치 마크에 대응하는 연산 성능 및 에너지 효율을 제1 측정하는 단계;외부 장치를 이용하여, 상기 벤치 마크에 대응하는 연산 성능 및 에너지 효율을 제2 측정하는 단계; 및상기 제1 측정 결과와 상기 제2 측정 결과를 비교하여, 상기 벤치 마크 실행 결과에 대해 정합성 판단을 수행하는 단계를 포함하는, 예측 방법."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "하드웨어와 결합되어 제1항 내지 제10항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "벤치 마크 실행 결과를 획득하고,예측 대상이 되는 인공 신경망 모델 및 분석 요구 정보를 포함하는 입력 데이터를 수신하고,상기 인공 신경망 모델이 구동될 장치의 하드웨어 정보를 수신하고,상기 벤치 마크 실행 결과 및 상기 하드웨어 정보에 기초하여, 예측 모델을 구축하고,상기 인공 신경망 모델을 구성하는 복수의 레이어들 각각에 대응하는 레이어 정보를 추출하고,상기 예측 모델에 상기 분석 요구 정보 및 상기 레이어 정보를 입력하여, 상기 복수의 레이어들 각각에 대응하는 연산 성능 정보 및 에너지 효율 정보를 예측하는 프로세서를 포함하는 예측 장치."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 프로세서는상기 복수의 레이어들 각각에 대응하는 상기 연산 성능 정보 및 상기 에너지 효율 정보를 상기 장치를 구성하는구성 요소 별로 예측하는, 예측 장치."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 프로세서는상기 복수의 레이어들 별로 해당 레이어에서의 연산량과 메모리 접근량 사이의 가중치를 결정하고,공개특허 10-2025-0028875-5-상기 가중치에 기초하여, 상기 복수의 레이어들 각각에 대응하는 상기 연산 성능 정보 및 상기 에너지 효율 정보를 예측하는, 예측 장치."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 프로세서는상기 복수의 레이어들을 연산량 바운드 레이어 또는 메모리 바운드 레이어로 분류하고,상기 분류 결과에 기초하여, 상기 복수의 레이어들 각각에 대응하는 상기 연산 성능 정보 및 상기 에너지 효율정보를 예측하는, 예측 장치."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,상기 프로세서는상기 복수의 레이어들 각각에 대응하는 입력 데이터 정보 및 출력 데이터 정보를 추출하는, 예측 장치."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서,상기 프로세서는사용자 설정 정보를 수신하고,상기 사용자 설정 정보에 기초하여, 벤치 마크를 생성하고,상기 벤치 마크를 실행하여 상기 벤치 마크 실행 결과를 생성하는, 예측 장치."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 프로세서는미리 정의된 동작 주파수 정보, 벤치 마크의 대상이 되는 인공 신경망 모델 정보 및 상기 장치를 구성하는 구성요소 정보를 수신하는, 예측 장치."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 프로세서는상기 벤치 마크의 대상이 되는 인공 신경망 모델을 구성하는 복수의 레이어들 별로 해당 레이어의 입력 데이터크기 및 동작 주파수에 기초하여 상기 벤치 마크를 생성하는, 예측 장치."}
{"patent_id": "10-2023-0110052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에 있어서,공개특허 10-2025-0028875-6-상기 프로세서는성능 및 에너지 효율을 제1 측정하고,외부 장치를 이용하여, 상기 벤치 마크에 대응하는 연산 성능 및 에너지 효율을 제2 측정하고,상기 제1 측정 결과와 상기 제2 측정 결과를 비교하여, 상기 벤치 마크 실행 결과에 대해 정합성 판단을 수행하는, 예측 장치."}
{"patent_id": "10-2023-0110052", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "예측 방법 및 장치가 개시된다. 일 실시예에 따른 예측 방법은 벤치 마크 실행 결과를 획득하는 단계, 예측 대 상이 되는 인공 신경망 모델 및 분석 요구 정보를 포함하는 입력 데이터를 수신하는 단계, 인공 신경망 모델이 구동될 장치의 하드웨어 정보를 수신하는 단계, 벤치 마크 실행 결과 및 하드웨어 정보에 기초하여, 예측 모델을 구축하는 단계, 인공 신경망 모델을 구성하는 복수의 레이어들 각각에 대응하는 레이어 정보를 추출하는 단계; 및 예측 모델에 분석 요구 정보 및 레이어 정보를 입력하여, 복수의 레이어들 각각에 대응하는 연산 성능 정보 및 에너지 효율 정보를 예측하는 단계를 포함한다."}
{"patent_id": "10-2023-0110052", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래 실시예들은 인공 신경망 모델을 실행하는 장치의 성능 및 전력 효율을 예측하는 방법에 관한 것이다."}
{"patent_id": "10-2023-0110052", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥 러닝(deep learning)은 다중 처리 계층을 갖는 심화 그래프(deep graph)를 이용하여 입력 데이터에서 높은 레벨의 추상화를 모델링하려는 알고리즘 집합에 기초한 연산 아키텍처를 말한다. 일반적으로 딥 러닝 아키텍처 에는 다수의 뉴런 레이어과 파라미터들을 포함할 수 있다. 예를 들어, 딥 러닝 아키텍처 중 CNN(Convolutional Neural Network)은 이미지 분류, 이미지 캡션 생성, 시각적 질문 응답 및 자동 운전 차량과 같은, 많은 인공 지 능 및 머신 러닝 어플리케이션에서 널리 사용되고 있다. 이와 같은 뉴럴 네트워크 시스템은 예컨대 이미지의 분류를 위해 수많은 파라미터를 포함하고 수많은 연산을 필요로 하기 때문에 높은 복잡도를 가지며, 자원, 전력 등을 많이 소모한다. 이에 따라 뉴럴 네트워크 시스 템을 구현하기 위해서는 이들 연산을 효율적으로 연산하기 위한 방안이 요구되며, 특히 자원이 제한적으로 제공 되는 예컨대 모바일 환경에서는 연산 효율을 높이는 것의 중요성이 더욱 높다."}
{"patent_id": "10-2023-0110052", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 예측 방법은 벤치 마크 실행 결과를 획득하는 단계; 예측 대상이 되는 인공 신경망 모델 및 분석 요구 정보를 포함하는 입력 데이터를 수신하는 단계; 상기 인공 신경망 모델이 구동될 장치의 하드웨어 정 보를 수신하는 단계; 상기 벤치 마크 실행 결과 및 상기 하드웨어 정보에 기초하여, 예측 모델을 구축하는 단계; 상기 인공 신경망 모델을 구성하는 복수의 레이어들 각각에 대응하는 레이어 정보를 추출하는 단계; 및 상기 예측 모델에 상기 분석 요구 정보 및 상기 레이어 정보를 입력하여, 상기 복수의 레이어들 각각에 대응하 는 연산 성능 정보 및 에너지 효율 정보를 예측하는 단계를 포함할 수 있다. 상기 예측하는 단계는 상기 복수의 레이어들 각각에 대응하는 상기 연산 성능 정보 및 상기 에너지 효율 정보를 상기 장치를 구성하는 구성 요소 별로 예측하는 단계를 포함할 수 있다. 상기 예측하는 단계는 상기 복수의 레이어들 별로 해당 레이어에서의 연산량과 메모리 접근량 사이의 가중치를 결정하는 단계; 및 상기 가중치에 기초하여, 상기 복수의 레이어들 각각에 대응하는 상기 연산 성능 정보 및 상 기 에너지 효율 정보를 예측하는 단계를 포함할 수 있다. 상기 예측하는 단계는 상기 복수의 레이어들을 연산량 바운드 레이어 또는 메모리 바운드 레이어로 분류하는 단 계; 및상기 분류 결과에 기초하여, 상기 복수의 레이어들 각각에 대응하는 상기 연산 성능 정보 및 상기 에너지 효율 정보를 예측하는 단계를 포함할 수 있다. 상기 레이어 정보를 추출하는 단계는 상기 복수의 레이어들 각각에 대응하는 입력 데이터 정보 및 출력 데이터 정보를 추출하는 단계를 포함할 수 있다. 상기 벤치 마크 실행 결과를 획득하는 단계는 사용자 설정 정보를 수신하는 단계; 상기 사용자 설정 정보에 기 초하여, 벤치 마크를 생성하는 단계; 및 상기 벤치 마크를 실행하여 상기 벤치 마크 실행 결과를 생성하는 단계 를 포함할 수 있다. 사용자 설정 정보를 수신하는 단계는 미리 정의된 동작 주파수 정보, 벤치 마크의 대상이 되는 인공 신경망 모 델 정보 및 상기 장치를 구성하는 구성 요소 정보를 수신하는 단계를 포함할 수 있다. 상기 벤치 마크를 생성하는 단계는 상기 벤치 마크의 대상이 되는 인공 신경망 모델을 구성하는 복수의 레이어 들 별로 해당 레이어의 입력 데이터 크기 및 동작 주파수에 기초하여 상기 벤치 마크를 생성하는 단계를 포함할 수 있다. 상기 벤치 마크를 생성하는 단계는 상기 장치를 구성하는 구성 요소에 대응하는 커널에 기초하여 상기 벤치 마 크를 생성하는 단계를 포함할 수 있다. 상기 벤치 마크 실행 결과를 생성하는 단계는 응용 프로그램 인터페이스(API)에 기초하여, 상기 벤치 마크에 대 응하는 연산 성능 및 에너지 효율을 제1 측정하는 단계; 외부 장치를 이용하여, 상기 벤치 마크에 대응하는 연 산 성능 및 에너지 효율을 제2 측정하는 단계; 및 상기 제1 측정 결과와 상기 제2 측정 결과를 비교하여, 상기 벤치 마크 실행 결과에 대해 정합성 판단을 수행하는 단계를 포함할 수 있다. 일 실시예에 따른 예측 장치는 벤치 마크 실행 결과를 획득하고, 예측 대상이 되는 인공 신경망 모델 및 분석 요구 정보를 포함하는 입력 데이터를 수신하고, 상기 인공 신경망 모델이 구동될 장치의 하드웨어 정보를 수신 하고, 상기 벤치 마크 실행 결과 및 상기 하드웨어 정보에 기초하여, 예측 모델을 구축하고, 상기 인공 신경망 모델을 구성하는 복수의 레이어들 각각에 대응하는 레이어 정보를 추출하고, 상기 예측 모델에 상기 분석 요구 정보 및 상기 레이어 정보를 입력하여, 상기 복수의 레이어들 각각에 대응하는 연산 성능 정보 및 에너지 효율 정보를 예측하는 프로세서를 포함할 수 있다. 상기 프로세서는 상기 복수의 레이어들 각각에 대응하는 상기 연산 성능 정보 및 상기 에너지 효율 정보를 상기 장치를 구성하는 구성 요소 별로 예측할 수 있다. 상기 프로세서는 상기 복수의 레이어들 별로 해당 레이어에서의 연산량과 메모리 접근량 사이의 가중치를 결정 하고, 상기 가중치에 기초하여, 상기 복수의 레이어들 각각에 대응하는 상기 연산 성능 정보 및 상기 에너지 효 율 정보를 예측할 수 있다. 상기 프로세서는 상기 복수의 레이어들을 연산량 바운드 레이어 또는 메모리 바운드 레이어로 분류하고, 상기 분류 결과에 기초하여, 상기 복수의 레이어들 각각에 대응하는 상기 연산 성능 정보 및 상기 에너지 효율 정보 를 예측할 수 있다. 상기 프로세서는 상기 복수의 레이어들 각각에 대응하는 입력 데이터 정보 및 출력 데이터 정보를 추출할 수 있 다. 상기 프로세서는 사용자 설정 정보를 수신하고, 상기 사용자 설정 정보에 기초하여, 벤치 마크를 생성하고, 상 기 벤치 마크를 실행하여 상기 벤치 마크 실행 결과를 생성할 수 있다. 상기 프로세서는 미리 정의된 동작 주파수 정보, 벤치 마크의 대상이 되는 인공 신경망 모델 정보 및 상기 장치 를 구성하는 구성 요소 정보를 수신할 수 있다. 상기 프로세서는 상기 벤치 마크의 대상이 되는 인공 신경망 모델을 구성하는 복수의 레이어들 별로 해당 레이 어의 입력 데이터 크기 및 동작 주파수에 기초하여 상기 벤치 마크를 생성할 수 있다. 상기 프로세서는 성능 및 에너지 효율을 제1 측정하고, 외부 장치를 이용하여, 상기 벤치 마크에 대응하는 연산 성능 및 에너지 효율을 제2 측정하고, 상기 제1 측정 결과와 상기 제2 측정 결과를 비교하여, 상기 벤치 마크 실행 결과에 대해 정합성 판단을 수행할 수 있다."}
{"patent_id": "10-2023-0110052", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 개시되어 있는 특정한 구조적 또는 기능적 설명들은 단지 기술적 개념에 따른 실시예들을 설명하 기 위한 목적으로 예시된 것으로서, 실제로 구현된 형태는 다양한 다른 모습을 가질 수 있으며 본 명세서에 설 명된 실시예로만 한정되지 않는다. 제1 또는 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 이런 용어들은 하나의 구성요소 를 다른 구성요소로부터 구별하는 목적으로만 이해되어야 한다. 예를 들어 제1 구성요소는 제2 구성요소로 명명 될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관계를 설명하는 표현들, 예를 들어 \"~간의\"와 \"바로~간의\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 해당 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되 는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 실시예들은 퍼스널 컴퓨터, 랩톱 컴퓨터, 태블릿 컴퓨터, 스마트 폰, 텔레비전, 스마트 가전 기기, 지능형 자동 차, 키오스크, 웨어러블 장치 등 다양한 형태의 제품으로 구현될 수 있다. 이하, 실시예들을 첨부된 도면을 참 조하여 상세하게 설명한다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다. 도 1은 일 실시예에 따른 예측 장치의 개략적인 블록도를 나타낸다. 도 1을 참조하면, 예측 장치는 벤치마크 구동 장치, 뉴럴 네트워크 후킹 장치 및 전력/성능 예측 장치를 포함할 수 있다. 그러나 도시된 구성요소 모두가 필수구성요소인 것은 아니다. 도시된 구성요소보 다 많은 구성요소에 의해 예측 장치가 구현될 수도 있고, 그보다 적은 구성요소에 의해서도 예측 장치 는 구현될 수 있다. 예를 들어, 아래에서 도 2를 참조하여 설명하겠으나, 예측 장치는 사용자 프로그램, 주파수 제어 장치, 전력/성능 측정 장치 및 정합성 검증 장치를 더 포함할 수도 있다. 나아가, 예측 장치 는 벤치마크 구동 장치, 뉴럴 네트워크 후킹 장치 및 전력/성능 예측 장치 로 구별되는 것으로 도시되어 있으나, 실제로는 전체의 동작이 하나 이상의 프로세서에 의해 수행될 수 있다. 예측 장치는 연산 장치(예를 들어, 그래픽 프로세싱 유닛(GPU))가 인공 신경망 모델을 실행할 때, 해당 연 산 장치의 전력 효율과 성능을 예측할 수 있다. 아래에서, 인공 신경망 모델은 GPU에 의해 실행되는 것을 기준 으로 설명하나, 인공 신경망 모델은 GPU 이외에 다양한 연산 장치에 의해 실행될 수 있다. 인공 신경망 (artificial neural network, ANN) 모델은 신경망, 인공 신경망, 뉴럴 네트워크, 뉴럴 네트워크 모델, 딥 뉴럴네트워크(deep neural network, DNN) 등으로 지칭될 수 있다. 예측 장치는 GPU의 메모리 모듈과 연산 모듈 별 전력 효율과 성능에 대한 데이터를 수집할 수 있다. 인공 신경망 모델을 실행하기 위한 하드웨어 가속기의 스펙을 선정하고, 가속기를 설계 및 개발할 때 수집된 데이터 를 활용할 수 있다. 또한, 신규 뉴럴 네트워크 구조를 구성할 때, 수집된 레이어의 특성에 대한 데이터를 활용 해 높은 성능과 전력 효율을 달성할 수 있는 하드웨어 아키텍쳐를 확보할 수 있다. 나아가, 다수의 GPU로 가속하는 대규모 서버 시스템의 슈퍼 컴퓨터를 구성하거나, 별도의 가속 ASIC 칩 기반의 서버 시스템을 구성할 때, 예측 장치를 통해 획득한 데이터를 기반 데이터로 사용할 수 있다. 또한, 새로 운 설계방법으로 하드웨어 아키텍쳐를 탐색할 때, 예측 장치를 이용하여 전력 효율 및 성능 데이터를 수집 하거나 예측할 수 있다. 벤치마크 구동 장치, 뉴럴 네트워크 후킹 장치 및 전력/성능 예측 장치 의 동작 방법은 아래에서 도 2 내지 도 10를 참조하여 상세히 설명한다. 도 2는 일 실시예에 따른 예측 시스템의 개략적인 블록도를 나타낸다. 도 2를 참조하면, 일 실시예에 따른 예측 시스템은 중앙 처리 장치(CPU), 메인 메모리, 그래픽 처리 장치, 시스템 파워 측정 장치, 인터페이스 모듈 및 예측 장치를 포함할 수 있다. 도 1을 참조하여 설명한 내용은 도 2에 동일하게 적용될 수 있다. 예를 들어, 도 1을 참조하여 설명한 예측 장치 는 도 2의 예측 장치에 동일하게 적용될 수 있다. 중앙 처리 장치는 뉴럴 네트워크 모델이 구동할 수 있도록 전반적인 동작을 제어한다. 중앙 처리 장치 는 하나의 프로세서 코어를 포함하거나, 복수의 프로세서 코어들을 포함할 수 있다. 중앙 처리 장치(21 0)는 메인 메모리에 저장 된 프로그램들을 실행할 수 있다. 그래픽 처리 장치, 시스템 파워 측정 장 치, 인터페이스 모듈 및 예측 장치를 제어할 수 있다. 또한, 중앙 처리 장치는 그래픽 처 리 장치와 같이 뉴럴 네트워크 모델의 일부 연산을 수행할 수 있다. 나아가, 도 2에서는 예측 장치가 CPU와 구분되는 하나의 하드웨어인 것으로 도시되어 있으나, 실시예 에 따라서는 예측 장치는 중앙 처리 장치에 포함될 수 있다. 예를 들어, 예측 장치를 통해 수 행되는 동작은 소프트웨어 프로그램 형태로 구현될 수 있고, 해당 소프트웨어 프로그램은 메인 메모리에 저장된 후, 중앙 처리 장치에서 메인 메모리에 저장된 소프트웨어 프로그램을 실행할 수 있다. 메인 메모리는 GPU 전력효율 측정과 성능 예측 장치를 제어하기 위한 명령들(Instructions) 또는 GPU 전력 효율 측정과 성능 예측 장치의 입력 데이터와 출력 데이터를 저장할 수 있다. 메인 메모리는 DRAM(Dynamic RAM) 또는 SRAM(Static RAM) 등의 메모리로 구현할 수 있다. 그래픽 처리 장치는 다양한 그래픽 연산을 수행할 수 있다. 그래픽 처리 장치는 유사한 연산을 반복 해서 처리하는 병렬 연산에 유리한 구조를 가지고 있다. 그래서, 그래픽 처리 장치는 그래픽 연산 뿐만 아니라 뉴럴 네트워크 모델의 연산 중 대규모의 행렬 곱셈과 덧셈 연산을 효율적으로 연산할 수 있다. 그래픽 처리 장치는 하나 또는 다수의 코어로 구성할 수 도 있다. 또한, 내부에 메모리를 포함하고 있어서 데이터 이동을 최소화하도록 구성될 수도 있다. 시스템 파워 측정 장치는 시스템 전체의 소모 전력을 측정할 수 있는 장치이다. 시스템 파워 측정 장치 는 소모 전류, 실시간 전압, 실시간 전력, 누적 전력을 측정할 수 있다. 시스템 파워 측정 장치는 측정한 결과값을 예측 장치로 보내거나 메인 메모리에 저장할 수 있다. 인터페이스 모듈은 뉴럴 네트워크 시스템과 외부 호스트 시스템과의 통신 기능을 수행한다. 인터페이스 모듈을 통해 메인 메모리에 접근하여 데이터를 읽거나 쓸 수 있도록 한다. 예를 들어, 시스템 내부 의 인터커넥터를 통해 데이터 버스, 어드레스 버스, 컨트롤 버스 등의 시스템 버스를 사용할 수 있도록 인터페 이스를 제공할 수도 있다. 예측 장치는 하나 또는 다수의 사용자 프로그램, 뉴럴 네트워크 후킹 장치, 벤치마크 구동 장치 , 주파수 제어 장치, 전력/성능 측정 장치 및 정합성 검증 장치 및 전력/성능 예측 장치 를 포함할 수도 있다. 그러나 전술한 바와 같이, 도시된 구성요소 모두가 필수구성요소인 것은 아니다. 도시된 구성요소보다 많은 구성요소에 의해 예측 장치가 구현될 수도 있고, 그보다 적은 구성요소에 의해 서도 예측 장치는 구현될 수 있다. 사용자 프로그램은 사용자 설정 정보, 뉴럴 네트워크 프로그램, 벤치마크 프로그램을 포함하는 장치이다. 사용자 설정 정보는 뉴럴 네트워크 프로그램을 실행시키는 뉴럴 네트워크 모델에 대한 메타 파라미터, 모델 구동을 위한 설정 파라미터, 벤치마크 프로그램을 구동하기 위한 프로파일 파라미터 등 GPU 전력효율 측정과 성능 예측 장치를 구동하기 위한 설정 데이터를 포함할 수 있다. 뉴럴 네트워크 프로그램은 CNN, RNN, LSTM 등 다양 한 뉴럴 네트워크 모델을 학습시키고, 추론하는 프로그램이다. 뉴럴 네트워크 모델 학습 시에는 포워드 패스 (forward pass) 및 백워드 패스(backward pass)가 모두 실행되고 추론 시에는 포워드 패스가 실행된다. 벤치마 크 프로그램은 GPU의 하드웨어 구성요소별 소모 전력이나 성능을 수집하기 위한 특정 단위의 벤치마크 커널들과 커널들을 실행시키는 프로그램이다. 뉴럴 네트워크 후킹 장치는 사용자로부터 주어진 뉴럴 네트워크 모델에서 모델을 구성하는 각 레이어의 특 성을 추출하여 저장하는 장치이다. 레이어 특성에는 입출력 텐서의 크기, 자료형, 각종 파라미터들 및 포워드 패스 및 백워드 패스 정보가 있을 수 있다. 뉴럴 네트워크 프레임워크에서 제공하는 모델 레이어 뿐만 아니라, 사용자가 직접 설계한 뉴럴 네트워크 레이어 또한 후킹 정보를 표시하여 레이어 특성 정보를 추출할 수 있다. 뉴럴 네트워크 후킹 장치의 동작 방법은 아래에서 도 7을 참조하여 보다 상세히 설명한다. 벤치마크 구동 장치는 GPU 하드웨어 구성요소별 사용자의 요구사항을 반영한 벤치마크를 생성하고, 벤치마 크 프로그램을 실행하고, 실행 결과를 저장하는 장치이다. 벤치마크 구동 장치는 뉴럴 네트워크를 구성하 는 복수의 레이어들 별 벤치마크를 생성하고 수집할 수 있다. 또한, 벤치마크 구동 장치는 연산 기능 중 심의 벤치마크, 메모리 입출력 기능 중심의 벤치마크, 연산과 메모리 기능이 혼재되어 있는 기능의 벤치마크와 같이 유연하고 다양한 벤치마크를 생성하고 수집할 수 있다. 예를 들어, GPU의 연산 기능을 하는 하드웨어 구 성요소는 SM(Streaming Multiprocessor), FP(Floating Point)16 FU(Functional Unit), FP32 FU, FP64 FU, Special FU, 텐서 코어(Tensor Core)이 있을 수 있으며, 메모리 입출력 기능을 하는 하드웨어 구성요소는 공유 메모리(Shared Memory), L1 cache, L2 cache, 글로벌 메모리(Global Memory)가 있을 수 있다. 각각의 하드웨 어 구성요소에 스트레스(Stress)를 발생시키는 커널을 동작 시켜서 벤치마크 결과를 수집할 수 있다. 이때 하 드웨어 구성요소의 유틸라이제이션(utilization)을 여러 단계로 세팅하여 정확도를 높일 수 있다. 예를 들어 25%, 50%, 75%, 100%의 네 단계로 구분하여 하드웨어 구성요소의 벤치마크 결과의 정확도를 통계적으로 향상시 킬 수 있다. 벤치마크 구동 장치의 동작 방법은 아래에서 도 4 내지 도 5b를 참조하여 보다 상세히 설명 한다. 주파수 제어 장치는 사용자의 설정 정보 대로 GPU의 주파수를 고정하거나 주파수별 비교가 가능하도록 제 어하는 장치이다. GPU 주파수는 코어 클락 주파수(Core Clock Frequency)와 메모리 클락 주파수(Memory Clock Frequency)가 있을 수 있다. GPU별 코어 클락 주파수 별로 GPU 전압값이 변경되는 구간이 다르기 때문에, 주파 수 제어 장치는 GPU 주파수를 변경하여 최적의 전성비를 가지는 조건을 찾아낼 수 있다. 또한 GPU별 메모 리 클락 주파수가 코어 클락 주파수에 따라 정해져 있는 경우도 있고, 주파수 제어 장치는 별도의 메모리 클락 주파수를 사용할 수 있는지도 확인할 수 있다. 전력/성능 측정 장치는 벤치마크와 사용자 설정 정보에 따라 GPU의 소모 전력과 성능을 측정하는 장치이다. GPU는 GPU 제조사에서 GPU구동 방식을 프로그램으로 제어할 수 있도록 응용 프로그래밍 인터페이스 (Application Programming Interface)를 제공한다. 예를 들어, NVIDIA사의 경우, NVIDIA Management Library (NVML)을 제공하여 GPU의 전력, 온도, 성능 등을 측정 및 설정하는 기능을 제공하고 있다. 전력/성능 측정 장 치는 이를 활용하여, 벤치마크의 특정 시점에서 GPU가 소모하는 전력을 측정할 수 있거나, 특정 시간 간격 동안 GPU의 총 소모 전력과 평균 전력을 계산할 수도 있다. 정합성 검증 장치는 전력/성능 측정 장치에서 측정한 결과값이 정상값인지 이상값인지 확인하는 장치 이다. 전력/성능 측정 장치의 측정한 결과값의 정합성을 확인하기 위해, 정합성 검증 장치는 전력/성 능 측정 장치에서 측정한 결과값을 시스템 파워 측정 장치에서 측정한 결과값을 비교하여 전력/성능 측정 장치에서 측정한 결과값이 정상값인지 이상값인지 확인할 수 있다. 만약 값의 차이와 추세가 이상현 상이 발생했을 시, 정합성 검증 장치는 사용자 프로그램, 뉴럴 네트워크 후킹 장치, 벤치마크 구동 장치, 주파수 제어 장치를 점검하고, 전력/성능 측정 장치를 재 구동하여 이상 원인을 찾 아낼 수도 있다. 전력/성능 예측 장치는 전력/성능 측정 장치에서 측정한 결과값과 GPU 하드웨어 정보를 사용하여, 새 롭게 주어지는 사용자 요구사항(분석 요구 정보)에 대한 전력/성능의 결과를 예측하는 장치이다. 전력/성능 예 측 장치는 전력/성능 측정 장치의 측정한 결과값과 GPU 하드웨어 정보를 기반으로 예측 모델을 구축 할 수 있고, 이 예측 모델을 통해 예측값을 계산할 수 있다. 또한 뉴럴 네트워크 후킹 장치에서 학습과 추론에 따라 포워드 패스 및 백워드 패스의 특성 정보를 추출하기에, 전력/성능 예측 장치는 학습과 추론모두에서 전력/성능을 예측할 수 있다. 뉴럴 네트워크 모델의 같은 레이어일지라도 학습 또는 추론 수행에 따 라 성능이 다를 수 있는데 예를 들어, 드롭아웃(Dropout) 연산의 경우 추론 시 아무런 연산이 수행되지 않는다. 전력/성능 예측 장치의 동작 방법은 아래에서 도 8 내지 도 10을 참조하여 보다 상세히 설명한다. 도 3은 일 실시예에 따른 뉴럴 네트워크 프로그램을 GPU로 실행할 때, GPU 전력/성능 예측 모델을 구축하고 GPU 전력/성능 예측을 수행하는 동작의 흐름도를 도시한 도면이다. 도 3을 참조하면, 단계들(310 내지 390)은 도 2에 도시된 예측 시스템을 사용하여 수행되는 것으로 기술된다. 그러나 이 단계들(310 내지 390)은 어떤 다른 적절한 전자 기기를 통해, 그리고 어떤 적절한 시스템 내에서도 사용될 수 있을 것이다. 나아가, 도 3의 동작은 도시된 순서 및 방식으로 수행될 수 있지만, 도시된 실시예의 사상 및 범위를 벗어나지 않으면서 일부 동작의 순서가 변경되거나 일부 동작이 생략될 수 있다. 도 3에 도시된 다수의 동작은 병렬로 또는 동시에 수행될 수 있다. 보다 구체적으로, 예측 시스템의 GPU 전력/성능 예측 동작은 크게 1)GPU 전력/성능 예측을 위한 예측 모델을 구 축하는 단계(이하에서, 예측 모델 구축 단계로 지칭될 수 있다)와 2)구축된 예측 모델을 이용하여 예측 대상이 되는 인공 신경망 모델을 구성하는 복수의 레이어들 각각에 대응하는 연산 성능 정보 및 에너지 효율 정보를 예 측하는 단계(이하에서, 예측 단계로 지칭될 수 있다)로 구성될 수 있다. 단계들(310 내지 360)은 예측 모델 구 축 단계에 관한 것이고, 단계들(370 내지 390)은 예측 단계에 관한 것일 수 있다. 단계에서, 벤치마크 구동 장치(예: 도 2의 벤치마크 구동 장치)는 사용자 설정 정보를 받고 벤치마크 를 생성할 수 있다. 사용자 설정 정보는 미리 정의된 동작 주파수 정보, 벤치 마크의 대상이 되는 인공 신경망 모델 정보 및 장치를 구성하는 구성 요소 정보를 포함할 수 있다. 단계에서, 주파수 제어 장치(예: 도 2의 주파수 제어 장치)는 사용자가 설정한 정보로 코어 클락 주 파수와 메모리 클락 주파수를 설정할 수 있다. 벤치마크 구동 장치(예: 도 2의 벤치마크 구동 장치)는 설 정된 주파수에 따라 벤치마크를 실행할 수 있다. 단계에서, 실행된 벤치마크에 대한 소모 전력과 성능은 전력/성능 측정 장치(예: 도 2의 전력/성능 측정 장치)와 시스템 파워 측정 장치를 통해 측정될 수 있다. 단계에서, 정합성 검증 장치(예: 도 2의 정합성 검증 장치는 시스템 파워 측정 장치(예: 도 2의 시스 템 파워 측정 장치)에서 측정된 결과값과 전력/성능 측정 장치에서 측정된 결과값의 비교를 통해 정합성을 판단할 수 있다. 두 측정값 비교 결과, 전력/성능 측정 장치의 측정 결과값에 이상이 있다고 판단될 경우, 단계에서, 정합 성 검증 장치는 사용자 설정정보, 뉴럴 네트워크 후킹 장치, 벤치마크 구동 장치, 주파수 제어 장치, 전력/성능 측정 장치 등을 점검할 수 있다. 이후, 예측 시스템은 다시 단계으로 돌아가, 벤치마크를 다시 실행해 소 모 전력과 성능을 측정하고, 전력/성능 측정 결과값에 이상이 없을 경우, 단계에서, 벤치마크 실행 결과로 부터 전력/성능 예측 모델들을 구축할 수 있다. 전력/성능 예측 모델이 구축되면, 전력/성능 예측 장치(예: 도 2의 전력/성능 예측 장치)는 예측을 원하는 뉴럴 네트워크 프로그램에 대해, 뉴럴 네트워크 프로그램이 실행되는 연산 장치(예: GPU)의 전력/성능 예측을 수행할 수 있다. 단계에서, 예측을 원하는 뉴럴 네트워크 프로그램이 실행되면, 뉴럴 네트워크 후킹 장치(예: 도 2의 뉴럴 네트워크 후킹 장치)를 통해 뉴럴 네트워크 모델을 구성하는 레이어별 정보가 추출될 수 있다. 단계에서, 전력/성능 예측 장치에 의해 각 레이어별로 전력/성능 예측 모델이 선택된다. 단계에서, 전력/성능 예측 장치는 전력/성능 예측 모델을 통해 레이어별 예측값을 계산하고, 레이어별 예 측값을 모두 합쳐 모델 전체의 예측값을 계산할 수 있다. 추가적인 예측이 필요할 경우, 예측 시스템은 뉴럴 네트워크 프로그램을 다시 실행하고 모델 전체의 예측값을 계산할 수 있다. 도 4는 일 실시예에 따른 벤치마크 구동 장치의 동작을 설명하기 위한 도면이다. 도 4를 참조하면, 일 실시예에 따른 벤치마크 구동 장치(예: 도 2의 벤치마크 구동 장치)는 벤치마크 생성 동작, 벤치마크 실행 동작 및 벤치마크 결과 저장 동작을 수행할 수 있다.벤치 마크 생성 동작에서, 벤치마크 구동 장치는 레이어 벤치마크와 GPU 벤치마크를 생성할 수 있다. 보다 구체적으로, 벤치마크 구동 장치는 사전에 정의된 동작 주파수와 네트워크 입력 정보를 입력으로 받아 인 공 신경망 모델의 레이어에 대한 레이어 벤치마크를 생성할 수 있다. 레이어 벤치마크는 라이브러리에서 제공 하는 인공 신경망 모델에 대한 레이어 벤치마크(예를 들어, PyTorch DNN Layer Benchmarks)와 사용자가 정의한 DNN 레이어 벤치마크( User-defined DNN Layer Benchmark)를 포함할 수 있다. 또한, 벤치마크 구동 장치는 사전에 정의된 동작 주파수를 입력으로 받아 SM, 텐서코어를 포함하는 연산 관련 구성요소와 공유 메모리, L1 cache를 포함하는 메모리 관련 구성요소에 관한 연산장치 벤치마크(이하에서, 설명 의 편의를 위해 GPU 벤치마크 또는 GPU 마이크로 벤치마크(microbenchmark)로 지칭될 수 있다)를 생성할 수 있 다. 도 5a는 일 실시예에 따른 벤치마크 구동 장치에서 생성된 벤치마크의 예시를 도시한 도면이다. 도 5a를 참조하면, 레이어 벤치마크는 레이어에 대해 동작 주파수별, 입력 크기별 조합으로 생성된 레이어 벤치마크일 수 있다. 벤치마크의 동작 주파수는 (500Mhz, 800Mhz, 1100Mhz, 1400Mhz) 중 하나일 수 있고, (N, M, K)는 입력 데이터의 차원을 의미할 수 있다. 레이어 벤치마크는 뉴럴 네트워크를 구성하는 다양 한 레이어들(예를 들어, Add 레이어, Baddbmm 레이어, Bmm레이어, Crossentropy 레이어, Linear 레이어, Matmul 레이어, Dropout 레이어, Embedding 레이어, Gelu 레이어)을 대상으로 생성될 수 있다. GPU 벤치마크는 GPU 구성요소별 CUDA 커널(kernel)을 활용하여 생성 가능하다. 예를 들어, GPU 벤치마크 를 참조하면, 벤치마크 구동 장치는 총 16개의 GPU 커널로 SM 개수, 벤치마크의 총연산량을 조정해 가면서, GPU 벤치마크 커널을 생성할 수 있다. 다시 도 4를 참조하면, 벤치마크 실행 동작에서, 벤치마크 구동 장치는 생성된 벤치마크를 실행하여 실행 된 벤치마크에 대한 소모 전력과 성능을 획득할 수 있다. 예를 들어, 벤치마크 구동 장치는 생성된 벤치마크를 실행할 수 있고, 전력/성능 측정 장치(예: 도 2의 전력/성 능 측정 장치)는 실행된 벤치마크에 대한 GPU 오퍼레이션 카운트(Operation Count)와 GPU 소모 에너지를 측정할 수 있고, 측정 결과를 벤치마크 구동 장치로 전달할 수 있다. 벤치마크 결과 저장 동작에서, 벤치 마크 구동 장치는 측정된 결과를 저장할 수 있다. 예를 들어, 저장되는 벤치마크 측정 결과는 레이어 성능 데 이터베이스, 레이어 오퍼레이션 카운트 데이터베이스 및 소모 전력 데이터베이스를 포함할 수 있다. 도 5b 내지 도 5c는 일 실시예에 따른 벤치마크에 대한 소모 전력과 성능을 측정하는 예시를 도시한 도면이다. 도 5b를 참조하면, 전력/성능 측정 장치는 CUPTI을 활용하여 GPU 오퍼레이션 카운트를 측정할 수 있다. GPU 구 성요소별 오퍼레이션 카운트에 해당하는 GPU 커널에 측정 코드를 랩핑시켜 측정할 수 있다. 측정된 성능 은 벤치마크 결과로 저장될 수 있다. 도 5c를 참조하면, 전력/성능 측정 장치는 GPU 소모 에너지를 측정할 수 있다. 예를 들어, 전력/성능 측정 장 치는 NVNV를 이용해 NVIDIA사 GPU의 소모 에너지를 측정할 수 있다. NVML 은 NVIDIA GPU의 전력, 온도, 성능 등을 측정하고, GPU의 클락 주파수 등을 제어하는 기능을 제공한다. 전력/성능 측정 장치는 이를 이용해 사용 자 설정 정보에 맞추어 GPU를 제어하고 벤치마크 프로그램이 실행되는 동안 GPU의 전력/성능을 측정할 수 있다. 벤치마크 프로그램이 실행되기 직전, 주어진 사용자 설정 정보에 맞추어 주파수 제어 장치의 제어값에 따라 GPU의 클락 주파수 등이 설정된다. 전력/성능 측정 장치는 전력 측정을 위한 전력 측정 스레드를 생성하고 실 행시킬 수 있다. 예를 들면, 전력 측정 스레드는 50ms 간격으로 NVML라이브러리의 전력 측정 API를 호출해 현 재 GPU의 소모 전력을 측정해 기록할 수 있다. 전력/성능 측정 장치는 벤치마크 프로그램을 실행하기 직전의 시점(timestamp, t_s)을 측정해 기록할 수 있다. 전력/성능 측정 장치는 벤치마크 프로그램을 충분한 시간 동안 실행시킨 뒤, 벤치마크 프로그램이 종료되면 전 력 측정 스레드 또한 종료 시킨다. 전력/성능 측정 장치는 벤치마크 프로그램이 종료된 직후의 시점 (timestamp, t_e)을 측정하고, 벤치마크 프로그램을 실행하기 직전에 측정한 값과 비교해 벤치마크 실행에 얼마 나 오랜 시간이 걸렸는지 계산할 수 있다. 전력/성능 측정 장치는 벤치마크 프로그램의 실행 시간과 벤치마크 프로그램의 총 연산량을 통해 GPU의 성능을 다양한 방법으로 계산할 수 있다. 또한, 벤치마크 프로그램의 실행 전후 시점 정보와 전력 측정 스레드가 기록 한 GPU의 전력 소모 데이터를 이용해 벤치마크 프로그램이 실행되는 동안 GPU에서 소모한 총 전력을 다양한 방법으로 계산할 수도 있다. 예를 들면 측정시간 간격을 잘게 나누어 전체 연산량이나 총 소모 전력을 극한값으 로 구하는 구분구적법을 사용할 수도 있다. 측정된 소모 전력은 벤치마크 결과로 저장될 수 있다. 도 6은 일 실시예에 따른 정합성 검증 방법을 설명하기 위한 흐름도를 도시한 도면이다. 도 6을 참조하면, 단계들(610 내지 660)은 도 2의 예측 장치를 사용하여 수행되는 것으로 기술된다. 그러 나 이 단계들(610 내지 660)은 어떤 다른 적절한 전자 기기를 통해, 그리고 어떤 적절한 시스템 내에서도 사용 될 수 있을 것이다. 나아가, 도 6의 동작은 도시된 순서 및 방식으로 수행될 수 있지만, 도시된 실시예의 사상 및 범위를 벗어나지 않으면서 일부 동작의 순서가 변경되거나 일부 동작이 생략될 수 있다. 도 6에 도시된 다수의 동작은 병렬로 또는 동시에 수행될 수 있다. 정합성 검증 장치(예: 도 2의 정합성 검증 장치)는 전력/성능 측정 장치(예: 도 2의 전력/성능 측정 장치 )에서 측정한 결과값이 정상값인지 이상값인지 확인하는 장치이다. 정합성 검증 장치는 전력 전력/성능 측정 장치에서 측정한 GPU의 소모 전력값에 이상이 있는지 검증하고, 만약 값의 차이와 추세가 이상이 있다면, 사용자 설정정보, 뉴럴 네트워크 후킹 장치, 벤치마크 구동 장치, 주파수 제어 장치 등을 점검해 이상 원인을 파악할 수 있다. 단계에서, 예측 장치는 냉각 팬, 외부 디스크 등의 장치를 일정한 속도로 사용하도록 컴퓨터 시스템을 설 정할 수 있다. 컴퓨터 시스템 전체의 소모 전력에는 GPU뿐만 아니라 CPU, 냉각 팬, 메인보드 등 다양한 장치의 소모 전력이 포함됨으로 정합성 검증을 할 때, 이러한 요소들을 통제하는 것이 중요할 수 있다. 벤치마크 프로 그램을 실행하기 전 냉각 팬 등의 장치는 고정된 속도로 작동하도록 설정하고, 벤치마크 프로그램이 실행되는 도중에 CPU나 하드 디스크 등을 사용하는 다른 프로그램이 실행되지 않도록 주의해야 한다. 단계에서, 예측 장치는 전력/성능 측정 장치가 측정한 GPU의 소모 전력값을 검증하기 위해 해당 GPU가 장 착된 컴퓨터 시스템 전체의 소모 전력값을 별도로 측정한다. 시스템 전체의 소모 전력은 시스템 파워 측정 장 치(예: 도 2의 시스템 파워 측정 장치)를 통해 측정할 수 있다. 시스템 파워 측정 장치는 HIOKI 3334 power meter 등과 같은 전력 소모 측정 장비를 활용할 수 도 있다. 단계에서, 예측 장치는 벤치마크 프로그램을 실행하고, 단계에서, 전력/성능 측정 장치의 GPU의 소모 전력 측정과 시스템 파워 측정 장치의 컴퓨터 시스템 전체의 소모 전력 측정을 종료할 수 있다. 단계에서, 정합성 검증 장치는 벤치마크 프로그램을 실행하는 시간(time span)에 대해 GPU의 전력 소모 추 세와 컴퓨터 시스템 전체의 전력 소모 추세가 크게 차이가 난다면 GPU의 전력/성능 측정 장치에 이상이 발생했 다고 판단할 수 있다. 벤치마크 프로그램이 실행되는 동안 GPU의 전력 소모 증가량보다 컴퓨터 시스템 전체의 전력 소모 증가량이 월등히 높다면 GPU의 전력/성능 측정 장치를 점검할 필요가 있다. 예를 들면, GPU를 사용하지 않을 때 시스템 전체의 소모 전력량을 라 하고, GPU를 최대 강도로 사용했을 때 시스템 전체의 소모 전력량을 라 하자. GPU를 최대 강도로 사용함으로써 시스템 전체의 소모 전력량은 만큼 증가했다고 할 수 있다. 만약 GPU를 절반의 강도(50% utilization) 사용하는 경우 시스템 전체의 소모 전력량이 만큼 증가하는 것을 기대할 수 있다. 만약 이와 크게 다른 수치만큼 시스템 전체의 전력 소모량이 변화했다면, 정합성 검증 장치는 GPU의 전력/성능 측정 장치를 점검할 필요가 있다고 판단할 수 있다. 즉, GPU를 사용하는 강도가 라면 시스템 전체의 전력 소모량은 만큼 증가하는 것을 기대할 수 있고, 정합성 검증 장치는 이 값을 기준으로 GPU의 전력/성능 측정 장치의 이상을 감지할 수 있다. 도 7은 일 실시예에 따른 뉴럴 네트워크 후킹 장치의 동작을 설명하기 위한 도면이다. 도 7을 참조하면, 사용자의 뉴럴 네트워크 프로그램이 실행되면 뉴럴 네트워크 후킹 장치(예: 도 2의 뉴럴 네트 워크 후킹 장치)는 후킹 모듈과 정보 추출 모듈을 통해 원하는 뉴럴 네트워크 레이어 정보를 추출할 수 있다. 뉴럴 네트워크 후킹 장치는 뉴럴 네트워크 후킹 장치는 사전에 정의된 함수 리스트 또는 사용자 가 추가한 별도의 프로그램을 통해 뉴럴 네트워크 레이어의 입출력 정보를 후킹할 수 있다. 추출된 레이어별 입출력 정보는 자동으로 예측 모델의 입력으로 들어가며 전체 네트워크의 성능 및 에너지 소모량이 예측될 수 있다. 보다 구체적으로, 뉴럴 네트워크 프로그램은 사용자 프로그램에 포함되어 있으며, PyTorch 등의 뉴럴 네트워크 라이브러리를 이용해 구현될 수 있다. 뉴럴 네트워크 후킹 장치에 뉴럴 네트워크 프로그램 코드를 연결하여 실 행시키는 것으로 사용자가 뉴럴 네트워크 프로그램의 변경을 최소화하면서 원하는 레이어 정보들을 추출하는 후 킹 모듈을 뉴럴 네트워크 프로그램에 추가할 수 있다. 후킹 모듈은 사용자의 뉴럴 네트워크 프로그램이 실행되는 동안 뉴럴 네트워크 모델을 구성하는 레이어들 의 목록을 생성하는 모듈이다. 예를 들어, 뉴럴 네트워크 프로그램이 PyTorch 에서 제공하는 뉴럴 네트워크 레 이어들로 구성되어 있다면, 후킹 모듈은 PyTorch 에서 제공하는 레이어 API들을 바꿔치기해 PyTorch의 코 드가 실행되기 직전에 후킹 모듈을 한번 거쳐가도록 할 수 있다. 뉴럴 네트워크 프로그램의 컨트롤 플로우(control flow)가 후킹 모듈을 거쳐가는 동안 후킹 모듈은 어떤 뉴럴 네트워크 레이어들이 어떤 입출력에 대해 실행되는지 목록을 수집하고 구성할 수 있다. 레이어 목록 구성에 필요한 정보를 추출한 이후에는 뉴럴 네트워크 프로그램의 컨트롤 플로우를 다시 PyTorch 로 넘겨주어 이후의 뉴럴 네트워크 프로그램이 정상적으로 작동될 수 있도록 한다. 정보 추출 모듈은 뉴럴 네트워크 모델을 구성하는 레이어 목록으로부터 필요한 정보를 추출하는 모듈이다. 정보의 종류는 레이어 종류, 레이어별 입출력 텐서의 크기, 각종 파라미터, 자료형, 포워드 패스, 백워드 패스 정보 등이 있을 수 있다. 정보 추출 모듈은 동일한 연산을 수행하는 레이어들을 하나로 묶어 같은 레이어로 취급할 수도 있다. 이를 통해, 전력/성능 측정 장치에서 레이어별 성능 및 전력을 측정하는 데 필요한 시간을 절약할 수 있다. 도 8은 일 실시예에 따른 전력/성능 예측 장치의 동작을 설명하기 위한 도면이다. 도 8을 참조하면, 전력/성능 예측 장치(예: 도 2의 전력/성능 예측 장치)는 전력/성능 측정 장치의 측정한 결과값과 GPU HW 정보를 기반으로 새롭게 주어지는 사용자 요구사항에 대한 전력/성능의 결과를 예측하는 장치 이다. 전력/성능 예측 장치는 구축된 예측 모델을 바탕으로 학습과 추론에 따라 뉴럴 네트워크 프로그램의 소모 전력 및 성능을 예측 할 수 있다. 뉴럴 네트워크 모델을 구성하는 레이어들의 정보를 뉴럴 네트워크 후킹 장치(예: 도 2의 뉴럴 네트워크 후킹 장치)를 통해 추출하고 난 뒤에, 전력/성능 예측 장치는 각 레이어들의 GPU소 모 전력 및 소요 시간을 예측 모델을 바탕으로 예측할 수 있다. 전력/성능 예측 장치는 레이어 별 예측치들을 모두 더해 뉴럴 네트워크 모델 전체의 GPU 소모 전력 및 소요 시간을 예측할 수 있다. 전력/성능 예측 장치는 예측 모델을 구성하기 위해 레이어 벤치마크와 GPU 벤치마크를 실행한 결과를 사용할 수 있다. 벤치마크를 실행하는 동안 전력/성능 측정 장치를 통해 GPU의 소모 전력과 성능을 측정할 수 있다. 전력/성능 예측 장치는 측정 결과 값을 예측 모델의 파라미터들로 사용할 수 있다. 예측 모델은 성능 예측 모델과 전력 소모 예측 모델로 구성될 수 있다. 뉴럴 네트워크 레이어의 소요 시간을 예측하는 성능 모델은 다음과 같이 구성할 수 있다. 먼저, 전력/성능 예측 장치는 뉴럴 네트워크를 구성하는 복수의 레이어들 각각을 메모리 접근량에 비해 연산량이 상대적으로 적은 메모리 바운드 레이어(memory-bound layer) 또는, 메모리 접근량에 비해 연산량이 많은 연산 바운드 레이어(compute-bound layer)로 구분할 수 있다. 연산 바운드 레이어의 소요 시간은 수학식 1과 같은 수식으로 예측할 수 있다. 수학식 1 수학식 1에서, 은 뉴럴 네트워크 레이어, 는 GPU의 연산 모듈, 는 해당 레이어에서 각 연산 모듈의 필요 연산량, 는 해당 레이어의 연산 모듈 활용 효율(efficiency), 는 GPU 스펙 중 이론적 최고 성능의 동작 주파수를 의미한다. 는 추출된 레이어 정보로부터 계산이 가능하고, 는 뉴럴 네트워크 레이어 벤치마 크 실행 결과로부터 계산이 가능하고, 는 GPU의 스펙과 GPU 실행 환경으로부터 계산이 가능할 수 있다. 메모리 바운드 레이어의 소요 시간은 수학식 2와 같은 수식으로 예측할 수 있다. 수학식 2"}
{"patent_id": "10-2023-0110052", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 2에서, 은 뉴럴 네트워크 레이어, 는 각각 해당 레이어의 메모리 읽기/쓰기 바이트 수, 은 해당 레이어의 메모리 활용 효율(efficiency), 는 GPU 메모리 대역폭(bandwidth)을 의미한다. 는 추출 된 레이어 정보로부터 계산이 가능하고, 은 뉴럴 네트워크 레이어 벤치마크 실행 결과로부터 계산이 가능하 고, 는 GPU의 스펙과 GPU실행 환경으로부터 계산이 가능할 수 있다. 연산 바운드 레이어 및 메모리 바운드 레이어의 전력 소모는 수학식 3과 같은 수식을 통해 예측할 수 있다. 수학식 3"}
{"patent_id": "10-2023-0110052", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 3에서, 은 뉴럴 네트워크 레이어, 는 GPU 구성요소 인덱스, 는 GPU의 static(idle) 상태의 소 모 에너지, 는 GPU 구성 요소별 연산 당 소모 에너지를 의미한다. 및 는 GPU연산 기능을 하는 HW 구성요소별 전력/성능 벤치마크 실행 결과에서 얻을 수 있는 값일 수 있다. 전력/성능 예측 장치 전력/성능 측정 장치의 측정한 결과값과 GPU HW 정보를 기초하여, 수학식 1 내지 3을 계산 할 수 있고, 수학식 1 내지 3에 기초하여 예측 모델을 구성할 수 있다. 이후, 전력/성능 측정 장치는 구축된 예측 모델을 이용하여, 새롭게 입력되는 인공 신경망 모델의 전력과 성능을 예측할 수 있다. 도 9는 일 실시예에 따른 인공 신경망 모델의 소모 전력을 예측하는 방법의 예시를 도시한 도면이다. 일 실시예에 따른 전력/성능 예측 장치는 구축된 예측 모델과, 네트워크 후킹 장치를 통해 획득한 레이어 정보 를 예측 모델에 입력하여, 상기 복수의 레이어들 각각에 대응하는 연산 성능 정보 및 에너지 효율 정보를 예측할 수 있다. 도 9를 참조하면, 전력/성능 예측 장치는 동작 주파수 정보(예: 1250Mhz), 분석의 대상이 되는 레이어의 크기 (예: (8192, 3072, 3072)를 획득할 수 있고, 벤치마크 결과로 생성된 데이터를 이용하여 수학식 3 계산에 필요 한 값들을 획득할 수 있다. 이 때, 전력/성능 예측 장치는 벤치마크 결과로 생성된 데이터에 동작 주파수 정보 및 레이어의 크기에 대응하는 값이 없을 경우, 보간 등의 방법을 이용하여 필요한 값들을 추정할 수 있다. 전력/성능 예측 장치는 해당 레이어가 컴퓨트 바운드인지, 메모리 바운드인지 판단하고, 메모리 바운드라는 판 단에 기초하여 연산을 통해 메모리 바운드 레이어의 소모 전력을 예측할 수 있다. 도 10은 일 실시예에 따른 최적 동작 주파수를 결정하는 방법을 설명하기 위한 도면이다. 도 10을 참조하면, 일 실시예에 따른 예측 시스템은 뉴럴 네트워크 모델을 측정 및 예측한 결과로 목표 성능과 제약조건에 맞는 GPU의 최적 동작주파수를 찾을 수 있다. 예를 들어, 뉴럴 네트워크 모델은 GPT-3 Medium (Batch Size 16) 모델일 수 있고, 목표 성능 정보는 목표 성능, 목표 전력 소모, EDP(Energy-Delay Product) 정보를 포함할 수 있고, 제약조건은 최대 GPU 클락 주파수, 최소 GPU 클락 주파수, 포워드/백워드 반복당 시간 제한을 포함할 수 있다. 그래프는 측정된 포워드/백워드 연산 소요 시간과 예측 시스템을 통해 예측한 포워드/백워드 연산 소요 시간을 후보 주파수 별로 도시한 그래프이고, 그래프는 측정된 포워드/백워드 연산 소모 에너지와 예측 시스템을 통해 예측한 포워드/백워드 연산 소모 에너지를 후보 주파수 별로 도시한 그래프이다. 그래프들 (1010, 1020)을 참조하면, 측정된 데이터와 예측된 데이터의 차이가 크지 않음을 알 수 있다. 표를 참조하면, 예측 시스템은 1095Mhz를 목표 전력 소모에 맞는 GPU 최적 동작주파수로 결정할 수 있고, 1110Mhz를 목표 성능에 맞는 GPU 최적 동작 주파수로 결정할 수 있다. 도 11은 일 실시예에 따른 예측 방법을 설명하기 위한 순서도이다. 도 11을 참조하면, 단계들(1110 내지 1160)은 도 2에 도시된 예측 시스템을 사용하여 수행되는 것으로 기술된다. 그러나 이 단계들(1110 내지 1160)은 어떤 다른 적절한 전자 기기를 통해, 그리고 어떤 적절한 시스 템 내에서도 사용될 수 있을 것이다. 나아가, 도 11의 동작은 도시된 순서 및 방식으로 수행될 수 있지만, 도시된 실시예의 사상 및 범위를 벗어나지 않으면서 일부 동작의 순서가 변경되거나 일부 동작이 생략될 수 있다. 도 3에 도시된 다수의 동작은 병렬로 또는 동시에 수행될 수 있다. 단계에서, 예측 시스템은 벤치 마크 실행 결과를 획득할 수 있다. 예측 시스템은 사용자 설정 정보를 수 신하고, 사용자 설정 정보에 기초하여, 벤치 마크를 생성하고, 벤치 마크를 실행하여 벤치 마크 실행 결과를 생 성할 수 있다. 예측 시스템은 미리 정의된 동작 주파수 정보, 벤치 마크의 대상이 되는 인공 신경망 모델 정보 및 장치를 구성 하는 구성 요소 정보를 수신할 수 있다. 예측 시스템은 벤치 마크의 대상이 되는 인공 신경망 모델을 구성하는 복수의 레이어들 별로 해당 레이어의 입력 데이터 크기 및 동작 주파수에 기초하여 벤치 마크를 생성할 수 있다. 예측 시스템은 장치를 구성하는 구성 요소에 대응하는 커널에 기초하여 벤치 마크를 생성할 수 있다. 예측 시스템은 응용 프로그램 인터페이스(API)에 기초하여, 벤치 마크에 대응하는 연산 성능 및 에너지 효율을 제1 측정하고, 외부 장치를 이용하여, 벤치 마크에 대응하는 연산 성능 및 에너지 효율을 제2 측정하고, 제1 측 정 결과와 제2 측정 결과를 비교하여, 벤치 마크 실행 결과에 대해 정합성 판단을 수행할 수 있다. 단계에서, 예측 시스템은 예측 대상이 되는 인공 신경망 모델 및 분석 요구 정보를 포함하는 입력 데이터 를 수신할 수 있다. 단계에서, 예측 시스템은 인공 신경망 모델이 구동될 장치의 하드웨어 정보를 수신할 수 있다. 단계에서, 예측 시스템은 벤치 마크 실행 결과 및 하드웨어 정보에 기초하여, 예측 모델을 구축할 수 있 다.단계에서, 예측 시스템은 인공 신경망 모델을 구성하는 복수의 레이어들 각각에 대응하는 레이어 정보를 추출할 수 있다. 예측 시스템은 복수의 레이어들 각각에 대응하는 입력 데이터 정보 및 출력 데이터 정보를 추 출할 수 있다. 단계에서, 예측 시스템은 예측 모델에 분석 요구 정보 및 레이어 정보를 입력하여, 복수의 레이어들 각각 에 대응하는 연산 성능 정보 및 에너지 효율 정보 중 적어도 하나를 예측할 수 있다. 예측 시스템은 복수의 레이어들 각각에 대응하는 연산 성능 정보 및 에너지 효율 정보를 장치를 구성하는 구성 요소 별로 예측할 수 있다. 예측 시스템은 복수의 레이어들 별로 해당 레이어에서의 연산량과 메모리 접근량 사이의 가중치를 결정할 수 있 고, 가중치에 기초하여, 복수의 레이어들 각각에 대응하는 연산 성능 정보 및 에너지 효율 정보를 예측할 수 있 다. 예측 시스템은 복수의 레이어들을 연산량 바운드 레이어 또는 메모리 바운드 레이어로 분류하고, 분류 결과에 기초하여, 복수의 레이어들 각각에 대응하는 연산 성능 정보 및 에너지 효율 정보를 예측할 수 있다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리 케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처 리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2023-0110052", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하 나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들의 조합을 포함 할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로(collectively) 처 리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2023-0110052", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5a 도면5b 도면5c 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2023-0110052", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 예측 장치의 개략적인 블록도를 나타낸다. 도 2는 일 실시예에 따른 예측 시스템의 개략적인 블록도를 나타낸다. 도 3은 일 실시예에 따른 뉴럴 네트워크 프로그램을 GPU로 실행할 때, GPU 전력/성능 예측 모델을 구축하고 GPU 전력/성능 예측을 수행하는 동작의 흐름도를 도시한 도면이다. 도 4는 일 실시예에 따른 벤치마크 구동 장치의 동작을 설명하기 위한 도면이다. 도 5a는 일 실시예에 따른 벤치마크 구동 장치에서 생성된 벤치마크의 예시를 도시한 도면이다.도 5b 내지 도 5c는 일 실시예에 따른 벤치마크에 대한 소모 전력과 성능을 측정하는 예시를 도시한 도면이다. 도 6은 일 실시예에 따른 정합성 검증 방법을 설명하기 위한 흐름도를 도시한 도면이다. 도 7은 일 실시예에 따른 뉴럴 네트워크 후킹 장치의 동작을 설명하기 위한 도면이다. 도 8은 일 실시예에 따른 전력/성능 예측 장치의 동작을 설명하기 위한 도면이다. 도 9는 일 실시예에 따른 인공 신경망 모델의 소모 전력을 예측하는 방법의 예시를 도시한 도면이다. 도 10은 일 실시예에 따른 최적 동작 주파수를 결정하는 방법을 설명하기 위한 도면이다. 도 11은 일 실시예에 따른 예측 방법을 설명하기 위한 순서도이다."}
