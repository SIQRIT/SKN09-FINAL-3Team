{"patent_id": "10-2019-0109157", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0027991", "출원번호": "10-2019-0109157", "발명의 명칭": "전자장치 및 그 제어방법", "출원인": "삼성전자주식회사", "발명자": "최찬희"}}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자장치에 있어서,사용자의 음성을 수신하고,상기 수신되는 음성을 인식 가능한 복수의 음성인식기로부터 상기 음성의 복수의 인식결과를 각각 획득하고,상기 복수의 인식결과 중에서 상기 음성에 대한 인식 적합도가 높은 인식결과에 따른 동작을 수행하는 프로세서를 포함하는 전자장치."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 수신되는 음성은 기 등록된 혼동 단어를 포함하고,상기 프로세서는, 상기 복수의 음성인식기 중에서 상기 혼동 단어를 포함하는 인식결과를 상기 인식 적합도가높다고 식별하는 전자장치."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는, 복수의 혼동 단어를 포함하는 리스트에 기초하여 상기 혼동 단어를 포함하는 인식결과를 식별하는 전자장치."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 리스트에 포함된 상기 복수의 혼동 단어는, 기 등록된 사전에 포함되지 않는 단어, 고유명사, 또는 이전의인식결과에서 인식이 실패한 단어 중 적어도 하나를 포함하는 전자장치."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 프로세서는, 상기 수신되는 음성에 대한 인식이 수행되는 상황에 기초하여 상기 인식 적합도가 높은 음성인식기를 식별하고, 상기 식별된 음성인식기로부터 인식결과를 획득하는 전자장치."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 수신되는 음성은 상기 전자장치가 컨텐트 또는 서비스를 제공하는 중에 수신되고,상기 프로세서는, 상기 복수의 인식결과 중에서 상기 제공되는 컨텐트 또는 서비스와 관련된 인식결과를 상기인식 적합도가 높다고 식별하는 전자장치."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 프로세서는, 상기 복수의 인식결과 중에서 상기 발화를 한 사용자와 관련된 인식결과를 상기 인식 적합도가 높다고 식별하는 전자장치."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2021-0027991-3-제1항에 있어서,상기 프로세서는, 상기 복수의 인식결과 중에서 상기 전자장치와 접속 가능한 외부장치와 관련된 인식결과를 상기 인식 적합도가 높다고 식별하는 전자장치."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 복수의 음성인식기를 각기 구비한 복수의 서버와 통신하는 통신부를 더 포함하며,상기 프로세서는, 상기 복수의 음성인식기 중에서 상기 인식 적합도가 높은 음성인식기에 대해, 나머지 음성인식기보다 상기 발화 오디오를 먼저 전달하는 전자장치."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "전자장치의 제어방법에 있어서,사용자의 음성을 수신하는 단계와,상기 수신되는 음성을 인식 가능한 복수의 음성인식기로부터 상기 음성의 복수의 인식결과를 각각 획득하는 단계와;상기 복수의 인식결과 중에서 상기 음성에 대한 인식 적합도가 높은 인식결과에 따른 동작을 수행하는 단계를포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 수신되는 음성은 기 등록된 혼동 단어를 포함하고,상기 복수의 음성인식기 중에서 상기 혼동 단어를 포함하는 인식결과를 상기 인식 적합도가 높다고 식별하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,복수의 혼동 단어를 포함하는 리스트에 기초하여 상기 혼동 단어를 포함하는 인식결과를 식별하는 전자장치의제어방법."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 리스트에 포함된 상기 복수의 혼동 단어는, 기 등록된 사전에 포함되지 않는 단어, 고유명사, 또는 이전의인식결과에서 인식이 실패한 단어 중 적어도 하나를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서,상기 수신되는 음성에 대한 인식이 수행되는 상황에 기초하여 상기 인식 적합도가 높은 음성인식기를 식별하고,상기 식별된 음성인식기로부터 인식결과를 획득하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,상기 수신되는 음성은 상기 전자장치가 컨텐트 또는 서비스를 제공하는 중에 수신되고,상기 복수의 인식결과 중에서 상기 제공되는 컨텐트 또는 서비스와 관련된 인식결과를 상기 인식 적합도가 높다고 식별하는 전자장치의 제어방법.공개특허 10-2021-0027991-4-청구항 16 제10항에 있어서,상기 복수의 인식결과 중에서 상기 발화를 한 사용자와 관련된 인식결과를 상기 인식 적합도가 높다고 식별하는전자장치의 제어방법."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,상기 복수의 인식결과 중에서 상기 전자장치와 접속 가능한 외부장치와 관련된 인식결과를 상기 인식 적합도가높다고 식별하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0109157", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항에 있어서,상기 복수의 음성인식기는 복수의 서버에 각기 구비되며,상기 복수의 음성인식기 중에서 상기 인식 적합도가 높은 음성인식기에 대해, 나머지 음성인식기보다 상기 발화오디오를 먼저 전달하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0109157", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자장치는, 사용자의 음성을 수신하고, 상기 수신되는 음성을 인식 가능한 복수의 음성인식기로부터 음성의 복 수의 인식결과를 각각 획득하고, 복수의 인식결과 중에서 음성에 대한 인식 적합도가 높은 인식결과에 따른 동작 을 수행하는 프로세서를 포함한다."}
{"patent_id": "10-2019-0109157", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사용자의 발화에 대한 음성인식결과를 획득하여 대응 동작을 실행할 수 있는 전자장치 및 그 제어방 법에 관한 것으로서, 상세하게는 사용자 발화의 음성신호를 변환시킨 텍스트 데이터의 정확도에 관련된 전자장 치 및 그 제어방법에 관한 것이다."}
{"patent_id": "10-2019-0109157", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "소정의 정보를 특정 프로세스에 따라서 연산 및 처리하기 위해, 연산을 위한 CPU, 칩셋, 메모리 등의 전자부품 들을 기본적으로 포함하는 전자장치는, 처리 대상이 되는 정보 또는 사용 용도가 무엇인지에 따라서 다양한 종 류로 구분될 수 있다. 예를 들면, 전자장치에는 범용의 정보를 처리하는 PC나 서버 등의 정보처리장치, 영상데 이터를 처리하는 영상처리장치, 오디오를 처리하는 오디오장치, 가정 내 잡무를 수행하는 생활가전 등이 있다. 영상처리장치는 처리된 영상데이터를 자체 구비한 디스플레이 패널(display panel) 상에 영상으로 표시하는 디 스플레이장치로 구현될 수 있다. 전자장치는 사용자 입력을 수신하고, 수신된 사용자 입력에 대응하는 커맨드의 지시에 따라서 사전에 지정된 동 작을 수행한다. 사용자 입력의 방식은 인터페이스의 종류에 따라서 다양하다. 예를 들면, 전자장치는 버튼 또는 리모트 컨트롤러로부터 사용자 조작에 따른 제어신호를 수신하거나, 카메라를 통해 사용자의 제스처를 감지하거 나, 카메라를 통해 아이트랙킹(eye-tracking)을 하거나, 마이크로폰을 통해 사용자의 발화에 따른 음성신호를 수신할 수 있다. 특히, 전자장치는 사용자 발화의 음성인식처리 결과에 따른 커맨드를 획득하고, 획득한 커맨드 가 지시하는 동작을 수행할 수 있다. 음성인식처리는 사용자 발화에 따른 음성신호를 프로세서가 해석 가능한 텍스트 데이터로 변환시키는 프로세스 를 포함하며, 이러한 프로세스를 STT(Speech-to-Text)라고 지칭한다. STT 프로세스를 수행하기 위한 하드웨어/ 소프트웨어 컴포넌트는 음성인식기 또는 음성인식엔진이라고 지칭한다. 음성인식엔진은 다양한 모델링 기술에 의해 구현될 수 있다. 예를 들면, HMM(Hidden Markov Model) 등의 알고리즘에 따라서, 다양한 화자들이 발성한 음성이 통계적으로 모델링되어 음향 모델이 구현되고, 말뭉치(언어 연구를 위하여 컴퓨터가 텍스트를 가공, 처 리, 분석할 수 있는 형태로 모아 놓은 자료의 집합) 수집을 통해 언어 모델이 구현된다. 이러한 모델들에 의해 음성인식엔진이 형성된다. 음성인식엔진은 전자장치에 구비될 수도 있고, 전자장치가 통신 가능한 서버에 구비될 수도 있다. 그런데, 어떠 한 화자의 데이터 및 말뭉치를 사용하여 음성인식엔진이 모델링되었는지에 따라서, 또는 음성인식엔진을 제작하 여 제공하는 제조사들의 관심에 따라서, 음성인식엔진의 모델링 시에 고려되는 패러미터는 상이할 수 있다. 그결과, 소정 음성인식엔진이 제공하는 음성인식결과는 사용자의 발화 의도와 정확하게 맞지 않을 수도 있다. 이러한 관점에서, 전자장치는 사용자의 발화가 입력될 때, 가능한 한 사용자의 발화 의도에 맞는 음성인식결과 를 도출하는 것이 중요하다."}
{"patent_id": "10-2019-0109157", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 전자장치는, 사용자의 음성을 수신하고, 상기 수신되는 음성을 인식 가능한 복수의 음 성인식기로부터 상기 음성의 복수의 인식결과를 각각 획득하고, 상기 복수의 인식결과 중에서 상기 음성에 대한 인식 적합도가 높은 인식결과에 따른 동작을 수행하는 프로세서를 포함한다. 또한, 상기 수신되는 음성은 기 등록된 혼동 단어를 포함하고, 상기 프로세서는, 상기 복수의 음성인식기 중에 서 상기 혼동 단어를 포함하는 인식결과를 상기 인식 적합도가 높다고 식별할 수 있다. 또한, 상기 프로세서는, 복수의 혼동 단어를 포함하는 리스트에 기초하여 상기 혼동 단어를 포함하는 인식결과 를 식별할 수 있다. 또한, 상기 리스트에 포함된 상기 복수의 혼동 단어는, 기 등록된 사전에 포함되지 않는 단어, 고유명사, 또는 이전의 인식결과에서 인식이 실패한 단어 중 적어도 하나를 포함할 수 있다. 또한, 상기 프로세서는, 상기 수신되는 음성에 대한 인식이 수행되는 상황에 기초하여 상기 인식 적합도가 높은 음성인식기를 식별하고, 상기 식별된 음성인식기로부터 인식결과를 획득할 수 있다. 또한, 상기 수신되는 음성은 상기 전자장치가 컨텐트 또는 서비스를 제공하는 중에 수신되고, 상기 프로세서는, 상기 복수의 인식결과 중에서 상기 제공되는 컨텐트 또는 서비스와 관련된 인식결과를 상기 인식 적합도가 높다 고 식별할 수 있다. 또한, 상기 프로세서는, 상기 복수의 인식결과 중에서 상기 발화를 한 사용자와 관련된 인식결과를 상기 인식 적합도가 높다고 식별할 수 있다. 또한, 상기 프로세서는, 상기 복수의 인식결과 중에서 상기 전자장치와 접속 가능한 외부장치와 관련된 인식결 과를 상기 인식 적합도가 높다고 식별할 수 있다. 또한, 상기 복수의 음성인식기를 각기 구비한 복수의 서버와 통신하는 통신부를 더 포함하며, 상기 프로세서는, 상기 복수의 음성인식기 중에서 상기 인식 적합도가 높은 음성인식기에 대해, 나머지 음성인식기보다 상기 발화 오디오를 먼저 전달할 수 있다. 또한, 본 발명의 실시예에 따른 전자장치의 제어방법은, 사용자의 음성을 수신하는 단계와, 상기 수신되는 음성 을 인식 가능한 복수의 음성인식기로부터 상기 음성의 복수의 인식결과를 각각 획득하는 단계와; 상기 복수의 인식결과 중에서 상기 음성에 대한 인식 적합도가 높은 인식결과에 따른 동작을 수행하는 단계를 포함한다."}
{"patent_id": "10-2019-0109157", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부도면을 참조하여 본 발명에 따른 실시예들에 관해 상세히 설명한다. 각 도면을 참조하여 설명하 는 실시예들은 특별한 언급이 없는 한 상호 배타적인 구성이 아니며, 하나의 장치 내에서 복수 개의 실시예가"}
{"patent_id": "10-2019-0109157", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "선택적으로 조합되어 구현될 수 있다. 이러한 복수의 실시예의 조합은 본 발명의 기술분야에서 숙련된 기술자가 본 발명의 사상을 구현함에 있어서 임의로 선택되어 적용될 수 있다. 만일, 실시예에서 제1구성요소, 제2구성요소 등과 같이 서수를 포함하는 용어가 있다면, 이러한 용어는 다양한 구성요소들을 설명하기 위해 사용되는 것이며, 용어는 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사 용되는 바, 이들 구성요소는 용어에 의해 그 의미가 한정되지 않는다. 실시예에서 사용하는 용어는 해당 실시예 를 설명하기 위해 적용되는 것으로서, 본 발명의 사상을 한정하지 않는다. 또한, 본 명세서에서의 복수의 구성요소 중 \"적어도 하나(at least one)\"라는 표현이 나오는 경우에, 본 표현은 복수의 구성요소 전체 뿐만 아니라, 복수의 구성요소 중 나머지를 배제한 각 하나 혹은 이들의 조합 모두를 지 칭한다. 도 1은 전자장치가 사용자 발화의 음성인식결과를 획득하는 환경을 나타내는 예시도이다. 도 1에 도시된 바와 같이, 본 발명의 실시예에 따른 전자장치는 영상을 표시 가능한 디스플레이장치로 구 현된다. 전자장치는 TV, 컴퓨터, 태블릿, 휴대용 미디어 플레이어, 웨어러블 디바이스, 비디오 월, 전자액 자 등을 포함한다. 다만, 실제로 전자장치는 디스플레이장치 뿐만 아니라, 디스플레이를 구비하지 않은 셋 탑박스 등의 영상처리장치이거나, 냉장고, 세탁기 등의 생활가전이거나, 컴퓨터본체와 같은 정보처리장치 등 다 양한 종류의 장치로 구현될 수 있다. 또한, 전자장치는 하나의 고정된 위치에 설치되어 사용되는 장치일 수 있고, 사용자가 휴대하고 이동하면서 사용이 가능한 모바일기기일 수도 있다. 전자장치는 사용자의 음성을 수신할 수 있다. 즉, 전자장치는 사용자가 발화하면, 발화에 따른 음성 신호를 획득한다. 발화에 따른 음성신호를 획득하기 위하여, 전자장치는 발화를 수집하는 마이크로폰을 구 비하거나, 또는 마이크로폰을 가진 리모트 컨트롤러 또는 별도의 외부장치로부터 음성신호를 수신할 수도 있다. 전자장치는 획득한 사용자 발화의 음성신호에 대한 음성인식처리의 결과를 획득하고, 음성인식결과에 대응 하는 커맨드에 따른 동작을 수행한다. 여기서, 음성인식처리는 음성신호를 텍스트 데이터로 변환하는 STT 처리 과정과, 텍스트 데이터가 나타내는 커맨드를 식별하여, 식별된 커맨드가 지시하는 동작을 수행하는 커맨드 식별 및 수행 과정을 포함한다. 예를 들어, 사용자가 \"볼륨을 높여\"라고 발화하면, 전자장치는 발화의 음성신호 가 음성인식처리되도록 하여 텍스트 데이터를 획득하고, 이 획득한 텍스트 데이터가 나타내는 커맨드가 식별되 도록 하고, 식별된 커맨드에 따라서 전자장치의 볼륨을 높인다. 음성인식처리의 STT 처리 과정 및 커맨드 식별 및 수행 과정은, 전자장치에서 모두 실행될 수도 있다. 그 러나, 이 경우에 전자장치에 필요한 시스템 부하 및 소요 저장용량이 상대적으로 커지게 되므로, 적어도 일부의 과정은 네트워크를 통해 전자장치와 통신 가능하게 접속되는 서버(110, 120, 130)에 의해 수행될수 있다. 예를 들면, 서버(110, 120, 130)가 STT 처리 과정을 수행하고 전자장치가 커맨드 식별 및 수행 과정을 수행할 수 있다. 또는, 서버(110, 120, 130)가 STT 처리 과정 및 커맨드 식별 및 수행 과정을 모두 수행 하고, 전자장치는 단지 서버(110, 120, 130)로부터 결과를 수신하기만 할 수도 있다. 본 실시예에서는 서 버(110, 120, 130)가 STT 처리 과정을 수행하고 전자장치가 커맨드 식별 및 수행 과정을 수행하는 경우를 중심으로 설명하지만, 각 과정은 설계 가능한 음성인식 처리 환경 하에서 전자장치 또는 서버(110, 120, 130)에서 한정되지 않고 수행될 수 있다. STT 처리 과정을 수행하기 위해서는 해당 과정을 실질적으로 수행하는 음성인식엔진이 구축되어야 한다. 본 실 시예의 경우에 각 서버(110, 120, 130)는 개별적으로 음성인식엔진을 구비한다. 음성인식엔진은 개발자, 제조사, 모델 개발에 사용된 화자 데이터 및 말뭉치 데이터 등에 의해 고유한 특성을 가질 수 있다. 이러한 특 성에 따라서, 동일한 음성신호에 대해 각 음성인식엔진이 출력하는 음성인식결과는 상이할 수도 있다. 전자장치는 복수의 서버(110, 120, 130)로부터 사용자 발화의 음성신호의 인식결과를 각각 수신한다. 전자 장치는 복수의 서버(110, 120, 130)로부터 각각 수신한 복수의 인식결과 중에서 발화 음성신호에 대한 인 식 적합도가 상대적으로 높은 인식결과를 식별한다. 예를 들어, 전자장치는 음성신호를 복수의 서버(110, 120, 130)에 각기 전송한다. 각 서버(110, 120, 130)는 음성신호를 수신하면, 각자 구비한 음성인식엔진을 사용하여 인식결과를 도출하고, 도출된 인식결과를 전자장치에 전송한다. 전자장치는 복수의 서버(110, 120, 130)로부터 각기 획득한 복수의 인식결과 중에서 발화 음성신호에 대한 인식 적합도가 상대적으로 높은 인식결과를 선택한다. 이로써, 전자장치는 가능한 한 사용자의 발화 의도에 맞는 음성인식결과를 도출할 수 있다. 전자장치(10 0)가 발화 음성신호에 대한 인식 적합도를 식별하는 구체적인 방법에 관해서는 후술한다. 이하, 전자장치의 구성에 관해 설명한다. 도 2는 전자장치의 구성 블록도이다. 도 2에 도시된 바와 같이, 전자장치은 통신부와, 신호입출력부와, 디스플레이부와, 사용자 입력부와, 저장부와, 마이크로폰과, 프로세서를 포함한다. 서버는 서버통신부와, 서버저장부와, 서버프로세서를 포함한다. 본 실시예에서는 하나의 서버만 나타내고 있지만, 실제로는 전자장치는 복수의 서버에 통신 접속된다. 이하, 전자장치의 구성에 관해 설명한다. 본 실시예서는 전자장치가 TV인 경우에 관해 설명하지만, 전자장치는 다양한 종류의 장치로 구현될 수 있으므로, 본 실시예가 전자장치의 구성을 한정하는 것 은 아니다. 전자장치가 디스플레이장치로 구현되지 않는 경우도 가능하며, 이 경우의 전자장치는 디 스플레이부와 같은 영상 표시를 위한 구성요소들을 포함하지 않을 수 있다. 예를 들면 전자장치가 셋 탑박스로 구현되는 경우에, 전자장치는 신호입출력부를 통해 외부의 TV에 영상신호를 출력할 수 있다. 통신부는 다양한 종류의 유선 및 무선 통신 프로토콜에 대응하는 통신모듈, 통신칩 등의 구성요소들 중 적 어도 하나 이상을 포함하는 양방향 통신회로이다. 예를 들면, 통신부는 와이파이 방식에 따라서 AP와 무선 통신을 수행하는 무선통신모듈이나, 블루투스 등과 같은 1대 1 다이렉트 무선통신을 수행하는 무선통신모듈이나, 라우터 또는 게이트웨이에 유선 접속된 랜카드로 구현될 수 있다. 통신부는 네트워크 상의 서버와 통신함으로써, 서버와의 사이에 데이터 패킷을 송수신할 수 있다. 또는, 통신부는 전자장치의 본체와 분리된 리모트 컨트롤러와 통신함으로써, 리모트 컨트롤러로부터 전송되는 제어신호를 수신할 수 있다. 신호입출력부는 셋탑박스 또는 광학미디어 재생장치와 같은 외부장치와 1:1 또는 1:N(N은 자연수) 방식으 로 유선 접속됨으로써, 해당 외부장치로부터 데이터를 수신하거나 또는 해당 외부장치에 데이터를 출력한다. 신 호입출력부는 예를 들면 HDMI 포트, DisplayPort, DVI 포트, 썬더볼트, USB 포트 등과 같이, 기 설정된 전송규격에 따른 커넥터 또는 포트 등을 포함한다. 디스플레이부는 화면 상에 영상을 표시할 수 있는 디스플레이 패널을 포함한다. 디스플레이 패널은 액정 방식과 같은 수광 구조 또는 OLED 방식과 같은 자발광 구조로 마련된다. 디스플레이부는 디스플레이 패널 의 구조에 따라서 부가적인 구성을 추가로 포함할 수 있는데, 예를 들면 디스플레이 패널이 액정 방식이라면, 디스플레이부는 액정 디스플레이 패널과, 광을 공급하는 백라이트유닛과, 액정 디스플레이 패널의 액정을구동시키는 패널구동기판을 포함한다. 사용자입력부는 사용자의 입력을 수행하기 위해 사용자가 조작할 수 있도록 마련된 다양한 종류의 입력 인 터페이스 관련 회로를 포함한다. 사용자입력부는 전자장치의 종류에 따라서 여러 가지 형태의 구성이 가능하며, 예를 들면 전자장치의 기계적 또는 전자적 버튼부, 터치패드, 디스플레이부에 설치된 터치 스크린 등이 있다. 저장부는 디지털화된 데이터를 저장한다. 저장부는 전원의 제공 유무와 무관하게 데이터를 보존할 수 있는 비휘발성 속성의 스토리지(storage)와, 프로세서에 의해 처리되기 위한 데이터가 로딩되며 전원이 제 공되지 않으면 데이터를 보존할 수 없는 휘발성 속성의 메모리(memory)를 포함한다. 스토리지에는 플래시메모리 (flash-memory), HDD(hard-disc drive), SSD(solid-state drive) ROM(Read Only Memory) 등이 있으며, 메모리 에는 버퍼(buffer), 램(RAM; Random Access Memory) 등이 있다. 마이크로폰 또는 음성입력부는 사용자 발화를 비롯한 외부 환경의 소리를 수집한다. 마이크로폰은 수 집된 소리의 음성신호를 프로세서에 전달한다. 마이크로폰은 전자장치의 본체에 설치될 수도 있 고, 전자장치의 본체와 분리된 리모트 컨트롤러에 설치될 수도 있다. 후자의 경우에, 마이크로폰에 의한 음성신호는 리모트 컨트롤러로부터 통신부에 수신된다. 후자의 경우에 관해 보다 구체적으로 설명하 면, 리모트 컨트롤러의 마이크로폰을 통해 수집된 사용자 발화의 음성신호는 디지털신호로 변환된다. 리모 트 컨트롤러는 변환된 디지털신호를 통신부와 통신 가능한 프로토콜, 예를 들면 블루투스, 와이파이, 지그 비 등의 프로토콜에 기반하여 통신부에 전송한다. 통신부에 수신되는 디지털신호는 프로세서로 전달되어 처리된다. 사용자 발화의 음성이 프로세서에 전달되는 여러 과정에 관해서는 후술한다. 프로세서는 인쇄회로기판 상에 장착되는 CPU, 칩셋, 버퍼, 회로 등으로 구현되는 하나 이상의 하드웨어 프 로세서를 포함하며, 설계 방식에 따라서는 SOC(system on chip)로 구현될 수도 있다. 프로세서는 전자장치 이 디스플레이장치로 구현되는 경우에 디멀티플렉서, 디코더, 스케일러, 오디오 DSP(Digital Signal Processor), 앰프 등의 다양한 프로세스에 대응하는 모듈들을 포함한다. 여기서, 이러한 모듈들 중 일부 또는 전체가 SOC로 구현될 수 있다. 예를 들면, 디멀티플렉서, 디코더, 스케일러 등 영상처리와 관련된 모듈이 영상 처리 SOC로 구현되고, 오디오 DSP는 SOC와 별도의 칩셋으로 구현되는 것이 가능하다. 프로세서는 마이크로폰을 통해 획득된 음성신호를 통신부를 통해 서버에 전달하고, 음성신 호의 음성처리 결과인 텍스트 데이터를 하나 이상의 서버로부터 통신부를 통해 수신한다. 프로세서 는 하나 이상의 서버로부터 수신된 하나 이상의 텍스트 데이터를 처리하여, 텍스트 데이터가 지시하 는 동작을 수행한다. 이하, 서버의 구성에 관해 설명한다. 서버통신부는 다양한 종류의 유선 및 무선 통신 프로토콜에 대응하는 통신모듈, 통신칩 등의 구성요소들 중 적어도 하나 이상을 포함하는 양방향 통신회로이다. 서버통신부는 전자장치의 통신부에 대응 하는 통신규격을 지원함으로써, 광역 네트워크를 통해 전자장치을 비롯한 다양한 종류의 클라이언트와 네 트워크를 통해 통신할 수 있다. 서버저장부는 서버프로세서에 의해 데이터의 독취, 기록, 수정, 삭제, 갱신 등의 동작이 수행된다. 서버저장부는 플래시메모리, HDD, SSD, 버퍼, 램 등의 다양한 비휘발성 메모리 및 휘발성 메모리를 포함한 다. 본 실시예의 서버저장부는 음성신호의 STT 처리를 위한 음성인식엔진을 하나 이상 포함한다. 서버프로세서는 인쇄회로기판 상에 장착되는 CPU, 칩셋, 버퍼, 회로 등으로 구현되는 하나 이상의 하드웨 어 프로세서를 포함하며, 설계 방식에 따라서는 SOC로 구현될 수도 있다. 서버프로세서는 전자장치로 부터 수신되는 정보에 기반하여 다양한 처리를 수행할 수 있다. 예를 들면, 서버프로세서는 전자장치(21 0)로부터 음성신호를 수신하면, 서버저장부에 저장된 음성인식엔진을 사용하여 음성신호의 STT 처리를 수 행하고, STT 처리 결과 도출된 텍스트 데이터를 서버통신부를 통해 전자장치에 전송한다. 한편, 프로세서는 복수의 서버로부터 수신한 복수의 인식결과 중에서 발화 음성에 대한 인식 적합도 가 상대적으로 높은 인식결과를 식별하고, 식별된 인식결과에 따른 커맨드를 식별하는 동작을 수행하기 위한 데 이터 분석, 처리, 및 결과 정보 생성 중 적어도 일부를 규칙 기반 또는 인공지능(Artificial Intelligence) 알 고리즘으로서 기계학습, 신경망 네트워크(neural network), 또는 딥러닝 알고리즘 중 적어도 하나를 이용하여 수행할 수 있다.일 예로, 프로세서는 학습부 및 인식부의 기능을 함께 수행할 수 있다. 학습부는 학습된 신경망 네트워크 를 생성하는 기능을 수행하고, 인식부는 학습된 신경망 네트워크를 이용하여 데이터를 인식(또는, 추론, 예측, 추정, 판단)하는 기능을 수행할 수 있다. 학습부는 신경망 네트워크를 생성하거나 갱신할 수 있다. 학습부는 신 경망 네트워크를 생성하기 위해서 학습 데이터를 획득할 수 있다. 일 예로,학습부는 학습 데이터를 후술하는 저 장부 또는 외부로부터 획득할 수 있다. 학습 데이터는, 신경망 네트워크의 학습을 위해 이용되는 데이터일 수 있으며, 상기한 동작을 수행한 데이터를 학습데이터로 이용하여 신경망 네트워크를 학습시킬 수 있다. 학습부는 학습 데이터를 이용하여 신경망 네트워크를 학습시키기 전에, 획득된 학습 데이터에 대하여 전처리 작 업을 수행하거나, 또는 복수 개의 학습 데이터들 중에서 학습에 이용될 데이터를 선별할 수 있다. 일 예로, 학 습부는 학습 데이터를 기 설정된 포맷으로 가공하거나, 필터링하거나, 또는 노이즈를 추가/제거하여 학습에 적 절한 데이터의 형태로 가공할 수 있다.학습부는 전처리된 학습 데이터를 이용하여 상기한 동작을 수행하도록 설 정된 신경망 네트워크를 생성할 수 있다. 학습된 신경망 네트워크는, 복수의 신경망 네트워크(또는, 레이어)들로 구성될 수 있다. 복수의 신경망 네트워 크의 노드들은 가중치를 가지며, 복수의 신경망 네트워크들은 일 신경망 네트워크의 출력 값이 다른 신경망 네 트워크의 입력 값으로 이용되도록 서로 연결될 수 있다. 신경망 네트워크의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN (Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네 트워크 (Deep Q-Networks)과 같은 모델을 포함할 수 있다. 한편 인식부는 상기한 동작을 수행하기 위해, 타겟 데이터를 획득할 수 있다. 타겟 데이터는 저장부 또는 외부로부터 획득된 것일 수 있다. 타겟 데이터는 신경망 네트워크의 인식 대상이 되는 데이터일 수 있다. 인식 부는 타겟 데이터를 학습된 신경망 네트워크에 적용하기 전에, 획득된 타겟 데이터에 대하여 전처리 작업을 수 행하거나, 또는 복수 개의 타겟 데이터들 중에서 인식에 이용될 데이터를 선별할 수 있다. 일 예로, 인식부는 타겟 데이터를 기 설정된 포맷으로 가공하거나, 필터링 하거나, 또는 노이즈를 추가/제거하여 인식에 적절한 데 이터의 형태로 가공할 수 있다. 인식부는 전처리된 타겟 데이터를 신경망 네트워크에 적용함으로써, 신경망 네 트워크로부터 출력되는 츨력값을 획득할 수 있다. 인식부는 출력값과 함께, 확률값 또는 신뢰도값을 획득할 수 있다. 이러한 구성 하에서, 전자장치가 사용자 발화의 STT 처리 결과를 획득하는 방법에 관해 설명한다. 도 3은 전자장치의 제어방법을 나타내는 플로우차트이다. 도 3에 도시된 바와 같이, 아래 동작은 전자장치의 프로세서에 의해 실행된다. 310 단계에서 전자장치는 사용자 발화의 음성을 수신한다. 320 단계에서 전자장치는 발화 음성을 인식 가능한 복수의 음성인식기 또는 음성인식엔진을 식별한다. 만일 복 수의 서버가 각기 음성인식엔진을 구비한 경우, 전자장치는 각 서버에 대해 발화 음성의 인식결과를 획득할 수 있도록 통신이 가능한지 여부를 점검할 수 있다. 330 단계에서 전자장치는 식별된 복수의 음성인식엔진 각각에 발화 음성을 전송한다. 여기서, 전자장치는 복수 의 음성인식엔진에 대해 동일한 발화 음성을 전송한다. 340 단계에서 전자장치는 발화 음성을 전송한 복수의 음성인식엔진 각각으로부터 발화 음성의 인식결과를 획득 한다. 350 단계에서 전자장치는 획득한 복수의 인식결과 중에서 발화 음성에 대한 인식 적합도가 높은 인식결과를 식 별한다. 360 단계에서 전자장치는 식별된 인식결과에 따른 동작을 수행한다. 이와 같이, 전자장치는 복수의 음성인식엔진으로부터 획득한 복수의 인식결과 중에서 발화 음성에 대한 인식 적 합도가 높은 인식결과를 선택함으로써, 보다 정확한 음성인식동작이 수행되도록 할 수 있다. 인식 적합도는 여러 가지 방법에 의해 식별될 수 있다. 이하, 전자장치가 인식 적합도를 기반으로 인식결과를 식별하는 구체적인 실시예들에 관해 설명한다. 도 4는 전자장치가 단어리스트에 기초하여 복수의 음성인식결과로부터 어느 하나를 선택하는 구조를 나타내는 블록도이다. 도 4에 도시된 바와 같이, 전자장치는 입력되는 사용자 발화의 음성신호에 대응하는 N개의 텍스트 데이터 를 획득한다(N은 둘 이상의 자연수). N개의 텍스트 데이터는 N개의 음성인식엔진에 의해 각기 생성된 것으로서, 동일한 음성신호에 대한 음성인식결과를 나타낸다. 이들 각 음성인식엔진은 전자장 치, 외부장치 또는 서버에 각기 구비된다. 하나의 장치에 하나의 음성인식엔진이 구비될 수 있고, 하나의 장치에 둘 이상의 음성인식엔진이 구비되는 것도 가능하다. 즉, 복수의 음성인식엔진 중 하나 이상이 전자장치에 구비되고 나머지 음성인식엔진이 서버에 구비될 수 있고, 복수의 음성인식엔진 각각이 개 별 서버에 구비될 수도 있고, 복수의 음성인식엔진 중 하나 이상이 전자장치에 구비되고 나머지 음성인식 엔진이 전자장치와 근거리 통신이 가능한 외부장치에 구비될 수도 있다. 음성인식결과 선택부는 N개의 음성인식엔진의 텍스트 데이터 중에서, 발화의 음성신호에 대한 인식 적합도가 상대적으로 높은 어느 하나의 텍스트 데이터를 선택한다. 여기서, 음성인식결과 선택 부는 N개의 음성인식엔진의 텍스트 데이터 중에서 단어 리스트에 기반하여 음성신호 에 대한 인식 적합도가 상대적으로 높은 어느 하나의 텍스트 데이터를 선택할 수 있다. 음성인식결과 선택부는 전자장치의 프로세서일 수 있고, 프로세서에 의해 실행되는 운영체제, 미들웨어, 어플리케이션일 수도 있다. 또는, 음성인식결과 선택부는 전자장치가 아닌, 서버 또는 외부장치의 프로세 서이거나, 서버 또는 외부장치의 프로세서에 의해 실행되는 운영체제, 미들웨어, 어플리케이션일 수도 있다. 단어 리스트는 통상적인 표준 사전에 수록되지 않은 단어들을 포함하거나, 또는 표준 사전에 수록되었다고 하더라도 음성인식결과가 정확하지 않을 것으로 사전에 예상되는 단어들을 포함한다. 단어 리스트에 포함 되는 이러한 단어들을 편의상 혼동 단어라고 지칭한다. 음성인식엔진의 구조에 따라서 차이는 있을 수 있 지만, 표준 사전에 수록된 단어는 음성인식결과에서 정확한 텍스트 데이터가 나올 확률이 높다. 그러나, 표준 사전에 수록되지 않은 단어는 상기한 확률이 낮을 것이다. 단어 리스트는 음성인식결과의 정확도가 상대적으로 낮은 단어들 중에서, 현 시점에서 사용 빈도가 상대적으로 높을 것으로 예상되는 단어들을 포함한다. 단어 리스트를 생성 및 구축하는 예시에 관해서는 후술한다. N개의 텍스트 데이터가 모두 동일한 내용이라면, 음성인식결과 선택부는 별도의 프로세스 없이 어느 하나의 텍스트 데이터를 최종적으로 선택할 수 있다. 반면에 N개의 텍스트 데이터 중 적어도 일부가 서로 상이한 내용이라면, 음성인식결과 선택부는 먼저 각 텍스트 데이터 사이에서 서로 상이한 단어를 식별한다. 음성인식결과 선택부는 식별된 단어들 중 에서 단어 리스트의 단어들에 대응하는 단어를 식별한다. 단어 리스트에 대응하는 단어가 식별되면, 음성인식결과 선택부는 N개의 텍스트 데이터 중에서 해당 단어를 가진 텍스트 데이터를 최종적 으로 선택한다. 즉, 음성인식결과 선택부는 텍스트 데이터가 단어 리스트에 수록된 혼동 단어를 포함하면, 해당 텍스트 데이터를 제공하는 음성인식엔진의 음성신호에 대한 인식 적합도를 상대 적으로 높다고 식별한다. 이로써, 음성인식결과 선택부는 단어 리스트에 기초하여, N개의 텍스트 데이터 중에서 어느 한 텍스트 데이터를 선택할 수 있다. 또는, 추가적인 실시예로서, 음성인식결과 선택부는 N개의 텍스트 데이터 중에서 동일한 내용의 텍스 트 데이터의 퍼센티지가 문턱값을 초과하면, 단어 리스트의 참조 없이, 퍼센티지가 문턱값을 초과하 는 텍스트 데이터를 선택할 수도 있다. 즉, 설계 방식에 따라서는, 다수의 음성인식엔진이 동일한 결과를 출력한 경우에, 추가적인 프로세스 없이 다수의 결과를 수용하는 방식도 가능하다. 예를 들어 N=10이고 문턱값이 60%으로 설정되어 있는 경우를 고려한다. 10개의 텍스트 데이터 중에서 7개 의 텍스트 데이터의 내용이 동일하다면, 음성인식결과 선택부는 이 7개의 텍스트 데이터 중 어 느 하나를 선택한다. 반면, 10개의 텍스트 데이터 중에서 4개의 텍스트 데이터의 내용이 동일하다면, 음성인식결과 선택부는 앞선 실시예와 같이 단어 리스트를 기반으로 텍스트 데이터를 선택할 수 있다. 음성인식결과 선택부 또는 단어 리스트는 전자장치에 마련될 수 있지만, 설계 방식에 따라서는 전자 장치가 아닌 외부장치 또는 서버에 마련될 수도 있다. 예를 들면, 음성인식결과 선택부를 구비한 전자장치 가 단어 리스트를 저장하는 서버로부터 해당 단어 리스트를 획득하여 참조하는 것이 가능하다. 또는, 음성인식결과 선택부 및 단어 리스트가 외부장치 또는 서버에 마련되고, 전자장치는 음성인식결과 선택부의 동작에 따른 결과를 수신할 수도 있다. 서버가 단어 리스트를 저장하는 경우에, 본 서버는 음 성인식 Assistant의 서버로 구현되거나, 기타 다양한 상황을 포괄하기 위한 별도의 서버로 구현될 수도 있다. 한편, N개의 텍스트 데이터 사이에서 서로 상이한 단어들 중에서, 단어 리스트에 대응하는 단어를 식 별하는 방법은 여러 가지 방법 또는 알고리즘이 가능하다. 이하, 간단한 식별 방법에 관해 설명한다. 도 5는 전자장치가 복수의 텍스트 데이터 중에서 어느 하나를 식별하는 원리를 개략적으로 나타내는 예시도이다. 도 5에 도시된 바와 같이, 전자장치는 사용자 발화에 따른 음성신호의 음성인식결과인 복수의 텍스트 데이터 (510, 520, 530), 예를 들어 3개의 텍스트 데이터(510, 520, 530)를 획득할 수 있다. 각 텍스트 데이터(510, 520, 530)는 단어의 배치 순서를 고려한 단어 구조로 나타낼 수 있다. 제1텍스트 데이터에 있어서, 제일 앞선 0번째 위치에 단어 \"A\"가, 1번째 위치에 단어 \"A\"가, 2번째 위치에 단어 \"K\"가, 3번째 위치에 단어 \"C\"가, 4번째 위치에 단어 \"C\"가, 5번째 위치에 단어 \"D\"가 나온다. 이에 따라서, 제1텍스트 데이터의 단어 구조 는 \"AAKCCD\"로 나타낼 수 있다. 같은 원리로, 제2텍스트 데이터의 단어 구조는 \"AALCCD\"로, 제3텍스트 데 이터의 단어 구조는 \"AAMCCD\"로 각기 나타낼 수 있다. 여기서, A, C, D, K, L, M은 각기 서로 상이한 단어 를 나타낸다. 전자장치는 복수의 텍스트 데이터(510, 520, 530) 중에서 서로 상이한 단어가 나타나는지 여부를 식별한다. 복 수의 텍스트 데이터(510, 520, 530) 중에서 서로 상이한 단어는, 각 텍스트 데이터(510, 520, 530)의 2번째 위 치의 단어이다. 각각의 2번째 위치의 단어는, 제1텍스트 데이터에서 \"K\", 제2텍스트 데이터에서 \"L\", 제3텍스트 데이터에서 \"M\"이다. 전자장치는 각 텍스트 데이터(510, 520, 530)의 2번째 위치의 단어 중에서, 단어 리스트에 포함되는 혼동 단어가 있는지를 식별하고, 해당 혼동 단어를 포함하는 텍스트 데이터를 최종 선택한다. 전자장치는 검색 대상 인 단어 \"K\", \"L\", \"M\" 중에서 단어 리스트에 \"M\"이 포함되어 있다고 검색되면, \"M\"을 포함하는 제3텍스트 데이터를 선택한다. 이로써, 전자장치는 단어 리스트에 기초하여 복수의 텍스트 데이터(510, 520, 530) 중 어느 하나를 선택할 수 있다. 단어 리스트에 기초하여 어느 하나의 텍스트 데이터를 선택하는 방법이 상기한 실시예에 한정되는 것은 아니며, 다양한 방법이 적용될 수 있다. 예를 들면, 전자장치는 TF-IDF(Term Frequency - Inverse Document Frequency) 알고리즘에 기반하여, 복수의 단어 중에서 단어 리스트에 대응하는 단어를 식별할 수 있다. TF-IDF는 단어 빈도 (TF) 및 역 문서 빈도(IDF)를 사용하여 문서 단어 행렬(Document-Term Matrix, DTM) 내의 각 단어들마다 중요 한 정도를 가중치로 주는 방법이다. 이하, 단어 리스트를 생성 및 업데이트하는 방법에 관해 설명한다. 도 6은 전자장치가 단어 리스트를 생성 및 업데이트하는 방법을 나타내는 예시도이다. 도 6에 도시된 바와 같이, 전자장치는 다양한 소스로부터 전자장치의 상태 및 사용 환경에 관련된 정보를 획득하고, 획득한 정보를 기반으로 단어 리스트를 생성한다. 또한, 전자장치는 단어 리스트를 생성한 방법에 준하여 단어 리스트를 업데이트한다. 단어 리스트는 전자장치 이외에, 외부장치, 서버 등에 의해서 생성 및 업데이트될 수도 있다. 단어 리스트는 실시간으로 업데이트될 수 있다. 다만, 업데이 트 시 발생하는 부하의 감소를 위해, 단어 리스트는 주기적으로 업데이트되거나, 전자장치의 시스템 부하 가 상대적으로 적을 때에 수행될 수 있다. 또는, 전자장치는 단어 리스트의 업데이트를 사용자에게 확인하 는 UI를 표시하고, UI를 통한 사용자 입력에 따라서 선택적으로 업데이트를 수행할 수도 있다. 전자장치의 상태 및 사용 환경에 관련된 정보는 다양한 소스로부터 획득되는 다양한 종류의 정보로 마련될 수 있다. 이러한 정보는 예를 들면 인터넷 또는 소셜 네트워크 서비스를 통해 다수의 사용자들이 검색한 실시간 검색어, 방송컨텐트 제공자가 방송 프로그램과 관련하여 제공하는 EPG(Electronic Program Guide) 데이 터, 스트리밍 서버가 제공하는 VOD(Video-on-Demand) 리스트, 다양한 컨텐트 서비스 제공자가 제공하는 컨텐트 정보, 전자장치에 기 저장된 전자장치의 장치 정보, 전자장치를 사용하는 사용자의 사용자 계정으로부터 획득되 는 사용 이력, 전자장치에 저장된 전화번호나 이름 등의 사용자 정보, 전자장치에 접속되어 있는 외부장치 목록, 전자장치에 현재 접속되어 있지 않더라도 차후에 접속이 가능하다고 예상되는 외부장치 목록(예를 들면, 이전 시점에서 전자장치에 접속된 이력이 있는 외부장치이거나, 접속이 가능한 외부장치의 목록 등) 등을 포함한다. 전자장치는 이와 같은 정보로부터 기 설정된 기준에 따라서 여러 단어들을 도출하고, 획득한 단어들 에 기반하여 단어 리스트를 생성한다. 상기한 기준은 정보의 속성에 따라서 다양하게 마련될 수 있으며, 특정한 조건으로 한정되는 것은 아니다. 예를 들면, 전자장치는 획득한 실시간 검색어로부터 소정 순위 이상인 검색어를 획득한다. 전자장치는 EPG 데이 터, VOD 리스트로부터 프로그램의 제목 및 프로그램의 출연자 이름을 획득한다. 전자장치는 컨텐트 정보로부터 컨텐트의 제목을 획득한다. 전자장치는 장치 정보로부터 전자장치의 제조사, 모델명, 브랜드명을 획득한다. 전 자장치는 사용자의 사용 이력으로부터 사용자의 이름, 해당 사용자가 소유한 여러 전자장치의 제조사, 모델명, 브랜드명, 이전의 인식결과에서 인식이 실패했던 이력이 있는 단어를 획득한다. 이와 같이 도출된 단어들은, 해당 단어가 도출되는 정보를 획득한 시점의 트렌드를 반영하게 된다. 전자장치는 도출된 단어들을 모두 혼동 단어로 포함시켜 단어 리스트를 생성하거나 또는 업데이트할 수 있다. 다만, 보다 효율적인 단어 리스트를 구현하기 위해, 전자장치는 도출된 단어들을 필터링 함으로써, 선별된 혼동 단어들로 단어 리스트를 구성할 수도 있다. 필터링에는 여러 가지 방법이 가능한데, 예를 들면 전자장치는 도출된 단어들 중에서 표준 사전에 수 록되어 있는 단어들을 제외하고, 그 이외의 단어들을 단어 리스트에 포함시킬 수 있다. 또는, 전자장치는 도출된 단어들 중에서 고유명사를 단어 리스트에 포함시킬 수도 있다. 소정 언어에 관한 표준 사전은 해당 언어를 사용하는 사회 또는 국가에서 공인된 단체 또는 학자들에 의해 작성되어 제안될 수 있다. 음성인식 엔진이 설계될 때에, 음성인식엔진의 모델링에는 표준 사전도 참조된다. 이는, 표준 사전에 실린 단어들은 음성 인식엔진에 의해 정확하게 인식될 확률이 높고, 표준 사전에 실리지 않은 단어들 또는 고유명사들은 음성인식엔 진에 의해 정확하게 인식될 확률이 상대적으로 낮다고 기대될 수 있다. 따라서, 전자장치는 도출된 단어들 중에서, 표준 사전에 실리지 않았으므로 정확하게 인식될 확률이 낮다 고 예상되는 단어들을 선별하여, 단어 리스트에 포함시킨다. 물론, 이와 같은 필터링의 방법은 하나 의 예시일 뿐이며, 다양한 방법이 필터링에 적용될 수 있다. 한편, 단어 리스트는 포함 가능한 단어의 수에 제한이 있을 수 있다. 단어 리스트의 각 단어는 소정 기준에 따라서 우선순위가 부여될 수 있다. 이 기준은, 예를 들면 복수의 텍스트 데이터 중 어느 하나를 선택하 기 위해 검색된 빈도의 이력이거나, 또는 단어 리스트에 포함된 시점일 수도 있다. 물론, 본 기준의 예시 는 이에 한정되지 않는다. 전자장치는 단어 리스트에 수록된 단어의 수가 기 설정된 개수를 초과하면, 우선순위에 따라서 단어 리스 트 내 종래의 단어를 삭제하고, 새로 획득된 단어를 추가함으로써 단어 리스트를 업데이트한다. 예를 들면, 전자장치는 단어 리스트 내에서 단어를 삭제함에 있어서, 복수의 텍스트 데이터 중 어느 하나를 선 택하기 위해 검색된 빈도가 가장 낮은 순서대로 단어를 삭제할 수도 있고, 단어 리스트에서 가장 오래된 순서대로 단어를 삭제할 수도 있다. 한편, 앞선 실시예에서는 혼동 단어를 포함하는 단어 리스트에 기초하여 상대적으로 높은 인식 적합도를 가진 인식결과를 식별하는 구성에 관해 설명하였다. 그러나, 다른 실시예로서, 복수의 음성인식엔진으로부터 각각 인 식결과를 수신하지 않고, 상대적으로 높은 인식 적합도를 가진 음성인식엔진을 식별하여 해당 음성인식엔진으로 부터 인식결과를 수신하는 구성도 가능한 바, 이하 이러한 실시예에 관해 설명한다. 도 7은 전자장치가 현재 상황에 기초하여 인식 적합도가 높은 음성인식엔진을 식별하는 방법을 나타내는 플로우 차트이다. 도 7에 도시된 바와 같이, 아래 동작은 전자장치의 프로세서에 의해 실행된다. 710 단계에서 전자장치는 사용자 발화 음성신호를 수신한다. 720 단계에서 전자장치는 발화 음성신호를 인식 가능한 복수의 음성인식엔진을 식별한다. 730 단계에서 전자장치는 발화 음성신호에 대한 인식이 수행되는 현재 상황을 식별한다. 740 단계에서 전자장치는 식별된 복수의 음성인식엔진 중에서, 식별된 상황에 기초하여 발화 음성신호에 대한 인식 적합도가 높은 음성인식엔진을 식별한다.750 단계에서 전자장치는 인식 적합도가 상대적으로 높다고 식별된 음성인식엔진에 의한 발화 음성의 인식결과 를 획득한다. 760 단계에서 전자장치는 획득한 인식결과에 따른 동작을 수행한다. 발화 음성신호에 대한 인식이 수행되는 현재 상황은 전자장치가 획득 가능한 다양한 정보에 기초하여 식별될 수 있다. 이하, 상기한 상황을 식별하는 예시에 관해 설명한다. 도 8은 발화 음성신호에 대한 인식이 수행되는 상황에 관한 예시도이다. 도 8에 도시된 바와 같이, 전자장치는 발화 음성신호를 수신하는 현 시점의 다양한 상황을 식별하고, 식별된 상 황에 대응하는 음성인식엔진을 선택한다. 본 상황은 예를 들면 컨텐트/서비스 카테고리, 사용자 카테고리 , 장치 카테고리 등 다양한 카테고리(810, 820, 830)로 분류될 수 있다. 전자장치는 이들 카테고리 (810, 820, 830) 중 어느 하나에 기초하여 인식 적합도가 높은 음성인식엔진을 식별한다. 각 카테고리(810, 820, 830)는 룩업테이블 형식으로 복수의 상태 항목에 대응하는 음성인식엔진을 정의할 수 있 다. 전자장치는 현 시점에 해당하는 어느 한 카테고리(810, 820, 830)의 상태를 식별하고, 식별된 상태에 대응 하는 음성인식엔진을 인식 적합도가 상대적으로 높은 것으로 식별할 수 있다. 전자장치는 복수의 카테고리(810, 820, 830) 중 현재 상황에 맞는 어느 한 카테고리(810, 820, 830)를 선택하고, 선택한 카테고리(810, 820, 830) 내에서 현재 상황에 대응하는 상태를 검색할 수 있다. 컨텐트/서비스 카테고리는 전자장치가 제공하는 컨텐트 또는 서비스에 관한 속성에 대응하는 음성인식엔진 을 정의한다. 컨텐트는 방송 프로그램 영상, 스트리밍되는 영상, 저장된 파일의 재생 영상, 스트리밍되는 오디 오, 저장된 파일의 재생 오디오 등과 같은 멀티미디어 컨텐트일 수도 있고, 쇼핑몰, 뉴스 사이트와, 같은 웹 사 이트일 수도 있고, 기타 다양한 어플리케이션 등이 가능하다. 서비스는 컨텐트를 제공하기 위한 다양한 어플리 케이션, 웹 서비스, 전자장치의 동작 모드, 전자장치의 기능 등이 가능하다. 예를 들어, 전자장치는 발화 음성신호가 수신되는 시점에, 웹 브라우저 상에 쇼핑몰 사이트가 표시되고 있는 상 황이라고 식별할 수 있다. 이 경우에, 전자장치는 컨텐트 또는 서비스에 관련된 컨텐트/서비스 카테고리 내에서, 쇼핑몰 사이트에 대응하는 음성인식엔진 B를 식별한다. 이에 따라서, 전자장치는 음성인식엔진 B로부터 의 인식결과를 최종적으로 선택한다. 사용자 카테고리는 사용자의 이름, 성별, 거주지, 국적, 나이, 직업 등의 인적사항에 관한 속성에 대응하 는 음성인식엔진을 정의한다. 사용자의 이름에 기초하여 식별하는 경우에, 전자장치는 발화 음성신호가 수신되 면 해당 발화를 수행하는 사용자의 계정에 기반하여 해당 사용자의 이름을 식별한다. 전자장치는 사용자 카테고 리에서 식별된 사용자에 대응하는 음성인식엔진을 식별한다. 예를 들어 사용자 이름이 Catherine M.이라고 식별되었다면, 전자장치는 음성인식엔진 F로부터의 인식결과를 선택한다. 장치 카테고리는 전자장치, 또는 발화 음성신호가 수신되는 시점에 전자장치에 접속되어 있는 외부장치의 기기 정보에 관한 속성에 대응하는 음성인식엔진을 정의한다. 장치 카테고리에 정의된 기기 정보는 전자장 치의 기기 ID, 모델명, 브랜드명, 제조사명이거나, 외부장치의 기기 ID, 모델명, 브랜드명, 제조사명일 수 있다. 외부장치에 기초하여 식별하는 경우에, 전자장치는 발화 음성신호가 수신되면 현재 접속되어 있는 외부장 치의 기기 ID를 식별한다. 전자장치는 식별된 기기 ID가 제2기기이면, 장치 카테고리에서 제2기기에 대응 하는 음성인식엔진 B를 식별한다. 전자장치는 음성인식엔진 B로부터의 인식결과를 선택한다. 이와 같이 전자장치가 다양한 상황에 맞는 음성인식엔진을 미리 정의하고, 발화 음성신호가 수신되는 상황에 맞 는 음성인식엔진을 선택하는 이유에 관해 설명한다. 음성인식엔진을 설계하는 개발사는, 통상적으로 자신들이 관심이 있는 분야에 포커스를 두고 음성인식엔진을 모 델링한다. 예를 들어 개발사가 TV를 제조하는 제조사와 관련이 있다면, 해당 개발사는 TV의 동작 제어에 포커스 를 두고 음성인식엔진을 설계할 것이다. 그 결과 생성된 음성인식엔진은 TV 동작에 관한 발화를 상대적으로 정 확하게 인식할 확률이 높다고 기대된다. 또는, 개발사가 쇼핑몰을 운영하는 회사와 관련이 있다면, 해당 개발사 는 쇼핑몰에서의 물품 구매에 포커스를 두고 음성인식엔진을 설계할 것이다. 그 결과 생성된 음성인식엔진은 쇼 핑에 관한 발화를 상대적으로 정확하게 인식할 확률이 높다고 기대된다. 이러한 관점에서, 전자장치의 현재 상황과 관련성이 높은 음성인식엔진의 음성인식결과가, 나머지 음성인식엔진 의 음성인식결과에 비해 정확도가 높다고 기재될 수 있다. 이에, 본 실시예에 따른 전자장치는 발화 음성신호가 수신되는 시점의 전자장치의 상황에 맞는 음성인식엔진을 식별하고, 식별된 음성인식엔진의 인식결과를 획득한다. 한편, 앞선 실시예에서는 발화 음성신호에 대한 인식 적합도가 높은 음성인식엔진을 식별하여, 식별된 음성인식 엔진의 인식결과를 획득하는 구성에 관해 설명하였다. 그러나, 이러한 인식 적합도는 인식결과를 획득할 음성인 식엔진을 식별하는 구성 이외에도, 음성신호를 복수의 음성인식엔진 중에서 어느 음성인식엔진에 먼저 보낼 것 인가에 관한 구성에도 적용될 수 있다. 이하, 이러한 실시예에 관해 설명한다. 도 9는 전자장치가 인식 적합도에 따라서 각 서버에 순차적으로 음성신호를 전송하는 방법을 나타내는 예시도이 다. 도 9에 도시된 바와 같이, 전자장치는 발화 음성신호가 수신되면, 복수의 음성인식엔진을 각기 구비한 복 수의 서버(910, 920, 930, 940)와 통신 가능한지 여부를 식별한다. 전자장치는 통신이 가능하다고 식별된 복수의 서버(910, 920, 930, 940)의 음성인식엔진 중에서, 발화 음성신호에 대한 인식 적합도가 상대적으로 높 은 음성인식엔진을 식별한다. 인식 적합도를 식별하는 방법은 앞선 실시예들에서 설명한 바 있으므로, 본 실시 예에서는 설명을 생략한다. 전자장치가 통신 가능하며 각기 음성인식엔진을 가진 서버(910, 920, 930, 940)가 제1서버, 제2서버 , 제3서버, 제4서버가 있다고 한다. 전자장치는 발화 음성신호에 대한 이들 네 서버(910, 920, 930, 940)의 음성인식엔진 각각의 인식 적합도를 식별한다. 예를 들어, 제1서버의 음성인식엔진의 인 식 적합도가 높고, 제2서버, 제3서버, 제4서버 각각의 음성인식엔진의 인식 적합도가 낮다고 식 별될 수 있다. 이 경우에, 전자장치는 제1서버의 음성인식엔진에 의해 먼저 인식 처리가 수행되도록, 복수의 서버(910, 920, 930, 940) 중에서 제1서버에 먼저 음성신호를 전송한다. 제1서버에 음성신호 를 전송한 이후, 전자장치는 나머지 제2서버, 제3서버, 제4서버에 음성신호를 전송한다. 이와 같이, 전자장치가 인식 적합도가 높은 음성인식엔진을 가진 제1서버에 발화 음성신호를 우선적 으로 전송하는 이유는 다음과 같다. 전자장치는 복수의 서버(910, 920, 930, 940)에 음성신호를 전송하고, 각 서버(910, 920, 930, 940)로부터 음성신호의 인식결과인 텍스트 데이터를 수신하게 된다. 이 경우에, 전자장 치 및 복수의 서버(910, 920, 930, 940) 사이의 통신환경에 따라서는 네트워크 트래픽이 심하게 발생할 수 있다. 네트워크 통신의 특성 상, 전자장치 및 서버(910, 920, 930, 940) 사이의 데이터 송수신이 과도하게 지연되면, 데이터가 정상적으로 송수신되지 못하고 종료될 수 있다. 이러한 현상은, 특히 나중 순서에 음성신호 가 전송되는 서버(910, 920, 930, 940)의 경우에 현저히 나타날 수 있다. 따라서, 본 실시예에서의 전자장치는 인식 적합도가 높은 음성인식엔진을 가진 제1서버에 우선적으로 음성신호를 전송함으로써, 보다 정확한 인식결과를 안정적으로 획득할 수 있도록 한다. 또는, 네트워크 트래픽을 고려하여, 전자장치는 복수의 음성인식엔진 중에서 인식을 수행할 음성인식엔진 및 인식을 수행하지 않을 음성인식엔진을 구분할 수도 있다. 이하, 이러한 실시예에 관해 설명한다. 도 10은 전자장치가 발화 음성신호를 전달할 음성인식엔진을 식별하는 방법을 나타내는 플로우차트이다. 도 10에 도시된 바와 같이, 아래 동작은 전자장치의 프로세서에 의해 실행된다. 1010 단계에서 전자장치는 사용자 발화 음성신호를 수신한다. 1020 단계에서 전자장치는 발화 음성신호를 인식 가능한 복수의 음성인식엔진을 식별한다. 1030 단계에서 전자장치는 발화 음성신호에 대한 인식이 수행되는 현재 상황을 식별한다. 1040 단계에서 전자장치는 식별된 복수의 음성인식엔진 중에서, 식별된 상황에 기초하여 발화 음성신호를 전달 할 하나 이상의 음성인식엔진 및 발화 음성신호를 전달하지 않을 하나 이상의 음성인식엔진을 구분한다. 여기서, 인식을 수행할 음성인식엔진 및 인식을 수행하지 않을 음성인식엔진을 구분하는 기준은 여러 가지가 가 능하다. 이러한 기준은 발화하는 사용자의 정보, 전자장치의 기기 정보, 컨텐트 또는 서비스의 속성 등이 가능 하다. 즉, 앞선 실시예에서 설명한 바와 같이 전자장치는 발화 음성신호를 수신하는 현 시점의 다양한 상황을 식별하고, 식별된 상황에 대응하여 인식을 수행할 음성인식엔진 및 인식을 수행하지 않을 음성인식엔진을 구분 할 수 있다. 1050 단계에서 전자장치는 발화 음성신호를 전달하도록 구분된 음성인식엔진에 의한 발화 음성의 인식결과를 획 득한다.1060 단계에서 전자장치는 획득한 인식결과에 따른 동작을 수행한다. 예를 들면, 전자장치는 방송 프로그램 중 쇼핑몰의 영상이 표시되는 중에 발화 음성신호가 수신되었다면, 여러 음성인식엔진 중에서 방송 프로그램의 재생 제어 또는 쇼핑몰 등에 특화된 음성인식엔진들에 음성신호를 전달하 고, 그 외의 음성인식엔진들에는 음성신호를 전달하지 않을 수 있다. 한편, 앞선 실시예에서 설명한 바와 같이, 단어 리스트는 다양한 소스로부터 선별된 혼동 단어들을 포함할 수 있다. 한 가지 예시로서, 혼동 단어는 이전 음성인식의 실패 이력으로부터 획득될 수도 있는 바, 이하 이러한 실시예에 관해 설명한다. 도 11은 전자장치가 음성인식의 실패 이력으로부터 혼동 단어를 획득하는 원리를 나타내는 예시도이다. 도 11에 도시된 바와 같이, 전자장치는 사용자로부터 1차 발화 음성신호를 수신한다. 1110 단계에서 전자장치는 1차 발화 음성신호의 정상적인 인식결과를 획득하는 것에 실패할 수 있다. 통상적으로, 사용자는 발화에 대한 결과가 실행되지 않으면, 발화 이외의 입력(리모트 컨트롤러의 버튼 조작, 터치스크린의 터치, 제스쳐 지시 등)을 통해 해당 결과에 따른 동작을 직접 지시한다. 즉, 발화가 실패했을 때에 소정 시간 이내에 수행되는 사 용자 입력은, 해당 발화의 인식결과와 큰 관련성을 가질 소지가 높다는 것을 나타낸다. 1차 발화 음성신호의 인식결과가 실패한 이후 소정 시간 이내에 사용자 입력이 수신되면, 1120 단계에서 전자장 치는 사용자 입력에 대응하는 동작을 수행한다. 1130 단계에서, 전자장치는 1차 발화 음성의 실패한 인식결과 및 사용자 입력의 대응 동작의 관련성을 분석하여 혼동 단어를 획득하고, 획득한 혼동 단어를 단어 리스트에 포함시킨다. 예를 들어 1차 발화 음성이 특정한 방송 프로그램을 표시할 것을 지시하는 내용이고, 1110 단계에서 1차 발화 음성의 인식 결과에서 무언가를 표시할 것을 지시하는 것 까지는 인식이 성공하였으나, 표시 대상이 무엇인지 인식하는 것이 실패할 수 있다. 만일 1120 단계에서 대응 동작이 특정 방송 프로그램을 표시하는 것이었다면, 1110 단계에서 인식에 실패한 음성 부분은, 1120 단계에서 표시되는 방송 프로그램을 지시하는 것으로 기대될 수 있다. 전자장치는 해당 방송 프로그램의 명칭을 EPG 데이터로부터 획득하여, 단어 리스트에 추가할 수 있다. 1차 발화 음성의 실패한 인식결과 및 사용자 입력의 대응 동작의 관련성은 다양한 방법 또는 알고리즘에 의해 수행될 수 있으며, 예를 들면 머신 러닝, 딥 러닝 분야의 AI를 통한 알고리즘이 적용될 수 있다. 이후, 전자장치는 1차 발화 음성신호와 동일한 내용의 2차 발화 음성신호를 수신할 수 있다. 1140 단계에서 전 자장치는 2차 발화 음성신호의 인식 처리를 수행함에 있어서 단어 리스트를 참조한다. 단어 리스트(110 0)는 1차 발화 음성신호의 인식 실패 결과에 기반한 혼동 단어를 포함하므로, 1150 단계에서 전자장치는 단어 리스트의 혼동 단어를 참조함으로써 인식 처리를 성공할 수 있다. 본 실시예에서는 전자장치가 음성 인식을 수행하는 것으로 설명하였지만, 설계 방식에 따라서는 서버가 음성 인 식을 수행할 수도 있다. 한편, 상기한 실시예들은 사용자 발화를 인식하는 분야에 관련된 것들이다. 그러나, 사용자의 지시를 입력하기 위한 방식은 다양하며, 이들 중에는 인식 알고리즘을 필요로 하는 것들도 있다. 즉, 본 발명의 사상은 단순히 발화에만 한정되는 것은 아니며, 사용자 입력 방식들 중에서 인식 처리를 필요로 하는 제반 구성에 적용될 수 있다. 이하, 이러한 실시예에 관해 설명한다. 도 12는 전자장치의 구성 블록도이다. 도 12에 도시된 바와 같이, 전자장치는 통신부, 신호입출력부, 디스플레이부, 사용자 입력부, 저장부, 센서, 프로세서를 포함한다. 센서를 제외한 나머지 구성요소들 의 기본적인 사항은 앞선 실시예에서의 동명의 구성요소들에 준하므로, 자세한 설명을 생략한다. 센서는 사용자의 제스처를 감지하기 위한 카메라를 포함한다. 센서는 소정 시간 동안에 수행되는 사용자의 제스처를 캡처하고, 캡처된 영상이 프로세서에 전달되도록 한다. 본 실시예에서는 전자장치 가 사용자의 제스처를 감지하는 센서를 구비한 경우에 관해 설명하나, 프로세서가 사용자의 제스처를 캡처한 영상을 획득하는 방법은 이에 한정되지 않는다. 예를 들면, 전자장치는 통신부 또 는 신호입출력부를 통해 카메라를 가진 외부장치와 접속되며, 외부장치로부터 해당 영상을 획득할 수도있다. 저장부는 사용자의 다양한 제스처에 대응하는 동작 커맨드의 리스트를 저장한다. 프로세서는 센서에 의해 캡처된 영상을 분석하여 사용자의 제스처를 식별하고, 저장부에 저 장된 리스트 상에서 식별된 제스처에 대응하는 커맨드를 검색하고, 검색된 커맨드가 지시하는 동작이 수행되도 록 한다. 예를 들면, 리스트는 사용자가 한 손을 좌측에서 우측으로 이동시키는 모션에 대응하여 채널 전환 커 맨드를 지정할 수 있다. 프로세서는 캡처된 영상에서 나타나는 사용자의 제스처가 한 손을 좌측에서 우측 으로 이동시키는 모션이라고 식별되면, 리스트에 기초하여 채널 전환 커맨드를 식별하고, 식별된 채널 전환 커 맨드에 따라서 채널을 전환시킨다. 본 실시예에서는 전자장치가 캡처된 영상을 분석하여 사용자의 제스처를 식별하는 영상 분석 과정을 수행 하는 경우에 관해 설명하였으나, 별도의 서버 또는 외부장치가 영상 분석 과정을 수행하여 전자장치에 제 공할 수도 있다. 그런데, 영상 분석 과정에 사용되는 모델, 알고리즘, AI 등에 따라서, 식별되는 제스처는 다른 결과가 나올 수 있다. 이러한 관점에서, 다음과 같은 동작에 따라서 제스처가 식별될 수 있다. 도 13은 전자장치가 사용자 제스처의 인식결과를 획득하는 방법의 플로우차트이다. 도 13에 도시된 바와 같이, 이하 동작은 전자장치의 프로세서에 의해 수행된다. 1310 단계에서 전자장치는 사용자 제스처를 캡처한 영상을 수신한다. 1320 단계에서 전자장치는 해당 영상을 분석하기 위한 복수의 분석모델을 식별한다. 각 분석모델은 개별적으로 영상을 분석하여 사용자 제스처를 식별하도록 마련된다. 1330 단계에서 전자장치는 식별된 복수의 분석모델 중에서 사용자 제스처에 대한 인식 적합도가 상대적으로 높 은 분석모델을 식별한다. 1340 단계에서 전자장치는 인식 적합도가 상대적으로 높다고 식별된 분석모델에 의해 영상으로부터 사용자 제스 처의 식별결과를 획득한다. 350 단계에서 전자장치는 획득한 식별결과에 따른 동작을 수행한다. 이와 같이, 전자장치는 복수의 분석모델 중에서 사용자 제스처에 대한 인식 적합도가 높은 분석모델을 선택함으 로써, 보다 정확한 제스처 인식 동작이 수행되도록 할 수 있다. 사용자 제스처에 대한 인식 적합도는, 앞선 실 시예에서의 사용자 발화 음성에 대한 인식 적합도를 응용하여 적용할 수 있으므로, 자세한 설명을 생략한다. 한편, 전자장치가 사용자 발화의 음성을 획득하는 수단은 여러 가지 방식이 가능한 바, 이하 전자장치가 발화 음성을 획득하는 여러 수단에 관해 설명한다. 도 14는 전자장치 및 여러 입력장치의 구성 블록도이다. 도 14에 도시된 바와 같이, 전자장치는 통신부와, 프로세서를 포함한다. 통신부는 지 원 가능한 통신 프로토콜에 따라서 복수의 통신모듈을 포함할 수 있다. 예를 들면, 복수의 통신모듈 은 이더넷 모뎀, 와이파이 통신칩, 블루투스 통신칩, 적외선 수신모듈 등을 포함하며, 각 통신모듈(141 4)은 지원하는 프로토콜 기반의 통신을 수행하도록 마련된다. 전자장치는 통신부를 통해 다양한 외부장치(1420, 1430) 또는 서버와 통신이 가능하다. 외부 장치(1420, 1430)는 서버의 경우와 동일한 통신모듈을 통해 전자장치와 통신할 수도 있는 바, 예를 들면 전자장치는 와이파이 통신칩인 통신모듈을 통해 서버 및 외부장치(1420, 1430)와 와이파이 기반 무선통신을 수행할 수 있다. 또는, 전자장치는 상이한 통신모듈을 통해 전 자장치와 통신할 수도 있는 바, 예를 들면 전자장치는 이더넷 모뎀인 통신모듈을 통해 서버 와 통신하는 한편, 블루투스 통신칩인 통신모듈을 통해 외부장치(1420, 1430)와 통신할 수 있다. 외부장치(1420, 1430)는 전자장치와 관련된 전용기기이거나, 전자장치와 관련되어 제조된 것은 아 니지만 전자장치와 통신하여 사용할 수 있도록 마련된 범용기기일 수 있다. 예를 들면, 전용기기는 전자 장치를 제어하도록 제공되는 리모트 컨트롤러일 수 있고, 범용기기는 모바일기기일 수 있다. 전자장치는 다음과 같은 방법으로 사용자 발화 음성을 획득할 수 있다. 전자장치는 소리를 수집하는 마이크로폰을 구비할 수 있다. 마이크로폰을 통해 수집된 사용 자 발화의 음성신호는 디지털신호로 변환되어 프로세서에 전달된다. 프로세서는 전달받은 발화 음 성신호를 처리하는데, 구체적인 처리 방법은 앞선 실시예에서 설명한 바 있으므로, 본 실시예에서는 추가적인 설명을 생략한다. 또는, 리모트 컨트롤러가 마이크로폰을 구비한 경우에, 전자장치는 마이크로폰을 통해 수집된 사용자 발화의 음성신호를 리모트 컨트롤러로부터 수신할 수도 있다. 리모트 컨트롤러는 마 이크로폰을 통해 수집된 사용자 발화의 음성신호는 디지털신호로 변환하고, 이 디지털신호를 통신모듈 이 수신 가능한 프로토콜에 따라서 리모트 컨트롤러 통신부를 통해 통신모듈로 전송한다. 또는, 모바일기기와 같은 범용기기의 경우에, 전자장치의 제어를 위해 마련된 어플리케이션을 인스 톨하여 실행시킴으로써 모바일기기는 리모트 컨트롤러와 유사하게 동작할 수 있다. 모바일기기 는 상기한 어플리케이션이 실행되는 동안 마이크로폰을 통해 수집된 사용자 발화의 음성신호를 디 지털신호로 변환하여, 모바일기기 통신부를 통해 통신모듈로 전송한다. 이와 같이, 전자장치는 다양한 방식으로 사용자 발화 음성을 획득할 수 있다. 한편, 설계 방식에 따라서는, 전자장치가 복수의 음성인식엔진 중에서 발화 음성에 대한 인식 적합도가 높은 음 성인식엔진을 식별하고, 식별된 음성인식엔진의 인식결과를 획득하는 방법도 가능하다. 이하, 이러한 실시예에 관해 설명한다. 도 15는 전자장치의 제어방법을 나타내는 플로우차트이다. 도 15에 도시된 바와 같이, 아래 동작은 전자장치의 프로세서에 의해 실행된다. 1510 단계에서 전자장치는 사용자 발화의 음성을 수신한다. 1520 단계에서 전자장치는 발화 음성을 인식 가능한 복수의 음성인식엔진을 식별한다. 1530 단계에서 전자장치는 식별된 복수의 음성인식엔진 중에서 발화 음성에 대한 인식 적합도가 높은 음성인식 엔진을 식별한다. 1540 단계에서 전자장치는 인식 적합도가 가장 높다고 식별된 음성인식엔진에 의한 발화 음성의 인식결과를 획 득한다. 1550 단계에서 전자장치는 획득한 인식결과에 따른 동작을 수행한다. 이와 같이, 전자장치는 복수의 음성인식엔진 중에서 발화 음성에 대한 인식 적합도가 높은 음성인식엔진을 선택 함으로써, 보다 정확한 음성인식동작이 수행되도록 할 수 있다. 이상 실시예들에서 설명한 바와 같은 장치의 동작은, 해당 장치에 탑재된 인공지능에 의해 수행될 수 있다. 인 공지능은 기계 학습 알고리즘을 활용하여 다양한 제반 시스템에 적용될 수 있다. 인공지능 시스템은 인간 수준 내지는 인간 수준에 버금가는 지능을 구현하는 컴퓨터 시스템으로서, 기계, 장치 또는 시스템이 자율적으로 학 습하고 판단하며, 사용 경험의 누적에 기반하여 인식률 및 판단 정확도가 향상되는 시스템이다. 인공지능 기술 은 입력되는 데이터들의 특징을 스스로 분류하고 학습하는 알고리즘을 이용한 기계학습 기술 및 알고리즘을 활 용하여, 인간의 두뇌의 인지, 판단 등의 기능을 모사하는 요소 기술들로 구성된다. 요소 기술들은, 예를 들면 인간의 언어와 문자를 인식하는 언어적 이해 기술, 사물을 인간의 시각처럼 인식하는 시각적 이해 기술, 정보를 판단하여 논리적으로 추론하고 예측하는 추론 및 예측 기술, 인간의 경험 정보를 지 식 데이터로 처리하는 지식 표현 기술, 차량의 자율 주행이나 로봇의 움직임을 제어하는 동작 제어 기술 중 적 어도 어느 하나를 포함한다. 여기서, 언어적인 이해는 인간의 언어 또는 문자를 인식하고 응용 처리하는 기술로서, 자연어의 처리, 기계 번 역, 대화 시스템, 질의 응답, 음성 인식 및 합성 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 예측하는 기술로서, 지식 및 확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험 정보를 지식 데이터로 자동화 처리하는 기술로서, 데이터의 생성 및 분류와 같은 지식 구축, 데이터의 활용과 같은 지식 관리 등을 포함한다.본 발명의 예시적 실시예에 따른 방법들은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 이러한 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파 일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 예를 들어, 컴퓨터 판독 가능 매체는 삭제 가능 또는 재기록 가능 여부와 상관없이, USB 메모리장치와 같은 비휘발성 저장 장치, 또는 예를 들어 RAM, ROM, 플 래시메모리, 메모리 칩, 집적 회로와 같은 메모리, 또는 예를 들어 CD, DVD, 자기 디스크 또는 자기 테이프 등 과 같은 광학 또는 자기적으로 기록 가능함과 동시에 기계(예를 들어, 컴퓨터)로 읽을 수 있는 저장 매체에 저 장될 수 있다. 이동 단말 내에 포함될 수 있는 메모리는 본 발명의 실시 예들을 구현하는 지시들을 포함하는 프 로그램 또는 프로그램들을 저장하기에 적합한 기계로 읽을 수 있는 저장 매체의 한 예임을 알 수 있을 것이다. 본 저장 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트 웨어의 기술 분야에서 숙련된 기술자에게 공지되어 사용 가능한 것일 수도 있다. 또는, 본 컴퓨터 프로그램 명 령은 컴퓨터 프로그램 프로덕트에 의해 구현될 수도 있다."}
{"patent_id": "10-2019-0109157", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 전자장치가 사용자 발화의 음성인식결과를 획득하는 환경을 나타내는 예시도이다. 도 2는 전자장치의 구성 블록도이다. 도 3은 전자장치의 제어방법을 나타내는 플로우차트이다. 도 4는 전자장치가 단어리스트에 기초하여 복수의 음성인식결과로부터 어느 하나를 선택하는 구조를 나타내는 블록도이다. 도 5는 전자장치가 복수의 텍스트 데이터 중에서 어느 하나를 식별하는 원리를 개략적으로 나타내는 예시도이다. 도 6은 전자장치가 단어 리스트를 생성 및 업데이트하는 방법을 나타내는 예시도이다.도 7은 전자장치가 현재 상황에 기초하여 인식 적합도가 높은 음성인식엔진을 식별하는 방법을 나타내는 플로우 차트이다. 도 8은 발화 음성신호에 대한 인식이 수행되는 상황에 관한 예시도이다. 도 9는 전자장치가 인식 적합도에 따라서 각 서버에 순차적으로 음성신호를 전송하는 방법을 나타내는 예시도이 다. 도 10은 전자장치가 발화 음성신호를 전달할 음성인식엔진을 식별하는 방법을 나타내는 플로우차트이다. 도 11은 전자장치가 음성인식의 실패 이력으로부터 혼동 단어를 획득하는 원리를 나타내는 예시도이다. 도 12는 전자장치의 구성 블록도이다. 도 13은 전자장치가 사용자 제스처의 인식결과를 획득하는 방법의 플로우차트이다. 도 14는 전자장치 및 여러 입력장치의 구성 블록도이다. 도 15는 전자장치의 제어방법을 나타내는 플로우차트이다."}
