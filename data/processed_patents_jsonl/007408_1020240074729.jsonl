{"patent_id": "10-2024-0074729", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0108325", "출원번호": "10-2024-0074729", "발명의 명칭": "멀티모드 스마트 카메라, 스마트 카메라 시스템 및 그것의 제어 방법", "출원인": "주식회사 카카오엔터프라이즈", "발명자": "김민주"}}
{"patent_id": "10-2024-0074729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 타 스마트 카메라와 스트리밍 영상을 공유하기 위한 통신부;영상을 촬영하는 이미지 센서;제어부; 및제 1 인공지능 모델을 탑재하는 DPU(Data processing unit)를 포함하되,상기 제어부는,상기 타 스마트 카메라로부터 공유되는 스트리밍 영상을 상기 제 1 인공지능 모델에 기초하여 분석하되,상기 제 1 인공지능 모델은 상기 촬영된 영상과 상기 스트리밍 영상을 합하여 생성한 합성 스트리밍 영상을 입력으로 하여 상기 분석을 수행하는,스마트 카메라."}
{"patent_id": "10-2024-0074729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 합성 스트리밍 영상은,상기 촬영된 영상과 상기 스트리밍 영상을 중 적어도 하나를 인코딩한 후 합하여 생성한 것인,스마트 카메라."}
{"patent_id": "10-2024-0074729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 인코딩은, 인코딩 대상 영상의 용량을 줄이는 것인,스마트 카메라."}
{"patent_id": "10-2024-0074729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 인코딩은, 상기 촬영된 영상의 해상도를 변경하거나 프레임 레이트를 변경하는 것인,스마트 카메라."}
{"patent_id": "10-2024-0074729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 타 스마트 카메라에 공유되는 스트리밍 영상은 상기 적어도 하나의 타 스마트 카메라 각각에 탑재된 적어도 하나의 제 2 인공지능 모델에 기초하여 분석되는,스마트 카메라.공개특허 10-2024-0108325-3-청구항 6 제 5 항에 있어서, 상기 제어부는,상기 제 2 인공지능 모델에 기초하여 분석된 분석 결과를 회신 받도록 상기 통신부를 제어하고,상기 제 1 인공지능 모델에 기초하여 분석을 수행하는데 있어서, 상기 회신 받은 분석 결과를 고려하여 분석을수행하는,스마트 카메라."}
{"patent_id": "10-2024-0074729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 5 항에 있어서, 상기 타 스마트 카메라에 공유되는 스트리밍 영상은,상기 촬영된 영상에 인코딩을 적용한 영상인,스마트 카메라."}
{"patent_id": "10-2024-0074729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "적어도 하나의 타 스마트 카메라와 스트리밍 영상을 공유하는 단계;영상을 촬영하는 단계;제 1 인공지능 모델을 탑재하는 단계; 및상기 타 스마트 카메라로부터 공유되는 스트리밍 영상을 상기 제 1 인공지능 모델에 기초하여 분석하는 단계를포함하되,상기 분석하는 단계는 상기 촬영된 영상과 상기 스트리밍 영상을 합하여 생성한 합성 스트리밍 영상을 상기 제1 인공지능 모델의 입력으로 하여 상기 분석을 수행하는,스마트 카메라의 제어 방법."}
{"patent_id": "10-2024-0074729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서, 상기 합성 스트리밍 영상은,상기 촬영된 영상과 상기 스트리밍 영상을 중 적어도 하나를 인코딩한 후 합하여 생성한 것인,스마트 카메라의 제어 방법."}
{"patent_id": "10-2024-0074729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 인코딩은, 인코딩 대상 영상의 용량을 줄이는 것인,스마트 카메라의 제어 방법."}
{"patent_id": "10-2024-0074729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 인코딩은, 상기 촬영된 영상의 해상도를 변경하거나 프레임 레이트를 변경하는 것인,공개특허 10-2024-0108325-4-스마트 카메라의 제어 방법."}
{"patent_id": "10-2024-0074729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 8 항에 있어서,상기 타 스마트 카메라에 공유되는 스트리밍 영상은 상기 적어도 하나의 타 스마트 카메라 각각에 탑재된 적어도 하나의 제 2 인공지능 모델에 기초하여 분석되는,스마트 카메라의 제어 방법."}
{"patent_id": "10-2024-0074729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,상기 제 2 인공지능 모델에 기초하여 분석된 분석 결과를 회신 받도록 상기 통신부를 제어하는 단계를 더 포함하고,상기 분석을 수행하는 단계는, 상기 회신 받은 분석 결과를 상기 제 1 인공지능 모델의 입력으로 함께 제공하여분석을 수행하는,스마트 카메라의 제어 방법."}
{"patent_id": "10-2024-0074729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 12 항에 있어서, 상기 타 스마트 카메라에 공유되는 스트리밍 영상은,상기 촬영된 영상에 인코딩을 적용한 영상인,스마트 카메라의 제어 방법."}
{"patent_id": "10-2024-0074729", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 자체적으로 탑재된 인공지능 모델에 기초하여 영상을 분석할 수 있는 스마트 카메라에 관한 것이다. 보다 구체적으로 본 발명은, 적어도 하나의 타 스마트 카메라와 스트리밍 영상을 공유하기 위한 통신부, 영상을 촬영하는 이미지 센서, 제어부, 및 제 1 인공지능 모델을 탑재하는 DPU(Data processing unit)를 포함하되, 상 기 제어부는, 상기 타 스마트 카메라로부터 공유되는 스트리밍 영상을 상기 제 1 인공지능 모델에 기초하여 분석 하는, 스마트 카메라에 관한 것이다."}
{"patent_id": "10-2024-0074729", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 멀티모드로 동작 가능한 스마트 카메라에 관련된 기술에 관한 것으로, 보다 구체적으로는 다양한 종 류의 머신러닝 알고리즘을 수행하는데 있어서 복수 개의 스마트 카메라가 협력하여 인공지능에 기반한 영상 분 석을 수행하도록 구성되는 스마트 카메라 관련 기술에 관한 것이다."}
{"patent_id": "10-2024-0074729", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "보안을 위하여 특정 지역을 감시하기 위하여 고정식 카메라가 설치된다. 이렇게 설치되는 적어도 하나의 고정식 카메라는 관제 시스템으로 영상을 전송하며, 전송된 영상은 관제 모니터를 통하여 출력되거나, 추후 열람을 위 하여 기록될 수 있다. 최근 인공지능 관련 분야의 기술이 급속도로 발전하면서, 고정식 카메라의 영상이 인공지능에 의해서 분석이 이 루어지고 있다. 즉, 사람이 관제 모니터를 주시하지 않아도, 인공지능에 의해서 영상이 모니터링될 수 있다는 것이다. 예를 들어서, 관제 시스템에 탑제된 인공지능 모듈은, 영상에서 누군가 월담하는 것을 분석하여 경고를 해 줄 수 있다. 하지만 이런 고정식 카메라는 자체적으로 인공지능 모듈을 구비하고 있지 않으며, 관제 시스템과의 연결이 해제 될 경우 분석이 불가능하다는 문제점이 존재한다. 이에 따라, 자체적으로 인공지능 모델을 구비하여, 관제 시스템과의 연결 여부와 무관하게 인공지능에 기초한 분석을 제공할 수 있는 스마트 카메라에 관한 연구가 요구되는 실정이다."}
{"patent_id": "10-2024-0074729", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 스마트 카메라 자체에 얼굴 인식(face detection)이나 객체 인식(object detection) 등의 인공지능 모델을 구비할 수 있는 스마트 카메라를 제공하는 것이다. 본 발명이 해결하고자 하는 다른 과제는 클라우드 서버와 연결이 해제된 상태에서도, 스마트 카메라 자체적으로 영상 분석을 수행할 수 있는 시스템을 제공하는 것이다. 본 발명이 해결하고자 하는 다른 과제는 서로 다른 종류의 인공지능 모델을 구비하는 복수 개의 스마트 카메라 가 서로 연결된 상태로 구비되어, 협력하는 방식으로 영상 분석을 수행할 수 있는 스마트 카메라 시스템을 제공 하는 것이다. 본 발명에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2024-0074729", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0074729", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 또는 다른 과제를 해결하기 위해 본 발명의 일 측면에 따르면, 적어도 하나의 타 스마트 카메라와 스트리 밍 영상을 공유하기 위한 통신부; 영상을 촬영하는 이미지 센서; 제어부; 및 제 1 인공지능 모델을 탑재하는 DPU(Data processing unit)를 포함하되, 상기 제어부는, 상기 타 스마트 카메라로부터 공유되는 스트리밍 영상 을 상기 제 1 인공지능 모델에 기초하여 분석하는, 스마트 카메라를 제공한다. 상기 공유되는 스트리밍 영상은 상기 적어도 하나의 타 스마트 카메라 각각에 탑재된적어도 하나의 제 2 인공지 능 모델에 기초하여 분석될 수 있다. 상기 제어부는, 상기 제 2 인공지능 모델에 기초하여 분석된 분석 결과를 회신 받도록 상기 통신부를 제어할 수 있다. 상기 제어부는, 상기 제 1 인공지능 모델에 기초하여 분석을 수행하는데 있어서, 상기 회신 받은 분석 결과를 고려하여 분석을 수행할 수 있다. 상기 제어부는, 상기 촬영된 영상에 대해서 인코딩을 수행하고, 상기 인코딩 된 영상을 상기 적어도 하나의 타 스마트 카메라에 공유할 수 있다. 상기 인코딩은, 상기 촬영된 영상의 해상도를 변경하거나 프레임 레이트를 변경하는 것일 수 있다. 상기 또는 다른 과제를 해결하기 위해 본 발명의 다른 측면에 따르면, 적어도 하나의 타 스마트 카메라와 스트 리밍 영상을 공유하는 단계; 영상을 촬영하는 단계; 제 1 인공지능 모델을 탑재하는 단계; 및 상기 타 스마트 카메라로부터 공유되는 스트리밍 영상을 상기 제 1 인공지능 모델에 기초하여 분석하는 단계를 포함하는, 스마 트 카메라의 제어 방법을 제공한다. 상기 적어도 하나의 타 스마트 카메라 각각은 적어도 상기 적어도 하나의 타 스마트 카메라 각각에 탑재된 적어 도 하나의 제 2 인공지능 모델에 기초하여 분석될 수 있다. 상기 제 2 인공지능 모델에 기초하여 분석된 분석 결과를 회신 받는 단계를 더 포함할 수 있다. 상기 제 1 인공지능 모델에 기초하여 분석을 수행하는 단계는, 상기 회신 받은 분석 결과를 고려하여 분석을 수 행할 수 있다. 상기 촬영된 영상에 대해서 인코딩을 수행하하는 단계를 더 포함하고, 상기 공유하는 단계는 상기 인코딩 된 영 상을 상기 적어도 하나의 타 스마트 카메라에 공유할 수 있다.상기 인코딩은, 상기 촬영된 영상의 해상도를 변경하거나 프레임 레이트를 변경하는 것일 수 있다. 상기 또는 다른 과제를 해결하기 위해 본 발명의 또 다른 측면에 따르면, 제 1 인공지능 모델을 탑재하는 제 1 스마트 카메라; 제 2 인공지능 모델을 탑재하는 제 2 스마트 카메라를 포함하되, 상기 제 1 및 제 2 스마트 카 메라는, 영상을 촬영하고, 서로 촬영된 영상을 스트리밍 형태로 공유하며, 각각이 탑재하는 제 1 또는 제 2 인 공지능 모델로 상기 공유되는 영상을 분석하는, 스마트 카메라 시스템을 제공한다."}
{"patent_id": "10-2024-0074729", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 스마트 카메라 및 관련 시스템의 효과에 대해 설명하면 다음과 같다. 본 발명의 실시 예들 중 적어도 하나에 의하면, 스마트 카메라 자체에 얼굴 인식(face detection), 얼굴 식별 (face recognition)이나 객체 인식(object detection) 등의 인공지능 모델을 구비할 수 있는 스마트 카메라를 제공할 수 있다는 장점이 있다. 또한, 본 발명의 실시 예들 중 적어도 하나에 의하면, 클라우드 서버와 연결이 해제된 상태에서도, 스마트 카메 라 자체적으로 영상 분석을 수행할 수 있는 시스템을 제공할 수 있다는 장점이 있다. 또한, 본 발명의 실시 예들 중 적어도 하나에 의하면, 서로 다른 종류의 인공지능 모델을 구비하는 복수 개의 스마트 카메라가 서로 연결된 상태로 구비되어, 협력하는 방식으로 영상 분석을 수행할 수 있는 스마트 카메라 시스템을 제공할 수 있는 시스템을 제공할 수 있다는 장점이 있다. 본 발명의 적용 가능성의 추가적인 범위는 이하의 상세한 설명으로부터 명백해질 것이다. 그러나 본 발명의 사 상 및 범위 내에서 다양한 변경 및 수정은 당업자에게 명확하게 이해될 수 있으므로, 상세한 설명 및 본 발명의 바람직한 실시 예와 같은 특정 실시 예는 단지 예시로 주어진 것으로 이해되어야 한다."}
{"patent_id": "10-2024-0074729", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 오프로딩(offloading)은 컴퓨팅 자원 및 계산 속도의 한계를 극복하기 위해 로컬 컴퓨터에서 수행하는 어플리케 이션의 일부를 컴퓨팅 자원과 처리능력이 우수한 원격지 컴퓨터에 전달하여 처리한 후 결과를 반환받는 방식이 다. 최근에는 컴퓨팅 자원과 처리능력에 한계를 갖고 있는 모바일 컴퓨팅 분야에서 처리속도를 높이고 배터리 소모를 줄이기 위해, VR(Virtual Reality), AR(Augmented Reality) 모바일 게임, 멀티미디어 데이터, 360도 동 영상 처리, 인터넷 방송용 이미지 처리 분야에서 응용되고 있다. 영상으로부터 객체를 인식하는 기술은 영상 처리나 패턴 인식, 컴퓨터 비전과 신경망, 인공지능 같은 다양한 분 야에 걸쳐서 활발히 연구되고 있고, 상업적, 법적으로 수많은 응용분야를 가지고 있다. 일반적으로 인공지능이 적용된 인공지능 모델을 이용하기 위해서는 인공지능 모델을 개발하기 위한 인력을 배치 하거나, 인공지능 모델을 개발하는 업체로부터 원하는 인공지능 모델을 제공받는 방식을 취하고 있다. 이에 따라 본 발명에서는 인공지능 모델을 모듈화하고, 스토어 시스템을 통하여 인공지능 모듈을 제공함으로써, 사용자 별로 다양한 사용 목적에 맞는 인공지능 모듈을 이용할 수 있도록 하는 시스템을 제안한다. 이를 위해서 본 발명의 일실시예에서는, 스마트 카메라 자체에 인공지능 모델 탑재 플랫폼(예를 들어 TensorFlow와 같은 플랫폼)이 구비되고, 적어도 하나의 인공지능 모델(얼굴 인식 모듈이나 객체 인식 모듈 등) 이 탑재되어서 사용자가 원하는대로 인식 등의 영상 분석을 수행할 수 있도록 제안한다. 특히, 본 발명의 일실시예에 따르면, 적어도 하나의 인공지능 모델을 사용자가 직접 변경해서 사용 가능하도록 제공될 수도 있다. 이를 위해 별도의 스토어 서버(시스템)로부터 적어도 하나의 인공지능 모델을 사용자가 직접 다운로드 받아 설치 가능하도록 제공될 수도 있다. 이로 인하여 다양한 서드 파티 개발자들이 인공지능 모델을 개발한 후 스토어 서버를 통하여 배포하면, 스마트 카메라의 사용자들이 원하는대로 선택적으로 인공지능 모델 을 스마트 카메라에 설치하여 영상 분석 등에 활용할 수 있을 것이다. 본 발명의 일실시예에서는, 스마트 카메라 측(엣지 파트)에 설치될 수 있는 인공지능 모듈 스토어(이하 카메라 용 스토어)와, 클라우드 서버 측에 설치될 수 있는 인공지능 모듈 스토어(이하 서버용 스토어)를 구분하여 제공 할 수도 있을 것이다. 스마트 카메라 측에 설치되는 인공지능 모델은 상대적으로 가볍고 간단한 연산을 수행하며, 클라우드 서버 측에 설치되는 인공지능 모델은 상대적으로 무겁고 복잡한 연산을 수행할 것이다. 본 발명의 일실시예에 따르면, 스마트 카메라 자체에서 인공지능 모델의 추가적인 학습도 가능하도록 구비될 수 있다. 본 발명의 일실시예에 따르면, 스마트 카메라와는 별도로 구비되는 학습 서버에 의해서 스마트 카메라에 구비되 는 인공지능 모델이 지속적으로 업데이트되도록 구비될 수 있다. 이하 도면을 참고하여 보다 상세하게 설명한다. 도 1은 본 발명의 일실시예에 따른 스마트 카메라 시스템을 도시하는 도면이다. 본 발명의 일실시예에 따른 스마트 카메라 시스템은, 스마트 카메라, 적어도 하나의 일반 카메라 (100'), 클라우드 서버, 스토어 서버 및 사용자 단말을 포함하도록 구성될 수 있다. 도 1에 도시된 구성요소들은 스마트 카메라 시스템을 구현하는데 있어서 필수적인 것은 아니어서, 본 명세 서 상에서 설명되는 스마트 카메라 시스템은 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들 을 가질 수 있다. 스마트 카메라는 이미지 센서를 통하여 촬영되는 영상에 대한 인코딩/디코딩을 수행하고, 압축을 수행하며, 자체 로컬 저장소에 저장할 수 있다. 그리고 스마트 카메라는 자체에서 인공지능 모델을 구비하 여 클라우드 서버의 보조 없이 촬영되는 영상에 대한 간단한 분석을 수행할 수 있다. 스마트 카메라는, 사용자에게 신속하게 알림을 주기 위하여 요구되는 간단한 종류의 인공지능 모델은 자체 적으로 수행하되, 복잡한 연산이 요구되고 많은 데이터 베이스의 사용이 필요한 인공지능 모델의 경우에는 클라 우드 서버로 전송하여 분석할 수 있다. 스마트 카메라는, 클라우드 서버에서 분석을 수행하기 위한 트리거 이벤트를 감지하기 위한 인공지능 모델을 자체적으로 구비하고, 이러한 인공지능 모델을 이용하여 이벤트가 감지될 경우 2차적인 메타데이터를 형 성하여 클라우드 서버에서 상대적으로 더 복잡한 인공지능 분석을 수행할 수 있도록 형성된 메타데이터를 클라우드 서버에 전달한다. 스마트 카메라는 네트워크를 통하여 클라우드 서버와 데이터를 주고 받을 수 있다. 적어도 하나의 일반 카메라(100')는, 멀티 모드에서 동작하기 위한 구성이다. 본 발명의 일실시예에 따른 싱글 모드는, 스마트 카메라를 통하여 촬영되는 영상에 대한 분석을 수행하는 모드를 의미한다. 본 발명의 일실시예에 따른 멀티 모드는, 스마트 카메라와 함께 적어도 하나의 일반 카 메라(100')가 촬영하는 영상에 대한 분석을 수행하는 모드를 의미한다. 멀티 모드에서 적어도 하나의 일반 카메라(100')는 이미지 센서를 통하여 영상을 촬영하고, 촬영된 영상을 스마 트 카메라 또는 클라우드 서버에 전달한다. 이렇게 적어도 하나의 일반 카메라(100')로부터 촬영된 영상을 전달 받은 스마트 카메라 또는 클라우드 서 버는, 설치된 인공지능 모델에 기초하여 촬영된 영상에 대한 분석을 수행할 수 있을 것이다. 클라우드 서버는 스마트 카메라나 적어도 하나의 일반 카메라(100')로부터 촬영된 영상을 분석한다. 이때 클라우드 서버는 적어도 하나의 인공지능 모델을 구비하고, 인공지능 모델에 기초하여 촬영된 영상에 대한 분석을 수행할 수 있다. 클라우드 서버는 스마트 카메라에 의해서 1차적으로 분석이 이루어진 촬영 영상에 대하여 2차적인 분 석을 수행할 수 있다. 이때 1차적인 분석이 2차적인 분석 보다 상대적으로 더 간단한 분석일 수 있을 것이다. 클라우드 서버는, 스마트 카메라의 분석에 의해서 트리거 이벤트가 발생되었다고 판단될 경우, 촬영 영상에 대한 보다 구체적인 분석을 수행할 수 있을 것이다. 스토어 서버(102, store server)는 적어도 하나의 인공지능 모델을 저장한다. 스토어 서버는 스마트 카메 라에 설치되기 위한 상대적으로 간단한 인공지능 모델(카메라용 모델)을 저장하는 카메라용 스토어와 클라 우드 서버에 설치되기 위한 상대적으로 복잡한 인공지능 모델(서버용 모델)을 저장하는 서버용 스토어를 포함하도록 구성될 수 있다. 카메라용 스토어는, 스마트 카메라에 설치될 수 있는 간단한 인공지능 모델인 \"카메라용 모델\"을 사용자들 간에 공유하기 위한 가상의 공간을 의미할 수 있다. 서버용 스토어는, 클라우드 서버에 설치되기 위한 상대적으로 복잡한 인공지능 모델인 \"서버용 모델\"을 사 용자들 간에 공유하기 위한 가상의 공간을 의미할 수 있다. 다양한 서드 파티 개발자들은 각각이 특정 분야에 특화된 인공지능 모델을 개발한 후 스토어 서버를 통하 여 배포할 수 있다. 상술한 바와 같이 스마트 카메라의 사용자들이 원하는대로 선택적으로 인공지능 모델 을 스마트 카메라에 설치하여 영상 분석 등에 활용할 수 있을 것이다. 사용자는 스토어 서버에 접속하여, 스토어 서버에 저장되어 있는 적어도 하나의 인공지능 모델들을 확인하고, 자신이 사용하고자 하는 인공지능 모델을 선택하여 스마트 카메라 또는 클라우드 서버에 설치하여 실행시킬 수 있을 것이다. 사용자 단말은 스마트 카메라 또는 클라우드 서버에 접속하여, 스마트 카메라 또는 클라우 드 서버에 대한 설정을 수행할 수 있다. 이를 위해서 스마트 카메라 또는 클라우드 서버는 사용 자 단말에 사용자 인터페이스(인터넷 브라우저 등을 통하여)를 제공하거나, 사용자 단말에 설치된 별 도의 어플리케이션을 통하여 사용자로부터 설정 입력을 수신할 수 있을 것이다. 사용자는 사용자 단말을 통하여 스마트 카메라 또는 클라우드 서버에 설치되고 실행되는 인공지 능 모델을 선택할 수 있다. 사용자 단말은 스토어 서버에 접속하여, 스토어 서버에 저장되어 있 는 적어도 하나의 인공지능 모델을 확인한 후, 디스플레이를 통하여 사용자에게 출력해 줄 수 있다. 사용자는 출력된 적어도 하나의 인공지능 모델을 확인한 후, 스마트 카메라 또는 클라우드 서버에 설치하고자 하는 인공지능 모델을 선택하여 설치할 수 있을 것이다. 이하 도 2를 참고하여, 스마트 카메라의 구체적인 구성을 좀 더 상세히 설명한다. 도 2는 본 발명의 일실시예에 따른 스마트 카메라의 블록도를 도시하는 도면이다. 본 발명의 일실시예에 따른 스마트 카메라는, 제어부, 통신부, 전원부, FPGA 블록, 메모리, 이미지 센서, 인코더 및 카메라 학습부를 포함하도록 구성될 수 있다. 도 2에 도 시된 구성요소들은 스마트 카메라를 구현하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설명되 는 스마트 카메라는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 제어부는 통상적으로 스마트 카메라의 전반적인 동작을 제어한다. 제어부는 스마트 카메라(10 0)의 구성요소들을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리하거나 메모리에 저장된 응용 프로그램을 구동함으로써, 사용자에게 적절한 정보 또는 기능을 제공 또는 처리할 수 있다. 통신부는 스마트 카메라와 유무선 통신 시스템 사이, 스마트 카메라와 적어도 하나의 일반 카메 라(100') 사이, 또는 스마트 카메라와 클라우드 서버 사이의 유무선 통신을 가능하게 하는 하나 이상 의 모듈을 포함할 수 있다. 또한, 상기 통신부는, 스마트 카메라를 하나 이상의 네트워크에 연결하는하나 이상의 모듈을 포함할 수 있다. 전원부는 제어부의 제어 하에서, 외부의 전원, 내부의 전원을 인가 받아 스마트 카메라에 포함 된 각 구성요소들에 전원을 공급한다. 이러한 전원부는 배터리를 포함하며, 상기 배터리는 내장형 배터리 또는 교체가능한 형태의 배터리가 될 수 있다. FPGA 블록은 인공지능 모델을 탑재(deploy)시키고, 탑재된 인공지능 모델을 실행 및 가속화시키기 위한 구 성이다. FPGA 블록에는 인코더(204-1), 디코더(204-2) 및 ML(Machine learning)(204-3) 서브 블록이 포함 되도록 구성될 수 있다. 메모리는 스마트 카메라의 다양한 기능을 지원하는 데이터를 저장한다. 메모리는 스마트 카메라 에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 스마트 카 메라의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 또한 이러한 응용 프로그램 중 적어도 일부는, 스마트 카메 라의 기본적인 기능(예를 들어, 전화 착신, 발신 기능, 메시지 수신, 발신 기능)을 위하여 출고 당시부터 스마트 카메라상에 존재할 수 있다. 한편, 응용 프로그램은, 메모리에 저장되고, 스마트 카메라 상에 설치되어, 제어부에 의하여 상기 스마트 카메라의 동작(또는 기능)을 수행하도록 구동될 수 있 다. 특히 본 발명의 일실시예에 따른 메모리는 인공지능 모델을 탑재하기 위한 DPU(Data processing unit)를 더 포함하도록 구성될 수 있다. 이미지 센서는 정지영상 또는 동영상 등의 화상 프레임을 처리한다. 처리된 화상 프레임은 메모리에 저장되거나, 통신부를 통하여 클라우드 서버로 전송될 수 있다. 인코더는 이미지 센서에 의해서 처리된 화상 프레임이 메모리에 저장되기 전에, 화상 프레임에 대한 인코딩을 수행한다. 상기 각 구성요소들 중 적어도 일부는, 이하에서 설명되는 다양한 실시 예들에 따른 스마트 카메라의 동작, 제어, 또는 제어방법을 구현하기 위하여 서로 협력하여 동작할 수 있다. 또한, 상기 스마트 카메라 의 동작, 제어, 또는 제어방법은 상기 메모리에 저장된 적어도 하나의 응용 프로그램의 구동에 의하여 스 마트 카메라 상에서 구현될 수 있다. 카메라 학습부는 스마트 카메라에 설치된 인공지능 모델에 대한 학습을 수행하는 구성이다. 이때 카 메라 학습부는 지도 학습(supervised learning)을 통하여 인공지능 모델을 훈련시킬 수 있다. 지도 학습이 란, 입력값과 그에 따른 출력값이 있는 데이터를 이용하여 주어진 입력에 맞는 출력을 찾는 학습을 의미한다. 도 3은 본 발명의 일실시예에 따른 스마트 카메라의 계층별 세부 구조를 도시하는 도면이다. 도시된 도면을 참고하면, 스마트 카메라는 어플리케이션 계층, 미들웨어 계층, OS(Operation system) 계층, 하드웨어 계층으로 구성되나, 반드시 이에 한정되는 것은 아니다. 어플리케이션 계층은, 서비스 POD(301-1) 및 에이전트 POD(301-2)으로 구성될 수 있다. 포드(POD)란, 컨테 이너 오케스트레이션 플랫폼 상에서 어플리케이션의 최소 단위를 의미할 수 있다. 예를 들어 컨테이너 오케스트 레이션 플랫폼의 POD일 수 있다. 여러 개의 컨테이너로 구성된 포드도 있고, 단일 컨테이너로만 이루어진 포드도 있다. 컨테이너를 포드로 그룹 화하는 이유는 리소스를 더 지능적으로 공유하기 위해서입니다. 포드에 속한 컨테이너끼리 동일한 컴퓨팅 리소스를 공유할 수 있다. 이러한 컴퓨팅 리소스를 쿠버네티스에 풀링 하여 클러스터를 만들고, 이를 바탕으로 지능적으로 분산된 애플리케이션 실행 시스템을 제공할 수 있다. 서비스 POD(301-1)는 서비스 어플리케이션을 실행하기 위한 구성으로, 서비스 어플리케이션을 제공하기 위한 적 어도 하나의 라이브러리를 포함할 수 있다. 도시된 도면에서는, 파이토치(Pytorch) 라이브러리와 텐서플로우 (TensorFlow) 라이브러리를 포함하고 있으나, 이는 예시에 불과할 뿐 본 발명이 이에 한정되는 것은 아닐 것이다.에이전트 POD(301-2)는, FW 업데이트 에이전트 및 Mgmt 에이전트를 포함하도록 구성될 수 있다. FW 업데이트 에이전트(Firmware update agent)는 카메라 시스템의 \"Bootloader/OS(Kernel 및 Library)\" 업그레 이드 기능을 제공한다. 에이전트에 제공되는 바이너리는 각 디바이스 DNA기반으로 서명된 형태로 전달된다. Dev Mgmt agent는 서비스를 제공하는 Service app, M/L model update 및 Camera 설정 기능을 제공한다. Mgmt 에이전트는 디바이스 DNA 를 기반으로 인증 절차를 진행하는 디바이스 등록 기능을 제공한다. 미들웨어 계층은, 멀티미디어 프레임워크, 디바이스 런타임 라이브러리 및 AI(Artificial Intelligence) 라이브러리를 포함하도록 구성될 수 있다. 멀티미디어 프레임워크는 이미지 센서로부터 촬영되는 영상을 실시간 스트리밍으로 관리하기 위한 미들웨어로, 실시간 스트리밍 프로토콜(Real Time Streaming Protocol, RTSP)에 기초하여 동작한다. 실시간 스트리밍 프로토 콜은 스트리밍 미디어 서버를 제어할 목적으로 엔터테인먼트, 통신 시스템에 사용하도록 설계된 네트워크 프로 토콜이다. 디바이스 런타임 라이브러리란, 스마트 카메라가 실행되는 동안 컴파일러가 사용하기 위한 기능을 구성한 다. AI 라이브러리는, 인공지능 모델을 구성 및 학습하기 위한 기능을 구성하는 역할을 수행한다. OS 계층은 디바이스 드라이버, 비디오/오디오 블록 및 네트워크 블록을 포함하도록 구성될 수 있다. 디바이스 드라이버는 스마트 카메라를 구성하기 위한 적어도 하나의 하드웨어 구성을 제어하기 위한 소프 트웨어를 의미한다. 비디오/오디오 블록은 스마트 카메라에서 다루는 비디오와 오디오를 처리하기 위한 구성이다. 네트워크 블록은 스마트 카메라의 데이터 송수신을 처리하기 위한 구성을 의미한다. 하드웨어 계층은 FPGA SoM(System-on-Modules), 이미지 센서 모듈, 무선 모듈 및 I/O 블록을 포함한다. FPGA SoM(System-on-Modules)은, 도 2의 FPGA 블록을 구현하기 위한 구성으로, 인공지능 모델의 탑재 및 가속화를 지원한다. 이미지 센서 모듈은, 정지영상 또는 동영상 등의 화상 프레임을 처리하기 위한 구성이다. 무선 모듈은 스마트 카메라의 무선 통신을 지원하기 위한 모듈을 의미한다. I/O 블록은, 스마트 카메라의 I/O 인터페이스를 구성하기 위한 역할을 수행한다. 이하, 도 4를 참고하여 클라우드 서버의 구체적인 구성에 대해서 구체적으로 설명한다. 도 4는 본 발명의 일실시예에 따른 클라우드 서버의 블록도를 도시하는 도면이다. 본 발명의 일실시예에 따른 클라우드 서버는, 프로세서, 서버 메모리, 서버 학습부 및 서 버 통신부를 포함하도록 구성될 수 있다. 도 4에 도시된 구성요소들은 클라우드 서버를 구현하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설명되는 클라우드 서버는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 서버 메모리는 프로세서에 의해 실행 가능한 하나 이상의 명령어를 저장한다. 서버 메모리는, 클라우드 서버에 탑재되고 실행되는 적어도 하나의 인공지능 모델을 저장할 수 있다. 프로세서는 서버 메모리에 저장된 하나 이상의 명령어를 실행한다. 프로세서는 명령어를 실행하 는 것에 의해 본 발명의 상세한 설명에서 설명되는 하나 이상의 동작을 실행할 수 있다. 서버 학습부는, 스마트 카메라 또는 클라우드 서버에 탑재된 적어도 하나의 인공지능 모델에 대 한 학습을 수행한다. 특히, 서버 학습부는 스마트 카메라에 탑재되어 있는 인공지능 모델을 학습하고, 학습에 의해서 업데이트된 인공지능 모델을 다시 스마트 카메라에 탑재시킴으로써 주기적 또는 비주기적으로 스마트 카메라의 인공지능 모델을 업데이트시킬 수 있다. 서버 통신부는 적어도 하나의 스마트 카메라, 일반 카메라(100'), 스토어 서버 및 사용자 단말 중 적어도 하나와 데이터를 주고 받기 위한 모듈을 구비한다. 이어서 본 발명의 스마트 카메라 시스템의 제어 순서도에 대해서 도 5a 및 도 5b를 참고하여 설명한다. 도 5a 및 도 5b는 본 발명의 일실시예에 따른 스마트 카메라 시스템의 제어 순서도를 도시하는 도면이다. 도 5a는 스마트 카메라에 구비되는 \"카메라용 모델\"만을 사용한 경우를 도시하며, 도 5b는 스마트 카메라 및 클라우드 서버에 구비되는 \"서버용 모델\"을 함께 사용하는 경우를 도시한다. 먼저 도 5a의 순서도를 먼저 설명한다. 스토어 서버는 사용자 단말에게 자신이 저장하고 있는 적어도 하나의 인공지능 모델의 목록을 제공 (S501)한다. 사용자 단말은 제공 받은 적어도 하나의 인공지능 모델의 목록 및 각 인공지능 모델에 대한 상세 정보를 사용자에게 출력하고, 사용자로부터 선택 입력을 수신(S502)할 수 있다. 그리고 사용자 단말은 스토어 서버에게 선택 입력에 의해서 선택된 인공지능 모델이 무엇인지를 나타 내는 선택 정보를 스토어 서버에게 전달(S503)한다. 선택 정보를 수신한 스토어 서버는, 사용자에 의해서 선택된 인공지능 모델을 제 1 및 제 2 스마트 카메라 (100-1, 100-2) 각각에게 전송(S504-1, S504-2)한다. 도시된 예시에서는 하나의 선택 입력에 기초하여, 제 1 및 제 2 스마트 카메라(100-1, 100-2) 각각에게 전송되 는 인공지능 모델이 선택되는 것으로 설명하였지만, 반드시 이에 한정되는 것은 아니다. 즉, 사용자는 제 1 및 제 2 스마트 카메라(100-1, 100-2) 각각에 탑재시키기 위한 인공지능 모델을 각각 선택하여 탑재시킬 수 있을 것이다. 그리고 제 1 및 제 2 스마트 카메라(100-1, 100-2)는 전송 받은 인공지능 모델을 탑재(S505)시킨다. 본 발명의 일실시예에 따른 탑재(deploy)란, 인공지능 모델이 분석을 수행할 수 있도록 저장하고, 실제 분석을 수행할 수 있도록 요구되는 다양한 준비 프로세스 및 설정을 수행하는 것을 의미할 수 있다. 본 발명의 일실시예에 따른 스마트 카메라 및 스마트 카메라 시스템은, 사용자가 선택한 복수 개의 스 마트 카메라 간에 그룹을 형성하고, 그룹에 속한 스마트 카메라들 간에 인공지능 분석을 협업하도록 제안한다. 예를 들어, 하나의 그룹 내에서 '화재 감시'를 위한 제 1 인공지능 모델과 '얼굴 감지'를 위한 제 2 인공지능 모델이 동시에 요구된다고 가정한다. 이때, 그룹에 속해 있는 스마트 카메라 각각이 제 1 및 제 2 인공지능 모 델을 함께 구비하는 것은 어렵거나, 적어도 효과적이지 않을 수 있다. 왜냐하면 일반적으로 스마트 카메라(10 0)는 소형이며, 상대적으로 낮은 메모리와 상대적으로 낮은 연산 수준의 프로세서가 예상되기 때문이다. 즉, 하나의 스마트 카메라에 제 1 및 제 2 인공지능 모델이 동시에 탑재되기 어려울 뿐만 아니라, 탑재가 된다고 하더라도 실시간으로 촬영되는 영상에 대한 분석을 수행하는데 있어서, 프로세서 성능 상 제 1 및 제 2 인공지능 모델을 함께 실행시키는 것이 어려울 수 있다. 이에 따라, 본 발명의 일실시예에서는 그룹에 속한 스마트 카메라 각각이 서로 다른 인공지능 모델을 탑재하되, 스트리밍 형태로 영상의 공유를 통하여 인공지능 분석을 협업하도록 제안하는 것이다. 그 후, 제 1 및 제 2 스마트 카메라(100-1, 100-2)는 이미지 센서를 통하여 촬영되는 영상에 대하여 실시 간 처리를 수행(S506)할 수 있다. 처리되는 실시간 영상은 스트리밍 형태로 공유(S507)된다. 본 발명의 일실시예에 따른 공유란, 실시간으로 촬영한 영상을 타 스마트 카메라에 전송하는 것을 의미할 수 있 다. 또한, 타 스마트 카메라에서 실시간으로 촬영된 영상을 수신 받을 수 있을 것이다. 도 5에 도시된 예시에서 제 1 스마트 카메라(100-1)에서 촬영된 실시간 영상이 제 2 스마트 카메라(100-2)에게 전송될 수 있으며, 반대 로 제 2 스마트 카메라(100-2)에서 촬영된 실시간 영상이 제 1 스마트 카메라(100-1)에게 전송될 수 있다. 제 1 및 제 2 스마트 카메라(100-1, 100-2)는 자신이 촬영하는 영상뿐만 아니라 스트리밍 형태로 공유되는 영상 에 대하여 분석(S508)을 수행한다. 이때 각자 탑재하고 있는 인공지능 모델에 기초하여 분석을 수행할 수 있을 것이다. 예를 들어, 제 1 스마트 카메라(100-1)가 탑재하는 제 1 인공지능 모델에 기초하여, 자신이 촬영한 실시간 영상 에 대한 분석뿐만 아니라, 제 2 스마트 카메라(100-2)로부터 공유 받은 영상에 대한 분석을 수행할 수 있을 것 이다. 제 2 스마트 카메라(100-2)에 탑재되는 제 2 인공지능 모델에 대해서도 마찬가지 동작이 수행될 수 있을 것이다. 분석이 완료되면, 제 1 및 제 2 스마트 카메라(100-1, 100-2)는 영상 분석 결과를 공유(S509)할 수 있다. 그리 고, 사용자 단말에게도 영상 분석 결과를 제공(S510)할 수 있을 것이다. 도 5b의 순서도를 설명한다. 도 5b의 제어 순서도에서는, 하나의 스마트 카메라인 경우를 예시로 설명하지만, 두 개 이상의 스마트 카 메라(100-1, 100-2, ...)로 구성될 수 있음은 상술한 바와 같다. 먼저 스마트 카메라와 클라우드 서버 각각은 인공지능 모델을 탑재(S511)할 수 있다. 보다 구체적으 로 스마트 카메라는 '카메라용 모델'을 탑재하고, 클라우드 서버는 '서버용 모델'을 탑재할 수 있다. 스토어 서버로부터 모델을 선택하고 전송 받는 프로세스는, 상술한 도 5a의 S501 ~ S504 단계와 동일할 수 있다. 스마트 카메라는 이미지 센서를 통하여 촬영되는 영상에 대하여 실시간 처리를 수행(S512)할 수 있다. 그리고 실시간으로 처리되는 영상에 대하 1차 분석을 수행(S513)한다. 이어서 스마트 카메라는 1차 분석 결과에 기초하여, 2차 분석이 필요한지 여부를 판단(S514)한다. 상술한 바와 같이 '카메라용 모델'은 상대적으로 작은 사이즈의 인공지능 모델일 수 있다. '카메라용 모델'만으 로 충분하게 분석이 될 수도 있지만, 경우에 따라서 보다 큰 사이즈의 모델이 요구되는 경우가 있을 수 있다. 이를 위해서 본 발명의 일실시예에서는, 보다 큰 사이즈의 모델인 '서버용 모델'의 보조가 필요한 경우, 클라우 드 서버로 전송하여 추가 분석을 수행하도록 제안한다. 본 발명의 일실시예에 따른 2차 분석이 필요한지 여부의 판단은, 1차 분석 결과가 명확하지 않은 경우 2차 분석 이 필요한 것으로 판단할 수 있다. 본 발명의 다른 실시예에 따른 2차 분석이 필요한지 여부의 판단은, 1차 분석 결과와는 상관 없이, 항상 2차 분 석을 수행하도록 판단할 수 있다. 즉, S514 단계를 생략하고 바로 영상을 전송(S515)시킬 수 있다. 영상을 전송 받은 클라우드 서버는, 영상에 대한 2차 분석을 수행(S516)한다. 그리고 2차 분석 결과를 스 마트 카메라에게 회신한다.도 5a 및 도 5b의 순서도에서는 두 개의 스마트 카메라(100-1, 100-2)의 제어 순서를 기준으로 설명하였지만, 그 이상의 스마트 카메라에도 본 발명이 적용될 수 있음은 자명할 것이다. 도 5b에서 설명한 실시예에 따르면, 각 스마트 카메라는 적어도 하나의 인공지능 모델을 가지고 있으며, 타 스 마트 카메라에서 촬영된 영상 분석까지 처리하여, 외부와의 네트워크 연결(인터넷 연결 등) 없이도 보안 기능을 수행할 수 있을 것이다. 이어서, 도 6 및 도 7을 참고하여 보다 구체적인 실시예를 설명한다. 도 6은 본 발명의 일실시예에 따른 스마트 카메라 시스템의 일예시를 도시하는 도면이다. 도 7은 도 6의 예 시에서의 매장 전면 스마트 카메라(100-1) 및 매장 후면 스마트 카메라(100-3)의 협업 제어 순서도를 도시하는 도면이다. 도 6에 도시된 실시예에 따르면, 스마트 카메라 시스템은 매장(커피숍이나 식당 등)의 전면에 배치되는 매 장 전면 스마트 카메라(100-1), 매장 내에 배치되는 매장 내부 스마트 카메라(100-2) 및 매장 후면에 배치되는 매장 후면 스마트 카메라(100-3)를 하나의 그룹으로써 제어 및 관리할 수 있다. 각 스마트 카메라는, 적어도 하나의 인공지능 모델을 구비하여 각기 필요한 기능을 지원할 수 있다. 각 스마트 카메라는 자신이 구비하는 적어도 하나의 인공지능 모델을 이용하여 다른 스마트 카메라의 영상까지 분석 처리 할 수 있다. 특히, 스마트 카메라 시스템이 별도의 외부 네트워크 망(인터넷 망)에 연결되지 않거나 연결이 끊어진다고 하더라도, 각 스마트 카메라가 구비(탑재)하는 적어도 하나의 인공지능 모델을 이용하여 영상을 분 석하여 보안 기능을 수행할 수 있을 것이다. 도 6에 도시된 예시에서, 매장 전면 스마트 카메라(100-1)는 가상 펜스(virtual fence) 기능을 수행하는 인공지 능 모델(이하 가상 펜스 모델)을 구비(탑재)할 수 있다. 가상 펜스 기능이란, 카메라가 촬영하는 공간에 가상의 펜스(울타리)를 형성하고, 카메라를 통하여 촬영되는 영 상을 실시간으로 분석하여 가상의 펜스를 넘거나 침범하는 사람을 감지하는 기능을 의미한다. 이때, 이와 같은 사람이 감지되면 사용자에게 알림을 출력해 주거나, 침범하는 사람에게 경고를 할 수 있다. 매장 내부 스마트 카메라(100-2)는 화재 감시 기능을 구비하는 인공지능 모델(이하, 화재 감시 모델)을 탑재할 수 있다. 그리고 매장 외부 스마트 카메라(100-3)는 사람 감지 기능을 구비하는 인공지능 모델(사람 감지 모 델)을 탑재할 수 있다. 도 6의 예시를 참고하면, 각 스마트 카메라(100-1 ~ 100-3)는 아래와 같은 기능이 요구될 수 있다. 매장 전면 스마트 카메라(100-1) 및 매장 후면 스마트 카메라(100-3)는 주간에 사람 식별 기능 및 식별된 사람 의 경로를 추적하는 경로 추적 기능을 수행하고, 야간에는 출입문의 보안과 관련된 기능(가상 펜스, 객체 인식 기능, 오디오 모니터링 등)을 수행할 수 있다. 매장 내부 스마트 카메라(100-2)는 주간에 사람 식별 기능 및 식별된 사람의 경로를 추적하는 경로 추적 기능을 수행하고, 야간에는 실내 보안과 관련된 기능(객체 인식 기능, 오디오 모니터링 및 화재 감시)을 수행할 수 있 다. 즉, 이와 같은 예시에서 매장 전면 스마트 카메라(100-1)는, 자신이 탑재하는 가상 펜스 모델 외에 화재 감시 모델이나 사람 감지 모델은 구비하고 있지 않는다. 하지만, 매장 전면 스마트 카메라(100-1)로부터 촬영되는 영 상에서도, 사람이 감지되는지 여부를 확인할 필요성이 존재할 것이다. 도 7을 참고하면, S701-1 및 S701-2 단계에서 매장 전면 스마트 카메라(100-1) 및 매장 후면 스마트 카메라 (100-2) 각각은 가상 펜스 모델 및 사람 인식 모델을 탑재할 수 있다. 그리고 매장 전면 스마트 카메라(100-1)는 실시간으로 영상을 촬영(S702)하며, 촬영되는 영상을 스트리밍 형태 로 공유(S703)한다. 스트리밍 형태로 영상을 공유 받은 매장 후면 스마트 카메라(100-3)는, 전송 받은 영상과 자신이 촬영하는 영상 에 대해서 모두 사람 인식 영상 분석(S704)을 수행한다. 사람 인식 영상 분석이란, 사람 인식 모델에 기초하여 영상 내에서 사람이 존재하는지 여부, 사람의 골격, 행동이나 경로 중 적어도 하나를 식별하는 분석을 의미할 수 있다. 이어서, 매장 후면 스마트 카메라(100-3)는 S704 단계에서의 분석 결과를 매장 전면 스마트 카메라(100-1)에게 회신(S705)해 줄 수 있다. 이때, 그룹 내에 속한 다른 스마트 카메라에게 공유해 줄 수도 있을 것이다. S704에서의 분석 결과는, 인식된 사람의 식별 정보, 인식된 위치(매장 내에서의 지점) 정보, 인식된 사람의 이 동 경로 정보 및 인식된 사람의 행동 정보 중 적어도 하나를 포함할 수 있다. 본 발명의 일실시예에서는, 타 스 마트 카메라로부터 회신 받은 분석 결과를 더 고려하여, 영상 분석을 수행하도록 제안한다. 도 7에서 도시된 실시예에서, 사람을 인식한 분석 결과는 해당 영상 내에서 가상 펜스 분석을 수행하는데 있어 서 활용될 수 있을 것이다. 예를 들면, 인식된 사람의 옷차림 등의 정보(옷차림의 색깔 등)를 이용하여, 어두운 곳에서 가상 펜스 기능을 활용하는데 있어서 해당 옷차림의 색깔을 강조하여 살펴볼 수 있을 것이다. 이처럼, 스마트 카메라 간에 분석 결과를 공유하는 방식을 통하여, 서로 영상을 분석하는데 정확도를 향상시킬 수 있을 것이다. 도 7의 매장 전면 스마트 카메라(100-1)는 영상 분석 결과를 회신하면, 회신 결과를 참고하여 가상 펜스 모델을 기초로 가상 펜스 영상을 분석(S706)할 수 있다. 도시된 제어 실시예에서와 같이, 매장 전면 스마트 카메라(100-1)는 '가상 펜스 모델'만을 구비하고 있지만, 매 장 전면 스마트 카메라(100-1)를 통하여 촬영되는 영상에 대해서도 다른 인공지능 모델(사람 인식 내지 화재 감 시)을 활용한 분석이 가능하다는 장점이 존재한다. 더 나아가, 도시된 예시에서의 스마트 시스템을 구성하 는 그룹은 외부 네트워크 망(인터넷 망)과 연결되어 있지 않다고 하더라도, 즉 클라우드 서버와 통신 없이도, 자체적으로 구비하는 인공지능 모델에 기초하여 영상 분석을 지속적으로 수행할 수 있을 것이다. 도 7의 제어 순서도에서는, 매장 전면 스마트 카메라(100-1)에서 촬영되는 영상을 매장 후면 스마트 카메라 (100-3)에 공유하여 분석하는 예시를 들어 설명하였지만, 이에 한정되지 않고 타 스마트 카메라에서 촬영된 영 상이 공유되어 분석되는 것이 본 발명의 실시예에 포함될 수 있을 것이다.도 8은 본 발명의 일실시예에 따른 스마트 카메라 시스템의 다른 예시를 도시하는 도면이다. 도 8에 도시된 실시예에 따르면, 스마트 카메라 시스템은 주차장 등의 입구에 배치되는 주차장 입구 스마트 카메라(100-1) 및 주차장 내에 배치되는 주차장 내부 스마트 카메라(100-2, 100-3)를 하나의 그룹으로써 제어 및 관리할 수 있다. 도시된 예시에서는 외부 주차장을 예로 들고 있지만, 건물 내부나 다양한 형태의 주차 공간에도 동일하게 적용 할 수 있을 것이다. 도 8의 실시예에서도 마찬가지로 각 스마트 카메라는, 적어도 하나의 인공지능 모델을 구비하여 각기 필요한 기 능을 지원할 수 있다. 각 스마트 카메라는 자신이 구비하는 적어도 하나의 인공지능 모델을 이용하여 다른 스마 트 카메라의 영상까지 분석 처리할 수 있다. 먼저 도 8에 도시된 예시에서, 주차장 입구 스마트 카메라(100-1)는 출입 객체 감지(Object detection) 기능을 수행하는 인공지능 모델(이하 객체 감지 모델)을 구비(탑재)할 수 있다. 주차장 입구 스마트 카메라(100-1)는 객체 감지 모델을 통하여, 주차장의 입구로 진입하는 객체(차량 등)를 감 지하고, 그에 맞는 동작을 수행할 수 있을 것이다. 예를 들어, 진입하는 차량의 종류 및 번호판을 감지하고, 차 단봉을 올리도록 제어할 수 있을 것이다. 주차장 내부 스마트 카메라(100-2, 100-3)는 주차 공간 관리 기능을 구비하는 인공지능 모델을 탑재할 수 있다. 주차 공간 관리 기능이란, 주차면이 비어있는지 여부, 차량이 주차면(주차 라인)에 제대로 주차를 했는지 여부 를 감지하고 알림이나 경고를 출력하는 기능 등을 포함한다. 상술한 바와 같이 특정 스마트 카메라에 탑재되는 인공지능 모델의 기능이 실질적으로 타 스마트 카메라에 공유 되는 효과가 있을 수 있다. 하지만 많은 수의 스마트 카메라로부터 촬영되는 영상을 하나의 인공지능 모델 내지 하나의 스마트 카메라 내에 서 분석하는 것이 쉽지 않을 수 있다. 왜냐하면 하나의 스마트 카메라 내에서 분석할 수 있는 양은 한정적일 수 있는데, 많은 수의 스마트 카메라에서 촬영되는 영상을 모두 분석하는 것은 많은 프로세스가 요구될 수 있기 때 문이다. 따라서 본 발명의 일실시예에 따른 스마트 카메라 시스템은, 인공지능 모델을 적용하는데 있어서 실제 촬영 된 영상을 분석하는 것이 아니라, 촬영된 영상을 인코딩하여 분석하도록 제안한다. 영상 분석을 수행하는데 있 어서 요구되는 프로세스를 줄이기 위해서이다. 이러한 실시예에 대해서 도 9를 참고하여 설명한다. 도 9는 본 발명의 일실시예에 따라, 영상 분석을 수행하기 전에 인코딩을 수행하는 제어 순서를 도시한다. 도 9를 참고하면, S901-1 및 S901-2 단계에서 제 1 스마트 카메라(100-1) 및 제 2 스마트 카메라(100-2) 각각 은 제 1 및 제 2 인공지능 모델을 탑재할 수 있다. 그리고 제 1 스마트 카메라(100-1) 및 제 2 스마트 카메라(100-2) 각각은 실시간으로 영상을 촬영(S902)하며, 촬영된 영상에 대해서 인코딩(S903)을 수행할 수 있다. 본 발명의 일실시에에 따른 인코딩이란, 촬영된 영상의 용량을 줄일 수 있는 다양한 종류의 동작을 모두 포함할 수 있다. 예를 들어, 인코딩은, 촬영된 영상의 프레임이 60fps일 때, 10fps로 줄이는 것을 포함할 수 있다. 도 10을 참고하여, 인코딩의 예시를 설명한다. 도 10은 본 발명의 일실시예에 따른 인코딩의 개념도를 도시하는 도면이다. 도시된 도면을 참고하면, 제 1 내제 제 4 스마트 카메라(100-1 ~ 100-4)로부터 촬영되는 제 1 내지 제 4 영상 프레임(1001-1 ~ 1001-4)가 도시된다. 각 영상 프레임은 n 번째 프레임에서부터 n + 19 번째 프레임(총 20개의 프레임)이 도시된다. 이러한 인코딩 프로세스 일부 내지 전체는, 제 1 내제 제 4 스마트 카메라(100-1 ~ 100-4) 각각에서 수행될 수 있을 것이다. 본 발명의 일실시예에 따른 인코딩은, 전체 영상 프레임 중에서 일부 프래임을 제거하는 방식으로 수행될 수 있 다. 도 10에 도시된 예시에서와 같이, n + 4p(p는 자연수)의 프레임만을 유지시키고 나머지 프레임은 삭제시킬 수 있을 것이다. 특히 본 발명의 일실시예에서는 실시간으로 영상을 분석할 수 있도록, 복수 개의 스마트 카메라로부터 촬영된 영상을 인코딩하고, 인코딩 된 영상들을 하나로 통합하여 합성 스트리밍 영상를 생성하도록 제안한다. 합 성 스트리밍 영상은 기존 스트리밍 영상과 동일한 프레임 레이트로 생성되어, 기존 스트리밍 영상과 동일 하게 취급하여 영상 분석을 수행할 수 있을 것이다. 즉, 이렇게 생성된 합성 스트리밍 영상은 인공지능 모델의 입력으로 제공될 수 있을 것이다. 이를 위해서, 본 발명에서는, 통합하기 위한 스트리밍 영상의 개수(즉, 현재 활성화되어 있는 스마트 카메라의 개수)를 S라고 하였을 때, n + (S * p)(p는 자연수)의 프레임을 추출하여 인코딩 할 수 있다. 즉, 도 10의 예시 에서 4 개의 스트리밍 영상이 통합(4개의 스마트 카메라가 활성화)되므로, n + 4p의 프레임이 추출되어 인코딩 (1002-1 ~ 1002-4)된다. 이를 위하여 제 1 내제 제 4 스마트 카메라(100-1 ~ 100-4) 각각은 통합이 필요한 스 트리밍 영상의 개수를 판단한 후, 위와 같은 인코딩을 수행할 수 있을 것이다. 제 1 영상 프레임(1001-1)에서 추출된 프레임으로 인코딩된 제 1 인코딩 프레임(1002-1)이 생성되며, 마찬가지 로 제 2 내지 제 4 영상 프레임(1001-2 ~ 1001-4)으로부터 인코딩된 제 2 내지 제 4 인코딩 프레임(1002-2 ~ 1002-4)이 생성될 수 있을 것이다. 본 발명의 일실시예에서는, 제 1 내지 제 4 인코딩 프레임(1002-1 ~ 1002-4)을 연속적으로 나열하는 방식으로 합성 스트리밍 영상을 형성할 수 있을 것이다. 한편 도시된 예시에서는 n ~ n + 19 프레임으로 총 20프레임을 가지고 합성을 하는 예시를 들어 설명하였지만, 이렇나 프레임의 개수에 본 발명이 한정되지는 않을 것이다. 다른 개수의 프레임으로 합성할 경우, 인코딩 프레 임을 구성하는 프레임의 개수가 도 10의 5개와 다를 수 있을 것이다. 이상으로 본 발명에 따른 스마트 카메라 및 그것의 제어 방법의 실시예를 설시하였으나 이는 적어도 하나의 실 시예로서 설명되는 것이며, 이에 의하여 본 발명의 기술적 사상과 그 구성 및 작용이 제한되지는 아니하는 것으 로, 본 발명의 기술적 사상의 범위가 도면 또는 도면을 참조한 설명에 의해 한정／제한되지는 아니하는 것이다. 또한 본 발명에서 제시된 발명의 개념과 실시예가 본 발명의 동일 목적을 수행하기 위하여 다른 구조로 수정하"}
{"patent_id": "10-2024-0074729", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "거나 설계하기 위한 기초로써 본 발명이 속하는 기술분야의 통상의 지식을 가진 자에 의해 사용되어질 수 있을"}
{"patent_id": "10-2024-0074729", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "것인데, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자에 의한 수정 또는 변경된 등가 구조는 청구범위에서 기술되는 본 발명의 기술적 범위에 구속되는 것으로서, 청구범위에서 기술한 발명의 사상이나 범위를 벗어나 지 않는 한도 내에서 다양한 변화, 치환 및 변경이 가능한 것이다."}
{"patent_id": "10-2024-0074729", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 스마트 카메라 시스템을 도시하는 도면이다. 도 2는 본 발명의 일실시예에 따른 스마트 카메라의 블록도를 도시하는 도면이다. 도 3은 본 발명의 일실시예에 따른 스마트 카메라의 계층별 세부 구조를 도시하는 도면이다. 도 4는 본 발명의 일실시예에 따른 클라우드 서버의 블록도를 도시하는 도면이다. 도 5a 및 도 5b는 본 발명의 일실시예에 따른 스마트 카메라 시스템의 제어 순서도를 도시하는 도면이다. 도 6은 본 발명의 일실시예에 따른 스마트 카메라 시스템의 일예시를 도시하는 도면이다. 도 7은 도 6의 예시에서의 매장 전면 스마트 카메라(100-1) 및 매장 후면 스마트 카메라(100-3)의 협업 제어 순 서도를 도시하는 도면이다. 도 8은 본 발명의 일실시예에 따른 스마트 카메라 시스템의 다른 예시를 도시하는 도면이다. 도 9는 본 발명의 일실시예에 따라, 영상 분석을 수행하기 전에 인코딩을 수행하는 제어 순서를 도시한다. 도 10은 본 발명의 일실시예에 따른 인코딩의 개념도를 도시하는 도면이다."}
