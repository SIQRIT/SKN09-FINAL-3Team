{"patent_id": "10-2020-0041025", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0123633", "출원번호": "10-2020-0041025", "발명의 명칭": "음성 명령에 대응하는 태스크를 수행하는 전자 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "최성환"}}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,외부로부터의 음성을 음성 데이터로 변환하는 마이크;통신 회로, 및상기 마이크 및 상기 통신 회로에 작동적으로 연결된 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는:상기 마이크로부터 수신한 상기 음성 데이터로부터, 상기 전자 장치의 음성 명령 기능을 트리거링하도록 설정된트리거 음성을 확인하고,외부 전자 장치로부터, 상기 통신 회로를 통하여, 상기 외부 전자 장치에서 상기 트리거 음성을 포함하는 컨텐트가 출력됨을 나타내는 정보를 포함하는 통신 신호를 획득하고,상기 통신 신호에 기반하여 상기 외부 전자 장치에서 상기 트리거 음성을 포함하는 컨텐트가 출력됨이확인되고, 상기 음성 데이터로부터 상기 트리거 음성이 확인되면, 상기 트리거 음성 이후에 상기 마이크로부터획득되는 추가 음성 데이터에 대한 처리를 스킵하도록 설정되는 전자 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,적어도 하나의 프로세서는, 상기 음성 데이터로부터 상기 트리거 음성이 확인되고, 상기 외부 전자 장치에서 상기 트리거 음성을 포함하는컨텐트가 출력됨이 확인되지 않음에 기반하여, 상기 트리거 음성 이후에 상기 마이크로부터 획득되는 상기 추가음성 데이터에 대한 처리를 수행하도록 설정되는 전자 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 추가 음성 데이터에 대한 처리는, 상기 추가 음성 데이터에 기반하여 명령을 획득하는 동작, 상기 획득된명령을 수행하는 동작, 또는 상기 획득된 명령을 다른 외부 전자 장치로 송신하는 동작 중 적어도 하나를 포함하는 전자 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 추가 음성 데이터에 대한 처리는,상기 추가 음성 데이터의 인식을 다른 외부 전자 장치로 요청하는 동작, 상기 요청에 대응하는 정보를 수신하는동작, 또는 상기 수신된 정보에 대응하는 동작을 수행하는 동작 중 적어도 하나를 포함하는 전자 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 적어도 하나의 프로세서는, 상기 트리거 음성 이후에 상기 마이크로부터 획득되는 상기 추가 음성 데이터에 대한 처리를 스킵하는 동작의 적어도 일부로,상기 통신 신호에 기반하여 상기 외부 전자 장치에서 상기 트리거 음성을 포함하는 컨텐트가 출력됨이 확인되는제 1 시점 및, 상기 음성 데이터로부터 상기 트리거 음성이 확인되는 제 2 시점 사이의 차이가 지정된 조건을공개특허 10-2021-0123633-3-만족함에 기반하여, 상기 추가 음성 데이터에 대한 처리를 스킵하도록 설정된 전자 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 적어도 하나의 프로세서는, 상기 트리거 음성 이후에 상기 마이크로부터 획득되는 상기 추가 음성 데이터에 대한 처리를 스킵하는 동작의 적어도 일부로,상기 통신 신호에 기반하여 상기 외부 전자 장치에서 상기 트리거 음성을 포함하는 컨텐트가 출력됨이확인되고, 상기 음성 데이터로부터 상기 트리거 음성이 확인되면, 상기 추가 음성 데이터의 처리 여부를 문의하는 메시지를 출력하고,상기 문의하는 메시지에 대응하여, 긍정의 응답의 확인 실패에 기반하여, 상기 추가 음성 데이터에 대한 처리를스킵하도록 설정된 전자 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 적어도 하나의 프로세서는,상기 문의하는 메시지에 대응하여, 상기 긍정의 응답이 확인됨에 기반하여, 상기 추가 음성 데이터를 처리하도록 더 설정된 전자 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 적어도 하나의 프로세서는, 상기 트리거 음성 이후에 상기 마이크로부터 획득되는 상기 추가 음성 데이터에 대한 처리를 스킵하는 동작의 적어도 일부로,상기 트리거 음성에 대응하는 제 1 말뭉치가 획득된 경우에는, 상기 트리거 음성에 응답하는 응답 음성의 출력을 스킵하고, 상기 추가 음성 데이터에 대응하는 제 2 말뭉치가 획득된 경우에 상기 추가 음성 데이터에 대한처리를 스킵하고, 또는상기 트리거 음성 및 상기 추가 음성 데이터를 포함하는 제 2 말뭉치가 획득되는 경우에는, 상기 추가 음성 데이터에 대한 처리를 스킵하도록 설정된 전자 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "미디어 장치에 있어서,전기적인 신호를 음성으로 변환하여 출력하는 스피커;통신 회로, 및상기 스피커 및 상기 통신 회로에 작동적으로 연결된 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는:미디어 파일을 획득하고,상기 미디어 파일에 대응하는 정보를 이용하여, 상기 미디어 파일에 대응하는 음성을 상기 스피커를 이용하여출력하도록 제어하고,상기 미디어 파일에 대응하는 음성에 미리 지정된 트리거 음성이 포함됨을 확인하고,상기 미디어 파일에 대응하는 음성에 상기 트리거 음성이 포함됨을 나타내는 정보를 포함하는 통신 신호를 외부전자 장치로 송신하도록 상기 통신 회로를 제어하도록 설정된 미디어 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,공개특허 10-2021-0123633-4-상기 적어도 하나의 프로세서는, 상기 미디어 파일에 대응하는 음성에 상기 트리거 음성이 포함됨을 확인하는동작의 적어도 일부로,상기 미디어 파일을 디코딩하여 디코딩된 신호를 확인하고,상기 디코딩된 신호에 음성 인식을 수행하여 텍스트를 확인하고,상기 확인된 텍스트가 상기 트리거 음성에 대응하는 텍스트와 대응되는지 여부를 확인하도록 설정된 미디어 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치에 있어서,외부로부터의 음성을 음성 데이터로 변환하는 마이크;통신 회로, 및상기 마이크 및 상기 통신 회로에 작동적으로 연결된 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는:상기 마이크로부터 수신한 상기 음성 데이터로부터, 명령을 확인하고,상기 통신 회로를 통하여, 외부 전자 장치에서 출력중인 미디어 파일에 대한 정보를, 상기 외부 전자 장치로부터 수신하고,상기 음성 데이터가 상기 외부 전자 장치에서 출력중인 미디어 파일에 대한 정보에 대응되는지 여부를확인하고,상기 음성 데이터가 상기 외부 전자 장치에서 출력중인 미디어 파일에 대한 정보에 대응되지 않으면, 상기 명령을 처리하고,상기 음성 데이터가 상기 외부 전자 장치에서 출력중인 미디어 파일에 대한 정보에 대응되면, 상기 명령의 처리를 스킵하도록 설정된 전자 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 적어도 하나의 프로세서는, 상기 음성 데이터가 상기 외부 전자 장치에서 출력중인 미디어 파일에 대한 정보에 대응되면, 상기 명령의 처리를 스킵하는 동작의 적어도 일부로,상기 음성 데이터가 상기 외부 전자 장치에서 출력중인 미디어 파일에 대한 정보가 획득되는 제 1 시점 및 상기음성 데이터로부터 상기 명령을 확인하는 제 2 시점 사이의 차이가 지정된 조건을 만족함에 기반하여, 상기 명령의 처리를 스킵하도록 설정된 전자 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11 항에 있어서,상기 적어도 하나의 프로세서는, 상기 음성 데이터가 상기 외부 전자 장치에서 출력중인 미디어 파일에 대한 정보에 대응되면, 상기 명령의 처리를 스킵하는 동작의 적어도 일부로,상기 음성 데이터가 상기 외부 전자 장치에서 출력중인 미디어 파일에 대한 정보에 대응되면, 상기 명령의 처리여부를 문의하는 메시지를 출력하고,상기 문의하는 메시지에 대응하여, 긍정의 응답의 확인 실패에 기반하여, 상기 명령에 대한 처리를 스킵하도록설정된 전자 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,공개특허 10-2021-0123633-5-상기 적어도 하나의 프로세서는,상기 문의하는 메시지에 대응하여, 상기 긍정의 응답이 확인됨에 기반하여, 상기 명령을 처리하도록 더 설정된전자 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 11 항에 있어서,상기 적어도 하나의 프로세서는, 상기 외부 전자 장치에서 출력중인 미디어 파일에 대한 정보를, 상기 외부 전자 장치로부터 수신하는 동작의 적어도 일부로,상기 출력중인 미디어 파일을 디코딩한 신호의 적어도 일부, 또는 상기 디코딩한 신호에 대응하는 텍스트의 적어도 일부 중 적어도 일부를 수신하도록 설정된 전자 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 11 항에 있어서,상기 적어도 하나의 프로세서는, 상기 외부 전자 장치에서 출력중인 미디어 파일에 대한 정보를, 상기 외부 전자 장치로부터 수신하는 동작의 적어도 일부로,상기 명령에 대응하는 서브 음성이 획득되는 시간 동안의 정보를 상기 외부 전자 장치로, 상기 통신 회로를 통하여 요청하고,상기 통신 회로를 통하여, 상기 요청에 응답하는 상기 외부 전자 장치에서 출력중인 미디어 파일에 대한 정보를수신하도록 설정된 전자 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "미디어 장치에 있어서,전기적인 신호를 음성으로 변환하여 출력하는 스피커;통신 회로, 및상기 스피커 및 상기 통신 회로에 작동적으로 연결된 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는:미디어 파일을 획득하고,상기 미디어 파일에 대응하는 정보를 이용하여, 상기 미디어 파일에 대응하는 음성을 상기 스피커를 이용하여출력하도록 제어하고,상기 통신 회로를 통하여, 상기 미디어 전자 장치에서 출력중인 미디어 파일에 대한 정보를, 외부 전자 장치로송신하도록 설정된 미디어 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 적어도 하나의 프로세서는, 상기 통신 회로를 통하여, 상기 미디어 전자 장치에서 출력중인 미디어 파일에대한 정보를, 외부 전자 장치로 송신하는 동작의 적어도 일부로,상기 출력중인 미디어 파일을 디코딩한 신호의 적어도 일부, 또는 상기 디코딩한 신호에 대응하는 텍스트의 적어도 일부 중 적어도 일부를 송신하도록 설정된 전자 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 17 항에 있어서,상기 적어도 하나의 프로세서는, 상기 통신 회로를 통하여, 상기 미디어 전자 장치에서 출력중인 미디어 파일에대한 정보를, 외부 전자 장치로 송신하는 동작의 적어도 일부로,공개특허 10-2021-0123633-6-상기 출력중인 미디어 파일에 대한 정보 중 제 1 시간 동안의 미디어 파일에 대한 정보의 요청을, 상기 통신 회로를 통하여 수신하고,상기 요청에 응답하여, 상기 제 1 시간 동안의 미디어 파일에 대한 정보를, 상기 통신 회로를 통하여, 상기 외부 전자 장치로 송신하도록 설정된 미디어 장치."}
{"patent_id": "10-2020-0041025", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "외부로부터의 음성을 음성 데이터로 변환하는 마이크, 통신 회로, 및 상기 마이크 및 상기 통신 회로에 작동적으로 연결된 적어도 하나의 프로세서를 포함하는 전자 장치의 동작 방법에 있어서,상기 마이크로부터 수신한 상기 음성 데이터로부터, 상기 전자 장치의 음성 명령 기능을 트리거링하도록 설정된트리거 음성을 확인하는 동작;외부 전자 장치로부터, 상기 통신 회로를 통하여, 상기 외부 전자 장치에서 상기 트리거 음성을 포함하는 컨텐트가 출력됨을 나타내는 정보를 포함하는 통신 신호를 획득하는 동작, 및상기 통신 신호에 기반하여 상기 외부 전자 장치에서 상기 트리거 음성을 포함하는 컨텐트가 출력됨이확인되고, 상기 음성 데이터로부터 상기 트리거 음성이 확인되면, 상기 트리거 음성 이후에 상기 마이크로부터획득되는 추가 음성 데이터에 대한 처리를 스킵하는 동작을 포함하는 전자 장치의 동작 방법."}
{"patent_id": "10-2020-0041025", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에 따른 전자 장치는, 외부로부터의 음성을 음성 데이터로 변환하는 마이크, 통신 회로, 및 상기 마이 크 및 상기 통신 회로에 작동적으로 연결된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 상기 마이크로부터 수신한 상기 음성 데이터로부터, 상기 전자 장치의 음성 명령 기능을 트리거링하 (뒷면에 계속)"}
{"patent_id": "10-2020-0041025", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시의 일 실시예는 음성 명령에 대응하는 태스크를 수행하는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2020-0041025", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공 지능 스피커가 활발하게 도입되고 있다. 인공 지능 스피커는, 생활 공간 곳곳에 배치되어 사용자로 부터의 음성 명령을 대기할 수 있다. 인공 지능 스피커는, 사용자의 호출 명령이 발생하면, 이에 응답할 수 있 다. 인공 지능 스피커가 응답한 이후, 사용자는 추가적으로 음성을 발화할 수 있다. 인공 지능 스피커는, 마 이크를 통하여 음성을 음성 데이터로 변환할 수 있다. 인공 지능 스피커는, 음성 데이터를 처리할 수 있으며, 처리 결과에 대응하는 동작을 수행할 수 있다. 예를 들어, 인공 지능 스피커는, 음성 인식을 수행하여 음성 인 식에 대응하는 태스크를 수행할 수 있다. 또는, 인공 지능 스피커는, 음성 인식 수행을 AI 서버에 요청할 수 있으며, AI 서버에서는 음성 인식에 대응하는 태스크를 수행하거나, 태스크를 수행하기 위한 동작에 대한 정보 를 인공 지능 스피커로 제공할 수 있다. 인공 지능 스피커는, 처리 결과를 음성으로 출력할 수 있다. 이에 따 라, 사용자는 음성 명령을 발화하고, 이에 대응하는 음성 응답을 청취할 수 있어, 대화를 통한 음성 명령 수행 이 가능할 수 있다."}
{"patent_id": "10-2020-0041025", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "인공 지능 스피커가 배치된 공간에 TV와 같은 음성을 출력하는 미디어 장치가 함께 배치될 수 있다. 예를 들어, 미디어 장치가 호출 명령 및/또는 음성 명령을 포함하는 음성을 출력할 수 있다. 이 경우, 인공 지능 스 피커는, 해당 음성이 사용자가 발화한 것인지 미디어 장치로부터 출력된 것인지를 구분할 수 없다. 이에 따라, 미디어 장치로부터 출력된 음성이 처리됨으로써, 사용자가 원하지 않는 태스크가 수행될 수 있다. 예를 들어, 미디어 장치에서, 특정 물품의 구매를 명령하는 음성이 출력되는 경우, 사용자가 원하지 않는 특정 물품의 구매 가 진행될 수도 있다. 본 개시의 다양한 실시예는, 미디어 장치로부터의 정보에 기반하여, 음성 명령의 처리 여부를 결정할 수 있는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2020-0041025", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따라서, 전자 장치는, 외부로부터의 음성을 음성 데이터로 변환하는 마이크, 통신 회로, 및 상기 마이크 및 상기 통신 회로에 작동적으로 연결된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로 세서는, 상기 마이크로부터 수신한 상기 음성 데이터로부터, 상기 전자 장치의 음성 명령 기능을 트리거링하도 록 설정된 트리거 음성을 확인하고, 외부 전자 장치로부터, 상기 통신 회로를 통하여, 상기 외부 전자 장치에서 상기 트리거 음성을 포함하는 컨텐트가 출력됨을 나타내는 정보를 포함하는 통신 신호를 획득하고, 상기 통신 신호에 기반하여 상기 외부 전자 장치에서 상기 트리거 음성을 포함하는 컨텐트가 출력됨이 확인되고, 상기 음 성 데이터로부터 상기 트리거 음성이 확인되면, 상기 트리거 음성 이후에 상기 마이크로부터 획득되는 추가 음 성 데이터에 대한 처리를 스킵하도록 설정될 수 있다. 일 실시예에 따라서, 미디어 장치는, 전기적인 신호를 음성으로 변환하여 출력하는 스피커, 통신 회로, 및 상기 스피커 및 상기 통신 회로에 작동적으로 연결된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로 세서는, 미디어 파일을 획득하고, 상기 미디어 파일에 대응하는 정보를 이용하여, 상기 미디어 파일에 대응하는 음성을 상기 스피커를 이용하여 출력하도록 제어하고, 상기 미디어 파일에 대응하는 음성에 미리 지정된 트리거 음성이 포함됨을 확인하고, 상기 미디어 파일에 대응하는 음성에 상기 트리거 음성이 포함됨을 나타내는 정보를 포함하는 통신 신호를 외부 전자 장치로 송신하도록 상기 통신 회로를 제어하도록 설정될 수 있다. 일 실시예에 따라서, 전자 장치는, 외부로부터의 음성을 음성 데이터로 변환하는 마이크, 통신 회로, 및 상기 마이크 및 상기 통신 회로에 작동적으로 연결된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로 세서는, 상기 마이크로부터 수신한 상기 음성 데이터로부터, 명령을 확인하고, 상기 통신 회로를 통하여, 외부 전자 장치에서 출력중인 미디어 파일에 대한 정보를, 상기 외부 전자 장치로부터 수신하고, 상기 음성 데이터가 상기 외부 전자 장치에서 출력중인 미디어 파일에 대한 정보에 대응되는지 여부를 확인하고, 상기 음성 데이터 가 상기 외부 전자 장치에서 출력중인 미디어 파일에 대한 정보에 대응되지 않으면, 상기 명령을 처리하고, 상 기 음성 데이터가 상기 외부 전자 장치에서 출력중인 미디어 파일에 대한 정보에 대응되면, 상기 명령의 처리를 스킵하도록 설정될 수 있다. 일 실시예에 따라서, 미디어 장치는, 전기적인 신호를 음성으로 변환하여 출력하는 스피커, 통신 회로, 및 상기 스피커 및 상기 통신 회로에 작동적으로 연결된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로 세서는, 미디어 파일을 획득하고, 상기 미디어 파일에 대응하는 정보를 이용하여, 상기 미디어 파일에 대응하는 음성을 상기 스피커를 이용하여 출력하도록 제어하고, 상기 통신 회로를 통하여, 상기 미디어 전자 장치에서 출 력중인 미디어 파일에 대한 정보를, 외부 전자 장치로 송신하도록 설정될 수 있다. 일 실시예에 따라서, 외부로부터의 음성을 음성 데이터로 변환하는 마이크, 통신 회로, 및 상기 마이크 및 상기 통신 회로에 작동적으로 연결된 적어도 하나의 프로세서를 포함하는 전자 장치의 동작 방법은, 상기 마이크로부 터 수신한 상기 음성 데이터로부터, 상기 전자 장치의 음성 명령 기능을 트리거링하도록 설정된 트리거 음성을 확인하는 동작, 외부 전자 장치로부터, 상기 통신 회로를 통하여, 상기 외부 전자 장치에서 상기 트리거 음성을 포함하는 컨텐트가 출력됨을 나타내는 정보를 포함하는 통신 신호를 획득하는 동작, 및 상기 통신 신호에 기반 하여 상기 외부 전자 장치에서 상기 트리거 음성을 포함하는 컨텐트가 출력됨이 확인되고, 상기 음성 데이터로 부터 상기 트리거 음성이 확인되면, 상기 트리거 음성 이후에 상기 마이크로부터 획득되는 추가 음성 데이터에 대한 처리를 스킵하는 동작을 포함할 수 있다."}
{"patent_id": "10-2020-0041025", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 다양한 실시예에 따라서, 미디어 장치로부터의 정보에 기반하여, 음성 명령의 처리 여부를 결정할 수 있는 전자 장치 및 그 동작 방법이 제공될 수 있다. 이에 따라, 미디어 장치로부터 출력된 음성에 대응하는 태 스크가 잘못 수행될 가능성이 저하된다."}
{"patent_id": "10-2020-0041025", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 일 실시예에 따른 IoT(internet of things) 시스템을 도시한다. 한편, 도 1의 구성 요소 중 적어 도 일부는 생략될 수도 있으며, 도시되지 않은 구성 요소가 더 포함되도록 구현될 수도 있다. 도 1을 참조하면, 일 실시예에 따른 IoT 시스템은, 제 1 IoT 서버, 제 1 노드(node), 보이스 어시스턴스(voice assistance) 서버, 제 2 IoT 서버, 제 2 노드, 또는 디바이스들 (121,122,123,124,125,136,137,151,152,153) 중 적어도 하나를 포함할 수 있다. 일 실시예에 따라서, 제 1 IoT 서버는, 통신 인터페이스, 프로세서, 또는 저장부 중 적어 도 하나를 포함할 수 있다. 제 2 IoT 서버는, 통신 인터페이스, 프로세서, 또는 저장부 중 적어도 하나를 포함할 수 있다. 본 문서에서의 “IoT 서버”는, 예를 들어 데이터 네트워크(예: 데이터 네 트워크 또는 데이터 네트워크)에 기반하여, 중계 디바이스(예: 제 1 노드 또는 제 2 노드(15 0))를 통하거나, 또는 중계 디바이스 없이 직접적으로(directly), 하나 또는 그 이상의 디바이스들(예: 디바이 스들(121,122,123,124,125,151,152,153))을 원격으로 제어 및/또는 모니터링할 수 있다. 여기에서의 “디바이 스”는, 예를 들어 가택, 사무실, 공장, 빌딩, 외부 지점, 또는 다른 타입의 부지들과 같은 로컬 환경 내에 배 치되는(또는, 위치하는) 센서, 가전, 사무용 전자 디바이스, 또는 공정 수행을 위한 디바이스로, 그 종류에는 제한이 없다. 디바이스는, 외부(예: IoT 서버)로부터의 명령어를 수신하여 명령어에 대응하는 동작을 수행하거 나, 또는 외부로부터의 요청, 또는 지정된 조건의 만족됨에 기반하여 요청된 정보(예를 들어, 센싱된 정보)를 외부로 제공할 수 있다. 제어 명령을 수신하여 제어 명령에 대응하는 동작을 수행하는 디바이스를 “타겟 디바 이스”로 명명할 수 있다. IoT 서버는, 디바이스로 특정 동작을 수행하도록 야기하는 명령어, 특정 정보의 제 공을 요청하는 명령어, 특정 정보의 삭제를 요청하는 명령어, 또는 특정 정보의 생성을 요청하는 명령어 중 적 어도 하나를 송신할 수 있거나, 또는 디바이스로부터의 데이터를 수신할 수 있다. IoT 서버는, 복수의 디바이 스들 중 타겟 디바이스를 선택하고 제어 명령을 제공하는 점에서, 중앙 서버(central server)로 명명될 수도 있 다. 일 실시예에 따라서, 제 1 IoT 서버는, 데이터 네트워크를 통하여 디바이스들(121,122,123)과 통신을 수행할 수 있다. 데이터 네트워크는, 예를 들어 인터넷, 또는 컴퓨터 네트워크(예: LAN 또는 WAN)와 같은 원거리 통신을 위한 네트워크를 의미할 수 있으며, 또는 셀룰러 네트워크를 포함할 수도 있다. 예를 들어, 데 이터 네트워크는, 유선 연결 및/또는 무선 연결을 위한 적어도 하나의 통신 디바이스, 및 케이블을 포함할 수 있으며, 통신을 위한 적어도 하나의 기능이 가상화된 경우에는 가상화 서비스를 제공하는 서버의 적어도 일 부를 포함할 수도 있다. 데이터 네트워크의 종류에는 제한이 없다. 일 실시예에 따라서, 제 1 IoT 서버는, 통신 인터페이스를 통하여 데이터 네트워크에 연결될 수 있다. 통신 인터페이스는, 데이터 네트워크의 통신을 지원하기 위한 통신 디바이스(또는, 통신모듈)를 포함할 수 있으며, 하나의 구성 요소(예: 단일 칩)로 통합되거나, 또는 별도의 복수의 구성 요소들(예: 복수 칩들)로 구현될 수 있다. 제 1 IoT 서버는, 제 1 노드를 통하여 디바이스들(121,122,123)와 통신을 수행할 수 있다. 제 1 노드는, 제 1 IoT 서버로부터의 데이터를 데이터 네트워크를 통 하여 수신하고, 수신한 데이터를 디바이스들(121,122,123) 중 적어도 일부로 송신할 수 있다. 또는, 제 1 노드 는, 디바이스들(121,122,123) 중 적어도 일부로부터 데이터를 수신하고, 수신한 데이터를 데이터 네트워크 를 통하여 제 1 IoT 서버로 송신할 수 있다. 제 1 노드는, 데이터 네트워크 및 디바이스 들(121,122,123) 사이의 브릿지(bridge)로서 기능할 수 있다. 한편, 도 1에서는 제 1 노드가 하나인 것과 같이 도시되어 있지만 이는 단순히 예시적인 것으로, 그 숫자에는 제한이 없다. 제 1 IoT 서버는, 적어도 하나의 노드와 각 노드별 연결되는 디바이스들에 대한 구성(configuration)을 관리할 수 있다. 상술한 노드 별 연결되는 디바이스에 대한 구성은, 물리적 그래프(physical graph)로 명명될 수도 있다. 물리적 그래프는, 노 드 별 연결되는 디바이스에 대한 구성과, 또는 IoT 서버에 직접적으로 연결되는 디바이스(예: 디바이스들 (124,125))에 대한 구성 중 적어도 하나를 포함할 수도 있다. 물리적 그래프는, 디바이스들간 연결 관계, 발생 된 이벤트 등을 시각적으로 표시되는 형태로 구현될 수도 있으나, 그 구현 형태에는 제한이 없다. 물리적 그래 프는, 디바이스의 상태 및 이벤트의 제어에 이용될 수도 있다. 본 문서에서의 “노드”는, 엣지 컴퓨팅 시스템(edge computing system)일 수 있거나, 또는 허브(hub) 디바이스 일 수 있다. 일 실시예에 따라서, 제 1 노드는, 데이터 네트워크의 유선 및/또는 무선의 통신을 지 원하며, 아울러 디바이스들(121,122,123)과의 유선 및/또는 무선의 통신을 지원할 수 있다. 예를 들어, 제 1 노 드는, 블루투스, Wi-Fi, Wi-Fi direct, Z-wave, Zig-bee, INSETEON, X10, UWB 또는 IrDA(infrared data association 중 적어도 하나와 같은 근거리 통신 네트워크를 통하여 디바이스들(121,122,123)과 연결될 수 있으 나, 통신 종류에는 제한이 없다. 제 1 노드는, 예를 들어 가택, 사무실, 공장, 빌딩, 외부 지점, 또는 다 른 타입의 부지들과 같은 환경 내에 배치(또는, 위치)될 수 있다. 이에 따라, 디바이스들(121,122,123)은, 제 1 IoT 서버에 의하여 제공되는 서비스에 의하여 모니터링 및/또는 제어될 수 있으며, 디바이스들 (121,122,123)은 제 1 IoT 서버로의 직접 연결을 위한 완전한 네트워크 통신(예: 인터넷 통신)의 캐퍼빌리 티를 갖출 것이 요구되지 않을 수 있다. 디바이스들(121,122,123)은, 예를 들어 전등 스위치, 근접 센서, 온도 센서 등으로 가택 환경 내의 전자 장치로 구현된 것과 같이 도시되었지만, 이는 예시적인 것으로 제한은 없다. 제 1 노드가 엣지 컴퓨팅 시스템으로 구현되는 경우에 대하여서는 도 3을 참조하여 설명하도록 한다. 일 실시예에 따라서, 제 1 IoT 서버는, 디바이스들(124,125)과의 직접 통신(direct communication)을 지 원할 수도 있다. 여기에서, “직접 통신”은, 예를 들어 제 1 노드와 같은 중계 디바이스를 통하지 않은 통신으로, 예를 들어 셀룰러 통신 네트워크 및/또는 데이터 네트워크를 통한 통신을 의미할 수 있다. 예를 들 어, 디바이스들(124,125)은 셀룰러 통신 캐퍼빌리티를 갖출 수 있다. 이에 따라, 디바이스들(124,125)은, 제 1 노드가 배치된 영역을 벗어난 경우에도, 셀룰터 통신 네트워크 및/또는 데이터 네트워크를 통하여 제 1 IoT 서버와 통신을 수행할 수 있다. 예를 들어, 센서는, 차량 내에 위치하며, 차량의 운행 속력을 센싱하고, 이를 제 1 IoT 서버로 송신할 수 있다. 또는, 스마트 폰은, 제 1 IoT 서버로 사용자 센싱 데이터, 또는 제어 명령을 송신할 수도 있다. 스마트 폰에서는, 디바이스 제어를 위한 어플리케이션 이 실행될 수 있으며, 사용자는 실행 화면을 조작하여 등록된 디바이스 중 적어도 일부를 제어할 수 있다. 일 실시예에 따라서, 제 1 IoT 서버는, 디바이스들(121,122,123,124,125) 중 적어도 일부로 제어 명령을 송신할 수 있다. 여기에서, “제어 명령”은, 제어 가능한 디바이스가 특정 동작을 수행하도록 야기하는 데이 터를 의미할 수 있으며, 특정 동작은 디바이스에 의하여 수행되는 동작으로, 정보의 출력, 정보의 센싱, 정보의 보고, 정보의 관리(예: 삭제, 또는 생성)를 포함할 수 있으며, 그 종류에는 제한이 없다. 예를 들어, 프로세서 는, 외부(예: 보이스 어시스턴스 서버, 제 2 IoT 서버, 외부 시스템, 또는 디바이스들 (121,122,123,124,125) 중 적어도 일부)로부터 제어 명령을 생성하기 위한 정보(또는, 요청)를 획득하고, 획득 한 정보에 기반하여 제어 명령을 생성할 수 있다. 또는, 프로세서는, 디바이스들(121,122,123,124,125) 중 적어도 일부의 모니터링 결과가 지정된 조건을 만족함에 기반하여 제어 명령을 생성할 수 있다. 프로세서 는, 제어 명령을, 타겟 디바이스로 송신하도록 통신 인터페이스를 제어할 수 있다. 일 실시예에 따라서, 프로세서, 또는 프로세서, 프로세서는, CPU(central processing unit), DSP(digital signal processor), AP(application processor), CP(communication processor) 등과 같은 범용 프로세서, GPU(graphical processing unit), VPU(vision processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU(neural processing unit)와 같은 인공 지능 전용 프로세서 중 하나 이상의 조합으로 구현될 수 있다. 상술 한 처리 유닛은 단순히 예시적인 것으로, 프로세서는, 예를 들어 메모리에 저장된 인스트럭션을 실행하여, 실행된 결과를 출력할 수 있는 연산 수단이라면 제한이 없음을 당업자는 이해할 것이다. 일 실시예에 따 라서, 프로세서는, 예를 들어 타겟 디바이스의 결정 및/또는 제어 명령의 전달을 수행할 수 있다. 프로세 서는, 저장부에 저장된 데이터베이스(database: DB)에 기반하여 등록된 디바이스들에 대한 정보 를 관리할 수 있다. 예를 들어, 프로세서는, 사용자 요청에 기반하여, 특정 사용자 계정에 대응하여 적어 도 하나의 타겟 디바이스를 등록 또는 삭제할 수 있으며, 디바이스에 대한 정보를 데이터베이스에 저장할 수 있다. 사용자는, 예를 들어 랩탑 컴퓨터 또는 스마트 폰을 이용하여, 전용 어플리케이션 또는 웹 어플리케 이션에 기반하여 제 1 IoT 서버에서 제공하는 서비스에 특정 사용자 계정으로 로그인 할 수 있다. 사용자 의 전자 장치는, 로그인 된 상태에서, 타겟 디바이스의 관리, 타겟 디바이스의 동작 조건 설정, 타겟 디바이스 에 대한 제어 명령 입력과 같은 서비스를 제 1 IoT 서버에 요청할 수 있다. 일 실시예에 따라서, 프로세서는, 메모리에 저장된 자동화 어플리케이션(automation application)에 기반하여 제어 명령의 생성 및 전달을 수행할 수 있다. 예를 들어, 프로세서는, 자동화 어플리케이션을 실행할 수 있다. 자동화 어플리케이션은, 예를 들어 디바이스들의 제어 또는 모니터링에 이용되는 소프트웨어 컴포넌트일 수 있다. 자동화 어플리케이션은, 예를 들어 이벤트 핸들러(event handler) 및/또는 시스템 내에서 발생되는 이벤트의 다양한 타입에 응답하기 위하여 동작하는 제어들(controls) 중 적어도 하나를 포함할 수 있 다. 이벤트 핸들러는, 자동화 어플리케이션으로 구독된(subscribed) 이벤트를 서비스하기 위한 소프트웨어 컴 포넌트일 수 있다. 자동화 어플리케이션은 예를 들어 이벤트를 구독한 이벤트 핸들러를 정의할 수 있으며, 자 동화 어플리케이션은 특정 이벤트가 발생한 경우 인보크(invoke)될 수 있다. 일 실시예에 따라서, 제 1 IoT 서버는 하나 또는 이상의 자동화 어플리케이션의 생성 요청을 획득할 수 있 다. 제 1 IoT 서버는, 예를 들어 생성 요청에 기반하여, 디바이스들 중 적어도 일부를 특정한 이벤 트에 기반하여 제어할 수 있는 자동화 어플리케이션을 생성할 수 있다. 하나의 예에서, 사용자는, 사용자 전자 장치를 통하여 하나의 자동화 어플리케이션(예: 전등-온)을 선택할 수 있으며, 선택된 자동화 어플리케이션은 근접 센서의 근접 센싱 결과에 기반한 전등 스위치의 턴-온을 수행하도록 설정될 수 있다. 예를 들 어, 근접 센싱 결과의 “근접” 상태는 이벤트를 구성할 수 있으며, 전등 스위치의 턴-온은 액션(또는, 액 션 데이터)을 구성할 수 있다. 프로세서는, 액션에 기반하여 제어 명령을 타겟 디바이스(예: 전등 스위치 )로 전달할 수 있다. 일 실시예에 따라서, 프로세서는, API에 기반하여 웹-기반 인터페이스를 구성하거나, 또는 제 1 IoT 서버에 의하여 관리되는 리소스(resource)를 외부에 노출시킬 수 있다. 웹-기반 인터페이스는, 예를 들어 제 1 IoT 서버 및 외부 웹 서비스 사이의 통신을 지원할 수 있다. 프로세서는, 예를 들어 외부 시스 템으로 하여금 디바이스들(121,122,123)의 제어 및/또는 억세스를 허용할 수도 있다. 외부 시스템은, 예를 들어 시스템과 연관이 없거나, 또는 일부가 아닌 독립적인 시스템일 수 있다. 외부 시스템은, 예를 들어 외부 서버이거나, 또는 웹 사이트일 수 있다. 하지만, 외부 시스템으로부터의 디바이스들(121,122,123), 또는 제 1 IoT 서버의 리소스로의 억세스에 대한 보안이 요구된다. 일 실시예 에 따라서, 프로세서는, 자동화 어플리케이션은 API에 기반한 API 엔드 포인트(예: URL(universal resource locator))을 외부에 노출할 수 있다. API 엔드 포인트는, 일 실시예에 따라 동적(dynamically)으로 구성될 수 있으며, 이에 따라 보안성이 증대될 수 있다. 프로세서는, API 엔드 포인트를 통하여 요청을 수신할 수 있다. 프로세서는, API 엔드 포인트를 인증이 완료된 경우에 제공할 수도 있다. API 엔드 포 인트는, 예를 들어 자동화 어플리케이션의 인스턴스(instance)마다 유니크하게 정의될 수 있다. 자동화 어플리 케이션은, 외부 시스템으로부터 수신된 억세스 요청을 서비스하기 위한 이벤트 핸들러를 정의할 수 있다. 프로세서는, OAUTH2와 같은 사용자 인증을 수행할 수도 있다. 또는, 프로세서는, 외부로부터의 억세 스를 승인할 것을 사용자에게 요청할 수도 있다. 상술한 바에 따라서, 제 1 IoT 서버는, 제어 명령을 디바이스들(121,122,123) 중 타겟 디바이스에게 전달 할 수 있다. 한편, 제 2 IoT 서버의 통신 인터페이스, 프로세서, 저장부의 API, 데 이터베이스에 대한 설명은, 제 1 IoT 서버의 통신 인터페이스, 프로세서, 저장부의 API, 데이터베이스에 대한 설명과 실질적으로 동일할 수 있다. 아울러, 제 2 노드에 대한 설명 은, 제 1 노드에 대한 설명과 실질적으로 동일할 수 있다. 제 2 IoT 서버는, 제어 명령을 디바이스 들(151,152,153) 중 타겟 디바이스에게 전달할 수 있다. 제 1 IoT 서버 및 제 2 IoT 서버는, 하나 의 실시예에서는 동일한 서비스 제공자에 의하여 운영될 수 있으나, 다른 실시예에서는 상이한 서비스 제공자들 에 의하여 각각 운영될 수도 있다. 상이한 서비스 제공자들의 IoT 서버들 사이의 인터랙션에 대하여서는 도 4 를 참조하여 설명하도록 한다.일 실시예에 따라서, 보이스 어시스턴스 서버는, 데이터 네트워크를 통하여 제 1 IoT 서버와 데 이터를 송수신할 수 있다. 일 실시예에 따른 보이스 어시스턴스 서버는, 통신 인터페이스, 프로세서 , 또는 저장부 중 적어도 하나를 포함할 수 있다. 통신 인터페이스는, 데이터 네트워크(미도시) 및/또는 셀룰러 네트워크(미도시)를 통하여 스마트 폰 또는 AI 스피커와 통신을 수 행할 수 있다. 스마트 폰 또는 AI 스피커는 마이크를 포함할 수 있으며, 사용자 음성(user voice)을 획득하여 음성 신호로 변환하여, 음성 신호를 보이스 어시스턴스 서버로 송신할 수 있다. 프로세서 는, 통신 인터페이스를 통하여 스마트 폰 또는 AI 스피커로부터 음성 신호를 수신할 수 있다. 프로세서는, 수신한 음성 신호를 저장된 모델(예: 도 2의 제1 보이스 어시스턴트 모델 및/또는 제2 보이스 어시스턴트 모델)에 기반하여 처리할 수 있다. 프로세서는, 데이터베이스에 저장된 정보에 기반하여, 처리 결과를 이용하여 제어 명령을 생성(또는, 확인)할 수 있다. 예를 들어, 데이터베이스 에서는, 연결된 디바이스들(예: 디바이스들(121,122,123))에 대한 정보가 저장될 수 있다. 보이스 어시스 턴스 서버는, 데이터 네트워크를 통하여 제 1 IoT 서버로부터 디바이스에 대한 정보를 수신할 수 있으며, 이를 저장할 수 있다. 보이스 어시스턴스 서버는, 디바이스에 대한 정보와, 음성 데이터 처리 결과에 기반하여, 타겟 디바이스 및 제어 명령을 생성(또는, 확인)할 수 있으며, 이에 대한 정보를 제 1 IoT 서 버로 송신할 수 있다. 제 1 IoT 서버는, 수신한 정보에 기반하여, 타겟 디바이스를 확인하고, 확인 된 타겟 디바이스로 제어 명령을 송신할 수 있다. 또 다른 실시예에서, 보이스 어시스턴스 서버는, 음성 데이터 처리 결과(예: 자연어 이해 결과)를 제 1 IoT 서버로 송신할 수도 있다. 제 1 IoT 서버는, 데이터 처리 결과에 기반하여, 타겟 디바이스 및 제어 명령을 생성(또는, 확인)할 수 있다. 제 1 IoT 서버 는, 확인된 타겟 디바이스로 제어 명령을 송신할 수 있다. 상술한 바에 따라서, 사용자는, 원격에서 음성 을 발화함으로써, IoT 서버에 연결된 디바이스들을 제어할 수 있다. 통신 인터페이스는, 데이터 네트워크 를 지원하기 위한 장치라면 제한이 없다. 일 실시예에 따라서, 저장부(113,133,143)는, 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있으며, 그 종류 에는 제한이 없다. 도 2는, 일 실시예에 따른 IoT 서버 및 보이스 어시스턴스 서버를 도시한다. 한편, 도 2의 구성 요소 중 적어 도 일부는 생략될 수도 있으며, 도시되지 않은 구성 요소가 더 포함되도록 구현될 수도 있다. 일 실시예에 따른 보이스 어시스턴트 서비스를 제공하는 시스템은, 클라이언트 디바이스, 적어도 하나의 디바이스, 보이스 어시스턴트 서버 및 IoT 서버를 포함할 수 있다. 적어도 하나의 디바이스 는 보이스 어시스턴트 서비스를 위하여 보이스 어시스턴트 서버 및/또는 IoT 서버에 미리 등록 된 디바이스일 수 있다. 일 실시예에 따라서, 클라이언트 디바이스(예: 도 1의 스마트 폰 또는 AI 스피커)는 사용자로부 터 음성 입력(예를 들어, 발화)을 수신할 수 있다. 일 실시예에서, 클라이언트 디바이스는 음성 인식 모듈 을 포함할 수 있다. 일 실시예에서, 클라이언트 디바이스는 제한적인 기능을 갖는 음성 인식 모듈을 포함 할 수 있다. 예를 들어, 클라이언트 디바이스는 지정된 음성 입력(예를 들어, ‘하이 빅스비’, ‘오케이 구글’등과 같은 웨이크 업 입력)을 감지하는 기능 또는 일부 음성 입력으로부터 획득한 음성 신호를 전처리하 는 기능을 갖는 음성 인식 모듈을 포함할 수 있다. 클라이언트 디바이스는 인공 지능 스피커(AI speaker) 일 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 적어도 하나의 디바이스 중 일부가 클라이언트 디바이스일 수 있다. 일 실시예에 따라서, 적어도 하나의 디바이스(예: 도 1의 디바이스들(121,122,123) 중 적어도 하나)는 보 이스 어시스턴트 서버 및/또는 IoT 서버로부터의 제어 명령에 따라 특정 동작을 수행하는 타겟 디바 이스일 수 있다. 적어도 하나의 디바이스는, 클라이언트 디바이스가 수신한 사용자의 음성 입력에 기 초하여, 특정 동작을 수행하도록 제어될 수 있다. 일 실시예에서, 적어도 하나의 디바이스 중 적어도 일부 는, 보이스 어시스턴트 서버 및/또는 IoT 서버로부터 제어 명령을 받지 않고, 클라이언트 디바이스 로부터 제어 명령을 수신할 수도 있다. 클라이언트 디바이스는 마이크를 통해 사용자의 음성 입력을 수신하고, 수신된 음성 입력에 기반한 음성 신호(또는, 음성 입력에 대응하는 발화 데이터)를 보이스 어시스턴트 서버에 전송할 수 있다. 보이스 어시스턴트 서버는 클라이언트 디바이스로부터 사용자의 음성 입력을 수신하고, 수신된 음성 신호를 해석함으로써, 적어도 하나의 디바이스 중에서 사용자의 의도에 따른 동작들을 수행할 타겟 디바이 스를 선택하고, 선택된 타겟 디바이스 및 타겟 디바이스가 수행할 동작들에 관한 정보를 IoT 서버 또는 타 겟 디바이스에게 제공할 수 있다. IoT 서버는 보이스 어시스턴트 서비스를 위한 디바이스에 관한 정보를 등록하고 관리할 수 있으며, 보이스 어시스턴트 서버에게 보이스 어시스턴트 서비스를 위한 디바이스 정보를 제공할 수 있다. 디바이스 정보는, 보이스 어시스턴트 서비스를 제공하는데 이용되는 디바이스에 관련된 정보로서, 예를 들어, 디바이스의 식별 정보(디바이스 id 정보), 기능 수행 능력 정보(capability), 위치 정보, 또는 상태 정보 중 적어도 하나를 포함할 수 있다. 또한, IoT 서버는 보이스 어시스턴트 서버로부터 타겟 디바이스 및 타겟 디바이스가 수행할 동작들에 관한 정보를 수신하고, 타겟 디바이스에게 동작들의 제어를 위한 제어 정보를 제공할 수 있다. 발화 데이터는, 보이스 어시스턴트 서비스를 제공받기 위하여 사용자가 발화하는 음성에 관련된 데이터로서, 사 용자의 발화를 나타내는 데이터일 수 있다. 발화 데이터는 디바이스의 동작과 관련된 사용자의 의도를 해 석하는데 이용되는 데이터일 수 있다. 발화 데이터는, 예를 들어, 텍스트 형식의 발화문 또는 NLU 모델(예: 제 1 NLU 모델 또는 제 2 NLU 모델)의 출력 값의 형식을 가지는 발화 파라미터 중 적어도 하나를 포함할 수 있다. 발화 파라미터는, NLU 모델(예: 제 1 NLU 모델 또는 제 2 NLU 모델)로부터 출력되는 데이터 로서, 인텐트 및 파라미터를 포함할 수 있다. 인텐트는 NLU 모델(예: 제 1 NLU 모델 또는 제 2 NLU 모델 )을 이용하여 텍스트를 해석함으로써 결정되는 정보로서, 사용자의 발화 의도를 나타낼 수 있다. 인텐트는, 예를 들어, 사용자가 의도하는 디바이스의 동작을 나타내는 정보일 수 있다. 인텐트는, 사용자의 발 화 의도를 나타내는 정보(이하, 의도 정보)뿐 아니라, 사용자의 의도를 나타내는 정보에 대응하는 수치 값을 포 함할 수 있다. 수치 값은, 텍스트가 특정 의도를 나타내는 정보와 관련될 확률을 나타낼 수 있다. NLU 모델을 이용하여 텍스트를 해석한 결과, 사용자의 의도를 나타내는 정보가 복수 개 획득되는 경우, 각 의도 정보에 대 응되는 수치 값이 최대인 의도 정보가 인텐트로 결정될 수 있다. 또한, 파라미터는 인텐트와 관련된 디바이스의 세부 동작들을 결정하기 위한 변수(variable) 정보일 수 있다. 파라미터는 인텐트와 관련된 정보이며, 하나의 인텐트에 복수 종류의 파라미터가 대응될 수 있다. 파라미터는 디바이스의 동작 정보를 결정하기 위한 변수 정 보뿐만 아니라, 텍스트가 그 변수 정보와 관련될 확률을 나타내는 수치 값을 포함할 수 있다. 자연어 이해 모델 을 이용하여 텍스트를 해석한 결과, 파라미터를 나타내는 변수 정보가 복수 개 획득될 수 있다. 이 경우, 각 변 수 정보에 대응되는 수치 값이 최대인 변수 정보가 파라미터로 결정될 수 있다. 액션 데이터는, 소정의 발화 데이터에 대응되는 디바이스의 일련의 세부 동작들에 관한 데이터일 수 있다. 예를 들어, 액션 데이터는, 소정의 발화 데이터에 대응하여 디바이스가 수행할 세부 동작들, 각 세부 동작들과 다른 세부 동작과의 연관 관계, 및 세부 동작들의 실행 순서에 관련된 정보를 포함할 수 있다. 세부 동작과 다 른 세부 동작과의 연관 관계는, 하나의 세부 동작을 실행하기 위해서 그 세부 동작을 실행하기 전에 실행되어야 할 다른 세부 동작에 대한 정보를 포함한다. 예를 들어, 수행할 동작이 “음악 재생”인 경우, “전원 온(on)” 은 “음악 재생” 동작 이전에 실행되어야 하는 다른 세부 동작이 될 수 있다. 또한, 액션 데이터는 예를 들어, 특정 동작의 수행을 위하여 타겟 디바이스가 실행해야 할 기능들, 기능들의 실행 순서, 기능들을 실행하기 위하 여 필요한 입력 값 및 기능들의 실행 결과로서 출력되는 출력 값을 포함할 수 있으나, 이에 한정되지 않는다. 디바이스는, 스마트폰, 태블릿 PC, PC, 스마트 TV, 휴대폰, PDA(personal digital assistant), 랩톱, 미 디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지털 카메라 및 기타 모바일 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 또한, 디바이스는 통신 기능 및 데이터 프로세싱 기능을 구비한 전등, 에어컨, TV, 로봇 청소기, 세탁기, 체중계, 냉장고, 셋톱 박스(set-top box), 홈 오토메이션 컨트롤 패널(home automation control panel), 보안 컨트롤 패널(security control panel), 게임 콘솔, 전자 키, 캠코더(camcorder), 또는 전자 액자 등의 가전 기기일 수 있다. 또한, 디바이스는 통신 기능 및 데이터 프로세싱 기능을 구비한 시 계, 안경, 헤어 밴드 및 반지 등의 웨어러블 디바이스일 수 있다. 그러나, 이에 제한되지 않으며, 디바이스 는 보이스 어시스턴트 서버 및/또는 IoT 서버로부터 네트워크를 통하여 데이터를 송수신할 수 있는 모든 종류의 기기를 포함할 수 있다. 일 실시예에 따라서, 보이스 어시스턴스 서버는 통신 인터페이스(예: 도 1의 통신 인터페이스), 프로세서(예: 도 1의 통신 인터페이스) 또는 저장부(예: 도 1의 통신 인터페이스) 중 적어도 하나를 포함하며, 저장부는 제1 보이스 어시스턴트 모델, 적어도 하나의 제2 보이스 어시스턴트 모델, SDK 인터페이스 모듈, 또는 DB 중 적어도 하나를 포함할 수 있다. 일 실시예에 따라서, 통신 인터페이스는, 클라이언트 디바이스, 디바이스 또는 IoT 서버 중 적어도 하나와 통신을 수행한다. 통신 인터페이스는, 디바이스와 직접 통신을 수행하거나, 또는 IoT 서버의 중계에 기반하여 통신을 수행할 수도 있다. 통신 인터페이스는 클라이언트 디바이스 , 디바이스 및 IoT 서버와 통신을 위한 하나 이상의 구성요소를 포함할 수 있다. 프로세서는 통상적으로 보이스 어시스턴스 서버의 전반적인 동작을 제어한다. 예를 들어, 프로세서 는, 저장부에 저장된 프로그램(예를 들어, 어플리케이션, 인스트럭션, 또는 알고리즘 중 적어도 하나)들을 실행함으로써, 본 명세서에서의 보이스 어시스턴스 서버의 기능을 수행할 수 있다. 프로세서 는, 저장부에 저장된 모델을 이용하여 동작하거나, 저장부에 저장된 모듈을 실행시킬 수 있다. 본 문서에서의 임의의 모듈이 특정 동작을 수행하는 것은, 프로세서에 의하여 모듈 내에서 정의된(또는, 저장된) 동작이 수행됨을 의미할 수도 있다. 저장부에 저장된 프로그램들은 그 기능에 따라 분류될 수 있는데, 예를 들어, 제1 보이스 어시스턴트 모델 , 적어도 하나의 제2 보이스 어시스턴트 모델 및 SDK 인터페이스 모듈 등으로 분류될 수 있다. 일 실시예에 따라서, 제1 보이스 어시스턴트 모델은 사용자 음성 입력을 분석하여 사용자 의도와 관련된 타겟 디바이스를 결정하는 모델이다. 제1 보이스 어시스턴트 모델은 ASR (Automatic Speech Recognition) 모델, 제1 NLU 모델, 제1 NLG 모델, 디바이스 판단 모듈, 기능 비교 모듈, 발화 데 이터 획득 모듈, 액션 데이터 생성 모듈 및 모델 업데이터를 포함할 수 있다. ASR 모델은 ASR을 수행함으로써, 음성 신호를 텍스트로 변환한다. ASR 모델은 음향 모델(acoustic model; AM) 또는 언어 모델(language model; LM) 등 기 정의된 모델을 이용하여 음성 신호를 컴퓨터로 판독 가 능한 텍스트로 변환하는 ASR을 수행할 수 있다. 클라이언트 디바이스로부터 노이즈가 제거되지 않은 음향 신호가 수신되는 경우에, ASR 모델은 수신된 음향 신호에서 노이즈를 제거하여 음성 신호를 획득하고, 음 성 신호에 대하여 ASR을 수행할 수 있다. 제1 NLU 모델은 텍스트를 분석하고, 분석 결과에 기초하여 사용자의 의도에 관련된 제1 인텐트를 결정한다. 제1 NLU 모델은, 텍스트를 해석하여 텍스트에 대응하는 제1 인텐트를 획득하도록 학습된 모델일 수 있다. 인텐트는, 텍스트에 포함된 사용자의 발화 의도를 나타내는 정보일 수 있다. 디바이스 판단 모듈은 제1 NLU 모델을 이용하여 문법적 분석(syntactic analyze) 및/또는 의미적 분 석(semantic analyze)을 수행함으로써, 변환된 텍스트로부터 사용자의 제1 인텐트(intent)를 결정할 수 있다. 일 실시예에서, 디바이스 판단 모듈은 제1 NLU 모델을 이용하여, 변환된 텍스트를 형태소, 단어 (word), 또는 구(phrase)의 단위로 파싱(parse)하고, 파싱된 형태소, 단어, 또는 구의 언어적 특징(예: 문법적 요소)을 이용하여 파싱된 텍스트로부터 추출된 단어의 의미를 추론할 수 있다. 디바이스 판단 모듈은, 추 론된 단어의 의미를 제1 NLU 모델에서 제공되는 기 정의된 인텐트들과 비교함으로써, 추론된 단어의 의미 에 대응되는 제1 인텐트를 결정할 수 있다. 디바이스 판단 모듈은 제1 인텐트에 기초하여 타겟 디바이스의 타입(type)을 결정할 수 있다. 디바이스 판단 모듈은 파싱된 텍스트 및 타겟 디바이스 정보를 제2 보이스 어시스턴트 모델에게 제공한다. 일 실시예에서, 디바이스 판단 모듈은 결정된 타겟 디바이스의 식별 정보(예: 디바이스 id)를 파싱된 텍스트와 함께 제2 보이스 어시스턴트 모델에게 제공할 수 있다. 제1 NLG 모델은 디바이스들의 기능을 등록하고 발화 데이터의 생성 또는 편집을 위한 질의 메시지를 생성할 수 있다. 기능 비교 모듈은, 예를 들어 신규 디바이스 등록 시, 기등록된 디바이스의 기능과 신규 디바이스의 기능을 비교할 수 있다. 기능 비교 모듈은 기등록된 디바이스의 기능과 신규 디바이스의 기능이 동일 또는 유사한지를 판단할 수 있다. 기능 비교 모듈은 신규 디바이스의 기능들 중에서 기등록된 디바이스의 기능과 동일 또는 유사한 기능을 식별할 수 있다. 기능 비교 모듈은 신규 디바이스의 명세 정보로부터 신규 디바이스에 의해 지원되는 기능을 나타내는 명칭 을 식별하고, 식별된 명칭이 기등록된 디바이스에 의해 지원되는 기능의 명칭과 동일 또는 유사한 지를 판 단할 수 있다. 이 경우, DB는 소정 기능을 나타내는 명칭 및 유사어들에 관한 정보를 미리 저장할 수 있으 며, 저장된 유사어 정보에 기초하여 기등록된 디바이스의 기능과 신규 디바이스의 기능이 동일 또는 유사 한지를 판단할 수 있다.또한, 기능 비교 모듈은 DB에 저장된 발화 데이터를 참고하여 기능의 동일 유사 여부를 판단할 수 있 다. 기능 비교 모듈은 기등록된 디바이스의 기능과 관련된 발화 데이터를 이용하여, 신규 디바이스의 기능이 기등록된 디바이스의 기능과 동일 또는 유사한지를 판단할 수 있다. 이 경우, 기능 비교 모듈(26 5)은 제1 NLU 모델을 이용하여 발화 데이터를 해석하고, 발화 데이터 내에 포함된 단어들의 의미에 기초하여 신 규 디바이스의 기능이 기등록된 디바이스의 기능과 동일 또는 유사한지를 판단할 수 있다. 기능 비교 모듈은 기등록된 디바이스의 단일 기능과 신규 디바이스의 단일 기능이 동일 또는 유사한 지를 판단할 수 있다. 기능 비교 모듈은 기등록된 디바이스의 기능 세트와 신규 디바이스의 기능 세 트가 동일 또는 유사한 지를 판단할 수 있다. 발화 데이터 획득 모듈은 신규 디바이스의 기능에 관련된 발화 데이터를 획득할 수 있다. 발화 데이터 획 득 모듈은 기등록된 디바이스의 기능들 중에서 신규 디바이스의 기능과 동일 또는 유사하다고 판단된 기능에 대응되는 발화 데이터를 발화 데이터 DB로부터 추출할 수 있다. 발화 데이터 획득 모듈은 기등록된 디바이스의 기능 세트들 중에서 신규 디바이스의 기능과 동일 또 는 유사하다고 판단된 기능 세트에 대응되는 발화 데이터를 발화 데이터 DB로부터 추출할 수 있다. 이 경 우, 기등록된 디바이스의 기능에 대응되는 발화 데이터, 및 기등록된 디바이스의 기능 세트에 대응되 는 발화 데이터는, 발화 데이터 DB에 미리 저장되어 있을 수 있다. 발화 데이터 획득 모듈은 동일 또는 유사하다고 판단된 기능 및 기능 세트를 편집하고 편집된 기능들에 대 응되는 발화 데이터를 생성할 수도 있다. 발화 데이터 획득 모듈은 동일 또는 유사하다고 판단된 기능들을 조합하고, 조합된 기능들에 대응되는 발화 데이터를 생성할 수 있다. 또한, 발화 데이터 획득 모듈은 동일 또는 유사하다고 판단된 기능 및 기능 세트를 조합하고, 조합된 기능들에 대응되는 발화 데이터를 생성할 수 있 다. 또한, 발화 데이터 획득 모듈은 동일 또는 유사하다고 판단된 기능 세트 내의 기능들 중 일부 기능을 삭제하고, 일부 기능이 삭제된 기능 세트에 대응되는 발화 데이터를 생성할 수 있다. 발화 데이터 획득 모듈은 발화 데이터를 확장할 수 있다. 발화 데이터 획득 모듈은 추출 또는 생성된 발화 데이터의 표현을 수정함으로써, 추출 또는 생성된 발화 데이터와 의미는 동일하지만 상이한 표현을 가지는 유사 발화 데이터를 생성할 수 있다. 발화 데이터 획득 모듈은 제1 NLG 모델을 이용하여, 추가 기능의 등록 및 발화 데이터의 생성 또는 편집을 위한 질의를 출력할 수 있다. 발화 데이터 획득 모듈은 신규 디바이스의 기능을 등록하고 발화 데 이터의 생성을 안내하기 위한 안내 텍스트 또는 안내 음성 데이터를 사용자의 디바이스 또는 개발자의 디 바이스(미도시)에게 제공할 수 있다. 발화 데이터 획득 모듈은 신규 디바이스의 기능들 중에서 기등록된 디바이스의 기능과 상이한 기능들의 목록을 사용자의 디바이스 또는 개발자의 디바이스(미도시)에게 제공할 수 있다. 발화 데이터 획득 모듈은 상이한 기능들 중 적어도 일부에 관련된 추천 발화 데이터를 사 용자의 디바이스 또는 개발자의 디바이스(미도시)에게 제공할 수 있다. 발화 데이터 획득 모듈은 제1 NLU 모델을 이용하여 질의에 대한 응답을 해석할 수 있다. 발화 데이터 획득 모듈은 해석된 응답에 기초하여, 신규 디바이스의 기능들에 관련된 발화 데이터를 생성할 수 있다. 발화 데이터 획득 모듈은 해석된 사용자의 응답 또는 해석된 개발자의 응답을 이용하여 신규 디바이스의 기능들에 관련된 발화 데이터를 생성하고, 생성된 발화 데이터를 추천할 수 있다. 발화 데이터 획득 모듈 은 신규 디바이스의 기능들 중 일부를 선택하고, 선택된 일부 기능 각각에 관련된 발화 데이터들을 생성할 수 있다. 발화 데이터 획득 모듈은 신규 디바이스의 기능들 중 일부를 선택하고, 선택된 일부 기능들의 조합 에 관련된 발화 데이터를 생성할 수 있다. 발화 데이터 획득 모듈은 신규 디바이스의 기능들의 식별 값 및 속성에 기초하여, 제1 NLG 모델을 이용하여 신규 디바이스의 기능에 관련된 발화 데이터를 생성할 수 있다. 액션 데이터 생성 모듈은 동일 또는 유사한 기능들 및 발화 데이터에 기초하여, 신규 디바이스에 대한 액 션 데이터를 생성할 수 있다. 예를 들어, 발화 데이터에 대응되는 기능이 단일 기능인 경우에, 액션 데이터 생 성 모듈은 단일 기능을 나타내는 세부 동작을 포함하는 액션 데이터를 생성할 수 있다. 예를 들어, 발화 데이터에 대응되는 기능이 기능 세트인 경우에, 액션 데이터 생성 모듈은 기능 세트 내의 기능들을 나타내 는 세부 동작들, 및 세부 동작들의 실행 순서를 생성할 수 있다. 액션 데이터 생성 모듈은 신규 디바이스 의 신규 기능과 관련하여 생성된 발화 데이터를 이용하여 액션 데이터를 생성할 수 있다. 액션 데이터 생성 모 듈은 발화 데이터에 관련된 신규 디바이스의 신규 기능들을 식별하고, 식별된 기능들의 실행 순서를 결정함으로써, 생성된 발화 데이터에 대응되는 액션 데이터를 생성할 수 있다. 생성된 액션 데이터는 발화 데이터 및 유사 발화 데이터에 매칭될 수 있다. 모델 업데이터는 발화 데이터 및 액션 데이터를 이용하여 신규 디바이스에 관련된 제2 보이스 어시스턴트 모델을 생성 또는 업데이트할 수 있다. 모델 업데이터는 신규 디바이스의 기능에 관련된 기 등록된 디바이스의 기능에 대응되는 발화 데이터, 신규 디바이스의 기능과 관련하여 신규로 생성된 발화 데이터, 확장된 발화 데이터 및 액션 데이터를 이용하여, 신규 디바이스에 관련된 제2 보이스 어시스턴트 모델을 생성 또는 업데이트할 수 있다. 모델 업데이터는 신규 디바이스에 관련된 발화 데이터 및 액션 데이 터를 발화 데이터 DB 및 액션 데이터 DB에 누적하여 저장할 수 있다. 또한, 모델 업데이터는 액 션 플랜 관리 모델 내에 포함된 캡슐 형태의 데이터베이스인 CAN(Concept Action Network)를 생성 또는 업 데이트할 수 있다. 제2 보이스 어시스턴트 모델은 특정 디바이스에 특화된 모델로, 사용자의 음성 입력에 대응하는 타겟 디바 이스가 수행할 동작을 결정할 수 있다. 제2 보이스 어시스턴트 모델은 제2 NLU 모델, 제2 NLG 모델 및 액션 플랜 관리 모델을 포함할 수 있다. 보이스 어시스턴스 서버는 디바이스의 타입 별로 제2 보이스 어시스턴트 모델을 포함할 수 있다. 제2 NLU 모델은 특정 디바이스에 특화된 NLU 모델로서, 텍스트를 분석하고, 분석 결과에 기초하여 사용자 의 의도에 관련된 제2 인텐트를 결정한다. 제2 NLU 모델은 디바이스의 기능을 고려하여 사용자의 입력 음 성을 해석할 수 있다. 제2 NLU 모델은, 텍스트를 해석하여 텍스트에 대응하는 제2 인텐트를 획득하도록 학 습된 모델일 수 있다. 제2 NLG 모델은 특정 디바이스에 특화된 NLG 모델로서, 사용자에게 보이스 어시스턴트 서비스를 제공하기 위하여 필요한 질의 메시지를 생성할 수 있다. 제2 NLG 모델은 디바이스의 기능을 고려하여 사용자와의 대 화를 위한 자연어를 생성할 수 있다. 액션 플랜 관리 모델은, 디바이스에 특화된 모델로서 사용자의 음성 입력에 대응하는 타겟 디바이스가 수 행할 동작을 결정하는 모델일 수 있다. 액션 플랜 관리 모델은 신규 디바이스의 기능을 고려하여 신규 디 바이스가 수행할 동작 정보를 플래닝할 수 있다. 액션 플랜 관리 모델은 해석된 사용자의 발화 음성으로부터 신규 디바이스가 수행해야 할 세부 동작들을 선택하고 선택된 세부 동작들의 실행 순서를 플래닝할 수 있다. 액션 플랜 관리 모델은 플래닝 결과를 이 용하여 신규 디바이스가 수행할 세부 동작에 관한 동작 정보를 획득할 수 있다. 동작 정보는, 디바이스가 수행 할 세부 동작들, 세부 동작들 간의 연관 관계, 및 세부 동작들의 실행 순서와 관련된 정보일 수 있다. 동작 정 보는 예를 들어, 세부 동작들의 수행을 위하여 신규 디바이스가 실행해야 할 기능들, 기능들의 실행 순서, 기능 들을 실행하기 위하여 필요한 입력 값 및 기능들의 실행 결과로서 출력되는 출력 값을 포함할 수 있으나, 이에 한정되지 않는다. 액션 플랜 관리 모델은 신규 디바이스의 복수의 세부 동작들 및 복수의 세부 동작들 간의 관계에 관한 정 보를 관리할 수 있다. 복수의 세부 동작들 중 각각의 세부 동작과 다른 세부 동작과의 연관 관계는, 하나의 세 부 동작을 실행하기 위해서 그 세부 동작을 실행하기 전에 필수적으로 실행되어야 할 다른 세부 동작에 대한 정 보를 포함할 수 있다. 액션 플랜 관리 모델은 디바이스의 동작들 및 동작들 간의 연관 관계를 나타내는 캡슐 형태의 데이터베이 스인 CAN(Concept Action Network)를 포함할 수 있다. CAN(Concept Action Network)은 특정 동작의 수행을 위 하여 디바이스가 실행해야 할 기능들, 기능들의 실행 순서, 기능들을 실행하기 위하여 필요한 입력 값 및 기능 들의 실행 결과로서 출력되는 출력 값을 포함하며, 컨셉 및 컨셉 간의 관계를 나타내는 지식 트리플들로 구성된 온톨로지 그래프로 구현될 수 있다. SDK 인터페이스 모듈은 클라이언트 디바이스 또는 개발자의 디바이스(미도시)와 통신 인터페이스 를 통하여 데이터를 송수신할 수 있다. 클라이언트 디바이스 또는 개발자의 디바이스(미도시)는 신규 디바이스의 등록을 위한 소정의 소프트웨어 개발 킷(SDK: Software Development Kit)을 설치할 수 있으며, 설치 된 소프트웨어 개발 킷을 통하여 보이스 어시스턴스 서버로부터 GUI를 수신할 수 있다. 프로세서는 신규 디바이스의 기능을 등록하고 발화 데이터의 생성을 위한 GUI를, SDK 인터페이스 모듈을 통하여 사용 자의 디바이스 또는 개발자의 디바이스(미도시)에게 제공할 수 있다. 프로세서는 사용자의 디바이스 에게 제공된 GUI를 통한 사용자의 응답 입력을 사용자의 디바이스로부터 SDK 인터페이스 모듈을통하여 수신하거나, 개발자의 디바이스(미도시)에게 제공된 GUI를 통한 개발자의 응답 입력을 SDK 인터페이스 모듈을 통하여 개발자의 디바이스(미도시)로부터 수신할 수 있다. SDK 인터페이스 모듈은 IoT 서버 와 통신 인터페이스를 통하여 데이터를 송수신할 수도 있다. DB는 보이스 어시스턴트 서비스를 위한 각종 정보를 저장할 수 있다. DB는 발화 데이터 DB 및 액션 데이터 DB를 포함할 수 있다. 발화 데이터 DB는 클라이언트 디바이스, 디바이스 및 신규 디바이스의 기능들에 관련된 발화 데이터를 저장할 수 있다. 액션 데이터 DB는 클라이언트 디바이스, 디바이스 및 신규 디바이스의 기능들에 관련된 액션 데이터를 저장할 수 있다. 발화 데이터 DB에 저장된 발화 데이터 및 액션 데이터 DB에 저장된 액션 데이터는 서로 매핑될 수 있다. 일 실시예에 따라서, IoT 서버(예: 도 1 의 제 1 IoT 서버)는, 통신 인터페이스(예: 도 1의 통 신 인터페이스), 프로세서(예: 도 1의 프로세서), 또는 저장부(예: 도 1의 저장부) 중 적어도 하나를 포함할 수 있다. 저장부는, 프로토콜(protocol) 변환 모듈, 데이터 브로커 모듈 (data borker) 모듈, 디바이스 관리(management) 모듈, 인증(authentication) 모듈, AI 학습 모듈, AI 수행 모듈, 어플리케이션 실행 모듈, 어플리케이션 및 데이터 관리 모듈, API, 또는 DB 중 적어도 하나를 포함할 수 있다. 상술한 바와 같이, IoT 서버는, 연결된 디바이스가 타겟 디바이스로 판단된 경우, 디바이스로 제어 명령을 전달할 수 있다. 도 2에서는, IoT 서버와 디바이스가 노드의 중계없이 데이터를 송수신 하는 것과 같이 도시되었지만, 이는 예시적인 것으로, 도 1에서 설명한 바와 같이, 노드의 중계에 따라 데이터 를 송수신할 수도 있다. 일 실시예에 따라서, 보이스 어시스턴스 서버로부터, 타겟 디바이스에 대한 정보 및/또는 제어 명령이 획 득되면, 프로세서는, 통신 인터페이스를 통하여, 타겟 디바이스로 제어 명령을 송신할 수 있다. 또 는, 프로세서는, 보이스 어시스턴스 서버가 아닌 다른 소스로부터도 타겟 디바이스에 대한 정보 및/ 또는 제어 명령을 획득할 수도 있거나, 또는 미리 지정된 조건의 검출에 기반하여 타겟 디바이스에 대한 정보 및/또는 제어 명령을 획득할 수도 있다. 상술한 바와 같이, 프로세서는, 예를 들어 자동화 어플리케이션 을 실행함으로써, 타겟 디바이스로 제어 명령을 제공할 수 있으나, 제공 방식에는 제한이 없다. 일 실시예에 따라서, 프로토콜 변환 모듈은, 디바이스 타입 핸들러 모듈로 명명될 수도 있으며, 예를 들어 디바이스의 고유한 능력으로부터 디바이스를 추상화한 디바이스 타입 핸들러를 구현할 수 있다. 더욱 상세하게, 디바이스 타입 핸들러는, 디바이스에 대한 명령 및 상태에 대하여 일반화 또는 정규화된 언어를 이용 하여, 자동화 어플리케이션을 작성할 수 있도록 한다. 프로토콜 변환 모듈은, 일반화된 언어를 디바이스 에 특정된 언어로 변환할 수 있다. 프로토콜 변환 모듈은, 디바이스에 특정된 이벤트 및 상태를 수신하고, 데이터 브로커 모듈이 이용할 수 있도록 일반화된 이벤트 및 상태를 제공할 수 있다. 프로토콜 변환 모듈은, 데이터 브로커 모듈로부터 일반화된 명령을 수신하며, 디바이스에 전달될 수 있도록 이 를 디바이스에 특정된 명령으로 변환할 수 있다. 일 실시예에 따라서, 데이터 브로커 모듈은, 통신 인터페이스를 통하여 외부(예: 노드, 또는 보이스 어시스턴스 서버)로부터 이벤트 데이터를 수신하고, 이벤트 데이터가 시스템 내에서 어떠한 방식으로 라우 팅되어야 할 지 판단할 수 있다. 데이터 브로커 모듈은, 이벤트 처리 및 라우팅 모듈로 명명될 수도 있다. 일 실시예에 따라서, 디바이스 관리 모듈은, 디바이스에 관한 정보를 등록하고 관리할 수 있다. 디바 이스 정보는, 예를 들어, 디바이스의 식별 정보(디바이스 id 정보), 기능 수행 능력 정보(capability), 위치 정 보, 또는 상태 정보 중 적어도 하나를 포함할 수 있다. 일 실시예에 따라서, 인증 모듈은, 디바이스의 식별, 등록, 또는 인증 중 적어도 하나를 수행할 수 있다. 인증 모듈은, 외부로부터의 억세스에 대한 인증을 수행할 수도 있다. 인증 모듈은, 또 다른 IoT 서버 연결 시의 또 다른 IoT 서버에 대한 인증을 수행할 수도 있다. 일 실시예에 따라서, AI 학습 모듈은, 예를 들어 DB에 저장된 학습을 위한 데이터에 기반하여 학습을 수행할 수 있으며, 학습 수행 결과로 AI 모델을 생성할 수 있다. 예를 들어, DB에는, 보이스 어시스턴스서버로부터의 타겟 디바이스 정보 및 제어 명령과, 제어 명령 수행 시점에서의 디바이스 정보가 연관되어 저장될 수 있다. AI 학습 모듈은, 정보에 대한 기계 학습을 수행하여, 예를 들어 디바이스 정보를 입력받 으면 대응하는 타겟 디바이스 및 제어 명령을 출력할 수 있는 AI 모델을 생성할 수 있다. AI 수행 모듈은, 디바이스 정보를 AI 모델에 입력할 수 있으며, AI 모델로부터 타겟 디바이스 및 제어 명령을 확인 할 수 있다. 이에 따라, 보이스 어시스턴스 서버의 개입 없이도, IoT 서버는, 디바이스 정보에 기반 하여 디바이스를 제어할 수도 있다. AI 모델은, 예를 들어 자동화 어플리케이션으로부터 독립적으로 관리 될 수도 있으며, 구현에 따라서 AI 모델에 기반하여 자동화 어플리케이션이 업데이트되도록 구현될 수도 있다. 또는, AI 모델이 자동화 어플리케이션의 인스턴스로 추가되도록 구현될 수도 있다. 만약, AI 모델이 자동화 어 플리케이션의 일부로 포함되거나, 업데이트에 이용되는 경우에는 AI 수행 모듈이 어플리케이션 실행 모듈 에 포함되거나, 생략될 수도 있다. 일 실시예에 따라서, 어플리케이션 실행 모듈은, 자동화 어플리케이션을 실행할 수 있다. 어플리케이션 및 데이터 관리 모듈은, 자동화 어플리케이션이 실행된 이력, 예를 들어 이벤트 및 액션에 대한 데이터를 관리할 수 있으며, 이를 DB에 저장하거나, 또는 DB로부터 삭제할 수 있다. API는, 상술한 바와 같이, 웹-기반 인터페이스를 구성하거나, 또는 제 리소스의 외부로의 노출(예: API 엔드-포인트)에 이용될 수 있다. DB에는, 자동화 어플리케이션과 연관된 정보, 디바이스에 대한 정보, 물리적 그래프, 또는 AI 모델 중 적어도 하나가 저장될 수 있다. 도 3은 다양한 실시예에 따른 IoT 서버 및 엣지 컴퓨팅 시스템을 도시한다. 한편, 도 3의 구성 요소 중 적어도 일부는 생략될 수도 있으며, 도시되지 않은 구성 요소가 더 포함되도록 구현될 수도 있다. 도 3을 참조하면, 일 실시예에 따라서, 엣지 컴퓨팅 시스템(예: 도 1의 노드)는, IoT 서버(예: 도 1의 제 1 IoT 서버)와 통신을 수행할 수 있으며, 디바이스들(351,352,353)(예: 디바이스들 (121,122,123))과 통신을 수행할 수 있다. 엣지 컴퓨팅 시스템은, 예를 들어 로컬(local) 환경, 즉 디바 이스들(351,352,353)이 배치(또는, 위치)된 영역에 배치될 수 있다. 엣지 컴퓨팅 시스템는 이벤트 검출에 대응하는 액션이 수행되도록, 타겟 디바이스를 결정하여 타겟 디바이스에 제어 명령을 전달할 수 있다. 예를 들어, 엣지 컴퓨팅 시스템는, 자동화 어플리케이션 및/또는 AI 모델에 기반하여, 타겟 디바이스에 제어 명 령을 전달할 수 있다. 엣지 컴퓨팅 시스템 및 디바이스들(351,352,353)이 중계 장치 없이 직접적으로 연 결될 수 있으므로, 타겟 디바이스의 제어 명령의 수행 시 레이튼시(latency)가, 중앙 서버(예: IoT 서버) 가 개입된 경우에 비하여 감소할 수 있다. 아울러, 타겟 디바이스 및 제어 명령의 결정이 로컬 영역에서 수행 될 수 있으므로, 중앙 서버(예: IoT 서버)의 연산량이 분산될 수 있다. 또한, 이벤트에 대한 정보가 중앙 서버(예: IoT 서버)에 제공되지 않을 수 있어, 사용자 프라이버시가 향상될 수도 있다. 일 실시예에 따라서, 엣지 컴퓨팅 시스템는, 제 1 통신 인터페이스, 제 2 통신 인터페이스, 프 로세서, 또는 저장부 중 적어도 하나를 포함할 수 있다. 저장부는, 프로토콜 변환 모듈, 데이터 브로커 모듈, 디바이스 관리 모듈, 인증 모듈, AI 수행 모듈, 어플리케이션 실행 모듈, 어플리케이션 및 데이터 관리 모듈, API, 또는 DB 중 적어도 하나를 포함할 수 있다. 일 실시예에 따라서, 제 1 통신 인터페이스는, 로컬 영역에서의 디바이스들(351,352,353)과 통신을 수행할 수 있다. 상술한 바와 같이, 제 1 통신 인터페이스는, 블루투스, Wi-Fi, Wi-Fi direct, Z-wave, Zig- bee, INSETEON, X10 등) 또는 IrDA(infrared data association 중 적어도 하나와 같은 근거리 통신을 지원하기 위한 적어도 하나의 통신 모듈을 포함할 수 있다. 제 2 통신 인터페이스는, 예를 들어 IoT 서버와 통신을 수행할 수 있다. 제 2 통신 인터페이스는, 인터넷, 또는 컴퓨터 네트워크(예: LAN 또는 WAN)와 같 은 원거리 통신을 지원하기 위한 적어도 하나의 통신 모듈을 포함할 수 있다. 한편, 프로세서, 프로토콜 변환 모듈, 데이터 브로커 모듈, 디바이스 관리 모듈, 인증 모 듈, AI 수행 모듈, 어플리케이션 실행 모듈, 어플리케이션 및 데이터 관리 모듈, API, 또는 DB 각각의 동작은, IoT 서버의 프로세서, 프로토콜 변환 모듈, 데이터 브 로커 모듈, 디바이스 관리 모듈, 인증 모듈, AI 수행 모듈, 어플리케이션 실행 모듈, 어플리케이션 및 데이터 관리 모듈, API, 또는 DB 각각의 동작과 실질적으로 유사할 수 있다. 한편, 도 3에서는, 엣지 컴퓨팅 시스템는, AI 학습 모듈을 포함하지 않은 것과 같이 도시되어 있다. 엣지 컴퓨팅 시스템는, IoT 서버로부터 AI 모델을 수신하고, 수신된 AI 모델에 기반하여, 타겟 디바이스 및 제어 명령을 확인할 수도 있다. 엣지 컴퓨팅 시스템는, 기 수행한 이벤트 별 액션에 대한 정보를 AI학습을 위하여 IoT 서버로 제공할 수 있거나, 또는 프라이버시 보호를 위하여 제공하지 않도록 구현될 수 도 있다. 또 다른 실시예에서는, 엣지 컴퓨팅 시스템도, AI 학습 모듈을 포함할 수도 있으며, 이 경우 기 수행한 이벤트 별 액션에 대한 정보에 기반하여 AI 모델을 직접 생성할 수도 있다. 도 4는 일 실시예에 따른 클라우드 간의 동작을 설명하기 위한 흐름도이다. 도 4를 참조하면, 클라우드-클라우드 서비스 시스템은, 어플리케이션(application)(또는, 클라이언트 (client)), 시작 클라우드(origin cloud), 타겟 클라우드(target cloud), 및 디바이스 (device)(또는, 서버(server))를 포함할 수 있다. 클라우드-클라우드 서비스 시스템의 동작은, 예를 들어, OCF(open connectivity foundation)에서 제언되는 표준을 따를 수 있지만, 이는 예시적인 것으로 그 동작에는 제한이 없다. 도 4에서의 어플리케이션의 동작은 예를 들어 도 1에서의 디바이스의 동작일 수 있으 며, 시작 클라우드의 동작은 예를 들어 도 1에서의 제 1 IoT 서버의 동작일 수 있으며, 타겟 클라우 드의 동작은 예를 들어 도 1에서의 제 2 IoT 서버의 동작일 수 있으며, 디바이스의 동작은 예를 들어 도 1에서의 디바이스들(151,152,153) 중 적어도 하나의 동작일 수 있다. 일 실시예에 따라서, 411 동작에서, 시작 클라우드 및 타겟 클라우드는, 서로의 URI(또는, URL)를 확 인할 수 있다. 예를 들어, 클라우드-클라우드 서비스 시스템의 적어도 하나의 엔티티는, 메디에이터(mediato r)에 기반하여 디바이스 및/또는 클라우드의 프로비젼(provision)을 수행할 수 있다. 여기에서, 메디에이터는, 예를 들어 OCF 표준에서 정의된 논리 기능(logical function)으로, 클라우드 서비스 제공자로부터의 어플리케이 션일 수 있다. 메디에이터는, 클라우드의 URI(또는, URL)을 획득하도록 아웃 오브 밴드 프로세스(out of band process)를 수행하도록 설정될 수 있다. 413 동작에서, 시작 클라우드 및 타겟 클라우드는, 보안 연 결(예를 들어, transport layer security(TSL) 세션)을 셋업할 수 있다. 415 동작에서, 디바이스는, 타 겟 클라우드에 디바이스 온 보딩(device on boarding)을 수행할 수 있다. 여기에서, 디바이스 온 보딩은, 예를 들어 디바이스를 타겟 클라우드에 등록시키는 절차를 의미할 수 있으며, 그 방식에는 제한이 없 다. 417 동작에서, 어플리케이션은, 시작 클라우드, 및 타겟 클라우드는, 최초 연계(initial association) 절차를 수행할 수 있다. 최초 연계 절차는, 예를 들어 인증 과정 및/또는 권한 설정 과정을 포함 할 수 있다. 예를 들어, 어플리케이션이 타겟 클라우드와의 링크 연결(link account)을 요청받으면, URL 오픈(open)을 시작 클라우드에 요청하는 동작을 포함할 수 있다. 최초 연계 절차는, 시작 클라우드 가 상태 쿼리 파라미터(state query parameter)를 생성 및 저장하고, 인증 절차(예: OAuth process)를 개 시하고, 타겟 클라우드의 인증 서버를 redirect하는 동작을 포함할 수 있다. 최초 연계 절차는, 어플리케 이션이 타겟 클라우드의 인증 서버로 redirect를 수행하고, 인증 서버로부터의 정보에 기반하여 인증 UI를 제공하는 동작을 포함할 수 있다. 최초 연계 절차는, 인증 UI에 대하여 타겟 클라우드의 크리덴셜 (credential)을 입력받고, 사용자 크리덴셜을 인증 서버로 제공하고, 인증서버로부터의 정보에 기반하여 동의 화면을 제공하고, 시작 클라우드의 인증 어플리케이션에의 권한 부여를 인증 서버로 제공하는 동작을 포함 할 수 있다. 최초 연계 절차는, 어플리케이션이 권한 부여에 대응하여 인증 서버로부터 권한 코드를 redirect 받는 동작, redirect를 수행하는 동작을 포함할 수 있다. 최초 연계 절차는, 시작 클라우드가 상 태 쿼리 파라미터를 검증하는 동작, 권한 코드를 인증 서버와 교환하고 토큰을 refresh하는 동작, 토큰을 인증 서버로부터 반환받는 동작과 시작 클라우드의 사용자 Id로 억세스 연계 및 토큰 refresh를 수행하는 동작 을 포함할 수 있다. 상술한 절차는, 단순히 예시적인 것으로 적어도 일부의 절차가 생략되거나, 다른 절차가 추가될 수도 있음을 당업자는 이해할 것이다. 419 동작에서, 시작 클라우드 및 타겟 클라우드은 디바이스 및 리소스 디스커버리 절차를 수행할 수 있다. 디바이스 및 리소스 디스커버리 절차는, 예를 들어 시작 클라우드가 타겟 클라우드에 연결된 디바이스 및 제공되는 리소스를 디스커버리하는 일련의 절차를 의미할 수 있다. 예를 들어, 디바이스 및 리소 스 디스커버리 절차는, 시작 클라우드가 타겟 클라우드로 억세스 토큰을 포함하는, 디바이스 정보 요 청 메시지(예: GET https://devices)를 송신하는 동작을 포함할 수 있다. 디바이스 및 리소스 디스커버리 절차 는, 타겟 클라우드가, 응답으로서, 타겟 클라우드가 호스팅하는 디바이스들에 대한 정보를 포함하는 메시지(예: 200 OK)를, 시작 클라우드로 송신하는 동작을 포함할 수 있다. 421 동작에서, 어플리케이션은 시작 클라우드에 대하여 리소스 제어(resource)를 요청할 수 있다. 리소스 제어는, 예를 들어 타겟 클라우드에 연결되는 디바이스의 제어, 디바이스로부터의 정보 획득, 또는 타겟 클라우드에 의하여 제공되는 리소스 이용 중 적어도 하나를 포함할 수 있으며, 그 종류에는 제한이없다. 예를 들어, 어플리케이션은 시작 클라우드에 POST coaps://deviceid/resourcehref 메시지를 송신할 수 있다. 메시지는, 예를 들어 디바이스 식별자(deviceid) 및 링크 파라미터(resourcehref)를 포함할 수 있으나, 제한은 없다. 페이로드는, RT(resource type)의 업데이트를 위하여 OCF에 의하여 정의될 수 있다. 어플리케이션은 CoAP 방식이 아닌 다른 방식에 기반하여 리소스 제어를 요청할 수도 있음을 당업자는 이해 할 것이다. 423 동작에서, 시작 클라우드는, 타겟 클라우드에 리소스 제어를 요청할 수 있다. 예를 들어, 시작 클라우드는 타겟 클라우드에 POST coaps://deviceid/resourcehref 메시지를 송신할 수 있다. 425 동작에서, 타겟 클라우드는, 디바이스에 리소스 제어를 요청할 수 있다. 예를 들어, 타 겟 클라우드는, 예를 들어 deviceid에 대응하는 디바이스에 POST coaps://resourcehref 메시지를 송 신할 수 있다. 예를 들어, 디바이스는, POST coaps://resourcehref 메시지에 대응하여 2.05 응답 메시지 를 송신할 수 있다. 타겟 클라우드는, 2.05 응답 메시지를 시작 클라우드에 송신할 수 있으며, 시작 클라우드는 2.05 응답 메시지를 어플리케이션으로 송신할 수 있다. 427 동작에서, 어플리케이션은 관측(observer)을 요청할 수 있다. 예를 들어, 어플리케이션은, 디바 이스에서의 이벤트에 대한 관측을 요청할 수 있으며, 이는 사용자 조작(또는, 다른 조건의 충족)에 의하여 요청될 수 있다. 한편, 이벤트에 대한 관측은 단순히 예시적인 것으로, 관측 요청 이외에도 어플리케이션(40 1)을 통한 디바이스의 제어 또한 가능함을 당업자는 이해할 것이다. 예를 들어, 어플리케이션은 시 작 클라우드로 GET coaps://deviceid/resourcehref 메시지를 송신할 수 있다. 메시지에는, 예를 들어 관 측 요청을 나타내는 정보(예; observe=0(register))가 포함될 수도 있다. 시작 클라우드는, 429 동작에서, 이벤트 구독(event subscription)을 타겟 클라우드에 요청할 수 있다. 예를 들어, 시작 클라우 드는, POST https://devices/resourcehref/subscriptions 메시지를 타겟 클라우드로 송신할 수 있다. 메시지에는, 예를 들어 이벤트 타입(event type)(예를 들어, 리소스 컨텐츠가 변경되는 타입), 이벤트 URL(예를 들어, https://eventsurl), 또는 signing secret 중 적어도 하나를 포함할 수 있으며, 제한은 없다. 타겟 클라우드는, 시작 클라우드에 200 OK 메시지를 송신할 수 있다. 메시지에는, 구독 식별자 (subscription-ID)(예를 들어, UUID)가 포함될 수 있다. 타겟 클라우드는, 디바이스로 구독의 등록 을 요청하는 메시지(예: GET coaps://resourcehref)를 송신할 수 있다. 디바이스는, 이에 대응하여 구독 의 등록을 확인하는 2.05 응답 메시지를 타겟 클라우드에 송신할 수 있다. 메시지에는, 구독의 등록을 나 타내는 정보(예: observe=0), 또는 장치 식별자 중 적어도 하나가 포함될 수도 있다. 타겟 클라우드는, signing secret을 이용하여 HMAC-SHA256 시그니처를 계산할 수 있다. 타겟 클라우드는, 시작 클라우드 에 Post https://eventsrul의 메시지를 송신할 수 있다. 메시지에는, 예를 들어 구독 식별자(예: UUID), 시퀀스 넘버, 이벤트 타입, 또는 이벤트 시그니처(event signature) 중 적어도 하나가 포함될 수 있다. 시작 클라우드는, 이에 대응하여 200 OK 메시지를 타겟 클라우드로 송신할 수 있다. 시작 클라우드 는, 이벤트 시그니처를 인증할 수 있다. 시작 클라우드는, HMAC-SHA256 시그니처를 계산하고, 이를 수신 한 정보와 비교할 수 있다. 시작 클라우드는, 어플리케이션에 2.05 확인 메시지를 송신할 수 있으며, 메시지에는 구독이 등록되었음을 나타내는 정보가 포함될 수도 있다. 431 동작에서, 타겟 클라우드는, 디바이스로부터 이벤트 발생을 확인할 수 있다. 433 동작에서, 타 겟 클라우드는, 시작 클라우드에 이벤트를 통지할 수 있으며, 435 동작에서 시작 클라우드는 어 플리케이션에 이벤트를 통지할 수 있다. 예를 들어, 디바이스에서 이벤트가 발생한 경우를 상정하도 록 한다. 예를 들어, 디바이스는, 타겟 클라우드에 2.05 응답 메시지를 타겟 클라우드에 송신 할 수 있다. 메시지에는, 이벤트에 대한 정보가 포함될 수도 있다. 타겟 클라우드는, signing secret을 이용하여 HMAC-SHA256 시그니처를 계산할 수 있다. 타겟 클라우드는, 시작 클라우드에 Post https://eventsrul의 메시지를 송신할 수 있다. 메시지에는, 예를 들어 구독 식별자(예: UUID), 시퀀스 넘버, 이벤트 타입, 또는 이벤트 시그니처(event signature) 중 적어도 하나가 포함될 수 있다. 시작 클라우드 는, 이에 대응하여 200 OK 메시지를 타겟 클라우드로 송신할 수 있다. 시작 클라우드는, 이벤트 시 그니처를 인증할 수 있다. 시작 클라우드는, HMAC-SHA256 시그니처를 계산하고, 이를 수신한 정보와 비교 할 수 있다. 시작 클라우드는, 어플리케이션에 2.05 확인 메시지를 송신할 수 있으며, 메시지에는 이벤트에 대한 정보가 포함될 수도 있다. 도 5는, 일 실시예에 따른 전자 장치, 미디어 장치, 및 AI 서버를 도시한다. 일 실시예에 따른, 전자 장치 는, 예를 들어 도 1에서의 AI 스피커와 같은 마이크 및 스피커를 포함할 수 있다. 전자 장치의 마이크는, 전자 장치의 외부의 음성, 즉 공기의 떨림을 전기적인 신호인 음성 데이터로 변환할 수 있다. 전자 장치는, 음성 데이터에 기반하여 트리거 음성을 인식할 수 있다. 트리거 음성은, 음성 인식 서비스 를 개시하기 위하여 설정된 음성으로, 예를 들어 음성 인식 서비스 제공에서 고안한 텍스트(예: hi bixby, okgoogle, shiri, 또는 Alexa 등)으로 설정될 수 있다. 전자 장치는, 트리거 음성에 대응하는 텍스트가 검 출되는지 여부를 확인할 수 있으며, 본 개시에서 트리거 음성의 인식은, 트리거 음성에 대응하는 텍스트의 인식 으로 이해될 수도 있다. 일 실시예에 따라서, 전자 장치는, 트리거 음성이 인식되면, 이에 대응하는 응답 음성을 스피커를 통하여 출력할 수 있다. 전자 장치는, 응답 음성 이후에 추가적으로 마이크를 통하여 입력되는 음성 데이터에 기 반하여 동작할 수 있다. 예를 들어, 전자 장치는, 음성 데이터를 AI 서버(예: 도 1의 보이스 어시스 턴트 서버)로 음성 데이터를 전달할 수 있으며, AI 서버는 음성 데이터를 처리하여 대응하는 동작을 수행할 수 있다. 또는, 전자 장치가 음성 데이터를 인식하여 획득된 명령어를 AI 서버로 전달할 수 도 있으며, AI 서버에서는 명령어를 처리할 수도 있다. 구현에 따라, 트리거 음성 없이, 전자 장치 는 음성 데이터를 처리(예: AI 서버로 송신, 및/또는 음성 데이터를 인식하여 획득된 명령어를 AI 서버 로 송신)할 수도 있다. 아울러, 도 5에서는, 전자 장치가 AI 서버로, 음성 데이터 및/또는 명 령어를 송신하는 것과 같이 도시되어 있지만, 이는 단순히 예시적인 것으로, 전자 장치는, 홈 네트워크에 연결된 적어도 하나의 장치(예: 장치들(121,122,123)) 또는 IoT 서버(예: IoT 서버)에 음성 데이터 및/또 는 명령어를 송신할 수도 있으며, 적어도 하나의 장치는 음성 데이터 및/또는 명령어에 대응하는 동작을 수행할 수 있다. 한편, 전자 장치는, 도 5에서와 같이 AI 스피커와 같이 도시되어 있지만, 이는 단순히 예시적인 것으로 음성을 처리하여 대응하는 동작을 수행할 수 있는 장치라면 제한이 없음을 당업자는 이해할 것이다. 일 실시예에 따라서, 미디어 장치는, 미디어 파일에 대응하는 컨텐트를 출력할 수 있다. 도 5에서와 같이, 미디어 장치는 디스플레이를 통한 화면 및 음성을 함께 출력할 수 있으며, 이 경우 컨텐트는 화면 및 음성을 함께 포함하는 동영상 컨텐트일 수 있다. 한편, 음성을 포함하는 컨텐트를 제공 가능한 미디어 파일이라면 제한이 없음을 당업자는 이해할 것이다. 아울러, 미디어 장치 또한 도 5에서와 같이, TV 뿐만 아니라 음성을 포함하는 컨텐트를 출력할 수 있는 장치라면 제한이 없다. 한편, 도 5에서와 같이, 미디어 장치로부터 출력된 음성이 전자 장치에 의하여 음성 데이터로 변환될 수 있다. 만약, 미디어 장치로부터 출력된 음성에 트리거 음성(예: Hi, Bixby, OK, google, Shiri 등)이 포함된 경우, 전자 장치는 음성을 변환한 음성 데이터로부터 트리거 음성을 검출할 수 있다. 전자 장치는, 트리거 음성 이후의 추가 음성을 처리할 수 있다. 만약, 추가 음성에 특정 물품에 대 한 구매 명령이 포함된 경우, 전자 장치 및/또는 AI 서버는, 추가 음성에 대응하는 구매 명령을 수행 할 수도 있다. 예를 들어, 전자 장치는, 추가 음성에 대한 처리 요청을 AI 서버로 송신할 수 있으며, AI 서버는 추가 음성에 대한 처리를 수행함으로써, 구매 명령을 인식하고, 구매 명령에 대응하는 동작을 수행할 수 있다. 또는, 전자 장치는, 추가 음성으로부터 구매 명령을 직접 인식하고, 구매 명령에 대응하는 동작을 직접 수행할 수도 있다. 본 개시에 따른, 미디어 장치는 출력하는 음성에 트리거 음성 및/또는 명령이 포함되는지 여부를 확 인할 수 있다. 만약, 출력하는 음성에 트리거 음성 및/또는 명령이 포함되는 경우, 이를 전자 장치 에 알릴 수 있다. 전자 장치는, 출력하는 음성에 트리거 음성 및/또는 명령이 포함되는 것으로 확인 되면, 트리거 음성 및/또는 명령의 처리를 스킵하거나, 또는 처리 여부를 문의할 수도 있다. 도 6은 일 실시예에 따른 전자 장치 및 미디어 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 6의 실시예는, 도 7a를 참조하여 설명하도록 한다. 도 7a는 일 실시예에 따른 전자 장치 및 미디어 장치의 블록도 를 도시한다. 본 개시에서, 전자 장치 및/또는 미디어 장치가 특정 동작을 수행하는 것은, 전자 장 치 및/또는 미디어 장치에 포함된 프로세서 및/또는 프로세서가 특정 동작을 수행하거나, 다른 하드웨어가 특정 동작을 수행하도록 제어함을 의미할 수 있다. 또는, 전자 장치 및/또는 미디어 장 치가 특정 동작을 수행하는 것은, 메모리 및/또는 메모리에 저장된 인스트럭션이 실행되어, 프 로세서 및/또는 프로세서가 특정 동작을 수행하거나, 다른 하드웨어가 특정 동작을 수행하도록 제어 함을 의미할 수 있다. 또는, 전자 장치 및/또는 미디어 장치가 특정 동작을 수행하는 것은, 특정 동 작 수행을 위한 인스트럭션이 메모리 및/또는 메모리에 저장됨을 의미할 수도 있다. 일 실시예에 따라서, 미디어 장치는, 601 동작에서 미디어 파일을 획득할 수 있다. 미디어 장치의 프로세서는, 미디어 파일을 획득할 수 있다. 미디어 장치의 프로세서는, 예를 들어 메모리 에 미리 저장된 미디어 파일(예: 음원 파일, 또는 동영상 파일)을 로딩할 수 있다. 메모리는, 미디 어 장치에 포함되는 것과 같이 도시되어 있지만, 구현에 따라 탈부착이 가능한 저장 수단(예: USB 스토리 지, 또는 외장 하드)으로 구현되어 미디어 장치에 유선 또는 무선으로 연결될 수도 있다. 미디어 장치는, 특정 미디어 파일에 대한 재생 명령(예를 들어, 특정 미디어 파일에 대응하는 아이콘에 대한 선택)을 확인할 수 있으며, 이에 기반하여 미디어 파일을 로딩할 수 있다. 또 다른 예에서, 미디어 장치는, 실시 간으로 미디어 파일을 스트리밍할 수도 있다. 미디어 장치는, 예를 들어 컨텐트 재생을 위한 데이터를 포 함하는 복수의 패킷을 통신 회로를 통하여 수신할 수 있거나, 또는 방송 데이터를 방송 신호 수신 모듈(미 도시)을 통하여 수신할 수 있다. 수신된 데이터는 버퍼(예: 메모리 내의 버퍼 또는 메모리 외부의 버퍼)에 저장될 수 있으며, 프로세서는 저장된 데이터를 로딩할 수 있다. 본 개시에서의 미디어 파일의 획득은, 상술한 바와 같이 미리 저장된 미디어 파일의 로딩 및/또는 통신 회로를 통하여 획득된 데이터의 로딩을 포함할 수 있으며, 제한은 없음을 당업자는 이해할 것이다. 일 실시예에 따라서, 미디어 장치는, 603 동작에서, 미디어 파일에 대응하는 컨텐트를 출력하면서, 미디어 파일로부터 트리거 음성을 검출할 수 있다. 예를 들어, 프로세서는, 미디어 파일이 디코딩된 신호에 기반 하여 트리거 음성, 예를 들어 트리거 음성에 대응하는 텍스트를 검출할 수 있다. 예를 들어, 프로세서는, 인코딩된 미디어 파일을 획득할 수 있으며, 컨텐트 출력을 위하여 인코딩된 미디어 파일을 디코딩할 수 있다. 프로세서는, 디코딩된 신호를 스피커로 전달할 수 있으며, 스피커는 디코딩된 신호에 대응하는 음성을 출력할 수 있다. 만약, 미디어 파일이 동영상 파일인 경우에는, 프로세서가 디스플레이(미도시)를 통하여 동영상 파일에 기반한 화면을 출력하도록 제어할 수 있음을 당업자는 이해할 것이다. 프로세서는, 디코딩된 신호에 기반하여 음성 인식을 수행할 수 있다. 예를 들어, 프로세서는, 디코딩된 신호에 ASR을 수행하여 디코딩된 신호에 대응하는 텍스트를 확인할 수 있다. 프로세서는, 확인된 텍스트에 트리거 음성 에 대응하는 텍스트가 포함되는지 여부를 확인할 수 있다. 프로세서는, 상술한 텍스트 비교에 기반하여 트리거 음성이 출력되는 음성에 포함되는지 여부를 검출할 수 있다. 한편, 디코딩된 미디어 파일을 직접 획득 한 경우에는, 프로세서는, 별도의 디코딩 과정 없이 미디어 파일에 기반하여 트리거 음성의 검출 여부를 확인할 수 있다. 일 실시예에 따라서, 미디어 장치는, 605 동작에서, 트리거 음성이 검출됨을 전자 장치에 알릴 수 있 다. 예를 들어, 미디어 장치의 프로세서는, 통신 회로를 통하여, 전자 장치의 통신 회로 로 트리거 음성이 검출됨을 나타내는 정보를 포함하는 통신 신호를 송신할 수 있다. 해당 통신 신호에 의 하여 전자 장치가 추가 음성 데이터 처리를 스킵할 수 있으므로, 해당 통신 신호를 무시 명령(ignore command)라 명명될 수도 있다. 도 7a에서는, 미디어 장치가 전자 장치로 별도의 중계 장치 없이 직 접 통신 신호를 송신하는 것과 같이 도시되어 있지만, 이는 예시적인 것으로 미디어 장치 및 전자 장치 사이의 통신 신호의 송수신을 적어도 하나의 중계 장치가 수행할 수도 있다. 예를 들어, 블루투스 계열 의 통신, Wi-Fi direct, Z-wave, Zig-bee, INSETEON, X10, UWB 또는 IrDA(infrared data association)과 같은 P2P 통신인 경우에는, 통신 회로가 트리거 음성이 검출됨을 나타내는 정보를 포함하는 통신 신호를 중계 장치 없이 전자 장치의 통신 회로로 송신할 수 있다. 통신 회로들(512,522) 사이에 이미 페어링 (paring)(또는, 연결(connection))은 형성된 것을 상정하도록 한다. 또는, 통신 회로가 와이 파이 통신을 통하는 경우, 적어도 하나의 억세스 포인트(미도시)를 통하여 전자 장치의 통신 회로로 트리거 음성 이 검출됨을 나타내는 정보를 포함하는 통신 신호를 송신할 수도 있다. 또는, 통신 회로는, 네트워크 통 신(예: 인터넷 통신)을 통하여 통신 회로로 트리거 음성이 검출됨을 나타내는 정보를 포함하는 통신 신호 를 송신할 수도 있다. 일 실시예에 따라서, 전자 장치는, 607 동작에서, 트리거 음성이 미디어 장치에서 검출됨을 확인할 수 있다. 전자 장치의 프로세서는, 통신 회로를 통하여 수신되는 통신 신호로부터 트리거 음성 이 검출됨을 나타내는 정보를 확인할 수 있다. 609 동작에서, 전자 장치는, 마이크를 통하여 획득되 는 음성 데이터에서 트리거 음성이 검출된 경우, 추가 음성 데이터 처리를 스킵할 수 있다. 미디어 장치 의 스피커로부터 출력되는 음성이, 예를 들어 하나의 말뭉치인 “Hi, bixby”일 수 있다. 미디어 장 치의 프로세서는, “Hi, bixby”을 출력하기 위한 미디어 파일(예: 미디어 파일이 디코딩된 신호)에 트리거 음성에 대응하는 텍스트인 “Hi, bixby”가 포함된 것을 확인할 수 있다. 미디어 장치의 프로세서 는, 트리거 음성이 검출됨을 나타내는 통신 신호를 전자 장치로 송신할 수 있다. 전자 장치의 프로세서는, 통신 회로를 통하여 수신된 통신 신호에 기반하여, 미디어 장치로부터 트리거 음성 이 검출됨을 나타내는 음성이 출력되었음을 확인할 수 있다. 아울러, 프로세서는, 마이크로부터 외 부로부터 발생한 음성이 변환된 음성 데이터를 수신할 수 있다. 프로세서는, 예를 들어 음성 데이터 에 대하여 ASR을 수행하여 “Hi, bixby”의 텍스트를 확인할 수 있다. 프로세서는, 마이크를 통하여 획득된 음성 내에 트리거 음성인 “Hi, bixby”가 포함됨을 확인할 수 있다. 프로세서는, 미디어 장 치로부터 트리거 음성이 출력되었음에 기반하여, 마이크를 통하여 획득된 음성 내의 트리거 음성을 무시할 수 있다. 예를 들어, 프로세서는, 마이크를 통하여 획득된 음성 내의 트리거 음성 이 포함된 경우에, “What can I do for you?”의 응답 음성을 출력하도록 설정될 수 있다. 하지만, 미디어 장 치로부터 트리거 음성이 검출됨을 나타내는 음성이 출력되었음에 기반하여, 프로세서는 응답 음성을 출력하지 않을 수 있다. 프로세서는, 이후 추가 음성 데이터가 획득되더라도, 해당 음성 데이터를 처리하 지 않을 수 있다. 또는, 프로세서는, 외부 전자 장치가 자신을 호출하였음을 나타내는 음성(예: Another device calls me, right?)을 스피커(미도시)를 통하여 출력하고, 추가 음성 데이터를 처리하지 않을 수도 있다. 만약, 사용자로부터의 추가 음성 데이터으로부터, 이후 추가 음성 데이터에 대한 처리 명령이 인식되면, 전자 장치는 추가 음성 데이터를 처리할 수도 있다. 일 실시예에 따라서, 프로세서는, 수신된 통신 신호에 기반하여 미디어 장치에서 트리거 음성이 출력됨을 확인한 제 1 시점과, 마이크를 통하여 획득된 음성 데이터에서 트리거 음성이 포함됨을 확인한 제 2 시점을 확인할 수 있다. 프로세서는, 제 1 시점 및 제 2 시점의 사이의 차이가 미리 지정된 조건을 만족하는 경우(예를 들어, 제 1 시점 및 제 2 시점 사이의 차이가 임계치 미만인 경우)에, 트리거 음성 이후의 추가 음성 데이터를 처리하지 않도록 설정될 수도 있다. 임계치는, 미디어 장치에서의 음성 인식에 소요 되는 시간, 통신 신호의 생성에 소요되는 시간, 통신 신호의 송수신에 소요되는 시간, 전자 장치가 통신 신호로부터 정보를 확인하는데 소요되는 시간, 또는 전자 장치가 트리거 음성을 인식하는데 소요되는 시간 중 적어도 하나를 고려하여 설정될 수 있으나, 그 설정에 이용되는 팩터에는 제한이 없다. 이에 따라, 미디어 장치로부터 트리거 음성이 출력된 이후에, 일정 시간이 지난 후에 사용자가 트리거 음성을 발화한 경우, 전자 장치는 사용자의 트리거 음성에 대응하여 동작할 수도 있다. 한편, 상술한 제 1 시점 및 제 2 시점 에 의한 조건은 단순히 예시적인 것으로, 전자 장치가, 트리거 음성을 인식하는 과정에서 확인되는 시점들, 미디어 장치로부터 통신 신호로부터 정보를 확인하는 과정에서 확인되는 시점들 중 적어도 하나를 포함하는 조건으로 치환될 수 있음을 당업자는 이해할 것이다. 일 실시예에서, 프로세서가, 트리거 음성 및 명령을 함께 인식하는 경우에는, 트리거 음성 이후에 검출된 음성에 대한 처리를 스킵하도록 설정될 수도 있다. 예를 들어, 미디어 장치가 하나의 말뭉치인 “Hi, bixby, buy one soccer ball”의 음성을 출력하는 경우를 상정하도록 한다. 프로세서는, 예를 들어 음성 데이터에 대하여 ASR을 수행하여, 하나의 말뭉치인 “Hi, bixby, buy one soccer ball”의 텍스트를 확인할 수 있다. 프로세서는, 마이크를 통하여 획득된 음성 내에 트리거 음성인 “Hi, bixby”가 포함됨 을 확인할 수 있다. 프로세서는, “Hi, bixby”의 트리거 음성 이후의 텍스트인 “buy one soccer ball ”의 명령의 처리 여부를, 미디어 장치에서 트리거 음성이 출력된지 여부에 따라 결정할 수 있다. 예를 들어, 미디어 장치는 출력하는 음성인 “Hi, bixby, buy one soccer ball”에 트리거 음성이 포함됨을 확 인할 수 있으며, 트리거 음성이 검출됨을 통신 회로를 통하여 전자 장치로 알릴 수 있다. 미디어 장 치에서 트리거 음성이 출력된 것이 확인되면, 프로세서는, “Hi, bixby”의 트리거 음성 이후의 “ buy one soccer ball”의 처리를 스킵할 수 있다. 미디어 장치에서 트리거 음성이 출력된 것이 확인되지 않으면, 프로세서는, “Hi, bixby”의 트리거 음성 이후의 “buy one soccer ball”의 처리를 수행할 수 있다. 예를 들어, 프로세서는, AI 서버로 “buy one soccer ball”의 처리를 요청할 수 있으며, AI 서버는, “buy one soccer ball”에 대응하는 명령인, 축구공의 전자상거래 구매를 수행할 수 있다. 또는, 프로세서는, “buy one soccer ball”를 인식하여 구매 명령을 생성할 수 있으며, 구매 명령을 AI 서버(또는, 전자 상거래와 연관된 외부 장치)로 송신할 수도 있다. 일 실시예에 따라서, 프로세서 및/또는 프로세서는, CPU(central processing unit), DSP(digital signal processor), AP(application processor), CP(communication processor) 등과 같은 범용 프로세서, GPU(graphical processing unit), VPU(vision processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU(neural processing unit)와 같은 인공 지능 전용 프로세서 중 하나 이상의 조합으로 구현될 수 있다. 통신 회로 및/또는 통신 회로는, 상술한 다양한 통신 방식 중 적어도 하나 이상을 지원하는 통신 모듈 또는, 통신 모 듈의 집합으로 구현될 수 있으며, 각각은 하나 또는 그 이상의 하드웨어로 구현될 수 있다. 메모리 및/또 는 메모리는, 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카 드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램 (RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있으며, 그 종류에는 제한이 없 다. 메모리 및/또는 메모리에는, 본 개시에서 수행되는 동작을 수행하도록 하는 적어도 하나의 인스 트럭션이 저장될 수 있다. 메모리 및/또는 메모리에는, ASR 및/또는 트리거 음성을 검출할 수 있는위한 알고리즘(또는, 모델)이 저장될 수도 있다. 도 7b는 일 실시예에 따른 전자 장치 및 미디어 장치의 블록도를 도시한다. 도 7b를 참조하면, 미디어 장치의 프로세서에는 미디어 소스, 디코더, 또는 음성 인식 모 듈 중 적어도 하나가 포함될 수 있다. 전자 장치의 프로세서에는 음성 인식 모듈 또는 명 령 프로세서 중 적어도 하나가 포함될 수 있다. 본 개시에서 프로세서 및/또는 프로세서에 구 성요소(예: 명령 프로세서, 미디어 소스, 디코더, 음성 인식 모듈(531,543))가 포함되는 것은, 해당 하드웨어가 프로세서의 SoC(system on chip)에 포함되는 것을 의미할 수 있거나, 또는 해당 구성 요 소의 동작을 수행하기 위한 소프트웨어가 프로세서에 의하여 로딩되어 동작함을 의미할 수도 있다. 일 실시예에 따라서, 미디어 장치의 미디어 소스는 미디어 파일을 획득할 수 있다. 미디어 소스 는, 예를 들어 미디어 파일이 로딩을 위한 프로그램 및/또는 하드웨어를 의미할 수 있으나, 제한은 없다. 또는, 미디어 소스는, 미디어 파일이 제공되는 소스를 의미할 수도 있으며, 이 경우 미디어 소스는, 저장 수단, 또는 통신 회로를 의미할 수도 있고, 이 때에는 프로세서의 외부에 위치할 수도 있다. 일 실시예에 따라서, 디코더는, 미디어 소스로부터 제공되는 인코딩된 미디어 파일을 디코딩할 수 있 다. 오디오 컨텐트의 미디어 파일은, 예를 들어 MP3 방식, AAC(Advanced Audio Coding) 방식, WMA(Windows Media Audio) 방식, Vorbis 방식, FLAC(Free Lossless Audio Codec) 방식, Opus 방식, AC3 방식, AMR- WB(Adaptive Multi-Rate Wideband) 방식 중 적어도 하나의 방식에 따라 인코딩/디코딩될 수 있으며, 그 방식에 는 제한이 없다. 비디오 컨텐트의 미디어 파일은, 예를 들어 H.26x 방식, WMV (Windows Media Video) 방식, Theora 방식, VP8 방식, VP9 방식, 또는 AV1 방식 중 적어도 하나의 방식에 따라 인코딩/디코딩될 수 있으며, 그 방식에는 제한이 없다. 디코더는, 상술한 다양한 디코딩 방식 중 적어도 하나에 따라 인코딩된 미디어 파일을 디코딩할 수 있다. 일 실시예에 따라서, 디코더는, 디코딩된 신호를 음성 인식 모듈 및 스피커로 제공할 수 있다. 스피커는, 디코딩된 신호에 기반하여 음성을 출력할 수 있다. 스피커는, 예를 들어 아날로그 형태의 신호를 음성으로 출력할 수 있다. 음성 인식 모듈은, 디코딩된 신호에 기반하여 트리거 음성을 검출할 수 있다. 음성 인식 모듈은, 일 실시예에서 트리거 음성 및/또는 그 외의 음성을 인식하도록 설정될 수 있다. 만약, 음성 인식 모듈이 트리거 음성만을 검출하도록 설정된 경우, 음성 인식 모듈은 상대적 으로 경량의 음성 인식 모델로 구현될 수 있다. 구현에 따라, 음성 인식 모듈은, 트리거 음성 이외에도 다른 음성을 인식할 수도 있도록 구현될 수도 있다. 다른 실시예에서는, 음성 인식 모듈은 ASR 및 NLU까 지 수행할 수도 있다. 이 경우 음성 인식 모듈은, 미디어 파일로부터 트리거 음성 이외에도 명령을 검출 할 수도 있으며, 이에 대하여서는 더욱 상세하게 후술하도록 한다. 일 실시예에 따라서, 음성 인식 모듈은, 미디어 파일에 기반하여 트리거 음성이 검출되면, 트리거 음성이 발생되었음을 나타내는 정보를 통신 회로를 통하여 전자 장치로 송신할 수 있다. 해당 정보는, 예를 들어 플래그 형식으로 구현될 수 있으나, 그 표현 형태에는 제한이 없다. 일 실시예에 따라서, 마이크는, 외부로부터의 음성을 음성 데이터로 변환하여 출력할 수 있다. 예를 들어, 마이크는, 아날로그 음성을 전기적인 신호로 변환하여 출력할 수 있다. 음성 인식 모듈은, 음 성 데이터에 기반하여 트리거 음성을 검출할 수 있다. 음성 인식 모듈은, 트리거 음성 및/또는 트리거 음 성이 검출됨을 나타내는 정보를 명령 프로세서로 전달할 수 있다. 명령 프로세서는, 명령어를 처리 하는 모듈로, 예를 들어 AI 서버, 또는 IoT 서버와 같은 외부 장치로, 음성의 처리를 요청하거나, 및/또는 명령 어를 전달할 수 있다. 또는, 명령 프로세서는, 외부 전자 장치의 개입 없이, 직접 명령에 대응하는 동작 을 수행할 수도 있다. 일 실시예에 따라서, 명령 프로세서는, 음성 인식 모듈로부터 트리거 음성 및/또는 트리거 음성이 검 출됨을 나타내는 정보를 수신할 수 있다. 명령 프로세서는, 통신 회로를 통하여 수신되는 통신 신호 로부터 미디어 장치로부터 트리거 음성이 출력됨을 나타내는 정보를 확인할 수 있다. 명령 프로세서(53 2)는, 미디어 장치로부터 트리거 음성이 출력됨을 나타내는 정보에 기반하여, 음성 인식 모듈에 의하 여 인식되는 트리거 음성 및/또는 추가 음성 데이터의 처리를 스킵할 수 있다. 도 8은 일 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 8의 동작들 중 기 설 명된 동작에 대하여서는 그 설명을 간명하게 하도록 한다. 일 실시예에 따른, 전자 장치는, 801 동작에서, 마이크를 통하여 음성 데이터를 획득할 수 있다. 803 동 작에서, 전자 장치는, 음성 데이터에서 트리거 음성을 검출할 수 있다. 805 동작에서, 전자 장치는, 미디어 장치로부터, 트리거 음성이 검출됨을 나타내는 정보가 수신되는지 여부를 확인할 수 있다. 트리거 음성이 검출되는 것으로 확인되면(805-예), 전자 장치는, 807 동작에서, 추가 음성 데이터 처리를 스킵할 수 있다. 예를 들어, 전자 장치는, 음성 데이터에서 트리거 음성이 검출됨에도 불구하고, 응답 음 성을 출력하지 않을 수 있다. 예를 들어, 전자 장치는, 트리거 음성 이후에 추가 음성 데이터에 대한 처 리(예: AI 서버로의 처리 요청 및/또는 전자 장치 내에서의 처리)를 스킵할 수 있다. 트리거 음성이 검출 되지 않은 것으로 확인되면(805-아니오), 전자 장치는 809 동작에서 추가 음성 데이터를 처리할 수 있다. 하나의 예에서, 전자 장치는, 트리거 음성(예: Hi, bixby)에 대응하여 응답 음성(예: What can I do for you?)을 스피커를 통하여 출력할 수 있으며, 이후 추가적으로 획득되는 추가 음성 데이터(예: buy one soccer ball)를 처리할 수 있다. 예를 들어, 전자 장치는, 추가 음성 데이터의 처리를 AI 서버로 전달할 수 있으 며, AI 서버로부터 처리 결과가 수신되면 처리 결과에 대응하는 동작을 수행할 수 있다. 예를 들어, 전자 장치 는, 추가 음성 데이터로부터 직접 명령을 인식할 수 있으며, 해당 명령에 대응하는 동작을 수행하거나, 또 는 외부 장치로 명령어를 전달할 수도 있다. 다른 예에서, 전자 장치는, 트리거 음성과 추가 음성(예: Hi, bixby, buy one soccer ball)을, 중간에 응답 음성 출력 없이 획득할 수도 있다. 예를 들어, 전자 장치 는, 트리거 음성 이후에 추가 음성 데이터(예: buy one soccer ball)에 대한 처리(예: AI 서버로의 처리 요청 및/또는 전자 장치 내에서의 처리)를 스킵할 수 있다 도 9는 일 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 9의 동작들 중 기 설 명된 동작에 대하여서는 그 설명을 간명하게 하도록 한다. 일 실시예에 따른, 전자 장치는, 901 동작에서, 마이크를 통하여 음성 데이터를 획득할 수 있다. 903 동 작에서, 전자 장치는, 음성 데이터에서 트리거 음성이 검출됨을 확인할 수 있다. 905 동작에서, 전자 장 치는 미디어 장치로부터, 트리거 음성이 검출됨을 나타내는 정보를 수신할 수 있다. 907 동작에서, 전자 장치는, 추가 음성 데이터의 처리 여부를 문의할 수 있다. 예를 들어, 전자 장치는, 스피커를 통하여, “Are you sure you called me?”와 같은 음성을 출력하거나, 또는 추가 음성 데이터의 처리 여부를 문 의하는 메시지를 디스플레이로 출력할 수도 있으며, 출력 예시에는 제한이 없다. 일 실시예에 따라서, 전자 장치는, 909 동작에서, 추가 음성 데이터의 처리 명령이 획득되는지 여부를 확 인할 수 있다. 예를 들어, 전자 장치는, 사용자 확인음성(예: Yes), 또는 디스플레이에 표시되는 승인 아 이콘의 선택 등에 기반하여, 추가 음성 데이터의 처리 명령이 획득되는지 여부를 확인할 수 있다. 추가 음성 데이터의 처리 명령이 획득되지 않는 경우(909-아니오), 전자 장치는 911 동작에서 추가 음성 데이터 처리 를 스킵할 수 있다. 추가 음성 데이터의 처리 명령이 획득되는 경우(909-예), 전자 장치는 913 동작에서 추가 음성 데이터를 처리할 수 있다. 도 10은 일 실시예에 따른 전자 장치 및 미디어 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 10 의 실시예는 도 11을 참조하여 설명하도록 한다. 도 11은 일 실시예에 따른 전자 장치 및 미디어 장치의 동작 을 설명하기 위한 도면을 도시한다. 도 10의 동작들 중 기 설명된 동작에 대하여서는 그 설명을 간명하게 하도 록 한다. 일 실시예에 따른, 미디어 장치는, 1001 동작에서, 미디어 파일을 획득할 수 있다. 미디어 장치는, 1003 동작에서, 미디어 파일에 대응하는 컨텐트를 출력할 수 있다. 1005 동작에서, 미디어 장치는, 미디 어 파일의 적어도 일부에 대응하는 정보를 전자 장치로 제공할 수 있다. 예를 들어, 도 11에서와 같이, 미디어 장치는, 디코딩된 신호에 대한 정보를 포함하는 통신 신호를 전자 장치로 송신할 수 있 다. 또는, 미디어 장치는, 도 11에서와 같이, 디코딩된 신호에 대한 음성 인식 결과(예: ASR 적용 결과) 인 텍스트에 대한 정보를 포함하는 통신 신호를 전자 장치로 송신할 수 있다. 예를 들어, 미디어 장치는, 실시간으로 미디어 파일에 대한 정보를 전자 장치로 송신하거나, 또는 이벤트 검출 기반으로 미디어 파일에 대한 정보를 전자 장치로 송신할 수 있다. 일 실시예에 따라서, 전자 장치는, 1007 동작에서, 마이크를 통하여 획득되는 음성 데이터와, 수신된 미디 어 파일에 대응하는 정보가 대응되는지 여부를 확인할 수 있다. 예를 들어, 전자 장치는 디코딩된 신호 와 마이크로부터 출력되는 아날로그 신호 사이의 유사도가 임계치를 초과하는지 여부를 확인할 수 있다. 또 다른 예에서, 전자 장치는, 미디어 파일로부터 검출된 텍스트가, 마이크로부터 출력되는 아날로 그 신호로부터 인식되는 텍스트에 대응되는 지 여부를 확인할 수 있다. 마이크를 통하여 획득되는 음성 데이터 와, 수신된 미디어 파일이 대응됨에 기반하여, 전자 장치는 1009 동작에서 음성 데이터의 처리를 스킵할수 있다. 도 12는 일 실시예에 따른 전자 장치 및 미디어 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 12 의 실시예는 도 13을 참조하여 설명하도록 한다. 도 13은 일 실시예에 따른 미디어 파일에 대한 정보를 설명하 기 위한 도면이다. 도 12의 동작들 중 기 설명된 동작에 대하여서는 그 설명을 간명하게 하도록 한다. 일 실시예에 따른, 미디어 장치는, 1201 동작에서 미디어 파일을 획득할 수 있다. 미디어 장치는, 1203 동작에서 미디어 파일에 대응하는 컨텐트를 출력할 수 있다. 전자 장치는 1205 동작에서 마이크를 통하여 획득되는 음성 데이터에 기반하여 명령을 확인할 수 있다. 전자 장치는, 전자 장치 내부의 ASR 및 NLU를 수행가능한 음성 인식 모델에 기반하여 명령을 확인할 수 있다. 또는, 전자 장치는, 음성 데이터의 처리(예: ASR 및/또는 NLU) 중 적어도 일부를 외부 장치(예: AI 서버)로 요청할 수 있으며, 이에 대한 응답을 수신하여 명령을 확인할 수도 있다. 전자 장치는, 1207 동작에서, 확인된 명령에 대응하는 서브 음성 데이터가 획득된 제 1 시간 구간에 대응하는 미디어 파일에 대응하는 정보를 미디어 장치로 요청할 수 있다. 예를 들어, 전자 장치는, 지정된 거리 내에 미디어 장치가 위치함을 확인할 수 있거나, 또 는 미디어 장치가 배치된 공간에 전자 장치가 진입함을 확인할 수 있다. 전자 장치는, 이 경우 확인된 명령에 대응하는 서브 음성 데이터가 획득된 제 1 시간 구간에 대응하는 미디어 파일에 대한 정보를 미 디어 장치로 요청할 수 있다. 1209 동작에서, 미디어 장치는, 요청에 응답하여 제 1 시간 구간에 대 응하는 미디어 파일에 대응하는 정보를 제공할 수 있다. 예를 들어, 도 13에서와 같이, 미디어 장치는, 미디어 파일에 대응하는 디코딩된 신호 중 제 1 시간 구간에 대응하는 정보를 전자 장치로부 터 요청받을 수 있다. 미디어 장치는, 제 1 시간 구간에 대응하는 신호를 전자 장치로 제공할 수 있다. 도시되지는 않았지만, 미디어 장치는, 제 1 시간 구간에 대응하는 텍스트를 요청받을 수 도 있으며, 이 경우 미디어 장치는 제 1 시간 구간에 대응하는 텍스트를 전자 장치로 제공할 수도 있 다. 일 실시예에 따라서, 전자 장치는 1211 동작에서, 마이크를 통하여 획득되는 음성 데이터와, 수신된 미디 어 파일에 대응하는 정보가 대응됨을 확인할 수 있다. 예를 들어, 도 13에서의 제 1 시간 구간에 대응하 는 신호와, 마이크를 통하여 획득되는 음성 데이터의 유사도를 확인할 수 있으며, 유사도가 임계값 이상 인 경우에 음성 데이터 및 수신된 미디어 파일에 대한 정보가 대응되는 것으로 확인할 수도 있다. 음성 데이터 및 수신된 미디어 파일에 대한 정보가 대응되는 것으로 확인되면, 1213 동작에서, 전자 장치는 음성 데이 터의 처리를 스킵할 수도 있다. 도 14는 일 실시예에 따른 전자 장치, AI 서버 및 미디어 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 14의 동작들 중 기 설명된 동작에 대하여서는 그 설명을 간명하게 하도록 한다. 일 실시예에 따른, 미디어 장치는, 1401 동작에서 미디어 파일을 획득할 수 있다. 1403 동작에서, 미디어 장치는, 미디어 파일에 대응하는 컨텐트를 출력하면서, 미디어 파일로부터 트리거 음성을 검출할 수 있다. 1405 동작에서, 미디어 장치는, 트리거 음성 검출됨을 AI 서버로 알릴 수 있다. 전자 장치는 1407 동작에서 마이크를 통하여 획득되는 음성 데이터에서 트리거 음성을 검출할 수 있다. 1409 동작에서, 전 자 장치는, 음성 데이터, 예를 들어 트리거 음성 이후에 입력되는 추가 음성 데이터의 처리를 AI 서버 로 요청할 수 잇다. 일 실시예에 따라서, AI 서버는, 1411 동작에서, 제 1 공간에 배치된 장치들이 적어도 동시에 트리거 음성 을 검출함을 확인할 수 있다. 예를 들어, 미디어 장치 및 전자 장치는 트리거 음성을 검출한 시점에 대한 정보를 함께 AI 서버로 송신할 수도 있다. AI 서버는, 미디어 장치의 위치에 대한 정보 및 전자 장치의 위치에 대한 정보를 관리할 수 있으며, 이에 따라 양 장치들이 기 지정된 크기의 범위 내 에 함께 배치됨을 확인할 수 있다. 제 1 공간에 배치된 장치들이 적어도 동시에 트리거 음성을 검출함이 확인 되는 경우, AI 서버는, 1413 동작에서, 전자 장치로부터 요청된 음성 데이터의 처리를 스킵할 수 있 다. AI 서버는, 요청된 음성 데이터의 처리를 스킵하는 취지의 메시지를 전자 장치로 제공할 수도 있으며, 이 경우 전자 장치는 미디어 장치에서의 출력 음성에 의하여 음성 데이터 처리가 스킵되었음 을 나타내는 메시지를 다양한 형태로 출력할 수도 있다. 본 문서에 개시된 일 실시예들에 따른 전자 장치는 다양한 형태의 장치가 될 수 있다. 전자 장치는, 예를 들면, 컴퓨터 장치, 휴대용 통신 장치 (예: 스마트폰), 휴대용 멀티미디어 장치, 휴대용 의료 기기, 카메라, 웨어러블 장치, 또는 가전 장치를 포함할 수 있다. 본 문서의 실시예에 따른 전자 장치는 전술한 기기들에 한정되지 않는 다.본 문서의 일 실시예들 및 이에 사용된 용어들은 본 문서에 기재된 기술적 특징들을 특정한 실시예들로 한정하 려는 것이 아니며, 해당 실시예의 다양한 변경, 균등물, 또는 대체물을 포함하는 것으로 이해되어야 한다. 도면 의 설명과 관련하여, 유사한 또는 관련된 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 아이템에 대응하는 명사의 단수 형은 관련된 문맥상 명백하게 다르게 지시하지 않는 한, 아이템 한 개 또는 복수 개를 포 함할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\",“A 또는 B 중 적어도 하나,”\"A, B 또는 C,\" \"A, B 및 C 중 적어도 하나,”및 “A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당 하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. \"제 1\", \"제 2\", 또는 \"첫째\" 또는 \"둘째\"와 같은 용어들은 단순히 해당 구성요소를 다른 해당 구성요소와 구분하기 위해 사 용될 수 있으며, 해당 구성요소들을 다른 측면(예: 중요성 또는 순서)에서 한정하지 않는다. 어떤(예: 제 1) 구 성요소가 다른(예: 제 2) 구성요소에, “기능적으로” 또는 “통신적으로”라는 용어와 함께 또는 이런 용어 없 이, “커플드” 또는 “커넥티드”라고 언급된 경우, 그것은 어떤 구성요소가 다른 구성요소에 직접적으로(예: 유선으로), 무선으로, 또는 제 3 구성요소를 통하여 연결될 수 있다는 것을 의미한다. 본 문서에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로 등의 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 부품의 최소 단위 또는 그 일부가 될 수 있다. 예를 들면, 일 실시예에 따르면, 모듈은 ASIC(application-specific integrated circuit)의 형태로 구현될 수 있다. 본 문서의 일 실시예들은 기기(machine)(예: 마스터 장치 또는 태스크 수행 장치) 의해 읽을 수 있는 저장 매체 (storage medium)(예: 내장 메모리 또는 외장 메모리)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨어 (예: 프로그램)로서 구현될 수 있다. 예를 들면, 기기(예: 마스터 장치 또는 태스크 수행 장치)의 프로세서는, 저장 매체로부터 저장된 하나 이상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행할 수 있다. 이 것은 기기가 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도록 운영되는 것을 가능하게 한 다. 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포 함할 수 있다. 기기로 읽을 수 있는 저장매체 는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적’은 저장매체가 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하 지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저 장되는 경우를 구분하지 않는다. 일실시예에 따르면, 본 문서에 개시된 일 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치들(예: 스 마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 일 실시예들에 따르면, 기술한 구성요소들의 각각의 구성요소(예: 모듈 또는 프로그램)는 단수 또는 복수의 개 체를 포함할 수 있다. 일 실시예들에 따르면, 전술한 해당 구성요소들 중 하나 이상의 구성요소들 또는 동작들 이 생략되거나, 또는 하나 이상의 다른 구성요소들 또는 동작들이 추가될 수 있다. 대체적으로 또는 추가적으로, 복수의 구성요소들(예: 모듈 또는 프로그램)은 하나의 구성요소로 통합될 수 있다. 이런 경우, 통 합된 구성요소는 복수의 구성요소들 각각의 구성요소의 하나 이상의 기능들을 통합 이전에 복수의 구성요소들 중 해당 구성요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 일 실시예들에 따르면, 모듈, 프 로그램 또는 다른 구성요소에 의해 수행되는 동작들은 순차적으로, 병렬적으로, 반복적으로, 또는 휴리스틱하게 실행되거나, 동작들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또는 하나 이상의 다른 동작들이 추 가될 수 있다. 본 개시에 따른 전자 장치의 음성 인식 방법에 있어서, 미디어 장치로부터의 출력된 음성에 의한 동작을 방지하 기 위하여 사용자의 음성을 인식하고 의도를 해석하기 위한 방법으로, 예를 들어, 마이크를 통해 아날로그 신호 인 음성 신호를 수신하고, ASR(Automatic Speech Recognition)모델을 이용하여 음성 부분을 컴퓨터로 판독 가능 한 텍스트로 변환할 수 있다. 자연어 이해(Natural Language Understanding, NLU) 모델을 이용하여 변환된 텍 스트를 해석하여, 사용자의 발화 의도를 획득할 수 있다. 여기서 ASR 모델 또는 NLU 모델은 인공지능 모델일 수 있다. 인공지능 모델은 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계된 인공지능 전용 프로세서에 의해 처리될 수 있다. 인공지능 모델은 학습을 통해 만들어 질 수 있다. 여기서, 학습을 통해 만들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 인공 지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리하는 기술로서, 자연어 처리(Natural Language Processing), 기계 번역(Machine Translation), 대화 시스템(Dialog System), 질의 응답(Question Answering), 음성 인식/합성(Speech Recognition/Synthesis) 등을 포함한다."}
{"patent_id": "10-2020-0041025", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 IoT(internet of things) 시스템을 도시한다. 도 2는, 일 실시예에 따른 IoT 서버 및 보이스 어시스턴스 서버를 도시한다. 도 3은 다양한 실시예에 따른 IoT 서버 및 엣지 컴퓨팅 시스템을 도시한다.도 4는 일 실시예에 따른 클라우드 간의 동작을 설명하기 위한 흐름도이다. 도 5는, 일 실시예에 따른 전자 장치, 미디어 장치, 및 AI 서버를 도시한다. 도 6은 일 실시예에 따른 전자 장치 및 미디어 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 7a는 일 실시예에 따른 전자 장치 및 미디어 장치의 블록도를 도시한다. 도 7b는 일 실시예에 따른 전자 장치 및 미디어 장치의 블록도를 도시한다. 도 8은 일 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 9는 일 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 10은 일 실시예에 따른 전자 장치 및 미디어 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 11은 일 실시예에 따른 전자 장치 및 미디어 장치의 동작을 설명하기 위한 도면을 도시한다. 도 12는 일 실시예에 따른 전자 장치 및 미디어 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 13은 일 실시예에 따른 미디어 파일에 대한 정보를 설명하기 위한 도면이다. 도 14는 일 실시예에 따른 전자 장치, AI 서버 및 미디어 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다."}
