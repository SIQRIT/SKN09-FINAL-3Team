{"patent_id": "10-2019-0099131", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0020219", "출원번호": "10-2019-0099131", "발명의 명칭": "대용어", "출원인": "삼성전자주식회사", "발명자": "이강욱"}}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,마이크;카메라;적어도 하나의 인스트럭션이 저장된 메모리; 및상기 마이크, 상기 카메라 및 상기 메모리와 연결되어 상기 전자 장치를 제어하는 적어도 하나의 프로세서;를포함하고,상기 프로세서는, 상기 적어도 하나의 인스트럭션을 실행함으로써,상기 마이크를 통해 입력된 사용자의 음성에 대응되는 텍스트를 획득하고, 상기 획득된 텍스트에 질의가 포함된경우, 상기 질의에 대한 응답을 제공하며,상기 프로세서는,상기 질의에 대용어가 포함된 경우, 상기 카메라를 통해 획득된 이미지에서 상기 대용어에 대응되는 관심 영역을 식별하고, 상기 질의를 포함하는 대화 내용에 기초하여, 상기 식별된 관심 영역에 포함된 적어도 하나의 객체 중 상기 대용어가 지칭하는 객체를 식별하고, 상기 식별된 객체에 대한 정보를 상기 응답으로 제공하는, 전자 장치."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 대용어가 가지는 거리 속성에 따라 상기 획득된 이미지에서 상이한 영역을 상기 관심 영역으로 식별하는,전자 장치."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는,상기 대용어가 가까운 거리의 객체를 지칭하는 대용어인 경우, 상기 획득된 이미지에서 상대적으로 가까운 거리에 위치하는 영역을 상기 관심 영역으로 식별하고, 상기 대용어가 먼 거리의 객체를 지칭하는 대용어인 경우,상기 획득된 이미지에서 상대적으로 먼 거리에 위치하는 영역을 상기 관심 영역으로 식별하는, 전자 장치."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 프로세서는,상기 질의에 제1 대용어가 포함되고 상기 질의 또는 상기 질의 이후에 입력된 질의에 제2 대용어가 포함되는 경우, 상기 제1 대용어가 지칭하는 제1 객체가 상기 획득된 이미지의 일 영역에서 식별된 후, 상기 제1 대용어 및상기 제2 대용어의 거리 속성에 기초하여, 상기 제1 객체 및 상기 제2 대용어가 지칭하는 제2 객체 간의 상대적위치 관계를 판단하고, 상기 획득된 이미지에서 상기 일 영역을 기준으로 상기 상대적 위치 관계를 갖는 영역을상기 제2 대용어에 대응되는 관심 영역으로 식별하는, 전자 장치."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2021-0020219-3-제1항에 있어서,상기 프로세서는,상기 획득된 이미지에서 각각 하나의 객체가 존재하는 적어도 하나의 영역을 식별하고, 상기 획득된 이미지 내상기 식별된 영역의 밀집도에 기초하여 상기 대용어에 대응되는 관심 영역을 식별하는, 전자 장치."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 프로세서는,상기 대용어가 단수의 객체를 지칭하는 대용어인 경우, 상기 획득된 이미지에서 상기 식별된 영역의 밀집도가상대적으로 낮은 영역을 상기 관심 영역으로 식별하고,상기 대용어가 복수의 객체를 지칭하는 대용어인 경우, 상기 획득된 이미지에서 상기 식별된 영역의 밀집도가상대적으로 높은 영역을 상기 관심 영역으로 식별하는, 전자 장치."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 메모리는, 상기 전자 장치가 운용되는 공간의 맵에 대한 정보 및 상기 맵 상에 존재하는 객체들의 위치 정보를 저장하고,상기 프로세서는,상기 대용어가 객체의 종류에 대한 정보를 포함하고 있는 경우, 상기 저장된 객체들의 위치 정보로부터 상기 종류의 객체가 존재하는 위치 정보를 획득하고,상기 맵에 대한 정보에 기초하여, 상기 획득된 이미지로부터 상기 획득된 위치 정보와 매칭되는 상기 관심 영역을 식별하는, 전자 장치."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 프로세서는,상기 획득된 이미지에서 객체가 존재하는 적어도 하나의 영역을 식별하고, 상기 식별된 영역 중 상기 관심 영역에 포함된 영역에 포함된 객체를 식별하고,상기 질의, 상기 질의 이전에 입력된 사용자의 이전 질의 및 상기 이전 질의에 대한 응답을 포함하는 대화 내용에 기초하여, 상기 대용어가 지칭하는 객체에 대한 정보를 획득하고,상기 획득된 객체에 대한 정보에 기초하여, 상기 관심 영역에 포함된 영역에 포함된 객체 중 상기 대용어가 지칭하는 객체를 식별하는, 전자 장치."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 프로세서는,상기 획득된 객체에 대한 정보에 기초하여 상기 관심 영역으로부터 상기 대용어가 지칭하는 객체를 식별할 수없는 경우, 추가 정보에 대한 요청을 출력하고, 상기 출력된 요청에 따른 사용자의 재질의 또는 응답이 입력되면, 상기 입력된 재질의 또는 응답으로부터 객체에 대한 추가 정보를 획득하고, 상기 획득된 추가 정보에 기초하여, 상기 관심 영역에 포함된 영역에 포함된 객체 중 상기 대용어가 지칭하는 객체를 식별하는, 전자 장치."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,공개특허 10-2021-0020219-4-이동 수단;을 더 포함하고,상기 메모리는, 상기 전자 장치가 운용되는 공간의 맵에 대한 정보 및 상기 맵상에 존재하는 객체들의 위치 정보를 저장하고,상기 프로세서는,상기 획득된 객체에 대한 정보에 기초하여 상기 관심 영역으로부터 상기 대용어가 지칭하는 객체를 식별할 수없는 경우, 상기 저장된 위치 정보에 기초하여, 상기 맵 상에서 상기 전자 장치가 위치하는 지점 주변에 존재하는 적어도 하나의 객체를 식별하고,상기 주변에 존재하는 적어도 하나의 객체 중 상기 획득된 객체에 대한 정보와 관련된 객체가 존재하지 않는 경우, 상기 저장된 위치 정보에 기초하여, 상기 획득된 객체에 대한 정보와 관련된 객체가 존재하는 상기 맵 상의지점으로 이동하도록 상기 이동 수단을 제어하는, 전자 장치."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 카메라는, 회전이 가능하도록 상기 전자 장치 상에 형성되고,상기 프로세서는,상기 카메라를 통해 촬영된 사용자의 이미지를 통해, 상기 사용자가 가리키는 방향 또는 상기 사용자가 바라보는 방향을 판단하고,상기 판단된 방향에 기초하여 상기 카메라의 촬영 방향을 조절하고,상기 조절된 카메라를 통해 획득된 이미지로부터 상기 대용어에 대응되는 관심 영역을 식별하는, 전자 장치."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,이동 수단;을 더 포함하고,상기 메모리는, 상기 전자 장치가 운용되는 공간의 맵에 대한 정보를 저장하고,상기 프로세서는,상기 조절된 카메라를 통해 획득된 이미지에서 장애물이 식별된 경우, 상기 맵에 대한 정보 및 상기 식별된 장애물에 대한 정보를 이용하여, 상기 장애물이 포함되지 않은 상기 판단된 방향의 이미지를 획득할 수 있는 지점으로 이동하도록 상기 이동 수단을 제어하는, 전자 장치."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "사용자의 질의가 입력되면 상기 질의에 대한 응답을 제공하는 전자 장치의 제어 방법에 있어서,상기 질의에 대용어가 포함된 경우, 카메라를 통해 획득된 이미지에서 상기 대용어에 대응되는 관심 영역을 식별하는 단계;상기 식별된 관심 영역에 포함된 적어도 하나의 객체 중 상기 대용어가 지칭하는 객체를 식별하는 단계; 및상기 식별된 객체에 대한 정보를 상기 응답으로 제공하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 관심 영역을 식별하는 단계는,상기 대용어가 가지는 거리 속성에 따라 상기 획득된 이미지에서 상이한 영역을 상기 관심 영역으로 식별하는,제어 방법."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "공개특허 10-2021-0020219-5-제14항에 있어서,상기 관심 영역을 식별하는 단계는,상기 대용어가 가까운 거리의 객체를 지칭하는 대용어인 경우, 상기 획득된 이미지에서 상대적으로 가까운 거리에 위치하는 영역을 상기 관심 영역으로 식별하고, 상기 대용어가 먼 거리의 객체를 지칭하는 대용어인 경우,상기 획득된 이미지에서 상대적으로 먼 거리에 위치하는 영역을 상기 관심 영역으로 식별하는, 제어 방법."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 관심 영역을 식별하는 단계는,상기 질의에 제1 대용어가 포함되고 상기 질의 또는 상기 질의 이후에 입력된 질의에 제2 대용어가 포함되는 경우, 상기 제1 대용어가 지칭하는 제1 객체가 상기 획득된 이미지의 일 영역에서 식별된 후, 상기 제1 대용어 및상기 제2 대용어의 거리 속성에 기초하여, 상기 제1 객체 및 상기 제2 대용어가 지칭하는 제2 객체 간의 상대적위치 관계를 판단하고, 상기 획득된 이미지에서 상기 일 영역을 기준으로 상기 상대적 위치 관계를 갖는 영역을상기 제2 대용어에 대응되는 관심 영역으로 식별하는, 제어 방법."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 관심 영역을 식별하는 단계는,상기 획득된 이미지에서 각각 하나의 객체가 존재하는 적어도 하나의 영역을 식별하고, 상기 획득된 이미지 내상기 식별된 영역의 밀집도에 기초하여 상기 대용어에 대응되는 관심 영역을 식별하는, 제어 방법."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서,상기 전자 장치에는, 상기 전자 장치가 운용되는 공간의 맵에 대한 정보 및 상기 맵 상에 존재하는 객체들의 위치 정보가 저장되고,상기 관심 영역을 식별하는 단계는,상기 대용어가 객체의 종류에 대한 정보를 포함하고 있는 경우, 상기 저장된 객체들의 위치 정보로부터 상기 종류의 객체가 존재하는 위치 정보를 획득하고,상기 맵에 대한 정보에 기초하여, 상기 획득된 이미지로부터 상기 획득된 위치 정보와 매칭되는 상기 관심 영역을 식별하는, 제어 방법."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제13항에 있어서,상기 대용어가 지칭하는 객체를 식별하는 단계는,상기 획득된 이미지에서 객체가 존재하는 적어도 하나의 영역을 식별하고, 상기 식별된 영역 중 상기 관심 영역에 포함된 영역에 포함된 객체를 식별하고,상기 질의, 상기 질의 이전에 입력된 사용자의 이전 질의 및 상기 이전 질의에 대한 응답을 포함하는 대화 내용에 기초하여, 상기 대용어가 지칭하는 객체에 대한 정보를 획득하고,상기 획득된 객체에 대한 정보에 기초하여, 상기 관심 영역에 포함된 영역에 포함된 객체 중 상기 대용어가 지칭하는 객체를 식별하는, 제어 방법."}
{"patent_id": "10-2019-0099131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,공개특허 10-2021-0020219-6-상기 대용어가 지칭하는 객체를 식별하는 단계는,상기 획득된 객체에 대한 정보에 기초하여 상기 관심 영역으로부터 상기 대용어가 지칭하는 객체를 식별할 수없는 경우, 추가 정보에 대한 요청을 출력하고, 상기 출력된 요청에 따른 사용자의 재질의 또는 응답이 입력되면, 상기 입력된 재질의 또는 응답으로부터 객체에 대한 추가 정보를 획득하고, 상기 획득된 추가 정보에 기초하여 상기 관심 영역에 포함된 영역에 포함된 객체 중 상기 대용어가 지칭하는 객체를 식별하는, 제어 방법."}
{"patent_id": "10-2019-0099131", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사용자의 질의에 대한 응답을 제공하는 전자 장치가 개시된다. 본 전자 장치는, 마이크, 카메라, 적어도 하나의 인스트럭션이 저장된 메모리, 적어도 하나의 프로세서를 포함하고, 프로세서는, 질의에 대용어가 포함된 경우, 카메라를 통해 획득된 이미지에서 대용어에 대응되는 관심 영역을 식별하고, 질의를 포함하는 대화 내용에 기초 하여, 식별된 관심 영역에 포함된 적어도 하나의 객체 중 대용어가 지칭하는 객체를 식별하고, 식별된 객체에 대 한 정보를 응답으로 제공한다."}
{"patent_id": "10-2019-0099131", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 사용자의 질의에 대한 응답을 제공하는 전자 장치에 관한 것으로, 보다 상세하게는, 사용자가 발화한 대용어의 의미를 명확하게 파악하기 위해 주변 환경 및 사용자와 관련된 다양한 요소를 복합적으로 고려하는 전 자 장치에 관한 것이다."}
{"patent_id": "10-2019-0099131", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래에, 사용자의 발화 내용을 이해하고 그에 대한 대답을 제공할 수 있는 인공지능 모델에 대해 다양한 연구가 선행되었다. 이러한 인공지능 모델들은, 예를 들면 다수의 상품이 진열된 매장 내에서 손님을 응대하기 위한 로 봇 등에 이용될 수 있었다. 다만, 사람이 발화하는 문장 내에 대용어가 포함된 경우, 대용어 그 자체로는 의미가 명확하게 파악될 수 없기 때문에, 종래의 인공지능 모델을 포함한 전자 장치만으로는 해당 대용어를 명확히 이해하여 적절한 응답을 제공 하기 어려웠다."}
{"patent_id": "10-2019-0099131", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 목적은, 비록 입력된 사용자의 음성에 대용어가 포함되어 있더라도, 대용어 자체의 거리 속성 및 대 용어가 지칭하는 객체의 수 등을 이용하여, 카메라를 통해 촬영된 이미지상에서 대용어가 지칭하는 객체를 명확 하게 인식할 수 있는 전자 장치를 개시함에 있다."}
{"patent_id": "10-2019-0099131", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 전자 장치는, 마이크, 카메라, 적어도 하나의 인스트럭션이 저장된 메모리, 상기 마이크, 상기 카메라 및 상기 메모리와 연결되어 상기 전자 장치를 제어하는 적어도 하나의 프로세서를 포함하 고, 상기 프로세서는, 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 마이크를 통해 입력된 사용자의 음 성에 대응되는 텍스트를 획득하고, 상기 획득된 텍스트에 질의가 포함된 경우, 상기 질의에 대한 응답을 제공하 며, 상기 프로세서는, 상기 질의에 대용어가 포함된 경우, 상기 카메라를 통해 획득된 이미지에서 상기 대용어 에 대응되는 관심 영역을 식별하고, 상기 질의를 포함하는 대화 내용에 기초하여, 상기 식별된 관심 영역에 포 함된 적어도 하나의 객체 중 상기 대용어가 지칭하는 객체를 식별하고, 상기 식별된 객체에 대한 정보를 상기 응답으로 제공한다. 본 개시의 일 실시 예에 따라, 사용자의 질의가 입력되면 상기 질의에 대한 응답을 제공하는 전자 장치의 제어 방법은, 상기 질의에 대용어가 포함된 경우, 카메라를 통해 획득된 이미지에서 상기 대용어에 대응되는 관심 영 역을 식별하는 단계, 상기 식별된 관심 영역에 포함된 적어도 하나의 객체 중 상기 대용어가 지칭하는 객체를 식별하는 단계 및 상기 식별된 객체에 대한 정보를 상기 응답으로 제공하는 단계를 포함한다."}
{"patent_id": "10-2019-0099131", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따른 전자 장치는, 인간이 주변 상황을 고려하여 상대방이 발화한 대용어를 직관적으로 이해하는 메 커니즘을 전자 장치의 이미지 처리와 결합하여 기술적/단계적으로 재현한 결과, 인간 안내원 대신 고객을 적절 하게 응대할 수 있는 인공지능 기기로 동작할 수 있다. 구체적으로, 본 개시의 전자 장치는, 전체 대화 내용뿐만 아니라 대용어 자체의 속성을 고려하여 대용어가 지칭 하는 객체를 판단하므로, 대용어를 포함하는 사용자의 발화를 더욱 정확하고 신속하게 이해할 수 있다."}
{"patent_id": "10-2019-0099131", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에 대하여 구체적으로 설명하기에 앞서, 본 명세서 및 도면의 기재 방법에 대하여 설명한다. 먼저, 본 명세서 및 청구범위에서 사용되는 용어는 본 개시의 다양한 실시 예들에서의 기능을 고려하여 일반적 인 용어들을 선택하였다. 하지만, 이러한 용어들은 당해 기술 분야에 종사하는 기술자의 의도나 법률적 또는 기 술적 해석 및 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 일부 용어는 출원인이 임의로 선정한 용어 도 있다. 이러한 용어에 대해서는 본 명세서에서 정의된 의미로 해석될 수 있으며, 구체적인 용어 정의가 없으 면 본 명세서의 전반적인 내용 및 당해 기술 분야의 통상적인 기술 상식을 토대로 해석될 수도 있다. 또한, 본 명세서에 첨부된 각 도면에 기재된 동일한 참조번호 또는 부호는 실질적으로 동일한 기능을 수행하는 부품 또는 구성요소를 나타낸다. 설명 및 이해의 편의를 위해서 서로 다른 실시 예들에서도 동일한 참조번호 또는 부호를 사용하여 설명한다. 즉, 복수의 도면에서 동일한 참조 번호를 가지는 구성요소를 모두 도시되어 있다 고 하더라도, 복수의 도면들이 하나의 실시 예를 의미하는 것은 아니다. 또한, 본 명세서 및 청구범위에서는 구성요소들 간의 구별을 위하여 \"제1\", \"제2\" 등과 같이 서수를 포함하는 용어가 사용될 수 있다. 이러한 서수는 동일 또는 유사한 구성요소들을 서로 구별하기 위하여 사용하는 것이며 이러한 서수 사용으로 인하여 용어의 의미가 한정 해석되어서는 안 된다. 일 예로, 이러한 서수와 결합된 구성 요소는 그 숫자에 의해 사용 순서나 배치 순서 등이 제한되어서는 안 된다. 필요에 따라서는, 각 서수들은 서로 교체되어 사용될 수도 있다. 본 명세서에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성 요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 실시 예에서 \"모듈\", \"유닛\", \"부(part)\" 등과 같은 용어는 적어도 하나의 기능이나 동작을 수행하는 구성요소를 지칭하기 위한 용어이며, 이러한 구성요소는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\", \"유닛\", \"부(part)\" 등은 각각이 개별적인 특정 한 하드웨어로 구현될 필요가 있는 경우를 제외하고는, 적어도 하나의 모듈이나 칩으로 일체화되어 적어도 하나 의 프로세서로 구현될 수 있다. 또한, 본 개시의 실시 예에서, 어떤 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적인 연결뿐 아니라, 다른 매체를 통한 간접적인 연결의 경우도 포함한다. 또한, 어떤 부분이 어떤 구성요소를 포함한다는 의미는, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것 을 의미한다. 도 1a 및 도 1b는, 본 개시에 따른 전자 장치가 대용어의 속성을 이용하여 대용어가 지칭하는 객체를 식별하는 예들을 개략적으로 설명하기 위한 도면들이다. 도 1a를 참조하면, 로봇으로 구현된 전자 장치는, 사용자로부터 \"이거 얼마야?\"라는 음성이 입력되는 경우, 카메라를 통해 획득된 이미지상에서 \"이거\"라는 대용어가 지칭하는 객체를 식별할 수 있다. 다만, 도 1a를 참조하면, 전자 장치가 카메라를 통해 획득된 이미지 내에는 하나가 아닌 복수의 객 체, 즉 에어컨 'ABC' 및 에어컨 'DEF'가 존재한다. 이때, 도 1a를 참조하면, 전자 장치는 \"이거\"의 거리 속성에 따라 이미지상에서 비교적 가까운 영역 만을 관심 영역으로 식별하게 되고, 이 경우 전자 장치는 관심 영역 내에 포함된 에어컨 'ABC'를 \"이거\"가 지칭하는 객체로 식별할 수 있다. 그리고, 전자 장치는 \"이거 얼마야?\"라는 사용자의 질의에 대한 응답으로 \"에어컨 'ABC'의 가격은 100만원 입니다.\"라는 정보를 시각적 또는 청각적으로 제공할 수 있다. 반면, 도 1b는 사용자로부터 \"저거 얼마야?\"라는 음성이 입력되는 경우를 가정한 도면이다. 도 1b를 참조하면, 전자 장치는 \"저거\"의 거리 속성에 따라 이미지상에서 비교적 먼 영역을 관심 영역으로 식별하게 되고, 이 경우 전자 장치는 관심 영역 내에 포함된 에어컨 'DEF'를 \"저거\"가 지칭하 는 객체로 식별할 수 있다. 그리고, 전자 장치는 \"저거 얼마야?\"라는 사용자의 질의에 대한 응답으로 \"에어컨 'DEF'의 가격은 150만원 입니다.\"라는 정보를 시각적 또는 청각적으로 제공할 수 있다. 이렇듯, 본 개시에 따른 전자 장치는, 대용어 자체의 속성을 객체 인식에 이용한 결과, 상황별로 각각의 대용어 가 지칭하는 객체를 보다 정확하게 식별해낼 수 있다. 이하 도면들을 통해서는, 본 개시에 따른 전자 장치의 구성 및 동작을 기술적/구체적으로 설명한다. 도 2a는 본 개시의 일 실시 예에 따른 전자 장치의 구성 및 동작을 하드웨어 기준으로 설명하기 위한 블록도이 다. 도 2a를 참조하면, 본 개시의 일 실시 예에 따른 전자 장치는 마이크, 카메라, 메모리 및 프로세서를 포함할 수 있다.전자 장치는 고정형/이동형 로봇으로 구현될 수 있다. 구체적으로, 전자 장치는 사용자의 발화 내용 을 인식하여 사용자에게 필요한 정보를 제공하는 안내 로봇의 형태로 다양한 목적의 시설/공간 등에서 사용될 수 있다. 전자 장치는 스마트 워치나 스마트 안경 등 웨어러블 디바이스로 구현될 수 있으며, 그밖에 스마트폰이나 태블릿 PC 등 다양한 단말 장치로 구현될 수도 있다. 마이크는 회로로 구성되어 오디오 신호를 전기적 신호로 변환할 수 있다. 전자 장치는 마이크를 통해 사용자의 음성을 입력받을 수 있으며, 입력된 음성을 발화한 사용자의 위치를 파악하기 위해 복수의 마이 크가 전자 장치에 구비될 수도 있다. 카메라는 전자 장치의 주변의 이미지를 획득하기 위한 구성으로, RGB 카메라, 뎁스 카메라, RGB- D(Depth) 카메라 등을 포함할 수 있다. 카메라는 스테레오 카메라 또는 3D 카메라로 구현될 수도 있다. 전자 장치는 카메라를 통해 전자 장치 주변에 대한 RGB 이미지뿐만 아니라 뎁스 이미지도 획득 할 수 있다. 메모리는 전자 장치의 구성요소들의 전반적인 동작을 제어하기 위한 운영체제(OS: Operating System) 및 전자 장치의 구성요소와 관련된 적어도 하나의 인스트럭션 또는 데이터를 저장하기 위한 구성이다. 프로세서는 메모리에 저장된 적어도 하나의 인스트럭션을 실행함으로써 후술할 다양한 실시 예들에 따른 동작을 수행할 수 있다. 메모리는 ROM, 플래시 메모리 등의 비휘발성 메모리를 포함할 수 있으며, DRAM 등으로 구성된 휘발성 메모 리를 포함할 수 있다. 또한, 메모리는 하드 디스크, SSD(Solid state drive) 등을 포함할 수도 있다. 프로세서는 마이크, 카메라 및 메모리 등과 연결되어 메모리에 저장된 적어도 하나의 인스트럭션을 실행함으로써 전자 장치를 제어할 수 있다. 이를 위해, 프로세서는 CPU(Central Processing Unit), AP(Application Processor) 등과 같은 범용 프로 세서, GPU(Graphic Processing Unit), VPU(Vision Processing Unit) 등과 같은 그래픽 전용 프로세서 또는 NPU(Neural Processing Unit)와 같은 인공지능 전용 프로세서 등으로 구현될 수 있다. 또한, 프로세서는 SRAM 등의 휘발성 메모리를 포함할 수 있다. 일 예로, ROM 및 RAM 을 포함하는 메모리 및 프로세서가 동일한 칩 내에 포함되도록 전자 장치 내에 구현될 수 있다. 또한, 서로 다른 종류의 프로세서를 포함하는 복수의 칩이 전자 장치 내에 포함될 수 있다. 다만, 이는 일부 예들일뿐 전자 장치 내 메모리 및 프로세서의 물리적 구성이 상술한 예들에 한정되는 것은 아니다. 본 개시에 따른 전자 장치는 도 2b에 도시된 모듈들을 포함할 수 있다. 도 2b에 도시된 모듈들 각각은 메 모리상의 ROM이나 메모리상의 하드 디스크/SSD 내에 소프트웨어적으로 구현되어 프로세서를 통 해 제어될 수 있다. 다만, 모듈들 중 적어도 하나의 적어도 일부는 하드웨어적으로 구현될 수도 있으며, 경우에 따라서는 모듈들 중 적어도 하나가 하드웨어적인 회로만으로 구현되는 것도 가능하다. 도 2b를 참조하면, 전자 장치는 음성 인식 모듈, 자연어 이해 모듈, 질의-응답 모듈, 자연 어 생성 모듈, 텍스트 분석 모듈, 카메라 모듈, 관심 영역 추출 모듈, 객체 인식 모듈 , 대용어 치환 모듈 등을 포함할 수 있다. 프로세서는 마이크를 통해 입력된 사용자의 음성에 대응되는 텍스트를 획득하고, 획득된 텍스트에 질 의가 포함된 경우, 질의에 대한 응답을 제공할 수 있다. 이 경우, 프로세서는 음성 인식 모듈을 통해, 입력된 사용자의 음성을 인식하여 텍스트로 변환할 수 있다. 이를 위해, 음성 인식 모듈은 노이즈 제거 모듈, ASR(Automatic Speech Recognition) 모듈 등을 포 함할 수 있다. 구체적으로, 프로세서는 오디오 신호(사용자의 음성)로부터 적어도 하나의 특징 정보를 추 출한 뒤 이를 음향 모델(Acoustic Model)과 비교하여 하나 이상의 음소를 추출하고, 추출된 음소를 언어 모델 (Language Model)을 기반으로 조합하여 하나 이상의 단어/문장을 포함하는 텍스트를 생성할 수 있다. 그리고, 프로세서는 자연어 이해 모듈을 통해 텍스트를 기계 언어로 변환하여 텍스트 내에 포함된 적 어도 하나의 단어/문장의 의미를 식별할 수 있다. 이때, 프로세서는 형태소 분석(morphologicalanalysis), 통사 분석(syntactic analysis), 의미 분석(semantic analysis) 및 화용 분석(pragmatic analysis) 중 적어도 하나를 수행하도록 학습된 인공지능 모델을 이용할 수 있다. 만약, 사용자의 음성이 질의에 해당하는 것으로 식별되면, 프로세서는 질의-응답 모듈을 통해 해당 질의에 맞는 응답을 기계 언어 형태로 획득할 수 있다. 이 경우, 프로세서는 다양한 객체에 대한 정보를 포함하는 데이터 베이스를 이용하여, 질의에 대한 응답을 생성할 수 있다. 예를 들어, 데이터 베이스에는, 복수 의 제품들 각각의 제품명, 종류(ex. 냉장고, 침대, 스마트폰, 공기 청정기 등), 크기, 색깔, 가격, 성능, 출시 일, 기능, 생산자, 생산 장소 등에 대한 정보가 포함될 수 있다. 그리고, 프로세서는 자연어 생성 모듈을 통해, 획득된 기계 언어를 이용하여 응답 텍스트를 생성할 수 있다. 그리고, 프로세서는 질의에 대한 응답을 제공할 수 있다. 구체적으로, 프로세서는 생성된 응답 텍스 트를 디스플레이(도시되지 않음) 또는 스피커(도시되지 않음) 등을 통해 시각적/청각적으로 출력할 수 있다. 다만, 사용자의 질의에 대용어가 포함된 경우, 문제가 생길 수 있다. 본 개시에 있어 대용어는, 특정한 하나 이 상의 객체를 지칭하기 위한 단어로, 해당 객체의 이름, 제품명 등을 상황에 따라 대체할 수 있는 단어이다. 대 용어는 '이것', '저것', '이거', '저거', '이것들', '저것들', '그것' 등의 대명사뿐만 아니라, '이 에어컨', '이 장치', '저 공기 청정기들', '이 아이', '쟤' 등 지칭되는 객체에 대한 정보를 일부 포함하고 있는 대용 단어도 포함할 수 있다. 만약 사용자의 질의에 대용어가 포함된 경우, 대용어가 지칭하는 객체가 불명확하므로, 설령 프로세서가 질의-응답 모듈 및 자연어 생성 모듈을 이용하더라도 해당 질의에 맞는 적절한 응답이 제공되지 않을 수 있다. 프로세서는 텍스트 분석 모듈을 통해, 사용자의 음성에 대응되는 텍스트 내에 대용어가 포함되어 있 는지 판단할 수 있다. 이 경우, 프로세서는 텍스트 분석 모듈을 통해 형태소 분석(morphological analysis), 통사 분석(syntactic analysis), 의미 분석(semantic analysis) 및 화용 분석(pragmatic analysis) 중 적어도 하나를 수행할 수 있으며, 품사 태깅을 통해 텍스트 내에 포함된 대용어를 추출할 수 있다. 사용자의 질의 내에 대용어가 포함된 경우, 프로세서는 카메라를 통해 획득된 이미지에서 대용어에 대응되는 관심 영역을 식별하고(S110), 식별된 관심 영역에서 대용어가 지칭하는 객체를 식별할 수 있다(S120). S110 과정에서, 프로세서는 텍스트 분석 모듈을 통해 판단된 대용어의 속성에 따라, 획득된 이미지로 부터 관심 영역을 식별할 수 있다. 이 경우, 프로세서는 관심 영역 추출 모듈을 통해 관심 영역을 식 별할 수 있다. 이하 도 3a, 도 3b, 도 4, 도 5a, 도 5b, 도 6a 및 도 6b를 통해, 프로세서가 대용어의 속성에 따라 관심 영역을 식별하는 다양한 실시 예들을 설명한다. 프로세서는, 대용어가 가지는 거리 속성에 따라, 획득된 이미지에서 상이한 영역을 관심 영역으로 식별할 수 있다. 프로세서는, 대용어가 가까운 거리의 객체를 지칭하는 대용어인 경우, 획득된 이미지에서 상대적으로 가까 운 거리에 위치하는 영역을 관심 영역으로 식별하고, 대용어가 먼 거리의 객체를 지칭하는 대용어인 경우, 획득 된 이미지에서 상대적으로 먼 거리에 위치하는 영역을 관심 영역으로 식별할 수 있다. 구체적으로, 프로세서는 카메라를 통해 획득된 뎁스 이미지를 통해 뎁스 이미지 내 각 영역들과 전자 장치 간의 거리를 식별하고, 식별된 거리 및 대용어의 거리 속성에 따라, 뎁스 이미지 내에서 관심 영역을 식별 할 수 있다. 도 3a 및 도 3b는, 본 개시에 따른 전자 장치가 대용어 자체의 거리 속성에 따라 관심 영역을 식별하는 예를 설 명하기 위한 도면들이다. 도 3a를 참조하면, \"저거 얼마야?\"라는 사용자의 질의가 입력되는 경우, 프로세서는 비교적 먼 위치의 객 체를 지칭하는 대용어 \"저거\"의 거리 속성에 따라, 이미지 내에서 비교적 먼 거리에 위치하는 영역(350- 1)을 관심 영역으로 식별할 수 있다. 그 결과, 도 3a를 참조하면, 이미지 내에서 비교적 전자 장치로부터 먼 거리에 위치하는 객체들의 영 역들(311, 312, 313)은 관심 영역(350-1)에 포함되는 반면, 이미지 내에서 비교적 전자 장치로부터 가까운 거리에 위치하는 객체들의 영역들(314, 315)은 관심 영역(350-1)에 포함되지 않게 된다. 한편, 객체들의 영역들(311, 312, 313, 314, 315) 및/또는 해당 객체들은 객체 인식 모듈에 의해 인식될 수 있다. 객체 인식 모듈은 이미지가 입력되면 이미지상에서 적어도 하나의 객체가 존재하는 영역을 식별 하도록 학습된 인공지능 모델 및/또는 이미지상에 포함된 객체가 무엇인지 식별하도록 학습된 인공지능 모델을 이용할 수 있다. 도 3b를 참조하면, \"이거 얼마야?\"라는 사용자의 질의가 입력되는 경우, 프로세서는 비교적 가까운 위치의 객체를 지칭하는 대용어 \"이거\"의 거리 속성에 따라, 이미지 내에서 비교적 가까운 거리에 위치하는 영역 (350-2)을 관심 영역으로 식별할 수 있다. 그 결과, 도 3b를 참조하면, 이미지 내에서 비교적 전자 장치로부터 먼 거리에 위치하는 객체들의 영 역들(311, 312, 313)은 관심 영역(350-2)에 포함되지 않는 반면, 이미지 내에서 비교적 전자 장치로 부터 가까운 거리에 위치하는 객체들의 영역들(314, 315)은 관심 영역(350-2)에 포함되게 된다. 프로세서는, 복수의 대용어들이 입력된 경우, 대용어들 간의 상대적 위치 관계에 따라 관심 영역을 식별할 수도 있다. 구체적으로, 사용자의 질의에 제1 대용어가 포함되고 해당 질의 또는 해당 질의 이후에 입력된 질의에 제2 대용 어가 포함되는 경우를 가정할 수 있다. 이때, 만약 제1 대용어가 지칭하는 제1 객체가 획득된 이미지의 일 영역에서 식별된 상황이라면, 프로세서(14 0)는 제1 대용어 및 제2 대용어의 거리 속성에 기초하여, 제1 객체 및 제2 대용어가 지칭하는 제2 객체 간의 상 대적 위치 관계를 판단할 수 있다. 그리고, 프로세서는 제1 객체가 식별된 일 영역을 기준으로, 앞서 판단된 상대적 위치 관계를 갖는 영역을 제2 대용어에 대응되는 관심 영역으로 식별할 수 있다. 관련하여, 도 4는 본 개시에 따른 전자 장치가 대용어 간의 상대적 거리 속성에 따라 관심 영역을 식별하는 예 를 설명하기 위한 도면이다. 도 4는, \"이거는 몇 인치고, 저거는 몇 인치야?\"라는 사용자의 질의가 입력된 상황을 가정한다. 또한, 도 4는, 해당 질의에 포함된 \"이거\"가 지칭하는 객체가 영역에 포함된 객체로 식별된 상황을 가정한다. 이때, 프로세서는 대용어 \"이거\" 및 대용어 \"저거\" 각각의 거리 속성을 고려하여, \"저거\"가 지칭하는 객체 는 \"이거\"가 지칭하는 객체보다 더 멀리 위치한다는 상대적 위치 관계를 판단할 수 있다. 그리고, 프로세서는 \"이거\"가 지칭하는 객체가 식별된 영역보다 더 먼 영역을 \"저거\"가 지칭하 는 객체를 식별하기 위한 관심 영역으로 식별할 수 있다. 프로세서는 대용어가 지칭하는 객체의 수에 따라 관심 영역을 식별할 수도 있다. 이 경우, 프로세서는 객체 인식 모듈을 통해 획득된 이미지에서 각각 하나의 객체가 존재하는 적어도 하나의 영역을 식별할 수 있다. 그리고, 프로세서는 획득된 이미지 내 식별된 영역의 밀집도에 기초하여 대용어에 대응되는 관심 영역을 식별할 수 있다. 구체적으로, 대용어가 단수의 객체를 지칭하는 대용어인 경우, 프로세서는 획득된 이미지에서 식별된 영역 의 밀집도가 상대적으로 낮은 영역을 관심 영역으로 식별하고, 대용어가 복수의 객체를 지칭하는 대용어인 경우, 프로세서는 획득된 이미지에서 식별된 영역의 밀집도가 상대적으로 높은 영역을 관심 영역으로 식별 할 수 있다. 관련하여, 도 5a 및 도 5b는, 본 개시에 따른 전자 장치가 대용어가 지칭하는 객체의 수에 따라 관심 영역을 식 별하는 예들을 설명하기 위한 도면들이다. 도 5a는, 각각 하나의 객체가 존재하는 영역들(511, 512, 513, 514) 이 객체 인식 모듈을 통해 식별된 상황을 전제로 한다. 도 5a를 참조하면, \"이거 얼마야?\"라는 질의가 입력된바, 프로세서는 텍스트 분석 모듈을 통해 \"이거\"가 하나의 객체를 지칭한다는 점을 판단할 수 있다. 그리고, 프로세서는, 이미지 내에서 객체 인식 모듈을 통해 식별된 영역들(511, 512, 513, 514) 간의 밀집도가 비교적 낮은 영역(550-1)을 관심 영 역으로 식별할 수 있다.반면, 도 5b를 참조하면, \"이것들 얼마야?\"라는 질의가 입력된바, 프로세서는 텍스트 분석 모듈을 통 해 \"이것들\"이 복수의 객체를 지칭한다는 점을 판단할 수 있다. 그리고, 프로세서는, 이미지 내에서 객체 인식 모듈을 통해 식별된 영역들(511, 512, 513, 514) 간의 밀집도가 비교적 높은 영역(550-2)을 관 심 영역으로 식별할 수 있다. 한편, 도 5a 및 도 5b에서 입력된 대용어들 \"이거\" 및 \"이것들\"은 모두 가까운 거리 속성을 가지는 대용어들이 므로, 프로세서는 도 3b와 같이 이미지상에서 비교적 가까운 거리의 영역에 관심 영역(510-1, 510- 2)이 포함되도록 관심 영역을 식별하였다. 한편, 메모리는, 전자 장치가 운용되는 공간의 맵에 대한 정보 및 맵 상에 존재하는 객체들의 위치 정보를 저장할 수 있다. 맵에 대한 정보는, 전자 장치가 운용되는 공간의 구조(모양, 크기 등)에 대한 정 보를 포함할 수 있다. 맵 상에 존재하는 객체들의 위치 정보는, 각 종류의 객체들이 맵 상의 어느 지점에 존재 하는지에 대한 내용을 포함할 수 있다. 보다 구체적으로, 객체들의 위치 정보는, 맵 상에 존재하는 제품들 각각 이 맵 상의 어느 지점에 존재하는지에 대한 정보를 포함할 수 있다. 또한, 객체들의 위치 정보는, 맵 상에 존재 하는 제품들 각각의 제품명, 종류(ex. 냉장고, 침대, 스마트폰, 공기 청정기 등), 크기, 색깔, 가격, 성능, 출 시일, 기능, 생산자, 생산 장소 등에 대한 정보를 포함할 수 있다. 이때, 프로세서는, 만약 대용어가 객체의 종류에 대한 정보를 포함하고 있는 경우, 저장된 객체들의 위치 정보로부터 해당 종류의 객체가 존재하는 위치 정보를 획득할 수 있다. 그리고, 프로세서는 맵에 대한 정 보에 기초하여, 획득된 이미지로부터 획득된 위치 정보와 매칭되는 관심 영역을 식별할 수 있다. 관련하여, 도 6a 및 도 6b는, 대용어가 객체의 종류를 포함하는 경우, 본 개시에 따른 전자 장치가 해당 종류에 따라 관심 영역을 식별하는 예를 설명하기 위한 도면들이다. 도 6a는 각 종류의 제품들의 위치 정보가 맵에 대한 정보와 함께 도시된 도면이다. 도 6a를 참조하면, \"공 기 청정기\"에 해당하는 기기들은 맵상에서 영역에 위치한다. 도 6a를 참조하면, 프로세서는 센서(도시되지 않음. ex: 가속도 센서, 지자기 센서, 라이다 센서, 관성 센 서 등)를 통해 맵상 전자 장치의 위치 및 전자 장치의 카메라가 바라보는 방향을 식 별할 수 있다. 도 6b를 참조하면, \"이 공기 청정기 얼마야?\"라는 질의가 입력된 경우, 프로세서는 텍스트 분석 모듈(22 0)을 통해 대용어인 \"이 공기 청정기\"에 포함된 객체의 종류(: 공기 청정기)를 식별할 수 있다. 이 경우, 프로세서는, 카메라의 위치 및 방향을 이용하여, 카메라를 통해 획득된 이 미지 내에서 공기 청정기의 영역에 매칭되는 관심 영역을 식별할 수 있다. S120 과정에서, 프로세서는 사용자의 질의를 포함하는 사용자 및 전자 장치 간의 대화 내용에 기초하 여, 관심 영역 내에 포함된 객체 중 대용어가 지칭하는 객체를 식별할 수 있다. 이 경우, 프로세서는 먼저 객체 인식 모듈을 통해, 획득된 이미지에서 객체가 존재하는 적어도 하나 의 영역을 식별할 수 있다. 구체적으로, 프로세서는 객체 인식 모듈을 통해 적어도 하나의 객체가 존 재할 확률이 임계값 이상인 하나 이상의 영역을 식별할 수 있다. 그리고, 프로세서는 객체 인식 모듈을 이용하여, 식별된 영역 중 관심 영역에 포함된 영역에 포함된 객체를 식별할 수 있다. 이 경우, 프로세서는 객체 인식 모듈이 이용하는 인공지능 모델의 출력에 따 라 하나 이상의 객체를 식별할 수 있다. 예를 들어, 프로세서는 식별된 영역 중 관심 영역에 포함된 영역을 판단하고, 입력 이미지에 포함된 객체 의 제품명(또는 제품 번호, 사람인 경우 사람 이름 등)을 출력하도록 학습된 인공지능 모델에 판단된 영역 각각 을 입력하여, 관심 영역 내에 존재하는 하나 이상의 객체를 구체적으로 인식할 수 있다. 한편, 프로세서는 객체 인식 모듈을 통해 카메라를 통해 획득된 이미지에 포함된 객체를 모두 인식한 뒤, 그 중 관심 영역 내에 포함된 객체만을 선택할 수도 있다. 상술한 실시 예들에 의해 관심 영역 내의 객체가 인식(또는 선택)되면, 프로세서는 사용자의 질의, 해당 질의 이전에 입력된 사용자의 이전 질의 및 이전 질의에 대한 응답을 포함하는 대화 내용에 기초하여, 대용어가 지칭하는 객체에 대한 정보를 획득하고, 획득된 객체에 대한 정보에 기초하여, 관심 영역에 포함된 객체 중 대 용어가 지칭하는 객체를 식별할 수 있다. 객체에 대한 정보는, 객체의 종류, 크기, 색깔, 성능, 기능, 장점, 단점, 생산자, 판매자, 생산 장소 등 다양할 수 있다. 이때, 프로세서는 대용어 치환 모듈을 통해, 대화 내용으로부터 객체에 대한 정보를 추출하고, 추출 된 객체에 대한 정보가 관심 영역 내 인식된 적어도 객체와 매칭되는지 여부를 식별할 수 있다. 이 경우, 프로 세서는 관심 영역 내 인식된 객체 중 추출된 정보와 매칭되는 객체를 대용어가 지칭하는 객체로 식별할 수 있다. 이때, 대용어 치환 모듈은 대화 내용으로부터 대용어와 관련 있는 객체에 대한 정보를 추출하도록 학습된 인공지능 모델를 이용할 수 있다. 또한, 대용어 치환 모듈은, 추출된 객체에 대한 정보 및 관심 영역 내에 서 인식된 하나 이상의 객체에 대한 데이터가 입력되면, 인식된 하나 이상의 객체 각각과 대용어 간의 매칭 확 률을 출력하도록 학습된 인공지능 모델을 이용할 수도 있다. 도 7은, 본 개시에 따른 전자 장치가 사용자 및 전자 장치 간의 대화 내용을 이용하여 관심 영역 내 객체 중 대 용어가 지칭하는 객체가 무엇인지 판단하는 예를 설명하기 위한 도면이다. 도 7은, 객체 인식 모듈을 통한 관심 영역 내 객체 인식 결과를 도시한다. 도 7을 참조하면, 관심 영 역 내에서 공기 청정기 'A', 공기 청정기 'B', 에어컨 'AB'이 인식되었다. 도 7을 참조하면, 프로세서는 텍스트 분석 모듈을 이용하여, \"그러면, 이건 얼마야?\"라는 사용자의 질의뿐 만 아니라 그 전에 입력된 사용자의 질의(\"공기 청정기 'A' 얼마야?\") 및 전자 장치의 응답(\"50만원이에요.\")을 포함하는 대화 내용을 분석할 수 있다. 이 경우, 프로세서는 대화 내용에 포함된 객체의 종류(:공기 청정기)를 식별할 수 있다. 또한, 공기 청정 기 'A'의 가격에 대해서는 이미 응답이 되었다는 점을 식별할 수 있다. 따라서, 프로세서는 관심 영역 내 객체들 중 \"이건\"이 의미하는 객체가 공기 청정기 'B'라는 점 을 식별할 수 있다. 즉, 프로세서는 대용어 치환 모듈을 통해 대용어 \"이건\"이 의미하는 객체가 공기 청정기 'B'라는 점을 식별할 수 있다. S120 과정을 통해 대용어가 지칭하는 객체가 식별되면, 프로세서는 대용어가 지칭하는 객체에 대한 정보 (ex. 제품의 가격, 사이즈, 성능, 제조사 등) 중 사용자의 질의에 대응되는 정보를 질의에 대한 응답으로 제공 할 수 있다. 구체적으로, 프로세서는 음성 인식 모듈을 통해 인식된 텍스트를 대용어 치환 모듈의 대용어 식 별 결과(ex. \"이건\" = \"공기청정기 'B'\")에 따라 전처리하여 자연어 이해 모듈로 입력할 수 있다. 그 결과, 자연어 이해 모듈은 사용자의 질의를 \"그러면, 공기 청정기 'B'는 얼마야?\"로 이해할 수 있고, 전자 장치는 질의-응답 모듈 및 자연어 생성 모듈을 이용하여 '공기 청정기 'B'의 가격을 알려주는 응답을 제공할 수 있다. 한편, 대화 내용으로부터 획득된 객체에 대한 정보에 기초하여 관심 영역으로부터 대용어가 지칭하는 객체가 식 별되지 않는 경우, 프로세서는 추가 정보에 대한 요청을 출력할 수 있다. 예로, \"이건 얼마야?\"라는 질의와 관련된 대화 내용으로부터 획득된 객체에 대한 정보에 따르면 \"이건\"이 지칭 하는 객체의 종류는 에어컨임에도, 관심 영역에 포함된 객체 중 에어컨이 없는 경우를 들 수 있다. 이 경우, 프 로세서는 디스플레이(도시되지 않음) 또는 스피커(도시되지 않음) 등을 통해 추가 정보에 대한 요청(ex. \"무엇을 말씀하시는지 모르겠어요. 다시 한 번 질문해 주시겠어요?\", \"에어컨 'A'를 말씀하시는 건가요?\" 등) 을 출력할 수 있다. 관련하여, 도 8은, 관심 영역 내에 대용어가 지칭하는 객체가 존재하지 않는 것으로 식별된 경우, 본 개시에 따 른 전자 장치가 추가 정보에 대한 요청을 출력하는 일 예를 설명하기 위한 도면이다. 도 8에서 관심 영역 내 객체 인식 결과를 참조하면, 관심 영역 내에서 인식된 객체는 에어컨 'A' 및 에어컨 'B'이다. 다만, 아무런 사전 대화 없이 사용자로부터 \"'이거' 좋아?\"라는 질의가 입력된 경우, 프로세서는 대화 내 용만으로는 대용어가 지칭하는 객체를 명확히 식별하지 못할 수 있다. 예를 들어, 도 8과 같이 대화 내용만으로는 객체에 대한 정보가 전혀 획득되지 않는 경우, 대용어 치환 모 듈을 통해 출력되는 에어컨 'A' 및 에어컨 'B' 각각의 대용어 \"이거\"에 대한 매칭 확률이 임계값보다낮을 수 있다(만약 관심 영역 내 객체 인식 결과에 단 하나의 객체만이 포함되는 경우라면, 비록 대화 내용으로 부터 아무런 정보도 획득되지 않더라도, 해당 객체의 대용어 매칭 확률은 임계값보다 높을 수도 있겠지만, 도 8 과 같이 관심 영역 내 객체가 두 개 이상인 경우라면 대용어가 지칭하는 객체를 식별하기 위한 추가 정보가 필 요할 수 있다). 이 경우, 도 8을 참조하면, 프로세서는 \"말씀하신 \"이거\"를 알 수 없습니다. 제품명을 말씀해 주시겠어 요?\"와 같은 추가 정보에 대한 요청을 출력할 수 있다. 추가 정보에 대한 요청에 따른 사용자의 재질의 또는 응답이 입력되면, 프로세서는 입력된 재질의 또는 응 답으로부터 객체에 대한 추가 정보를 획득하고, 획득된 추가 정보에 기초하여, 관심 영역에 포함된 영역에 포함 된 객체 중 대용어가 지칭하는 객체를 식별할 수 있다. 도 8의 경우로 예를 들면, \"에어컨 'A' 얼마야?\"라는 재질의가 입력되는 경우, 프로세서는 에어컨 'A'의 가격을 알리는 응답을 출력할 수 있다. 한편, 추가 정보에 대한 요청을 출력한 결과 \"왼쪽에 있는거 말한거 야.\"와 같은 응답이 입력되는 경우, 프로세서는 에어컨 'A' 및 에어컨 'B' 중 획득된 이미지(또는 관심 영 역)상에서 상대적으로 왼쪽에 있는 에어컨의 가격을 알리는 응답을 출력할 수 있다. 도 9a 및 도 9b는, 본 개시의 다양한 실시 예에 따른 전자 장치의 구성/동작을 하드웨어 및/또는 소프트웨어 기 준으로 설명하기 위한 블록도들이다. 도 9a를 참조하면, 전자 장치는 마이크, 카메라, 메모리 및 프로세서 외에도 센서 , 디스플레이, 스피커, Actuator 중 적어도 하나를 더 구비할 수 있다. 센서는 가속도 센서, 지자기 센서, 라이다 센서, Ultrasonic 센서, 관성 센서, GPS(Global Positioning System) 센서 등을 포함할 수 있다. 전자 장치가 이동 수단을 포함하는 경우, 주행 내지는 모션을 수행하는 과정에서 전자 장치는 카메라 및/또는 센서를 통해 주변의 지형, 객체, 장애물을 식별할 수 있다. 또한, 전자 장치는 센서 를 통해 전자 장치가 향하는 방향, 카메라가 바라보는 방향, 전자 장치의 이동 방향, 속도, 위치 등을 감지할 수 있다. 디스플레이는 전자 장치가 정보를 시각적으로 제공하기 위한 구성이다. 전자 장치는 하나 이상 의 디스플레이를 포함할 수 있으며, 입력된 사용자의 질의에 대한 응답을 디스플레이를 통해 표시할 수 있다. 디스플레이는 LCD(Liquid Crystal Display), PDP(Plasma Display Panel), OLED(Organic Light Emitting Diodes), TOLED(Transparent OLED), Micro LED 등으로 구현될 수 있다. 디스플레이는, 사용자의 터치 조작을 감지할 수 있는 터치스크린 형태로 구현될 수 있으며, 접히거나 구부 러질 수 있는 플렉서블 디스플레이로 구현될 수도 있다. 스피커는 전자 장치가 정보를 청각적으로 제공하기 위한 구성이다. 전자 장치는 하나 이상의 스 피커를 포함할 수 있으며, 입력된 사용자의 질의에 대한 응답을 스피커를 통해 오디오 신호로 출력할 수 있다. 한편, 도 9a를 통해 도시되지는 않았으나, 전자 장치는 이어폰/헤드폰 단자를 구비하는 한편, 이어폰/헤드 폰 단자를 통해 응답에 대응되는 오디오 신호를 출력할 수도 있다. Actuator는 전자 장치의 주행 및/또는 모션을 구동하기 위한 구성이다. 전자 장치는 주행용 Actuator 및 모션용 Actuator를 별도로 구비할 수 있으며, Actuator는 프로세서의 제어에 따라 전자 장치의 이 동 수단 및/또는 전자 장치의 적어도 일부의 물리적 움직임을 제어할 수 있다. 한편, 비록 도시되지는 않았으나, 전자 장치는 이밖에 외부 장치와 통신을 수행하기 위한 통신부 (communicator), 음성 외 다른 방식으로 사용자 입력을 수신하기 위한 사용자 입력부(user inputter) 등을 추가 로 포함할 수도 있다. 도 9a와 같은 하드웨어 구조를 가지는 전자 장치는, 도 9b와 같은 구조로 모듈들을 포함할 수 있다. 도 9b를 참조하면, 전자 장치는 도 2b를 통해 도시 및 설명한 모듈들 외에도, 자연어 생성 모듈을 통 해 생성된 응답(텍스트)을 스피커를 통해 오디오 신호 형태로 출력하기 위한 TTS 모듈을 더 포함할수 있다. 또한, 전자 장치는 대용어가 지칭하는 객체가 대용어 치환 모듈을 통해 식별되지 못한 경우 추가 정보에 대한 요청을 생성하기 위한 추가 정보 요청 모듈를 더 포함할 수 있다. 또한, 전자 장치는 사용자의 지시/응시 방향을 판단하는 지시/응시 방향 감지 모듈, 센서를 제 어하고 센서의 센싱 데이터를 다른 모듈로 전달하기 위한 센서 모듈, 전자 장치의 이동 수단 및 전자 장치의 적어도 일부의 물리적 움직임을 제어하기 위한 주행/모션 모듈, 기저장된 적어도 하나의 객체 의 위치 정보를 전자 장치의 위치와 비교하기 위한 위치 정보 매칭 모듈 중 적어도 하나를 더 포함할 수 있다. 도 9a 및/또는 도 9b와 같이 구성된 전자 장치는, 상술한 S110 및 S120 과정의 실시 예들뿐만 아니라, 그 와 관련된 다양한 추가 실시 예들에 따라 동작할 수 있다. 이하 도 10a, 도 10b, 도 10c, 도 11, 도 12를 통해 다양한 추가 실시 예들에 대해 설명한다. 일 실시 예로, 카메라는 회전이 가능하도록 전자 장치 상에 형성되고, 프로세서는 지시/응시 방 향 감지 모듈을 이용하여 사용자가 가리키거나 응시하는 방향을 판단할 수 있다. 이 경우, 지시/응시 방향 감지 모듈은 카메라로부터 획득된 이미지를 통해 사용자가 가리키거나 응시 하는 방향을 판단할 수 있다. 관련하여, 도 10a는 전자 장치가 대용어가 지칭하는 객체에 대한 사용자의 지시 방향을 판단하는 일 예를 설명 하기 위한 도면이다. 도 10a를 참조하면, 프로세서는 카메라를 통해 획득된 이미지(ex. RGB 이미지)를 이용하여 사용자의 손가락을 인식할 수 있다. 이 경우, 프로세서는 지시/응시 방향 감지 모듈과 연결된 객체 인식 모듈을 이용할 수도 있다. 그리고, 프로세서는 카메라를 통해 획득된 뎁스 이미지를 통해, 손가락상에 위치하는 세 개 지 점 각각의 거리 정보를 식별할 수 있다. 이 경우, 프로세서는 세 개 지점 각각의 거리 정보를 이용하여 사용자의 손가락이 지시하는 방향을 판단할 수 있다. 도 10b는 전자 장치가 대용어가 지칭하는 객체에 대한 사용자의 응시 방향을 판단하는 일 예를 설명하기 위한 도면이다. 도 10b를 참조하면, 프로세서는 카메라를 통해 획득된 이미지(ex. RGB 이미지)를 이용하여 사용자의 머리를 인식할 수 있다. 그리고, 프로세서는 머리에서 눈이 있는 지점을 식별하고, 그 밖에 코, 귀, 턱 등 얼굴의 방향과 관련된 지점들을 식별할 수 있다. 이때, 프로세서는 지시/응시 방향 감지 모듈과 연결된 객체 인식 모듈을 이용하거나 또는 얼굴 이미지로부터 응시 방향을 검출하 도록 학습된 별도의 인공지능 모델을 이용할 수도 있다. 그리고, 프로세서는 식별된 지점들(1022, 1023)을 이용하여 사용자가 응시하는 방향을 판단할 수 있 다. 한편, 도 10a 내지 도 10b는 뎁스 카메라 또는 RGB-D 카메라를 통해 획득된 뎁스 이미지를 이용한 것이지만, 전 자 장치가 스테레오 카메라를 통해 획득된 복수의 이미지 간의 차이에 따라 지시/응시 방향을 판단하는 실 시 예도 가능하다. 또는, 전자 장치는 단순히 RGB 이미지만을 제공하는 싱글 카메라를 이용하여 이미지 내 명암 및 그림자를 분석함으로써 사용자의 응시/지시 방향을 판단할 수도 있다. 프로세서는 판단된 지시/응시 방향에 기초하여 카메라의 촬영 방향을 조절하고, 조절된 카메라를 통 해 획득된 이미지로부터 대용어에 대응되는 관심 영역을 식별할 수 있다. 즉, 프로세서는 조절된 카메라를 통해 획득된 이미지에 대하여 S110 단계를 수행할 수 있다. 도 10c는 사용자의 지시/응시 방향에 따라 카메라의 방향을 조절하는 실시 예를 설명하기 위한 도면이다. 도 10c를 참조하면, 로봇인 전자 장치는 카메라를 구비한 헤드부 및 이동 수단(ex. 바퀴)을 구 비한 바디부를 포함할 수 있다. 도 10c를 참조하면, 헤드부는 지면에 평행한 방향 및/또는 지면에 수직한 방향으로 회전할 수 있으며, 그 결과 카메라의 방향이 조절될 수 있다.바디부는 이동 수단을 이용하여 지면에 평행한 방향으로 회전할 수 있다. 그 결과, 전자 장치의 이동 방향 및 카메라의 방향이 조절될 수 있다. 이때, 도 10c와 같이 구현된 전자 장치의 프로세서는, 주행/모션 모듈을 통해 헤드부 및/ 또는 바디부를 제어하여 카메라의 방향을 조절할 수 있다. 한편, S110 단계에서, 프로세서는 지시/응시 방향 감지 모듈을 통해 판단된 지시/응시 방향을 이용하 여 관심 영역을 식별할 수도 있다. 관련하여, 도 11은, 본 개시의 전자 장치가 사용자의 지시/응시 방향에 따라 관심 영역을 식별하는 예를 설명하 기 위한 도면이다. 도 11을 참조하면, 프로세서는 카메라를 통해 획득된 이미지 중 사용자의 지시/응시 방향 으로부터 기설정된 범위(ex. 지시/응시 방향을 기준으로 기설정된 각도 범위) 내인 영역을 관심 영 역으로 식별할 수 있다. 그리고, 프로세서는 관심 영역으로부터 대용어가 지칭하는 객체를 식별할 수 있다. 한편, 이동 수단을 포함하는 전자 장치의 메모리가 전자 장치가 운용되는 공간의 맵에 대한 정 보를 저장하고 있는 경우, 카메라를 통해 획득된 이미지에서 장애물이 식별되면, 프로세서는 맵에 대 한 정보 및 식별된 장애물에 대한 정보를 이용하여, 장애물이 포함되지 않으면서도 판단된 방향의 이미지를 획 득할 수 있는 지점으로 이동하도록 이동 수단을 제어할 수 있다. 관련하여, 도 12는, 카메라를 통해 획득된 이미지상에서 장애물이 발견된 경우, 본 개시의 전자 장치가 맵에 대 한 정보 및 사용자의 지시/응시 방향을 고려하여 이동하는 예를 설명하기 위한 도면이다. 도 12는 프로세서가 지시/응시 방향에 따라 카메라의 방향을 조절한 후 카메라를 통해 이 미지를 획득한 상황을 가정한다. 도 12를 참조하면, 프로세서는 객체 인식 모듈을 통해 장애물을 인식할 수 있다. 도 12를 참조 하면, 이미지상에서 지시/응시 방향에 따른 관심 영역 내에 아무런 객체가 인식되지 않는 상황이므로, 프 로세서는 장애물을 피해서 방향에 위치한 객체들을 촬영할 수 있는 위치로 이동하도록 이동 수단을 제어할 수 있다. 이때, 프로세서는 객체 인식 모듈을 통해 인식된 장애물의 크기나 모양에 대한 정보를 획득할 수 있 으며, 장애물 및/또는 맵에 대한 정보에 기반한 주변 지형에 부딪히지 않는 경로로 이동하도록 이동 수단을 제 어할 수 있다. 한편, 이동 수단을 포함하는 전자 장치의 메모리가 전자 장치가 운용되는 공간의 맵에 대한 정 보 및 맵상에 존재하는 객체들의 위치 정보를 저장하고 있는 상황에서, 대화 내용에 따라 획득된 객체에 대한 정보에 기초하여 관심 영역으로부터 대용어가 지칭하는 객체가 식별되지 않는 경우, 프로세서는 추가 정보 에 대한 요청을 출력하지 않고, 전자 장치의 맵 상 위치를 대화 내용에 따라 획득된 객체에 대한 정보와 매칭해볼 수 있다. 구체적으로, 프로세서는 저장된 위치 정보에 기초하여, 맵 상에서 전자 장치가 위치하는 지점 주변에 존재하는 적어도 하나의 객체를 식별할 수 있다. 이때, 프로세서는 센서 및 센서 모듈을 통해 수신된 센싱 데이터를 이용하여 전자 장치의 맵 상 위치를 식별하고, 저장된 객체들의 위치 정보 중 전자 장치의 맵 상 위치의 주변(전자 장치의 맵 상 위치로부터 기설정된 범위 내)에 매칭되는 위치 정보를 가지는 적어도 하나의 객체를 식별할 수 있다. 그리고, 프로세서는 주변에 존재하는 적어도 하나의 객체 중 획득된 객체에 대한 정보와 관련된 객체가 존 재하지 않는 경우, 저장된 위치 정보에 기초하여, 획득된 객체에 대한 정보와 관련된 객체가 존재하는 맵 상의 지점으로 이동하도록 이동 수단을 제어할 수 있다. 예를 들어, 전자 장치의 주변에 존재하는 객체들의 종류는 에어컨 및 TV뿐인 반면, 대화 내용을 통해 획득 된 객체의 종류는 공기 청정기인 경우, 프로세서는 저장된 객체들의 위치 정보 중 공기 청정기의 위치 정 보를 이용하여 맵 상에서 공기 청정기들이 위치하는 지점으로 이동하도록 주행/모션 모듈을 제어할 수 있 다. 이 경우, 전자 장치가 공기 청정기들이 위치하는 지점에 도착하면, 프로세서는 추가 정보를 요청 하도록 추가 정보 요청 모듈을 제어할 수도 있다.한편, 비록 도 9b에는 도시되지 않았으나, 전자 장치는 대용어 음향 분석 모델을 더 포함할 수 있다. 프로세서는, 대용어 음향 분석 모델을 통해, 입력된 사용자의 음성(오디오 신호) 중 대용어의 오디오 신호 만을 추출한 뒤, 해당 오디오 신호의 특성에 따라 관심 영역을 식별/조정할 수 있다. 오디오 신호의 특성은 오 디오 신호의 시간 길이, 음 높이 외에도 오디오 신호에 대해 도메인 변환을 적용한 결과에 따른 다양한 특징 정 보 등을 포함할 수 있다. 예를 들어, 프로세서는 사용자의 질의에 \"저거\"라는 대용어가 포함된 경우, \"저거\"에 대응되는 오디오 신 호의 시간 길이가 길수록 관심 영역을 이미지상에서 더 먼 영역으로 식별할 수 있다. 또한, 프로세서는 \" 저거\"에 대응되는 오디오 신호의 음 높이가 높을수록 관심 영역을 이미지상에서 더 먼 영역으로 식별할 수도 있 다. 또한, \"저거\"에 대응되는 오디오 신호의 특징 정보와 비교적 강한 발음(ex. '저거'의 된소리-> '쩌거')의 특징 정보 간의 유사도가 높을수록, 프로세서는 관심 영역을 이미지상에서 더 먼 영역으로 식별할 수 있다. 한편, 대용어 치환 모듈은, 객체 인식 모듈의 객체 인식 결과와 무관하게, 텍스트 분석 모듈로 부터 획득된 대화 내용만으로 대용어가 지칭하는 객체를 판단할 수도 있다. 이를 위해, 대용어 치환 모듈 은, 대용어를 포함하는 대화 내용으로부터 대용어가 지칭하는 객체를 추출하도록 설계/학습된 대화 기반 객체 인식 모듈을 포함할 수 있다. 이하 도 13 내지 도 16을 통해서는, 본 개시에 따른 전자 장치의 제어 방법을 설명한다. 도 13은, 본 개시에 따라 사용자의 질의가 입력되면, 질의에 대한 응답을 제공하는 전자 장치의 제어 방법을 설 명하기 위한 순서도이다. 도 13을 참조하면, 본 제어 방법은, 입력된 사용자의 질의에 대용어가 포함된 경우, 카메라를 통해 획득된 이미 지에서 대용어에 대응되는 관심 영역을 식별할 수 있다(S1310). 이 경우, 대용어가 가지는 거리 속성에 따라, 획득된 이미지에서 상이한 영역을 관심 영역으로 식별할 수 있다. 일 예로, 대용어가 \"이거\", \"이것들\"과 같이 가까운 거리의 객체를 지칭하는 대용어인 경우, 획득된 이미지 내 에서 상대적으로 가까운 거리에 위치하는 영역을 관심 영역으로 식별하고, 대용어가 \"저거\", \"저것들\"과 같이 먼 거리의 객체를 지칭하는 대용어인 경우, 획득된 이미지에서 상대적으로 먼 거리에 위치하는 영역을 관심 영 역으로 식별할 수 있다. 일 예로, 질의에 제1 대용어가 포함되고 해당 질의 또는 해당 질의 이후에 입력된 질의에 제2 대용어가 포함되 는 경우, 제1 대용어가 지칭하는 제1 객체가 획득된 이미지의 일 영역에서 식별된 후, 제1 대용어 및 제2 대용 어의 거리 속성에 기초하여, 제1 객체 및 제2 대용어가 지칭하는 제2 객체 간의 상대적 위치 관계를 판단하고, 제1 객체가 식별된 일 영역을 기준으로 상술한 상대적 위치 관계를 갖는 영역을 제2 대용어에 대응되는 관심 영 역으로 식별할 수 있다. 한편, 본 제어 방법은, 획득된 이미지에서 각각 하나의 객체가 존재하는 적어도 하나의 영역을 식별하고, 획득 된 이미지 내 식별된 영역의 밀집도에 기초하여 대용어에 대응되는 관심 영역을 식별할 수도 있다. 구체적으로, 대용어가 \"이거\", \"저거\" 등 단수의 객체를 지칭하는 대용어인 경우, 획득된 이미지에서 식별된 영 역의 밀집도가 상대적으로 낮은 영역을 관심 영역으로 식별하고, 대용어가 \"이것들\", \"저것들\"과 같이 복수의 객체를 지칭하는 대용어인 경우, 획득된 이미지에서 식별된 영역의 밀집도가 상대적으로 높은 영역을 관심 영역 으로 식별할 수 있다. 한편, 전자 장치에 전자 장치가 운용되는 공간의 맵에 대한 정보 및 맵 상에 존재하는 객체들의 위치 정보가 저 장된 경우, 본 제어 방법은, 저장된 객체들의 위치 정보를 이용하여 관심 영역을 식별할 수도 있다. 일 예로, 대용어가 객체의 종류에 대한 정보를 포함하고 있는 경우, 저장된 객체들의 위치 정보로부터 해당 종 류의 객체가 존재하는 위치 정보를 획득할 수 있다. 이 경우, 맵에 대한 정보에 기초하여, 획득된 이미지로부터 획득된 위치 정보와 매칭되는 관심 영역을 식별할 수 있다. 그리고, 본 제어 방법은, 식별된 관심 영역에 포함된 적어도 하나의 객체 중 대용어가 지칭하는 객체를 식별할 수 있다(S1320). 구체적으로, 획득된 이미지에서 객체가 존재하는 적어도 하나의 영역을 식별하고, 식별된 영역 중 관심 영역에 포함된 영역에 포함된 객체를 식별할 수 있다. 그리고, 입력된 질의, 해당 질의 이전에 입력된 사용자의 이전 질의 및 이전 질의에 대한 응답을 포함하는 대화 내용에 기초하여 대용어가 지칭하는 객체에 대한 정보를 획득하고, 획득된 객체에 대한 정보에 기초하여, 관심 영역에 포함된 영역에 포함된 객체 중 대용어가 지칭하는 객체를 식별할 수 있다. 한편, 대화 내용에 기초하여 획득된 객체에 대한 정보에 기초하여 관심 영역으로부터 대용어가 지칭하는 객체를 식별할 수 없는 경우, 추가 정보에 대한 요청을 출력할 수 있다. 이 경우, 출력된 요청에 따른 사용자의 재질의 또는 응답이 입력되면, 입력된 재질의 또는 응답으로부터 객체에 대한 추가 정보를 획득하고, 획득된 추가 정보에 기초하여 관심 영역에 포함된 영역에 포함된 객체 중 대용어가 지칭하는 객체를 식별할 수 있다. 그리고, 대용어를 지칭하는 객체로 식별된 객체에 대한 정보를 응답으로 제공할 수 있다(S1330). 구체적으로, 사용자의 질의에서 대용어를 식별된 객체로 치환하고, 대용어가 식별된 객체로 치환된 질의에 대한 응답을 시각 적 또는 청각적으로 출력할 수 있다. 도 14는, 본 개시에 따른 제어 방법이 도 13의 과정들을 시작하게 되는 과정의 일 예를 구체적으로 설명하기 위 한 알고리즘이다. 도 14를 참조하면, 전자 장치는 카메라를 통해 획득된 이미지에 포함된 사용자를 인식함으로써 사용자를 발견한 경우 또는 사용자의 음성이 입력된 경우(S1405), 사용자 방향으로 카메라를 회전시킬 수 있다(S1410). 이때, 사용자로부터 기설정된 거리까지 근접할 수 있다. 이 경우, \"무엇을 도와드릴까요?\"와 같은 안내를 시각 적/청각적으로 출력할 수도 있다. 한편, 도 14의 S1405와 달리, 전자 장치의 특정한 버튼을 누르는 입력, 특정 한 정보의 NFC(Near Field Communication) 태그 입력 등 기설정된 이벤트에 따라 S1410 단계를 수행할 수도 있 다. 사용자의 질의가 입력되는 경우(S1415 - Y), 질의에 대용어가 포함되어 있지 않은 경우라면(S1420 - N), 사용자 의 질의에 대한 응답을 제공할 수 있다(S1425). 예를 들어, \"에어컨 'A'는 얼마야?\"라는 질의가 입력되는 경우, 복수의 제품에 대한 정보를 포함하는 데이터 베이스로부터 에어컨 'A'에 대한 가격 정보를 획득하여 \"에어컨 'A'는 120만원입니다.\"라는 응답을 제공할 수 있다. 다만, 입력된 사용자의 질의에 \"이거\", \"저것들\" 등의 대용어가 포함된 경우(S1420 - Y), 본 제어 방법은 카메 라를 통해 획득된 이미지를 이용하여 사용자가 지시하는 방향 또는 응시하는 방향을 식별할 수 있다(S1430). 이때, 사용자의 지시/응시 방향이 식별되지 않으면(S1435 - N), \"무엇을 말씀하시는지 알 수 없어요. 제품명을 말씀해 주시겠어요?\"와 같은 추가 정보 요청을 출력할 수 있다. 반면, 사용자의 지시/응시 방향이 식별된 경우(1435- Y), 식별된 방향으로 카메라를 회전하여 이미지를 획득할 수 있다(S1445). 그리고, 도 13의 S1310 내지 S1330 단계를 수행할 수 있다. 한편, 도 13의 과정을 수행하기 전 과정은 도 14의 경우에만 한정되는 것이 아니며, 도 14의 과정들의 순서가 변경되어 수행되거나 및/또는 도 14의 과정들 중 적어도 일부만이 수행될 수도 있다. 도 15는, 본 개시에 따른 제어 방법이 관심 영역을 식별하는 S1310 단계의 구체적인 일 예를 설명하기 위한 알 고리즘이다. 도 15를 참조하면, 먼저 대용어가 '이 에어컨', '저 공기 청정기들'과 같이 객체의 종류(에어컨, 공기 청정기) 를 포함하는지 식별할 수 있다(S1510). 만약, 대용어가 객체의 종류를 포함하는 경우(S1510 - Y), 카메라를 통해 획득된 이미지 내에 대용어에 포함된 종류의 객체가 위치하는 영역이 있는지 판단할 수 있다(S1520). 구체적으로, 라이다 센서 또는 3D 카메라 등을 통해 수신된 센싱 데이터를 저장된 맵에 대한 정보와 비교하여 맵 상에서 전자 장치의 위치 및 이미지를 촬영한 카메라의 방향을 식별할 수 있다. 그리고, 저장된 맵 상 객체 들의 위치 정보에 포함된 각 종류의 객체들의 위치 정보를 이용하여, 대용어에 포함된 종류의 객체가 이미지 내 에 존재하는지 식별할 수 있다. 만약, 이미지 내에 대용어에 포함된 종류의 객체가 존재하는 경우(S1520 - Y), 이미지 내에서 대용어에 포함된 종류의 객체가 위치하는 영역을 관심 영역으로 설정할 수 있다(S1530). 반면, 전자 이미지 내에 대용어에 포함된 종류의 객체가 존재하는 경우(S1520 - N), 전자 장치의 주변에 대용어 에 포함된 종류의 객체가 존재하는지 판단할 수 있다(S1540). 구체적으로, 각 종류의 객체들의 위치 정보 및 전자 장치의 위치를 비교하여, 전자 장치 주변에 대용어에 포함 된 종류의 객체가 존재하는지 판단할 수 있다. 만약, 전자 장치의 주변에 대용어에 포함된 종류의 객체가 존재하지 않는 경우(S1550 - N), 사용자에게 추가 정 보를 요청하거나 또는 맵 상에서 해당 종류의 객체가 존재하는 위치로 이동할 수 있다(S1550). 만약, 전자 장치의 주변에 대용어에 포함된 종류의 객체가 존재하는 경우(S1550 - Y), 해당 종류의 객체가 있는 방향으로 카메라를 회전하여 이미지를 새롭게 획득할 수 있다(S1560). 그리고, 새롭게 획득된 이미지 내에서 대 용어에 포함된 종류의 객체가 위치하는 영역을 관심 영역으로 설정할 수 있다(S1530). 그리고, 대용어의 거리 속성에 따라 관심 영역을 조정할 수 있다(S1570). 구체적으로, 대용어가 \"이거\"와 같이 가까운 거리의 객체를 지칭하는 경우 관심 영역을 S1530에서 설정된 영역보다 조금 가까운 영역으로 조정하고, 대용어가 \"저거\"와 같이 먼 거리의 객체를 지칭하는 경우 관심 영역을 S1530에서 설정된 영역보다 조금 먼 영역 으로 조정할 수 있다. 그리고, 대용어가 지칭하는 객체의 수에 따라 관심 영역을 조정할 수 있다(S1580). 구체적으로, 이미지 내에서 존재가 식별된 객체들의 밀집도를 이미지 내 영역별로 판단한 뒤, 대용어가 단수인 경우, S1570에서 설정된 관 심 영역 중에서도 밀집도가 비교적 낮은 영역만을 최종 관심 영역으로 설정하고, 대용어가 복수인 경우, S1570 에서 설정된 관심 영역 중에서도 밀집도가 비교적 높은 영역만을 최종 관심 영역으로 설정할 수 있다. 한편, 도 15를 참조하면, 대용어가 객체의 종류를 포함하지 않는 경우(S1510 - N), 곧바로 S1570 단계를 통해 관심 영역을 설정하고, S1580 단계를 통해 관심 영역을 조정할 수 있다. 한편, 도 15의 실시 예는 S1310 단계의 구체적인 일 예일뿐, 본 개시를 접한 통상의 기술자가 공지된 기술상식 을 이용하여 도 15 내 적어도 하나의 단계를 수정/제거하거나 또는 새로운 단계를 추가하여 실시할 수 있음은 물론이다. 구체적으로, 도 15는 일 예일 뿐 도 15에 포함된 각 단계의 순서가 바뀌거나 도 15에 포함된 단계들 중 일부만 이 S1310 과정에서 수행될 수도 있다. 또한, 도 15에는 도시되지 않았으나, 이미지 내에서 사용자의 지시/응시 방향에 대응되는 영역으로 관심 영역을 설정(조정)하는 단계가 더 추가될 수도 있다. 도 16은, 본 개시에 따른 제어 방법이 관심 영역 내에서 대용어가 지칭하는 객체를 식별하는 S1320 단계의 일 예를 구체적으로 설명하기 위한 알고리즘이다. 도 16을 참조하면, 본 제어 방법은 카메라를 통해 획득된 이미지(: 관심 영역이 식별된 이미지와 동일한 이미지)에서 객체가 존재하는 적어도 하나의 영역을 식별할 수 있다(S1605). 이때, 이미지가 입력되면 이미지에 서 객체가 존재할 확률이 임계 값 이상인 영역을 식별하도록 학습된 인공지능 모델을 이용할 수 있다. 만약 이미지에서 객체가 존재하는 영역이 하나도 존재하지 않는 경우(S1610 - Y), 사용자에게 추가 정보를 요청 하고(S1635), 도 14의 S1415 단계로 돌아갈 수 있다. 반면, 이미지에서 객체가 존재하는 영역이 하나 이상 식별되는 경우(S1610 - N), 식별된 영역 중 관심 영역에 포함된 영역의 객체를 식별할 수 있다(S1615). 구체적으로, 식별된 영역을 객체 인식용 인공지능 모델에 입력하 여, 식별된 영역 각각에 포함된 객체의 제품명 등을 구체적으로 인식할 수 있다. 그리고, 입력된 사용자의 질의를 포함하는 사용자 및 전자 장치 간의 대화 내용에 따라, 대용어가 지칭하는 객 체에 대한 정보를 획득할 수 있다(S1620). 그리고, 관심 영역 내에서 식별된 객체 중 획득된 객체에 대한 정보에 매칭되는 객체가 있는지 식별할 수 있다 (S1625). 만약, 매칭되는 객체가 있는 경우(S1625 - Y), 해당 객체를 대용어가 지칭하는 객체로 식별할 수 있다(S1630). 이 경우, 대용어가 지칭하는 객체로 식별된 객체에 대한 정보를 포함하는 응답을 제공할 수 있다. 반면, 매칭되는 객체가 없는 경우(S1625 - N), 대용어 치환에 실패한 것으로 인식하고(S1640), 대용어 치환 실 패 횟수가 2회 이상인지 판단할 수 있다(S1645). 만약, 대용어 치환 실패 횟수가 2회 이상인 경우(S1645 - Y), 곧바로 사용자에게 추가 정보를 요청하고(S1635), S1415 단계로 돌아갈 수 있다. 반면, 대용어 치환 실패 횟수가 1회인 경우(S1645 - N), 전자 장치의 주변에 객체에 대한 정보와 매칭되는 객체 가 있는지 식별할 수 있다(S1650). 만약, 매칭되는 객체가 주변에 없는 경우라면(S1650 - N), 맵 상에서 매칭되는 객체가 있는 곳으로 이동한 (S1655) 뒤 추가 정보를 요청하고(S1635), 매칭되는 객체가 주변에 있는 경우라면(S1650 - Y), 곧바로 추가 정 보를 요청할 수 있다(S1635). 한편, 도 16의 실시 예는 S1320 단계의 구체적인 일 예일뿐, 본 개시를 접한 통상의 기술자가 공지된 기술상식 을 이용하여 도 16 내 적어도 하나의 단계를 수정/제거하거나 또는 새로운 단계를 추가하여 실시할 수 있음은 물론이다. 한편, 이상 도 13 내지 도 16을 통해 설명한 전자 장치의 제어 방법은, 도 2a, 도 2b, 도 9a 및 도 9b를 통해 도시 및 설명한 전자 장치를 통해 수행될 수 있다. 또는, 이상 도 13 내지 도 16을 통해 설명한 전자 장치의 제어 방법은, 전자 장치 및 하나 이상의 외부 장 치를 포함하는 시스템을 통해 수행될 수도 있다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합된 것 을 이용하여 컴퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 본 개시에서 설명되는 실시 예들은 ASICs(Application Specific Integrated Circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(Programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processor), 제어기 (controller), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서(microprocessor), 기타 기능 수행을 위한 전기적인 유닛(unit) 중 적어도 하나를 이용하여 구현될 수 있다. 일부의 경우에 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구 현에 의하면 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 상술한 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 작동을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 전자 장치에서의 처리동작을 수행하기 위한 컴퓨터 명령 어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium)에 저장될 수 있다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프로세서에 의 해 실행되었을 때 상술한 다양한 실시 예에 따른 전자 장치의 처리 동작을 상술한 특정 기기가 수행하도록 한다. 비일시적 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니 라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상 술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있다. 또한, 이상에서는 본 발명의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2019-0099131", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해돼서는 안 될 것이다."}
{"patent_id": "10-2019-0099131", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a 및 도 1b는, 본 개시에 따른 전자 장치가 대용어의 속성을 이용하여 대용어가 지칭하는 객체를 식별하는 예들을 개략적으로 설명하기 위한 도면들, 도 2a 및 도 2b는, 본 개시의 일 실시 예에 따른 전자 장치의 구성/동작을 하드웨어 및/또는 소프트웨어를 기준 으로 설명하기 위한 블록도들, 도 3a 및 도 3b는, 본 개시에 따른 전자 장치가 대용어가 지칭하는 객체를 식별하기 위해, 대용어의 거리 속성 에 따라 관심 영역을 식별하여 예를 설명하기 위한 도면들, 도 4는 본 개시에 따른 전자 장치가 대용어 간의 상대적 거리 속성에 따라 관심 영역을 식별하는 예를 설명하기 위한 도면, 도 5a 및 도 5b는, 본 개시에 따른 전자 장치가 대용어가 지칭하는 객체의 수에 따라 관심 영역을 식별하는 예 들을 설명하기 위한 도면들, 도 6a 및 도 6b는, 대용어가 객체의 종류를 포함하는 경우, 본 개시에 따른 전자 장치가 해당 종류에 따라 관심 영역을 식별하는 예를 설명하기 위한 도면들, 도 7은, 본 개시에 따른 전자 장치가 사용자 및 전자 장치 간의 대화 내용을 이용하여 관심 영역 내 객체 중 대 용어가 지칭하는 객체가 무엇인지 판단하는 예를 설명하기 위한 도면, 도 8은, 관심 영역 내에 대용어가 지칭하는 객체가 존재하지 않는 것으로 식별된 경우, 본 개시에 따른 전자 장 치가 추가 정보에 대한 요청을 출력하는 일 예를 설명하기 위한 도면, 도 9a 및 도 9b는, 본 개시의 다양한 실시 예에 따른 전자 장치의 구성/동작을 하드웨어 및/또는 소프트웨어를 기준으로 설명하기 위한 블록도들, 도 10a 내지 도 10c는, 본 개시에 따른 전자 장치가 대용어가 지칭하는 객체에 대한 사용자의 지시/응시 방향을 식별하고, 식별된 방향에 따라 카메라의 방향을 조절하는 예를 설명하기 위한 도면들, 도 11은, 본 개시의 전자 장치가 사용자의 지시/응시 방향에 따라 관심 영역을 식별하는 예를 설명하기 위한 도 면, 도 12는, 카메라를 통해 획득된 이미지상에서 장애물이 발견된 경우, 본 개시의 전자 장치가 맵에 대한 정보 및 사용자의 지시/응시 방향을 고려하여 이동하는 예를 설명하기 위한 도면, 도 13은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 순서도, 도 14는, 본 개시에 따른 제어 방법이 도 13의 과정을 시작하기 전에 수행하는 과정의 일 예를 구체적으로 설명 하기 위한 알고리즘, 도 15는, 본 개시에 따른 제어 방법이 관심 영역을 식별하는 일 예를 구체적으로 설명하기 위한 알고리즘, 그리 고 도 16은, 본 개시에 따른 제어 방법이 관심 영역 내에서 대용어가 지칭하는 객체를 식별하는 일 예를 구체적으 로 설명하기 위한 알고리즘이다."}
