{"patent_id": "10-2018-7011569", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0063163", "출원번호": "10-2018-7011569", "발명의 명칭": "언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터를 채택한 자동화된 음악 작곡 및", "출원인": "앰퍼 뮤직 인코포레이티드", "발명자": "실버스테인, 앤드류, 에이치."}}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "시스템 사용자에 의해 제공되는 감정 타입 및 스타일 타입 음악적 경험 디스크립터와 시간 및/또는 공간 파라미터에 의해 구동되는 자동화된 음악 작곡 및 생성 시스템으로서,시스템 사용자가 프로세싱을 위해 상기 자동화된 음악 작곡 및 생성 시스템에 감정 타입 및 스타일 타입 음악적경험 디스크립터와 시간 및/또는 공간 파라미터를 제공할 수 있도록 하는 시스템 사용자 인터페이스; 및상기 시스템 사용자 인터페이스에 작동 가능하게 연결된 자동화된 음악 작곡 및 생성 엔진으로서, 디지털 음악조각에 대해 선택된 하나 이상의 음악 악기의 오케스트레이션을 이용하여 배열 및 연주되는 음악 음표 세트를각각 가진 하나 이상의 디지털 음악 조각을 작곡 및 생성하기 위해 함께 협력하는 복수의 기능 특정 서브 시스템을 포함하는 자동화된 음악 작곡 및 생성 엔진을 포함하며,상기 자동화된 음악 작곡 및 생성 엔진은 다양한 기능 특정 서브 시스템의 구성을 포함하며, 다양한 기능 특정서브 시스템은,상기 시스템 사용자 인터페이스로부터 상기 감정 타입 및 스타일 타입 음악적 경험 디스크립터와 시간 및/또는공간 파라미터를 수신하고, 상기 파라미터를 프로세싱 및 변환하여, 자동화된 음악 작곡 및 생성 중에 상기 기능 특정 서브 시스템 중 하나 이상이 사용하기 위한 음악 이론 기반 파라미터를 생성하는 파라미터 변환 서브시스템;하나 이상의 가상 악기로 이루어진 합주단에 의한 연주를 위해 작곡되는 상기 음악 조각을 자동으로 편곡하는오케스트레이션 서브 시스템;하나 이상의 자동화된 가상 악기 음악 합성 기술을 채택하여 편곡된 디지털 음악 조각의 디지털 버전을 제작하는 디지털 조각 제작 서브 시스템; 및상기 자동화된 음악 작곡 및 생성 시스템 내에서의 피드백 및 학습 사이클을 지원하는 피드백 및 학습 서브 시스템을 포함하며,상기 시스템 사용자는 상기 자동화된 음악 작곡 및 생성 시스템에 의해 작곡된 편곡 음악 조각에 대한 경험에응답하여 생성된 편곡 음악 조각 및/또는 음악 선호도에 대한 평가를 제공하며,상기 자동화된 음악 작곡 및 생성 시스템은 상기 시스템 사용자에 의해 제공된 상기 평가 및/또는 선호도에 기초하여 갱신된 음악 조각을 자동으로 생성하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 시스템 사용자 인터페이스는 비디오, 오디오 레코딩, 이미지, 또는 이벤트 마커로 이루어진 군으로부터 선택된 디지털 미디어 조각을 수신하며, 상기 자동화된 음악 작곡 및 생성 시스템은 상기 디지털미디어 조각을 음악적으로 스코어링하고 디지털 음악 조각과 디지털 미디어 조각을 조합하여 경험 및 검토를 위하여 상기 시스템 사용자 인터페이스를 통해 상기 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된 디지털 미디어 조각을 제작하기 위해 상기 디지털 음악 조각을 생성하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 자동화된 음악 작곡 및 생성 엔진은 편곡된 음악 조각에 대한 컨트롤러 코드를 제작하는컨트롤러 코드 제작 서브 시스템을 더 포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 가상 악기 음악 합성은 디지털 오디오 샘플링 기술을 포함한 음악 및 악기 합성 기술을이용하여 생성된 하나 이상의 가상 악기를 이용하여 제작된 디지털 오디오 음표, 화음 및 음표 시퀀스를 이용하여 음표 단위 및 화음 단위의 음악 조각 제작을 포함하는, 자동화된 음악 작곡 및 생성 시스템.공개특허 10-2018-0063163-3-청구항 5 제3항에 있어서, 상기 자동화된 음악 작곡 및 생성 엔진은,작곡되고 있는 음악 조각에 대한 일반 리듬을 생성하는 일반 리듬 생성 서브 시스템;작곡되고 있는 음악 조각에 대한 화음을 생성하는 일반 피치 생성 서브 시스템;작곡되고 있는 음악 조각에 대한 멜로디 리듬을 생성하는 멜로디 리듬 생성 서브 시스템; 및작곡되고 있는 음악 조각에 대한 멜로디 피치를 생성하는 멜로디 피치 생성 서브 시스템을 더 포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 일반 리듬 생성 서브 시스템은 길이 생성 서브 시스템; 템포 생성 서브 시스템; 박자 생성 서브 시스템; 키 생성 서브 시스템; 비트 계산기 서브 시스템; 조성 생성 서브 시스템; 마디 계산기 서브 시스템; 노래 형태 생성 서브 시스템; 하위 악절 길이 생성 서브 시스템; 하위 악절 내 화음 수 계산기 서브 시스템; 악절 길이 생성 서브 시스템; 특이 악절 생성 서브 시스템; 악절 내 화음 수 계산기 서브 시스템; 화음 길이 생성 서브 시스템; 특이 하위 악절 생성 서브 시스템; 악기 편성 서브 시스템; 악기 선택기 서브 시스템; 및타이밍 생성 서브 시스템 중 하나 이상의 서브 시스템을 포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서, 상기 일반 피치 생성 서브 시스템은,제1 화음 생성 서브 시스템, 하위 악절 화음 진행 생성 서브 시스템, 악절 화음 진행 생성 서브 시스템, 및 화음 자리바꿈 생성 서브 시스템 중 하나 이상의 서브 시스템을 포함하며,상기 멜로디 리듬 생성 서브 시스템은 멜로디 하위 악절 길이 생성 서브 시스템, 멜로디 하위 악절 생성 서브시스템, 멜로디 악절 길이 생성 서브 시스템, 멜로디 특이 악절 생성 서브 시스템, 멜로디 길이 생성 서브 시스템 및 멜로디 음표 리듬 생성 서브 시스템을 포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서, 상기 멜로디 피치 생성 서브 시스템은 제1 피치 생성 서브 시스템; 하위 악절 피치 생성 서브시스템; 악절 피치 생성 서브 시스템; 및 피치 옥타브 생성 서브 시스템 중 하나 이상의 서브 시스템을 포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제5항에 있어서, 상기 오케스트레이션 서브 시스템은 오케스트레이션 생성 서브 시스템을 포함하는, 자동화된음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제5항에 있어서, 상기 컨트롤러 코드 제작 서브 시스템은 컨트롤러 코드 생성 서브 시스템을 포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제3항에 있어서, 상기 디지털 조각 제작 서브 시스템은 디지털 오디오 샘플 오디오 검색기 서브 시스템; 디지털오디오 샘플 조직기 서브 시스템; 조각 통합기 서브 시스템; 조각 포맷 번역기 서브 시스템; 및 조각 전달기 서브 시스템 중 하나 이상의 서브 시스템을 포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제3항에 있어서, 상기 피드백 및 학습 서브 시스템은 피드백 서브 시스템; 음악 편집성 서브 시스템; 선호도 저장기 서브 시스템; 음악적 커널 서브 시스템; 사용자 취향 서브 시스템; 모집단 취향 서브 시스템; 사용자 선호도 서브 시스템; 및 모집단 선호도 서브 시스템 중 하나 이상의 서브 시스템을 포함하는, 자동화된 음악 작곡공개특허 10-2018-0063163-4-및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제3항에 있어서, 상기 시스템 사용자는 인간인, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제3항에 있어서, 상기 음악 이론 파라미터 중 하나 이상은 확률 기반 음악 이론 파라미터를 포함하는, 자동화된음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "시스템 사용자에 의해 제공되는 감정 타입 및 스타일 타입 음악적 경험 디스크립터와 시간 및/또는 공간 파라미터에 의해 구동되는 자동화된 음악 작곡 및 생성 프로세스로서,(a) 상기 시스템 사용자가 감정 타입 및 스타일 타입 음악적 경험 디스크립터와 시간 및/또는 공간 파라미터 세트를, 상기 감정 타입 및 스타일 타입 음악적 경험 디스크립터와 시간 및/또는 공간 파라미터 세트에 응답하여음악 조각을 자동으로 작곡 및 생성하도록 구성된 기능 특정 서브 시스템으로 구성된 자동화된 음악 작곡 및 생성 엔진에 작동 가능하게 연결된 시스템 사용자 인터페이스에 제공하는 단계;(b) 상기 감정 타입 및 스타일 타입 파라미터와 시간 및/또는 공간 파라미터 세트를 음악 이론 파라미터 세트로변환하는 단계;(c) 상기 음악 이론 파라미터 세트를 상기 자동화된 음악 작곡 및 생성 엔진 내의 상기 기능 특정 서브 시스템에 제공하는 단계;(d) 상기 기능 특정 서브 시스템이 상기 음악 이론 파라미터 세트를 프로세싱하고, 하나 이상의 자동화된 가상악기 음악 합성법을 이용하여 디지털 음악 조각을 자동으로 작곡 및 생성하는 단계; 및(e) 검토 및 평가를 위해 상기 시스템 사용자에게 디지털 음악 조각을 전달하는 단계를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,(e) 제작된 음악 조각에 대한 시스템 사용자의 평가 및/또는 선호도에 관한 피드백을 상기 시스템 사용자가 상기 시스템 사용자 인터페이스에 제공하는 단계; 및(f) 상기 시스템 사용자에 의한 검토 및 평가를 위해 상기 피드백을 이용하여 다른 디지털 음악 조각을 생성하는 단계를 더 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서, 상기 시스템 사용자 인터페이스는 인터넷 인프라에 작동 가능하게 연결된 웹 서버, 애플리케이션 서버 및 데이터베이스(RDBMS) 서버를 포함한 데이터 프로세싱 센터와 통신하는 클라이언트 머신을 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서, 상기 음악 이론 파라미터 중 하나 이상은 확률 기반 음악 이론 파라미터를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항에 있어서, 상기 시스템 사용자 인터페이스는 인터넷 인프라에 작동 가능하게 연결된 웹 서버, 애플리케이션 서버 및 데이터베이스(RDBMS) 서버를 포함한 데이터 프로세싱 센터와 통신하는 클라이언트 머신을 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "공개특허 10-2018-0063163-5-제15항에 있어서, 상기 기능 특정 서브 시스템은,하나 이상의 자동화된 가상 악기 음악 합성 기술을 채택하여 편곡된 디지털 음악 조각의 디지털 버전을 제작하는 디지털 조각 제작 서브 시스템을 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제15항에 있어서, 상기 가상 악기 음악 합성은 디지털 오디오 샘플링 기술을 포함한 음악 및 악기 합성 기술을이용하여 생성된 하나 이상의 가상 악기를 이용하여 제작된 디지털 오디오 음표, 화음 및 음표 시퀀스를 이용하여 음표 단위 및 화음 단위의 음악 조각 제작을 포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "시스템 사용자에 의해 제공되는 감정 타입 및 스타일 타입 음악적 경험 디스크립터와 시간 및/또는 공간 파라미터에 의해 구동되는 자동화된 음악 작곡 및 생성 프로세스로서,(a) 시스템 사용자가 감정 타입 및 스타일 타입 음악적 경험 디스크립터와 시간 및/또는 공간 파라미터 세트를,상기 감정 타입 및 스타일 타입 음악적 경험 디스크립터와 시간 및/또는 공간 파라미터 세트에 응답하여 음악조각을 자동으로 작곡 및 생성하도록 구성된 기능 특정 서브 시스템으로 구성된 자동화된 음악 작곡 및 생성 엔진에 작동 가능하게 연결된 시스템 사용자 인터페이스에 제공하는 단계;(b) 상기 감정 타입 및 스타일 타입 파라미터와 시간 및/또는 공간 파라미터 세트를 음악 이론 파라미터 세트로변환하는 단계;(c) 상기 음악 이론 파라미터 세트를 상기 자동화된 음악 작곡 및 생성 엔진 내의 상기 기능 특정 서브 시스템에 제공하는 단계;(d) 상기 기능 특정 서브 시스템이 상기 음악 이론 파라미터 세트를 프로세싱하여, 디지털 음악 조각을 자동으로 작곡 및 생성하는 단계;(e) 검토 및 평가를 위해 상기 시스템 사용자에게 디지털 음악 조각을 전달하는 단계;(f) 제작된 음악 조각에 대한 시스템 사용자의 평가 및/또는 선호도에 관한 피드백을 상기 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 엔진에 제공하는 단계; 및(g) 상기 시스템 사용자에 의한 검토 및 평가를 위해 상기 피드백을 이용하여 다른 디지털 음악 조각을 생성하는 단계를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "자동화된 음악 작곡 및 생성 시스템에 의해 지원되는 자동화된 음악 작곡 및 생성 프로세스로서,(a) 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 시스템으로 자동으로 작곡 및 생성하고자 하는 음악 조각에 대한 음악적 디스크립터로서 감정 타입 및 스타일 타입 및 선택적으로 타이밍 타입 파라미터를 수신하는단계;(b) 작곡될 음악 조각을 위한 일반 리듬을 생성하기 위해 일반 리듬 서브 시스템(A1)을 이용하는 단계;(c) 작곡되고 있는 음악 조각을 위한 화음을 생성하기 위해 일반 피치 생성 서브 시스템(A2)을 이용하는 단계;(d) 작곡되고 있는 음악 조각을 위한 멜로디 리듬을 생성하기 위해 멜로디 리듬 생성 서브 시스템(A3)을 이용하는 단계;(e) 작곡되고 있는 음악 조각을 위한 멜로디 피치를 생성하기 위해 멜로디 피치 생성 서브 시스템(A4)을 이용하는 단계;(f) 작곡되고 있는 음악 조각을 위한 오케스트레이션을 생성하기 위해 오케스트레이션 서브 시스템(A5)을 이용하는 단계;(g) 음악 조각을 위한 컨트롤러 코드를 제작하기 위해 컨트롤러 코드 제작 서브 시스템(A6)을 이용하는 단계;(h) 디지털 음악 조각을 제작하기 위해 디지털 조각 제작 서브 시스템(A7)을 이용하는 단계; 및공개특허 10-2018-0063163-6-(i) 시스템의 피드백 및 학습 사이클을 지원하기 위해 피드백 및 학습 서브 시스템(A8)을 이용하는 단계를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 상기 단계 (a)에서, 상기 음악적 경험 디스크립터가 시스템 사용자 I/O 서브 시스템(B0)을 통해 제공되며, 이는 GUI 기반일 수 있거나, EDI, XML, XML-HTTP, 및 머신 또는 컴퓨터 기반 머신인 시스템 사용자를 지원하여 상기 머신으로부터 자동화된 음악 작곡 및 생성 서비스를 요청하기 위해 머신 대 머신 또는 컴퓨터 대 컴퓨터 통신이 필요한 다른 유형의 정보 교환 기술을 이용하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제23항에 있어서, 상기 단계 (b)에서, 길이 생성 서브 시스템(B2); 템포 생성 서브 시스템(B3); 박자 생성 서브시스템(B4); 키 생성 서브 시스템(B5); 비트 계산기 서브 시스템(B6); 조성 생성 서브 시스템(B7); 마디 계산기서브 시스템(B8); 노래 형태 생성 서브 시스템(B9); 하위 악절 길이 생성 서브 시스템(B15); 하위 악절 내 화음수 계산기 서브 시스템(B16); 악절 길이 생성 서브 시스템(B12); 특이 악절 생성 서브 시스템(B10); 악절 내 화음 수 계산기 서브 시스템(B13); 화음 길이 생성 서브 시스템(B11); 특이 하위 악절 생성 서브 시스템(B14); 악기 편성 서브 시스템(B38); 악기 선택기 서브 시스템(B39); 및 타이밍 생성 서브 시스템(B41) 중 하나 이상의서브 시스템이 작곡될 음악 조각을 위한 일반 리듬을 생성시키기 위해 이용되는, 자동화된 음악 작곡 및 생성프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제23항에 있어서, 상기 단계 (c)에서, 제1 일반 리듬 생성 서브 시스템(B17); 하위 악절 화음 진행 생성 서브시스템(B19); 악절 화음 진행 생성 서브 시스템(B18); 및 화음 자리바꿈 생성 서브 시스템(B20) 중 하나 이상의서브 시스템이 작곡되고 있는 음악 조각을 위한 화음을 생성시키기 위해 이용되는, 자동화된 음악 작곡 및 생성프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제23항에 있어서, 상기 단계 (d)에서, 멜로디 하위 악절 길이 생성 서브 시스템(B25); 멜로디 하위 악절 생성서브 시스템(B24); 멜로디 악절 길이 생성 서브 시스템(B23); 멜로디 특이 악절 생성 서브 시스템(B22); 멜로디길이 생성 서브 시스템(B21); 및 멜로디 음표 리듬 생성 서브 시스템(B26) 중 하나 이상의 서브 시스템이 작곡되고 있는 음악 조각을 위한 멜로디 리듬을 생성시키기 위해 이용되는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제23항에 있어서, 상기 단계 (e)에서, 제1 피치 생성 서브 시스템(B27); 하위 악절 피치 생성 서브 시스템(B29); 악절 피치 생성 서브 시스템(B28); 및 피치 옥타브 생성 서브 시스템(B30) 중 하나 이상의 서브 시스템이 작곡되고 있는 음악 조각을 위한 멜로디 피치를 생성하기 위해 이용되는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제23항에 있어서, 상기 단계 (f)에서, 오케스트레이션 생성 서브 시스템(B31) 중 하나 이상의 서브 시스템이 작곡되고 있는 음악 조각을 위한 오케스트레이션을 생성하기 위해 이용되는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제23항에 있어서, 상기 단계 (g)에서, 컨트롤러 코드 생성 서브 시스템(B32) 중 하나 이상의 서브 시스템이 음악 조각을 위한 컨트롤러 코드를 생성하기 위해 이용되는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제23항에 있어서, 상기 단계 (h)에서, 디지털 오디오 샘플 오디오 검색기 서브 시스템(B333); 디지털 오디오 샘플 조직기 서브 시스템(B34); 조각 통합기 서브 시스템(B35); 조각 포맷 번역기 서브 시스템(B50); 및 조각 전달기 서브 시스템(B36) 중 하나 이상의 서브 시스템이 디지털 음악 조각을 제작하기 위해 이용되는, 자동화된공개특허 10-2018-0063163-7-음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제23항에 있어서, 상기 단계 (i)에서, 피드백 서브 시스템(B42); 음악 편집성 서브 시스템(B43l); 선호도 저장기 서브 시스템(B44); 음악적 커널 서브 시스템(B45); 사용자 취향 서브 시스템(B46); 모집단 취향 서브 시스템(B47); 사용자 선호도 서브 시스템(B48); 및 모집단 선호도 서브 시스템(B49) 중 하나 이상의 서브 시스템이 시스템의 피드백 및 학습 사이클을 지원하기 위해 이용되는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "음악을 자동으로 작곡 및 생성하기 위해, 시스템 사용자에 의해 제공되는 감정 타입 및 스타일 타입 음악적 경험 디스크립터와 시간 및 공간 파라미터에 의해 구동되는 자동화된 가상 악기 음악 합성을 이용하는 자동화된음악 작곡 및 생성 엔진으로서,작곡될 음악 조각을 위한 일반 리듬을 생성하는 일반 리듬 생성 서브 시스템(A1)으로서, 길이 생성 서브 시스템(B2), 템포 생성 서브 시스템(B3), 박자 생성 서브 시스템(B4), 키 생성 서브 시스템(B5), 비트 계산기 서브 시스템(B6), 조성 생성 서브 시스템(B7), 마디 계산기 서브 시스템(B8), 노래 형태 생성 서브 시스템(B9), 하위악절 길이 생성 서브 시스템(B15), 하위 악절 내 화음 수 계산기 서브 시스템(B16), 악절 길이 생성 서브 시스템(B12), 특이 악절 생성 서브 시스템(B10), 악절 내 화음 수 계산기 서브 시스템(B13), 화음 길이 생성 서브시스템(B11), 특이 하위 악절 생성 서브 시스템(B14), 악기 편성 서브 시스템(B38), 악기 선택기 서브 시스템(B39), 및 타이밍 생성 서브 시스템(B41)으로 이루어진 군으로부터 선택된 하나 이상의 서브 시스템을포함하는, 일반 리듬 생성 서브 시스템(A1);작곡되고 있는 음악 조각을 위한 화음을 생성하는 일반 피치 생성 서브 시스템(A2)으로서, 제1 화음 생성 서브시스템(B17), 하위 악절 화음 진행 생성 서브 시스템(B19), 악절 화음 진행 생성 서브 시스템(B18), 및 화음 자리바꿈 생성 서브 시스템(B20)으로 이루어진 군으로부터 선택된 하나 이상의 서브 시스템을 포함하는, 일반 피치 생성 서브 시스템(A2);작곡되고 있는 음악 조각을 위한 멜로디 리듬을 생성하는 멜로디 리듬 생성 서브 시스템(A3)으로서, 멜로디 하위 악절 길이 생성 서브 시스템(B25), 멜로디 하위 악절 생성 서브 시스템(B24), 멜로디 악절 길이 생성 서브시스템(B23), 멜로디 특이 악절 생성 서브 시스템(B22), 멜로디 길이 생성 서브 시스템(B21), 및 멜로디 음표리듬 생성 서브 시스템(B26)으로 이루어진 군으로부터 선택된 하나 이상의 서브 시스템을 포함하는, 멜로디 리듬 생성 서브 시스템(A3);작곡되고 있는 음악 조각을 위한 멜로디 피치를 생성하는 멜로디 피치 생성 서브 시스템(A4)으로서, 제1 피치생성 서브 시스템(B27), 하위 악절 피치 생성 서브 시스템(B29), 악절 피치 생성 서브 시스템(B28), 및 피치 옥타브 생성 서브 시스템(B30)으로 이루어진 군으로부터 선택된 하나 이상의 서브 시스템을 포함하는, 멜로디 피치 생성 서브 시스템(A4);작곡되고 있는 음악 조각을 위한 오케스트레이션을 생성하는 오케스트레이션 서브 시스템(A5)으로서, 오케스트레이션 생성 서브 시스템(B31)을 포함하는, 오케스트레이션 서브 시스템(A5);음악 조각을 위한 컨트롤러 코드를 제작하는 컨트롤러 코드 제작 서브 시스템(A6)으로서, 컨트롤러 코드 생성서브 시스템(B32)을 포함하는, 컨트롤러 코드 제작 서브 시스템(A6);디지털 음악 조각을 제작하는 디지털 조각 제작 서브 시스템(A7)으로서, 디지털 오디오 샘플 오디오 검색기 서브 시스템(B33), 디지털 오디오 샘플 조직기 서브 시스템(B34), 조각 통합기 서브 시스템(B35), 조각 포맷 번역기 서브 시스템(B50), 및 조각 전달기 서브 시스템(B36)으로 이루어진 군으로부터 선택된 하나 이상의 서브 시스템을 포함하는, 디지털 조각 제작 서브 시스템(A7); 및시스템의 피드백 및 학습 사이클을 지원하는 피드백 및 학습 서브 시스템(A8)으로서, 피드백 서브 시스템(B42),음악 편집성 서브 시스템(B43), 선호도 저장기 서브 시스템(B44), 음악적 커널 서브 시스템(B45), 사용자 취향서브 시스템(B46), 모집단 취향 서브 시스템(B47), 사용자 선호도 서브 시스템(B48), 및 모집단 선호도 서브 시스템(B49)으로 이루어진 군으로부터 선택된 하나 이상의 서브 시스템을 포함하는, 피드백 및 학습 서브 시스템(A8)을 포함하는, 자동화된 음악 작곡 및 생성 엔진.공개특허 10-2018-0063163-8-청구항 34 자동화된 음악 작곡 및 생성 프로세스로서,(i) 언어 음악적 경험 디스크립터 및 가상 악기 음악 합성의 사용을 지원하는 단계;(ii) 시스템 사용자가 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 자동화된 음악 작곡 및 생성 엔진에 의해 생성된 음악으로 스코어링될 미디어를 선택하는 단계;(iii) 시스템 사용자가 음악적으로 스코어링될 선택된 미디어에 적용하기 위해 시스템의 자동화된 음악 작곡 및생성 엔진에 제공된 음악적 경험 디스크립터를 선택하는 단계;(iv) 시스템 사용자가 자동화된 음악 작곡 및 생성 엔진을 기동하여 선택된 미디어에 스코어링되어 있는 제공된음악적 디스크립터에 기초한 음악을 작곡 및 생성하는 단계; 및(v) 시스템이 작곡된 음악을 선택된 미디어와 조합하여, 표시 및 향유하기 위한 복합 미디어 파일을 제작하는단계를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "자동화된 음악 작곡 및 생성 엔진으로서,사용자 GUI 기반 입출력 서브 시스템; 일반 리듬 서브 시스템; 일반 리듬 생성 서브 시스템; 멜로디 리듬 생성서브 시스템; 멜로디 피치 생성 서브 시스템; 오케스트레이션 서브 시스템; 컨트롤러 코드 제작 서브 시스템;디지털 조각 제작 서브 시스템; 및 피드백 및 학습 서브 시스템을 포함하는, 자동화된 음악 작곡 및 생성 엔진."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "자동화된 음악 작곡 및 생성 시스템으로서,그 내부의 다양한 서브 시스템에 채택된 확률 기반 파라미터 테이블에 대한 분배, 후속 서브 시스템의 설치 및자동화된 음악 작곡 및 생성을 위해 하나 이상의 음악적 경험 디스크립터를 시스템 사용자가 선택할 수 있도록하는 사용자 GUI 기반 입출력 서브 시스템(B0);선택된 음악적 감정 디스크립터를 포착하기 위해 사용자 GUI 기반 입출력 서브 시스템과 인터페이싱하는 디스크립터 파라미터 포착 서브 시스템(B1);음악적 스타일 디스크립션 파라미터를 포착하기 위해 사용자 GUI 기반 입출력 서브 시스템과 인터페이싱하는 스타일 파라미터 포착 서브 시스템(B37); 및자동화된 음악 작곡 및 생성 중에, 상기 음악적 감정 및 스타일 디스크립션 파라미터를 수신하여 그 내부의 다양한 서브 시스템에 채택된 파라미터 테이블을 자동으로 생성하도록 구성된 파라미터 변환 서브 시스템(B53)을포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_37", "content": "자동화된 음악 작곡 및 생성 시스템으로서,함께 집적된 복수의 서브 시스템을 포함하며, 사용자 GUI 기반 입출력 서브 시스템(B0)은 자동화된 음악 작곡및 생성 중에 사용하기 위해 파라미터 변환 엔진 서브 시스템에 의해 음악 이론 파라미터 테이블로 변환된 다음그 내부의 상기 복수의 서브 시스템에 분배되도록 하나 이상의 음악적 경험 디스크립터를 시스템 사용자가 선택할 수 있도록 하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_38", "content": "시스템 사용자에 의해 제공되는 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 자동화된 가상 악기 음악 합성을 지원하는 자동화된 음악 작곡 및 생성 프로세스로서, 언어 기반 음악적 경험 디스크립터와 비디오, 오디오 레코딩, 이미지, 또는 이벤트 마커는 시스템 사용자 인터페이스를 통해 입력으로서제공되고, 자동화된 음악 작곡 및 생성 엔진에 의해 사용되어, 가상 악기 음악 합성을 이용하여 음악적으로 스코어링된 미디어 또는 이벤트 마커를 생성시키며, 이들은 시스템 사용자 인터페이스를 통해 시스템 사용자에게다시 제공되는, 자동화된 음악 작곡 및 생성 프로세스.공개특허 10-2018-0063163-9-청구항 39 제38항에 있어서, 상기 음악적으로 스코어링된 미디어는 비디오, 오디오 파일, 이미지, 슬라이드 쇼 및 이벤트마커로부터 선택된 미디어 아이템을 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_40", "content": "시스템 사용자에 의해 제공되는 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 자동화된 가상 악기 음악 합성을 채택한 자동화된 음악 작곡 및 생성 프로세스로서,(a) 시스템 사용자가 시스템 사용자 인터페이스에 작동 가능하게 연결된 자동화된 음악 작곡 및 생성 엔진에 액세스한 다음, 상기 자동화된 음악 작곡 및 생성 엔진에 의해 생성된 음악으로 스코어링될 비디오, 오디오 레코딩, 슬라이드 쇼, 사진이나 이미지 또는 이벤트 마커를 상기 시스템 사용자 인터페이스로부터 선택하는 단계;(b) 상기 시스템 사용자가 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 상기 자동화된 음악 작곡및 생성 엔진에 제공하는 단계;(c) 상기 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 엔진을 기동하여 시스템 사용자에 의해 선택된 미디어 또는 이벤트 마커에 스코어링되어 있는(즉, 적용되어 있는) 입력된 음악적 디스크립터에 기초한 자동화된가상 악기 음악 합성을 사용하여 음악을 작곡 및 생성하는 단계;(d) 상기 시스템 사용자가 스코어링된 미디어 또는 이벤트 마커에 대해 제작된 작곡 및 생성된 음악을수용하고, 시스템 사용자가 주관적으로 경험하여 형성된 음악적 경험을 고려하여 제작된 음악에 대한 시스템 사용자의 평가 및/또는 음악 선호도에 관한 피드백을 상기 자동화된 음악 작곡 및 생성 엔진에 제공하는 단계; 및(v) 상기 시스템은 수용한 작곡된 음악을 선택된 미디어 또는 이벤트 마커와 조합하여, 분배 및 표시하기 위한비디오 파일을 제작하는 단계를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_41", "content": "제40항에 있어서, 단계 (b)는 텍스트 키보드 및/또는 음성 인식 인터페이스를 사용하여 시스템 사용자 인터페이스에 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 제공하는 단계를 포함하는, 자동화된 음악 작곡및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_42", "content": "장난감 음악 악기로서,비디오 스코어링 프로세스 중에 어린이에 의해 선택된 아이콘 기반 음악적 경험 디스크립터 및 음악적 스타일디스크립터에 의해 구동되는 자동화된 음악 작곡 및 생성 엔진; 및상기 자동화된 음악 작곡 및 생성 엔진에 작동 가능하게 연결된 시스템 사용자 인터페이스를 지원하는 컴퓨팅플랫폼을 포함하며,상기 컴퓨팅 플랫폼은,제어 프로그램을 저장하기 위한 프로그램 메모리와 어린이에 의해 스코어링될 비디오 및/또는 기타 미디어의 라이브러리를 저장하기 위한 영구 메모리를 갖춘 프로세서;상기 자동화된 음악 작곡 및 생성 엔진에 의해 자동으로 생성된 음악 조각으로 어린이에 의해 스코어링될 선택된 비디오를 표시하기 위한 터치 스크린 디스플레이 패널;선택된 비디오를 스코어링하기 위해 음악적 감정 디스크립터와 음악적 스타일 디스크립터를 어린이가 선택할 수있도록 하는 키보드; 및스코어링될 선택된 비디오와 연관된 오디오를 재생하고 상기 장난감 악기에 의해 자동으로 작곡된 음악을 연주하기 위한 오디오 스피커; 및상기 컴퓨팅 플랫폼이 무선 데이터 통신 네트워크에 작동 가능하게 연결된 하나 이상의 장치와 무선 통신을 확립할 수 있도록 하는 무선 네트워크 어댑터를 포함하며,상기 자동화된 음악 작곡 및 생성 엔진은 상기 키보드와 상기 터치 스크린 디스플레이 패널을 이용하여 어린이공개특허 10-2018-0063163-10-에 의해 선택되어 상기 자동화된 음악 작곡 및 생성 엔진에 제공된 음악적 경험 디스크립터와 음악적 스타일 디스크립터에 기초하여 선택된 비디오를 스코어링하기 위해 자동으로 작곡된 음악을 생성하는 가상 악기 음악 합성을 채택하고,상기 터치 스크린 디스플레이는 어린이가 라이브러리로부터 비디오를 선택 및 로드할 수 있도록 하며, 그 다음,어린이가 상기 키보드로부터 음악적 감정 및 스타일 디스크립터를 선택할 수 있음으로써, 어린이가 선택된 비디오의 분절된 장면에 대해 지정 음악을 작곡 및 생성할 수 있게 되는, 장난감 음악 악기."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_43", "content": "장난감 음악 작곡 및 생성 시스템 내에서의 자동화된 음악 작곡 및 생성 프로세스로서,(a) 시스템 사용자에 의해 제공된 음악적 경험 디스크립터에 의해 구동되는 자동화된 음악 작곡 및 생성 엔진에작동 가능하게 연결된 시스템 사용자 인터페이스를 지원하는 그래픽 아이콘을 제공하는 단계;(b) 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 엔진에 액세스한 다음, 상기 자동화된 음악 작곡 및 생성 엔진에 의해 생성된 음악으로 스코어링될 비디오를 선택하는 단계;(c) 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 엔진에 제공될 그래픽 아이콘 기반 음악적 경험 디스크립터를 선택하는 단계;(d) 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 엔진을 기동하고, 선택된 비디오 미디어에 스코어링되어있는 입력된 음악적 디스크립터에 기초하여 음악을 작곡 및 생성하는 단계;(e) 상기 장난감 음악 작곡 및 생성 시스템이 작곡된 음악을 선택된 비디오와 조합하여, 표시 및 시스템 사용자가 향유하기 위한 비디오 파일을 제작하는 단계; 및(f) 상기 비디오 파일을 검토 및 평가하고 선택된 그래픽 아이콘 기반 음악적 경험 디스크립터를 변경하여, 표시 및 향유하기 위한 새로운 비디오 파일을 제작하는 단계를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_44", "content": "음악 작곡 및 비디오 스코어링 장난감 악기로서,상기 음악 작곡 및 비디오 스코어링 장난감 악기로 연주하는 어린이 또는 성인에 의해 선택된 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 자동화된 음악 작곡 및 생성 엔진;상기 음악 작곡 및 비디오 스코어링 장난감을 제어하기 위해 상기 자동화된 음악 작곡 및 생성 엔진에 작동 가능하게 연결되고, 자동화된 음악 작곡 및 생성 엔진에 의해 생성된 비디오 및 음악 라이브러리를 저장하기 위한저장 장치를 가진 컴퓨팅 플랫폼; 및상기 저장 장치 내에 유지된 비디오 라이브러리로부터 또는 로컬 또는 인터넷에 연결된 원격 비디오 파일 서버로부터 선택된 비디오 파일을 표시하기 위한 디스플레이 스크린을 포함하며,어린이 또는 성인이 상기 시스템 사용자 인터페이스로부터 음악적 경험 디스크립터를 선택할 수 있음으로써, 어린이 또는 성인이 선택된 비디오의 분절된 장면에 대해 지정 음악을 작곡 및 생성할 수 있게 되는, 음악 작곡및 비디오 스코어링 장난감 악기."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_45", "content": "제44항에 있어서, 상기 시스템 사용자 인터페이스는 물리적 또는 가상 키보드를 포함하는, 음악 작곡 및 비디오스코어링 장난감 악기."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_46", "content": "제44항에 있어서, 음악적 경험 디스크립터는 감정 디스크립터 아이콘 및 스타일 디스크립터 아이콘을 포함하는,음악 작곡 및 비디오 스코어링 장난감 악기."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_47", "content": "자동화된 장난감 음악 작곡 및 생성 악기 시스템으로서,공개특허 10-2018-0063163-11-비디오 또는 기타 미디어 객체의 분절을 스코어링하는 데 사용하기 위한 자동화된 음악 작곡 및 생성 엔진; 및그래픽 아이콘 기반 음악적 경험 디스크립터를 선택하기 위한 시스템 사용자 인터페이스로서, 상기 시스템 사용자 인터페이스를 통해 입력으로서 선택된 비디오 또는 미디어 객체의 분절을 스코어링하는 데 사용하기 위해 상기 그래픽 아이콘 기반 음악적 경험 디스크립터를 상기 자동화된 음악 작곡 및 생성 엔진에 제공함으로써, 음악적으로 스코어링된 비디오 스토리를 자동으로 생성하는 시스템 사용자 인터페이스를 포함하며,상기 음악적으로 스코어링된 비디오 스토리는 상기 시스템 사용자 인터페이스를 통해 시스템 사용자에게 다시제공되는, 자동화된 장난감 음악 작곡 및 생성 악기 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_48", "content": "장난감 악기로서, 장난감 악기로 연주하는 어린이 또는 성인에 의해 선택된 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 자동화된 가상 악기 음악 합성을 지원하는 자동화된 음악 작곡 및 생성 엔진을 포함하며,장난감 악기의 저장 장치 내에 유지된 비디오 라이브러리로부터 또는 로컬 또는 인터넷에 연결된 원격 비디오파일 서버로부터 비디오를 선택하여 로드하기 위해 터치 스크린 디스플레이가 제공되며, 그 다음, 어린이는 물리적 또는 가상 키보드로부터 음악적 경험 디스크립터를 선택할 수 있음으로써, 어린이가 선택된 비디오의 분절된 장면에 대해 지정 음악을 작곡 및 생성할 수 있게 되는, 장난감 악기."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_49", "content": "전자 정보 프로세싱 및 디스플레이 시스템으로서,시스템 사용자의 창조적 및/또는 오락적 요구를 지원하는 SOC 기반의 자동화된 음악 작곡 및 생성 엔진; 및상기 SOC 기반의 자동화된 음악 작곡 및 생성 엔진에 작동 가능하게 연결된 시스템 사용자 인터페이스로서, 상기 시스템 사용자 인터페이스를 통해 입력으로서 (i) 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터와, (ii) 비디오, 오디오 레코딩, 이미지, 슬라이드 쇼 또는 이벤트 마커를 시스템 사용자가 입력할 수 있도록하는 시스템 사용자 인터페이스를 포함하며,상기 SOC 기반의 자동화된 음악 작곡 및 생성 엔진은 상기 시스템 사용자 인터페이스를 통해 시스템 사용자에게다시 제공되는 음악적으로 스코어링된 미디어 또는 이벤트 마커를 생성시키는, 전자 정보 프로세싱 및 디스플레이 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_50", "content": "제49항에 있어서, 상기 음악적으로 스코어링된 미디어는 하나 이상의 비디오, 팟 캐스트, 이미지 및 슬라이드쇼를 포함하는, 전자 정보 프로세싱 및 디스플레이 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_51", "content": "제49항에 있어서,컨트롤러를 지원하는 하나 이상의 버스 아키텍처와 집적된, 영구 메모리, 터치 스크린 디스플레이 패널, 마이크스피커, 키보드 또는 키패드, 무선 네트워크 어댑터와 인터페이싱하는 CPU, 프로그램 메모리(DRAM) 및 비디오메모리(VRAM)를 포함한 서브 시스템 아키텍처를 포함하는, 전자 정보 프로세싱 및 디스플레이 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_52", "content": "자동화된 음악 작곡 및 생성 시스템으로서,자동화된 음악 작곡 및 생성 엔진; 및언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터를 제공하기 위해 상기 자동화된 음악 작곡 및 생성엔진에 작동 가능하게 연결된 시스템 사용자 인터페이스를 포함하며,(i) 음악적 경험 디스크립터와, (ii) 비디오, 오디오 레코딩, 이미지, 슬라이드 쇼 또는 이벤트 마커가 상기 시스템 사용자 인터페이스를 통해 입력으로서 제공되어, 음악적으로 스코어링된 미디어 또는 이벤트 마커를 생성시키기 위해 상기 자동화된 음악 작곡 및 생성 엔진에 의해 사용되고,상기 음악적으로 스코어링된 미디어 또는 이벤트 마커는 상기 시스템 사용자 인터페이스를 통해 시스템 사용자공개특허 10-2018-0063163-12-에게 다시 제공되는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_53", "content": "언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 자동화된 음악 작곡 및 생성 프로세스로서,(i) 시스템 사용자가 자동화된 음악 작곡 및 생성 엔진에 의해 지원되는 자동화된 음악 작곡 시스템에 액세스한다음, 상기 자동화된 음악 작곡 및 생성 엔진에 의해 생성된 음악으로 스코어링될 비디오, 오디오 레코딩(즉,팟 캐스트), 슬라이드 쇼, 사진이나 이미지 또는 이벤트 마커를 선택하는 단계;(ii) 상기 시스템 사용자가 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 상기 자동화된 음악 작곡및 생성 엔진에 제공하는 단계;(iii) 상기 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 엔진을 기동하여 선택된 미디어 또는 이벤트 마커에 스코어링되어 있는 입력된 음악적 디스크립터에 기초한 음악을 작곡 및 생성하며, 가상 악기 음악 합성을이용하는 단계;(iv) 상기 시스템 사용자가 스코어링된 미디어 또는 이벤트 마커에 대해 제작된 작곡 및 생성된 음악을 수용하고, 시스템 사용자가 주관적으로 경험하여 형성된 음악적 경험을 고려하여 제작된 음악에 대한 상기 시스템 사용자의 평가 및/또는 음악 선호도에 관한 피드백을 상기 자동화된 음악 작곡 및 생성 엔진에 제공하는 단계; 및(v) 상기 자동화된 음악 작곡 시스템이 수용한 작곡된 음악을 선택된 미디어 또는 이벤트 마커와 조합하여, 분배 및 표시하기 위한 비디오 파일을 제작하는 단계를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_54", "content": "제53항에 있어서, 상기 가상 악기 음악 합성은 디지털 오디오 샘플링 기술을 포함한 음악 및 악기 합성 기술을이용하여 생성된 하나 이상의 가상 악기를 이용하여 제작된 디지털 오디오 음표, 화음 및 음표 시퀀스를 이용하여 음표 단위 및 화음 단위의 음악 조각 제작을 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_55", "content": "기업 수준의 인터넷 기반 음악 작곡 및 생성 시스템으로서,인터넷 인프라에 작동 가능하게 연결된 웹 서버, 애플리케이션 서버 및 데이터베이스 서버를 지원하는 데이터프로세싱 센터; 및인터넷 인프라에 작동 가능하게 연결된 복수의 클라이언트 머신으로서, 상기 데이터 프로세싱 센터에 액세스하여, 웹 기반 브라우저를 이용하여 누구나 상기 데이터 프로세싱 센터 내의 서버에 의해 지원되는 자동화된 음악작곡 및 생성 서비스에 액세스할 수 있도록 함으로써, 상기 클라이언트 머신 중 하나를 이용하여 비디오, 이미지, 슬라이드 쇼, 오디오 레코딩 및 기타 이벤트를 스코어링하여 상기 데이터 프로세싱 센터 내의 적어도 하나의 웹 서버에 작동 가능하게 연결된 시스템 사용자 인터페이스에 음악적 경험 디스크립터를 제공하는 복수의 클라이언트 머신을 포함하는, 기업 수준의 인터넷 기반 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_56", "content": "제54항에 있어서, 상기 언어 기반 음악적 경험 디스크립터와 비디오, 오디오 레코딩, 이미지, 또는 이벤트 마커는 상기 시스템 사용자 인터페이스를 통해 입력으로서 제공되고, 상기 자동화된 음악 작곡 및 생성 엔진에 의해사용되어, 시스템 사용자 인터페이스를 통해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된 미디어또는 이벤트 마커를 생성시키는, 기업 수준의 인터넷 기반 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_57", "content": "제54항에 있어서, 상기 음악적으로 스코어링된 미디어는 비디오, 팟 캐스트, 이미지 및 슬라이드 쇼로 이루어진군으로부터 선택되는, 기업 수준의 인터넷 기반 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_58", "content": "자동화된 음악 작곡 및 생성 프로세스로서,공개특허 10-2018-0063163-13-(a) 시스템 사용자가 시스템 사용자 인터페이스에 작동 가능하게 연결된 자동화된 음악 작곡 및 생성 시스템에액세스한 다음, 상기 자동화된 음악 작곡 및 생성 엔진에 의해 생성된 음악으로 스코어링될 비디오, 오디오 레코딩(즉, 팟 캐스트), 슬라이드 쇼, 사진이나 이미지 또는 이벤트 마커를 선택하는 단계;(b) 상기 시스템 사용자가 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 상기 자동화된 음악 작곡및 생성 엔진에 제공하는 단계;(c) 상기 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 시스템을 기동하여 선택된 미디어 또는 이벤트 마커에 스코어링되어 있는 입력된 음악적 디스크립터에 기초한 음악을 작곡 및 생성하는 단계;(d) 상기 시스템 사용자가 스코어링된 미디어 또는 이벤트 마커에 대해 제작된 작곡 및 생성된 음악을수용하고, 시스템 사용자가 주관적으로 경험하여 형성된 음악적 경험을 고려하여 제작된 음악에 대한 시스템 사용자의 평가 및/또는 음악 선호도에 관한 피드백을 상기 자동화된 음악 작곡 및 생성 시스템에 제공하는 단계;및(e) 상기 자동화된 음악 작곡 및 생성 시스템이 수용한 작곡된 음악을 선택된 미디어 또는 이벤트 마커와 조합하여, 분배 및 표시하기 위한 비디오 파일을 제작하는 단계를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_59", "content": "제58항에 있어서, 상기 시스템 사용자 인터페이스는 (i) 상기 시스템 인터페이스에 업로드하기 위한 비디오 선택과, (ii) 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 시스템을 기동할 수 있도록 하는 음악 작곡 전용옵션을 위한 인터페이스 객체를 표시하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_60", "content": "제58항에 있어서, 시스템 사용자가 GUI에서 \"비디오 선택\" 객체를 선택할 때, 시스템은 사용자가 로컬 포토 앨범, 클라우드에 호스팅된 공유 폴더 및 개인의 스마트 폰 카메라 롤로부터의 로컬 포토 앨범을 포함하는 서로다른 여러 로컬 및 원격 파일 저장 위치로부터 비디오 파일을 선택할 수 있도록 하는, 자동화된 음악 작곡 및생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_61", "content": "제58항에 있어서, 선택된 비디오는 스코어링을 위해 표시되는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_62", "content": "제58항에 있어서, 시스템 사용자가 찾는 음악적 경험을 선택하고 특징짓는 복수의 감정 클래스를 표시하기위해, 시스템 사용자는 음악 감정/음악 스타일/음악 스포팅 메뉴로부터 \"음악 감정\" 카테고리를 선택하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_63", "content": "제58항에 있어서, 선택된 비디오를 스코어링하기 위해 시스템 사용자가 찾는 음악적 경험을 선택하고 특징짓는많은 서로 다른 감정을 표시하기 위하여, 시스템 사용자는 음악 감정 메뉴로부터 음악 감정 카테고리를 선택하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_64", "content": "제58항에 있어서, 선택된 비디오를 스코어링하기 위해 시스템 사용자가 찾는 음악적 경험을 선택하고 특징짓는많은 서로 다른 스타일을 표시하기 위하여, 시스템 사용자는 음악 스타일 메뉴로부터 \"음악 스타일\" 카테고리를선택하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_65", "content": "제58항에 있어서, 음악 스포팅 기능 중에 시스템 사용자가 선택할 수 있는 명령 세트를 표시하기 위하여, 시스템 사용자는 음악 스포팅 메뉴로부터 \"음악 스포팅\" 카테고리를 선택하는, 자동화된 음악 작곡 및 생성 프로세스.공개특허 10-2018-0063163-14-청구항 66 제58항에 있어서, 음악 작곡이 생성되었고 선택된 비디오에 대한 미리 보기가 준비된 후, 시스템 사용자에게 음악 조각에 대해 설정된 음악적 경험 디스크립터를 편집하고 음악 작곡을 다시 컴파일하거나, 작곡되어 생성된음악 조각을 수용하고 오디오와 비디오를 믹싱하여 스코어링된 비디오 파일을 제작하는 옵션이 제공되는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_67", "content": "기업 수준 시스템에 의해 지원되는 자동화된 음악 작곡 및 생성 프로세스로서,(i) 시스템 사용자가 자동화된 음악 작곡 및 생성 엔진에 액세스한 다음, 상기 자동화된 음악 작곡 및 생성 엔진에 의해 생성된 음악으로 스코어링될 비디오, 오디오 레코딩, 슬라이드 쇼, 사진이나 이미지 또는 이벤트 마커를 선택하는 단계;(ii) 시스템 사용자가 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 상기 자동화된 음악 작곡 및생성 엔진에 제공하는 단계;(iii) 시스템 사용자가 자동화된 음악 작곡 및 생성 엔진을 기동하여 선택된 미디어 또는 이벤트 마커에 스코어링되어 있는 입력된 음악적 디스크립터에 기초하여 음악을 작곡 및 생성하는 단계;(iv) 시스템 사용자가 스코어링된 미디어 또는 이벤트 마커에 대해 제작된 작곡 및 생성된 음악을 수용하고, 시스템 사용자가 주관적으로 경험하여 형성된 음악적 경험을 고려하여 제작된 음악에 대한 시스템 사용자의 평가및/또는 음악 선호도에 관한 피드백을 시스템에 제공하는 단계; 및(v) 시스템이 수용한 작곡된 음악을 선택된 미디어 또는 이벤트 마커와 조합하여, 분배 및 표시하기 위한 비디오 파일을 제작하는 단계를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_68", "content": "사용자가 선택한 음악적 감정 및 스타일 디스크립터를 이용하여 생성되어 자동으로 작곡된 음악으로 증강된 텍스트, SMS 및 이메일 메시지를 사용자가 생성 및 전달할 수 있도록 하는 인터넷 기반의 자동화된 음악 작곡 및생성 시스템으로서,시스템 사용자 인터페이스와 인터넷 인프라에 작동 가능하게 연결된 자동화된 음악 작곡 및 생성 엔진; 및인터넷 상에서 지원되는 텍스트, SMS 및 이메일 서비스를 제공하는 복수의 모바일 및 데스크탑 클라이언트 머신을 포함하며,상기 각각의 클라이언트 머신은, 인터넷 인프라를 통해 다른 클라이언트 머신으로 전달하기 위한 텍스트, SMS및/또는 이메일 메시지에 내장되는 자동으로 작곡된 음악을 생성하기 위해, 자동으로 작곡된 음악이 내장되어증강된 텍스트, SMS 및 이메일 메시지를 경험하기 위해, 상기 자동화된 음악 작곡 및 생성 엔진에 제공된 음악적 감정 디스크립터 아이콘 및 음악적 스타일 디스크립터 아이콘을 선택함으로써 상기 자동화된 음악 작곡 및생성 엔진을 이용하여 사용자에 의해 자동으로 작곡된 음악을 추가함으로써 증강될 수 있는 텍스트 애플리케이션, SMS 애플리케이션 및 이메일 애플리케이션을 갖는, 인터넷 기반의 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_69", "content": "제68항에 있어서, 상기 모바일 클라이언트 머신은 터치 스크린 인터페이스, 메모리 아키텍처, 중앙처리장치, 인터페이스 회로 및 다양한 통신 프로토콜을 지원하는 네트워크 어댑터를 가진 인터넷이 가능한 스마트 폰 및 태블릿 컴퓨터로 이루어진 군으로부터 선택되는, 인터넷 기반의 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_70", "content": "제68항에 있어서, 제1 클라이언트 애플리케이션이 상기 각각의 클라이언트 머신에서 가동하며, 텍스트 또는 SMS메시지의 생성과, 상기 제1 클라이언트 애플리케이션에 의해 지원되는 제1 메뉴 스크린으로부터 언어 및/또는그래픽 아이콘 기반 감정 디스크립터 및 스타일 디스크립터를 선택함으로써 그 내부에 생성된 자동으로 작곡된음악 조각의 생성 및 삽입을 지원하는 가상 키보드를 시스템 사용자에게 제공하는, 인터넷 기반의 자동화된 음악 작곡 및 생성 시스템.공개특허 10-2018-0063163-15-청구항 71 제68항에 있어서, 제2 클라이언트 애플리케이션이 상기 각각의 클라이언트 머신에서 가동하며, 이메일 문서의생성과, 상기 제2 클라이언트 애플리케이션에 의해 지원되는 제2 메뉴 스크린으로부터 언어 및/또는 그래픽 아이콘 기반 감정 디스크립터 및 스타일 타입 디스크립터를 선택하는 사용자에 의해 그 내부에 생성된 자동으로작곡된 음악 조각의 생성 및 내장을 지원하는 가상 키보드를 시스템 사용자에게 제공하는, 인터넷 기반의 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_72", "content": "제68항에 있어서, 상기 클라이언트 머신은 터치 스크린 인터페이스, 메모리 아키텍처, 프로세서, 인터페이스 회로 및 다양한 통신 프로토콜을 지원하는 네트워크 어댑터를 가진 모바일 컴퓨팅 머신으로서 실현되고, 상기 모바일 컴퓨팅 머신에서 가동하는 클라이언트 애플리케이션은 마이크로소프트 워드, PDF 또는 이미지(예컨대, jpg또는 tiff) 문서의 생성과, 상기 클라이언트 애플리케이션에 의해 지원되는 메뉴 스크린으로부터 언어 및/또는그래픽 아이콘 기반 음악 감정 디스크립터 및 음악 스타일 디스크립터를 선택하는 시스템 사용자에 의해 생성된자동 작곡 음악 조각의 생성 및 삽입을 지원하는 가상 키보드를 사용자에게 제공하는, 인터넷 기반의 자동화된음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_73", "content": "제68항에 있어서, 상기 클라이언트 머신은 터치 스크린 인터페이스, 메모리 아키텍처, 중앙처리장치, 그래픽 프로세서, 인터페이스 회로, 다양한 통신 프로토콜을 지원하는 네트워크 어댑터를 가진 모바일 컴퓨팅 머신으로서실현되고, 제2 클라이언트 애플리케이션이 가동하여, 웹 기반(즉, html) 문서의 생성과, 상기 제2 클라이언트애플리케이션에 의해 지원되는 메뉴 스크린으로부터 언어 및/또는 그래픽 아이콘 기반 감정 디스크립터 및 스타일 디스크립터를 선택함으로써 생성된 자동 작곡 음악 조각의 생성 및 삽입을 지원하는 가상 키보드를 사용자에게 제공하며, 이에 따라, 음악 조각이 내장된 URL 상에서 동작하는 통상의 웹 브라우저를 사용하여 원격 클라이언트에게 전달되어 경험될 수 있고, 이로부터 내장된 음악 조각이 웹, 애플리케이션 및 데이터베이스 서버를 통해 서비스되는, 인터넷 기반의 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_74", "content": "자동화된 음악 작곡 및 생성 시스템으로서, 자동화된 음악 작곡 및 생성 엔진을 사용하여 사용자에 의해 작곡된음악을 추가함으로써 인터넷 상에서 지원되는 텍스트, SMS 및 이메일 서비스를 사용하여 모바일 및 데스크탑 클라이언트 머신이 증강되도록 배치된 인터넷 기반의 자동화된 음악 작곡 및 생성 플랫폼과, 이와 같은 텍스트,SMS 및 이메일 메시지를 위한 작곡 음악 조각을 생성하는 데 사용하기 위해 사용자가 그래픽 및/또는 언어 기반감정 및 스타일 디스크립터를 쉽게 선택할 수 있도록 텍스트, SMS 및/또는 이메일 메시지를 제작할 때 클라이언트 머신에 의해 지원되는 그래픽 사용자 인터페이스를 포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_75", "content": "자동으로 작곡된 음악 조각을 생성 및 전달하기 위한 시스템 네트워크로서,언어 또는 아이콘 기반 음악적 경험 디스크립터에 기초하여 음악을 자동으로 작곡 및 생성하기 위해 인터넷 인프라에 작동 가능하게 연결된 자동화된 음악 작곡 및 생성 엔진;상기 자동화된 음악 작곡 및 생성 엔진에 의해 자동으로 작곡 및 생성된 음악 조각이 문서에 내장되어 연주될수 있도록, 상기 자동화된 음악 작곡 및 생성 엔진과 인터넷 인프라에 작동 가능하게 연결된 복수의 통신, 애플리케이션 및 데이터베이스 서버; 및상기 자동화된 음악 작곡 및 생성 엔진에 의해 자동으로 작곡 및 생성된 음악 조각이 내장된 문서를 표시하기위해 인터넷 인프라에 작동 가능하게 연결된 복수의 웹 이용가능한 모바일 클라이언트 머신을 포함하며,상기 각각의 모바일 클라이언트 머신은 터치 스크린 인터페이스, 메모리 아키텍처, 중앙처리장치 및 무선 통신프로토콜을 지원하는 무선 네트워크 어댑터를 가진 컴퓨팅 플랫폼을 포함하고,상기 클라이언트 머신은 애플리케이션을 포함하며, 애플리케이션은 가동될 때 메뉴 스크린으로부터 언어 및/또는 그래픽 아이콘 기반 감정 디스크립터 및 스타일 디스크립터를 선택함으로써 생성된 작곡 음악 조각의 생성공개특허 10-2018-0063163-16-및 삽입을 지원하는 가상 키보드를 사용자에게 제공하며, 이에 따라, 음악 조각이 원격 클라이언트 머신에게 전달되는 문서에 내장되어 다른 시스템 사용자에 의해 경험될 수 있는, 시스템 네트워크."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_76", "content": "인터넷 기반의 자동화된 음악 작곡 및 생성 시스템으로서,언어 또는 아이콘 기반 음악적 경험 디스크립터에 기초하여 음악을 자동으로 작곡 및 생성하기 위해 인터넷 인프라에 작동가능하게 연결된 자동화된 음악 작곡 및 생성 엔진;상기 자동화된 음악 작곡 및 생성 엔진에 의해 자동으로 작곡 및 생성된 음악 조각이 문서에 내장되어 연주될수 있도록, 상기 자동화된 음악 작곡 및 생성 엔진과 인터넷 인프라에 작동가능하게 연결된 복수의 통신, 애플리케이션 및 데이터베이스 서버를 포함하고,상기 클라이언트 머신은 애플리케이션을 포함하며, 애플리케이션은 가동될 때 (i) 메뉴 스크린으로부터 언어 및/또는 그래픽 아이콘 기반 감정 디스크립터 및 스타일 디스크립터를 선택함으로써 생성된 작곡 음악 조각의 생성과, (ii) 텍스트, SMS 및 이메일 문서 또는 메시지에 자동으로 작곡된 음악 조각의 내장을 지원하는 가상 키보드를 사용자에게 제공하며, 이에 따라, 상기 텍스트, SMS 및 이메일 문서 또는 메시지가 내장된 음악 조각과함께 원격 클라이언트 머신에게 전달되어 다른 시스템 사용자에 의해 경험될 수 있는, 인터넷 기반의 자동화된음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_77", "content": "음악적으로 스코어링된 텍스트, SMS, 이메일, PDF, 워드 및/또는 html 문서를 자동적이고 즉각적으로 생성하기위해 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 자동화된 가상 악기 음악 합성의 사용을 지원하는 웹 기반 시스템을 사용한 자동화된 음악 작곡 및 생성 프로세스로서,(i) 시스템 사용자가 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 자동화된 음악 작곡 및 생성 시스템에 의해 생성된 음악으로 스코어링될(예컨대, 증강될) 텍스트, SMS 또는 이메일 메시지 또는 워드, PDF 또는HTML 문서를 선택하는 단계;(ii) 시스템 사용자가 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 자동화된 음악 작곡 및 생성시스템에 제공하는 단계;(iii) 시스템 사용자가 자동화된 음악 작곡 및 생성 시스템을 기동하여 선택된 메시지 또는 문서에 스코어링되어 있는 입력된 음악적 디스크립터에 기초한 음악을 작곡 및 생성하는 단계;(iv) 시스템 사용자가 메시지 또는 문서에 대해 제작된 작곡 및 생성된 음악을 수용하거나, 음악을 거부하고 다른 음악적 경험 디스크립터의 제공 및 갱신된 음악적 경험 디스크립터 입력에 기초하여 음악을 재작곡하도록 하는 요구를 포함한 피드백을 시스템에 제공하는 단계; 및(v) 수용한 작곡된 음악을 메시지 또는 문서와 조합하여, 분배 및 표시하기 위한 새로운 파일을 제작하는 단계를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_78", "content": "음악적으로 스코어링된 텍스트, SMS, 이메일, PDF, 워드 및/또는 html 문서를 작성하기 위해 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 자동화된 음악 작곡 및 생성 프로세스로서,(a) 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 엔진에 액세스하는 단계;(b) 상기 자동화된 음악 작곡 및 생성 엔진에 의해 생성된 음악으로 스코어링될 텍스트, SMS 또는 이메일 메시지 또는 워드, PDF 또는 HTML 문서를 선택하는 단계;(ii) 시스템 사용자가 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 상기 자동화된 음악 작곡 및생성 엔진에 제공하는 단계;(iii) 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 엔진을 기동하여 선택된 메시지 또는 문서에 스코어링되어 있는 입력된 음악적 디스크립터에 기초한 음악을 작곡 및 생성하는 단계;(iv) 시스템 사용자가 메시지 또는 문서에 대해 제작된 작곡 및 생성된 음악을 수용하거나, 음악을 거부하고 다공개특허 10-2018-0063163-17-른 음악적 경험 디스크립터의 제공 및 갱신된 음악적 경험 디스크립터 입력에 기초하여 음악을 재작곡하도록 하는 요구를 포함한 피드백을 상기 자동화된 음악 작곡 및 생성 엔진에 제공하는 단계; 및(v) 수용한 작곡된 음악을 메시지 또는 문서와 조합하여, 분배 및 표시하기 위한 새로운 파일을 제작하는 단계를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_79", "content": "인공 지능 기반(AI 기반) 자율 음악 작곡 및 연주 시스템으로서,(i) 인간 음악가 그룹에 의해 연주되고 있는 실제 또는 합성 음악 악기 세트로부터 음악 신호를 수신하거나,(ii) 상기 실제 또는 합성 음악 악기 세트로부터의 상기 음악 신호를 버퍼링 및 분석하거나,(iii) 음악가 밴드에 의해 연주되고 있는 음악을 증강하는 음악을 실시간으로 작곡 및 생성하거나,(iv) 상기 인간 음악가에 의한 후속 재생, 검토 및 심의를 위해 기록되는 음악을 녹음, 분석 및 작곡하도록 구성된 자동화된 음악 작곡 및 생성 엔진;상기 자동화된 음악 작곡 및 생성 엔진을 수납하는 휴대용 하우징으로서,그래픽 아이콘을 선택하고 그래픽 정보를 검토하기 위한 터치 타입 디스플레이 스크린;상기 음악 악기 세트로부터 생성되는 전기 신호를 수신하기 위한 제1 오디오 신호 입력 커넥터 세트;하나 이상의 마이크로부터 생성되는 전기 신호를 수신하기 위한 제2 오디오 신호 입력 커넥터 세트;시스템 환경 내의 악기 세트로부터 MIDI 입력 신호를 수신하기 위한 MIDI 신호 입력 커넥터 세트;오디오 출력 신호를 오디오 신호 전치 증폭기 및/또는 증폭기로 전달하기 위한 오디오 출력 신호 커넥터;무선 네트워크 어댑터 및 관련 신호 안테나 구조; 및사용자 작동 모드를 선택하기 위한 기능 버튼 세트를 더 포함하는, 휴대용 하우징을 포함하며,상기 사용자 작동 모드는,(i) 상기 AI 기반 자율 음악 작곡 및 연주 시스템이 음악 세션 중에 그 음악 환경으로부터 수신하여 분석한 음악 정보 스트림에 응답하여 음악적으로 자율적으로 선도하는 LEAD 모드;(ii) 상기 AI 기반 자율 음악 작곡 및 연주 시스템이 음악 세션 중에 그 음악 환경 내의 음악 악기로부터 수신하여 분석한 음악에 응답하여 음악적으로 자율적으로 추종하는 FOLLOW 모드;(iii) 상기 AI 기반 자율 음악 작곡 및 연주 시스템이 음악 세션 중에 그 환경 내의 음악 악기로부터 수신하여분석한 음악에 기초하여 음악을 자동으로 작곡하는 COMPOSE 모드; 및(iv) 상기 AI 기반 자율 음악 작곡 및 연주 시스템이 음악 세션 중에 그 환경으로부터 수신하여 분석한 음악 정보에 응답하여 자동으로 작곡된 음악을 실시간으로 자율적으로 연주하는 PERFORM 모드 중 둘 이상의 모드를 포함하는, AI 기반 자율 음악 작곡 및 연주 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_80", "content": "AI 기반 자율 음악 작곡 및 작곡 연주 시스템으로서,자동화된 음악 작곡 및 생성 엔진을 포함하며,상기 AI 기반 시스템은 그 주변 악기와 음악가로부터 음악 신호를 수신하여 이들 악기를 버퍼링 및 분석하고,이에 응답하여, 음악가 밴드에 의해 연주되고 있는 음악을 증강하게 될 음악을 실시간으로 작곡 및 생성할 수있거나, 인간 음악가에 의한 후속 재생, 검토 및 심의를 위해 기록되는 음악을 녹음, 분석 및 작곡할 수 있는,AI 기반 자율 음악 작곡 및 작곡 연주 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_81", "content": "상기 자동화된 음악 작곡 및 생성 엔진의 변형된 버전을 채택하여 실제 및/또는 합성 음악 악기 세트를 연주하는 인간 음악가 밴드에서 사용하기 위한 인공 지능(AI) 기반 자율 음악 작곡, 생성 및 연주 시스템으로서, AI공개특허 10-2018-0063163-18-기반 시스템은 그 주변 악기 및 음악가로부터 음악 신호를 수신하여 이들 악기를 버퍼링 및 분석하고, 이에 응답하여, 음악가 밴드에 의해 연주되고 있는 음악을 증강하게 될 음악을 실시간으로 작곡 및 생성할 수 있거나,인간 음악가에 의한 후속 재생, 검토 및 심의를 위해 기록되는 음악을 녹음, 분석 및 작곡할 수 있는, AI 기반자율 음악 작곡, 생성 및 연주 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_82", "content": "자율 음악 분석, 작곡 및 연주 악기 시스템으로서,터치 타입 디스플레이 스크린;시스템 환경 내의 음악 악기 세트로부터 생성되는 오디오 신호를 수신하기 위한 오디오 신호 입력 커넥터 세트;시스템 환경 내의 악기 세트로부터 MIDI 입력 신호를 수신하기 위한 MIDI 신호 입력 커넥터 세트;오디오 출력 신호를 전달하기 위한 오디오 출력 신호 커넥터;무선 네트워크 어댑터 및 관련 신호 안테나 구조; 및사용자 작동 모드를 위한 기능 버튼 세트를 지원하는, 콤팩트한 휴대용 하우징을 포함하며,상기 사용자 작동 모드는,(i) 상기 자율 음악 분석, 작곡 및 연주 악기 시스템이 음악 세션 중에 그(로컬 또는 원격) 음악 환경으로부터수신하여 분석한 음악 정보 스트림에 응답하여 음악적으로 자율적으로 선도하는 LEAD 모드;(ii) 상기 자율 음악 분석, 작곡 및 연주 악기 시스템이 음악 세션 중에 그(로컬 또는 원격) 음악 환경 내의 음악 악기로부터 수신하여 분석한 음악에 응답하여 음악적으로 자율적으로 추종하는 FOLLOW 모드;(iii) 상기 자율 음악 분석, 작곡 및 연주 악기 시스템이 음악 세션 중에 그(로컬 또는 원격) 환경 내의 음악악기로부터 수신하여 분석한 음악에 기초하여 음악을 자동으로 작곡하는 COMPOSE 모드; 및(iv) 상기 자율 음악 분석, 작곡 및 연주 악기 시스템이 음악 세션 중에 그 환경으로부터 수신하여 분석한 음악정보에 응답하여 자동으로 작곡된 음악을 실시간으로 자율적으로 연주하는 PERFORM 모드 중 둘 이상의 모드를포함하는, 자율 음악 분석, 작곡 및 연주 악기 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_83", "content": "제82항에 있어서,(i) 세션에 앞서, 시스템 사용자는 상기 자동화된 음악 작곡 및 생성 악기 시스템에 대해 LEAD 또는 FOLLOW 작동 모드 중 하나를 선택하고;(ii) 그 다음, 세션에 앞서, 상기 자율 음악 분석, 작곡 및 연주 악기 시스템은 음악 세션 중의 창조적 환경에서 음악가 그룹에 의해 연주되는 음악 악기 그룹과 인터페이스되며;(iii) 세션 중에, 시스템은 세션 중에 악기 그룹으로부터 생성된 오디오 및/또는 MIDI 데이터 신호를 수신하고,이 신호들을 피치 데이터 및 멜로디 구조에 대하여 분석하며;(iv) 세션 중에, 상기 자율 음악 분석, 작곡 및 연주 악기 시스템은 요약된 피치 및 멜로디 데이터로부터 음악적 디스크립터를 자동으로 생성하고, 음악적 경험 디스크립터를 사용하여 실시간 단위로 세션을 위한 음악을 작곡하며;(v) PERFORM 모드가 선택된 경우, 상기 자율 음악 분석, 작곡 및 연주 악기 시스템은 작곡된 음악을 생성하고,COMPOSE 모드가 선택된 경우, 세션 중에 작곡된 음악이 음악가 그룹에 의한 후속 액세스 및 검토를 위해 저장되는, 자율 음악 분석, 작곡 및 연주 악기 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_84", "content": "자율 음악 분석, 작곡 및 연주 악기 시스템으로서,음악 악기 세트로부터 생성된 MIDI 입력 신호뿐만 아니라 오디오 신호를 수신하기 위한 입력 포트; 및이 신호들을 피치 이벤트의 발생 및 멜로디 구조에 대하여 시간 및/또는 주파수 도메인에서 실시간으로 분석함공개특허 10-2018-0063163-19-으로써, 시스템이 자동화된 음악 작곡 및 생성 엔진을 이용한 자동화된 음악 작곡 및 생성의 생성에 사용하기위해 이 정보로부터 음악적 경험 디스크립터를 자동으로 요약할 수 있도록 하는, 신호 분석기를 포함하는, 자율음악 분석, 작곡 및 연주 악기 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_85", "content": "제84항에 있어서, 상기 신호 분석기는 시스템 버스 아키텍처를 포함하며, 상기 시스템 버스 아키텍처와 집적된CPU, 프로그램 메모리(DRAM) 및 비디오 메모리(VRAM)를 포함하는, 자율 음악 분석, 작곡 및 연주 악기 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_86", "content": "음악 작곡 프로세스를 지원하는 자동화된 음악 작곡 및 생성 시스템으로서,(a) 감정 및 스타일 타입 음악적 경험 디스크립터의 수신에 응답하여 자동으로 작곡된 음악 조각의 음악 스코어표현을 자동으로 생성하는 단계; 및(b) 다른 사람들의 즐거움을 위해 자동으로 작곡된 음악을 제작하는 하나 이상의 MIDI 기반 음악 악기를 구동및 제어하기 위하여 그와 같은 표현을 MIDI 제어 신호로 변환하는 단계를 포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_87", "content": "상위 음악적 랜드스케이프 조직을 가진 자동화된 음악 작곡 및 생성 시스템으로서,시스템 사용자 GUI 기반 입력 서브 시스템(A0);피치 랜드스케이프 서브 시스템(C0)으로서,작곡되고 있는 음악 조각을 위한 화음(즉, 피치 이벤트)을 생성하는 일반 피치 생성 서브 시스템(A2);작곡되고 있는 음악 조각을 위한 멜로디 피치를 생성하는 멜로디 피치 생성 서브 시스템(A4)으로서,상기 멜로디 피치는 독립적으로 또는 다른 이벤트와 협력하여 작곡되고 있는 음악 조각의 멜로디 및/또는 임의의 멜로디 재료의 일부를 구성하는 모든 이벤트의 공간 내의 배열을 음악 조각 내에서 포함하는, 멜로디 피치생성 서브 시스템(A4);작곡되고 있는 음악 조각을 위한 오케스트레이션을 생성하는 오케스트레이션 서브 시스템(A5); 및컨트롤러 코드 제작 서브 시스템(A6)을 포함하며,상기 피치 랜드스케이프는 음악 조각 내에서 모든 이벤트의 공간 내의 배열을 포함하고,상기 이벤트는 항상 그와 같은 것은 아니지만 흔히음악 조각의 키 및 조성에 의해 상위에서음악 조각의 구조, 형태 및 악절에 의해 중위에서, 그리고각각의 악기, 참가자 및/또는 음악 조각의 다른 구성 요소의 이벤트의 특정 조직에 의해 하위에서 조직되는, 피치 랜드스케이프 서브 시스템(C0);리듬 랜드스케이프 서브 시스템(C1)으로서,작곡될 음악 조각을 위한 일반 리듬을 생성하는 일반 리듬 생성 서브 시스템(A1);작곡되고 있는 음악 조각을 위한 멜로디 리듬를 생성하는 멜로디 리듬 생성 서브 시스템(A3);작곡되고 있는 음악 조각을 위한 오케스트레이션을 생성하는 상기 오케스트레이션 서브 시스템(A5)으로서,작곡되고 있는 음악 조각을 위한 상기 오케스트레이션은 음악 조각의 조작, 배열 및/또는 적응을 설명하는, 오케스트레이션 서브 시스템(A5);작곡되고 있는 음악 조각을 위한 컨트롤러 코드를 제작하는 상기 컨트롤러 코드 제작 서브 시스템(A6)으로서,작곡되고 있는 음악 조각을 위한 상기 컨트롤러 코드는 실제 음표, 리듬 및 악기 편성에서 흔히 분리된 음악적공개특허 10-2018-0063163-20-표현에 관한 정보를 설명하는, 컨트롤러 코드 제작 서브 시스템(A6)을 포함하며,상기 리듬 랜드스케이프(C1)는 음악 조각 내에서 모든 이벤트의 시간 내의 배열을 포함하고,상기 이벤트는 항상 그러한 것은 아니지만 흔히음악 조각의 템포, 박자 및 길이에 의해 상위에서,음악 조각의 구조, 형태 및 악절에 의해 중위에서, 그리고각각의 악기, 참가자 및/또는 음악 조각의 다른 구성 요소의 이벤트의 특정 조직에 의해 하위에서 조직되는, 리듬 랜드스케이프 서브 시스템(C1);작곡되고 있는 디지털 음악 조각을 제작하는 디지털 조각 제작 서브 시스템(A7)으로서,상기 작곡되고 있는 디지털 음악 조각은 오직 아날로그 방식만이 아니라 디지털이나 디지털과 아날로그 조합에의한 음악 조각의 표현을 설명하는, 디지털 조각 제작 서브 시스템(A7); 및자동으로 작곡된 음악 조각을 검토한 시스템 사용자의 선호도가 추후 음악 조각의 자동화된 작곡에서 이용되는,시스템의 피드백 및 학습 사이클을 지원하는 피드백 및 학습 서브 시스템(A8)을 포함하는, 자동화된 음악 작곡및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_88", "content": "제87항에 있어서, 상기 GUI 기반 입력 서브 시스템(A0)은 사용자 GUI 기반 입출력 서브 시스템(B0); 디스크립터파라미터 포착 서브 시스템(B1); 파라미터 변환 엔진 서브 시스템(B51); 스타일 파라미터 포착 서브 시스템(B37); 및 타이밍 파라미터 포착 서브 시스템(B40)을 포함하고; 상기 서브 시스템들은 시스템 사용자를 통해 또는 종단 시스템 애플리케이션에 의해 요구되는 다른 수단 및 방식을 통해 시스템(A0)에 제공된 모든 음악적 경험 파라미터(예컨대, 감정 디스크립터, 스타일 디스크립터 및 타이밍/공간 디스크립터)를 수신 및프로세싱하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_89", "content": "제87항에 있어서, 상기 일반 리듬 생성 서브 시스템(A1)은 길이 생성 서브 시스템(B2); 템포 생성 서브 시스템(B3); 박자 생성 서브 시스템(B4); 비트 계산기 서브 시스템(B6); 마디 계산기 서브 시스템(B8); 노래 형태 생성 서브 시스템(B9); 하위 악절 길이 생성 서브 시스템(B15); 하위 악절 내 화음 수 계산기 서브 시스템(B16);악절 길이 생성 서브 시스템(B12); 특이 악절 생성 서브 시스템(B10); 악절 내 화음 수 계산기 서브 시스템(B13); 화음 길이 생성 서브 시스템(B11); 특이 하위 악절 생성 서브 시스템(B14); 악기 편성 서브 시스템(B38); 악기 선택기 서브 시스템(B39); 및 타이밍 생성 서브 시스템(B41)을 포함하는, 자동화된 음악 작곡 및생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_90", "content": "제87항에 있어서, 작곡되고 있는 음악 조각을 위한 화음(즉, 피치 이벤트)을 생성하는 상기 일반 피치 생성 서브 시스템(A2)은 키 생성 서브 시스템(B5); 조성 생성 서브 시스템(B7); 제1 일반 리듬 생성 서브 시스템(B17);하위 악절 화음 진행 생성 서브 시스템(B19); 악절 화음 진행 생성 서브 시스템(B18); 화음 자리바꿈 생성 서브시스템(B20); 악기 편성 서브 시스템(B38); 및 악기 선택기 서브 시스템(B39)을 포함하는, 자동화된 음악 작곡및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_91", "content": "제87항에 있어서, 상기 멜로디 리듬 생성 서브 시스템(A3)은 멜로디 하위 악절 길이 생성 서브 시스템(B25); 멜로디 하위 악절 생성 서브 시스템(B24); 멜로디 악절 길이 생성 서브 시스템(B23); 멜로디 특이 악절 생성 서브시스템(B22); 멜로디 길이 생성 서브 시스템(B21); 및 멜로디 음표 리듬 생성 서브 시스템(B26)을 포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_92", "content": "제87항에 있어서, 상기 멜로디 피치 생성 서브 시스템(A4)은 제1 피치 생성 서브 시스템(B27); 하위 악절 피치생성 서브 시스템(B29); 악절 피치 생성 서브 시스템(B28); 및 피치 옥타브 생성 서브 시스템(B30)을 포함하는,공개특허 10-2018-0063163-21-자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_93", "content": "제87항에 있어서, 상기 오케스트레이션 서브 시스템(A5)은 오케스트레이션 생성 서브 시스템(B31)을 포함하는,자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_94", "content": "제87항에 있어서, 상기 컨트롤러 코드 제작 서브 시스템(A6)은 컨트롤러 코드 생성 서브 시스템(B32)을 포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_95", "content": "제87항에 있어서, 상기 디지털 조각 제작 서브 시스템(A7)은 디지털 오디오 샘플 오디오 검색기 서브 시스템(B33); 디지털 오디오 샘플 조직기 서브 시스템(B34); 조각 통합기 서브 시스템(B35); 조각 포맷 번역기 서브시스템(B50); 및 조각 전달기 서브 시스템(B36)을 포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_96", "content": "제87항에 있어서, 상기 피드백 및 학습 서브 시스템(A8)은 피드백 서브 시스템(B42); 음악 편집성 서브 시스템(B43); 선호도 저장기 서브 시스템(B44); 음악적 커널 서브 시스템(B45); 사용자 취향 서브 시스템(B46); 모집단 취향 서브 시스템(B47); 사용자 선호도 서브 시스템(B48); 및 모집단 선호도 서브 시스템(B49)을 포함하는,자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_97", "content": "제87항에 있어서, 상기 시스템 사용자는 터치 스크린, 키보드 및 마이크 음성 인식 인터페이스 중 하나 이상을지원하는 상기 GUI 기반 입출력 서브 시스템(B0)에 감정, 스타일 및 타이밍 타입 음악적 경험 디스크립터와 같은 입력을 제공하며;GUI 기반 입출력 서브 시스템(B0)으로부터 나온 다양한 데이터 신호 출력이 상기 디스크립터 파라미터 포착 서브 시스템(B1), 상기 파라미터 변환 엔진 서브 시스템(B51), 상기 스타일 파라미터 포착 서브 시스템(B37) 및상기 타이밍 파라미터 포착 서브 시스템(B40)에 입력 데이터 신호로서 제공되고;상기 디스크립터 파라미터 포착 서브 시스템(B1)은 단어, 이미지 및/또는 작곡될 음악 조각에 의해 제작되는 음악적 경험의 다른 표현을 수신하고, 그 다음, 포착된 이 감정 타입 음악적 경험 파라미터들은 다른 서브 시스템으로의 후속 전송을 위해 저장되며;상기 스타일 파라미터 포착 서브 시스템(B17)은 단어, 이미지 및/또는 작곡될 음악 조각에 의해 제작되는 음악적 경험의 다른 표현을 수신하고, 그 다음, 포착된 이 스타일 타입 음악적 경험 파라미터들은 다른 서브 시스템으로의 후속 전송을 위해 저장되며;음악 스포팅이 시스템 사용자에 의해 활성화되거나 액세스되고, 타이밍 파라미터가 상기 입력 서브 시스템(B0)으로 전송되는 경우, 상기 타이밍 파라미터 포착 서브 시스템(B40)은 그와 같은 기능성을 지원하기 위해 다른서브 시스템(예컨대, 서브 시스템(A1, A2 등))을 활성화할 것인, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_98", "content": "제88항에 있어서, 상기 파라미터 변환 엔진 서브 시스템(B51)은 단어, 이미지 및/또는 작곡될 음악 조각에 의해제작되는 음악적 경험 파라미터의 다른 표현을 수신하고, 이 감정 타입, 스타일 타입 및 타이밍 타입 음악적 경험 파라미터들은 각 서브 시스템으로의 후속 분배 및 로드를 위해 제공된 시스템 사용자 입력에 기초하여 확률기반 시스템 작동 파라미터(SOP) 테이블 세트를 생성하기 위해 엔진 서브 시스템(B51)에 의해 변환되는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_99", "content": "자동화된 음악 작곡 및 생성 엔진을 구성하기 위한 네트워크로서, 상기 네트워크는,자동화된 음악 작곡 및 생성 엔진에 작동 가능하게 연결된 하나 이상의 원격 시스템 설계자 클라이언트 워크스공개특허 10-2018-0063163-22-테이션으로서,(i) 파라미터 변환 엔진 서브 시스템 및(ii) 관련 파라미터 테이블 아카이브 데이터베이스 서브 시스템을 가진, 하나 이상의 원격 시스템 설계자 클라이언트 워크스테이션을 포함하며,각각의 워크스테이션 클라이언트 시스템은 상기 파라미터 변환 엔진 서브 시스템 내에서의 파라미터 매핑 구성(PMC)의 생성 및 관리를 위해 GUI 기반 작업 환경을 지원하며,전세계 어디든 원격 위치한 상기 각각의 시스템 설계자는 상기 자동화된 음악 작곡 및 생성 엔진이 연결된 시스템 네트워크에 로그인하여 GUI 기반 작업 환경에 액세스하고,(i) 시스템 사용자에 의해 선택될 수 있는 감정 타입, 스타일 타입 및 타이밍/공간 파라미터의 서로 다른 가능한 세트와(ii) 상기 파라미터 변환 엔진 서브 시스템 및 상기 관련 파라미터 테이블 아카이브 데이터베이스 서브 시스템내에서의 영구 저장을 위해, 바람직하게는 파라미터 테이블 내에 유지되는 대응하는 음악 이론 시스템 작동 파라미터 세트(SOPs) 사이의 파라미터 매핑 구성(PMCs)을 생성하는, 네트워크."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_100", "content": "파라미터 변환 엔진 서브 시스템과 복수의 파라미터 채택 서브 시스템을 포함하는 자동화된 음악 작곡 및 생성시스템에서의 파라미터 관리 방법으로서,(a) 상기 파라미터 변환 엔진 서브 시스템의 영구 저장소에 생성되어 로드되어 있는 현재 생성된 파라미터 매핑구성 리스트로부터 선택된, 상기 파라미터 변환 엔진 서브 시스템 내의 기존 파라미터 매핑 구성을 관리하는 단계; 및/또는(b) 상기 자동화된 음악 작곡 및 생성 시스템에 채택된 상기 서브 시스템 내에서의 생성 및 로드를 위해, (i)시스템 사용자에 의해 선택될 수 있는 감정/스타일/타이밍 파라미터의 가능한 세트와 (ii) 대응하는 음악 이론시스템 작동 파라미터(SOP) 테이블(들) 세트 사이의 파라미터 매핑 구성을 생성하는 데 사용하기 위해 그래픽사용자 인터페이스(GUI)를 적어도 하나의 시스템 설계자에게 제시함으로써 상기 파라미터 변환 엔진 서브 시스템의 영구 저장소에 로드하기 위한 새로운 파라미터 매핑 구성을 생성하는 단계를 포함하는, 파라미터 관리 방법."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_101", "content": "자동화된 음악 작곡 및 생성 시스템으로서,키보드 및/또는 음성 인식 인터페이스를 사용하여 생성된 언어 기반 음악적 경험 디스크립터 및 가사 단어 디스크립터를 수신하는 시스템 사용자 인터페이스;상기 가사 단어 디스크립터를 분석하여 대응하는 피치 이벤트를 생성하는 실시간 피치 이벤트 분석 서브시스템; 및상기 시스템 사용자 인터페이스와 상기 실시간 피치 이벤트 분석 서브 시스템에 작동 가능하게 연결된 자동화된음악 작곡 엔진을 포함하며,상기 언어 기반 음악적 경험 디스크립터 및/또는 피치 이벤트는 음악 조각을 자동으로 작곡 및 생성하여 상기음악 조각으로 미디어 또는 이벤트 마커를 감정적으로 스코어링하기 위해 상기 자동화된 음악 작곡 엔진에 의해사용되는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_102", "content": "제101항에 있어서, 상기 미디어는 비디오 레코딩, 슬라이드 쇼, 오디오 레코딩 또는 이벤트 마커로 이루어진 군으로부터 선택된, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_103", "content": "제101항에 있어서, 상기 자동화된 음악 작곡 및 생성 시스템은 장면 이미지 및/또는 정보 콘텐츠에 기초하여 음공개특허 10-2018-0063163-23-악적 경험 디스크립터를 추출하며, 그 후, 상기 음악적 경험 디스크립터는 음악적으로 스코어링된 미디어, 음악파일 및/또는 하드카피 시트 뮤직을 생성하기 위해 상기 자동화된 음악 작곡 및 생성 시스템에 의해 사용되는,자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_104", "content": "제101항에 있어서, 상기 시스템 사용자 인터페이스는 시스템 사용자에 의해 제공된 타이핑되거나, 말로 전해지거나, 노래 불려진 대사 또는 가사 입력의 상기 실시간 피치 이벤트 분석 서브 시스템으로의 전송을 더 포함하며, 실시간 피치 이벤트, 리듬 및 운율 분석이 실시되어 음악 작곡 및 생성 프로세스 중에 상기 자동화된 음악작곡 및 생성 시스템에서 음악을 작곡 및 생성하기 위해 각각 후속 사용되는 타이핑되고, 말로 전해지고 노래불려진 가사에 대한 서로 다른 피치 이벤트 스트림을 생성시키는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_105", "content": "제101항에 있어서, 상기 실시간 피치 이벤트 분석 서브 시스템은 가사 입력 핸들러; 피치 이벤트 출력 핸들러;어휘 사전; 및 모음 포맷 분석기; 및 모드 컨트롤러를 포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_106", "content": "자동화된 음악 작곡 및 생성 시스템에 시스템 사용자에 의해 제공된 가사 입력을 이용하여 자동화된 방식으로음악을 작곡 및 생성하는 방법으로서,(a) 자동화된 음악 작곡 및 생성 시스템의 시스템 사용자 인터페이스에 음악적 경험 디스크립터를 제공하는 단계;(b) 상기 자동화된 음악 작곡 및 생성 시스템에 의해 작곡 및 생성된 음악으로 스코어링될 비디오 또는 미디어객체의 하나 이상의 장면을 위해, 상기 자동화된 음악 작곡 및 생성 시스템의 시스템 사용자 인터페이스에 타이핑되거나, 말로 전해지거나 또는 노래 불려진 포맷으로 표현된 가사 입력을 제공하는 단계;(c) 시간 및/또는 주파수 도메인 기술에 기초하여, 타이핑되거나/말로 전해지거나/노래 불려진 가사의 실시간리듬, 피치 이벤트 및 운율 분석을 이용하여, 시스템 사용자 인터페이스에 제공된 가사 입력을 프로세싱하는 단계;(d) 분석된 가사 입력으로부터 타임라인에서의 피치 이벤트 및 그와 같은 검출된 피치 이벤트가 발생한 타이밍정보를 가진 코드를 추출하는 단계; 및(e) 상기 자동화된 음악 작곡 및 생성 시스템의 다양한 서브 시스템에 채택된 확률 기반 파라미터 테이블을 제한하는 데 사용하기 위해 상기 자동화된 음악 작곡 및 생성 시스템에 추출된 피치 이벤트를 제공하는 단계를 포함하는, 자동화된 방식으로 음악을 작곡 및 생성하는 방법."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_107", "content": "가사 입력에 의해 구동되는 음악 작곡 및 생성 시스템 내에서의 자동화된 음악 작곡 및 생성 프로세스로서,(a) 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 엔진에 액세스한 다음, 상기 자동화된 음악 작곡 및 생성 시스템에 의해 생성된 음악으로 스코어링될 미디어를 선택하는 단계;(b) 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 시스템에 가사 입력을 제공하고, 음악적으로 스코어링될미디어를 선택하는 단계;(a) 상기 자동화된 음악 작곡 및 생성 엔진이, 상기 가사 입력에 기초하여 음악을 자동으로 작곡 및 생성하기위해 상기 자동화된 음악 작곡 및 생성 엔진에 제공된 피치 이벤트를 추출하기 위하여, 피치 및 리듬 추출 서브시스템을 이용하여 상기 가사 입력으로부터 피치 정보를 자동으로 추출하는 단계; 및(d) 상기 시스템이 작곡된 음악을 선택된 미디어와 조합하여, 표시 및 향유하기 위한 복합 미디어 파일을 제작하는 단계를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_108", "content": "프로세스를 지원하는 자동화된 음악 작곡 및 생성 시스템 내의 파라미터 변환 엔진 서브 시스템으로서,공개특허 10-2018-0063163-24-상기 자동화된 음악 작곡 및 생성 시스템 내의 서브 시스템 내에 유지된 특정 파라미터 테이블의 파라미터 가중치를 자동으로 조절하는 단계를 포함하는, 파라미터 변환 엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_109", "content": "제108항에 있어서, 가사적으로/음악적으로 왜곡된 파라미터 테이블 또는 로컬 구현법과 관련하여 후술한 가사/음악 응답 파라미터 값 섹션 메커니즘과 같은 대안적인 파라미터 메커니즘으로부터 파라미터 값을 선택하기 위해 난수 발생기가 사용되는, 파라미터 변환 엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_110", "content": "제108항에 있어서, 상기 피치 및 리듬 추출 서브 시스템은 시스템 사용자가 제공한 가사 또는 음악(단독으로 또는 선택된 음악적 경험 및 타이밍 파라미터와 함께)으로부터 실시간 피치 및 리듬 정보를 포착하기 위해 사용되며, 상기 정보는 각 서브 시스템에 지원된 가사/음악 응답 파라미터 값 선택 메커니즘에 제공되는, 파라미터 변환 엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_111", "content": "제108항에 있어서, 상기 파라미터 값 선택 메커니즘은 시스템 사용자로부터 추출된 피치 및 리듬 정보를 수신하고, 확률 기반 파라미터 테이블 내의 어떤 파라미터 값이 선택되어야 하는지에 대한 결정 기준을 형성하기 위해이를 이용할 수 있는, 파라미터 변환 엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_112", "content": "제108항에 있어서, 상기 실시간 피치 이벤트 분석 서브 시스템은 시스템 사용자 입력을 입력 리듬, 피치, 및 리듬/피치의 동기 수준으로 증류하는, 파라미터 변환 엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_113", "content": "제108항에 있어서, 상기 가사/음악 입력은 (i) 감정 타입 및 스타일 타입 음악적 경험 디스크립터와 함께 보충적인 음악적 경험 디스크립터의 역할을 하거나, (ii) 가사/음악 입력은 감정 및/또는 스타일 디스크립터 없이주요한 음악적 경험 디스크립터의 역할을 하는, 파라미터 변환 엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_114", "content": "제108항에 있어서, 상기 실시간 피치 이벤트 분석 서브 시스템은 동기 컨텐츠를 분석하여 패턴, 경향, 선호도및/또는 재료 내의 다른 의미있는 관계를 식별하고; 상기 파라미터 변환 엔진 서브 시스템은 이 관계들을 상기시스템 작동 파라미터 테이블에 대한 파라미터 값 또는 값 범위 선호도로 변환하며; 그 다음, 상기 시스템은 후속하여 생성된 음악 조각이 입력 재료의 분석을 반영하도록 가사/음악 입력 재료의 분석을 반영하는 파라미터가이미 생성 및/또는 로드된 시스템 작동 테이블로부터 특정 값(들)을 선택할 가능성이 보다 높은, 파라미터 변환엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_115", "content": "제108항에 있어서, 입력 재료가 짧고 빠른 리듬 재료의 고주파수로 구성된 경우, 리듬 관련 서브 시스템은 입력재료가 영향을 미칠 수 있는 파라미터 테이블에서 16분음표 및 8분 음표 리듬 값 또는 다른 값을 선택할 가능성이 보다 높은, 파라미터 변환 엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_116", "content": "제108항에 있어서, 입력 재료가 마이너 키를 포함한 피치로 구성된 경우, 피치 관련 서브 시스템은 입력 재료가영향을 미칠 수 있는 마이너 키(들) 및 관련 마이너 화음 및 화음 진행 또는 다른 값을 선택할 가능성이 보다높은, 파라미터 변환 엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_117", "content": "제108항에 있어서, 시스템 사용자 입력 재료가 특정 스타일을 추종하거나 특정 컨트롤러 코드 옵션을 채택한 경우, 악기 편성 서브 시스템과 컨트롤러 코드 서브 시스템은 각각 특정 악기 및/또는 특정 컨트롤러 코드 옵션을공개특허 10-2018-0063163-25-선택할 가능성이 보다 높은, 파라미터 변환 엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_118", "content": "제108항에 있어서, 팝 스타일을 추종하는 멜로디를 노래하는 시스템 사용자는 상기 서브 시스템 내의 파라미터가 팝 악기 옵션을 변경하고 심하게 강조하도록 할 수 있는, 파라미터 변환 엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_119", "content": "제108항에 있어서, 딜레이 효과를 모방하는 멜로디를 노래하는 시스템 사용자는 상기 서브 시스템 내의 파라미터가 딜레이 및 관련 컨트롤러 코드 옵션을 변경하고 심하게 강조하도록 할 수 있는, 파라미터 변환 엔진 서브시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_120", "content": "제108항에 있어서, 시스템 사용자 입력 재료가 특정 악기 및/또는 그 연주 방법을 추종하거나 모방하는 경우,오케스트레이션 서브 시스템은 특정 오케스트레이션 옵션을 선택할 가능성이 보다 높은, 파라미터 변환 엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_121", "content": "제108항에 있어서, 악기(들)의 모방된 음악 연주(들)로 멜로디를 노래하는 시스템 사용자는 상기 서브 시스템내의 파라미터가 사용자 입력을 반영하기 위해 조각의 오케스트레이션을 변경하고 심하게 강조하도록 할 수 있는, 파라미터 변환 엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_122", "content": "제108항에 있어서, 시스템 사용자가 아르페지오 멜로디를 노래하는 경우, 상기 서브 시스템 내의 파라미터는 작곡되고 있는 음악 조각의 아르페지오 또는 유사한 오케스트레이션을 심하게 강조하도록 변경될 수 있는, 파라미터 변환 엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_123", "content": "제108항에 있어서, 서로 다른 음악 기능을 연주하는 모방된 악기로 멜로디를 노래하는 시스템 사용자는 상기 서브 시스템 내의 파라미터가 시스템 사용자에 의해 모방되는 바와 같이 각각의 악기와 관련된 음악 기능 선택을변경하고 심하게 강조하도록 할 수 있는, 파라미터 변환 엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_124", "content": "제108항에 있어서, 시스템 사용자가 바이올린 스타일로 멜로디를 노래하는 것과 기타 스타일로 반주하는 것을교대로 하는 경우, 상기 서브 시스템의 파라미터는 음악 조각의 관련되거나 유사한 악기(들)에 대한 이 음악 기능들을 심하게 강조할 수 있는, 파라미터 변환 엔진 서브 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_125", "content": "자동화된 음악 작곡 및 생성 시스템에서 실시간 피치 이벤트 분석 서브 시스템을 이용하여 자동화된 방식으로음악을 작곡 및 생성하는 방법으로서,(a) 상기 자동화된 음악 작곡 및 생성 시스템의 시스템 사용자 인터페이스에 음악적 경험 디스크립터를 제공하는 단계;(b) 상기 자동화된 음악 작곡 및 생성 시스템에 의해 작곡 및 생성된 음악으로 스코어링될 비디오 또는 미디어객체의 하나 이상의 장면을 위해, 상기 시스템 사용자 인터페이스에 (예컨대, 타이핑되거나, 말로 전해지거나또는 노래 불려진 포맷의) 가사 입력을 제공하는 단계;(c) 분석된 가사 입력으로부터 피치 이벤트, 리듬 정보 및/또는 운율 정보, 및 (ii) 그와 같은 검출 이벤트가언제 발생하였는지에 대한 타이밍 정보를 가진 코드를 추출하기 위해 상기 실시간 피치 이벤트 분석 서브 시스템을 이용하는 단계;(d) 타임라인을 따라 그와 같은 검출 이벤트가 언제 발생하였는지를 정확하게 나타내기 위해 추출된 피치 이벤공개특허 10-2018-0063163-26-트, 리듬 정보 및 운율 정보를 부호화하는 단계;(e) 상기 자동화된 음악 작곡 및 생성 시스템의 다양한 서브 시스템에 채택된 시스템 작동 파라미터를 제한하는데 사용하기 위해 상기 자동화된 음악 작곡 및 생성 시스템에 추출된 피치 이벤트, 리듬 및 운율 정보를 제공하는 단계를 순서대로 포함하는, 자동화된 방식으로 음악을 작곡 및 생성하는 방법."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_126", "content": "제125항에 있어서, 상기 음악적 경험 디스크립터는 감정 타입 음악적 경험 디스크립터와 스타일 타입 음악적 경험 디스크립터를 포함하는, 방법."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_127", "content": "제125항에 있어서, 상기 음악적 경험 디스크립터는 키보드 데이터 입력, 음성 인식, 및 데이터 입력 및 취급 분야에 공지된 장치로 이루어진 군으로부터 선택된 장치에 의해 제공되는, 방법."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_128", "content": "제125항에 있어서, 시스템 사용자는 의도된 미디어 조각 또는 섹션의 가사를 말하거나 노래하며, 이를 위해, 가사는 상기 자동화된 음악 작곡 및 생성 시스템에 의해 작곡 및 생성될 음악의 적어도 제한된 수의 음표에 대해음색, 리듬 및 멜로디를 전송하도록 의도되는, 방법."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_129", "content": "제125항에 있어서, 말로 전해지거나 노래 불려진 가사 또는 단어에 대응하는 음성 신호는 타이핑되거나/말로 전해지거나/노래 불려진 가사 또는 단어의 실시간 리듬, 피치 이벤트 및/또는 운율 분석을 실행하도록 프로그래밍된 디지털 신호 프로세싱(DSP) 칩을 이용하여 디지털화되고 프로세싱되는, 방법."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_130", "content": "제125항에 있어서, 상기 디지털 신호 프로세싱(DSP) 칩은 가사에서 모음의 발생을 확인하기 위해 모음 포먼트분석을 채택하고, 상기 모음은 상기 자동화된 음악 작곡 및 생성 시스템에 제공된 가사 입력으로부터 멜로디의감각을 얻기 위해 대응하는 피치의 음표를 생성하기 위해 사용되는, 방법."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_131", "content": "제125항에 있어서, 시스템 입출력 인터페이스는 상기 자동화된 음악 작곡 및 생성 시스템에 의해 지원되는 임의의 자연어로 타이핑된 단어, 말로 전해진 단어 및/또는 노래 불려진 음성의 형태로 상기 자동화된 음악 작곡 및생성 시스템에 시스템 사용자가 가사 입력을 전송할 수 있도록 하는, 방법."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_132", "content": "제125항에 있어서, 상기 실시간 피치 이벤트 분석 서브 시스템은,시스템 사용자에 의해 제공되는 서로 다른 가사 입력 형태를 취급하는 가사 입력 핸들러;상기 실시간 피치 이벤트 분석 서브 시스템에 의해 생성되는 서로 다른 피치 이벤트 출력 스트림을 취급하는 피치 이벤트 출력 핸들러;상기 실시간 피치 이벤트 분석 서브 시스템에 의해 지원되는 언어로 각 단어에 언어 정보 및 모델을 저장하는어휘 사전;프로세싱된 가사 입력에 포함된 모음 포먼트를 분석하는 모음 포맷 분석기; 및상기 실시간 피치 이벤트 분석 서브 시스템의 가사 입력 모드를 제어하는 모드 컨트롤러를 포함하는, 방법."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_133", "content": "가사 음악적 경험 디스크립터에 의해 구동되는 자동화된 음악 작곡 및 생성 시스템 내에서의 자동화된 음악 작곡 및 생성 프로세스로서,(a) 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 상기 자동화된 음악 작곡 및공개특허 10-2018-0063163-27-생성 시스템에 채택된 자동화된 음악 작곡 및 생성 엔진에 의해 생성된 음악으로 스코어링될 미디어를 선택하는단계;(b) 시스템 사용자가 음악적으로 스코어링될 선택된 미디어에 적용하기 위해 상기 자동화된 음악 작곡 및 생성엔진에 제공된 가사를 포함한 음악적 경험 디스크립터를 선택하는 단계;(c) 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 엔진을 기동하여 선택된 미디어에 스코어링되어 있는 제공된 음악적 디스크립터에 기초한 음악을 작곡 및 생성하는 단계;(d) 시스템 사용자가 스코어링된 미디어 조각 또는 이벤트 마커에 대해 작곡되어 생성된 음악을 검토하며, 음악을 수용하고/또는 도출된 음악적 경험을 고려하여 사용자 선호도에 대한 피드백을 상기 자동화된 음악 작곡 및생성 엔진에 제공하며, 및/또는 음악적 디스크립터 및 파라미터를 변경하고, 변경된 음악 조각을 재생하도록 상기 자동화된 음악 작곡 및 생성 엔진에 요청하는 단계; 및(e) 시스템이 작곡된 음악 조각을 선택된 비디오에 조합하여, 분배 및 표시하기 위한 새로운 미디어 파일을 제작하는 단계를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_134", "content": "시스템 사용자에 의해 자동화된 음악 작곡 및 생성 시스템에 타이핑된 가사 입력으로서 제공된 가사 표현을 프로세싱하는 방법으로서,(a) 문자소 또는 형태소의 열로서 텍스트 기반 가사 입력을 수신하는 단계;(b) 상기 문자소 또는 형태소의 열을 사전을 이용하여 음소의 음성 열로 자동으로 전사하는 단계;(c) 음성 열의 음소에 기초하여, 음소 열에 존재하는 모음을 (디폴트) 모음 포맷의 열로 자동으로 변환하는 단계;(d) 검출된 모음 포맷을 리듬 정보가 없는 음표의 열을 나타내는 피치 이벤트의 열로 자동으로 변환하는 단계;및(e) 상기 피치 이벤트의 열을 상기 자동화된 음악 작곡 및 생성 시스템에 전송하는 단계를 포함하는, 가사 표현을 프로세싱하는 방법."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_135", "content": "시스템 사용자에 의해 자동화된 음악 작곡 및 생성 시스템에 말로 전해진 가사 표현 입력을 프로세싱하는 방법으로서,(a) 음향 신호로서 말로 전해진 가사 입력을 수신하는 단계;(b) 사전 및 음성 인식 방법을 이용하여 음성 등가 열을 생성하기 위해, 신호 프로세싱 기술을 이용하여 음향신호를 자동으로 프로세싱하는 단계;(c) 상기 음성 열의 음소에 기초하여, 상기 음소 열에 존재하는 모음을 (디폴트) 모음 포맷의 열로 자동으로 변환하는 단계;(d) 그 다음, 검출된 모음 포맷을 리듬 정보가 있는 피치 이벤트의 열로 자동으로 변환하는 단계;(e) 상기 모음 포먼트의 열로부터 리듬 데이터가 있는 피치 이벤트의 열을 생성하는 단계; 및(f) 상기 피치 이벤트 및 리듬 데이터를 상기 자동화된 음악 작곡 및 생성 시스템에 전송하는 단계를 포함하는,가사 표현 입력을 프로세싱하는 방법."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_136", "content": "시스템 사용자에 의해 자동화된 음악 작곡 및 생성 시스템에 가사 입력으로서 노래 불려진 가사 표현을 프로세싱하는 방법으로서,(a) 연속적으로 버퍼링되고 프로세싱되는 음향 신호로서 상기 노래 불려진 가사 입력을 수신하는 단계;(b) 사전을 이용하여 음성 등가 열을 생성하기 위해, 신호 프로세싱 기술을 이용하여 상기 음향 신호를 자동으공개특허 10-2018-0063163-28-로 프로세싱하는 단계;(c) 상기 음성 열의 음소에 기초하여, 음소 열에 존재하는 모음을 (디폴트) 모음 포맷의 열로 자동으로 변환하는 단계;(d) 검출된 모음 포맷을 리듬 정보가 있는 피치 이벤트의 열로 자동으로 변환하는 단계; 및(e) 상기 자동화된 음악 작곡 및 생성 시스템에 관한 피치 이벤트 및 리듬 데이터를 자동으로 전송하는 단계를포함하는, 가사 표현을 프로세싱하는 방법."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_137", "content": "시스템 사용자에 의해 제공되는 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 자동화된 음악 작곡 및 생성 프로세스로서, 언어 기반 음악적 경험 디스크립터와 비디오, 오디오 레코딩, 이미지또는 이벤트 마커가 시스템 사용자 인터페이스를 통해 입력으로서 제공되고, 자동화된 음악 작곡 및 생성 엔진에 의해 사용되어 시스템 사용자 인터페이스를 통해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된미디어 또는 이벤트 마커를 가상 악기 음악 합성을 이용하여 생성하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_138", "content": "자동화된 장난감 음악 작곡 및 생성 악기 시스템으로서, 그래픽 아이콘 기반 음악적 경험 디스크립터와 비디오가 시스템 사용자 인터페이스를 통해 입력으로서 선택되고, 자동화된 음악 작곡 및 생성 엔진에 의해 사용되어시스템 사용자 인터페이스를 통해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된 비디오 스토리를 자동으로 생성하는, 자동화된 장난감 음악 작곡 및 생성 악기 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_139", "content": "기업 수준의 인터넷 기반 음악 작곡 및 생성 시스템으로서, 인터넷 인프라에 작동 가능하게 연결된 웹 서버, 애플리케이션 서버 및 데이터베이스(RDBMS) 서버를 갖춘 데이터 프로세싱 센터에 의해 지원되며, 클라이언트머신, 소셜 네트워크 서버 및 웹 기반 통신 서버에 의해 액세스될 수 있고, 웹 사이트에서 웹 기반 브라우저를이용하여 누구나 자동화된 음악 작곡 및 생성 서비스에 액세스할 수 있도록 함으로써, 텍스트 키보드 및/또는음성 인식 인터페이스를 사용하여 생성된 언어 기반 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악합성 기술을 사용하여 음악으로 비디오, 이미지, 슬라이드 쇼, 오디오 파일 및 기타 이벤트를 스코어링할 수 있도록 하는, 기업 수준의 인터넷 기반 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_140", "content": "기업 수준 시스템에 의해 지원되는 자동화된 음악 작곡 및 생성 프로세스로서,(i) 시스템 사용자가 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 자동화된 음악 작곡 및 생성 시스템에 의해 생성된 음악으로 스코어링될 비디오, 오디오 레코딩(즉, 팟 캐스트), 슬라이드 쇼, 사진이나 이미지 또는 이벤트 마커를 선택하는 단계;(ii) 시스템 사용자가 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 상기 자동화된 음악 작곡 및생성 엔진에 제공하는 단계;(iii) 시스템 사용자가 상기 자동화된 음악 작곡 및 생성 엔진을 기동하고, 선택된 미디어 또는 이벤트 마커에스코어링되어 있는 입력된 음악적 디스크립터에 기초하여 음악을 작곡 및 생성하는 단계;(iv) 시스템 사용자가 스코어링된 미디어 또는 이벤트 마커에 대해 제작된 작곡 및 생성된 음악을 수용하고, 시스템 사용자가 주관적으로 경험하여 형성된 음악적 경험을 고려하여 제작된 음악에 대한 시스템 사용자의 평가및/또는 음악 선호도에 관한 피드백을 시스템에 제공하는 단계; 및(v) 시스템이 수용한 작곡된 음악을 선택된 미디어 또는 이벤트 마커와 조합하여, 분배 및 표시하기 위한 비디오 파일을 제작하는 단계를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_141", "content": "자동화된 음악 작곡 및 생성 시스템으로서,공개특허 10-2018-0063163-29-자동화된 음악 작곡 및 생성 엔진을 이용하여 시스템 사용자에 의해 자동으로 작곡된 음악을 추가함으로써 증강되는 텍스트, SMS 및 이메일 서비스를 각각 지원하는 복수의 모바일 및 데스크탑 클라이언트 머신을 갖춘 시스템 네트워크 상에 배치된 인터넷 기반의 자동화된 음악 작곡 및 생성 플랫폼과, 텍스트, SMS 및 이메일 메시지를 위한 작곡 음악 조각을 생성하는 데 사용하기 위해 사용자가 그래픽 및/또는 언어 기반 감정 및 스타일 디스크립터를 쉽게 선택할 수 있도록 텍스트, SMS 및/또는 이메일 문서를 제작할 때 클라이언트 머신에 의해 지원되는 그래픽 사용자 인터페이스를 포함하는, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_142", "content": "작곡된 음악을 텍스트, SMS, 이메일 문서/메시지에 추가하기 위해 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 인터넷 기반의 자동화된 음악 작곡 및 생성 시스템으로서, 언어 기반 또는 아이콘 기반 음악적 경험 디스크립터가 시스템 사용자 인터페이스를 통해 입력으로서 시스템 사용자에 의해 제공되고, 자동화된 음악 작곡 및 생성 엔진에 의해 사용되어 최종 마무리 및 전송 전에 시스템 사용자 인터페이스를통해 시스템 사용자에 의한 미리보기를 위해 생성되는 음악적으로 스코어링된 텍스트 문서 또는 메시지를 생성하는, 인터넷 기반의 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_143", "content": "음악적으로 스코어링된 텍스트, SMS, 이메일, PDF, 워드 및/또는 html 문서를 자동적이고 즉각적으로 생성하기위해 입력으로서 제공된 음악적 경험 디스크립터에 의해 구동되는 자동화된 가상 악기 음악 합성의 사용을 지원하는 웹 기반 시스템을 사용한 자동화된 음악 작곡 및 생성 프로세스로서,(a) 시스템 사용자가 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 상기 자동화된 음악 작곡 및 생성엔진에 의해 생성된 음악으로 스코어링될 텍스트, SMS 또는 이메일 메시지 또는 워드, PDF 또는 HTML 문서를 선택하는 단계;(ii) 시스템 사용자가 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 상기 자동화된 음악 작곡 및생성 엔진에 제공하는 단계;(iii) 시스템 사용자가 자동화된 음악 작곡 및 생성 시스템을 기동하여 선택된 메시지 또는 문서에 스코어링되어 있는 입력된 음악적 디스크립터에 기초한 음악을 작곡 및 생성하는 단계;(iv) 시스템 사용자가 메시지 또는 문서에 대해 제작된 작곡 및 생성된 음악을 수용하거나, 음악을 거부하고 다른 음악적 경험 디스크립터의 제공 및 갱신된 음악적 경험 디스크립터 입력에 기초하여 음악을 재작곡하도록 하는 요구를 포함한 피드백을 시스템에 제공하는 단계; 및(v) 수용한 작곡된 음악을 메시지 또는 문서와 조합하여, 분배 및 표시하기 위한 새로운 파일을 제작하는 단계를 포함하는, 자동화된 음악 작곡 및 생성 프로세스."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_144", "content": "자동화된 음악 작곡 및 생성 엔진, 실제 및/또는 합성 음악 악기 세트를 연주하는 인간 음악가 밴드에서 사용하기 위한 인공 지능(AI) 기반 자율 음악 작곡, 생성 및 연주 시스템으로서, AI 기반 자율 음악 작곡, 생성 및 연주 시스템은 그 주변 악기 및 음악가로부터 음악 신호를 수신하여 이들 악기를 버퍼링 및 분석하고, 이에 응답하여, 음악가 밴드에 의해 연주되고 있는 음악을 증강하게 될 음악을 실시간으로 작곡 및 생성할 수 있거나, 인간 음악가에 의한 후속 재생, 검토 및 심의를 위해 기록되는 음악을 녹음, 분석 및 작곡할 수 있는, AI 기반 자율 음악 작곡, 생성 및 연주 시스템."}
{"patent_id": "10-2018-7011569", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_145", "content": "자동화된 음악 작곡 및 생성 시스템으로서, 음악 작곡 및 생성 프로세스 중에 시스템 내의 파라미터를 변경하기위해 실시간 피치 이벤트, 리듬 및 운율 분석이 실시되는 서브 시스템에 시스템 사용자에 의해 제공된 타이핑되거나, 말로 전해지거나, 노래 불려진 대사 또는 가사 입력을 전송하는 시스템 사용자 인터페이스가 제공된, 자동화된 음악 작곡 및 생성 시스템."}
{"patent_id": "10-2018-7011569", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "자동화된 음악 작곡 및 생성 기계, 엔진, 시스템 및 방법, 그리고 아키텍처는 음악 이론이나 연습에 대한 어떤 지식 또는 전문 음악 지식이나 기타 창의적 노력이 없어도, 이에 한정되지는 않지만, 모든 오브젝트, 엔티티 및/ 또는 이벤트뿐만 아니라 비디오, 사진, 슬라이드 쇼 및 기존 오디오 포멧을 포함한 모든 종류의 미디어 콘텐츠에 동기화되는 특이한 전문가 품질의 음악을 음악 작곡 로봇 시스템을 포함한 누구나 즉각 생성할 수 있도록 하며, 시스템 사용자는 본 발명의 자동화된 작곡 및 생성 시스템에 의해 궁극적으로 작곡될 음악 조각에 음악적으로 표 현될 자신의 감정 및/또는 예술적 개념에 대한 지식만 있으면 된다."}
{"patent_id": "10-2018-7011569", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 선행 기술에서는 일반적으로 필요한 음악 이론에 대한 특별한 지식이나 연습이 없어도 다양하게 응용 하기 위한 원곡을 생성하기 위하여 어린이와 기업 모두뿐만이 아니라 개인, 개인들의 그룹을 돕는 신규하고 개 선된 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2018-7011569", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "비디오 및 그래픽 아트 창작자가 자신이 직면한 시간적, 법적 및 예산적 제약 내에서 자신의 콘텐츠에 적합한 음악을 발견하는 것은 매우 어렵다. 또한, 적합한 음악을 검색한지 몇 시간 또는 몇 일이 지난 후, 라이센스 규 제, 비-독점권 및 유연성 없는 제품은 디지털 콘텐츠에 음악을 통합하는 프로세스를 종종 방해한다. 자신의 프 로젝트에서, 콘텐츠 창작자는 그것을 만들어가는 창의성과 협업 때문이 아니라, \"예술 음악\"과는 달리, 그 기능 적 목적 때문에 가치를 인정받는 음악인 \"상품 음악\"을 종종 사용한다. 현재, 상품 음악 시장은 3억불이며, 매년 창작되고 있는 상품 음악을 사용하는 콘텐츠의 양적 증가와 콘텐츠 창 작자 수에서의 기술 지원 급증으로 인해, 성장하고 있다. 프리랜서 비디오 편집자, 제작자 및 소비자 콘텐츠 창 작자에서부터 광고/디지털 브랜딩 에이전시 및 기타 전문 콘텐츠 창작 회사에 이르기까지, 음악의 발견과 디지 털 미디어 내에 통합하는 문제의 해결책에 대한 극심한 요구가 있었다. 물론, 음악을 창작하고 작곡을 돕기 위한 컴퓨터 및 알고리즘의 사용이 수십년 동안 많은 사람들에 의해 추진되 었으나, 그다지 큰 성공을 거두지 못했다. 자신의 2000년도 대표적 저서인 \"알고리즘 작곡가\"에서, 데이비드 코 프(David Cope)는 2000년도의 최신 기술을 다시 조사하고, ALICE(ALgorithmically Integrated Composing Environment: 알고리즘적으로 집적된 작곡 환경)라 칭한 자신의 쌍방향 음악 작곡 시스템을 개발하는 자신의 성 과를 포함하여, 자신이 쓴 바와 같이, \"알고리즘 작곡\"에서의 자신의 성과를 서술하였다. 이 유명한 저서에서, 데이비드는 작곡가의 스타일로 새로운 음악을 작곡 및 생성하는 작곡가를 보조하고, 작곡 된 이전 음악으로부터 음악적 지능을 추출하여 작곡가가 예전에 받지 못했던 유용한 수준의 지원을 제공하기 위 해 자신의 ALICE 시스템이 어떻게 사용될 수 있는지에 대해 서술하였다. 데이비드 코프는 지난 15년 동안 이 분 야에서 자신의 성과를 거두었으며, 그의 인상적인 창작품은 예술가들의 음악 작곡으로부터 음악적 지능을 추출 하기 위한 최선의 노력에 기초하여 그들의 특이한 스타일에 따라 음악을 생성하기 위해 그들의 능력을 강화하기 위한 많은 흥미로운 도구를 음악인들에게 제공한다. 그러나, 이와 같은 성과는 급속하게 성장하고 있는 상품 음 악 시장의 욕구와 요구를 충족시킬 수 있는 특이한 음악 조각을 비음악인이 자동으로 작곡 및 생성할 수 있도록 하는 어떤 적절한 방안을 제공하기에는 명백히 부족하다. 2004년에, 하인리히 타우베(Heinrich Taube) 교수는 자신의 유명한 저서 \"Notes From The Metalevel: An Introduction To Computer Composition\"을 러틀리지 출판사(348페이지)를 통해 출판하였으며, 이는 리스프의 방언인 커먼 리스프(Common Lisp)로 프로그래밍되어 커먼 뮤직(COMMON MUSIC)이라 지칭되는 컴퓨터 및 객체 지 향 음악 작곡 소프트웨어를 사용하여 음악 작곡을 연구하기 위한 매뉴얼로서 소개되었다. \"Notes from The Metal Level\"에서, 타우베 교수는 컴퓨터 보조 작곡에서는 사전 작곡 데이터의 연산, 이벤트 편집, 재생 실시 등의 작곡 작업 등을 컴퓨터가 용이하게 한다고 설명하고 있다. 어떤 면에서, 컴퓨터는 작곡 형식주의의 표현으 로서가 아니라 작곡자가 작곡 아이디어를 얻기 이전에 또는 이후에 적용된다. 타우베 교수는 용어 자동 작곡은 \"독립적으로\" 음악을 작곡하도록 설계된 컴퓨터 시스템에 적용될 수 있다고 또한 설명하고 있다. 데이비드 코프 의 음악적 지능에서의 실험과 같은 소프트웨어와 어떤 종류의 소리 설치물이 이와 같은 종류의 시스템의 예이다. 컴퓨터 기반 작곡은 연주 점수보다 더 높은 수준으로 작곡 아이디어를 명시적으로 표현하기 위해 컴퓨 터를 사용하는 것을 의미한다. 명시적 메타레벨 표현은 작곡(작곡의 작곡)을 구성하는 관계와 프로세스가 이들 을 생각하는 작곡가로부터 분리된 기계 내부에서 표현되는 것을 의미한다. 이것이 Notes From The Metalevel의 핵심 주제이다. Notes From The Metalevel에서 타우베 교수가 서술한 바와 같이, 1980년대에, 리스프는 현실 세 계 애플리케이션을 모델링하기 위해 객체 지향 프로그래밍이라는 강력한 방법론을 채택하였다. 객체 지향 프로 그래밍에서는, 원하는 도메인이 객체 시스템에 속한 클래스 또는 메소드로써 모델링되거나 표현된다. 타우베 교 수의 커먼 뮤직(CM) 소프트웨어 시스템은 그 데이터와 거동을 객체 시스템을 사용하여 표현한다. 커먼 뮤직의 경우, 애플리케이션 도메인은 음악 작곡이며, 객체 모델링은 작곡 구조와 소리 발생시 그 거동의 표현을 수반한 다. 커먼 뮤직 소프트웨어 애플리케이션에서는, 자동화된 음악 작곡을 위한 메타레벨 모델, 작곡 내에서 데이터 객체들 간의 전환 및 다양한 애플리케이션에서 동일한 것을 발생시키기 위한 자동화된 시스템을 제공하기 위해 은닉 마르코프 모델과 기타 확률 기반 모델이 광범위하게 사용된다.또한, 지난 수십년 동안, 수많은 기타 음악 작곡 시스템이 은닉 마르코프 모델, 생성적 문법, 전환망, 카오스와 자기 유사성(프랙탈), 유전 알고리즘, 셀룰러 오토마타, 신경망 및 인공 지능(AI) 메소드와 같은 다양한 기술을 사용하여 제안 및/또는 개발되었다. 이와 같은 시스템의 대부분은 컴퓨터 알고리즘의 도움을 받아 음악을 작곡 하고자 하지만, 일부는 자동화된 방법으로 음악을 작곡 및 생성하는 것으로 보이기도 한다. 그러나, 이와 같은 자동화된 음악 작곡 시스템에 의해 제작된 음악의 품질은 상업적 시장이나, 미디어 관련 제 품, 특별 행사 등에 가치를 추가하고자 하는 소비자 시장에서 수용 가능한 용처를 찾아내기에는 상당히 불량했 다. 그 결과, 훌륭한 음악을 제작하는 기계에 대한 꿈은 언젠가 이를 실현하고자 하는 많은 사람들의 노력에도 불구하고 지금까지 이루어지지 않고 있다. 그 결과, 현대 시장에서의 사용 및 판매에 적절한 컴퓨터 또는 기계 보조 음악 작곡을 이용하기 위하여 많은 절 충이 이루어졌다. 예컨대, 미국 특허 제7,754,959호 \"System and Method of Automatically Creating An Emotional Controlled Soundtrack\" by Herberger et al. (assigned to Magix AG)에서는, 디지털 비디오 편집 소프트웨어의 사용자가 기본 비디오 작품의 장면과 전반적인 감정이나 기분이 일치하는 감정적으로 제어된 사운드 트랙을 자동으로 생 성할 수 있도록 하는 시스템을 제공한다. 개시된 바와 같이, 사용자는 각 장면의 전반적인 기분에 대응하는 감 정 태그를 비디오 작품 내에 배치함으로써 사운드 트랙의 생성을 제어할 수 있을 것이다. 후속 사운드 트랙 생 성 단계는 이 태그를 이용하여 화면 상의 움직임과 대체로 일치하는 음악 반주를 비디오 작품에 제공하고, 이 음악 반주는 서로 연관된 적어도 하나의 음악적 스타일을 각각 가진 복수의 미리 기록된 루프(및 트랙)를 사용 한다. 개시된 바와 같이, 감정 태그와 연관된 기분은 행복, 슬픔, 로맨틱, 흥분, 무서움, 긴장, 절망, 사색, 분 노, 긴장 및 황홀로 이루어진 군으로부터 선택된다. 개시된 바와 같이, 복수의 미리 기록된 음악 루프와 연관된 스타일은 록, 스윙, 재즈, 왈츠, 디스코, 라틴, 컨트리, 가스펠, 래그타임, 칼립소, 레게, 오리엔탈, 리듬 앤 블루스, 살사, 힙합, 랩, 삼바, 자이데코, 블루스 및 클래식으로 이루어진 군으로부터 선택된다. 미디어의 프레임에 스코어링하기 위해 감정 태그를 사용하는 전반적인 개념은 매력적이지만, 미국 특허 제 7,754,959호에서 허버거 등이 개시 및 교시한 바와 같은, 음악의 일부분을 작곡 및 생성하기 위한 자동화된 방 법 및 장치는 대부분의 환경에서 바람직하거나 실현 가능하지도 않고, 거의 모든 상품 음악 시장에서 유용한 애 플리케이션으로만 이 시스템이 과도하게 제한되도록 한다. 아울러, 급속하게 성장하고 있는 상품 음악 시장의 요구를 충족하기 위해 노력하고 있는 수많은 회사가 있지만, 별로 성공적이지 않다. Score Music Interactive의 XHail 시스템의 개요 특히, 아일랜드 웩스포드 컨트리, 고리, 마켓 스퀘어 소재(상호명 Xhail) Score Music Interactive는 미국 특허 제7,754,959호에 제안된 방식을 따라 사용자가 미리 기록된 오디오 루프와 트랙의 새로운 조합을 생성할 수 있 도록 하는 XHail 시스템을 제공한다. 베타 웹 기반 소프트웨어로서 현재 이용가능한 XHail 시스템은 음악 교육받은 개인이 디스크립팅 태그에 기초하 여 기존 음악 루프들의 특이한 조합을 생성할 수 있도록 한다. XHail 시스템을 알맞게 사용하기 위해서는, 사용 자가 음악 생성 프로세스를 이해하여야만 하며, 여기에는, 이에 한정되지는 않지만, (i) 어떤 악기들이 함께 연 주될 때 좋은 효과를 내는지에 대한 이해, (ii) 악기들의 오디오 수준이 어떻게 서로 균형을 이루어야 하는지에 대한 이해, (iii) 다양한 악기 팔레트로 어떻게 음악적 윤곽을 만드는지에 대한 이해, (iv) 이에 한정되지는 않 지만, 오케스트라 및 합성 악기, 음향 효과 및 음파 생성기를 포함하는 각각의 가능한 악기 또는 소리/오디오 생성기를 어떻게 식별하는지에 대한 이해, 및 (v) 음악 분야에서의 표준 또는 평균 수준의 지식 보유가 포함된 다. XHail 시스템이 빠른 속도로 기존 음악 루프들을 내부적으로 새로운 조합으로 결합하는 것으로 보이지만, 기존 음악 루프들로 생성된 조합을 우아한 음악 조각으로 변환하기 위해서는 많은 시간과 노력이 필요하다. 기존 비 디오에 음악 조합을 동기화하기 위해서는 추가적인 시간과 노력이 필요하다. XHail 시스템은 그 조합 프로세스 를 위해 미리 제작된\"음악 루프\"를 원재료로 사용하기 때문에, 그 시스템 데이터베이스 내의 루프의 양에 의해, 그리고 각각 독립적으로 생성된 음악 루프의 품질에 의해 제한된다. 또한, 각 루프의 독창적 창의성의 소유권, 저작권 및 기타 법적 지정인이 각 루프의 독립적인 창작자에 의해 적어도 부분적으로 소유되기 때문에, 그리고 XHail 시스템이 전체 생성 프로세스를 제어 및 생산하지 않기 때문에, XHail 시스템의 사용자는 기존 루프가 조 합에 사용될 때마다 그 루프 창작자들 각각에 대해 법적 및 재정적 의무를 갖는다.콘텐츠 제작 프로세스에서 작곡가를 대체하고자 하는 사람들에게는 XHail 시스템이 음악의 발견 및 통합을 위한 가능한 해결책인 것으로 보이지만, 예술 음악을 제작하고자 희망하는 사람들은 이를 만드는 예술가를 항상 찾을 것이며, 아무리 성능이 좋아도 기계에게 인간 예술가의 창조력을 전적으로 넘기지는 않을 것으로 생각된다. 또 한, 생성된 음악의 라이센스 프로세스가 복잡하고, 전달 물질이 유연하지 않으며, 시스템의 완벽한 이해와 사용 을 위해서는 음악 이론과 현재 음악 소프트웨어의 이해가 필요하고, 아마도 가장 중요한 것은 XHail 시스템이 사용자 별로 그리고/또는 사용자 전체에 걸쳐 학습하고 개선할 능력이 없다는 것이다. JukeDeck의 Scorify 시스템의 개요 캠브리지 졸업생인 에드 렉스와 패트릭 스톱스에 의해 설립되고 영국 런던에 기반을 둔 JukeDeck의 Scorify 시 스템은 인공 지능(AI)을 사용하여 비디오를 위한 특이한 음악 조각을 생성하는 것으로 미국 특허 제 9,361,869 호에 개략적으로 기술되어 있다. Scorify 시스템은 비디오 창작자가 자신의 비디오에 컴퓨터 생성 음악을 추가 할 수 있도록 한다. Scorify 시스템은 그 시스템과 함께 사용될 수 있는 미리 제작된 비디오의 길이에 제한이 있다. Scorify의 유일한 사용자 입력은 기본 스타일/장르 기준이다. 현재, Scorify의 이용가능한 스타일은, 선 택적 서브 스타일 악기 지정 및 개괄적 음악 템포 안내와 함께, 테크노, 재즈, 블루스, 8비트 및 심플이다. 특 정 악기와 템포 지정을 선택하도록 사용자에게 요구하기 때문에, Scorify 시스템에서는 본질적으로 그 사용자가 클래식 음악 용어를 이해하고, 이에 한정되지는 않지만, 오케스트라 및 합성 악기, 음향 효과 및 음파 생성기를 포함하는 각각의 가능한 악기 또는 소리/오디오 생성기를 식별할 수 있어야 한다. Scorify 시스템은 시스템에 의해 생성될 음악 조각과 관련하여 임의의 사용자가 자신의 욕구 및/또는 의도를 통 신할 수 있도록 하는 충분한 준비가 부족하다. 또한, Scorify 시스템에 의해 지원되는 개별 악기의 오디오 품질 이 여전히 전문적인 기준보다 훨씬 낮다. 또한, Scorify 시스템은 사용자가 비디오와 관계없는 음악을 생성하거나, 비디오 이외의 다른 미디어를 위한 음 악을 생성하거나, 함께 생성된 콘텐츠와 관계없는 비디오와 함께 생성된 음악을 저장 또는 액세스하는 것을 허 용하지 않는다. Scorify 시스템이 시장의 문제에 대해 매우 기본적이고 제한된 해결책을 제공하는 것처럼 보이지만, 이 시스템 은 사용자 별로 그리고/또는 사용자 전체에 걸쳐 학습하고 개선할 능력이 없다. 또한, Scorify 시스템 및 음악 전달 메커니즘은 창작자가 자신의 욕구를 정확하게 반영하는 콘텐츠를 제작할 수 있도록 하기에는 불충분하며, 생성된 음악이 존재하게 되면, 생성된 음악을 수동 또는 자동으로 편집하거나 개선할 방법이 없다. SmartSound의 SonicFire Pro 시스템의 개요 미국 사우스 캐롤라이나의 뷰포트 외곽에 위치한 SmartSound의 SonicFire Pro 시스템은 사용자가 자신의 비디오 콘텐츠를 위해 미리 제작된 음악을 구매하여 사용할 수 있도록 한다. 웹 기반 및 데스크탑 기반 애플리케이션으 로서 현재 이용가능한 SonicFire Pro 시스템은 그 사용자를 위한 제한된 커스터마이징성 옵션과 함께 미리 제작 된 음악을 사용하는 스톡 뮤직 라이브러리(Stock Music Library)를 제공한다. 특정 악기와 볼륨 지정을 선택하 도록 사용자에게 요구하기 때문에, SonicFire Pro 시스템에서는 본질적으로 그 사용자가 (i) 이에 한정되지는 않지만, 오케스트라 및 합성 악기, 음향 효과 및 음파 생성기를 포함하는 각각의 가능한 악기 또는 소리/오디오 생성기를 식별할 수 있고, (ii) 각 개별 악기가 음악 조각에서 모든 다른 악기와 어떻게 균형을 이루어야 하는 지에 대한 전문적인 지식을 보유할 수 있는 능력이 필요하다. 음악이 미리 제작되기 때문에, 각각의 음악 조각 에 대해 제한된 \"변주곡\" 옵션이 존재한다. 또한, 각각의 음악 조각이 각 사용자에 대해 유기적으로(즉, 음표 단위 및/또는 화음 단위로) 제작되지 않기 때문에, 사용자에게 제공되는 음악의 양이 유한하다. 이 프로세스는 비교적 힘들며, 미리 제작된 음악 조각을 선택하고, 제한된 최적화성 기능을 추가한 다음, 그 음악 조각의 길이 를 지정하는 데 상당한 시간이 소요된다. SonicFire Pro 시스템은 제작될 수 있는 콘텐츠의 양에 의해 제한된 시장에 해결책을 제시하는 것과 더불어, 미 리 제작된 음악이 경제적인 생계 유지의 이유로 감당할 수 없는 가격 아래의 최저 가격을 제시할 것으로 보인다. 또한, 콘텐츠의 제한된 공급으로 인해, 각 사용자에 대한 음악의 특이성과 완벽한 커스터마이징성이 부 족하다. SonicFire Pro 시스템은 사용자 별로 그리고/또는 사용자 전체에 걸쳐 자체 학습하거나 개선할 능력이 없다. 또한, 이전에 제작된 음악을 발견하여 통합하기 위해 소프트웨어를 사용하는 프로세스는 상당한 시간이 소요될 수 있으며, 그 결과로 발견된 음악은 이전에 제작된 음악을 사용함으로써 생길 가능성이 높은 엄격한 라 이센스 및 법적 요건에 의해 여전히 제한을 받는다. 기타 Stock Music Library Stock Music Library는 라이센스를 위해 사용할 수 있는, 대개 온라인상에서 이용 가능한 미리 제작된 음악의 집합이다. 이와 같은 Music Library에서, 미리 제작된 음악은 일반적으로 사용자가 키워드로 음악 조각을 검색 할 수 있도록 하기 위해 관련 디스크립터로 태그되어 있다. 가장 눈에 띄는 것은, 모든 (때로는 \"로열티 프리 뮤직\"이라고도 지칭되는) 스톡 뮤직이 미리 제작된다는 것과, 그 음악의 제작에 모든 사용자 입력이 부족하다는 것이다. 사용자는 자신의 콘텐츠에 적절한 음악 조각을 발견하기 전에 수백 개 또는 수천 개가 될 수 있는 개별 오디오 트랙을 브라우징하여야 한다. SmartSound의 SonicFire Pro 시스템과 매우 유사한 특징, 기능, 한계, 단점 및 결함을 포함하거나 나타내는 Stock Music의 추가적인 예에는, 예컨대, 오디오 소켓(Audio Socket), 프리 뮤직 아카이브(Free Music Archive), 프랜들리 뮤직(Friendly Music), 럼블 피쉬(Rumble Fish), 및 뮤직 베드(Music Bed)가 포함된다. 적합한 음악을 발견하기까지의 시간의 길이, 콘텐츠에 음악을 통합하기 위한 라이센스 프로세스와 비용, 및 유 연성 없는 전달 옵션(흔히, 싱글 스테레오 오디오 파일)이 심하게 부적절한 해결책으로서 역할하기 때문에, 전 술한 종래 기술은 상품 음악에 대한 시장의 요구에 오직 부분적으로만 대응하고 있다. 또한, 일정 수준의 음악 이론 배경 및/또는 교육이 필요하기 때문에, 현재의 시스템을 잠재력을 최대한으로 사 용하고자 하는 모든 콘텐츠 창작자에게는 한층 더 추가적인 훈련이 필요하게 된다. 또한, 전술한 종래 기술의 시스템은, 이들이 다른 사람들에 의해 사용될 때 학습하거나, 적응하거나, 자체 개선 하지 않으며, 전문 작곡가와 함께 작업하는 경험의 그것과 필적하는 \"세심한\" 서비스를 거의 제공하지 않는 정 적 시스템이다. 따라서, 종래 기술과 그 단점 및 결함을 감안하면, 종래 기술의 시스템, 방법 및 기술이 가진 결함과 단점을 극 복하면서, 제안되거나 필요한 경우가 있을 때, 이벤트, 조직, 브랜드, 가족 등을 지원하고/또는 축하할 뿐만 아 니라, 다양한 미디어 제품에 스코어링하는 데 사용하기 위한 음악 조각을, 어떤 음악적 지식, 이론 또는 전문 지식이 없어도, 다른 정보 시스템은 물론 개인이 자동으로 작곡하고 생성할 수 있도록 하는 것을 가능하게 하는 새롭고 개선된 정보 프로세싱 시스템과 방법에 대한 큰 요구가 당업계에 존재한다."}
{"patent_id": "10-2018-7011569", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "따라서, 본 발명의 주된 목적은 음악 이론이나 연습에 대한 어떤 지식 또는 전문 음악 지식이나 기타 창의적 노 력이 없어도, 이에 한정되지는 않지만, 모든 오브젝트, 엔티티 및/또는 이벤트뿐만 아니라 비디오, 사진, 슬라 이드 쇼 및 기존 오디오 포멧을 포함한 모든 종류의 미디어 콘텐츠에 동기화되는 필요 조건이 아닌 옵션을 가진 특이한 전문가 품질의 음악을 누구나 즉각 생성할 수 있도록 하는 새롭고 개선된 자동화된 음악 작곡 및 생성 시스템 및 기계 및 정보 프로세싱 아키텍처를 제공하는 것이다. 본 발명의 다른 목적은, 시스템 사용자는 본 발명의 자동화된 작곡 및 생성 시스템에 의해 궁극적으로 작곡될 음악 조각에 음악적으로 표현될 자신의 감정 및/또는 예술적 개념에 대한 지식만 있으면 되는, 그와 같은 자동 화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 음악을 생성하고, 전문 미디어 작곡가의 전통적인 작곡 프로세스를 완전히 변경 및 증 진시키기 위한 새로운 프로세스를 지원하는 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 음악 조각을 제작하는 데 필요한 모든 음악적 및 비음악적 결정을 직관적으로 수행하며, 작곡 프로세스를 학습하고 코드화하여, 가장 복잡하고 창조적인 인간의 노력 중 하나인 음악의 작곡 및 생성을 대폭 개선하는, 계속하여 학습하고 진화하는 시스템으로 형식화하는 자동화된 음악 작곡 및 생성 시 스템을 사용하여 음악을 생성하는, 새로운 프로세스를 제공하는 것이다. 본 발명의 다른 목적은, 모든 비교 또는 경쟁 범위에 걸쳐 전문 음악 작곡가의 그것에 필적하는 음악을 자동으 로 작곡 및 생성하기 위해, 시스템 사용자에 의해 제공되는 음악적 경험 디스크립터와 시공간(T&S) 파라미터에 의해 구동되는 자동화된 가상 악기 음악 합성 기술을 사용하여 음악을 작곡 및 생성하는 새로운 프로세스를 제공하는 것이다. 본 발명의 다른 목적은, 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이며, 시스템의 음악적 정신 및 지능 은 본 발명의 정보 프로세싱 원리에 따라 시스템 내에서 지원되는 전문화된 정보 세트, 구조 및 프로세스에 내 장된다. 본 발명의 다른 목적은, 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이며, 시스템의 음악 정신 및 메모리 가 한 개인의 지적 및/또는 정서적 능력으로 제한되는 것이 아니라 시스템을 사용하며 상호 작용하게 되는 모든 사람들의 변형력에 응답하여 성장할 여지가 있도록, 사용자 전체 집단뿐만 아니라 개별 사용자를 포함할 수 있 는 시스템 사용자와의 상호 작용에 응답하여 시스템의 음악 정신이 시간이 지남에 따라 변형, 적응 및 진화할 수 있도록 자동화된 학습 능력이 제공된다. 본 발명의 다른 목적은, 매우 빠른 음악 생성과 매우 높은 제품 기능성을 제공하는 매우 직관적이고 자연스러우 며 사용이 용이한 그래픽 인터페이스(GUI)를 지원하는 새롭고 개선된 자동화된 음악 작곡 및 생성 시스템을 제 공하는 것이다. 본 발명의 다른 목적은, 이에 한정되지는 않지만, 텍스트, 이미지, 언어, 음성, 메뉴 선택, 시간, 오디오 파일, 비디오 파일 또는 기타 디스크립팅 메커니즘을 포함한 사용자에게 자연스러운 방식으로 사용자가 음악을 통해 전하고자 하는 것, 및/또는 바람직한 음악 스타일, 및/또는 바람직한 음악 타이밍, 및/또는 이들 3가지 입력 카 테고리들 중 어느 하나, 쌍 또는 다른 조합을 시스템 사용자가 기술할 수 있도록 하는 새롭고 개선된 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 시스템 사용자에 의해 제공되는 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크 립터에 의해 구동되는 자동화된 가상 악기 음악 합성을 지원하는 자동화된 음악 작곡 및 생성 프로세스를 제공 하는 것이며, 언어 기반 음악적 경험 디스크립터와 비디오, 오디오 레코딩, 이미지, 또는 이벤트 마커는 시스템 사용자 인터페이스를 통해 입력으로서 제공되고, 본 발명의 자동화된 음악 작곡 및 생성 엔진에 의해 사용되어, 가상 악기 음악 합성을 이용하여 음악적으로 스코어링된 미디어(예컨대, 비디오, 팟 캐스트, 이미지, 슬라이드 쇼 등) 또는 이벤트 마커를 생성시키며, 이들은 시스템 사용자 인터페이스를 통해 시스템 사용자에게 다시 제공 된다. 본 발명의 다른 목적은, 시스템 사용자에 의해 제공되는 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크 립터에 의해 구동되는 자동화된 가상 악기 음악 합성의 사용을 지원하는 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이며, (i) 프로세스의 제1단계에서, 시스템 사용자는 자동화된 음악 작곡 및 생성 시스템에 액세스 한 다음, 자동화된 음악 작곡 및 생성 시스템에 의해 생성된 스코어링될 비디오, 오디오 레코딩(예컨대, 팟 캐 스트), 슬라이드 쇼, 사진이나 이미지 또는 이벤트 마커를 선택하고, (ii) 그 다음, 시스템 사용자는 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 그 자동화된 음악 작곡 및 생성 엔진에 제공하며, (iii) 시스템 사용자는 자동화된 음악 작곡 및 생성 시스템을 기동하여 시스템 사용자에 의해 선택된 미디어 또는 이벤트 마 커에 스코어링되어 있는(즉, 적용되어 있는) 입력된 음악적 디스크립터에 기초한 자동화된 가상 악기 음악 합성 방법을 사용하여 음악을 작곡 및 생성하며, (iv) 시스템 사용자는 스코어링된 미디어 또는 이벤트 마커에 대해 제작된 작곡 및 생성된 음악을 수용하고, 시스템 사용자가 주관적으로 경험하여 형성된 음악적 경험을 고려하여 제작된 음악에 대한 시스템 사용자의 평가 및/또는 음악 선호도에 관한 피드백을 시스템에 제공하며, (v) 시스 템은 수용한 작곡된 음악을 선택된 미디어 또는 이벤트 마커와 조합하여, 분배 및 표시/공연하기 위한 비디오 파일을 제작한다. 본 발명의 다른 목적은, 상상할 수 있는 거의 모든 사용자 애플리케이션에서 사용될 수 있는 콤팩트한 휴대용 하우징 내에 제공된 텍스트 키보드 및/또는 음성 인식 인터페이스를 사용하여 생성된 언어 기반 음악적 경험 디 스크립터에 의해 구동되는 자동화된 가상 악기 음악 합성을 지원하는 자동화된 음악 작곡 및 생성 악기 시스템 을 제공하는 것이다. 본 발명의 다른 목적은, 장난감 악기로 연주하는 어린이 또는 성인에 의해 선택된 아이콘 기반 음악적 경험 디 스크립터에 의해 구동되는 자동화된 가상 악기 음악 합성을 지원하는 자동화된 음악 작곡 및 생성 엔진을 지원 하는 장난감 악기를 제공하는 것이며, 장난감 악기의 저장 장치 내에 유지된 비디오 라이브러리로부터 또는 로 컬 또는 인터넷에 연결된 원격 비디오 파일 서버로부터 시스템 사용자가 비디오를 선택하여 로드하도록 터치 스 크린 디스플레이가 제공되며, 그 다음, 어린이는 물리적 또는 가상 키보드 또는 시스템 인터페이스 등으로부터 음악적 경험 디스크립터(예컨대, 감정 디스크립터 아이콘 및 스타일 디스크립터 아이콘)를 선택할 수 있음으로써, 하나 이상의 어린이가 선택된 비디오의 하나 이상의 분절된 장면에 대해 지정 음악을 작곡 및 생성할 수 있 게 된다. 다른 목적은 자동화된 장난감 음악 작곡 및 생성 악기 시스템을 제공하는 것이며, 그래픽 아이콘 기반 음악적 경험 디스크립터와 비디오가 자동화된 장난감 음악 작곡 및 생성 악기 시스템의 시스템 사용자 인터페이스(즉, 터치 스크린 키보드)를 통해 입력으로서 선택되고, 그 자동화된 음악 작곡 및 생성 엔진에 의해 사용되어, 재생 및 시청을 위해 시스템 사용자 인터페이스를 통해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된 비 디오 스토리를 자동으로 생성한다. 본 발명의 다른 목적은, 그 시스템 사용자의 창조적 및/또는 오락적 요구를 지원하기 위해 그 전자 정보 프로세 싱 및 디스플레이 시스템 아키텍처 내에 SOC 기반의 자동화된 음악 작곡 및 생성 엔진을 통합한 전자 정보 프로 세싱 및 디스플레이 시스템을 제공하는 것이다. 본 발명의 다른 목적은 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 자동화된 가 상 악기 음악 합성을 지원하는 SOC 기반 음악 작곡 및 생성 시스템을 제공하는 것이며, 언어 기반 음악적 경험 디스크립터와 비디오, 오디오 파일, 이미지, 슬라이드 쇼 또는 이벤트 마커는 시스템 사용자 인터페이스를 통해 입력으로서 제공되고, 자동화된 음악 작곡 및 생성 엔진에 의해 사용되어 시스템 사용자 인터페이스를 통해 시 스템 사용자에게 다시 제공되는 음악적으로 스코어링된 미디어(예컨대, 비디오, 팟 캐스트, 이미지, 슬라이드 쇼 등) 또는 이벤트 마커를 생성시킨다. 본 발명의 다른 목적은, 인터넷 인프라에 작동 가능하게 연결된 웹 서버, 애플리케이션 서버 및 데이터베이스 (RDBMS) 서버를 갖춘 데이터 프로세싱 센터에 의해 지원되며, 클라이언트 머신, 소셜 네트워크 서버 및 웹 기반 통신 서버에 의해 액세스될 수 있고, 웹 사이트(예컨대, 유튜브, 비메오 등), 소셜 네트워크, 소셜 메시징 네트 워크(예컨대, 트위터) 및 기타 인터넷 기반 프로퍼티에서 웹 기반 브라우저를 이용하여 누구나 자동화된 음악 작곡 및 생성 서비스에 액세스할 수 있도록 함으로써, 텍스트 키보드 및/또는 음성 인식 인터페이스를 사용하여 생성된 언어 기반 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성 기술을 사용하여 자동으로 작 곡된 음악으로 비디오, 이미지, 슬라이드 쇼, 오디오 파일 및 기타 이벤트을 스코어링할 수 있도록 하는, 기업 수준의 인터넷 기반 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 기업 수준 시스템에 의해 지원되는 자동화된 음악 작곡 및 생성 프로세스를 제공하는 것이며, (i) 프로세스의 제1단계에서, 시스템 사용자는 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 자동화된 음악 작곡 및 생성 시스템에 의해 생성된 음악으로 스코어링될 비디오, 오디오 레코딩(즉, 팟 캐스 트), 슬라이드 쇼, 사진이나 이미지 또는 이벤트 마커를 선택하고, (ii) 그 다음, 시스템 사용자는 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 시스템의 자동화된 음악 작곡 및 생성 엔진에 제공하며, (iii) 시스템 사용자는 자동화된 음악 작곡 및 생성 시스템을 기동하고, 선택된 미디어 또는 이벤트 마커에 스코어링 되어 있는 입력된 음악적 디스크립터에 기초하여 음악을 작곡 및 생성하며, (iv) 시스템 사용자는 스코어링된 미디어 또는 이벤트 마커에 대해 제작된 작곡 및 생성된 음악을 수용하고, 시스템 사용자가 주관적으로 경험하 여 형성된 음악적 경험을 고려하여 제작된 음악에 대한 시스템 사용자의 평가 및/또는 음악 선호도에 관한 피드 백을 시스템에 제공하며, (v) 시스템은 수용한 작곡된 음악을 선택된 미디어 또는 이벤트 마커와 조합하여, 분 배 및 표시하기 위한 비디오 파일을 제작한다. 본 발명의 다른 목적은, 본 발명의 자동화된 음악 작곡 및 생성 엔진을 이용하여 사용자에 의해 작곡된 음악을 추가함으로써 인터넷 상에서 지원되는 텍스트, SMS 및 이메일 서비스를 사용하여 모바일 및 데스크탑 클라이언 트 머신이 증강될 수 있도록 배치된 인터넷 기반의 자동화된 음악 작곡 및 생성 플랫폼과, 이와 같은 텍스트, SMS 및 이메일 메시지를 위한 작곡된 음악 조각을 생성하는 데 사용하기 위해 사용자가 그래픽 및/또는 언어 기 반 감정 및 스타일 디스크립터를 쉽게 선택할 수 있도록 텍스트, SMS 및/또는 이메일 문서(즉, 메시지)를 제작 할 때 클라이언트 머신에 의해 지원되는 그래픽 사용자 인터페이스를 제공하는 것이다. 본 발명의 다른 목적은, 본 발명의 자동화된 음악 작곡 및 생성 엔진을 지원하는 시스템 네트워크에 배치된 모 바일 클라이언트 머신(예컨대, 인터넷이 가능한 스마트 폰 또는 태블릿 컴퓨터)이며, 클라이언트 머신은 터치 스크린 인터페이스, 메모리 아키텍처, 중앙처리장치, 그래픽 프로세서, 인터페이스 회로, 다양한 통신 프로토콜 을 지원하는 네트워크 어댑터, 및 현대 스마트 폰 장치(예컨대, 애플의 아이폰, 삼성의 안드로이드 갤럭시 등) 에서 기대되는 기능을 지원하는 기타 기술을 가진 모바일 컴퓨팅 머신으로서 실현되고, 웹 기반(즉, html) 문서 의 생성과, 메뉴 스크린으로부터 언어 및/또는 그래픽 아이콘 기반 감정 디스크립터 및 스타일 디스크립터를 선 택하여 생성된 작곡 음악 조각의 생성 및 삽입을 지원하는 가상 키보드를 사용자에게 제공하는 클라이언트 애플리케이션이 가동하고 있음으로써, 음악 조각이 내장된 URL 상에서 동작하는 통상의 웹 브라우저를 사용하여 원 격 클라이언트에게 전달되어 경험될 수 있고, 이로부터 내장된 음악 조각은 웹, 애플리케이션 및 데이터베이스 서버를 통해 서비스된다. 본 발명의 다른 목적은, 작곡된 음악을 텍스트, SMS, 이메일 문서/메시지에 추가하기 위해 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 자동화된 가상 악기 음악 합성의 사용을 지원하는 인터넷 기반의 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이며, 언어 기반 또는 아이콘 기반 음악적 경험 디스 크립터가 시스템 사용자 인터페이스를 통해 입력으로서 시스템 사용자에 의해 제공되고, 자동화된 음악 작곡 및 생성 엔진에 의해 사용되어 최종 마무리 및 전송 전에 시스템 사용자 인터페이스를 통해 시스템 사용자에 의한 미리보기를 위해 생성되는 음악적으로 스코어링된 텍스트 문서 또는 메시지를 생성한다. 본 발명의 다른 목적은, 음악적으로 스코어링된 텍스트, SMS, 이메일, PDF, 워드 및/또는 HTML 문서를 자동적이 고 즉각적으로 생성하기 위해 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 자동 화된 가상 악기 음악 합성의 사용을 지원하는 웹 기반 시스템을 사용한 자동화된 음악 작곡 및 생성 프로세스를 제공하는 것이며, (i) 프로세스의 제1단계에서, 시스템 사용자는 자동화된 음악 작곡 및 생성 시스템에 액세스 한 다음, 자동화된 음악 작곡 및 생성 시스템에 의해 생성된 음악으로 스코어링될(예컨대, 증강될) 텍스트, SMS 또는 이메일 메시지 또는 워드, PDF 또는 HTML 문서를 선택하고, (ii) 그 다음, 시스템 사용자는 언어 기반 및/ 또는 아이콘 기반 음악적 경험 디스크립터를 시스템의 자동화된 음악 작곡 및 생성 엔진에 제공하며, (iii) 시 스템 사용자는 자동화된 음악 작곡 및 생성 시스템을 기동하여 선택된 메시지 또는 문서에 스코어링되어 있는 입력된 음악적 디스크립터에 기초한 음악을 작곡하며, (iv) 시스템 사용자는 메시지 또는 문서에 대해 제작된 작곡 및 생성된 음악을 수용하거나, 음악을 거부하고 다른 음악적 경험 디스크립터의 제공 및 갱신된 음악적 경 험 디스크립터 입력에 기초하여 음악을 재작곡하도록 하는 요구를 포함한 피드백을 시스템에 제공하며, (v) 시 스템은 수용한 작곡된 음악을 메시지 또는 문서와 조합하여, 분배 및 표시하기 위한 새로운 파일을 제작한다. 본 발명의 다른 목적은, 자동화된 음악 작곡 및 생성 엔진의 변형된 버전을 채택하여 실제 및/또는 합성 음악 악기 세트를 연주하는 인간 음악가 밴드에서 사용하기 위한 AI 기반 자율 음악 작곡, 생성 및 연주 시스템을 제 공하는 것이며, AI 기반 시스템은 주변 악기 및 음악가로부터 음악 신호를 수신하여 이들 악기를 버퍼링 및 분 석하고, 이에 응답하여, 음악가 밴드에 의해 연주되고 있는 음악을 증강하게 될 음악을 실시간으로 작곡 및 생 성할 수 있거나, 인간 음악가에 의한 후속 재생, 검토 및 심의를 위해 기록되는 음악을 녹음, 분석 및 작곡할 수 있다. 본 발명의 다른 목적은, LCD 터치 타입 디스플레이 스크린, 내장형 스테레오 마이크 세트, 시스템 환경 내의 음 악 악기 세트로부터 생성되는 오디오 신호를 수신하기 위한 오디오 신호 입력 커넥터 세트, 시스템 환경 내의 악기 세트로부터 MIDI 입력 신호를 수신하기 위한 MIDI 신호 입력 커넥터 세트, 오디오 출력 신호를 오디오 신 호 전치 증폭기 및/또는 증폭기로 전달하기 위한 오디오 출력 신호 커넥터, WIFI 및 BT 네트워크 어댑터 및 관 련 신호 안테나 구조, 및 사용자 작동 모드를 위한 기능 버튼 세트를 포함한 콤팩트하고 견고한 휴대용 하우징 을 가진 자율적 음악 분석, 작곡 및 연주 악기를 제공하는 것이며, 사용자 작동 모드는 (i) 악기 시스템이 음악 세션 중에 그 (로컬 또는 원격) 음악 환경으로부터 수신하여 분석한 음악 정보 스트림에 응답하여 음악적으로 자율적으로 선도하는 LEAD 모드, (ii) 악기 시스템이 음악 세션 중에 그 (로컬 또는 원격) 음악 환경 내의 음악 악기로부터 수신하여 분석한 음악에 응답하여 음악적으로 자율적으로 추종하는 FOLLOW 모드, (iii) 시스템이 음 악 세션 중에 그 (로컬 또는 원격) 환경 내의 음악 악기로부터 수신하여 분석한 음악에 기초하여 음악을 자동으 로 작곡하는 COMPOSE 모드, 및 (iv) 시스템이 음악 세션 중에 그 환경으로부터 수신하여 분석한 음악 정보에 응 답하여 자동으로 작곡된 음악을 실시간으로 자율적으로 연주하는 PERFORM 모드를 포함한다. 본 발명의 다른 목적은, 자동화된 음악 작곡 및 생성 악기 시스템을 제공하는 것이며, MIDI 입력 신호뿐만 아니 라 오디오 신호가 시스템 환경 내의 음악 악기 세트로부터 생성되어 악기 시스템에 의해 수신되고, 이 신호들이 피치 이벤트 및 멜로디 및 리듬 구조의 발생에 대하여 시간 및/또는 주파수 도메인에서 실시간으로 분석됨으로 써, 시스템은 본 발명의 자동화된 음악 작곡 및 생성 엔진을 사용한 자동화된 음악 작곡 및 생성의 생성에 사용"}
{"patent_id": "10-2018-7011569", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "하기 위해 이 정보로부터 음악적 경험 디스크립터를 자동으로 요약할 수 있다. 본 발명의 다른 목적은, 시스템을 사용한 자동화된 음악 작곡 및 생성 프로세스를 제공하는 것이며, (i) 프로세 스의 제1단계에서, 시스템 사용자는 자동화된 음악 작곡 및 생성 악기 시스템에 대해 LEAD 또는 FOLLOW 작동 모 드 중 하나를 선택하고, (ii) 그 다음, 세션에 앞서, 시스템은 음악 세션 중의 창조적 환경에서 음악가 그룹에 의해 연주되는 음악 악기 그룹과 인터페이스되며, (iii) 세션 중에, 시스템은 세션 중에 악기 그룹으로부터 생성된 오디오 및/또는 MIDI 데이터 신호를 수신하고, 이 신호들을 피치 및 리듬 데이터 및 멜로디 구조에 대하여"}
{"patent_id": "10-2018-7011569", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "분석하며, (iv) 세션 중에, 시스템은 요약된 피치, 리듬 및 멜로디 데이터로부터 음악적 디스크립터를 자동으로 생성하고, 음악적 경험 디스크립터를 사용하여 실시간 단위로 각 세션을 위한 음악을 작곡하며, (v) PERFORM 모 드가 선택된 경우, 시스템은 세션을 위해 작곡된 음악을 자동으로 생성하고, COMPOSE 모드가 선택된 경우, 세션 중에 작곡된 음악이 음악가 그룹에 의한 후속 액세스 및 검토를 위해 저장된다. 본 발명의 다른 목적은, 시스템 사용자가 본 발명의 원리에 따라 작곡된 음악으로 감정적으로 스코어링될 비디 오 내의 하나 이상의 장면에 가사를 더 적용할 수 있도록, 텍스트 키보드 및/또는 음성 인식 인터페이스를 사용 하여 생성된 언어 기반 음악적 경험 디스크립터 및 가사(LYRIC) 또는 단어 디스크립터의 사용과 가상 악기 음악 합성을 지원하는 신규한 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 시스템 버스 아키텍처 주변에 집적된 멀티 코어 CPU, 멀티 코어 GPU, 프로그램 메모리 (DRAM), 비디오 메모리(VRAM), 하드 드라이브, LCD/터치 스크린 디스플레이 패널, 마이크/스피커, 키보드, WIFI/블루투스 네트워크 어댑터, 피치 인식 모듈/보드, 및 전원 공급 장치 및 분배 회로와 같은 다양한 구성 요 소를 나타내는 실제 또는 가상 키보드 인터페이스로 시스템 사용자에 의해 선택된 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성을 지원하는 그와 같은 자동화된 음악 작곡 및 생성 시스 템을 제공하는 것이다. 본 발명의 다른 목적은, 가사 입력 및 기타 미디어(예컨대, 비디오 레코딩, 라이브 비디오 방송, 비디오 게임, 슬라이드 쇼, 오디오 레코딩 또는 이벤트 마커)를 포함한 언어 및/또는 그래픽 기반 음악적 경험 디스크립터가 시스템 사용자 인터페이스(즉, 터치 스크린 키보드)를 통해 입력으로서 선택되고, 미디어는 (예컨대, 장면 이미 지 및/또는 정보 콘텐츠에 기초하여) 음악적 경험 디스크립터를 추출하기 위해 시스템에 의해 자동으로 분석될 수 있으며, 그 후, 시스템 사용자 인터페이스 또는 기타 수단을 통해 시스템 사용자에게 다시 제공되는 음악적 으로 스코어링된 미디어를 생성하기 위해 그 자동화된 음악 작곡 및 생성 엔진에 의해 사용되는, 그와 같은 자 동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 본 발명의 음악 작곡 및 생성 프로세스 중에 시스템 내의 시스템 작동 파라미터를 변경 하기 위해 사용되는 자동으로 포착된 데이터에 대해 실시간 피치 이벤트, 리듬 및 운율 분석이 실시되는 서브 시스템에 시스템 사용자에 의해 제공된 타이핑되거나, 말로 전해지거나 또는 노래 불려진 단어를 전송하기 위해 시스템 사용자 인터페이스가 제공되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 주요 단계는 언어 음악적 경험 디스크립터, (선택적으로는 가사 입력) 및 가상 악기 음 악 합성의 사용 지원을 포함하고, (i) 프로세스의 제1단계에서, 시스템 사용자는 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 그 자동화된 음악 작곡 및 생성 엔진에 의해 생성된 음악으로 스코어링될 미디어를 선 택하고, (ii) 시스템 사용자는 음악적으로 스코어링될 선택된 미디어에 적용하기 위해 시스템의 자동화된 음악 작곡 및 생성 엔진에 제공된 음악적 경험 디스크립터(및 선택적으로는 가사)를 선택하며, (iii) 시스템 사용자 는 자동화된 음악 작곡 및 생성 엔진을 기동하여 선택된 미디어에 스코어링되어 있는 제공된 음악적 디스크립터 에 기초한 음악을 작곡 및 생성하며, (iv) 시스템은 작곡된 음악을 선택된 미디어와 조합하여, 표시 및 향유하 기 위한 복합 미디어 파일을 제작하는, 그와 같은 자동화된 음악 작곡 및 생성 프로세스를 제공하는 것이다. 본 발명의 다른 목적은, 2개의 매우 높은 수준의 \"음악적 랜드스케이프\" 카테고리, 즉, (i) 일반 피치 생성 서 브 시스템(A2), 멜로디 피치 생성 서브 시스템(A4), 오케스트레이션 서브 시스템(A5) 및 컨트롤러 코드 제작 서 브 시스템(A6)을 포함한 피치 랜드스케이프 서브 시스템(C0), 및 (ii) 일반 리듬 생성 서브 시스템(A1), 멜로디 리듬 생성 서브 시스템(A3), 오케스트레이션 서브 시스템(A5) 및 컨트롤러 코드 제작 서브 시스템(A6)을 포함한 리듬 랜드스케이프 서브 시스템으로 분할된 시스템 아키텍처를 포함하는 자동화된 음악 작곡 및 생성 엔진을 제 공하는 것이다. 본 발명의 다른 목적은, 사용자 GUI 기반 입출력 서브 시스템(A0), 일반 리듬 서브 시스템(A1), 일반 피치 생성 서브 시스템(A2), 멜로디 리듬 생성 서브 시스템(A3), 멜로디 피치 생성 서브 시스템(A4), 오케스트레이션 서브 시스템(A5), 컨트롤러 코드 제작 서브 시스템(A6), 디지털 조각 제작 서브 시스템(A7) 및 피드백 및 학습 서브 시스템(A8)을 포함한 시스템 아키텍처를 포함하는 자동화된 음악 작곡 및 생성 엔진을 제공하는 것이다. 본 발명의 다른 목적은, 함께 집적된 복수의 서브 시스템을 포함한 자동화된 음악 작곡 및 생성 시스템을 제공 하는 것이며, 사용자 GUI 기반 입출력 서브 시스템(B0)은 시스템 내의 다양한 서브 시스템에 유지된 테이블에 분배 및 로드된 확률 기반 시스템 작동 파라미터로의 프로세싱 및 변환과 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 후속 서브 시스템의 설립 및 사용을 위해 디스크립터 파라미터 포착 서브 시스템(B1)에 전송 하기 위한 하나 이상의 음악적 경험 디스크립터를 시스템 사용자가 선택할 수 있도록 한다. 본 발명의 다른 목적은, 함께 집적된 복수의 서브 시스템을 포함한 자동화된 음악 작곡 및 생성 시스템을 제공 하는 것이며, 디스크립터 파라미터 포착 서브 시스템(B1)은 그 내부의 다양한 서브 시스템에 유지된 파라미터 테이블에 분배하기 위한 확률 기반 시스템 작동 파라미터 세트를 생성하기 위해 선택된 음악적 경험 디스크립터 를 수신 및 프로세싱하기 위한 사용자 GUI 기반 입출력 서브 시스템과 인터페이스된다. 본 발명의 다른 목적은, 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이며, 스타일 파라미터 포착 서브 시 스템(B37)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 시스템 사용자는 그 내부의 다양한 서브 시스템에 분배되는 확률 기반 파라미터 테이블을 생성하기 위한 파라미터 변환 엔진 내에서의 프로세싱 및 변환과 본 발 명의 자동화된 음악 작곡 및 생성 프로세스 중에 후속 서브 시스템의 설립 및 사용을 위해 스타일 파라미터 포 착 서브 시스템에 예시적인 \"스타일 타입\" 음악적 경험 디스크립터-예컨대, 팝을 제공한다. 본 발명의 다른 목적은, 타이밍 파라미터 포착 서브 시스템(B40)은 자동화된 음악 작곡 및 생성 엔진에 사용되 고, 타이밍 파라미터 포착 서브 시스템(B40)은 시스템 내의 다양한 서브 시스템으로의 분배와 본 발명의 자동화 된 음악 작곡 및 생성 프로세스 중에 후속 서브 시스템의 설립 및 사용을 위해 타이밍 생성 서브 시스템(B41)에 타이밍 파라미터를 제공하는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 파라미터 변환 엔진 서브 시스템(B51)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 음악적 경험 디스크립터 파라미터 및 타이밍 파라미터 서브 시스템은 시스템 사용자에 의해 제공된 타이밍 신호 파라미터와 사용자가 제공한 음악적 경험 디스크립터의 특정 세트에 대해 생성된 확률 기반 시스템 작동 파라미 터 세트로 자동 변환되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 타이밍 생성 서브 시스템(B41)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 타이밍 파라미터 포착 서브 시스템(B40)은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 생성될 (i) 작곡될 조 각의 길이, (ii) 음악 조각의 시작, (iii) 음악 조각의 정지, (iv) 음악 조각의 볼륨 증가 및 (v) 음악 조각에 서의 악센트와 관련한 타이밍 정보를 생성하기 위해 타이밍 생성 서브 시스템(B41)에 타이밍 파라미터(예컨대, 조각의 길이)를 제공하는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 길이 생성 서브 시스템(B2)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 시스템 사 용자에 의해 특정된 조각의 시간 길이가 길이 생성 서브 시스템(B2)에 제공되며, 이 서브 시스템은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 작곡될 음악 조각의 시작 및 정지 위치를 생성하는, 그와 같은 자동 화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 템포 생성 서브 시스템(B3)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 조각의 템 포(즉, BPM)는 이 서브 시스템에 제공된 조각 시간 길이 및 음악적 경험 파라미터에 기초하여 연산되며, 도출된 템포는 분당 비트(BPM) 단위로 측정되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 박자 생성 서브 시스템(B4)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 조각의 박 자는 이 서브 시스템에 제공된 조각 시간 길이 및 음악적 경험 파라미터에 기초하여 연산되며, 도출된 템포는 분당 비트(BPM) 단위로 측정되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자 동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 키(Key) 생성 서브 시스템(B5)은 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되 고, 조각의 키는 시스템에 제공된 음악적 경험 파라미터에 기초하여 연산되며, 도출된 키는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 선택되어 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하 는 것이다. 본 발명의 다른 목적은, 비트 계산기 서브 시스템(B6)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 조각의 비트 수는 시스템에 제공된 조각 길이와 시스템에 의해 연산된 템포에 기초하여 연산되며, 도출된 비트 수는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 마디 계산기 서브 시스템(B8)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 조각의 마디 수는 조각의 비트 수와 조각의 연산된 박자에 기초하여 연산되며, 조각의 박자는 본 발명의 자동화된 음악작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 조성 생성 서브 시스템(B7)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 조각의 조 성는 서브 시스템 내에 유지된 확률 기반 조성 파라미터 테이블과 시스템 사용자에 의해 시스템에 제공된 음악 적 경험 디스크립터를 이용하여 선택되며, 선택된 조성는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 노래 형태 생성 서브 시스템(B9)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 노래 형태는 서브 시스템 내에 유지된 확률 기반 노래 형태 하위 악절 파라미터 테이블과 시스템 사용자에 의해 시스 템에 제공된 음악적 경험 디스크립터를 이용하여 선택되며, 선택된 노래 형태는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 하위 악절 길이 생성 서브 시스템(B15)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 하위 악절 길이는 서브 시스템 내에 유지된 확률 기반 하위 악절 길이 파라미터 테이블과 시스템 사 용자에 의해 시스템에 제공된 음악적 경험 디스크립터를 이용하여 선택되며, 선택된 하위 악절 길이는 본 발명 의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공 하는 것이다. 본 발명의 다른 목적은, 화음 길이 생성 서브 시스템(B11)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 화 음 길이는 서브 시스템 내에 유지된 확률 기반 화음 길이 파라미터 테이블과 시스템 사용자에 의해 시스템에 제 공된 음악적 경험 디스크립터를 이용하여 선택되며, 선택된 화음 길이는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 특이 하위 악절 생성 서브 시스템(B14)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 특이 하위 악절은 서브 시스템 내에 유지된 확률 기반 특이 하위 악절 파라미터 테이블과 시스템 사 용자에 의해 시스템에 제공된 음악적 경험 디스크립터를 이용하여 선택되며, 선택된 특이 하위 악절은 본 발명 의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공 하는 것이다. 본 발명의 다른 목적은, 하위 악절 내 화음 수 계산 서브 시스템(B16)은 자동화된 음악 작곡 및 생성 엔진에 사 용되고, 하위 악절 내 화음 수는 연산된 특이 하위 악절을 사용하여 계산되며, 하위 악절 내 화음 수는 본 발명 의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공 하는 것이다. 본 발명의 다른 목적은, 악절 길이 생성 서브 시스템(B12)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 악 절 길이는 악절 길이 분석기를 이용하여 측정되며, 악절 길이(마디의 수)는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 특이 악절 생성 서브 시스템(B10)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 특 이 악절의 수는 악절 분석기를 이용하여 결정되며, 특이 악절의 수는 본 발명의 자동화된 음악 작곡 및 생성 프 로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 악절 내 화음 수 계산 서브 시스템(B13)은 자동화된 음악 작곡 및 생성 엔진에 사용되 고, 악절 내 화음 수가 결정되며, 악절 내 화음 수는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사 용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 제1 일반 리듬 생성 서브 시스템(B17)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 제1 화음은 제1 화음 밑음 테이블, 화음 기능 테이블 및 화음 기능 조성 분석기를 이용하여 결정되며, 제1 화음 은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시 스템을 제공하는 것이다. 본 발명의 다른 목적은, 하위 악절 화음 진행 생성 서브 시스템(B19)은 자동화된 음악 작곡 및 생성 엔진에 사 용되고, 하위 악절 화음 진행은 화음 밑음 테이블, 화음 기능 밑음 변조기 테이블, 현재 화음 기능 테이블 값, 및 비트 밑음 변조기 테이블과 비트 분석기를 이용하여 결정되며, 하위 악절 화음 진행은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 악절 화음 진행 생성 서브 시스템(B18)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 악절 화음 진행은 하위 악절 분석기를 이용하여 결정되며, 개선된 악절은 본 발명의 자동화된 음악작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 화음 자리바꿈 생성 서브 시스템(B20)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 화음 자리바꿈은 제1 화음 자리바꿈 테이블과 화음 자리바꿈 테이블을 이용하여 결정되며, 도출된 화음 자리바 꿈은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 멜로디 하위 악절 길이 생성 서브 시스템(B25)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 멜로디 하위 악절 길이는 확률 기반 멜로디 하위 악절 길이 테이블을 이용하여 결정되며, 도출된 멜 로디 하위 악절 길이는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음 악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 멜로디 하위 악절 생성 서브 시스템(B24)은 자동화된 음악 작곡 및 생성 엔진에 사용되 고, 하위 악절 멜로디 배치는 확률 기반 하위 악절 멜로디 배치 테이블을 이용하여 결정되며, 선택된 하위 악절 멜로디 배치는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 멜로디 악절 길이 생성 서브 시스템(B23)은 자동화된 음악 작곡 및 생성 엔진에 사용되 고, 멜로디 악절 길이는 하위 악절 멜로디 분석기를 이용하여 결정되며, 도출된 멜로디 악절 길이는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하 는 것이다. 본 발명의 다른 목적은, 멜로디 특이 악절 생성 서브 시스템(B22)은 자동화된 음악 작곡 및 생성 엔진에 사용되 고, 특이 멜로디 악절은 특이 멜로디 악절 분석기를 이용하여 결정되며, 도출된 특이 멜로디 악절은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하 는 것이다. 본 발명의 다른 목적은, 멜로디 길이 생성 서브 시스템(B21)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 멜로디 길이는 악절 멜로디 분석기를 이용하여 결정되며, 도출된 악절 멜로디는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 멜로디 음표 리듬 생성 서브 시스템(B26)은 자동화된 음악 작곡 및 생성 엔진에 사용되 고, 멜로디 음표 리듬은 확률 기반 제1 음표 길이 테이블과, 확률 기반 제1, 제2, 및 제n 화음 길이 테이블을 이용하여 결정되며, 도출된 멜로디 음표 리듬은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 제1 피치 생성 서브 시스템(B27)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 제1 피치는 확률 기반 제1 음표 길이 테이블과, 확률 기반 제1, 제2, 및 제n 화음 길이 테이블을 이용하여 결정되며, 도출된 멜로디 음표 리듬은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같 은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 하위 악절 피치 생성 서브 시스템(B29)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 하위 악절 피치는 확률 기반 멜로디 음표 테이블, 확률 기반 화음 변조기 테이블 및 확률 기반 도약 자리바꿈 변조기 테이블을 이용하여 결정되며, 도출된 하위 악절 피치는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 악절 피치 생성 서브 시스템(B28)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 악 절 피치는 하위 악절 멜로디 분석기를 이용하여 결정되며 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 피치 옥타브 생성 서브 시스템(B30)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 피치 옥타브는 확률 기반 멜로디 음표 옥타브 테이블을 이용하여 결정되며, 도출된 피치 옥타브는 본 발명의 자 동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 악기 편성 서브 시스템(B38)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 악기 편 성은 시스템 사용자에 의해 제공된 음악적 경험 디스크립터(예컨대, 스타일 디스크립터)에 기초한 확률 기반 악 기 테이블을 이용하여 결정되며, 악기 편성은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는,그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 악기 선택기 서브 시스템(B39)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 조각 악기 선택은 확률 기반 악기 선택 테이블을 이용하여 결정되며 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 오케스트레이션 생성 서브 시스템(B31)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 서브 시스템에 채택된 확률 기반 파라미터 테이블(즉, 악기 오케스트레이션 우선 순위 결정 테이블, 악기 에너지 테이블, 피아노 에너지 테이블, 악기 기능 테이블, 피아노 손 기능 테이블, 피아노 보이싱 테이블, 피아노 리듬 테이블, 제2 음표 오른손 테이블, 제2 음표 왼손 테이블, 피아노 강약 테이블)은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복-에 대해 설정되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되어 작곡되고 있는 음악 조각의 일부를 생성하는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하 는 것이다. 본 발명의 다른 목적은, 컨트롤러 코드 생성 서브 시스템(B32)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 서브 시스템에 채택된 확률 기반 파라미터 테이블(즉, 악기, 악기 그룹 및 조각 너비 컨트롤러 코드 테이블)은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복-에 대해 설정되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되어 작곡되고 있는 음악 조각의 일부를 생성하는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 디지털 오디오 검색기 서브 시스템(B33)은 자동화된 음악 작곡 및 생성 엔진에 사용되 고, 디지털 오디오(악기 음표) 파일이 검색되어, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되 는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 디지털 오디오 샘플 조직기 서브 시스템(B34)은 자동화된 음악 작곡 및 생성 엔진에 사 용되고, 검색된 디지털 오디오(악기 음표) 파일은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 음악 조각에 따라 정확한 시간 및 공간에 조직되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 조각 통합기 서브 시스템(B35)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 디지털 오디오 파일은 시스템 사용자가 사용을 위해 수용할 수 있는 형태 또는 형태들로 통합 및 조작되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 조각 포맷 번역기 서브 시스템(B50)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 완성된 음악 조각은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 요청된 원하는 대안적인 포맷으로 번 역되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 조각 전달기 서브 시스템(B36)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 디지털 오디오 파일은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 시스템 사용자에게 전달될 디지털 오디오 파일로 조합되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 피드백 서브 시스템(B42)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, (i) 디지털 오디오 파일과 추가적인 조각 포맷은 요청된 조각의 모든 속성이 정확하게 전달되는지를 결정 및 확인하기 위해 분석되며, (ii) 디지털 오디오 파일과 추가적인 조각 포맷은 음악 조각의 특이성을 결정 및 확인하기 위해 분석 되고, (iii) 시스템 사용자는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 오디오 파일 및/또는 추가 적인 조각 포맷을 분석하는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 음악 편집성 서브 시스템(B43)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 시스템 을 다시 시작, 재실행, 변경 및/또는 재생하고자 하는 요청이 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 실행되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 선호도 저장기 서브 시스템(B44)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 음악 적 경험 디스크립터, 파라미터 테이블 및 파라미터는 본 발명의 미래의 자동화된 음악 작곡 및 생성 프로세스 중에 조각이 더 분명히 수신되도록 하기 위해 사용자 및 자율적인 피드백을 반영하도록 변조되는, 그와 같은 자 동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 음악적 커널(예컨대, \"DNA\") 생성 서브 시스템(B45)은 자동화된 음악 작곡 및 생성 엔 진에 사용되고, 음악 조각의 음악적 \"커널\"은 (i) 멜로디(하위 악절 멜로디 음표 선택 순서), (ii) 하모니(즉,악절 화음 진행), (iii) 템포, (iv) 볼륨, 및/또는 (v) 오케스트레이션 측면에서 결정됨으로써, 이 음악 커널은 본 발명의 미래의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될 수 있는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 사용자 취향 생성 서브 시스템(B46)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 시스템 사용자의 음학적 취향은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 음악 작곡을 위한 스타일 및 음악적 경험 디스크립터, 파라미터 및 테이블 값을 변경 또는 변환하는 데 사용하기 위해 시스템 사용자 피 드백 및 자율적 조각 분석에 기초하여 결정되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것 이다. 본 발명의 다른 목적은, 모집단 취향 집계기 서브 시스템(B47)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 모집단의 음학 취향은 집계되어 스타일 음악적 경험 디스크립터로 변하며, 이에 응답하여 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 파라미터 테이블 확률이 변경될 수 있는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 사용자 선호도 서브 시스템(B48)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 시스 템 사용자 선호도(예컨대, 스타일 및 음악적 경험 디스크립터, 테이블 파라미터)는 본 발명의 자동화된 음악 작 곡 및 생성 프로세스 중에 결정되어 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 모집단 선호도 서브 시스템(B49)은 자동화된 음악 작곡 및 생성 엔진에 사용되고, 사용 자 모집단 선호도(예컨대, 스타일 및 음악적 경험 디스크립터, 테이블 파라미터)는 본 발명의 자동화된 음악 작 곡 및 생성 프로세스 중에 결정되어 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 템포 생성 서브 시스템(B3)에 유지되고, 시스템에 의해 지원되는 각각의 감정적 디스크립터에 대하여, 시스템에 의해 지원되는 각 템포(분당 비트)에 대한 확률 척도가 제공되며, 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 길이 생성 서브 시스템(B2)에 유지되고, 시스템에 의해 지원되는 각각의 감정적 디스크립터에 대하여, 시스템에 의해 지원되는 각 길이(초)에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 박자 생성 서브 시스템(B4)에 유지되고, 시스템에 의해 지원되는 각각의 감정적 디스크립터에 대하여, 시스템에 의해 지원되는 각 박자에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 키 생성 서브 시 스템(B5)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 시스템에 의해 지원되는 각 키에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 조성 생성 서브 시스템(B7)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 시스템에 의 해 지원되는 각 조성(즉, 메이저, 마이너 내추럴, 마이너 하모닉, 마이너 멜로딕, 도리안, 프리지안, 리디안, 믹솔리디안, 에올리안, 및 로크리안)에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하 는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 노래 형태 생성 서브 시스템(B9)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 각 하 위 악절 형태(a, aa, ab, aaa, aba, abc)뿐만 아니라, 시스템에 의해 지원되는 각 노래 형태(즉, A, AA, AB, AAA, ABA, ABC)에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 하위 악절 길이 생성 서브 시스템(B15)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 시스템에 의해 지원되는 각 하위 악절 길이(즉, 마디)에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테 이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 화음 길이 생성 서브 시스템(B11)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 시스 템에 의해 지원되는 각각의 제1 화음 길이 및 제2 화음 길이에 대한 확률 척도가 제공되며, 이 확률 기반 파라 미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 제1 일반 리듬 생 성 서브 시스템(B17)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 시 스템에 의해 지원되는 (즉, 계이름으로 표시된) 각각의 밑음 음표에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 하위 악절 화음 진행 생성 서브 시스템(B19)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대 하여, 시스템에 의해 지원되는 마디 내의 (즉, 계이름으로 표시된) 각각의 오리지널 화음 밑음과 향후 비트에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 화음 자리바꿈 생 성 서브 시스템(B20)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 시 스템에 의해 지원되는 (즉, 계이름으로 표시된) 각각의 자리바꿈 및 오리지널 화음 밑음에 대한 확률 척도가 제 공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 멜로디 하위 악절 길이 진행 생성 서브 시스템(B25)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터 에 대하여, 시스템에 의해 지원되는 (즉, 계이름으로 표시된) 각각의 오리지널 화음 밑음에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그 와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 멜로디 음표 리듬 생성 서브 시스템(B26)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 시스템에 의해 지원되는 각각의 제1 음표 길이 및 제2 화음 길이에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 제1 피치 생성 서 브 시스템(B27)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 시스템 에 의해 지원되는 (즉, 계이름으로 표시된) 각각의 음표에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생 성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 하위 악절 피치 생성 서브 시스템(B29)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 시스템에 의해 지원되는 (즉, 계이름으로 표시된) 각각의 오리지널 음표 및 도약 자리바꿈에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그 와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 멜로디 하위 악절 길이 진행 생성 서브 시스템(B25)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터 에 대하여, 시스템에 의해 지원되는 하위 악절로 멜로디가 시작하는 시간 길이에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자 동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 멜로디 음표 리듬 생성 서브 시스템(B25)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 시스템에 의해 지원되는 각각의 제1 음표 길이, 제2 화음 길이(즉, 마디), 및 제n 화음 길이에 대한 확률 척도 가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 제1 피치 생성 서 브 시스템(B27)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 시스템 에 의해 지원되는 각각의 음표에 대한 확률 기반 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하 는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 하위 악절 피치 생성 서브 시스템(B29)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 시스템에 의해 지원되는 각각의 오리지널 음표 및 도약 자리바꿈에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 피치 옥타브 생성 서브 시스템(B30)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 확률 척도 세트가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 그 자동화된 음악 작곡 및 생성 엔진의 악기 선택기 서브 시스템(B39)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 시스템에 의해 지원되는 각각의 악기에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 자동화된 음악 작곡 및 생성 엔진의 오케스트레이션 생성 서브 시스템(B31)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 시스 템에 의해 지원되는 각각의 악기에 대한 확률 척도가 제공되며, 이 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 확률 기반 파라미터 테이블은 자동화된 음악 작곡 및 생성 엔진의 컨트롤러 코드 생성 서브 시스템(B32)에 유지되고, 시스템 사용자에 의해 선택되는 각각의 음악적 경험 디스크립터에 대하여, 시스 템에 의해 지원되는 각각의 악기에 대한 확률 척도가 제공되며, 이 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 시스템이 시스템 사용자로부터 그 음악적 경험 디스크립터 입력을 수신하고 시스템이 자동으로 배치되어 그 작동 모드로 구성된 후에, 타이밍 제어 서브 시스템은 각 서브 시스템으로 전송되는 타이 밍 제어 펄스 신호를 생성하기 위해 사용되고, 음악은 본 발명의 원리에 따라 자동으로 작곡 및 생성되는, 그와 같은 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 다른 목적은, 실시간 피치 이벤트 분석 서브 시스템을 이용하여 음악을 자동으로 작곡하고 자동화된 방식으로 생성하는 신규한 시스템 및 방법을 제공하는 것이다. 본 발명의 다른 목적은, (a) 자동화된 음악 작곡 및 생성 시스템의 시스템 사용자 인터페이스에 (예컨대, \"감정 타입\" 음악적 경험 디스크립터 및 \"스타일 타입\" 음악적 경험 디스크립터를 포함하는) 음악적 경험 디스크립터 를 제공하는 단계; (b) 시스템에 의해 작곡 및 생성된 음악으로 스코어링될 비디오 또는 미디어 객체의 하나 이 상의 장면을 위해, 시스템의 시스템 사용자 인터페이스에 (예컨대, 타이핑되거나, 말로 전해지거나 또는 노래 불려진 포맷의) 가사 입력을 제공하는 단계; (c) 시간 및/또는 주파수 도메인 기술에 기초하여, (스코어링된 미 디어의 특정 프레임에 대해) 타이핑되거나/말로 전해지거나/노래 불려진 가사 또는 단어의 실시간 리듬, 피치이벤트 및 운율 분석을 이용하여, 시스템 사용자 인터페이스에 제공된 가사 입력을 프로세싱하는 실시간 피치 이벤트 분석 서브 시스템을 이용하는 단계; (d) 분석된 가사 입력으로부터 고해상도 타임라인에서의 피치 이벤 트, 리듬 정보 및 운율 정보, 및 그와 같은 검출 이벤트가 언제 발생하였는지에 대한 타이밍 정보를 가진 코드 를 추출하기 위해 실시간 피치 이벤트 분석 서브 시스템을 이용하는 단계; 및 (e) 자동화된 시스템의 다양한 서 브 시스템에 채택된 확률 기반 파라미터 테이블을 제한하는 데 사용하기 위해 자동화된 음악 작곡 및 생성 엔진 에 추출된 정보를 제공하는 단계를 포함하는 프로세스를 지원하는, 그와 같은 자동화된 음악 작곡 및 생성 시스 템을 제공하는 것이다. 본 발명의 다른 목적은, 본 발명의 자동화된 음악 작곡 및 생성 시스템 네트워크의 파라미터 변환 엔진 서브 시 스템 내에서의 파라미터 구성의 생성 및 관리를 지원하는 분산된 원격 액세스 가능 GUI 기반 작업 환경을 제공 하는 것이며, 전세계 어디든 원격 위치한 시스템 설계자는 시스템 네트워크에 로그인하여 GUI 기반 작업 환경에 액세스할 수 있고, (i) 시스템 사용자에 의해 선택될 수 있는 감정 타입, 스타일 타입 및 타이밍/공간 파라미터 의 가능한 세트와 (ii) 본 발명의 자동화된 음악 작곡 및 생성 시스템 네트워크에 의해 지원되는 파라미터 변환 엔진 서브 시스템 및 그 관련 파라미터 테이블 아카이브 데이터베이스 서브 시스템 내에서의 영구 저장을 위해, 바람직하게는 파라미터 테이블 내에 유지되는 대응하는 확률 기반 음악 이론 시스템 작동 파라미터의 세트 사이 의 파라미터 매핑 구성을 만들 수 있다. 본 발명의 다른 목적은, 감정 및 스타일 타입 음악적 경험 디스크립터에 따라 자동으로 작곡된 음악 조각의 음 악 스코어 표현을 생성하고, 다른 사람들의 즐거움을 위해 자동으로 작곡된 음악 조각을 제작하기 위한 음악 작 곡 로봇 형태의 신규한 자동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 또한, 본 발명의 다른 목적은, 감정 및 스타일 타입 음악적 경험 디스크립터에 따라 자동으로 작곡된 음악 조각 의 음악 스코어 표현을 생성하고, 다른 사람들의 즐거움을 위해 자동으로 작곡된 음악 조각을 제작하는 하나 이 상의 MIDI 기반 음악 악기를 구동 및 제어하기 위하여 그와 같은 표현을 MIDI 제어 신호로 변환하는 신규한 자 동화된 음악 작곡 및 생성 시스템을 제공하는 것이다. 본 발명의 여타 목적은 본 발명에 첨부된 특허 청구 범위를 참조하면 이하에서 명백해질 것이다."}
{"patent_id": "10-2018-7011569", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "첨부 도면을 참조하면, 도면 전체에 걸쳐 유사한 구조와 요소는 유사한 참조 번호로 표시된다. 본 발명의 자동화된 음악 작곡 및 생성 시스템 및 다양한 애플리케이션에서 그 자동화된 음악 작곡 및 생성 엔 진의 채택에 대한 개요 도 1은 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성의 사용 을 지원하는 본 발명의 자동화된 음악 작곡 및 생성 시스템(S1)의 상위 시스템 아키텍처를 나타내며, 언어 기반 음악적 경험 디스크립터와 미디어 조각(예컨대, 비디오, 오디오 파일, 이미지) 또는 이벤트 마커는 시스템 사용 자에 의해 시스템 사용자 입출력(I/O) 인터페이스(B0)를 통해 입력으로서 제공되고, 도 25a 내지 도 84e에 도시 된 본 발명의 자동화된 음악 작곡 및 생성 엔진(E1)에 의해 사용되어 시스템 사용자 (I/O) 인터페이스(B0)를 통 해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된 미디어(예컨대, 비디오, 팟 캐스트, 오디오 파일, 슬라이드 쇼 등) 또는 이벤트 마커를 생성시킨다. 이 신규한 시스템과 그 지원 정보 프로세스의 세부 사항은 매 우 상세하게 기술적으로 후술하기로 한다. 본 발명의 자동화된 음악 작곡 및 생성 시스템의 아키텍처는 영화, 비디오 게임 등을 포함한 다양한 종류의 미 디어에 대해 음악 악보를 작곡하는 본 발명자의 현실 세계에서의 경험에서 영감을 받았다. 도 25a 및 도 25b에 도시된 바와 같이, 본 발명의 시스템은 많은 상위 서브 시스템, 구체적으로는, 입력 서브 시스템(A0), 일반 리 듬 서브 시스템(A1), 일반 리듬 생성 서브 시스템(A2), 멜로디 리듬 생성 서브 시스템(A3), 멜로디 피치 생성 서브 시스템(A4), 오케스트레이션 서브 시스템(A5), 컨트롤러 코드 제작 서브 시스템(A6), 디지털 조각 제작 서 브 시스템(A7), 및 피드백 및 학습 서브 시스템(A8)을 포함한다. 도 28a 및 도 28b에 나타낸 개략도에 도시된 바와 같이, 이 상위 서브 시스템(A0 내지 A7)들은 각각 서브 시스템 세트를 포함하며, 이 서브 시스템들 중 다 수는 변환 엔진 서브 시스템(B51)에 의해 생성 및 로드되는 확률 기반 시스템 작동 파라미터 테이블(즉, 구조) 를 유지한다. 도 2는 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 자동화된 가상 악기 음악 합 성을 이용한 본 발명의 일반화된 자동화된 음악 작곡 및 생성 프로세스를 실행하기 위한 주요 단계를 나타낸다. 본원에서 사용되는 바와 같이, 용어 \"가상 악기 음악 합성\"은 본원에 개시된 기술을 이용하여 실제 또는 가상 악기로부터 녹음된 디지털 오디오 샘플링 음표, 화음 및 음표 시퀀스를 이용한 음표 단위 및 화음 단위의 음악 조각 제작을 의미한다. 이 음악 합성 방법은 음악 조각을 제작하기 위해 음악의 많은 루프와 트랙이 사전 녹음 되어 메모리 저장 장치(예컨대, 데이터베이스)에 저장되는 방법과는 근본적으로 다른데, 그 이유는 이와 같은 종래 기술의 합성법에서는 사용되는 음악의 구성 요소 내에 음표와 화음의 기본적인 음악 이론 정의/사양이 없 기 때문이다. 현저히 대조적으로, 본 발명의 시스템/기계에 의해 자동으로 작곡 및 생성되는 음악 조각 내의 각 각의 음악 이벤트(예컨대, 음표, 화음, 악절, 하위 악절, 리듬, 비트, 마디, 멜로디 및 피치)의 엄격한 음악 이 론 사양이 본 발명의 원리에 따른 가상 악기 음악 합성 방법을 실시하기 위해 전체 음악 작곡/생성 프로세스 중 에 시스템에 의해 유지되어야만 한다. 도 2에 도시된 바와 같이, 자동화된 음악 작곡 프로세스의 제1단계에서, 시스템 사용자는 본 발명의 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 본 발명의 자동화된 음악 작곡 및 생성 시스템에 의해 생성된 음악 으로 스코어링될 비디오, 오디오 레코딩(즉, 팟 캐스트), 슬라이드 쇼, 사진이나 이미지 또는 이벤트 마커를 선 택하고, (ii) 그 다음, 시스템 사용자는 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 시스템의 자 동화된 음악 작곡 및 생성 엔진에 제공하며, (iii) 시스템 사용자는 자동화된 음악 작곡 및 생성 시스템을 기동 하여 선택된 미디어 또는 이벤트 마커에 스코어링되어 있는 입력된 음악적 디스크립터에 기초한 음악을 작곡 및 생성하며, (iv) 시스템 사용자는 스코어링된 미디어 또는 이벤트 마커에 대해 제작된 작곡 및 생성된 음악을 수 용하고, 시스템 사용자가 주관적으로 경험하여 형성된 음악적 경험을 고려하여 제작된 음악에 대한 시스템 사용 자의 평가 및/또는 음악 선호도에 관한 피드백을 시스템에 제공하며, (v) 시스템은 수용한 작곡된 음악을 선택 된 미디어 또는 이벤트 마커와 조합하여, 분배 및 표시하기 위한 비디오 파일을 제작한다. 자동화된 음악 작곡 및 생성 시스템은 많은 서브 시스템으로 구성된 복잡한 시스템이며, 본 발명의 자동화된 음 악 작곡 및 생성 프로세스를 지원하는 고도로 전문화된 생성 프로세스를 지원하기 위해 복잡한 계산기, 분석기 및 기타 전문화된 기계가 사용된다. 이 구성 요소들은 각각 본 발명의 음악 작곡 및 생성 엔진 시스템(즉, 엔진)의 특정 부분에서 중요한 역할을 하며, 자동화된 음악 작곡 및 생성 엔진의 필수 요소에 대한 각 구성 요 소의 조합은 그 부분의 일부 또는 전부의 합보다 훨씬 더 큰 값을 생성한다. 이 서브 시스템 구성 요소의 각각 의 구조 및 기능적 목적에 대한 간결하고 상세한 기술적 설명이 이하의 도 27 내지 도 76에 제공된다. 도 26a 내지 도 26p에 나타낸 바와 같이, 도 25a 내지 도 25b에 특정된 각각의 상위 서브 시스템은 본 발명의 매우 복잡한 자동화된 음악 작곡 및 생성 시스템 내에서 실행될 매우 특수한 기능을 가진 하나 이상의 고도로전문화된 서브 시스템에 의해 실현된다. 바람직한 실시형태에서, 시스템은 자동화된 가상 악기 음악 합성 기술 을 채택하여 구현하고, 다양한 종류의 악기로부터 샘플링된 음표와 화음, 그리고 음표 시퀀스가 디지털 방식으 로 샘플링되어 데이터베이스 내의 디지털 오디오 샘플로서 표현되며, 본 발명의 시스템에 의해 작곡 및 생성되 는 음악 조각에 따라 조직화된다. 도 27에 도시된 GUI 기반 입출력 서브 시스템에 제공된 (도 83a, 도 83b, 도 83c, 도 83d, 도 83e 및 도 83f에 도시된 감정 타입 디스크립터와 도 84a 내지 도 84e에 도시된 스타일 타입 디 스크립터를 포함한) 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 응답하여, 시스템 사용자가 원 하는 감정 및 스타일 요구 사항을 반영하기 위해, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 시스템 이 자동으로 실행된다. 도 27에서, 음악적 경험 디스크립터와 선택적으로 (작곡된 음악으로 스코어링될 임의의 미디어 형태의 시간 및 공간 요구 사항을 특정하는) 시간 및 공간 파라미터가 입출력 서브 시스템(B0)에 의해 지원되는 GUI 기반 인터 페이스로 제공된다. 입출력 서브 시스템(B0)의 출력은 도 26a 내지 도 26p에 나타낸 바와 같이 자동화된 음악 작곡 및 생성 엔진의 다른 서브 시스템(B1, B37 및 B40)에 제공된다. 도 28a 및 도 28b에 나타낸 바와 같이, 디스크립터 파라미터 포착 서브 시스템(B1)은 도 28d에 개략적으로 도시 된 파라미터 변환 엔진 서브 시스템(B51)과 인터페이스하며, 음악적 경험 디스크립터(예컨대, 도 83a, 도 83b, 도 83c, 도 83d, 도 83e 및 도 83f에 도시된 감정 타입 디스크립터와 도 84a, 도 84b, 도 84c, 도 84d, 도 84e 에 도시된 스타일 타입 디스크립터)와 타이밍(예컨대, 시작, 정지 및 히트 타이밍 위치) 및/또는 공간 사양(예 컨대, 포토 슬라이드 쇼의 슬라이드 번호 21)이 서브 시스템(B0)의 시스템 사용자 인터페이스에 제공된다. 이 음악적 경험 디스크립터들은 시스템의 다양한 서브 시스템에 의해 생성되고 분배된 다음 로드되어 사용되는 프 로그램가능한 음악 이론 파라미터 테이블에 유지되는 시스템 작동 파라미터(SOP) 값으로 파라미터 변환 엔진 (B51)에 의해 자동으로 변환된다. 설명의 예시 및 용이함을 위해, 음악적 경험 디스크립터-행복-가 도 77a 내지 도 79에 도시된 바와 같이 시스템 사용자 입력 선택으로서 사용된다. 그러나, 5개의 예시적인 감정 타입 음악적 경험 디스크립터에 대응하는 SOP 파라미터 테이블이 오직 예시만을 위해 도 77a 내지 도 77t에 도시되어 있다. 서브 시스템 내의 이와 같은 SOP 테이블의 치수는 (i) 개별 서브 시스템의 감정 타입 디스크립터에 구성되거나 치수가 정해진 확률 SOP 테이블에 대해, 시스템 사용자가 선택한 것만큼 많은 감정 타입 음악적 경험 디스크립 터와, (ii) 개별 서브 시스템의 스타일 타입 디스크립터에 구성되거나 치수가 정해진 확률 SOP 테이블에 대해, 시스템 사용자가 선택한 것만큼 많은 스타일 타입 음악적 경험 디스크립터를 포함할 것으로 이해된다. 이하에서는, 도 28c, 도 28d 및 도 28e와 본원에 개시된 관련 도면에 개략적으로 도시된 변환 엔진 모델을 참조 하여, 이와 같은 비음악적 시스템 사용자 파라미터가 시스템에 채택된 다양한 시스템 작동 파라미터(SOP) 테이 블의 확률 기반 시스템 작동 파라미터로 변환되거나 매핑되는 원리를 설명할 것이다. 이와 관련하여, 서브 시스 템(B51)의 파라미터 변환 엔진의 부하가 서브 시스템(B0)의 음악적 경험 디스크립터 인터페이스에 의해 지원되 는 자유도에 따라 어떻게 증가할 것인지를 예시하는 것이 도움이 될 것이다. 시스템이 N개의 서로 다른 감정 타입 음악적 경험 디스크립터(Ne) 세트와 M개의 서로 다른 스타일 타입 음악적 경험 디스크립터(Ms) 세트를 지원하고, 시스템 사용자가 시스템 사용자 인터페이스 서브 시스템(B0)에서 선택할 수 있는, 예시적인 시스템을 생각해 보기로 한다. 또한, 시스템 사용자가 N개의 서로 다른 감정 타입 음악적 경 험 디스크립터(Ne) 세트로부터 오직 1개의 감정 타입 디스크립터와, M개의 서로 다른 스타일 타입 음악적 경험 디스크립터(Ms) 세트로부터 오직 1개의 스타일 타입 디스크립터를 자유롭게 선택하는 경우를 생각해 보기로 한다. 시스템 사용자가 N개의 특이한 감정 타입 음악적 경험 디스크립터(Ne) 중 어느 하나와 M개의 서로 다른 스타일 타입 음악적 경험 디스크립터(Ms) 중 오직 1개를 선택할 수 있는, 이와 같이 매우 제한된 경우에, 도 28c, 도 28d 및 도 28e의 파라미터 변환 엔진 서브 시스템(B51)은 각각의 자동화된 음악 작곡 프로세스 중에 자 신의 각 서브 시스템에 대한 분배 및 로드를 위해 도 77a 내지 도 79에 도시된 바와 같이 Nsopt = Ne!/(Ne-r)!re! x Ms!/(Ms-rs)!rs!개의 특이한 확률 시스템 작동 파라미터(SOP) 테이블 세트를 생성할 필요가 있을 것이며, 여기 서, Ne는 감정 타입 음악적 경험 디스크립터의 총수이고, Ms는 스타일 타입 음악적 경험 디스크립터의 총수이며, re는 감정에 대해 선택된 음악적 경험 디스크립터의 수이고, rs는 스타일에 대해 선택된 음악적 경험 디스크립터 의 수이다. re=1이고 rs=1인 경우, 상기 계승 기반 조합식은 Nsopt = Ne x Me로 감소된다. Ne = 30 x Me = 10인 경 우, 변환 엔진은 30개의 서로 다른 감정 디스크립터 세트와 10개의 스타일 디스크립터 세트를 지원하는 300개의 서로 다른 확률 시스템 작동 파라미터 테이블 세트를 생성시키는 용량을 갖게 될 것이며, 이에 따라, 시스템 사용자는 본 발명의 원리에 따른 시스템의 예시적 실시형태를 이용하여 음악을 생성하기 위해-음악적 경험 디스크 립터로-자동화된 음악 작곡 및 생성 시스템을 구성할 때 1개의 감정 디스크립터와 1개의 스타일 디스크립터를 선택할 수 있다. 시스템 사용자가 n개의 특이한 감정 타입 음악적 경험 디스크립터(ne) 세트로부터 2개의 특이한 감정 타입 음악 적 경험 디스크립터와, m개의 서로 다른 스타일 타입 음악적 경험 디스크립터(Ms) 세트로부터 2개의 특이한 스타 일 타입 음악적 경험 디스크립터를 자유롭게 선택하는 경우, 도 28c, 도 28d 및 도 28e의 변환 엔진은 본 발명 의 각각의 자동화된 음악 작곡 프로세스 중에 자신의 각 서브 시스템에 대한 분배 및 로드를 위해 도 77a 내지 도 79에 도시된 바와 같이 Nsopt = Ne!/(Ne-2)!2! x Ms!/(Ms-2)!2! 개의 서로 다른 확률 시스템 작동 파라미터 테 이블(SOPT) 세트를 생성하여야 하며, 여기서, ne는 감정 타입 음악적 경험 디스크립터의 총수이고, Ms는 스타일 타입 음악적 경험 디스크립터의 총수이며, re=2는 감정에 대해 선택된 음악적 경험 디스크립터의 수이고, rs=2는 스타일에 대해 선택된 음악적 경험 디스크립터의 수이다. Ne = 30 x Me = 10인 경우, 파라미터 변환 엔진 서브 시스템(B51)은 30개의 서로 다른 감정 디스크립터 세트와 10개의 스타일 디스크립터 세트를 지원하는 Nsopt = 30!/(30-2)!2! x 10!/(10-2)!2! 개의 서로 다른 확률 시스템 작동 파라미터 테이블 세트를 생성시키는 용량을 갖게 될 것이며, 이에 따라, 시스템 사용자는 본 발명의 원리에 따른 시스템의 예시적 실시형태를 이용하여 음 악을 생성하기 위해-음악적 경험 디스크립터로-자동화된 음악 작곡 및 생성 시스템을 프로그래밍할 때 1개의 감 정 디스크립터와 1개의 스타일 디스크립터를 선택할 수 있다. 상기 계승 기반 조합식은, 위에 주어진 예시적인 예에서, 감정 타입 음악적 경험 디스크립터에 대해 선택될 수 있는 서로 다른 입력의 전체 작동 범위, 스타일 타입 음악적 경험 디스크립터의 Ms의 수, 감정에 대해 선택될 수 있는 음악적 경험 디스크립터의 re의 수, 및 스 타일에 대해 선택될 수 있는 음악적 경험 디스크립터의 rs의 수에 대해, 서로 다른 확률 시스템 작동 파라미터 테이블 세트가 얼마나 많이 생성되어야 할 것인지에 대한 지침을 제공한다. 설계 파라미터(Ne, Ms, re 및 rs)는 상업적으로 사용하기 위하여 설계, 제조 및 분배될 임의의 특정한 자동화된 음악 작곡 및 생성 시스템 기반 제 품에 대해 기대되는 시스템 사용자 기반의 감정적 및 예술적 요구를 충족하기 위해 필요에 따라 선택될 수 있는 것으로 이해된다. 특별히, 변환 엔진 서브 시스템(B51)에 의해 생성될 수 있는 테이블 세트의 예상 크기에 대한 확률 시스템 작동 테이블의 정량적 성질을 위에서 검토하였으나, (i) 본 발명의 시스템의 시스템 사용자 인터페이스에 의해 지원 되는 음악적 경험 디스크립터와 타이밍 및 공간 파라미터와, (ii) 도 77a 내지 도 79에 도시된 확률 기반 시스 템 작동 파라미터 테이블(SOPT)에 반영된 음악 이론 개념 사이에 존재하는 정량적 관계와, 각각의 자동화된 음 악 작곡 및 생성 프로세스가 본 발명의 시스템 내에서 시계 장치처럼 실행되기 전에 변환 엔진 내에서 생성되어 다양한 서브 시스템 내에 분배 및 로드되어야만 하는 각각의 확률 기반 시스템 작동 파라미터 테이블 세트에 대 한 특정 확률 값을 선택하기 위해 이 정량적 관계가 어떻게 사용될 수 있는지를 도 28c, 도 28d 및 도 28e와 도 77a 내지 도 79를 참조하여 차후의 시점에 논의하는 것이 적절할 것이다. 시스템 내의 서브 시스템의 전반적인 타이밍 및 제어에 관하여, 시스템 사용자가 선택한 음악적 경험 디스크립 터와 시스템에 제공되는 타이밍 및/또는 공간 파라미터의 주어진 세트에 대해 자동화된 음악 작곡 및 생성 프로 세스를 각각 실행하는 중에 각 서브 시스템의 타이밍을 예시하고 있는 도 80a 및 도 80b에 개시된 시스템 타이 밍도를 참조할 것이다. 도 80a 및 도 80b에 나타낸 바와 같이, 시스템은 턴 온되는 B1으로 시작하며, 시스템 사용자로부터 입력을 수용 하고, B37, B40 및 B41로 유사한 프로세스가 뒤따른다. 이 시점에, 폭포 생성 프로세스가 도입되고, 시스템은 순차적인 방식으로 플랫폼의 각 구성 요소를 초기화, 도입 및 해제한다. 도 80a 및 도 80b에 기술된 바와 같이, 각 구성 요소가 전체 작곡 프로세스에 걸쳐 온으로 유지되거나 능동적으로 연관될 필요가 없다. 도 81, 도 81a, 도 81b, 도 81c, 도 81d, 도 81e, 도 81f, 도 81g, 도 81h, 도 81i 및 도 81j에 의해 형성된 테이블은 자동화된 음악 작곡 및 생성 시스템의 각 구성 요소의 입력 및 출력 정보 포맷(들)을 기술한다. 다시 말하면, 이와 같은 포맷은 실제 음악 작곡 방법에 직접적으로 상관한다. 각 구성 요소는 시스템 내의 후속 구성 요소가 정확하게 기능할 수 있도록 하는 별개의 입력 및 출력 세트를 갖는다. 도 26a 내지 도 26p는 자동화된 음악 작곡 및 생성 시스템 내부에 있거나 입출력되는 정보의 흐름 및 프로세싱 을 도시하고 있다. 블록(1, 37, 40 및 41)에 대한 사용자 입력으로 시작하여, 각각의 구성 요소 서브 시스템은 계통적으로 결정하고, 다른 결정 구성 요소/서브 시스템에 영향을 미치며, 시스템이 음악 작곡 및 생성 프로세스에서 급속하게 진행할 수 있도록 한다. 도 26a 내지 도 26p와 본원의 다른 도면에서, (교차하는 선과 조합되 지 않는다는 것을 지시하기 위해 다른 선과 교차할 때는 쇄선이 되는) 실선은 개별 구성 요소를 연결하고, 삼각 형은 프로세스의 흐름을 지시하며, 프로세스는 선 위에 있는 삼각형의 꼭지점의 방향으로 이동하여 선에 대해 수직한 삼각형의 변으로부터 멀어진다. 어떠한 쇄선 지시 없이 교차하는 선들은 선 위의 삼각형에 의해 지시된 방향으로 다시 이동하는 정보 및/또는 프로세스의 조합 및/또는 분할을 나타낸다. 도 26a 내지 도 26p에 예시된 자동화된 음악 작곡 및 생성 시스템의 아키텍처 구성 요소에 의해 지원되는 본 발 명의 자동화된 음악 작곡 및 생성 프로세스의 개요 이 시점에, 도 101에 개시된 상위 흐름도를 참조하여, 본원에 개시되고 교시된 본 발명의 다양한 시스템에 의해 지원되는 자동화된 음악 작곡 및 생성 프로세스의 개요를 제공하는 것이 유용할 것이다. 이 프로세스에 관련하 여, 전술한 가상 악기 음악 합성 방법을 실시하는 본 발명의 자동화된 음악 작곡 및 생성 프로세스를 지원하기 위해 시스템에 의해 제공되는 대응하는 상위 시스템 아키텍처를 따르기 위해, 도 26a 내지 도 26p를 또한 참조 하기로 한다. 도 101의 블록(A)에 지시되고 도 26a 내지 도 26d에 반영된 바와 같이, 본 발명의 예시적인 실시형태에 따른 자 동화된 음악 작곡 및 생성 프로세스의 제1단계는 시스템 사용자가 본 발명의 기계로 자동으로 작곡 및 생성하고 자 하는 음악 조각에 대한 음악적 디스크립터로서 감정 타입 및 스타일 타입 및 선택적으로 타이밍 타입 파라미 터를 수신하는 단계를 포함한다. 이 시스템 사용자 인터페이스가 GUI 기반일 필요는 없는 것으로 이해되지만, 통상적으로, 음악적 경험 디스크립터는 GUI 기반 시스템 사용자 I/O 서브 시스템(B0)을 통해 제공되며, EDI, XML, XML-HTTP, 및 머신 또는 컴퓨터 기반 머신인 시스템 사용자를 지원하여 본원에 개시된 본 발명의 원리를 실행하는 머신으로부터 자동화된 음악 작곡 및 생성 서비스를 요청하기 위해 머신 대 머신 또는 컴퓨터 대 컴퓨 터 통신이 필요한 다른 유형의 정보 교환 기술을 이용할 수 있다. 도 101의 블록(B)에 지시되고 도 26d 내지 도 26j에 반영된 바와 같이, 본 발명의 예시적인 실시형태에 따른 자 동화된 음악 작곡 및 생성 프로세스의 제2단계는 작곡될 음악 조각을 위한 일반 리듬을 생성하기 위해 일반 리 듬 서브 시스템(A1)을 이용하는 단계를 포함한다. 프로세스의 이 단계는 다음의 서브 시스템을 이용하는 단계를 포함한다: 길이 생성 서브 시스템(B2); 템포 생성 서브 시스템(B3); 박자 생성 서브 시스템(B4); 키 생성 서브 시스템(B5); 비트 계산기 서브 시스템(B6); 조성 생성 서브 시스템(B7); 마디 계산기 서브 시스템(B8); 노래 형 태 생성 서브 시스템(B9); 하위 악절 길이 생성 서브 시스템(B15); 하위 악절 내 화음 수 계산기 서브 시스템 (B16); 악절 길이 생성 서브 시스템(B12); 특이 악절 생성 서브 시스템(B10); 악절 내 화음 수 계산기 서브 시 스템(B13); 화음 길이 생성 서브 시스템(B11); 특이 하위 악절 생성 서브 시스템(B14); 악기 편성 서브 시스템 (B38); 악기 선택기 서브 시스템(B39); 및 타이밍 생성 서브 시스템(B41). 도 101의 블록(C)에 지시되고 도 26j 및 도 26k에 반영된 바와 같이, 본 발명의 예시적인 실시형태에 따른 자동 화된 음악 작곡 및 생성 프로세스의 제3단계는 작곡되고 있는 음악 조각을 위한 화음을 생성하기 위해 일반 피 치 생성 서브 시스템(A2)을 이용하는 단계를 포함한다. 프로세스의 이 단계는 다음의 서브 시스템을 이용하는 단계를 포함한다: 제1 일반 리듬 생성 서브 시스템(B17); 하위 악절 화음 진행 생성 서브 시스템(B19); 악절 화 음 진행 생성 서브 시스템(B18); 및 화음 자리바꿈 생성 서브 시스템(B20). 도 101의 블록(D)에 지시되고 도 26k 및 도 26l에 반영된 바와 같이, 본 발명의 예시적인 실시형태에 따른 자동 화된 음악 작곡 및 생성 프로세스의 제4단계는 작곡되고 있는 음악 조각을 위한 멜로디 리듬을 생성하기 위해 멜로디 리듬 생성 서브 시스템(A3)을 이용하는 단계를 포함한다. 프로세스의 이 단계는 다음의 서브 시스템을 이용하는 단계를 포함한다: 멜로디 하위 악절 길이 생성 서브 시스템(B25); 멜로디 하위 악절 생성 서브 시스템 (B24); 멜로디 악절 길이 생성 서브 시스템(B23); 멜로디 특이 악절 생성 서브 시스템(B22); 멜로디 길이 생성 서브 시스템(B21); 및 멜로디 음표 리듬 생성 서브 시스템(B26). 도 101의 블록(E)에 지시되고 도 26l 및 도 26m에 반영된 바와 같이, 본 발명의 예시적인 실시형태에 따른 자동 화된 음악 작곡 및 생성 프로세스의 제5단계는 작곡되고 있는 음악 조각을 위한 멜로디 피치를 생성하기 위해 멜로디 피치 생성 서브 시스템(A4)을 이용하는 단계를 포함한다. 프로세스의 이 단계는 다음의 서브 시스템을 포함한다: 제1 피치 생성 서브 시스템(B27); 하위 악절 피치 생성 서브 시스템(B29); 악절 피치 생성 서브 시스 템(B28); 및 피치 옥타브 생성 서브 시스템(B30). 도 101의 블록(F)에 지시되고 도 26m에 반영된 바와 같이, 본 발명의 예시적인 실시형태에 따른 자동화된 음악 작곡 및 생성 프로세스의 제6단계는 작곡되고 있는 음악 조각을 위한 오케스트레이션을 생성하기 위해 오케스트레이션 서브 시스템(A5)을 이용하는 단계를 포함한다. 프로세스의 이 단계는 오케스트레이션 생성 서브 시스템 (B31)을 포함한다. 도 101의 블록(G)에 지시되고 도 26m에 반영된 바와 같이, 본 발명의 예시적인 실시형태에 따른 자동화된 음악 작곡 및 생성 프로세스의 제7단계는 음악 조각을 위한 컨트롤러 코드를 생성하기 위해 컨트롤러 코드 제작 서브 시스템(A6)을 이용하는 단계를 포함한다. 프로세스의 이 단계는 컨트롤러 코드 생성 서브 시스템(B32)을 이용하 는 단계를 포함한다. 도 101의 블록(H)에 지시되고 도 26m 및 도 26n에 반영된 바와 같이, 본 발명의 예시적인 실시형태에 따른 자동 화된 음악 작곡 및 생성 프로세스의 제8단계는 디지털 음악 조각을 제작하기 위해 디지털 조각 제작 서브 시스 템(A7)을 이용하는 단계를 포함한다. 프로세스의 이 단계는 다음의 서브 시스템을 이용하는 단계를 포함한다: 디지털 오디오 샘플 오디오 검색기 서브 시스템(B333); 디지털 오디오 샘플 조직기 서브 시스템(B34); 조각 통 합기 서브 시스템(B35); 조각 포맷 번역기 서브 시스템(B50); 및 조각 전달기 서브 시스템(B36). 도 101의 블록(I)에 지시되고 도 26n, 도 26o 및 도 26p에 반영된 바와 같이, 본 발명의 예시적인 실시형태에 따른 자동화된 음악 작곡 및 생성 프로세스의 제9단계는 시스템의 피드백 및 학습 사이클을 지원하기 위해 피드 백 및 학습 서브 시스템(A8)을 이용하는 단계를 포함한다. 프로세스의 이 단계는 다음의 서브 시스템을 이용하 는 단계를 포함한다: 피드백 서브 시스템(B42); 음악 편집성 서브 시스템(B43l); 선호도 저장기 서브 시스템 (B44); 음악적 커널 서브 시스템(B45); 사용자 취향 서브 시스템(B46); 모집단 취향 서브 시스템(B47); 사용자 선호도 서브 시스템(B48); 및 모집단 선호도 서브 시스템(B49). 본 발명의 자동화된 음악 작곡 및 생성 시스템의 제1 예시적 실시형태의 사양 도 3은 콤팩트한 휴대용 하우징 내에 제공된 텍스트 키보드 및/또는 음성 인식 인터페이스를 사용하여 생성된 언어 기반 음악적 경험 디스크립터의 사용과 가상 악기(예컨대, 샘플링된 악기) 음악 합성을 지원하는 본 발명 의 제1 예시적 실시형태에 따른 자동화된 음악 작곡 및 생성 악기 시스템을 나타낸다. 도 4는 시스템 버스 아키텍처 주변에 집적된 다양한 구성 요소를 나타내는 텍스트 키보드 및/또는 음성 인식 인 터페이스를 사용하여 생성된 언어 기반 음악적 경험 디스크립터의 사용과 가상 악기(예컨대, 샘플링된 악기) 음 악 합성을 지원하는 본 발명의 제1 예시적 실시형태의 자동화된 음악 작곡 및 생성 악기 시스템의 예시적 구현 의 개략도이다. 일반적으로, 위에서 특정되고 도 26a 내지 도 84e에 나타낸 상호 협력하는 그 서브 시스템들을 모두 포함하는 도 3에 나타낸 자동 또는 자동화된 음악 작곡 및 생성 시스템은 자동 음악 작곡 및 생성 시스템에 의해 지원될 작동 기능 및 모드를 실현하도록 특수하게 구성되고 프로그래밍된 디지털 전자 회로, 아날로그 전자 회로, 또는 디지털 및 아날로그 전자 회로의 조합을 이용하여 구현될 수 있다. 디지털 집적 회로(IC)는 음악 악기 제조 분 야뿐만 아니라 전자 회로 분야에 공지된 방식으로 실리콘으로 제작되는 칩 위에 실현된 저전력 및 혼합(즉, 디 지털과 아날로그) 신호 시스템(즉, 시스템 온 어 칩 또는 SOC) 구현예를 포함할 수 있다. 이와 같은 구현예는 본 발명의 시스템에 기초한 특정 제품 설계를 위해 필요하거나 요구될 수 있는 바와 같이 멀티 CPU와 멀티 GPU 의 사용을 포함할 수도 있다. 이와 같은 디지털 집적 회로(ID)의 구현예에 대한 세부 사항을 위해, 카덴스 디자 인 시스템즈 사, 시놉시스 사, 멘토 그래픽스 사 및 기타 전자 설계 자동화 회사를 포함하여 이 분야의 많은 기 업과 전문가를 참조할 수 있다. 예시를 위해, 시스템의 디지털 회로 구현예를 SOC 또는 유사한 디지털 집적 회로 주변에 구성된 구성 요소들의 아키텍처로서 나타내었다. 도시된 바와 같이, 시스템은 멀티 코어 CPU, 멀티 코어 GPU, 프로그램 메모리(DRAM) 및 비디오 메모리(VRAM)를 포함하는 SOC 서브 아키텍처; 하드 드라이브(SATA); LCD/터치 스크린 디스플레이 패 널; 마이크/스피커; 키보드; WIFI/블루투스 네트워크 어댑터; 피치 인식 모듈/보드; 및 전원 공급 장치와 분배 회로를 포함한 다양한 구성 요소를 포함하고, 도시된 바와 같이, 이들은 모두 시스템 버스 아키텍처와 지원 컨 트롤러 칩 주변에 집적된다. 프로그램 및 그래픽 명령이 모두 단일의 IC 소자 내에서 구현될 수 있는 하이브리드 멀티 코어 CPU/GPU 칩으로 서 멀티 코어 CPU와 GPU 모두가 실현되는 것도 가능하지만, 멀티 코어 CPU의 주요 기능은 프로그램 메모리(예컨 대, 마이크로 코드)에 로드된 프로그램 명령을 실행하는 것인 반면, 멀티 코어 GPU는 통상적으로 멀티 코어 CPU 로부터 그래픽 명령을 수신하여 실행하며, WIFI/블루투스(BT) 네트워크 어댑터와 피치 인식 모듈/회로뿐만 아니 라, LCD/터치 스크린 디스플레이 패널, 마이크/스피커, 키보드 또는 키패드 장치를 위한 인터페이스 회로와 아 울러, 컴퓨팅 및 그래픽 파이프라인이 모두 지원된다. WIFI/블루투스(BT) 네트워크 어댑터와 피치 인식 모듈/회로뿐만 아니라, LCD/터치 스크린 디스플레이 패널, 마이크/스피커, 키보드 또는 키패드 장치의 목적은 시스템에 채택된 다른 서브 시스템뿐만 아니라 시스템 인터페이스 서브 시스템(B0)에 의해 지원되는 기능을 지원 및 구현 하는 것일 것이다. 도 5는 텍스트 키보드 및/또는 음성 인식 인터페이스를 사용하여 생성된 언어 기반 음악적 경험 디스크립터의 사용과 가상 악기(예컨대, 샘플링된 악기) 음악 합성을 지원하는 제1 예시적 실시형태의 자동화된 음악 작곡 및 생성 악기 시스템을 나타내며, 언어 기반 음악적 경험 디스크립터와 비디오, 오디오 레코딩, 이미지, 또는 이벤 트 마커는 시스템 사용자 인터페이스를 통해 입력으로서 제공되고, 본 발명의 자동화된 음악 작곡 및 생성 엔진 에 의해 사용되어 시스템 사용자 인터페이스를 통해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된 미디어(예컨대, 비디오, 팟 캐스트, 이미지, 슬라이드 쇼 등) 또는 이벤트 마커를 생성시킨다. 도 6은 도 3 내지 도 5에 나타낸 악기 시스템을 사용하여 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크 립터와 가상 악기(예컨대, 샘플링된 악기) 음악 합성의 사용을 지원하는 본 발명의 제1 예시적 실시형태의 자동 화된 음악 작곡 및 생성 프로세스를 실행하는 데 포함되는 주요 단계를 설명하며, (i) 프로세스의 제1단계에서, 시스템 사용자는 본 발명의 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 본 발명의 자동화된 음악 작 곡 및 생성 시스템에 의해 생성된 음악으로 스코어링될 비디오, 오디오 레코딩(즉, 팟 캐스트), 슬라이드 쇼, 사진이나 이미지 또는 이벤트 마커를 선택하고, (ii) 그 다음, 시스템 사용자는 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 시스템의 자동화된 음악 작곡 및 생성 엔진에 제공하며, (iii) 시스템 사용자는 자동 화된 음악 작곡 및 생성 시스템을 기동하고, 선택된 미디어 또는 이벤트 마커에 스코어링되어 있는 입력된 음악 적 디스크립터에 기초하여 음악을 작곡 및 생성하며, (iv) 시스템 사용자는 스코어링된 미디어 또는 이벤트 마 커에 대해 제작된 작곡 및 생성된 음악을 수용하고, 시스템 사용자가 주관적으로 경험하여 형성된 음악적 경험 을 고려하여 제작된 음악에 대한 시스템 사용자의 평가 및/또는 음악 선호도에 관한 피드백을 시스템에 제공하 며, (v) 시스템은 수용한 작곡된 음악을 선택된 미디어 또는 이벤트 마커와 조합하여, 분배 및 표시하기 위한 비디오 파일을 제작한다. 본 발명의 제1 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스템의 작동 모드의 사양 도 3 내지 도 6에 나타낸 제1 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스템은 (i) 인간 시스템 사용자 가 자동화된 음악 작곡 및 생성 시스템에 음악적 경험 디스크립터와 타이밍/공간 파라미터 입력을 제공하는 수 동 모드; (ii) 인간 시스템 사용자와의 상호 작용 없이 자동화된 음악 작곡 및 생성 시스템의 작동을 자율적으 로 제어하기 위해, 하나 이상의 컴퓨터 제어식 시스템이 자동화된 음악 작곡 및 생성 시스템에 음악적 경험 디 스크립터와 선택적으로 타이밍/공간 파라미터를 자동으로 제공하는 자동 모드; 및 (iii) 인간 시스템 사용자와 하나 이상의 컴퓨터 제어식 시스템이 모두 자동화된 음악 작곡 및 생성 시스템에 음악적 경험 디스크립터와 선 택적으로 타이밍/공간 파라미터를 제공하는 하이브리드 모드를 포함한 다양한 작동 모드로 작동할 수 있다. 본 발명의 자동화된 음악 작곡 및 생성 시스템의 제2 예시적 실시형태의 사양 도 7은 가상 악기 음악 합성과 아이콘 기반 음악적 경험 디스크립터를 이용하여 본 발명의 제2 예시적 실시형태 의 자동화된 음악 작곡 및 생성 엔진을 지원하는 장난감 악기를 나타내며, 라이브러리로부터 비디오를 선택하여 로드하도록 터치 스크린 디스플레이가 제공되며, 그 다음, 어린이는 물리적 키보드로부터 음악적 경험 디스크립 터(예컨대, 감정 디스크립터 아이콘 및 스타일 디스크립터 아이콘)를 선택할 수 있음으로써, 어린이가 선택된 비디오의 분절된 장면에 대해 지정 음악을 작곡 및 생성할 수 있게 된다. 도 8은 키보드 인터페이스를 사용하여 선택된 그래픽 아이콘 기반 음악적 경험 디스크립터의 사용과 가상 악기 (예컨대, 샘플링된 악기) 음악 합성을 지원하는 본 발명의 제2 예시적 실시형태의 자동화된 음악 작곡 및 생성 악기 시스템의 예시적 구현의 개략도이며, 시스템 버스 아키텍처 주변에 집적된 멀티 코어 CPU, 멀티 코어 GPU, 프로그램 메모리(DRAM), 비디오 메모리(VRAM), 하드 드라이브(SATA), LCD/터치 스크린 디스플레이 패널, 마이크 /스피커, 키보드, WIFI/블루투스 네트워크 어댑터, 및 전원 공급 장치 및 분배 회로와 같은 다양한 구성 요소를 나타낸다. 일반적으로, 위에서 특정되고 도 26a 내지 도 84e에 나타낸 상호 협력하는 그 서브 시스템들을 모두 포함하는 도 7에 나타낸 자동 또는 자동화된 음악 작곡 및 생성 시스템은 자동 음악 작곡 및 생성 시스템에 의해 지원될 작동 기능 및 모드를 실현하도록 특수하게 구성되고 프로그래밍된 디지털 전자 회로, 아날로그 전자 회로, 또는 디지털 및 아날로그 전자 회로의 조합을 이용하여 구현될 수 있다. 디지털 집적 회로(IC)는 음악 악기 제조 분 야뿐만 아니라 전자 회로 분야에 공지된 방식으로 실리콘으로 제작되는 칩 위에 실현된 저전력 및 혼합(즉, 디지털과 아날로그) 신호 시스템(즉, 시스템 온 어 칩 또는 SOC) 구현예를 포함할 수 있다. 이와 같은 구현예는 본 발명의 시스템에 기초한 특정 제품 설계를 위해 필요하거나 요구될 수 있는 바와 같이 멀티 CPU와 멀티 GPU 의 사용을 포함할 수도 있다. 이와 같은 디지털 집적 회로(ID)의 구현예에 대한 세부 사항을 위해, 카덴스 디자 인 시스템즈 사, 시놉시스 사, 멘토 그래픽스 사 및 기타 전자 설계 자동화 회사를 포함하여 이 분야의 많은 기 업과 전문가를 참조할 수 있다. 예시를 위해, 시스템의 디지털 회로 구현예를 SOC 또는 유사한 디지털 집적 회로 주변에 구성된 구성 요소들의 아키텍처로서 나타내었다. 도시된 바와 같이, 시스템은 멀티 코어 CPU, 멀티 코어 GPU, 프로그램 메모리(DRAM) 및 비디오 메모리(VRAM)를 포함하는 SOC 서브 아키텍처; 하드 드라이브(SATA); LCD/터치 스크린 디스플레이 패 널; 마이크/스피커; 키보드; WIFI/블루투스 네트워크 어댑터; 피치 인식 모듈/보드; 및 전원 공급 장치와 분배 회로를 포함한 다양한 구성 요소를 포함하고, 도시된 바와 같이, 이들은 모두 시스템 버스 아키텍처와 지원 컨 트롤러 칩 주변에 집적된다. 프로그램 및 그래픽 명령이 모두 단일의 IC 소자 내에서 구현될 수 있는 하이브리드 멀티 코어 CPU/GPU 칩으로 서 멀티 코어 CPU와 GPU 모두가 실현되는 것도 가능하지만, 멀티 코어 CPU의 주요 기능은 프로그램 메모리(예컨 대, 마이크로 코드)에 로드된 프로그램 명령을 실행하는 것인 반면, 멀티 코어 GPU는 통상적으로 멀티 코어 CPU 로부터 그래픽 명령을 수신하여 실행하며, WIFI/블루투스(BT) 네트워크 어댑터와 피치 인식 모듈/회로뿐만 아니 라, LCD/터치 스크린 디스플레이 패널, 마이크/스피커, 키보드 또는 키패드 장치를 위한 인터페이스 회로와 아 울러, 컴퓨팅 및 그래픽 파이프라인이 모두 지원된다. WIFI/블루투스(BT) 네트워크 어댑터와 피치 인식 모듈/회 로뿐만 아니라, LCD/터치 스크린 디스플레이 패널, 마이크/스피커, 키보드 또는 키패드 장치의 목적은 시스템에 채택된 다른 서브 시스템뿐만 아니라 시스템 인터페이스 서브 시스템(B0)에 의해 지원되는 기능을 지원 및 구현 하는 것일 것이다. 도 9는 제2 예시적 실시형태의 자동화된 장난감 음악 작곡 및 생성 장난감 악기 시스템의 상위 시스템 블록도이 며, 그래픽 아이콘이 음악적 경험 디스크립터에 기초하고, 비디오가 시스템 사용자 인터페이스(즉, 터치 스크린 키보드)를 통해 입력으로서 선택되고, 본 발명의 자동화된 음악 작곡 및 생성 엔진에 의해 사용되어, 시스템 사 용자 인터페이스를 통해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된 비디오 스토리를 생성한다. 도 10은 도 7 내지 도 9에 나타낸 악기 시스템을 사용하여 그래픽 아이콘 기반 음악적 경험 디스크립터와 가상 악기 음악 합성의 사용을 지원하는 본 발명의 제2 예시적 실시형태의 장난감 음악 작곡 및 생성 시스템 내에서 자동화된 음악 작곡 및 생성 프로세스를 실행하는 데 포함되는 주요 단계를 도시한 흐름도이며, (i) 프로세스의 제1단계에서, 시스템 사용자는 본 발명의 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 본 발명의 자동 화된 음악 작곡 및 생성 엔진에 의해 생성된 음악으로 스코어링될 비디오를 선택하고, (ii) 시스템 사용자는 시 스템의 자동화된 음악 작곡 및 생성 엔진에 제공될 그래픽 아이콘 기반 음악적 경험 디스크립터를 선택하며, (iii) 시스템 사용자는 자동화된 음악 작곡 및 생성 엔진을 기동하고, 선택된 비디오 미디어에 스코어링되어 있 는 입력된 음악적 디스크립터에 기초하여 음악을 작곡 및 생성하며, (iv) 시스템은 작곡된 음악을 선택된 비디 오와 조합하여, 표시 및 향유하기 위한 비디오 파일을 제작한다. 본 발명의 제2 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스템의 작동 모드의 사양 도 7 내지 도 10에 나타낸 제2 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스템은 (i) 인간 시스템 사용 자가 자동화된 음악 작곡 및 생성 시스템에 음악적 경험 디스크립터와 타이밍/공간 파라미터 입력을 제공하는 수동 모드; (ii) 인간 시스템 사용자와의 상호 작용 없이 자동화된 음악 작곡 및 생성 시스템의 작동을 자율적 으로 제어하기 위해, 하나 이상의 컴퓨터 제어식 시스템이 자동화된 음악 작곡 및 생성 시스템에 음악적 경험 디스크립터와 선택적으로 타이밍/공간 파라미터를 자동으로 제공하는 자동 모드; 및 (iii) 인간 시스템 사용자 와 하나 이상의 컴퓨터 제어식 시스템이 모두 자동화된 음악 작곡 및 생성 시스템에 음악적 경험 디스크립터와 선택적으로 타이밍/공간 파라미터를 제공하는 하이브리드 모드를 포함한 다양한 작동 모드로 작동할 수 있다. 본 발명의 자동화된 음악 작곡 및 생성 시스템의 제3 예시적 실시형태의 사양 도 11은 그 시스템 사용자의 창조적 및/또는 오락적 요구를 지원하는 도출된 시스템 내에 본 발명의 SOC 기반의 자동화된 음악 작곡 및 생성 엔진을 통합한 본 발명의 제3 예시적 실시형태에 따른 전자 정보 프로세싱 및 디스 플레이 시스템의 사시도이다. 도 11a는 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터와 가상 악기 음악 합성의 사용을 지원하는 본 발명의 SOC 기반 음악 작곡 및 생성 시스템의 상위 시스템 아키텍처를 도시한 개략도이며, 언어 기반 음악적경험 디스크립터와 비디오, 오디오 레코딩, 이미지, 슬라이드 쇼 또는 이벤트 마커는 시스템 사용자 인터페이스 를 통해 입력으로서 제공되고, 본 발명의 자동화된 음악 작곡 및 생성 엔진에 의해 사용되어 시스템 사용자 인 터페이스를 통해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된 미디어(예컨대, 비디오, 팟 캐스트, 이미지, 슬라이드 쇼 등) 또는 이벤트 마커를 생성시킨다. 도 11b는 고상(DRAM) 하드 드라이브와 인터페이싱하는 멀티 코어 CPU, 멀티 코어 GPU, 프로그램 메모리(RAM) 및 비디오 메모리(VRAM)를 포함한 SOC 기반 서브 시스템 아키텍처, 컨트롤러 등을 지원하는 하나 이상의 버스 아키 텍처와 집적된 LCD/터치 스크린 디스플레이 패널, 마이크 스피커, 키보드 또는 키패드, WIFI/블루투스 네트워크 어댑터, 및 3G/LTE/GSM 네트워크 어댑터를 포함하는 도 11 및 도 11a에 도시된 시스템을 나타낸다. 일반적으로, 위에서 특정되고 도 26a 내지 도 84d에 나타낸 상호 협력하는 그 서브 시스템들을 모두 포함하는 도 11에 나타낸 자동 또는 자동화된 음악 작곡 및 생성 시스템은 자동 음악 작곡 및 생성 시스템에 의해 지원될 작동 기능 및 모드를 실현하도록 특수하게 구성되고 프로그래밍된 디지털 전자 회로, 아날로그 전자 회로, 또는 디지털 및 아날로그 전자 회로의 조합을 이용하여 구현될 수 있다. 디지털 집적 회로(IC)는 음악 악기 제조 분 야뿐만 아니라 전자 회로 분야에 공지된 방식으로 실리콘으로 제작되는 칩 위에 실현된 저전력 및 혼합(즉, 디 지털과 아날로그) 신호 시스템(즉, 시스템 온 어 칩 또는 SOC) 구현예를 포함할 수 있다. 이와 같은 구현예는 본 발명의 시스템에 기초한 특정 제품 설계를 위해 필요하거나 요구될 수 있는 바와 같이 멀티 CPU와 멀티 GPU 의 사용을 포함할 수도 있다. 이와 같은 디지털 집적 회로(ID)의 구현예에 대한 세부 사항을 위해, 카덴스 디자 인 시스템즈 사, 시놉시스 사, 멘토 그래픽스 사 및 기타 전자 설계 자동화 회사를 포함하여 이 분야의 많은 기 업과 전문가를 참조할 수 있다. 예시를 위해, 시스템의 디지털 회로 구현예를 SOC 또는 유사한 디지털 집적 회로 주변에 구성된 구성 요소들의 아키텍처로서 나타내었다. 도시된 바와 같이, 시스템은 멀티 코어 CPU, 멀티 코어 GPU, 프로그램 메모리(DRAM) 및 비디오 메모리(VRAM)를 포함하는 SOC 서브 아키텍처; 하드 드라이브(SATA); LCD/터치 스크린 디스플레이 패 널; 마이크/스피커; 키보드; WIFI/블루투스 네트워크 어댑터; 피치 인식 모듈/보드; 및 전원 공급 장치와 분배 회로를 포함한 다양한 구성 요소를 포함하고, 도시된 바와 같이, 이들은 모두 시스템 버스 아키텍처와 지원 컨 트롤러 칩 주변에 집적된다. 프로그램 및 그래픽 명령이 모두 단일의 IC 소자 내에서 구현될 수 있는 하이브리드 멀티 코어 CPU/GPU 칩으로 서 멀티 코어 CPU와 GPU 모두가 실현되는 것도 가능하지만, 멀티 코어 CPU의 주요 기능은 프로그램 메모리(예컨 대, 마이크로 코드)에 로드된 프로그램 명령을 실행하는 것인 반면, 멀티 코어 GPU는 통상적으로 멀티 코어 CPU 로부터 그래픽 명령을 수신하여 실행하며, WIFI/블루투스(BT) 네트워크 어댑터와 피치 인식 모듈/회로뿐만 아니 라, LCD/터치 스크린 디스플레이 패널, 마이크/스피커, 키보드 또는 키패드 장치를 위한 인터페이스 회로와 아 울러, 컴퓨팅 및 그래픽 파이프라인이 모두 지원된다. WIFI/블루투스(BT) 네트워크 어댑터와 피치 인식 모듈/회 로뿐만 아니라, LCD/터치 스크린 디스플레이 패널, 마이크/스피커, 키보드 또는 키패드 장치의 목적은 시스템에 채택된 다른 서브 시스템뿐만 아니라 시스템 인터페이스 서브 시스템(B0)에 의해 지원되는 기능을 지원 및 구현 하는 것일 것이다. 도 12는 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터와 가상 악기 음악 합성의 사용을 지원하는 도 11 및 도 11a에 나타낸 SOC 기반 시스템을 이용한 본 발명의 자동화된 음악 작곡 및 생성 프로세스를 실행하 는 데 포함되는 주요 단계를 설명하며, (i) 프로세스의 제1단계에서, 시스템 사용자는 본 발명의 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 본 발명의 자동화된 음악 작곡 및 생성 시스템에 의해 생성된 음악으로 스코어링될 비디오, 오디오 레코딩(즉, 팟 캐스트), 슬라이드 쇼, 사진이나 이미지 또는 이벤트 마커를 선택하 고, (ii) 그 다음, 시스템 사용자는 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 시스템의 자동화 된 음악 작곡 및 생성 엔진에 제공하며, (iii) 시스템 사용자는 자동화된 음악 작곡 및 생성 시스템을 기동하고, 선택된 미디어 또는 이벤트 마커에 스코어링되어 있는 입력된 음악적 디스크립터에 기초하여 음악을 작곡 및 생성하며, (iv) 시스템 사용자는 스코어링된 미디어 또는 이벤트 마커에 대해 제작된 작곡 및 생성된 음악을 수용하고, 시스템 사용자가 주관적으로 경험하여 형성된 음악적 경험을 고려하여 제작된 음악에 대한 시 스템 사용자의 평가 및/또는 음악 선호도에 관한 피드백을 시스템에 제공하며, (v) 시스템은 수용한 작곡된 음 악을 선택된 미디어 또는 이벤트 마커와 조합하여, 분배 및 표시하기 위한 비디오 파일을 제작한다. 본 발명의 제3 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스템의 작동 모드의 사양 도 11 내지 도 12에 나타낸 제3 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스템은 (i) 인간 시스템 사용 자가 자동화된 음악 작곡 및 생성 시스템에 음악적 경험 디스크립터와 타이밍/공간 파라미터 입력을 제공하는수동 모드; (ii) 인간 시스템 사용자와의 상호 작용 없이 자동화된 음악 작곡 및 생성 시스템의 작동을 자율적 으로 제어하기 위해, 하나 이상의 컴퓨터 제어식 시스템이 자동화된 음악 작곡 및 생성 시스템에 음악적 경험 디스크립터와 선택적으로 타이밍/공간 파라미터를 자동으로 제공하는 자동 모드; 및 (iii) 인간 시스템 사용자 와 하나 이상의 컴퓨터 제어식 시스템이 모두 자동화된 음악 작곡 및 생성 시스템에 음악적 경험 디스크립터와 선택적으로 타이밍/공간 파라미터를 제공하는 하이브리드 모드를 포함한 다양한 작동 모드로 작동할 수 있다. 본 발명의 자동화된 음악 작곡 및 생성 시스템의 제4 예시적 실시형태의 사양 도 13은 인터넷 인프라에 작동 가능하게 연결된 웹 서버, 애플리케이션 서버 및 데이터베이스(RDBMS) 서버를 갖 춘 데이터 프로세싱 센터에 의해 지원되며, 클라이언트 머신, 소셜 네트워크 서버 및 웹 기반 통신 서버에 의해 액세스될 수 있고, 웹 사이트(예컨대, 유튜브, 비메오 등)에서 웹 기반 브라우저를 이용하여 누구나 자동화된 음악 작곡 및 생성 서비스에 액세스할 수 있도록 함으로써, 텍스트 키보드 및/또는 음성 인식 인터페이스를 사 용하여 생성된 언어 기반 음악적 경험 디스크립터와 가상 악기 음악 합성을 사용하여 음악으로 비디오, 이미지, 슬라이드 쇼, 오디오 레코딩 및 기타 이벤트를 스코어링하는, 본 발명의 제4 예시적 실시형태의 기업 수준의 인 터넷 기반 음악 작곡 및 생성 시스템의 개략도이다. 도 13a는 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터와 가상 악기 음악 합성의 사용을 지원하는 도 13에 나타낸 시스템에 의해 지원되는 자동화된 음악 작곡 및 생성 프로세스의 상위 시스템 아키텍처를 도시 한 개략도이며, 언어 기반 음악적 경험 디스크립터와 비디오, 오디오 레코딩, 이미지 또는 이벤트 마커는 웹 기 반 시스템 사용자 인터페이스를 통해 입력으로서 제공되고, 본 발명의 자동화된 음악 작곡 및 생성 엔진에 의해 사용되어 시스템 사용자 인터페이스를 통해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된 미디어(예 컨대, 비디오, 팟 캐스트, 이미지, 슬라이드 쇼 등) 또는 이벤트 마커를 생성시킨다. 도 13b는 도 13 및 도 13a에 도시된 기업 수준의 자동화된 음악 작곡 및 생성 시스템을 구현하기 위해 하나 이 상이 사용될 수 있는 예시적인 컴퓨팅 서버 머신의 시스템 아키텍처를 나타낸다. 도 14는 도 13 및 도 13a에 도시된 시스템에 의해 지원되는 자동화된 음악 작곡 및 생성 프로세스를 실행하는 데 포함되는 주요 단계를 도시한 흐름도이며, (i) 프로세스의 제1단계에서, 시스템 사용자는 본 발명의 자동화 된 음악 작곡 및 생성 시스템에 액세스한 다음, 본 발명의 자동화된 음악 작곡 및 생성 시스템에 의해 생성된 음악으로 스코어링될 비디오, 오디오 레코딩(즉, 팟 캐스트), 슬라이드 쇼, 사진이나 이미지 또는 이벤트 마커 를 선택하고, (ii) 그 다음, 시스템 사용자는 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 시스템 의 자동화된 음악 작곡 및 생성 엔진에 제공하며, (iii) 시스템 사용자는 자동화된 음악 작곡 및 생성 시스템을 기동하고, 선택된 미디어 또는 이벤트 마커에 스코어링되어 있는 입력된 음악적 디스크립터에 기초하여 음악을 작곡 및 생성하며, (iv) 시스템 사용자는 스코어링된 미디어 또는 이벤트 마커에 대해 제작된 작곡 및 생성된 음악을 수용하고, 시스템 사용자가 주관적으로 경험하여 형성된 음악적 경험을 고려하여 제작된 음악에 대한 시 스템 사용자의 평가 및/또는 음악 선호도에 관한 피드백을 시스템에 제공하며, (v) 시스템은 수용한 작곡된 음 악을 선택된 미디어 또는 이벤트 마커와 조합하여, 분배 및 표시하기 위한 비디오 파일을 제작한다. 본 발명의 제4 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스템의 작동 모드의 사양 도 13 내지 도 15w에 나타낸 제4 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스템은 (i) 인간 시스템 사 용자가 자동화된 음악 작곡 및 생성 시스템에 미디어 조각(예컨대, 비디오, 슬라이드 쇼 등)뿐만 아니라 음악적 경험 디스크립터와 타이밍/공간 파라미터 입력을 제공하여, 시스템 사용자에 의해 제공된 명령에 따라 음악 조 각에 스코어링된 음악 조각을 자동으로 생성할 수 있는 스코어 미디어 모드; 및 (ii) 인간 시스템 사용자가 자 동화된 음악 작곡 및 생성 시스템에 음악적 경험 디스크립터와 타이밍/공간 파라미터 입력을 제공하여, 시스템 사용자가 사용하기 위해 스코어링된 음악 조각을 자동으로 생성할 수 있는 음악 작곡 전용 모드를 포함한 다양 한 작동 모드로 작동할 수 있다. 본 발명의 제4 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스템에 의해 지원되는 다양한 작동 모드를 위 한 그래픽 사용자 인터페이스(GUIs)의 사양 도 15a는 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스 (GUI) 스크린이며, (i) 본 발명의 자동화된 음악 작곡 및 생성 프로세스에서의 제1단계로서 시스템에 비디오를 업로드한 다음, 업로드된 비디오에 스코어링되는 음악을 자동으로 작곡 및 생성하기 위한 \"비디오 선택\"과, (ii) 본 발명의 자동화된 음악 작곡 및 생성 시스템을 이용하여 오직 음악만을 작곡하기 위한 \"음악 전용\" 중 하나의 그래픽 아이콘을 선택함으로써, 전술한 바와 같이 그 스코어 미디어 작동 모드 또는 그 음악 작곡 전용작동 모드로 시스템을 유도하기 위한 인터페이스 객체가 표시되어 있다. 스코어 미디어 모드의 사양 사용자가 비디오 또는 다른 미디어와 함께 음악을 생성하고자 결정하는 경우, 사용자는 도 15a 내지 도 15w에 나타내고 후술한 작업 흐름에 참여하는 옵션을 가질 것이다. 이 작업 흐름의 세부 사항은 후술하기로 한다. 시스템 사용자가 도 15a의 GUI에서 \"비디오 선택\" 객체를 선택하면, 도 15b에 나타낸 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이 도 13 내지 도 14에 도시된 시스템에 의해 생성되어 서비스된다. 이 작동 모드에서, 시스템은 도 15b 및 도 15c에 도시된 바와 같이 서로 다른 여러 로컬 및 원격 파일 저장 위치(예컨대, 포토 앨 범, 클라우드에 호스팅된 공유 폴더, 및 개인의 스마트 폰 카메라 롤로부터의 포토 앨범)로부터 사용자가 비디 오 파일 또는 다른 미디어 객체(예컨대, 슬라이드 쇼, 사진, 오디오 파일, 팟 캐스트 등)를 선택할 수 있도록 한다. 사용자가 이 모드를 이용하여 비디오 또는 다른 미디어와 함께 음악을 생성하기로 결정하면, 시스템 사용 자는 그렇게 선택된 옵션을 지원하는 작업 흐름에 참여하는 옵션을 가질 것이다. 도 15d에 나타낸 GUI 스크린을 이용하여, 시스템 사용자가 찾는 음악적 경험을 선택하고 특징짓는 4개의 예시적 인 감정 클래스(즉, 드라마, 액션, 코미디 및 공포)를 표시하기 위해, 시스템 사용자는 음악 감정/음악 스타일/ 음악 스포팅 메뉴로부터 \"음악 감정\" 카테고리를 선택한다. 도 15e는 음악 감정 카테고리-드라마를 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 GUI 스크린을 나타낸다. 도 15f는 음악 감정 카테고리-드라마를 선택하는 시 스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 GUI 스크린을 나 타내며, 시스템 사용자가 선택된 비디오를 스코어링하기 위해 드라마-분류된 감정-행복, 로맨틱 및 영감을 선택 하였다. 도 15g는 음악 감정 카테고리-액션을 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의 해 생성 및 서비스되는 예시적인 GUI 스크린을 나타낸다. 도 15h는 음악 감정 카테고리-액션을 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 GUI 스크린을 나타내 며, 시스템 사용자가 선택된 비디오를 스코어링하기 위해 액션-분류된 감정-흥분 및 스파이를 선택하였다. 도 15i는 음악 감정 카테고리-코미디를 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 GUI 스크린을 나타낸다. 도 15j는 음악 감정 카테고리-드라마를 선택하는 시 스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이며, 시스템 사용자가 선택된 비디오를 스코어링하기 위해 코미디-분류된 감정-별난 및 슬랩 스틱을 선택하였다. 도 15k는 음악 감정 카테고리-공포를 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의 해 생성 및 서비스되는 예시적인 GUI 스크린을 나타낸다. 도 15l는 음악 감정 카테고리-공포를 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페 이스(GUI) 스크린을 나타내며, 시스템 사용자가 선택된 비디오를 스코어링하기 위해 공포-분류된 감정-유혈, 충 격 및 미스터리를 선택하였다. 이 시점에, 제4 예시적 실시형태는 본 발명의 시스템에 의해 작곡 및 생성될 음악의 감정 품질을 특징짓기 위해 고정된 감정 타입 음악적 경험 디스크립터 세트를 나타내고 있지만, 일반적으로, 본 발명의 음악 작곡 시스템은, 예컨대, 언어 디스크립터(예컨대, 단어), 이미지 및/또는 유사한 감정 표현, 형용사, 또는 본 발명의 시스템에 의해 작곡 및 생성될 음악에 표현될 감정 품질을 사용자가 음악으로 전하고자 하는 다른 디스크립터와 같은 광범위한 감정 타입 디스크립터의 선택 및 입력을 지원하도록 쉽게 개조될 수 있을 것으로 이해된다는 것 을 유의하여야 한다. 도 15m은 음악 감정 카테고리의 선택을 종료하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 GUI 스크린을 나타내며, \"당신의 음악을 제작할 준비가 되었나요?\" Amper를 작동시키려면 작곡을 누르고 당신의 선택 사항을 편집하려면 취소를 누르세요\"--메시지를 시스템 사용자에게 표 시하고 있다. 이 작업 흐름 단계에서, 시스템 사용자는 작곡을 선택할 수 있으며, 시스템은 시스템 사용자에 의해 시스템 인 터페이스에 제공된 감정 타입 음악적 경험 파라미터에만 기초하여 자동으로 음악을 작곡 및 생성할 것이다. 그 와 같은 경우, 시스템은 자동화된 음악 작곡 및 생성 시스템에서 사용하기 위한 스타일 타입 파라미터를 선택할것이다. 대안적으로, 시스템 사용자는 사용자가 자신의 선택을 편집하고 음악 작곡 사양에 음악 스타일 파라미 터를 추가할 수 있도록 하기 위해 취소를 선택하는 옵션을 갖는다. 도 15n은 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 GUI 스크린을 나타내며, 시스 템 사용자는 음악 감정/음악 스타일/음악 스포팅 메뉴로부터 음악 스타일 버튼의 선택이 뒤따르는 취소를 선택 함으로써, 시스템 사용자가 찾는 음악적 경험을 선택하고 특징짓는 20개의 스타일(즉, 팝, 록, 힙합 등)을 표시 한다. 도 15o는 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 GUI 스크린이며, 시스템 사용 자가 음악 스타일 카테고리-팝 및 피아노를 선택하였다. 이 시점에, 제4 예시적 실시형태는 본 발명의 시스템에 의해 작곡 및 생성될 음악의 스타일 품질을 특징짓기 위 해 고정된 스타일 타입 음악적 경험 디스크립터 세트를 나타내고 있지만, 일반적으로, 본 발명의 음악 작곡 시 스템은, 예컨대, 언어 디스크립터(예컨대, 단어), 이미지 및/또는 유사한 감정 표현, 형용사, 또는 본 발명의 시스템에 의해 작곡 및 생성될 음악에 표현될 스타일 품질을 사용자가 음악으로 전하고자 하는 다른 디스크립터 와 같은 광범위한 스타일 타입 디스크립터의 선택 및 입력을 지원하도록 쉽게 개조될 수 있을 것으로 이해된다 는 것을 유의하여야 한다. 도 15p는 음악 스타일 카테고리-팝 및 피아노를 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 GUI 스크린이다. 이 작업 흐름 단계에서, 시스템 사용자는 작곡을 선택할 수 있으며, 시스템은 시스템 사용자에 의해 시스템 인터페이스에 제공된 감정 타입 음악적 경험 파라미 터에만 기초하여 자동으로 음악을 작곡 및 생성할 것이다. 그와 같은 경우, 시스템은 자동화된 음악 작곡 및 생 성 시스템에서 사용하기 위해 시스템 사용자에 의해 선택된 감정 타입 및 스타일 타입 음악적 경험 파라미터를 모두 사용할 것이다. 대안적으로, 시스템 사용자는 사용자가 자신의 선택을 편집하고 음악 작곡 사양에 음악 스 포팅 파라미터를 추가할 수 있도록 하기 위해 취소를 선택하는 옵션을 갖는다. 도 15q는 시스템 사용자가 음악 스포팅 기능 중에 선택할 수 있는 6개의 명령을 표시하기 위해, 시스템 사용자 가 음악 감정/음악 스타일/음악 스포팅 메뉴로부터 \"음악 스포팅\" 카테고리를 선택할 수 있도록 하는, 도 13 내 지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 GUI 스크린이다. 도 15r은 기능 메뉴로부터 \"음악 스포팅\"을 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스 템에 의해 생성 및 서비스되는 예시적인 GUI 스크린이며, 도시된 바와 같이 선택된 비디오에 스코어링되어 있는 \"시작\", \"정지\", \"히트\", \"페이드 인\", \"페이드 아웃\" 및 \"새로운 분위기\" 마커를 나타내고 있다. 이 예시적 실시형태에서, \"음악 스포팅\" 기능 또는 모드는 이에 한정되지는 않지만 음악 시작, 정지, 디스크립 터 변경, 스타일 변경, 볼륨 변경, 구조 변경, 악기 편성 변경, 분할, 조합, 복사 및 붙여넣기를 포함하여 시스 템 사용자가 음악으로 전하고자 하는 음악 이벤트의 타이밍 파라미터를 시스템 사용자가 전하도록 할 수 있다. 이 프로세스는 도 26a 내지 도 26d의 서브 시스템 블록(40, 41)에 표시되어 있다. 보다 상세하게 후술하는 바와 같이, 본 발명의 자동 음악 작곡 및 생성 시스템 내의 변환 엔진(B51)은 감정 타입 및 스타일 타입 디스크립터 파라미터뿐만 아니라 타이밍 파라미터 정보를 수신하고, 도 77a 내지 도 79에 반영된 적절한 확률 기반 시스템 작동 파라미터 테이블 세트를 생성하며, 이는 블록(1, 37)으로 지시된 서브 시스템을 이용하여 자신의 각 서브 시스템으로 분배된다. 도 15s는 음악 스포팅 기능의 종료에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예 시적인 GUI 스크린이며, \"음악을 제작할 준비가 되었나요?\" Amper를 작동시키려면 작곡을 누르고 \"당신의 선택 사항을 편집하려면 취소를 누르세요\"--메시지를 시스템 사용자에게 표시하고 있다. 이 시점에, 시스템 사용자는 시스템 사용자에 의해 시스템에 제공된 음악적 경험 디스크립터와 타이밍 파라미터를 이용하여 자동 음악 작곡 및 생성 시스템을 기동하게 될 작곡을 선택하는 옵션을 갖는다. 대안적으로, 시스템 사용자는 취소를 선택할 수 있으며, 그 결과, 시스템은 음악 감정, 음악 스타일 및 음악 스포팅에 대해 3개의 주요 기능 메뉴가 모두 표시 되는 도 15d에 나타낸 바와 같은 GUI 스크린 또는 유사한 형태를 표시하기 위해 되돌아갈 것이다. 도 15t는 \"작곡\" 버튼을 누르는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서 비스되는 예시적인 GUI 스크린을 나타내며, 문구 \"바운싱 뮤직\"에 의해 음악이 작곡 및 생성되고 있음을 지시한 다. 음악 조각을 생성하라는 시스템에 대한 사용자의 요청을 확인한 후, 사용자의 클라이언트 시스템은 그 요청 을 국부적으로 또는 외부적으로 음악 작곡 및 생성 시스템에 전송하며, 그 결과, 요청이 충족된다. 시스템은 음 악 조각을 생성하고, 음악을 국부적으로 또는 외부적으로 사용자에게 전송한다.도 15u는 시스템 사용자의 작곡된 음악이 검토할 준비가 되었을 때 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 GUI 스크린을 나타낸다. 도 15v는 GUI 스크린에서 \"당신의 음악이 준비되었습니다\" 객체를 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 GUI 스크린이다. 프로세스의 이 단계에서, 시스템 사용자는 생성된 음악을 미리 볼 수 있다. 음악이 비디오 또는 다른 미디어와 함께 생성된 경우, 음악은 미리 보기에서 이 콘텐츠에 동기화될 수 있다. 도 15v에 나타낸 바와 같이, 음악 작곡이 생성되었고 선택된 비디오에 대한 미리 보기가 준비된 후, 시스템 사 용자에게는 다수의 옵션, 즉, (i) 음악 조각에 대해 설정된 음악적 경험 디스크립터를 편집하고 음악 작곡을 다시 컴파일하는 옵션; (ii) 작곡되어 생성된 음악 조각을 수용하고 오디오를 비디오와 믹싱하여 스코어링된 비디오 파일을 제작하는 옵션; 및 (iii) 본 발명의 자동 음악 작곡 및 생성 시스템에 의해 지원되는 다른 옵션을 선택하는 옵션이 제공된다. 사용자가 음악에 대한 동일한 요청을 시스템에 다시 제출하고 다른 음악 조각을 수신하고자 한다면, 시스템 사 용자는 그렇게 하는 것을 선택할 수도 있다. 사용자가 사용자 요청의 전부 또는 일부를 변경하고자 한다면, 사 용자는 이와 같은 변경을 할 수 있다. 사용자가 그렇게 하고자 한다면, 사용자는 추가적인 요청을 할 수 있다. 이에 한정되지는 않지만, 콘텐츠 내의 기존 오디오와 플랫폼에 의해 생성된 음악을 포함하여, 사용자가 작업하 고 있는 프로젝트 내의 오디오의 일부 또는 전부를 밸런싱 및 믹싱하는 것을 사용자가 선택할 수 있다. 사용자 는 생성된 음악 조각을 편집하는 것을 선택할 수 있다. 사용자는 생성된 음악을 편집하거나, 타이밍 정보를 삽입하거나, 제거하거나, 조정하거나, 또는 변경할 수 있다. 또한, 사용자는 음악의 구조, 음악의 오케스트레이션을 편집할 수 있고/또는 조각의 음악 커널 또는 음악 게놈을 저장 또는 통합할 수 있다. 사용자는 음악의 템포와 피치를 조정할 수 있다. 각각의 이와 같은 변경은 음악 조각 수준에서 또는 특정 서브 세트와 관련하여, 및/또는 그 조합으로 적용될 수 있다. 사용자가 처음에 플랫폼을 이용하여 생성한 미디어를 다운로드하고/또는 분배하는 것을 사용자가 선택할 수 있다. 사용자가 처음에 플랫폼을 이용하여 생성한 미디어를 다운로드하고/또는 분배하는 것을 사용자가 선택할 수 있 다. 도 15s에 나타낸 GUI 스크린에서, 시스템 사용자가 취소를 선택하기로 결정하는 경우, 시스템은 전술한 바와 같 이 음악 감정 디스크립터, 음악 스타일 디스크립터 및/또는 음악 스포팅 파라미터에 대해 시스템 사용자가 편집 할 수 있도록 하는 완전한 기능 메뉴를 갖춘 도 15d에 나타낸 바와 같은 GUI 스크린을 생성하여 전달한다. 음악 작곡 전용 시스템 작동 모드의 사양 사용자가 도 15a의 GUI 스크린에서 음악 전용을 선택함으로써 임의의 추가적인 콘텐츠와 관계 없이 음악을 생성 하기로 결정하는 경우, 사용자가 음악으로 전하고자 하는 음악 이벤트의 타이밍 파라미터를 전하고자 하는 경우 이 스포팅 기능이 여전히 사용될 수 있을지라도, 도 15b, 도 15c, 도 15q, 도 15r 및 도 15s에 나타낸 GUI 스크 린에 제시되고 설명된 작업 흐름은 필요하지 않다. 도 15b는 시스템 사용자가 도 15a의 GUI에서 \"음악 전용\" 객체를 선택할 때 도 13 내지 도 14에 도시된 시스템 에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이다. 이 작동 모드에서, 시스템은 음악적 경험 디스크립터에 반영된 품질을 표현하는 음악 조각을 자동으로 작곡 및 생성하는 시스템에서 사용하 기 위해, 사용자가 감정 및 스타일 디스크립터 파라미터를 선택할 수 있도록 한다. 이 모드에서는, 전술한 음악 스포팅을 위한 스코어링 명령이 통상적으로 지원되지 않는다는 것을 제외하고, 일반적인 작업 흐름이 스코어 미 디어 모드에서와 동일하다. 그러나, 시스템 사용자는 일부 음악 형태에서 요구되는 경우 타이밍 파라미터 정보 를 입력할 수 있을 것이다. 본 발명의 자동화된 음악 작곡 및 생성 시스템의 제5 예시적 실시형태의 사양 도 16은 본 발명의 제5 예시적 실시형태에 따른 자동화된 음악 작곡 및 생성 시스템을 나타낸다. 이 예시적 실 시형태에서는, 본 발명의 자동화된 음악 작곡 및 생성 엔진과 텍스트, SMS 및/또는 이메일 문서(즉, 메시지)를 생성할 때 클라이언트 머신에 의해 지원되는 그래픽 사용자 인터페이스를 사용하여 사용자에 의해 자동으로 작 곡된 음악을 추가함으로써, 인터넷 상에서 지원되는 텍스트, SMS 및 이메일 서비스를 사용하여 모바일 및 데스크탑 클라이언트 머신 등이 증강될 수 있도록, 인터넷 기반의 자동화된 음악 작곡 및 생성 플랫폼이 배치된다. 이와 같은 인터페이스와 지원된 기능을 이용하면, 원격 시스템 사용자는 다양한 문서 및 파일 타입뿐만 아니라 텍스트, SMS 및 이메일 메시지에 삽입하기 위한 작곡된 음악 조각을 생성하는 데 사용하기 위해 그래픽 및/또는 언어 기반 감정 및 스타일 디스크립터를 쉽게 선택할 수 있다. 도 16a는 도 16에 도시된 시스템 네트워크에 배치된 모바일 클라이언트 머신(예컨대, 인터넷이 가능한 스마트 폰 또는 태블릿 컴퓨터)의 사시도이며, 클라이언트 머신은 터치 스크린 인터페이스, 메모리 아키텍처, 중앙처리 장치, 그래픽 프로세서, 인터페이스 회로, 다양한 통신 프로토콜을 지원하는 네트워크 어댑터, 및 현대 스마트 폰 장치(예컨대, 애플의 아이폰, 삼성의 안드로이드 갤럭시 등)에서 기대되는 기능을 지원하는 기타 기술을 가 진 모바일 컴퓨팅 머신으로서 실현되고, 텍스트 또는 SMS 메시지의 생성과, 메뉴 스크린으로부터 언어 및/또는 그래픽 아이콘 기반 감정 디스크립터 및 스타일 디스크립터를 선택하여 생성된 작곡 음악 조각의 생성 및 삽입 을 지원하는 가상 키보드를 사용자에게 제공하는 제1 예시적인 클라이언트 애플리케이션이 가동하고 있다. 도 16b는 도 16에 도시된 시스템 네트워크에 배치된 모바일 클라이언트 머신(예컨대, 인터넷이 가능한 스마트 폰 또는 태블릿 컴퓨터)의 사시도이며, 클라이언트 머신은 터치 스크린 인터페이스, 메모리 아키텍처, 중앙처리 장치, 그래픽 프로세서, 인터페이스 회로, 다양한 통신 프로토콜을 지원하는 네트워크 어댑터, 및 현대 스마트 폰 장치(예컨대, 애플의 아이폰, 삼성의 안드로이드 갤럭시 등)에서 기대되는 기능을 지원하는 기타 기술을 가 진 모바일 컴퓨팅 머신으로서 실현되고, 본 발명의 원리에 따라 메뉴 스크린으로부터 언어 및/또는 그래픽 아이 콘 기반 감정 디스크립터 및 스타일 디스크립터를 선택하는 사용자에 의해 내부에 생성된 작곡 음악 조각의 생 성 및 내장과 이메일 문서의 생성을 지원하는 가상 키보드를 사용자에게 제공하는 제2 예시적인 클라이언트 애 플리케이션이 가동하고 있다. 도 16c는 도 16에 도시된 시스템 네트워크에 배치된 모바일 클라이언트 머신(예컨대, 인터넷이 가능한 스마트 폰 또는 태블릿 컴퓨터)의 사시도이며, 클라이언트 머신은 터치 스크린 인터페이스, 메모리 아키텍처, 중앙처리 장치, 그래픽 프로세서, 인터페이스 회로, 다양한 통신 프로토콜을 지원하는 네트워크 어댑터, 및 현대 스마트 폰 장치(예컨대, 애플의 아이폰, 삼성의 안드로이드 갤럭시 등)에서 기대되는 기능을 지원하는 기타 기술을 가 진 모바일 컴퓨팅 머신으로서 실현되고, 마이크로소프트 워드, PDF 또는 이미지(예컨대, jpg 또는 tiff) 문서의 생성과, 메뉴 스크린으로부터 언어 및/또는 그래픽 아이콘 기반 감정 디스크립터 및 스타일 디스크립터를 선택 하여 생성된 작곡 음악 조각의 생성 및 삽입을 지원하는 가상 키보드를 사용자에게 제공하는 제2 예시적인 클라 이언트 애플리케이션이 가동하고 있다. 도 16d는 도 16에 도시된 시스템 네트워크에 배치된 모바일 클라이언트 머신(예컨대, 인터넷이 가능한 스마트 폰 또는 태블릿 컴퓨터)의 사시도이며, 클라이언트 머신은 터치 스크린 인터페이스, 메모리 아키텍처, 중앙처리 장치, 그래픽 프로세서, 인터페이스 회로, 다양한 통신 프로토콜을 지원하는 네트워크 어댑터, 및 현대 스마트 폰 장치(예컨대, 애플의 아이폰, 삼성의 안드로이드 갤럭시 등)에서 기대되는 기능을 지원하는 기타 기술을 가 진 모바일 컴퓨팅 머신으로서 실현되고, 웹 기반(즉, html) 문서의 생성과, 메뉴 스크린으로부터 언어 및/또는 그래픽 아이콘 기반 감정 디스크립터 및 스타일 디스크립터를 선택하여 생성된 작곡 음악 조각의 생성 및 삽입 을 지원하는 가상 키보드를 사용자에게 제공하는 제2 예시적인 클라이언트 애플리케이션이 가동하고 있음으로써, 음악 조각이 내장된 URL 상에서 동작하는 통상의 웹 브라우저를 사용하여 원격 클라이언트에게 전 달되어 경험될 수 있고, 이로부터 내장된 음악 조각은 웹, 애플리케이션 및 데이터베이스 서버를 통해 서비스된 다. 도 17은 시스템 버스 아키텍처와 집적된 시스템 버스 아키텍처 주위의 멀티 코어 CPU, 멀티 코어 GPU, 프로그램 메모리(RAM), 비디오 메모리(VRAM), 하드 드라이브(SATA 드라이브), LCD/터치 스크린 디스플레이 패널, 마이크 스피커, 키보드, WIFI/블루투스 네트워크 어댑터, 및 3G/LTE/GSM 네트워크 어댑터를 포함한 서브 시스템 모듈을 포함하는 도 16a, 도 16b, 도 16c 및 도 16d에 도시된 시스템에 배치된 각 클라이언트 머신의 시스템 아키텍처 의 개략도이다. 도 18은 작곡된 음악을 텍스트, SMS, 이메일 문서/메시지에 추가하기 위해 언어 및/또는 그래픽 아이콘 기반 음 악적 경험 디스크립터와 가상 악기 음악 합성의 사용을 지원하는 본 발명의 인터넷 기반 음악 작곡 및 생성 시 스템의 상위 시스템 아키텍처를 도시한 개략도이며, 언어 기반 또는 아이콘 기반 음악적 경험 디스크립터가 시 스템 사용자 인터페이스를 통해 입력으로서 제공되고, 본 발명의 자동화된 음악 작곡 및 생성 엔진에 의해 사용 되어 최종 마무리 및 전송 전에 시스템 사용자 인터페이스를 통해 시스템 사용자에 의한 미리보기를 위해 생성 되는 음악적으로 스코어링된 텍스트 문서 또는 메시지를 생성한다.도 19는 음악적으로 스코어링된 텍스트, SMS, 이메일, PDF, 워드 및/또는 html 문서를 생성하기 위해 언어 및/ 또는 그래픽 아이콘 기반 음악적 경험 디스크립터와 가상 악기 음악 합성의 사용을 지원하는 도 16 내지 도 18 에 나타낸 웹 기반 시스템을 사용한 본 발명의 자동화된 음악 작곡 및 생성 프로세스를 실행하는 데 포함되는 주요 단계를 도시한 흐름도이며, (i) 프로세스의 제1단계에서, 시스템 사용자는 본 발명의 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 본 발명의 자동화된 음악 작곡 및 생성 시스템에 의해 생성된 음악으로 스코 어링될(예컨대, 증강될) 텍스트, SMS 또는 이메일 메시지 또는 워드, PDF 또는 HTML 문서를 선택하고, (ii) 그 다음, 시스템 사용자는 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 시스템의 자동화된 음악 작곡 및 생성 엔진에 제공하며, (iii) 시스템 사용자는 자동화된 음악 작곡 및 생성 시스템을 기동하여 선택된 메시 지 또는 문서에 스코어링되어 있는 입력된 음악적 디스크립터에 기초한 음악을 작곡 및 생성하며, (iv) 시스템 사용자는 메시지 또는 문서에 대해 제작된 작곡 및 생성된 음악을 수용하거나, 음악을 거부하고 다른 음악적 경 험 디스크립터의 제공 및 갱신된 음악적 경험 디스크립터 입력에 기초하여 음악을 재작곡하도록 하는 요구를 포 함한 피드백을 시스템에 제공하며, (v) 시스템은 수용한 작곡된 음악을 메시지 또는 문서와 조합하여, 분배 및 표시하기 위한 새로운 파일을 제작한다. 본 발명의 자동화된 음악 작곡 및 생성 시스템의 제6 예시적 실시형태의 사양 도 20은 본 발명의 자동화된 음악 작곡 및 생성 엔진의 변형된 버전을 채택한 AI 기반 자율 음악 작곡 및 작곡 연주 시스템 주변의 실제 또는 합성 음악 악기를 갖춘 음악가 밴드의 개략도이며, AI 기반 시스템은 그 주변 악 기 및 음악가로부터 음악 신호를 수신하여 이들 악기를 버퍼링 및 분석하고, 이에 응답하여, 음악가 밴드에 의 해 연주되고 있는 음악을 증강하게 될 음악을 실시간으로 작곡 및 생성할 수 있거나, 인간 음악가에 의한 후속 재생, 검토 및 심의를 위해 기록되는 음악을 녹음, 분석 및 작곡할 수 있다. 도 21은 LCD 터치 타입 디스플레이 스크린, 내장형 스테레오 마이크 세트, 시스템 환경 내의 음악 악기 세트로 부터 생성되는 오디오 신호를 수신하기 위한 오디오 신호 입력 커넥터 세트, 시스템 환경 내의 악기 세트로부터 MIDI 입력 신호를 수신하기 위한 MIDI 신호 입력 커넥터 세트, 오디오 출력 신호를 오디오 신호 전치 증폭기 및 /또는 증폭기로 전달하기 위한 오디오 출력 신호 커넥터, WIFI 및 BT 네트워크 어댑터 및 관련 신호 안테나 구 조, 및 사용자 작동 모드를 위한 기능 버튼 세트를 포함한 콤팩트하고 견고한 휴대용 하우징을 가진 자율적 음 악 분석, 작곡 및 연주 악기의 개략도이며, 사용자 작동 모드는 (i) 악기 시스템이 음악 세션 중에 그 (로컬 또 는 원격) 음악 환경으로부터 수신하여 분석한 음악 정보 스트림에 응답하여 음악적으로 자율적으로 선도하는 LEAD 모드, (ii) 악기 시스템이 음악 세션 중에 그 (로컬 또는 원격) 음악 환경 내의 음악 악기로부터 수신하여 분석한 음악에 응답하여 음악적으로 자율적으로 추종하는 FOLLOW 모드, (iii) 시스템이 음악 세션 중에 그 (로 컬 또는 원격) 환경 내의 음악 악기로부터 수신하여 분석한 음악에 기초하여 음악을 자동으로 작곡하는 COMPOSE 모드, 및 (iv) 시스템이 음악 세션 중에 그 환경으로부터 수신하여 분석한 음악 정보에 응답하여 자동으로 작곡 된 음악을 실시간으로 자율적으로 연주하는 PERFORM 모드를 포함한다. 도 22는 도 21에 나타낸 자동화된 음악 작곡 및 생성 악기 시스템의 상위 시스템 아키텍처를 도시한다. 도 22에 도시된 바와 같이, 시스템 환경 내의 음악 악기 세트로부터 생성된 MIDI 입력 신호뿐만 아니라 오디오 신호가 악기 시스템에 의해 수신되고, 이 신호들이 피치 이벤트 및 멜로디 구조의 발생에 대하여 시간 및/또는 주파수 도메인에서 실시간으로 분석된다. 이와 같은 분석 및 프로세싱의 목적은, 시스템이 본 발명의 자동화된 음악 작 곡 및 생성 엔진을 사용하여 자동화된 음악 작곡 및 생성의 생성에 사용하기 위해 이 정보로부터 음악적 경험"}
{"patent_id": "10-2018-7011569", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "디스크립터를 자동으로 요약할 수 있도록 하는 것이다. 도 23은 시스템 버스 아키텍처와 집적된 시스템 버스 아키텍처 주위의 멀티 코어 CPU, 멀티 코어 GPU, 프로그램 메모리(DRAM), 비디오 메모리(VRAM), 하드 드라이브(SATA 드라이브), LCD/터치 스크린 디스플레이 패널, 스테레 오 마이크, 오디오 스피커, 키보드, WIFI/블루투스 네트워크 어댑터, 및 3G/LTE/GSM 네트워크 어댑터를 포함한 서브 시스템 모듈의 구성을 포함하는 도 20 및 도 21에 도시된 시스템의 시스템 아키텍처의 개략도이다. 일반적으로, 위에서 특정되고 도 26a 내지 도 84e에 나타낸 상호 협력하는 그 서브 시스템들을 모두 포함하는 도 20 및 도 21에 나타낸 자동 또는 자동화된 음악 작곡 및 생성 시스템은 자동 음악 작곡 및 생성 시스템에 의 해 지원될 작동 기능 및 모드를 실현하도록 특수하게 구성되고 프로그래밍된 디지털 전자 회로, 아날로그 전자 회로, 또는 디지털 및 아날로그 전자 회로의 조합을 이용하여 구현될 수 있다. 디지털 집적 회로(IC)는 음악 악 기 제조 분야뿐만 아니라 전자 회로 분야에 공지된 방식으로 실리콘으로 제작되는 칩 위에 실현된 저전력 및 혼 합(즉, 디지털과 아날로그) 신호 시스템(즉, 시스템 온 어 칩 또는 SOC) 구현예일 수 있다. 이와 같은 구현예는 본 발명의 시스템에 기초한 특정 제품 설계를 위해 필요하거나 요구될 수 있는 바와 같이 멀티 CPU와 멀티 GPU의 사용을 포함할 수도 있다. 이와 같은 디지털 집적 회로(ID)의 구현예에 대한 세부 사항을 위해, 카덴스 디자 인 시스템즈 사, 시놉시스 사, 멘토 그래픽스 사 및 기타 전자 설계 자동화 회사를 포함하여 이 분야의 많은 기 업과 전문가를 참조할 수 있다. 예시를 위해, 시스템의 디지털 회로 구현예를 SOC 또는 유사한 디지털 집적 회로 주변에 구성된 구성 요소들의 아키텍처로서 나타내었다. 도시된 바와 같이, 시스템은 멀티 코어 CPU, 멀티 코어 GPU, 프로그램 메모리(DRAM) 및 비디오 메모리(VRAM)를 포함하는 SOC 서브 아키텍처; 하드 드라이브(SATA); LCD/터치 스크린 디스플레이 패 널; 마이크/스피커; 키보드; WIFI/블루투스 네트워크 어댑터; 피치 인식 모듈/보드; 및 전원 공급 장치와 분배 회로를 포함한 다양한 구성 요소를 포함하고, 도시된 바와 같이, 이들은 모두 시스템 버스 아키텍처와 지원 컨 트롤러 칩 주변에 집적된다. 프로그램 및 그래픽 명령이 모두 단일의 IC 소자 내에서 구현될 수 있는 하이브리드 멀티 코어 CPU/GPU 칩으로 서 멀티 코어 CPU와 GPU 모두가 실현되는 것도 가능하지만, 멀티 코어 CPU의 주요 기능은 프로그램 메모리(예컨 대, 마이크로 코드)에 로드된 프로그램 명령을 실행하는 것인 반면, 멀티 코어 GPU는 통상적으로 멀티 코어 CPU 로부터 그래픽 명령을 수신하여 실행하며, WIFI/블루투스(BT) 네트워크 어댑터와 피치 인식 모듈/회로뿐만 아니 라, LCD/터치 스크린 디스플레이 패널, 마이크/스피커, 키보드 또는 키패드 장치를 위한 인터페이스 회로와 아 울러, 컴퓨팅 및 그래픽 파이프라인이 모두 지원된다. WIFI/블루투스(BT) 네트워크 어댑터와 피치 인식 모듈/회 로뿐만 아니라, LCD/터치 스크린 디스플레이 패널, 마이크/스피커, 키보드 또는 키패드 장치의 목적은 시스템에 채택된 다른 서브 시스템뿐만 아니라 시스템 인터페이스 서브 시스템(B0)에 의해 지원되는 기능을 지원 및 구현 하는 것일 것이다. 도 24는 도 20 내지 도 23에 나타낸 시스템을 사용한 본 발명의 자동화된 음악 작곡 및 생성 프로세스를 실행하 는 데 포함되는 주요 단계를 도시한 흐름도이며, (i) 프로세스의 제1단계에서, 시스템 사용자는 본 발명의 자동 화된 음악 작곡 및 생성 악기 시스템에 대해 LEAD 또는 FOLLOW 작동 모드 중 하나를 선택하고, (ii) 그 다음, 세션에 앞서, 시스템은 음악 세션 중의 창조적 환경에서 음악가 그룹에 의해 연주되는 음악 악기 그룹과 인터페 이스되며, (iii) 세션 중에, 시스템은 세션 중에 악기 그룹으로부터 생성된 오디오 및/또는 MIDI 데이터 신호를"}
{"patent_id": "10-2018-7011569", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수신하고, 이 신호들을 피치 데이터 및 멜로디 구조에 대하여 분석하며, (iv) 세션 중에, 시스템은 요약된 피치 및 멜로디 데이터로부터 음악적 디스크립터를 자동으로 생성하고, 음악적 경험 디스크립터를 사용하여 실시간 단위로 세션을 위한 음악을 작곡하며, (v) PERFORM 모드가 선택된 경우, 시스템은 작곡된 음악을 생성하고, COMPOSE 모드가 선택된 경우, 세션 중에 작곡된 음악이 음악가 그룹에 의한 후속 액세스 및 검토를 위해 저장된 다. 본 발명의 자동화된 음악 작곡 및 생성 엔진의 예시적 실시형태의 사양 도 25a는 본원에서 본 발명의 다양한 실시형태에 채택된 본 발명의 자동화된 음악 작곡 및 생성 엔진(E1)의 상 위 시스템도이다. 도시된 바와 같이, 엔진(E1)은 도시된 바와 같이 구성된 사용자 GUI 기반 입력 서브 시스템 (A0), 일반 리듬 서브 시스템(A1), 일반 피치 생성 서브 시스템(A2), 멜로디 리듬 생성 서브 시스템(A3), 멜로 디 피치 생성 서브 시스템(A4), 오케스트레이션 서브 시스템(A5), 컨트롤러 코드 제작 서브 시스템(A6), 디지털 조각 제작 서브 시스템(A7) 및 피드백 및 학습 서브 시스템(A8)을 포함한다. 도 25b는 2개의 매우 높은 수준의 서브 시스템, 즉, (i) 일반 피치 생성 서브 시스템(A2), 멜로디 피치 생성 서 브 시스템(A4), 오케스트레이션 서브 시스템(A5) 및 컨트롤러 코드 제작 서브 시스템(A6)을 포함한 피치 랜드스 케이프 서브 시스템(C0), 및 (ii) 일반 리듬 생성 서브 시스템(A1), 멜로디 리듬 생성 서브 시스템(A3), 오케스 트레이션 서브 시스템(A5) 및 컨트롤러 코드 제작 서브 시스템(A6)을 포함한 리듬 랜드스케이프 서브 시스템 (C1)을 포함하는 본 발명의 시스템을 도시한 상위 시스템도이다. 이 단계에서, 본 발명의 자동화된 음악 작곡 및 생성 시스템의 다양한 실시형태를 실시할 때 이해하는 데 도움 이 될 중요한 음악 이론 개념과 관련된 몇 가지 중요한 정의와 용어를 논의하는 것이 적절하다. 그러나, 본 발 명의 시스템이 매우 복잡하고 풍부한 시스템 아키텍처를 갖고 있기는 하지만, 그와 같은 특징 및 양태는 모든 시스템 사용자에게 본질적으로 명료하므로, 그들이 음악 이론에 대한 지식이나 음악적 경험 및/또는 재능을 필 수적으로 갖지 않을 수 있게 한다. 본 발명의 시스템을 사용하기 위해서, 시스템 사용자는, (i) 자동으로 작곡 된 음악 조각에 시스템 사용자가 전하고자 하는 감정의 종류에 대한 감각, 및/또는 (ii) 시스템 사용자가 음악 작곡이 추종하길 원하거나 생각하는 음악적 스타일에 대한 감각을 갖기만 하면 된다. 최상위에서, \"피치 랜드스케이프\"(C0)는 음악 조각 내에서 모든 이벤트의 공간 내의 배열을 포함하는 용어이다. 이와 같은 이벤트는 항상 그러한 것은 아니지만 흔히 음악 조각의 키 및 조성에 의해 상위에서; 음악 조각의 구 조, 형태 및 악절에 의해 중위에서; 그리고 각각의 악기, 참가자 및/또는 음악 조각의 다른 구성 요소의 이벤트 의 특정 조직에 의해 하위에서 조직된다. 피치 랜드스케이프 관리를 지원하기 위해 시스템 내에서 이용 가능한 다양한 서브 시스템 자원이 도 25b에 나타낸 개략도에 지시되어 있다. 마찬가지로, \"리듬 랜드스케이프\"(C1)는 음악 조각 내에서 모든 이벤트의 시간 내의 배열을 포함하는 용어이다. 이와 같은 이벤트는 항상 그러한 것은 아니지만 흔히 음악 조각의 템포, 박자 및 길이에 의해 상위에서; 음악 조각의 구조, 형태 및 악절에 의해 중위에서; 그리고 각각의 악기, 참가자 및/또는 음악 조각의 다른 구성 요소 의 이벤트의 특정 조직에 의해 하위에서 조직된다. 피치 랜드스케이프 관리를 지원하기 위해 시스템 내에서 이 용 가능한 다양한 서브 시스템 자원이 도 25b에 나타낸 개략도에 지시되어 있다. 본 발명의 자동화된 음악 작곡 및 생성 시스템에 채택된 피치 및 리듬 랜드스케이프 서브 시스템 아키텍처 내에 서 중요한 역할을 하는 몇 가지 다른 상위 개념이 존재한다. 특히, \"멜로디 피치\"는 독립적으로 또는 다른 이벤트와 협력하여 작곡되고 있는 음악 조각의 멜로디 및/또는 임 의의 멜로디 재료의 일부를 구성하는 모든 이벤트의 공간 내의 배열을 음악 조각 내에서 포함하는 용어이다. \"멜로디 리듬\"은 독립적으로 또는 다른 이벤트와 협력하여 작곡되고 있는 음악 조각의 멜로디 및/또는 임의의 멜로디 재료의 일부를 구성하는 모든 이벤트의 시간 내의 배열을 음악 조각 내에서 포함하는 용어이다. 작곡되고 있는 음악 조각을 위한 \"오케스트레이션\"은 음악 조각의 조작, 배열 및/또는 적응을 설명하기 위해 사 용되는 용어이다. 작곡되고 있는 음악 조각을 위한 \"컨트롤러 코드\"는 실제 음표, 리듬 및 악기 편성에서 흔히 분리된 음악적 표 현에 관한 정보를 설명하기 위해 사용되는 용어이다. 작곡되고 있는 음악의 \"디지털 조각\"은 오직 아날로그 방식만이 아니라 디지털이나 디지털과 아날로그 조합에 의한 음악 조각의 표현을 설명하기 위해 사용되는 용어이다. 도 26a 내지 도 26p는 함께 취합되어, 사용자 GUI 기반 입출력 서브 시스템(A0/B0)에 제공된 음악적 경험 디스 크립터가 매우 상세하게 기술적으로 후술한 본 발명의 자동화된 음악 작곡 및 생성 프로세스에서의 프로세싱 및 사용을 위해 자신의 적절한 서브 시스템에 분배되도록, 도 25의 각 서브 시스템이 본 발명의 원리에 따라 다른 서브 시스템과 함께 어떻게 구성되는지를 나타낸다. 이 시점에서, 본 발명의 자동화된 음악 작곡 및 생성 시스 템(S) 내에서 상위 서브 시스템(A0 내지 A8)을 구현하는 역할을 하는 각각의 서브 시스템(B0 내지 B52)을 확인 및 설명하는 것이 적절하다. 구체적으로, 도 26a 내지 도 26d에 나타낸 바와 같이, GUI 기반 입력 서브 시스템(A0)은 사용자 GUI 기반 입출 력 서브 시스템(B0); 디스크립터 파라미터 포착 서브 시스템(B1); 파라미터 변환 엔진 서브 시스템(B51); 스타 일 파라미터 포착 서브 시스템(B37); 및 타이밍 파라미터 포착 서브 시스템(B40)을 포함한다. 이 서브 시스템들 은 시스템 사용자를 통해 또는 가까운 종단 시스템 애플리케이션에 의해 요구되는 다른 수단 및 방식을 통해 시 스템(A0)에 제공된 모든 음악적 경험 파라미터(예컨대, 감정 디스크립터, 스타일 디스크립터 및 타이밍/공간 디 스크립터)를 수신 및 프로세싱한다. 도 30, 도 26e, 도 26f, 도 26g, 도 26h, 도 26i 및 도 36에 나타낸 바와 같이, 작곡될 음악 조각을 위한 일반 리듬을 생성하는 일반 리듬 생성 서브 시스템(A1)은 길이 생성 서브 시스템(B2); 템포 생성 서브 시스템(B3); 박자 생성 서브 시스템(B4); 비트 계산기 서브 시스템(B6); 마디 계산기 서브 시스템(B8); 노래 형태 생성 서브 시스템(B9); 하위 악절 길이 생성 서브 시스템(B15); 하위 악절 내 화음 수 계산기 서브 시스템(B16); 악절 길 이 생성 서브 시스템(B12); 특이 악절 생성 서브 시스템(B10); 악절 내 화음 수 계산기 서브 시스템(B13); 화음 길이 생성 서브 시스템(B11); 특이 하위 악절 생성 서브 시스템(B14); 악기 편성 서브 시스템(B38); 악기 선택 기 서브 시스템(B39); 및 타이밍 생성 서브 시스템(B41)을 포함한다. 도 36 및 도 26k에 나타낸 바와 같이, 작곡되고 있는 음악 조각을 위한 화음(즉, 피치 이벤트)을 생성하는 일반 피치 생성 서브 시스템(A2)은 키 생성 서브 시스템(B5); 조성 생성 서브 시스템(B7); 제1 일반 리듬 생성 서브 시스템(B17); 하위 악절 화음 진행 생성 서브 시스템(B19); 악절 화음 진행 생성 서브 시스템(B18); 화음 자리 바꿈 생성 서브 시스템(B20); 악기 편성 서브 시스템(B38); 및 악기 선택기 서브 시스템(B39)을 포함한다. 도 26k 및 도 26l에 나타낸 바와 같이, 작곡되고 있는 음악 조각을 위한 멜로디 리듬을 생성하는 멜로디 리듬 생성 서브 시스템(A3)은 멜로디 하위 악절 길이 생성 서브 시스템(B25); 멜로디 하위 악절 생성 서브 시스템(B24); 멜로디 악절 길이 생성 서브 시스템(B23); 멜로디 특이 악절 생성 서브 시스템(B22); 멜로디 길이 생성 서브 시스템(B21); 및 멜로디 음표 리듬 생성 서브 시스템(B26)을 포함한다. 도 26l 및 도 27m에 나타낸 바와 같이, 작곡되고 있는 음악 조각을 위한 멜로디 피치를 생성하는 멜로디 피치 생성 서브 시스템(A4)은 제1 피치 생성 서브 시스템(B27); 하위 악절 피치 생성 서브 시스템(B29); 악절 피치 생성 서브 시스템(B28); 및 피치 옥타브 생성 서브 시스템(B30)을 포함한다. 도 26m에 나타낸 바와 같이, 작곡되고 있는 음악 조각을 위한 오케스트레이션을 생성하는 오케스트레이션 서브 시스템(A5)은 오케스트레이션 생성 서브 시스템(B31)을 포함한다. 도 26m에 나타낸 바와 같이, 작곡되고 있는 음악 조각을 위한 컨트롤러 코드를 제작하는 컨트롤러 코드 제작 서 브 시스템(A6)은 컨트롤러 코드 생성 서브 시스템(B32)을 포함한다. 도 26m 및 도 26n에 나타낸 바와 같이, 작곡되고 있는 음악의 디지털 조각을 제작하는 디지털 조각 제작 서브 시스템(A7)은 디지털 오디오 샘플 오디오 검색기 서브 시스템(B33); 디지털 오디오 샘플 조직기 서브 시스템 (B34); 조각 통합기 서브 시스템(B35); 조각 포맷 번역기 서브 시스템(B50); 및 조각 전달기 서브 시스템(B36) 을 포함한다. 도 26n, 도 26o 및 도 26p에 나타낸 바와 같이, 시스템의 피드백 및 학습 사이클을 지원하는 피드백 및 학습 서 브 시스템(A8)은 피드백 서브 시스템(B42); 음악 편집성 서브 시스템(B43); 선호도 저장기 서브 시스템(B44); 음악적 커널 서브 시스템(B45); 사용자 취향 서브 시스템(B46); 모집단 취향 서브 시스템(B47); 사용자 선호도 서브 시스템(B48); 및 모집단 선호도 서브 시스템(B49)을 포함한다. 도 26n, 도 26o 및 도 26p에 나타낸 바와 같이, 시스템의 피드백 및 학습 사이클을 지원하는 피드백 및 학습 서 브 시스템(A8)은 피드백 서브 시스템(B42); 음악 편집성 서브 시스템(B43); 선호도 저장기 서브 시스템(B44); 음악적 커널 서브 시스템(B45); 사용자 취향 서브 시스템(B46); 모집단 취향 서브 시스템(B47); 사용자 선호도 서브 시스템(B48); 및 모집단 선호도 서브 시스템(B49)을 포함한다. 시스템에 채택된 서브 시스템의 개요를 파 악하였으나, 이 시점에, 도 26a 내지 도 26p에 명확하게 나타낸 바와 같이, 서브 시스템들 사이에 존재하는 입 출력 포트 관계를 상세하게 설명하는 것이 적절하다. 도 26a 내지 도 26j에 나타낸 바와 같이, 시스템 사용자는 통상적으로 당업계에 공지된 LCD 터치 스크린, 키보 드 또는 마이크 음성 인식 인터페이스를 사용하여, GUI 기반 입출력 서브 시스템(B0)에 감정, 스타일 및 타이밍 타입 음악적 경험 디스크립터와 같은 입력을 제공한다. 그리고, GUI 기반 입출력 서브 시스템(B0)으로부터 나온 다양한 데이터 신호 출력이 도시된 바와 같이 디스크립터 파라미터 포착 서브 시스템(B1), 파라미터 변환 엔진 서브 시스템(B51), 스타일 파라미터 포착 서브 시스템(B37) 및 타이밍 파라미터 포착 서브 시스템(B40)에 입력 데이터 신호로서 제공된다. (감정) 디스크립터 파라미터 포착 서브 시스템(B1)은 단어, 이미지 및/또는 작곡될 음악 조각에 의해 제작되는 음악적 경험의 다른 표현을 수신하고, 그 다음, 포착된 이 감정 타입 음악적 경험 디스크립터들은 다른 서브 시스템으로의 후속 전송을 위해 바람직하게는 로컬 데이터 저장 장치(예컨대, 로컬 데이터베이스, DRAM 등)에 저장된다. 스타일 파라미터 포착 서브 시스템(B17)은 단어, 이미지 및/또는 작곡될 음악 조각에 의해 제작되는 음악적 경험의 다른 표현을 수신하고, 그 다음, 포착된 이 스타일 타입 음악적 경험 디스크립터들은 마찬가지로 다른 서브 시스템으로의 후속 전송을 위해 바람직하게는 로컬 데이터 저장 장치(예 컨대, 로컬 데이터베이스, DRAM 등)에 저장된다. 음악 스포팅 기능이 시스템 사용자에 의해 활성화되거나 액세 스되고, 타이밍 파라미터가 입력 서브 시스템(B0)으로 전송되는 경우, 타이밍 파라미터 포착 서브 시스템(B40) 은 그와 같은 기능성을 지원하기 위해 다른 서브 시스템(예컨대, 서브 시스템(A1, A2 등))을 활성화할 것이다. 파라미터 변환 엔진 서브 시스템(B51)은 단어, 이미지 및/또는 작곡될 음악 조각에 의해 제작되는 음악적 경험 파라미터의 다른 표현을 수신하고, 이 감정 타입, 스타일 타입 및 타이밍 타입 음악적 경험 디스크립터들은 각 서브 시스템으로의 후속 분배 및 로드를 위해 제공된 시스템 사용자 입력에 기초하여 확률 기반 시스템 작동 파 라미터 테이블 세트를 생성하기 위해 엔진 서브 시스템(B51)에 의해 변환되며, 이에 대해서는 다른 도면과 아울 러 특히 도 23b3a 내지 도 28e 및 도 28f 내지 도 28j를 참조하여, 매우 상세하게 기술적으로 후술하기로 한다. 시스템에 채택된 서브 시스템의 개요를 파악하였으나, 이 시점에, 도 26a 내지 도 26p에 명확하게 나타낸 바와 같이, 서브 시스템들 사이에 존재하는 입출력 포트 관계를 상세하게 설명하는 것이 적절하다. 입력 서브 시스템(B0) 내의 서브 시스템들 사이의 입출력 포트 연결의 사양 도 26a 내지 도 26j에 나타낸 바와 같이, 시스템 사용자는 통상적으로 당업계에 공지된 LCD 터치 스크린, 키보 드 또는 마이크 음성 인식 인터페이스를 사용하여, GUI 기반 입출력 서브 시스템(B0)에 감정, 스타일 및 타이밍타입 음악적 경험 디스크립터와 같은 입력을 제공한다. 그리고, 감정 및 스타일 음악적 디스크립터와 타이밍 파 라미터를 부호화하는 GUI 기반 입출력 서브 시스템(B0)으로부터 나온 다양한 데이터 신호 출력이 도시된 바와 같이 디스크립터 파라미터 포착 서브 시스템(B1), 파라미터 변환 엔진 서브 시스템(B51), 스타일 파라미터 포착 서브 시스템(B37) 및 타이밍 파라미터 포착 서브 시스템(B40)에 입력 데이터 신호로서 제공된다. 도 26a 내지 도 26j에 나타낸 바와 같이, (감정) 디스크립터 파라미터 포착 서브 시스템(B1)은 단어, 이미지 및 /또는 작곡될 음악 조각에 의해 제작되는 음악적 경험의 다른 표현을 수신하고, 그 다음, 포착된 이 감정 타입 음악적 경험 디스크립터들은 다른 서브 시스템으로의 후속 전송을 위해 바람직하게는 로컬 데이터 저장 장치(예 컨대, 로컬 데이터베이스, DRAM 등)에 저장된다. 도 26a 내지 도 26j에 나타낸 바와 같이, 스타일 파라미터 포착 서브 시스템(B17)은 단어, 이미지 및/또는 작곡 될 음악 조각에 의해 제작되는 음악적 경험의 다른 표현을 수신하고, 그 다음, 포착된 이 스타일 타입 음악적 경험 디스크립터들은 마찬가지로 다른 서브 시스템으로의 후속 전송을 위해 바람직하게는 로컬 데이터 저장 장 치(예컨대, 로컬 데이터베이스, DRAM 등)에 저장된다. \"음악 스포팅\" 기능이 시스템 사용자에 의해 활성화되거나 액세스되고, 타이밍 파라미터가 입력 서브 시스템 (B0)으로 전송되는 경우, 타이밍 파라미터 포착 서브 시스템(B40)은 그와 같은 기능성을 지원하기 위해 다른 서 브 시스템(예컨대, 서브 시스템(A1, A2 등))을 활성화할 것이다. 도 26a 내지 도 26j에 나타낸 바와 같이, 파라미터 변환 엔진 서브 시스템(B51)은 단어, 이미지 및/또는 작곡될 음악 조각에 의해 반영되는 음악적 경험 파라미터와 타이밍 파라미터의 다른 표현을 수신하고, 이 감정 타입, 스타일 타입 및 타이밍 타입 음악적 경험 디스크립터들은 각 서브 시스템으로 후속 분배 및 로드되는 확률 기반 시스템 작동 파라미터 테이블 세트를 제공된 시스템 사용자 입력에 기초하여 출력으로서 생성하기 위해 파라미 터 변환 엔진 서브 시스템(B51)에 의해 자동으로 그리고 투명하게 변환되며, 이에 대해서는 다른 도면과 아울러 특히 도 28c 내지 도 28e 및 도 28f 내지 도 28j를 참조하여, 매우 상세하게 기술적으로 후술하기로 한다. 일반 리듬 생성 서브 시스템(A1) 내의 서브 시스템들 사이의 입출력 포트 연결의 사양 도 26a 내지 도 26j에 나타낸 바와 같이, 일반 리듬 생성 서브 시스템(A1)은 작곡될 음악 조각을 위해 일반 리 듬을 생성한다. 도 26a 내지 도 26j에 나타낸 바와 같이, 사용자 GUI 기반 입출력 서브 시스템(B0)의 데이터 입력 포트는 LCD 터치 스크린 디스플레이 패널, 키보드, 마이크 및 당업계에 공지된 다양한 종류의 데이터 입력 장치에 의해 실 현될 수 있다. 도시된 바와 같이, 사용자 GUI 기반 입출력 서브 시스템(B0)의 데이터 출력은 (감정 타입) 디스 크립터 파라미터 포착 서브 시스템(B1), 파라미터 변환 엔진 서브 시스템(B51), 스타일 파라미터 포착 서브 시 스템(B37) 및 타이밍 파라미터 포착 서브 시스템(B40)의 데이터 입력 포트에 연결된다. 도 26a 내지 도 26p에 나타낸 바와 같이, 파라미터 변환 엔진 서브 시스템(B51)의 데이터 입력 포트는 모집단 취향 서브 시스템(B47)의 출력 데이터 포트와 사용자 선호도 서브 시스템(B48)의 데이터 입력 포트에 연결되어, 데이터 피드백 경로 기능을 한다. 도 26a 내지 도 26p에 나타낸 바와 같이, 파라미터 변환 엔진(B51)의 데이터 출력 포트는 (감정 타입) 디스크립 터 파라미터 포착 서브 시스템(B1)과 스타일 파라미터 포착 서브 시스템(B37)의 데이터 입력 포트에 연결된다. 도 26a 내지 도 26f에 나타낸 바와 같이, 스타일 파라미터 포착 서브 시스템(B37)의 데이터 출력 포트는 악기 편성 서브 시스템(B38)과 하위 악절 길이 생성 서브 시스템(B15)의 데이터 입력 포트에 연결된다. 도 26a 내지 도 26g에 나타낸 바와 같이, 타이밍 파라미터 포착 서브 시스템(B40)의 데이터 출력 포트는 타이밍 생성 서브 시스템(B41), 길이 생성 서브 시스템(B2), 템포 생성 서브 시스템(B3), 박자 생성 서브 시스템(B4) 및 키 생성 서브 시스템(B5)의 데이터 입력 포트에 연결된다. 도 26a 내지 도 26g에 나타낸 바와 같이, (감정 타입) 디스크립터 파라미터 포착 서브 시스템(B1)과 타이밍 파 라미터 포착 서브 시스템(B40)의 데이터 출력 포트는 (i) 구조 제어를 위한 길이 생성 서브 시스템(B2)의 데이 터 입력 포트, (ii) 템포 제어를 위한 템포 생성 서브 시스템(B3)의 데이터 입력 포트, (iii) 박자 제어를 위한 박자 생성 서브 시스템(B4)의 데이터 입력 포트, 및 (iv) 키 제어를 위한 키 생성 서브 시스템(B5)의 데이터 입 력 포트에 연결된다. 도 26e에 나타낸 바와 같이, 길이 생성 서브 시스템(B2)과 템포 생성 서브 시스템(B3)의 데이터 출력 포트는 비 트 계산기 서브 시스템(B6)의 데이터 입력 포트에 연결된다. 도 26e 내지 도 26k에 나타낸 바와 같이, 비트 계산기 서브 시스템(B6)과 박자 생성 서브 시스템(B4)의 데이터 출력 포트는 마디 계산기 서브 시스템(B8)의 입력 데이터 포트에 연결된다. 도 26e, 도 26f, 도 26g 및 도 26h에 나타낸 바와 같이, 마디 계산기 서브 시스템(B8)의 출력 데이터 포트는 노 래 형태 생성 서브 시스템(B9)과 아울러 특이 하위 악절 생성 서브 시스템(B14)의 데이터 입력 포트에 연결된다. 도 26g에 나타낸 바와 같이, 키 생성 서브 시스템(B5)의 출력 데이터 포트는 조성 생성 서브 시스템(B7)의 데이 터 입력 포트에 연결된다. 도 26g 및 도 26j에 나타낸 바와 같이, 조성 생성 서브 시스템(B7)의 데이터 출력 포트는 제1 일반 리듬 생성 서브 시스템(B17)과 아울러 하위 악절 화음 진행 생성 서브 시스템(B19)의 데이터 입력 포트에 연결된다. 도 26e1, 도 26h 및 도 26i에 나타낸 바와 같이, 노래 형태 서브 시스템(B9)의 데이터 출력 포트는 하위 악절 길이 생성 서브 시스템(B15), 화음 길이 생성 서브 시스템(B11) 및 악절 길이 생성 서브 시스템(B12)의 데이터 입력 포트에 연결된다. 도 26g, 도 26h, 도 26i 및 도 26j에 나타낸 바와 같이, 하위 악절 길이 생성 서브 시스템(B15)의 데이터 출력 포트는 특이 하위 악절 생성 서브 시스템(B14)의 입력 데이터 포트에 연결된다. 도시된 바와 같이, 특이 하위 악절 생성 서브 시스템(B14)의 출력 데이터 포트는 하위 악절 내 화음 수 계산기 서브 시스템(B16)의 입력 데이 터 포트에 연결된다. 도시된 바와 같이, 화음 길이 생성 서브 시스템(B11)의 출력 데이터 포트는 악절 내 화음 수 계산기 서브 시스템(B13)에 연결된다. 도 26h에 나타낸 바와 같이, 하위 악절 내 화음 수 계산기 서브 시스템(B16)의 데이터 출력 포트는 악절 길이 생성 서브 시스템(B12)의 데이터 입력 포트에 연결된다. 도 26e, 도 26h, 도 26i 및 도 26j에 나타낸 바와 같이, 악절 길이 생성 서브 시스템(B12)의 데이터 출력 포트 는 특이 악절 생성 서브 시스템(B10)의 데이터 입력 포트에 연결된다. 도 26j에 나타낸 바와 같이, 특이 악절 생성 서브 시스템(B10)의 데이터 출력 포트는 악절 내 화음 수 계산기 서브 시스템(B13)의 데이터 입력 포트에 연결된다. 일반 피치 생성 서브 시스템(A2) 내의 서브 시스템들 사이의 입출력 포트 연결의 사양 도 26j 및 도 26k에 나타낸 바와 같이, 일반 피치 생성 서브 시스템(A2)은 작곡되고 있는 음악 조각을 위해 화 음을 생성한다. 도 26g 및 도 26j에 나타낸 바와 같이, 제1 화음 생성 서브 시스템(B17)의 데이터 출력 포트는 조성 생성 서브 시스템(B7)의 출력 데이터 포트에도 연결된 하위 악절 화음 진행 생성 서브 시스템(B19)의 데이터 입력 포트에 연결된다. 도 26j에 나타낸 바와 같이, 하위 악절 화음 진행 생성 서브 시스템(B19)의 데이터 출력 포트는 악절 화음 진행 생성 서브 시스템(B18)의 데이터 입력 포트에 연결된다. 도 26j 및 도 26k에 나타낸 바와 같이, 악절 화음 진행 생성 서브 시스템(B18)의 데이터 출력 포트는 화음 자리 바꿈 생성 서브 시스템(B20)의 데이터 입력 포트에 연결된다. 멜로디 리듬 생성 서브 시스템(A3) 내의 서브 시스템들 사이의 입출력 포트 연결의 사양 도 26k 및 도 26l에 나타낸 바와 같이, 멜로디 리듬 생성 서브 시스템(A3)은 작곡되고 있는 음악 조각을 위해 멜로디 리듬을 생성한다. 도 26j 및 도 26k에 나타낸 바와 같이, 화음 자리바꿈 생성 서브 시스템(B20)의 데이터 출력 포트는 멜로디 하 위 악절 길이 생성 서브 시스템(B18)의 데이터 입력 포트에 연결된다. 도 26k에 나타낸 바와 같이, 화음 자리바꿈 생성 서브 시스템(B20)의 데이터 출력 포트는 멜로디 하위 악절 길 이 생성 서브 시스템(B25)의 데이터 입력 포트에 연결된다. 도 26k에 나타낸 바와 같이, 멜로디 하위 악절 길이 생성 서브 시스템(B25)의 데이터 출력 포트는 멜로디 하위 악절 생성 서브 시스템(B24)의 데이터 입력 포트에 연결된다.도 26k에 나타낸 바와 같이, 멜로디 하위 악절 생성 서브 시스템(B24)의 데이터 출력 포트는 멜로디 악절 길이 생성 서브 시스템(B23)의 데이터 입력 포트에 연결된다. 도 26k에 나타낸 바와 같이, 멜로디 악절 길이 생성 서브 시스템(B23)의 데이터 출력 포트는 멜로디 특이 악절 생성 서브 시스템(B22)의 데이터 입력 포트에 연결된다. 도 26k 및 도 26l에 나타낸 바와 같이, 멜로디 특이 악절 생성 서브 시스템(B22)의 데이터 출력 포트는 멜로디 길이 생성 서브 시스템(B21)의 데이터 입력 포트에 연결된다. 도 26l에 나타낸 바와 같이, 멜로디 길이 생성 서브 시스템(B21)의 데이터 출력 포트는 멜로디 음표 리듬 생성 서브 시스템(B26)의 데이터 입력 포트에 연결된다. 멜로디 피치 생성 서브 시스템(A4) 내의 서브 시스템들 사이의 입출력 포트 연결의 사양 도 26l 내지 도 26n에 나타낸 바와 같이, 멜로디 피치 생성 서브 시스템(A4)은 작곡되고 있는 음악 조각을 위해 멜로디 피치를 생성한다. 도 26l에 나타낸 바와 같이, 멜로디 음표 리듬 생성 서브 시스템(B26)의 데이터 출력 포트는 제1 피치 생성 서 브 시스템(B27)의 데이터 입력 포트에 연결된다. 도 26l에 나타낸 바와 같이, 제1 피치 생성 서브 시스템(B27)의 데이터 출력 포트는 하위 악절 피치 생성 서브 시스템(B29)의 데이터 입력 포트에 연결된다. 도 26l에 나타낸 바와 같이, 하위 악절 피치 생성 서브 시스템(B29)의 데이터 출력 포트는 악절 피치 생성 서브 시스템(B28)의 데이터 입력 포트에 연결된다. 도 26l 및 도 26m에 나타낸 바와 같이, 악절 피치 생성 서브 시스템(B28)의 데이터 출력 포트는 피치 옥타브 생 성 서브 시스템(B30)의 데이터 입력 포트에 연결된다. 오케스트레이션 서브 시스템(A5) 내의 서브 시스템들 사이의 입출력 포트 연결의 사양 도 26m에 나타낸 바와 같이, 오케스트레이션 서브 시스템(A5)은 작곡되고 있는 음악 조각을 위해 오케스트레이 션을 생성한다. 도 26d 및 도 26m에 나타낸 바와 같이, 피치 옥타브 생성 서브 시스템(B30)과 악기 선택기 서브 시스템(B39)의 데이터 출력 포트는 오케스트레이션 생성 서브 시스템(B31)의 데이터 입력 포트에 연결된다. 도 26m에 나타낸 바와 같이, 오케스트레이션 생성 서브 시스템(B31)의 데이터 출력 포트는 컨트롤러 코드 생성 서브 시스템(B32)의 데이터 입력 포트에 연결된다. 컨트롤러 코드 제작 서브 시스템(A6) 내의 서브 시스템들 사이의 입출력 포트 연결의 사양 도 26m에 나타낸 바와 같이, 컨트롤러 코드 제작 서브 시스템(A6)은 작곡되고 있는 음악 조각을 위해 컨트롤러 코드를 제작한다. 도 26m에 나타낸 바와 같이, 오케스트레이션 생성 서브 시스템(B31)의 데이터 출력 포트는 컨트롤러 코드 생성 서브 시스템(B32)의 데이터 입력 포트에 연결된다. 디지털 조각 제작 서브 시스템(A7) 내의 서브 시스템들 사이의 입출력 포트 연결의 사양 도 26m 및 도 26n에 나타낸 바와 같이, 디지털 조각 제작 서브 시스템(A7)은 음악의 디지털 조각을 제작한다. 도 26m에 나타낸 바와 같이, 컨트롤러 코드 생성 서브 시스템(B32)의 데이터 출력 포트는 디지털 오디오 샘플 오디오 검색기 서브 시스템(B33)의 데이터 입력 포트에 연결된다. 도 26m 및 도 26n에 나타낸 바와 같이, 디지털 오디오 샘플 오디오 검색기 서브 시스템(B33)의 데이터 출력 포 트는 디지털 오디오 샘플 조직기 서브 시스템(B34)의 데이터 입력 포트에 연결된다. 도 26n에 나타낸 바와 같이, 디지털 오디오 샘플 조직기 서브 시스템(B34)의 데이터 출력 포트는 조각 통합기 서브 시스템(B35)의 데이터 입력 포트에 연결된다. 도 26n에 나타낸 바와 같이, 조각 통합기 서브 시스템(B35)의 데이터 출력 포트는 조각 포맷 번역기 서브 시스 템(B50)의 데이터 입력 포트에 연결된다.도 26n에 나타낸 바와 같이, 조각 포맷 번역기 서브 시스템(B50)의 데이터 출력 포트는 조각 전달기 서브 시스 템(B36)과 아울러 피드백 서브 시스템(B42)의 데이터 입력 포트에 연결된다. 피드백 및 학습 서브 시스템(A8) 내의 서브 시스템들 사이의 입출력 포트 연결의 사양 도 26n, 도 26o 및 도 26p에 나타낸 바와 같이, 피드백 및 학습 서브 시스템(A8)은 시스템의 피드백 및 학습 사 이클을 지원한다. 도 26n에 나타낸 바와 같이, 조각 전달기 서브 시스템(B36)의 데이터 출력 포트는 피드백 서브 시스템(B42)의 데이터 입력 포트에 연결된다. 도 26n 및 도 26o에 나타낸 바와 같이, 피드백 서브 시스템(B42)의 데이터 출력 포트는 음악 편집성 서브 시스 템(B43)의 데이터 입력 포트에 연결된다. 도 26o에 나타낸 바와 같이, 음악 편집성 서브 시스템(B43)의 데이터 출력 포트는 선호도 저장기 서브 시스템 (B44)의 데이터 입력 포트에 연결된다. 도 26o에 나타낸 바와 같이, 선호도 저장기 서브 시스템(B44)의 데이터 출력 포트는 음악적 커널(DNA) 서브 시 스템(B45)의 데이터 입력 포트에 연결된다. 도 26o에 나타낸 바와 같이, 음악적 커널(DNA) 서브 시스템(B45)의 데이터 출력 포트는 사용자 취향 서브 시스 템(B46)의 데이터 입력 포트에 연결된다. 도 26o에 나타낸 바와 같이, 사용자 취향 서브 시스템(B46)의 데이터 출력 포트는 모집단 취향 서브 시스템 (B47)의 데이터 입력 포트에 연결된다. 도 26o 및 도 26p에 나타낸 바와 같이, 모집단 취향 서브 시스템(B47)의 데이터 출력 포트는 사용자 선호도 서 브 시스템(B48)과 모집단 선호도 서브 시스템(B49)의 데이터 입력 포트에 연결된다. 도 26a 내지 도 26p에 나타낸 바와 같이, 음악 편집성 서브 시스템(B43), 선호도 저장기 서브 시스템(B44), 음 악적 커널(DNA) 서브 시스템(B45), 사용자 취향 서브 시스템(B46) 및 모집단 취향 서브 시스템(B47)의 데이터 출력 포트는, 도 26a 내지 도 26p에 나타낸 제1 데이터 피드백 루프의 일부로서, 파라미터 변환 엔진 서브 시스 템(B51)뿐만 아니라, 사용자 선호도 서브 시스템(B48)과 모집단 선호도 서브 시스템(B49)의 데이터 입력 포트에 제공된다. 도 26n 내지 도 26p에 나타낸 바와 같이, 음악 편집성 서브 시스템(B43), 선호도 저장기 서브 시스템(B44), 음 악적 커널(DNA) 서브 시스템(B45), 사용자 취향 서브 시스템(B46), 모집단 취향 서브 시스템(B47), 사용자 선호 도 서브 시스템(B48) 및 모집단 선호도 서브 시스템(B49)의 데이터 출력 포트는, 도 26a 내지 도 26p에 나타낸 제2 데이터 피드백 루프의 일부로서, (감정 타입) 디스크립터 파라미터 포착 서브 시스템(B1), 스타일 디스크립 터 포착 서브 시스템(B37) 및 타이밍 파라미터 포착 서브 시스템(B40)의 데이터 입력 포트에 제공된다. 본 발명의 자동화된 음악 작곡 및 생성 시스템으로 상위(A-레벨) 서브 시스템을 구현하는 하위(B-레벨) 서브 시 스템 및 각 하위 서브 시스템에 채택된 파라미터 테이블의 신속한 식별의 사양 도 23b3a, 도 28d 및 도 28e를 참조하면, 본 발명의 시스템 전체의 각 서브 시스템 내에 로드된 파라미터 테이 블에 저장된 시스템 작동 파라미터 세트로 파라미터 변환 엔진 서브 시스템(B51)을 통해 시스템 사용자가 제공 한 감정, 스타일, 타이밍/공간 파라미터 세트가 어떻게 매핑되는지를 예시한 개략도가 도시되어 있다. 또한, 도 28f, 도 28g, 도 28h, 도 28i 및 도 28j에 도시된 개략도 역시 시스템 아키텍처 내에서 특정 상위(A-레벨) 서브 시스템을 구현하기 위해 어떤 하위(B-레벨) 서브 시스템이 사용되는지, 그리고 시스템 내에서 어떤 B-레벨 서브 시스템 내에 어떤 파라미터 테이블이 채택되는지를 예시한 맵을 제공한다. 이 서브 시스템들과 파라미터 테이블 들은 이하에서 매우 상세하게 기술적으로 특정하기로 한다. 본 발명의 자동화된 음악 작곡 및 생성 시스템 내의 다양한 서브 시스템의 프로그램된 테이블 내에 유지된 확률 기반 시스템 작동 파라미터의 사양 도 77a 내지 도 79에 특정된 다양한 서브 시스템의 프로그램된 테이블 내에 유지된 확률 기반 시스템 작동 파라 미터(SOPs)는 본 발명의 자동화된 음악 작곡 및 생성 시스템 내에서 중요한 역할을 한다. 이 시점에, (i) 이 시 스템 작동 파라미터(SOPs) 테이블들, (ii) 이들이 포함하고 있는 정보 요소, (iii) 이들이 나타내는 음악 이론 객체, (iv) 자신의 각 서브 시스템 내에서 이들이 실행하는 기능, 및 (v) 이와 같은 정보 객체가 의도된 목적을위해 서브 시스템 내에서 어떻게 사용되는지를 매우 상세하게 설명하는 것이 적절하다. 템포 생성 서브 시스템(B3) 내의 템포 생성 테이블의 사양 도 77a는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 템포 생성 서브 시스템(B3)에 유지된 확률 기반 파라미 터 테이블을 나타낸다. 도 77a에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선택된 각각 의 감정 타입 음악적 경험 디스크립터(예컨대, 도 83a 내지 도 83f의 감정 디스크립터 테이블로부터 선택된 행 복, 슬픔, 분노, 무서움, 사랑)에 대해, 시스템에 의해 지원되는 각 템포(분당 비트)에 대한 확률 척도가 제공 되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 템포 생성 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 템포(들)를 결정하기 위한 체계를 제 공하는 것이다. 템포 생성 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 33에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템 은 테이블 내의 어떤 값(들) 및/또는 파라미터(들)가 사용될지에 대해 결정(들)을 행한다. 길이 생성 서브 시스템(B2) 내의 길이 생성 테이블의 사양 도 77b는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 길이 생성 서브 시스템(B2)에 유지된 확률 기반 파라미 터 테이블을 나타낸다. 도 77b에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선택된 각각 의 감정 타입 음악적 경험 디스크립터(예컨대, 도 83a 내지 도 83f의 감정 디스크립터 테이블로부터 선택된 행 복, 슬픔, 분노, 무서움, 사랑)에 대해, 시스템에 의해 지원되는 각 길이(초)에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 길이 생성 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 길이(들)를 결정하기 위한 체계를 제 공하는 것이다. 길이 생성 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 32에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템 (B2)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 박자 생성 서브 시스템(B4) 내의 박자 생성 테이블의 사양 도 77c는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 박자 생성 서브 시스템(B4)에 유지된 확률 기반 박자 생성 테이블을 나타낸다. 도 77c에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선택된 각 각의 감정 타입 음악적 경험 디스크립터(예컨대, 도 83a 내지 도 83f의 감정 디스크립터 테이블로부터 선택된 행복, 슬픔, 분노, 무서움, 사랑)에 대해, 시스템에 의해 지원되는 각 박자에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 박자 생성 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 박자(들)를 결정하기 위한 체계를 제 공하는 것이다. 박자 생성 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 34에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템 (B4)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 모든 시스템 작동 파라미터(SOP) 테이블과 마찬가지로, 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자 입력 서브 시스템(B0)에서 선택된 모든 가능한 음악적 경험 디스크립터를 위한 확률 가중 템포 파라미터 테이블 을 생성한다. 이 입력들을 고려하여, 이 서브 시스템(B4)은 조각의 박자(들)를 생성한다. 예컨대, 입력 디스크 립터가 행복이고 길이가 30초이며 템포가 분당 60비트인 조각은 4/4 박자(마디당 4개의 사분음표)를 사용할 1/3 의 확률, 6/8 박자(마디당 6개의 팔분음표)를 사용할 1/3의 확률 및 2/4 템포(마디당 2개의 사분음표)를 사용할 1/3의 확률을 가질 수 있다. 다양한 섹션, 음악 타이밍 파라미터 및/또는 시작과 정지가 음악에 존재하는 경우, 다양한 박자가 선택될 수 있다. 감정 및 스타일 디스크립터와 박자 사이에는 강한 관계가 있다. 예컨대, 왈츠는 흔히 3/4 박자로 연주되는 반면, 행진곡은 흔히 2/4 박자로 연주된다. 시스템의 박자 테이블은 음악적 경험 및/또는 스타일과 재료가 전달 되는 박자 사이의 문화적 연관성을 반영한다. 또한, 음악 조각의 박자(들)는 감정 및 스타일 디스크립터 입력에 무관할 수 있으며, 단지 특정 타이밍 요청과 음악의 마디 및/또는 비트를 정렬하기 위해 존재할 수 있다. 예컨대, 특정 템포의 음악 조각이 4/4 마디의 네 번째 비트와 다음 4/4 마디의 첫 번째 비트 사이의 중간에 발생하였을 조각 내의 순간에 악센트를 넣을 필요가있을 경우, 원하는 악센트에 한 마디 앞서 7/8로 박자를 변화시키면, 마디의 첫 번째 비트에서 악센트가 정확하 게 대신 발생하게 될 것이며, 이는 마디의 다운비트와 일치하는 보다 음악적인 악센트에 적합할 것이다. 키 생성 서브 시스템(B5) 내의 키 생성 테이블의 사양 도 77d는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 키 생성 서브 시스템(B5)에 유지된 확률 기반 파라미터 테이블을 나타낸다. 도 77d에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선택된 각각의 감정 타입 음악적 경험 디스크립터에 대해, 시스템에 의해 지원되는 각 키에 대한 확률 척도가 제공되며, 이 확 률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 키 생성 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 키(들)를 결정하기 위한 체계를 제공하 는 것이다. 키 생성 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 35에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B5)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 조성 생성 서브 시스템(B7) 내의 조성 생성 테이블의 사양 도 77e는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 조성 생성 서브 시스템(B7)에 유지된 확률 기반 파라미 터 테이블을 나타낸다. 도 77e에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선택된 각각 의 감정 타입 음악적 경험 디스크립터에 대해, 시스템에 의해 지원되는 각 조성(즉, 메이저, 마이너 내추럴, 마 이너 하모닉, 마이너 멜로딕, 도리안, 프리지안, 리디안, 믹솔리디안, 에올리안, 및 로크리안)에 대한 확률 척 도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된 다. 조성 생성 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 조성(들)을 결정하기 위한 체계를 제 공하는 것이다. 조성 생성 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 38에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템 (B7)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 노래 형태 생성 서브 시스템(B9) 내의 파라미터 테이블의 사양 도 77f는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 노래 형태 생성 서브 시스템(B9)에 유지된 확률 기반 파라미터 테이블을 나타낸다. 도 77f에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선택 된 각각의 감정 타입 음악적 경험 디스크립터에 대해, 각 하위 악절 형태(a, aa, ab, aaa, aba, abc)뿐만 아니 라, 시스템에 의해 지원되는 각 노래 형태(즉, A, AA, AB, AAA, ABA, ABC)에 대한 확률 척도가 제공되며, 이 확 률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 노래 형태 생성 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 노래 형태(들)를 결정하기 위한 체계를 제공하는 것이다. 노래 형태 생성 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정된 다양한 서 브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 39a 및 도 39b에 도시된 유도 추계학적 프로 세스를 통해, 서브 시스템(B9)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명 의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 하위 악절 생성 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 하위 악절(들)을 결정하기 위한 체계를 제공하는 것이다. 하위 악절 생성 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정된 다양한 서 브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 39a 및 도 39b에 도시된 유도 추계학적 프로 세스를 통해, 서브 시스템(B9)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명 의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 하위 악절 길이 생성 서브 시스템(B15) 내의 파라미터 테이블의 사양 도 77g는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 하위 악절 길이 생성 서브 시스템(B15)에 유지된 확률 기반 파라미터 테이블을 나타낸다. 도 77g에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선택된 각각의 감정 타입 음악적 경험 디스크립터에 대해, 시스템에 의해 지원되는 각 하위 악절 길이에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에사용된다. 하위 악절 길이 생성 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 길이(들) 또는 지속 시간 (들)을 결정하기 위한 체계를 제공하는 것이다. 하위 악절 길이 생성 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 40에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B15)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터 (들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 화음 길이 생성 서브 시스템(B11) 내의 파라미터 테이블의 사양 도 77h는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 화음 길이 생성 서브 시스템(B11)에 유지된 확률 기반 파라미터 테이블을 나타낸다. 도 77h에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선택 된 각각의 감정 타입 음악적 경험 디스크립터에 대해, 시스템에 의해 지원되는 각 제1 화음 길이 및 제2 화음 길이에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프 로세스 중에 사용된다. 제1 화음 길이 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 제1 화음(들) 또는 우세 하모니 (들)의 지속 시간을 결정하기 위한 체계를 제공하는 것이다. 제1 화음 길이 테이블은 B1, B37, B40 및 B41에 의 해 결정된 바와 같이 적절한 파라미터 세트를 로드함으로써 사용되며, 유도 추계학적 프로세스를 통해, 서브 시 스템은 테이블의 어떤 값(들) 및/또는 파라미터(들)가 사용될지에 대해 결정(들)을 행한다. 제2 화음 길이 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 비-제1 화음(들) 또는 우세 하모 니(들)의 지속 시간을 결정하기 위한 체계를 제공하는 것이다. 제2 화음 길이 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 77q, 도 77r 및 도 77s에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B11)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대 해 결정(들)을 행한다. 일반 리듬 생성 서브 시스템(B17) 내의 파라미터 테이블의 사양 도 77i는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 일반 리듬 생성 서브 시스템(B17)에 유지된 확률 기반 파라미터 테이블을 나타낸다. 도 77i에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선택 된 각각의 감정 타입 음악적 경험 디스크립터에 대해, 시스템에 의해 지원되는 (즉, 계이름으로 표시된) 각 밑 음 음표에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 제1 화음 밑음 테이블의 주요 기능은 조각, 섹션, 악절 또는 다른 유사한 구조의 제1 화음(들)의 밑음을 결정하 기 위한 체계를 제공하는 것이다. 제1 화음 밑음 테이블은 서브 시스템(B1, B5, B7 및 B37)에 의해 결정된 다양 한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 유도 추계학적 프로세스를 통해, 서브 시 스템(B17)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작 곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 화음 기능 테이블의 주요 기능은 화음 또는 화음들의 음악 기능을 결정하기 위한 체계를 제공하는 것이다. 화음 기능 테이블은 B1, B5, B7 및 B37에 의해 결정된 바와 같이 적절한 파라미터 세트를 로드함으로써 사용되며, 도 47에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B17)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행 한다. 하위 악절 화음 진행 생성 서브 시스템(B19) 내의 파라미터 테이블의 사양 도 77j 및 도 77k는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 하위 악절 화음 진행 생성 서브 시스템(B1 9)에 유지된 확률 기반 파라미터 테이블을 나타낸다. 도 77j 및 도 77k에 나타낸 바와 같이, 시스템에 의해 지 원되고 시스템 사용자에 의해 선택된 각각의 감정 타입 음악적 경험 디스크립터에 대해, 시스템에 의해 지원되 는 마디 내의 (즉, 계이름으로 표시된) 각각의 오리지널 화음 밑음과 향후 비트에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 화음 기능 밑음 변조기 테이블의 주요 기능은 현재 결정되고 있는 화음 기능(들)에 미래의 화음 밑음 음표 결정 (들)을 인과 방식으로 연결하기 위한 체계를 제공하는 것이다. 화음 기능 밑음 변조기 테이블은 서브 시스템(B1, B5, B7 및 B37)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 유도 추계학적 프로세스를 통해, 서브 시스템(B19)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터 (들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 현재 화음 기능의 주요 기능은 화음 기능 테이블과 동일하다. 현재 화음 기능 테이블은 화음 기능 테이블과 동 일하다. 비트 밑음 변조기 테이블의 주요 기능은 화음 밑음(들) 및 기능(들)이 현재 결정되고 있는 시간의 배열에 미래 의 화음 밑음 음표 결정(들)을 인과 방식으로 연결하기 위한 체계를 제공하는 것이다. 비트 밑음 변조기 테이블 은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으 로써 사용되며, 도 48a, 도 48b 및 도 48c에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B19)은 파라 미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로 세스 중에 사용될지에 대해 결정(들)을 행한다. 화음 자리바꿈 생성 서브 시스템(B20) 내의 파라미터 테이블의 사양 도 77l는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 화음 자리바꿈 생성 서브 시스템(B20)에 유지된 확률 기반 파라미터 테이블을 나타낸다. 도 77l에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선택된 각각의 감정 타입 음악적 경험 디스크립터에 대해, 시스템에 의해 지원되는 (즉, 계이름으로 표시된) 각 자리바꿈 및 오리지널 화음 밑음에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자 동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 제1 화음 자리바꿈 테이블의 주요 기능은 조각, 섹션, 악절 또는 다른 유사한 구조의 제1 화음(들)의 자리바꿈 을 결정하기 위한 체계를 제공하는 것이다. 제1 화음 자리바꿈 테이블은 B1, B37, B40 및 B41에 의해 결정된 바 와 같이 적절한 파라미터 세트를 로드함으로써 사용되며, 유도 추계학적 프로세스를 통해, 서브 시스템(B20)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 화음 자리바꿈 테이블의 주요 기능은 조각, 섹션, 악절 또는 다른 유사한 구조의 비-제1 화음(들)의 자리바꿈을 결정하기 위한 체계를 제공하는 것이다. 화음 자리바꿈 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결 정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 50a, 도 50b 및 도 50c에 도 시된 유도 추계학적 프로세스를 통해, 서브 시스템(B20)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미 터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 멜로디 하위 악절 길이 진행 생성 서브 시스템(B25) 내의 파라미터 테이블의 사양 도 77m은 본 발명의 자동화된 음악 작곡 및 생성 엔진 및 시스템의 멜로디 하위 악절 길이 진행 생성 서브 시스 템(B25)에 유지된 확률 기반 파라미터 테이블을 나타낸다. 도 77m에 나타낸 바와 같이, 시스템에 의해 지원되고 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복에 대 해 구성된 각각의 감정 타입 음악적 경험 디스크립터에 대해, 시스템에 의해 지원된 하위 악절로 멜로디가 시작 하는 각각의 1/4 음표 수에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 멜로디 길이 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 길이(들) 및/또는 리듬 값(들)을 결정하기 위한 체계를 제공하는 것이다. 멜로디 길이 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정 된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 51에 도시된 유도 추계학적 프 로세스를 통해, 서브 시스템(B25)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 멜로디 하위 악절 생성 서브 시스템(B24) 내의 파라미터 테이블의 사양 도 77n는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 멜로디 하위 악절 길이 생성 서브 시스템(B24)에 유지 된 확률 기반 파라미터 테이블의 개략도를 나타낸다. 도 77n에 나타낸 바와 같이, 시스템에 의해 지원되고 시스 템 사용자에 의해 선택된 각각의 감정 타입 음악적 경험 디스크립터에 대해, 시스템에 의해 지원된 하위 악절로 각각의 1/4에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 하위 악절 멜로디 배치 테이블의 주요 기능은 멜로디 또는 다른 음악 이벤트에서 위치(들)를 결정하기 위한 체 계를 제공하는 것이다. 하위 악절 멜로디 배치 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정된 다양 한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 52a 및 도 52b에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B24)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 멜로디 음표 리듬 생성 서브 시스템(B26) 내의 파라미터 테이블의 사양 도 77o은 본 발명의 자동화된 음악 작곡 및 생성 엔진의 멜로디 음표 리듬 생성 서브 시스템(B26)에 유지된 확 률 기반 파라미터 테이블을 나타낸다. 도 77o에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의 해 선택된 각각의 감정 타입 음악적 경험 디스크립터에 대해, 시스템에 의해 지원되는 각 제1 음표 길이 및 제2 화음 길이에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생 성 프로세스 중에 사용된다. 제1 음표 길이 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조에서 제1 음표(들)의 지속 시간을 결정하기 위한 체계를 제공하는 것이다. 제1 음표 길이 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결 정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 28dd1, 도 28dd2 및 도 28dd3 에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B26)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파 라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한 다. 제1 피치 생성 서브 시스템(B27) 내의 파라미터 테이블의 사양 도 77p은 본 발명의 자동화된 음악 작곡 및 생성 엔진의 제1 피치 생성 서브 시스템(B27)에 유지된 확률 기반 파라미터 테이블을 나타낸다. 도 77p에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선택 된 각각의 감정 타입 음악적 경험 디스크립터에 대해, 시스템에 의해 지원되는 (즉, 계이름으로 표시된) 각 음 표에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로 세스 중에 사용된다. 제1 멜로디 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 제1 멜로디(들) 및/또는 멜로디 재 료(들)의 피치(들)를 결정하기 위한 체계를 제공하는 것이다. 멜로디 길이 테이블은 서브 시스템(B1, B5, B7 및 B37)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 57에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B27)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터 (들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 하위 악절 피치 생성 서브 시스템(B29) 내의 파라미터 테이블의 사양 도 77q, 도 77r 및 도 77s은 본 발명의 자동화된 음악 작곡 및 생성 엔진의 하위 악절 피치 생성 서브 시스템 (B29)에 유지된 4개의 확률 기반 시스템 작동 파라미터(SOP) 테이블을 나타낸다. 도 77q, 도 77r 및 도 77s에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선택된 각각의 감정 타입 음악적 경험 디스크 립터에 대해, 시스템에 의해 지원되는 (즉, 계이름으로 표시된) 각 오리지널 음표 및 도약 자리바꿈에 대한 확 률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사 용된다. 멜로디 음표 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 멜로디(들) 및/또는 멜로디 재료 (들)의 피치(들)를 결정하기 위한 체계를 제공하는 것이다. 멜로디 음표 테이블은 서브 시스템(B1, B5, B7 및 B37)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 58a, 도 58b 및 도 58c에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B29)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정 (들)을 행한다. 화음 변조기 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 멜로디(들) 및/또는 멜로디 재료 (들)의 피치(들)에 영향을 미치는 체계를 제공하는 것이다. 멜로디 음표 테이블은 서브 시스템(B1, B5, B7 및 B37)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 58a, 도 58b 및 도 58c에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B29)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정 (들)을 행한다.도약 자리바꿈 변조기 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 멜로디(들) 및/또는 멜로 디 재료(들)의 피치(들)에 영향을 미치는 체계를 제공하는 것이다. 도약 자리바꿈 변조기 테이블은 서브 시스템 (B1 및 B37)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 58a, 도 58b 및 도 58c에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B29)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대 해 결정(들)을 행한다. 도약 유발 변조기 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조의 멜로디(들) 및/또는 멜로디 재료(들)의 피치(들)에 영향을 미치는 체계를 제공하는 것이다. 도약 유발 변조기 테이블은 서브 시스템(B1 및 B37)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 58a, 도 58b 및 도 58c에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B29)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정 (들)을 행한다. 피치 옥타브 생성 서브 시스템(B30) 내의 파라미터 테이블의 사양 도 77t는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 피치 옥타브 생성 서브 시스템(B30)에 유지된 확률 기 반 파라미터 테이블을 나타낸다. 도 77t에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선 택된 각각의 감정 타입 음악적 경험 디스크립터에 대해, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용하기 위한 확률 척도 세트가 제공된다. 멜로디 음표 옥타브 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조에서 음표(들)의 특정 주파수 (들)를 결정하기 위한 체계를 제공하는 것이다. 멜로디 음표 옥타브 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 60a 및 도 60b 에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B30)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파 라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한 다. 악기 서브 시스템(B38) 내의 파라미터 테이블의 사양 도 77u 및 도 77v는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 악기 서브 시스템(B38)에 유지된 확률 기반 악기 테이블을 나타낸다. 도 77u 및 도 77v에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선택된 각각의 감정 타입 음악적 경험 디스크립터에 대해, 시스템에 의해 지원되는 각 악기에 대한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 악기 테이블의 주요 기능은 악기 선택기 서브 시스템(B39)이 음악 작곡 프로세스의 후속 단계에서 선택할 수 있 는 로컬 악기 라이브러리를 저장하기 위한 체계를 제공하는 것이다. 서브 시스템(B38) 내에서는 유도 추계학적 프로세스나, 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작 곡 및 생성 프로세스 중에 사용될지에 대해 어떠한 결정(들)도 행해지지 않는다. 이와 같은 결정은 악기 선택기 서브 시스템(B39) 내에서 이루어진다. 악기 선택기 서브 시스템(B39) 내의 파라미터 테이블의 사양 도 77w 및 도 77x는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 악기 선택기 서브 시스템(B39)에 유지된 확 률 기반 악기 섹션 테이블을 나타낸다. 도 77u 및 도 77v에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선택된 각각의 감정 타입 음악적 경험 디스크립터에 대해, 시스템에 의해 지원되는 각 악기에 대 한 확률 척도가 제공되며, 이 확률 기반 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중 에 사용된다. 악기 선택 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조에서 사용될 악기 또는 악기들을 결정하 기 위한 체계를 제공하는 것이다. 악기 선택 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 62a 및 도 62b에 도시된 유도 추계학적 프 로세스를 통해, 서브 시스템(B39)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 오케스트레이션 생성 서브 시스템(B31) 내의 파라미터 테이블의 사양 도 78a, 도 78b 및 도 78c은 도 63a 내지 도 63i에 도시된 본 발명의 자동화된 음악 작곡 및 생성 엔진의 오케 스트레이션 생성 서브 시스템(B31)에 유지된 확률 기반 파라미터 테이블을 나타낸다. 도 78a, 도 78b 및 도 78c 에 나타낸 바와 같이, 시스템에 의해 지원되고 시스템 사용자에 의해 선택된 각각의 감정 타입 음악적 경험 디 스크립터에 대해, 시스템에 의해 지원되는 각 악기에 대한 확률 척도가 제공되며, 이 파라미터 테이블은 본 발 명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 악기 오케스트레이션 우선 순위 결정 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조에서 오케스 트레이션의 순서 및/또는 프로세스를 결정하기 위한 체계를 제공하는 것이다. 악기 오케스트레이션 우선 순위 결정 테이블은 서브 시스템(B1 및 B37)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함 으로써 사용되며, 도 63a에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B31)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지 에 대해 결정(들)을 행한다. 악기 기능 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조에서 각 악기의 음악 기능을 결정하기 위한 체계를 제공하는 것이다. 악기 기능 테이블은 B1 및 B37에 의해 결정된 바와 같이 적절한 파라미터 세트를 로드함으로써 사용되며, 도 63a에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B31)은 파라미터 테이블 로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사 용될지에 대해 결정(들)을 행한다. 피아노 손 기능 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조에서 피아노의 각 손의 음악 기능 을 결정하기 위한 체계를 제공하는 것이다. 피아노 손 기능 테이블은 서브 시스템(B1 및 B37)에 의해 결정된 다 양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 63b 및 도 63c에 도시된 유도 추계학 적 프로세스를 통해, 서브 시스템(B31)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 피아노 보이싱 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조에서 피아노의 각 손의 각 음표의 보이싱을 결정하기 위한 체계를 제공하는 것이다. 피아노 보이싱 테이블은 서브 시스템(B1 및 B37)에 의해 결정 된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 63c에 도시된 유도 추계학적 프 로세스를 통해, 서브 시스템(B31)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 피아노 리듬 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조에서 피아노의 각 이벤트에서 배열을 결정하기 위한 체계를 제공하는 것이다. 피아노 리듬 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정 된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 63c에 도시된 유도 추계학적 프 로세스를 통해, 서브 시스템(B31)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 제2 음표 오른손 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조에서 피아노의 오른손의 각각의 비-제1 이벤트에서 배열을 결정하기 위한 체계를 제공하는 것이다. 제2 음표 오른손 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 63c 및 도 63d에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B31)은 파라미터 테이블로부터 어떤 값 (들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 제2 음표 왼손 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조에서 피아노의 왼손의 각각의 비-제 1 이벤트에서 배열을 결정하기 위한 체계를 제공하는 것이다. 제2 음표 왼손 테이블은 서브 시스템(B1, B37, B40 및 B41)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 63d에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B31)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라 미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 제3 음표 오른손 길이 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조(들) 내에서 피아노의 오른 손의 제3 음표의 리듬 길이를 결정하기 위한 체계를 제공하는 것이다. 제3 음표 오른손 길이 테이블은 서브 시 스템(B1 및 B37)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 63d 및 도 63e에 도시된 유도 추계학적 프로세스를 통해, 서브 시스템(B31)은 파라미터 테이블로부터 어떤 값 (들) 및/또는 파라미터(들)가 선택되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해결정(들)을 행한다. 피아노 강약 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조에서 피아노의 음악적 표현을 결정하 기 위한 체계를 제공하는 것이다. 피아노 보이싱 테이블은 서브 시스템(B1 및 B37)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 63f 및 도 63g에 도시된 유도 추계학적 프로세 스를 통해, 서브 시스템(B31)은 파라미터 테이블로부터 어떤 값(들) 및/또는 파라미터(들)가 선택되어 본 발명 의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될지에 대해 결정(들)을 행한다. 컨트롤러 코드 생성 서브 시스템(B32) 내의 파라미터 테이블의 사양 도 79는 도 64에 도시된 바와 같은 본 발명의 자동화된 음악 작곡 및 생성 엔진의 컨트롤러 코드 생성 서브 시 스템(B32)에 유지된 확률 기반 파라미터 테이블을 나타낸다. 도 79에 나타낸 바와 같이, 시스템에 의해 지원되 고 시스템 사용자에 의해 선택된 각각의 감정 타입 음악적 경험 디스크립터에 대해, 시스템에 의해 지원되는 각 악기에 대한 확률 척도가 제공되며, 이 파라미터 테이블은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중 에 사용된다. 악기 컨트롤러 코드 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조에서 악기의 음악적 표현을 결 정하기 위한 체계를 제공하는 것이다. 악기 컨트롤러 코드 테이블은 서브 시스템(B1 및 B37)에 의해 결정된 다 양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 유도 추계학적 프로세스를 통해, 값(들) 및/또는 파라미터(들)의 사용에 대해 결정(들)을 행한다. 악기 그룹 컨트롤러 코드 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조에서 악기 그룹의 음악적 표현을 결정하기 위한 체계를 제공하는 것이다. 악기 그룹 컨트롤러 코드 테이블은 서브 시스템(B1 및 B37)에 의해 결정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 유도 추계학적 프로세스 를 통해, 값(들) 및/또는 파라미터(들)의 사용에 대해 결정(들)을 행한다. 조각 너비 컨트롤러 코드 테이블의 주요 기능은 음악 조각, 섹션, 악절 또는 다른 구조에서 전체 음악적 표현을 결정하기 위한 체계를 제공하는 것이다. 조각 너비 컨트롤러 코드 테이블은 서브 시스템(B1 및 B37)에 의해 결 정된 다양한 서브 시스템으로 적절한 파라미터 세트를 로드함으로써 사용되며, 도 64에 도시된 유도 추계학적 프로세스를 통해, 값(들) 및/또는 파라미터(들)의 사용에 대해 결정(들)을 행한다. 본 발명의 자동화된 음악 작곡 및 생성 시스템 내의 서브 시스템에 확률 기반 시스템 작동 파라미터(SOP)를 분 배하는 방법 파라미터 변환 엔진 서브 시스템(B51)에 의해 생성된 확률 기반 음악 이론 파라미터가 본 발명의 자동화된 음악 작곡 및 생성 시스템의 개별 서브 시스템으로 전송될 수 있음으로써, 지원된 자동화된 음악 작곡 프로세스 중에 그 내부에서 액세스될 수 있도록 하는 다양한 방법이 존재한다. 다양한 방법에 대해 상세하게 후술하기로 한다. 본 발명의 예시적 실시형태 전체에 걸쳐 설명된 제1 바람직한 방법에 따르면, 다음의 작동이 조직화된 방식으로 발생한다. (i) 시스템 사용자가 시스템 입력 서브 시스템(B0)에 감정 및 스타일 타입 음악적 경험 디스크립터(예컨대, 행 복 및 팝)와 타이밍/공간 파라미터(T = 32초) 세트를 제공하며, 그 다음, 이들은 파라미터 변환 엔진 서브 시스 템(B51)으로 전송되고; (ii) 파라미터 변환 엔진 서브 시스템(B51)이 행복 감정 디스크립터와 팝 스타일 디스크립터에 대응하는 확률 기반 파라미터 테이블 세트만을 자동으로 생성하고, 이 음악 이론 파라미터를 그들의 각 감정/스타일 특정 파라 미터 테이블(또는 리스트, 어레이 등과 같은 다른 적당한 데이터 구조)에서 조직화하며; 그리고 (iii) 서브 시스템(B1, B37 및 B51) 중 어느 하나 이상이 서브 시스템(B51)으로부터 확률 기반 감정/스타일 특 정 파라미터 테이블을 그들의 목표 서브 시스템으로 전송하기 위해 사용되고, 목표 서브 시스템에서는 이 감정/ 스타일 특정 파라미터 테이블이 도 80a 및 도 80b에 설명된 타이밍 제어 프로세스에 따라 본 발명의 자동화된 음악 작곡 프로세스의 실행 사이클의 특정 시간/단계에서의 액세스 및 사용을 위해 서브 시스템으로 로드된다. 이와 같은 제1 방법을 이용하면, 감정 및 스타일 타입 음악적 경험 파라미터가 확률 기반 파라미터 테이블을 채 택한 다수의 서브 시스템 각각으로 전송될 필요가 없다. 그 이유는, 시스템 사용자가 원하고 시스템 사용자에 의해 선택된 감정 타입 및 스타일 타입 음악적 경험 디스크립터에 의해 특징지어지며 시스템 인터페이스로 제공 되는 음악적 경험을 구현하고자 하는 음악 이론 파라미터 값을 포함한 감정/스타일 특정 파라미터 테이블이 서브 시스템에 로드되기 때문이다. 따라서, 이 방법에서는, 이 서브 시스템(B51)으로부터 생성된 음악 이론 파라 미터 테이블이 시스템 사용자에 의해 선택되는 감정 및 스타일 타입 음악적 경험 디스크립터를 본질적으로 포함 하기 때문에, 시스템 사용자의 음악적 경험 디스크립터가 파라미터 변환 엔진 서브 시스템(B51)을 지나 전송될 필요가 없다. 도면 전체에 걸쳐 예시된 바와 같이, 타이밍 파라미터 포착 서브 시스템(B40)을 통해 시스템 사용 자로부터 특정 서브 시스템으로 타이밍/공간 파라미터를 전송할 필요는 있을 것이다. 제2 바람직한 방법에 따르면, 다음의 작동이 조직화된 방식으로 발생한다. (iii) 시스템 구성 및 설립 중에, GUI 기반 입출력 서브 시스템(B0)에서 시스템 사용자에 의한 선택을 위해 이 용가능한 모든 감정 디스크립터와 스타일 디스크립터에 대응하는 모든 가능한(즉, 허용가능한) 확률 기반 파라 미터 테이블 세트를 자동으로 생성한 다음, 이 음악 이론 파라미터를 그들의 각 감정/스타일 파라미터 테이블 (또는 리스트, 어레이 등과 같은 다른 적당한 데이터 구조)에서 조직화하기 위해, 파라미터 변환 엔진 서브 시 스템(B51)이 사용되며; (ii) 시스템 구성 및 설립 중에, 생성된 모든 확률 기반 파라미터 테이블 세트를 시스템 데이터 버스를 가로질 러 그들의 각 목표 서브 시스템으로 전송하기 위해 서브 시스템(B1, B37 및 B51)이 사용되고, 목표 서브 시스템 에서는 파라미터 테이블이 메모리에 로드되며; (iii) 시스템 작동 및 사용 중에, 시스템 사용자가 시스템 입력 서브 시스템(B0)에 감정 및 스타일 타입 음악적 경험 디스크립터(예컨대, 행복 및 팝)와 타이밍/공간 파라미터(T = 32초)의 특정 세트를 제공하며, 그 다음, 이 들은 파라미터 포착 서브 시스템(B1, B37 및 B40)에 의해 수신되고; (iv) 시스템 작동 및 사용 중에, 파라미터 포착 서브 시스템(B1, B37 및 B40)이 (시스템 사용자에 의해 선택된) 이 감정 디스크립터와 스타일 디스크립터를 시스템 내의 다양한 서브 시스템으로 전송하며; 그리고 (v) 시스템 작동 및 사용 중에, 서브 시스템으로 전송된 감정 디스크립터와 스타일 디스크립터는 도 80a 및 도 80b에 설명된 타이밍 제어 프로세스에 따라 본 발명의 자동화된 음악 작곡 프로세스의 실행 사이클의 특정 시간 /단계에서의 액세스 및 사용을 위해 선택된 감정 및 스타일 디스크립터(예컨대, 행복 및 팝)에만 관련되는 생성 된 확률 기반 파라미터 테이블의 특정 부분에 액세스하기 위해 각 서브 시스템에 의해 사용된다. 이와 같은 제2 방법을 이용하면, 감정 및 스타일 타입 음악적 경험 파라미터가 확률 기반 파라미터 테이블을 채 택한 다수의 서브 시스템 각각으로 전송될 필요가 있다. 그 이유는, 서브 시스템 내에서의 자동화된 음악 작곡 프로세스 중에 액세스 및 사용되어야 하는 음악 이론 파라미터 값을 포함한 감정/스타일 특정 파라미터 테이블 에 대한 정보를 서브 시스템이 가질 필요가 있기 때문이다. 따라서, 이 제2 방법에서는, 일반화된 음악 이론 파 라미터 테이블이 시스템 사용자에 의해 선택되는 감정 및 스타일 타입 음악적 경험 디스크립터를 포함하지 않기 때문에, 시스템 사용자의 감정 및 스타일 음악적 경험 디스크립터가 파라미터 포착 서브 시스템(B1 및 B37)을 통해 시스템의 다양한 서브 시스템으로 전송되어야만 한다. 또한, 이 제2 방법을 사용할 경우, 도면 전체에 걸 쳐 예시된 바와 같이, 타이밍 파라미터 포착 서브 시스템(B40)을 통해 시스템 사용자로부터 특정 서브 시스템으 로 타이밍/공간 파라미터를 전송할 필요가 있을 것이다. 전술한 방법이 바람직하기는 하지만, 본 발명의 정신에 따라 음악을 자동으로 작곡 및 생성하기 위한 자동화된 시스템 및 방법을 실시하는 데 다른 방법이 사용될 수 있을 것으로 이해된다. 본 발명의 자동화된 음악 작곡 시스템에 채택되는 B-레벨 서브 시스템의 사양 및 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 각 서브 시스템에 의해 지원되며 그 내부에서 실행되는 특정 정보 프로세싱 동작 이제, 도 27 내지 도 76에 개시된 개략도를 참조하여, 본 발명의 시스템(S) 및 그 엔진(E1)에 채택되는 각각의 B-레벨 서브 시스템의 보다 상세한 기술적 사양과, 그 자동화된 음악 작곡 및 생성 프로세스의 각각의 전체 사 이클 중에 각 서브 시스템에 의해 지원되는 특정 정보 프로세싱 동작 및 기능을 설명하기로 한다. 특히, 다음과 같은 시스템 입력, 즉, (i) 감정 타입 음악 디스크립터 = 행복; (ii) 스타일 타입 디스크립터 = 팝; 및 (iii) 타이밍 파라미터 t = 32초를 제공하는 시스템 사용자에 응답하여, 자동화된 가상 악기 음악 합성 방법을 사용하여, 음표 단위 및 화음 단위로 완성된 음악 조각을 시스템이 생성하는 경우의 일례를 고려하여, 각 서브 시스템과 자동화된 음악 작곡 프로세스 중에 실행되는 동작에 대해 설명하기로 한다. 도면에 나타낸 바와 같이, 예시적인 자동화된 음악 작곡 및 생성 프로세스는 도 32에 나타낸 길이 생성 서브 시 스템(B2)에서 시작하여, 예시적인 음악 조각의 작곡이 완성되는 도 63i를 통과한 다음, 컨트롤러 코드 생성 서 브 시스템이 음악 작곡을 위한 컨트롤러 코드를 생성하는 도 64에서 재개되고, 도 65에 나타낸 서브 시스템(B33) 내지 도 68의 서브 시스템(B36)은 시스템 사용자에게 전달하기 위해 작곡된 디지털 음악 조각의 생성을 완료한다. 이와 같은 전체 프로세스는 시계 장치 방식으로 도 80a 및 도 80b에 도시된 바와 같이 타이밍 제어 데이터 신호가 생성되어 분배되는 서브 시스템 제어 서브 시스템(B60)(즉, 서브 시스템 제어 서브 시스템(A9)) 하에서 제어된다. 또한, 서브 시스템(B1, B37, B40 및 B41)은 자동화된 음악 작곡 프로세스 중에 음악 이벤트의 생성에 기여하지 는 않지만, 이 서브 시스템들은 시스템 사용자로부터 포착된 다음 사용자에게 투명한 방식으로 파라미터 변환 엔진 서브 시스템(B51)에 제공되는 감정, 스타일 및 타이밍/공간 파라미터의 수집, 관리 및 분배를 포함한 필수 적인 기능을 수행하며, 파라미터 변환 엔진 서브 시스템에서는, 제공된 이들 음악적 경험 및 타이밍/공간 파라 미터가 도 25a에 도시된 서브 시스템 제어 서브 시스템(B60)의 제어 하에 자신의 각 서브 시스템에 분배 및 로 드되는 테이블 또는 다른 적당한 데이터/정보 구조에 조직화된 대응하는 음악 이론 시스템 작동 파라미터 세트 로 자동으로 변환되어 매핑된다. 서브 시스템 제어 서브 시스템(B60)의 기능은 서브 시스템들의 입출력 데이터 포트들 사이의 모든 데이터 흐름 경로가 적절한 시간 순서로 활성화되도록 입출력 서브 시스템(B0)에 대한 시스 템 사용자 입력에 응답하여 각 서브 시스템이 다른 서브 시스템과 정밀하게 협력하여 특정 순간에 작동할 수 있 도록 하는 타이밍 제어 데이터 신호를 도 80a 및 도 80b에 도시된 바와 같이 생성하는 것이며, 따라서, 각각의 서브 시스템은 본 발명의 자동화된 음악 작곡 및 생성 프로세스에 기여하고 그 작동을 수행하는 데 필요한 필수 데이터를 갖는다. 제어 데이터 흐름 라인이 도 26a 내지 도 26p에 도시된 B-레벨 서브 시스템 아키텍처에 보이 지는 않지만, 그와 같은 제어 데이터 흐름 경로가 도 25a에 나타낸 대응하는 모델에 도시되어 있으며, 입력 서 브 시스템(A0)의 출력 포트는 서브 시스템 제어 서브 시스템(A9)의 입력 포트에 연결되고, 서브 시스템(A9)의 출력 데이터 포트는 서브 시스템(A1 내지 A8)의 입력 데이터 포트에 제공된다. 대응하는 데이터 흐름 경로가 B- 레벨 개략도에 존재하지만, 설명의 명료함을 위해 표시되지 않았다. 사용자 GUI 기반 입출력 서브 시스템(B0)의 사양 도 27는 본 발명의 자동화된 음악 작곡 및 생성 엔진 및 시스템(E1)에서 사용되는 사용자 GUI 기반 입출력 서브 시스템(BO)의 개략도를 나타낸다. 작동 중에, 시스템 사용자는 자신이 원하는 음악적 경험 디스크립터(들)(예컨 대, 감정 디스크립터 및 스타일 디스크립터(들)) 및/또는 타이밍 정보를 통신하기 위해 시스템 GUI 또는 다른 지원되는 인터페이스 메커니즘과 상호 작용한다. 예시적인 실시형태 및 예시적인 도면에서, (i) 감정 타입 음악 적 경험 디스크립터 = 행복이 (감정) 디스크립터 파라미터 포착 서브 시스템(B1)으로의 분배를 위해 엔진의 입 출력 시스템(B0)에 제공되고, (ii) 스타일 타입 음악적 경험 디스크립터 = 팝이 스타일 파라미터 포착 서브 시 스템(B37)으로의 분배를 위해 엔진의 입출력 시스템(B0)에 제공되며, 그리고 (iii) 타이밍 파라미터 = 32초가 타이밍 파라미터 포착 서브 시스템(B40)으로의 분배를 위해 엔진의 입출력 시스템(B0)에 제공된다. 그리고, 이 서브 시스템들은 제공된 음악적 경험 파라미터 및 타이밍/공간 데이터 세트를 도 28c, 도 28d 및 도 28e에 나타 낸 파라미터 변환 엔진 서브 시스템(B51)의 입력 데이터 포트로 전송하며, 파라미터 변환 엔진 서브 시스템 (B51)은 실행을 위해 준비 중인 자동화된 음악 작곡 및 생성 프로세스에서 사용하기 위하여 시스템 전체의 다양 한 서브 시스템으로의 후속 분배 및 로드를 위해 적절한 확률 기반 파라미터 프로그래밍 테이블 세트를 생성한 다. 디스크립터 파라미터 포착 서브 시스템(B1)의 사양 도 28a 및 도 28b는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 (감정 타입) 디스크립터 파라미 터 포착 서브 시스템(B1)의 개략도를 나타낸다. 디스크립터 파라미터 포착 서브 시스템(B1)은 자신이 선호하는 감정, 정서, 및/또는 음악에 대한 다른 디스크립터를 사용자가 지정할 수 있도록 하는 입력 메커니즘의 역할을 한다. 이는 서브 시스템의 경계 내에 설정된 창조적 제어를 사용자가 갖는 쌍방향 서브 시스템이다. 예시적인 예에서, 시스템 사용자는 예시적인 '감정 타입\" 음악적 경험 디스크립터-행복을 디스크립터 파라미터 포착 서브 시스템(B1)에 제공한다. 이 파라미터는 파라미터 변환 엔진(B51)에 의해 사용되어, 그 내부의 다양한 서브 시스템으로의 후속 분배와 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 후속 서브 시스템의 설립 및 사용을 위해 확률 기반 파라미터 프로그래밍 테이블을 생성한다. 파라미터가 입력되면, 파라미터 변환 엔진 서브 시스템(B51)은 시스템 작동 파라미터 테이블을 생성하고, 시스 템은 관련 데이터 테이블, 데이터 세트 및 기타 정보를 시스템 전체의 각각의 다른 서브 시스템으로 로드한 다. 감정 타입 디스크립터 파라미터는 시스템 사용자에 의해 수동 또는 반자동으로, 또는 서브 시스템 자체에 의해 자동으로 서브 시스템(B51)에 입력될 수 있다. 입력 파라미터를 프로세싱할 때, 서브 시스템은 도 81 내지 도 81j에 설명된 바와 같이 감정 디스크립터 파라미터를 디스크립터들의 임의의 조합으로 증류(즉, 구문분석 및 변환)할 수 있다. 또한, 짧은 이야기 형태로 쓰여진 텍스트 기반 감정 디스크립터가 제공되는 경우, 디 스크립터 파라미터 포착 서브 시스템(B1)은 제공된 텍스트 이야기 속의 단어를 구문 분석 및 분석하여 도 81 내 지 도 81j에 도시된 바와 같은 감정 디스크립터 라이브러리에 엔트리를 가진 감정 타입 디스크립터 단어로 번역 함으로써, 번역 프로세스를 통해, 사실상 모든 단어 세트가 도 81 내지 도 81j의 감정 디스크립터 라이브러리에 등록된 하나 이상의 감정 타입 음악 디스크립터를 표현하기 위해 사용될 수 있고, 시스템 사용자가 본 발명의 시스템으로 자동으로 작곡하고자 하는 음악의 종류를 설명하기 위해 사용될 수 있다. 바람직하게, 증류된 디스크립터의 수는 1과 10 사이지만, 그 수는 실시형태마다, 응용예마다 달라질 수 있으며, 달라질 것이다. 다수의 증류된 디스크립터가 존재하는 경우, 그리고 필요한 경우, 파라미터 변환 엔진 서브 시 스템(B51)은 입력된 디스크립터 파라미터를 정확하게 나타내기 위해 기존의 데이터 테이블, 데이터 세트 및 기 타 정보를 조합함으로써 새로운 파라미터 데이터 테이블, 데이터 세트 및 기타 정보를 생성할 수 있다. 예컨대, 디스크립터 파라미터 \"행복\"은 메이저 키와 업비트 템포에 관련된 파라미터 데이터 세트를 로드할 수 있다. 이 와 같은 변환 및 매핑 프로세스에 대해서는 매우 상세하게 후술된 파라미터 변환 엔진 서브 시스템(B51)을 참조 하여 매우 상세하게 설명하기로 한다. 위에서 특정된 음악 이론 및 정보 프로세싱 기능을 수행할 뿐만 아니라, 필요하거나 도움이 될 때, 시스템(B1) 은 확률 기반 음악 이론 시스템 작동 파라미터(SOP) 테이블(또는 그와 유사한 데이터 구조)을 본 발명의 자동화 된 음악 작곡 및 생성 시스템 전체에 배치된 다양한 서브 시스템으로 전송할 때 파라미터 변환 엔진 시스템 (B51)을 보조할 수도 있다. 스타일 파라미터 포착 서브 시스템(B37)의 사양 도 29a 및 도 29b는 본 발명의 자동화된 음악 작곡 및 생성 엔진 및 시스템에 사용되는 스타일 파라미터 포착 서브 시스템(B37)의 개략도를 나타낸다. 스타일 파라미터 포착 서브 시스템(B37)은 사용자가 자신이 선호하는 음악 조각의 스타일 파라미터(들)를 지정할 수 있도록 하는 입력 메커니즘 역할을 한다. 이는 서브 시스템의 경 계 내에 설정된 창조적 제어를 사용자가 갖는 쌍방향 서브 시스템이다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 스타일, 또는 음악적 요소(멜 로디, 리듬, 하모니, 강약, 형태 등)를 표현하는 특징적인 방식은 모든 음악 조각의 기본적인 구성 요소이다. 도 29a 및 도 29b의 예시적인 예에서, 서브 시스템에 채택된 확률 기반 파라미터 프로그래밍 테이블은 예시적인 \"스타일 타입\" 음악적 경험 디스크립터 = 팝에 대해 설립되어, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 스타일 디스크립터 파라미터는 시스템 사용자에 의해 수동 또는 반자동으로, 또는 서브 시스템 자체에 의해 자 동으로 입력될 수 있다. 파라미터가 입력되면, 파라미터 변환 엔진 서브 시스템(B51)은 B37로부터 사용자의 음 악적 스타일 입력을 수신하고, 통상적으로, 존재하는 테이블 세트를 분석하고 현재 제공된 스타일 디스크립터를 참조함으로써, 시스템의 나머지 부분을 가로질러 관련 확률 테이블을 생성한다. 다수의 디스크립터가 요청되는 경우, 파라미터 변환 엔진 서브 시스템(B51)이 제공되는 스타일 디스크립터의 조합을 반영하는 시스템 작동 파 라미터(SOP) 테이블을 생성한 다음, 서브 시스템(B37)은 이 파라미터 테이블들을 이들의 각 서브 시스템에 로드 한다. 입력 파라미터를 프로세싱할 때, 파라미터 변환 엔진 서브 시스템(B51)은 도 84a 내지 도 84e에 설명된 바와 같 이 입력 파라미터를 스타일들의 임의의 조합으로 증류할 수 있다. 증류된 스타일의 수는 1과 10 사이일 수 있다. 다수의 증류된 스타일이 존재하는 경우, 그리고 필요한 경우, 파라미터 변환 서브 시스템(B51)은 입력된 디스크립터 파라미터를 정확하게 나타내는 시스템 작동 파라미터를 생성하기 위해 기존의 데이터 테이블, 데이 터 세트 및 기타 정보를 조합함으로써 새로운 데이터 테이블, 데이터 세트 및 기타 정보를 생성할 수 있다. 위에서 특정된 음악 이론 및 정보 프로세싱 기능을 수행할 뿐만 아니라, 필요하거나 도움이 될 때, 서브 시스템 (B37)은 확률 기반 음악 이론 시스템 작동 파라미터(SOP) 테이블(또는 그와 유사한 데이터 구조)을 본 발명의 자동화된 음악 작곡 및 생성 시스템 전체에 배치된 다양한 서브 시스템으로 전송할 때 파라미터 변환 엔진 시스 템(B51)을 보조할 수도 있다. 타이밍 파라미터 포착 서브 시스템(B40)의 사양 도 30는 본 발명의 자동화된 음악 작곡 및 생성 엔진(E1)에 사용되는 타이밍 파라미터 포착 서브 시스템(B40)을 나타낸다. 타이밍 파라미터 포착 서브 시스템(B40)은 타이밍 생성 서브 시스템(B41)이 로드되어 사용되는지의 여부 또는 생성되고 있는 음악 조각이 시스템 자체 내의 프로세스에 의해 결정된 특정의 미리 설정된 길이가 될것인지에 대해 근처에서 결정한다. 타이밍 파라미터 포착 서브 시스템(B40)은 음악 조각을 위해 타이밍 파라미 터가 생성될 방식을 결정한다. 사용자가 타이밍 파라미터를 수동으로 입력하는 것을 선택한 경우, 특정 사용자 인터페이스가 사용자에게 이용가능하게 될 것이다. 사용자가 타이밍 파라미터를 수동으로 입력하는 것을 선택하 지 않는 경우, 특정 사용자 인터페이스가 사용자에게 이용가능하지 않게 될 수 있다. 도 31a 및 도 31b에 나타 낸 바와 같이, 서브 시스템(B41)은 음악이 시작할 때, 음악이 정지할 때, 음악 볼륨이 증감할 때, 그리고 음악 작곡을 위해 제시된 타임라인을 따라 음악 악센트가 발생하려고 하는 위치에서, 작곡되고 있는 음악 조각의 길 이에 대한 타이밍 특정을 허용한다. 작동 중에, 타이밍 파라미터 포착 서브 시스템(B40)은 시스템 내의 다양한 서브 시스템으로의 분배와 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중의 후속 서브 시스템의 설립 및 사용을 위해 타이밍 생성 서브 시스템(B41)에 타이밍 파라미터를 제공한다. 위에서 특정된 음악 이론 및 정보 프로세싱 기능을 수행할 뿐만 아니라, 필요하거나 도움이 될 때, 서브 시스템 (B40)은 확률 기반 음악 이론 시스템 작동 파라미터(SOP) 테이블(또는 그와 유사한 데이터 구조)을 본 발명의 자동화된 음악 작곡 및 생성 시스템 전체에 배치된 다양한 서브 시스템으로 전송할 때 파라미터 변환 엔진 시스 템(B51)을 보조할 수도 있다. 본 발명의 파라미터 변환 엔진(PTE)(B51)의 사양 도 28c, 도 28d 및 도 28e에 도시된 바와 같이, 파라미터 변환 엔진 서브 시스템(B51)은 서브 시스템(B0)을 통 해 시스템 사용자에 의해 각각 제공된 감정 타입, 스타일 타입 및 타이밍 타입 파라미터를 취급하기 위해 서브 시스템(B1, B37 및 B40)과 집적되어 표시되어 있다. 파라미터 변환 엔진 서브 시스템(B51)은 서브 시스템(B1, B37 및 B40)으로부터 시스템 사용자 입력(들) 디스크립터 및 파라미터를 수용하여, 이 파라미터(예컨대, 입력 (들))를 본원에 개시된 가상 악기 음악 합성 기술을 이용하여 음악을 자동으로 작곡 및 생성하기 위해 시스템이 그 작동 중에 사용하게 될 확률 기반 시스템 작동 파라미터 테이블로 변환함으로써, 본질적인 기능을 수행한다. 특이 음악 조각을 제작할 때 사용하기 위하여, 임의의 음악적 경험(예컨대, 감정 및 스타일) 디스크립터 및 타 이밍 및/또는 공간 파라미터 세트를 프로세스하기 위해 파라미터 변환 엔진 서브 시스템(B51)에 의해 사용되는 프로그램된 방법에 대해서는 도 28c 내지 도 28e를 참조하여 매우 상세하게 후술하기로 하며, 입력 서브 시스템 (B0)의 시스템 사용자 인터페이스에서 이용가능한 메뉴로부터 선택된 음악적 경험 디스크립터(예컨대, 감정 및 스타일 디스크립터)와 타이밍 및 공간 파라미터는 음악 작곡 및 생성 프로세스 중에 각 서브 시스템 내에 로드 되어 사용되는 대응하는 확률 기반 시스템 작동 파라미터(SOP) 테이블 세트로 자동으로 변환된다. 매우 상세하게 후술하는 바와 같이, 서브 시스템(B51) 내에서 지원되는 이 파라미터 변환 프로세스는 시스템의 서브 시스템 내에 유지되는 확률 기반 시스템 작동 파라미터(SOP) 테이블 내에 표현되고 내장된 음악 이론 개념 을 채택하며, 도 80a 및 도 80b에 개시된 타이밍 제어도에 도시된 타이밍 신호에 의해 제어되는 시계열 프로세 스의 실행 중에 그 작동을 제어한다. 파라미터 변환 엔진 서브 시스템(B51)를 설계, 구성 및 작동할 때 사용하 기 위한 다양한 파라미터 변환 원리 및 실행에 대해서는 상세하게 후술하기로 한다. 위에서 특정된 음악 이론 및 정보 프로세싱 기능을 수행할 뿐만 아니라, 파라미터 변환 엔진 서브 시스템(B51) 은 확률 기반 음악 이론 시스템 작동 파라미터(SOP) 테이블(또는 그와 유사한 데이터 구조)을 본 발명의 자동화 된 음악 작곡 및 생성 시스템 전체에 배치된 다양한 서브 시스템으로 전적으로 전송할 수 있다. 파라미터 테이블 취급 및 프로세싱 서브 시스템(B70)의 사양 일반적으로, 본 발명의 시스템의 서브 시스템 내에서 사용하기 위한 대응하는 확률 기반 음악 이론 파라미터 세 트를 생성하기 위해, 시스템 사용자에 의해 선택된 다수의 감정 타입 및 스타일 타입 음악적 경험 디스크립터를 시스템이 관리할 필요가 있다. 파라미터 테이블 취급 및 프로세싱 서브 시스템(B70)의 주요 기능은 상세하게 후 술하는 바와 같이 전세계적 또는 국지적 수준에서 이와 같은 필요에 대처하는 것이다. 도 28k는 본 발명의 자동화된 음악 작곡 및 생성 엔진과 관련되어 사용되는 파라미터 테이블 취급 및 프로세싱 서브 시스템(B70)을 나타낸다. 파라미터 테이블 취급 및 프로세싱 서브 시스템(B70)의 주요 기능은 본 발명의 시스템의 서브 시스템 내에서의 프로세스 및 사용이 더 편리하고 용이한 형태로 시스템 파라미터 테이블을 생성 하기 위해 임의의 시스템 파라미터 테이블 변환(들)이 필요한지의 여부를 결정하는 것이다. 파라미터 테이블 취 급 및 프로세싱 서브 시스템(B70)은 (i) 파라미터 변환 엔진 서브 시스템(B51)의 데이터 출력 포트로부터 다수 (즉, 하나 이상)의 감정/스타일 특정 음악 이론 시스템 작동 파라미터(SOP) 테이블을 수신하고, (ii) 이 파라미 터 테이블을 후술한 파라미터 테이블 프로세싱 방법(M1, M2 또는 M3) 중 하나를 이용하여 프로세싱하며, (iii) 본 발명의 시스템의 서브 시스템 내에서의 프로세스 및 사용이 더 편리하고 용이한 형태의 시스템 작동 파라미터 테이블을 생성함으로써, 그 기능을 수행한다. 일반적으로, 본 발명의 이 양태를 실시하는 2개의 서로 다른 방법이 존재한다: (i) 도 26a 내지 도 26j에 나타 낸 바와 같이, 파라미터 변환 엔진 서브 시스템(B51)으로 구성된 파라미터 테이블 취급 및 프로세싱 서브 시스 템(B70)으로 나타낸 바와 같은, 글로벌 방식으로 파라미터 테이블 취급 및 변환 프로세싱 작동을 수행하는 방법; 또는 (ii) 도 28a 내지 도 79에 나타낸 바와 같이, 확률 기반 시스템 작동 파라미터 테이블을 지원하는 각 서브 시스템의 입력 데이터 포트로 구성된 파라미터 테이블 취급 및 프로세싱 서브 시스템(B70)으로 나타낸 바와 같은, 각 서브 시스템 내에서 로컬 방식으로 파라미터 테이블 취급 및 변환 프로세싱 작동을 수행하는 방 법. 두 가지 방법이 모두 예시를 위해 본원에 개시되어 있다. 그러나, 파라미터 테이블 취급 및 프로세싱 서브 시스템(B70)에 대해서는 도 26a 내지 도 26j에 나타낸 글로벌 구현예를 참조하여 후술하기로 한다. 도 26a 내지 도 26j에 나타낸 바와 같이, 파라미터 테이블 취급 및 프로세싱 서브 시스템(B70)의 데이터 입력 포트는 파라미터 테이블 취급 및 프로세싱 서브 시스템(B70)의 출력 데이터 포트에 연결되는 반면, 서브 시스템 (B70)의 데이터 출력 포트는 (i) 파라미터 테이블 아카이브 데이터베이스 서브 시스템(B80)의 입력 데이터 포트 와, (ii) 도 28a 내지 도 79와 본원에 개시된 다른 도면에 도시된 파라미터 테이블 채택 서브 시스템(B2, B3, B4, B5, B7, B9, B15, B11, B17, B19, B20, B25, B26, B24, B27, B29, B30, B38, B39, B31, B32 및 B41)의 입 력 데이터 포트에도 연결된다. 도 28k에 나타낸 바와 같이, 파라미터 테이블 취급 및 프로세싱 서브 시스템(B70)은 하나 이상의 감정/스타일 인덱스 시스템 작동 파라미터 테이블을 수신하여, 경우에 따라 시스템 입력(즉, 파라미터 테이블) 변환이 필요 하거나 필요하지 않은지의 여부를 결정한다. 단일의 감정/스타일 인덱스 시스템 파라미터 테이블만이 수신되는 경우에는, 변환이 필요할 것 같지 않으므로, 시스템 파라미터 테이블은 통상적으로 통과 방식으로 서브 시스템 (B70)의 데이터 출력 포트로 전송된다. 2개 이상의 감정/스타일 인덱스 시스템 파라미터 테이블이 수신되는 경 우에는, 이 파라미터 테이블들이 변환 프로세싱을 필요로 하거나 그 혜택을 누릴 가능성이 있으므로, 서브 시스 템(B70)은 그 데이터 입력 포트에서 수신된 시스템 파라미터 테이블에 작동하는 3개의 서로 다른 방법(M1, M2 및 M3)을 지원하여, 이 파라미터 테이블을 서브 시스템 내에서의 최적 사용에 적합한 형태의 파라미터 테이블로 변환한다. 다수의 감정/스타일 음악적 경험 디스크립터가 입력 서브 시스템(B0)에 제공되고 다수의 감정/스타일 인덱스 시 스템 파라미터 테이블이 파라미터 변환 엔진 서브 시스템(B51)에 의해 자동으로 생성되는 상황에서 사용하기 위 해 수반되는 규칙과 고려해야 하는 3개의 사례 시나리오가 존재한다. 방법(M1)이 채택되고, 서브 시스템(B70)이 다수의 감정/스타일 인덱스 시스템 파라미터 테이블 중에서 결정을 행하며, 감정/스타일 인덱스 시스템 파라미터 테이블 중에서 오직 하나만을 사용하기로 결정하는, 제1 사례 시 나리오를 고려하기로 한다. 방법 1 시나리오에서, 서브 시스템(B70)은, 특수한 경우에 또는 전체적인 경향으로서, 서브 시스템(B0)에 입력 된 다수의 음악적 경험 디스크립터에 대한 응답으로 생성된 다수의 파라미터 테이블 중에서, 이 디스크립터 인 덱스 파라미터 테이블 중 단일의 테이블이 가장 잘 사용될 수 있을 것으로 인식한다. 일례로서, 행복, 활기찬 및 긍정적이 모두 감정 타입 음악적 경험 디스크립터로서 입력되는 경우, 활기찬은 행 복과 긍정적을 포함하기 때문에, 활기찬에 대해 생성된 시스템 파라미터 테이블(들)이 3개의 모든 입력에 대응 하기 위해 필요한 음악 체계를 제공할 수도 있다. 아울러, 크리스마스, 휴일 및 겨울이 모두 스타일 타입 음악 적 경험 디스크립터로서 입력되는 경우, 크리스마스에 대한 테이블(들)이 3개의 모든 입력에 대응하기 위해 필 요한 음악 체계를 제공할 수도 있다. 또한, 흥분과 긴장이 모두 감정 타입 음악적 경험 디스크립터로서 입력되고, 시스템 사용자가 10이 최대 흥분이 고 0이 최소 흥분인데 흥분을 10 중 9로 특정하고, 10이 최대 긴장이고 0이 최소 긴장인데 긴장을 10 중 2로 특 정하는 경우(그 결과, 이에 한정되지는 않지만, 라인 상에서 슬라이더를 움직이거나, 텍스트 필드에 퍼센트를 입력함으로써, 각 디스크립터의 양이 그래픽으로 전달될 수 있음), 흥분에 대한 시스템 파라미터 테이블(들)이 양 입력에 대응하기 위해 필요한 음악 체계를 제공할 수도 있다. 이들 3개의 모든 예에서, 서브 세트이므로 추 가적인 디스크립터의 보다 구체적인 버전이 되는 음악적 경험 디스크립터가 그 테이블(들)이 사용될 수 있는 음 악적 경험 디스크립터로서 선택된다. 방법(M2)이 채택되고, 서브 시스템(B70)이 다수의 감정/스타일 인덱스 시스템 파라미터 테이블 중에서 결정을 행하며, 다수의 감정/스타일 디스크립터 인덱스 시스템 파라미터 테이블의 조합을 사용하기로 결정하는, 제2 사례 시나리오를 고려하기로 한다. 방법 2 시나리오에서, 서브 시스템(B70)은, 특수한 경우에 또는 전체적인 경향으로서, 서브 시스템(B0)에 입력 된 다수의 감정/스타일 디스크립터에 대한 응답으로 서브 시스템(B51)에 의해 생성된 다수의 감정/스타일 디스 크립터 인덱스 시스템 파라미터 테이블 중에서, 이 디스크립터 인덱스 시스템 파라미터 테이블 중 일부 또는 전 부의 조합이 가장 잘 사용될 수 있을 것으로 인식한다. 방법 2에 따르면, 이에 한정되지는 않지만, 오직 특정 테이블 내의 특정 디스크립터 테이블(들)의 (가중) 평균(들)과 우성을 포함하는 기능을 채택함으로써, 이와 같 은 시스템 파라미터의 조합이 생성될 수 있다. 일례로서, 행복, 활기찬 및 긍정적이 모두 감정 디스크립터로서 입력되는 경우, 3개의 모든 디스크립터에 대한 시스템 파라미터 테이블(들)이 함께 잘 협력하여 (동일한 가중치를 가진) 각 서브 시스템 테이블 내의 데이터를 평균함으로써 3개의 모든 입력에 대응하기 위해 필요한 음악 체계를 제공할 수도 있다. 아울러, 크리스마스, 휴 일 및 겨울이 모두 스타일 디스크립터로서 입력되는 경우, 셋 모두에 대한 테이블(들)이 일반 리듬 생성 서브 시스템(A1)을 위한 크리스마스 테이블, 일반 피치 생성 서브 시스템(A2)을 위한 휴일 테이블, 및 컨트롤러 코드 및 모든 다른 서브 시스템을 위한 휴일 및 겨울 시스템 파라미터 테이블의 조합을 이용하여 3개의 모든 입력에 대응하기 위해 필요한 음악 체계를 제공할 수도 있다. 또한, 흥분과 긴장이 모두 감정 타입 음악적 경험 디스크 립터로서 입력되고, 시스템 사용자가 10이 최대 흥분이고 0이 최소 흥분인데 흥분을 10 중 9로 특정하고, 10이 최대 긴장이고 0이 최소 긴장인데 긴장을 10 중 2로 특정하는 경우(그 결과, 이에 한정되지는 않지만, 라인 상 에서 슬라이더를 움직이거나, 텍스트 필드에 퍼센트를 입력함으로써, 각 디스크립터의 양이 그래픽으로 전달될 수 있음), 가중 평균을 채택한 테이블(들) 내의 가중치가 사용자 사양 수준에 의해 영향을 받을 수도 있다. 이 들 3개의 모든 예에서, 디스크립터들은 세트(들)와 서브 세트(들)로서 분류될 뿐만 아니라, 서로에 대한 전체 감정 및/또는 스타일 스펙트럼 내에서의 그들의 관계에 의해서도 분류된다. 방법(M3)이 채택되고, 서브 시스템(B70)이 다수의 감정/스타일 인덱스 시스템 파라미터 테이블 중에서 결정을 행하며, 다수의 감정/스타일 디스크립터 인덱스 시스템 파라미터 테이블은 사용하지 않기로 결정하는, 제3 사례 시나리오를 고려하기로 한다. 방법 3 시나리오에서, 서브 시스템(B70)은, 특수한 경우에 또는 전체적인 경향으 로서, 서브 시스템(B0)에 입력된 다수의 감정/스타일 디스크립터에 대한 응답으로 서브 시스템(B51)에 의해 생 성된 다수의 감정/스타일 디스크립터 인덱스 시스템 파라미터 테이블 중에서, 감정/스타일 인덱스 시스템 파라 미터 테이블 중 어느 것도 가장 잘 사용될 수 없을 것으로 인식한다. 일례로서, 행복과 슬픔이 모두 감정 디스크립터로서 입력되는 경우, 시스템은 조울증과 같은 별도의 디스크립터 (들)에 대한 테이블(들)이 함께 잘 협력하여 양 입력에 대응하기 위해 필요한 음악 체계를 제공할 수도 있을 것으로 결정할 수 있다. 아울러, 어쿠스틱, 인디 및 포크가 모두 스타일 디스크립터로서 입력되는 경우, 시스템은 피아노, 기타, 바이올린 및 밴조와 같은 별도의 디스크립터(들)에 대한 테이블(들)이 함께 잘 협력하여 입력에 대응하기 위해 필요한 음악 체계를, 가능하다면, 방법에서 상술한 방안(들)을 따라, 제공할 수도 있을 것으 로 결정할 수 있다. 또한, 흥분과 긴장이 모두 감정 디스크립터로서 입력되고, 시스템 사용자가 10이 최대 흥분 이고 0이 최소 흥분인데 흥분을 10 중 9로 특정하고, 10이 최대 긴장이고 0이 최소 긴장인데 긴장을 10 중 8로 특정하는 경우(그 결과, 이에 한정되지는 않지만, 라인 상에서 슬라이더를 움직이거나, 텍스트 필드에 퍼센트를 입력함으로써, 각 디스크립터의 양이 그래픽으로 전달될 수 있음), 시스템은 이 입력들의 적절한 디스크립션이 공황이며, 디스크립터 공황에 대한 기존 시스템 파라미터 테이블 세트의 결핍이 새로운 디스크립터에 대한 테이 블 세트를 자율적으로 생성하기 위해 (가능성이 유사한) 기존 디스크립터의 시스템 파라미터 테이블을 사용할 수 있을 것이라고 결정할 수 있으며, 이 새로운 시스템 파라미터 테이블을 서브 시스템(들) 프로세스(들)에서 이용한다. 이들 모든 예에서, 서브 시스템(B70)은 시스템 사용자의 의도(들)를 만족하는 음악 조각을 궁극적으로 생성하는 체계를 제공하기 위해 대응하는 시스템 파라미터 테이블이 (함께) 사용될 수 있는 추가적 또는 대안적 디스크립 터(들)가 존재하거나 생성될 수 있을 것으로 인식한다. 파라미터 테이블 아카이브 데이터베이스 서브 시스템(B80)의 사양 도 28l는 본 발명의 자동화된 음악 작곡 및 생성 시스템에서 사용되는 파라미터 테이블 아카이브 데이터베이스 서브 시스템(B80)을 나타낸다. 이 서브 시스템(B80)의 주요 기능은 개별 시스템 사용자를 위해 생성된 모든 감 정/스타일 인덱스 시스템 작동 파라미터(SOP) 테이블과 시스템 상에서 음악 작곡을 요청하고 시스템에 제공된 감정/스타일/타이밍 파라미터에 응답하여 시스템에 의해 작곡된 음악 조각에 대한 피드백을 제공한 시스템 사용 자의 모집단뿐만 아니라, 사용자 계정 프로파일, 취향 및 선호도를 영구 저장 및 보존하는 것이다.도 28l에 나타낸 바와 같이, 관계형 데이터베이스 관리 시스템(RBMS), 비관계형 데이터베이스 시스템 또는 다른 데이터베이스 기술로서 실현되는 파라미터 테이블 아카이브 데이터베이스 서브 시스템(B80)은 도 28l에 도시된 바와 같은 데이터베이스 스키마에 따라 예시적 실시형태에서 테이블 구조에 데이터를 저장한다. 도시된 바와 같이, GUI 기반 입출력 서브 시스템(B0)의 출력 데이터 포트는 시스템 GUI 인터페이스를 사용하는 시스템 사용자로부터 데이터베이스 요청을 수신하기 위해 파라미터 테이블 아카이브 데이터베이스 서브 시스템 (B80)의 출력 데이터 포트에 연결된다. 도시된 바와 같이, 피드백 및 학습 작동에 연관된 서브 시스템(B42 내지 B48)의 출력 데이터 포트는 보존된 파라미터 테이블에 대한 요청 전송, 데이터베이스 및 파라미터 테이블을 변 경하기 위한 데이터베이스에 대한 액세스 및 시스템 피드백 및 학습 작동과 연관된 작동의 수행을 위해 파라미 터 테이블 아카이브 데이터베이스 서브 시스템(B80)의 데이터 입력 포트에 작동 가능하게 연결된다. 도시된 바 와 같이, 파라미터 테이블 아카이브 데이터베이스 서브 시스템(B80)의 데이터 출력 포트는 피드백 및 학습 작동 에 연관된 서브 시스템(B42 내지 B48)의 데이터 입력 포트에 작동 가능하게 연결된다. 또한, 도 26a 내지 도 26p에 나타낸 바와 같이, 파라미터 테이블 취급 및 프로세싱 서브 시스템(B7)의 출력 데이터 포트는 미래의 분 석, 사용 및 프로세싱을 위하여 이 서브 시스템(B80)에 의해 취급, 처리 및 생성된 모든 파라미터 테이블의 사 본을 보존하기 위해 파라미터 테이블 아카이브 데이터베이스 서브 시스템(B80)의 데이터 입력 포트에 연결된다. 일반적으로, 모든 파라미터 데이터 세트, 테이블 및 이와 유사한 구조가 파라미터 테이블 아카이브 데이터베이 스 서브 시스템(B80)에 글로벌 방식으로 저장될 것이지만, 본 발명의 시스템에서 자동화된 음악 작곡 및 생성 프로세스 중에 고속의 안정적인 방식으로 그 내부에서 수행되는 전문화된 정보 프로세싱 동작을 지원하기 위해 필요한 경우, 시스템이 서브 시스템 내의 로컬 영구 데이터 저장을 지원할 것으로 이해된다. 타이밍 생성 서브 시스템(B41)의 사양 도 31a 및 도 31b는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 타이밍 생성 서브 시스템(B41)을 나타낸다. 일반적으로, 타이밍 생성 서브 시스템(B41)은 음악 조각에 대한 타이밍 파라미터를 결정한다. 이 정 보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 이에 한정되지는 않지만, 시작, 정지, 변조, 악센트, 볼륨 변경, 형태 변경, 멜로디 변경, 화음 변경, 악기 편 성 변경, 오케스트레이션 변경, 박자 변경, 템포 변경 및/또는 디스크립터 파라미터 변경하라는 음악 조각에 대 한 지시를 포함하는 타이밍 파라미터는 모든 음악 조각의 기본적인 구성 요소이다. 타이밍 파라미터 포착 서브 시스템(B40)은, 이에 한정되지는 않지만, 조각의 디스크립터(들), 스타일(들), 디스 크립터 변경, 스타일 변경, 악기 변경, 일반적인 타이밍 정보(시작, 일시 정지, 히트 포인트, 정지), 박자(변경), 템포(변경), 키(변경), 조성(변경), 컨트롤러 코드 정보 및 오디오 믹스를 포함하여, 생성되고 있 는 음악 조각을 위한 타이밍 맵을 생성하는 것으로서 보일 수도 있다. 이 맵는 전적으로 사용자에 의해, 전적으 로 서브 시스템에 의해, 또는 사용자와 서브 시스템 간의 협업으로 생성될 수 있다. 보다 구체적으로, 타이밍 파라미터 포착 서브 시스템(B40)은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 생성될 (i) 작곡될 조각의 길이, (ii) 음악 조각의 시작, (iii) 음악 조각의 정지, (iv) 음악 조각의 볼륨 증가 및 (v) 음악 조각에서의 임의의 악센트와 관련한 타이밍 정보를 생성하기 위해 타이밍 생성 서브 시스템 (B41)에 타이밍 파라미터(예컨대, 조각의 길이)를 제공한다. 예컨대, 시스템 사용자는 음악 조각이 특정 시점에 시작하고, 수초 후에 변조하며, 더 나중에 템포를 변경하고, 일시 정지하며, 재시작한 다음, 큰 악센트로 종료할 것을 요청할 수도 있다. 이 정보는 사용자 요청의 정확하고 성공적인 구현을 허용하기 위해 시스템의 나머지 서브 시스템으로 전달된다. 사용자가 음악의 시작 지점은 선택 하지만 정지 지점을 입력하지 못하는 시나리오를 포함하여, 가능한 한 성공적으로 조각이 생성될 수 있도록 하 는 사용자와 시스템 입력의 조합이 있을 수도 있다. 임의의 사용자 입력이 없는 경우, 시스템은 논리적 및 음악 적 정지 지점을 생성할 수도 있다. 셋째로, 임의의 사용자 입력이 없는 경우, 시스템은 사용자가 원한다고 자신 이 믿는 것을 정확하게 전달하기 위한 시도로 전체 타이밍 파라미터 세트를 생성할 수도 있다. 길이 생성 서브 시스템(B2)의 사양 도 32는 본 발명의 자동화된 음악 작곡 및 생성 엔진 및 시스템에서 사용되는 길이 생성 서브 시스템(B2)을 나 타낸다. 일반적으로, 길이 생성 서브 시스템(B2)은 생성되고 있는 음악 조각의 길이를 결정한다. 길이는 모든 음악 조각의 기본적인 구성 요소이다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 시스템 사용자에 의해 특정된 조각의 시간 길이가 길이 생성 서브 시스템(B2)에 제공되며, 이 서브 시스템은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 작곡될 음악조각의 시작 및 정지 위치를 생성한다. 예시적인 실시형태에서, 길이 생성 서브 시스템(B2)는 서브 시스템(B41)으로부터 타이밍 맵 정보를 취득하여, 음악 조각의 길이를 결정한다. 자동적으로, 음악 조각이 어떤 기존의 콘텐츠를 수반하도록 생성되는 경우, 음악 조각의 길이는 기존 콘텐츠의 길이와 동일할 것이다. 사용자가 원하는 길이를 수동으로 입력하고자 원하는 경우, 사용자는 [시간: 분: 초] 포맷과 같은 임의의 시간 포맷으로 원하는 길이를 삽입할 수 있거나, 이에 한정 되지는 않지만, 그래픽으로 표시된 타임라인에 \"음악 시작\" 및 \"음악 정지\"를 포함한 디지털 이정표를 배치함으 로써 원하는 길이를 시각적으로 입력할 수 있다. 이 프로세스는 서브 시스템 자체에 의해 복제되거나, 자율적으 로 완료될 수 있다. 예컨대, 시스템의 시스템 인터페이스를 사용하는 사용자는 (i) \"음악 시작\"과 (ii) 30초 동 안의 음악 지속을 요청하기 위해 그래픽으로 표시된 타임라인을 따라 한 지점을 선택할 수 있으며, 그 다음, (시스템 인터페이스를 통해) 서브 시스템에게 적절한 시간에 \"음악 정지\" 이정표를 자동으로 생성하도록 요청할 수 있다. 도 32에 나타낸 바와 같이, 길이 생성 서브 시스템(B2)은 시스템 사용자에 의해 선택된 (또는 그렇지 않으면 시 스템에 의해 자동으로 특정된) 길이를 입력으로서 수신하고, 이 정보를 이용하여, 시스템의 메모리 구조 내에 유지된 음악 스코어 표현을 따라 음악 조각의 시작 지점을 결정한다. 도 32에 나타낸 바와 같이, 길이 생성 서 브 시스템(B2)으로부터의 출력은 작곡 중인 음악 조각의 타임라인을 따라 단일의 지점으로서 표시되어 있다. 템포 생성 서브 시스템(B3)의 사양 도 33는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 템포 생성 서브 시스템(B3)을 나타낸다. 일 반적으로, 템포 생성 서브 시스템(B3)은 완성되었을 때 음악 조각이 갖게 될 템포(들)를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 템포 또는 음악 조각이 실행되거나 연주되는 속도는 모든 음악 조각의 기본적인 구성 요소이다. 원칙적으로, (즉, 분 당 비트 또는 BPM으로 측정된) 조각의 템포는 시스템 사용자(들)에 의해 이 서브 시스템에 제공된 조각 시간 길 이 및 음악적 경험 파라미터에 기초하여 연산되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용 된다. 도 33에 나타낸 바와 같이, 템포 생성 서브 시스템(B3)은 도 28a에 나타낸 템포 파라미터 테이블과 파라미터 선 택 메커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 도 28a에 나타낸 바 와 같이, 예시적인 실시형태에서는, GUI 기반 입출력 서브 시스템(B0)을 이용하여, 프로세스의 음악적 경험 특 정 단계 중에 시스템 사용자가 선택할 수 있는 각각의 잠재적 감정 타입 음악적 경험 디스크립터에 대해 서브 시스템(B51)에 의해 다른 확률 테이블(즉, 서브 테이블)이 생성된다. 오직 예시를 위해, 시스템 사용자가 선택 했을지도 모르는 다수의 가능한 감정에 대한 예시적인 확률(음악 이론) 시스템 작동 파라미터(SOP) 테이블이 도 28a, 도 28b 및 도 28c에 도시되어 있지만, 시스템 사용자에 의해 실제로 선택된 감정 타입 및 스타일 타입 디 스크립터에 대응하는 시스템 작동 파라미터 테이블만이 파라미터 변환 엔진 서브 시스템(B51)에 의해 실제로 생 성된 다음, 본 발명의 자동화된 음악 작곡 프로세스의 실행 중에 자신의 각 서브 시스템 내에 분배 및 로드될 것으로 이해된다. 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공된 다양한 음악적 경험 디스크립터를 위한 확률 가중 템포 파라미터 테이블을 생성한다. 도 33에서, 서브 시스템(B3)에 채 택된 확률 기반 파라미터 테이블은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복을 위해 설립되어 자동화 된 음악 작곡 및 생성 프로세스 중에 사용됨으로써, 도 33의 하단에 도시된 음악 스코어 표현에 도시된 바와 같 이 작곡되고 있는 음악 조각의 일부를 생성한다. 도 33에 도시된 바와 같이, 작곡 중인 음악 조각의 템포는, 예시적인 실시형태에서는 파라미터 테이블로부터 선 택될 파라미터를 결정하는 난수 발생기를 이용하여, 서브 시스템(B3) 내에 로드된 확률 기반 조성 파라미터 테 이블로부터 선택된다. 그러나, 가사 또는 언어/음성/노래/음악 입력이 시스템에 의해 지원되는 도 88 내지 도 100에 도시된 바와 같은 대안적인 실시형태에서는, 서브 시스템 내의 파라미터 선택 메커니즘이 더 진보된 방법 을 사용할 수 있다. 예컨대, 그와 같은 경우에는, 각 서브 시스템 내의 파라미터 선택 메커니즘이 시스템 사용 자로부터 시스템에 의해 수신되는 가사 또는 언어/음성/노래 입력의 실제 피치, 리듬 및/또는 하모니 특징과 관 련하여 서브 시스템 내에 확립된 기준에 기초하여 파라미터 값을 선택할 수 있다. 이와 같은 변형 및 변경이 자 동화된 음악 작곡 프로세스 중에 각 서브 시스템 내에서 이용가능한 결정 경로를 효과적으로 제한할 것이지만, 그와 동시에, 많은 애플리케이션에서 필요하거나 요구되는 경우, 작곡되고 있는 음악이 상품 타입 음악에서 보 다 예술 타입 음악으로 전환할 수 있도록 한다.길이 생성 서브 시스템(B2)의 출력을 고려하여, 템포 생성 서브 시스템은 조각의 템포(들)를 생성한다. 예컨대, 입력 감정 타입 디스크립터가 \"행복\"이고 길이가 30초인 조각은 60 BPM의 템포를 사용할 1/3의 확률, 80 BPM의 템포를 사용할 1/3의 확률 및 100 BPM의 템포를 사용할 1/3의 확률을 가질 수 있다. 다양한 섹션 및/또는 시작 과 정지가 음악에 존재하는 경우, 섹션들 사이의 템포를 조절하는 템포 곡선과 아울러, 음악 타이밍 파라미터 및/또는 다수의 템포가 선택될 수 있다. 이 곡선은 상당한 양의 시간(예컨대, 많은 마디) 동안 지속될 수 있거 나, 전혀 지속될 수 없다(예컨대, 템포의 즉각적인 변경). 도 33에 나타낸 바와 같이, 템포 생성 서브 시스템(B3)은 도 28a에 나타낸 템포 테이블과 파라미터 선택 메커니 즘(예컨대, 난수 발생기 또는 전술한 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 파라미터 변환 엔진 서브 시스템(B51)은 입력 서브 시스템(B0)을 이용하여 시스템 사용자에 의해 선택된 다양한 음악적 경험 디스크립터를 위한 확률 가중 템포 파라미터 테이블을 생성한다. 도 33에서, 서브 시스템(B3)에 채 택된 확률 기반 파라미터 테이블은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복을 위해 설립되어 자동화 된 음악 작곡 및 생성 프로세스 중에 사용됨으로써, 작곡되고 있는 음악 조각의 일부를 생성한다. 조각의 템포 는 서브 시스템(B3) 내에 설립된 확률 기반 템포 파라미터 테이블을 이용하여 선택된다. 템포 생성 서브 시스템 (B3)으로부터의 출력은 도 33에 나타낸 바와 같은 예시적인 음악 조각에서 60 BPM이 있을 것이라는 지시를 갖춘 완전 쉼표이다. 자동화된 음악 작곡 프로세스의 이 단계에서는 박자 할당이 결정되지 않는다. 박자 생성 서브 시스템(B4)의 사양 도 34는 본 발명의 자동화된 음악 작곡 및 생성 엔진 및 시스템에서 사용되는 박자 생성 서브 시스템(B4)을 나 타낸다. 박자, 또는 음악의 펄스 또는 비트를 제공하는 스트레스 또는 악센트의 순환 패턴은 모든 음악 조각의 기본적인 구성 요소이다. 일반적으로, 박자 생성 서브 시스템은 생성되고 있는 음악 조각의 박자(들)를 결정한 다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하 게 된다. 작곡되고 있는 음악 조각의 박자는 이 서브 시스템에 제공된 조각 시간 길이 및 음악적 경험 파라미터 에 기초하여 연산되며, 도출된 템포는 분당 비트(BPM) 단위로 측정되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 34에 나타낸 바와 같이, 박자 생성 서브 시스템(B4)은 도 28c에 나타낸 박자 파라미터 테이블과 아울러 파라 미터 선택 메커니즘(예컨대, 난수 발생기 또는 전술한 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 파라미터 변환 엔진 서브 시스템(B51)은 입력 서브 시스템(B0)을 이용하여 시스템 사용자에 의해 선택된 다양한 음악적 경험 디스크립터를 위한 확률 가중 파라미터 테이블을 생성한다. 도 34에서, 서브 시스템(B11)에 채택된 확률 기반 파라미터 테이블은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복을 위해 설립되어 자동화된 음 악 작곡 및 생성 프로세스 중에 사용됨으로써, 도 34의 하단에 도시된 음악 스코어 표현에 도시된 바와 같이 작 곡되고 있는 음악 조각의 일부를 생성한다. 조각의 박자는 서브 시스템(B4) 내에 설립된 확률 기반 박자 파라미 터 테이블을 이용하여 선택된다. 박자 생성 서브 시스템(B4)으로부터의 출력은 도 33에 지시된 바와 같이 예시 적인 음악 조각에서 60개의 사분음표와 4/4 타이밍이 있을 것이라는 지시를 갖춘 완전 쉼표이다. 특히, 4/4 타 이밍은 작곡되고 있는 음악 조각이 조각의 각 마디 중에 4개의 사분음표가 연주되도록 요청하게 될 것을 의미한 다. 키 생성 서브 시스템(B5)의 사양 도 35는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 키 생성 서브 시스템(B5)을 나타낸다. 키, 또는 특정 조성을 규정하는 음표의 특정 스케일 또는 시리즈는 모든 음악 조각의 기본적인 구성 요소이다. 일반 적으로, 키 생성 서브 시스템(B5)은 생성되고 있는 음악 조각의 키를 결정한다. 일반적으로, 키 생성 서브 시스 템(B5)은 음악 조각이 갖게 될 키(들)를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 또한, 조각의 키는 시스템 사용자(들)에 의해 시스템 에 제공된 음악적 경험 파라미터에 기초하여 연산된다. 도출된 키는 본 발명의 자동화된 음악 작곡 및 생성 프 로세스 중에 선택되어 사용된다. 도 35에 나타낸 바와 같이, 이 서브 시스템은 도 28d에 나타낸 키 파라미터 테이블과 아울러 파라미터 선택 메 커니즘(예컨대, 난수 발생기 또는 전술한 바와 같은 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 파라미터 변환 엔진 서브 시스템(B51)은 입력 서브 시스템(B0)으로부터 선택된 다양한 음악적 경험 디스크립터 를 위한 확률 가중 키 파라미터 테이블을 생성한다. 도 35에서, 서브 시스템(B5)에 채택된 확률 기반 키 파라미터 테이블은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복을 위해 설립되어 자동화된 음악 작곡 및 생성 프로세스 중에 사용됨으로써, 작곡되고 있는 음악 조각의 일부를 생성한다. 조각의 키는 서브 시스템(B5) 내에 설립된 확률 기반 키 파라미터 테이블을 이용하여 선택된다. 키 생성 서브 시스템(B5)으로부터의 출력은 도 35 에 나타낸 바와 같이 시스템에 의해 관리되고 있는 음악 스코어 표현에 키 서명으로서 표시되어 있다. 비트 계산기 서브 시스템(B6)의 사양 도 36는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 비트 계산기 서브 시스템(B6)을 나타낸다. 비트 계산기 서브 시스템은 음악 조각 내의 비트 수를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨 터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 비트, 또는 지휘자의 손이나 지휘봉의 오 르내림에 의해, 메트로놈에 의해, 또는 음악 내의 악센트에 의해 좌우될 수 있는 음악의 규칙적 펄스는 모든 음 악 조각의 기본적인 구성 요소이다. 조각 내의 비트 수는 시스템에 제공된 조각 길이와 시스템에 의해 연산된 템포에 기초하여 연산되며, 도출된 비트 수는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 36에 나타낸 바와 같이, 비트 계산기 서브 시스템(B6)은 도 36에 개략적으로 도시된 비트 계산 메커니즘에 의해 지원된다. 이 서브 시스템(B6)은 조각의 길이와 조각의 템포의 역수를 곱하거나, 조각의 각 섹션의 길이와 대응하는 섹션의 템포의 역수를 곱하고 그 결과를 더하여, 음악 조각 내의 비트 수를 계산한다. 예컨대, 템포가 60 BPM이고 4/4 박자인 30초의 음악 조각은 30 비트[30초* 1/60 BPM]를 가질 것이고, 각각의 비트는 각 마디 내 의 단일 사분음표를 나타낸다. 비트 계산기 서브 시스템(B6)의 출력은 작곡되고 있는 음악 조각 내에서 계산된 비트 수이다. 사례에서는, 도 36에 나타낸 바와 같이, 시스템에 의해 관리되고 있는 음악 스코어 표현에 제시된 바와 같이, 32 비트가 계산되었다. 마디 계산기 서브 시스템(B8)의 사양 도 37는 본 발명의 자동화된 음악 작곡 및 생성 엔진 및 시스템에서 사용되는 마디 계산기 서브 시스템(B8)을 나타낸다. 마디 계산기 서브 시스템(B8)은 음악 조각에서 완성된 마디와 미완성된 마디의 수를 결정한다. 이 정 보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 마디, 또는 고정된 비트 수를 포함하는 음악 조각의 최소 운율 분할의 기표는 모든 음악 조각의 기본적인 구성 요소이다. 조각 내의 마디 수는 조각 내의 비트 수와 연산된 조각의 박자에 기초하여 연산되며, 조각 내의 박자 는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 37에 나타낸 바와 같이, 마디 계산기 서브 시스템(B8)은 도 37에 개략적으로 도시된 비트 계산 메커니즘에 의해 지원된다. 이 서브 시스템은, 오직 1개의 박자를 가진 조각에서, 각 음악 조각 내의 비트 수를 조각의 박 자(들)의 분자로 나누어 음악 조각 내에 얼마나 많은 마디가 있는지를 결정한다. 예컨대, 템포가 60 BPM이고 4/4 박자여서 30 비트인 30초의 음악 조각은 [30/4]인 7.5 마디를 가질 것이고, 각각의 비트는 각 마디 내의 단 일 사분음표를 나타낸다. 마디 계산기 서브 시스템(B8)의 출력은 작곡되고 있는 음악 조각 내에서 계산된 박자 수이다. 사례에서는, 도 37에 나타낸 바와 같이, 시스템에 의해 관리되고 있는 음악 스코어 표현에 제시된 바와 같이, 8개의 박자가 표시되었다. 조성 생성 서브 시스템(B7)의 사양 도 38는 본 발명의 자동화된 음악 작곡 및 생성 엔진 및 시스템에서 사용되는 조성 생성 서브 시스템(B7)을 나 타낸다. 조성, 또는 메이저, 마이너 또는 다른 음계에 기초한 으뜸음 주위에서의 음악 조각의 주요 조직은 모든 음악 조각의 기본적인 구성 요소이다. 조성 생성 서브 시스템은 음악 조각의 조성 또는 조성들을 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 도 38에 나타낸 바와 같이, 이 서브 시스템(B7)은 도 28e에 나타낸 조성 파라미터 테이블과 아울러 파라미터 선 택 메커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 각 파라미터 테이블은 합이 1인 확률을 포함한다. 각각의 특정 확률은 0 내지 1 범위의 특정 섹션을 포함한다. 난수가 확률의 특정 섹션 내에 있는 경우, 그것이 선택된다. 예컨대, 2개의 파라미터 A와 B가 각각 50%의 선택 기회를 가진 경우, 난수가 0 내지 0.5 사이에 있으면, A를 선택할 것이고, 0.5 내지 1 사이에 있으면, B를 선택 할 것이다. 조각의 조성 수는 서브 시스템(B7) 내에 설립된 확률 기반 조성 파라미터 테이블을 이용하여 선택된다. 파라미 터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공되는 다양한 음악적 경험 디스크립터를 위한 확률 가중 조성 파라미터 테이블을 생성한다. 도 38에서, 서브 시스템(B7)에 채택 된 확률 기반 파라미터 테이블은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복을 위해 설립되어 자동화된 음악 작곡 및 생성 프로세스 중에 사용됨으로써, 도 38의 하단에 도시된 음악 스코어 표현에 도시된 바와 같이 작곡되고 있는 음악 조각의 일부를 생성한다. 서브 시스템(B0)에 제공되는 모든 시스템 사용자 입력을 고려하여, 이 시스템(B7)은 조각의 조성(들)을 생성한 다. 예컨대, 입력 디스크립터가 \"행복\"이고 길이가 30초이며 템포가 60 BPM이고 박자가 4/4이며 키가 C인 조각 은 메이저 조성을 사용할 2/3의 확률, 또는 마이너 조성을 사용할 1/3의 확률을 가질 수 있다. 다수의 섹션, 음 악 타이밍 파라미터 및/또는 시작과 정지가 음악에 존재하는 경우, 다수의 조성이 선택될 수 있다. 조성 생성 서브 시스템(B7)의 출력은 작곡되고 있는 음악 조각의 선택된 조성이다. 일례에서, \"메이저 음계\" 조성이 도 38 에서 선택된다. 노래 형태 생성 서브 시스템(B9)의 사양 도 39a 및 도 39b는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 노래 형태 생성 서브 시스템(B 9)을 나타낸다. 형태, 또는 음악 조각의 구조는 모든 음악 조각의 기본적인 구성 요소이다. 노래 형태 생성 서 브 시스템은 음악 조각의 노래 형태를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값 (들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 도 39a 및 도 39b에 나타낸 바와 같이, 이 서브 시스템은 도 28f에 도시된 노래 형태 파라미터 테이블 및 노래 형태 하위 악절 테이블과 아울러 파라미터 선택 메커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 일반적으로, 노래 형태는 서브 시스템(B9) 내에 설립된 확률 기반 노래 형태 하위 악절 파라미터 테이블을 이용 하여 선택된다. 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0) 에 제공되는 다양한 음악적 경험 디스크립터를 위한 확률 가중 노래 형태 파라미터를 생성한다. 도 39a 및 도 39b에서, 서브 시스템(B9)에 채택된 확률 기반 파라미터 테이블은 예시적인 \"감정 타입\" 음악적 경험 디스크립 터-행복을 위해 설립되어 자동화된 음악 작곡 및 생성 프로세스 중에 사용됨으로써, 도면의 하단에 도시된 음악 스코어 표현에 도시된 바와 같이 작곡되고 있는 음악 조각의 일부를 생성한다. 서브 시스템(B0)에 제공되는 모든 시스템 사용자 입력을 고려하여, 이 서브 시스템(B9)은 조각의 노래 형태를 생성한다. 예컨대, 입력 디스크립터가 \"행복\"이고 길이가 30초이며 템포가 60 BPM이고 박자가 4/4인 조각은 ABA(또는, 대안적으로는 버스 코러스 버스라고 기술됨) 형태일 1/3의 확률, AAB(또는, 대안적으로는 버스 버스 코러스라고 기술됨) 형태일 1/3의 확률, 또는 AAA(또는, 대안적으로는 버스 버스 버스라고 기술됨) 형태일 1/3 의 확률을 가질 수 있다. 또한, 노래 형태의 각 섹션은 제1 섹션(A)이 (전술한 바와 동일한 가능 확률 및 디스 크립션을 추종하는) 서브 섹션(\"aba\")으로 구성되도록, 다수의 서브 섹션을 가질 수 있다. 또한, 각 서브 섹션 은 다수의 모티브를 가질 수 있으며, 따라서, 서브 섹션(\"a\")은 (전술한 바와 동일한 가능 확률 및 디스크립션 을 추종하는) 모티브(\"i, ii, iii\")로 구성될 수 있다. 형태가 비거나, 조직되지 않았거나, 존재하지 않는다 하더라도, 모든 음악은 형태를 갖는다. 팝 음악은 전통적 으로 인트로, 버스, 코러스, 브릿지, 솔로, 아우트로 등을 포함한 형태 요소를 갖는다. 각각의 형태 요소는 간 결한 방식으로 전체적인 조각의 형태를 전하는 것을 돕기 위해 문자로 표현될 수 있으며, 따라서, 버스 코러스 버스 형태를 가진 노래는 A B A로서 표현될 수도 있다. 노래 형태 악절은 악절 자체 내의 노래에 구조를 제공하 는 하위 악절을 가질 수도 있다. 버스 또는 A 섹션이 2개의 반복된 스탠자로 구성되는 경우, 하위 악절은 \"aa\" 일 수 있다. 도 39a 및 도 39b에 나타낸 바와 같이, 노래 형태 생성 서브 시스템(B9)은 서브 시스템(B51)으로부터 노래 형태 테이블을 수신하여 입력으로서 로드한다. 노래 형태가 난수 발생기를 사용하여 노래 형태 테이블로부터 선택되 지만, 도 88 내지 도 100에 나타낸 바와 같은 다른 시스템 실시형태에서는 다른 가사 입력 기반 메커니즘이 사 용될 수 있을 것으로 이해된다. 그 후, 다른 선택 메커니즘이 채택될 수 있을 것으로 이해되지만, 노래 형태 하 위 악절 파라미터 테이블이 로드되고, 난수 발생기가 병렬 방식으로 선택하며, 난수 발생기를 사용하여 악절의 제1 및 제2 하위 악절 섹션을 위해 하위 악절이 선택된다. 노래 형태 생성 서브 시스템(B9)으로부터의 출력은 선택된 노래 형태 및 선택된 하위 악절이다. 하위 악절 길이 생성 서브 시스템(B15)의 사양 도 40은 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 하위 악절 길이(리듬 길이) 생성 서브 시스 템(B15)을 나타낸다. 리듬, 또는 규정된 반복가능한 패턴으로의 시간의 공간의 분할 또는 시간 내에서 음악의 제어된 움직임은 모든 음악 조각의 기본적인 구성 요소이다. 하위 악절 길이 생성 서브 시스템(B15)은 작곡되고 있는 음악 조각 내의 각 하위 악절(대안적으로는 서브 섹션 또는 모티브라고 기술됨)의 길이 또는 리듬 길이를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 도 40에 나타낸 바와 같이, 하위 악절 길이(리듬 길이) 생성 서브 시스템(B15)은 도 28g에 나타낸 하위 악절 길 이(즉, 리듬 길이) 파라미터 테이블 및 파라미터 선택 메커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라 미터 선택기)에 의해 지원된다. 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공되는 다양 한 음악적 경험 디스크립터를 위한 확률 가중 하위 악절 길이 파라미터 테이블 세트를 생성한다. 도 40에서, 서 브 시스템(B11)에 채택된 확률 기반 파라미터 테이블은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복을 위해 설립되어 자동화된 음악 작곡 및 생성 프로세스 중에 사용됨으로써, 도 40의 하단에 도시된 음악 스코어 표현에 도시된 바와 같이 작곡되고 있는 음악 조각의 일부를 생성한다. 하위 악절 길이 생성 서브 시스템(B15)은 작곡되고 있는 음악 조각의 각 악절 내의 하위 악절의 길이(즉, 리듬 길이)를 결정한다. 이 길이는 (i) 악절의 전체 길이(즉, 2초의 악절은 200초의 악절보다 훨씬 적은 하위 악절 옵션을 가질 것임), (ii) 조각의 타이밍 필요 요소, 및 (iii) 감정 타입 및 스타일 타입 음악적 경험 디스크립 터에 의해 결정된다. 서브 시스템(B0)에 제공되는 모든 시스템 사용자 입력을 고려하여, 이 시스템(B15)은 조각의 하위 악절 길이를 생성한다. 예컨대, 30초의 음악 조각은 각각 7.5초인 4개의 서브 섹션, 10초인 3개의 서브 섹션, 또는 4초, 5초, 6초, 7초 및 8초인 5개의 서브 섹션을 가질 수 있다. 예컨대, 하위 악절 길이 생성 서브 시스템(B15)에 나타낸 바와 같이, 하위 악절 길이 테이블이 로드되며, 선택 된 노래 형태 내의 각 하위 악절을 위해, 서브 시스템(B15)은 각 하위 악절에 대한 길이 마디를 병렬 방식으로 선택한 다음, 도 40의 하단에 개시된 음악 스코어 표현에 도시된 바와 같이 서브 시스템으로부터의 출력으로서 하위 악절 길이(즉, 리듬 길이) 테이블을 생성한다. 화음 길이 생성 서브 시스템(B11)의 사양 도 41a, 도 41b, 도 41c 및 도 41d는 본 발명의 자동화된 음악 작곡 및 생성 엔진 및 시스템에서 사용되는 화음 길이 생성 서브 시스템(B11)을 나타낸다. 리듬, 또는 규정된 반복가능한 패턴으로의 시간의 공간의 분할 또는 시간 내에서 음악의 제어된 움직임은 모든 음악 조각의 기본적인 구성 요소이다. 화음 길이 생성 서브 시스템 (B11)은 음악 조각 내의 각 화음의 리듬(즉, 디폴트 화음 길이(들))을 결정한다. 이 정보는 (주어진 경우에) 사 용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 도 41a 내지 도 41d에 나타낸 바와 같이, 화음 길이 생성 서브 시스템(B11)은 도 28h에 도시된 화음 길이 파라 미터 테이블 및 전술한 바와 같은 파라미터 선택 메커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 일반적으로, 화음 길이는 시스템 사용자에 의해 시스템에 제공된 음악적 경험 디스크립터에 기초하여 서브 시스 템 내에 설립된 확률 기반 화음 길이 파라미터 테이블을 이용하여 선택된다. 선택된 화음 길이는 본 발명의 자 동화된 음악 작곡 및 생성 프로세스 중에 사용됨으로써, 도 41d의 하단에 도시된 음악 스코어 표현에 도시된 바 와 같이 작곡되고 있는 음악 조각의 일부를 생성한다. 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공되는 다양 한 음악적 경험 디스크립터를 위한 확률 가중 화음 길이 파라미터 테이블 세트를 생성한다. 도 41a 내지 도 41d 에서, 서브 시스템(B11)에 채택된 확률 기반 파라미터 테이블은 예시적인 \"감정 타입\" 음악적 경험 디스크립터- 행복을 위해 설립되어 자동화된 음악 작곡 및 생성 프로세스 중에 사용됨으로써, 도면의 하단에 도시된 음악 스 코어 표현에 도시된 바와 같이 작곡되고 있는 음악 조각의 일부를 생성한다. 서브 시스템(B11)은 시스템 사용자가 제공한 음악적 경험 디스크립터와 타이밍 파라미터, 그리고 시스템(B11)에 로드된 파라미터 테이블을 이용하여, (일반적으로, 필수적이지는 않지만, 비트와 마디 면에서) 조각 전체에 걸 쳐 화음 길이를 생성한다. 예컨대, 4/4 마디 내의 화음은 2비트 동안 지속될 수 있고, 이 정보에 기초하여 다음 화음이 1비트 동안 지속될 수 있으며, 이 정보에 기초하여 마지막 화음이 1비트 동안 지속될 수 있다. 제1 화음이 1비트 동안 지속될 수도 있으며, 이 정보에 기초하여, 다음 화음이 3비트 동안 지속될 수 있다. 도 41a 내지 도 41d에 나타낸 바와 같이, 도 28h에 나타낸 화음 길이 테이블이 서브 시스템(B51)으로부터 로드 되며, 병렬 방식으로, 제1 하위 악절(a)의 제1 화음 길이가 제1 화음 길이 테이블을 사용하여 결정되고, 제1 하 위 악절(a)의 제2 화음 길이가 도시된 바와 같이 제1 화음 길이 테이블과 제2 화음 길이 테이블을 모두 사용하 여 결정된다. 마찬가지로, 제2 하위 악절(b)의 제1 화음 길이가 제1 화음 길이 테이블을 사용하여 결정되고, 제 2 하위 악절(b)의 제2 화음 길이가 제1 화음 길이 테이블과 제2 화음 길이 테이블을 모두 사용하여 결정된다. 사례에서 선택된 노래 형태(A B A) 내의 각 악절에 대해 이 프로세스가 반복된다. 나타낸 바와 같이, 화음 길이 생성 서브 시스템(B11)으로부터의 출력은 선택된 노래 형태 내의 악절(A B A)에 대한 하위 악절 화음 길이 세트 이다. 이 하위 악절 화음 길이는 도 41d에 나타낸 음악 스코어 표현에 그래픽으로 표시된다. 특이 하위 악절 생성 서브 시스템(B14)의 사양 도 42는 본 발명의 자동화된 음악 작곡 및 생성 엔진 및 시스템에서 사용되는 특이 하위 악절 생성 서브 시스템 (B14)을 나타낸다. 특이 하위 악절 생성 서브 시스템(B14)은 작곡되고 있는 음악 조각 내의 각 악절에 얼마나 많은 특이 하위 악절이 있는지를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 되며, 모든 음악 조각의 기본적인 구성 요소이다. 도 42에 나타낸 바와 같이, 이 서브 시스템(B14)은 하위 악절 분석기와 화음 길이 분석기에 의해 지원된다. 특 이 하위 악절 생성 서브 시스템(B20) 내의 하위 악절 분석기의 주요 기능은 하위 악절 또는 하위 악절들의 기능 성과 가능한 도출을 결정하는 것이다. 작동 중에, 하위 악절 분석기는 음악 조각의 조각, 섹션, 악절 또는 다른 길이의 템포, 박자, 형태, 화음(들), 하모니(들) 및 구조를 이용하여 그 출력을 결정한다. 특이 하위 악절 생성 서브 시스템(B20) 내의 화음 길이 분석기의 주요 기능은 화음 및/또는 하위 악절의 길이를 결정하는 것이다. 작 동 중에, 화음 길이 분석기는 음악 조각의 조각, 섹션, 악절 또는 다른 길이의 템포, 박자, 형태, 화음(들), 하 모니(들) 및 구조를 이용하여 그 출력을 결정한다. 도 42에 나타낸 바와 같이, 특이 하위 악절 생성 서브 시스템(B14)은 하위 악절 길이(리듬 길이) 생성 서브 시 스템(B15)으로부터 생성된 데이터 출력(즉, 하위 악절 길이 마디 세트)을 하위 악절 분석기와 화음 길이 분석기 를 이용하여 자동으로 분석하여, 조각 내 특이 하위 악절의 수에 대한 목록을 제작한다. 예컨대, 30초의 음악 조각이 4개의 7.5초 하위 악절을 가지면, 각각 한번 발생하는 4개의 특이 하위 악절, (2개는 각각 한번 발생하 고 1개는 두번 발생하는) 3개의 특이 하위 악절, 각각 두번 발생하는 2개의 특이 하위 악절, 또는 네번 발생하 는 1개의 특이 하위 악절이 있을 수도 있으며, 특이 하위 악절 생성 서브 시스템(B14)은 본 발명의 자동화된 음 악 작곡 및 생성 프로세스 중에 그와 같은 결정을 자동으로 행한다. 하위 악절 내 화음 수 계산 서브 시스템(B16)의 사양 도 43는 본 발명의 자동화된 음악 작곡 및 생성 엔진 및 시스템에서 사용되는 하위 악절 내 화음 수 계산 서브 시스템(B16)을 나타낸다. 하위 악절 내 화음 수 계산기는 각 하위 악절에 얼마나 많은 화음이 있는지를 결정한 다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하 게 되며, 모든 음악 조각의 기본적인 구성 요소이다. 하위 악절 내 화음 수는 연산된 특이 하위 악절을 사용하 여 계산되며, 하위 악절 내 화음 수는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 43에 나타낸 바와 같이, 이 서브 시스템(B16)은 화음 계수기에 의해 지원된다. 작동 중에, 서브 시스템(B1 6)은 서브 시스템(B11, B14 및 B15)으로부터의 출력을 조합하여 각 하위 악절에 얼마나 많은 화음이 있는지를 계산한다. 예컨대, 2마디 하위 악절 내의 모든 화음 길이가 1마디 길이이면, 하위 악절 내에 2개의 화음이 존재 하며, 이 데이터는 하위 악절 내 화음 수 계산 서브 시스템(B16)으로부터의 출력으로서 생성될 것이다. 악절 길이 생성 서브 시스템(B12)의 사양 도 44은 본 발명의 자동화된 음악 작곡 및 생성 엔진 및 시스템에서 사용되는 악절 길이 생성 서브 시스템(B1 2)의 개략도를 나타낸다. 리듬, 또는 규정된 반복가능한 패턴으로의 시간의 공간의 분할 또는 시간 내에서 음악 의 제어된 움직임은 모든 음악 조각의 기본적인 구성 요소이다. 악절 길이 생성 서브 시스템(B12)은 음악 조각 내의 각 악절의 길이 또는 리듬을 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 악절의 길이가 악절 길이 분석기를 사용하여 측정된 다음, (마디 수 단위의) 악절의 길이는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 44에 나타낸 바와 같이, 이 서브 시스템(B12)은 악절 길이 분석기에 의해 지원된다. 악절 길이 분석기의 주 요 기능은 악절의 길이 및/또는 리듬 값을 결정하는 것이다. 악절 길이 분석기는 음악 조각, 섹션, 악절 또는 추가적인 세그먼트(들)의 모든 하위 악절과 다른 구성 요소의 길이(들) 및/또는 리듬 값(들)을 고려하여 그 출 력을 결정한다. 서브 시스템(B1, B31 및/또는 B40)으로부터 수신된 입력을 고려하여, 서브 시스템(B12)은 자동으로 작곡되고 있 는 음악 조각의 악절 길이를 생성한다. 예컨대, 1분의 음악 조각은 30초인 2개의 악절, 또는 20초인 3개의 악절 을 가질 수 있다. 하나 이상의 서브 섹션의 조합이 악절의 길이를 생성할 수 있으므로, 이전에 생성된 서브 섹 션의 길이가 각 악절의 길이를 통지하기 위해 사용된다. 출력 악절 길이는 도 44에 나타낸 음악 스코어 표현에 그래픽으로 표시된다. 특이 악절 생성 서브 시스템(B10)의 사양 도 45는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 특이 악절 생성 서브 시스템(B10)을 나타낸 다. 악절, 또는 음악의 종속적 분할로서 흔히 간주되는 음악 단위는 모든 음악 조각의 기본적인 구성 요소이다. 특이 악절 생성 서브 시스템(B10)은 음악 조각에 얼마나 많은 특이 악절이 포함될지를 결정한다. 이 정보는 (주 어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 특이 악 절의 수가 서브 시스템(B10) 내의 악절 분석기를 사용하여 결정된 다음, 특이 악절의 수는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 45에 나타낸 바와 같이, 서브 시스템(B10)은 악절 (길이) 분석기에 의해 지원된다. 악절 길이 분석기의 주요 기능은 악절의 길이 및/또는 리듬 값을 결정하는 것이다. 악절 길이 분석기는 음악 조각, 섹션, 악절 또는 추가 적인 세그먼트(들)의 모든 하위 악절과 다른 구성 요소의 길이(들) 및/또는 리듬 값(들)을 고려하여 그 출력을 결정한다. 특이 악절 생성 서브 시스템(B10) 내에서, 악절 분석기는 서브 시스템(B12)으로부터 제공된 데이터를 분석함으 로써, 작곡될 조각 내 특이 악절 또는 섹션의 수에 대한 목록을 제작한다. 1분의 음악 조각이 4개의 15초 악절 을 가지면, 각각 한번 발생하는 4개의 특이 악절, (2개는 각각 한번 발생하고 1개는 두번 발생하는) 3개의 특이 악절, 각각 두번 발생하는 2개의 특이 악절, 또는 네번 발생하는 1개의 특이 악절이 있을 수도 있으며, 이 데이 터는 서브 시스템(B10)으로부터의 출력으로서 생성될 것이다. 악절 내 화음 수 계산 서브 시스템(B13)의 사양 도 46는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 악절 내 화음 수 계산 서브 시스템(B13)을 나타낸다. 악절 내 화음 수 계산기는 각 악절에 얼마나 많은 화음이 있는지를 결정한다. 이 정보는 (주어진 경 우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 되며, 모든 음악 조각 의 기본적인 구성 요소이다. 도 46에 나타낸 바와 같이, 서브 시스템(B13)은 화음 계수기에 의해 지원된다. 화음 계수기의 주요 기능은 악절 내의 화음 수를 결정하는 것이다. 서브 시스템(B13) 내의 화음 계수기는 각 악절의 길이를 악절 내 화음의 리듬 및/또는 길이로 나누어 악절 내의 화음 수를 결정한다. 예컨대, 1개의 사분음표 전체의 일정한 화음 길이를 가 진 4/4 박자에 60 BPM의 템포를 가진 30초 악절은 악절 내에 30개의 화음을 가질 것이다. 그리고, 연산된 악절 내 화음 수는 서브 시스템(B13)으로부터의 출력으로서 제공되어, 본 발명의 자동화된 음악 작곡 및 생성 프로세 스 중에 사용된다. 제1 일반 리듬 생성 서브 시스템(B17)의 사양 도 47는 본 발명의 자동화된 음악 작곡 및 생성 엔진 및 시스템에서 사용되는 제1 일반 리듬 생성 서브 시스템 (B17)을 나타낸다. 화음, 2개 이상(일반적으로 적어도 3개)의 음표의 동시 음향은 모든 음악 조각의 기본적인 구성 요소이다. 제1 일반 리듬 생성 서브 시스템(B17)은 작곡되고 있는 음악 조각의 제1 화음 또는 음표(들)를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 도 47에 나타낸 바와 같이, 제1 일반 리듬 생성 서브 시스템(B17)은 도 28i에 나타낸 제1 화음 밑음 음표 테이 블, 도 28i에 나타낸 화음 기능 테이블, 화음 조성 분석기, 및 전술한 파라미터 선택 메커니즘(예컨대, 난수 발 생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 화음 기능 조성 분석기의 주요 기능은 화음 또는 다른 하모니 재료의 조성을 결정하여, 조성에 포함된 피치를 결정하는 것이다. 작동 중에, 화음 기능 조성 분석 기는 화음 또는 하모니의 키(들), 음악 기능(들) 및 밑음 음표(들)를 고려하여 그 조성을 결정한다.파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공되는 다양 한 음악적 경험 디스크립터를 위한 밑음 음표 및 화음 기능의 확률 가중 데이터 세트(즉, 파라미터 테이블)를 생성한다. 도 47에서, 서브 시스템(27u)에 채택된 확률 기반 파라미터 테이블(즉, 확률 기반 제1 화음 밑음 테 이블 및 확률 기반 화음 기능 테이블)은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복을 위해 설립되어 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 서브 시스템(B17)은 서브 시스템(B51)에 의해 생성되어 로드된 파라미터 테이블을 이용하여, 조각의 제1 화음을 선택한다. 예컨대, C 메이저의 \"행복\" 음악 조각에는, 제1 화음이 C 메이저 삼화음일 1/3의 확률, 제1 화음이 G 메이저 삼화음일 1/3의 확률, 및 제1 화음이 F 메이저 삼화음일 1/3의 확률이 있을 수 있다. 도 47에 나타낸 바와 같이, 서브 시스템(B17)은 제1 화음 밑음 음표 테이블에 액세스하고, 난수 발생기 또는 다 른 파라미터 선택 메커니즘을 이용하여, 제1 밑음 음표(예컨대, 사례에서는 제1 밑음 음표 = 7)를 선택한다. 그 후, 서브 시스템(B17)은 도 28i에 나타낸 화음 기능 테이블에 액세스하고, 난수 발생기 또는 다른 파라미터 선 택 메커니즘을 이용하여, 제1 화음 기능(예컨대, 사례에서는 제1 화음 기능 = 1)을 선택한다. 그리고, 서브 시 스템(B17)은 화음 기능 분석기를 사용함으로써 화음 또는 하모니의 키(들), 음악 기능(들) 및 밑음 음표(들)를 고려하여 제1 화음 기능의 조성을 결정한다. 나타낸 바와 같이, 메이저 삼화음이 제1 화음 기능 조성으로서 식 별되고, 제1 화음은 G 메이저 삼화음으로서 식별되며, 이들은 도 47에 나타낸 음악 스코어 표현에 표시되어 있 다. 하위 악절 화음 진행 생성 서브 시스템(B19)의 사양 도 48a, 도 48b 및 도 48c은 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 하위 악절 화음 진행 생 성 서브 시스템(B19)을 나타낸다. 화음, 2개 이상(일반적으로 적어도 3개)의 음표의 동시 음향은 모든 음악 조 각의 기본적인 구성 요소이다. 하위 악절 화음 진행 생성 서브 시스템(B19)은 음악 조각의 각 하위 악절에 대해 화음 진행이 어떻게 이루어질지를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 도 48a, 도 48b 및 도 48c에 나타낸 바와 같이, 하위 악절 화음 진행 생성 서브 시스템(B19)은 도 77j 및 도 77k에 나타낸 화음 밑음 테이블, 화음 기능 밑음 변조기 테이블, 화음 밑음 변조기 테이블, 현재 기능 테이블, 비트 밑음 변조기 테이블, 비트 분석기, 및 파라미터 선택 메커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 비트 분석기의 주요 기능은 현재 또는 미래 음악 이벤트(들)에서의 위치를 결정하는 것이다. 비트 분석기는 조각, 섹션, 악절 또는 다른 구조의 템포, 박자 및 형태를 이용하여 그 출력을 결정한다. 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공되는 다양 한 음악적 경험 디스크립터를 위한 확률 가중 하위 악절 화음 진행 파라미터 테이블 세트를 생성한다. 서브 시 스템에 채택된 확률 기반 파라미터 테이블(즉, 화음 밑음 테이블, 화음 기능 밑음 변조기 테이블 및 비트 밑음 변조기 테이블)은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복을 위해 설립되어 본 발명의 자동화된 음 악 작곡 및 생성 프로세스 중에 사용된다. 도 48a 및 도 48b에 나타낸 바와 같이, 서브 시스템(B19)은 서브 시스템(B51)에 의해 생성되어 로드된 화음 밑 음 테이블에 액세스하고, 난수 발생기 또는 적당한 파라미터 선택 메커니즘을 이용하여, 조각의 제1 화음을 선 택한다. 예컨대, 제1 하위 악절 화음이 C 메이저인 C 메이저의 \"행복\" 음악 조각에는, 다음 화음이 C 메이저 삼 화음일 1/3의 확률, 다음 화음이 G 메이저 삼화음일 1/3의 확률, 및 다음 화음이 F 메이저 삼화음일 1/3의 확률 이 있을 수 있다. 이 모델은 선택되고 있는 각 화음의 확률을 결정하기 위해 모든 가능한 이전의 결과와 모든 가능한 미래의 결과를 고려한다. 이 프로세스는 각 하위 악절의 시작부터 각 하위 악절의 끝까지 반복한다. 도 48b 및 도 48c에 나타낸 바와 같이, 서브 시스템(B19)은 서브 시스템에 로드된 화음 기능 변조기 테이블에 액세스하여, 화음 밑음 테이블의 오리지널 밑음 음표 칼럼 값에 값을 가산하거나 감산한다. 그리고, 도 48b 및 도 48c에 나타낸 바와 같이, 서브 시스템(B19)은 도시된 바와 같이 서브 시스템(B19)에 로드 된 비트 밑음 변조기 테이블에 액세스하고, 비트 분석기를 사용함으로써 조각, 섹션, 악절 또는 다른 구조의 템 포, 박자 및 형태를 고려하여 현재 또는 미래 음악 이벤트(들)에서의 위치를 결정한 다음, 비트 밑음 분석기를 선택한다. 사례에서, 마디 내의 다음 비트는 2이다. 그리고, 서브 시스템(B19)은 화음 밑음 테이블의 오리지널 밑음 음표 칼럼 값에 대해 비트 밑음 변조기 테이블 값을 가산하거나 감산한다. 도 48c에 나타낸 바와 같이, 난수 발생기 또는 다른 파라미터 선택 메커니즘을 이용하여, 서브 시스템(B19)은 다음 화음 밑음을 선택한다. 화음 기능 밑음 변조기 테이블로 시작하여, 전술한 프로세스는 모든 화음이 선택될 때까지 반복된다. 도 48c에 나타낸 바와 같이, 하위 악절 화음 진행 생성 서브 시스템(B19)에 의해 자동으로 선택된 화음은 작곡 되고 있는 음악 조각에 대한 음악 스코어 표현에 그래픽으로 표시된다. 악절 화음 진행 생성 서브 시스템(B18)의 사양 도 49는 본 발명의 자동화된 음악 작곡 및 생성 엔진 및 시스템에서 사용되는 악절 화음 진행 생성 서브 시스템 (B18)을 나타낸다. 화음, 2개 이상(일반적으로 적어도 3개)의 음표의 동시 음향은 모든 음악 조각의 기본적인 구성 요소이다. 악절 화음 진행 생성 서브 시스템(B18)은 제1 화음 또는 음표(들)를 제외하고 음악 조각의 각 악절의 화음을 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 일반적으로, 악절 화음 진행이 하위 악절 분석기를 이용하여 결정되어, 개선된 악절이 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용됨으로써, 도면의 하단에 도시된 음악 스코어 표현에 도시된 바와 같이 작곡되고 있는 음악 조각의 일부를 생성한다. 도 49에 나타낸 바와 같이, 악절 화음 진행 생성 서브 시스템(B18)은 하위 악절 (길이) 분석기에 의해 지원된다. 하위 악절 (길이) 분석기의 주요 기능은 현재 또는 미래 음악 이벤트(들)에서의 위치를 결정하는 것 이다. 비트 분석기는 조각, 섹션, 악절 또는 다른 구조의 템포, 박자 및 형태를 이용하여 그 출력을 결정한다. 작동 중에, 악절 화음 진행 생성 서브 시스템(B18)은 제1 화음 생성 서브 시스템(B17)으로부터 출력을 수신하여, 각 하위 악절로부터의 화음을 변조, 변경, 추가 및 삭제함으로써, 각 악절의 화음을 생성한다. 예컨 대, 악절이 동일한 화음 진행을 각각 포함한 2개의 하위 악절로 구성되는 경우, 제2 하위 악절 내의 제1 화음이 더 많은 음악 화음 진행을 생성하기 위해 (서브 시스템(B51)에 의해 생성되어 로드된 데이터 세트 또는 파라미 터 테이블을 추종하여) 변경될 1/2의 확률과 하위 악절 화음 진행이 변하지 않고 유지될 1/2의 확률이 있을 수 있다. 화음 자리바꿈 생성 서브 시스템(B20)의 사양 도 50a, 도 50b 및 도 50c은 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 화음 자리바꿈 생성 서 브 시스템(B20)을 나타낸다. 화음 자리바꿈 생성 서브 시스템(B20)은 음악 조각 내의 각 화음의 자리바꿈을 결 정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기 초하게 된다. 자리바꿈, 화음 또는 음표 위치는 모든 음악 조각의 기본적인 구성 요소이다. 화음 자리바꿈은 제 1 화음 자리바꿈 테이블 및 화음 자리바꿈 테이블을 사용하여 결정된다. 도 50a 및 도 50b에 나타낸 바와 같이, 이 서브 시스템(B20)은 제1 화음 자리바꿈 테이블과 도 28k에 나타낸 화 음 자리바꿈 테이블, 및 파라미터 선택 메커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공되는 다양 한 음악적 경험 디스크립터를 위한 확률 가중 화음 자리바꿈 파라미터 테이블 세트를 생성한다. 도 50a 내지 도 50c에서, 서브 시스템에 채택된 확률 기반 파라미터 테이블(즉, 제1 화음 자리바꿈 테이블 및 화음 자리바꿈 테 이블)은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복을 위해 설립된다. 도 50a 및 도 50b에 나타낸 바와 같이, 서브 시스템(B20)은 서브 시스템(B19)으로부터의 출력을 입력으로서 수 신하고, 제1 화음 자리바꿈 테이블과 서브 시스템(B51)에 의해 로드되고 도 28k에 나타낸 화음 자리바꿈 테이블 에 액세스한다. 서브 시스템(B20)은 난수 발생기 또는 다른 파라미터 선택 메커니즘을 이용하여 조각 내의 각 화음의 제1 자리바꿈을 결정한다. 예컨대, C 메이저 삼화음이 밑음 위치에 있고(C, E, G) 다음 화음이 G 메이저 삼화음인 경우, G 메이저 삼화음 이 밑음 위치에 있을 1/3의 확률, G 메이저 삼화음이 제1 자리바꿈에 있을 1/3의 확률(E, G, C), 또는 G 메이저 삼화음이 제2 자리바꿈에 있을 1/3의 확률(E, C, E)이 있을 수 있다. 도 50c에 나타낸 바와 같이, 제1 화음의 자리바꿈이 결정된 후, 모든 화음 자리바꿈이 선택될 때까지 화음 자리 바꿈 선택 프로세스가 반복된다. 모든 이전의 자리바꿈 결정은 모든 미래의 자리바꿈 결정에 영향을 미친다. 음악 조각, 악절, 하위 악절 및 마디에서의 다음 화음 자리바꿈은 화음 자리바꿈이 미래에 선택될 수 있는 디폴트 랜드스케이프에 영향을 미친다. 도 50c에 나타낸 바와 같이, 자리바꿈된 화음의 최종 목록이 도 50c의 하단에 배치된 음악 스코어 표현에 그래 픽으로 표시된다. 멜로디 하위 악절 길이 생성 서브 시스템(B25)의 사양 도 51는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 멜로디 하위 악절 길이 생성 서브 시스템 (B25)을 나타낸다. 리듬, 또는 규정된 반복가능한 패턴으로의 시간의 공간의 분할 또는 시간 내에서 음악의 제 어된 움직임은 모든 음악 조각의 기본적인 구성 요소이다. 멜로디 하위 악절 길이 생성 서브 시스템(B25)은 음 악 조각 내의 각 멜로디 하위 악절의 길이 또는 리듬을 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴 퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 도 51에 나타낸 바와 같이, 이 서브 시스템(B25)은 도 77m에 나타낸 멜로디 길이 테이블과, 파라미터 선택 메커 니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공되는 다양 한 음악적 경험 디스크립터를 위한 하위 악절 길이의 확률 가중 데이터 세트(즉, 파라미터 테이블)를 생성한다. 도 51에서, 서브 시스템에 채택된 확률 기반 파라미터 프로그래밍 테이블은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복을 위해 설립되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 작동 중에, 서브 시스템(B25)는 각 하위 악절 멜로디의 길이를 결정하기 위해 서브 시스템(B51)에 의해 로드된 멜로디 길이 파라미터 테이블과 함께 이전의 모든 특이 하위 악절 길이 출력을 입력으로서 사용한다. 도 51에 나타낸 바와 같이, 서브 시스템(B25)은 난수 발생기 또는 다른 파라미터 선택 메커니즘을 이용하여 작 곡되고 있는 음악 조각 내의 각 하위 악절을 위한 멜로디 길이를 선택한다. 예컨대, 5초의 하위 악절에서는, 전 체 하위 악절에 걸쳐 이 하위 악절로 멜로디가 발생할 1/2의 확률과 이 하위 악절로 멜로디가 전혀 발생하지 않 을 1/2의 확률이 있을 수 있다. 나타낸 바와 같이, 각 하위 악절(a, b 및 c)에 대한 프로세스에서 멜로디 길이 선택 프로세스가 실행된다. 사례에 나타낸 바와 같이, 서브 시스템(B25)의 출력은 작곡되고 있는 음악에 대한 멜로디 길이 할당 세트이다: 즉, a 하위 악절에는 6/4인 \"d\" 길이가 할당되고; b 하위 악절에는 7/4인 \"e\" 길이가 할당되며; 및 c 하위 악절 에는 6/4인 \"f\" 길이가 할당된다. 멜로디 하위 악절 생성 서브 시스템(B24)의 사양 도 52a 및 도 52b는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 멜로디 하위 악절 생성 서브 시 스템(B24)을 나타낸다. 멜로디, 또는 음악적 형상을 달성하도록 배열된 모드, 리듬 및 피치로 구성된 음색의 연 속은 모든 음악 조각의 기본적인 구성 요소이다. 멜로디 하위 악절 생성 서브 시스템은 음악 조각의 멜로디 내 에 얼마나 많은 멜로디 하위 악절이 있는지를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결 정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 도 52a 및 도 52b에 나타낸 바와 같이, 멜로디 하위 악절 생성 서브 시스템(B24)은 도 77n에 나타낸 하위 악절 배치 테이블 및 전술한 바와 같은 파라미터 선택 메커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공되는 다양 한 음악적 경험 디스크립터를 위한 확률 가중 멜로디 하위 악절 길이 파라미터 테이블 세트를 생성한다. 도 52a 에서, 서브 시스템(B24)에 채택된 확률 기반 파라미터 테이블은 예시적인 \"감정 타입\" 음악적 경험 디스크립터- 행복을 위해 설립되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 52a 및 도 52b에 나타낸 바와 같이, 각 하위 악절 멜로디(d, e 및 f)를 위해, 멜로디 하위 악절 생성 서브 시스템(B24)은 하위 악절 멜로디 배치 테이블에 액세스하여, 및 전술한 난수 발생기 또는 다른 파라미터 선택 메커니즘을 이용하여 하위 악절 멜로디 배치를 선택한다. 사례에 나타낸 바와 같이, 서브 시스템(B24)은, 3개의 5초 하위 악절로 각각 구성된 2개의 악절을 가진 30초 길 이의 조각에서, 각각의 하위 악절이 B25에서 결정된 바와 같은 특정 길이의 멜로디를 포함할 수 있을 1/2의 확 률을 가진 테이블 파라미터를 선택할 수 있다. 이 경우, 모든 3개의 하위 악절의 멜로디 길이가 제1 악절의 멜로디 길이에 포함될 수 있을 1/2의 확률과 3개의 하위 악절 중 오직 1개의 총 멜로디 길이가 제1 악절의 총 멜 로디 길이에 포함될 수 있을 1/2의 확률이 존재한다. 도 52a 및 도 52b에 나타낸 바와 같이, 하위 악절 멜로디 길이(d)가 3개의 사분음표로 하위 악절을 시작하고, 하위 악절 멜로디 길이(e)가 2개의 사분음표로 하위 악절을 시작하며, 하위 악절 멜로디 길이(f)가 3개의 사분 음표로 하위 악절을 시작하도록, 서브 시스템(B24)은 파라미터 테이블로부터 선택한다. 하위 악절의 이 시작 위 치들은 멜로디 하위 악절 생성 서브 시스템(B24)의 출력이며, 본 발명의 자동화된 음악 작곡 프로세스에 의해 작곡되고 있는 음악 조각을 위해 도 52b의 하단에 개시된 음악 스코어 표현의 제1 보표에 도시되어 있다. 멜로디 악절 길이 생성 서브 시스템(B23)의 사양 도 53는 본 발명의 자동화된 음악 작곡 및 생성 엔진(E1) 및 시스템에서 사용되는 멜로디 악절 길이 생성 서브 시스템(B23)을 나타낸다. 멜로디, 또는 음악적 형상을 달성하도록 배열된 모드, 리듬 및 피치로 구성된 음색의 연속은 모든 음악 조각의 기본적인 구성 요소이다. 멜로디 악절 길이 생성 서브 시스템(B23)은 음악 조각의 각 멜로디 악절의 길이 또는 리듬을 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 도출된 멜로디의 악절 길이는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 53에 도시된 바와 같이, 멜로디 악절 길이 생성 서브 시스템(B23)은 하위 악절 멜로디 분석기에 의해 지원된 다. 하위 악절 멜로디 분석기의 주요 기능은 음악 조각의 중요한 구성 요소를 변경함으로써 악절 멜로디를 개선 하기 위해 변경된 하위 악절 구조(들)를 결정하는 것이다. 하위 악절 멜로디 분석기는 음악 조각, 섹션, 악절 또는 추가적인 세그먼트(들)의 멜로디, 하모니 및 시간 기반 구조(들)를 고려하여 그 출력을 결정한다. 악절 멜 로디는 그들이 존재하는 리듬, 하모니 및 전체적인 음악적 맥락을 검토하고, 그들의 맥락에 더 잘 맞게 그들을 바꾸거나 조정함으로써 변경된다. 도 53에 나타낸 바와 같이, 멜로디 악절 길이 생성 서브 시스템(B23)은 서브 시스템(B24)의 출력을 더 큰 악절 수준의 멜로디 재료로 변환한다. 서브 시스템(B51)에 의해 로드된 데이터 세트 및 테이블과 함께 이전의 모든 악절과 하위 악절 출력을 이용하여, 이 서브 시스템(B23)은 길이가 30초이고 3개의 10초 악절을 가진 멜로디 조 각을 제작하는 능력이 있으며, 각각의 악절은 서브 시스템(B24)에서 결정된 바와 같은 특정 길이의 멜로디를 포 함할 수 있다. 3개의 모든 악절의 3개의 모든 멜로디 길이가 조각의 멜로디 길이에 포함될 수 있거나, 3개의 악 절의 총 멜로디 길이의 오직 하나만 조각의 총 멜로디 길이에 포함될 수 있다. 본 발명의 시스템(즉, 자동화된 음악 작곡 및 생성 기계)에 의해 작곡되고 있는 음악 조각의 악절 및 하위 악절 구조를 생성하기 위해 사용되는 문법에 의해서만 제약을 받는 많은 가능한 변형이 멜로디 악절 구조에 있다. 도 53에 나타낸 바와 같이, 멜로디 악절 길이 생성 서브 시스템(B23)은, 사례의 경우, 각각의 멜로디 하위 악절 (d, e 및 f)에 대해, 멜로디가 본 발명의 자동화된 시스템에 의해 작곡되고 있는 음악 조각을 위해 더 큰 악절 수준의 음악 재료 조각을 형성하기 시작할 때, 하위 악절로 (i) 멜로디 악절 길이 및 (ii) 사분음표의 수를 출 력한다. 그리고, 도출된 멜로디 악절 길이는 도 53의 하단에 도시된 음악 스코어 표현의 제1 보표에 도시된 바와 같이 작곡되고 있는 음악 조각을 생성하기 위해 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 멜로디 특이 악절 생성 서브 시스템(B22)의 사양 도 54는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 멜로디 특이 악절 생성 서브 시스템(B22)을 나타낸다. 멜로디, 또는 음악적 형상을 달성하도록 배열된 모드, 리듬 및 피치로 구성된 음색의 연속은 모든 음 악 조각의 기본적인 구성 요소이다. 멜로디 특이 악절 생성 서브 시스템은 음악 조각 내에 얼마나 많은 특이 멜 로디 악절이 포함될 것인지를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 특이 멜로디 악절은 특이 멜로디 악절 분석기를 이용하여 결정된다. 이 프로세스는 이전의 모든 악절 및 하위 악절 서브 시스템의 출력을 수득하여, 조각을 위해 얼마나 많은 특이 멜로디 악절을 생성할 필요가 있는지를 결정할 때, 서브 시스템(B21)이 작동하기 위해 필요한 음악적 및 비음악적 데이터를 생성한다. 도 54에 나타낸 바와 같이, 멜로디 특이 악절 생성 서브 시스템(B22)은 특이 멜로디 악절 분석기에 의해 지원되 며, 이는 조각, 섹션, 악절 또는 다른 음악 구조에서 멜로디 또는 다른 음악 이벤트의 \"특이한\" 경우를 결정 및 식별하기 위해 음악 조각 내의 멜로디(들) 및 다른 음악 이벤트를 이용한다. 특이 멜로디 악절은 다른 멜로디악절과 상이한 것이다. 특이 멜로디 악절 분석기는 그 데이터 출력을 위한 특이 멜로디 악절을 결정하기 위해 음악 조각의 조각, 섹션, 악절 또는 다른 구조의 멜로디 및 다른 음악 이벤트를 모두 비교한다. 도 54에 나타낸 바와 같이, 서브 시스템(B22)은 특이 멜로디 악절 분석기를 이용하여, 서브 시스템(B22)의 입력 포트에 제공되는 멜로디 악절(d, e 및 f) 내의 멜로디 또는 다른 음악 이벤트의 특이한 경우를 결정 및 식별한 다. 도 54에 나타낸 바와 같이, 멜로디 특이 악절 생성 서브 시스템(B22)으로부터의 출력은 2개의 특이 멜로디 악절 이다. 그리고, 도출된 특이 멜로디 악절은 본 발명의 자동화된 음악 작곡 및 생성 프로세스의 후속 단계 중에 사용된 다. 멜로디 길이 생성 서브 시스템(B21)의 사양 도 55는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 멜로디 길이 생성 서브 시스템(B21)을 나타 낸다. 멜로디, 또는 음악적 형상을 달성하도록 배열된 모드, 리듬 및 피치로 구성된 음색의 연속은 모든 음악 조각의 기본적인 구성 요소이다. 멜로디 길이 생성 서브 시스템은 음악 조각 내의 멜로디 길이를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 멜로디 길이는 악절 멜로디 분석기를 이용하여 결정된다. 도 55에 나타낸 바와 같이, 멜로디 길이 생성 서브 시스템(B21)은 악절 멜로디 분석기에 의해 지원되며, 음악 조각의 중요한 구성 요소를 변경함으로써 조각 멜로디를 개선하기 위해 변경된 악절 구조(들)를 결정한다. 일반 적으로, 개선된 조각 멜로디를 생성하기 위해 모든 악절이 변경될 수 있다. 악절 멜로디 분석기는 음악 조각, 섹션, 악절 또는 추가적인 세그먼트(들)의 멜로디, 하모니(화음) 및 시간 기반 구조(들)를 고려하여 그 출력을 결정한다. 예컨대, 악절 멜로디 분석기는 30초의 음악 조각이 6개의 5초 하위 악절과, 각각 2개의 하위 악절로 구성된 3개의 10초 악절을 갖는다고 결정할 수 있다. 대안적으로, 악절 멜로디 분석기는 멜로디가 30초이며 2회 이상 발생한다고 결정할 수 있다. 도 55에 나타낸 바와 같이, 서브 시스템(B21)은 악절 멜로디 분석기를 이용하여, 도 55에 도시된 음악 스코어 표현에 나타낸 바와 같이, 새로운 악절 멜로디(d, d+e 및 e)를 형성하기 위해, 멜로디 악절(d 및 e) 내에 변경 된 악절 구조를 가진 악절 멜로디를 결정 및 식별한다. 그리고, 도출된 악절 멜로디는 도 55의 프로세스 도면의 하단에 도시된 음악 스코어 표현의 제1 보표에 도시된 바와 같이 작곡되고 있는 음악 조각의 대부분을 생성하기 위해 자동화된 음악 작곡 및 생성 프로세스 중에 사용 된다. 멜로디 음표 리듬 생성 서브 시스템(B26)의 사양 도 56a, 도 56b 및 도 56c은 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 멜로디 음표 리듬 생성 서브 시스템(B26)을 나타낸다. 리듬, 또는 규정된 반복가능한 패턴으로의 시간의 공간의 분할 또는 시간 내에서 음악의 제어된 움직임은 모든 음악 조각의 기본적인 구성 요소이다. 멜로디 음표 리듬 생성 서브 시스템은 음악 조각을 위한 디폴트 멜로디 음표 리듬(들)이 무엇이 될 것인가를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 도 56a, 도 56b 및 도 56c에 나타낸 바와 같이, 멜로디 음표 리듬 생성 서브 시스템(B26)은 제1 음표 길이 파라 미터 테이블, 도 77o에 나타낸 제1 및 제2 화음 길이 파라미터 테이블, 및 전술한 바와 같은 파라미터 선택 메 커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공되는 다양 한 음악적 경험 디스크립터를 위한 확률 가중 파라미터 테이블 세트를 생성한다. 도 56a, 도 56b 및 도 56c에 나타낸 바와 같이, 서브 시스템에 채택된 확률 기반 파라미터 프로그래밍 테이블은 예시적인 \"감정 타입\" 음악 적 경험 디스크립터-행복을 위해 설립되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 56a 내지 도 56c에 나타낸 바와 같이, 서브 시스템(B26)은 서브 시스템(B51, B40 및 B41)에 의해 로드된 파 라미터 테이블을 이용하여, 멜로디를 위한 제1 리듬을 선택하고 조각 내의 멜로디(또는 멜로디들)를 위한 전체 리듬 재료를 생성한다. 예컨대, 4/4 박자이며 길이가 한 마디인 멜로디에서는, 제1 리듬이 2비트 동안 지속될수 있고, 이 정보에 기초하여, 다음 화음이 1비트 동안 지속될 수 있으며, 이 정보에 기초하여, 마디 내의 마지 막 화음이 1비트 동안 지속될 수 있는 1/3의 확률이 있을 수 있다. 제1 화음이 1비트 동안 지속될 수도 있으며, 이 정보에 기초하여, 다음 화음이 3비트 동안 지속될 수 있다. 이 프로세스는 조각의 전체 멜로디 재료가 리드 미컬하게 생성될 때까지 계속되며, 각 리듬에 피치 재료가 할당되기를 대기하고 있다. 특히, 각 멜로디 음표의 리듬은 이전의 모든 멜로디 음표의 리듬; 동일한 마디, 악절 및 하위 악절 내의 다른 멜로디 음표의 리듬; 및 미래에 발생할 수 있는 멜로디 음표의 멜로디 리듬에 의존한다. 제2 멜로디 음표의 리 듬이 제1 멜로디 음표의 리듬에 의해 영향을 받고, 제3 멜로디 음표의 리듬이 제1 및 제2 멜로디 음표의 리듬에 의해 영향을 받도록 하는 식으로, 특정 멜로디 음표의 리듬에 대한 결정에 각각의 선행하는 멜로디 음표 리듬 결정 인자가 고려된다. 도 56a 내지 도 56c에 나타낸 바와 같이, 서브 시스템(B26)은 자동화된 음악 작곡 및 생성 기계에 의해 작곡되 고 있는 조각 내의 (i) 멜로디를 위한 제1 리듬을 생성하고, (ii) 멜로디(또는 멜로디들)를 위한 전체 리듬 재 료를 선택하는 다단계 프로세스를 관리한다. 도 56a 및 도 56b에 나타낸 바와 같이, 이 프로세스는 난수 발생기를 채택하여 그 결과를 관련 확률 테이블에 매핑함으로써 제1 음표 길이(즉, 음표 리듬)를 선택하는 단계를 포함한다. 제1 단계 중에, 서브 시스템(B26)은 서브 시스템에 로드되어 있는 제1 음표 길이 테이블로부터 멜로디 악절(d)의 제1 음표 길이를 선택하기 위해, (전술한 바와 같은) 난수 발생기 또는 전술한 다른 파라미터 선택 메커니즘을 이용한다. 그리고, 도 56b 및 도 56c에 나타낸 바와 같이, 서브 시스템(B26)은 동일한 방법과 제1 및 제2 화음 길이 파라미터 테이블을 이용하여 멜로디 악절(d)의 제2 음표 길이를 선택한 다음, 제3 화음 음표 길이를 선택한다. 프로세스는 멜로디 악절 길이 (d)가 사분음표로 채워질 때까지 계속된다. 이 프로세스는 매우 상세하게 후술된다. 도 56b에 나타낸 바와 같이, 제1 음표 길이 프로세스의 결과와 일치하는 테이블의 칼럼을 먼저 선택한 다음, 난 수 발생기를 채택하여 그 결과를 관련 확률 테이블에 매핑함으로써 제2 음표 길이가 선택된다. 제2 단계 중에, 서브 시스템(B26)은 멜로디가 시작할 때까지 멜로디 하위 악절(d-e)로 음표를 삽입하기 시작하며, 프로세스는 멜로디 악절(d-e)이 음표로 채워질 때까지 계속된다. 도 56c에 나타낸 바와 같이, 제1 및 제2 음표 길이 프로세스의 결과와 일치하는 테이블의 칼럼을 먼저 선택한 다음, 난수 발생기를 채택하여 그 결과를 관련 확률 테이블에 매핑함으로써 제3 음표 길이가 선택된다. 멜로디 악절(d-e)이 음표로 채워지면, 서브 시스템(B26)은 마지막 단계 중에 멜로디 악절(e)로 음표를 채우기 시작하며, 프로세스는 멜로디 악절(e)이 음표로 채워질 때까지 계속된다. 그리고, 도 56a 내지 도 56c에 나타낸 바와 같이, 서브 시스템(B26)은 채워진 악절 길이(d, d-e 및 e)로부터 조 각 멜로디 리듬을 선택한다. 그리고, 도출된 조각 멜로디 리듬은 본 발명의 자동화된 음악 작곡 및 생성 프로세 스 중에 사용하기 위해 준비되며, 도 56c의 하단에 도시된 음악 스코어 표현의 제1 보표에 도시되어 있다. 제1 피치 생성 서브 시스템(B27)의 사양 도 57는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 제1 피치 생성 서브 시스템(B27)을 나타낸다. 피치, 또는 소리를 인식가능한 음색으로 만드는 소리의 특정 품질은 모든 음악 조각의 기본적인 구성 요소이다. 제1 피치 생성 서브 시스템은 음악 조각을 위한 멜로디의 제1 피치가 무엇이 될 것인가를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 도 57에 나타낸 바와 같이, 제1 피치 생성 서브 시스템(B27)은 도 77p에 나타낸 제1 멜로디 파라미터 테이블과, 전술한 바와 같은 파라미터 선택 메커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공되는 다양 한 음악적 경험 디스크립터를 위한 확률 가중 제1 피치 데이터 세트(즉, 파라미터 테이블)를 생성한다. 도 57에 서, 서브 시스템에 채택된 확률 기반 파라미터 프로그래밍 테이블(예컨대, 제1 피치 테이블)은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복을 위해 설립되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사 용된다. 일반적으로, 제1 피치 생성 서브 시스템(B27)은 조각 내의 멜로디(또는 멜로디들)를 위한 제1 피치를 선택하기 위해 서브 시스템(B51)에 로드된 파라미터 테이블뿐만 아니라 다른 서브 시스템(B26)으로부터의 데이터 출력을이용한다. 예컨대, C 메이저의 \"행복\" 음악 조각에는, 제1 피치가 \"C\"일 1/3의 확률, 제1 피치가 \"G\"일 1/3의 확률, 및 제1 피치가 \"F\"일 1/3의 확률이 있을 수 있다. 도 57에 나타낸 바와 같이, 서브 시스템(B27)은 서브 시스템 내에 로드된 제1 멜로디 테이블로부터 제1 멜로디 음표를 선택하기 위해 전술한 바와 같이 난수 발생기 또는 다른 파라미터 선택 메커니즘을 이용한다. 사례에서 는, 제1 멜로디 음표 = 7이 서브 시스템(B27)에 의해 테이블로부터 선택되었다. 도 57에 나타낸 바와 같이, 멜로디를 위해 선택된 제1 피치(즉, 제1 멜로디 음표)는 도 57에 나타낸 프로세스 도면의 하단에 도시된 음악 스코어 표현의 제1 보표에 도시된 바와 같이 작곡되고 있는 음악 조각의 일부를 생 성하기 위해 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 하위 악절 피치 생성 서브 시스템(B29)의 사양 도 58a, 도 58b 및 도 58c은 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 하위 악절 피치 생성 서 브 시스템(B29)의 개략도를 나타낸다. 하위 악절 피치 생성 서브 시스템(B29)은 음악 조각의 하위 악절 피치를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 피치, 또는 소리를 인식가능한 음색으로 만드는 소리의 특정 품질은 모든 음악 조각의 기본적인 구성 요소이다. 도 58a, 도 58b 및 도 58c에 나타낸 바와 같이, 하위 악절 피치 생성 서브 시스템(B29)은 멜로디 음표 테이블, 화음 변조기 테이블, 도약 자리바꿈 변조기 테이블 및 도 77q, 도 77r 및 도 77s에 나타낸 도약 유발 변조기 테 이블과, 상세하게 전술한 바와 같은 파라미터 선택 메커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미 터 선택기)에 의해 지원된다. 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공되는 다양 한 음악적 경험 디스크립터를 위한 확률 가중 파라미터 테이블 데이터 세트를 생성한다. 도 58a에 나타낸 바와 같이, 서브 시스템(B29)에 채택된 확률 기반 파라미터 프로그래밍 테이블은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복을 위해 설립되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 이 서브 시스템(B29)은 조각의 하위 악절 내의 멜로디(또는 멜로디들)를 위한 피치 재료를 생성하기 위해 서브 시스템(B51)에 의해 로드된 파라미터 테이블뿐만 아니라 이전 서브 시스템을 이용한다. 예컨대, (1비트 동안) 제1 피치가 \"C\"이고 4/4 박자이며 길이가 한 마디인 멜로디에서는, 다음 피치가 (1비트 동안) \"C\"일 수 있고, 이 정보에 기초하여, 다음 피치가 (1비트 동안) \"D\"일 수 있으며, 이 정보에 기초하여, 마디 내의 마지막 피치가 (1비트 동안) \"E\"일 수 있는 1/3의 확률이 있을 수 있다. 하위 악절의 각 피치는 이전 의 모든 음표의 피치; 동일한 마디, 악절 및 하위 악절 내의 다른 음표의 피치; 및 미래에 발생할 수 있는 음표 의 피치에 의존한다. 제2 음표의 피치가 제1 음표의 피치에 의해 영향을 받고, 제3 음표의 피치가 제1 및 제2 음표의 피치에 의해 영향을 받도록 하는 식으로, 특정 음표의 피치에 대한 결정에 각각의 선행하는 피치 결정 인자가 고려된다. 또한, 선택되는 피치의 근간이 되는 화음은 가능한 피치 옵션의 랜드스케이프에 영향을 미친 다. 예컨대, 다른 화음이 발생하는 시간 동안보다, 음표(C E G)로 구성된 C 메이저 화음이 발생하는 시간 동안 에, 음표 피치가 이 화음으로부터 음표를 선택할 가능성이 보다 높을 것이다. 또한, 음표의 피치는 단계적으로 계속하기보다는 오름차순 또는 내림차순 경로 중 하나로부터 방향을 변경하고 하나의 음표에서 다른 음표로 도 약하도록 권장된다. 서브 시스템(B29)은 이와 같은 고급 피치 재료 생성 기능을 수행하도록 작동한다. 도 58a, 도 58b 및 도 58c에 나타낸 바와 같이, 서브 시스템(B29)은 각 하위 악절 내의 멜로디 음표 파라미터 테이블로부터 음표(즉, 피치 이벤트)를 선택하여 작곡되고 있는 음악 조각을 위한 하위 악절 멜로디를 생성하기 위해 전술한 바와 같은 난수 발생기 또는 다른 적당한 파라미터 선택 메커니즘을 이용한다. 도 58a 및 도 58b에 나타낸 바와 같이, 서브 시스템(B29)은 멜로디 음표가 선택됨과 동시에 어떤 화음이 발생하 는지에 기초하여 멜로디 음표 테이블에서 확률을 변경하기 위해 화음 변조기 테이블을 이용한다. 멜로디 음표 테이블의 상단 행은 기본 코드의 밑음 음표를 나타내며, 좌측 열의 3 문자 약어는 화음 조성을 나타내고, 이 2 개의 명칭이 교차하는 셀은 변경될 피치 클래스를 나타내며, 확률 변화 열은 멜로디 음표 테이블에서 피치 클래 스가 변경되는 양을 나타낸다. 도 58b 및 도 58c에 나타낸 바와 같이, 서브 시스템(B29)은 이전 음표(들) 사이의 (반음에서 측정된) 거리에 기 초하여 멜로디 음표 테이블에서 확률을 변경하기 위해 도약 자리바꿈 변조기 테이블을 이용한다. 도 58b 및 도 58c에 나타낸 바와 같이, 서브 시스템(B29)은 이전 음표(들) 사이의 (반음에서 측정된) 거리와 이 거리가 발생한 시간프레임에 기초하여 멜로디 음표 테이블에서 확률을 변경하기 위해 도약 유발 변조기 테이블 을 이용한다. 음악 조각을 위해 도출된 하위 악절 피치(즉, 음표)는 도 58c에 개시된 프로세스 도면의 하단에 도시된 음악 스 코어 표현의 제1 보표에 도시된 바와 같이 작곡되고 있는 음악 조각의 일부를 생성하기 위해 자동화된 음악 작 곡 및 생성 프로세스 중에 사용된다. 악절 피치 생성 서브 시스템(B28)의 사양 도 59는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 악절 피치 생성 서브 시스템(B28)을 나타낸 다. 피치, 또는 소리를 인식가능한 음색으로 만드는 소리의 특정 품질은 모든 음악 조각의 기본적인 구성 요소 이다. 악절 피치 생성 서브 시스템(B28)은 제1 피치(들)를 제외하고 음악 조각 내의 멜로디의 피치를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 도 59에 나타낸 바와 같이, 이 서브 시스템은 하위 악절 멜로디 분석기와, 파라미터 선택 메커니즘(예컨대, 난 수 발생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 하위 악절 멜로디 분석기의 주요 기능은 음악 조각의 중요한 구성 요소를 변경하기 위해 변경된 하위 악절 구조 (들)를 결정하는 것이다. 하위 악절 멜로디 분석기는 음악 조각, 섹션, 악절 또는 추가적인 세그먼트(들)의 멜 로디, 하모니 및 시간 기반 구조(들)를 고려하여 그 출력을 결정한다. 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공되는 다양 한 음악적 경험 디스크립터를 위한 확률 가중 멜로디 음표 리듬 파라미터 테이블 세트를 생성한다. 도 59에 나 타낸 바와 같이, 서브 시스템(B29)에 채택된 확률 기반 파라미터 테이블은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복을 위해 설립되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 악절 피치 생성 서브 시스템(B28)은 하위 악절 멜로디 분석기를 이용하여 B29의 출력을 더 큰 악절 수준의 멜로 디 재료로 변환한다. 하위 악절 멜로디 분석기의 주요 기능은 멜로디(들) 또는 다른 멜로디 재료의 기능성과 가 능한 도출을 결정하는 것이다. 멜로디 하위 악절 분석기는 음악 조각의 조각, 섹션, 악절 또는 다른 길이의 템 포, 박자, 형태, 화음(들), 하모니(들) 및 구조를 이용하여 그 출력을 결정한다. 서브 시스템(B51)에 의해 로드된 데이터 세트 및 파라미터 테이블과 함께 이전의 모든 악절과 하위 악절 출력을 이용하여, 이 서브 시스템(B28)은, 2개의 동일한 하위 악절로 구성된 멜로디에서, 더 음악적인 악절 수준의 멜 로디를 생성하기 위해 하위 악절 멜로디가 두번째 발생할 때 음표가 변경될 수 있는 1/2의 확률을 생성할 수 있 다. 하위 악절 멜로디는 그들이 존재하는 리듬, 하모니 및 전체적인 음악적 맥락을 검토하고, 그들의 맥락에 더 잘 맞게 그들을 바꾸거나 조정함으로써 변경된다. 이 프로세스는 전체 멜로디 재료의 피치 정보(즉, 음표)가 생성될 때까지 계속된다. 결정된 악절 피치는 도 59 의 프로세스 도면에 개시된 음악 스코어 표현에 도시된 바와 같이 작곡되고 있는 음악 조각의 일부를 생성하기 위해 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 음악 조각을 위해 도출된 악절 피치는 도 59에 개시된 프로세스 도면의 하단에 도시된 음악 스코어 표현의 제1 보표에 도시된 바와 같이 작곡되고 있는 음악 조각의 일부를 생성하기 위해 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 피치 옥타브 생성 서브 시스템(B30)의 사양 도 60a 및 도 60b는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 피치 옥타브 생성 서브 시스템 (B30)의 개략도를 나타낸다. 주파수, 또는 일반적으로 헤르츠(㎐) 단위로 측정되는 음악 피치의 초당 진동수는 모든 음악 조각의 기본적인 구성 요소이다. 피치 옥타브 생성 서브 시스템(B30)은 음악 조각 내의 각 음표 및/ 또는 화음의 옥타브와, 그에 따른 피치의 특정 주파수를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴 퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 도 60a 및 도 60b에 나타낸 바와 같이, 피치 옥타브 생성 서브 시스템(B30)은 도 77t에 도시된 멜로디 음표 옥 타브 테이블 및 전술한 바와 같은 파라미터 선택 메커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공되는 다양 한 음악적 경험 디스크립터를 위한 확률 가중 멜로디 음표 옥타브 파라미터 테이블 세트를 생성한다. 도 60a 및 도 60b에서, 서브 시스템에 채택된 확률 기반 파라미터 테이블은 예시적인 \"감정 타입\" 음악적 경험 디스크립터 -행복을 위해 설립되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 60a 및 도 60b에 나타낸 바와 같이, 멜로디 음표 옥타브 테이블은 로드된 음표 세트와 함께 사용되어, 음악 조각 내의 다른 멜로디 음표 및/또는 하모니 구조에 대한 관계에 기초하여 각 음표의 주파수를 결정한다. 일반 적으로, 조각 내에는 0부터 무한개 직전 사이의 임의의 갯수의 멜로디 음표가 있을 수 있다. 시스템은 음악 작 곡 및 생성 사이클마다 이 갯수를 자동으로 결정한다. 예컨대, 음표 \"C\"의 경우, C가 피아노 키보드 상의 제4 C와 등가일 1/3의 확률, C가 피아노 키보드 상의 제5 C 와 등가일 1/3의 확률, 또는 C가 피아노 키보드 상의 제5 C와 등가일 1/3의 확률이 있을 수 있다. 음악 조각 내의 음표 및 화음의 도출된 피치 주파수는 도 60b에 개시된 프로세스 도면의 하단에 도시된 음악 스 코어 표현의 제1 보표에 도시된 바와 같이 작곡되고 있는 음악 조각의 일부를 생성하기 위해 본 발명의 자동화 된 음악 작곡 및 생성 프로세스 중에 사용된다. 악기 편성 서브 시스템(B38)의 사양 도 61a 및 도 61b는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 악기 편성 서브 시스템(B38)을 나타낸다. 악기 편성 서브 시스템(B38)은 음악 조각에 사용될 수 있는 악기 및 다른 음악 소리 및/또는 장치를 결정한다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 되며, 모든 음악 조각의 기본적인 구성 요소이다. 도 61a 및 도 61b에 나타낸 바와 같이, 이 서브 시스템(B38)은 선택되는 임의의 악기 옵션의 확률을 지원하는 도 77w 및 도 77x에 나타낸 악기 선택 테이블로부터 분리되어 악기의 모든 가능성(즉, 가능한 악기의 목록)을 나타내는 확률 기반이 아닌 평범한 테이블인 도 29q1a 및 도 29q1b에 도시된 악기 테이블에 의해 지원된다. 파라미터 변환 엔진 서브 시스템(B51)은 입력 서브 시스템(B0)에 의해 지원되는 GUI로부터 선택가능한 다양한 \"스타일 타입\" 음악적 경험 디스크립터를 위한 악기 데이터 세트(즉, 파마미터 테이블)를 생성한다. 도 61a 및 도 61b에서, 서브 시스템에 채택된 파라미터 프로그래밍 테이블은 예시적인 \"스타일 타입\" 음악적 경험 디스크 립터-팝을 위해 설립되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 예컨대, 스타일 파라 미터 \"팝\"은 피아노, 어쿠스틱 기타, 일렉트릭 기타, 드럼 키트, 일렉트릭 베이스 및/또는 여성 보컬을 포함하 는 데이터 세트를 로드할 수도 있다. 음악 조각을 위해 선택된 악기 및 다른 음악 소리는 작곡되고 있는 음악 조각의 일부를 생성하기 위해 본 발명 의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 악기 선택기 서브 시스템(B39)의 사양 도 62a 및 도 62b는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 악기 선택기 서브 시스템(B39)을 나타낸다. 악기 선택기 서브 시스템(B39)은 음악 조각에 사용될 악기 및 다른 음악 소리 및/또는 장치를 결정한 다. 이 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하 게 되며, 모든 음악 조각의 기본적인 구성 요소이다. 도 62a 및 도 62b에 나타낸 바와 같이, 악기 선택기 서브 시스템(B39)은 도 77w 및 도 77x에 나타낸 악기 선택 테이블 및 파라미터 선택 메커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된 다. 악기 선택기 서브 시스템(B39)을 이용하여, 다음과 같이 작곡되고 있는 각 음악 조각을 위한 악기가 선택된 다. 악기 선택 테이블 내의 각 악기 그룹은 작곡되고 있는 음악 조각에 참여하기 위해 선택될 특정 확률을 가지 며, 이 확률은 다른 악기 그룹과 무관하다. 각 악기 그룹 내에서, 악기의 각 스타일 및 각 악기는 조각에 참여 하기 위해 선택될 특정 확률을 가지며, 이 확률은 다른 확률과 무관하다. 파라미터 변환 엔진 서브 시스템(B51)은 입력 서브 시스템(B0)으로부터 선택가능한 다양한 음악적 경험 디스크 립터를 위한 확률 가중 악기 선택(즉, 파라미터) 테이블 데이터 세트를 생성한다. 도 62a 및 도 62b에서, 서브 시스템에 채택된 확률 기반 시스템 파라미터 테이블은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복과 \" 스타일 타입\" 음악적 경험 디스크립터-팝을 위해 설립되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중 에 사용된다. 예컨대, 피아노, 어쿠스틱 기타, 일렉트릭 기타, 드럼 키트, 일렉트릭 베이스 및/또는 여성 보컬을 포함하는 데 이터 세트를 가진 스타일 타입 음악적 경험 디스크립터 \"팝\"은 각 악기가 음악 조각에 사용되기 위해 개별적으 로 선택될 2/3의 확률을 가질 수 있다. 감정 및 스타일 디스크립터와 음악을 연주하는 악기 사이에는 강한 관계가 있다. 예컨대, 록 음악 조각은 기타, 드럼 및 키보드를 가질 수 있는 반면, 클래식 음악 조각은 현악기, 목관 악기 및 금관 악기를 가질 수 있다. 따 라서, 시스템 사용자가 스타일로서 록 음악을 선택하면, 악기 선택 테이블은 그와 같은 악기를 가능한 선택으로 서 나타낼 것이다. 음악 조각을 위해 악기 선택기 서브 시스템(B39)에 의해 선택된 악기 및 다른 음악 소리는 작곡되고 있는 음악 조각의 일부를 생성하기 위해 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 오케스트레이션 생성 서브 시스템(B31)의 사양 도 63a 내지 도 63i는 본 발명의 자동화된 음악 작곡 및 생성 엔진(B31)에서 사용되는 오케스트레이션 생성 서 브 시스템(B31)을 나타낸다. 오케스트레이션, 또는 악기 앙상블로 연주하기 위한 음악 조각의 배열은 모든 음악 조각의 기본적인 구성 요소이다. 도 62a의 하단과 아울러 도 63f의 상단에 음악 스코어 표현으로 나타낸 바와 같은 리드 시트(또는 그와 유사한) 표현으로 통상적으로 표시되는 작곡된 음악 조각으로부터, 오케스트레이션 생성 서브 시스템(B31)은 자동화된 음악 작곡 프로세스에 의해 지금까지 자동으로 작곡된 음악 조각으로부터 유 래된, 선택된 악기에 의해 어떤 음악(즉, 음표 또는 피치의 세트)이 연주될 것인지를 결정한다. 각각의 선택된 악기를 위해 편곡 또는 정리된 이 음악은 선택된 악기 그룹에 의한 음악 조각의 오케스트레이션을 결정할 것이다. 도 63a 내지 도 63i에 나타낸 바와 같이, 오케스트레이션 생성 서브 시스템(B31)은 다음의 구성 요소, 즉, (i) 도 78a, 도 78b 및 도 78c에 나타낸 바와 같은 악기 오케스트레이션 우선 순위 결정 테이블, 악기 기능 테이블, 피아노 손 기능 테이블, 피아노 보이싱 테이블, 피아노 리듬 테이블, 제1 피아노 리듬 테이블, 제2 음표 오른손 테이블, 제2 음표 왼손 테이블, 제3 음표 오른손 길이 테이블 및 피아노 강약 테이블; (ii) 도 63c에 도시된 피 아노 음표 분석기, 도 63g에 도시된 시스템 분석기 및 도 63i에 도시된 마스터 오케스트레이션 분석기; 및 (iii) 상세하게 전술한 바와 같은 파라미터 선택 메커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 서브 시스템(B31)에 채택되는 음악 데이터 분석기의 기능을 간략하게 설명하는 것이 도움이 될 것이다. 매우 상세하게 후술하는 바와 같이, 도 63c에 도시된 피아노 음표 분석기의 주요 기능은 피아노에 의해 연주된 임의의 이전 음표와 피아노에 의해 연주될 수 있는 임의의 가능한 미래 음표와 모두 관련하여, 화음의 피치 부 재와 피아노의 각 손의 기능을 분석한 다음, 피아노 상에서 어떤 피치가 각 손에 의해 연주될 수 있는 가능한 음표의 범위 내에 있는지를 결정하는 것이다. 도 63g에 도시된 시스템 분석기의 주요 기능은 악기의 오케스트레이션의 리듬과 피치를 결정 및 조정하여 잠재 적인 오케스트레이션 충돌을 회피, 개선 및/또는 해결하기 위해 작곡된 음악 조각의 조각, 섹션, 악절 또는 다 른 길이의 모든 리듬, 하모니 및 음색 관련 정보를 분석하는 것이다. 또한, 도 63i에 도시된 마스터 오케스트레이션 분석기의 주요 기능은 조각의 오케스트레이션의 리듬과 피치를 결정 및 조정하여 잠재적인 오케스트레이션 충돌을 회피, 개선 및/또는 해결하기 위해 음악 조각의 조각, 섹션, 악절 또는 다른 길이의 모든 리듬, 하모니 및 음색 관련 정보를 분석하는 것이다. 일반적으로, 감정 및 스타일 디스크립터, 음악을 연주하는 악기 및 조각 중에 선택된 악기가 연주하는 음악 사 이에는 강한 관계가 있다. 예컨대, 록 스타일로 편곡된 음악 조각은 클래식 스타일로 편곡된 동일한 음악 조각 과는 완전히 다른 소리를 가질 수 있다. 그러나, 음악 조각의 오케스트레이션은 감정 및 스타일 디스크립터 입 력과 무관할 수 있으며, 단지 타이밍 요청을 수행하기 위해 존재할 수도 있다. 예컨대, 음악 조각이 지금까지의 오케스트레이션과는 무관하게 어느 순간 악센트할 필요가 있는 경우, 심벌즈와 같이 큰 소리로 충돌하는 타악기 가 이 타이밍 요청을 성공적으로 달성할 수 있으며, 사용자 요청에 따른 보다 음악적인 오케스트레이션에 적합 하다. 모든 서브 시스템과 마찬가지로, 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공되는 다양한 음악적 경험 디스크립터를 위해 위에서 확인된 가능한 악기 편성 파라미터 테이블의 확률 가중 세트를 생성한다. 도 63a 내지 도 63i에서, 오케스트레이션 생성 서브 시스템(B51)에 채택 된 확률 기반 파라미터 프로그래밍 테이블(즉, 악기 오케스트레이션 우선 순위 결정 테이블, 악기 에너지 테이 블, 피아노 에너지 테이블, 악기 기능 테이블, 피아노 손 기능 테이블, 피아노 보이싱 테이블, 피아노 리듬 테이블, 제2 음표 오른손 테이블, 제2 음표 왼손 테이블, 피아노 강약 테이블)은 예시적인 \"감정 타입\" 음악적 경 험 디스크립터-행복과 \"스타일 타입\" 디스크립터-팝을 위해 설립되어 본 발명의 자동화된 음악 작곡 및 생성 프 로세스 중에 사용된다. 이 음악적 경험 디스크립터 정보는 (주어진 경우에) 사용자 입력, 컴퓨터로 결정된 값 (들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 도 63a 및 도 63b에 도시된 바와 같이, 서브 시스템(B37, B38 및 B39)으로부터의 입력에 기초하여, 오케스트레 이션 생성 서브 시스템(B51)은 난수 발생기 또는 다른 파라미터 선택 메커니즘을 이용하여, 이 조각에 사용될 특정 스타일의 음악 카테고리 내에 있는 악기의 특정 개수와 이들이 편성될 특정 순서를 결정할 수 있다. 예컨 대, 팝 스타일로 작곡된 음악 조각은 총 4개의 악기일 수 있는 1/2의 확률과 총 5개의 악기일 수 있는 1/2의 확 률을 가질 수 있다. 4개의 악기가 선택되는 경우, 조각은 악기가 피아노, 어쿠스틱 기타, 드럼 키트 및 베이스 인 1/2의 확률과 악기가 피아노, 어쿠스틱 기타, 일렉트릭 기타 및 베이스인 1/2의 확률을 포함하는 악기 오케 스트레이션 우선 순위 결정 테이블을 가질 수 있다. 도 63a에는, 6개의 예시적인 악기 오케스트레이션에 대해 서로 다른 순위 세트가 표시되어 있다. 도시된 바와 같이, 사례에서는, 피아노, 일렉트릭 베이스 1 및 바이올린 을 제공하기 위해 난수 발생기를 이용하여 선택된 악기 오케스트레이션 순서가 만들어진다. 도 63a 내지 도 63g에 도시된 흐름도는 편성될 제1 악기-피아노에 대한 오케스트레이션 프로세스를 설명한다. 도시된 바와 같이, 피아노 오케스트레이션 프로세스의 단계에는 피아노에 할당되는 음악 조각 내의 각 음표에 대한 피아노/악기 기능 선택, 피아노 보이싱 선택, 피아노 리듬 길이 선택, 및 피아노 강약 선택이 포함된다. 이 단계들에 대한 세부 사항은 후술하기로 한다. 도 63a 및 도 63b에 도시된 바와 같이, 오케스트레이션 생성 서브 시스템(B51)은 미리 로드된 악기 기능 테이블 에 액세스하고, 임의 함수 생성기(또는 다른 파라미터 선택 메커니즘)을 이용하여 작곡되고 있는 음악 조각의 각 부분(예컨대, 악절 멜로디, 조각 멜로디 등)을 위한 악기 기능을 선택한다. 오케스트레이션 프로세스의 이 단계의 결과는 음악 조각의 각 부분에 대한 기능(예컨대, 기본 멜로디, 보조 멜로디, 기본 하모니, 보조 하모니 또는 반주)의 할당을 포함한다. 이와 같은 기능 코드 또는 인덱스는 상세하게 후술한 바와 같이 오케스트레이션 프로세스의 후속 단계에서 사용될 것이다. 기본 멜로디 악기로서 기능하는 악기의 오케스트레이션은 반주로서 기능하는 경우에서와는 매우 다를 수 있으므 로, 오케스트레이션에서는 음악의 조각 또는 섹션 내에서 각 악기 및 악기 그룹의 기능의 명확한 계층을 생성하 는 것이 중요하다. \"악기 기능\"의 예가 도 63a에 나타낸 악기 기능 테이블에 도시되어 있으며, 예컨대, 기본 멜 로디; 보조 멜로디; 기본 하모니; 보조 하모니; 및 반주를 포함한다. 그러나, 작곡된 음악의 특정 조각을 편곡 하기 위해 사용되는 악기에 의해 지원될 수 있는 더 많은 악기 기능이 있는 것으로 이해된다. 예컨대, 피아노, 어쿠스틱 기타, 드럼 키트 및 베이스를 이용한 \"행복\" C 메이저 음악 조각의 마디에서, 서브 시스템(B31)은 멜 로디를 피아노에, 화음의 지지적인 스트러밍 패턴을 어쿠스틱 기타에, 업비트 리듬을 드럼 키트에, 화음 진행의 최저 자리바꿈 패턴의 음표를 베이스에 할당할 수 있다. 일반적으로, 각 악기의 특정 오케스트레이션의 확률은 조각 내의 모든 다른 악기뿐만 아니라 악기의 이전 오케스트레이션에 의해 직접적으로 영향을 받는다. 따라서, 오케스트레이션 생성 서브 시스템(B31)은 조각을 위해 선택된 특정 악기에 대해, 이에 한정되지는 않지 만, (즉, 도 63e 및 도 63f에 나타낸 \"리드 시트\" 음악 스코어 표현의 처음 2개의 보표에 도시된) 화음 진행 및 멜로디 재료를 포함하는 이전에 생성된 음악 재료를 편곡한다. 사례에서의 악기, 즉, 바이올린(Vln.), 피아노 (Pno.) 및 일렉트릭 베이스(E.B.)를 위해 편곡된 음악은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 음악 오케스트레이션을 위해 생성되어 유지된 도 63f, 도 63g 및 도 63h의 음악 스코어 표현의 제3, 제4/제5 및 제6 보표에 각각 표시될 것이다. 특히, 도 63a 내지 도 63i에 도시된 사례에서, 서브 시스템(B31)은 다음의 악 기 기능 할당을 자동으로 실시하였다: (i) 기본 멜로디 기능이 바이올린(Vln.)에 할당되고, 이 악기 기능을 위 해 편곡된 음악은 제1 및 제2 보표에 개시된 리드 시트 음악 작곡으로부터 유도된 다음, 도 63f에 나타낸 음악 표현의 제3 보표를 따라 표현될 것이며; 보조 멜로디 기능은 피아노(Pno.)의 오른손(RH)에 할당되는 반면 기본 하모니 기능은 피아노의 왼손(LH)에 할당되고, 이 악기 기능을 위해 편곡된 음악은 제1 및 제2 보표에 개시된 리드 시트 음악 작곡으로부터 유도된 다음, 도 63f에 나타낸 음악 표현의 제4 및 제5 보표를 따라 표현될 것이 며; 그리고 보조 하모니 기능은 일렉트릭 베이스(E.B.)에 할당되고, 이 악기 기능을 위해 편곡된 음악은 제1 및 제2 보표에 개시된 리드 시트 음악 작곡으로부터 유도된 다음, 도 63f에 나타낸 음악 표현의 제6 보표를 따라 표현될 것이다. 가까운 사례의 경우, 예컨대, 악기 오케스트레이션의 순서는 다음과 같이 되도록 선택되었다; 각각 피아노 의 RH 및 LH 악기로 보조 멜로디 및 기본 하모니 기능을 수행하는 피아노; 기본 멜로디 기능을 수행하는 바이올린; 및 기본 하모니 기능을 수행하는 일렉트릭 베이스(E.B.). 따라서, 바이올린이 편곡된 음악의 기본 멜로디 기능을 수행하도록 선택된 사실에도 불구하고, 서브 시스템(B31)은 이렇게 지정된 순서로 선택된 악기 그룹을 위해 편곡된 음악을 생성할 것이다. 또한, 본 발명의 자동화된 음악 작곡 프로세스 전반에 걸쳐 서브 시 스템(B31)이 오케스트레이션 서브 프로세스의 악기 기능 단계 중에 혹시 이와 같은 결정을 실행할 필요가 있는 경우, 다수의 악기가 동일한 악기 기능을 수행할 수 있다(즉, 피아노와 바이올린이 모두 기본 멜로디 기능을 수 행할 수 있음)는 것이 지적된다. 서브 시스템(B31)이 오케스트레이션 프로세스 중에 앞이 아닌 시점에 악기 기 능 할당을 수행할 것이지만, 서브 시스템(B31)은 전술한 그 시스템 및 마스터 분석기를 이용하여 음악의 전체 오케스트레이션을 완성되었을 때 자동으로 분석하고, 본 발명의 시스템에 의해 작곡된 음악 조각의 리드 시트 음악 표현에 기초하여, 새로운 악기 기능 할당을 실행하고 특정 악기를 위해 편곡된 음악을 다시 생성하는 것이 타당한지의 여부를 결정할 것이라고 한다. 특정 확률적 또는 추계학적 결정이 서브 시스템(B31)에 의해 어떻게 이루어지는지에 따라, 본 발명의 자동화된 음악 작곡 시스템에 의해 작곡된 음악 조각을 위해 허용가능한 음악 오케스트레이션이 생성되기 전에, 도 63a 내지 도 63i에 나타낸 프로세스를 통해 수개의 완벽한 사이클을 필요 로 할 수 있다. 본 발명의 여타 양태는 이하에서 보다 쉽게 명확해질 것이다. 도 63a 내지 도 63i의 프로그램 도면에 나타낸 바와 같이, 각 악기의 기능이 결정되면, 서브 시스템(B31)은 (i) 각 악기의 특성과 통상적으로 어떻게 연주될 수 있는지에 기초하여, 악기가 연주하거나 그 기능을 수행하는 방 식에 대한 결정 및 (ii) 작곡된 음악 조각을 위해 리드 시트 음악 스코어에 표시된 각 음표로부터 유도된 음악 (예컨대, 단일의 음표, 다이아드(diads), 멜로디 및 화음)의 생성을 지원하기 위해 악기 기능-특정 기능 테이블 (예컨대, 피아노 손 기능 테이블)을 로드함으로써, 선택된 악기 기능을 수행하는 악기를 위해 편곡된 음악 조각 을 제작하게 된다. 도 63b에 나타낸 예에서는, 확률 기반 피아노 손 기능 테이블이 사례에서 선택된 악기 기능, 즉, 보조 멜로디를 위해 로드된다. 설명의 명료함을 위해, 확률 기반 피아노 손 기능(파라미터) 테이블만이 도 63b에 나타냈으나, 악기 오케스트레이션 서브 시스템(B31)은 다른 악기 기능 각각을 위해, 즉, 기본 멜로디; 기 본 하모니; 보조 하모니; 및 반주 각각을 위해, 확률 기반 피아노 손 기능 테이블에 액세스할 것이라고 이해된 다. 또한, 악기 오케스트레이션 서브 시스템(B31)은 오케스트레이션 프로세스에 포함된 각 악기를 위해 서브 시 스템(B31)에 의해 선택될 수 있는 각각의 가능한 악기 기능에 맞게 프로그램된 확률 기반 악기 기능 테이블 세 트에 액세스할 것이라고 이해된다. 예컨대, 통상적으로 왼손과 오른손으로 연주되는 피아노 악기를 고려하기로 한다. 이 경우, (3/4 박자표의) 왈 츠 피아노 반주는 피아노를 위해 편곡된 음악 조각의 모든 다운비트에서의 왼손 연주와 모든 제2 및 제3 비트에 서의 오른손 연주를 가질 수 있다. 이와 같이 피아노를 위한 악기 특정 기능 할당은 (i) (도 63f의 음악 스코어 표현의 제1 보표에 표현된) 작곡된 음악 조각의 리드 시트 내의 각 음표를 프로세싱하며; 그리고 (ii) 피아노의 오른손(RH) 및 왼손(LH) 악기 모두를 위해 편곡된 음악을 생성하고, 이렇게 편곡된 음악을 도 63a 및 도 63c에 나타낸 피아노 손 기능 테이블에 표시하는 악기 오케스트레이션 서브 시스템(B31)에 의해 실행된다. 피아노 손 기능 테이블과 전술한 바와 같은 난수 발생기를 이용하여, 서브 시스템(B31)은 리드 시트 음악 스코어 내의 각 음표를 프로세싱하고, 피아노의 오른손 및 왼손 악기를 위한 음악을 생성한다. 피아노 악기를 위해 발생하는 편곡된 음악 생성 프로세스는 서브 시스템(B31)에 의해 다음과 같이 실행된다. 리 드 시트 음악 스코어 내의 제1 음표에 대하여, 서브 시스템(B31)은 (i) 피아노 손 기능 테이블의 RH 부분에 표 시된 확률을 참조하고, 난수 발생기(또는 다른 파라미터 선택 메커니즘)를 이용하여, 도 63f에 나타낸 제4 보표 에 표시된 바와 같이, 피아노의 RH 악기의 보표에 생성 및 추가될 멜로디, 단일 음표 또는 화음 중 어느 하나를 RH 기능 테이블로부터 선택하며; 그 직후에, (ii) 피아노 손 기능 테이블의 LH 부분에 표시된 확률을 참조하고, 난수 발생기(또는 다른 파라미터 선택 메커니즘)를 이용하여, 도 63f에 나타낸 제5 보표에 표시된 바와 같이, 피아노의 LH 악기의 보표에 생성 및 추가될 멜로디, 단일 음표(비멜로디), 다이아드 또는 화음 중 어느 하나를 RH 기능 테이블 내의 선택된 칼럼으로부터 선택한다. 특히, 다이애드(또는 다이아드)는 2개의 음표 또는 피치의 세트인 반면, 화음은 3개 이상의 음표를 갖지만, 특정 맥락에서, 음악가는 다이애드를 화음으로 또는 화음을 대 신하는 것으로 고려할 수 있다. 매우 일반적인 2음표 \"화음\"은 완전 5도 간격이다. 간격은 2개의 피치 사이의 거리이기 때문에, 다이애드는 그것이 나타내는 간격에 의해 분류될 수 있다. 다이애드의 피치가 연속적으로 발 생하는 경우, 그들은 멜로디 간격을 형성한다. 그들이 동시에 발생하는 경우, 그들은 하모니 간격을 형성한다. 도 63a 및 도 63b에 나타낸 바와 같이, 악기 오케스트레이션 서브 시스템은 지금까지 작곡된 음악 조각에 기초하여 이전에 생성된 음표 중 어느 것이 피아노의 오른손 및 왼손 부분을 위해 가능한 음표인지를 결정한다. 이 기능은 피아노에 의해 연주된 임의의 이전 음표와 피아노에 의해 연주될 수 있는 임의의 가능한 미래 음표와 모두 관련하여, 화음의 피치 부재(음표)와 피아노의 각 손의 기능을 분석한 다음, 피아노 상에서 어떤 피치(즉,피아노 키와 연관된 음표)가 각 손(즉, 왼손은 피아노 상에서 저주파수 음표에 액세스하는 반면, 오른손은 피아 노 상에서 고주파수 음표에 액세스함)에 의해 연주될 수 있는 가능한 음표의 범위 내에 있는지를 결정하는 피아 노 음표 분석기를 이용하여 서브 시스템에 의해 달성된다. 피아노 상에서 특정 인간의 손(RH 또는 LH)에 의 해 통상적으로 연주가능하지 않은 음표들은 피아노를 위해 편곡된 음악 조각으로부터 걸러지거나 제거되는 반면, 연주가능한 음표들은 피아노 음악 오케스트레이션과 연관된 데이터 구조에 남아야 한다. 도 63c 및 도 63d에 나타낸 바와 같이, 각각의 피아노 손을 위해 음표가 생성되면, 서브 시스템(B31)은 피아노 를 위해 편곡된 음악 조각 내의 음표(즉, 피치)들의 수직 간격과 순서에 영향을 미치는 프로세스인 피아노 보이 싱을 실행한다. 예컨대, 악기 보이싱은 어느 음표가 화음의 상단 또는 중간에 있는지, 어느 음표가 2배가 되는 지, 또는 각 음표가 어느 옥타브에 있는지에 대해 영향을 미친다. 피아노 보이싱은 단순한 2열 테이블로서 도 63a 및 도 63b에 개략적으로 도시된 피아노 보이싱 테이블에 액세스하는 서브 시스템(B31)에 의해 달성되며, 실 제로는, 악기 오케스트레이션 프로세스의 이 단계에서 피아노를 위해 편곡된 음악에 존재하는 각각의 음악 이벤 트(예컨대, 단일 음표(비멜로디), 화음, 다이아드 또는 멜로디)를 피아노가 연주할 수 있는 다양한 방식을 나타 내는 파라미터를 수록한 많은 행과 열을 포함하는 복잡한 테이블일 것이다. 피아노 보이싱 테이블에 나타낸 바 와 같이, 종래 방식을 따라, 음표 C에는 숫자 0이 할당되고, C#에는 1이 할당되는 등, 음계 상의 12개의 음표 또는 피치는 각각 0 내지 11의 숫자로 표시된다. 도 63c의 예시적인 피아노 보이싱 테이블은 편곡된 음악 조각 내에서 발생할 수 있는 단일 음표(비멜로디) 이벤트를 위해 가능한 LH 및 RH의 조합만을 나타내고 있지만, 실제 의 이 피아노 보이싱 테이블은 당업계에 공지된 바와 같이 피아노를 위해 편곡된 음악 내에서 발생할 가능성이 있는 많은 다른 가능한 음악 이벤트(예컨대, 화음, 다이아드 및 멜로디)를 위한 보이싱 파라미터를 포함할 것으 로 이해된다. 피아노를 위해 편곡된 음악 내에 생성된 음표를 악기가 연주하려고 하는 방식이 전술한 바와 같이 결정되면, 서 브 시스템(B31)은 도 63d 및 도 63e에 나타낸 피아노 리듬 테이블을 이용하여 음표 길이 또는 지속 시간(즉, 음 표 리듬)을 포함한 사양을 결정하고, 피아노 오케스트레이션이 채워질 때까지 편곡된 음악 조각을 위한 음표 지 속 시간을 계속 특정한다. 도 63e에 나타낸 바와 같이, 피아노 음표 리듬(즉, 음표 길이) 특정 프로세스는 본 발명의 시스템 내에서 허용될 메모리 및 데이터 프로세싱만큼 많은 단계를 이용하여 실행된다. 예시적인 실시형 태에서는, 도 63d 및 도 63e에 나타낸 바와 같이, (i) 왼속 및 오른손 구성 요소를 가진 확률 기반 제1 피아노 리듬(음표 길이) 테이블, (ii) 왼속 및 오른손 구성 요소를 가진 제2 피아노 리듬(음표 길이) 테이블, 및 (iii) 왼속 및 오른손 구성 요소를 가진 제3 피아노 리듬(음표 길이) 테이블을 이용하여, 제1(첫번째) 음표, 제2 (순 차) 음표 및 제3 (순차) 음표를 순차적으로 프로세싱하기 위해 3개의 단계들이 서브 시스템(B31) 내에서 지원된 다. 특히, 3차 추계학적 모델에 있어서, 오른손 제2 피아노 리듬(음표 길이) 테이블에 포함된 확률 값은 피아노 의 오른손 악기에 의해 연주되어 서브 시스템(B31)에 의해 관찰될 수 있는 제1 음표에 의존하며, 오른손 제3 피 아노 리듬(음표 길이) 테이블에 포함된 확률 값은 피아노의 오른손 악기에 의해 연주되어 서브 시스템(B31)에 의해 관찰될 수 있는 제1 음표에 의존한다. 마찬가지로, 왼손 제2 피아노 리듬(음표 길이) 테이블에 포함된 확 률 값은 피아노의 왼손 악기에 의해 연주되어 서브 시스템(B31)에 의해 관찰될 수 있는 제1 음표에 의존하며, 왼손 제3 피아노 리듬(음표 길이) 테이블에 포함된 확률 값은 피아노의 왼손 악기에 의해 연주되어 서브 시스템 (B31)에 의해 관찰될 수 있는 제1 음표에 의존한다. 피아노 음표 리듬(즉, 음표 길이) 제어를 위해 고차 추계학적 모델이 사용되는 경우, 서브 시스템(B31) 내에서 지원되는 오케스트레이션 프로세스를 실행하기 위해 4차나 아마도 더 차원이 높은 피아노(음표) 리듬(음표 길이) 테이블이 사용될 것이다. 이 음표 프로세싱 단계로부터 나온 결과물은 도 63f에 나타낸 음악 스코어 표현 에 도시된 바와 같이 피아노를 위해 편곡된 음악 조각에서 특정된 음표 길이 또는 지속 시간을 가진 음표이다. 사용되는 추계학적 모델의 차수와 무관하게, 악기 오케스트레이션 서브 시스템(B31)은 주어진 악기를 위해 편곡 된 음악의 각 조각에서 적절한 음표 길이(즉, 음표 리듬)를 결정해야 한다. 따라서, 예컨대, 이전의 예를 계속 하여, 피아노의 왼손 악기가 다운비트로 몇몇 음표를 연주하면, 이는 팔분음표 또는 이분음표 지속 시간 동안 여러 음표를 연주할 수 있다. 각각의 음표 길이는 이전의 모든 음표의 음표 길이; 동일한 마디, 악절 및 하위 악절 내의 다른 음표의 음표 길이; 및 미래에 발생할 수 있는 음표의 음표 길이에 의존한다. 제2 음표의 길이가 제1 음표의 길이에 의해 영향을 받고, 제3 음표의 길이가 제1 및 제2 음표의 길이에 의해 영향을 받도록 하는 식으로, 특정 음표의 길이에 대한 결정에 각각의 선행하는 음표 길이 결정 인자가 고려된다. 피아노 오케스트레이션을 위한 음표 길이를 결정되면, 서브 시스템(B31)에 의해 실행되는 다음 단계는 도 63f에 나타낸 프로세스 도면에 표시된 피아노 강약 테이블로 나타낸 바와 같이 피아노 악기를 위한 \"강약\"을 결정하는 것이다. 일반적으로, 강약은 음악 작곡의 음량 또는 부드러움을 의미하고, 피아노 또는 악기의 강약은 편곡된음악 조각을 연주할 때 악기에 의해 생성되는 소리의 강도에 특별한 동적 특성을 부여하기 위해 피아노 또는 악 기를 연주하는 방법에 관련된다. 이와 같은 동적 특성은 음량 및 부드러움과 아울러, 작곡이 수행될 때 악기로 부터 나오는 소리 볼륨이 시간에 따라 증가하거나 감소하는 속도를 포함할 것이다. 도 63g의 프로세스 도면에 개시된 피아노 강약 테이블에 반영된 바와 같이, 지난 수백년 동안 피아노를 위해 \"강약\"에 대한 몇개의 전통적 분류, 즉, (i) 피아노(소프트); 메조 피아노; 메조 포르테가 개발되었다. 각각의 경우에서, 악기의 강약은 본 발명의 자동화된 음악 작곡 및 생성 시스템에 의해, 또는 본 발명의 원리에 따라 음악을 작곡, 생성 및 실행하 기 위해 시스템이 집적되거나 요청될 수 있는 임의의 도출된 시스템에 의해, 악기가 연주되거나 실행되는 방법 에 관련된다. 도 63f에 나타낸 바와 같이, 피아노의 오른손 악기, 그 다음 피아노의 왼손 악기에 의해 연주되는 제1 음표를 위한 피아노 강약을 선택하기 위해, 도 78a, 도 78b 및 도 2r3에 나타낸 피아노 강약 테이블과 난수 발생기(또 는 다른 파라미터 선택 메커니즘)을 이용하여, 피아노 악기를 위한 강약이 결정된다. 도 63f에 도시된 피아노 강약 테이블은 설명의 간단 명료함을 위해 1차 추계학적 모델로서 나타냈으나, (대부분의 악기 강약 테이블뿐만 아니라) 실제 피아노 강약 테이블은, 각각의 음표 강약이 이전의 모든 음표의 음표 강약; 동일한 마디, 악절 및 하위 악절 내의 다른 음표의 음표 강약; 및 미래에 발생할 수 있는 음표의 음표 강약에 의존하는, n차 추계학적 프로세스로서 모델링되고 구현될 것으로 이해된다. 제2 음표의 강약이 제1 음표의 강약에 의해 영향을 받고, 제 3 음표의 강약이 제1 및 제2 음표의 강약에 의해 영향을 받도록 하는 식으로, 특정 음표의 강약에 대한 결정에 각각의 선행하는 음표 강약 결정 인자가 고려된다. 어떤 경우에서는, 특정 마디 또는 마디들, 또는 멜로디 악절 또는 악절들, 또는 하위 악절 또는 하위 악절들에서, 또는 어떤 경우에는 전체 멜로디 조각에서, 볼륨이 점진적 으로 증가하거나 감소하도록, 피아노 강약 테이블이 프로그래밍될 것이다. 다른 경우에서는, 하나의 특정 마디 에서 다른 마디로, 또는 멜로디 악절에서 다른 멜로디 악절로, 또는 하나의 하위 악절에서 다른 하위 악절로, 또는 어떤 경우에는 하나의 멜로디 조각에서 다른 멜로디 악절로, 피아노 음표 강약이 변하도록, 피아노 강약 테이블이 프로그래밍될 것이다. 일반적으로, 악기 연주의 강약은 항상 변화할 것이지만, 흔히 클래식 음악 이론 카논을 추종하는 지표를 유도함으로써 결정된다. 그와 같은 피아노 강약 테이블이 가까운 임의의 특정 애플리케 이션을 위해 어떻게 설계될 수 있을 것인가라는 의문이 본 발명이 개시한 교시의 혜택을 보는 당업자에게 일어 날 것이다. 이 피아노 강약 프로세스는 피아노의 오른손 악기를 위해 도 63g의 음악 스코어 표현의 제4 보표에 표시된 편곡 된 피아노 음악 내의 다음 음표에 대해, 그리고 피아노의 왼손 악기를 위해 도 63g의 음악 스코어 표현의 제5 보표에 표시된 편곡된 피아노 음악 내의 다음 음표에 대해 작용을 반복한다. 모든 피아노 강약이 선택되어 피아 노에 할당된 조각의 각 부분의 모든 피아노 음표에 전해질때까지, 강약 프로세스는 반복되며 피아노 오케스트레 이션 내의 모든 음표에 대해 작용한다. 나타낸 바와 같이, 피아노를 위한 강약 표시(e, g, p, mf, f)와 함께, 도출된 음악 스코어 표현이 도 63g의 상단에 도시되어 있다. 도 63g에 표시된 바와 같이, 전체 서브 시스템(B31)은 다음 악기(예컨대, 일렉트릭 베이스 1)에 대해 상기 악기 오케스트레이션 프로세스를 반복함으로써, 도 63h에 나타낸 음악 스코어 표현의 제6 보표에 표시된 바와 같이, 일렉트릭 베이스를 위해 편곡된 음악이 시스템의 메모리 내에 생성되어 저장되도록 한다. 도 63g 및 도 63h에 나타낸 바와 같이, 일렉트릭 베이스 악기를 편성할 때, 서브 시스템(B31)은 이전에 편성된 악기들 간의 충돌을 자동으로 점검하기 위해 시스템 분석기를 사용한다. 도시된 바와 같이, 시스템 분석기는 서 브 시스템(B31)에서 사용되는 다양한 테이블 내의 확률을 조정함으로써 편성된 악기들 간의 가능한 충돌을 제거 한다. 편성된 악기들 간의 가능한 충돌의 예에는, 예컨대, 이전의 악기와 충돌하는 피치 범위 내로 악기가 편성 된 때(즉, 악기가 낮은 품질의 오케스트레이션을 만드는 다른 악기와 정확하게 동일한 피치/주파수를 연주할 때); 이전 악기와 충돌하는 강약으로 악기가 편성된 경우(즉, 모든 악기가 조용히 연주하고 하나의 악기가 이제 매우 크게 연주하는 경우); 이전의 오케스트레이션에 비추어 실제 음악가에 의해 물리적으로 가능하지 않은 무 언가를 하도록 악기가 편성된 경우(즉, 한명의 타악기 연주자가 한번에 8개의 드럼 키트를 연주할 수 없음)가 포함될 수 있다. 도 63h은 일렉트릭 베이스(E.B.) 악기에 의해 연주되는 보정된 음악 악기 편성을 위한 음악 스 코어 표현을 나타낸다. 도 63h의 하단에 나타낸 바와 같이, 서브 시스템(B31)은 음악 작곡의 악기 그룹 내의 다음 악기(즉, 바이올린) 를 위해 전술한 오케스트레이션 프로세스를 반복한다. 바이올린에 의해 연주되는 편곡된 음악을 위한 음악 스코 어 표현이 도 63i의 프로세스 도면에 개시된 최상단 음악 스코어 표현에 나타낸 제3 보표에 개시되어 있다. 도 63i에 나타낸 바와 같이, 오케스트레이션이 완료되면, 오케스트레이션 생성 서브 시스템(B13)은 마스터 오케 스트레이션 분석기를 이용하여 도출된 오케스트레이션을 변경 및 개선하고, 모든 음악적 또는 비음악적 오차 및 /또는 비효율을 보정한다. 이 예에서는, 오케스트레이션 프로세스의 이 단계의 마지막에 생성된 도 63i에 개시 된 프로세스 도면의 하부에 개시된 마지막 음악 스코어 표현에 나타낸 바와 같이, 도 63i의 피아노 오케스트레 이션의 제2 및 제3 낮은 음자리표 보표의 옥타브 음표는 제거되었다. 음악 조각의 악기 편성을 위해 선택된 악기와 다른 음악 소리는 본 발명의 자동화된 음악 작곡 및 생성 프로세 스 중에 사용됨으로써, 도 63i의 하단에 도시된 음악 스코어 표현에 나타낸 바와 같이, 작곡되고 있는 음악 조 각의 일부를 생성하게 된다. 컨트롤러 코드 생성 서브 시스템(B32)의 사양 도 64은 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 컨트롤러 코드 생성 서브 시스템(B32)을 나 타낸다. 이에 한정되지는 않지만, 조음, 호흡 유지, 운음, 볼륨, 팬 위치, 발현, 레가토, 리버브, 트레몰로, 코 러스, 주파수 컷오프를 포함하는 컨트롤러 코드, 또는 음악 명령은 모든 디지털 음악 조각의 기본적인 구성 요 소이다. 특히, 컨트롤러 코드(CC)는 편곡된 음악의 임의의 주어진 조각에 존재하는 음표와 음악 구조 상에서 악 기 오케스트레이션 서브 시스템(B31)의 제어 범위를 벗어난 편곡된 음악 작곡의 다양한 특성 및 특징을 제어하 기 위해 사용된다. 따라서, 악기 오케스트레이션 서브 시스템(B31)이 편곡된 음악의 임의의 조각을 위해, 예컨 대, 악기 기능, 음표 길이(즉, 음표 리듬) 및 악기 보이싱과 같은 연주 기능을 제어하기 위해 n차 추계학적 모 델(즉, 확률 파라미터 테이블)을 채택할 때, 컨트롤러 코드 생성 서브 시스템(B31)은 편곡된 음악 조각의 다른 특징, 즉, 조음, 호흡 유지, 운음, 볼륨, 팬 위치, 발현, 레가토, 리버브, 트레몰로, 코러스, 주파수 컷오프 및 다른 특징을 제어하기 위해 n차 추계학적 모델(즉, 확률 파라미터 테이블)을 채택한다. 대안적인 실시형태에서, 컨트롤러 코드 생성 서브 시스템(B32)에 의해 지원되는 제어 기능 중 일부는 악기 오케스트레이션 서브 시스템 (B31)에 의해 구현될 수 있으며, 그 반대의 경우도 가능하다. 그러나, 본 발명의 자동화된 음악 작곡 및 생성 시스템에 의해 채택되는 관리된 자원의 우아한 계층 때문에, 본원에 개시된 예시적인 실시형태가 바람직한 실시 형태이다. 컨트롤러 코드 생성 서브 시스템(B32)은 작곡 및 생성되고 있는 음악 조각에 사용될 각 음표의 컨트롤러 코드 및/또는 그와 유사한 정보를 결정한다. 이 서브 시스템(B32)은 작곡되고 있는 음악의 음표와 화음을 위한 \"컨트 롤러 코드\" 정보를 결정하고 생성한다. 이 정보는 (주어진 경우에) 시스템 사용자 입력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 도 64에 나타낸 바와 같이, 컨트롤러 코드 생성 서브 시스템(B32)은 도 79에 나타낸 컨트롤러 코드 파라미터 테 이블과, 상세하게 전술한 파라미터 선택 메커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미터 선택기) 에 의해 지원된다. 컨트롤러 코드 데이터의 형태는 통상적으로 0 내지 127의 스케일로 주어진다. 0인 볼륨(CC 7)은 최소의 볼륨이 존재한다는 것을 의미하는 반면, 127인 볼륨은 최대의 볼륨이 존재한다는 것을 의미한다. 0 인 팬(CC 10)은 신호가 극좌측으로 이동하는 것을 의미하고, 64는 중앙으로 이동하는 것을 의미하며, 127은 극 우측으로 이동하는 것을 의미한다. 각각의 악기, 악기 그룹 및 조각은 서로 다른 프로세싱 효과, 컨트롤러 코드 데이터, 및/또는 사용하기 위해 선 택되는 다른 오디오/미디 조작 툴의 특정한 독립적 확률을 갖는다. 그리고, 각각의 선택된 조작 툴을 이용하여, 서브 시스템(B32)은 선택 툴이 음악 조각, 섹션, 악절 또는 다른 구조(들)에 영향을 미치고/또는 변경하는 방식; 음악 구조들이 서로 영향을 미치는 방법; 및 컨트롤러 코드 툴이 조작하는 음악 재료를 개선하는 조작 랜 드스케이프를 생성하는 방법을 결정한다. 파라미터 변환 엔진 서브 시스템(B51)은 시스템 사용자에 의해 선택되어 입력 서브 시스템(B0)에 제공되는 다양 한 음악적 경험 디스크립터를 위한 가능한 컨트롤러 코드(즉, 파라미터) 테이블의 확률 가중 데이터 세트를 생 성한다. 도 64에서, 서브 시스템에 채택된 확률 기반 파라미터 프로그래밍 테이블(즉, 악기, 악기 그룹 및 조각 폭 컨트롤러 코드 테이블)은 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복과 \"스타일 타입\" 음악적 경험 디스크립터-팝을 위해 설립되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 컨트롤러 코드 생성 서브 시스템(B32)은 서브 시스템(B1, B37, B38, B39, B40 및/또는 B41)으로부터 로드된 악 기, 악기 그룹 및 조각 폭 컨트롤러 코드 파라미터 테이블 및 데이터 세트를 이용한다. 도 64에 나타낸 바와 같 이, 바이올린 악기를 위한 악기 및 조각 폭 컨트롤러 코드(CC) 테이블은 리버브; 딜레이; 패닝; 트레몰로 등과 같은 파라미터를 제어하기 위한 확률 파라미터를 갖는다. 컨트롤러 코드 생성 서브 시스템(B31)이 도 64에 1차 추계학적 모델로서 나타나 있지만, 실제로는, 파라미터 변환 엔진 서브 시스템(B51)에 의해 생성되어 서브 시스템(B32) 내에 로드되는 각 악기, 악기 그룹 및 조각 폭 컨트롤러 코드 테이블은 n차 추계학적 프로세스로서 모 델링되고 구현될 것이며, 주어진 음표에 적용하기 위한 각 컨트롤러 코드 테이블은 이전의 모든 음표를 위한 컨 트롤러 코드 테이블; 동일한 마디, 악절 및 하위 악절 내의 다른 음표를 위한 컨트롤러 코드 테이블; 및 미래에 발생할 수 있는 음표를 위한 컨트롤러 코드에 의존한다. 일반적으로, 감정 및 스타일 디스크립터와 음악이 연주되는 방법을 통지하는 컨트롤러 코드 정보 사이에는 강한 관계가 있다. 예컨대, 록 스타일로 편곡된 음악 조각은 다량의 딜레이와 리버브를 가질 수 있는 반면, 보컬리스 트는 트레몰로를 연주에 포함시킬 수 있다. 그러나, 음악 조각을 생성하기 위해 사용되는 컨트롤러 코드 정보는 감정 및 스타일 디스크립터 입력과 무관할 수 있으며, 단지 타이밍 요청을 수행하기 위해 존재할 수도 있다. 예 컨대, 음악 조각이 지금까지의 컨트롤러 코드 정보와는 무관하게 어느 순간 악센트할 필요가 있는 경우, 일정한 딜레이에서 딜레이가 전혀 없는 것으로 이동하는 것과 같은 컨트롤러 코드 정보의 변화는 이 타이밍 요청을 성 공적으로 달성할 수 있으며, 사용자 요청에 따른 보다 음악적인 오케스트레이션에 적합하다. 음악 조각의 악기 편성을 위해 선택된 컨트롤러 코드는 후술하는 바와 같이 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될 것이다. 디지털 오디오 샘플 생성 서브 시스템의 사양 및 서브 시스템(B33 및 B34)에서의 그 용도 본원에 개시된 본 발명의 자동화된 음악 작곡 및 생성(즉, 제작) 시스템은 작곡된 음악의 각 조각을 위해 음악 스코어 표현에 특정된 개별 음표의 디지털 오디오 샘플을 제작하기 위해 디지털 방식으로 합성된(즉, 가상) 음 악 악기 또는 가상 악기의 라이브러리를 사용한다. 작곡된 음악 조각 내의 개별 음표를 표현하는 각 디지털 오 디오 샘플을 제작하기 위해 사용될 수 있는 실제 기술과는 무관하게,이와 같이 디지털 방식으로 합성된(즉, 가 상) 악기는 디지털 오디오 샘플 생성 서브 시스템으로서 지칭될 것이다. 일반적으로, 시스템에 의해 작곡된 음악의 임의의 조각으로부터 음악을 생성하기 위해, 서브 시스템(B33 및 B34)은 작곡된 음악 조각의 음악 스코어 표현에 특정된 가상 악기로 연주되는 음악 이벤트(예컨대, 음표와 같은 피치 이벤트, 및 리듬 이벤트)를 청각적으로 실현하기 위한 음악 악기 라이브러리를 필요로 한다. 본 발명의 자 동화된 음악 작곡 및 생성 시스템과 함께 사용하기 위해, 음악 악기 라이브러리 및 음악 소리 라이브러리를 생 성, 설계 및 유지하기 위해 이용가능한 여러 가지 기술, 즉, 디지털 오디오 샘플링 합성 방법; 부분 음색 합성 방법, 주파수 변조(FM) 합성 방법 및 가상 악기 합성 기술의 다른 형태가 존재한다. 디지털 오디오 샘플링 합성 방법은 (실제 악기 또는 다른 오디오 이벤트와 같은) 음원을 기록하는 단계, 및 본 발명의 시스템에서 사용하기 위해 지능적인 방식으로 이 샘플들을 조직하는 단계를 포함한다. 구체적으로, 각 오디오 샘플은 단일 음표 또는 화음 또는 소정의 음표 세트를 포함한다. 가능한 모든 용도의 자연스러운 기록이 샘플링된 악기 라이브러리에서 포착되어 이용가능하도록, 각각의 음표, 화음 및/또는 소정의 음표 세트는 광범 위한 서로 다른 볼륨, 서로 다른 속도, 서로 다른 조음 및 서로 다른 효과 등으로 기록된다. 각각의 기록은 특 정 오디오 파일 포맷으로 조작되어, 식별 정보를 가진 메타 데이터로 지명 및 태그된다. 그 다음, 각각의 기록 은 바람직하게는 자동화된 음악 작곡 및 생성 시스템이 액세스할 수 있거나 그 내부에 유지된 데이터베이스 내 에 기억 및 저장된다. 예컨대, 88개의 키(즉, 음표)를 가진 어쿠스틱 피아노에서는, 함께 취합되어 완전히 디지 털 방식으로 샘플링된 피아노 악기를 구성하는 10,000개 이상의 분리된 디지털 오디오 샘플을 갖는 것은 놀라운 일이 아니다. 음악 제작 중에, 이와 같이 디지털 방식으로 샘플링된 음표는 시스템으로 작곡되는 음악을 생성하 기 위해 실시간으로 액세스된다. 본 발명의 시스템 내에서, 이와 같은 디지털 오디오 샘플은, 상세하게 후술하 는 바와 같이, 서브 시스템(B33 및 B34)에 의해 검색 및 조직되는 디지털 오디오 파일로서 기능한다. 1980년대에 뉴 잉글랜드 디지털 사의 싱클러비어 부분 음색 음악 합성기 시스템에 의해 대중화된 부분 음색 합 성 방법을 이용하여, (부분 음색 합성 라이브러리를 위해) 모델링되는 임의의 주어진 악기에 의해 연주될 수 있 는 음계를 따라 각 음표가 샘플링되며, 그 부분 음색 구성 성분은 디지털 메모리에 저장된다. 그리고, 음악 제 작/생성 중에, 음표가 주어진 옥타브에 따라 연주되면, 각각의 부분 음색 구성 성분은 그 부분 음색 채널로부터 자동으로 독출되어 모든 다른 채널과 함께 음악 음표를 합성하기 위해 아날로그 채널에 추가된다. 부분적인 음 색 채널이 독출되어 조합되는 속도는 제작된 음표의 피치를 결정한다. 부분 음색 합성 기술은 참고로 원용된 미 국 특허 제4,554,855호; 제4,345,500호; 및 제4,726,067호에 교시되어 있다. 모투 사의 마하파이브 3 유니버설 샘플러 및 가상 음악 악기 설계 툴에 의해 지원되는 바와 같은 최첨단 가상 악기 합성 방법을 사용하여, 음악가는 본 발명의 시스템에서의 음악 제작(즉, 생성)을 지원하기 위해 거의 모든 가상 악기, 실제 악기, 또는 상상할 수 있는 악기를 위한 지정 소리 라이브러리를 생성할 수 있다.FM 합성과 같이 음악 음표 및 악기 합성을 위해 개발된 다른 기술이 존재하며, 가상 악기 설계 및 음악 제작을 위해 다양한 상업용 제품에 이 기술이 채택되어 있음을 발견할 수 있다. 디지털 오디오 검색기 서브 시스템(B33)의 사양 도 65은 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 디지털 오디오 검색기 서브 시스템(B33)을 나타낸다. 디지털 오디오 샘플, 또는 서로 다른 시점에 수득된 오디오 신호의 진폭을 나타내는 이산 값(숫자)은 모든 음악 조각의 기본적인 구성 요소이다. 디지털 오디오 샘플 검색기 서브 시스템(B33)은 시스템에 의해 작곡 된 음악의 편곡된 조각에서 요구되는 개별 디지털 오디오 샘플을 검색한다. 디지털 오디오 검색기 서브 시스템 (B33)은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 생성된 각 악기 음표의 에너지를 포함한 스펙트 럼 에너지를 포함한 디지털 오디오 파일의 위치를 결정하고 검색하기 위해 사용된다. 본 발명의 시스템 내에 이 서브 시스템(B33)을 구현하기 위해 당업계에 공지된 다양한 기술이 사용될 수 있다. 디지털 오디오 샘플 조직기 서브 시스템(B34)의 사양 도 66은 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 디지털 오디오 샘플 조직기 서브 시스템 (B34)을 나타낸다. 디지털 오디오 샘플 조직기 서브 시스템(B34)은 디지털 오디오 샘플 검색기 서브 시스템 (B33)에 의해 검색된 디지털 오디오 샘플-디지털 오디오 악기 음표 파일을 조직하고 배열하며, 음악 조각에 따 른 타임라인을 따라 정확한 시간 및 공간 순서로 이 파일을 조직함으로써, 타임라인의 시작부터 통합되어 실행 되거나 연주될 때, 전체 음악 조각이 정확하고 들릴 수 있게 전송되어 다른 사람이 들을 수 있도록 한다. 즉, 디지털 오디오 샘플 조직기 서브 시스템(B34)은 음악 조각 내에서 각 오디오 파일의 시간적 및 공간적 정확한 위치를 결정한다. 점증적으로 보면, 이 오디오 파일은 제작 또는 작곡/생성된 음악 조각의 정확한 오디오 표현 을 만든다. 이 서브 시스템(B34)에 대한 비유는 (음악 조각에 대한) 매우 구체적인 청사진을 추종하여 청사진의 도면(들) 및 수치(들)와 일치하는 물리적 구조(들)를 생성하는 프로세스이다. 조각 통합기 서브 시스템(B35)의 사양 도 67a는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 조각 통합기 서브 시스템(B35)을 나타낸다. 디지털 오디오 파일, 또는 재생될 수 있는 포착된 소리의 기록은 모든 기록된 음악 조각의 기본적인 구성 요소 이다. 조각 통합기 서브 시스템(B35)은 서브 시스템(B34)로부터 수득된 개별 오디오 파일의 조직된 집합으로부 터 디지털 오디오 샘플을 수집하고, 이 디지털 오디오 파일을 동일하거나 더 많은 양의 정보를 포함한 하나 이 상의 디지털 오디오 파일(들)로 통합하거나 조합한다. 이 프로세스는 파형, 컨트롤러 코드 및/또는 다른 조작 툴 데이터 및 서로 매끄럽게 연결되어야 하는 오디오 파일의 추가적인 특징과 일치하는 검사 및 결정 방법을 포 함한다. 조각 통합기 서브 시스템(B35)에 의해 통합될 디지털 오디오 샘플은 (주어진 경우에) 시스템 사용자 입 력, 컴퓨터로 결정된 값(들) 또는 이들의 조합 중 어느 하나에 기초하게 된다. 조각 포맷 번역기 서브 시스템(B50)의 사양 도 67b은 본 발명의 자동화된 음악 작곡 및 생성 엔진(E1)에서 사용되는 조각 포맷 번역기 서브 시스템(B50)을 나타낸다. 조각 포맷 번역기 서브 시스템(B50)은 디지털 조각의 오디오 및 텍스트 표현을 분석하고, 시스템 사 용자 또는 시스템에 의해 요청된 바와 같이 조각의 새로운 포맷을 생성한다. 그와 같은 새로운 포맷에는, 이에 한정되지는 않지만, MIDI, 비디오, 대체 오디오, 이미지 및/또는 대체 텍스트가 포함될 수 있다. 서브 시스템 (B50)는 완성된 음악 조각을 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 요청된 원하는 대체 포맷으 로 번역한다. 조각 전달기 서브 시스템(B36)의 사양 도 68는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 조각 전달기 서브 시스템(B36)을 나타낸다. 조각 전달기 서브 시스템(B36)은 포맷된 디지털 오디오 파일(들)을 시스템으로부터, 통상적으로 시스템 인터페 이스 서브 시스템(B0)을 통해 정보 및/또는 파일(들)을 요청하는 시스템 사용자(인간 또는 컴퓨터 중 하나)에게 전송한다. 피드백 서브 시스템(B42)의 사양 도 69a, 도 69b 및 도 69c은 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 피드백 서브 시스템 (B42)을 나타낸다. 도시된 바와 같이, 피드백 서브 시스템(B42)의 입출력 데이터 포트는 도 26a 내지 도 26p에 나타낸 데이터 입출력 포트로 구성된다. 피드백 서브 시스템(B42)의 주요 목적은 본 발명의 자동화된 음악 작곡 기술을 이용하여 시스템에 의해 자동으로 생성된 음악 조각의 품질, 정밀도, 음악성 및 다른 요소를 실시간 또는 준실시간으로 개선하기 위해 사용자 및/또는 컴퓨터 피드백을 수용하는 것이다. 일반적으로, 시스템 작동 중에, 피드백 서브 시스템(B42)은 매우 구체적인 것에서부터 매우 모호한 것에 이르는 범위의 입력을 허용하고, 이 피드백에 따라 작용한다. 예컨대, 생성된 조각이, 예컨대, (i) 빠르도록(즉, 증가 된 템포를 갖도록), (ii) 특정 음악적 경험 디스크립터를 크게 강조하고, 타이밍 파라미터를 변경하도록, 그리 고 (iii) 특정 악기를 포함하도록, 사용자가 정보를 제공할 수 있거나, 시스템이 자발적으로 결정할 수 있다. 이 피드백은 이전에 지정된 피드백 요청 목록 또는 확장가능한 피드백 형태를 통해 주어질 수 있으며, 임의의 단어, 이미지, 또는 피드백의 다른 표현으로서 수용될 수 있다. 도 69a, 도 69b 및 도 69c에 나타낸 바와 같이, 조각 피드백 서브 시스템(B42)은 그 데이터 입력 포트로부터 각 종 데이터를 수신하고, 이 데이터는 서브 시스템(B42) 내에 지원된 조각 피드백 분석기에 의해 자율적으로 분석 된다. 일반적으로, 조각 피드백 분석기는, 이에 한정되지는 않지만, 품질 및 정밀도의 자율적인 또는 인공 지능 적인 기준과 품질 및 정밀도의 인간 또는 인간 보조 기준을 포함한 모든 이용가능한 입력을 고려하여, 작곡된 음악의 분석된 조각에 적당한 응답을 결정한다. 조각 피드백 분석기로부터의 데이터 출력은 간단한 이진 응답으 로 제한될 수 있으며, 동적 다변량 및 다상성 응답과 같이 복잡할 수 있다. 그리고, 분석기는 이와 같은 입력과 분석에 기초하여 음악 조각의 리듬, 하모니 및 다른 값을 가장 잘 변경하는 방법을 결정한다. 본 발명의 시스템 피드백 아키텍처를 이용하면, 음악, 섹션, 악절 또는 다른 구조의 전체 조각이 생성된 후에, 임의의 작곡된 음 악 조각 내의 데이터를 변환할 수 있거나, 음악이 생성됨과 동시에 음악의 조각을 변환할 수 있다. 도 69a에 나타낸 바와 같이, 피드백 서브 시스템(B41)은 자율적 확인 분석을 실행한다. 자율적 확인 분석은 품 질 보증/자체 검사 프로세스이며, 이를 통해, 시스템은 선택된 음악 조각을 검사하고, 이를 오리지널 시스템 입 력에 대해 비교하며, 요청된 조각의 모든 속성이 성공적으로 생성되어 전달되었는지와 도출된 조각이 특이한지 를 확인한다. 예컨대, 행복 음악 조각이 메이저 키로 끝나는 경우, 분석은 실패한 확인을 출력하고, 조각의 다 시 제작될 것이다. 이 프로세스는 사용자에게 전송되는 모든 음악 조각이 충분한 품질이며, 사용자의 기대에 부 응하거나 능가할 것인지를 확인하는 데에 중요하다. 도 69a에 나타낸 바와 같이, 피드백 서브 시스템(B42)은 디지털 오디오 파일과 추가적인 조각 포맷을 분석하여, (i) 요청된 조각의 모든 속성이 정확하게 전달되는지, (ii) 음악 조각의 \"특이성\"을 결정 및 확인하기 위해 디 지털 오디오 파일과 추가적인 조각 포맷이 분석되는지, 그리고 (iii) 시스템 사용자가 본 발명의 미래의 자동화 된 음악 작곡 생성 프로세스 중에 오디오 파일 및/또는 추가적인 조각 포맷을 분석하는지를 결정 및 확인한다. 특이 조각은 모든 다른 조각과는 상이한 조각이다. 특이성은 새로운 조각의 특이성을 무효로 하는 기존 음악 조 각을 찾아서 음악 조각의 모든 속성을 모든 다른 음악 조각의 모든 속성에 비교함으로써 측정될 수 있다. 도 69a, 도 69b 및 도 69c에 나타낸 바와 같이, 음악 조각의 특이성이 성공적으로 확인되지 않으면, 피드백 서 브 시스템(B42)은 입력된 음악적 경험 디스크립터 및/또는 서브 시스템 음악 이론 파라미터를 변경한 다음, 음 악 조각을 다시 제작하기 위해 자동화된 음악 작곡 및 생성 프로세스를 다시 시작한다. 음악 조각의 특이성이 성공적으로 확인되면, 피드백 서브 시스템(B42)은 사용자 확인 분석을 실행한다. 사용자 확인 분석은 피드백 및 편집 프로세스이며, 이를 통해, 사용자는 시스템에 의해 생성된 음악 조각을 수신하고 다음에 할 일, 즉, 현재 의 조각을 수용할지, 동일한 입력에 기초하여 새로운 조각을 요청할지, 또는 변경된 입력에 기초하여 새롭거나 변경된 조각을 요청할지를 결정한다. 이는 생성된 조각의 편집성을 고려하여 인간 작곡가에게 피드백을 제공하 여 그로 하여금 변경 요청을 연기하도록 하는 것과 동일한 시스템에서의 요점이다. 그 후, 도 69b에 나타낸 바와 같이, 시스템 사용자는 오디오 파일 및/또는 추가적인 조각 포맷을 분석하고, 피 드백이 필요한지의 여부를 결정한다. 이와 같은 분석을 실행하기 위해, 시스템 사용자는 (i) 조각 또는 음악을 부분적으로 또는 전체적으로 들을 수 있거나, (ii) (표준 MIDI 규칙으로 표현된) 스코어 파일을 볼 수 있거나, 그렇지 않으면, (iii) 음악 조각과 상호 작용할 수 있으며, 음악은 색, 맛, 물리적인 감각 등과 함께 전해질 수 있고, 이들은 모두 사용자가 음악 조각을 경험할 수 있도록 한다. 피드백이 필요하다고 결정되지 않은 경우, 시스템 사용자는 (i) 현재의 음악 조각으로 계속하거나, (ii) 시스템 을 이용하여 새로운 음악 조각을 제작하기 위해, 사용자에 의해 제공된 정확하게 동일한 입력 음악적 경험 디스 크립터 및 타이밍/공간 파라미터를 사용한다. 피드백이 필요하다고 결정되는 경우, 시스템 사용자는 공급된 원 하는 피드백을 시스템에 제공한다. 이와 같은 시스템 사용자 피드백은 텍스트, 언어학/언어, 이미지, 음성, 메 뉴, 오디오, 비디오, 오디오/비디오(AV) 등의 형태를 취할 수 있다. 시스템 사용자가 입출력 서브 시스템(B0)의 GUI를 통해 피드백을 시스템에 제공하기를 원하는 경우, 예컨대, 5 개의 풀 다운 메뉴를 지원하는 시스템 메뉴를 통해 몇가지 피드백 옵션이 시스템 사용자에게 이용가능해질 것이다. 도 22qq2 및 도 69c에 나타낸 바와 같이, 제1 풀 다운 메뉴는 시스템 사용자에게 다음의 메뉴 옵션을 제공한다: (i) 속도를 더 빠르게 한다; (ii) 악센트 위치를 변경한다; 및 (iii) 디스크립터 등을 변경한다. 시스템 사용자 는 이와 같은 선택 중 어느 하나를 수행할 수 있으며, 그 다음, 이 새로운 파라미터로 작곡된 음악의 새로운 조 각을 재생하도록 시스템에 요청할 수 있다. 도 69b 및 도 69c에 나타낸 바와 같이, 제2 풀 다운 메뉴는 시스템 사용자에게 다음의 메뉴 옵션을 제공한다: (i) 조각의 섹션을 새로운 섹션으로 대체한다; (ii) 새로운 섹션이 기존 파라미터를 추종하는 경우, 입력 디스 크립터 및/또는 서브 시스템 파라미터 테이블을 변경한 다음, 시스템을 다시 시작하여 조각 또는 음악을 다시 제작한다; 및 (iii) 새로운 섹션이 변경된 및/또는 새로운 파라미터를 추종하는 경우, 입력 디스크립터 및/또는 서브 시스템 파라미터 테이블을 변경한 다음, 시스템을 다시 시작하여 조각 또는 음악을 다시 제작한다. 시스템 사용자는 이와 같은 선택 중 어느 하나를 수행할 수 있으며, 그 다음, 작곡된 음악의 새로운 조각을 재생하도록 시스템에 요청할 수 있다. 도 69b 및 도 69c에 나타낸 바와 같이, 제3 풀 다운 메뉴는 시스템 사용자에게 다음의 옵션을 제공한다: (i) 다 수의 조각을 소수의 조각으로 조합한다; (ii) 조합될 음악 조각과 각 조각의 부분을 지정한다; (iii) 시스템이 지정된 섹션을 조합한다; 및 (iv) 전환 지점 분석기를 사용하고 섹션 및/또는 조각 사이에 전환을 다시 제작하 여 매끄러운 전환을 만든다. 시스템 사용자는 이와 같은 선택 중 어느 하나를 수행할 수 있으며, 그 다음, 작곡 된 음악의 새로운 조각을 재생하도록 시스템에 요청할 수 있다. 도 69b 및 도 69c에 나타낸 바와 같이, 제4 풀 다운 메뉴는 시스템 사용자에게 다음의 옵션을 제공한다: (i) 조 각을 다수의 조각으로 분할한다; (ii) 기존 조각 내에서, 각 조각에 대해 원하는 시작 및 정지 섹션을 지정한다; (iii) 각각의 새로운 조각이 자동으로 생성된다; 및 (iv) 분할 조각 분석기를 사용하고 각각의 새로 운 조각의 시작과 끝을 다시 제작하여 매끄러운 시작과 끝을 만든다. 시스템 사용자는 이와 같은 선택 중 어느 하나를 수행할 수 있으며, 그 다음, 작곡된 음악의 새로운 조각을 재생하도록 시스템에 요청할 수 있다. 도 69b 및 도 69c에 나타낸 바와 같이, 제4 풀 다운 메뉴는 시스템 사용자에게 다음의 옵션을 제공한다: (i) 다 수의 조각을 한번에 비교한다; (ii) 비교할 조각을 선택한다; (iii) 비교할 조각을 선택한다; 및 (iv) 바람직한 조각을 선택한다. 시스템 사용자는 이와 같은 선택 중 어느 하나를 수행할 수 있으며, 그 다음, 작곡된 음악의 새로운 조각을 재생하도록 시스템에 요청할 수 있다. 음악 편집성 서브 시스템(B43)의 사양 도 70은 본 발명의 자동화된 음악 작곡 및 생성 엔진(E1)에서 사용되는 음악 편집성 서브 시스템(B43)을 나타낸 다. 음악 편집성 서브 시스템(B43)은 최종 사용자 또는 컴퓨터가 결과에 만족할 때까지 작곡된 음악이 편집 및 변경될 수 있도록 허용한다. 서브 시스템(B43) 또는 사용자는 입력을 변경할 수 있으며, 이에 응답하여, 서브 시스템(B43)으로부터의 입출력 결과와 데이터가 음악 조각을 변경할 수 있다. 음악 편집성 서브 시스템(B43)은 서브 시스템(B42)으로부터의 정보를 통합함과 아울러, 별도의 비피드백 관련 정보가 포함될 수 있도록 허용한다. 예컨대, 시스템 사용자는 각각의 개별 악기 및/또는 음악 조각 전체의 볼륨을 변경할 수 있고, 조각 의 악기 편성 및 오케스트레이션을 변경할 수 있으며, 조각을 생성하는 디스크립터, 스타일 입력 및/또는 타이 밍 파라미터를 변경할 수 있고, 음악 조각을 원하는대로 더 조정할 수 있다. 시스템 사용자는 본 발명의 자동화 된 음악 작곡 및 생성 프로세스 중에 시스템을 다시 시작, 다시 실행, 변경 및/또는 재생하도록 요청할 수도 있 다. 선호도 저장기 서브 시스템(B44)의 사양 도 71는 본 발명의 자동화된 음악 작곡 및 생성 엔진(E1)에서 사용되는 선호도 저장기 서브 시스템(B44)을 나타 낸다. 선호도 저장기 서브 시스템(B44)은 시스템 사용자의 선호도를 잘 반영하기 위하여, 수정된 확률 기반 파 라미터 테이블, 논리 순서 및/또는 시스템에서 사용된 다른 요소를 변경 및/또는 교체한 다음 저장하고, 이 데 이터를 시스템의 서브 시스템에 분배한다. 이는 앞으로 나아가는 사용자의 음악적 및 비음악적 선호도를 더 정 확하게 반영하기 위해, 조각이 필요한 변화에 따라 재생될 수 있도록 허용하고, 서브 시스템이 데이터 세트, 데 이터 테이블 및 다른 정보를 조정할 수 있도록 허용한다. 도 71에 나타낸 바와 같이, 서브 시스템(B44)은 피드백 분석기, 템포 파라미터 테이블 및 변형된 템포 파라미터 테이블과, 상세하게 전술한 바와 같은 파라미터 선택 메커니즘(예컨대, 난수 발생기 또는 가사 입력 기반 파라미터 선택기)에 의해 지원된다. 피드백 분석기의 주요 기능은 음악 조각, 섹션, 악절, 또는 다른 구조(들)의 분석 및 개선을 위한 길을 결정하 는 것이다. 피드백 분석기는 사용자 또는 컴퓨터 기반 (모든 음악적 및 비음악적) 입력뿐만 아니라 멜로디, 하 모니 및 시간 기반 구조(들)를 고려하여 그 출력을 결정한다. 도 71에 반영된 예에 나타낸 바와 같이, 시스템 사용자는 음악 \"조각이 빨라야 한다\"는 피드백을 제공하고 있다. 이 시스템 사용자 피드백에 응답하여, 서브 시스템(B44)이 확률 기반 템포 파라미터 테이블을 조정함으로 써, 시스템 사용자의 요구(들)를 잘 반영하도록 템포가 조정된다. 그리고, 도 71에 나타낸 바와 같이, 서브 시스템(B44)은 변형된 템포 파라미터 테이블 및 난수 발생기를 이용하 여 음악 조각을 위한 새로운 템포를 선택하며, 이에 따라, 오리지널 템포(예컨대, 85 BPM)보다 더 빨라진다. 그 리고, 이와 같은 변경과 선호도는 사용자의 개인 프로필에 저장되며, 사용자가 시스템을 계속 사용할 때 다시 불러져 재사용되고 잠재적으로는 다시 변경될 것이다. 음악적 커널(DNA) 생성 서브 시스템(B45)의 사양 도 72는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 음악적 커널(DNA) 생성 서브 시스템(B45)을 나타낸다. 음악적 커널(DNA) 생성 서브 시스템(B45)은 임의의 다른 음악 조각으로부터 이를 구별할 수 있는 음 악 조각의 요소를 분석, 추출 및 저장한다. 음악적 커널(DNA) 생성 서브 시스템(B45)은, 음악 조각의 모든 요소 를 입력으로서 수용하고 음악 이론 기반 및 필터를 이용하여 그 출력을 결정하는 (음악적) DNA 분석기를 이용하 여, 그 기능을 수행하며, 상기 출력은 음악 조각의 DNA에 중요한 것으로 간주되는 모든 이벤트의 조직적 세트이 다. 이 입력 데이터를 이용하여, DNA 분석기는 특정 리듬, 하모니, 음색 관련 음악 이벤트, 또는 단독으로 또는 다른 이벤트와 협력하여 음악 조각에서 중요한 역할을 하는 다른 음악 이벤트를 식별 및 분리한다. 이와 같은 이벤트들은 멜로디 및 리듬 모티브와 같이 음악 조각의 매우 식별력 있는 특징이 될 수도 있다. 일반적으로, 서브 시스템(B45)은 (i) 멜로디(하위 악절 멜로디 음표 선택 순서), (ii) 하모니(즉, 악절 화음 진 행), (iii) 템포, (iv) 볼륨, 및 (v) 오케스트레이션 측면에서 음악 조각의 음악적 \"커널\"을 결정하며, 따라서, 이 음악 커널은 본 발명의 미래의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될 수 있다. 이 정보는 나중 에 음악 조각을 완전하거나 불완전한 정밀도로 복제하기 위해 사용될 수도 있다. 예컨대, 사용자가 저장된 멜로디로 나중에 새로운 조각을 제작할 수 있도록, 서브 시스템(B45)은 음악 조각의 멜로디 및 모든 관련 멜로디 및 리듬 재료를 저장할 수 있다. 또한, 조각의 제작 환경 및 데이터를 복제하기 위 해 B32로부터의 정보를 분석 및 저장할 수 있다. 사용자 취향 생성 서브 시스템(B46)의 사양 도 73는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 사용자 취향 생성 서브 시스템(B46)을 나타 낸다. 서브 시스템은 시스템 사용자 피드백과 자율적 조각 분석에 기초하여 시스템 사용자의 음악적 취향을 결 정하며, 이 음악 취향 정보는 사용자의 선호도를 잘 반영하기 위해 음악적 경험 디스크립터, 파라미터 및 테이 블 값, 논리 순서 및/또는 음악 작곡을 위한 시스템의 다른 요소를 변경 또는 수정하기 위해 사용된다. 일반적으로, 서브 시스템(B46)은 미래에 사용자 요청을 더 정확하고 신속하게 충족시키기 위해, 사용자 개인의 음악적 및 비음악적 취향을 분석하고, 음악 조각을 제작하기 위해 사용되는 데이터 세트, 데이터 테이블 및 다 른 정보를 변경한다. 예컨대, 시스템이 그럴 것이라고 믿지 않는 경우에도, 이 서브 시스템은 슬픈 음악이 생성 될 때 \"행복\" 음악에 대한 사용자의 요청이 가장 만족된다고 인식할 수 있다. 이 경우, \"행복\" 요청이 이루어지 면 이 사용자를 위해 슬픈 음악이 생성되도록, 시스템은 모든 관련 서브 시스템과 데이터를 변경하게 된다. 그 리고, 이와 같은 변경과 선호도는 사용자의 개인 프로필에 저장되며, 사용자가 시스템을 계속 사용할 때 다시 불러져 재사용되고 잠재적으로는 다시 변경될 것이다. 도 73에 나타낸 바와 같이, 서브 시스템(B46)은 그 기능을 수행하기 위해 사용자 취향 분석기와 다양한 파라미 터 테이블을 시스템 전체에 채택한다. 도 73에 나타낸 바와 같이, 사용자 취향 분석기는 자율적 조각 분석을 수행하고, 시스템 사용자 피드백을 이용 하여, 서브 시스템(B46)은 시스템 사용자의 선호도를 잘 반영하기 위해 시스템 사용자의 시스템 디스크립터, 파 라미터 및 테이블 값을 변경한다. 도 73에 나타낸 바와 같이, 사용자가 로맨틱 디스크립터로 특징지어진 음악 조각을 검토하기 위해 요청함으로써 피드백을 제공하는 경우, 시스템은 로맨틱으로 특징지어진 시스템 사용자의 노래를 반환할 수 있다. 도시된 바 와 같이, 시스템 사용자에 의해 생성된 제1 조각이 현악기를 포함하고 시스템 사용자가 서브 시스템(B46)에 피 드백-덜 감상적으로-을 제공하는 사례를 고려하기로 한다. 이에 응답하여, 서브 시스템(B46)은 그 기능을 수행하고, 조각이 다시 제작된다. 생성된 제2 조각은 현악기를 일렉트릭 기타로 대체한다. 이에 응답하여, 시스템 사용자는 서브 시스템(B46)에 피드백-더 로맨틱하게-을 제공 한다. 이에 응답하여, 서브 시스템(B46)은 그 기능을 수행하고, 조각이 다시 제작된다. 생성된 제3 조각은 일렉 트릭 기타에 피아노를 추가하고, 시스템 사용자는 서브 시스템(B46)에 피드백-완벽한-을 제공한다. 이에 응답하 여, 서브 시스템(B46)은 로맨틱 디스크립터로 이 시스템 사용자를 위한 악기 편성 파라미터 테이블을 변경함으 로써, 악기 편성 프로세스 중에 일렉트릭 기타와 피아노가 사용될 확률을 증가시키고 현악기를 사용할 확률을 감소시킨다. 모집단 취향 집계기 서브 시스템(B47)의 사양 도 74는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 모집단 취향 집계기 서브 시스템(B47)을 나 타낸다. 모집단 취향 서브 시스템(B47)은 미래에 모든 사용자 요청을 더 정확하고 신속하게 충족시키기 위해, 모든 사용자 개인의 음악적 및 비음악적 취향을 분석하고, 음악 조각을 제작하기 위해 사용되는 데이터 세트, 데이터 테이블 및 다른 정보를 변경한다. 일반적으로, 서브 시스템(B47)은 모집단의 음악 취향을 집계하여 음악 적 경험 디스크립터로 변경하고, 이에 응답하여, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 테이블 확률이 변경될 수 있다. 예컨대, 시스템이 그럴 것이라고 믿지 않는 경우에도, 이 서브 시스템은 슬픈 음악이 생성될 때 \"행복\" 음악에 대한 전체 사용자 기반의 요청이 가장 만족된다고 인식할 수 있다. 이 경우, \"행복\" 요청이 개인 사용자에 의해 이루어지면 전체 사용자 기반을 위해 슬픈 음악이 생성되도록, 시스템은 모든 관련 서브 시스템과 데이터를 변 경하게 된다. 그리고, 이와 같은 변경과 선호도는 모집단 수준으로 저장되며, 시스템 사용자들이 시스템을 계속 사용할 때 다시 불러져 재사용되고 잠재적으로는 다시 변경될 것이다. 도 74에 나타낸 바와 같이, 모집단 취향 서브 시스템(B47)은 모든 사용자 피드백을 컴파일링 및 조직화하고 디 스크립터, 파라미터 테이블 값 및 다른 피드백을 포함하는 것을 돕는 모집단 취향 집계기를 채택한다. 도 74의 프로세스 도면에서는, 음악적 경험 디스크립터-로맨틱에 대한 사례가 고려된다. 도 74에 나타낸 이 예 에서, 모집단은 음악 조각의 악기 편성에 대한 피드백을 제공하였다. 이 피드백에 반응하여, 모집단 취향 서브 시스템(B47)은 사용자의 요구(들)를 잘 반영하기 위해 시스템의 악기 편성 서브 시스템(들) 내에 있는 확률 파 라미터 테이블에서 템포를 조정한다. 나타낸 바와 같이, 사용자 1의 피드백은 그녀/그가 현악기를 좋아하지 않 았고 일렉트릭 기타를 좋아했으며 피아노를 좋아한다는 것이다. 사용자 s의 피드백은 그녀/그가 현악기를 좋아 하지 않았고 일렉트릭 기타를 좋아했으며 오르간을 좋아한다는 것이다. 사용자 s의 피드백은 그녀/그가 현악기 를 좋아하지 않았고 일렉트릭 기타를 좋아했으며 피아노를 좋아한다는 것이다. 이에 응답하여, 서브 시스템 (B47)은 로맨틱 음악적 경험 디스크립터를 선택한 사용자를 위해 악기 편성 테이블에서 템포에 대한 확률 파라 미터를 변경함으로써, 악기 편성 프로세스 중에 일렉트릭 기타와 피아노의 확률을 증가시키고 현악기가 선택될 확률을 감소시킨다. 도 74에 나타낸 바와 같이, 이 사례에서, 서브 시스템(B47)은 로맨틱을 선택하는 시스템 사용자를 위해 악기 편 성 파라미터 테이블에 대해 다음과 같은 변경을 행한다: (i) 악기 편성 중에 현악기 카테고리를 선택할 확률을 감소시킨다; (ii) 기타 카테고리를 선택할 확률을 증가시키고, 이 카테고리 내에서, 일렉트릭 기타를 선택할 확 률을 크게 증가시키며, 어쿠스틱 기타를 선택할 확률을 미묘하게 증가시킨다; 그리고 (iii) 키보드 악기 카테고 리를 선택할 확률을 증가시키고, 그 카테고리 내에서, 피아노를 선택할 확률을 크게 증가시키며, 오르간을 선택 할 확률을 미묘하게 증가시킨다. 나타낸 바와 같이, 서브 시스템(B47)을 이용하면, 사용자 모집단의 선호도를 잘 반영하기 위해, 시스템 사용자 및 컴퓨터 피드백이 모두 시스템의 확률 테이블, 논리 순서 및/또는 다른 요소를 확인 및/또는 변경하기 위해 사용된다. 사용자 선호도 서브 시스템(B48)의 사양 도 75는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 사용자 선호도 서브 시스템(B48)을 나타낸다. 사용자 선호도 서브 시스템(B48)은 미래에 임의의 사용자 요청을 더 정확하고 신속하게 충족시키기 위해, 모든 시스템 구성 요소로부터의 각 사용자 관련 데이터 및 선호도를 저장한다. 그리고, 이 시스템 사용자선호도(예컨대, 음악적 경험 디스크립터, 테이블 파라미터)는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 75에 나타낸 바와 같이, 시스템 사용자 선호도를 잘 만족시키는데 시스템이 미래에 사용하기 위해, 서브 시 스템(B48)은 (GUI 기반 서브 시스템(B0)으로부터 선택된) 시스템 사용자 음악적 경험 디스크립터 파라미터, 파 라미터 테이블 값 및 다른 선호도를 입력으로서 수신하여 저장한다. 도 75에 나타낸 바와 같이, 작동 중에, 서브 시스템(B48)이 서브 시스템(B1, B37, B40 및/또는 B41)으로부터 로 드된 디폴트 확률 기반 파라미터 테이블을 사용자 특정의 변경된 디폴트 파라미터 테이블로 변화시킴으로써, 변 경된 디폴트 테이블이 특정 시스템 사용자 요청을 더 정확하고 효율적으로 만족시킬 것이다. 모집단 선호도 서브 시스템(B49)의 사양 도 76는 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 모집단 선호도 서브 시스템(B49)을 나타낸다. 모집단 선호도 서브 시스템(B49)은 미래에 임의의 사용자들의 요청을 정확하고 신속하게 충족시키기 위해, 모든 시스템 구성 요소로부터의 모든 사용자 관련 데이터 및 선호도를 저장한다. 모집단 저장기 서브 시 스템은 모집단의 선호도를 잘 반영하기 위하여, 확률 테이블, 논리 순서 및/또는 시스템의 다른 요소를 변경 및 /또는 교체한다. 그리고, 모집단 선호도(예컨대, 음악적 경험 디스크립터, 테이블 파라미터)에 대한 이와 같은 변경은 모집단의 프로필(들)에 저장되고, 모집단이 시스템을 계속 사용할 때 다시 불러져 재사용되고 잠재적으 로는 다시 변경될 것이다. 도 76에 나타낸 바와 같이, 모집단 선호도를 잘 만족시키는데 시스템이 미래에 사용하기 위해, 서브 시스템 (B49)은 (GUI 기반 서브 시스템(B0)으로부터 선택된) 시스템 사용자 음악적 경험 디스크립터 파라미터, 파라미 터 테이블 값 및 다른 선호도를 입력으로서 수신하여 저장한다. 도 76에 나타낸 바와 같이, 작동 중에, 서브 시스템(B49)이 서브 시스템(B1, B37, B40 및/또는 B41)으로부터 로 드된 디폴트 확률 기반 파라미터 테이블을 사용자 모집단 유도의 변경된 디폴트 파라미터 테이블로 변화시킴으 로써, 변경된 디폴트 테이블이 특정 사용자 모집단 요청을 더 정확하고 효율적으로 만족시킬 것이다. 본 발명의 파라미터 변환 엔진 서브 시스템(B51)에 채택된 파라미터 변환 원리의 개요 본 발명의 시스템 및 방법을 실시하는 경우, 본 발명의 원리에 따른 파라미터 변환 엔진 서브 시스템(B51)을 설 계, 구축 및 작동할 때 후술하는 다양한 원리를 이용할 것이다. 본 발명의 본질은 음악 또는 음악 이론에 대한 형식적인 지식을 전혀 필요로 하지 않고 작곡될 음악의 감정, 스타일 및 타이밍 양태를 시스템 사용자(예컨대, 고급 컴퓨팅 머신과 아울러 인간)가 특정할 수 있도록 허용하거나 권한을 부여하는 것이다. 그러나, 이 목표를 실현하기 위해서, 본 발명의 시스템은 시스템 사용자 입력이 확률 가중 음악 이론 파라미터로 변환되는 파라미 터 변환 엔진(B51) 내에서 강하게 실행되는 강력하고 풍부한 음악 이론 개념과 원리를 채택할 필요가 있으며, 확률 가중 음악 이론 파라미터는 시스템 작동 파라미터(SOP) 테이블에 로드되어, 적절한 시스템 작동을 위해 특 별히 의도되고 요구되는 다양한 서브 시스템 전반에 분배되어 로드된다. 서브 시스템(B2)의 파라미터 테이블에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변 환 사용자가 조각 길이를 제공하는 경우에는, 길이 파라미터 테이블이 사용되지 않는다. 사용자가 조각 길이를 제 공하지 않는 경우에는, 시스템 파라미터 테이블이 조각 길이를 결정한다. 음악이 기존 컨텐츠를 반주하기 위해 생성되고 있는 경우, 그 길이는 기존 콘텐츠의 길이가 되도록 디폴트된다. 음악이 기존 컨텐츠를 반주하기 위해 생성되고 있지 않은 경우, 그 길이는 음악적 감정 및 스타일 디스크립터 입력에 기초한 길이와 확률을 가진 확 률 테이블에 따라 결정된다. 예컨대, 팝 음악은 3분의 길이를 가질 50%의 기회, 2분의 길이를 가질 25%의 기회 및 4분의 길이를 가질 25%의 기회를 가질 수 있는 반면, 클래식은 6분의 길이를 가질 50%의 기회, 5분의 길이를 가질 25%의 기회 및 7분의 길이를 가질 25%의 기회를 가질 수 있다. 서브 시스템(B3)의 파라미터 테이블에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변 환 일반적으로, 감정 및 스타일 디스크립터와 템포 사이에는 강한 관계가 있다. 예컨대, 행복으로 분류된 음악은 흔히 중간 정도에서 빠른 템포로 연주되는 반면, 슬픔으로 분류된 음악은 흔히 더 느린 템포로 연주된다. 시스 템의 템포 테이블은 음악적 경험 및/또는 스타일과 재료가 전달되는 속도 사이의 문화적 연관성을 반영한다. 빠 른 방식으로 말하는 음성은 흔히 성급하거나 서두르는 것으로 인식되며, 느린 방식으로 말하는 음성은 흔히 신중하거나 차분한 것으로 인식되므로, 템포는 전달되는 콘텐츠의 매체에 구속되지도 않는다. 또한, 음악 조각의 템포(들)는 감정 및 스타일 디스크립터 입력에 무관할 수 있으며, 단지 특정 타이밍 요청과 음악의 마디 및/또는 비트를 정렬하기 위해 존재할 수 있다. 예컨대, 특정 템포의 음악 조각이 마디의 네 번째 비트와 다음 마디의 첫 번째 비트 사이의 어딘가에서 발생하였을 조각 내의 순간에 악센트를 넣을 필요가 있을 경우, 원하는 악센트에 한 마디 앞서 템포를 증가시키면, 마디의 첫 번째 비트에서 악센트가 정확하게 대신 발 생하게 될 것이며, 이는 마디의 다운비트와 일치하는 보다 음악적인 악센트에 적합할 것이다. 서브 시스템(B4)의 파라미터 테이블에 유지된 시스템 작동 파라미터로의 음악적 경험 파라미터의 변환 감정 및 스타일 디스크립터와 박자 사이에는 강한 관계가 있다. 예컨대, 왈츠는 흔히 3/4 박자로 연주되는 반면, 행진곡은 흔히 2/4 박자로 연주된다. 시스템의 박자 테이블은 음악적 경험 및/또는 스타일과 재료가 전달 되는 박자 사이의 문화적 연관성을 반영한다. 또한, 음악 조각의 박자(들)는 감정 및 스타일 디스크립터 입력에 무관할 수 있으며, 단지 특정 타이밍 요청과 음악의 마디 및/또는 비트를 정렬하기 위해 존재할 수 있다. 예컨대, 특정 템포의 음악 조각이 4/4 마디의 네 번째 비트와 다음 4/4 마디의 첫 번째 비트 사이의 중간에 발생하였을 조각 내의 순간에 악센트를 넣을 필요가 있을 경우, 원하는 악센트에 한 마디 앞서 7/8로 박자를 변화시키면, 마디의 첫 번째 비트에서 악센트가 정확하 게 대신 발생하게 될 것이며, 이는 마디의 다운비트와 일치하는 보다 음악적인 악센트에 적합할 것이다. 상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B4)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터(SOP) 테이블에 저장된 특정 음악 이론 파라 미터(즉, 값) 사이의 \"변환 매핑\"(즉, 통계적 또는 이론적 관계)을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 서브 시스템(B5)의 파라미터 테이블에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변 환 감정 및 스타일 디스크립터와 키 사이에는 강한 관계가 있다. 예컨대, 팝 음악은 흔히 올림음이 전혀 없거나 약 간 있는 키(예컨대, C, G, D, A, E)로 연주되는 반면, 에픽 음악은 흔히 내림음이 약간 있거나 많은 키(예컨대, F, Bb, Eb, Ab)로 연주된다. 시스템의 키 테이블은 음악적 경험 및/또는 스타일과 재료가 전달되는 키 사이의 문화적 연관성을 반영한다. 또한, 음악 조각의 키(들)는 감정 및 스타일 디스크립터 입력에 무관할 수 있으며, 단지 타이밍 요청을 반영하 기 위해 존재할 수 있다. 예컨대, 조각의 긴장을 높일 필요가 있는 순간에, 키를 단삼도 위로 조정하면 이와 같 은 결과를 달성할 수 있다. 또한, 특정 악기는 특정 키로 더 잘 연주하고, 키의 결정은 어떤 악기가 특정 스타 일로 연주할 가능성이 높은지를 고려할 수 있다. 예컨대, 바이올린이 연주할 가능성이 높은 클래식 스타일에서, 내림음보다는 올림음이 전혀 없거나 약간 있는 키로 음악 조각을 제작하는 것이 훨씬 더 바람직할 것이다. 서브 시스템(B0)을 통해 시스템 사용자가 선택한 모든 입력을 고려하여, 키 생성 서브 시스템(B5)은 조각의 키 (들)를 생성한다. 예컨대, \"행복\" 입력 디스크립터를 갖고, 길이가 30초이며, 템포가 60BPM이고, 박자가 4/4인 조각은 C 키(또는 1-12 음계에서 1, 또는 1-11 음계에서 0)를 사용할 1/3의 확률, G 키(또는 1-12 음계에서 8, 또는 1-11 음계에서 7)를 사용할 1/3의 확률, 또는 A 키(또는 1-12 음계에서 10, 또는 1-11 음계에서 9)를 사용 할 1/3의 확률을 가질 수 있다. 음악 내에 다수의 섹션, 음악 타이밍 파라미터 및/또는 시작 및 정지가 있는 경 우, 다수의 키가 선택될 수 있다. 상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B5)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터(SOP) 테이블에 저장된 특정 음악 이론 파라 미터(즉, 값) 사이의 \"변환 매핑\"(즉, 통계적 또는 이론적 관계)을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 서브 시스템(B7)의 파라미터 테이블에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변 환 감정 및 스타일 디스크립터와 조성 사이에는 강한 관계가 있다. 예컨대, 행복한 음악은 흔히 메이저 조성으로 연주되는 반면, 슬픈 음악은 흔히 마이너 조성으로 연주된다. 시스템의 키 테이블은 음악적 경험 및/또는 스타일과 재료가 전달되는 조성 사이의 문화적 연관성을 반영한다. 또한, 음악 조각의 조성(들)은 감정 및 스타일 디스크립터 입력에 무관할 수 있으며, 단지 타이밍 요청을 반영 하기 위해 존재할 수 있다. 예컨대, 긴장 기간에서 축하 기간으로 전환할 필요가 있는 순간에, 조성을 마이너에 서 메이저로 변경하면 이와 같은 결과를 달성할 수 있다. 사용자는 생성될 음악 조각의 조성을 알거나 선택할 필요가 없다. 조성은 문화적 카논과 직접 연관성을 갖고, 이 테이블을 채우는 파라미터와 확률은 이 역사에 대한 깊은 지식과 이해를 기반으로 한다. 예컨대, 행복한 음 악은 흔히 메이저 조성으로 생성되고, 슬픈 음악은 흔히 마이너 조성으로 생성되며, 장난기 있는 음악은 흔히 리디안 조성으로 생성된다. 사용자의 음악적 감정 및 스타일 디스크립터 입력은 어떤 조성이 음악 조각에 가능 한 옵션인지를 결정하고 각각의 확률이 어떻게 될지를 결정할 책임이 있다. 상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B7)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터(SOP) 테이블에 저장된 특정 음악 이론 파라 미터(즉, 값) 사이의 \"변환 매핑\"(즉, 통계적 또는 이론적 관계)을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 서브 시스템(B9)의 파라미터 테이블에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변 환 형태가 비거나, 조직되지 않았거나, 존재하지 않는다 하더라도, 모든 음악은 형태를 갖는다. 팝 음악은 전통적 으로 인트로, 버스, 코러스, 브릿지, 솔로, 아우트로 등을 포함한 형태 요소를 갖는다. 또한, 노래 형태 악절은 악절 자체 내의 노래에 구조를 제공하는 하위 악절을 가질 수 있다. 음악의 각 스타일은 스타일과 쉽게 연관되는 형태 구조를 확립하였다. 팝 음악 외에, 고전 소나타는 제시부 발 전부 재현부(물론, 이는 단순화됨)의 형태를 가질 수 있으며, 재현부는 제시부의 변형된 표현이다. 이는 ABA'로 표현될 수 있으며, '은 오리지널 \"A\" 재료의 변형된 표현을 의미한다. 노래 형태는 음악 조각의 길이에 의해서도 결정된다. 음악 조각이 길면, 조각의 형태에 대해 존재하는 유연성과 옵션이 더 커진다. 대조적으로, 5초의 음악 조각은 현실적으로 몇 가지 제한된 형태 옵션(흔히, 단일의 A 형 태)만을 가질 수 있다. 또한, 타이밍 이벤트는 노래 형태에 영향을 미칠 수 있다. 음악 조각에서 큰 변화를 나 타낼 필요가 있는 경우, 코러스 또는 B 섹션이 이 변화를 효과적으로 만들 수 있다. 감정도 역시 노래 형태에 영향을 미칠 수 있다. 예컨대, 연가로 기술된 노래는 문화적 카논을 따라 그와 연관된 전형적인 형태를 가질 수 있는 반면, 셀틱이라고 기술된 노래는 매우 다른 노래 형태를 가질 수 있다. 상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B9)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터 테이블에 저장된 특정 음악 이론 파라미터 사이의 변환 매핑을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 서브 시스템(B15)의 파라미터 테이블에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변 환 일반적으로, 하위 악절 길이는 (i) 악절의 전체 길이(즉, 2초의 악절은 200초의 악절보다 훨씬 적은 하위 악절 옵션을 가질 것임), (ii) 조각의 타이밍 필요 요소(즉, 파라미터), 및 (iii) 스타일 및 감정 타입 음악적 경험 디스크립터에 의해 결정된다. 하위 악절 길이의 양, 길이, 및 확률은 음악 조각을 제작할 때 서로 가장 잘 맞는 전술한 특성의 조합에 대한 지식과 조각 길이에 의존한다. 하위 악절 길이는 시스템 사용자에 의해 제공되는 감정 및 스타일 디스크립터에 의해 영향을 받는다. 예컨대, 행복한 타입의 음악은 더 짧은 하위 악절 길이를 필요로 할 수 있는 반면, 슬픈 타입의 음악은 더 긴 하위 악절 길이를 필요로 할 수 있다. 하위 악절의 양이 많으면, 각각 매우 긴 길이를 가질 가능성이 적다. 그리고, 하위 악절의 양이 적으면, 각각 매우 긴 길이를 가질 가능성이 많다. 또한, 어떤 하위 악절이 결정될 때, 미래의 하위 악절 결정 및 관련 파라미터가 이용가능한 나머지 길이를 반영 하도록 변경될 수 있으므로, 하위 악절은 음악 조각 및 특정 악절의 길이 내에 맞아야 한다.음악이 사용자의 요청에 자연스럽게 맞도록, 하위 악절은 사용자가 요청한 타이밍 정보를 중심으로 구성될 수도 있다. 예컨대, 사용자가 조각 내에 2개의 마디가 있도록 음악에서의 변화를 요청하는 경우, 하위 악절 길이가 2 마디일 수 있는 완전 100%의 확률로 인해, 제1 하위 악절 길이는 2 마디일 수 있다. 이 파라미터 변환 엔진 서브 시스템(B51)은 시스템의 이전의 모든 프로세스에서의 입력에 기초하여 모든 시스템 사용자 입력 파라미터를 분석한 다음, 리듬 및 길이의 확률 가중 데이터 세트를 생성하여 SOP 테이블에 로드한 다. 이 입력을 고려하여, 이 시스템은 조각의 하위 악절 길이를 생성한다. 예컨대, 30초의 음악 조각은 각각 7.5초인 4개의 서브 섹션, 10초인 3개의 서브 섹션, 또는 4초, 5초, 6초, 7초 및 8초인 5개의 서브 섹션을 가질 수 있다. 상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B15)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터 테이블에 저장된 특정 음악 이론 파라미터 사이의 변환 매핑을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 서브 시스템(B11)의 파라미터 테이블에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변 환 감정 및 스타일 디스크립터와 화음 길이 사이에는 강한 관계가 있다. 예컨대, 광분하는 음악은 자주 변하는 매 우 짧은 화음 길이를 가질 가능성이 있는 반면, 사색적인 음악은 훨씬 덜 자주 변하는 매우 긴 화음 길이를 가 질 수 있다. 시스템의 길이 테이블은 음악적 경험 및/또는 스타일과 재료가 전달되는 조성 사이의 문화적 연관 성을 반영한다. 또한, 각 화음의 길이는 이전의 모든 화음의 길이; 동일한 마디, 악절 및 하위 악절 내의 다른 화음의 길이; 및 미래에 발생할 수 있는 화음의 길이에 의존한다. 제2 화음의 길이가 제1 화음의 길이에 의해 영향을 받고, 제3 화음의 길이가 제1 및 제2 화음의 길이에 의해 영향을 받도록 하는 식으로, 특정 화음의 길이에 대한 결정에 각 각의 선행하는 화음 길이 결정 인자가 고려된다. 상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B11)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터 테이블에 저장된 특정 음악 이론 파라미터 사이의 변환 매핑을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 서브 시스템(B17)의 파라미터 테이블에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변 환 감정 및 스타일 디스크립터와 제1 화음 사이에는 강한 관계가 있다. 예컨대, 전통적인 음악 조각은 음악 조각의 키와 동일한 밑음 음표로 시작할 수 있는 반면, 더 창의적인 음악 조각은 조각의 키와 특별히 동일하지 않은 밑 음 음표로 시작할 수 있다. 밑음 음표가 선택되면, 화음의 기능이 결정되어야 한다. 대부분의 경우, 화음의 기능은 선택된 키 및 조성의 온 음계에서 삼화음이 생성되는 경우 발생하게 되는 것이다. 예컨대, C 메이저에서 C 화음은 흔히 I 화음으로서 기 능할 것이며, C 메이저에서 G 화음은 흔히 V 화음으로서 기능할 것이다. 화음의 기능이 결정되면, 특정 화음 음 표가 지정된다. 예컨대, C 화음이 I 화음으로서 기능하도록 결정되면, 음표는 C E G가 되도록 결정되고, D 화음 이 ii 화음으로서 기능하도록 결정되면, 음표는 C F A가 되도록 결정된다. 음악 조각의 제1 화음 밑음 음표는 시스템에 대한 감정 및 스타일 디스크립터 입력에 기초한다. 음악 카논은 다 양한 음악 타입으로 나타나도록 특정 제1 밑음 음표에 대한 문화적 기대를 생성하였다. 예컨대, 팝 음악은 흔히 C 메이저의 키에서 밑음이 C인, 0의 밑음으로 시작한다. 제1 밑음 음표가 선택되면, 제1 밑음 음표를 포함하게 될 화음의 기능이 결정되어야만 한다. C 메이저의 키에서, C인 밑음 음표는 밑음에 구축된 메이저 또는 마이너 삼화음 중 어느 하나를 합리적으로 가질 수 있다. 이로 인해, \"I\" 메이저 화음 또는 \"i\" 마이너 화음의 기능성 이 도출될 것이다. 또한, \"I\" 메이저 화음은 \"I\" 메이저 화음과 동일한 소리를 낼 수는 있지만 다른 의도로 다 르게 기능하는 \"V/V\" 메이저 화음으로서 실제로 기능할 수 있다. 이 기능이 결정되면, 화음의 기능이 화음을 구 성하게 될 음표들의 시스템을 알려주기 때문에, 이제 제1 화음을 알게 된다. 예컨대, 임의의 \"I\" 메이저 삼화음 은 음계의 밑음, 제3 및 제5 음표, 또는 C 메이저의 키로 구성될 것이며, C 메이저 삼화음은 C, E 및 G 음표로 구성될 것이다.상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B17)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터 테이블에 저장된 특정 음악 이론 파라미터 사이의 변환 매핑을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 서브 시스템(B19)의 파라미터 테이블에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변 환 감정 및 스타일 디스크립터와 화음 진행 사이에는 강한 관계가 있다. 예컨대, 팝 음악 조각은 C A F G의 하위 악절 화음 진행을 가질 수 있는 반면, 복음 음악 조각은 C F C F의 하위 악절 화음 진행을 가질 수 있다. 또한, 진행의 화음 밑음은 이전의 모든 화음의 화음 밑음; 동일한 마디, 악절 및 하위 악절 내의 다른 화음의 화음 밑음; 및 미래에 발생할 수 있는 화음의 화음 밑음에 의존한다. 제2 화음의 밑음이 제1 화음의 밑음에 의 해 영향을 받고, 제3 화음의 밑음이 제1 및 제2 화음의 밑음에 의해 영향을 받도록 하는 식으로, 특정 화음의 밑음에 대한 결정에 각각의 선행하는 화음 밑음 결정 인자가 고려된다. 화음의 밑음이 결정되면, 전술한 바와 같이 화음의 기능이 결정된다. 그리고, 화음의 기능은 화음 밑음 테이블 에 직접적으로 영향을 미칠 것이며, 이에 따라, 화음 밑음이 미래에 선택될 수 있는 디폴트 랜드스케이프를 변 경하게 될 것이다. 예컨대, I 화음으로서 기능하는 C 메이저 키의 C 메이저 화음은 디폴트 랜드스케이프를 추종 할 것인 반면, Ⅴ/Ⅳ 화음으로서 기능하는 C 메이저 키의 C 메이저 화음은 다음 화음이 Ⅳ 화음(또는 합리적으 로 대체 또는 변경)이 될 수 있도록 안내하는 변경된 랜드스케이프를 추종할 것이다. 또한, 음악 조각, 악절, 하위 악절 및 마디에서의 다음 화음의 위치는 화음 밑음이 미래에 선택될 수 있는 디폴 트 랜드스케이프에 영향을 미친다. 예컨대, 악절의 끝에 있는 다운비트에 앞서는 화음은 후속 화음이 I 화음이 나 화음 진행을 정확하게 해결하는 다른 화음이 되도록 보장할 수 있다. 지금까지의 음악의 문화적 카논에 기초하여, 감정 및 스타일 디스크립터는 음악 조각에서의 화음들의 어떤 연관 성 또는 진행으로 잘 표현되거나 제시될 수 있다. 다음에 선택되어야 하는 화음을 결정하기 위해, B17의 방식과 유사한 방식으로 후속 화음 밑음이 먼저 결정된다. 각각의 가능한 오리지널 화음 밑음을 위해, 각각의 가능한 후속 화음 밑음에 대한 확률이 확립되었으며, 이 확률은 구체적으로는 사용자에 의해 선택된 감정 및 스타일 디 스크립터에 기초하게 된다. 다음으로, 역시 B17의 방식과 유사한 방식으로, 화음의 기능이 선택된다. 화음의 기능은 화음이 추종할 가능성 이 있는 것에 영향을 미칠 것이며, 이에 따라, 화음 변조기 테이블은 기능이 선택되는 기반이 되는 화음 밑음 테이블의 확률에 대해 변화를 제공한다. 이와 같은 방식으로, 화음 기능은 다음에 선택되는 화음 밑음에 직접적 으로 영향을 미칠 것이다. 다음으로, 화음의 시간 및 공간에서의 위치가 고려되는데, 그 이유는 이 인자가 선택되는 화음 밑음 음표와 강 한 관계를 갖기 때문이다. 화음이 선택될 마디 내의 다음 비트에 기초하여, 화음 밑음 음표 테이블 파라미터가 더 변경된다. 이 사이클은 음악 조각에 대해 모든 화음이 선택될 때까지 되풀이하여 재생된다. 상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B19)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터 테이블에 저장된 특정 음악 이론 파라미터 사이의 변환 매핑을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 감정 및 스타일 디스크립터와 화음 진행 사이에는 강한 관계가 있다. 예컨대, 팝 음악 조각은 C A F G의 하위 악절 화음 진행을 가질 수 있는 반면, 복음 음악 조각은 C F C F의 하위 악절 화음 진행을 가질 수 있다. 또한, 진행의 화음 밑음은 이전의 모든 화음의 화음 밑음; 동일한 마디, 악절 및 하위 악절 내의 다른 화음의 화음 밑음; 및 미래에 발생할 수 있는 화음의 화음 밑음에 의존한다. 제2 화음의 밑음이 제1 화음의 밑음에 의 해 영향을 받고, 제3 화음의 밑음이 제1 및 제2 화음의 밑음에 의해 영향을 받도록 하는 식으로, 특정 화음의 밑음에 대한 결정에 각각의 선행하는 화음 밑음 결정 인자가 고려된다. 화음의 밑음이 결정되면, 전술한 바와 같이 화음의 기능이 결정된다. 그리고, 화음의 기능은 화음 밑음 테이블 에 직접적으로 영향을 미칠 것이며, 이에 따라, 화음 밑음이 미래에 선택될 수 있는 디폴트 랜드스케이프를 변 경하게 될 것이다. 예컨대, I 화음으로서 기능하는 C 메이저 키의 C 메이저 화음은 디폴트 랜드스케이프를 추종 할 것인 반면, Ⅴ/Ⅳ 화음으로서 기능하는 C 메이저 키의 C 메이저 화음은 다음 화음이 Ⅳ 화음(또는 합리적으로 대체 또는 변경)이 될 수 있도록 안내하는 변경된 랜드스케이프를 추종할 것이다. 또한, 음악 조각, 악절, 하위 악절 및 마디에서의 다음 화음의 위치는 화음 밑음이 미래에 선택될 수 있는 디폴 트 랜드스케이프에 영향을 미친다. 예컨대, 악절의 끝에 있는 다운비트에 앞서는 화음은 후속 화음이 I 화음이 나 화음 진행을 정확하게 해결하는 다른 화음이 되도록 보장할 수 있다. 서브 시스템(B20)의 파라미터 테이블에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변 환 경험(즉, 감정) 및 스타일 디스크립터와 화음 자리바꿈 사이에는 강한 관계가 있다. 예컨대, 록 음악 조각은 도 미넌트 으뜸음(tonic)의 화음 자리바꿈을 가질 수 있는 반면, 클래식 음악 조각은 으뜸음, 제1 자리바꿈 및 제2 자리바꿈의 훨씬 더 다양한 혼합으로 구성된 화음 자리바꿈을 가질 수 있다. 제1 화음의 자리바꿈이 결정된다. 나아가, 모든 이전의 자리바꿈 결정은 모든 미래의 자리바꿈 결정에 영향을 미친다. 음악 조각, 악절, 하위 악절 및 마디에서의 다음 화음 자리바꿈은 화음 자리바꿈이 미래에 선택될 수 있는 디폴트 랜드스케이프에 영향을 미친다. 상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B20)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터 테이블에 저장된 특정 음악 이론 파라미터 사이의 변환 매핑을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 서브 시스템(B25)의 파라미터 테이블에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변 환 감정 및 스타일 디스크립터와 멜로디 길이 사이에는 강한 관계가 있다. 예컨대, 클래식 음악 조각은 (클래식 음 악의 더 긴 형태에 적절한) 긴 멜로디 길이를 가질 수 있는 반면, 팝 음악 조각은 (팝 음악의 더 짧은 형태에 적절한) 더 짧은 멜로디 길이를 가질 수 있다. 멜로디 길이에 대한 하나의 중요한 고려 사항은 하위 악절에서 멜로디가 시작하는 위치를 결정하는 것이다. 하위 악절에서 멜로디가 뒤에서 시작할 수록, 거기에 있을 가능성 이 낮아진다. 또한, 멜로디 하위 악절 길이는 감정 및 스타일 디스크립터 입력에 무관할 수 있으며, 단지 특정 타이밍 요청과 음악의 마디 및/또는 비트를 정렬하기 위해 존재할 수 있다. 예컨대, 음악 조각이 하위 악절의 중간 어딘가에서 발생하였을 조각 내의 순간에 악센트를 넣을 필요가 있을 경우, 이 장소에서 멜로디를 시작하면, 생성하기 위해 추가적인 조각 조작이 필요하였을 보다 음악적인 악센트를 생성할 수 있다. 멜로디 하위 악절 길이는 사용자에 의해 제공된 음악 감정 및 스타일 디스크립터에 기초하여 결정된다. 멜로디 하위 악절 길이의 양, 길이, 및 확률은 조각 길이, 특이 하위 악절, 악절 길이, 및 음악 조각을 제작할 때 서로 가장 잘 맞는 전술한 특성의 조합에 대한 지식에 의존한다. 멜로디 하위 악절의 양이 많으면, 각각 매우 긴 길이를 가질 가능성이 적다. 그리고, 멜로디 하위 악절의 양이 적으면, 각각 매우 긴 길이를 가질 가능성이 많다. 또한, 어떤 멜로디 하위 악절이 결정될 때, 미래의 멜로디 하위 악절 결정 및 관련 파라미터가 이용가능한 나머 지 길이를 반영하도록 변경될 수 있으므로, 멜로디 하위 악절은 음악 조각 및 특정 악절의 길이 내에 맞아야 한 다. 음악이 사용자의 요청에 자연스럽게 맞도록, 멜로디 하위 악절은 사용자가 요청한 타이밍 정보를 중심으로 구성 될 수도 있다. 예컨대, 사용자가 조각 내에 3개의 마디가 있도록 음악에서의 변화를 요청하는 경우, 멜로디 하 위 악절 길이가 2 마디일 수 있는 완전 100%의 확률로 인해, 제1 멜로디 하위 악절 길이는 3 마디일 수 있다. 상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B25)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터 테이블에 저장된 특정 음악 이론 파라미터 사이의 변환 매핑을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 서브 시스템(B26)에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변환 감정 및 스타일 디스크립터와 멜로디 음표 리듬 사이에는 강한 관계가 있다. 예컨대, 광분하는 음악은 자주 변 하는 매우 짧은 멜로디 음표 리듬을 가질 가능성이 있는 반면, 사색적인 음악은 훨씬 덜 자주 변하는 매우 긴 화음 길이를 가질 수 있다. 시스템의 리듬 테이블은 음악적 경험 및/또는 스타일과 재료가 전달되는 조성 사이 의 문화적 연관성을 반영한다. 또한, 각 멜로디 음표의 리듬은 이전의 모든 멜로디 음표의 리듬; 동일한 마디, 악절 및 하위 악절 내의 다른 멜로디 음표의 리듬; 및 미래에 발생할 수 있는 멜로디 음표의 멜로디 리듬에 의존한다. 제2 멜로디 음표의 리 듬이 제1 멜로디 음표의 리듬에 의해 영향을 받고, 제3 멜로디 음표의 리듬이 제1 및 제2 멜로디 음표의 리듬에 의해 영향을 받도록 하는 식으로, 특정 멜로디 음표의 리듬에 대한 결정에 각각의 선행하는 멜로디 음표 리듬 결정 인자가 고려된다. 또한, 각 멜로디 음표의 길이은 이전의 모든 멜로디 음표의 길이; 동일한 마디, 악절 및 하위 악절 내의 다른 멜로디 음표의 길이; 및 미래에 발생할 수 있는 멜로디 음표의 길이에 의존한다. 제2 멜로디 음표의 길이가 제1 멜로디 음표의 길이에 의해 영향을 받고, 제3 멜로디 음표의 길이가 제1 및 제2 멜로디 음표의 길이에 의해 영 향을 받도록 하는 식으로, 특정 멜로디 음표의 길이에 대한 결정에 각각의 선행하는 멜로디 음표 길이 결정 인 자가 고려된다. 상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B26)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터 테이블에 저장된 특정 음악 이론 파라미터 사이의 변환 매핑을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 서브 시스템(B29)의 파라미터 테이블에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변 환 감정 및 스타일 디스크립터와 피치 사이에는 강한 관계가 있다. 예컨대, 팝 음악 조각은 주로 온음계적 피치를 가질 수 있는 반면, 전위 음악 조각은 피치의 키와의 관계 또는 심지어 서로에 대해 구속되는 피치를 가질 수 있다. 하위 악절의 각 피치는 이전의 모든 음표의 피치; 동일한 마디, 악절 및 하위 악절 내의 다른 음표의 피치; 및 미래에 발생할 수 있는 음표의 피치에 의존한다. 제2 음표의 피치가 제1 음표의 피치에 의해 영향을 받고, 제3 음표의 피치가 제1 및 제2 음표의 피치에 의해 영향을 받도록 하는 식으로, 특정 음표의 피치에 대한 결정에 각 각의 선행하는 피치 결정 인자가 고려된다. 또한, 선택되는 피치의 근간이 되는 화음은 가능한 피치 옵션의 랜드스케이프에 영향을 미친다. 예컨대, 다른 화음이 발생하는 시간 동안보다, 음표(C E G)로 구성된 C 메이저 화음이 발생하는 시간 동안에, 음표 피치가 이 화음으로부터 음표를 선택할 가능성이 보다 높을 것이다. 또한, 음표의 피치는 단계적으로 계속하기보다는 오름차순 또는 내림차순 경로 중 하나로부터 방향을 변경하고 하나의 음표에서 다른 음표로 도약하도록 권장된다. 상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B29)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터 테이블에 저장된 특정 음악 이론 파라미터 사이의 변환 매핑을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 서브 시스템(B30)의 파라미터 테이블에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변 환 감정 및 스타일 디스크립터와 피치 주파수 사이에는 강한 관계가 있다. 예컨대, 쓸쓸한 음악 조각은 주파수 범 위에서 더 낮은 피치를 가질 수 있는 반면, 활기찬 음악 조각은 주파수 범위에서 더 높은 피치를 가질 수 있다. 하위 악절의 각 피치 주파수는 이전의 모든 음표의 피치 주파수; 동일한 마디, 악절 및 하위 악절 내의 다른 음 표의 피치 주파수; 및 미래에 발생할 수 있는 음표의 피치 주파수에 의존한다. 제2 음표의 피치 주파수가 제1 음표의 피치 주파수에 의해 영향을 받고, 제3 음표의 피치 주파수가 제1 및 제2 음표의 피치 주파수에 의해 영 향을 받도록 하는 식으로, 특정 음표의 피치 주파수에 대한 결정에 각각의 선행하는 피치 주파수 결정 인자가 고려된다. 상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B30)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터 테이블에 저장된 특정 음악 이론 파라미터 사이의 변환 매핑을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 서브 시스템(B39)의 파라미터 테이블에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변 환 감정 및 스타일 디스크립터와 음악을 연주하는 악기 사이에는 강한 관계가 있다. 예컨대, 록 음악 조각은 기타, 드럼 및 키보드를 가질 수 있는 반면, 클래식 음악 조각은 현악기, 목관 악기 및 금관 악기를 가질 수 있다. 감정 및 스타일 디스크립터와 음악 조각의 악기 편성 또는 음악 조각의 섹션 사이에는 강한 관계가 있다. 팝 음 악은 기타, 베이스, 키보드 및 타악기를 가질 가능성이 있는 반면, 클래식 음악은 현악기, 금관 악기 및 목관 악기를 가질 가능성이 있다. 또한, 다양한 종류의 팝 음악 또는 서로 다른 음악적 감정 및 스타일 디스크립터는 각 악기 카테고리 내에 다양한 종류의 악기를 가질 수 있으며, 이에 따라, 세찬 팝 음악은 일렉트릭 기타를 가 질 수 있는 반면, 차분한 팝 음악은 어쿠스틱 기타를 가질 수 있다. 또한, 조각 악기 편성이 조각 내에 모든 악기를 포함할 것임에도 불구하고, 모든 악기가 언제나 항상 함께 연주 되지 않을 수 있다. 상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B39)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터 테이블에 저장된 특정 음악 이론 파라미터 사이의 변환 매핑을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 서브 시스템(B31)의 파라미터 테이블에 시스템 작동 파라미터 테이블을 채우는 음악적 경험 파라미터의 변환 감정 및 스타일 디스크립터와 음악을 연주하는 악기 사이에는 강한 관계가 있다. 예컨대, 록 스타일로 편곡된 음악 조각은 클래식 스타일로 편곡된 동일한 음악 조각과는 완전히 다른 소리를 가질 수 있다. 또한, 음악 조각의 오케스트레이션은 감정 및 스타일 디스크립터 입력과 무관할 수 있으며, 단지 타이밍 요청을 수행하기 위해 존재할 수도 있다. 예컨대, 음악 조각이 지금까지의 오케스트레이션과는 무관하게 어느 순간 악 센트할 필요가 있는 경우, 심벌즈와 같이 큰 소리로 충돌하는 타악기가 이 타이밍 요청을 성공적으로 달성할 수 있으며, 사용자 요청에 따른 보다 음악적인 오케스트레이션에 적합하다. 기본 멜로디 악기로서 기능하는 악기의 오케스트레이션은 반주로서 기능하는 경우에서와는 매우 다를 수 있으므 로, 오케스트레이션에서는 음악의 조각 또는 섹션 내에서 각 악기 및 악기 그룹의 기능의 명확한 계층을 생성하 는 것이 중요하다. 악기의 기능이 결정되면, 악기가 연주하는 방식이 결정될 수 있다. (3/4 박자표의) 왈츠에서 피아노 반주는 모든 다운비트에서의 왼손 연주와 모든 제2 및 제3 비트에서의 오른손 연주를 가질 수 있다. 악 기가 연주될 방식이 결정되면, 음표 길이를 포함한 사양이 결정될 수 있다. 예컨대, 이전의 예를 계속하여, 피 아노의 왼손이 다운비트로 연주하면, 이는 팔분음표 또는 이분음표 동안 연주할 수 있다. 각각의 음표 길이는 이전의 모든 음표의 음표 길이; 동일한 마디, 악절 및 하위 악절 내의 다른 음표의 음표 길 이; 및 미래에 발생할 수 있는 음표의 음표 길이에 의존한다. 제2 음표의 길이가 제1 음표의 길이에 의해 영향 을 받고, 제3 음표의 길이가 제1 및 제2 음표의 길이에 의해 영향을 받도록 하는 식으로, 특정 음표의 길이에 대한 결정에 각각의 선행하는 음표 길이 결정 인자가 고려된다. 효과적인 오케스트레이션을 생성하기 위해, 각 악기의 강약도 결정되어야 한다. 악기 연주의 강약은 항상 변화 할 것이지만, 흔히 클래식 음악 이론 카논을 추종하는 지표를 유도함으로써 결정된다. 상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B31)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터 테이블에 저장된 특정 음악 이론 파라미터 사이의 변환 매핑을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 서브 시스템(B32)의 파라미터 테이블에 유지된 확률 기반 시스템 작동 파라미터로의 음악적 경험 파라미터의 변 환 감정 및 스타일 디스크립터와 음악이 연주되는 방법을 통지하는 컨트롤러 코드 정보 사이에는 강한 관계가 있다. 예컨대, 록 스타일로 편곡된 음악 조각은 다량의 딜레이와 리버브를 가질 수 있는 반면, 보컬리스트는 트레몰로를 연주에 포함시킬 수 있다. 또한, 음악 조각의 컨트롤러 코드 정보는 감정 및 스타일 디스크립터 입력과 무관할 수 있으며, 단지 타이밍 요 청을 수행하기 위해 존재할 수도 있다. 예컨대, 음악 조각이 지금까지의 컨트롤러 코드 정보와는 무관하게 어느 순간 악센트할 필요가 있는 경우, 일정한 딜레이에서 딜레이가 전혀 없는 것으로 이동하는 것과 같은 컨트롤러 코드 정보의 변화는 이 타이밍 요청을 성공적으로 달성할 수 있으며, 사용자 요청에 따른 보다 음악적인 오케스 트레이션에 적합하다. 상기 원리와 고려 사항은 (i) 시스템 사용자(들)에 의해 시스템의 입출력 서브 시스템(B0)에 제공되는 감정, 스 타일 및 타이밍/공간 파라미터의 허용가능한 특정 조합과, (ii) 서브 시스템(B32)에 로드되어 본 발명의 자동화 된 음악 작곡 및 생성 시스템 중에 사용되는 시스템 작동 파라미터 테이블에 저장된 특정 음악 이론 파라미터 사이의 변환 매핑을 규정하거나 생성할 때 시스템 설계자(들)에 의해 이용될 것이다. 본 발명의 자동화된 음악 작곡 및 생성 시스템의 특정 부분의 타이밍 제어 도 80a 및 도 80b는 특정 타이밍 제어 펄스 신호가 도 26a 내지 도 26p에 나타낸 시스템도의 각 서브 시스템 블 록도로 전송되는 시간 순서를 도시한 타이밍 제어도의 개략도를 나타낸다. 특히, 이 시간 순서 이벤트는 시스템 이 시스템 사용자로부터 그 음악적 경험 디스크립터 입력을 수신하고, 시스템이 자동으로 배치되어 본 발명의 원리에 따라 음악이 자동으로 작곡 및 생성되는 그 작동 모드로 구성된 후에 발생한다. 본 발명의 예시적인 실시형태에 의해 지원되는 입출력 데이터 신호의 종류와 다양한 가능한 포맷 도 81 내지 도 81j는, 도 81에 따라 함께 조립될 경우, 본원에 기술된 본 발명의 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스템 내의 각 서브 시스템에 의해 제공되는 입출력 데이터 신호의 종류와 다양한 가능한 포맷을 설명한 테이블의 개략도를 나타내며, 각 서브 시스템은 그 블록명 또는 식별자(예컨대, B1)로 테이블 내 에서 식별된다. 도 82은 본 발명의 자동화된 음악 작곡 및 생성 시스템에 채택된 다양한 특수하게 구성된 정보 프로세싱 서브 시스템을 통과하는 다양한 데이터 입출력 신호(예컨대, 텍스트, 화음, 오디오 파일, 바이너리, 명령, 박자, 이 미지, 시간, 피치, 숫자, 조성, 템포, 문자, 언어, 음성, MIDI 등)에 의해 제공되는 예시적인 데이터 포맷을 설 명한 테이블의 개략도이다. 본 발명의 자동화된 음악 작곡 및 생성 시스템에 의해 지원되는 음악적 경험 디스크립터의 사양 도 83a 내지 도 83f는 1차, 2차 및 3차 감정에 따라 배열된 예시적인 계층적 \"감정\" 디스크립터 세트를 설명한 테이블을 나타낸다. 이 감정 타입 디스크립터는 본 발명의 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스 템에 시스템 사용자 입력으로서 제공하기 위해 시스템 사용자에 대해 \"음악적 경험 디스크립터\"로서 제공된다. 도 84a, 도 84b, 도 84c, 도 84d 및 도 84e는 함께 취합되어, 본 발명의 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스템에 입력으로서 제공하기 위해 시스템 사용자에 대해 음악적 경험 디스크립터로서 제공되는 예시 적인 \"스타일\" 디스크립터 세트를 설명한 테이블을 제공한다. 본 발명의 자동화된 음악 작곡 및 생성 시스템의 파라미터 변환 엔진 서브 시스템(B51) 내에 파라미터 구성을 생성하고 관리하기 위한 시스템 네트워크 툴 도 85는 본 발명의 자동화된 음악 작곡 및 생성 엔진(E1)에 작동 가능하게 연결된 (i) 복수의 원격 시스템 설계 자 클라이언트 워크스테이션(DWS)을 포함하는 본 발명의 자동화된 음악 작곡 및 생성 시스템 네트워크를 나타낸 다. 다른 도면에 나타낸 바와 같이, 파라미터 변환 엔진 서브 시스템(B51)과 그 관련 파라미터 테이블 아카이브 데이터베이스 서브 시스템(B80)은 엔진(E1)에 유지된다. 각각의 워크스테이션 클라이언트 시스템(DWS)은 예시적 실시형태가 설계 및 제조 중인 것에 관계없이 파라미터 변환 엔진 서브 시스템(B51) 내에서의 \"파라미터 매핑 구성(PMC)\"의 생성 및 관리를 위해 GUI 기반 작업 환경을 지원한다. 이 시스템 네트워크를 이용하면, 전세계 어 디든 원격 위치한 하나 이상의 시스템 설계자는 시스템 네트워크에 로그인하여 GUI 기반 작업 환경에 액세스할 수 있고, (i) 시스템 사용자에 의해 선택될 수 있는 감정 타입, 스타일 타입 및 타이밍/공간 파라미터의 서로 다른 가능한 세트와 (ii) 파라미터 변환 엔진 서브 시스템(B51) 및 그 관련 파라미터 테이블 아카이브 데이터베 이스 서브 시스템(B80) 내에서의 영구 저장을 위해, 바람직하게는 파라미터 테이블 내에 유지되는 대응하는 확 률 기반 음악 이론 시스템 작동 파라미터 세트 사이의 \"파라미터 매핑 구성\"을 만들 수 있다. 이 파라미터 매핑 구성 툴은 시스템 설계 단계에서 파라미터 변환 엔진 서브 시스템(B52)을 구성하기 위해 사용 되며, 이에 따라, 프로그램은 본원에 기술된 시스템 사용자 입력의 다양한 가능한 조합을 위해 시스템의 파라미 터 테이블 세트에 확률 파라미터를 규정 또는 설정한다. 더 구체적으로, 이 시스템 설계자 툴은, 자동화된 음악 작곡 및 생성 프로세스의 실행 전에, 궁극적으로는 서브 시스템으로 분배 및 로드되는 파라미터 테이블 내에서 음악 이론 시스템 작동 파라미터(SOP)와 시스템 사용자가 선택한 감정/스타일/타이밍 파라미터 세트 사이의 확 률 관계를 시스템 설계자(들)가 규정할 수 있도록 한다. 시스템 설계자에 의한 이와 같은 선행 파라미터 매핑 구성은 시스템 작동과, 음악 조각의 특정 부분이 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 시스템 에 의해 궁극적으로 어떻게 작곡 및 생성될지를 로컬 결정하기 위해 각 서브 시스템에 의해 사용되는 각 서브 시스템 내에 채택된 파라미터 선택 메커니즘(예컨대, 난수 발생기 또는 사용자가 공급한 가사 또는 멜로디 입력 데이터 세트)에 제약을 부과한다. 도 86a에 나타낸 바와 같이, 도 85에 나타낸 시스템 네트워크에 의해 지원되는 GUI 기반 작업 환경은 시스템 설 계자에게 (i) 기존의 파라미터 매핑 구성을 관리하고, (ii) 파라미터 변환 엔진 서브 시스템(B51)에 로드하고 영구 저장하기 위해 새로운 파라미터 매핑 구성을 생성하는 선택을 제공한다. 그리고, 파라미터 변환 엔진 서브 시스템(B51)은 도 77a 내지 도 79에 나타낸 대응하는 확률 기반 음악 이론 시스템 작동 파라미터(SOP) 테이블 (들)을 생성하고, 이를 배치된 본 발명의 자동화된 음악 작곡 및 생성 시스템에 채택된 다양한 서브 시스템 내 에 로드한다. 도 86b에 나타낸 바와 같이, 시스템 설계자는 (i) 도 86a에 도시한 GUI로부터의 기존 파라미터 매핑 구성의 관 리를 선택하고, 본 발명의 시스템의 파라미터 변환 엔진 서브 시스템(B51)의 영구 저장소에 생성되어 로드되어 있는 현재 생성된 파라미터 매핑 구성 리스트가 제시된다. 도 87a에 나타낸 바와 같이, 시스템 설계자는 도 86a에 나타낸 GUI 스크린으로부터 (i) 새로운 파라미터 매핑 구성의 생성을 선택한다. 도 87b에 나타낸 바와 같이, 시스템 설계자에게는 배치된 본 발명의 자동화된 음악 작곡 및 생성 시스템에 채택 된 다양한 서브 시스템 내에서의 로드를 위해 (i) 사스템 사용자가 선택할 수 있는 가능한 감정/스타일/타이밍 파라미터 세트와, 도 77a 내지 도 79에 나타낸 대응하는 확률 기반 음악 이론 시스템 작동 파라미터(SOP) 테이 블(들) 세트 사이의 파라미터 매핑 구성을 생성하는 데 사용하기 위한 GUI 기반 워크시트가 제시된다. 도 86b에 나타낸 예시적인 GUI 기반 워크시트를 이용하여, 시스템 설계자 또는 그와 함께 일하는 팀의 과제는, 임의의 주 어진 시스템 사용자에 의해 선택될 수 있는 감정/스타일/타이밍 파라미터의 각각의 가능한 세트에 대하여, 도 77a 내지 도 79에 도시된 확률 기반 시스템 작동 파라미터(SOP) 테이블의 마스터 세트 내에 각 음악 이론 SOP 테이블을 위한 대응하는 확률 값 세트를 생성하는 것이다. 일반적으로, 파라미터 변환 능력을 가진 파라미터 변환 엔진 서브 시스템(B51)을 구성하기 위해 생성되어야 할 확률 기반 SOP 테이블의 가능한 조합의 수는 상당히 클 것이고, 본 발명의 원리에 따라 배치된 임의의 주어진 시스템 설계를위해 시스템 사용자에 의해 선택될 수 있는 가능한 감정 타입 및 스타일 타입 음악적 경험 디스크 립터의 크기에 의존할 것이다. 이와 같은 가능한 조합의 규모는 앞에서 논의되고 모델링되었다. 도 85 내지 도 87b에 도시된 이 툴은 시스템 설계 전문가가 본원에 개시된 본 발명의 자동화된 음악 작곡 및 생 성 시스템 내에 자신의 음악 작곡 전문성, 지식 및 노하우를 추가하고 구체화할 수 있는 방법의 예시적인 예에 불과하다. 통상적으로, 이와 같은 전문성, 지식 및/또는 노하우는, 본원에 개시된 바와 같이 시스템의 다양한 서브 시스템과 연관된 다양한 시스템 작동 파라미터(SOP) 테이블 내에 유지된 파라미터 및 데이터 세트를 조작 하기 위해 개조된 기술을 이용하여, 시스템 설계자(들)와 엔지니어(들)로부터 음악 작곡 기계로 지원되는 디지 털 및/또는 아날로그 회로에 전달될 것이다. 당업자에게는 본원에 개시된 본 발명의 개시물에 비추어 다른 기술 과 방법이 쉽게 떠오를 것이다. 파라미터 변환 엔진 서브 시스템(B51)에 생성된 확률 기반 시스템 작동 파라미터 테이블의 구성에 영향을 주기 위한 가사 및/또는 음악 입력의 사용, 및 본 발명의 시스템에 채택된 다양한 서브 시스템에 채택된 확률 기반 시스템 작동 파라미터 테이블로부터 파라미터 값을 선택하는 대안적인 방법 예시적인 실시형태 전반에 걸쳐, 본 발명의 자동화된 음악 작곡 및 생성 시스템의 다양한 서브 시스템에 채택된 다양한 확률 기반 음악 이론 시스템 작동 파라미터 테이블로부터 파라미터 값을 선택하기 위해 난수 발생기가 사용되는 것으로 나타나 있다. 비확률 파라미터 값 선택 메커니즘이 자동화된 음악 작곡 및 생성 프로세스 중에 사용될 수 있을 것으로 이해된다. 이와 같은 메커니즘은 파라미터 변환 엔진 서브 시스템(B51) 내에서 글로벌하 게, 또는 확률 기반 파라미터 테이블을 채택한 각 서브 시스템 내에서 로컬하게 실현될 수 있다.글로벌 방법의 경우에는, 피치 및 리듬 추출 서브 시스템(B2)에 의해 시스템 사용자가 제공한 가사 입력 또는 음악 입력(예컨대, 곡조의 허밍 또는 휘파람)으로부터 자동으로 추출된 피치 정보에 응답하여 파라미터 변환 엔 진 서브 시스템(B51)(또는 다른 전용 서브 시스템)이 도 28c 내지 도 28e에 나타낸 특정 파라미터 테이블의 파 라미터 값의 가중치를 자동으로 조정할 수 있다. 이와 같은 글로벌 방법에서는, 가사적으로/음악적으로 왜곡된 파라미터 테이블 또는 로컬 구현법과 관련하여 후술한 가사/음악 응답 파라미터 값 섹션 메커니즘과 같은 대안 적인 파라미터 메커니즘으로부터 파라미터 값을 선택하기 위해 난수 발생기가 사용될 수 있다. 로컬 방법의 경우에는, 도 88에 나타낸 시스템에 채택된 실시간 피치 이벤트 분석 서브 시스템(B52)이 시스템 사용자가 제공한 가사 또는 음악(단독으로 또는 선택된 음악적 경험 및 타이밍 파라미터와 함께)으로부터 실시 간 피치 및 리듬 정보를 포착하기 위해 사용될 수 있으며, 상기 정보는 (난수 발생기 대신) 각 서브 시스템에 지원된 가사/음악 응답 파라미터 값 선택 메커니즘에 제공된다. 파라미터 값 선택 메커니즘은 시스템 사용자로 부터 추출된 피치 및 리듬 정보를 수신하고, 확률 기반 파라미터 테이블 내의 어떤 파라미터 값이 선택되어야 하는지에 대한 결정 기준을 형성하기 위해 이를 이용할 수 있다. 이상적으로는, 도출된 작곡 음악이 실시간 피 치 이벤트 분석 서브 시스템(B52)에 의해 추출된 피치 및 리듬 정보에 대응하도록, 선택이 이루어질 것이다. 글로벌 또는 로컬 중 어느 한 방법에서, 가사 및/또는 다른 입력 매체(들)(예컨대, 허밍, 휘파람, 두드리기) 세 트로부터, 본 발명의 시스템은, 예컨대, 도 88 내지 도 100의 실시간 피치 이벤트 분석 서브 시스템(B52)을 이 용하여, 시스템 사용자 입력을 입력 리듬, 피치, 및 리듬/피치의 동기 수준으로 증류할 수 있다. 일부 경우에서, 이 가사/음악 입력은 감정 타입 및 스타일 타입 음악적 경험 디스크립터와 함께 보충적인 음악적 경 험 디스크립터의 역할을 할 수 있거나; 다른 경우에서, 가사/음악 입력은 감정 및/또는 스타일 디스크립터 없이 주요한 음악적 경험 디스크립터의 역할을 할 수 있다. 그리고, 실시간 피치 이벤트 분석 서브 시스템(B52)은 동 기 컨텐츠를 분석하여 패턴, 경향, 선호도 및/또는 재료 내의 다른 의미있는 관계를 식별할 수 있다. 그리고, 파라미터 변환 엔진 서브 시스템(B52)은 이 관계들을 도 77a 내지 도 79에 나타낸 확률 기반 시스템 작동 파라 미터 테이블에 대한 파라미터 값 또는 값 범위 선호도로 변환할 수 있다. 그리고, 시스템은 후속하여 생성된 음 악 조각이 입력 재료의 분석을 반영하도록 가사/음악 입력 재료의 분석을 반영하는 (파라미터가 이미 생성 및/ 또는 로드된) 시스템 작동 테이블로부터 특정 값(들)을 선택할 가능성이 보다 높다. 시스템 사용자에 의해 가사/음악 입력으로부터 추출될 경우, 본 발명의 이 대안적인 실시형태에 제안된 가사 또 는 음악 응답 파라미터 선택 메커니즘을 이용하여 특정 파라미터 테이블 내의 파라미터 값을 선택하는 데 통상 적으로 영향을 미치게 될 몇 가지 피치 및 리듬 정보에 대해 논의하는 것이 도움이 될 것이다. 이 사례는 위에 서 논의한 글로벌 및 로컬 구현법 모두에 적용될 것이다. 예컨대, 입력 재료가 짧고 빠른 리듬 재료의 고주파수로 구성된 경우, 리듬 관련 서브 시스템(즉, 도 28c 내지 도 27bc에 도시된 B2, B3, B4, B9, B15, B11, B25 및 B26)은 입력 재료가 영향을 미칠 수 있는 파라미터 테이 블에서 16분음표 및 8분음표 리듬 값 또는 다른 값을 선택할 가능성이 보다 높다. 다음의 리듬 관련 예를 고려 하기로 한다: (i) 빠르고 짧은 리듬 재료를 가진 멜로디를 노래하는 시스템 사용자는 서브 시스템(B26) 내의 확 률이 16분음표 및 8분음표 옵션을 변경하고 심하게 강조하도록 할 수 있고; (ii) 3개의 동일한 리듬이 반복되는 패턴의 왈츠를 노래하는 시스템 사용자는 서브 시스템(B4) 내의 확률이 3/4 또는 6/8 박자 옵션을 변경하고 심 하게 강조하도록 할 수 있으며; (iii) 버스 코러스 버스 형태를 추종하는 노래를 노래하는 시스템 사용자는 서 브 시스템(B9) 내의 확률이 ABA 형태 옵션을 변경하고 심하게 강조하도록 할 수 있고; (iv) 매우 빠른 카덴스를 가진 멜로디를 노래하는 시스템 사용자는 서브 시스템(B3) 내의 확률이 더 빠른 템포 옵션을 변경하고 심하게 강조하도록 할 수 있으며; 그리고 (v) 천천히 변하며 아래에 내재된 하모니 진행을 가진 멜로디를 노래하는 시 스템 사용자는 서브 시스템(B11) 내의 확률이 더 긴 화음 길이 옵션을 변경하고 심하게 강조하도록 할 수 있다. 입력 재료가 마이너 키를 포함한 피치로 구성된 경우, 피치 관련 서브 시스템(즉, 도 28c, 도 28d 및 도 28e에 도시된 B5, B7, B17, B19, B20, B27, B29 및 B30)은 입력 재료가 영향을 미칠 수 있는 마이너 키(들) 및 관련 마이너 화음 및 화음 진행 또는 다른 값을 선택할 가능성이 보다 높다. 다음의 피치 관련 예를 고려하기로 한다: (i) 마이너 조성을 추종하는 멜로디를 노래하는 시스템 사용자는 서브 시스템(B7) 내의 확률이 마이너 조 성 옵션을 변경하고 심하게 강조하도록 할 수 있고; (ii) 피치 D 주위에 중심을 둔 멜로디를 노래하는 시스템 사용자는 서브 시스템(B27) 내의 확률이 D 피치 옵션을 변경하고 심하게 강조하도록 할 수 있으며; (iii) E 주 위에 중심을 둔 아래에 내재된 하모니 진행을 추종하는 멜로디를 노래하는 시스템 사용자는 서브 시스템(B17) 내의 확률이 E 밑음 음표 옵션을 변경하고 심하게 강조하도록 할 수 있고; (iv) 낮은 피치 범위를 추종하는 멜 로디를 노래하는 시스템 사용자는 서브 시스템(B30) 내의 확률이 더 낮은 피치 옥타브 옵션을 변경하고 심하게 강조하도록 할 수 있으며; 그리고 (v) 피치 D F# 및 A 주위에 중심을 둔 아래에 내재된 하모니 진행을 추종하는멜로디를 노래하는 시스템 사용자는 서브 시스템(B5) 내의 확률이 D 키 옵션을 변경하고 심하게 강조하도록 할 수 있다. 시스템 사용자 입력 재료가 특정 스타일을 추종하거나 특정 컨트롤러 코드 옵션을 채택한 경우, 도 28c, 도 28d 및 도 28e에 도시된 악기 편성 서브 시스템(B38 및 B39)과 컨트롤러 코드 서브 시스템(B32)은 각각 특정 악기 및/또는 특정 컨트롤러 코드 옵션을 선택할 가능성이 보다 높다. 다음의 예를 고려하기로 한다: (i) 팝 스타일 을 추종하는 멜로디를 노래하는 시스템 사용자는 서브 시스템(B39) 내의 확률이 팝 악기 옵션을 변경하고 심하 게 강조하도록 할 수 있으며; 그리고 (ii) 딜레이 효과를 모방하는 멜로디를 노래하는 시스템 사용자는 서브 시 스템(B32) 내의 확률이 딜레이 및 관련 컨트롤러 코드 옵션을 변경하고 심하게 강조하도록 할 수 있다. 또한, 시스템 사용자 입력 재료가 특정 악기 및/또는 그 연주 방법을 추종하거나 모방하는 경우, 도 28c, 도 28d 및 도 28e에 도시된 오케스트레이션 서브 시스템(B31)은 특정 오케스트레이션 옵션을 선택할 가능성이 보다 높다. 다음의 오케스트레이션 관련 예를 고려하기로 한다: (i) 악기(들)의 모방된 음악 연주(들)로 멜로디를 노 래하는 시스템 사용자는 서브 시스템(B31) 내의 확률이 사용자 입력을 반영하기 위해 조각의 오케스트레이션을 변경하고 심하게 강조하도록 할 수 있으며; (ii) 시스템 사용자가 아르페지오 멜로디를 노래하는 경우, 서브 시 스템(B31)은 아르페지오 또는 유사한 오케스트레이션을 심하게 강조할 수 있고; (iii) 서로 다른 음악 기능을 연주하는 모방된 악기로 멜로디를 노래하는 시스템 사용자는 서브 시스템(B31) 내의 확률이 시스템 사용자에 의 해 모방되는 바와 같이 각각의 악기와 관련된 음악 기능 선택을 변경하고 심하게 강조하도록 할 수 있으며; 그 리고 (iv) 시스템 사용자가 바이올린 스타일로 멜로디를 노래하는 것과 기타 스타일로 반주하는 것을 교대로 하 는 경우, 서브 시스템(B31)은 음악 조각의 관련되거나 유사한 악기(들)에 대한 이 음악 기능들을 심하게 강조할 수 있다. 본 발명의 자동화된 음악 작곡 및 생성 시스템의 제7 예시적 실시형태의 사양 도 88은 경우에 따라 타이핑된 텍스트 열, 말로 전해진 단어, 또는 노래 불려진 가사의 형태로 시스템 사용자에 의해 입출력 서브 시스템(B0)에 제공되는 언어 기반 또는 그래픽 아이콘 기반 음악적 경험 디스크립터 및 선택 적으로는 가사(단어 열) 표현에 의해 구동되는 가상 악기 음악 합성을 지원하는 본 발명의 자동화된 음악 작곡 및 생성 악기 시스템의 제7 대안적 실시형태를 나타낸다. 본원에서 사용되는 바와 같이, 용어 \"가상 악기 음악 합성\"은, 예컨대, 본원에 개시된 디지털 오디오 샘플링 기술을 포함한 다양한 음악 및 악기 시스템 합성 기술을 이용하여 생성된 하나 이상의 가상 악기를 이용하여 제작된 디지털 오디오 음표, 화음 및 음표 시퀀스를 이용한 음표 단위 및 화음 단위의 음악 조각 제작을 의미한다. 도 88에 나타낸 이 예시적인 실시형태에서, 이 시스템 사용자 입력은 시스템 사용자가 감정, 스타일 및 타이밍 타입 음악적 디스크립터를 시스템에 통신할 수 있도록하는 텍스트 키보드/키패드, 오디오 마이크, 음성 인식 인 터페이스 및/또는 다른 적당한 시스템 사용자 인터페이스를 이용하여 제작될 수 있다. 이 시스템 구성에 의하면, 시스템 사용자는 본 발명의 원리에 따라 작곡된 음악으로 스코어링될 포토 슬라이드 쇼 또는 스코어링 된 비디오 내의 하나 이상의 장면에, 예컨대, 타이핑되거나, 말로 전해지거나 및/또는 노래 불려진 가사(예컨대, 하나 이상의 단어 악절)를 더 적용할 수 있다. 더 상세하게 후술하는 바와 같이, 타임라인을 따라 피치 이벤트의 자동화된 검색을 허용하는 모음 포먼트를 추 출하기 위해, 가사가 타이핑되는지, 말로 전해지는지 또는 노래 불려지는지에 따라, 가사는 시스템 사용자에 의 해 특정 장면에 적용될 때 다양한 방식으로 프로세싱될 것이다. 이와 같은 피치 이벤트는 시스템 사용자에 의해 입력으로서 시스템 인터페이스 서브 시스템(B0)에 제공될 수 있는 타이밍 파라미터 및 가사를 포함한 완벽한 음 악적 경험 디스크립터 세트에 기초하여 시스템 작동 파라미터를 생성하기 위해 파라미터 변환 엔진 서브 시스템 (B51)이 사용하는 음악적 경험 디스크립터 및 타이밍/공간 파라미터를 통지하고 제한하는 데 사용될 수 있다. 도 89에 도시된 바와 같이, 자동화된 음악 작곡 및 생성 악기 시스템은 키보드 인터페이스, 마이크, 터치 스크 린 인터페이스 또는 음성 인식 인터페이스를 이용하여 선택된 그래픽 아이콘 기반 음악적 경험 디스크립터에 의 해 구동되는 가상 악기 음악 합성을 지원한다. 일반적으로, 위에서 특정되고 도 26a 내지 도 84e에 나타낸 상호 협력하는 그 서브 시스템들을 모두 포함하는 도 88에 나타낸 자동 또는 자동화된 음악 작곡 및 생성 시스템은 자동 음악 작곡 및 생성 시스템에 의해 지원될 작동 기능 및 모드를 실현하도록 특수하게 구성되고 프로그래밍된 디지털 전자 회로, 아날로그 전자 회로, 또는 디지털 및 아날로그 전자 회로의 조합을 이용하여 구현될 수 있다. 디지털 집적 회로(IC)는 음악 악기 제조 분 야뿐만 아니라 전자 회로 분야에 공지된 방식으로 실리콘으로 제작되는 칩 위에 실현된 저전력 및 혼합(즉, 디지털과 아날로그) 신호 시스템(즉, 시스템 온 어 칩 또는 SOC) 구현예를 포함할 수 있다. 이와 같은 구현예는 본 발명의 시스템에 기초한 특정 제품 설계를 위해 필요하거나 요구될 수 있는 바와 같이 멀티 CPU와 멀티 GPU 의 사용을 포함할 수도 있다. 이와 같은 디지털 집적 회로(ID)의 구현예에 대한 세부 사항을 위해, 카덴스 디자 인 시스템즈 사, 시놉시스 사, 멘토 그래픽스 사 및 기타 전자 설계 자동화 회사를 포함하여 이 분야의 많은 기 업과 전문가를 참조할 수 있다. 예시를 위해, 시스템의 디지털 회로 구현예를 SOC 또는 유사한 디지털 집적 회로 주변에 구성된 구성 요소들의 아키텍처로서 나타내었다. 도시된 바와 같이, 시스템은 멀티 코어 CPU, 멀티 코어 GPU, 프로그램 메모리(DRAM) 및 비디오 메모리(VRAM)를 포함하는 SOC 서브 아키텍처; 하드 드라이브(SATA); LCD/터치 스크린 디스플레이 패 널; 마이크/스피커; 키보드; WIFI/블루투스 네트워크 어댑터; 피치 인식 모듈/보드; 및 전원 공급 장치와 분배 회로를 포함한 다양한 구성 요소를 포함하고, 도시된 바와 같이, 이들은 모두 시스템 버스 아키텍처와 지원 컨 트롤러 칩 주변에 집적된다. 프로그램 및 그래픽 명령이 모두 단일의 IC 소자 내에서 구현될 수 있는 하이브리드 멀티 코어 CPU/GPU 칩으로 서 멀티 코어 CPU와 GPU 모두가 실현되는 것도 가능하지만, 멀티 코어 CPU의 주요 기능은 프로그램 메모리(예컨 대, 마이크로 코드)에 로드된 프로그램 명령을 실행하는 것인 반면, 멀티 코어 GPU는 통상적으로 멀티 코어 CPU 로부터 그래픽 명령을 수신하여 실행하며, WIFI/블루투스(BT) 네트워크 어댑터와 피치 인식 모듈/회로뿐만 아니 라, LCD/터치 스크린 디스플레이 패널, 마이크/스피커, 키보드 또는 키패드 장치를 위한 인터페이스 회로와 아 울러, 컴퓨팅 및 그래픽 파이프라인이 모두 지원된다. WIFI/블루투스(BT) 네트워크 어댑터와 피치 인식 모듈/회 로뿐만 아니라, LCD/터치 스크린 디스플레이 패널, 마이크/스피커, 키보드 또는 키패드 장치의 목적은 시스템 인터페이스 서브 시스템(B0)에 의해 지원되는 기능을 지원 및 구현하는 것이지만, 도 88 내지 도 90에 나타낸 시스템에 채택된 다른 서브 시스템을 구현하기 위해서 사용될 수도 있다. 도 90에 나타낸 자동화된 음악 작곡 및 생성 시스템에서는, 가사 입력 및 기타 미디어(예컨대, 비디오 레코딩, 슬라이드 쇼, 오디오 레코딩 또는 이벤트 마커)를 포함한 언어 및/또는 그래픽 기반 음악적 경험 디스크립터가 시스템 사용자 인터페이스(B0)를 통해 입력으로서 선택된다. 서브 시스템(B0)에 의해 지원되는 시스템 사용자 인터페이스는 도 15a 내지 도 15v에 나타낸 것과 유사한 GUI 화면을 지원하는 터치 스크린 키보드를 이용하여 실현될 수 있지만, 예상대로, 본 발명의 실시형태 마다 스타일과 포맷이 다를 것이다. 음악적 경험 디스크립터 와 미디어는 시스템 사용자 인터페이스(B0)로 제공된 다음, (예컨대, 제공된 미디어 콘텐츠 내의 장면 이미지 및/또는 감정 정보 콘텐츠에 기초하여) 음악적 경험 디스크립터를 추출하기 위해 시스템에 의해(예컨대, AI 기 반 이미지 및 음성 프로세싱 방법을 사용하여) 자동으로 분석된다. 그 후, 기계로 추출된 음악적 경험 디스크립 터뿐만 아니라, 시스템에 제공된 음악적 경험 디스크립터는, 후속 액세스, 분배 및 사용을 위해 시스템 사용자 인터페이스를 통해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된 미디어를 자동으로 생성하기 위해, 시스템(S) 내의 자동화된 음악 작곡 및 생성 엔진(E1)에 의해 사용된다. 도 90a에 나타낸 바와 같이, 시스템 입출력 인터페이스(B0)는 시스템에 의해 지원되는 임의의 자연어로 타이핑 된 단어, 말로 전해진 단어 및/또는 노래 불려진 음성의 형태로 시스템에 시스템 사용자가 가사 입력을 전송할 수 있도록 한다. 통상적으로, 전세계의 모든 주요 언어(예컨대, 영어, 스페인어, 프랑스어, 중국어, 일본어, 러 시아어 등)가 지원될 것이다. 도시된 바와 같이, 시스템은 실시간 피치 이벤트 분석 서브 시스템(B52)에 제공되 는 가사 입력 형태(예컨대, 그래픽 열, 말로 전해진 가사를 나타내는 음향 신호 및 노래 불려진 가사를 나타내 는 음향 신호)를 취급하도록 각각 최적화된 3개의 서로 다른 가사 입력 프로세싱 모드를 지원한다. 가사 입력 모드(예컨대, 1 - 타이핑된 가사, 2 - 말로 전해진 가사 및 3 - 노래 불려진 가사)는 GUI 기반 시스템 입출력 서브 시스템(B0)으로부터 시스템 사용자에 의해 선택될 수 있다. 이와 같은 가사 입력은 서브 시스템(B52)으로 부터의 출력을 파라미터 변환 엔진 서브 시스템(B51)으로 전송하기 위해 타임 코딩으로 멀티플렉서를 지원하는 실시간 피치 이벤트 분석 서브 시스템(B52)에 제공된다. 실시간 피치 이벤트 분석 서브 시스템(B52) 내에서는, 시스템 사용자에 의해 제공된 가사 입력에 대해 실시간 피치 이벤트, 리듬 및 운율 분석이 실시되어, 각각 타이 핑되고, 말로 전해지고 노래 불려진 가사에 대한 3개의 서로 다른 피치 이벤트 스트림을 생성시킨다. 이 출력들 은 본 발명의 음악 작곡 및 생성 프로세스 중에 시스템 내의 시스템 작동 파라미터를 변경하기 위해 후속 사용 된다. 도 90b는 서브 시스템(B52) 내에 채택된 다양한 구성 요소를 이용하여 가사 입력을 프로세싱하는 프로그램된 프 로세서를 중심으로 구성된 하위 구성 요소, 즉, 시스템 사용자에 의해 제공되는 서로 다른 가사 입력 형태를 취 급하는 가사 입력 핸들러; 서브 시스템(B52)에 의해 생성되는 서로 다른 피치 이벤트 출력 스트림을 취급하는 피치 이벤트 출력 핸들러; 시스템에 의해 지원되는 언어로 각 단어에 언어 정보 및 모델을 저장하는 어휘 사전;프로세싱된 가사 입력에 포함된 모음 포먼트를 분석하는 모음 포맷 분석기; 및 서브 시스템(B52)의 가사 입력 모드를 제어하는 모드 컨트롤러를 포함하는 것으로서, 도 90a에 나타낸 서브 시스템에 채택되는 실시간 피치 이 벤트 분석 서브 시스템(B52)를 나타낸다. 도 91에는, 실시간 피치 이벤트 분석 서브 시스템(B52)을 이용하여 자동화된 방식으로 음악을 작곡 및 생성하는 방법을 설명하고 있다. 도시된 바와 같이, 방법은 다음의 단계 시퀀스를 포함한다: (a) 자동화된 음악 작곡 및 생성 시스템의 시스템 사용자 인터페이스에 (예컨대, 도 83a 내지 도 83f에 나타낸 바와 같은 \"감정 타입\" 음악 적 경험 디스크립터 및 도 84a 내지 도 84e에 나타낸 바와 같은 \"스타일 타입\" 음악적 경험 디스크립터를 포함 하는) 음악적 경험 디스크립터를 제공하는 단계; (b) 시스템에 의해 작곡 및 생성된 음악으로 스코어링될 비디 오 또는 미디어 객체의 하나 이상의 장면을 위해, 시스템의 시스템 사용자 인터페이스에 (예컨대, 타이핑되거나, 말로 전해지거나 또는 노래 불려진 포맷의) 가사 입력을 제공하는 단계; (c) 시간 및/또는 주파 수 도메인 기술에 기초하여, (스코어링된 미디어의 특정 프레임에 대해) 타이핑되거나/말로 전해지거나/노래 불 려진 가사 또는 단어의 실시간 리듬, 피치 이벤트 및 운율 분석을 이용하여, 시스템 사용자 인터페이스에 제공 된 가사 입력을 프로세싱하는 실시간 피치 이벤트 분석 서브 시스템(B52)을 이용하는 단계; (d) 분석된 가사 입 력으로부터 고해상도 타임라인에서의 피치 이벤트, 리듬 정보 및 운율 정보, 및 그와 같은 검출 이벤트가 언제 발생하였는지에 대한 타이밍 정보를 가진 코드를 추출하기 위해 실시간 피치 이벤트 분석 서브 시스템(B52)을 이용하는 단계; 및 (e) 자동화된 시스템의 다양한 서브 시스템에 채택된 확률 기반 T시스템 작동 파라미터(SOP) 테이블을 제한하는 데 사용하기 위해 자동화된 음악 작곡 및 생성 엔진(E1)에 추출된 피치 이벤트, 리듬 및 운 율 정보를 제공하는 단계. 이하에서 이들 단계 각각을 매우 상세하게 논의하는 것이 도움이 될 것이다. 도 91의 단계(A)에서, (예컨대, 도 83a 내지 도 83f에 나타낸 바와 같은 \"감정 타입\" 음악적 경험 디스크립터 및 도 84a 내지 도 84e에 나타낸 바와 같은 \"스타일 타입\" 음악적 경험 디스크립터를 포함하는) 음악적 경험 디 스크립터는 자동화된 음악 작곡 및 생성 시스템의 시스템 사용자 인터페이스에 다양한 방식으로 제공될 수 있다. 이와 같은 정보 입력은 적절한 GUI 스크린을 사용하는 LCD 터치 스크린 디스플레이를 통해 제공될 수 있 다. 대안적으로, 음악적 경험 디스크립터는 키보드 데이터 입력, 음성 인식, 또는 데이터 입력 및 취급 분야에 공지된 다른 방법에 의해 제공될 수 있다. 도 91의 단계(B)에서, (예컨대, 타이핑되거나, 말로 전해지거나 또는 노래 불려진 포맷의) 가사 입력은 시스템 에 의해 작곡 및 생성된 음악으로 스코어링될 비디오 또는 미디어 객체의 하나 이상의 장면을 위해, 다양한 방 식으로 시스템의 시스템 사용자 인터페이스에 제공될 수 있다. 이와 같은 가사 정보는 마이크, 음성 인식, 타이 핑된 키보드 데이터 입력, 또는 데이터 입력 및 취급 분야에 공지된 임의의 다른 방법을 통해 제공될 수 있으며, 시스템 사용자는 의도된 미디어 조각 또는 섹션의 가사를 말하거나 노래하고, 이를 위해 가사는 자동화 된 음악 작곡 및 생성 시스템에 의해 작곡 및 생성될 음악의 적어도 제한된 수의 음표에 대해 음색, 리듬 및 멜 로디를 전송하도록 의도된다. 도 91의 단계(C)에서, 시스템 사용자 인터페이스에 제공된 가사 입력은 다양한 종류의 신호 프로세싱 장치를 이 용하여, 바람직하게는, (i) 시간 및/또는 주파수 도메인 기술에 기초하여, (미디어의 특정 프레임에 대해) 타이 핑되거나/말로 전해지거나/노래 불려진 가사 또는 단어의 실시간 리듬, 피치 이벤트 및 운율 분석을 이용하여, 프로세싱될 수 있다. 미디어의 조각 또는 섹션에 스코어링되는 말로 전해지거나 노래 불려진 가사 또는 단어의 경우에, 대응하는 음성 신호는 통상적으로 가사에서 모음의 발생과 그 피치 특징을 확인하기 위해 모음 포먼트 분석 및 관련 기술을 채택하여 타이핑되거나/말로 전해지거나/노래 불려진 가사 또는 단어의 실시간 리듬, 피치 이벤트 및/또는 운율 분석을 실행하도록 프로그래밍된 고속 디지털 신호 프로세싱(DSP) 칩을 이용하여 디지털화 되고 프로세싱될 것이며, 모음은 가사 입력으로부터 멜로디의 감각을 얻기 위해 대응하는 피치의 음표로 변환될 수 있다. 도 91의 단계(D)에서, 분석된 가사 입력으로부터 고해상도 타임라인에서의 피치 이벤트, 리듬 정보 및 운율 정 보를 추출하는 것은 전술한 바와 같이 프로그램된 DSP 칩을 이용하여 실시될 수 있으며, 이와 같이 추출된 피치 및 리듬 정보는 타임라인을 따라 그와 같은 검출 이벤트가 언제 발생하였는지를 정확하게 나타내기 위해 타이밍 정보와 함께 부호화될 수 있다. 도 91의 단계(E)에서, 추출된 정보는 궁극적으로 자동화된 음악 작곡 및 생성 엔진 내의 파라미터 변환 엔진 (B51)에 제공되며, 파라미터 변환 엔진(B51)에 의해 생성/갱신된 확률 기반 파라미터 테이블을 제약하기 위해 그 내부에서 사용된다. 분석된 가사 입력의 주요 목적은 도 88에 나타낸 시스템의 자동화된 음악 작곡 및 생성 엔진(E1) 내의 파라미터 변환 엔진 서브 시스템(B51)이 가사 입력과 함께 시스템 사용자에 의해 제공되는 감정/스타일의 음악적 경험 디 스크립터 세트를 위해 구성된 확률 기반 시스템 작동 파라미터(SOP) 테이블을 제약하기 위해 이 자동으로 추출 된 피치 이벤트, 리듬 및 운율 정보를 사용할 수 있도록 하는 것이다. 작곡된 음악이 제공된 가사의 멜로디 구 조를 추종하고 지원하도록, 추출된 피치 이벤트는 본 발명의 시스템에 의해 작곡될 음악 조각의 멜로디 악절 구 조의 생성을 안내하는 역할을 하는 피치 관련 파라미터 테이블의 확률을 설정하는 데 사용될 수 있다. 작곡된 음악이 제공된 가사의 리듬 구조를 추종하고 지원하도록, 리듬 및/또는 운율 정보는 본 발명의 시스템에 의해 작곡될 음악 조각의 리듬 악절 구조의 생성을 안내하는 역할을 하는 리듬 관련 파라미터 테이블의 확률을 설정 하는 데 사용될 수 있다. 도 92은 (가사를 포함한) 언어 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성을 지원하는 도 88 에 나타낸 제7 예시적 실시형태의 음악 작곡 및 생성 시스템 내에서 자동화된 음악 작곡 및 생성 프로세스를 실 행하는 데 포함되는 주요 단계를 설명한다. 도 92에 도시된 바와 같이, 이 방법은 (a) 시스템 사용자가 자동화 된 음악 작곡 및 생성 시스템에 액세스한 다음, 그 자동화된 음악 작곡 및 생성 엔진에 의해 생성된 음악으로 스코어링될 미디어를 선택하는 단계; (b) 시스템 사용자가 음악적으로 스코어링될 선택된 미디어에 적용하기 위 해 시스템의 자동화된 음악 작곡 및 생성 엔진에 제공된 음악적 경험 디스크립터(및 선택적으로는 가사)를 선택 하는 단계; (c) 시스템 사용자가 자동화된 음악 작곡 및 생성 엔진을 기동하여 선택된 미디어에 스코어링되어 있는 제공된 음악적 디스크립터에 기초한 음악을 작곡 및 생성하는 단계; (d) 시스템 사용자가 스코어링된 미디 어 조각 또는 이벤트 마커에 대해 작곡되어 생성된 음악을 검토하며, 음악을 수용하고/또는 도출된 음악적 경험 을 고려하여 사용자 선호도에 대한 피드백을 시스템에 제공하며, 및/또는 음악적 디스크립터 및 파라미터를 변 경하고, 변경된 음악 조각을 재생하도록 시스템에 요청하는 단계; 및 (e) 시스템이 작곡된 음악을 선택된 미디 어와 조합하여, 분배 및 표시하기 위한 새로운 미디어 파일을 제작하는 단계를 포함한다. 도 88 및 도 89에 나타낸 시스템 내의 서브 시스템(B1)의 맥락에서 실시간 피치 이벤트 분석 서브 시스템(B52) 의 작동을 설명하기 위해서는, 자동화된 음악 작곡 및 생성 시스템을 구동하는 데 사용하기 위해, 서로 다른 감 정 상태(예컨대, 행복 및 슬픔)에 의해 각 세트가 특징지어지는 2개의 서로 다른 예시적 가사 세트가 일련의 서 로 다른 피치 이벤트를 생성하기 위해 실시간 피치 이벤트 분석 서브 시스템(B52)에 의해 어떻게 프로세싱되는 지를 설명하는 것이 도움이 될 것이다. 이제 도 93를 참조하면, (그래픽으로 표시된 모음에 할당된) 모음 포맷의 존재에 기초하여 타이핑된 가사로부터"}
{"patent_id": "10-2018-7011569", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "요약된 대응하는 피치 이벤트(예컨대, 음표)를 유도하기 위해 감정 행복(예컨대, 찰스 스트라우스의 \"Put On A Happy Face\")의 타이핑된 가사 표현(단어 세트) 특징을 프로세싱하는 실시간 피치 이벤트 분석 서브 시스템 (B52)이 도시되어 있으며, 이 피치 이벤트는 통상적으로 시스템에 제공된 음악적 경험 디스크립터의 감정 및 스 타일 타입과 함께 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하기 위해 가사 입력으로서 제공된다. 구체적으로, 도 93는 시스템 사용자에 의해 시스템에 타이핑된 가사 입력으로서 제공되는 예에서 감정 행복(예 컨대, 찰스 스트라우스의 \"Put On A Happy Face\")의 타이핑된 가사 표현(단어 세트) 특징을 프로세싱하는 방법 을 실시할 때, 도 88의 시스템 내에서 실행되는 상위 단계를 설명한다. 도 93의 블록(A)에 나타낸 바와 같이, 실시간 피치 이벤트 분석 서브 시스템(B52)은 문자소(또는 형태소)의 열 로서 텍스트 기반 가사 입력을 수신한다. 도 93의 블록(B)에서, 서브 시스템(B52)은 텍스트 열을 로컬 사전을 이용하여 음성 등가 열로 자동으로 전사한 다. 도 93의 블록(C)에서, 음성 열의 이 음소에 기초하여, 서브 시스템(B52)은 음소 열에 존재하는 모음을 (디폴트) 모음 포맷의 열로 자동으로 변환한다. 바람직하게, 디폴트 모음 포맷은 텍스트 기반 표현을 위해 도 90b의 어휘 사전에 나열되는 반면, 모음 포맷은 실시간 음성 프로세싱 및 응용 언어학 분야에 공지된 실시간 분광사진술 및 그와 유사한 기술에 기초할 수 있는 모음 포먼트 분석기를 이용하여 자동으로 검색된다. 도 93의 블록(D)에서, 서브 시스템(B52)은 검출된 모음 포맷을 음악 음표의 열(예컨대, 이 사례에서는 리듬 정 보가 없는 피치 이벤트)로 자동으로 변환한다. 도 93의 블록(E)에서, 서브 시스템(B52)은 모음 포먼트의 열로부터 음표의 열(예컨대, 피치 이벤트)을 생성한다. 도 93의 블록(F)에서, 서브 시스템(B52)은 (예컨대, 검출된 피치 이벤트에 관련된) 피치 이벤트 데이터를 파라 미터 변환 엔진(B51)에 전송함으로써, 시스템에 제공된 음악적 경험 디스크립터의 감정 및 스타일 타입을 고려하여, 음악적 경험 디스크립터와 사양에 맞는 확률 기반 시스템 작동 파라미터를 생성하는 것을 보조한다. 여기 서의 목적은 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하고, 본 발명의 자동화된 음악 작곡 프로세스 중에 시스템의 구동을 돕는 것이다. 그리고, 이와 같은 피치 이벤트 정보는 본 발명의 음악 작곡 및 생성 프로 세스의 궁극적인 실행과 시스템 전반에 분배 및 로딩되기 전에 SOP 테이블을 생성하기 위해 파라미터 변환 엔진 서브 시스템(B51) 내에서 사용된다. 이제 도 94을 참조하면, (그래픽으로 표시된 모음에 할당된) 모음 포맷의 존재에 기초하여 말로 전해진 가사로"}
{"patent_id": "10-2018-7011569", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "부터 요약된 대응하는 피치 이벤트(예컨대, 음표)를 유도하기 위해 감정 행복(예컨대, 찰스 스트라우스의 \"Put On A Happy Face\")의 말로 전해진 가사 표현(단어 세트) 특징을 프로세싱하는 실시간 피치 이벤트 분석 서브 시 스템(B52)이 도시되어 있으며, 이 피치 이벤트는 통상적으로 시스템에 제공된 음악적 경험 디스크립터의 감정 및 스타일 타입과 함께 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하기 위해 가사 입력으로서 제공된다. 구체적으로, 도 94은 시스템 사용자에 의해 시스템에 타이핑된 가사 입력으로서 제공되는 예에서 감정 행복(예 컨대, 찰스 스트라우스의 \"Put On A Happy Face\")의 말로 전해진 가사 표현(단어 세트) 특징을 프로세싱하는 방 법을 실시할 때, 도 88의 시스템 내에서 실행되는 상위 단계를 설명한다. 도 94의 블록(A)에 나타낸 바와 같이, 실시간 피치 이벤트 분석 서브 시스템(B52)은 음향 신호로서 말로 전해진 가사 입력을 수신한다. 도 94의 블록(B)에서, 서브 시스템(B52)은 당업계에 공지된 로컬 사전 및 음성 인식 방법을 이용하여 음성 등가 열을 생성하기 위해, A/D 및 디지털 신호 프로세싱 기술을 이용하여 음향 신호를 자동으로 프로세싱한다. 도 94의 블록(C)에서, 음성 열의 이 음소에 기초하여, 서브 시스템(B52)은 음소 열에 존재하는 모음을 (디폴트) 모음 포맷의 열로 자동으로 변환한다. 바람직하게, 디폴트 모음 포맷은 텍스트 기반 표현을 위해 도 90b의 어휘 사전에 나열되는 반면, 모음 포맷은 실시간 음성 프로세싱 및 응용 언어학 분야에 공지된 실시간 분광사진술 및 그와 유사한 기술에 기초할 수 있는 모음 포먼트 분석기를 이용하여 자동으로 검색된다. 도 94의 블록(D)에서, 서브 시스템(B52)은 검출된 모음 포맷을 음악 음표의 열(예컨대, 이 사례에서는 리듬 정 보가 있는 피치 이벤트)로 자동으로 변환한다. 도 94의 블록(E)에서, 서브 시스템(B52)은 모음 포먼트의 열로부터 음표의 열(예컨대, 리듬 데이터가 있는 피치 이벤트)을 생성한다. 도 94의 블록(F)에서, 서브 시스템(B52)은 (예컨대, 말로 전해진 음성 신호의 검출된 피치 이벤트 및 리듬 특징 에 관련된) 피치 이벤트 및 리듬 데이터를 파라미터 변환 엔진(B51)에 전송함으로써, 시스템에 제공된 음악적 경험 디스크립터의 감정 및 스타일 타입을 고려하여, 음악적 경험 디스크립터와 사양에 맞는 확률 기반 시스템 작동 파라미터를 생성하는 것을 보조한다. 여기서의 목적은 작곡될 음악 조각의 음악적 경험 디스크립션을 보조 하고, 본 발명의 자동화된 음악 작곡 프로세스 중에 시스템의 구동을 돕는 것이다. 그리고, 이와 같은 피치 이 벤트 및 포착된 리듬 데이터는 본 발명의 음악 작곡 및 생성 프로세스의 궁극적인 실행과 시스템 전반에 분배 및 로딩되기 전에 SOP 테이블을 생성하기 위해 파라미터 변환 엔진 서브 시스템(B51) 내에서 사용된다. 이제 도 95를 참조하면, (그래픽으로 표시된 모음에 할당된) 모음 포맷의 존재에 기초하여 노래 불려진 가사로"}
{"patent_id": "10-2018-7011569", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "부터 요약된 대응하는 피치 이벤트(예컨대, 음표)를 유도하기 위해 감정 행복(예컨대, 찰스 스트라우스의 \"Put On A Happy Face\")의 노래 불려진 가사 표현(단어 세트) 특징을 프로세싱하는 실시간 피치 이벤트 분석 서브 시 스템(B52)이 도시되어 있으며, 이 피치 이벤트는 통상적으로 시스템에 제공된 음악적 경험 디스크립터의 감정 및 스타일 타입과 함께 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하기 위해 가사 입력으로서 제공된다. 구체적으로, 도 95는 시스템 사용자에 의해 시스템에 노래 불려진 가사 입력으로서 제공되는 예에서 감정 행복 (예컨대, 찰스 스트라우스의 \"Put On A Happy Face\")의 노래 불려진 가사 표현(단어 세트) 특징을 프로세싱하는 방법을 실시할 때, 도 88의 시스템 내에서 실행되는 상위 단계를 설명한다. 도 95의 블록(A)에 나타낸 바와 같이, 실시간 피치 이벤트 분석 서브 시스템(B52)은 연속적으로 버퍼링되고 프 로세싱되는 음향 신호로서 노래 불려진 가사 입력을 수신한다. 도 95의 블록(B)에서, 서브 시스템(B52)은 로컬 사전을 이용하여 음성 등가 열을 생성하기 위해, A/D 및 다른 디지털 신호 프로세싱 기술을 이용하여 음향 신호를 자동으로 프로세싱한다. 도 95의 블록(C)에서, 음성 열의 이 음소에 기초하여, 서브 시스템(B52)은 음소 열에 존재하는 모음을 (디폴트) 모음 포맷의 열로 자동으로 변환한다. 모음 포맷은 실시간 음성 프로세싱 및 응용 언어학 분야에 공지된 실시간 분광사진술 및 그와 유사한 기술에 기초할 수 있는 모음 포먼트 분석기를 이용하여 자동으로 검색된다. 도 95의 블록(D)에서, 서브 시스템(B52)은 검출된 모음 포맷을 음악 음표의 열(예컨대, 이 사례에서는 리듬 정 보가 있는 피치 이벤트)로 자동으로 변환한다. 도 95의 블록(E)에서, 서브 시스템(B52)은 검출된 모음 포맷으로부터 음악 음표의 열(예컨대, 이 사례에서는 리 듬 정보가 있는 피치 이벤트)을 생성한다. 도 95의 블록(F)에서, 서브 시스템(B52)은 (예컨대, 노래 불려진 가사의 검출된 피치 이벤트 및 리듬 특징에 관 련된) 피치 이벤트 및 리듬 데이터를 파라미터 변환 엔진(B51)에 전송함으로써, 시스템에 제공된 음악적 경험 디스크립터의 감정 및 스타일 타입을 고려하여, 음악적 경험 디스크립터와 사양에 맞는 확률 기반 시스템 작동 파라미터를 생성하는 것을 보조한다. 여기서의 목적은 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하고, 본 발명의 자동화된 음악 작곡 프로세스 중에 시스템의 구동을 돕는 것이다. 그리고, 이와 같은 피치 이벤트 및 포착된 리듬 데이터는 전술한 바와 같이 서브 시스템(B52)에 의해 포착되는 피치 이벤트, 리듬 및 운율 정보에 의해 제약되는 시스템 사용자 입력을 위한 확률 기반 SOP 테이블 세트를 자동으로 생성하기 위해 파라미터 변환 엔진 서브 시스템(B51) 내에서 사용된다. 도 96는 본 발명의 자동화된 모음 포맷 분석법 및 다른 방법을 이용하여 도 95의 블록(E)에서 노래 불려진 가사 표현 내에서 자동으로 인식된 음악 음표의 스코어를 나타낸다. 나타낸 바와 같이, 각각의 음표는 대응하는 모음 의 제1 및 제2 포먼트의 비율에 대응하는 간격 내에 피치를 갖는다. 이제 도 97을 참조하면, (그래픽으로 표시된 모음에 할당된) 모음 포맷의 존재에 기초하여 타이핑된 가사로부터"}
{"patent_id": "10-2018-7011569", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "요약된 대응하는 피치 이벤트(예컨대, 음표)를 유도하기 위해 감정 슬픔 또는 우울함(예컨대, 이, 입 하버그 및 해롤드 알렌의 \"Somewhere Over The Rainbow\")의 타이핑된 가사 표현(단어 세트) 특징을 프로세싱하는 실시간 피치 이벤트 분석 서브 시스템(B52)이 도시되어 있으며, 이 피치 이벤트는 통상적으로 시스템에 제공된 음악적 경험 디스크립터의 감정 및 스타일 타입과 함께 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하기 위해 가사 입력으로서 제공된다. 구체적으로, 도 97은 시스템 사용자에 의해 시스템에 타이핑된 가사 입력으로서 제공되는 예에서 감정 슬픔 또 는 우울함(예컨대, 이, 입 하버그 및 해롤드 알렌의 \"Somewhere Over The Rainbow\")의 타이핑된 가사 표현(단어 세트) 특징을 프로세싱하는 방법을 실시할 때, 도 88의 시스템 내에서 실행되는 상위 단계를 설명한다. 도 97의 블록(A)에 나타낸 바와 같이, 실시간 피치 이벤트 분석 서브 시스템(B52)은 문자소(또는 형태소)의 열 로서 텍스트 기반 가사 입력을 수신한다. 도 97의 블록(B)에서, 서브 시스템(B52)은 텍스트 열을 로컬 사전을 이용하여 음성 등가 열로 자동으로 전사한 다. 도 97의 블록(C)에서, 음성 열의 이 음소에 기초하여, 서브 시스템(B52)은 음소 열에 존재하는 모음을 (디폴트) 모음 포맷의 열로 자동으로 변환한다. 바람직하게, 디폴트 모음 포맷은 텍스트 기반 표현을 위해 도 90b의 어휘 사전에 나열되는 반면, 모음 포맷은 실시간 음성 프로세싱 및 응용 언어학 분야에 공지된 실시간 분광사진술 및 그와 유사한 기술에 기초할 수 있는 모음 포먼트 분석기를 이용하여 자동으로 검색된다. 도 97의 블록(D)에서, 서브 시스템(B52)은 검출된 모음 포맷을 음악 음표의 열(예컨대, 이 사례에서는 리듬 정 보가 없는 피치 이벤트)로 자동으로 변환한다. 도 97의 블록(E)에서, 서브 시스템(B52)은 모음 포먼트의 열로부터 음표의 열(예컨대, 피치 이벤트)을 생성한다. 도 97의 블록(F)에서, 서브 시스템(B52)은 (예컨대, 검출된 피치 이벤트에 관련된) 피치 이벤트 데이터를 파라 미터 변환 엔진(B51)에 전송함으로써, 시스템에 제공된 음악적 경험 디스크립터의 감정 및 스타일 타입을 고려 하여, 음악적 경험 디스크립터와 사양에 맞는 확률 기반 시스템 작동 파라미터를 생성하는 것을 보조한다. 여기 서의 목적은 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하고, 본 발명의 자동화된 음악 작곡 프로세스 중에 시스템의 구동을 돕는 것이다. 그리고, 이와 같은 피치 이벤트 및 포착된 리듬 데이터는 전술한 바와 같이서브 시스템(B52)에 의해 포착되는 피치 이벤트, 리듬 및 운율 정보에 의해 제약되는 시스템 사용자 입력을 위 한 확률 기반 SOP 테이블 세트를 자동으로 생성하기 위해 파라미터 변환 엔진 서브 시스템(B51) 내에서 사용된 다. 이제 도 98을 참조하면, (그래픽으로 표시된 모음에 할당된) 모음 포맷의 존재에 기초하여 말로 전해진 가사로"}
{"patent_id": "10-2018-7011569", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "부터 요약된 대응하는 피치 이벤트(예컨대, 음표)를 유도하기 위해 감정 슬픔 또는 우울함(예컨대, 이, 입 하버 그 및 해롤드 알렌의 \"Somewhere Over The Rainbow\")의 말로 전해진 가사 표현(단어 세트) 특징을 프로세싱하는 실시간 피치 이벤트 분석 서브 시스템(B52)이 도시되어 있으며, 이 피치 이벤트는 통상적으로 시스템에 제공된 음악적 경험 디스크립터의 감정 및 스타일 타입과 함께 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하기 위해 가사 입력으로서 제공된다. 구체적으로, 도 98은 시스템 사용자에 의해 시스템에 타이핑된 가사 입력으로서 제공되는 예에서 감정 슬픔 또 는 우울함(예컨대, 이, 입 하버그 및 해롤드 알렌의 \"Somewhere Over The Rainbow\")의 말로 전해진 가사 표현 (단어 세트) 특징을 프로세싱하는 방법을 실시할 때, 도 88의 시스템 내에서 실행되는 상위 단계를 설명한다. 도 98의 블록(A)에 나타낸 바와 같이, 실시간 피치 이벤트 분석 서브 시스템(B52)은 음향 신호로서 말로 전해진 가사 입력을 수신한다. 도 98의 블록(B)에서, 서브 시스템(B52)은 당업계에 공지된 로컬 사전 및 음성 인식 방법을 이용하여 음성 등가 열을 생성하기 위해, A/D 및 디지털 신호 프로세싱 기술을 이용하여 음향 신호를 자동으로 프로세싱한다. 도 98의 블록(C)에서, 음성 열의 이 음소에 기초하여, 서브 시스템(B52)은 음소 열에 존재하는 모음을 (디폴트) 모음 포맷의 열로 자동으로 변환한다. 바람직하게, 디폴트 모음 포맷은 텍스트 기반 표현을 위해 도 90b의 어휘 사전에 나열되는 반면, 모음 포맷은 실시간 음성 프로세싱 및 응용 언어학 분야에 공지된 실시간 분광사진술 및 그와 유사한 기술에 기초할 수 있는 모음 포먼트 분석기를 이용하여 자동으로 검색된다. 도 98의 블록(D)에서, 서브 시스템(B52)은 검출된 모음 포맷을 음악 음표의 열(예컨대, 이 사례에서는 리듬 데 이터가 있는 피치 이벤트)로 자동으로 변환한다. 도 98의 블록(E)에서, 서브 시스템(B52)은 모음 포먼트의 열로부터 음표의 열(예컨대, 리듬 데이터가 있는 피치 이벤트)을 생성한다. 도 98의 블록(F)에서, 서브 시스템(B52)은 (예컨대, 검출된 피치 이벤트 및 리듬 특징에 관련된) 피치 이벤트 데이터를 파라미터 변환 엔진(B51)에 전송함으로써, 시스템에 제공된 음악적 경험 디스크립터의 감정 및 스타일 타입을 고려하여, 음악적 경험 디스크립터와 사양에 맞는 확률 기반 시스템 작동 파라미터를 생성하는 것을 보 조한다. 여기서의 목적은 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하고, 본 발명의 자동화된 음악 작 곡 프로세스 중에 시스템의 구동을 돕는 것이다. 그리고, 이와 같은 피치 이벤트 및 포착된 리듬 데이터는 전술 한 바와 같이 서브 시스템(B52)에 의해 포착되는 피치 이벤트, 리듬 및 운율 정보에 의해 제약되는 시스템 사용 자 입력을 위한 확률 기반 SOP 테이블 세트를 자동으로 생성하기 위해 파라미터 변환 엔진 서브 시스템(B51) 내 에서 사용된다. 이제 도 99을 참조하면, (그래픽으로 표시된 모음에 할당된) 모음 포맷의 존재에 기초하여 노래 불려진 가사로"}
{"patent_id": "10-2018-7011569", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "부터 요약된 대응하는 피치 이벤트(예컨대, 음표)를 유도하기 위해 감정 슬픔 또는 우울함(예컨대, 이, 입 하버 그 및 해롤드 알렌의 \"Somewhere Over The Rainbow\")의 노래 불려진 가사 표현(단어 세트) 특징을 프로세싱하는 실시간 피치 이벤트 분석 서브 시스템(B52)이 도시되어 있으며, 이 피치 이벤트는 통상적으로 시스템에 제공된 음악적 경험 디스크립터의 감정 및 스타일 타입과 함께 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하기 위해 가사 입력으로서 제공된다. 구체적으로, 도 99은 시스템 사용자에 의해 시스템에 노래 불려진 가사 입력으로서 제공되는 예에서 감정 슬픔 또는 우울함(예컨대, 이, 입 하버그 및 해롤드 알렌의 \"Somewhere Over The Rainbow\")의 노래 불려진 가사 표현 (단어 세트) 특징을 프로세싱하는 방법을 실시할 때, 도 88의 시스템 내에서 실행되는 상위 단계를 설명한다. 도 99의 블록(A)에 나타낸 바와 같이, 실시간 피치 이벤트 분석 서브 시스템(B52)은 연속적으로 버퍼링되고 프 로세싱되는 음향 신호로서 노래 불려진 가사 입력을 수신한다. 도 99의 블록(B)에서, 서브 시스템(B52)은 로컬 사전을 이용하여 음성 등가 열을 생성하기 위해, A/D 및 다른 디지털 신호 프로세싱 기술을 이용하여 음향 신호를 자동으로 프로세싱한다.도 99의 블록(C)에서, 음성 열의 이 음소에 기초하여, 서브 시스템(B52)은 음소 열에 존재하는 모음으로부터 (디폴트) 모음 포맷의 열을 자동으로 생성한다. 모음 포맷은 실시간 음성 프로세싱 및 응용 언어학 분야에 공지 된 실시간 분광사진술 및 그와 유사한 기술을 이용하여 실현될 수 있는 서브 시스템(B52) 내의 모음 포먼트 분 석기(VFA)를 이용하여 자동으로 검색된다. 도 99의 블록(E)에서, 서브 시스템(B52)은 검출된 모음 포맷으로부터 음악 음표의 열(예컨대, 이 사례에서는 리 듬 데이터가 있는 피치 이벤트)을 자동으로 생성한다. 도 99의 블록(F)에서, 서브 시스템(B52)은 (예컨대, 노래 불려진 가사의 검출된 피치 이벤트 및 리듬 특징에 관 련된) 피치 이벤트 및 리듬 데이터를 파라미터 변환 엔진(B51)에 전송함으로써, 시스템에 제공된 음악적 경험 디스크립터의 감정 및 스타일 타입을 고려하여, 음악적 경험 디스크립터와 사양에 맞는 확률 기반 시스템 작동 파라미터를 생성하는 것을 보조한다. 여기서의 목적은 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하고, 본 발명의 자동화된 음악 작곡 프로세스 중에 시스템의 구동을 돕는 것이다. 그리고, 이와 같은 피치 이벤트 및 포착된 리듬 데이터는 전술한 바와 같이 서브 시스템(B52)에 의해 포착되는 피치 이벤트, 리듬 및 운율 정보에 의해 제약되는 시스템 사용자 입력을 위한 확률 기반 SOP 테이블 세트를 자동으로 생성하기 위해 파라미터 변환 엔진 서브 시스템(B51) 내에서 사용된다. 도 100는 본 발명의 자동화된 모음 포맷 분석법 및 다른 방법을 이용하여 도 100의 블록(E)에서 노래 불려진 가 사 표현 내에서 자동으로 인식된 음악 음표의 스코어를 나타낸다. 나타낸 바와 같이, 각각의 음표는 대응하는 모음의 제1 및 제2 포먼트의 비율에 대응하는 음계 상의 간격 내에 피치를 갖는다. 다른 애플리케이션에서의 본 발명의 자동화된 음악 작곡 및 생성 엔진의 채택 본 발명의 자동화된 음악 작곡 및 생성 엔진은 본 발명의 개시물이 설명한 애플리케이션 이외의 많은 애플리케 이션에서 사용될 것이다. 예컨대, 시스템이 무기한 지속되는 음악 또는 홀드 뮤직(즉, 스트리밍 음악)을 제공하기 위해 사용되는 용례를 고려하기로 한다. 이 애플리케이션에서, 시스템은 명확하거나 불명확한 길이의 특이한 음악을 생성하기 위해 사 용될 것이다. 시스템은 음악적 경험 및 스타일 세트를 전달하도록 구성될 수 있으며, 음악을 변경하기 위해 실 시간 오디오, 비주얼, 또는 텍스트 입력에 대해 반응할 수 있고, 음악을 변화시킴으로써, 오디오, 비주얼, 또는 텍스트 입력을 소기의 프로그램된 음악적 경험 및 스타일에 맞추는 작업을 할 수 있다. 예컨대, 시스템은 소비 자를 진정시키기 위해 홀드 뮤직에서, (판매를 더 촉진하기 위해) 긴급성과 필요성의 감정을 유도하기 위해 소 매점에서, 광고 음악을 콘텐츠의 각 개별 소비자와 잘 맞추기 위해 맥락 관련 광고에서 사용될 수 있다. 다른 용례는 시스템이 가상 현실 또는 다른 소셜 환경에서 실제로 또는 가상으로 라이브 스코어 음악을 제공하 기 위해 사용되는 경우일 것이다. 여기서, 시스템은 음악적 경험 및 스타일 세트를 전달하도록 구성될 수 있으 며, 실시간 오디오, 비주얼, 또는 텍스트 입력에 대해 반응할 수 있다. 이와 같은 방식으로, 시스템은 경험 제 약에서 특정 수준의 유연성과 연동하는 \"라이브 스코어\" 콘텐츠 경험을 할 수 있다. 예컨대, 흔히 게임을 플레 이하는 매우 다양한 방식과 승급하기 위한 매우 다양한 과정이 있는 비디오 게임에서, 시스템은 특정 시발점에 도달할 때까지 반복되는 미리 제작된 음악에 의존하는 (전통적인 방법) 대신 게임이 플레이될 때 게임용 음악을 정확하게 생성할 수 있을 것이다. 이 시스템은 가상 현실 및 복합 현실 시뮬레이션 및 경험에서도 쓸모가 있을 것이다. 본 발명의 예시적인 실시형태의 변형 상기한 예시적 실시형태를 참조하여 본 발명을 상세하게 설명하였다. 그러나, 본 발명의 개시물을 읽을 수 있는 혜택을 받는 당업자에게는 수많은 변형이 쉽게 떠오를 것이다. 대안적인 실시형태에서, 본 발명의 자동화된 음악 작곡 및 생성 시스템은 본 발명의 원리에 따라 시스템 사용자 가 제공한 다른 음악적 경험 디스크립터와 함께 프로세싱 및 사용하기 위해 시스템 입력 인터페이스에 대한, 예 컨대, 음표, 화음, 피치, 멜로디, 리듬, 템포 및 다른 음악 품질과 같이 인습적으로 기보되는 음악 정보의 입력 을 지원하도록 변형될 수 있다. 예컨대, 상술한 본 발명의 대안적인 실시형태에서, 시스템은 독립형 장비, 악기, 내장형 시스템, 기업 수준 시 스템, 분산형 시스템 및 소셜 통신 네트워크, 이메일 통신 네트워크, SMS 메시징 네트워크, 전기 통신 시스템 등에 내장된 애플리케이션으로 실현될 수 있다. 이와 같은 대안적인 시스템의 구성은 본 발명의 원리와 기술을 이용하는 제품이나 서비스에 대한 특정 최종 사용자 애플리케이션과 목표 시장에 의존할 것이다.선행 기술 시스템의 방식 특징에서 음악 루프들을 함께 연결하는 것과는 완전히 대조적으로, 본원에 개시된 바 람직한 실시형태는 음향적으로 실현된 음표, 화음, 리듬 및 자동화된 음악 작곡에서 특정된 다른 이벤트를 생성 하기 위해 가상 악기 음악 합성의 사용을 교시하였지만, 본 발명의 자동화된 음악 작곡 및 생성 시스템은 시스 템에 의해 생성된 음악 스코어 표현을 조정하고, 이 시스템 출력 수준을 MIDI 제어 신호로 전환하여 하나 이상 의 MIDI 기반 음악 악기 그룹을 구동 및 제어함으로써 다른 사람들의 즐거움을 위해 자동으로 작곡된 음악을 제 작할 수 있도록 변환될 수 있는 것으로 이해된다. 이와 같은 자동화된 음악 작곡 및 생성 시스템은 팻 메시니의 2010년 오케스트리온 프로젝트 중에 전시된 바와 같은 MIDI 제어 악기 그룹 전체를 구동할 수 있다. 이와 같은 자동화된 음악 작곡 및 생성 시스템은 상업적으로 이용가능한 PIANODISC® 및 YAMAHA® MIDI 기반 음악 생성 시 스템의 대안으로서 가정이나 상업적 환경에서 이용가능하게 될 수 있다. 본 발명의 이와 같은 대안적인 실시형 태는 본원에 개시된 시스템 및 모델에 포함되며, 본 발명의 정신 및 범위 내에 속한다. 본 발명의 다양한 자동화된 음악 작곡 및 생성 기계, 엔진, 장치, 악기 및 로봇(즉, 시스템)을 구현하기 위한 다양한 방법과 수단이 개시되었지만, 본 발명의 개시물의 혜택을 받는 당업자에게는 다른 대안적인 방법과 수단 이 쉽게 떠오를 것이다. 여타 모든 그와 같은 변경 및 변형은 첨부된 특허 청구 범위에 의해 규정된 바와 같은 본 발명의 사상 및 범위 에 속하는 것으로 간주된다."}
{"patent_id": "10-2018-7011569", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 목적은 도면과 함께 읽을 경우 보다 완벽하게 이해될 것이다. 도 1은 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성의 사용 을 지원하는 본 발명의 자동화된 음악 작곡 및 생성 시스템(즉, 기계)의 상위 시스템 아키텍처를 도시한 개략도 이며, 언어 기반 음악적 경험 디스크립터와 비디오, 오디오 레코딩, 이미지, 또는 이벤트 마커는 시스템 사용자 인터페이스를 통해 입력으로서 제공되고, 본 발명의 자동화된 음악 작곡 및 생성 엔진에 의해 사용되어 시스템 사용자 인터페이스를 통해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된 미디어(예컨대, 비디오, 팟 캐스트, 이미지, 슬라이드 쇼 등) 또는 이벤트 마커를 생성시킨다. 도 2는 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성의 사용 을 지원하는 본 발명의 일반화된 자동화된 음악 작곡 및 생성 프로세스를 실행하는 데 포함되는 주요 단계를 도 시한 흐름도이며, (i) 프로세스의 제1단계에서, 시스템 사용자는 본 발명의 자동화된 음악 작곡 및 생성 시스템 에 액세스한 다음, 본 발명의 자동화된 음악 작곡 및 생성 시스템에 의해 생성된 음악으로 스코어링될 비디오, 오디오 레코딩(예컨대, 팟 캐스트), 슬라이드 쇼, 사진이나 이미지 또는 이벤트 마커를 선택하고, (ii) 그 다음, 시스템 사용자는 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 시스템의 자동화된 음악 작곡 및 생성 엔진에 제공하며, (iii) 시스템 사용자는 자동화된 음악 작곡 및 생성 시스템을 기동하여 선택된 미디 어 또는 이벤트 마커에 스코어링되어 있는 입력된 음악적 디스크립터에 기초한 음악을 작곡 및 생성하며, (iv) 시스템 사용자는 스코어링된 미디어 또는 이벤트 마커에 대해 제작된 작곡 및 생성된 음악을 수용하고, 시스템 사용자가 주관적으로 경험하여 형성된 음악적 경험을 고려하여 제작된 음악에 대한 시스템 사용자의 평가 및/또 는 음악 선호도에 관한 피드백을 시스템에 제공하며, (v) 시스템은 수용한 작곡된 음악을 선택된 미디어 또는 이벤트 마커와 조합하여, 분배 및 표시하기 위한 비디오 파일을 제작한다. 도 3은 콤팩트한 휴대용 하우징 내에 제공된 텍스트 키보드 및/또는 음성 인식 인터페이스를 사용하여 생성된 언어 기반 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성을 지원하는 본 발명의 제1 예시적 실 시형태에 따른 자동화된 음악 작곡 및 생성 악기 시스템의 사시도를 나타낸다.도 4는 시스템 버스 아키텍처 주변에 집적된 SOC 기반 서브 아키텍처의 다양한 구성 요소와 기타 시스템 구성 요소를 나타내는 텍스트 키보드 및/또는 음성 인식 인터페이스를 사용하여 생성된 언어 기반 음악적 경험 디스 크립터에 의해 구동되는 가상 악기 음악 합성을 지원하는 본 발명의 제1 예시적 실시형태의 자동화된 음악 작곡 및 생성 악기 시스템의 예시적 구현의 개략도이다. 도 5는 텍스트 키보드 및/또는 음성 인식 인터페이스를 사용하여 생성된 언어 기반 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성을 지원하는 제1 예시적 실시형태의 자동화된 음악 작곡 및 생성 악기 시스 템의 상위 시스템 블록도이며, 언어 기반 음악적 경험 디스크립터와 비디오, 오디오 레코딩, 이미지, 또는 이벤 트 마커는 시스템 사용자 인터페이스를 통해 입력으로서 제공되고, 본 발명의 자동화된 음악 작곡 및 생성 엔진 에 의해 사용되어 시스템 사용자 인터페이스를 통해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된 미디어(예컨대, 비디오, 팟 캐스트, 이미지, 슬라이드 쇼 등) 또는 이벤트 마커를 생성시킨다. 도 6은 도 3 내지 도 5에 나타낸 악기 시스템을 사용하여 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크 립터와 가상 악기 음악 합성의 사용을 지원하는 본 발명의 제1 예시적 실시형태의 자동화된 음악 작곡 및 생성 프로세스를 실행하는 데 포함되는 주요 단계를 도시한 흐름도이며, (i) 프로세스의 제1단계에서, 시스템 사용자 는 본 발명의 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 본 발명의 자동화된 음악 작곡 및 생성 시 스템에 의해 생성된 음악으로 스코어링될 비디오, 오디오 레코딩(즉, 팟 캐스트), 슬라이드 쇼, 사진이나 이미 지 또는 이벤트 마커를 선택하고, (ii) 그 다음, 시스템 사용자는 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 시스템의 자동화된 음악 작곡 및 생성 엔진에 제공하며, (iii) 시스템 사용자는 자동화된 음악 작 곡 및 생성 시스템을 기동하고, 선택된 미디어 또는 이벤트 마커에 스코어링되어 있는 입력된 음악적 디스크립 터에 기초하여 음악을 작곡 및 생성하며, (iv) 시스템 사용자는 스코어링된 미디어 또는 이벤트 마커에 대해 제 작된 작곡 및 생성된 음악을 수용하고, 시스템 사용자가 주관적으로 경험하여 형성된 음악적 경험을 고려하여 제작된 음악에 대한 시스템 사용자의 평가 및/또는 음악 선호도에 관한 피드백을 시스템에 제공하며, (v) 시스 템은 수용한 작곡된 음악을 선택된 미디어 또는 이벤트 마커와 조합하여, 분배 및 표시하기 위한 비디오 파일을 제작한다. 도 7은 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성을 사용한 본 발명의 제2 예 시적 실시형태의 자동화된 음악 작곡 및 생성 엔진을 지원하는 장난감 악기의 사시도를 나타내며, 라이브러리로 부터 비디오를 선택하여 로드하도록 터치 스크린 디스플레이가 제공되며, 그 다음, 어린이는 물리적 키보드로부 터 음악적 경험 디스크립터(예컨대, 감정 디스크립터 아이콘 및 스타일 디스크립터 아이콘)를 선택할 수 있음으 로써, 어린이가 선택된 비디오의 분절된 장면에 대해 지정 음악을 작곡 및 생성할 수 있게 된다. 도 8은 키보드 인터페이스를 사용하여 시스템 사용자에 의해 선택된 그래픽 아이콘 기반 음악적 경험 디스크립 터에 의해 구동되는 가상 악기 음악 합성의 사용을 지원하는 본 발명의 제2 예시적 실시형태의 자동화된 음악 작곡 및 생성 악기 시스템의 예시적 구현의 개략도이며, 시스템 버스 아키텍처 주변에 집적된, 하드 드라이브 (SATA)와 인터페이싱하는 멀티 코어 CPU, 멀티 코어 GPU, 프로그램 메모리(DRAM), 비디오 메모리(VRAM)와 같은 SOC 기반 서브 아키텍처, LCD/터치 스크린 디스플레이 패널, 마이크/스피커, 키보드, WIFI/블루투스 네트워크 어댑터, 및 전원 공급 장치 및 분배 회로의 다양한 구성 요소를 나타낸다. 도 9는 제2 예시적 실시형태의 자동화된 장난감 음악 작곡 및 생성 장난감 악기 시스템의 상위 시스템 블록도이 며, 그래픽 아이콘 기반 음악적 경험 디스크립터와 비디오가 시스템 사용자 인터페이스(즉, 터치 스크린 키보드)를 통해 입력으로서 선택되고, 본 발명의 자동화된 음악 작곡 및 생성 엔진에 의해 사용되어, 시스템 사 용자 인터페이스를 통해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된 비디오 스토리를 생성한다. 도 10은 도 7 내지 도 9에 나타낸 악기 시스템을 사용하여 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성의 사용을 지원하는 본 발명의 제2 예시적 실시형태의 장난감 음악 작곡 및 생성 시스템 내에서 자동화된 음악 작곡 및 생성 프로세스를 실행하는 데 포함되는 주요 단계를 도시한 흐름도이며, (i) 프로세스의 제1단계에서, 시스템 사용자는 본 발명의 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 본 발명의 자동화된 음악 작곡 및 생성 엔진에 의해 생성된 음악으로 스코어링될 비디오를 선택하고, (ii) 시스 템 사용자는 시스템의 자동화된 음악 작곡 및 생성 엔진에 제공될 그래픽 아이콘 기반 음악적 경험 디스크립터 를 선택하며, (iii) 시스템 사용자는 자동화된 음악 작곡 및 생성 엔진을 기동하고, 선택된 비디오 미디어에 스 코어링되어 있는 입력된 음악적 디스크립터에 기초하여 음악을 작곡 및 생성하며, (iv) 시스템은 작곡된 음악을 선택된 비디오와 조합하여, 표시 및 향유하기 위한 비디오 파일을 제작한다. 도 11은 그 시스템 사용자의 창조적 및/또는 오락적 요구를 지원하는 도출된 시스템 내에 본 발명의 SOC 기반의자동화된 음악 작곡 및 생성 엔진을 통합한 본 발명의 제3 예시적 실시형태에 따른 전자 정보 프로세싱 및 디스 플레이 시스템의 사시도이다. 도 11a는 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성의 사 용을 지원하는 본 발명의 SOC 기반 음악 작곡 및 생성 시스템의 상위 시스템 아키텍처를 도시한 개략도이며, 언 어 기반 음악적 경험 디스크립터와 비디오, 오디오 레코딩, 이미지, 슬라이드 쇼 또는 이벤트 마커는 시스템 사 용자 인터페이스를 통해 입력으로서 제공되고, 본 발명의 자동화된 음악 작곡 및 생성 엔진에 의해 사용되어 시 스템 사용자 인터페이스를 통해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된 미디어(예컨대, 비디 오, 팟 캐스트, 이미지, 슬라이드 쇼 등) 또는 이벤트 마커를 생성시킨다. 도 11b는 고상(DRAM) 하드 드라이브(SATA)와 인터페이싱하는 것으로 나타낸 멀티 코어 CPU, 멀티 코어 GPU, 프 로그램 메모리(RAM) 및 비디오 메모리(VRAM)를 포함한 SOC 기반 서브 시스템 아키텍처, 컨트롤러 등을 지원하는 하나 이상의 버스 아키텍처와 집적된 LCD/터치 스크린 디스플레이 패널, 마이크 스피커, 키보드 또는 키패드, WIFI/블루투스 네트워크 어댑터, 및 3G/LTE/GSM 네트워크 어댑터를 포함하는 도 11 및 도 11a에 도시된 시스템 의 개략도이다. 도 12는 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성의 사 용을 지원하는 도 11 및 도 11a에 나타낸 SOC 기반 시스템을 이용한 본 발명의 자동화된 음악 작곡 및 생성 프 로세스를 실행하는 데 포함되는 주요 단계를 도시한 흐름도이며, (i) 프로세스의 제1단계에서, 시스템 사용자는 본 발명의 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 본 발명의 자동화된 음악 작곡 및 생성 시스템 에 의해 생성된 음악으로 스코어링될 비디오, 오디오 레코딩(즉, 팟 캐스트), 슬라이드 쇼, 사진이나 이미지 또 는 이벤트 마커를 선택하고, (ii) 그 다음, 시스템 사용자는 언어 기반 및/또는 아이콘 기반 음악적 경험 디스 크립터를 시스템의 자동화된 음악 작곡 및 생성 엔진에 제공하며, (iii) 시스템 사용자는 자동화된 음악 작곡 및 생성 시스템을 기동하고, 선택된 미디어 또는 이벤트 마커에 스코어링되어 있는 입력된 음악적 디스크립터에 기초하여 음악을 작곡 및 생성하며, (iv) 시스템 사용자는 스코어링된 미디어 또는 이벤트 마커에 대해 제작된 작곡 및 생성된 음악을 수용하고, 시스템 사용자가 주관적으로 경험하여 형성된 음악적 경험을 고려하여 제작된 음악에 대한 시스템 사용자의 평가 및/또는 음악 선호도에 관한 피드백을 시스템에 제공하며, (v) 시스템은 수 용한 작곡된 음악을 선택된 미디어 또는 이벤트 마커와 조합하여, 분배 및 표시하기 위한 비디오 파일을 제작한 다. 도 13은 인터넷 인프라에 작동 가능하게 연결된 웹 서버, 애플리케이션 서버 및 데이터베이스(RDBMS) 서버를 갖 춘 데이터 프로세싱 센터에 의해 지원되며, 클라이언트 머신, 소셜 네트워크 서버 및 웹 기반 통신 서버에 의해 액세스될 수 있고, 웹 사이트(예컨대, 유튜브, 비메오 등)에서 웹 기반 브라우저를 이용하여 누구나 자동화된 음악 작곡 및 생성 서비스에 액세스할 수 있도록 함으로써, 텍스트 키보드 및/또는 음성 인식 인터페이스를 사 용하여 생성된 언어 기반 음악적 경험 디스크립터와 가상 악기 음악 합성을 사용하여 음악으로 비디오, 이미지, 슬라이드 쇼, 오디오 레코딩 및 기타 이벤트를 스코어링하는, 본 발명의 제4 예시적 실시형태의 기업 수준의 인 터넷 기반 음악 작곡 및 생성 시스템의 개략도이다. 도 13a는 언어 및/또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성의 사 용을 지원하는 도 13에 나타낸 시스템에 의해 지원되는 자동화된 음악 작곡 및 생성 프로세스의 상위 시스템 아 키텍처를 도시한 개략도이며, 언어 기반 음악적 경험 디스크립터와 비디오, 오디오 레코딩, 이미지 또는 이벤트 마커는 웹 기반 시스템 사용자 인터페이스를 통해 입력으로서 제공되고, 본 발명의 자동화된 음악 작곡 및 생성 엔진에 의해 사용되어 시스템 사용자 인터페이스를 통해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링 된 미디어(예컨대, 비디오, 팟 캐스트, 이미지, 슬라이드 쇼 등) 또는 이벤트 마커를 생성시킨다. 도 13b는 도 13 및 도 13a에 도시된 기업 수준의 자동화된 음악 작곡 및 생성 시스템을 구현하기 위해 하나 이 상이 사용될 수 있는 예시적인 컴퓨팅 서버 머신의 시스템 아키텍처의 개략도이다. 도 14는 도 13 및 도 13a에 도시된 시스템에 의해 지원되는 본 발명의 자동화된 음악 작곡 및 생성 프로세스를 실행하는 데 포함되는 주요 단계를 도시한 흐름도이며, (i) 프로세스의 제1단계에서, 시스템 사용자는 본 발명 의 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 본 발명의 자동화된 음악 작곡 및 생성 시스템에 의해 생성된 음악으로 스코어링될 비디오, 오디오 레코딩(즉, 팟 캐스트), 슬라이드 쇼, 사진이나 이미지 또는 이벤 트 마커를 선택하고, (ii) 그 다음, 시스템 사용자는 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 시스템의 자동화된 음악 작곡 및 생성 엔진에 제공하며, (iii) 시스템 사용자는 자동화된 음악 작곡 및 생성 시 스템을 기동하고, 선택된 미디어 또는 이벤트 마커에 스코어링되어 있는 입력된 음악적 디스크립터에 기초하여음악을 작곡 및 생성하며, (iv) 시스템 사용자는 스코어링된 미디어 또는 이벤트 마커에 대해 제작된 작곡 및 생성된 음악을 수용하고, 시스템 사용자가 주관적으로 경험하여 형성된 음악적 경험을 고려하여 제작된 음악에 대한 시스템 사용자의 평가 및/또는 음악 선호도에 관한 피드백을 시스템에 제공하며, (v) 시스템은 수용한 작 곡된 음악을 선택된 미디어 또는 이벤트 마커와 조합하여, 분배 및 표시하기 위한 비디오 파일을 제작한다. 도 15a는 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스 (GUI) 스크린이며, (i) 본 발명의 자동화된 음악 작곡 및 생성 프로세스에서의 제1단계로서 시스템에 업로드하 기 위한 비디오 선택과, (ii) 시스템 사용자가 본 발명의 자동화된 음악 작곡 및 생성 시스템을 기동할 수 있도 록 하는 음악 작곡 전용 옵션을 위한 인터페이스 객체가 표시되어 있다. 도 15b는 시스템 사용자가 도 15a의 GUI의 \"비디오 선택\" 객체를 선택할 때 도 13 내지 도 14에 도시된 시스템 에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이며, 시스템은 사용자가 서로 다 른 여러 로컬 및 원격 파일 저장 위치(예컨대, 로컬 포토 앨범, 클라우드에 호스팅된 공유 폴더, 및 개인의 스 마트 폰 카메라 롤로부터의 로컬 포토 앨범)로부터 비디오 파일을 선택할 수 있도록 한다. 도 15c는 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스 (GUI) 스크린이며, 선택된 비디오가 본 발명의 원리에 따라 스코어링하기 위해 표시된다. 도 15d는 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스 (GUI) 스크린이며, 시스템 사용자가 찾는 음악적 경험을 선택하고 특징짓는 4개의 예시적인 감정 클래스(즉, 드 라마, 액션, 코미디 및 공포)를 표시하기 위해, 시스템 사용자는 음악 감정/음악 스타일/음악 스포팅(spotting) 메뉴로부터 \"음악 감정\" 카테고리를 선택한다. 도 15e는 음악 감정 카테고리-드라마를 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이다. 도 15f는 음악 감정 카테고리-드라마를 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이며, 시스템 사용자가 선택된 비디오 를 스코어링하기 위해 드라마-분류된 감정-행복, 로맨틱 및 영감을 후속하여 선택하였다. 도 15g는 음악 감정 카테고리-액션을 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의 해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이다. 도 15h는 음악 감정 카테고리-액션을 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의 해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이며, 시스템 사용자가 선택된 비디오를 스코어링하기 위해 액션-분류된 감정-흥분 및 스파이를 후속하여 선택하였다. 도 15i는 음악 감정 카테고리-코미디를 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이다. 도 15j는 음악 감정 카테고리-드라마를 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이며, 시스템 사용자가 선택된 비디오 를 스코어링하기 위해 코미디-분류된 감정-별난 및 슬랩 스틱을 후속하여 선택하였다. 도 15k는 음악 감정 카테고리-공포를 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의 해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이다. 도 15l는 음악 감정 카테고리-공포를 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의 해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이며, 시스템 사용자가 선택된 비디오를 스코어링하기 위해 공포-분류된 감정-유혈, 충격 및 미스터리를 후속하여 선택하였다. 도 15m은 음악 감정 카테고리의 선택을 종료하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이며, \"당신의 음악을 제작할 준비가 되었나요?\" Amper를 작동시키려면 작곡을 누르고 당신의 선택 사항을 편집하려면 취소를 누르세요\"--메시지를 시스템 사용자에게 표시하고 있다. 도 15n은 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스 (GUI) 스크린이며, 시스템 사용자가 찾는 음악적 경험을 선택하고 특징짓는 20개의 스타일(즉, 팝, 록, 힙합 등)을 표시하기 위해, 시스템 사용자는 음악 감정/음악 스타일/음악 스포팅 메뉴로부터 \"음악 스타일\" 카테고리를 선택한다. 도 15o는 음악 스타일 카테고리-팝 및 피아노를 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이다. 도 15p는 음악 스타일 카테고리의 선택을 종료하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템 에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이며, \"당신의 음악을 제작할 준비 가 되었나요?\" Amper를 작동시키려면 작곡을 누르고 당신의 선택 사항을 편집하려면 취소를 누르세요\"--메시지 를 시스템 사용자에게 표시하고 있다. 도 15q는 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스 (GUI) 스크린이며, 시스템 사용자가 음악 스포팅 기능 중에 선택할 수 있는 6개의 명령--\"시작\", \"정지\", \"히트\", \"페이드 인\", \"페이드 아웃\" 및 \"새로운 분위기\" 명령을 표시하기 위해, 시스템 사용자는 음악 감정/음 악 스타일/음악 스포팅 메뉴로부터 \"음악 스포팅\" 카테고리를 선택한다. 도 15r은 기능 메뉴로부터 \"음악 스포팅\"을 선택하는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스 템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이며, 도시된 바와 같이 선택된 비디오에 스코어링되어 있는 \"시작\", \"정지\" 및 명령을 나타내고 있다. 도 15s는 음악 스포팅 기능의 종료에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예 시적인 그래픽 사용자 인터페이스(GUI) 스크린이며, \"당신의 음악을 제작할 준비가 되었나요? Amper를 작동시키 려면 작곡을 누르고 당신의 선택 사항을 편집하려면 취소를 누르세요\"--메시지를 시스템 사용자에게 표시하고 있다. 도 15t는 \"작곡\" 버튼을 누르는 시스템 사용자에 응답한 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서 비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이다. 도 15u는 시스템 사용자의 작곡된 음악이 검토할 준비가 되었을 때 도 13 내지 도 14에 도시된 시스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이다. 도 15v는 음악 작곡이 생성되었고 선택된 비디오에 대한 미리 보기가 준비된 후 도 13 내지 도 14에 도시된 시 스템에 의해 생성 및 서비스되는 예시적인 그래픽 사용자 인터페이스(GUI) 스크린이며, 시스템 사용자에게는 음 악 조각에 대해 설정된 음악적 경험 디스크립터를 편집하고 음악 작곡을 다시 컴파일하거나, 작곡되어 생성된 음악 조각을 수용하고 오디오와 비디오를 믹싱하여 스코어링된 비디오 파일을 제작하는 옵션이 제공된다. 도 16은 본 발명의 제5 예시적 실시형태에 따른 자동화된 음악 작곡 및 생성 시스템의 사시도이며, 본 발명의 자동화된 음악 작곡 및 생성 엔진과 텍스트, SMS 및/또는 이메일 문서(즉, 메시지)를 제작할 때 클라이언트 머 신에 의해 지원되는 그래픽 사용자 인터페이스를 사용하여 사용자에 의해 자동으로 작곡된 음악을 추가함으로써, 인터넷 상에서 지원되는 텍스트, SMS 및 이메일 서비스를 사용하여 모바일 및 데스크탑 클라이언 트 머신 등이 증강될 수 있도록, 인터넷 기반의 자동화된 음악 작곡 및 생성 플랫폼이 배치되며, 이에 따라, 이 와 같은 텍스트, SMS 및 이메일 메시지를 위한 작곡된 음악 조각을 생성하는 데 사용하기 위해 사용자가 그래픽 및/또는 언어 기반 감정 및 스타일 디스크립터를 쉽게 선택할 수 있다. 도 16a는 도 16에 도시된 시스템 네트워크에 배치된 모바일 클라이언트 머신(예컨대, 인터넷이 가능한 스마트 폰 또는 태블릿 컴퓨터)의 사시도이며, 클라이언트 머신은 터치 스크린 인터페이스, 메모리 아키텍처, 중앙처리 장치, 그래픽 프로세서, 인터페이스 회로, 다양한 통신 프로토콜을 지원하는 네트워크 어댑터, 및 현대 스마트 폰 장치(예컨대, 애플의 아이폰, 삼성의 안드로이드 갤럭시 등)에서 기대되는 기능을 지원하는 기타 기술을 가 진 모바일 컴퓨팅 머신으로서 실현되고, 텍스트 또는 SMS 메시지의 생성과, 메뉴 스크린으로부터 언어 및/또는 그래픽 아이콘 기반 감정 디스크립터 및 스타일 디스크립터를 선택하여 생성된 작곡 음악 조각의 생성 및 삽입 을 지원하는 가상 키보드를 사용자에게 제공하는 제1 예시적인 클라이언트 애플리케이션이 가동하고 있다. 도 16b는 도 16에 도시된 시스템 네트워크에 배치된 모바일 클라이언트 머신(예컨대, 인터넷이 가능한 스마트 폰 또는 태블릿 컴퓨터)의 사시도이며, 클라이언트 머신은 터치 스크린 인터페이스, 메모리 아키텍처, 중앙처리 장치, 그래픽 프로세서, 인터페이스 회로, 다양한 통신 프로토콜을 지원하는 네트워크 어댑터, 및 현대 스마트 폰 장치(예컨대, 애플의 아이폰, 삼성의 안드로이드 갤럭시 등)에서 기대되는 기능을 지원하는 기타 기술을 가 진 모바일 컴퓨팅 머신으로서 실현되고, 본 발명의 원리에 따라 메뉴 스크린으로부터 언어 및/또는 그래픽 아이 콘 기반 감정 디스크립터 및 스타일 타입 디스크립터를 선택하는 사용자에 의해 내부에 생성된 작곡 음악 조각의 생성 및 내장과 이메일 문서의 생성을 지원하는 가상 키보드를 사용자에게 제공하는 제2 예시적인 클라이언 트 애플리케이션이 가동하고 있다. 도 16c는 도 16에 도시된 시스템 네트워크에 배치된 모바일 클라이언트 머신(예컨대, 인터넷이 가능한 스마트 폰 또는 태블릿 컴퓨터)의 사시도이며, 클라이언트 머신은 터치 스크린 인터페이스, 메모리 아키텍처, 중앙처리 장치, 그래픽 프로세서, 인터페이스 회로, 다양한 통신 프로토콜을 지원하는 네트워크 어댑터, 및 현대 스마트 폰 장치(예컨대, 애플의 아이폰, 삼성의 안드로이드 갤럭시 등)에서 기대되는 기능을 지원하는 기타 기술을 가 진 모바일 컴퓨팅 머신으로서 실현되고, 마이크로소프트 워드, PDF 또는 이미지(예컨대, jpg 또는 tiff) 문서의 생성과, 메뉴 스크린으로부터 언어 및/또는 그래픽 아이콘 기반 감정 디스크립터 및 스타일 디스크립터를 선택 하여 생성된 작곡 음악 조각의 생성 및 삽입을 지원하는 가상 키보드를 사용자에게 제공하는 제2 예시적인 클라 이언트 애플리케이션이 가동하고 있다. 도 16d는 도 16에 도시된 시스템 네트워크에 배치된 모바일 클라이언트 머신(예컨대, 인터넷이 가능한 스마트 폰 또는 태블릿 컴퓨터)의 사시도이며, 클라이언트 머신은 터치 스크린 인터페이스, 메모리 아키텍처, 중앙처리 장치, 그래픽 프로세서, 인터페이스 회로, 다양한 통신 프로토콜을 지원하는 네트워크 어댑터, 및 현대 스마트 폰 장치(예컨대, 애플의 아이폰, 삼성의 안드로이드 갤럭시 등)에서 기대되는 기능을 지원하는 기타 기술을 가 진 모바일 컴퓨팅 머신으로서 실현되고, 웹 기반(즉, html) 문서의 생성과, 메뉴 스크린으로부터 언어 및/또는 그래픽 아이콘 기반 감정 디스크립터 및 스타일 디스크립터를 선택하여 생성된 작곡 음악 조각의 생성 및 삽입 을 지원하는 가상 키보드를 사용자에게 제공하는 제2 예시적인 클라이언트 애플리케이션이 가동하고 있음으로써, 음악 조각이 내장된 URL 상에서 동작하는 통상의 웹 브라우저를 사용하여 원격 클라이언트에게 전 달되어 경험될 수 있고, 이로부터 내장된 음악 조각은 웹, 애플리케이션 및 데이터베이스 서버를 통해 서비스된 다. 도 17은 시스템 버스 아키텍처와 집적된 시스템 버스 아키텍처 주위의 멀티 코어 CPU, 멀티 코어 GPU, 프로그램 메모리(RAM), 비디오 메모리(VRAM), 하드 드라이브(SATA 드라이브), LCD/터치 스크린 디스플레이 패널, 마이크 스피커, 키보드, WIFI/블루투스 네트워크 어댑터, 및 3G/LTE/GSM 네트워크 어댑터를 포함한 서브 시스템 모듈을 포함하는 도 16a, 도 16b, 도 16c 및 도 16d에 도시된 시스템에 배치된 각 클라이언트 머신의 시스템 아키텍처 의 개략도이다. 도 18은 작곡된 음악을 텍스트, SMS, 이메일 문서/메시지에 추가하기 위해 언어 및/또는 그래픽 아이콘 기반 음 악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성의 사용을 지원하는 본 발명의 인터넷 기반 음악 작 곡 및 생성 시스템의 상위 시스템 아키텍처를 도시한 개략도이며, 언어 기반 또는 아이콘 기반 음악적 경험 디 스크립터가 시스템 사용자 인터페이스를 통해 입력으로서 제공되고, 본 발명의 자동화된 음악 작곡 및 생성 엔 진에 의해 사용되어 최종 마무리 및 전송 전에 시스템 사용자 인터페이스를 통해 시스템 사용자에 의한 미리보 기를 위해 생성되는 음악적으로 스코어링된 텍스트 문서 또는 메시지를 생성한다. 도 19는 음악적으로 스코어링된 텍스트, SMS, 이메일, PDF, 워드 및/또는 html 문서를 생성하기 위해 언어 및/ 또는 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성의 사용을 지원하는 도 16 내지 도 18에 나타낸 웹 기반 시스템을 사용한 본 발명의 자동화된 음악 작곡 및 생성 프로세스를 실행하는 데 포함되는 주요 단계를 도시한 흐름도이며, (i) 프로세스의 제1단계에서, 시스템 사용자는 본 발명의 자동화 된 음악 작곡 및 생성 시스템에 액세스한 다음, 본 발명의 자동화된 음악 작곡 및 생성 시스템에 의해 생성된 음악으로 스코어링될(예컨대, 증강될) 텍스트, SMS 또는 이메일 메시지 또는 워드, PDF 또는 HTML 문서를 선택 하고, (ii) 그 다음, 시스템 사용자는 언어 기반 및/또는 아이콘 기반 음악적 경험 디스크립터를 시스템의 자동 화된 음악 작곡 및 생성 엔진에 제공하며, (iii) 시스템 사용자는 자동화된 음악 작곡 및 생성 시스템을 기동하 여 선택된 메시지 또는 문서에 스코어링되어 있는 입력된 음악적 디스크립터에 기초한 음악을 작곡 및 생성하며, (iv) 시스템 사용자는 메시지 또는 문서에 대해 제작된 작곡 및 생성된 음악을 수용하거나, 음악을 거부하고, 다른 음악적 경험 디스크립터의 제공 및 갱신된 음악적 경험 디스크립터 입력에 기초한 음악의 재작 곡에 대한 요청을 포함한 피드백을 시스템에 제공하며, (v) 시스템은 수용한 작곡된 음악을 메시지 또는 문서와 조합하여, 분배 및 표시하기 위한 새로운 파일을 제작한다. 도 20은 본 발명의 자동화된 음악 작곡 및 생성 엔진의 변형된 버전을 채택한 AI 기반 자율 음악 작곡 및 작곡 연주 시스템 주변의 실제 또는 합성 음악 악기를 갖춘 인간 음악가 밴드의 개략도이며, AI 기반 시스템은 그 주 변 악기 및 음악가로부터 음악 신호를 수신하여 이들 악기를 버퍼링 및 분석하고, 이에 응답하여, 음악가 밴드 에 의해 연주되고 있는 음악을 증강하게 될 음악을 실시간으로 작곡 및 생성할 수 있거나, 인간 음악가에 의한후속 재생, 검토 및 심의를 위해 기록되는 음악을 녹음, 분석 및 작곡할 수 있다. 도 21은 자율 음악 분석, 작곡 및 연주 악기 시스템을 도시한 개략도이며, LCD 터치 타입 디스플레이 스크린, 내장형 스테레오 마이크 세트, 시스템 환경 내의 음악 악기 세트로부터 생성되는 오디오 신호를 수신하기 위한 오디오 신호 입력 커넥터 세트, 시스템 환경 내의 악기 세트로부터 MIDI 입력 신호를 수신하기 위한 MIDI 신호 입력 커넥터 세트, 오디오 출력 신호를 오디오 신호 전치 증폭기 및/또는 증폭기로 전달하기 위한 오디오 출력 신호 커넥터, WIFI 및 BT 네트워크 어댑터 및 관련 신호 안테나 구조, 및 사용자 작동 모드를 위한 기능 버튼 세트를 포함한 콤팩트하고 견고한 휴대용 하우징을 가진 자율적 음악 분석, 작곡 및 연주 악기 시스템의 개략도 이며, 사용자 작동 모드는 (i) 악기 시스템이 음악 세션 중에 그 (로컬 또는 원격) 음악 환경으로부터 수신하여 분석한 음악 정보 스트림에 응답하여 음악적으로 자율적으로 선도하는 선도(LEAD) 모드, (ii) 악기 시스템이 음 악 세션 중에 그 (로컬 또는 원격) 음악 환경 내의 음악 악기로부터 수신하여 분석한 음악에 응답하여 음악적으 로 자율적으로 추종하는 추종(FOLLOW) 모드, (iii) 시스템이 음악 세션 중에 그 (로컬 또는 원격) 환경 내의 음 악 악기로부터 수신하여 분석한 음악에 기초하여 음악을 자동으로 작곡하는 작곡(COMPOSE) 모드, 및 (iv) 시스 템이 음악 세션 중에 그 환경으로부터 수신하여 분석한 음악 정보에 응답하여 자동으로 작곡된 음악을 실시간으 로 자율적으로 연주하는 연주(PERFORM) 모드를 포함한다. 도 22는 도 21에 나타낸 자율 음악 분석, 작곡 및 연주 악기 시스템의 상위 시스템 아키텍처를 도시한 개략도이 며, 시스템 환경 내의 음악 악기 세트로부터 생성된 MIDI 입력 신호뿐만 아니라 오디오 신호가 악기 시스템에 의해 수신되고, 이 신호들이 피치 이벤트 및 멜로디 구조의 발생에 대하여 시간 및/또는 주파수 도메인에서 실 시간으로 분석됨으로써, 시스템은 본 발명의 자동화된 음악 작곡 및 생성 엔진을 사용하여 자동화된 음악 작곡"}
{"patent_id": "10-2018-7011569", "section": "도면", "subsection": "도면설명", "item": 2, "content": "및 생성의 생성에 사용하기 위해 이 정보로부터 음악적 경험 디스크립터를 자동으로 요약할 수 있다. 도 23은 시스템 버스 아키텍처와 집적된 시스템 버스 아키텍처 주위의 멀티 코어 CPU, 멀티 코어 GPU, 프로그램 메모리(DRAM), 비디오 메모리(VRAM), 하드 드라이브(SATA 드라이브), LCD/터치 스크린 디스플레이 패널, 스테레 오 마이크, 오디오 스피커, 키보드, WIFI/블루투스 네트워크 어댑터, 및 3G/LTE/GSM 네트워크 어댑터를 포함한 서브 시스템 모듈의 구성을 포함하는 도 20 및 도 21에 도시된 악기 시스템의 시스템 아키텍처의 개략도이다. 도 24는 도 20 내지 도 23에 나타낸 시스템을 사용한 본 발명의 자동화된 음악 작곡 및 생성 프로세스를 실행하 는 데 포함되는 주요 단계를 도시한 흐름도이며, (i) 프로세스의 제1단계에서, 시스템 사용자는 본 발명의 자동 화된 음악 작곡 및 생성 악기 시스템에 대해 LEAD 또는 FOLLOW 작동 모드 중 하나를 선택하고, (ii) 그 다음, 세션에 앞서, 시스템은 음악 세션 중의 창조적 환경에서 음악가 그룹에 의해 연주되는 음악 악기 그룹과 인터페 이스되며, (iii) 세션 중에, 시스템은 세션 중에 악기 그룹으로부터 생성된 오디오 및/또는 MIDI 데이터 신호를"}
{"patent_id": "10-2018-7011569", "section": "도면", "subsection": "도면설명", "item": 3, "content": "수신하고, 이 신호들을 피치 데이터 및 멜로디 구조에 대하여 분석하며, (iv) 세션 중에, 시스템은 요약된 피치 및 멜로디 데이터로부터 음악적 디스크립터를 자동으로 생성하고, 음악적 경험 디스크립터를 사용하여 실시간 단위로 세션을 위한 음악을 작곡하며, (v) PERFORM 모드가 선택된 경우, 시스템은 작곡된 음악을 생성하고, COMPOSE 모드가 선택된 경우, 세션 중에 작곡된 음악이 음악가 그룹에 의한 후속 액세스 및 검토를 위해 저장된 다. 도 25a는 도시된 바와 같이 구성된 사용자 GUI 기반 입력 서브 시스템, 일반 리듬 서브 시스템, 일반 리듬 생성 서브 시스템, 멜로디 리듬 생성 서브 시스템, 멜로디 피치 생성 서브 시스템, 오케스트레이션 서브 시스템, 컨 트롤러 코드 제작 서브 시스템, 디지털 조각 제작 서브 시스템, 및 피드백 및 학습 서브 시스템을 포함한 시스 템 아키텍처를 포함하는 본 발명의 다양한 실시형태에 채택된 본 발명의 자동화된 음악 작곡 및 생성 엔진의 상 위 시스템도이다. 도 25b는 2개의 매우 높은 수준의 \"음악적 랜드스케이프\" 카테고리, 즉, (i) 일반 피치 생성 서브 시스템(A2), 멜로디 피치 생성 서브 시스템(A4), 오케스트레이션 서브 시스템(A5) 및 컨트롤러 코드 제작 서브 시스템(A6)을 포함한 피치 랜드스케이프 서브 시스템(C0), 및 (ii) 일반 리듬 생성 서브 시스템(A1), 멜로디 리듬 생성 서브 시스템(A3), 오케스트레이션 서브 시스템(A5) 및 컨트롤러 코드 제작 서브 시스템(A6)을 포함한 리듬 랜드스케 이프 서브 시스템(C1)을 포함하는 본 발명의 시스템을 도시한 상위 시스템도이다. 도 26a, 도 26b, 도 26c, 도 26d, 도 26e, 도 26f, 도 26g, 도 26h, 도 26i, 도 26j, 도 26k, 도 26l, 도 26m, 도 26n, 도 26o 및 도 26p는 함께 취합되어, 본 발명의 자동화된 음악 작곡 및 생성 프로세스에서 사용하기 위 해 사용자 GUI 기반 입출력 시스템(B0)에 제공된 음악적 디스크립터가 자신의 적절한 서브 시스템으로 분배되도 록, 본 발명의 원리에 따라 기타 서브 시스템과 함께 구성된 도 25a 및 도 25b의 각 서브 시스템을 나타낸 상세 한 시스템도를 제공한다.도 27는 본 발명의 자동화된 음악 작곡 및 생성 엔진(E1)에서 사용되는 사용자 GUI 기반 입출력 서브 시스템 (B0)의 개략도를 나타내며, 시스템 사용자는 디스크립터 파라미터 포착 서브 시스템(B1)으로의 분배를 위해 입 출력 시스템(B0)에 음악적 경험 디스크립터-예컨대, 행복-를 제공하고, 확률 기반 테이블은 후속 서브 시스템 설치 및 자동화된 음악 작곡 및 생성에서 사용하기 위해 그 내부의 다양한 서브 시스템에서의 분배 및 로드를 위하여 도 28d에 나타낸 파라미터 변환 엔진 서브 시스템(B51)에 의해 생성되어 유지된다. 도 28a 및 도 28b는 함께 취합되어 본 발명의 자동화된 음악 작곡 및 생성 엔진에서 사용되는 디스크립터 파라 미터 포착 서브 시스템(B1)의 개략도를 나타내며, 시스템 사용자는 그 내부의 다양한 서브 시스템에 채택되는 확률 기반 파라미터 테이블로의 분배와 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 후속 서브 시스템 의 설립 및 사용을 위하여 디스크립터 파라미터 포착 서브 시스템에 예시적인 \"감정 타입\" 음악적 경험 디스크 립터-행복-를 제공한다. 도 28c, 도 28d 및 도 28e는 함께 취합되어, 예시적 실시형태의 시스템 내의 다양한 서브 시스템에 테이블 타입 데이터 구조로 분배하기 위하여 음악 이론 시스템 작동 파라미터로의 프로세싱 및 변환을 위해 감정 타입 및 스 타일 타입 음악적 경험 디스크립터와 타이밍/공간 파라미터를 수신하는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 파라미터 포착 서브 시스템(B1), 스타일 파라미터 포착 서브 시스템(B37) 및 타이밍 파라미터 포착 서브 시스템(B40)으로 구성된 파라미터 변환 엔진 서브 시스템(B51)의 개략도를 제공한다. 도 28f, 도 28g, 도 28h, 도 28i 및 도 28j는 함께 취합되어, 본 발명의 자동화된 음악 작곡 및 생성 시스템의 서브 시스템 내에 채택된 특정 음악 이론 시스템 작동 파라미터(SOP) 테이블의 위치를 특정한 개략적인 맵을 제 공한다. 도 28k는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 파라미터 테이블 취급 및 프로세싱 서브 시스 템(B70)의 개략도이며, 다수의 감정/스타일 특정 음악 이론 시스템 작동 파라미터(SOP) 테이블이 파라미터 변환 엔진 서브 시스템(B51)으로부터 수신되어, 하나 이상의 파라미터 테이블 프로세싱 방법(M1, M2, 또는 M3)을 이 용하여 취급 및 프로세싱됨으로써, 본 발명의 시스템의 서브 시스템 내에서 프로세싱 및 사용이 보다 편리하고 간단한 형태로 시스템 작동 파라미터 테이블을 생성한다. 도 28l은 시스템 상에서 시스템 사용자 음악 작곡 요청에 대해 생성되는 모든 감정/스타일 인덱스 시스템 작동 파라미터(SOP)뿐만 아니라 시스템 사용자 계정 프로파일, 취향 및 선호도를 저장 및 보존하기 위한, 본 발명의 자동화된 음악 작곡 및 생성 시스템에 사용되는 파라미터 테이블 아카이브 데이터베이스 서브 시스템(B80)의 개 략도이다. 도 29a 및 도 29b는 함께 취합되어 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 스타일 파라미터 포 착 서브 시스템(B37)의 개략도를 나타내며, 서브 시스템에 채택된 확률 기반 파라미터 테이블이 예시적인 \"스타 일 타입\" 음악적 경험 디스크립터-팝에 대해 설정되어, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 30는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 타이밍 파라미터 포착 서브 시스템(B40)의 개 략도를 나타내며, 타이밍 파라미터 포착 서브 시스템(B40)은 시스템 내의 다양한 서브 시스템으로의 분배와 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 후속 서브 시스템의 구성 및 사용을 위하여 타이밍 생성 서 브 시스템(B41)에 타이밍 파라미터를 제공한다. 도 31a 및 도 31b는 함께 취합되어 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 타이밍 생성 서브 시스템(B41)의 개략도를 나타내며, 타이밍 파라미터 포착 서브 시스템(B40)은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 생성될 (i) 작곡될 조각의 길이, (ii) 음악 조각의 시작, (iii) 음악 조각의 정지, (iv) 음 악 조각의 볼륨 증가 및 (v) 음악 조각에서의 악센트와 관련한 타이밍 정보를 생성하기 위해 타이밍 생성 서브 시스템(B41)에 타이밍 파라미터(예컨대, 조각의 길이)를 제공한다. 도 32는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 길이 생성 서브 시스템(B2)의 개략도를 나타내 며, 시스템 사용자에 의해 특정된 조각의 시간 길이가 길이 생성 서브 시스템(B2)에 제공되며, 이 서브 시스템 은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 작곡될 음악 조각의 시작 및 정지 위치를 생성한다. 도 33는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 템포 생성 서브 시스템(B3)의 개략도를 나타내 며, 조각의 템포(즉, BPM)는 이 서브 시스템에 제공된 조각 시간 길이 및 음악적 경험 파라미터에 기초하여 연 산되며, 도출된 템포는 분당 비트(BPM) 단위로 측정되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에사용된다. 도 34는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 박자 생성 서브 시스템(B4)의 개략도를 나타내 며, 조각의 박자는 이 서브 시스템에 제공된 조각 시간 길이 및 음악적 경험 파라미터에 기초하여 연산되며, 도 출된 템포는 분당 비트(BPM) 단위로 측정되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 35는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 키 생성 서브 시스템(B5)의 개략도를 나타내며, 조각의 키는 시스템에 제공된 음악적 경험 파라미터에 기초하여 연산되며, 도출된 키는 본 발명의 자 동화된 음악 작곡 및 생성 프로세스 중에 선택되어 사용된다. 도 36는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 비트 계산기 서브 시스템(B6)의 개략도를 나타 내며, 조각의 비트 수는 시스템에 제공된 조각 길이와 시스템에 의해 연산된 템포에 기초하여 연산되며, 도출된 비트 수는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 37는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 마디 계산기 서브 시스템(B8)의 개략도를 나타 내며, 조각의 마디 수는 조각의 비트 수와 조각의 연산된 박자에 기초하여 연산되며, 조각의 박자는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 38은 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 조성 생성 서브 시스템(B7)의 개략도를 나타내 며, 조각의 조성 수는 시스템 사용자에 의해 시스템에 제공된 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행 복에 대해 서브 시스템 내에 채택된 확률 기반 조성 파라미터 테이블을 이용하여 선택되며, 선택된 조성은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 39a 및 도 39b는 함께 취합되어 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 노래 형태 생성 서 브 시스템(B9)의 개략도를 나타내며, 노래 형태는 시스템 사용자에 의해 시스템에 제공된 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복에 대해 서브 시스템 내에 채택된 확률 기반 노래 형태 하위 악절 파라미터 테이블 을 이용하여 선택되며, 선택된 노래 형태는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 40은 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 하위 악절 길이 생성 서브 시스템(B15)의 개략 도를 나타내며, 하위 악절 길이는 시스템 사용자에 의해 시스템에 제공된 예시적인 \"감정 타입\" 음악적 경험 디 스크립터-행복에 대해 서브 시스템 내에 채택된 확률 기반 하위 악절 길이 파라미터 테이블을 이용하여 선택되 며, 선택된 하위 악절 길이는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 41a, 도 41b, 도 41c 및 도 41d는 함께 취합되어 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 화 음 길이 생성 서브 시스템(B11)의 개략도를 나타내며, 화음 길이는 시스템 사용자에 의해 시스템에 제공된 예시 적인 \"감정 타입\" 음악적 경험 디스크립터에 대해 서브 시스템 내에 채택된 확률 기반 화음 길이 파라미터 테이 블을 이용하여 선택되며, 선택된 화음 길이는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 42는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 특이 하위 악절 생성 서브 시스템(B14)의 개략 도를 나타내며, 특이 하위 악절은 시스템 사용자에 의해 시스템에 제공된 \"감정 타입\" 음악적 경험 디스크립터- 행복에 대해 서브 시스템 내의 확률 기반 특이 하위 악절 파라미터 테이블을 이용하여 선택되며, 선택된 특이 하위 악절은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 43는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 하위 악절 내 화음 수 계산 서브 시스템(B16) 의 개략도를 나타내며, 하위 악절 내 화음 수는 연산된 특이 하위 악절을 사용하여 계산되며, 하위 악절 내 화 음 수는 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 44은 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 악절 길이 생성 서브 시스템(B12)의 개략도를 나타내며, 악절 길이는 악절 길이 분석기를 이용하여 측정되며, 악절 길이(마디의 수)는 본 발명의 자동화된 음 악 작곡 및 생성 프로세스 중에 사용된다. 도 45는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 특이 악절 생성 서브 시스템(B10)의 개략도를 나타내며, 특이 악절의 수는 악절 분석기를 이용하여 결정되며, 특이 악절의 수는 본 발명의 자동화된 음악 작 곡 및 생성 프로세스 중에 사용된다. 도 46는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 악절 내 화음 수 계산 서브 시스템(B13)의 개 략도를 나타내며, 악절 내 화음 수가 결정되며, 악절 내 화음 수는 본 발명의 자동화된 음악 작곡 및 생성 프로 세스 중에 사용된다.도 47는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 제1 일반 리듬 생성 서브 시스템(B17)의 개략 도를 나타내며, 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복에 대해 서브 시스템 내에 채택된 확률 기반 파라미터 테이블(즉, 확률 기반 제1 화음 밑음 테이블 및 확률 기반 화음 기능 테이블)은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 48a, 도 48b 및 도 48c은 함께 취합되어 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 하위 악절 화음 진행 생성 서브 시스템(B19)의 개략도를 나타내며, 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복에 대해 서브 시스템 내에 채택된 확률 기반 파라미터 테이블(즉, 화음 밑음 테이블, 화음 기능 밑음 변조기, 및 비트 밑음 변조기 테이블)은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 49는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 악절 화음 진행 생성 서브 시스템(B18)의 개략 도를 나타내며, 악절 화음 진행은 하위 악절 분석기를 이용하여 결정되며, 개선된 악절은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 50a, 도 50b 및 도 50c는 함께 취합되어 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 화음 자리 바꿈 생성 서브 시스템(B20)의 개략도를 나타내며, 화음 자리바꿈은 예시적인 \"감정 타입\" 음악적 경험 디스크 립터-행복에 대한 확률 기반 파라미터 테이블(즉, 제1 화음 자리바꿈 테이블 및 화음 자리바꿈 테이블)을 이용 하여 결정되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 51는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 멜로디 하위 악절 길이 생성 서브 시스템(B2 5)의 개략도를 나타내며, 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복에 대해 서브 시스템 내에 채택된 확률 기반 파라미터 테이블(즉, 멜로디 길이 테이블)은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 52a 및 도 52b는 함께 취합되어 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 멜로디 하위 악절 생성 서브 시스템(B24)의 개략도를 나타내며, 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복에 대해 서브 시스템 내에 채택된 확률 기반 파라미터 테이블(즉, 하위 악절 멜로디 배치 테이블)은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 53는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 멜로디 악절 길이 생성 서브 시스템(B23)의 개 략도를 나타내며, 멜로디 악절 길이는 하위 악절 멜로디 분석기를 이용하여 결정되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 54는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 멜로디 특이 악절 생성 서브 시스템(B22)의 개 략도를 나타내며, 특이 멜로디 악절은 특이 멜로디 악절 분석기를 이용하여 결정되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 55는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 멜로디 길이 생성 서브 시스템(B21)의 개략도 를 나타내며, 멜로디 길이는 악절 멜로디 분석기를 이용하여 결정되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 56a, 도 56b 및 도 56c은 함께 취합되어 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 멜로디 음 표 리듬 생성 서브 시스템(B26)의 개략도를 나타내며, 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복에 대 해 서브 시스템 내에 채택된 확률 기반 파라미터 테이블(즉, 제1 음표 길이 테이블과, 제1 및 제2 화음 길이 테 이블)은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 57는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 제1 피치 생성 서브 시스템(B27)의 개략도를 나타내며, 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복에 대해 서브 시스템 내에 채택된 확률 기반 파라 미터 테이블(즉, 제1 멜로디 테이블)은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 58a, 도 58b 및 도 58c은 함께 취합되어 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 하위 악절 피치 생성 서브 시스템(B29)의 개략도를 나타내며, 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복에 대해 서브 시스템 내에 채택된 확률 기반 파라미터 테이블(즉, 멜로디 음표 테이블과 화음 변조기 테이블, 도약 자리 바꿈 변조기 테이블, 및 도약 유발 변조기 테이블)은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사 용된다. 도 59는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 악절 피치 생성 서브 시스템(B28)의 개략도를 나타내며, 악절 피치는 하위 악절 멜로디 분석기를 이용하여 결정되며 본 발명의 자동화된 음악 작곡 및 생성프로세스 중에 사용된다. 도 60a 및 도 60b는 함께 취합되어 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 피치 옥타브 생성 서브 시스템(B30)의 개략도를 나타내며, 확률 기반 파라미터 테이블(즉, 멜로디 음표 옥타브 테이블)이 예시적 인 \"감정 타입\" 음악적 경험 디스크립터-행복에 대해 설정되어 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 61a 및 도 61b는 함께 취합되어 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 악기 편성 서브 시 스템(B38)의 개략도를 나타내며, 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복에 대해 서브 시스템 내에 채택된 확률 기반 파라미터 테이블(즉, 악기 테이블)은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 62a 및 도 62b는 함께 취합되어 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 악기 선택기 서브 시스템(B39)의 개략도를 나타내며, 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복에 대해 서브 시스템 내 에 채택된 확률 기반 파라미터 테이블(즉, 악기 선택 테이블)은 본 발명의 자동화된 음악 작곡 및 생성 프로세 스 중에 사용된다. 도 63a, 도 63b, 도 63c, 도 63d, 도 63e, 도 63f, 도 63g, 도 63h 및 도 63i는 함께 취합되어 본 발명의 자동 화된 음악 작곡 및 생성 엔진에 사용되는 오케스트레이션 생성 서브 시스템(B31)의 개략도를 나타내며, 예시적 인 \"감정 타입\" 음악적 경험 디스크립터-행복에 대해 서브 시스템 내에 채택된 확률 기반 파라미터 테이블(즉, 악기 오케스트레이션 우선 순위 결정 테이블, 악기 에너지 테이블, 피아노 에너지 테이블, 악기 기능 테이블, 피아노 손 기능 테이블, 피아노 보이싱 테이블, 피아노 리듬 테이블, 제2 음표 오른손 테이블, 제2 음표 왼손 테이블, 피아노 강약 테이블 등)은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 64은 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 컨트롤러 코드 생성 서브 시스템(B32)의 개략 도를 나타내며, 예시적인 \"감정 타입\" 음악적 경험 디스크립터-행복에 대해 서브 시스템 내에 채택된 확률 기반 파라미터 테이블(즉, 악기, 악기 그룹 및 조각 너비 컨트롤러 코드 테이블)은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 65은 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 디지털 오디오 검색기 서브 시스템(B33)의 개 략도를 나타내며, 디지털 오디오(악기 음표) 파일이 검색되어, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 66은 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 디지털 오디오 샘플 조직기 서브 시스템(B34) 의 개략도를 나타내며, 검색된 디지털 오디오(악기 음표) 파일은 본 발명의 자동화된 음악 작곡 및 생성 프로세 스 중에 음악 조각에 따라 정확한 시간 및 공간에 조직된다. 도 67a는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 조각 통합기 서브 시스템(B35)의 개략도를 나 타내며, 하위 악절 피치는 확률 기반 멜로디 음표 테이블, 확률 기반 화음 변조기 테이블 및 확률 기반 도약 자 리바꿈 변조기 테이블을 이용하여 결정되어, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용된다. 도 67b은 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 조각 포맷 번역기 서브 시스템(B50)의 개략도 를 나타내며, 완성된 음악 조각은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 요청된 원하는 대안적 인 포맷으로 번역된다. 도 68는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 조각 전달기 서브 시스템(B36)의 개략도를 나 타내며, 디지털 오디오 파일은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 시스템 사용자에게 전달될 디지털 오디오 파일로 조합된다. 도 69a, 도 69b 및 도 69c는 함께 취합되어 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 피드백 서 브 시스템(B42)의 개략도를 나타내며, (i) 디지털 오디오 파일과 추가적인 조각 포맷은 요청된 조각의 모든 속 성이 정확하게 전달되는지를 결정 및 확인하기 위해 분석되며, (ii) 디지털 오디오 파일과 추가적인 조각 포맷 은 음악 조각의 특이성을 결정 및 확인하기 위해 분석되고, (iii) 시스템 사용자는 본 발명의 자동화된 음악 작 곡 및 생성 프로세스 중에 오디오 파일 및/또는 추가적인 조각 포맷을 분석한다. 도 70은 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 음악 편집성 서브 시스템(B43)의 개략도를 나 타내며, 시스템을 다시 시작, 재실행, 변경 및/또는 재생하고자 하는 요청이 본 발명의 자동화된 음악 작곡 및생성 프로세스 중에 실행된다. 도 71는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 선호도 저장기 서브 시스템(B44)의 개략도를 나타내며, 음악적 경험 디스크립터 및 파라미터 테이블은 본 발명의 미래의 자동화된 음악 작곡 및 생성 프로세 스 중에 조각이 더 분명히 수신되도록 하기 위해 사용자 및 자율적인 피드백을 반영하도록 변조된다. 도 72는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 음악적 커널(즉, DNA) 생성 서브 시스템(B45) 의 개략도를 나타내며, 음악 조각의 음악적 \"커널\"(즉, DNA)은 (i) 멜로디(하위 악절 멜로디 음표 선택 순서), (ii) 하모니(즉, 악절 화음 진행), (iii) 템포, (iv) 볼륨, 및 (v) 오케스트레이션 측면에서 결정됨으로써, 이 음악 커널은 본 발명의 미래의 자동화된 음악 작곡 및 생성 프로세스 중에 사용될 수 있다. 도 73는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 사용자 취향 생성 서브 시스템(B46)의 개략도 를 나타내며, 시스템 사용자의 음학적 취향은 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 음악 작곡 을 위한 음악적 경험 디스크립터, 파라미터 및 테이블 값을 변경 또는 변환하는 데 사용하기 위해 시스템 사용 자 피드백 및 자율적 조각 분석에 기초하여 결정된다. 도 74는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 모집단 취향 집계기 서브 시스템(B47)의 개략 도를 나타내며, 모집단의 음학 취향은 집계되어 음악적 경험 디스크립터로 변하며, 이에 응답하여 본 발명의 자 동화된 음악 작곡 및 생성 프로세스 중에 테이블 확률이 변경될 수 있다. 도 75는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 사용자 선호도 서브 시스템(B48)의 개략도를 나타내며, 시스템 사용자 선호도(예컨대, 음악적 경험 디스크립터, 테이블 파라미터)는 본 발명의 자동화된 음 악 작곡 및 생성 프로세스 중에 결정되어 사용된다. 도 76는 본 발명의 자동화된 음악 작곡 및 생성 엔진에 사용되는 모집단 선호도 서브 시스템(B49)의 개략도를 나타내며, 사용자 모집단 선호도(예컨대, 음악적 경험 디스크립터, 테이블 파라미터)는 본 발명의 자동화된 음 악 작곡 및 생성 프로세스 중에 결정되어 사용된다. 도 77a는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 템포 생성 서브 시스템(B3)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복, 슬픔, 분노, 무 서움, 사랑에 대해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라 미터 테이블의 개략도를 나타낸다. 도 77b는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 길이 생성 서브 시스템(B2)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복, 슬픔, 분노, 무 서움, 사랑에 대해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라 미터 테이블의 개략도를 나타낸다. 도 77c는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 박자 생성 서브 시스템(B4)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복, 슬픔, 분노, 무 서움, 사랑에 대해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라 미터 테이블의 개략도를 나타낸다. 도 77d는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 키 생성 서브 시스템(B5)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복에 대해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블의 개략도를 나타낸다. 도 77e는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 조성 생성 서브 시스템(B7)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복에 대해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블의 개략도를 나타낸 다. 도 77f는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 노래 형태 생성 서브 시스템(B9)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복에 대해 구성 되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블의 개략도를 나타낸다. 도 77g는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 하위 악절 길이 생성 서브 시스템(B15)에 유지되고, 도83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복에 대해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블의 개략 도를 나타낸다. 도 77h는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 화음 길이 생성 서브 시스템(B11)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복에 대해 구성 되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블의 개략도를 나타낸다. 도 77i는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 제1 일반 리듬 생성 서브 시스템(B17)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복에 대해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블의 개략 도를 나타낸다. 도 77j 및 도 77k는 함께 취합되어, 본 발명의 자동화된 음악 작곡 및 생성 엔진의 하위 악절 화음 진행 생성 서브 시스템(B19)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음 악적 경험 디스크립터-행복에 대해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블의 개략도를 나타낸다. 도 77l은 본 발명의 자동화된 음악 작곡 및 생성 엔진의 화음 자리바꿈 생성 서브 시스템(B20)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복에 대해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블의 개략 도를 나타낸다. 도 77m은 본 발명의 자동화된 음악 작곡 및 생성 엔진의 멜로디 하위 악절 길이 진행 생성 서브 시스템(B25)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터 -행복에 대해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블의 개략도를 나타낸다. 도 77n는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 멜로디 하위 악절 생성 서브 시스템(B24)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복에 대 해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블의 개 략도를 나타낸다. 도 77o은 본 발명의 자동화된 음악 작곡 및 생성 엔진의 멜로디 음표 리듬 생성 서브 시스템(B26)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복에 대 해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블의 개 략도를 나타낸다. 도 77p은 본 발명의 자동화된 음악 작곡 및 생성 엔진의 제1 피치 생성 서브 시스템(B27)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복에 대해 구성 되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블의 개략도를 나타낸다. 도 77q, 도 77r 및 도 77s은 함께 취합되어, 본 발명의 자동화된 음악 작곡 및 생성 엔진의 하위 악절 피치 생 성 서브 시스템(B29)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복에 대해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블의 개략도를 나타낸다. 도 77t는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 피치 옥타브 생성 서브 시스템(B30)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복에 대해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블의 개략 도를 나타낸다. 도 77u 및 도 77v는 함께 취합되어, 본 발명의 자동화된 음악 작곡 및 생성 엔진의 악기 서브 시스템(B38)에 유 지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터- 행복에 대해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 악기 테이블의 개략도를 나타낸다. 도 77w 및 도 77x는 함께 취합되어, 본 발명의 자동화된 음악 작곡 및 생성 엔진의 악기 선택기 서브 시스템 (B39)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디 스크립터-행복에 대해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 악 기 선택기 테이블의 개략도를 나타낸다. 도 78a, 도 78b 및 도 78c은 함께 취합되어, 본 발명의 자동화된 음악 작곡 및 생성 엔진의 오케스트레이션 생 성 서브 시스템(B31)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복에 대해 구성되며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블 및 에너지 기반 파라미터 테이블의 개략도를 나타낸다. 도 79는 본 발명의 자동화된 음악 작곡 및 생성 엔진의 컨트롤러 코드 생성 서브 시스템(B32)에 유지되고, 도 83a 내지 도 83f의 감정 디스크립터 테이블에 특정된 예시적인 감정 타입 음악적 경험 디스크립터-행복 및 도 84a 내지 도 83f의 스타일 디스크립터 테이블에 특정된 스타일 타입 음악적 경험 디스크립터-팝에 대해 구성되 며, 본 발명의 자동화된 음악 작곡 및 생성 프로세스 중에 사용되는, 확률 기반 파라미터 테이블의 개략도를 나 타낸다. 도 80a 및 도 80b는 함께 취합되어, 시스템이 시스템 사용자로부터 그 음악적 경험 디스크립터 입력을 수신하고, 시스템이 자동으로 배치되어 본 발명의 원리에 따라 음악이 자동으로 작곡 및 생성되는 그 작동 모드 로 구성된 후에, 특정 타이밍 제어 펄스 신호가 도 26a 내지 도 26p에 나타낸 시스템도의 각 서브 시스템 블록 도로 전송되는 시간 순서를 도시한 타이밍 제어도의 개략도를 나타낸다. 도 81a, 도 81b, 도 81c, 도 81d, 도 81e, 도 81f, 도 81g, 도 81h, 도 81i 및 도 81j는 함께 취합되어, 본원 에 기술된 본 발명의 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스템 내의 각 서브 시스템에 의해 제공 되는 입출력 데이터 신호의 종류와 다양한 가능한 포맷을 설명한 테이블의 개략도를 나타내며, 각 서브 시스템 은 그 블록명 또는 식별자(예컨대, B1)로 테이블 내에서 식별된다. 도 82은 본 발명의 자동화된 음악 작곡 및 생성 시스템에 채택된 다양한 특수하게 구성된 정보 프로세싱 서브 시스템을 통과하는 다양한 데이터 입출력 신호(예컨대, 텍스트, 화음, 오디오 파일, 바이너리, 명령, 박자, 이 미지, 시간, 피치, 숫자, 조성, 템포, 문자, 언어, 음성, MIDI 등)에 의해 제공되는 예시적인 데이터 포맷을 설 명한 테이블의 개략도이다. 도 83a, 도 83b, 도 83c, 도 83d, 도 83e 및 도 83f는 함께 취합되어, 본 발명의 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스템에 입력으로서 제공하기 위해 시스템 사용자에 대해 \"음악적 경험 디스크립터\"로서 제 공되는 1차, 2차 및 3차 감정에 따라 배열된 예시적인 계층적 \"감정\" 디스크립터 세트를 설명한 테이블의 개략 도를 제공한다. 도 84a, 도 84b, 도 84c, 도 84d 및 도 84e는 함께 취합되어, 본 발명의 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스템에 입력으로서 제공하기 위해 시스템 사용자에 대해 제공되는 예시적인 \"스타일\" 음악적 경험 디 스크립터(MUSEX) 세트를 설명한 테이블을 제공한다. 도 85는 본 발명의 자동화된 음악 작곡 및 생성 엔진(E1)에 작동 가능하게 연결된 복수의 원격 시스템 설계자 클라이언트 워크스테이션을 포함하는 본 발명의 자동화된 음악 작곡 및 생성 시스템 네트워크의 개략도이며, 그 파라미터 변환 엔진 서브 시스템 및 그 관련 파라미터 테이블 아카이브 데이터베이스 서브 시스템이 유지되고, 각각의 워크스테이션 클라이언트 시스템은 파라미터 변환 엔진 서브 시스템 내에서의 \"파라미터 매핑 구성 (PMC)\"의 생성 및 관리를 위해 GUI 기반 작업 환경을 지원하며, 전세계 어디든 원격 위치한 시스템 설계자는 시 스템 네트워크에 로그인하여 GUI 기반 작업 환경에 액세스할 수 있고, (i) 시스템 사용자에 의해 선택될 수 있 는 감정 타입, 스타일 타입 및 타이밍/공간 파라미터의 서로 다른 가능한 세트와 (ii) 파라미터 변환 엔진 서브 시스템 및 그 관련 파라미터 테이블 아카이브 데이터베이스 서브 시스템 내에서의 영구 저장을 위해, 바람직하 게는 파라미터 테이블 내에 유지되는 대응하는 확률 기반 음악 이론 시스템 작동 파라미터 세트 사이의 파라미 터 매핑 구성을 만들 수 있다. 도 86a는 도 85에 나타낸 시스템 네트워크에 의해 지원되는 GUI 기반 작업 환경의 개략도이며, 시스템 설계자는 (i) 기존 파라미터 매핑 구성의 관리 및 (ii) 도 28a 내지 도 79에 나타낸 대응하는 확률 기반 음악 이론 시스 템 작동 파라미터(SOP) 테이블(들)을 생성하게 되는, 파라미터 변환 엔진 서브 시스템(B51)에서의 로드 및 영구 저장을 위한 새로운 파라미터 매핑 구성의 생성을 선택하고, 이를 배치된 본 발명의 자동화된 음악 작곡 및 생성 시스템에 채택된 다양한 서브 시스템 내에 로드한다. 도 86b는 도 86a에 나타낸 시스템 네트워크에 의해 지원되는 GUI 기반 작업 환경의 개략도이며, 시스템 설계자 는 (i) 기존 파라미터 매핑 구성의 관리를 선택하고, 본 발명의 시스템의 파라미터 변환 엔진 서브 시스템(B5 1)의 영구 저장소에 생성되어 로드되어 있는 현재 생성된 파라미터 매핑 구성 리스트가 제시된다. 도 87a는 도 86a에 나타낸 시스템 네트워크에 의해 지원되는 GUI 기반 작업 환경의 개략도이며, 시스템 설계자 는 (i) 새로운 파라미터 매핑 구성의 생성을 선택한다. 도 87b는 도 86a에 나타낸 시스템 네트워크에 의해 지원되는 GUI 기반 작업 환경의 개략도이며, 시스템 설계자 에게는 배치된 본 발명의 자동화된 음악 작곡 및 생성 시스템에 채택된 다양한 서브 시스템 내에서의 생성 및 로드를 위해 (i) 사스템 사용자가 선택할 수 있는 가능한 감정/스타일/타이밍 파라미터 세트와, 도 28a 내지 도 79에 나타낸 대응하는 확률 기반 음악 이론 시스템 작동 파라미터(SOP) 테이블(들) 세트 사이의 파라미터 매핑 구성을 생성하는 데 사용하기 위한 GUI 기반 워크시트가 제시된다. 도 88은 시스템 사용자가 본 발명의 원리에 따라 작곡된 음악으로 감정적으로 스코어링될 비디오 내의 하나 이 상의 장면에 가사를 더 적용할 수 있도록, 텍스트 키보드 및/또는 음성 인식 인터페이스를 사용하여 생성된 언 어 기반 음악적 경험 디스크립터 및 가사 단어 디스크립터에 의해 구동되는 가상 악기 음악 합성의 사용을 지원 하는 본 발명의 자동화된 음악 작곡 및 생성 악기 시스템의 제7 대안적 실시형태의 사시도이다. 도 89은 시스템 버스 아키텍처 주변에 집적된 멀티 코어 CPU, 멀티 코어 GPU, 프로그램 메모리(DRAM), 비디오 메모리(VRAM), 하드 드라이브(SATA), LCD/터치 스크린 디스플레이 패널, 마이크/스피커, 키보드, WIFI/블루투스 네트워크 어댑터, 피치 인식 모듈/보드, 및 전원 공급 장치 및 분배 회로와 같은 다양한 구성 요소를 나타내는 키보드 인터페이스를 이용하여 선택된 그래픽 아이콘 기반 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성의 사용을 지원하는 본 발명의 자동화된 음악 작곡 및 생성 악기 시스템의 제7 예시적 실시형태의 예 시적 구현의 개략도이다. 도 90는 제7 예시적 실시형태의 자동화된 음악 작곡 및 생성 시스템의 상위 시스템 블록도이며, 가사 입력 및 기타 미디어(예컨대, 비디오 레코딩, 슬라이드 쇼, 오디오 레코딩 또는 이벤트 마커)를 포함한 언어 및/또는 그 래픽 기반 음악적 경험 디스크립터가 시스템 사용자 인터페이스(B0)(즉, 터치 스크린 키보드)를 통해 입력으로 서 선택되고, 미디어는 (예컨대, 장면 이미지 및/또는 정보 콘텐츠에 기초하여) 음악적 경험 디스크립터를 추출 하기 위해 시스템에 의해 자동으로 분석될 수 있으며, 그 후, 시스템 입력 서브 시스템(B0)의 인터페이스를 통 해 시스템 사용자에게 다시 제공되는 음악적으로 스코어링된 미디어, 음악 파일 및/또는 하드카피 시트 뮤직을 생성하기 위해 본 발명의 자동화된 음악 작곡 및 생성 엔진(E1)에 의해 사용된다. 도 90a는 타임 코딩으로 멀티플렉서를 지원하는 실시간 피치 이벤트 분석 서브 시스템(B52)에 시스템 사용자에 의해 제공된 타이핑되거나, 말로 전해지거나, 노래 불려진 대사 또는 가사 입력을 전송하는 시스템 사용자 인터 페이스의 개략 블록도이며, 실시간 피치 이벤트, 리듬 및 운율 분석이 실시되어 본 발명의 음악 작곡 및 생성 프로세스 중에 시스템 내의 파라미터를 변경하기 위해 각각 후속 사용되는 타이핑되고, 말로 전해지고 노래 불 려진 가사에 대한 3개의 서로 다른 피치 이벤트 스트림을 생성시킨다. 도 90b는 프로그래밍된 프로세서를 중심으로 구성된 하위 구성 요소, 즉, 가사 입력 핸들러, 피치 이벤트 출력 핸들러, 어휘 사전, 모음 포맷 분석기 및 모드 컨트롤러를 포함하는, 도 90a에 나타낸 서브 시스템에 채택된 실 시간 피치 이벤트 분석 서브 시스템(B52)의 상세한 개략 블록도이다. 도 91은 도 88 내지 도 90b에 나타낸 본 발명의 자동화된 음악 작곡 및 생성 시스템에 시스템 사용자에 의해 제 공된 가사 입력을 이용하여 자동화된 방식으로 음악을 작곡 및 생성하는 방법을 설명한 흐름도이며, 프로세스는 (a) 자동화된 음악 작곡 및 생성 시스템의 시스템 사용자 인터페이스에 음악적 경험 디스크립터를 제공하는 단 계; (b) 시스템에 의해 작곡 및 생성된 음악으로 스코어링될 비디오 또는 미디어 객체의 하나 이상의 장면을 위 해, 시스템의 시스템 사용자 인터페이스에 (예컨대, 타이핑되거나, 말로 전해지거나 또는 노래 불려진 포맷의) 가사 입력을 제공하는 단계; (c) 시간 및/또는 주파수 도메인 기술에 기초하여, 타이핑되거나/말로 전해지거나/ 노래 불려진 가사의 실시간 리듬, 피치 이벤트 및 운율 분석을 이용하여, 시스템 사용자 인터페이스에 제공된 가사 입력을 프로세싱하는 단계; (d) 분석된 가사 입력으로부터 타임라인에서의 피치 이벤트 및 그와 같은 검출 된 피치 이벤트가 발생한 타이밍 정보를 가진 코드를 추출하는 단계; 및 (e) 자동화된 시스템의 다양한 서브 시 스템에 채택된 확률 기반 파라미터 테이블을 제한하는 데 사용하기 위해 자동화된 음악 작곡 및 생성 엔진에 추 출된 피치 이벤트를 제공하는 단계를 포함한다.도 92은 (가사를 포함한) 언어 음악적 경험 디스크립터에 의해 구동되는 가상 악기 음악 합성의 사용을 지원하 는 본 발명의 제7 예시적 실시형태의 음악 작곡 및 생성 시스템 내에서 자동화된 음악 작곡 및 생성 프로세스를 실행하는 데 포함되는 주요 단계를 도시한 흐름도이며, 프로세스의 제1단계에서, (a) 시스템 사용자는 자동화된 음악 작곡 및 생성 시스템에 액세스한 다음, 그 자동화된 음악 작곡 및 생성 엔진에 의해 생성된 음악으로 스코 어링될 미디어를 선택하고, (b) 시스템 사용자는 음악적으로 스코어링될 선택된 미디어에 적용하기 위해 시스템 의 자동화된 음악 작곡 및 생성 엔진에 제공된 음악적 경험 디스크립터(및 선택적으로는 가사)를 선택하며, (c) 시스템 사용자는 자동화된 음악 작곡 및 생성 엔진을 기동하여 선택된 미디어에 스코어링되어 있는 제공된 음악 적 디스크립터에 기초한 음악을 작곡 및 생성하며, 그리고 (d) 시스템은 작곡된 음악을 선택된 미디어와 조합하 여, 표시 및 향유하기 위한 복합 미디어 파일을 제작한다."}
{"patent_id": "10-2018-7011569", "section": "도면", "subsection": "도면설명", "item": 4, "content": "도 93는 검출된 모음 포맷으로부터 음악 음표(예컨대, 피치 이벤트)를 자동으로 요약하여 시스템에 제공된 음악 적 경험 디스크립터의 감정 및 스타일 타입과 함께 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하기 위 해 시스템에 타이핑된 가사 입력으로서 제공된 감정 행복(예컨대, 찰스 스트라우스의 \"Put On A Happy Face\")의 타이핑된 가사 표현(단어 세트) 특징을 프로세싱하는 방법에 포함되는 상위 단계를 설명한 흐름도이다."}
{"patent_id": "10-2018-7011569", "section": "도면", "subsection": "도면설명", "item": 5, "content": "도 94은 검출된 모음 포맷으로부터 음악 음표(예컨대, 피치 이벤트)를 자동으로 요약하여 시스템에 제공된 음악 적 경험 디스크립터의 감정 및 스타일 타입과 함께 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하기 위 해 시스템에 말로 전해진 가사 입력으로서 제공된 감정 행복(찰스 스트라우스의 \"Put On A Happy Face\")의 말로 전해진 가사 표현 특징을 프로세싱하는 방법에 포함되는 상위 단계를 설명한 흐름도이다."}
{"patent_id": "10-2018-7011569", "section": "도면", "subsection": "도면설명", "item": 6, "content": "도 95는 검출된 모음 포맷으로부터 음악 음표(예컨대, 피치 이벤트)를 자동으로 요약하여 시스템에 제공된 음악 적 경험 디스크립터의 감정 및 스타일 타입과 함께 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하기 위 해 시스템에 노래 불려진 가사 입력으로서 제공된 감정 행복(찰스 스트라우스의 \"Put On A Happy Face\")의 노래 불려진 가사 표현 특징을 프로세싱하는 방법에 포함되는 상위 단계를 설명한 흐름도이다. 도 96는 자동화된 모음 포맷 분석법을 이용하여 도 95의 블록(E)에서 노래 불려진 가사 표현 내에서 자동으로 인식된 음악 음표 스코어의 개략도이다."}
{"patent_id": "10-2018-7011569", "section": "도면", "subsection": "도면설명", "item": 7, "content": "도 97은 검출된 모음 포맷으로부터 음악 음표(예컨대, 피치 이벤트)를 자동으로 요약하여 시스템에 제공된 음악 적 경험 디스크립터의 감정 및 스타일 타입과 함께 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하기 위 해 시스템에 타이핑된 가사 입력으로서 제공된 감정 슬픔 또는 우울함(예컨대, 이, 입 하버그 및 해롤드 알렌의 \"Somewhere Over The Rainbow\")의 타이핑된 가사 표현 특징을 프로세싱하는 방법에 포함되는 상위 단계를 설명 한 흐름도이다."}
{"patent_id": "10-2018-7011569", "section": "도면", "subsection": "도면설명", "item": 8, "content": "도 98은 검출된 모음 포맷으로부터 음악 음표(예컨대, 피치 이벤트)를 자동으로 요약하여 시스템에 제공된 음악 적 경험 디스크립터의 감정 및 스타일 타입과 함께 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하기 위 해 시스템에 말로 전해진 가사 입력으로서 제공된 감정 슬픔 또는 우울함(예컨대, 이, 입 하버그 및 해롤드 알 렌의 \"Somewhere Over The Rainbow\")의 말로 전해진 가사 표현 특징을 프로세싱하는 방법에 포함되는 상위 단계 를 설명한 흐름도이다."}
{"patent_id": "10-2018-7011569", "section": "도면", "subsection": "도면설명", "item": 9, "content": "도 99은 검출된 모음 포맷으로부터 음악 음표(예컨대, 피치 이벤트)를 자동으로 요약하여 시스템에 제공된 음악 적 경험 디스크립터의 감정 및 스타일 타입과 함께 작곡될 음악 조각의 음악적 경험 디스크립션을 보조하기 위 해 시스템에 노래 불려진 가사 입력으로서 제공된 감정 슬픔 또는 우울함(예컨대, 이, 입 하버그 및 해롤드 알 렌의 \"Somewhere Over The Rainbow\")의 노래 불려진 가사 표현 특징을 프로세싱하는 방법에 포함되는 상위 단계 를 설명한 흐름도이다. 도 100는 자동화된 모음 포맷 분석법을 이용하여 도 99의 블록(E)에서 노래 불려진 가사 표현 내에서 자동으로 인식된 음악 음표 스코어의 개략도이다. 도 101은 본 발명의 자동화된 음악 작곡 및 생성 프로세스를 지원하기 위해 시스템에 의해 제공되는 상위 시스 템 아키텍처를 도시한 도 26a 내지 도 26p를 참조하여 본 발명의 다양한 시스템에 의해 지원되는 자동화된 음악 작곡 및 생성 프로세스의 개요를 제공하는 상위 흐름도 세트이다."}
