{"patent_id": "10-2017-7030274", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2017-0134508", "출원번호": "10-2017-7030274", "발명의 명칭": "인공 신경망들에 대한 관련성 스코어 할당", "출원인": "프라운호퍼 게젤샤프트 쭈르 푀르데룽 데어 안겐", "발명자": "바흐, 세바스찬"}}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "관련성 스코어를 아이템들의 세트에 할당하기 위한 장치로서,상기 관련성 스코어는, 상기 아이템들(42)의 세트(16)를 망 출력(18)에 맵핑하기 위해 뉴런들(12)로 구성된 인공 신경망(10)의 상기 아이템들(42)의 세트(16)로의 적용에 대한 관련성을 표시하며,상기 장치는, 각각의 아이템에 대한 관련성 스코어를 획득하기 위해, 상기 인공 신경망(10)을 통해 초기 관련성스코어를 역으로 전파함으로써 상기 망 출력(18)으로부터 도출된 상기 초기 관련성 스코어(R)를 상기 아이템들(42)의 세트(16)로 재분배하도록 구성되고,상기 장치는, 각각의 뉴런에 대해, 상기 각각의 뉴런의 하류 이웃 뉴런들의 세트의 사전에 재분배된 관련성 스코어들이 분배 함수를 사용하여 상기 각각의 뉴런의 상류 이웃 뉴런들의 세트에 분배되도록 하는 방식으로 상기역방향 전파를 수행하도록 구성되는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 장치는, 상기 분배 함수가 관련성 보존 속성을 갖도록 구성되는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항 또는 제 2 항에 있어서,상기 장치는, 상기 인공 신경망의 모든 뉴런들에 대해 하나의 분배 함수를 동등하게 사용하여 상기 역방향 전파를 수행하도록 구성되는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항 내지 제 3 항 중 어느 한 항에 있어서,상기 장치는, 상기 분배 함수가:상기 각각의 뉴런의 상류 이웃 뉴런들의 세트에 의해 상기 각각의 뉴런의 영향의 정도를 결정하는 상기 인공망의 가중치들,상기 인공망(10)의 상기 아이템들(42)의 세트(16)로의 적용 시에 상기 상류 이웃 뉴런들을 명시하는(manifest)상기 상류 이웃 뉴런들의 세트의 뉴런 활성화들, 및상기 각각의 뉴런의 하류 이웃 뉴런들의 세트의 사전에 재분배된 관련성 스코어들의 합산의 함수이도록 구성되는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항 내지 제 4 항 중 어느 한 항에 있어서,상기 장치는, 각각의 뉴런 j에 대해, 얼마나 많은 관련성이 관련성 메시지 Rij로서 상기 각각의 뉴런 j로부터 상기 상류 이웃 뉴런 i로 재분배되는지를 산출하는 상기 분배 함수가 다음과 같도록 구성되며:상기 각각의 뉴런 j의 하류 이웃들의 수인 K를 갖는 는 자신의 모든 컴포넌트들에 대한 단조 증가 함공개특허 10-2017-0134508-3-수이고, 상기 각각의 뉴런의 상기 사전에 재분배된 관련성 스코어 를 산출하며, q(i)는 상기 각각의 뉴런 j에 상기 상류 이웃 뉴런 i를 연결하는 가중치들 wij, 상기 인공망(10)의상기 아이템들(42)의 세트(16)로의 적용으로부터 초래되는 상기 각각의 뉴런 j의 상기 상류 이웃 뉴런 i의 활성화 xi, 및 상기 뉴런 j의 가능한 제로-값의 바이어스 항 bj에 의존하는 함수인, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 인, 관련성 스코어를 아이템들의 세트에 할당하기 위한장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 5 항 또는 제 6 항에 있어서,상기 장치는, 상기 함수 q(i)가 함수 s에 의해 계산되는 가중된 활성화들 의 함수 p이므로, 이도록 구성되는, 관련성 스코어를 아이템들의 세트에할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 함수 s는, 상기 가중된 활성화 zij가 다음으로서 주어지도록 선택되며:또는 상기 I는 상기 뉴런 j의 상류 이웃 뉴런들 i의 수인, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 5 항 내지 제 8 항 중 어느 한 항에 있어서,상기 장치는, 상기 함수 q(i)가 Rj＞0인 각각의 뉴런 j에 대해 순서화 속성을 충족하도록 구성되며,상기 순서화 속성은,a) 이면, 인 뉴런 j의 상류 이웃 뉴런들인 모든 i1 및 i2에 대해, 가 참으로 유지되고,b) 또는, 인 뉴런 j의 상류 이웃 뉴런들인 모든 i1 및 i2에대해, 가 참으로 유지되는 경우에 충족되는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2017-0134508-4-제 5 항 내지 제 8 항 중 어느 한 항에 있어서,상기 장치는, 상기 함수 q(i)가 순서화 속성을 충족하도록 구성되며,상기 순서화 속성은 인 뉴런 j의 상류 이웃 뉴런들인 모든 i1 및 i2에 대해, 제로에서 자신의 최소값을 가지며 간격(-∞,0) 상에서 단조 감소하고 간격 (0,+∞) 상에서는 단조 증가하는 함수 에대해 가 참으로 유지되는 경우에 충족되는, 관련성 스코어를 아이템들의 세트에 할당하기위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 장치는, 상기 함수 가 다음과 같이 주어지도록 구성되는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치.에 대해,"}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 5 항 내지 제 11 항 중 어느 한 항에 있어서,상기 장치는, 상기 함수 q(i)가 뉴런들의 신경망 함수의 테일러 분해를 상속받거나 그에 비례하도록 구성되는,관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 5 항 내지 제 11 항 중 어느 한 항에 있어서,상기 장치는, 데이터로부터 학습되고, 뉴런 j의 상류 이웃들 i의 활성화들 xi를 값 에 근사 에러까지 맵핑하는 함수의 테일러 분해에 상기 관련성 메시지Rij가 비례하도록 구성되는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 1 항 내지 제 13 항 중 어느 한 항에 있어서,상기 장치는, 상기 분배 함수가 다음과 같도록 구성되며:또는n은 상기 각각의 뉴런 j의 상류 이웃 뉴런들의 수이고, Rij는 상기 각각의 뉴런 j로부터 상기 상류 이웃 뉴런 i로 재분배된 관련성 메시지이고, Rjk는 상기 하류 이웃 뉴런 k로부터 상기 각각의 뉴런 j로 재분배된 관련성 메시지이고, xi는 상기 신경망의 상기 아이템들(42)의 세트(16)로의 적용 동안의 상기 상류 이웃 뉴런 i의 활성화공개특허 10-2017-0134508-5-이고, wij는 상기 상류 이웃 뉴런 i를 상기 각각의 뉴런 j에 연결하는 가중치이고, wrj는 또한, 상류 이웃 뉴런r을 상기 각각의 뉴런 j에 연결하는 가중치이고, bj는 상기 각각의 뉴런 j의 바이어스 항이고, h()는 스칼라 함수이며,상기 각각의 뉴런 j의 하류 이웃들의 수인 K를 갖는 는 자신의 모든 컴포넌트들에 대한 단조 증가 함수이고, 상기 각각의 뉴런 j의 상기 사전에 재분배된 관련성 스코어 를 산출하는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 1 항 내지 제 13 항 중 어느 한 항에 있어서,상기 장치는, 상기 각각의 뉴런 j의 상류 이웃 뉴런들 i의 세트로의 분배가 분배 함수를 사용하여 수행되도록구성되며,상기 분배 함수는 다음과 같고:또는이고, n은 상기 각각의 뉴런의 상류 이웃 뉴런들의 수이고, Rij는 상기 각각의 뉴런 j로부터 상기 상류 이웃 뉴런 i로 재분배된 관련성 메시지이고, Rjk는 상기 하류 이웃 뉴런 k로부터 상기 각각의 뉴런 j로 재분배된 관련성 메시지이고, xi는 상기 신경망의 상기 아이템들(42)의 세트(16)로의 적용 동안의 상기 상류 이웃 뉴런 i의 활성화이고, wij는 상기 상류 이웃 뉴런 i를 상기 각각의 뉴런 j에 연결하는 가중치이고, wrj는 또한, 상류 이웃 뉴런 r을 상기 각각의 뉴런 j에 연결하는 가중치이고, bj는 상기 각각의 뉴런 j의 바이어스 항이고, h()는 스칼라 함수이며, 이고, 상기 각각의 뉴런j의 하류 이웃들의 수인 K를 갖는 는 자신의 모든 컴포넌트들에 대한 단조 증가 함수이고, 상기 각각의뉴런 j의 상기 사전에 재분배된 관련성 스코어 를 산출하는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 14 항 또는 제 15 항에 있어서, 인, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치.공개특허 10-2017-0134508-6-청구항 17 제 14 항 내지 제 16 항 중 어느 한 항에 있어서,상기 h()는 안정화 함수 인, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 1 항 내지 제 17 항 중 어느 한 항에 있어서,상기 장치는, 각각의 아이템에 재분배된 상류 이웃 뉴런으로서 상기 각각의 아이템을 갖는 뉴런들의 관련성 메시지들을 합산함으로써, 각각의 아이템 i에 대해, 상기 각각의 아이템 i의 관련성 스코어들 Ri를 계산하도록 구성되는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 1 항 내지 제 18 항 중 어느 한 항에 있어서,상기 인공 신경망은, 상기 아이템들(42)의 세트(16)의 아이템들이 상기 인공 신경망의 인공 뉴런들의 서브세트에 대해 상류 이웃들을 형성하도록 상기 아이템들의 세트에 직접 적용되고, 상기 망 출력은 상기 인공 신경망의하류 말단에서 뉴런의 뉴런 활성화에 대응하는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 1 항 내지 제 19 항 중 어느 한 항에 있어서,상기 망 출력(18)은 스칼라이거나 ― 상기 망 출력으로부터 도출되는 상기 초기 관련성 스코어는 상기 스칼라의값과 동일하거나, 또는 상기 스칼라의 값에 단조 증가 함수를 적용함으로써 도출됨 ―, 또는상기 망 출력은 벡터이며, 상기 초기 관련성 스코어는 상기 벡터의 하나 또는 그 초과의 컴포넌트들의 값과 동일하거나, 또는 상기 벡터의 하나 또는 그 초과의 컴포넌트들의 값에 단조 증가 함수를 적용함으로써 도출되는,관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제 1 항 내지 제 20 항 중 어느 한 항에 있어서,상기 장치는, 이도록 상기 역방향 전파를 수행하도록 구성되며, 는 상기 아이템들(42)의 세트(16)의 모든 아이템들 i의 관련성 스코어들에 걸친 합산을 나타내고, f는 에만 의존하는 단조 함수인, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제 21 항에 있어서,상기 장치는, 상기 f가 항등 함수(identity function)이도록 구성되는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제 1 항 내지 제 22 항 중 어느 한 항에 있어서,상기 장치는, 각각의 뉴런에 대하여, 상기 분배 함수에 의해 상기 각각의 뉴런의 상류 이웃 뉴런들의 세트에 분배되는 관련성 메시지 값들의 합산이 ξ(SN)와 동일하거나 그로부터 5%를 넘게 벗어나지 않도록 구성되며,SN은 상기 각각의 뉴런의 하류 이웃 뉴런들의 세트로부터 상기 각각의 뉴런으로의 관련성 메시지들의 합산을 나공개특허 10-2017-0134508-7-타내고, ξ는 SN에만 의존하는 단조 함수를 나타내는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제 23 항에 있어서,상기 장치는, 상기 ξ가 항등 함수이도록 구성되는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제 1 항 내지 제 24 항 중 어느 한 항에 있어서,상기 인공 신경망은, 각각의 뉴런(12)이 일 시퀀스의 계층들 중 하나에 속하도록 계층화되며,상기 장치는, 상기 인공 신경망의 모든 뉴런들에 대해 하나의 분배 함수를 동등하게 사용하여 상기 역방향 전파를 수행하도록 구성되는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제 1 항 내지 제 24 항 중 어느 한 항에 있어서,상기 인공 신경망은, 각각의 뉴런(12)이 일 시퀀스의 계층들 중 하나에 속하도록 계층화되며,상기 장치는, 각각의 계층에 대하여, 상기 각각의 계층의 뉴런들에 분배되는 관련성 메시지 값들의 합산이 ζ(SL) 와 동일하거나 그로부터 5%를 넘게 벗어나지 않기 위해 상기 역방향 전파를 수행하도록 구성되며,SL은 상기 각각의 계층에 하류인 계층의 뉴런들의 사전에 재분배된 관련성 스코어들의 합산을 나타내고, ζ는 SL에만 의존하는 단조 함수를 나타내는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제 1 항 내지 제 26 항 중 어느 한 항에 있어서,상기 아이템들의 세트(16)는,화상 ― 상기 아이템들(42)의 세트(16)의 아이템들(42) 각각은 상기 화상의 픽셀들 또는 서브픽셀들 중 하나 또는 그 초과에 대응함 ―, 및/또는비디오 ― 상기 아이템들(42)의 세트(16)의 아이템들(42) 각각은 상기 비디오의 화상들의 하나 또는 그 초과의픽셀들 또는 서브픽셀들, 상기 비디오의 화상들 또는 상기 비디오의 화상 시퀀스들에 대응함 ―, 및/또는오디오 신호 ― 상기 아이템들(42)의 세트(16)의 각각의 아이템들(42)은 상기 오디오 신호의 하나 또는 그 초과의 오디오 샘플들에 대응함 ―, 및/또는화상, 비디오 또는 오디오 신호로부터 국부적으로 또는 전역적으로 추출된 국부 특성들 또는 변환의 특성 맵 ―상기 아이템들(42)의 세트(16)의 아이템들(42)은 국부 특성들에 대응함 ―, 및/또는텍스트 ― 상기 아이템들(42)의 세트(16)의 아이템들(42)은 상기 텍스트의 단어들, 문장들 또는 단락들에 대응함 ―, 및/또는소셜 네트워크 관계 그래프와 같은 그래프 ― 상기 아이템들(42)의 세트(16)의 아이템들(42)은 노드들 또는 에지들 또는 노드들의 세트들 또는 에지들의 세트 또는 서브그래프들에 대응함 ―이거나 또는 그들의 결합인, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "데이터 프로세싱을 위한 시스템(100)으로서,제 1 항 내지 제 27 항 중 어느 한 항에 기재된, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치(50),및상기 아이템들의 세트로부터 프로세싱(106)되고 도출될 데이터 또는 상기 아이템들의 세트(16)를 프로세싱하면서 관련성 스코어들에 의존하여 상기 프로세싱을 적응시키기 위한 장치(102)를 포함하는, 데이터 프로세싱을 위공개특허 10-2017-0134508-8-한 시스템."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제 28 항에 있어서,상기 프로세싱은 손실있는 프로세싱이며,상기 프로세싱하기 위한 장치는, 더 낮은 관련성 스코어들이 할당된 아이템들과 비교하여, 더 높은 관련성 스코어들이 할당된 아이템들에 대한 손실있는 프로세싱의 손실도를 감소시키도록 구성되는, 데이터 프로세싱을 위한시스템."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제 28 항에 있어서,상기 프로세싱은 시각화이며,상기 적응시키기 위한 장치는, 상기 관련성 스코어들에 의존하여 상기 시각화에서 강조를 수행하도록 구성되는,데이터 프로세싱을 위한 시스템."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제 28 항에 있어서,상기 프로세싱은, 메모리로부터의 판독 또는 추가적인 측정의 수행에 의한 데이터 보충(replenishment)이며,상기 프로세싱하기 위한 장치(102)는, 상기 관련성 스코어들에 의존하여 상기 데이터 보충을 포커싱(focus)하도록 구성되는, 데이터 프로세싱을 위한 시스템."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "관심 영역을 강조하기 위한 시스템(110)으로서,제 1 항 내지 제 26 항 중 어느 한 항에 기재된, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치(50),및관련성 스코어들에 의존하여 관련성 그래프(114)를 생성하기 위한 장치(112)를 포함하는, 관심 영역을 강조하기위한 시스템."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "신경망을 최적화하기 위한 시스템(120)으로서,제 1 항 내지 제 27 항 중 어느 한 항에 기재된, 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치(50);아이템들의 복수의 상이한 세트들에 할당하기 위해 상기 장치를 적용하기 위한 장치(122); 및상기 아이템들의 복수의 상이한 세트들에 할당하기 위한 장치의 적용 동안 상기 망의 뉴런들에 할당된 관련성들을 누산하고, 상기 신경망 내의 증가된 관련성의 부분(128)에 의존하여 상기 인공 신경망을 최적화함으로써, 상기 신경망 내의 상기 증가된 관련성의 부분(128)을 검출하기 위한 장치(124)를 포함하는, 신경망을 최적화하기위한 시스템."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "관련성 스코어를 아이템들의 세트에 할당하기 위한 방법으로서,상기 관련성 스코어는, 상기 아이템들(42)의 세트(16)를 망 출력(18)에 맵핑하기 위해 뉴런들(12)로 구성된 인공 신경망(10)의 상기 아이템들(42)의 세트(16)로의 적용에 대한 관련성을 표시하며,상기 방법은, 각각의 아이템에 대한 관련성 스코어를 획득하기 위해, 상기 인공 신경망(10)을 통해 초기 관련성스코어를 역으로 전파함으로써 상기 망 출력(18)으로부터 도출된 상기 초기 관련성 스코어(R)를 상기 아이템들(42)의 세트(16)로 재분배하는 단계를 포함하고,공개특허 10-2017-0134508-9-상기 역방향 전파는, 각각의 뉴런에 대해, 상기 각각의 뉴런의 하류 이웃 뉴런들의 세트의 사전에 재분배된 관련성 스코어들이 분배 함수를 사용하여 상기 각각의 뉴런의 상류 이웃 뉴런들의 세트에 분배되도록 하는 방식으로 수행되는, 관련성 스코어를 아이템들의 세트에 할당하기 위한 방법."}
{"patent_id": "10-2017-7030274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "컴퓨터 프로그램으로서,컴퓨터 상에서 구동하는 경우, 제 34 항에 기재된 방법을 수행하기 위한 프로그램 코드를 갖는, 컴퓨터 프로그램."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 신경망이 적용되는 아이템들의 세트에 대한 관련성 스코어 할당의 작업은, 각각의 아이템에 대한 관련성 스 코어를 획득하기 위하여 인공 신경망을 통해 초기 관련성 스코어를 역으로 전파시키는 것에 의해, 망 출력으로부 터 도출된 초기 관련성 스코어를 아이템들의 세트로 재분배함으로써 획득된다. 특히, 이러한 역방향 전파는, 각 각의 뉴런에 대해, 각각의 뉴런의 하류 이웃 뉴런들의 세트의 사전에 재분배된 관련성 스코어들이 분배 함수에 따라 각각의 뉴런의 상류 이웃 뉴런들의 세트 상에 분배되도록 하는 방식으로 그 역방향 전파를 수행함으로써 인 공 신경망들의 더 넓은 세트에 적용가능하고 그리고/또는 더 낮은 계산 노력으로 적용가능하다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 인공 신경망들에 대한 관련성 스코어 할당에 관련된다. 그러한 관련성 스코어 할당은, 예를 들어, 관 심 영역 (ROI) 식별을 위해 사용될 수 있다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "컴퓨터 프로그램들은, 이미지들 및 텍스트들의 자동 분류와 같은 많은 복잡한 작업들을 성공적으로 해결하거나 사람의 신용도를 평가할 수 있다. 기계 학습 알고리즘들은 그들이 데이터로부터 학습하기 때문에 특히 성공적 이며, 즉, 프로그램은 큰 라벨링된(또는 약하게 라벨링된) 훈련(training) 세트를 획득하고, 일부 훈련 페이즈 (phase) 이후, 그 프로그램은 새로운 미지의 예들로 일반화할 수 있다. 많은 은행들은, 신용을 신청하는 사람 의 신용도를 (예를 들어, 연령, 주소, 소득 등에 기초하여) 분류하는 시스템을 갖는다. 그러한 시스템들의 주 된 결점은 해석능력이며, 즉, 시스템은 일반적으로, 판단에 이르게 되는 이유 및 방법 (예를 들어, 누군가가 신 용할 수 없는 것으로 분류되는 이유)에 대한 정보를 제공하지 않고; 분류 판단을 결정하는 지식 및 관계들은 다 소 '암시적'이다. 분류 판단들을 이해 및 해석하는 것은, 그것이 시스템의 추론을 검증하게 하고 인간 전문가, 예를 들어, 은행가, 벤처 자본 투자자 또는 의사에게 정보를 제공하므로 많은 응용에서 높은 가치를 갖는다. 기계 학습 방 법들은 대부분의 경우들에서, 블랙 박스로서 작동하는 단점을 가지며, 그들을 특정 판단에 도달하게 했던 것에 관한 어떠한 정보도 제공하지 않는다. 일반적으로 복잡한 알고리즘들은 (충분한 훈련 데이터가 이용가능한 경 우) 단순한(선형) 방법들보다 훨씬 더 양호한 성능을 갖지만, 그들에게는 특히 해석능력이 부족하다. 최근에, 일 타입의 분류기들, 즉 신경망들이 매우 대중적이게 되었고 탁월한 결과들을 산출했다. 이러한 타입의 방법들 은 비선형 맵핑들의 시퀀스로 구성되며, 특히 해석하기가 어렵다. 통상적인 이미지 분류 작업에서, 예를 들어, 이미지(예를 들어, 상어의 이미지)가 주어질 수 있다. 도 15를 참 조한다. 기계 학습(ML) 알고리즘은 특정한 클래스(예를 들어, '상어의 이미지들')에 속하는 것으로 이미지 를 분류한다. 클래스들의 세트(예를 들어, 상어들, 사람들, 유흥 야외들)가 선험적으로 정의 됨을 유의한다. 알고리즘은, 그 알고리즘이 이미지가 클래스 '상어의 이미지들'에 속한다는 판단에 이르 게 되는 이유를 그 알고리즘이 사용자에게 알리지 않기 때문에 블랙 박스이다. 픽셀 레벨에 관한 이러한 분류 판단에 대한 설명은, 예를 들어, 이미지가 주로 상어 지느러미 때문에 '상어의 이미지들'의 클래스에 속하는 것으로 분류되었다는 것을 관측하기에 흥미로울 것이다. 그러한 \"관련성 맵\"은 에 예시된다. 이미지들의 분류는 많은 컴퓨터 비전 응용, 예를 들어, 이미지 검색 [15], 로봇 공학 [10], 의료 이미징 [50], 레이더 이미지들에서의 물체 검출 [17] 또는 안면 검출 [49]에서 핵심 요소가 되었다. 신경망들 [6]이 이들 작 업들에 널리 사용되며,ImageNet [11]과 같은 이미지 분류 및 랭킹에 대한 경쟁들에서 최상의 제안들 중 하나였 다. 그러나 기계 학습의 많은 방법들과 유사하게, 이들 모델들에는 종종 분류기 예측들의 직접적인 해석능력이 부족하다. 즉, 분류기는 블랙 박스로서 작동하며, 그것이 특정한 분류 판단에 도달한 이유에 관한 상세한 정보 를 제공하지 않는다. 즉, 도 15의 해석 가능성은 이용가능하지 않다. 이러한 해석능력의 부족은, 로우(raw) 이미지 픽셀들을 그의 특성 표현으로 프로세싱하고 그로부터 최종 분류기 함수로 프로세싱하는 다양한 맵핑들의 비-선형으로 인한 것이다. 이것은, 그것이 인간 전문가들이 분류 판단을 신중하게 검증하는 것을 방해하므로, 분류 응용들에서 상당한 결점이다. 단순한 예 또는 아니오의 응답은 종종 응용들에서 제한된 값을 가지며, 여기서, 임의의 것이 발생하는 곳 또는 그것이 어떻게 구성되는지와 같은 질문은 단지 특정한 구조의 존재 또는 부재의 바이너리 또는 실수값의 1차원 평가보다 더 관련이 있다. 몇몇 작업들은 신경망들을 설명하는 주제에 전념해왔다. [54]는 픽셀 수준에 또한 적용가능한 뉴런들에서 분류 기 판단들을 분석하는 것에 전념한다. 그것은 컨볼루션 망(network)들의 아키텍처[23]에 대해 출력 계층들로부 터 입력 픽셀들을 향해 계층-단위(layer-wise) 하향 변환을 수행한다. 이러한 작업은 정류된 선형 활성화 기능 들을 갖는 뉴런들의 레이어들을 가진 콘볼루션 신경망들의 아키텍처에 특유하다. 입력 이미지 내의 픽셀들에 관한 편미분들에 대한 근사로서 [54]의 작업의 해석을 설정하는 [42]를 참조한다. 고레벨의 의미에서, [54]의 작업은, 이미지 입력을 재구성하기 위한 최적화 문제들, 즉 입력들을 향해 하향으로 응답들을 어떻게 투영할지 를 해결하는 [55] 내의 그 자신의 전임 작업으로부터의 방법을 사용하며, [54]는, 특성 맵들이 음수가 아니라는 것을 보장하기 위한 하나의 목적으로, 펼쳐진 맵들로부터의 정보를 입력들을 향해 투영시키기 위해, 정류된 선 형 유닛들을 사용한다. 입력 포인트 x의 편미분들과 상이한 포인트 x0 주위의 완전한 테일러 시리즈 사이에 놓여있는 다른 접근법이"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "[42]에서 제시된다. 이러한 작업은, 미분 및 나머지 바이어스(둘 모두는 추가적으로 특정되지 않음)를 계산하 기 위해 입력 포인트 x와는 상이한 포인트 x0를 사용하지만, 테일러 시리즈의 완전한 선형 가중항 x―x0를 사용 하기 위한 불특정 이유를 피한다. 신경망 모델을 사용하여 입력 변수들의 중요도를 정량화하는 것이 또한 생태 학 모델링과 같은 특정 영역들에서 연구되어 왔으며, 여기서, [16, 34]는 편미분들을 계산하는 것, 섭동 분석, 가중치 분석, 및 훈련 시간에 변수들을 포함 및 제거하는 효과를 연구하는 것을 포함하는 가능한 분석들의 큰 총체(ensemble)를 조사했다. 신경망에서 판단들을 이해하기 위한 상이한 방안은, 더 해석가능한 모델(예를 들 어, 판단 트리)을 신경망에 의해 학습된 기능에 맞추고, 이러한 새로운 모델에 의해 학습된 규칙들을 추출하는 것이다. 그러나, 인공 신경망들에 대한 관련성 스코어 할당의 작업을 실현하기 위한 견고하고 구현하기에 용이하며 광범 위하게 적용가능한 개념에 대한 필요성이 여전히 존재한다. 따라서, 인공 신경망이 적용되는 아이템 세트에 관련성 스코어를 할당하기 위한 개념을 제공하는 것이 본 발명 의 목적이며, 이 개념은 더 넓은 세트의 인공 신경망들에 적용가능하고 그리고/또는 계산 노력들을 낮춘다. 이러한 목적은 계류중인 독립 청구항들의 요지에 의해 달성된다. 인공 신경망이 적용되는 아이템들의 세트에 대한 관련성 스코어 할당의 작업은, 각각의 아이템에 대한 관련성 스코어를 획득하기 위하여 인공 신경망을 통해 초기 관련성 스코어를 역으로 전파시키는 것에 의해, 망 출력으 로부터 도출된 초기 관련성 값을 아이템들의 세트로 재분배함으로써 획득될 수 있다는 것이 본 출원의 기본적인 발견이다. 특히, 이러한 역방향 전파는, 각각의 뉴런에 대해, 각각의 뉴런의 하류 이웃 뉴런들의 세트의 사전 에 재분배된 관련성 스코어들이 분배 함수에 따라 각각의 뉴런의 상류 이웃 뉴런들의 세트 상에 분배되도록 하 는 방식으로 그 역방향 전파를 수행함으로써 인공 신경망들의 더 넓은 세트에 적용가능하고 그리고/또는 더 낮 은 계산 노력으로 적용가능하다. 다양한 실시예들에 따른 본 발명의 바람직한 구현들 및 응용들이 종속 청구항들의 요지이며, 본 출원의 바람직 한 실시예들은 다음의 도면들에 관해 더 상세히 아래에서 설명된다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "블록도들에 관한 본 출원의 다양한 실시예들을 설명하기 전에, 이들 실시예들의 기저가 되는 개념들이 먼저 인 공 신경망들에 대한 간략한 소개에 의해, 그리고 그 다음에 실시예들의 개념의 기저가 되는 사상들을 설명함으 로써 설명될 것이다. 신경망은, 입력 데이터와 출력 데이터 사이의 복잡한 맵핑을 근사하도록 훈련될 수 있는 상호연결된 비선형 프 로세싱 유닛들의 그래프이다. 입력 데이터는, 예를 들어, 이미지(픽셀들의 세트)이고, 출력은, 예를 들어, 분 류 판단임을 유의한다(가장 단순한 경우에서, +1/-1은 이미지에서 상어가 존재한다는 '예' 또는 상어가 존재하 지 않는다는 '아니오'를 의미함). 각각의 비선형 프로세싱 유닛(또는 뉴런)은 비선형 활성화 함수가 적용되는 그 유닛의 입력들의 가중된 선형 결합으로 구성된다. 인덱스 i를 사용하여 인덱스 j를 갖는 뉴런으로 들어오는 뉴런들을 표시하기 위해 인덱스 i를 사용하는 경우, 비선형 활성화 함수는 다음과 같이 정의된다: 여기서, 는 비선형 단조 증가 함수이고, wij는 뉴런 i를 뉴런 j에 연결하는 가중치이며, bj는 바이어스 항이 다. 신경망은 그의 연결 구조, 그의 비선형 활성화 함수, 및 그의 가중치에 의해 정의된다. 아래의 실시예들은 관련성 전파로 지칭되는 후속 설명에서 존재할 수 있고 존재하는 개념을 사용한다. 그것은, 출력 뉴런들에 의해 모델링되는 바와 같은 데이터 내의 특정한 구조에 대한 증거를 다시 입력 뉴런들에 재분배 한다. 따라서, 그것은 입력 변수들(예를 들어, 픽셀들)의 관점들에서 그 자신의 예측에 대한 설명을 생성하기 를 추구한다. 개념은 계층들의 수, 활성화 함수의 타입 등과 관계없이 모든 각각의 타입의 (루프-없는) 신경망 에 대해 작동함을 유의한다. 따라서, 그것은, 많은 알고리즘들이 신경망들의 관점들에서 설명될 수 있으므로, 많은 인기 모델들에 적용될 수 있다. 관련성 전파 절차의 예시는 컨볼루션/서브-샘플링 계층들, 그에 뒤따르는 완전히-연결된 계층들의 시퀀스로 구 성된 망에 대해 아래에서 주어진다. 특히, 도 1a는 간략화된 예시적인 방식으로 인공 신경망의 일 예를 도시한다. 인공 신경망은 도 1에 원들 로 도시된 뉴런들로 구성된다. 뉴런들은 서로 상호연결되거나 서로 상호작용한다. 일반적으로, 각각 의 뉴런은, 한편으로는 하류 이웃(또는 후임자) 뉴런들 및 다른 한편으로는 상류 이웃(또는 전임자) 뉴런들에 연결된다. 용어들 \"상류\", \"전임자\", \"하류\" 및 \"후임자\"는, 아이템들의 세트를 망 출력에 매핑, 즉 예측을 수행하기 위해 신경망이 아이템들의 세트에 적용될 경우 신경망이 동작하는 일반적인 전파 방향을 지칭한다. 도 1a에 도시된 바와 같이, 아이템들의 세트는, 예를 들어, 이미지의 픽셀들의 어레이 내의 각각의 픽 셀 포지션에 대응하는 공간 위치의 장면의 컬러 또는 강도에 대응하는 픽셀값과 각각의 픽셀을 연관시킴으로써 이미지를 형성하는 픽셀들의 세트일 수 있다. 그 경우에서, 세트는 아이템들의 순서화된 콜렉션 (collection), 즉 픽셀들의 어레이이다. 이러한 경우, 아이템들은 개별 픽셀값들에 대응할 것이며, 즉, 각각의 아이템은 하나의 픽셀에 대응할 것이다. 나중에, 본 출원이 화상들의 분야로 제한되지는 않는다는 것이 명확해 질 것이다. 오히려, 아이템들의 세트는 아이템들 사이에 정의된 임의의 순서가 없는 아이템들의 세트일 수 있다. 그 사이의 혼합물들이 또한 사실일 수 있다. 뉴런들의 제 1 또는 가장 낮은 계층은 인공 신경망의 입력의 일 종류를 형성한다. 즉, 이러한 가 장 낮은 계층의 각각의 뉴런은 자신의 입력들로서 아이템들의 세트의 적어도 서브세트의 값들, 즉 픽셀값들의 적어도 서브세트를 수신한다. 세트로부터의 아이템들의 서브세트들의 합집합(그 서브세트들의 값들은 가장 낮은 계층의 특정한 뉴런으로 입력됨)은, 예를 들어, 세트, 즉 도 1a의 경우에서는 전 체 이미지와 동일하다. 즉, 세트의 각각의 아이템에 대해, 그의 값은 가장 낮은 계층의 뉴런들 중 적어도 하나로 입력된다. 신경망의 반대측, 즉 그의 하류/출력측에서, 망은 하나 또는 그 초과의 출력 뉴런들(12')을 포함하며, 그 뉴런들은 그들에게는 하류 이웃/후임자 뉴런들이 없다는 점에서 뉴런들과는 상이하다. 세트에 적용 된 이후 그리고 프로세싱을 완료한 이후, 각각의 출력 뉴런(12')에 저장된 값들은 망 출력을 형성한다. 즉, 망 출력은, 예를 들어, 스칼라일 수 있다. 그 경우에서, 단지 하나의 출력 뉴런(12')만이 존재할 것이며, 망의 동작 이후의 그의 값은 망 출력을 형성할 것이다. 도 1에 예시된 바와 같이, 그러한 망 출력은 아이 템들의 세트, 즉 도 1a의 경우에서는 이미지가 특정한 클래스에 속하는 또는 속하지 않는 가능성에 대 한 측정일 수 있다. 그러나, 망 출력은 대안적으로 벡터일 수 있다. 그 경우에서, 1개 초과의 출력 뉴런 (12')이 존재하며, 망의 동작의 종료 시에 획득되는 바와 같은 이들 출력 뉴런들(12') 각각의 값은 망 출력 벡터의 각각의 컴포넌트를 형성한다. 도 1은, 예를 들어, 망 출력의 각각의 컴포넌트가 측정이라는 것을 예시하며, 그 측정은, 세트가 각각의 컴포넌트와 연관된 각각의 클래스, 예컨대 \"보트를 나타내는\" 이미지 들, \"트럭을 나타내는\" 이미지들, \"자동차를 나타내는\" 이미지들에 속하는 가능성을 측정한다. 다른 예들이 또 한 상상가능하며, 본 명세서의 아래에서 제시될 것이다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "따라서, 위의 내용을 요약하면, 신경망은, 순방향 전파 또는 정상 동작에서, 아이템들의 세트를 뉴런 출력 에 맵핑하기 위해 상호연결된 뉴런들을 포함한다. 출력 뉴런들(12')과 유사한 방식으로(그 출력 뉴런들의값은 망의 동작의 종료 시에 망 출력을 형성함), 세트의 아이템들, 즉 도 1a의 예시적인 경우에서는 이 미지의 픽셀들은 뉴런들과 함께 망의 입력 뉴런들로 간주될 수 있으며, 그에 의해 형성되는 계층들 은 각각, 중간 뉴런들 또는 중간 계층들이다. 따라서, 특히, 예를 들어, 망의 가장 높은 중간 계층, 또는 망의 가장 높은 계층을 형성할 때 하나 또는 그 초과의 출력 뉴런들(12')을 해석하는 경우에는 망의 두 번째 가장 높은 계층을 형성하는 중간 뉴런들의 하류 이웃/후임자 뉴런들을 출력 뉴런들(12')이 형성할 수 있는 것처럼, 입력 뉴런들은, 중간 뉴런들의 상류 이웃 또는 전임자 뉴런들, 즉 계층의 상류 이웃 또는 전임자 계층들로 간주될 수 있다. 도 1은 신경망의 간략화된 예를 예시하며, 그 예에 따라, 망의 뉴런들은, 특정한 뉴런의 상류 이웃/후임자 뉴런들(그들 모두는 각각의 뉴런이 속하는 계층에 비해 중간의 더 낮은 계층의 멤버들임) 및 하류 이웃/후임자 뉴런들(그들 모두는 중간의 더 높은 계층의 멤버들임)을 갖는 계층들의 시퀀스를 계층들 이 형성한다는 의미로 계층들에 엄격히 배열된다. 그러나, 도 1은, 아래에서 추가적으로 서술되는 본 발명 의 실시예들이 이러한 이슈에 대해 적용될 수 있는 신경망들의 종류를 제한하는 것으로 해석되지는 않아야 한다. 오히려, 뉴런들의 이러한 엄격한 계층화된 배열은 대안적인 실시예들에 따라 변경될 수 있으며, 예 를 들어, 상류 이웃/전임자 뉴런들은 하나 초과의 선행 계층의 뉴런들로부터의 서브세트이고 그리고/또는 하류 이웃/후임자 뉴런들은 1개 초과의 상위 계층의 뉴런들로부터의 서브세트이다. 또한, 망의 순방향 전파 동작 동안 각각의 뉴런이 단지 1회 횡단될 것이라고 도 1이 제안하지만, 하나 또는 그 초과의 뉴런들은 2회 또는 그 이상 횡단될 수 있다. 추가적인 변형 가능성들이 아래에서 논의될 것이다. 지금까지 설명된 바와 같이, 망을 세트, 즉 도 1a의 예시적인 경우에서는 이미지에 적용할 경우, 망은 순방향 전파 동작을 수행한다. 이러한 동작 동안, 자신의 상류 이웃/전임자 뉴런들로부터 자신의 입 력값들 모두를 수신하는 각각의 뉴런은 각각의 뉴런 함수에 의해, 그의 활성화로 지칭되는 출력값을 계산한 다. 위의 예시적인 수학식에서 xj로 지칭되는 이러한 활성화는 각각의 하류 이웃/후임자 뉴런들의 입력값을 형 성한다. 이러한 측정에 의해, 세트의 아이템들의 값들은 출력 뉴런(12')으로 종결하기 위해 뉴런을 통 해 전파된다. 보다 정확하게는, 세트의 아이템들의 값들은 망의 가장 낮은 계층의 뉴런들의 입력 값들을 형성하며, 출력 뉴런들(12')은 그들의 상류 이웃/전임자 뉴론들의 활성화들을 입력 값들로서 수신하 고, 그들의 출력값들, 즉 망 출력을 각각의 뉴런 함수에 의해 계산한다. 망의 뉴런들(12 및 12')과 연 관된 뉴런 함수들은 모든 뉴런들(12 및 12') 사이에서 동일할 수 있거나, 또는 뉴런 함수들이 파라미터화가능하 다는 것을 의미하는 \"등식(equality)\"으로 그들 사이에서 상이할 수 있으며, 기능 파라미터들은 등식을 방해하 지 않으면서 뉴런들 사이에서 상이할 수 있다. 다양한/상이한 뉴런 함수들의 경우에서, 이들 함수들은 망 의 동일한 계층의 뉴련들 사이에서 동일할 수 있거나, 또는 하나의 계층 내의 뉴런들 사이에서도 상이할 수 있 다. 따라서, 망은, 예를 들어, 컴퓨터상에서 구동하는 컴퓨터 프로그램, 즉 소프트웨어의 형태로 구현될 수 있 지만, 전기 회로의 형태와 같은 하드와이어링된 형태의 구현이 또한 실현가능할 것이다. 각각의 뉴런은 위 에서 설명된 바와 같이, 예를 들어, 입력값들의 선형 결합의 비선형 스칼라 함수 로서 위의 명시적인 예에 서 제시되는 뉴런 함수를 사용하여 자신의 입력값들에 기초하여 활성화를 계산한다. 설명된 바와 같이, 뉴런들 (12 및 12')과 연관된 뉴런 함수들은 파라미터화된 함수일 수 있다. 예를 들어, 아래에서 서술되는 특정한 예 들 중 하나에서, 뉴런 j에 대한 뉴런 함수들은 각각의 뉴런의 모든 입력값들 i에 대한 오프셋 bj 및 가중치 wij 를 사용하여 파라미터화가능하다. 이들 파라미터들은 파선 박스를 사용하여 도 1a에 예시된다. 이들 파라 미터들은 훈련한 망에 의해 획득될 수 있다. 이를 위해, 망은, 예를 들어, 정확한 망 출력이 알려 지는 아이템들의 세트들의 훈련 세트, 즉, 도 1a의 예시적인 경우에서는 라벨링된 이미지들의 훈련 세트에 반복적으로 적용된다. 그러나, 다른 가능성들이 또한 존재할 수 있다. 심지어 결합이 실현가능할 수 있다. 아래에서 추가적으로 설명되는 실시예들은 파라미터들의 결정의 임의의 종류의 근원 또는 방식으로 제한되 지 않는다. 도 1a는, 예를 들어, 콘볼루션 필터들에 의하여 이미지의 특성 추출을 에뮬레이팅(emulate)하 기 위해, 예를 들어, (하류) 트레일링(trailing) 계층의 각각의 뉴런이 특성 맵들로부터의 특성값을 표현하 도록, 세트, 즉 망의 입력으로부터 중간의 숨겨진 계층으로 연장하는 계층들로 구성되는 망의 상류 부분이 인공적으로 생성 또는 학습된다는 것을 예시한다. 각각의 특성 맵은, 예를 들어, 특정한 특징 또는 특성 또는 임펄스 응답 등과 연관된다. 따라서, 각각의 특성 맵은, 예를 들어, 연관된 필터의 연관된 특성/특징/임펄스 응답에서 다른 특성 맵과는 상이한 특성 맵을 갖는 입력 이미지의 드물게 샘플링된필터링된 버전으로 고려될 수 있다. 예를 들어, 세트가 X·Y개의 아이템들, 달리 말해, 픽셀들, 즉 X개의 열들 및 Y개의 행들의 픽셀들을 가지면, 각각의 뉴런은 하나의 특성 맵의 하나의 특성값에 대응할 것이며, 그 값은 이미지의 특정한 부분과 연관된 국부적인 특성 스코어에 대응할 것이다. P·Q개의 특성 스코어 샘 플들, 예를 들어, 즉 P개의 열들 및 Q개의 행들의 특성값들을 갖는 N개의 특성 맵들의 경우에서, 부분의 하 류 트레일링 계층에서의 뉴런들의 수는, 예를 들어, X·Y보다 작거나 클 수 있는 N·P·Q일 것이다. 특성 맵들 의 기저가 되는 특성 설명자들 또는 필터들의 변환은 각각, 부분 내의 뉴런들의 뉴런 함수들을 셋팅하 거나, 또는 그 뉴런들의 뉴런 함수들을 파라미터화하는데 사용될 수 있다. 그러나, 망의 그러한 \"학습\"되기보 다는 \"변환된\" 부분의 존재가 본 출원 및 그의 실시예들에 필수적이지는 않으며, 대안적으로는 그러한 부분 이 존재하지 않을 수 있다는 것을 또한 유의한다. 그러나, 어느 경우에서든, 뉴런들의 뉴런 함수들이 모든 뉴런들 사이에서 동일하거나 하나의 계층의 뉴런들 사이에서 동일하거나 등의 방식일 수 있다는 것이 실현가능 하다고 언급할 시에, 뉴런 함수는 파라미터화가능할 수 있으며, 파라미터화가능한 뉴런 함수가 그 뉴런들 사이 에서 동일할 수 있더라도, 이러한 뉴런 함수의 함수 파라미터(들)는 이들 뉴런들 사이에서 변할 수 있다. 중간 계층들의 수가 유사하게 자유로우며, 1과 동일하거나 1보다 클 수 있다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "위의 내용을 요약하면, 정상 동작 모드의 망의 응용은 다음과 같다: 세트로서 역할을 하는 입력 이미지 는 망에 종속되거나 또는 커플링된다. 즉, 이미지의 픽셀값들은 제 1 계층의 뉴런들에 대 한 입력값들을 형성한다. 이들 값들은 설명된 바와 같이, 망을 통해 순방향을 따라 전파되며, 망 출력 을 초래한다. 도 1에 도시 된 입력 이미지의 경우에서, 예를 들어, 망 출력은, 예를 들어, 이러한 입력 이미지가 제 3 클래스, 즉 자동차를 나타내는 이미지들의 클래스에 속한다는 것을 표시할 것이다. 보 다 정확하게는, 클래스 \"자동차\"에 대응하는 출력 뉴런이 높은 값으로 종결될 것이지만, 여기에서 \"트럭\" 및 \" 보트\"에 예시적으로 대응하는 다른 출력 뉴런들은 낮은(더 낮은) 값들로 종결될 것이다. 그러나, 본 출원의 명세서의 도입 부분에서 설명된 바와 같이, 이미지, 즉 세트 가 자동차 등을 나타내 는지 여부에 관한 정보는 충분하지 않을 수 있다. 오히려, 어떤 픽셀들, 즉 세트의 어떤 아이템들이 망 의 결정을 위해 관련되었는지 여부, 예를 들어, 어떤 픽셀들이 자동차를 나타내는지 여부를 표시하는 픽셀 들의 입도 레벨의 정보를 갖는 것이 바람직할 것이다. 이러한 작업은 아래에서 설명되는 실시예들에 의해 처리 된다. 특히, 도 2a는, 도 2a의 예시적인 경우에서는 픽셀들의 도메인인 세트의 아이템들로의 관련성 스코어 할당 의 작업을 이행하기 위해 아래에서 더 상세히 설명되는 본 발명의 실시예들이 어떻게 동작하는지를 예시적인 방 식으로 도시한다. 특히, 도 2a는 이러한 관련성 스코어 할당이 역방향 전파 프로세스(역 또는 관련성 전파)에 의해 수행된다는 것을 예시하며, 그 프로세스에 따라, 관련성 값 R은, 예를 들어, 망 입력, 즉 아이템들의 세트 를 향하여 망을 통해 역으로 전파되고, 그에 의해, 이미지의 각각의 픽셀에 대해 세트의 각각의 아 이템 i에 대한 관련성 스코어 Ri를 획득한다. 예를 들어, X·Y개의 픽셀들을 포함하는 이미지에 대해, i는 {1 … X·Y} 내에 있을 수 있고, 각각의 아이템/픽셀 i는, 예를 들어, 픽셀 포지션(xi, yi)에 대응한다. 도 1의 순 방향 전파 방향과 반대로 진행하는 역방향 전파 방향을 따라 이러한 역방향 전파를 수행할 시에, 이하 에서 설명되는 실시예들은 이제 더 상세하게 설명되고 관련성 보존 및 관련성 재분배로 지칭되는 특정한 제한들 을 준수한다. 간략히 말하자면, 관련성 스코어 할당은 인공 신경망의 완성된 기구로부터 세트로 시작한다. 위에서 설명된 바와 같이, 이러한 기구는 망 출력에서 종결된다. 초기 관련성 값 R은 이러한 망 출력으로부터 도출된다. 아래에서 설명되는 예들에서, 예를 들어, 하나의 출력 뉴런(12')의 출력값은 이러한 관련성 값 R로 서 사용된다. 그러나, 망 출력으로부터의 도출은 또한, 예를 들어, 망 출력에 적용된 단조 함수를 사용하여 상 이하게 수행될 수 있다. 다른 예들이 아래에서 기재된다. 어느 경우에서든, 이러한 관련성 값은 그런다음, 망 출력을 초래하기 위해 세트에 적용될 경우 망 이 작업하는 순방향 전파 방향과 비교하여 반대 방향을 포인팅하는 역방향, 즉 로 망을 통해 전파 된다. 역방향 전파는, 각각의 뉴런에 대해, 각각의 뉴런의 하류 이웃 뉴런들의 세트의 사전에 재분배된 관 련성 값들의 합산이 각각의 뉴런의 상류 이웃 뉴런들로 분배되어 관련성이 \"실질적으로 보존\"되게 하는 방식으 로 행해진다. 예를 들어, 분배 함수는, 역방향 전파를 완료한 이후 초기 관련성 값 R이 세트의 아이템들 i 의 관련성 스코어들 Ri의 합산과 동일하도록(정확하게는, 즉 또는 단조 함수 f(), 즉 를 통해) 선택될 수 있다. 다음에서, 분배 함수 및 분배 함수가 어떻게 유리하게 선택될지에 관한 일부 일반적인사상들이 논의된다. 역방향 전파 동안, 뉴런들의 뉴런 활성화들이 역방향 전파를 안내하기 위해 사용된다. 즉, 망 출력을 획득하기 위해 망을 세트에 적용하는 동안의 인공 신경망의 뉴런 활성화들은 사전에 저장되고 역방 향 전파 절차를 안내하기 위해 재사용된다. 아래에서 더 상세히 설명될 바와 같이, 테일러 근사가 역방향 전파 를 근사하기 위해 사용될 수 있다. 따라서, 도 2a에 예시된 바와 같이, 역방향 전파의 프로세스는, 출력 뉴런 (들)으로부터 시작하여, 역방향 전파 방향을 따라 망의 입력측을 향해 초기 관련성 값 R을 분배하는 것으로 고려될 수 있다. 이러한 측정에 의해, 증가된 관련성의 관련성 유동 경로들은 출력 뉴런으로부터 망의 입력 측을 향해 유도되고, 즉 입력 뉴런들은 아이템들의 세트 그 자체에 의해 형성된다. 도 2에 예시적으로 예시된 바와 같이, 망을 통한 통과 동안 경로들이 간헐적으로 분기된다. 최종적으로, 경로들은 아이템들의 세트 내의 증가된 관련성의 핫스팟들에서 종결된다. 도 2a에 도시된 바와 같이, 입력 이미지 를 사용하는 특정한 예에서, 관련성 스코어들 Ri는, 이미지 내의 증가된 관련성의 영역들, 즉 망의 대응하는 망 출력으로의 종결에서 주요 역할을 했던 이미지 내의 영역들을 픽셀 레벨로 표시한다. 다 음에서, 직전에 언급된 관련성 보존 및 관련성 재분배 속성들은, 망의 뉴런들에 대한 뉴런 함수들로서의 비 선형 활성화 함수들에 대한 위의 예를 사용하여 더 상세히 논의된다. 속성 1: 관련성 보존 관련성 전파 모델의 제 1의 기본적인 속성은 증거가 생성되거나 손실될 수 없다는 것을 부과한다. 이것은, 전 역 스케일(즉, 신경망 출력으로부터 다시 신경망 입력으로) 및 국부 스케일(즉, 개별적인 비선형 프로세싱 유닛 들의 레벨로) 둘 모두에 적용된다. 그러한 제한은, 키르히호프의 회로 법칙들을 신경망에 적용하고 \"전기 전류\"의 물리적 개념을 \"시맨틱(semantic) 증거\"로 대체하는 것에 해당한다. 특히, 도 3을 참조한다. 인덱스 j를 갖는 뉴런으로 들어오고 그 뉴런으로 나가는 뉴런들을 나타내기 위해 인덱스들 i 및 k를 사용하면 (들어오는 뉴런들은 도 3에서 으로 예시되고, 따라서 전임자들 또는 상류 이웃들을 형성함), 아이덴티티는,"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "를 유지해야 하며, 여기서, Rij는 뉴런 j로부터 뉴런 i로 유동하는 관련성을 나타내고, Rjk는 뉴런 k로부터 뉴런 j로 유동하는 관련성을 나타낸다. 관련성 보존 법칙은, '뉴런으로 유동하는' 관련성들의 합산이 '이러한 뉴런 밖으로 유동하는' 관련성들의 합산과 동일해야 한다는 것을 나타냄을 유의한다. 관련성 보존은, 입력 뉴런 관 련성들(예를 들어, 픽셀들의 관련성들)의 합산이 망의 출력값(예를 들어, 분류 스코어)과 동일하다는 것을 보장 한다. 속성 2: 관련성 재분배 관련성 전파 모델의 제 2의 기본은, 관련성의 국부적인 재분배가 망 내의 모든 뉴런들에 변함없이 적용되는 고 정된 법칙을 따라야 한다는 것이다. 많은 상이한 법칙들이 관련성 재분배에 대해 정의될 수 있다. 법칙들 중 일부는 \"의미가 있지만\", 다른 법칙들은 아니다. 하나의 그러한 의미있는 법칙은, 예를 들어, 다음과 같으며:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, n은 i에 의해 인덱싱된 뉴런들의 수이다. 이러한 재분배 법칙에 대한 유리화(rationalization)는, 뉴 런 xj의 활성화에 가장 많이 기여하는 뉴런들 xi가 들어오는 관련성 의 대부분을 차지할 것이라는 것 이다. 또한, 재분배된 관련성 Rij를 모든 들어오는 뉴런들 i에 걸쳐 합산하면, 속성 1이 충족된다는 것이 명확 해야 한다. 그러나, 위의 결정론적 관련성 전파 법칙은 2개의 결점들을 갖는다: 먼저, 그것은, 분모가 제로에 가까울 경우 수치적으로 불안정할 수 있다. 둘째로, 그것은 정의되지 않은 의미를 갖는 Rij에 대한 음의 값들을 생성할 수있다. 첫번째 이슈는 다음과 같이 법칙을 재정의함으로써 해결되며:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, 는 분모가 제로에 가까워지는 것을 방지하는 수치 안정기이고, 는 속성 1을 준수하기 위해 매우 작게 선택된다. 두번째 이슈는 뉴런 활성화들에 대한 양의 기여들만을 고려함으로써 해결 되며, 특히 다음과 같다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, 본 발명은, 2개의 양의 량(quantity)들의 비율이 반드시 양이므로, 관련성이 있을 것임을 주목했다. 이들 2개의 향상들은 안정성 및 양성(positivity) 속성 둘 모두를 충족시키도록 용이하게 결합될 수 있다. 관련성 보존은, 재분배가 무엇인지(= 전체값(합산)을 일정하게 유지하면서, 출력 관련성들을 입력 변수들에 분 배하는 것)를 나타내는 반면, 관련성 재분배는, 그것을 어떻게 행할지(= \"의미있는\" 재분배는 활성화에 가장 많 이 기여하는(큰 가중된 활성화들 xiwij를 갖는) 뉴런들이 들어오는 관련성들의 대부분을 차지할 것이라는 것을 보장해야 함)를 나타냄을 유의한다. 본 출원의 일 실시예에 따른 장치를 설명하기 전에, 위의 도입부는 가능한 대안들을 더 명확하게 제시하기 위해 확장되어야 한다. 예를 들어, 도 1a 및 도 2a에 관해 설명된 실시예가 아이템 세트로서 이미지를 사용했지만(망의 하 나의 층의 뉴런들의 뉴런 활성화들이 이미지의 \"국부적인 특성들\", 즉 특성 맵들의 샘플들을 표현하는 그러 한 방식으로 망을 가급적 설계함), 도 1b 및 도 2b의 실시예는 특성 맵들을 아이템들의 세트로서 사용한다. 즉, 망에는 특성 맵들의 특성 샘플들이 공급된다. 특성 맵들은, 입력 이미지로부 터 각각의 특성 맵을 각각 추출하는 특성 추출기들에 동일하게 가함으로써 입력 이미지로부터 획득될 수 있다. 이러한 특성 추출 동작은 화살표를 사용하여 도 1b에 예시된다. 예를 들어, 특성 추출기는, 예 를 들어, 행들 및 열들로 배열된 특성 샘플들로 구성되는 대응하는 특성 맵을 획득하기 위해, 이미지에 걸 쳐 필터 커널을 이동시켜 특성 샘플을 기구마다 도출하기 위하여 필터 커널을 이미지에 국부적으로 적용할 수 있다. 필터 커널/템플릿은 각각, 각각의 특성 추출기들 및 대응하는 특성 맵들에 개별적일 수 있다. 여기서, 도 1b의 망은 도 1a의 망의 나머지 부분, 즉 부분을 제거한 이후의 망의 나머지와 일 치할 수 있다. 따라서, 도 1b의 경우에서, 특성 샘플값들은, 소위 예측 프로세스의 일부로서 망을 통해 순 방향을 따라 전파되고, 망 출력을 초래한다. 도 2b는 도 1b의 망에 대한 관련성 역 전파 프로세스를 도시한다: 역방향 전파 프로세스는, 망 입력, 즉 아이템들의 세트를 향하여 망을 통해 관련성 값 R을 역으로 전파하며, 그에 의해, 각각의 아이템에 대한 관련성 스코어 Ri를 획득한다. 도 2b의 경우에서, 그에 따 라 관련성 스코어 Ri는 특성 샘플 i 마다 획득된다. 그러나, 특성 맵들이 개별적인 필터 추출 기능들에 의 하여 특성 맵을 통해 이미지 콘텐츠에 관련되므로, 각각의 관련성 스코어 i는, 즉 이미지의 개별적인 픽셀 포지션들로 세트의 아이템들의 개별적인 관련성 스코어들을 고정된 방식으로 분배함으로써, 픽셀 도메인으 로, 즉 픽셀들로 변환될 수 있다. \"고정된 방식\"은, 각각의 관련성 스코어의 특성 맵과 연관된 특성 추출기들 에 고유하게 의존하며, 특성 추출의 역함수의 일 종류를 표현한다. 따라서, 이러한 역함수는 특성 세트 도메인으로부터 픽셀들의 공간 도메인까지의 갭을 좁히기(close) 위해 역 전파 프로세스의 일 종류의 확장 을 형성한다. 추가적으로, 도 1a 및 도 2a의 경우에서, 이미지의 각각의 픽셀, 즉 의 각각의 아이템이 스칼라를 운반 한다는 것이 사전에 가정됨을 유의한다. 예를 들어, 이러한 해석은 그레이 스케일 이미지의 경우에 적용될 수 있으며, 예를 들어, 각각의 픽셀값은 그레이 스케일 값에 대응한다. 그러나, 다른 가능성들이 또한 존재한 다. 예를 들어, 이미지는 컬러 이미지일 수 있다. 그 경우에서, 세트의 각각의 아이템은 이미지의 하나 또는 그 초과의 컬러 평면들 또는 컬러 컴포넌트들의 샘플 또는 픽셀값에 대응할 수 있다. 3개의 컴포 넌트들은, 컬러 이미지들을 향한 도 1a 및 도 2a의 확장을 도시하는 도 1c 및 도 2c에 예시적으로 예시된다. 따라서, 도 1c 및 도 2c의 경우의 아이템들의 세트는, X·Y개의 픽셀 포지션들 각각에 대해 3개 의 컬러 컴포넌트들 각각에 대한 컬러 컴포넌트 값을 갖는 경우에서 X·Y·3일 것이다. 그러나, 컬러 컴포넌트 들의 수는 3 이외일 수 있다. 추가적으로, 컬러 컴포넌트들의 공간 해상도는 동일할 필요가 없다. 도 2c의 역 전파는 아이템, 즉 컬러 컴포넌트 샘플 당 관련성 값으로 종결된다. 각각의 픽셀에 대해 모든 컴포넌트들에 대 한 컴포넌트 값을 갖는 경우에서, 최종 관련성 맵은 각각의 픽셀의 컬러 컴포넌트들에 대해 획득되는 관련성 값 들을 합산함으로써 획득될 수 있다. 이것은 에 예시된다. 도 1 내지 도 2c가 이미지들 및 픽셀들에 관련되었지만, 본 출원의 실시예들은 그 종류의 데이터로 제한되지 않 는다. 예를 들어, 텍스트들 및 그의 단어들이 기반으로서 사용될 수 있다. 소셜 그래프 분석 애플리케이션은 다음과 같이 볼 수 있다: 관련성은 그래프 내의 노드들 및 연결들에 할당되고, 여기서 그래프는 신경망으로 의 입력으로서 주어진다. 소셜 그래프 분석의 콘텍스트에서, 노드들은 사용자들을 표현할 수 있고, 연결들은 그 사용자들 사이의 관계를 표현할 수 있다. 그러한 연결들은 또한, 정보 흐름들(예를 들어, 인용망(citations network)) 또는 조직 내의 책임의 체인을 모델링하도록 지시될 수 있다. 신경망들은, 예를 들어, 입력으로서 주어진 그래프에 대해, 그래프의 특정한 속성(예를 들어, 특정한 소셜 그래프에 연관된 생산성)을 예측하도록 훈련될 수 있다. 이러한 경우에서, 관련성 전파 및 히트맵핑 방법은, 예측된 속성(즉, 높은 또는 낮은 생산 성)을 설명하는 서브구조들 또는 노드들을 이러한 그래프에서 식별하기를 추구할 것이다. 신경망들은 또한, 추 후의 시점에서 그래프의 상태를 예측하도록 훈련될 수 있다. 이러한 경우에서, 관련성 전파 절차는, 그래프 내 의 어떤 서브구조가 그래프의 미래의 상태를 설명하는지(예를 들어, 어떤 서브구조들 또는 노드들이 그래프의 정보를 확산시키거나 또는 그의 상태를 변화시키기 위한 그들의 능력으로 소셜 그래프에서 가장 영향이 있는 지)를 식별하기를 추구할 것이다. 따라서, 신경망은, 예를 들어, 광고 캠페인(회귀 작업)의 성공(예를 들어, 판매된 제품들의 수)을 예측하는데 사용될 수 있다. 관련성 스코어들은 성공에 대한 일부 영향있는 양상들을 식별하는데 사용될 수 있다. 회사는 이들 관련성 양상들에만 포커싱함으로써 금전을 절약할 수 있다. 관련성 스코어 할당 프로세스는 광고 캠페인의 모든 각각의 아이템에 대한 스코어를 줄 수 있다. 그런다음, 판단 프로 세서는 이러한 입력 및 또한, 광고 캠페인의 모든 각각의 아이템의 비용들에 관한 정보를 취하고, 캠페인에 대 한 최적의 전략을 판단할 수 있다. 그러나, 관련성은 또한, 위에서 도시된 바와 같이 특성 선택을 위해 사용될 수 있다. 관련성 스코어 할당은 초기 관련성 값 R의 도출로 시작한다. 위에서 언급된 바와 같이, 관련성 스코어 할당은, 신경망의 출력 뉴런들 중 하나의 \"의미\"를 참조하여 역 전파에 의해 세트의 아이템들에 대한 관련성 값들을 획득하기 위해 그 하나의 출력 뉴런에 기초하여 셋팅될 수 있다. 그러나, 망 출력은 대안적으로 벡터일 수 있으며, 출력 뉴런들은, 그 출력이 중첩한 또는 비-중첩한 서브세트들로 분할될 수 있다는 그러한 의미들을 가 질 수 있다. 예를 들어, 의미(카테고리) \"트럭\" 및 \"자동차\"에 대응하는 출력 뉴런들은 의미 \"차량\"의 출력 뉴 런들의 서브세트를 초래하도록 결합될 수 있다. 따라서, 출력 뉴런들 둘 모두의 출력값들은 역 전파에서 시작 포인트로서 사용될 수 있으며, 그에 의해, 서브세트의 의미, 즉 \"차량\"에 대한 관련성을 표시하는 아이템들 , 즉 픽셀들에 대한 관련성 스코어들을 초래한다. 아이템 세트가 화상(아이템들의 세트의 아이템들 각각은 화상의 하나의 픽셀에 대응함)이라고 위의 설명이 제안했지만, 이것은 상이할 수 있다. 예를 들어, 각각의 아이템은, 도 2c에 예시된 바와 같은 슈퍼 픽 셀과 같은 픽셀들 또는 서브픽셀들의 세트에 대응할 수 있다(픽셀은 일반적으로 rgb 값들을 가짐. 서브픽셀은, 예를 들어, 픽셀의 그린 컴포넌트일 것임). 추가적으로, 아이템 세트는 대안적으로 비디오일 수 있으며, 아이템들의 세트의 아이템들 각각은 비디오의 화상들의 하나 또는 그 초과의 픽셀들, 비디오의 화 상들 또는 비디오의 화상 시퀀스들에 대응한다. 아이템이 참조하는 픽셀들의 서브세트는 상이한 시간 스탬프들 의 화상들의 픽셀들을 포함할 수 있다. 추가적으로, 아이템 세트는 오디오 신호일 수 있으며, 아이템들 의 세트의 각각의 아이템들은 PCM 샘플들과 같은 오디오 신호의 하나 또는 그 초과의 오디오 샘플 들에 대응한다. 세트의 개별적인 아이템들은 오디오 레코딩의 샘플들 또는 임의의 다른 부분일 수 있다. 또는, 아이템들의 세트는 주파수들과 시간의 곱 공간(product space)이며, 각각의 아이템은, 예를 들어, 중첩하 는 윈도우들의 시퀀스의 MDCT 스펙트럼들로 구성되는 스펙트로그램과 같은 하나 또는 그 초과의 주파수 시간 간 격들의 세트이다. 추가적으로, 세트는 국부적인 특성들에 대응하는 아이템들의 세트의 아이템들 을 갖는 화상, 비디오 또는 오디오 신호로부터 국부적으로 추출되는 국부적인 특성들, 또는 텍스트의 단어 들, 문장들 또는 단락들에 대응하는 아이템들의 세트의 아이템들을 갖는 텍스트의 특성 맵일 수 있다. 완전함을 위해, 도 1d 및 도 2d는 변형예를 도시하며, 그 예에 따르면, 아이템들의 데이터 세트는 이미지보 다는 텍스트이다. 그 경우에 대해, 도 1d는, 실제로 (예를 들어, I) 단어들의 시퀀스인 텍스트가, 단 어단위 변환에 따라 공통 길이, 즉 컴포넌트들 vij의 공통 수 J의 각각의 벡터 vi로 각각의 단어 wi를 맵핑함으로써, \"추상적\" 또는 \"해석가능\" 버전으로 변환된다는 것을 예시한다. 각각의 컴포넌트는 시 맨틱 의미와 연관될 수 있다. 사용될 수 있는 워드단위 변환은, 예를 들어, Word2Vec 또는 단어 표시자 벡터들 이다. 벡터들 vi의 컴포넌트들 vij는 세트의 아이템들을 표현하고 망에 종속되며, 그에 의해 망의 출력 노드들(12')에서 예측 결과를 초래한다. 도 2d에 도시된 역방향 전파는 아이템 당, 즉 각각의 벡터 컴포넌트 vij(0＜i＜I; 0＜j＜J)에 대한 관련성 값을 초래한다. 예를 들어, 0＜j＜J를 갖는 각각의 단어 wi와 연관된 벡터 vi의 컴포넌트들 vij에 대한 관련성 스코어들을 각각의 단어 wi에 대해 합산하는 것은 단어 당 관련성 합산값(관련성 스코어)을 초래하며, 따라서, 텍스트 내의 각각의 단어 wi는 그의 관련성 스코어 합산 에 따라 강조될 수 있다. 강조 옵션들의 수는 2 또는 그 초과일 수 있다. 즉, 단어들의 관련성 합산값들은 단 어 당 강조 옵션을 초래하도록 양자화될 수 있다. 강조 옵션은 상이한 강조 강도와 연관될 수 있으며, 관련성 합산값들로부터 강조 옵션들로의 맵핑은 관련성 합산값들과 라이라이팅 강도 사이의 단조 연관을 초래할 수 있 다. 또한, 신경망이 이미지들에 대한 예측의 성능에 관련되었던 예들과 유사하게, 도 1d 및 도 2d의 망의 입력측 부분은 일부 해석가능한 의미를 가질 수 있다. 이미지들의 경우에서, 이것은 특성 세트들을 갖는다. 도 1d 및 도 2d의 경우에서, 망의 입력 부분은 세트의 컴포넌트들로 구성되는 벡터들의 가장 가능성있 는 더 낮은 차원의 벡터들로의 다른 벡터 단위 맵핑을 표현할 수 있으며, 그 더 낮은 차원의 벡터들의 컴포넌트 들은, 세트의 컴포넌트들로 구성된 벡터들의 다소 단어군 관련 컴포넌트들과 비교하여 다소 시맨틱 의미를 가질 수 있다. 도 4는 관련성 스코어를 아이템들의 세트에 할당하기 위한 장치의 일 예를 도시한다. 장치는, 예를 들어, 소프 트웨어로, 즉 프로그래밍된 컴퓨터로서 구현된다. 그러나, 다른 구현 가능성들이 또한 상상가능하다. 어느 경 우에서든, 장치는, 아이템들의 세트에 관련성 스코어를 아이템-단위로 할당하기 위해 위에서 서술된 역 방향 전파 프로세스를 사용하도록 구성되며, 관련성 스코어는, 각각의 아이템에 대해, 그의 망 출력에 기초 한 망 출력의 망의 도출 시에 이러한 아이템이 어떤 관련성을 갖는지를 표시한다. 따라서, 도 4는 신 경망을 또한 도시한다. 망은 장치의 일부가 아닌 것으로 도시되며: 오히려, 망은, 장치에 의 해 스코어들이 아이템들의 세트에 할당될 \"관련성\"의 의미의 소스를 정의한다. 그러나, 대안적으로, 장치 는 망을 또한 포함할 수 있다. 도 4는, 작은 원들로서 예시적으로 표시되는 아이템들을 갖는 아이템들의 세트를 수신하는 것으로 망 을 도시한다. 도 4는 또한, 위에서 설명된 바와 같이 뉴런의 상류 이웃/전임자 뉴런들에 기초한 뉴런 활성 화 계산을 제어하는 함수 가중치들, 즉 뉴런 함수들의 파라미터들과 같은 뉴런 파라미터들에 의해 망이 제어되는 가능성을 예시한다. 이들 파라미터들은, 예를 들어, 메모리 또는 저장부에 저장될 수 있다. 도 4는 또한, 파라미터들을 사용하는 아이템들의 세트를 프로세싱하는 것을 완료한 이후의 망 의 출력, 즉 망 출력 및 선택적으로는 세트를 프로세싱한 것으로부터 초래되는 뉴런들의 뉴런 활성 화들을 예시하며, 뉴런 활성화들은 참조 부호에 의해 예시된다. 뉴런 활성화들, 망 출력 및 파라 미터들은 메모리에 저장되는 것으로 예시적으로 도시되지만, 그들은 또한, 별개의 저장부 또는 메모리 에 저장될 수 있거나 또는 저장되지 않을 수 있다. 장치는, 망 출력으로의 액세스를 가지며, 세트(1 6)의 각각의 아이템 i에 대한 관련성 스코어 Ri를 획득하기 위해 위에 기재된 역방향 전파 원리 및 망 출력 을 사용하여 재분배 작업을 수행한다. 특히, 위에서 설명된 바와 같이, 장치는 망 출력으로부터 초기 관련성 값 R을 도출하고, 아이템들 i에 대한 개별 관련성 스코어들 Ri로 종결하기 위해 역방향 전파 프로세 스를 사용하여 이러한 관련성 R을 재분배한다. 세트의 개별 아이템들은 참조 부호에 의해 표시된 작은 원들에 의해서 도 4에 예시된다. 위에서 설명된 바와 같이, 재분배는 파라미터들 및 뉴런 활성화들 에 의해 안내될 수 있으며, 따라서, 장치는 이들 데이터 아이템들에 대한 액세스를 또한 가질 수 있다. 추가적으로, 도 4에 도시된 바와 같이, 실제 신경망은 장치 내에서 구현될 필요가 없다. 오히려, 장치 는 뉴런들의 수, 파라미터들이 속하는 뉴런 함수들, 및 뉴런 상호연결과 같은 망의 구성에 대한 액 세스를 갖고, 즉 그 구성에 대해 알 수 있으며, 그 정보는 도 4에 예시된 바와 같이, 메모리 또는 저장부 또는 다른 곳에 또한 저장될 수 있는 용어 신경망 설명을 사용하여 도 4에 예시되어 있다. 대안적인 실시예에서, 인공 신경망은 또한, 장치가 재분배 작업을 수행하는 재분배 프로세서에 부가하여 신경망 을 세트에 적용하기 위한 신경망 프로세서를 포함할 수 있도록 장치 상에 구현된다. 따라서, 위에 제시된 실시예들은 그 중에서도, 컴퓨터 시각에서 인기가 있는 다계층화된 신경망들에 대한 해석 능력과 분류 사이의 갭을 좁힐 수 있다. 신경망들(예를 들어, [6, 31])에 대해, 본 발명은, 일반화된 p-수단에 기초한 임의의 연속 뉴런들 및 풀링(pooling) 함수들을 이용하여 일반적인 다계층화된 망 구조들을 고려할 것이다. 다음의 섹션, 즉 일반적인 개념으로서의 픽셀-단위 분해는 분류기들의 픽셀-단위 분해의 기저가 되는 기본적인 접근법들을 설명할 것이다. 이러한 픽셀-단위 분해는 도 1a 및 도 2c에 관해 예시되었다. 다계층 망들에 대한 픽셀-단위 분해는, 일반적인 개념으로서의 픽셀-단위 분해에서 설명되는 테일러-기반 및 계층-단위 관련성 전파 접근법들 둘 모두를 신경망 아키텍처에 적용한다. 본 발명의 프레임워크의 실험적인 평가는 실험들에서 행해질 것이다. 일반적인 개념으로서의 픽셀-단위 분해 픽셀-단위 분해의 전체 개념은 이미지 분류 작업에서 분류기 f에 의해 행해지는 예측 f(x)에 대한 이미지 x의 단일 픽셀의 기여를 이해할 것이다. 본 발명은 각각의 이미지 x에 대해 별개로, 어떤 픽셀들이 어느 정도로 양 또는 음의 분류 결과에 기여하는지를 발견하기를 원한다. 또한, 본 발명은 측정에 의해 정량적으로 이러한 정 도를 표현하기를 원한다. 본 발명은 제로로 임계치화된 실수값 출력들을 분류기가 갖는다고 가정한다. 그러한 셋업에서, 그것은, f(x)>0가 학습된 구조의 존재를 나타내도록 하는 맵핑 이다. 2-클래스 분류 기들에 대한 확률적인 출력들은, 0.5를 감산하거나 예측의 로그를 취하고 그런다음, 2.0의 로그를 부가함으로써 일반화의 손실없이 처리될 수 있다. 본 발명은, 특정한 예측 f(x)에 대한 입력 이미지 x의 각각의 입력 픽셀 x(d)의 기여를 발견하는 것에 관심있다. 분류에 특정적인 중요한 제한은, 분류에 관한 최대 불확실성의 상태에 관한 미분 기여도를 발견하는데에 있으며, 그런다음, 그것은 루트 포인트들 f(x0)=0에 의해 표현된다. 하나의 가능한 방식은 다음과 같이, 각각의 픽셀들에 대해 별개의 입력 차원들 xd의 항들의 합산으로 예측 f(x)를 분해 하는 것이다: 수학식 1"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "정량적인 해석은, Rd＜0가 분류될 구조의 존재에 대한 반대 증거(evidence against)에 기여하는 반면, Rd＞0가 그 존재에 대한 증거에 기여한다는 것이다. 후속 시각화의 항들에서, 각각의 입력 픽셀 x(d)에 대한 결과적인 관련성들 Rd는, 컬러 공간에 맵핑되고, 종래의 히트맵과 같은 그러한 방식으로 시각화될 수 있다. Rd의 부호들 이 위의 정량적인 해석을 따라야 한다는, 즉, 양의 값들은 양의 기여도들을 나타내고, 음의 값들은 음의 기여도 들을 나타내야 한다는 하나의 기본적인 제약이 다음의 작업에 존재할 것이다. 다음에서, 개념은 수학식 에서와 같이 픽셀-단위 분해를 달성하려는 목적을 위한 개념으로서의 계층-단위 관 련성 전파로서 표시된다. 본 발명은 또한, 계층-단위 관련성 전파의 근사를 산출하는 테일러 분해에 기초한 접 근법을 논의한다. 본 발명은, 넓은 범위의 비-선형 분류 아키텍처들에 대해, 계층-단위 관련성 전파가 테일러 확장에 의한 근사를 사용할 필요없이 행해질 수 있다는 것을 나타낼 것이다. 본 발명이 후속하여 제시하는 방 법들은 세그먼트화를 수반하지 않는다. 그들은 학습 셋업으로서의 픽셀-단위 훈련 또는 훈련 페이즈에 대한 픽 셀-단위 라벨링을 요구하지 않는다. 여기서 사용된 셋업은 이미지-단위 분류이며, 여기서, 훈련 동안 하나의 라벨은 이미지에 대해 전체로서 제공되지만, 기여도는 분류기 훈련에 대한 것은 아니다. 방법들은 미리 훈련된 분류기의 최상부 상에 구축된다. 그들은 미리 훈련된 분류기에 이미 적용가능하다. 계층-단위 관련성 전파 일반적인 형태의 계층-단위 관련성 전파는, 분류기가 수 개의 계층들의 계산으로 분해될 수 있다고 가정한다. 그러한 계층들은, 이미지로부터의 특성 추출의 일부들 또는 계산된 특성들 상에서 실행되는 분류 알고리즘의 일부들일 수 있다. 이후에 도시되는 바와 같이, 이것은 신경망들에 대해 가능하다. 제 1 계층은 입력들, 즉 이미지의 픽셀들일 수 있고, 최종 계층은 분류기 f의 실수값 예측 출력이다. l번째 계 층은 차원 V(l)을 갖는 벡터 로서 모델링된다. 계층-단위 관련성 전파는, 본 발명이 계층 l+1에서 벡터 z의 각각의 차원 z(d,l+1)에 대해 관련성 스코어 를 갖는다고 가정한다. 개념은, 다음의 수 학식이 성립(hold)하도록 입력 계층에 더 가까운 다음의 계층 l에서 벡터 z의 각각의 차원 z(d,l)에 대한 관련성 스코어 를 발견하는 것이다. 수학식 2"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "그런다음, 분류기 출력 f(x)인 최종 계층으로부터 아래로 이미지 픽셀들로 구성된 입력 계층 x까지 하향으로 수 학식 를 반복하는 것은 원하는 수학식 을 산출한다. 입력 계층에 대한 관련성은 수학식 에서 원하는 합산 분해로서 기능할 것이다. 본 발명이 나타낼 바와 같이, 그러한 분해 그 자체는 고유하지도 않으며, 그것 이 분류기 예측의 의미있는 해석을 산출하는 것을 보장하지도 않는다. 여기서, 본 발명은 간단한 반례를 제공한다. 본 발명이 하나의 계층을 갖는다고 가정한다. 입력은 이다. 본 발명은, 몇몇 임의의 그리고 차원-특정 특성 공간 맵핑 및 바이어스 b를 갖는 선형 분류기를 사 용하며, 다음과 같다: 수학식 3"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "제 2 계층에 대한 관련성을 평범하게 로서 정의한다. 그런다음, 하나의 가능한 계층-단위 관련성 전파 수식은 다음과 같이 입력 x에 대한 관련성 R을 정의할 것이다: 수학식 4"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "이것은 수학식들 및 를 명확하게 충족시키지만, 모든 입력 차원들의 관련성 는 예측 f(x)와 동일한 부호를 갖는다. 픽셀-단위 분해 해석의 관점들에서, 모든 입력 포인트는, f(x)＞0이면 구조의 존재를 향하고, f(x)＜0이면 구조의 부재를 향한다. 이것은 많은 분류 문제들에 대해 현실적인 해석이 아니다. 계층-단위 관련성 전파를 정의하는 더 의미있는 방식을 논의한다. 이러한 예에 대해, 본 발명은 다음을 정의한 다:수학식 5"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "그런다음, 특성 차원 xd의 관련성은 수학식 의 항의 부호에 의존한다. 이것은 많은 분류 문제들에 대해 이 치에 맞는 해석이다. 이러한 제 2 예는, 계층-단위 관련성 전파가 특성 공간 맵핑 와 같은 비-선형들을 어 느 정도까지는 처리할 수 있다는 것과 수식 를 충족시키는 계층-단위 관련성 전파의 일 예가 실제로는 어떻 게 보일 수 있는지를 나타낸다. 특성 공간 맵핑 에 대한 어떠한 정규(regularity) 가정도 여기서 전혀 요 구되지 않으며, 그것이 심지어 르베그 측정 하에서 비-연속적이거나 측정가능하지 않을 수 있음을 유의한다. 기저의 수식 는 특성 프로세싱의 계층들 사이의 관련성 R에 대한 보존 법칙으로서 해석될 수 있다. 위의 예는 또한, 관련성 R이 무엇인지, 즉 예측 함수 f(x)에 대한 국부적인 기여도에 관한 직관을 제공한다. 그 의미에서, 출력 계층의 관련성은 예측 그 자체 f(x)로서 선택될 수 있다. 이러한 제 1 예는, 선형 경우에 대한 분해로서 예상할 수 있는 것을 나타낸다. 선형 경우는 제 1 직관을 제공한다. 본 발명은, 제 2의 더 그래픽적이고 비-선형인 예를 제공한다. 도 5는, 뉴런들 및 뉴런들 사이의 연결들에 대 한 가중치들 wij을 갖는 신경망-형상 분류기를 도시한다. 각각의 뉴런 i는 활성화 함수로부터의 출력 ai를 갖는 다. 최상부 계층은 7로 인덱싱된 하나의 출력 뉴런으로 구성된다. 각각의 뉴런 i에 대해, 본 발명은 관련성 Ri를 계산할려고 한다. 본 발명은, 계층 인덱스가 명백할 때마다 모든 뉴런들이 명시적인 뉴런 인덱스를 가지므로, 이러한 예에 대해서는 계층 인덱스 위첨자 를 드롭할 것이다. 본 발명은 최상부 계층 관련성 을 함수 값으로서 초기화하며, 따라서, 이다. 수학식 의 계층-단위 관련성 전파는 이제 다음을 성립하 도록 요구한다: 수학식 6"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "수학식 7"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "본 발명은 이러한 예에 대해 2개의 가정들을 행할 것이다. 먼저, 본 발명은, 각각의 연결을 따라 전송될 수 있 는 뉴런들 i 및 j 사이의 메시지들 의 항들에서 계층-단위 관련성을 표현한다. 그러나, 메시지들은 도 6에 도시된 바와 같이, 예측 시간에서 발생하는 것과는 대조적으로, 뉴런으로부터 그의 입력 뉴런들로 안내된다. 둘째로, 본 발명은 다음과 같이, 뉴런 7을 제외한 임의의 뉴런의 관련성을 들어오는 메시지들의 합 산으로서 정의한다:수학식 8"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "예를 들어, 이다. 뉴런 7은 어쨌든 어떠한 들어오는 메시지들도 갖지 않음을 유의한다. 대신, 그의 관련성은 로서 정의된다. 수학식 에서 그리고 다음의 텍스트에서, 입 력 및 소스라는 용어들은, 계층-단위 관련성 전파의 계산 시간이 아니라 분류 시간 동안 정의된 바와 같은 방향 으로의 다른 뉴런에 대한 입력이라는 의미를 갖는다. 예를 들어, 도 6에서, 뉴런들 1 및 2는 뉴런 4에 대한 입 력들 및 소스인 반면, 뉴런 6은 뉴런들 2 및 3에 대한 싱크(sink)이다. 수학식 에서 부호화된 2개의 가정들 이 주어지면, 수학식 에 의한 계층-단위 관련성 전파는 다음의 충분 조건에 의해 충족될 수 있다: 수학식 9"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "수학식 10"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "수학식 11"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "수학식 12"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 19, "content": "일반적으로, 이러한 조건은 다음과 같이 표현될 수 있다: 수학식 13"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 20, "content": "조건 과 정의 사이의 차이는, 조건 에서는 합산이 계층 l+1의 고정 뉴런 k에 대해 계층 l의 소스들 위에서 합산이 실행되는 반면, 정의 에서는 합산이 계층 l의 고정 뉴런 i에 대해 계층 l+1의 싱크들 위에서 실행된다는 점이다. 이러한 조건은 필수 조건이 아니라 충분 조건이다. 그것은 정의 의 결과이다. 메시지 들 이 뉴런 k의 관련성 를 계층 l의 자신의 입력 뉴런들 상으로 분배하기 위해 사용된다는 것을언급함으로써 충분 조건 이 해석될 수 있다. 다음의 섹션들은 이러한 개념, 및 정의 및 충분 조건 에 의해 주어진 바와 같은 관련성 보존의 더 엄격한 형태에 기초할 것이다. 이제, 본 발명은, 메시지들 을 정의함으로써 본 발명의 예에 대해 계층-단위 관련성 전파에 대한 명시적 인 수식을 도출할 수 있다. 계층-단위 관련성 전파는 분류 시간 동안 전달되는 메시지들을 반영해야 한다. 본 발명은, i가 k로의 순방향 연결을 가지면, 분류 시간 동안, 뉴런 i가 aiwik를 뉴런 k에 입력한다는 것을 안다. 따라서, 본 발명은 다음에 의해 수학식들 및 을 표현할 수 있다: 수학식 14"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 21, "content": "수학식 15"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 22, "content": "일반적으로, 이것은 다음과 같이 표현될 수 있다: 수학식 16"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 23, "content": "이러한 정의는 분모가 제로가 되는 경우 그 정의가 사용가능하도록 여전히 적응될 필요가 있지만, 수학식 에서 주어진 예는, 메시지 일 수 있는 것, 즉 선행 계층 l로부터 뉴런 i의 입력에 의해 비례적으로 이미 계산되어 가중된 싱크 뉴런 의 관련성의 개념을 제공한다. 이러한 개념은, 본 발명이 사이한 분류 아키 텍처들을 사용하고 뉴런의 개념을 주어진 계층의 특성 벡터의 차원으로 대체하는 경우 유사한 방식으로 유지된 다. 수식 은 제 2 속성을 가지며: 뉴런 aiwik의 기여도가 상이한 부호 그런다음 모든 입력 뉴런들로부터의 기여 도들의 합산을 가지면, 즉 뉴런이 관련성의 일부를 상속받은 최상부 뉴런에 대한 전체 경향에 대해 뉴런이 발화 (fire)하면, 메시지 에 의해 전송된 관련성의 부호는 스위칭되게 된다. 수학식 의 선형 맵핑을 이 용한 예와 동일하게, 입력 뉴런은 그의 입력 부호에 의존하여 양 또는 음의 관련성을 상속받을 수 있다. 또한, 하나의 추가적인 속성이 여기서 나타난다. 관련성 분배를 위한 수식은 비-선형 및 심지어 미분가능하지 않거나 비-연속적인 뉴런 활성화들 ak에 적용가능하다. 알고리즘은, 이미 계산된 계층 l+1의 관련성들 로 시작할 것이다. 그런다음, 메시지들 은, 계층 l+1로부터의 모든 엘리먼트들 k 및 선행 계층 l로부 터의 엘리먼트들 i에 대해, 수학식 이 성립되도록 하는 방식으로 계산될 것이다. 그런다음, 정의 이 계 층 l의 모든 엘리먼트들에 대한 관련성 를 정의하는데 사용될 것이다. 테일러-타입 분해 일반적인 미분가능 예측기 f에 대해 에서와 같은 분해를 달성하기 위한 하나의 대안적인 접근법은 1차 테일 러 근사이다. 수학식 17"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 24, "content": "테일러 기점 x0의 선택은 이러한 셋업에서 자유 파라미터이다. 위에서 언급된 바와 같이, 분류의 경우에서, 본 발명은, f(x)＞0가 학습된 구조의 존재를 나타내고 f(x)＜0가 그 구조의 부재를 나타내므로, 포인트들의 세트 f(x0)=0에 의해 주어진 예측의 최대 불확실성의 상태에 관한 각각의 픽셀의 기여도를 발견하는데에 관심이 있다. 따라서, x0는 예측기 f의 루트이도록 선택되어야 한다. 예측의 테일러 근사의 정밀도를 위해, x0는, 더 높은 차 수의 테일러 근사들에 따라 테일러 잔여(Taylor residuum)를 최소화하기 위해 유클리드 기준(norm) 하에서 x에 가깝도록 선택되어야 한다. 최소 기준을 갖는 다수의 기존의 루트들 x0의 경우에서, 그들은 이들 모든 솔루션들 에 걸친 평균을 얻기 위해 평균 또는 적분될 수 있다. 위의 수학식은 다음으로 간략화된다: 수학식 18"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 25, "content": "픽셀-단위 분해는, 가까운 루트 포인트 x0가 발견될 필요가 있으므로 테일러 시리즈를 넘어 예측 포인트 x에 대 한 비-선형 의존성을 포함한다. 따라서, 전체 픽셀-단위 분해는, 루트 포인트 x0가 예측 포인트 x에 의존하므 로, 선형이 아니라 국부적으로 선형인 알고리즘이다. 수 개의 작업들은, 예측 포인트 x에서 편미분들을 사용하는 것에 기초했던 분류기 예측들의 시각화를 위해 민감 도 맵 [2, 18, 38]을 사용해왔다. 예측 포인트 x에서의 미분들에 기초한 민감도 맵들과 픽셀-단위 분해 접근법 사이에는 2개의 본질적인 차이들이 존재한다. 먼저, 예측 포인트 x에서의 함수값 f(x)와 동일한 포인트 x에서 의 미분 Df(x) 사이에 어떠한 직접적인 관계도 존재하지 않는다. 둘째로, 본 발명은, 예측 함수의 루트들의 세 트 f(x0)=0에 의해 주어지는 특정한 상태에 대한 분류기 예측을 설명하는데에 관심이 있다. 예측 포인트에서의 미분 Df(x)는 반드시, 유클리드 놈 하에서 가까운 루트를 포인팅할 필요는 없다. 그것은, 예측 f(x)와 동일한 부호를 여전히 가질 수 있고 따라서, 예측 함수의 루트 포인트들의 세트에 대한 차이를 설명하기 위해 오해할 수 있는 가장 근접한 국부적인 최적을 포인팅한다. 따라서, 예측 포인트 x에서의 미분들은 본 발명의 목적을 달성하기에 유용하지 않다. 도 7은, 국부 그라디언트들(상향 화살표들)과 예측의 차원-단위 분해(하향 화살표) 사이의 질적인 차이를 예시한다. 특히, 이러한 도면은, 예측 포인트 x에서의 그라디언트(여기서는 사각형에 의 해 표시됨)가 반드시 판단 경계 상의 가까운 포인트를 포인팅할 필요가 없다는 직관을 도시한다. 대신, 그것은, 국부적인 최적 또는 판단 경계 상의 먼 포인트를 포인팅한다. 이러한 예에서, 예측 포인트 x에서의 국 부 그라디언트로부터의 설명 벡터는 관련없는 방향으로 너무 큰 기여도를 갖는다. 다른 클래스의 가장 가까운 이웃들이 매우 상이한 각도에서 발견될 수 있다. 따라서, 예측 포인트 x에서의 국부 그라디언트는 함수값 f (x)에 대한 단일 차원들의 기여도들에 대한 양호한 설명이 아닐 수 있다. 좌측 이미지의 예측 포인트 및 우측 이미지의 테일러 루트 포인트에서의 국부 그라디언트들은 검정 화살표들에 의해 표시된다. 가장 인접한 루트 포인트 x0는 판단 경계 상의 삼각형으로서 도시된다. 우측 이미지에서 하향 화살표는 가장 인접한 루트 포인트 x0 주변에서 테일러 확장에 의한 f(x)의 근사를 시작화한다. 근사는, Df(x0)(우측 패널에서 회색 화살표)와 x- x0(우측 패널에서 파선) 사이의 차원-단위 곱을 표현하는 벡터로서 주어지며, 이것은 Df(x0)와 x-x0 사이의 외적 의 대각선과 동등하다.하나의 기술적인 어려움은 루트 포인트 x0를 발견하는 것이다. 연속하는 분류기들에 대해, 본 발명은, 라벨링되 지 않은 테스트 데이터, 또는 샘플링 접근법에서 훈련 데이터로부터 학습된 생성 모델에 의해 생성된 데이터를 사용하며, 그들의 예측이 반대 후보를 갖도록, 즉 f(x)f(x')＜0 이도록 예측 포인트 x와 후보 포인트들의 세트 {x'} 사이에서 라인 탐색을 수행할 수 있다. 라인 이 간격 교차에 의해 발견될 수 있는 f의 루트를 포함해야 한다는 것은 명백하다. 따라서, 각각의 후보 포인트 x'는 하나의 루트를 산출하며, 하나의 포인트는 테일러 잔여를 최소화하는 루트 포인트를 선택하거나 또는 낮은 테일러 잔류들을 갖는 루트 포 인트들의 서브세트에 걸친 평균을 사용할 수 있다. 하나의 계층 또는 계층들의 서브세트에 적용되는 경우 테일러-타입 분해는 함수가 매우 비선형인 경우에 관련성 전파의 근사 방식으로서 관측될 수 있음을 유의한다. 이것은 특히, 출력 계층의 관련성이 예측 함수 f(x)의 값 으로서 초기화되는 경우에 수학식 이 전파 수학식 를 근사적으로 충족하므로, 그것이 선행 계층의 함수 로서 출력 함수 f에 적용되는 경우에 성립된다. 테일러 근사와는 달리, 계층-단위 관련성 전파는 입력 포인트 이외의 제 2 포인트를 사용하도록 요구하지 않는다. 다계층 망들에 대한 픽셀-단위 분해라는 섹션 의 수식들은, 계층-단위 관련성 전파가 테일러 확장에 의해 근사할 필요성 없이 넓은 범위의 아키텍처에 대해 구현될 수 있다는 것을 시연할 것이다. 다계층 망들에 대한 픽셀-단위 분해 다계층 망들은 계층-단위 방식으로 조직화되는 상호연결된 뉴런들의 세트로서 일반적으로 구축된다. 그들은, 서로 결합되는 경우, 제 1 계층 뉴런들(입력)을 최종 계층 뉴런들(출력)에 맵핑하는 수학적인 함수를 정의한다. 본 발명은 xi에 의해 각각의 뉴런을 나타내며, 여기서, i는 뉴런에 대한 인덱스이다. 관례상, 본 발명은 망의 각각의 계층에 대해 상이한 인덱스들을 연관시킨다. 본 발명은, 주어진 계층의 모든 뉴런들에 걸친 합산을 에 의해 나타내고, 다른 계층의 모든 뉴런들에 걸친 합산을 에 의해 나타낸다. 본 발명은 픽셀 활성 화들에 대응하는 뉴런들을 x(d)에 의해 나타낸다(즉, 그 활성화들을 이용하여, 본 발명은 분류 판단의 분해를 획 득하려고 할 것임). 하나의 계층으로부터 다음의 계층으로의 일반적인 맵핑은 선형 투영, 그 다음에 비-선형 함수로 구성된다: 수학식 50"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 26, "content": "수학식 51"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 27, "content": "수학식 52"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 28, "content": "여기서, wij는 뉴런 xi를 뉴런 xj에 연결시키는 가중치이고, bj는 바이어스 항이며, g는 비-선형 활성화 함수이다 (사용된 명칭을 명확하게 하기 위해 도 8 참조). 다계층 망들은 이들 계층들 중 여러 개를 적층하며, 이들 각 각은 많은 수의 뉴런들로 구성된다. 일반적인 비-선형 함수들은 쌍곡선 탄젠트 g(t)=tanh(t) 또는 정류 함수 g(t)=max(0,t)이다. 신경망의 이러한 수식화는, 콘볼루션 및 합산-폴링이 선형 동작들인 경우, 단순한 다계층 퍼셉트론 [39] 또는 콘볼루션 신경망들 [25]과 같은 넓은 범위의 아키텍처들을 포함하기에 일반적으로 충분하다.테일러-타입 분해 망의 입력과 출력 사이의 맵핑을 구현하는 벡터값의 다변수 함수를 에 의해 나타내면, 분류 판단 의 제 1의 가능한 설명은 다음과 같이, 판단 함수 f의 인접한 루트 포인트 x0에서의 테일러 확장에 의해 획득될 수 있다: 수학식 53"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 29, "content": "픽셀-단위 분해를 위해 요구되는 미분 ∂f(x)/∂x(d)은 역전파 알고리즘 [39]를 사용하여 망 토폴로지를 재사용 함으로써 효율적으로 계산될 수 있다. 특히, 특정한 계층 j까지 미분들을 역전파하는 경우, 본 발명은, 체인 법칙을 사용하여 이전의 계층 i의 미분을 계산할 수 있다: 수학식 54"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 30, "content": "테일러-기반 분해의 요건은 x에 대한 분류 판단의 국부적인 설명을 지원하는 루트들 x0(즉, 분류 경계 상의 포인 트들)를 발견하는 것이다. 이들 루트들은 x의 이웃에서 국부 탐색에 의해 발견될 수 있다. 그러나, [43]에서 언급된 바와 같이, 이것은, 본래의 샘플 x와 인지적으로 동등하고 루트로서의 그의 선택이 정보없는(non- informative) 픽셀-단위 분해들을 생성할 입력 공간의 포인트들로 유도될 수 있다. 대안적으로, 루트 포인트들은 x에 의해 정의된 세그먼트 및 상이한 클래스의 그의 가장 가까운 이웃에 대한 라 인 탐색에 의해 발견될 수 있다. 이러한 솔루션은, 자연스러운 이미지들에 대한 경우와 같이 데이터 매니폴드 가 희박하게 거주되는 경우에 문제가 있다. 그러한 경우에서, x와 그의 가장 가까운 이웃 사이의 직선을 따르 는 것은 데이터 매니폴드로부터 크게 벗어나며 유사하게 불량한 픽셀-단위 분해들을 갖는 루트들 x0을 생성할 가 능성이 있다. 계층-단위 관련성 역전파 테일러-타입 분해에 대한 대안으로서, 역 전달에서 각각의 계층의 관련성들을 계산하는 것, 즉 상부 계층 관련 성들 의 함수로서 관련성들 을 표현하며, 입력(픽셀들)에 도달할 때까지 관련성들을 역전파하는 것 이 가능하다. 방법은 다음과 같이 작동한다: 분류 판단 f(x)에 대한 특정한 뉴런의 관련성 을 알 경우, 본 발명은 이 전의 계층들의 뉴런들로 전송되는 메시지들의 관점들에서 그러한 관련성의 분해를 획득하려고 할 것이다. 본 발명은 이들 메시지들을 로 지칭한다. 특히, 수학식들 및 에 의해 표현될 때, 다음과 같은 보존 속성 수학식 55 이 성립되어야 한다. 선형 뉴런 의 경우에서(여기서, 관련성은 Rj=f(x)임), 그러한 분해는 에 의해 즉시 주 어진다. 그러나, 일반적인 경우에서, 뉴런 활성화 xj는 zj의 비-선형 함수이다. 그럼에도, 쌍곡선 탄젠트 및 정류 함수에 대해(g=0를 충족시키는 2개의 간단한 단조 증가 함수들), 사전활성화들 zij는 Rj에 대한 각각의 뉴런 xi의 상대적인 기여도를 측정하기 위한 합리적인 방식을 여전히 제공한다. 관련성 분해의 제 1의 가능한 선택은 국부 및 전역 사전활성화들의 비율에 기초하며, 다음과 같이 주어진다: 수학식 56"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 31, "content": "이들 관련성들 은 특히 다음과 같이, 수학식 의 보존 속성들을 근사하도록 용이하게 나타낸다: 수학식 57"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 32, "content": "여기서, 승수는 바이어스 항에 의해 흡수(또는 주입)되는 관련성을 설명한다. 필요하다면, 잔류 바이어스 관련 성이 각각의 뉴런 xi 상으로 재분배될 수 있다. 수학식 의 전파 법칙의 결점은, 작은 값들 zj에 대해, 관련성들 이 제한되지 않는 값들을 취할 수 있 다는 것이다. 제한없음은 미리 정의된 안정기 ε≥0를 도입함으로써 극복될 수 있다: 수학식 58"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 33, "content": "그런다음, 보전 법칙은 다음이 된다: 수학식 59"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 34, "content": "여기서, 본 발명은 일부 추가적인 관련성이 안정기에 의해 흡수된다는 것을 관측할 수 있다. 특히, 안정기 ε가 매우 크게 되면, 관련성은 완전히 흡수된다.관련성을 누설하지 않는 대안적인 안정화 방법은 음 및 양의 사전활성화들을 별개로 처리하는 것으로 구성된다. 이라 하며, 여기서, \"-\" 및 \"+\"는 zij 및 bj의 음 및 양의 부분 을 나타낸다. 관련성 전파는 이제 다음과 같이 정의된다: 수학식 60"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 35, "content": "여기서, α＞0, β＜0, α+β=1이다. 예를 들어, α=2 β=-1에 대해, 보존 법칙은 다음과 같게 되며: 수학식 61"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 36, "content": "이 수학식은 수학식 과 유사한 형태를 갖는다. 이러한 대안적인 전파 방법은 또한, 상이한 팩터들 α 및 β를 선택함으로써 긍정적인 및 부정적인 증거의 중요도를 수동으로 제어하도록 허용한다. 다음에서, 더 일반적으로, 본 발명은, 뉴런 j로부터 뉴런 j의 상류 이웃인 뉴런 i로의 관련성 메시지들에 대해 Rij를 기입할 것이다. 계층화된 구조를 갖는 신경망의 특정한 경우에서, Rij는 를 기입하는 단축화된 방 식이며, 여기서, i 및 j는 각각 계층들 l 및 l+1의 뉴런들이다. 유사하게, 본 발명은 뉴런의 관련성 스코어에 대한 계층 인덱스를 드롭하며, 대신 Rj를 기입할 수 있다. 위의 재분배 수식들에 부가하여, 본 발명은 다음과 같이 대안적인 수식들을 정의할 수 있다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 37, "content": "여기서, n은 각각의 뉴런의 상류 이웃 뉴런들의 수이고, Rij는 각각의 뉴런 j로부터 상류 이웃 뉴런 i로 재분배 된 관련성 값이고, Rj는 뉴런 i의 하류 뉴런인 뉴런 j의 관련성이고, xi는 신경망의 적용 동안의 상류 이웃 뉴런 i의 활성화이고, wij는 상류 이웃 뉴런 i를 각각의 뉴런 j에 연결하는 가중치이고, wrj는 또한, 상류 이웃 뉴런 r을 각각의 뉴런 j에 연결하는 가중치이고, bj는 각각의 뉴런 j의 바이어스 항이며, h()는 스칼라 함수이다. 통상적으로, h()는 작은 ε를 부가함으로써 값을 제로로부터 멀리 유지하는 수치 안정기 항, 예를 들어, h(x)=x+εsign(x)이다.유사하게, 다른 대안들은 다음과 같다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 38, "content": "일단 관련성 전파에 대한 법칙이 선택되었다면, 하부 계층의 각각의 뉴런의 전체 관련성은, 수학식들 및 과 일치하여 모든 상위-계층 뉴런들로부터 들어오는 관련성을 합산함으로써 결정되며, 다음과 같다: 수학식 62"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 39, "content": "관련성은, 그것이 입력 픽셀들 x(d)에 도달할 때까지 하나의 계층으로부터 다른 계층으로 역전파되며, 여기서, 관련성들 은 판단 f(x)의 원하는 픽셀-단위 분해를 제공한다. 신경망들에 대한 완전한 계층-단위 관련성"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 40, "content": "전파 절차는 알고리즘 2에서 요약된다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 41, "content": "위의 수식들 및 은 특정한 구조를 충족시키는 계층들에 직접 적용가능하다. 본 발명이 선행 계층으로 부터의 활성화들 xi로부터의 입력들의 함수로서 모델링된 하나의 계층으로부터의 뉴런 활성화 xj를 갖는다고 가 정한다. 그런다음, 다음과 같도록 하는 함수 gi 및 함수들 hij가 존재하면, 계층-단위 관련성 전파가 직접 적용가능하다: 수학식 63"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 42, "content": "그러한 일반적인 경우에서, 수학식 으로부터의 가중항들 zij=xiwij은 hij(xi)의 함수로 그에 따라 대체되어야 한다. 본 발명은 다시, 최대 풀링조차도 일반화된 수단의 제한으로서 이러한 구조로 맞춰진다는 것을 언급하며, 예를 들어, 수학식 를 참고한다. 국부 재정규화 [26, 36]과 같은 더 높은 정도의 비-선형도를 갖는 구조들에 대해, 뉴런 활성화 xj에 적용되는 테일러 근사는, 수학식 에서 주어진 바와 같이 구조에 대 한 근사를 달성하기 위해 다시 사용될 수 있다. 최종적으로, 계층-단위 관련성 전파가 테일러 시리즈 또는 편미분들과는 상이하다는 것이 이러한 섹션에서 설정 된 수식들로부터 관측될 수 있다. 테일러 시리즈와는 달리, 그것은 입력 이미지 이외의 제 2 포인트를 요구하 지 않는다. 테일러 시리즈의 계층-단위 적용은 계층-단위 관련성 전파의 근사 버전을 달성하기 위한 일반적인 방식으로서 해석될 수 있다. 유사하게, 미분들에 의존하는 임의의 방법들과는 대조적으로, 뉴런 활성화들의 미 분가능성 또는 평활도 속성들은, 계층-단위 관련성 전파를 충족시키는 수식들을 정의할 수 있기 위한 필수 요건 이 아니다. 그러한 의미에서, 그것은 더 일반적인 원리이다. 일반화된 관점 위의 수식들 A5 내지 A8이 일반화될 수 있다. 본 발명이 계층 l+1의 모든 뉴런들 k에 대한 관련성 스코어들 을 이미 갖는다고 가정한다. 먼저, 기본적 인 개념은, 다음의 수학식 이 충족되도록 메시지들 을 생성하고,"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 43, "content": "그런다음, 계층 l의 모든 뉴런들 i에 대한 관련성들 을 이들 메시지들로부터 계산한다는 것이다. 위에서 설명된 바와 같이, 수학식들 A5 내지 A8은 메시지들 을 어떻게 계산하는지에 대한 예들이다. 위에서 설 명된 접근법에서, 다음의 수학식"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 44, "content": "은 계층 l의 모든 뉴런들 i에 대한 관련성들 을 계산하기 위해 사용되었다. 제 1 일반화는 수학식 에 대해 행해질 수 있다: 모든 메시지들 이 주어지면, 본 발명은, 본 발명이 로서 나타내고 입력으로서 메시지들 을 취하는 관련성 메시지들 의 합산 이외의 다른 함수를 사용함으로써 계층 l의 모든 뉴런들 i에 대한 관련성들 을 계산할 수 있다: 뉴런 i의 관련성은 다음과 같이 함수 에 의해 계산되며:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 45, "content": "이 수식은 그의 인수들 각각에서 단조 증가해야 하며, 수학식 의 합산의 일반화로서 관측될 수 있다. 상류 및 하류 뉴런들의 용어를 사용하는 경우, 본 발명은 다음과 같이 기입할 수 있다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 46, "content": "다소 덜 일반적이지만 이러한 일반화의 가능한 비번하게 사용되는 변형은 다음과 같다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 47, "content": "m2 및 m3는 하나의 변수의 단조 증가 함수이다. 예를 들어, 다음과 같다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 48, "content": "여기서, c는 관련성 보존이 유지되도록 선택되는 상수이다. 이러한 예는 n의 큰 값들에 대한 큰 항들에 더 많 은 가중치를 부여한다. 제 2 일반화는, 이 항상 의 배수인 항인 수식들 A5 내지 A8을 고려하는 경우 수학식 에 관해 행해질 수 있다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 49, "content": "여기서, q(i)는 다음과 같도록 하는 가중 함수이다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 50, "content": "그 수학식은 수학식 이 여전히 성립된다는 것을 보장한다. 계층 l+1의 뉴런들 k에 대한 뉴런 관련성 스코어들이 계층 l+2의 뉴런들 p에 대한 뉴런 관련성 스코어들로부터 이전에 계산되었으므로, 본 발명은 또한, 위의 수학식을 다음과 같이 재기입할 수 있다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 51, "content": "따라서, 본 발명은 일반화의 제 1 레벨에 도달한다: 일반화 1 뉴런들의 세트 {k}에 대한 뉴런 관련성 스코어들 Rk의 세트가 주어지면, 본 발명은, 이기 위 해 메시지 가중 함수 가 존재하도록 뉴런들의 세트 {k}에 대한 상류 뉴런들인 뉴런들의 세트 {i}에 대한 관 련성 메시지들을 계산한다. 관련성 메시지들 의 세트가 주어지면, 본 발명은 다음과 같도록 그의 인수들에서 단조 증가하는 함수 에 의해 뉴런 i의 관련성 스코어를 계산한다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 52, "content": "특히, 관련성 메시지 항들만을 사용하는 경우 그리고 본 발명이 뉴런 i의 하류 뉴런들인 모든 뉴런들 k에 대한 메시지들 을 갖는다고 가정하면, 그런다음, 본 발명은 다음을 계산할 수 있다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 53, "content": "일반화 1의 종료 부가적으로, 본 발명은, 관련성 보존 속성이 충족되는 것을 요구할 수 있다. 이것은, 예를 들어, 망이 계층화 되면, 함수 가 엘리먼트들에 걸친 합산이고 다음의 수식이 성립되는 경우이다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 54, "content": "수치 안정성의 요건들은, 관련성 보존 속성이 오직 근사적으로만 충족되기 위해, 예를 들어, 관련성들의 계층- 단위 합산이 5%의 편차들까지 동일하기 위해 수치 안정기 항들을 포함하도록 본 발명에게 요구할 수 있음을 유 의한다. 수치 안정기에 대한 일 예로서 수식들 A5 및 A6에서 사용되는 함수 h(z)=z+εsign(z)를 참조한다. 일반화 2 일부 허용도까지의 관련성 보존 속성의 요건은 다음과 같은 조건들에 의해 표현된다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 55, "content": "상류 및 하류 용어의 관점들에서, 이것은 다음과 같을 것이다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 56, "content": "이것은 또한, 2개의 상이한 관점들로 재수식화될 수 있다. 제 1 관점에서, 본 발명은, 신경망에 대한 입력들로 서 기능하는 입력 아이템들의 세트 내의 각각의 아이템에 대한 출력 및 관련성들 Ri로부터의 초기 관련성 R만을 고려한다. 그런다음, 본 발명은, 신경망의 중간 계층들에서 관련성들의 합산을 특정하지 않으면서 이들 항들에 서 위의 요건을 수식화할 수 있다. 제 2 관점에서, 본 발명은 뉴런들의 관련성 스코어들 대신, 입력되는 뉴런들 사이의 관련성 메시지들을 고려하 고, 하나의 고정 뉴런을 남긴다. 본 발명은, 자신의 모든 하류 뉴런들로부터 특정한 뉴런 j를 입력하는 메시지들의 합산이 뉴런 j로부터 자신의 상류 뉴런들로 전송되는 메시지들의 합산과 근사적으로, 다시 예시적으로는 5%의 허용도로 동등하는 것을 요구 한다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 57, "content": "일반화 2의 종료 본 발명이 중간 항에 대해, 자신의 입력에만 의존하는 단조 함수 ζ, f 또는 ξ를 고려하는 경우, 이들 모든 3 개의 관점들이 추가적으로 일반화될 수 있다. 일반화 2B 관점 1: 뉴런들의 관련성 스코어들 Rk"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 58, "content": "관점 2: 출력 뉴런들의 관련성 스코어 R 및 입력 아이템들의 세트 내의 아이템들에 대한 관련성 스코어들"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 59, "content": "관점 3: 뉴런 j의 상류 및 하류 뉴런 이웃들에 대한 관련성 스코어들 Rjk"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 60, "content": "일반화 2B의 종료 이제, 일반화의 제 3 레벨을 고려한다. 수학식들 A5 내지 A8을 조사하는 경우, 본 발명은 일반화의 위의 레벨들에 대한 일부 부가적인 요건들을 식별할 수 있다. 먼저, 수학식들 A5 내지 A8의 모든 q(i)는 가중된 활성화들 zij에 의존한다. 수식들 A5 대 A6와 A7 대 A8 사이의 차이는 단지 가중된 활성화들 zij의 정의에 놓여있다.A5 및 A7에서, 가중된 활성화는 zij=xiwij이다. A6 및 A8에서, 가중된 활성화는 이며, 여기 서, bj는 뉴런 j의 바이어스이고, l은 뉴런 j에 대한 상류 뉴런들의 수이다. 가중된 활성화의 정의의 이러한 차이는 바이어스 항의 2개의 상이한 관점들로부터 유래한다. 제 1 수학식 zij=xiwij에서, 바이어스 항은, bj의 값과 동일한 값을 갖는 일정한 출력을 출력하는 별개의 뉴런에 의해 모델링된다. 바이어스가 별개의 뉴런에 의 해 생성되므로, 그것은 가중된 활성화들의 계산들을 입력하지 않는다. 제 2 관점에서, 바이어스는, 뉴런 j에 대한 각각의 입력에 부가되는 부가적인 항이며, 즉 이것은 가중된 활성화 의 제 2 정의에서, 부가된 항 을 설명한다. 그러므로 실제로, 본 발명은 가중된 활성화 zij를 정의하기 위한 2개의 상이한 방식들을 이용하여 2개의 수학식 들 A5 및 A7로부터 도출된 2개의 기본 수식들만을 갖는다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 61, "content": "여기서, 는, zij의 정의가 바이어스를 포함하지 않으면, 즉 zij가 zij=xiwij로서 정의되면 1이고, 그렇지 않으 면 제로이다. 여기서, 본 발명은, 단조 증가 함수 에 의한 뉴런 관련성 스코어 Rj의 일반적인 정의 대신 다음을 암묵적으로 사용했다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 62, "content": "수학식들 A5* 및 A7*에 의해 주어진 이들 특수한 경우들에서, 본 발명은 다음을 갖는다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 63, "content": "및"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 64, "content": "이러한 조사는 일반화의 제 3 레벨로 유도된다. 일반화 3 함수 q(i)는 가중된 활성화들 zij에 의존하며, 여기서, 가중된 활성화는 뉴런 활성화들 xi, 연결 가중치들 wij, 및 바이어스 항들 bj의 함수이다. zij=s(xi, wij, bj). 특수한 경우들로서, 다음이 있다: 일반화 3의 종료 최종적으로, 일반화의 제 4 레벨이 존재한다. 수학식들 A5* 및 A7*를 조사할 경우, 암묵적인 속성, 즉 가중된 활성화들 zij의 순서화에 대한 q(i)의 의존성이 관측될 수 있다. 직관적으로, 2개의 뉴런들 i1 및 i2에 대해, 가중된 활성화 중 하나가 다른 것보다 크면, 즉 이면, 뉴런 i2는 또한, 뉴런 i1보다 뉴런 j로부터 더 큰 몫을 수신해야 한다. 그러나, 뉴런 관련성 스코어들 Rj, 가중된 활성화들 zij 및 가중치들 q(i)가 상이한 부호들을 가질 수 있고, 이는 결과적인 관련성 메시지 에서 기호 플립핑(flipping)들을 유도하기 때문에, 이러한 직관적인 개념을 정의하는데에 주의를 기울려야 한다. 이것은, 가 간 단히 요청될 수 없기 때문이다. 반례를 제공하기 위해, 수식 A5*에서, 이지만 이면, 그것은 다음을 따른다: . 그러나, 이러한 경우에 성립 되는 것은, 항 이 q(i1) 및 (i2)에 대해 동일하기 때문에, 이다. 수식들 A5* 및 A7*을 조사하면, 이들 수식들에 의해 충족되는 순서화 속성들의 세트가 있을 수 있다. 순서화 속성들을 정의하기 위한 하나의 방식은, 가중된 활성화들 zij의 절대값들 및 메시지 가중 함수 의 절대값들의 일반화를 고려하는 것이다. 수식 A5*에 대해, 다음의 순서화 속성은 다음을 성립한다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 65, "content": "수식 A7*에 대해, 약간 상이한 순서화 속성이 성립된다. 다음을 고려한다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 66, "content": "및"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 67, "content": "그런다음, 함수에 대해, 다음과 같다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 68, "content": "다음의 순서화 속성은 다음을 성립한다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 69, "content": "여기서, 함수 가 α, β에 대한 상이한 값들을 갖는 수식 A5*에 대한 순서화 속성을 또한 포함하도록 α=1, β=1에 관해 임을 유의한다. 위에서 주어진 함수 g(.)의 추가적인 일반화는, 제로에서 자신의 최소값을 가지며 간격(-∞,0) 상에서 단조 감 소하고 간격 (0,+∞) 상에서는 단조 증가하는 함수를 유도한다. 따라서, 본 발명은 다음에 도달한다. 일반화 4 메시지 함수 는, 뉴런 j의 상류 이웃 뉴런들인 모든 i1 및 i2에 대해, 다음과 같이 순서화 속성을 충족하도 록 요구된다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 70, "content": "제로에서 자신의 최소값을 가지며 간격(-∞,0) 상에서 단조 감소하고 간격 (0,+∞) 상에서는 단조 증가하는 함 수 에 대해 가 참으로 유지된다. 특히, 함수 에 대한 하나의 선택은 α≥0, β≥0에 관해 이다. 일반화 4의 종료 순서화 속성들을 정의하기 위한 다른 방식은 Rj＞0 일 때 그 경우로 자신을 제약하는 것이다. 이것은, 음의 뉴 런 관련성들을 전파하는데에 관심없는 경우에 의미가 있다. 이를 이해하기 위해, 신경망에 의해 행해진 예측이 구조의 존재에 관해 확실한 경우(이는, 뉴런의 출력이 입력으로서의 아이템들의 세트에 대해 매우 긍정적인 스 코어들을 갖는다는 것을 암시함), 아이템들의 세트 내의 단일 아이템들에 대한 예측들을 행하는데에 일반적으로 관심이 있다는 것이 고려되어야 한다. 뉴런의 출력이 매우 긍정적인 스코어들을 가지면, 대부분의 뉴런들이 신 경망의 매우 긍정적인 예측을 지원하고 있기 때문에, 대부분의 뉴런 관련성들도 긍정적이라는 것이 예상될 수 있으며, 따라서, 실제로 부정적인 관련성들을 갖는 뉴런들의 소량 부분을 무시할 수 있다. 다른 순서화 속성을 추론하기 위해, 이면, 본 발명은 또한, h(t)=t+εsign(t)에 대해 을 갖는다. 특히, 수식 A5*를 고려하는 경우, 다음의 순서화 속성이 성립된다: 이면, 뉴런 j의 상류 뉴런들인 모든 i1 및 i2에 대해, 본 발명은 을 갖는다. 이면, 뉴런 j의 상류 뉴런들인 모든 i1 및 i2에 대해, 본 발명은 을 갖는다. 이러한 속성은 수식 A7*에 대해서는 성립되지 않는다. 일반화 5 메시지 함수 는, 및 이면, 뉴런 j의 상류 뉴런들인 모든 i1 및 i2에 대해, 본 발명 이 를 갖는 순서화 속성을 충족시키도록 요구된다. 일반화 5의 종료 경우 Rj＞0에 대해 유용할 수 있는 다른 순서화 속성은 다음일 것이다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 71, "content": "이것은 수식 A7*에 대해 성립된다. 즉, 본 발명이 동일한 부호를 갖는 가중된 활성화들만을 비교하면, 둘 모두의 수식들 A5* 및 A7*에 대해 또한 성립되는 추가적인 순서화 속성이 존재한다: 메시지 함수 는, 및 이면 이라는 것이 참으로 유지되는 순서화 속성을 충족하도록 요구된다.이것은, 함수 를 절대값으로 대체하기 위한 방식이다. 수식 A5*이 더 협소한 순서화 속성, 즉 다음을 충족시킴을 유의한다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 72, "content": "본 발명이 zij=xiwij 또는 로 플러그인(plug in)할 경우 이들 모든 수식들이 성립하므로, 본 발명은, 본 발명이 사용한 가중된 활성화들 zij의 정의가 어떤 것인지에 의존하여 위의 순서화 속성들 각각으로 부터 2개의 버전들을 생성할 수 있다. 순서화 속성들을 정의하기 위한 다른 가능성들이 존재함을 유의한다. 예를 들어, 다음의 8개의 조건들은 또한, 관련성 메시지들의 관점들에서 표현되는 의미있는 순서화 속성들을 산 출할 것이다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 73, "content": "또는"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 74, "content": "또는"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 75, "content": "또는"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 76, "content": "또는"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 77, "content": "또는"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 78, "content": "또는"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 79, "content": "또는"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 80, "content": "망 입력들의 함수로서 망 출력 함수에 테일러 확장을 적용하는 것 대신, 테일러 확장은 또한, 단일 뉴런의 관련 성 스코어를 자신의 상류 이웃들에 재분배하도록 적용될 수 있다. 이것은, 뉴런들의 다른 세트에 대한 테일러 분배에 따른 관련성 분배와 뉴런들의 하나의 세트에 대한 위의 제시된 전략들을 결합시키도록 허용한다. 테일러 확장은 다음의 방식으로 사용될 수 있다: 가 상류 이웃 뉴런들 i1,…,in 의 입력들 의 함수로서의 뉴런 j의 뉴런 활성화 함수라고 가정한다. 그런다음, 가 포인트 주변의 입력들 에 대한 xj의 테일러 확장이라고 한다. 그런다음, 본 발 명은, 다음과 같이 셋팅함으로써 위의 수식들과 함께 테일러 확장을 사용할 수 있다: . 다양한 부가적인 설명들 따라서, 깊은 신경망(deep neural network: DNN)들과 같은 최신 분류기들이 다음과 같이 작동한다. 1) 망 구조(예를 들어, 계층들의 수, 유닛들 등)가 사람에 의해 설계된다. 2) 망 파라미터들(가중치들)은 잠재적으로 수백만의 라벨링된(및 라벨링되지 않은) 데이터 샘플들, 예를 들어, 이미지들을 사용하여 훈련/최적화된다. 일부 미리-훈련된 망들이 웹 상에서 이용가능함을 유의한다. 3) 망은, 새로운 이미지에 적용될 수 있으며, 예를 들어, 특정한 클래스, 예컨대 '상어를 포함하는 이미지들', '뉴스 기사들인 텍스트 문서' 또는 '신용도가 부족한 사람들'의 클래스에 속하는 것으로 이미지를 분류할 수 있 다. 4) 망이 매우 비-선형이고 매우 복잡하므로, 이러한 특정한 이미지가 왜 '상어'로 분류되는지를 이해하는 것은 어렵다. 따라서, 망은 블랙 박스로서 작동한다(도 4 참조). 5) 제시된 실시예들은 분류기가 자신의 판단에 왜 도달했는지를 설명할 수 있으며, 즉 본 발명은 (예를 들어, 픽셀들의 관점들에서) 중요 정보가 로케이팅되는 장소를 시각화할 수 있다. 추상적으로 말하자면, 본 발명은, 큰 스케일(예를 들어, 전체 이미지, 전체 텍스트 문서)로 계산되었던 분류 판단 더 작은 스케일들(예를 들어, 개별 이미지들, 개별 작업들)로 분해할 수 있다. 6) DNN들이 이미지들에 대해 훈련될 뿐만 아니라 실제로 모든 각각의 타입의 데이터, 예를 들어, 시간 시리즈, 단어들, 물리 측정들 등에 적용될 수 있으므로, 설명된 실시예들의 원리들은 많은 상이한 시나리오들에 적용가 능하다. 도 5 내지 도 10에 관해 앞서 제시된 설명은 다음에서, 도 4의 관련성 스코어 할당 장치의 설명에 대한 일부 부 가적인 언급들을 제공하기 위해 사용될 것이다. 장치가 단지 재분배만을 수행하도록 구성될 수 있다는 것은 이미 위에서 설명되었다. 그러나, 부가적으로, 장치는 또한, 인공 신경망의 세트에 대한 실 제 적용을 수행하도록 구성될 수 있다. 따라서, 장치는 이러한 대안에 대해, 기준 부호가 재사용될 수 있는 신경망 프로세서 및 기준 부호가 재사용될 수 있는 재분배 프로세서를 포함하는 것으로 고려될 수 있 다. 어느 경우든, 장치는, 예를 들어, 저장부 또는 메모리를 포함할 수 있다. 그러나, 흥미롭게도, 분류 프로세스와 같은 예측 프로세스 상에서 한편으로는 망을 수반하는 계층과 역방향 전파 프로세스가 망을 통해 역으로 횡단하는 곳까지의 층 사이에 갭이 존재할 수 있음을 유의해야 한다. 예를 들어, 도 1a- c 및 도 2a-c의 경우에서, 예측 프로세스에서 수반된 순방향 전파가 역방향 전파 프로세스와 동일한 계 층들의 망에 걸쳐있거나 또는 그 망을 포함한다는 것이 예시되었다. 즉, 순방향 전파 프로세스 또는 망은 세트에 직접 적용되었고, 역방향 전파는 세트에 대한 관련성 스코어들로 직접 종결되었다. 도 1b 및 도 2b에서, 예를 들어, 예측 프로세스 내에서, 이러한 세트는 특성 추출 프로세스 에 의해 미리-채워졌으며, 예를 들어, 본래의 이미지와 오버레이되는 방식으로, 증가된 관련성 스코어 의 관련성 부분들을 강조하기 위해, 이러한 특성 추출의 역, 즉 은 역 전파 프로세스를 연장하고 공간(픽셀) 도메인에서 관련 부분들의 강조를 수행하기 위해 사용되었다. 그러나, 위에 기재된 설명은 또한, 특성 추출 프로세스가 대안적으로는, 인공 신경망의 하나 또는 그 초과의 부가적인 계층들, 즉 순방향 전파 방향에서 망의 실제(훈련된) 부분에 선행하는 뉴런들의 층들, 즉 층들 또는 부분을 사용하여 변환 또는 설명될 수 있다는 것을 나타내었다. 특성 추출의 작업을 단지 미러링하는 이들 계층들은 실제로는 관 련성 할당 프로세스에서 역방향 전파로 횡단될 필요는 없다. 그러나, 상위 계층 측의 부분의 이들 부가적 인 (변환된) 층들은 예측 프로세스 동안 순방향 전파 프로세스에서, 즉 망의 실제(훈련된) 부분을 횡단하기전에 시작하는 그의 말단에서 횡단될 수 있다. 그에 의해, 관련성 스코어들 Ri는 픽셀들보다는 특성 샘플들에 대해 획득될 것이다. 달리 말하면, 관련성은 입력 변수들의 관점들에서 (예를 들어, 이미지들의 경우에서는 각 각의 픽셀의 레드, 그린, 및 블루 컴포넌트들 또는 텍스트들의 경우에는 각각의 단어와 연관된 벡터의 컴포넌트 들) 뿐만 아니라 이들 아이템들의 비선형 변환의 관점들에서 (망의 특정한 계층의 뉴런들) 분해될 수 있다. 따 라서, 본 발명은, 특정한 중간 계층에서 관련성 역 투영을 중지하는 것을 원할 수 있다. 자연적으로, 한편으로 는 순방향 전파의 시작 포인트와 다른 한편으로는 역방향 전파의 종결-포인트 사이의 이러한 갭의 예는 또 한 다른 종류의 데이터, 즉 이미지들 이외의 데이터, 이를테면 예컨대, 오디오 신호들, 텍스트들에 적용될 수 있다. 망 출력 및 세트의 아이템들의 종류에 대한 부가적인 유의점들이 가치있는 것으로 보인다. 망 출 력에 관해, 그것이 스칼라 또는 벡터일 수 있다는 것이 또한 위에서 서술되었으며, 스칼라 또는 벡터의 컴 포넌트들은, 예를 들어, 실수값들이다. 그로부터 도출되는 관련성 값 R은, 스칼라 또는 벡터의 컴포넌트들 중 하나로부터 각각 도출되는 실수값일 수 있다. \"아이템들\"에 관해, 위의 예들은 그것이 유사하게 스칼라들 또는 벡터들일 수 있다는 것을 이미 충분히 명확하게 했었다. 한편으로는 도 1a 및 도 2a 및 다른 한편으로는 도 1c 및 도 2c의 병치가 이것을 명확하게 한다. 도 1c 및 도 2c에 도시된 바와 같은 컬러화된 화상들의 픽셀 들의 경우에서, 픽셀값들은 벡터들, 즉 예시적으로는 여기에서, RGB, CMYK 등과 같은 3개(또는 그 초과)의 스칼 라 컬러 컴포넌트들에 대응하는 3개 또는 심지어 그 초과의 컴포넌트들의 벡터들이다. 세트의 아이템들 은 픽셀의 스칼라 컴포넌트들이다. 아이템들의 세트 상으로의 관련성 값의 재분배는 각각의 아이템, 즉 각 각의 픽셀에 대한 각각의 컴포넌트에 대한 관련성 값 Ri를 초래한다. 각각의 픽셀에 대한 하나의 스칼라 관련성 값을 도출하기 위해, 각각의 픽셀의 모든 컴포넌트들의 관련성 값들은 그 픽셀에 대한 그러한 일반적인 관련성 값을 획득하기 위해 합산될 수 있다. 이것은 도 2c에서 로 도시되었다. 유사한 측정들이 텍스트들의 경우 들에서 발생할 수 있다. 따라서, 입력 변수들의 관점들에서의 관련성 분해는, 관련성 분해의 용이한 시각화 및 해석을 허용하는 방식으로 재그룹화될 수 있다. 예를 들어, 픽셀 도메인의 히트맵으로서 관련성을 시각화하기 위해, 본 발명은 도 2c에 관해 설명된 바와 같이, 각각의 픽셀에 대해 자신의 레드, 그린 및 블루 컴포넌트들에 연관된 관련성을 합산할 수 있다. 유사하게, 텍스트 분석에 대하여, 히트맵핑된 텍스트로서의 문서의 관련성 분해를 시각화하기 위해, 본 발명은 각각의 단어에 대해, 대응하는 벡터의 각각의 컴포넌트에 연관된 관련성을 합산할 수 있다. 다른 예들이 또한 평가될 수 있다. 그러나, 안정화 함수 (수학식들 A5* 및 A7* 참조)에 의해 부과되는 바 와 같은 환경들은, 예를 들어, 일반화 2B로부터의 전술된 함수들 f, ξ 및 ζ에 의해 설명된 관련성 속성이, 예 를 들어, 아이템들의 각각의 세트에 대해 충족되지 않을 수 있도록 하는 관련성 \"누설\"을 초래할 수 있다. 예를 들어, 그것은 단지, 최대 망 출력의 적어도 75%에 도달하는 망 출력을 초래하는 세트들 또는 아이템들에 대해서만 충족될 수 있다. 예를 들어, 인공 신경망에 의해 수행된 예측은 특정한 화상이 \"고양이\"를 나타내는 지이고, 그러다음, 그 화상이 고양이를 나타내는 75%보다 더 높은 값을 망 출력에서의 예측이 초래하는 이미지 들에 대한 예측들은 역방향 전파에 종속되는 경우, f와 관련된 (그들 전체 또는 적어도 99% 초과에 대한) 조건 을 충족시키는 픽셀들에 대한 관련성 스코어들을 초래할 수 있는 반면, 다른 화상들은 그렇지 않거나 확실하지 않을 수 있다고 가정한다. 다른 관점으로부터, 분배 함수는, 그것이 \"의미있는\" 역방향 전파된 관련성 스코어들을 초래하도록 유리하게 선 택되어야 한다. 이를 위해, 분배 함수는, 관련성 보존 속성에 부가적으로 또는 대안적으로 일부 \"순서화\" 속성 을 준수할 수 있다. 즉, 위에서 논의된 관련성 보존 속성을 준수하지 않더라도, 분배 함수는 의미있는 역으로 전파된 관련성 스코어들을 초래할 수 있다. 특히, 각각의 뉴런 j에 대해, 얼마나 많은 관련성 Rij가 각각의 뉴 런 j로부터 상류 이웃 뉴런 i까지 재분배되는지를 산출하는 분배 함수는 다음과 같을 수 있으며:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 81, "content": "여기서, 각각의 뉴런 j의 하류 이웃들의 수인 K를 갖는 는 그의 모든 컴포넌트들에 대한 단조 증가 함 수이고, 각각의 뉴런 j의 사전에 재분배된 관련성 값을 산출하고, q(i)는 각각의 뉴런 j의 상류 이웃 뉴런들 i의 활성화들 xi에 의존하는 순서화 속성을 충족시키는 함수이고, I 는 상류 이웃 뉴런들 i의 수이며, 가중치 wij는 상류 이웃 뉴런 i를 각각의 뉴런 j에 연결시키고, 존재하는 경우, 각각의 뉴런 j의 바이어스 항 bj는 부재하면 제로인 것으로 가정되며, 여기서, 순서화 속성은 일반화 4 및 일반화 5에서 그리고 그 주변에서 주어진 것들 중 하나이다. 도 4는 관련성 스코어 할당 프로세스의 다이어그램을 동시에 나타냈고, (10 및 52)와 같이 그 내에 도시된 엘리 먼트들은 그러한 방법/프로세스 동안 수행되는 프로세스 단계들을 표현하며, 여기서, (30 및 38)과 같은 단계들 은 프로세스 동안 부가적으로 수행되는 선택적인 단계들 또는 작업들을 표현함을 또한 유의해야 한다. 대안적 으로, 장치는 작업들(30 및 38 또는 30)을 부가적으로 수행하도록 구성될 수 있다. 예를 들어, 이들 작업 들 모두는 컴퓨터 프로그램의 코드의 상이한 부분들을 표현할 수 있으며, 그 코드에 기초하여 프로세스 또는 장 치가 구현된다. 추가적으로, 위의 설명은 다음에서, 본 출원의 범위에 관한 오해를 피하기 위해 일부 상이한 용어를 사용하여 설명될 것이다. 특히, 위의 설명은 샘플에 대해 행해진 예측의 분석을 나타내며, 여기서, \"샘플\"은 아이템들의 세트이다. 예측은, 아이템들의 세트에 기초하여 망 출력을 도출하는 프로세스이고, 입력으로서 샘플을 취하는 맵핑에 의해 수행된다. 예측은 샘플에 대해 전체로서 행해지며, 벡터-값 또는 실수-값 출력 또는 벡터-값 또는 실수- 값 출력, 즉 망 출력으로 변환될 수 있는 출력을 초래한다. 예측 맵핑은 신경망을 통한 순방향 전파를 수반한다. 그것은 다음의 방식으로 분해될 수 있다: 그것은 입력들을 취하고 입력들에 함수, 즉 신경 함수를 적용함으로써 출력을 계산하는 엘리먼트로 구성된다. 적어도 하나의 엘리먼트는 입력으로서 샘플, 즉 세트의 하나의 아이템을 갖는다. 모델은, 각각의 엘리먼트가 입력으로서 샘플의 최대 하나의 아이템을 취 하도록 일반화의 손실없이 행해진다. 적어도 하나의 엘리먼트는 입력으로서 다른 엘리먼트들의 출력들을 취한다. 이들은 위에서 설명된 바와 같이, 엘리먼트에 의존하는 값과 그의 입력을 곱함으로써 가중될 수 있다. 가중치들 중 적어도 하나는 비-제로이다. 적어도 하나의 엘리먼트의 출력은 샘플의 예측을 행하기 위해 사용된다. 샘플 아이템으로부터 모델 내의 예측들로의 연결이 존재한다. 다르게 말하면, 위의 서술된(계층화된) 역방향 전파는, 아이템들의 세트에 대한 예측이 이미 수행되었다는 가정 으로 수행된다. 프로세스는, 예측에 의해, 즉 망 출력에 기초하여 직접 계산되었던 그 모든 엘리먼트들의 관련 성의 초기화로 시작한다. 이러한 출력이 실수-값이면, 관련성 R은 계산되었던 출력 뉴런을 형성하고, 각각의 예측 망 출력은 모델의 예측값의 사용에 의해 초기화된다. 출력이 벡터값이면, 관련성 R은 모든 출력 뉴런들에 대해 셋팅될 수 있고, 하나의 출력 뉴런 경우에 대한 실수값 출력들의 경우에 대해 설명된 초기화를 사용함으로 써 그리고 나머지 출력 뉴런들에 대해 관련성을 제로로 셋팅함으로써 초기화될 수 있다. 초기화 이후, 다음의 2개의 수식들에는 교대의 방식으로 계산이 가해진다. 특히, 관련성 Rk가 이미 계산되었던 각각의 엘리먼트(뉴런) k에 대해, 입력들을 엘리먼트 k에 제공하는 모든 엘 리먼트들 i에 대한 메시지들 은 다음이 되도록 계산된다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 82, "content": "대안적으로, 그들이 수학식 A1을 충족하도록 하는 방식으로, 수학식 A2만이 사용되거나 메시지들 이 단지 암묵적으로 계산될 수 있다. 신경망이 사이클들을 포함하는 경우, 즉 신경망이 반복적이고 시간-종속적인 상태를 갖는 경우, 그의 구조는, 본 발명이 위에서 설명된 바와 동일한 절차를 적용할 수 있는 피드포워드 맵핑을 초래하는 시간으로 전개 (unfold)될 수 있다. 시간으로 전개됨으로써, 본 발명은 각각의 시간 단계에서 망의 상태를 모델링하는 하나의 계층을 갖는다는 것을 의미한다.메시지들 중 적어도 하나는, (일부 단계에서, 그의 계산을 위해 필요한 관련성 Rk가 계산되었기 때문에, 그 메시지가 계산될 수 있더라도) 입력 엘리먼트 i의 관련성 Ri를 계산하기 전에 랜덤값으로 대체될 수 있다. 메시지들 중 적어도 하나는, (일부 단계에서, 그의 계산을 위해 필요한 관련성 Rk가 계산되었기 때문에, 그 메시지가 계산될 수 있더라도) 입력 엘리먼트 i의 관련성 Ri를 계산하기 전에 상수값으로 대체될 수 있다. 다음으로, 본 발명은 계층-단위 관련성 전파 원리에 대한 더 기술적인 관점을 제공한다. 각각의 계층은 인덱스 를 할당받아야 한다. 제 1 계층은 인덱스 1을 갖고, 최종 계층은 가장 높은 인덱스를 갖는다. 세트 내의 각각의 아이템에 대한 스코어는 다음의 방식으로 계산될 수 있다: 본 발명은, 본 발명이 아이템들의 순서화된 콜렉션에 대한 예측을 이미 갖는다고 가정한다. ● 먼저, 아래에서 설명되는 바와 같이 출력 계층인 최종 계층의 관련성을 초기화한다: ● 출력이 실수값이면, 모델의 예측값으로서 최종 계층의 단일 엘리먼트에 대한 관련성을 초기화한다. ● 출력이 벡터값이면, 출력 계층의 적어도 하나의 엘리먼트에 대한 실수값 출력들의 경우에 대해 설명된 초기 화를 사용하는 것 및 나머지 엘리먼트들에 대해서는 관련성을 제로로 셋팅하는 것 중 어느 하나에 의해 최종 계 층의 모든 엘리먼트들에 대한 관련성을 초기화한다. ● 둘째로, 하나의 계층 인덱스로부터 상류 계층까지 계층들에 걸쳐 반복을 수행한다. 반복은 다음과 같이 행해진다: ● (l+1로 인덱싱된) 현재의 계층의 모든 엘리먼트들에 대한 관련성들 이 주어지면, 다음이 되도록 현재 의 계층(인덱스 l+1)의 각각의 엘리먼트로부터 상류 계층(인덱스 l)의 모든 엘리먼트들까지 메시지 항들 을 계산하며:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 83, "content": "그 수학식은 근사 에러들까지 성립된다. ● 계층으로부터 그의 상류 계층까지 모든 메시지들 이 주어지면, 다음에 의해 상류 계층에 대한 관련성 을 계산한다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 84, "content": "이로부터, 계층 l의 모든 관련성들 이 계산되었기 때문에, 반복은 다음의 상류 계층 l-1에 대해 수행될 것 이다. ● 계층 1까지 아래로 모든 계층들을 통한 반복의 결과는 제 1 계층의 모든 엘리먼트들에 대한 관련성 스코어들 이며, 그 스코어들은 순서화된 콜렉션의 아이템들에 대한 스코어들이다. 방법의 결과는, 아이템들의 순서화된 콜렉션에 대해 행해진 예측에 대한 아이템의 관련성을 나타내는 아이템 당 하나의 스코어이거나, 또는 결과는 다음 중 적어도 하나와 결합된 스코어이다:● 스코어들의 각각의 간격이 하나의 컬러에 맵핑되도록 하는 이들 스코어들의 컬러로의 맵핑. ● 각각의 아이템에 대한 스코어들에 의해 결정된 순서에 따른 아이템들의 분류된 리스트. 그것은 다음과 같을 수 있다: ― 함수가 계층 l에 있다면, 본 발명은 로서 문자 i로 인덱싱된 엘리먼트의 출력값을 나타낸다. ― i로 인덱싱된 하나의 엘리먼트로부터 j로 인덱싱된 다른 엘리먼트로의 연결들은 가중치들 wij를 가질 수 있으 며, 그 가중치들은 이전의 엘리먼트로부터의 출력에 곱해진다. 따라서, i로 인덱싱된 계층 l로부터 j로 인덱싱된 엘리먼트로의 입력은 다음과 같이 기입될 수 있다:"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 85, "content": "● 바이어스 항들은 어떠한 입력도 취하지 않고 일정한 출력들을 제공하는 엘리먼트들에 의해 표현될 수 있다. 특히, 본 발명은, 모델의 적어도 하나의 엘리먼트 및 이러한 엘리먼트의 입력들의 세트에 수식들의 다음의 세트 들 중 적어도 하나를 적용함으로써 메시지 항들 을 계산한다: ● (위에서 주어진) 수학식들 A5 또는 A6 또는 A7 또는 A8 메시지 항들 은 모델의 적어도 하나의 엘리먼트 및 이러한 엘리먼트의 입력들의 세트에 위의 수학식들 A1 내지 A26 중 적어도 하나를 적용함으로써 계산될 수 있다. 샘플은 아이템들의 순서화된 콜렉션일 수 있다. 다음에서, 본 발명은 아이템들의 순서화된 콜렉션들의 수 개의 가능한 예들의 리스트를 제공할 것이다. 아이템들의 순서화된 콜렉션은 이미지일 수 있고, 각각의 아이템은 그의 하나 또는 그 초과의 픽셀들의 세트일 수 있다. 아이템들의 순서화된 콜렉션은 텍스트일 수 있고, 각각의 아이템은 그의 하나 또는 그 초과의 단어들의 세트일 수 있다. 아이템들의 순서화된 콜렉션은 텍스트일 수 있고, 각각의 아이템은 그의 하나 또는 그 초과의 문장들의 세트일 수 있다. 아이템들의 순서화된 콜렉션은 텍스트일 수 있고, 각각의 아이템은 그의 하나 또는 그 초과의 단락들의 세트일 수 있다. 아이템들의 순서화된 콜렉션은 키 값 쌍들의 리스트일 수 있고, 각각의 아이템은 그의 하나 또는 그 초과의 키 값 쌍들의 세트일 수 있다. 아이템들의 순서화된 콜렉션은 금융 데이터 또는 회사-관련 데이터의 키 값 쌍들의 리스트일 수 있고, 각각의 아이템은 하나 또는 그 초과의 키 값 쌍들의 세트일 수 있다. 아이템들의 순서화된 콜렉션은 비디오일 수 있고, 각각의 아이템은 타임스탬프들을 갖는 픽셀들의 하나 또는 그 초과의 쌍들의 세트일 수 있다. 아이템들의 순서화된 콜렉션은 비디오일 수 있고, 각각의 아이템은 하나 또는 그 초과의 프레임들의 세트일 수 있다. 아이템들의 순서화된 콜렉션은 비디오일 수 있고, 각각의 아이템은 하나 또는 그 초과의 픽셀들의 세트일 수 있 다. 학습가능한 신경망의 기술적인 규격 다음의 단락은, 다른 타입들의 피상적인 학습 알고리즘들과는 차이가 있는 훈련 페이즈 동안 신경망의 대부분의 계층들이 학습되는 방식으로 그 신경망을 설명한다. 그것은 다음의 속성들을 가질 수 있다. ― 모델이 테스트 시간에 2개로 계층화되면, 제 1 계층 가중치들은, 훈련 데이터의 세트, 및 훈련 데이터의 서 브세트에 의존하는 에러 측정을 사용하여 최적화된다. ― 모델이 테스트 시간에 3개 또는 4개로 계층화되면, 적어도 제 1 또는 제 2 계층 가중치들은, 훈련 데이터의 세트, 및 훈련 데이터의 서브세트에 의존하는 에러 측정을 사용하여 최적화된다. ― 모델이 테스트 시간에 5개 또는 그 초과로 계층화되면, 적어도 제 1 계층으로부터 제 3의 최종 계층까지에서 하나의 계층의 가중치들은, 훈련 데이터의 세트, 및 훈련 데이터의 서브세트에 의존하는 에러 측정을 사용하여 최적화된다. (이것은 최종 계층들이 또한 최적화되도록 허용한다). 계층의 엘리먼트들 중 적어도 하나는 정류된 선형 활성화 유닛들일 수 있다. 계층의 엘리먼트들 중 적어도 하나는 헤비사이드(Heaviside) 선형 활성화 유닛들일 수 있다. 계층의 엘리먼트들 중 적어도 하나는 tanh 활성화 유닛들일 수 있다. 계층의 엘리먼트들 중 적어도 하나는 로지스틱 활성화 유닛들일 수 있다. 계층의 엘리먼트들 중 적어도 하나는 S자형(sigmoidal) 선형 활성화 유닛들일 수 있다. 실험들 본 발명은, 2개의 데이터 세트들의 대한 결과들, 해석되기에 용이한 MNIST에 대한 결과들의 2개의 세트들, 및 ILSVRC 챌린지(challenge)로부터의 1000개의 카테고리들을 예측하는 카페 개방 소스 패키지 [20]의 일부로서 제 공되는 15계층의 이미 훈련된 망에 본 발명이 의존하는 실험들의 제 2 세트를 나타낸다. 하나의 측면에서, MNIST 디지트(digit)들에 대한 실험들에 의해, 본 발명은, 본 발명이 훈련 페이즈에 특유한 세부사항들을 알아 낼 수 있다는 것을 나타내도록 의도한다. 다른 측면에서, 카페 도구박스로부터의 미리 훈련된 망에 대한 결과 들은, 방법이 박스로부터 깊은 신경망으로 작동하고 훈련 페이즈 동안 가능한 트릭들에 의존하지 않는다는 것을 시연한다. 본 발명은, 미리 훈련된 망을 사용하여 기준 스코어 할당을 다른 실제 이미지들에 적용했다. 관련성 스코어들 의 형태의 분류 판단들의 설명들은 클래스, 예를 들어, '상어'에 대한 상어 지느러미, '컵'에 대한 둥근 형상, '화산'에 대한 산 형상 등의 의미있는 특성들을 강조한다. 관련성 스코어 할당이 이미지의 모든 그라디언트들 을 강조하는 것이 아니라, 그것은 특이한 특성들을 강조함을 유의한다. 예를 들어, 도 9는, ImageNet 데이터 세트로부터 1000개의 클래스들을 구별하도록 훈련된 신경망으로의 위에서-서술된 관련성 스코어 할당의 적용을 도시한다: 상부 이미지들은 망, 즉 세트로의 입력을 나타내고, 하부 이미지들은 위의 실시예들에 따라 픽셀 들에 할당된 관련성 스코어들을 각각의 입력 이미지당 하나씩 표시하는 히트맵을 나타낸다. 히트맵들은 위에서 서술된 바와 같이, 입력 이미지들 상에 오버레이될 수 있다. 뱀들(좌측 이미지)의 경우에서, 껍데기를 표현하 는 픽셀들은 대부분의 초기 관련성 스코어를 수용하고, 즉 뱀을 나타냄으로서 이미지들을 분류하는 망의 예측을 초래하기 위한 주요한 이유로서 식별되고, 상어(좌측 이미지로부터 두번째)의 경우에서, 지느러미를 표현하는 픽셀들은 초기 관련성 스코어의 대부분을 수용하고, 언덕(우측 이미지로부터 두번재)의 경우에서, 산마루를 표 현하는 픽셀들은 초기 관련성 스코어의 대부분을 수용하며, 성냥들(좌측 이미지)의 경우에서, 성냥들 및 불을 표현하는 픽셀들은 초기 관련성 스코어의 대부분을 수용한다는 것이 관측된다. 본 발명은 또한, MNIST 데이터 세트에 대해 신경망을 훈련시켰다. 이러한 데이터 세트는 0으로부터 9까지의 숫 자들의 이미지들을 포함한다. 훈련시킨 이후, 망은 새로운 관측되지 않은 이미지들을 분류할 수 있다. 역-전 파 관련성 스코어 할당으로, 본 발명은, 망이 3의 이미지를 클래스 '3'으로 분류한 이유, 즉 3을 다른 숫자들과 상이하게 한 것을 질의할 수 있다. 도 10의 히트맵에서, (다른 숫자들에 비해) 3의 가장 중요한 특성들은 중앙 의 수평 스트로크 및 (숫자 8에 대해서는 그곳에 존재할) 좌측의 수직 연결들의 부재라는 것이 관측될 수 있다. 본 발명은 또한, 예를 들어, 4의 이미지가 '9'로 분류되지 않은 이유, 즉 4의 이미지를 관측할 때 9가 아닌 이 유(speak againt)를 질의할 수 있다. '9'에 대한 반대 증거는 4의 최상부의 갭이라는 것이 관측될 수 있다. 화살표를 사용하여 표시된 레드 컬러는 특정한 클래스에 대한 증거를 나타내고, 으로 표시된 블루 컬러"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 86, "content": "는 클래스에 대한 반대 증거를 나타냄을 유의한다. 요약으로, 본 발명은, 방법이 분류 판단들의 의미있는 설명 들을 제공한다는 것을 나타내었다. 적용들 이제까지, 설명은 관련성 스코어 할당 프로세스에 중심을 두었다. 다음에서, 세트의 아이템들에 할당된 관 련성 스코어들이 사용될 수 있는 것이 간략히 설명될 것이다. 일반적인 적용은 더 크고 더 복잡한 알고리즘(CA)의 일부로서 본 명세서에서 제안된 관련성 스코어 할당(RS 할 당)을 사용할 것이다. 본 발명은, 알고리즘 CA를 적용하는 것이 매우 비싼 상황들을 고려할 수 있으므로, 본 발명의 RS 할당은, 알고리즘 CA가 적용될 수 있는 일부 관심 영역들을 정의할 수 있다. 예를 들어, ― 의사의 시간은 귀중하다. RS 할당은 암을 스캐닝할 경우 이미지에서 중요한 영역들을 식별할 수 있다. ― 비디오 코딩에서, 채널 대역폭은 귀중하다. RS 할당은, 예를 들어, 더 양호한 코딩 전략(예를 들어, 중요한 부분들에 대해서는 더 많은 비트들을 사용함) 또는 더 양호한 송신 스케줄(예를 들어, 중요한 정보를 먼저 송신 함)을 결정하기 위해 비디오의 어떤 부분들이 다른 부분들보다 더 중요한지에 대해 알고리즘 CA에게 통지할 수 있다. ― 히트맵은 일부 예측 작업을 위하여 부가적인 특성들을 계산하기 위해 사용될 수 있다. 예를 들어, 본 발명 은 훈련된 망을 사용하고, 그것을 일부 이미지에 적용하며, 더 중요한 영역들로부터 더 많은 특성들을 추출할 수 있다. 이것은 계산 시간 또는 정보 송신의 감소를 초래할 수 있다. 대안적으로, 그로부터 추출된 영역들 또는 부가적인 정보는 훈련된 망을 재훈련 및 개선시키기 위해 사용될 수 있다. ― RS 할당은 사용자 또는 회사가 특정한 작업에 대해 어떤 영역들 또는 특성들이 중요한지를 알려고 하는 경우 에 조사 도구로서 사용될 수 있다. 추가적으로, 이미지 애플리케이션 분야에서, ― RS 할당은 의료용 애플리케이션들에서, 예를 들어, 병리학적 이미지들에서 종양들을 식별하거나 MRI 이미지 들에서 관찰들을 식별할 시에 의사들에 대한 보조로서 사용될 수 있다. 더 구체적인 예들은 다음을 포함한다: ― 생물학적 조직들의 이미지들에서 염증 징후들의 검출, ― 생물학적 조직들의 이미지들에서 암 징후들의 검출, ― 생물학적 조직들의 이미지들에서 병리학적 변화들의 검출. ― RS 할당은 일반적인 이미지들에 적용될 수 있다. 예를 들어, 소셜 웹사이트 플랫폼들 또는 검색 엔진들은 많은 이미지들을 가지며, 어떤 것이 이미지를 '재미있거나', '특이하거나', '흥미있게 하는지 또는 어떤 것이 사람, 주택의 이미지 또는 주택들의 인테리어들을 매력적/심지적 또는 덜 매력적/덜 심미적이게 하는지에 관심 이 있을 수 있다. ― RS 할당은, 이미지의 어떤 부분이 비정상적인 이벤트를 감지하도록 시스템을 트리거링하는지를 검출하기 위 해 감시 애플리케이션들에서 사용될 수 있다. ― 위성들, 항공기들 또는 원격 감지 데이터에 의해 취해진 이미지들에서 토지 사용 변화들의 검출. 비디오 애플리케이션 분야에서, ― 히트맵들은, 예를 들어, 중요한 정보를 포함하는 영역들에 대해서는 더 많은 비트들을 사용하고 다른 영역들 에 대해서는 더 적은 비트들을 사용하여 코딩의 압축 강도를 셋팅하기 위해 사용될 수 있다."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 87, "content": "― RS 할당은 비디오 요약을 위해, 즉 비디오에서 '관련' 프레임들을 식별하기 위해 사용될 수 있다. 이것은 지능형 비디오 브라우징을 허용할 것이다. ― 애니메이션 영화들은 종종 매우 사실적으로 보이지는 않는다. 영화들을 더 현실적으로 보이게 하기 위해 어 떤 것이 '누락'됐는지는 명확하지 않다. 이러한 경우, 히트맵들은 비디오의 비현실적인 부분들을 강조하기 위 해 사용될 수 있다. 텍스트 애플리케이션들의 경우에서, ― 텍스트 문서들의 카테고리들로의 분류는 DNN들 또는 BoW 모델들에 의해 수행될 수 있다. RS 할당은 문서들 이 특정한 클래스로 분류되는 이유를 시각화할 수 있다. 토픽에 대한 텍스트의 관련성은 추가적인 프로세싱을"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 88, "content": "위해 강조 또는 선택될 수 있다. RS 할당은 중요 단어들을 강조할 수 있으며, 따라서 긴 텍스트의 요약을 제공 할 수 있다. 그러한 시스템들은, 예를 들어, 특허 변호사들이 많은 텍스트 문서들을 신속히 브라우징하기 위해유용할 수 있다. 금융 데이터 애플리케이션들의 경우에서, 은행들은, 어떤 사람이 신용 대출을 받을지 여부를 결정하기 위해 (깊은) 신경망들(예를 들어, 독일의 슈파 (Schufa) 시스템)과 같은 분류기들을 사용한다. 이들 알고리즘이 어떻게 작동하는지는 투명하지 않으며, 예를 들어, 신용을 얻지 못하는 일부 사람들은 그 이유를 알지 못한다. RS 할당은 어떤 사람이 신용을 얻지 못하는 이유를 정확히 나타낸다. 마케팅/세일즈의 분야에서, ― RS 할당은, 어떤 특정 제품 설명 이미지/텍스트가 제품(예를 들어, 아파트 임대, 이베이 제품 설명)을 판매 하게 하는지를 결정하기 위해 사용될 수 있다. ― RS 할당은 무엇이 온라인 비디오/블로그 포스트를 많이 보게하거나 좋아하게 되는지를 결정하기 위해 사용될 수 있다. ― 회사들은 어떤 '특성들'이, 예를 들어, 그들의 웹사이트 또는 제품을 매력있게 하는지에 일반적으로 관심이 있을 수 있다. ― 회사들은, 어떤 사용자들이 제품을 구매하고 다른 사용자들이 제품을 구매하지 않는 이유에 관심이 있다. RS 할당은, 사용자들이 제품을 구매하지 않는 이유를 식별하고 그에 따라 광고 전략을 개선시키는데 사용될 수 있다. 언어학/교육 분야에서, ― RS 할당은 텍스트의 어떤 부분이 영어, 프랑스어, 스페인어 또는 독일어와 같은 특정 언어에 대해 모국어로 하는 사람을 비-모국어로 하는 사람으로부터 구별하는지를 결정하기 위해 사용될 수 있다. ― RS 할당은, 문서가 특정한 사람에 의해 기입되었거나 기입되지 않았던 텍스트 내의 증거의 엘리먼트들을 발 견하기 위해 사용될 수 있다. 위의 설명에서, 상이한 실시예들이 관련성 스코어들을 아이템들의 세트에 할당하기 위해 제공되었다. 예를 들 어, 예들은 화상들에 대해 제공되었다. 화상들의 예들과 관련하여, 실시예들은 관련성 스코어들의 사용에 대해, 즉 관련성 스코어들을 사용하여 화상들에서 관련 부분들을 강조하기 위해, 즉 본래의 화상과 오버레이될 수 있는 비트맵의 사용에 의해 제공되었다. 다음에서, 관련성 스코어들을 사용 또는 활용하는 실시예들, 즉 위 에-설명된 관련성 스코어 할당을 기초로서 사용하는 실시예들이 제시된다. 도 11은 아이템들의 세트를 프로세싱하기 위한 시스템을 예시한다. 시스템은 일반적으로, 참조 부호를 사 용하여 표시된다. 시스템은 장치 이외에 프로세싱 장치를 포함한다. 둘 모두는 세트에 대해 동 작한다. 프로세싱 장치는 프로세싱 결과를 획득하기 위해 아이템들의 세트, 즉 세트를 프로세싱 하도록 구성된다. 이를 행할 시에, 프로세싱 장치는, 관련성 스코어 할당기에 의해 세트의 아이 템들에 할당되는 관련성 스코어들 Ri에 의존하여 자신의 프로세싱을 적응시키도록 구성된다. 장치 및 장치 는 하나 또는 그 초과의 컴퓨터들 상에서 구동하는 소프트웨어를 사용하여 구현될 수 있다. 그들은 별개 의 컴퓨터 프로그램들 또는 하나의 공통 컴퓨터 프로그램 상에서 구현될 수 있다. 세트에 관해, 위에서 제 시된 예들 모두가 유효하다. 예를 들어, 프로세싱 장치가 데이터 압축과 같은 손실있는 프로세싱을 수행 한다고 가정한다. 예를 들어, 장치에 의해 수행되는 데이터 압축은 무관성 감소를 포함할 수 있다. 세트 는, 예를 들어, 화상 또는 비디오와 같은 이미지 데이터를 표현할 수 있으며, 장치에 의해 수행되는 프로세싱은 손실있는 속성의 압축일 수 있고, 즉 장치는 인코더일 수 있다. 그 경우에서, 장치는, 예를 들어, 더 낮은 관련성 스코어들이 할당되는 아이템들과 비교하여 보다 더 높은 관련성 스코어들이 할당되는 아 이템들에 대한 프로세스의 손실도를 감소시키도록 구성될 수 있다. 손실도는, 예를 들어, 양자화 스텝 사이즈 를 통해 또는 인코더의 레이트 제어의 이용가능한 비트레이트를 변경시킴으로써 변경될 수 있다. 예를 들어, 관련성 스코어가 높은 샘플들의 영역들은, 예컨대 더 높은 비트 레이트, 더 낮은 양자화 스텝 사이즈 등을 사용 하여 덜 손실있게 코딩될 수 있다. 따라서, 관련성 스코어 할당은, 예를 들어, 비디오 장면에서 용의자 (suspect person)들의 검출/예측에 관해 자신의 관련성 스코어 할당을 수행한다. 그 경우에서, 프로세싱 장치 는, 이러한 예에 따라, 관심있는 장면들, 즉 용의자들이 그 장면 내에서 검출되었기 때문에 관심있게 되는 시공간 부분들에 관해 세트를 표현하는 비디오를 손실있게 압축할 시에 더 많은 데이터 레이트를 소비할 수 있다. 또는, 프로세싱 장치는 동일한 데이터 레이트를 사용하지만, 관련성 스코어들에 의해 달성된 가중으로 인해, 압축은 높은 관련성 스코어들을 갖는 샘플들의 아이템들에 대해서는 더 낮아지고, 압축은 낮은 관련 성 스코어들을 갖는 샘플들의 아이템들에 대해서는 더 높아진다. 그 경우에서, 프로세싱 결과는 손실있게 압축된 데이터 또는 데이터 스트림, 즉 비디오의 압축된 버전이다. 그러나, 이전에 언급된 바와 같이, 세 트는 비디오 데이터로 제한되지 않는다. 그것은 화상 또는 오디오스트림 등일 수 있다. 완전함을 위해, 도 12는 도 11의 시스템의 변형예를 도시한다. 여기서, 관련성 스코어 할당은, 세트의 아이템들에 대한 관련성 스코어들 Ri를 도출하도록 세트에 대해 동작하지만, 프로세싱 장치는 세트 와 동일하지 않은 프로세싱될 데이터에 대해 동작한다. 오히려, 세트는 데이터로부터 도출 된다. 도 12는, 예를 들어, 도 1의 예시적인 경우를 예시하며, 그에 따라, 세트는 특성 추출 프로세스(3 0)에 의해 데이터로부터 도출된다. 따라서, 세트는 데이터를 \"설명\"한다. 관련성 값들 Ri는 위 에서 설명된 방식으로, 특성 추출 프로세스에 관한 역 또는 역방향 맵핑을 표현하는 역방향 맵핑 프로세스 를 통해 본래의 데이터와 연관될 수 있다. 따라서, 프로세싱 장치는 데이터에 대해 동작하 고, 관련성 스코어들 Ri에 의존하여 자신의 프로세싱을 적응 또는 간소화시킨다. 도 11 및 도 12의 프로세싱 장치에 의해 수행되는 프로세싱은 손실있는 압축과 같은 손실있는 프로세싱으 로 제한되지 않는다. 예를 들어, 세트 또는 데이터에 대한 위의 예들의 대부분에서, 세트의 아이 템들은 1, 2 또는 그 초과의 차원들에서 순서화된 아이템들의 순서화된 콜렉션을 형성한다. 예를 들어, 픽셀들 은 적어도 2차원들에서 순서화되며, 즉 x 및 y는 2개의 측면 차원들이고, 시간축을 포함하는 경우에는 3차원들 도 존재한다. 오디오 신호들의 경우에서, 시간 도메인(예를 들어, PCM) 샘플들 또는 MDCT 계수들과 같은 샘플 들은 시간축을 따라 순서화된다. 그러나, 세트의 아이템들은 또한, 스펙트럼 도메인에서 순서화될 수 있다. 즉, 세트의 아이템들은, 예를 들어, 화상, 비디오 또는 오디오 신호의 스펙트럼 분해의 계수들을 표 현할 수 있다. 그 경우에서, 프로세스 및 역 프로세스는 각각, 스펙트럼 분해 또는 순방향 변환 또는 역 변환을 표현할 수 있다. 이들 경우들 모두에서, 관련성 스코어 할당기에 의해 획득되는 바와 같은 관련 성 스코어들 Ri가 유사하게 순서화되며, 즉 그들은 관련성 스코어들의 순서화된 콜렉션을 형성하거나, 달리 말하 면, 세트 또는 프로세싱을 통해서는 데이터와 오버레이될 수 있는 \"관련성 맵\"을 형성한다. 따라 서, 프로세싱 장치는, 예를 들어, 세트의 아이템들 사이의 순서 또는 데이터의 샘플들의 순서를 사용하여 데이터의 세트의 시각화를 수행하며, 시각화의 관련 부분을 강조하기 위해 관련성 맵을 사용 할 수 있다. 예를 들어, 프로세싱 결과는 스크린 상의 화상의 표현일 것이며, 세트 또는 데이터(10 6)에서 증가된 관련성의 부분을 각각 표시하기 위해 예를 들어, 블링킹(blinking), 컬러 반전 등을 사용하여 스 크린 상의 일부 부분을 강조하는 관련성 맵 장치를 사용한다. 예를 들어, 그러한 시스템은, 예를 들 어, 데이터 또는 세트에 의해 표현된 장면, 즉 비디오 또는 화상의 특정한 부분으로, 예를 들어, 경비 (security guard)들의 주의를 끌기 위하여 비디오 감시 목적을 위해 사용될 수 있다. 대안적으로, 장치에 의해 수행되는 프로세싱은 데이터 보충(replenishment)을 표현할 수 있다. 예를 들어, 데이터 보충은 메모리로부터의 판독을 지칭할 수 있다. 다른 대안으로서, 데이터 보충은 추가적인 측정 을 수반할 수 있다. 예를 들어, 세트가 다시 순서화된 콜렉션, 즉 화상에 속하는 특성 맵이고 화상 그자체 또는 비디오라고 가정한다. 그 경우에서, 프로세싱 장치는, ROI, 즉 관심 영역의 정보에서 관련성 스코어들 Ri를 도출할 수 있으며, 세트가 참조하는 완전한 장면에 대한 데이터 보충을 수행하는 것을 피하 기 위해 이러한 ROI로 데이터 보충을 포커싱할 수 있다. 예를 들어, 제 1 관련성 스코어 할당은 낮은 해상도의 현미경 화상에 대하여 장치에 의해 수행될 수 있으며, 그런다음, 장치는 관련성 스코어들이 높은 관련 성을 표시하는 낮은 해상도 현미경 화상 밖의 국부 부분에 대해 다른 현미경 측정을 수행할 수 있다. 따라서, 프로세싱 결과는 데이터 보충, 즉 고해상도의 현미경 화상의 형태의 추가적인 측정일 것이다. 따라서, 데이터 레이트 비용을 제어하는 목적을 위해 도 11 또는 도 12의 시스템을 사용하는 경우에서, 시 스템은 효율적인 압축 개념을 초래한다. 시각화 프로세스들을 위해 시스템을 사용하는 경우에서, 시 스템은 뷰어가 일부 관심영역을 실현하는 가능성을 증가시킬 수 있다. 데이터 보충을 간소화시키기 위해 시스템을 사용하는 경우에서, 시스템은 관심없는 영역들에 대한 데이터 보충의 수행을 피함으로써 데 이터 보충의 양을 피할 수 있다. 도 13은 아이템들의 세트의 관심영역을 강조하기 위한 시스템을 도시한다. 즉, 도 13의 경우에서, 아이템 들의 세트는 특성 맵, 화상, 비디오, 오디오 신호 등과 같은 순서화된 콜렉션인 것으로 다시 가정된다. 관련성 스코어 할당기는, 관련성 스코어 할당기에 의해 제공된 관련성 스코어들 Ri에 의존하여 관련성 그래프 를 생성하는 그래프 생성기에 부가하여 시스템에 의해 포함된다. 관련성 그래프는 이미 위에서설명된 바와 같이, 컬러가 관련성들 Ri를 \"측정\"하기 위해 사용되는 히트맵일 수 있다. 관련성 스코어들 Ri는 위에서 설명된 바와 같이, 스칼라이거나, 그 스코어들은 이미지의 하나의 컬러 픽셀에 속하는 상이한 컬러 컴포 넌트들의 서브-픽셀들의 관련성 스코어들과 같이 함께 속하는 맵핑 관련성 스코어들을 합산함으로써 스칼라가 될 수 있다. 그런다음, 예를 들어, 스칼라 관련성 스코어들 Ri는 개별 픽셀의 1차원 스칼라 관련성 스코어들을 CCT 값으로서 사용하여 컬러 또는 그레이 스케일로 맵핑될 수 있다. 그러나, 1차원으로부터 RGB와 같은 3차원 컬러 공간으로의 임의의 맵핑은 컬러화된 맵을 생성하기 위해 사용될 수 있다. 예를 들어, 본 발명은, 색조들 의 간격으로 스코어들을 맵핑하고, 채도 및 값 차원들을 고정시키며, 그런다음 HSV 표현을 RGB 표현으로 변환한 다. 그러나, 관련성 그래프는 대안적으로, 히스토그램 등의 형태로 표현될 수 있다. 그래프 생성기는 관 련성 그래프를 디스플레이하기 위한 디스플레이를 포함할 수 있다. 이것 외에도, 그래프 생성기는, 관련성 스코어 할당기를 구현하는 컴퓨터 프로그램과 별개이거나 그 내에 포함될 수 있는 컴퓨터 프로그램 과 같은 소프트웨어를 사용하여 구현될 수 있다. 구체적인 예로서, 아이템들의 세트가 이미지라고 가정한다. 할당기에 따라 획득된 각각의 픽셀에 대한 픽 셀-단위 관련성 스코어들은, 값들의 세트로/상으로 이산화/양자화될 수 있으며, 이산화/양자화 인덱스들은 컬러 들의 세트로 맵핑될 수 있다. 맵핑은 그래프 생성기에서 행해질 수 있다. 픽셀들의 컬러들로의 결과적인 할당, 즉 이를테면 컬러들에 대한 일부 CCT(컬러 온도)-측정에 따르는 관련성-컬러 맵핑의 경우에서는 \"히트 맵\"은 데이터베이스에 또는 저장 매체 상에 이미지 파일로서 저장되거나 생성기의 뷰어에 제시될 수 있다. 대안적으로, 픽셀들의 컬러들로의 할당은 본래의 이미지와 오버레이될 수 있다. 그 경우에서, 도 11 및 도 12 의 프로세서는 그래프 생성기로서 작동할 수 있다. 결과적인 오버레이 이미지는 매체 상에 이미지 파일로 서 저장되거나 뷰어에 제시될 수 있다. \"오버레이\"는, 예를 들어, 본래의 이미지를 그레이스케일 이미지로 변 환함으로써 행해지며, 색조값들에 맵핑되는 컬러값들로의 픽셀-단위 관련성 스코어들의 맵핑을 위해 사용될 수 있다. 오버레이 이미지는 색조-채도-값 표현을 사용함으로써 프로세서에 의해 생성될 수 있으며, 즉, 값 (그러나, 그 값은 거의 블랙인 픽셀이 어떠한 명확하게 가시적인 컬러들을 갖지 않기 때문에 너무 작은 값들에 대한 캡(cap)을 가지며, 또한 가능하게는, 채도는 본래의 이미지로부터 취해짐)은, 본래의 이미지의 그레이 스 케일 버전의 각각의 샘플의 그레이 스케일 값으로부터 획득되고, 색조값들은 컬러 맵으로부터 취해진다. 프로 세서는, 직전에 서술된 바와 같이 생성되는 이미지, 예를 들어, 컬러 맵 또는 오버레이 또는 관련성 스코 어들의 순서화된 세트(이들은 이미지로서 표현될 수 있지만, 이것은 필수요건은 아님)를 세그먼트화로 가할 수 있다. 매우 높은 스코어들을 갖는 영역들 또는 큰 절대값들을 가진 스코어들을 갖는 영역들에 대응하는 그러한 세그먼트화된 이미지 내의 그 세그먼트들은 추출되고, 데이터베이스 또는 저장 매체에 저장되며, (후속 수동 조 사를 이용하여 또는 그 조사 없이) 분류기 훈련 절차를 위한 부가적인 훈련 데이터로서 사용될 수 있다. 아이 템들의 세트가 텍스트이면, 관련성 할당의 결과는 위에서 설명된 바와 같이 단어 당 또는 문장 당 관련성 스코어일 수 있다. 그런다음, 관련성 스코어는 값들의 세트로 이산화되고 컬러들의 세트로 맵핑될 수 있다. 그런다음, 단어들은 프로세서에 의하여 컬러에 의해 마킹될 수 있으며, 결과적인 컬러-강조된 텍스트는 데 이터베이스에 또는 저장 매체 상에 저장되거나 사람에게 제시될 수 있다. 단어들을 강조하는 것에 대안적으로 또는 부가적으로, 프로세서는 단지, 단어들의 서브세트, 텍스트의 문장 부분들 또는 문장들, 즉 (예를 들 어, 스코어 또는 그의 절대값의 임계치화에 의한) 가장 높은 스코어들 또는 스코어들의 가장 높은 절대값들을 갖는 것들을 선택하며, 이러한 선택을 데이터베이스에 또는 저장 매체 상에 저장하거나 그것을 사람에게 제시할 수 있다. 샘플이 데이터베이스 내의 테이블에 저장된 키 값 쌍들의 세트, 예를 들어, 회사들에 관한 금융 데이 터로 구성되도록 관련성 할당이 데이터 세트에 적용되면, 각각의 샘플에 대한 결과는 키-값 쌍 당 관련성 스코어일 것이다. 그런다음, 주어진 샘플에 대해, (예를 들어, 스코어 또는 그의 절대값의 임계치화에 의한) 가장 높은 스코어들 또는 스코어들의 가장 높은 절대값들을 갖는 키-값 쌍들의 서브세트가 선택될 수 있으며, 이러한 선택은 데이터베이스에 또는 저장 매체 상에 저장되거나 사람에게 제시될 수 있다. 이것은 프로세서 또는 생성기에 의해 행해질 수 있다. 데이터 세트가 이미지 또는 비디오일 수 있다는 것이 도 12에 대해 위에서 이미 서술되었다. 그런다음, 픽 셀-단위 관련성 스코어들은 높은 스코어들을 갖는 영역들을 발견하기 위해 사용될 수 있다. 이를 위해, 위에서 언급된 세그먼트화 또는 비디오 세그먼트화가 예시적으로 사용될 수 있다. 비디오의 경우에서, 높은 스코어의 영역은 비디오의 공간-시간 서브세트 또는 부분일 것이다. 각각의 영역에 대해, 영역 당 스코어는, 예를 들어,p-평균 또는 영역의 픽셀들에 대한 픽셀-단위 스코어들의 변위치 (quantile)를 계산함으로써 계산될 수 있다. 그런다음, 데이터 세트, 예를 들어, 비디오는 압축 레이트가 계산 된 스코어에 따라 영역들에 대해 조정될 수 있는 프로세서에 의한 압축 알고리즘에 가해질 것이다. 영역 스코어들의 압축 레이트들로의 단조 (하강 또는 상승) 맵핑이 사용될 수 있다. 그런다음, 영역들 각각은 영역 스코어들의 압축 레이트들로의 맵핑에 따라 인코딩될 것이다. 추가적으로, 프로세서는 세트로서의 이미지의 경우에서 다음과 같이 작동할 수 있다: 직전에 서술된 세그먼트화는 모든 픽셀들에 대한 스코어들의 세트 또는 오버레이 이미지 또는 컬러 맵에 적용될 수 있으며, 매 우 높은 스코어들을 갖는 영역들 또는 큰 절대값들을 가진 스코어들을 갖는 영역들에 대응하는 세그먼트들이 추 출될 수 있다. 그런다음, 프로세서는, 뚜렷한 또는 이례적인 콘텐츠의 가능성에 대한 콘텐츠의 체크를 위해 본 래의 이미지의 이들 공동-로케이팅된 세그먼트들을 사람 또는 다른 알고리즘에 제시할 수 있다. 이것은, 예를 들어, 경비 애플리케이션들에서 사용될 수 있다. 유사하게, 세트는 비디오일 수 있다. 차례로, 전체 비디오는 프레임들의 세트로 구성된다. 위에서 이미 언급된 바와 같이, 아이템들의 세트 내의 아이템은 프 레임 또는 프레임들의 서브세트 또는 프레임들의 서브세트로부터의 영역들의 세트일 수 있다. 공간-시간 비디 오 세그먼트화는 아이템들에 대한 높은 평균 스코어들 또는 아이템들에 대한 스코어들의 높은 평균 절대값들 중 어느 하나를 갖는 공간-시간 영역들을 발견하기 위해, 아이템들로의 관련성 스코어 할당에 적용될 수 있다. 위 에서 언급된 바와 같이, 영역 내의 아이템들에 할당된 평균 스코어들은, 예를 들어, p-평균 또는 변위치 추정기 를 사용하여 측정될 수 있다. 일부 임계치 위의 스코어들과 같은 가장 높은 그러한 스코어들을 갖는 공간-시간 영역들은, 프로세서에 의해 (예를 들어, 이미지 또는 비디오 세그먼트화에 의해) 추출되며, 뚜렷한 또는 이례적인 콘텐츠의 가능성에 대한 콘텐츠의 체크를 위해 사람 또는 다른 알고리즘에 제시될 수 있다. 체크하기 위한 알고리즘은 프로세서에 포함될 수 있거나, 또는 그 외부에 있을 수 있으며, 이것은, 높은(가장 높은) 스코어의 영역들의 체크를 모니터링하는 위의 경우들에 대해 또한 참이다. 일 실시예에 따르면, 가장 높은 그러한 스코어들을 갖는 직전에-언급된 공간-시간 영역들은 비디오들에 대해 행 해진 예측들에 대한 훈련 개선의 목적을 위해 사용된다. 언급된 바와 같이, 아이템들의 세트는 프레임들의 세트에 의해 표현될 수 있는 전체적인 비디오이다. 아이템들의 세트 내의 아이템은 프레임 또는 프레임들의 서 브세트 또는 프레임들의 서브세트로부터의 영역들의 세트이다. 그런다음, 비디오 세그먼트화는 아이템들에 대 한 높은 평균 스코어들 또는 아이템들에 대한 스코어들의 높은 평균 절대값들 중 어느 하나를 갖는 공간-시간 영역들을 발견하기 위해 적용된다. 프로세서는 다른 뉴런들에 연결된 신경망의 뉴런들을 선택하여, 간접 적인 연결들을 통해 위의 영역들이 선택된 뉴런들의 입력의 일부가 되게 할 수 있다. 프로세서는 다음의 방식으로 신경망을 최적화할 수 있다: 위에서와 같이 (예를 들어, 높은 관련성 스코어들 또는 그들의 높은 절대 값들을 갖는 영역들로부터 직접적인 또는 간접적인 입력들을 가짐으로써) 선택된 뉴런 및 입력 이미지가 주어지 면, 프로세서는, 망 출력 또는 망 출력의 제곱을 증가시키거나, 또는 선택된 뉴런의 입력들의 가중치들 및 선택된 뉴런의 직접적인 또는 간접적인 상류 이웃들인 그 뉴런들의 가중치들을 변화시킴으로써 망 출력을 감소 시키기를 시도한다. 그러한 변화는, 예를 들어, 변화될 가중치들에 대하여, 주어진 이미지에 대한 뉴런 출력의 그라디언트를 계산함으로써 행해질 수 있다. 그런다음, 가중치들은 그라디언트 곱하기 스텝사이즈 상수에 의해 업데이트된다. 언급할 필요도 없이, 공간-시간 영역은 또한, 픽셀-단위 스코어들의 세그먼트화에 의해, 즉 세 트의 아이템들로서 픽셀들을 사용함으로써 획득될 수 있으며, 그런다음, 위에서 서술되었던 최적화를 수행 한다. 심지어 대안적으로, 관련성 할당은 노드들, 및 가중치들을 갖거나 갖지 않는 지향된 또는 지향되지 않은 에지들 로 구성된 그래프 데이터에 적용될 수 있으며: 그런다음, 세트의 아이템은, 예를 들어, 서브그래프일 것이다. 엘리먼트-단위 관련성 스코어는 각각의 서브그래프에 대해 계산될 것이다. 서브그래프는, 예를 들어, 노 드들 및 가중치들을 갖는 그들의 에지들을 정수들로 부호화하면서 중지 기호들로서 예비된 정수들에 의해 시맨 틱 유닛들을 분리시킴으로써 그 서브그래프가 정수로서 인코딩되면, 신경망에 대한 입력일 수 있다. 대안적으 로, 아이템 당 관련성 스코어를 계산하기 위한 세트의 아이템은 노드일 수 있다. 그런다음, 본 발명은 아 이템-단위 관련성 스코어들을 계산한다. 그 후, 높은 평균 스코어를 갖는 서브그래프들의 세트는 그래프 세그 먼트화에 의해 발견될 수 있다(평균 스코어는, p-평균 에 의해 또는 노 드들에 걸친 스코어들의 변위치에 의해 계산될 수 있음). 각각의 노드에 대한 스코어는 값들의 세트로 이산화되고, 이산화 인덱스들은 컬러들의 세트로 맵핑된다. 노드들 및 서브그래프들의 컬러들 및/또는 추출된 서브그 래프들로의 결과적인 할당은 데이터베이스에 또는 저장 매체 상에 파일로서 저장되거나 뷰어에게 제시될 수 있 다. 도 14는 신경망을 최적화하기 위한 시스템을 예시한다. 시스템은 일반적으로, 참조 부호를 사용하여 표시 되며, 관련성 스코어 할당기, 적용 장치 및 검출 및 최적화 장치를 포함한다. 적용 장치는 아이템들의 복수의 상이한 세트들에 장치를 적용하도록 구성된다. 따라서, 각각의 적용에 대해, 장치 는 세트의 아이템에 대한 관련성 스코어들을 결정한다. 그러나, 이때에, 장치는 역방향 전파 동안 신경망의 개별적인 중간 뉴런들에 할당된 관련성 값들을 또한 출력하며, 그에 의해, 각각의 적용에 대 한 전술된 관련성 경로들을 획득한다. 즉, 장치의 각각의 세트로의 각각의 적용에 대해, 검출 및 최적화 장치는 신경망의 관련성 전파 맵을 획득한다. 장치는, 장치의 상이한 세트들 로의 적용 동안 망의 중간 뉴런들에 할당된 관련성들을 누산하거나 오버레이함으로써 신경망 내의 증가된 관련성의 부분을 검출한다. 즉, 장치는, 세트들의 집단(population)에 걸쳐 장치의 역방향 전파 프로세스로 높은 퍼센티지의 관련성을 전파하는 그 뉴런들을 포함하는 신경망의 부 분을 획득하기 위해, 상이한 관련성 전파 맵들을 오버레이하거나, 또는 오버레이에 의해 누산한다. 그런다음, 이러한 정보는 인공 신경망을 최적화하기 위하여 장치에 의해 사용될 수 있다. 특히, 예를 들어, 인공 신경망의 뉴런들의 상호연결부들 중 일부는 그의 예측 능력을 손상시키지 않으면서 인 공 신경망을 더 작게 하기 위해 중지될 수 있다. 그러나, 다른 가능성들이 또한 존재한다. 추가적으로, 그것은, 관련성 스코어 할당 프로세스가 히트맵을 제공하고, 그 프로세스가, 예를 들어, 평활도 및 다른 속성들에 대해 분석된다는 것일 수 있다. 분석에 기초하여, 일부 액션이 트리거링될 수 있다. 예를 들어, 신경망이 히트맵 분석에 따라 \"충분히 양호한\" 개념들을 캡쳐하기 때문에, 그 신경망의 훈련은 중지될 수 있다. 추가적으로, 히트맵 분석 결과는 무엇이든 행하기 위해 신경망 예측 결과들, 즉 예측과 함께 사용될 수 있음을 유의해야 한다. 특히, 히트맵 및 예측 결과들 둘 모두에 의존하는 것은, 예를 들어, 히트맵이 예측의 확실성에 대한 무언가를 언급할 수 있기 때문에, 오직 예측 결과들에만 의존하는 것에 비해 유리할 수 있다. 신경망의 품질은 히트맵을 분석함으로써 잠재적으로 평가될 수 있다. 최종적으로, 제안된 관련성 전파는 분류 작업들에 대해 훈련된 망들에 대하여 위에서 주로 예시되었지만, 일반 화의 손실없이, 위에서 설명된 실시예들은 출력 클래스들에 기인되는 스코어를 할당하는 임의의 망에 적용될 수 있다는 것이 강조된다. 이들 스코어들은 회귀 또는 랭킹과 같은 다른 기술들을 사용하여 학습될 수 있다. 따라서, 위의 설명에서, 신경망 예측기들을 이해하도록 허용하는 계층-단위 관련성 전파로 지칭될 수 있는 방법 을 구현하는 실시예들이 제시되었다. 이러한 신규한 원리의 상이한 적용들이 시연되었다. 이미지들에 대해, 픽셀 기여도들은 히트맵들로서 시각화될 수 있으며, 분류 판단의 유효성을 직관적으로 검증할 뿐만 아니라 잠재 적으로 관심있는 영역들에 추가적인 분석을 포커싱할 수 있는 사람의 전문가에게 제공될 수 있다는 것을 나타내 었다. 위에서 언급된 바와 같이, 원리는 다양한 작업들, 분류기들 및 데이터 타입에 적용될 수 있으며, 즉 이 미지들로 제한되지 않는다. 일부 양상들이 장치의 맥락에서 설명되었지만, 이들 양상들이 또한 대응하는 방법의 설명을 표현한다는 것은 명 확하며, 여기서, 블록 또는 디바이스는 방법 단계 또는 방법 단계의 특성에 대응한다. 유사하게, 방법 단계의 맥락에서 설명된 양상들은 또한, 대응하는 장치의 대응하는 블록 또는 아이템 또는 특성의 설명을 표현한다. 방법 단계들 중 일부 또는 모두는, 예를 들어, 마이크로프로세서, 프로그래밍가능 컴퓨터 또는 전자 회로와 같 은 하드웨어 장치에 의해(또는 사용함으로써) 실행될 수 있다. 일부 실시예들에서, 가장 중요한 방법 단계들 중 일부의 하나 또는 그 초과는 그러한 장치에 의해 실행될 수 있다. 특정한 구현 요건들에 의존하면, 본 발명의 실시예들은 하드웨어 또는 소프트웨어로 구현될 수 있다. 구현은, 각각의 방법이 수행되도록 프로그래밍가능한 컴퓨터 시스템과 협력하는(또는 협력할 수 있는), 전자적으로 판독 가능한 제어 신호들이 저장된 디지털 저장 매체, 예를 들어, 플로피 디스크, DVD, 블루-레이, CD, ROM, PROM, EPROM, EEPROM 또는 FLASH 메모리를 사용하여 수행될 수 있다. 따라서, 디지털 저장 매체는 컴퓨터 판독가능할 수 있다. 본 발명에 따른 일부 실시예들은, 본 명세서에 설명된 방법들 중 하나가 수행되도록 프로그래밍가능한 컴퓨터 시스템과 협력할 수 있는, 전자적으로 판독가능한 제어 신호들을 갖는 데이터 캐리어를 포함한다. 일반적으로, 본 발명의 실시예들은 프로그램 코드를 갖는 컴퓨터 프로그램 물건으로서 구현될 수 있으며, 프로 그램 코드는, 컴퓨터 프로그램 물건이 컴퓨터 상에서 구동되는 경우 방법들 중 하나를 수행하기 위해 동작된다. 프로그램 코드는, 예를 들어, 머신 판독가능 캐리어 상에 저장될 수 있다. 다른 실시예들은, 머신 판독가능 캐리어 상에 저장되는, 본 명세서에 설명된 방법들 중 하나를 수행하기 위한 컴퓨터 프로그램을 포함한다. 즉, 따라서, 본 발명의 방법의 실시예는, 컴퓨터 프로그램이 컴퓨터 상에서 구동되는 경우, 본 명세서에 설명된 방법들 중 하나를 수행하기 위한 프로그램 코드를 갖는 컴퓨터 프로그램이다. 따라서, 본 발명의 방법들의 추가적인 실시예는, 본 명세서에 설명된 방법들 중 하나를 수행하기 위한 컴퓨터 프로그램(상부에 기록됨)을 포함하는 데이터 캐리어(또는 디지털 저장 매체, 또는 컴퓨터-판독가능 매체)이다. 데이터 캐리어, 디지털 저장 매체 또는 레코딩된 매체는 통상적으로, 유형이고 그리고/또는 비-일시적이다. 따라서, 본 발명의 방법의 추가적인 실시예는, 본 명세서에 설명된 방법들 중 하나를 수행하기 위한 컴퓨터 프 로그램을 표현하는 데이터 스트림 또는 신호들의 시퀀스이다. 데이터 스트림 또는 신호들의 시퀀스는, 예를 들 어, 데이터 통신 연결을 통해, 예를 들어, 인터넷을 통해 전달되도록 구성될 수 있다. 추가적인 실시예는, 본 명세서에 설명된 방법들 중 하나를 수행하도록 구성 또는 적응되는 프로세싱 수단, 예를 들어, 컴퓨터, 또는 프로그래밍가능 로직 디바이스를 포함한다. 추가적인 실시예는, 본 명세서에 설명된 방법들 중 하나를 수행하기 위한 컴퓨터 프로그램이 인스톨된 컴퓨터를 포함한다. 본 발명에 따른 추가적인 실시예는, 본 명세서에 설명된 방법들 중 하나를 수행하기 위한 컴퓨터 프로그램을 (예를 들어, 전자적으로 또는 광학적으로) 수신기에 전달하도록 구성된 장치 또는 시스템을 포함한다. 수신기 는, 예를 들어, 컴퓨터, 모바일 디바이스, 메모리 디바이스 등일 수 있다. 장치 또는 시스템은, 예를 들어, 컴 퓨터 프로그램을 수신기에 전달하기 위한 파일 서버를 포함할 수 있다. 일부 실시예들에서, 프로그래밍가능 로직 디바이스(예를 들어, 필드 프로그래밍가능 게이트 어레이)는, 본 명세 서에 설명된 방법들의 기능들 중 일부 또는 모두를 수행하기 위해 사용될 수 있다. 일부 실시예들에서, 필드 프로그래밍가능 게이트 어레이는, 본 명세서에 설명된 방법들 중 하나를 수행하기 위해 마이크로프로세서와 협 력할 수 있다. 일반적으로, 방법들은 바람직하게 임의의 하드웨어 장치에 의해 수행된다. 본 명세서에 설명된 장치는, 하드웨어 장치를 사용하여, 또는 컴퓨터를 사용하여, 또는 하드웨어 장치 및 컴퓨 터의 결합을 사용하여 구현될 수 있다. 본 명세서에 설명된 방법은, 하드웨어 장치를 사용하여, 또는 컴퓨터를 사용하여, 또는 하드웨어 장치 및 컴퓨 터의 결합을 사용하여 수행될 수 있다. 상술된 실시예들은 단지, 본 발명의 원리들에 대해 예시적일 뿐이다. 본 명세서에 설명된 어레인지먼트 (arrangement)들 및 세부사항들의 변형들 및 변경들이 당업자들에게는 명백할 것임을 이해한다. 따라서, 본 명 세서의 실시예들의 설명 및 해설에 의해 제시된 특정한 세부사항들이 아니라 임박한 특허 청구항들의 범위에 의 해서만 제한되는 것이 의도이다. 참조 문헌들"}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 89, "content": "[6] Christopher M Bishop et al. Pattern recognition and machine learning, volume 1. springer New York, 2006."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 90, "content": "[10] Hendrik Dahlkamp, Adrian Kaehler, David Stavens, Sebastian Thrun, and Gary R. Bradski. Self- supervised monocular road detection in desert terrain. In Robotics: Science and Systems, 2006."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 91, "content": "[11] Jia Deng, Alex Berg, Sanjeev Satheesh, Hao Su, Aditya Khosla, and Fei-Fei Li. The ImageNet Large Scale Visual Recognition Challenge 2012 (ILSVRC2012). http://www.image- net.org/challenges/LSVRC/2012/."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 92, "content": "[12] Dumitru Erhan, Yoshua Bengio, Aaron Courville, and Pascal Vincent. Visualizing higher-layer features of a deep network. Technical Report 1341, University of Montreal, June 2009."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 93, "content": "[15] L. Fei-Fei and P. Perona. A bayesian hierarchical model for learning natural scene categories. In Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on,volume 2, pages 524-531 vol. 2, 2005."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 94, "content": "[16] Muriel Gevrey, Ioannis Dimopoulos, and Sovan Lek. Review and comparison of methods to study the contribution of variables in artificial neural network models. Ecological Modelling, 160:249-264, 2003."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 95, "content": "[17] Ronny Hansch and Olaf Hellwich. Object recognition from polarimetric SAR images. In Uwe Soergel, editor, Radar Remote Sensing of Urban Areas, volume 15 of Remote Sensing and Digital Image Processing, pages 109-131. Springer Netherlands, 2010."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 96, "content": "[20] Yangqing Jia. Caffe: An open source convolutional architecture for fast feature embedding. http://caffe.berkeleyvision.org/, 2013."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 97, "content": "[23] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In Peter L. Bartlett, Fernando C. N. Pereira, Christopher J. C. Burges, Leon Bottou, and Kilian Q. Weinberger, editors, NIPS, pages 1106-1114, 2012."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 98, "content": "[25] Yann LeCun and Corinna Cortes. The MNIST database of handwritten digits. http://yann.lecun.com/exdb/mnist/, 1998."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 99, "content": "[26] Yann LeCun, Koray Kavukcuoglu, and Clement Farabet. Convolutional networks and applications in vision. In ISCAS, pages 253-256. IEEE, 2010."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 100, "content": "[27] Quoc V. Le. Building high-level features using large scale unsupervised learning. In ICASSP, pages 8595-8598, 2013."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 101, "content": "[31] Gregoire Montavon, Genevieeve B. Orr, and Klaus-Robert Muller, editors. Neural Networks: Tricks of the Trade, Reloaded, volume 7700 of Lecture Notes in Computer Science (LNCS). Springer, 2nd edn edition, 2012."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 102, "content": "[34] Julian D Olden, Michael K Joy, and Russell G Death. An accurate comparison of methods for quantifying variable importance in artificial neural networks using simulated data. Ecological Modelling, 178(3-4):389-397, 2004."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 103, "content": "[36] Nicolas Pinto, David D Cox, and James J DiCarlo. Why is real-world visual object recognition hard? PLoS Comput Biol, 4:27, 1 2008."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 104, "content": "[39] David E. Rumelhart, Geoffrey E. Hinton, and Ronald J. Williams. Learning representations by back-propagating errors. Nature, 323:533-536, Oct 1986."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 105, "content": "[41] Rudy Setiono and Huan Liu. Understanding neural networks via rule extraction. In IJCAI, pages 480-487. Morgan Kaufmann, 1995."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 106, "content": "[42] Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Deep inside convolutional networks: Visualising image classification models and saliency maps. CoRR, abs/1312.6034, 2013."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 107, "content": "[43] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfellow, and Rob Fergus. Intriguing properties of neural networks. CoRR, abs/1312.6199, 2013."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 108, "content": "[49] Paul A. Viola and Michael J. Jones. Rapid object detection using a boosted cascade of simple features. In CVPR , pages 511-518, 2001."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 109, "content": "[50] Ross Walker, Paul Jackway, Brian Lovell, and Dennis Longstaff. Classification of cervical cell nuclei using morphological segmentation and textural feature extraction. In Australian New Zealand Conference on Intelligent Information Systems, 1994."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 110, "content": "[54] Matthew D. Zeiler and Rob Fergus. Visualizing and understanding convolutional networks. CoRR, abs/1311.2901, 2013."}
{"patent_id": "10-2017-7030274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 111, "content": "[55] Matthew D. Zeiler, Graham W. Taylor, and Rob Fergus. Adaptive deconvolutional networks for mid and high level feature learning. In ICCV, pages 2018-2025, 2011.도면 도면1a 도면1b 도면1c 도면1d 도면2a 도면2b 도면2c 도면2d 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15"}
{"patent_id": "10-2017-7030274", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 본 발명의 실시예들에 따른 역방향 전파를 사용하는 관련성 스코어 할당이 적용될 수 있는 인공 신경망 을 사용하는 예측의 일 예의 개략도를 도시한다. 도 2a는 기초로서 도 1의 인공 신경망을 예시적으로 사용하는 본 출원의 실시예들에 따라 사용되는 역방향 전파 프로세스를 예시한 개략도를 도시한다. 도 1a 및 도 2b는 도 1a 및 도 2a의 변형예를 도시하며, 그 변형예에 따라, 망 및 관련성 할당은 이미지의 픽셀 들보다는 특성 맵들에 대해 동작된다. 도 1c 및 도 2c는 도 1a 및 도 2a를 컬러 이미지들 상으로 적용하는 가능성을 도시한다. 도 1d 및 도 2d는 도 1a 및 도 2a의 변형예를 도시하며, 그 변형예에 따라, 망 및 관련성 할당은 이미지들보다는 텍스트들에 대해 동작된다. 도 3은 인공 신경망의 중간 뉴런, 및 상향 및 하류 이웃 뉴런들로의 그의 연결을 개략적으로 예시하며, 여기서, 예시적으로 3개의 상류 이웃 뉴런들이 또한 도시된다. 도 4는 일 실시예에 따른, 관련성 스코어들을 아이템들의 세트에 할당하기 위한 장치의 블록도를 도시한다. 도 5는 예측 시간 동안의 신경망-형상 분류기를 도시한다. wij는 연결 가중치들이다. ai는 뉴런 i의 활성화이 다. 도 6은 계층-단위 관련성 계산 시간 동안의 도 5의 신경망-형상 분류기를 도시한다. 는 계산될 뉴런 i의 관련성이다. 의 계산을 용이하게 하기 위해, 본 발명은 메시지들 을 도입한다. 는, 수학 식 의 계층-단위 관련성이 보존되도록 계산될 필요가 있는 메시지들이다. 메시지들은 분류를 위해 사용되는 연결들을 통해 뉴런 i로부터 그의 입력 뉴런들 j로 전송되며, 예를 들어, 2는 뉴런들 4, 5, 6에 대한 입력 뉴런 이다. 뉴런 3은 5, 6에 대한 입력 뉴런이다. 뉴런들 4, 5, 6은 뉴런 7에 대한 입력이다. 도 7은, 0.6 내지 0.9의 영역의 그린 도트들로부터 ―0.8의 블루 도트들을 분리시키는 판단 경계인 점선의 블랙 라인을 갖는 분류를 위한 예시적인 실수값 예측 함수를 도시한다. 블루 도트들은 음으로 라벨링되고, 그린 도 트들은 양으로 라벨링된다. 좌측에는 예측 포인트의 분류 함수의 국부 그래디언트가 도시되고, 우측에는 판단 경계 상의 루트 포인트에 관한 테일러 근사가 예시된다. 도 8은 뉴런들 및 가중 연결들을 설명하는 상이한 변수들로 주석이 달린 다층 신경망에 대한 일 예를 예시한다. 좌측: 순방향 전달. 우측: 역방향 전달. 도 9는 ImageNet 데이터 세트로부터 1000개의 클래스들을 구별하기 위해 훈련된 신경망에 대한 픽셀-단위 (pixel-wise) 분해를 예시한다. 도 10은, 우측에서, 숫자들 \"3\" 및 \"4\"의 주변 부분들을 예시적으로 예시하는 히트 맵들(heat map)을 예시적으 로 도시하는 0으로부터 9까지의 숫자들의 이미지들을 포함하는 본 출원의 실시예들의 개념이 MNIST(국립 혼합 표준 및 기술 기관(Mixed National Institute of Standards and Technology)) 데이터 세트에 적용되는 실험을 도시하며, 그 숫자들 \"3\" 및 \"4\"는, 각각, 이들 숫자들을 \"3\"으로서 인지하고 \"9\"로부터 각각의 숫자를 구별하 기 위한 높은 관련성을 갖는다. 도 11은 일 실시예에 따른 데이터 프로세싱을 위한 시스템의 블록도를 도시한다. 도 12는, 아이템들의 세트가 도출되는 데이터에 대해 프로세싱이 수행된다는 점에서 도 11과는 상이한 일 실시 예에 따른 데이터 프로세싱을 위한 시스템의 블록도를 도시한다. 도 13은 일 실시예에 따른 ROI 강조(highlighting) 시스템의 블록도를 도시한다. 도 14는 일 실시예에 따른 신경망 최적화 시스템을 도시한다. 도 15는, 인공 신경망에 관한 관련성 스코어 할당의 작업 및 인공 신경망의 통상적인 예측 작업에 대한 관계를 예시하는 개략도를 도시한다."}
