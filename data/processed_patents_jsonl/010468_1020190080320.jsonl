{"patent_id": "10-2019-0080320", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0116836", "출원번호": "10-2019-0080320", "발명의 명칭": "영상 처리 장치 및 그 영상 처리 방법", "출원인": "삼성전자주식회사", "발명자": "임형준"}}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 명령어를 저장하는 메모리; 및상기 메모리와 전기적으로 연결된 프로세서;를 포함하고, 상기 프로세서는, 상기 명령어를 실행함으로써, 입력 영상을 학습 네트워크 모델에 적용하여 상기 입력 영상에 포함된 픽셀 블록에 대응되는 텍스처 패치를 상기 픽셀 블록에 적용하여 출력 영상을 획득하며,상기 학습 네트워크 모델은, 영상의 특성에 기초하여 분류된 복수의 클래스 각각에 대응되는 텍스처 패치를 저장하며, 상기 입력 영상에 기초하여 상기 복수의 클래스 각각에 대응되는 텍스처 패치를 학습하는, 영상 처리 장치."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 학습 네트워크 모델은, 상기 픽셀 블록의 특성에 기초하여 상기 복수의 클래스 중 하나를 식별하고, 상기 식별된 클래스에 대응되는 텍스처 패치를 출력하며, 상기 픽셀 블록과 상기 식별된 클래스 간의 제1 유사도 및 상기 텍스처 패치와 상기 식별된 클래스 간의 제2 유사도를 비교하여 상기 텍스처 패치를 업데이트할지 여부를 식별하는, 영상 처리 장치."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 학습 네트워크 모델은, 상기 제1 및 제2 유사도에 기초하여 상기 식별된 클래스에 대응되는 텍스처 패치를 상기 픽셀 블록으로 대체하거나, 상기 픽셀 블록을 상기 식별된 클래스에 대응되는 텍스처 패치로 추가하는, 영상 처리 장치."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 학습 네트워크 모델은, 상기 비교 결과에 기초하여 상기 제1 유사도가 상기 제2 유사도 보다 작은 값이면, 상기 식별된 클래스에 대응되는 상기 텍스처 패치를 유지하고, 상기 비교 결과에 기초하여 상기 제1 유사도가 상기 제2 유사도 보다 큰 값이면, 상기 픽셀 블록에 기초하여 상기 텍스처 패치를 업데이트하는, 영상 처리 장치."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 학습 네트워크 모델은, 상기 식별된 클래스에 대응되는 텍스처 패치가 복수 개인 경우, 상기 픽셀 블록 및 상기 복수 개의 텍스처 패치공개특허 10-2020-0116836-3-각각의 상관 관계(correlation)에 기초하여 상기 복수 개의 텍스처 패치 중 어느 하나를 식별하는, 영상 처리장치."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 학습 네트워크 모델은, 상기 복수의 클래스 각각에 대응되는 텍스처 패치의 저장 시기 또는 상기 텍스처 패치의 적용 빈도수 중 적어도하나에 기초하여 상기 텍스처 패치를 학습하는, 영상 처리 장치."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 학습 네트워크 모델은, 상기 픽셀 블록의 특성에 기초하여 상기 픽셀 블록이 상기 복수의 클래스 중 어느 하나에 대응되지 않는 것으로식별되면, 상기 픽셀 블록의 특성에 기초하여 신규 클래스를 생성하고 상기 신규 클래스에 상기 픽셀 블록을 맵핑하여 저장하는, 영상 처리 장치."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 학습 네트워크 모델은,상기 입력 영상에 포함된 복수의 픽셀 블록 각각에 대응되는 클래스를 식별하고,상기 복수의 클래스 각각의 식별 빈도수에 기초하여 상기 복수의 클래스 중 적어도 하나에 대응되는 상기 메모리의 저장 공간의 크기를 변경하는, 영상 처리 장치."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 학습 네트워크 모델은,상기 식별 빈도수에 기초하여 기 설정된 횟수 미만으로 식별된 클래스에 대응되는 텍스처 패치를 상기 메모리로부터 삭제하고, 상기 텍스처 패치의 삭제에 따라 확보된 저장 공간을 나머지 클래스에 할당하는, 영상 처리 장치."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 복수의 클래스는, 평균 픽셀 값, 픽셀 좌표, 분산, 에지 강도, 에지 방향 또는 색상 중 적어도 하나를 기준으로 구분되는, 영상처리 장치."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 프로세서는, 상기 획득된 텍스처 패치 및 상기 픽셀 블록 간 상관 관계(correlation)에 기초하여 상기 텍스처 패치에 대한가중치를 획득하고,상기 가중치가 적용된 텍스처 패치를 상기 픽셀 블록에 적용하여 상기 출력 영상을 획득하는, 영상 처리 장치."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2020-0116836-4-제1항에 있어서, 상기 출력 영상은, 4K UHD(Ultra High Definition) 영상 또는 8K UHD 영상인, 영상 처리 장치."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "영상 처리 장치의 영상 처리 방법에 있어서,입력 영상을 학습 네트워크 모델에 적용하여 상기 입력 영상에 포함된 픽셀 블록에 대응되는 텍스처 패치를 상기 픽셀 블록에 적용하여 출력 영상을 획득하는 단계;를 포함하고,상기 학습 네트워크 모델은,영상의 특성에 기초하여 분류된 복수의 클래스 각각에 대응되는 텍스처 패치를 저장하며,상기 입력 영상에 기초하여 상기 복수의 클래스 각각에 대응되는 텍스처 패치를 학습하는, 영상 처리 방법."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 학습 네트워크 모델은, 상기 픽셀 블록의 특성에 기초하여 상기 복수의 클래스 중 하나를 식별하고, 상기 식별된 클래스에 대응되는 텍스처 패치를 출력하며, 상기 픽셀 블록과 상기 식별된 클래스 간의 제1 유사도 및 상기 텍스처 패치와 상기 식별된 클래스 간의 제2 유사도를 비교하여 상기 텍스처 패치를 업데이트할지 여부를 식별하는, 영상 처리 방법."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 학습 네트워크 모델은,상기 제1 및 제2 유사도에 상기 식별된 클래스에 대응되는 텍스처 패치를 상기 픽셀 블록으로 대체하거나, 상기픽셀 블록을 상기 식별된 클래스에 대응되는 텍스처 패치로 추가하는, 영상 처리 방법."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 학습 네트워크 모델은, 상기 비교 결과에 기초하여 상기 제1 유사도가 상기 제2 유사도 보다 작은 값이면, 상기 식별된 클래스에 대응되는 상기 텍스처 패치를 유지하고, 상기 비교 결과에 기초하여 상기 제1 유사도가 상기 제2 유사도 보다 큰 값이면, 상기 픽셀 블록에 기초하여 상기 텍스처 패치를 업데이트하는, 영상 처리 방법."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,상기 학습 네트워크 모델은, 상기 식별된 클래스에 대응되는 텍스처 패치가 복수 개인 경우, 상기 픽셀 블록 및 상기 복수 개의 텍스처 패치각각의 상관 관계(correlation)에 기초하여 상기 복수 개의 텍스처 패치 중 어느 하나를 식별하는, 영상 처리방법."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서,공개특허 10-2020-0116836-5-상기 학습 네트워크 모델은, 상기 복수의 클래스 각각에 대응되는 텍스처 패치의 저장 시기 또는 상기 텍스처 패치의 적용 빈도수 중 적어도하나에 기초하여 상기 텍스처 패치를 학습하는, 영상 처리 방법."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제13항에 있어서,상기 학습 네트워크 모델은, 상기 픽셀 블록의 특성에 기초하여 상기 픽셀 블록이 상기 복수의 클래스 중 어느 하나에 대응되지 않는 것으로식별되면, 상기 픽셀 블록의 특성에 기초하여 신규 클래스를 생성하고 상기 신규 클래스에 상기 픽셀 블록을 맵핑하여 저장하는, 영상 처리 방법."}
{"patent_id": "10-2019-0080320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제13항에 있어서,상기 복수의 클래스는, 평균 픽셀 값, 픽셀 좌표, 분산, 에지 강도, 에지 방향 또는 색상 중 적어도 하나를 기준으로 구분되는, 영상처리 방법."}
{"patent_id": "10-2019-0080320", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "영상 처리 장치가 개시된다. 적어도 하나의 명령어를 저장하는 메모리 및 메모리와 전기적으로 연결된 프로세서 를 포함하고, 프로세서는, 명령어를 실행함으로써, 입력 영상을 학습 네트워크 모델에 적용하여 입력 영상에 포 함된 픽셀 블록에 대응되는 텍스처 패치를 픽셀 블록에 적용하여 출력 영상을 획득하며, 학습 네트워크 모델은, 영상의 특성에 기초하여 분류된 복수의 클래스 각각에 대응되는 텍스처 패치를 저장하며, 입력 영상에 기초하여 복수의 클래스 각각에 대응되는 텍스처 패치를 학습한다."}
{"patent_id": "10-2019-0080320", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상 처리 장치 및 그 제어 방법에 관한 것으로, 더욱 상세하게는 입력 영상의 텍스처 성분을 복원하 는 영상 처리 장치 및 그 영상 처리 방법에 관한 것이다. 또한, 본 발명은 학습 네트워크 모델을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 인공 지능 (Artificial Intelligence, AI) 시스템 및 그 응용에 관한 것이다."}
{"patent_id": "10-2019-0080320", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자 기술의 발달에 힘입어 다양한 유형의 전자기기가 개발 및 보급되고 있다. 특히, 가정, 사무실, 공공 장소 등 다양한 장소에서 이용되는 영상 처리 장치는 최근 수년 간 지속적으로 발전하고 있다. 최근 4K UHD TV 등의 고해상도 디스플레이 패널들이 출시되어 널리 보급되어 있다. 하지만, 아직 고품질의 고해 상도 컨텐츠는 많이 부족한 상황이다. 이에 저해상도 컨텐츠에서 고해상도 컨텐츠를 생성하기 위한 다양한 기술 이 요구되는 상황이다. 아울러, MPEG/H.264/HEVC 등의 영상 압축으로 인해 컨텐츠의 텍스처 손실이 발생될 수 있고 이에 따라 손실된 텍스처 성분을 복원하기 위한 기술이 요구되는 상황이다. 또한, 근래에는 인간 수준의 지능을 구현하는 인공 지능 시스템이 다양한 분야에서 이용되고 있다. 인공 지능 시스템은 기존의 룰(rule) 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공 지능 시스템은 사용할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 룰 기반 스마트 시스템은 점차 딥러닝 기반 인공 지능 시스템으로 대체되고 있다. 인공 지능 기술은 기계학습(예로, 딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 인공 지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 시각적 이해 는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 오브젝트 인식, 오브젝트 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간 의 경험정보를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임을 제어하는 기술로서, 움직임 제어(항법, 충돌, 주행), 조작 제어(행동 제어) 등을 포함한다. 한편, 종래의 영상 처리 장치는 손실된 텍스처 성분을 복원하기 위해 고정된 텍스처 패치를 적용하거나, 영상과 의 적합성이 떨어지는 텍스처 패치를 적용하는 문제가 있었다. 이에, 영상에 적합하게 텍스처를 생성하는 기술 에 대한 요구가 있었다."}
{"patent_id": "10-2019-0080320", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 필요성에 따른 것으로, 본 발명의 목적은, 입력 영상의 특성에 기초하여 학습된 텍스처 패치 를 이용하여 입력 영상의 세밀감(detail)을 향상시키는 영상 처리 장치 및 그 영상 처리 방법을 제공함에 있다."}
{"patent_id": "10-2019-0080320", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이상과 같은 목적을 달성하기 위한 본 개시의 일 실시 예에 따른 영상 처리 장치는, 적어도 하나의 명령어를 저 장하는 메모리 및 상기 메모리와 전기적으로 연결된 프로세서를 포함하고, 상기 프로세서는, 상기 명령어를 실 행함으로써, 입력 영상을 학습 네트워크 모델에 적용하여 상기 입력 영상에 포함된 픽셀 블록에 대응되는 텍스 처 패치를 획득하고, 상기 픽셀 블록에 상기 획득된 텍스처 패치를 적용하여 출력 영상을 획득하며, 상기 학습 네트워크 모델은, 영상의 특성에 기초하여 분류된 복수의 클래스 각각에 대응되는 텍스처 패치를 저장하며, 상 기 입력 영상에 기초하여 상기 복수의 클래스 각각에 대응되는 텍스처 패치를 학습한다. 여기서, 상기 학습 네트워크 모델은, 상기 픽셀 블록의 특성에 기초하여 상기 복수의 클래스 중 하나를 식별하 고, 상기 식별된 클래스에 대응되는 텍스처 패치를 출력하며, 상기 픽셀 블록과 상기 식별된 클래스 간의 제1 유사도 및 상기 텍스처 패치와 상기 식별된 클래스 간의 제2 유사도를 비교하여 상기 텍스처 패치를 업데이트할 지 여부를 식별할 수 있다. 또한, 상기 학습 네트워크 모델은, 상기 상기 제1 및 제2 유사도에 기초하여 상기 식별된 클래스에 대응되는 텍 스처 패치를 상기 픽셀 블록으로 대체하거나, 상기 픽셀 블록을 상기 식별된 클래스에 대응되는 텍스처 패치로 추가할 수 있다. 또한, 상기 학습 네트워크 모델은, 상기 비교 결과에 기초하여 상기 제1 유사도가 상기 제2 유사도 보다 작은 값이면, 상기 식별된 클래스에 대응되는 상기 텍스처 패치를 유지하고, 상기 비교 결과에 기초하여 상기 제1 유 사도가 상기 제2 유사도 보다 큰 값이면, 상기 픽셀 블록에 기초하여 상기 텍스처 패치를 업데이트할 수 있다. 또한, 상기 학습 네트워크 모델은, 상기 식별된 클래스에 대응되는 텍스처 패치가 복수 개인 경우, 상기 픽셀 블록 및 상기 복수 개의 텍스처 패치 각각의 상관 관계(correlation)에 기초하여 상기 복수 개의 텍스처 패치 중 어느 하나를 식별할 수 있다. 또한, 상기 학습 네트워크 모델은, 상기 복수의 클래스 각각에 대응되는 텍스처 패치의 저장 시기 또는 상기 텍 스처 패치의 적용 빈도수 중 적어도 하나에 기초하여 상기 텍스처 패치를 학습할 수 있다. 또한, 상기 학습 네트워크 모델은, 상기 픽셀 블록의 특성에 기초하여 상기 픽셀 블록이 상기 복수의 클래스 중 어느 하나에 대응되지 않는 것으로 식별되면, 상기 픽셀 블록의 특성에 기초하여 신규 클래스를 생성하고 상기 신규 클래스에 상기 픽셀 블록을 맵핑하여 저장할 수 있다. 또한, 상기 복수의 클래스는, 평균 픽셀 값, 픽셀 좌표, 분산, 에지 강도, 에지 방향 또는 색상 중 적어도 하나 를 기준으로 구분될 수 있다. 또한, 상기 프로세서는, 상기 획득된 텍스처 패치 및 상기 픽셀 블록 간 상관 관계(correlation)에 기초하여 상 기 텍스처 패치에 대한 가중치를 획득하고, 상기 가중치가 적용된 텍스처 패치를 상기 픽셀 블록에 적용하여 상 기 출력 영상을 획득할 수 있다. 또한, 상기 출력 영상은, 4K UHD(Ultra High Definition) 영상 또는 8K UHD 영상일 수 있다. 한편, 본 개시의 일 실시 예에 따른 영상 처리 장치의 영상 처리 방법은, 입력 영상을 학습 네트워크 모델에 적 용하여 상기 입력 영상에 포함된 픽셀 블록에 대응되는 텍스처 패치를 획득하는 단계 및 상기 픽셀 블록에 상기 획득된 텍스처 패치를 적용하여 출력 영상을 획득하는 단계를 포함하고, 상기 학습 네트워크 모델은, 영상의 특 성에 기초하여 분류된 복수의 클래스 각각에 대응되는 텍스처 패치를 저장하며, 상기 입력 영상에 기초하여 상 기 복수의 클래스 각각에 대응되는 텍스처 패치를 학습한다. 여기서, 상기 학습 네트워크 모델은, 상기 픽셀 블록의 특성에 기초하여 상기 복수의 클래스 중 하나를 식별하 고, 상기 식별된 클래스에 대응되는 텍스처 패치를 출력하며, 상기 픽셀 블록과 상기 식별된 클래스 간의 제1 유사도 및 상기 텍스처 패치와 상기 식별된 클래스 간의 제2 유사도를 비교하여 상기 텍스처 패치를 업데이트할 지 여부를 식별할 수 있다. 여기서, 상기 학습 네트워크 모델은, 상기 제1 및 제2 유사도에 기초하여 상기 식별된 클래스에 대응되는 텍스 처 패치를 상기 픽셀 블록으로 대체하거나, 상기 픽셀 블록을 상기 식별된 클래스에 대응되는 텍스처 패치로 추 가할 수 있다. 또한, 상기 학습 네트워크 모델은, 상기 비교 결과에 기초하여 상기 제1 유사도가 상기 제2 유사도 보다 작은 값이면, 상기 식별된 클래스에 대응되는 상기 텍스처 패치를 유지하고, 상기 비교 결과에 기초하여 상기 제1 유 사도가 상기 제2 유사도 보다 큰 값이면, 상기 픽셀 블록에 기초하여 상기 텍스처 패치를 업데이트할 수 있다. 또한, 상기 학습 네트워크 모델은, 상기 식별된 클래스에 대응되는 텍스처 패치가 복수 개인 경우, 상기 픽셀 블록 및 상기 복수 개의 텍스처 패치 각각의 상관 관계(correlation)에 기초하여 상기 복수 개의 텍스처 패치 중 어느 하나를 식별할 수 있다. 또한, 상기 학습 네트워크 모델은, 상기 복수의 클래스 각각에 대응되는 텍스처 패치의 저장 시기 또는 상기 텍 스처 패치의 적용 빈도수 중 적어도 하나에 기초하여 상기 텍스처 패치를 학습할 수 있다. 또한, 상기 학습 네트워크 모델은, 상기 픽셀 블록의 특성에 기초하여 상기 픽셀 블록이 상기 복수의 클래스 중 어느 하나에 대응되지 않는 것으로 식별되면, 상기 픽셀 블록의 특성에 기초하여 신규 클래스를 생성하고 상기 신규 클래스에 상기 픽셀 블록을 맵핑하여 저장할 수 있다. 또한, 상기 학습 네트워크 모델은, 상기 입력 영상에 포함된 복수의 픽셀 블록 각각에 대응되는 클래스를 식별 하고, 상기 복수의 클래스 각각의 식별 빈도수에 기초하여 상기 복수의 클래스 중 적어도 하나에 대응되는 상기 메모리의 저장 공간의 크기를 변경할 수 있다. 여기서, 상기 학습 네트워크 모델은, 상기 식별 빈도수에 기초하여 기 설정된 횟수 미만으로 식별된 클래스에 대응되는 텍스처 패치를 상기 메모리로부터 삭제하고, 상기 텍스처 패치의 삭제에 따라 확보된 저장 공간을 나 머지 클래스에 할당할 수 있다. 또한, 상기 복수의 클래스는, 평균 픽셀 값, 픽셀 좌표, 분산, 에지 강도, 에지 방향 또는 색상 중 적어도 하나 를 기준으로 구분될 수 있다. 또한, 상기 출력 영상을 획득하는 단계는, 상기 획득된 텍스처 패치 및 상기 픽셀 블록 간 상관 관계 (correlation)에 기초하여 상기 텍스처 패치에 대한 가중치를 획득하는 단계 및 상기 가중치가 적용된 텍스처 패치를 상기 픽셀 블록에 적용하여 상기 출력 영상을 획득하는 단계를 포함할 수 있다. 또한, 상기 출력 영상은, 4K UHD(Ultra High Definition) 영상 또는 8K UHD 영상일 수 있다. 또한, 본 개시의 일 실시 예에 따른 영상 처리 장치의 프로세서에 의해 실행되는 경우 상기 영상 처리 장치가 동작을 수행하도록 하는 컴퓨터 명령을 저장하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 동작은, 입력 영상을 학습 네트워크 모델에 적용하여 상기 입력 영상에 포함된 픽셀 블록에 대응되는 텍스처 패치를 획득하는 단계 및 상기 픽셀 블록에 상기 획득된 텍스처 패치를 적용하여 출력 영상을 획득하는 단계를 포함하고, 상기 학습 네트워크 모델은, 영상의 특성에 기초하여 분류된 복수의 클래스 각각에 대응되는 텍스처 패치를 저장하며, 상기 입력 영상에 기초하여 상기 복수의 클래스 각각에 대응되는 텍스처 패치를 학습한다."}
{"patent_id": "10-2019-0080320", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이 본 개시의 다양한 실시 예에 따르면, 영상의 특성에 기초하여 학습된 텍스처 패치를 이용한 텍스처 생성을 통해 영상 전체의 세밀감을 향상시킬 수 있게 된다."}
{"patent_id": "10-2019-0080320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수 치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. A 또는/및 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다. 본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프로세서(미도시)로 구현될 수 있다. 본 명세서에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전자 장치)를 지칭할 수 있다. 이하 첨부된 도면들을 참조하여 본 개시의 일 실시예를 보다 상세하게 설명한다. 도 1은 본 개시의 일 실시 예에 따른 영상 처리 장치의 구현 예를 설명하기 위한 도면이다. 영상 처리 장치는 도 1에 도시된 바와 같이 TV로 구현될 수 있으나, 이에 한정되는 것은 아니며 스마트 폰, 태블릿 PC, 노트북 PC, HMD(Head mounted Display), NED(Near Eye Display), LFD(large format display), Digital Signage(디지털 간판), DID(Digital Information Display), 비디오 월(video wall), 프로젝터 디스플 레이 등과 같이 디스플레이 기능을 갖춘 장치라면 한정되지 않고 적용 가능하다. 영상 처리 장치는 다양한 해상도의 영상 또는 다양한 압축 영상을 수신할 수 있다. 예를 들어, 영상 처리 장치는 SD(Standard Definition), HD(High Definition), Full HD, Ultra HD 영상 중 어느 하나의 영상을 수신할 수 있다. 또한 영상 처리 장치는 MPEG(예를 들어, MP2, MP4, MP7 등), AVC, H.264, HEVC 등으로 압축된 형태로 영상을 수신할 수도 있다. 일 실시 예에 따라 영상 처리 장치가 UHD TV로 구현더라도, UHD 컨텐츠 자체가 부족하기 때문에 SD(Standard Definition), HD(High Definition), Full HD 등의 영상(이하 저해상도 영상이라 함)이 입력되는 경우가 많다. 이 경우, 입력된 저해상도 영상을 UHD 영상(이하 고해상도 영상이라 함)으로 확대하여 제공하는 방법을 이용할 수 있다. 하지만, 영상의 확대 과정에서 영상의 텍스처(texture)가 블러(Blur)되어 세밀감이 저 하되는 문제가 있다. 여기서, 영상의 텍스처는 영상 중에서 동일한 피쳐(feature)로 간주되는 영역의 특유의 무 늬 또는 모양을 의미한다. 다른 실시 예에 따라 고해상도 영상이 입력되더라도 영상 압축 등으로 인해 텍스처의 손실이 발생되어 세밀감이 떨어지는 문제가 있다. 디지털 영상은 화소 수가 증가할수록 더 많은 데이터를 필요로 하게 되며, 대용량 데이 터를 압축하게 되는 경우 압축으로 인한 텍스처의 손실은 불가피하기 때문이다. 따라서, 이하에서는 상술한 바와 같이 다양한 경우에 있어 손실된 텍스처 성분을 복원하여 영상의 세밀감을 향 상시키는 다양한 실시 예에 대해 설명하도록 한다. 도 2는 본 개시의 일 실시 예에 따른 영상 처리 장치의 구성을 나타내는 블록도다. 도 2에 따르면, 영상 처리 장치는 메모리 및 프로세서를 포함한다. 메모리는 프로세서와 전기적으로 연결되며, 본 개시의 다양한 실시 예를 위해 필요한 데이터를 저장 할 수 있다. 예를 들어, 메모리는 프로세서에 포함된 롬(ROM)(예를 들어, EEPROM(electrically erasable programmable read-only memory)), 램(RAM) 등의 내부 메모리로 구현되거나, 프로세서와 별도의 메모리로 구현될 수도 있다. 이 경우, 메모리는 데이터 저장 용도에 따라 영상 처리 장치에 임베디드 된 메모리 형태로 구현되거나, 영상 처리 장치에 탈부착이 가능한 메모리 형태로 구현될 수도 있다. 예를 들어, 영상 처리 장치의 구동을 위한 데이터의 경우 영상 처리 장치에 임베디드된 메모리에 저장되고, 영상 처리 장치의 확장 기능을 위한 데이터의 경우 영상 처리 장치에 탈부착이 가능한 메 모리에 저장될 수 있다. 한편, 영상 처리 장치에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non- volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메 모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나로 구현되고, 영상 처리 장치에 탈부착이 가능한 메모리의 경우 메모리 카드 (예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구현될 수 있다. 일 실시 예에 따라 메모리는 입력 영상에 포함된 픽셀 블록에 대응되는 텍스처 패치를 획득하기 위해 이용되는 학습 네트워크 모델을 저장할 수 있다. 여기서, 학습 네트워크 모델은 복수의 영상에 기초하여 기계 학습(Machine Learning)된 모델일 수 있다. 예를 들어, 학습 네트워크 모델은 복수의 샘플 영상 및 입력 영상 에 기초하여 CNN(Convolution Neural Network, 컨벌루션 신경망) 학습된 모델일 수 있다. 여기서, CNN은음성처리, 이미지 처리 등을 위해 고안된 특수한 연결구조를 가진 다층신경망이다. 특히, CNN은 픽셀에 전처리 를 통하여 이미지를 다양하게 필터링하고, 이미지의 특성을 인식할 수 있다. 일 예로, 입력 영상에 포함된 기 설정된 크기의 픽셀 블록의 특성을 인식할 수 있다. 한편, 학습 네트워크 모델은 CNN에 한정되지 않음은 물 론이다. 예를 들어, 영상 처리 장치는 RNN(Recurrent Neural Network), DNN(Deep Neural Network) 등 다 양한 신경망(Neural Network)에 기반한 학습 네트워크 모델을 이용할 수 있음은 물론이다. 한편, “텍스처 패치”는 픽셀 블록의 텍스처를 향상시키기 위해 해당 픽셀 블록에 적용되는 패치를 의미할 수 있다. 여기서, \"패치\"는 기능을 고려하여 편의상 적용된 용어이므로, 패치라는 용어 이외에 다양한 용어가 본 실시 예에 적용될 수 있다. 예를 들면, 각 패치는 복수의 패치 값이 픽셀 단위의 행렬 형태로 배열된 구조를 가 지는 바, 이러한 형태를 고려하여 마스크(mask)로 지칭될 수도 있다. 후술하는 바와 같이, 텍스처 패치가 해당 픽셀 블록에 적용됨에 따라, 픽셀 블록의 텍스처가 향상되고 세밀감이 증대될 수 있다. 한편, 영상 처리 장치 는 픽셀 블록의 특성에 관계 없이 픽셀 블록에 이미 정해진텍스처 패치를 적용하는 것이 아니라, 학습 네 트워크 모델을 이용하여 업데이트된텍스처 패치를 적용할 수 있다. 프로세서는 메모리와 전기적으로 연결되어 영상 처리 장치의 전반적인 동작을 제어한다. 일 실시 예에 따라 프로세서는 디지털 영상 신호를 처리하는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프로세서(microprocessor), T-CON(Timing controller)으로 구현될 수 있다. 다만, 이에 한정되는 것은 아니며, 중앙처리장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), 컨트롤러(controller), 어플리케이션 프로세서(application processor(AP)), 또 는 커뮤니케이션 프로세서(communication processor(CP)), ARM 프로세서 중 하나 또는 그 이상을 포함하거나, 해당 용어로 정의될 수 있다. 또한, 프로세서는 프로세싱 알고리즘이 내장된 SoC(System on Chip), LSI(large scale integration)로 구현될 수도 있고, FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 프로세서는 입력 영상을 영상 처리하여 출력 영상을 획득한다. 구체적으로, 프로세서는 입력 영상에 텍스처 향상 처리를 수행하여 출력 영상을 획득할 수 있다. 여기서, 출력 영상은 UHD(Ultra High Definition) 영상 특히, 4K UHD 영상 또는 8K UHD 영상일 수 있으나, 이에 한정되는 것은 아니다. 특히, 본 개시의 일 실시 예에 따른 프로세서는 텍스처 향상 처리에 이용될 텍스처 패치를 획득할 수 있다. 구체적으로, 프로세서는 입력 영상을 학습 네트워크 모델에 적용하여 입력 영상에 포함된 픽셀 블록에 대응되는 텍스처 패치를 획득할 수 있다. 여기서, 픽셀 블록은 적어도 하나의 픽셀을 포함하는 인 접한 픽셀들의 집합을 의미한다. 도 3은 본 개시의 일 실시 예에 따른 픽셀 블록을 설명하기 위한 도면이다. 도 3을 참조하면, 프로세서는 입력 영상을 구성하는 영상 프레임에 있어서, 영상 프레임에 포함된 복 수의 픽셀을 픽셀 블록 단위로 구분하여 학습 네트워크 모델에 입력할 수 있다. 일 실시 예에 따라, 프로세 서는 영상 프레임을 구성하는 복수의 픽셀 블록을 순차적으로 학습 네트워크 모델에 입력할 수 있다. 이어서, 학습 네트워크 모델은 입력되는 복수의 픽셀 블록(20-1, ... 20-n) 각각에 대응되는 텍스처 패치(30-1, ... 30-n)를 출력할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는 입력 영상을 5*5 크기의 픽셀 블록으로 식별할 수 있으 나, 픽셀 블록의 크기는 이에 한정되는 것은 아니며, 3*3, 4*4 등 N*N 형태의 다양한 크기로 구현 가능하다. 예 를 들어, 프로세서는 영상 처리의 목적, 입력 영상의 해상도(예를 들어, FHD), 출력 영상의 해상도 (UHD, 8K) 등에 따라 입력 영상을 다양한 크기의 픽셀 블록으로 구분할 수 있음은 물론이다. 이하에서 는, 설명의 편의를 위해 입력 영상을 구성하는 영상 프레임에서 행렬 형태로 배열된 구조의 기 설정된 크기 의 픽셀 그룹을 입력 영상에서 획득된 픽셀 블록으로 상정하여 설명하도록 한다. 도 2로 돌아와서, 본 개시의 일 실시 예에 따른 프로세서는 입력 영상을 학습 네트워크 모델을 적용하 여 픽셀 블록에 대응되는 텍스처 패치를 획득할 수 있다. 이에 대한 구체적인 설명은 도 4를 참조하여 하도 록 한다. 도 4는 본 개시의 일 실시 예에 따른 텍스처 패치를 설명하기 위한 도면이다. 도 4는 입력 영상을 구성하는 픽셀들 각각을 픽셀 값으로 표현한 도면이다. 본 개시의 일 실시 예에 따른 프로세서는 입력 영상을 학습 네트워크 모델을 적용하여 픽셀 블록에 대응되는 텍스처 패치를획득할 수 있다. 여기서, 적용이란 입력 영상을 학습 네트워크 모델에 입력하는 것을 의미하며, 학습 네트 워크의 출력이 텍스처 패치가 될 수 있다. 여기서, 학습 네트워크 모델은, 입력 영상에 포함된 픽셀 블록에 대응되는 텍스처 패치를 출력할 수 있고, 픽셀 블록에 기초하여 학습을 수행할 수 있다. 일 실시 예에 따른 학습 네트워크 모델은 영상의 다양한 특성 중 어느 하나를 기준으로 분류된 복수의 클래스를 포함할 수 있고, 복수의 클래스 각각에 대응되는 텍스처 패치를 포함할 수 있다. 예를 들어, 학습 네트워크 모델은 영상의 특성 중 에지 방향에 기초하여 분류된 복수의 클래스를 저장할 수 있고, 복수의 클래스 각각에 매칭된 텍스처 패치를 포함할 수 있다. 다른 예로, 학습 네트워크 모델은 영상의 특성 중 픽셀 블록 단 위의 계조 평균 값에 기초하여 분류된 복수의 클래스를 저장할 수 있고, 복수의 클래스 각각에 매칭된 텍스처 패치를 포함할 수 있다. 한편, 본 개시의 일 실시 예에 따른 영상 처리 장치는 복수의 학습 네트워크 모델을 포함할 수 있음은 물 론이다. 일 예로, 영상 처리 장치는 에지 방향을 기준으로 클래스를 구분하고, 텍스처 패치에 대한 학 습을 수행하는 제1 학습 네트워크 모델, 계조 평균 값을 기준으로 클래스를 구분하고, 학습을 수행하는 제2 학 습 네트워크 모델, 색 좌표를 기준으로 클래스를 구분하고, 학습을 수행하는 제3 학습 네트워크 모델 등 복수의 학습 네트워크 모델을 포함할 수 있다. 일 실시 예에 따른 영상 처리 장치는 입력 영상의 특성에 기초 하여 복수의 학습 네트워크 모델 중 어느 하나를 식별하고, 식별된 학습 네트워크 모델을 입력 영상에 적용 하여 텍스처 패치를 획득할 수 있다. 예를 들어, 영상 처리 장치는 복수의 학습 네트워크 모델 중 입 력 영상의 특성에 기초하여 적합한 텍스처 패치 획득을 위한 어느 하나의 학습 네트워크 모델을 식별하 는 전(前)처리 학습 네트워크 모델을 포함할 수 있다. 전처리 학습 네트워크 모델은 영상의 특성에 기초하여 예 를 들어, 입력 영상을 구성하는 복수의 픽셀들 색상이 유사 색상 내에 분포되어 있다면, 복수의 학습 네트 워크 모델 중 에지 방향을 기준으로 클래스를 구분하고, 텍스처 패치를 출력하는 제1 학습 네트워크 모델을 식별할 수 있다. 본 개시의 일 실시 예에 따른 학습 네트워크 모델은 입력 영상에 기초하여 학습을 수행할 수 있다. 예를 들 어, 학습 네트워크 모델은 입력 영상에 포함된 픽셀 블록에 대응되는 클래스에 대한 해당 픽셀 블록 의 제1 유사도를 식별하고, 클래스에 대한 해당 클래스에 매칭된 텍스처 패치의 제2 유사도를 식별할 수 있다. 이어서, 제1 및 제2 유사도에 기초하여 텍스처 패치의 업데이트 여부를 식별할 수 있다. 예를 들 어, 학습 네트워크 모델은 제1 유사도가 제2 유사도 보다 크면, 획득된 텍스처 패치가 해당 입력 영상 의 텍스처 향상에 적합하지 않은 것으로 판단하고, 입력 영상의 픽셀 블록에 기초하여 업데이트를 수행 할 수 있다. 학습 네트워크 모델은 입력 영상을 구성하는 다양한 픽셀 블록들 중 해당 픽셀 블록와 동 일한 클래스에 속하는 타 픽셀 블록(20’)에 대응되는 텍스처 패치를 출력함에 있어서, 업데이트 전 텍스처 패치가 아닌, 픽셀 블록에 기초하여 업데이트 된 텍스처 패치(30’)를 출력할 수 있다. 이에 따라, 학 습 네트워크 모델이 출력하는 텍스처 패치는 입력 영상의 텍스처 향상에 적합할 수 있다. 다른 예로, 학습 네트워크 모델은 제2 유사도가 제1 유사도보다 크면, 획득된 텍스처 패치가 해당 입력 영상의 텍 스처 향상에 적합한 것으로 판단하고, 텍스처 패치를 유지할 수 있다. 한편, 본 개시의 일 실시 예에 따른 복수의 클래스 중 픽셀 블록에 대응되는 클래스를 구분(또는, 식별)하 는 학습 네트워크 모델의 동작은 분류기(Classifier), 클래스 식별기 등으로 지칭될 수 있다. 여기서, 분류기는 입력 영상에 포함된 픽셀 블록이 입력되면, 복수의 클래스 중 픽셀 블록에 적합한 클래스를 식별할 수 있다. 예를 들어, 분류기는 픽셀 블록의 에지 방향을 식별하고, 식별된 에지 방향과 복수의 클래스 각각 을 정의하는 에지 방향 간의 유사도를 식별할 수 있다. 이어서, 분류기는 복수의 클래스 중 유사도가 가장 큰 하나의 클래스를 해당 픽셀 블록에 대응되는 클래스로 식별할 수 있다. 본 개시의 일 실시 예에 따른 학습 네트워크 모델은 픽셀 블록에 대응되는 클래스를 식별하는 모델(예를 들 어, 분류기 모델) 및 픽셀 블록과 해당 픽셀 블록에 대응되는 텍스처 패치의 유사도를 비교하여 텍 스처 패치에 대한 자가 학습(Self-Learning)을 수행하는 모델의 결합을 의미할 수 있다. 일 실시 예에 따른 학습 네트워크 모델은 외부 장치에 의존하지 않고 영상 처리 장치 자체적으로 학습을 수행하는 온 디바이 스 머신 러닝 모델(On-device Machine Learning Model)일 수 있다. 한편, 이는 일 실시 예이고, 학습 네트워크 모델은 분류기 모델은 온 디바이스(On-device) 기반으로 동작하고, 텍스처 패치에 대한 학습을 수행하는 모델은 외부 서버 기반으로 동작하는 형태로 구현될 수도 있음은 물론이다. 이에 따라 학습 네트워크 모델은 영상의 특성에 기초하여 분류 및 학습된 복수의 클래스 각각에 대응되는 텍스 처 패치를 저장할 수 있다. 학습 네트워크 모델은 입력 영상에 대응되는 텍스처 패치를 출력함과 동시 에, 입력 영상에 포함된 픽셀 값에 기초하여 복수의 클래스 각각에 대응되는 텍스처 패치를 학습할 수 있다. 도 4를 참조하면, 학습 네트워크 모델은 픽셀 블록의 특성에 기초하여 복수의 클래스 중 해당 픽셀 블록 에 대응되는 하나의 클래스를 식별할 수 있다. 예를 들어, 학습 네트워크 모델은 영상의 다양한 특성 중 에 지(edge) 방향(또는, 에지 패턴)에 기초하여 분류된 복수의 클래스를 저장할 수 있다. 여기서, 에지는 픽셀 값 (또는, 픽셀의 밝기)이 낮은 값에서 높은 값 또는 높은 값에서 낮은 값으로 변하는 지점을 의미할 수 있다. 에 지는 영상에 포함된 다양한 오브젝트에 따라 생성되는 오브젝트 간의 경계선을 의미할 수도 있다. 일 예에 따른 학습 네트워크 모델은 복수의 클래스 중 픽셀 블록의 에지 방향(또는, 경계선의 방향)에 대응되는 하나의 클래스를 식별할 수 있다. 또한, 학습 네트워크 모델은 복수의 클래스 중 픽셀 블록의 에지 방향과 가장 유 사한(또는, 가장 적합한) 하나의 클래스를 식별할 수 있다. 이어서, 학습 네트워크 모델은 식별된 클래스에 대 응되는 텍스처 패치를 출력할 수 있다. 도 2로 돌아와서, 본 개시의 일 실시 예에 따른 프로세서는 학 습 네트워크 모델로부터 출력된 텍스처 패치를 입력 영상에 적용하여 텍스처 향상 처리를 수행할 수 있다. 도 5는 본 개시의 일 실시 예에 따른 학습 네트워크 모델을 설명하기 위한 도면이다. 본 개시의 일 실시 예에 따른 학습 네트워크 모델은 영상의 특성에 기초하여 분류된 복수의 클래스 및 복수의 클래스 각각에 대응되는 적어도 하나의 텍스처 패치를 저장할 수 있다. 도 5를 참조하면, 학습 네트워크 모델은 영상의 특성 중 에지 방향을 기준으로 분류된 제1 내지 제n 클래스를 포함할 수 있다. 또한, 학습 네트워크 모 델은 제1 내지 제n 클래스 각각에 대응되는 텍스처 패치를 포함할 수 있다. 여기서, 영상의 특성은 픽셀 블록 에 포함된 픽셀 값들의 평균, 분산, 픽셀 좌표, 에지 강도, 에지 방향 또는 색상 중 적어도 하나를 의미할 수 있다. 따라서, 일 실시 예에 따른 학습 네트워크 모델은 픽셀 값들의 평균, 분산, 픽셀 좌표, 에지 강도, 에 지 방향 또는 색상 중 적어도 하나를 기준으로 구분된 복수의 클래스를 포함할 수 있다. 한편, 학습 네트워크 모델은 상술한 예시 외에, 픽셀 블록으로부터 식별 가능한 다양한 특징에 기초하여 복수의 클래스를 생성할 수 있고, 해당 픽셀 블록이 복수의 클래스 중 어느 클래스에 대응되는지 여부를 식별할 수 있음은 물론이다. 예를 들어, 학습 네트워크 모델은 색 좌표를 기준으로 클래스를 구분할 수 있고, 픽셀 블록에 포 함된 픽셀들의 색 좌표의 평균에 기초하여 해당 픽셀 블록에 대응되는 클래스를 식별할 수도 있다. 도 5를 참조하면, 일 실시 예에 따른 프로세서는 입력 영상을 구성하는 영상 프레임에 있어서, 영상 프레임에 포함된 복수의 픽셀을 픽셀 블록 단위로 구분하여 학습 네트워크 모델에 입력할 수 있다. 일 실시 예에 따라, 프로세서는 영상 프레임을 구성하는 복수의 픽셀 블록을 순차적으로 학습 네트워크 모델에 입력할 수 있다. 이어서, 학습 네트워크 모델은 입력되는 복수의 픽셀 블록(20-1, ... 20-n) 각각에 대응되는 텍스처 패치(30-1, ... 30-n)를 출력할 수 있다. 일 예로, 학습 네트워크 모델은 제1 픽셀 블록(20-1)의 특성에 기초하여 복수의 클래스 중 제1 픽셀 블록(20- 1)에 대응되는 클래스를 식별할 수 있다. 예를 들어, 학습 네트워크 모델은 제1 픽셀 블록(20-1)을 구성하는 픽 셀들에 기초하여 제1 픽셀 블록(20-1)의 에지 방향을 식별하고, 식별된 에지 방향이 복수의 클래스 중 어느 클 래스에 대응되는지 여부를 식별할 수 있다. 구체적으로, 학습 네트워크 모델은 복수의 클래스들과 제1 픽셀 블 록(20-1) 간 유사도를 식별할 수 있다. 예를 들어, 학습 네트워크 모델은 제1 픽셀 블록(20-1)의 에지 방향이 0 °이면, 제2 내지 제8 클래스(Class #2 - Class #8) 대비 제1 클래스(Class #1)에서 높은 유사도(또는, 적합도)를 획득할 수 있다. 여기서, 제1 클래스(Class#1)는 에지 방향 0°를 기준으로 정의된 클래스를 의미할 수 있다. 이어서, 학습 네트워크 모델은 제1 픽셀 블록(20-1)에 대응되는 클래스로 제1 클래스(Class #1)를 식 별할 수 있다. 이어서, 프로세서는 학습 네트워크 모델을 통해 제1 클래스(Class #1)에 대응되는 제1 텍스 처 패치(30-1)를 획득할 수 있다. 다른 예로, 제2 픽셀 블록(20-2)가 복수의 클래스 중 제2 클래스(Class #2)에 대응되는 것으로 식별되면, 학습 네트워크 모델은 제2 클래스(Class #2)에 대응되는 제2 텍스처 패치(30-2)를 제공할 수 있다. 한편, 도 5에서는 설명의 편의를 위해 학습 네트워크 모델이 에지 방향을 기준으로 구분된 제1 내지 제8 클래스 를 포함하고, 클래스들 각각이 하나의 텍스처 패치 즉, 제1 내지 제8 텍스처 패치(30-1, ... 30-8)를 포함하는 것으로 도시하였으나, 이에 한정되지 않음은 물론이다. 일 실시 예에 따른 학습 네트워크 모델은 픽셀 블록의 특성에 기초하여 해당 픽셀 블록이 복수의 클래스 중 어느 하나에 대응되지 않는 것으로 식별되면, 해당 픽셀 블록의 특성에 기초하여 신규 클래스를 생성하고,신규 클래스에 픽셀 블록을 맵핑하여 저장할 수 있다. 일 예로, 픽셀 블록과 복수의 클래스들 간의 유사도 가 모두 임계 값 미만이면, 학습 네트워크 모델은 픽셀 블록의 특성에 기초하여 복수의 클래스 외의 새로운 클래스를 생성할 수도 있다. 도 5를 참조하면, 일 실시 예에 따라 학습 네트워크 모델은 제1 내지 제8 클래스들과 제4 픽셀 블록(20-4) 간 유사도가 임계 값 미만이면, 즉, 제4 픽셀 블록(20-4)에 대응되는 클래스가 식별되지 않으면, 제4 픽셀 블록 (20-4)의 특성에 기초하여 제9 클래스를 생성할 수 있다. 예를 들어, 복수의 클래스가 에지 방향을 기준으로 분 류되어 있으면, 학습 네트워크 모델은 제4 픽셀 블록(20-4)을 구성하는 픽셀들의 에지 방향을 식별하고 식별된 에지 방향을 기준으로 제9 클래스를 생성할 수 있다. 이어서, 학습 네트워크 모델은 제4 픽셀 블록(20-4)을 제9 클래스에 맵핑하여 저장할 수 있다. 예를 들어, 학습 네트워크 모델은 새롭게 생성된 제9 클래스에 대응되는 텍 스처 패치로 제4 픽셀 블록(20-4)을 저장할 수 있다. 도 2로 돌아와서, 본 개시의 일 실시 예에 따른 학습 네트워크 모델은 픽셀 블록에 대응되는 클래스에 매칭 된 텍스처 패치가 식별되면, 픽셀 블록과 클래스와의 유사도, 텍스처 패치와 클래스와의 유사도에 기초하여 텍스처 패치의 업데이트 여부를 식별할 수 있다. 여기서, 학습 네트워크 모델은 클래스를 정의하 는 기준과 픽셀 블록 간의 유사도(또는, 적합도) 및 클래스를 정의하는 기준과 해당 클래스에 매칭된 텍스 처 패치 간의 유사도를 비교하여 업데이트 여부를 식별할 수 있다. 도 5를 참조하면, 학습 네트워크 모델은 에지 방향을 기준으로 분류된 복수의 클래스를 포함할 수 있다. 복수의 클래스 중 제1 클래스(Class#1)은 에지 방향이 0°로 정의된 클래스이고, 제5 클래스(Class#5)는 에지 방향이 90°로 정의된 클래스를 의미할 수 있다. 학습 네트워크 모델은 제1 픽셀 블록(20-1)이 입력되면, 제1 픽셀 블록(20-1)의 에지 방향에 기초하여 복수의 클래스 중 유사도가 가장 큰 제1 클래스(Class#1)를 식별할 수 있다. 이어서, 제1 클래스(Class#1)와 제1 픽셀 블록(20-1) 간 유사도와 제1 클래스(Class#1)와 제1 텍스처 패치(30-1) 간 유사도를 비교하여 제1 텍스처 패치 (30-1)의 업데이트 여부를 식별할 수 있다. 이에 대한 구체적인 설명은 도 6을 참조하여 하도록 한다. 도 6은 본 개시의 일 실시 예에 따른 클래스 및 텍스처 패치를 설명하기 위한 도면이다. 도 6을 참조하면, 학습 네트워크 모델은 픽셀 블록의 특성에 기초하여 복수의 클래스 중 픽셀 블록에 대응되는 클래스를 식별할 수 있다. 예를 들어, 픽셀 블록은 65°의 에지 방향을 포함하면, 학습 네트워크 모델은 제1 내지 제8 클래스(Class#1 - Class#8) 중 67.5°의 에지 방향으로 정의된 제4 클래스(Class #4)를 식별할 수 있다. 이어서, 학습 네트워크 모델은 식별된 제4 클래스(Class #4)에 대응되는 텍스처 패치를 획 득할 수 있다. 이어서, 학습 네트워크 모델은 픽셀 블록과 제4 클래스(Class#4)와의 유사도, 텍스처 패치와 제4 클래 스(Class#4)와의 유사도에 기초하여 텍스처 패치의 업데이트 여부를 식별할 수 있다. 여기서, 유사도는 다 양한 형태의 유사도 측정 알고리즘, 적합도 측정 알고리즘, 기계 학습 알고리즘을 이용하여 측정될 수 있음은 물론이다. 예를 들어, 계조 값에 기초하여 히스토그램을 비교하거나, 유클리디언 거리 등을 산출하여 유사도를 식별할 수 있고, 다른 예로 CNN(Convolution Neural Network) 학습된 알고리즘 모델에 기초하여 유사도를 식별 할 수도 있음은 물론이다. 예를 들어, 학습 네트워크 모델의 종래에 타 입력 영상(10’), 샘플 영상 등에 기초한 학습 결과에 따라 제4 클 래스(Class#4)에 매칭된 텍스처 패치의 에지 방향이 50°인 경우를 상정할 수 있다. 제4 클래스(Class#4)를 정의하는 에지 방향이 67.5°이므로, 학습 네트워크 모델은 65°의 에지 방향을 포함하는 픽셀 블록의 제1 유사도가 50°의 에지 방향을 포함하는 텍스처 패치의 제2 유사도 대비 큰 값을 가지며, 픽셀 블록이 제4 클래스(Class#4)에 적합한 것으로 식별할 수 있다. 학습 네트워크 모델은 픽셀 블록에 기초하여 텍스처 패치를 대체할 수 있다. 이어서, 학습 네트워크 모델은 입력 영상에 포함된 타 픽셀 블록(20’)이 입력 되고 타 픽셀 블록(20’)이 제4 클래스(Class#4)에 대응되면, 65°의 에지 방향을 포함하는 픽셀 블록에 기 초하여 업데이트된 텍스처 패치(30’)를 출력할 수 있다. 이어서, 프로세서는 텍스처 패치(30’)에 기초하 여 타 픽셀 블록(20’)의 텍스처를 생성할 수 있다. 다른 예로, 픽셀 블록에 대응되는 클래스와 해당 픽셀 블록 간 제1 유사도 보다 클래스와 해당 클래스에 매 칭된 텍스처 패치 간 제2 유사도가 큰 경우를 상정할 수도 있다. 이 경우, 학습 네트워크 모델은 텍스처 패 치가 입력 영상, 픽셀 블록의 텍스처 생성에 적합한 것으로 식별할 수 있고, 텍스처 패치를 그 대로 유지하는 할 수 있다.한편, 본 개시의 일 실시 예에 따라 학습 네트워크 모델은 입력 영상에 포함된 픽셀 블록에 대응되는 텍스처 패치를 획득하는 과정에서 해당 텍스처 패치를 업데이트하므로, 입력 영상의 텍스처 향상에 적합한 텍스처 패치를 포함하는 영상 처리 모델을 생성할 수 있다. 예를 들어, 숲, 잔디 등 오브젝트를 포함하는 입력 영상에 학습 네트워크 모델을 적용하면, 학습 네트워크 모델은 입력 영상을 구성하는 픽셀 블록와 클래스 간 유사도와 기 저장된 텍스처 패치와 클래스 간 유사도를 비교하여 기 저장된 텍스처 패치를 유지하거나 해당 픽셀 블록으로 기 저장된 텍스처 패치 를 대체할 수 있다. 일 실시 예에 따라, 입력 영상에 포함된 타 픽셀 블록(20’)에 학습 네트워크 모델 이 적용되면, 학습 네트워크 모델은 선행 과정에서 픽셀 블록에 기초하여 업데이트된 텍스처 패치(30’)를 식별할 수 있다. 이 경우, 업데이트된 텍스처 패치(30’)는 입력 영상으로부터 획득된 패치이므로, 동일한 입력 영상에 포함된 타 픽셀 블록(20’)과 높은 상관 관계, 높은 적합도를 가질 수 있다. 따라서, 프로세서 는 업데이트된 텍스처 패치(30’)를 타 픽셀 블록(20’)에 적용하여 텍스처가 생성되고 세밀감이 향상된 출력 영상을 획득할 수 있다. 도 2로 돌아와서, 본 개시의 일 실시 예에 따른 본 개시의 일 실시 예에 따른 학습 네트워크 모델은 복수의 클 래스 각각에 대응되는 텍스처 패치의 저장 시기 또는 텍스처 패치의 적용 빈도수 중 적어도 하나에 기 초하여 텍스처 패치를 학습할 수 있다. 일 예로, 학습 네트워크 모델은 입력 영상에 기초하여 텍스처 패치를 학습할 수 있고, 기 저장된 텍스 처 패치의 저장 시기를 추가로 고려할 수 있다. 예를 들어, 학습 네트워크 모델은 입력 영상에 포함된 픽셀 블록에 대응되는 텍스처 패치의 저장 시기가 일정 기간을 경과한 것으로 식별되면, 텍스처 패치 를 픽셀 블록으로 대체할 수 있다. 텍스처 패치의 저장 시기가 오래된 경우, 입력 영상과의 적 합도, 매칭 관계의 클래스와의 유사도가 떨어지는 것을 의미할 수 있으므로, 학습 네트워크 모델은 입력 영상 에 포함된 픽셀 블록에 기초하여 학습을 수행하고, 텍스처 패치를 업데이트할 수 있다. 학습 네트 워크 모델은 입력 영상에 포함된 픽셀 블록을 해당 픽셀 블록에 대응되는 클래스의 텍스처 패치 로 맵핑하고, 새롭게 맵핑된 텍스처 패치를 입력 영상의 텍스처를 생성하기 위해 이용할 수 있다. 다른 예로, 본 개시의 일 실시 예에 따른 학습 네트워크 모델은 픽셀 블록과 클래스 간 제1 유사도와 텍스 처 패치와 클래스 간 제2 유사도가 동일하면, 텍스처 패치의 저장 시점, 활용 빈도수 등에 기초하여 텍 스처 패치를 업데이트할 수도 있다. 예를 들어, 제1 및 제2 유사도가 동일하면, 입력 영상의 텍스처 생 성에 픽셀 블록이 기 저장된 텍스처 패치보다 적합할 수 있으므로, 픽셀 블록에 기초하여 텍스처 패치를 업데이트할 수 있다. 또 다른 예로, 제1 및 제2 유사도가 동일하면, 학습 네트워크 모델은 텍스처 패치 외에 픽셀 블록을 추가할 수도 있음은 물론이다. 다만, 이는 일 실시 예로 텍스처 패치의 저장 시기가 일정 기간을 경과하면 텍스처 패치가 반드시 업데 이트되어야 함을 의미하지는 않는다. 다른 예로, 학습 네트워크 모델은 텍스처 패치의 적용 빈도수에 기초하여 텍스처 패치를 학습할 수 있 다. 일 예로, 특정 텍스처 패치가 현재 입력 중인 영상 외에도 종래에 타 입력 영상(10’)의 텍스처 생 성을 위해 빈번하게 이용된 것으로 식별되면, 특정 텍스처 패치는 해당 클래스와의 적합도가 높고, 텍스처 생성에 유용하게 적용가능함을 의미할 수 있다. 이와 달리, 특정 텍스처 패치가 입력 영상의 텍스처 생 성에 이용된 빈도가 적은 것으로 식별되면, 학습 네트워크 모델은 텍스처 패치가 맵핑 관계의 클래스와 적 합도가 낮은 것으로 식별할 수 있다. 이 경우, 학습 네트워크 모델은 입력 영상에 포함된 픽셀 블록으 로 텍스처 패치를 대체할 수 있다. 예를 들어, 픽셀 블록의 특성에 기초하여 복수의 클래스 중 특정 클 래스가 해당 픽셀 블록에 대응되는 클래스임이 식별되고, 식별된 클래스에 대응되는 텍스처 패치의 저 장 시점이 일정 기간 경과하였거나 영상에의 적용 빈도수가 임계 횟수 미만이면, 학습 네트워크 모델은 해당 픽 셀 블록으로 텍스처 패치를 대체할 수 있다. 도 7은 본 개시의 일 실시 예에 따른 입력 영상을 학습하는 모델을 설명하기 위한 도면이다, 도 7을 참조하면, 학습 네트워크 모델은 복수의 클래스 중 일부 클래스에 대응되는 텍스처 패치를 저장하지 않을 수 있다. 예를 들어, 도 5에 도시된 바와 같이, 제1 내지 제8 클래스 각각에 대응되는 제1 내지 제8 텍스 처 패치(30-1, ... , 30-8)을 저장하는 것이 아니라, 복수의 클래스 중 일부 클래스는 맵핑 관계의 텍스처 패치 를 저장하고 있고, 나머지 클래스는 텍스처 패치를 저장하지 않을 수 있다. 이 경우, 학습 네트워크 모 델은 입력 영상에 기초하여 텍스처 패치를 획득 및 저장할 수 있다. 일 예로, 학습 네트워크 모델이 입력 영상에 포함된 픽셀 블록에 대응되는 클래스를 식별하고, 식별된 클래스에 대응되는 텍스처 패치 를 포함하지 않는 경우를 상정할 수 있다. 학습 네트워크 모델은 해당 픽셀 블록을 식별된 클래스에 맵 핑하여 저장할 수 있다. 한편, 클래스는 하나의 텍스처 패치만 포함하는 것으로 설명하였으나, 반드시 이에 한정되지 않는다. 예를 들어, 제1 클래스는 제1 클래스에 대응되는 적어도 두 개의 텍스처 패치를 포함할 수 있다. 일 실시 예에 따라 학습 네트워크 모델은 입력 영상에 포함된 픽셀 블록의 클래스를 식별하고, 식별된 클래스에 픽셀 블록을 텍스처 패치로 추가할 수 있다. 여기서, 학습 네트워크 모델은 종래에 기 저장된 텍스처 패치 를 삭제하거나, 대체하는 것이 아니라, 기 저장된 텍스처 패치를 제1 텍스처 패치로, 픽셀 블록를 제2 텍스처 패치로 하여 해당 클래스에 맵핑하여 저장할 수 있다. 일 실시 예에 따른 학습 네트워크 모델은 픽셀 블록에 대응되는 것으로 식별된 클래스에 대응되는 텍스처 패치가 복수 개 존재하면, 픽셀 블록과 복수 개의 텍스처 패치 각각의 상관 관계에 기초하여 복수 개의 텍스처 패치 중 어느 하나를 식별할 수 있다. 예를 들어, 픽셀 블록에 대응되는 클래스가 제4 클래스 이고, 제4 클래스와 맵핑 관계의 텍스처 패치가 제1 내지 제3 텍스처 패치인 경우를 상정할 수 있다. 학습 네트 워크 모델은 픽셀 블록과 제1 내지 제3 텍스처 패치 각각의 상관 관계를 식별하고, 식별된 상관 관계들 중 가장 높은 상관 값을 가지는 텍스처 패치를 식별할 수 있다. 가장 높은 상관 값을 가지는 텍스처 패치는 픽셀 블록 의 텍스처 생성에 가장 높은 적합도를 가지는 패치임을 의미할 수 있다. 이어서, 학습 네트워크 모델은 식 별된 텍스처 패치를 픽셀 블록에 적용하여 텍스처를 생성할 수 있다. 도 8은 본 개시의 다른 실시 예에 따른 클래스를 설명하기 위한 도면이다. 도 8을 참조하면, 일 실시 예에 따른 학습 네트워크 모델은 영상의 특성에 기초하여 픽셀 블록을 제1 내지 제16 클래스 중 어느 하나의 클래스로 분류할 수 있다. 이어서, 학습 네트워크 모델은 분류된 클래스와 맵핑 관 계의 텍스처 패치를 식별할 수 있다. 이어서, 식별된 텍스처 패치를 픽셀 블록에 적용할 수 있다. 한편, 학습 네트워크 모델은 다양한 기준에 따라 클래스를 구분할 수 있다. 또한, 클래스의 개수는 고정되거나 한정된 것이 아니며, 학습 네트워크 모델은 복수의 클래스 중 특정 클래스를 삭제하거나, 복수의 클래스 외의 추가 클래스를 생성할 수도 있음은 물론이다. 설명의 편의를 위해 에지 방향을 기준으로 클래스를 구분하고, 복수의 클래스 각각이 단일 텍스처 패치를 포함 하는 경우를 상정하여 설명하였으나, 이에 한정되지 않음은 물론이다. 예를 들어, 일 실시 예에 따른 학습 네트 워크 모델은 색 좌표의 분포를 기준으로 제1 내지 제n 클래스로 분류할 수 있고, 입력 영상에 포함된 픽셀 블록의 색 좌표 분포에 기초하여 제1 내지 제n 클래스 중 대응되는 클래스를 식별할 수 있다. 다른 예로, 학습 네트워크 모델은 평균 계조 값, 계조 값의 분산 등을 기준으로 제1 내지 제n 클래스로 분류할 수도 있음은 물론이다. 도 9는 본 개시의 일 실시 예에 따른 학습 결과를 설명하기 위한 도면이다. 도 9를 참조하면, 학습 네트워크 모델은 입력 영상을 구성하는 복수의 픽셀 블록 각각에 대응되는 텍스 처 패치를 제공하고, 프로세서는 텍스처 패치를 픽셀 블록에 적용하여 세밀감이 향상된 출력 영상을 획득할 수 있다. 학습 네트워크 모델이 입력 영상에 포함된 픽셀 블록에 기초하여 학습을 수행함에 따라 영상의 입 력 전과 후에 학습 네트워크 모델에 포함된 복수의 클래스 및 텍스처 패치가 상이할 수 있다. 예를 들어, 영상의 입력 전에 학습 네트워크 모델은 선행하여 입력된 타 영상 또는 샘플 영상에 기초하여 학습된 텍스처 패 치를 포함할 수 있다. 학습 네트워크 모델은 입력 영상에 포함된 픽셀 블록과 해당 픽셀 블록 에 대응되는 클래스 간의 유사도, 해당 클래스에 맵핑된 텍스처 패치와 클래스 간의 유사도를 식별하고, 식 별 결과에 기초하여 텍스처 패치를 업데이트 할 수 있다. 예를 들어, 학습 네트워크 모델은 픽셀 블록 으로 텍스처 패치를 대체하거나, 텍스처 패치를 유지할 수 있다. 도 9는 입력 영상에 기초한 학습 네트워크 모델의 학습 결과를 도시한 도면이다. 도 9를 참조하면, 학습 네 트워크 모델에 포함된 복수의 클래스 중 일부 클래스는 맵핑 관계의 텍스처 패치가 입력 영상에 포함된 픽셀 블록으로 대체되었다. 다른 예로, 복수의 클래스 중 나머지 클래스는 맵핑 관계의 텍스처 패치가 유지되었다. 도 5, 6, 7에서 픽셀 블록에 도시된 화살표는 해당 픽셀 블록에 대응되는 클래스를 도시한 것이고, 도 9에서 픽셀 블록에 도시된 화살표는 학습 네트워크 모델의 학습 결과에 따라 텍스처 패치가 해당 픽셀 블록으로 대체되었음을 의미한다. 예를 들어, 도 9를 참조하면, 클래스 2, 4, 6 각각에 대응되는 텍스처 패 치가 입력 영상에 포함된 픽셀 블록으로 대체되었다. 도 2로 돌아와서, 본 개시의 일 실시 예에 따른 프로세서는 텍스처 패치 및 픽셀 블록 간 상관 관 계에 기초하여 텍스처 패치에 대한 가중치를 획득할 수 있다. 이어서, 프로세서는 가중치가 적용된 텍 스처 패치(30’)를 픽셀 블록에 적용하여 출력 영상을 획득할 수 있다. 입력 영상에 포함된 픽셀 블록과 학습 네트워크 모델로부터 획득된 텍스처 패치 간 상관 관계 (correlation)(또는 상관도 또는 연관도) 는 일정한 수치로 계산되어 두 변량 x, y이 서로 관련성이 있다고 추 측되는 관계를 의미하며, 관계성의 정도는 상관 계수(correlation coefficient)라고 불리는 수치로 나타내어질 수 있다. 예를 들어, 상관 계수는 -1.0 에서 +1.0 사이의 수치로 표현될 수 있으며, 부호에 상관없이 숫자의 절 대값이 클수록 관련성이 더 크다고 볼 수 있다. 예를 들어, 음(-)의 값은 부적 상관을 나타내고, 양(+)의 값은 정적 상관을 나타낼 수 있다. 예를 들어, 해당 픽셀 블록에 포함된 픽셀 값 I = [i0, i1, ..., in-1], 텍스처 패치 R[n]에 포함된 값 R[n] = [r0, r1, ..., rn-1]라 하면, 상관 값 C[n]은 E[I*R[n]] = ii * ri로 획득될 수 있다. 또는, 대상 픽셀 블럭에 포함된 픽셀 값들의 평균을 m(I), 텍스처 패치 R[n]에 포함된 값들의 평균을 m(R[n])라 하면, 상관 값은 하기와 같은 수학식 1에 기초하여 획득될 수 있다. 수학식 1"}
{"patent_id": "10-2019-0080320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한편, 본 개시의 다른 실시 예에 따라, 텍스처 패치의 평균은 0일 수 있다. 텍스처 패치를 적용하여도 입력 영상 전체의 밝기가 변하지 않고 유지되도록 하기 위함이다. 일 실시 예에 따라, 텍스처 패치의 평균이 0이면, 수학식 1은 하기 수학식 2와 같이 유도될 수 있다. 수학식 2"}
{"patent_id": "10-2019-0080320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "본 개시의 일 실시 예에 따른 학습 네트워크 모델은 픽셀 블록과 해당 픽셀 블록에 대응되는 텍스처 패 치 간 상관 관계가 임계 값 이상이면, 해당 픽셀 블록의 클래스에 대응되는 텍스처 패치를 유지할 수 있다. 다른 예로, 학습 네트워크 모델은 픽셀 블록과 해당 픽셀 블록에 대응되는 텍스처 패치 간 상관 관계가 임계 값 미만이면, 해당 픽셀 블록에 기초하여 텍스처 패치를 업데이트 할 수 있다.. 다른 예로, 프로세서는 획득된 상관 값에 기설정된 비례 상수를 곱하여 획득된 값을 텍스처 패치에 대 응되는 가중치로서 획득할 수 있다. 예를 들어, 프로세서는 상관 값에 기초하여 0 내지 1 범위의 가중치를 획득할 수 있다. 일 예에 따라 상관 관계에 따라 텍스처 패치에 가중치 0을 적용하는 경우, 해당 텍스처 패 치는 대상 픽셀 블록에 더해지지 않게 된다. 예를 들어, 평탄한 영역이나 강한 에지(edge)가 포함된 영 역에서는 모든 클래스 및 모든 텍스처 패치에 대한 상관 관계가 매우 낮을 가능성이 높기 때문에 아무런 texture도 생기지 않게 된다. 이 경우, 에지 영역에서 발생할 수 있는 링잉 현상을 방지할 수 있고, 평탄한 영 역에 불필요한 텍스처가 더해지는 것을 방지할 수 있게 된다. 다만, 본 개시의 다른 실시 예에 따르면, 픽셀 블록과 텍스처 패치 간 유사도 정보는, 상술한 상관 관 계 외에, 다양한 비용 함수에 의해 획득될 수도 있다. 예를 들어, 유사성을 판단하는 비용 함수(cost functio n)로는 MSE(Mean Square Error), SAD(Sum of absolute difference), MAD(Median Absolute Deviation), correlation 등을 사용할 수 있다. 예를 들어, MSE를 적용하는 경우, 대상 픽셀 블럭의 MSE를 산출하고, MSE 관 점에서 대상 픽셀 블록과 텍스처 패치 간 유사도를 획득할 수 있다. 예를 들어, MSE 차이에 기초하여 유사도 가중치가 결정될 수 있다. 프로세서는 획득된 가중치를 텍스처 패치에 각각에 적용하고, 가중치가 적용된 텍스처 패치를 대 상 픽셀 블록에 적용하여 출력 영상을 획득할 수 있다. 여기서, 적용이란, 대상 픽셀 블록에 포함된 각 픽셀 값에 가중치가 적용된 텍스처 패치의 대응되는 영역에 포함된 값을 덧셈하는 방식이 될 수 있다. 다만, 이에 한정되는 것은 아니며 단순 덧셈 외의 추가 처리가 수행될 수도 있음은 물론이다. 본 개시의 다른 실시 예에 따르면, 프로세서는 텍스처 패치가 획득되면, 텍스처 패치에 주파수 필 터링을 적용하고, 주파수 필터링이 적용된 텍스처 패치를 대상 픽셀 블럭에 적용할 수도 있다. 즉, 프로세 서는 텍스처 패치를 입력 영상에 더하기 전에 주파수 필터링을 적용하여, 텍스처 패치의 주파수 범위를 변형시킬 수 있다. 예를 들어, 프로세서는 high-pass filter를 사용하여 고주파 텍스처를 생성할 수도 있고, low-pass filter를 사용하여 저주파 텍스처를 생성할 수 있다. 하기 수학식 3은 필터링된 텍스처 (Filter(T))를 입력 영상(I)과 더해 출력 영상(O)을 획득하는 과정을 나타낸다. 수학식 3"}
{"patent_id": "10-2019-0080320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "예를 들어, 프로세서는 텍스처 패치에 가우시안 블러링(또는 가우시안 필터링)과 같은 low-pass filter를 적용할 수 있다. 가우시안 블러링은 가우시안 확률 분포에 기초한 가우시안 필터를 이용하여 블러 처 리하는 방법으로, 가우시안 필터를 텍스처 패치에 적용하게 되면 고주파 성분은 차단되어 블러 처리가 된다. 일 실시 예에 따른 프로세서는 텍스처 패치에 포함된 모든 픽셀 값들에 대한 가우시안 필터링을 수행하여, 블러링된 텍스처 패치(30’)를 획득할 수 있다. 이어서, 프로세서는 블러링된 텍스처 패치(30’)를 대응되는 픽셀 블록에 적용하여 출력 영상을 획득할 수 있다. 한편, 상술한 영상 처리 과정 즉, 텍스처 향상 처리는 실시 예에 따라 영상의 스케일링 이전 또는 이후에 수행 될 수 있다. 예를 들어, 저해상도 영상을 고해상도 영상으로 확대하는 스케일링 이후에 상술한 영상 처리를 수 행하거나, 압축 영상을 디코딩하는 과정에서 상술한 영상 처리를 수행한 후 스케일링을 수행할 수도 있다. 본 개시의 다른 실시 예에 따른 학습 네트워크 모델은 서로 다른 가중치를 적용된 복수의 텍스처 패치를 획득할 수도 있다. 예를 들어, 학습 네트워크 모델은 픽셀 블록에 대응되는 클래스를 식별하고, 해당 클래스에 대응되는 제1 내지 제n 텍스처 패치를 획득할 수 있다. 이이서, 학습 네트워크 모델은 픽셀 블록과 제1 내지 제n 텍스처 패치들 간의 상관 관계를 식별할 수 있다. 예를 들어, 학습 네트워크 모델은 픽셀 블록과 제1 텍스처 패치 간 상관 관계에 기초하여 제1 가중치를 획득하고, 픽셀 블록과 제 2 텍스처 패치 간 상관 관계에 기초하여 제2 가중치를 획득할 수 있다. 이어서, 학습 네트워크 모델은 제1 가중치를 제1 텍스처 패치에 곱셈하고, 제2 가중치를 제2 텍스처 패치에 곱셈하고, 제1 가중치가 곱해진 제1 텍스처 패치 및 제2 가중치가 곱해진 제2 텍스 처 패치를 대상 픽셀 블록에 적용하여 출력 영상을 획득할 수 있다. 본 개시의 일 실시 예에 따르면, 상관 관계에 따라 가중치는 기설정된 범위, 예를 들어 0 내지 1 사이 범위에서 결정될 수 있다. 예를 들어, 학습 네트워크 모델은 픽셀 블록과 획득된 텍스처 패치 간 상관 관계가 최 소인 경우 가중치를 0으로 결정하고, 상관 관계가 최대인 경우 가중치 1로 결정하며, 상관 관계가 최소 내지 최 대 사이에서는 선형적으로 증가되도록 가중치를 결정할 수 있다. 도 10은 본 개시의 다른 실시 예에 따른 클래스를 설명하기 위한 도면이다. 도 10을 참조하면, 학습 네트워크 모델은 학습을 수행하는 과정에서 클래스 별로 텍스처 패치를 추가, 삭제 할 수 있다. 일 실시 예에 따라 학습 네트워크 모델은 입력 영상에 포함된 복수의 픽셀 블록에 기초하여 학습을 수행함 에 따라 특정 클래스에 포함된 텍스처를 삭제하거나, 특정 클래스에 복수의 텍스처 패치를 저장할 수 있다. 따 라서, 학습 네트워크 모델은 복수의 클래스 각각에 텍스처 패치를 저장하기 위한 저장 공간을 동일하게 할당할 수도 있고, 특정 클래스에 나머지 클래스 보다 많은 저장 공간을 할당할 수도 있다. 일 실시 예에 따라 학습 네트워크 모델은 입력 영상에 포함된 복수의 픽셀 블록 각각의 클래스를 식별하고, 복수의 클래스 각각의 식별 빈도수에 기초하여 복수의 클래스 중 적어도 하나에 대응되는 메모리의 저장 공간의 크기를 변경할 수 있다. 예를 들어, 학습 네트워크 모델은 식별 빈도수에 따라 기 설정된 빈도수 이상식별된 클래스에 텍스처 패치를 저장하기 위한 저장 공간을 추가 할당하여 메모리의 저장 공간의 크기를 증가시킬 수 있다. 여기서, 기 설정된 빈도수는 픽셀 블록 전체 개수 대비 특정 클래스가 20% 이상 식별되는 경 우를 의미할 수 있다. 한편, 이는 일 실시 예에 불과하며 기 설정된 횟수는 10% 등 다양하게 설정될 수 있음은 물론이다. 다른 예로, 학습 네트워크 모델은 식별 빈도수에 기초하여 가장 많이 식별된 클래스에 대응되는 저장 공간의 크기가 증가시킬 수 있다. 예를 들어, 입력 영상에 포함된 복수의 픽셀 블록 중 다수의 픽셀 블록이 제4 클래스에 대응되는 경우를 상 정할 수 있다. 학습 네트워크 모델은 제4 클래스에 대응되는 메모리 상의 저장 공간의 크기를 증가시킬 수 있다. 일 실시 예에 따라 학습 네트워크 모델은 픽셀 블록이 제4 클래스에 대응되는 것으로 식별되면, 해당 픽셀 블록 과 제4 클래스 간의 제1 유사도를 식별하고, 제4 클래스에 기 저장된 텍스처 패치 간의 제2 유사도를 식별할 수 있다. 이어서, 학습 네트워크 모델은 제1 유사도가 제2 유사도 보다 작은 값이면 기 저장된 텍스처 패치를 유지 하고, 해당 픽셀 블록을 제4 클래스에 추가로 저장할 수 있다. 여기서, 기 저장된 텍스처 패치가 해당 픽셀 블 록 보다 선 순위를 가질 수 있다. 다른 예로, 학습 네트워크 모델은 제1 유사도가 제2 유사도 보다 큰 값이면 해당 픽셀 블록을 제4 클래스에 추 가로 저장할 수 있다. 여기서, 기 저장된 텍스처 패치의 우선 순위가 후 순위로 변경되고, 해당 픽셀 블록이 기 저장된 텍스처 패치 보다 선 순위를 가질 수 있다. 또 다른 실시 예로, 학습 네트워크 모델은 복수의 클래스 별 식별 빈도수에 기초하여 가장 많이 식별된 클래스 에 기 설정된 개수의 텍스처 패치가 저장 가능하도록 메모리의 저장 공간의 크기를 변경할 수 있고, 두번 째로 많이 식별된 클래스에 기 설정된 개수 보다 적은 개수의 텍스처 패치가 저장 가능하도록 저장 공간의 크기 를 변경할 수 있다. 예를 들어, 학습 네트워크 모델은 가장 많이 식별된 제4 클래스에 최대 10개의 텍스처 패치 가 저장 가능하도록 저장 공간의 크기를 변경할 수 있고, 두번째로 많이 식별된 제2 클래스에 최대 6개의 텍스 처 패치가 저장 가능하도록 저장 공간의 크기를 변경할 수 있다. 한편, 구체적인 숫자는 일 실시 예에 불과하며 저장 가능한 텍스처 패치의 개수는 다양하게 설정될 수 있음은 물론이다. 한편, 학습 네트워크 모델은 해당 픽셀 블록을 언제나 식별된 클래스에 대응되는 텍스처 패치로 추가하는 것은 아니고, 해당 픽셀 블록과 식별된 클래스 간의 유사도가 기 설정된 값 미만이면 해당 픽셀 블록을 추가하지 않 을 수 있음은 물론이다. 일 예로, 학습 네트워크 모델은 해당 픽셀 블록과 식별된 클래스 간의 유사도가 50%미 만이면, 해당 픽셀 블록을 식별된 클래스의 텍스처 패치로 추가하지 않을 수 있다. 다른 예로, 학습 네트워크 모델은 입력 영상에 포함된 복수의 픽셀 블록 각각의 클래스를 식별함에 있어서 기 설정된 횟수 미만 식별된 클래스에 대응되는 텍스처 패치를 메모리로부터 삭제할 수 있다. 이어서, 학 습 네트워크 모델은 텍스처 패치의 삭제에 따라 확보된 메모리의 저장 공간을 나머지 클래스에 할당할 수 있다. 예를 들어, 학습 네트워크 모델은 복수의 픽셀 블록 각각의 클래스를 식별한 결과에 따라 제3 클래스에 대응되 는 픽셀 블록의 개수가 기 설정된 개수 미만이면, 제3 클래스에 기 저장된 텍스처 패치를 삭제하고, 제3 클래스 에 대응되는 텍스처 패치를 저장하기 위한 저장 공간을 나머지 클래스에 할당할 수 있다. 이에 따라, 학습 네트 워크 모델은 높은 빈도수로 식별되는 클래스에 복수의 텍스처 패치가 저장 가능하도록 해당 클래스에 저장 공간 의 크기를 증가시킬 수 있다. 다른 예로, 학습 네트워크 모델은 식별 빈도수에 기초하여 가정 적게 식별된 클래스를 삭제하여 해당 클래스에 기 할당된 저장 공간을 나머지 클래스로 재할당할 수도 있다. 도 11은 도 2에 도시된 전자 장치의 세부 구성을 나타내는 블록도이다. 도 11에 따르면, 영상 처리 장치는 메모리, 프로세서, 입력부, 디스플레이, 출력부 및 사용자 인터페이스을 포함한다. 도 11에 도시된 설명 중 도 2에 도시된 구성과 중복되는 구성에 대해서는 자세한 설명을 생략하도록 한다. 본 개시의 일 실시 예에 따르면, 메모리는 본 개시에 따른 다양한 동작들에서 생성되는 데이터를 저장하는 단일 메모리로 구현될 수 있다, 다만, 본 개시의 다른 실시 예에 따르면, 메모리는 제1 내지 제3 메모리를 포함하도록 구현될 수 있다. 제1 메모리는 입력부를 통해 입력된 영상 중 적어도 일부를 저장할 수 있다. 특히, 제1 메모리는 입력된 영상 프레임 중 적어도 일부 영역을 저장할 수 있다. 이 경우 적어도 일부 영역은 본 개시의 일 실시 예에 따른 영상 처리를 수행하기에 필요한 영역이 될 수 있다. 일 실시 예에 따라, 제1 메모리는 N 라인 메모리로 구현될 수 있다. 예를 들어, N 라인 메모리는 세로 방향으로 17 라인 상당의 용량을 가지는 메모리가 될 수 있으나, 이 에 한정되는 것은 아니다. 예를 들어, 1080p(1,920×1,080의 해상도)의 Full HD 영상이 입력되는 경우 Full HD 영상에서 17 라인의 영상 영역 만이 제1 메모리에 저장된다. 이와 같이 제1 메모리는 N 라인 메모리로 구현되고, 입력된 영상 프레임 중 일부 영역 만이 영상 처리를 위해 저장되는 이유는 하드웨어적 한계에 따라 제1 메모리의 메모리 용량이 제한적이기 때문이다. 제2 메모리는 획득된 적어도 하나의 텍스처 패치 등을 저장하기 위한 메모리로, 본 개시의 다양한 실시 예에 따라 다양한 사이즈의 메모리로 구현될 수 있다. 예를 들 어, 본 개시의 일 실시 예에 따라 입력 영상의 각 픽셀 값에 대응되는 텍스처 성분을 모두 획득하여 저장한 후 입력 영상에 적용하도록 구현되는 경우, 제2 메모리는 입력 영상의 크기와 같거나 큰 사이즈로 구현될 수 있다. 다른 실시 예에 따라 제1 메모리의 사이즈에 대응되는 영상 단위로 텍스처 성분을 적용하거나, 픽셀 라인 단위 로 획득된 텍스처 성분을 픽셀 라인 단위로 적용하는 등의 경우에는 해당 영상 처리를 위한 적절한 사이즈로 구 현될 수도 있다. 한편, 제2 메모리는 메모리 전체 영역 중 학습 네트워크 모델에 할당된 메모리 영역을 의 미할 수도 있음은 물론이다. 제3 메모리는 획득된 텍스처 성분을 적용하여 영상 처리한 출력 영상이 저장되는 메모리로, 본 개시의 다양한 실시 예에 따라 다양한 사이즈의 메모리로 구현될 수 있다. 예를 들어, 본 개시의 일 실시 예에 따라 입력 영상 의 각 픽셀 값에 대응되는 텍스처 성분을 모두 적용하여 출력 영상을 획득하여 디스플레하도록 구현되는 경 우, 제3 메모리는 입력 영상의 크기와 같거나 큰 사이즈로 구현될 수 있다. 다른 실시 예에 따라 제1 메모리의 사이즈에 대응되는 영상 단위로 영상을 출력하거나, 패치 크기에 대응되는 라인 단위로 출력하는 등의 경우에는 해당 영상 저장을 위한 적절한 사이즈로 구현될 수도 있다. 다만, 제1 메모리 또는 제2 메모리에 출력 영상이 오버라이트되거나, 출력 영상이 저장되지 않고 바로 디스플레 이되는 형태로 구현되는 경우 등에 제3 메모리는 필요하지 않을 수 있다. 입력부는 다양한 타입의 컨텐츠, 예를 들어 영상 신호를 수신한다. 예를 들어 입력부는 AP 기반의 Wi-Fi(와이파이, Wireless LAN 네트워크), 블루투스(Bluetooth), 지그비(Zigbee), 유/무선 LAN(Local Area Network), WAN, 이더넷, IEEE 1394, HDMI(High Definition Multimedia Interface), MHL (Mobile High- Definition Link), USB (Universal Serial Bus), DP(Display Port), 썬더볼트(Thunderbolt), VGA(Video Graphics Array)포트, RGB 포트, D-SUB(D-subminiature), DVI(Digital Visual Interface) 등과 같은 통신 방식 을 통해 외부 장치(예를 들어, 소스 장치), 외부 저장 매체(예를 들어, USB), 외부 서버(예를 들어 웹 하드) 등 으로부터 스트리밍 또는 다운로드 방식으로 영상 신호를 입력받을 수 있다. 여기서, 영상 신호는 디지털 신호가 될 수 있으나 이에 한정되는 것은 아니다. 디스플레이는 LCD(liquid crystal display), OLED(organic light-emitting diode), ED(Light-Emitting Diode), micro LED, LCoS(Liquid Crystal on Silicon), DLP(Digital Light Processing), QD(quantum dot) 디 스플레이 패널 등과 같은 다양한 형태로 구현될 수 있다. 출력부는 음향 신호를 출력한다. 예를 들어, 출력부는 프로세서에서 처리된 디지털 음향 신호를 아날로그 음향 신호로 변환하고 증폭 하여 출력할 수 있다. 예를 들어, 출력부는 적어도 하나의 채널을 출력할 수 있는, 적어도 하나의 스피커 유닛, D/A 컨버터, 오디오 앰프(audio amplifier) 등을 포함할 수 있다. 일 예로, 출력부는 L 채널, R 채 널을 각각 재생하는 L 채널 스피커 및 R 채널 스피커를 포함할 수 있다. 다만, 이에 한정되는 것은 아니며, 출 력부는 다양한 형태로 구현가능하다. 다른 예로, 출력부는 L 채널, R 채널, Center 채널을 재생하는 사운드 바 형태로 구현되는 것도 가능하다. 사용자 인터페이스는 버튼, 터치 패드, 마우스 및 키보드와 같은 장치로 구현되거나, 상술한 디스플레이 기능 및 조작 입력 기능도 함께 수행 가능한 터치 스크린, 리모콘 수신부 등으로 구현될 수 있다. 여기서, 버튼 은 영상 처리 장치의 본체 외관의 전면부나 측면부, 배면부 등의 임의의 영역에 형성된 기계적 버튼, 터치 패드, 휠 등과 같은 다양한 유형의 버튼이 될 수 있다. 한편, 도 11에는 도시되지 않았지만, 본 개시의 실시 예에 따른 영상 처리 전에 입력 영상의 노이즈를 제거하는 프리 필터링을 추가적으로 적용하는 것도 가능하다. 예를 들어, 가우시안 필터와 같은 스무딩 필터(SmoothingFilter), 입력 영상을 기설정된 가이던스(guidance)에 대비시켜 필터링하는 가이디드(guided) 필터 등을 적용하 여 두드러진 노이즈를 제거할 수 있다. 도 12는 본 개시의 일 실시 예에 따른 학습 네트워크 모델을 학습하고 이용하기 위한 영상 처리 장치의 구성을 나타내는 블록도이다. 도 12를 참조하면, 프로세서는 학습부 및 인식부 중 적어도 하나를 포함할 수 있다. 도 12의 프로세서는 도 2의 영상 처리 장치의 프로세서 또는 데이터 학습 서버(미도시)의 프로세서에 대 응될 수 있다. 학습부는 픽셀 블록의 클래스를 식별하기 위한 기준을 갖는 인식 모델 및 클래스에 따라 픽셀 블록 에 대응되는 텍스처 패치를 획득하기 위한 기준을 갖는 인식 모델을 생성 또는 학습시킬 수 있다. 학습 부는 수집된 학습 데이터를 이용하여 판단 기준을 갖는 인식 모델을 생성할 수 있다. 일 예로, 학습부는 영상에 포함된 픽셀 블록을 학습 데이터로서 이용하여 해당 픽셀 블록에 대응 되는 클래스를 판단하기 위한 인식 모델을 생성, 학습 또는 갱신시킬 수 있다. 또 다른 예로, 학습부는 픽셀 블록과 클래스 간의 유사도 및 텍스처 패치와 클래스 간의 유사도 를 비교하여 텍스처 패치의 업데이트 여부를 판단하는 인식 모델을 생성, 학습 또는 갱신시킬 수 있다. 인식부는 소정의 데이터(예를 들어, 입력 영상)를 학습된 인식 모델의 입력 데이터로 사용하여, 소정의 데이터에 포함된 인식 대상 또는 상황을 추정할 수 있다. 일 예로, 인식부는 입력 영상의 픽셀 블록을 학습된 인식 모델의 입력 데이터로 사용하여 해당 픽셀 블록의 클래스 및 텍스처 패치를 식별할 수 있다. 학습부의 적어도 일부 및 인식부의 적어도 일부는, 소프트웨어 모듈로 구현되거나 적어도 하나의 하드웨어 칩 형태로 제작되어 영상 처리 장치에 탑재될 수 있다. 예를 들어, 학습부 및 인식부 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또 는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 영상 처리 장치 또는 객체 인식 장치에 탑재될 수도 있다. 이때, 인공 지능을 위한 전용 하드웨어 칩은 확률 연산에 특화된 전용 프로세서로서, 기존의 범용 프로세서보다 병렬처리 성능이 높아 기계 학습과 같은 인공 지능 분야의 연산 작업을 빠르게 처리할 수 있다. 학습부 및 인식부가 소프트웨 어 모듈(또는, 인스트럭션(instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터 로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장 될 수 있다. 이 경우, 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의 해 제공될 수 있다. 또는, 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 이 경우, 학습부 및 인식부는 하나의 영상 처리 장치에 탑재될 수도 있으며, 또는 별개의 영상 처 리 장치들에 각각 탑재될 수도 있다. 예를 들어, 학습부 및 인식부 중 하나는 영상 처리 장치(10 0)에 포함되고, 나머지 하나는 외부의 서버에 포함될 수 있다. 또한, 학습부 및 인식부는 유선 또 는 무선으로 통하여, 학습부가 구축한 모델 정보를 인식부로 제공할 수도 있고, 학습부로 입 력된 데이터가 추가 학습 데이터로서 학습부로 제공될 수도 있다. 도 13은 본 개시의 일 실시 예에 따른 영상 처리 방법을 설명하기 위한 흐름도이다. 도 13에 도시된 영상 처리 방법에 따르면, 입력 영상을 학습 네트워크 모델에 적용하여 입력 영상에 포함된 픽 셀 블록에 대응되는 텍스처 패치를 획득한다(S1310). 이어서, 픽셀 블록에 획득된 텍스처 패치를 적용하여 출력 영상을 획득한다(S1320). 여기서, 학습 네트워크 모델은, 영상의 특성에 기초하여 분류된 복수의 클래스 각각에 대응되는 텍스처 패치를 저장하며, 입력 영상에 기초하여 복수의 클래스 각각에 대응되는 텍스처 패치를 학습할 수 있다. 또한, 일 실시 예에 따른 학습 네트워크 모델은, 픽셀 블록의 특성에 기초하여 복수의 클래스 중 하나를 식별하 고, 식별된 클래스에 대응되는 텍스처 패치를 출력하며, 픽셀 블록과 식별된 클래스 간의 제1 유사도 및 텍스처 패치와 식별된 클래스 간의 제2 유사도를 비교하여 텍스처 패치의 업데이트할지 여부를 식별할 수 있다.일 실시 예에 따른 학습 네트워크 모델은, 제1 및 제2 유사도에 기초하여 식별된 클래스에 대응되는 텍스처 패 치를 픽셀 블록으로 대체하거나, 픽셀 블록을 식별된 클래스에 대응되는 텍스처 패치로 추가할 수 있다. 또한, 학습 네트워크 모델은, 비교 결과에 기초하여 제1 유사도가 제2 유사도 보다 작은 값이면, 식별된 클래스 에 대응되는 텍스처 패치를 유지하고, 비교 결과에 기초하여 제1 유사도가 제2 유사도 보다 큰 값이면, 픽셀 블 록에 기초하여 텍스처 패치를 업데이트할 수 있다. 본 개시의 일 실시 예에 따른 학습 네트워크 모델은, 식별된 클래스에 대응되는 텍스처 패치가 복수 개인 경우, 픽셀 블록 및 복수 개의 텍스처 패치 각각의 상관 관계(correlation)에 기초하여 복수 개의 텍스처 패치 중 어 느 하나를 식별할 수 있다. 또한, 학습 네트워크 모델은, 복수의 클래스 각각에 대응되는 텍스처 패치의 저장 시기 또는 텍스처 패치의 적 용 빈도수 중 적어도 하나에 기초하여 텍스처 패치를 학습할 수 있다. 본 개시의 일 실시 예에 따른 학습 네트워크 모델은, 픽셀 블록의 특성에 기초하여 픽셀 블록이 복수의 클래스 중 어느 하나에 대응되지 않는 것으로 식별되면, 픽셀 블록의 특성에 기초하여 신규 클래스를 생성하고 신규 클 래스에 픽셀 블록을 맵핑하여 저장할 수 있다. 여기서, 복수의 클래스는, 평균 픽셀 값, 픽셀 좌표, 분산, 에지 강도, 에지 방향 또는 색상 중 적어도 하나를 기준으로 구분될 수 있다. 본 개시의 일 실시 예에 따른 출력 영상을 획득하는 S1320단계는, 획득된 텍스처 패치 및 픽셀 블록 간 상관 관 계(correlation)에 기초하여 텍스처 패치에 대한 가중치를 획득하는 단계 및 가중치가 적용된 텍스처 패치를 픽 셀 블록에 적용하여 출력 영상을 획득하는 단계를 포함할 수 있다. 여기서, 출력 영상은, 4K UHD(Ultra High Definition) 영상 또는 8K UHD 영상일 수 있다. 다만, 본 개시의 다양한 실시 예들은 영상 처리 장치 뿐 아니라, 셋탑 박스와 같은 영상 수신 장치, 영상 처리 장치 등 영상 처리가 가능한 모든 전자 장치에 적용될 수 있음은 물론이다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합을 이 용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 일부 경우 에 있어 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구현에 의 하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 동작을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 음향 출력 장치의 프로세싱 동작을 수행하기 위한 컴퓨 터 명령어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium) 에 저장될 수 있다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프 로세서에 의해 실행되었을 때 상술한 다양한 실시 예에 따른 음향 출력 장치에서의 처리 동작을 특정 기기 가 수행하도록 한다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등 이 있을 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2019-0080320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2019-0080320", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 영상 처리 장치의 구현 예를 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 영상 처리 장치의 구성을 나타내는 블록도다. 도 3은 본 개시의 일 실시 예에 따른 픽셀 블록을 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시 예에 따른 텍스처 패치를 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따른 학습 네트워크 모델을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시 예에 따른 클래스 및 텍스처 패치를 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시 예에 따른 입력 영상을 학습하는 모델을 설명하기 위한 도면이다, 도 8은 본 개시의 다른 실시 예에 따른 클래스를 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시 예에 따른 학습 결과를 설명하기 위한 도면이다. 도 10은 본 개시의 다른 실시 예에 따른 클래스를 설명하기 위한 도면이다. 도 11은 도 2에 도시된 전자 장치의 세부 구성을 나타내는 블록도이다. 도 12는 본 개시의 일 실시 예에 따른 학습 네트워크 모델을 학습하고 이용하기 위한 영상 처리 장치의 구성을 나타내는 블록도이다. 도 13은 본 개시의 일 실시 예에 따른 영상 처리 방법을 설명하기 위한 흐름도이다."}
