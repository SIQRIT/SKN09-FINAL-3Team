{"patent_id": "10-2021-0051763", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0131894", "출원번호": "10-2021-0051763", "발명의 명칭": "훈련된 심층 신경망의 압축 장치 및 방법", "출원인": "(주)인시그널", "발명자": "문현철"}}
{"patent_id": "10-2021-0051763", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "훈련된 인공 신경망의 압축을 위한 장치로서, 파라미터 감소 모듈(parameter reduction module), 파라미터 근사화 모듈(parameter approximation module),및 인코딩 모듈(encoding module)을 포함하고, 상기 파라미터 감소 모듈은, 상기 훈련된 인공 신경망을 표현하는 가중치를 포함하는 파라미터의 개수를 감소시키고,상기 파라미터 근사화 유닛은, 상기 훈련된 인공 신경망을 표현하는 가중치를 포함하는 파라미터 또는 상기 파라미터 감소 모듈에 의하여 감소된 파라미터를 근사화하며, 상기 인코딩 모듈은, 상기 파라미터 근사화 유닛에 의하여 근사화된 파라미터들을 인코딩하여 비트스트림을 생성하되, 양자화 파라미터 덴시티(quantization parameter density)와 양자화 파라미터로 표현되는 고정된 스텝사이즈를 사용하는 균일 양자화(uniform quantizsation) 기법 또는 가중치 텐서가 코드북과 텐서 인덱스로 표현되는 코드북 기반 기법을 적용하는 것을 특징으로 하는 훈련된 인공 신경망의 압축 장치."}
{"patent_id": "10-2021-0051763", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 파라미터 감소 모듈은, 매트릭스 분해 기법을 이용하여 가중치 텐서(weight tensors)의 크기를 줄여서 상기 파라미터의 개수를 감소시키되, 상기 매트릭스 분해 기법에 사용되는 행렬 인자(factor)들, 랭크값(rankvalue, 정수 기반), 필터 재구성을 위한 리쉐이핑 모드(reshaping mode, 정수 기반) 및 최초 행렬과 재구성된행렬의 차원(dimension)을 지시하는 정보 중에서 하나 이상을 생성하여 출력하는 것을 특징으로 하는 훈련된 인공 신경망의 압축 장치."}
{"patent_id": "10-2021-0051763", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 파라미터 감소 모듈이 상기 파라미터의 개수를 감소시키는 과정은 선택적인 과정으로서, 상기 비트스트림은 상기 파라미터의 개수를 감소시키는 과정이 수행되었는지 여부를 지시하는 정보를 포함하는 것을 특징으로하는 훈련된 인공 신경망의 압축 장치."}
{"patent_id": "10-2021-0051763", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "메모리 또는 스토리지에 저장되어 있는 프로그래밍 명령어를 가져와서 실행하는 프로세서를 포함하는 컴퓨터 시스템을 이용하여 훈련된 심층 인공 신경망을 압축하는 방법으로서, 훈련된 심층 신경망을 기술하는 가중치 매트릭스를 간략화하기 위한 파라미터 감소 단계;상기 파라미터 감소 단계에서 감소된 상기 가중치 매트릭스를 근사화하기 위한 파라미터 근사화 단계; 및상기 파라미터 근사화 단계에서 근사화된 가중치 매트릭스를 소정의 방향으로 스캔하고, 스캔된 가중치들을 순차적으로 엔트로피 코딩하여 비트스트림으로 출력하기 위한 인코딩 단계를 포함하고, 상기 인코딩 단계에서는, 상기 파라미터 근사화 유닛에 의하여 근사화된 파라미터들을 인코딩하여 비트스트림을생성하되, 양자화 파라미터 덴시티(quantization parameter density)와 양자화 파라미터로 표현되는 고정된 스텝 사이즈를 사용하는 균일 양자화(uniform quantizsation) 기법 또는 가중치 텐서가 코드북과 텐서 인덱스로표현되는 코드북 기반 기법을 적용하는 것을 특징으로 하는 훈련된 인공 신경망의 압축 방법."}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "훈련된 인공 신경망의 압축을 위한 장치 및 방법이 제공된다. 일 실시예에 따른 훈련된 인공 신경망의 압축 장치 는, 파라미터 감소 모듈(parameter reduction module), 파라미터 근사화 모듈(parameter approximation module), 및 인코딩 모듈(encoding module)을 포함하고, 상기 파라미터 감소 모듈은, 상기 훈련된 인공 신경망을 (뒷면에 계속)"}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공 신경망(Artificial Neural Network, ANN)의 압축 기술에 관한 것으로, 보다 구체적으로 멀티미 디어 콘텐츠의 기술(description) 및 분석(analysis)을 위한 훈련된 심층 신경망을 압축하기 위한 장치 및 방법 에 관한 것이다."}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능(Artificial Intelligence, AI)을 다양한 산업 분야에서 활용하기 위한 시도들이 계속되어 왔다. 특히, 최근의 인공 지능 기술은 생물학적 신경망과 공통된 특정 성능을 갖는 정보 처리 시스템인 신경망(Neural Network, NN)을 활용하면서, 그 성능이 큰 폭으로 향상되고 있으며, 그에 따라 응용 분야도 급속도로 증가하고 있다. 이러한 신경망(NN)은 '인공' 신경망(Artificial Neural Network, ANN)이라고도 불린다. 인공 신경망(ANN)은 동 물 신경의 행동 특성을 모방하는 분산 병렬 정보 처리 모델이다. ANN에는 서로 연결되어 있는 많은 수의 노드 (뉴런이라고도 함)가 존재한다. ANN은 두 가지 특징을 가지고 있다: 1) 각 뉴런은 특정 출력 기능(활성화 기능 이라고도 함)을 통해 다른 인접한 뉴런으로부터 가중 입력값을 계산한다. 2) 뉴런들 사이의 정보 전송 강도는 소위 \"가중치(weight)\"이라고 불리는 것에 의해 측정되며, 그러한 가중치는 특정한 알고리즘의 자기 학습에 의 해 조정될 수 있다. ANN은 신경망에 포함되는 변수 및 토폴로지 관계를 지정하기 위해 상이한 아키텍쳐를 사용할 수 있다. 신경망에 포함되는 파라미터는 뉴런의 활동과 함께 뉴런들 간의 연결의 가중치일 수 있다. 신경망 토폴로지의 유형으로 피드 포워드 네트워크와 역방향 전파 신경망(backward propagation neural network)이 있다. 전자에서는 동일 한 계층에서 서로 연결된 각 계층 내의 노드가 다음 스테이지로 공급되는데, 제공되는 입력 패턴에 따라 연결의 가중치를 수정하는 '학습 규칙'의 일부 형태를 포함한다. 후자에서는 가중 조정치의 역방향 에러 전파를 허용하 는 것으로, 전자보다 진보된 신경망이다. 심층 신경망(Deep Neural Network, DNN)은 다수의 레벨의 상호 연결된 노드를 갖는 신경망에 대응하여 매우 비 선형이고 고도로 변화하는 기능을 콤팩트하게 표현할 수 있다. 그럼에도 불구하고, 다수의 계층과 연관된 노드 의 수와 함께 DNN에 대한 계산 복잡도가 급격히 상승한다. 최근까지 이러한 DNN을 학습 또는 훈련(training)시 키기 위한 효율적인 연산 방법들이 개발되고 있다. DNN의 학습 속도가 획기적으로 높아짐에 따라, 음성 인식, 이미지 세분화, 물체 감지, 안면 인식 등의 다양하고 복잡한 작업에 성공적으로 적용되고 있다. 멀티미디어 콘텐츠, 예컨데 비디오의 압축 및 복원도 이러한 DNN의 적용이 시도되고 있는 분야의 하나이다. 현 재 차세대 비디오 코딩으로 고효율 비디오 코딩(High Efficiency Video Coding, HEVC)이 ITU-T(비디오 코딩 전 문가 그룹) 및 ISO/IEC MPEG(동영상 전문가 그룹) 표준화 조직의 공동 비디오 프로젝트에 의하여 개발되어 국제 표준으로 채택되어 사용되고 있으며, DNN을 HEVC 등과 같은 새로운 비디오 코딩 표준에 적용함으로써, 그 성능 을 더욱 향상시키는 것이 가능하다는 것이 알려져 있다. 이러한 시도의 하나가 한국공개특허 제10-2018-0052651 호, \"비디오 코딩에서의 신경망 기반 프로세싱의 방법 및 장치\"에 개시되어 있다. 그러나, 신경망의 규모는 최근 몇 년 동안 급속한 발전으로 인해 폭발하고 있다. 몇몇 진보된 신경망 모델들은 수백 개의 층과 수십억 개의 연결을 가지고 있을 것이다. 그리고 그것의 구현은 계산-중심과 기억-중심 둘 다이 다. 신경망이 점점 커지고 있기 때문에, 이동 단말기 등과 같이 스토리지 및 프로세서의 성능에 제약이 있는 장치에 서 적용하기 위해서는 신경망 모델을 작은 크기로 만드는 것이 상당히 중요하지만, 이는 신경망의 성능을 저하 시킬 수가 있어서 한계가 존재한다. 특히, 이동 단말기에서 중요한 어플리케이션으로 활용되는 멀티미디어 콘텐 츠의 생산 및 소비를 위한 비디오 코딩 어플리케이션에 적용하기 위해서는, 작은 크기의 신경망 모델이 필수적 이다. 뿐만 아니라, 비디오 코딩 어플리케이션의 특성상, 인코딩 장치와 디코딩 장치 간의 호환성도 확보될 필 요가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 제10-2018-0052651호, \"비디오 코딩에서의 신경망 기반 프로세싱의 방법 및 장치\""}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 하나의 과제는 훈련된 심층 신경망, 특히 멀티미디어 콘텐츠의 기술(description) 및 분석(analysis)을 위한 훈련된 심층 신경망(trained deep neural networks)을 압축하기 위한 장치 및 방법 을 제공하는 것이다."}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "멀티미디어 콘텐츠의 기술(description) 및 분석(analysis)을 위한 훈련된 심층 신경망의 압축을 위한 장치와 이에 사용되는 방법을 제공한다. 일 실시예에 따른 훈련된 인공 신경망의 압축을 위한 장치는, 파라미터 감소 모듈(parameter reduction module), 파라미터 근사화 모듈(parameter approximation module), 및 인코딩 모듈 (encoding module)을 포함하는데, 상기 파라미터 감소 모듈은, 상기 훈련된 인공 신경망을 표현하는 가중치를 포함하는 파라미터의 개수를 감소시키고, 상기 파라미터 근사화 유닛은, 상기 훈련된 인공 신경망을 표현하는 가중치를 포함하는 파라미터 또는 상기 파라미터 감소 모듈에 의하여 감소된 파라미터를 근사화하며, 상기 인코 딩 모듈은, 상기 파라미터 근사화 유닛에 의하여 근사화된 파라미터들을 인코딩하여 비트스트림을 생성하되, 양 자화 파라미터 덴시티(quantization parameter density)와 양자화 파라미터로 표현되는 고정된 스텝 사이즈를 사용하는 균일 양자화(uniform quantizsation) 기법 또는 가중치 텐서가 코드북과 텐서 인덱스로 표현되는 코드 북 기반 기법을 적용한다. 상기 실시예의 일 측면에 의하면, 상기 파라미터 감소 모듈은, 매트릭스 분해 기법을 이용하여 가중치 텐서 (weight tensors)의 크기를 줄여서 상기 파라미터의 개수를 감소시키되, 상기 매트릭스 분해 기법에 사용되는 행렬 인자(factor)들, 랭크값(rank value, 정수 기반), 필터 재구성을 위한 리쉐이핑 모드(reshaping mode, 정 수 기반) 및 최초 행렬과 재구성된 행렬의 차원(dimension)을 지시하는 정보 중에서 하나 이상을 생성하여 출력 할 수 있다. 이 경우에, 상기 파라미터 감소 모듈이 상기 파라미터의 개수를 감소시키는 과정은 선택적인 과정으로서, 상기 비트스트림은 상기 파라미터의 개수를 감소시키는 과정이 수행되었는지 여부를 지시하는 정보를 포함할 수 있다. 상기한 과제를 해결하기 위한 본 발명의 다른 실시예는 메모리 또는 스토리지에 저장되어 있는 프로그래밍 명령 어를 가져와서 실행하는 프로세서를 포함하는 컴퓨터 시스템을 이용하여 훈련된 심층 인공 신경망을 압축하는 방법으로서, 훈련된 심층 신경망을 기술하는 가중치 매트릭스를 간략화하기 위한 파라미터 감소 단계, 상기 파 라미터 감소 단계에서 감소된 상기 가중치 매트릭스를 근사화하기 위한 파라미터 근사화 단계 및 상기 파라미터 근사화 단계에서 근사화된 가중치 매트릭스를 소정의 방향으로 스캔하고, 스캔된 가중치들을 순차적으로 엔트로 피 코딩하여 비트스트림으로 출력하기 위한 인코딩 단계를 포함하고, 상기 인코딩 단계에서는, 상기 파라미터 근사화 유닛에 의하여 근사화된 파라미터들을 인코딩하여 비트스트림을 생성하되, 양자화 파라미터 덴시티 (quantization parameter density)와 양자화 파라미터로 표현되는 고정된 스텝 사이즈를 사용하는 균일 양자화 (uniform quantizsation) 기법 또는 가중치 텐서가 코드북과 텐서 인덱스로 표현되는 코드북 기반 기법을 적용 한다."}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 의하면, 멀티미디어 컨텐츠의 기술 및 분석(description and analysis)을 위한 훈련된 심층 신경망의 압축을 시스템을 구성하는 서로 다른 모듈들 사이의 인터페이스를 제공함으로써, 인공 신경망의 효율 적인 압축과 전송이 가능하다. 특히, 본 발명의 실시예에서 의하면, 훈련된 심층 신경망의 압축 시스템이 로우 랭크 근사화 또는 로우 랭크 디 스플레이스먼트 근사화 과정을 통해서 파라미터를 감소시키는데, 매트릭스 분해 기법을 이용하여 콘볼루션 계층 또는 전연결 계층를 기술하는 모델 구조(가중치 텐서 벡터)를 변화시킨다. 이 때, 매트릭스 분해 기법에 사용되 는 행렬 인자(factor)들, 랭크값(rank value, 정수 기반), 필터 재구성을 위한 리쉐이핑 모드(reshaping mode,정수 기반) 및 최초 행렬과 재구성된 행렬의 차원(dimension)을 지시하는 정보 중에서 하나 이상을 생성하여 출 력함으로써, 효율적인 파라미터의 감소가 가능하다."}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 바람직한 실시형태 및 실시예를 설명한다. 다만, 이하의 실시형태 및 실시예 는 본 발명의 바람직한 구성을 예시적으로 나타내는 것일 뿐이며, 본 발명의 범위는 이들 구성에 한정되지 않는 다. 그리고 이하의 설명에 있어서, 장치의 하드웨어 구성 및 소프트웨어 구성, 처리 흐름, 제조조건, 크기, 재 질, 형상 등은, 특히 특정적인 기재가 없는 한, 본 발명의 범위를 이것으로 한정하려는 취지인 것은 아니다. 인공 신경망(ANN)은 멀티미디어 분석과 처리, 미디어 부호화, 데이터 분석, 그리고 많은 다른 어플리케이션에서 광범위한 작업을 위해 널리 채택되고 있다. 그런데, 이들 대부분의 애플리케이션은 계산 전력과 메모리가 제한 된 더 많은 수의 디바이스에 훈련된 네트워크 인스턴스(trained network instance)를 배치해야 한다. 그러한 용 도의 경우, 신경망의 상호운용 가능하고 컴팩트한 표현(interoperable and compact representations)이 요구된 다. 이러한 요구를 충족시키기 위하여, 다양한 심층 학습 프레임워크(deep learning framework)에서 상호 운용 할 수 있고 선택적으로 압축을 적용할 수 있는 교환 포맷(exchange format)이 개발되어 오고 있다. 또한, 최근 에는 MPEG이 NNR(Compression of Neural Networks for Multimedia Content Description and Analysis)이라는 신경망의 상호운용 가능한 압축 표현(interoperable compressed representation of neural networks)을 개발하 고 있다. 도 1은 비디오 압축을 위한 사용예(use case)에서의 MPEG-NNR 프레임워크로서 DNN 기반 비디오 코딩 시스템을 보여 주는 것이다. 도 1을 참조하면, DNN 기반 비디오 코딩 시스템은 네트워크 트레이닝 프레임워크 (network training framework, 110), 인코더(encoder, 120), 신경망 압축부(Neural Network(NN) compression, 140) 및 디코더(decoder, 130)를 포함한다. 네트워크 트레이닝 프레임워크는 DNN 기반 코딩 도구를 학습시켜서 기술한 학습된 도구 신경망을 생성한다. 이를 위하여, 네트워크 트레이닝 프레임워크는 우선 DNN 기반 코딩 도구들의 일 집합을 고안하 고 또한 이들을 각각 학습시킨다. 여기서, 고안된 DNN 기반 코딩 도구는 소정의 망 구조(network structure)를 갖는 소정의 네트워크 모델을 가리킨다. DNN 기반 코딩 도구는 2가지 유형이 존재할 수 있다. 보다 구체적으로, DNN 기반 코딩 도구는 인코더 및 디코더 모두에 필수적인 기능을 구현하는 제1 코딩 도구(도 1a에서는 Type-A로 표시되어 있는 도구 A(toolA) 및 도구 B(tool B)가 이에 해당됨)와 인코더와 디코더 중에서 어느 하나에만 필수적인 기능을 구 현하는 제2 코딩 도구(도 1a에서는 Type-B로 표시되어 있는 도구 C(tool C) 및 도구 D(tool D)가 이에 해당됨) 의 두 가지 유형이 존재한다. 이것은 이미지/비디오 코딩에서, 일부의 코딩 도구, 즉 제1 코딩 도구는 인코더 와 디코더 모두에 요구되는 것이고, 나머지 다른 일부의 코딩 도구, 즉 제2 코딩 도구는 인코더(12 0)와 디코더 중에서 어느 하나에만 요구되는 기능이기 때문이다. 예를 들어, 비디오 코딩 과정에서, 인-루 프 필터링 과정은 인코더와 디코더 모두에서 행해지는 제1 코딩 도구의 기능에 해당하지만, 인트라 모드 예측 과정은 오직 인코더에서만 행해지는 제2 코딩 도구의 기능에 해당되며, 디코더로는 오직 결정된 예측 모드 정보만이 보내진다. 따라서 두 가지 유형의 DNN 기반 코딩 도구가 고려되어야 하며, 이러한 DNN 기반 코딩 도구의 유형(type)은 반 드시 학습된 DNN 기반 코딩 도구의 상위 레벨 정보로서 표시가 되어야 한다. 전술한 바와 같이, 도 1a에서는 인 코더와 디코더 모두에게 필요한 도구 A(tool A) 및 도구 B(tool B)는 Type-A로 표시되어 있으며, 인 코더와 디코더 중에서 하나에게만 필요한 도구 C(tool C) 및 도구 D(tool D)는 Type-B로 표시되어 있다. 그리고 네트워크 트레이닝 프레임워크에서 학습된 DNN 기반 도구의 결과물(results of trained DNN based tool), 즉 학습된 신경망은 인코더 및/또는 디코더로 전달되어야 하며 또는 상호 호환이 가능하게 교 환되어야 한다. 이것은 네트워크 구조와 학습된 가중치(network structure and trained weight)를 포함하는 학 습된 신경망(trained network)을 기술하기 위한 호환가능한 포맷(interoperable format)을 규정함으로써 달성 할 수 있다. 호환가능한 포맷은 학습된 신경망뿐만 아니라 시스템 구성(system configuration)에 관한 상위 레 벨 정보(high-level information)를 기술할 필요가 있다. 예를 들어, 도구 단위 기반 방법의 경우에는, 해당 도 구가 인코더와 디코더 모두에 공통적으로 적용되는지 또는 어느 하나에만 적용되는지를 지시하기 위 한 도구의 유형 정보가 상호호환 가능한 포맷으로 기술되어야 한다. 이와 같이, 상호호환 가능한 포맷으로 기술된 학습된 신경망은 학습된 DNN 기반 도구 신경망뿐만 아니라 도 1에 도시되어 있는 시스템의 전반적인 구성에 관한 상위 레벨 정보를 포함하고 있어야 한다. 보다 구체적으로, 학습된 DNN 기반 도구 신경망과 관련된 상위 레벨 정보로는, 인식(recognition), 분류 (classification), 생성(generation), 차별화(discrimination) 등과 같은 해당 신경망의 기본 기능의 관점에서 본 목표 응용(target application)에 관한 정보, 도구 단위 기반 방법인지 또는 전체 코덱 단위 기반 방법인지 에 관한 정보, 도구 단위 기반 방법에서 학습된 DNN 기반 코딩 도구의 유형을 지시하는 정보, 도구 단위 기반 방법에서 인코더가 특정 부호화 과정의 수행시에 학습된 도구 신경망을 추론 엔진에 적용하는 것과 규격화된 이 미지 또는 비디오 부호화 도구를 적용하는 것 중에서 무엇을 선택하였는지를 지시하는 정보, 최적화된 콘텐츠 유형(customized content type)에 관한 정보, 오토인코더(autoencoder), CNN(Convolutional Neural Network), GAN(Generative Adversarial Network), RNN(Recurrent Neural Network) 등과 같은 학습된 DNN 기반 신경망의 알고리즘에 관한 기초 정보, 트레이닝 데이터 및/또는 테스트 데이터에 관한 기본 정보, 메모리 용량 및 컴퓨팅 파워의 관점에서 추론 엔진에 요구되는 능력에 관한 정보, 모델 압축에 관한 정보 등을 포함한다. 그리고 네트워크 트레이닝 프레임워크는 하나 이상의 학습된 도구 신경망, 즉 학습된 도구 단위 신경망의 코딩된 기술(trained coded representation of neural network)을 선택하여 인코더 및/또는 디코더 로 전송한다. 전술한 바와 같이, 학습된 도구 신경망의 유형, 즉 도구의 유형에 따라서 인코더와 디코더 모두에게 전송되거나 또는 인코더 또는 디코더에게만 전송될 수 있다. 보다 구체적으로, 도 1 에 예시적으로 도시된 바와 같이, 인코더와 디코더 모두에게 필요한 Type-A의 도구 A(tool A) 및 도 구 B(tool B)는 인코더와 디코더 모두에게 전송되지만, 디코더에게 필요한 Type-B의 도구 C(tool C) 및 도구 D(tool D)는 디코더에게만 전송된다. 이 때, 네트워크 트레이닝 프레임워크로부터 인코더 및/또는 디코더로 전송되는 학습된 도구 신 경망의 전부 또는 일부는 신경망 압축부를 거쳐서 전송될 수도 있다. 즉, 네트워크 트레이닝 프레임워크 에서 생성되어 기술된 학습된 도구 신경망의 일부는 네트워크 트레이닝 프레임워크로부터 인코더 및/또는 디코더로 바로 전송되지만, 학습된 도구 신경망의 나머지 일부는 신경망 압축부를 경 유하여 네트워크 트레이닝 프레임워크로부터 인코더 및/또는 디코더로 전송될 수 있다. 신경망 압축부는 학습된 도구 신경망을 압축하여 호환 가능한 포맷으로 기술하기 위한 수단이다. 이러한 신경망 압축부의 일례는 가속기 라이브러리(accelerator library)이다. 가속기 라이브러리, 즉 신경망 압 축부를 이용한 학습된 도구 신경망의 압축은 선택적(optional) 과정이다. 즉, 학습된 도구 신경망이 압축을 거치지 않고서도 인코더 및/또는 디코더로 전송될 수 있을 정도로 충분히 컴팩트한 경우이거나 또 는 압축으로 인하여 코덱의 성능을 심각하게 떨어뜨리는 경우 등에는, 학습된 도구 신경망은 신경망 압축부 를 거치지 않고 직접 인코더 및/또는 디코더로 전송될 수 있다. 인코더 및/또는 디코더는 신경망 압축부로부터 전송받은 압축된 도구 신경망을 복원하여, 인코 딩 및/또는 디코딩의 해당 과정에서 신경망을 활용하여 영상 데이터를 인코딩하거나 또는 인코딩된 영상 데이터 를 디코딩한다. 신경망 압축부가 구현된 컴퓨터 시스템 도 2는 도 1의 신경망 압축부가 구현된 컴퓨터 시스템의 구성의 일례를 보여 주는 도면이다. 도 2를 참조하면, 컴퓨터 시스템은 하나 또는 이상의 프로세서, 입출력 장치 인터페이스, 네트 워크 인터페이스, 인터컨넥터(BUS, 240), 메모리 및 스토리지를 포함한다. 이러한 컴퓨터 시스 템은 단일의 컴퓨팅 장치로 구성한 특정한 하나의 장치이거나 또는 하나 이상의 프로세서와 하나 이상의 관련 메모리를 포함하여 구성된 다수의 장치일 수 있다. 프로세서는 메모리 또는 스토리지에 저장되어 있는 프로그래밍 명령어를 가져와서 실행한다. 마 찬가지로, 프로세서는 메모리에 어플리케이션 데이터를 저장하거나 또는 가져온다. 입출력 장치 인터 페이스는, 키보드, 디스플레이 및 마우스 장치 등과 같은 입출력 장치를 컴퓨터 시스템에 연결하 기 위한 것이다. 네트워크 인터페이스는 유선이나 무선을 통해 자체망(인트라넷)이나 인터넷, 무신통신 네 트워크 등과 같은 외부망과 통신하기 위한 것으로, 데이터 통신 네트워크를 통해 데이터를 전송한다. 인터컨넥터는, 프로세서와 입출력 장치 인터페이스, 스토리지, 네트워크 인터페이스 및 메모리 각각의 사이에서, 프로그래밍 명령어 및 어플리케이션 데이터를 전송하는 기능을 수행한다. 이 러한 인터컨넥터는 하나 이상의 버스(BUS)일 수 있다. 프로세서는 단일의 중앙처리장치(CPU)이거나 또는 복수의 CPU, 다양한 구현예에서 복수의 프로세싱 코어를 갖는 단일의 CPU로 구현될 수 있다. 일 측면에 의 하면, 프로세서는 디지털 신호 프로세서(Digital Signal Processor, DSP)일 수 있다. 메모리는 일반적으로 SRAM(Static Random Access Memory), DRAM(Dynamic Random Access Memory) 또는 플 래시(Flash) 등과 같은 메모리랜덤 엑세스 메모리를 포함한다. 스토리지는 일반적으로 하드 디스크 드라이 브, SSD(Solid State Device), 제거 가능한 메모리 카드, 광 스토리지, 플래시 메모리 디바이스, NAS(Network Attached Storage) 또는 SAN(Storage Area Device)에의 연결(connections) 등과 같은 비휘발성 메모리를 포함 한다. 컴퓨터 시스템은 하나 이상의 운영 체제(Operating System, OS, 164)를 포함할 수 있다. 운영 체제 는 일부는 메모리에 저장되고 나머지 일부는 스토리지에 저장될 수 있다. 이와는 달리, 운영 체제 는 전체가 메모리에 저장되거나 또는 스토리지에 저장될 수도 있다. 운영 체제는, 프로세 서, 입출력 장치 인터페이스, 네트워크 인터페이스 등과 같은 다양한 하드웨어 리소스들 사이에 서 인터페이스를 제공한다. 또한, 운영 체제는 어플리케이션 프로그램을 위한 시간 기능(time function) 등과 같은 공통 서비스를 제공한다. 심층 신경망 압축 장치는, 도 1의 신경망 압축부에 대응하는 것으로, 훈련된 심층 신경망, 예컨대 훈 련된 심층 컨블루션 신경망(Deep Convolutional Neural Network)을 압축하여 비트스트림으로 출력한다. 즉, 심 층 신경망 압축 장치는 학습된 또는 훈련된 심층 신경망을 압축하여, 호환 가능한 포맷으로 기술하기 위한 수단이다. 이에 의하면, 결과물인 압축된 심층 신경망은 신경망의 상호운용 가능한 압축 표현(interoperable compressed representation of neural networks)에 해당된다. 훈련된 심층 신경망을 압축하기 위하여, 심층 신 경망 압축 장치는, 훈련된 심층 신경망에 대한 가지치기(pruning), 양자화(quantization) 및 엔트로피 코 딩(entropy coding)을 포함하는 일련의 과정을 수행하여, 비트스트림을 출력한다. 신경망 압축 및 복원 시스템 도 3은 신경망의 압축 및 복원을 위한 프레임워크의 구성을 보여 주는 블록도이다. 도 3을 참조하면, 신경망의 압축 및 복원을 위한 프레임워크는 파라미터 감소 모듈(parameter reduction module, Part 1), 파라미터 근사 화 모듈(parameter approximation module, Part 2), 재구성 모듈(reconstruction module, Part 3), 인코딩 모 듈(encoding module, Part 4) 및 디코딩 모듈(decoding module, Part 5)을 포함한다. 도 3에서 최초 신경망 모 델(Original NN Model)과 재구성된 신경망 모델(Reconstructed NN Model)은 동일한 모델 포맷으로 구성됨을 가정한다. 파라미터 감소 모듈(Part 1)에서의 과정은, 전처리의 관점에서 수행하는 것으로, 임의적인 과정이다. 따라서 파 라미터 감소 모듈(Part 1)에서의 과정을 거치지 않고, 최초 신경망 모델(Original NN Model)이 바로 파라미터 근사화 모듈(Part 2)로 입력될 수도 있다. 다만, 파라미터 감소 모듈(Part 1)을 거치는 경우에는, 해당 모듈의 수행과 관련된 정보(메타데이터 등)가 생성되어서, 신경망 복원을 위해 압축 및 전송될 수 있다. 예컨대, 가지 치기 기법 및/또는 매트릭스 분해 기법의 수행 여부를 지시하는 정보(플래그)와 함께 해당 기법의 수행과 관련 된 정보들이 메타데이터로서, 파라미터 감소 모듈(Part 1)의 출력이 될 수 있는데, 이에 대해서는 후술한다. 그 리고 출력된 정보는 복원을 위하여 재구성 모듈(Part 3) 및/또는 디코딩 모듈(Part 5)로 전송될 수 있다. 파라미터 감소 모듈(Part 1)에서는 신경망을 기술하는 파라미터들의 집합을 감소시키는 과정을 수행한다. 파라 미터 감소 모듈(Part 1)에서는 가지치기(pruning) 등과 같은 성김화(sparsity) 기법 및/또는 행렬 분해(matrix decomposition) 기법 등이 적용될 수 있다. 성김화 기법은, 가중치를 'o'으로 설정하여 가중치들의 빈도를 희박 하게 하거나 또는 신경망의 연결관계를 잘라서 간소화하는 것을 목표로 한다. 그리고 행렬 분해 기법은, 신경망 의 파리미터 텐서(parameter tensors)를 보다 작은 행렬들로 분해한다. 이러한 성김화 기법과 행렬 분해 기법은 연속적으로 적용(예컨대, 먼저 가중치들을 성김화한 후에, 성김화된 가중치들의 행렬을 분해함)되거나 또는 둘 중에서 어느 하나의 기법만이 적용될 수도 있다. 파라미터 감소 모듈로의 입력 데이터는, 특정한 심층 학습 프레임워크에 의하여 특정되는 신경망을 기술하는 파 라미터들과 아키텍쳐(구조 정의)이다. 그리고 파라미터 감소 모듈로부터의 출력 데이터도, 상기 입력 데이터와 동일하다. 이러한 입력 데이터와 출력 데이터의 기술 포맷(representation format)에는 특별한 제한은 없는데, Keras/Tensorflow 또는 Pytorch 등이 적용될 수 있다. 성김화 또는 가지치기 유닛은 학습된 신경망(Learning Neural Networks)들을 감소된 파라미터 크기로 만든다. 가지치기는 각각의 단위, 예컨대 하나의 가중치나 채널 단위에서의 가중치의 중요도를 구하고, 중요도가 떨어지 는 가중치에 대한 연결을 제거(파라미터값을 0으로 함)한다. 이러한 가지치기 기법에서는, 원래의 성능을 유지하는 동안에 각각의 신경망들의 레이어가 가능한 네트워크들을 가지치기하도록, 좋은 임계값을 설정하는 것에서 문제가 발생한다. 다수의 레이어들로 구성된 신경망들에 대해, 특히 한 계층의 임계값이 다른 계층의 임계값들에 종속적일 수 있다는 것을 고려하면, 임계값을 찾기 위한 브루 트 포스는 실용적이지 않을 수 있다. 또한, 가지치기는 원래의 성능을 회복하기 위해 네트워크의 재훈련을 요구 할 수 있다. 이러한 가지치기 처리는 효율적이라고 확인되기 위해 상당한 시간이 소요될 수 있다. 본 명세서에 서 설명되듯이, 다양한 실시 예들에서, 네트워크를 재훈련하기 위한 방법들과 함께 임계값들의 자동 선택은 파 라미터들을 줄이기 위해 신경망을 가지치기하는 데 사용될 수 있다. 신경망 내에서 약한 반응(weak response) 또는 불필요한 파라미터를 가진 뉴런을 잘라내기 위하여, 해당 파라미 터의 중요성을 판정하기 위한 기준은 알고리즘에 따라서 변경될 수 있다. 이러한 기준은 도 4에 도시된 바와 같 이, 목적 함수(objective function)로 정의될 수 있다. 도 4를 참조하면, 가지치기 기법은 다음의 과정으로 진 행될 수 있다: 데이터 유형 결정(data type decision) -> 목적 함수 결정 및 파리미터 입력(object function decision & parameter input) -> 결정값을 가지치기(pruning decision value) -> 가지치기된 신경망 모델 (pruned NN model). 데이터 유형 결정 과정에서는 어떤 유닛(개별 또는 채널 단위)이 가지치기될 것인지를 판정한다. 그리고 목적 함수 결정 및 파리미터 입력 과정에서, 목적 함수는 파라미터들의 중요성을 가지고 목적 함수가 정의된다. 목적 함수를 정의하기 위한 파라미터들로는, 가중치 임계치(weight value threshold), 스케일링 팩터(scaling factor), 기울기(gradient) 등이 있다. 그리고 외적 파라미터들로는 가지치기 비율(pruning rate) 및/또는 임 의적이지만 재훈련을 위한 하이퍼파리미터(hyperparameter for re-training) 등이 있다. 가지치기 기법은 크게 학습 여부에 따라 2가지 방식으로 나뉠 수 있다. 첫 번째 방식은, 부가적인 학습 과정이 필요하지 않으며, 이미 학습된 가중치값을 기준으로 가지치기 기법을 수행한다. 예를 들어, 가중치값들의 임계 치(threshold)를 미리 설정해두고서, 이에 따라서 가중치값의 중요도를 판단한 다음 가지치기를 수행한다. 두 번째 방식은, 부가적인 학습 과정이 필요하며, 이 때는 학습에 필요한 하이퍼파라미터(hyperparameter)와 학습 데이터가 입력이 되어야 한다. 또한, 가지치기 기법은 추가적으로 압축율도 같이 설정할 수 있으며, 목적 함수 (objective function)는 가지치기 기법의 방법을 나타낸다. 예를 들어, 두 번째 가지치기 방식은, 학습된 가중 치값을 유지한 상태로, 스케일링 팩터(scaling factor)만을 학습하는 방법과 지정한 성능(task-based loss)에최대한 가까워지는 임계치(threshold)만을 학습하는 방법이 있다. 이러한 가지치기 기법과 관련하여, 전술한 파라미터들이나 설정된 임계치 등은, 신경망의 복원을 위한 메타데이 터로서, 신경망 복원을 위한 메타데이터로서 출력될 수 있다. 예를 들어, 가지치기 기법에서 추가적으로 필요한 마스크 정보(가중치가 0인 위치를 나타내는 정보) 및/또는 임계치 정보 등이, 가지치기 또는 성김화 과정의 메 타데이터로서 출력될 수 있다. 또한, 해당 과정에서 실제로 파라미터의 개수가 감소하였는지에 대한 정보(예컨 대, 복원의 신경망 모델의 차원(dimension)값과 압축 이전의 신경망 모델의 차원(dimension)값이 동일한지 여부 를 지시하는 플래그)도 가지치기 또는 성김화 과정의 메타데이터로서 출력될 수 있다. 매트릭스 분해 유닛에서는 1개의 층의 가중치 행렬(weight matrix)를 N(N은 2 이상의 정수)개의 가중치 행렬로 분해한다. 즉, 1개 층(layer)의 인덱스마다 N개의 인덱스가 생성되며, 원래 모델과는 다른 모델이 생성된다. 이 에 따라, 가중치 파라미터의 수를 줄일 수 있을 뿐만 아니라, 런타임 감수 효과도 기대할 수 있다. 이러한 매트 릭스 분해 기법은, 일반적으로 완전히 연결된(fully-connected) 층과 컨벌루션(convolution) 층에 적용이 가능 하다. 매트릭스 분해 기법의 일례는 하위 랭크(Low Rank, LR) 근사화 처리 또는 하위 디스플레이스먼트 랭크(Low Displacement Rank, LDR) 근사화 처리이다. 하위 랭크 근사화 처리 또는 하위 디스플레이스먼트 랭크 근사화 처 리는 다차원의 벡터 형식으로 표현되는 신경망의 가중치들을 그 보다 차원이 낮은 다수 개의 백터, 예컨대 행벡 터 및/또는 열벡터로 표현함으로써, 계산량을 줄이기 위한 것이다. 예컨대, 컨볼루션 계층에 적용되는 하위 랭크 근사화는 다음과 같이 수행될 수 있다: 2D-CNN에서 훈련된 콘볼루 션 가중치는 4D 유형(필터 크기, 필터 크기, 입력 채널 수, 출력 채널 수)이다. 수학식 1은 각 채널의 근사 방 정식을 보여준다. W_st의 차원은 d x d로 표현되는데, 여기서 d는 컬볼루션 계층의 필터 크기다. 또한, 하위 랭 크로 근사될 수 있는 행렬 Us, Vt의 차원은 d x R로 표현된다. 여기서 R은 하위 랭크 근사치를 위한 크기의 목 표치이다. 수학식 1"}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하위 랭크 근사화의 일 예에 의하면, 가중치들의 데이터 양을 감소하기 위하여, 각 컨벌루션 계층에서 가중치들 의 2D 커널 행렬은 2개의 1D 커널 행렬로 변환될 수 있다. 따라서, 이 방법의 목적은 W와 (U×V)의 최소 차이를 제공하는 (U,V)를 찾는 것이다. 필터 재구성을 최적화하기 위한 비용 함수는 수학식 2와 같다. 수학식 2"}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "하위-랭크 근사화의 다른 예에 의하면, 가중치들의 데이터 양을 감소시키기 위하여, 각 컨벌루션 계층에서 가중 치들의 2D 커널 행렬은 3개의 커널 행렬로 변환될 수 있다(예컨대, CP(CANDECOMP/PARAFAC) 분해 (decomposition)). 즉, 하나의 컨볼루션 가중치들을 3개의 가중치들로 분해한다. 이러한 CP 분해의 기본 공식은 수학식 3으로 표현될 수 있다. 수학식 3 여기서, R은 컴포넌트의 개수를 가리키는데, 이것은 텐서 랭크(tensor rank)이다. 일반적으로, 2D-CNN에서 존재하는 훈련된 컨벌루션 계층의 가중치는 4D 유형이다. T × S × D × D의 크기를 갖는 컨벌루션 커널 텐서 K는, 출력 채널에 대응하는 T, 입력 채널에 대응하는 S 및 커널 크기에 대응하는 D를 포함한다. CP 분해에서는 컨벌루션 커널 텐서 K를 랭크 R로 근사화한다. 이것은 다음의 수학식 4로 표현될 수 있다. 수학식 4"}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 및 은 각각 크기 및 를 갖는 3개의 컴포넌트이다. 따라서 분해된 결과는 다음의 수학식 5와 같이 매핑될 수 있다. 수학식 5"}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "일반적인 컨벌루션의 경우에, 컨벌루션 연산을 입력 채널 × 출력 채널의 수만큼 해야 하지만, depthwise 컨벌 루션의 경우에는 출력 채널의 수만큼 연산을 수행하면 된다. 이 때, 필터 재구성을 최적화하기 위한 비용함수는 다음의 수학식 6과 같다. 수학식 6"}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, 이다. 이러한 실시예에 따른 하위-랭크 근사화 방법에 의하면, 가중치 파라미터의 수를 줄일 수 있을 뿐만 아니라 연 산 속도도 향상시킬 수가 있다. 일반적으로, 매트릭스 분해 유닛의 출력은, 행렬 A, B(여기서, 행렬 A, B는 매트릭스 분해에 사용되는 행렬 인 자(factor)들), 랭크값(rank value, 정수 기반), 필터 재구성을 위한 리쉐이핑 모드(reshaping mode, 정수 기 반), 최초 행렬과 재구성된 행렬의 차원(dimension) 등이 있다. 이 출력의 전부 또는 일부는, 신경망 모델의 복 원/재구성을 위하여, 재구성 모듈(Part 3) 및/또는 디코딩 모듈(Part 5)로 전송될 수 있다. 이 중에서, 리쉐이핑 모드(W')는 하나 또는 복수의 모드를 가질 수 있다. 일례로, 리쉐이핑 모드(W')는 수학식 7과 같은 4개의 모드를 가질 수 있으며, 매트릭스 분해 유닛에서 어떠한 모드를 적용했는지 여부는 리쉐이핑 모 드 정보로서, 신경망 복원을 위해 전송되어야 한다. 수학식 7"}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 8은 하위 랭크 근사화 기법을 위한, 전연결 계층의 가중치 매트릭스를 기술하는 것이다. 수학식 8"}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "수학식 9는 하위 랭크 근사화 기법을 위한, 컨볼루션 계층의 가중치 매트릭스를 기술하는 것이다. 수학식 9"}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "하위 디스플레이스먼트 근사화 기법은, 분해 과정은 하위 랭크 근사화 기법과 동일하지만, 분해하는 과정의 입 력은 하위 랭크 근사화 기법과 상이하다. 수학식 10은 하위 디스플레이스먼트 근사화 기법을 기술하는 것이다. 수학식 10"}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "여기서, f값은 임의로 설정된다. 그리고 신경망 모델의 복원을 위해서는 행렬 A, B도 매트릭스 분해 유닛의 출 력이 되어야 하는 것을 알 수 있다. 이러한 매트릭스 분해 유닛의 출력은, 해당 파라미트 매트릭스가 전연결(FC) 계층에 대한 것인지 또는 컨볼루션 계층에 대한 것인지에 따라 달라질 수 있다. 그리고 내트릭스 분해 유닛의 출력은, 적용되는 기법이 하위 랭크 근사화 기법인지 또는 하위 디스플레이스먼트 근사화 기법인지에 따라서도 달라질 수 있다. 이것의 일례는 도 8에 도시되어 있다. 만일, 전연결 계층에 대하여 하위 랭크 근사화 기법이 적용되는 경우(LR & FC layers)에는, 매트릭스 분해 유닛의 출력은, 해당 과정에서 실제로 파라미터의 개수가 감소하였는지에 대 한 정보(예컨대, 복원의 신경망 모델의 차원(dimension)값과 압축 이전의 신경망 모델의 차원(dimension)값이 동일한지 여부를 지시하는 플래그), 랭크값, Reshape_mode=none, 최초 행렬의 차원 등이 포함될 수 있다. 대신에, 컨볼루션 계층에 대하여 하위 랭크 근사화 기법이 적용되는 경우(LR & Conv layers)에는, 매트릭스 분 해 유닛의 출력은, 해당 과정에서 실제로 파라미터의 개수가 감소하였는지에 대한 정보(예컨대, 복원의 신경망 모델의 차원(dimension)값과 압축 이전의 신경망 모델의 차원(dimension)값이 동일한지 여부를 지시하는 플래그), 랭크값, Reshape_mode= 1 (or 2, 3, 4), 최초 행렬의 차원 등이 포함될 수 있다. 만일, k번째 계층이 컨볼루션 계층이면, 계층 파라미터(Wk)는 4차원 텐서이다. 이 4차원 텐서는 로 분해될 수 있는데, 여기서 는 입력 채널의 수이고, 는 출력 채널의 수이며, 는 2D 필터 커널의 크기이다. 그리고 컨볼루션 계층 텐서(W)는 수학식 11을 이용하여 2D 매트릭스로 리 쉐이퍼(reshape)함으로써 압축할 수 있다. 수학식 11"}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "여기서, m은 1~4 중에서 어느 하나의 값을 갖는 모드값으로서, 모드는 다음의 수학식 12에 정의되어 있는 내용 에 기초하여 결정될 수 있다. 수학식 12"}
{"patent_id": "10-2021-0051763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "또한, 컨볼루션 계층에 대하여, 하위 디스플레이스먼트 근사화 기법이 적용되는 경우(LDR & Conv layers)에는, 매트릭스 분해 유닛의 출력은, 해당 과정에서 실제로 파라미터의 개수가 감소하였는지에 대한 정보(예컨대, 복 원의 신경망 모델의 차원(dimension)값과 압축 이전의 신경망 모델의 차원(dimension)값이 동일한지 여부를 지 시하는 플래그), 랭크값, Reshape_mode= 1 (or 2, 3, 4), 인자(factor) A, B, 최초 행렬의 차원 등이 포함될 수 있다. 파라미터 근사화 모듈에서는 추출된 파라미터 텐서들에 파라미터 근사화 기법을 적용한다. 파라미터 근사화 기 법은 예컨대, 양자화(quantization), 변환(transfomation), 예측(prediction) 등의 기법을 포함한다. 파라미터 근사화 모듈로의 입력은, 예컨대 numpy.float32 포맷의 넘파이 어레이(numpy array), 예컨대 가중치 행렬(일반적을로, 텐서 형태) 어레이로 표현되는 아이템으로, 네트워크의 모든 파라미터 텐서와 키(key)로서 그 들 각각의 명칭을 담고 있는 사전(dictionary) 형태이다. 각 파라미터 텐서의 명칭은, 해당 모델의 코디네이터 에 의하여 제공되는 각각의 모델 정의에 의하여 특정되는 명명법(예컨대, 테스트 모델에서의 명명법)과 일치하여야 한다. 파라미터 근사화 모듈로부터의 출력은, 세 개의 키, 즉 \"parameters\", \"int_parameters\" 및 \"metadata\"를 담고 있는 사전이다. 여기서, \"parameters\"는, 근사화 과정 동안에 수정되지 않는(즉, 근사화 과정과 상관 없는 파라 미터) 모든 파라미터들을 값(values)으로, 그리고 그들 각각의 이름을 키(keys)로 가지고 있는 사전 형태 (float-point로 저장)를 포함한다(예컨대, layer_type). 이것들은 예컨대 numpy.int32 포맷의 넘파이 어레이 (numpy array)로 표현될 수 있다. 그리고 \"int_parameters\"는, 근사화 과정을 통해 생기는 정수(interger) 기 반의 파라미터들, 즉 근사화 과정 동안에 수정되는 모든 파라미터 텐서들로서, 그들 각각의 정수 표현(integer representation)은 아이템으로, 그리고 그들 각각의 명칭은 키로 표현되는 사전을 포함한다. \"metadata\"는 근사 화 과정 동안에 생성되는 모든 메타데이터를 포함(저장)한다. 이러한 메타데이터는, 후속되는 재구성 과정에서 요구되는 모든 필요한 정보를 포함한다. 즉, 후속되는 재구성 과정에서는, 예컨대 네트워크의 모든 numpy.int32 포맷의 파라미터 텐서들을 numpy.float32 포맷으로 표현되도 록 할 수 있어야 한다. 메타데이터들은 모든 파라미터들(전역, global)에 의하여 공유되거나(예를 들어, 양자화 를 수행할 때 발생하는 코드북이나 step_size 등) 또는 특정 파라미터들(국지, local)에 의하여 공유될 수 있다 (예를 들어, per_layer 파라미터처럼 레이어 특성마다 바뀌는 메타데이터들이 해당됨). 후자의 경우에, 재구성 과정을 위하여, 파라미터 명칭과 메타데이터 사이의 개별적인 매핑이 제공되어야 한다. 서로 다른 근사화 기법 사이의 유연성을 확보하기 위하여, 메타데이터의 구체적인 포맷은, 사용되는 특정한 기법에 따라서 임의로 선택 될 수 있다. 그러나 일관성의 보장을 위하여, 사전 구조가 바람직하다. 메타데이터는, 예컨대 양자화 과정에서 발생하는 step_size 및 codebook 정보를 포함한다. 또한, 부가적으로 필 요한 파라미터들(예를 들면, RD를 구할 때의 lambda값이나 step_size를 학습해서 구할 때 필요한 하이퍼파라미 터들)도 메타데이터로 표현될 수 있다. 재구성 모듈에서는, 파라미터 근사화 모듈에 의해서 생성되는 근사화된 파라미터 텐서를 복원한다. 일반적으로, 비트스트림에서 복원된 메타데이터 정보를 이용하여, 근사화된 파라미터 텐서를 복원할 수 있다. 재구성 모듈로 의 입력은, 파라미터 근사화 모듈의 출력과 동일한 포맷을 갖는다. 그리고 재구성 모듈로부터의 출력은, 근사화 모듈의 입력과 동일한 포맷을 갖는다. 도 5a 및 도 5b는 파라미터 근사화 모듈의 인터페이스를 보여 주는 도면이다. 도 5a 및 도 5b를 참조하면, 파라 미터 근사화 모듈은, 파라미터 근사화 과정(도 5a)과 재구성 과정(도 5b)에 대한 인터페이스 정의를 제공한다. 인코딩 모듈은 엔트로피 인코딩 기법을 사용한다. 인코딩 모듈에서는 인코딩을 할 수 있는 데이터 포맷과 인코 딩을 할 수 없는 데이터 포맷을 식별할 수 있다. 인코딩 모듈이 해석(이해)할 수 없는 모든 데이터는, \"보조 데 이터(auxiliary data)\"로 분류되어서, 일련화된 방식(serialized manner)으로 비트스트림으로 바로 전달된다. 인코딩 모듈의 입력은 파라미터 근사화 모듈의 출력과 동일한 포맷을 갖는다. 그리고 인코딩 모듈의 출력은, 예 컨대 numpy.float32 포맷의 넘파이 어레이로 표현되는 비트스트림이다. 이러한 비트스트림은 입력 사전 내의 모 든 아이템에 대한 정보를 담고 있다. 키 명칭이나 사전 구조 등과 같은 다른 정보들은 비트스트림으로 인코딩될 필요가 없다. 엔트로피 인코딩에서는, 예컨대 가중치 파라미터들을 왼쪽 위에서부터 스캔을 시작할 수 있다. 즉, 왼쪽에서 오 른쪽으로 행 우선 방식으로 스캔한 뒤, 위쪽에서 아래쪽으로 행을 스캔한다. 이진화 과정에서는 양자화된 인덱스값들을 이진화 형태로 저장한다. 예컨대, 양자화된 인덱스값은 \"Sig_flag\", \"Sign_flag\", \"AbsGrXFlag\", \"MaxNumNoRem\" 및/또는 \"RemAbs\" 값을 이용하여, 이진화하여 표현될 수 있다. 여 기서, \"Sig_flag\"는 인덱스값이 0인지 아닌지에 대해서 나타낸다. \"Sign_flag\"는 0이 아닌 인덱스값의 부호를 나타낸다. \"AbsGrXFlag\"는 인덱스값의 크기를 나타내는 것으로서, 만약, AbsGrXFlag==1이면, 해당 인덱스값은 X 값(일반적으로 2의 지수승으로 표현됨)보다 큰 것을 의미하며, 이에 따라서 해당 플래그가 0이 나올때가지 계속 나타내어야 한다. \"MaxNumNoRem\"는 최대로 나타낼 AbsGrX를 나타내며, \"RemAbs\"는 인덱스값이 MaxNumNoRem을 갖닌 AbsGrXFlag값이 0일 때, 발생하는 나머지 값들을 이진화 표현 형태로 나타낸다. 이 때, 나머지 값을 나타 내는 빈(bin)들은 바이패스(bypass)로 코딩한다. 예를 들어, MaxNumNoRem==8이면, index 절대값 5~8인 경우는 RemAbs의 값을 보내주어야 한다. 컨택스트 모델에서는, 이진화 과정에서 사용한 \"Sig_flag\", \"Sign_flag\", \"AbsGrXFlag\" 등이 해당된다. 도 6a는 엔트로피 코딩이 사용되는 인코딩 모듈의 인터페이스를 보여주는 도면이 다. 디코딩 모듈에서는 입력되는 비트스트림에 대한 무손실 디코딩을 수행한다. 디코딩 모듈의 입력은, 인코딩 모듈 에서 특정되는 비트스트림이며, 또한 아이템이 없는 빈 사전의 경우에는 인코딩 모듈의 입력과 동일한 포맷을 가진다. 디코딩 모듈의 출력은, 파라미터 근사화 모듈의 입력과 동일하 포맷의 사전 형태를 갖는다. 그러나 디 코딩 모듈의 출력은, 파라미터 근사화 모듈의 출력 내에 존재하는 파라미터, 메타데이터, int_parameter와 동일 해야 한다(loseless coding). 도 6b는 엔트로피 디코딩이 사용되는 디코딩 모듈의 인터페이스를 보여 주는 도면 이다. 도 7a 내지 도 7d는 신경망의 압축 및 복원을 위한 프레임워크를 구성하는 각 모듈에서의 메타데이터의 신택스 헤더 테이블를 보여 주는 것으로서, 도 7a는 파라미터 근사화 모듈에서의 메타데이터의 신택스 헤더 테이블을, 도 7b는 재구성 모듈에서의 메타데이터의 신택스 헤더 테이블을, 도 7c는 인코더 모듈에서의 신택스 헤더 테이 블을, 도 7d는 디코더 모듈에서의 신택스 헤더 테이블을 보여 준다. 도 9a 내지 도 9d는 복원(디코딩) 과정에서 사용되는 엔트로피 코딩 신택스의 일례를 보여 주는 것이다. 보다 구체적으로, 도 9a는 계층 신택스(Layer Syntax)를 보여 주는 것이다. 도 9a에서 파라미터 \"end_of_quant_layer_one_bit\"는 종료 비트(terminating bit, \"1\")를 가리키며, 파라미터 \"nseting_zero_bit\" 는 0으로 설정되는 1비트이다. 도 9b는 양자화 파라미터 신택스(Quantization Parameter Syntax)를 보여 주는 것이다. 도 9b에서 파라미터 \"qp\"는 양자화 파라미터(quantization parameter)를 가리킨다. 도 9c는 양자화된 가중치 텐서 신택스(Qunatized Weight Tensor Syntax)를 보여 주는 것이다. 도 9d는 양자화된 가중치 신택스(Qunatized Weight Syntax)를 보여 주는 것이다. 도 9d에서 파라미터 \"sig_flag\"는 양자화된 가중치(QunatWeight[i])가 0이 아닌지를 가리키는 것으로서, 값이 '0'이면 양자화된 가 중치(QunatWeight[i])가 0인 것을 나타낸다. 파라미터 \"sign_flag\"는 양자화된 가중치(QunatWeight[i])가 양수 인지 또는 음수인지를 가리키는 것으로서, 값이 '1'이면 양자화된 가중치(QunatWeight[i])가 음인 것을 나타낸 다. 파라미터 \"abs_level_greater_x[j]\"는 양자화된 가중치(QunatWeight[i])의 절대값이 'j+1' 보다 큰지를 가 리키며, \"abs_level_greater_x2[j]\"는 지수 골롬 나머지(exponential golomb remainder)의 단항 부분(unary part)을 포함하며, 파라미터 \"abs_remainder\"는 고정된 길이의 나머지를 가리킨다. 전술한 바와 같이, 이상의 설명은 실시예에 불과할 뿐이며 이에 의하여 한정되는 것으로 해석되어서는 안된다. 본 발명의 기술 사상은 후술하는 특허청구범위에 기재된 발명에 의해서만 특정되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다. 따라서 전술한 실시 예가 다양한 형태로 변형되어 구현될 수 있다는 것은 통상의 기술자에게 자명하다."}
{"patent_id": "10-2021-0051763", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 비디오 압축을 위한 사용예(use case)에서의 MPEG-NNR 프레임워크로서 DNN 기반 비디오 코딩 시스템을 보여 주는 것이다. 도 2는 도 1의 신경망 압축부가 구현된 컴퓨터 시스템의 구성의 일례를 보여 주는 도면이다. 도 3은 도 1의 신경망 압축부에서의 신경망 압축을 위한 시스템의 일례를 보여 주는 도면이다. 도 4는 파라미터 근사 모듈의 일례로서, 가지치기 유닛에서의 가지치기 과정의 일례를 보여 주는 흐름도이다. 도 5a는 파라미터 근사화 모듈의 파라미터 근사화 과정에 대한 인터페이스를 보여 주는 도면이다. 도 5b는 파라미터 근사화 모듈의 재구성 과정에 대한 인터페이스를 보여 주는 도면이다. 도 6a는 엔트로피 코딩이 사용되는 인코딩 모듈의 인터페이스를 보여주는 도면이다. 도 6b는 엔트로피 디코딩이 사용되는 디코딩 모듈의 인터페이스를 보여 주는 도면이다. 도 7a 내지 도 7d는 신경망의 압축 및 복원을 위한 프레임워크를 구성하는 각 모듈에서의 메타데이터의 신택스 헤더 테이블를 보여 주는 것으로서, 도 7a는 파라미터 근사화 모듈에서의 메타데이터의 신택스 헤더 테이블을, 도 7b는 재구성 모듈에서의 메타데이터의 신택스 헤더 테이블을, 도 7c는 인코더 모듈에서의 신택스 헤더 테이 블을, 도 7d는 디코더 모듈에서의 신택스 헤더 테이블을 보여 준다. 도 8은 매트릭스 분해 유닛의 출력의 유형을 설명하기 위한 도면이다. 도 9a 내지 도 9d는 복원(디코딩) 과정에서 사용되는 엔트로피 코딩 신택스의 일례를 보여 주는 것이다."}
