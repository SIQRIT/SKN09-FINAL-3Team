{"patent_id": "10-2024-0136999", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0159807", "출원번호": "10-2024-0136999", "발명의 명칭": "인공지능 기반 블렌디드 러닝 시스템 및 방법", "출원인": "(주)엔에스데블", "발명자": "이언주"}}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "온라인 학습(IBL) 또는 유비쿼터스 기반 학습(UBL) 시에, 학습자의 출석을 기록하고 학습 콘텐츠를 제공하며,사용자 단말의 정면 카메라를 주시하며 학습자가 바른 정면 자세로 주의집중 학습되도록 학습자의 얼굴 부분의학습 패턴을 저장하고, 학습자의 얼굴 부분의 학습 자세를 얼굴의 윤곽선과 눈/코/귀/입을 포함하여 3D 렌더링하여 표시하며, 학습자의 학습 패턴에 등급/점수를 기록하며 학습 자세의 통과/탈락 예측과 학습 분석 차트의통계 데이터를 시각화하여 출력하는 LRS 서버; 상기 LRS 서버와 유무선 통신망을 통해 연결되고, 상기 학습 콘텐츠를 제공받고 카메라와 안면인식 모듈을 구비하며, 학습자의 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들 인식하고, 학습자의 말소리를 인식하며, 학습자의3D 학습 얼굴과 학습 패턴과 통계 데이터를 제공받으며, 3D 렌더러와 미디어 재생부와 상기 안면인식 모듈과 음성인식 모듈을 구비한 학습자 단말들; 및 상기 LRS 서버와 유무선 통신망을 통해 연결되는 감독관 단말을 포함하고, 상기 LRS 서버는 3D 학습 콘텐츠를 제공하며, 실시간으로 상기 학습자의 3D 학습 얼굴을 상기 학습자 단말의 카메라를 주시하는 얼굴 모습이 표현되는 얼굴의 윤곽선과 머리와 이마/눈/코/귀/입을 포함하여 3D 모델링하여 렌더링하는 3D 렌더러를 더 포함하는 인공지능 기반 블렌디드 러닝 시스템."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 학습자 단말들과 상기 감독관 단말은 PC, 노트북, 스마트폰 또는 태블릿 PC를 사용하는, 인공지능 기반 블렌디드 러닝 시스템."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 학습자 단말은 얼굴의 윤곽선과 눈2/코/귀2 안면인식 모듈이 구비되며, 상기 안면인식 모듈은 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 인식하기 위해 posenet 알고리즘을 사용하는, 인공지능 기반 블렌디드 러닝 시스템."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 학습자 단말은 상기 음성인식 모듈이 구비되고, 상기 음성인식 모듈은 주변 잡음을 필터링하고 학습자의말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음성을 인식하기 위해 SileroVAD 및 SpeechBrain 알고리즘을사용하는, 인공지능 기반 블렌디드 러닝 시스템."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 LRS 서버는 상기 학습자 단말과 상기 감독관 단말과 유무선 통신을 통해 연결되는 WWW 서버; 유무선 통신망을 통해 태블릿 상기 학습자 단말과 상기 감독관 단말로 온라인 학습(IBL)과 시험(IBT) 또는 유비쿼터스 기반 학습(UBL)과 시험(UBT)의 응용 서비스를 제공하도록 제어하는 제어부; 상기 제어부에 연결되며, 학습자의 회원 정보를 등록받아 ID/Passwd를 저장하여 관리하는 회원 등록부; 공개특허 10-2024-0159807-3-상기 제어부에 연결되며, 학번/passwd, QR 코드/Passwd 또는 ID/Passwd 또는 온라인 인증서를 사용하여 사용자를 인증하는 사용자 인증부; 상기 제어부에 연결되며, 온라인 학습(IBL)과 시험(IBT) 또는 유비쿼터스 기반 학습(UBL)과 시험(UBT)의 출석을관리하는 출석관리부; 상기 제어부에 연결되며, 온라인 학습(IBL) 또는 유비쿼터스 기반 학습(UBL) 콘텐츠를 제공하는 학습 콘텐츠 제공부; 상기 제어부에 연결되며, 학습자별로 학습자의 안면인식 데이터를 수신받아 얼굴의 윤곽선과 눈2/코/귀2 얼굴의특징점들을 추출하여 온라인 학습 IBL/UBL 주의집중 학습되도록 학습자의 얼굴의 학습 패턴을 분석하는 안면인식 분석부; 상기 제어부에 연결되며, 학습자별로 학습자의 음성인식 데이터를 수신받아 학습자의 소리 패턴을 분석하는 음성인식 분석부; 상기 제어부에 연결되며, 실시간으로 수신되는 학습자의 안면 인식 데이터 및/또는 학습자의 말소리 데이터를수신받아 학습자별 학습 관련 빅 데이터를 수신받아 학습 패턴 통계 데이터를 시각화하여 학습 패턴 파이 차트,막대그래프, 산점도를 표시하는 빅 데이터 분석/통계 제공부; 및 교수자와 과목 학습자DB, 학습 콘텐츠DB, 및 얼굴 사진 DB를 포함하는 인공지능 기반 블렌디드 러닝 시스템."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 LRS 서버는 학습자 단말들과 감독관 단말과 연결되고 실시간으로 학습자의 얼굴 영상과 음성 데이터를 저장하고 스트리밍 서비스를 제공하는 NVR 서버를 더 포함하는 인공지능 기반 블렌디드 러닝 시스템."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 온라인 학습 IBL 또는 UBL 학습/또는 시험 시에, 상기 감독관 단말은 상기 LRS 서버를 통해 다수의 학습자 단말의 학습자의 출석을 확인하고, 안면인식과 음성인식 기술을 활용한 AI 감독관으로써, 학습자별 학습 패턴을 모니터링하며, 학습자의 두 눈의 아이트랙킹, 눈2/코/귀2의 안면 인식 데이터 및 주변 화이트 노이즈를 필터링한학습자의 말소리의 음성 인식 데이터를 모니터링하다가, 학습자의 학습 자세가 비딱하면(학습자의 비딱한 자세,고개 돌림, 말소리) 눈과 귀의 거리와 코와 귀의 거리를 포함하는 특징점들과의 거리가 일정 기준치 이하로 학습 자세가 삐탁하거나 고개를 상하 방향/좌우 방향으로 돌리거나, 말소리가 들리면, 해당 사용자 단말로IBL/UBL 주의집중 학습되도록 경고 메시지 또는 알람을 전송하는, 인공지능 기반 블렌디드 러닝 시스템."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 LRS 서버에 연동된 상기 학습자 단말에서, 학습 시간 동안, 녹음/녹화 데이터(소리 파일과 이미지 파일이통합된 영상 파일)을 상기 LRS 서버로 전송하여 저장되는 상기 학습자 단말에 구비된 녹음 및 녹화 프로그램을구비하는, 인공지능 기반 블렌디드 러닝 시스템."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제5항에 있어서, 상기 LRS 서버는 온라인 시험 IBT 또는 UBT 시험을 위해, 응시자의 얼굴의 윤곽선과 눈2/코/귀2의 시각적인 부정행위를 감지하는안면인식 분석부와 말소리를 분석하는 음성인식 분석부를 기본적으로 구비하며, 상기 제어부에 연결되며, 응시자 단말과 상기 감독관 단말로 시험 프로그램(App)과 시험지를 제공하며, 응시자정보들과 응시자의 현장 얼굴 사진, 감독관 정보를 관리하며, 상기 온라인 시험 IBT 또는 상기 UBT 시험 시에일정 시험 시간 이내에 각각의 응시자 단말에 시험지 작성 답안을 저장 후 시험 종료시 시험 서버로 전송되며,공개특허 10-2024-0159807-4-응시자들의 시험지 작성 답안, 채점 결과, 감독관 정보와 응시자 현황 정보를 저장하여 관리하는 시험 관리부;응시자들의 시험지와 작성 답안, 채점 결과를 저장하는 시험 정보DB; 및응시자 정보와 표준 크기의 정면 얼굴 사진을 저장하는 응시자DB와 얼굴 DB, 시험 DB를 더 포함하는 인공지능기반 블렌디드 러닝 시스템."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "(a) 온라인 학습(IBL) 또는 유비쿼터스 기반 학습(UBL) 시에, 3D 렌더러와 미디어 재생부와 안면인식 모듈과 음성 인식 모듈을 구비한 학습자 단말로부터 LRS 서버에 접속하여 ID/Passwd 로그인 후 학습자의 출석을 등록하여상기 LRS 서버로부터 학습 콘텐츠를 제공받는 단계; 및 (b) 상기 LRS 서버가 학습자의 출석을 기록/저장하고 학습 콘텐츠를 제공하며, 상기 학습자 단말의 정면 카메라를 주시하며 학습자가 정면 바른 자세로 주의 집중학습되도록 학습자의 얼굴 부분의 학습 패턴을 저장하고, 학습자의 얼굴 부분의 학습 자세를 표시하는 얼굴의 윤곽선과 눈/코/귀/입을 포함하여 3D 렌더링하여 표시하며,학습자의 얼굴 부분의 학습 패턴에 등급/점수를 기록하며, 학습 자세의 통과/탈락 예측과 학습 분석 차트의 통계 데이터를 시각화하여 출력하는 단계를 포함하며, 상기 LRS 서버는 실시간으로 학습자의 3D 학습 얼굴을 상기 학습자 단말의 카메라를 주시하는 얼굴 모습이 표현되는 얼굴의 윤곽선과 머리와 이마/눈/코/귀/입을 포함하여 3D 모델링하여 렌더링하는 3D 렌더러를 더포함하며, 상기 3D 렌더러에 의해 실시간으로 상기 학습자의 3D 학습 얼굴을 상기 학습자 단말의 카메라를 주시하는 얼굴모습이 표현되는 얼굴의 윤곽선과 머리와 이마/눈/코/귀/입을 포함하여 3D 모델링하여 렌더링하며, 상기 학습자단말은 상기 학습자의 3D 학습 얼굴과 학습 패턴과 통계 데이터를 제공받는 단계를 더 포함하는 인공지능 기반블렌디드 러닝 서비스 방법."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 학습자 단말들과 감독관 단말은 PC, 노트북, 스마트폰 또는 태블릿 PC를 사용하는, 인공지능 기반 블렌디드 러닝 서비스 방법."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 학습자 단말은 얼굴의 윤곽선과 눈2/코/귀2 안면인식 모듈이 구비되며, 상기 안면인식 모듈은 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 인식하기 위해 posenet 알고리즘을 사용하는, 인공지능 기반 블렌디드 러닝 서비스 방법."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서, 상기 학습자 단말은 상기 음성인식 모듈이 구비되고, 상기 음성인식 모듈은 주변 잡음을 필터링하고 학습자의말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음성을 인식하기 위해 SileroVAD 및 SpeechBrain 알고리즘을사용하는, 인공지능 기반 블렌디드 러닝 서비스 방법."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서, 상기 학습자 단말은 얼굴의 윤곽선과 눈2/코/귀2 안면인식 모듈이 구비되며, 상기 LRS 서버와 유무선 통신망을통해 연결되고, 상기 학습 콘텐츠를 제공받고 카메라와 안면인식 모듈을 구비하며 학습자의 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 인식하며, 학습자의 학습 자세가 비딱하면(학습자의 비딱한 자세, 고개 돌림, 말소리) 눈과 귀의 거리와 코와 귀의 거리를 포함하는 특징점들과의 거리가 일정 기준치 이하로 학습 자세가 비딱하공개특허 10-2024-0159807-5-거나 고개를 상하 방향/좌우 방향으로 돌리거나, 해당 사용자 단말로 IBL/UBL 주의집중 학습되도록 자체적으로경고 메시지 또는 알람을 출력하는, 인공지능 기반 블렌디드 러닝 서비스 방법."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서, 온라인 학습 IBL 또는 UBL 학습/또는 시험 시에, 상기 LRS 서버에 접속된 감독관 단말은 다수의 학습자 단말의학습자의 출석을 확인하고, 안면인식과 음성인식 기술을 활용한 AI 감독관으로써, 학습자별 학습 패턴을 모니터링하며, 주변 화이트 노이즈를 필터링한 학습자의 말소리의 음성 인식 데이터를 모니터링하다가, 학습자의 말소리가 들리면, 해당 사용자 단말로 IBL/UBL 주의집중 학습되도록 경고 메시지 또는 알람을 전송하는 단계를 더포함하는 인공지능 기반 블렌디드 러닝 서비스 방법."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서, 상기 LRS 서버는 상기 학습자 단말과 감독관 단말과 유무선 통신을 통해 연결되는 WWW 서버; 유무선 통신망을 통해 상기 학습자 단말과 상기 감독관 단말로 온라인 학습(IBL)과 시험(IBT) 또는 유비쿼터스기반 학습(UBL)과 시험(UBT)의 응용 서비스를 제공하도록 제어하는 제어부; 상기 제어부에 연결되며, 학습자의 회원 정보를 등록받아 ID/Passwd를 저장하여 관리하는 회원 등록부; 상기 제어부에 연결되며, 학번/Passwd, QR 코드/Passwd 또는 ID/Passwd 또는 온라인 인증서를 사용하여 사용자를 인증하는 사용자 인증부; 상기 제어부에 연결되며, 태블릿 PC, 스마트폰, PC 기반 온라인 학습(IBL)과 시험(IBT) 또는 유비쿼터스 기반학습(UBL)과 시험(UBT)의 출석을 관리하는 출석관리부; 상기 제어부에 연결되며, 온라인 학습(IBL) 또는 유비쿼터스 기반 학습(UBL) 콘텐츠를 제공하는 학습 콘텐츠 제공부; 상기 제어부에 연결되며, 학습자별로 학습자의 안면인식 데이터를 수신받아 얼굴의 윤곽선과 눈2/코/귀2 얼굴의특징점들을 추출하여 온라인 학습 IBL/UBL 주의집중 학습되도록 학습자의 얼굴의 학습 패턴을 분석하는 안면인식 분석부; 상기 제어부에 연결되며, 학습자별로 학습자의 음성인식 데이터를 수신받아 학습자의 소리 패턴을 분석하는 음성인식 분석부; 상기 제어부에 연결되며, 실시간으로 수신되는 학습자의 안면 인식 데이터 및/또는 학습자의 말소리 데이터를수신받아 학습자별 학습 관련 빅 데이터를 수신받아 학습 패턴 통계 데이터를 시각화하여 학습 패턴 차트, 막대그래프, 산점도를 표시하는 빅 데이터 분석/통계 제공부; 및 학습자DB, 학습 콘텐츠DB, 및 얼굴 사진 DB를 포함하는 인공지능 기반 블렌디드 러닝 서비스 방법."}
{"patent_id": "10-2024-0136999", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항에 있어서, 학습 시간 동안, 상기 학습자 단말에 구비된 녹음 및 녹화 프로그램의 녹음/녹화 데이터(소리 파일과 이미지 파일이 통합된 영상 파일)을 상기 LRS 서버로 전송하여 저장되는 단계를 더 포함하는 인공지능 기반 블렌디드 러닝 서비스 방법."}
{"patent_id": "10-2024-0136999", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 기반 블렌디드 러닝 시스템 및 방법이 개시된다. 상기 블렌디드 러닝 시스템은 온라인 학습 또는 유비 쿼터스 기반 학습(UBL) 시에, 학습자의 출석을 기록하고 학습 콘텐츠를 제공하며, 사용자 단말의 정면 카메라를 주시하며 학습자가 바른 자세로 주의집중 학습되도록 학습자의 안면인식과 음성 인식을 통해 학습자의 학습 패턴 (뒷면에 계속)"}
{"patent_id": "10-2024-0136999", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 AI 기반 블렌디드 러닝(blended learning) 시스템에 관한 것으로, 보다 상세하게는 비대면 온라인 학 습(IBL, Internet based learning)과 유비쿼터스 기반 학습(UBL, Ubiquitous based learning)에서 LRS 서버와연동하여 사용자 단말은 3D 렌더러와 미디어 재생부와 안면인식 모듈과 음성인식 모듈을 구비하고, 학습 콘텐츠 를 제공하며 학습자의 얼굴의 학습 패턴을 모니터링하는 LRS 서버에 연동된 사용자 단말의 정면 카메라에 포커 싱된 학습 콘텐츠에 정면 시선을 바로보고 주의집중 학습되도록 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점들 을 안면 인식을 하며, 학습자의 얼굴의 학습 패턴을 모니터링하고 일정 각도로 시선이 빗나갈 경우 또는 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어깨와 어깨의 거리의 해 당 방향의 거리가 일정 기준치를 넘는 경우, 말소리가 들리는 경우 소리와 메시징 기술을 사용하여 주의 집중 학습하도록 해당 사용자 단말로 알람/경고 메시지를 발생하는, 인공지능 기반 블렌디드 러닝 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2024-0136999", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "얼굴 인식(Face Recognition) 기술은 형상 기반 매칭 방법(appearance based matching method), 및 특징 (feature) 기반의 얼굴 인식이 주로 사용된다. 얼굴 인식은 카메라의 촬영 각도, 조명의 방향, 자세(pose), 표 정의 변화 및 시간에 따른 얼굴의 변화에 따라 다르게 인식된다. 특징(feature) 기반의 얼굴 인식은 디지털 카메라, IoT 디바이스의 카메라 또는 스마트폰의 카메라로 촬영된 영 상 데이터를 Haar-like feature를 이용한 검출 방법과 MCT(Modified Census Transform) 영상을 이용한 검출 방 법이 사용된다. 스마트폰의 카메라의 입력 영상에서 Haar-like feature로 학습된 얼굴 및 눈 검출기를 사용하여 얼굴의 윤곽선과 이마/눈/코/입을 검출하고, 원형의 눈동자를 검출하기 위해 관심 영역(ROI, Region of Interest)으로 설정된 눈 영역을 grayscale로 변환하며, 눈 영역에서 눈동자와 눈의 외곽선 영역이 추출되는 실 험에 의한 통계적인 임계값(threshold)을 사용하여 눈 이미지의 histogram[x축 각 픽셀의 화소값, y축 해당 화 소 값의 갯수]을 구하고 눈의 이미지를 otsu 알고리즘에 의해 이진화(binarization)한 후, 히스토그램 평활화 (histogram equalization)를 통해 눈 영역의 사진의 전처리를 수행하며, 얼굴 영역에서 윤곽선과 눈썹과 눈, 코, 입의 얼굴 특징 얼굴데이터를 검출하고, 텍스처 특징(texture features)과 형상 특징(shape features)을 추출하여 얼굴 인식 DB에 저장된 얼굴 사진의 특징점들과 유사도를 비교하여 얼굴이 인식된다. 얼굴 영역의 눈썹과 눈, 코, 입, 턱의 특징 값은 Haar-like feature의 흰 영역에서 포함되는 픽셀들의 합에서 검은 영역에서 포함되는 픽셀의 합의 차로 표현된다. 예를들면, 가로와 세로 표준 크기의 얼굴 영역 사진에서 검출된 눈 영역에서 오른쪽과 왼쪽 눈의 양쪽 끝점 까 지의 거리, 허프 원 변환(hough circle transform) 알고리즘을 사용하여 추출된 눈동자(iris)의 크기 값이 특징 값으로 사용된다. 도 1a는 기존 얼굴 인식 장치의 구성도이다. 얼굴 인식 장치는 영상 표시 장치, 영상 촬영 장치, 얼굴 인식 서버, 태블릿 PC, 랩톱(Laptop), 개인용 PC, 스마트폰, 개인 휴대용 단말기(Personal Digital Assistant, PDA), 이동통신 단말기, 및 지능형 로봇 (Intelligence Robot) 등 중 어느 하나 단말일 수 있다. 얼굴 인식 장치는 카메라로부터 입력 영상을 획득하는 입력 영상 획득부; 상기 입력 영상에서 얼굴 영역을 검출하여 얼굴 포즈(Pose)를 정규화함으로써 정면 포즈 영상을 생성하고, 상기 카메라와 피사체 간의 거 리에 따른 원근왜곡(Perspective Distortion)을 제거하기 위하여 상기 정면 포즈 영상의 원근감(Perspective) 을 정규화하여 정규화 영상을 생성하는 정규화부; 상기 정규화 영상으로부터 상기 피사체의 얼굴을 표현하 는 특징 벡터(feature vector)를 추출하는 특징 벡터 추출부; 및 기 학습된 분류 모델에 상기 특징 벡터를 적용하여 상기 입력 영상에 포함된 상기 피사체의 얼굴을 인식하는 얼굴인식부를 포함한다. 입력 영상 획득부는 카메라로부터 입력 영상을 획득한다. 카메라는 깊이인식 카메라, 스테레오 카메라, 및 컬러 카메라일 수 있다(예를 들면, Kinect 카메라 등). 또한, 입력 영상은 인식 대상이 되는 피사체의 얼굴이 포함된 영상으로서 2차원 정지영상 및 동영상을 포함한다. 입력 영상은 컬러 영상, 깊이 영상, 및 컬러-깊이 (RGB-D) 영상을 포함할 수 있다. 정규화부는 입력 영상으로부터 얼굴 영역을 검출하고, 얼굴 포즈(Pose) 및 원근감(Perspective)을 정규화 하여 정규화 영상을 생성한다. 얼굴 포즈에 변화가 있는 경우, 그레이스케일, 형상, 얼굴의 특징점들의 위치 등 이 달라지기 때문에 얼굴 인식률이 저하된다. 또한, 카메라와 피사체 간의 거리가 달라지면 동일한 피사체라 하 더라도 촬영된 위치마다 원근 왜곡(Perspective Distortion, 뒤틀림)이 다르게 발생하므로, 다른 피사체를 촬영 한 것처럼 보이기도 한다. 따라서, 얼굴인식률을 향상시키기 위해 입력 영상의 얼굴 포즈 및 원근감을 정규화할필요가 있다. 정규화부는, 다양한 포즈의 학습용 얼굴 영상을 제1 인공신경망의 입력층에 입력하고, 정면포즈의 학습용 얼굴 영상이 상기 제1 인공신경망의 출력층에서 출력되도록 상기 제1 인공신경망을 학습시키는 얼굴포즈 정규화 학습부; 및 상기 제1 인공신경망의 출력층에서 출력된 데이터를 제 2 인공신경망의 입력층에 입력하고, 원근왜 곡이 없는 학습용 얼굴 영상이 상기 제 2 인공신경망의 출력층에서 출력되도록 상기 제2 인공신경망을 학습시키 는 원근감 정규화 학습부를 포함한다. 상기 정규화부는, 학습이 완료된 상기 제1 인공신경망과 상기 제2 인공신경망을 통합한 통합 인공신경망의 입력 층에 다양한 원근 왜곡이 있는 다양한 포즈의 학습용 얼굴영상을 입력하고, 정면 포즈의 원근 왜곡이 없는 학습 용 얼굴 영상이 상기 통합 인공신경망의 출력층에서 출력되도록 상기 통합 인공신경망을 학습시킨다. 특징 벡터 추출부는 기계 학습(Machine Learning)에 의해 결정되며, 정규화 영상으로부터 피사체의 얼굴을 표현하는 특징 벡터(feature vector)를 추출한다. 특징 벡터는 얼굴 인식에 사용되는 특징값들을 원소로 가지는 벡터이다. 특징벡터를 추출하는데 사용되는 필터 로써 Gabor 필터, Haar 필터, LBP(Local Binary Pattern) - DLBP(Discriminative LBP), ULBP(Uniform LBP), NLBP(Number LBP) 등을 포함 - 등이 있으나, 반드시 이에 한정되지 않으며 그 밖의 다른 필터가 사용될 수 있다. 얼굴 인식부는 기 학습된 분류 모델에 의해 특징 벡터 추출부에서 추출된 특징 벡터를 적용하여 입력 영상에 포함된 피사체의 얼굴을 인식한다. 기 학습된 분류 모델은 서포트 벡터 머신(Support Vector Machine, SVM), 선형 판별 분석(Linear Discriminant Analysis, LDA), 및 Softmax 등을 포함할 수 있으나, 반드시 이에 한정되지 않는다. 가상 얼굴 영상 생성부는 정규화부, 특징 벡터 추출부, 및 얼굴 인식부가 학습하는데 사용 되는 복수의 가상 얼굴 영상을 생성할 수 있다. 복수의 가상 얼굴 영상은 가상 얼굴 영상 생성부가 카메라로부터 획득된 하나 이상의 2차원 기준 영상을 이용하여 합성한 3차원 얼굴 모델을 변형시킴으로써 생성되는 얼굴 영상을 의미한다. 이와 관련된 선행기술2로써, 특허 등록번호 10-2103521에서는 “인공지능 심층학습 기반의 영상물 인식 시스템 및 방법“이 등록되어 있다. 도 1b는 종래의 인공 지능 심층 학습 기반의 영상물 인식 시스템의 구성도이다. 인공 지능의 심층 학습(Deep Learning)으로 다양한 이미지를 사전 학습하고, 상기 사전 학습 결과를 반영하여 유통되는 영상물에 대해 프레 임 단위로 이미지를 분석하고, 경우에 따라 영상물의 음성 정보도 함께 분석하여 시간순으로 키워드를 도출해 낸 후 사전에 축적되어 있던 영상물 대본의 시계열적 키워드와 비교하는 방식의 인공지능 심층학습 기반의 영상 물 인식 시스템 및 방법을 제공한다. 인공지능에 의해 구현되는 시스템은, 다수의 오브젝트 이미지를 키워드로 심층학습(DeepLearning)하는 데이터셋 학습부; 영상물 대본에서 키워드를 추출하여 시계열적으로 나열, 저장하는 DB부; 영상물을 프레임 단위 이미지 분석을 통해, 이미지 상의 오브젝트들과 오브젝트 간의 관계를 키워드로 추출하여 시계열적으로 나열하는 영상 물 분석부; 및 상기 DB부와 영상물 분석부의 키워드를 비교하여 유사성을 판단하는 비교판단부를 포함한다. 이와 관련된 선행기술1로써, 특허등록번호 10-1770817에서는 \"온라인 학습자를 위한 주의집중 판단 시스템 및 그 방법\"이 등록되어 있다. 상기 온라인 학습자를 위한 주의집중 판단 시스템은 콘텐츠를 입력받아 등록하는 입력부; 상기 등록된 콘텐츠에서 콘텐츠 정보를 생성하여 카테고리별로 저장하는 데이터베이스; 상기 등록된 콘텐츠 중 사용자가 선택한 콘텐츠를 디스플레이하는 디스플레이부; 상기 사용자가 선택한 콘텐츠에서 단어를 추출하고 상기 추출된 단어와 상기 카테고리별로 저장된 콘텐츠 정보 를 이용하여 콘텐츠 단어 및 노이즈 단어를 생성하는 단어 생성부; 및 상기 콘텐츠 단어 및 상기 노이즈 단어로 구성된 질의응답을 이용하여 상기 사용자의 주의집중 여부를 판단하는 주의집중 판단부;를 포함하며, 상기 단어 생성부는 기 콘텐츠가 등록되면 자동적으로 상기 콘텐츠로부터 자막 및 명사를 추출하여 단어를 생성 하고, 상기 저장된 콘텐츠 정보와 상기 생성된 단어에 대해서 각각 가중치를 계산하며, 상기 계산된 가중치에 따라 상기 콘텐츠 단어를 생성함으로써, 상기 가중치에 따라 상기 콘텐츠 단어를 포함하는 상기 질의응답을 사 용자에게 제공하고, 상기 단어 생성부는 상기 콘텐츠 단어 및 노이즈 단어를 학습자가 이전에 시청했던 콘텐츠를 기반으로 생성함으 로써, 동일한 콘텐츠에 대해서도 학습자마다 서로 다른 콘텐츠 단어 및 노이즈 단어를 생성한다. 이와 관련된 선행기술3로써, 특허 등록번호 10-1690546에서는 단말기의 음성인식을 통한 어학학습 방법 및 시스 템이 등록되어 있다. 도 1c를 참조하면, 단말기는 어학 어플리케이션 실행에 따른 화면을 제공하는 표시부; 개인의 발음 차이를 고려 하여 설정되는 다수의 패턴 데이터를 저장하는 단말저장부; 및 상기 어학 어플리케이션을 실행하여 적어도 하나 의 어학 문제를 제시하고, 상기 어학 문제에 대응하는 음성 데이터를 사용자로부터 수집하고, 상기 수집된 음성 데이터와 상기 다수의 패턴 데이터를 비교하고, 매칭도가 기 설정값 보다 높은 패턴 데이터를 선택하여 음성 인 식을 위한 범위를 설정하고, 상기 선택된 패턴 데이터와 상기 수집된 음성 데이터를 비교하여 음성 인식을 수행 한 후 어학문제에 대한 평가 결과를 생성하는 단말제어부 포함한다. 이와 관련된 선행기술4로써, 특허등록번호 10-2041618 (등록일자 2019년 10월 31일), \"인공지능 음성인식을 위 한 기계학습 기반 자연어 말뭉치 구축 서비스 제공 시스템 및 방법\"이 등록되어 있다. 그러나, 기존의 이러닝 또는 유러닝 시스템은 단순히 온라인 학습 콘텐츠를 제공하였으며, 얼굴 인식 기술과 소 리와 메시징 기술을 사용하여 학습자가 부주의하게 얼굴 시선이 이탈하면 실시간으로 AI 안면 인식에 의해 이를 감지하고, 해당 사용자 단말로 알람을 발생하며 주의집중 학습이 되도록 하는 블렌디드 러닝 시스템을 제공하지 않았다. 선행기술문헌 특허문헌 (특허문헌 0001) 특허등록번호 10-1770817 (등록일자 2017년 08월 17일), \"온라인 학습자를 위한 주의집중 판단 시스템 및 그 방법\", 고려대학교 산학협력단 (특허문헌 0002) 특허등록번호 10-2103521 (등록일자 2020년 04월 16일), \"인공지능 심층 학습 기반의 영상물 인식 시스템 및 방법\", 상명대학교 산학협력단 (특허문헌 0003) 특허등록번호 10-1690546 (등록일자 2016년 12월 22일), \"단말기의 음성인식을 통한 어학학습 방법 및 시스템\", 에스케이텔레콤 주식회사 (특허문헌 0004) 특허등록번호 10-2041618 (등록일자 2019년 10월 31일), \"인공지능 음성인식을 위한 기계학습 기반 자연어 말뭉치 구축 서비스 제공 시스템 및 방법\", (주)미디어코퍼스"}
{"patent_id": "10-2024-0136999", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기 문제점을 해결하기 위한 본 발명의 목적은 비대면 온라인 학습(IBL)과 유비쿼터스 기반 학습(UBL, Ubiquitous based learning)에서 LRS 서버와 연동하여 사용자 단말은 3D 렌더러와 미디어 재생부와 안면인식 모 듈과 음성인식 모듈을 구비하고, 학습 콘텐츠를 제공하고, 학습자의 얼굴 학습 패턴을 모니터링하는 LRS 서버에 연동된 사용자 단말의 정면 카메라에 포커싱된 학습 콘텐츠에 정면 시선을 바로보고 주의집중 학습되도록 얼굴 의 윤곽선과 눈2/코/귀2의 얼굴의 특징점들을 안면 인식을 하며, 학습자의 얼굴의 학습 패턴을 모니터링하고 일 정 각도로 시선이 빗나갈 경우 또는 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목 과 어깨의 거리, 어깨와 어깨의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우, 말소리가 들리는 경우 소 리와 메시징 기술을 사용하여 주의 집중 학습하도록 해당 사용자 단말로 알람/경고 메시지를 발생하는, 인공지능 기반 블렌디드 러닝 시스템을 제공한다. 본 발명의 다른 목적은 인공지능 기반의 블렌디드 러닝 서비스 방법을 제공한다."}
{"patent_id": "10-2024-0136999", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 목적을 달성하기 위해, 인공지능 기반 블렌디드 러닝 시스템은 온라인 학습(IBL) 또는 유비쿼터스 기 반 학습(UBL) 시에, 학습자의 출석을 기록하고 학습 콘텐츠를 제공하며, 사용자 단말의 정면 카메라를 주시하며 학습자가 바른 정면 자세로 주의 집중학습되도록 학습자의 얼굴 부분의 학습 패턴을 저장하고, 학습자의 얼굴 부분의 학습 자세를 얼굴의 윤곽선과 눈/코/귀/입을 포함하여 3D 렌더링하여 표시하며, 학습자의 학습 패턴에 등급/점수를 기록하며 학습 자세의 통과/탈락 예측과 학습 분석 차트의 통계 데이터를 시각화하여 출력하는 LRS 서버; 상기 LRS 서버와 유무선 통신망을 통해 연결되고, 상기 학습 콘텐츠를 제공받고 카메라와 안면인식 모듈 을 구비하며 학습자의 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 인식하고, 학습자의 말소리를 인식하며, 학습자의 3D 학습 얼굴과 학습 패턴과 통계 데이터를 제공받으며, 3D 렌더러와 미디어 재생부와 상기 안면인식 모듈과 음성인식 모듈을 구비한 학습자 단말들; 및 상기 LRS 서버와 유무선 통신망을 통해 연결되는 감독관 단 말을 포함하고, 상기 LRS 서버는 3D 학습 콘텐츠를 제공하며, 실시간으로 상기 학습자의 3D 학습 얼굴을 상기 학습자 단말의 카 메라를 주시하는 얼굴 모습이 표현되는 얼굴의 윤곽선과 머리와 이마/눈/코/귀/입을 포함하여 3D 모델링하여 렌 더링하는 3D 렌더러를 더 포함한다. 본 발명의 다른 목적을 달성하기 위해, 인공지능 기반 블렌디드 러닝 서비스 방법은 (a) 온라인 학습(IBL) 또는 유비쿼터스 기반 학습(UBL) 시에, 3D 렌더러와 미디어 재생부와 안면인식 모듈과 음성 인식 모듈을 구비한 학습 자 단말로부터 LRS 서버에 접속하여 ID/Passwd 로그인 후 학습자의 출석을 등록하여 상기 LRS 서버로부터 학습 콘텐츠를 제공받는 단계; 및 (b) 상기 LRS 서버가 학습자의 출석을 기록/저장하고 학습 콘텐츠를 제공하며, 상 기 학습자 단말의 정면 카메라를 주시하며 학습자가 정면 바른 자세로 주의 집중학습되도록 학습자의 얼굴 부분 의 학습 패턴을 저장하고, 학습자의 얼굴 부분의 학습 자세를 표시하는 얼굴의 윤곽선과 눈/코/귀/입을 포함하 여 3D 렌더링하여 표시하며, 학습자의 얼굴 부분의 학습 패턴에 등급/점수를 기록하며, 학습 자세의 통과/탈락 예측과 학습 분석 차트의 통계 데이터를 시각화하여 출력하는 단계를 포함하고, 상기 LRS 서버는 실시간으로 학습자의 3D 학습 얼굴을 상기 학습자 단말의 카메라를 주시하는 얼굴 모습이 표현 되는 얼굴의 윤곽선과 머리와 이마/눈/코/귀/입을 포함하여 3D 모델링하여 렌더링하는 3D 렌더러를 더 포함하며, 상기 3D 렌더러에 의해 실시간으로 상기 학습자의 3D 학습 얼굴을 상기 학습자 단말의 카메라를 주시하는 얼굴 모습이 표현되는 얼굴의 윤곽선과 머리와 이마/눈/코/귀/입을 포함하여 3D 모델링하여 렌더링하며, 상기 학습자 단말은 상기 학습자의 3D 학습 얼굴과 학습 패턴과 통계 데이터를 제공받는 단계를 더 포함한다."}
{"patent_id": "10-2024-0136999", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 인공지능 기반의 블렌디드 러닝 시스템 및 방법은 비대면 온라인 학습(IBL)과 유비쿼터스 기반 학습 (UBL, Ubiquitous based learning)에서 LRS 서버와 연동하여 사용자 단말은 3D 렌더러와 미디어 재생부와 안면 인식 모듈과 음성인식 모듈을 구비하고, 학습 콘텐츠를 제공하고 학습패턴을 모니터링하는 LRS 서버에 연동된 사용자 단말의 정면 카메라에 포커싱된 학습 콘텐츠에 시선을 바로보고 주의집중 학습되도록 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점들을 안면 인식을 하며, 학습자의 학습 패턴을 모니터링하고 일정 각도로 시선이 빗 나갈 경우 또는 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어깨 와 어깨의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우 소리와 메시징 기술을 사용하여 해당 사용자 단 말로 알람/경고 메시지를 발생하여 학습자가 주의 집중 학습되도록 하는 효과가 있다."}
{"patent_id": "10-2024-0136999", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 바람직한 실시예를 첨부된 도면을 참조하여 발명의 구성 및 동작을 상세하게 설명한다. 본 발명은 개시되는 실시예들에 한정되는 것이 아니라 해당 기술 분야에서 통상의 지식을 가진 자가 서로 다른 다양한 형태로 구현될 수 있다. 본 발명의 설명에 있어서 관련된 공지의 기술 또는 구성에 대한 구체적인 설명 이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 자세한 설명을 생략한다. 또한, 첨부된 도면 번호는 동일한 구성을 표기할 때에 다른 도면에서 동일한 도면 번호를 부여한다. 본 연구는 특정한 실시 형태에 대해 한정하지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균 등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 발명의 인공지능 기반 블렌디드 러닝 시스템 및 방법은 비대면 온라인 학습(IBL, Internet based learning) 과 유비쿼터스 기반 학습(UBL, Ubiquitous based learning)에서 LRS 서버와 연동하여 사용자 단말의 교육 콘텐 츠 viewer는 미디어 재생부와 안면인식 모듈과 음성인식 모듈을 구비하고, 학습 콘텐츠를 제공하고 학습자의 얼 굴 부분의 학습 패턴을 모니터링하는 LRS 서버에 연동된 사용자 단말의 정면 카메라에 포커싱된 학습 콘텐츠에 정면 시선을 바로보고 주의집중 학습되도록 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점들을 안면 인식을 하며, 학습자의 얼굴 부분의 학습 패턴을 모니터링하고 일정 각도로 시선이 빗나갈 경우 또는 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어깨와 어깨의 거리의 해당 방향의 거 리가 일정 기준치를 넘는 경우, 또는 학습자의 말소리가 들리는 경우 소리와 메시징 기술을 사용하여 해당 사용 자 단말로 알람/경고 메시지를 발생하여 학습자가 주의 집중 학습되도록 한다. 도 2a, 2b는 비대면 온라인 학습에서 웹 브라우저 기반 ubcloud 인공지능을 사용한 주의 집중 학습 시스템의 구 현 예이다. 온라인 학습(IBL) 또는 UBL(Ubiquitous-Based Learning) 기술을 적용하여 학습 서버에 유무선 통신망을 통해 접속된 스마트 기기(태블릿 PC)를 활용한 유비쿼터스 기반 학습(UBL)과 시험 방식인 UBT(Ubiquitous-Based Test) 기술을 활용한 문제중심학습(PBL; Problem Based Learning) 및 실습, 이러닝/유러닝 온라인 학습(IBL)/ 유비쿼터스 기반 학습(UBL) 시에 학습자의 행동 데이터를 인식하여 주의집중 학습을 제공하는 블렌디드 러닝 시 스템을 제공한다. 본 발명의 인공지능 기반 블렌디드 러닝 시스템 및 방법은 비대면 온라인 이러닝/유러닝 학습 시에, 사용자 단 말(태블릿 PC, 스마트폰, PC)은 3D 렌더러와 미디어 재생부와 안면인식 모듈과 음성인식 모듈을 구비하며, 사용 자 단말은 LRS 서버로부터 학습 콘텐츠를 제공받고 학습자의 얼굴 부분의 학습 패턴을 기록하는 LRS 서버와 연 동되는 교육 콘텐츠 viewer가 설치되고, AI 안면 인식/동작 인식/음성 인식, 소리와 메시징 기술을 사용하여 사 용자 단말의 정면 카메라를 사용한 AI 기반 안면 인식(posenet 알고리즘, real-time face pose estimation) 기 술을 사용하는 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점들을 인식하는 안면인식 모듈이 탑재되며, 얼굴 인 식 시에 응시자 단말의 정면 카메라(C)를 사용하여 촬영된 얼굴 사진을 학습 콘텐츠 서버의 얼굴 사진 DB의 학 습자 얼굴 사진의 특징점들과 비교하여 학습자의 출석 여부를 검출하고, 비대면 온라인 학습에서, 사용자 단말 의 정면 카메라 영상 데이터를 사용하여 실시간으로 AI 기반 안면을 인식하여 학습자의 영상의 얼굴의 행동 패 턴을 검출하여 학습 콘텐츠 서버(ubcloud 서버)에 연동된 사용자 단말의 정면 카메라에 포커싱 된 비대면 강의 학습 콘텐츠에 정면 시선을 바로보고 주의집중 학습되도록 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점 5점 척도 안면 인식을 통해 일정 각도로 시선이 빗나갈 경우 또는 눈과 귀의 거리, 코와 귀의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우, 또는 학습자의 말소리가 들리는 경우 해당 사용자 단말로 알람/경고 메시지를 발생하 며, 소리와 메시징 기술을 사용하여 학습자가 주의집중 학습되도록 한다. 도 3은 온라인 학습 IBL/UBL 유비쿼터스 기반 학습 시에, 태블릿 PC, 스마트폰, PC 기반 학습 콘텐츠를 제공하 고 Blended Learning을 위한 학습자의 얼굴 부분의 학습 패턴을 기록하는 LRS 서버를 구비하는 안면인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템 구성도이다. 안면인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템은 UBL 클라우드 서버로써 온 라인 학습 IBL과 UBL 학습 콘텐츠를 제공하는 LRS 서버, 학습자 단말 및 감독관 단말(300,310,311)을 포함 한다. 사용자 단말(310,311)은 LRS 서버로부터 학습 콘텐츠를 제공받고, 학습자의 안면 인식/음성 인식을 통해 학습자의 얼굴 부분의 학습 패턴을 기록하며 그 통계 데이터를 시각화하여 출력하며, LRS 서버로부터 유무 선 통신망을 통해 온라인 학습 콘텐츠를 제공받는 스마트폰, 태블릿 PC 뿐만 아니라, 유무선 통신망(이더넷, Wi-Fi, LTE 4G/5G)을 통해 인터넷 접속이 가능한 노트북을 포함한다. 사용자 단말은 안면인식 모듈과, 음성인식 모듈과 3D 학습 얼굴과 학습 패턴 통계 데이터를 데이터 시각화하여 표시하는 3D 뷰어가 구비된다. 사용자 단말(310,311)은 유러닝 학습 플랫폼에서 온라인 학습 IBL/UBL 주의집중 합습이 되도록 학습 콘텐츠를 제공받고, 학습자의 얼굴 부분의 학습 패턴을 기록하는 LRS 서버와 연동되는 교육 콘텐츠 viewer가 설치되며, AI 안면 인식/동작 인식/음성 인식과 메시징 기술을 사용하여 학습자 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특 징점 5점 척도 특징점들을 인식하고 학습자의 얼굴의 행동 패턴 데이터를 인식하는 안면인식 모듈과, 주변 잡음 을 필터링하고 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음성을 인식하는 음성인식 모듈을 구 비한다. 학습자 단말로써, 사용자 단말(310,311)의 안면 인식 모듈은 얼굴의 윤곽선과 눈2/코/귀2 얼굴이 특징점들을 인 식하기 위해 posenet 알고리즘을 사용한다. 사용자 단말(310,311)의 음성인식 모듈은 주변 잡음을 필터링하고, 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음성을 인식하기 위해 SileroVAD 및 SpeechBrain 알고리즘을 사용하였다. 감독관 단말과 사용자 단말은 LRS 서버에 접속되며 각각 \"교사 모드\" 및 \"학습자 모드\"로 동작된다. 본 발명의 인공지능 기반 블렌디드 러닝 시스템은 온라인 학습(IBL) 또는 유비쿼터스 기반 학습(UBL) 시에, 학습자의 출석을 기록하고 학습 콘텐츠를 제공하며, 마이크와 스피커와 카메라를 구비한 사용자 단말의 정면 카메라를 주시하며 학습자가 바른 정면 자세로 주의 집 중학습되도록 학습자의 안면인식과 음성 인식(소리 인식)을 통해 시청각적인 학습자의 얼굴 부분의 학습 패턴을 기록/저장하고, 학습자의 학습 자세를 3D 렌더링하여 표시하며, 학습자의 얼굴 부분의 학습 패턴에 등급/점수를기록하고 이에 따른 학습 자세의 통과/탈락 예측과 개인별 학습 분석 차트의 통계 데이터를 시각화(파이 차트, 막대 그래프, scatter diagram)하여 출력하는 LRS 서버; 상기 LRS 서버와 유무선 통신망을 통해 연결되고, 카메라와 안면인식 모듈과 음성인식 모듈 및 서버 연동 녹음 프로그램(UBL 학습 시간 동안 녹음)을 구비하며, 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 인식하고 말소리를 인식하며, 학습자의 3D 학습 얼굴과 학습자의 얼굴 부분의 학습 패턴과 통계 데이터를 제공받으며, 3D 렌더러와 미디어 재생부와 안면인식 모듈과 음성인식 모듈을 구비한 학습자 단말들; 및 상기 LRS 서버와 유무선 통신망(이더넷, Wi-Fi, LTE 4G/5G)을 통해 연결되고, 학습자의 자세가 비딱하면 해당 사용자 단말로 온라인 학습 IBL/UBL 주의집중 학습되도록 LRS 서버를 통해 해당 학습자 단말로 알람 또는 경고 메시지를 전송하는 감독관 단말을 포함하고, 상기 LRS 서버는 3D 학습 콘텐츠를 제공하며, 실시간으로 상기 학습자의 3D 학습 얼굴을 상기 학습자 단말 의 카메라를 주시하는 얼굴 모습이 표현되는 얼굴의 윤곽선과 머리와 이마/눈/코/귀/입을 포함하여 3D 모델링하 여 렌더링하는 3D 렌더러를 더 포함한다. 학습 시간 동안, 학습자 단말은 학습자의 영상과 말소리가 레코딩되는 녹음 및 녹화 프로그램, 학습자의 학습 얼굴이 3D 모델링되고 렌더링되는 학습자의 얼굴 부분의 학습 패턴 3D viewer가 설치되며, 사용자 단말로부터 학습자의 학습 영상과 소리 데이터를 LRS 서버로 전송한다. 블렌디드 러닝 시스템의 온라인 학습(IBL) 또는 유비쿼터스 기반 학습(UBL) 시에, 얼굴의 윤곽선과 눈2/코/귀2 를 감지하는 안면인식 모듈은 응시자 단말의 카메라로 실시간으로 촬영된 정면 얼굴 영상의 ROI를 검출하여 코 의 정점을 기준으로 center alignment를 통해 표준 크기로 크기 보정/회전/각도 보정된 표준 크기의 정면 얼굴 사진에 대하여 AI 안면 인식 알고리즘을 사용하여 얼굴 객체를 추출하고, 얼굴 행동 패턴을 인식하며, 학습자의 얼굴의 윤곽선과 눈2/코/귀2의 얼굴 특징점들을 추출하며, 얼굴 특징 추출과 분류를 통해 눈2/코/귀2의 얼굴의 특징점들의 각각 좌측/우측 귀와 좌측/우측 눈의 중심점(동공)과의 유클리디안 거리(d)와 유사도(similarity)를 계산하고, 온라인 학습(IBL) 또는 유비쿼터스 기반 학습(UBL) 콘텐츠를 제공하는 LRS 서버의 얼굴사진 DB 의 사진과 데이터와 비교하여 출석을 확인하며, 온라인 학습 IBL/IBT 시험 또는 UBL 학습/UBT 시험시에 눈/코 3 점이 양 끝 귀 2점에 가까워지는 지에 따라 오른쪽/왼쪽으로 머리 이동을 감지하고 부정행위와 관련된 얼굴의 이상행동 패턴을 검출하고, 얼굴 인식 시에 안면윤곽선 인식이 안되는 경우, 화면으로부터 일정 각도 이상으로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어깨와 어깨의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우) 학습자 단말의 카메라로 촬영되는 얼굴 행동 패턴을 인식하여 전면 얼굴이 좌우로 돌아간 각도에 따라 우측 눈 과 우측 귀의 거리와 좌측 눈과 좌측 귀의 거리가 달라지므로, 또는 학습자의 말소리가 들리는 경우 주의집중 학습되도록 관련 이미지 또는 영상 데이터를 LRS 서버로 전송하고, LRS 서버에 연동된 감독관 단말이 확인 후, 감독관 단말로부터 LRS 서버를 통해 해당 학습자 단말로 주의집중 학습되도록 경고 메시지를 전 송하거나 또는 알람을 발생한다. 사용자 단말(310,311)에서 정면 자세로 학습자가 온라인 학습(IBL) 또는 유비쿼터스 기반 학습(UBL)이 되도록, 사용자 단말의 정면 카메라로 촬영된 학습자의 안면 인식 시에 눈과 귀의 거리와 코와 귀의 거리를 포함하는 얼 굴의 특징점들과의 거리가 일정 기준치 이하로 비딱한 자세가 검출되거나 또는 음성 인식시에 학습자의 말소리 들리는 경우 해당 사용자 단말로 알람 또는 경고 메시지를 출력하여 주의집중 학습되도록 한다. 온라인 학습 IBL/IBT 또는 UBL 학습/또는 UBT 시험 시에, 감독관 단말은 LRS 서버를 통해 다수의 학습자 단말의 학습자의 출석을 확인하고, 안면인식과 음성인식 기술을 활용한 AI 감독관으로써, 학습자별 얼굴 부분의 학습 패턴 또는 시험 패턴을 모니터링하며, 학습자의 두 눈의 아이트랙킹, 얼굴의 윤곽선과 눈2/코/귀2의 안면 인식 데이터 및 주변 화이트 노이즈를 필터링한 학습자의 말소리의 음성 인식 데이터를 모니터링하다가, 일정 기준치 이하로 학습자의 학습 자세가 비딱하면(학습자의 비딱한 자세, 고개 돌림, 말소리) 눈과 귀의 거리와 코 와 귀의 거리를 포함하는 특징점들과의 거리가 일정 기준치 이하로 학습 자세가 삐탁하거나 고개를 상하 방향/ 좌우 방향으로 돌리거나, 말소리가 들리면, 해당 사용자 단말로 온라인 학습/UBL 주의집중 학습되도록 경고 메 시지 또는 알람을 전송한다. 이때, 학습자 단말은 일정 기준치 이하로 학습 자세가 비딱하면 주의집중 학습되도록 경고 메시지 또는 알람이 출력된다. LRS 서버는 WWW 서버, 제어부, 회원 등록부, 사용자 인증부, 출석 관리부, 학 습 콘텐츠 제공부, 안면인식 분석부, 음성인식 분석부, 빅 데이터 분석/통계제공부, 3D 렌 더러, 학습자DB, 학습 콘텐츠DB, 및 얼굴사진 DB를 포함한다. 상기 LRS 서버는 학습자 단말과 감독관 단말과 유무선 통신을 통해 연결되는 WWW 서버; 유무선 통신망을 통해 태블릿 PC, 스마트폰, PC의 학습자 단말과 감독관 단말로 온라인 학습(IBL)과 시험(IBT) 또는 유비쿼터스 기반 학습(UBL)과 유비쿼터스 기반 시험(UBT)의 응용 서비스를 제공하도록 제어하는 제어부 ; 상기 제어부에 연결되며, 학습자의 회원 정보를 등록받아 ID/Passwd를 저장하여 관리하는 회원 등록부 ; 상기 제어부에 연결되며, 학번/Passwd, QR 코드/Passwd 또는 ID/Passwd 또는 온라인 인증서를 사용하여 사 용자를 인증하는 사용자 인증부; 상기 제어부에 연결되며, 태블릿 PC, 스마트폰, PC 기반 온라인 학습(IBL)과 시험(IBT) 또는 유비쿼터스 기반 학습(UBL)과 시험(UBT)의 출석을 관리하는 출석관리부; 상기 제어부에 연결되며, 온라인 학습(IBL) 또는 유비쿼터스 기반 학습(UBL) 콘텐츠를 제공하는 학습 콘텐 츠 제공부; 상기 제어부에 연결되며, 학습자별로 학습자의 안면인식 데이터를 수신받아 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 추출하여 온라인 학습 IBL/UBL 주의집중 학습되도록 학습자의 얼굴의 학습 패턴을 분석하는 안면인식 분석부; 상기 제어부에 연결되며, 학습자별로 학습자의 음성인식 데이터를 수신받아 학습자의 소리 패턴을 분석하 는 음성인식 분석부; 상기 제어부에 연결되며, 실시간으로 수신되는 학습자의 안면 인식 데이터 및/또는 학습자의 말소리 데이 터를 수신받아 학습자별 학습 관련 빅 데이터를 수신받아 학습자의 얼굴 부분의 학습 패턴 통계 데이터를 시각 화하여 학습 패턴 파이 차트, 막대 그래프, 산점도(scatter diagram)를 표시하는 빅 데이터 분석/통계 제공부 ; 및 교수자와 과목과 학습자DB, 학습 콘텐츠DB, 및 얼굴사진 DB를 포함한다. 상기 LRS 서버는 학습자 단말들과 감독관 단말과 연결되고, 실시간으로 학습자의 얼굴 영상과 음성 데이터 를 저장하며, 스트리밍 서비스를 제공하는 NVR 서버를 더 포함한다. 상기 LRS 서버는 3D 학습 콘텐츠를 제공하며, 실시간으로 학습자의 3D 학습 얼굴을 얼굴의 윤곽선과 머리 와 이마/눈/코/귀/입을 3D 모델링하여 렌더링하는 3D 렌더러를 더 포함한다. 상기 LRS 서버에 연동된 상기 학습자 단말은 학습 시간 동안, 녹음/녹화 데이터(소리 파일과 이미지 파일 이 통합된 영상 파일)을 상기 LRS 서버로 전송하여 저장되며, 상기 학습자 단말은 녹음 및 녹화 프로그램 이 구비된다. 상기 제어부에 연결되며, 학습자 단말에서 안면인식 모듈과 얼굴의 특징점들을 인식하는 안면인식 모듈에 의해 정면 카메라의 영상에 대하여 안면인식 기술(posenet 알고리즘)을 사용하여 눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 오른쪽/왼쪽으로 머리 이동을 감지하고 온라인 학습(IBL)과 유비쿼터스 기반 학습(UBL) 시 얼굴의 학습 패턴을 검출하며, 안면윤곽선 인식이 안되는 경우, 학습 화면 또는 시험 화면으로부터 얼굴이 일정 각도 이상으로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어깨와 어깨의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우) 감독관 단말에 표시되고, 감독관 단말로부터 LRS 서버를 통해 해당 학습자 단말로 부 정행위 관련 경고 메시지 또는 알람을 해당 학습자 단말로 전송한다. 모집단(population)의 n개의 표본(sample)을 추출하고, 모집단의 평균/표준편차/분산을 계산하여 학습 패턴 빅 데이터 분석을 통해 통계 분석(학습 패턴 평균, 개인별 표준편차)을 실시하여 막대 그래프, 시간 경과에 따른 학습 패턴(학습 자세, 고개의 좌우 방향, 상하 방향)이 표시된 산점도(scatter diagram)로 데이터 시각화하여 표시된다. n명의 학습자들의 학습 패턴[n개의 표본(sample)]의 모평균 E(x) E(x)= m = (X1+X2+X3+...+Xn)/n 모평균(mean) m, 표준편차(standard deviation)가 σ 일때, 모집단(population)에서 샘플링된 크기가 n개의 표 본(sample)을 추출하여 생성된 표본 평균 m과 표본 분산 을 갖는 모평균과 모분산을 갖는 정규 분포 N(m, )를 이루며, 이에 따라 표본 평균 m을 갖는 표준 정규 분포를 이룬다. 표준 정규 분포는 학습 패턴 n개의 표본 평균 m 및 표준편차 σ를 계산하며, 표본 오차는 ±2P (신뢰도, 95% 신 뢰구간)을 갖는다. 도 4 내지 도 6은 UBL 클라우드 서버(LRS 서버, Learning Record Server)에 접속된 사용자 단말의 주의집중 UBL 학습 테스트 화면이다. 도 7은 학습자의 센터 얼라이먼트(centre alignment)를 기준으로 학습자의 자세 인식 얼굴의 윤곽선과 눈2/코/ 귀2 안면인식 초기화 화면이다. 1) 안면 인식과 음성 인식을 실행하는 AI 감독관 프로그램이 사용자 단말의 카메라를 주시하는 학습자의 센터 얼라인먼트(centre alignment)를 기준으로 성공적으로 학습자의 얼굴의 안면 인식을 했다면 눈2/코/귀2에 빨간 점이 찍힌 캡춰가 출력된다[Close 버튼을 클릭한다]. 2) 학습자가 머리를 오른쪽으로 움직이면, 우측 상단에 경고 메시지가 팝업된다. [메시지, Please focus on screen]. 메시지를 확인한 후, 고개를 왼쪽으로 돌려서 메시지를 한번 더 확인한다. 3) 사용자 단말의 카메라를 가리거나 얼굴을 숨긴 뒤 메시지 팝업을 확인한다. [메시지, Face not available] 온라인 학습 IBL/IBT 또는 UBL 학습/또는 UBT 시험 시에, 수업 진행중 집중하지 않았을때 화면 메시지 우측 상 단에 화면에 경고 메시지를 출력하고, 동시에 소리로 경고음을 출력한다. 실시예에서는, 서울대-NSD 공동보고서에서, 서울대학교 사범대학 AI 감독관 기반 교육연구센터에서 AI 교육 활 용 사례 및 온라인 학습 시스템에 대하여, UBL 클라우드 서버(LRS 서버) 상에서 태블릿 PC 기반의 유비쿼터스 기반 학습(UBL) 및 유비쿼터스 기반 시험(UBT)에 얼굴의 윤곽선과 눈2/코/귀2 안면 인식과 음성 인식이 사용된 AI 감독관 기술을 실시하였으며, 영어를 외국어로 학습하는 상황에서 영어 독해 및 쓰기 과정에서 학습자의 인 지적 처리 과정을 통해 특정 회사의 뇌파도 검출과 함께 고려하여 \"학습집중도\"를 평가한 결과 긍정적인 결과가 있었다. LRS 서버와 연동되는 학습 콘텐츠를 제공하는 LMS와 AI 감독관 기술은 학습자의 행동 데이터를 기록하고 제공하기 때문에, AI 감독관은 일반적인 LMS가 제공하던 서버 접속 시간, 접속 횟수, 학습 시간, 과제 등의 로 그 데이터를 넘어, 수업 참여에 대한 직접적인 데이터를 제공할 수 있다. AI 감독관을 사용한 학습자의 시선 추적(Eye-Tracking) 또는 안구 이동(Eye-Movement)에 관련된 로그 데이터를 저장하여 실험을 실시하였다. 도 8은 Posenet 알고리즘을 사용한 학습자의 학습 얼굴 눈2/코/귀2 얼굴 영상과, 3D 학습 얼굴 렌더링(3D view), 및 학습자의 얼굴 부분의 학습 패턴과 관련된 통계 데이터를 시각화하여 학습 분석 차트로 표시된 막대 그래프와 산점도(좌우 방향, 상하 방향)를 나타낸다. 안면인식 시에, 양쪽 귀/눈/코 5점 사이 거리 비율을 계산한 각도/비율 정보, 얼굴의 좌우 방향, 얼굴의 상하 방향을 테스트하였다. 도 9는 출석, 온라인 학습 IBL/UBL 학습 콘텐츠를 제공하고 AI 모듈을 구동하여 학습자의 얼굴 안면 인식에 의 해 학습 패턴(등급, 점수), 학습과 과제수행(assignment), 학습자별 학습 패턴을 제공하며 통과/탈락 예측을 제 공하는 UBL 클라우드 서버(LRS 서버)의 지식 트랙킹 모듈(activities), activities의 그룹핑, 학습 패턴 일반화, 학습 패턴 통계 데이터 시각화 및 통과/탈락 예측(prediction)을 제공하는 UBL 클라우드 서버(LRS 서버)의 구성도이다. 도 10a 내지 도 10d는 출석, 학습 콘텐츠를 제공하고 AI 모듈을 구동하여 학습자의 얼굴 안면 인식에 의해 학습 패턴(등급, 점수), 학습과 과제수행(assignment), 학습자별 얼굴 부분의 학습 패턴을 제공하며, 학습 자세의 통과/탈락 예측을 제공하는 UBL 클라우드 서버(LRS 서버)의 지식 트랙킹 액티비티들(activities)과 애트리뷰션, 학습 진단을 나타낸 도면이다. 액티비티들(activities)은 Log in time, Log out time, Stay time in UBL, Number of dairy visit, Study time in viewer, Video watching time, Video call stay time, Video cal stay time, 출석(attentance)들이 특정 애트리뷰트(사이트 방문, 뷰어, 퀴즈, 토론, 과제 수행, 팀 프로젝트, MSG)에 그룹핑되어 연결되며, 각각 의 애트리뷰트는 진단 목록의 학습 역량, 학습 패턴, 콘텐츠 이용, 관심, 집중도, initiative, 관계 (Relationship)과 연결된다. 온라인 학습 IBL 또는 UBL 학습 시에, 학습자의 얼굴 부분의 학습 패턴이 지속적으로 불량한 학습자가 감지된 경우, LRS 서버에 연동된 감독관 단말은 해당 학습자는 주의력 결핍증(attention deficit disorder)을 가 진 학습자로 판단하여 해당 학습자를 주의집중 학습 모니터링 관리 대상자로 선정하여 카메라 안면 인식/음성 인식을 하여 주의집중 바른 정면 학습 태도가 되도록 항시 모니터링한다. 도 11은 온라인 학습 IBL/ UBL 학습 시에, UI/UX 화면의 음성 검출 화면이다. 도 12는 음성 인식 시에, 주변 잡음을 필터링하고 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음 성 인식된 SileroVAD 및 SpeechBrain 알고리즘 실행 결과이다. 사용자 단말의 음성인식 모듈은 SileroVAD 및 SpeechBrain 알고리즘을 사용하였으며 이에 한정하지 않으며 다양 한 알고리즘을 사용할 수 있고, 음성 인식 시에, 마이크로 입력된 음성 신호에 대하여 미리 저장된 생활상의 특 정 소리(TV 소리, 전화 소리, 탁자 소리, 집 문여는 소리)를 필터링하고 주변 잡음(가우시안 노이즈)을 필터링 하며, 순수한 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 학습자의 말소리를 음성 인식한다. 또한, 본 발명의 인공지능 기반 블렌디드 러닝 서비스 방법은 (a) 온라인 학습(IBL) 또는 유비쿼터스 기반 학습(UBL) 시에, 3D 렌더러와 미디어 재생부와 안면인식 모듈과 음 성 인식 모듈을 구비한 학습자 단말로부터 LRS 서버에 접속하여 ID/Passwd 로그인 후 학습자의 출석을 등 록하여 상기 LRS 서버로부터 학습 콘텐츠를 제공받는 단계; 및 (b) 상기 LRS 서버가 학습자의 출석을 기록하고 사용자 단말로 학습 콘텐츠를 제공하며, 사용자 단말의 정 면 카메라를 주시하며 학습자가 바른 자세로 주의 집중학습되도록 학습자의 얼굴 부분의 학습 패턴을 기록/저장 하고, 학습자의 얼굴 부분의 학습 자세를 얼굴의 윤곽선과 눈2/코/귀2/입을 포함하여 3D 렌더링하여 표시하며, 학습자의 얼굴 부분의 학습 패턴에 등급/점수를 기록하며 통과/탈락 예측과 학습 분석 차트의 통계 데이터를 시 각화하여 출력하는 단계를 포함하고, 상기 LRS 서버는 실시간으로 학습자의 3D 학습 얼굴을 상기 학습자 단말의 카메라를 주시하는 얼굴 모습이 표현되는 얼굴의 윤곽선과 머리와 이마/눈/코/귀/입을 포함하여 3D 모델링하여 렌더링하는 3D 렌더러를 더 포함 하며, 상기 3D 렌더러에 의해 실시간으로 상기 학습자의 3D 학습 얼굴을 상기 학습자 단말의 카메라를 주시하는 얼굴 모습이 표현되는 얼굴의 윤곽선과 머리와 이마/눈/코/귀/입을 포함하여 3D 모델링하여 렌더링하며, 상기 학습자 단말은 상기 학습자의 3D 학습 얼굴과 학습 패턴과 통계 데이터를 제공받는 단계를 더 포함한다. 상기 방법에서, 상기 학습자 단말은 얼굴의 윤곽선과 눈2/코/귀2 안면인식 모듈과 음성인식 모듈이 구비되며, 상기 LRS 서버와 유무선 통신망을 통해 연결되고, 상기 학습 콘텐츠를 제공받고 카메라와 안면인식 모듈을 구비하며 학습자의 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 인식하며, 학습자의 학습 자세가 비딱하면 (학습자의 비딱한 자세, 고개 돌림, 말소리) 학습 자세가 비딱하거나 고개를 상하 방향/좌우 방향으로 돌리거나, 음성 인식에 의해 학습자의 말소리가 들리면, 해당 사용자 단말로 온라인 학습 IBL/UBL 주의집중 학 습되도록 자체적으로 경고 메시지 또는 알람을 출력한다. 상기 방법은, 온라인 학습 IBL 또는 UBL 학습/또는 UBT 시험 시에, 상기 LRS 서버에 접속된 감독관 단말은 다수의 학습자 단말의 학습자의 출석을 확인하고, 안면인식과 음성 인식 기술을 활용한 AI 감독관으로써, 학습 자별 얼굴 부분의 학습 패턴을 모니터링하며, 학습자의 두 눈의 아이트랙킹, 얼굴의 윤곽선과 눈2/코/귀2의 안 면 인식 데이터 및 주변 화이트 노이즈를 필터링한 학습자의 말소리의 음성 인식 데이터를 모니터링하다가, 학 습자의 학습 자세가 비딱하면(학습자의 비딱한 자세, 고개 돌림, 말소리) 눈과 귀의 거리와 코와 귀의 거리를 포함하는 특징점들과의 거리가 일정 기준치 이하로 학습 자세가 삐탁하거나 고개를 상하 방향/좌우 방향으로 돌 리거나, 말소리가 들리면, 해당 사용자 단말로 온라인 학습/UBL 주의집중 학습되도록 경고 메시지 또는 알람을전송하는 단계를 더 포함한다. 상기 학습자 단말은 얼굴의 윤곽선과 눈2/코/귀2 안면인식 모듈과 음성인식 모듈이 구비되며, 상기 안면 인식 모듈은 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 인식하기 위해 posenet 알고리즘을 사용 한다. 상기 LRS 서버는 실시간으로 학습자의 3D 학습 얼굴을 얼굴의 윤곽선과 사용자 단말의 카메라를 주시하는 얼굴 모습이 표현되는 머리와 이마/눈/코/귀/입을 포함하여 3D 모델링하여 렌더링하는 3D 렌더러를 더 포함하며, 상기 방법은 상기 3D 렌더러에 의해 실시간으로 학습자의 3D 학습 얼굴을 얼굴의 윤곽선과 사용자 단말의 카메 라를 주시하는 얼굴 모습이 표현되는 머리와 이마/눈2/코/귀2/입을 포함하여 3D 모델링하여 렌더링하는 단계를 더 포함한다. 상기 방법은 학습 시간 동안, 상기 학습자 단말에 구비된 녹음 및 녹화 프로그램의 녹음/녹화 데이터(소리 파일 과 이미지 파일이 통합된 영상 파일)을 상기 LRS 서버로 전송하여 저장되는 단계를 더 포함한다. 도 13은 온라인 학습 IBL/UBL 학습 또는 시험 시에, LRS 서버와 연동된 사용자 단말의 녹음/녹화 프로그램을 보 인 화면이다. 사용자 단말의 앱 실행 및 LRS 서버로 시험데이터 요청, QR 코드 인식(또는 바코드 인식), 안면 인식 -> 데이터 확인 -> 레코딩 대기 -> 레코딩 시작(시험 데이터 기반 자동 오프라인 레코딩) -> 레코딩 중 앱 강제종 료 등 예외 처리(재시작, 계속 레코딩 기능) -> 레코딩 종료 대기 -> 레코딩 종료 -> 레코딩 종료 후 처리(이미 지 취합 및 영상파일, 녹음 파일) -> 응시자 단말로부터 LRS 서버로 전송(학습 또는 시험 부정행위 관련 이미지, 영상 파일, 녹음 파일) -> 전송실패 예외 처리(자동 재시도, 수동 업로드) -> 처리 종료 메시지를 LRS 서버로부터 수신받고 종료된다. 또한, 온라인 학습 IBL 또는 UBL 학습 과정 후에, 온라인 시험 IBT 또는 UBT 시험이 실시된다. 추가적으로, LMS와 UBL,UBT 클라우드 서버로 사용되는 LRS 서버는 온라인 시험 IBT 또는 UBT 시험을 위해, 응시자의 얼굴의 윤곽선과 눈2/코/귀2의 시각적인 부정행위를 감지하는 안면인식 분석부와 말소리를 분석하는 음성인식 분석부를 기본적으로 구비하며, 상기 제어부에 연결되며, 상기 응시자 단말과 상기 감독관 단말로 시험 프로그램(App)과 시험지를 제공하 며, 응시자 정보들과 응시자의 현장 얼굴 사진, 감독관 정보를 관리하며, 온라인 시험 IBT 또는 UBT 시험 시에 일정 시험 시간 이내에 각각의 응시자 단말에 시험지 작성 답안을 저장 후 시험 종료시 시험 서버로 전송되며, 응시자들의 시험지 작성 답안, 채점 결과, 감독관 정보와 응시자 현황 정보를 저장하여 관리하는 시험 관리부; 응시자들의 시험지와 작성 답안, 채점 결과를 저장하는 시험 정보DB; 응시자 정보와 표준 크기의 정면 얼굴 사 진을 저장하는 응시자DB와 얼굴 DB, 및 시험 DB를 더 포함한다. 온라인 시험 IBT 또는 UBT 시험을 관리하는 시험 관리부는 의과 대학/치과 대학/약학 대학/공과 대학 등의 대학 시험, TOEIC/TOEFL 시험, 어학 시험, 공무원 시험, 자격증 시험, 어학 교육, 보건의료교육 등의 학습과 온라인 시험지를 제공하는 문제 은행의 각종 공인 인증 시험 또는 비공인 시험을 시험 일정과 장소를 공지하고, 시험 서버의 데이터베이스의 시험 프로그램을 사용하여 유무선 통신망을 통해 응시자 단말들에게 온라인 시험 또는 오프라인 상에서 저장된 시험 문제를 활용하여 시험을 치를 수 있는 모든 형태의 PC/스마트 기기를 활용하는 UBT 시험을 제공한다. LRS 서버의 제어부는 시험일정과 장소가 확정되면, 감독관을 선임하여 감독관에게 감독관 선임 정보 를 제공하고, 응시자들에게 문자 메시지/웹페이지를 통해 시험 일정과 장소를 공지하며, 시험 당일 시험장소의 감독관 단말로 시험 정보와 시험지 정보를 송수신하여 시험을 진행 관리하고, 자동채점결과부 및 검수관리부의 결과로부터 채점 결과를 해당 응시자 단말들로 제공한다. 시험정보 데이터베이스에 저장되는 시험 정보는 시험 제목, 시험 일정과 장소, 시험 시간, 시험 장소의 위치 정 보, 할당된 시험실별 감독관 정보와 응시자들 명단, 시험실별 좌석수, A/B 문제 유형별 시험지의 문제 정보, 답 안 정보, 채점 정보를 포함한다. 그리고, 응시자 데이터베이스는 이름, 주민등록번호, 집주소, 이동전화번호, 이메일 등을 포함하는 응시자 정보, 응시자 사진(표준 크기의 얼굴 정면 사진) 및 학번/passwd, QR 코드/passwd, ID/passwd 식별 정보와 시험 관련 정보, 응시자 신청 현황이 저장된다. 또한, 상기 LRS 서버는 온라인 학습 IBL/UBL 학습 후에, 정해진 일정과 시간과 장소에서 온라인 시험 또는 UBT 시험을 실시하는 시험관리부와 채점부를 추가적으로 더 구비하며, 온라인 시험 IBT 또는 UBT 시험 시에, 정해진 일정과 시간과 장소에서 학습자의 응시표에 부착되는 인식 코드로 써 바코드 또는 QR 코드를 사용하며, 실시예에서는 응시자들에게 QR 코드가 부착된 응시표가 제공된다. 상기 시험 프로그램의 시험지 문항은 주관식 및/또는 객관식 시험 문항을 포함하며, 각 문항마다 텍스트 및 이 미지 뿐만 아니라 텍스트, 이미지, VR/AR 콘텐츠, 음성과 동영상 중 적어도 하나 이상이 포함된 멀티미디어 시 험 문항이 출제되어 응시자 단말(300,310,311)로 디스플레이된다. 상기 응시자 단말(300,310,311)은 획일적으로 정면 카메라(C)를 구비하는 태블릿 PC, 스마트폰, PC, 노트북 중 어느 하나의 단말을 사용하며, 온라인 시험 또는 UBT 시험 서버를 구비하는 LRS 서버로부터 다운로드된 시 험 프로그램(App)이 설치되고, 온라인 시험 또는 UBT 시험 서버와 연동되는 영상과 소리가 레코딩되는 녹음 및 녹화 프로그램이 설치된다. 시험시에는 , 상기 응시자 단말(300,310,311)은 응시자 단말의 정면 카메라 영상의 얼굴의 특징점들을 인식하는 인공지능 안면인식 모듈; 온라인 시험 또는 UBT 시험 중에, 시각적인 부정행위를 방지하도록 응시자 단말의 정면 카메라 영상의 얼굴의 행동 패턴을 인식하여 얼굴의 특징점들을 구성하는 얼굴의 윤곽선과 눈2, 코, 귀2의 얼굴의 특징점 5점 척도 부 정행위 방지 모듈; 및 온라인 시험 IBT 또는 UBT 시험 중에, 청각적인 부정행위를 방지하도록 응시자의 말소리를 인식하는 음성 인식 모듈을 포함한다. 추가적으로, 응시자 단말은 주관식 시험 문항을 위해 스타일러스 펜의 필기체를 인식하여 문자로 변환하여 필기 체 문자를 인식하는 터치 센서와 디스플레이를 구비하는 응시자 단말의 필기체 인식부를 더 포함한다. 추가적으로, 온라인 시험 IBT 또는 UBT 시험은 2지/3지/4지/5지선다 객관식 시험 뿐만아니라 주관식 시험을 제 공하며. 주관식 시험 문항은 터치센서와 디스플레이를 구비하는 응시자 단말의 필기체 인식부를 사용하여 스타 일러스 펜의 필기체를 인식하여 문자로 변환하여 필기체 문자를 인식하는 주관식 시험을 포함한다. 마찬가지로, 상기 안면인식 모듈에 사용된 상기 안면윤곽선 인식 기술은 posenet 알고리즘을 사용한다. 안면인식과 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점 5점 척도 부정행위를 방지하는 안면인식 모듈은 얼굴의 특징점 눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 오른쪽/왼쪽으로 머리 이동을 감지하고 추적하여 얼 굴의 행동 패턴을 검출하며, FACE RECOGNITION/FACE MOTION RECOGNITION/RESULT ANLAYSIS를 통해 얼굴 인식시 에 안면윤곽선 인식이 안되는 경우, 태블릿 PC의 카메라 영상이 촬영되는 시험 화면으로부터 일정 각도 이상으 로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어깨와 어깨의 거리의 해당 방향의 거리가 일정 수치를 넘는 경 우), 말소리가 들리는 경우 해당 응시자 단말로 경고 메시지 또는 알람을 출력하거나 또는 해당 응시자 단말에 저장한 후 이를 시험 종료시 서버로 전송하며, 서버는 응시자들에게 채점 결과를 제공한다. 마찬가지로, 응시자 단말은 온라인 또는 UBT 시험 서버와 연동되는 녹음/녹화 프로그램이 설치되며, AI 안면인 식/동작인식/소리인식 기술을 사용하여 인공지능 안면인식 모듈과 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점 5 점 척도 부정행위 방지 모듈, 및 음성인식 모듈을 구비하며, 온라인 시험 또는 UBT 시험 서버와 연동하여 온라 인 시험 또는 UBT 시험의 대리시험 방지 및 시청각적인 부정행위를 방지하게 된다. 본 발명에 따른 실시예들은 다양한 컴퓨터 수단을 통해 수행될 수 있는 프로그램 명령 형태로 구현되고, 컴퓨터 판독 가능 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 기록 매체는 프로그램 명령, 데이터 파일, 데이 터 구조를 단독으로 또는 조합하여 포함할 수 있다. 컴퓨터 판독 가능 기록 매체는 스토리지, 하드 디스크, 플 로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램 (RAM), 플래시 메모리, 스토리지 등과 같은 저장 매체에 프로그램 명령을 저장하고 수행하도록 구성된 하드웨어 장치가 포함될 수 있다. 프로그램 명령의 예는 컴파일러에 의해 만들어지는 것과, 기계어 코드 뿐만 아니라 인터프리터를 사용하여 컴퓨터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 상기 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로써 작동하도록 구성될 수 있다. 이상에서 설명한 바와 같이, 본 발명의 방법은 프로그램으로 구현되어 컴퓨터의 소프트웨어를 이용하여 읽을 수 있는 형태로 기록매체(CD-ROM, RAM, ROM, 메모리 카드, 하드 디스크, 광자기 디스크, 스토리지 디바이스 등)에 저장될 수 있다. 본 발명의 구체적인 실시예를 참조하여 설명하였지만, 본 발명은 상기와 같이 기술적 사상을 예시하기 위해 구 체적인 실시 예와 동일한 구성 및 작용에만 한정되지 않고, 본 발명의 기술적 사상과 범위를 벗어나지 않는 한 도 내에서 다양하게 변형하여 실시될 수 있으며, 본 발명의 범위는 후술하는 특허청구범위에 의해 결정되어야 한다."}
{"patent_id": "10-2024-0136999", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 기존 얼굴 인식 장치의 구성도이다. 도 1b는 종래의 인공지능 심층학습 기반의 영상물 인식 시스템의 구성도이다. 도 2a, 2b는 비대면 온라인 학습에서 웹 브라우저 기반 ubcloud 인공지능을 사용한 주의 집중 학습 시스템의 구 현 예이다.도 3은 온라인 학습 IBL/UBL 유비쿼터스 기반 학습 시에, 태블릿 PC, 스마트폰, PC 기반 학습 콘텐츠를 제공하 고 Blended Learning을 위한 학습자의 얼굴 부분의 학습 패턴을 기록하는 LRS 서버를 구비하는 안면인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템 구성도이다. 도 4 내지 도 6은 UBL 클라우드 서버(LRS 서버, Learning Record Server)에 접속된 사용자 단말의 주의집중 UBL 학습 테스트 화면이다. 도 7은 학습자의 센터 얼라이먼트(centre alignment)를 기준으로 학습자의 자세 인식 얼굴의 윤곽선과 눈2/코/ 귀2 안면인식 초기화 화면이다. 도 8은 Posenet 알고리즘을 사용한 학습자의 학습 얼굴 눈2/코/귀2 얼굴 영상과, 3D 학습 얼굴 렌더링(3D view), 및 학습 패턴과 관련된 통계 데이터를 시각화하여 학습 분석 차트로 표시된 막대 그래프와 산점도를 나 타낸다. 도 9는 출석, 온라인 학습/UBL 학습 콘텐츠를 제공하고 AI 모듈을 구동하여 학습자의 얼굴 안면 인식에 의해 학 습 패턴(등급, 접수), 학습과 과제수행(assignment), 학습자별 학습 패턴을 제공하며 통과/탈락 예측을 제공하 는 UBL 클라우드 서버(LRS 서버)의 지식 트랙킹 모듈(activities), activities의 그룹핑, 학습 패턴 일반화, 학습 패턴 통계 데이터 시각화 및 통과/탈락 예측(prediction)을 제공하는 UBL 클라우드 서버(LRS 서버)의 구성 도이다. 도 10a 내지 도 10d는 출석, 온라인 학습 IBL/UBL 학습 콘텐츠를 제공하고 AI 모듈을 구동하여 학습자의 얼굴 안면 인식에 의해 학습 패턴(등급, 접수), 학습과 과제수행(assignment), 학습자별 학습 패턴을 제공하며 통과/ 탈락 예측을 제공하는 UBL 클라우드 서버(LRS 서버)의 지식 트랙킹 액티비티들과 애트리뷰션, 학습 진단을 나타 낸 도면이다. 도 11은 온라인 학습 IBL/UBL 학습 시에, UI/UX 화면의 음성 검출 화면이다. 도 12는 음성 인식 시에, 주변 잡음을 필터링하고 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음 성 인식된 SileroVAD 및 SpeechBrain 알고리즘 실행 결과이다. 도 13은 온라인 학습 IBL/UBL 학습 또는 시험 시에, LRS 서버와 연동된 사용자 단말의 녹음/녹화 프로그램을 보 인 화면이다."}
