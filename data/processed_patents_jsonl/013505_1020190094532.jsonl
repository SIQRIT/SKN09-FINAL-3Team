{"patent_id": "10-2019-0094532", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0066149", "출원번호": "10-2019-0094532", "발명의 명칭": "사용자 인증 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "조근석"}}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 발화 입력에 기초하여 사용자를 인증하는 방법에 있어서,사용자의 발화 입력에 기초하여 입력 오디오 신호를 획득하는 동작;상기 입력 오디오 신호로부터, 적어도 하나의 발화 구간의 오디오 신호 및 적어도 하나의 비 발화 구간의 오디오 신호를 구별하는 동작;상기 비 발화 구간의 오디오 신호에 기초하여, 상기 발화 입력이 수신된 환경을 나타내는 환경 정보를 생성하는동작;상기 생성된 환경 정보 및 상기 사용자에 대하여 미리 등록된 등록 오디오 신호에 대응되는 발화 입력이 수신된환경을 나타내는 등록 환경 정보의 비교 결과에 기초하여, 상기 사용자를 인증하기 위한 인증 기준을 조정하는동작; 및상기 조정된 인증 기준 및 상기 입력 오디오 신호에 기초하여 상기 사용자를 인증하는 동작;을 포함하는사용자 인증 방법."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 적어도 하나의 발화 구간의 오디오 신호 및 적어도 하나의 비 발화 구간의 오디오 신호를 구별하는 동작은상기 입력 오디오 신호를 미리 설정된 프레임 단위로 분할하는 동작;상기 분할된 프레임들의 오디오 특징을 추출하는 동작; 및상기 추출된 오디오 특징에 기초하여, 상기 분할된 프레임들 중에서 상기 발화 구간에 대응되는 프레임들 및 상기 비 발화 구간에 대응되는 프레임들을 구별하는 동작;을 포함하는사용자 인증 방법."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 환경 정보를 생성하는 동작은상기 비 발화 구간에 대응되는 프레임들의 오디오 특징을 이용하여 상기 환경 정보를 생성하는 것인,사용자 인증 방법."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 환경 정보는상기 오디오 신호가 수신된 상황을 나타내는 복수의 세부 상황에 관련된 정보 및 상기 복수의 세부 상황과 대응되는 복수의 벡터에 관한 정보를 포함하는공개특허 10-2020-0066149-3-사용자 인증 방법"}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 사용자를 인증하는 동작은상기 사용자를 인증하기 위하여 상기 미리 등록된 등록 오디오 신호를 획득하는 동작;상기 등록 오디오 신호로부터 등록 발화 구간의 오디오 신호를 획득하는 동작; 및상기 발화 구간의 오디오 신호 및 상기 등록 발화 구간의 오디오 신호를 비교함으로써, 상기 사용자를 인증하는동작;을 포함하는사용자 인증 방법."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 등록 오디오 신호는적어도 하나의 등록 발화 구간의 오디오 신호 및 적어도 하나의 등록 비 발화 구간의 오디오 신호를 포함하고,상기 등록 비 발화 구간의 오디오 신호는상기 등록 오디오 신호에 대응되는 상기 발화 입력이 수신된 상황을 나타내는 등록 환경 정보를 생성하는데 이용되는사용자 인증 방법."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 인증 기준을 조정하는 동작은상기 발화 구간의 오디오 신호 및 상기 등록 발화 구간의 오디오 신호 간의 유사도의 임계치를 조정하는 것인사용자 인증 방법."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 유사도의 임계치를 조정하는 동작은미리 설정된 임계치 테이블로부터 상기 발화 구간의 길이 및 상기 등록 발화 구간의 길이에 대응하는 어느 하나의 임계치를 선택하는 동작; 및상기 환경 정보 및 상기 등록 환경 정보의 비교 결과에 기초하여, 상기 선택된 임계치를 조정하는 동작;을 포함하는사용자 인증 방법."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "공개특허 10-2020-0066149-4-제8항에 있어서,상기 선택된 임계치를 조정하는 동작은상기 환경 정보에 대응하는 벡터 및 상기 등록 환경 정보에 대응하는 벡터 간 유사도에 기초하여, 상기 선택된임계치를 조정하는 것인사용자 인증 방법."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 유사도의 임계치를 조정하는 동작은상기 발화 구간의 오디오 신호로부터 상기 발화 구간의 오디오 신호의 평균 에너지값을 산출하는 동작;상기 등록 발화 구간의 오디오 신호로부터 상기 등록 발화 구간의 오디오 신호의 평균 에너지값을 산출하는 동작; 및상기 발화 구간의 오디오 신호로부터 산출된 평균 에너지값을 상기 등록 발화 구간의 오디오 신호로부터 산출된평균 에너지값과 비교하여 상기 유사도의 임계치를 조정하는 동작;을 더 포함하는사용자 인증 방법."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 유사도의 임계치를 조정하는 동작은상기 사용자의 음색에 기초하여 미리 설정된 파라미터 값 또는 상기 전자 장치의 특성에 기초하여 미리 설정된파라미터 값 중 적어도 하나에 기초하여, 상기 임계치를 조정하는 동작을 더 포함하는사용자 인증 방법."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "전자 장치에 있어서,마이크;메모리; 및적어도 하나의 프로세서;를 포함하며,상기 적어도 하나의 프로세서는사용자의 발화 입력에 기초하여 입력 오디오 신호를 획득하고, 상기 입력 오디오 신호로부터, 적어도 하나의 발화 구간의 오디오 신호 및 적어도 하나의 비 발화 구간의 오디오 신호를 구별하고, 상기 비 발화 구간의 오디오신호에 기초하여, 상기 발화 입력이 수신된 환경을 나타내는 환경 정보를 생성하고, 상기 생성된 환경 정보 및상기 사용자에 대하여 미리 등록된 등록 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 등록 환경 정보의 비교 결과에 기초하여, 상기 사용자를 인증하기 위한 인증 기준을 조정하고, 상기 조정된 인증 기준및 상기 입력 오디오 신호에 기초하여 상기 사용자를 인증하는, 전자 장치."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "공개특허 10-2020-0066149-5-제12항에 있어서,상기 적어도 하나의 프로세서는상기 입력 오디오 신호를 미리 설정된 프레임 단위로 분할하고, 상기 분할된 프레임들의 오디오 특징을 추출하고, 상기 추출된 오디오 특징에 기초하여, 상기 분할된 프레임들 중에서 상기 발화 구간에 대응되는 프레임들및 상기 비 발화 구간에 대응되는 프레임들을 구별하는전자 장치."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 적어도 하나의 프로세서는 상기 비 발화 구간에 대응되는 프레임들의 오디오 특징을 이용하여 상기 환경 정보를 생성하는전자 장치."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는상기 사용자를 인증하기 위하여 상기 미리 등록된 등록 오디오 신호를 획득하고, 상기 등록 오디오 신호로부터등록 발화 구간의 오디오 신호를 획득하고, 상기 발화 구간의 오디오 신호 및 상기 등록 발화 구간의 오디오 신호를 비교함으로써, 상기 사용자를 인증하는전자 장치."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 등록 오디오 신호는적어도 하나의 등록 발화 구간의 오디오 신호 및 적어도 하나의 등록 비 발화 구간의 오디오 신호를 포함하고,상기 등록 비 발화 구간의 오디오 신호는상기 등록 오디오 신호에 대응되는 발화 입력이 수신된 상황을 나타내는 등록 환경 정보를 생성하는데 이용되는전자 장치."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 적어도 하나의 프로세서는상기 발화 구간의 오디오 신호 및 상기 등록 발화 구간의 오디오 신호 간의 유사도의 임계치를 조정하는전자 장치."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "공개특허 10-2020-0066149-6-제17항에 있어서,상기 적어도 하나의 프로세서는 미리 설정된 임계치 테이블로부터 상기 발화 구간의 길이 및 상기 등록 발화 구간의 길이에 대응하는 어느 하나의 임계치를 선택하고, 상기 환경 정보 및 상기 등록 환경 정보의 비교 결과에 기초하여, 상기 선택된 임계치를조정하는전자 장치."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 적어도 하나의 프로세서는 상기 환경 정보에 대응하는 벡터 및 상기 등록 환경 정보에 대응하는 벡터 간 유사도에 기초하여, 상기 선택된임계치를 조정하는전자 장치."}
{"patent_id": "10-2019-0094532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "사용자의 발화 입력에 기초하여 입력 오디오 신호를 획득하는 동작;상기 입력 오디오 신호로부터, 적어도 하나의 발화 구간의 오디오 신호 및 적어도 하나의 비 발화 구간의 오디오 신호를 구별하는 동작;상기 비 발화 구간의 오디오 신호에 기초하여, 상기 발화 입력이 수신된 환경을 나타내는 환경 정보를 생성하는동작;상기 생성된 환경 정보 및 상기 사용자에 대하여 미리 등록된 등록 오디오 신호에 대응되는 발화 입력이 수신된환경을 나타내는 등록 환경 정보의 비교 결과에 기초하여, 상기 사용자를 인증하기 위한 인증 기준을 조정하는동작; 및상기 조정된 인증 기준 및 상기 입력 오디오 신호에 기초하여 상기 사용자를 인증하는 동작;을 포함하는 사용자를 인증하는 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체."}
{"patent_id": "10-2019-0094532", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사용자 인증 방법 및 장치가 제공된다. 본 개시의 일부 실시예에 따른 전자 장치가 사용자를 인증하는 방법은, 사용자의 발화 입력에 기초하여 입력 오디오 신호를 획득하는 동작, 상기 입력 오디오 신호로부터, 적어도 하나 의 발화 구간의 오디오 신호 및 적어도 하나의 비 발화 구간의 오디오 신호를 구별하는 동작, 상기 비 발화 구간 의 오디오 신호에 기초하여, 상기 발화 입력이 수신된 환경을 나타내는 환경 정보를 생성하는 동작, 상기 생성된 환경 정보 및 상기 사용자에 대하여 미리 등록된 등록 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타 내는 등록 환경 정보의 비교 결과에 기초하여, 상기 사용자를 인증하기 위한 인증 기준을 조정하는 동작 및 상기 조정된 인증 기준 및 상기 입력 오디오 신호에 기초하여 상기 사용자를 인증하는 동작을 포함할 수 있다."}
{"patent_id": "10-2019-0094532", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 사용자 인증 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2019-0094532", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 사용자 중심의 인터페이스를 구현하는 휴먼 컴퓨터 인터렉션(HCI: Human Computer Interaction)으로서, 사용자의 음성을 인식하는 음성 인식 기능을 갖는 전자기기의 사용이 점차 늘어나고 있다. 전자기기는 미리 등록된 사용자로부터 음성을 수신하고 분석하여, 사용자에게 전자기기에 대한 접근 및 제어를 허용하기 위한 사용자 인증을 수행한다. 이에 따라, 음성 인식 기능은 사용자의 음성을 인식하여 미리 등록 사 용자에 해당하는지를 오류 없이 정확하게 판단하는 것이 중요하다. 일반적으로, 전자기기는 사용자로부터 최초로 입력받은 음성을 통해 사용자 등록을 수행하고, 이후 사용자 인증 과정에서 입력받은 사용자의 음성과 등록된 음성을 비교하여 사용자 인증을 수행한다. 다만, 사용자 인증을 수행하는 시점의 전자기기의 주변 환경은 사용자 등록을 수행하는 시점의 주변 환경과 상 이할 수 있다. 따라서, 동일한 사용자의 음성 입력이라도, 전자기기와 사용자의 거리, 전자기기 주변에 존재하 는 소음과 같은 외부 환경의 영향으로 인해 다르게 인식될 수 있다. 결국, 사용자 인증 성능의 저하를 방지하기 위해서는 전자기기의 외부 환경의 변화를 고려할 필요가 있다."}
{"patent_id": "10-2019-0094532", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일부 실시예는, 사용자 등록 시의 환경과 사용자 인증 시의 환경을 서로 비교하여 사용자 인증에 사 용되는 인증 기준을 조정함으로써 사용자 인증 성능의 저하를 방지할 수 있는 사용자 인증 방법 및 장치를 제공 하는 것을 목적으로 한다."}
{"patent_id": "10-2019-0094532", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 사용자의 발화 입력에 기초하 여 입력 오디오 신호를 획득하는 동작, 상기 입력 오디오 신호로부터, 적어도 하나의 발화 구간의 오디오 신호 및 적어도 하나의 비 발화 구간의 오디오 신호를 구별하는 동작, 상기 비 발화 구간의 오디오 신호에 기초하여, 상기 발화 입력이 수신된 환경을 나타내는 환경 정보를 생성하는 동작, 상기 생성된 환경 정보 및 상기 사용자 에 대하여 미리 등록된 등록 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 등록 환경 정보의 비 교 결과에 기초하여, 상기 사용자를 인증하기 위한 인증 기준을 조정하는 동작 및 상기 조정된 인증 기준 및 상 기 입력 오디오 신호에 기초하여 상기 사용자를 인증하는 동작을 포함하는 사용자 인증 방법을 제공할 수 있다. 또한, 본 개시의 제2 측면은, 마이크, 메모리 및 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로 세서는 사용자의 발화 입력에 기초하여 오디오 신호를 획득하고, 상기 입력 오디오 신호로부터, 적어도 하나의 발화 구간의 오디오 신호 및 적어도 하나의 비 발화 구간의 오디오 신호를 구별하고, 상기 비 발화 구간의 오디 오 신호에 기초하여, 상기 발화 입력이 수신된 환경을 나타내는 환경 정보를 생성하고, 상기 생성된 환경 정보 및 상기 사용자에 대하여 미리 등록된 등록 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 등록 환경 정보의 비교 결과에 기초하여, 상기 사용자를 인증하기 위한 인증 기준을 조정하고, 상기 조정된 인증 기 준 및 상기 입력 오디오 신호에 기초하여 상기 사용자를 인증하는 전자 장치를 제공할 수 있다. 또한, 본 개시의 제3 측면은, 사용자의 발화 입력에 기초하여 입력 오디오 신호를 획득하는 동작, 상기 입력 오 디오 신호로부터, 적어도 하나의 발화 구간의 오디오 신호 및 적어도 하나의 비 발화 구간의 오디오 신호를 구 별하는 동작, 상기 비 발화 구간의 오디오 신호에 기초하여, 상기 발화 입력이 수신된 환경을 나타내는 환경 정 보를 생성하는 동작, 상기 생성된 환경 정보 및 상기 사용자에 대하여 미리 등록된 등록 오디오 신호에 대응되 는 발화 입력이 수신된 환경을 나타내는 등록 환경 정보의 비교 결과에 기초하여, 상기 사용자를 인증하기 위한 인증 기준을 조정하는 동작 및 상기 조정된 인증 기준 및 상기 입력 오디오 신호에 기초하여 상기 사용자를 인 증하는 동작을 포함하는 사용자를 인증하는 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽 을 수 있는 기록 매체를 제공할 수 있다."}
{"patent_id": "10-2019-0094532", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 의하면, 사용자 등록 시의 환경과 사용자 인증 시의 환경을 서로 비교하여 사용자 인증에 사용되는 인증 기준을 조정함으로써 사용자 인증 성능의 저하를 방지할 수 있는 사용자 인증 방법 및 장치를 제공할 수 있는 효과가 있다."}
{"patent_id": "10-2019-0094532", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한, 어떤 부분이어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 일부 실시예에 따른 전자 장치가 사용자의 발화 입력에 기초하여 인증을 수행하는 방법을 개념적으로 나 타내는 도면이다. 도 1을 참조하면, 일부 실시예에 따른 전자 장치는 사용자의 발화 입력에 기초하여 입력 오디오 신호 를 획득할 수 있다. 발화 입력은 사용자가 발화할 때 전자 장치의 마이크를 통해 입력되는 소리에 기초하여 이루어지는 것으로서, 사용자가 발화할 때 전자 장치의 마이크를 통해 입력되는 소리는, 예를 들어, 사용자의 음성 또는 전자 장치 주변의 소음 중 적어도 하나를 포함할 수 있다. 전자 장치는, 예를 들어, 사용자가 발화하는 동안 전자 장치의 마이크를 통해 입력받은 소리를 전기적인 파형 신호로 변환하여 오디오 신호를 획득할 수 있다. 본 개시에서 오디오 신호는 사용자가 발화 하는 동안 사용자의 발성 및 전자 장치의 주변 환경에 의해 생성된 소리에 기초하여 전자 장치(100 0)가 획득하는 전기적인 파형 신호를 의미한다. 전자 장치는, 예를 들어, 휴대폰(mobile phone), 스마트폰(smart phone). 스마트 TV, 스마트 오디오, 스 마트 스피커, 인공지능 스피커, PC(Personal Computer), 노트북 컴퓨터, 태블릿 PC 및 내비게이션(navigation) 단말기와 같이 사용자로부터 오디오 신호를 입력받을 수 있는 장치 중 어느 하나일 수 있으나, 이에 제한되 지 않는다. 전자 장치는 사용자의 발화 입력에 기초하여 획득된 입력 오디오 신호를 사용하여 사용자 인증 을 수행할 수 있다. 전자 장치는 입력 오디오 신호가 획득되기 이전의 사용자 등록 단계에서, 사용자의 발화 입력에 기초하여 등록 오디오 신호를 획득할 수 있다. 전자 장치는, 예를 들어, 등록 오디오 신호가 획득됨에 따라, 등록 오디오 신호에 대응되는 발 화 입력을 수행한 사용자에 대응되는 사용자 DB(Data Base)를 생성할 수 있다. 전자 장치는 사용자 의 발화 입력에 기초하여 등록 오디오 신호를 획득하고, 획득된 등록 오디오 신호를 사용자 DB에 저장할 수 있다. 전자 장치는 등록 오디오 신호와 입력 오디오 신호를 서로 비교하여 사용자 인증을 수행할 수 있다. 입력 오디오 신호 및 등록 오디오 신호는, 예를 들어, 사용자의 특정 문장을 사용하는 발화 입력 에 기초하여 전자 장치가 획득한 오디오 신호일 수 있다. 입력 오디오 신호의 획득에 사용되는 문장의 내용은 등록 오디오 신호의 획득에 사용된 문장의 내용 과 서로 동일할 수 있다. 예를 들어, 사용자 등록을 위한 등록 오디오 신호의 획득에 사용된 문장이 \"Hi, Bixby.\"일 경우, 사용자 인증을 위한 입력 오디오 신호의 획득에 사용되는 문장 또한 \"Hi, Bixby.\"와 같이 등록 오디오 신호의 획득에 사용된 문장과 동일한 문장일 수 있다. 한편, 입력 오디오 신호의 획득에 사용되는 문장의 내용은 등록 오디오 신호의 획득에 사용된 문장의 내용과 서로 일부가 상이할 수 있다. 예를 들어, 사용자 등록을 위한 등록 오디오 신호의 획득에 사용된 문장이 \"Hi, Bixby.\"일 경우, 사용자 인증을 위한 입력 오디오 신호의 획득에 사용되는 문장은 \"Wake up, Bixby.\"와 같이 등록 오디오 신호의 획득에 사용된 문장과 일부 상이한 문장일 수 있다. 한편, 또 다른 예로, 입력 오디오 신호의 획득에 사용되는 문장의 내용은 등록 오디오 신호의 획득에 사용된 문장의 내용과 서로 완전히 상이할 수 있다. 예를 들어, 사용자 등록을 위한 등록 오디오 신호의 획득에 사용된 문장이 \"Hi, Bixby.\"일 경우, 사용자 인증을 위한 입력 오디오 신호의 획득에 사용되는 문 장은 \"Hello, buddy.\"와 같이 등록 오디오 신호의 획득에 사용된 문장과 완전히 상이한 문장일 수 있다. 한편, 또 다른 예로, 사용자 등록을 위한 등록 오디오 신호의 획득에 사용된 문장이 \"Hi, Bixby.\"일 경우, 입력 오디오 신호의 획득에 사용되는 문장은 \"Hi, Bixby, 오늘 날씨 알려줘.\"와 같이 전자 장치의 음성 인식 기능을 활성화 시키는 웨이크업(wakeup) 명령 및 전자 장치의 소정의 기능을 실행시키기 위한 명령을 포함하는 문장일 수 있다.이처럼 일부 실시예에 따른 전자 장치는 등록 오디오 신호의 획득에 사용된 문장과 동일한 문장은 물론, 등록 오디오 신호의 획득에 사용된 문장의 내용과 서로 상이한 문장, 즉 전자 장치의 소정의 기능을 실행시키기 위한 문장 등에 대응되는 다양한 오디오 신호에 기초하여 사용자 인증을 수행할 수 있다. 전자 장치는 사용자 인증을 수행하기 위하여, 오디오 신호에 포함된 모든 정보 중 음성 인식 목적에 부합 되는 일부의 정보만을 추출하여 사용할 수 있다. 음성 인식 목적에 부합되는 일부의 정보는, 예를 들어, 통계적 인 방법을 통해 오디오 신호로부터 추출될 수 있다. 음성 인식에 사용되기 위하여 오디오 신호로부터 추출된 정보들은 오디오 특징(audio feature)으로 지칭될 수 있다. 오디오 특징은, 예를 들어, 주파수 상의 스펙트럼(spectrum) 분포가 서로 상이한 복수의 성분을 포함하도 록 오디오 신호로부터 추출될 수 있다. 전자 장치는 입력 오디오 신호와 등록 오디오 신호를 서로 비교하기 위하여, 입력 오디오 신호 와 등록 오디오 신호 각각으로부터 오디오 특징을 추출할 수 있다. 전자 장치는 오디오 신호로부터 오디오 특징을 추출하는 과정에서 불필요하게 중복되는 음성 정보를 없애 고, 동일 오디오 신호 간의 일관성을 높임과 동시에 다른 오디오 신호와는 변별력을 높일 수 있는 정보로서, 오 디오 특징 벡터(audio feature vector)를 획득할 수 있다. 이와 같은 오디오 특징 벡터는, 예를 들어, 선형 예측 계수(Linear Predictive Coefficient), 켑스트럼 (Cepstrum), 멜 프리퀀시 켑스트럼(Mel Frequency Cepstral Coefficient, MFCC) 또는 주파수 대역별 에너지 (Filter Bank Energy) 중 적어도 하나를 계산하는 방식을 통해 오디오 신호로부터 추출될 수 있으나, 이에 제한 되지 않는다. 전자 장치가 획득한 입력 오디오 신호는 발화 구간의 오디오 신호 및 비 발화 구간의 오디오 신호를 포함할 수 있다. 전자 장치는 입력 오디오 신호로부터 추출된 오디오 특징 벡터에 기초하여, 입력 오디오 신호로부터 발화 구간의 오디오 신호 및 비 발화 구간의 오디오 신호 중 어느 하나를 구별할 수 있 다. 발화 구간의 오디오 신호는 전자 장치가 획득한 입력 오디오 신호의 전체 구간에서 사용자의 음 성에 기초하여 생성된 것으로 분류되는 구간의 오디오 신호를 의미한다. 발화 구간의 오디오 신호는 사용자(1 0)의 음성으로부터 생성된 오디오 신호를 포함할 수 있다. 비 발화 구간의 오디오 신호는 전자 장치가 획득한 입력 오디오 신호의 전체 구간에서, 사용자 의 음성이 아닌, 전자 장치 주변의 소음 등에 의해 생성된 것으로 분류되는 구간의 오디오 신호를 의미한 다. 비 발화 구간의 오디오 신호는 사용자의 음성으로부터 생성된 오디오 신호를 포함하지 않을 수 있다. 한편, 전자 장치가 획득한 등록 오디오 신호는 등록 발화 구간의 오디오 신호 및 등록 비 발화 구간의 오 디오 신호를 포함할 수 있다. 전자 장치는 등록 오디오 신호로부터 추출된 오디오 특징 벡터에 기초 하여, 등록 오디오 신호로부터 등록 발화 구간의 오디오 신호 및 등록 비 발화 구간의 오디오 신호 중 어 느 하나를 구별할 수 있다. 등록 발화 구간의 오디오 신호는 전자 장치가 획득한 등록 오디오 신호의 전체 구간에서 사용자(1 0)의 음성에 기초하여 생성된 것으로 분류되는 구간의 오디오 신호를 의미한다. 등록 발화 구간의 오디오 신호 는 사용자의 음성으로부터 생성된 오디오 신호를 포함할 수 있다. 등록 비 발화 구간의 오디오 신호는 전자 장치가 획득한 등록 오디오 신호의 전체 구간에서, 사용자 의 음성이 아닌, 전자 장치 주변의 소음 등에 의해 생성된 것으로 분류되는 구간의 오디오 신호를 의 미한다. 등록 비 발화 구간의 오디오 신호는 사용자의 음성으로부터 생성된 오디오 신호를 포함하지 않을 수 있다. 전자 장치는 등록 오디오 신호 및 입력 오디오 신호의 비교를 통해 사용자 인증을 수행하기 위 하여, 등록 발화 구간의 오디오 신호 및 발화 구간의 오디오 신호 각각으로부터 사용자 음성의 특징을 나타내는 사용자 특징 벡터를 획득할 수 있다. 전자 장치는 오디오 신호로부터 획득된 오디오 특징 벡터를 사용하여 사용자 특징 벡터를 획득할 수 있다. 전자 장치는. 예를 들어, 사용자 특징 벡터를 획득하기 위한 심층 신경망(Deep Neural Network, DNN) 모델을 사용하여, 오디오 특징 벡터로부터 사용자 특징 벡터를 생성할 수 있다. 사용자 특징 벡터의 생성에 사용되는 심층 신경망 모델은 오디오 신호로부터 사용자 음성의 특징을 식별하기 위 한 모델일 수 있다. 사용자 특징 벡터의 생성에 사용되는 심층 신경망 모델은, 예를 들어, 서로 다른 환경의 복 수의 사용자에 대한 오디오 특징 벡터를 입력받고, 각 사용자에 대한 사용자 특징 벡터를 출력하는 과정을 통해 학습될 수 있다. 본 개시에서 전자 장치가 사용자 특징 벡터를 생성하기 위해 사용하는 심층 신경망은, 예를 들어, 컨볼루 션 뉴럴 네트워크(Convolution Neural Network, CNN), 순환 신경망(Recurrent Neural Network, RNN) 및 GAN (Generative Adversarial Networks) 중 적어도 하나를 포함할 수 있으나, 이에 제한되지 않으며, 사용자 특징 벡터의 생성에 사용될 수 있는 모든 종류의 심층 신경망이 이용될 수 있다. 전자 장치는, 예를 들어, 등록 발화 구간의 오디오 신호로부터, 등록 오디오 신호에 대응되는 발화 입력을 수행한 사용자에 대한 등록 사용자 특징 벡터를 획득할 수 있다. 전자 장치는 획득된 등록 사 용자 특징 벡터를 사용자 DB에 저장할 수 있다. 전자 장치는, 예를 들어, 복수의 사용자의 발화 입력에 기초하여 복수의 등록 오디오 신호를 획득하 고, 복수의 사용자에 대한 사용자 DB를 생성할 수 있다. 전자 장치는 복수의 사용자의 발화 입력에 기초 하여 획득한 복수의 등록 오디오 신호로부터 복수의 사용자 각각에 대한 등록 사용자 특징 벡터를 획득할 수 있다. 전자 장치는 획득된 복수의 사용자 각각에 대한 등록 사용자 특징 벡터를 각 사용자 DB에 저장 할 수 있다. 입력 오디오 신호가 획득되면, 전자 장치는, 예를 들어, 발화 구간의 오디오 신호로부터, 입력 오디 오 신호에 대응되는 발화 입력을 수행한 사용자에 대한 사용자 특징 벡터를 획득할 수 있다. 입력 오디오 신호가 획득되면, 전자 장치는, 예를 들어, 사용자 등록 단계에서 미리 생성된 사용자 DB로부터 등록 오디오 신호를 획득하고, 등록 발화 구간의 오디오 신호로부터 등록 사용자 특징 벡터를 획 득할 수 있다. 입력 오디오 신호가 획득되면, 전자 장치는, 다른 예로, 사용자 등록 단계에서 미리 생성된 사용자 DB로부터 직접 등록 사용자 특징 벡터를 획득할 수 있다. 입력 오디오 신호가 획득되면, 전자 장치는, 예를 들어, 복수의 사용자 DB로부터 각 사용자의 등록 사용자 특징 벡터를 획득하고, 발화 구간의 오디오 신호로부터 사용자 특징 벡터를 획득하여 사용자 식별을 수 행할 수 있다. 사용자 식별은 복수의 사용자 중 입력 오디오 신호에 대응되는 발화 입력에 사용된 음성과 음성의 특징이 가장 유사한 사용자를 결정하는 것을 의미한다. 즉, 사용자 식별은 미 등록된 사용자의 발화 입력에 의해 입력 오디오 신호가 획득되더라도 등록 사용자 중 음성 특징의 유사도가 가장 높은 사용자를, 발화 입력을 수행한 사 용자로 결정하는 것에 그친다. 전자 장치는, 예를 들어, 복수의 사용자 DB로부터 획득된 각 사용자에 대한 등록 사용자 특징 벡터와 발 화 구간의 오디오 신호로부터 획득된 사용자 특징 벡터 간 유사도를 획득할 수 있다. 전자 장치는 복수의 사용자 DB 중 발화 구간의 오디오 신호로부터 획득된 사용자 특징 벡터와의 유사도가 가장 높은 등록 사용자 특징 벡터를 포함하는 어느 하나의 사용자 DB를 확인함으로써, 복수의 사용자 중 어느 하나의 사용자를 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자로 결정할 수 있다. 본 개시에서, 벡터 간 유사도 획득은 벡터 간 내적(dot product) 방식, 로그 우도(log likelihood) 계산에 기초 한 유사도 획득 방식 또는 벡터 간 유사도 획득을 위하여 학습된 심층 신경망 모델을 사용하는 방식 중 적어도 하나의 방식으로 이루어질 수 있으나, 이에 제한되지 않으며, 벡터 사이의 유사도 획득에 사용될 수 있는 모든 방식이 이용될 수 있다. 사용자 식별 과정에서 복수의 사용자 중 어느 하나의 사용자가 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자로 결정되면, 전자 장치는, 예를 들어, 사용자에 대하여 획득된 등록 사용자 특징 벡터 및 사용자 특징 벡터에 기초하여 사용자 인증을 수행할 수 있다. 사용자 인증은 발화 입력을 수행한 사용자가 특정 사용자에 해당하는지 여부를 결정하는 것을 의미한다. 즉, 사 용자 인증은 발화 입력을 수행한 사용자가 특정 사용자에 해당하는지 여부를 판단하는 것으로, 발화 입력을 수 행한 사용자가 특정 사용자가 아닌 경우, 사용자의 접근 또는 명령을 거부(reject)하기 위하여 사용될 수 있다. 전자 장치는 사용자를 인증하기 위한 인증 기준을 사용할 수 있다. 전자 장치가 사용하는 인증 기 준은 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 특정 사용자에 해당하는 것으로 결정하기 위한 소정의 기준일 수 있다. 전자 장치는, 예를 들어, 등록 발화 구간의 오디오 신호로부터 획득된 등록 사용자 특징 벡터와 발화 구 간의 오디오 신호로부터 획득된 사용자 특징 벡터 간 유사도를 획득할 수 있다. 전자 장치는 획득된 유사 도를 사용자 인증을 수행하기 위한 기준과 비교하여 사용자에 대한 인증을 수행할 수 있다. 사용자 인증에 사용되는 기준은, 예를 들어, 등록 발화 구간의 오디오 신호로부터 획득된 등록 사용자 특징 벡 터와 발화 구간의 오디오 신호로부터 획득된 사용자 특징 벡터 간 유사도에 대한 임계치일 수 있다. 사용자 특징 벡터는, 예를 들어, 사용자가 발성하는 다양한 음소의 특징에 관한 정보를 포함할 수 있다. 등 록 오디오 신호의 획득에 사용된 문장의 내용과 서로 상이한 문장으로 이루어지는 입력 오디오 신호 의 획득에 사용되는 문장은, 등록 오디오 신호의 획득에 사용된 문장에 포함된 음소와 동일한 음소를 일부 포함할 수 있다. 이와 같은 일부 동일한 음소에 기초하여, 전자 장치는 등록 오디오 신호의 획득에 사용된 문장과 동일한 문장은 물론, 등록 오디오 신호의 획득에 사용된 문장과 서로 상이한 문장에 대응되 는 입력 오디오 신호에 기초하여 사용자 인증을 수행할 수 있다. 한편, 사용자가 등록 오디오 신호에 대응되는 발화 입력을 수행하는 환경과, 입력 오디오 신호에 대응되는 발화 입력을 수행하는 환경은 서로 다른 환경일 수 있다. 전자 장치는 이와 같은 환경 차이에 의한 사용자 인증 성능의 저하를 방지하기 위하여, 사용자 인증에 사용되는 기준을 조정할 수 있다. 전자 장치는 사용자 인증에 사용되는 기준을 조정하기 위하여, 등록 오디오 신호가 획득된 환경 입 력 오디오 신호가 획득된 환경을 서로 비교할 수 있다. 즉, 등록 오디오 신호가 획득된 환경과 입력 오디오 신호가 획득된 환경이 서로 다른 환경에 해당할 경우, 전자 장치는 이와 같은 환경 간 비교 결과에 기초하여 사용자 인증에 사용되는 기준을 조정함으로써, 환경 차이로 인한 전자 장치의 사용 자 인증 성능의 저하를 방지할 수 있다. 전자 장치는 등록 오디오 신호가 획득된 환경 입력 오디오 신호가 획득된 환경을 비교하기 위 하여, 등록 비 발화 구간의 오디오 신호 및 비 발화 구간의 오디오 신호 각각으로부터, 발화 입력이 수신된 환 경을 나타내는 환경 정보를 획득할 수 있다. 환경 정보는 사용자의 발화 입력이 전자 장치에 입력되는 시점의 환경을 나타내는 정보일 수 있다. 환경 정보는, 예를 들어, 전자 장치 주변의 소음에 관련된 정보, 전자 장치의 위치, 전자 장치와 사용자 간의 거리에 관한 정보를 포함할 수 있으나, 이에 제한되지 않는다. 전자 장치의 주변에서 발생되는 소음은, 예를 들어, 일정 기간 이상의 지속 여부(예를 들어, 타인의 일회 성 발화, 타인 간 대화에 의한 지속성 발화 등), 반복 여부(예를 들어, 해변가의 주기적인 파도 소리, 지하철 내의 주기적인 주행 소리 등) 또는 음의 높낮이(예를 들어, 음의 높낮이가 주기적으로 변하는 사이렌 소리) 중 적어도 하나에 기초하여 구분될 수 있다. 환경 정보는, 예를 들어, 오디오 신호가 획득된 상황을 나타내는 벡터 정보를 포함할 수 있다. 전자 장치(100 0)는, 예를 들어, 오디오 신호로부터 획득된 오디오 특징 벡터를 사용하여, 발화 입력이 수신된 환경을 나타내 는 환경 정보로서 환경 특징 벡터를 획득할 수 있다. 전자 장치는. 예를 들어, 환경 특징 벡터를 획득하 기 위한 심층 신경망 모델을 사용하여, 오디오 특징 벡터로부터 환경 특징 벡터를 획득할 수 있다. 환경 특징 벡터의 획득에 사용되는 심층 신경망 모델은, 예를 들어, 전술한 사용자 특징 벡터를 획득하기 위한 심층 신경망 모델과 동일한 심층 신경망 모델일 수 있다. 환경 특징 벡터의 획득에 사용되는 심층 신경망 모델 은 비 발화 구간의 오디오 신호로부터 사용자의 발화 입력이 수행되는 환경의 특징을 식별하기 위한 모델일 수 있다. 환경 특징 벡터의 획득에 사용되는 심층 신경망 모델은, 예를 들어, 서로 다른 환경의 복수의 사용자 에 대한 오디오 특징 벡터를 입력받고, 각 사용자에 대한 환경 특징 벡터를 출력하는 과정을 통해 학습될 수 있 다. 전자 장치는, 예를 들어, 등록 비 발화 구간의 오디오 신호로부터 등록 오디오 신호에 대응되는 환 경 정보를 획득할 수 있다. 전자 장치는, 예를 들어, 등록 비 발화 구간의 오디오 신호로부터, 등록 오디 오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 환경 정보로서 등록 환경 특징 벡터를 획득할 수 있다. 전자 장치는 획득된 등록 환경 특징 벡터를 사용자에 대응되는 사용자 DB에 저장할 수 있다. 즉, 사용자 DB는, 예를 들어, 등록 오디오 신호, 등록 오디오 신호를 입력한 사용자에 대응되는 등록 사용자 특징 벡터 및 등록 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 등록 환경 특징 벡터 중 적어도 하나를 포함할 수 있다. 전자 장치는, 예를 들어, 복수의 사용자의 발화 입력에 기초하여 복수의 등록 오디오 신호를 획득하 고, 복수의 사용자에 대한 사용자 DB를 생성할 수 있다. 전자 장치는 복수의 사용자의 발화 입력에 기초 하여 획득한 복수의 등록 오디오 신호로부터 복수의 사용자 각각에 대한 등록 환경 특징 벡터를 획득할 수 있다. 전자 장치는 획득된 복수의 사용자 각각에 대한 등록 환경 특징 벡터를 각 사용자 DB에 저장할 수 있다. 입력 오디오 신호가 획득되면, 전자 장치는, 예를 들어, 비 발화 구간의 오디오 신호로부터, 입력 오디오 신호에 대응되는 환경 정보를 획득할 수 있다. 전자 장치는, 예를 들어, 비 발화 구간의 오 디오 신호로부터, 입력 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 환경 정보로서 환경 특징 벡터를 획득할 수 있다. 입력 오디오 신호가 획득되면, 전자 장치는, 예를 들어, 사용자 등록 단계에서 미리 생성된 사용자 DB로부터 등록 오디오 신호를 획득하고, 등록 비 발화 구간의 오디오 신호로부터 등록 환경 특징 벡터를 획득할 수 있다. 입력 오디오 신호가 획득되면, 전자 장치는, 다른 예로, 사용자 등록 단계에서 미 리 생성된 사용자 DB로부터 직접 등록 환경 특징 벡터를 획득할 수 있다. 전자 장치는 등록 비 발화 구간의 오디오 신호로부터 획득된 등록 환경 특징 벡터 및 비 발화 구간의 오 디오 신호로부터 획득된 환경 특징 벡터에 기초하여, 입력 오디오 신호가 획득된 환경 및 등록 오디오 신 호가 획득된 환경을 비교할 수 있다. 전자 장치는 입력 오디오 신호가 수신된 환경 및 등록 오 디오 신호가 수신된 환경의 비교 결과에 기초하여, 사용자를 인증하기 위한 기준을 조정할 수 있다 . 전자 장치는, 예를 들어, 등록 비 발화 구간의 오디오 신호로부터 획득된 등록 환경 특징 벡터와 비 발화 구간의 오디오 신호로부터 획득된 환경 특징 벡터 간 유사도를 획득할 수 있다. 전자 장치는 획득된 유사 도에 기초하여, 사용자를 인증하기 위한 기준을 조정할 수 있다. 전자 장치는 조정된 인증 기준 및 입력 오디오 신호에 기초하여 사용자를 인증할 수 있다 . 즉, 전자 장치는, 예를 들어, 획득된 등록 발화 구간의 오디오 신호로부터 획득된 등록 사용자 특징 벡터 와 발화 구간의 오디오 신호로부터 획득된 사용자 특징 벡터 간 유사도를 획득할 수 있다. 전자 장치는 획득된 유사도를 조정된 인증 기준과 비교하여 사용자에 대한 인증을 수행할 수 있다. 한편, 다른 일부 실시예서, 전자 장치는 사용자의 발화 입력에 기초하여 획득한 입력 오디오 신호 를 네트워크를 통해 서버에 송신할 수 있다. 서버는 전자 장치로부터 전달받은 입력 오 디오 신호를 사용하여 사용자 인증을 수행할 수 있다. 서버는, 예를 들어, 전자 장치를 통해 전달받은 등록 오디오 신호를 서버의 메모리에 저장할 수 있다. 서버는, 다른 예로, 전자 장치를 통해 전달받은 등록 오디오 신호에 기초하여 사용자 DB를 생성하고, 생성된 사용자 DB를 서버의 메모리에 저장할 수 있다. 사용자 인증을 수행한 뒤, 서버는 인증 결과를 전자 장치를 통해 사용자에게 전달할 수 있다. 서버가 입력 오디오 신호, 등록 오디오 신호 및 사용자 DB를 사용하여 사용자 인증을 수행하는 구체적인 방법은, 전술한 일부 실시예에 따른 전자 장치가 사용자 인증을 수행하는 방법과 동일하므로, 이에 대한 자세한 설명은 생략한다. 도 2는 일부 실시예에 따른 사용자 인증 방법을 나타낸 흐름도이다. 도 2를 참조하면, 단계 S201에서, 전자 장치는 사용자의 발화 입력에 기초하여 입력 오디오 신호 를 획득할 수 있다. 단계 S202에서, 전자 장치는 획득된 입력 오디오 신호로부터, 적어도 하나의 발화 구간의 오디오 신 호 및 적어도 하나의 비 발화 구간의 오디오 신호를 구별할 수 있다. 전자 장치는, 예를 들어, 획득된 입력 오디오 신호를 프레임 단위로 분할할 수 있다. 전자 장치 는 프레임 단위로 분할된 입력 오디오 신호로부터 발화 구간의 오디오 신호 및 비 발화 구간의 오디 오 신호를 구별하여 획득할 수 있다. 전자 장치는, 예를 들어, 전 처리 단계에서 VAD(Voice Activity Detection) 또는 SNR(Signal to Noise Ratio)의 피크 값 분석 등을 수행하여 입력 오디오 신호로부터 발화 구간의 오디오 신호 및 비 발화 구간 의 오디오 신호를 획득할 수 있다. 전자 장치는, 다른 예로, 입력 오디오 신호에 대해 획득된 오디오 특징 벡터 및 음향 모델(Acoustic model, AM)을 사용하여 발화 구간의 오디오 신호 및 비 발화 구간의 오디오 신호를 획득할 수 있다. 전자 장치 가 음향 모델을 사용하여 발화 구간의 오디오 신호 및 비 발화 구간의 오디오 신호를 획득하는 구체적인 방법에 대해서는 도 3 및 도 4의 실시예를 통해 후술한다. 단계 S203에서, 전자 장치는 비 발화 구간의 오디오 신호에 기초하여, 입력 오디오 신호에 대응되는 발화 입력이 수신된 상황을 나타내는 환경 정보를 생성할 수 있다. 단계 S204에서, 전자 장치는 생성된 환경 정보 및 사용자에 대하여 미리 등록된 등록 오디오 신호 에 대응되는 발화 입력이 수신된 환경을 나타내는 등록 환경 정보의 비교 결과에 기초하여, 사용자를 인증하기 위한 인증 기준을 조정할 수 있다. 단계 S205에서, 전자 장치는 조정된 인증 기준 및 입력 오디오 신호에 기초하여 사용자 인증을 수행 할 수 있다. 전자 장치는, 예를 들어, 등록 발화 구간으로부터 획득된 등록 사용자 특징 벡터 및 발화 구 간의 오디오 신호로부터 획득된 사용자 특징 벡터 간 유사도를 획득하고, 획득된 유사도를 조정된 임계치와 비 교하여 사용자 인증을 수행할 수 있다. 한편, 다른 일부 실시예에서, 도 2의 입력 오디오 신호의 획득(S201) 내지 조정된 인증 기준 및 입력 오디오 신 호에 기초한 사용자 인증(S205) 중 적어도 하나는 서버에 의해 수행될 수 있다. 도 3은 일부 실시예에 따른 입력 오디오 신호에 포함된 발화 구간의 오디오 신호 및 비 발화 구간의 오디오 신 호를 나타내는 도면이다. 전자 장치는, 예를 들어, 입력 오디오 신호를 미리 설정된 프레임 단위로 분할할 수 있다. 전자 장 치는 분할된 각 프레임의 오디오 신호로부터 오디오 특징 벡터를 추출할 수 있다. 음성 인식 분야에서, 오디오 특징 벡터를 추출에 사용되는 오디오 신호의 각 프레임은 시간 도메인 상 20[ms]의 길이를 가지며, 각 프레임이 10[ms] 길이씩 서로 중첩되도록 분할되는 것이 일반적이나, 본 개시의 오디오 특징 벡터 추출 방식이 이와 같은 규격에 제한되는 것은 아니다. 입력 오디오 신호는, 예를 들어, 적어도 하나의 발화 구간의 오디오 신호 및 적어도 하나의 비 발화 구간 의 오디오 신호를 포함할 수 있다. 만약 사용자가 발화 입력을 수행하는 동안 잠시 발성을 중단할 경우, 입 력 오디오 신호는 각 발성 구간과 대응되는 발화 구간의 오디오 신호를 포함함과 동시에, 발성의 시작 이 전 구간, 발성을 중단한 구간 및 발성의 종료 이후 구간에 대응되는 비 발화 구간의 오디오 신호를 포함할 수 있다. 전자 장치는 각 프레임의 오디오 신호로부터 추출된 오디오 특징 벡터에 기초하여, 각 프레임의 오디오 신호를 발화 구간의 오디오 신호 및 비 발화 구간의 오디오 신호로 구분할 수 있다. 전자 장치는, 예를 들어, 연속된 복수의 프레임에 포함되어있는지 여부와 관계없이, 복수의 발화 구간의 오디오 신호에 대한 오디오 특징 벡터를 모두 누적하여 사용자 특징 벡터의 생성에 사용할 수 있다. 또한, 전자 장치는, 예를 들어, 연속된 복수의 프레임에 포함되어있는지 여부와 관계없이 복수의 비 발화 구간의 오디오 신호에 대한 오디오 특징 벡터를 모두 누적하여 환경 특징 벡터의 생성에 사용할 수 있다. 도 3을 참조하면, 입력 오디오 신호는 제1 구간 오디오 신호, 제2 구간 오디오 신호, 제3 구간 오디오 신호, 제4 구간 오디오 신호 및 제5 구간 오디오 신호를 포함할 수 있다. 각 구간 오디 오 신호는, 예를 들어, 적어도 하나 이상의 프레임을 포함할 수 있다. 전자 장치는, 예를 들어, 각 구간 오디오 신호에 포함된 적어도 하나 이상의 프레임 각각에 대하여 오디 오 특징 벡터를 획득할 수 있다. 전자 장치는, 예를 들어, 제1 구간 오디오 신호 내지 제5 구간 오디오 신호 각각에 대하여 획 득된 오디오 특징 벡터에 기초하여, 제1 구간 오디오 신호, 제2 구간 오디오 신호 및 제4 구간 오디 오 신호를 발화 구간의 오디오 신호로 구별하고, 제3 구간 오디오 신호 및 제5 구간 오디오 신호 를 비 발화 구간의 오디오 신호로 구별할 수 있다. 전자 장치는, 예를 들어, 복수의 발화 구간의 오디오 신호, 즉 제1 구간 오디오 신호, 제2 구간 오 디오 신호 및 제4 구간 오디오 신호의 오디오 특징 벡터를 사용하여 사용자 특징 벡터를 획득할 수 있다. 한편, 전자 장치는, 예를 들어, 복수의 비 발화 구간의 오디오 신호, 즉 제3 구간 오디오 신호 및 제5 구간 오디오 신호의 오디오 특징 벡터를 사용하여 환경 특징 벡터를 획득할 수 있다. 참고로, 이하에서 설명할 도면들은 설명의 편의를 위해, 오디오 신호를 구성하는 적어도 하나 이상의 발화 구간 의 오디오 신호 및 적어도 하나의 비 발화 구간의 오디오 신호를, 각각 하나의 발화 구간의 오디오 신호 및 하 나의 비 발화 구간의 오디오 신호로 도시하기로 한다. 도 4는 일부 실시예에 따른 입력 오디오 신호로부터 사용자 특징 벡터를 획득하는 방법을 나타내는 도면이다. 도 4를 참조하면, 전자 장치는 발화 구간의 오디오 신호를 식별하기 위하여, 입력 오디오 신호로부터 제1 오디오 특징 벡터를 획득할 수 있다. 전자 장치는 제1 오디오 특징 벡터에 기초하여, 입력 오디오 신호로부터 발화 구간의 오디오 신호 및 비 발화 구간의 오디오 신호를 구별할 수 있다. 전자 장치는, 예를 들어, 음향 모델을 사용하여 입력 오디오 신호의 각 프레임의 음향 스코어 (acoustic score), 즉, 각 프레임이 특정 음소에 해당할 확률을 획득함으로써, 입력 오디오 신호의 각 프 레임을 발화 구간의 오디오 신호에 대응되는 프레임 및 비 발화 구간의 오디오 신호에 대응되는 프레임 중 어느 하나의 프레임으로 구분할 수 있다. 일반적으로 음성 인식 분야에서 사용되는 음향 모델의 단위로는 모노폰(monophone), 다이폰(diphone), 트라이폰 (triphone), 퀸폰(quinphone), 음절(syllable), 단어(word) 등이 있다. 모노폰은 하나의 음소가 동일하면 같은 단위로 취급하고, 다이폰은 바로 앞의 음소 또는 바로 뒤에 음소가 달라지면 서로 다른 단위로 간주하고, 트리 폰은 좌우의 음소가 동시에 같아야 같은 단위로 취급할 수 있다. 전자 장치는, 예를 들어, 음향 모델을 사용한 각 프레임에 대한 분석 결과로서, 복수의 음소 후보 중 음 향 스코어가 가장 높은 음소 후보를 선택하고, 선택된 음소 후보가 사일런스(silence) 인덱스를 갖는 음소 후보 에 해당할 경우, 해당 프레임을 비 발화 구간의 오디오 신호에 대응되는 프레임으로 분류할 수 있다. 전자 장치는, 예를 들어, 음향 모델을 사용한 각 프레임에 대한 분석 결과로서, 복수의 음소 후보 중 음 향 스코어가 가장 높은 음소 후보를 선택하고, 선택된 음소 후보가 사일런스(silence) 인덱스를 갖는 음소 후보 이외의 다른 음소 후보에 해당할 경우, 해당 프레임을 발화 구간의 오디오 신호에 대응되는 프레임으로 분류할 수 있다. 즉, 전자 장치는 각 프레임의 음향 스코어에 기초하여 입력 오디오 신호의 모든 프레임을 비 발화 구간의 오디오 신호에 대응되는 프레임 중 어느 하나로 분류함으로써, 입력 오디오 신호로부터 발화 구간 의 오디오 신호 및 비 발화 구간의 오디오 신호를 구별할 수 있다. 전자 장치는 발화 구간의 오디오 신호로부터 제2 오디오 특징 벡터를 획득할 수 있다. 전자 장치 는, 예를 들어, 제1 오디오 특징 벡터의 획득에 사용되는 오디오 특징 벡터 추출 방식과 상이한 방식을 통해 발화 구간의 오디오 신호로부터 제2 오디오 특징 벡터를 획득할 수 있다. 전자 장치는 획득된 제2 오디오 특징 벡터에 기초하여, 사용자에 대응되는 사용자 특징 벡터를 생성 할 수 있다. 한편, 다른 일부 실시예에서, 도 4의 제1 오디오 특징 벡터의 획득 내지 사용자 특징 벡터의 생성 중 적어도 하나는 서버에서 수행될 수 있다. 도 5a는 일부 실시예에 따른 사용자 등록 환경 및 등록 오디오 신호의 관계를 나타내는 도면이다. 도 5a를 참조하면, 사용자는 자신을 제1 전자 장치의 사용자로 등록할 수 있다. 사용자는, 예를 들 어, 소정의 제1 문장을 발성하여 제1 전자 장치에 대한 발화 입력을 수행할 수 있다. 제1 전자 장치는사용자의 발화 입력에 기초하여 제1 등록 오디오 신호를 획득할 수 있다. 제1 전자 장치가 사용자로부터 제1 등록 오디오 신호에 대응되는 발화 입력을 수신하는 환경은 사 용자, 제1 전자 장치 및 제1 전자 장치의 주변에 위치한 TV가 존재하는 실내 공간일 수 있다. 제1 전자 장치가 제1 등록 오디오 신호를 획득하는 시점에, TV의 전원은 오프(off) 상태일 수 있 다. 제1 전자 장치는, 예를 들어, 제1 등록 오디오 신호를 제1 등록 발화 구간의 오디오 신호 및 제1 등록 비 발화 구간의 오디오 신호로 구별할 수 있다. 도 5b는 일부 실시예에 따른 사용자 인증 환경 및 입력 오디오 신호의 관계를 나타내는 도면이다. 도 5b를 참조하면, 사용자는, 예를 들어, 제2 문장을 발성하여 제1 전자 장치에 대한 발화 입력을 수행 할 수 있다. 제1 전자 장치는 사용자의 발화 입력에 기초하여 제1 입력 오디오 신호를 획득할 수 있다. 제2 문장은, 예를 들어, 사용자의 등록에 사용된 제1 문장과 서로 상이한 문장일 수 있다. 제1 전자 장치가 사용자로부터 제1 입력 오디오 신호에 대응되는 발화 입력을 수신하는 환경은 사 용자, 제1 전자 장치 및 제1 전자 장치의 주변에 위치한 TV가 존재하는 실내 공간일 수 있다. 다만, 제1 전자 장치가 사용자로부터 제1 입력 오디오 신호에 대응되는 발화 입력을 수신하는 시점에 TV의 전원은, 제1 등록 오디오 신호에 대응되는 발화 입력을 수신한 시점과는 달리, 온(on) 상태일 수 있으며, TV의 스피커에서는 제1 전자 장치의 마이크에 입력될 수 있는 크기의 음량을 갖는 소리가 출력 될 수 있다. 제1 전자 장치는, 예를 들어, 제1 입력 오디오 신호를 제1 발화 구간의 오디오 신호 및 제1 비 발화 구간의 오디오 신호로 구별할 수 있다. 도 5a 및 도 5b를 참조하면, TV의 스피커를 통해 출력되는 소리가 존재하는 환경으로 인해, 제1 등록 비 발 화 구간의 오디오 신호와 제1 비 발화 구간의 오디오 신호는 서로 상이할 수 있다. 즉, 제1 등록 비 발화 구간의 오디오 신호의 오디오 특징과 제1 비 발화 구간의 오디오 신호의 오디 오 특징은 서로 상이할 수 있으며, 오디오 특징 간 차이는 제1 TV의 스피커 출력 레벨이 높아짐에 따라 더 커질 수 있다. 제1 전자 장치는, 예를 들어, 서로 상이한 제1 등록 비 발화 구간의 오디오 신호의 오디오 특징과 제1 비 발화 구간의 오디오 신호의 오디오 특징에 기초하여, 사용자 인증을 위한 인증 기준을 조정할 수 있다. 제1 전자 장치는, 예를 들어, 제1 비 발화 구간의 오디오 신호를 사용하여, 제1 입력 오디오 신호 에 대응되는 발화 입력이 수신된 환경을 나타내는 환경 정보를 획득할 수 있다. 제1 전자 장치는, 예 를 들어, 제1 비 발화 구간의 오디오 신호로부터 제1 환경 특징 벡터를 획득할 수 있다. 한편, 제1 전자 장치는, 예를 들어, 미리 등록된 제1 등록 오디오 신호로부터 획득한 제1 등록 비 발 화 구간의 오디오 신호를 사용하여, 제1 등록 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나 타내는 환경 정보를 획득할 수 있다. 제1 전자 장치는, 예를 들어, 제1 등록 비 발화 구간의 오디오 신호 로부터 제1 등록 환경 특징 벡터를 획득할 수 있다. 제1 전자 장치는 제1 등록 환경 특징 벡터와 제1 환경 특징 벡터의 비교를 통해, 각 오디오 신호가 수신된 환경 사이의 유사 정도를 판단하고, 판단 결과에 기초하여 사용자 인증을 위한 인증 기준을 조정할 수 있다. 즉, 제1 등록 환경 특징 벡터와 제1 환경 특징 벡터의 유사 정도는 제1 TV의 스피커 출력 레벨이 높아짐에 따라 낮아질 수 있다. 한편, 다른 일부 실시예에서, 도 5a 및 도 5b의 제1 등록 환경 특징 벡터와 제1 환경 특징 벡터의 비교를 통한 인증 기준 조정은 서버에 의해 수행될 수 있다. 이처럼 본 개시의 일부 실시예에 따른 사용자 인증 방법을 사용하는 전자 장치 및/또는 서버는, 등 록 오디오 신호가 획득된 환경 및 입력 오디오 신호가 획득된 환경 사이의 유사도를 고려하여 인증 기준의 조정 정도를 결정함으로써, 오디오 신호의 다양한 입력 환경에 대응하여 사용자 인증 성능의 저하를 방지할 수 있다. 도 6a는 일부 실시예에 따른 사용자 등록 환경 및 등록 오디오 신호의 관계를 나타내는 도면이다. 도 6a를 참조하면, 사용자는 자신을 제1 전자 장치의 사용자로 등록할 수 있다. 사용자는, 예를 들 어, 소정의 제1 문장을 발성하여 제1 전자 장치에 대한 발화 입력을 수행할 수 있다. 제1 전자 장치는 사용자의 발화 입력에 기초하여 제2 등록 오디오 신호를 획득할 수 있다. 제1 전자 장치가 사용자로부터 제2 등록 오디오 신호에 대응되는 발화 입력을 수신하는 환경은 사 용자, 제1 전자 장치 및 제1 전자 장치의 주변에 위치한 TV가 존재하는 실내 공간일 수 있다. 제1 전자 장치가 제2 등록 오디오 신호를 획득하는 시점에, 제1 전자 장치와 사용자는 제1 거 리 만큼 떨어져 있을 수 있다. 제1 전자 장치는, 예를 들어, 제2 등록 오디오 신호를 제2 등록 발화 구간의 오디오 신호 및 제2 등록 비 발화 구간의 오디오 신호로 구별할 수 있다. 도 6b는 일부 실시예에 따른 사용자 인증 환경 및 입력 오디오 신호의 관계를 나타내는 도면이다. 도 6b를 참조하면, 사용자는, 예를 들어, 제2 문장을 발성하여 제1 전자 장치에 대한 발화 입력을 수행 할 수 있다. 제1 전자 장치는 사용자의 발화 입력에 기초하여 제2 입력 오디오 신호를 획득할 수 있다. 제2 문장은, 예를 들어, 사용자의 등록에 사용된 제1 문장과 서로 상이한 문장일 수 있다. 제1 전자 장치가 사용자로부터 제2 입력 오디오 신호에 대응되는 발화 입력을 수신하는 환경은 사 용자, 제1 전자 장치 및 제1 전자 장치 주변에 위치한 TV가 존재하는 실내 공간일 수 있다. 다만, 제1 전자 장치가 사용자로부터 제2 입력 오디오 신호에 대응되는 발화 입력을 수신하는 시점에 제1 전자 장치와 사용자는, 제2 입력 오디오 신호에 대응되는 발화 입력을 수신한 시점과는 달리, 제2 거리 만큼 떨어져 있을 수 있다. 제1 전자 장치는, 예를 들어, 제2 입력 오디오 신호를 제2 발화 구간의 오디오 신호 및 제2 비 발화 구간의 오디오 신호로 구별할 수 있다. 도 6a 및 도 6b를 참조하면, 사용자와 제1 전자 장치 사이의 거리가 제1 거리에서 제2 거리로 늘어남에 따라, 제2 등록 발화 구간의 오디오 신호와 제2 발화 구간의 오디오 신호는 서로 상이할 수 있다. 평균 에너지는 오디오 신호의 세기를 나타내는 척도이며, 각 발화 구간의 평균 에너지는 사용자와 제1 전자 장치 사이의 거리가 늘어남에 따라 작아질 수 있다. 즉, 제2 등록 발화 구간의 오디오 신호의 평균 에 너지와 제2 발화 구간의 오디오 신호의 평균 에너지는 서로 상이할 수 있으며, 이와 같은 평균 에너지 차 이는 사용자와 제1 전자 장치 사이의 거리가 늘어남에 따라 더 커질 수 있다. 제1 전자 장치는, 예를 들어, 서로 상이한 제2 등록 발화 구간의 오디오 신호의 평균 에너지와 제2 발 화 구간의 오디오 신호의 평균 에너지에 기초하여, 사용자 인증을 위한 인증의 기준을 조정할 수 있다. 제1 전자 장치는, 예를 들어, 제2 등록 발화 구간의 오디오 신호의 평균 에너지가 제2 발화 구간의 오 디오 신호의 평균 에너지보다 클 경우, 제2 거리가 제1 거리보다 긴 것으로 판단하고, 제2 등록 발화 구간의 오디오 신호의 평균 에너지 및 제2 발화 구간의 오디오 신호의 평균 에너지의 에너지 비 율에 기초하여 사용자 인증을 위한 인증 기준을 조정할 수 있다. 한편, 다른 일부 실시예에서, 도 6a 및 도 6b의 평균 에너지의 에너지 비율에 기초한 인증 기준 조정은 서버 에 의해 수행될 수 있다. 이처럼 본 개시의 일부 실시예에 따른 사용자 인증 방법을 사용하는 전자 장치 및/또는 서버는, 등 록 오디오 신호가 획득된 환경 및 입력 오디오 신호가 획득된 환경 사이의 유사도를 고려하여 인증 기준의 조정 정도를 결정함으로써, 오디오 신호의 다양한 입력 환경에 대응하여 사용자 인증 성능의 저하를 방지할 수 있다. 도 7은 일부 실시예에 따른 발화 구간의 오디오 신호 및 등록 발화 구간의 오디오 신호에 기초하여 사용자 인증 을 수행하는 과정을 나타낸 도면이다. 도 7을 참조하면, 입력 오디오 신호가 획득되면, 전자 장치는 획득된 입력 오디오 신호로부터 발화 구간의 오디오 신호를 획득할 수 있다. 전자 장치는 획득된 발화 구간의 오디오 신호로부터 사 용자 특징 벡터를 획득할 수 있다.일부 실시예에서, 발화 구간의 오디오 신호로부터 사용자 특징 벡터가 획득되는 과정에서, 전자 장치의 주변 환경에 의해 생성된 오디오 신호에 대응되는 환경 성분은 완전히 제거되지 않고 사용자 특징 벡터에 남아 있을 수 있다. 환경 성분이 제거된 사용자 특징 벡터를 생성하기 위하여, 전자 장치는 사용자 특징 벡터에 대한 후처리 를 수행할 수 있다. 전자 장치는, 예를 들어, 사용자 특징 벡터로부터 환경 성분을 제거하기 위한 후처리 모델을 사용하여, 발화 구간의 오디오 신호로부터 획득된 사용자 특징 벡터에 잔존하는 환경 성분을 제거할 수 있다. 사용자 특징 벡터로부터 환경 성분을 제거하는데 사용되는 심층 신경망 모델은, 예를 들어, 사용자 특징 벡터의 생성에 사용되는 심층 신경망 모델을 사용하여 복수의 제2 환경(예를 들어, 주변 소음의 크기가 소정의 임계치 이하인 복수의 환경)에서 획득된 사용자 특징 벡터를 입력받고, 제1 환경(예를 들어, 주변 소음의 크기가 소정 의 임계치 이하로서, 소음이 존재하지 않는 것으로 판단된 환경)에서 특정 사용자에 대해 획득된 사용자 특징 벡터와 동일한 벡터를 출력하는 과정을 통해 학습될 수 있다. 한편, 전자 장치는, 예를 들어, 사용자 특징 벡터로부터 제거된 잔존 환경 성분에 기초하여, 사용자 인증 에 사용되는 임계치를 추가로 조정할 수 있다. 임계치의 추가 조정은, 도 8을 통해 후술할 환경 특징 벡터의 유 사도에 기초한 임계치 조정에 더하여, 환경 특징 벡터의 유사도에 기초한 임계치 조정과 동일한 방식으로 이루 어질 수 있다. 한편, 입력 오디오 신호가 획득되면, 전자 장치는, 예를 들어, 사용자 DB로부터 등록 오디오 신호 를 획득하고, 획득된 등록 오디오 신호로부터 등록 발화 구간의 오디오 신호를 획득할 수 있다. 전자 장치는 획득된 등록 발화 구간의 오디오 신호로부터 등록 사용자 특징 벡터를 획득할 수 있다. 입력 오디오 신호가 획득되면, 전자 장치는, 다른 예로, 사용자 DB로부터 등록 사용자 특징 벡터를 직접 획득할 수도 있다. 전자 장치는, 예를 들어, 사용자 인증을 수행하기 위해, 등록 발화 구간의 오디오 신호로부터 획득된 등 록 사용자 특징 벡터와 발화 구간의 오디오 신호로부터 획득된 사용자 특징 벡터 간 유사도를 산출할 수 있다 . 전자 장치는 산출된 사용자 특징 벡터 간 유사도를 임계치와 비교할 수 있다. 전자 장치는 획 득된 사용자 특징 벡터 간 유사도 및 임계치의 비교 결과에 기초하여 사용자에 대한 인증을 수행할 수 있다 . 한편, 다른 일부 실시예에서, 도 7의 발화 구간의 오디오 신호의 획득 내지 사용자 특징 벡터 간 유사도 및 임계치의 비교에 따른 사용자 인증 중 적어도 하나는 서버에 의해 수행될 수 있다. 도 8은 일부 실시예에 따른 비 발화 구간의 오디오 신호 및 등록 비 발화 구간의 오디오 신호를 사용하여 사용 자 인증을 위한 임계치를 조정하는 방법을 나타낸 도면이다. 도 8을 참조하면, 입력 오디오 신호가 획득되면, 전자 장치는 획득된 입력 오디오 신호로부터 발화 구간의 오디오 신호를 획득할 수 있다. 등록 발화 구간의 오디오 신호가 획득되면, 전자 장치 는 시간 도메인 상 발화 구간의 오디오 신호가 지속되는 시간의 길이(이하, 발화 구간의 길이)를 식별할 수 있 다. 한편, 사용자로부터 입력 오디오 신호가 입력되면, 전자 장치는, 예를 들어, 사용자 DB로부터 등록 오디오 신호를 획득하고, 획득된 등록 오디오 신호로부터 등록 발화 구간의 오디오 신호를 획득할 수 있다. 등록 발화 구간의 오디오 신호가 획득되면, 전자 장치는 시간 도메인 상 등록 발화 구간의 오 디오 신호가 지속되는 시간의 길이(이하, 등록 발화 구간의 길이)를 식별할 수 있다. 전자 장치는 획득된 발화 구간의 길이 및 등록 발화 구간의 길이에 기초하여, 임계치 테이블에 포함된 복 수의 임계치 중 사용자 인증에 이용되는 어느 하나의 임계치를 선택할 수 있다. 한편, 입력 오디오 신호가 획득되면, 전자 장치는 획득된 입력 오디오 신호로부터 비 발화 구 간의 오디오 신호를 획득할 수 있다. 전자 장치는 획득된 비 발화 구간의 오디오 신호로부터, 입력 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 환경 정보를 획득할 수 있다.한편, 입력 오디오 신호가 획득되면, 전자 장치는, 예를 들어, 사용자 DB로부터 등록 오디오 신호 를 획득하고, 획득된 등록 오디오 신호로부터 등록 비 발화 구간의 오디오 신호를 획득할 수 있다 . 전자 장치는 획득된 등록 비 발화 구간의 오디오 신호로부터, 등록 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 등록 환경 정보를 획득할 수 있다. 전자 장치는 환경 정보 및 등록 환경 정보를 서로 비교할 수 있다. 전자 장치는 획득된 환경 정보 및 등록 환경 정보의 비교 결과에 기초하여, 임계치 테이블로부터 선택된 어느 하나의 임계치를 조정 할 수 있다. 한편, 다른 일부 실시예에서, 도 8의 발화 구간의 오디오 신호의 획득 내지 환경 정보 및 등록 환경 정보 의 비교 결과에 기초한 임계치의 조정 중 적어도 하나는 서버에 의해 수행될 수 있다. 도 9는 일부 실시예에 따른 미리 설정된 임계치 테이블을 나타낸 도면이다. 일부 실시예에 따른 전자 장치는, 사용자 인증을 위한 기준으로서, 등록 발화 구간의 오디오 신호로부터 획득된 등록 사용자 특징 벡터와 발화 구간의 오디오 신호로부터 획득된 사용자 특징 벡터 간 유사도에 대한 적 어도 하나의 임계치를 사용할 수 있다. 적어도 하나의 임계치는, 예를 들어, 입력 오디오 신호의 획득 이 전에 전자 장치의 메모리에 미리 저장될 수 있다. 인증 기준으로 사용되는 복수의 임계치는, 예를 들어, 임계치 테이블로 전자 장치의 메모리에 저장될 수 있다. 임계치 테이블은, 예를 들어, 복수의 사용자의 발화 입력에 대응되는 오디오 신호에 기초하여 생성될 수 있다. 임계치 테이블은, 예를 들어, 획득된 오디오 신호가 특정 사용자와 서로 대응되는지 여부에 관한 이진 종속 변 수(즉, 대응되거나, 대응되지 않음을 나타내는 이진 종속 변수)에 대한 로지스틱 회귀(logistic regression) 분 석을 통해 획득될 수 있다. 로지스틱 회귀 분석을 통해 획득된 복수의 임계치는, 예를 들어, 0 내지 1 사이의 정규화된 스칼라 값을 가질 수 있다. 임계치 테이블은, 예를 들어, 인증 오류의 백분율, 즉 사용자를 타인으로 인식하여 사용자 인증을 거부하는 본 인 거부율(False Rejection Rate, FRR) 및 타인을 사용자로 인식하여 사용자 인증을 승인하는 타인 수락률 (False Acceptance Rate, FAR) 간 비율에 기초하여 생성된 복수의 임계치를 포함할 수 있다. 일반적으로, 전자 장치의 사용자 인증 정확도는 시간 도메인 상 입력 오디오 신호가 지속되는 시간의 길이 및 등록 오디오 신호의 길이가 증가하면 높아지는 경향이 있다. 만약, 단일 임계치를 사용할 경우, 입력 오디오 신 호의 길이 및 등록 오디오 신호의 길이가 증가하면 타인 수락률이 증가하고, 입력 오디오 신호의 길이 및 등록 오디오 신호의 길이가 감소하면 본인 거부율이 증가할 수 있다. 본인 거부율과 타인 수락률은 서로 상충(trade off) 관계에 있으므로, 임계치 테이블은 다양한 길이의 입력 오 디오 신호 및 등록 오디오 신호에 대응되는 복수의 임계치를 포함하도록 설정될 수 있으며, 전자 장치는 임계치 테이블을 사용함으로써, 입력 오디오 신호 및 등록 오디오 신호의 길이의 감소 또는 증가에 따른 사용자 인증 성능의 변화를 방지할 수 있다. 전자 장치는, 예를 들어, 복수의 임계치를 포함하는 임계치 테이블로부터, 입력 오디오 신호의 발화 구간의 길이 및 등록 오디오 신호의 등록 발화 구간의 길이에 대응되는 어느 하나의 임계치를 선택할 수 있다. 전자 장치는, 예를 들어, 사용자로부터 입력 오디오 신호에 대응되는 발화 입력을 수신함과 동시에 발화 구간의 길이를 실시간으로 측정할 수 있다. 전자 장치는, 예를 들어, 사용자 등록 단계 등록 오디오 신호를 획득함과 동시에 등록 발화 구간의 길이를 측정하고, 측정된 등록 발화 구간의 길이를 사용자 DB에 저장할 수 있다. 도 9를 참조하면, 일부 실시예에 따른 임계치 테이블은 5[sec] 길이의 단위로 분류된 등록 발화 구간의 길이 (P1) 및 0.1[sec] 길이의 단위로 분류된 발화 구간의 길이(P2) 각각에 대응되는 복수의 임계치를 포함할 수 있 다. 임계치 테이블에 포함된 복수의 임계치는, 예를 들어, 0 내지 1 사이의 정규화된 스칼라 값을 가질 수 있다. 예를 들어, 입력 오디오 신호의 발화 구간의 길이가 1.15(sec)이고 등록 오디오 신호의 등록 발화 구 간의 길이가 16(sec)일 경우, 전자 장치는 사용자 인증을 위한 임계치를 0.673734로 선택할 수 있다. 한편, 입력 오디오 신호의 발화 구간의 길이가 1.5(sec)이고 등록 오디오 신호의 등록 발화 구간의 길이가 20(sec)일 경우, 전자 장치는 사용자 인증을 위하여 사용되는 임계치를 0.870094로 선택할 수 있 다. 전자 장치는 서로 다른 발화 구간의 길이를 갖는 입력 오디오 신호가 획득될 경우, 임계치 테이블 을 사용함으로써 동일한 등록 발화 구간의 길이에 대하여 서로 다른 임계치를 사용할 수 있으므로, 입력 오 디오 신호의 길이의 감소 또는 증가에 따른 사용자 인증 성능의 변화를 방지할 수 있다. 도 10은 일부 실시예에 따른 사용자 DB의 업데이트 방법을 나타낸 흐름도이다. 전자 장치가 반복하여 사용자에 대한 인증을 수행함에 따라, 사용자 DB는 업데이트될 수 있다. 예를 들어, 전자 장치가 반복하여 사용자의 인증을 수행함에 따라, 사용자 DB에 저장된 등록 오디오 신호 , 등록 사용자 특징 벡터, 등록 환경 특징 벡터, 등록 발화 구간의 길이 중 적어도 하나가 업데이트될 수 있다. 전자 장치는, 예를 들어, 사용자 DB를 업데이트하기 위하여, 사용자 인증을 위한 임계치 테이블과 구별되 는 별도의 임계치 테이블을 사용할 수 있다. 전자 장치는, 예를 들어, 사용자 DB로부터 획득된 등록 사용자 특징 벡터와 입력 오디오 신호로부터 획득된 사용자 특징 벡터 사이의 유사도를 획득하고, 획득된 유사도를 사용자 인증을 위한 기준이 되는 임계치 테이블에서 선택된 어느 하나의 임계치와 비교하여 사용자 인증을 수행할 수 있다. 획득된 유사도가 선택된 임계치 이상의 값을 가질 경우, 전자 장치는, 예를 들어, 획득된 사용자 특징 벡 터 간 유사도를 사용자 DB의 업데이트를 위한 임계치 테이블에서 선택된 어느 하나의 임계치와 비교할 수 있다. 사용자 DB의 업데이트를 위한 임계치 테이블은, 예를 들어, 사용자 인증에 사용되는 임계치 테이블에 비하여 상 대적으로 낮은 타인 수락률(FAR)을 갖는 복수의 임계치를 포함하도록 설정될 수 있다. 즉, 동일한 등록 발화 구 간의 길이 및 발화 구간의 길이에 대하여, 사용자 DB의 업데이트를 위한 임계치 테이블은 사용자 인증을 위한 기준이 되는 임계치 테이블에 비하여 상대적으로 높은 임계치를 포함하도록 설정될 수 있다. 즉, 전자 장치는 사용자 DB의 업데이트를 위한 임계치 테이블을 사용함으로써, 사용자 인증을 위한 기준 이 되는 임계치 테이블에 비하여 상대적으로 높은 임계치를 만족하는 입력 오디오 신호를 선별할 수 있다. 전자 장치는 선별된 입력 오디오 신호에 기초하여 사용자 DB를 업데이트할 수 있으므로, 사용자 인 증이 반복됨에 따라 전자 장치의 사용자 인증 성능은 향상될 수 있다. 도 10을 참조하면, 전자 장치는, 예를 들어, 단계 S1001에서 입력 오디오 신호로부터 발화 구간의 오디오 신호를 획득하고, S1002 단계에서, 획득된 발화 구간의 오디오 신호로부터 사용자 특징 벡터를 획득할 수 있다. S1003 단계에서, 전자 장치는 사용자 DB로부터 획득된 등록 사용자 특징 벡터 및 발화 구간의 오디 오 신호로부터 획득된 사용자 특징 벡터 간 유사도를 계산하고, 계산된 유사도를 제1 임계치 테이블로부 터 선택된 어느 하나의 임계치와 비교할 수 있다. 제1 임계치 테이블은, 예를 들어, 사용자 인증을 위한 복수의 임계치를 포함할 수 있다. 비교 결과, 계산 된 유사도가 제1 임계치 테이블로부터 선택된 어느 하나의 임계치 이상일 경우, S1004 단계에서, 전자 장 치는 계산된 유사도를 제2 테이블로부터 선택된 어느 하나의 임계치와 비교할 수 있다. 제2 임계치 테이블은, 예를 들어, 사용자 DB의 업데이트를 위한 복수의 임계치를 포함할 수 있다. 비교 결과, 계산된 유사도가 제2 임계치 테이블로부터 선택된 어느 하나의 임계치 이상일 경우, S1005 단 계에서, 전자 장치는 사용자 DB로부터 획득된 등록 사용자 특징 벡터와 발화 구간의 오디오 신호로부터 획득된 사용자 특징 벡터에 대한 가중 합(weighted sum)을 계산할 수 있다. 전자 장치는, 예를 들어, 사용자 DB로부터 획득된 등록 발화 구간의 길이 및 입력 오디오 신호로부 터 획득된 발화 구간의 길이 간 비율에 따라, 사용자 DB로부터 획득된 등록 사용자 특징 벡터 및 발화 구간의 오디오 신호로부터 획득된 사용자 특징 벡터에 서로 다른 가중치를 적용하여 가중합을 계산할 수 있다. 예를 들어, 사용자 DB로부터 획득된 등록 발화 구간의 길이가 12(sec)이고 입력 오디오 신호로부터 획득된 발화 구간의 길이가 3(sec)일 경우, 전자 장치는 등록 사용자 특징 벡터와 사용자 특징 벡터에 대하여 4:1 비율의 가중치를 적용한 가중합을 통해 새로운 사용자 특징 벡터를 획득할 수 있다. S1005 단계의 계산 결과에 기초하여, 전자 장치는, S1006 단계에서, 사용자 DB를 업데이트할 수 있다. 새 로운 사용자 특징 벡터가 획득되면, 전자 장치는 사용자 DB에 포함된 등록 사용자 특징 벡터를 획득된 새 로운 사용자 특징 벡터로 업데이트할 수 있다. 한편, 전자 장치는 등록 환경 특징 벡터에 대해서도 사용자 특징 벡터와 동일한 방식으로 업데이트를 수 행할 수 있다. 전자 장치는, 예를 들어, S1004 단계의 비교 결과, 계산된 유사도가 제2 임계치 테이블로부터 선택 된 어느 하나의 임계치 이상일 경우, 사용자 DB의 등록 사용자 특징 벡터를 업데이트함과 동시에 등록 환경 특 징 벡터를 업데이트할 수 있다. 예를 들어, 사용자 DB로부터 획득된 등록 비 발화 구간의 길이가 2(sec)이고, 입력 오디오 신호로부터 획 득된 비 발화 구간의 길이가 1(sec)일 경우, 전자 장치는 등록 환경 특징 벡터와 환경 특징 벡터에 대한 2:1 비율의 가중치를 적용한 가중합을 통해 새로운 환경 특징 벡터를 획득할 수 있다. 새로운 환경 특징 벡터가 획득되면, 전자 장치는 사용자 DB에 포함된 등록 환경 특징 벡터를 획득된 새로 운 환경 특징 벡터로 갈음하여 업데이트할 수 있다. 도 11은 일부 실시예에 따른 비 발화 구간의 오디오 신호 및 등록 비 발화 구간의 오디오 신호를 사용하여 임계 치를 조정하는 방법을 나타낸 도면이다. 도 11을 참조하면, 입력 오디오 신호가 획득되면, 전자 장치는 획득된 입력 오디오 신호로부터 발화 구간의 오디오 및 비 발화 구간의 오디오 신호를 획득할 수 있다(1101, 1102). 전자 장치는 획득된 비 발화 구간의 오디오 신호로부터, 입력 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 환경 정보를 획득할 수 있다. 전자 장치는, 예를 들어, 비 발화 구간의 오디오 신호로부터, 입력 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 환경 정보로서 환경 특징 벡터를 획득할 수 있다. 한편, 입력 오디오 신호가 획득되면, 전자 장치는 획득된 등록 오디오 신호로부터 등록 발화 구간의 오디오 신호 및 등록 비 발화 구간의 오디오 신호를 획득할 수 있다(1103, 1104). 전자 장치는 획득된 등록 비 발화 구간의 오디오 신호로부터, 등록 오디오 신호에 대응되는 발화 입 력이 수신된 환경을 나타내는 환경 정보를 획득할 수 있다. 전자 장치는, 예를 들어, 등록 비 발화 구간 의 오디오 신호로부터, 등록 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 환경 정보로서 등록 환경 특징 벡터를 획득할 수 있다. 전자 장치는, 예를 들어, 획득된 환경 특징 벡터 및 등록 환경 특징 벡터 간 유사도를 획득할 수 있다 . 전자 장치는 획득된 환경 특징 벡터 간 유사도에 기초하여, 임계치 테이블에 포함된 복수의 임계치 중에 서 선택된 사용자 인증에 이용되는 어느 하나의 임계치를 조정할 수 있다. 조정된 임계치는 발화 구간의 오디오 신호로부터 획득된 사용자 특징 벡터 및 등록 발화 구간의 오디오 신호로부터 획득된 등록 사용 자 특징 벡터 간 유사도와 비교되어 사용자 인증에 사용될 수 있다, 전자 장치는, 예를 들어, 다음의 수식에 따라 임계치를 조정할 수 있다. 수학식 1"}
{"patent_id": "10-2019-0094532", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상기 [수학식 1]에서, Sr은 환경 특징 벡터 간 유사도를, ws는 환경 특징 벡터 간 유사도의 가중 계수를, THbase 는 임계치 테이블에서 선택된 어느 하나의 임계치를, THfinal은 조정된 임계치를 의미한다. 환경 특징 벡터의 유사도 Sr은, 예를 들어, 동일한 환경 특징 벡터 사이에 대하여 1의 값을 가질 수 있다. 환경 특징 벡터 유사도의 가중 계수 ws는, 예를 들어, 다른 거리 및 다른 환경 조건에서 획득된 복수의 오디오 신호를 포함하는 실험 데이 터에 기초하여 설정될 수 있다. 한편, 다른 일부 실시예에서, 도 11의 발화 구간의 오디오 신호의 획득 내지 환경 특징 벡터 및 등록 환 경 특징 벡터 간 유사도에 기초한 임계치 조정 중 적어도 하나는 서버에 의해 수행될 수 있다. 도 12는 일부 실시예에 따른 발화 구간의 오디오 신호 및 등록 발화 구간의 오디오 신호를 사용하여 임계치를 조정하는 방법을 나타낸 도면이다. 도 12를 참조하면, 입력 오디오 신호가 획득되면, 전자 장치는 획득된 입력 오디오 신호로부터 발화 구간의 오디오 및 비 발화 구간의 오디오 신호를 획득할 수 있다(1201, 1202). 전자 장치는 획득된 발화 구간의 오디오 신호로부터 발화 구간의 평균 에너지를 산출할 수 있다. 오디오 신호의 특정 구간의 평균 에너지는, 예를 들어, 특정 구간에 포함된 오디오 신호의 프레임의 진폭에 대 한 절대값의 평균에 대응될 수 있다. 한편, 입력 오디오 신호가 획득되면, 전자 장치는 획득된 등록 오디오 신호로부터 등록 발화 구간의 오디오 신호 및 등록 비 발화 구간의 오디오 신호를 획득할 수 있다(1203, 1204). 전자 장치는, 예를 들어, 획득된 등록 발화 구간의 오디오 신호로부터 등록 발화 구간의 평균 에너지를 획득할 수 있다. 전자 장치는, 다른 예로, 사용자 등록 단계에서 미리 생성된 사용자 DB로부터 직 접 등록 발화 구간의 평균 에너지를 획득할 수 있다. 전자 장치는 산출된 발화 구간의 평균 에너지 및 등록 발화 구간의 평균 에너지를 서로 비교하여 에너지 비율을 획득할 수 있다. 전자 장치는, 예를 들어, 다음의 수식에 따라 에너지 비율을 획득할 수 있다. 수학식 2"}
{"patent_id": "10-2019-0094532", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기 [수학식 2]에서, Eenroll은 등록 발화 구간의 오디오 신호로부터 산출된 평균 에너지값을, Etest는 발화 구간 의 오디오 신호로부터 산출된 평균 에너지값을, Er은 에너지 비율을 의미한다. 전자 장치는 획득된 에너지 비율에 기초하여, 임계치 테이블에 포함된 복수의 임계치 중에서 선택 된 사용자 인증에 이용되는 어느 하나의 임계치를 조정할 수 있다. 조정된 임계치는 발화 구간의 오디오 신호로부터 획득된 사용자 특징 벡터 및 등록 발화 구간의 오디오 신호로부터 획득된 등록 사용자 특징 벡터 간 유사도와 비교되어 사용자 인증에 사용될 수 있다, 전자 장치는, 예를 들어, 다음의 수식에 따라 임계치를 조정할 수 있다. 수학식 3 상기 [수학식 3]에서, Er은 에너지 비율을, we는 에너지 비율의 가중 계수를, THbase는 임계치 테이블에서 선택된 어느 하나의 임계치를, THfinal은 조정된 임계치를 의미한다. 에너지 비율의 가중 계수 we는, 예를 들어, 다른 거 리 및 다른 환경 조건에서 획득된 복수의 오디오 신호를 포함하는 실험 데이터에 기초하여 설정될 수 있다. 전자 장치는, 예를 들어, 도 11 및 도 12의 임계치 조정 방법 중 적어도 하나의 방법을 사용하여 임계치 를 조정할 수 있다. 도 11 및 도 12의 임계치 조정 방법을 모두 사용할 경우, 전자 장치는 상기 [수학식 1] 및 [수학식 3]이 결합된 다음의 수식에 따라 임계치를 조정할 수 있다. 수학식 4"}
{"patent_id": "10-2019-0094532", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "한편, 전자 장치는 복수의 사용자에 대한 전자 장치의 사용자 간 인증 성능의 편차를 제거하기 위 한 사용자 특성 파라미터 값을 사용할 수 있다. 사용자 특성 파라미터 값은 사용자 간 음색(timbre)의 차이에 따른 전자 장치의 인증 성능의 편차를 제거하기 위해 임계치에 적용되는 파라미터 값을 의미한다. 예를 들어, 복수의 사용자로부터 입력받은 오디오 신호에 기초하여 획득되는 보편적인 음성에 대한 통계 모델인 배경 화자 모델(Universal Background Model, UBM)과 비교할 때, 제1 사용자의 사용자 특징 벡터 및 배경 화자 모델로부터 획득되는 평균 사용자 특징 벡터 간 유사도는, 제2 사용자의 사용자 특징 벡터 및 배경 화자 모델로 부터 획득되는 평균 사용자 특징 벡터 간 유사도보다 상대적으로 낮을 수 있다. 즉, 사용자 간 음색의 차이로 인해, 제1 사용자 및 제2 사용자에 대한 전자 장치의 인증 성능은 서로 달라질 수 있다. 이와 같은 인증 성능의 편차를 제거하기 위해, 전자 장치는 사용자 등록 과정에서 특정 사용자에 대하여 획득된 사용자 특징 벡터와 배경 화자 모델로부터 획득된 평균 사용자 특징 벡터 간 유사도를 획득하고, 획득된 유사도에 기초하여 해당 사용자에 대한 사용자 특성 파라미터 값을 설정할 수 있다. 전자 장치는 설정된 사용자 특성 파라미터 값을 사용하여 해당 사용자의 인증에 사용되는 임계치를 조정할 수 있다. 전자 장치 는, 예를 들어, 설정된 사용자 특성 파라미터 값을 해당 사용자에 대한 사용자 DB에 저장할 수 있다. 한편, 다른 일부 실시예에서, 사용자 특성 파라미터 값의 설정 및 설정된 사용자 특성 파라미터 값에 기초한 임계치의 조정은 서버에 의해 수행될 수 있다. 사용자 특성 파라미터 값의 설정 및 설정된 사용자 특성 파라미터 값에 기초한 임계치의 조정이 서버에 의해 수행되는 구체적인 예는 도 22 및 도 23의 실시예를 통해 후술한다. 한편, 전자 장치는 복수의 사용자에 대한 전자 장치의 사용자 간 인증 성능의 편차를 제거하기 위 해, 등록 사용자 특징 벡터 및 사용자 특징 벡터 간 유사도에 대한 정규화(normalize)를 수행할 수 있다. 전자 장치에 등록된 제1 사용자는, 예를 들어, 제1 사용자의 사용자 DB로부터 획득된 등록 사용자 특징 벡터 및 제1 사용자의 발화 입력에 대응되는 입력 오디오 신호로부터 획득된 사용자 특징 벡터 간 유사도 의 평균이 제2 사용자에 비해 상대적으로 낮을 수 있다. 전자 장치는 제1 사용자에 대해 획득되는 사용자 특징 벡터 간 유사도 평균 및 제2 사용자에 대해 획득되는 사용자 특징 벡터 간 유사도 평균 사이의 편차를 제 거하기 위하여 사용자 특징 벡터 간 유사도에 대한 정규화를 수행할 수 있다. 예를 들어, A 사용자의 사용자 등록 이후, A 사용자가 발화 입력을 3번 수행하는 동안, 전자 장치는 A 사 용자 DB로부터 등록 사용자 특징 벡터를 획득하고, A 사용자의 발화 입력에 대응되는 3개의 입력 오디오 신호 각각으로부터 사용자 특징 벡터를 획득할 수 있다. 전자 장치는 A 사용자 DB로부터 획득된 등록 사용자 특징 벡터 및 3개의 입력 오디오 신호로부터 획득된 사용자 특징 벡터 간 유사도를 획득할 수 있다. 예를 들어, A 사용자 DB로부터 획득된 등록 사용자 특징 벡터및 3개의 입력 오디오 신호로부터 획득된 사용자 특징 벡터 간 유사도는 각각 0.20, 0.30 및 0.25의 스칼라값을 가질 수 있다. 전자 장치는, 예를 들어, 사용자 특징 벡터 간 유사도인 0.20, 0.30 및 0.25의 평균을 계산하여 획득된 0.25의 스칼라 값을, A 사용자 DB로부터 획득된 등록 사용자 특징 벡터 및 A 사용자의 새로운 입력 오디오 신호 로부터 획득되는 사용자 특징 벡터 간 유사도에 대하여 정규화를 수행하기 위한 평균 유사도로 설정할 수 있다. A 사용자의 발화에 기초하여 새로운 입력 오디오 신호가 획득되고, 새로운 입력 오디오 신호로부터 획득된 사용 자 특징 벡터 및 A 사용자 DB로부터 획득된 등록 사용자 특징 벡터간 유사도가 0.32의 스칼라값일 경우, 전자 장치는 0.32를 A 사용자의 평균 유사도 0.25로 나누어 0.0128의 스칼라 값으로 정규화할 수 있다. 한편, 다른 예로, B 사용자의 사용자 등록 이후, B 사용자가 발화 입력을 3번 수행하는 동안, 전자 장치 는 B 사용자 DB로부터 등록 사용자 특징 벡터를 획득하고, B 사용자의 발화 입력에 대응되는 3개의 입력 오디오 신호 각각으로부터 사용자 특징 벡터를 획득할 수 있다. 전자 장치는 B 사용자 DB로부터 획득된 등록 사용자 특징 벡터 및 3개의 입력 오디오 신호로부터 획득된 사용자 특징 벡터 간 유사도를 획득할 수 있다. 예를 들어, B 사용자 DB로부터 획득된 등록 사용자 특징 벡터 및 3개의 입력 오디오 신호로부터 획득된 사용자 특징 벡터 간 유사도는 각각 0.10, 0.20 및 0.15의 스칼라값을 가질 수 있다 전자 장치는, 예를 들어, 사용자 특징 벡터 간 유사도인 0.10, 0.20 및 0.15의 평균을 계산하여 획득된 0.15의 스칼라 값을, B 사용자 DB로부터 획득된 등록 사용자 특징 벡터 및 B 사용자의 새로운 입력 오디오 신호 로부터 획득되는 사용자 특징 벡터 간 유사도에 대하여 정규화를 수행하기 위한 평균 유사도로 설정할 수 있다. B 사용자의 발화에 기초하여 새로운 입력 오디오 신호가 획득되고, 새로운 입력 오디오 신호로부터 획득된 사용 자 특징 벡터 및 B 사용자 DB로부터 획득된 등록 사용자 특징 벡터에 대한 유사도가 0.22의 스칼라값일 경우, 전자 장치는 0.22를 B 사용자의 평균 유사도 0.15로 나누어 0.0147의 스칼라 값으로 정규화할 수 있다. 한편, 전자 장치는 장치 간 오디오 신호 처리 성능 차이에 따른 사용자 인증 성능의 편차를 제거하기 위 한 장치 특성 파라미터 값을 사용할 수 있다. 장치 특성 파라미터 값은 장치 간 하드웨어 특성의 차이에 따른 전자 장치의 인증 성능의 편차를 제거하기 위해 임계치에 적용되는 파라미터 값을 의미한다. 예를 들어, 서로 다른 종류의 전자 장치 간 오디오 신호 처리 성능은 각 전자 장치의 하드웨어 특 성에 따라 서로 상이할 수 있다. 전자 장치의 오디오 신호 처리 성능은, 예를 들어, 전자 장치에 포함된 마이크의 개수, 감도 및 해상도 등에 따라 달라질 수 있다. 전자 장치는 전자 장치의 종류에 따라 오디오 신호 처리 성능이 달라질 수 있음을 고려하여, 장치 간 오디오 신호 처리 성능 차이에 따른 사용자 인증 성능의 편차를 제거하기 위한 장치 특성 파라미터 값을 사 용할 수 있다. 한편, 다른 일부 실시예에서, 도 12의 발화 구간의 오디오 신호의 획득 내지 발화 구간의 평균 에너지 및 등록 발화 구간의 평균 에너지 간 에너지 비율에 기초한 임계치의 조정 중 적어도 하나는 서버에 의해 수행될 수 있다. 도 13은 일부 실시예에 따른 복수의 전자 장치가 사용되는 환경을 나타내는 도면이다. 도 13의 (a)를 참조하면, 일부 실시예에 따른 전자 장치는 스마트폰(1000A)일 수 있다. 스마트폰(1000A)은, 예를 들어, 사용자 등록 단계에서, 사용자의 발화 입력에 기초하여 획득한 등록 오디오 신호로부터 등록 발화 구간의 입력 오디오 신호를 획득할 수 있다. 스마트폰(1000A)은 등록 발화 구 간의 입력 오디오 신호로부터 사용자 등록 사용자 특징 벡터를 획득하고, 획득된 등록 사용자 특징 벡터를 사용자 DB에 저장할 수 있다. 스마트폰(1000A)은, 예를 들어, 사용자 등록 단계에서 사용자 DB를 생성함과 동시에, 사용자 DB가 생성된 전자 장치의 종류가 스마트폰(1000A)임을 나타내는 전자 장치 ID 정보를 사용자 DB에 저장 할 수 있다. 스마트폰(1000A)은, 예를 들어, 사용자 DB를 스마트폰(1000A)의 메모리에 저장할 수 있다. 한편, 도 13의 (b)를 참조하면, 일부 실시예에 따른 전자 장치는 인공지능 스피커(1000B)일 수 있다. 인공지능 스피커(1000B)는, 예를 들어, 스마트폰(1000A)으로부터 사용자 DB를 전달받을 수 있다. 인공지 능 스피커(1000B)는 스마트폰(1000A)으로부터 전달받은 사용자 DB를 인공지능 스피커(1000B)의 메모리에 저장할 수 있다. 사용자가 인공지능 스피커(1000B)에 대한 발화 입력을 수행하면, 인공지능 스피커(1000B)는 사용자의 발화 입력에 기초하여 입력 오디오 신호를 획득할 수 있다. 입력 오디오 신호가 획득되면, 인공지능 스피커(1000B)는 입력 오디오 신호로부터 발화 구간의 오디 오 신호를 획득하고, 발화 구간의 오디오 신호로부터 사용자 특징 벡터를 획득할 수 있다. 입력 오디오 신호가 획득되면, 인공지능 스피커(1000B)는 사용자 DB로부터 등록 사용자 특징 벡터 를 획득할 수 있다. 인공지능 스피커(1000B)는 사용자 특징 벡터 및 등록 사용자 특징 벡터 간 유사도를 획득하 고, 획득된 유사도를 임계치와 비교하여, 사용자 인증을 수행할 수 있다. 이와 같이 사용자가 복수의 전자 장치를 사용할 경우, 각 전자 장치는 다른 전자 장치로 부터 전달받은 사용자 DB에 기초하여 사용자 인증을 수행할 수 있으므로, 사용자는 어느 하나의 전자 장치 에 대한 최초 사용자 등록을 통해 모든 전자 장치에 대한 등록을 수행한 것과 동일한 결과를 얻을 수 있다. 한편, 다른 일부 실시예에서, 도 13의 사용자에 대한 사용자 등록 및 사용자 인증은 서버에 의해 수 행될 수 있다. 서버는, 예를 들어, 사용자 등록 단계에서, 스마트폰(1000A)으로부터 등록 오디오 신호를 수신하고, 수신한 등록 오디오 신호로부터 등록 발화 구간의 입력 오디오 신호를 획득할 수 있다. 서버 는 등록 발화 구간의 입력 오디오 신호로부터 사용자 등록 사용자 특징 벡터를 획득하고, 획득된 등록 사용자 특징 벡터를 사용자 DB에 저장할 수 있다. 서버는, 예를 들어, 사용자 등록 단계에서 사용자 DB를 생성함과 동시에, 사용자 DB가 생성 된 전자 장치의 종류가 스마트폰(1000A)임을 나타내는 전자 장치 ID 정보를 사용자 DB에 저장할 수 있다. 서버는, 예를 들어, 사용자 DB를 서버의 메모리에 저장할 수 있다. 사용자가 인공지능 스피커(1000B)에 대한 발화 입력을 수행하면, 서버는, 예를 들어, 인공지능 스피 커(1000B)로부터 입력 오디오 신호를 수신할 수 있다. 입력 오디오 신호가 획득되면, 서버는 입력 오디오 신호로부터 발화 구간의 오디오 신호를 획득하고, 발화 구간의 오디오 신호로부 터 사용자 특징 벡터를 획득할 수 있다. 입력 오디오 신호가 획득되면, 서버는 사용자 DB로부터 등록 사용자 특징 벡터를 획득 할 수 있다. 서버는 사용자 특징 벡터 및 등록 사용자 특징 벡터 간 유사도를 획득하고, 획득된 유 사도를 임계치와 비교하여, 사용자 인증을 수행할 수 있다. 이와 같이 사용자가 복수의 전자 장치를 사용할 경우, 서버는 동일한 사용자 DB에 기초하여 사 용자 인증을 수행할 수 있으므로, 사용자는 어느 하나의 전자 장치에 대한 최초 사용자 등록을 통해 모든 전자 장치에 대한 등록을 수행한 것과 동일한 결과를 얻을 수 있다. 한편, 스마트폰(1000A) 및 인공지능 스피커(1000B)는, 예를 들어, 서로 다른 종류의 전자 장치로서, 각 장치에 포함된 마이크의 개수, 감도 및 해상도 등이 서로 상이할 수 있다. 즉, 스마트폰(1000A) 및 인공지능 스 피커(1000B)의 오디오 신호 처리 성능은 서로 상이할 수 있다. 본 개시의 일부 실시예에 따른 사용자 인증 방법을 사용하는 전자 장치 및/또는 서버는, 전자 장치 간 오디오 신호 처리 성능 차이에 따른 사용자 인증 성능의 편차를 제거하기 위한 장치 특성 파라미터 값을 사용할 수 있다. 도 14는 일부 실시예에 따른 장치 특성 파라미터 값에 기초하여 조정된 임계치를 사용하여 사용자를 인증하는 방법을 나타낸 흐름도이다. 장치 특성 파라미터 값은, 예를 들어, 복수의 서로 다른 종류의 전자 장치 간에 설정될 수 있다. 인공지능 스피커(1000B)가 사용할 수 있는 장치 특성 파라미터 값은, 예를 들어, 스마트폰(1000A) 및 인공지능 스피커(1000B)의 오디오 신호 처리 성능 차이의 측정을 통해, 사용자의 등록 단계 이전에 미리 설정될 수 있다. 스마트폰(1000A)은, 예를 들어, 사용자의 제1 발화 입력에 기초하여 제1 오디오 신호를 획득할 수 있다. 스마트 폰(1000A)은 제1 오디오 신호로부터 사용자 특징 벡터를 획득할 수 있다. 스마트폰(1000A)은 제1 오디오 신호로 부터 획득된 사용자 특징 벡터 및 기준 사용자 특징 벡터 간 유사도를 획득할 수 있다. 예를 들어, 스마트폰 (1000A)이 획득한 사용자 특징 벡터 간 유사도는 0.99의 스칼라 값을 가질 수 있다. 한편, 인공지능 스피커(1000B)는, 예를 들어, 사용자의 제1 발화 입력에 기초하여 제2 오디오 신호를 획득할 수 있다. 인공지능 스피커(1000B)는 제2 오디오 신호로부터 사용자 특징 벡터를 획득할 수 있다. 인공지능 스피커 (1000B)는 제2 오디오 신호로부터 획득된 사용자 특징 벡터 및 기준 사용자 특징 벡터 간 유사도를 획득할 수 있다. 예를 들어, 인공지능 스피커(1000B)가 획득한 사용자 특징 벡터 간 유사도는 0.5의 스칼라 값을 가질 수 있다. 장치 특성 파라미터 값은, 예를 들어, 사용자의 동일한 제1 발화 입력에 대하여, 스마트폰(1000A)이 획득한 사 용자 특징 벡터 간 유사도 0.99 및 인공지능 스피커(1000B)가 획득한 사용자 특징 벡터 간 유사도 0.5의 편차인 0.49 스칼라 값에 기초하여 설정될 수 있다. 한편, 스마트폰(1000A)은, 예를 들어, 사용자가 발화 입력을 수행하지 않는 환경에서 제3 오디오 신호를 획득할 수 있다. 스마트폰(1000A)은 제3 오디오 신호로부터 환경 특징 벡터를 획득할 수 있다. 스마트폰(1000A)은 제3 오디오 신호로부터 획득된 환경 특징 벡터 및 기준 환경 특징 벡터 간 유사도를 획득할 수 있다. 예를 들어, 스 마트폰(1000A)이 획득한 환경 특징 벡터 간 유사도는 0.98의 스칼라 값을 가질 수 있다. 한편, 인공지능 스피커(1000B)는, 예를 들어, 사용자가 발화 입력을 수행하지 않는 환경에서 제4 오디오 신호를 획득할 수 있다. 인공지능 스피커(1000B)는 제4 오디오 신호로부터 환경 특징 벡터를 획득할 수 있다. 인공지능 스피커(1000B)는 제4 오디오 신호로부터 획득된 환경 특징 벡터 및 기준 환경 특징 벡터 간 유사도를 획득할 수 있다. 예를 들어, 인공지능 스피커(1000B)가 획득한 환경 특징 벡터 간 유사도는 0.5의 스칼라 값을 가질 수 있 다. 장치 특성 파라미터 값은, 예를 들어, 사용자가 발화 입력을 수행하지 않는 동일한 환경에 대하여, 스마트폰 (1000A)이 획득한 환경 특징 벡터 간 유사도 0.98 및 인공지능 스피커(1000B)가 획득한 환경 특징 벡터 간 유사 도 0.5의 편차인 0.48 스칼라 값에 기초하여 설정될 수 있다. 장치 특성 파라미터 값은, 다른 예로, 사용자가 발화 입력을 수행하지 않는 동일한 환경에 대하여, 스마트폰 (1000A)이 획득한 환경 특징 벡터 및 인공지능 스피커(1000B)가 획득한 환경 특징 벡터 간 유사도에 기초하여 설정될 수도 있다. 인공지능 스피커(1000B)가 사용할 수 있는 장치 특성 파라미터 값은, 다른 예로, 사용자의 등록 단계 이후 에 스마트폰(1000A) 및 인공지능 스피커(1000B)의 오디오 신호 처리 성능 차이의 측정을 통해 설정 또는 업데이 트 될 수 있다. 이때 장치 특성 파라미터 값의 설정 또는 업데이트에 사용되는 기준 사용자 특징 벡터 및 기준 환경 특징 벡터는, 사용자 등록 단계에서 스마트폰(1000A)이 획득한 등록 사용자 특징 벡터 및 등록 환경 특징 벡터일 수 있다. 도 14를 참조하면, S1401 단계에서, 입력 오디오 신호를 획득한 인공지능 스피커(1000B)는 스마트폰 (1000A)으로부터 등록 사용자 특징 벡터를 수신할 수 있다. 인공지능 스피커(1000B)는, 예를 들어, 스마트폰(1000A)으로부터 사용자 DB를 전달받을 수 있다. 인공지 능 스피커(1000B)는 스마트폰(1000A)으로부터 전달받은 사용자 DB로부터 등록 사용자 특징 벡터를 획득할 수 있다. 입력 오디오 신호가 획득되면, 인공지능 스피커(1000B)는 입력 오디오 신호로부터 발화 구간의 오디 오 신호를 획득하고, 발화 구간의 오디오 신호로부터 사용자 특징 벡터를 추출할 수 있다. S1402 단계에서, 인공지능 스피커(1000B)는 등록 사용자 특징 벡터 및 입력 오디오 신호로부터 추출된 사 용자 특징 벡터 간 유사도를 획득할 수 있다. S1403 단계에서, 인공지능 스피커(1000B)는 인공지능 스피커(1000B)의 장치 특성 파라미터 값에 기초하여, 사용 자 인증에 사용되는 임계치를 조정할 수 있다. 인공지능 스피커(1000B)는, 예를 들어, 스마트폰(1000A)으로부터전달받은 사용자 DB에 포함된 전자 장치 ID 정보에 기초하여, 사용자 DB가 생성된 전자 장치(100 0)의 종류가 스마트폰(1000A)임을 확인할 수 있다. 사용자 DB가 생성된 전자 장치의 종류가 스마트폰(1000A)임을 확인한 인공지능 스피커(1000B)는, 예를 들어, 스마트폰(1000A) 및 인공지능 스피커(1000B)의 사용자 인증 성능 차이에 대응하여 미리 설정된 장치 특성 파라미터 값에 기초하여, 사용자 인증에 사용되는 임계치를 조정할 수 있다. 한편, 전자 장치는, 동일한 종류의 전자 장치 간에도 개체 별로 오디오 신호 처리 성능에 차이가 있을 수 있음을 고려하여, 동일한 종류의 전자 장치 간 사용자 인증 성능의 편차를 제거하기 위해 장치 특성 파라미터 값을 사용할 수도 있다. 동일한 종류의 전자 장치 간 사용자 인증 성능의 편차를 제거하기 위해 장치 특성 파라미터 값은, 전술한 서로 다른 종류의 전자 장치 간 사용자 인증 성능의 편차를 제거하기 위해 장치 특성 파라미터 값의 설정 방법과 동일한 방법을 통해 설정될 수 있다. 전자 장치는, 예를 들어, 다음의 수식에 따라 임계치를 조정할 수 있다. 수학식 5"}
{"patent_id": "10-2019-0094532", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "상기 [수학식 5]에서, Er은 에너지 비율을, we는 에너지 비율의 가중 계수를, Sr은 환경 특징 벡터의 유사도를, ws는 환경 특징 벡터 유사도의 가중 계수를, THbase는 임계치 테이블에서 선택된 어느 하나의 임계치를, THbias는 장치 특성 파라미터 값을, THspk_bias는 사용자 특성 파라미터 값을, THfinal은 조정된 임계치를 의미한다. 한편, 다른 일부 실시예에서, 장치 특성 파라미터 값의 설정 및 설정된 장치 특성 파라미터 값에 기초한 임계치 의 조정은 서버에 의해 수행될 수 있다. 장치 특성 파라미터 값의 설정 및 설정된 장치 특성 파라미터 값 에 기초한 임계치의 조정이 서버에 의해 수행되는 구체적인 예는 도 22 및 도 23의 실시예를 통해 후술한 다. 도 15는 일부 실시예에 따른 사용자 등록 단계에서 사용되는 사용자 인터페이스를 나타낸 도면이다. 도 15를 참조하면, 일부 실시예에 따른 전자 장치는, 사용자 등록 단계에서 제1 환경의 A 사용자의 발화 입력에 기초하여 등록 오디오 신호를 획득할 수 있다. 전자 장치는 등록 오디오 신호로부터 등록 발화 구간의 오디오 신호를 획득할 수 있다. 전자 장치는 획득된 등록 발화 구간의 오디오 신호로부터 등록 A 사용자 특징 벡터를 획득할 수 있다. 한편, 전자 장치는 등록 오디오 신호로부터 등록 비 발화 구간의 오디오 신호를 획득할 수 있다. 전자 장치는 획득된 등록 비 발화 구간의 오디오 신호로부터 등록 환경 특징 벡터를 획득할 수 있다. 전자 장치는 등록 발화 구간의 오디오 신호로부터 획득된 등록 A 사용자 특징 벡터 및 등록 비 발화 구간의 오디오 신호로부터 획득된 등록 환경 특징 벡터에 기초하여 A 사용자 DB를 생성할 수 있다. 전자 장치는, 예를 들어, A 사용자 DB를 생성하는 과정에서 전자 장치의 디스플레이에 사용 자 등록 단계에 관한 인터페이스를 표시할 수 있다. 전자 장치는, 예를 들어, 제1 환경의 A 사용자로부터 등록 오디오 신호에 대응되는 발화 입 력을 수신함에 따라, A 사용자 DB의 생성에 필요한 등록 발화 구간의 오디오 신호가 정상적으로 획 득되고 있음을 인터페이스를 통해 나타낼 수 있다.전자 장치는, 다른 예로, 제1 환경의 A 사용자로부터 등록 오디오 신호에 대응되는 발화 입 력을 수신함에 따라, A 사용자 DB의 생성에 필요한 등록 A 사용자 특징 벡터가 정상적으로 획득되 고 있음을 사용자 인터페이스를 통해 나타낼 수 있다. 전자 장치는, 예를 들어, 제1 환경의 A 사용자로부터 등록 오디오 신호에 대응되는 발화 입 력을 여러 번 수신하는 동안, 등록 A 사용자 특징 벡터의 정상적인 획득 횟수를 나타내는 메시지 또는 게 이지 중 적어도 하나를 사용자 인터페이스를 통해 단계적으로 표시할 수 있다(1561, 1581). 한편, 전자 장치는, 예를 들어, 제1 환경의 A 사용자로부터 등록 오디오 신호에 대응되는 발 화 입력을 수신함에 따라, A 사용자 DB의 생성에 필요한 등록 비 발화 구간의 오디오 신호가 정상 적으로 획득되고 있음을 나타낼 수 있다. 전자 장치는, 다른 예로, 제1 환경의 A 사용자로부터 등록 오디오 신호에 대응되는 발화 입 력을 수신함에 따라, A 사용자 DB의 생성에 필요한 등록 환경 특징 벡터가 정상적으로 획득되고 있 음을 사용자 인터페이스를 통해 나타낼 수 있다. 전자 장치는, 예를 들어, 제1 환경의 A 사용자로부터 등록 오디오 신호에 대응되는 발화 입 력을 여러 번 수신하는 동안, 등록 환경 특징 벡터의 정상적인 획득 횟수를 나타내는 메시지 또는 게이지 중 적어도 하나를 사용자 인터페이스를 통해 단계적으로 표시할 수 있다(1362, 1382). 도 16은 일부 실시예에 따른 사용자 인증 과정에서 사용되는 사용자 인터페이스를 나타낸 도면이다. 도 16을 참조하면, 일부 실시예에 따른 전자 장치는 사용자 인증 단계에서 제2 환경의 A 사용자의 발화 입력에 기초하여 입력 오디오 신호를 획득할 수 있다. 전자 장치는 입력 오디오 신호로부터 발화 구간의 오디오 신호를 획득할 수 있다. 전자 장치 는 획득된 발화 구간의 오디오 신호로부터 A 사용자 특징 벡터를 추출할 수 있다. 입력 오디오 신호가 획득되면, 전자 장치는 사용자 등록 단계에서 미리 생성된 A 사용자 DB 로부터 등록 A 사용자 특징 벡터를 획득할 수 있다. 전자 장치는 발화 구간의 오디오 신호로부터 추출된 A 사용자 특징 벡터 및 A 사용자 DB로부터 획득된 등록 A 사용자 특징 벡터 간 유사도를 획득하여 A 사용자에 대한 인증을 수행할 수 있다. 전자 장치는, 예를 들어, A 사용자에 대한 인증을 수행하는 과정에서 전자 장치의 디스플레 이에 사용자 인증 과정에 관한 인터페이스를 표시할 수 있다. 전자 장치는, 예를 들어, A 사용자에 대한 인증 결과를 인터페이스를 통해 나타낼 수 있다(1661, 1681). 한편, 전자 장치는 입력 오디오 신호로부터 비 발화 구간의 오디오 신호를 획득할 수 있다. 전자 장치는 획득된 비 발화 구간의 오디오 신호로부터 환경 특징 벡터를 추출할 수 있다. 입력 오디오 신호가 획득되면, 전자 장치는 사용자 등록 단계에서 미리 생성된 A 사용자 DB 로부터 등록 환경 특징 벡터를 획득할 수 있다. 전자 장치는 비 발화 구간의 오디오 신호로부터 추출된 환경 특징 벡터 및 A 사용자 DB로부터 획득된 등록 환경 특징 벡터 간 유사도를 획득하여, 제1 환경 및 제2 환경의 유사 정도를 판단할 수 있다. 전자 장치는, 예를 들어, 제1 환경 및 제2 환경의 유사 정도에 대한 판단 결과를 인터페이스를 통해 나타 낼 수 있다. 전자 장치는, 예를 들어, 환경 특징 벡터 및 등록 환경 특징 벡터 간 유사 정도를 레벨 단위 로 표시할 수 있다(1662, 1682). 전자 장치는, 예를 들어, 환경 특징 벡터 및 등록 환경 특징 벡터 간 유사 정도를, 유사 정도가 가장 낮은 레벨 1 내지 유사 정도가 가장 높은 레벨 5 사이의 레벨 중 어 느 하나의 레벨로 표시할 수 있다. 전자 장치는, 예를 들어, 환경 특징 벡터와 등록 환경 특징 벡터의 유사 정도에 기초하여 A 사용자에게 입력 오디오 신호의 재입력을 요청하는 메시지를 사용자 인터페이스에 표시할 수 있다.예를 들어, 환경 특징 벡터 및 등록 환경 특징 벡터의 비교 결과, 전자 장치는 환경 특징 벡 터와 등록 환경 특징 벡터의 유사 정도가 소정의 기준 레벨보다 낮다고 판단할 수 있다. 전자 장치는, 판단 결과에 기초하여, '다른 장소에서 다시 말씀해주세요.'와 같이 A 사용자에게 제 2 환경 이외의 환경에서 발화 입력을 재 수행하도록 요청하는 메시지를 사용자 인터페이스에 표시할 수 있다 . 도 17은 일부 실시예에 따른 복수의 사용자에 대한 사용자 등록 단계를 나타낸 도면이다. 도 17을 참조하면, 일부 실시예에 따른 전자 장치는 사용자 등록 과정에서 제1 환경의 A 사용자의 발화 입력에 기초하여 등록 오디오 신호를 획득할 수 있다. 전자 장치는 등록 오디오 신호로부터 등록 발화 구간의 오디오 신호를 획득할 수 있다. 전자 장치는 획득된 등록 발화 구간의 오디오 신호로부터 등록 A 사용자 특징 벡터를 추출할 수 있다. 한편, 전자 장치는 등록 오디오 신호로부터 등록 비 발화 구간의 오디오 신호를 획득할 수 있다. 전자 장치는 획득된 등록 비 발화 구간의 오디오 신호로부터 등록 환경 특징 벡터를 획득할 수 있다. 전자 장치는 등록 발화 구간의 오디오 신호로부터 획득된 등록 A 사용자 특징 벡터 및 등록 비 발화 구간의 오디오 신호로부터 획득된 등록 환경 특징 벡터에 기초하여 A 사용자 DB를 생성할 수 있다. 전자 장치는, 예를 들어, 제1 환경의 A 사용자로부터 등록 오디오 신호에 대응되는 발화 입 력을 수신함에 따라, 등록 A 사용자 특징 벡터 및 등록 환경 특징 벡터가 정상적으로 획득되고 있 음을 인터페이스를 통해 나타낼 수 있다. 예를 들어, 제1 환경의 A 사용자로부터 등록 오디오 신호에 대응되는 발화 입력을 5번 수신한 전자 장치는, 등록 A 사용자 특징 벡터 및 등록 환경 특징 벡터의 획득 횟수를 나타내는 게이지와 등록 완료를 나타내는 메시지 중 적어도 하나를 사용자 인터페이스를 통해 표시할 수 있다(1761, 1762). 다시 도 17을 참조하면, 일부 실시예에 따른 전자 장치는 사용자 등록 과정에서 제2 환경의 B 사용자 의 발화 입력에 기초하여 등록 오디오 신호를 획득할 수 있다. 전자 장치는 등록 오디오 신호로부터 등록 발화 구간의 오디오 신호를 획득할 수 있다. 전자 장치는 획득된 등록 발화 구간의 오디오 신호로부터 등록 B 사용자 특징 벡터를 추출할 수 있다. 한편, 전자 장치는 등록 오디오 신호로부터 등록 비 발화 구간의 오디오 신호를 획득할 수 있다. 전자 장치는 획득된 등록 비 발화 구간의 오디오 신호로부터 등록 환경 특징 벡터를 획득할 수 있다. 전자 장치는 등록 발화 구간의 오디오 신호로부터 획득된 등록 B 사용자 특징 벡터 및 등록 비 발화 구간의 오디오 신호로부터 획득된 등록 환경 특징 벡터에 기초하여 B 사용자 DB를 생성할 수 있다. 전자 장치는, 예를 들어, 제2 환경의 B 사용자로부터 등록 오디오 신호에 대응되는 발화 입 력을 수신함에 따라, 등록 B 사용자 특징 벡터 및 등록 환경 특징 벡터가 정상적으로 획득되고 있 음을 인터페이스를 통해 나타낼 수 있다. 예를 들어, 제2 환경의 B 사용자로부터 등록 오디오 신호에 대응되는 발화 입력을 5번 수신한 전자 장치는, 등록 B 사용자 특징 벡터 및 등록 환경 특징 벡터의 획득 횟수를 나타내는 게이지와 등록 완료를 나타내는 메시지 중 적어도 하나를 사용자 인터페이스를 통해 표시할 수 있다(1781, 1782). 도 15 내지 도 17는 전자 장치가 사용자 특징 벡터 및 환경 특징 벡터의 획득에 관한 정보를 메시지 및 게이지 등을 통해 인터페이스에 표시하는 실시예에 대해 나타내고 있으나, 사용자 특징 벡터 및 환경 특징 벡터 의 획득에 관한 정보는 메시지 및 게이지 이외에, 기호, 문장, 색상 및 음성 등의 정보 전달 수단에 의해 전달 될 수도 있으며, 이에 제한되지 않는다.도 18은 부 실시예에 따른 복수의 사용자의 대화에 기초한 사용자 인증 과정을 나타낸 도면이다. 도 17 및 도 18을 참조하면, 일부 실시예에 따른 전자 장치는, A 사용자 및 B 사용자 각각에 대한 사용자 등록이 이루어진 제1 환경 및 제2 환경이 아닌, 제3 환경에서 이루어지는 A 사용자 및 B 사 용자의 대화에 의한 발화 입력에 기초하여 사용자 인증을 수행할 수 있다. 즉, 일부 실시예에서, 전자 장치가 A 사용자 및 B 사용자로부터 발화 입력을 수신한 제1 환 경 및 제2 환경은 서로 다른 환경일 수 있고, 전자 장치가 A 사용자 및 B 사용자의 대화에 의한 발화 입력을 수신하는 제3 환경 또한 제1 환경 및 제2 환경과 서로 다른 환경일 수 있다. 전자 장치는, 예를 들어, A 사용자 및 B 사용자의 대화에 의한 발화 입력에 기초하여 획득한 입력 오디오 신호로부터 A, B 대화 발화 구간의 오디오 신호 및 A, B 대화 비 발화 구간의 오디오 신호를 구별하여 획득할 수 있다. A, B 대화 발화 구간의 오디오 신호는, 예를 들어, A 사용자 의 발화에 의한 오디오 신호 및 B 사용자의 발화에 의한 오디오 신호 중 적어도 하나를 포함할 수 있다. 전자 장치는 A, B 대화 발화 구간의 오디오 신호로부터 오디오 특징을 추출하고, 추출된 오디오 특 징으로부터 사용자 특징 벡터를 획득할 수 있다. 전자 장치는 A, B 대화 발화 구간의 오디오 신호에 대해 획득된 사용자 특징 벡터를 A 사용 자 DB로부터 획득된 등록 A 사용자 특징 벡터 및 B 사용자 DB로부터 획득된 등록 B 사용자 특징 벡터와 각각 비교하여 유사도를 계산할 수 있다. 전자 장치는, 예를 들어, A, B 대화 발화 구간의 오디오 신호에 포함된 소정의 프레임 단위의 오디 오 신호로부터 사용자 특징 벡터를 획득할 수 있다. 전자 장치는 획득된 사용자 특징 벡터를 등록 A 사용자 특징 벡터 및 등록 B 사용자 특징 벡터와 각각 비교하여, 등록 A 사용자 특징 벡터 와의 유사도 및 등록 B 사용자 특징 벡터와의 유사도를 획득할 수 있다. 전자 장치는, 다른 예로, A, B 대화 발화 구간의 오디오 신호에 포함된 발화(utterance) 단위의 오 디오 신호로부터 사용자 특징 벡터를 획득할 수 있다. 전자 장치는 획득된 사용자 특징 벡터(185 1)를 등록 A 사용자 특징 벡터 및 등록 B 사용자 특징 벡터와 각각 비교하여, 등록 A 사용자 특징 벡터와의 유사도 및 등록 B 사용자 특징 벡터와의 유사도를 획득할 수 있다. 한편, 전자 장치는 A, B 대화 비 발화 구간의 오디오 신호로부터 오디오 특징을 추출하고, 추출된 오디오 특징으로부터 환경 특징 벡터를 획득할 수 있다. 전자 장치는, 예를 들어, A, B 대화 비 발화 구간의 오디오 신호에 대해 획득된 환경 특징 벡터 및 A 사용자 DB로부터 획득된 A 사용자의 등록 환경 특징 벡터를 비교하여 유사도를 획득할 수 있다. 전자 장치는 환경 특징 벡터 및 A 사용자의 등록 환경 특징 벡터의 유사도에 기초하여, 임계 치 테이블로부터 선택된 어느 하나의 임계치를 조정하여 A 사용자에 대하여 조정된 임계치를 획득 할 수 있다. 한편, 전자 장치는, 예를 들어, A, B 대화 비 발화 구간의 오디오 신호에 대해 획득된 환경 특징 벡터 및 B 사용자 모델로부터 획득된 B 사용자의 등록 환경 특징 벡터를 비교하여 유사도를 획득할 수 있다. 전자 장치는 환경 특징 벡터 및 B 사용자의 등록 환경 특징 벡터의 유사도에 기초하여, 임계 치 테이블로부터 선택된 어느 하나의 임계치를 조정하여 B 사용자에 대하여 조정된 임계치를 획득 할 수 있다. 전자 장치는 등록 A 사용자 특징 벡터와의 유사도 및 등록 B 사용자 특징 벡터와의 유사도를 각 사용자에 대하여 조정된 임계치와 비교하여 사용자 인증을 수행할 수 있다. 전자 장치는, 예를 들어, 획득된 등록 A 사용자 특징 벡터와의 유사도 및 등록 B 사용자 특징 벡터 와의 유사도를 비교하여 사용자 식별을 수행할 수 있다. 즉, 전자 장치는 사용자 특징 벡터 에 대응되는 오디오 신호가 A 사용자 및 B 사용자 중 어느 사용자의 발화 입력에 대응되는지 판단할 수 있다.전자 장치는, 예를 들어, 사용자 식별 결과에 기초하여, A 사용자 및 B 사용자에 대한 사용자 인증을 수 행할 수 있다. 전자 장치는, 예를 들어, 사용자 특징 벡터에 대응되는 오디오 신호가 A 사용자의 발화 입력에 대 응되는 것으로 판단될 경우, 사용자 특징 벡터에 대한 등록 A 사용자 특징 벡터와의 유사도 및 A 사용자에 대하여 조정된 임계치를 비교하여 A 사용자에 대한 인증을 수행할 수 있다. 전자 장치는, 예를 들어, 사용자 특징 벡터에 대응되는 오디오 신호가 B 사용자의 발화 입력에 대 응되는 것으로 판단될 경우, 사용자 특징 벡터에 대한 등록 B 사용자 특징 벡터와의 유사도 및 B 사용자에 대하여 조정된 임계치를 비교하여 B 사용자에 대한 인증을 수행할 수 있다. 이처럼 본 개시의 일부 실시예에 따른 사용자 인증 방법을 사용하는 전자 장치 및/또는 서버는, 오 디오 신호를 입력하는 복수의 사용자에 대하여, 각 사용자의 등록 환경에 대응되는 환경 특징 벡터에 기초하여 각 사용자에 대한 인증에 사용되는 임계치를 개별적으로 조정함으로써, 각 사용자의 사용자 등록 환경의 차이에 따른 사용자 인증 성능의 저하를 방지할 수 있다. 한편, 다른 일부 실시예에서, 도 18의 제3 환경에서 이루어지는 A 사용자 및 B 사용자의 대화에 의 한 발화 입력에 기초한 사용자 인증의 각 단계 중 적어도 하나는 서버에 의해 수행될 수 있다. 도 19는 일부 실시예에 따른 조정된 임계치를 사용하여 사용자를 인증하는 방법을 나타낸 흐름도이다. 단계 S1901에서, 전자 장치는 임계치 테이블로부터 어느 하나의 임계치를 선택할 수 있다. 단계 S1902에서, 전자 장치는 도 11의 내지 도 14의 실시예에 따른 임계치 조정 방법 중 적어도 하나의 임계치 조정 방법에 기초하여, 임계치 테이블로부터 선택된 어느 하나의 임계치를 조정할 수 있다. 단계 S1903에서, 전자 장치는 입력 오디오 신호의 발화 구간의 오디오 신호로부터 획득된 사용자 특 징 벡터 및 등록 오디오 신호의 등록 발화 구간의 오디오 신호로부터 획득된 등록 사용자 특징 벡터 간 유 사도를, 단계 S1902에서 조정된 임계치와 비교할 수 있다. 비교 결과, 계산된 유사도가 미리 설정된 임계치 이상이면, 전자 장치는 단계 S1904에서 사용자 인증을 승인할 수 있다. 전자 장치는, 예를 들어, 계산된 유사도가 미리 설정된 임계치 이상이면, 등록 오디오 신호에 대응 되는 발화 입력을 수행한 사용자와 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 서로 동일 한 사용자인 것으로 판단하고 사용자 인증을 승인할 수 있다. 반대로, 비교 결과, 계산된 유사도가 미리 설정된 임계치 미만이면, 전자 장치는 단계 S1905에서 사용자 인증을 거부할 수 있다. 전자 장치는, 예를 들어, 계산된 유사도가 미리 설정된 임계치 미만이면, 등록 오디오 신호에 대응 되는 발화 입력을 수행한 사용자와 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 서로 동일 한 사용자가 아닌 것으로 판단하고 사용자 인증을 거부할 수 있다. 한편, 다른 일부 실시예에서, 도 19의 임계치 선택(S1901) 내지 사용자 인증 승인(S1904) 또는 사용자 인증 거 부(S1905)중 적어도 하나는 서버에 의해 수행될 수 있다. 도 20은 일부 실시예에 따른 전자 장치의 구성을 나타낸 블록도이다. 도 20을 참조하면, 일부 실시예에 따른 전자 장치는 프로세서, 사용자 입력부, 통신부 , 메모리, 마이크, 스피커 및 디스플레이를 포함할 수 있다. 사용자 입력부는, 전자 장치의 동작을 제어하기 위한 사용자의 입력을 수신할 수 있다. 예를 들어, 사용자 입력부에는 키 패드(key pad), 마이크, 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방 식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠, 조그 스위치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 통신부는 서버와의 통신을 위한 하나 이상의 통신 모듈을 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신부 또는 이동 통신부 중 적어도 하나를 포함할 수 있다. 근거리 통신부(short-range wireless communication unit)는, 블루투스 통신부, BLE(Bluetooth Low Energy) 통 신부, 근거리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 지그비(Zigbee) 통신부, 적외선(IrDA, infrared Data Association) 통신부, WFD(Wi-Fi Direct) 통신부, UWB(ultra wideband) 통신부, Ant+ 통신부 등을 포함할 수 있으나, 이에 제한되는 것은 아니다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한다. 여 기에서, 무선 신호는, 음성 호 신호, 화상 통화 호 신호 또는 문자/멀티미디어 메시지 송수신에 따른 다양한 형 태의 데이터를 포함할 수 있다. 메모리는 전자 장치의 동작을 제어하기 위한 프로그램을 저장할 수 있다. 메모리는 전자 장 치의 동작을 제어하기 위한 적어도 하나의 인스트럭션을 포함할 수 있다. 메모리에 저장된 프로그 램들은 그 기능에 따라 복수 개의 모듈들로 분류될 수 있다. 메모리는, 예를 들어, 등록 사용자에 대응되는 사용자 DB를 저장할 수 있다. 사용자 DB는, 예를 들어, 등 록 오디오 신호, 등록 오디오 신호를 입력한 사용자에 대응되는 등록 사용자 특징 벡터 및 등록 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 등록 환경 특징 벡터 중 적어도 하나를 포함할 수 있다. 메모리는, 예를 들어, 오디오 신호를 발화 구간의 오디오 신호 및 비 발화 구간의 오디오 신호로 구분하 기 위한 음향 모델, 발화 구간의 오디오 신호로부터 사용자 특징 벡터를 획득하기 위한 심층 신경망 모델, 사용 자 특징 벡터로부터 환경 성분을 제거하는데 사용되는 심층 신경망 모델 및 환경 특징 벡터를 획득하기 위한 심 층 신경망 모델 등을 저장할 수 있다. 메모리는, 예를 들어, 사용자 인증에 사용되는 복수의 임계치를 포함하는 임계치 테이블 및 사용자 DB의 업데이트에 사용되는 임계치 테이블을 저장할 수 있다. 메모리는, 예를 들어, 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티 미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있으나, 이에 제한되지 않는다. 마이크는 전자 장치 주변의 소리를 입력받을 수 있다. 사용자가 발화 입력을 수행할 때 마이크 를 통해 입력되는 소리는, 예를 들어, 사용자의 음성 또는 전자 장치 주변의 소음 중 적어도 하나 를 포함할 수 있다. 스피커는 통신부로부터 수신되거나 메모리에 저장된 오디오 신호를 소리로 출력할 수 있다. 스피커는 전자 장치에서 수행되는 기능(예를 들어, 호신호 수신음, 메시지 수신음, 알림음)과 관련 된 신호를 소리로 출력할 수 있다. 디스플레이는 전자 장치에서 처리되는 정보를 표시 출력한다. 예를 들어, 디스플레이는, 전 자 장치의 제어를 위한 인터페이스, 전자 장치의 상태 표시를 위한 인터페이스 등을 디스플레이할 수 있다. 디스플레이는, 예를 들어, 사용자 인증 수행 결과, 즉 사용자 인증 승인 및 사용자 인증 거부에 관한 결 과 메시지를 디스플레이할 수 있다. 한편, 디스플레이와 터치패드가 레이어 구조를 이루어 터치 스크린으로 구성되는 경우, 디스플레이(200 7)는 출력 장치 이외에 입력 장치로도 사용될 수 있다. 프로세서는 통상적으로 전자 장치의 전반적인 동작을 제어할 수 있다. 예를 들어, 프로세서 는, 메모리에 저장된 프로그램들을 실행함으로써, 사용자 입력부, 통신부, 메모리, 마 이크, 스피커, 및 디스플레이를 전반적으로 제어할 수 있다. 프로세서는 사용자의 발화 입력에 기초하여 입력 오디오 신호를 획득할 수 있다. 프로세서는, 입력 오디오 신호로부터, 적어도 하나의 발화 구간의 오디오 신호 및 적어도 하나의 비 발화 구간의 오디오 신 호를 구별할 수 있다. 프로세서는 비 발화 구간의 오디오 신호에 기초하여, 발화 입력이 수신된 상황을 나타내는 환경 정보를 생성할 수 있다. 프로세서는, 생성된 환경 정보 및 사용자에 대하여 미리 등록된 등록 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 등록 환경 정보의 비교 결과에 기초하여, 사용자를 인증하기위한 인증 기준을 조정할 수 있다. 프로세서는 조정된 인증 기준 및 입력 오디오 신호에 기초하여 사용자 를 인증할 수 있다. 프로세서는 입력 오디오 신호를 미리 설정된 프레임 단위로 분할하고, 분할된 프레임들의 오디오 특징을 추출하고, 추출된 오디오 특징에 기초하여, 분할된 프레임들 중에서 발화 구간에 대응되는 프레임들 및 비 발화 구간에 대응되는 프레임들을 구별할 수 있다. 프로세서는, 비 발화 구간에 대응되는 프레임들의 오디오 특징을 이용하여 상기 환경 정보를 생성할 수 있다. 프로세서는 사용자를 인증하기 위하여 미리 등록된 등록 오디오 신호를 획득하고, 등록 오디오 신호로부 터 등록 발화 구간의 오디오 신호를 획득하고, 발화 구간의 오디오 신호 및 획득된 등록 발화 구간의 오디오 신 호를 비교하여 사용자를 인증할 수 있다. 예를 들어, 등록 오디오 신호는 적어도 하나의 등록 발화 구간의 오디오 신호 및 적어도 하나의 등록 비 발화 구간의 오디오 신호를 포함하고, 등록 비 발화 구간의 오디오 신호는 등록 오디오 신호에 대응되는 발화 입력이 수신된 상황을 나타내는 등록 환경 정보를 생성하는데 이용될 수 있다. 프로세서는 발화 구간의 오디오 신호 및 등록 발화 구간의 오디오 신호 간의 유사도의 임계치를 조정할 수 있다. 프로세서는 미리 설정된 임계치 테이블로부터 발화 구간의 길이 및 등록 발화 구간의 길이에 대응하는 어 느 하나의 임계치를 선택하고, 환경 정보 및 등록 환경 정보의 비교 결과에 기초하여, 선택된 임계치를 조정할 수 있다. 프로세서는 환경 정보에 대응하는 벡터 및 등록 환경 정보에 대응하는 벡터 간 유사도에 기초하여, 선택 된 임계치를 조정할 수 있다. 일부 실시예에 따른 프로세서는, 예를 들어, 인공지능 연산을 수행할 수 있다. 프로세서는, 예를 들어, CPU(Central Processing Unit), GPU(Graphics Processing Unit), NPU(Neural Processing Unit), FPGA(Field Programmable Gate Array), ASIC(application specific integrated circuit) 중 어느 하나일 수 있으나, 이에 제한되지 않는다. 도 21은 일부 실시예에 따른 서버의 구성을 나타낸 블록도이다. 본 개시의 일부 실시예에 따른 사용자 인증 방법은, 전자 장치 및/또는 전자 장치와 유선 또는 무 선 통신을 통해 연결되는 서버에 의해 수행될 수 있다. 도 21을 참조하면, 일부 실시예에 따른 서버는, 통신부, 프로세서 및 메모리를 포함할 수 있다. 본 개시의 일부 실시예에 따른 사용자 인증 방법이 전자 장치 및 전자 장치와 유선 또는 무선 통 신을 통해 연결되는 서버에 의해 수행되는 구체적인 예는 도 22 및 도 23의 실시예를 통해 후술한다. 통신부는 전자 장치와의 통신을 위한 하나 이상의 통신 모듈을 포함할 수 있다. 예를 들어, 통신부 는, 근거리 통신부 또는 이동 통신부 중 적어도 하나를 포함할 수 있다. 근거리 통신부(short-range wireless communication unit)는, 블루투스 통신부, BLE(Bluetooth Low Energy) 통 신부, 근거리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 지그비(Zigbee) 통신부, 적외선(IrDA, infrared Data Association) 통신부, WFD(Wi-Fi Direct) 통신부, UWB(ultra wideband) 통신부, Ant+ 통신부 등을 포함할 수 있으나, 이에 제한되지 않는다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한다. 여 기에서, 무선 신호는, 음성 호 신호, 화상 통화 호 신호 또는 문자/멀티미디어 메시지 송수신에 따른 다양한 형 태의 데이터를 포함할 수 있다. 메모리는 서버의 동작을 제어하기 위한 프로그램을 저장할 수 있다. 메모리는 서버의 동작을 제어하기 위한 적어도 하나의 인스트럭션을 포함할 수 있다. 메모리는, 예를 들어, 등록 사용자에 대응되는 사용자 DB를 저장할 수 있다. 사용자 DB는, 예를 들어, 등 록 오디오 신호, 등록 오디오 신호를 입력한 사용자에 대응되는 등록 사용자 특징 벡터 및 등록 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 등록 환경 특징 벡터 중 적어도 하나를 포함할 수 있다.메모리는, 예를 들어, 오디오 신호를 발화 구간의 오디오 신호 및 비 발화 구간의 오디오 신호로 구분하 기 위한 음향 모델, 발화 구간의 오디오 신호로부터 사용자 특징 벡터를 획득하기 위한 심층 신경망 모델, 사용 자 특징 벡터로부터 환경 성분을 제거하는데 사용되는 심층 신경망 모델 및 환경 특징 벡터를 획득하기 위한 심 층 신경망 모델 등을 저장할 수 있다. 메모리는, 예를 들어, 사용자 인증에 사용되는 복수의 임계치를 포함하는 임계치 테이블 및 사용자 DB의 업데이트에 사용되는 임계치 테이블을 저장할 수 있다. 프로세서는, 통상적으로 서버의 전반적인 동작을 제어할 수 있다. 예를 들어, 프로세서는, 메모리에 저장된 프로그램들을 실행함으로써, 통신부 및 메모리를 제어할 수 있다. 프로세서는 사용자의 발화 입력에 기초하여 입력 오디오 신호를 획득할 수 있다. 프로세서는, 입력 오디오 신호로부터, 적어도 하나의 발화 구간의 오디오 신호 및 적어도 하나의 비 발화 구간의 오디오 신 호를 구별할 수 있다. 프로세서는 비 발화 구간의 오디오 신호에 기초하여, 발화 입력이 수신된 상황을 나타내는 환경 정보를 생성할 수 있다. 프로세서는, 생성된 환경 정보 및 사용자에 대하여 미리 등록된 등록 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 등록 환경 정보의 비교 결과에 기초하여, 사용자를 인증하기 위한 인증 기준을 조정할 수 있다. 프로세서는 조정된 인증 기준 및 입력 오디오 신호에 기초하여 사용자 를 인증할 수 있다. 프로세서는 입력 오디오 신호를 미리 설정된 프레임 단위로 분할하고, 분할된 프레임들의 오디오 특징을 추출하고, 추출된 오디오 특징에 기초하여, 분할된 프레임들 중에서 발화 구간에 대응되는 프레임들 및 비 발화 구간에 대응되는 프레임들을 구별할 수 있다. 프로세서는, 비 발화 구간에 대응되는 프레임들의 오디오 특징을 이용하여 상기 환경 정보를 생성할 수 있다. 프로세서는 사용자를 인증하기 위하여 미리 등록된 등록 오디오 신호를 획득하고, 등록 오디오 신호로부 터 등록 발화 구간의 오디오 신호를 획득하고, 발화 구간의 오디오 신호 및 획득된 등록 발화 구간의 오디오 신 호를 비교하여 사용자를 인증할 수 있다. 예를 들어, 등록 오디오 신호는 적어도 하나의 등록 발화 구간의 오디오 신호 및 적어도 하나의 등록 비 발화 구간의 오디오 신호를 포함하고, 등록 비 발화 구간의 오디오 신호는 등록 오디오 신호에 대응되는 발화 입력이 수신된 상황을 나타내는 등록 환경 정보를 생성하는데 이용될 수 있다. 프로세서는 발화 구간의 오디오 신호 및 등록 발화 구간의 오디오 신호 간의 유사도의 임계치를 조정할 수 있다. 프로세서는 미리 설정된 임계치 테이블로부터 발화 구간의 길이 및 등록 발화 구간의 길이에 대응하는 어 느 하나의 임계치를 선택하고, 환경 정보 및 등록 환경 정보의 비교 결과에 기초하여, 선택된 임계치를 조정할 수 있다. 프로세서는 환경 정보에 대응하는 벡터 및 등록 환경 정보에 대응하는 벡터 간 유사도에 기초하여, 선택 된 임계치를 조정할 수 있다. 일부 실시예에 따른 프로세서는, 예를 들어, 인공지능 연산을 수행할 수 있다. 프로세서는, 예를 들어, CPU(Central Processing Unit), GPU(Graphics Processing Unit), NPU(Neural Processing Unit), FPGA(Field Programmable Gate Array), ASIC(application specific integrated circuit) 중 어느 하나일 수 있으나, 이에 제한되지 않는다. 도 22는 일부 실시예에 따른 전자 장치가 서버를 통해 사용자 인증을 수행하는 방법을 나타낸 흐름도이다. 도 22를 참조하면, 단계 S2201에서, 전자 장치는 사용자의 발화 입력에 기초하여 입력 오디오 신호 를 획득할 수 있다. 단계 S2202에서, 전자 장치는 획득된 입력 오디오 신호를 서버에게 송신 할 수 있다. 단계 S2203에서, 전자 장치로부터 입력 오디오 신호를 수신한 서버는, 입력 오디오 신호(10 1)로부터 적어도 하나의 발화 구간의 오디오 신호 및 적어도 하나의 비 발화 구간의 오디오 신호를 획득할 수 있다.서버는, 예를 들어, 입력 오디오 신호를 미리 설정된 프레임 단위로 분할할 수 있다. 서버는 프레임 단위로 분할된 입력 오디오 신호로부터 발화 구간의 오디오 신호 및 비 발화 구간의 오디오 신호를 구별하여 획득할 수 있다. 단계 S2204에서, 서버는 획득된 비 발화 구간의 오디오 신호에 기초하여, 입력 오디오 신호에 대응 되는 발화 입력이 수신된 환경을 나타내는 환경 정보를 획득할 수 있다. 서버는, 예를 들어, 비 발화 구간의 오디오 신호로부터, 입력 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 환경 정보로서 환경 특징 벡터를 획득할 수 있다. 서버는, 예를 들어, 사용자 등록 단계에서 미리 저장된 사용자 DB로부터, 등록 오디오 신호에 대응 되는 발화 입력이 수신된 환경을 나타내는 환경 정보로서 등록 환경 특징 벡터를 획득할 수 있다. 단계 S2205에서, 서버는 생성된 환경 정보에 기초하여, 사용자를 인증하기 위한 인증 기준을 조정할 수 있다. 서버는, 예를 들어, 환경 특징 벡터 및 등록 환경 특징 벡터 간 유사도에 기초하여, 사용자를 인증하기 위하여 임계치 테이블로부터 선택된 어느 하나의 임계치를 조정할 수 있다. 한편, 서버는, 예를 들어, 사용자 특성 파라미터 값에 기초하여, 사용자를 인증하기 위하여 임계치 테이 블로부터 선택된 어느 하나의 임계치를 조정할 수 있다. 서버는, 예를 들어, 사용자 등록 단계에서 특정 사용자에 대하여 획득된 사용자 특징 벡터와 배경 화자 모델로부터 획득된 평균 사용자 특징 벡터 간 유사도를 획득하고, 획득된 유사도에 기초하여 해당 사용자에 대 한 사용자 특성 파라미터 값을 설정할 수 있다. 서버는, 예를 들어, 설정된 사용자 특성 파라미터 값을 해당 사용자의 사용자 DB에 저장할 수 있다. 서버는 미리 저장된 사용자 DB로부터 획득된 사용자 특성 파라미터 값에 기초하여, 임계치 테이블로부터 선택된 어느 하나의 임계치를 조정할 수 있다. 한편, 서버는, 예를 들어, 장치 특성 파라미터 값에 기초하여, 사용자를 인증하기 위하여 임계치 테이블 로부터 선택된 어느 하나의 임계치를 조정할 수 있다. 서버는, 예를 들어, 사용자 등록 단계에서 사용자 DB를 생성함과 동시에, 등록 오디오 신호를 획득한 전 자 장치를 식별하기 위한 전자 장치 ID 정보를 사용자 DB에 저장할 수 있다. 서버는, 예를 들어, 입력 오디오 신호를 획득한 전자 장치로부터 획득한 전자 장치 ID 정보가 등록 오디 오 신호를 획득한 전자 장치의 전자 장치 ID 정보와 일치하지 않을 경우, 입력 오디오 신호를 획득한 전자 장치 및 등록 오디오 신호를 획득한 전자 장치에 대응되는 장치 특성 파라미터 값에 기초하여, 임계치 테이블로부터 선택된 어느 하나의 임계치를 조정할 수 있다. 서버가 사용할 수 있는 장치 특성 파라미터 값은, 예를 들어, 전자 장치 간 오디오 신호 처리 성능 차이 의 측정을 통해, 사용자의 등록 단계 이전에 미리 설정될 수 있다. 도 14의 실시예의 구성을 참조하여 설명하면, 서버는, 예를 들어, 사용자의 제1 발화 입력에 기초하여 스 마트폰(1000A)이 획득한 제1 오디오 신호를 전달받을 수 있다. 서버는 제1 오디오 신호로부터 사용자 특 징 벡터를 획득할 수 있다. 서버는 제1 오디오 신호로부터 획득된 사용자 특징 벡터 및 기준 사용자 특징 벡터 간 유사도를 획득할 수 있다. 서버는, 예를 들어, 사용자의 제1 발화 입력에 기초하여 인공지능 스피커(1000B)가 획득한 제2 오디오 신 호를 전달받을 수 있다. 서버는 제2 오디오 신호로부터 사용자 특징 벡터를 획득할 수 있다. 서버 는 제2 오디오 신호로부터 획득된 사용자 특징 벡터 및 기준 사용자 특징 벡터 간 유사도를 획득할 수 있다. 서버는, 예를 들어, 사용자의 동일한 제1 발화 입력에 대하여, 제1 오디오 신호로부터 획득한 사용자 특 징 벡터 및 기준 사용자 특징 벡터 간 유사도와, 제2 오디오 신호로부터 획득한 사용자 특징 벡터 및 기준 사용 자 특징 벡터 간 유사도의 편차에 기초하여 장치 특성 파라미터 값을 설정할 수 있다. 한편, 서버는, 예를 들어, 사용자가 발화 입력을 수행하지 않는 환경에서 스마트폰(1000A)이 획득한 제3 오디오 신호를 전달받을 수 있다. 서버는 제3 오디오 신호로부터 환경 특징 벡터를 획득할 수 있다. 서버 는 제3 오디오 신호로부터 획득된 환경 특징 벡터 및 기준 환경 특징 벡터 간 유사도를 획득할 수 있다.서버는, 예를 들어, 사용자가 발화 입력을 수행하지 않는 환경에서 인공지능 스피커(1000B)가 획득한 제4 오디오 신호를 전달받을 수 있다. 서버는 제4 오디오 신호로부터 환경 특징 벡터를 획득할 수 있다. 서버 는 제4 오디오 신호로부터 획득된 환경 특징 벡터 및 기준 환경 특징 벡터 간 유사도를 획득할 수 있다. 서버는, 예를 들어, 사용자가 발화 입력을 수행하지 않는 동일한 환경에 대하여, 제3 오디오 신호로부터 획득한 환경 특징 벡터 및 기준 환경 특징 벡터 간 유사도와, 제4 오디오 신호로부터 획득한 환경 특징 벡터 및 기준 환경 특징 벡터 간 유사도의 편차에 기초하여 장치 특성 파라미터 값을 설정할 수 있다. 서버는, 다른 예로, 사용자가 발화 입력을 수행하지 않는 동일한 환경에 대하여, 제3 오디오 신호로부터 획득한 환경 특징 벡터 및 제4 오디오 신호로부터 획득한 환경 특징 벡터 간 유사도에 기초하여 장치 특성 파라 미터 값을 설정할 수도 있다. 서버가 사용할 수 있는 장치 특성 파라미터 값은, 다른 예로, 사용자의 등록 단계 이후에 스마트폰 (1000A) 및 인공지능 스피커(1000B)의 오디오 신호 처리 성능 차이의 측정을 통해 설정 또는 업데이트 될 수 있 다. 이때 장치 특성 파라미터 값의 설정 또는 업데이트에 사용되는 기준 사용자 특징 벡터 및 기준 환경 특징 벡터는, 사용자 등록 단계에서 서버가 획득한 등록 사용자 특징 벡터 및 등록 환경 특징 벡터일 수 있다. 단계 S2206에서, 서버는 조정된 인증 기준 및 오디오 신호에 기초하여 사용자를 인증할 수 있다. 서버는 예를 들어, 사용자 DB로부터 획득된 등록 사용자 특징 벡터 및 발화 구간의 오디오 신호로부터 획 득된 사용자 특징 벡터에 기초하여 사용자 인증을 수행할 수 있다. 서버는 예를 들어, 등록 사용자 특징 벡터 및 사용자 특징 벡터 간 유사도를 획득하고, 획득된 유사도를 조정된 임계치와 비교하여 사용자 인증을 수 행할 수 있다. 단계 S2207에서, 서버는 사용자 인증의 결과를 전자 장치에게 송신할 수 있다. 단계 S2208에서, 전자 장치는 서버로부터 수신한 사용자 인증 결과를 출력할 수 있다. 전자 장치는, 예를 들어, 스피커 또는 디스플레이 중 적어도 하나를 통해 사용자 인증 결과 를 소리 또는 이미지로 출력함으로써, 사용자에게 사용자 인증 결과를 전달할 수 있다. 도 23은 일부 실시예에 따른 서버가 전자 장치를 통해 사용자 인증을 수행하는 방법을 나타낸 흐름도이다. 도 23을 참조하면, 단계 S2301에서, 전자 장치는 사용자의 발화 입력에 기초하여 입력 오디오 신호 를 획득할 수 있다. 단계 S2302에서, 전자 장치는 입력 오디오 신호로부터 적어도 하나의 발화 구간 의 오디오 신호 및 적어도 하나의 비 발화 구간의 오디오 신호를 획득할 수 있다. 전자 장치는, 예를 들어, 입력 오디오 신호를 미리 설정된 프레임 단위로 분할할 수 있다. 서버 는 프레임 단위로 분할된 입력 오디오 신호로부터 발화 구간의 오디오 신호 및 비 발화 구간의 오디 오 신호를 구별하여 획득할 수 있다. 단계 S2303에서, 전자 장치는 획득된 비 발화 구간의 오디오 신호에 기초하여, 입력 오디오 신호에 대응되는 발화 입력이 수신된 환경을 나타내는 환경 정보를 획득할 수 있다. 전자 장치는, 예를 들어, 비 발화 구간의 오디오 신호로부터, 입력 오디오 신호에 대응되는 발화 입 력이 수신된 환경을 나타내는 환경 정보로서 환경 특징 벡터를 획득할 수 있다. 단계 S2304에서, 전자 장치는 발화 구간의 오디오 신호, 비 발화 구간의 오디오 신호 및 환경 정보를 서 버에게 송신할 수 있다. 전자 장치는, 예를 들어, 비 발화 구간의 오디오 신호로부터 획득된 환경 특징 벡터를 서버에게 전달할 수 있다. 서버는, 예를 들어, 사용자 등록 단계에서 미리 생성된 사용자 DB로부터, 등록 오디오 신호에 대응 되는 발화 입력이 수신된 환경을 나타내는 환경 정보로서 등록 환경 특징 벡터를 획득할 수 있다. 단계 S2305에서, 서버는 전자 장치로부터 전달받은 환경 정보에 기초하여, 사용자를 인증하기 위한 인증 기준을 조정할 수 있다. 서버는, 예를 들어, 비 발화 구간의 오디오 신호로부터 획득된 환경 특징 벡터 및 사용자 DB로부터 획득 된 등록 환경 특징 벡터 간 유사도에 기초하여, 사용자를 인증하기 위하여 임계치 테이블로부터 선택된 어느 하 나의 임계치를 조정할 수 있다.한편, 서버는, 예를 들어, 사용자 특성 파라미터 값에 기초하여, 사용자를 인증하기 위하여 임계치 테이 블로부터 선택된 어느 하나의 임계치를 조정할 수 있다. 한편, 서버는, 예를 들어, 장치 특성 파라미터 값에 기초하여, 사용자를 인증하기 위하여 임계치 테이블 로부터 선택된 어느 하나의 임계치를 조정할 수 있다. 서버가 사용자 특성 파라미터 값 및 장치 특성 파라미터 값에 기초하여 임계치를 조정하는 구체적인 방법 은, 전술한 도 22의 서버가 임계치를 조정하는 방법과 동일하므로, 이에 대한 자세한 설명은 생략한다. 단계 S2306에서, 서버는 조정된 인증 기준 및 오디오 신호에 기초하여 사용자를 인증할 수 있다. 서버는 예를 들어, 사용자 DB로부터 획득된 등록 사용자 특징 벡터 및 발화 구간의 오디오 신호로부터 획 득된 사용자 특징 벡터에 기초하여 사용자 인증을 수행할 수 있다. 서버는 예를 들어, 등록 사용자 특징 벡터 및 사용자 특징 벡터 간 유사도를 획득하고, 획득된 유사도를 조정된 임계치와 비교하여 사용자 인증을 수 행할 수 있다. 단계 S2307에서, 서버는 사용자 인증의 결과를 전자 장치에게 송신할 수 있다. 단계 S2308에서, 전자 장치는 서버로부터 수신한 사용자 인증 결과를 출력할 수 있다. 전자 장치는, 예를 들어, 스피커 또는 디스플레이 중 적어도 하나를 통해 사용자 인증 결과 를 소리 또는 이미지로 출력함으로써, 사용자에게 사용자 인증 결과를 전달할 수 있다. 도 24는 일부 실시예에 따른 전자 장치 및 서버가 사용자 식별 및 사용자 인증을 수행하는 방법을 나타낸 흐름 도이다. 도 24를 참조하면, 일부 실시예에 따른 전자 장치는 사용자의 발화 입력에 기초하여 입력 오디오 신 호를 획득하고, 입력 오디오 신호에 대한 전처리를 수행할 수 있다. 입력 오디오 신호에 대한 전처리는 입력 오디오 신호로부터 오디오 특징을 추출하는 과정을 포함할 수 있다. 전자 장치는 전처리가 수행된 입력 오디오 신호로부터 웨이크업 문장을 검출하고, 검출된 웨이크업 문장에 기초하여 사용자에 대한 인증 프로세스를 시작할 수 있다. 전자 장치는, 예를 들어, 특 정 키워드의 포함 여부를 판단하여 입력 오디오 신호로부터 웨이크업 문장을 검출할 수 있다. 전자 장치는, 예를 들어, 먼저 제1 웨이크업 모듈을 사용하여 VAD(Voice Activity Detection) 방식을 통 해 사용자의 음성을 감지할 수 있다. 전자 장치는, 예를 들어, 제1 웨이크업 모듈을 저 전력 구동 방 식을 사용하는 상시 활성화 상태(always on)로 설정할 수 있다. 전자 장치는 제1 웨이크업 모듈을 사용하여 사용자의 발화 입력을 지속적으로 감지함으로써, 발화 입 력에 대응되는 입력 오디오 신호에 사용자의 음성이 포함되어 있는지 여부를 판단할 수 있다. 입력 오디오 신호에 사용자의 음성이 포함되어 있는 것으로 판단되면, 전자 장치는, 예를 들어, 제1 웨이크업 모듈을 사용하여 입력 오디오 신호의 키워드 포함 여부를 판단할 수 있다. 제1 웨이크업 모듈을 사용하여 판단한 결과, 입력 오디오 신호에 키워드가 포함되어있는 것으로 판단되면, 전자 장치는 제2 웨이크 업 모듈을 활성화할 수 있다. 전자 장치는 제2 웨이크업 모듈을 사용하여 입력 오디오 신호의 키워드 포함 여부를 재판단할 수 있다. 전자 장치는, 예를 들어, 키워드 검출 모델을 사용하는 제2 웨이크업 모듈을 통해 오디오 신호의 키워드 포함 여부를 판단할 수 있다. 제2 웨이크업 모듈이 사용하는 키워드 검출 모델의 구체적인 학습 방법은 도 25를 통해 후술한다. 입력 오디오 신호로부터 웨이크업 문장이 검출되면, 전자 장치는 복수의 사용자 DB에 기초하 여, 오디오 신호를 입력한 사용자에 대한 사용자 식별(identification)을 수행할 수 있다. 전자 장치는, 예를 들어, 입력 오디오 신호의 적어도 일부 및 복수의 사용자 DB를 사용하여 사용자 식별을 수행할 수 있다. 전자 장치는, 예를 들어, 입력 오디오 신호의 적어도 일부로서, 웨이크업 문장에 대응되는 사용자 특징 벡터를 획득하고, 획득된 사용자 특징 벡터를 복수의 사용자 DB로부터 획득된 각 사용자 특징 벡터 와 비교하여 유사도를 계산할 수 있다. 전자 장치는, 다른 예로, 입력 오디오 신호의 전체로부터 획득된 사용자 특징 벡터를 복수의 사용자 DB로부터 획득된 각 사용자 특징 벡터와 비교하여 유사도를 계산할 수 있다. 전자 장치는, 예를 들어, 사용자 특징 벡터를 획득하기 위한 심층 신경망 모델을 사용하여, 입력 오디오 신호의 적어도 일부 또는 전체로부터 사용자 특징 벡터를 획득할 수 있다. 전자 장치는, 예를 들어, 계산된 유사도가 가장 높은 사용자 특징 벡터를 포함하는 사용자 DB가 A 사용자 DB임을 확인하고, 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 A 사용자인 것으로 식별 할 수 있다. 한편, 전자 장치의 사용자 식별이 완료되면, 서버는 전자 장치로부터 입력 오디오 신호 및 사용자 식별 결과를 전달받을 수 있다. 서버는, 예를 들어, 전자 장치로부터 전처리가 이루어진 입력 오디오 신호 및 사용자 식별 결과를 전달받을 수 있다. 서버는, 다른 예로, 전자 장치로부터 전처리가 이루어지지 않은 입력 오디오 신호 및 사용자 식별 결과를 전달받을 수 있다. 서버는 전자 장치로부터 전달받은 사용자 식별 결과에 기초하여 계정 인증을 수행할 수 있다 . 예를 들어, 전자 장치가 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자를 A 사용자로 결정한 경우, 서버는 A 사용자에 대한 계정 인증을 수행할 수 있다. 서버에 저장된 복수의 사용자 DB는 전자 장치가 사용하는 복수의 사용자 DB를 포함할 수 있다. 서버는 A 사용자에 대한 계정 인증을 통해, 서버에 저장된 복수의 사용자 DB로부터 A 사용자 DB를 획득할 수 있다. 서버는 전자 장치로부터 입력 오디오 신호 및 복수의 사용자 DB로부터 획득된 A 사용자 DB에 기초하여, 입력 오디오 신호의 전체 문장에 대한 자동 음성 인식(Automatic Speech Recognition, ASR)을 수행할 수 있다. 서버는, 각 등록 사용자에 대하여 개인화된 언어 모델(Personalized Language Model, PLM)을 사용하는 자동 음성 인식의 결과로, 입력 오디오 신호에 포함된 웨이크업 문장 및 소정의 기능을 실행시키기 위한 문장을 구분하여 식별할 수 있다. 서버는 전자 장치로부터 전달받은 입력 오디오 신호 및 복수의 사용자 DB로부터 획득된 A 사용자 DB에 기초하여 사용자 인증을 수행할 수 있다. 서버는 입력 오디오 신호에 대하여, 도 1 내지 도 23을 통해 전술한 본 개시의 사용자 인증 방법을 통해 사용자 인증을 수행할 수 있다. 서버는, 예를 들어, 사용자 특징 벡터를 획득하기 위한 심층 신경망 모델을 사용하여, 입력 오디오 신호 의 적어도 일부 또는 전체로부터 사용자 특징 벡터를 획득할 수 있다. 서버는, 예를 들어, 사용자 특징 벡터를 획득하기 위한 심층 신경망 모델을 사용하여, 입력 오디오 신호 의 적어도 일부 또는 전체로부터 사용자 특징 벡터를 획득할 수 있다. 서버가 사용자 특징 벡터를 획득하기 위해 사용하는 심층 신경망 모델은, 예를 들어, 전자 장치가 사용하는 사용자 특징 벡터를 획득 하기 위한 심층 신경망 모델과 서로 동일한 심층 신경망 모델이거나, 서로 다른 심층 신경망 모델일 수 있다. 서버는 획득된 사용자 특징 벡터 및 획득된 A 사용자 DB로부터 획득된 등록 사용자 특징 벡터 간 유사도 에 기초하여 사용자 인증을 수행할 수 있다. 서버는, 예를 들어, 획득된 사용자 특징 벡터 및 획득된 A 사용자 DB로부터 획득된 등록 사용자 특징 벡터 간 유사도를 임계치와 비교하여, 입력 오디오 신호에 대응 하는 발화 입력을 수행한 사용자가 A 사용자에 해당하는지 여부를 결정할 수 있다. 한편, 서버는 사용자 인증 결과에 따라, 사용자 식별 결과 및 사용자 인증 결과의 일치 여부를 판 단할 수 있다. 예를 들어, 전자 장치가 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자 를 A 사용자로 결정한 경우, 서버는, 사용자 인증 결과를 통해, 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 실제로 A 사용자에 해당하는지 여부를 판단할 수 있다. 판단 결과, 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 A 사용자에 해당할 경우, 서버는 자연 언어 이해(Natural Language Understanding)모델을 통해 A 사용자의 명령에 대 응하는 응답을 생성할 수 있다.예를 들어, 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 A 사용자에 해당하고, 입력 오 디오 신호가 \"Hi, Bixby, today's weather.\"와 같은 날씨 정보에 관한 문장에 대응할 경우, 서버는 A 사용자의 명령에 대응하여 날씨 정보의 제공 기능을 실행시킴으로써, \"Today's weather is sunny.\"와 같은 날 씨 정보를 전달하기 위한 응답을 생성할 수 있다. 다른 예로, 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 A 사용자에 해당하고, 입력 오 디오 신호가 \"Hi, Bixby, today's schedule.\"과 같은 개인 일정 정보에 관한 문장에 대응할 경우, 서버 는 A 사용자의 명령에 대응하여 일정 정보 제공 기능을 실행시킴으로써, \"Today, we have three scheduled jobs.\"와 같은 A 사용자에 대한 일정 정보를 전달하기 위한 응답을 생성할 수 있다. 한편, 판단 결과, 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 A 사용자에 해당 하는 것으로 판단되지만, 입력 오디오 신호로부터 획득된 환경 특징 벡터 및 A 사용자 DB로부터 획득된 등 록 환경 특징 벡터의 유사도가 입력 오디오 신호의 재입력을 요구하기 위한 소정의 임계치 미만일 경우, 서버는 사용자에게 발화 입력을 다시 수행할 것을 요청하기 위한 응답을 생성할 수 있다. 예를 들어, 입력 오디오 신호가 \"Hi, Bixby, accept the payment.\"와 같은 지불 승인 문장에 대응되고, 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 A 사용자에 해당하는 것으로 판단되지만, 입력 오디오 신호로부터 획득된 환경 특징 벡터 및 A 사용자 DB로부터 획득된 등록 환경 특징 벡터의 유사 도가 입력 오디오 신호의 재입력을 요구하기 위한 소정의 임계치 미만일 경우, 서버는 지불 보안 강 화 기능을 실행시킴으로써 \"Sorry, please try again in other place.\"와 같은 오디오 신호의 재입력이 필요함 을 알리기 위한 응답을 생성할 수 있다. 다른 예로, 입력 오디오 신호가 \"Hi, Bixby, accept the payment.\"와 같은 지불 승인 문장에 대응되고, 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 A 사용자에 해당하는 것으로 판단되지만, 입력 오디오 신호로부터 획득된 환경 특징 벡터 및 A 사용자 DB로부터 획득된 등록 환경 특징 벡터의 유사 도가 입력 오디오 신호의 재입력을 요구하기 위한 소정의 임계치 미만일 경우, 서버는 지불 보안 강 화 기능을 실행시킴으로써 \"Sorry, please reduce the noise around you\"와 같은 주변 소음의 제거를 요청하기 위한 응답을 생성할 수 있다. 한편, 판단 결과, 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 A 사용자에 해당 하지 않을 경우, 서버는 계정 인증의 승인에 따라 결정된 사용자 계정을 A 사용자로부터 일반 사용 자로 전환할 수 있다. 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 일반 사용자 에 해당하는 것으로 판단한 서버는 자연 언어 이해(Natural Language Understanding)를 통해 일반 사용자의 명령에 대응하는 응답을 생성할 수 있다. 예를 들어, 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 A 사용자에 해당하지 않고, 입 력 오디오 신호가 \"Hi, Bixby, today's weather.\"와 같이 날씨 정보에 관한 문장에 대응할 경우, 서버 는, 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 A 사용자에 해당하는 경우와 동 일하게, 일반 사용자의 명령에 대응하여 날씨 정보의 제공 기능을 실행시킴으로써, \"Today's weather is sunny.\"와 같은 날씨 정보를 전달하기 위한 응답을 생성할 수 있다. 그러나, 다른 예로, 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 A 사용자에 해당하지 않고, 입력 오디오 신호가 \"Hi, Bixby, today's schedule.\"과 같은 개인 일정 정보를 획득하기 위한 문장 에 대응할 경우, 서버는, 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 A 사용자 에 해당하는 경우와 달리, 개인 정보 보호 기능을 실행시킴으로써, \"Sorry, user authentication is required.\"와 같은 사용자 인증이 필요함을 알리기 위한 응답을 생성할 수 있다. 한편, 판단 결과 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 A 사용자에 해당하 지 않을 경우, 서버는 사용자에게 발화 입력을 다시 수행할 것을 요청하기 위한 응답을 생성할 수 있 다. 서버는 생성된 응답을 전자 장치로 전달할 수 있다. 예를 들어, 입력 오디오 신호에 대응되는 발화 입력을 수행한 사용자가 A 사용자에 해당하지 않고, 입 력 오디오 신호가 \"Hi, Bixby, today's schedule.\"과 같은 개인 일정 정보를 획득하기 위한 문장에 대응 할 경우, 서버는 개인 정보 보호 기능을 실행시킴으로써, \"Sorry, please try again.\"과 같은 오디오 신 호의 재입력이 필요함을 알리기 위한 응답을 생성할 수 있다.이처럼, 일부 실시예에 따른 사용자 인증 방법은, 전자 장치 및 서버의 연산 성능 차이를 고려하여, 전자 장치에서 웨이크업 문구에 기초한 모듈 활성화 및 사용자 식별을 수행하고, 서버를 통해 사용자 인증을 수행함으로써, 연산 속도 및 사용자 인증 성능의 저하를 방지할 수 있다. 또한, 일부 실시예에 따른 사용자 인증 방법은, 사용자 식별 결과, 사용자 인증 결과 및 사용자 명령의 내용에 기초한 응답을 생성함으로써, 사용자의 개인 정보를 보호함과 동시에, 인증에 성공한 사용자에게는 필요한 정보 를 신속하게 제공할 수 있다. 서버에 의해 생성된 응답 및 사용자 인증의 결과는 전자 장치로 전달될 수 있다. 전자 장치는 서버로부터 전달받은 응답 및 사용자 인증의 결과를 출력할 수 있다. 전자 장치 는, 예를 들어, 스피커 또는 디스플레이 중 적어도 하나를 통해, 생성된 응답 및 사용자 인 증 결과를 소리 또는 이미지로 출력하여 사용자에게 전달할 수 있다. 도 25는 일부 실시예에 따른 키워드 검출 모델의 학습 방법을 나타낸 도면이다. 도 25를 참조하면, 일부 실시예에 따른 전자 장치가 사용하는 키워드 검출 모델은 멀티 태스크 학습 (multi-task training) 방식을 통해 학습될 수 있다. 전자 장치가 사용하는 키워드 검출 모델은, 예를 들어, 키워드 검출을 주 태스크로, 자동 음성 인식을 보 조 태스크로 하는 멀티 태스크 학습 방식을 통해 학습될 수 있다. 멀티 태스크 학습은 하나 이상의 보조 태스크 가 주 태스크와 함께 학습되는 학습 방식을 사용하며, 공유 레이어 이외에 각 태스크에 대한 별도의 레이어를 사용하여 각 태스크에 대응되는 모델을 학습할 수 있다. 멀티 태스크 학습은 유사한 성격을 지닌 태스크 간 일반화(generalize) 성능을 높이기 위한 학습으로서, 모든 태스크 간에 연관성이 존재함을 가정한다. 멀티 태스크 학습은 별개의 태스크를 동시에 학습하여 서로의 정보를 부분적으로 공유함으로써, 신뢰도 높은 학습 모델을 구성할 수 있는 장점을 갖는다. 다시 도 25를 참조하면, 일부 실시예에 따른 키워드 검출 모델의 학습에 사용되는 공유 레이어는 주 태스 크인 키워드 검출의 학습과 보조 태스크인 자동 음성 인식의 학습을 위해 공유될 수 있다. 공유 레이어는, 예를 들어, 시간 지연 신경망(time delay neural network, TDNN)으로 이루어질 수 있다. 시간 지연 신경망은 다차원 인공 신경망으로서, 신경망의 각 계층에서 컨텍스트(context)를 모델링하는 신경망 이다. 시간 지연 신경망은, 예를 들어, 오디오 신호의 연속된 프레임의 컨텍스트(context)를 이용하기 위해, 특 정 프레임의 오디오 특징 벡터 이외에, 이전 프레임의 오디오 특징 벡터 및 이후 프레임의 오디오 특징 벡터를 사용할 수 있다. 도 26은 일부 실시예에 따른 시간 지연 신경망의 오디오 특징 벡터 처리 방법을 나타낸 도면이다. 도 26을 참조하면, 시간 지연 신경망은 입력 레이어(Input Layer)을 통해 오디오 신호의 각 프레임으로부터 획 득된 오디오 특징 벡터를 입력받을 수 있다. 시간 지연 신경망은, 예를 들어, 오디오 신호의 t 번째 프레임의 오디오 특징 벡터에 대하여, 후술할 프 레임 단위 표현(representation)을 획득하기 위해, t 번째 프레임의 오디오 특징 벡터 이외에 t-13 번째 프레임 내지 t-1 번째 프레임의 오디오 특징 벡터와 t+1 번째 프레임 내지 t+9 번째 프레임의 오디오 특 징 벡터를 모두 사용할 수 있다. 다시 도 26을 참조하면, 시간 지연 신경망의 입력 레이어에 입력된 t 번째 프레임의 오디오 특징 벡터가, t-2 번째 프레임의 오디오 특징 벡터, t-1 번째 프레임의 오디오 특징 벡터, t+1 번째 프레임의 오디오 특징 벡 터 및 t+2 번째 프레임의 오디오 특징 벡터와 함께 첫 번째 은닉 레이어(Hidden Layer 1)의 노드로 입력되는 경 로가 굵은 실선으로 도시되어있다. 이와 같이 다섯 개의 프레임에 대한 오디오 특징 벡터에 대해 도시된 경로는, 각 프레임의 오디오 특징 벡터가 서로 결합(concatenate)되어 상위층의 노드로 입력됨을 나타낸다. 입력 레이어로부터 첫 번째 은닉 레이어로 이어지는 모든 경로는, t-13 번째 프레임의 오디오 특징 벡터 내지 t+9 번째 프레임의 오디오 특징 벡터가, t-2 번째 프레임의 오디오 특징 벡터 내지 t+2 번째 프레임의 오디오 특징 벡터와 동일하게, 다섯 개의 프레임 단위로 결합되어 첫 번째 은닉 레이어의 노드에 입력됨을 나타낸다. 은닉 레이어를 통과하는 결합된 오디오 특징 벡터들은, 예를 들어, 은닉 레이어의 각 노드의 활성화 함수 (Activation Function)에 의해 변환될 수 있다.t-13 번째 프레임의 오디오 특징 벡터 내지 t+9 번째 프레임의 오디오 특징 벡터는 첫 번째 은닉 레이어 내지 세 번째 은닉 레이어를 통과하는 과정에서 결합 및 변환되어, t 번째 프레임에 대응되는 프레임 단위 표현 으로 출력층(Output Layer)을 통해 출력될 수 있다. 시간 지연 신경망의 t 번째 프레임의 오디오 특징 벡터에 대응되는 프레임 단위 표현의 출력은, 순차적으 로 t+1 번째 프레임의 오디오 특징 벡터에 대하여 동일하게 이루어질 수 있다. 즉, 시간 지연 신경망은 오디오 신호의 각 프레임에 대응하는 프레임 단위 표현을 순차적으로 출력할 수 있다. 이처럼, 시간 지연 신경망은 특정 프레임의 오디오 특징 벡터 이외에, 이전 프레임의 오디오 특징 벡터 및 이후 프레임의 오디오 특징 벡터를 사용하여 특정 프레임의 오디오 특징 벡터에 대응되는 프레임 단위 표현을 출력할 수 있으므로, 학습 과정에서 오디오 신호의 컨텍스트는 유지될 수 있다. 다시 도 25를 참조하면, 키워드 검출 모델의 학습에 사용되는 공유 레이어 위에는 주 태스크를 위한 키워 드 학습용 레이어 및 보조 태스크를 위한 자동 음성 인식 학습용 레이어가 연결(stack)될 수 있다. 공유 레이어에서 출력된 프레임 단위 표현은 키워드 학습용 레이어에 입력될 수 있다. 도 27은 일부 실시예에 따른 키워드 학습용 레이어의 공유 레이어로부터 출력된 프레임 단위 표현에 대한 처리 과정을 나타낸 도면이다. 일부 실시예에서, 주 태스크인 키워드 검출을 학습하기 위한 데이터가 공유 레이어에 입력될 수 있다. 키 워드 학습용 레이어는, 예를 들어, 키워드 검출을 위한 셀프 어텐션 레이어(self attention Layer)를 포 함할 수 있다. 특정 키워드는 오디오 신호의 복수의 연속된 프레임으로부터 획득된 오디오 특징 벡터와 서로 대응될 수 있다. 키워드 검출 학습용 데이터는, 예를 들어, 특정 키워드 및 특정 키워드에 대응하는 복수의 오디오 특징 벡터에 관한 정보를 포함할 수 있다. 키워드 학습용 레이어에 포함된 셀프 어텐션 레이어는, 복수의 연속된 프레임으로부터 획득된 오디오 특 징 벡터가 특정 키워드에 대응되는지 여부를 판단하기 위하여, 공유 레이어에서 출력된 복수의 프레임 단 위 표현을 사용할 수 있다. 도 27을 참조하면, 오디오 신호의 M개의 프레임에 대한 오디오 특징 벡터를 입력받은 공유 레이어는 M개 의 프레임 단위 표현을 출력할 수 있다. 공유 레이어로부터 출력된 M개의 프레임 단위 표현 은 키워드 학습용 레이어에 포함된 셀프 어텐션 레이어에 입력될 수 있다. 셀프 어텐션 레이어는, 예를 들어, 복수의 포인트를 강조하기 위하여 서로 다른 프레임 단위 표현에 존재하는 정보를 결합하여 사용하는 멀티 헤드 셀프 어텐션(multi head self attention) 메커니즘을 사용하여, M개 의 프레임 단위 표현으로부터 헤드의 수만큼인 h개의 세그먼트 단위 표현을 획득할 수 있다. 셀프 어텐션 레이어는, 예를 들어, h개의 세그먼트 단위 표현에 대한 결합 및 오디오 특징 벡터의 크기를 조정하기 위한 가중치 행렬의 적용을 통해 하나의 세그먼트 단위 표현을 획득할 수 있다. 다시 도 25를 참조하면, 셀프 어텐션 레이어를 통해 출력되는 세그먼트 레벨 표현은 키워드 특정 키워드에 대응 되는 레이블(label)에 대한 확률을 출력하는 SOFTMAX 레이어에 입력될 수 있다. SOFTMAX 레이어에서 세그먼트 단위 표현은, 예를 들어, 'Hi Bixby' 및 'Bixby'의 키워드에 대응되는 키워드 노드 및 논-키워드(non- keyword)에 대응되는 필러(filler) 노드 각각에 대한 확률로 변환될 수 있다. 이처럼 일부 실시예에 따른 키워드 검출 모델은, 키워드 검출 학습용 데이터에 기초하여 공유 레이어 및 키워드 학습용 레이어의 가중치를 조정하는 방식으로 학습될 수 있다. 한편, 일부 실시예서, 보조 태스크인 자동 음성 인식을 학습하기 위한 데이터가 공유 레이어에 입력될 수 있다. 자동 음성 인식을 학습하기 위한 데이터는, 예를 들어, 특정 음소열 및 특정 음소열에 대응하는 오디오 특징 벡터에 관한 정보를 포함할 수 있다. 자동 음성 인식의 학습에 사용되는 음소열은 음소의 배열로서, 예를 들어, 3개의 음소를 포함하는 트라이폰(triphone)일 수 있다. 공유 레이어에서 출력된 프레임 단위 표현은 자동 음성 인식 학습용 레이어에 입력될 수 있다. 공유 레이어에서 출력된 프레임 단위 표현은 자동 음성 인식 학습용 레이어에 포함된 활성화 함수 인 ReLU(Rectified Linear Unit)가 활성화되어있는 복수의 피드 포워드(feed forward) 레이어에 입력될 수 있다. 피드 포워드 레이어는 은닉 레이어의 출력을 동일한 은닉 레이어로 다시 입력하지 않고, 하위 은닉 레이어 의 출력을 상위 은닉 레이어로만 입력하는 특징을 갖는다. 자동 음성 인식 학습용 레이어의 피드 포워드 레이어에서 프레임 단위 표현은, 예를 들어, 특정 트라이폰 의 레이블에 대응되는 출력 노드 각각에 대한 확률로 변환될 수 있다. 즉, 키워드와 달리, 키워드에 비해 발화 길이가 짧은 트라이폰은 단일 프레임으로부터 획득된 오디오 특징 벡터 와 서로 대응될 수 있으므로, 자동 음성 인식 학습용 레이어는 하나의 프레임 단위 표현이 특정 트라이폰 에 대응할 확률을 획득하는 자동 음성 인식을 학습할 수 있다. 이처럼 일부 실시예에 따른 키워드 검출 모델은, 자동 음성 인식 학습용 데이터에 기초하여 공유 레이어 및 자동 음성 인식 학습용 레이어의 가중치를 조정하는 방식으로 학습될 수 있다. 이처럼, 일부 실시예에 따른 전자 장치는 멀티 태스크 학습 및 셀프 어텐션 메커니즘을 사용하여 학습된 키워드 검출 모델을 사용함으로써, 웨이크업 문구를 검출하기 위한 키워드 검출의 신뢰도를 높일 수 있는 장점 을 갖는다. 한편, 일부 실시예에서, 키워드 검출 모델의 학습이 완료되면, 전자 장치는 자동 음성 인식 학습용 레이 어가 제거된 키워드 검출 모델을 사용하여 키워드 검출을 위한 연산을 수행할 수 있다. 전자 장치는 멀티 태스크 학습 방식을 통해 학습된 후, 보조 태스크의 학습을 위한 자동 음성 인식 학습 용 레이어가 제거된 키워드 검출 모델을 사용함으로써, 키워드 검출의 신뢰도를 높임과 동시에 연산량을 감소시킬 수 있는 장점을 갖는다. 도 20 내지 도 25의 내용을 참조하면, 본 개시의 일부 실시예에 따른 사용자 인증 방법은 전자 장치 및 서버 중 어느 하나에 의해서만 단독으로 수행될 수 있는 것은 아니며, 사용자 인증 방법의 각 단계가 전 자 장치 및 서버 중 적어도 하나에 의해 수행될 수 있음을 당업자는 용이하게 이해할 수 있을 것이다. 일부 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어를 포함하는 기 록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스 될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독 가능 매체는 컴퓨터 저장 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로 그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 본 명세서에서, \"부\"는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로세 서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다. 전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술 분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다. 도면 도면1 도면2 도면3 도면4 도면5a 도면5b 도면6a 도면6b 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21 도면22 도면23 도면24 도면25 도면26 도면27"}
{"patent_id": "10-2019-0094532", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일부 실시예에 따른 전자 장치가 사용자의 발화 입력에 기초하여 인증을 수행하는 방법을 개념적으로 나 타내는 도면이다. 도 2는 일부 실시예에 따른 사용자 인증 방법을 나타낸 흐름도이다. 도 3은 일부 실시예에 따른 입력 오디오 신호에 포함된 발화 구간의 오디오 신호 및 비 발화 구간의 오디오 신 호를 나타내는 도면이다. 도 4는 일부 실시예에 따른 입력 오디오 신호로부터 사용자 특징 벡터를 획득하는 방법을 나타내는 도면이다.도 5a는 일부 실시예에 따른 사용자 등록 환경 및 등록 오디오 신호의의 관계를 나타내는 도면이다. 도 5b는 일부 실시예에 따른 사용자 인증 환경 및 입력 오디오 신호의 관계를 나타내는 도면이다. 도 6a는 일부 실시예에 따른 사용자 등록 환경 및 등록 오디오 신호의 관계를 나타내는 도면이다. 도 6b는 일부 실시예에 따른 사용자 인증 환경 및 입력 오디오 신호의 관계를 나타내는 도면이다. 도 7은 일부 실시예에 따른 발화 구간의 오디오 신호 및 등록 발화 구간의 오디오 신호에 기초하여 사용자 인증 을 수행하는 과정을 나타낸 도면이다. 도 8은 일부 실시예에 따른 비 발화 구간의 오디오 신호 및 등록 비 발화 구간의 오디오 신호를 사용하여 사용 자 인증을 위한 임계치를 조정하는 방법을 나타낸 도면이다. 도 9는 일부 실시예에 따른 미리 설정된 임계치 테이블 나타낸 도면이다. 도 10은 일부 실시예에 따른 사용자 DB의 업데이트 방법을 나타낸 도면이다. 도 11은 일부 실시예에 따른 비 발화 구간의 오디오 신호 및 등록 비 발화 구간의 오디오 신호를 사용하여 임계 치를 조정하는 방법을 나타낸 도면이다. 도 12는 일부 실시예에 따른 발화 구간의 오디오 신호 및 등록 발화 구간의 오디오 신호를 사용하여 임계치를 조정하는 방법을 나타낸 도면이다. 도 13은 일부 실시예에 따른 복수의 전자 장치가 사용되는 환경을 나타내는 도면이다. 도 14는 일부 실시예에 따른 장치 특성 파라미터 값에 기초하여 조정된 임계치를 사용하여 사용자를 인증하는 방법을 나타낸 흐름도이다. 도 15는 일부 실시예에 따른 사용자 등록 단계에서 사용되는 사용자 인터페이스를 나타낸 도면이다. 도 16은 일부 실시예에 따른 사용자 인증 과정에서 사용되는 사용자 인터페이스를 나타낸 도면이다. 도 17은 일부 실시예에 따른 복수의 사용자에 대한 등록 단계를 나타낸 도면이다. 도 18은 일부 실시예에 따른 복수의 사용자의 대화에 기초한 사용자 인증 과정을 나타낸 도면이다. 도 19는 일부 실시예에 따른 조정된 인증 기준을 사용하여 사용자를 인증하는 방법을 나타낸 흐름도이다. 도 20은 일부 실시예에 따른 전자 장치의 구성을 나타낸 블록도이다. 도 21은 일부 실시예에 따른 전자 장치의 구성을 나타낸 블록도이다. 도 22는 일부 실시예에 따른 전자 장치가 서버를 통해 사용자 인증을 수행하는 방법을 나타낸 흐름도이다. 도 23은 일부 실시예에 따른 서버가 전자 장치를 통해 사용자 인증을 수행하는 방법을 나타낸 흐름도이다. 도 24는 일부 실시예에 따른 전자 장치 및 서버가 사용자 식별 및 사용자 인증을 수행하는 방법을 나타낸 흐름 도이다. 도 25는 일부 실시예에 따른 키워드 검출 모델의 학습 방법을 나타낸 도면이다. 도 26은 일부 실시예에 따른 시간 지연 신경망의 오디오 특징 벡터 처리 방법을 나타낸 도면이다. 도 27은 일부 실시예에 따른 키워드 학습용 레이어의 공유 레이어로부터 출력된 프레임 단위 표현에 대한 처리 과정을 나타낸 도면이다."}
