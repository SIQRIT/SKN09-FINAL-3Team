{"patent_id": "10-2021-0164392", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0077278", "출원번호": "10-2021-0164392", "발명의 명칭": "다중 플랫폼 및 사용자 디바이스의 센싱 데이터에 대한 연계 동기화 및 검색 방법", "출원인": "주식회사 카카오모빌리티", "발명자": "홍승환"}}
{"patent_id": "10-2021-0164392", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "다중 플랫폼 및 사용자 디바이스의 센싱 데이터에 대한 연계 동기화 및 검색 방법에 있어서, 상기 다중 플랫폼 및 상기 사용자 디바이스로부터 취득된 센싱 데이터에 대해 시공간 동기화를 수행하는 단계; 상기 동기화된 센싱 데이터와 관련된 관측값, 기하 파라미터, 변화 데이터를 메타 정보로 등록하고 소정 기준에 따라 상기 메타 정보를 하위 집합군 별로 그룹화하는 단계; 상기 시공간 동기화에 적용된 시공간 정보에 기초하여 상기 하위 집합군에서 연계가능한 데이터 셋을 상기 상위집합군 별로 그룹화하는 단계;상기 상위 집합군의 속성에 따라 상기 데이터셋을 통합 관리하도록 상기 상위 집합군을 최상위 그룹과 연결하는단계; 및 상기 연계가능한 데이터 셋의 탐색을 요구하는 사용자 요청에 따라, 상기 집합군으로 접근하여 상기 연계가능한데이터 셋을 검색하는 단계를 포함하는, 연계 동기화 및 검색 방법."}
{"patent_id": "10-2021-0164392", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 취득된 센싱 데이터에 대해 시공간 동기화를 수행하는 단계는 상기 센싱 데이터를 융합하는 전처리 과정을수행하고, 전처리된 센싱 데이터에 대해 상기 시공간 동기화를 수행하는 것인, 연계 동기화 및 검색 방법."}
{"patent_id": "10-2021-0164392", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 취득된 센싱 데이터에 대해 시공간 동기화를 수행하는 단계 후, 상기 동기화된 센싱 데이터와 매칭되는 기존 센싱 데이터가 존재하는 경우, 상기 동기화된 센싱 데이터로 갱신되며, 상기 그룹화하는 단계 및 상기 연결하는 단계는 상기 갱신된 센싱 데이터에 기반하여 수행되는, 연계 동기화 및 검색 방법."}
{"patent_id": "10-2021-0164392", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 메타 정보를 하위 집합군 별로 그룹화하는 단계는 동기화된 시간 및 동기화된 공간 중 적어도 하나에 따라상기 동기화된 센싱 데이터의 관측값, 기하 파라미터, 변화 데이터를 변환하여 상기 연계가능한 데이터 셋을 생성하고, 상기 데이터 셋에 대한 메타 정보를 하위 집합군 별로 그룹화하는, 연계 동기화 및 검색 방법."}
{"patent_id": "10-2021-0164392", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서, 상기 메타 정보를 하위 집합군 별로 그룹화하는 단계는 동기화된 시간 및 동기화된 공간 중 적어도 하나에 따라상기 동기화된 복수의 센싱 데이터를 융합함과 아울러서 상기 복수의 센싱 데이터에 대해 결합 데이터를 생성하고, 상기 결합 데이터에서 연계가능한 데이터 셋을 결정하며, 상기 데이터 셋에 대한 메타 정보를 하위 집합군공개특허 10-2023-0077278-3-별로 그룹화하는, 연계 동기화 및 검색 방법."}
{"patent_id": "10-2021-0164392", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서, 상기 결합 데이터는 상기 동기화된 시간의 순서 및 상기 동기화된 공간의 정렬 중 적어도 어느 하나에 따른 연속적인 상기 복수의 센싱 데이터에 기반하여 생성되는, 연계 동기화 및 검색 방법."}
{"patent_id": "10-2021-0164392", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서, 상기 검색하는 단계는 상기 사용자 요청에 따른 상기 시공간 동기화의 상기 시공간 정보를 기초로 상기 집합군을 접근하여, 상기 연계가능한 데이터 셋을 탐색하는, 연계 동기화 및 검색 방법."}
{"patent_id": "10-2021-0164392", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서, 상기 검색하는 단계는 상기 사용자 요청에 따른 목적 데이터, 상기 시공간 정보 및 상기 메타 정보에 기초하여상기 목적 데이터 및 상기 데이터 셋을 전처리하고, 상기 전처리된 목적 데이터 및 상기 전처리된 데이터 셋을분석하여 결과 데이터를 생성하는, 연계 동기화 및 검색 방법."}
{"patent_id": "10-2021-0164392", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서, 상기 검색하는 단계 후, 상기 연계가능한 데이터 셋을 편집하거나, 상기 사용자 요청에 따른 머신 러닝 모델에사용하는 상기 연계가능한 데이터 셋을 추출하여 가공하는 단계를 더 포함하는, 연계 동기화 및 검색 방법."}
{"patent_id": "10-2021-0164392", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서, 상기 데이터 셋을 편집하거나, 추출하여 가공하는 단계에서, 상기 편집, 상기 추출 및 가공을 요구하는 사용자요청이 복수인 경우, 서버는 상기 사용자 요청 별로 태스크 영역을 할당하여, 상기 태스크 영역 별로 상기 사용자 요청에 따른 상기 연계가능한 데이터 셋을 로딩하여 처리하는, 연계 동기화 및 검색 방법."}
{"patent_id": "10-2021-0164392", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다중 플랫폼 및 사용자 디바이스의 센싱 데이터에 대한 연계 동기화 및 검색 방법이 개시된다. 상기 연계 동기화 및 검색 방법은, 상기 다중 플랫폼 및 상기 사용자 디바이스로부터 취득된 센싱 데이터에 대해 시공간 동기화를 수행하는 단계; 상기 동기화된 센싱 데이터와 관련된 관측값, 기하 파라미터, 변화 데이터를 메 타 정보로 등록하고 소정 기준에 따라 상기 메타 정보를 하위 집합군 별로 그룹화하는 단계; 상기 시공간 동기화 에 적용된 시공간 정보에 기초하여 상기 하위 집합군에서 연계가능한 데이터 셋을 상기 상위 집합군 별로 그룹화 하는 단계; 상기 상위 집합군의 속성에 따라 상기 데이터셋을 통합 관리하도록 상기 상위 집합군을 최상위 그룹 과 연결하는 단계; 및 상기 연계가능한 데이터 셋의 탐색을 요구하는 사용자 요청에 따라, 상기 집합군으로 접근 하여 상기 연계가능한 데이터 셋을 검색하는 단계를 포함한다."}
{"patent_id": "10-2021-0164392", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 다중 플랫폼 및 사용자 디바이스의 센싱 데이터에 대한 연계 동기화 및 검색 방법에 관한 것이며, 보 다 구체적으로 다중 플랫폼 및 사용자 디바이스로부터 취득된 센싱 데이터에 시공간 동기화와 연결 관계를 통해 다중 플랫폼, 사용자 디바이스, 시스템이 상호 연계가능한 동기화 및 검색 방법에 대한 것이다."}
{"patent_id": "10-2021-0164392", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재까지는 자율주행 센싱에 있어서, 이동체 단독 또는 특정 시스템 단독으로 데이터가 수집되어 활용되고 있다. 특정 알고리즘, 학습모델, 기계 장치 등에 적합하도록 데이터가 설계 개발되어 중복적인 데이터 수집, 가 공, 저장 과정이 수행되어 낭비되는 실정이다.최근에는 V2V, V2I, V2P 등의 V2X를 통해 다양한 플랫폼, 사용자 디바이스 간의 연결된 구조로 작동되는 시스템 개발이 활발히 진행되는 추세이다. 그러나, 종래의 단독 플랫폼에서 수집된 데이터들은 단독 기준 시스템으로 데이터들이 관리되어 서로 간의 연계되기 곤란한 상황이다."}
{"patent_id": "10-2021-0164392", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 기술적 과제는 다중 플랫폼 및 사용자 디바이스로부터 취득된 센싱 데이터에 시공간 동기화와 연결 관계를 통해 다중 플랫폼, 사용자 디바이스, 시스템이 상호 연계가능한 동기화 및 검색 방법을 제공하는데 그 목적이 있다. 본 개시에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2021-0164392", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0164392", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 양상에 따르면, 다중 플랫폼 및 사용자 디바이스의 센싱 데이터에 대한 연계 동기화 및 검색 방법 이 개시된다. 상기 연계 동기화 및 검색 방법은, 상기 다중 플랫폼 및 상기 사용자 디바이스로부터 취득된 센싱 데이터에 대해 시공간 동기화를 수행하는 단계; 상기 동기화된 센싱 데이터와 관련된 관측값, 기하 파라미터, 변화 데이터를 메타 정보로 등록하고 소정 기준에 따라 상기 메타 정보를 하위 집합군 별로 그룹화하는 단계; 상기 시공간 동기화에 적용된 시공간 정보에 기초하여 상기 하위 집합군에서 연계가능한 데이터 셋을 상기 상위 집합군 별로 그룹화하는 단계; 상기 상위 집합군의 속성에 따라 상기 데이터셋을 통합 관리하도록 상기 상위 집 합군을 최상위 그룹과 연결하는 단계; 및 상기 연계가능한 데이터 셋의 탐색을 요구하는 사용자 요청에 따라, 상기 집합군으로 접근하여 상기 연계가능한 데이터 셋을 검색하는 단계를 포함한다. 본 개시의 다른 실시예에 따르면, 상기 취득된 센싱 데이터에 대해 시공간 동기화를 수행하는 단계는 상기 센싱 데이터를 융합하는 전처리 과정을 수행하고, 전처리된 센싱 데이터에 대해 상기 시공간 동기화를 수행할 수 있 다. 본 개시의 또 다른 실시예에 따르면, 상기 취득된 센싱 데이터에 대해 시공간 동기화를 수행하는 단계 후, 상기 동기화된 센싱 데이터와 매칭되는 기존 센싱 데이터가 존재하는 경우, 상기 동기화된 센싱 데이터로 갱신되며, 상기 그룹화하는 단계 및 상기 연결하는 단계는 상기 갱신된 센싱 데이터에 기반하여 수행될 수 있다. 본 개시의 다른 실시예에 따르면, 상기 메타 정보를 하위 집합군 별로 그룹화하는 단계는 동기화된 시간 및 동 기화된 공간 중 적어도 하나에 따라 상기 동기화된 센싱 데이터의 관측값, 기하 파라미터, 변화 데이터를 변환 하여 상기 연계가능한 데이터 셋을 생성하고, 상기 데이터 셋에 대한 메타 정보를 하위 집합군 별로 그룹화할 수 있다. 본 개시의 다른 실시예에 따르면, 상기 메타 정보를 하위 집합군 별로 그룹화하는 단계는 동기화된 시간 및 동 기화된 공간 중 적어도 하나에 따라 상기 동기화된 복수의 센싱 데이터를 융합함과 아울러서 상기 복수의 센싱 데이터에 대해 결합 데이터를 생성하고, 상기 결합 데이터에서 연계가능한 데이터 셋을 결정하며, 상기 데이터 셋에 대한 메타 정보를 하위 집합군 별로 그룹화할 수 있다. 본 개시의 다른 실시예에 따르면, 상기 결합 데이터는 상기 동기화된 시간의 순서 및 상기 동기화된 공간의 정 렬 중 적어도 어느 하나에 따른 연속적인 상기 복수의 센싱 데이터에 기반하여 생성될 수 있다. 본 개시의 다른 실시예에 따르면, 상기 검색하는 단계는 상기 사용자 요청에 따른 상기 시공간 동기화의 상기 시공간 정보를 기초로 상기 집합군을 접근하여, 상기 연계가능한 데이터 셋을 탐색할 수 있다. 본 개시의 다른 실시예에 따르면, 상기 검색하는 단계는 상기 사용자 요청에 따른 목적 데이터, 상기 시공간 정 보 및 상기 메타 정보에 기초하여 상기 목적 데이터 및 상기 데이터 셋을 전처리하고, 상기 전처리된 목적 데이 터 및 상기 전처리된 데이터 셋을 분석하여 결과 데이터를 생성할 수 있다. 본 개시의 다른 실시예에 따르면, 상기 검색하는 단계 후, 상기 연계가능한 데이터 셋을 편집하거나, 상기 사용 자 요청에 따른 머신 러닝 모델에 사용하는 상기 연계가능한 데이터 셋을 추출하여 가공하는 단계를 더 포함할수 있다. 본 개시의 다른 실시예에 따르면, 상기 데이터 셋을 편집하거나, 추출하여 가공하는 단계에서, 상기 편집, 상기 추출 및 가공을 요구하는 사용자 요청이 복수인 경우, 서버는 상기 사용자 요청 별로 태스크 영역을 할당하여, 상기 태스크 영역 별로 상기 사용자 요청에 따른 상기 연계가능한 데이터 셋을 로딩하여 처리할 수 있다."}
{"patent_id": "10-2021-0164392", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 개시에 대하여 위에서 간략하게 요약된 특징들은 후술하는 본 개시의 상세한 설명의 예시적인 양상일 뿐이며, 본 개시의 범위를 제한하는 것은 아니다."}
{"patent_id": "10-2021-0164392", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 다중 플랫폼 및 사용자 디바이스로부터 취득된 센싱 데이터에 시공간 동기화와 연결 관계를 통해 다중 플랫폼, 사용자 디바이스, 시스템이 상호 연계가능한 동기화 및 검색 방법을 제공할 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0164392", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참고로 하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나, 본 개시는 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시의 실시 예를 설명함에 있어서 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그에 대한 상세한 설명은 생략한다. 그리고, 도면에서 본 개시에 대한 설명과 관계없 는 부분은 생략하였으며, 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시에 있어서, 어떤 구성요소가 다른 구성요소와 \"연결\", \"결합\" 또는 \"접속\"되어 있다고 할 때, 이는 직접 적인 연결 관계 뿐만 아니라, 그 중간에 또 다른 구성요소가 존재하는 간접적인 연결관계도 포함할 수 있다. 또 한 어떤 구성요소가 다른 구성요소를 \"포함한다\" 또는 \"가진다\"고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 배제하는 것이 아니라 또 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 개시에 있어서, 제 1, 제 2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용 되며, 특별히 언급되지 않는 한 구성요소들 간의 순서 또는 중요도 등을 한정하지 않는다. 따라서, 본 개시의 범위 내에서 일 실시 예에서의 제 1 구성요소는 다른 실시 예에서 제 2 구성요소라고 칭할 수도 있고, 마찬가지 로 일 실시 예에서의 제 2 구성요소를 다른 실시 예에서 제 1 구성요소라고 칭할 수도 있다. 본 개시에 있어서, 서로 구별되는 구성요소들은 각각의 특징을 명확하게 설명하기 위함이며, 구성요소들이 반드 시 분리되는 것을 의미하지는 않는다. 즉, 복수의 구성요소가 통합되어 하나의 하드웨어 또는 소프트웨어 단위 로 이루어질 수도 있고, 하나의 구성요소가 분산되어 복수의 하드웨어 또는 소프트웨어 단위로 이루어질 수도 있다. 따라서, 별도로 언급하지 않더라도 이와 같이 통합된 또는 분산된 실시 예도 본 개시의 범위에 포함된다. 본 개시에 있어서, 다양한 실시 예에서 설명하는 구성요소들이 반드시 필수적인 구성요소들은 의미하는 것은 아 니며, 일부는 선택적인 구성요소일 수 있다. 따라서, 일 실시 예에서 설명하는 구성요소들의 부분집합으로 구성 되는 실시 예도 본 개시의 범위에 포함된다. 또한, 다양한 실시예에서 설명하는 구성요소들에 추가적으로 다른 구성요소를 포함하는 실시 예도 본 개시의 범위에 포함된다. 이하, 첨부한 도면을 참조하여 본 개시의 실시 예들에 대해서 설명한다. 도 1은 이동체가 네트워크를 통해 다른 장치와 통신을 수행하는 것을 나타낸 도면이다. 도 1을 참조하면, 이동체는 다른 이동체 또는 다른 디바이스와 통신을 수행할 수 있다. 이때, 일 예로, 이동체 는 셀룰라 통신, WAVE 통신, DSRC(Dedicated Short Range Communication) 또는 그 밖에 다른 통신 방식에 기초 하여 다른 이동체 또는 다른 디바이스와 통신을 수행할 수 있다. 즉, 셀룰러 통신망으로서 LTE, 5G와 같은 통신 망, WiFi 통신망, WAVE 통신망 등이 이용될 수 있다. 또한, DSRC와 같이 이동체에서 사용되는 근거리 통신망 등 이 사용될 수 있으며, 상술한 실시예로 한정되지 않는다. 또한, 일 예로, 이동체의 통신과 관련하여, 이동체 보안을 위해 이동체 내부에 위치하는 디바이스만 통신을 수 행할 수 있는 모듈과 이동체 외부 디바이스와 통신을 수행할 수 있는 모듈이 분리되어 존재할 수 있다. 일 예로, 이동체 내부에서는 와이파이 통신처럼 이동체 내의 일정 범위 내의 디바이스에 대해서만 보안에 기초하여 통신을 수행할 수 있다. 일 예로, 이동체와 이동체 운전자의 개인 소유 디바이스는 상호 간의 통신만을 수행하 기 위한 통신 모듈을 포함할 수 있다. 즉, 이동체와 이동체 운전자의 개인 디바이스는 외부 통신망과 차단된 통 신망을 이용할 수 있다. 또한, 일 예로, 이동체는 외부 디바이스와 통신을 수행하는 통신 모듈을 포함할 수 있 다. 또한, 일 예로, 상술한 모듈은 하나의 모듈로 구현될 수 있다. 즉, 하나의 모듈에 기초하여 이동체는 다른 디바이스와 통신을 수행할 수 있으며, 상술한 실시예로 한정되지 않는다. 즉, 이동체에서 통신 방법은 다양한 방법에 기초하여 구현될 수 있으며, 상술한 실시예로 한정되지 않는다. 이때, 이동체는 예를 들어, 이동할 수 있는 디바이스를 지칭할 수 있다. 일 예로, 이동체는 차량 (Autonomous Vehicle, Automated Vehicle 포함), 드론, 개인 모빌리티, 이동 오피스, 이동 호텔 또는 PAV(Personal Air Vehicle) 일 수 있다. 개인 모빌리티는 예컨대 안정적인 독립주행을 위해 적어도 3개의 휠을 포함하는 이동체, 또는 1개 또는 2개의 휠을 구비하더라도 균형을 유지하여 독립적으로 주행될 수 있는 이동체(예, 싱글 휠 세그 웨이, 투 휠 세그웨이, 전동 킥보드 등)를 포함할 수 있다. 개인 모빌리티는 동력원으로 배터리를 이용한 전기 를 사용할 수 있으나, 이에 제한되지 않고 모빌리티를 이동시킬 수 있는 어떠한 형태의 동력원을 활용할 수 있 다. 일 예로, 개인 모빌리티는 한 명의 사용자만이 탑승 또는 이용할 수 있는 이동 수단을 의미할 수 있다. 또 한, 개인 모빌리티는 소형 이동 수단으로 소수의 사용자가 이용할 수 있는 이동 수단을 의미할 수 있다. 일 예 로, 싱글 휠, 투 휠, 세그웨이류 및 전동 킥보드뿐만 아니라 전동 휠체어, 전기 자전거 및 전기 이륜차도 개인 모빌리티가 될 수 있다. 또한, 이동체는 그 밖에 다른 이동하는 장치일 수 있으며, 상술한 실시예로 한정되지 않는다. 또한, 이동체와 데이터 교환 및 통신하는 개체는 외부 디바이스로서, 서버, 사용자 디바이스, 지능형 교통 정보 를 제공하는 다양한 ITS 디바이스 및 다른 이동체 중 적어도 하나일 수 있다. 서버는 지도 정보, 공간 정보 및 기준 데이터를 저장하여 관리하고, 이동체 등의 요청에 따라 이들을 제공할 수 있다. 사용자 디바이스는 스마트 폰, 스마트패드, 스마트 워치 등일 수 있다. 또 다른 일 예로, 디바이스는 기타 통신이 가능하여 신호를 교환할 수 있는 장치를 의미할 수 있으며, 상술한 실시예로 한정되지 않는다. ITS 디바이스는 예를 들어 RSU(Road Side Unit)일 수 있다. RSU는 도로 주변 장치로서 통신이 가능한 장치일 수 있다. 또한, 일 예로, RSU는 건물이나 기 타 지역에 신호를 송수신할 수 있도록 설치된 구조물을 지칭할 수 있으며, 상술한 실시예로 한정되지 않는다. 다만, 하기에서는 설명의 편의를 위해 RSU로 통칭하며, 이에 대해서는 다양한 구조물이나 장치일 수 있으며, 상 술한 실시예로 한정되지 않는다.도 2는 상호 통신하는 이동체 및 서버의 개략적인 모듈을 나타내는 구성도이다. 본 개시에 따른 다중 플랫폼 및 사용자 디바이스의 센싱 데이터에 대한 연계 동기화 및 검색 방법을 구현하는 시스템은 이동형 플랫폼으로서의 이동체, RSU와 같은 고정형 플랫폼, 사용자 디바이스 및 서버로 구 성될 수 있다. 이동체는 주변 환경을 감지하는 다중 센서, 통신부, 입력부, 디스플레이부, 메모리, 이동체의 운행 제어를 실행하는 구동부및 프로세서를 포함할 수 있다. 다중 센서는 관측 센서, 항법 센서, 주행 센서를 구비할 수 있다. 관측 센서는 카메라, 라 이다, 레이더 센서 등을 포함하여 주변 환경을 관측하는 센서들로 구성될 수 있다. 항법 센서는 이동체 의 위치, 방향 정보를 수집할 수 있는 GNSS, IMU 센서, 항법 센서 등을 포함할 수 있다. 주행 센서는 운행 중에 작동되는 이동체의 구동, 조향, 제동 등의 발생 및 동작 정도를 검출하는 다양한 센서를 포함할 수 있다. 주행 센서는 이동체의 동작 과정에서의 주행 상태와 주행 제어 상태를 감지하고, 프로세서 는 감지된 상태 정보에 기반하여, 운행 제어 데이터를 구성하는 다양한 정보를 생성할 수 있다. 카메라 센서는 이동 중인 지상 또는 공중 플랫폼에 탑재되어 그 주위의 주변 대상물, 예컨대 지형, 지물을 이미 지로 촬영하여 영상용 관측 데이터를 취득하는 센서이며, 측량용 또는 비측량용 카메라, 스테레오 카메라일 있 으며, 이에 제한되지 않는다. 라이다 센서(Light Detection and Ranging; LiDAR)는 플랫폼에 탑재되어 그 주위의 대상물과 관련된 3차원 지 리 데이터, 예컨대 지형, 지물 관련 데이터를 획득하여 3차원 측량용 관측 데이터를 취득하는 센서로서, 능동형 원격 탐사용 센서이다. 예를 들어, 라이다 센서는 레이저 또는 초음파 센서 등일 수 있다. 이러한 라이다 센서 는 데이터를 취득하고자 하는 대상물에 레이저를 주사하며 대상물로부터 반사되어 복귀하는 전자파의 시차와 에 너지 변화를 감지하여 대상물에 대한 거리와 반사 강도를 산출한다. 항법 센서는 측위 정보, 플랫폼의 위치, 자세 및 속도 등의 항법 정보를 검출하여 항법용 관측 데이터를 취득하는 센서로서, 위성 항법 장치(GPS)를 통해 플랫폼의 이동 위치를 취득하는 위치 취득 장치와 관성 측정 장치(Inertial Measurement Unit; IMU), 관성 항법 장치(Inertial Navigation System; INS)를 통해 차량의 자 세를 취득하는 자세 취득 장치 등으로 구성될 수 있다. 대 지형, 지물을 이미지로 촬영하여 영상용 관측 데이터 를 취득하는 센서이며, 측량용 또는 비측량용 카메라, 스테레오 카메라일 있으며, 이에 제한되지 않는다. 동일 플랫폼인 이동체의 센서들 간의 기하 정보는 이동체의 주행 중에 취득된 센서 데이터 및 센서에 내재된 고유 정보에 기반하여 도출되는 내부 기하 정보 및 외부 기하 정보를 포함할 수 있다. 각 센서들은 상술 한 정보뿐만 아니라 다른 정보들을 포함할 수 있으며, 각 센서마다 구체적 정보를 예를 들어 설명하면 이하와 같이 열거될 수 있다. 예컨대, 카메라 센서의 경우, 카메라 센서 관련 정보는 IOP (내부기하). EOP (외부기하), 촬영날짜, 촬영시간, 조도, ISO, 셔터스피드, 영상 이름, 폴더 이름, 시간 동기화 정보, 센서 시리얼번호, 렌즈 모델, 센서 모델 등 을 포함할 수 있다. 라이다 센서 관련 정보는 내부 기하정보, 외부 기하정보, 시간 동기화 정보, 레이저 파장, 레이저 강도, 레이저 송수신 시간, 레이저 관측 각/거리, 레이저 펄스, 전자적 지연 시간, 대기 지연 시간, 센서 온도 등을 포함할 수 있다. 항법 센서 관련 정보는 GNSS 센서 모델 정보, IMU 센서 모델 정보, GNSS 수신 정보, GNSS 수신 위성 개수, GNSS 위성 신호 강도, GNSS 네비게이션 정보, 전리층/대류층 신호지연 정보, DOP 정보, 지구자전 관련 정보, 이중/다 중 GNSS 장비 정보, Base station 정보, SBAS 정보, 좌표계 정보, 타원체 정보, 지오이드 정보 등을 포함할 수 있다. 이에 더하여, 항법 센서 관련 정보는 Wheel센서 회전/이동 정보, 자이로 센서 Scale/Bias 정보, 가속도계 Scale/Bias 정보, 위치/자세 정보 및 예상 오차량, 속도/가속도 정보 및 예상 오차량, 각속도/각가속도 정보 및 예상 오차량, 필터링 모델 및 소거 오차 정보, 플랫폼과의 기하 관계 정보, 센서 간 기하 관계 정보, 시간 동기 화 정보 등을 포함할 수 있다. 운행 제어 데이터는 상술한 관측 및 측위 센서 데이터 뿐만 아니라, 이하의 다양한 정보를 추가로 포함할 수 있 다. 주변 정보는 이동체의 카메라, 이동체 주변의 외부 디바이스 또는 서버로부터 수신된 이동체 주변의 객체와 관련된 위치, 종류, 모션, 형상 등에 관한 데이터로 구성될 수 있다. 객체는 정적 객체 혹은 동적 객체 일 수 있다. 정적 객체는 고정 시설물과 같이 이동성을 수반하지 않는 객체일 수 있다. 동적 객체는 사람, 다 른 이동체, 동물과 같이 이동성이 있는 객체일 수 있다. 이벤트 정보는 이동체의 주변 혹은 예상 경로에서 발생된 다양한 상황 정보일 수 있다. 이벤트 정보는 예 컨대, 교통 상황, 사고 상황, 공사 상황, 국지적 기상 상황과 관련된 정보일 수 있다. 지도 정보는 서버의 데이터베이스에 기록될 수 있으며, 도로, 도로 주변의 시설물, 차선 정보 등의 다양한 데이터를 2차원 또는 3차원적으로 표현될 수 있다. 공간 정보는 서버의 데이터베이스에 기록될 수 있으며, 지도 정보와 연관된 3차원 공간 상에 시점 별로 구조화될 수 있다. 구체적으로, 공간 정보는 지도 상의 객체의 이력 정보를 시점 별로 구조화하여 저장할 수 있으며, 차선 단위 또는 cm 단위의 고정밀도로 객체 정보를 기록 할 수 있다. 주행 패턴 정보는 사용자의 이동체 운전 및 사용 패턴, 알고리즘에서 제시한 이동체 경로 및 운행 제어와 관련 된 옵션의 선택 패턴, 특정 동승자의 탑승한 경우의 이동체 사용 패턴 등과 관련된 정보일 수 있다. 주행 패턴 정보는 프로세서가 사용자가 이동체의 입력부 또는 터치 수신가능한 디스플레이부를 통해 선택한 옵션 유형을 분석하여 추정될 수 있다. 또한, 주행 패턴 정보는 사용자 디바이스 또는 이동체로부 터 입력받은 특정 동승자가 탑승한 경우, 사용자가 이용하는 경로, 운전 패턴을 포함하는 주행 패턴을 포함할 수 있다. 또한, 주행 패턴 정보는 이벤트 정보, 기상 정보와 연관되어 사용자가 이용하는 운전 패턴, 경로를 포 함할 수 있다. 통신부는 기준 시스템(200; 이하, 기준 시스템 및 서버는 혼용하여 기재), ITS 디바이스, 다른 이동체와 통신하여, 이동체의 다중 센서로부터 획득되지 않는 운행 제어 데이터를 수신할 수 있다. 서버 또는 외부 디바이스로부터 획득되는 운행 제어 데이터는 이벤트 정보, 경로 속성 정보, 지도 정보, 공간 정보, 기상 정보 등일 수 있다. 입력부 및 디스플레이부는 사용자의 경로 안내 요구를 수신하는 인터페이스를 제공하며, 경로 및 운 행 제어와 관련된 상태 및 경로를 디스플레이할 수 있다. 본 도면에서는 입력부 및 디스플레이부를 별개 모듈로 도시하고 있으나, 터치 입력이 가능한 디스플레이부는 입력부를 포함할 수 있다. 메모리는 운행 제어 데이터를 저장하거나, 외부 호출에 의해 상기 데이터를 제공할 수 있다. 구동부는 프로세서의 제어에 의해, 이동체의 기계적 동작을 실행할 수 있다. 구동부는 전 륜 및 후륜에 동력을 전달하는 동력 계통, 제동 계통, 스티어링에 따른 이동체의 방향을 전달하는 조향 계 통 등일 수 있다. 서버는 이동체를 포함하는 복수의 이동형 플랫폼 및 RSU, 소정 위치에 설치된 에지 디바이스를 포함 하는 고정형 플랫폼과 통신하면서, 다중 플랫폼 및 다중 센서의 데이터를 융합하기 위한 소트웨어 내지 애플리 케이션을 구동하고, 융합에 필요한 지도 및 공간 정보를 저장하여 활용할 수 있다. 서버를 포함하는 기준 시스템 관련 시간 정보, 기하 정보, 공간 정보, 기준 시간계 정보, 기준 좌표계 정 보, 시계 오차 정보, 기하 오차 정보. 캘리브레이션 정보 등을 포함할 수 있다. 본 실시예에서, 이동체과 같은 이동형 플랫폼을 위주로 설명하였으나, 고정형 플랫폼은 구동부를 제 외한 다른 모듈을 포함할 수 있으며, 지도 및 공간 정보에서 고정형 플랫폼의 측위 정보를 보유하는 경우, 항법 센서가 생략될 수도 있다. 도 3은 본 개시에 따른 다중 플랫폼 및 사용자 디바이스의 센싱 데이터에 대한 연계 동기화 및 검색 방법에 적 용되는 서버의 데이터베이스 상에 등록된 데이터들의 집합 체계를 도식화한 도면이다. 서버의 데이터베이스는 다중 플랫폼 및 상기 사용자 디바이스로부터 취득된 센싱 데이터를 시공간 동기화 정보에 따라 연계하며 계층적으로 연결하여 기록할 수 있다. 다중 플랫폼은 이동형 플랫폼 및 고정형 플랫폼일 수 있으며, 플랫폼은 이동, 정지, 설치된 형태의 데이터 수집 시스템으로 특정 데이터 저장소 또는 서버 상에 데이터를 송신한다. 다중 플랫폼의 각각은 카메라, 라이다, 레 이더, 측위, 통신 등의 센서들(102~106)을 하나 이상 포함한 시스템을 탑재할 수 있다. 사용자 디바이스는 사용 자가 도보 및 이동체 중에 소지하는 디바이스로서 예를 들어 스마트폰, 스마트워치, 태블릿, 랩탑 등의 다양한 형태의 컴퓨팅 장치일 수 있다. 데이터 간의 동기화를 위해 각 플랫폼과 설치된 센서들은 특정 시간과 공간에대한 관측값과 설정값을 가질 수 있다. 단독 설치된 센서, 다중 플랫폼, 사용자 디바이스는 각각 데이터를 수집 하며 수집된 데이터들은 상호간의 시간, 공간 값들이 기준 시스템, 즉 서버로 연계하여 동기화될 수 있다. 연계 및 동기화된 데이터들은 서로 간의 연결 정보를 가지고 데이터베이스 상에 저장될 수 있다. 데이터 사용 단계에서는 서버의 기준 데이터 상에 등록된 시간, 공간 값들을 사용하여 시공간 동기화 알고리즘과 관련 파라미터들을 목적 데이터를 검색하여 결합하여 데이터 분석에 활용할 수 있다. 또한, 데이터 간의 시공간 동기화 과정을 단순화하기 위해 데이터 융합 과정들이 일종의 데이터 전처리 과정으 로 수행될 수 있으며, 수행 이후의 데이터들 또는 시공간적 정보를 지니며, 필요 시 프로세스 중간 산출물과 함 께 데이터베이스에 갱신될 수 있다. 시공간 정보들은 시간, 공간 변수들에 대한 변환 과정들을 통해 통합될 수 있으며, 변수들과 변화 정보들이 메타데이터 상에 등록되고, 등록된 메타데이터들은 다수 데이터베이스 간의 동 기화 과정을 통해 정리될 수 있다. 각기 다른 다수의 플랫폼에서 수집 데이터들은 전체 데이터 구조 상에서 각기 다른 집합으로 상에 등록되어 관 리되며, 특정 목적을 지닌 데이터 분석과 정보 추출을 위해 각기 다른 집합의 데이터들이 연계되어 통합 데이터 화되어 분석될 수 있다. 도 3을 참조하면, 하위집합의 데이터들은 수집단계에서의 데이터들과 관련 메타정보들로 정의될 수 있으며, 상 위집합들은 시공간정보를 이용하여 연계된 데이터 집합들이다. 최상위집합은 정의된 데이터셋들을 통합관리하기 위한 집합으로 정의될 수 있다. 여기서, 하위집합, 상위집합 간의 관계 사이에 별도의 집합체계가 존재할 수 있으며, 해당 집합에 대해 비교적 상위집합들을 통해 하위집합 및 데이터들을 검색하여 접근하거나, 또는 하위집합의 상위집합들을 검색하여 접근 할수도 있다. 이와 관련하여, 다중 플랫폼 및 상기 사용자 디바이스로부터 취득된 센싱 데이터가 데이터베이스에 연계하여 관 리되는 과정은 이하와 같다. 서버는 센싱 데이터에 대해 시공간 동기화를 수행하고, 동기화된 센싱 데이터 와 관련된 관측값, 기하 파라미터, 변화 데이터를 메타 정보로 등록하고 소정 기준에 따라 상기 메타 정보를 하 위 집합군 별로 그룹화할 수 있다. 소정 기준은 시공간 동기화에 적용되는 시공간 정보와 관련된 데이터일 수 있다. 시공간 정보에 기초하여 상기 하위 집합군에서 연계가능한 데이터 셋을 상기 상위 집합군 별로 그룹화하 고, 상위 집합군의 속성에 따라 상기 데이터셋을 통합 관리하도록 상기 상위 집합군을 최상위 그룹과 연결할 수 있다. 취득된 센싱 데이터에 대해 시공간 동기화를 수행할 때, 센싱 데이터를 융합하는 전처리 과정을 진행할 수 있다. 전처리 과정은 각 센싱 데이터의 기하 변환, 특정 변환식에 의한 변환, 소정의 기하 모델에 의한 변환, 데이터베이스의 지도 및 공간 정보의 기준 데이터를 참조하여 처리되는 변환 등일 수 있다. 전처리 과정은 예컨 대, 플랫폼 데이터 및 센서 데이터의 사이즈 변환, 회전, 변이, 경계 강화, 특정 객체 추정, 배경 분류, 사물 분류 등의 알고리즘을 적용할 수 있다. 데이터 연계에 있어 데이터 수집 또는 전처리에서 등록된 시간과 공간에 대한 관측값과 설정값들은 시공간 동기화 정보로 사용되어, 관련된 데이터셋들과 이에 포함된 센서 셋을 검색하 는데 활용될 수 있다. 이에 더하여, 취득된 센싱 데이터에 대해 시공간 동기화를 수행한 후, 동기화된 센싱 데이터와 매칭되는 기존 센싱 데이터가 존재하는 경우, 동기화된 센싱 데이터로 갱신되며, 하위 집합군 및 상위 집합군으로의 그룹화 및 최상위 집합군으로의 연결은 갱신된 센싱 데이터에 기반하여 진행될 수 있다. 분석된 데이터도 시공간적 정보를 지니며, 필요 시 프로세스 중간 산출물과 함께 데이터베이스에 갱신될 수 있다. 한편, 센싱 데이터에 대한 연계 동기화하여 집합군 별로 그룹화하기 위해서, 센싱 데이터에 대해 시공간 동기화 도 선행될 수 있다. 시공간 동기화 과정에 대해 이하에서 서술하기로 한다. 서버는 이동형 및 고정형 플랫폼으로부터 센서 데이터, 시간 및 공간 동기화 정보를 수신할 수 있다. 이외에도, 각 플랫폼은 서버에 등록할 각 개체의 식별 및 인증 정보 및 도 2를 통해 상술한 정보들을 서버 로 전송할 수 있다. 다음으로, 서버는 수신한 플랫폼 및 센서 데이터들에 대해 전처리 과정을 수행할 수 있다. 전처리 과정은 예컨대, 플랫폼 데이터 및 센서 데이터의 사이즈 변환, 회전, 변이, 경계 강화, 특정 객체 추정, 배경 분류, 사물 분류 등의 알고리즘을 적용할 수 있다. 이하에서, 플랫폼 데이터 및 센서 데이터는 데이터로약칭하여 설명될 수 있다. 다음으로, 서버는 전처리된 데이터들에 대해 기준 시간계로 동기화할 수 있다. 이하에서는 시간 동기화에 대해 상세히 설명한다. 먼저, 서버는 각 플랫폼의 다중센서 시스템에 탑재된 항법 센서 및 관측 센서로부터 데이터들을 수집할 수 있다. 이어서, 서버은 다중센서 시스템 또는 각 센서 시스템의 시계 모듈 시간을 동기화할 수 있다. 이 때, 관측 센서의 촬영 주기 정보는 엣지 또는 서버의 모듈에 기록될 수 있다. 경우에 따라, 관측 센서의 촬영 주기 정보를 기록하기 위한 별도의 모듈이 설치될 수 있다. 별도의 모듈은 타임 프로토콜 서 버(time protocol)일 수 있으며, 항법 신호 수신기 정보에 기초하여 시간 동기화함으로써, 관측 센서의 촬 영 정보의 촬영 주기 정보와 동기화하는데 사용할 수 있다. 시간 모듈의 시간 동기화와 관련하여 예를 들어 구체적으로 설명하면, 각 플랫폼의 시스템은 카메라, 라이다, 레이더, 레이저 중 적어도 하나를 포함한 관측 센서를 탑재할 수 있으며, 관측 센서의 시계는 시간을 기록 할 수 있다. 기록된 시간들은 각 시계마다의 시간계를 가지고 있으며, 다중 플랫폼, 다중 센서 간의 시간계가 통일 내지 일관되지 않을 수 있다. 이에 따라 센서 시간계를 하나로 통일할 필요성이 있으며, 센서 시간계의 통 일화는 다중 플랫폼마다의 다중 센서에 대한 트리깅 시간을 기록하여 분석하는 방법과, 다중 플랫폼에서의 다중 센서의 시간계를 동기화하여 통일하는 방법 등이 있을 수 있다. 트리깅 시간을 기록하는 방법은 라이다 또는 레이더 센서가 신호를 송수신하는 주기와 영상 촬영 주기를 동기화 하며 각 플랫폼에서 트리깅하여 해당 시간을 기록하는 것일 수 있다. 동일 트리깅을 통해 수집된 데이터들은 동 일 시간에 수집된 데이터로 해당 시간을 기록하여 관리할 수 있다. 또한 다중 플랫폼에서의 다중 센서의 시간을 동기화하는 방식은 서버으로부터 수신된 동기화 신호를 통해, 각 센서 내 탑재된 시계를 동기화시키는 방 식일 수 있다. 센서 모듈의 시계는 서버로부터 교환되는 메시지, 혹은, 서버으로부터 수신하는 일정 주기 신호를 통해서 보정될 수 있다. 서버은 지상에 설치된 별도의 기준 기지국 데이터 뿐만 아니라, 위성 으로부터 보정 신호를 수신하여, 동기화 신호를 보정할 수도 있다. 이어서, 서버는 다중 플랫폼에 탑재된 각 센서의 센서 데이터 시간계가 통일된지 여부를 확인할 수 있다. 센서 데이터 시간계가 통일되지 않으면, 서버는 각 센서의 센서 데이터 시간계를 동일 시간계로 변환할 수 있다. 상기 단계는 시간 동기화에 대한 검수 과정이며, 통일화되지 않는 경우에만 선택적으로 수행될 수 있다. 검수 과정은 센서 트리깅 횟수, 촬영 횟수, 신호 송신 횟수, 신호 수신 횟수, 신호 기록 횟수, 센서 데이터 기록 횟 수 중 적어도 하나의 값을 확인하여, 상기 값과 동기화된 시계 모듈에 기록된 데이터를 비교할 수 있다. 비교 결과, 동일 시간계에 있지 않는 시계 모듈의 시간이 동일 시간계로 적용되도록 변환될 수 있다. 시간 정보 기준의 동기화시 센서 데이터와 항법 정보 간 시간이 정확하게 일치하지 않음에 따라, 시간에 대한 내삽/외삽 과정이 수행될 수 있다. 예를 들어, 도 5에서와 같이, 동일 시간계에서 수집된 데이터도 각 데이터의 수집 샘플링(Sampling) 시간이 서로 상이하여, 샘플링 시간들이 동기화될 필요성이 있다. 이를 위한 시간 동기 화는 내삽(interpolation)/외삽(exterpolation) 과정으로 진행될 수 있으며, 이 때, 플랫폼의 항법 (Navigation) 정보들도 함께 활용될 수 있다. 이를 통해, 기준 시간축을 참조하여 정의된 시간 정보들이 하나의 시간 값을 갖도록 동기화될 수 있으며, 이는 비록 다른 시점에서 데이터가 수집되었을지라도 한 시점에서 수집 된 데이터로 해석되어 처리될 수 있다. 센서 데이터 시간계가 통일되면, 서버는 기록된 각 관측, 항법 센서들(102, 104)의 시간의 프레임 동기화 수행 및 동일 시간에 수집된 센서 데이터들의 연관 관계를 결정할 수 있다. 다음으로, 서버는 다중센서 시스템 기하 모델을 기준으로 시간 정보 기반 동기화 데이터의 공간 동기화를 수행할 수 있다. 여기서, 공간 동기화는 다중 플랫폼의 다중 센서 각각이 보유하는 시공간 정보에 기반하여 진 행될 수 있다. 정의된 시간동기화 결과와 사전에 정의된 공간 동기화 정보를 통해서 센서들 간의 동기화 과정을 우선 수행할 수 있다. 결과를 확인하고, 다음으로, 서버는 공간 동기화된 데이터에 대해 오차 여부를 확인할 수 있다. 오차가 발생한 경우, 시간 및 공간 동기화에 대한 편위 값(offset)이 공간 동기화된 데이터에 적용될 수 있다. 오차 검수는 예를 들어, 아래 두가지 방법이 적용될 수 있다. 오차 검수는 3차원 기준 데이터와 지오레퍼런싱 (Georeferencing)된 관측 센서 데이터 간 비교 방법이 있을 수 있다. 서버에 저장된 지도 및 공간 정보의 기준 객체의 정보와 센서 데이터에서 취득되어 3차원적으로 지오레퍼런싱된 객체 정보를 비교하여 오차를 검수 할 수 있다. 다른 예로, 오차 검수는 다중센서 시스템 내 데이터들을 상호 비교하는 방법이 있을 수 있다. 예컨 대 동일 공간으로 추정되는 다중 플랫폼의 카메라, 라이다 센서로부터 취득된 센서 데이터를 비교가능하도록 변 환하여 특징 객체를 기준으로 비교함으로써, 오차를 검수할 수 있다. 오차 검수에 의해 공간 동기화 오차가 제거되거나, S235 단계에서 공간 동기화 오차가 없는 것으로 확인된 경우, 시간 동기화 프로세스가 완료될 수 있다. 이와 같이, 시간 동기화 프로세스 완료 후, 서버는 시간 동기화된 데이터를 기준 공간계로 동기화할 수 있 다. 이는 다중 플랫폼의 다중 센서의 각 데이터에 대한 기하학적 해석에 기반하여 수행될 수 있다. 이와 관련한 설명에 앞서, 공간 동기화 프로세스를 개념적으로 이해하기 위해, 기하 모델과 파라미터를 이용한 공간 동기화 프로세스를 서술하기로 한다. 공간 동기화는 다중 센서 내 또는 다중 센서 간 정의되는 기하모델을 기반으로 수행되며, 경우에 따라, 지상 기 준좌표계과의 기하관계식을 정의하여 적용할 수 있다. 다중 플랫폼에 적용된 다중 센서 시스템에서, 동작 중인 관측 센서 간의 기하는 특정 기하모델을 통해 정의될 필요가 있다. 여기서 3차원의 좌표계에 존재하는 사 물이 센서의 좌표계에 투영될 때, 우선적으로 기하는 기본적으로 각 축에 대한 거리 값으로 정의되는 직교 좌표 계 또는 수평/수직각과 거리 값으로 정의되는 구면 좌표계의 기하로 표현될 수 있다. 데이터 기록 형태는 좌표 계 변환의 최종 단계 또는 중간 단계에서 저장될 수 있으며, 데이터 용량 압축을 위해 내삽 프로세스를 전제한 데이터 형태로 저장될 수 있다. 영상 형태로 저장될 경우에는 공선조건식과 같이 일정 면에 투영되는 기하 모델을 기준으로 정의될 수 있다. 이 때, 센서 데이터의 왜곡이 발생을 감소시키기 위해 보정 파라미터를 포함한 기하식을 추가 적용할 수 있다. 다중 센서들의 공간 동기화는 센서들 간의 위치 및 자세 값에 대한 변환을 기반으로 하거나 별도의 기하식을 통 해 수행될 수 있다. 또한, 공간 동기화에서, 항법 센서에 기록된 플랫폼 이동 정보를 통해 관측 정보들은 절대 좌표계로 등록될 수 있다. 일반적으로, 공간 동기화를 위한 파라미터들은 센서 시스템의 설계 사양로부터 획득 될 수 있으나, 더욱 정밀한 공간 동기화를 위해 캘리브레이션 과정을 수행할 수도 있다. 또한, 기하 파라미터 의해 센서 간 동기화 오차가 캘리브레이션 작업만으로 수행되지 않을 경우, 오차는 시간에 특정 오프셋(offset) 값을 포함하여 보정할 수 있다. 이하에서는, 이상의 공간 동기화 프로세스에 대해 상세히 설명하기로 한다. 동기화 오차는 다중 플랫폼의 다중 센서의 데이터 상에 오차가 예상될 때만 수행될 수 있다. 도 8은 데이터 변환의 일예로, 모든 변환 프로세스는 단일 식으로도 표현 및 수행이 가능하다. 단일 프로세스 적용 시에는 오차 확인 및 정보 보정은 단일 프로세스 로 가능하다. RSU와 같이 고정형 플랫폼일 경우 항법 정보가 포함되지 않을 수 있다. 우선, 서버는 다중 플랫폼들의 센서들 간의 동기화를 과정 수행을 위해, 시간 동기화된 데이터를 수신하여, 각 데이터와 관련된 센서 내부 정보에 대한 데이터를 변환할 수 있다. 내부 정보에 대한 데이터 변환은 예컨대, 어안, 광각렌즈 등에서 주로 나타나는 방사왜곡 등에 대한 보정일 수 있다. 라이다 센서의 경우 예를 들면, 라이다 센서의 수직각, 수평각에 대한 변환을 통한 3차원 좌표 산출일 수 있다. 레이더 센서의 경우 예를 들면, 레이저에 의해 반사된 신호 처리를 통해 물체가 인지되고, 해당 물체에 대한 위치 및 속도 데이터로 변환하기 위한 정보들일 수 있다. 다음으로, 서버는 센서들의 각 데이터와 관련된 센서 외부 정보에 대한 데이터를 변환할 수 있다. 센서 외부 변수는 예컨대, 각 센서의 위치, 자세, 스케일(scale) 정보를 포함할 수 있다. 센서 데이터는 센서 외부 정보를 통해, 2차원 내지는 3차원 변환이 수행될 수 있다. 각 센서들의 외부 정보에 의한 변환을 통해, 센 서 데이터는 통일 좌표계로 투영 또는 변환되어 동기화될 수 있다. 이어서, 서버는 센서들의 외부 정보에 대한 데이터의 변환에 의해, 기하 변환된 센서 데이들의 동기화에 오차가 있는지를 확인할 수 있다. 동기화 오차 확인은 통일 좌표계로 투영 또는 변환된 결과를 확인하여, 센서 데이터들 및 기준 객체의 데이터와 의 이격량을 확인할 수 있다. 이격량 확인 시 영상 내에 투영 또는 3차원 공간 상에 투영시켜 확인할 수 있다. 확인된 이격량이 소정의 제 1 오차 임계치를 초과할 경우, 센서 외부 정보에 오차가 있는 것으로 예측한 경우,서버는 센서 외부 정보에 대한 보정을 수행할 수 있다. 센서 외부 정보의 보정으로도 오차가 제 2 오차 임 계치를 초과할 경우, 서버는 외부 정보와 함께, 센서 내부 정보를 보정할 수 있다. 센서 내부/외부 정보들 을 보정할 때, 서버는 확인된 이격량을 최소 또는 최적화하여 내부 정보 및 외부 정보들을 보정할 수 있다. 다음으로, 동기화 오차가 없거나 보정되면, 서버는 다중 플랫폼의 항법 센서에 대한 센서 데이터를 변환 할 수 있다. 항법 정보는 GNSS/INS, 비콘, RFID, UWB 와 같은 측위 정보를 활용하거나, 센서 데이터를 기준데이터와 정합하 여 산출한 정보를 통해 수집한다. 항법 정보는 지도 등 기준좌표계 상의 플랫폼의 위치, 자세 정보를 포함할 수 있다. 서버는 항법 정보를 통해, 센서 데이터들을 실제 환경에서의 기준 좌표계로 투영 또는 변환되어 동 기화될 수 있다. 변환 데이터들은 지도 등 기준 데이터 상에 투영되어 활용될 수 있다. 이어서, 서버는 항법 센서를 기준으로 변환된 센서 데이터에 오차가 있는지를 확인할 수 있다. 동기화 오차 확인은 기준 좌표계 상에 투영 또는 변환 결과를 확인하여 그 이격량을 확인할 수 있다. 이격량 확 인시 지상기준점 등 플랫폼 외부에서 수집된 기준 데이터를 활용할 수 있다. 다음으로, 서버는 항법 정보로 인한 센서 데이터에 오차가 있는 경우, 우선적으로 항법 정보를 보정할 수 있다. 이 단계는 센서 데이터의 오차 원인을 분석하는 과정을 포함할 수 있다. 오차 원인 분석은 확인된 오차 내지 이격량이 제 3 오차 임계치를 초과할 경우, 오차 원인의 분석 결과에 따라, 항법 정보의 보정, 센서 데이 터의 내부 및 외부 정보에 대한 보정을 수행할 수 있다. 항법 정보 보정은 예를 들어, 다른 시간에 수집된 데이 터와의 비교 등 독립적으로 구축된 기준 데이터와의 이격량을 비교하며 수행할 수 있다. 다른 예로 내부, 외부, 항법 정보들을 보정할 경우, 서버는 확인된 이격량을 최소 또는 최적화하여 해당 정보들을 보정할 수 있다. 다음으로, 서버는 다중 플랫폼에서 변환된 다중 센서의 데이터를 동기화할 수 있다. 다중센서 데이터 동기화는 데이터 간의 융합 활용에 있어 센서 내부/외부 정보와 항법 정보를 활용하여 수행할 수 있다. 일례로, 3차원 점군 데이터를 2차원 영상 데이터의 동기화함에 있어서, 투영 관계는 공선조건식 (Collinearity Equation)을 통해 정의하여 수행할 수 있다. 이 때 항법 정보, 센서 외부/내부 정보, 시간 동기 화 정보들이 활용될 수 있다. 이어서, 서버는 동기화된 다중 센서의 데이터 간에 오차가 있는지를 확인할 수 있다. 오차가 있는 경우, 서버는 데이터 동기화 오차 요인을 분석하여, 센서 외부 정보 및 센서 내부 정보에 대 한 데이터 변환, 항법 정보에 대한 데이터 변환 중 오차가 발생된 변환을 탐색할 수 있다. 탐색 결과에 따라, 서버는 해당 변환 별 보정 작업을 수행할 수 있다. 오차가 보정되거나 동기화된 다중센서 데이터 간에 오차가 없는 경우, 공간 동기화 프로세스는 완료될 수 있다. 앞서 설명한 시간 및 공간 동기화 프로세스가 완료된 후, 상기 프로세스가 완료된 다중 플랫폼의 다중 센서의 데이터를 지도 정보의 지도 좌표계로 동기화할 수 있다. 이어서, 서버는 지도 좌표계로 동기화된 데이터 간의 연계 관계를 정의할 수 있다. 연계 관계는 서버(20 0)에 저장되는 지도 및 공간 정보에 구조화되어 저장될 수 있다. 연계 관계는 다중 플랫폼마다의 카메라 센서, 라이다 센서, 항법 센서, 시스템 정보를 구성하는 상술의 데이터들 중 적어도 하나를 해당 위치 및 시점 별로 지도 및 공간 정보에 기록하도록 구성될 수 있다. 다음으로, 서버는 연계된 센서 데이터 간에 시공간 오차가 있는지를 확인하여, 있는 경우 연계된 센서 데 이터와 관련된 내부 및 외부 정보, 항법 정보에 대하여 보정을 수행하여, 시스템 캘리브레이션을 수행할 수 있 다. 다음으로, 보정에 따라 시스템이 캘리브레이션되면, 서버는 센서 데이터의 시간, 공간 동기화 정보를 갱신 할 수 있다. 도 4는 본 개시에 따른 다중 플랫폼 및 사용자 디바이스의 센싱 데이터에 대한 연계 동기화 및 검색 방법에서, 사용자 요청에 따라 연계 데이터를 검색하는 과정을 나타낸 도면이다. 도 4에서는, 사용자가 연계 데이터들을 검색 및 분석 시에 데이터베이스로부터 목적 데이터들을 검색, 전처리하 고 분석 과정을 수행하여 결과들을 제공받고, 중간 산출물과 분석 결과물을 데이터베이스 상에 등록하는 과정에 대한 개념을 예시하고 있다. 서버의 데이터베이스 상에 등록된 데이터들은 수집, 전처리, 가공, 결합, 분석 등의 단계에서 등록된 시공 간 동기 정보를 통해 연계되어 각각의 데이터셋 형태로 추출되어 활용될 수 있다, 구체적으로, 서버는 사용자 디바이스로부터 전송된 사용자 요청에 따른 상기 시공간 동기화의 상기 시공간 정보를 기초로 최상위, 상위 및 하위 집합군을 접근하여, 연계가능한 데이터 셋을 검색할 수 있다. 검색은 사용 자 요청에 따른 목적 데이터, 시공간 정보 및 상기 메타 정보에 기초하여 목적 데이터 및 데이터 셋을 전처리하 고, 전처리된 목적 데이터 및 상기 전처리된 데이터 셋을 분석하여 결과 데이터를 생성할 수 있다. 도 5는 융합 데이터와 센서 데이터가 시공간 동기 정보를 통해 연계되어 생성된 데이터 셋을 예시한 도면이다. 도 6은 시계열적으로 정렬된 복수의 동기화된 센서 데이터에 기반하여 결합 데이터를 생성하여 데이터 셋을 구 축하는 과정을 예시한 도면이다 도 5에서의 데이터들은 해당 데이터 수집에서 사용된 센서에 대한 정보들을 함께 가지고 있어 시공간 동기 및 연계 데이터 검색 과정 중에 사용될 수 있다. 시간의 흐름에 따라 센서는 주기 또는 비주기적으로 데이터들을 수집하게 되며, 수집된 각 센서 데이터들(센서 #)도 시공간 동기화 정보들을 포함할 수 있다. 시공간 동기화 정보들을 통해 연계된 센서 데이터들(센서 #)은 센서 결합(sensor fusion) 과정을 통해 새로운 형태의 결합 데이터(데이터 #)를 생성할 수 있다. 이 때, 데이터 가 가지고 있는 센서 정보들을 연결하여 센서 결합 정보를 추출 또는 생성할 수 있으며, 연속된 데이터셋들은 해당 센서 결합 정보를 사용하여 새로운 형태의 결합 데이터(데이터 #)를 생성하게 된다. 구체적으로, 동기화된 시간에 따라 동기화된 복수의 센싱 데이터(센서 #)를 융합함과 아울러서 복수의 센싱 데이터에 대해 결합 데이 터(데이터 #)를 생성하고, 결합 데이터에서 연계가능한 데이터 셋을 결정하며, 데이터 셋에 대한 메타 정보를 하위 집합군 별로 그룹화할 수 있다. 일례로, 카메라-라이다 간의 데이터 결합 시에는 3차원, 2차원 간의 변환 관계를 통해 센서 결합 정보들이 생성 될 수 있으며, 깊이 영상, 색상 점군 등의 형태로 결합 데이터가 원본 데이터의 수집 시간에 따라 생성될 수 있 다. 이 때, 원본 데이터의 수집시간이 일치하지 않을 경우에는 기준 시점에 대한 별도의 시간 리샘플링(time resampling) 과정이 수행될 수도 있다. 다른 예로, 라이다-측위 데이터 간의 결합 시에는 3차원 변환관계를 통해 라이다 데이터가 지도 정보를 포함하 거나 관측 대상물에 대한 절대위치정보를 포함할 수 있다. 이 때, 연속적으로 수집된 라이다 데이터들이 절대위 치 정보로 변환됨에 따라 하나의 기준 절대좌표를 지닌 기준 공간계 내에서 시계열적 데이터들이 등록되어 하나 의 점군 데이터셋을 구성할 수 있다. 또한, 절대좌표를 지닌 기준 공간계 상에 등록된 데이터는 일종의 지도 정보와 같은 역할을 수행할 수 있으며, 서로 다른 시간과 공간 상에서 수집된 센서 및 데이터들도 공간 동기화를 통해 등록되어 활용될 수 있다. 이 때, 기준 공간계는 2차원 또는 3차원의 좌표계로 표현될 수 있으며, 시간 정보 또한 포함될 수 있다. 도 6을 참조하면, 서버가 동기화된 시간(t, t-1, t+1, t+2) 및 공간 중 적어도 하나에 따라 동기화된 복수 의 센싱 데이터를 융합함과 아울러서 복수의 센싱 데이터(센서 #)에 대해 결합 데이터(결합데이터 #1-#2(t), 결 합데이터 #1-#2 (t+1))를 생성하는 과정에서, 결합 데이터(결합데이터 #1-#2(t), 결합데이터 #1-#2 (t+1))가 동 기화된 시간의 순서(t, t-1, t+1, t+2) 및 동기화된 공간의 정렬 중 적어도 어느 하나에 따른 연속적인 복수의 센싱 데이터에 기반하여 생성될 수도 있다. 이후, 서버는 결합 데이터에서 연계가능한 데이터 셋을 결정하 며, 데이터 셋에 대한 메타 정보를 하위 집합군 별로 그룹화할 수 있다. 도 7은 복수의 공간계 상에 수집된 센서 데이터와 융합 데이터가 공간 동기화를 통해 기준 공간계에서 생성된 데이터 셋을 예시한 도면이다 서버의 공간 동기화 모듈은 서버의 지도 및 공간 정보에서 채용하는 기준 공간계(동기화된 공간계 #1, 2)에 근거하여, 복수의 센싱 데이터(센서 #)를 융합함과 아울러서 복수의 센싱 데이터에 대해 결합 데이터 (데이터 #)를 생성할 수 있다. 이후, 서버는 결합 데이터에서 연계가능한 데이터 셋을 결정하며, 데이터 셋에 대한 메타 정보를 하위 집합군 별로 그룹화할 수 있다. 도 8은 본 개시에 따른 다중 플랫폼 및 사용자 디바이스의 센싱 데이터에 대한 연계 동기화 및 검색 방법에서, 편집 작업자 및 모델 개발자에 의한 사용자 요청에 의해 데이터 셋을 편집, 가공하는 과정을 모듈화하여 나타낸도면이다. 서버는 사용자 요청에 따라 연계가능한 데이터 셋을 편집하거나, 머신 러닝 모델에 사용하는 연계가능한 데이터 셋을 추출하여 가공할 수 있다. 시공간 동기화를 통해 연계된 센서와 데이터들이 데이터 서버 상에 등록된 경우, 다수의 사용자들이 서버 에 접속하여 각기 다른 데이터 편집 및 분석을 수행할 수 있다. 그 예로, 연계 데이터를 이용하여 인공지능 모 델을 개발하고 모델 학습용 데이터를 편집할 때, 다수의 데이터 편집 작업자들과 다수의 모델 개발자들이 동시 에 서버 상에 접속하여 각자의 작업을 수행할 수 있다. 도 9는 다수 사용자들의 요청 별로 할당된 서버의 태스크 영역을 통해 복수 사용자 요청이 수행되는 것을 예시 한 도면이다. 도 9는 다수 사용자들이 임시 저장소와 데이터 서버를 통해 작업한 데이터가 동기화를 통해 할당 된 저장소에 등록되는 것을 보여주고 있다 데이터 셋을 편집하거나, 추출하여 가공하는 때, 서버는 편집, 추출 및 가공을 요구하는 사용자 요청이 복 수인 경우, 서버는 사용자 요청 별로 태스크 영역(저장소 #1, 2)을 할당하여, 태스크 영역 별로 사용자 요 청에 따른 상기 연계가능한 데이터 셋을 로딩하여 처리할 수 있다. 구체적으로, 다수의 사용자들이 동시적 작업을 수행하는데 있어서 데이터 및 데이터셋들이 하위집합 또는 상위 집합 형태로 다수 존재함에 따라, 각기 다른 저장소를 임시로 할당하여 작업이 수행될 수 있다. 임시 할당된 저 장소에서 시간 주기, 사용자 입력 등의 특정 이벤트를 통해 동기화 서버를 작동시키면, 생성 및 수정된 데이터 들에 대한 동기화가 이루어지며, 할당된 저장소에 각기 등록될 수 있다. 본 개시의 예시적인 방법들은 설명의 명확성을 위해서 동작의 시리즈로 표현되어 있지만, 이는 단계가 수행되는 순서를 제한하기 위한 것은 아니며, 필요한 경우에는 각각의 단계가 동시에 또는 상이한 순서로 수행될 수도 있 다. 본 개시에 따른 방법을 구현하기 위해서, 예시하는 단계에 추가적으로 다른 단계를 포함하거나, 일부의 단 계를 제외하고 나머지 단계를 포함하거나, 또는 일부의 단계를 제외하고 추가적인 다른 단계를 포함할 수도 있 다. 본 개시의 다양한 실시 예는 모든 가능한 조합을 나열한 것이 아니고 본 개시의 대표적인 양상을 설명하기 위한 것이며, 다양한 실시 예에서 설명하는 사항들은 독립적으로 적용되거나 또는 둘 이상의 조합으로 적용될 수도 있다. 또한, 본 개시의 다양한 실시 예는 하드웨어, 펌웨어(firmware), 소프트웨어, 또는 그들의 결합 등에 의해 구현 될 수 있다. 하드웨어에 의한 구현의 경우, 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 범용 프로세서(general processor), 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 본 개시의 범위는 다양한 실시 예의 방법에 따른 동작이 장치 또는 컴퓨터 상에서 실행되도록 하는 소프트웨어 또는 머신-실행가능한 명령들(예를 들어, 운영체제, 애플리케이션, 펌웨어(firmware), 프로그램 등), 및 이러한 소프트웨어 또는 명령 등이 저장되어 장치 또는 컴퓨터 상에서 실행 가능한 비-일시적 컴퓨터-판독가능 매체 (non-transitory computer-readable medium)를 포함한다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2021-0164392", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 이동체가 네트워크를 통해 다른 디바이스와 통신을 수행하는 것을 나타낸 도면이다. 도 2는 상호 통신하는 이동체 및 서버의 개략적인 모듈을 나타내는 구성도이다. 도 3은 본 개시에 따른 다중 플랫폼 및 사용자 디바이스의 센싱 데이터에 대한 연계 동기화 및 검색 방법에 적 용되는 서버의 데이터베이스 상에 등록된 데이터들의 집합 체계를 도식화한 도면이다. 도 4는 본 개시에 따른 다중 플랫폼 및 사용자 디바이스의 센싱 데이터에 대한 연계 동기화 및 검색 방법에서, 사용자 요청에 따라 연계 데이터를 검색하는 과정을 나타낸 도면이다. 도 5는 융합 데이터와 센서 데이터가 시공간 동기 정보를 통해 연계되어 생성된 데이터 셋을 예시한 도면이다. 도 6은 시계열적으로 정렬된 복수의 동기화된 센서 데이터에 기반하여 결합 데이터를 생성하여 데이터 셋을 구 축하는 과정을 예시한 도면이다 도 7은 복수의 공간계 상에 수집된 센서 데이터와 융합 데이터가 공간 동기화를 통해 기준 공간계에서 생성된 데이터 셋을 예시한 도면이다 도 8은 본 개시에 따른 다중 플랫폼 및 사용자 디바이스의 센싱 데이터에 대한 연계 동기화 및 검색 방법에서, 편집 작업자 및 모델 개발자에 의한 사용자 요청에 의해 데이터 셋을 편집, 가공하는 과정을 모듈화하여 나타낸 도면이다. 도 9는 다수 사용자들의 요청 별로 할당된 서버의 태스크 영역을 통해 복수 사용자 요청이 수행되는 것을 예시 한 도면이다."}
