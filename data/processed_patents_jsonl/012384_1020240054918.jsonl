{"patent_id": "10-2024-0054918", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0158166", "출원번호": "10-2024-0054918", "발명의 명칭": "컴퓨팅 환경에서의 협력적 콘텐츠 생성을 위한 시스템 및 방법", "출원인": "티엠알더블유 파운데이션 아이피 에스에이알엘", "발명자": "예를리 세바트"}}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠(collaborative content) 생성을 실행하기 위한 방법으로서,콘텐츠 생성 시스템에 의해, 제1 사용자로부터 제1 입력과 제2 사용자로부터 제2 입력을 수신하는 단계,입력 퓨전 시스템에 의해, 머신 러닝 모델을 사용함으로써 상기 제1 입력 및 상기 제2 입력을 분석하여 듀플리케이트(duplicate) 데이터, 리던던시(redundancy) 데이터, 및/또는 프롬프트(prompt) 데이터의 존재를 결정하는단계,상기 제1 입력 및 상기 제2 입력 중, 적어도 하나로부터 상기 프롬프트 데이터의 존재를 결정 시, 상기 입력 퓨전 시스템에 의해, 상기 프롬프트 데이터를 액션 생성 시스템에 송신하는 단계,상기 액션 생성 시스템에 의해, 상기 프롬프트 데이터 및 상기 머신 러닝 모델에 기초하여 제1 액션 데이터를생성하는 단계, 및상기 액션 생성 시스템에 의해, 상기 제1 액션 데이터에 기초하여 상기 컴퓨팅 환경에서 제1 액션을 실행하는단계를 포함하는, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 방법."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 입력 및 상기 제2 입력 중, 적어도 하나 내에서 상기 듀플리케이트 데이터의 존재를 결정 시, 상기 입력 퓨전 시스템에 의해, 상기 제1 입력 및 상기 제2 입력 중, 적어도 하나로부터 상기 듀플리케이트 데이터를제거하는 단계를 더 포함하는, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 방법."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제1 입력 및 상기 제2 입력 중, 적어도 하나 내에서 상기 듀플리케이트 데이터 및 상기 리던던시 데이터의존재를 결정 시, 상기 입력 퓨전 시스템에 의해, 상기 제1 입력 및 상기 제2 입력 중, 적어도 하나로부터 상기듀플리케이트 데이터 및 상기 리던던시 데이터를 제거하는 단계를 더 포함하는, 인공 지능을 사용하여 컴퓨팅환경에서 협력적 콘텐츠 생성을 실행하기 위한 방법."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제1 입력 및 상기 제2 입력 중, 적어도 하나는 텍스트 데이터를 포함하는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 방법."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 입력 퓨전 시스템에 의해, 상기 제1 입력 및 상기 제2 입력 중, 적어도 하나를 컨버트된 데이터로 컨버트하는 단계를 더 포함하되,상기 제1 입력 및 상기 제2 입력 중, 적어도 하나는 이미지 데이터, 오디오 데이터, 및 햅틱 데이터 중, 적어도하나를 포함하고, 상기 컨버트된 데이터는 컨버트된 텍스트 데이터를 포함하는 것인, 인공 지능을 사용하여 컴공개특허 10-2024-0158166-3-퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 방법."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 듀플리케이트 데이터 또는 상기 리던던시 데이터의 존재를 결정 시, 상기 입력 퓨전 시스템에 의해, 상기컨버트된 텍스트 데이터로부터 상기 듀플리케이터 데이터 및 상기 리던던시 데이터 중, 적어도 하나에 대응하는텍스트 데이터를 제거하는 단계를 더 포함하는, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을실행하기 위한 방법."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 머신 러닝 모델은 직접적인 사용자 입력 또는 간접적인 사용자 입력에 기초하여 상기 듀플리케이트데이터, 상기 리던던시 데이터, 및/또는 상기 프롬프트 데이터의 존재를 결정하는 것을 용이하게 하는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 방법."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 컴퓨팅 환경은 가상 환경인 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기위한 방법."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 컴퓨팅 환경은 증강 환경인 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기위한 방법."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 제1 액션은 상기 가상 환경의 공간에서 엘리먼트를 생성하거나 수정하는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 방법."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 엘리먼트는 시각적 엘리먼트 및 오디오 엘리먼트 중, 적어도 하나인 것인, 인공 지능을 사용하여 컴퓨팅환경에서 협력적 콘텐츠 생성을 실행하기 위한 방법."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 제1 입력과 상기 제2 입력은 동기적으로(synchronously) 수신되는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 방법."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 제1 입력과 상기 제2 입력은 비동기적으로(asynchronously) 수신되는 것인, 인공 지능을 사용하여 컴퓨팅환경에서 협력적 콘텐츠 생성을 실행하기 위한 방법."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공개특허 10-2024-0158166-4-제1항에 있어서,상기 콘텐츠 생성 시스템에 의해, 상기 제1 사용자 또는 상기 제2 사용자에게 그래픽 인터페이스를 디스플레이하기 위한 신호를 생성하는 단계;상기 콘텐츠 생성 시스템에 의해, 상기 제1 사용자 또는 상기 제2 사용자로부터 선택 커맨드를 수신하는 단계;및상기 콘텐츠 생성 시스템에 의해, 상기 선택 커맨드에 기초하여 상기 컴퓨팅 환경에서 사용자 생성 엘리먼트를제공하는 단계를 더 포함하되,상기 그래픽 인터페이스는 조정가능한 타임라인을 포함하고,상기 선택 커맨드는 상기 조정가능한 타임라인 상의 시구간을 선택하며, 그리고상기 사용자 생성 엘리먼트는 상기 시구간에 기초하여 상기 콘텐츠 생성 시스템에 의해 선택되는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 방법."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 컴퓨터 시스템으로서,명령어들을 저장하는 메모리; 및동작들을 수행하기 위해 상기 명령어들을 실행하도록 구성된 하나 이상의 프로세서를 포함하며,상기 동작들은:콘텐츠 생성 시스템에 의해, 제1 사용자로부터 제1 입력과 제2 사용자로부터 제2 입력을 수신하는 동작,입력 퓨전 시스템에 의해, 머신 러닝 모델을 사용함으로써 상기 제1 입력 및 상기 제2 입력을 분석하여 듀플리케이트 데이터, 리던던시 데이터, 및/또는 프롬프트 데이터의 존재를 결정하는 동작,상기 제1 입력 및 상기 제2 입력 중, 적어도 하나로부터 상기 프롬프트 데이터의 존재를 결정 시, 상기 입력 퓨전 시스템에 의해, 상기 프롬프트 데이터를 액션 생성 시스템에 송신하는 동작,상기 액션 생성 시스템에 의해, 상기 프롬프트 데이터 및 상기 머신 러닝 모델에 기초하여 제1 액션 데이터를생성하는 동작, 및상기 액션 생성 시스템에 의해, 상기 제1 액션 데이터에 기초하여 상기 컴퓨팅 환경에서 제1 액션을 실행하는동작을 포함하는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 컴퓨터 시스템."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 동작들은 상기 듀플리케이트 데이터의 존재를 결정 시, 상기 입력 퓨전 시스템에 의해, 상기 제1 입력 및상기 제2 입력 중, 적어도 하나로부터 상기 듀플리케이트 데이터를 제거하는 동작을 더 포함하는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 컴퓨터 시스템."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 동작들은 상기 듀플리케이트 데이터 및 상기 리던던시 데이터의 존재를 결정 시, 상기 입력 퓨전 시스템에의해, 상기 제1 입력 및 상기 제2 입력 중, 적어도 하나로부터 상기 듀플리케이트 데이터 및 상기 리던던시 데이터를 제거하는 동작을 더 포함하는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 컴퓨터 시스템."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서,공개특허 10-2024-0158166-5-상기 제1 입력 및 상기 제2 입력 중, 적어도 하나는 텍스트 데이터를 포함하는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 컴퓨터 시스템."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항에 있어서,상기 동작들은 상기 입력 퓨전 시스템에 의해, 상기 제1 입력 및 상기 제2 입력 중, 적어도 하나를 컨버트된 데이터로 컨버트하는 동작을 더 포함하되,상기 제1 입력 및 상기 제2 입력 중, 적어도 하나는 이미지 데이터, 오디오 데이터, 및 햅틱 데이터 중, 적어도하나를 포함하고,상기 컨버트된 데이터는 컨버트된 텍스트 데이터를 포함하는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 컴퓨터 시스템."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 동작들은 상기 듀플리케이트 데이터 또는 상기 리던던시 데이터의 존재를 결정 시, 상기 입력 퓨전 시스템에 의해, 상기 컨버트된 텍스트 데이터로부터 상기 듀플리케이터 데이터 및 상기 리던던시 데이터 중, 적어도하나에 대응하는 텍스트 데이터를 제거하는 동작을 더 포함하는, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적콘텐츠 생성을 실행하기 위한 컴퓨터 시스템."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제15항에 있어서,상기 머신 러닝 모델은 직접적인 사용자 입력 또는 간접적인 사용자 입력에 기초하여 상기 듀플리케이트데이터, 상기 리던던시 데이터, 및/또는 상기 프롬프트 데이터의 존재를 결정하는 것을 용이하게 하는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 컴퓨터 시스템."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제15항에 있어서,상기 컴퓨팅 환경은 가상 환경인 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기위한 컴퓨터 시스템."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제15항에 있어서,상기 컴퓨팅 환경은 증강 환경인 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기위한 컴퓨터 시스템."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제22항에 있어서,상기 제1 액션은 상기 가상 환경의 공간에서 엘리먼트를 생성하거나 수정하는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 컴퓨터 시스템."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제24항에 있어서,상기 엘리먼트는 시각적 엘리먼트 및 오디오 엘리먼트 중, 적어도 하나인 것인, 인공 지능을 사용하여 컴퓨팅환경에서 협력적 콘텐츠 생성을 실행하기 위한 컴퓨터 시스템."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "공개특허 10-2024-0158166-6-제15항에 있어서,상기 제1 입력과 상기 제2 입력은 동기적으로 수신되는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 컴퓨터 시스템."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제15항에 있어서,상기 제1 입력과 상기 제2 입력은 비동기적으로 수신되는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적콘텐츠 생성을 실행하기 위한 컴퓨터 시스템."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "컴퓨터 시스템의 하나 이상의 프로세서에 의해 실행될 때, 상기 컴퓨터 시스템으로 하여금 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 방법을 수행하게 하는 명령어들을 저장하는 비일시적인 컴퓨터 판독가능 매체로서,상기 방법은:콘텐츠 생성 시스템에 의해, 제1 사용자로부터 제1 입력과 제2 사용자로부터 제2 입력을 수신하는 단계,입력 퓨전 시스템에 의해, 머신 러닝 모델을 사용함으로써 상기 제1 입력 및 상기 제2 입력을 분석하여 듀플리케이트 데이터, 리던던시 데이터, 및 프롬프트 데이터 중, 적어도 하나를 검출하는 단계,상기 제1 입력 및 상기 제2 입력 중, 적어도 하나로부터 상기 프롬프트 데이터를 검출 시, 상기 입력 퓨전 시스템에 의해, 상기 프롬프트 데이터를 액션 생성 시스템에 송신하는 단계,상기 액션 생성 시스템에 의해, 상기 프롬프트 데이터 및 상기 머신 러닝 모델에 기초하여 제1 액션 데이터를생성하는 단계, 및상기 액션 생성 시스템에 의해, 상기 제1 액션 데이터에 기초하여 상기 컴퓨팅 환경에서 제1 액션을 실행하는단계를 포함하는 것인, 비일시적인 컴퓨터 판독가능 매체."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "인공 지능을 사용하여 컴퓨팅 환경에서 콘텐츠 생성을 실행하기 위한 방법으로서,콘텐츠 생성 시스템에 의해, 제1 입력 및 제2 입력을 수신하는 단계,입력 퓨전 시스템에 의해, 머신 러닝 모델을 사용함으로써 상기 제1 입력 및 상기 제2 입력을 분석하여 듀플리케이트 데이터, 리던던시 데이터, 및/또는 프롬프트 데이터의 존재를 결정하는 단계,상기 제1 입력 및 상기 제2 입력 중, 적어도 하나로부터 상기 프롬프트 데이터의 존재를 결정 시, 상기 입력 퓨전 시스템에 의해, 상기 프롬프트 데이터를 액션 생성 시스템에 송신하는 단계,상기 액션 생성 시스템에 의해, 상기 프롬프트 데이터 및 상기 머신 러닝 모델에 기초하여 제1 액션 데이터를생성하는 단계, 및상기 액션 생성 시스템에 의해, 상기 제1 액션 데이터에 기초하여 상기 컴퓨팅 환경에서 제1 액션을 실행하는단계를 포함하는, 인공 지능을 사용하여 컴퓨팅 환경에서 콘텐츠 생성을 실행하기 위한 방법."}
{"patent_id": "10-2024-0054918", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제29항에 있어서,상기 제1 입력과 상기 제2 입력은 비동기적으로 수신되는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 콘텐츠생성을 실행하기 위한 방법.공개특허 10-2024-0158166-7-청구항 31 제29항에 있어서,상기 제1 입력과 상기 제2 입력은 동기적으로 수신되는 것인, 인공 지능을 사용하여 컴퓨팅 환경에서 콘텐츠 생성을 실행하기 위한 방법."}
{"patent_id": "10-2024-0054918", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 방법, 본 방법은 콘텐츠 생성 시스 템에 의해, 제1 사용자로부터 제1 입력과 제2 사용자로부터 제2 입력을 수신하는 단계, 입력 퓨전 시스템에 의해, 머신 러닝 모델을 사용함으로써 제1 입력 및 제2 입력을 분석하여 듀플리케이트(duplicate) 데이터, 리던 던시(redundancy) 데이터, 및/또는 프롬프트(prompt) 데이터의 존재를 결정하는 단계, 제1 입력 및 제2 입력 중, 적어도 하나로부터 프롬프트 데이터의 존재를 결정 시, 입력 퓨전 시스템에 의해, 프롬프트 데이터를 액션 생성 시스템에 송신하는 단계, 액션 생성 시스템에 의해, 프롬프트 데이터 및 머신 러닝 모델에 기초하여 제1 액션 데 이터를 생성하는 단계, 및 액션 생성 시스템에 의해, 제1 액션 데이터에 기초하여 컴퓨팅 환경에서 제1 액션을 실행하는 단계를 포함한다."}
{"patent_id": "10-2024-0054918", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 컴퓨팅 환경에서 콘텐츠를 생성하는 것에 관한 것이며, 더 구체적으로는, 다수의 사용자들이 가상 환 경에서 향상된 창의적인(creative) 능력 및/또는 효과로 콘텐츠를 공동 생성할 수 있게 하기 위해 인공 지능을 사용하여 협력적(collaborative) 콘텐츠 생성을 실행하기 위한 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2024-0054918", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재의 기술들은 인공 지능(AI)이 특정 활동을 수행할 수 있게 하기 위해 인간 사용자가 AI를 포함하는 컴퓨터 프로그램에 (예를 들어, 음성 또는 타이핑을 통해) 특정 커맨드를 제공할 수 있게 한다. AI에 의해 수행되는 활 동들 중 일부는 AI 알고리즘의 특정 레벨의 트레이닝을 필요로 하는 창의적인 활동이다. 예를 들어, 기존의 AI 플랫폼들(예를 들어, Siri, ChatGPT, DALL-E, Mid-Journey, Stable Diffusion 등)은 모두, 사용자의 요청에 응 답하는 콘텐츠를 생성하는 데 사용될 수 있는 컴퓨터 모델을 트레이닝한다. 특히, 인간들은 본래 사회적 존재이고, 많은 경우에, 함께 상호작용하고 콘텐츠를 생성할 때 인간의 창의적인 능력이 향상된다. 그러나, 현재의 시스템들 및 방법들은 인간들이 AI 컴퓨터 모델의 도움으로 공동 생성할 수 있게 하지 않는다. 대신, 현재의 시스템들 및 방법들은 개별 레벨에서 일어나는 생성에 중점을 둔다. 따라서, 개발 중인 AI 기술의 도움으로 다수의 사용자들 간에 협력적으로 달성될 수 있는 생성의 사회적이고 창의적인 양태들은 제한된다. 예를 들어, 현재의 AI 플랫폼들(예를 들어, Siri, ChatGPT, DALL-E, Mid-Journey, Stable Diffusion 등)을 이용하는 기술들은 음성을 텍스트로 컨버트(convert)하고 텍스트를 서버에 제출할 수 있으며, 여기서 음성 대 텍스트 컨버전이 에지 또는 클라우드에서 일어날 수 있다. 그런 다음, 서버는 텍스트를 AI에 전 송될 수 있다. 대안적으로는, 사용자가 AI에 전송될 하나 이상의 프롬프트(prompt)를 컴퓨터에 수동으로 타이핑 하고 입력할 수 있고, 일부 시스템은 사용자의 입력에 기초하여 이미지 또는 상이한 유형의 콘텐츠를 생성할 수 있다. 그러나, 기존의 모든 시스템들은 단지 단일 사용자로부터 입력 커맨드를 캡처하고 입력 커맨드를 대응하 는 액션으로 트랜스레이트(translate)할 뿐이다. 즉, 기존의 시스템들 중 어느 것도 다수의 사용자들에 의해 콘 텐츠를 생성하는 협력적이고 창의적인 양태를 가능하게 하지 않는다. 본 개시는 이러한 위에서 언급된 과제들 및 결점들 중 하나 이상을 극복하는 것에 관한 것이다. 본 명세서에서 제공되는 배경 설명은 본 개시의 맥락을 일반적으로 제시하기 위한 것이다. 본 명세서에서 달리 나타내어지지 않는 한, 본 섹션에서 설명되는 자료는 본 출원의 청구범위에 대한 종래 기술이 아니고, 이 섹션에 포함됨으로 써 종래 기술 또는 종래 기술의 시사인 것으로 자인하는 것이 아니다. 본 개시의 특정 양태들에 따르면, 다수의 사용자들이 가상 환경에서 향상된 창의적인 능력 및/또는 효과로 콘텐 츠를 공동 생성할 수 있게 하기 위해 인공 지능을 사용하여 협력적 콘텐츠 생성을 실행하기 위한 시스템 및 방 법들이 제공된다. 일 양태에 따르면, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 방법이 제공된 다. 본 방법은 콘텐츠 생성 시스템에 의해, 제1 사용자로부터 제1 입력과 제2 사용자로부터 제2 입력을 수신하 는 단계; 입력 퓨전(fusion) 시스템에 의해, 머신 러닝 모델을 사용함으로써 제1 입력 및 제2 입력을 분석하여 듀플리케이트(duplicate) 데이터, 리던던시(redundancy) 데이터, 및/또는 프롬프트 데이터의 존재를 결정하는 단계; 제1 입력 및 제2 입력 중, 적어도 하나로부터 프롬프트 데이터의 존재를 결정 시, 입력 퓨전 시스템에 의 해, 프롬프트 데이터를 액션 생성 시스템에 송신하는 단계; 액션 생성 시스템에 의해, 프롬프트 데이터 및 머신 러닝 모델에 기초하여 제1 액션 데이터를 생성하는 단계; 및 액션 생성 시스템에 의해, 제1 액션 데이터에 기초 하여 컴퓨팅 환경에서 제1 액션을 실행하는 단계를 포함할 수 있다.다른 양태들에서, 본 명세서에서 설명되는 방법들 중 임의의 방법은 다음의 단계들 또는 특징들 중 임의의 것을 포함할 수 있다. 입력 퓨전 시스템은 제1 입력 및 제2 입력 중, 적어도 하나 내에서 듀플리케이트 데이터의 존 재를 결정 시 제1 입력 및 제2 입력 중, 적어도 하나로부터 듀플리케이트 데이터를 제거할 수 있다. 입력 퓨전 시스템은 제1 입력 및 제2 입력 중, 적어도 하나 내에서 듀플리케이트 데이터 및 리던던시 데이터의 존재를 결 정 시 제1 입력 및 제2 입력 중, 적어도 하나로부터 듀플리케이트 데이터 및 리던던시 데이터를 제거할 수 있다. 제1 입력 및 제2 입력 중, 적어도 하나는 텍스트 데이터를 포함할 수 있다. 입력 퓨전 시스템은 제1 입력 및 제2 입력 중, 적어도 하나를 컨버트된 데이터로 컨버트할 수 있다. 제1 입력 및 제2 입력 중, 적어도 하나는 이미지 데이터, 오디오 데이터, 및 햅틱 데이터 중, 적어도 하나를 포함할 수 있다. 컨버트된 데이터는 컨버트 된 텍스트 데이터를 포함할 수 있다. 입력 퓨전 시스템은 듀플리케이터 데이터 또는 리던던시 데이터의 존재를 결정 시 컨버트된 텍스트 데이터로부터 듀플리케이터 데이터 및 리던던시 데이터 중, 적어도 하나에 대응하는 텍스트 데이터를 제거할 수 있다. 머신 러닝 모델은 직접적인 사용자 입력 또는 간접적인 사용자 입력에 기초하 여 듀플리케이트 데이터, 리던던시 데이터, 및/또는 프롬프트 데이터의 존재를 결정하는 것을 용이하게 할 수 있다. 컴퓨팅 환경은 가상 환경일 수 있다. 컴퓨팅 환경은 증강 환경일 수 있다. 제1 액션은 가상 환경의 공간 에서 엘리먼트를 생성하거나 수정하는 것일 수 있다. 엘리먼트는 시각적 엘리먼트 및 오디오 엘리먼트 중, 적어 도 하나일 수 있다. 제1 입력과 제2 입력은 동기적으로(synchronously) 수신될 수 있다. 제1 입력과 제2 입력은 비동기적으로(asynchronously) 수신될 수 있다. 콘텐츠 생성 시스템은 제1 사용자 또는 제2 사용자에게 그래픽 인터페이스를 디스플레이하기 위한 신호를 생성할 수 있다. 콘텐츠 생성 시스템은 제1 사용자 또는 제2 사용자 로부터 선택 커맨드를 수신할 수 있다. 콘텐츠 생성 시스템은 선택 커맨드에 기초하여 컴퓨팅 환경에서 사용자 생성 엘리먼트를 제공할 수 있다. 그래픽 인터페이스는 조정가능한 타임라인을 포함할 수 있다. 선택 커맨드는 조정가능한 타임라인 상의 시구간을 선택할 수 있다. 사용자 생성 엘리먼트는 시구간에 기초하여 콘텐츠 생성 시스템에 의해 선택될 수 있다. 일 양태에 따르면, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 컴퓨터 시스템 이 제공될 수 있다. 컴퓨터 시스템은 명령어들을 저장하는 메모리. 및 동작들을 수행하기 위해 명령어들을 실행 하도록 구성된 하나 이상의 프로세서를 포함할 수 있다. 동작들은 콘텐츠 생성 시스템에 의해, 제1 사용자로부 터 제1 입력과 제2 사용자로부터 제2 입력을 수신하는 동작, 입력 퓨전 시스템에 의해, 머신 러닝 모델을 사용 함으로써 제1 입력 및 제2 입력을 분석하여 듀플리케이트 데이터, 리던던시 데이터, 및/또는 프롬프트 데이터의 존재를 결정하는 동작, 제1 입력 및 제2 입력 중, 적어도 하나로부터 프롬프트 데이터의 존재를 결정 시, 입력 퓨전 시스템에 의해, 프롬프트 데이터를 액션 생성 시스템에 송신하는 동작, 액션 생성 시스템에 의해, 프롬프 트 데이터 및 머신 러닝 모델에 기초하여 제1 액션 데이터를 생성하는 동작, 및 액션 생성 시스템에 의해, 제1 액션 데이터에 기초하여 컴퓨팅 환경에서 제1 액션을 실행하는 동작을 포함할 수 있다. 다른 양태들에서, 본 명세서에서 설명되는 시스템들 중 임의의 방법은 다음의 단계들 또는 특징들 중 임의의 것 을 포함할 수 있다. 입력 퓨전 시스템은 듀플리케이트 데이터의 존재를 결정 시 제1 입력 및 제2 입력 중, 적어 도 하나로부터 듀플리케이트 데이터를 제거할 수 있다. 입력 퓨전 시스템은 듀플리케이트 데이터 및 리던던시 데이터의 존재를 결정 시 제1 입력 및 제2 입력 중, 적어도 하나로부터 듀플리케이트 데이터 및 리던던시 데이 터를 제거할 수 있다. 제1 입력 및 제2 입력 중, 적어도 하나는 텍스트 데이터를 포함할 수 있다. 입력 퓨전 시 스템은 제1 입력 및 제2 입력 중, 적어도 하나를 컨버트된 데이터로 컨버트할 수 있다. 제1 입력 및 제2 입력 중, 적어도 하나는 이미지 데이터, 오디오 데이터, 및 햅틱 데이터 중, 적어도 하나를 포함할 수 있다. 컨버트 된 데이터는 컨버트된 텍스트 데이터를 포함할 수 있다. 입력 퓨전 시스템은 듀플리케이터 데이터 또는 리던던 시 데이터의 존재를 결정 시 컨버트된 텍스트 데이터로부터 듀플리케이터 데이터 및 리던던시 데이터 중, 적어 도 하나에 대응하는 텍스트 데이터를 제거할 수 있다. 머신 러닝 모델은 직접적인 사용자 입력 또는 간접적인 사용자 입력에 기초하여 듀플리케이트 데이터, 리던던시 데이터, 및/또는 프롬프트 데이터의 존재를 결정하는 것을 용이하게 할 수 있다. 컴퓨팅 환경은 가상 환경일 수 있다. 컴퓨팅 환경은 증강 환경일 수 있다. 제1 액션 은 가상 환경의 공간에서 엘리먼트를 생성하거나 수정하는 것일 수 있다. 엘리먼트는 시각적 엘리먼트 및 오디 오 엘리먼트 중, 적어도 하나일 수 있다. 제1 입력과 제2 입력은 동기적으로 수신될 수 있다. 제1 입력과 제2 입력은 비동기적으로 수신될 수 있다. 일 양태에 따르면, 비일시적인 컴퓨터 판독가능 매체는 컴퓨터 시스템의 하나 이상의 프로세서에 의해 실행될 때, 컴퓨터 시스템으로 하여금 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 방 법을 수행하게 하는 명령어들을 저장할 수 있다. 본 방법은 콘텐츠 생성 시스템에 의해, 제1 사용자로부터 제1 입력과 제2 사용자로부터 제2 입력을 수신하는 단계, 입력 퓨전 시스템에 의해, 머신 러닝 모델을 사용함으로써제1 입력 및 제2 입력을 분석하여 듀플리케이트 데이터, 리던던시 데이터, 및 프롬프트 데이터 중, 적어도 하나 를 검출하는 단계, 제1 입력 및 제2 입력 중, 적어도 하나로부터 프롬프트 데이터를 검출 시, 입력 퓨전 시스템 에 의해, 프롬프트 데이터를 액션 생성 시스템에 송신하는 단계, 액션 생성 시스템에 의해, 프롬프트 데이터 및 머신 러닝 모델에 기초하여 제1 액션 데이터를 생성하는 단계, 및 액션 생성 시스템에 의해, 제1 액션 데이터에 기초하여 컴퓨팅 환경에서 제1 액션을 실행하는 단계를 포함할 수 있다. 일 양태에 따르면, 인공 지능을 사용하여 컴퓨팅 환경에서콘텐츠 생성을 실행하기 위한 방법이 제공될 수 있다. 본 방법은 콘텐츠 생성 시스템에 의해, 제1 입력 및 제2 입력을 수신하는 단계, 입력 퓨전 시스템에 의해, 머신 러닝 모델을 사용함으로써 제1 입력 및 제2 입력을 분석하여 듀플리케이트 데이터, 리던던시 데이터, 및/또는 프롬프트 데이터의 존재를 결정하는 단계, 제1 입력 및 제2 입력 중, 적어도 하나로부터 프롬프트 데이터의 존 재를 결정 시, 입력 퓨전 시스템에 의해, 프롬프트 데이터를 액션 생성 시스템에 송신하는 단계, 액션 생성 시 스템에 의해, 프롬프트 데이터 및 머신 러닝 모델에 기초하여 제1 액션 데이터를 생성하는 단계, 및 액션 생성 시스템에 의해, 제1 액션 데이터에 기초하여 컴퓨팅 환경에서 제1 액션을 실행하는 단계를 포함할 수 있다. 다른 양태들에서, 본 명세서에서 설명되는 방법들 중 임의의 방법은 다음의 단계들 또는 특징들 중 임의의 것을 포함할 수 있다. 제1 입력과 제2 입력은 비동기적으로 수신될 수 있다. 제1 입력과 제2 입력은 동기적으로 수신 될 수 있다. 전술한 일반적인 설명과 다음의 상세한 설명 둘 모두는 대표적이고 설명적일 뿐이고, 청구되는 바와 같이, 본 발명을 제한하지 않는다는 것이 이해될 수 있다."}
{"patent_id": "10-2024-0054918", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다음의 실시예들은 다수의 사용자들이 컴퓨팅 환경(예를 들어, 증강 현실 환경, 가상 현실 환경, 및 2차원(2D) 또는 3차원(3D) 시뮬레이션된 환경)에서 향상된 창의적인 능력 및/또는 효과로 콘텐츠를 공동 생성할 수 있게 위해 인공 지능을 사용하여 협력적 콘텐츠 생성을 실행하기 위한 시스템들 및 방법들을 설명한다. 위에서 설명 된 바와 같이, 기존의 시스템들은 AI 기능을 개별 레벨에서 이용한다. 즉, 사용자는 AI 시스템에 하나 이상의 입력 커맨드를 제공할 수 있고, AI 시스템은 솔루션 또는 응답을 제한적이고 단방향적인(unidirectional) 접근 법으로 제공한다. 이와 같이, 현재, 인공 지능 플랫폼을 이용하는 컴퓨팅 환경에서 다수의 사용자들에 의한 협 력적 콘텐츠 생성을 용이하게 하기 위한 기술적 솔루션은 없다. 이와 같이, 다수의 사용자들 간의 공동 생성을 자연적으로 가능하게 할 수 있는, 창의적인 기능들을 협력적 레벨에서 달성하기 위한 다방향적 (multidirectional)이고 동기적인 접근법을 용이하게 할 수 있는 시스템 및 방법들에 대한 필요성이 존재한다. 다수의 사용자들 간의 이러한 협력적 상호작용은 사용자들이 단순히 서로 대화를 나누는 듯한 느낌을 생성할 수 있다. 즉, 본 개시의 시스템들 및 방법들은 컨버전 동안 중요한 키워드를 자동적이고 직관적으로 검출하여, 키워드를 사용자에 의해 요구되는 컴퓨팅 환경(예를 들어, 증강 현실 환경, 가상 현실 환경, 및 2차원(2D) 또는 3 차원(3D) 시뮬레이션된 환경)에서 창의적인 액션으로 컨버트할 수 있다. 추가적으로, 본 시스템들 및 방법들은 하나 이상의 창의적인 세션 동안 단일 사용자 또는 다수의 사용자들로부터 다수의 형태들의 입력을 동기적으로 또는 비동기적으로 검출하여, 개별적 또는 협력적 콘텐츠 생성을 위한 반복적인 창의적인 제안을 제공하기 위한 사용자 입력의 지속적인(persistent) AI 지원 프로세싱을 용이하게 할 수 있다. 따라서, 본 개시의 시스템들 및 방법들은 창의적인 세션이 트레이닝된 머신 러닝 시스템 또는 모듈에 의해 비통상적인 방식으로 구동될 수 있게 하기 위한 직관적이고 효율적인 프로세스, 뿐만 아니라 인터페이스를 제공함으로써 컴퓨팅 환경에서 하나 이상 의 사용자의 콘텐츠 생성 및 협력적 상호작용을 상당히 개선한다. 다음의 실시예들은 복수의 사용자들이 인공 지능 기반 절차적 기술을 사용하여 컴퓨팅 환경(예를 들어, 증강 현 실 환경, 가상 현실 환경, 및 2차원(2D) 또는 3차원(3D) 시뮬레이션된 환경)에서 콘텐츠를 동기적으로 또는 비 동기적으로 공동 생성할 수 있게 하기 위한 시스템들 및 방법들을 설명한다. 본 개시의 양태들에 따르면, 본 시 스템들 및 방법들은 하나 이상의 사용자로부터의 입력 데이터의 캡처를 용이하게 할 수 있다. 입력 데이터는 오 디오 데이터(예를 들어, 음성, 오디오 파일 등), 햅틱 데이터, 텍스트 데이터, 이미지 데이터, 비디오 데이터, 또는 임의의 다른 유형의 데이터를 동기적으로 또는 비동기적으로 포함할 수 있지만, 이에 제한되는 것은 아니 다. 본 개시의 시스템들 및 방법들은 데이터를 텍스트 데이터로 컨버트하고, 데이터를 분석하고, 데이터를 클리 닝(cleaning)하고, 데이터로부터 프롬프트를 추출하고, 프롬프트를 컴퓨팅 환경에서 창의적인 효과를 갖는 창의 적인 액션으로 컨버트하여 창의적인 작업 또는 콘텐츠를 생성하는 것을 용이하게 할 수 있다. 본 개시의 양태들 에 따르면, 데이터를 클리닝하기 위한 프로세스는 예를 들어, 텍스트로부터 불필요한 데이터를 제거하는 것(예 를 들어, 듀플리케이트 및 리던던시를 제거하는 것)을 포함할 수 있다. 창의적인 효과는 그래픽일 수 있으며, 이는 컴퓨팅 환경에서 형상, 형태, 색상, 밝기(예를 들어, 광 또는 광의 강도를 추가 또는 제거), 치수, 엘리먼 트(예를 들어, 가구) 등을 변경하기 위해 하나 이상의 그래픽 이미지를 트랜스레이트하는 것을 포함할 수 있다. 추가적으로 또는 대안적으로, 창의적인 효과는 음악 작곡, 미술 작업, 텍스트북, 비디오 게임 제작, 건축 설계, 책 제작, 물품 제조, 및/또는 그래픽 디자인(예를 들어, 기업을 위한 가상 환경의 생성)에 기초할 수 있다. 컴퓨팅 환경 또는 컴퓨팅 환경의 특정 영역은 창의적인 효과가 적용될 수 있는 화이트 캔버스와 유사하게 기능 할 수 있다. 이러한 창의적인 효과는 실시간으로 또는 실시간에 가깝게 표면들 또는 공간들 중 하나 이상에 제 공될 수 있다. 추가적으로, 본 개시의 시스템들 및 방법들은 컴퓨팅 환경의 사용자에게 하나 이상의 창의적인 제안을 제공할 수 있으며, 여기서 각 제안은 특정 입력에 기초하여 특정 사용자에 관한 것일 수 있다. 따라서, 본 개시의 시스템들 및 방법들은 하나 이상의 머신 러닝 모델을 이용함으로써 하나 이상의 사용자가 컴퓨팅 환 경에서 콘텐츠를 생성하고 다른 사용자와 상호작용할 수 있는 방식을 개선한다. 이제, 본 설명의 대상은 그 일부를 형성하고, 예시를 통해 특정 대표적인 실시예들을 도시하는 첨부 도면을 참 조하여 더 충분하게 설명될 것이다. 본 명세서에서 \"대표적인\"으로서 설명되는 실시예 또는 구현예는 예를 들어, 다른 실시예 또는 구현예에 비해 바람직하거나 유리한 것으로 해석되어서는 안되며; 그보다, 실시예(들) 가 \"예시적인\" 실시예(들)\"임을 반영하거나 나타내는 것으로 의도된다. 대상은 다양한 상이한 형태들로 구현될 수 있고, 이에 따라, 다뤄지거나 청구되는 대상은 본 명세서에서 제시되는 임의의 대표적인 실시예들로 제한되 지 않는 것으로 해석되도록 의도되며; 대표적인 실시예들은 단지 예시적인 것일 뿐이다. 마찬가지로, 청구되거 나 다뤄지는 대상에 대한 합리적으로 넓은 범위가 의도된다. 다른 것들 중에서도, 예를 들어, 대상은 방법, 디 바이스, 컴포넌트, 또는 시스템으로서 구현될 수 있다. 따라서, 실시예들은, 예를 들어, 하드웨어, 소프트웨어, 펌웨어, 또는 이들의 임의의 조합(소프트웨어 그 자체 이외)의 형태를 취할 수 있다. 이에 따라, 다음의 상세한 설명은 제한적인 의미로 취해지도록 의도되지 않는다. 명세서 및 청구범위 전반에 걸쳐, 용어들은 명시적으로 언급되는 의미를 넘어 맥락상 시사되거나 암시되는 미묘 한 의미를 가질 수 있다. 마찬가지로, 본 명세서에서 사용되는 \"일 실시예에서\"라는 문구가 반드시 동일한 실시 예를 지칭하는 것은 아니고 본 명세서에서 사용되는 \"다른 실시예에서\"라는 문구가 반드시 상이한 실시예를 지 칭하는 것은 아니다. 예를 들어, 청구되는 대상은 대표적인 실시예들의 조합을 전체적으로 또는 부분적으로 포 함하는 것으로 의도된다. 아래에서 사용되는 용어는 본 개시의 특정 예에 대한 상세한 설명과 함께 사용되더라도, 가장 광범위한 합리적 인 방식으로 해석될 수 있다. 실제로, 특정 용어들이 아래에서 강조될 수도 있지만, 임의의 제한된 방식으로 해 석되도록 의도되는 임의의 용어는 본 상세한 설명 섹션에서 명시적으로 그리고 구체적으로 정의될 것이다. 전술 한 일반적인 설명과 다음의 상세한 설명 둘 모두는 대표적이고 설명적일 뿐이고, 청구되는 바와 같이, 본 특징을 제한하지 않는다. 본 개시에서, \"~에 기초\"라는 용어는 \"~에 적어도 부분적으로 기초\"를 의미한다. 단수 형태는 문맥이 달리 지시 하지 않는 한 복수의 대상들을 포함한다. \"대표적인\"이라는 용어는 \"이상적인(ideal)\"보다는 \"예시적인 (example)\"이라는 의미로 사용된다. \"~ 중\"이라는 용어는 포괄적인 것으로 의도되고, 나열된 항목들 중 어느 하 나의 항목, 임의의 항목, 여러 항목들, 또는 모든 항목들을 의미한다. \"포함한다\", \"포함하는\", \"포함하다\", \" 포함한\", 또는 이의 다른 활용형은 엘리먼트들의 리스트를 포함하는 프로세스, 방법, 또는 제품이 반드시 이들 엘리먼트들만을 포함하는 것이 아니라, 그러한 프로세스, 방법, 물품, 또는 장치에 내재하거나 명시적으로 나열 되지 않은 다른 엘리먼트를 포함할 수 있도록 비배타적인 포함을 다루도록 의도된다. \"실질적으로\" 및 \"일반적 으로\"와 같은 상대적인 용어들은 명시되거나 이해되는 값의 ±10%의 가능한 편차를 나타내기 위해 사용된다. 이제 첨부된 도면들을 참조하면, 도 1은 본 개시의 하나 이상의 실시예에 따른, 예시적인 환경(또는 시스템 (들))의 개요를 도시한다. 환경은 예를 들어, 네트워크 시스템(들) 및 협력적 콘텐츠 생성 시스 템(들))과 통신하도록 구성된 제1 사용자 디바이스(들) 및 제2 사용자 디바이스(들)를 포함할 수 있다. 환경에서 두 개의 사용자 디바이스(들)(110 및 120)가 도시되어 있지만, 환경에는 네트워크 시스템(들) 및/또는 협력적 콘텐츠 생성 시스템(들)과 동기적으로 또는 비동기적으로 통신하고, 본 개시에 따른, 다수의 사용자들의 협력적 콘텐츠 생성에 참여하기 위한 추가적인 사용자 디바이스들이 제공될 수 있다. 본 개시의 양태들에 따르면, 네트워크 시스템(들)은 유선 또는 무선 네트워크들을 포함하는 하나 이상의 네트워크를 정의할 수 있다. 네트워크 시스템(들)은 예를 들어, 인터넷 및/또는 하나 이상의 클라우드 네 트워크를 포함할 수 있다. 또한, 네트워크 시스템(들)은 인터넷과 같은 공용 네트워크, 인트라넷과 같은 사설 네트워크, 또는 이들의 조합을 포함할 수 있고, TCP/IP 기반 네트워킹 프로토콜을 포함하지만 이에 제한되 는 것은 아닌 현재 이용가능하거나 향후 개발될 다양한 네트워킹 프로토콜들을 이용할 수 있다. 네트워크 시스 템(들)은 사용자 디바이스( 110 및 120)와 협력적 콘텐츠 생성 시스템(들) 간의 데이터의 통신을 가 능하게 하기 위해 사용자 디바이스(들)(110 및 120)를 협력적 콘텐츠 생성 시스템(들)에 통신가능하게 결 합시키도록 구성될 수 있다. 네트워크 시스템(들)은 일반적으로, 정보를 하나의 디바이스로부터 다른 디바 이스로 통신하기 위해 임의의 형태의 컴퓨터 판독가능 또는 기계 판독가능 매체를 채용할 수 있게 될 수 있다. 네트워크 시스템(들)은 컴퓨팅 디바이스들 간에서 정보가 이동할 수 있는 통신 방법들을 포함할 수 있다. 네트워크 시스템(들)은 공용 또는 사설 네트워크 연결로서 여겨질 수 있고, 예를 들어, 가상 사설 네트워 크 또는 공용 인터넷을 통해 채용되는 암호화 또는 다른 보안 메커니즘 등을 포함할 수 있다. 일 실시예에서, 사용자 디바이스(들)(110 및 120)는 협력적 콘텐츠 생성 시스템(들)과 직접 통신할 수 있 거나 네트워크 시스템(들) 또는 다른 이용가능한 통신 채널을 통해 간접적으로 통신할 수 있다. 사용자 디 바이스(들)(110 및 120)이 협력적 콘텐츠 생성 시스템(들)과 직접 통신하는 경우에서, 협력적 콘텐츠 생성 시스템(들)은 예를 들어, 위에서 네트워크 시스템(들)을 참조하여 설명된 하나 이상의 통신 방법을 통해 통신을 용이하게 하도록 구현되고 구성될 수 있다. 본 개시의 양태들에 따르면, 협력적 콘텐츠 생성 시스템(들)은 서버 시스템(들), 입력 퓨전 시스템 (들), 생성형 AI 시스템(들), 및 컴퓨팅 환경 생성 시스템(들)을 포함할 수 있다. 일부 실시예 들에서, 협력적 콘텐츠 생성 시스템(들)은 본 개시의 양태들에 따른, 서버 시스템(들), 입력 퓨전 시 스템(들), 생성형 AI 시스템(들), 및 컴퓨팅 환경 생성 시스템(들)의 일부 또는 모든 기능들을 수행하도록 구성될 수 있는 하나 이상의 서버일 수 있다. 본 개시에서, 시스템(들)은 다양한 전자 및 컴퓨터 시 스템들을 포함할 수 있는 다양한 구현예들을 포함할 수 있다. 본 명세서에서 설명되는 하나 이상의 구현예는 둘 이상의 특정 상호연결된 하드웨어 모듈들 또는 디바이스들을 사용하여, 모듈들 사이에서 그리고 모듈들을 통해 통신될 수 있는 관련 제어 및 데이터 신호들로, 또는 주문형 직접 회로의 부분들로서 기능들을 구현할 수 있다. 따라서, 시스템(들)은 소프트웨어, 펌웨어, 및 하드웨어 구현들을 포괄한다. 본 개시의 양태들에 따르면, 서버 시스템(들)은 클라우드 서버/네트워크, 에지 서버/네트워크 상에, 네트 워크 시스템(들) 내에, 그리고/또는 서버 시스템(들)이 협력적 콘텐츠 생성 시스템(들)과 직접 적으로 또는 간접적으로 통합될 수 있는 위치 상에 위치될 수 있는 하나 이상의 데이터 서버 또는 데이터베이스 를 포함할 수 있다. 서버 시스템(들)은 본 개시의 실시예들에 따라, 협력적 콘텐츠 생성의 실행을 용이하 게 하기 위해 사용자 디바이스(들) 및/또는 네트워크 시스템(들)으로부터 수신되는 데이터를 저장하 고 프로세싱할 수 있다. 추가적으로, 서버 시스템(들)은 협력적 콘텐츠 생성의 실행을 용이하게 하기 위해입력 퓨전 시스템(들), 생성형 AI 시스템(들), 및 컴퓨팅 환경 생성 시스템(들)으로 또는 이로 부터 데이터 또는 커맨드 신호를 수신하고 송신할 수 있다. 본 개시의 양태들에 따르면, 입력 퓨전 시스템(들)은 제1 사용자 및 제2 사용자로부터 하나 이 상의 입력 또는 커맨드를 수신할 수 있다. 위에서 설명된 바와 같이, 환경은 둘보다 많은 사용자들 또는 사용자 디바이스들을 포함할 수 있다. 따라서, 입력 퓨전 시스템(들)은 둘보다 많은 사용자들 또는 사용자 디바이스들로부터 입력 및 커맨드를 수신할 수 있다. 대안적으로, 입력 퓨전 시스템(들)은 협업 세션의 유 형에 따라 단지 제1 사용자 또는 제2 사용자로부터만 하나 이상의 입력 또는 커맨드를 수신할 수 있 다. 즉, 협력적 콘텐츠 생성 시스템(들)은 단일 사용자 생성 세션 또는 다중 사용자 생성 세션을 용이하게 할 수 있다. 본 개시에서, 입력 및 커맨드라는 용어들은 상호교환적으로 사용될 수 있다. 사용자 입력 또는 커 맨드는 예를 들어, 오디오 입력, 햅틱 입력, 텍스트 입력, 이미지 입력, 제스처 입력, 또는 비디오 입력을 포함 할 수 있지만, 이에 제한되는 것은 아니다. 즉, 예를 들어, 환경 내의 사용자 디바이스에 연결되거나 사용 자 디바이스와 통합된 센서 또는 다른 적합한 수단을 통해 용인가능한 임의의 유형의 데이터가 본 개시에 따른 사용자 입력 또는 커맨드인 것으로 고려될 수 있다. 사용자 커맨드는 직접적인 또는 간접적인 커맨드일 수 있다. 예를 들어, 직접적인 커맨드는 하나 이상의 사용자에 의해 직접 입력되는 커맨드를 수행할 것(예를 들어, 선택된 영역에 대해 특정 색상을 변경하는 것)을 협력적 콘텐츠 생성 시스템(들)에 지시하도록 구성될 수 있는 커맨드를 지칭할 수 있다. 반대로, 간접적인 커맨드는 커맨드들로부터 정보(예를 들어, 사용자가 말하고 있는 것)를 해석하고 추론할 것을 협력적 콘텐츠 생성 시스템(들)에 지시하도록 구성될 수 있는 커맨드를 지칭할 수 있다. 예를 들어, 직접적인 커맨드는 사용자가 단순히 특정 생성 영역을 선택하고 커맨드를 직접 전 송할 수 있기 때문에, 협력적 콘텐츠 생성 시스템(들)에 의한 학습, 분석, 및 해석을 덜 필요로 할 수 있 다. 그러나, 간접적인 커맨드는 협력적 콘텐츠 생성 시스템(들)이 데이터를 캡처하고 AI 또는 머신 러닝 모델에 의해 해석되는 것에 가능한 한 가까울 수 있는 클린한 커맨드를 추출하려고 시도함에 따라, 더 많은 트 레이닝(예를 들어, 머신 러닝 모델 트레이닝)을 필요로 할 수 있다. 예를 들어, 간접적인 커맨드는 사용자가 자 신의 창의적인 작업이라고 고려하는 것에 대해 브레인스토밍(brainstorming)하고 있을 수 있는 경우, 하나 이상 의 사용자가 그들 간의 창의적인 세션에서 대화를 나눌 때 주로 사용될 수 있다. 대안적으로, 단일 사용자는 자 신이 창의적인 작업인 것으로 고려할 수 있는 것에 대해 브레인스토밍하기 위해 창의적인 세션에서 혼자 말할 수 있다. 일 실시예에서, 제1 사용자 및/또는 제2 사용자는 각각, 제1 사용자 디바이스(들) 및 제2 사용 자 디바이스(들)에 동기적으로 또는 비동기적으로 커맨드를 입력할 수 있다. 입력 퓨전 시스템(들)은 사용자 디바이스(들)(110 및 120)로부터 입력 커맨드를 네트워크 시스템(들) 및/또는 서버 시스템 (들)을 통해 직접 또는 간접적으로 수신할 수 있다. 그런 다음, 입력 퓨전 시스템(들)은 입력 커맨드 를 텍스트 데이터로 트랜스크라이브(transcribe)하거나 컨버트할 수 있다. 텍스트 데이터의 형태로 수신될 수 있는 입력 커맨드의 경우, 입력 퓨전 시스템(들)에 의한 텍스트 데이터로의 컨버전은 필요하지 않을 수 있 다. 그런 다음, 입력 퓨전 시스템(들)은 텍스트 데이터의 시맨틱스를 캡처함으로써(예를 들어, 대화의 맥 락을 이해함), 듀플리케이트 및/또는 리던던시(예를 들어, 불필요한 정보)를 검출함으로써, 텍스트 데이터를 라 벨링함으로써, 그리고/또는 프롬프트를 검출함으로써, 입력 커맨드의 유형 또는 형태에 따라, 컨버트된 텍스트 데이터 또는 수신된 텍스트 데이터를 분석할 수 있다. 그런 다음, 입력 퓨전 시스템(들)은 필요하다면, 예 를 들어, 검출된 듀플리케이트 및/또는 리던던시를 제거함으로써, 분석된 텍스트 데이터를 클리닝하거나 수정할 수 있다. 그런 다음, 입력 퓨전 시스템(들)은 만약 있다면, 분석되고 클리닝된 텍스트 데이터로부터 프롬 프트를 추출하는 것을 진행할 수 있다. 일부 실시예들에서, 입력 퓨전 시스템(들)은 트레이닝된 머신 러닝 모델을 이용할 수 있다. 그런 다음, 입력 퓨전 시스템(들)은 추출된 클린한 프롬프트를 생성형 AI 시스템 (들)에 전송할 수 있다. 일부 실시예들에서, 데이터 컨버전 또는 트랜스크립션은 사용자 디바이스 (들)(110, 120)에서 일어날 수 있다. 따라서, 사용자 디바이스(들)(110, 120)는 오디오 또는 다른 유형의 데이 터의 텍스트로의 컨버전을 가능하게 하는 컴퓨터 코드를 구현하고, 트랜스크라이브된 텍스트를 협력적 콘텐츠 생성 시스템(들)에 전송할 수 있다. 대안적으로, 위에서 설명된 바와 같이, 데이터 트랜스크립션 또는 컨 버전은 협력적 콘텐츠 생성 시스템(들)에서 입력 퓨전 시스템(들)에 의해 일어날 수 있어서, 입력 디 바이스(들)(110, 120)는 어떠한 데이터 트랜스크립션 또는 컨버전도 수행할 필요가 없을 수 있다. 대안적으로, 입력 퓨전 시스템(들)의 모든 기능들은 텍스트 트랜스크립션 또는 컨버전, 입력, 또는 커맨드 데이터 분석, 및/또는 입력 또는 커맨드 데이터 클리닝을 포함하여, 생성형 AI 시스템(들)에 의해 수행될 수 있다. 일 실시예에서, 라벨링 프로세스는 이미지 데이터, 햅틱 데이터, 비디오 데이터, 오디오 데이터 및/또는 다른 유형의 데이터와 같은 임의의 유형의 입력 또는 커맨드 데이터에 대해 입력 퓨전 시스템(들)에 의해 수행 될 수 있다. 텍스트 데이터를 포함하지 않는 데이터의 경우, 라벨링 프로세스는 커맨드를 텍스트로 트랜스크라 이브하는 유형으로서 고려될 수 있다. 예를 들어, 공간에 달을 포함하는 사용자(예를 들어, 사용자(112, 122)) 에 의해 제공된 사진이 입력 퓨전 시스템(들)에 의해 수신되는 경우, 입력 퓨전 시스템(들)은 실제 프롬프트 및 창의적인 작업으로 컨버트될 수 있는, 예를 들어, 달, 빛나는, 흰색, 암흑 공간 등을 포함하는 라 벨을 생성할 수 있다. 다른 예로서, 클래식 음악의 연주가 업로드되는 음악 생성 세션에서, 입력 퓨전 시스템 (들)은 실제 프롬프트 및 창의적인 작업으로 컨버트될 수 있는, 예를 들어, 화음이 조화로운, 클래식한, 부드러운 음악을 포함하는 라벨을 생성할 수 있다. 텍스트로 수신되는 데이터의 경우, 위에서 설명된 라벨링 프 로세스를 수행하는 대신에, 카테고리화 프로세스가 유사하게 수행될 수 있다. 예를 들어, 공간에 있는 달을 포 함하는 텍스트 데이터가 입력 퓨전 시스템(들)에 의해 수신되는 경우, 입력 퓨전 시스템(들)은 텍스 트 데이터를 예를 들어, 달, 빛나는, 흰색, 암흑 공간 등으로 카테고리화할 수 있다. 일 실시예에서, 입력 퓨전 시스템(들)은 하나 이상의 사용자로부터 텍스트 및 비 텍스트 데이터 둘 모두를 동기적으로 수신할 수 있 다. 이러한 실시예에서, 입력 퓨전 시스템(들)은 트랜스크립션 및 카테고리화 둘 모두를 동시에 또는 순차 적으로 수행할 수 있다. 일례에서, 라벨링 또는 카테고리화 프로세스는 수신된 입력의 작성자(예를 들어, 사용 자(112 또는 122))를 식별하는 텍스트를 추가하는 것을 포함한다. 이러한 식별은 대응하는 사용자의 사용자 디 바이스를 인식하는 것, 및 사용자 음성 또는 (예를 들어, 얼굴 인식을 통해) 사용자 이미지를 인식하는 것 및/ 또는 기타 중, 하나 이상에 의해 수행될 수 있다. 추가적으로, 입력 퓨전 시스템(들)은 텍스트 데이터로부 터 분석된 정보를 비 텍스트 데이터로부터 분석된 정보와 비교하여, 실제 프롬프트 및 창의적인 작업으로 컨버 트될 수 있는 라벨 또는 카테고리를 생성할 수 있다. 예를 들어, 비 텍스트 데이터로부터 식별된 하나 이상의 라벨과 텍스트 데이터로부터 식별된 하나 이상의 카테고리화는 프롬프트 및 창의적인 작업으로 컨버트하기 위해 입력 퓨전 시스템(들)에 의해 함께 프로세싱될 수 있다. 위에서 설명된 컨버전 프로세스와 카테고리화 프 로세스는 함께 동시에 또는 순차적으로 수행될 수 있다. 본 개시의 양태들에 따르면, 생성형 AI 시스템(들)은 입력 퓨전 시스템(들)으로부터 하나 이상의 프 롬프트를 수신할 수 있다. 일 실시예에서, 생성형 AI 시스템(들)은 입력 퓨전 시스템(들)으로부터 수 신된 하나 이상의 프롬프트에 기초하여 하나 이상의 창의적인 제안을 생성할 수 있다. 각 제안은 특정 입력에 기초하여 특정 사용자와 관련될 수 있다. 예를 들어, 제1 사용자가 벽의 색상을 적색으로 수정하라는 커맨 드를 전송하고 제2 사용자가 벽의 색상을 청색으로 수정하라는 커맨드를 전송하는 경우, 생성형 AI 시스템 (들)은 입력 퓨전 시스템(들)으로부터 수신된 프롬프트들에 기초하여 커맨드들에 있어서의 차이를 인 식할 수 있다. 그런 다음, 생성형 AI 시스템(들)은 제1 커맨드를 제1 사용자의 커맨드로서 라벨링하 고, 제2 커맨드를 제2 사용자의 커맨드로서 라벨링할 수 있다. 그런 다음, 생성형 AI 시스템(들)은 제1 사용자에 대응하는 제1 제안, 및 제2 사용자에 대응하는 제2 제안을 준비하는 것을 진행할 수 있 다. 물론, 제안을 준비하기 위한 동일하거나 유사한 프로세스 또는 방법이 다양한 다른 유형의 사용자 커맨드 (예를 들어, 이미지, 텍스트, 햅틱 등)에 적용될 수 있다. 그런 다음, 생성형 AI 시스템(들)은 제안을 컴 퓨팅 환경 생성 시스템(들)에 송신할 수 있다. 일 실시예에서, 생성형 AI 시스템(들)은 입력 퓨전 시스템(들)으로부터 수신된 입력 데이터를 이용하 고 생성형 AI 시스템(들)의 기능을 용이하게 하기 위해 사용될 수 있는 출력 데이터를 생성할 수 있는 하 나 이상의 생성형 AI 모델을 포함할 수 있다. 생성형 AI 모델은 예를 들어, 콘텐츠를 표현하고 프로세싱하기 위 해 사용되는 다양한 AI 알고리즘들의 조합을 포함할 수 있다. 또한, 하나 이상의 창의적인 제안을 생성하기 위 해, 생성형 AI 모델은 자연 언어 프로세싱 기법을 이용하여 텍스트를 생성하여, 글자, 구두점, 및 단어와 같은 원시 문자를 문장, 스피치의 일부, 엔티티, 및 액션으로 변형할 수 있으며, 그런 다음, 이는 다수의 인코딩 기 법들을 사용하여 벡터로서 표현될 수 있다. 추가적으로, 이미지는 생성형 AI 시스템(들)에 의해 하나 이상 의 창의적인 제안으로서 사용되도록 다양한 시각적 엘리먼트들로 변형될 수 있으며, 이는 또한 벡터로 표현될 수 있다. 일 실시예에서, 질의 또는 프롬프트에 응답하여 새로운 콘텐츠를 생성하는 데 특정 신경망이 사용될 수 있다. 생성형 AI 시스템(들)에 의한 하나 이상의 창의적인 제안을 생성하는 데 생성적 대립 네트워크 (Generative Adversarial Network, GAN) 및 변이형 오토 인코더(Variational Autoencoder, VAE)와 같은 기법이 이용될 수 있다.일 실시예에서, 본 개시의 AI 알고리즘은 AI 시스템(들)에서의 AI 알고리즘의 적용 전에 미리 결정된 수의 데이터세트로 트레이닝될 수 있다. 추가적으로, AI 알고리즘은 환경에서 수행되는 창의 적인 세션 동안 학습을 계속할 수 있다. 예를 들어, AI 시스템(들)은 각 창의적인 세션 후에 각 사용자의 창의적인 스타일로부터 학습할 수 있다. 그런 다음, AI 시스템(들)은 머신 러닝을 통해 AI 알고리즘을 개 선할 수 있어서, AI 시스템(들)이 창의적인 제안을 더 빠르게 그리고/또는 더 양호한 품질로 생성하고 제공할 수 있게 된다. 본 개시의 양태들에 따르면, 컴퓨팅 환경 생성 시스템(들)은 환경 내의 사용자들(112, 122)이 콘텐츠 를 생성하기 위해 협력하는 데 이용할 수 있는 하나 이상의 컴퓨팅 환경의 생성을 용이하게 할 수 있다. 컴퓨팅 환경은 예를 들어, 증강 현실 환경, 가상 현실 환경, 및 2차원(2D) 또는 3차원(3D) 시뮬레이션된 환경을 포함할 수 있지만, 이에 제한되는 것은 아니다. 컴퓨팅 실시예에서의 컴퓨팅 환경 및 사용자 협력의 예는 또한 공동 계 류 중인 미국 특허 출원 제17/006,327호에서 개시되며, 이의 전체 개시 내용이 임의의 부인, 부정, 및 모순을 제외하고, 본 명세 참조로 통합된다. 또한, 공동 계류 출원에서 개시되는 임의의 머신 러닝 알고리즘은 입력 퓨 전 시스템(들) 및/또는 생성형 AI 시스템(들)에 의해 사용되는 머신 러닝 모델과 조합하여 또는 개별 적으로 사용되도록 통합될 수 있다. 일 실시예에서, 컴퓨팅 환경 생성 시스템(들)은 이미 존재하는 가상 환경의 영역에서 하나 이상의 컴퓨팅 환경의 생성을 용이하게 할 수 있다. 일 실시예에서, 컴퓨팅 환경 생성 시스템(들)은 예를 들어, 사용자 디바이스(들)(110 및 120), 입력 퓨전 시스템(들), 및/또는 생성형 AI 시스템(들)으로부터 사용자 커맨드, 프롬프트 및/또는 제안을 수신할 수 있다. 그런 다음, 컴퓨팅 환경 생성 시스템(들)은 환경의 사용자들이 콘텐츠를 생성하기 위해 서 로 상호작용하는 데 이용할 수 있는 그래픽 및/또는 오디오 인터페이스를 생성할 수 있다. 예를 들어, 컴퓨팅 환경 생성 시스템(들)은 하나 이상의 사용자 그래픽 표현(user graphical representation, UGR) 또는 오 디오 표현을 통해 가상 환경에서 하나 이상의 엘리먼트를 생성할 수 있다. 이러한 UGR 또는 오디오 표현은 하나 이상의 카메라 또는 마이크로폰, 예를 들어, 사용자 디바이스(예를 들어, 사용자 디바이스(들)(110, 120))와 통 합된 카메라 또는 마이크로폰 또는 사용자 디바이스와는 분리되어 있지만 사용자 디바이스에 전기적으로 연결된 카메라 또는 마이크로폰에 의해 캡처되는 실시간 카메라 또는 마이크로폰 피드로부터 생성될 수 있다. UGR은 사 용자들이 가상 환경에서 콘텐츠를 생성하기 위해 서로 협력하는 것을 도울 수 있다. 예를 들어, 제1 사용자 가 사용자 디바이스(들)에 의해 검출될 수 있는 움직임을 보일 때, 가상 세계에서 제1 사용자와 연관된 UGR은 제1 사용자에 의해 보여진 움직임에 기초하여 움직이거나 하나 이상의 효과를 생성할 수 있 다. 유사하게, 제2 사용자가 사용자 디바이스(들)에 의해 검출될 수 있는 움직임을 보일 때, 제2 사 용자와 연관된 또 다른 UGR은 제2 사용자에 의해 보여진 움직임에 기초하여 움직이거나 하나 이상의 효과를 생성할 수 있다. 입력 퓨전 시스템(들), 및/또는 생성형 AI 시스템(들)은 하나 이상의 머신 러닝 모델을 이용하여 프롬프트를 클리닝, 분석, 및/또는 추출하여 제1 사용자 및 제2 사용자에 의해 보여진 움직임에 기초한 제안을 제1 사용자 및/또는 제2 사용자에게 제공한다. 따라서, 협력적 콘텐 츠 생성 시스템(들)은 다수의 사용자들이 컴퓨팅 환경에서 콘텐츠를 공동 생성할 수 있게 하기 위해 인공 지능을 사용한 협력적 콘텐츠 생성의 실행을 용이하게 할 수 있다. 도 2는 본 개시의 실시예들에 따른, 콘텐츠 생성 데이터를 생성하기 위한 대표적인 시스템의 블록도 를 도시한다. 도 1에서 도시된 환경의 협력적 콘텐츠 생성 시스템(들)은 하나 이상의 사용자로부터 사용자 데이터를 수신할 수 있다. 이러한 실시예에서, 협력적 콘텐츠 생성 시스템(들)은 예시 및 설 명의 명확성을 위해 입력 퓨전 시스템(들) 및 생성형 AI 시스템(들)만으로 도시되어 있다. 그러나, 협력적 콘텐츠 생성 시스템(들)은 도 1에서 도시된 시스템(들) 중 전부 또는 일부를 포함할 수 있다. 계속해서 도 2를 참조하면, 사용자 데이터는 하나 이상의 사용자가 사용자 디바이스에 입력 또는 커맨드를 제공할 때 하나 이상의 사용자 디바이스(예를 들어, 사용자 디바이스(들)(110, 120))에 의해 생성될 수 있다. 사용자 디바이스는 제1 내지 제n 사용자 입력 데이터(210a 내지 210n)를 동기적으로 또는 비동기적으로 생성할 수 있다. 즉, 둘보다 많은 사용자들이 입력들 또는 커맨드들을 실질적으로 동시에 제공할 때, 사용자 입력 데이 터(210a-210n)는 동기적으로 생성된다고 할 수 있다. 반대로, 둘보다 많은 사용자들이 입력들 또는 커맨드들을 실질적으로 동시에 제공하지 않을 때, 사용자 입력 데이터(210a-210n)는 비동기적으로 생성된다고 할 수 있다. 따라서, 둘보다 많은 사용자 입력 데이터(210a-210n)가 협력적 콘텐츠 생성 시스템(들)에 동기적으로 전송 될 때, 상기의 둘보다 많은 입력 데이터(210a-210n)는 서로 중첩될 수 있고, 그 반대도 마찬가지이다. 도 1을 참조하여 위에서 설명된 바와 같이, 사용자 데이터는 협력적 콘텐츠 생성 시스템(들)에 직접 또는 네 트워크 시스템(들)을 통해 간접적으로 전송될 수 있다. 일 실시예에서, 사용자 데이터는 오디오 데이터(예를 들어, 음성, 오디오 파일 등), 햅틱 데이터, 텍스트 데이터, 이미지 데이터, 비디오 데이터, 또는 임의의 다른 유형의 데이터 중 임의의 것을 개별적으로 또는 조합 하여 포함할 수 있으며, 이는 사용자 디바이스(예를 들어, 사용자 디바이스(들)(110, 120))에 통신가능하게 연결된 하나 이상의 센서에 의해 캡처되거나 감지될 수 있다. 대안적으로 또는 추가적으로, 사용자 데이터는 (예를 들어, 수동으로 커맨드를 타이핑하거나 텍스트 파일을 업로드함으로써) 하나 이상의 사용자에 의해 직접 입력될 수 있다. 예를 들어, 오디오 데이터를 입력하는 경우, 오디오 데이터는 클라이언트 디바이스의 하나 이 상의 마이크로폰에 의해 캡처되거나 감지될 수 있다. 대안적으로, 오디오 데이터는 예를 들어, 미리 녹음된 음 악 및/또는 음성을 포함하는 오디오 파일로서, 사용자에 의해 직접 업로드될 수 있다. 다른 예에서, 입력 데이 터는 협력적 콘텐츠 생성 시스템(들)에 송신되도록 사용자 디바이스를 통해 업로드되거나 사용자의 카메라 에 의해 캡처된 이미지 파일일 수 있다. 오디오 및/또는 이미지 파일은 이의 오디오 및/또는 이미지 데이터에서 임의의 프롬프트를 추출하기 위해 입력 퓨전 시스템(들)에 의해 분석될 수 있다. 햅틱 데이터의 경우, 사 용자는 입력 디바이스, 증강 환경, 또는 가상 환경 상의 하나 이상의 표면을 수동으로 터치할 수 있다. 예를 들 어, 사용자는 수정되거나 조작될 하나 이상의 표면을 물리적으로 또는 가상으로 터치하거나 클릭함으로써 입력 을 선택할 수 있다. 일 실시예에서, 하나 이상의 사용자는 콘텐츠를 생성하기 위한 컴퓨팅 환경에서 특정 영역 을 페인팅(예를 들어, 생성 또는 정제(refinement)를 위한 특정 영역을 정의할 수 있는 2D 라인 또는 3D 커브로 서 브러시스트로크(brushstroke)를 페인팅)할 수 있다. 계속해서 도 2를 참조하면, 협력적 콘텐츠 생성 시스템(들))은 컨버전 시스템(들), 리던던시/듀플리 케이션 검출 시스템(들), 프롬프트 추출 시스템(들), 및 모델 생성 시스템(들)을 포함할 수 있 다. 일 실시예에서, 복수의 사용자들 또는 입력 디바이스들로부터 사용자 데이터를 수신 시, 입력 퓨전 시 스템(들)은 하나 이상의 머신 러닝 모델을 사용하여 사용자 데이터에 대해 데이터 클리닝을 수행할 수 있다. 전술한 실시예들에서 설명된 바와 같이, 사용자 데이터는 사용자에 의해 제공된 정보의 형태 또 는 유형에 따라 컨버전 시스템(들)에 의해 텍스트 데이터로 컨버트될 수 있다. 일 실시예에서, 컨버전 시 스템(들)은 실질적으로 동시에 두 개 이상의 입력 디바이스들에 의해 전송된 사용자 데이터에서 임의 의 커맨드가 있는지 여부를 검출할 수 있다. 사용자 커맨드들의 수신을 실질적으로 동시에 검출 시, 리던던시/ 듀플리케이션 검출 시스템(들)은 이해하거나 프로세싱하기 위해 AI 모델(예를 들어, 머신 러닝 모델)에 대 해 간단하고 효율적인 방식으로 입력 데이터에서의 관련 정보(예를 들어, 텍스트 또는 비 텍스트 정보)를 클리닝할 수 있다. 예를 들어, 입력 정보의 클리닝은 머신 러닝 모델에 대응하는 업로드된 양식에 기초하여 수 행될 수 있다. 머신 러닝 모델은 모델 생성 시스템(들)에 의해 생성되고/거나 트레이닝될 수 있다. (예를 들어, 커맨드들의 중첩이 불명확한 데이터를 생성할 수 있기 때문에 또는 커맨드의 흐름을 방해할 수 있는 노이 즈로 인해) 혼란스럽거나 인식할 수 없는(또는 이해할 수 없는) 커맨드가 있는 경우, 리던던시/듀플리케이션 검 출 시스템(들)은 이러한 데이터 비트를 불명확한 것으로 플래깅하고 특정 커맨드 또는 메시지에 대한 명확 성을 얻기 위해 하나 이상의 명확화 메시지를 사용자에게 전송할 수 있다. 입력 퓨전 시스템(들)에 의해 이용되는 AI 모델은 하나 이상의 모델 생성 시스템(들)에 의해 생성될 수 있다. 일 실시예에서, 모델 생성 시스템(들)은 AI 모델들(예를 들어, 머신 러닝 모델들) 중 하나 이상을 생성하 고/거나 트레이닝할 수 있다. 모델 생성 시스템(들)은 입력 퓨전 시스템(들)의 일부로서 통합된 입력 퓨전 시스템(들)에 상주할 수 있다. 대안적으로, 모델 생성 시스템(들)은 네트워크 시스템(들) 내에, 클라우드 서버/네트워크 상에, 또는 에지 서버/네트워크 상에 위치될 수 있지만, 이에 제한되는 것은 아 니다. 모델 생성 시스템(들)은 머신 러닝 모델 및 머신 러닝 애플리케이션을 생성하기 위해 컴포넌트들의 라이브러리를 생성할 수 있는 머신 러닝 플랫폼일 수 있다. 모델 생성 시스템(들)은 사용자가 클라우드 기 반 네트워크 인프라스트럭처에 대한 상세한 지식 또는 모델을 구축하기 위한 코드를 어떻게 생성하는지에 대한 지식 없이 머신 러닝 애플리케이션을 생성할 수 있게 할 수 있다. 모델 생성 시스템(들)은 식별된 데이터 를 분석할 수 있고, 사용자는 머신 러닝 애플리케이션 또는 모델을 생성하기 위한 하나 이상의 라이브러리 컴포 넌트 및 연관된 애플리케이션 프로그래밍 인터페이스(Application Programming Interface, API)를 선택하기 위 해 원하는 예측 및 성능 특성을 제공하였다. 머신 러닝 기법은 모델에 대한 피드백 및 조정을 가능하게 하기 위 해 머신 러닝 모델의 출력을 모니터링하고 평가할 수 있다. 머신 러닝 애플리케이션 또는 모델은 독립형 실행 가능 코드로서 내보내기 위해 트레이닝, 테스트, 및 컴파일될 수 있다. 예를 들어, 모델 생성 시스템(들) 은 아웃페인팅(Outpainting)을 실행하는 데 이용되는 하나 이상의 거대 언어 모델(large language model, LLM) 및/또는 머신 러닝 모델을 이용할 수 있다. 일 실시예에서, 모델 생성 시스템(들)은 다른 머신 러닝 애플 리케이션, 모델 및/또는 시스템(예를 들어, 생성형 AI 시스템(들))에 사용될 수 있는 하나 이상의 라이브 러리 컴포넌트를 생성하고 저장할 수 있다. 모델 생성 시스템(들)은 입력 퓨전 시스템(들)이 예를 들 어, 사용자의 선호도 이력에 기초하여 추천을 할 수 있게 하는 프로파일을 생성할 수 있다. 생성 시스템 (들)은 원하는 성능 기준 내에서 원하는 결과를 달성하는 데 필요한 인프라스트럭처 리소스의 수 및 유형 을 검출할 수 있다.일 실시예에서, 모델 생성 시스템(들)에 의해 생성된 단일 머신 러닝 모델은 컨버전 시스템(들), 리 던던시/듀플리케이션 검출 시스템(들), 및 프롬프트 추출 시스템(들)에 의해 동시에 또는 순차적으로 이용될 수 있다. 대안적으로, 모델 생성 시스템(들)에 의해 생성된 다수의 머신 러닝 모델들이 컨버전 시 스템(들), 리던던시/듀플리케이션 검출 시스템(들), 및 프롬프트 추출 시스템(들)에 의해 동시 에 또는 순차적으로 이용될 수 있다. 따라서, 입력 퓨전 시스템(들)은 하나 이상의 사용자에 의한 컴퓨팅 환경에서의 동기적 또는 비동기적 창의적인 세션을 용이하게 할 수 있다. 일반적으로 단일 커맨드 또는 요청이 AI 모델에 의해 일방적인(unilateral) 방식으로 프로세싱될 것을 요구하는 종래의 AI 플랫폼과는 달리, 본 개시 의 시스템들 및 방법들은 하나 이상의 사용자에 의해 제공되는 다수의 동기적 또는 비동기적 입력들의 프로세싱 을 용이하게 한다. 예를 들어, 컴퓨팅 환경에서 콘텐츠 생성에 참여하는 하나 이상의 사용자는 입력들을 동기적 으로 또는 비동기적으로 제공할 수 있다. 협력적 콘텐츠 생성 시스템(들)은 모든 입력들을 지속적인 방식 으로 동기적으로 또는 비동기적으로 프로세싱할 수 있다. 따라서, 협력적 콘텐츠 생성 시스템(들)은 하나 이상의 창의적인 세션에서 하나 이상의 사용자에 의해 입력이 제공되기 전, 동안, 및/또는 후에, 하나 이상의 머신 러닝 모델에 기초하여, 창의적인 효과 및/또는 제안을 제공하였다. 계속해서 도 2를 참조하면, 리던던시/듀플리케이션 검출 시스템(들)은 사용자 데이터에서 하나 이상 의 리던던시(예를 들어, 불필요한 정보) 및/또는 듀플리케이트를 검출할 수 있다. 예를 들어, 리던던시/듀플리 케이션 검출 시스템(들)은 컴퓨팅 환경에서 단일 사용자의 또는 다수의 사용자들 간의 창의적인 작업에 가 치를 부가하는 콘텐츠와 연관된 정보만이 남도록 사용자 데이터에서 반복되는 단어들 및 프롬프트들을 검 출할 수 있다. 예를 들어, 창의적인 다이얼로그 또는 대화를 하는 세 명의 사용자들이 있고 사용자들 중 두 명 이 동일한 것을 말하는 경우, 리던던시/듀플리케이션 검출 시스템(들)은 예를 들어, 모델 생성 시스템 (들)에 의해 생성된 머신 러닝 모드(들)를 이용함으로써, 리던던시 및/또는 듀플리케이트를 검출할 수 있 고, 프롬프트 추출 시스템(들)이 창의적인 작업에 가치를 부가하는 프롬프트만을 추출할 수 있게 한다. 일 실시예에서, 전술한 실시예들에서 설명된 클리닝 프로세스가 일어나기 전 또는 후에 리던던시 및/또는 듀플리케 이트의 검출이 수행될 수 있다. 추가적으로, 추임새(filler word)를 사용하거나, 문장을 반복하거나, 또는 사용자들 중 일부가 컴퓨팅 환경에서 의 다수의 사용자들 간의 창의적인 작업에 가치를 부가하지 않는 소리를 내는 경우, 리던던시/듀플리케이션 검 출 시스템(들)은 사용자 데이터에 존재할 수 있는 임의의 프롬프트를 프롬프트 추출 시스템(들)(24 6)에 의해 추출하기 전에 사용자 데이터에서의 리던던시 및/또는 듀플리케이트를 폐기하는 것을 진행할 수 있다. 이러한 방식으로, 생성형 AI 시스템(들)은 단지 창의적인 세션에 유용한 커맨드만을 수신할 수 있음 으로써, 사용자 입력에 기초하여 창의적인 효과 및 제안을 결정하는 것의 효율성 및 정확도를 증가시킬 수 있다. 계속해서 도 2를 참조하면, 생성형 AI 시스템(들)은 제안/효과 생성 시스템(들) 및 모델 생성 시스템 (들)을 포함할 수 있다. 제안/효과 생성 시스템(들)은 컴퓨팅 환경(예를 들어, 증강 현실 환경, 가상 현실 환경, 및 2차원(2D) 또는 3차원(3D) 시뮬레이션된 환경 등)에서 창의적인 효과를 생성하기 위한 콘텐츠 생 성 데이터를 생성할 수 있다. 도 3은 도 1 및 도 2를 참조하여 설명된 실시예들의 시스템들 및 방법들의 기능들을 용이하게 할 수 있는 예시적인 가상 환경을 도시한다. 이제, 본 개시의 실시예들에 따른, 협력적 콘텐 츠 생성의 특징에 대한 이해를 돕기 위해 도 2의 특징이 도 3의 가상 환경과 조합하여 설명될 것이다. 물 론, 본 개시의 실시예들에 따른, 협력적 콘텐츠 생성을 용이하게 하기 위해 임의의 컴퓨팅 환경(예를 들어, 증 강 현실 환경, 가상 현실 환경, 및 2차원(2D) 또는 3차원(3D) 시뮬레이션된 환경 등)이 적용가능할 수 있다. 일 실시예에서, 가상 환경은 생성형 AI 시스템(들)에 의해 생성된 콘텐츠 생성 데이터에 따라 컴퓨팅 환경 생성 시스템(예를 들어, 컴퓨팅 환경 생성 시스템(들))에 의해 생성될 수 있다. 간략화를 위 해, 가상 환경을 생성하는 것의 세부사항은 생략된다. 컴퓨팅 환경(예를 들어, 증강 현실 환경, 가상 현실 환경, 및 2차원(2D) 또는 3차원(3D) 시뮬레이션된 환경 등)을 생성하는 것에 대한 상세한 설명이 공동 계류 중 인 미국 특허 출원 제17/006,327호에서 제공되며, 이의 전문이 본 명세서에 참조로 통합된다. 가상 환경은 제1 사용자 그래픽 표현(UGR), 제2 UGR, 및 제3 UGR을 포함할 수 있다. UGR들(302-306)은 제1, 제2, 및 제3 사용자들의 이미지들을 캡처하는 하나 이상의 카메라로부터 수신된 데이터 또는 신호에 기초하여 생성될 수 있다. UGR들(302-306)은 배경 이미지를 제거하는 이미지 제거 프로세스에 기초하여 생성될 수 있으며, 이는 단지 사용자를 나타내는 이미지만이 가상 환경으로 삽입될 수 있게 할 수 있다. 일 실시예에서, 가상 환경은 공간(또는 표면)을 포함할 수 있다. 공간은 하나 이상의 사용자에 의한 협력적 콘텐츠 생성을 용이하게 하기 위해 제공될 수 있다. 즉, 하나 이상의 사용자는 예를 들어, UGR들(302-306)을 통해, 공간에 대해 창의적인 액션을 수행할 수 있다. 예를 들어, UGR들(302-306)에 의해 엘리 먼트가 생성되거나 수정될 수 있다. 일 실시예에서, 공간은 가상 환경에서의 창의적인 공간일 수 있다. 그 러나, 창의적인 공간은 가상 환경의 선택된 영역, 공간, 또는 객체일 수도 있다. 예를 들어, 창의적인 공간은 벽, (미술 페인팅을 위한) 실제 미술 캔버스, 시티 모델, 제조품, 책 등일 수 있으며, 여기서 그 선택된 영역, 공간, 또는 객체에 대해 모든 커맨드가 전송되고 프로세싱될 수 있다. 도 3에는 테이블이 도시되어 있지만, 본 개시의 실시예들에 따라, 협력적 콘텐츠 생성을 용이하게 하기 위해 임의의 공간 또는 표면이 이용될 수 있다. 예를 들어, 다수의 사용자들이 협력하고 엘리먼트(예를 들어, 드로잉, 페인팅, 글 등)를 생성할 수 있게 하기 위해 가상 환경에 \"화이트 캔버스\"가 제공될 수 있다. 따라서, 협력적 콘텐츠 생성 시스템(들) 은 가상 환경의 공간 및 표면(예를 들어, 공간) 상에서 창의적인 변경이 실시간으로 또는 거의 실시 간으로 보여지는 방식으로 대화를 통해 그리고/또는 다른 수단을 통해 창의적인 세션이 자연적으로 이루어지는 것을 용이하게 하거나 가능하게 한다. 다시 도 2를 참조하면, 생성형 AI 시스템(들)에 의해 생성된 콘텐츠 생성 데이터는 그래픽 데이터 (220a), 오디오 데이터(220b), 텍스트 데이터(220c), 및 햅틱 데이터(220n)를 포함할 수 있지만, 이에 제한되는 것은 아니다. 예를 들어, 콘텐츠 생성 데이터는 도 3의 가상 환경에서 창의적인 효과를 제공하기 위 한 정보 또는 신호를 포함할 수 있다. 일 실시예에서, 콘텐츠 생성 데이터는 가상 환경에서의 엘리먼 트에 대한 변경을 용이하게 할 수 있다. 엘리먼트에 대한 변경은 엘리먼트의 형상, 형태, 색상, 밝기(예를 들어, 광 또는 광의 강도를 추가하거나 제거함), 치수 등을 변경하는 것을 포함할 수 있다. 추가적으 로, 엘리먼트는 가상 환경 내의 객체(예를 들어, 가구, 건물, 차량 등)일 수 있다. 또한, 엘리먼트 는 음악 작품, 미술 작품, 텍스트북, 또는 제품으로서 표현될 수 있지만, 이에 제한되는 것은 아니다. 계속해서 도 2를 참조하면, 제안/효과 생성 시스템(들)은 사용자에게 하나 이상의 창의적인 제안을 생성할 수 있으며, 여기서 각 제안은 특정 입력에 기초하여 특정 사용자에게 속할 수 있다. 예를 들어, 제안/효과 생성 시스템(들)은 특정 입력 커맨드를 제공하거나 전송하는 각 사용자에 기초하여 다수의 사용자들로부터 수신 된 입력 커맨드를 라벨링할 수 있다. 예를 들어, 사용자 A(예를 들어, 제1 사용자)가 컴퓨팅 환경(예를 들 어, 증강 현실 환경, 가상 현실 환경, 및 2차원(2D) 또는 3차원(3D) 시뮬레이션된 환경)에서 벽의 색상을 적색 으로 수정하라는 커맨드를 전송하고, 사용자 B(예를 들어, 제2 사용자)가 벽의 색상을 청색으로 수정하라 는 커맨드를 전송하는 경우, 제안/효과 생성 시스템(들)은 두 개의 별개의 커맨드들을 인식할 수 있다. 그 런 다음, 제안/효과 생성 시스템(들)은 제1 커맨드를 사용자 A의 커맨드로서 그리고 제2 커맨드를 사용자 B의 커맨드로서 라벨링할 수 있고, 사용자 A에 대응하는 하나 이상의 제안 및 사용자 B에 대응하는 상이한 제안 을 생성할 수 있다. 물론, 이러한 프로세스는 다른 유형의 커맨드(예를 들어, 이미지, 텍스트, 햅틱 등)와 유사 하게 적용될 수 있다. 일 실시예에서, 제안/효과 생성 시스템(들)은 컴퓨팅 환경(예를 들어, 증강 현실 환경, 가상 현실 환경, 및 2차원(2D) 또는 3차원(3D) 시뮬레이션된 환경)의 하나 이상의 표면 또는 공간(예를 들어, 공간)에 대한 하나 이상의 창의적인 효과를 용이하게 하기 위한 콘텐츠 생성 데이터를 생성할 수 있다. 이러한 실시예에 서, 제안/효과 생성 시스템(들)은 컴퓨팅 환경의 사용자로부터 추가적인 데이터가 수신됨에 따라 창의적인 작업을 계속해서 정제할 수 있다. 즉, 제안/효과 생성 시스템(들)은 맥락 반복에 기초하여 창의적인 효과 및 제안을 생성하기 위해 사용자 입력 데이터를 지속적으로 분석할 수 있다. 예를 들어, 제안/효과 생성 시스템 (들)이 사용자에 의해 전송된 커맨드에 기초하여 특징들 전부 또는 대부분을 포함하는 컴퓨팅 환경에서 창 의적인 효과를 제공하기 위한 데이터 또는 신호(예를 들어, 콘텐츠 생성 데이터)을 생성한 후에, 생성형 AI 시스템(들)은 사용자가 창의적인 세션을 계속함에 따라 현재 창의적인 콘텐츠를 리뷰하고 계속해서 더 정제할 수 있다. 또한, 사용자는 창의적인 콘텐츠를 생성하고 정제하기 위한 특정 영역을 또한 선택할 수 있다. 예를 들어, 사용자는 클릭하거나, 터치하거나, (예를 들어, 생성 또는 정제를 위한 특정 영역을 정의하기 위한) 2D 라인 또는 3D 커브로서 브러시스트로크를 페인팅하거나, 가상 환경의 특정 영역, 객체, 볼륨, 또는 공 간에 텍스트를 쓰거나 말함으로써 선택할 수 있고, 그 후 자신의 커맨드를 전송할 수 있다. 일부 실시예들에서, 생성형 AI 시스템(들)은 창의적인 세션이 끝난 후에, 지속적인 반복에 기초하여, 독립적으로 장식 (embellishment) 기법을 적용할 수 있다. 장식 기법은 완성된 또는 준완성된 창의적인 작업에 예를 들어, 색상, 명암, 선명도, 밝기 개선, 표면 평활화, 폐색 적용, 또는 다른 정제 기법을 적용하는 것을 포함한다. 마찬가지 로, 오디오 생성의 경우, 장식 기법은 노이즈 감소, 볼륨 증가, 톤 향상 등을 포함할 수 있다. 일 실시예에서, 생성형 AI 시스템(들)은 하나 이상의 사용자가 말할 때 창의적인 작업이 수행되는 실시간 창의적인 세션을 용이하게 하도록 구성될 수 있다. 그러나, 일부 실시예들에서, 원하는 창의적인 작업이 추가프로세싱을 필요로 하는 경우, 생성형 AI 시스템(들)은 사용자에게 추정되는 완료 시간을 통지할 수 있고, 온라인 또는 오프라인 중 어느 하나로 필요한 시간을 내는 것을 진행할 수 있다. 예를 들어, 사용자가 창의적인 세션을 종료할 때, 사용자는 이후에, 협력적 콘텐츠 생성 시스템(들)이 창의적인 작업을 완료했음을 나타 내는 통지를 수신할 수 있고, 사용자는 리뷰 및/또는 수정을 위해 완성된 생성물에 액세스할 수 있다. 따라서, 본 개시의 시스템들 및 방법들은 영구(들), 창의적인 협력적 세션 전, 동안, 및 후에 창의적인 제안 및 효과를 생성하기 위한 지속적인 맥락 반복을 통해 사용자 입력들의 동기적 또는 비동기적 프로세싱을 실행하기 위해 입 력 퓨전 시스템(들) 및 생성형 AI 시스템(들)을 이용함으로써 컴퓨팅 환경에서 하나 이상의 사용자의 콘텐츠 생성 및 협력적 상호작용을 상당히 개선한다. 도 4는 도 1 내지 도 3을 참조하여 설명된 전술한 실시예들에 따른, 컴퓨팅 환경(예를 들어, 증강 현실 환경, 가상 현실 환경, 및 2차원(2D) 또는 3차원(3D) 시뮬레이션된 환경들)에서 인공 지능을 사용하여 협력적 콘텐츠 생성을 실행하기 위한 대표적인 방법의 흐름도를 도시한다. 단계 402에서, 협력적 콘텐츠 생성 시스템(예 를 들어, 협력적 콘텐츠 생성 시스템(들)은 다수의 사용자들(예를 들어, 사용자들(112, 122)로부터 다중 사용자 입력 커맨드를 수신할 수 있다. 협력적 콘텐츠 생성 시스템은 도 4에서 도시된 방법을 용이하게 하 기 위해 도 1 내지 도 3을 참조하여 설명된 하나 이상의 시스템(들) 및/또는 모듈을 이용할 수 있다. 단계 404 에서, 협력적 콘텐츠 생성 시스템은 다중 사용자 입력 커맨드를 텍스트로 트랜스크라이브할 수 있다. 예를 들어, 협력적 콘텐츠 생성 시스템은 텍스트 형태로 제공되지 않는 커맨드에 대해 입력 커맨드를 텍스트로 컨버 트할 수 있다. 이러한 커맨드는 예를 들어, 오디오 입력, 햅틱 입력, 이미지 입력, 제스처 입력, 또는 비디오 입력의 형태일 수 있지만, 이에 제한되는 것은 아니다. 단계 406에서, 협력적 콘텐츠 생성 시스템은 도 1 내지 도 3을 참조하여 전술한 실시예들에 따라, 컨버트된 텍스트를 분석하여 리던던시 및 듀플리케이트를 검출하고/ 거나, 프롬프트를 검출하고/거나, 텍스트 데이터 라벨링을 수행할 수 있다. 단계 408에서, 협력적 콘텐츠 생성 시스템은 분석되고 컨버트된 텍스트를 클리닝할 수 있다. 즉, 컨버트된 텍스트에서 임의의 리던던시 및 듀플리 케이트가 검출된 경우, 협력적 콘텐츠 생성 시스템은 검출된 리던던시 및 듀플리케이트를 컨버트된 텍스트로부 터 제거할 수 있다. 또한, 필요하다면, 라벨링은 텍스트로 컨버트된 입력 커맨드의 형태에 기초하여 협력적 콘 텐츠 생성 시스템에 의해 수행될 수 있다. 단계 410에서, 협력적 콘텐츠 생성 시스템은 클리닝되고 컨버트된 텍 스트로부터 하나 이상의 프롬프트를 추출할 수 있다. 프롬프트는 컴퓨팅 환경에서 창의적인 효과의 적용을 용이 하게 하기 위한 정보 또는 데이터를 포함할 수 있다. 컴퓨팅 환경은 본 개시의 전술한 실시예들과 관련하여 개 시된 임의의 컴퓨팅 환경(예를 들어, 증강 현실 환경, 가상 현실 환경, 및 2차원(2D) 또는 3차원(3D) 시뮬레이 션된 환경)일 수 있다. 단계 412에서, 협력적 콘텐츠 생성 시스템은 컴퓨팅 환경에서 프롬프트를 창의적인 액션 또는 효과의 형태로 실행할 수 있다. 일 실시예에서, 본 개시의 실시예들에 따라, 컴퓨팅 세계에서 다수의 사용 자들에 의한 협력적 콘텐츠 생성을 용이하게 하기 위해 단계들 404-412에서 하나 이상의 머신 러닝 모델이 이용 될 수 있다. 도 5는 본 개시의 양태들에 따른, 컴퓨팅 환경에서 인공 지능을 사용하여 협력적 콘텐츠 생성을 실행하기 위한 대표적인 사용자 인터페이스를 도시한다. 사용자 인터페이스는 도 1 내지 도 4를 참조하여 설명된 컴 퓨팅 환경(예를 들어, 증강 현실 환경, 가상 현실 환경, 및 2차원(2D) 또는 3차원(3D) 시뮬레이션된 환경) 중 임의의 환경에서 제공될 수 있다. 일 실시예에서, 사용자 인터페이스는 입력 퓨전 시스템(들) 및/또 는 생성형 AI 시스템(들)으로부터 수신된 데이터에 기초하여 컴퓨팅 환경 생성 시스템(들)에 의해 생 성될 수 있다. 사용자 인터페이스는 복수의 사용자들(502, 504, 506)에 의해 작동되거나 조작되도록 구성 될 수 있다. 하나 이상의 사용자(502, 504, 506)는 도 5에서 도시된 바와 같이, 사용자 인터페이스 내의 타임라인 상의 슬라이더를 작동할 수 있다. 일부 실시예들에서, 슬라이더 대신에 버튼, 키, 또는 다 른 적절한 그래픽 또는 오디오 엘리먼트가 이용될 수 있다. 타임라인은 하나 이상의 시간 위치(514, 516, 518) 를 포함할 수 있으며, 여기서 사용자는 특정 시구간에서 이루어진 창의적인 효과를 리뷰하거나 수정하기 위해 타임라인 상에서 슬라이더를 앞뒤로 위치시킬 수 있다. 예를 들어, 시간 위치는 시구간(예를 들어, 3:00분)에서 위치(예를 들어, X, Y, Z 좌표)와 연관된 프롬프트(예를 들어, 프롬프트 1)를 정의할 수 있다. 일 실시예에서, 컴퓨팅 환경 생성 시스템(들)은 선택된 시간 위치(예를 들어, 514, 516, 또는 518)와 연관된 하나 이상의 프롬프트를 생성할 수 있다. 그런 다음, 사용자(502, 504, 및/또는 506)는 예를 들어, 컴퓨팅 환경 에서 그래픽 엘리먼트로서 제공될 수 있는 프롬프트를 클릭함으로써, 프롬프트를 선택할 수 있다. 따라서, 협력 적 콘텐츠 생성 시스템(들)은 컴퓨팅 환경의 사용자가 타임라인을 앞뒤로 슬라이딩하고 프롬프트 또는 커 맨드를 클릭하여 추가적인 콘텐츠 생성 또는 수정을 용이하게 하기 위한 지속적인 반복 기능을 수행할 수 있게 할 수 있다. 도 6은 본 개시의 양태들에 따른, 인공 지능을 사용하여 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 다른 대표적인 방법의 흐름도를 도시한다. 특히, 방법은 도 1 내지 도 5를 참조하여 설명된 실시예들 에 따라 수행될 수 있다. 예를 들어, 방법은 환경 및 시스템 내의 하나 이상의 시스템에 의해 수행될 수 있다. 또한, 방법은 가상 환경에서 수행될 수 있고, 사용자 인터페이스를 이용할 수 있다. 단계 602에서, 콘텐츠 생성 시스템에 의해, 제1 사용자로부터 제1 입력과 제2 사용자로부터 제2 입력을 수신할 수 있다. 콘텐츠 생성 시스템은 도 1 및 도 2에서 도시된 협력적 콘텐츠 생성 시스템(들)일 수 있 다. 일 실시예에서, 제1 사용자는 도 1에서 도시된 제1 사용자일 수 있고, 제2 사용자는 도 1에서 도시된 제2 사용자일 수 있다. 대안적으로, 제1 및 제2 사용자들은 도 5에서 도시된 임의의 사용자(502, 504, 506) 또는 도 3에서 도시된 UGR(302, 304, 306)에 의해 표현된 임의의 사용자일 수 있다. 제1 입력 또는 제2 입 력은 도 2에서 도시된 사용자 데이터를 포함할 수 있다. 예를 들어, 제1 입력은 도 2에서 도시된 제1 사용 자 입력 데이터(210a)일 수 있고, 제2 입력은 도 2에서 도시된 제2 사용자 입력 데이터(210b)일 수 있다. 제1 및 제2 입력들 각각은 예를 들어, 오디오 데이터(예를 들어, 음성, 오디오 파일 등), 햅틱 데이터, 텍스트 데이 터, 이미지 데이터, 비디오 데이터, 또는 임의의 다른 유형의 데이터를 포함할 수 있다. 일 실시예에서, 제1 입 력과 제2 입력은 동기적으로 또는 비동기적으로 수신될 수 있다. 단계 604에서, 입력 퓨전 시스템은 듀플리케이트 데이터, 리던던시 데이터, 및/또는 프롬프트 데이터의 존재에 대해 머신 러닝 모델을 사용함으로써 제1 입력 및 제2 입력을 분석할 수 있다. 입력 퓨전 시스템은 도 1 및 도 2에서 도시된 입력 퓨전 시스템(들)일 수 있다. 머신 러닝 모델은 모델 생성 시스템(들) 또는 모델 생성 시스템(들)으로부터 생성될 수 있다. 일 실시예에서, 머신 러닝 모델은 직접적인 사용자 입력 또는 간접적인 사용자 입력에 기초하여 듀플리케이트 데이터, 리던던시 데이터, 및/또는 프롬프트 데이터의 존재를 결정하는 것을 용이하게 할 수 있다. 일 실시예에서, 입력 퓨전 시스템은 제1 입력 및 제2 입력 중, 적어도 하 나를 컨버트된 데이터로 컨버트할 수 있다. 이러한 실시예에서, 제1 입력 및 제2 입력 중, 적어도 하나는 이미 지 데이터, 오디오 데이터, 및 햅틱 데이터 중, 적어도 하나를 포함할 수 있다. 또한, 컨버트된 데이터는 컨버 트된 텍스트 데이터를 포함할 수 있다. 일 실시예에서, 듀플리케이터 데이터 또는 리던던시 데이터의 존재를 결 정 시, 입력 퓨전 시스템은 제1 입력 및 제2 입력 중, 적어도 하나로부터 듀플리케이터 데이터 및 리던던시 데 이터 중, 적어도 하나를 제거할 수 있다. 일 실시예에서, 듀플리케이터 데이터 또는 리던던시 데이터의 존재를 결정 시, 입력 퓨전 시스템은 컨버트된 텍스트 데이터로부터 듀플리케이터 데이터 및 리던던시 데이터 중, 적어 도 하나에 대응하는 텍스트 데이터를 제거할 수 있다. 단계 606에서, 제1 입력 및 제2 입력 중, 적어도 하나로부터 프롬프트 데이터의 존재를 결정 시, 입력 퓨전 시 스템은 프롬프트 데이터를 액션 생성 시스템에 송신할 수 있다. 액션 생성 시스템은 도 1 및 도 2에서의 생성형 AI 시스템(들)일 수 있다. 단계 608에서, 액션 생성 시스템은 프롬프트 데이터 및 머신 러닝 모델에 기초하여 제1 액션 데이터를 생성할 수 있다. 대안적으로, 제1 액션 데이터는 제2 머신 러닝 모델에 기초하여 생성될 수 있다. 일 실시예에서, 제2 머신 러닝 모델은 모델 생성 시스템(들) 또는 모델 생성 시스템(들)에 의해 생성될 수 있다. 단계 610에서, 액션 생성 시스템은 액션 생성 시스템에 의해, 제1 액션 데이터에 기초하여 컴퓨팅 환경에서 제1 액션을 실행할 수 있다. 일 실시예에서, 컴퓨팅 환경은 가상 환경 및 증강 환경 중, 적어도 하나일 수 있다. 대 안적으로, 컴퓨팅 환경은 증강 현실 환경, 가상 현실 환경, 및 2차원(2D) 또는 3차원(3D) 시뮬레이션된 환경일 수 있지만, 이에 제한되는 것은 아니다. 일 실시예에서, 제1 액션은 가상 환경 및 증강 환경 중, 적어도 하나의 환경의 공간에서 엘리먼트를 생성하거나 수정할 수 있다. 또한, 엘리먼트는 시각적 엘리먼트 및 오디오 엘리먼 트 중, 적어도 하나일 수 있다. 일 실시예에서, 콘텐츠 생성 시스템은 제1 사용자 또는 제2 사용자에게 그래픽 인터페이스를 디스플레이하기 위한 신호를 생성할 수 있다. 그래픽 인터페이스는 사용자 인터페이스일 수 있다. 또한, 콘텐츠 생성 시스템은 제1 사용자 또는 제2 사용자로부터 선택 커맨드를 수신할 수 있다. 일 실시 예에서, 선택 커맨드는 슬라이더를 슬라이딩하거나 프롬프트와 연관된 그래픽 엘리먼트를 클릭할 수 있다. 또한, 콘텐츠 생성 시스템은 선택 커맨드에 기초하여 컴퓨팅 환경에서 사용자 생성 엘리먼트를 제공할 수 있다. 일 실시예에서, 그래픽 제어기는 조정가능한 타임라인이다. 일 실시예에서, 선택 커맨드는 조정가능한 타임라인 상의 시구간을 선택할 수 있다. 일 실시예에서, 사용자 생성 엘리먼트는 시구간에 기초하여 콘텐츠 생성 시스템 에 의해 선택될 수 있다. 일반적으로, 도 4 및 도 6에서 도시된 프로세스들, 및 도 1 내지 도 3 및 도 5와 관련하여 설명된 시스템들 및/ 또는 인터페이스들과 같은, 컴퓨터 구현가능한 것으로 이해되는, 본 개시에서 논의된 임의의 프로세스는 상술한 바와 같이, 사용자 디바이스(들)(110, 120), 협력적 콘텐츠 생성 시스템(들), 서버 시스템(들), 입력 퓨전 시스템(들), 생성형 AI 시스템(들), 컴퓨팅 환경 생성 시스템(들)과 같은, 컴퓨터 시스템의 하나 이상의 프로세서에 의해 수행되거나 그 외 구현될 수 있다. 하나 이상의 프로세서에 의해 수행되는 프 로세스 또는 프로세스 단계는 또한 동작으로도 지칭될 수 있다. 하나 이상의 프로세서는, 하나 이상의 프로세서 에 의해 실행될 때, 하나 이상의 프로세서로 하여금 프로세스들을 수행하게 하는 명령어들(예를 들어, 소프트웨 어 또는 컴퓨터 판독가능 코드)에 대한 액세스를 가짐으로써 이러한 프로세스들을 수행하도록 구성될 수 있다. 명령어들은 컴퓨터 시스템의 메모리 내에 저장될 수 있다. 프로세서는 중앙 프로세싱 유닛(CPU), 그래픽 프로세 싱 유닛(GPU), 또는 다른 유형의 프로세싱 유닛일 수 있다. 사용자 디바이스(들)(110, 120), 협력적 콘텐츠 생성 시스템(들), 서버 시스템(들), 입력 퓨전 시스 템(들), 생성형 AI 시스템(들), 및 컴퓨팅 환경 생성 시스템(들)과 같은 컴퓨터 시스템, 또는 컴퓨팅 환경에서 협력적 콘텐츠 생성을 용이하게 하기 위한 동작을 수행하는 임의의 다른 시스템은 하나 이상의 컴퓨팅 디바이스를 포함할 수 있다. 컴퓨터 시스템의 하나 이상의 프로세서가 복수의 프로세서들로서 구현되는 경우, 복수의 프로세서들은 단일 컴퓨팅 디바이스 내에 포함될 수 있거나 복수의 컴퓨팅 디바이스들 사이에 분 산될 수 있다. 컴퓨터 시스템이 복수의 컴퓨팅 디바이스들을 포함하는 경우, 컴퓨터 시스템의 메모리는 복수의 컴퓨팅 디바이스들 중 각 컴퓨팅 디바이스의 각기의 메모리를 포함할 수 있다. 도 7은 컴퓨터 시스템의 컴퓨팅 디바이스의 예를 예시한다. 컴퓨팅 디바이스는 프로세서(들)(예 를 들어, CPU, GPU, 또는 다른 프로세싱 유닛), 메모리, 및 다른 디바이스들과 통신하기 위한 통신 인터페 이스(들)(예를 들어, 네트워크 인터페이스)를 포함할 수 있다. 메모리는 휘발성 메모리, 이를테면 RAM, 및/또는 비휘발성 메모리, 이를테면 ROM 및 저장 매체를 포함할 수 있다. 저장 매체의 예들은 솔리드 스테 이트 저장 매체(예를 들어, 솔리드 스테이트 드라이브 및/또는 착탈식 플래시 메모리), 광학 저장 매체(예를 들 어, 광학 디스크), 및/또는 자기 저장 매체(예를 들어, 하드 디스크 드라이브)를 포함한다. 전술한 명령어들(예 를 들어, 소프트웨어 또는 컴퓨터 판독가능 코드)은 메모리의 임의의 휘발성 및/또는 비휘발성 메모리 컴 포넌트 내에 저장될 수 있다. 컴퓨팅 디바이스는 일부 실시예들에서, 입력 디바이스(들)(예를 들어, 키보드, 마우스, 조이스틱, 제어기, 또는 터치스크린) 및 출력 디바이스(들)(예를 들어, 디스플레이, 헤드 업 디스플레이, AR 디스플레이, VR 디스플레이, 프린터)를 더 포함할 수 있다. 예를 들어, 사용자 디바이스 (들)(110, 120)가 태블릿 컴퓨터로서 구현될 수 있는 경우, 사용자 디바이스(들)(110, 120)는 터치스크린 및 디 스플레이를 가질 수 있다. 컴퓨팅 디바이스의 전술한 엘리먼트들은 하나 이상의 버스를 나타내는 버스 를 통해 서로 연결될 수 있다. 일부 실시예들에서, 컴퓨팅 디바이스의 프로세서(들))는 CPU와 GPU 둘 모두를 포함한다. 하나 이상의 프로세서에 의해 실행가능한 명령어들은 비일시적인 컴퓨터 판독가능 매체 상에 저장될 수 있다. 이에 따라, 본 개시에서 컴퓨터 구현 방법이 설명될 때마다, 본 개시는 또한, 하나 이상의 프로세서에 의해 실 행될 때, 하나 이상의 프로세서로 하여금 컴퓨터 구현 방법을 수행하도록 구성하고/거나 컴퓨터 구현 방법을 수 행하게 하는 명령어들을 저장하는 비일시적인 컴퓨터 판독가능 매체를 설명하는 것으로서 이해되어야 한다. 비 일시적인 컴퓨터 판독가능 매체의 예는 RAM, ROM, 솔리드 스테이트 저장 매체(예를 들어, 솔리드 스테이트 드라 이브), 광학 저장 매체(예를 들어, 광학 디스크), 및 자기 저장 매체(예를 들어, 하드 디스크 드라이브)를 포함 한다. 비일시적인 컴퓨터 판독가능 매체는 컴퓨터 시스템의 메모리의 일부일 수 있거나 임의의 컴퓨터 시스템과 별개일 수 있다. 대표적인 실시예들에 대한 상기한 설명에서, 본 개시를 간소화하고 다양한 발명의 양태들 중 하나 이상의 양태 에 대한 이해를 돕기 위해, 다양한 특징들이 때때로 단일 실시예, 도면, 또는 그 설명으로 함께 그룹화된다는 것을 이해해야 한다. 그러나, 본 개시의 방법은 청구되는 발명이 각 청구항에서 명시적으로 열거된 것보다 더 많은 특징을 필요로 한다는 의도를 반영하는 것으로서 해석되어서는 안 된다. 오히려, 다음의 청구범위가 반영 하는 바와 같이, 발명의 양태들은 전술한 개시된 단일 실시예의 모든 특징들보다 적게 있다. 이에 따라, 본 상 세한 설명 다음의 청구범위는 이에 의해 본 상세한 설명에 명시적으로 통합되며, 각 청구항은 본 개시의 별개의 실시예로서 자체적으로 존재한다. 또한, 본 명세서에서 설명된 일부 실시예들은 다른 실시예에 포함된 일부 특징들을 포함하고 다른 특징은 포함 하지 않지만, 상이한 실시예들의 특징들의 조합은 본 개시의 범위 내에 있고, 당업자에 의해 이해될 바와 같이, 상이한 실시예들을 형성하는 것으로 의도된다. 예를 들어, 다음의 청구범위에서, 청구된 실시예들 중 임의의 실 시예가 임의의 조합으로 사용될 수 있다. 이에 따라, 특정 실시예들이 설명되었지만, 당업자는 본 개시의 사상으로부터 벗어나지 않고 다른 그리고 추가 수정이 행해질 수 있다는 것을 인식할 것이고, 이러한 모든 변경 및 수정은 본 개시의 범위 내에 속하는 것으로서 주장하는 것으로 의도된다. 예를 들어, 기능은 블록도로부터 추가되거나 삭제될 수 있고, 기능 블록들 간에 서 동작들이 상호교환될 수 있다. 단계들은 본 개시의 범위 내에서 설명된 방법들에 추가되거나 삭제될 수 있다. 위에서 개시된 대상은 예시적인 것으로 간주되어야 하고, 첨부된 청구범위는 본 개시의 진정한 사상 및 범위 내 에 속하는 모든 그러한 수정, 향상, 및 다른 구현을 커버하도록 의도된다. 이에 따라, 법률에 의해 허용되는 최 대 범위 내에서, 본 개시의 범위는 다음의 청구항들 및 그 등가물들의 가장 광범위한 허용가능한 해석에 의해 결정되어야 하고, 전술한 상세한 설명에 의해 국한되거나 제한되지 않아야 한다. 본 개시의 다양한 구현예들이 설명되었지만, 본 개시의 범위 내에서 더 많은 구현이 가능하다는 것이 당업자에게 명백할 것이다. 따라서, 본 개시는 제한되지 않아야 한다."}
{"patent_id": "10-2024-0054918", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 통합되고 본 명세서의 일부를 구성하는 첨부 도면들은 본 개시의 대표적인 양태들을 예시하고, 본 설명과 함께, 본 개시의 원리들을 설명하는 역할을 한다. 도 1은 본 개시의 시스템들, 방법들, 및 다른 양태들이 구현될 수 있는 예시적인 환경의 개요를 도시한다. 도 2는 본 개시의 양태들에 따른, 컴퓨팅 환경에서 콘텐츠 생성 데이터를 생성하기 위한 대표적인 시스템의 블 록도를 도시한다. 도 3은 본 개시의 양태들에 따른, 인공 지능을 사용하여 협력적 콘텐츠 생성을 실행하는 대표적인 컴퓨팅 환경 을 도시한다. 도 4는 본 개시의 양태들에 따른, 컴퓨팅 환경에서 인공 지능을 사용하여 협력적 콘텐츠 생성을 실행하는 대표 적인 방법의 흐름도를 도시한다. 도 5는 본 개시의 양태들에 따른, 컴퓨팅 환경에서 인공 지능을 사용하여 협력적 콘텐츠 생성을 실행하는 대표 적인 사용자 인터페이스를 도시한다. 도 6은 본 개시의 양태들에 따른, 컴퓨팅 환경에서 협력적 콘텐츠 생성을 실행하기 위한 다른 대표적인 방법의 흐름도를 도시한다. 도 7은 본 명세서에서 설명되는 기법들을 실행할 수 있는 컴퓨터 시스템을 도시한다."}
