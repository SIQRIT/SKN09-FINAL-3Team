{"patent_id": "10-2022-0180435", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0098570", "출원번호": "10-2022-0180435", "발명의 명칭": "시퀀스 처리 디코더의 문맥 벡터 생성을 통한 인공지능의 문맥 축적, 저장, 전송 방법", "출원인": "김강모", "발명자": "김강모"}}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "시퀀스 처리 디코더(Sequence Processing Decoder)가 입력, 출력 데이터를 처리하는 방법에 있어서,(A.1) 디코더가 하나 이상의 문맥 벡터(Context Vector)를 포함하는 입력 값을 디코더의 입력 데이터로 넣는 단계;(A.2) 디코더의 하나 이상의 레이어(Layer)에서 하나 이상의 문맥 벡터를 포함하는 데이터를 가공, 처리하여 새로운 문맥 벡터를 출력하는 단계 ; 및(A.3) 상기 하나 이상의 문맥 벡터를 포함하는 디코더의 출력 데이터를 다시 디코더의 입력으로 넣는 단계를 포함하는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터 유지 방법."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 상기 (A.1) 단계에서,인코더의 여러 레이어 중 하나 이상의 레이어에서 추출한 입력 데이터를 토대로 문맥 벡터의 초기값을 구성하는것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터 유지 방법."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,한 개 이상의 문맥 벡터를 디코더가 입력으로 받아 출력으로 변환하고 이렇게 출력된 문맥벡터와 병합 대상인문맥 벡터 중 일부 혹은 전부를 하나 혹은 그 이상의 문맥 벡터로 병합(Merge)하는 단계를 포함하는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터를 병합(Merge) 하는 방법."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서, 시퀀스 처리 디코더가 두 개 이상의 문맥 벡터를 병합하는 방법은,(B.1) 디코더가 하나 이상의 문맥 벡터를 디코더의 입력 문맥 벡터로 받아 가공된 하나 이상의 문맥 벡터를 출력하는 단계;(B.2) 하나 이상의 문맥 벡터와 상기 디코더의 출력으로 생성된 하나 이상의 문맥 벡터를 병합(Merge)하여 하나이상의 문맥 벡터를 출력하는 단계; 및(B.3) 상기 병합된 문맥 벡터 중 하나 이상의 문맥 벡터를 다시 디코더의 입력 문맥 벡터로 받아 가공된 새로운문맥 벡터를 출력하는 단계를 포함하는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터 병합 방법."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3항에 있어서, 시퀀스 처리 디코더가 두 개 이상의 문맥 벡터를 병합하는 방법은,(C.1) 디코더가 병합할 문맥 벡터 중 두 개 이상의 문맥 벡터를 디코더의 입력 문맥 벡터로 받아 가공된 두 개이상의 문맥 벡터를 출력하는 단계;(C.2) 상기 디코더의 출력으로 가공되어 생성된 두 개 이상의 새로운 문맥 벡터들 중 두 개 이상의 문맥 벡터를병합(Merge)하여 하나 이상의 문맥 벡터를 출력하는 단계;공개특허 10-2024-0098570-3-(C.3) 상기 병합된 문맥 벡터와 병합 대상 문맥 벡터 중 두 개 이상의 문맥 벡터를 디코더의 입력 문맥 벡터로받아 가공된 두 개 이상의 새로운 문맥 벡터들을 출력하는 단계를 포함하는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터 병합 방법."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항 내지 3항에 있어서,(D.1) 디코더가 검색하고자 하는 문맥의 내용을 구성하는 단계;(D.2) 상기 문맥의 내용을 토대로 데이터 저장소에 저장된 문맥 벡터를 검색하는 단계; 및(D.3) 디코더에 상기 인출된 문맥 벡터를 포함하는 입력 데이터를 유입하는 단계를 포함하는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터 저장, 검색 방법."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서, 시퀀스 처리 디코더의 문맥 벡터가 검색 가능하도록 저장하는 방법은,하나 이상의 문맥 벡터와 함께 요약 정보를 함께 저장하고 요약 정보에 대한 키워드나 검색 명령어를 통해 문맥을 검색하는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터 저장, 검색 방법."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 6항에 있어서, 시퀀스 처리 디코더의 문맥 벡터가 검색 가능하도록 저장하는 방법은,하나 이상의 문맥 벡터와 함께 문맥 벡터의 축약 벡터를 함께 저장하고 검색하고자 하는 문맥 벡터의 축약 벡터의 유사도 순으로 문맥 벡터를 검색하는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터 저장, 검색 방법."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 6항에 있어서, (D.1) 단계는,시퀀스 처리 디코더가 검색하고자 하는 문맥 벡터의 특징을 담은 문맥 벡터로부터 검색 키워드나 검색 질의문을만들어내는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터 저장, 검색 방법."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 6항에 있어서, (D.1) 단계는,시퀀스 처리 디코더가 검색하고자 하는 문맥 벡터의 특징을 담은 문맥 벡터로부터 데이터 저장소 검색을 위한축약 벡터를 만들어내는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터 저장, 검색 방법."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1항 내지 3항에 있어서,(E.1) 시퀀스 처리 디코더의 모델이 만들어낸 문맥 벡터를 네트워크나 저장 매체를 통해 다른 시퀀스 처리 디코더의 모델에게 전송하는 단계; 및(E.2) 상기 문맥 벡터를 전송 받은 디코더 모델이 디코더에 전송 받은 문맥 벡터를 입력으로 넣어 문맥 벡터를출력하는 단계를 포함하는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터 전송 방법. 공개특허 10-2024-0098570-4-청구항 12 제 11항에 있어서, 시퀀스 처리 디코더의 문맥 벡터 전송 방법은,(F.1) 상기 문맥 벡터를 전송 받은 시퀀스 처리 디코더의 모델이 전송 받은 문맥 벡터를 입력으로 넣어 출력으로 만들어낸 문맥 벡터를, 상기 문맥 벡터를 전송했던 시퀀스 처리 디코더의 모델에게 전송하는 단계; 및(F.2) 상기 문맥 벡터를 최초 전송했던 시퀀스 처리 디코더의 모델이 상기 전송 받은 문맥 벡터를 디코더의 입력으로 넣어 출력으로 새로운 문맥 벡터를 만들어내는 단계를 포함하는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터 전송방법."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11항에 있어서, 시퀀스 처리 디코더의 문맥 벡터 전송 방법은,셋 이상의 시퀀스 처리 디코더의 모델이 문맥 벡터를 전송하고 전송 받은 문맥 벡터를 디코더의 입력으로 넣어출력으로 새로운 문맥 벡터를 만들어내는 단계를 포함하는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터전송방법."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서, 시퀀스 처리 디코더의 문맥 벡터 전송 방법은,하나의 시퀀스 처리 디코더 모델이 둘 이상의 시퀀스 처리 디코더 모델의 문맥 벡터를 전송 받아 디코더의 입력으로 넣어 하나 이상의 병합된 문맥 벡터를 생성하고 전송하는 단계를 포함하는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터 처리, 전송 방법."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 11항에 있어서, 시퀀스 처리 디코더의 문맥 벡터 전송 방법은,(G.1) 시퀀스 처리 디코더의 문맥 벡터를 더 낮은 차원의 축약 벡터로 압축하는 단계;(G.2) 상기 축약 벡터를 네트워크나 저장 매체를 통해 다른 시퀀스 처리 디코더 모델로 전송하는 단계;(G.3) 상기 축약 벡터를 전송 받아 원본 문맥 벡터와 유사한 벡터로 원복하는 단계; 및(G.4) 원복된 문맥 벡터를 상기 추상화된 문맥 벡터를 전송 받은 시퀀스 처리 디코더 모델이 입력으로 넣어 출력 문맥 벡터를 만들어내는 단계를 포함하는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터 전송방법."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 1항의 방법을 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 3항의 방법을 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 6항의 방법을 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "공개특허 10-2024-0098570-5-제 11항의 방법을 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체."}
{"patent_id": "10-2022-0180435", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 12항의 방법을 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체."}
{"patent_id": "10-2022-0180435", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "트랜스포머와 같은 인코더-디코더 기반 시퀀스 처리기(Sequence Processor)의 시퀀스 처리 디코더(Sequence Processing Decoder)가 이전에 실행된 입력/출력 데이터의 문맥을 축적하고 전송하고 저장하기 위한 시퀀스 처리 디코더의 문맥벡터(Context Vector) 생성을 통한 인공지능의 문맥 축적, 저장, 전송 방법이 개시된다. 본 발명의 일 실시예에 따른 시퀀스 처리 디코더의 문맥벡터(Context Vector) 생성을 통한 인공지능의 문맥 축적, 저장, 전 송 방법은 디코더가 하나 이상의 문맥 벡터(Context Vector)를 포함하는 입력 값을 디코더의 입력 데이터로 넣는 단계, 디코더의 하나 이상의 레이어(Layer)에서 하나 이상의 문맥 벡터를 포함하는 데이터를 가공, 처리하여 새 로운 문맥 벡터를 출력하는 단계 및 하나 이상의 문맥 벡터를 포함하는 디코더의 출력 데이터를 다시 디코더의 입력으로 넣는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0180435", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 분야의 발명으로, 시퀀스 처리 디코더(Sequence Processing Decoder)의 문맥을 생성, 유지, 병합, 저장, 전송하는 방법으로 보다 상세하게는 시퀀스 처리 디코더의 입력으로 문맥을 받아 입력 데이터를 처 리하는 중에 문맥을 가공, 처리하여 시퀀스 처리 디코더의 출력으로 생성하는 방법, 두 개 이상의 문맥을 병합 하는 방법, 문맥을 데이터 저장소에 저장하는 방법, 문맥을 전송하는 방법에 관한 것이다."}
{"patent_id": "10-2022-0180435", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능 기술의 비약적 발전으로 GPT와 같은 초 거대 모델을 중심으로 고도화된 자연어처리가 가능해지면 서, 소프트웨어 코드 생성, 이미지 생성, 영상 생성, 음성 합성 등에서 탁월한 성능을 보여주고 있다. 이러한 초 거대 모델은 선행기술인 트랜스포머와 같은 시퀀스 처리기(Sequence Processor)에 기반하고 있다. 시 퀀스 처리기는 문장 안에 포함된 단어의 위치 및 단어 간의 상호 연관성을 벡터로 표현하여 입력으로 받아 이를 추상화하는 인코더(Encoder) 모듈과 인코더 모듈이 축약한 내용을 바탕으로 출력값을 만들어내는 일종의 시퀀스 처리 디코더(Sequence Processing Decoder)로 구성된다. 시퀀스 처리기 인코더의 입력은 모든 입력을 한 번에 처리하여 출력을 만들어내는 반면, 이를 받아 동작하는 시 퀀스 처리 디코더는 토큰 단위로 여러 번의 처리를 실행하여 출력을 만들어낸다. 예를 들어, \"how are you\"라는 질문에 \"I am fine\" 으로 응답하는 시퀀스 처리 모델이 있다면, \"how are you\" 는 한번에 인코더의 입력에 들어가서 추상화된 출력이 나오고, 시퀀스 처리 디코더의 첫번째 단계에서는 인코더 의 출력을 포함하는 입력으로 디코더가 \"how\" 라는 단어를 도출할 수 있는 출력을 만들고, 이 디코더의 출력을 다시 디코더의 입력으로 넣으면 \"how\" 와 \"are\" 를 도출할 수 있는 출력이 디코더에서 나온다. 이렇게 시퀀스 처리 디코더는 디코더가 출력했던 내용을 다시 디코더의 입력에 넣어, 인코더가 입력 데이터를 추상화한 출력과 디코더의 이전 출력을 함께 고려하여 디코더의 새로운 출력을 만들어낸다. 종래의 시퀀스 처리 디코더는 이렇게 입력 데이터와 출력 중인 데이터 만을 고려하여 인코더와 시퀀스 처리 디 코더가 동작하기 때문에 여러 차례에 걸쳐 인코더-디코더가 입력, 출력을 받은 내용에 대한 문맥을 유지할 수 없는 문제점이 있다. 선행기술문헌 특허문헌 비특허문헌(비특허문헌 0001) [문헌1] Ashish Vaswani 외 7명, Attention is All You Need, 2017 (비특허문헌 0002) https://arxiv.org/pdf/1706.03762.pdf (비특허문헌 0003) [문헌2] Geoffrey E. Hinton외 2명, A Fast Learning Algorithm for Deep Belief Nets, 2006 (비특허문헌 0004) http://www.cs.toronto.edu/~hinton/absps/ncfast.pdf"}
{"patent_id": "10-2022-0180435", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "종래의 시퀀스 처리기는 입력 데이터와 출력 중인 데이터 만을 고려하여 인코더와 디코더가 동작하기 때문에 현 재의 입력 데이터에 대한 반응으로 출력을 만들어 낼 뿐, 이전의 입력 데이터에 대한 고려를 할 수가 없다. 이전의 입력 데이터와 현재의 입력 데이터를 고려하여 새로운 출력 데이터를 만들어내기 위해서는 이전의 입력 데이터에 대한 정보가 디코더에 들어와야 하지만, 종래의 시퀀스 처리기는 이 부분을 고려하지 못하고 있다. 따라서 챗봇(Chatbot)과 같이 인간과 상호 소통하는 형태의 인공지능은 이전까지의 대화를 기억하지 못하고 문 맥에 맞지 않는 답을 하는 문제가 있을 수 있다. 인간과 인공지능의 상호 소통은 인공지능의 출력을 인간이 원하는 형태로 점차적으로 개선해 나갈 수 있다는 점 에서 인공지능 기술의 핵심 요소라고 할 수 있지만, 종래의 시퀀스 처리기는 이를 반영하지 못하고 있다. 아울러, 종래의 기술은 인간처럼 사고의 결과를 문맥으로 저장하고 저장된 문맥을 검색하여 예전에 사고했던 결 과를 토대로 새로운 사고를 할 수 없다. 또한, 종래의 기술은 인간처럼 두가지 이상의 개념으로 만들어진 문맥들을 하나로 통합할 수 없어, 저차원의 개 념을 점진적으로 고차원의 개념으로 발전시켜 나갈 수 없다. 게다가, 종래의 기술은 인공지능이 상호 소통하고 모델을 점진적으로 개선해 나가기 위해서는 서로 원활하게 정 보를 주고 받을 수 있어야 하지만, 문맥의 부재로 인해 이를 구현하기가 쉽지 않다. 인공지능이 유지, 관리하는 문맥은 주제, 내용, 범위에 따라 그 크기가 방대할 수 있어, 네트워크 대역폭 사용 량이나 저장수단에 기록될 공간의 크기를 최소화하기 위해서는 이를 압축할 수 있는 방법 또한 필요하다."}
{"patent_id": "10-2022-0180435", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "위와 같은 종래의 시퀀스 처리기의 문제점을 해결하기 위해서는 아래와 같은 네 가지 주요 과제에 대한 해결 수 단이 필요하다. 첫째, 이전 추론 과정에서의 입력 및 출력 데이터에 대한 고려를 한 상태로 시퀀스 처리 디코더가 추론 과정을 수행할 수 있도록 하기 위해 시퀀스 처리 디코더의 문맥을 유지할 수 있는 방법이 필요하다. 둘째, 문맥상 저차원의 개념을 점진적으로 고차원의 개념으로 발전시켜 나가기 위해, 둘 이상의 문맥을 하나의 문맥으로 병합하는 방법이 필요하다. 셋쩨, 인공지능 모델이 다양한 문맥을 필요에 따라 검색할 수 있도록 문맥을 저장하고 검색하는 방법이 필요하 다. 넷째, 인공지능 모델이 상호 소통하고 모델을 점진적으로 개선해 나가기 위해 문맥을 인공지능 모델 간에 주고 받을 수 있는 방법이 필요하다. 상기 기술적 과제 중 첫째, 시퀀스 처리 디코더가 문맥을 유지하기 위한 기술적 과제는 본 발명에 따라, (A.1) 디코더가 하나 이상의 문맥 벡터(Context Vector)를 포함하는 입력 값을 디코더의 입력 데이터로 넣는 단계; (A.2) 디코더의 하나 이상의 레이어(Layer)에서 하나 이상의 문맥 벡터를 포함하는 데이터를 가공, 처리하여 새로운 문맥 벡터를 출력하는 단계; 및 (A.3) 상기 하나 이상의 문맥 벡터를 포함하는 디코더의 출력 데이터를 다 시 디코더의 입력으로 넣는 단계를 포함하는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터 유지 방법에 의해서 달성된다. 상기 (A.1) 단계는, 인코더의 여러 레이어 중 하나 이상의 레이어에서 추출한 입력 데이터를 토대로 문맥 벡터 의 초기값을 구성하는 것이 바람직하다. 상기 기술적 과제 중 둘째, 둘 이상의 문맥을 하나의 문맥으로 병합하기 위한 기술적 과제는 본 발명에 따라, 한 개 이상의 문맥 벡터를 디코더가 입력으로 받아 출력으로 변환하고 이렇게 출력된 문맥벡터와 병합 대상인 문맥 벡터 중 일부 혹은 전부를 하나 혹은 그 이상의 문맥 벡터로 병합(Merge)하는 단계를 포함하는 것을 특징 으로 하는 시퀀스 처리 디코더의 문맥 벡터를 병합(Merge) 하는 방법에 의해서 달성된다. 상기 문맥 벡터를 병합하는 방법은, (B.1) 디코더가 하나 이상의 문맥 벡터를 디코더의 입력 문맥 벡터로 받아 가공된 하나 이상의 문맥 벡터를 출력하는 단계; (B.2) 하나 이상의 문맥 벡터와 상기 디코더의 출력으로 생성 된 하나 이상의 문맥 벡터를 병합(Merge)하여 하나 이상의 문맥 벡터를 출력하는 단계; 및 (B.3) 상기 병합된 문맥 벡터 중 하나 이상의 문맥 벡터를 다시 디코더의 입력 문맥 벡터로 받아 가공된 새로운 문맥 벡터를 출력 하는 단계를 포함하는 것이 바람직하다. 문맥 벡터를 병합하는 또 다른 방법으로, (C.1) 디코더가 병합할 문맥 벡터 중 두 개 이상의 문맥 벡터를 디코 더의 입력 문맥 벡터로 받아 가공된 두 개 이상의 문맥 벡터를 출력하는 단계; (C.2) 상기 디코더의 출력으로 가공되어 생성된 두 개 이상의 새로운 문맥 벡터들 중 두 개 이상의 문맥 벡터를 병합(Merge)하여 하나 이상의 문맥 벡터를 출력하는 단계; (C.3) 상기 병합된 문맥 벡터와 병합 대상 문맥 벡터 중 두 개 이상의 문맥 벡터를 디코더의 입력 문맥 벡터로 받아 가공된 두 개 이상의 새로운 문맥 벡터들을 출력하는 단계를 포함하는 것이 바 람직하다. 상기 기술적 과제 중 셋째, 인공지능 모델이 다양한 문맥을 필요에 따라 검색할 수 있도록 문맥을 저장하고 검 색하기 위한 기술적 과제는 본 발명에 따라, (D.1) 디코더가 검색하고자 하는 문맥의 내용을 구성하는 단계; (D.2) 상기 문맥의 내용을 토대로 데이터 저장소에 저장된 문맥 벡터를 검색하는 단계; 및 (D.3) 디코더에 상기 인출된 문맥 벡터를 포함하는 입력 데이터를 유입하는 단계를 포함하는 것을 특징으로 하는 시퀀스 처리 디코더 의 문맥 벡터 저장, 검색 방법에 의해 달성된다."}
{"patent_id": "10-2022-0180435", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "상기 문맥 벡터가 검색 가능하도록 저장하는 방법은, 하나 이상의 문맥 백터와 함께 요약 정보를 함께 저장하고"}
{"patent_id": "10-2022-0180435", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "요약 정보에 대한 키워드나 검색 명령어를 통해 문맥을 검색하는 것이 바람직하다. 상기 문맥 벡터가 검색 가능하도록 저장하는 또 다른 방법으로, 하나 이상의 문맥 벡터와 함께 문맥 벡터의 축 약 벡터를 함께 저장하고 검색하고자 하는 문맥 벡터의 축약 벡터의 유사도 순으로 문맥 벡터를 검색하는 것이 바람직하다."}
{"patent_id": "10-2022-0180435", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 4, "content": "문맥 벡터를 요약정보와 함께 저장하여 요약 정보에 대한 키워드나 검색 명령어로 데이터 저장소를 검색하는 경 우에, 상기 (D.1) 단계는 시퀀스 처리 디코더가 검색하고자 하는 문맥 벡터의 특징을 담은 문맥 벡터로부터 검 색 키워드나 검색 질의문을 만들어내는 것이 바람직하다. 문맥 벡터를 축약 정보와 함께 저장하여 축약 벡터의 유사도 순으로 문맥 벡터를 검색하는 경우, 상기 (D.1) 단 계는 시퀀스 처리 디코더가 검색하고자 하는 문맥 벡터의 특징을 담은 문맥 벡터로부터 데이터 저장소 검색을 위한 축약 벡터를 만들어내는 것이 바람직하다. 상기 기술적 과제 중 넷째, 문맥을 인공지능 모델 간에 주고받기 위한 기술적 과제는 본 발명에 따라, (E.1) 시 퀀스 처리 디코더의 모델이 만들어낸 문맥 벡터를 네트워크나 저장 매체를 통해 다른 시퀀스 처리 디코더의 모 델에게 전송하는 단계; 및 (E.2) 상기 문맥 벡터를 전송 받은 디코더 모델이 디코더에 전송 받은 문맥 벡터를 입력으로 넣어 문맥 벡터를 출력하는 단계를 포함하는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡터 전 송 방법에 의해 달성된다. 상기 시퀀스 처리 디코더의 문맥 벡터 전송 방법은, (F.1) 상기 문맥 벡터를 전송 받은 시퀀스 처리 디코더의 모델이 전송 받은 문맥 벡터를 입력으로 넣어 출력으로 만들어낸 문맥 벡터를, 상기 문맥 벡터를 전송했던 시퀀 스 처리 디코더의 모델에게 전송하는 단계; 및 (F.2) 상기 문맥 벡터를 최초 전송했던 시퀀스 처리 디코더의 모 델이 상기 전송 받은 문맥 벡터를 디코더의 입력으로 넣어 출력으로 새로운 문맥 벡터를 만들어내는 단계를 포 함하는 것이 바람직하다. 상기 시퀀스 처리 디코더의 문맥 벡터 전송 방법은, 셋 이상의 시퀀스 처리 디코더의 모델이 문맥 벡터를 전송 하고 전송 받은 문맥 벡터를 디코더의 입력으로 넣어 출력으로 새로운 문맥 벡터를 만들어내는 단계를 포함하는 것이 바람직하다. 또한, 상기 시퀀스 처리 디코더의 문맥 벡터 전송 방법은, 하나의 시퀀스 처리 디코더 모델이 둘 이상의 시퀀스 처리 디코더 모델의 문맥 벡터를 전송 받아 디코더의 입력으로 넣어 하나 이상의 병합된 문맥 벡터를 생성하고 전송하는 단계를 포함하는 것이 바람직하다. 마지막으로, 상기 시퀀스 처리 디코더의 문맥 벡터 전송 방법에 있어 네트워크 대역폭의 사용량을 혹은 저장 매 체에 기록될 데이터의 크기를 최소화 하여 전송하고자 하는 목표는, (G.1) 시퀀스 처리 디코더의 문맥 벡터를 더 낮은 차원의 축약 벡터로 압축하는 단계; (G.2) 상기 축약 벡터를 네트워크나 저장 매체를 통해 다른 시퀀스 처리 디코더 모델로 전송하는 단계; (G.3) 상기 축약 벡터를 전송 받아 원본 문맥 벡터와 유사한 벡터로 원복 하는 단계; 및 (G.4) 원복된 문맥 벡터를 상기 추상화된 문맥 벡터를 전송 받은 시퀀스 처리 디코더 모델이 입 력으로 넣어 출력 문맥 벡터를 만들어내는 단계를 포함하는 것을 특징으로 하는 시퀀스 처리 디코더의 문맥 벡 터 전송방법에 의해 달성될 수 있다."}
{"patent_id": "10-2022-0180435", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 시퀀스 처리 디코더의 추론 과정에서 문맥을 유지하는 방식으로 이전의 입력 데이터에 대한 고려를 한 채로 출력 데이터를 만들어낼 수 있는 기술이다. 또한, 둘 이상의 문맥을 병합하여 다양한 문맥을 고려한 출력 데이터를 만들어 낼 수 있으며, 문맥을 데이터 저 장소에 저장하고 검색함으로써 다양한 문맥 중 시퀀스 처리 디코더가 필요로 하는 문맥을 검색, 활용하는 것이 가능하고, 문맥을 서로 주고 받으며 여러 인공지능 모델 간에 의사소통을 가능하게 한다."}
{"patent_id": "10-2022-0180435", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과로, 챗봇(Chatbot)과 같이 인간과 상호 소통하는 형태의 인공지능이 이전까지의 대화를 기억하고, 과거 데이터를 통해 축적한 사용자(인간)의 개인적 상황이 저장된 문맥을 활용하여 개인화된 대화가 가능하며, 현재 대화의 문맥에서 벗어나지 않는 대화를 하는 것이 가능하다. 아울러, 인공지능의 출력 결과에 대해 인간과 인공지능이 문맥을 유지하며 상호 소통, 출력 결과를 점차 개선하 도록 인공지능에게 가이드를 제시할 수 있다. 아울러, 인간처럼 사고의 결과를 문맥으로 저장하고 저장된 문맥을 검색하여 예전에 사고했던 결과를 토대로 새 로운 사고를 할 수 있다. 또한, 인간처럼 두가지 이상의 개념으로 만들어진 문맥들을 하나로 통합하고, 저차원의 개념을 점진적으로 고차 원의 개념으로 발전시켜 나갈 수 있다. 그리고, 인공지능이 문맥을 주고받으며 상호 소통하는 방식의 비지도 학습(Unsupervised Learning)방식으로 인 공지능 모델을 점진적으로 개선해 나갈 수 있다. 마지막으로, 인공지능이 유지, 관리하는 문맥은 주제, 내용, 범위에 따라 그 크기가 방대할 수 있지만, 네트워 크 대역폭 사용량이나 저장수단에 기록될 공간의 크기를 최소화할 수 있다."}
{"patent_id": "10-2022-0180435", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명의 바람직한 실시예에 대해 상세히 설명한다. 도 1은 종래의 기술인 트랜스포머와 같은 인코더-디코더로 구성된 시퀀스 처리기의 동작 절차를 도시한 도면이 다. 도 1을 참조하면, 종래의 시퀀스 처리기는 여러 레이어(layer)로 쌓인 인코더가 입력 토큰 How, Are, You 를 받아 인코더의 추론(Inference) 과정을 통해 아래 레이어에서 위 레이어로 데이터를 가공해 올리며 최 상단 인코더 레이어가 최종적으로 인코딩된 데이터를 출력한다. 이렇게 출력된 인코딩된 데이터는 다시 여 러 레이어로 쌓인 디코더에 전달되며, 입력 토큰을 한번에 처리했던 인코더와는 달리 디코더의 추론 과정은 여러차례 실행되며 한 번에 하나의 토큰을 출력 한다. 아울러, 이렇게 출력된 토큰의 정보는 다시 디코 더의 최 하단 레이어에 입력으로 유입된다. 설명의 용이를 위해 토큰을 입력에 넣는 것으로 표현했을 뿐, 실제로는 디코더의 입출력은 토큰을 추상화한 벡터이다. 더 상세히 기술하자면, 디코더는 I를 먼저 토큰으로 출력하고, 이를 다시 디코더에 입력에 넣어, 디코더 하단부터 상단으로 데이터를 가공해 올리면 최 상단 디코더는 I와 함께 새로운 토큰 Am을 출력 한다. 다시 이 새로운 토큰을 입력단으로 넣어 디코더 하단부터 상단으로 데이터를 가공해 올리면서 최 상단 디코더는 기존의 토큰인 I, Am과 함께 Fine을 출력한다. 도 2는 입력, 출력 문맥 벡터가 각 1개인 시퀀스 처리 디코더(A.1, A.2, A.3)의 하나의 실시예를 도시한 도면이 다. 본 발명에서 디코더의 기존 입력 토큰인 I과 Am에 문맥벡터를 추가로 디코더의 추론 과정으로 최 하단 레이어에 입력으로 넣고 하단부터 상단으로 데이터를 가공해 올리면 최 상단 디코더는 기존의 출력 토큰인 I, Am, Fine외에도 문맥벡터을 함께 출력한다. 하나의 바람직한 실시 예로서 문맥 벡터의 초기값은 인코더 최 상단 레이어의 출력 값을 활용해 구성할 수 있다. 또 다른 바람직한 실시 예로서, 문맥 벡터의 초기값은 인코더를 구성하는 각 레이어에서 추출한 데이터를 활용해 구성할 수 있다. 상기 인코더의 출력 값이나 여러 레이어에서 추출한 데이터를 활용해 문맥 벡터의 초기값을 가공할 때, 종래의 기술인 트랜스포머와 같은 시퀀스 처리기가 인코더에서 디코더로 데이터를 취합하여 멀티 헤드 어텐션(Multi- Head Attention)에 전달하는 것과 같은 방법을 사용하는 것을 고려할 수 있다. 이후, 디코더의 추론 과정에서 문맥 벡터의 가공과 관련하여, 하나의 바람직한 실시예로 디코더를 실 행하면서 디코더의 여러 레이어 중 하나 이상의 레이어에서 추출한 데이터를 가공하여 문맥 벡터를 만들수 있다. 이렇게 시퀀스 처리 디코더의 문맥 유지가 되지 않는 문제점을 해결하기 위해, 본 발명은 디코더에 문맥 벡터 (Context Vector)를 입력으로 추가하며, 이 문맥 벡터가 디코더의 레이어를 따라 가공된 새로운 문맥 벡터로 변 환되어 디코더의 출력으로 나오게 되며, 이는 다음 토큰 출력을 얻기 위한 디코더의 다음 번 추론의 입력 으로 사용된다. 상기 기술한 바와 같이, 디코더는 출력 데이터를 한 번에 만들지 못하고, 여러 차례에 걸쳐 디코더의 출력을 다 시 디코더의 입력으로 넣는 방식으로 동작하는데, 이 때 디코더의 출력으로 나온 문맥 벡터 또한 다시 디코더의 입력으로 들어가도록 하는 방식으로 문맥을 유지하고 점진적으로 발전시킬 수 있다. 문맥 벡터의 형식 및 가공에 대한 하나의 실시 예로서, 문맥 벡터를 기존 시퀀스 처리 디코더의 입력 포맷에 맞 추어 문맥의 내용을 충분히 담을 수 있는 개수의 토큰으로 유입하는 방식이 있다. 또 다른 실시 예로는 시퀀스 처리 디코더의 입력 포맷을 두 가지로 받을 수 있도록 하여, 먼저 문맥 벡터를 입 력 받고 이어서 디코더가 이전의 추론 과정에서 출력했던 토큰을 다시 입력으로 받도록 디코더를 구성하는 것을 고려해볼 수 있다. 또 다른 실시 예로는 시퀀스 처리 디코더의 입력과 다른 포맷의 문맥 벡터를 가공, 출력하도록 기존의 시퀀스 처리 디코더와 문맥 벡터 디코더를 분리된 별도의 디코더로 구성하고, 기존의 시퀀스 처리 디코더와 문맥 벡터 처리 디코더를 분리하여 훈련시킬 수 있다. 또 다른 실시 예로는 시퀀스 처리 디코더의 입력과 다른 포맷의 문맥 벡터를 가공, 출력하도록 기존의 시퀀스 처리 디코더와 문맥 벡터 디코더를 분리된 별도의 디코더로 구성하되, 기존의 시퀀스 처리 디코더와 문맥 처리 디코더 레이어를 연결하는 것으로 기존의 시퀀스 처리 디코더와 문맥 처리 디코더가 함께 훈련되도록 모델을 구 성할 수 있다. 본 발명의 바람직한 실시 예로, 문맥을 유지하며 사용자(인간)와 대화하는 인공지능 챗봇(Chat Bot)의 구현을 예를 들 수 있다. 맨 처음 사용자가 인공지능에게 질문을 하면, 이 질문은 시퀀스 처리기의 인코더의 입력으로 들어가고, 인코더를 구성하는 여러 레이어 중 하나 이상의 레이어가 출력한 데이터 혹은 레이어의 중간 연산 과 정에서 추출한 데이터를 취합하여 문맥 벡터의 초기값을 가공할 수 있다. 이렇게 가공된 문맥벡터를 디코더 가 장 아래 레이어의 입력으로 유입시켜 실행하면 가장 윗 레이어의 출력으로 새로운 문맥 벡터와 함께 사용자에게 응답할 토큰들이 나온다. 이후의 대화에서 사용자가 또 다른 메시지를 챗봇에게 보내면, 사용자의 메시지는 다 시 인코더의 입력으로 들어가고, 상기 디코더의 이전 추론과정에서 생성된 문맥 벡터를 디코더의 입력으로 유입 시켜 기존에 대화하던 문맥 안에서 대화를 이어가는 응답 토큰을 출력해낼 수 있다. 또한 상기 두 번째 응답 토큰을 생성하기 위한 디코더의 입력 문맥 벡터를 가공하는 하나의 실시 예로, 인코더 를 구성하는 여러 레이어 중 하나 이상의 레이어가 출력한 데이터 혹은 레이어의 중간 연산 과정에서 추출한 데 이터를 기존의 문맥에 병합하는 것을 고려할 수 있다. 도 3은 출력 문맥 벡터가 각 2개인 시퀀스 처리 디코더의 하나의 실시예를 도시한 도면이다. 디코더는 두개 이상의 문맥 벡터(320,330)를 입력으로 받을 수 있으며, 다시 두개 이상의 문맥 벡터 (340,350)를 출력으로 내놓는다. 이 때, 입력 문맥 벡터의 갯수와 출력 문맥 벡터의 갯수가 같을 필요는 없으며, 하나의 실시예로 출력 문맥 벡터가 입력 문맥 벡터보다 많을 경우 이를 디코더의 입력에 넣기 위 해, 출력 문맥 벡터를 병합하여 입력 문맥 벡터의 갯수와 일치하는 수의 문맥 벡터를 만들어낼 수 있다. 도 4는 병합할 문맥 벡터의 일부만 시퀀스 처리 디코더를 통해 가공, 처리하며 문맥 벡터를 병합하는 과정(B.1, B.2, B.3)의 하나의 실시예를 도시한 도면이다. 두 개 이상의 문맥 벡터를 병합(Merge)하기 위한 하나의 바람직한 실시 예로, 디코더의 첫 번째 추론 과 정(좌측 도면)에서 기존 입력 I에 추가로 문맥(B)를 디코더의 최 하단 레이어에 입력으로 넣고 추론 과정을 거쳐 최상단 레이어에서 기존의 출력 토큰인 I와 Am외에 추가로 디코더에 의해 가공된 문맥(B')를 출력한다. 이는 디코더을 거치지 않은 문맥A와 함께 병합과정을 거쳐 문맥AB'(43 5)로 가공된다. 이는 다시 디코더의 두 번째 추론 과정(우측 도면)에서 기존입력 I, Am에 추가로 문맥(AB')로서 디코 더의 최 하단 레이어에 입력으로 넣고 추론 과정을 거쳐 최상단 레이어에서 기존의 토큰 I, Am, Fine외에 추가로 디코더에 의해 가공된 문맥(A'B'')을 출력한다. 이는 디코더를 거치지 않은 문맥B와 함 께 병합 과정을 거쳐 문맥 BA'B''으로 가공되며, 이는 다음번 추론에 디코더의 입력으로 활용된다. 도 5는 병합할 모든 문맥 벡터를 시퀀스 처리 디코더를 통해 가공, 처리하며 문맥 벡터를 병합하는 과정(C.1, C.2, C.3)의 하나의 실시예를 도시한 도면이다. 두 개 이상의 문맥 벡터를 병합(Merge)하기 위한 하나의 바람직한 실시 예로, 디코더의 첫 번째 추론 과 정(좌측 도면)에서 기존 입력 I에 추가로 문맥(A) 및 문맥(B)를 디코더의 최 하단 레이어에 입 력으로 넣고 추론 과정을 거쳐 최 상단 레이어에서 기존의 출력 토큰인 I와 Am외에 추가로 디코더에 의해 가공된 문맥(A')와 문맥(B')를 출력한다. 이 두 문맥 벡터는 병합과정을 거쳐 문맥A'B'로 가공된다. 이는 다시 디코더의 두 번째 추론 과정(우측 도면)에서 기존입력 I, Am에 추가로 문맥(B) 및 문맥 (A'B')로서 디코더의 최 하단 레이어에 입력으로 넣고 추론 과정을 거쳐 최상단 레이어에서 기존의 토큰 I, Am, Fine외에 추가로 디코더에 의해 가공된 문맥(B')과 문맥(A''B'')을 출력한다. 이 두 문맥 벡터는 병합 과정을 거쳐 문맥B'A''B''으로 가공되며, 이는 다음번 추론에 디코더의 입력으 로 활용된다. 도 4와 도 5에 도식된 문맥 병합 방법의 여러 가지 다양한 실시예로 디코더(410,510)의 매 추론 과정마다 문맥A와 문맥B를 번갈아가며 입력으로 넣는 방식 문맥A나 문맥B중 어느 것을 넣을지 무작위로 결정하는 방 식 문맥A나 문맥B중 중요도에 따라 확률적으로 둘 중 하나의 문맥이 더 자주 들어가게 하는 방식 앞서 언급한 확률을 신경망이 출력으로 내놓도록 하는 방식 등 다양한 방식을 고려할 수 있다. 출력 문맥 벡터를 병합(430,465,535,570)하기 위한 하나의 실시 예로서 두 개의 문맥 벡터를 입력으로 받고 하 나의 문맥 벡터를 출력으로 받는 온전히 연결된 신경망(Fully Connected Neural Network)을 활용할 수 있다. 또 다른 실시 예로서, 종래의 기술인 트랜스포머와 같은 시퀀스 처리기의 멀티헤드 어텐션(Multi-Head Attention) 에서 여러 개의 스케일드 닷 프로덕트 어텐션(Scaled Dot-Product Attention)을 병합(Concat)하는 방법을 활용 할 수 있다. 도 6은 문맥 벡터를 데이터 저장소에 저장하고 검색(D.1, D.2, D.3)하는 하나의 실시 예를 도시한 도면이다. 디코더가 검색하고자 하는 내용을 담은 문맥(A')을 생성하여 데이터 저장소에서 원하는 문맥 벡터를 검색하는데 사용할 수 있다. 이렇게 검색된 문맥 벡터는 이후 디코더의 추론 과정에 사용될 수 있다."}
{"patent_id": "10-2022-0180435", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "데이터 저장소에 문맥 벡터를 저장할 때, 하나의 바람직한 실시 예로 해당 문맥의 요약 정보를 텍스트(Text)로 함께 저장하여 검색 가능하게 하는 것을 고려할 수 있다. 이 경우, 위의 사용자와 챗봇 간의 대화 예제에서 사"}
{"patent_id": "10-2022-0180435", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "용자의 관심분야와 일치하는 문맥을 검색하기 위해 문맥 벡터와 함께 저장된 문맥의 요약 정보에 대한 키워드나 검색 명령어를 통해 문맥을 검색하고 이를 기존의 문맥과 병합하여 대화를 이어나가는 상황을 구현할 수 있다. 데이터 저장소에 문맥 벡터를 저장하는 또 다른 하나의 실시 예로, 저장하고자 하는 문맥을 오토인코더(Auto Encoder)(1010,1020,1030)와 같은 모델로 추상화하여 원본 문맥 벡터(1010,1030)보다 낮은 차원의 축약된 문맥 벡터을 데이터 저장소에 원본 문맥 벡터와 함께 저장하여, 추후 디코더가 출력한 문맥 벡터와 유사도가 높은 문맥을 데이터 저장소에서 검색하여 이를 병합, 더 깊이 있는 내용으로 구성된 새로운 문맥 벡터를 만들어 가며 토큰을 생성할 수 있다. 또 다른 하나의 실시 예로, 문맥 벡터를 디코더의 입력으로 넣어 문맥과 관련된 다른 문맥을 문맥 벡터 데이터 저장소에서 질의하는 키워드나 질의 명령어를 디코더의 출력 토큰으로 생성하도록 디코더를 훈련(Train)할 수도 있다.사용자와의 대화가 아닌, 챗봇이 비지도 학습(Unsupervised Learning)으로 더 많은 문맥을 만드는 방법의 하나 의 실시 예로, 마치 사람이 다른 사람과 대화 없이 혼자 생각하는 상황을 구현하기 위해, 미리 준비된 '인생의 궁극적 목적은 무엇이 바람직한가' 라는 질문을 인코더의 입력으로 넣고 디코더의 출력으로 '가족의 건강과 행 복을 추구하는 삶이다' 라는 문장을 구성하는 토큰과 함께 이 질문과 답에 대한 문맥을 가진 문맥 벡터를 낮은 차원이 문맥 벡터로 축약하고, 이와 유사도가 높은 문맥 벡터를 데이터 저장소에서 검색하여 이를 현재의 문맥 벡터와 함께 디코더의 입력으로 사용한 채로 똑같은 질문을 인코더에 입력하는 과정을 반복하여 더 나은 답을 찾아갈 수 있다. 도 7은 시퀀스 처리 디코더의 문맥 벡터와 가장 유사한 문맥 벡터를 데이터 저장소에서 가져오는 과정의 하나의 실시 예를 도시한 순차(Sequence) 다이어그램이다. 문맥 벡터를 데이터 저장소에 저장하고 검색하는 하나의 실시 예로, 시퀀스 처리 디코더가 문맥 벡터(74 0)를 문맥 벡터 검색 시스템에 전송하면, 문맥 벡터 검색 시스템은 오토인코더(1010,1020,1030)와 같 은 모델을 이용하여 이를 낮은 차원의 축약 벡터로 변환하고 문맥 벡터 데이터 저장소에 축약 벡터와 유사도가 높은 문맥 벡터를 검색 하도록 하여 검색된 문맥 벡터 리스트를 가져올 수 있다(770,780). 도 8은 문맥 벡터를 데이터 저장소에서 시퀀스 처리 디코더가 질의한 문맥을 가져오는 과정의 하나의 실시 예를 도시한 순차 다이어그램이다. 문맥 벡터를 데이터 저장소에 저장하고 검색하는 하나의 실시 예로, 시퀀스 처리 디코더가 문맥 벡터(84 0)를 문맥 벡터 검색 시스템에 전송하면, 문맥 벡터 검색 시스템은 시퀀스 처리 디코더 모델 혹 은 그와 별개로 분리된 스퀀스 처리 디코더에 해당 문맥 벡터를 입력으로 넣고, 데이터 저장소 검색에 사용할 쿼리 혹은 키워드로 디코더가 출력하도록 할 수 있다. 이렇게 생성한 데이터 저장소 쿼리 혹은 키워드로 문맥 벡터 데이터 저장소를 검색하여 검색된 문맥 벡터 리스트를 가져올 수 있다(870,880). 문맥 벡터 데이터 베이스를 검색하여 사용하는 하나의 실시 예로, 상기 사용자와 챗봇 간의 대화의 예에서, 사 용자의 화제 전환에 대해 기존에 대화하던 문맥에 이어서 전환된 화제의 대화를 이어나갈 수 있다. 예를들어, 상기 언급한 사용자와 챗봇의 대화에서 사용자와 챗봇이 처음에는 한국의 현대사에 대한 대화를 이어가다가 사 용자가 요즘 한국 주요 관광지를 찾는 것에 관심이 있다는 메시지에 챗봇이 문맥 벡터 데이터 저장소의 '한국 주요 관광지' 문맥을 검색해서 이를 기존의 문맥인 '한국의 현대사' 문맥 벡터와 병합, 한국 현대사 역사의 현 장을 체험할 수 있는 관광지를 추천할 수 있다. 도 9는 여러 시퀀스 처리 디코더 모델들이 질의 문맥 벡터와 질의 응답 벡터를 통해 데이터를 주고 받는 과정 (E.1, E.2, F.1, F.2)의 하나의 실시 예를 도시한 순차 다이어그램이다. 마치 사람과 사람이 메신저를 통해 대화하는 인공지능끼리 서로 대화하며 비지도 학습을 하는 하나의 실시 예로 서, 시퀀스 처리 디코더 모델 A가 시퀀스 처리 디코더 모델 B에게 첫번째 질의에 대한 문맥 벡터 을 전송하고 응답 문맥 벡터을 받는다. 마찬가지로, 시퀀스 처리 디코더 모델 A이 시퀀스 처리 디코더 모델 C에게 질의 문맥 벡터을 보내 응답 문맥 벡터을 받는다. 이 세 시퀀스 처리 디코더 모델 A, B, C는 각각 서로 다른 전문 영역에 대해 훈련된 모델일 수 있다. 예를 들어, 디코더 모델 A는 자동차 설계에 대해, 디코더 모델 B는 전세계에 판매된 자동차가 탑재한 기능에 대해, 디코더 모델 C는 각국의 자동차 와 관련된 법과 규제에 대해 학습된 모델이라면, 디코더 모델 A는 '미국에 팔기 위한 경차를 제조할 때 미국의 규제에 부합하여 최소한으로 자동차에 내장해야 하는 기능은 어떤 것인가?'라는 질문에 대해 디코더 모델 B에게 는 미국에 판매된 경차에 탑재된 기능을 질의하고, 디코더 모델 C에게는 현재 미국의 경차에 대한 규제를 질의 하고 이 두 질의에 대한 응답 문맥 벡터를 병합한 후, 병합된 문맥 벡터로 디코더 모델 A가 스스로 최적의 답을 찾거나, 모델 B, C에게 병합된 문맥벡터(990,991)을 전송하여 모델 B에게는 모델 C가 제시한 미국의 경차 규제를 고려한 답을 요구할 수 있다. 도 10은 문맥벡터를 데이터 저장소에 저장하거나 네트워크로 보내기 위해 차원이 낮은 축약 벡터로 추상화하기 위한 오토 인코더(Auto Encoder)의 하나의 실시 예를 도시한 블록 다이어그램이다. 이는 도 7의 문맥 검색 시스템이 시퀀스 처리 디코더으로부터 받은 문맥벡터를 문맥 벡터 데이 터 저장소에 문맥 벡터와 함께 저장된 축약벡터와 유사도가 높은 문맥 벡터 검색에 활용하기 위해 문 맥벡터를 더 낮은 차원의 축약 벡터로 가공하는데 활용될 수 있다. 아울러, 도9 에서 시퀀스 처리 디코더 모델들이 서로 문맥 벡터를 주고 받는 하나의 실시 예로서, 네트워크 대 역폭 사용량을 최소화하기 위해 문맥 벡터를 더 낮은 차원의 축약 벡터로 가공하는 과정(G.1, G.2, G.3, G.4)에 서도 사용될 수 있다. 또한, 데이터 저장소에 저장하고자 하는 문맥 벡터와 이 문맥 벡터를 축약한 축약 벡터를 저장하는 경우, 문맥 벡터를 축약하는 데에도 사용될 수 있다. 산업상 이용가능성 상기 기술한 바와 같이 본 발명은 사용자(인간)-인공지능 챗봇 간의 문맥 유지 대화, 명령어를 통해 이 미지를 생성하는 모델과 같은 생성 인공지능 모델의 출력 결과를 사용자가 문맥을 유지하며 요구 사항을 가이드 하며 출력 결과의 품질을 점차적 개선, 대용량 데이터에 대한 비지도 학습(Unsupervised Learning)에 있어, 문맥 데이터 저장소의 다양한 문맥 활용을 통한 훈련 (Training)을 통한 모델 성능 향상 데이터 수집이 어 려운 경우, 인간이 서로 회의하며 아이디어를 발전시켜 나가듯, 인공지능 모델 간의 문맥 교환을 통한 의사소통 을 하며 모델의 성능을 점차적으로 향상시키도록 훈련하는 모델 비지도 학습에 활용할 수 있다."}
{"patent_id": "10-2022-0180435", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래의 기술인 트랜스포머와 같은 인코더-디코더로 구성된 시퀀스 처리기의 동작 절차를 도시한 도면, 도 2는 출력 문맥 벡터가 각 1개인 시퀀스 처리 디코더(A.1, A.2, A.3)의 하나의 실시 예를 도시한 도면, 도 3은 출력 문맥 벡터가 각 2개인 시퀀스 처리 디코더의 하나의 실시 예를 도시한 도면,도 4는 병합할 문맥 벡터의 일부만 시퀀스 처리 디코더를 통해 가공, 처리하며 문맥 벡터를 병합하는 과정(B.1, B.2, B.3)의 하나의 실시 예를 도시한 도면 도 5는 병합할 모든 문맥 벡터를 시퀀스 처리 디코더를 통해 가공, 처리하며 문맥 벡터를 병합하는 과정(C.1, C.2, C.3)의 하나의 실시 예를 도시한 도면, 도 6은 문맥 벡터를 데이터 저장소에 저장하고 검색(D.1, D.2, D.3)하는 하나의 실시 예를 도시한 도면, 도 7은 시퀀스 처리 디코더의 문맥 벡터와 가장 유사한 문맥 벡터를 데이터 저장소에서 가져오는 과정의 하나의 실시 예를 도시한 순차(Sequence) 다이어그램, 도 8은 문맥 벡터를 데이터 저장소에서 시퀀스 처리 디코더가 질의한 문맥을 가져오는 과정의 하나의 실시 예를 도시한 순차 다이어그램, 도 9는 여러 시퀀스 처리 디코더 모델들이 질의 문맥 벡터와 질의 응답 벡터를 통해 데이터를 주고받는 과정 (E.1, E.2, F.1, F.2)의 하나의 실시 예를 도시한 순차 다이어그램, 도 10은 문맥벡터를 데이터 저장소에 저장하거나 네트워크로 보내기 위해 차원이 낮은 축약 벡터로 추상화하기 위한 오토 인코더(Auto Encoder)의 하나의 실시 예를 도시한 블록 다이어그램이다."}
