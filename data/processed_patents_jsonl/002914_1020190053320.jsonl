{"patent_id": "10-2019-0053320", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0053154", "출원번호": "10-2019-0053320", "발명의 명칭": "인공지능 서비스를 인터페이싱하는 장치 및 방법", "출원인": "에스케이텔레콤 주식회사", "발명자": "이용희"}}
{"patent_id": "10-2019-0053320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "미디어 리소스 서버(media resource function, MRF)로부터 통화 중에 발생되는 미디어 데이터를 수신하는 통신부와,상기 미디어 데이터에 인공지능 서비스에 대한 요청이 포함되어 있는지를 분석하는 분석부와,상기 분석 결과 상기 요청이 상기 미디어 데이터에 포함되어 있으면, 상기 요청 이후에 상기 미디어 리소스 서버로부터 수신된 제1 미디어 데이터가 상기 통신부를 통해 인공지능 서비스 제공 서버로 전달되도록 제어하고,상기 제1 미디어 데이터의 전달에 대한 응답으로 상기 인공지능 서비스 제공 서버로부터 제2 미디어 데이터가수신되면, 상기 수신된 제2 미디어 데이터가 상기 통신부를 통해 상기 미디어 리소스 서버로 전달되도록 제어하는 제어부를 포함하는인공지능 서비스의 인터페이싱 장치."}
{"patent_id": "10-2019-0053320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 분석부는,상기 미디어 데이터가 기 정의된 형태의 DTMF(dual tone multiple frequency) 신호를 포함하면, 상기 요청이포함되어 있는 것으로 분석하는인공지능 서비스의 인터페이싱 장치."}
{"patent_id": "10-2019-0053320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 분석부는,상기 미디어 데이터가 기 정의된 음성 패턴을 가지면, 상기 요청이 포함되어 있는 것으로 분석하는인공지능 서비스의 인터페이싱 장치."}
{"patent_id": "10-2019-0053320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 제어부는,상기 미디어 리소스 서버에게 명령을 전달하여서, 상기 인공지능 서비스를 요청한 단말 장치의 상대방 단말 장치에게 상기 제2 미디어 데이터가 전달되지 않도록 제어하는인공지능 서비스의 인터페이싱 장치."}
{"patent_id": "10-2019-0053320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 제어부는,상기 요청이 상기 미디어 데이터에 포함되어 있는 것으로 분석되면 상기 미디어 리소스 서버에게 명령을 전달하여서, 상기 인공지능 서비스를 요청한 단말 장치의 상대방 단말 장치에게 대기 음원 또는 대기 영상이 제공되도록 제어하는인공지능 서비스의 인터페이싱 장치.공개특허 10-2019-0053154-3-청구항 6 제 5 항에 있어서,상기 제어부는,상기 요청이 수신된 이후부터 상기 제2 미디어 데이터가 전달되기 전까지, 상기 대기 음원 또는 상기 대기 영상이 상기 상대방 단말 장치에게 제공되도록 제어하는인공지능 서비스의 인터페이싱 장치."}
{"patent_id": "10-2019-0053320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 분석부는 상기 인공지능 서비스를 요청한 단말 장치에 입력되는 음성의 크기를 상기 미디어 리소스 서버로부터 전달받아서 인식하고,상기 제어부는,상기 미디어 리소스 서버에게 명령을 전달하여서, 상기 단말 장치에 입력되는 음성의 크기를 기초로 상기 제2미디어 데이터의 볼륨 크기가 조절되도록 제어하는인공지능 서비스의 인터페이싱 장치."}
{"patent_id": "10-2019-0053320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 통신부는 응용 서비스 노드(telephony application server, TAS)로부터 상호 간에 통화가 연결된 단말 장치들에 대한 정보를 전달받고,상기 분석부는,상기 정보가 전달받은 이후, 상기 통신부를 통해 수신되는 미디어 데이터에 상기 요청이 포함되어 있는지 여부를 분석하는인공지능 서비스의 인터페이싱 장치."}
{"patent_id": "10-2019-0053320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 분석부는,상기 인공지능 서비스 제공 서버로부터 전달받은 객체(object)를 통해 구현되되, 상기 객체는 상기 미디어 리소스 서버를 통해서 상기 단말 장치들 간의 통화에 참여자로서 개입하는인공지능 서비스의 인터페이싱 장치."}
{"patent_id": "10-2019-0053320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "인공지능 서비스의 인터페이싱 장치에 의하여 수행되는 인공지능 서비스를 인터페이싱하는 방법으로서,미디어 리소스 서버(media resource function, MRF)로부터 통화 중에 발생되는 미디어 데이터를 수신하는 단계와,상기 미디어 데이터에 인공지능 서비스에 대한 요청이 포함되어 있는지를 분석하는 단계와,상기 분석 결과 상기 요청이 상기 미디어 데이터에 포함되어 있으면, 상기 요청 이후에 상기 미디어 리소스 서버로부터 수신된 제1 미디어 데이터를 인공지능 서비스 제공 서버로 전달하는 단계와,상기 제1 미디어 데이터의 전달에 대한 응답으로 상기 인공지능 서비스 제공 서버로부터 제2 미디어 데이터를수신하는 단계와,공개특허 10-2019-0053154-4-상기 수신된 제2 미디어 데이터를 상기 미디어 리소스 서버로 전달하는 단계를 포함하는인공지능 서비스를 인터페이싱 하는 방법."}
{"patent_id": "10-2019-0053320", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에 따른 인공지능 서비스의 인터페이싱 장치는 미디어 리소스 서버(media resource function, MRF)로부 터 통화 중에 발생되는 미디어 데이터를 수신하는 통신부와, 상기 미디어 데이터에 인공지능 서비스에 대한 요청 이 포함되어 있는지를 분석하는 분석부와, 상기 분석 결과 상기 요청이 상기 미디어 데이터에 포함되어 있으면, 상기 요청 이후에 상기 미디어 리소스 서버로부터 수신된 제1 미디어 데이터가 상기 통신부를 통해 인공지능 서 비스 제공 서버로 전달되도록 제어하고, 상기 제1 미디어 데이터의 전달에 대한 응답으로 상기 인공지능 서비스 제공 서버로부터 제2 미디어 데이터가 수신되면, 상기 수신된 제2 미디어 데이터가 상기 통신부를 통해 상기 미 디어 리소스 서버로 전달되도록 제어하는 제어부를 포함한다."}
{"patent_id": "10-2019-0053320", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 서비스를 인터페이싱하는 장치 및 방법에 관한 것이다. 보다 자세하게는 통화 중에 단말 장치가 요청하는 인공지능 서비스를 처리하고, 이러한 요청에 따른 응답이 단말 장치에게 제공될 수 있도록 인 터페이싱하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2019-0053320", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "스마트폰 또는 스마트 패드와 같은 스마트 기기는 음성/영상 통화 기능, 그리고 데이터 통신 기능을 제공한다. 특히, VoLTE 서비스에서는 데이터 통신 뿐만 아니라 음성/영상 통화까지도 LTE 시스템을 통해 제공된다. VoLTE 서비스에 따르면, 음성/영상 통화 중에도 사용자는 상대방과 실시간으로 지도, 음악, 뉴스 또는 사진과 같은 컨 텐츠를 공유할 수 있다. 한편 최근에는 인공지능 서비스를 제공하는 서버가 등장하고 있다. 인공지능 서비스 제공 서버는 학습 기능을 갖추고 있기에, 사용될수록 수준 높은 서비스를 제공할 수 있다. 스마트 기기는 이러한 인공지능 서비스 제공 서버에 데이터 통신 기능을 이용하여 접속할 수 있으며, 사용자는 이러한 스마트 기기를 통해 다양한 서비스를 제공받을 수 있다. 예컨대, 사용자는 스마트 기기를 통해 인공지능 서비스 제공 서버에게 날씨나 개인 스케쥴 에 대한 간단한 질문 뿐 아니라 보다 복잡하고 고도한 정보에 대한 질의까지도 할 수 있으며, 이에 대한 응답을 제공받을 수 있다. 전술한 스마트 기기는 음성/영상 통화가 수행되는 경우에도 인공지능 서비스 제공 서버에 접속할 수 있으며, 따 라서 사용자는 음성/영상 통화 중에도 인공지능 서비스를 제공받을 수 있다. 그런데, 사용자가 음성/영상 통화 중에 인공지능 서비스를 제공받기 위해서는, 이를 위한 별도의 어플리케이션이 실행되어야 한다. 예컨대, 사용 자는 통화 중에 웹브라우저 또는 별도의 어플리케이션을 실행한 뒤 인공지능 서비스 제공 서버에 접속하여서, 원하는 정보를 요청하여야 한다. 인공지능 서비스 제공 서버로부터 응답이 오면, 이러한 응답은 해당 어플리케 이션을 통해서 제공될 수 있다. 만약 사용자가 상대방과 이러한 응답을 공유하기를 원하는 경우, 사용자는 통 화 중 또는 통화 종료 후에 이메일을 통해 응답을 전달하거나 또는 별도의 어플리케이션을 통해 전달할 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국특허공개공보, 제 2011-0041322호 (2011.04.21. 공개)"}
{"patent_id": "10-2019-0053320", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에 본 발명이 해결하고자 하는 과제는, 음성/영상 통화 중에 별도의 요청하는 어플리케이션을 통하지 않고 단 말 장치를 통해 요청되는 인공지능 서비스를 처리하고, 그 결과를 음성/영상 통화를 이용하여 단말 장치에게 제 공하는 기술을 제공하는 것이다. 다만, 본 발명의 해결하고자 하는 과제는 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른 해 결하고자 하는 과제는 아래의 기재로부터 본 발명이 속하는 통상의 지식을 가진 자에게 명확하게 이해될 수 있 을 것이다."}
{"patent_id": "10-2019-0053320", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 인공지능 서비스의 인터페이싱 장치는 미디어 리소스 서버(media resource function, MRF)로 부터 통화 중에 발생되는 미디어 데이터를 수신하는 통신부와, 상기 미디어 데이터에 인공지능 서비스에 대한 요청이 포함되어 있는지를 분석하는 분석부와, 상기 분석 결과 상기 요청이 상기 미디어 데이터에 포함되어 있 으면, 상기 요청 이후에 상기 미디어 리소스 서버로부터 수신된 제1 미디어 데이터가 상기 통신부를 통해 인공 지능 서비스 제공 서버로 전달되도록 제어하고, 상기 제1 미디어 데이터의 전달에 대한 응답으로 상기 인공지능 서비스 제공 서버로부터 제2 미디어 데이터가 수신되면, 상기 수신된 제2 미디어 데이터가 상기 통신부를 통해 상기 미디어 리소스 서버로 전달되도록 제어하는 제어부를 포함한다. 일 실시예에 따른 인공지능 서비스의 인터페이싱 방법은 미디어 리소스 서버(media resource function, MRF)로 부터 통화 중에 발생되는 미디어 데이터를 수신하는 단계와, 상기 미디어 데이터에 인공지능 서비스에 대한 요 청이 포함되어 있는지를 분석하는 단계와, 상기 분석 결과 상기 요청이 상기 미디어 데이터에 포함되어 있으면, 상기 요청 이후에 상기 미디어 리소스 서버로부터 수신된 제1 미디어 데이터를 인공지능 서비스 제공 서버로 전 달하는 단계와, 상기 제1 미디어 데이터의 전달에 대한 응답으로 상기 인공지능 서비스 제공 서버로부터 제2 미 디어 데이터를 수신하는 단계와, 상기 수신된 제2 미디어 데이터를 상기 미디어 리소스 서버로 전달하는 단계를 포함한다."}
{"patent_id": "10-2019-0053320", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시예에 따르면 단말 장치들 간의 통화 중에도 어느 하나의 단말 장치로부터 인공지능 서비스에 대한 요청 이 있는지를 검출할 수 있고, 이러한 요청에 따른 인공지능 서비스를 해당 단말 장치에게 제공할 수 있다. 또 한, 어느 하나의 단말 장치가 요청한 인공지능 서비스의 요청 내용 또는 결과물은 상대방 단말 장치에게 제공되 지 않도록 설정될 수 있으며, 만약 상대방 단말 장치에게 해당 요청 내용이나 결과물이 제공되지 않는 경우라면 기 정의된 대기 음원이나 대기 영상이 제공될 수 있다."}
{"patent_id": "10-2019-0053320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하"}
{"patent_id": "10-2019-0053320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명 은 청구항의 범주에 의해 정의될 뿐이다. 본 발명의 실시예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명의 실시예에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 도 1은 일 실시예에 따른 인공지능 인터페이싱 장치가 적용된 이동통신망을 개념적으로 도시한 도면이다. 다만, 도 1은 예시적인 것에 불과하므로, 인공지능 인터페이싱 장치(이하, 인터페이싱 장치라고 지칭)가 도 1에 도시된 이동통신망에만 적용되는 것으로 한정 해석되지는 않는다. 도 1을 참조하면, 이동통신망은 인터페이싱 장치, 인공지능 서비스 제공 서버 및 호처리망 을 포함할 수 있다. 제1 단말 장치(300/1)와 제2 단말 장치(300/2)는 각각 이러한 이동통신망에 접속하는 단말을 예시적으로 도시한 것이며, 각 단말 장치(300/1,300/2)는 이들 이동통신망에 접속하여서 음성/영상통화나, 또는 인공지능 서비스와 같은 데이터 서비스를 제공받을 수 있다. 먼저, 인공지능 서비스 제공 서버는 인공지능 서비스를 제공하는 서버를 지칭한다. 인공지능 서비스 제공 서버는 단말 장치(300/1,300/2) 이외에도 다양한 단말이나 서버와 연결될 수 있으며, 이들 각각에게 다양 한 인공지능 서비스를 제공할 수 있다. 도 2는 이러한 인공지능 서비스 제공 서버의 구성을 도시한 도면이다. 도 2를 참조하면, 인공지능 서비스 제공 서버는 인공지능 처리를 수행하는 인공지능 처리부(intelligence workflow, IWF), 자연어를 처 리하는 자연어 처리부(natural language understand) 또는 음성 합성을 수행하는 음성 합성부(text to speech, TTS) 모듈을 포함할 수 있다. 아울러, 이러한 인공지능 서비스 제공 서버는 복수 개의 서버 로 이루어진 서버군으로서 형성될 수 있다. 다시 도 1을 참조하면, 호처리망은 단말 장치(300/1,300/2) 들이 접속하는 통신망이다. 도 3은 호처리망 에 대한 구성을 개념적으로 도시한 도면이다. 도 3을 참조하면, 호처리망은 크게 지능망과 레거시 (legacy) 호처리망으로 구성되며, 레거시 호처리망 내에 LTE 호처리망이 포함될 수 있으며, 이 와 같이 구성되는 것으로 한정 해석되지 않는다. 이 중 지능망은 예컨대 지능망 노드로서 정의될 수 있는 IMS(IP multimedia subsystem)수 있다. 지능망 은 교환기망(Call Session Control Function,CSCF), 응용 서비스 노드(telephony application server, TAS) 또는 미디어 리소스 서버(media resource function, MRF)를 포함하며, 그 외에 HLR(Home Location Register), MGCF(Media Gateway Control Function), MGW(Media Gateway), SCC AS(Service Centralization and Continuity Application Server) 등을 포함할 수 있다. 아울러, 이 하에서 설명할 각 구성들이 수행하는 기능은 예시적인 것에 불과하다. 따라서, 각 구성들은 이하에서 기술되는 기능 이외의 다른 기능들을 추가적으로 수행할 수 있다. 이 중 교환기망은 각 단말 장치(300/1,300/2)의 위치, 즉 해당 단말 장치가 어떠한 기지국에 연결되어 있 는지에 대한 정보를 획득한다. 응용 서비스 노드는 전화와 관련된 기본 기능 및 전화와 관련된 부가 서비스(call hold, swap, forward) 등을 처리한다. 예컨대 응용 서비스 노드는 단말 장치(300/1)가 인공지능 서비스를 이용할 수 있는지, 즉 이러한 서비스를 사전에 신청한 단말 장치인지 여부 등을 판단하고 처리할 수 있다. 또한, 응용 서비스 노드는 단말 장치 상호 간에 통화가 연결되거나 끊긴 경우, 이를 이하에서 설명할 인터 페이싱 장치에게 통보할 수 있다. 미디어 리소스 서버는 코덱 변환을 수행한다. 코덱 변환을 통해, 서로 상이한 사양의 단말 장치 간의 패 킷 교환이 가능하다. 이를 위해, 미디어 리소스 서버는 코덱 변환 모듈을 포함할 수 있다. 미디어 리소스 서버는 미디어 데이터를 전달(forking)한다. 예컨대 미디어 리소스 서버는 제1 단말 장치(300/1)와 제2 단말 장치(300/2) 간에 음성/영상이 전달되도록 할 수 있다. 또한 미디어 리소스 서버(41 3)는 각 단말 장치(300/1,300/2)로부터 전달받은 미디어 데이터를 인터페이싱 장치에게 전달할 수 있으며, 또한 반대 방향으로 전달할 수도 있다. 이를 위해, 미디어 리소스 서버는 각 단말 장치(300/1,300/2) 또 는 인터페이싱 장치와의 통신을 위한 통신 모듈을 포함할 수 있다. 미디어 리소스 서버는 미디어 데이터를 믹싱(mixing)(또는 먹싱(muxing))한다. 미디어 데이터란 각 단말 장치(300/1,3002)에게 제공되는 음성/영상 통화, 데이터 패킷 또는 DTMF(dual tone multiple frequency) 신호 등을 포함할 수 있으며 다만 이에 한정되는 것은 아니다. 믹싱에 있어서, 미디어 리소스 서버는 다양한 객체로부터 전달받은 음원들을 서로 믹싱할 수 있다. 예컨 대, 미디어 리소스 서버는 각 단말 장치(300/1,300/2)에게 전달될 음성/영상에 인공지능 서비스 제공 서버 로부터 전달받은 음성 신호를 믹싱할 수 있으며, 또한 각 단말 장치(300/1,3002)에게 전달될 음성/영상에 기 정의된 음원이나 영상(이하에서는 대기 음원 또는 대기 영상이라고 지칭)을 믹싱할 수 있다. 아울러, 미디 어 리소스 서버는 믹싱되는 음원들의 크기를 조절할 수 있는데, 이러한 조절은 응용 서비스 노드로부 터 전달받은 명령에 의해 수행 가능하다. 이를 위해, 미디어 리소스 서버는 믹싱 모듈을 포함할 수 있다. 미디어 리소스 서버는 미디어 데이터를 분석할 수 있다. 예컨대, 미디어 리소스 서버는 미디어 데이 터를 분석하여서, 이러한 미디어 데이터에 기 정의된 DTMF 신호가 포함되어 있는지 여부를 분석할 수 있다. 이 를 위해, 미디어 리소스 서버는 신호 분석 모듈을 포함할 수 있다. 다만, 미디어 리소스 서버가 미디어 데이터를 분석하여서, 이러한 미디어 데이터에 기 정의된 DTMF 신호가 포함되어 있는지 여부를 분석하는 특징은 실시예에 따라서 구현되거나 구현되지 않을 수도 있다. 한편, 도시된 HLR(Home Location Register), MGCF(Media Gateway Control Function), MGW(Media Gateway), SCC AS(Service Centralization and Continuity Application Server)의 경우 이미 공지 된 구성과 동일하므로 이에 대한 설명은 생략하기로 한다. 다음으로, 레거시 호처리망은 예컨대 WCDMA와 같은 이동통신망을 의미할 수 있으며, 각 단말 장치 (300/1,300/2)에게 서킷 기반의 음성/영상 서비스를 제공할 수 있다. 레거시 호처리망은 MSC(mobile switching center) 또는 홈 위치 등록기(home location register, HLR)를 포함하고, 그 외에 GGSN(Gateway General packet radio service Support Node), NodeB, RNC(Radio Network Controller), SGSN(Serving General packet radio service Support Node), CGS(Cellular Gateway Switch) 등을 포함하거나 이들과 연결될 수 있다. 아울러, 레거시 호처리망은 공지된 망과 동일한 구성을 가질 수 있는 바, 이러한 레거시 호처리망의 각 구성에 대한 자세한 설명은 생략하기로 한다. LTE 패킷망은 예컨대 LTE 이동통신망일 수 있으며, 각 단말 장치(300/1,300/2)에게 패킷 데이터를 전달 할 수 있다. LTE 패킷망은 MME(mobility management entity) 또는 PGW(packet data network gateway)를 포함하며, 이외에도 eNodeB, SGW(Serving Gateway), PCRF(Policy & Charging Rule Function), HSS(Home Subscriber Server) 등을 포함하거나 이들과 연결될 수 있다. 아울러, LTE 패 킷망은 공지된 망과 동일한 구성을 가질 수 있는 바, 이러한 LTE 패킷망에 대한 자세한 설명은 생략 하기로 한다. 다시 도 1을 참조하면, 각 단말 장치(300/1,300/2)는 호처리망을 구성하는 복수 개의 셀 중의 어느 하나 (또는 둘 이상)의 셀에 위치하여서 음성/영상 통화 또는 인공지능 서비스와 같은 데이터 서비스를 제공받을 수 있다. 이러한 단말 장치(300/1,300/2)는 스마트폰이나 스마트 패드 또는 태블릿 패드와 같이 다양한 형태로 구 현 가능하다. 도 1에 도시된 단말 장치(300/1,300/2) 중 어느 하나의 단말 장치가 발신 단말이면 다른 하나의 단말 장치는 수신 단말일 수 있다. 도 4는 도 1에 도시된 인터페이싱 장치의 구성을 도시한 도면이다. 먼저, 인터페이싱 장치는 이하에서 설 명할 기능을 수행하는 서버군에서 구현 가능하다. 아울러, 인터페이싱 장치는 단말 장치(300/1,300/2)들 간의 통화 중에, 어느 하나의 단말 장치(300/1)가 요청하는 인공지능 서비스를 인공지능 서비스 제공 서버(20 0)와 연동하여서 처리하고, 이러한 요청에 따른 응답을 단말 장치(300/1 또는 300/2)에게 제공할 수 있다. 도 4를 참조하면, 인터페이싱 장치는 통신부, 분석부 및 제어부를 포함하며, 다만 이에 한 정되는 것은 아니다. 통신부는 미디어 데이터와 같은 데이터를 각 단말 장치(300/1,300/2), 응용 서비스 노드 또는 인공지 능 서비스 제공 서버와 송수신하며, 유선 또는 무선 통신 모듈을 포함할 수 있다. 분석부와 제어부는 이하에서 설명할 기능을 수행하도록 프로그램된 명령어를 저장하는 메모리와, 이 러한 명령어를 실행하는 마이크로프로세서에 의해 구현 가능하다. 이 중, 분석부에 대해 먼저 살펴보면, 분석부는 통신부를 통해 수신된 미디어 데이터에 인공지 능 서비스에 대한 요청이 포함되어 있는지를 분석한다. 예컨대 분석부는, 단말 장치들(300/1,300/2) 간의 통화 중에 통신부를 통해서 단말 장치(300/1)로부터 미디어 데이터가 수신되면, 이러한 미디어 데이터에 기 정의된 DTMF(dual tone multiple frequency) 신호가 포함되어 있는지를 분석할 수 있다. 분석 결과, 미디 어 데이터에 기 정의된 DTMF 신호가 포함된 경우, 분석부는 해당 단말 장치(300/1)가 인공지능 서비스를 요청한 것으로 분석할 수 있다. 또는, 분석부는, 단말 장치들(300/1,300/2) 간의 통화 중에 통신부 를 통해서 단말 장치(300/1)로부터 미디어 데이터가 수신되면, 이러한 미디어 데이터에 기 정의된 음성 패턴, 예컨대 '아리야'와 같은 음성 패턴이 포함되어 있는지를 분석할 수 있다. 분석 결과, 미디어 데이터에 기 정의 된 음성 패턴이 포함된 경우, 분석부는 해당 단말 장치(300/1)가 인공지능 서비스를 요청한 것으로 분석할 수 있다. 즉, 일 실시예에 따르면 단말 장치들 간의 통화 중에도 어느 하나의 단말 장치로부터 인공지능 서비스에 대한 요청이 있는지를 검출할 수 있다. 이러한 분석부는 다양한 실시예의 형태로서 구현 가능하다. 예컨대, 제1 실시예로서, 분석부는 미디 어 데이터가 DTMF 신호를 포함하는지 또는 이러한 미디어 데이터가 기 정의된 음성 패턴을 포함하는지 여부를 분석하는 분석 모듈의 형태로 구현 가능하다. 제2 실시예로서, 분석부는 인공지능 서비스 제공 서버(20 0)에게 미디어 데이터를 전달하면서 분석을 의뢰하고, 인공지능 서비스 제공 서버로부터 그 결과를 전달받 는 모듈의 형태로 구현 가능하다. 제3 실시예로서, 분석부는 인공지능 서비스 제공 서버로부터 전달 받은 객체(object)에 의해 인터페이싱 장치에서 구현될 수 있는데, 이러한 분석부는 미디어 리소스 서버를 통해 단말 장치들(300/1,300/2) 간의 통화에 그룹 통화의 일원으로서 참여할 수 있다. 분석부 가 그룹 통화의 일원으로서 참여할 경우, 분석부는 단말 장치들(300/1,300/2) 간에 송수신되는 미디 어 데이터를 그룹 통화의 참여자로서 전달받고 이를 분석할 수 있다. 한편, 분석부에 의해 수행되는 전술한 절차, 즉 미디어 데이터에 인공지능 서비스에 대한 요청이 포함되어 있는지를 분석하는 절차는, 단말 장치들(300/1,300/2) 상호 간에 통화가 연결된 이후에 수행될 수 있다. 이를 위해, 응용 서비스 노드는 단말 장치들(300/1,300/2) 상호 간에 통화가 연결되면, 이를 분석부에게 통보할 수 있으며, 이러한 통보를 받은 인터페이싱 장치는 그 후부터 '리스닝 모드'에 진입하였다고 할 수 있다. 한편, 실시예에 따라서 미디어 리소스 서버는 미디어 데이터에 DTMF 신호가 포함되어 있는지 여부를 분석 할 수도 있는데, 이 경우에 분석부는 미디어 데이터에 DTMF 신호가 포함되어 있는지를 분석하지 않고 미디 어 리소스 서버로부터 분석된 결과를 전달받기만 할 수도 있다. 다만, 이하에서는 분석부가 미디어 데이터에 DTMF 신호가 포함되어 있는지를 분석하고, 그 대신 미디어 리소스 서버는 이러한 기능을 수행하 지 않는 것을 전제로 설명하기로 한다. 분석부는 미디어 데이터가 음성/영상 통화인 경우, 이에 포함된 소리의 크기를 분석한다. 예컨대, 분석부 는 각 단말 장치(300/1,300/2)로 입력되는 사용자의 음성을 미디어 리소스 서버로부터 전달받은 뒤, 음성의 크기(볼륨)를 분석할 수 있다. 이를 위해, 분석부는 음성의 크기를 분석하는 분석 모듈을 포함할 수 있다. 분석부에 의해 분석된 음성의 크기는, 이후에서 설명하겠지만 인공지능 서비스 제공 서버 가 제공하는 미디어 데이터의 볼륨 크기의 조절에 활용될 수 있다. 제어부는 미디어 리소스 서버와 인공지능 서비스 제공 서버 사이에서 이들 간에 미디어 데이터 가 전달되도록 제어한다. 즉, 제어부에 의해, 미디어 리소스 서버로부터 전달받은 미디어 데이터는 인공지능 서비스 제공 서버에게 전달되고, 인공지능 서비스 제공 서버로부터 전달받은 미디어 데이터 는 미디어 리소스 서버에게 전달될 수 있다. 이 때, 미디어 리소스 서버로부터 전달받은 미디어 데 이터가 인공지능 서비스 제공 서버에게 전달되는 과정은 forking이라고 지칭될 수도 있다. 이하에서는 인공지능 서비스 제공 서버에게 전달되는 미디어 데이터는 제1 미디어 데이터라고 지칭하고, 인공지능 서비스 제공 서버로부터 전달받은 미디어 데이터는 제2 미디어 데이터라고 지칭하기로 한다. 제 1 미디어 데이터는 단말 장치(300/1)가 인공지능 서비스 제공 서버에게 인공지능 서비스를 요청한 실질적 인 사항(예컨대, 날씨에 대한 문의 또는 개인 스케쥴에 대한 문의 등)을 포함할 수 있으나 다만 이에 한정되는 것은 아니다. 또한, 제2 미디어 데이터는 인공지능 서비스 제공 서버가 제1 미디어 데이터에 대한 응답일 수 있으나 이에 한정되는 것은 아니다. 제어부는 인공지능 서비스를 요청한 단말 장치(300/1)의 상대방 단말 장치(300/2)에게 어떠한 미디어 데이 터가 전달될지를 다양한 실시예의 형태로 제어할 수 있다. 예컨대, 제1 실시예로서, 제어부는 상대방 단 말 장치(300/2)에게 제1 미디어 데이터(단말 장치(300/1)의 인공지능 서비스에 대한 요청) 및 제2 미디어 데이 터(제1 미디어 데이터에 대한 인공지능 서비스 제공 서버의 응답)가 모두 전달되도록 제어할 수 있다. 또 는, 제2 실시예로서, 제어부는 상대방 단말 장치(300/2)에게 제1 미디어 데이터만 제공되고 제2 미디어 데 이터는 제공되지 않도록 제어하거나 또는 제1 미디어 데이터와 제2 미디어 데이터 모두가 제공되지 않도록 제어 할 수 있다. 제2 실시예에서 제어부는 상대방 단말 장치(300/2)에게 제2 미디어 데이터가 제공되지 않는 시간 또는 제1 미디어 데이터와 제2 미디어 데이터가 제공되지 않는 시간 동안에는 기 정의된 대기 음원이나 대 기 영상이 제공되도록 제어할 수 있으며, 또는 상대방 단말 장치(300/2)가 대기 통화(call hold) 상태가 되도록 제어할 수 있다. 전술한 제1 실시예 또는 제2 실시예의 구현을 위해, 제어부는 미디어 리소스 서버 에게 해당하는 실시예의 구현을 위한 명령을 전달할 수 있다. 여기서, 제어부가 제1 실시예와 제2 실시예 중 어떠한 실시예에 따라서제어할지 여부는 다양한 방법으로 결정될 수 있다. 예컨대, 인공지능 서비스에 대한 요청으로서 DTMF 신호가 입력된 경우, DTMF 신호의 패턴 (1234# or 1111*)에 따라서 제1 실시예와 제2 실시예 중 어느 하나로 결정될 수 있다. 즉, 단말 장치(300/1)의사용자는 자신의 원하는 형태에 따른 DTMF 신호의 패턴을 입력할 수 있으며, 이러한 DTMF 신호의 패턴에 따라서 제1 실시예와 제2 실시예 중 어느 하나로 결정될 수 있다. 이와 달리, 사용자(단말 장치(300/1)의 사용자 또는 단말 장치(300/2)의 사용자)가 사전에 등록한 사항에 따라서 제1 실시예와 제2 실시예 중 어느 하나로 결정될 수 있다. 즉, 일 실시예에 따르면, 어느 하나의 단말 장치가 요청한 인공지능 서비스의 요청 내용 또는 결과물은 상대방 단말 장치에게 제공되거나 제공되지 않을 수 있으며, 만약 상대방 단말 장치에게 해당 요청 내용이나 결과물이 제공되지 않는다면 그 대신 기 정의된 대기 음원이나 대기 영상이 제공될 수 있다. 제어부는 제2 미디어 데이터의 볼륨 크기가 조절되도록 제어할 수 있다. 이를 위해 제어부는 각 단 말 장치(300/1,300/2)로 입력되는 음성의 크기를 고려할 수 있다. 이 때, 각 단말 장치(300/1,300/2)로 입력되 는 음성의 크기는 전술한 바와 같이 분석부로부터 전달받은 것일 수 있다. 예컨대, 단말 장치(300/1)로 입력되는 음성의 크기가 기 설정된 기준보다 크다면, 제2 미디어의 볼륨 크기는 작게 조절될 수 있으며, 음성의 크기가 기준보다 작다면, 제2 미디어의 볼륨 크기는 크게 조절될 수 있으나 이에 한정되는 것은 아니다. 아울 러, 제어부는 단말 장치(300/1)와 단말 장치(300/2) 각각에게 제공되는 제2 미디어 데이터의 볼륨 크기가 서로 상이하도록 제어할 수 있다. 즉, 일 실시예에 따르면, 사용자의 음성과 인공지능 서비스 제공 서버가 제공하는 제2 미디어 데이터의 볼륨 크 기가 상대적으로 조절될 수 있다. 제어부는 단말 장치(300/1)와 단말 장치(300/2) 간의 통화가 종료되었다는 사실을 응용 서비스 노드 로부터 전달받을 수 있으며, 이 경우 제어부는 미디어 리소스 서버 및 인공지능 서비스 제공 서버 각각과의 연결 관계가 종료되도록 절차를 처리할 수 있다. 이상에서 살펴본 바와 같이, 일 실시예에 따르면 단말 장치들 간의 통화 중에도 어느 하나의 단말 장치로부터 인공지능 서비스에 대한 요청이 있는지를 검출할 수 있다. 또한, 어느 하나의 단말 장치가 요청한 인공지능 서 비스의 요청 내용 또는 결과물은 상대방 단말 장치에게 제공되거나 제공되지 않을 수 있으며, 만약 상대방 단말 장치에게 해당 요청 내용이나 결과물이 제공되지 않는 경우라면 기 정의된 대기 음원 또는 대기 영상이 제공될 수 있다. 도 5는 일 실시예에 따른 인공지능 서비스를 인터페이싱하는 방법의 절차를 도시한 도면이다. 도 5에 도시된 방법은 도 4에 도시된 인터페이싱 장치에 의하여 수행 가능하다. 아울러, 도 5에 도시된 방법은 예시적인 것에 불과하므로, 도 5에 도시된 절차 중 적어도 하나가 수행되지 않거나 도시된 절차의 순서와는 다르게 수행 될 수 있으며, 또한 도시되지 않은 다른 절차가 수행될 수도 있다. 도 5를 참조하면, 미디어 리소스 서버로부터 통화 중에 발생되는 미디어 데이터를 수신하는 단계가 수행된 다(S100). 다음으로, 미디어 데이터에 인공지능 서비스에 대한 요청이 포함되어 있는지를 분석하는 단계가 수 행된다(S110). 다음으로, 단계 S110의 분석 결과 인공지능 서비스에 대한 요청이 미디어 데이터에 포함되어 있 으면, 이러한 요청 이후에 미디어 리소스 서버로부터 수신된 제1 미디어 데이터를 인공지능 서비스 제공 서버로 전달하는 단계가 수행된다(S120). 다음으로, 제1 미디어 데이터의 전달에 대한 응답으로서 인공지 능 서비스 제공 서버로부터 제2 미디어 데이터를 수신하는 단계가 수행된다(S130). 다음으로, 단계 S130 에서 수신된 제2 미디어 데이터를 미디어 리소스 서버에게 전달하는 단계가 수행된다(S140). 이하에서는 도 6을 도 1 내지 5와 함께 참조하여서, 제1 실시예에 따른 인공지능 서비스를 인터페이싱하는 방법 의 흐름에 대하여 살펴보기로 한다. 도 6을 참조하면, 제1 단말 장치(300/1)와 제2 단말 장치(300/2) 간에는 단계 S200의 호 연결 단계를 통해 서로 간에 음성/영상 통화가 개시된다. 제1 단말 장치(300/1)가 발신 단말이라면 제2 단말 장치(300/2)는 착신 단말 일 수 있으며, 이 때의 제2 단말 장치(300/2)는 착신측 호처리망(420 또는 430)에 연결될 수 있다. 응용 서비스 노드는 단말 장치들(300/1,300/2) 상호 간에 음성/영상 통화가 개시되었음을 인터페이싱 장치 에게 전달한다(S210). 그러면, 인공지능 서비스의 인터페이싱 장치는 리스닝 모드에 돌입한다 (S220). 리스닝 모드란 제1 단말 장치(300/1)와 제2 단말 장치(300/2) 중 어느 하나로부터 인공지능 서비스에 대한 요청이 있는지를 검출하는 모드를 의미한다. 제1 단말 장치(300/1)와 제2 단말 장치(300/2) 간에는 음성/영상 통화로 인해 미디어 데이터가 송수신된다 (S300). 미디어 데이터란, 각 단말 장치(300/1,3002)에게 제공되는 음성/영상 통화, 데이터 패킷 또는DTMF(dual tone multiple frequency) 신호 등을 포함할 수 있음은 전술한 바와 같다. 제1 단말 장치(300/1)의 사용자는 단계 S300의 음성/영상 통화 중에 인공지능 서비스를 요청할 수 있다. 이를 위해, 사용자는 제1 단말 장치(300/1)에 DTMF 신호를 입력할 수 있다. 그에 따라 제1 단말 장치(300/1)로부터 미디어 리소스 서버로 전달되는 미디어 데이터에는 DTMF 신호가 포함될 수 있다(S400). 미디어 리소스 서 버는 단계 S400를 통해 전달받은 미디어 데이터를 인터페이싱 장치에게 전달할 수 있다(S410). 그러 면, 인터페이싱 장치의 분석부는 미디어 데이터를 분석하여서 이러한 미디어 데이터에 기 정의된 DTMF 신호가 포함되어 있는지를 분석할 수 있다. 분석 결과 미디어 데이터에 기 정의된 DTMF 신호가 포함되어 있다면, 인터페이싱 장치는 인공지능 서비스에 대한 요청이 있다고 감지할 수 있다(S420). 아울러 도면에 는 도시되지 않았지만 단계 S420 이후부터 미디어 리소스 서버는 forking을 시작할 수 있다. 즉, 미디어 리소스 서버는 제1 단말 장치(300/1)로부터 전달받은 미디어 데이터를 인공지능 서비스의 인터페이싱 장치 에게 전달할 수 있다. 인공지능 서비스에 대한 요청이 있으면, 인터페이싱 장치의 제어부는 미디어 리소스 서버에게 명령을 전달하여서, 제2 단말 장치(300/2)에게 대기 음원 또는 대기 영상이 제공되도록 제어할 수 있다(S430). 이 경우 제2 단말 장치(300/2)에게는 제1 단말 장치(300/1)의 사용자의 음성, 예컨대 인공지능 서비스에 대한 실질적인 요청인 제1 미디어 데이터가 전달되지 않고 그 대신 대기 음원 또는 대기 영상만이 제공될 수 있다 (S440). 다만, 단계 S430과 S440은 선택적으로 수행될 수 있으며, 만약 단계 S430과 S440이 수행되지 않는다면, 제1 단말 장치(300/1)의 사용자의 음성인 제1 미디어 데이터가 제2 단말 장치(300/2)에게 제공될 수 있다. 제1 단말 장치(300/1)의 사용자에 의해 인공지능 서비스가 단계 S400에서 요청된 이후, 제1 단말 장치(300/1)는 제1 미디어 데이터를 미디어 리소스 서버에게 전달할 수 있다(S500). 미디어 리소스 서버는 제1 미 디어 데이터를 인공지능 서비스 제공 서버에게 전달(forking)할 수 있다(S510). 그러면, 인공지능 서비스 제공 서버는 스스로 또는 인터페이싱 장치와 연동하여서 인공지능 프로세스를 처리할 수 있다(S520). 처리의 결과물인 제2 미디어 데이터는 인공지능 서비스 제공 서버로부터 인터페이싱 장치를 거쳐서 미디어 리소스 서버에게 제공될 수 있다(S530). 미디어 리소스 서버는 믹싱을 수행할 수 있다(S540). 여기서의 믹싱은 제2 미디어 데이터, 제1 단말 장치 (300/1)나 제2 단말 장치(300/2)의 각 사용자로부터 입력된 음성/영상이 대상이 될 수 있으며, 이러한 단계 S540은 선택적으로 수행될 수 있다. 아울러, 단계 S540에서 미디어 리소스 서버는 제2 미디어 데이터의 볼륨 크기를 제1 단말 장치(300/1)나 제2 단말 장치(300/2)의 각 사용자로부터 입력되는 음성/영상의 볼륨 크기 를 기초로 조절할 수 있는데, 이러한 조절은 인터페이싱 장치의 제어부로부터 전달받은 명령에 따른 것일 수 있다. 제2 미디어 데이터는 제1 단말 장치(300/1)에게 전달될 수 있다(S550). 또한, 제2 미디어 데이터는 제2 단말 장치(300/2)에게도 전달될 수 있다(S560). 여기서 단계 S550과 S560에서 전달되는 제2 미디어 데이터는 단계 S540이 수행되는지에 따라서 각 사용자로부터 입력된 음성/영상과 믹싱된 형태일 수 있다. 아울러, 단계 S560 은 선택적으로 수행 가능하다. 이 후, 제1 단말 장치(300/1)와 제2 단말 장치(300/2) 간의 호가 종료될 수 있다(S600). 그러면, 응용 서비스 노드는 호가 종료되었음을 인식한 뒤 이를 인터페이싱 장치에게 전달할 수 있다(S610). 그러면, 인 터페이싱 장치의 제어부는 미디어 리소스 서버와의 관계에서 절차를 종료할 수 있고(S620), 또 한 도면에는 도시되지 않았지만 인공지능 서비스 제공 서버와의 관계에서도 절차를 종료할 수 있다. 이하에서는 도 7을 도 1 내지 5와 함께 참조하여서, 제2 실시예에 따른 인공지능 서비스를 인터페이싱하는 방법 의 흐름에 대하여 살펴보기로 한다. 도 7을 참조하면, 제1 단말 장치(300/1)와 제2 단말 장치(300/2) 간에는 단계 S1200의 호 연결 단계를 통해 서 로 간에 음성/영상 통화가 개시된다. 제1 단말 장치(300/1)가 발신 단말이라면 제2 단말 장치(300/2)는 착신 단말일 수 있으며, 이 때의 제2 단말 장치(300/2)는 착신측 호처리망(420 또는 430)에 연결될 수 있다. 응용 서비스 노드는 단말 장치들(300/1,300/2) 상호 간에 음성/영상 통화가 개시되었음을 인지한다. 이 때 도면에는 도시되지 않았지만, 응용 서비스 노드는 각 단말 장치들(300/1,300/2)이 인공지능 서비스를 이용할 수 있는지, 즉 이러한 서비스를 사전에 신청한 단말 장치인지 여부 등을 판단하고 처리할 수 있다. 사 전에 단말 장치가 이러한 서비스를 신청하지 않았다면, 이하의 절차는 수행되지 않는다. 그러나, 단말 장치가 사전에 이러한 서비스를 신청하였다면, 응용 서비스 노드는 인공지능 서비스의 인터 페이싱 장치에게 단말 장치들(300/1,300/2) 상호 간에 음성/영상 통화가 개시되었음을 전달한다(S1210). 그러면, 인공지능 서비스의 인터페이싱 장치는 리스닝 모드에 돌입한다(S1220). 리스닝 모드란 제1 단말 장치(300/1)와 제2 단말 장치(300/2)로부터 인공지능 서비스에 대한 요청이 있는지를 검출하는 모드를 의미한다. 또한, 미디어 리소스 서버 또한 forking을 시작한다. 제1 단말 장치(300/1)와 제2 단말 장치(300/2) 간에는 음성/영상 통화로 인해 미디어 데이터가 송수신된다 (S1300). 제1 단말 장치(300/1)의 사용자는 단계 S1300의 음성/영상 통화 중에 인공지능 서비스를 요청할 수 있다. 이를 위해, 사용자는 기 정의된 음성 패턴을 제1 단말 장치(300/1)에게 입력할 수 있다. 그에 따라 제1 단말 장치 (300/1)로부터 미디어 리소스 서버로 전달되는 미디어 데이터에는 이러한 음성 패턴이 포함될 수 있다 (S1400). 미디어 리소스 서버는 단계 S1400를 통해 전달받은 미디어 데이터를 인터페이싱 장치에게 전달(forking)할 수 있다(S1410). 그러면, 인터페이싱 장치의 분석부는 미디어 데이터를 분석하여서 이러한 미디어 데이터에 기 정의된 음성 패턴이 포함되어 있는지를 분석할 수 있다. 분석 결과 미디어 데이터 에 기 정의된 음성 패턴이 포함되어 있다면, 인터페이싱 장치는 인공지능 서비스에 대한 요청이 있음을 감 지할 수 있다(S1420). 인공지능 서비스에 대한 요청이 있으면, 인터페이싱 장치의 제어부는 미디어 리소스 서버에게 명령을 전달하여서, 제2 단말 장치(300/2)에게 대기 음원 또는 대기 영상이 제공되도록 제어할 수 있다(S1430). 이 경우 제2 단말 장치(300/2)에게는 제1 단말 장치(300/1)의 사용자의 음성, 예컨대 인공지능 서비스에 대한 실질적인 요청인 제1 미디어 데이터가 전달되지 않고 그 대신 대기 음원 또는 대기 영상만이 제공될 수 있다 (S1440). 다만, 단계 S1430과 S1440은 선택적으로 수행될 수 있으며, 만약 단계 S1430과 S1440이 수행되지 않 는다면, 제1 단말 장치(300/1)의 사용자의 음성인 제1 미디어 데이터가 제2 단말 장치(300/2)에게 제공될 수 있 다. 제1 단말 장치(300/1)의 사용자에 의해 인공지능 서비스가 단계 S1400에서 요청된 이후, 제1 단말 장치(300/1) 는 제1 미디어 데이터를 미디어 리소스 서버에게 전달할 수 있다(S1500). 미디어 리소스 서버는 제1 미디어 데이터를 인공지능 서비스 제공 서버에게 전달(forking)할 수 있다(S1510). 그러면, 인공지능 서 비스 제공 서버는 스스로 또는 인터페이싱 장치와 연동하여서 인공지능 프로세스를 처리할 수 있다 (S1520). 처리의 결과물인 제2 미디어 데이터는 인공지능 서비스 제공 서버로부터 인터페이싱 장치를 거쳐서 미디어 리소스 서버에게 제공될 수 있다(S1530). 미디어 리소스 서버는 믹싱을 수행할 수 있다(S1540). 여기서의 믹싱은 제2 미디어 데이터, 제1 단말 장 치(300/1)나 제2 단말 장치(300/2)의 각 사용자로부터 입력된 음성/영상이 대상이 될 수 있으며, 이러한 단계 S1540은 선택적으로 수행될 수 있다. 한편, 단계 1S540에서 미디어 리소스 서버는 제2 미디어 데이터의 볼륨 크기를 제1 단말 장치(300/1)나 제2 단말 장치(300/2)의 각 사용자로부터 입력되는 음성/영상의 볼륨 크기 를 기초로 조절할 수 있는데, 이러한 조절은 인터페이싱 장치의 제어부로부터 전달받은 명령에 따른 것일 수 있다. 제2 미디어 데이터는 제1 단말 장치(300/1)에게 전달될 수 있다(S1550). 또한, 제2 미디어 데이터는 제2 단말 장치(300/2)에게도 전달될 수 있다(S1560). 여기서 단계 S1550과 S1560에서 전달되는 제2 미디어 데이터는 단 계 S1540이 수행되는지에 따라서 각 사용자로부터 입력된 음성/영상과 믹싱된 형태일 수 있다. 아울러, 단계 S1560은 선택적으로 수행 가능하다. 이 후, 제1 단말 장치(300/1)와 제2 단말 장치(300/2) 간의 호가 종료될 수 있다(S1600). 그러면, 응용 서비스 노드는 호가 종료되었음을 인식한 뒤 이를 인터페이싱 장치에게 전달할 수 있다(S1610). 그러면, 인 터페이싱 장치의 제어부는 미디어 리소스 서버와의 관계에서 절차를 종료할 수 있고(S1620), 또 한 도면에는 도시되지 않았지만 인공지능 서비스 제공 서버와의 관계에서도 절차를 종료할 수 있다. 이상에서 살펴본 바와 같이, 일 실시예에 따르면 단말 장치들 간의 통화 중에도 어느 하나의 단말 장치로부터 인공지능 서비스에 대한 요청이 있는지를 검출할 수 있고, 이러한 요청에 따른 인공지능 서비스를 해당 단말 장 치에게 제공할 수 있다. 또한, 어느 하나의 단말 장치가 요청한 인공지능 서비스의 요청 내용 또는 결과물은 상대방 단말 장치에게 선택적으로 제공될 수 있으며, 만약 상대방 단말 장치에게 해당 요청 내용이나 결과물이 제공되지 않는 경우라면 기 정의된 대기 음원 또는 대기 영상이 제공될 수 있다.이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 품질에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하 기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 균등한 범위 내에 있는 모든 기술사상은 본 발명의 권 리범위에 포함되는 것으로 해석되어야 할 것이다. 산업상 이용가능성 일 실시예에 따르면, 음성/영상 통화 중에 별도의 어플리케이션을 통하지 않고 요청되는 인공지능 서비스를 처 리하고, 그 결과를 음성/영상 통화를 이용하여 제공하는 기술을 제공할 수 있다."}
{"patent_id": "10-2019-0053320", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 인공지능 인터페이싱 장치가 적용된 이동통신망을 개념적으로 도시한 도면이다. 도 2는 도 1에 도시된 인공지능 서비스 제공 서버의 구성을 도시한 도면이다. 도 3은 도 1에 도시된 호처리망의 구성을 도시한 도면이다. 도 4는 도 1에 도시된 인공지능 인터페이싱 장치의 구성을 도시한 도면이다. 도 5는 일 실시예에 따른 인공지능 인터페이싱 방법의 절차를 도시한 도면이다. 도 6은 일 실시예에 따른 인공지능 인터페이싱 방법의 흐름을 도시한 도면이다. 도 7은 다른 실시예에 따른 인공지능 인터페이싱 방법의 흐름을 도시한 도면이다."}
