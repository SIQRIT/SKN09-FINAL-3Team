{"patent_id": "10-2021-7033450", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0132719", "출원번호": "10-2021-7033450", "발명의 명칭": "딥 러닝 모델의 적응 방법, 장치 및 전자 기기", "출원인": "베이징 바이두 넷컴 사이언스 앤 테크놀로지 코.,", "발명자": "우, 투어방"}}
{"patent_id": "10-2021-7033450", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "딥 러닝 모델의 적응 방법에 있어서,최초 딥 러닝 모델의 모델 정보, 적응해야 하는 타겟 하드웨어의 하드웨어 정보를 획득하는 단계;상기 모델 정보 및 상기 하드웨어 정보에 따라, 전환 경로 테이블을 조회하여, 매칭된 타겟 전환 경로를 획득하는 단계; 및상기 타겟 전환 경로에 따라, 상기 최초 딥 러닝 모델을 상기 전환 경로의 중간 딥 러닝 모델로 전환하고, 상기중간 딥 러닝 모델을 상기 타겟 딥 러닝 모델로 전환하는 단계; 를 포함하는,것을 특징으로 하는 딥 러닝 모델의 적응 방법."}
{"patent_id": "10-2021-7033450", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 중간 딥 러닝 모델은 여러 개일 수 있고, 상기 타겟 전환 경로는 복수의 상기 중간 딥 러닝 모델의 전환순서를 지시하는데 사용되고;상기 타겟 전환 경로에 따라, 상기 최초 딥 러닝 모델을 상기 전환 경로의 중간 딥 러닝 모델로 전환하고, 상기중간 딥 러닝 모델을 상기 타겟 딥 러닝 모델로 전환하는 단계는,상기 타겟 전환 경로의 복수의 상기 중간 딥 러닝 모델의 전환 순서에 따라, 매번 모델 전환의 전환 전 모델과전환 후 모델 및 매번 모델 전환의 수행 순서를 결정하는 단계;매번 모델 전환의 전환 전 모델과 전환 후 모델 사이의 매핑 관계에 따라, 매번 모델 전환의 전환 태스크를 생성하는 단계; 및강기 매번 모델 전환의 수행 순서에 따라, 상기 최초 딥 러닝 모델 순서에 대해 상기 매번 모델 전환의 전환 태스크를 수행하여, 상기 타겟 딥 러닝 모델을 획득하는 단계; 를 포함하는,것을 특징으로 하는 딥 러닝 모델의 적응 방법."}
{"patent_id": "10-2021-7033450", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 매번 모델 전환의 전환 전 모델과 전환 후 모델 사이의 매핑 관계에 따라, 매번 모델 전환의 전환 태스크를 생성하는 단계는,매번 모델 전환의 전환 전 모델 및 전환 후 모델에 대해, 오퍼레이터 매핑 관계, 텐서 매핑 관계 및 모델 파라미터 매핑 관계 중의 적어도 하나를 조회하는 단계;오퍼레이터 매핑 관계, 텐서 매핑 관계 및 모델 파라미터매핑 관계 중의 적어도 하나에 따라, 매번 모델 전환의전환 태스크를 생성하는 단계; 를 포함하는,것을 특징으로 하는 딥 러닝 모델의 적응 방법."}
{"patent_id": "10-2021-7033450", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중의 어느 한 항에 있어서,상기 타겟 하드웨어가 적어도 2개일 경우, 상기 모델 정보 및 상기 하드웨어 정보에 따라, 전환 경로 테이블을조회하여, 매칭된 타겟 전환 경로를 획득하는 단계는,각 타겟 하드웨어의 하드웨어 정보를 각각 상기 모델 정보와 조합하여, 적어도 2개의 그룹 정보를 획득하는 단공개특허 10-2021-0132719-3-계;적어도 2개의 그룹 정보에 따라 상기 전환 경로 테이블을 조회하여, 적어도 2개의 후보 전환 경로를 획득하는단계 - 각 후보 전환 경로는 상기 대응하는 그룹 정보와 매칭됨 - ; 및적어도 2개의 후보 전환 경로에 따라, 타겟 전환 경로를 생성하는 단계; 를 포함하는,것을 특징으로 하는 딥 러닝 모델의 적응 방법."}
{"patent_id": "10-2021-7033450", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 적어도 2개의 후보 전환 경로에 따라, 상기 타겟 전환 경로를 생성하는 단계는,상기 적어도 2개의 후보 전환 경로의 중합 부분을 결정하는 단계; 및적어도 2개의 후보 전환 경로의 중합된 부분을 합병하여, 타겟 전환 경로를 획득하는 단계; 를 포함하는,것을 특징으로 하는 딥 러닝 모델의 적응 방법."}
{"patent_id": "10-2021-7033450", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제3항 중의 어느 한 항에 있어서,상기 모델 정보는 모델 구조 정보 및 훈련 아키텍처 정보를 포함하는,것을 특징으로 하는 딥 러닝 모델의 적응 방법."}
{"patent_id": "10-2021-7033450", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "딥 러닝 모델의 적응 장치에 있어서,최초 딥 러닝 모델의 모델 정보, 적응해야 하는 타겟 하드웨어의 하드웨어 정보를 획득하는데 사용되는 획득 모듈;상기 모델 정보 및 상기 하드웨어 정보에 따라, 전환 경로 테이블을 조회하여, 매칭된 타겟 전환 경로를 획득하는데 사용되는 조회 모듈; 및상기 타겟 전환 경로에 따라, 상기 최초 딥 러닝 모델을 상기 전환 경로의 중간 딥 러닝 모델로 전환하고, 상기중간 딥 러닝 모델을 상기 타겟 딥 러닝 모델로 전환하는데 사용되는 전환 모듈; 을 포함하는,것을 특징으로 하는 딥 러닝 모델의 적응 장치."}
{"patent_id": "10-2021-7033450", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,중간 딥 러닝 모델이 여러 개일 경우, 상기 타겟 전환 경로는 상기 복수의 중간 딥 러닝 모델의 전환 순서를 지시하는데 사용되고; 상기 전환 모듈은,상기 타겟 전환 경로의 상기 복수의 중간 딥 러닝 모델의 전환 순서에 따라, 매번 모델 전환의 전환 전 모델과전환 후 모델 및 매번 모델 전환의 수행 순서를 결정하는데 사용되는 결정 유닛;매번 모델 전환의 전환 전 모델과 전환 후 모델 사이의 매핑 관계에 따라, 매번 모델 전환의 전환 태스크를 생성하는데 사용되는 생성 유닛; 및상기 매번 모델 전환의 수행 순서에 따라, 상기 최초 딥 러닝 모델 순서에 대해 상기 매번 모델 전환의 전환 태스크를 수행하여, 상기 타겟 딥 러닝 모델을 획득하는데 사용되는 수행 유닛; 을 포함하는,것을 특징으로 하는 딥 러닝 모델의 적응 장치."}
{"patent_id": "10-2021-7033450", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,공개특허 10-2021-0132719-4-상기 생성 유닛은, 또한,매번 모델 전환의 전환 전 모델 및 전환 후 모델에 대해, 오퍼레이터 매핑 관계, 텐서 매핑 관계 및 모델 파라미터 매핑 관계 중의 적어도 하나를 조회하고;상기 오퍼레이터 매핑 관계, 텐서 매핑 관계 및 모델 파라미터매핑 관계 중의 적어도 하나에 따라, 매번 모델전환의 전환 태스크를 생성하는데 사용되는,것을 특징으로 하는 딥 러닝 모델의 적응 장치."}
{"patent_id": "10-2021-7033450", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항 내지 제9항 중의 어느 한 항에 있어서,상기 타겟 하드웨어는 적어도 2개이고, 상기 조회 모듈은,각 타겟 하드웨어의 하드웨어 정보를 각각 상기 모델 정보와 조합하여, 적어도 2개의 그룹 정보를 획득하는데사용되는 조합 유닛;적어도 2개의 그룹 정보에 따라 상기 전환 경로 테이블을 조회하여, 적어도 2개의 후보 전환 경로를 획득하는데사용되는 조회 유닛 - 각 후보 전환 경로는 상기 대응하는 그룹 정보와 매칭됨 -; 및상기 적어도 2개의 후보 전환 경로에 따라, 상기 타겟 전환 경로를 생성하는데 사용되는 경로 생성 유닛; 을 포함하는,것을 특징으로 하는 딥 러닝 모델의 적응 장치."}
{"patent_id": "10-2021-7033450", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10에 있어서,상기 경로 생성 유닛은, 또한상기 적어도 2개의 후보 전환 경로의 중합된 부분을 결정하고;상기 적어도 2개의 후보 전환 경로의 중합된 부분을 합병하여, 상기 타겟 전환 경로를 획득하는데 사용되는,것을 특징으로 하는 딥 러닝 모델의 적응 장치."}
{"patent_id": "10-2021-7033450", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10에 있어서,제7항 내지 제9항 중의 어느 한 항에 있어서,상기 모델 정보는 모델 구조 정보 및 훈련 아키텍처 정보를 포함하는,것을 특징으로 하는 딥 러닝 모델의 적응 장치."}
{"patent_id": "10-2021-7033450", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "전자 기기에 있어서,적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서와 통신 가능하게 연결되는 메모리; 를 포함하고,상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령이 상기 적어도 하나의 프로세서에 의해 실행될 경우, 상기 적어도 하나의 프로세서가 제1항 내지 제6항 중 어느 한 항의상기 딥 러닝 모델의 적응 방법을 수행하도록 하는,것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2021-7033450", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체에 있어서,공개특허 10-2021-0132719-5-상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제6항 중 어느 한 항의 방법을 수행하도록 하는,것을 특징으로 하는 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2021-7033450", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 딥 러닝 모델의 적응 방법, 장치, 전자 기기 및 매체를 개시하였고, 인공지능, 딥 러닝, 클라우드 컴 퓨팅"}
{"patent_id": "10-2021-7033450", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한것이다. 구체적인 구현 수단은, 최초 딥 러닝 모델의 모델정보, 적응해야 하는 타겟 하드웨 어의 하드웨어 정보를 획득한 후, 모델 정보 및 하드웨어 정보에 따라, 전환 경로 테이블을 조회하여, 매칭된 타 겟 전환 경로를 획득하고, 타겟 전환 경로에 따라, 최초 딥 러닝 모델을 전환 경로의 중간 딥 러닝 모델로 전환 하고, 중간 딥 러닝 모델을 타겟 딥 러닝 모델로 전환한다. 이로하여, 최초 딥 러닝 모델의 모델 정보와 타겟 하 드웨어의 하드웨어 정보를 기반으로 결정한 모델 전환 경로로 딥 러닝 모델의 전환을 하고, 임의의 유형의 최초 딥 러닝 모델을 임의의 타겟 하드웨어에 적응되는 타겟 딥 러닝 모델로 전환하도록 구현하고, 딥 러닝 모델이 부 동한 하드웨어 단말에 적응하기 어려운 문제를 해결한다. 대 표 도 - 도1"}
{"patent_id": "10-2021-7033450", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2021-0132719 CPC특허분류 G06N 3/08 (2013.01) 발명자 씨에, 용캉 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 1 0번가, 10, 바이두 캠퍼스 2층 천, 샤오위 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 1 0번가, 10, 바이두 캠퍼스 2층 쟝, 량훠 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 1 0번가, 10, 바이두 캠퍼스 2층리우, 제 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 1 0번가, 10, 바이두 캠퍼스 2층 쒸, 빈빈 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 1 0번가, 10, 바이두 캠퍼스 2층명 세 서 청구범위 청구항 1 딥 러닝 모델의 적응 방법에 있어서, 최초 딥 러닝 모델의 모델 정보, 적응해야 하는 타겟 하드웨어의 하드웨어 정보를 획득하는 단계; 상기 모델 정보 및 상기 하드웨어 정보에 따라, 전환 경로 테이블을 조회하여, 매칭된 타겟 전환 경로를 획득하 는 단계; 및 상기 타겟 전환 경로에 따라, 상기 최초 딥 러닝 모델을 상기 전환 경로의 중간 딥 러닝 모델로 전환하고, 상기 중간 딥 러닝 모델을 상기 타겟 딥 러닝 모델로 전환하는 단계; 를 포함하는, 것을 특징으로 하는 딥 러닝 모델의 적응 방법. 청구항 2 제1항에 있어서, 상기 중간 딥 러닝 모델은 여러 개일 수 있고, 상기 타겟 전환 경로는 복수의 상기 중간 딥 러닝 모델의 전환 순서를 지시하는데 사용되고; 상기 타겟 전환 경로에 따라, 상기 최초 딥 러닝 모델을 상기 전환 경로의 중간 딥 러닝 모델로 전환하고, 상기 중간 딥 러닝 모델을 상기 타겟 딥 러닝 모델로 전환하는 단계는, 상기 타겟 전환 경로의 복수의 상기 중간 딥 러닝 모델의 전환 순서에 따라, 매번 모델 전환의 전환 전 모델과 전환 후 모델 및 매번 모델 전환의 수행 순서를 결정하는 단계; 매번 모델 전환의 전환 전 모델과 전환 후 모델 사이의 매핑 관계에 따라, 매번 모델 전환의 전환 태스크를 생 성하는 단계; 및 강기 매번 모델 전환의 수행 순서에 따라, 상기 최초 딥 러닝 모델 순서에 대해 상기 매번 모델 전환의 전환 태 스크를 수행하여, 상기 타겟 딥 러닝 모델을 획득하는 단계; 를 포함하는, 것을 특징으로 하는 딥 러닝 모델의 적응 방법. 청구항 3 제2항에 있어서, 상기 매번 모델 전환의 전환 전 모델과 전환 후 모델 사이의 매핑 관계에 따라, 매번 모델 전환의 전환 태스크 를 생성하는 단계는, 매번 모델 전환의 전환 전 모델 및 전환 후 모델에 대해, 오퍼레이터 매핑 관계, 텐서 매핑 관계 및 모델 파라 미터 매핑 관계 중의 적어도 하나를 조회하는 단계; 오퍼레이터 매핑 관계, 텐서 매핑 관계 및 모델 파라미터매핑 관계 중의 적어도 하나에 따라, 매번 모델 전환의 전환 태스크를 생성하는 단계; 를 포함하는, 것을 특징으로 하는 딥 러닝 모델의 적응 방법. 청구항 4 제1항 내지 제3항 중의 어느 한 항에 있어서, 상기 타겟 하드웨어가 적어도 2개일 경우, 상기 모델 정보 및 상기 하드웨어 정보에 따라, 전환 경로 테이블을 조회하여, 매칭된 타겟 전환 경로를 획득하는 단계는, 각 타겟 하드웨어의 하드웨어 정보를 각각 상기 모델 정보와 조합하여, 적어도 2개의 그룹 정보를 획득하는 단계; 적어도 2개의 그룹 정보에 따라 상기 전환 경로 테이블을 조회하여, 적어도 2개의 후보 전환 경로를 획득하는 단계 - 각 후보 전환 경로는 상기 대응하는 그룹 정보와 매칭됨 - ; 및 적어도 2개의 후보 전환 경로에 따라, 타겟 전환 경로를 생성하는 단계; 를 포함하는, 것을 특징으로 하는 딥 러닝 모델의 적응 방법. 청구항 5 제4항에 있어서, 상기 적어도 2개의 후보 전환 경로에 따라, 상기 타겟 전환 경로를 생성하는 단계는, 상기 적어도 2개의 후보 전환 경로의 중합 부분을 결정하는 단계; 및 적어도 2개의 후보 전환 경로의 중합된 부분을 합병하여, 타겟 전환 경로를 획득하는 단계; 를 포함하는, 것을 특징으로 하는 딥 러닝 모델의 적응 방법. 청구항 6 제1항 내지 제3항 중의 어느 한 항에 있어서, 상기 모델 정보는 모델 구조 정보 및 훈련 아키텍처 정보를 포함하는, 것을 특징으로 하는 딥 러닝 모델의 적응 방법. 청구항 7 딥 러닝 모델의 적응 장치에 있어서, 최초 딥 러닝 모델의 모델 정보, 적응해야 하는 타겟 하드웨어의 하드웨어 정보를 획득하는데 사용되는 획득 모 듈; 상기 모델 정보 및 상기 하드웨어 정보에 따라, 전환 경로 테이블을 조회하여, 매칭된 타겟 전환 경로를 획득하 는데 사용되는 조회 모듈; 및 상기 타겟 전환 경로에 따라, 상기 최초 딥 러닝 모델을 상기 전환 경로의 중간 딥 러닝 모델로 전환하고, 상기 중간 딥 러닝 모델을 상기 타겟 딥 러닝 모델로 전환하는데 사용되는 전환 모듈; 을 포함하는, 것을 특징으로 하는 딥 러닝 모델의 적응 장치. 청구항 8 제7항에 있어서, 중간 딥 러닝 모델이 여러 개일 경우, 상기 타겟 전환 경로는 상기 복수의 중간 딥 러닝 모델의 전환 순서를 지 시하는데 사용되고; 상기 전환 모듈은, 상기 타겟 전환 경로의 상기 복수의 중간 딥 러닝 모델의 전환 순서에 따라, 매번 모델 전환의 전환 전 모델과 전환 후 모델 및 매번 모델 전환의 수행 순서를 결정하는데 사용되는 결정 유닛; 매번 모델 전환의 전환 전 모델과 전환 후 모델 사이의 매핑 관계에 따라, 매번 모델 전환의 전환 태스크를 생 성하는데 사용되는 생성 유닛; 및 상기 매번 모델 전환의 수행 순서에 따라, 상기 최초 딥 러닝 모델 순서에 대해 상기 매번 모델 전환의 전환 태 스크를 수행하여, 상기 타겟 딥 러닝 모델을 획득하는데 사용되는 수행 유닛; 을 포함하는, 것을 특징으로 하는 딥 러닝 모델의 적응 장치. 청구항 9 제8항에 있어서,상기 생성 유닛은, 또한, 매번 모델 전환의 전환 전 모델 및 전환 후 모델에 대해, 오퍼레이터 매핑 관계, 텐서 매핑 관계 및 모델 파라 미터 매핑 관계 중의 적어도 하나를 조회하고; 상기 오퍼레이터 매핑 관계, 텐서 매핑 관계 및 모델 파라미터매핑 관계 중의 적어도 하나에 따라, 매번 모델 전환의 전환 태스크를 생성하는데 사용되는, 것을 특징으로 하는 딥 러닝 모델의 적응 장치. 청구항 10 제7항 내지 제9항 중의 어느 한 항에 있어서, 상기 타겟 하드웨어는 적어도 2개이고, 상기 조회 모듈은, 각 타겟 하드웨어의 하드웨어 정보를 각각 상기 모델 정보와 조합하여, 적어도 2개의 그룹 정보를 획득하는데 사용되는 조합 유닛; 적어도 2개의 그룹 정보에 따라 상기 전환 경로 테이블을 조회하여, 적어도 2개의 후보 전환 경로를 획득하는데 사용되는 조회 유닛 - 각 후보 전환 경로는 상기 대응하는 그룹 정보와 매칭됨 -; 및 상기 적어도 2개의 후보 전환 경로에 따라, 상기 타겟 전환 경로를 생성하는데 사용되는 경로 생성 유닛; 을 포 함하는, 것을 특징으로 하는 딥 러닝 모델의 적응 장치. 청구항 11 제10에 있어서, 상기 경로 생성 유닛은, 또한 상기 적어도 2개의 후보 전환 경로의 중합된 부분을 결정하고; 상기 적어도 2개의 후보 전환 경로의 중합된 부분을 합병하여, 상기 타겟 전환 경로를 획득하는데 사용되는, 것을 특징으로 하는 딥 러닝 모델의 적응 장치. 청구항 12 제10에 있어서, 제7항 내지 제9항 중의 어느 한 항에 있어서, 상기 모델 정보는 모델 구조 정보 및 훈련 아키텍처 정보를 포함하는, 것을 특징으로 하는 딥 러닝 모델의 적응 장치. 청구항 13 전자 기기에 있어서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 가능하게 연결되는 메모리; 를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령이 상기 적 어도 하나의 프로세서에 의해 실행될 경우, 상기 적어도 하나의 프로세서가 제1항 내지 제6항 중 어느 한 항의 상기 딥 러닝 모델의 적응 방법을 수행하도록 하는, 것을 특징으로 하는 전자 기기. 청구항 14 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체에 있어서,상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제6항 중 어느 한 항의 방법을 수행하도록 하는, 것을 특징으로 하는 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체. 발명의 설명 기 술 분 야 본 출원은 컴퓨터 기술 분야에 관한 것으로, 구체적으로 인공지능, 딥 러닝, 클라우드 컴퓨팅 기술 분야에 관한 것이고, 특히 딥 러닝 모델의 적응 방법, 장치, 전자 기기 및 저장 매체에 관한 것이다."}
{"patent_id": "10-2021-7033450", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재, 신경망을 대표로 딥 러닝은 업계에서 광범한 착지와 응용을 받고 있고, 대규모 딥 러닝 모델 배치의 수요 를 기반으로, 다양한 유형의 인공지능(Artificial Intelligence, AI) 추리 가속 칩이 파생된다. 그러나, 다양한 유형의 AI 추리 가속 칩의 형태는 부동하고 해쉬레이트는 동일하지 않고, 응용 장면도 다양하다. 따라서, 다양 한 유형의 AI 추리 가속 칩은, 항상 어느 한가지의 특정 아키텍처에서의 딥 러닝 모델에만 적용되고, 기타 아키 텍처에서의 딥 러닝 모델을 운행할 수 없다. 따라서, 다양한 아키텍처의 딥 러닝 모델과 AI 추리 가속 칩을 적응하게 하는 것은, 급히 해결해야 할 기술적 과제이다. 본 출원은 딥 러닝 모델의 적응 방법, 장치, 전자 기기 및 저장 매체를 제공한다. 본 출원의 제1 측면 실시예에 따르면 딥 러닝 모델의 적응 방법을 제공하고, 당해 방법은, 최초 딥 러닝 모델의 모델 정보, 적응해야 하는 타겟 하드웨어의 하드웨어 정보를 획득하는 단계; 상기 모델 정보 및 상기 하드웨어 정보에 따라, 전환 경로 테이블을 조회하여, 매칭된 타겟 전환 경로를 획득하 는 단계; 상기 타겟 전환 경로에 따라, 상기 최초 딥 러닝 모델을 상기 전환 경로의 중간 딥 러닝 모델로 전환하고, 상기 중간 딥 러닝 모델을 상기 타겟 딥 러닝 모델로 전환하는 단계; 를 포함한다. 본 출원의 제2 측면 실시예에 따르면 딥 러닝 모델의 적응 장치를 제공하고, 당해 장치는, 최초 딥 러닝 모델의 모델 정보, 적응해야 하는 타겟 하드웨어의 하드웨어 정보를 획득하는데 사용되는 획득 모 듈; 상기 모델 정보 및 상기 하드웨어 정보에 따라, 전환 경로 테이블을 조회하여, 매칭된 타겟 전환 경로를 획득하 는데 사용되는 조회 모듈; 상기 타겟 전환 경로에 따라, 상기 최초 딥 러닝 모델을 상기 전환 경로의 중간 딥 러닝 모델로 전환하고, 상기 중간 딥 러닝 모델을 상기 타겟 딥 러닝 모델로 전환하는데 사용되는 전환 모듈; 을 포함한다. 본 출원의 제3 측면 실시예에 따르면 전자 기기를 제공하고, 당해 전자 기기는, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 가능하게 연결되는 메모리; 를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령이 상기 적 어도 하나의 프로세서에 의해 실행될 경우, 상기 적어도 하나의 프로세서가 제1 측면 실시예의 딥 러닝 모델의 적응 방법을 수행하도록 한다. 본 출원의 제4 측면 실시예에 따르면 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체를 더 제공하고, 상기 컴퓨터 명령은 제1 측면 실시예의 딥 러닝 모델의 적응 방법을 수행하도록 한다. 상기 출원 중의 일 실시예는 하기의 우점 또는 유익한 효과를 구비한다. 최초 딥 러닝 모델을 기반으로 하는 모 델 정보 및 타겟 하드웨어의 하드웨어 정보를 통해, 모델 전환 경로를 결정하여, 모델 전환 경로에 따라 딥 러닝 모델의 전환을 함으로, 임의의 유형의 최초 딥 러닝 모델을 임의의 타겟 하드웨어에 적응되는 타겟 딥 러닝 모델로 전환하도록 구현하고, 딥 러닝 모델이 부동한 하드웨어 단말에 적응하지 못하는 문제를 해결한다."}
{"patent_id": "10-2021-7033450", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "이해해야할 것은, 본 발명의 내용 부분에서 설명하는 내용은 본 출원 실시예의 관건 또는 중요한 특징을 식별하 기 위한 것이 아니고, 본 출원의 범위를 한정하기 위한 것도 아니다. 본 출원의 기타 특징은 이하의 명세서를 통해 용이하게 이해된다."}
{"patent_id": "10-2021-7033450", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "하기의 도면과 결합하여 본 출원의 예시적인 실시예를 설명한다. 여기에는 이해를 돕기 위해 본 출원의 실시예 의 복수의 세부 사항을 포함하고, 실시예들은 단지 예시적인 것으로 간주되어야 한다. 때문에 이 발명에 속하는 기술 분야의 통상의 기술자는 본 출원의 범위 및 사상을 벗어나지 않고 실시예에 여러가지 변경과 수정을 할 수 있다는 것을 인식해야 한다. 동시에 정확성과 간결성을 위해 하기의의 설명에서는 공지 기능과 구조에 대한 설 명은 생략한다. 아래는 도면을 참조하여 본 출원 실시예의 딥 러닝 모델의 적응 방법, 장치, 전자 기기 및 저장 매체를 설명한 다. 도1은 본 출원의 실시예1에서 제공하는 딥 러닝 모델의 적응 방법의 흐름도이다. 본 출원의 실시예는 당해 딥 러닝 모델의 적응 방법이 딥 러닝 모델의 적응 장치에 구성된 것을 예를 들어 설명 하고, 당해 딥 러닝 모델의 적응 장치는 임의 전자 기기에 적용될 수 있고, 당해 전자 기기가 딥 러닝 모델의 적응 기능을 수행하도록 할 수 있다. 전자 기기는 개인용 컴퓨터(Personal Computer, PC), 클라우드 기기, 모바일 기기 등일 수 있고, 모바일 기기는 휴대폰, 태블릿 PC, 개인 휴대 정보 단말, 웨어러블 기기, 차량 탑재 기기 등 다양한 동작 시스템의 하드웨어 기기일 수 있다. 도1에 도시한 바와 같이, 당해 딥 러닝 모델의 적응 방법은, 단계101 내지 단계103을 포함한다. 단계101에서, 최초 딥 러닝 모델의 모델 정보, 적응해야 하는 타겟 하드웨어의 하드웨어 정보를 획득한다. 최초 딥 러닝 모델은, 전환할 심층 신경망 구조를 포함하는 기계 학습 모델을 가리킨다. 딥 러닝 모델의 모델 정보는, 딥 러닝 모델의 훈련 아키텍처, 딥 러닝 모델의 네트워크 유형, 딥 러닝 모델의 모델 구조 정보, 딥 러 닝 모델의 모델 파일 등을 포함할 수 있다. 예를 들면, 딥 러닝 모델의 훈련 아키텍처는, 오픈 소스 소프트웨어 베이스아키텍처(예를 들면 TensorFlow 아키 텍처), PyTorch 아키텍처, 딥 러닝 아키텍처(Convolutional Architecture for Fast Feature Embedding, Caffe), 별령 분산식 딥 러닝아키텍처(Parallel Distributed Deep Learning, PaddlePaddle) 등일 수 있다. 딥 러닝 모델의 네트워크 유형은, 모든 주류 분류, 검사 및 신경망 분할일 수 있다. 예를 들면, 네트워크 유형 은 심층적인 컨볼루션 신경망(예를 들면 AlexNet), 심도 분해 가능한 컨볼루션을 기반으로 하는 모델(예를 들면 MobileNet), 타겟 검사에 사용되는 네트워크 모델(Regions with CNN features, RCNN) 등일 수 있다. 딥 러닝 모델의 모델 구조 정보는, 딥 러닝 모델이 포함하는 기본 구조일 수 있다. 예를 들면, 완전히 연결된 레이어, 루프 구조, 컨볼루션 레이어/풀링 레이어 등을 포함할 수 있다. 딥 러닝 모델의 모델 파일은, 알고리즘 엔지니어가 어느 한가지 딥 러닝 아키텍처로 모델를 구축하고, 파라미터 를 조절 및 훈련 최적화한 후, 최종 생성된 네트워크 파라미터와 모델 구조와 함께 저장하여, 획득한 파일일 수 있다. 부동한 딥 러닝 아키텍처를 훈련하여 획득한 모델 파일의 포맷은 완전히 동일하지 않지만, 완정한 파일은 통상적으로 텐서 데이터, 단항 연산 및 계산 그래프 등 정보를 포함한다. 이해해야 할 것은, 인공지능 하드웨어는 모두 자신의 요구에 만족되는 딥 러닝 모델만을 운행할 수 있으므로, 적응해야 할 타겟 하드웨어의 하드웨어 정보가 부동할 경우, 운행 가능한 해당 딥 러닝 모델은 부동하다. 선택적으로, 적응해야 할 타겟 하드웨어의 하드웨어 정보는, 적응해야 할 타겟 하드웨어 유형일 수 있다. 예를 들면, 인텔 중앙 처리 장치(Intel Central Processing Unit / Processor, Intel CPU), ARM 프로세서, 하이실리 콘 프로세서 등일 수 있다. 설명해야 할 것은, 적응해야 할 타겟 하드웨어는 현재 시중의 임의 주류 인공지능 하드웨어일 수 있고, 여기서 한정하지 않는다. 하나의 가능한 상황에서, 적응해야 하는 타겟 하드웨어는 1개에 한정되지 않고, 2개 또는 2개 이상일 수 있고, 이때, 적응해야 하는 타겟 하드웨어의 하드웨어 정보는 모든 타겟 하드웨어의 하드웨어 정보를 포함한다. 단계102에서, 모델 정보 및 하드웨어 정보에 따라, 전환 경로 테이블을 조회하여, 매칭된 타겟 전환 경로를 획 득한다. 전환 경로 테이블은, 임의 2개의 딥 러닝 모델의 모델 훈련 아키텍처, 네트워크 유형, 모델 파일, 및 적응해야 하는 타겟 하드웨어의 하드웨어 정보에 따라, 미리 구성된 전환 경로를 가리킬 수 있다. 전환 경로 테이블은 임 의의 유형의 딥 러닝 모델의 훈련 아키텍처, 네트워크 유형, 모델 파일, 및 적응해야 하는 타겟 하드웨어의 전 환 경로을 포함할 수 있다. 타겟 전환 경로는, 전환 경로 테이블에서 최초 딥 러닝 모델의 모델 정보, 적응해야 하는 타겟 하드웨어의 하드 웨어 정보와 매칭되는 전환 경로를 가리킨다. 본 출원의 실시예에서, 최초 딥 러닝 모델의 모델 정보, 적응해야 하는 타겟 하드웨어의 하드웨어 정보를 획득 한 후, 모델 정보 및 하드웨어 정보에 따라, 전환 경로 테이블에서 매칭된 타겟 전환 경로를 조회해 낼 수 있다. 일 예시로서, PaddlePaddle훈련 아키텍처에 의해 훈련된 최초 딥 러닝 모델 MobileNetV1 모델을, Intel CPU에 서 수행한 딥 러닝 모델로 전환해야 할 경우, Mo bileNetV1 모델의 모델 정보, 적응해야 하는 타겟 하드웨어에 따라, 전환 경로 테이블을 조회하여, 매칭된 타겟 전환 경로: Paddle model→ caffe model→ optimize model→ dldt model(Intel CPU에 적용됨)를 획득할 수 있다. 단계103에서, 타겟 전환 경로에 따라, 최초 딥 러닝 모델을 전환 경로의 중간 딥 러닝 모델로 전환하고, 중간 딥 러닝 모델을 타겟 딥 러닝 모델로 전환한다. 이해해야 할 것은, 최초 딥 러닝 모델을 타겟 딥 러닝 모델에 전환하는 전환 과정은, 여러 번의 모델 전환을 겪 어야, 적응되는 타겟 하드웨어가 수행할 수 있는 딥 러닝 모델을 획득할 수 있다. 본 출원에서, 최초 딥 러닝 모델을 타겟 딥 러닝 모델의 타겟 전환 경로에 전환할 것을 결정한 후, 타겟 전환 경로에 따라, 최초 딥 러닝 모델을 전환 경로의 중간 딥 러닝 모델로 전환할 수 있음으로, 중간 딥 러닝 모델을 타겟 딥 러닝 모델에 전환한다. 하나의 가능한 상황에서, 타겟 전환 경로에 따라 최초 딥 러닝 모델을 타겟 딥 러닝 모델로 전환할 경우, 전환 과정의 중간 딥 러닝 모델은 1개 뿐이고, 먼저 타겟 전환 경로에 따라 최초 딥 러닝 모델을 중간 딥 러닝 모델 로 전환할 수 있음으로, 중간 딥 러닝 모델을 타겟 딥 러닝 모델로 전환한다. 다른 하나의 가능한 상황에서, 타겟 전환 경로에 따라 최초 딥 러닝 모델을 타겟 딥 러닝 모델로 전환할 경우, 전환 과정의 중간 딥 러닝 모델은 여러 개일 수 있다. 일 예시로서, 타겟 전환 경로가 Paddle model→ caffe model→ optimize model→ dldt model(Intel CPU에 적용 됨)일 경우, 타겟 전환 경로에 따라, 최초 딥 러닝모델인 Paddle모델을 중간 딥 러닝 모델인 caffe모델로 전환 하고, 중간 딥 러닝 모델인 caffe모델을 중간 딥 러닝 모델링인 optimize모델로 전환하고, 중간 딥 러닝 모델인 optimize 모델을 Intel CPU의 타겟 딥 러닝 모델인 dldt 모델에 적을하도록 전환한다. 본 출원 실시예의 딥 러닝 모델의 적응 방법은, 최초 딥 러닝 모델의 모델정보, 적응해야 하는 타겟 하드웨어의 하드웨어 정보를 획득한 후, 모델 정보 및 하드웨어 정보에 따라, 전환 경로 테이블을 조회하여, 매칭된 타겟 전환 경로를 획득하고, 나아가, 타겟 전환 경로에 따라, 최초 딥 러닝 모델을 전환 경로의 중간 딥 러닝 모델로 전환하고, 중간 딥 러닝 모델을 타겟 딥 러닝 모델로 전환한다. 이로하여, 최초 딥 러닝 모델의 모델 정보와 타 겟 하드웨어의 하드웨어 정보를 기반으로, 모델 전환 경로를 결정하여, 모델 전환 경로에 따라 딥 러닝 모델의 전환을 하고, 임의의 유형의 최초 딥 러닝 모델을 임의의 타겟 하드웨어에 적응되는 타겟 딥 러닝 모델로 전환 하도록 구현하고, 딥 러닝 모델이 부동한 하드웨어 단말에 적응하기 어려운 문제를 해결한다. 상기 실시예의 기반에서, 하나의 가능한 상황에서, 상기 단계103에서 타겟 전환 경로에 따라 최초 딥 러닝 모델 을 타겟 딥 러닝 모델에 전환할 경우, 전환 과정의 중간 딥 러닝 모델은 여러 개일 수 있고, 이때, 타겟 전환 경로는 복수의 중간 딥 러닝 모델의 전환 순서을 지시하는데 사용될 수 있다. 타겟 전환 경로에 따라 모델 전환 을 할 경우, 복수의 중간 딥 러닝 모델의 전환 순서에 따라, 매번 모델 전환의 전환 태스크를 수행하여, 최초 딥 러닝 모델을 타겟 하드웨어에 적응되는 타겟 딥 러닝 모델에 전환하도록 구현함으로, 임의의 유형의 모델 전 환을 구현한다. 아래는 도2와 결합하여 상세한 설명을 하고, 도2는 본 출원의 실시예2에서 제공하는 모델 전환 의 서브 흐름도이다. 도2에 도시한 바와 같이, 상기 단계103는 단계201 내지 203을 더 포함한다. 단계201에서, 타겟 전환 경로의 복수의 중간 딥 러닝 모델의 전환 순서에 따라, 매번 모델 전환의 전환 전 모델 과 전환 후 모델 및 매번 모델 전환의 수행 순서를 결정한다. 설명해야 할 것은, 타겟 전환 경로에 따라 최초 딥 러닝 모델을 타겟 딥 러닝 모델로 전환하고, 전환 과정의 중 간 딥 러닝 모델이 여러 개일 경우, 타겟 전환 경로는 복수의 중간 딥 러닝 모델의 전환 순서를 포함한다. 본 출원 실시예에서, 타겟 전환 경로에 따라 최초 딥 러닝 모델을 타겟 딥 러닝 모델로 전환하고, 전환 과정에 서 중간 딥 러닝 모델이 여러 개일 경우, 타겟 전환 경로의 복수의 중간 딥 러닝 모델의 전환 순서에 따라, 매 번 모델 전환의 전환 전 모델, 전환 후 모델, 및 매번 모델 전환의 수행 순서를 결정한다. 일 예시로서, 타겟 전환 경로가 Paddle model→ caffe model→ optimize model→ dldt model일 경우, 보다시피, 중간 딥 러닝 모델은 2개이고, 타겟 전환 경로에 따라 최초 딥 러닝 모델을 타겟 딥 러닝 모델로 전 환하는 과정에서, 먼저, 타겟 전환 경로의 복수의 중간 딥 러닝 모델의 전환 순서에 따라, 처음 모델 전환하는 전환 전 모델 및 전환 후 모델이 각각 Paddle모델 및 caffe모델임을 결정하고, 계속하여, 두 번째 모델 전환하 는 전환 전 모델 및 전환 후 모델이 각각 caffe모델 및 optimize모델임을 결정하고, 나아가, 세 번째 모델 전환 하는 전환 전 모델 및 전환 후 모델이 각각 optimize모델 및 dldt모델임을 결정한다. 이로하여, 타겟 전환 경로 의 복수의 중간 딥 러닝 모델의 전환 순서에 따라, 매번 모델 전환의 전환 전 모델과 전환 후 모델 및 매번 모 델 전환의 수행 순서를 결정한다. 단계202에서, 매번 모델 전환의 전환 전 모델과 전환 후 모델 사이의 매핑 관계에 따라, 매번 모델 전환의 전환 태스크를 생성한다. 본 출원의 실시예에서, 매번 모델 전환의 전환 전 모델과 전환 후 모델을 결정한 후, 매번 모델 전환의 전환 전 모델과 전환 후 모델 사이의 매핑 관계를 결정할 수 있고, 나아가, 매번 모델 전환의 전환 전 모델과 전환 후 모델 사이의 매핑 관계에 따라, 매번 모델 전환의 전환 태스크를 생성할 수 있다. 계속하여 단계201의 예시를 예로 들어, 타겟 전환 경로가 Paddle model→ caffe model→ optimize model→ dldt model일 경우, 세번 모델 전환의 전환 태스크를 생성할 수 있고, 각각 전환 태스크1, Paddle model→ caffe model; 전환 태스크2, caffe model→ optimize model; 전환 태스크3, optimize model→ dldt model이다. 가능한 구현 방식으로서, 매번 모델 전환의 전환 전 모델 및 전환 후 모델에 대해, 오퍼레이터 매핑 관계, 텐서 매핑 관계 및 모델 파라미터 매핑 관계 중의 적어도 하나를 조회할 수 있고, 오퍼레이터 매핑 관계, 텐서 매핑 관계 및 모델 파라미터매핑 관계 중의 적어도 하나에 따라, 매번 모델 전환의 전환 태스크를 생성한다. 이로하 여, 매번 모델 전환의 전환 태스크에 따라, 타겟 딥 러닝 모델을 획득할 수 있다. 매번 모델 전환의 전환 전 모델과 전환 후 모델의 모델 오퍼레이터는 부동할 수 있고, 모델 오퍼레이터의 정렬 방법은 부동할 수있다. 따라서, 오퍼레이터 매핑 관계를 조회하여, 전환 전 모델 및 전환 후 모델의 오퍼레이터 매핑 관계를 결정할 수 있다. 텐서는 모든 딥 러닝 아키텍처의 가장 핵심적인 컴포넌트이고, 실제로는 하나의 다차원 배열이고, 당해 목적은 더 높은 차원의 매트릭스, 벡터를 생성하는 것이다. 모델 파라미터는 각 컨볼루션 레이어의 파라미터, 예를 들면 파라미터 수량, 파라미터가 점유하는 공간 등을 포함할 수 있다. 단계203에서, 매번 모델 전환의 수행 순서에 따라, 최초 딥 러닝 모델 순서에 대해 매번 모델 전환의 전환 태스 크를 수행하여, 타겟 딥 러닝 모델을 획득한다. 본 출원의 실시예에서, 타겟 전환 경로의 복수의 중간 딥 러닝 모델의 전환 순서에 따라, 매번 모델 전환의 수 행 순서를 결정한 후, 매번 모델 전환의 수행 순서에 따라, 최초 딥 러닝 모델에 대해 순차적으로 매번 모델 전 환의 전환 태스크를 수행하여, 타겟 하드웨어에 적응하는 타겟 딥 러닝 모델을 획득한다. 계속하여 상기 예시를 예로 들어, 타겟 전환 경로에 따라 최초 딥 러닝 모델에서 타겟 딥 러닝 모델로 전환하도 록 결정할 경우, 순차적으로 수행해야 할 모델 전환하는 전환 태스크는 각각, 전환 태스크1, Paddle model→ caffe model; 전환태스크2, caffe model→ optimize model; 전환태스크3, optimize model→ dldt model이다. 나아가, 당해 3번 모델 전환한 전환 태스크를 순차적으로 수행하여, Intel CPU에 적응하는 타겟 딥 러닝 모델을 획득한다. 본 출원의 실시예에서, 타겟 전환 경로에 따라, 최초 딥 러닝 모델을 전환 경로의 중간 딥 러닝 모델로 전환하 고, 중간 딥 러닝 모델을 타겟 딥 러닝 모델로 전환하는 과정에서, 중간 딥 러닝 모델이 여러 개일 경우, 타겟 전환 경로의 복수의 중간 딥 러닝 모델의 전환 순서에 따라, 매번 모델 전환의 수행 순서를 결정할 수 있고, 나 아가, 모델 전환하는 수행 순서에 따라, 최초 딥 러닝 모델 순서에 대해 매번 모델 전환의 전환 태스크를 수행 하여, 타겟 하드웨어에 적응하는 타겟 딥 러닝 모델을 획득한다. 기존의 딥 러닝 모델이 전환할 경우 한 번의 모델 전환 태스크를 구현할 수 밖에 없는 점에 대비해, 본 출원은 모델 전환 과정에 여러 번의 모델 전환 태스 크가 존재하도록 구현함으로, 임의 모델의 전환을 구현할 수 있고, 딥 러닝 모델이 임의 하드웨어에 적응하는 목적을 구현한다. 실제의 응용 장면에서, 최초 딥 러닝 모델을 복수의 타겟 하드웨어에 적응하도록 전환하는 경우가 존재할 수 있 다. 즉, 타겟 하드웨어는 적어도 2개이고, 당해 상황에서, 상기 단계102에서 생성한 타겟 전환 경로도 적어도 2 가지 경로임으로, 적어도 2개의 타겟 전환 경로에 따라, 최초 딥 러닝 모델을 적어도 2개의 타겟 하드웨어에 적 응하는 적어도 2개의 타겟 딥 러닝 모델로 전환하는 것이다. 아래는 도3과 결합하여 상세한 설명을 하고, 도3은 본 출원의 실시예3에서 제공하는 타겟 전환 경로를 생성하는 서브 흐름도이다. 도3에 도시한 바와 같이, 상기 단계102는 단계301 내지 단계303을 더 포함한다. 단계301에서, 각 타겟 하드웨어의 하드웨어 정보를 각각 모델 정보와 조합하여, 적어도 2개의 그룹 정보를 획득 한다. 하나의 가능한 상황에서, 최초 딥 러닝 모델이 적응해야 하는 타겟 하드웨어는 적어도 2개이고, 각 타겟 하드웨 어의 하드웨어 정보를 획득한 후, 각 타겟 하드웨어의 하드웨어 정보를 각각 최초 딥 러닝 모델의 모델 정보와 조합하여, 적어도 2개의 그룹 정보를 획득한다. 최초 딥 러닝 모델의 모델 정보는, 모델 구조 정보 및 훈련 아키텍처 정보를 포함할 수 있다. 이로하여, 최초 딥 러닝 모델의 모델 구조 정보 및 훈련 아키텍처 정보에 따라, 각 타겟 하드웨어의 하드웨어 정보와 조합하여, 적어도 2개의 그룹 정보를 획득한다. 일 예시로서, 타겟 하드웨어가 2개일 경우, 즉, 각각 하드웨어A 및 하드웨어B일 경우, 최초 딥 러닝 모델의 모 델 정보를 각각 하드웨어A 및 하드웨어B의 하드웨어 정보와 조합함으로, 2개의 그룹 정보를 획득한다. 단계302에서, 적어도 2개의 그룹 정보에 따라 전환 경로 테이블을 조회하여, 적어도 2개의 후보 전환 경로를 획 득한다. 각 후보 전환 경로는 대응하는 그룹 정보와 매칭된다. 이해해야 할 것은, 적어도 2개의 타겟 하드웨어의 하드웨어 정보는 부동하다. 따라서, 적어도 2개의 그룹 정보 를 획득한 후, 적어도 2개의 그룹 정보에 따라 전환 경로 테이블을 조회하여, 적어도 2개의 후보 전환 경로를 획득할 수 있고, 각 후보 전환 경로는 대응하는 그룹 정보와 매칭된다. 일 예시로서, 최초 딥 러닝 모델이 Paddle모델일 경우, PaddlePaddle이 훈련된 MobileNetV1 모델을, Intel CPU 및 하이실리콘의 어센드( )910 칩에서 수행하는 딥 러닝 모델로 전환해야 하고, 2개의 타겟 하드웨어에 대 응하는 그룹 정보를 결정한 후, 2개의 그룹 정보에 따라 전환 경로 테이블를 조회하여, 2개의 후보 전환 경로를획득할 수 있다. 당해 경로는 각각 경로1 및 경로2를 포함한다. 경로1, Paddle model→ caffe model→ optimize model→ dldt model(Intel CPU에 적응됨); 경로2, Paddle model→ caffe model→ optimize model→ atlas model(하이실리콘의 어센드910에 적응됨). 단계303에서, 적어도 2개의 후보 전환 경로에 따라, 타겟 전환 경로를 생성한다. 본 출원 실시예에서, 최초 딥 러닝 모델이 적응해야 하는 타겟 하드웨어가 적어도 2개일 경우, 적어도 2개의 후 보 전환 경로를 결정한 후, 적어도 2개의 후보 전환 경로에 따라, 타겟 전환 경로를 생성할 수 있다. 하나의 가능한 상황에서, 적어도 2개의 후보 전환 경로에 중합된 전환 태스크가 없을 경우, 적어도 2개의 후보 전환 경로를 타겟 전환 경로로 하고, 최초 딥 러닝 모델을 전환하여, 적어도 2개의 타겟 하드웨어에 적응되는 타겟 딥 러닝 모델을 획득한다. 다른 하나의 가능한 상황에서, 적어도 2개의 후보 전환 경로에 중합된 부분이 존재할 경우, 적어도 2개의 후보 전환 경로의 중합된 부분을 합병하여, 타겟 전환 경로를 획득할 수 있다. 상기 단계302의 예시를 예로 들어, 2개의 후보 전환 경로의 중합된 부분이 Paddle model→ caffe model→ optimize model일 경우, 당해 2개의 후보 전환 경로의 중합된 부분을 합병하여, 합병 후의 타겟 전환 경로를 획 득하고, 당해 경로는 아래와 같다. Paddle model→ caffe model→ optimize model→"}
{"patent_id": "10-2021-7033450", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이로하여, 적어도 2개의 후보 전환 경로에 중합된 부분이 존재할 경우, 적어도 2개의 후보 전환 경로의 중합된 부분을 합병하여, 적어도 2개의 후보 전환 경로에 대한 최적화를 구현함으로, 최적화하여 획득한 타겟 전환 경 로에 따라 적어도 2개의 타겟 하드웨어에 적응되는 타겟 딥 러닝 모델을 쾌속적으로 생성한다. 보다시피, 타겟 하드웨어가 적어도 2개일 경우, 각 타겟 하드웨어의 하드웨어 정보와 모델 정보를 조합하여, 적 어도 2개의 그룹 정보를 획득할 수 있고, 적어도 2개의 그룹 정보에 따라 전환 경로 테이블을 조회하여, 적어도 2개의 후보 전환 경로를 획득하고, 나아가, 적어도 2개의 후보 전환 경로에 따라, 타겟 전환 경로를 생성한다. 이로하여, 최초 딥 러닝 모델이 적응해야 하는 타겟 하드웨어가 여러 개일 경우, 타겟 전환 경로에 따라 적어도 2개의 타겟 하드웨어에 적응되는 타겟 딥 러닝모델을 생성함으로, 모델 전환하는 속도를 향상시킨다. 상기 실시예를 구현하기 위해, 본 출원은 딥 러닝 모델의 적응 장치를 제공한다. 도4는 본 출원의 실시예4에서 제공하는 딥 러닝 모델의 적응 장치의 구조 개략도이다. 도4에 도시한 바와 같이, 당해 딥 러닝 모델의 적응 장치는, 획득 모듈, 조회 모듈 및 전환 모 듈을 포함한다. 획득 모듈은, 최초 딥 러닝 모델의 모델 정보, 적응해야 하는 타겟 하드웨어의 하드웨어 정보를 획득하는 데 사용된다. 조회 모듈은, 모델 정보 및 하드웨어 정보에 따라, 전환 경로 테이블을 조회하여, 매칭된 타겟 전환 경로 를 획득하는데 사용된다. 전환 모듈은, 타겟 전환 경로에 따라, 최초 딥 러닝 모델을 전환 경로의 중간 딥 러닝 모델로 전환하고, 중간 딥 러닝 모델을 타겟 딥 러닝 모델로 전환하는데 사용된다. 하나의 가능한 상황으로서, 중간 딥 러닝 모델은 여러 개일 수 있고, 타겟 전환 경로는 복수의 중간 딥 러닝 모 델의 전환 순서를 지시하는데 사용되고; 전환 모듈은, 타겟 전환 경로의 복수의 중간 딥 러닝 모델의 전환 순서에 따라, 매번 모델 전환의 전환 전 모델과 전환 후 모 델 및 매번 모델 전환의 수행 순서를 결정하는데 사용되는 결정 유닛; 매번 모델 전환의 전환 전 모델과 전환 후 모델 사이의 매핑 관계에 따라, 매번 모델 전환의 전환 태스크를 생 성하는데 사용되는 생성 유닛; 매번 모델 전환의 수행 순서에 따라, 최초 딥 러닝 모델 순서에 대해 매번 모델 전환의 전환 태스크를 수행하여, 타겟 딥 러닝 모델을 획득하는데 사용되는 수행 유닛; 을 포함한다.다른 하나의 가능한 상황으로서, 생성 유닛은, 매번 모델 전환의 전환 전 모델 및 전환 후 모델에 대해, 오퍼레이터 매핑 관계, 텐서 매핑 관계 및 모델 파라 미터 매핑 관계 중의 적어도 하나를 조회하고; 오퍼레이터 매핑 관계, 텐서 매핑 관계 및 모델 파라미터매핑 관계 중의 적어도 하나에 따라, 매번 모델 전환의 전환 태스크를 생성하는데 더 사용된다. 다른 하나의 가능한 상황으로서, 타겟 하드웨어는 적어도 2개이고, 조회 모듈은, 각 타겟 하드웨어의 하드웨어 정보를 각각 모델 정보와 조합하여, 적어도 2개의 그룹 정보를 획득하는데 사용되 는 조합 유닛; 적어도 2개의 그룹 정보에 따라 전환 경로 테이블을 조회하여, 적어도 2개의 후보 전환 경로를 획득하는데 사용 되는 조회 유닛 - 각 후보 전환 경로는 대응하는 그룹 정보와 매칭됨 - ; 적어도 2개의 후보 전환 경로에 따라, 타겟 전환 경로를 생성하는데 사용되는 경로 생성 유닛; 을 포함한다. 다른 하나의 가능한 상황으로서, 경로 생성 유닛은, 적어도 2개의 후보 전환 경로의 중합된 부분을 결정하고; 적어도 2개의 후보 전환 경로의 중합된 부분을 합병하여, 타겟 전환 경로를 획득하는데 더 사용된다. 다른 하나의 가능한 상황으로서, 모델 정보는 모델 구조 정보 및 훈련 아키텍처 정보를 포함할 수 있다. 설명해야 할 것은, 상기 딥 러닝 모델의 적응 방법의 실시예에 대한 해석 설명은 당해 실시예의 딥 러닝 모델의 적응 장치에도 적용됨으로, 더는 설명하지 않는다. 본 출원 실시예의 딥 러닝 모델의 적응 장치는, 최초 딥 러닝 모델의 모델정보, 적응해야 하는 타겟 하드웨어의 하드웨어 정보를 획득한 후, 모델 정보 및 하드웨어 정보에 따라, 전환 경로 테이블을 조회하여, 매칭된 타겟 전환 경로를 획득하고, 나아가, 타겟 전환 경로에 따라, 최초 딥 러닝 모델을 전환 경로의 중간 딥 러닝 모델로 전환하고, 중간 딥 러닝 모델을 타겟 딥 러닝 모델로 전환한다. 이로하여, 최초 딥 러닝 모델의 모델 정보와 타 겟 하드웨어의 하드웨어 정보를 기반으로, 모델 전환 경로를 결정하여, 모델 전환 경로에 따라 딥 러닝 모델의 전환을 하고, 임의의 유형의 최초 딥 러닝 모델을 임의의 타겟 하드웨어에 적응되는 타겟 딥 러닝 모델로 전환 하도록 구현하고, 딥 러닝 모델이 부동한 하드웨어 단말에 적응하기 어려운 문제를 해결한다. 상기 실시예를 구현하기 위해, 본 출원은 전자 기기를 제공하고, 당해 전자 기기는, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 가능하게 연결되는 메모리; 를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령이 상기 적 어도 하나의 프로세서에 의해 실행될 경우, 상기 적어도 하나의 프로세서가 상기 실시예의 딥 러닝 모델의 적응 방법을 수행하도록 한다. 상기 실시예를 구현하기 위해, 본 출원은 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체를 더 제공하고, 상기 컴퓨터 명령은, 상기 실시예의 딥 러닝 모델의 적응 방법을 수행하도록 한다. 본 출원의 실시예에 따르면, 본 출원은 전자 기기 및 판독 가능한 저장 매체를 더 제공한다. 도 5에 도시한 바와 같이, 이는 본 출원의 실시예의 딥 러닝 모델의 적응 방법을 구현하기 위한 전자 기기의 블 록도이다. 전자 기기는 복수 형식의 디지털 컴퓨터를 나타낸다. 예를 들면, 랩톱 컴퓨터, 데스크톱 컴퓨터, 워 크스테이션, 개인 정보 단말(PAD), 서버, 블레이드 서버, 메인 프레임 및 기타 적합한 컴퓨터일 수 있다. 전자 기기는 복수 형식의 모바일 장치를 나타낸다. 예를 들면 개인 정보 단말(PAD), 셀룰러 폰, 스마트 폰, 웨어러블 기기 및 기타 유사한 컴퓨팅 장치일 수 있다. 본 출원에 나타난 컴포넌트, 이들의 연결와 관계, 및 기능은 단지 예시적인 것 뿐이며, 본 출원에서 설명 및/또는 요구한 본 출원의 구현을 한정하려는 것은 아니다. 도5에 도시한 바와 같이, 당해 전자 기기에는, 하나 또는 복수의 프로세서, 메모리 및 각 컴포넌트를 연결하기 위한 고속 인터페이스와 저속 인터페이스를 포함하는 인터페이스를 포함한다. 각 컴포넌트는 서로 다 른 버스를 이용하여 서로 연결되고, 공동 메인보드에 장착될 수 있고 수요에 의해 기타 방식으로 장착될 수도있다. 프로세서는 메모리 또는 메모리 상에 저장되어 외부의 입력 / 출력 장치 (예를 들면, 인터페이스에 결합 된 디스플레이 기기)에 GUI의 그래픽 정보를 표시하기 위한 명령을 포함한, 전자 기기 내에서 실행 가능한 명령 을 처리할 수 있다. 기타 실시 방식에서, 필요에 따라, 복수의 프로세서 및/또는 복수의 버스를 복수의 메모리 와 같이 사용할 수 있다. 마찬가지로, 복수의 전자 기기를 연결할 수 있고. 각 전자 기기는 일부 필요한 동작 (예를 들면, 서버 어레이, 한 그룹의 블레이드 서버 또는 멀티 프로세서 시스템)을 제공한다. 도5에서는 하나의 프로세서를 예로 든다. 메모리는 본 출원에서 제공하는 비일시적 컴퓨터 판독 가능 저장 매체이다. 상기 메모리에는 적어도 하나 의 프로세서에 의해 수행 가능한 명령이 저장되어 있고, 상기 적어도 하나의 프로세서가 본 출원에서 제공하는 딥 러닝 모델의 적응 방법을 실행할 수 있게 한다. 본 출원의 비일시적 컴퓨터 판독 가능 저장 매체에는 컴퓨터 명령이 저장되어 있고, 당해 컴퓨터 명령은 컴퓨터가 본 출원에서 제공하는 딥 러닝 모델의 적응 방법을 실행하 게 한다. 메모리는 비일시적 컴퓨터 판독 가능 저장 매체로서, 비일시적 소프트웨어 프로그램, 비일시적 컴퓨터 실 행 가능한 프로그램 및 모듈을 저장하는데 사용된다. 예를 들면, 본 출원의 실시예 중의 딥 러닝 모델의 적응 방법에 대응하는 프로그램 명령/모듈(예를 들면, 도4에 도시한 바와 같은 획득 모듈, 조회 모듈)일 수 있다. 프로세서는 메모리에 저장된 비일시적 소프트웨어 프로그램, 명령 및 모듈을 작동시켜, 서 버의 복수의 기능 응용 및 데이터 처리를 실행한다. 즉 상기 방법 실시예의 딥 러닝 모델의 적응 방법을 구현한 다. 메모리는 프로그램 저장영역과 데이터 저장영역을 포함할 수 있고, 프로그램 저장영역은 운영체제, 적어도 하나의 기능에 필요한 애플리케이션 프로그램을 저장할 수 있고, 데이터 저장영역은 전자 기기의 사용에 의해 생성된 데이터 등을 저장할 수 있다. 이 외에, 메모리는 고속 랜덤 액세스 메모리를 포함할 수 있고, 비일 시적 메모리, 예를 들면 적어도 하나의 자기 디스크 메모리, 플래시 메모리 또는 기타 비일시적 솔리드 스테이 트 메모리를 더 포함할 수 있다. 일부 실시예에서, 메모리는 선택적으로 프로세서에 대해 원격으로 설치되는 메모리를 포함하고, 이러한 원격 메모리는 네트워크를 통해 전자 기기에 연결될 수 있다. 상기 네트워 크의 구현예는 인터넷, 인트라넷, 근거리 통신망, 이동 통신망 및 이들의 조합을 포함하나 이에 한정되지 않는 다. 딥 러닝 모델의 적응 방법을 수행하는 전자 기기는 입력 장치 및 출력 장치를 더 포함할 수 있다. 프 로세서, 메모리, 입력 장치 및 출력 장치는 버스 또는 기타 방식을 통해 연결될 수 있고, 도 5에서는 버스를 통해 연결되는 것을 예로 한다. 입력 장치는 입력된 숫자 또는 문자 정보를 수신할 수 있고, 전자 기기의 사용자 설정 및 기능 제어와 관 련되는 키 신호 입력을 생성할 수 있고, 예를 들어, 터치 스크린, 키보드, 마우스, 트랙패드, 터치패드, 포인팅 스틱, 하나 또는 복수의 마우스 버튼, 트랙볼, 조이스틱 등 입력 장치이다. 출력 장치는 디스플레이 기기, 보조 조명 장치(예를 들면, LED)와 촉각 피드백 장치(예를 들면, 진동 모터) 등을 포함할 수 있다. 당해 디스플 레이 기기는 액정 디스플레이(LCD), 발광 다이오드(LED) 디스플레이 및 플라즈마 디스플레이를 포함할 수 있으 나 이에 한정되지 않는다. 일부 실시예에서, 디스플레이 기기는 터치 스크린일 수 있다. 여기서 설명하는 시스템과 기술의 여러 가지 실시형태는 디지털 전자회로 시스템, 집적회로 시스템, 전용 ASIC (특정 용도 지향 집적 회로), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및/또는 이들의 조합에서 실현될 수 있다. 이러한 여러 가지 실시형태는 하나 또는 복수의 컴퓨터 프로그램에서 실시되는 것을 포함할 수 있고, 당해 하나 또는 복수의 컴퓨터 프로그램은 적어도 하나의 프로그래밍 가능 프로세서를 포함하는 프로그래밍 가능 시스템에 서 실행 및/또는 해석되며, 당해 프로그래밍 가능 프로세서는 전용 또는 일반 프로그래밍 가능 프로세서일 수 있으며, 저장 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장치에서 데이터와 명령을 수신할 수 있 고, 데이터와 명령을 당해 저장 시스템, 당해 적어도 하나의 입력 장치 및 당해 적어도 하나의 출력 장치에 전 송할 수 있다. 이러한 컴퓨팅 프로그램(프로그램, 소프트웨어, 소프트웨어 애플리케이션 또는 코드라고도 한다)은 프로그래밍 가능 프로세서의 기계 명령을 포함하고, 고급 절차 및/또는 객체 지향 프로그래밍 언어 및/또는 어셈블리/기계 언어를 이용하여 이러한 컴퓨팅 프로그램을 실시할 수 있다. 본 명세서에서 사용한 용어 \"기계 판독 가능 매 체\"와 \"컴퓨터 판독 가능 매체\"는 기계 명령 및/또는 데이터를 프로그래밍 가능 프로세서에 제공하는 임의의 컴 퓨터 프로그램 제품, 기기 및/또는 장치(예를 들면 자기 디스크, 광 디스크, 메모리, 프로그래밍 가능 로직 장 치(PLD))를 가리키고, 기계 판독 가능 신호인 기계 명령을 수신하는 기계 판독 가능 매체를 포함한다. 용어 \"기계 판독 가능 신호\"는 기계 명령 및/또는 데이터를 프로그래밍 가능 프로세서에 제공하는 임의의 신호를 가리킨 다. 사용자와의 인터랙션을 제공하기 위해, 여기서 설명된 시스템 및 기술은 컴퓨터 상에서 구현할 수 있으며, 당해 컴퓨터는 사용자에게 정보를 디스플레이하는 디스플레이 장치(예를 들면 CRT(음극선관) 또는 LCD(액정 디스플레 이) 모니터); 및 키보드와 지향 장치(예를 들면, 마우스 또는 트랙볼)를 구비하고, 사용자는 당해 키보드와 당 해 지향 장치를 통해 컴퓨터에 입력을 제공할 수 있다. 기타 유형의 장치도 사용자와의 인터랙션에 사용될 수 있는 바, 예를 들면 사용자에게 제공된 피드백은 임의의 형식의 감각 피드백(예를 들면 시각적 피드백, 청각적 피드백 또는 촉각적 피드백)일 수 있고, 임의의 형식(음향 입력, 음성 입력 또는 촉각 입력을 포함)에 의해 사 용자로부터의 입력을 수신할 수 있다. 여기서 설명한 시스템과 기술을 백그라운드 컴포넌트를 포함하는 컴퓨팅 시스템(예를 들면 데이터 서버), 또는 미들웨어 컴포넌트를 포함하는 컴퓨팅 시스템(예를 들면 애플리케이션 서버), 또는 프론트 엔드 컴포넌트를 포 함하는 컴퓨팅 시스템(예를 들면 그래픽 사용자 인터페이스 또는 네트워크 브라우저를 구비한 사용자 컴퓨터이 며, 사용자는 당해 그래픽 사용자 인터페이스 또는 당해 네트워크 브라우저를 통해 여기서 설명한 시스템과 기 술의 실시형태와 인터랙션할 수 있다), 또는 이러한 백그라운드 컴포넌트, 미들웨어 컴포넌트 또는 프론트 엔드 컴포넌트의 임의의 조합을 포함하는 컴퓨팅 시스템에서 실시될 수 있다. 임의의 형태 또는 매체의 디지털 데이 터 통신(예를 들면 통신 네트워크)를 통해 시스템의 컴포넌트를 서로 연결할 수 있다. 통신 네트워크의 예시는 근거리 통신망 (LAN), 광역 통신망 (WAN) 및 인터넷을 포함한다. 컴퓨터 시스템은 클라이언트와 서버를 포함할 수 있다. 클라이언트와 서버는 일반적으로 서로 떨어져 있으며, 통신 네트워크를 통해 서로 인터랙션한다. 대응하는 컴퓨터에서 운행되고 서로 클라이언트-서버 관계를 가지는 컴퓨터 프로그램에 의해 클라이언트와 서버의 관계를 생성한다. 본 출원 실시예의 기술적 수단은, 최초 딥 러닝 모델의 모델정보, 적응해야 하는 타겟 하드웨어의 하드웨어 정 보를 획득한 후, 모델 정보 및 하드웨어 정보에 따라, 전환 경로 테이블을 조회하여, 매칭된 타겟 전환 경로를 획득하고, 나아가, 타겟 전환 경로에 따라, 최초 딥 러닝 모델을 전환 경로의 중간 딥 러닝 모델로 전환하고, 중간 딥 러닝 모델을 타겟 딥 러닝 모델로 전환한다. 이로하여, 최초 딥 러닝 모델의 모델 정보와 타겟 하드웨 어의 하드웨어 정보를 기반으로, 모델 전환 경로를 결정하여, 모델 전환 경로에 따라 딥 러닝 모델의 전환을 하 고, 임의의 유형의 최초 딥 러닝 모델을 임의의 타겟 하드웨어에 적응되는 타겟 딥 러닝 모델로 전환하도록 구 현하고, 딥 러닝 모델이 부동한 하드웨어 단말에 적응하기 어려운 문제를 해결한다. 이해해야 할 것은, 상기 복수 형식의 흐름에 의해, 단계를 재정열, 추가 또는 삭제할 수 있다. 예를 들면, 본 출원에 기재한 각 단계는 병행하여 또는 순차적으로 실행할 수도 있고, 서로 다른 순서로 실행할 수도 있다. 본 출원에서 개시한 기술 방안이 원하는 결과만 구현할 수 있으면 본 출원에서는 이에 한정하지 않는다. 상기 구체적인 실시 방식은 본 출원의 보호 범위를 한정하지 않는다. 본 발명이 속하는 기술 분야의 통상의 기 술자는 설계 요구 및 기타 요소에 의해 여러가지 수정, 조합, 서브 조합 및 대체가 이루어질 수 있음을 이해해 야 한다. 본 출원의 정신과 원칙 내에서 이루어진 모든 수정, 동등한 대체 및 개선은 본 출원 보호 범위에 포함 된다.도면 도면1 도면2 도면3 도면4 도면5"}
{"patent_id": "10-2021-7033450", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면은 본 기술적 수단을 더 잘 이해하는데 사용되고, 본 출원을 한정하려는 것은 아니다. 도1은 본 출원의 실시예1에서 제공하는 딥 러닝 모델의 적응 방법의 흐름도이다. 도2는 본 출원의 실시예2에서 제공하는 모델 전환의 서브 흐름도이다. 도3은 본 출원의 실시예3에서 제공하는 타겟 전환 경로를 생성하는 서브 흐름도이다. 도4는 본 출원의 실시예4에서 제공하는 딥 러닝 모델의 적응 장치의 구조 개략도이다. 도5는 본 출원 실시예의 전자 기기를 구현하는데 사용되는 블록도이다."}
