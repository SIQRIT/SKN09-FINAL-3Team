{"patent_id": "10-2022-0060283", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0160592", "출원번호": "10-2022-0060283", "발명의 명칭": "조건부 시계열 생성적 적대 신경망을 이용하여 가상 풍황 및 해황 데이터를 생성하는 방법", "출원인": "한국전력기술 주식회사", "발명자": "김대호"}}
{"patent_id": "10-2022-0060283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 장치에 의해 수행되는 가상 풍황 및 해황 데이터의 생성 방법에 있어서,사용자로부터, 생성하고자 하는 상기 가상 풍황 및 해황 데이터의 시간 조건을 한정하는 시간 조건 정보(ct)를수신하는 단계;상기 시간 조건 정보(ct)를 미리 학습된 인코딩 신경망(Ec)에 입력하여 인코딩된 시간 조건 정보(ctz)를 생성하는단계;상기 인코딩된 시간 조건 정보(ctz)와 노이즈(zt)를 미리 학습된 생성 신경망(Gz)에 입력하여 임베딩된 가상 시계열 데이터(tz)를 생성하는 단계;상기 임베딩된 가상 시계열 데이터(tz)를 미리 학습된 슈퍼바이저 신경망(Sz)에 입력하여 다음 스텝(t+1)의 임베딩된 가상 시계열 데이터(t+1z)를 생성하는 단계; 및상기 다음 스텝(t+1)의 임베딩된 가상 시계열 데이터(t+1z)를 미리 학습된 리커버리 신경망(Rx)에 입력하여 다음스텝(t+1)의 복원된 가상 시계열 데이터()를 상기 가상 풍황 및 해황 데이터로서 생성하는 단계를 포함하는가상 풍황 및 해황 데이터의 생성 방법."}
{"patent_id": "10-2022-0060283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 슈퍼바이저 신경망(Sz) 및 상기 리커버리 신경망(Rx)을 학습시키는 단계를 더 포함하고,상기 슈퍼바이저 신경망(Sz) 및 상기 리커버리 신경망(Rx)을 학습시키는 단계는,실제 시계열 데이터(xt)를 임베딩 신경망(Ex)에 입력하여 임베딩된 실제 시계열 데이터(xtz)를 생성하는 단계;상기 임베딩된 실제 시계열 데이터(xtz)를 상기 리커버리 신경망(Rx)에 입력하여 복원된 실제 시계열 데이터(t)를 생성하는 단계; 및 상기 임베딩된 실제 시계열 데이터(xtz)를 상기 슈퍼바이저 신경망(Sz)에 입력하여 다음 스텝(t+1)의 임베딩된실제 시계열 데이터(xt+1z)를 생성하는 단계를 포함하는 것을 특징으로 하는 가상 풍황 및 해황 데이터의 생성 방법."}
{"patent_id": "10-2022-0060283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 슈퍼바이저 신경망(Sz) 및 상기 리커버리 신경망(Rx)을 학습시키는 단계는,실제 시계열 데이터(xt)와 복원된 실제 시계열 데이터(t) 간의 오차가 최소화되도록 상기 임베딩 신경망(Ex)과상기 리커버리 신경망(Rx)을 학습시키는 단계; 및공개특허 10-2023-0160592-3-상기 임베딩된 실제 시계열 데이터(xtz)와 상기 다음 스텝(t+1)의 임베딩된 실제 시계열 데이터(xt+1z) 간의 오차가 최소화되도록 상기 슈퍼바이저 신경망(Sz)을 학습시키는 단계를 더 포함하는 것을 특징으로 하는 가상 풍황및 해황 데이터의 생성 방법."}
{"patent_id": "10-2022-0060283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 슈퍼바이저 신경망(Sz) 및 상기 리커버리 신경망(Rx)을 학습시키는 단계는,LR=[Σt||xt-t||2]에 따라 재구성 손실(LR)을 결정하는 단계;Ls=[Σt||xtz-xt+1z||2]에 따라 예측 손실(LS)을 결정하는 단계; 및상기 재구성 손실(LR)과 상기 예측 손실(LS)을 기초로 λLS+LR를 최소화하도록 상기 슈퍼바이저 신경망(Sz) 및 상기 리커버리 신경망(Rx)을 학습시키는 단계를 포함하고, λ는 재구성 손실(LR)과 예측 손실(LS) 간의 스케일을 조정하는 초모수(hyperparameter)인 것을 특징으로 하는가상 풍황 및 해황 데이터의 생성 방법."}
{"patent_id": "10-2022-0060283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 인코딩 신경망(Ec)을 학습시키는 단계를 더 포함하고,상기 인코딩 신경망(Ec)을 학습시키는 단계는,조건 정보(ct)를 상기 인코딩 신경망(Ec)에 입력하여 인코딩된 조건 정보(ctz)를 생성하는 단계;상기 인코딩된 조건 정보(ctz)를 디코딩 신경망(Rc)에 입력하여 디코딩된 조건 정보(t)를 생성하는 단계; 및조건 정보(ct)와 디코딩된 조건 정보(t) 간의 오차가 최소화되도록 상기 인코딩 신경망(Ec)과 상기 디코딩 신경망(Rc)을 학습시키는 단계를 포함하는 것을 특징으로 하는 가상 풍황 및 해황 데이터의 생성 방법."}
{"patent_id": "10-2022-0060283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 생성 신경망(Gz)을 학습시키는 단계를 더 포함하고,상기 생성 신경망(Gz)을 학습시키는 단계는,상기 인코딩된 조건 정보(ctz)와 노이즈(zt)를 상기 생성 신경망(Gz)에 입력하여 임베딩된 가상 시계열 데이터(tz)를 생성하는 단계;상기 임베딩된 가상 시계열 데이터(tz)를 상기 슈퍼바이저 신경망(Sz)에 입력하여 다음 스텝(t+1)의 임베딩된가상 시계열 데이터(t+1z)를 생성하는 단계;상기 다음 스텝(t+1)의 임베딩된 가상 시계열 데이터(t+1z)를를 상기 리커버리 신경망(Rx)에 입력하여 다음 스텝(t+1)의 복원된 가상 시계열 데이터()를 생성하는 단계; 및공개특허 10-2023-0160592-4-실제 시계열 데이터(xt)와 상기 다음 스텝(t+1)의 복원된 가상 시계열 데이터() 간의 분산 및 평균의 차이가 최소화되도록 상기 생성 신경망(Gz)을 학습시키는 단계를 포함하는 것을 특징으로 하는 가상 풍황 및 해황 데이터의 생성 방법."}
{"patent_id": "10-2022-0060283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 생성 신경망(Gz)을 학습시키는 단계는,실제 시계열 데이터(xt)를 임베딩 신경망(Ex)에 입력하여 임베딩된 실제 시계열 데이터(xtz)를 생성하는 단계;상기 임베딩된 실제 시계열 데이터(xtz)를 상기 슈퍼바이저 신경망(Sz)에 입력하여 다음 스텝(t+1)의 임베딩된실제 시계열 데이터(xt+1z)를 생성하는 단계; 및상기 임베딩된 실제 시계열 데이터(xtz)와 상기 다음 스텝(t+1)의 임베딩된 실제 시계열 데이터(xt+1z) 간의 오차가 최소화되도록 상기 생성 신경망(Gz)을 학습시키는 단계를 더 포함하는 것을 특징으로 하는 가상 풍황 및 해황데이터의 생성 방법."}
{"patent_id": "10-2022-0060283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제8항에 있어서,상기 생성 신경망(Gz)을 학습시키는 단계는,LV=(E()-E(xt))+(Var()-Var(xt))에 따라 분포 손실(LV)을 결정하는 단계;LS=[Σt||xtz-xt+1z||2]에 따라 예측 손실(LS)을 결정하는 단계; LU= [Σt log(1-)]에 따라 판별 손실(LU)을 결정하는 단계; 및상기 분포 손실(LV), 상기 예측 손실(LS), 및 상기 판별 손실(LU)을 기초로 LS+LV+γLU를 최소화하도록 상기 생성신경망(Gz)을 학습시키는 단계를 포함하고, γ는 상기 분포 손실(LV), 상기 예측 손실(LS), 및 상기 판별 손실(LU) 간의 스케일을 조정하는 초모수(hyperparameter)인 것을 특징으로 하는 가상 풍황 및 해황 데이터의 생성 방법."}
{"patent_id": "10-2022-0060283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 생성 신경망(Gz)을 학습시키는 단계는,LV=(E()-E(xt))+(Var()-Var(xt))에 따라 분포 손실(LV)을 결정하는 단계;LS=[Σt||xtz-xt+1z||2]에 따라 예측 손실(LS)을 결정하는 단계; LU= [Σt log(1-)]에 따라 판별 손실(LU)을 결정하는 단계; 및상기 분포 손실(LV), 상기 예측 손실(LS), 및 상기 판별 손실(LU)을 기초로 LS+LV+γLU를 최소화하도록 상기 생성신경망(Gz)을 학습시키는 단계를 포함하고, 공개특허 10-2023-0160592-5-γ는 상기 분포 손실(LV), 상기 예측 손실(LS), 및 상기 판별 손실(LU) 간의 스케일을 조정하는 초모수(hyperparameter)인 것을 특징으로 하는 가상 풍황 및 해황 데이터의 생성 방법."}
{"patent_id": "10-2022-0060283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 판별 신경망(Dx)을 학습시키는 단계를 더 포함하고,상기 판별 신경망(Dx)을 학습시키는 단계는,실제 시계열 데이터(xt)를 임베딩 신경망(Ex)에 입력하여 임베딩된 실제 시계열 데이터(xtz)를 생성하는 단계;상기 임베딩된 실제 시계열 데이터(xtz)와 상기 인코딩된 조건 정보(ctz)를 판별 신경망(Dx)에 입력하여 분류 결과(Yt)를 생성하는 단계; 및LU= [Σt logYt]+ [Σt log(1-t)]에 따라 결정되는 판별 손실(LU)을 최소화하도록 상기 판별신경망(Dx)을 학습시키는 단계를 포함하는 것을 특징으로 하는 가상 풍황 및 해황 데이터의 생성 방법."}
{"patent_id": "10-2022-0060283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "컴퓨팅 장치를 이용하여 제1항 내지 제10항 중 어느 한 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2022-0060283", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다양한 실시예들에 따라서 컴퓨팅 장치에 의해 수행되는 가상 풍황 및 해황 데이터의 생성 방법이 제공된다. 상 기 방법은 사용자로부터, 생성하고자 하는 상기 가상 풍황 및 해황 데이터의 시간 조건을 한정하는 시간 조건 정 보(ct)를 수신하는 단계, 상기 시간 조건 정보(ct)를 미리 학습된 인코딩 신경망(Ec)에 입력하여 인코딩된 시간 (뒷면에 계속)"}
{"patent_id": "10-2022-0060283", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 조건부 시계열 생성적 적대 신경망(GAN, Generative Adversarial Networks)을 이용하여 풍황 및 해 황 데이터를 생성하는 방법에 관한 것이다."}
{"patent_id": "10-2022-0060283", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "단기간 또는 장기간의 풍황 및 해황 데이터를 생성함에 있어서, 풍황 및 해황 데이터의 확률 분포를 추정하는 것은 중요한 문제이다. 인공지능 기술이 발전하면서 GAN을 이용하여 풍황 및 해황 시계열 데이터의 확률 분포 를 추정하는 기술이 제안되었다. 종래에는 일반적으로 순환신경망 기반 GAN(Generative Adversarial Networks)을 사용하여 풍황 및 해황 데이터 를 생성하였다. GAN은 생성기(Generator)와 판별기(Discriminator) 간의 적대적 학습(Adversarial learning) 을 통해 풍황 및 해황 데이터의 확률 분포를 추정한다. 그러나 이는 두 가지 문제점이 있다. 첫 번째 문제점은 시간적 역동성(Temporal Dynamics)를 유지할 수 없다는 것이다. 시간적 역동성은 단위 시간에 따라 바뀌는 변수들 간의 복잡한 변화를 의미한다. 두 번째 문제점은 다양한 형태(시간/일/월)의 시간 조건부 확률분포 제어가 불가능하다는 것이다."}
{"patent_id": "10-2022-0060283", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 적대적 학습 신경망과 지도 학습 신경망을 사용하여 시간적 역동성(temporal dynamics)를 유지하면서, 다양한 형태, 예컨대, 시간, 일, 월, 등의 조건 정보를 수신하여 원하는 조건 하의 풍 황 및 해황 데이터를 생성할 수 있는 방법을 제공하는 것이다."}
{"patent_id": "10-2022-0060283", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제들을 달성하기 위한 기술적 수단으로서, 본 발명의 일 측면에 따른 컴퓨팅 장치에 의해 수행 되는 가상 풍황 및 해황 데이터의 생성 방법은 사용자로부터, 생성하고자 하는 상기 가상 풍황 및 해황 데이터 의 시간 조건을 한정하는 시간 조건 정보(ct)를 수신하는 단계, 상기 시간 조건 정보(ct)를 미리 학습된 인코딩 신경망(Ec)에 입력하여 인코딩된 시간 조건 정보(ctz)를 생성하는 단계, 상기 인코딩된 시간 조건 정보(ctz)와 노 이즈(zt)를 미리 학습된 생성 신경망(Gz)에 입력하여 임베딩된 가상 시계열 데이터( tz)를 생성하는 단계, 상기 임베딩된 가상 시계열 데이터( tz)를 미리 학습된 슈퍼바이저 신경망(Sz)에 입력하여 다음 스텝(t+1)의 임베딩된 가상 시계열 데이터( t+1z)를 생성하는 단계, 및 상기 다음 스텝(t+1)의 임베딩된 가상 시계열 데이터( t+1z)를 미 리 학습된 리커버리 신경망(Rx)에 입력하여 다음 스텝(t+1)의 복원된 가상 시계열 데이터( )를 상기 가상 풍 황 및 해황 데이터로서 생성하는 단계를 포함한다. 일 예에 따르면, 상기 슈퍼바이저 신경망(Sz) 및 상기 리커버리 신경망(Rx)을 학습시키는 단계를 더 포함할 수 있다. 상기 슈퍼바이저 신경망(Sz) 및 상기 리커버리 신경망(Rx)을 학습시키는 단계는 실제 시계열 데이터(xt)를 임베 딩 신경망(Ex)에 입력하여 임베딩된 실제 시계열 데이터(xtz)를 생성하는 단계, 상기 임베딩된 실제 시계열 데이 터(xtz)를 상기 리커버리 신경망(Rx)에 입력하여 복원된 실제 시계열 데이터( t)를 생성하는 단계, 및 상기 임베 딩된 실제 시계열 데이터(xtz)를 상기 슈퍼바이저 신경망(Sz)에 입력하여 다음 스텝(t+1)의 임베딩된 실제 시계 열 데이터(xt+1z)를 생성하는 단계를 포함할 수 있다. 상기 슈퍼바이저 신경망(Sz) 및 상기 리커버리 신경망(Rx)을 학습시키는 단계는 실제 시계열 데이터(xt)와 복원 된 실제 시계열 데이터( t) 간의 오차가 최소화되도록 상기 임베딩 신경망(Ex)과 상기 리커버리 신경망(Rx)을 학 습시키는 단계, 및 상기 임베딩된 실제 시계열 데이터(xtz)와 상기 다음 스텝(t+1)의 임베딩된 실제 시계열 데이 터(xt+1z) 간의 오차가 최소화되도록 상기 슈퍼바이저 신경망(Sz)을 학습시키는 단계를 더 포함할 수 있다. 상기 슈퍼바이저 신경망(Sz) 및 상기 리커버리 신경망(Rx)을 학습시키는 단계는 LR= [Σt||xt- t||2]에 따라 재구성 손실(LR)을 결정하는 단계, Ls= [Σt||xtz-xt+1z||2]에 따라 예측 손실(LS)을 결정하는 단계, 및 상기 재구성 손실(LR)과 상기 예측 손실(LS)을 기초로 λLS+LR를 최소화하도록 상기 슈퍼바이저 신경망(Sz) 및 상기 리 커버리 신경망(Rx)을 학습시키는 단계를 포함할 수 있다. 여기서, λ는 재구성 손실(LR)과 예측 손실(LS) 간의 스케일을 조정하는 초모수(hyperparameter)일 수 있다. 상기 인코딩 신경망(Ec)을 학습시키는 단계를 더 포함할 수 있다. 상기 인코딩 신경망(Ec)을 학습시키는 단계는 조건 정보(ct)를 상기 인코딩 신경망(Ec)에 입력하여 인코딩된 조건 정보(ctz)를 생성하는 단계, 상기 인코딩된 조건 정보(ctz)를 디코딩 신경망(Rc)에 입력하여 디코딩된 조건 정보( t)를 생성하는 단계, 및 조건 정보(ct)와 디코딩된 조건 정보( t) 간의 오차가 최소화되도록 상기 인코딩 신경망(Ec)과 상기 디코딩 신경망(Rc)을 학습시 키는 단계를 포함할 수 있다. 상기 생성 신경망(Gz)을 학습시키는 단계를 더 포함할 수 있다. 상기 생성 신경망(Gz)을 학습시키는 단계는 상 기 인코딩된 조건 정보(ctz)와 노이즈(zt)를 상기 생성 신경망(Gz)에 입력하여 임베딩된 가상 시계열 데이터( t z)를 생성하는 단계, 상기 임베딩된 가상 시계열 데이터( tz)를 상기 슈퍼바이저 신경망(Sz)에 입력하여 다음 스텝(t+1)의 임베딩된 가상 시계열 데이터( t+1z)를 생성하는 단계, 상기 다음 스텝(t+1)의 임베딩된 가상 시계열 데이터( t+1z)를를 상기 리커버리 신경망(Rx)에 입력하여 다음 스텝(t+1)의 복원된 가상 시계열 데이터( )를 생성하는 단계, 및 실제 시계열 데이터(xt)와 상기 다음 스텝(t+1)의 복원된 가상 시계열 데이터( ) 간의 분 산 및 평균의 차이가 최소화되도록 상기 생성 신경망(Gz)을 학습시키는 단계를 포함할 수 있다. 상기 생성 신경망(Gz)을 학습시키는 단계는 실제 시계열 데이터(xt)를 임베딩 신경망(Ex)에 입력하여 임베딩된 실제 시계열 데이터(xtz)를 생성하는 단계, 상기 임베딩된 실제 시계열 데이터(xtz)를 상기 슈퍼바이저 신경망 (Sz)에 입력하여 다음 스텝(t+1)의 임베딩된 실제 시계열 데이터(xt+1z)를 생성하는 단계, 및 상기 임베딩된 실제 시계열 데이터(xtz)와 상기 다음 스텝(t+1)의 임베딩된 실제 시계열 데이터(xt+1z) 간의 오차가 최소화되도록 상 기 생성 신경망(Gz)을 학습시키는 단계를 더 포함할 수 있다. 상기 생성 신경망(Gz)을 학습시키는 단계는 상기 임베딩된 가상 시계열 데이터( tz)와 상기 인코딩된 조건 정보 (ctz)를 판별 신경망(Dx)에 입력하여 분류 결과( t)를 생성하는 단계, 및 상기 다음 스텝(t+1)의 임베딩된 가상 시계열 데이터( t+1z)와 상기 인코딩된 조건 정보(ctz)를 상기 판별 신경망(Dx)에 입력하여 분류 결과( t)를 생성 하는 단계를 더 포함할 수 있다. 상기 생성 신경망(Gz)을 학습시키는 단계는 LV= (E( )-E(xt))+ (Var( )-Var(xt))에 따라 분포 손실(LV)을 결정하는 단계, LS= [Σt||xtz-xt+1z||2]에 따라 예측 손실(LS)을 결정하는 단계, LU= [Σt log(1- )]에 따라 판별 손실(LU)을 결정하는 단계, 및 상기 분포 손실(LV), 상기 예측 손실(LS), 및 상기 판별 손실 (LU)을 기초로 LS+LV+γLU를 최소화하도록 상기 생성 신경망(Gz)을 학습시키는 단계를 포함할 수 있다. 여기서, γ는 상기 분포 손실(LV), 상기 예측 손실(LS), 및 상기 판별 손실(LU) 간의 스케일을 조정하는 초모수 (hyperparameter)일 수 있다. 상기 판별 신경망(Dx)을 학습시키는 단계를 더 포함할 수 있다. 상기 판별 신경망(Dx)을 학습시키는 단계는 실 제 시계열 데이터(xt)를 임베딩 신경망(Ex)에 입력하여 임베딩된 실제 시계열 데이터(xtz)를 생성하는 단계, 상기 임베딩된 실제 시계열 데이터(xtz)와 상기 인코딩된 조건 정보(ctz)를 판별 신경망(Dx)에 입력하여 분류 결과(Y t)를 생성하는 단계, 및 LU= [Σt logYt]+ [Σt log(1- t)]에 따라 결정되는 판별 손실(LU)을 최소화하도록 상기 판별 신경망(Dx)을 학습시키는 단계를 포함할 수 있다. 상술한 기술적 과제들을 달성하기 위한 기술적 수단으로서, 본 발명의 일 측면에 따른 컴퓨터 프로그램은 컴퓨 팅 장치를 이용하여 전술한 가상 풍황 및 해황 데이터의 생성 방법을 실행시키기 위하여 매체에 저장된다."}
{"patent_id": "10-2022-0060283", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 적대적 학습 신경망과 지도 학습 신경망을 사용하여 시간적 역동성를 유지하면 서, 다양한 형태, 예컨대, 시간, 일, 월, 등의 조건 정보를 수신하여 원하는 조건 하의 풍황 및 해황 데이터를 생성할 수 있다. 가상으로 생성된 풍황 및 해황 데이터는 실제 데이터와 유사한 분포 특성을 갖고 있으므로, 실제 데이터를 기초 로 유의미한 추정 결과를 도출할 수 있다."}
{"patent_id": "10-2022-0060283", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 다양한 실시예들을 상세히 설명한다. 그러나 본 개시의 기술적 사상은 다양한 형태로 변형되어 구현 될 수 있으므로 본 명세서에서 설명하는 실시예들로 제한되지 않는다. 본 명세서에 개시된 실시예들을 설명함 에 있어서 관련된 공지 기술을 구체적으로 설명하는 것이 본 개시의 기술적 사상의 요지를 흐릴 수 있다고 판단 되는 경우 그 공지 기술에 대한 구체적인 설명을 생략한다. 동일하거나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 본 명세서에서 어떤 요소가 다른 요소와 \"연결\"되어 있다고 기술될 때, 이는 \"직접적으로 연결\"되어 있는 경우 뿐 아니라 그 중간에 다른 요소를 사이에 두고 \"간접적으로 연결\"되어 있는 경우도 포함한다. 어떤 요소가 다 른 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 요소 외에 또 다른 요소를 배제하는 것이 아니라 또 다른 요소를 더 포함할 수 있는 것을 의미한다. 일부 실시예들은 기능적인 블록 구성들 및 다양한 처리 단계들로 설명될 수 있다. 이러한 기능 블록들의 일부 또는 전부는 특정 기능을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현될 수 있다. 예 를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회 로 구성들에 의해 구현될 수 있다. 본 개시의 기능 블록들은 다양한 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 본 개시의 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 본 개시의 기능 블록이 수행하는 기능은 복수의 기능 블록에 의해 수행되거나, 본 개시에서 복수의 기능 블록이 수 행하는 기능들은 하나의 기능 블록에 의해 수행될 수도 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술을 채용할 수 있다. 도 1은 본 발명에 따른 컴퓨팅 장치의 내부 구성을 간략하게 도시한다. 도 1을 참조하면, 컴퓨팅 장치는 제어부, 메모리, 및 데이터베이스(DB, 130)를 포함할 수 있다. 제어부, 메모리, 및 DB는 버스를 통해 서로 데이터를 교환할 수 있다. 일 실시예에 따르면, 제어부, 메모리, 및 DB 중 일부만 컴퓨팅 장치에 포함될 수 있다. 일 실시예에 따르면, 컴퓨팅 장치는 제어부, 메모리, 및 DB 외에, 통신 모듈, 입출력 장치, 또는 저장 장치 등을 더 포함할 수 있다.제어부는 통상적으로 컴퓨팅 장치의 전반적인 동작을 제어한다. 제어부는 기본적인 산술, 로직 및 입출력 연산을 수행하고, 예컨대 메모리에 저장된 프로그램 코드, 예컨대, 인공 신경망을 실행할 수 있 다. 제어부는 프로세서로 지칭될 수 있다. 메모리는 프로세서가 판독할 수 있는 기록 매체로서, RAM, ROM 및 디스크 드라이브와 같은 비소멸성 대용량 기록장치(permanent mass storage device)를 포함할 수 있다. 메모리에는 운영체제와 적어도 하 나의 프로그램 또는 어플리케이션 코드, 예컨대, 인공 신경망 코드가 저장될 수 있다. 메모리에는 조건 정보를 저차원 잠재 공간(latent space)으로 압축하기 위한 인코딩 신경망을 학습하기 위 한 프로그램 코드, 및 인코딩 신경망을 이용하여 조건 정보를 저차원 잠재 공간(latent space)으로 압축하여 인 코딩된 조건 정보를 생성하기 위한 프로그램 코드가 저장될 수 있다. 메모리에는 저차원 잠재 공간에 압축된 인코딩된 조건 정보를 복원하기 위한 디코딩 신경망을 학습하기 위 한 프로그램 코드, 및 디코딩 신경망을 이용하여 인코딩된 조건 정보를 복원하여 디코딩된 조건 정보를 생성하 기 위한 프로그램 코드가 저장될 수 있다. 메모리에는 시계열 데이터를 저차원 잠재 공간(latent space)에 매핑하기 위한 임베딩 신경망을 학습하기 위한 프로그램 코드, 및 임베딩 신경망을 이용하여 시계열 데이터를 저차원 잠재 공간(latent space)에 매칭하 여 임베딩된 시계열 데이터를 생성하기 위한 프로그램 코드가 저장될 수 있다. 메모리에는 저차원 잠재 공간에 매핑된 임베딩된 시계열 데이터를 복원하기 위한 리커버리 신경망을 학습 하기 위한 프로그램 코드, 및 리커버리 신경망을 이용하여 임베딩된 시계열 데이터를 복원하여 복원된 시계열 데이터를 생성하기 위한 프로그램 코드가 저장될 수 있다. 메모리에는 현재 스텝(즉, 스텝 t)에서 다음 스텝(즉, 스텝 t+1)을 예측하기 위한 슈퍼바이저 신경망을 학 습하기 위한 프로그램 코드, 및 슈퍼바이저 신경망을 이용하여 현재 스텝의 임베딩된 시계열 데이터로부터 다음 스텝의 임베딩된 시계열 데이터를 생성하기 위한 프로그램 코드가 저장될 수 있다. 메모리에는 인코딩된 조건 정보와 랜덤 노이즈에 기초하여 임베딩된 가상 시계열 데이터를 생성하기 위한 생성 신경망을 학습하기 위한 프로그램 코드, 및 생성 신경망을 이용하여 임베딩된 가상(fake) 시계열 데이터를 생성하기 위한 프로그램 코드가 저장될 수 있다. 메모리에는 실제 시계열 데이터로부터 생성된 임베딩된 실제 시계열 데이터와 랜덤 노이즈로부터 생성된 임베딩된 가상 시계열 데이터를 판별하기 위한 판별 신경망에, 임베딩된 실제 시계열 데이터와 임베딩된 가상 시계열 데이터 간의 저차원 잠재 공간의 확률 분포를 학습하기 위한 프로그램 코드, 및 판별 신경망을 이용하여 입력된 임베딩된 시계열 데이터가 실제(real) 데이터인지 아니면 가상(fake) 데이터인지를 판별하기 위한 프로 그램 코드가 저장될 수 있다. 메모리에 저장된 인공 신경망을 학습하기 위한 프로그램 코드 및/또는 인공 신경망을 실행하기 위한 프로 그램 코드는 제어부에 로딩되어 제어부에 의해 실행될 수 있다. DB는 프로세서가 판독할 수 있는 기록 매체로서, 디스크 드라이브와 같은 비소멸성 대용량 기록장치 를 포함할 수 있다. DB는 인공 신경망들의 학습에 사용되는 데이터들을 저장할 수 있다. 예를 들면, DB에는 수십년 동안의 한반도 주변의 실제 해황 및 풍황 데이터가 저장될 수 있다. 다양한 실시예들에 따른 제어부의 동작에 대하여 아래에서 더욱 자세히 설명한다. 도 2는 일 실시예에 따른 풍황 및 해황 데이터를 생성하는 방법을 수행하는 제어부의 전체 구성을 도시한다. 도 2를 참조하면, 제어부는 조건 인코딩 모듈, 데이터 임베딩 모듈, 슈퍼바이저 모듈, 생 성기 모듈, 및 판별기 모듈를 포함한다. 제어부는 조건부 시계열 GAN을 이용하여 풍황 및 해황 데이터를 생성할 수 있다. 제어부는 적대적 학습 신경망뿐만 아니라 지도 학습 신경망을 함께 사용함으로써, 시간적 역동성(temporal dynmics)를 유지하면 서 다양한 형태, 예컨대, 시간, 일, 월, 등의 시간 조건을 수신하여 원하는 조건 하의 풍황 및 해황 데이터를 생성할 수 있는 방법을 제공할 수 있다. 본 명세서에서 기호 \"~\"는 복원된 데이터를 의미하고, 기호 \"^\"는 가상으로 생성된 가짜 데이터를 의미한다. 예를 들면, 복원된 시계열 데이터( t)는 원본 시계열 데이터(xt)가 임베딩 신경망(Ex, 222)에서 저차원 잠재 공 간으로 임베딩된 후, 리커버리 신경망(Rx, 224)에서 리커버리 되는 과정을 거친 데이터임을 나타낸다. tz는 저 차원 잠재 공간에 매핑된 압축된 가상 시계열 데이터를 의미한다. 조건 인코딩 모듈은 다양한 형태의 조건 정보(ct)를 저차원의 잠재 공간으로 압축하는 모듈로서, 인코딩 신경망(Ec, 212) 및 디코딩 신경망(Rc, 214)을 포함한다. 조건 인코딩 모듈은 조건 정보(ct)를 입력받는다. 조건 정보(ct)는 사용자가 생성하기를 희망하는 다양한 형태, 예컨대, 시간, 일, 월, 등의 시간 조건에 관한 정보를 벡터화한 데이터이다. 조건 정보(ct)는 다양한 형태의 시간 조건을 압축하여 노이즈로부터 데이터 생성 시 사용되는 조건부 역할을 한다. 인코딩 신경망(Ec, 212)은 아래의 수학식과 같이 조건 정보(ct)를 저차원 잠재 공간으로 압축하여 인코딩된 조건 정보(ctz)를 생성할 수 있다. ctz=Ec(ct) 디코딩 신경망(Rc, 214)은 아래의 수학식과 같이 인코딩된 조건 정보(ctz)를 복원하여 디코딩된 조건 정보( t)를 생성할 수 있다. t=Rc(ctz) 데이터 임베딩 모듈은 실제 시계열 데이터(xt)를 저차원의 잠재 공간으로 매핑하는 모듈로서, 임베딩 신경 망(Ex, 222) 및 리커버리 신경망(Rx, 224)을 포함한다. 임베딩 신경망(Ex, 222)과 리커버리 신경망(Rx, 224)은 LSTM(Long Short Term Memory) 또는 GRU(Gated Recurrent Unit)와 같은 순환 신경망으로 구성될 수 있다. 데이터 임베딩 모듈은 시계열 데이터(xt)를 입력받는다. 시계열 데이터(xt)는 실제 측정된 풍황 및 해황 데이터로서, 시간의 순서에 따라 나열된 데이터이다. 임베딩 신경망(Ex, 222)은 아래의 수학식과 같이 시계열 데이터(xt)를 저차원 잠재 공간에 매핑하여 임베딩된 시 계열 데이터(xtz)를 생성할 수 있다. xtz=Ex(xt) 리커버리 신경망(Rx, 224)은 아래의 수학식과 같이 임베딩된 시계열 데이터(xtz)를 복원하여 복원된 시계열 데이 터( t)를 생성할 수 있다. t=Rx(xtz) 슈퍼바이저 모듈은 현재 스텝(즉, 스텝 t)에서 다음 스텝(즉, 스텝 t+1)을 예측하기 위한 모듈로서, 지도 학습(Supervised learning)을 통해 다음 스텝의 예측을 용이하게 하는 역할을 수행한다. 슈퍼바이저 모듈(23 0)은 슈퍼바이저 신경망(Sz, 232)을 포함한다. 슈퍼바이저 신경망(Sz, 232)은 아래의 수학식과 같이 현재 스텝(t)의 임베딩된 시계열 데이터(xtz, tz)를 입력받 고, 현재 스텝(t)의 임베딩된 시계열 데이터(xtz, tz)로부터 다음 스텝(t+1)의 임베딩된 시계열 데이터(xt+1z, t+1z)를 생성할 수 있다. xt+1z=Sz(xtz) t+1z=Sz( tz) 생성기 모듈은 랜덤 노이즈로부터 가짜(fake) 시계열 데이터를 생성하기 위한 모듈로서, 생성 신경망(Gz, 242)을 포함한다. 생성 신경망(Gz, 242)은 LSTM 또는 GRU와 같은 순환 신경망으로 구성될 수 있다. 생성 신경망(Gz, 242)은 아래의 수학식과 같이 노이즈(zt)와 인코딩된 조건 정보(ctz)를 입력받고, 노이즈(zt)와 인코딩된 조건 정보(ctz)를 기초로 임베딩된 가상 시계열 데이터( tz)를 생성할 수 있다. tz=Gz(zt, ctz) 판별기 모듈은 실제 데이터와 가상 데이터 간의 저차원 잠재 공간의 확률 분포를 학습하기 위한 모듈로서, 실제 시계열 데이터(xt)로부터 생성된 임베딩된 실제 시계열 데이터(xtz)와 랜덤 노이즈(zt)로부터 생성된 임베딩 된 가상 시계열 데이터( tz)를 판별하기 위한 판별 신경망(Dx, 252)을 포함한다. 판별 신경망(Dx, 252)은 LSTM 또는 GRU와 같은 순환 신경망으로 구성될 수 있다. 판별 신경망(Dx, 252)은 아래의 수학식과 같이 임베딩된 시계열 데이터(xtz, tz, t+1z)와 인코딩된 조건 정보 (ctz)를 입력받고, 임베딩된 시계열 데이터(xtz, tz, t+1z)가 실제(real) 데이터인지 아니면 가상(fake) 데이터 인지를 판별하여 분류 결과(Yt, t)를 출력할 수 있다. Yt=Dx(xtz, ctz) t=Dx( tz, ctz) t=Dx( t+1z, ctz) 도 3은 일 실시예에 따라서 제어부의 조건 인코딩 모듈을 학습시키는 과정을 도시한다. 도 3을 참조하면, 조건 인코딩 모듈은 인코딩 신경망(Ec, 212) 및 디코딩 신경망(Rc, 214)을 포함한다. 인코딩 신경망(Ec, 212)은 ctz=Ec(ct)과 같이 조건 정보(ct)를 입력받고, 인코딩된 조건 정보(ctz)를 출력한다. 디코딩 신경망(Rc, 214)은 t=Rc(ctz)과 같이 인코딩된 조건 정보(ctz)를 입력받고, 디코딩된 조건 정보( t)를 출 력한다. 조건 인코딩 모듈을 학습시키는 목적은 다양한 형태의 조건 정보(ct)를 저차원 잠재 공간에 매핑하는 것이다. 조건 정보(ct)는 사용자가 생성하기를 희망하는 다양한 형태, 예컨대, 시간, 일, 월, 등의 시간 조건에 관 한 정보를 벡터화한 데이터이다. 조건 정보(ct)는 인코딩 신경망(Ec, 212)에서 인코딩된 조건 정보(ctz)로 압축 되고, 인코딩된 조건 정보(ctz)는 디코딩 신경망(Rc, 214)에서 디코딩된 조건 정보( t)로 복원된다. 다양한 형태의 조건 정보(ct)가 잠재 공간에 잘 매핑되도록 조건 인코딩 모듈이 학습될 수 있다. 예를 들 면, 인코딩 신경망(Ec, 212)과 디코딩 신경망(Rc, 214)은 원본 조건 정보(ct)와 디코딩된 조건 정보( t) 간의 오 차가 최소화되도록 학습될 수 있다. 일 예에 따르면, 하기 수학식에 따라 정의되는 손실(LE)을 최소화하도록 인 코딩 신경망(Ec, 212)과 디코딩 신경망(Rc, 214)을 학습시킬 수 있다. LE= [Σt||ct- t||2] 도 4는 일 실시예에 따라서 제어부의 데이터 임베딩 모듈과 슈퍼바이저 모듈을 학습시키는 과정을 도 시한다. 도 4를 참조하면, 데이터 임베딩 모듈은 임베딩 신경망(Ex, 222) 및 리커버리 신경망(Rx, 224)을 포함한다. 임베딩 신경망(Ex, 222)은 xtz=Ex(xt)과 같이 실제 시계열 데이터(xt)를 입력받고, 임베딩된 시계열 데이터(xtz)를 출력한다. 리커버리 신경망(Rx, 224)은 t=Rx(xtz)과 같이 임베딩된 시계열 데이터(xtz)를 입력받 고, 복원된 시계열 데이터( t)를 출력한다. 데이터 임베딩 모듈을 학습시키는 목적은 실제 시계열 데이터(xt)가 잘 복원될 수 있도록 시계열 데이터 (xt)를 저차원의 잠재 공간에 매칭하는 것이다. 시계열 데이터(xt)는 스텝(t)에 실제로 측정된 풍황 및 해황 데 이터이며, 여기서 t는 1 이상 T 이하의 자연수이다. 전체 시계열 데이터들(x1:T)은 시간 순서에 따라 배열된 풍 황 및 해황 데이터일 수 있다. 시계열 데이터(xt)는 임베딩 신경망(Ex, 222)을 통해 저차원의 잠재 공간 상에 임베딩된 시계열 데이터(xtz)로 압축되고, 임베딩된 시계열 데이터(xtz)는 리커버리 신경망(Rx, 224)을 통해 복원된 시계열 데이터( t)로 복원된 다. 실제 시계열 데이터(xt)가 저차원의 잠재 공간에 잘 매핑되도록 데이터 임베딩 모듈이 학습될 수 있다. 예를 들면, 임베딩 신경망(Ex, 222) 및 리커버리 신경망(Rx, 224)은 원본 시계열 데이터(xt)와 복원된 시계열 데 이터( t) 간의 오차가 최소화되도록 학습될 수 있다. 일 예에 따르면, 하기 수학식에 따라 정의되는 재구성 손 실(LR)을 최소화하도록 임베딩 신경망(Ex, 222)과 리커버리 신경망(Rx, 224)을 학습시킬 수 있다. LR= [Σt||xt- t||2] 한편, 본 발명에 따르면, 현재 스텝(예컨대, 스텝 t)에서 다음 스텝(예컨대, 스텝 t+1)을 예측하기 위한 슈퍼바 이저 모듈은 지도 학습(Supervised learning)을 통해 다음 스텝의 예측을 용이하게 하는 역할을 수행한다. 슈퍼바이저 모듈은 슈퍼바이저 신경망(Sz, 232)을 포함한다. 슈퍼바이저 신경망(Sz, 232)은 xt+1z=Sz(xtz)과 같이 현재 스텝(t)의 임베딩된 실제 시계열 데이터(xtz)를 입력받 고, 현재 스텝(t)의 임베딩된 실제 시계열 데이터(xtz)로부터 다음 스텝(t+1)의 임베딩된 실제 시계열 데이터 (xt+1z)를 생성할 수 있다. 슈퍼바이저 신경망(Sz, 232)은 현재 스텝(t)의 임베딩된 실제 시계열 데이터(xtz)와 다음 스텝(t+1)의 임베딩된 실제 시계열 데이터(xt+1z) 간의 오차가 최소화되도록 학습될 수 있다. 일 예에 따르면, 하기 수학식에 따라 정 의되는 예측 손실(LS)을 최소화하도록 슈퍼바이저 신경망(Sz, 232)을 학습시킬 수 있다. Ls= [Σt||xtz-xt+1z||2] 데이터 임베딩 모듈과 슈퍼바이저 모듈은 예컨대 min(λLS+LR)와 같이 재구성 손실(LR)과 예측 손실 (LS)을 기초로 λLS+LR를 최소화하도록 학습될 수 있다. 여기서, λ는 재구성 손실(LR)과 예측 손실(LS) 간의 스 케일을 조정하는 초모수(hyperparameter)이다. 도 5a 및 도 5b는 일 실시예에 따라서 제어부의 생성기 모듈을 학습시키는 과정을 도시한다. 먼저, 학습을 위해 가상 데이터라고 판별한 경우 '0'을 출력하고, 실제 데이터라고 판별한 경우 '1'을 출력한다 고 가정한다. 생성기 모듈과 판별기 모듈은 번갈아 가면서 서로 경쟁적(adversarial)으로 학습한다. 생성기 모듈과 판별기 모듈의 학습의 목적은 실제 데이터와 가상 데이터 간의 저차원의 잠재 공간의확률 분포를 추정하는 것이다. 생성기 모듈은 판별기 모듈이 가짜 데이터를 실제 데이터라고 판별하도록 학습할 수 있다. 즉, 생성 기 모듈에서 생성된 임베딩된 가상 시계열 데이터( tz)를 판별기 모듈이 실제 데이터라고 판별하여 '1'을 출력하도록 생성기 모듈을 학습시킬 수 있다. 도 5a를 참조하면, 생성기 모듈은 생성 신경망(Gz, 242)을 포함한다. 생성 신경망(Gz, 242)은 tz=Gz(zt, ctz)와 같이 노이즈(zt)와 인코딩된 조건 정보(ctz)를 입력받고, 노이즈(zt)와 인코딩된 조건 정보(ctz)를 기초로 임베딩된 가상 시계열 데이터( tz)를 생성할 수 있다. 임베딩된 가상 시계열 데이터( tz)는 현재 스텝(t)의 임 베딩된 가상 시계열 데이터( tz)이다. 현재 스텝(t)의 임베딩된 가상 시계열 데이터( tz)는 슈퍼바이저 신경망(Sz, 232)에 입력되고, 슈퍼바이저 신경 망(Sz, 232)은 t+1z=Sz( tz)에 따라 다음 스텝(t+1)의 임베딩된 가상 시계열 데이터( t+1z)를 출력할 수 있다. 다음 스텝(t+1)의 임베딩된 가상 시계열 데이터( t+1z)는 리커버리 신경망(Rx, 224)에 입력되고, 리커버리 신경망 (Rx, 224)은 =Rx( t+1z)에 따라 다음 스텝(t+1)의 복원된 가상 시계열 데이터( )를 출력할 수 있다. 생성기 모듈을 학습하기 위해 분포 손실(LV)이 정의될 수 있다. 분포 손실(LV)은 다음 스텝(t+1)의 복원된 가상 시계열 데이터( )와 현재 스텝(t)의 실제 시계열 데이터(xt) 간의 분산과 평균의 차이를 줄이도록 생성 기 모듈을 학습하기 위한 손실 함수로서, 하기 수학식과 같이 정의될 수 있다. LV= (E( )-E(xt))+(Var( )-Var(xt)) 한편, 실제 시계열 데이터(xt)는 임베딩 신경망(Ex, 222)에 입력되고, 임베딩 신경망(Ex, 222)은 xtz=Ex(xt)에 따 라 임베딩된 시계열 데이터(xtz)를 출력할 수 있다. 현재 스텝(t)의 임베딩된 시계열 데이터(xtz)는 슈퍼바이저 신경망(Sz, 232)에 입력되고, 슈퍼바이저 신경망(Sz, 232)은 xt+1z=Sz(xtz)에 따라 다음 스텝(t+1)의 임베딩된 실 제 시계열 데이터(xt+1z)를 출력할 수 있다. 생성기 모듈을 학습하기 위해 예측 손실(LS)이 정의될 수 있다. 예측 손실(LS)은 현재 스텝(t)에서 다음 스텝(t+1) 데이터를 잘 예측하기 위한 손실 함수로서, 하기 수학식과 같이 현재 스텝(t)의 임베딩된 실제 시계 열 데이터(xtz)와 다음 스텝(t+1)의 임베딩된 실제 시계열 데이터(xt+1z) 간의 오차가 최소화되도록 정의될 수 있 다. LS= [Σt||xtz-xt+1z||2] 도 5b를 참조하면, 생성기 모듈에서 생성된 임베딩된 가상 시계열 데이터( tz)가 판별기 모듈에서 1 로 판별되는 과정이 도시된다. 인코딩된 조건 정보(ctz)는 노이즈(zt)와 함께 생성 신경망(Gz, 242)에 입력되고, 생성 신경망(Gz, 242)은 tz=Gz(zt, ctz)에 따라 노이즈(zt)와 인코딩된 조건 정보(ctz)를 기초로 현재 스텝(t)의 임베딩된 가상 시계열 데 이터( tz)를 출력할 수 있다. 현재 스텝(t)의 임베딩된 가상 시계열 데이터( tz)는 인코딩된 조건 정보(ctz)와 함께 판별 신경망(Dx, 252)에 입 력되고, 판별 신경망(Dx, 252)은 t=Dx( tz, ctz)에 따라 1의 분류 결과( t)를 출력할 수 있다. 현재 스텝(t)의 임베딩된 가상 시계열 데이터( tz)는 슈퍼바이저 신경망(Sz, 232)에 입력되고, 슈퍼바이저 신경 망(Sz, 232)은 t+1z=Sz( tz)에 따라 다음 스텝(t+1)의 임베딩된 가상 시계열 데이터( t+1z)를 출력할 수 있다. 다음 스텝(t+1)의 임베딩된 가상 시계열 데이터( t+1z)는 인코딩된 조건 정보(ctz)와 함께 판별 신경망(Dx, 252) 에 입력되고, 판별 신경망(Dx, 252)은 t=Dx( t+1z, ctz)에 따라 1의 분류 결과( t)를 출력할 수 있다. 생성기 모듈을 학습하기 위해 판별 손실(LU)이 정의될 수 있다. 생성기 모듈의 역할은 판별기 모듈 이 생성기 모듈에서 생성된 임베딩된 가상 시계열 데이터( tz)를 실제 시계열 데이터로 인식하도록 하 는 것이므로, 판별 손실(LU)은 판별기 모듈이 임베딩된 가상 시계열 데이터( tz)에 대하여 1의 분류 결과 ( t)를 출력하도록 학습하기 위한 손실 함수로서, 하기 수학식과 같이 정의될 수 있다. LU= [Σt log(1- )] 생성기 모듈은 예컨대 min(LS+LV+γLU)와 같이 예측 손실(LS), 분포 손실(LV) 및 판별 손실(LU)을 기초로 LS+LV+γLU를 최소화하도록 학습될 수 있다. 여기서, γ는 예측 손실(LS) 및 분포 손실(LV)과 판별 손실(LU) 간 의 스케일을 조정하는 초모수(hyperparameter)이다. 도 6a 및 도 6b는 일 실시예에 따라서 제어부의 판별기 모듈을 학습시키는 과정을 도시한다. 판별기 모듈은 가상 데이터와 실제 데이터의 분류 정확도를 높이도록 학습하여야 하므로, 가상 데이터를 0 으로 분류하고, 실제 데이터를 1로 분류하도록 학습될 수 있다. 도 6a를 참조하면, 실제 시계열 데이터(xtz)가 판별기 모듈에서 1로 판별되는 과정이 도시된다. 판별기 모듈은 판별 신경망(Dx, 252)을 포함한다. 판별 신경망(Dx, 252)은 Yt=Dx(xtz, ctz)와 같이 임베딩 된 실제 시계열 데이터(xtz)와 인코딩된 조건 정보(ctz)를 입력받고, 임베딩된 실제 시계열 데이터(xtz)가 실제 (real) 데이터인지 아니면 가상(fake) 데이터인지를 판별하여 분류 결과(Yt)를 출력할 수 있다. 임베딩된 실제 시계열 데이터(xtz)는 실제 데이터이므로, 판별 신경망(Dx, 252)은 1의 분류 결과(Yt)를 출력할 수 있다. 도 6b를 참조하면, 생성기 모듈에서 생성된 임베딩된 가상 시계열 데이터( tz, t+1z)가 판별기 모듈 에서 0으로 판별되는 과정이 도시된다. 인코딩된 조건 정보(ctz)는 노이즈(zt)와 함께 생성 신경망(Gz, 242)에 입력되고, 생성 신경망(Gz, 242)은 tz=Gz(zt, ctz)에 따라 노이즈(zt)와 인코딩된 조건 정보(ctz)를 기초로 현재 스텝(t)의 임베딩된 가상 시계열 데 이터( tz)를 출력할 수 있다. 현재 스텝(t)의 임베딩된 가상 시계열 데이터( tz)는 인코딩된 조건 정보(ctz)와 함께 판별 신경망(Dx, 252)에 입 력되고, 판별 신경망(Dx, 252)은 t=Dx( tz, ctz)에 따라 0의 분류 결과( t)를 출력할 수 있다. 현재 스텝(t)의 임베딩된 가상 시계열 데이터( tz)는 슈퍼바이저 신경망(Sz, 232)에 입력되고, 슈퍼바이저 신경 망(Sz, 232)은 t+1z=Sz( tz)에 따라 다음 스텝(t+1)의 임베딩된 가상 시계열 데이터( t+1z)를 출력할 수 있다.다음 스텝(t+1)의 임베딩된 가상 시계열 데이터( t+1z)는 인코딩된 조건 정보(ctz)와 함께 판별 신경망(Dx, 252) 에 입력되고, 판별 신경망(Dx, 252)은 t=Dx( t+1z, ctz)에 따라 0의 분류 결과( t)를 출력할 수 있다. 판별기 모듈을 학습하기 위해 판별 손실(LU)이 하기 수학식과 같이 정의될 수 있다. 판별기 모듈은 판별 손실(LU)을 최소화하도록 학습될 수 있다. LU= [Σt logYt]+ [Σt log(1- t)] 도 7은 일 실시예에 따라서 신경망들의 학습이 완료된 제어부를 이용하여 가상 데이터를 생성하는 과정을 도시 한다. 도 7을 참조하면, 사용자로부터 데이터를 생성할 시간 조건에 관한 조건 정보(ct)가 수신될 수 있다. 조건 정 보(ct)는 사용자가 생성하기를 희망하는 다양한 형태, 예컨대, 시간, 일, 월, 등의 시간 조건에 관한 정보를 벡 터화한 데이터이다. 조건 정보(ct)는 인코딩 신경망(Ec, 212)에 입력되고, 인코딩 신경망(Ec, 212)는 조건 정보 (ct)를 압축하여 인코딩된 조건 정보(ctz)를 출력할 수 있다. 인코딩된 조건 정보(ctz)는 노이즈(zt)와 함께 생성 신경망(Gz, 242)에 입력될 수 있다. 생성 신경망(Gz, 242)은 tz=Gz(zt, ctz)에 따라 노이즈(zt)와 인코딩된 조건 정보(ctz)를 기초로 현재 스텝(t)의 임베딩된 가상 시계열 데 이터( tz)를 출력할 수 있다. 현재 스텝(t)의 임베딩된 가상 시계열 데이터( tz)는 슈퍼바이저 신경망(Sz, 232)에 입력되고, 슈퍼바이저 신경 망(Sz, 232)은 t+1z=Sz( tz)에 따라 다음 스텝(t+1)의 임베딩된 가상 시계열 데이터( t+1z)를 출력할 수 있다. 다음 스텝(t+1)의 임베딩된 가상 시계열 데이터( t+1z)는 리커버리 신경망(Rx, 224)에 입력되고, 리커버리 신경망 (Rx, 224)은 =Rx( t+1z)에 따라 다음 스텝(t+1)의 복원된 가상 시계열 데이터( )를 출력할 수 있다. 복원 된 가상 시계열 데이터( )는 본 발명에 따라서 가상으로 생성된 데이터이다. 아래에서는 본 발명에 따라서 가상으로 생성된 데이터와 실제 데이터를 비교한다. 도 8은 본 발명에 따라서 가상으로 생성된 데이터와 실제 데이터의 8월 및 9월 파랑 장미도를 도시한다. 도 9 는 본 발명에 따라서 가상으로 생성된 데이터와 실제 데이터의 8월 및 9월 바람 장미도를 도시한다. 도 8은 방위별 파향 출현빈도와 파향별 파고계급 빈도를 장미도로 도시한 것이고, 도 9는 방위별 풍향 출현빈도 와 풍향별 풍속계급 빈도를 장미도로 도시한 것이다. 도 8 및 도 9의 좌측 도면은 실제 데이터에 대한 것이고, 우측 도면은 본 발명에 따라서 가상으로 생성된 데이터에 대한 것이다. 도 8 및 도 9의 상측 도면은 8월에 대 한 것이고, 하측 도면은 9월에 대한 것이다. 도 8 및 도 9의 장미도를 참조하면, 본 발명에 따라 가상으로 생성된 데이터와 실제 데이터는 월별로 비교하면 상당히 유사하게 모사하는 것으로 나타난다. 본 발명에 따라 가상으로 생성된 데이터는 실제 데이터의 분포 특 성을 잘 모사하고 있음을 알 수 있다. 도 10은 본 발명에 따라서 가상으로 생성된 데이터와 실제 데이터의 8월 및 9월의 1일(1시간 간격) 기준 파고 시계열 그래프를 도시한다. 도 11은 본 발명에 따라서 가상으로 생성된 데이터와 실제 데이터의 8월 및 9월의 1일(1시간 간격) 기준 풍속 시계열 그래프를 도시한다. 도 10은 8월과 9월에 1일(1시간 간격) 기준으로 파고 시계열 데이터를 그래프로 도시한 것이고, 도 11은 8월과 9월에 1일(1시간 간격) 기준으로 풍속 시계열 데이터를 그래프로 도시한 것이다. 도 8 및 도 9의 좌측 도면은 실제 데이터에 대한 것이고, 우측 도면은 본 발명에 따라서 가상으로 생성된 데이터에 대한 것이다. 도 8 및 도 9의 상측 도면은 8월에 대한 것이고, 하측 도면은 9월에 대한 것이다. 도 12는 본 발명에 따라서 가상으로 생성된 데이터와 실제 데이터의 특정 조건 하 작업 가능일수 박스플롯 그래 프를 도시한다. 도 12의 상측 도면은 실제 데이터에 대한 것이고, 하측 도면은 본 발명에 따라서 가상으로 생 성된 데이터에 대한 것이다. 도 10의 파고 시계열 데이터와 도 11의 풍속 시계열 데이터를 이용하여 작업가능 시간대(예컨대, 07:00 ~ 19:00)의 연속되는 일정시간(ex. 8시간 연속)동안 파고, 풍속 기준 특정 조건 하의 작업가능일수를 통계 분석하 여 박스플롯으로 비교한 결과를 도 12에 도시하였다. 도 12에 도시된 바와 같이, 본 발명에 따라 가상으로 생 성된 데이터를 기초로 파고 및 풍속 기준 특정 조건 하에서 추정된 작업가능일수는 실제 데이터를 기초로 추정 된 작업가능일수와 상당히 유사함을 알 수 있다. 본 발명에 따르면, 판별 손실(LU)을 이용한 적대적 학습(Adversarial Learning)과 예측 손실(LS)을 이용한 지도 학습(Supervised Learning)을 함께 사용하기 때문에 시간적 역동성를 유지하면서, 다양한 형태의 조건 정보(시 간/일/월)를 입력하고, 이러한 조건 하의 가상 데이터를 생성할 수 있다. 종래의 GAN 모델에서는 원하는 조건의 가상 데이터를 생성하기 위해서 해당 조건에 부합하는 실제 데이터를 따 로 모아 별도의 모델을 개별적으로 학습해야 한다. 그러나, 본 발명에 따르면, 개별 모델을 학습할 필요없이 하나의 딥러닝 모델에서 조건 정보를 입력 받아서 해당 조건 정보에 부합하는 풍황/해황 데이터를 생성할 수 있 다. 종래의 풍황/해황의 장기 예측은 확률론적인 모델을 구축하여 몬테카를로 시뮬레이션을 활용하여 통계치를 산출 하여 예측한다. 이는 다변수들의 복잡한 상관관계를 동시에 고려하는데 한계가 있다. 본 발명에 따르면, 유의 파고, 풍속, 유의파주기, 풍향, 파향 등 변수들 간의 복잡한 비선형적인 상관관계를 고려한 실제 시계열 데이터 를 생성할 수 있다. 또한 몬테카를로 시뮬레이션은 사전에 확률분포를 정의하여야 하지만, 본 발명에 따르면 확률분포를 별도로 정의할 필요가 없다. 본 발명은 과거(약 40년)의 풍황/해황 데이터의 확률분포를 추정하고 학습된 결과를 이용하여 실제 시계열 데이 터의 시간적 역동적 특성과 유사한 가상 시계열 데이터를 생성하여, 확률론적으로 풍황/해황을 장기 예측할 수 있다. 충분히 큰 개수(N)의 가상 데이터를 생성하여 유의파고, 파향, 풍속, 풍향 등의 확률론적 추론값을 산출 하며, 발전량 예측, 선박의 출항 및 작업 가능일 등을 예측하는데 활용될 수 있다. 예를 들면, 작업가능일의 경우, 몬테카를로 시뮬레이션의 경우 시뮬레이션을 통한 유의파고와 풍속의 평균과 표 준편차를 이용하여 작업가능일 수를 확률론적으로 예측한다. 본 발명에 따르면, 1일 단위의 유의파고와 풍속 시계열을 동시에 생성하여 특정조건(예를 들면 작업이 가능한 시간대인 아침7시부터 저녁8시까지의 일과시간 중 풍속 14m/s이하 & 유의파고 1m이하 조건을 8시간이상 유지와 같은 조건)을 만족하는 작업가능일수를 확률론적으 로 산출할 수 있다. 이는 24시간의 시계열을 평균과 표준편차를 이용하여 통계처리하는 기존 방식과 달리 24시 간의 연속적인 시계열을 충분히 큰 개수(N)만큼 생성함으로써 가능하다. 이상 설명된 다양한 실시예들은 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그램의 형 태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이때, 매 체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것일 수도 있다. 또한, 매체는 단일 또는 수개 하드웨어가 결합된 형태의 다양한 기록수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트워크 상에 분산 존재하는 것일 수도 있다. 매 체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예시로, 애플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어를 공급 내지 유통하는 사이트, 서버 등에서 관리 하는 기록매체 내지 저장매체도 들 수 있다. 본 명세서에서, \"부\", \"모듈\" 등은 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프 로세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다. 예를 들면, \"부\", \"모듈\" 등은 소프트웨어 구성 요소들, 객체 지향 소프트웨어 구성 요소들, 클래스 구성 요소들 및 태스 크 구성 요소들과 같은 구성 요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레 이들 및 변수들에 의해 구현될 수 있다."}
{"patent_id": "10-2022-0060283", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2022-0060283", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 컴퓨팅 장치의 내부 구성을 간략하게 도시한다. 도 2는 일 실시예에 따른 풍황 및 해황 데이터를 생성하는 방법을 수행하는 제어부의 전체 구성을 도시한다. 도 3은 일 실시예에 따라서 제어부의 조건 인코딩 모듈을 학습시키는 과정을 도시한다. 도 4는 일 실시예에 따라서 제어부의 데이터 임베딩 모듈과 슈퍼바이저 모듈을 학습시키는 과정을 도시한다. 도 5a 및 도 5b는 일 실시예에 따라서 제어부의 생성기 모듈을 학습시키는 과정을 도시한다. 도 6a 및 도 6b는 일 실시예에 따라서 제어부의 판별기 모듈을 학습시키는 과정을 도시한다. 도 7은 일 실시예에 따라서 신경망들의 학습이 완료된 제어부를 이용하여 가상 데이터를 생성하는 과정을 도시 한다. 도 8은 본 발명에 따라서 가상으로 생성된 데이터와 실제 데이터의 8월 및 9월 파랑 장미도를 도시한다. 도 9는 본 발명에 따라서 가상으로 생성된 데이터와 실제 데이터의 8월 및 9월 바람 장미도를 도시한다. 도 10은 본 발명에 따라서 가상으로 생성된 데이터와 실제 데이터의 8월 및 9월의 1일(1시간 간격) 기준 파고 시계열 그래프를 도시한다. 도 11은 본 발명에 따라서 가상으로 생성된 데이터와 실제 데이터의 8월 및 9월의 1일(1시간 간격) 기준 풍속 시계열 그래프를 도시한다. 도 12는 본 발명에 따라서 가상으로 생성된 데이터와 실제 데이터의 특정 조건 하 작업 가능일수 박스플롯 그래 프를 도시한다."}
