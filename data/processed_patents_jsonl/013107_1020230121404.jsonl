{"patent_id": "10-2023-0121404", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0038549", "출원번호": "10-2023-0121404", "발명의 명칭": "자율주행 교육용 로봇 및 자율주행 교육용 로봇 시스템", "출원인": "주식회사 제타뱅크", "발명자": "최동완"}}
{"patent_id": "10-2023-0121404", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "클라이언트로 기능하는 전자 장치; 및상기 전자 장치와 데이터를 교환하는 자율주행 교육용 로봇;을 포함하고,상기 자율주행 교육용 로봇은,구동부; 및상기 전자 장치로부터 수신되는 데이터에 기초하여 상기 구동부를 제어하는 제어부;를 포함하고,상기 제어부는,상기 전자 장치에 제공할 자율주행 태스크를 생성하는 서버; 및상기 전자 장치로부터, 상기 자율주행 태스크를 수행함에 따라 생성되는 동작 데이터를 수신하고, 상기 동작 데이터에 기초하여, 이동 경로를 생성하는 경로 생성부; 및상기 이동 경로를 따라 이동하도록 상기 구동부를 제어하는 신호를 생성하는 신호 생성부;를 포함하는 자율주행교육용 로봇 시스템."}
{"patent_id": "10-2023-0121404", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "클라이언트로 기능하는 전자 장치와 데이터를 교환하는 통신부;구동부; 및상기 전자 장치로부터 수신되는 데이터에 기초하여 상기 구동부를 제어하는 제어부;를 포함하고,상기 제어부는,상기 전자 장치에 제공할 자율주행 태스크를 생성하는 서버; 및상기 전자 장치로부터, 상기 자율주행 태스크를 수행함에 따라 생성되는 동작 데이터를 수신하고, 상기 동작 데이터에 기초하여, 이동 경로를 생성하는 경로 생성부; 및상기 이동 경로를 따라 이동하도록 상기 구동부를 제어하는 제1 신호를 생성하는 신호 생성부;를 포함하는 자율주행 교육용 로봇."}
{"patent_id": "10-2023-0121404", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 서버는,상기 태스크를 생성하기 위한 적어도 하나의 프로그램 모듈이 이미지 형태로 구현되는 자율주행 교육용 로봇."}
{"patent_id": "10-2023-0121404", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2항에 있어서,외부 상황을 감지하는 센싱부;를 더 포함하고,상기 서버는,상기 센싱부에서 생성된 데이터를 이용하여 상기 자율주행 태스크를 생성하는 자율주행 교육용 로봇."}
{"patent_id": "10-2023-0121404", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2025-0038549-3-제 2항에 있어서,외부 상황을 감지하는 센싱부;를 더 포함하고,상기 신호 생성부는,상기 제1 신호보다 상기 센싱부에서 생성된 데이터에 기초하여 생성된 제2 신호를 더 우선하여 처리하는 자율주행 교육용 로봇."}
{"patent_id": "10-2023-0121404", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 클라이언트로 기능하는 전자 장치; 및 상기 전자 장치와 데이터를 교환하는 자율주행 교육용 로봇;을 포함하고, 상기 자율주행 교육용 로봇은, 구동부; 및 상기 전자 장치로부터 수신되는 데이터에 기초하여 상기 구 동부를 제어하는 제어부;를 포함하고, 상기 제어부는, 상기 전자 장치에 제공할 자율주행 태스크를 생성하는 서 버; 및 상기 전자 장치로부터, 상기 자율주행 태스크를 수행함에 따라 생성되는 동작 데이터를 수신하고, 상기 동작 데이터에 기초하여, 이동 경로를 생성하는 경로 생성부; 및 상기 이동 경로를 따라 이동하도록 상기 구동부 를 제어하는 신호를 생성하는 신호 생성부;를 포함하는 자율주행 교육용 로봇 시스템에 관한 것이다."}
{"patent_id": "10-2023-0121404", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 자율주행 교육용 로봇 및 자율주행 교육용 로봇 시스템에 관한 것이다."}
{"patent_id": "10-2023-0121404", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇은 최근 산업 현장뿐만 아니라 가정이나 사무실, 관공서 등 일반 건물내에서 가사일이나 사무 보조로서 활 용되고 있다. 이러한 로봇은 공간 내에서 이동을 하면서 탑재된 고유의 기능을 수행한다. 청소 로봇, 안내 로 봇, 방범 로봇, 방역 로봇 등을 예로 들 수 있다. 로봇의 활용도가 높아지면서 로봇 엔지니어를 양성하기 위한 로봇 교육에 대한 관심도 높아지고 있다. 로봇 교 육의 효율성을 높이기 위해서는 교육용 로봇에 대한 개발이 필수적이다. 종래기술에 따른 교육용 로봇은 등록번호 10-2569918과 같이 교육용 코딩 로봇 장치를 다수 제시하는데, 단순 코딩 교육만으로는 로봇의 자율주행 관련 기술에 대한 지식을 습득하기는 어렵다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록번호 10-2569918"}
{"patent_id": "10-2023-0121404", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기한 문제점을 해결하기 위하여, 로봇의 자율주행 관련 기술에 대한 교육을 할 수 있는 자율주행 교육용 로봇을 제공하는데 목적이 있다. 또한, 본 발명은, 상기 자율주행 교육용 로봇이 포함된 시스템을 제공하는데 목적이 있다. 본 발명의 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제들은 아래의 기재 로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0121404", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 달성하기 위하여, 본 발명의 실시예에 따른 자율주행 교육용 로봇 시스템은, 클라이언트로 기능하 는 전자 장치; 및 상기 전자 장치와 데이터를 교환하는 자율주행 교육용 로봇;을 포함하고, 상기 자율주행 교육 용 로봇은, 구동부; 및 상기 전자 장치로부터 수신되는 데이터에 기초하여 상기 구동부를 제어하는 제어부;를 포함하고, 상기 제어부는, 상기 전자 장치에 제공할 자율주행 태스크를 생성하는 서버; 및 상기 전자 장치로부 터, 상기 자율주행 태스크를 수행함에 따라 생성되는 동작 데이터를 수신하고, 상기 동작 데이터에 기초하여, 이동 경로를 생성하는 경로 생성부; 및 상기 이동 경로를 따라 이동하도록 상기 구동부를 제어하는 신호를 생성 하는 신호 생성부;를 포함한다. 본 발명의 실시예에 따른 자율주행 교육용 로봇은, 클라이언트로 기능하는 전자 장치와 데이터를 교환하는 통신 부; 구동부; 및 상기 전자 장치로부터 수신되는 데이터에 기초하여 상기 구동부를 제어하는 제어부;를포함하고, 상기 제어부는, 상기 전자 장치에 제공할 자율주행 태스크를 생성하는 서버; 및 상기 전자 장치로부 터, 상기 자율주행 태스크를 수행함에 따라 생성되는 동작 데이터를 수신하고, 상기 동작 데이터에 기초하여, 이동 경로를 생성하는 경로 생성부; 및 상기 이동 경로를 따라 이동하도록 상기 구동부를 제어하는 제1 신호를 생성하는 신호 생성부;를 포함한다. 상기 서버는, 상기 태스크를 생성하기 위한 적어도 하나의 프로그램 모듈이 이미지 형태로 구현된다. 본 발명의 실시예에 따른 자율주행 교육용 로봇은, 외부 상황을 감지하는 센싱부;를 더 포함하고, 상기 서버는, 상기 센싱부에서 생성된 데이터를 이용하여 상기 자율주행 태스크를 생성한다. 본 발명의 실시예에 따른 자율주행 교육용 로봇은, 외부 상황을 감지하는 센싱부;를 더 포함하고, 상기 신호 생 성부는, 상기 제1 신호보다 상기 센싱부에서 생성된 데이터에 기초하여 생성된 제2 신호를 더 우선하여 처리한 다. 기타 실시예들의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2023-0121404", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 다음과 같은 효과가 하나 혹은 그 이상 있다. 첫째, 로봇에 지식이 없는 교육 대상자도 제시되는 교육용 로봇으로부터 제공되는 태스크를 수행함으로써 로봇 교육의 효율성을 높이는 효과가 있다. 둘째, 교육용 로봇에 서버가 구현되고, 전자 장치가 클라이언트로 기능함에 따라, 사용자 인터페이스의 편의성 이 증대되는 효과가 있다. 셋째, 로봇의 자율주행 기술에 대한 효율적인 교육이 가능한 효과가 있다."}
{"patent_id": "10-2023-0121404", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 청구범위의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0121404", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 도 1은 본 발명의 실시예에 따른 시스템을 설명하는데 참조되는 도면이다. 도면을 참조하면, 시스템은, 자율주행 교육용 로봇 시스템으로 명명될 수 있다. 시스템은, 자율주행 교 육용 로봇 및 전자 장치를 포함할 수 있다. 자율주행 교육용 로봇은 전자 장치와 통신할 수 있다. 자율주행 교육용 로봇은, 태스크를 생성 하여 전자 장치에 제공할 수 있다. 자율주행 교육용 로봇은, 도 2 내지 도 7을 참조하여 보다 상세하 게 설명한다. 전자 장치는, 사용자 입력에 기초하여, 태스크를 수행할 수 있다. 이를 위해, 전자 장치는 사용자 입력을 수신하는 입력부, 사용자가 확인할 수 있는 형태로 정보를 출력하는 출력부, 통신부 및 컴퓨팅 장치를 포함할 수 있다. 한편, 사용자는 교육 대상자일 수 있다. 전자 장치는, 교육용 로봇으로부터 제공받은 태스크에 대한 정보를 출력부를 통해 출력할 수 있다. 전자 장치는, 태스크에 대한 사용자 입력을 입력부를 통해 수신할 수 있다. 전자 장치는, 입력부를 통해 수신되는 사용자 입력에 기초하여, 태스크를 수행할 수 있다. 전자 장치는, 태스크를 수행함에 따라 생성되는 동작 데이터를 통신부를 통해 교육용 로봇에 전송할 수 있다. 본 발명의 실시예에 따라, 자율주행 교육용 로봇은 서버로 기능하고, 전자 장치는 클라이언트로 기능 할 수 있다. 도 2는 본 발명의 실시예에 따른 자율주행 교육용 로봇의 제어 블럭도이다. 도면을 참조하면, 자율주행 교육용 로봇은, 특정 공간에서 스스로 이동하면서 동작을 수행할 수 있다. 자 율주행 교육용 로봇은, 자율 주행할 수 있다. 자율주행 교육용 로봇은, 센싱부 및 인공지능 모 듈에서 생성된 데이터에 기초하여 주행 경로를 생성하고, 생성된 경로를 따라 자율 주행할 수 있다. 자율주행 교육용 로봇은, 센싱부, 인공지능 모듈, 통신부, 입력부, 메모리, 제 어부, 구동부, 암 구동부, HMI 및 충전부를 포함할 수 있다. 센싱부는, 자율주행 교육용 로봇 내부 또는 외부의 상황을 감지할 수 있다. 센싱부는, 적어도 하나의 센서에서 생성된 데이터를 제어부에 제공할 수 있다. 제어부는, 센싱부로부터 수신된 데 이터에 기초하여 동작을 수행할 수 있다. 센싱부는, 대상 공간에서 사람을 검출할 수 있다. 예를 들면, 센싱부는, 카메라로 촬영된 영상 분석 을 통해, 대상 공간에서 사람을 검출할 수 있다. 센싱부는, 대상 공간의 오염도를 측정할 수 있다. 예를 들면, 센싱부는, 환경 센서에서 생성된 데이 터를 통해, 대상 공간의 오염도를 측정할 수 있다. 한편, 센싱부는, 자율주행 교육용 로봇이 주행하는 도중에 내부 또는 외부의 상황을 감지할 수 있다. 센싱부는, 복수의 센서를 포함한다. 센싱부는, 초음파 센서, 라이다, 레이다, 적외선 센서, 카메라, 환경 센서, IMU(Inertial Measurement Unit)를 포함할 수 있다. 초음파 센서는, 초음파를 이용하여, 자율주행 교육용 로봇 외부의 오브젝트를 감지할 수 있다. 초음파 센서는, 초음파 송신부, 수신부를 포함할 수 있다. 실시예에 따라, 초음파 센서는, 초음파 송신부, 수신 부와 전기적으로 연결되어, 수신되는 신호를 처리하고, 처리된 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적어도 하나의 제어부를 더 포함할 수 있다. 초음파 센서의 제어부 기능은 제어부에서 구현될 수도 있다. 초음파 센서는, 초음파를 기초로 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 초음파 센서는, 자율주행 교육용 로봇의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 자율 주행 교육용 로봇 외부의 적절한 위치에 배치될 수 있다. 라이다는, 레이저 광을 이용하여, 자율주행 교육용 로봇 외부의 오브젝트를 감지할 수 있다. 라이다는, 광 송신부 및 광 수신부를 포함할 수 있다. 실시예에 따라, 라이다는, 광 송신부 및 광 수신부와 전 기적으로 연결되어, 수신되는 신호를 처리하고, 처리된 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적 어도 하나의 제어부를 더 포함할 수 있다. 라이다의 제어부 기능은 제어부에서 구현될 수도 있다. 라이다는, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식으로 구현될 수 있다. 라이다는, 구동식 또는 비구동식으로 구현될 수 있다. 구동식으로 구현되는 경우, 라이다는, 모터에 의해 회전되며, 자율주행 교육용 로봇 주변의 오브젝트를 검 출할 수 있다. 비구동식으로 구현되는 경우, 라이다는, 광 스티어링에 의해, 자율주행 교육용 로봇을 기준으로 소정 범위 내에 위치하는 오브젝트를 검출할 수 있다. 자율주행 교육용 로봇은 복수의 비구동식 라이다를 포함할 수 있다. 라이다는, 레이저 광 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 라이다는, 자율주행 교육용 로봇의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 자율주행 교육용 로봇 외부의 적절한 위치에 배치될 수 있다. 레이다는, 전자파 송신부, 수신부를 포함할 수 있다. 레이더는 전파 발사 원리상 펄스 레이더(Pulse Radar) 방 식 또는 연속파 레이더(Continuous Wave Radar) 방식으로 구현될 수 있다. 레이더는 연속파 레이더 방식 중에서 신호 파형에 따라 FMCW(Frequency Modulated Continuous Wave)방식 또는 FSK(Frequency Shift Keying) 방식으 로 구현될 수 있다. 레이더는 전자파를 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브 젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 레이더는, 자율주행 교육용 로봇의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 자율주행 교육용 로봇의 외부의 적절한 위치에 배치될 수 있다. 적외선 센서는, 적외선 송신부, 수신부를 포함할 수 있다. 적외선 센서는, 적외선 광을 기초로 오브젝트를 검출 하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 적외선 센서는, 자율주행 교육용 로봇의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 자율 주행 교육용 로봇의 외부의 적절한 위치에 배치될 수 있다. 카메라는, 자율주행 교육용 로봇 외부 영상을 촬영할 수 있다. 카메라는, 영상을 이용하여 자율주행 교육용 로봇 외부의 오브젝트에 대한 정보를 생성할 수 있다. 카메라 는 적어도 하나의 렌즈, 적어도 하나의 이미지 센서 및 이미지 센서와 전기적으로 연결되어 수신되는 신호를 처 리하고, 처리되는 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적어도 하나의 제어부를 포함할 수 있다. 카메라는, 모노 카메라, 스테레오 카메라 중 적어도 어느 하나일 수 있다. 카메라는, 다양한 영상 처리 알고리즘을 이용하여, 오브젝트의 위치 정보, 오브젝트와의 거리 정보 또는 오브젝 트와의 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 획득된 영상에서, 시간에 따른 오브젝트 크기의 변화를 기초로, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 핀홀(pin hole) 모델, 노면 프로파일링 등을 통해, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 스테레오 카메라에서 획득된 스테레오 영상에서 디스패러티(disparity) 정보를 기초로 오 브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 카메라는, 자율주행 교육용 로봇 외부를 촬영하기 위해 FOV(field of view) 확보가 가능한 위치에 장착될 수 있다. 자율주행 교육용 로봇은, 복수의 카메라를 포함할 수 있다. 예를 들면, 자율주행 교육용 로봇은, 전 방 카메라, 후방 카메라, 좌측방 카메라, 우측방 카메라를 구성된 4채널 카메라를 포함할 수 있다. 환경 센서는, 대상 공간에 대한 오염도를 센싱할 수 있다. 예를 들면, 환경 센서는, 대상 공간에서의 방역 대상 이 되는 생화학적 오염 물질의 유무, 농도 등을 센싱할 수 있다. IMU(Inertial Measurement Unit)는, 자율주행 교육용 로봇의 관성을 측정할 수 있다. IMU는, 가속도계와 회전 속도계, 때로는 자력계의 조합을 사용하여 자율주행 교육용 로봇의 특정한 힘, 각도 비율 및 때로는 자율주행 교육용 로봇을 둘러싼 자기장을 측정하는 전자 장치로 설명될 수 있다. 제어부는, IMU로부 터 수신되는 데이터에 기초하여 자율주행 교육용 로봇의 자세에 대한 정보를 생성할 수 있다. IMU는, 가속도 센서, 자이로 센서, 자기 센서 중 적어도 어느 하나를 포함할 수 있다. 인공지능 모듈은, 머신 러닝으로 사물, 공간, 자율주행 교육용 로봇의 속성을 학습할 수 있다. 머신 러닝은 컴퓨터에게 사람이 직접 로직(Logic)을 지시하지 않아도 데이터를 통해 컴퓨터가 학습을 하고 이를 통해 컴퓨터가 알아서 문제를 해결하게 하는 것을 의미한다. 딥러닝(Deep Learning)은. 인공지능(artificial intelligence)을 구성하기 위한 인공신경망(Artificial Neural Networks: ANN)에 기반으로 해 컴퓨터에게 사람의 사고방식을 가르치는 방법으로 사람이 가르치지 않아도 컴퓨 터가 스스로 사람처럼 학습할 수 있는 인공지능 기술이다. 상기 인공신경망(ANN)은 소프트웨어 형태로 구현되거나 칩(chip) 등 하드웨어 형태로 구현될 수 있다. 인공지능 모듈은 공간의 속성, 장애물 등 사물의 속성이 학습된 소프트웨어 또는 하드웨어 형태의 인공신 경망(ANN)을 포함할 수 있다. 예를 들어, 인공지능 모듈은 딥러닝(Deep Learning)으로 학습된 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), DBN(Deep Belief Network) 등 심층신경망(Deep Neural Network: DNN)을 포함 할 수 있다. 인공지능 모듈은 상기 심층신경망(DNN)에 포함된 노드들 사이의 가중치(weight)들에 기초하여 입력되는 영 상 데이터에 포함되는 공간, 사물의 속성을 판별할 수 있다. 인공지능 모듈은, 머신 러닝(machine learning)으로 기학습된 데이터에 기초하여 상기 선택된 특정 시점 영상에 포함되는 공간, 장애물의 속성을 인식할 수 있다. 한편, 메모리에는 공간, 사물 속성 판별을 위한 입력 데이터, 상기 심층신경망(DNN)을 학습하기 위한 데이 터가 저장될 수 있다. 메모리에는 카메라가 획득한 원본 영상과 소정 영역이 추출된 추출 영상들이 저장될 수 있다. 또한, 실시예에 따라서는, 메모리에는 상기 심층신경망(DNN) 구조를 이루는 웨이트(weight), 바이어스 (bias)들이 저장될 수 있다. 또는, 실시예에 따라서는, 상기 심층신경망 구조를 이루는 웨이트(weight), 바이어스(bias)들은 인공지능 모듈 의 임베디드 메모리(embedded memory)에 저장될 수 있다. 한편, 인공지능 모듈은 센싱부를 통해 수신한 데이터를 트레이닝(training) 데이터로 사용하여 학습 과정을 수행할 수 있다. 자율주행 교육용 로봇은 통신부를 통하여 상기 소정 서버로부터 머신 러닝과 관련된 데이터를 수신할 수 있다. 이 경우에, 자율주행 교육용 로봇은, 상기 소정 서버로부터 수신된 머신 러닝과 관련된 데이터에 기초하여 인공지능 모듈을 업데이트(update)할 수 있다. 자율주행 교육용 로봇의 동작으로 획득되는 데이터가 서버로 전송될 수 있다. 자율주행 교육용 로봇 은, 서버로 공간(space), 사물(Object), 사용(Usage) 관련 데이터(Data)를 서버로 전송할 수 있다. 여기서, 공 간(space), 사물(Object) 관련 데이터는 자율주행 교육용 로봇이 인식한 공간(space)과 사물(Object)의 인식 관련 데이터이거나, 카메라가 획득한 공간(space)과 사물(Object)에 대한 이미지 데이터일 수 있다. 또한, 사용(Usage) 관련 데이터(Data)는 소정 제품, 예를 들어, 자율주행 교육용 로봇의 사용에 따라 획득되는 데이터로, 사용 이력 데이터, 센싱부에서 획득된 센싱 데이터 등이 해당될 수 있다. 한편, 자율주행 교육용 로봇의 인공지능 모듈에는 CNN(Convolutional Neural Network) 등 심층신경 망 구조(DNN)가 탑재될 수 있다. 상기 학습된 심층신경망 구조(DNN)는 인식용 입력 데이터를 입력받고, 입력 데 이터에 포함된 사물, 공간의 속성을 인식하여, 그 결과를 출력할 수 있다. 또한, 상기 학습된 심층신경망 구조 (DNN)는 인식용 입력 데이터를 입력받고, 자율주행 교육용 로봇의 사용(Usage) 관련 데이터(Data)를 분석 하고 학습하여 사용 패턴, 사용 환경 등을 인식할 수 있다. 한편, 공간(space), 사물(Object), 사용(Usage) 관련 데이터(Data)는 통신부를 통하여 서버로 전송될 수 있다. 서버는 학습된 웨이트(weight)들의 구성을 생성할 수 있고, 서버는 심층신경망(DNN) 구조를 트레이닝 (training) 데이터를 사용하여 학습할 수 있다. 서버는 수신한 데이터에 기초하여, 심층신경망(DNN)을 학습시킨 후, 업데이트된 심층신경망(DNN) 구조 데이터를 자율주행 교육용 로봇으로 전송하여 업데이트하게 할 수 있다. 이에 따라, 자율주행 교육용 로봇은 점점 더 똑똑해지고, 사용할수록 진화되는 사용자 경험(UX)을 제공할 수 있다. 인공지능 모듈은, 센싱부를 통해 수신한 데이터를 트레이닝 데이터로 사용하여 오브젝트를 검출 동작 의 학습 과정을 수행할 수 있다. 여기서, 오브젝트는, 자율주행 교육용 로봇 주변의 사물, 사람, 구조물 등 자율주행 교육용 로봇의 이동에 직접적 또는 간접적으로 영향을 주는 객체로 정의할 수 있다. 인공지능 모듈은, 소프트웨어로 구현되거나, 하드웨어 형태로 구현될 수 있다. 인공지능 모듈이 프로 세서(예를 들면, GPU)로 구현되는 경우, 인공지능 모듈이 구현된 프로세서로 명명될 수 있다. 한편, 실시예에 따라, 인공지능 모듈은, 제어부의 하위 개념으로 분류될 수 있다. 이경우, 인공지능 모듈의 동작은 제어부의 동작으로 설명될 수 있다. 통신부는, 무선으로 전자 장치와 신호를 교환할 수 있다. 전자 장치는, 클라이언트로 기능할 수 있다. 통신부는, 외부의 전자 장치와 데이터를 교환할 수 있다. 통신부는, 통신을 수행하기 위해 송신 안테나, 수신 안테나, 각종 통신 프로토콜이 구현 가능한 RF(Radio Frequency) 회로 및 RF 소자 중 적어도 어느 하나를 포함할 수 있다. 입력부는, 사용자로부터 정보를 입력받기 위한 것으로, 입력부에서 수집한 데이터는, 제어부에 의해 분석되어, 사용자의 제어 명령으로 처리될 수 있다. 입력부는, 음성 입력부, 터치 입력부를 포함할 수 있다. 실시예에 따라, 제스쳐 입력부 또는 기계식 입력 부를 포함할 수 있다. 음성 입력부는, 사용자의 음성 입력을 전기적 신호로 전환할 수 있다. 전환된 전기적 신호는, 제어부에 제 공될 수 있다. 음성 입력부는, 하나 이상의 마이크로 폰을 포함할 수 있다. 터치 입력부는, 사용자의 터치 입력을 전기적 신호로 전환할 수 있다. 전환된 전기적 신호는 제어부에 제 공될 수 있다. 터치 입력부는, 사용자의 터치 입력을 감지하기 위한 터치 센서를 포함할 수 있다. 실시예에 따라, 터치 입력부는 디스플레이와 일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있다. 이 러한, 터치 스크린은, 자율주행 교육용 로봇과 사용자 사이의 입력 인터페이스 및 출력 인터페이스를 함께 제공할 수 있다.제스쳐 입력부는, 사용자의 제스쳐 입력을 전기적 신호로 전환할 수 있다. 전환된 전기적 신호는 제어부에 제공될 수 있다. 제스쳐 입력부는, 사용자의 제스쳐 입력을 감지하기 위한 적외선 센서 및 이미지 센서 중 적어도 어느 하나를 포함할 수 있다. 기계식 입력부는, 버튼, 돔 스위치(dome switch), 조그 휠 및 조그 스위치 중 적어도 어느 하나를 포함할 수 있 다. 기계식 입력부에 의해 생성된 전기적 신호는, 제어부에 제공될 수 있다. 메모리는, 제어부와 전기적으로 연결된다. 메모리는 유닛에 대한 기본데이터, 유닛의 동작제어 를 위한 제어데이터, 입출력되는 데이터를 저장할 수 있다. 메모리는, 제어부에서 처리된 데이터를 저장할 수 있다. 메모리는, 하드웨어적으로, ROM, RAM, EPROM, 플래시 드라이브, 하드 드라이브 중 적어도 어느 하나로 구성될 수 있다. 메모리는 제어부의 처리 또는 제어를 위한 프로그램 등, 자율주행 교육 용 로봇 전반의 동작을 위한 다양한 데이터를 저장할 수 있다. 메모리는, 제어부와 일체형으로 구현될 수 있다. 실시예에 따라, 메모리는, 제어부의 하위 구성으로 분류될 수 있다. 구동부는, 자율주행 교육용 로봇의 이동 동력을 제공할 수 있다. 구동부는, 동력 생성부 및 동 력 전달부를 포함할 수 있다. 동력 생성부는, 전기 에너지를 힘 에너지로 전환할 수 있다. 이를 위해 동력 생성부는, 적어도 하나의 모터로 구성될 수 있다. 동력 전달부는, 동력 생성부에서 생성된 동력을 구동휠에 전달할 수 있다. 동력 전달부는, 적어도 하나의 기어 또는 적어도 하나의 벨트를 포함할 수 있다. 암 구동부는, 암을 구동할 수 있다. 암 구동부는, 암이 적어도 하나의 관절을 기준으로 회전하기 위한 동력을 제공할 수 있다. 암 구동부(15 5)는, 동력 생성부 및 동력 전달부를 포함할 수 있다. 동력 생성부는, 전기 에너지를 힘 에너지로 전환할 수 있다. 이를 위해 동력 생성부는, 적어도 하나의 모터로 구성될 수 있다. 동력 전달부는, 동력 생성부에서 생성된 동력을 암의 복수의 회전부에 전달할 수 있다. 동력 전달부는, 적어도 하나의 기어 또는 적어도 하나의 벨트를 포함할 수 있다. HMI(Human Machine Interface)는, 대상 공간에 위치한 사람과 인터렉션을 수행할 수 있다. 이를 위해 HMI는, 출력 장치로 디스플레이 및 스피커를 포함할 수 있다. 상술한 입력부는 HMI의 하위 개념으로 분류될 수 있다. 디스플레이는, 다양한 정보에 대응되는 그래픽 객체를 표시할 수 있다. 디스플레이는 액정 디스플레이(liquid crystal display, LCD), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display, TFT LCD), 유기 발광 다이오드(organic light-emitting diode, OLED), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전자잉크 디스플레이(e-ink display) 중에서 적어도 하나를 포함할 수 있다. 디스플레이는 터치 입력부와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써, 터치 스크린을 구현 할 수 있다. 디스플레이는 복수로 구성될 수 있다. 예를 들면, 디스플레이는, 터치 스크린으로 구성되어 터치 입 력을 수신할 수 있는 제1 디스플레이 및 정보 출력을 위한 제2 디스플레이로 구성될 수 있다. 스피커는, 제어부로부터 제공되는 전기 신호를 오디오 신호로 변환하여 출력한다. 이를 위해, 스피커 는, 하나 이상의 스피커를 포함할 수 있다. 충전부는, 충전 스테이션으로부터 전기 에너지를 공급받을 수 있다. 충전부는. 공급받은 전기 에너지 를 배터리에 저장할 수 있다. 제어부는, 자율주행 교육용 로봇의 각 유닛의 전반적인 동작을 제어할 수 있다. 제어부는 ECU(Electronic Control Unit)로 명명될 수 있다. 제어부는, 자율주행 교육용 로봇의 각 유닛과 전기적으로 연결된다. 제어부는, ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processors), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 제어부는, 전자 장치로부터 수신되는 데이터에 기초하여 구동부 및 암 구동부 중 적어도 어느 하나를 제어할 수 있다. 제어부는, 통신부를 통해, 전자 장치로부터 데이터를 수신할 수 있다. 여기서, 데이터는, 자율 주행 교육용 로봇의 동작과 관련된 데이터일 수 있다. 제어부는, 수신되는 데이터에 기초하여, 구동부 및 암 구동부 중 적어도 어느 하나를 제어할 수 있다. 제어부는, 서버, 경로 생성부 및 신호 생성부를 포함할 수 있다. 서버는, 전자 장치에 제공할 자율주행 태스크(Task)를 생성할 수 있다. 자율주행 태스크는, 전자 장치를 통한 사용자 입력에 따라 자율주행 교육용 로봇의 동작을 유도하는 프로 그램일 수 있다. 자율주행 교육용 로봇에 서버가 포함됨으로 인해, 전자 장치가 사용자에게 교육용 브라우저를 제공할 수 있다. 자율주행 교육용 로봇이 서버로 기능하고, 전자 장치는, 클라이언트로 기능할 수 있다. 전자 장치는, 교육용 브라우저를 통해, 자율주행 태스크와 관련된 화면을 제공할 수 있다. 서버는, 제1 자율주행 태스크를 생성할 수 있다. 제1 자율주행 태스크는 예제 자율주행 태스크로 명명될 수 있다. 예를 들면, 제1 자율주행 태스크는, 자율주행 교육용 로봇의 암의 제1 동작을 유도하기 위해 전자 장치 에 제공되는 프로그램일 수 있다. 제1 자율주행 태스크는, 기 설정된 시나리오에 맞춰 사용자의 단순 입력을 유도하는 방식으로 구현될 수 있다. 전자 장치에 제1 자율주행 태스크가 제공된 상태에서, 전자 장치는, 교육용 브라우저를 통해, 자율주 행 태스크와 관련된 화면을 표시할 수 있다. 전자 장치는 기 설정된 시나리오대로 화면을 표시할 수 있다. 전자 장치는 기 설정된 시나리오 대로 사용자의 실행 버튼을 반복적으로 수신할 수 있다. 전자 장치는, 제1 자율주행 태스크를 수행함에 따라 제1 동작 데이터를 생성할 수 있다. 전자 장치는, 제1 동작 데이터를 자율주행 교육용 로봇에 전송할 수 있다. 서버는, 제2 자율주행 태스크를 생성할 수 있다. 제2 자율주행 태스크는 실습 자율주행 태스크로 명명될 수 있다. 예를 들면, 제2 자율주행 태스크는, 자율주행 교육용 로봇의 암의 제2 동작을 유도하기 위해 전자 장치 에 제공되는 프로그램일 수 있다. 제2 동작은 제1 동작과 다른 동작일 수 있다. 제2 자율주행 태스크는, 미션 동작 수행을 위해, 사용자의 응용 입력을 유도하는 방식으로 구현될 수 있다. 제2 자율주행 태스크는, 제1 자율주행 태스크를 참조하여, 사용자의 응용을 유도하여 주어진 미션을 수행하기 위한 자율주행 태스크로 설명될 수 있다. 응용 입력은, 단순 입력과는 다르게 버튼의 입력 순서 및 입력 조합을 구성 하여 입력되는 사용자 입력으로 설명될 수 있다. 미션 동작은, 구동부 및 암 구동부의 구동에 따라 조합될 수 있는 자율주행 교육용 로봇의 움직 임으로 설명될 수 있다. 한편, 서버는, 센싱부의 데이터를 이용하여, 제2 자율주행 태스크를 생성할 수 있다. 예를 들면, 서 버는, 센싱부를 감지된 외부 오브젝트에 대한 데이터에 기초하여, 오브젝트를 회피하며 이동하는 제2 자율주행 태스크를 생성할 수 있다.한편, 서버는, 도커(docker) 기반으로 구축될 수 있다. 서버는, 태스크를 생성하기 위한 적어도 하나 의 프로그램 모듈이 이미지 형태로 구현될 수 있다. 여기서, 이미지는 도커 이미지일 수 있다. 서버가 도커 기반으로 구축됨으로 인해, 서버를 구성하는 프로그램의 관리 및 배포가 용이하다. 복수 의 자율주행 교육용 로봇에 효율적으로 서버를 구축할 수 있다. 경로 생성부는, 전자 장치로부터 자율주행 태스크를 수행함에 따라 생성되는 동작 데이터를 수신할 수 있다. 경로 생성부는, 동작 데이터에 기초하여, 이동 경로를 생성할 수 있다. 신호 생성부는, 이동 경로를 따라 이동하도록 구동부를 제어하는 신호를 생성할 수 있다. 신호 생성부는, 제1 자율주행 태스크를 수행함에 따라 생성된 제1 동작 데이터에 기초하여, 구동부 및 암 구동부 중 적어도 어느 하나를 제어하기 위한 제1 구동 신호를 생성할 수 있다. 신호 생성부는, 제2 자율주행 태스크를 수행함에 따라 생성된 제2 동작 데이터이 기초하여, 구동부 및 암 구동부 중 적어도 어느 하나를 제어하기 위한 제2 구동 신호를 생성할 수 있다. 신호 생성부는, 자율주행 태스크에 기초하여, 신호 생성부에서 생성된 제1 자율주행 신호보다 센싱부 에서 생성된 데이터에 기초하여, 신호 생성부에서 생성된 제2 자율주행 신호를 더 우선하여 처리할 수 있다. 이로인해, 제1 자율주행 신호에 기초하여 자율주행 교육용 로봇이 이동 중에 장애물이 감지되는 경우, 장 애물을 회피할 수 있게 된다. 도 3은 본 발명의 실시예에 따른 시스템의 신호처리도이다. 도면을 참조하면, 서버는, 자율주행 태스크를 생성할 수 있다(S310). 자율주행 태스크는, 전자 장치 를 통한 사용자의 입력을 통해 자율주행 교육용 로봇의 자율주행 동작을 수행하기 위한 프로그램으로 설명 될 수 있다. 제어부는, 통신부를 통해, 자율주행 태스크에 대응한 동작 데이터를 수신할 수 있다(S320). 제어부는, 통신부를 통해 자율주행 태스크를 전자 장치에 전송할 수 있다. 전자 장치는, 자율주행 태스크와 관련된 화면이 브라우저로 표시된 상태에서, 사용자 입력을 수신할 수 있다. 전자 장치(20 0)는, 사용자 입력에 기초하여, 자율주행 태스크에 대응한 동작 데이터를 생성할 수 있다. 전자 장치는, 동작 데이터를 자율주행 교육용 로봇에 전송하고, 제어부는, 동작 데이터를 수신할 수 있다. 경로 생성부는, 동작 데이터에 기초하여 자율주행 교육용 로봇의 이동 경로를 생성할 수 있다(S325). 신호 생성부는, 자율주행 교육용 로봇이 이동 경로를 따라 자율주행할 수 있도록 제1 신호를 생성할 수 있다(S330). 구동부는, 제1 신호에 기초하여, 구동휠을 동작시킬 수 있다(S340). 이동 경로를 따라 자율주행 교육용 로봇이 주행 중에, 센싱부는, 이동 경로상 오브젝트를 검출할 수 있다(S350). 이경우, 신호 생성부는, 센싱부로부터 센싱 데이터를 수신할 수 있다. 이경우, 신호 생성부는, 제1 신호보다 센싱부에서 생성된 데이터에 기초하여 생성된 제2 신호를 더 우선하여 처리할 수 있다 (S360). 구동부는, 제1 신호에 기초한 동작을 멈추고, 제2 신호에 기초하여 구동휠을 동작시킬 수 있다(S370). 도 4는 본 발명의 실시예에 따른 서버를 설명하는데 참조되는 도면이다. 도면을 참조하면, 서버는, 도커 기반으로 구축될 수 있다. 이를 위해, 서버는, 컴퓨터, OS, 도 커엔진 및 컨테이너를 포함할 수 있다. 컴퓨터는, 적어도 하나의 프로세서를 포함할 수 있다. OS는, 서버 운영 체제로 컴퓨터에 설치될 수 있다. 도커엔진은, 클라이언트와 서버 아키텍처를 따르는 애플리케이션으로 도커 이미지를 관리할 수 있다. 컨테이너는, 격리된 상태로 시스템 자원 및 네트워크를 사용할 수 있는 독립된 공간이다. 서버는 복 수의 컨테이너를 포함할 수 있고, 각각의 컨테이너에는 서버의 기능을 구현하는 개별 프로그램 들이 할당될 수 있다. 이와 같이, 교육용 로봇의 서버가 도커 기반으로 구축됨으로 인해, 제한된 자율주행 교육용 로봇 의 시스템 자원을 효율적으로 이용할 수 있게 된다. 도 5 내지 도 7은 본 발명의 실시예에 따른 자율주행 교육용 로봇의 동작을 설명하는데 참조되는 도면이다. 도 5는 제1 자율주행 태스크에 기초한 자율주행 교육용 로봇의 동작을 예시하고, 도 6은 제2 자율주행 태 스크에 기초한 자율주행 교육용 로봇의 동작을 예시하고, 도 7은 센싱부에서 생성된 데이터에 기초한 자율주행 교육용 로봇의 동작을 예시한다. 도 5를 참조하면, 제1 자율주행 태스크는, 교육용 로봇이, 제2 오브젝트(OB2)와 제3 오브젝트(OB3) 사이를 가로질러 가도록 이동 경로를 생성하여 이동하도록하는 프로그램일 수 있다. 전자 장치는, 제1 자율주행 태스크가 수신되어, 제1 자율주행 태스크와 관련된 화면이 브라우저로 표시된 상태에서, 기 설정된 시나리오에 따라 실행 버튼(예를 들면, 키보드의 엔터버튼)이 여러번 입력되는 신호를 수 신할 수 있다. 전자 장치는, 제1 자율주행 태스크에 대응되는 제1 동작 데이터를 생성할 수 있다. 제1 동작 데이터는, 기 설정된 시나리오에 따라 입력 버튼이 눌려지면 생성되는 교육용 로봇의 동작을 유도하는 데이터이다. 교육용 로봇은, 전자 장치로부터 제1 동작 데이터를 수신하고, 제1 동작 데이터에 기초하여, 제1 이 동 경로를 생성하고, 제1 이동 경로를 따라 이동할 수 있다. 여기서, 제1 이동 경로는, 제2 오 브젝트(OB2)와 제3 오브젝트(OB3) 사이를 가로질러 가는 시작점(ST)에서부터 도착점(ED)까지의 경로일 수 있다. 도 6을 참조하면, 제2 자율주행 태스크는, 교육용 로봇이, 제1 이동 경로와는 다른 제2 이동 경로 로 이동하는 것을 미션 동작으로 하는 프로그램일 수 있다. 제2 이동 경로는, 제1 오브젝트(OB)와 제 2 오브젝트(OB2) 사이를 가로질러 가는 경로일 수 있다. 전자 장치는, 제2 자율주행 태스크가 수신되어 제2 자율주행 태스크와 관련된 화면이 브라우저로 표시된 상태에서, 사용자 응용 입력을 수신할 수 있다. 전자 장치는, 제2 자율주행 태스크에 대응되는 제2 동작 데이터를 생성할 수 있다. 제2 동작 데이터는, 응 용 사용자 입력 수신에 따라 생성되는 교육용 로봇의 동작을 유도하는 데이터이다. 교육용 로봇은, 전자 장치로부터 제2 동작 데이터를 수신하고, 제2 동작 데이터에 기초하여, 제2 이 동 경로를 생성하고, 제2 이동 경로를 따라 이동할 수 있다. 여기서, 제2 이동 경로는, 제1 오 브젝트(OB)와 제2 오브젝트(OB2) 사이를 가로질러 가는 시작점(ST)에서부터 도착점(ED)까지의 경로일 수 있다. 도 7을 참조하면, 교육용 로봇이 제2 이동 경로를 따라 이동하는 중에, 센싱부는 제1 오브젝트 (OB1)를 감지할 수 있다. 이경우, 교육용 로봇는, 센싱부에서 생성된 데이터에 기초한 동작을 더 우 선하여 처리할 수 있다. 예를 들면, 교육용 로봇은, 제2 이동 경로를 따라 자율주행하는 동작을 멈추고 제1 오브젝트(OB)를 회피하는 제3 이동 경로를 생성하여, 제3 이동 경로를 따라 이동할 수 있다. 예를 들면, 교육용 로봇은, 제2 이동 경로를 따라 자율주행하는 동작을 멈추고 제1 오브젝트(OB)가 더 이상 검출되지 않는 경우 다시 제2 이동 경로를 따라 자율주행할 수 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 상기 컴 퓨터는 프로세서 또는 제어부를 포함할 수도 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석 되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다.부호의 설명 10 : 자율주행 교육용 로봇 시스템 100 : 자율주행 교육용 로봇 200 : 전자장치"}
{"patent_id": "10-2023-0121404", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 시스템을 설명하는데 참조되는 도면이다. 도 2는 본 발명의 실시예에 따른 자율주행 교육용 로봇의 제어 블럭도이다. 도 3은 본 발명의 실시예에 따른 시스템의 신호처리도이다. 도 4는 본 발명의 실시예에 따른 서버를 설명하는데 참조되는 도면이다. 도 5 내지 도 7은 본 발명의 실시예에 따른 자율주행 교육용 로봇의 동작을 설명하는데 참조되는 도면이다."}
