{"patent_id": "10-2021-0062969", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0131123", "출원번호": "10-2021-0062969", "발명의 명칭": "인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련 방법 및 시스템", "출원인": "리벨리온 주식회사", "발명자": "오진욱"}}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "프로세싱 유닛은 가속기(accelerator)에 포함된 프로세싱 엘리먼트(processing element)의 SIMD(SingleInstruction Multiple Data) 폭(width)을 식별하는 단계; 상기 프로세싱 유닛은 인공 신경망의 가중치들을 초기화하는 단계; 상기 프로세싱 유닛은 상기 식별된 SIMD 폭에 따라 상기 인공 신경망의 입력 채널과 출력 채널에 배열된 가중치들을 가중치 그룹들로 그룹화하는 단계; 상기 프로세싱 유닛은 상기 가중치 그룹들을 의식(aware)하여 상기 인공 신경망에 포함된 상기 복수의 가중치들을 가지치기(pruning)하는 단계; 및상기 프로세싱 유닛은 상기 가지치기된 복수의 가중치들을 업데이트하는 단계를 포함하는 인공 신경망의 가속하드웨어를 위한 가지치기 기반의 훈련 방법."}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 프로세싱 유닛은, CPU(Central Processing Unit), 또는 GPU(Graphic Processing Unit)인 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련 방법."}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 SIMD 폭이 2일 때, 상기 복수의 가중치들 중에서 2개의 가중치들이 하나의 가중치 그룹을 형성하며,상기 SIMD 폭이 4일 때, 상기 복수의 가중치들 중에서 4개의 가중치들이 하나의 가중치 그룹을 형성하며,상기 SIMD 폭이 8일 때, 상기 복수의 가중치들 중에서 8개의 가중치들이 하나의 가중치 그룹을 형성하는 인공 신경망의 가속 하드웨어를위한 가지치기 기반의 훈련 방법."}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 프로세싱 유닛은 상기 가중치 그룹들을 의식(aware)하여 상기 인공 신경망에 포함된 상기복수의 가중치들을 가지치기(pruning)하는 단계는,상기 프로세싱 유닛은 상기 가중치 그룹들 각각에서 대표 가중치들을 추출하는 단계; 상기 프로세싱 유닛은 상기 대표 가중치들 각각을 문턱값들 각각과 비교하는 단계; 및상기 대표 가중치들 중 어느 하나가 대응하는 문턱값보다 작을 때, 상기 프로세싱 유닛은 상기 대표 가중치들중 어느 하나에 대응하는 가중치 그룹에 속한 가중치들 모두를 0으로 설정하는 단계를 포함하는 인공 신경망의가속 하드웨어를 위한 가지치기 기반의 훈련 방법."}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 프로세싱 유닛은 상기 가중치 그룹들을 의식(aware)하여 상기 인공 신경망에 포함된 상기복수의 가중치들을 가지치기(pruning)하는 단계는,공개특허 10-2022-0131123-3-상기 대표 가중치들 중 다른 하나가 대응하는 문턱값보다 클 때, 상기 프로세싱 유닛은 상기 대표 가중치들 중다른 하나에 대응하는 가중치 그룹에 속한 가중치들 모두를 유지하는 단계를 더 포함하는 인공 신경망의 가속하드웨어를 위한 가지치기 기반의 훈련 방법."}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 인공 신경망의 입력 채널과 상기 인공 신경망의 출력 채널에서 0을 가지는 가중치들이 상기 식별된 SIMD 폭에 해당하는 만큼 연속해서 존재하는 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의훈련 방법."}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 프로세싱 엘리먼트는, 가중치 레지스터를 포함하며, 상기 가중치 레지스터는 행렬로 구현되며, 상기 행렬의 행을 따라 상기 인공 신경망의 출력 채널에 배열된 가중치들이 순서대로 삽입되며, 상기 행렬의 열을 따라 상기 인공 신경망의 입력 채널에 배열된 가중치들이 순서대로 삽입되는 인공 신경망의가속 하드웨어를 위한 가지치기 기반의 훈련 방법."}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제4항에 있어서, 상기 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련 방법은,상기 프로세싱 유닛은 손실 함수의 기울기와, 상기 문턱값들과 관련된 상기 손실 함수의 기울기에 기초하여 상기 인공 신경망의 가중치들과, 상기 문턱값들을 업데이트하는 단계를 더 포함하는 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련 방법."}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "명령들을 저장하는 메모리; 및상기 명령들을 실행하는 프로세싱 유닛을 포함하며, 상기 명령들은, 가속기에 포함된 프로세싱 엘리먼트의 SIMD 폭을 식별하며, 인공 신경망의 가중치들을 초기화하며, 상기 식별된 SIMD 폭에 따라 상기 인공 신경망의 입력 채널과 출력 채널에 배열된 가중치들을 가중치 그룹들로그룹화하며, 상기 가중치 그룹들을 의식하여 상기 인공 신경망에 포함된 상기 복수의 가중치들을 가지치기하며, 상기 가지치기된 복수의 가중치들을 업데이트하도록 구현되는 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련 시스템."}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 프로세싱 유닛은, CPU(Central Processing Unit), 또는 GPU(Graphic Processing Unit)인 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련 시스템."}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서, 공개특허 10-2022-0131123-4-상기 SIMD 폭이 2일 때, 상기 복수의 가중치들 중에서 2개의 가중치들이 하나의 가중치 그룹을 형성하며,상기 SIMD 폭이 4일 때, 상기 복수의 가중치들 중에서 4개의 가중치들이 하나의 가중치 그룹을 형성하며,상기 SIMD 폭이 8일 때, 상기 복수의 가중치들 중에서 8개의 가중치들이 하나의 가중치 그룹을 형성하는 인공 신경망의 가속 하드웨어를위한 가지치기 기반의 훈련 시스템."}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서, 상기 가중치 그룹들을 의식하여 상기 인공 신경망에 포함된 상기 복수의 가중치들을 가지치기하는 명령은, 상기 가중치 그룹들 각각에서 대표 가중치를 추출하며, 상기 대표 가중치들 각각을 문턱값들 각각과 비교하며, 상기 대표 가중치들 중 어느 하나가 대응되는 문턱값보다 작을 때, 상기 대표 가중치들 중 어느 하나에 대응하는 가중치 그룹들에 속한 가중치들 모두를 0으로 설정하는 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련 시스템."}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 가중치 그룹들을 의식하여 상기 인공 신경망에 포함된 상기 복수의 가중치들을 가지치기하는 명령은,상기 대표 가중치들 중 다른 하나가 대응하는 문턱값보다 클 때, 상기 대표 가중치들 중 다른 하나에 대응하는가중치 그룹들에 속한 가중치들 모두를 유지하도록 구현되는 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련 시스템."}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서, 상기 인공 신경망의 입력 채널과 상기 인공 신경망의 출력 채널에서 0을 가지는 가중치들이 상기 식별된 SIMD 폭에 해당하는 만큼 연속해서 존재하는 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의훈련 시스템."}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서, 상기 프로세싱 엘리먼트는, 가중치 레지스터를 포함하며, 상기 가중치 레지스터는, 행렬로 구현되며, 상기 행렬의 행을 따라 상기 인공 신경망의 출력 채널에 배열된 가중치들이 순서대로 삽입되며, 상기 행렬의 열을 따라 상기 인공 신경망의 입력 채널에 배열된 가중치들이 순서대로 삽입되는 인공 신경망의가속 하드웨어를 위한 가지치기 기반의 훈련 시스템."}
{"patent_id": "10-2021-0062969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서, 상기 명령들은, 손실 함수의 기울기와, 상기 문턱값들과 관련된 상기 손실 함수의 기울기에 기초하여 상기 인공 신경망의 가중치들과, 상기 문턱값들을 업데이트하도록 구현되는 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련공개특허 10-2022-0131123-5-시스템."}
{"patent_id": "10-2021-0062969", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련 방법이 개시된다. 상기 인공 신경망의 가속 하드웨어 를 위한 가지치기 기반의 훈련 방법은 프로세싱 유닛은 가속기에 포함된 프로세싱 엘리먼트의 SIMD 폭을 식별하 는 단계, 상기 프로세싱 유닛은 인공 신경망의 가중치들을 초기화하는 단계, 상기 프로세싱 유닛은 상기 식별된 SIMD 폭에 따라 상기 인공 신경망의 입력 채널과 출력 채널에 배열된 가중치들을 가중치 그룹들로 그룹화하는 단 계, 상기 프로세싱 유닛은 상기 가중치 그룹들을 의식(aware)하여 상기 인공 신경망에 포함된 상기 복수의 가중 치들을 가지치기(pruning)하는 단계, 및 상기 프로세싱 유닛은 상기 가지치기된 복수의 가중치들을 업데이트하는 단계를 포함한다."}
{"patent_id": "10-2021-0062969", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련 방법 및 시스템에 관한 것으로, 상세하게 는 가속 하드웨어에서 연산 속도 향상과 에너지 소비 감소를 위한 인공 신경망의 가속 하드웨어를 위한 가지치 기 기반의 훈련 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2021-0062969", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 신경망(artificial neural network)은 컴퓨터 비전(computer vision), 자연어 처리, 및 음성 인식과 같은 다양한 인공 지능 어플리케이션들에서 사용된다. 인공 신경망은 훈련 단계와 추론 단계로 나뉠 수 있다. 훈련 단계에서 훈련 데이터를 이용하여 인공 신경망의 파라미터들이 학습된다. 추론 단계에서 새로운 입력 데이터를 훈련된 인공 신경망에 적용하여 인공 신경망의 예측 결과가 출력된다. 훈련 동작은 CPU, 또는 GPU에서 수행된다. 추론 동작은 인공 지능 어플리케이션들을 가속시키기 위해 특별히 고 안된 가속 하드웨어인 AI 가속기에서 수행된다. 더 복잡한 연산을 수행하고 정확도를 높이기 위해 인공 신경망의 사이즈가 증가함에 따라 에너지 소비 증가와 병목 현상이 발생할 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 공개특허공보 제10-2020-0093404호(2020.08.05.)"}
{"patent_id": "10-2021-0062969", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적인 과제는 상기와 같은 종래의 문제점들을 해결하기 위한 것으로, 인공 신경망 의 훈련 단계에서 인공 신경망의 사이즈를 줄여 에너지 소비 감소와 연산 속도 향상이 가능한 인공 신경망의 가 속 하드웨어를 위한 가지치기 기반의 훈련 방법 및 시스템을 제공하는 것이다."}
{"patent_id": "10-2021-0062969", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련 방법은 프로세싱 유닛은 가속기(accelerator)에 포함된 프로세싱 엘리먼트(processing element)의 SIMD(Single Instruction Multiple Data) 폭(width)을 식별하는 단계, 상기 프로세싱 유닛은 인공 신경망의 가중치들을 초기화하는 단계, 상기 프 로세싱 유닛은 상기 식별된 SIMD 폭에 따라 상기 인공 신경망의 입력 채널과 출력 채널에 배열된 가중치들을 가 중치 그룹들로 그룹화하는 단계, 상기 프로세싱 유닛은 상기 가중치 그룹들을 의식(aware)하여 상기 인공 신경 망에 포함된 상기 복수의 가중치들을 가지치기(pruning)하는 단계, 및 상기 프로세싱 유닛은 상기 가지치기된 복수의 가중치들을 업데이트하는 단계를 포함한다. 상기 프로세싱 유닛은 CPU(Central Processing Unit), 또는 GPU(Graphic Processing Unit)일 수 있다. 상기 SIMD 폭이 2일 때, 상기 복수의 가중치들 중에서 2개의 가중치들이 하나의 가중치 그룹을 형성한다. 상기 SIMD 폭이 4일 때, 상기 복수의 가중치들 중에서 4개의 가중치들이 하나의 가중치 그룹을 형성한다. 상기 SIMD 폭이 8일 때, 상기 복수의 가중치들 중에서 8개의 가중치들이 하나의 가중치 그룹을 형성한다. 상기 프로세싱 유닛은 상기 가중치 그룹들을 의식(aware)하여 상기 인공 신경망에 포함된 상기 복수의 가중치들 을 가지치기(pruning)하는 단계는 상기 프로세싱 유닛은 상기 가중치 그룹들 각각에서 대표 가중치들을 추출하는 단계, 상기 프로세싱 유닛은 상기 대표 가중치들 각각을 문턱값들 각각과 비교하는 단계, 및 상기 대표 가중 치들 중 어느 하나가 대응하는 문턱값보다 작을 때, 상기 프로세싱 유닛은 상기 대표 가중치들 중 어느 하나에 대응하는 가중치 그룹에 속한 가중치들 모두를 0으로 설정하는 단계를 포함한다. 상기 프로세싱 유닛은 상기 가중치 그룹들을 의식(aware)하여 상기 인공 신경망에 포함된 상기 복수의 가중치들 을 가지치기(pruning)하는 단계는, 상기 대표 가중치들 중 다른 하나가 대응하는 문턱값보다 클 때, 상기 프로 세싱 유닛은 상기 대표 가중치들 중 다른 하나에 대응하는 가중치 그룹에 속한 가중치들 모두를 유지하는 단계 를 더 포함할 수 있다. 상기 인공 신경망의 입력 채널과 상기 인공 신경망의 출력 채널에서 0을 가지는 가중치들이 상기 식별된 SIMD 폭에 해당하는 만큼 연속해서 존재한다. 상기 프로세싱 엘리먼트는 가중치 레지스터를 포함한다. 상기 가중치 레지스터는 행렬로 구현된다. 상기 행렬의 행을 따라 상기 인공 신경망의 출력 채널에 배열된 가중치들이 순서대로 삽입된다. 상기 행렬의 열 을 따라 상기 인공 신경망의 입력 채널에 배열된 가중치들이 순서대로 삽입된다. 상기 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련 방법은 상기 프로세싱 유닛은 손실 함수의 기 울기와, 상기 문턱값들과 관련된 상기 손실 함수의 기울기에 기초하여 상기 인공 신경망의 가중치들과, 상기 문 턱값들을 업데이트하는 단계를 더 포함할 수 있다. 본 발명의 실시 예에 따른 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련 시스템은 명령들을 저장 하는 메모리, 및 상기 명령들을 실행하는 프로세싱 유닛을 포함한다. 상기 명령들은 가속기에 포함된 프로세싱 엘리먼트의 SIMD 폭을 식별하며, 인공 신경망의 가중치들을 초기화하 며, 상기 식별된 SIMD 폭에 따라 상기 인공 신경망의 입력 채널과 출력 채널에 배열된 가중치들을 가중치 그룹 들로 그룹화하며, 상기 가중치 그룹들을 의식하여 상기 인공 신경망에 포함된 상기 복수의 가중치들을 가지치 기하며, 상기 가지치기된 복수의 가중치들을 업데이트하도록 구현된다. 상기 프로세싱 유닛은 CPU(Central Processing Unit), 또는 GPU(Graphic Processing Unit)일 수 있다. 상기 SIMD 폭이 2일 때, 상기 복수의 가중치들 중에서 2개의 가중치들이 하나의 가중치 그룹을 형성한다. 상기 SIMD 폭이 4일 때, 상기 복수의 가중치들 중에서 4개의 가중치들이 하나의 가중치 그룹을 형성한다. 상기 SIMD 폭이 8일 때, 상기 복수의 가중치들 중에서 8개의 가중치들이 하나의 가중치 그룹을 형성한다. 상기 가중치 그룹들을 의식하여 상기 인공 신경망에 포함된 상기 복수의 가중치들을 가지치기하는 명령은 상기 가중치 그룹들 각각에서 대표 가중치를 추출하며, 상기 대표 가중치들 각각을 문턱값들 각각과 비교한다. 상기 대표 가중치들 중 어느 하나가 대응되는 문턱값보다 작을 때, 상기 대표 가중치들 중 어느 하나에 대응하 는 가중치 그룹들에 속한 가중치들 모두를 0으로 설정한다. 상기 가중치 그룹들을 의식하여 상기 인공 신경망에 포함된 상기 복수의 가중치들을 가지치기하는 명령은 상기 대표 가중치들 중 다른 하나가 대응하는 문턱값보다 클 때, 상기 대표 가중치들 중 다른 하나에 대응하는 가중 치 그룹들에 속한 가중치들 모두를 유지하도록 구현된다. 상기 인공 신경망의 입력 채널과 상기 인공 신경망의 출력 채널에서 0을 가지는 가중치들이 상기 식별된 SIMD 폭에 해당하는 만큼 연속해서 존재한다. 상기 프로세싱 엘리먼트는 가중치 레지스터를 포함한다. 상기 가중치 레지스터는 행렬로 구현된다. 상기 행렬의 행을 따라 상기 인공 신경망의 출력 채널에 배열된 가중치들이 순서대로 삽입된다. 상기 행렬의 열 을 따라 상기 인공 신경망의 입력 채널에 배열된 가중치들이 순서대로 삽입된다. 상기 명령들은 손실 함수의 기울기와, 상기 문턱값들과 관련된 상기 손실 함수의 기울기에 기초하여 상기 인공 신경망의 가중치들과, 상기 문턱값들을 업데이트하도록 구현된다."}
{"patent_id": "10-2021-0062969", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련 방법 및 시스템은 인공 신경망의 가중치들에 대해 훈련이 끝난 뒤 가속기에서 가지치기(pruning)가 수행되는 것이 아니라 인공 신경망 의 가중치들의 훈련 단계에서 가속기에 포함된 프로세싱 유닛의 SIMD(Single Instruction Multiple Data) 폭을 고려하여 가지치기(pruning)을 수행함으로써 가속기의 하드웨어 구조에 유연한 가중치들의 제공이 가능하다는 효과가 있다. 또한, 본 발명의 실시 예에 따른 인공 신경망의 가속 하드웨어를 위한 가지치기 기반의 훈련 방법 및 시스템은 인공 신경망의 입력 채널과 출력 채널에 배열된 가중치들을 그룹화하고, 가속기에 포함된 프로세싱 유닛의 SIMD 폭에 따라 그룹화된 가중치들을 훈련시킴으로써 가속기에서 연산 속도 향상과 에너지 소비 감소가 가능하다는 효과가 있다."}
{"patent_id": "10-2021-0062969", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 개시되어 있는 본 발명의 개념에 따른 실시 예들에 대해서 특정한 구조적 또는 기능적 설명들은 단 지 본 발명의 개념에 따른 실시 예들을 설명하기 위한 목적으로 예시된 것으로서, 본 발명의 개념에 따른 실시 예들은 다양한 형태들로 실시될 수 있으며 본 명세서에 설명된 실시 예들에 한정되지 않는다. 본 발명의 개념에 따른 실시 예들은 다양한 변경들을 가할 수 있고 여러 가지 형태들을 가질 수 있으므로 실시 예들을 도면에 예시하고 본 명세서에 상세하게 설명하고자 한다. 그러나, 이는 본 발명의 개념에 따른 실시 예 들을 특정한 개시 형태들에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물, 또는 대체물을 포함한다. 제1 또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용어 들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로 만, 예컨대 본 발명의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1구성요소는 제2구성요소로 명명될 수 있고, 유사하게 제2구성요소는 제1구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관 계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다.본 명세서에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 설시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 나타낸다. 일반 적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 이하, 첨부한 도면을 참조하여 본 발명의 바람직한 실시 예를 설명함으로써, 본 발명을 상세히 설명한다. 도 1은 본 발명의 실시 예에 따른 시스템의 블록도를 나타낸다. 도 2는 도 1에 도시된 프로세싱 유닛의 동작을 설명하기 위한 인공 신경망의 블록도를 나타낸다. 도 1과 도 2를 참고하면, 시스템은 연산 속도 향상과 에너지 소비 감소가 가능한 스마트 폰, 노트북, 태블 릿 PC, PC, 또는 서버와 같은 전자 장치이다. 시스템은 CPU(Central Processing Unit; 10), GPU(Graphics Processing Unit; 20), 메모리, 및 가속기를 포함한다. 도 1에 도시된 시스템은 본 발명을 설명 하기 위한 일 실시 예를 나타낸다. 실시 예에 따라 시스템은 다양하게 구현될 수 있다. 예컨대, 시스템 은 입력 장치(미도시), 또는 송수신기(transceiver; 미도시)를 더 포함할 수 있다. CPU, GPU, 메 모리, 및 가속기는 버스에 접속된다. CPU, GPU, 메모리, 및 가속기는 버스 를 통해 명령들과 데이터를 주고 받는다. CPU는 인공 신경망의 가중치들(weights)과 편향 벡터들(bias vectors)인 파라미터들을 훈련시키기 위 한 명령들을 실행한다. 실시 예에 따라 인공 신경망의 훈련은 GPU에서 수행될 수 있다. 메모리는 CPU, 또는 GPU에서 실행되는 명령들을 저장한다. 본 발명에서 프로세싱 유닛은 CPU, 또는 GPU를 의미한다. 가속기는 인공 신경망의 훈련이 끝난 뒤인 인공 신경망의 추론이 수행된다. 실시 예에 따라 가 속기는 AI 가속기로 호칭될 수 있다. 또한, 실시 예에 따라 가속기는 가속 하드웨어로 호칭될 수 있 다. 도 2를 참고하면, 인공 신경망은 입력 레이어(input layer; 105), 은닉 레이어(hidden layer; 107), 및 출력 레이어(output layer; 109)를 포함한다. 입력 레이어는 각 값(each value)을 수신한다. 입력 레이어는 각 값을 복제(duplicate)하고, 복제된 각 값을 은닉층으로 전송한다. 상기 각 값은 입력 활성화(input activations)라고 호칭될 수 있다. 메모리 는 각 값을 저장한다. 은닉 레이어는 각 값과 가중치들을 곱하고, 가중치 합(weighted sum)을 출력한다. 상기 가중치 합은 출력 활성화(output activations)라고 호칭될 수 있다. 메모리는 가중치들과 가중치 합을 저장한다. 실시 예에 따라 은닉 레이어는 가중치 합을 활성화 함수에 적용할 수 있다. 인공 신경망의 훈련 단계 에서 각 값과 가중치들의 곱은 CPU, 또는 GPU에서 수행된다. 인경 신경망의 추론 단계에서 각 값 과 가중치들의 곱은 가속기에서 수행된다. 출력 레이어는 은닉 레이어로부터 수신된 가중치 합을 활성화 함수(activation function)에 적용하여 출력 값을 생성한다. 입력 레이어, 은닉 레이어, 및 출력 레이어 각각은 노드들을 포함한다. 실시 예에 따라 입력 레 이어, 은닉 레이어, 및 출력 레이어의 노드들의 수와, 은닉 레이어의 레이어 수는 다양할 수 있다. 입력 레이어, 은닉 레이어, 및 출력 레이어의 노드들의 수와, 은닉 레이어의 레 이어 수의 증가함에 따라 인공 신경망의 사이즈는 증가한다. 인공 신경망의 사이즈의 증가는 에너지 소비 증가와 병목 현상을 유발한다. 따라서 인공 신경망의 훈련 단계에서 에너지 효율성과 연산 속도 증가 를 위해 인공 신경망를 감소시킬 필요가 있다. 또한, 인공 신경망의 각 값과 가중치들의 수가 증가함에 따라 메모리에서 필요한 저장 공간은 증가한다. 따라서 인공 신경망의 훈련 단계에서 메모리의 저장 공간의 절약이 필요하다. 도 3은 도 2에 도시된 인공 신경망의 은닉 레이어(hidden layer)의 입력 활성화(input activations)와 가중치 (weights)를 나타낸다. 도 2와 도 3을 참고하면, 입력 활성화는 인공 신경망에서 사용되는 데이터 구조인 3D 텐서(tensor)로 표현 될 수 있다. 입력 활성화의 3D 텐서는 H x W x C 행렬로 표현될 수 있다. 가중치는 4D 텐서로 표현될 수 있다. 가중치의 4D 텐서는 R x S x C x K 행렬로 표현될 수 있다. 가중치의 4D 텐서에서 'C'는 입력 채널을 나타낸다. 가중치의 4D 텐서에서 'K'는 출력 채널을 나타낸다. 출력 활성화는 3D 텐서로 표현될 수 있다. 출력 활성화의 3D 텐서는 P x Q x K 행렬로 표현될 수 있다. 출력 활 성화는 입력 활성화와 가중치를 곱하고 누산(accumulate)함으로써 생성된다. 도 4는 도 3에 도시된 4D 가중치 텐서(tensor)와 2D 가중치 행렬을 나타낸다. 도 4를 참고하면, 4D 가중치 텐서는 도 3에 도시된 4D 가중치 텐서와 대응된다. 가중치들은 4D 텐서의 행렬에 배열된다. 예컨대, 계수 W(1,1,1,1), W(1,1,2,1), 및 W(1,1,3,1)는 R x S x 1 x 1 행렬의 첫 번째 행에 배열된다. 계수 W(1,1,1,1)에서 첫 번째 1은 첫 번째 출력 채널을, 두 번째 1은 첫 번째 입력 채널을, 세 번째 1은 첫 번째 열을, 네 번째 1은 첫 번째 행을 나타낸다. 이는 본 발명의 실시 예를 설명하기 위해 정의된 것으로, 실시 예에 따라 계수의 좌표는 다양하게 정의될 수 있다. 계수 W(1,2,1,1), W(1,2,2,1), 및 W(1,2,3,1)은 R x S x 2 x 1 행렬의 첫 번째 행에 배열된다. 계수 W(1,C,1,1), W(1,C,2,1), 및 W(1,C,3,1)은 R x S x C x 1 행렬의 첫 번째 행에 배열된다. C는 입력 채널의 수를 의미한다. 계수 W(K,1,1,1), W(K,1,2,1), 및 W(K,1,3,1)는 R x S x C x K 행렬의 첫 번째 행에 배열된다. K 는 출력 채널의 수를 의미한다. 도 1과 도 4를 참고하면, CPU, 또는 GPU는 4D 가중치 텐서의 입력 채널과 출력 채널을 고려하여 4D 가 중치 텐서를 복수의 2D 가중치 행렬들로 변환한다. 구체적으로, CPU, 또는 GPU는 4D 텐서에서 입력 채 널 방향으로 배열된 가중치들은 2D 가중치 행렬에서 열 방향으로 순서대로 입력하도록 4D 가중치 텐서를 2D 가 중치 행렬로 변환한다. 도 4에서 4D 텐서에서 입력 채널 방향으로 배열된 가중치들 W(1,1,1,1), W(1,2,1,1), W(1,3,1,1),..., 및 W(1,C,1,1)은 2D 가중치 행렬에서 첫 번째 열(C1)에 배열된다. 도 4에서 4D 텐서에서 입력 채널 방향으로 배열된 가중치들 W(2,1,1,1), W(2,2,1,1), W(2,3,1,1),..., 및 W(2,C,1,1)은 2D 가중치 행렬에서 두 번째 열(C2)에 배열된다. 또한, CPU, 또는 GPU는 4D 텐서에서 출력 채널 방향으로 배열된 가중치들은 2D 가중치 행렬에서 행 방 향으로 순서대로 입력하도록 4D 가중치 텐서를 2D 가중치 행렬로 변환한다. 도 4에서 4D 텐서에서 출력 채널 방 향으로 배열된 가중치들 W(1,1,1,1), W(2,1,1,1), ..., 및 W(K,1,1,1)은 2D 가중치 행렬에서 첫 번째 행(R1)에 배열된다. 도 4에서 4D 텐서에서 출력 채널 방향으로 배열된 가중치들 W(1,2,1,1), W(2,2,1,1), ..., 및 W(K,2,1,1)은 2D 가중치 행 렬에서 두 번째 행(R2)에 배열된다. R x S x C x K 행렬의 4D 텐서에서 같은 입력 채널과 같은 출력 채널에 위치한 각 가중치들은 서로 다른 2D 가 중치 행렬들에 속한다. 예컨대, 가중치 W(1,1,1,1)은 첫 번째 2D 가중치 행렬에 속하며, 가중치 W(1,1,2,1)은 두 번째 2D 가중치 행렬에 속한다. 도 5는 도 1에 도시된 가속기의 블록도를 나타낸다. 도 1과 도 5를 참고하면, 가속기는 컨트롤러, 입력 활성화 버퍼, 가중치 버퍼, 출력 버퍼 , 제1레지스터, 제2레지스터, 복수의 프로세싱 엘리먼트들(processing elements; 270), 및 누 산기(accumulator; 280)를 포함한다. 컨트롤러는 CPU, 또는 GPU로부터 가속기의 동작을 실행시키기 위한 명령들을 수신한다. 예컨 대, 상기 명령들은 로드(load) 명령, 곱셈 명령, 합산 명령, 및 저장 명령을 포함할 수 있다. 컨트롤러가 상기 로드 명령을 수신할 때, 컨트롤러는 제1레지스터에 저장된 입력 활성화들, 또는 제2레지스터 에 저장된 가중치들을 복수의 프로세싱 엘리먼트들에 로드(load)하기 위해 제1레지스터, 또는 제2레지스터를 제어한다. 컨트롤러는 CPU, 또는 GPU로부터 수신된 명령들에 따라 가속기의 각 구성요소들(220, 230, 240, 250, 260, 270, 및 280)의 동작들을 제어한다. 입력 활성화 버퍼는 메모리로부터 입력 활성화들을 수신하여 저장한다. 가중치 버퍼는 메모리 로부터 가중치들을 수신하여 저장한다. 출력 버퍼는 누산기로부터 출력되는 결과 값을 저장하고, 결과 값을 CPU, GPU, 또는 메모리 로 전송한다. 제1레지스터는 입력 활성화 버퍼로부터 입력 활성화들을 수신하고 저장한다. 제2레지스터는 가 중치 버퍼로부터 가중치들을 수신하고 저장한다. 제1레지스터와 제2레지스터는 FIFO(First In First Out) 레지스터일 수 있다. 복수의 프로세싱 엘리먼트들 각각은 제1레지스터로부터 수신된 입력 활성화들과 제2레지스터로 부터 수신된 가중치들을 곱하는 곱셈 연산을 수행한다. 복수의 프로세싱 엘리먼트들에서 부분 합들이 출력 될 수 있다. 복수의 프로세싱 엘리먼트들은 프로세싱 엘리먼트 어레이로 호칭될 수 있다. 누산기는 복수의 프로세싱 엘리먼트들로부터 출력되는 부분 합들을 저장하고, 부분 합들을 더하여 곱 셈 가중치 합(weighted sum)을 업데이트한다. 실시 예에 따라 가속기의 구조는 다양하게 구현될 수 있다. 도 6은 도 5에 도시된 프로세싱 엘리먼트(processing element)의 내부 블록도를 나타낸다. 도 5와 도 6을 참고하면, 복수의 프로세싱 엘리먼트들은 모두 같은 구조를 가진다. 도 6에 대표적으로 복 수의 프로세싱 엘리먼트들 중 어느 하나의 프로세싱 엘리먼트가 도시된다. 프로세싱 엘리먼트는 가중치 레지스터, 입력 활성화 레지스터, 복수의 곱셈기들, 및 가산 기를 포함한다. 가중치 레지스터는 제2레지스터로부터 가중치들을 전송받는다. 가중치 레지스터는 가중치들을 저장하기 위한 행렬(MX)로 구현된다. SIMD 폭이 8일 때, 행렬(MX)의 폭은 8일 수 있다. 행렬(MX)의 높이는 8보다 크며, 16보다 작을 수 있다. 즉, 행 렬(MX)의 가로에는 8개의 가중치들이 배열되며, 행렬(MX)의 세로에는 가중치들이 8개 이상 배열될 수 있다. 도 4와 도 6을 참고하면, CPU, 또는 GPU에 의해 가중치의 4D 텐서의 입력 채널과 출력 채널을 고려하여 가중치의 4D 텐서가 2D 가중치 행렬로 변환된다. 변환된 2D 가중치 행렬에서 가중치들이 가중치의 입력 채널과 출력 채널을 고려하여 배열된다. CPU, 또는 GPU는 가속기에 포함된 프로세싱 엘리먼트의 SIMD(Single Instruction Multiple Data) 폭(width)을 식별한다. 예컨대, 가속기에 포함된 프로세싱 엘리먼트의 SIMD 폭이 2일 때, CPU, 또는 GPU는 가속기에 포함된 프로세싱 엘리먼트의 SIMD 폭 2를 식별할 수 있다. 가속기 에 포함된 프로세싱 엘리먼트의 SIMD 폭이 4일 때, CPU, 또는 GPU는 가속기에 포함된 프로세싱 엘리먼트의 SIMD 폭 4를 식별할 수 있다. CPU, 또는 GPU는 상기 식별된 SIMD 폭에 따라 인공 신경망의 입력 채널과 출력 채널에 배열된 가 중치들을 가중치 그룹들로 그룹화한다. 인공 신경망의 입력 채널은 도 4에 도시된 'C'를 의미하며, 인공 신경망의 출력 채널은 도 4에 도시된 'K'를 의미한다. CPU, 또는 GPU는 상기 식별된 SIMD 폭에 따라 변환된 2D 가중치 행렬에서 인공 신경망의 입력 채 널과 출력 채널에 배열된 가중치들을 가중치 그룹들로 그룹화한다. 예컨대, SIMD 폭이 2일 때, 2개의 가중치들 이 하나의 그룹을 형성한다. SIMD 폭이 4일 때, 4개의 가중치들이 하나의 그룹을 형성한다. SIMD 폭이 8일 때, 가중치들은 8로 나뉠 수 있다. 변환된 2D 가중치 행렬의 행에는 출력 채널의 순서대로 가중 치들이 배열된다. 도 6에서 가중치 그룹(GH1)은 8개의 가중치들(W(1,1,1,1), W(2,1,1,1),..., 및 W(8,1,1,1))을 포함할 수 있다. 가중치 그룹(GH2)은 8개의 가중치들(W(9,1,1,1), W(10,1,1,1),..., 및 W(16,1,1,1))을 포함할 수 있다. 가중치 그룹(GH3)은 8개의 가중치들(W(17,1,1,1), W(18,1,1,1),..., 및 W(24,1,1,1))을 포함할 수 있다. 변환된 2D 가중치 행렬의 열에는 입력 채널의 순서대로 가중치들이 배열된다. 가중치 그룹(GV1)은 8개의 가중치 들(W(1,1,1,1), W(1,2,1,1),..., 및 W(1,8,1,1))을 포함할 수 있다. 가중치 그룹(GV2)은 8개의 가중치들(W(1,9,1,1), W(1,10,1,1),..., 및 W(1,16,1,1))을 포함할 수 있다. 가중치 그룹(GV3)은 8개의 가중치들(W(1,17,1,1), W(1,18,1,1),..., 및 W(1,24,1,1))을 포함할 수 있다. CPU, 또는 GPU의 제어 하에 그룹화된 가중치들이 입력 채널과 출력 채널을 고려하여 가중치 레지스터 에 포함된 행렬(MX)에 저장된다. 예컨대, 행렬(MX)의 첫 번째 행(R1)에는 가중치들(W(1,1,1,1), W(2,1,1,1),..., 및 W(8,1,1,1))을 포함하는 가중치 그룹(GH1)이 저장된다. 행렬(MX)의 첫 번째 열(C1)에는 가중치(W(1,1,1,1), W(1,2,1,1),..., 및 W(1,8,1,1))을 포함하는 가중치 그룹(GV1)이 저장된다. 그룹화된 가중치들을 입력 채널과 출력 채 널을 고려하여 가중치 레지스터에 포함된 행렬(MX)에 저장함으로써, 종래보다 더 많은 가중치들이 가중치 레지스터에 저장될 수 있다. 종래보다 더 많은 가중치들이 가중치 레지스터에 저장됨으로써 한 번에 더 많은 부분 합 연산이 가능하다. 즉, 연산 속도가 향상될 수 있다. 행렬(MX)의 행을 따라 인공 신경망의 출력 채널(K)에 배열된 가중치들(W(1,1,1,1), W(2,1,1,1),..., 및 W(8,1,1, 1))이 순서대로 삽입된다. 삽입되는 가중치들(W(1,1,1,1), W(2,1,1,1),..., 및 W(8,1,1,1))의 수는 SIMD 폭과 같다. 행렬(MX)의 열을 따라 인공 신경망의 입력 채널(C)에 배열된 가중치들(W(1,1,1,1), W(1,2,1,1), ... , 및 W(1,8,1,1))이 순서대로 삽입된다. 삽입되는 가중치들(W(1,1,1,1), W(1,2,1,1), ... , 및 W(1,8,1,1))의 수는 SIMD 폭과 같다. 가속기의 SIMD 폭에 따라 인공 신경망의 입력 채널(C)과 출력 채널(K)에 배열된 가중치들을 그 룹화하여 가중치 레지스터에 저장함으로써 가속기에서 연산 속도 향상과 에너지 소비 감소가 달성될 수 있다. 입력 활성화 레지스터는 입력 활성화들이 저장된다. 복수의 곱셈기들 각각은 가중치 레지스터로부터 출력되는 가중치와 입력 활성화 레지스터로부터 출력되는 입력 활성화를 곱한다. SIMD 폭이 8일 때, 복수의 곱셈기들은 8개이다. 한 번의 명령에 따라 8번 의 곱셈이 동시에 수행된다. 실시 예에 따라 복수의 곱셈기들의 수는 다양할 수 있다. 복수의 곱셈기들로 부터 출력되는 값들은 가산기로 입력된다. 가산기는 부분 합을 생성한다. 가산기에 의해 생성되 는 부분 합은 가중치 레지스터에 포함된 행렬(MX)에 저장될 수 있다. 도 7은 도 1에 도시된 시스템의 동작 방법을 설명하기 위한 흐름도를 나타낸다. 구체적으로 도 7은 도 2에 도시 된 인공 신경망의 훈련 방법을 설명하기 위한 흐름도이다. 도 1 내지 도 7을 참고하면, 프로세싱 유닛은 가속기에 포함된 프로세싱 엘리먼트의 SIMD 폭을 식별 한다(S100). 상기 프로세싱 유닛은 CPU, 또는 GPU이다. 가속기에 포함된 프로세싱 엘리먼트 의 SIMD 폭이 8일 때, 상기 프로세싱 유닛은 가속기에 접근하여 SIMD 폭 8을 식별할 수 있다. 상기 프로세싱 유닛은 인공 신경망의 가중치들을 초기화한다(S200). 상기 복수의 가중치들은 임의로 초기 화될 수 있다. 또한, 실시 예에 따라 상기 복수의 가중치들은 다른 인공 신경망을 통해 얻어진 미리 결정된 값 들로 초기화될 수 있다. 상기 프로세싱 유닛은 상기 식별된 SIMD 폭에 따라 인공 신경망의 입력 채널과 출력 채널에 배열된 가중치 들을 가중치 그룹들로 그룹화한다(S300). 즉, 상기 프로세싱 유닛은 상기 식별된 SIMD 폭에 따라 인공 신경망 의 입력 채널과 출력 채널에 배열된 가중치들을 가중치 그룹들로 나눈다. 인공 신경망의 입력 채널은 도 3에서 'C'로 표현된다. 인공 신경망의 출력 채널은 도 3에서 'K'로 표현된다. 인공 신경망의 입력 채널에 배열된 가중치들이란 도 4에서 입력 채널(C)을 따라 순차적으로 배열된 가중치들(W(1,1,1,1), W(1,2,1,1),..., 및 W(1,C,1,1))을 의미한다. 인공 신경망의 출력 채널에 배열된 가중치들이란 도 4에서 출력 채널(K)을 따라 순차적으로 배열된 가중치들(W(1,1,1,1), W(2,1,1,1), ..., 및 W(K,1,1,1))을 의미한다. SIMD 폭이 2일 때, 2개의 가중치 들이 하나의 그룹을 형성한다. SIMD 폭이 4일 때, 4개의 가중치들이 하나의 그룹을 형성한다. SIMD 폭이 8일 때, 8개의 가중치들(예컨대, (W(1,1,1,1), W(1,2,1,1),..., 및 W(1,8,1,1))이 하나의 그룹을 형성한다. 상기 식별된 SIMD 폭에 따라 인공 신경망의 입력 채널과 출력 채널에 배열된 가중치들을 그룹화하기 위해 상기 프로세싱 유닛은 4D 가중치 텐서의 입력 채널과 출력 채널을 고려하여 4D 가중치 텐서를 복수의 2D 가중치 행렬들로 변환할 수 있다. 구체적으로, 상기 프로세싱 유닛은 4D 텐서에서 입력 채널 방향으로 배열된 가중치들 은 2D 가중치 행렬에서 열 방향으로 순서대로 입력하도록 4D 가중치 텐서를 2D 가중치 행렬로 변환할 수 있다. 또한, 상기 프로세싱 유닛은 4D 가중치 텐서에서 출력 채널 방향으로 배열된 가중치들은 2D 가중치 행렬에서 행 방향으로 순서대로 입력하도록 4D 가중치 텐서를 2D 가중치 행렬로 변환한다. 상기 프로세싱 유닛은 상기 변환된 복수의 2D 가중치 행렬들에서 상기 SIMD 폭에 따라 상기 가중치들을 가중치 그룹들로 그룹화할 수 있다. 예컨대, SIMD 폭이 8이라 가정할 때, 상기 프로세싱 유닛은 상기 변환된 복수의 2D 가중치 행렬들 중 어느 하나에서 행에 입력된 8개의 가중치들(W(1,1,1,1), W(1,2,1,1),..., 및 W(1,8,1,1))을 하나의 가중 치 그룹으로 형성 수 있다. 또한, 상기 프로세싱 유닛은 상기 변환된 복수의 2D 가중치 행렬들 중 어느 하나에 서 열에 입력된 8개의 가중치들(W(1,1,1,1), W(1,2,1,1),..., 및 W(1,8,1,1))을 하나의 가중치 그룹으로 형성할 수 있다. 이와 유사한 방법으로 2D 가중치 행렬들에 배열된 가중치들이 그룹화된다. 상기 프로세싱 유닛은 상기 그룹화된 가중치들을 의식(aware)하여 인공 신경망에 포함된 상기 복수의 가중 치들을 가지치기(pruning)한다(S400). 의식한다함은 가지치기 동작을 수행함에 있어서 상기 그룹화된 가중치들 을 고려한다는 것을 의미한다. 가지치기는 인공 신경망에서 중요하지 않은 가중치들을 제거함으로써 인공 신경망의 연결들의 수를 줄이는 것을 목표로 한다. 인공 신경망의 가중치들을 0으로 설정함으로써 중요하지 않은 연결들이 제거될 수 있다. 가지치기의 구체적인 동작은 아래와 같다. 상기 프로세싱 유닛은 상기 그룹화된 가중치들 각각에서 대표 가중치들 각각을 추출한다. 상기 대표 가중치 각각은 상기 그룹화된 가중치들 중에서 임의로 추출될 수 있다. 예컨대, 상기 그룹화된 가중 치들(W(1,1,1,1), W(1,2,1,1),..., 및 W(1,8,1,1))에서 임의로 가중치(W(1,1,1,1))가 대표 가중치로 추출될 수 있다. 또한, 실시 예에 따라 상기 그룹화된 가중치들(W(1,1,1,1), W(1,2,1,1),..., 및 W(1,8,1,1))의 RMS(Root Mean Square)를 계산하고 RMS 값이 대표 가중치로 추출될 수 있다. 또한, 실시 예에 따라 상기 그룹화된 가중치들(W(1,1,1,1), W(1,2,1,1),..., 및 W(1,8,1,1))의 평균을 계산하고 평균 값이 대표 가중치로 추출될 수 있다. 또한, 실시 예에 따라 상기 그룹화된 가중치들(W(1,1,1,1), W(1,2,1,1),..., 및 W(1,8,1,1))의 최소 값(예컨대, W(1,2,1,1)), 또는 최대 값(예컨대, W(1,8,1,1))이 대표 가중치로 추출될 수 있다. 상기 프로세싱 유닛은 상기 대표 가중치들 각각을 문턱값들 각각과 비교한다. 상기 문턱값들 각각은 임의로 설 정될 수 있다. 상기 대표 가중치들 중 어느 하나가 대응되는 문턱값보다 작을 때, 상기 프로세싱 유닛은 상기 그룹화된 가중치 들 전부를 제거하기 위해 상기 그룹화된 가중치들 전부를 0으로 설정한다. 예컨대, 상기 그룹화된 가중치들 (W(1,1,1,1), W(1,2,1,1),..., 및 W(1,8,1,1))이 모두 0으로 설정될 수 있다. 상기 0으로 설정은 가중치 행렬과 희소 행 렬(sparse matrix)의 곱으로 설정될 수 있다. 희소 행렬은 많은 0의 값들을 포함하는 행렬이다. 따라서 인공 신 경망의 입력 채널(C)과 상기 인공 신경망의 출력 채널(K)에서 0을 가지는 가중치들(예컨대, W(1,1,1,1), W(1,2,1,1),..., 및 W(1,8,1,1))이 상기 식별된 SIMD 폭(예컨대, 8)에 해당하는 만큼 연속해서 존재할 수 있다. 또한, 프로세싱 엘리먼트에 구현된 행렬(MX)에서 임의의 하나의 행에 배열된 가중치들의 값들이 전부 0이거나, 임의의 하나의 열에 배열된 가중치들의 값들이 전부 0일 수 있다. 0의 개수는 SIMD 폭만큼 존재한다. 예컨대, SIMD 폭이 8일 때, 0의 개수는 0이다. 실시 예에 따라 프로세싱 엘리먼트에 구현된 행렬(MX)에서 0을 가지 는 가중치들(예컨대, W(1,1,1,1), W(1,2,1,1),..., 및 W(1,8,1,1))은 제외될 수 있다. 즉, 프로세싱 엘리먼트에 구 현된 행렬(MX)에서 0을 가지는 가중치들(예컨대, W(1,1,1,1), W(1,2,1,1),..., 및 W(1,8,1,1))은 발견되지 않을 수 있다. 반대로, 상기 대표 가중치들 중 다른 하나가 대응되는 문턱값보다 클 때, 상기 프로세싱 유닛은 상기 그룹화된 가중치들 전부(예컨대, W(1,1,1,1), W(2,1,1,1), ..., 및 W(8,1,1,1))를 유지한다. 유지한다함은 상기 그룹화된 가중치들전부(예컨대, W(1,1,1,1), W(2,1,1,1), ..., 및 W(8,1,1,1))를 변경하지 않는다는 것을 의미한다. 즉, 가중치 행렬과 희 소 행렬의 곱셈 동작은 수행되지 않는다. 상기 프로세싱 유닛은 상기 가지치기된 복수의 가중치들을 업데이트한다(S500). 0이 아닌 가중치들은 업데이트 된다. 도 2를 참고하면, CPU, 또는 GPU와 같은 프로세싱 유닛은 인공 신경망을 통해 훈련 데이터 (training data)로부터 활성화 데이터를 프로파게이팅(propagating)한다. 즉, 상기 프로세싱 유닛은 입력 레이 어에 훈련 데이터를 입력하고, 은닉 레이어와 출력 레이어를 통해 활성화 데이터를 출력한다. 상기 프로세싱 유닛은 상기 활성화 데이터와 목표 데이터에 기초하여 손실 함수(loss function)의 값을 계산한 다. 상기 손실 함수의 값은 상기 활성화 데이터와 목표 데이터 사이의 MSE(Means Squared Error), 또는 크로스- 엔트로피(cross-entropy)를 이용하여 계산될 수 있다. 상기 프로세싱 유닛은 인공 신경망의 가중치들과 관련된 상기 손실 함수(loss function)의 기울기 (gradient)와, 문턱값들(Threshold)과 관련된 상기 손실 함수의 기울기를 계산하기 위해 상기 손실 함수의 값을 백프로파게이팅(backpropagating)한다. 백프로파게이션 동작은 인공 신경망의 가중치들과 관련된 상기 손 실 함수(loss function)의 기울기(gradient)와, 문턱값들(Threshold)과 관련된 상기 손실 함수의 기울기를 계 산하는 동작을 포함한다. 상기 백프로파게이션은 상기 가중치들과 문턱값들을 조절하여 상기 손실 함수의 값을 최소화를 목표로 한다. 상기 가중치들과 관련된 상기 손실 함수는 상기 가중치들의 변화에 따른 상기 손실 함수의 값의 변화를 의미한 다. 상기 문턱값들과 관련된 상기 손실 함수는 상기 문턱값들의 변화에 따른 손실 함수의 값의 변화를 의미한다. 상기 프로세싱 유닛은 인공 신경망의 가중치들과 관련된 상기 손실 함수의 기울기와, 상기 문턱 값들과 관련된 상기 손실 함수의 기울기에 따라 인공 신경망의 가중치들과, 상기 문턱값들을 업데이트한다. 상기 문턱값들의 업데이트에 따라 특정 가중치 그룹들이 모두 0으로 재설정되거나, 0으로 설정이 취소될 수 있다. 상기 프로세싱 유닛은 인공 신경망의 오버피팅(overfitting)을 피하기 위해 인공 신경망에 대해 구조 화된 희소 정규화(structured sparisty regularization)를 수행한다. 구조화된 희소 정규화란 가중치 그룹들을 고려하여 정규화 동작을 수행함을 의미한다. 상기 문턱값들의 업데이트 동작은 구조화된 회소 정규화를 수행하 는 과정에서 수행된다. 상기 구조화된 희소 정규화의 최적화 목표(optimization target)는 다음의 수학식과 같 이 표현될 수 있다. [수학식 1]"}
{"patent_id": "10-2021-0062969", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상기 는 최적화 목표를, 상기 는 문턱값을, 상기 는 가중치들을, 상기 는 분류 손 실(classification loss)을, 상기 는 어느 하나의 그룹에 속한 가중치들을 얼마나 패널티를 주기 위해 (penalize) 결정하는 페널티 텀(penalty term), 혹은 정규화 파라미터(regularization parameter)를, 상기 는 구조화된 희소 정규화 텀(structured sparisty regularization term을 의미한다. 상기 N 은 콘볼루션 층들(convolution layers)의 수를 의미하며, 상기 n은 가중치 텐서의 순서를 의미한다. 구체적으로 는 L1 규범(norm) 또는 L2 규범(norm)일 수 있다. 상기 분류 손실( )은 최종 손실(overall loss)을 최소화하기 위해 업데이트된다. 상기 구조화된 희 소 정규화 텀( )은 손실을 최소화하는 방향으로 학습된다. 상기 문턱값( )은 희소화 (sparsity)를 증가시키는 방향으로 업데이트된다. 상기 가중치 그룹들은 SIMD 폭을 고려하여 인공 신경망의 입력 채널(C)과 출력 채널(K)에 배열된 가중치들 이 그룹화된 그룹들이다. 상기 구조화된 희소 정규화를 통해 중요하지 않은 가중치 그룹들을 제거하기 위해 상 기 중요하지 않은 가중치 그룹들이 0으로 설정된다. 본 발명에서는 SIMD 폭을 고려하여 인공 신경망의 입력 채널(C)과 출력 채널(K)에 배열된 가중치들을 그룹 화하고, 그룹화된 가중치들을 의식하여 인공 신경망에 포함된 복수의 가중치들을 가지치기함으로써 가속기 에서 연산 속도 향상과 에너지 소비 감소가 가능하다. 가속기의 프로세싱 엘리먼트에서 입력 활 성화들과 가중치들의 곱셈 연산이 수행된다. 가속기의 프로세싱 엘리먼트에서 곱셈 연산을 고려하여 인공 신경망의 가중치들을 가지치기함으로써 연산 속도 향상과 에너지 소비 감소가 가능하다. 연속해서 0 인 가중치들을 한꺼번에 계산하도록 함으로써 연산 속도 향상과 에너지 소비 감소가 가능하다. 또한, 연속해서 0인 가중치들을 계산하지 않도록 함으로써 연산 속도 향상과 에너지 소비 감소가 가능하다. 가속기의 하드 웨어 구조인 SIMD 폭을 고려하여 가지치기함으로써 연산 속도 향상과 에너지 소비 감소가 가능하다. 또한, 가속 기의 하드웨어 구조인 SIMD 폭을 고려하여 가지치기함으로써 가속기의 하드웨어 구조에 유연한 가중 치들의 제공이 가능하다. 종래기술은 가속기의 하드웨어 구조에 종속적인 가중치들을 설정함으로써 가속기 의 하드웨어 구조가 변경되는 경우, 인공 신경망의 파라미터들이 최적화될 수 없는 문제점이 있었다. 하지만, 본 발명의 경우 SIMD 폭을 고려하여 인공 신경망의 파라미터들을 설정함으로써 가속기의 하 드웨어 구조가 변경되더라도 유연하게 인공 신경망의 파라미터들의 변경이 가능하다는 장점이 있다. 또한, 인공 신경망의 훈련 단계에서 메모리의 저장 공간의 절약이 가능하다. 가중치들을 그룹으로 나누어 가지치기를 하게 되면 추론의 정확도가 떨어질 수 있다. 또한, 가중치들을 그룹으 로 나누지 않고 가지치기를 하게 되면 가지치기의 성능이 떨어진다. 본 발명에서는 SIMD 폭을 고려하여 인공 신 경망의 입력 채널(C)과 출력 채널(K)에 배열된 가중치들을 그룹화하고, 그룹화된 가중치들을 의식하여 인 공 신경망에 포함된 복수의 가중치들을 가지치기함으로써 정확도를 유지하고, 성능을 높일 수 있다. 또한, 본 발명에서는 인공 신경망의 입력 채널(C)과 출력 채널(K)까지 고려하여 가지치기를 함으로써 추론의 정 확도를 유지할 수 있다. 도 8은 도 5에 도시된 프로세싱 엘리먼트의 다른 내부 블록도를 나타낸다. 도 1, 도 5, 및 도 8을 참고하면, 복수의 프로세싱 엘리먼트들은 모두 같은 구조를 가진다. 도 5에 대표적 으로 복수의 프로세싱 엘리먼트들 중 어느 하나의 프로세싱 엘리먼트가 도시된다. 프로세싱 엘리먼트는 가중치 레지스터, 입력 활성화 레지스터, 복수의 곱셈기들, 및 가산 기를 포함한다. 가중치 레지스터는 제2레지스터로부터 가중치들(예컨대, W11~W44)을 전송받는다. 가중치 레지스터 는 가중치들을 저장하기 위한 행렬(MX)로 구현된다. 도 8에서 4개의 가중치들(W11~W14, W21~W24, W31~W34, 또 는 W41~W44)이 하나의 가중치 그룹(G1, G2, G3, 또는 G4)을 형성한다. 각 가중치 그룹들(G1~G4)은 행렬(MX)에서 각 행에 배열된다. 프로세싱 유닛은 가중치 그룹들(G1~G4)에서 대표 가중치들을 추출한다. 상기 프로세싱 유닛은 대표 가중치들 각 각을 가지치기 마스크들의 문턱값들 각각과 비교한다. 상기 프로세싱 유닛은 상기 비교에 따라 가중치 그룹들 (G1~G4) 중 특정 그룹(예컨대, G2, 또는 G3)에 속한 가중치들(W21~W24, 또는 W31~W34)을 모두 0으로 설정할 수 있 다. 입력 활성화 레지스터는 제1레지스터로부터 입력 활성화들(예컨대, a11~a41)을 전송받는다. 입력 활성 화들(a11~a41)은 행렬로 구현된다. 복수의 곱셈기들 각각은 가중치 레지스터로부터 출력되는 가중치들과 입력 활성화 레지스터로부 터 출력되는 입력 활성화들을 곱한다. 예컨대, 첫 번째 사이클에서 곱셈기는 가중치 레지스터에서 제 1가중치 그룹(G1)에 포함된 가중치들(W11~W14)과 입력 활성화 레지스터에서 제1열(CL1)에 포함된 입력 활성 화들(a11~a14)을 곱한다. 곱셈기는 가중치(W11)와 입력 활성화(a11)를 곱한다. 곱셈기는 가중치(W12)와 입력 활성화(a12)를 곱한다. 가산기는 부분 합(partial sum)을 생성한다. 두 번째 사이클에서 곱셈기는 가중치 레지스터에서 제2가중치 그룹(G2)에 포함된 가중치들(W21~W24)과 입력 활성화 레지스터에서 제2열(CL2)에 포함된 입력 활성화들(a21~a24)을 곱한다. 가산기는 부분 합 을 생성한다. 세 번째 사이클에서 곱셈기는 가중치 레지스터에서 제3가중치 그룹(G3)에 포함된 가중치들(W31~W34)과 입력 활성화 레지스터에서 제3열(CL3)에 포함된 입력 활성화들(a31~a34)을 곱한다. 가산기는 부분 합 을 생성한다. 네 번째 사이클에서 곱셈기는 가중치 레지스터에서 제4가중치 그룹(G4)에 포함된 가중치들(W41~W44)과 입력 활성화 레지스터에서 제4열(CL4)에 포함된 입력 활성화들(a41~a44)을 곱한다. 가산기는 부분 합 을 생성한다. 만약, 가중치 레지스터에서 가중치 그룹들(G1~G4) 중 특정 가중치 그룹(G2, 또는 G3)이 0으로 설정된 제로 그룹이라 가정할 때, 가중치들(W21~W24)과 입력 활성화들(a21~a24)의 곱의 연산, 또는 가중치들(W31~W34)과 입력 활 성화들(a31~a34)의 곱의 연산은 스킵(skip)될 수 있다. 이는 가속기의 연산 속도 향상으로 이어진다. 도 9는 도 5에 도시된 복수의 프로세싱 엘리먼트들의 내부 블록도를 나타낸다. 도 9에서는 설명의 편의를 위해 프로세싱 엘리먼트들 중 일부 프로세싱 엘리먼트들만이 도시된다. 또한, 도 9에서는 설명의 편의를 위해 프로세 싱 엘리먼트에서 가중치 레지스터만이 도시된다. 도 9(a)는 로드 밸런싱 동작이 적용되기 전의 복수의 프로세싱 엘리먼트들의 내부 블록도를 나타낸다. 도 9(b)는 로드 밸런싱 동작 적용 후의 복수의 프로세싱 엘리먼트들의 내부 블록도를 나타낸다. 도 1 내지 도 9(a)를 참고하면, 프로세싱 엘리먼트들(270-1~270-3)은 가중치 레지스터들(271-1~271-3)을 포함한 다. 가중치 레지스터들(271-1~271-3)에서 해시(hash) 블록은 제로(zero) 그룹을 의미한다. 즉, 제로 그룹에 포 함된 가중치들은 모두 0이다. 가중치 레지스터들(271-1~271-3)에서 빈(blank) 블록은 제로가 아닌 그룹을 의미 한다. 실시 예에 따라 하나의 그룹을 형성하는 가중치들의 수는 다양할 수 있다. 예컨대, 4개의 가중치들이 하 나의 가중치 그룹을 형성할 수 있다. 컨트롤러의 제어 하에 프로세싱 엘리먼트들은 곱셈 명령을 수행한다. 제1프로세싱 엘리먼트(270-1)는 상기 곱셈 명령에 따라 제1가중치 그룹(G1)에 속한 가중치들과 입력 활성화들을 곱한다. 다만, 제1가중치 그룹 (G1)은 제로 그룹이므로, 제1가중치 그룹(G1)에 속한 가중치들과 입력 활성화들을 곱하는 곱셈 동작은 스킵된다. 동시에 제2프로세싱 엘리먼트(270-2)는 상기 곱셈 명령에 따라 제1가중치 그룹(G1)에 속한 가중치들 과 입력 활성화들을 곱한다. 그리고, 제2프로세싱 엘리먼트(270-2)는 부분 합을 생성한다. 또한, 제3프로세싱 엘리먼트(270-3)도 상기 곱셈 명령에 따라 제1가중치 그룹(G1)에 속한 가중치들과 입력 활성화들을 곱한다. 그 리고, 제3프로세싱 엘리먼트(270-3)는 부분 합을 생성한다. 제1가중치 그룹(G1)에 대한 곱셈 동작이 끝난 후, 프로세싱 엘리먼트들(270-1~270-3)은 나머지 가중치 그룹들 (G2~G8)에 대해서도 순차적으로 곱셈 명령을 수행한다. 제1프로세싱 엘리먼트(270-1)의 가중치 레지스터(271-1)에서 제1가중치 그룹(G1), 제3가중치 그룹(G3), 제5가중 치 그룹(G5), 및 제6가중치 그룹(G6)이 제로 그룹들이라 가정한다. 가중치 레지스터(271-1)에서 제로 그룹들이 많을수록 가속기의 연산 속도가 향상될 수 있다. 왜냐하면 제로 그룹에서 가중치들과 입력 활성화들의 곱 의 연산이 스킵될 수 있기 때문이다. 제2프로세싱 엘리먼트(270-2)의 가중치 레지스터(271-2)에서 제3가중치 그룹(G3)과 제5가중치 그룹(G5)이 제로 그룹들이라 가정한다. 제3프로세싱 엘리먼트(270-3)의 가중치 레지스터(271-3)에서 제6가중치 그룹(G6)이 제로 그룹이라 가정한다. 제1프로세싱 엘리먼트(270-1)는 다른 프로세싱 엘리먼트들(270-2과 270-3)보다 더 많은 제로 그룹들을 포함하고 있다. 따라서 제1프로세싱 엘리먼트(270-1)는 다른 프로세싱 엘리먼트들(270-2과 270-3)보다 더 빨리 곱셈 명령 들을 수행할 수 있다. 제3프로세싱 엘리먼트(270-3)는 가장 적은 제로 그룹을 포함하고 있어서 프로세싱 엘리먼 트들(270-1~270-3) 중 연산 속도가 가장 느리다. 하지만, 제1프로세싱 엘리먼트(270-1)는 제3프로세싱 엘리먼트 (270-3)의 곱셈 명령들이 완전히 끝나기 전까지 대기하여야한다. 즉, 가속기의 연산 속도는 가장 적은 제 로 그룹을 포함하는 프로세싱 엘리먼트(270-3)에 따라 결정된다. 따라서 이러한 레이턴스(latency)를 감소시키 기 위해 로드 밸런싱(load balancing)이 요구된다. 추론 단계에서 가속기의 연산 속도 향상을 위해 훈련 단계에서 로드 밸런싱이 수행된다. 도 1 내지 도 9(b)를 참고하면, 상기 프로세싱 유닛은 가속기의 프로세싱 엘리먼트들(270-1, 270-2, 및 270-3)의 가중치 레지스터들(271-1, 271-2, 및 271-3) 각각에서 상기 가지치기 마스크들이 적용된 가중치들의 배열을 분석한다. 즉, 상기 프로세싱 유닛은 가중치 레지스터들(271-1, 271-2, 및 271-3) 각각에서 각 열에 배 열된 가중치들이 모두 0인 제로 가중치 그룹들의 개수를 카운팅한다. 상기 제로 가중치 그룹들은 제로 그룹들을 의미한다. 예컨대, 상기 프로세싱 유닛은 제1프로세싱 엘리먼트(270-1)의 가중치 레지스터(271-1)에서 제로 가중치 그룹들 (G1, G3, G5, 및 G6)의 개수(4개)를 카운팅한다. 상기 프로세싱 유닛은 제2프로세싱 엘리먼트(270-2)의 가중치 레지스터(271-2)에서 제로 가중치 그룹들(G3과 G5)의 개수(2개)를 카운팅한다. 상기 프로세싱 유닛은 제3프로세 싱 엘리먼트(270-3)의 가중치 레지스터(271-3)에서 제로 가중치 그룹(G6)의 개수(1개)를 카운팅한다. 상기 프로세싱 유닛은 상기 배열의 분석에 따라 임의의 에포크들(epoch) 동안 가중치 레지스터들(271-1, 271-2, 및 271-1) 중 특정 가중치 레지스터(예컨대, 271-1)에 배열된 가중치들을 업데이트하지 않기 위해 상기 특정 가 중치 레지스터(예컨대, 271-1)에 배열된 가중치들에 대응하는 가지치기 마스크의 문턱값들을 유지한다. 하나의 에포크는 인공 신경망을 통해 한 번의 데이터가 프로파게이팅되고, 백프로파게이팅되는 것을 의미한다. 상기 프로세싱 유닛은 프로세싱 엘리먼트들(270-1, 270-2, 및 270-3)의 가중치 레지스터들(271-1, 271-2, 및 271-3) 중 제로 가중치 그룹들의 개수가 가장 많은 프로세싱 엘리먼트(예컨대, 270-1)의 가중치 레지스터(예컨 대, 271-1)를 판단한다. 상기 배열의 분석 결과, 상기 프로세싱 유닛은 제1프로세싱 엘리먼트(270-1)의 가중치 레지스터(271-1)에서 제로 가중치 그룹들이 가장 많다고 판단한다. 따라서 상기 프로세싱 유닛은 제1프로세싱 엘리먼트(270-1)의 가중치 레지스터(271-1)에 배열된 가중치들을 업데이트하지 않기 위해 임의의 에포크들 동안 제1가중치 레지스터(271-1)에 배열된 가중치들에 대응하는 가지치기 마스크의 문턱값들을 유지한다. 그러므로 임의의 에포크들 동안 제1가중치 레지스터(271-1)에서 제1가중치 그룹(G1), 제3가중치 그룹(G3), 제5가중치 그 룹(G5), 및 제6가중치 그룹(G6)은 제로 그룹을 유지하고, 제1가중치 레지스터(271-1)에서 나머지 가중치 그룹들 (G2, G4, G7, 및 G8)은 논 제로 그룹(non-zero) 그룹을 유지한다. 실시 예에 따라 프로세싱 엘리먼트들(270-1, 270-2, 및 270-3)의 가중치 레지스터들(271-1, 271-2, 및 271-3) 중 특정 가중치 레지스터의 제로 가중치 그룹들의 개수가 다른 가중치 레지스터의 제로 가중치 그룹들의 개수와 임의의 값의 합보다 큰 지를 판단한다. 프로세싱 엘리먼트들(270-1, 270-2, 및 270-3)의 가중치 레지스터들 (271-1, 271-2, 및 271-3) 중 특정 가중치 레지스터(예컨대, 271-1)의 가중치 그룹들의 개수(예컨대, 4개)가 다 른 프로세싱 엘리먼트(예컨대, 270-3)의 가중치 레지스터(271-3)의 제로 가중치 그룹들의 개수(예컨대, 1개)와 임의의 값(예컨대, 1)의 합보다 큰 때, 상기 프로세싱 유닛은 임의의 에포크들 동안 상기 특정 가중치 레지스터 (예컨대, 271-1)에 배열된 가중치들에 대응하는 가지치기 마스크들의 문턱값들을 유지한다. 제1가중치 레지스터(271-1)에 배열된 가중치들을 업데이트하지 않는 동안, 상기 프로세싱 유닛은 나머지 가중치 레지스터들(271-2과 271-3)에 배열된 가중치들에 대해 더 많이 가지치기를 수행하도록 상기 나머지 가중치 레지 스터들(271-2과 271-3)에 배열된 가중치들에 대응하는 가지치기 마스크들의 문턱값들을 조정한다. 구체적으로 상기 프로세싱 유닛은 상기 나머지 가중치 레지스터들(271-2과 271-3)에 배열된 가중치들에 대응하는 가지치기 마스크들의 문턱값들을 작게 재설정하여 더 많은 제로 그룹들이 생성되도록 한다. 도 9(b)는 로드 밸런싱 동작 적용 후의 복수의 프로세싱 엘리먼트들의 내부 블록도를 나타낸다. 도 9(b)를 참고하면, 제1가중치 레지스터(271-1)에 배열된 가중치들은 업데이트되지 않는다. 제1가중치 레지스 터(271-1)의 제로 그룹들과 넌 제로(non-zero) 그룹들은 변하지 않는다. 하지만, 제2가중치 레지스터(271-2)와 제3가중치 레지스터(271-3)에 배열된 가중치들은 변한다. 가중치 레지스 터들(271-2과 271-3)에 배열된 가중치들에 대응하는 가지치기 마스크들의 문턱값들이 조정되고, 제2가중치 레지 스터(271-2)와 제3가중치 레지스터(271-3)에 포함된 가중치 그룹들이 변한다. 제2가중치 레지스터(271-2)의 제7 가중치 그룹(G7)과 제8가중치 그룹(G8)이 넌 제로 그룹들에서 제로 그룹들로 변한다. 제3가중치 레지스터(271- 3)의 제2가중치 그룹(G2), 제3가중치 그룹(G3), 및 제8가중치 그룹(G8)이 넌 제로 그룹들에서 제로 그룹들로 변 한다. 로드 밸런싱 후에 가중치 레지스터들(271-1, 271-2, 및 271-3)은 모두 동일한 개수의 제로 그룹들을 포함하게 된다. 따라서 가속기의 레이턴스가 감소될 수 있다. 실시 예에 따라 가중치 레지스터들(271-1, 271-2, 및 271-3)에 포함된 제로 그룹들의 수는 같지 않을 수 있다. 예컨대, 제1가중치 레지스터들(271-1)의 제로 그룹들의 수가 4개라 할 때, 제2가중치 레지스터들(271-2)과 제3 가중치 레지스터들(271-3)의 제로 그룹들의 수는 5개일 수 있다. 가중치 레지스터들(271-1, 271-2, 및 271-3)에 포함된 제로 그룹들의 수는 같지 않은 경우라도 가속기의 레이턴스는 처음보다 감소될 수 있다. 도 10은 도 1에 도시된 시스템의 다른 동작 방법을 설명하기 위한 흐름도를 나타낸다. 도 1과, 도 8 내지 도 10을 참고하면, 프로세싱 유닛은 인공 신경망의 가중치들에 대해 가지치기(pruning) 마스크들을 적용한다(S10). 구체적으로, 상기 프로세싱 유닛은 상기 가중치들을 가중치 그룹들로 그룹화한다. 가지치기 마스크들 각각은 희소 행렬(sparse matrix)이다. 희소 행렬은 많은 0의 값들을 포함하는 행렬이다. 가 지치기 마스크들을 적용하는 것은 가중치 행렬과 희소 행렬의 곱셈을 의미한다. 인공 신경망의 가중치들에 대해 가지치기 마스크들을 적용하는 구체적인 동작은 다음과 같다. 상기 프로세싱 유닛은 상기 가중치들을 가중치 그룹들로 그룹화한다. 구체적으로, 상기 프로세싱 유닛은 상기 가중치들을 채널들, 또는 필터들을 고려하여 가중치 그룹들로 나눌 수 있다. 예컨대, 상기 프로세싱 유닛은 상 기 가중치들을 입력 채널에 배열된 가중치들, 또는 출력 채널에 배열된 가중치들을 고려하여 가중치 그룹들로 나눌 수 있다. 또한, 상기 프로세싱 유닛은 SIMD(Single Instruction Multiple Data) 폭에 따라 가중치들을 가중치 그룹들로 그룹화할 수 있다. 예컨대, SIMD 폭이 2일 때, 상기 프로세싱 유닛은 2개의 가중치들이 하나의 가중치 그룹을 형성하도록 가중치들을 가중치 그룹들로 나눌 수 있다. SIMD 폭이 4일 때, 상기 프로세싱 유닛은 4개의 가중치 들이 하나의 가중치 그룹을 형성하도록 가중치들을 가중치 그룹들로 나눌 수 있다. SIMD 폭이 8일 때, 상기 프 로세싱 유닛은 8개의 가중치들이 하나의 가중치 그룹을 형성하도록 가중치들을 가중치 그룹들로 나눌 수 있다. 상기 프로세싱 유닛은 상기 가중치 그룹들 각각과 상기 가지치기 마스크들의 문턱값들 각각을 비교한다. 상기 가지치기 마스크들은 대응하는 문턱값들을 포함한다. 구체적으로, 상기 프로세싱 유닛은 상기 가중치 그룹들에 서 대표 가중치들을 추출한다. 상기 대표 가중치들은 상기 가중치 그룹들에서 임의로 추출될 수 있다. 예컨대, 가중치 그룹들 중 어느 하나의 가중치 그룹이 8개의 가중치들(W1~W8)을 포함할 때, 임의로 제1가중치(W1)가 대 표 가중치로서 추출될 수 있다. 또한, 실시 예에 따라 가중치 그룹이 8개의 가중치들(W1~W8)을 포함할 때, 8개 의 가중치들의 RMS(Root Means Square)를 계산하고, RMS 값이 대표 가중치로서 추출될 수 있다. 또한, 실시 예 에 따라 가중치 그룹이 8개의 가중치들(W1~W8)을 포함할 때, 8개의 가중치들 중 최소 값, 또는 최대 값이 대표 가중치로서 추출될 수 있다. 상기 프로세싱 유닛은 가중치 그룹들 각각에서 추출된 대표 가중치들 각각을 상기 가지치기 마스크들의 문턱값 들 각각과 비교한다. 상기 문턱값들 각각은 임의로 설정될 수 있다. 또한, 상기 문턱값들은 서로 다르게 설정될 수 있다. 상기 대표 가중치들 중 어느 하나가 대응하는 문턱값보다 작을 때, 상기 프로세싱 유닛은 상기 대표 가중치들 중 어느 하나에 대응하는 가중치 그룹에 속한 가중치들 모두를 0으로 설정한다. 예컨대, 하나의 가중치 그룹인 8개의 가중치들(W1~W8) 중 대표 가중치가 대응하는 문턱값보다 작을 때, 상기 프로세싱 유닛은 상기 대표 가중 치에 대응하는 가중치 그룹에 속한 가중치들(W1~W8)을 모두 0으로 설정한다. 상기 0으로 설정은 가중치 행렬과 희소 행렬의 곱으로 설정될 수 있다. 반대로, 상기 대표 가중치들 중 다른 하나가 대응하는 문턱값보다 클 때, 상기 프로세싱 유닛은 상기 대표 가중 치들 중 다른 하나에 대응하는 가중치 그룹에 속한 가중치들을 모두 유지한다. 유지한다함은 상기 가중치 그룹 에 속한 가중치들(W1~W8)을 모두 변경하지 않는다 것을 의미한다. 즉, 가중치 행렬과 희소 행렬의 곱셈 동작은 수행되지 않는다. 상기 프로세싱 유닛은 인공 신경망을 통해 훈련 데이터(training data)로부터 활성화 데이터를 프로파게이 팅(propagating)한다(S20). 즉, 상기 프로세싱 유닛은 인공 신경망의 입력 레이어에 훈련 데이터를 입력하고, 은닉 레이어와 출력 레이어를 통해 활성화 데이터를 출력한다. 상기 프로세싱 유닛은 상기 활성화 데이터와 목표 데이터에 기초하여 손실 함수(loss function)의 값을 계산한 다(S30). 상기 손실 함수의 값은 상기 활성화 데이터와 목표 데이터 사이의 MSE(Means Squared Error), 또는 크 로스-엔트로피(cross-entropy)를 이용하여 계산될 수 있다. 상기 프로세싱 유닛은 인공 신경망의 가중치들과 관련된 상기 손실 함수(loss function)의 기울기 (gradient)와, 상기 가지치기 마스크들의 문턱값들(Threshold)과 관련된 상기 손실 함수의 기울기를 계산하기 위해 상기 손실 함수의 값을 백프로파게이팅(backpropagating)한다(S40). 백프로파게이션 동작은 인공 신경망 의 가중치들과 관련된 상기 손실 함수(loss function)의 기울기(gradient)와, 문턱값들(Threshold)과 관 련된 상기 손실 함수의 기울기를 계산하는 동작을 포함한다. 상기 백프로파게이션은 상기 가중치들과 문턱값들 을 조절하여 상기 손실 함수의 값을 최소화를 목표로 한다. 인공 신경망의 가중치들에 따라 손실 함수의 값이 변한다. 따라서 상기 프로세싱 유닛은 가중치들에 따른 손실 함수의 변화 값을 이용하여 가중치들과 관련된 손실 함수의 기울기를 계산한다. 가지치기 마스크들의 문턱값들에 따라 손실 함수의 값도 변한다. 상기 문턱값들에 따라 가중치들이 0으로 설정 될 수 있기 때문이다. 따라서 상기 프로세싱 유닛은 가지치기 마스크들의 문턱값들에 따른 손실 함수의 변화 값 을 이용하여 상기 가지치기 마스크들의 문턱값들과 관련된 손실 함수의 기울기를 계산한다. 상기 프로세싱 유닛은 인공 신경망의 가중치들과 관련된 상기 손실 함수의 기울기와, 상기 가지치기 마스 크들의 문턱값들과 관련된 상기 손실 함수의 기울기에 기초하여 인공 신경망의 가중치들과, 상기 가지치기 마스크의 문턱값들을 업데이트한다(S50). 상기 문턱값들의 업데이트에 따라 특정 가중치 그룹들이 모두 0으로 재설정되거나, 0으로의 설정이 취소될 수 있다. 상기 프로세싱 유닛은 인공 신경망의 오버피팅(overfitting)을 피하기 위해 인공 신경망에 대해 구조 화된 희소 정규화(structured sparsity regularization)를 수행한다. 구조화된 희소 정규화란 가중치 그룹들을 고려하여 정규화 동작을 수행함을 의미한다. 상기 프로세싱 유닛은 가속기의 프로세싱 엘리먼트들의 가중치 레지스터들에서 상기 가지치기 마스크들이 적용된 가중치들의 배열을 분석한다. 상기 프로세싱 유닛은 상기 배열의 분석에 따라 임의의 에포크 들(epoch) 동안 상기 가중치 레지스터들 중 특정 가중치 레지스터에 배열된 가중치들을 업데이트하지 않기 위해 상기 특정 가중치 레지스터에 배열된 가중치들에 대응하는 가지치기 마스크의 문턱값들을 유지한다. 상기 프로세싱 유닛은 상기 특정 가중치 레지스터에 배열된 가중치들을 제외한 나머지 가중치 레지스터들에 배 열된 가중치들을 업데이트하기 위해 상기 나머지 가중치들에 대응하는 가지치기 마스크들의 문턱값들을 조정한 다. 상기 프로세싱 유닛은 조정된 문턱값들에 따라 인공 신경망을 훈련시킨다. 본 발명에서는 가속기의 프로세싱 엘리먼트들의 가중치 레지스터들에 배열된 제로 가중치 그룹 들을 고려하여 가지치기함으로써 가속기에서의 레이턴시를 감소될 수 있다. 본 발명은 도면에 도시된 일 실시 예를 참고로 설명되었으나 이는 예시적인 것에 불과하며, 본 기술 분야의 통 상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시 예가 가능하다는 점을 이해할 것이다. 따라 서 본 발명의 진정한 기술적 보호 범위는 첨부된 등록청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2021-0062969", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 상세한 설명에서 인용되는 도면을 보다 충분히 이해하기 위하여 각 도면의 상세한 설명이 제공된다. 도 1은 본 발명의 실시 예에 따른 시스템의 블록도를 나타낸다. 도 2는 도 1에 도시된 프로세싱 유닛의 동작을 설명하기 위한 인공 신경망의 블록도를 나타낸다. 도 3은 도 2에 도시된 인공 신경망의 은닉 레이어(hidden layer)의 입력 활성화(input activations)와 가중치 (weights)를 나타낸다. 도 4는 도 3에 도시된 4D 가중치 텐서(tensor)와 2D 가중치 행렬을 나타낸다. 도 5는 도 1에 도시된 가속기의 블록도를 나타낸다. 도 6은 도 5에 도시된 프로세싱 엘리먼트(processing element)의 내부 블록도를 나타낸다. 도 7은 도 1에 도시된 시스템의 동작 방법을 설명하기 위한 흐름도를 나타낸다. 도 8은 도 5에 도시된 프로세싱 엘리먼트의 다른 내부 블록도를 나타낸다. 도 9는 도 5에 도시된 복수의 프로세싱 엘리먼트들의 내부 블록도를 나타낸다. 도 10은 도 1에 도시된 시스템의 다른 동작 방법을 설명하기 위한 흐름도를 나타낸다."}
