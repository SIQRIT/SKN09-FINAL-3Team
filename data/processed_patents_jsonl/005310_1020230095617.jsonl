{"patent_id": "10-2023-0095617", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0013706", "출원번호": "10-2023-0095617", "발명의 명칭": "자기 위치 측정이 가능한 로봇 및 위치 측정 방법", "출원인": "주식회사 케이티", "발명자": "박형준"}}
{"patent_id": "10-2023-0095617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "자기 위치 측정이 가능한 로봇에 있어서,2차원 건축 도면으로부터 생성된 3차원 도면을 저장하는 저장 장치;카메라; 및상기 카메라에서 촬영된 이미지로부터 공간을 구성하는 선분을 추출하고, 추출된 선분과 상기 3차원 도면의 선분을 비교하여 현재 위치를 결정하는 프로세서를 포함하는 로봇."}
{"patent_id": "10-2023-0095617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 추출된 선분과 상기 3차원 도면의 대응 선분 간의 거리가 가장 작은 상기 3차원 도면 상의 위치를 현재 위치로 결정하는 것을 특징으로 하는 로봇."}
{"patent_id": "10-2023-0095617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 추출된 선분과 상기 3차원 도면의 대응 선분 간의 거리는,상기 추출된 선분의 각 픽셀과 상기 대응 선분의 각 대응 픽셀 간 거리의 합인 것을 특징으로 하는 로봇."}
{"patent_id": "10-2023-0095617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 3차원 도면은,상기 2차원 건축 도면에서 검출된 각 코너 지점의 점의 집합과, 상기 2차원 건축 도면에서 가상의 광선을 발사하는 가상 로봇을 주행시키며 검출한 바닥면 선분들에 대한 점의 집합을 기초로 생성된 것을 특징으로 하는 로봇."}
{"patent_id": "10-2023-0095617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 3차원 도면은,상기 바닥면 선분들에 대한 점의 집합에서 서로 교차하고 상기 각 코너 지점의 점의 집합에 속하는 바닥면의 코너 지점을 기준으로 상기 바닥면 선분들을 상부로 프로젝션하여 천장면을 형성하고, 천장면의 코너 지점과 상기바닥면의 코너 지점을 이어 형성된 것을 특징으로 하는 로봇."}
{"patent_id": "10-2023-0095617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 3차원 도면의 상기 천장면과 상기 바닥면 사이의 높이는,상기 가상 로봇의 카메라에서 촬영되는 이미지의 세로 거리와, 미리 학습된 3차원 좌표 추정 모델에 상기 가상로봇의 카메라에서 촬영되는 이미지의 상단 또는 하단 중심 좌표를 입력하여 출력되는 깊이 값을 이용하여 구해지는 것을 특징으로 하는 로봇.공개특허 10-2024-0013706-3-청구항 7 제6항에 있어서,상기 3차원 좌표 추정 모델은,실제 로봇을 임의의 실제 3차원 공간 내에서 움직이며 카메라로 획득한 각 이미지의 점의 좌표들의 행렬집합과, 그 각 이미지의 점에 대응하는 실제 3차원 공간 내의 점의 좌표들의 행렬 집합을 이용하여 학습되는 것을 특징으로 하는 로봇."}
{"patent_id": "10-2023-0095617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "로봇의 자기 위치 측정 방법에 있어서,2차원 건축 도면으로부터 생성된 3차원 도면을 저장하는 단계;상기 로봇의 카메라에서 촬영된 이미지로부터 공간을 구성하는 선분을 추출하는 단계; 및추출된 선분과 상기 3차원 도면의 선분을 비교하여 현재 위치를 결정하는 단계를 포함하는 자기 위치 측정방법."}
{"patent_id": "10-2023-0095617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 결정하는 단계는,상기 추출된 선분과 상기 3차원 도면의 대응 선분 간의 거리가 가장 작은 상기 3차원 도면 상의 위치를 현재 위치로 결정하는 것을 특징으로 하는 자기 위치 측정 방법."}
{"patent_id": "10-2023-0095617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 추출된 선분과 상기 3차원 도면의 대응 선분 간의 거리는,상기 추출된 선분의 각 픽셀과 상기 대응 선분의 각 대응 픽셀 간 거리의 합인 것을 특징으로 하는 자기 위치측정 방법."}
{"patent_id": "10-2023-0095617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 3차원 도면은,상기 2차원 건축 도면에서 검출된 각 코너 지점의 점의 집합과, 상기 2차원 건축 도면에서 가상의 광선을 발사하는 가상 로봇을 주행시키며 검출한 바닥면 선분들에 대한 점의 집합을 기초로 생성된 것을 특징으로 하는 자기 위치 측정 방법."}
{"patent_id": "10-2023-0095617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 3차원 도면은,상기 바닥면 선분들에 대한 점의 집합에서 서로 교차하고 상기 각 코너 지점의 점의 집합에 속하는 바닥면의 코너 지점을 기준으로 상기 바닥면 선분들을 상부로 프로젝션하여 천장면을 형성하고, 천장면의 코너 지점과 상기바닥면의 코너 지점을 이어 형성된 것을 특징으로 하는 자기 위치 측정 방법."}
{"patent_id": "10-2023-0095617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 3차원 도면의 상기 천장면과 상기 바닥면 사이의 높이는,공개특허 10-2024-0013706-4-상기 가상 로봇의 카메라에서 촬영되는 이미지의 세로 거리와, 미리 학습된 3차원 좌표 추정 모델에 상기 가상로봇의 카메라에서 촬영되는 이미지의 상단 또는 하단 중심 좌표를 입력하여 출력되는 깊이 값을 이용하여 구해지는 것을 특징으로 하는 자기 위치 측정 방법."}
{"patent_id": "10-2023-0095617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 3차원 좌표 추정 모델은,실제 로봇을 임의의 실제 3차원 공간 내에서 움직이며 카메라로 획득한 각 이미지의 점의 좌표들의 행렬집합과, 그 각 이미지의 점에 대응하는 실제 3차원 공간 내의 점의 좌표들의 행렬 집합을 이용하여 학습되는 것을 특징으로 하는 자기 위치 측정 방법."}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "2차원 실내 건축 도면을 이용하여 생성된 3차원 건축 도면과 카메라를 이용하여 자기 위치를 측정할 수 있는 로 봇 및 위치 측정 방법이 개시된다. 일 측면에 따른, 자기 위치 측정이 가능한 로봇은, 2차원 건축 도면으로부터 생성된 3차원 도면을 저장하는 저장 장치; 카메라; 및 상기 카메라에서 촬영된 이미지로부터 공간을 구성하는 선 분을 추출하고, 추출된 선분과 상기 3차원 도면의 선분을 비교하여 현재 위치를 결정하는 프로세서를 포함한다."}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은, 자기 위치 측정이 가능한 로봇 및 위치 측정 방법에 관한 것으로, 보다 구체적으로 카메라로 촬영한 영상을 이용하여 자기 위치 측정이 가능한 로봇 및 위치 측정 방법에 관한 것이다."}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현존하는 실내 로봇의 경우, 실내 주행 지도와 고가의 2D 라이다(Lidar)와 같은 센서 장치를 활용하여 실내에서 의 자기 위치를 측정한다. 이와 같은 방식은 넓은 실내 공간에 대한 주행 지도의 생성에 많은 시간과 인력 자원 이 소요되고, 또한 2D 라이다(Lidar) 또는 3D 라이다와 같은 고가의 센서 장치를 실내 로봇에 장착해야 하기 때 문에 많은 비용이 소요되는 문제점이 있다. 따라서, 실내 주행 지도의 생성에 소요되는 시간을 최소화할 수 있 는 방안과 로봇이 고가의 센서 장치를 이용하지 않고 실내 공간에서 자기 위치를 측정할 수 있는 방안이 필요하 다."}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 해결하기 위해 제안된 것으로, 2차원 실내 건축 도면을 이용하여 생성된 3차원 건축 도면과 카메라를 이용하여 자기 위치를 측정할 수 있는 로봇 및 위치 측정 방법을 제공하는데 그 목적이 있다."}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 측면에 따른, 자기 위치 측정이 가능한 로봇은, 2차원 건축 도면으로부터 생성된 3차원 도면을 저장하는 저 장 장치; 카메라; 및 상기 카메라에서 촬영된 이미지로부터 공간을 구성하는 선분을 추출하고, 추출된 선분과 상기 3차원 도면의 선분을 비교하여 현재 위치를 결정하는 프로세서를 포함한다. 상기 프로세서는, 상기 추출된 선분과 상기 3차원 도면의 대응 선분 간의 거리가 가장 작은 상기 3차원 도면 상 의 위치를 현재 위치로 결정할 수 있다. 상기 추출된 선분과 상기 3차원 도면의 대응 선분 간의 거리는, 상기 추출된 선분의 각 픽셀과 상기 대응 선분 의 각 대응 픽셀 간 거리의 합일 수 있다. 상기 3차원 도면은, 상기 2차원 건축 도면에서 검출된 각 코너 지점의 점의 집합과, 상기 2차원 건축 도면에서 가상의 광선을 발사하는 가상 로봇을 주행시키며 검출한 바닥면 선분들에 대한 점의 집합을 기초로 생성될 수 있다. 상기 3차원 도면은, 상기 바닥면 선분들에 대한 점의 집합에서 서로 교차하고 상기 각 코너 지점의 점의 집합에 속하는 바닥면의 코너 지점을 기준으로 상기 바닥면 선분들을 상부로 프로젝션하여 천장면을 형성하고, 천장면 의 코너 지점과 상기 바닥면의 코너 지점을 이어 형성될 수 있다. 상기 3차원 도면의 상기 천장면과 상기 바닥면 사이의 높이는, 상기 가상 로봇의 카메라에서 촬영되는 이미지의 세로 거리와, 미리 학습된 3차원 좌표 추정 모델에 상기 가상 로봇의 카메라에서 촬영되는 이미지의 상단 또는 하단 중심 좌표를 입력하여 출력되는 깊이 값을 이용하여 구해질 수 있다. 상기 3차원 좌표 추정 모델은, 실제 로봇을 임의의 실제 3차원 공간 내에서 움직이며 카메라로 획득한 각 이미 지의 점의 좌표들의 행렬 집합과, 그 각 이미지의 점에 대응하는 실제 3차원 공간 내의 점의 좌표들의 행렬 집 합을 이용하여 학습될 수 있다. 다른 측면에 따른, 로봇의 자기 위치 측정 방법은, 2차원 건축 도면으로부터 생성된 3차원 도면을 저장하는 단 계; 상기 로봇의 카메라에서 촬영된 이미지로부터 공간을 구성하는 선분을 추출하는 단계; 및 추출된 선분과 상 기 3차원 도면의 선분을 비교하여 현재 위치를 결정하는 단계를 포함한다. 상기 결정하는 단계는, 상기 추출된 선분과 상기 3차원 도면의 대응 선분 간의 거리가 가장 작은 상기 3차원 도 면 상의 위치를 현재 위치로 결정할 수 있다. 상기 추출된 선분과 상기 3차원 도면의 대응 선분 간의 거리는, 상기 추출된 선분의 각 픽셀과 상기 대응 선분 의 각 대응 픽셀 간 거리의 합일 수 있다. 상기 3차원 도면은, 상기 2차원 건축 도면에서 검출된 각 코너 지점의 점의 집합과, 상기 2차원 건축 도면에서 가상의 광선을 발사하는 가상 로봇을 주행시키며 검출한 바닥면 선분들에 대한 점의 집합을 기초로 생성될 수 있다. 상기 3차원 도면은, 상기 바닥면 선분들에 대한 점의 집합에서 서로 교차하고 상기 각 코너 지점의 점의 집합에 속하는 바닥면의 코너 지점을 기준으로 상기 바닥면 선분들을 상부로 프로젝션하여 천장면을 형성하고, 천장면 의 코너 지점과 상기 바닥면의 코너 지점을 이어 형성될 수 있다. 상기 3차원 도면의 상기 천장면과 상기 바닥면 사이의 높이는, 상기 가상 로봇의 카메라에서 촬영되는 이미지의 세로 거리와, 미리 학습된 3차원 좌표 추정 모델에 상기 가상 로봇의 카메라에서 촬영되는 이미지의 상단 또는 하단 중심 좌표를 입력하여 출력되는 깊이 값을 이용하여 구해질 수 있다. 상기 3차원 좌표 추정 모델은, 실제 로봇을 임의의 실제 3차원 공간 내에서 움직이며 카메라로 획득한 각 이미 지의 점의 좌표들의 행렬 집합과, 그 각 이미지의 점에 대응하는 실제 3차원 공간 내의 점의 좌표들의 행렬 집 합을 이용하여 학습될 수 있다."}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 사람이 원격으로 로봇을 조정하여 지도를 그리는 기존 방식과 다르게 2차원 건축 도면을 바 탕으로 자동으로 3차원 지도를 생성할 수 있기 때문에, 넓은 공간 혹은 많은 층이 있는 건물에 대한 지도를 생 성할 때 필요한 인력을 획기적으로 줄일 수 있는 장점이 있다. 본 발명에 따르면, 종래의 로봇이 라이다를 포함하여 다양한 센서 장치를 통해 자신의 위치를 추정하는 방식과 다르게 일반적인 2D 카메라만을 사용하여 높은 정확도로 자신의 위치를 추정할 수 있다. 따라서, 기존 로봇에 들어가는 고가 장치에 대한 의존도를 줄임으로써, 로봇의 생산 단가를 획기적으로 낮출 수 있게 된다."}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용되는 것으로 서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시예를 설명함 에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단 되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이해할 수 있도 록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사 상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또 는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘어져서 구현될 수도 있다. 본 발명에서 로봇이 실내에서 카메라로 촬영한 영상을 기초로 자기 위치를 측정하기 위해서는 실내 공간에 대한 3차원 건축 도면이 필요하다. 본 발명의 일 실시예에 따른 3차원 건축 도면 생성장치에서 2차원 실내 건축 도면 을 이용하여 3차원 건축 도면을 구축한다. 도 1은 본 발명의 일 실시예에 따른 3차원 건축 도면 생성장치의 구성을 나타낸 도면이다. 3차원 건축 도면 생 성장치는, 메모리, 메모리 제어기, 하나 이상의 프로세서(CPU), 주변 인터페이스, 입출력(I/O) 서브시스템, 디스플레이 장치, 입력 장치 및 통신 회로를 포함할 수 있다. 이러한 구성요소는 하나 이상의 통신 버스 또는 신호선을 통하여 통신한다. 이러한 여러 구성요소는 하나 이상의 신호 처리 및/또는 애플리케이션 전 용 집적 회로(application specific integrated circuit)를 포함하여, 하드웨어, 소프트웨어 또는 하드웨어와 소프트웨어 둘의 조합으로 구현될 수 있다. 주변 인터페이스는 입출력 주변 장치를 프로세서 및 메모리와 연결한다. 하나 이상의 프로세서는 다양한 소프트 웨어 프로그램 및/또는 메모리에 저장되어 있는 명령어 세트를 실행하여 시스템을 위한 여러 기능을 수행하고 데이터를 처리한다. 일부 실시예에서, 주변 인터페이스, 프로세서 및 메모리 제어기는 칩과 같은 단일 칩 상에 서 구현될 수 있다. 일부 다른 실시예에서, 이들은 별개의 칩으로 구현될 수 있다. I/O 서브시스템은 디스플레이 장치, 입력 장치와 같은 입출력 주변장치와 주변 인터페이스 사이에 인터페이스를 제공한다. 디스플레이 장치는 LCD(liquid crystal display) 기술 또는 LPD(light emitting polymer display), OLED(Organic Light Emitting Diodes) 기술을 사용할 수 있다. 프로세서는 시스템에 연관된 동작을 수행 하고 명령어들을 수행하도록 구성된 프로세서로서, 예를 들어, 메모리로부터 검색된 명령어들을 이용하여, 시스 템의 컴포넌트 간의 입력 및 출력 데이터의 수신과 조작을 제어할 수 있다. 일부 실시예에서, 소프트웨어 구성요소는 운영 체제, 그래픽 모듈(명령어 세트), 본 발명을 위한 동작을 수행하 기 위한 프로그램이 탑재(설치)된다. 운영 체제는, 예를 들어, 다윈(Darwin), RTXC, LINUX, UNIX, OS X, WINDOWS 또는 VxWorks, 안드로이드, iOS 등과 같은 내장 운영체제일 수 있고, 일반적인 시스템 태스크(task)(예 를 들어, 메모리 관리, 저장 장치 제어, 전력 관리 등)를 제어 및 관리하는 다양한 소프트웨어 구성요소 및/또 는 장치를 포함하고, 다양한 하드웨어와 소프트웨어 구성요소 사이의 통신을 촉진시킨다. 통신 회로는 이더넷통신 회로 및 RF 회로를 포함할 수 있다. 이더넷 통신 회로는 유선 통신을 수행하고, RF 회로는 전자파를 송수 신한다. RF 회로는 전기 신호를 전자파로 또는 그 반대로 변환하며 이 전자파를 통하여 통신 네트워크, 다른 이 동형 게이트웨이 및 통신 장치와 통신한다. 도 1을 참조하면, 3차원 건축 도면 생성장치는, 수신부, 코너 검출부, 바닥 선분 검출부 및 생성부를 포함하고, 이들은 앞서 설명한 하드웨어 또는/및 소프트웨어의 결합에 의해 구현될 수 있고, 바람직하게 소프트웨어로 구현되어 메모리에 저장되고 프로세서에 의해 실행될 수 있다. 수신부는, 2차원 건축 도면을 수신한다. 2차원 건축 도면은, 다양한 입력 수단을 통해 수신될 수 있다. 예 를 들어, 수신부는, USB 저장장치로부터 2차원 건축 도면을 수신하거나, 또는 수신부는, 원격지의 서 버나 원격지 저장장치로부터 2차원 건축 도면을 수신할 수 있다. 코너 검출부는, 상기 2차원 건축 도면을 바이너리 이미지로 변경한 후, 바이너리 이미지를 이용하여 각 코 너 지점을 검출한다. 예를 들어, Harris Corner 알고리즘을 이용할 수 있다. 코너 검출부는, 모든 코너 지 점에 대한 집합(Cx)을 중복없이 구성한다. 도 2는 본 발명의 일 실시예에 따른 2차원 건축 도면의 코너 지점을 검출한 예로서, 붉은색 원 부분이 코너 지점이다. 바닥 선분 검출부는, 상기 2차원 건축 도면 내에서 가상 로봇을 배치하고, 가상 로봇을 주행시키며 가상 로봇에 설치된 카메라의 화각 정보를 기초로 가상의 광선을 발사하여, 바닥면 선분을 검출한다. 바닥 선분 검출 부는, 바닥면 선분을 구성하는 점에 대한 집합(Fx) 정보를 산출한다. 도 3은 본 발명의 일 실시예에 따른 2차원 건축 도면으로부터 바닥면 선분을 검출하는 예를 나타낸 도면이다. 도 3에서 녹색점 R은 2차원 건축 도면에서 가상 로봇의 위치이고 도 3의 이미지는 가상 로봇에 설치된 카메라의 화각에 대응한다. 즉 도 3의 이미지는 카메라의 가시권으로 이해될 수 있다. 2차원 건축 도면 내의 녹색점 R에 가상 로봇이 위치하고 가상 로봇이 특정 방향을 향하고 있다고 가정한 상태에서 가상 로봇의 카메라의 화각 정 보를 기초로 가상의 광선을 발사하면, 도 3에 도시된 바와 같이, 카메라의 화각 범위 내의 벽면에 대한 바닥면 선분의 점에 대한 집합이 검출된다. 도 3에서 pos 벡터는 2차원 건축 도면 내에서 가상 로봇의 현재 위치를 나타낸다. 예를 들어, 2차원 건축 도면 의 좌측 하단을 원점으로 한 xy 좌표계에서 가상 로봇의 현재 위치를 나타낸다. 그리고 도 3에서 검은색 선분인 dir 벡터는 가상 로봇이 바라보는 방향을 나타내고 2차원 건축 도면의 평면도 내부를 가르킨다. 그리고 도 3에서 파란색 선분은 2차원 건축 도면의 평면을 나타내고, plane 벡터로 표현할 수 있다. plane 벡터는 현 재 가시권에 들어오는 2차원 건축 도면의 평면도에서 방향 벡터 끝점(pos 벡터 + dir 벡터)부터 오른쪽 건축 평 면의 끝점까지를 나타낸다. 다시 말해, 오른쪽 가시권에 들어오는 건축 평면의 끝점은 (pos + dir) + plane으로 표현할 수 있으며, 왼쪽 가시권에 들어오는 건축 평면의 끝점은 (pos + dir) - plane 으로 표현할 수 있다. 앞에서 설명한 내용을 바탕으로 2차원 건축 도면 상에서 가상 로봇이 위치하는 R(pos 벡터)를 중심으로 광선을 순차적으로 발사하여 가시권에 들어오는 2차원 건축 도면 상에서의 벽면에 대한 바닥면 선분을 구성하는 점에 대한 집합(Fx) 정보를 얻어 벽면에 대한 바닥면 선분을 구성할 수 있다. 이때, 아래 (식1)를 통해 건축 평면도 의 선분을 검출하는 광선을 생성할 수 있다. (식1)에서 방향 벡터(dir 벡터)가 길어질수록 plane 벡터는 짧아지 게 되며, 건축 도면의 평면을 통과하는 광선의 각도(θ) 역시 짧아지게 된다. 즉, 도 3에서 파란색 선분이 위로 올라가게 되면 방향 벡터(dir 벡터)는 길어지고 plane 벡터는 짧아지며 코너 부분에서는 점으로 수렴하게 되며 광선의 각도(θ) 역시 0으로 수렴한다. (식1)"}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "생성부는, 상기 코너 검출부에서 검출된 각 코너 지점에 대한 점의 집합(Cx)과, 상기 바닥 선분 검출 부에서 검출한 바닥면 선분에 대한 점의 집합(Fx)을 기초로 2차원 건축 도면을 3차원 건축 도면으로 생성 한다. 이하 도면을 참조하여 구체적으로 설명한다. 도 4는 본 발명의 일 실시예에 따른 2차원 건축 도면에서 가상 로봇의 가시권에 있는 벽면에 대한 바닥면 선분 및 코너 지점을 나타낸다. 바닥면 선분에 대한 점의 집합(Fx)을 바탕으로 교차하는 점이 있는지 확인한 후, 해당 교차점이 2차원 건축 도면 상의 코너 지점에 대한 점의 집합(Cx)에 속하는지 확인한다. 해당 교차점이 2차원 건축 도면 상의 코너 지점에 대한 점의 집합(Cx)에 속하는 경우, 바닥면을 구성하는 선분을 프로젝션하여 천장면을 형성한다. 도 4의 예에서, 코너 지점에 대한 점의 집합(Cx) 중 C1이 바닥면 선분의 교점에 대응하는 것을 나타낸 다. 도 5는 본 발명의 일 실시예에 따른 천장면을 형성하는 예를 나타낸다. 도 5에 도시된 바와 같이, 바닥면을 구 성하는 선분을 프로젝션하여 천장면을 형성한다. 이때, 바닥면으로부터 천장면까지의 높이(wall height)를 설정 해야 한다. 높이를 구하는 방법에 대해서는 아래에서 도 6을 참조하여 구체적으로 설명한다. 도 6은 본 발명의 일 실시예에 따른 3차원 공간과 로봇의 카메라에서 촬영되는 2D 이미지 평면 그리고 이들의 대응 관계를 나타낸 도면이다. 도 6에서 로봇의 카메라에서 촬영되는 2D 이미지 평면 상에서 카메라가 바 라보는 한 점을 PRobot CAM으로 정의한다. 그 점에서 시작되는 두 개의 직선(620, 630)은 PRobot CAM을 포함하는 2D 이미지 평면을 통해 3차원 공간 내의 벽체의 평면으로 투영될 수 있다. 즉, 2D 이미지 평면에서의 Ptop 지점은, 3차원 공간 내의 벽체의 Ptop, 3D 지점에 대응하고, 2D 이미지 평면에서의 Pbottom 지점은, 3차원 공간 내의 벽체의 Pbottom, 3D 지점에 대응한다. 2D 이미지 평면은 로봇의 카메라의 화각에 대응하여 2D 이미 지 평면의 Ptop 지점과 Pbottom 지점 사이의 거리는 미리 알고 있으므로, 2D 이미지 평면과 3차원 공간 내의 벽체 사이의 거리 z를 알면 해당 벽체의 높이, 즉 Ptop, 3D 지점과 Pbottom, 3D 지점 사이의 거리(즉, 높이)를 알 수 있다. 여기서 Ptop 지점과 Pbottom 지점 사이의 거리는 2D 이미지 평면의 세로 거리에 해당한다. 이를 수학식으로 표현하면 다음 (수학식1)과 같이 표현할 수 있다. (수학식1)"}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기 (수학식1)의 우변의 (u, v, 1)은 2D 이미지 평면 상에서 Ptop 지점 또는 Pbottom 지점의 동차 좌표계 (homogeneous coordinates) 상의 좌표이고, 좌변의 (XC, YC, ZC, 1)은 2D 이미지 평면에서의 상기 점 (u, v, 1)에 대응하는 3차원 공간 내의 벽체의 점(즉, Ptop, 3D 지점과 Pbottom, 3D 지점)의 동차 좌표계 상의 좌표이다. 참고로, 2D 이미지 평면의 네 꼭지점의 좌표를 도 6과 같이 (b1, b4), (b1, b2), (b3, b2), (b3, b4)라 할 때, Ptop 지점과 Pbottom 지점의 좌표는 다음 (수학식2)와 같다. 아래 (수학식2)의 각 좌표를 상기 (수학식1)의 우 변의 (u, v, 1)와 같은 동차 좌표계 상의 좌표로 변환하여 상기 (수학식1)의 우변에 대입한다. (수학식2)"}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "상기 (수학식1)의 우변에 도 6의 2D 이미지 평면 상의 Ptop 지점의 좌표를 넣어 이에 대응하는 3차원 공간 내의 벽체의 Ptop, 3D 지점의 좌표를 구하고, 또한 상기 (수학식1)의 우변에 6의 2D 이미지 평면 상의 Pbottom 지점의 좌표를 넣어 이에 대응하는 3차원 공간 내의 벽체의 Pbottom, 3D 지점의 좌표를 구한 후, Ptop, 3D 지점과 Pbottom, 3D 지점 사이의 Y 축 거리를 구한다. 이와 같이 구해지는 Y 축 거리가 벽체의 높이에 해당한다. 이때, 상기 (수학식1)의 우변의 z는 미리 학습된 3D 좌표 추정 모델을 이용하여 구할 수 있다. 이에 대해서는 아래에서 자세히 설명하도록 하고, 상기 (수학식1)이 어떻게 유도되었는지를 먼저 설명한다. 2D 이미지 평면에서의 임의의 한 점 a의 동차 좌표계 상의 좌표를 (u, v, 1)라 하고, 그 점에 대응하는 카 메라 밖의 실제 점 A의 동차 좌표계 상의 좌표를 (XW, YW, ZW, 1)이라고 하며, 2D 이미지 평면 상의 점 a와 카메라 밖의 실제 점 A의 깊이(depth)가 같은 경우, 점 a와 점 A 사이의 관계는 다음 (수학식3)과 같이 표현할 수 있다.(수학식3) a=KDA 여기서 K는 행렬 형태의 내부 파라미터로 카메라의 초점 거리, 이미지 센서의 크기, 이미지 센서와 픽셀 간의 변환 관계를 포함하는데 카메라 캘리브레이션 과정을 통해 추정할 수 있다. D는 왜곡 계수로 렌즈의 굴절력과 같은 광학 특성으로 인해 실제 세계에서 볼 때 왜곡이 발생하는 현상을 보정하여 정확한 공간 위치를 추정하기 위해 사용하는 파라미터이다. 왜곡 계수 D 역시 카메라 캘리브레이션 과정을 통해 추정할 수 있다. 로봇이 카메라를 통해 바라보는 시점인 PRobot CAM의 평면(즉, 2D 이미지 평면)과 3차원 공간 내의 벽체 간의 깊이(depth)가 z만큼 떨어져 있을 경우, 상기 (수학식3)에 z를 연산하여 아래 (수학식4)와 같이 구할 수 있다. (수학식4) za=KDA 상기 (수학식4)를 동차 좌표 식으로 표현하면 다음 (수학식5)와 같다. (수학식5)"}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "상기 (수학식5)의 우변의 점 A의 좌표로 정리하면, 앞서 설명한 (수학식1)과 같다. 다음으로, 상기 (수학식1)의 우변의 z를 구할 수 있는 미리 학습된 3D 좌표 추정 모델을 설명한다. 3D 좌표 추정 모델은 학습 데이터로 미리 학습된다. 학습 데이터를 획득하기 위해, 실제 로봇을 임의의 실제 3 차원 공간 내에서 움직이며 카메라로 이미지를 획득한다. 이때, 실제 3차원 공간의 좌표계를 도 6의 좌표계와 동일하다고 할 때, 로봇의 Y 축 값은 고정되고 X 축 값 및 Z 축 값만이 변한다. 카메라로 각 이미지를 획득할 때의 각 이미지에서의 Ptop 지점 또는 Pbottom 지점의 동차 좌표들의 행렬 집합을 로 표현할 수 있고, 행렬의 원소인 의 경우 동차 좌표 로 표현할 수 있다. 각 이미지에서의 Ptop 지점 또는 Pbottom 지점에 대응하는 실제 3차원 공간 내의 벽체의 지점의 동차 좌표들의 행렬 집합을 로 표현할 수 있고, 행렬의 원소인 의 경우 동 차 좌표 로 표현할 수 있다. 이와 같이 획득된 동차 좌표 행렬 와 를 정규화시키기 위해 상수 행렬인 Tc와 Tl을 적용하여 정규화된 행 렬 및 를 구할 수 있다. 이와 같이 정규화된 점의 행렬 집합인 및 간의 관계를 정규화된 호 모그래피 행렬(homography matrix) 로 나타내면 다음 (수학식6)과 같다. (수학식6)"}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서 호모그래피 행렬은 두 개의 평면 간의 변환을 나타내는 3×3 행렬로서, 이 변환은 원근법(projection)을 사용하여 한 평면 상의 점들을 다른 평면 상의 대응하는 점들로 매핑하는데 사용한다. 상기 (수학식6)을 다시 정규화 전의 실제 동차 좌표로 표현할 경우, 다음 (수학식7)과 같이 표현할 수 있다. 그리고 (수학식7)에서 와 간의 변환 행렬, 즉 비정규화된 호모그래피 행렬은 다음 (수학식8)과 같이 정 리할 수 있다. (수학식8)"}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "앞서 언급한 3D 좌표 추정 모델은, 상술한 학습 데이터를 이용하여 상기 (수학식8)의 비정규화된 호모그래피 행 렬을 학습하고, 로봇의 카메라에서 얻은 2D 이미지 평면 상의 Ptop 지점 또는 Pbottom 지점의 동차 좌표계 상의 좌 표 (u, v, 1)가 입력되면, 다음 (수학식9)와 같이 상기 (수학식8)의 비정규화된 호모그래피 행렬을 곱하여, 실 제 3차원 공간 내의 대응하는 점의 로봇의 카메라로부터의 깊이(depth) z를 구할 수 있다. (수학식9)"}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "상기 (수학식9)에서 구해진 깊이 z를 상기 (수학식1)의 우변에 적용하여, 2D 이미지 평면 상의 Ptop 지점 및 Pbottom 지점의 좌표에 대응하는 실제 3차원 공간에 존재하는 Ptop, 3D 지점과 Pbottom, 3D 지점의 좌표를 구할 수 있고, 해당 좌표 간의 높이 차를 이용하여 실제 공간에 대한 높이를 구할 수 있다. 이와 같은 방식으로 바닥면 의 선분과 천장면의 선분 사이의 모든 높이를 계산하여 결정할 수 있다. 이상의 도 2 내지 도 6을 참조하여 설명한 방식으로 2차원 건축 도면으로 3차원 건축 도면을 형성할 수 있다. 이와 같이 형성된 3차원 건축 도면은 실제 주행하는 실내 로봇에 저장되고, 해당 로봇은 내장된 카메라로 촬영 한 영상과 3차원 건축 도면을 비교하여 자기의 현재 위치를 측정할 수 있다 도 7은 본 발명의 일 실시예에 따른 로봇의 구성을 나타낸 도면이다. 도 7을 참조하면, 본 발명의 일 실시예에 따른 로봇은, 버스(BUS)를 통해 통신하는 프로세서, 메모리, 카메라, 저장 장치, 센 서 그리고 구동 장치를 포함한다. 프로세서는 로봇의 동작을 제어하는 장치로서, 프로그램에 포 함된 명령들을 처리하는 다양한 형태의 프로세서일 수 있고, 예를 들면, CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 등 일 수 있다. 또 는, 프로세서는 메모리 또는 저장 장치에 저장된 명령을 실행하는 반도체 장치일 수 있다. 프로세서 는, 이후 설명할 로봇의 기능들 및 방법을 실행하도록 구성될 수 있다. 프로세서는, 저장 장치에 저장된 3차원 건축 도면을 이용하여 로봇의 실내 공간의 주행을 제어한다. 프로세서는, 로봇이 공간을 주행하면서 센서를 통해 다양한 장애물들이 센싱되면, 센싱한 장애물들 중 정적 장애물들에 대한 정보를 반영하여 3차원 건축 도면을 갱신할 수도 있다. 프로세서는, 3차원 건축 도면을 이용하여 센서가 센싱한 장애물이 동적 장애물인지 정적 장애물인지 구별할 수 있다. 3차원 건축 도면은 복수의 격자로 구성되고 각 격자에 점유도 값이 매핑될 수 있다. 프로세서 는, 장애물이 여러 개인 경우 각각의 장애물을 구별하고, 각 장애물의 위치를 추정할 수 있다. 또한, 프로 세서는, 위치를 추정한 각 동적 장애물과의 충돌 예측 시점을 계산하고, 충돌 예측 시점을 기초로 충돌 확 률을 계산하며, 충돌 확률을 토대로 로봇이 동적 장애물에 충돌하지 않을 속도를 계산하고, 동적 장애물을 회피 할 회피 경로를 생성할 수 있다. 메모리는, 다양한 형태의 휘발성 또는 비휘발성 저장 매체를 포함할 수 있다. 예를 들어, 메모리는, 본 발명의 동작을 실행하도록 기술된 명령들이 프로세서에 의해 처리되도록 해당 프로그램을 로드하며, ROM(read only memory) 및 RAM(random access memory)를 포함할 수 있다. 본 발명의 실시예에서 메모리는 프로세서의 내부 또는 외부에 위치할 수 있고, 메모리는, 이미 알려진 다양한 수단을 통해 프로세서 와 연결될 수 있다. 센서는, 본 발명의 동작에 따라 주행 중인 로봇이 정보를 수집하는 다양한 장비 (예를 들어, 라이다, 관성 측정 장치(IMU: Inertial Measurement Unit) 등)들을 포함할 수 있다. 프로세서는, 카메라에서 얻어진 이미지에서 공간을 구성하는 선분 정보를 추출하고, 추출된 선분 정 보와 3차원 건축 도면 상의 선분을 비교하여 로봇의 현재 위치를 측정한다. 여기서 카메라는 2D RGB 카메 라일 수 있다. 일 실시예에서, 카메라에서 얻어진 이미지에서 공간을 구성하는 선분 정보를 추출하는 수단 으로서, 미리 학습된 인공지능 신경망 모델, 보다 구체적으로 학습된 오토인코더(Autoencoder) 및 RCLCM(Reinforced Capture Large Context Module)을 이용할 수 있다. 도 8은 본 발명의 일 실시예에 따른 카메라의 이미지에서 공간을 구성하는 선분 정보를 추출하는 인공지능 신경 망 모델의 구조를 나타낸 도면이다. 로봇이 카메라에서 획득한 공간에 대한 RGB 이미지에서 객체(Object) 및 배경에 대한 모든 선분을 추출하여 원본 이미지에 오버레이하여 오토인코더에 입력(input, 830)으 로 넣는다. 이 과정은 해당 장면의 세가지 방향의 상호 직교 선분들을 추정하여 입력함으로써 고도로 복잡한 이 미지 장면에 대한 방향 정보를 사전에 전달할 수 있으며, 이는 네트워크 학습 훈력 속도를 가속화시킬 뿐만 아 니라, 다소 모호한 공간 구조 파악에 대한 정확도를 높이게 된다. 본 실시예에서 활용된 인코더(Encoder)는 Resnet 50 구조의 Full Pre-Activation 기반으로 구성되어 있으 며, 입력 이미지를 16배로 다운 샘플링하여 RCLCM의 입력으로 넣어준다. RCLCM은 atrous 컨볼루션 (convolution)을 병렬적이며 연속적으로 적용하여 Receptive Field(하나의 필터가 커버할 수 있는 이미지 영 역)을 확장시켰으며 이는 이미지에 대해 보다 많은 Context를 파악할 수 있게 된다. 이후 인공지능 신경망 모델 에서는 디코더(Decoder)를 통해 RCLCM의 출력에 대한 업샘플링(Upsampling) 과정을 진행하게 되며, 이때 보다 선명하고 부드러운 공간에 대한 선분을 얻기 위해 인코더(Encoder)에서 따로 저장했던 높은 해 상도의 특징(Feature)을 함께 넣어 적용하게 된다. 바람직하게, 인코더의 각 다운샘플링 과정에서의 특징 을 디코더의 대응하는 각 업생플링 과정에 반영한다. 디코더(Decoder)에서 위의 과정을 모든 완료하 게 되면 출력으로서 2D RGB 카메라에서 얻은 이미지에 대한 공간을 구성하는 축의 선분 정보가 나오게 된다. 프로세서는 2D RGB 카메라에서 얻어진 이미지로부터 획득된 공간을 구성하는 선분 정보와, 저장 장치 에 저장된 3차원 건축 도면의 선분 정보를 비교하여 로봇의 현재 위치를 측정한다. 구체적으로, 프로세서 는, 아래 (수학식10)에 따라 픽셀 거리 합(Pixel Distance Summation)을 통하여 공간에 대한 일치도 평가 를 진행한다. 프로세서는, 아래 (수학식10)에 따라 계산한 값 , 즉 3차원 건축 도면을 구성하는 선분( )과 2D RGB 카메라에서 얻은 이미지에서 추론한 공간을 구성하는 선분(z)의 사이의 거리 합 (즉, 두 선분의 대응 픽셀 간 거리의 합), 사전에 설정한 임계치 이내인 경우, 3차원 건축 도면에서 로봇의 위 치 x가 실제 로봇 위치인 것으로 판단할 수 있다. 또는, 프로세서는, 3차원 건축 도면을 구성하는 선분 ( )과 2D RGB 카메라에서 얻은 이미지에서 추론한 공간을 구성하는 선분(z) 사이의 거리 합이 가장 짧은 3차원 건축 도면 상의 위치 x를 로봇의 위치로 결정한다. (수학식10)"}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서 z는 2D 카메라에서 얻은 공간을 구성하는 선분, x는 3차원 건축 도면에서 로봇의 위치, σ는 z에서 노이즈를 보정하기 위한 상수, 는 픽셀 거리의 과도한 down-weighing을 막기 위한 상수, Fx는 3차원 건축 도 면을 구성하는 선분들, 는 Fx 중 3차원 건축 도면에서 z와 대응하는 선분을 의미한다. 도 9는 본 발명의 일 실시예에 따른 로봇의 카메라로 촬영된 이미지와 3차원 건축 도면의 선분을 비교한 예를 나타낸다. 카메라로 촬영된 이미지와 가장 일치하는 선분 구조를 보이는 3차원 건축 도면 상의 위치가 로 봇의 실제 위치로 결정된다. 도 10은 본 발명의 일 실시예에 따른 2차원 건축 도면으로부터 3차원 건축 도면을 생성하는 방법을 설명하는 흐 름도이다. 도 10을 참조하면, 단계 S1001에서, 3차원 건축 도면 생성장치는, 2차원 건축 도면을 수신한다. 2차원 건 축 도면은, 다양한 입력 수단을 통해 수신될 수 있다. 예를 들어, USB 저장장치로부터 2차원 건축 도면을 수신 하거나, 또는 원격지의 서버나 원격지 저장장치로부터 2차원 건축 도면을 수신할 수 있다. 단계 S1002에서, 3차원 건축 도면 생성장치는, 상기 2차원 건축 도면을 바이너리 이미지로 변경한 후, 바 이너리 이미지를 이용하여 각 코너 지점을 검출한다. 예를 들어, Harris Corner 알고리즘을 이용할 수 있다. 3 차원 건축 도면 생성장치는, 모든 코너 지점에 대한 점의 집합(Cx)을 중복없이 구성한다. 단계 S1003에서, 3차원 건축 도면 생성장치는, 상기 2차원 건축 도면 내에서 가상 로봇을 배치하고, 가상 로봇을 주행시키며 가상 로봇에 설치된 카메라의 화각 정보를 기초로 가상의 광선을 발사하여, 벽면에 대한 바 닥면 선분을 검출한다. 3차원 건축 도면 생성장치는, 바닥면 선분을 구성하는 점에 대한 집합(Fx) 정보를 산출한다. 3차원 건축 도면 생성장치는, 2차원 건축 도면 상에서 가상 로봇의 위치를 중심으로 광선을 순 차적으로 발사하여 가시권에 들어오는 2차원 건축 도면 상에서의 벽면에 대한 바닥면 선분을 구성하는 점에 대 한 집합(Fx) 정보를 얻어 벽면에 대한 바닥면 선분을 구성할 수 있다. 단계 S1004에서, 3차원 건축 도면 생성장치는, 상기 검출된 각 코너 지점에 대한 점의 집합(Cx)과, 상기 검출한 바닥면 선분에 대한 점의 집합(Fx)을 기초로 2차원 건축 도면을 3차원 건축 도면으로 생성한다. 구체적으로, 3 차원 건축 도면 생성장치는, 바닥 선분에 대한 점의 집합(Fx)을 바탕으로 교차하는 점이 있는지 확인한 후, 해당 교차점이 2차원 건축 도면 상의 코너 지점에 대한 점의 집합(Cx)에 속하는지 확인한다. 해당 교차점이 2차원 건 축 도면 상의 코너 지점에 대한 점의 집합(Cx)에 속하는 경우, 바닥면을 구성하는 선분을 프로젝션하여 천장면을 형성한다. 그리고, 3차원 건축 도면 생성장치는, 먼저, 바닥면의 코너 지점과, 프로젝션된 천장면의 코너 지점 을 이어서 벽면이 교차하는 수직 모서리의 선분을 형성하고, 미리 학습된 3D 좌표 추정 모델 및 상기 (수학식 1)을 이용하여, 바닥면의 선분과 천장면의 선분 사이이 높이를 계산하여 최종적으로 3차원 건축 도면을 생성한 다. 도 11은 본 발명의 일 실시예에 따른 로봇이 자기 위치를 측정하는 방법을 설명하는 흐름도이다. 도 11을 참조하면, 단계 S1101에서, 로봇은 카메라에서 얻어진 이미지에서 공간을 구성하는 선분 정보를 추출한다. 여기서 카메라는 2D RGB 카메라일 수 있다. 일 실시예에서, 카메라에서 얻어진 이미지에서 공간을 구성하는 선분 정보를 추출하는 수단으로서, 미리 학습된 인공지능 신경망 모델을 사용한다. 미리 학습 된 인공지능 신경망 모델은 앞에서 자세히 설명하였으므로 여기서는 설명을 생략한다. 단계 S1102에서, 로봇은 2D RGB 카메라에서 얻어진 이미지로부터 획득된 공간을 구성하는 선분 정보와, 저 장 장치에 저장된 3차원 건축 도면의 선분 정보를 비교하여 로봇의 현재 위치를 측정한다. 구체적으로, 로 봇은, 상기 (수학식10)에 따라 픽셀 거리 합(Pixel Distance Summation)을 통하여 공간에 대한 일치도 평가를 진행한다. 로봇은, 상기 (수학식10)에 따라 계산한 값 , 즉 3차원 건축 도면을 구성하는 선분 ( )과 2D RGB 카메라에서 얻은 이미지에서 추론한 공간을 구성하는 선분(z)의 거리의 합이, 사전에 설정한 임계치 이내인 경우, 3차원 건축 도면에서 로봇의 위치 x가 실제 로봇 위치인 것으로 판단할 수 있다. 또는, 로봇은, 3차원 건축 도면을 구성하는 선분( )과 2D RGB 카메라에서 얻은 이미지에서 추론한 공간을 구성하는 선분(z)의 거리의 합이 가장 짧은 3차원 건축 도면 상의 위치 x를 로봇의 위치로 결정한다. 본 명세서는 많은 특징을 포함하는 반면, 그러한 특징은 본 발명의 범위 또는 특허청구범위를 제한하는 것으로 해석되어서는 안 된다. 또한, 본 명세서에서 개별적인 실시예에서 설명된 특징들은 단일 실시예에서 결합되어 구현될 수 있다. 반대로, 본 명세서에서 단일 실시예에서 설명된 다양한 특징들은 개별적으로 다양한 실시예에 서 구현되거나, 적절히 결합되어 구현될 수 있다. 도면에서 동작들이 특정한 순서로 설명되었으나, 그러한 동작들이 도시된 바와 같은 특정한 순서로 수행되는 것으로, 또는 일련의 연속된 순서, 또는 원하는 결과를 얻기 위해 모든 설명된 동작이 수행되는 것으로 이해되어 서는 안 된다. 특정 환경에서 멀티태스킹 및 병렬 프로세싱이 유리할 수 있다. 아울러, 상술한 실시예에서 다양 한 시스템 구성요소의 구분은 모든 실시예에서 그러한 구분을 요구하지 않는 것으로 이해되어야 한다. 상술한 프로그램 구성요소 및 시스템은 일반적으로 단일 소프트웨어 제품 또는 멀티플 소프트웨어 제품에 패키지로 구 현될 수 있다. 상술한 바와 같은 본 발명의 방법은 프로그램으로 구현되어 컴퓨터로 읽을 수 있는 형태로 기록매체(시디롬, 램, 롬, 플로피 디스크, 하드 디스크, 광자기 디스크 등)에 저장될 수 있다. 이러한 과정은 본 발명이 속하는"}
{"patent_id": "10-2023-0095617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있으므로 더 이상 상세히 설명하지 않기로 한다.이상에서 설명한 본 발명은, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 있어 본 발명의 기술적 사상을 벗어나지 않는 범위 내에서 여러 가지 치환, 변형 및 변경이 가능하므로 전술한 실시예 및 첨부된 도면 에 의해 한정되는 것이 아니다."}
{"patent_id": "10-2023-0095617", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 3차원 건축 도면 생성장치의 구성을 나타낸 도면이다. 도 2는 본 발명의 일 실시예에 따른 2차원 건축 도면의 코너 지점을 검출한 예이다. 도 3은 본 발며의 일 실시예에 따른 2차원 건축 도면으로부터 바닥 선분을 검출하는 예를 나타낸 도면이다. 도 4는 본 발명의 일 실시예에 따른 2차원 건축 도면에서 가상 로봇의 가시권에 있는 바닥 선분 및 코너 지점을 나타낸다. 도 5는 본 발명의 일 실시예에 따른 천장면을 형성하는 예를 나타낸다. 도 6은 본 발명의 일 실시예에 따른 3차원 공간과 로봇의 카메라에서 촬영되는 2D 이미지 그리고 이들의 대응 관계를 나타낸 도면이다. 도 7은 본 발명의 일 실시예에 따른 로봇의 구성을 나타낸 도면이다. 도 8은 본 발명의 일 실시예에 따른 카메라의 이미지에서 공간을 구성하는 선분 정보를 추출하는 인공지능 신경망 모델의 구조를 나타낸 도면이다. 도 9는 본 발명의 일 실시예에 따른 로봇의 카메라로 촬영된 이미지와 3차원 건축 도면의 선분을 비교한 예를 나타낸다. 도 10은 본 발명의 일 실시예에 따른 2차원 건축 도면으로부터 3차원 건축 도면을 생성하는 방법을 설명하는 흐 름도이다. 도 11은 본 발명의 일 실시예에 따른 로봇이 자기 위치를 측정하는 방법을 설명하는 흐름도이다."}
