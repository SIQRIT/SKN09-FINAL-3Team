{"patent_id": "10-2022-0178992", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0098199", "출원번호": "10-2022-0178992", "발명의 명칭": "다중 센서 환경에서 이중 쿼리를 이용한 딥러닝 기반 센서융합 정보 생성 방법 및 시스템", "출원인": "한양대학교 산학협력단", "발명자": "최준원"}}
{"patent_id": "10-2022-0178992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "융합정보 생성 시스템에 의해 수행되는 딥러닝 기반 센서융합 정보 생성 방법에 있어서,다중 센서 환경에서 서로 다른 센서 데이터에 대해 딥 뉴럴 네트워크를 통해 각각의 특징지도를 획득하는 단계;및 상기 획득된 각각의 특징지도를 각 센서 별 좌표계에 따라 특징지도 융합 과정을 통해 다중센서 융합 특징지도를 생성하는 단계를 포함하는 딥러닝 기반 센서융합 정보 생성 방법."}
{"patent_id": "10-2022-0178992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 각각의 특징지도를 획득하는 단계는,카메라, 라이다, 레이다를 포함하는 다중 센서 중 두 개의 센서로부터 획득된 각각의 센서 데이터에 대해 딥 뉴럴 네트워크를 통해 각각의 특징지도를 획득하는 단계를 포함하는 딥러닝 기반 센서융합 정보 생성 방법."}
{"patent_id": "10-2022-0178992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 각각의 특징지도를 획득하는 단계는,제1 센서로부터 획득된 포인트들을 3차원 격자구조를 이용하여 구분하고, 상기 구분된 3차원 격자구조의 포인트들을 인코딩하여 제1 센서 좌표계 기준의 특징지도를 획득하는 단계를 포함하고,상기 제1 센서는, 라이다인 것을 특징으로 하는 딥러닝 기반 센서융합 정보 생성 방법."}
{"patent_id": "10-2022-0178992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 각각의 특징지도를 획득하는 단계는,제2 센서로부터 취득한 영상 데이터에 대해 제2 센서 좌표계 기준의 특징지도를 획득하는 단계를 포함하고,상기 제2 센서는, 카메라인 것을 특징으로 하는 딥러닝 기반 센서융합 정보 생성 방법."}
{"patent_id": "10-2022-0178992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 다중센서 융합 특징지도를 생성하는 단계는,상기 획득된 각각의 특징지도에 대해 게이팅 네트워크를 이용한 1차 다중센서 융합을 통해 강화된 특징지도를획득하는 단계 를 포함하는 딥러닝 기반 센서융합 정보 생성 방법."}
{"patent_id": "10-2022-0178992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2024-0098199-3-제5항에 있어서,상기 1차 다중센서 융합은, 상기 획득된 각각의 특징지도를 픽셀 별로 합한 후(element-wise summation), 컨볼루션 뉴럴 네트워크와 시그모이드 함수를 통과시켜 어텐션 지도(attention map)를 획득하고, 상기 획득된 각각의 특징지도에 상기 획득된 어텐션 지도를 픽셀 별로 곱하여(element-wise multiplication) 강화된 특징지도를획득하는 것을 특징으로 하는 딥러닝 기반 센서융합 정보 생성 방법."}
{"patent_id": "10-2022-0178992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 획득된 각각의 특징지도는, 라이다의 특징지도 및 카메라의 특징지도를 포함하고, 상기 다중센서 융합 특징지도를 생성하는 단계는,상기 라이다로부터 획득된 3차원 격자구조의 데이터를 카메라 좌표계로 정사영하여 카메라 좌표계의 라이다 특징지도를 획득하는 단계를 포함하는 딥러닝 기반 센서융합 정보 생성 방법."}
{"patent_id": "10-2022-0178992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 다중센서 융합 특징지도를 생성하는 단계는,상기 획득된 카메라 좌표계의 라이다 특징지도와 카메라 특징지도를 1차 다중 센서 융합을 통해 강화된 카메라특징지도를 획득하는 단계를 포함하는 딥러닝 기반 센서융합 정보 생성 방법."}
{"patent_id": "10-2022-0178992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제5항에 있어서,상기 다중센서 융합 특징지도를 생성하는 단계는,상기 획득된 각각의 특징지도에 대해 2차 다중센서 융합을 통해 다중센서 융합 특징지도를 생성하는 단계를 포함하는 딥러닝 기반 센서융합 정보 생성 방법."}
{"patent_id": "10-2022-0178992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 트랜스포머 네트워크는, 이중 쿼리를 이용하여 셀프 어텐션과 교차 어텐션으로 구성된 복수 개의 레이어를반복하는 구조로 구성된 것을 특징으로 하는 딥러닝 기반 센서융합 정보 생성 방법."}
{"patent_id": "10-2022-0178992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 다중센서 융합 특징지도를 생성하는 단계는,강화된 카메라 특징지도와 라이다 정보에 대해 트랜스포머 네트워크 기반의 융합 네트워크를 이용한 2차 다중센서 융합을 통해 다중센서 융합 특징지도를 생성하는 단계를 포함하는 딥러닝 기반 센서융합 정보 생성 방법."}
{"patent_id": "10-2022-0178992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 다중센서 융합 특징지도를 생성하는 단계는,3차원 격자구조의 라이다 특징지도 값을 라이다 쿼리의 특징값으로 정의하고, 상기 정의된 라이다 쿼리의3차원공개특허 10-2024-0098199-4-좌표값을 카메라 좌표계에 정사영한 위치의 카메라 특징지도 값을 이미지 쿼리로 사용하여 이중 쿼리를 구성하는 단계를 포함하는 딥러닝 기반 센서융합 정보 생성 방법."}
{"patent_id": "10-2022-0178992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 다중센서 융합 특징지도를 생성하는 단계는,상기 라이다 쿼리를 3차원 격자구조의 데이터 간의 관계성을 강화하기 위해 단일 센서 네트워크에 통과시키는단계를 포함하는 딥러닝 기반 센서융합 정보 생성 방법."}
{"patent_id": "10-2022-0178992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 다중센서 융합 특징지도를 생성하는 단계는,상기 라이다 쿼리와 상기 이미지 쿼리를 다중 센서 어텐션 네트워크에 통과시키는 단계 를 포함하는 딥러닝 기반 센서융합 정보 생성 방법."}
{"patent_id": "10-2022-0178992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "융합정보 생성 시스템에 있어서, 다중 센서 환경에서 서로 다른 센서 데이터에 대해 딥 뉴럴 네트워크를 통해 각각의 특징지도를 획득하는 특징지도 획득부; 및 상기 획득된 각각의 특징지도를 각 센서 별 좌표계에 따라 특징지도 융합 과정을 통해 다중센서 융합 특징지도를 생성하는 융합 특징지도 생성부를 포함하는 융합정보 생성 시스템."}
{"patent_id": "10-2022-0178992", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다중 센서 환경에서 이중 쿼리를 이용한 딥러닝 기반 센서융합 정보 생성 방법 및 시스템이 개시된다. 일 실시 예에 따른 융합정보 생성 시스템에 의해 수행되는 딥러닝 기반 센서융합 정보 생성 방법은, 다중 센서 환경에서 서로 다른 센서 데이터에 대해 딥 뉴럴 네트워크를 통해 각각의 특징지도를 획득하는 단계; 및 상기 획득된 각각 의 특징지도를 각 센서 별 좌표계에 따라 특징지도 융합 과정을 통해 다중센서 융합 특징지도를 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0178992", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 센서융합 정보를 생성하는 기술에 관한 것이다."}
{"patent_id": "10-2022-0178992", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥러닝을 기반으로 한 물체 인지 기법은 주로 단일 센서로부터 취득된 데이터를 딥 뉴럴 네트워크에 통과시켜 인지 결과를 얻게 된다. 하지만 단일 센서를 이용하는 경우, 단일 센서에 대한 의존성이 매우 커지므로 센서 데이터의 특성상 특정 원인으로 인해 부정확한 상황(예를 들면, 강한 빛에 의한 카메라 센서 오류, 습도로 인한 라이다 센서 오류, 거리가 먼 물체에 대한 라이다 포인트의 희소성 등)에 직면했을 때 인지 정확도가 매우 부정 확해진다. 이러한 단일 센서 인지 기법의 한계를 해결하기 위해 다중 센서를 입력으로 받는 센서융합 기반의 물체 인지 기법들이 제안되었다. 하지만, 종래의 다중 센서 융합 기반의 물체 인지 기법은 서로 다른 센서 데 이터의 경우 센서 데이터가 서로 다른 좌표계에서 서로 다른 정보 분포를 가지는 데이터로 표현이 되기 때문에 서로 다른 데이터 간의 상관성을 충분히 높이는 융합이 어렵다는 문제가 있다. 후보 단계 방식의 경우 후보를 단일 센서에서 추출하기 때문에 후보를 뽑는 센서에 대한 의존성이 커지고, 포인트 단계 융합 방식은 라이다 센 서의 거리가 멀어짐에 따라 가지는 라이다 포인트의 희소성이라는 문제를 그대로 가지고 있다는 문제가 있다. 또한, 기존의 특징값 융합 방식은 특성이 서로 다른 데이터를 단순히 좌표계 정사영을 통한 센서 데이터 융합으 로 진행되기 때문에 데이터 간의 상관성을 높이기 힘들다. 따라서, 서로 다른 좌표계로 표현되며 다른 특성을 가지는 데이터 간의 상관성을 충분히 고려하여 융합하여 보다 정확하고 강인한 물체 검출, 인식이 되도록 하는방법이 필요하다."}
{"patent_id": "10-2022-0178992", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "다중 센서 데이터에 대해 딥 뉴럴 네트워크를 통해 각각의 특징지도를 획득하고, 획득된 각각의 특징지도를 이 중 쿼리를 이용한 특징지도 융합 과정을 통해 다중센서 융합 특징지도를 생성하는 방법 및 시스템을 제공할 수 있다."}
{"patent_id": "10-2022-0178992", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "융합정보 생성 시스템에 의해 수행되는 딥러닝 기반 센서융합 정보 생성 방법은, 다중 센서 환경에서 서로 다른 센서 데이터에 대해 딥 뉴럴 네트워크를 통해 각각의 특징지도를 획득하는 단계; 및 상기 획득된 각각의 특징지 도를 각 센서 별 좌표계에 따라 특징지도 융합 과정을 통해 다중센서 융합 특징지도를 생성하는 단계를 포함할 수 있다. 상기 각각의 특징지도를 획득하는 단계는, 카메라, 라이다, 레이다를 포함하는 다중 센서 중 두 개의 센서로부 터 획득된 각각의 센서 데이터에 대해 딥 뉴럴 네트워크를 통해 각각의 특징지도를 획득하는 단계를 포함할 수 있다. 상기 각각의 특징지도를 획득하는 단계는, 제1 센서로부터 획득된 포인트들을 3차원 격자구조를 이용하여 구분 하고, 상기 구분된 3차원 격자구조의 포인트들을 인코딩하여 제1 센서 좌표계 기준의 특징지도를 획득하는 단계 를 포함하고, 상기 제1 센서는, 라이다일 수 있다. 상기 각각의 특징지도를 획득하는 단계는, 제2 센서로부터 취득한 영상 데이터에 대해 제2 센서 좌표계 기준의 특징지도를 획득하는 단계를 포함하고, 상기 제2 센서는, 카메라일 수 있다. 상기 다중센서 융합 특징지도를 생성하는 단계는, 상기 획득된 각각의 특징지도에 대해 게이팅 네트워크를 이용 한 1차 다중센서 융합을 통해 강화된 특징지도를 획득하는 단계를 포함할 수 있다. 상기 1차 다중센서 융합은, 상기 획득된 각각의 특징지도를 픽셀 별로 합한 후(element-wise summation), 컨볼 루션 뉴럴 네트워크와 시그모이드 함수를 통과시켜 어텐션 지도(attention map)를 획득하고, 상기 획득된 각각 의 특징지도에 상기 획득된 어텐션 지도를 픽셀 별로 곱하여(element-wise multiplication) 강화된 특징지도를 획득할 수 있다. 상기 획득된 각각의 특징지도는, 라이다의 특징지도 및 카메라의 특징지도를 포함하고, 상기 다중센서 융합 특 징지도를 생성하는 단계는, 상기 라이다로부터 획득된 3차원 격자구조의 데이터를 카메라 좌표계로 정사영하여 카메라 좌표계의 라이다 특징지도를 획득하는 단계를 포함할 수 있다. 상기 다중센서 융합 특징지도를 생성하는 단계는, 상기 획득된 카메라 좌표계의 라이다 특징지도와 카메라 특징 지도를 1차 다중 센서 융합을 통해 강화된 카메라 특징지도를 획득하는 단계를 포함할 수 있다. 상기 다중센서 융합 특징지도를 생성하는 단계는, 상기 획득된 각각의 특징지도에 대해 2차 다중센서 융합을 통 해 다중센서 융합 특징지도를 생성하는 단계를 포함할 수 있다. 상기 트랜스포머 네트워크는, 이중 쿼리를 이용하여 셀프 어텐션과 교차 어텐션으로 구성된 복수 개의 레이어를 반복하는 구조로 구성된 것일 수 있다. 상기 다중센서 융합 특징지도를 생성하는 단계는, 강화된 카메라 특징지도와 라이다 정보에 대해 트랜스포머 네 트워크 기반의 융합 네트워크를 이용한 2차 다중 센서 융합을 통해 다중센서 융합 특징지도를 생성하는 단계를 포함할 수 있다. 상기 다중센서 융합 특징지도를 생성하는 단계는, 3차원 격자구조의 라이다 특징지도 값을 라이다 쿼리의 특징 값으로 정의하고, 상기 정의된 라이다 쿼리의3차원 좌표값을 카메라 좌표계에 정사영한 위치의 카메라 특징지도 값을 이미지 쿼리로 사용하여 이중 쿼리를 구성하는 단계를 포함할 수 있다. 상기 다중센서 융합 특징지도를 생성하는 단계는, 상기 라이다 쿼리를 3차원 격자구조의 데이터 간의 관계성을 강화하기 위해 단일 센서 네트워크에 통과시키는 단계를 포함할 수 있다. 상기 다중센서 융합 특징지도를 생성하는 단계는, 상기 라이다 쿼리와 상기 이미지 쿼리를 다중 센서 어텐션 네 트워크에 통과시키는 단계를 포함할 수 있다. 융합정보 생성 시스템은, 다중 센서 환경에서 서로 다른 센서 데이터에 대해 딥 뉴럴 네트워크를 통해 각각의 특징지도를 획득하는 특징지도 획득부; 및 상기 획득된 각각의 특징지도를 각 센서 별 좌표계에 따라 특징지도 융합 과정을 통해 다중센서 융합 특징지도를 생성하는 융합 특징지도 생성부를 포함할 수 있다."}
{"patent_id": "10-2022-0178992", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "다중 센서 데이터를 입력으로 딥러닝 기법을 이용한 물체 검출 수행 시 각 좌표계에서 특징지도 융합을 통해 검 출 성능을 향상시킬 수 있다. 카메라 센서 데이터와 라이다 센서를 각각 딥 뉴럴 네트워크에 통과시키고 1차적으로 카메라 센서 좌표계에서 센서 융합을 진행한 후 2차적으로 라이다 센서 좌표계에서 센서 융합을 진행함으로써 특성이 다른 센서 데이터 간의 상관성을 점진적으로 향상시켜 다양한 분야에 효과적인 다중센서 융합 특징지도를 획득할 수 있게 된다. 최근 스마트 홈, 자율주행, 무인로봇 환경에서는 카메라 센서와 라이다 센서 등의 다중 센서 데이터를 이용하여 물체 검출을 수행할 때 활용될 것으로 예상된다. 다중 센서를 입력으로 주변 물체와 환경에 대한 이해를 효과적으로 수행할 수 있는 해결책을 제시하며, 다중 센 서를 이용하는 다양한 인공지능 기술에 적용이 가능하다."}
{"patent_id": "10-2022-0178992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 실시예를 첨부한 도면을 참조하여 상세히 설명한다. 실시예에서는 자율주행 또는 로봇 시스템에서 사용되는 다중 센서를 이용한 딥러닝 환경에서 작동하는 이중 쿼 리 기반 센서 융합 정보 생성 동작에 대하여 설명하기로 한다. 다중 센서 환경은 센서마다 서로 다른 좌표계와 다른 정보 특성을 가지고 있어 센서 정보 간의 간극을 완화시켜 센서 간의 정보를 융합하는 것이 가장 중요한 부분이다. 기존의 딥러닝 기반 다중 센서 3차원 물체 검출 기술은 단순히 특정 센서를 주 센서로 사용하고 다 른 센서를 보조 센서로 사용하는데 단순히 보조 센서를 주 센서에 옮김으로써 센서 데이터를 융합하였다. 결과 적으로 기존의 방식은 센서 데이터 간의 서로 다른 특성을 충분히 고려하지 못해 센서 정보 간의 상관성을 높이 지 못하였기 때문에 다중 센서 환경의 잠재력을 충분히 끌어내지 못하였다. 이러한 문제점을 해결하기 위하여, 센서 별로 쿼리를 할당하는 이중 쿼리를 이용해 센서의 특성을 고려하여 센서 간의 상관성을 단계적으로 끌어올 리는 융합 특징지도 생성 동작에 대하여 설명하기로 한다. 도 1은 일 실시예에 있어서, 융합정보 생성 시스템의 구성을 설명하기 위한 블록도이고, 도 2는 일 실시예에 있 어서, 딥러닝 기반 센서융합 정보 생성 방법을 설명하기 위한 흐름도이다. 융합정보 생성 시스템의 프로세서는 특징지도 획득부 및 융합 특징지도 생성부를 포함할 수 있 다. 이러한 프로세서의 구성요소들은 융합정보 생성 시스템에 저장된 프로그램 코드가 제공하는 제어 명령에따라 프로세서에 의해 수행되는 서로 다른 기능들(different functions)의 표현들일 수 있다. 프로세서 및 프 로세서의 구성요소들은 도 2의 딥러닝 기반 센서융합 정보 생성 방법이 포함하는 단계들(210 내지 220)을 수행 하도록 융합정보 생성 시스템을 제어할 수 있다. 이때, 프로세서 및 프로세서의 구성요소들은 메모리가 포함하 는 운영체제의 코드와 적어도 하나의 프로그램의 코드에 따른 명령(instruction)을 실행하도록 구현될 수 있다. 프로세서는 딥러닝 기반 센서융합 정보 생성 방법을 위한 프로그램의 파일에 저장된 프로그램 코드를 메모리에 로딩할 수 있다. 예를 들면, 융합정보 생성 시스템에서 프로그램이 실행되면, 프로세서는 운영체제의 제어에 따라 프로그램의 파일로부터 프로그램 코드를 메모리에 로딩하도록 융합정보 생성 시스템을 제어할 수 있다. 이때, 특징지도 획득부 및 융합 특징지도 생성부 각각은 메모리에 로딩된 프로그램 코드 중 대응하는 부분의 명령을 실행하여 이후 단계들(210 내지 220)을 실행하기 위한 프로세서의 서로 다른 기능적 표현들일 수 있다. 단계에서 특징지도 획득부는 다중 센서 환경에서 서로 다른 센서 데이터에 대해 딥 뉴럴 네트워크를 통해 각각의 특징지도를 획득할 수 있다. 특징지도 획득부는 카메라, 라이다, 레이다를 포함하는 다중 센 서 중 두 개의 센서로부터 획득된 각각의 센서 데이터에 대해 딥 뉴럴 네트워크를 통해 각각의 특징지도를 획득 할 수 있다. 특징지도 획득부는 제1 센서로부터 획득된 포인트들을 3차원 격자구조를 이용하여 구분하고, 구분된 3차원 격자구조의 포인트들을 인코딩하여 제1 센서 좌표계 기준의 특징지도를 획득할 수 있다. 특징지 도 획득부는 제2 센서로부터 취득한 영상 데이터에 대해 제2 센서 좌표계 기준의 특징지도를 획득할 수 있 다. 이때, 제1 센서는, 라이다, 제2 센서는 카메라일 수 있다. 단계에서 융합 특징지도 생성부는 획득된 각각의 특징지도를 각 센서별 좌표계에 따라 특징지도 융합 과정을 통해 다중센서 융합 특징지도를 생성할 수 있다. 융합 특징지도 생성부는 획득된 각각의 특징지도 에 대해 게이팅 네트워크를 이용한 1차 다중센서 융합을 통해 강화된 특징지도를 획득할 수 있다. 이때, 획득 된 각각의 특징지도는, 라이다의 특징지도 및 카메라의 특징지도를 포함할 수 있다. 융합 특징지도 생성부 는 라이다로부터 획득된 3차원 격자구조의 데이터를 카메라 좌표계로 정사영하여 카메라 좌표계의 라이다 특징지도를 획득할 수 있다. 융합 특징지도 생성부는 획득된 카메라 좌표계의 라이다 특징지도와 카메라 특징지도를 1차 다중 센서 융합을 통해 강화된 카메라 특징지도를 획득할 수 있다. 융합 특징지도 생성부(12 0)는 획득된 각각의 특징지도에 대해 2차 다중센서 융합을 통해 다중센서 융합 특징지도를 생성할 수 있다. 융 합 특징지도 생성부는 강화된 카메라 특징지도와 라이다 정보에 대해 트랜스포머 네트워크 기반의 융합 네 트워크를 이용한 2차 다중 센서 융합을 통해 다중센서 융합 특징지도를 생성할 수 있다. 융합 특징지도 생성부 는 3차원 격자구조의 라이다 특징지도 값을 라이다 쿼리의 특징값으로 정의하고, 정의된 라이다 쿼리의3차 원 좌표값을 카메라 좌표계에 정사영한 위치의 카메라 특징지도 값을 이미지 쿼리로 사용하여 이중 쿼리를 구성 할 수 있다. 융합 특징지도 생성부는 라이다 쿼리에서 3차원 격자구조의 데이터 간의 관계성을 강화하기 위해 단일 센서 네트워크에 통과시킬 수 있다. 융합 특징지도 생성부는 라이다 쿼리와 이미지 쿼리를 다 중 센서 어텐션 네트워크에 통과시킬 수 있다. 도 3은 일 실시예에 있어서, 다중 센서 데이터를 융합하는 동작을 설명하기 위한 도면이다. 융합정보 생성 시스템은 카메라, 라이다, 레이다 등의 다중 센서 중 두 가지의 센서 신호를 입력받아 획득한 다 중 센서 신호를 딥 뉴럴 네트워크를 통해 각각 특징지도(feature map)을 획득하고, 획득된 각각의 특징지도를 통합된 쿼리로 융합하여 센서 데이터 간의 상관성을 점진적으로 향상시켜 정확하고 강인한 인지를 수행할 수 있 는 다중센서 융합 특징지도를 생성하기 위한 구조를 포함할 수 있다. 이에, 서로 다른 센서 데이터의 융합을 통해 3차원 물체 검출, 영역 분할을 수행할 수 있다. 융합정보 생성 시스템은 서로 다른 센서 데이터에서 추출 된 특징지도를 각 좌표계에서 특징지도 융합 과정을 통해 점진적으로 상관성을 높이고 하나의 좌표계로 관리할 수 있도록 하는 통합 쿼리를 제공하며 각 센서의 좌표계에서 쿼리 간의 상관성을 향상시켜 융합된 특징지도를 제공하는 모듈을 제공할 수 있다. 보다 상세하게는, 융합정보 생성 시스템은 각각의 센서 데이터를 입력으로 받아 서로 다른 딥 뉴럴 네트워크 (311, 312)를 통과시켜 결과로서 센서 고유의 좌표계에서 표현되는 각각의 특징지도를 획득할 수 있다. 예를 들면, 융합정보 생성 시스템은 카메라, 라이다, 레이다 등의 다중 센서 중 두 가지의 센서 신호를 입력받아 획 득된 다중 센서 신호를 딥 뉴럴 네트워크를 통해 각각의 특징 지도를 획득할 수 있다. 여기서, 카메라의 경우, 카메라 좌표계, 라이다, 레이다의 경우, 3차원 좌표계로 표현될 수 있다. 이러한 특징지도들은 센서마다 다른 좌표계에서 표현되기 때문에 융합에 어려움이 있다. 융합정보 생성 시스템은 두 센서의 좌표계를 번갈아 가며 융합을 진행할 수 있다. 융합정보 생성 시스템은 센 서마다 다른 좌표계에서 각각의 딥 뉴럴 네트워크(311, 312)를 통해 각각의 특징지도를 획득할 수 있다. 융합 정보 생성 시스템은 센서 1의 제1 센서 데이터를 좌표계 변환 행렬을 통해 센서 2의 좌표계에 정사영 하여 제1 특징지도 융합을 수행할 수 있다. 도 5를 참고하면, 제1 특징지도 융합 동작을 설명하기 위한 도면으로, 다중 센서의 각 특징지도를 융합할 때 사용되는 게이팅 구조를 나타낸 것이다. 융합정보 생성 시스템은 센서 별 특징지도(예를 들면, 제1 특징지 도와 제2 특징지도)를 픽셀 별로 합한 후(element-wise summation), 컨볼루션 뉴럴 네트워크와 시그모이드 (sigmoid) 함수를 차례로 통과시켜 어텐션 지도(attention map)를 획득할 수 있다. 어텐션 지도는 네트워크가 스스로 특징지도의 중요한 부분을 찾아 강조시키는 역할을 수행한다. 융합정보 생성 시스템은 센서 별 특징지 도(예를 들면, 제1 특징지도, 제2 특징지도)에 어텐션 지도를 픽셀 별로 곱하여(element-wise multiplication) 중요한 부분이 강조된 센서 별 특징지도(예를 들면, 강화된 제1 특징지도, 강화된 제2 특징지도)를 획득할 수 있다. 게이팅 과정을 식으로 표현하면 다음과 같다."}
{"patent_id": "10-2022-0178992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 센서1의 제1 특징지도, 는 센서2의 제2 특징지도를 나타내고, 는 게이팅 구조를 통과한 특징지도를 나타낸다. 는 시그모이드 함수 를 의미하며, 는 센서2를 센서1의 좌표계로 정사영하는 함수 를 나타내며, 는 연결(concatenate) 연산(채널축 기준으로 특징지도를 쌓음)을 의미한다. 이와 같이, 융합정보 생성 시스템은 센서 1의 정보(제1 센서 데이터)를 좌표계 변환 행렬을 통해 센서 2의 좌표계에 정사영하여 병합(concatenate)하거나 더하거나 다중 센서 게이팅 네트워크를 통과시키 는 제1 특징지도 융합 과정을 통해 센서 2의 제2 특징지도를 강화시킬 수 있다. 이어서, 융합정보 생성 시스템은 강화된 센서 2의 제2 특징지도를 좌표계 변환 행렬을 통해 다시 센서 1로 정사영하고, 다시 센서 1의 제1 특징지도와 제1 센서에 정사영된 제2특징지도에 대해 제2 특징지도 융합 과 정을 통해 최종적으로 다중센서 융합 특징지도를 획득할 수 있다. 이처럼 각 센서 좌표계의 특징지도에 대해서 다른 센서로부터 온 특징지도와 융합 과정을 연이어 거치게 되면 센서의 특징지도 간의 상관성이 점진적 으로 상승하여 더욱 다양한 작업에 유용한 다중센서 융합 특징지도가 획득될 수 있다. 이렇게 얻은 다중 센서 융합 특징지도를 활용하여 3차원 혹은 조감도 기준의 물체 검출 또는 영역 분할 등의 인지 작업이 수행될 수 있다. 도 4는 일 실시예에 있어서, 라이다와 카메라를 이용한 센서 융합 동작을 설명하기 위한 도면이다. 도 4에서는 라이다 정보와 카메라 정보를 융합하여 3차원 물체 검출을 수행하는 구조에 대하여 설명하기로 한다. 먼저, 융합정보 생성 시스템은 카메라 센서로부터 취득된 영상 데이터에 대해 컨볼루션 뉴럴 네트워크 (CNN) 구조를 통해 카메라 좌표계 기준의 특징지도를 획득할 수 있다. 융합정보 생성 시스템은 라이다 센서로 부터 취득된 포인트 클라우드에 대해 3차원 격자구조를 이용하여 나누고, 나눠진 3차원 격자구조의 원소의 점들 을 따로 인코딩하여 라이다 좌표계 기준의 특징지도를 획득할 수 있다. 라이다 센서 신호의 경우, 보통 포인트 의 집합으로 표현될 수 있다. 융합정보 생성 시스템은 1차적으로 좌표계 변환 행렬을 이용하여 라이다 3차원 격자구조 데이터를 카메라 좌표 계로 정사영하여 카메라 좌표계의 라이다 특징지도를 획득할 수 있다. 융합정보 생성 시스템은 카메라 좌표계 의 라이다 특징지도와 카메라 특징지도에 대해 1차 다중 센서 융합(제1 특징지도 융합)을 통해 강화된 카 메라 특징지도를 획득할 수 있다. 융합정보 생성 시스템은 강화된 카메라 특징지도와 라이다 정보에 대해 2차 다중 센서 융합(제2 특징지도 융합)을 통해 다중센서 융합 특징지도를 생성할 수 있다. 2차 다중 센서 융 합(제2 특징지도 융합)은 단일 센서 데이터가 입력되도록 설계된 트랜스포머 네트워크 기반의 융합 네트워 크로 구성되어 다중센서 융합 특징지도를 생성할 수 있다. 트랜스포머 네트워크의 한 레이어는 쿼리를 입력으 로 셀프 어텐션(self-attention) 단계와 교차 어텐션(cross-attention)단계로 구성되며 복수 개(예를 들면, M 개)의 레이어를 반복하는 구조로 구성될 수 있다. 이때, 트랜스포머 네트워크에 구성된 레이어의 개수에 따라셀프 어텐션과 교차 어텐션이 반복될 수 있다. 융합정보 생성 시스템은 라이다의 3차원 격자구조의 라이다 특징지도 값을 라이다 쿼리의 특징값으로 정의하고, 3차원 격자구조의 좌표 위치를 쿼리 위치값으로 가질 수 있다. 융합정보 생성 시스템은 쿼리 위치값을 카메라 좌표계에 정사영한 위치의 카메라 특징지도 값을 가져와 이미지 쿼리로 정의할 수 있다. 융합정보 생성 시스템 은 라이다 쿼리끼리 3차원 데이터 간의 관계성을 강화하기 위한 단일센서 어텐션 네트워크를 통과시키고, 라이다 쿼리와 이미지 쿼리를 입력으로 이미지 특징지도 값을 유동적으로 가져오는 다중 센서 어텐션 네트워크 를 통과시킬 수 있다. 라이다 쿼리와 이미지 쿼리를 입력으로 카메라 특징지도를 유동적으로 가져올 수 있다. 네트워크를 통과한 두 쿼리는 다음 레이어의 단일센서 어텐션 네트워크의 입력으로 사용되게 된다. 복수 번 레이어를 반복하여 획득된 라이다 쿼리는 다중센서 특징값이 융합된 특징지도의 형태를 가지게 되고 추 가적인 네트워크를 통해 3차원 물체 인지를 수행하게 된다. 실시예에서 제안된 딥러닝 기반 센서융합 정보 생성을 위한 각 모듈의 효과가 실험을 통해 입증될 수 있다. nuScenes 물체 검출 데이터셋이 사용될 수 있으며 baseline 모듈로 CenterPoint에 적용하여 실험이 진행될 수 있다. 표 1: nuScenes 검증 데이터셋에서 수행한 딥러닝 기반 센서융합 정보 생성 방법."}
{"patent_id": "10-2022-0178992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "물체 검출 정확도는 nuScenes에서 제공하는 mAP(mean average precision)과 NDS(nuScenes detection score)로 계산될 수 있다. 방법 에서의 결과는 baseline 모듈에 도 4의 2차 다중센서 융합 모듈 중 단일센서 어텐션 네트워크 모듈을 제외하고 사용했을 때의 결과이며 제안한 트랜스포머 기반 모델을 사용했을 때 mAP가 8.3%, NDS가 4.4% 로 크게 향상된 것을 확인할 수 있다. 방법 는 도4의 2차 다중센서 융합 모듈을 모두 사용한 결 과이다. 최종적으로 실시예에서 제안된 딥러닝 기반 센서융합 정보 생성 방법은 도4 의 1차 다중 센서 융합 모 듈을 방법에 추가시켜서 얻은 방식이다. 실시예에서 제안된 딥러닝 기반 센서융합 정보 생성 방법은 종래 기술의 문제점을 다음과 같이 해결할 수 있다. 먼저, 종래의 단일센서만을 이용하는 딥러닝 기반 물체 인지 기술은 하나의 센서에 의존하여 물체 인지 작업을 수행하기 때문에 센서 데이터의 질이 저해되는 경우 인지 결과가 부정확 해질 수 있으나 제안하는 다중 센서 기 반의 융합 특징지도를 통해 물체 인지를 수행하는 경우 센서 정보에 강인한 검출 결과를 얻을 수 있으며, 각각 의 센서의 단점을 보완하는 형태로 융합 정보를 생성하여 물체 인지 성능을 높일 수 있다. 또한, 종래의 다중 센서 기반 물체 인지 기술의 경우 한 가지 좌표계에서만 센서 융합을 진행하기 때문에 정사영을 수행할 경우 센 서 데이터의 정보가 손실될 수 밖에 없었으며 센서 데이터간의 상관성에 대한 고려가 들어가지 않았다. 종래 기술과 비교하여 실시예에서 제안된 2차 다중 센서 데이터 융합 구조를 사용하면 종래의 융합 기법의 한계를 극 복할 수 있다. 실시예에서 제안된 딥러닝 기반 센서융합 정보 생성 방법은 다중 물체 검출, 물체의 움직임 예측 등의 물체 인 지 분야에 적용이 가능하다. 대표적인 적용가능 분야로는 자율주행 자동차, 스마트홈, 그리고 무인 로봇이 있 다. 첫째로, 자율주행 자동차 분야에서 이동하는 자차 주변의 환경과 물체에 대한 인지 정보는 다음 단계인 물 체 경로 예측 및 주행 판단을 위해 필수적으로 선행되어야 하며 안전에 직결되기 때문에 가장 중요한 부분이다. 자율주행 차량에는 기본적으로 카메라, 라이다, 레이다 등 다양한 센서가 장착되어 있기 때문에 제안하는 다중 센서 융합 정보 생성 기술은 물체 인지 정확도를 향상시켜 자율주행 환경의 안정성과 예측 및 판단의 정확도를 향상시킬 수 있다. 두 번째로, 스마트 홈 환경은 스마트 홈에 설치되어있는 카메라나 다른 센서에 의존해서 환 경 인지가 이루어지며 향상된 인지 정보를 바탕으로 제품의 작동 판단에 도움을 줄 수 있다. 세 번째로, 군사 용도나 쇼핑몰 등에 사용되는 무인 로봇의 경우에도 자율주행 차량과 비슷하게 움직이는 로봇의 주변 상황 인지, 예측 및 이동 경로 판단을 수행하게 되는데 무인 로봇에 탑재되어 있는 다중 센서의 데이터를 통해 인지 정확도를 상승시킴으로써 로봇의 안전 및 상호작용을 원활히 수행할 수 있는 기반이 될 수 있다. 실시예에서 제안된 딥러닝 기반 센서융합 정보 생성 방법을 사용하기 위해서 임베디드 시스템에 탑재되어 있는 라이다, 카메라, 레이다 등의 센서를 이용하여 센서 데이터를 실시간으로 취득하고, 취득된 센서 데이터를 그래 픽 프로세서 유닛(GPU)를 통해 다중 센서 정보를 제안하는 기술로 융합 후 인지 알고리즘을 수행할 수 있다.이를 위해서는 미리 다양한 환경에 대한 다중 센서 데이터를 확보한 후 딥 뉴럴 네트워크를 학습시킬 수 있다. 학습을 통해 최적화된 딥 뉴럴 네트워크는 네트워크의 계수를 저장함으로써 학습된 네트워크를 재사용할 수 있 다. 이를 임베디드 시스템에 적용하여 실시간 입력으로 들어오는 다중 센서 데이터에 알고리즘을 사용하여 결 과를 획득하게 된다. 더 나아가, 딥러닝을 이용한 다중 센서 기반의 물체 검출 기술은 현재 스마트홈 카메라나 자율주행, 모바일 로 봇 등에 응용될 수 있으며 향후에 인지를 넘어 물체의 추적 및 물체간의 관계 파악, 환경에 대한 이해를 통한 미래 예측 등 좀 더 복잡한 기능을 수행할 것으로 예상된다. 예를 들면, 스마트 홈 환경에서 다중 센서 정보를 융합하여 센서 데이터의 방해 요소에 강인한 물체 인지 작업을 수행한다면 위험 상황의 예측 및 예방이 가능하 다. 또한, 자율주행 환경에서는 자동화된 감시, 교통 모니터링 등의 고도화된 작업에 이용될 수 있다. 이와 같이 다중센서 융합 기술 기반의 물체 검출 알고리즘은 인간의 안전과 직결되며, 미래 기술에 기초가 되는 기술 로 대표적인 인공지능 기술 중의 하나라고 할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2022-0178992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2022-0178992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5"}
{"patent_id": "10-2022-0178992", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 있어서, 융합정보 생성 시스템의 구성을 설명하기 위한 블록도이다. 도 2는 일 실시예에 있어서, 딥러닝 기반 센서융합 정보 생성 방법을 설명하기 위한 흐름도이다. 도 3은 일 실시예에 있어서, 다중 센서 데이터를 융합하는 동작을 설명하기 위한 도면이다. 도 4는 일 실시예에 있어서, 라이다와 카메라를 이용한 센서 융합 동작을 설명하기 위한 도면이다. 도 5는 일 실시예에 있어서, 제1 특징지도 융합 동작을 설명하기 위한 도면이다."}
