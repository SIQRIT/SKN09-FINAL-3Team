{"patent_id": "10-2024-0130572", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0047183", "출원번호": "10-2024-0130572", "발명의 명칭": "의료 영상을 이용한 다중 장기 암 진단 방법 및 시스템", "출원인": "서울대학교병원", "발명자": "김영곤"}}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "의료 영상을 이용한 다중 장기 암 진단 방법에 있어서, 다중 장기의 의료 영상을 입력받는 단계; 상기 의료 영상를 전처리 하여 복수의 관심 영역 이미지를 생성하는 단계; 다중 작업-다중 인스턴스 학습(Multi-task Multiple Instance Learning, MT-MIL) 모델을 이용하여 상기 복수의관심 영역 이미지로부터 암 존재 여부 분류를 수행하는 단계; 를 포함하는 것을 특징으로 하는 다중 장기 암 진단 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 의료 영상은 병리 슬라이드 이미지이며, 상기 복수의 관심 영역 이미지를 생성하는 단계는, 이미지 분할 기법을 이용한 조직 추출(tissue extraction) 단계; 및 추출된 조직에 대해 복수의 배율로 패치 추출(patch extraction)을 수행하는 단계; 를 포함하는 것을 특징으로하는 다중 장기 암 진단 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 패치 추출을 수행하는 단계는 슬라이딩 윈도우(sliding window) 방식을 이용하여 수행되는 것을 특징으로하는 다중 장기 암 진단 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 슬라이딩 윈도우 방식은 10%, 20%, 50%를 포함하는 하나 이상의 비율로 수행되는 것을 특징으로 하는 다중장기 암 진단 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 MT-MIL 모델은 CNN(Convolutional Neural Network) 또는 ViT(Vision Transformer)를 기반으로 구성되는것을 특징으로 하는 다중 장기 암 진단 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 MT-MIL 모델은 장기 분류, 암의 병기(grading) 예측 및 형태학적 하위 유형 분류를 포함하는 하나 이상의공개특허 10-2025-0047183-3-보조 작업(auxiliary task)을 수행하는 것을 특징으로 하는 다중 장기 암 진단 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 암 존재 여부 또는 장기 분류 결과를 출력하는 단계; 를 더 포함하는 것을 특징으로 하는 다중 장기 암 진단 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 암 존재 여부 또는 장기 분류 결과를 출력하는 단계는, 패치 확률 맵(patch probability map) 또는 그래디언트 기반 클래스 활성화 맵(Grad-CAM)을 이용하여 암 영역을시각화하는 단계; 를 포함하는 것을 특징으로 하는 다중 장기 암 진단 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "다중 장기 암 진단을 위한 인공지능 모델의 학습 방법에 있어서,다중 장기에 대한 약레이블 데이터셋(weakly-labeled dataset)을 구축하는 단계;상기 구축된 데이터셋의 병리 이미지를 전처리하는 단계;상기 전처리된 이미지를 이용하여 다중 작업-다중 인스턴스 학습(Multi-task Multiple Instance Learning, MT-MIL) 모델을 학습하는 단계; 및상기 학습된 모델의 일반화 성능을 검증하는 단계;를 포함하는 것을 특징으로 하는 다중 장기 암 진단용 인공지능 모델의 학습 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 데이터셋을 구축하는 단계에서 상기 데이터셋은 각 장기별로 정상(normal) 및 암종(carcinoma) 샘플을 포함하고, 상기 다중 장기는 담관 및 췌장(BP), 유방(Breast), 결장(Colon), 내분비계(Endocrine), 여성 생식기(Female),비뇨생식기(GU), 두경부(H&N), 간(Liver), 피부(Skin) 및 위(Stomach) 중 적어도 둘 이상을 포함하는 것을 특징으로 하는 다중 장기 암 진단용 인공지능 모델의 학습 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 데이터셋을 구축하는 단계는 1.25Х, 2.5Х, 5Х, 10Х, 20Х, 40Х 배율 중 하나 이상의 배율로 의료 영상 데이터셋을 구축하고, 상기 학습된 모델의 일반화 성능을 검증하는 단계에서 각 배율별로 검증되며, 1.25Х 배율에서는 전체적인 조직 구조를 파악하고, 2.5Х 배율에서는 중간 수준의 세부 정보를 획득하며, 5Х,10Х, 20Х 및 40Х 배율에서는 세포 수준의 상세한 정보를 분석하는 것을 특징으로 하는 다중 장기 암 진단용공개특허 10-2025-0047183-4-인공지능 모델의 학습 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 전처리하는 단계는,이미지 분할 기법을 이용하여 조직 추출(tissue extraction)을 수행하는 단계; 및5Х, 10Х, 20Х 배율 중 하나 이상의 배율로 패치 추출(patch extraction)을 수행하는 단계; 를 포함하는 것을특징으로 하는 다중 장기 암 진단용 인공지능 모델의 학습 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서, 상기 MT-MIL 모델을 학습하는 단계는 Top K 패치의 평균값, 어텐션 기반 집계(Attention based aggregation),또는 로그-합-지수 풀링(Log-Sum-Exp Pooling) 중 하나 이상의 방법을 이용하여 다중 인스턴스 학습을 수행하는것을 특징으로 하는 다중 장기 암 진단용 인공지능 모델의 학습 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서, 상기 MT-MIL 모델을 학습하는 단계는 하드 파라미터 공유(hard parameter sharing) 또는 소프트 파라미터 공유(soft parameter sharing) 방식을 이용하는 것을 특징으로 하는 다중 장기 암 진단용 인공지능 모델의 학습 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서,상기 MT-MIL 모델을 학습하는 단계는 장기 분류, 암의 병기(grading) 예측 및 형태학적 하위 유형 분류를 포함하는 하나 이상의 보조 작업(auxiliary task)을 수행하는 것을 특징으로 하는 다중 장기 암 진단용 인공지능 모델의 학습 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서,상기 학습된 모델의 일반화 성능을 검증하는 단계는,시간적으로 독립적인 내부 테스트셋(temporally independent internal test set)를 이용한 검증;림프절(lymph node) 장기에 대한 테스트셋을 이용한 검증; 및공개 데이터셋을 이용한 검증; 중 적어도 하나 이상을 포함하는 것을 특징으로 하는 다중 장기 암 진단용 인공지능 모델의 학습 방법."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "의료 영상을 이용한 다중 장기 암 진단 시스템에 있어서, 공개특허 10-2025-0047183-5-모델 개발부; 및 모델 추론부; 를 포함하며, 상기 모델 개발부는, 다중 장기에 대한 약레이블 데이터셋(weakly-labeled dataset)을 구축하는 데이터 구축 컴포넌트; 상기 구축된 데이터셋의 의료 영상을 전처리하는 전처리 컴포넌트; 상기 전처리된 의료 영상을 이용하여 다중 작업-다중 인스턴스 학습(MT-MIL) 모델을 학습하는 모델 학습 컴포넌트; 및 상기 학습된 모델의 일반화 성능을 검증하는 성능 검증 컴포넌트; 를 포함하고, 상기 모델 추론부는, 새로운 의료 영상을 입력받는 입력 컴포넌트; 상기 입력된 의료 영상을 전처리하는 전처리 컴포넌트; 상기 전처리된 의료 영상에 대해 학습된 MT-MIL 모델을 이용하여 암 존재 여부 분류를 수행하는 진단 컴포넌트;및 상기 암 존재 여부 또는 장기 분류 결과를 출력하는 출력 컴포넌트; 를 포함하는 것을 특징으로 하는 다중 장기암 진단 시스템."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 모델 개발부의 데이터 구축 컴포넌트는 담관 및 췌장(BP), 유방(Breast), 결장(Colon), 내분비계(Endocrine), 여성 생식기(Female), 비뇨생식기(GU), 두경부(H&N), 간(Liver), 피부(Skin) 및 위(Stomach) 중둘 이상의 장기에 대한 데이터셋을 구축하는 것을 특징으로 하는 다중 장기 암 진단 시스템."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서,상기 모델 개발부의 성능 검증 컴포넌트는,시간적으로 독립적인 내부 테스트셋(temporally independent internal test set)을 이용한 검증;림프절(lymph node) 장기에 대한 테스트셋을 이용한 검증; 및공개 데이터셋을 이용한 검증; 중 적어도 하나 이상을 수행하는 것을 특징으로 하는 다중 장기 암 진단 시스템."}
{"patent_id": "10-2024-0130572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17항에 있어서,상기 모델 추론부의 진단 컴포넌트는 암 영역을 시각화하는 기능을 추가로 포함하며,상기 시각화하는 기능은 패치 확률 맵(patch probability map) 또는 그래디언트 기반 클래스 활성화 맵(Grad-CAM)을 이용하여 수행되는 것을 특징으로 하는 다중 장기 암 진단 시스템."}
{"patent_id": "10-2024-0130572", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시예들은 의료 영상을 이용한 다중 장기 암 진단 방법 및 시스템으로서, 다중 장기의 의료 영상을 입력받는 단 계; 상기 의료 영상를 전처리 하여 복수의 관심 영역 이미지를 생성하는 단계; 다중 작업-다중 인스턴스 학습 (Multi-task Multiple Instance Learning, MT-MIL) 모델을 이용하여 상기 복수의 관심 영역 이미지로부터 암 존 재 여부 분류를 수행하는 단계; 를 포함한다."}
{"patent_id": "10-2024-0130572", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 의료 영상 분석 기술 분야에 관한 것으로, 더욱 구체적으로는 인공지능을 이용한 다중 장기 암 진단 방법 및 시스템에 관한 것이다. 특히, 본 출원은 병리 슬라이드 이미지를 포함한 의료 영상을 분석하여 다양한 장기의 암을 동시에 진단하는 기술에 관한 것이다."}
{"patent_id": "10-2024-0130572", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "병리 슬라이드 이미지는 의학에서 조직이나 세포를 분석하기 위해 현미경으로 촬영한 영상으로, 조직 내 비정상 적인 세포 변화, 종양, 염증, 감염 등을 확인할 수 있는 질병 진단의 핵심 도구이다. 전통적으로 병리 슬라이드 분석은 병리학자가 수작업으로 슬라이드를 확인하는 방식으로 진행되어 왔다. 그러나 이러한 방식은 다음과 같 은 한계점을 가지고 있다: a) 시간 소요: 병리 슬라이드는 초고해상도 이미지(예: 100,000 × 100,000 픽셀)로, 수작업 진단 시 많은 시간이 소요된다. b) 일관성 부족: 병리학자의 경험, 피로도, 개인적 해석 차이에 따라 진 단 결과가 달라질 수 있다. c) 인력 부족: 전 세계적으로 병리학자 수가 부족해지고 있어, 효율적인 진단 시스 템의 필요성이 대두되고 있다. 이러한 문제점을 해결하기 위해 인공지능(Artificial Intelligence, AI)을 활용한 병리 이미지 분석 기술이 주 목받고 있다. AI는 병리 슬라이드의 미세 변화를 감지하는 데 뛰어난 능력을 보이며, 인간이 놓칠 수 있는 작은 세포 변화를 관찰하여 신속하고 일관된 진단을 가능하게 한다. 그러나 기존의 AI 기반 병리 이미지 분석 기술은 주로 단일 장기에 초점을 맞추고 있어, 다양한 장기의 암을 동 시에 진단하는 데 한계가 있었다. 또한, 대부분의 기존 모델은 완전 지도 학습(fully supervised learning) 방 식을 사용하여 많은 양의 레이블링된 데이터를 필요로 하는데, 이는 시간과 비용 면에서 비효율적이다. 따라서, 다중 장기의 암을 동시에 진단할 수 있고, 적은 양의 레이블링된 데이터로도 효과적으로 학습할 수 있 는 새로운 AI 모델의 개발이 요구되고 있다."}
{"patent_id": "10-2024-0130572", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기의 문제점을 해결하기 위하여 본 출원은 기존의 의료 영상 분석 기술, 특히 병리 슬라이드 이미지를 이용한 암 진단 기술의 한계를 극복하고자 한다. 주요 과제로는 먼저 기존의 단일 장기 중심 진단 모델의 한계를 넘어, 다양한 장기의 암을 동시에 진단할 수 있는 통합된 시스템을 개발하는 것이다. 또한, 완전 지도 학습 방식에 의 존하는 기존 모델들의 한계를 극복하고, 적은 양의 레이블링된 데이터로도 효과적으로 학습할 수 있는 모델을 개발하고자 한다. 다중 작업 학습 및 다중 인스턴스 학습 등의 고급 기계학습 기법을 활용하여 진단의 정확도를 높이는 것도 중요한 과제이다."}
{"patent_id": "10-2024-0130572", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 출원의 실시예들에 따른 의료 영상을 이용한 다중 장기 암 진단 방법은 다중 장기의 의료 영상을 입력받는 단계; 상기 의료 영상를 전처리 하여 복수의 관심 영역 이미지를 생성하는 단계; 다중 작업-다중 인스턴스 학습 (Multi-task Multiple Instance Learning, MT-MIL) 모델을 이용하여 상기 복수의 관심 영역 이미지로부터 암 존재 여부 분류를 수행하는 단계; 를 포함할 수 있다. 일 실시예에서, 상기 의료 영상은 병리 슬라이드 이미지이며, 상기 복수의 관심 영역 이미지를 생성하는 단계는, 이미지 분할 기법을 이용한 조직 추출(tissue extraction) 단계; 및 추출된 조직에 대해 복수의 배율로 패치 추출(patch extraction)을 수행하는 단계; 를 포함할 수 있다. 일 실시예에서, 상기 패치 추출 단계는 슬라이딩 윈도우(sliding window) 방식을 이용하여 수행될 수 있다. 일 실시예에서, 상기 슬라이딩 윈도우 방식은 10%, 20%, 50%를 포함하는 하나 이상의 비율로 수행될 수 있다. 일 실시예에서, 상기 MT-MIL 모델은 CNN(Convolutional Neural Network) 또는 ViT(Vision Transformer)를 기반 으로 구성될 수 있다. 일 실시예에서, 상기 MT-MIL 모델은 장기 분류, 암의 병기(grading) 예측 및 형태학적 하위 유형 분류를 포함하 는 하나 이상의 보조 작업(auxiliary task)을 수행할 수 있다. 일 실시예에서, 상기 시스템은 상기 암 존재 여부 또는 장기 분류 결과를 출력하는 단계; 를 더 포함할 수 있다. 일 실시예에서, 상기 암 존재 여부 또는 장기 분류 결과를 출력하는 단계는, 패치 확률 맵(patch probability map) 또는 그래디언트 기반 클래스 활성화 맵(Grad-CAM)을 이용하여 암 영역을 시각화하는 단계; 를 포함할 수 있다. 본 출원의 또 다른 실시예에 따른 다중 장기 암 진단을 위한 인공지능 모델의 학습 방법에 있어서, 다중 장기에 대한 약레이블 데이터셋(weakly-labeled dataset)을 구축하는 단계; 상기 구축된 데이터셋의 병리 이미지를 전 처리하는 단계; 상기 전처리된 이미지를 이용하여 다중 작업-다중 인스턴스 학습(Multi-task Multiple Instance Learning, MT-MIL) 모델을 학습하는 단계; 및 상기 학습된 모델의 일반화 성능을 검증하는 단계; 를 포함할 수 있다. 일 실시예에서, 상기 데이터셋을 구축하는 단계에서 상기 데이터셋은 각 장기별로 정상(normal) 및 암종 (carcinoma) 샘플을 포함하고, 상기 다중 장기는 담관 및 췌장(BP), 유방(Breast), 결장(Colon), 내분비계 (Endocrine), 여성 생식기(Female), 비뇨생식기(GU), 두경부(H&N), 간(Liver), 피부(Skin) 및 위(Stomach) 중 적어도 둘 이상을 포함할 수 있다. 일 실시예에서, 상기 데이터셋을 구축하는 단계는 1.25×, 2.5×, 5×, 10×, 20×, 40× 배율 중 하나 이상의 배율로 의료 영상 데이터셋을 구축하고, 상기 학습된 모델의 일반화 성능을 검증하는 단계에서 각 배율별로 검 증되며, 1.25× 배율에서는 전체적인 조직 구조를 파악하고, 2.5× 배율에서는 중간 수준의 세부 정보를 획득하 며, 5×, 10×, 20× 및 40× 배율에서는 세포 수준의 상세한 정보를 분석할 수 있다. 일 실시예에서, 상기 전처리하는 단계는, 이미지 분할 기법을 이용하여 조직 추출(tissue extraction)을 수행하 는 단계; 및 5×, 10×, 20× 배율 중 하나 이상의 배율로 패치 추출(patch extraction)을 수행하는 단계; 를 포함할 수 있다. 일 실시예에서, 상기 MT-MIL 모델을 학습하는 단계는 Top K 패치의 평균값, 어텐션 기반 집계(Attention based aggregation) 및 로그-합-지수 풀링(Log-Sum-Exp Pooling) 중 적어도 하나 이상의 방법을 이용하여 다중 인스 턴스 학습을 수행할 수 있다. 일 실시예에서, 상기 MT-MIL 모델을 학습하는 단계는 하드 파라미터 공유(hard parameter sharing) 또는 소프트 파라미터 공유(soft parameter sharing) 방식을 이용할 수 있다. 일 실시예에서, 상기 MT-MIL 모델을 학습하는 단계는 장기 분류, 암의 병기(grading) 예측 및 형태학적 하위 유 형 분류를 포함하는 하나 이상의 보조 작업(auxiliary task)을 수행할 수 있다. 일 실시예에서, 상기 학습된 모델의 일반화 성능을 검증하는 단계는, 시간적으로 독립적인 내부 테스트셋 (temporally independent internal test set)를 이용한 검증; 림프절(lymph node) 장기에 대한 테스트셋을 이 용한 검증; 및 공개 데이터셋을 이용한 검증; 중 적어도 하나 이상을 포함할 수 있다. 본 출원의 또 다른 일 실시예에 따른 의료 영상을 이용한 다중 장기 암 진단 시스템에 있어서, 모델 개발부; 및 모델 추론부; 를 포함하며, 상기 모델 개발부는, 다중 장기에 대한 약레이블 데이터셋(weakly-labeled datase t)을 구축하는 데이터 구축 컴포넌트; 상기 구축된 데이터셋의 의료 영상을 전처리하는 전처리 컴포넌트; 상기 전처리된 의료 영상을 이용하여 다중 작업 다중 인스턴스 학습(MT-MIL) 모델을 학습하는 모델 학습 컴포넌트; 및 상기 학습된 모델의 일반화 성능을 검증하는 성능 검증 컴포넌트; 를 포함하고, 상기 모델 추론부는, 새로운 의료 영상을 입력받는 입력 컴포넌트; 상기 입력된 의료 영상을 전처리하는 전처리 컴포넌트; 상기 전처리된 의 료 영상에 대해 학습된 MT-MIL 모델을 이용하여 암 존재 여부 분류를 수행하는 진단 컴포넌트; 및 상기 암 존재 여부 또는 장기 분류 결과를 출력하는 출력 컴포넌트; 를 포함할 수 있다. 일 실시예에서, 상기 모델 개발부의 데이터 구축 컴포넌트는 담관 및 췌장(BP), 유방(Breast), 결장(Colon), 내 분비계(Endocrine), 여성 생식기(Female), 비뇨생식기(GU), 두경부(H&N), 간(Liver), 피부(Skin) 및 위 (Stomach) 중 둘 이상의 장기에 대한 데이터셋을 구축할 수 있다. 일 실시예에서, 상기 모델 개발부의 전처리 컴포넌트는, 이미지 분할 기법을 이용한 조직 추출(tissue extraction)을 수행하는 컴포넌트; 및 5×, 10×, 20× 배율 중 하나 이상의 배율로 패치 추출(patch extraction)을 수행하는 컴포넌트; 를 포함할 수 있다. 일 실시예에서, 상기 모델 개발부의 모델 학습 컴포넌트는 CNN(Convolutional Neural Network) 또는 ViT(Vision Transformer)를 기반으로 MT-MIL 모델을 구성할 수 있다. 일 실시예에서, 상기 모델 개발부의 모델 학습 컴포넌트는 Top K 패치의 평균값, 어텐션 기반 집계(Attention based aggregation) 및 로그-합-지수 풀링(Log-Sum-Exp Pooling) 중 적어도 하나 이상의 방법을 이용하여 다중 인스턴스 학습을 수행할 수 있다. 일 실시예에서, 상기 모델 개발부의 성능 검증 컴포넌트는, 시간적으로 독립적인 내부 테스트셋(temporally independent internal test set)을 이용한 검증; 림프절(lymph node) 장기에 대한 테스트셋을 이용한 검증; 및 공개 데이터셋을 이용한 검증; 중 적어도 하나 이상을 수행할 수 있다. 일 실시예에서, 상기 모델 추론부의 진단 컴포넌트는 암 영역을 시각화하는 기능을 추가로 포함하며, 상기 시각 화 기능은 패치 확률 맵(patch probability map) 또는 그래디언트 기반 클래스 활성화 맵(Grad-CAM)을 이용하여 수행될 수 있다."}
{"patent_id": "10-2024-0130572", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 출원은 다중 장기 암 진단 모델을 통해 진단의 효율성과 정확성을 크게 향상시킬 수 있다. 하나의 통합된 모 델로 여러 장기의 암을 동시에 진단함으로써, 진단 시간을 단축하고 의료 자원을 효율적으로 활용할 수 있다. 약지도 학습 방법의 도입으로 데이터 준비에 필요한 시간과 비용을 크게 절감할 수 있다. 이는 모델 개발 및 업 데이트 주기를 단축시켜, 최신의 의학 지식을 신속하게 진단 시스템에 반영할 수 있게 한다. 고급 기계학습 기법의 적용으로 진단의 정확도가 향상된다. 이는 오진을 줄이고 환자의 생명과 건강을 보호하는 데 크게 기여할 수 있다. 모델의 판단 근거 시각화 기술을 통해 인공지능의 결정 과정을 의료진이 쉽게 이해하고 검증할 수 있다. 이는 인공지능 시스템에 대한 신뢰도를 높이고, 의료진과 인공지능 간의 협력을 강화하는 데 도움이 된다. 확장 가능한 시스템 설계로 인해 새로운 데이터와 의학 지식을 지속적으로 반영할 수 있어, 시간이 지날수록 시 스템의 성능이 향상되는 효과를 얻을 수 있다. 본 출원은 병리학 전문의가 부족한 지역에서도 고품질의 진단 서비스를 제공할 수 있게 함으로써, 의료 서비스 의 지역 간 격차를 줄이고 전반적인 의료 품질을 향상시키는 데 기여할 수 있다. 본 출원의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 청구범위의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0130572", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 출원의 일부 실시예들을 예시적인 도면을 참조하여 상세하게 설명한다. 각 도면의 구성 요소들에 참조 부호를 부가함에 있어서, 동일한 구성 요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가질 수 있다. 또한, 본 실시예들을 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명 이 본 기술 사상의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략할 수 있다. 용어 정의 본 출원 상에서 언급된 \"포함한다\", \"갖는다\", \"이루어진다\" 등이 사용되는 경우 \"~만\"이 사용되지 않는 이상 다른 부분이 추가될 수 있다. 구성 요소를 단수로 표현한 경우에 특별한 명시적인 기재 사항이 없는 한 복수를 포함하는 경우를 포함할 수 있다. 또한, 본 출원의 구성 요소를 설명하는 데 있어서, 제1, 제2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 달 리 명시하지 않는 한, 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질, 차례, 순서 또는 개수 등이 한정되지 않는다. 본 출원에서 '학습' 또는 '러닝'은 절차에 따른 컴퓨팅(computing)을 통하여 기계 학습(machine learning)을 수 행함을 지칭하는 용어이다. 본 출원에서 \"부(unit)\", \"모듈(module)\"\"장치(device)\", 컴포넌트(component) 또는 \"시스템(system)\" 등의 용 어는 하드웨어뿐만 아니라 해당 하드웨어에 의해 구동되는 소프트웨어의 조합을 지칭할 수 있는 것으로 의도된 다. 예를 들어, 하드웨어는 CPU(Central Processing Unit), GPU(Graphic Processing Unit) 또는 다른 프로세서 (processor)를 포함하는 데이터 처리 기기일 수 있다. 또한, 소프트웨어는 실행중인 프로세스(process), 객체 (object), 실행파일(executable), 실행 스레드(thread of execution), 프로그램(program) 등을 지칭할 수 있다. 본 출원에서 인공지능 모델은 의료 영상을 분석하여 암을 진단하는데 사용되는 기계학습 기반의 알고리즘을 지 칭한다. 특히, 다중 작업-다중 인스턴스 학습(Multitask Multiple Instance Learning, MT-MIL) 모델을 주로 사 용한다. 본 출원에서 의료 영상은 주로 병리 슬라이드의 디지털화된 이미지인 전체 슬라이드 이미지(Whole Slide Image, WSI)를 지칭한다. 이는 고해상도로 스캔된 조직 샘플의 디지털 표현이다. 본 출원에서 다중 인스턴스 학습(Multiple Instance Learning, MIL)은 전체 이미지(bag, 백)에 대한 레이블만 주어진 상태에서, 이미지의 부분(instance, 인스턴스)들을 학습하는 기계학습 방법을 의미한다. 본 출원에서 다중 작업 학습(Multi-task Learning)은 하나의 모델이 여러 관련 작업을 동시에 학습하는 방법으 로, 본 출원에서는 암 진단과 장기 분류를 동시에 수행한다. 본 출원에서 패치(Patch)는 WSI를 작은 크기의 부분 이미지로 분할한 것을 의미하며, 모델의 입력 단위로 사용 된다. 본 출원에서 Grad-CAM은 Gradient-weighted Class Activation Mapping의 약자로, 모델의 결정에 영향을 미친 이미지 영역을 시각화하는 기법을 의미한다. 본 출원에서 약지도 학습(Weakly Supervised Learning)은 전체 이미지에 대한 레이블만 제공되고 세부적인 영역 정보는 제공되지 않은 상태에서 학습하는 방법을 의미한다. 전체적인 구성 도 1은, 본 출원의 일 측면에 따른, 다중 장기 암 진단 시스템의 모델 개발부의 개략도이다. 상기 시스템은 모델 개발부 및 모델 추론부를 포함할 수 있다. 상기 모델 개발부는 다중 장기에 대 한 약레이블 데이터셋(weakly-labeled dataset)을 구축하는 데이터 구축 컴포넌트, 상기 구축된 데이터셋의 의료 영상을 전처리하는 전처리 컴포넌트, 상기 전처리된 의료 영상을 이용하여 다중 작업-다중 인스턴스 학습(Multitask Multiple Instance Learning, MT-MIL) 모델을 학습하는 모델 학습 컴포넌트, 그리고 내부 테스트셋(internal test set) 및 공개 데이터셋(open-dataset)을 통해 모델 성능을 검증하는 성능 검증 컴포넌 트를 포함한다. 상기 데이터 구축 컴포넌트는 다양한 장기의 병리 이미지를 수집하고 레이블링하는 작업을 수행한다. '약레 이블(Weakly-labeled)'이란 이미지 전체에 대해서만 레이블(예: 암 유무)이 주어지고, 암의 정확한 위치 정보는 제공되지 않는 데이터를 의미한다. 이러한 접근 방식은 데이터 준비 과정을 크게 간소화하고, 더 많은 데이터를 효율적으로 활용할 수 있게 한다. 구체적으로, 상기 데이터 구축 컴포넌트는 담관 및 췌장(BP), 유방(Breast), 결장(Colon), 내분비계 (Endocrine), 여성 생식기(Female), 비뇨생식기(GU), 두경부(H&N), 간(Liver), 피부(Skin), 위(Stomach) 등 다 양한 장기의 병리 이미지를 수집한다. 각 이미지에는 해당 장기와 암 유무에 대한 레이블만 부여되며, 이는 후 속 단계에서 다중 인스턴스 학습(Multiple Instance Learning, MIL)을 가능하게 한다. 전처리 컴포넌트에 의하여 수집된 병리 이미지는 인공지능 모델의 입력으로 사용되기 전에 여러 전처리 과 정을 거친다. 이 과정은 다음과 같은 세부 단계를 포함한다: a) 이미지 정규화: 서로 다른 환경에서 촬영된 이 미지들의 색상과 밝기를 일관되게 조정한다. 다만, 본 출원에서는 방대한 양의 학습 데이터를 사용하여 일반화 성능을 높이기 위해 일반적으로 사용되는 염색 정규화(Stain normalization)는 적용하지 않을 수 있다. b) 조직 추출(Tissue extraction): Otsu thresholding과 같은 이미지 분할 기법을 사용하여 배경으로부터 실제 조직 영 역을 분리한다. 이는 불필요한 배경 정보로 인한 노이즈를 줄이고 모델의 학습 효율성을 높인다. c) 패치 추출 (Patch extraction): 고해상도의 전체 슬라이드 이미지(Whole Slide Image, WSI)를 작은 패치로 분할한다. 전 처리 컴포넌트는 5×, 10×, 20× 등 다양한 배율로 패치를 추출하며, 10%, 20%, 50% 등의 슬라이딩 윈도우 (sliding window) 방식을 사용한다. 이를 통해 다양한 스케일의 정보를 포착할 수 있다. 모델 학습 컴포넌트는 전처리된 이미지 패치들을 입력으로 받아 다중 작업-다중 인스턴스 학습(Multi-task Multiple Instance Learning, MT-MIL) 모델을 학습시킨다. 이 모델의 주요 특징은 다음과 같다: a) 다중 인스 턴스 학습(MIL): 각 WSI를 하나의 백(bag)으로, 그 안의 패치들을 인스턴스로 간주한다. 이는 약레이블 데이터 를 효과적으로 활용할 수 있게 해준다. b) 다중 작업 학습(Multi-task Learning): 주 작업인 암 진단과 함께 장 기 분류, 암의 병기(grading) 예측 및 형태학적 하위 유형 분류를 포함하는 하나 이상의 보조 작업(auxiliary task)을 수행한다. 이를 통해 모델의 일반화 성능을 향상시키고 과적합을 방지한다. c) 모델 구조: CNN(Convolutional Neural Network, 예: VGG, ResNet) 또는 ViT(Vision Transformer)를 기반으로 하는 인코더 를 사용한다. d) 집계 방법: Top K 패치의 평균값, 어텐션 기반 집계(Attention based aggregation), 또는 로 그-합-지수 풀링(Log-Sum-Exp Pooling) 등의 방법을 사용하여 패치 단위의 예측을 슬라이드 단위의 예측으로 집 계한다. e) 파라미터 공유: 하드 파라미터 공유(Hard parameter sharing) 또는 소프트 파라미터 공유(soft parameter sharing) 방식을 채택하여 다중 작업 간 정보를 효과적으로 공유한다. 성능 검증 컴포넌트는 학습된 모델의 성능과 일반화 능력을 평가하기 위해 다양한 테스트셋을 사용한다: a) 시간적으로 독립적인 내부 테스트셋(Temporally independent internal test set): 학습 데이터와 다른 시기에 수집된 내부 데이터를 사용하여 모델의 시간적 일관성을 검증한다. b) 림프절(Lymph node) 테스트셋: 학습에 사 용되지 않은 새로운 장기(림프절)에 대한 테스트를 수행하여 모델의 일반화 능력을 평가한다. c) 공개 데이터셋 (예: TCGA, CAMELYON): 외부의 공개된 데이터셋을 사용하여 모델의 성능을 객관적으로 평가하고 다른 모델들과 비교한다. 이러한 종합적인 검증 과정을 통해 모델의 강건성과 일반화 능력을 확보하고, 다양한 임상 환경에서 의 적용 가능성을 평가한다. 도 2는, 본 출원의 일 실시예에서, 다중 장기 암 진단 시스템의 모델 추론부의 개략도이다. 도 2를 참조하면, 모델 추론부의 새로운 병리 이미지에 대한 암 진단 및 관련 정보를 제공하는 과정을 나타 내며, 다음과 같은 주요 단계로 구성된다: 모델 추론부는 병리 이미지를 스캔하는데, 유리 슬라이드에 준비된 조직 샘플을 고해상도 디지털 스캐너를 사용하여 디지털화한다. 스캐닝 과정은 다음과 같은 세부 단계를 포함한다: a) 슬라이드 준비: 조직 샘플이 포함된 유리 슬라이드를 스캐너에 장착한다. b) 초점 조정: 스캐너는 자동 초점 조정 기능을 사용하여 최적의 초점을 찾는다. c) 해상도 설정: 일반적으로 40Х 또는 20Х 배율로 스캔하여 세포 수준의 상세한 정보를 캡처 한다. d) 색상 보정: 스캐너는 내장된 색상 프로필을 사용하여 일관된 색상 재현을 보장한다. 모델 추론부는 스캔된 디지털 이미지를 WSI 형태로 저장한다. WSI는 다음과 같은 특징을 가진다: a) 대 용량 파일: 일반적으로 수 기가바이트 크기의 파일로, 고해상도 정보를 모두 포함한다. b) 피라미드 구조: 다양 한 해상도 레벨을 포함하여 빠른 확대/축소를 가능하게 한다. c) 메타데이터: 스캔 정보, 환자 정보(익명화된), 스캔 날짜 등의 부가 정보를 포함한다. d) 표준 포맷: 일반적으로 DICOM, SVS 등의 표준화된 포맷으로 저장되어 호환성을 보장한다. 모델 추론부는 저장된 WSI에 대해 다중 인스턴스 학습 기반의 범암 선별 모델(MIL-based pan-cancer carcinoma screening model)을 적용한다. 상기 모델 추론부는, 새로운 의료 영상을 입력받는 입력 컴 포넌트, 상기 입력된 의료 영상을 전처리하는 전처리 컴포넌트, 상기 전처리된 의료 영상에 대해 학습된 MT-MIL 모델을 이용하여 암 존재 여부 또는 장기 분류를 수행하는 진단 컴포넌트를 포함할 수 있다. 이 과정은 다음과 같은 단계를 포함한다: a) 이미지 전처리: WSI를 작은 패치로 분할하고, 각 패치에 대해 정규화 등의 전처리를 수행한다. b) 특징 추출: 각 패치에 대해 딥러닝 모델(예: CNN, ViT)을 사용하여 특징을 추출한다. c) 인스턴스 집계: MIL 알고리즘을 사용하여 패치 레벨의 예측을 슬라이드 레벨의 예측으로 통합한다. 모델 추론부는 상기 암 존재 여부 또는 장기 분류 결과를 출력하는 출력 컴포넌트를 포함할 수 있다. 모델 추론부는 모델의 출력을 바탕으로 암 여부를 진단한다. 이 단계는 다음과 같은 요소를 포함할 수 있다: a) 확률 점수: 슬라이드가 암을 포함할 확률을 0에서 1 사이의 값으로 출력한다. b) 임계값 적용: 미리 정의된 임계값을 사용하여 이진 분류(암/정상)를 수행한다. c) 신뢰도 구간: 예측의 불확실성을 나타내는 신뢰도 구간 을 함께 제공한다. d) 다중 장기 고려: 여러 장기에 대한 암 진단 결과를 종합적으로 제시한다. 모델 추론부는 진단 결과를 시각적으로 해석할 수 있도록 암 영역을 시각화한다. 상기 모델 추론부(2 0)의 진단 컴포넌트는 암 영역을 시각화하는 기능을 추가로 포함한다. 이 과정은 다음과 같은 기법을 포함할 수 있다: a) 히트맵 생성: 각 패치의 암 확률을 색상으로 매핑하여 히트맵을 생성한다. 히트맵 생성을 위한 다양한 방법론이 사용될 수 있으며, 여기에는 확률 맵(Probability map), 우선순위 맵(Priority map), Grad-CAM 등이 포함될 수 있다. b) Grad-CAM 적용: 모델의 결정에 영향을 미친 영역을 강조하는 Grad-CAM 기법을 사용한다. c) 오버레이: 생성된 시각화 결과를 원본 WSI 위에 오버레이하여 직관적인 이해를 돕는다. 이러한 종합적인 추론 과정을 통해, 본 출원의 시스템은 새로운 병리 이미지에 대해 정확한 암 진단, 직관적인 시각화를 수행함으로써 의료진의 진단을 효과적으로 보조한다. 도 3은, 본 출원의 일 실시예에서, 유리 슬라이드에서 병리 이미지를 스캔하여 전체 슬라이드 이미지(Whole Slide Image, WSI)를 생성하고 이를 인공지능 모델에 입력하는 프로세스를 나타낸 도면이다. 도 3을 참조하면, 이 프로세스는 다음과 같은 주요 단계로 구성될 수 있다: 유리 슬라이드 준비 단계로서 a) 조직 샘플 처리: 환자로부터 채취한 조직 샘플을 표준 병리학 절차에 따라 처리한다. b) 염색: Hematoxylin and Eosin (H&E) 등의 표준 염색법을 사용하여 조직을 염색한다. c) 마운팅: 처리된 조직을 유리 슬라이드 위에 마운팅하고 커버슬립을 덮는다. WSI 스캔 및 생성 단계로서, a) 스캐너 장착: 준비된 유리 슬라이드를 디지털 병리 스캐너에 장착한다. b) 스캔 설정: 해상도(일반적으로 20Х 또는 40Х), 초점 평면 수, 스캔 영역 등을 설정한다. c) 스캔 실행: 설정 에 따라 고해상도 디지털 스캔을 실행한다. d) 이미지 처리: 스캔된 이미지에 대해 스티칭, 색상 보정 등의 후 처리를 수행한다. e) WSI 파일 생성: 처리된 이미지를 표준 WSI 포맷(예: SVS, DICOM)으로 저장한다. WSI 저장 및 관리 단계로서, a) 데이터베이스 저장: 생성된 WSI 파일을 안전한 의료 영상 데이터베이스에 저장한다. b) 메타데이터 연결: 환자 정보, 스캔 정보 등의 메타데이터를 WSI 파일과 연결한다. c) 접근 제어: 적절한 보안 및 접근 제어 정책을 적용하여 환자 개인정보를 보호한다. AI 모델 입력 및 분석 단계로서, a) WSI 로딩: 저장된 WSI 파일을 AI 분석 시스템에 로드한다. b) 전처리: WSI를 패치로 분할하고, 필요한 경우 정규화, 증강 등의 전처리를 수행한다. c) 모델 적용: 전처리된 패치들에 대해 학습된 AI 모델(예: MT-MIL 모델)을 적용한다. d) 예측 생성: 모델의 출력을 바탕으로 암 존재 확률, 암 유형 등을 예측한다. 분석 결과 생성 단계로서, a) Grad-CAM 생성: 모델의 결정에 영향을 미친 영역을 시각화하는 Grad-CAM을 생 성한다. b) 확률 계산: 전체 슬라이드에 대한 암 확률(carcinoma probability)를 계산한다. c) 결과 통합: Grad-CAM 좌표값과 암 확률을 포함한 종합적인 분석 결과를 생성한다. 의사 진단 지원 단계로서, a) 결과 제시: 생성된 분석 결과를 의사에게 제시한다. b) 시각화 도구 제공: 의 사가 WSI를 탐색하며 AI 분석 결과를 오버레이하여 볼 수 있는 도구를 제공한다. c) 상호작용: 의사가 AI 결과 를 바탕으로 추가적인 영역 탐색이나 분석을 요청할 수 있는 기능을 제공한다. 최종 진단 단계(미도시)로서, a) 결과 해석: 의사는 AI 분석 결과와 자신의 전문 지식을 종합하여 결과를 해석 한다. b) 진단 결정: 모든 정보를 종합하여 최종 진단을 내린다. c) 보고서 작성: 진단 결과, AI 분석 결과, 사 용된 근거 등을 포함한 종합적인 진단 보고서를 작성한다. 이러한 상세한 프로세스를 통해, 본 출원은 고해상도 병리 이미지의 디지털화부터 AI 기반 분석, 그리고 최종 의사 진단까지의 전체 워크플로우를 효율적으로 지원한다. 모델 학습 도 4a 및 도 4b는, 본 출원의 일 실시예에서, 다중 장기 암 진단 시스템에서 사용되는 데이터셋의 구성 정보를 상세히 나타낸 도면이다. 도 4a는 학습셋(Train set)이고, 도 4b는 검증셋(Valid set)이다. 상기 데이터셋은 모 델의 학습 및 성능 평가에 핵심적인 역할을 한다. 도 4a 및 도 4b를 참조하면, 본 데이터셋의 각 장기는 10개의 주요 장기인 a) BP (Bile duct and Pancreas): 담관 및 췌장 b) Breast: 유방 c) Colon: 결장 d) Endocrine: 내분비계 e) Female: 여성 생식기 f) GU (Genitourinary): 비뇨생식기 g) H&N (Head and Neck): 두경부 h) Liver: 간 i) Skin: 피부 j) Stomach: 위를 포함하고 있다. 이러한 다양한 장기의 포함은 모델이 여러 종류의 암을 진단할 수 있는 범용성을 갖도록 한다. 각 장기별 데이터는 a) c0 (normal): 정상 조직 샘플 b) c1 (carcinoma): 암 조직 샘플 두 가지 클래스로 구분 될 수 있다. 이러한 이진 분류 구조는 모델이 각 장기에 대해 암의 존재 여부를 판단하는 기본적인 작업을 수행 할 수 있게 한다. 전체 데이터셋은 두 개의 하위 셋으로 나뉜다: a) 학습셋(Train set): 모델의 학습에 사용되는 데이터셋. 더 많 은 샘플 수를 포함한다. b) 검증셋(Valid set): 학습된 모델의 성능을 검증하는 데 사용되는 데이터셋으로서, Train set보다 적은 수의 샘플을 포함한다. 이러한 분할은 모델의 일반화 능력을 평가하고 과적합을 방지하는 데 중요하다. 각 장기 및 클래스별로 샘플 수가 명시되어 있다. 예를 들어, BP: Train set에 c0 379개, c1 333개 / Valid set에 c0 36개, c1 75개, Breast: Train set에 c0 866개, c1 480개 / Valid set에 c0 109개, c1 78개로 사용할 수 있는데, 이러한 상세한 분포 정보는 데이터의 균형과 대표성을 평가하는 데 중요하다. 일부 장기(예: H&N, Liver, Skin)의 경우 상대적으로 적은 수의 샘플을 가지고 있다. 이는 해당 장기의 암 진단 시 주의가 필요함을 시사한다. 총 샘플 수는 총 14,745개 샘플 (c0: 7,065개, c1: 7,680개)의 Train set, 총 2,204개 샘플 (c0: 987개, c1: 1,217개) Valid set으로서, 이러한 대규모 데이터셋은 모델의 강건(robust)한 학습을 가능하게 한다. 전체적으 로 c0와 c1 클래스 간의 샘플 수가 비교적 균형을 이루고 있다. 이는 모델이 특정 클래스에 편향되지 않도록 하 는 데 도움이 된다. Valid set의 샘플 수는 Train set의 약 15%를 차지한다. 이는 일반적인 머신러닝 관행에 부 합하는 비율이다. 도 5는, 본 출원의 일 실시예에서, 병리 이미지의 전처리 과정을 도시한 도면이다. 도 5를 참조하면, 이 전처리 과정은 원본 WSI를 AI 모델의 입력으로 적합한 형태로 변환하는 중요한 단계로, 다 음과 같은 주요 구성 요소와 단계를 포함한다: 원본 WSI는 a) 고해상도: 일반적으로 40× 또는 20× 배율로 스캔된 초고해상도 이미지 (예: 100,000 × 100,000 픽셀) b) 대용량: 보통 수 기가바이트 크기의 파일 c) 포맷: SVS, DICOM 등의 표준 디지털 병리 이미지 포맷 d) 메타데이터: 환자 정보, 스캔 정보 등을 포함할 수 있다. 조직 영역 추출(Tissue Extraction)은 a) 배경 제거: Otsu thresholding 또는 기타 이미지 분할 기법을 사용하 여 유리 슬라이드의 배경을 제거 b) 조직 영역 식별: 실제 조직이 있는 영역만을 선택적으로 추출 c) 경계 설정: 추출된 조직 영역의 경계를 명확히 정의 d) 노이즈 제거: 작은 조직 파편이나 아티팩트를 제거하는 구성 을 포함할 수 있다. 패치 생성(Patch Extraction)은 a) 슬라이딩 윈도우: 10%, 20%, 50% 등의 다양한 오버랩 비율로 슬라이딩 윈도 우 기법 적용 b) 다중 배율: 5×, 10×, 20× 등 다양한 배율로 패치 추출 c) 패치 크기: 일반적으로 256×256 또는 5125×12 픽셀 크기의 패치 생성 d) 패치 선별: 조직 함량이 일정 비율(예: 70%) 이상인 패치만 선택하는 구성을 포함할 수 있다. 패치 전처리는 a) 정규화: 각 패치의 픽셀 값을 표준화된 범위(예: 0-1)로 정규화 b) 색상 보정: 필요한 경우 색상 표준화 수행 (본 출원에서는 대량의 데이터로 인해 생략 가능) c) 데이터 증강: 필요시 회전, 반전 등의 데이터 증강 기법 적용 d) 패치 레이블링: 각 패치에 해당 슬라이드의 레이블(정상/암)을 할당하는 구성을 포함 할 수 있다. 패치 저장 및 관리는 a) 파일 시스템: 효율적인 접근을 위해 적절한 디렉토리 구조로 패치 저장 b) 메타데이터: 각 패치의 원본 WSI 정보, 위치 정보 등을 메타데이터로 저장 c) 인덱싱: 빠른 검색을 위한 패치 인덱스 생성 d) 압축: 필요시 무손실 압축 적용하여 저장 공간을 절약하는 구성을 포함할 수 있다. 패치 데이터셋 구성은 a) 학습셋(Train set): 모델 학습에 사용될 패치들의 집합 b) 검증셋(Valid set): 모델 성능 검증에 사용될 패치들의 집합 c) 테스트셋(Test set): 최종 모델 평가에 사용될 패치들의 집합 d) 데이터 균형(Data balance): 각 셋 내 정상/암 패치의 비율을 조정하는 구성을 포함할 수 있다. AI 모델 입력 준비는 a) 배치 구성: 모델 학습 시 효율적인 배치 크기로 패치 그룹화 b) 데이터 로더: 효율적인 데이터 로딩을 위한 커스텀 데이터 로더 구현 c) 메모리 관리: 대용량 데이터 처리를 위한 효율적인 메모리 관 리 전략 수립 d) GPU 최적화: GPU 메모리를 최대한 활용할 수 있는 데이터 형식으로 변환하는 과정을 포함할 수 있다. 이러한 상세한 전처리 과정을 통해, 본 출원의 시스템은 고해상도의 WSI를 효과적으로 처리하여 AI 모델이 학습 하고 추론할 수 있는 형태로 변환한다. 이는 모델의 학습 효율성을 높이고, 더 정확한 암 진단 결과를 도출하는 데 핵심적인 역할을 한다. 또한, 이러한 표준화된 전처리 과정은 다양한 출처의 병리 이미지를 일관성 있게 처 리할 수 있게 하여, 본 출원의 시스템의 범용성과 확장성을 크게 향상시킨다. 도 6은, 본 출원의 일 실시예에서, 다중 인스턴스 학습(MIL) 방법을 설명하는 도면이다. 도 6을 참조하면, 약지도 학습 방법의 하나로, 전체 이미지(Ground Truth)에 대한 레이블만을 이용하여 학습을 수행한다. 딥러닝 모델은 예측에 유용한 Top k 패치를 선택하고, 이들 패치의 출력(특징, 확률 등)을 집계하여 최종 예측을 수행한다. 도 6은 Top 1, Top 2, Top K 패치가 선택되고, 이를 통해 최종 예측 확률 0.934를 산출 하는 과정을 보여준다. 도 7은, 본 출원의 일 실시예에서, MT-MIL 모델이 하나 이상의 보조 작업(auxiliary task)을 수행하는 과정을 도시한 도면이다. 도 7을 참조하면, 본 출원의 핵심 구성 요소인 MT-MIL 모델은 주 작업인 암(Carcinoma) 진단 외에도 하나 이상 의 보조 작업을 수행할 수 있는 유연한 구조를 가지고 있다. 대표적인 보조 작업으로는 장기(Organ) 분류, 암의 병기(grading) 예측 및 형태학적 하위 유형 분류 작업을 포함할 수 있다. 장기 분류 작업은 입력된 의료 영상이 어느 장기에 해당하는지를 예측하며, 암의 병기 예측은 암의 진행 정도를 판단하는 작업이고, 형태학적 하위 유 형 분류는 암의 세부적인 유형을 구분하는 작업이다. MT-MIL 모델은 보조 작업을 수행하는 다중 작업 학습 방식 을 채택하고 있으며, 다음과 같은 주요 구성 요소와 특징을 가진다: MT-MIL 모델은a) 입력 처리: 병리 이미지의 다수의 패치(인스턴스)를 입력으로 받는다. b) 아키텍처: CNN(Convolutional Neural Network) 또는 ViT(Vision Transformer) 기반의 딥러닝 모델로 구성된다. c) 특징 추출: 각 패치로부터 고차원의 특징 벡터를 추출한다. d) 파라미터 공유: 모든 패치에 대해 동일한 인코더가 적 용되어 파라미터를 공유한다.특징 집계 메커니즘은 a) 풀링 연산: 추출된 패치별 특징을 하나의 백(bag) 레벨 표현으로 집계한다. b) 방법: 어텐션 기반 풀링(Attention-based pooling), 최대 풀링(Max pooling), 평균 풀링(Mean pooling) 등 다양한 집 계 방법을 사용할 수 있다. c) 중요도 가중치: 어텐션(Attention) 메커니즘을 사용할 경우, 각 패치의 중요도에 따른 가중치를 학습한다. 암(Carcinoma) 분류기는 a) 입력: 집계된 백 레벨 특징 표현 b) 구조: 완전 연결 층(Fully Connected Layer)으 로 구성 c) 출력: 암 존재 확률 (0~1 사이의 값) d) 활성화 함수: 시그모이드(Sigmoid) 함수를 사용하여 확률 값으로 변환하는 구성을 포함할 수 있다. 장기 분류기(보조 작업)는 a) 입력: 집계된 백 레벨 특징 표현 (암 분류기와 공유) b) 구조: 완전 연결 층으로 구성되며, 장기의 수만큼의 출력 노드를 가짐 c) 출력: 각 장기에 대한 확률 분포 d) 활성화 함수: 소프트맥스 (Softmax) 함수를 사용하여 다중 클래스 확률로 변환하는 구성을 포함할 수 있다. 암의 병기(grading) 예측기(보조 작업)는 a) 입력: 집계된 백 레벨 특징 표현 (암 분류기 및 장기 분류기와 공 유) b) 구조: 완전 연결 층(Fully Connected Layer)으로 구성되며, 병기의 수만큼의 출력 노드를 가짐 c) 출력: 각 병기에 대한 확률 분포 (예: 1기, 2기, 3기, 4기) d) 활성화 함수: 소프트맥스(Softmax) 함수를 사용하여 다 중 클래스 확률로 변환하는 구성을 포함할 수 있다. 추가적으로, 암의 진행 정도를 예측하여 치료 계획 수립에 도움을 주는 구성을 포함할 수 있다 형태학적 하위 유형(morphological subtypes) 분류기(보조 작업)는 a) 입력: 집계된 백 레벨 특징 표현 (다른 분류기들과 공유) b) 구조: 완전 연결 층으로 구성되며, 형태학적 하위 유형의 수만큼의 출력 노드를 가짐 c) 출력: 각 형태학적 하위 유형에 대한 확률 분포 (예: 선암, 편평세포암, 소세포암 등) d) 활성화 함수: 소프트 맥스(Softmax) 함수를 사용하여 다중 클래스 확률로 변환하는 구성을 포함할 수 있다. 추가적으로, 암의 세부적 인 유형을 분류하여 더 정확한 진단과 맞춤형 치료 전략 수립에 기여할 수 있다. 또한, 본 출원의 MT-MIL 모델은 여기에 언급된 보조 작업에 국한되지 않고, 필요에 따라 다른 유형의 보조 작업 을 추가하거나 변경할 수 있는 확장성을 갖추고 있다. 다중 작업 학습 메커니즘은 a) 손실 함수: 암 분류를 위한 이진 교차 엔트로피와 장기 분류를 위한 카테고리컬 교차 엔트로피의 가중 합 b) 가중치 조정: 두 작업의 상대적 중요도를 반영하는 가중치 파라미터 도입 c) 그래 디언트 흐름: 두 작업의 그래디언트가 공유 레이어를 통해 역전파되어 서로 영향을 미칠 수 있다. 학습 과정은 a) 순전파: 입력 패치들이 MIL 인코더(Encoder)를 통과하여 특징이 추출되고, 이를 바탕으로 두 분 류 작업이 수행된다. b) 역전파: 두 작업의 손실을 합산한 총 손실에 대해 역전파가 수행되며, 모든 파라미터가 동시에 업데이트된다. c) 배치 처리: 여러 WSI의 패치들을 배치로 구성하여 효율적인 학습 수행한다. 추론 과정은 a) 패치 단위 처리: 새로운 WSI의 패치들을 MIL 인코더에 입력한다. b) 특징 집계: 추출된 패치 특 징들을 백 레벨로 집계한다. c) 다중 출력: 암 확률과 장기 분류 결과를 동시에 출력한다. MT-MIL 모델의 이점으로는 a) 특징 공유: 두 작업 간 특징 공유를 통해 더 강건(robust)한 특징을 학습한다. b) 정규화 효과: 보조 작업이 주 작업의 과적합을 방지하는 정규화 역할 수행한다. c) 데이터 효율성: 제한된 데이 터로부터 더 많은 정보를 추출하여 학습 효율성 증대한다. d) 일반화 능력 향상: 다양한 작업을 학습함으로써 모델의 일반화 능력 향상한다. 이러한 MT-MIL 모델 구조는 병리 이미지의 특성을 효과적으로 포착하면서도, 암 진단이라는 주 목적과 함께 장 기 분류라는 부가적인 정보를 추출할 수 있게 해준다. 도 8은, 본 출원의 일 실시예에서, 다양한 데이터셋에서의 모델 성능 비교 표이다. 도 8을 참조하면, 본 출원의 다중 작업(Multi-task) 모델과 기존의 단일 작업(Single-task) 모델의 성능을 다양 한 데이터셋에서 비교한 표를 나타낸다. 이 성능 비교 표는 다음과 같은 주요 구성 요소와 특징을 포함한다: 데이터셋 구분은 a) Test LN: 림프절(Lymph Node) 테스트 데이터셋 b) CAMELYON16: 공개된 유방암 림프절 전이 데이터셋 c) TCGA: The Cancer Genome Atlas 프로그램의 다중 암종 데이터셋을 포함할 수 있다. 모델 구분은 a) 단일 작업(Single-task): 암 진단만을 수행하는 기존의 MIL 모델 b) 다중 작업(Multi-task): 암 진단과 장기 분류를 동시에 수행하는 본 출원의 MT-MIL 모델을 포함한다. 성능 지표는 a) AUROC (Area Under the Receiver Operating Characteristic curve)로서 모델의 분류 성능을 종 합적으로 나타내는 지표, 범위: 0~1, 1에 가까울수록 우수한 성능 b) ACC (Accuracy)로서 전체 샘플 중 정확히 분류된 샘플의 비율, 범위: 0~1, 1에 가까울수록 우수한 성능 c) PPV (Positive Predictive Value, 양성 예측 도)로서, 양성으로 예측한 샘플 중 실제 양성인 샘플의 비율, 범위: 0~1, 1에 가까울수록 우수한 성능 d) NPV (Negative Predictive Value, 음성 예측도)로서, 음성으로 예측한 샘플 중 실제 음성인 샘플의 비율, 범위: 0~1, 1에 가까울수록 우수한 성능을 포함할 수 있다. Test LN 데이터셋 결과 분석은 a) AUROC: Multi-task 모델(0.915)이 Single-task 모델(0.911)보다 소폭 우수했 다. b) ACC: Multi-task 모델(0.838)이 Single-task 모델(0.840)과 유사한 성능을 보였다. c) PPV와 NPV: 두 모델이 비슷한 수준의 성능을 보였다. CAMELYON16 데이터셋 결과 분석은 a) AUROC: Multi-task 모델(0.824)이 Single-task 모델(0.815)보다 우수했다. b) ACC: Single-task 모델(0.814)이 Multi-task 모델(0.713)보다 높았다. c) PPV와 NPV: Single- task 모델이 더 균형 잡힌 성능을 보였다. TCGA 데이터셋 결과 분석은 a) AUROC: Multi-task 모델(0.959)이 Single-task 모델(0.947)보다 우수했다. b) ACC: 두 모델 모두 매우 높은 정확도(0.987, 0.988)를 보였다. c) PPV: 두 모델 모두 완벽한 양성 예측도 (0.998)를 달성했다. d) NPV: Multi-task 모델(0.070)이 Single-task 모델(0.054)보다 우수했다. 종합 분석하면, a) 일관성: Multi-task 모델이 대부분의 데이터셋과 지표에서 일관되게 우수한 성능을 보인다. b) 일반화 능력: 다양한 데이터셋에서의 성능을 통해 Multi-task 모델의 우수한 일반화 능력 입증하였다. c) 트 레이드오프: 일부 지표에서는 Single-task 모델이 더 나은 성능을 보이나, 전반적으로 Multi-task 모델이 우수 했다. d) 데이터셋 특성: 각 데이터셋의 특성에 따라 모델 성능의 차이가 발생함을 확인했다. 따라서, 본 결과 는 장기 분류 작업의 추가가 전반적인 암 진단 성능 향상에 기여함을 입증하였다는 것에 의의가 있다. 도 9a 및 도 9b는, 본 출원의 일 실시예에서, 테스트셋에 대한 장기별 AUC 평가 결과 및 장기별 정확도 평가 결 과를 나타내는 표이다. 도 9a 및 도 9b를 참조하면, 총 10개 장기에 대해 1.25×, 2.5×, 5×, 10×의 네 가지 배율에서의 성능을 보여 준다. 대부분의 장기에서 5× 또는 10× 배율에서 가장 높은 AUC 값을 보이며, 전체적으로는 5× 배율에서 0.963의 최고 AUC 값을 달성했다. AUC 결과와 유사하게, 대부분의 장기에서 5× 또는 10× 배율에서 가장 높은 정확도를 보인다. 전체적으로는 5× 배율에서 0.916의 최고 정확도를 달성했다. 도 10은, 본 출원의 일 실시예에서, 테스트셋에 대한 림프절 검증 결과를 나타내는 표이다. 본 출원에서 림프절 검증을 별도로 수행하는 이유는 다음과 같다: a) 림프절의 특수성: 림프절은 다른 장기와 달리 크기가 매우 작다. 일반 절제술 검체에서 암을 찾는 것과 림프절 안에서 암을 찾는 것은 전략이 다를 수밖 에 없다. b) 데이터 특성의 차이: 림프절 샘플은 일반 조직 샘플과 비교해 크기가 훨씬 작다. 예를 들어, 일반 조직은 약 1GB 크기인 반면, 림프절 샘플은 약 0.1GB 크기이다. 이는 같은 수의 샘플이라도 실제 데이터 양에서 큰 차이를 만든다. c) 최적 배율의 차이: 일반 조직은 5×배율에서 좋은 성능을 보이는 반면, 림프절은 10×배 율에서 더 좋은 성능을 보인다. 이는 림프절의 작은 크기 때문에 더 높은 배율이 필요하기 때문이다. d) 알고리 즘 성능 차이: 일반 조직 데이터에 림프절 데이터를 함께 학습시키면 오히려 알고리즘의 정확도가 떨어지는 현 상이 종종 발견되는데, 이는 림프절의 특성이 다른 조직과 매우 다르다는 것을 의미한다. e) 전략적 분리: 따라 서, 림프절 검출을 위한 알고리즘을 별도로 개발할 필요성이 있으며, 이는 각 조직 유형에 최적화된 모델을 만 들기 위한 전략적 선택이다. f) 임상적 중요성: 림프절의 암 전이 여부는 많은 암 진단에서 중요한 정보를 제공 한다. 따라서 림프절에 대한 정확한 진단은 임상적으로 매우 중요하며, 이는 별도의 검증이 필요한 이유가 된다. 도 10을 참조하면, 검증에는 내부 데이터셋인 SNUH LN 셋(1,462장) 및 공개 데이터셋인 CAMELYON16 셋(정상: 80 / 종양: 49의 129개의 슬라이드)의 두 가지 림프절 데이터셋이 사용되었다. CAMELYON16 데이터셋은 유방암 전이 검출을 위한 디지털 병리 이미지 데이터셋이다. 각 데이터셋에 대해 1.25×, 2.5×, 5×, 10×의 네 가지 배율 에서 모델의 성능을 평가했다. 평가 지표로는 AUC, 정확도, 민감도, 특이도, PPV(양성예측도), NPV(음성예측 도)를 사용했다. SNUH LN 셋에서는 10× 배율에서 AUC 0.911, 정확도 0.840으로 가장 높은 성능을 보였다. CAMELYON16 셋에서도 10× 배율에서 AUC 0.815, 정확도 0.814로 가장 우수한 결과를 나타냈다. 도 11a 내지 도 11c는, 본 출원의 일 실시예에서, TCGA 테스트셋(공개 데이터셋)에 대한 암종(Carcinoma), 선암 종(Adenocarcinoma), 육종 및 림프종(Sarcoma & Lymphoma) 검증 결과를 나타내는 표이다. TCGA는 미국 국립 암 연구소(NCI)와 국립 인간 유전체 연구소(NHGRI)가 공동으로 시작한 대규모 암 유전체 프로젝트이다. 이 데이터셋은 33개 이상의 암 유형에 대한 방대한 양의 유전체, 후성유전체, 전사체 및 임상 데이터를 포함하고 있다. 도 11a를 참조하면, 11개의 서로 다른 암종 프로젝트에 대해 10× 배율에서 모델의 성능을 평가했다. 각 프로젝 트별로 샘플 수(N), 정확도(ACC), 진양성(TP), 진음성(TN), 위음성(FN), 위양성(FP)을 제시한다. 모든 프로젝트 에서 0.93 이상의 높은 정확도를 보였으며, 특히 식도 암종(TCGA-ESCA), 두경부 편평세포암종(TCGA-HNSC), 폐 편평세포암종(TCGA-LUSC)에서는 0.99 이상의 매우 높은 정확도를 달성했다. 도 11b를 참조하면, 10개의 서로 다른 선암종 프로젝트에 대해 10× 배율에서 모델의 성능을 평가했다. 대부분 의 프로젝트에서 0.90 이상의 높은 정확도를 보였으며, 특히 난소 장액성 낭선암(TCGA-OV)과 직장 선암(TCGA- READ)에서는 1.000의 완벽한 정확도를 달성했다. 다만, 신장 색소암(TCGA-KICH)에서는 상대적으로 낮은 0.702의 정확도를 보였는데, 이는 해당 암 유형의 특수성이나 데이터의 특성에 기인할 수 있다. 도 11c를 참조하면, 3개의 프로젝트(TCGA-DLBC, TCGA-SARC, TCGA-UCS)에 대해 10× 배율에서 모델의 성능을 평 가했다. 림프종(TCGA-DLBC)에서 0.925, 육종(TCGA-SARC)에서 0.975, 자궁 암육종(TCGA-UCS)에서 1.000의 정확 도를 보여, 다양한 유형의 암에 대해서도 높은 성능을 유지함을 확인할 수 있다. 이러한 결과들은 본 출원의 다중 장기 암 진단 시스템이 다양한 유형의 암종, 선암종, 육종, 림프종에 대해 높 은 정확도와 일관된 성능을 보이며, 특히 10Х 배율에서 우수한 성능을 달성함을 나타낸다. 도 12a 내지 도 12f는, 본 출원의 일 실시예에서, 의료 영상의 크기에 따른 추론 시간(inference time)을 측정 한 표이고, 각각은 1.25× 배율, 2.5× 배율, 5× 배율, 10× 배율, 20× 배율 및 40× 배율에서의 추론 시간을 나타낸다. 일 예에서, 영상의 크기를 7개 카테고리로 분류할 수 있는데, 500MB 이하는 그룹 0, 501-1,000MB는 그룹 1, 1,001-1,500MB는 그룹 2, 1,501-2,000MB는 그룹 3, 2,001-2,500MB는 그룹 4, 2,501-3,000MB는 그룹 5, 3,001MB 이상은 그룹 6으로 분류된다. 추론 시간 측정 방법은 세 단계로 구성되어 있으며, 첫째로 Otsu thresholding을 사용한 조직 분할, 둘째로 패치 추출, 셋째로 추론 과정을 거친다. 총 추론 시간은 이 세 단계의 시간을 합산하 여 계산된다. 또한, 각 크기 그룹에서 10장의 이미지를 무작위로 샘플링하여 측정을 진행하였다. 이러한 방법을 통해 영상 크기와 처리 시간 간의 관계를 분석하고, 시스템의 성능을 평가하였다. 도 12a을 참조하면, 1.25× 배율에서의 추론 시간이 도시되어 있다. 원본 mpp(microns per pixel)가 0.50과 0.25인 두 가지 경우에 대해, 이미지 크기에 따른 그룹별로 추론 시간을 측정했다. 각 그룹에 대해 이미지 크기 (W × H), 패치 수, 조직 분할 시간, 패치 추출 시간, 추론 시간, 그리고 총 처리 시간이 제시되어 있다. 1.25 × 배율에서는 가장 큰 이미지(그룹 6)에 대해서도 총 처리 시간이 10.37초로, 비교적 빠른 처리 속도를 보인다. 도 12b는 2.5× 배율에서의 추론 시간을 나타낸다. 1.25× 배율에 비해 이미지 크기와 패치 수가 증가하여, 처 리 시간도 전반적으로 증가했다. 가장 큰 이미지(그룹 6)의 경우 총 처리 시간이 22.35초로, 1.25× 배율의 약 2배 정도 소요된다. 도 12c는 5Х 배율에서의 추론 시간을 보여준다. 이미지 크기와 패치 수가 더욱 증가하여, 처리 시간도 크게 늘 어났다. 가장 큰 이미지(그룹 6)의 경우 총 처리 시간이 118.48초로, 약 2분 가까이 소요된다. 도 12d는 10× 배율에서의 추론 시간을 나타낸다. 이미지 크기와 패치 수가 5× 배율의 4배 정도로 증가하여, 처리 시간도 큰 폭으로 늘어났다. 가장 큰 이미지(그룹 6)의 경우 총 처리 시간이 294.35초로, 약 5분 정도 소 요된다. 도 12e는 20× 배율에서의 추론 시간을 보여준다. 이미지 크기와 패치 수가 매우 크게 증가하여, 처리 시간도 크게 늘어났다. 가장 큰 이미지(그룹 6)의 경우 총 처리 시간이 1698.16초로, 약 28분이 소요된다. 도 12f는 40× 배율에서의 추론 시간을 보여준다. 가장 큰 이미지(그룹 6)의 경우 총 처리 시간이 4623.06초(약 77분)로, 상당히 긴 시간이 소요되었다. 이러한 결과들은 배율이 증가함에 따라 처리해야 할 데이터량이 기하급수적으로 증가하여 추론 시간이 크게 늘 어남을 보여준다. 따라서 실제 진단 환경에서는 요구되는 정확도와 처리 시간 사이의 균형을 고려하여 적절한 배율을 선택해야 함을 시사한다. 또한, 고배율 분석이 필요한 경우 하드웨어 성능 향상이나 병렬 처리 기법 등 을 통해 처리 시간을 단축할 필요가 있음을 나타낸다. 이상에서 설명한 실시예들에 따른 장치에 의한 동작은 적어도 부분적으로 컴퓨터로 구현될 수 있는 방법 또는 컴퓨터 프로그램으로 구현되어, 컴퓨터로 읽을 수 있는 기록매체에 기록될 수 있다. 예를 들어, 프로그램 코드 를 포함하는 컴퓨터-판독가능 매체로 구성되는 프로그램 제품과 함께 구현되고, 이는 기술된 임의의 또는 모든 단계, 동작, 또는 과정을 수행하기 위한 프로세서에 의해 실행될 수 있다. 상기 컴퓨터는 데스크탑 컴퓨터, 랩탑 컴퓨터, 노트북, 스마트 폰, 또는 이와 유사한 것과 같은 컴퓨팅 장치일 수도 있고 통합될 수도 있는 임의의 장치일 수 있다. 컴퓨터는 하나 이상의 대체적이고 특별한 목적의 프로세서, 메모리, 저장공간, 및 네트워킹 구성요소(무선 또는 유선 중 어느 하나)를 가지는 장치다. 상기 컴퓨 터는 예를 들어, 마이크로소프트의 윈도우와 호환되는 운영 체제, 애플 OS X 또는 iOS, 리눅스 배포판(Linux distribution), 또는 구글의 안드로이드 OS와 같은 운영체제(operating system)를 실행할 수 있다. 상기 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록 장치를 포함한다. 컴퓨터가 읽을 수 있는 기록매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장 장치 등을 포함한다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수도 있다. 또한, 본 실시예를 구현하 기 위한 기능적인 프로그램, 코드 및 코드 세그먼트(segment)들은 본 실시예가 속하는 기술 분야의 통상의 기술 자에 의해 용이하게 이해될 수 있을 것이다. 이상에서 살펴본 본 출원은 도면에 도시된 실시예들을 참고로 하여 설명하였으나 이는 예시적인 것에 불과하며 당해 분야에서 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 실시예의 변형이 가능하다는 점을 이해할 것이다. 그러나, 이와 같은 변형은 본 출원의 기술적 보호범위 내에 있다고 보아야 한다. 따라서, 본 출원의 진 정한 기술적 보호범위는 첨부된 특허청구범위의 기술적 사상에 의해서 정해져야 할 것이다."}
{"patent_id": "10-2024-0130572", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 출원의 예시적인 실시예들을 보다 명확하게 설명하기 위해, 실시예에 대한 설명에서 필요한 도면이 아래에서 간단히 소개된다. 아래의 도면들은 본 출원의 실시예를 설명하기 목적일 뿐 한정의 목적이 아니라는 것으로 이 해되어야 한다. 또한, 설명의 명료성을 위해 아래의 도면들에서 과장, 생략 등 다양한 변형이 적용된 일부 요소 들이 도시될 수 있다. 도 1은, 본 출원의 일 측면에 따른, 다중 장기 암 진단 시스템의 모델 개발부의 개략도이다. 도 2는, 본 출원의 일 실시예에서, 다중 장기 암 진단 시스템의 모델 추론부의 개략도이다. 도 3은, 본 출원의 일 실시예에서, 유리 슬라이드에서 병리 이미지를 스캔하여 Whole Slide Image(WSI)를 생성 하고 이를 인공지능 모델에 입력하는 프로세스를 나타낸 도면이다. 도 4a 및 도 4b는, 본 출원의 일 실시예에서, 각 장기별 암 진단에 대한 데이터셋 구성 정보를 나타낸 도면이다. 도 5는, 본 출원의 일 실시예에서, 병리 이미지의 전처리 과정을 도시한 도면이다. 도 6은, 본 출원의 일 실시예에서, 다중 인스턴스 학습(MIL) 방법을 설명하는 도면이다. 도 7은, 본 출원의 일 실시예에서, MT-MIL 모델이 장기 분류, 암의 병기(grading) 예측 및 형태학적 하위 유형 분류를 포함하는 하나 이상의 보조 작업(auxiliary task)을 수행하는 과정을 도시한 도면이다. 도 8은, 본 출원의 일 실시예에서, 다양한 데이터셋에서의 모델 성능 비교 표이다. 도 9a 및 도 9b는, 본 출원의 일 실시예에서, 테스트셋에 대한 장기별 AUC 평가 결과 및 장기별 정확도 평가 결 과를 나타내는 표이다. 도 10은, 본 출원의 일 실시예에서, 테스트셋에 대한 림프절 검증 결과를 나타내는 표이다. 도 11a 내지 도 11c는, 본 출원의 일 실시예에서, TCGA 테스트셋(공개 데이터셋)에 대한 암종(Carcinoma), 선암 종(Adenocarcinoma), 육종 및 림프종(Sarcoma & Lymphoma) 검증 결과를 나타내는 표이다. 도 12a 내지 도 12f는, 본 출원의 일 실시예에서, 의료 영상의 크기에 따른 추론 시간(inference time)을 측정 한 표이고, 각각은 1.25× 배율, 2.5× 배율, 5× 배율, 10× 배율, 20× 배율 및 40× 배율에서의 추론 시간을 나타낸다."}
