{"patent_id": "10-2022-0144647", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0062771", "출원번호": "10-2022-0144647", "발명의 명칭": "데이터 선별 장치 및 방법", "출원인": "주식회사 케이티", "발명자": "송영택"}}
{"patent_id": "10-2022-0144647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 언레이블드 데이터를 복수의 그룹으로 분류하는 단계;그룹 별 준지도 학습을 통하여, 복수의 그룹에 각각 대응하는 복수의 그룹 모델을 생성하는 단계;그룹 모델의 성능이 제1 기준을 만족하게 하는 하나 이상의 그룹의 선별, 선별된 그룹들 내 데이터를 이용한 복수의 그룹의 재생성, 재생성된 복수의 그룹에 대한 그룹 별 트레이닝을 통한 복수의 그룹 모델의 재성성을 1회이상 반복 수행하는 단계; 및생성 또는 재생성된 그룹들 중, 그룹 모델의 성능이 제2 기준을 만족하게 하는 하나 이상의 그룹을 최종 선별하는 단계;를 포함하는데이터 선별 방법."}
{"patent_id": "10-2022-0144647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 그룹의 선별, 복수의 그룹의 재생성, 복수의 그룹 모델의 재생성을 1회 이상 반복 수행하는 단계는,그룹 모델의 성능을 기본 모델의 성능보다 우수하게 하는 하나 이상의 그룹을 선별하는 단계;를 포함하고,상기 기본 모델은,신뢰 데이터를 이용하여 선행적으로 학습된 모델인데이터 선별 방법."}
{"patent_id": "10-2022-0144647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 그룹의 선별, 복수의 그룹의 재생성, 복수의 그룹 모델의 재생성을 1회 이상 반복 수행하는 단계는,선별된 그룹들 내 데이터들의 일부가 교체되도록 복수의 그룹을 재생성하는 단계;를 더 포함하는데이터 선별 방법."}
{"patent_id": "10-2022-0144647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 선별된 그룹들 내 데이터들의 일부가 교체되도록 복수의 그룹을 재생성하는 단계는,상기 기본 모델의 성능과 상기 선별된 그룹들의 그룹 모델들 간의 성능 차들에 기반하여, 상기 선별된 그룹들에각각 대응하는 가중치들을 산출하는 단계;를 포함하는데이터 선별 방법."}
{"patent_id": "10-2022-0144647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서,'상기 선별된 그룹들 중 제1 그룹의 그룹 모델과 상기 기본 모델의 성능 차'가 '상기 선별된 그룹들 중 제2 그룹의 그룹 모델과 상기 기본 모델의 성능 차'보다 큰 경우, 상기 제1 그룹의 가중치가 상기 제2 그룹의 가중치보다 작은데이터 선별 방법.공개특허 10-2024-0062771-2-청구항 6 제 5항에 있어서,상기 선별된 그룹들 내 데이터들의 일부가 교체되도록 복수의 그룹을 재생성하는 단계는,상기 산출된 가중치들에 비례하도록, 상기 선별된 그룹들 내 데이터의 교체량을 결정하는 단계;를 포함하는데이터 선별 방법."}
{"patent_id": "10-2022-0144647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항에 있어서,상기 그룹의 선별, 복수의 그룹의 재생성, 복수의 그룹 모델의 재생성을 1회 이상 반복 수행하는 단계는,그룹 모델의 성능이 제1 기준을 만족하게 하는 그룹이 1개 남으면, 상기 반복 수행을 중단하는 단계;를 포함하는데이터 선별 방법."}
{"patent_id": "10-2022-0144647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1항에 있어서,상기 생성 또는 재생성된 그룹들 중, 그룹 모델의 성능이 제2 기준을 만족하게 하는 하나 이상의 그룹을 최종선별하는 단계는,상기 생성 또는 재생성된 그룹들 중, 그룹 모델이 가장 우수한 성능을 나타내게 하는 하나의 그룹을 최종 선별하는 단계;를 포함하는데이터 선별 방법."}
{"patent_id": "10-2022-0144647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "복수의 언레이블드 데이터를 수집하는 데이터 획득부; 및복수의 언레이블드 데이터를 복수의 그룹으로 분류하고, 그룹 별 준지도 학습을 통하여, 복수의 그룹에 각각 대응하는 복수의 그룹 모델을 생성하고, 그룹 모델의 성능이 제1 기준을 만족하게 하는 하나 이상의 그룹의 선별,선별된 그룹들 내 데이터를 이용한 복수의 그룹의 재생성, 재생성된 복수의 그룹에 대한 그룹 별 트레이닝을 통한 복수의 그룹 모델의 재성성을 1회 이상 반복 수행하고, 생성 또는 재생성된 그룹들 중, 그룹 모델의 성능이제2 기준을 만족하게 하는 하나 이상의 그룹을 최종 선별하는 제어부;를 포함하는데이터 선별 장치."}
{"patent_id": "10-2022-0144647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,상기 제어부는,그룹 모델의 성능을 기본 모델의 성능보다 우수하게 하는 하나 이상의 그룹을 선별하고,상기 기본 모델은,신뢰 데이터를 이용하여 선행적으로 학습된 모델인데이터 선별 장치."}
{"patent_id": "10-2022-0144647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10항에 있어서,상기 제어부는,공개특허 10-2024-0062771-3-선별된 그룹들 내 데이터들의 일부가 교체되도록 복수의 그룹을 재생성하는데이터 선별 장치."}
{"patent_id": "10-2022-0144647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 제어부는,상기 기본 모델의 성능과 상기 선별된 그룹들의 그룹 모델들 간의 성능 차들에 기반하여, 상기 선별된 그룹들에각각 대응하는 가중치들을 산출하는데이터 선별 장치."}
{"patent_id": "10-2022-0144647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 있어서,'상기 선별된 그룹들 중 제1 그룹의 그룹 모델과 상기 기본 모델의 성능 차'가 '상기 선별된 그룹들 중 제2 그룹의 그룹 모델과 상기 기본 모델의 성능 차'보다 큰 경우, 상기 제1 그룹의 가중치가 상기 제2 그룹의 가중치보다 작은데이터 선별 장치."}
{"patent_id": "10-2022-0144647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서,상기 제어부는,상기 산출된 가중치들에 비례하도록, 상기 선별된 그룹들 내 데이터의 교체량을 결정하는데이터 선별 장치."}
{"patent_id": "10-2022-0144647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 9항에 있어서,상기 제어부는,그룹 모델의 성능이 제1 기준을 만족하게 하는 그룹이 1개 남으면, 상기 반복 수행을 중단하는데이터 선별 장치."}
{"patent_id": "10-2022-0144647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 9항에 있어서,상기 제어부는,상기 생성 또는 재생성된 그룹들 중, 그룹 모델이 가장 우수한 성능을 나타내게 하는 하나의 그룹을 최종 선별하는데이터 선별 장치."}
{"patent_id": "10-2022-0144647", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "데이터 선별 방법이 개시된다. 본 발명에 따른 데이터 선별 방법은, 복수의 언레이블드 데이터를 복수의 그룹으 로 분류하는 단계, 그룹 별 준지도 학습을 통하여, 복수의 그룹에 각각 대응하는 복수의 그룹 모델을 생성하는 단계, 그룹 모델의 성능이 제1 기준을 만족하게 하는 하나 이상의 그룹의 선별, 선별된 그룹들 내 데이터를 이용 한 복수의 그룹의 재생성, 재생성된 복수의 그룹에 대한 그룹 별 트레이닝을 통한 복수의 그룹 모델의 재성성을 1회 이상 반복 수행하는 단계, 및, 생성 또는 재생성된 그룹들 중, 그룹 모델의 성능이 제2 기준을 만족하게 하 는 하나 이상의 그룹을 최종 선별하는 단계를 포함한다."}
{"patent_id": "10-2022-0144647", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은, 슈도 라벨에 의해 레이블링된 데이터들에 대한 그룹핑, 그룹의 성능 평가 및 선별, 재그룹핑을 반복 함으로써, 유의미한 데이터를 추출할 수 있는, 데이터 선별 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0144647", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능(artificial intelligence)은 인간의 지능으로 할 수 있는 사고, 학습, 자기계발 등을 컴퓨터가 할 수 있도록 하는 방법을 연구하는 컴퓨터 공학 및 정보기술의 한 분야로, 컴퓨터가 인간의 지능적인 행동을 모방할 수 있도록 하는 것을 의미한다. 데이터를 활용한 기계 학습 방법은 크게, 학습 데이터에 대한 라벨(label)이 주어진 상태에서 인공지능 모델을 학습시키는 지도 학습(supervised learning) 및 학습 데이터에 대한 라벨이 주어지지 않은 상태에서 인공지능 모델을 학습시키는 비지도 학습(unsupervised learning)으로 나뉜다. 지도 학습의 경우, 신뢰 데이터(신뢰 라벨(인간 등에 의해 생성된, 신뢰도 높은 라벨)이 매칭된 데이터)를 이용 하기 때문에 높은 정확도를 나타내는 모델을 생성할 수 있는 반면, 데이터에 대한 레이블링(labeling)을 수행하 는데 많은 시간 및 비용이 소요되고, 도메인에 따라 라벨(label)의 형태가 달라진다는 한계를 가진다. 최근 많은 데이터를 수집 및 유통하는 환경이 조성되면서, 인공지능 학습을 위한 데이터의 포화 현상이 나타나 고 있다. 그리고 비지도 학습의 경우에는 레이블링이 되지 않은 언레이블드 데이터(unlabeled data)를 활용하여 인공지능 모델을 학습시키기 때문에, 레이블링에 소요되는 시간 및 비용을 절약할 수 있다는 장점이 있는 반면, 비지도 학습에 기반하여 생성된 인공지능 모델의 정확도가 낮고, 도메인에 따라 학습 방법이 달라져야 한다는 한계를 가진다. 지도 학습 및 비지도 학습의 문제를 해결하기 위하여, 최근에는 준지도 학습(semi-supervised learning) 방식의 기계 학습 방법이 연구되고 있다. 준지도 학습이란, 라벨이 매칭된 레이블드 데이터(labeled data)와 라벨이 존 재하지 않는 언레이블드 데이터(unlabeled data)를 함께 활용하여 인공지능 모델을 트레이닝하는 기법으로, 지 속적으로 공급되는 데이터로 인한 데이터 포화 현상을 해결하면서도 지도 학습에서보다 더 높은 정확도를 가지 는 인공지능 모델을 획득할 수 있다. 준지도 학습에서는 주로 proxy-label 기법을 활용하는데, proxy-label 기법이란 신뢰 데이터(신뢰 라벨(인간 등 에 의해 생성된, 신뢰도 높은 라벨)이 매칭된 데이터)의 세트로 학습된 기본 모델을 이용하여 언레이블드 데이 터(unlabeled data) 들에 대한 슈도 라벨(pseudo-label)을 생성하고, 신뢰 데이터 및 레이블드 데이터(슈도 라 벨(pseudo-label)이 매칭된 데이터)를 이용하여 인공지능 모델을 학습시키는 기법을 의미한다. 하지만 준지도 학습 역시, 정확도 향상과 데이터 포화 현상의 문제들을 무조건적으로 해결할 수 있는 것은 아니 다. 준지도 학습에서 존재하는 많은 이슈 중 대표적인 세가지 이슈를 설명하면, 첫재는 기본 모델이 생성한 슈 도 라벨(pseudo-label)이 사람이 만든 신뢰 라벨보다 불확실성이 크기 때문에, 인공지능 모델의 학습에 그대로 사용하기에는 슈도 라벨(pseudo-label)들을 100프로 신뢰할 수 없다는 것이다. 둘째는 데이터의 비례 문제로, 신뢰 데이터와 언레이블드 데이터의 비율을 어떻게 조절할 것인지에 대한 이슈가 발생한다. 예를 들어 신뢰 데 이터의 수가 매우 적은 경우 슈도 라벨을 생성하기 위한 기본 모델 자체의 정확도가 낮아지기 때문에, 신뢰 데 이터와 함께 레이블드 데이터(슈도 라벨(pseudo-label)이 매칭된 데이터)를 이용하여 인공지능 모델을 학습시키 는 것이 도리어 인공지능 모델의 정확도를 낮추게 될 수 있다. 마지막은 언레이블드 데이터의 하드 케이스 문제 로, 언레이블드 데이터 자체가 라벨을 만들기 어려운 유형에 속하는 경우, 준지도 학습 중 생성되는 슈도 라벨 (pseudo-label) 또한 불확실성을 가질수 밖에 없다."}
{"patent_id": "10-2022-0144647", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 해결하기 위한 것으로, 본 발명의 목적은, 슈도 라벨에 의해 레이블링된 데이터들에 대한 그룹핑, 그룹의 성능 평가 및 선별, 재그룹핑을 반복함으로써, 유의미한 데이터를 추출할 수 있는, 데이터 선별 장치 및 방법을 제공하기 위함이다."}
{"patent_id": "10-2022-0144647", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 데이터 선별 방법은, 복수의 언레이블드 데이터를 복수의 그룹으로 분류하는 단계, 그룹 별 준 지도 학습을 통하여, 복수의 그룹에 각각 대응하는 복수의 그룹 모델을 생성하는 단계, 그룹 모델의 성능이 제1 기준을 만족하게 하는 하나 이상의 그룹의 선별, 선별된 그룹들 내 데이터를 이용한 복수의 그룹의 재생성, 재 생성된 복수의 그룹에 대한 그룹 별 트레이닝을 통한 복수의 그룹 모델의 재성성을 1회 이상 반복 수행하는 단 계, 및, 생성 또는 재생성된 그룹들 중, 그룹 모델의 성능이 제2 기준을 만족하게 하는 하나 이상의 그룹을 최 종 선별하는 단계를 포함한다.이 경우 상기 그룹의 선별, 복수의 그룹의 재생성, 복수의 그룹 모델의 재생성을 1회 이상 반복 수행하는 단계 는, 그룹 모델의 성능을 기본 모델의 성능보다 우수하게 하는 하나 이상의 그룹을 선별하는 단계를 포함하고, 상기 기본 모델은, 신뢰 데이터를 이용하여 선행적으로 학습된 모델일 수 있다. 이 경우 상기 그룹의 선별, 복수의 그룹의 재생성, 복수의 그룹 모델의 재생성을 1회 이상 반복 수행하는 단계 는, 선별된 그룹들 내 데이터들의 일부가 교체되도록 복수의 그룹을 재생성하는 단계를 더 포함할 수 있다. 이 경우 상기 선별된 그룹들 내 데이터들의 일부가 교체되도록 복수의 그룹을 재생성하는 단계는, 상기 기본 모 델의 성능과 상기 선별된 그룹들의 그룹 모델들 간의 성능 차들에 기반하여, 상기 선별된 그룹들에 각각 대응하 는 가중치들을 산출하는 단계를 포함할 수 있다. 이 경우 '상기 선별된 그룹들 중 제1 그룹의 그룹 모델과 상기 기본 모델의 성능 차'가 '상기 선별된 그룹들 중 제2 그룹의 그룹 모델과 상기 기본 모델의 성능 차'보다 큰 경우, 상기 제1 그룹의 가중치가 상기 제2 그룹의 가중치보다 작을 수 있다. 이 경우 상기 선별된 그룹들 내 데이터들의 일부가 교체되도록 복수의 그룹을 재생성하는 단계는, 상기 산출된 가중치들에 비례하도록, 상기 선별된 그룹들 내 데이터의 교체량을 결정하는 단계를 포함할 수 있다. 한편 상기 그룹의 선별, 복수의 그룹의 재생성, 복수의 그룹 모델의 재생성을 1회 이상 반복 수행하는 단계는, 그룹 모델의 성능이 제1 기준을 만족하게 하는 그룹이 1개 남으면, 상기 반복 수행을 중단하는 단계를 포함할 수 있다. 한편 상기 생성 또는 재생성된 그룹들 중, 그룹 모델의 성능이 제2 기준을 만족하게 하는 하나 이상의 그룹을 최종 선별하는 단계는, 상기 생성 또는 재생성된 그룹들 중, 그룹 모델이 가장 우수한 성능을 나타내게 하는 하 나의 그룹을 최종 선별하는 단계를 포함할 수 있다. 한편 본 발명에 따른 데이터 선별 장치는, 복수의 언레이블드 데이터를 수집하는 데이터 획득부, 및, 복수의 언 레이블드 데이터를 복수의 그룹으로 분류하고, 그룹 별 준지도 학습을 통하여, 복수의 그룹에 각각 대응하는 복 수의 그룹 모델을 생성하고, 그룹 모델의 성능이 제1 기준을 만족하게 하는 하나 이상의 그룹의 선별, 선별된 그룹들 내 데이터를 이용한 복수의 그룹의 재생성, 재생성된 복수의 그룹에 대한 그룹 별 트레이닝을 통한 복수 의 그룹 모델의 재성성을 1회 이상 반복 수행하고, 생성 또는 재생성된 그룹들 중, 그룹 모델의 성능이 제2 기 준을 만족하게 하는 하나 이상의 그룹을 최종 선별하는 제어부를 포함한다. 이 경우 상기 제어부는, 그룹 모델의 성능을 기본 모델의 성능보다 우수하게 하는 하나 이상의 그룹을 선별하고, 상기 기본 모델은, 신뢰 데이터를 이용하여 선행적으로 학습된 모델일 수 있다. 이 경우 상기 제어부는, 선별된 그룹들 내 데이터들의 일부가 교체되도록 복수의 그룹을 재생성할 수 있다. 이 경우 상기 제어부는, 상기 기본 모델의 성능과 상기 선별된 그룹들의 그룹 모델들 간의 성능 차들에 기반하 여, 상기 선별된 그룹들에 각각 대응하는 가중치들을 산출할 수 있다. 이 경우,'상기 선별된 그룹들 중 제1 그룹의 그룹 모델과 상기 기본 모델의 성능 차'가 '상기 선별된 그룹들 중 제2 그룹의 그룹 모델과 상기 기본 모델의 성능 차'보다 큰 경우, 상기 제1 그룹의 가중치가 상기 제2 그룹의 가중치보다 작을 수 있다. 이 경우 상기 제어부는, 상기 산출된 가중치들에 비례하도록, 상기 선별된 그룹들 내 데이터의 교체량을 결정할 수 있다. 한편 상기 제어부는, 그룹 모델의 성능이 제1 기준을 만족하게 하는 그룹이 1개 남으면, 상기 반복 수행을 중단 할 수 있다. 한편 상기 제어부는, 상기 생성 또는 재생성된 그룹들 중, 그룹 모델이 가장 우수한 성능을 나타내게 하는 하나 의 그룹을 최종 선별할 수 있다."}
{"patent_id": "10-2022-0144647", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 지속적으로 공급되는 무수히 많은 데이터로부터 유의미한 데이터를 추출하고 이를 이용하여 인공지능 모델의 성능을 높일 수 있는 장점이 있다. 또한 본 발명에 따르면, 개별 데이터에 대한 평가를 수행하는 대신, 그룹별 평가를 통해 유의미한 데이터를 추 출함으로써, 적은 시간 및 노력만으로 유의미한 데이터를 용이하게 추출할 수 있는 장점이 있다. 또한 본 발명에 따르면, 그룹의 생성, 그룹 별 그룹 모델의 생성, 그룹 모델의 평가를 통한 그룹의 선별을 반복 함으로써, 평가 대상 그룹의 수를 최대한 늘리고 그 중에서 최종 그룹을 선별할 수 있는 장점이 있다. 또한 그 룹 모델의 성능이 제1 기준을 만족하지 않게 하는 그룹 내 데이터들을 그룹의 재생성 대상에서 제외함으로써, 재생성되는 그룹들이 높은 성능을 나타낼 가능성을 높힐 수 있다."}
{"patent_id": "10-2022-0144647", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또 는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘어져서 구현될 수도 있다. 본 발명의 본격적인 설명에 앞서, 본 명세서에서 사용되는 용어를 정리한다. 학습 데이터는, 그대로 또는 가공되어, 인공지능 모델의 트레이닝에 사용될 수 있는 데이터로, 신뢰 데이터, 언 레이블드 데이터(unlabeled data), 레이블드 데이터(labeled data) 등을 포함할 수 있다. 언레이블드 데이터(unlabeled data)는, 레이블링되지 않은 데이터, 즉 라벨(label)이 매칭되지 않은 데이터를 의미할 수 있다. 신뢰 데이터는, 레이블링된 데이터이며, 신뢰 라벨이 매칭된 데이터를 의미할 수 있다. 예를 들어 신뢰 라벨은, 인간이 데이터를 확인 한 후에 직접 생성한 라벨, 또는 정확도가 매우 높은 인공지능 모델에 의해 생성된 라벨 일 수 있다. 레이블드 데이터(labeled data)는, 레이블링된 데이터이며, 슈도 라벨(pseudo-label)이 매칭된 데이터를 의미할 수 있다. 또한 인공지능 모델의 트레이닝 과정에서, 신뢰 데이터 또는 레이블드 데이터는 인공지능 모델에 대한 입력 데 이터로써 제공되고, 신뢰 라벨 또는 슈도 라벨(pseudo-label)은 인공지능 모델이 추론해 내야 하는 정답 데이터 로써 제공될 수 있다. 이 경우 인공지능 모델은, 입력 데이터에 기반하여 자신이 출력한 예측 데이터와 제공된 정답 데이터 간의 차이(loss)를 이용하여 트레이닝될 수 있다. 이하에서는, proxy-label 기법에 의해 준지도 학습이 수행되는 것으로 설명하나 이에 한정되지 않으며, 준지도 학습을 수행할 수 있는 다양한 기법에 본 발명이 적용될 수 있다. 도 1은 본 발명에 따른, 데이터 선별 장치를 설명하기 위한 블록도이다. 본 발명에 따른 데이터 선별 장치는, 데이터 획득부, 제어부 및 메모리를 포함할 수 있다. 데이터 획득부는 인공지능 모델의 트레이닝에 사용되는 복수의 학습 데이터를 수집할 수 있다. 이를 위해, 데이터 획득부는 유/무선 통신 기술을 이용하여 외부 장치와 통신하기 위한 통신 회로 또는 통신 모듈을 포함하고, 외부 장치로부터 데이터를 수신할 수 있다. 또한 데이터 획득부는 데이터 입력부를 포함하고, 장치의 운용자로부터 복수의 데이터를 수신할 수 있다. 제어부는 데이터 선별 장치의 전반적인 동작을 제어할 수 있다. 용어 “제어부”는, “마이크로 프로 세서”, “컨트롤러”, “마이크로 컨트롤러”, “프로세서” 등의 용어와 혼용되어 사용될 수 있다. 또한 제어부는 메모리로부터 인공지능 모델을 독출하여 실행할 수 있다. 이에 따라, 아래에서 설명하 는 인공지능 모델의 동작은, 제어부의 동작인 것으로 볼 수도 있다. 메모리는 데이터 선별 장치의 구동을 위한 프로그램, 명령어 및 기타 데이터를 저장할 수 있다. 또한 메모리는 하나 이상의 인공지능 모델을 저장하는 인공지능 모델 데이터베이스를 포함할 수 있다. 인공지능 모델에는 공지된 다양한 인경 신경망이나 기타 구조가 사용될 수 있다. 또한 인공지능 모델은 소프트웨어 또는 하드웨어와 소프트웨어의 조합으로 구현될 수 있으며, 인공지능 모델을 구성하는 하나 이상의 명령어는 인공지능 모델 데이터베이스에 저장될 수 있다. 또한 메모리는 학습 데이터들, 학습 데이터들에 매칭되는 라벨들을 저장하는 학습 데이터 데이터베이스 를 포함할 수 있다. 또한 메모리는 그룹 별 데이터, 그룹에 대응하는 그룹 모델, 그룹 모델의 성능에 대한 정보를 저장할 수 있다. 한편 데이터 선별 장치는 출력부(미도시)를 더 포함할 수 있다. 출력부(미도시)는, 제어부의 제어 하 에, 데이터 선별 장치에 저장되거나 데이터 선별 장치에서 처리하는 정보를 사용자에게 제공할 수 있 다. 이를 위해 출력부는 정보를 디스플레이 하는 디스플레이 모듈 또는 정보를 사용자 단말에 전송하는 통 신 모듈을 포함할 수 있다. 또한 데이터 선별 장치는 사용자 입력을 수신하는 입력부(미도시)를 더 포함할 수 있다. 도 2는 본 발명에 따른, 데이터 선별 방법을 설명하기 위한 순서도이다. 본 발명에 따른 데이터 선별 방법은, 복수의 언레이블드 데이터를 복수의 그룹으로 분류하는 단계(S210), 그룹 별 준지도 학습을 통하여, 복수의 그룹에 각각 대응하는 복수의 그룹 모델을 생성하는 단계(S220), 그룹 모델의 성능이 제1 기준을 만족하게 하는 하나 이상의 그룹의 선별, 선별된 그룹들 내 데이터를 이용한 복수의 그룹의 재생성, 재생성된 복수의 그룹에 대한 그룹 별 트레이닝을 통한 복수의 그룹 모델의 재성성을 1회 이상 반복 수 행하는 단계(S230), 및, 생성 또는 재생성된 그룹들 중, 그룹 모델의 성능이 제2 기준을 만족하게 하는 하나 이 상의 그룹을 최종 선별하는 단계(S240)를 포함할 수 있다. S210를 설명하기 전, 기본 모델에 대하여 설명한다. 메모리에는 기본 모델이 저장될 수 있다. 여기서 기본 모델은 신뢰 데이터를 이용하여 선행적으로 학습된 모델일 수 있다. 구체적으로 제어부 또는 기타 학습 장치는, 신뢰 데이터 및 신뢰 데이터에 매칭된 신뢰 라벨을 이용하여 기본 모델을 트레이닝할 수 있다. 더욱 구체적으로 제어부 또는 기타 학습 장치는, 신뢰 데이터를 입력 데이터로써 기본 모델에 제공할 수 있다. 또한 기본 모델이 신뢰 데이터에 기반하여 예측 데이터를 출력하면, 제어부는 신뢰 데이터에 매칭된 신뢰 라벨(정답 데이터) 및 예측 데이터 간의 차이에 기반하여 기본 모델의 파라미터를 업데이트할 수 있다. 그 리고 제어부는 복수의 신뢰 데이터를 포함하는 신뢰 데이터 셋을 이용하여 위 동작을 반복함으로써, 기본 모델의 파라미터를 최적화 할 수 있다. S210과 관련하여, 제어부는 복수의 언레이블드 데이터를 복수의 그룹으로 분류할 수 있다. 구체적으로 데이터 획득부는 언레이블드 데이터들을, 주기적 또는 비주기적으로 수집하고, 제어부는 언레이블드 데이터들을 메모리에 저장할 수 있다. 또한 언레이블드 데이터가 일정 시간 이상 수집되어 저장되었거나 언레이블드 데이터가 일정량 이상 수집되어 저장된 경우, 제어부는 저장된 복수의 언레이블드 데이터를 복수의 그룹으로 분류할 수 있다. 이 경우 제어부는 그룹별로 동일한 수의 언레이블드 데이터가 속하도록, 복수의 언레이블드 데이터를 복수 의 그룹으로 분류할 수 있다. 또한 제어부는, 별도의 기준 없이(예를 들어, 무작위로), 복수의 언레이블드 데이터를 복수의 그룹으로 분류할 수 있다. S220과 관련하여, 제어부는 그룹 별 준지도 학습을 통하여, 복수의 그룹에 각각 대응하는 복수의 그룹 모 델을 생성할 수 있다. 이와 관련해서는 도 3을 참고하여 설명한다. 도 3은 본 발명에 따른, 복수의 그룹에 대하여 준지도 학습을 수행하는 방법을 설명하기 위한 도면이다. 도 3을 참고하면, 다섯개의 그룹(Group A, Group B, Group C, Group D, Group E)이 존재하는 것으로 가정하여 설명한다. 다섯개의 그룹(Group A, Group B, Group C, Group D, Group E)에는 언레이블드 데이터들이 포함될 수 있다. 제어부는 제1 내지 제5 그룹 각각에 대하여 준 지도학습을 수행할 수 있다. 제1 그룹(Group A)을 예시적으 로 설명하나, 제1 그룹(Group A)에 대한 설명은 다른 그룹에도 적용될 수 있다. 제어부는 제1 그룹(Group A) 내 언레이블드 데이터들에 대한 슈도 라벨(pseudo-label)을 생성할 수 있다. 구체적으로 제어부는 제1 그룹(Group A) 내 언레이블드 데이터를 기본 모델에 제공하고, 기본 모델의 예측 데이터(예를 들어 클래스)를 언레이블드 데이터의 슈도 라벨(pseudo-label)로 설정할 수 있다. 이와 같은 동작 의 반복으로, 제1 그룹(Group A) 내 언레이블드 데이터들은, 슈도 라벨(pseudo-label)이 매칭된 레이블드 데이 터들로 변환될 수 있다. 이 경우 제어부는 슈도 라벨(pseudo-label)의 불확실성을 줄이기 위해 검증을 수행하고, 검증을 통과한 슈 도 라벨(pseudo-label)만을 선별할 수도 있다. 이를 위해 이미 공지된 다양한 검증 방법이 사용될 수 있다. 다음으로 제어부는 제1 그룹(Group A) 내 레이블드 데이터들 및 레이블드 데이터들에 매칭된 슈도 라벨 (pseudo-label)들을 이용하여 인공지능 모델을 트레이닝할 수 있다. 또한 제어부는 제1 그룹(Group A) 내 레이블드 데이터들 및 레이블드 데이터들에 매칭된 슈도 라벨(pseudo-label)들에 더하여, 신뢰 데이터들 및 신 뢰 데이터들에 매칭된 신뢰 라벨들을 이용하여 인공지능 모델을 트레이닝할 수 있다. 트레이닝 방법은 지도 학 습 알고리즘에 따를 수 있으며, 이는 앞서 기본 모델의 트레이닝에서 설명한 바 있다. 인공지능 모델에 대한 트레이닝이 완료되면 인공지능 모델의 파라미터가 최적화되며, 이러한 모델을 제1 그룹 모델(Model A)이라 명칭할 수 있다. 또한 제어부는 다른 그룹(Group B, Group C, Group D, Group E)에 대해서도 동일한 동작을 수행할 수 있 다. 이에 따라 복수의 그룹(Group A, Group B, Group C, Group D, Group E)에 각각 대응하는 복수의 그룹 모델 (Model A, Model B, Model C, Model D, Model E)이 생성될 수 있다. 다음으로, 제어부는 그룹 모델의 성능이 제1 기준을 만족하게 하는 하나 이상의 그룹의 선별, 선별된 그룹 들 내 데이터를 이용한 복수의 그룹의 재생성, 재생성된 복수의 그룹에 대한 그룹 별 트레이닝을 통한 복수의 그룹 모델의 재성성을 1회 이상 반복 수행할 수 있다(S230). 이와 관련해서는 도 4를 참고하여 설명한다. 도 4는 본 발명에 따른, 그룹의 선별, 복수의 그룹의 재생성, 복수의 그룹 모델의 재생성을 1회 이상 반복 수행 하는 방법을 설명하기 위한 순서도이다.도 4의 프로세스는 종료 조건(S232)이 만족될때까지, 1회 이상 반복 수행될 수 있다. 제어부는 그룹 모델의 성능이 제1 기준을 만족하게 하는 그룹들을 선별할 수 있다(S231). S231과 관련하여, 먼저 제어부는 기본 모델의 성능을 산출할 수 있다. 구체적으로 제어부는 테스트 데이터들의 셋을 기본 모델에 제공하고, 기본 모델이 테스트 데이터들에 기반하여 출력한 예측 데이터들 및 테 스트 데이터들에 매칭된 정답 데이터들의 차이에 기반하여 기본 모델의 평균 오차 값(mean Average Precision, mAP)을 산출할 수 있다. 또한 제어부는 제1 그룹 모델(Model A)의 성능을 산출할 수 있다. 구체적으로 제어부는 테스트 데이 터들의 셋을 제1 그룹 모델(Model A)에 제공하고, 제1 그룹 모델이 테스트 데이터들에 기반하여 출력한 예측 데 이터들 및 테스트 데이터들에 매칭된 정답 데이터들의 차이에 기반하여 제1 그룹 모델의 평균 오차 값(mean Average Precision, mAP)을 산출할 수 있다. 그리고 나서, 제어부는 기본 모델의 성능 및 제1 그룹 모델(Model A)의 성능에 기반하여, 기본 모델과 제1 그룹 모델(Model A)의 성능 차를 산출할 수 있다. 성능이란 인공지능 모델의 정확도를 의미하는 것이므로, “성 능 차”는 “정확도 차”라는 용어와 혼용되어 사용될 수 있다. 기본 모델과 그룹 모델의 성능 차는 아래와 같 은 수학식으로 표현될 수 있다. 수학식 1"}
{"patent_id": "10-2022-0144647", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "( : 기본 모델과 그룹 모델의 성능 차, : 기본 모델의 평균 오차 값, : 그룹 모델의 평균 오차 값) 제어부는 기본 모델과 복수의 그룹 모델의 성능 차들을 산출할 수 있다. 성능 차들의 예시는 다음과 같다. 표 1"}
{"patent_id": "10-2022-0144647", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "제1 기준의 일 예시로, 제어부는 그룹 모델의 성능이 기본 모델의 성능보다 우수하게 하는 하나 이상의 그 룹을 선별할 수 있다. 구체적으로 수학식 1을 다시 참고하면, 그룹 모델의 평균 오차 값이 기본 모델의 평균 오차 값보다 작다는 것은, 해당 그룹 모델의 성능이 기본 모델의 성능보다 우수하다는 것을 의미한다. 따라서 제어부는 복수의 그룹 모델(Model A, Model B, Model C, Model D, Model E) 중 기본 모델과의 성능 차가 양수인 하나 이상의 그 룹 모델(Model B, Model D, Model E)을 선별할 수 있다. 또한 제어부는 그룹 모델의 성능을 기본 모델의 성능보다 우수하게 한 하나 이상의 그룹(Group B, Group D, Group E)을 선별할 수 있다. 한편 그룹 모델의 성능이 제1 기준을 만족한다는 것이, 그룹 모델의 성능이 기본 모델의 성능보다 우수하다는 것으로 설명하였으나 이에 한정되지 않는다. 일 실시 예로, 그룹 모델의 성능이 제1 기준을 만족한다는 것은, 그룹 모델의 성능이 소정의 값을 만족한다는 것을 의미할 수 있다. 예를 들어 제어부는 복수의 그룹 모델 중, 그룹 모델의 평균 오차 값(mean Average Precision, mAP)이 소정의 값보다 작은 그룹 모델을 선별할 수 있다. 다음으로, 제어부는 선별된 그룹의 개수가 임계 개수 이하인지 판단할 수 있다(S232). 임계 개수가 1이라 고 가정하면, 현재 선별된 그룹의 개수는 3으로, 선별된 그룹의 개수는 임계 개수보다 크다. 따라서 제어부 는 S233 및 S234를 수행할 수 있다. 다음으로, 제어부는 선별된 그룹들 내 데이터를 이용하여 복수의 그룹을 재생성할 수 있다(S233). 구체적 으로, 제어부는 선별된 그룹들 내 데이터들의 일부가 교체되도록 복수의 그룹을 재생성할 수 있다. 이와 관련해서는 도 5를 참고하여 설명한다. 도 5는 본 발명에 따른, 복수의 그룹을 재생성하는 방법을 설명하기 위한 도면이다. 그룹 모델(Model B, Model D, Model E)의 성능이 기본 모델의 성능보다 우수하다는 것은, 인공지능 모델이 신뢰 데이터로부터는 알수 없는 정보나 패턴 등을 레이블드 데이터를 통해서 추가로 학습했다는 것을 의미한다. 이것 은 즉, 해당 인공지능 모델을 학습시킨 그룹 내에는 유의미한 데이터, 그리고 슈도 라벨이 적절하게 매칭된 데 이터가 다수 존재한다는 것을 의미한다. 따라서 도 5a에서 도시한 바와 같이, 제어부는 그룹 모델의 성능 이 제1 기준을 만족하게 하는 복수의 그룹(Group B, Group D, Group E) 내 데이터들을 이용하여 복수의 그룹을 재생성할 수 있다. 반면에 그룹 모델(Group A, Group C)의 성능이 기본 모델의 성능보다 낮다는 것은, 해당 그룹에 유의미한 데이 터, 그리고 슈도 라벨이 적절하게 매칭된 데이터가 적다는 것을 의미하며, 이것은 해당 그룹이 기본 모델의 성 능을 높이는데 부적합한 그룹이라는 것을 의미한다. 따라서 제어부는 그룹 모델의 성능이 제1 기준을 만족 하지 않게 하는 하나 이상의 그룹(예를 들어, 기본 모델과의 성능 차가 음수인 하나 이상의 그룹 모델(Group A, Group C)) 내 데이터들을, 복수의 그룹을 재생성하는 대상에서 제외할 수 있다. 이 경우 제어부는 선별된 복수의 그룹(Group B, Group D, Group E) 내 데이터들을 재분류 하여, 복수의 그 룹(Group F, Group G, Group H)를 재생성할 수 있다. 구체적으로 제어부는 복수의 그룹(Group B, Group D, Group E) 중 하나의 그룹 내 데이터의 일부를, 복수의 그룹(Group B, Group D, Group E) 중 다른 그룹 내 데이터로 교체하는 방식으로, 복수의 그룹(Group F, Group G, Group H)를 새롭게 생성할 수 있다. 더욱 구체적으로, 제어부는 선별된 복수의 그룹 중 제2 그룹(Group B) 내 데이터들의 일부를 다른 그룹 (Group D, Group E) 내 데이터로 교체하여 제6 그룹(Model F)를 생성할 수 있다. 즉 제어부는 제2 그룹 (Group B) 내 데이터들의 일부를 다른 그룹(Group D, Group E) 중 하나 이상의 그룹으로 이동시키고, 이동한 데 이터는 제2 그룹(Group B)에서 제거할 수 있다. 또한 제어부는 다른 그룹(Group D, Group E) 중 하나 이 상의 그룹 내 데이터들의 일부를 제2 그룹(Group B)으로 이동시키고, 이동한 데이터는 본래 소속되었던 그룹에 서 제거할 수 있다. 한편 제2 그룹(Group B)에서 하나 이상의 다른 그룹으로 이동한 데이터의 수는, 하나 이상의 다른 그룹에서 제2 그룹(Group B)으로 이동한 데이터의 수와 동일할 수 있다. 이 경우, 제2 그룹(Group B)과, 제2 그룹(Group B) 내 데이터들의 일부를 교체함으로써 생성된 제6 그룹(Group F)은, 데이터의 수가 동일할 수 있다. 제어부는 선별된 복수의 그룹 중 다른 그룹(Group D, Group E)에 대해서도 동일한 동작을 수행할 수 있다. 이에 따라 제6 그룹(Group F)과 함께, 제7 그룹(Group G) 및 제8 그룹(Group H)이 새롭게 생성될 수 있다. 다음은, 그룹 내 데이터의 교체량을 결정하는 방법에 대하여 설명한다. 먼저 제어부는 기본 모델의 성능과 선별된 그룹들의 그룹 모델들 간의 성능 차들에 기반하여, 선별된 그룹 들(Group B, Group D, Group E)에 각각 대응하는 가중치들을 산출할 수 있다. 이는 다음과 같은 수학식으로 표 현될 수 있다. 수학식 2"}
{"patent_id": "10-2022-0144647", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "( : 해당 그룹에 대응하는 성능 차, G: 선별된 그룹들의 성능 차들의 최소 공배수) 예를 들어 표 1의 예시를 다시 참고하면, 제2 그룹(Group B)에 대응하는 성능 차는 +2, 제4 그룹(Group D)에 대 응하는 성능 차는 +4, 제5 그룹(Group E)에 대응하는 성능 차는 +3이다. 이 경우 제어부는 선별된 그룹들 의 성능 차들의 최소 공배수인 12를 산출할 수 있다. 그리고 최소 공배수 12를 수학식 2에 대입함으로써, 제어 부는 제2 그룹(Group B)의 가중치인 6, 제4 그룹(Group D)의 가중치인 3, 제5 그룹(Group E)의 가중치인 4를 산출할 수 있다. 즉, 제4 그룹의 제4 그룹 모델과 기본 모델의 성능 차(+4)가 제2 그룹의 제2 그룹 모델과 기본 모델의 성능 차 (+2)보다 큰 경우, 제4 그룹의 가중치는 제2 그룹의 가중치보다 작을 수 있다. 또한 제4 그룹의 제4 그룹 모델과 기본 모델의 성능 차(+4)가 제5 그룹의 제5 그룹 모델과 기본 모델의 성능 차(+3)보다 큰 경우, 제4 그 룹의 가중치는 제5 그룹의 가중치보다 작을 수 있다. 다음으로, 제어부는 산출된 가중치들에 비례하도록, 선별된 그룹들 내 데이터들의 교체량을 결정할 수 있 다. 구체적으로 제어부는 산출된 가중치들에 비례하도록, 선별된 복수의 그룹 내 교체 대상 데이터의 수를 결정할 수 있다. 예를 들어 제2 그룹(Group B)의 가중치와 제4 그룹(Group D)의 가중치의 비율은 6:3(2:1)이다. 이 경우 제어부는 제2 그룹(Group B)의 교체 대상 데이터와 제4 그룹(Group D)의 교 체 대상 데이터의 비율을 6:3(2:1)으로 결정할 수 있다. 다른 예를 들어 제2 그룹(Group B)의 가중치와 제5 그룹(Group E)의 가중치의 비율은 6:4(3:2)이다. 이 경우 제어부는 제2 그룹(Group B)의 교체 대상 데이터와 제5 그룹(Group E)의 교체 대상 데이터 의 비율을 6:4(3:2)로 결정할 수 있다. 또한 제4 그룹(Group D)의 가중치와 제5 그룹(Group E)의 가중 치의 비율은 3:4이다. 이 경우 제어부는 제4 그룹(Group D)의 교체 대상 데이터와 제5 그룹 (Group E)의 교체 대상 데이터의 비율을 3:4로 결정할 수 있다. 그룹 모델의 성능이 기본 모델의 성능보다 우수하면서 성능차가 크다는 것은, 해당 그룹에 유의미한 데이터, 그 리고 슈도 라벨이 적절하게 매칭된 데이터가 가장 많이 존재한 다는 것을 의미한다. 따라서 제어부는 그룹 모델과 기본 모델 간의 성능 차가 클수록 해당 그룹 내 데이터의 교체량은 적게 설정함으로써, 더욱 우수한 성 능을 나타내는 그룹이 재생성될 확률을 높힐 수 있다. 가중치에 기반하여 교체량이 결정되면, 제어부는 선별된 복수의 그룹(Group B, Group D, Group E) 내 교체 대상 데이터(510, 520, 530)를 교체할 수 있다. 도 5b를 참고하면, 교체 대상 데이터를 교체하는 하나의 예가 도시되어 있다. 구체적으로 제어부는 그룹 내 교체 대상 데이터 모두를 하나 이상의 다른 그룹으로 이동시키고, 하나 이상의 다른 그룹 내 교체 대상 데이 터를 해당 그룹으로 이동시킬 수 있다. 예를 들어 도 5a를 참고하면, 제어부는 제2 그룹(Group B) 내 교체 대상 데이터 모두를 하나 이상의 다른 그룹(Group D, Group E)으로 이동시키고, 하나 이상의 다른 그룹 (Group D, Group E) 내 교체 대상 데이터(520, 530)의 일부 또는 전부를 제2 그룹(Group B)으로 이동시킬 수 있다. 도 5b에는 제2 그룹(Group B) 내 교체 대상 데이터를 교체함으로써 생성된 제6 그룹(Group F)이 도 시되어 있으며, 제2 그룹(Group B)의 교체 대상 데이터(도 5a에서 노란색으로 표시) 모두가 다른 그룹으로 이동 하고, 다른 그룹의 교체 대상 데이터(도 5a에서 분홍색, 하늘색으로 표시)가 제2 그룹(Group B)으로 이동함으로 써, 제6 그룹(Group F)이 생성되었다는 것을 알 수 있다. 이 경우 제2 그룹(Group B) 내 데이터의 수와 제6 그 룹(Group F) 내 데이터의 수는 동일할 수 있다. 또한 도 5b에는 제4 그룹(Group D) 내 교체 대상 데이터를 교체함으로써 생성된 제7 그룹(Group G)이 도시 되어 있으며, 제4 그룹(Group D)의 교체 대상 데이터(도 5a에서 분홍색으로 표시) 모두가 다른 그룹으로 이동하 고, 다른 그룹의 교체 대상 데이터(도 5a에서 노란색으로 표시)가 제4 그룹(Group D)으로 이동함으로써, 제7 그 룹(Group G)이 생성되었다는 것을 알 수 있다. 이 경우 제4 그룹(Group D) 내 데이터의 수와 제7 그룹(Group G) 내 데이터의 수는 동일할 수 있다. 도 5c를 참고하면, 교체 대상 데이터를 교체하는 또 하나의 예가 도시되어 있다. 구체적으로 제어부는 선 별된 복수의 그룹(Group B, Group D, Group E) 내 교체 대상 데이터(510, 520, 530)를 추출하고, 추출된 교체 대상 데이터(510, 520, 530)를 선별된 복수의 그룹(Group B, Group D, Group E)에 무작위로 다시 배치할 수 있 다. 도 5c에는 제2 그룹(Group B) 내 교체 대상 데이터가 교체됨으로써 생성된 제6 그룹(Group F)이 도시되어 있으며, 제2 그룹(Group B)의 교체 대상 데이터(도 5a에서 노란색으로 표시) 모두가 추출된 후, 모든 그룹의 교 체 대상 데이터(도 5a에서 노란색, 분홍색, 하늘색으로 표시)가 무작위로 혼합되어 제2 그룹(Group B)에 다시 배치되었다는 것을 알 수 있다. 이에 따라 제6 그룹(Group F)은 제2 그룹(Group B)의 교체 대상 데이터(노란색)의 일부, 제4 그룹(Group D)의 교체 대상 데이터(분홍색)의 일부 및 제5 그룹(Group E)의 교체 대상 데이터 (하늘색)의 일부를 포함할 수 있다. 이 경우 제2 그룹(Group B) 내 데이터의 수와 제6 그룹(Group F) 내 데이터 의 수는 동일할 수 있다. 또한 도 5c에는 제4 그룹(Group D) 내 교체 대상 데이터가 교체 됨으로써 생성된 제7 그룹(Group G)이 도 시되어 있으며, 제4 그룹(Group D)의 교체 대상 데이터(도 5a에서 분홍색으로 표시) 모두가 추출된 후, 모든 그 룹의 교체 대상 데이터(도 5a에서 노란색, 분홍색, 하늘색으로 표시)가 무작위로 혼합되어 제2 그룹(Group B)에 다시 배치되었다는 것을 알 수 있다. 이에 따라 제6 그룹(Group F)은 제2 그룹(Group B)의 교체 대상 데이터(노 란색)의 일부, 제4 그룹(Group D)의 교체 대상 데이터(분홍색)의 일부 및 제5 그룹(Group E)의 교체 대상 데이 터(하늘색)의 일부를 포함할 수 있다. 이 경우 제4 그룹(Group D) 내 데이터의 수와 제7 그룹(Group G) 내 데이 터의 수는 동일할 수 있다. 한편 도 5b 및 도 5c는 데이터 재배치의 예시일 뿐, 기존의 그룹의 데이터 일부가 다른 데이터로 교체되는 조건 하에서, 다양한 데이터 재배치 방법이 사용될 수 있다. 다시 도 4로 돌아가서, 제어부는 재생성된 복수의 그룹에 대한 그룹별 트레이닝을 통한 복수의 그룹 모델 의 재생성을 수행할 수 있다(S234). 구체적으로 제어부는 제6 그룹(Group F) 내 레이블드 데이터들 및 레이블드 데이터들에 매칭된 슈도 라벨 (pseudo-label)들을 이용하여 인공지능 모델을 트레이닝할 수 있다. 또한 제어부는 제6 그룹(Group F) 내 레이블드 데이터들 및 레이블드 데이터들에 매칭된 슈도 라벨(pseudo-label)들에 더하여, 신뢰 데이터들 및 신 뢰 데이터들에 매칭된 신뢰 라벨들을 이용하여 인공지능 모델을 트레이닝할 수 있다. 인공지능 모델에 대한 트 레이닝이 완료되면 인공지능 모델의 파라미터가 최적화되며, 이러한 모델을 제6 그룹 모델(Model F)이라 명칭할 수 있다. 또한 제어부는 재생성된 다른 그룹(Group G, Group H)에 대해서도 동일한 동작을 수행할 수 있다. 이에 따 라 재생성된 복수의 그룹(Group F, Group G, Group H)에 각각 대응하는 복수의 그룹 모델(Model F, Model G, Model H)이 생성될 수 있다. 또한 제어부는 종료 조건(S232)이 만족할 때까지, 도 4의 동작을 반복 수행할 수 있다. 도 6은 도 4의 동작을 반복 수행함에 따라 생성되는 그룹 및 그룹 모델을 도시한 도면이다. 도 6a를 참고하면, 도 4의 동작의 1회 반복에서 재생성된 복수의 그룹(Group F, Group G, Group H) 및 복수의 그룹 모델(Model F, Model G, Model H)이 도시되어 있다. 그리고 나서 제어부는 복수의 그룹(Group F, Group G, Group H) 및 복수의 그룹 모델(Model F, Model G, Model H)을 이용하여 도 4의 동작의 2회 반복을 수 행할 수 있다. 구체적으로 제어부는 복수의 그룹(Group F, Group G, Group H) 중 그룹 모델의 성능이 제1 기준을 만족하 게 하는 그룹들을 선별할 수 있다(S231). 더욱 구체적으로 제어부는 기본 모델과 복수의 그룹 모델(Model F, Model G, Model H)의 성능 차들을 산출할 수 있으며, 성능 차들의 예시는 다음과 같다. 표 2"}
{"patent_id": "10-2022-0144647", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이 경우 제어부는 그룹 모델의 성능이 기본 모델의 성능보다 우수하게 하는 하나 이상의 그룹(제7 그룹 (Group G), 제8 그룹(Group H))을 선별할 수 있다. 다음으로, 제어부는 선별된 그룹의 개수가 임계 개수 이하인지 판단할 수 있다(S232). 임계 개수가 1이라 고 가정하면, 현재 선별된 그룹의 개수는 2로, 선별된 그룹의 개수는 임계 개수보다 크다. 따라서 제어부 는 S233 및 S234를 수행할 수 있다. 그리고 나서, 도 6b를 참고하면, 제어부는 선별된 그룹(제7 그룹(Group G), 제8 그룹(Group H))들 내 데이 터들의 일부가 교체되도록 복수의 그룹(제9 그룹(Group I), 제10 그룹(Group J))을 재생성할 수 있다(S233). 또한 제어부는 재생성된 복수의 그룹(제9 그룹(Group I), 제10 그룹(Group J))에 대한 그룹별 트레이닝을 통한 복수의 그룹 모델(Model I, Model J)의 재생성을 수행할 수 있다(S234). 다음으로, 제어부는 도 4의 동작의 3회 반복을 수행할 수 있다. 구체적으로 제어부는 재생성된 복수 의 그룹(Group I, Group J) 중 그룹 모델의 성능이 제1 기준을 만족하게 하는 그룹들을 선별할 수 있다(S231). 기본 모델과 복수의 그룹 모델(Model I, Model J)의 성능 차들의 예시는 다음과 같다. 표 3"}
{"patent_id": "10-2022-0144647", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이 경우 제어부는 그룹 모델의 성능이 기본 모델의 성능보다 우수하게 하는 하나 이상의 그룹(제9 그룹 (Group I))을 선별할 수 있다. 한편, 그룹 모델의 성능이 제1 기준을 만족하게 하는 그룹이 1개 남으면, 제어부는 반복 수행을 중단할 수 있다. 구체적으로 제어부는 선별된 그룹의 개수가 임계 개수 이하인지 판단할 수 있다(S232). 선별된 그룹 (제9 그룹(Group I))의 개수가 1이고 임계 개수가 1인 경우, 제어부는 도 4의 동작의 반복 수행을 중단할 수 있다. 다시 도 2로 돌아가서, 제어부는 생성 또는 재생성된 그룹들 중, 그룹 모델의 성능이 제2 기준을 만족하게 하는 하나 이상의 그룹을 최종 선별할 수 있다(S240). 먼저 생성 또는 재생성된 그룹들 및 그룹들에 대응하는 성능차들을 나열하면 다음과 같다. 표 4"}
{"patent_id": "10-2022-0144647", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "이 경우 제어부는, 생성 또는 재생성된 그룹들 중, 그룹 모델이 가장 우수한 성능을 나타내게 하는 하나의 그룹을 최종 선별할 수 있다. 즉 제2 기준은 “그룹 모델과 기본 모델과의 성능 차가 양수이며 기본 모델과의 성능 차가 가장 클 것”일 수 있으며, 이 경우 제어부는 그룹 모델이 가장 높은 성능을 나타내게 한 제4 그룹(Group D)을 최종 선별할 수 있다. 제4 그룹(Group D)이 최종 선별 되면, 제어부는 제4 그룹(Group D)을 제외한 다른 그룹의 데이터들을 메모 리로부터 삭제할 수 있다. 또한 제어부는 제4 그룹(Group D) 내 레이블드 데이터들 및 레이블드 데이 터들에 매칭된 슈도 라벨(pseudo-label)들, 그리고 신뢰 데이터들 및 신뢰 데이터들에 매칭된 신뢰 라벨들을 이 용하여 인공지능 모델을 트레이닝할 수 있다. 한편 그룹 모델이 가장 우수한 성능을 나타내게 하는 하나의 그룹을 최종 선별하는 것으로 제2 기준을 설명하였 으나 이에 한정되지 않는다. 일 실시예로, 제어부는 그룹 모델의 성능이 일정 수준 이상인 하나 이상의 그 룹을 최종 선별할 수 있다. 예를 들어 제어부는 그룹 모델과 기본 모델과의 성능 차가 +3 이상인 하나 이 상의 그룹(Group D, Group E, Group G)을 최종 선별 할 수 있다. 제2 기준의 다른 실시예로, 제어부는 그룹 모델의 성능이 더 우수한 일정 개수의 그룹을 최종 선별할 할 수 있다. 예를 들어 제어부는 그룹 모델과 기본 모델과의 성능 차가 다른 그룹 모델보다 더 큰 일정 개수(예를 들어 3개)의 그룹(Group D, Group E, Group G)을 최종 선별 할 수 있다. 한편 다양한 제2 기준의 예시들이 존재할 수 있으나, 제2 기준의 다양한 예시들은 모두, 최종 선별되는 그룹의 그룹 모델이 기본 모델보다 더 우수한 성능을 나타내야 한다. 지속적으로 공급되는 언레이블드 데이터를 무조건적으로 사용하여 준지도 학습을 수행해서는 인공지능 모델의 성능을 높힐 수 없다. 그리고 본 발명에 따르면, 지속적으로 공급되는 무수히 많은 데이터로부터 유의미한 데이 터를 추출하고 이를 이용하여 인공지능 모델의 성능을 높일 수 있는 장점이 있다. 또한 본 발명에 따르면, 개별 데이터에 대한 평가를 수행하는 대신, 그룹별 평가를 통해 유의미한 데이터를 추 출함으로써, 적은 시간 및 노력만으로 유의미한 데이터를 용이하게 추출할 수 있는 장점이 있다. 또한 본 발명에 따르면, 그룹의 생성, 그룹 별 그룹 모델의 생성, 그룹 모델의 평가를 통한 그룹의 선별을 반복 함으로써, 평가 대상 그룹의 수를 최대한 늘리고 그 중에서 최종 그룹을 선별할 수 있는 장점이 있다. 또한 그 룹 모델의 성능이 제1 기준을 만족하지 않게 하는 그룹 내 데이터들을 그룹의 재생성 대상에서 제외함으로써, 재생성되는 그룹들이 높은 성능을 나타낼 가능성을 높힐 수 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 상기 컴 퓨터는 제어부를 포함할 수도 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니 되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하 고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2022-0144647", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른, 데이터 선별 장치를 설명하기 위한 블록도이다. 도 2는 본 발명에 따른, 데이터 선별 방법을 설명하기 위한 순서도이다. 도 3은 본 발명에 따른, 복수의 그룹에 대하여 준지도 학습을 수행하는 방법을 설명하기 위한 도면이다. 도 4는 본 발명에 따른, 그룹의 선별, 복수의 그룹의 재생성, 복수의 그룹 모델의 재생성을 1회 이상 반복 수행 하는 방법을 설명하기 위한 순서도이다. 도 5는 본 발명에 따른, 복수의 그룹을 재생성하는 방법을 설명하기 위한 도면이다. 도 6은 도 4의 동작을 반복 수행함에 따라 생성되는 그룹 및 그룹 모델을 도시한 도면이다."}
