{"patent_id": "10-2023-0018219", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0125319", "출원번호": "10-2023-0018219", "발명의 명칭": "충수 이미지를 이용하여 충수 병변을 분류하는 인공지능 모델의 구축 방법, 및 그 인공지능", "출원인": "가천대학교 산학협력단", "발명자": "박소현"}}
{"patent_id": "10-2023-0018219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 단층촬영(CT)된 복수의 충수 병변 이미지 중 소정의 제외기준에 해당하는 이미지를 배제하는 준비단계(S100);컴퓨터에 의해 실행되며, 상기 컴퓨터가,준비된 복수의 충수 이미지를 원본 이미지로 입력받은 단계(S120);각각의 상기 원본 이미지에 대해 소정 위치의 관심영역(ROI)을 선택한 뒤 소정 크기로 조정하는 단계(S140);소정 크기의 이미지들 중 CT 슬라이스 시퀀스 상에서 3개의 연속 이미지(10)를 선택하는 단계(S160);상기 연속 이미지(10) 중 제 1 이미지를 레드(R) 채널에서 레드(R) 이미지(20)로 생성하고, 제 2 이미지를 그린(G) 채널에서 그린(G) 이미지(30)로 생성하고, 제 3 이미지를 블루(B) 채널에서 블루(B) 이미지(40)로 생성하는단계(S180);상기 레드(R) 이미지(20), 상기 그린(G) 이미지(30), 상기 블루(B) 이미지(40)를 중첩하여 컬러이미지(50)를 생성하는 단계(S200); 및상기 컬러이미지(50)를 이용하여 인공지능 모델을 트레이닝 하는 단계(S220);를 포함하는 것을 특징으로 하는충수 이미지를 이용하여 충수 병변을 분류하는 인공지능 모델의 구축 방법."}
{"patent_id": "10-2023-0018219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 제외기준은 상기 충수 병변이 충수암이나 대장염인 경우 및 상기 충수 병변 이미지 상에서 움직임이 있는경우, 게실염으로 인한 장 천공이 있는 경우인 것을 특징으로 하는 충수 이미지를 이용하여 충수 병변을 분류하는 인공지능 모델의 구축 방법."}
{"patent_id": "10-2023-0018219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 분류되는 상기 충수 병변은 급성충수염, 급성게실염 및 정상충수 중 하나인 것을 특징으로 하는 충수 이미지를이용하여 충수 병변을 분류하는 인공지능 모델의 구축 방법."}
{"patent_id": "10-2023-0018219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 조정단계(S140)에서 상기 소정 위치의 관심영역(ROI)은 동일한 위치에서 선택된 정사각형의 관심영역(ROI)인 것을 특징으로 하는 충수 이미지를 이용하여 충수 병변을 분류하는 인공지능 모델의 구축 방법."}
{"patent_id": "10-2023-0018219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서, 상기 조정단계(S140)에서 상기 소정 크기는 224 × 224 픽셀의 크기인 것을 특징으로 하는 충수 이미지를 이용하여 충수 병변을 분류하는 인공지능 모델의 구축 방법."}
{"patent_id": "10-2023-0018219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2024-0125319-3-제 1 항에 있어서, 상기 선택단계(S160)에서 상기 3개의 연속 이미지(10)는 2 ~ 5 mm 간격으로 촬영된 것을 특징으로 하는 충수 이미지를 이용하여 충수 병변을 분류하는 인공지능 모델의 구축 방법."}
{"patent_id": "10-2023-0018219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서, 상기 트레이닝 단계(S220)의 상기 인공지능 모델은 합성곱 신경망(Convolutional Neural Network, CNN) 모델인것을 특징으로 하는 충수 이미지를 이용하여 충수 병변을 분류하는 인공지능 모델의 구축 방법."}
{"patent_id": "10-2023-0018219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서, 상기 합성곱 신경망(CNN) 모델은 EfficientNet 모델을 포함하는 것을 특징으로 하는 충수 이미지를 이용하여 충수 병변을 분류하는 인공지능 모델의 구축 방법."}
{"patent_id": "10-2023-0018219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서, 상기 입력단계(S120)는, 상기 준비된 복수의 충수 이미지를 트레이닝 데이터 세트에 60%, 상기 인공지능 모델의 구성을 평가하고 파라미터 조정을 위한 검증 데이터 세트에 20%, 및 분류 성능을 평가하기 위한 테스트 데이터 세트에 20%를 할당하는단계를 더 포함하고, 60%의 상기 트레이닝 데이터 세트를 원본 이미지로 입력받은 것을 특징으로 하는 충수 이미지를 이용하여 충수병변을 분류하는 인공지능 모델의 구축 방법."}
{"patent_id": "10-2023-0018219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터에 의해 판독 가능하고, 제 1 항 내지 제 9 항 중 어느 한 항에 따른 구축 방법으로 구축된 인공지능 모델이 기록된 컴퓨터 판독가능 기록매체."}
{"patent_id": "10-2023-0018219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "컴퓨터 단층촬영(CT)된 복수의 충수 병변 이미지 중 소정의 제외기준에 해당하는 이미지를 배제하는 준비단계(S100);컴퓨터에 의해 실행되며, 상기 컴퓨터가,준비된 복수의 충수 이미지를 원본 이미지로 입력받은 단계(S120);각각의 상기 원본 이미지에 대해 소정 위치의 관심영역(ROI)을 선택한 뒤 소정 크기로 조정하는 단계(S140);소정 크기의 이미지들 중 CT 슬라이스 시퀀스 상에서 3개의 연속 이미지(10)를 선택하는 단계(S160);상기 연속 이미지(10)를 레드(R) 채널에서 레드(R) 이미지(20)를 생성하고, 상기 연속 이미지(10)를 그린(G) 채널에서 그린(G) 이미지(30)를 생성하고, 상기 연속 이미지(10)를 블루(B) 채널에서 블루(B) 이미지(40)를 생성하는 단계(S180);상기 레드(R) 이미지(20), 상기 그린(G) 이미지(30), 상기 블루(B) 이미지(40)를 중첩하여 컬러이미지(50)를 생성하는 단계(S200); 및상기 컬러이미지(50)를 이용하여 인공지능 모델을 트레이닝 하는 단계(S220);테스트 데이터 세트로 상기 인공지능 모델을 테스트하는 단계(S240);테스트 결과, 충수 병변 분류의 민감도, 정확도 및 특이도가 기준치 이상인지 여부를 판단하는 단계(S260);공개특허 10-2024-0125319-4-상기 민감도, 정확도 및 특이도 중 적어도 하나가 기준치에 미달하는 경우, 새로운 복수의 충수 이미지를 새로운 트레이닝 데이터 세트로 추가(S300)하여 상기 인공지능 모델을 트레이닝하고, 상기 민감도, 정확도 및 특이도가 기준치 이상인 경우, 3장의 연속이미지를 상기 인공지능 모델에 입력하여 급성충수염, 급성게실염 및 정상충수 중 하나로 추론하게 하는 단계(S280);를 포함하는 것을 특징으로 하는 인공지능 모델을 이용한 충수 병변의 분류 방법."}
{"patent_id": "10-2023-0018219", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 충수 이미지를 이용하여 충수 병변을 분류하는 인공지능 모델의 구축 방법, 및 그 인공지능 모델을 이 용한 충수병변의 분류 방법에 관한 것이다. 이를 위해, 컴퓨터 단층촬영(CT)된 복수의 충수 병변 이미지 중 소정 의 제외기준에 해당하는 이미지를 배제하는 준비단계(S100); 컴퓨터에 의해 실행되며, 컴퓨터가, 준비된 복수의 (뒷면에 계속)"}
{"patent_id": "10-2023-0018219", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 충수 이미지를 이용한 충수 병변의 분류에 관한 것으로, 보다 상세하게는 충수 이미지를 이용하여 충 수 병변을 분류하는 인공지능 모델의 구축 방법, 및 그 인공지능 모델을 이용한 충수병변의 분류 방법에 관한 것이다."}
{"patent_id": "10-2023-0018219", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 급성 하복부 통증을 호소하며 병원이나 응급실을 찾는 환자가 많다. 이 경우 흔히 컴퓨터 단층촬영 (CT)을 통해 급성충수염(급성맹장염, acute appendicitis) 또는 급성게실염(acute diverticulitis) 중 하나를 진단하게 된다. 만약 급성충수염인 경우에는 긴급히 수술을 해야 하고, 급성게실염인 경우에는 수술없이 내과적 으로 치료한다. 따라서, 급성충수염과 급성게실염을 정확히 진단하는 것이 중요하고 만약 오진하는 경우 불필요 한 수술이 이루어지거나 수술시기를 놓쳐 늑막염으로 커질 수 있다. 그런데, 방사선과 전문의는 CT영상을 통해 이러한 병변의 차이를 쉽게 구분할 수 있지만 최근 응급실에서 CT 검 사의 증가로 인해 방사선 전문의에게 큰 부담으로 작용하고 있다. 한편, 종래에는 싱글(Single) 방법이 사용된다. 싱글 방법은 한 장의 복부 골반 CT 이미지로 구성된 단일 센터, 단일 프로토콜 코호트에 대해 합성곱 신경망(Convolutional Neural Network, CNN) 모델을 사용하여 급성충수염 을 자동으로 진단하는 방식이다. 그러나, 이러한 종래의 싱글 방법은 충수의 단면에 대한 2차원 정보만을 사용 할 뿐 CT 이미지의 깊이 정보를 활용하지 못하는 단점이 있었고, 이로 인해 정확도가 떨어져서 실무적으로 사용 하기 어렵고 신뢰도가 낮았다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 특허공개번호 제 10-2021-0095483 호 (CT영상을 이용한 인공지능 기반 측두하악관절 염 진단 기술)."}
{"patent_id": "10-2023-0018219", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명은 상기와 같은 문제점을 해결하기 위하여 안출된 것으로서, 본 발명의 해결하고자 하는 과제는 충수 이미지를 이용하여 충수 병변을 분류하는 인공지능 모델의 구축 방법, 및 그 인공지능 모델을 이용한 충수 병변의 분류 방법을 제공하는 것이다. 다만, 본 발명에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하"}
{"patent_id": "10-2023-0018219", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "지 않은 또 다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에 게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0018219", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기의 기술적 과제를 달성하기 위하여, 컴퓨터 단층촬영(CT)된 복수의 충수 병변 이미지 중 소정의 제외기준에 해당하는 이미지를 배제하는 준비단계(S100); 컴퓨터에 의해 실행되며, 컴퓨터가, 준비된 복수의 충수 이미지를원본 이미지로 입력받은 단계(S120); 각각의 원본 이미지에 대해 소정 위치의 관심영역(ROI)을 선택한 뒤 소정 크기로 조정하는 단계(S140); 소정 크기의 이미지들 중 CT 슬라이스 시퀀스 상에서 3개의 연속 이미지를 선 택하는 단계(S160); 연속 이미지 중 제 1 이미지를 레드(R) 채널에서 레드(R) 이미지로 생성하고, 제 2 이미지를 그린(G) 채널에서 그린(G) 이미지로 생성하고, 제 3 이미지를 블루(B) 채널에서 블루(B) 이미지 로 생성하는 단계(S180); 레드(R) 이미지, 그린(G) 이미지, 블루(B) 이미지를 중첩하여 컬러이 미지를 생성하는 단계(S200); 및 컬러이미지를 이용하여 인공지능 모델을 트레이닝 하는 단계(S220);를 포함하는 것을 특징으로 하는 충수 이미지를 이용하여 충수 병변을 분류하는 인공지능 모델의 구축 방법이 제공 된다. 또한, 제외기준은 충수 병변이 충수암이나 대장염인 경우 및 충수 병변 이미지 상에서 움직임이 있는 경우, 게 실염으로 인한 장 천공이 있는 경우이다. 또한, 분류되는 충수 병변은 급성충수염, 급성게실염 및 정상충수 중 하나이다. 또한, 조정단계(S140)에서 소정 위치의 관심영역(ROI)은 동일한 위치에서 선택된 정사각형의 관심영역(ROI)이다. 또한, 조정단계(S140)에서 소정 크기는 224 × 224 픽셀의 크기이다. 또한, 선택단계(S160)에서 3개의 연속 이미지는 2 ~ 5 mm 간격으로 촬영된다. 또한, 트레이닝 단계(S220)의 인공지능 모델은 합성곱 신경망(Convolutional Neural Network, CNN) 모델이다. 또한, 합성곱 신경망(CNN) 모델은 EfficientNet 모델을 포함한다. 또한, 입력단계(S120)는, 준비된 복수의 충수 이미지를 트레이닝 데이터 세트에 60%, 인공지능 모델의 구성을 평가하고 파라미터 조정을 위한 검증 데이터 세트에 20%, 및 분류 성능을 평가하기 위한 테스트 데이터 세트에 20%를 할당하는 단계를 더 포함하고, 60%의 트레이닝 데이터 세트를 원본 이미지로 입력받는다. 또한, 상기와 같은 본 발명의 목적은, 또 다른 카테고리로서 컴퓨터에 의해 판독 가능하고, 전술한 구축 방법으 로 구축된 인공지능 모델이 기록된 컴퓨터 판독가능 기록매체에 의해서도 달성될 수 있다. 또한, 본 발명의 목적은, 컴퓨터 단층촬영(CT)된 복수의 충수 병변 이미지 중 소정의 제외기준에 해당하는 이미 지를 배제하는 준비단계(S100); 컴퓨터에 의해 실행되며, 컴퓨터가, 준비된 복수의 충수 이미지를 원본 이미지 로 입력받은 단계(S120); 각각의 원본 이미지에 대해 소정 위치의 관심영역(ROI)을 선택한 뒤 소정 크기로 조정 하는 단계(S140); 소정 크기의 이미지들 중 CT 슬라이스 시퀀스 상에서 3개의 연속 이미지를 선택하는 단계 (S160); 연속 이미지를 레드(R) 채널에서 레드(R) 이미지를 생성하고, 연속 이미지를 그린(G) 채널 에서 그린(G) 이미지를 생성하고, 연속 이미지를 블루(B) 채널에서 블루(B) 이미지를 생성하는 단 계(S180); 레드(R) 이미지, 그린(G) 이미지, 블루(B) 이미지를 중첩하여 컬러이미지를 생성하 는 단계(S200); 및 컬러이미지를 이용하여 인공지능 모델을 트레이닝 하는 단계(S220); 테스트 데이터 세트 로 인공지능 모델을 테스트하는 단계(S240); 테스트 결과, 충수 병변 분류의 민감도, 정확도 및 특이도가 기준 치 이상인지 여부를 판단하는 단계(S260); 민감도, 정확도 및 특이도 중 적어도 하나가 기준치에 미달하는 경우, 새로운 복수의 충수 이미지를 새로운 트레이닝 데이터 세트로 추가(S300)하여 인공지능 모델을 트레이닝 하고, 민감도, 정확도 및 특이도가 기준치 이상인 경우, 3장의 연속이미지를 인공지능 모델에 입력하여 급성충 수염, 급성게실염 및 정상충수 중 하나로 추론하게 하는 단계(S280);를 포함하는 것을 특징으로 하는 인공지능 모델을 이용한 충수 병변의 분류 방법에 의해서도 달성될 수 있다."}
{"patent_id": "10-2023-0018219", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일실시예에 따르면, 인공지능 모델이 충수의 CT 이미지로부터 충수병변의 분류 및 정상충수를 빠르고 정확하게 분류한다. 특히, CT 이미지의 깊이 정보를 활용함으로서 정확도를 높이고, EfficientNet모델을 사용하여 분석 시간을 단축 할 수 있는 효과가 있다. 따라서, 충수 이미지의 분석에 도움이 될 수 있고, 오진이나 미진을 사전에 방지할 수 있다. 다만, 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효"}
{"patent_id": "10-2023-0018219", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "과들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을것이다."}
{"patent_id": "10-2023-0018219", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명에 관한 설명은 구조적 내지 기능적 설명을 위한 실시예에 불과하므로, 본 발명의 권리범위는 본문에 설명된 실시예에 의하여 제한되는 것으로 해석 되어서는 아니 된다. 즉, 실시예는 다양한 변경이 가능하고 여러 가지 형태를 가질 수 있으므로 본 발명의 권리 범위는 기술적 사상을 실현할 수 있는 균등물들을 포함하는 것으로 이해되어야 한다. 또한, 본 발명에서 제시된 목적 또는 효과는 특정 실시예가 이를 전부 포함하여야 한다거나 그러한 효과만을 포함하여야 한다는 의미는 아 니므로, 본 발명의 권리범위는 이에 의하여 제한되는 것으로 이해되어서는 아니 될 것이다. 본 발명에서 서술되는 용어의 의미는 다음과 같이 이해되어야 할 것이다. \"제1\", \"제2\" 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위한 것으로, 이들 용어들에 의해 권리범위가 한정되어서는 아니 된다. 예를 들어, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다고 언급된 때에 는, 그 다른 구성요소에 직접적으로 연결될 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어 야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다고 언급된 때에는 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 한편, 구성요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다.단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함하는 것으로 이해되어야 하고, \"포함 하다\" 또는 \"가지다\" 등의 용어는 설시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 여기서 사용되는 모든 용어들은 다르게 정의되지 않는 한, 본 발명이 속하는 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 용어들은 관 련 기술의 문맥상 가지는 의미와 일치하는 것으로 해석되어야 하며, 본 발명에서 명백하게 정의하지 않는 한 이 상적이거나 과도하게 형식적인 의미를 지니는 것으로 해석될 수 없다. 실시예의 구성 이하, 첨부된 도면을 참조하여 바람직한 실시예의 구성을 상세히 설명하기로 한다. 도 7은 본 발명에 따라, 충 수 이미지를 이용하여 충수 병변을 분류하는 인공지능 모델의 구축 방법, 및 그 인공지능 모델을 이용한 충수병 변의 분류 방법을 나타내는 흐름도이다. 본 발명에서 분류되는 충수 병변은 급성충수염, 급성게실염 및 정상충 수이다. 도 7에 도시된 바와 같이, 먼저, 컴퓨터 단층촬영(CT)된 복수의 충수 병변 이미지 중 소정의 제외기준에 해당하 는 이미지를 배제한다(S100). 이때, 제외기준은 충수 병변이 충수암이나 대장염인 경우 및 충수 병변 이미지 상 에서 움직임이 있는 경우, 게실염으로 인한 장 천공이 있는 경우이다. CT 이미지에 충수 병변에 관한 병변 코드 를 부여하고, 컴퓨터가 이를 읽음으로서 컴퓨터가 일괄 배제할 수 있다. 이러한 제외기준을 적용함으로서 인공 지능의 모델이 더 정확하고 빠르게 구축될 수 있다. 그 다음, 컴퓨터는 준비된 복수의 충수 이미지를 원본 이미지로 입력받는다(S120). 준비된 복수의 충수 이미지 를 트레이닝 데이터 세트에 60%, 인공지능 모델의 구성을 평가하고 파라미터 조정을 위한 검증 데이터 세트에 20%, 및 분류 성능을 평가하기 위한 테스트 데이터 세트에 20%를 할당한다. 그리고, 60%의 트레이닝 데이터 세 트를 원본 이미지로 입력받는다. 그 다음, 각각의 원본 이미지에 대해 소정 위치의 관심영역(ROI)을 선택한 뒤 소정 크기로 조정한다(S140). 이 때, 관심영역(ROI)은 충수(맹장)를 중심으로 하는 동일한 위치에서 선택된 정사각형의 관심영역(ROI)이고, 소정 크기는 224 × 224 픽셀의 정사각형 크기이다. 그 다음, 정사각형 크기의 이미지들 중 CT 슬라이스 시퀀스 상에서 3개의 연속 이미지를 선택한다(S160). CT 슬라이스 시퀀스는 단층 촬영의 수직방향이고, 예를 들어 환자의 하복부에서 흉부로 향하는 방향이 될 수 있 다. CT 슬라이스 시퀀스는 2 ~ 5 mm 간격으로 수십장의 이미지를 촬영한다. 이러한 시퀀스 간격은 충수와 그 주 변에서 좁을 수 있고(예 : 2 mm), 충수에서 멀어질수록 더 넓을 수 있다(예 : 5 mm). 본 발명에서 이러한 CT 슬 라이스 시퀀스 상에서 3개의 연속 이미지를 선택한다. 3장의 연속 이미지는 각각 레드(Red) 채널, 블루 (Blue) 채널, 그린(Green) 채널을 위한 것이다. 따라서, RGB 채널을 위해 최소 3장의 연속 이미지(제 1, 2, 3 이미지)가 필요하다. 그 다음, 도 1은 3장의 연속이미지를 R. G. B. 채널에서 레드(R) 이미지, 그린(G) 이미지, 블루 (B) 이미지를 생성하여 중첩함으로서 컬러이미지를 생성하는 과정을 도식적으로 나타낸 도면이다. 도 1 과 같이 연속 이미지 중 제 1 이미지를 레드(R) 채널에서 레드(R) 이미지로 생성하고, 제 2 이미지를 그린(G) 채널에서 그린(G) 이미지로 생성하고, 제 3 이미지를 블루(B) 채널에서 블루(B) 이미지로 생성 한다(S180). 구체적으로, 레드(R) 채널에서는 제 1 이미지 중 특정 그레이값 범위(예 : 0 ~ 255 중 120~140)의 픽셀을 레드(Red)로 변환(예 : RED : 255, GREEN : 0, BLUE : 0)한다. 그린(G) 채널에서는 제 2 이미지 중 특 정 그레이값 범위(예 : 0 ~ 255 중 141~160)의 픽셀을 그린(Green)으로 변환(예 : RED : 0, GREEN : 255, BLUE : 0)한다. 블루(B) 채널에서는 제 3 이미지 중 특정 그레이값 범위(예 : 0 ~ 255 중 161~ 180)의 픽셀을 블루 (Blue)로 변환(예 : RED : 0, GREEN : 0, BLUE : 255)한다. 그 다음, 도 1에 도시된 바와 같이, 레드(R) 이미지, 그린(G) 이미지, 블루(B) 이미지를 중첩하여 한 장의 컬러이미지를 생성한다(S200). 이와 같은 본원의 RGB 방법은 이미지의 중첩을 통해 연속하는 CT 이 미지에서 연결성 및 대상의 모양의 차이를 향상시킨다. 연속 슬라이스의 연결된 영역은 색상이 거의 회색인 반 면 연결되지 않은 영역과 다른 모양(즉, 기본 색상)의 영역이다. RGB 컬러 모델을 이용하여 3차원 볼륨으로 확 인할 수 있는 조직에 대한 연결 정보를 표현함으로써 2차원 영상에서 3차원 효과를 얻을 수 있다.그 다음, 컬러이미지를 이용하여 인공지능 모델을 트레이닝 한다(S220). 이러한 인공지능 모델은 합성곱 신 경망(Convolutional Neural Network, CNN) 모델이며, 구체적으로는 EfficientNet 모델을 사용한다. 도 2는 본 발명에 따른 인공지능 모델 중 EfficientNet 모델의 아키텍쳐를 나타내는 흐름도이다. 도 2에 도시된 바와 같이 각 단계는 레이어를 나타내며, EfficientNet 모델은 22개의 레이어로 구성된다. 제 1 레이어, “Con2D, 3×3”는 2차원 컨벌류션, 3×3의 레이어 커널 사이즈를 의미한다. 제 2 레이어, “MBConv1, 3×3”는 제 1 모바일 인버티드 보틀넥 컨볼류션(Moblie inverted bottle neck convolution, MBConv)으로 구성된 컨볼류션, 3×3의 레이어 커널 사이즈를 의미한다. MBConv는 기존의 컨볼류션 연산보다 적은 수의 파라미터로 특징을 추출할 수 있도록 (i) 특징맵을 채널 별로 분리하여 연산을 수행하는 뎁 스와이즈 컨볼루션(Depthwise convolution), (ii) 이를 1x1 컨볼류션 연산을 통해 다시 하나의 채널로 합치는 포인트와이즈 컨볼류션(Pointwise convolution), (iii) 채널 별 특징맵을 각 하나의 특징값으로 변환하는 스퀴 즈 네트워크(Squeeze network)와 (iv) 해당 특징값들의 중요도를 연산하는 익사이테이션 네트워크(Excitation network)을 거쳐, 충수 병변 분류를 위한 이미지의 특징을 추출하게 된다. 이러한 컨볼류션 신경망을 통한 특징 추출과 동시에, 라디오믹스(Radiomics) 방식을 이용한 특징 추출이 시행된 다. 라디오믹스 방식에서는 이미지의 픽셀 강도 분포를 나타내는 1차 특징(First-order feature)과 근접한 픽셀 사이의 신호 관계를 나타내는 질감 특징(Texture feature)이 추출된다. 이 중 질감 특징은 (i) 이미지에서 특정 값을 갖는 픽셀 쌍이 특정 공간에서 발생하는 빈도를 계산하는 GLCM(Gray Level Co-occurrence matrix), (ii) 이미지에서 같은 강도를 갖으며 연속적인 픽셀들의 길이를 계산하는 GLRLM(Gray Level Run Length Matrix), (iii) 이미지에서 같은 강도를 갖는 서로 인접한 픽셀들의 크기를 계산하는 GLSZM(Gray Level Size Zone Matrix), (iv) 이미지에서 특정 픽셀의 강도와 인접한 픽셀들의 평균 강도 사이의 차이를 계산하는 NGTDM(Neighboring Tone Difference Matrix), (v) 이미지에서 특정 거리만큼 떨어져 있는 픽셀들 사이에서 픽 셀 강도의 발생빈도를 계산하는 GLDM(Gray Level Dependence Matrix)이 적용된다. 그 다음, 분류 모델에서 과 대적합을 방지하기 위해, 가중치들의 절대값의 합이 0이 되도록 제약을 주는 라쏘 회귀(Lasso regression)를 통 한 특징 선택을 시행한다. 따라서 [표 1]에 도시된 바와 같이, 중요한 특징들이 선택된다. 선택된 특징들은 32- 16-16-8의 레이어 구조를 갖는 다층 퍼셉트론(Multi layer perceptorn)에 입력되어, 다시 8개의 특징으로 변환 되며, 이를 컨볼류션 방식으로 추출된 8개의 특징과 결합하여 급성충수염, 급성게실염, 정상충수 중 하나로 분 류하는 확률 값을 도출한다. 표 1 특징 정의 First order Interquartile range 이미지 강도 값들의 25 퍼센트 백분위수와 75 퍼센트 백분위 수의 차이 GLCM Cluster shade GLCM의 왜도과 균일도 GLDM Dependence non-uniformity normalized이미지의 종속성 유사도 Large dependence low gray level emphasis낮은 강도와 큰 의존성의 결합 분포 NGTDM Coarseness 중심 픽셀과 그 이웃간의 평균 차이 Strength 이미지 픽셀 강도의 변화율 및 거침 정도의 차이 제 3 레이어, “MBConv6, 3×3”는 제 6 모바일 인버티드 보틀넥 컨볼류션으로 구성된 컨볼류션, 3×3의 레이어 커널 사이즈를 의미한다. 이와 같은 방식으로 제 18 레이어까지 연산이 이루어진다. 제 19 레이어, “Global Average Pooling 2D”는 CNN에서 필터를 통과한 분할된 이미지의 데이터들 중 전체 평 균치를 선택하는 레이어이다. 제 20 레이어 “FC layer, 3“은 Fully Connected layer의 의미이고, ”3“은 3가지 충수 병변 중 하나로 분류 한다는 의미이다. 제 21 레이어 ”Softmax“는 분류된 결과에서 특징을 추출하고, 버려지는 값들을 제거하는 의미이다. 그리고, 최종적으로 급성충수염, 급성게실염, 정상충수 중 하나로 분류되어 출력(Output)된다. 학습을 위해 배치 크기를 64로 설정하고 에포크 수를 200으로 설정하고 Adam 최적화를 사용했다. 트레이닝 단계 에서 과적합을 피하기 위해 조기 중단을 조정했다. 따라서 10 에포크 동안 유효성 검사 손실이 개선되지 않으면 훈련이 중단되었다. 범주형 교차 엔트로피를 사용하여 손실 함수를 나타했다. 또한 학습율을 0.0001(1e-4)로 설 정하고, 에포크가 30 이상인 경우 학습율을 0.00001(1e-5)로 설정하여 학습이 진행됨에 따라 학습율을 낮추도록 하였다. 실험예 이하, 첨부된 도면을 참조하여 바람직한 실험예를 상세히 설명하기로 한다. 먼저, [표 2]와 같이, 제외기준에 해당하는 이미지를 배제하고 총 715명의 환자로부터 4078장의 이미지를 준비 한다. 표 2 합계 급성충수염 급성게실염 정상충수 환자수 715 246 254 215 데이터 수 (CT 이미지 슬라이스)4078 1959 823 1296 나이 44.3 ± 18.4 41.9 ± 19.2 44.6 ± 13.6 46.7 ± 21.9 여성:남성 (남성, %)347:368 (51.5)116:130 (52.8)117:137 (56.0)114: 101 (47.0) 그 다음, [표 2]의 데이터 세트를 [표 3]과 같이 트레이닝 데이터 세트(60%), 인공지능 모델의 구성을 평가하고 파라미터 조정을 위한 검증 데이터 세트(20%), 및 분류 성능을 평가하기 위한 테스트 데이터 세트(20%)로 할당 한다. 즉, 딥 러닝 모델을 훈련하기 위해 5중 교차 검증(CV1 ~ CV5))과 테스트 데이터 세트를 사용했다. 각 폴 드에 대해 데이터 세트 샘플은 [표 3]와 같이 무작위로 할당되었다. 표 3 cv 병증 Train case*Test caseTrain data∫유효 데이터Test dataTotal caseTotal data cv1충수염 199472506∬ ∧314 392 2461959 게실염 198562630 132 165 254 823 정상충수 171442472 207 265 2151296 cv2충수염 192542484 311 406 2461959 게실염 213412619 131 168 254 823 정상충수 172432466 206 268 2151296 cv3충수염 195512486 311 405 2461959 게실염 199552605 131 171 254 823 정상충수 169462435 204 280 2151296cv4충수염 195512492 312 401 2461959 게실염 204502615 131 169 254 823 정상충수 170452460 206 270 2151296 cv5 충수염 203432566 321 355 2461959 게실염 202522690 135 150 254 823 정상충수 178372598 217 213 2151296 *는 환자 수, ∫는 CT 슬라이드 개수, ∧는 CT 슬라이드의 실제 개수, ∬는 CT 슬라이드의 확대 개수이고 트레 이닝 CT 슬라이드의 개수를 균일하게 맞추기 위해 확장형으로 학습에 사용함. [표 4]은 급성충수염, 급성게실염 및 정상충수에 대해 종래의 싱글방법과 본 발명에 따른 RGB 방법을 사용한 CNN 분류를 나타낸다. 싱글방법과 RGB방법의 CNN 분류 성능은 McNemar 테스트를 사용하여 AUC(Area under the Curve) 곡선과 민감도에서 AUC 값에 따라 비교되었다. p <0.05는 통계적으로 유의한 것으로 간주되었다. 도 3a는 종래의 싱글(Single) 방법에 따른 ROC(Receiver Operating Characteristic) 커브의 AUC(Receiver Operating Characteristic) 그래프의 일예이고, 도 3b는 본 발명의 RGB 방법에 따른 ROC 커브의 AUC 그래프의 일예이다. 도 3a 및 도 3b에서 파란색 그래프는 급성충수염, 주황색 그래프는 급성게실염, 녹색 그래프는 정상충수를 나타 낸다. 도 3a 및 도 3b에 도시된 바와 같이, RGB 방법은 싱글방법에 비해 급성충수염(0.951 vs. 0.937; p < 0.0001), 급성게실염(0.972 vs. 0.963; p = 0.0025) 및 정상충수(0.979 vs. 0.971; p=0)로 나타나 싱글방법에 비해 더 유의하게 높은 평균 AUC를 보였다. 도 4a는 종래의 싱글 방법에서 클래스 활성화 맵(class activation map, CAM)이 없거나 있는 CNN(convoluted neural network)에 의해 올바르게 분류된 급성충수염의 사례이고, 도 4b는 본 발명에 따른 RGB 방법에서 클래스 활성화 맵(CAM)이 없거나 있는 CNN에 의해 올바르게 분류된 급성충수염의 사례이다. 도 4a의 왼쪽 3장의 흑백 이미지는 CAM 없는 CNN에 의해 분류된 이미지이며, 오른쪽 3장의 컬러 이미지는 CAM이 있는 CNN에 의해 분류된 이미지이다. 도 4b의 왼쪽 3장의 이미지는 CAM 없는 CNN에 의해 분류된 이미지이며, 오른쪽 3장의 이미지는 CAM 이 있는 CNN에 의해 분류된 이미지이다. 그리고, 도 5a는 종래의 싱글 방법에서 CAM이 없거나 있는 CNN에 의해 올바르게 분류된 급성게실염의 사례이고, 도 5b는 본 발명에 따른 RGB 방법에서 클래스 활성화 맵(CAM)이 없거나 있는 CNN에 의해 올바르게 분류된 급성 게실염의 사례이다. 도 6a는 종래의 싱글 방법에서 CAM이 없거나 있는 CNN에 의해 올바르게 분류된 정상충수염 의 사례이고, 도 6b는 본 발명에 따른 RGB 방법에서 CAM이 없거나 있는 CNN에 의해 올바르게 분류된 정상충수염 의 사례이다. 도 4a 내지 도 6b에 도시된 바와 같이, 급성충수염의 CT 이미지 중 싱글방법 및 RBG 방법에서 각각 146개 및 123개의 이미지가 급성게실염으로 오분류 되었다. 또한 136개 및 115개의 이미지는 두 가지 방법을 사용하여 정 상충수로 예측되었다. 823개의 급성게실염 CT 이미지 중 142개와 126개의 이미지가 두 가지 방법을 사용하여 급 성충수염으로 예측되었다. 또한 19개 및 11개의 이미지가 두 가지 방법을 이용하여 정상충수로 예측하였다. 정 상충수에 대한 1296개의 CT 이미지 중 144개와 128개의 이미지가 두 가지 방법을 사용하여 급성충수염으로 오분 류 되었다. 표 4 민감도 특이도 Precision (PPV)정확도 AUCp-값* 싱글방법 충수염 85.60 (83.97-87.13)86.50 (84.97-87.93)85.43 (84.02-86.74)86.07 (84.97-87.12)0.937<0.0001 게실염 80.44 (77.56-83.10)95.12 (94.32-95.83)80.63 (78.09-82.94)92.15 (91.28-92.96)0.9630.0025정상충수 87.89 (85.98-89.61)94.43 (93.51-95.25)88.02 (86.30-89.56)92.35 (91.49-93.15)0.9720.0101 RGB방법 충수염 87.85 (86.21-89.27)88.01 (86.55-89.37)87.14 (85.78-88.39)87.94 (86.90-88.92)0.951 게실염 83.35 (80.63-85.84)96.04 (95.31-96.68)84.17 (81.75-86.33)93.48 (92.68-94.22)0.972 정상충수 89.66 (87.87-91.27)95.47 (94.63-96.21)90.22 (88.59-91.63)93.62 (92.83-94.35)0.979 데이터는 AUC를 제외하고 %로 표시됨. 괄호 안의 숫자는 95% 신뢰 구간임. * p-값은 두 방법의 AUC 값 사이를 비교함. [표 4]에서와 같이 정상충수의 분류는 싱글방법에 비해 RGB 방법이 기존 충수에 비해 민감도(89.66 vs. 87.89 %; p = 0.244), 정확도(93.62% vs. 92.35%), 특이도(95.47% vs. 94.43%)가 약간 더 높게 나타났다. 급성게실염 의 분류는 싱글방법에 비해 RGB방법이 민감도(83.35 vs. 80.44%; p=0.019), 정확도(93.48% vs. 92.15%), 특이 도(96.04% vs. 95.12%)가 약간 더 높게 나타났다. RGB 방법은 싱글방법을 각각 사용하였을 때 보다 급성충수염 (0.951 vs. 0.937; p < 0.0001), 급성게실염(0.972 vs. 0.963; p = 0.0025) 및 정상충수(0.979 대 0.972, p = 0.0101))에 대해 AUC 곡선 아래에서 유의하게 더 높은 평균 면적을 보여주었다. 결론적으로 CNN은 CT 영상에서 급성충수염, 급성게실염 및 정상충수를 정확하게 구별하며 싱글방법보다 본 발명의 일실시예에 따른 RGB 방법을 사용하여 얻은 AUC가 더 높다. [표 5]는 모든 데이터에 대해 종래의 싱글방법과 본발명의 RGB방법의 차이를 나타내는 표이다. 표 5 라벨 싱글방법 총 데이터 급성충수염 예측급성게실염 예측정상충수 예측 급성충수염RGB급성충수염 예측1577 79 65 1721 급성게실염 예측56 62 5 123 정상충수 예측 44 5 66 115 총 데이터 1677 146 136 1959 급성게실염RGB급성충수염 예측82 37 7 126 급성게실염 예측59 621 6 686 정상충수 예측 1 4 6 11 총 데이터 142 662 19 823 정상충수RGB급성충수염 예측35 1 92 128 급성게실염 예측1 0 5 6 정상충수 예측 108 12 1042 1162 총 데이터 144 13 1139 1296 합계 RGB급성충수염 예측1694 117 164 1975 급성게실염 예측116 683 16 815 정상충수 예측 153 21 1114 1288 총 데이터 1963 821 1294 4078 상술한 바와 같이 개시된 본 발명의 바람직한 실시예들에 대한 상세한 설명은 당업자가 본 발명을 구현하고 실 시할 수 있도록 제공되었다. 상기에서는 본 발명의 바람직한 실시예들을 참조하여 설명하였지만, 해당 기술 분 야의 숙련된 당업자는 본 발명의 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시 킬 수 있음을 이해할 수 있을 것이다. 예를 들어, 당업자는 상술한 실시예들에 기재된 각 구성을 서로 조합하는 방식으로 이용할 수 있다. 따라서, 본 발명은 여기에 나타난 실시형태들에 제한되려는 것이 아니라, 여기서 개 시된 원리들 및 신규한 특징들과 일치하는 최광의 범위를 부여하려는 것이다. 본 발명은 본 발명의 정신 및 필수적 특징을 벗어나지 않는 범위에서 다른 특정한 형태로 구체화될 수 있다. 따 라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니 되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서 의 모든 변경은 본 발명의 범위에 포함된다. 본 발명은 여기에 나타난 실시형태들에 제한되려는 것이 아니라, 여기서 개시된 원리들 및 신규한 특징들과 일치하는 최광의 범위를 부여하려는 것이다. 또한, 특허청구범위에서 명시적인 인용 관계가 있지 않은 청구항들을 결합하여 실시예를 구성하거나 출원 후의 보정에 의해 새로운 청구 항으로 포함할 수 있다."}
{"patent_id": "10-2023-0018219", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에서 첨부되는 다음의 도면들은 본 발명의 바람직한 실시예를 예시하는 것이며, 후술하는 발명의 상세 한 설명과 함께 본 발명의 기술사상을 더욱 이해시키는 역할을 하는 것이므로, 본 발명은 그러한 도면에 기재된 사항에만 한정되어서 해석되어서는 아니된다. 도 1은 본 발명에 따른 충수 이미지를 이용하여 충수 병변을 분류하는 인공지능 모델의 구축 방법 중 3장의 연 속이미지를 R. G. B. 채널에서 레드(R) 이미지, 그린(G) 이미지, 블루(B) 이미지를 생성하여 중첩함으로서 컬러이미지를 생성하는 과정을 도식적으로 나타낸 도면, 도 2는 본 발명에 따른 인공지능 모델 중 EfficientNet 모델의 아키텍쳐를 나타내는 흐름도, 도 3a는 종래의 싱글(Single) 방법에 따른 ROC(Receiver Operating Characteristic) 커브의 AUC(Receiver Operating Characteristic) 그래프의 일예, 도 3b는 본 발명의 RGB 방법에 따른 ROC 커브의 AUC 그래프의 일예, 도 4a는 종래의 싱글 방법에서 클래스 활성화 맵(class activation map, CAM)이 없거나 있는 CNN(convoluted neural network)에 의해 올바르게 분류된 급성충수염의 사례, 도 4b는 본 발명에 따른 RGB 방법에서 클래스 활성화 맵(CAM)이 없거나 있는 CNN에 의해 올바르게 분류된 급성 충수염의 사례, 도 5a는 종래의 싱글 방법에서 클래스 활성화 맵(CAM)이 없거나 있는 CNN에 의해 올바르게 분류된 급성게실염의 사례, 도 5b는 본 발명에 따른 RGB 방법에서 클래스 활성화 맵(CAM)이 없거나 있는 CNN에 의해 올바르게 분류된 급성 게실염의 사례, 도 6a는 종래의 싱글 방법에서 클래스 활성화 맵(CAM)이 없거나 있는 CNN에 의해 올바르게 분류된 정상충수염의 사례, 도 6b는 본 발명에 따른 RGB 방법에서 클래스 활성화 맵(CAM)이 없거나 있는 CNN에 의해 올바르게 분류된 정상 충수염의 사례, 도 7은 본 발명에 따라, 충수 이미지를 이용하여 충수 병변을 분류하는 인공지능 모델의 구축 방법, 및 그 인공 지능 모델을 이용한 충수병변의 분류 방법을 나타내는 흐름도이다."}
