{"patent_id": "10-2017-0092475", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0010135", "출원번호": "10-2017-0092475", "발명의 명칭": "인공지능을 이용한 음악 생성 장치 및 방법", "출원인": "주식회사 마인드셋", "발명자": "임지순"}}
{"patent_id": "10-2017-0092475", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "새로운 음원인 생성 음원을 생성하기 위해 제공되는 음원을 수신하여 구조 단위로 구분하고 태깅하여 구조 정보를 생성하는 구분 파이프라인; 및상기 생성 음원을 생성하기 위한 음원 생성 인공지능을 포함하고, 상기 구조 정보를 이용하여 상기 음원 생성인공지능을 학습(training)시키거나, 상기 구조 정보를 토대로 상기 생성 음원의 구조 정보를 추론(inference)하도록 구성되는 인공지능 파이프라인;을 포함하는, 인공지능을 이용한 음악 생성 장치."}
{"patent_id": "10-2017-0092475", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 구분 파이프라인은,상기 음원에 자기 상관(auto-correlation) 연산을 통한 클러스터링을 수행하여 상기 음원의 시간별 구조에 대한정보인 제1구조 정보를 생성하는 구조 추출 모듈;상기 구조 추출 모듈에서 출력된 상기 제1구조 정보의 각 구간에 대한 특성을 분석하여 특성 정보를 생성하는특성 분석 모듈; 및상기 특성 정보와 상기 제1구조 정보를 토대로 특성이 유사한 구조를 같은 태그로 묶어서 제2구조 정보를 생성하는 구조 태깅 모듈;을 포함하고,상기 특성 정보는, 상기 음원의 비트, 음색, 멜로디, 음량 및 화성 중 적어도 하나에 대한 정보를 포함하며, 상기 인공지능 파이프라인은 상기 특성 정보와 상기 제2구조 정보를 이용하여 상기 음원 생성 인공지능을 학습시키거나, 상기 특성 정보와 상기 제2구조 정보를 토대로 상기 새로운 음원의 구조 정보를 추론하도록 구성되는것을 특징으로 하는, 인공지능을 이용한 음악 생성 장치."}
{"patent_id": "10-2017-0092475", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 구분 파이프라인은, 상기 생성 음원에 대한 구조 정보를 더 생성하고,상기 인공지능 파이프라인은,상기 생성 음원을 생성하는 제너레이션 모듈; 및상기 음원 및 상기 생성 음원의 상기 구조 정보의 차이에 대한 손실함수를 계산하고, 상기 손실함수를 최소화하는 방향으로 상기 제너레이션 모듈을 최적화하는 최적화 모듈;을 포함하는 것을 특징으로 하는, 인공지능을 이용한 음악 생성 장치."}
{"patent_id": "10-2017-0092475", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,공개특허 10-2019-0010135-3-상기 구분 파이프라인은, 상기 생성 음원에 대한 구조 정보를 더 생성하고,상기 인공지능 파이프라인은,상기 음원을 입력 데이터로 하고, 상기 음원을 특정 확률 분포로 저차원화 한 뒤, 상기 특정 확률 분포에서 샘플링한 잠재변수를 토대로 상기 생성 음원을 생성하는 제너레이션 모듈; 및상기 음원 및 상기 생성 음원의 상기 구조 정보의 차이에 대한 손실함수를 계산하고, 상기 손실함수를 최소화하는 방향으로 상기 제너레이션 모듈을 최적화하는 최적화 모듈;을 포함하는 것을 특징으로 하는, 인공지능을 이용한 음악 생성 장치."}
{"patent_id": "10-2017-0092475", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "인공지능을 이용한 음악 생성 장치의 일구성인 구조 추출 모듈이 수신된 음원에 자기 상관(auto-correlation)연산 방법을 통한 클러스터링을 수행하여 구간을 일축으로 하는 매트릭스 형태의 제1구조 정보를 생성하는 구조추출 단계;상기 음악 생성 장치의 일구성인 특성 분석 모듈이 상기 구조 추출 모듈에서 출력된 상기 제1구조 정보의 각 구간에 대한 특성을 분석하여, 구간을 일축으로 하는 매트릭스 형태의 특성 정보를 생성하는 특성 분석 단계;상기 음악 생성 장치의 일구성인 구조 태깅 모듈이 상기 특성 정보와 상기 제1구조 정보를 토대로 특성이 유사한 구조를 같은 태그로 묶어서 제2구조 정보를 생성하는 구조 태깅 단계;새로운 음원인 생성 음원을 생성하기 위한 음원 생성 인공지능을 포함하는 상기 음악 생성 장치의 일구성인 인공지능 파이프라인이 상기 특성 정보와 상기 제2구조 정보를 이용하여 상기 음원 생성 인공지능을 학습(training)시키거나, 상기 특성 정보와 상기 제2구조 정보를 토대로 상기 생성 음원의 구조 정보를 추론(inference)하도록 인공지능 학습 또는 추론 단계; 를 포함하는, 인공지능을 이용한 음악 생성 방법."}
{"patent_id": "10-2017-0092475", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 음악 생성 장치 및 방법에 관한 것이다. 이를 위하여 새로운 음원인 생성 음원을 생성하기 위해 제공되는 음원을 수신하여 구조 단위로 구분하고 태깅하여 구조 정보를 생성하는 구분 파이프라인; 및 생성 음원을 생성하기 위한 음원 생성 인공지능을 포함하고, 구조 정보를 이용하여 음원 생성 인 공지능을 학습(training)시키거나, 구조 정보를 토대로 음원의 구조 정보를 추론(inference)하도록 구성되는 인 공지능 파이프라인;이 제공될 수 있다. 화음이나 각 악기의 조합이 예측되는 방향으로 새로운 음원이 생성되는 효과가 발생된다."}
{"patent_id": "10-2017-0092475", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 음악 생성 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2017-0092475", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현대 미디어 컨텐츠 산업은 일차원적인 글, 회화, 음악을 넘어서 스토리, 영상, 음악, 시스템이 결합된 복잡적 인 멀티미디어 컨텐츠가 기본이 되어가고 있다. 그 예로, 원천 스토리나 광고를 게임, 영상물, 웹 드라마 등으 로 가공하는 사례가 지속적으로 증가하고 있다. 그 중 음악은 컨텐츠의 근본 소스까지는 아니지만 필수불가결하다는 특성을 가지고 있다. 게임이나 영상물을 원 천 스토리, 또는 회화적 컨셉, 시스템 설계(게임의 경우)를 기반으로 시작하는 경우는 많지만 음악을 기반으로 시작하는 경우는 거의 없다. 그래서 음악은 처음부터 비용을 들여 제작하기보다는 컨텐츠 제작 중간 과정에서 투입하는 경우가 많고, 큰 예산을 사용할 수 없는 중소 개발사의 경우 오픈소스 라이선스로 공개된 음원을 사용 하는 경우가 많다. 실제로 작곡가에게 컨텐츠의 음악 소스 외주를 의뢰할 때에는, 음악에 대한 이론적 지식이 부족한 컨텐츠 제작 자가 추상적인 느낌을 설명하고 그를 기반으로 작곡가가 작업해야 하는 상황이 대다수이며, 혹은 컨텐츠 제작자 가 다른 음원을 참조 음원으로 제시하고 작곡가가 참조 음원을 기반으로 작업하는 상황도 많이 있다. 참조 음원 이 있으면 상대적으로 작업의 효율이 높아지나, 여전히 작곡가는 음악을 바닥에서부터 분석해서 시퀀싱 (sequencing) 작업을 진행해야 한다.선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허, 10-1657975, 모바일 앱 기반의 실시간 영상의 배경음악 생성방법, 서강대 학교산학협력단"}
{"patent_id": "10-2017-0092475", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 다른 목적은, 위와 같은 음악 작업의 불균형을 해결하기 위해, 인공신경망을 이용하여 참조 음원의 모티프를 닮은 새로운 음원을 생성하는 인공지능을 이용한 음악 생성 장치 및 방법을 제공하는데에 있다."}
{"patent_id": "10-2017-0092475", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이하 본 발명의 목적을 달성하기 위한 구체적 수단에 대하여 설명한다. 본 발명의 목적은, 새로운 음원인 생성 음원을 생성하기 위해 제공되는 음원을 수신하여 구조 단위로 구분하고 태깅하여 구조 정보를 생성하는 구분 파이프라인; 및 상기 생성 음원을 생성하기 위한 음원 생성 인공지능을 포 함하고, 상기 구조 정보를 이용하여 상기 음원 생성 인공지능을 학습(training)시키거나, 상기 구조 정보를 토 대로 상기 생성 음원의 구조 정보를 추론(inference)하도록 구성되는 인공지능 파이프라인;을 포함하는, 인공지 능을 이용한 음악 생성 장치를 제공하여 달성될 수 있다. 또한, 상기 구분 파이프라인은, 상기 음원에 자기 상관(auto-correlation) 연산을 통한 클러스터링을 수행하여 상기 음원의 시간별 구조에 대한 정보인 제1구조 정보를 생성하는 구조 추출 모듈; 상기 구조 추출 모듈에서 출 력된 상기 제1구조 정보의 각 구간에 대한 특성을 분석하여 특성 정보를 생성하는 특성 분석 모듈; 및 상기 특 성 정보와 상기 제1구조 정보를 토대로 특성이 유사한 구조를 같은 태그로 묶어서 제2구조 정보를 생성하는 구 조 태깅 모듈;을 포함하고, 상기 특성 정보는, 상기 음원의 비트, 음색, 멜로디, 음량 및 화성 중 적어도 하나 에 대한 정보를 포함하며, 상기 인공지능 파이프라인은 상기 특성 정보와 상기 제2구조 정보를 이용하여 상기 음원 생성 인공지능을 학습시키거나, 상기 특성 정보와 상기 제2구조 정보를 토대로 상기 새로운 음원의 구조 정보를 추론하도록 구성되는 것을 특징으로 할 수 있다. 또한, 상기 구분 파이프라인은, 상기 생성 음원에 대한 구조 정보를 더 생성하고, 상기 인공지능 파이프라인은, 상기 생성 음원을 생성하는 제너레이션 모듈; 및 상기 음원 및 상기 생성 음원의 상기 구조 정보의 차이에 대한 손실함수를 계산하고, 상기 손실함수를 최소화하는 방향으로 상기 제너레이션 모듈을 최적화하는 최적화 모듈; 을 포함하는 것을 특징으로 할 수 있다. 또한, 상기 구분 파이프라인은, 상기 생성 음원에 대한 구조 정보를 더 생성하고, 상기 인공지능 파이프라인은, 상기 음원을 입력 데이터로 하고, 상기 음원을 특정 확률 분포로 저차원화 한 뒤, 상기 특정 확률 분포에서 샘 플링한 잠재변수를 토대로 상기 생성 음원을 생성하는 제너레이션 모듈; 및 상기 음원 및 상기 생성 음원의 상 기 구조 정보의 차이에 대한 손실함수를 계산하고, 상기 손실함수를 최소화하는 방향으로 상기 제너레이션 모듈 을 최적화하는 최적화 모듈;을 포함하는 것을 특징으로 할 수 있다. 본 발명의 다른 목적은, 인공지능을 이용한 음악 생성 장치의 일구성인 구조 추출 모듈이 수신된 음원에 자기 상관(auto-correlation) 연산 방법을 통한 클러스터링을 수행하여 구간을 일축으로 하는 매트릭스 형태의 제1구 조 정보를 생성하는 구조 추출 단계; 상기 음악 생성 장치의 일구성인 특성 분석 모듈이 상기 구조 추출 모듈에 서 출력된 상기 제1구조 정보의 각 구간에 대한 특성을 분석하여, 구간을 일축으로 하는 매트릭스 형태의 특성 정보를 생성하는 특성 분석 단계; 상기 음악 생성 장치의 일구성인 구조 태깅 모듈이 상기 특성 정보와 상기 제 1구조 정보를 토대로 특성이 유사한 구조를 같은 태그로 묶어서 제2구조 정보를 생성하는 구조 태깅 단계; 새로 운 음원인 생성 음원을 생성하기 위한 음원 생성 인공지능을 포함하는 상기 음악 생성 장치의 일구성인 인공지 능 파이프라인이 상기 특성 정보와 상기 제2구조 정보를 이용하여 상기 음원 생성 인공지능을 학습(training)시키거나, 상기 특성 정보와 상기 제2구조 정보를 토대로 상기 생성 음원의 구조 정보를 추론(inference)하도록 인공지능 학습 또는 추론 단계;를 포함하는, 인공지능을 이용한 음악 생성 방법을 제공하여 달성될 수 있다."}
{"patent_id": "10-2017-0092475", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기한 바와 같이, 본 발명에 의하면 이하와 같은 효과가 있다. 첫째, 본 발명의 일실시예에 따르면, 참조 음원과 멜로디가 유사하지 않으면서도 느낌이 유사한 음원을 무한정 생성할 수 있는 효과가 발생된다. 둘째, 본 발명의 일실시예에 따르면, 참조 음원과 지나치게 overfitting된 음원이 생성되지 않는 효과가 발생된 다. 셋째, 본 발명의 일실시예에 따르면, 화음이나 각 악기의 조합이 예측되는 방향으로 새로운 음원이 생성되는 효 과가 발생된다."}
{"patent_id": "10-2017-0092475", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 발명을 쉽게 실시할 수 있는 실시예를 상세히 설명한다. 다만, 본 발명의 바람직한 실시예에 대한 동작원리를 상세하게 설명함에 있 어서 관련된 공지기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되 는 경우에는 그 상세한 설명을 생략한다. 또한, 도면 전체에 걸쳐 유사한 기능 및 작용을 하는 부분에 대해서는 동일한 도면 부호를 사용한다. 명세서 전 체에서, 특정 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐만 아니라, 그 중간에 다른 소자를 사이에 두고, 간접적으로 연결되어 있는 경우도 포함한다. 또한, 특정 구성요소를 포함한다 는 것은 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라, 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 인공지능을 이용한 음악 생성 장치 [제1실시예] 도 1은 본 발명의 제1실시예에 따른 인공지능을 이용한 음악 생성 장치를 도시한 모식도이다. 도 1에 도시된 바 와 같이, 본 발명의 제1실시예에 따른 음악 생성 장치는, 구분 파이프라인, 인공지능 파이프라인을 포 함할 수 있다. 구분 파이프라인은 새로운 음원을 생성하기 위해 인공지능 파이프라인에 제공되는 음원을 수신하 여 구조 단위로 구분하고 태깅하는 파이프라인이다. 본 발명의 제1실시예에 따른 구분 파이프라인은 구조 추출 모듈, 특성 분석 모듈, 구조 태깅 모듈을 포함할 수 있다. 음원은 아날로그 음원 또는 디지털 음원을 포함할 수 있다. 구조 추출 모듈은 음원에 자기 상관(auto-correlation) 연산 등의 방법을 통한 클러스터링을 수행하 여 생성되는 2차원 배열을 이용하여 시간(또는 구간)을 일축으로 하는 매트릭스 형태의 제1구조 정보를 생성한 다. 2차원 배열의 형태로부터 참조 음원의 구조를 분석하고, 참조 음원을 구조적으로 분리하여 각 부분에 대한 타임스탬프(timestamp) 태그를 붙일 수 있다. 즉, 제1구조 정보는 음원의 시간별 또는 구간별 구조에 대한 정보 를 의미할 수 있고, 예를 들어, 각 구조가 [a, b, c, d, e, f, g, h]로 태깅되도록 구성될 수 있다. 특성 분석 모듈은 구조 추출 모듈에서 출력된 음원의 제1구조 정보의 각 구간에 대한 특성을 분 석하여 시간을 일축으로 하는 매트릭스 형태의 특성 정보를 생성한다. 특성 분석 모듈은 음원의 비트, 음색, 멜로디, 음량, 화성 등과 같은 특성을 분석할 수 있고, 각각의 특성에 대응되는 복수개의 특성 매 트릭스를 생성할 수 있다. 본 발명의 제1실시예에 따른 특성 정보는 vector 형태 또는 텍스트 형태로 구성될 수 있다. 비트 정보와 관련하여, 특성 분석 모듈은 다양한 onset detection 방법을 적용하여 해당 구간의 비트를 추 출할 수 있다. 또한, 이러한 비트 정보는 템포 정보 또는 박자 정보로 변환되어 이용될 수 있다. 예를 들어, 1 분당 비트 수가 높으면 템포가 빠른 음악인 것이다. 음색 정보와 관련하여, 특성 분석 모듈은 MFCC 분석 등의 방법을 적용하여 특정 구간의 음색 분포, 즉 음 악적으로는 악기 구성에 대한 정보를 추출할 수 있다. 본 발명의 제1실시예에 따른 특성 분석 모듈은 다양 한 악기의 개별 음원에 대한 MFCC 데이터를 이용하여 패턴 매칭을 통해 음색 식별을 수행할 수 있다. 멜로디 정보와 관련하여, 특성 분석 모듈은 STFT를 통해 음원의 tempogram을 추출하고, 해당 부분의 주 멜 로디에 해당하는 pitch contour를 추적하여 멜로디를 추출할 수 있다. 또는, 특성 분석 모듈이 음원의 멜 로디 변화 추이를 수치적으로 변환하여 멜로디 정보를 추출하도록 구성될 수 있다. 음량 정보와 관련하여, 특성 분석 모듈은 음원의 1차원 raw data가 가지는 진폭의 envelope를 통해 각 부 분의 음량을 계량화할 수 있다. 음량은 각 구조를 나누는 dominant factor가 아니기 때문에, 전체 음량 분포 내 에서 아주 유의미한 차이를 지니는 구조만이 음량 면에서 특징을 가진다고 할 수 있을 것이다. 화성 정보와 관련하여, 특성 분석 모듈의 화성 추출은 멜로디 추출과 유사하게 STFT 를 통해 산출한 tempogram을 바탕으로 가능하다. 단 pitch contour를 구하는 것이 아니라, 주어진 시간축의 window 내에 분포한 주파수 성분을 음악의 각 코드(기본 12개 근음을 바탕으로 major/minor만 구분하면 24개, maj7/min7/sus4 등등 을 모두 고려하다보면 엄청나게 늘어날 수 있음) 프리셋이 가지는 주파수 성분과 매칭하여 프리셋 상의 가장 유 사한 코드와 매칭한다. 방법론적으로는 멜로디 추출보다 더 쉽지만, 세부적인 화성을 구하려고 할수록 확률분포 의 중첩으로 인해 인식률은 떨어질 수 있다. 본 발명의 제1실시예에 따른 특성 분석 모듈은 추출한 비트 정보, 음색 정보, 멜로디 정보, 음량 정보, 화 성 정보 등을 벡터화하도록 구성될 수 있다. 벡터화된 정보는 일반적인 메모리 상의 행렬이 될 수도 있고, 미디 (MIDI) 혹은 OSC 데이터의 형태를 가질 수도 있다. 구조 태깅 모듈은 특성 분석 모듈에 의해 각 구간별로 분석된 특성 정보와 제1구조 정보를 토대로 특 성이 유사한 구조를 같은 태그로 묶어서 제2구조 정보를 생성하는 모듈이다. 예를 들어 구조 추출 모듈에 서 특성 분석 전에 각 구조를 [a, b, c, d, e, f, g, h]로 태깅했다면, 구조 태깅 모듈은 구조가 유사한 부분을 같은 태그로 묶어 [a, b, a', a'', b', b'', c, a'''] 와 같이 제1구조 정보를 변환할 수 있다. 이는 특정한 곡 내에서 어떤 부분이 반복적인 모티프로 사용되었는지, 어떤 부분에서 변주가 이루어졌는지, 전반적으 로 모티프가 어떤 분위기로 전개되었는지 등의 전반적인 구조를 확인할 수 있는 기반이 된다. 본 발명의 제1실시예에 따른 제2구조 정보는 vector 형태 또는 텍스트 형태로 구성될 수 있다. 인공지능 파이프라인은 특성 분석 모듈에서 음원의 각각의 특성에 관하여 시간을 일축으로 하는 매트 릭스 형태의 정보인 특성 정보를 수신하고, 구조 태깅 모듈에서 변환된 제2구조 정보를 수신할 수 있다. 인공지능 파이프라인은 특성 정보 및 제2구조 정보를 수신하여 새로운 음원을 생성시키기 위한 인공지능인 음원 생성 인공지능을 학습(training)하도록 구성되거나, 새로운 음원의 특성 정보 및 제2구조 정보를 추론 (inference)하도록 구성될 수 있다. 본 발명의 제1실시예에 따른 인공지능 파이프라인의 음원 생성 인공지능은 크게 Supervised Learning과 Unsupervised Learning을 포함할 수 있고, 구체적으로는 시계열 분석을 수행하는 LSTM(Long-Short Term Memory) 등의 RNN(Recurrent Neural Network) 계열, 매트릭스의 Convolution 곱을 이용하는 CNN(Convolution Neural Network) 계열, RNN 계열과 CNN 계열의 Hybrid 형태인 Pixel-CNN 등의 Hybrid 계열, VAE(Variable Auto-Encoder)나 GAN(Generative Adversaral Network) 등의 Generation 계열, 강화학습 계열(Reinforcement Learning), 유전자 알고리즘, 자연선택 알고리즘 등의 인공지능 또는 각 인공지능의 조합이 포함될 수 있다. 본 발명의 제1실시예에 따른 특성 정보 및 제2구조 정보는 각각의 인공지능의 입력데이터로 활용될 수 있도록 vector 형태 또는 텍스트 형태로 구성될 수 있다. 본 발명의 제1실시예에 따라 음원 생성 인공지능의 학습 또는 추론에 특성 정보 및 제2구조 정보가 이용되는 경 우, 모티프 또는 모티프의 전개 방식이 유사하면서도 각각의 특성이 상이한 새로운 음원을 생성할 수 있게 되는 효과가 발생된다. 또한, 제1음악의 화성과 제2음악의 모티프를 결합한 것과 같은 새로운 음원을 생성하는 것이 가능해지는 효과가 발생된다. 새로운 음원을 인공지능을 통해 생성하는 경우, 단순히 특정 음원 자체를 각종 인 공지능의 input data로 하게 되면 음악이라고 하기 어려운 음의 조합이 생성되게 되는 문제가 발생된다. 게다가, 이를 해소하기 위해 인공지능의 학습시간 또는 iteration을 늘리게 되면 지나치게 overfitting된 음원 이 생성되게 된다. 본 발명의 제1실시예에 따라 특성 정보 및 제2구조 정보를 이용하는 경우 특정 음원의 전체 적인 구조 및 각 구간의 특성을 기반으로 새로운 음원이 생성되므로 음악이라고 할 수 있는 음원이 생성될 확률 이 높아지고 인공지능의 학습시간도 짧아지는 효과가 발생된다. [제2실시예] 도 2는 본 발명의 제2실시예에 따른 인공지능을 이용한 음악 생성 장치를 도시한 모식도이다. 도 2에 도시된 바 와 같이, 본 발명의 제2실시예에 따른 음악 생성 장치는, 구분 파이프라인, 인공지능 파이프라인을 포 함할 수 있고, 인공지능 파이프라인은 인코딩 모듈, 최적화 모듈, 제너레이션 모듈을 포함할 수 있다. 구분 파이프라인은 새로운 음원을 생성하는 기초가 되는 참조용 음원 및 제너레이션 모듈에서 생 성된 생성 음원을 수신하여 특성을 분석하여 구조 단위로 구분하고 태깅하는 파이프라인이다. 본 발명의 제2실시예에 따른 구분 파이프라인은 구조 추출 모듈, 특성 분석 모듈, 구조 태깅 모듈을 포함할 수 있다. 참조용 음원은 생성 음원의 생성을 위해 최적화 모듈에서 생성 음원의 특징들과 비교되어 제너레이션 모듈의 인공신경망 가중치의 학습에 이용될 입력 데이터로서, 구분 파이프라인에 먼저 입력 되어 구간별로 구분되어 특징이 태깅될 수 있다. 생성 음원은 제너레이션 모듈에서 랜덤 생성되거나, 특정 입력 데이터를 통해 CNN(Convolution Neural Network) 등으로 디코딩되는 음원을 의미할 수 있다. 생성 음원은 참조용 음원과 최적화 모듈에 서 비교되고, 생성 음원이 최대한 참조용 음원의 특징에 수렴하도록 제너레이션 모듈이 학습될 수 있다. 참조용 음원과 생성 음원은 예를 들어, wav 포맷이나 MIDI(Musical Instrument Digital Interface) 포맷 또는 특정 매트릭스 형태로 구성될 수 있다. MIDI 포맷은 신디사이저나 시퀀서처럼 음악 하드웨어나 소프 트웨어를 컨트롤하는 명령 순서의 포맷이다. 즉, 이 포맷 자체가 사운드를 나타내는 것은 아니지만, 특정한 악 기들에게 특정한 시간에 소리를 내게 한다. 예를 들면, 악기 #1(Acoustic Grand Piano)을 선택하여 #60의 노트를 (C5) #127의 속도로 연주하게 한다는 정보를 담을 수 있다. 따라서 MIDI 포맷으로 음성 정보를 담을수는 없 지만, MIDI 파일로 저장된 음악에 대해서는 쉽게 악기를 바꾸거나 음표를 조정할 수 있다. MIDI 데이터는 단순 히 바이너리로 되어 있는 악보라고 볼 수 있다. 하지만, 음원의 선택과 여러 효과를 삽입하기 위해 내부 바이너 리는 MIDI Manufacturers Association에서 규정한 규약에 맞게 구성되어 있다. 본 발명의 제2실시예에 따라 참 조용 음원과 생성 음원이 MIDI 포맷으로 제공되는 경우, 인공신경망의 입력데이터로 이용되기 위해 적어도 하나 이상의 차원인 매트릭스 구조로 구성될 수 있다. 도 3은 본 발명의 제2실시예에 따라 MIDI 포맷을 텍스트 형태로 변환한 것이다. 도 3에 도시된 바와 같이, MIDI 포맷은 텍스트 형태를 기반으로 바이너리 매트릭 스를 구성할 수 있고, 이를 토대로 이미지화 하는 것도 가능하다. 도 3에 도시된 바와 같이, MIDI 데이터의 내 부는 가장 먼저 노트가 찍히는 시간 단위가 표현되며, 내부적으로는 variable length quantity라는 기법을 사용 하여 필요한 비트의 수를 효율적으로 줄인다. 그 다음으로 노트의 시작과 끝을 알리는 데이터가 들어가며, 이 데이터가 저장되는 channel, 음의 높낮이를 결정하는 pitch, 음의 크기를 결정하는 volume값이 저장된다. 구조 추출 모듈은 참조용 음원 및 생성 음원에 자기 상관(auto-correlation) 연산 등의 클러스 터링 기법을 수행하여 생성되는 2차원 배열을 이용하여 시간(또는 구간)을 일축으로 하는 매트릭스 형태의 제1 구조 정보를 생성한다. 2차원 배열의 형태로부터 음원의 구조를 분석하고, 음원을 구조적으로 분리하여 각 부분 에 대한 타임스탬프(timestamp) 태그를 붙일 수 있다. 특성 분석 모듈은 구조 추출 모듈에서 출력된 참조용 음원 및 생성 음원의 제1구조 정보의 각 구간에 대한 특성을 분석하여 시간을 일축으로 하는 매트릭스 형태의 특성 정보를 생성한다. 특성 분석 모듈 은 참조용 음원 및 생성 음원의 비트, 음색, 멜로디, 음량, 화성 등과 같은 특성을 분석할 수 있고, 각각의 특성에 대한 vector matrix를 구성할 수 있다. 비트 정보와 관련하여, 특성 분석 모듈은 다양한 onset detection 방법을 적용하여 해당 구간의 비트를 추 출할 수 있다. 또한, 이러한 비트 정보는 템포 정보 또는 박자 정보로 변환되어 이용될 수 있다. 예를 들어, 1 분당 비트 수가 높으면 템포가 빠른 음악인 것이다. 음색 정보와 관련하여, 특성 분석 모듈은 MFCC 분석 등의 방법을 적용하여 특정 구간의 음색 분포, 즉 음 악적으로는 악기 구성에 대한 정보를 추출할 수 있다. 본 발명의 제2실시예에 따른 특성 분석 모듈은 다양 한 악기의 개별 음원에 대한 MFCC 데이터를 이용하여 패턴 매칭을 통해 음색 식별을 수행할 수 있다. 멜로디 정보와 관련하여, 특성 분석 모듈은 STFT를 통해 참조용 음원 및 생성 음원의 tempogram을 추출하 고, 해당 부분의 주 멜로디에 해당하는 pitch contour를 추적하여 멜로디를 추출할 수 있다. 또는, 특성 분석 모듈이 참조용 음원 및 생성 음원의 멜로디 변화 추이를 수치적으로 변환하여 멜로디 정보를 추출하도록 구성될 수 있다. 도 4는 본 발명의 제2실시예에 따른 멜로디 정보 추출의 예를 도시한 것이다. 도 4에 도시된 바와 같이 본 발명의 제2실시예에 따른 특성 분석 모듈은 도 4의 (a) 부분과 같이 각각의 노트 사이에서의 노트의 높낮이 변화를 정수로 나타내고, (b) 부분과 같이 노트의 높낮이 변화를 벡터로 나타내며, (c) 부분과 같이 멜로디의 간격인 노트와 노트 사이 길이의 비율을 수치적으로 나타내는 방식으로 멜로디 정보를 추출할 수 있다. 도 4의 (a) 관련하여, 음계에서 음들 사이의 높이의 값을 어떻게 책정하느냐에 따라 순정율(Just scale), 피타고리안 음계(Pythagorean scale), 평균율(equal temerament)이 이용될 수 있다. 예를 들어, 평균율을 이용 하게 되면 C에서 1옥타브 높은 C로 가려면 +12를 하게 되고, C에서 G로 가기 위해서는 +7을 하게 되며, F에서 E 로 가게 되면 -1을 하게 된다. 음량 정보와 관련하여, 특성 분석 모듈은 참조용 음원의 1차원 raw data가 가지는 진폭의 envelope를 통해 각 부분의 음량을 계량화할 수 있다. 음량은 각 구조를 나누는 dominant factor가 아니기 때문에, 전체 음량 분 포 내에서 아주 유의미한 차이를 지니는 구조만이 음량 면에서 특징을 가진다고 할 수 있을 것이다. 화성 정보와 관련하여, 특성 분석 모듈의 화성 추출은 멜로디 추출과 유사하게 STFT 를 통해 산출한 tempogram을 바탕으로 가능하다. 단 pitch contour를 구하는 것이 아니라, 주어진 시간축의 window 내에 분포한 주파수 성분을 음악의 각 코드(기본 12개 근음을 바탕으로 major/minor만 구분하면 24개, maj7/min7/sus4 등등 을 모두 고려하다보면 엄청나게 늘어날 수 있음) 프리셋이 가지는 주파수 성분과 매칭하여 프리셋 상의 가장 유 사한 코드와 매칭한다. 방법론적으로는 멜로디 추출보다 더 쉽지만, 세부적인 화성을 구하려고 할수록 확률분포 의 중첩으로 인해 인식률은 떨어질 수 있다. 본 발명의 제2실시예에 따른 특성 분석 모듈은 추출한 비트 정보, 음색 정보, 멜로디 정보, 음량 정보, 화 성 정보 등을 벡터화하도록 구성될 수 있다. 벡터화된 정보는 일반적인 메모리 상의 행렬이 될 수도 있고, 미디(MIDI) 혹은 OSC 데이터의 형태를 가질 수도 있다. 구조 태깅 모듈은 특성 분석 모듈에 의해 각 구간별로 분석된 특성 정보와 제1구조 정보를 토대로 특 성이 유사한 구조를 같은 태그로 묶어서, 입력된 음원의 제2구조 정보를 생성하는 모듈이다. 예를 들어 구조 추 출 모듈에서 특성 분석 전에 각 구조를 [a, b, c, d, e, f, g, h]로 태깅했다면, 구조 태깅 모듈은 구조가 유사한 부분을 같은 태그로 묶어 [a, b, a', a'', b', b'', c, a'''] 와 같이 제1구조 정보를 변환할 수 있다. 이는 특정한 곡 내에서 어떤 부분이 반복적인 모티프로 사용되었는지, 어떤 부분에서 변주가 이루어졌 는지, 모티프의 전개는 어떻게 이루어지는지 등의 전반적인 구조를 확인할 수 있는 기반이 된다. 인공지능 파이프라인은 구조 파이프라인에서 생성된 참조용 음원 및 생성 음원의 특성 정보 및 제2구조 정보를 토대로 생성 음원과 참조용 음원을 비교하여 차이에 대한 Loss function(손실함수)을 최소화 하는 방향으로 제너레이션 모듈의 가중치를 최적화하는 파이프라인이다. 본 발명의 제2실시예에 따른 인공 지능 파이프라인은 인코딩 모듈, 최적화 모듈, 제너레이션 모듈을 포함할 수 있다. 인코딩 모듈은 참조용 음원 및 생성 음원의 특성 정보 및 제2구조 정보를 입력 데이터로 하는 Neural Network으로 구성될 수 있고, 특성 정보 및 제2구조 정보를 인코딩하여 latent vector matrix를 생성하 는 모듈이다. 본 발명의 제2실시예에 따른 인코딩 모듈은 latent vector 매트릭스 생성을 위해 Convolution Neural Network이 이용될 수 있다. 최적화 모듈은 인코딩 모듈에서 생성된 생성 음원과 참조용 음원의 latent vector matrix 또는 feature map의 차이에 대한 손실함수를 계산하고, 손실함수 결과를 토대로 제너레이션 모듈의 가중치를 back propagation하여 최적화하는 모듈이다. 본 발명의 제2실시예에 따른 최적화 모듈의 손실함수(loss function or cost function)로는 Softmax, cross entropy 등이 이용될 수 있다. 제너레이션 모듈은 생성 음원을 생성하는 디코더로 구성된 모듈이다. 본 발명의 제2실시예에 따른 제 너레이션 모듈은 생성 음원의 생성에 대해 랜덤 매트릭스에서 디코딩하여 생성하거나, 참조용 음원을 토대로 VAE(Variable auto-encoder)를 통해 생성할 수 있다. 도 5는 본 발명의 제2실시예에 따른 제너레이션 모 듈에 VAE가 이용된 예를 도시한 것이다. 도 5에 도시된 바와 같이, VAE가 이용되는 경우, 참조용 음원(20 0)이 입력데이터로 입력될 수 있고, 인코더를 지나 N차원(저차원화)의 가우스 분포의 평균과 표준편차 값을 대 변하는 latent vector가 생성되어 unit gaussian distribution을 만족하도록 인코더의 network가 학습될 수 있 다. 이러한 다변수 gaussian distribution에서 샘플링된 2~50차원의 잠재변수 vector를 통해 디코더로 디코딩을 수행(고차원화)하여 생성 음원을 생성하게 된다. 제너레이션 모듈은 최적화 모듈의 손실함수를 최소화하는 방향으로 가중치가 학습되어 점차적으로 참조용 음원의 특성 정보 및 제2구조 정보와 유사한 방향으로 생성 음원을 생성할 수 있다. 본 발명의 제2실시예에 따른 인공지능을 이용한 음악 생성 장치를 이용하면 제너레이션 모듈의 확률분포를 이용한 샘플링에 의해 생성되는 음원의 예측불가성이 향상되어 overfitting이 될 확률이 낮아지는 동시에, 특성 정보 및 제2구조 정보의 최적화에 의해 전체적인 특성과 구조는 유사한 음원이 생성될 수 있는 효과가 발생된다. [제3실시예] 도 6은 본 발명의 제3실시예에 따른 인공지능을 이용한 음악 생성 장치를 도시한 모식도이다. 도 6에 도시된 바 와 같이, 본 발명의 제3실시예에 따른 음악 생성 장치는, 인공지능 파이프라인의 최적화 모듈이 모티 프 최적화 모듈과 스타일 최적화 모듈를 포함할 수 있고, 참조용 음원이 모티프 참조를 위한 음 원인 모티프 참조용 음원과 스타일 참조를 위한 음원인 스타일 참조용 음원으로 구분될 수 있다. 도 7은 본 발명의 제3실시예에 따른 음악 생성 장치의 최적화 모듈을 도시한 모식도이다. 도 7에 도시된 바와 같이, 모티프 최적화 모듈은 모티프 Loss function을 포함하여 모티프 참조용 음원의 모티프와 생성 음원의 모티프의 차이를 최적화하는 모듈이다. 모티프 최적화 모듈은, 모티프 참조용 음원의 인 코딩 정보 중 Layer n에서의 feature map과 생성 음원의 인코딩 정보 중 Layer n에서의 feature map과의 차이를 최소화하는 방향으로 제너레이션 모듈의 가중치가 수렴되도록 모티프 Loss function이 구성될 수 있다. 본 발명의 제3실시예에 따른 모티프 최적화 모듈에 따르면 참조용 음원의 특정한 특성(비트, 화성, 멜 로디 등)의 시계열적인 흐름과 윤곽이 참조용 음원의 모티프로서 생성 음원에 적용될 수 있다. 스타일 최적화 모듈은 스타일 Loss function을 포함하여 스타일 참조용 음원의 스타일과 생성 음원 의 스타일의 차이를 최적화하는 모듈이다. 스타일 최적화 모듈은, 스타일 참조용 음원의 인코딩 정보 중 Layer m까지의 feature map들을 auto-correlation한 gram matrix와 생성 음원의 인코딩 정보 중 Layer m까지의 feature map들을 auto-correlation한 gram matrix와의 차이를 최소화하는 방향으로 제너레이션 모듈의 가중치가 수렴되도록 스타일 Loss function이 구성될 수 있다. 본 발명의 제3실시예에 따른 스타일 최적화 모듈에 따르면 참조용 음원의 특정한 특성(비트, 화성, 멜로디 등)의 시계열적인 흐름에 관계없이 전반적으로 존재하는 스타일이 참조용 음원의 스타일로서 생성 음원에 적용될 수 있다. 본 발명의 제3실시예에 따르면, 제1음원의 모티프에 제2음원의 스타일이 첨가되도록 생성 음원을 생성할 수 있 는 효과가 발생된다. 인공지능을 이용한 음악 생성 방법 도 8은 본 발명의 일실시예에 따른 인공지능을 이용한 음악 생성 방법을 도시한 것이다. 도 8에 도시된 바와 같 이, 본 발명의 일실시예에 따른 인공지능을 이용한 음악 생성 방법은 구조 추출 단계(S10), 특성 분석 단계 (S11), 구조 태깅 단계(S12), 인공지능 학습/추론 단계(S13)를 포함할 수 있다. 구조 추출 단계(S10)는 구조 추출 모듈이 음원에 자기 상관(auto-correlation) 연산 등의 방법을 통 한 클러스터링을 수행하여 생성되는 2차원 배열을 이용하여 시간(또는 구간)을 일축으로 하는 매트릭스 형태의 제1구조 정보를 생성하는 단계이다. 특성 분석 단계(S11)는 특성 분석 모듈이 구조 추출 모듈에서 출력된 음원의 제1구조 정보의 각 구간에 대한 특성을 분석하여 시간을 일축으로 하는 매트릭스 형태의 특성 정보를 생성하는 단계이다. 구조 태깅 단계(S12)는 구조 태깅 모듈이 특성 분석 모듈에 의해 각 구간별로 분석된 특성 정보와 제 1구조 정보를 토대로 특성이 유사한 구조를 같은 태그로 묶어서 제2구조 정보를 생성하는 단계이다. 인공지능 학습/추론 단계(S13)는 인공지능 파이프라인이 특성 분석 모듈에서 음원의 각각의 특성에 관 하여 시간을 일축으로 하는 매트릭스 형태의 정보인 특성 정보를 수신하고, 구조 태깅 모듈에서 변환된 제 2구조 정보를 수신하여 새로운 음원을 생성시키기 위한 인공지능인 음원 생성 인공지능을 학습(training)하거나, 새로운 음원의 특성 정보 및 제2구조 정보를 추론(inference)하는 단계이다. 이상에서 설명한 바와 같이, 본 발명이 속하는 기술 분야의 통상의 기술자는 본 발명이 그 기술적 사상이나 필 수적 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 상술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범 위는 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 등가 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함하는 것으로 해석되어야 한다. 본 명세서 내에 기술된 특징들 및 장점들은 모두를 포함하지 않으며, 특히 많은 추가적인 특징들 및 장점들이 도면들, 명세서, 및 청구항들을 고려하여 당업자에게 명백해질 것이다. 더욱이, 본 명세서에 사용된 언어는 주 로 읽기 쉽도록 그리고 교시의 목적으로 선택되었고, 본 발명의 주제를 묘사하거나 제한하기 위해 선택되지 않 을 수도 있다는 것을 주의해야 한다. 본 발명의 실시예들의 상기한 설명은 예시의 목적으로 제시되었다; 이는 개시된 정확한 형태로 본 발명을 제한 하거나, 빠뜨리는 것 없이 만들려고 의도한 것이 아니다. 당업자는 상기한 개시에 비추어 많은 수정 및 변형이 가능하다는 것을 이해할 수 있다. 본 설명의 일부는 정보 상 연산의 기호 표현 및 알고리즘에 관한 본 발명의 실시예들을 기술한다. 이러한 알고 리즘적 설명 및 표현은, 일반적으로 그들의 작업의 핵심을 효율적으로 다른 당업자에게 전달하기 위해 데이터처리 분야의 당업자에 의해 사용된다. 이러한 동작은 기능적, 연산적, 또는 논리적으로 설명되지만, 컴퓨터나 이와 동등한 전기 회로, 마이크로코드 등에 의해 구현될 것으로 이해된다. 나아가, 또한 이것은 모듈로서의 이 러한 동작의 배열을 나타내기 위해, 때때로 일반성의 상실 없이 편리하게 입증된다. 상기 기술된 동작 및 그들 의 연관된 모듈은 소프트웨어, 펌웨어, 하드웨어, 또는 이들의 임의의 조합 내에서 구현될 수 있다. 여기서 기술된 임의의 단계, 동작, 또는 프로세스는, 하나 이상의 하드웨어 또는 소프트웨어 모듈과 함께 단독 으로 또는 다른 장치와 조합하여 수행되거나 구현될 수 있다. 일 실시예에서, 소프트웨어 모듈은 컴퓨터 프로그 램 코드를 포함하는 컴퓨터-판독 가능 매체로 구성되는 컴퓨터 프로그램 제품과 함께 구현되고, 컴퓨터 프로그 램 코드는 기술된 임의의 또는 모든 공정, 단계, 또는 동작을 수행하기 위한 컴퓨터 프로세서에 의해 실행될 수 있다. 또한, 본 발명의 실시예들은, 여기서의 동작을 수행하기 위한 장치와 관련될 수 있다. 이들 장치는 요구되는 목 적을 위해 특별히 제작될 수 있고/있거나, 컴퓨터 내에 저장된 컴퓨터 프로그램에 의해 선택적으로 활성화되거 나 재구성되는 일반적-목적의 연산 장치를 포함할 수 있다. 이러한 컴퓨터 프로그램은, 유형의 컴퓨터 판독가능 저장 매체 또는 전자 명령어를 저장하기 위해 적합한 임의의 유형의 미디어 내에 저장될 수 있고, 컴퓨터 시스 템 버스에 결합될 수 있다. 나아가, 본 명세서에 참조되는 임의의 연산 시스템은 단일 프로세서를 포함할 수 있 거나, 증가한 연산 능력을 위한 다중 프로세서 디자인을 채택한 구조가 될 수 있다. 마지막으로, 본 명세서에 사용된 언어는 주로 읽기 쉽도록 그리고 교시의 목적으로 선택되었고, 본 발명의 주제 를 묘사하거나 제한하기 위해 선택되지 않을 수 있다. 그러므로 본 발명의 범위는 상세한 설명에 의해 한정되지 않고, 이를 기반으로 하는 출원의 임의의 청구항들에 의해 한정된다. 따라서, 본 발명의 실시예들의 개시는 예시적인 것이며, 이하의 청구항에 기재된 본 발명의 범 위를 제한하는 것은 아니다."}
{"patent_id": "10-2017-0092475", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 첨부되는 다음의 도면들은 본 발명의 바람직한 실시예를 예시하는 것이며, 발명의 상세한 설명과 함께 본 발명의 기술사상을 더욱 이해시키는 역할을 하는 것이므로, 본 발명은 그러한 도면에 기재된 사항에만 한정되어 해석되어서는 아니 된다. 도 1은 본 발명의 제1실시예에 따른 인공지능을 이용한 음악 생성 장치를 도시한 모식도, 도 2는 본 발명의 제2실시예에 따른 인공지능을 이용한 음악 생성 장치를 도시한 모식도, 도 3은 본 발명의 제2실시예에 따라 MIDI 포맷을 텍스트 형태로 변환한 것, 도 4는 본 발명의 제2실시예에 따른 멜로디 정보 추출의 예를 도시한 것, 도 5는 본 발명의 제2실시예에 따른 제너레이션 모듈에 VAE가 이용된 예를 도시한 것, 도 6은 본 발명의 제3실시예에 따른 인공지능을 이용한 음악 생성 장치를 도시한 모식도, 도 7은 본 발명의 제3실시예에 따른 음악 생성 장치의 최적화 모듈을 도시한 모식도, 도 8은 본 발명의 일실시예에 따른 인공지능을 이용한 음악 생성 방법을 도시한 것이다."}
