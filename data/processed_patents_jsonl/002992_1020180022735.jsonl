{"patent_id": "10-2018-0022735", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0102399", "출원번호": "10-2018-0022735", "발명의 명칭": "정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템 및 그 방법", "출원인": "(주)헬스허브", "발명자": "이병일"}}
{"patent_id": "10-2018-0022735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "의료영상 판독 전문가의 판독문으로부터 추출한 정규화된 형태의 정제된 학습 데이터를 생성하는 판독 기록 지도학습(supervised learning)부; 및상기 판독 기록 지도학습부에서 정제된 학습 데이터를 입력으로 상기 의료영상을 판독하도록 기계학습을 수행하는 학습모델생성부;를 포함하며,상기 기계학습은 상기 의료영상 판독 전문가의 판독문으로부터 정제된 학습 데이터를 지속적으로 업데이트하여입력받음으로써, 상기 학습 데이터가 자동으로 강화학습 데이터가 되는 것을 특징으로 하는 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템."}
{"patent_id": "10-2018-0022735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 판독 기록 지도학습(supervised learning)부는,상기 판독문의 파일 위치 주소로부터 데이터를 읽어 들이는 의료기록 데이터 로딩부;상기 판독문을 신체부위(Body Part) 별로 발견(Findings), 결론(Conclusion) 및 권고(Recommendation)를 포함한 섹션으로 분류하고, 상기 각 섹션의 평문텍스트로부터 질병관련 단어 또는 어구를 하나의 집합으로 라벨링하는 라벨링처리부;상기 라벨링된 판독문에서 질병관련 단어 또는 어구를 추출하고, 상기 추출된 단어 또는 어구로부터 공통된 특징을 추출하는 특징 추출부;상기 추출된 특징들을 규칙화하여 특징 행렬(Feature Matrix)을 생성하는 특징행렬 생성부;임의의 판독문이 주어지면 상기 판독문을 특징 행렬에 사상(mapping)시켜 특징을 분석하는 특징 분석부; 및상기 분석된 특징만으로 정제된 학습 데이터를 생성하는 정제 데이터 생성부;를 포함하는 것을 특징으로 하는정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템."}
{"patent_id": "10-2018-0022735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 의료기록 데이터 로딩부는, 입력값으로 주어진 판독문 원본 데이터의 파일 위치 주소로부터 파일의 위치,전체 파일 개수, 파일의 길이 또는 이들의 조합을 읽어 들여 시스템 메모리에 적재시키며,상기 라벨링 처리부는, 상기 시스템 메모리에 적재된 데이터를 신체부위(Body Part)별로 각 판독 섹션별로 라벨링하고, 이를 각각의 집합으로 분류하여 시스템 메모리상에 재배치하며,상기 특징 추출부는, 각 섹션의 평문텍스트와 SNOMED-CT, ICD-11, LOINC, KCD-10을 포함한 표준 의료 용어 데이터 집합과 비교하여 해당 평문텍스트만 선택적으로 추출하여, 의료관련 용어 추출부에서 추출된 의료 관련 용어로부터 단어 종류, 서술 형태, 서술 빈도 또는 이들의 조합을 분석하여 병변의 유무와 관련된 용어의 특징, 병변의 위치 표시와 관련된 용어의 특징, 증상 묘사와 관련된 용어의 특징, 병증의 종류를 나타내는 용어의 특징또는 이들의 조합을 추출하며,상기 특징행렬 생성부는, 상기 특징 추출부에서 추출된 특징들을 데이터 집합으로 하여 새롭게 입력되는 평문텍스트와 사상시킴으로써 유사 또는 동일 의미의 용어인지 비교 및 분석이 가능한 특징 행렬(Feature Matrix)을생성하며,상기 특징 분석부는, 정제되지 않은 원본 판독문이 입력되었을 때, 이를 특징 행렬에 사상시켜 판독문을 서술하는 평문텍스트에서 병변의 존재 유무, 병변의 위치, 증상, 병증의 종류 등을 추출, 분석 및 분류하며,공개특허 10-2019-0102399-3-상기 정제 데이터 생성부는, 상기 특징 분석부에서 추출, 분석 및 분류된 데이터들로 정제된 학습 데이터를 생성하는 것을 특징으로 하는 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템."}
{"patent_id": "10-2018-0022735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 학습모델생성부는, 융합 컨벌루션 뉴럴 네트워크(Converged Convolutional Neural Network)에 의해 학습이 수행되며, 상기 융합 컨벌루션 뉴럴 네트워크(Converged Convolutional Neural Network)는 상기 의료영상판독 전문가의 판독문으로부터 정제된 학습 데이터를 지속적으로 업데이트하여 입력받고 이를 학습모델의 생성에 반영함으로써, 융합 컨볼루션 뉴럴 네트워크를 통해서 딥러닝 기계학습을 수행하여 계산량을 줄이고 정확도를 향상시켜 전체적인 성능을 향상하는 것을 특징으로 하는 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템."}
{"patent_id": "10-2018-0022735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,상기 학습모델생성부는, 역방향 전파에 의해서 가중치가 업데이트되도록 구성되는 것을 특징으로 하는 정제된인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템."}
{"patent_id": "10-2018-0022735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "의료영상 판독 전문가의 판독문으로부터 추출한 정규화된 형태의 정제된 학습 데이터를 생성하는 판독 기록 지도학습(supervised learning) 단계; 및상기 판독 기록 지도학습 단계에서 정제된 학습 데이터를 입력으로 상기 의료영상을 판독하도록 기계학습을 수행하는 학습모델생성 단계;를 포함하며,상기 기계학습은 상기 의료영상 판독 전문가의 판독문으로부터 정제된 학습 데이터를 지속적으로 업데이트하여입력받음으로써, 상기 학습 데이터가 자동으로 강화학습 데이터가 되는 것을 특징으로 하는 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 방법."}
{"patent_id": "10-2018-0022735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,상기 판독 기록 지도학습(supervised learning) 단계는,상기 판독문의 파일 위치 주소로부터 데이터를 읽어 들이는 의료기록 데이터 로딩 단계;상기 판독문을 신체부위(Body Part) 별로 발견(Findings), 결론(Conclusion) 및 권고(Recommendation)를 포함한 섹션으로 분류하고, 상기 각 섹션의 평문텍스트로부터 질병관련 단어 또는 어구를 하나의 집합으로 라벨링하는 라벨링 처리 단계;상기 라벨링된 판독문에서 질병관련 단어 또는 어구를 추출하는 의료관련 용어 추출 단계;상기 추출된 단어 또는 어구로부터 공통된 특징을 추출하는 특징 추출 단계;상기 추출된 특징들을 규칙화하여 특징 행렬(Feature Matrix)을 생성하는 특징행렬생성 단계;임의의 판독문이 주어지면 상기 판독문을 특징 행렬에 사상(mapping)시켜 특징을 분석하는 특징 분석 단계; 및상기 분석된 특징만으로 정제된 학습 데이터를 생성하는 정제 데이터 생성 단계;를 포함하는 것을 특징으로 하는 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 방법."}
{"patent_id": "10-2018-0022735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서,상기 의료기록 데이터 로딩 단계는, 입력값으로 주어진 판독문 원본 데이터의 파일 위치 주소로부터 파일의 위치, 전체 파일 개수, 파일의 길이 또는 이들의 조합을 읽어 들여 시스템 메모리에 적재시키며,공개특허 10-2019-0102399-4-상기 라벨링 처리 단계는, 상기 시스템 메모리에 적재된 데이터를 신체부위(Body Part)별로 각 판독 섹션별로라벨링하고, 이를 각각의 집합으로 분류하여 시스템 메모리상에 재배치하며,상기 의료관련 용어 추출 단계는, 각 섹션의 평문텍스트와 SNOMED-CT, ICD-11, LOINC, KCD-10을 포함한 표준 의료 용어 데이터 집합과 비교하여 해당 평문텍스트만 선택적으로 추출하며,상기 특징 추출 단계는, 의료관련 용어 추출부에서 추출된 의료 관련 용어로부터 단어 종류, 서술 형태, 서술빈도 또는 이들의 조합을 분석하여 병변의 유무와 관련된 용어의 특징, 병변의 위치 표시와 관련된 용어의특징, 증상 묘사와 관련된 용어의 특징, 병증의 종류를 나타내는 용어의 특징 또는 이들의 조합을 추출하며,상기 특징행렬 생성 단계는, 상기 특징 추출부에서 추출된 특징들을 데이터 집합으로 하여 새롭게 입력되는 평문텍스트와 사상시킴으로써 유사 또는 동일 의미의 용어인지 비교 및 분석이 가능한 특징 행렬(Feature Matrix)을 생성하며,상기 특징 분석 단계는, 정제되지 않은 원본 판독문이 입력되었을 때, 이를 특징 행렬에 사상시켜 판독문을 서술하는 평문텍스트에서 병변의 존재 유무, 병변의 위치, 증상, 병증의 종류 등을 추출, 분석 및 분류하며,상기 정제 데이터 생성 단계는, 상기 특징 분석부에서 추출, 분석 및 분류된 데이터들로 정제된 학습 데이터를생성하는 것을 특징으로 하는 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 방법."}
{"patent_id": "10-2018-0022735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 6에 있어서,상기 학습모델생성 단계는, 융합 컨벌루션 뉴럴 네트워크(Converged Convolutional Neural Network)에 의해 학습이 수행되며, 상기 융합 컨벌루션 뉴럴 네트워크(Converged Convolutional Neural Network)는 상기 의료영상판독 전문가의 판독문으로부터 정제된 학습 데이터를 지속적으로 업데이트하여 입력받고 이를 학습모델의 생성에 반영함으로써, 융합 컨볼루션 뉴럴 네트워크를 통해서 딥러닝 기계학습을 수행하여 계산량을 줄이고 정확도를 향상시켜 전체적인 성능을 향상하는 것을 특징으로 하는 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 방법."}
{"patent_id": "10-2018-0022735", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서,상기 학습모델생성 단계는, 역방향 전파에 의해서 가중치가 업데이트되도록 구성되는 것을 특징으로 하는 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 방법."}
{"patent_id": "10-2018-0022735", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템 및 그 방법에 관한 것으로, 의료 영상 판독 전문가의 판독문으로부터 의료영상 판독의 강화 학습 데이터를 추출하여 이를 인공지능 학습 데이터로 활용함으로써 인공지능 의료영상 판독의 계산비용 및 복잡도를 낮추고 정확도를 향상시킬 수 있는 정제된 인공지 능 강화학습 데이터 생성을 통한 의료영상 판독 시스템 및 그 방법에 관한 것이다."}
{"patent_id": "10-2018-0022735", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템 및 그 방법에 관한 것으로, 더 욱 상세하게는 의료영상 판독 전문가의 판독문으로부터 의료영상 판독의 강화 학습 데이터를 추출하여 이를 인 공지능 학습 데이터로 활용함으로써 인공지능 의료영상 판독의 계산비용 및 복잡도를 낮추고 정확도를 향상시킬 수 있는 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템 및 그 방법에 관한 것이다."}
{"patent_id": "10-2018-0022735", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사람의 질병을 진단하기 위해 사용되는 의료기기들 중에서 상당수가 의료영상을 획득하여 출력한다. 사람의 신 체부위를 스캔하여 획득한 영상을 처리하여 병변이 존재하는지 여부를 판독한다. 의료영상으로부터 병변을 놓치지 않고 판독할 수 있는 능력에 따라 의사의 능력이 결정되기도 한다. 정확한 병 변의 판단과 병증의 조기 발견은 병을 치료하고 완치할 가능성을 높이는데 매우 중요하기 때문에, 의료영상의 정확한 판단은 무엇보다 중요하다고 할 수 있다. 그러나 다양한 분야의 의료영상에서 병변을 모두 잘 찾아내기란 여간 어려운 일이 아니며, 특정 분야에서 상당 히 오랜 시간동안 경험을 쌓지 않고서는 의료영상에서 병변을 정확하게 찾아내는 것이 매우 어렵다. 아울러 특 정 분야에서 오랜 경험을 쌓은 전문의가 흔하지도 않은 것이 현실이다.이러한 문제점을 오래 전부터 많은 사람들이 인지하여 이를 해결하고자 하였다. 대표적인 것이 컴퓨터 보조 진 단(CAD, Computer-Aided Diagnosis)의 개념이다. 이는 스캔한 의료영상을 디지털화하여 컴퓨터로 영상을 처리한 다음 객체의 특징들에 기반한 수학적 모델링을 통해 규칙기반 시스템(rule-based system)이나 전문가 시스템 (expert system)을 구성하는 것이다. 여기서 사용되는 영상분석기술은 주로 영상처리에 의한 패턴인식에서 기계학습을 통한 병변의 예측으로 진화되 고 있는데, 영상으로부터 특징을 추출하고, 추출한 특징들로 영상을 벡터화한 후 다양한 기계학습 분류기법을 활용하다가, 최근에는 딥러닝에 의한 방법이 주류를 이루고 있다. 의료영상을 분석하는 주요 과제로는 영상을 분류(classification)하고, 객체를 검출(detection)하며, 객체의 경 계를 추출(segmentation)하고, 서로 다른 영상의 정합(registration) 등이 있다. 이러한 주요 과제를 해결하는 수단으로 영상을 입력으로 하여 처리하는데 최적화된 컨벌루션 뉴럴 네트워크(CNN, convolutional neural network)가 가장 널리 이용된다. 대부분의 의료영상에 대한 학습방식은, 입력 데이터와 정답인 데이터를 학습 데이터로 하여, 입력과 정답 간의 함수관계를 CNN이 학습하는 지도학습의 범주에 속한다. 그러나 딥러닝 기반의 인공지능 기술은 매우 많은 수의 학습 데이터가 필요하다, 따라서 많은 수의 학습 데이터를 커버하기 위해서 학습 데이터의 정제가 매우 중요한 이슈이다. 즉, 양질의 방대한 학습 데이터를 확보하는 것과 정확한 판독성능을 확보하는 것이 무엇보다 중요하 다는 것을 알 수 있다. 따라서 본 발명에서는 의료영상 판독 전문가의 판독문으로부터 의료영상 판독의 강화 학습 데이터를 추출하여 이를 인공지능 학습 데이터로 활용함으로써 인공지능 의료영상 판독의 계산비용 및 복잡도를 낮추고 정확도를 향상시킬 수 있는 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템 및 그 방법을 제시하고 자 한다. 보다 상세하게는 판독 전문가의 판독문 텍스트 데이터로부터 정규화된 폼(form)을 생성하는 지도 학습 모델 (supervised learning model)의 구조 및 방법, 다수의 유효 판독문들로부터 추출해낸 정제된 학습 데이터의 구 조 및 데이터 생성, 정제된 학습 데이터를 CNN에 적용하여 종래의 CNN의 성능을 향상시킬 수 있는 의료영상 판 독 시스템 및 그 방법을 제시하고자 한다."}
{"patent_id": "10-2018-0022735", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "다음으로 본 발명의 기술분야에 존재하는 선행기술에 대하여 간단하게 설명하고, 이어서 본 발명이 상기 선행기 술에 비해서 차별적으로 이루고자 하는 기술적 사항에 대해서 기술하고자 한다. 먼저 한국공개특허 제10-2017-0140757호(2017.12.21.)는 임상 의사결정 지원 앙상블 시스템 및 이를 이용한 임 상 의사결정 지원 방법에 관한 것으로, 복수의 외부 의료기관으로부터 수신되는 기계학습을 통한 환자의 임상예 측 결과를 통합하여, 앙상블 예측을 수행함으로써, 상기 환자의 현재 상태뿐만 아니라 향후 상기 환자의 질환에 대한 진행 상태를 예측하여, 의료인의 의료행위에 관한 신속하고 정확한 임상 의사결정을 지원하기 위한 시스템 및 그 방법에 관한 것이다. 또한 한국공개특허 제10-2015-0108701호(2015.09.30.)는 의료 영상 내 해부학적 요소 시각화 시스템 및 방법에 관한 것으로, 의료 영상 내에 포함되어 있는 해부학적 요소들을 해부학적 맥락 정보를 이용하여 검증함으로써 자동으로 분류하고 분류된 해부학적 요소들을 사용자 친화적으로 시각화하는 의료 영상 내 해부학적 요소 시각 화 시스템 및 방법을 제시하고 있다. 한편 한국공개특허 제10-2015-0098119호(2015.08.27.)는 의료 영상 내 거짓양성 병변후보 제거 시스템 및 방법 에 관한 것으로, 의료 영상 내에서 검출된 병변후보를 해부학적 맥락정보를 이용하여 검증함으로써, 거짓양성 병변후보를 제거하는 의료 영상 내 거짓양성 병변후보 제거 시스템 및 방법을 제시하고 있다. 상기 선행기술들은 환자의 임상예측 결과를 통합하여 앙상블 예측을 수행하거나, 의료영상 내 해부학적 맥락 정 보를 이용하거나 및 거짓 양성 병변후보를 제거하는 것이나, 본 발명과 같이 딥러닝을 위한 방대한 학습 데이터 의 정제와 이를 통한 인공지능 의료영상 판독을 위한 학습모델의 계산비용 및 복잡도를 낮추고 정확도를 향상시 키는 것은 제시된 바가 없다."}
{"patent_id": "10-2018-0022735", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위해 창작된 것으로서, 의료영상 판독 전문가(영상의학과 전문의)의 판독문으로부터 의료영상 판독의 강화 학습 데이터를 추출하여 이를 인공지능 학습 데이터로 활용함으로써 인공 지능 의료영상 판독의 계산비용 및 복잡도를 낮추고 정확도를 향상시킬 수 있는 정제된 인공지능 강화학습 데이 터 생성을 통한 의료영상 판독 시스템 및 그 방법을 제공하는 것을 목적으로 한다. 또한 본 발명은 의료영상 판독 시스템의 성능을 향상시키기 위해, 이미지를 통한 학습 효과를 개선하고, 병변의 존재여부 및 위치를 식별할 뿐 만 아니라 동일한 신체 부위에 나타날 수 있는 다양한 병증의 종류를 식별하기 위해 잘 훈련된 영상의학과 전문의의 판독문들에 포함된 텍스트들을 정규화하여 정제된 학습 데이터를 생성할 수 있는 판독기록 지도학습 모델(medical report supervised learning model)을 생성하는 것을 또 다른 목적으 로 한다. 또한 본 발명은 의료영상 판독 시스템의 성능을 향상시키기 위해, 상기 생성한 판독기록 지도학습모델을 통해 검증이 완료된 판독문들을 학습시켜 정제된 학습 데이터(refined data)를 추출하여, 이를 의료 영상 이미지와 함께 강화 학습시킴으로써 학습 효과를 향상시키고 병증의 종류를 식별할 수 있는 새로운 구조를 지닌 정제된 학습 데이터의 구조 및 생성 방법을 제공하는 데 그 목적이 있다. 또한 본 발명은 상기의 새로운 데이터 구조를 갖는 정제된 학습 데이터로부터 병증의 종류를 식별할 수 있는 필 터들을 추출하여 이를 컨벌루션 뉴럴 네트워크에 상호작용시킴으로써 기존 컨벌루션 뉴럴 네트워크의 판독 성능 을 향상시키고 병증의 종류를 식별할 수 있는 새로운 구조를 가진 융합 컨벌루션 뉴럴 네트워크(Converged Convolutional Neural Network)를 구성할 수 있는 판독기록 지도학습 모델을 구축하는 데 그 목적이 있다."}
{"patent_id": "10-2018-0022735", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위하여 본 발명의 바람직한 실시예에 따른 정제된 인공지능 강화학습 데이터 생성 을 통한 의료영상 판독 시스템은, 의료영상 판독 전문가의 판독문으로부터 추출한 정규화된 형태의 정제된 학습 데이터를 생성하는 판독 기록 지도학습(supervised learning)부 및 상기 판독 기록 지도학습부에서 정제된 학습 데이터를 입력으로 상기 의료영상을 판독하도록 기계학습을 수행하는 학습모델생성부를 포함하며, 상기 기계학 습은 상기 의료영상 판독 전문가의 판독문으로부터 정제된 학습 데이터를 지속적으로 업데이트하여 입력받음으 로써, 상기 학습 데이터가 자동으로 강화학습 데이터가 되는 것을 특징으로 한다. 상기 판독 기록 지도학습(supervised learning)부는, 상기 판독문의 파일 위치 주소로부터 데이터를 읽어 들이 는 의료기록 데이터 로딩부, 상기 판독문을 신체부위(Body Part) 별로 발견(Findings), 결론(Conclusion) 및 권고(Recommendation)를 포함한 섹션으로 분류하고, 상기 각 섹션의 평문텍스트로부터 질병관련 단어 또는 어구 를 하나의 집합으로 라벨링하는 라벨링처리부, 상기 라벨링된 판독문에서 질병관련 단어 또는 어구를 추출하고, 상기 추출된 단어 또는 어구로부터 공통된 특징을 추출하는 특징 추출부, 상기 추출된 특징들을 규칙화하여 특 징 행렬(Feature Matrix)을 생성하는 특징행렬 생성부, 임의의 판독문이 주어지면 상기 판독문을 특징 행렬에 사상(mapping)시켜 특징을 분석하는 특징 분석부, 및 상기 분석된 특징만으로 정제된 학습 데이터를 생성하는 정제 데이터 생성부를 포함하는 것을 특징으로 한다. 상기 의료기록 데이터 로딩부는, 입력값으로 주어진 판독문 원본 데이터의 파일 위치 주소로부터 파일의 위치, 전체 파일 개수, 파일의 길이 또는 이들의 조합을 읽어 들여 시스템 메모리에 적재시키며, 상기 라벨링 처리부 는, 상기 시스템 메모리에 적재된 데이터를 신체부위(Body Part)별로 각 판독 섹션별로 라벨링하고, 이를 각각 의 집합으로 분류하여 시스템 메모리상에 재배치하며, 상기 특징 추출부는, 각 섹션의 평문텍스트와 SNOMED-CT, ICD-11, LOINC, KCD-10을 포함한 표준 의료 용어 데이터 집합과 비교하여 해당 평문텍스트만 선택적으로 추출하 여, 상기 의료관련 용어 추출부에서 추출된 의료 관련 용어로부터 단어 종류, 서술 형태, 서술 빈도 또는 이들 의 조합을 분석하여 병변의 유무와 관련된 용어의 특징, 병변의 위치 표시와 관련된 용어의 특징, 증상 묘사와 관련된 용어의 특징, 병증의 종류를 나타내는 용어의 특징 또는 이들의 조합을 추출하며, 상기 특징행렬 생성부 는, 상기 특징 추출부에서 추출된 특징들을 데이터 집합으로 하여 새롭게 입력되는 평문텍스트와 사상시킴으로 써 유사 또는 동일 의미의 용어인지 비교 및 분석이 가능한 특징 행렬(Feature Matrix)을 생성하며, 상기 특징 분석부는, 정제되지 않은 원본 판독문이 입력되었을 때, 이를 특징 행렬에 사상시켜 판독문을 서술하는 평문텍 스트에서 병변의 존재 유무, 병변의 위치, 증상, 병증의 종류 등을 추출, 분석 및 분류하며, 상기 정제 데이터 생성부는, 상기 특징 분석부에서 추출, 분석 및 분류된 데이터들로 정제된 학습 데이터를 생성하는 것을 특징으 로 한다. 상기 학습모델생성부는, 융합 컨벌루션 뉴럴 네트워크(Converged Convolutional Neural Network)에 의해 학습 이 수행되며, 상기 융합 컨벌루션 뉴럴 네트워크(Converged Convolutional Neural Network)는 상기 의료영상 판독 전문가의 판독문으로부터 정제된 학습 데이터를 지속적으로 업데이트하여 입력받고 이를 학습모델의 생성 에 반영함으로써, 융합 컨볼루션 뉴럴 네트워크를 통해서 딥러닝 기계학습을 수행하여 계산량을 줄이고 정확도 를 향상시켜 전체적인 성능을 향상하는 것을 특징으로 한다. 또한 상기 융합 컨벌루션 뉴럴 네트워크(Converged Convolutional Neural Network)는 역방향 전파에 의해서 가 중치가 업데이트되도록 구성되는 것을 특징으로 한다. 한편 본 발명의 또 다른 일 실시예에 따른 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 방법은, 의료영상 판독 전문가의 판독문으로부터 추출한 정규화된 형태의 정제된 학습 데이터를 생성하는 판독 기록 지도학습(supervised learning) 단계 및 상기 판독 기록 지도학습 단계에서 정제된 학습 데이터를 입력으 로 상기 의료영상을 판독하도록 기계학습을 수행하는 학습모델생성 단계를 포함하며, 상기 기계학습은 상기 의 료영상 판독 전문가의 판독문으로부터 정제된 학습 데이터를 지속적으로 업데이트하여 입력받음으로써, 상기 학 습 데이터가 자동으로 강화학습 데이터가 되는 것을 특징으로 한다. 상기 판독 기록 지도학습(supervised learning) 단계는, 상기 판독문의 파일 위치 주소로부터 데이터를 읽어 들 이는 의료기록 데이터 로딩 단계, 상기 판독문을 신체부위(Body Part) 별로 발견(Findings), 결론(Conclusion) 및 권고(Recommendation)를 포함한 섹션으로 분류하고, 상기 각 섹션의 평문텍스트로부터 질병관련 단어 또는 어구를 하나의 집합으로 라벨링하는 라벨링처리 단계, 상기 라벨링된 판독문에서 질병관련 단어 또는 어구를 추 출하는 의료관련 용어 추출 단계, 상기 추출된 단어 또는 어구로부터 공통된 특징을 추출하는 특징 추출 단계, 상기 추출된 특징들을 규칙화하여 특징 행렬(Feature Matrix)을 생성하는 특징행렬생성 단계, 임의의 판독문이 주어지면 상기 판독문을 특징 행렬에 사상(mapping)시켜 특징을 분석하는 특징 분석 단계, 및 상기 분석된 특징 만으로 정제된 학습 데이터를 생성하는 정제 데이터 생성 단계를 포함하는 것을 특징으로 한다. 상기 의료기록 데이터 로딩 단계는, 입력값으로 주어진 판독문 원본 데이터의 파일 위치 주소로부터 파일의 위 치, 전체 파일 개수, 파일의 길이 또는 이들의 조합을 읽어 들여 시스템 메모리에 적재시키며, 상기 라벨링 처 리 단계는, 상기 시스템 메모리에 적재된 데이터를 신체부위(Body Part)별로 각 판독 섹션별로 라벨링하고, 이 를 각각의 집합으로 분류하여 시스템 메모리상에 재배치하며, 상기 의료관련 용어 추출 단계는, 각 섹션의 평문 텍스트와 SNOMED-CT, ICD-11, LOINC, KCD-10을 포함한 표준 의료 용어 데이터 집합과 비교하여 해당 평문텍스트 만 선택적으로 추출하며, 상기 특징 추출 단계는, 상기 의료관련 용어 추출부에서 추출된 의료 관련 용어로부터 단어 종류, 서술 형태, 서술 빈도 또는 이들의 조합을 분석하여 병변의 유무와 관련된 용어의 특징, 병변의 위 치 표시와 관련된 용어의 특징, 증상 묘사와 관련된 용어의 특징, 병증의 종류를 나타내는 용어의 특징 또는 이 들의 조합을 추출하며, 상기 특징행렬 생성 단계는, 상기 특징 추출부에서 추출된 특징들을 데이터 집합으로 하 여 새롭게 입력되는 평문텍스트와 사상시킴으로써 유사 또는 동일 의미의 용어인지 비교 및 분석이 가능한 특징 행렬(Feature Matrix)을 생성하며, 상기 특징 분석 단계는, 정제되지 않은 원본 판독문이 입력되었을 때, 이를 특징 행렬에 사상시켜 판독문을 서술하는 평문텍스트에서 병변의 존재 유무, 병변의 위치, 증상, 병증의 종류 등을 추출, 분석 및 분류하며, 상기 정제 데이터 생성 단계는, 상기 특징 분석부에서 추출, 분석 및 분류된 데 이터들로 정제된 학습 데이터를 생성하는 것을 특징으로 한다. 상기 학습모델생성 단계는, 융합 컨벌루션 뉴럴 네트워크(Converged Convolutional Neural Network)에 의해 학 습이 수행되며, 상기 융합 컨벌루션 뉴럴 네트워크(Converged Convolutional Neural Network)는 상기 의료영상 판독 전문가의 판독문으로부터 정제된 학습 데이터를 지속적으로 업데이트하여 입력받고 이를 학습모델의 생성 에 반영함으로써, 융합 컨볼루션 뉴럴 네트워크를 통해서 딥러닝 기계학습을 수행하여 계산량을 줄이고 정확도 를 향상시켜 전체적인 성능을 향상하는 것을 특징으로 한다. 또한 상기 학습모델생성 단계는, 역방향 전파에 의해서 가중치가 업데이트되도록 구성되는 것을 특징으로 한다."}
{"patent_id": "10-2018-0022735", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서와 같이 본 발명의 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템 및 그 방법에 따르면, 사용자는 컨벌루션 뉴럴 네트워크를 이용하여 의료영상 이미지의 병변의 존재 여부, 병변의 위치, 병증 의 종류 등을 판독할 때, 의료영상 이미지의 픽셀 정보 분석을 통한 컨벌루션 뉴럴 네트워크의 출력값과 판독기 록 지도학습 모델에서 학습 결과로 산출된 동일 신체부위에 대한 판독기록 분석을 통한 출력값을 융합하여 종래 의 컨벌루션 뉴럴 네트워크를 이용한 의료영상 이미지 판독 결과보다 정확한 판독 결과를 얻거나 컨벌루션 뉴럴 네트워크의 계산 복잡도(complexity)를 낮출 수 있으며, 종래의 컨벌루션 뉴럴 네트워크를 통해 알 수 없었던병증의 종류까지 예측할 수 있는 효과가 있다."}
{"patent_id": "10-2018-0022735", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참조하여 본 발명의 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템 및 그 방법에 대한 바람직한 실시 예를 상세히 설명한다. 각 도면에 제시된 동일한 참조부호는 동일한 부재를 나타낸다. 또한 본 발명의 실시 예들에 대해서 특정한 구조적 내지 기능적 설명들은 단지 본 발명에 따른 실시 예를 설명하기 위한 목적으로 예시된 것으로, 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해"}
{"patent_id": "10-2018-0022735", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관 련 기술의 문맥상 가지는 의미와 일치하는 의미를 가지는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정 의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는 것이 바람직하다. 도 1은 종래의 의료영상 판독 시스템의 개념을 나타낸 도면이다. 도 2는 본 발명의 일 실시예에 따른 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템 및 그 방법의 개념을 나타낸 도면이다. 도 1에 도시된 바와 같이, 종래의 의료영상 판독시스템은 의사가 의료영상을 통해서 병변의 존재유무에 대한 판 단을 하는데 도움을 주는 시스템으로, 로컬, 병원, 의료기관 등의 데이터베이스에 저장된 의료영상을 이용하여 학습모델을 생성하고, 새로운 의료영상을 입력하면 상기 학습모델에 입력 의료영상을 적용하여 그 판독결과로부 터 병변을 예측하는 구조를 가지고 있었다. 이 경우 수많은 의료영상으로부터 학습모델을 생성하기 때문에 학습에 많은 시간이 소요되며, 정확도도 떨어지 는 문제가 있었다. 이에 본 발명에서는 이러한 문제를 극복하기 위해서 전문의의 의료영상에 대한 판독결과인 판독문으로 학습모델을 고도화하는 강화학습을 수행하는 구조를 제시하고자 한다. 도 2에 도시된 바와 같이, 전문의는 의료영상을 판독하여 판독문을 구성하는데, 여기서 생성된 판독문을 이용하 여 의료영상 판독 시스템의 학습모델의 학습결과를 향상시키는데 활용하고자 한다. 특히, 본 발명에서는 판독문 의 판독결과를 이용하여 의료영상을 학습하는 학습모델의 생성 과정에 학습 성능을 개선하고 복잡도를 줄이는 역할을 수행하도록 한다.이하에서는 본 발명의 일 실시예에 따른 의료영상 판독 시스템에 대한 세부 구성에 대해서 논의하고자 한다. 도 3은 본 발명의 일 실시예에 따른 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템의 구 성을 설명하기 위한 도면이다. 도 3에 도시된 바와 같이, 본 발명의 일 실시예에 따른 의료영상 판독 시스템은 판독문 지도 학습부, 의료영상 학습부, 의료영상 데이터베이스, 판독문 데이터베이스 등을 포함한다. 상기 의료영상 데이터베이스와 판독문 데이터베이스는 하나의 데이터베이스에 구성되어도 무방하다. 여기서 영상의학과 전문의는 의료영상을 판독한 다음 해당 영상의 판독문을 작성한다. 해당 의료영상 은 의료영상 학습부에 입력되어 기계학습을 수행한다. 아울러 판독문은 판독문 지도 학습부에 입력되어 해당 판독문의 특징을 추출하여 의료영상 학습부에 제공함으로써 해당 의료영상에 대한 학습 성 능(계산량, 복잡도)을 향상시키다. 따라서 본 발명의 의료영상 판독 시스템은 의료영상)을 입력으로 하여 의료영상을 학습하는 의료영상 학습부가 상기 의료영상을 전문의가 판독한 판독문으로부터 추출한 데이터를 이용하여 판독문 지도 학습부에서 의료영상 학습부에서 필요로 하는 정제된 학습 데이터를 제공하여, 의료영상의 학습 성능 을 향상시킨다, 이 과정에서 영상의학과 전문의의 의료영상에 대한 판독문을 점점 고도화하여 반영함으로써, 의료영상의 학습 성능을 향상시킨다. 이하에서는 의료영상의 판독문 지도 학습부와 의료영상 학습부의 구성에 대해서 자세하게 설명하고자 한다. 도 4는 본 발명의 일 실시예에 따른 정제된 인공지능 강화학습 데이터 생성을 위한 판독기록 지도학습(medical report supervised learning)부의 구성을 보인 블록도이다. 도 4에 도시된 바와 같이, 상기 판독기록 지도학습부는 판독문의 파일 위치 주소로부터 데이터를 읽어 들 이는 의료기록 데이터 로딩부, 상기 판독문을 신체부위(Body Part) 별로 발견(Findings), 결론 (Conclusion) 및 권고(Recommendation)를 포함한 섹션으로 분류하고, 상기 각 섹션의 평문텍스트로부터 질병관 련 단어 또는 어구를 하나의 집합으로 라벨링하는 라벨링처리부, 상기 라벨링된 판독문에서 질병관련 단어 또는 어구를 추출하고, 상기 추출된 단어 또는 어구로부터 공통된 특징을 추출하는 특징 추출부, 상기 추 출된 특징들을 규칙화하여 특징 행렬(Feature Matrix)을 생성하는 특징행렬 생성부를 포함한다. 이러한 결 과로 생성된 특징행렬은 데이터베이스에 저장되어, 향 후 입력되는 판독문을 특징행렬과 사상시켜 특징을 분석 하는데 사용할 수 있다. 아울러 상기 판독기록 지도학습부는 임의의 판독문이 주어지면 지도학습을 통해 상기 판독문을 특징 행렬 에 사상(mapping)시켜 특징을 분석하는 지도학습 특징 분석부 및 상기 분석된 특징만으로 정제된 학습 데 이터를 생성하는 정제 데이터 생성부를 더 포함한다. 여기서 상기 의료기록 데이터 로딩부는, 입력값으로 주어진 판독문 원본 데이터의 파일 위치 주소로부터 파일의 위치, 전체 파일 개수, 파일의 길이 또는 이들의 조합을 읽어 들여 시스템 메모리나 보조메모리에 적재 시키고, 그 결과를 이용하여 판독기록 지도학습에 활용한다. 상기 라벨링 처리부는, 상기 시스템 메모리 또는 보조메모리에 적재된 데이터를 신체부위(Body Part)별로 각 판독 섹션별로 라벨링하고, 이를 각각의 집합으로 분류하여 시스템 메모리나 보조메모리 상에 재배치한다. 상기 특징 추출부는, 각 섹션의 평문텍스트와 SNOMED-CT, ICD-11, LOINC, KCD-10을 포함한 표준 의료 용 어 데이터 집합과 비교하여 해당 평문텍스트만 선택적으로 추출하여, 상기 의료관련 용어 추출부에서 추출된 의 료 관련 용어로부터 단어 종류, 서술 형태, 서술 빈도 또는 이들의 조합을 분석하여 병변의 유무와 관련된 용어 의 특징, 병변의 위치 표시와 관련된 용어의 특징, 증상 묘사와 관련된 용어의 특징, 병증의 종류를 나타내는 용어의 특징 또는 이들의 조합을 추출한다. 상기 특징행렬 생성부는, 상기 특징 추출부에서 추출된 특징들을 데이터 집합으로 하여 새롭게 입력 되는 평문텍스트와 사상시킴으로써 유사 또는 동일 의미의 용어인지 비교 및 분석이 가능한 특징 행렬(Feature Matrix)을 생성한다. 다음으로 상기 지도학습 특징 분석부는, 정제되지 않은 원본 판독문이 입력되었을 때, 이를 지도학습모델 에 적용하여 특징행렬에 사상시켜 판독문을 서술하는 평문텍스트에서 병변의 존재 유무, 병변의 위치, 증상, 병 증의 종류 등을 추출, 분석 및 분류한다. 상기 정제 데이터 생성부는, 상기 지도학습 특징 분석부에서 추출, 분석 및 분류된 데이터들로 정제 된 학습 데이터를 생성한다. 상기 정제된 학습 데이터는 의료영상의 판독에 대한 성능을 향상시키기 위한 부가 정보에 해당한다. 특히 상기 지도학습 특징 분석부는 지도학습을 수행하는 것으로, 먼저 의료영상에 대한 잘 정의된 특징행 렬을 기준으로 임의의 새로이 입력된 의료영상의 판독문을 학습시켜 해당 입력된 판독문이 어떠한 특징행렬을 갖는지 분류하여 판단한다. 이를 위해서 새로이 입력되는 임의의 의료영상에 대한 판독문은 NLP(Natural Language Processor)를 통해 질병 관련 단어 또는 어구를 추출하고, 지도학습 모델에 입력하면, 입력된 판독문의 특징행렬과 매핑하여 정제된 학 습 데이터가 추출된다. 임의의 새로운 판독문이 입력되면 이를 기존의 특징행렬과 비교하여 분류하는데, 이때 임의의 새로운 판독문으 로부터 특징행렬을 추출해야 하므로, 결국 의료기록 데이터 로딩부, 라벨링 처리부, 특징 추출부 및 특징행렬 생성부의 과정을 포함하는 기준 특징행렬 추출부의 기능을 그대로 수행하는 방법 도 가능하고, 지도학습모델에 입력하여 분류하는 방법도 가능하다. 바람직하게 본 발명에서는 두 가지 방법을 모두 사용가능하다. 이하에서는 학습용 텍스트 데이터를 입력받아 정제된 학습 데이터를 생성하는 과정에 대해서 설명하고자 한다. 도 5는 본 발명의 일 실시예에 따른 정제된 인공지능 강화학습 데이터를 생성하는 과정을 보인 도면이다. 도 5에 도시된 바와 같이, 먼저 영상의학과 전문의의 판독문(Rk)을 입력받아 판독문 중 발견(Finding)(F)에 해 당하는 내용만 추출해 낸 집합을 생성하고, 여기서 판독문 중 결론(Conclusion)(C)에 해당하는 내용만 추출해 낸 집합을 생성하고, 판독문 중 권고(Recommendation(R)에 해당하는 내용만 추출해 낸 집합을 생성하고 레이블 링한다. 이러한 집합들은 신체부위(BP)별로 구분될 필요가 있다. 이렇게 레이블링된 사항으로부터 특징을 추출한다. 여기서 FM1, … , FMx 등은 라벨링된 판독문의 F, C, R 집합 에서 추출해 낸 특징맵(feature metric)의 집합이다. 즉 특징을 추출한 다음 특징별로 메트릭스를 구축한다. 예 를 들어, X번째 특징의 측정(feature metric)은 a1 부터 ak 까지 동일한 질병이나 증상을 나타내는 k개의 동의 어나 표현, 어휘를 모두 수렴 또는 지배(dominate)하는 A에 사상되며, 전체 특징행렬(Feature Metrix)은 질병명, 위치 표현, 중증 정도를 나타내는 각 측정(metric)으로 구성된다. 여기서 생성된 결과는 RRx로써, X번 째 로우 데이터(Raw data)(Rx)가 특징 행렬(Feature Matrix)을 통해 정제된(refined) 데이터를 출력한다. 도 6은 본 발명의 일 실시예에 따른 정제된 인공지능 강화학습 데이터 생성을 통한 융합 컨벌루션 뉴럴 네트워 크(CCNN)의 구성을 보인 개념도이다. 도 6에 도시된 바와 같이, 종래의 컨벌루션 뉴럴 네트워크에 정제된 인공지능 강화학습 데이터를 적용함으로써, 융합된 컨벌루션 뉴럴 네트워크를 구축할 수 있다. 예를 들어 정제된 인공지능 강화학습 데이터에서 판독문을 서술하는 평문텍스트로부터 병변의 존재 유무, 병변의 위치, 증상, 병증의 종류 등을 추출, 분석 및 분류하여 컨벌루션 단계에서 세밀하게 예측해야할 부분을 집중적으로 학습하고, 그렇지 않은 부분은 상대적으로 많은 계 산 복잡도를 부가하지 않도록 한다. 즉, 병변이 존재하는 부위에 대해서 정밀하게 학습하고, 증상이나 병변의 종류에 따라 다르게 학습함으로써, 모든 입력영상에 대해서 동일한 강도의 학습을 수행하는 것에 비해서 복잡도 는 줄이고 학습성능은 향상시키는 역할을 한다. 여기서 임의의 판독문이 입력되면 해당 의료영상에 대해서 판독문을 해독한 다음 지도학습모델에 따라 의료기록 을 분석한 다음 병변의 존재유무, 병변의 위치, 증상, 변증의 종류에 대한 정보를 추출하고, 분선 및 분류하여 지도학습 모델과 융합된 컨벌루션 뉴럴 네트워크를 구성하고 수행하도록 한다. 상기 융합된 컨벌루션 뉴럴 네트워크는 복수의 컨벌루션 레이어가 존재하며, 이때마다 지도학습의 결과를 이용 하여 커스터마이징된 컨벌루션을 수행하도록 한다. 이러한 방식으로 본 발명은 더욱 향상된 성능의 학습모델을 생성할 수 있다. 의료영상과 해당 의료영상의 판독문을 이용하여 영상의학과 전문의가 판독문을 판독한 결과에 서 각 신체부위 별로 발견, 결론, 권고 별로 라벨링하고, 특징을 추출하여 특징행렬을 생성하여 저장하고, 그결과를 새로운 의료영상의 판독문에 대해서도 특징행렬을 추출한 다음 기 저장된 특징행렬과 매핑하여 정제된 학습 데이터를 도출한다. 이러한 특징행렬을 분선하면 병변의 존재유무, 병변의 위치, 증상, 변증의 종류에 대 한 정보를 추출할 수 있다. 이를 통해서 융합 CNN을 구성하고 학습을 수행할 수 있다. 아울러 본 발명에 따른 융합 컨벌루션 네트워크는 전문의의 평가결과를 역으로 반영하는 역방향 전파에 의해서 가중치가 업데이트되도록 구성된다. 이는 CNN을 구성하는 각 단계에서 파라미터의 가중치를 업데이트함에 있어 서, 출력부의 판독결과를 은닉층, 컨벌루션 계층으로 가중치를 역으로 전파하여 수정하여 보다 정확한 판독이 가능하도록 한다. 도 7은 본 발명의 일 실시예에 따른 판독기록 지도학습 모델의 특징행렬 생성을 위한 흐름도이다. 도 7에 도시된 바와 같이, 지도학습 모델의 특징행렬 생성 과정은, 먼저 네트워크 또는 로컬 저장소에서 의료영 상 이미지의 다이콤 메타데이터 및 판독문을 로딩한다(S110). 다음으로 로딩한 의료영상 이미지의 다이콤 메타 데이터에 포함된 신체부위(Body Part) 필드를 추출한다(S120). 이어서, 의료영상 이미지의 판독문을 발견 (Findings), 결론(Conclusion), 권고(Recommendation) 별로 라벨링하여 각 집합에 평문텍스트들을 삽입한다 (S130). 이어서 추가 의료영상 이미지가 있으면(S140), S110 내지 S130의 과정을 반복하고, 아니면 표준 의료 용어 데이 터 집합을 로딩한다(S150). 또한 라벨링된 발견(Findings), 결론(Conclusion), 권고(Recommendation) 별로 해 당 집합의 각 요소들과 표준 의료용어 데이터집합을 순차적으로 맵핑하여 질병에 관련된 단어 또는 어휘를 추출 한다(S160). 상기 추출된 단어 및 어휘들로부터 단어 종류, 서술 형태, 서술 빈도 분석을 통해 특징을 추출한다(S170). 마지 막으로, 추출된 특징들을 엘리먼트로 하는 특징행렬을 생성한다(S180). 도 8은 본 발명의 일 실시예에 따른 판독기록 지도학습 모델에서 임의의 판독문에서 질병과 관련된 특징값을 추 출하는 흐름도이다. 도 8에 도시된 바와 같이, 본 발명의 일 실시예에 따른 임의의 판독문에서 질병과 관련된 특징값을 추출하는 과 정은 먼저 네트워크 또는 로컬 저장소에서 의료영상 이미지의 다이콤 메타데이터 및 판독문을 로딩한다(S210). 이어서 의료영상 이미지의 다이콤 메타데이터에 포함된 신체부위(Body Part) 필드를 추출한다(S220). 상기 의료영상 이미지의 판독문을 발견(Findings), 결론(Conclusion), 권고(Recommendation) 별로 라벨링하여 각 섹션별로 평문텍스트를 추출한다(S230). 그리고 추출된 평문텍스트를 동일 신체부위(Body Part)의 특징행렬 의 각 엘리먼트들과 맵핑한다(S240). 상기 특징행렬의 맵핑 결과 유사 또는 동일 용어 또는 어휘 표현이 존재하 는 텍스트의 데이터를 추출한다(S250). 이렇게 추출된 데이터를 분석하여 병변의 존재유무, 병변의 위치, 증상, 변증의 종류에 대한 정보를 추출할 수 있다. 이를 통해서 융합 CNN을 구성하고 학습을 수행할 수 있다. 도 9는 본 발명의 일 실시예에 따른 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 과정의 흐름 도이다. 도 9를 참조하면, 본 발명의 일 실시예에 따른 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 과 정은 먼저 의료영상 판독 전문가의 판독문으로부터 추출한 정규화된 형태의 정제된 학습 데이터를 생성하는 판 독기록 지도학습(supervised learning)을 수행한다(S310). 이어서 상기 판독 기록 지도학습 단계에서 정제된 학습 데이터를 입력으로 상기 의료영상을 판독하도록 기계학 습을 수행한다(S320). 상기 의료영상 판독 전문가의 판독문으로부터 정제된 학습 데이터를 지속적으로 업데이트하여 입력받고 이를 학 습모델의 생성에 반영함으로써, 융합 컨볼루션 뉴럴 네트워크를 통해서 딥러닝 기계학습을 수행하여 계산량을 줄이고 정확도를 향상시켜 전체적인 성능을 향상한다(S330). 이처럼, 본 발명에 따르면, 사용자는 컨벌루션 뉴럴 네트워크를 이용하여 의료영상 이미지의 병변의 존재 여부, 병변의 위치, 병증의 종류 등을 판독할 때, 의료영상 이미지의 픽셀 정보 분석을 통한 컨벌루션 뉴럴 네트워크 의 출력값과 판독기록 지도학습 모델에서 학습 결과로 산출된 동일 신체부위에 대한 판독기록 분석을 통한 출력 값을 융합하여 종래의 컨벌루션 뉴럴 네트워크를 이용한 의료영상 이미지 판독 결과보다 정확한 판독 결과를 얻 거나 컨벌루션 뉴럴 네트워크의 계산 복잡도(complexity)를 낮출 수 있으며, 종래의 컨벌루션 뉴럴 네트워크를통해 알 수 없었던 병증의 종류까지 예측할 수 있는 효과가 있다. 이상으로 본 발명은 도면에 도시된 실시예를 참고로 하여 설명되었으나, 이는 예시적인 것에 불과하며, 당해 기 술이 속하는 분야에서 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점 을 이해할 것이다. 따라서 본 발명의 기술적 보호범위는 아래의 특허청구범위에 의해서 판단되어야 할 것이다."}
{"patent_id": "10-2018-0022735", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래의 의료영상 판독 시스템의 개념을 나타낸 도면이다. 도 2는 본 발명의 일 실시예에 따른 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템 및 그 방법의 개념을 나타낸 도면이다. 도 3은 본 발명의 일 실시예에 따른 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 시스템의 구 성을 설명하기 위한 도면이다. 도 4는 본 발명의 일 실시예에 따른 정제된 인공지능 강화학습 데이터 생성을 위한 판독기록 지도학습 모델 (medical report supervised learning model)의 구성을 보인 블록도이다. 도 4는 본 발명의 일 실시예에 따른 정제된 인공지능 강화학습 데이터 생성을 위한 판독기록 지도학습(medical report supervised learning)부의 구성을 보인 블록도이다. 도 5는 본 발명의 일 실시예에 따른 정제된 인공지능 강화학습 데이터를 생성하는 과정을 보인 도면이다. 도 6은 본 발명의 일 실시예에 따른 정제된 인공지능 강화학습 데이터 생성을 통한 융합된 컨벌루션 뉴럴 네트 워크(CCNN)의 구성을 보인 개념도이다. 도 7은 본 발명의 일 실시예에 따른 판독기록 지도학습 모델의 특징행렬 생성을 위한 흐름도이다. 도 8은 본 발명의 일 실시예에 따른 판독기록 지도학습 모델에서 임의의 판독문에서 질병과 관련된 특징값을 추 출하는 흐름도이다. 도 9는 본 발명의 일 실시예에 따른 정제된 인공지능 강화학습 데이터 생성을 통한 의료영상 판독 과정의 흐름 도이다."}
