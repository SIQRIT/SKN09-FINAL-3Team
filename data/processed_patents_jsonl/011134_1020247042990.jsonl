{"patent_id": "10-2024-7042990", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0013239", "출원번호": "10-2024-7042990", "발명의 명칭": "AR-기반 가상 키보드", "출원인": "스냅 인코포레이티드", "발명자": "몰, 샤론"}}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 구현 방법(computer-implemented method)으로서, 증강 현실(AR) 시스템의 하나 이상의 프로세서에 의해:상기 AR 시스템의 하나 이상의 카메라를 사용하여, 상기 AR 시스템의 사용자에 의해 이루어진 텍스트 입력 시작제스처(start text entry gesture)를 검출하는 단계;상기 텍스트 입력 시작 제스처의 검출에 응답하여, 복수의 가상 키를 갖는 가상 키보드를 포함하는 가상 키보드사용자 인터페이스를 생성하는 단계;상기 AR 시스템의 디스플레이를 사용하여 상기 가상 키보드 사용자 인터페이스를 상기 사용자에게 제공하는 단계;상기 AR 시스템의 상기 하나 이상의 카메라를 사용하여, 상기 복수의 가상 키 중 하나 이상의 선택된 가상 키의상기 사용자의 선택을 결정하는 단계;상기 하나 이상의 선택된 가상 키에 기초하여 입력된 텍스트 데이터를 생성하는 단계; 및상기 AR 시스템의 디스플레이를 사용하여 상기 입력된 텍스트 데이터를 상기 사용자에게 제공하는 단계를 포함하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 하나 이상의 카메라를 사용하여, 상기 사용자에 의해 이루어진 텍스트 입력 종료 제스처를 검출하는 단계;및상기 가상 키보드 사용자 인터페이스를 닫는 단계를 추가로 포함하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 하나 이상의 선택된 가상 키의 상기 사용자의 선택을 결정하는 단계는:추적 서비스로부터 수신된 현재 추적 데이터에 기초하여 상기 사용자의 텍스트 입력 손과 연관된 랜드마크를 검출하는 단계;상기 랜드마크에 기초하여 랜드마크 충돌기를 생성하는 단계; 및상기 랜드마크 충돌기와 상기 하나 이상의 선택된 가상 키 사이의 충돌들을 검출함으로써 상기 하나 이상의 선택된 가상 키의 상기 사용자의 선택을 결정하는 단계를 추가로 포함하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 AR 시스템의 하나 이상의 카메라를 사용하여, 상기 AR 시스템의 사용자에 의해 이루어진텍스트 입력 시작 제스처를 검출하는 단계는:상기 하나 이상의 카메라를 사용하여 추적 데이터를 생성하는 단계;상기 추적 데이터에 기초하여 하나 이상의 골격 모델을 생성하는 단계; 및인공 지능 방법론들을 사용하여 상기 하나 이상의 골격 모델을 카테고리화하는 것 및 머신 러닝 방법론들을 사공개특허 10-2025-0013239-3-용하여 이전에 생성된 제스처 모델에 기초하여 상기 텍스트 입력 시작 제스처를 결정하는 단계를 추가로 포함하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 AR 시스템의 하나 이상의 카메라를 사용하여, 상기 AR 시스템의 사용자에 의해 이루어진텍스트 입력 시작 제스처를 검출하는 단계는:상기 하나 이상의 카메라를 사용하여 추적 데이터를 생성하는 단계;상기 추적 데이터에 기초하여 하나 이상의 골격 모델을 생성하는 단계;상기 하나 이상의 골격 모델을 이전에 생성된 제스처 골격 모델들과 비교하는 단계; 및상기 하나 이상의 골격 모델과 상기 제스처 골격 모델들의 비교에 기초하여 텍스트 입력 시작 제스처를 결정하는 단계를 추가로 포함하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 AR 시스템은 머리 착용형 디바이스를 포함하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "AR 시스템의 컴퓨팅 장치로서, 하나 이상의 프로세서; 및상기 하나 이상의 프로세서에 의해 실행될 때, 상기 컴퓨팅 장치로 하여금 동작들을 수행하게 하는 명령어들을저장하는 메모리를 포함하고, 상기 동작들은 상기 하나 이상의 프로세서에 의해:상기 AR 시스템의 하나 이상의 카메라를 사용하여, 상기 AR 시스템의 사용자에 의해 이루어진 텍스트 입력 시작제스처를 검출하는 단계;상기 텍스트 입력 시작 제스처의 검출에 응답하여, 복수의 가상 키를 갖는 가상 키보드를 포함하는 가상 키보드사용자 인터페이스를 생성하는 단계;상기 AR 시스템의 디스플레이를 사용하여 상기 가상 키보드 사용자 인터페이스를 상기 사용자에게 제공하는 단계;상기 하나 이상의 카메라를 사용하여, 상기 복수의 가상 키 중 하나 이상의 선택된 가상 키의 상기 사용자의 선택을 결정하는 단계;상기 하나 이상의 선택된 가상 키에 기초하여 입력된 텍스트 데이터를 생성하는 단계; 및상기 AR 시스템의 디스플레이를 사용하여 상기 입력된 텍스트 데이터를 상기 사용자에게 제공하는 단계를 포함하는, AR 시스템의 컴퓨팅 장치."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 명령어들은 추가로 상기 컴퓨팅 장치로 하여금:상기 하나 이상의 카메라를 사용하여, 상기 사용자에 의해 이루어진 텍스트 입력 종료 제스처를 검출하는 단계;및상기 가상 키보드 사용자 인터페이스를 닫는 단계를 포함하는 동작들을 수행하게 하는, AR 시스템의 컴퓨팅 장치."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "공개특허 10-2025-0013239-4-제7항에 있어서, 상기 컴퓨팅 장치로 하여금 상기 하나 이상의 선택된 가상 키의 상기 사용자의 선택을 결정하는 동작을 수행하게 하는 명령어들은 추가로 상기 컴퓨터로 하여금: 추적 서비스로부터 수신된 현재 추적 데이터에 기초하여 상기 사용자의 텍스트 입력 손과 연관된 랜드마크를 검출하는 단계;상기 랜드마크에 기초하여 랜드마크 충돌기를 생성하는 단계; 및상기 랜드마크 충돌기와 상기 하나 이상의 선택된 가상 키 사이의 충돌들을 검출함으로써 상기 하나 이상의 선택된 가상 키의 상기 사용자의 선택을 결정하는 단계의 동작들을 수행하게 하는, AR 시스템의 컴퓨팅 장치."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서, 상기 AR 시스템의 하나 이상의 카메라를 사용하여, 상기 AR 시스템의 사용자에 의해 이루어진텍스트 입력 시작 제스처를 검출하는 단계는:상기 하나 이상의 카메라를 사용하여 추적 데이터를 생성하는 단계;상기 추적 데이터에 기초하여 하나 이상의 골격 모델을 생성하는 단계; 및인공 지능 방법론들을 사용하여 상기 하나 이상의 골격 모델을 카테고리화하는 것 및 머신 러닝 방법론들을 사용하여 이전에 생성된 제스처 모델에 기초하여 상기 텍스트 입력 시작 제스처를 결정하는 단계를 추가로 포함하는, AR 시스템의 컴퓨팅 장치."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서, 상기 AR 시스템의 하나 이상의 카메라를 사용하여, 상기 AR 시스템의 사용자에 의해 이루어진텍스트 입력 시작 제스처를 검출하는 단계는:상기 하나 이상의 카메라를 사용하여 추적 데이터를 생성하는 단계;상기 추적 데이터에 기초하여 하나 이상의 골격 모델을 생성하는 단계;상기 하나 이상의 골격 모델을 이전에 생성된 제스처 골격 모델들과 비교하는 단계; 및상기 제스처 골격 모델들과 상기 하나 이상의 골격 모델의 비교에 기초하여 텍스트 입력 시작 제스처를 결정하는 단계를 추가로 포함하는, AR 시스템의 컴퓨팅 장치."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서, 상기 AR 시스템은 머리 착용형 디바이스를 포함하는, AR 시스템의 컴퓨팅 장치."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "비일시적 컴퓨터 판독가능 저장 매체로서,AR 시스템의 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금 동작들을 수행하게 하는 명령어들을 포함하고, 상기 동작들은:상기 AR 시스템의 하나 이상의 카메라를 사용하여, 상기 AR 시스템의 사용자에 의해 이루어진 텍스트 입력 시작제스처를 검출하는 단계;상기 텍스트 입력 시작 제스처의 검출에 응답하여, 복수의 가상 키를 갖는 가상 키보드를 포함하는 가상 키보드사용자 인터페이스를 생성하는 단계;상기 AR 시스템의 디스플레이를 사용하여 상기 가상 키보드 사용자 인터페이스를 상기 사용자에게 제공하는 단계;상기 AR 시스템의 상기 하나 이상의 카메라를 사용하여, 상기 복수의 가상 키 중 하나 이상의 선택된 가상 키의공개특허 10-2025-0013239-5-상기 사용자의 선택을 결정하는 단계;상기 하나 이상의 선택된 가상 키에 기초하여 입력된 텍스트 데이터를 생성하는 단계; 및상기 AR 시스템의 디스플레이를 사용하여 상기 입력된 텍스트 데이터를 상기 사용자에게 제공하는 단계를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 명령어들은 추가로 상기 컴퓨터로 하여금:상기 AR 시스템의 상기 하나 이상의 카메라를 사용하여, 상기 사용자에 의해 이루어진 텍스트 입력 종료 제스처를 검출하는 단계; 및상기 가상 키보드 사용자 인터페이스를 닫는 단계를 포함하는 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서, 상기 컴퓨터로 하여금 상기 하나 이상의 선택된 가상 키의 상기 사용자의 선택을 결정하는 동작을 수행하게 하는 명령어들은 추가로 상기 컴퓨터로 하여금: 추적 서비스로부터 수신된 현재 추적 데이터에 기초하여 상기 사용자의 텍스트 입력 손과 연관된 랜드마크를 검출하는 단계;상기 랜드마크에 기초하여 랜드마크 충돌기를 생성하는 단계; 및상기 랜드마크 충돌기와 상기 하나 이상의 선택된 가상 키 사이의 충돌들을 검출함으로써 상기 하나 이상의 선택된 가상 키의 상기 사용자의 선택을 결정하는 단계의 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서, 상기 컴퓨터로 하여금, 상기 AR 시스템의 상기 하나 이상의 카메라를 사용하여, 상기 AR 시스템의 사용자에 의해 이루어진 텍스트 입력 시작 제스처를 검출하는 동작을 수행하게 하는 상기 명령어들은 추가로 상기 컴퓨터로 하여금:상기 하나 이상의 카메라를 사용하여 추적 데이터를 생성하는 단계;상기 추적 데이터에 기초하여 하나 이상의 골격 모델을 생성하는 단계; 및인공 지능 방법론들을 사용하여 상기 하나 이상의 골격 모델을 카테고리화하는 것 및 머신 러닝 방법론들을 사용하여 이전에 생성된 제스처 모델에 기초하여 상기 텍스트 입력 시작 제스처를 결정하는 단계의 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-7042990", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서, 상기 컴퓨터로 하여금, 상기 AR 시스템의 상기 하나 이상의 카메라를 사용하여, 상기 AR 시스템의 사용자에 의해 이루어진 텍스트 입력 시작 제스처를 검출하는 동작을 수행하게 하는 상기 명령어들은 추가로 상기 컴퓨터로 하여금:상기 하나 이상의 카메라를 사용하여 추적 데이터를 생성하는 단계;상기 추적 데이터에 기초하여 하나 이상의 골격 모델을 생성하는 단계;상기 하나 이상의 골격 모델을 이전에 생성된 제스처 골격 모델들과 비교하는 단계; 및상기 하나 이상의 골격 모델과 상기 제스처 골격 모델들의 비교에 기초하여 텍스트 입력 시작 제스처를 결정하는 단계의 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.공개특허 10-2025-0013239-6-청구항 18 제13항에 있어서, 상기 AR 시스템은 머리 착용형 디바이스를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-7042990", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "증강 현실(AR) 디바이스를 위한 제스처 기반 텍스트 입력 사용자 인터페이스가 제공된다. AR 시스템은 AR 시스 템의 사용자에 의해 이루어진 텍스트 입력 시작 제스처를 검출하고, 복수의 가상 키를 갖는 가상 키보드를 포함 하는 가상 키보드 사용자 인터페이스를 생성하고, 가상 키보드 사용자 인터페이스를 사용자에게 제공한다. AR 시스템은 하나 이상의 카메라를 사용하여, 복수의 가상 키 중 하나 이상의 선택된 가상 키에 대한 사용자의 선택 을 결정하고, 하나 이상의 선택된 가상 키에 기초하여 입력된 텍스트 데이터를 생성한다. AR 시스템은 AR 시스 템의 디스플레이를 사용하여 입력된 텍스트 데이터를 사용자에게 제공한다."}
{"patent_id": "10-2024-7042990", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시내용은 일반적으로 사용자 인터페이스들에 관한 것으로, 더 상세하게는, 증강 및 가상 현실에서 사용되 는 사용자 인터페이스들에 관한 것이다."}
{"patent_id": "10-2024-7042990", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "머리 착용형 디바이스는, 머리 착용형 디바이스의 사용자가 그를 통해 주변 환경을 볼 수 있는 투명 또는 반투 명 디스플레이로 구현될 수 있다. 이러한 디바이스들은 사용자가 주변 환경을 보기 위해, 또한 주변 환경의 일 부로서 나타나고/나타나거나 그 위에 오버레이되도록 디스플레이를 위해 생성되는 객체들(예를 들어, 가상 객체 들, 예컨대 2D 또는 3D 그래픽 모델, 이미지들, 비디오, 텍스트 등의 렌더링)을 보기 위해, 투명 또는 반투명 디스플레이를 통해 볼 수 있게 한다. 이것은 전형적으로 \"증강 현실(augmented reality)\" 또는 \"AR\"이라고 지 칭된다. 머리 착용형 디바이스는 추가적으로 사용자의 시야를 완전히 가리고 사용자가 이동할 수 있거나 이동 될 수 있는 가상 환경을 디스플레이할 수 있다. 이것은 전형적으로 \"가상 현실\" 또는 \"VR\"이라고 지칭된다. 본 명세서에서 사용되는 바와 같이, AR이라는 용어는, 문맥이 달리 지시하지 않는 한, 전통적으로 이해되는 바 와 같은 증강 현실 및 가상 현실 중 어느 하나 또는 둘 다를 지칭한다. 머리 착용형 디바이스의 사용자는 다양한 작업을 수행하거나 오락 활동에 참여하기 위해 컴퓨터 소프트웨어 애 플리케이션에 액세스하고 이를 이용할 수 있다. 태스크들을 수행하는 것 또는 엔터테인먼트 활동에 참여하는 것은 텍스트의 입력을 포함할 수 있다. 텍스트를 입력하기 위해, 사용자는 머리 착용형 디바이스에 의해 제공 되는 텍스트 입력 사용자 인터페이스와 상호작용한다."}
{"patent_id": "10-2024-7042990", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "사용자 착용 AR 디바이스들과 같은 AR 시스템들은 이용가능한 사용자 입력 모달리티들에 관한 경우에 제한된다. 모바일 폰들과 같은 다른 모바일 디바이스들과 비교하여, AR 시스템의 사용자가 사용자 의도를 표시하고 액션 또는 애플리케이션을 인보크하는 것이 더 복잡하다. 모바일 폰을 사용할 때, 사용자는 홈 스크린으로 가서 특 정 아이콘을 탭하여 애플리케이션을 시작할 수 있다. 그러나, 터치스크린 또는 키보드와 같은 물리적 입력 디 바이스의 부족으로 인해, 그러한 상호작용들은 AR 시스템 상에서 쉽게 수행되지 않는다. 전형적으로, 사용자들 은 제한된 수의 하드웨어 버튼들을 누르거나 작은 터치패드를 사용함으로써 그들의 의도를 표시할 수 있다. 따 라서, 사용자 입력을 통해 그들의 의도를 표시하기 위해 사용자에 의해 활용될 수 있는 더 큰 범위의 입력들을 허용하는 입력 모달리티를 갖는 것이 바람직할 것이다. 일부 예들에 따르면, AR 시스템들과 함께 활용될 수 있는 입력 모달리티는 가상 객체들의 직접 조작(Direct Manipulation of Virtual Object)(DMVO)과 결합된 핸드-트래킹이며, 여기서 사용자는 2D 또는 3D 렌더링을 갖 는 AR 오버레이에서 사용자에게 디스플레이되는 사용자 인터페이스를 제공받는다. 렌더링은 2D 또는 3D의 그래 픽 모델의 것으로, 여기서 모델에 위치한 가상 객체들은 사용자 인터페이스의 상호작용 요소들에 대응한다. 이 러한 방식으로, 사용자는 AR 시스템을 착용하고 있는 동안 실세계 장면의 사용자의 시야 내의 오버레이 내의 객 체들로서 가상 객체들을 인지하거나, AR 시스템을 착용하고 있는 동안 사용자가 보는 가상 세계 내의 객체들로 서 가상 객체들을 인지한다. 사용자가 가상 객체들을 조작할 수 있게 하기 위해, AR 시스템은 사용자의 손들을 검출하고 그들의 움직임, 위치, 및/또는 포지션을 추적하여 가상 객체들과의 사용자의 상호작용들을 결정한다. 추가적인 예들에서, DMVO를 수반하지 않는 제스처들은 사용자 착용 AR 시스템들과 같은 AR 시스템들과 함께 사 용하기에 적합한 다른 입력 모달리티를 제공한다. 제스처들은 사용자가 AR 시스템을 착용하고 있는 동안 사용 자의 신체의 부분들이 AR 시스템에 의해 검출가능한 동안 사용자의 신체의 그러한 부분들을 이동시키고 포지셔 닝하는 사용자에 의해 이루어진다. 사용자의 신체의 검출가능한 부분들은 사용자의 상체, 팔들, 손들, 및 손가 락들의 부분들을 포함할 수 있다. 제스처의 컴포넌트들은 사용자의 팔들 및 손들의 움직임, 공간에서의 사용자 의 팔들 및 손들의 위치, 및 사용자가 그들의 상체, 팔들, 손들, 및 손가락들을 유지하고 있는 포지션들을 포함 할 수 있다. 제스처들은 사용자가 AR 경험으로부터 그들의 포커스를 벗어나게 하지 않고 AR 경험 동안 AR 시스 템에 사용자 입력들을 제공하는 방식을 제공하기 때문에 사용자에게 AR 경험을 제공하는 데 유용하다. 예로서, 하나의 기계에 대한 동작 매뉴얼인 AR 경험에서, 사용자는 AR 시스템의 렌즈들을 통해 실세계 장면에서 하나의 기계를 동시에 보고, 기계의 실세계 장면 뷰 상에서 AR 오버레이를 보고, AR 시스템에 사용자 입력들을 제공할 수 있다. 핸드-트래킹된 DMVO 및 제스처 입력 모달리티들 둘 다를 조합함으로써, 개선된 텍스트 입력 사용자 인터페이스 가 AR 시스템의 사용자에게 제공된다. 일부 예들에서, 사용자는 가상 키보드를 열기 위한 제스처를 행한다. 가상 키보드는 사용자가 왼손과 같은 텍스트 입력 손을 사용하여 조작하는 가상 키들을 포함한다. AR 시스템은 DMVO 방법론들을 사용하여 복수의 가상 키들 중 하나 이상의 선택된 가상 키들의 사용자의 선택을 결정하고, 하 나 이상의 선택된 가상 키들에 기초하여 입력된 텍스트 데이터를 생성한다. AR 시스템은 AR 시스템의 디스플레 이를 사용하여 입력된 텍스트 데이터를 사용자에게 제공한다. 추가적인 예들에서, 사용자에게는 사용자가 그들의 텍스트 입력 손을 사용하여 조향하는 무한 광선 커서 (infinite ray cursor)가 제공된다. 사용자는 무한 광선 커서를 하나 이상의 가상 키와 교차시킴으로써 가상 키보드의 하나 이상의 가상 키를 선택하도록 무한 광선 커서를 조향한다."}
{"patent_id": "10-2024-7042990", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "다른 기술적 특징들은 다음의 도면들, 설명들, 및 청구항들로부터 본 기술분야의 통상의 기술자에게 용이하게 명백할 수 있다. 도 1은 일부 예들에 따른, 머리 착용형 디바이스(예를 들어, 도 1의 안경)로 구성된 AR 시스템의 사시도이 다. 안경은 임의의 적합한 형상 기억 합금을 포함하는 플라스틱 또는 금속과 같은 임의의 적합한 재료로 제조된 프레임을 포함할 수 있다. 하나 이상의 예에서, 프레임은 브리지에 의해 연결된 제1 또 는 좌측 광학 요소 홀더(예를 들어, 디스플레이 또는 렌즈 홀더) 및 제2 또는 우측 광학 요소 홀더를 포함한다. 제1 또는 좌측 광학 요소 및 제2 또는 우측 광학 요소는 각각의 좌측 광학 요소 홀더 및 우측 광학 요소 홀더 내에 제공될 수 있다. 우측 광학 요소 및 좌측 광학 요소는 렌즈, 디스플레이, 디스플레이 어셈블리, 또는 전술한 것의 조합일 수 있다. 임의의 적합한 디스플레이 어셈블리 가 안경에 제공될 수 있다. 프레임은 좌측 암(arm) 또는 템플 피스(temple piece) 및 우측 암 또는 템플 피스를 추가로 포 함한다. 일부 예들에서, 프레임은 단일체 또는 일체형 구성을 갖도록 단일 재료 피스로 형성될 수 있다. 안경은 컴퓨터와 같은 컴퓨팅 디바이스를 포함할 수 있으며, 이는 프레임에 의해 운반되도록 임 의의 적합한 타입일 수 있고, 하나 이상의 예에서, 템플 피스 또는 템플 피스 중 하나에 부분적으로 배치되도록 적합한 크기 및 형상일 수 있다. 컴퓨터는 메모리, 무선 통신 회로부, 및 전원을 갖는 하나 이상의 프로세서를 포함할 수 있다. 이하에서 논의되는 바와 같이, 컴퓨터는 저전력 회로부, 고속 회로부, 및 디스플레이 프로세서를 포함한다. 다양한 다른 예들은 이러한 요소들을 상이한 구성들로 포함하거 나 상이한 방식들로 함께 통합될 수 있다. 컴퓨터의 양태들의 추가적인 세부사항들은 아래에 논의되는 데 이터 프로세서에 의해 예시되는 바와 같이 구현될 수 있다. 컴퓨터는 배터리 또는 다른 적절한 휴대용 전력 공급부를 추가로 포함한다. 일부 예들에서, 배터리 는 좌측 템플 피스에 배치되고, 우측 템플 피스에 배치된 컴퓨터에 전기적으로 결합된다. 안경은 배터리를 충전하기에 적합한 커넥터 또는 포트(도시되지 않음), 무선 수신기, 송신기 또는 송 수신기(도시되지 않음), 또는 이러한 디바이스들의 조합을 포함할 수 있다. 안경은 제1 또는 좌측 카메라 및 제2 또는 우측 카메라를 포함한다. 2개의 카메라가 도시되어 있지만, 다른 예들은 단일 또는 추가(즉, 2개보다 많은) 카메라의 사용을 고려한다. 하나 이상의 예에서, 안경 은 좌측 카메라 및 우측 카메라에 더하여 임의의 수의 입력 센서들 또는 다른 입력/출력 디바이 스들을 포함한다. 이러한 센서들 또는 입력/출력 디바이스들은 생체인식 센서들, 위치 센서들, 모션 센서들 등 을 추가적으로 포함할 수 있다. 일부 예들에서, 좌측 카메라 및 우측 카메라는 실세계 장면으로부터 3D 정보를 추출하기 위해 안경 에 의해 사용하기 위한 비디오 프레임 데이터를 제공한다. 안경은 또한 좌측 템플 피스 및 우측 템플 피스 중 하나 또는 둘 다에 장착되거나 그와 통합된 터치패드를 포함할 수 있다. 터치패드는 일부 예들에서 일반적으로 사용자의 관자놀이에 대략 평행 하게, 대체로 수직으로 배열된다. 본 명세서에서 사용되는 바와 같이, 대체로 수직으로 정렬된다는 것은 터치 패드가 수평보다 더 수직이지만, 잠재적으로 그보다 더 수직이라는 것을 의미한다. 추가적인 사용자 입력은 예 시된 예들에서 좌측 광학 요소 홀더 및 우측 광학 요소 홀더의 외부 상부 에지들 상에 제공되는 하나 이상의 버튼에 의해 제공될 수 있다. 하나 이상의 터치패드 및 버튼은 안경이 안경 의 사용자로부터 입력을 수신할 수 있는 수단을 제공한다. 도 2는 사용자의 관점에서 안경을 도시한다. 명확성을 위해, 도 1에 도시된 다수의 요소들은 생략되었다. 도 1에 설명된 바와 같이, 도 2에 도시된 안경은 좌측 광학 요소 홀더 및 우측 광학 요소 홀더 내에 각각 고정된 좌측 광학 요소 및 우측 광학 요소를 포함한다. 안경은 우측 프로젝터 및 우측 근안 디스플레이를 포함하는 전방(forward) 광학 어셈블리, 및 좌측 프로젝터 및 좌측 근안 디스플레이를 포함하는 전방 광학 어셈블리를 포함한다. 일부 예들에서, 근안 디스플레이들(near eye displays)은 도파관들이다. 도파관들은 반사 또는 회절 구조물들 (예를 들어, 격자들, 및/또는 거울들, 렌즈들, 또는 프리즘들과 같은 광학 요소들)을 포함한다. 프로젝터(20 4)에 의해 방출된 광은 근안 디스플레이의 도파관의 회절 구조물들을 만나고, 이는 사용자가 보는 실 세계 장면의 뷰를 오버레이하는 이미지를 우측 광학 요소 상에 또는 그 안에 제공하기 위해 사용자의 우측 눈을 향해 광을 지향시킨다. 유사하게, 프로젝터에 의해 방출된 광은 근안 디스플레이의 도파 관의 회절 구조물들을 만나고, 이는 사용자가 보는 실세계 장면의 뷰를 오버레이하는 이미지를 좌측 광학 요소 상에 또는 좌측 광학 요소 내에 제공하기 위해 사용자의 좌측 눈을 향해 광을 지향시킨다. GPU, 전 방 광학 어셈블리, 좌측 광학 요소, 및 우측 광학 요소의 조합은 안경의 광학 엔진을 제공 한다. 안경은 안경의 사용자에게 사용자 인터페이스의 디스플레이를 제공하는 것을 포함하여 사용자 의 실세계 장면 뷰의 오버레이를 생성하기 위해 광학 엔진을 사용한다. 그러나, 사용자의 시야에서 사용자에게 이미지를 디스플레이하기 위해 다른 디스플레이 기술들 또는 구성들이 광학 엔진 내에서 활용될 수 있다는 것이 이해될 것이다. 예를 들어, 프로젝터 및 도파관 대신에, LCD,LED 또는 다른 디스플레이 패널 또는 표면이 제공될 수 있다. 사용 시에, 안경의 사용자는 근안 디스플레이들 상에 정보, 콘텐츠 및 다양한 사용자 인터페이스들을 제시 받을 것이다. 본 명세서에서 더 상세히 설명되는 바와 같이, 사용자는 이어서 터치패드 및/또는 버튼들 , 연관된 디바이스(예를 들어, 도 8에 예시된 클라이언트 디바이스) 상의 음성 입력들 또는 터치 입 력들, 및/또는 안경에 의해 검출된 손 움직임들, 포지션들, 및 위치들을 사용하여 안경과 상호작용할 수 있다. 도 3은 머신으로 하여금 본 명세서에서 논의된 방법론들 중 임의의 하나 이상을 수행하게 하기 위한 명령 어들(예를 들어, 소프트웨어, 프로그램, 애플리케이션, 애플릿, 앱, 또는 다른 실행가능 코드)이 실행될 수 있는 (컴퓨팅 장치와 같은) 머신의 도식적 표현이다. 머신은 도 1의 안경의 컴퓨터로 서 활용될 수 있다. 예를 들어, 명령어들은 머신으로 하여금 본 명세서에 설명된 방법들 중 임의의 하나 이상을 실행하게 할 수 있다. 명령어들은 일반적인 비-프로그래밍된 머신을 설명되고 예시된 기능들을 설명된 방식으로 수행하도록 프로그래밍된 특정 머신으로 변환한다. 머신은 독립형 디바이 스로서 동작할 수 있거나 다른 머신들에 결합(예를 들어, 네트워킹)될 수 있다. 네트워킹된 배치에서, 머신 은 서버-클라이언트 네트워크 환경에서 서버 머신 또는 클라이언트 머신의 자격으로, 또는 피어-투-피어 (또는 분산형) 네트워크 환경에서 피어 머신으로서 동작할 수 있다. 머신은 서버 컴퓨터, 클라이언트 컴 퓨터, 개인용 컴퓨터(PC), 태블릿 컴퓨터, 랩톱 컴퓨터, 넷북, 셋톱 박스(STB), PDA, 엔터테인먼트 미디어 시스 템, 셀룰러 전화, 스마트 폰, 모바일 디바이스, 머리 착용형 디바이스(예를 들어, 스마트 시계), 스마트 홈 디 바이스(예를 들어, 스마트 어플라이언스), 다른 스마트 디바이스들, 웹 어플라이언스, 네트워크 라우터, 네트워 크 스위치, 네트워크 브리지, 또는 머신에 의해 취해질 액션들을 특정하는 명령어들을 순차적으로 또 는 다른 방식으로 실행할 수 있는 임의의 머신을 포함할 수 있지만, 이에 제한되지 않는다. 또한, 단일 머신 이 예시되어 있지만, \"머신\"이라는 용어는 또한 본 명세서에서 논의된 방법론들 중 임의의 하나 이상을 수 행하기 위해 명령어들을 개별적으로 또는 공동으로 실행하는 머신들의 컬렉션을 포함하는 것으로 간주될 수 있다. 머신은 버스를 통해 서로 통신하도록 구성될 수 있는 프로세서들, 메모리, 및 I/O 컴포넌 트들을 포함할 수 있다. 일부 예들에서, 프로세서들(예를 들어, CPU(Central Processing Unit), RISC(Reduced Instruction Set Computing) 프로세서, CISC(Complex Instruction Set Computing) 프로세서, GPU(Graphics Processing Unit), DSP(Digital Signal Processor), ASIC, RFIC(Radio-Frequency Integrated Circuit), 다른 프로세서, 또는 이들의 임의의 적합한 조합)은, 예를 들어, 명령어들을 실행하는 프로세서 및 프로세서를 포함할 수 있다. 용어 \"프로세서\"는 명령어들을 동시에 실행할 수 있는 2개 이상의 독립적인 프로세서(때때로 \"코어들\"이라고 지칭됨)를 포함할 수 있는 멀티-코어 프로세서들을 포함하도록 의도 된다. 도 3은 다수의 프로세서들을 도시하지만, 머신은 단일 코어를 갖는 단일 프로세서, 다수의 코 어들을 갖는 단일 프로세서(예를 들어, 멀티-코어 프로세서), 단일 코어를 갖는 다수의 프로세서들, 다수의 코 어들을 갖는 다수의 프로세서들, 또는 이들의 임의의 조합을 포함할 수 있다. 메모리는 메인 메모리, 정적 메모리, 및 저장 유닛을 포함하며, 이들 둘 다는 버스를 통해 프로세서들에 액세스가능하다. 메인 메모리, 정적 메모리, 및 저장 유닛은 본 명세 서에 설명된 방법론들 또는 기능들 중 임의의 하나 이상을 구현하는 명령어들을 저장한다. 명령어들(31 0)은 또한, 머신에 의한 그의 실행 동안, 완전히 또는 부분적으로, 메인 메모리 내에, 정적 메모리 내에, 저장 유닛 내의 머신 판독가능 매체 내에, 프로세서들 중 하나 이상 내에(예를 들 어, 프로세서의 캐시 메모리 내에), 또는 이들의 임의의 적합한 조합으로 상주할 수 있다. I/O 컴포넌트들은 입력을 수신하고, 출력을 제공하고, 출력을 생성하고, 정보를 송신하고, 정보를 교환하 고, 측정들을 캡처하는 등을 위한 매우 다양한 컴포넌트들을 포함할 수 있다. 특정 머신에 포함되는 특정 I/O 컴포넌트들은 머신의 타입에 의존할 것이다. 예를 들어, 모바일 폰들과 같은 휴대용 머신들은 터치 입력 디바이스 또는 다른 그러한 입력 메커니즘들을 포함할 수 있는 반면, 헤드리스 서버 머신은 그러한 터치 입력 디바이스를 포함하지 않을 가능성이 있을 것이다. I/O 컴포넌트들은 도 3에 도시되지 않은 많은 다른 컴 포넌트들을 포함할 수 있다는 것을 이해할 것이다. 다양한 예들에서, I/O 컴포넌트들은 출력 컴포넌트들 및 입력 컴포넌트들을 포함할 수 있다. 출력 컴포넌트들은 시각적 컴포넌트들(예를 들어, 플 라즈마 디스플레이 패널(PDP), 발광 다이오드(LED) 디스플레이, 액정 디스플레이(LCD), 프로젝터, 또는 음극선 관(CRT)과 같은 디스플레이), 음향 컴포넌트들(예를 들어, 스피커들), 햅틱 컴포넌트들(예를 들어, 진동 모터, 저항 메커니즘들), 다른 신호 생성기들 등을 포함할 수 있다. 입력 컴포넌트들은 영숫자 입력 컴포넌트들(예를 들어, 키보드, 영숫자 입력을 수신하도록 구성된 터치 스크린, 포토-광학 키보드, 또는 다른 영숫자 입력 컴포넌트들), 포인트 기반 입력 컴포넌트들(예를 들어, 마우스, 터치패드, 트랙볼, 조이스틱, 모션 센서, 또는 다른 포인팅 기구), 촉각 입력 컴포넌트들(예를 들어, 물리적 버튼, 터치들 또는 터치 제스처들의 위치 및/또는 힘을 제공하는 터치 스크린, 또는 다른 촉각 입력 컴포넌트들), 오디오 입력 컴포넌트들(예를 들어, 마이크로폰) 등을 포함할 수 있다. 추가 예들에서, I/O 컴포넌트들은, 광범위한 다른 컴포넌트들 중에서도, 바이오메트릭 컴포넌트들, 모션 컴포넌트들, 환경 컴포넌트들, 또는 포지션 컴포넌트들을 포함할 수 있다. 예를 들어, 바 이오메트릭 컴포넌트들은 표현들(예를 들어, 손 표현들, 얼굴 표정들, 음성 표현들, 신체 제스처들, 또는 눈 추적)을 검출하고, 생체신호들(예를 들어, 혈압, 심박수, 체온, 땀, 또는 뇌파들)을 측정하고, 사람을 식별 (예를 들어, 음성 식별, 망막 식별, 얼굴 식별, 지문 식별, 또는 뇌파계 기반 식별)하고, 그와 유사한 것을 하 는 컴포넌트들을 포함한다. 모션 컴포넌트들은 관성 측정 유닛(IMU)들, 가속도 센서 컴포넌트들(예를 들 어, 가속도계), 중력 센서 컴포넌트들, 회전 센서 컴포넌트들(예를 들어, 자이로스코프) 등을 포함할 수 있다. 환경 컴포넌트들은, 예를 들어, 조명 센서 컴포넌트들(예를 들어, 광도계), 온도 센서 컴포넌트들(예를 들 어, 주변 온도를 검출하는 하나 이상의 온도계), 습도 센서 컴포넌트들, 압력 센서 컴포넌트들(예를 들어, 기압 계), 음향 센서 컴포넌트들(예를 들어, 배경 잡음을 검출하는 하나 이상의 마이크로폰), 근접 센서 컴포넌트들 (예를 들어, 인근 객체들을 검출하는 적외선 센서들), 가스 센서들(예를 들어, 안전을 위해 유해성 가스들의 농 도들을 검출하거나 대기 내의 오염물질들을 측정하기 위한 가스 검출 센서들), 또는 주변 물리적 환경과 연관된 표시들, 측정들, 또는 신호들을 제공할 수 있는 다른 컴포넌트들을 포함한다. 포지션 컴포넌트들은 위치 센서 컴포넌트들(예를 들어, GPS 수신기 컴포넌트), 고도 센서 컴포넌트들(예를 들어, 고도계들 또는 고도가 도 출될 수 있는 기압을 검출하는 기압계들), 배향 센서 컴포넌트들(예를 들어, 자력계들) 및 그와 유사한 것을 포 함한다. 통신은 매우 다양한 기술들을 사용하여 구현될 수 있다. I/O 컴포넌트들은 머신을 결합 및 결 합을 통해 각각 네트워크 또는 디바이스들에 결합하도록 동작가능한 통신 컴포넌트들을 추 가로 포함한다. 예를 들어, 통신 컴포넌트들은 네트워크 인터페이스 컴포넌트 또는 네트워크와 인터 페이스하기 위한 다른 적절한 디바이스를 포함할 수 있다. 추가 예들에서, 통신 컴포넌트들은 유선 통신 컴포넌트들, 무선 통신 컴포넌트들, 셀룰러 통신 컴포넌트들, 근접장 통신(Near Field Communication)(NFC) 컴 포넌트들, Bluetooth® 컴포넌트들(예를 들어, Bluetooth® Low Energy), Wi-Fi® 컴포넌트들, 및 다른 모달리 티들을 통해 통신을 제공하기 위한 다른 통신 컴포넌트들을 포함할 수 있다. 디바이스들은 다른 머신 또 는 매우 다양한 주변 디바이스들 중 임의의 것(예를 들어, USB를 통해 결합된 주변 디바이스)일 수 있다. 더욱이, 통신 컴포넌트들은 식별자들을 검출할 수 있거나, 식별자들을 검출하도록 동작가능한 컴포넌트들 을 포함할 수 있다. 예를 들어, 통신 컴포넌트들은 RFID(Radio Frequency Identification) 태그 판독기 컴포넌트들, NFC 스마트 태그 검출 컴포넌트들, 광학 판독기 컴포넌트들(예를 들어, UPC(Universal Product Code) 바코드와 같은 1차원 바코드들, QR(Quick Response) 코드와 같은 다차원 바코드들, Aztec 코드, Data Matrix, Dataglyph, MaxiCode, PDF417, Ultra Code, UCC RSS-2D 바코드, 및 다른 광학 코드들을 검출하기 위한 광학 센서), 또는 음향 검출 컴포넌트들(예를 들어, 태깅된 오디오 신호들을 식별하기 위한 마이크로폰들)을 포 함할 수 있다. 또한, 인터넷 프로토콜(IP) 지오로케이션(geolocation)을 통한 위치, Wi-Fi® 신호 삼각측량을 통한 위치, 특정 위치를 나타낼 수 있는 NFC 비컨 신호 검출을 통한 위치 등과 같은 다양한 정보가 통신 컴포넌 트들을 통해 도출될 수 있다. 다양한 메모리들(예를 들어, 메모리, 메인 메모리, 정적 메모리, 및/또는 프로세서들의 메 모리) 및/또는 저장 유닛은 본 명세서에 설명된 방법론들 또는 기능들 중 임의의 하나 이상을 구현하거나 그에 의해 사용되는 명령어들 및 데이터 구조들(예를 들어, 소프트웨어)의 하나 이상의 세트를 저장할 수 있다. 이러한 명령어들(예를 들어, 명령어들)은, 프로세서들에 의해 실행될 때, 다양한 동작들이 개시된 예 들을 구현하게 한다. 명령어들은 송신 매체를 사용하여, 네트워크 인터페이스 디바이스(예를 들어, 통신 컴포넌트들에 포 함된 네트워크 인터페이스 컴포넌트)를 통해 그리고 다수의 잘 알려진 전송 프로토콜들(예를 들어, 하이퍼텍스 트 전송 프로토콜(HTTP)) 중 어느 하나를 사용하여 네트워크를 통해 송신 또는 수신될 수 있다. 유사하게, 명령어들은 디바이스들에 대한 커플링(예를 들어, 피어-투-피어 커플링)을 통해 송신 매체를 사용하여 송신 또는 수신될 수 있다.도 4a는 안경과 같은 AR 시스템의 제스처 기반 키보드 프로세스의 시퀀스 다이어그램이고, 도 4b는 텍스트 입력 시작/정지 제스처의 도시이고, 도 4c는 일부 예들에 따른 가상 키보드 사용자 인터페이스 의 도시이다. 제스처 기반 키보드 프로세스 동안, AR 시스템은 제스처 텍스트 입력 애플리케이션 을 활용하여 제스처 인식 방법론들 및 DMVO 방법론들을 이용하여 가상 키보드 사용자 인터페이스를 구현한다. 제스처 기반 키보드 프로세스 동안, 동작에서, AR 시스템의 하나 이상의 카메라는 AR 시스템의 사용자의 관점에서 실세계 장면의 실세계 장면 비디오 프레임 데이터를 생성한다. 하나 이상의 카메라 는 실세계 장면 비디오 프레임 데이터를 추적 서비스에 전달한다. 실세계 장면 비디오 프레임 데이터에는 사용자의 상체, 팔들, 손들, 및 손가락들의 부분들을 포함하는 사용자의 신체의 검출가능한 부 분들의 추적 비디오 프레임 데이터가 포함된다. 추적 비디오 프레임 데이터는 사용자가 가상 키보드 사용자 인 터페이스와 상호작용하기 위해 제스처를 취하거나 그들의 손들 및 손가락들을 움직일 때의 사용자의 상체, 팔들 및 손들의 부분들의 움직임의 비디오 프레임 데이터; 사용자가 가상 키보드 사용자 인터페이스와 상 호작용하기 위해 제스처를 취하거나 그들의 손들 및 손가락들을 이동시킬 때의 공간 내의 사용자의 팔들 및 손 들의 위치들의 비디오 프레임 데이터; 및 사용자가 가상 키보드 사용자 인터페이스와 상호작용하기 위해 제스처를 취하거나 그들의 손들 및 손가락들을 이동시킬 때 사용자가 그들의 상체, 팔들, 손들 및 손가락들을 유지하는 포지션들의 비디오 프레임 데이터를 포함한다. 동작에서, 추적 서비스는 실세계 장면에서 사용자의 상체, 팔들, 및 손들의 부분들 상의 랜드마크들 을 스캐닝하고, 검출하고, 추적한다. 일부 예들에서, 추적 서비스는 하나 이상의 카메라로부터 실세 계 장면 비디오 프레임 데이터를 수신하고, 실세계 장면 비디오 프레임 데이터에 포함된 추적 비디오 프레임 데이터로부터 사용자의 상체, 팔들, 및 손들의 특징들을 추출한다. 추적 서비스는 추출된 특징들 에 기초하여 현재 추적 데이터를 생성한다. 현재 추적 데이터는 랜드마크 식별, 실세계 장면에서의 위치, 및 사용자의 상체, 팔들, 및 손들과 연관된 하나 이상의 랜드마크의 카테고리화 정보를 포함하는 랜드마 크 데이터를 포함한다. 추적 서비스는 현재 추적 데이터를 제스처 인식 서비스에 전달한다. 또한, 추적 서비스는 현재 추적 데이터를 제스처 텍스트 입력 애플리케이션과 같은 AR 시스템 상에서 실행되고 있는 애플리케이션에 이용가능하게 한다. 동작에서, 제스처 인식 서비스는 추적 서비스로부터 현재 추적 데이터를 수신하고 현재 추 적 데이터에 기초하여 현재 검출된 제스처 데이터를 생성한다. 일부 예들에서, 제스처 인식 서비스 는 현재 추적 데이터에 포함된 랜드마크들의 랜드마크 데이터에 기초하여 사용자의 상체, 팔들, 손들, 및 손가락들의 하나 이상의 현재 골격 모델(current skeletal models)을 생성한다. 제스처 인식 서비스 는 하나 이상의 현재 골격 모델을 이전에 생성된 제스처 골격 모델들과 비교한다. 제스처 인식 서비스 는 하나 이상의 현재 골격 모델과 제스처 골격 모델들의 비교에 기초하여 검출된 제스처를 결정하고, 검출 된 제스처에 기초하여 현재 검출된 제스처 데이터를 생성한다. 추가적인 예들에서, 제스처 인식 서비스 는 랜드마크 데이터에 기초하여 하나 이상의 현재 골격 모델을 생성한다. 제스처 인식 서비스는 인 공 지능 방법론들을 사용하여 현재 골격 모델들을 카테고리화하는 것 및 머신 러닝 방법론들을 사용하여 이전에 생성된 제스처 모델에 기초하여 검출된 제스처를 결정한다. 제스처 인식 서비스는 검출된 제스처에 기초 하여 현재 검출된 제스처 데이터를 생성한다. 일부 예들에서, 하나 이상의 카메라, 추적 서비스, 및 제스처 인식 서비스는 현재 검출된 제스 처 데이터 및 현재 검출된 제스처 데이터가 AR 시스템에서 실행되는 애플리케이션에 대한 요구 시에 이용가능하도록 연속적으로 동작한다. 동작에서, 제스처 텍스트 입력 애플리케이션은 제스처 인식 서비스로부터 수신된 현재 검출된 제스처 데이터에 기초하여, 텍스트 입력 시작/정지 제스처와 같은 텍스트 입력 시작 제스처를 검출한 다. 텍스트 입력 시작 제스처는 AR 시스템에 의해 사용자에게 제공되는 AR 경험의 텍스트 장면 객체로의 텍스트 입력을 시작하라는 사용자에 의한 명령이다. 동작에서, 텍스트 입력 시작 제스처를 검출하는 것에 응답하여, 제스처 텍스트 입력 애플리케이션은 가상 키보드를 포함하는 가상 키보드 사용자 인터페이스를 생성한다. 가상 키보드는 가상 키보 드의 상호작용 가상 키들을 구성하는 복수의 가상 객체를 포함한다. 가상 키들은 가상 키보드 사용자 인터페이스에 의해 점유되는 실세계 장면에서의 공간의 볼륨에 대응하는 사용자 인터페이스 기하학 적 모델 또는 볼륨에서의 각각의 위치들을 갖는 기하학적 가상 객체들이다. 예로서, 사용자 인터페이스 기하학적 모델의 폭(X) 및 높이(Y)는 AR 시스템의 사용자의 관점으로부터의 시야에 의해 정의되고, 깊이(Z)는 사용자 의 눈 포지션에서 원점을 갖는 100cm의 물리적 길이에 의해 정의된다. 가상 키보드는 사용자가 자신의 팔 을 부분적으로 뻗으면서 자신의 손으로 가상 키보드에 도달하는 것을 가능하게 하는 사용자의 눈 포지션에 대한 50cm의 깊이 위치를 사용자 인터페이스 기하학적 모델에서 할당받는다. 제스처 텍스트 입력 애플리케이션은 가상 키보드 사용자 인터페이스의 렌더링 데이터를 생성하 고 렌더링 데이터를 AR 시스템의 광학 엔진에 전달한다. 동작에서, 광학 엔진은 렌더링 데이터에 기초하여 AR 시스템의 디스플레이에서 사용자에게 가상 키보드 사용자 인터페이스를 제공한 다. 동작에서, 제스처 텍스트 입력 애플리케이션은 제스처 인식 서비스로부터 수신된 현재 검출된 제스처 데이터에 기초하여 사용자가 그들의 자유로운 손을 사용한 텍스트 입력 제스처와 같은 텍스트 입력 제스처의 유지(hold)를 검출한다. 예를 들어, 제스처 텍스트 입력 애플리케이션은 현재 검출 된 제스처 데이터에서 식별된 현재 검출된 제스처가 텍스트 입력 제스처와 동일하다고 결정한다. 사용자가 텍스트 입력 제스처를 유지하는 동안, 사용자는 단어와 같은 의도된 텍스트를 입력하기 위해 가 상 키들을 통과하도록 그들의 텍스트 입력 손을 연속적인 모션으로 이동시킨다. 연속적인 모션(45 4)을 행할 때, 사용자는 의도된 텍스트에 포함된 문자들을 나타내는 가상 키들뿐만 아니라 의도된 텍스트에 포 함되지 않은 문자들을 나타내는 추가적인 가상 키들을 통과할 것이다. 하나 이상의 카메라, 추적 서비스 , 및 제스처 인식 서비스가 연속적으로 동작함에 따라, 현재 검출된 제스처 데이터는 사용자가 텍스트 입력 제스처를 홀드하는 동안 생성된 연속 모션의 연속 모션 제스처 데이터를 포함한다. 동 작에서, 제스처 텍스트 입력 애플리케이션은 현재 검출된 제스처 데이터를 수신하고, 현재 검출 된 제스처 데이터에 포함된 연속 모션 제스처 데이터를 수집한다. 동작에서, 제스처 텍스트 입력 애플리케이션은 제스처 인식 서비스로부터 수신된 현재 검출된 제스처 데이터에 기초하여 사용자에 의한 텍스트 입력 제스처의 해제(release)를 검출한다. 예를 들 어, 제스처 텍스트 입력 애플리케이션은 현재 검출된 제스처 데이터에서 식별된 현재 검출된 제스처 가 사용자에 의해 그들의 자유로운 손을 사용하여 유지되고 있던 텍스트 입력 제스처가 아니라고 결 정한다. 동작에서, 제스처 텍스트 입력 애플리케이션은 연속 모션의 수집된 연속 모션 제스처 데이터에 기초하여 입력된 텍스트 데이터를 생성한다. 일부 예들에서, 제스처 텍스트 입력 애플리케이션은 수 집된 연속 모션 제스처 데이터를 인공 지능 방법론들, 및 머신 러닝 방법론들을 사용하여 이전에 생성된 연속 모션 제스처 모델을 사용하여 텍스트 데이터에 매핑한다. 제스처 텍스트 입력 애플리케이션은 매핑된 텍 스트 데이터에 기초하여 현재 검출된 제스처 데이터를 생성한다. 제스처 텍스트 입력 애플리케이션은 입력된 텍스트 데이터를 텍스트 장면 객체에 전달한다. 동 작에서, 텍스트 장면 객체는 입력된 텍스트 데이터를 AR 시스템의 디스플레이에서 사용자에게 제공한다. 동작에서, 제스처 텍스트 입력 애플리케이션은 제스처 인식 서비스로부터 수신된 현재 검출된 제스처 데이터에 기초하여, 텍스트 입력 시작/정지 제스처와 같은, 그러나 이에 제한되지 않는, 텍스 트 입력 종료 제스처를 검출하고, 제스처 텍스트 입력 애플리케이션은 가상 키보드 사용자 인터페이스 를 닫고 종료한다. 일부 예들에서, 텍스트 입력 종료 제스처는 위로 스와이프 제스처, 아래로 스와이프 제스처, 좌측으로 스와이프 제스처, 우측으로 스와이프 제스처, 주먹을 쥐는 것, \"정지 제스처\"에서 손을 들고 있는 것 등과 같은 임의의 제스처일 수 있다. 일부 예들에서, 제스처 텍스트 입력 애플리케이션은 제스처 텍스트 입력 애플리케이션이 동작에 서 사용자가 텍스트 입력 종료 제스처를 행하는 것을 검출할 때까지 루프를 실행한다. 루프는 동작 (사용자가 텍스트 입력 제스처를 행하고 유지하는 것을 검출함), 동작(연속적인 모션 제스처 데 이터를 수집함), 동작(사용자에 의한 텍스트 입력 제스처의 해제를 검출함), 및 동작(입력된 텍스트 데이터를 생성하고 입력된 텍스트 데이터를 텍스트 장면 객체에 전달함)을 포함한다. 이러한 방식으로, 사용자는 다수의 단어 또는 텍스트를 텍스트 장면 객체에 입력할 수 있다. 일부 예들에서, 동작 동안, 제스처 텍스트 입력 애플리케이션이 연속 모션 제스처 데이터를 수집할 때, 제스처 텍스트 입력 애플리케이션은 수집된 연속 모션 제스처 데이터의 부분적 세트에 기초하여 타이프어헤드(typeahead) 검색 모드에서 추정된 텍스트를 생성한다. 예를 들어, 사용자가 그들의 자유로운 손(45 8)으로 텍스트 입력 제스처를 유지하면서 그들의 텍스트 입력 손으로 연속적인 모션을 행할 때, 제스 처 텍스트 입력 애플리케이션은 동작에서 검출된 바와 같이 사용자가 텍스트 입력 제스처를 해 제하기 전에 연속적인 모션 제스처 데이터의 부분적 세트를 결정한다. 제스처 텍스트 입력 애플리케이션 은 인공 지능 방법론들, 및 머신 러닝 방법론들을 사용하여 이전에 생성된 연속적인 모션 제스처 모델을 사용하 여 연속적인 모션 제스처 데이터의 부분적 세트를 텍스트 데이터에 매핑한다. 제스처 텍스트 입력 애플리케이 션은 매핑된 텍스트 데이터에 기초하여 입력된 텍스트 데이터를 생성하고 입력된 텍스트 데이터(45 6)를 텍스트 장면 객체에 전달한다. 동작에서, 텍스트 장면 객체는 입력된 텍스트 데이터(45 6)를 AR 시스템의 디스플레이에서 사용자에게 제공한다. 사용자가 추정된 텍스트가 의도된 텍스트라고 결정하 면, 사용자는 텍스트 입력 제스처를 해제한다. 일부 예들에서, 가상 키보드 사용자 인터페이스는 AR 시스템의 사용자의 시야 내에서 AR 시스템을 사용하 는 사용자의 관점으로부터 고정된 깊이(z-거리)에 유지된다. 일부 예들에서, 가상 키보드는 \"취소\" 또는 \"나가기(exit)\" 가상 키와 같이, 가상 키보드를 닫고 제 스처-기반 키보드 프로세스를 종료하기 위해 사용자에 의해 선택가능한 가상 키를 포함한다. 일부 예들에서, 제스처 텍스트 입력 애플리케이션은 사용자에게 제공되는 AR 경험 동안 AR 시스템이 제공 을 위해 사용하는 애플리케이션이다. AR 시스템은 제스처 기반 키보드 프로세스를 사용하여, 사용자가 입 력된 텍스트 데이터를 AR 경험의 텍스트 장면 객체 내에 입력하기 위한 입력 모달리티를 제공한다. 일부 예들에서, AR 시스템의 제스처 텍스트 입력 애플리케이션은 다양한 API들 및 시스템 라이브러리들을 활용함으로써 제스처 인식 서비스 및 추적 서비스의 기능들을 수행한다. 도 5a는 안경과 같은 AR 시스템의 핸드-트래킹된 키보드 프로세스의 시퀀스 다이어그램이고, 도 5b는 텍스트 입력 시작/종료 제스처의 도시이고, 도 5c는 일부 예들에 따른 가상 키보드 사용자 인터페이스 의 도시이다. 핸드-트래킹된 키보드 프로세스 동안, AR 시스템은 핸드-트래킹 텍스트 입력 애플리케 이션을 위한 가상 키보드 사용자 인터페이스를 구현하기 위해 제스처 인식 방법론들 및 DMVO 방법론 들을 활용한다. 핸드-트래킹된 키보드 프로세스 동안, 동작에서, AR 시스템의 하나 이상의 카메라는 AR 시스템 의 사용자의 관점에서 실세계 장면의 실세계 장면 비디오 프레임 데이터를 생성한다. 하나 이상의 카메라 는 실세계 장면 비디오 프레임 데이터를 추적 서비스에 전달한다. 실세계 장면 비디오 프레임 데이터에는 사용자의 상체, 팔들, 손들, 및 손가락들의 부분들을 포함하는 사용자의 신체의 검출가능한 부 분들의 추적 비디오 프레임 데이터가 포함된다. 추적 비디오 프레임 데이터는 사용자가 가상 키보드 사용자 인 터페이스와 상호작용하기 위해 제스처를 취하거나 그들의 손들 및 손가락들을 움직일 때의 사용자의 상체, 팔들 및 손들의 부분들의 움직임의 비디오 프레임 데이터; 사용자가 가상 키보드 사용자 인터페이스와 상 호작용하기 위해 제스처를 취하거나 그들의 손들 및 손가락들을 움직일 때의 공간 내의 사용자의 팔들 및 손들 의 위치들의 비디오 프레임 데이터; 및 사용자가 가상 키보드 사용자 인터페이스와 상호작용하기 위해 제 스처를 취하거나 그들의 손들 및 손가락들을 움직일 때 사용자가 그들의 상체, 팔들, 손들 및 손가락들을 유지 하는 포지션들의 비디오 프레임 데이터를 포함한다. 동작에서, 추적 서비스는 실세계 장면에서 사용자의 상체, 팔들, 및 손들의 부분들 상의 랜드마크들 을 스캐닝하고, 검출하고, 추적한다. 일부 예들에서, 추적 서비스는 하나 이상의 카메라로부터 실세 계 장면 비디오 프레임 데이터를 수신하고, 실세계 장면 비디오 프레임 데이터에 포함된 추적 비디오 프레임 데이터로부터 사용자의 상체, 팔들, 및 손들의 특징들을 추출한다. 추적 서비스는 추출된 특징들 에 기초하여 현재 추적 데이터를 생성한다. 추적 데이터는 랜드마크 식별, 실세계 장면에서의 위치, 및 사용자의 상체, 팔들, 및 손들의 움직임과 연관된 하나 이상의 랜드마크를 식별하는 카테고리화 정보를 포함하 는 랜드마크 데이터를 포함한다. 추적 서비스는 현재 추적 데이터를 제스처 인식 서비스에 전 달한다. 또한, 추적 서비스는 현재 추적 데이터를 핸드-트래킹 텍스트 입력 애플리케이션과 같 은 AR 시스템 상에서 실행되고 있는 애플리케이션에 이용가능하게 한다. 동작에서, 제스처 인식 서비스는 추적 서비스로부터 현재 추적 데이터를 수신하고, 현재 추적 데이터에 기초하여 현재 검출된 제스처 데이터를 생성한다. 일부 예들에서, 제스처 인식 서비 스는 현재 추적 데이터에 포함된 랜드마크들의 랜드마크 데이터에 기초하여 사용자의 상체, 팔들, 손들, 및 손가락들의 하나 이상의 현재 골격 모델을 생성한다. 제스처 인식 서비스는 하나 이상의 현재 골 격 모델들을 이전에 생성된 제스처 골격 모델들과 비교한다. 제스처 인식 서비스는 하나 이상의 현재 골 격 모델들과 제스처 골격 모델들의 비교에 기초하여 검출된 제스처를 결정하고, 검출된 제스처에 기초하여 현재 검출된 제스처 데이터를 생성한다. 추가적인 예들에서, 제스처 인식 서비스는 랜드마크 데이터에 기 초하여 하나 이상의 현재 골격 모델을 생성한다. 제스처 인식 서비스는 인공 지능 방법론들을 사용하여 현재 골격 모델들을 카테고리화하는 것 및 머신 러닝 방법론들을 사용하여 이전에 생성된 제스처 모델에 기초하 여 검출된 제스처를 결정한다. 제스처 인식 서비스는 검출된 제스처에 기초하여 현재 검출된 제스처 데이 터를 생성한다. 일부 예들에서, 하나 이상의 카메라, 추적 서비스, 및 제스처 인식 서비스는 현재 검출된 제스 처 데이터 및 현재 추적 데이터가 AR 시스템에 의해 실행되는 임의의 애플리케이션에 대한 요구 시에 이용가능하도록 연속적으로 동작한다. AR 시스템에 의한 핸드-트래킹 텍스트 입력 애플리케이션의 실행 동안, 동작에서, 핸드-트래킹 텍스 트 입력 애플리케이션은 제스처 인식 서비스로부터 수신된 현재 검출된 제스처 데이터에 기초하 여, 텍스트 입력 시작/종료 제스처와 같은 텍스트 입력 시작 제스처를 검출한다. 텍스트 입력 시작 제스 처는 AR 시스템에 의해 사용자에게 제공되는 AR 경험의 텍스트 장면 객체로의 텍스트 입력을 시작하라는 사용자에 의한 명령이다. 텍스트 입력 제스처를 검출하는 것에 응답하여, 동작에서, 핸드-트래킹 텍스트 입력 애플리케이션은 가상 키보드를 포함하는 가상 키보드 사용자 인터페이스를 생성한다. 가상 키보드는 가상 키보 드의 상호작용 가상 키들을 구성하는 복수의 가상 객체를 포함한다. 가상 키들은 가상 키보드 사용자 인터페이스에 의해 점유되는 실세계 장면에서의 공간의 볼륨에 대응하는 사용자 인터페이스 기하학 적 모델 또는 볼륨에서의 각각의 위치들을 갖는 기하학적 가상 객체들이다. 예로서, 사용자 인터페이스 기하학 적 모델의 폭(X) 및 높이(Y)는 AR 시스템의 사용자의 관점으로부터의 시야에 의해 정의되고, 깊이(Z)는 사용자 의 눈 포지션에서 원점을 갖는 100cm의 물리적 길이에 의해 정의된다. 가상 키보드는 사용자가 자신의 팔 을 부분적으로 뻗으면서 자신의 손으로 가상 키보드에 도달하는 것을 가능하게 하는 사용자의 눈 포지션에 대한 50cm의 깊이 위치를 사용자 인터페이스 기하학적 모델에서 할당받는다. 동작에서, 핸드-트래킹 텍스트 입력 애플리케이션은 가상 키보드 사용자 인터페이스의 렌더링 데이터를 생성하고 렌더링 데이터를 AR 시스템의 광학 엔진에 전달한다. 동작에서, 광학 엔진은 렌더링 데이터에 기초하여 AR 시스템의 디스플레이에서 사용자에게 가상 키보드 사용자 인터 페이스를 제공한다. 동작에서, 핸드-트래킹 텍스트 입력 애플리케이션은 추적 서비스로부터 현재 추적 데이터 를 수신한다. 핸드-트래킹 텍스트 입력 애플리케이션은 현재 추적 데이터에 기초하여, 사용자의 텍 스트 입력 손과 연관된 랜드마크, 예를 들어, 사용자의 텍스트 입력 손의 집게손가락의 끝을 검출한 다. 핸드-트래킹 텍스트 입력 애플리케이션은 랜드마크에 기초하여 가상 키보드 사용자 인터페이스 에서 랜드마크 충돌기를 생성한다. 가상 키들로부터 가상 키를 선택하기 위해, 사용자는 가상 키보 드 사용자 인터페이스 내에서 랜드마크 충돌기를 이동시키기 위해 그들의 텍스트 입력 손을 이 동시킨다. 가상 키를 선택하지 않고 가상 키들 위에 랜드마크 충돌기를 이동시키기 위해, 사용자는 사용자 인터페이스 기하학적 모델에서 가상 키보드의 위치로부터 멀어지게 그들의 텍스트 입력 손을 후퇴시키고, 따라서 가상 키들을 클리어한다. 가상 키를 선택하기 위해, 사용자는 가상 키 위에 그들의 텍스트 입력 손을 포지셔닝시키고, 랜드마크 충돌기가 선택된 가상 키와 충돌할 때까지 가상 키를 \" 누르거나\" \"찌르기(poke)\" 위해 그들의 텍스트 입력 손을 뻗는다. 핸드-트래킹 텍스트 입력 애플리케이션 은 랜드마크 충돌기와 하나 이상의 선택된 가상 키들 사이의 충돌들을 검출함으로써 하나 이상의 선 택된 가상 키들에 대한 사용자의 선택을 결정한다. 동작에서, 핸드-트래킹 텍스트 입력 애플리케이션은 선택된 가상 키에 기초하여 입력된 텍스트 데이 터를 생성한다. 일부 예들에서, 가상 키들의 각각의 가상 키는 캐릭터와 연관된다. 핸드-트래킹 텍 스트 입력 애플리케이션은 연관된 캐릭터들을 입력된 텍스트 데이터로 변환한다. 핸드-트래킹 텍스트 입력 애플리케이션은 입력된 텍스트 데이터를 텍스트 장면 텍스트 장면 객체 에 전달한다. 동작에서, 텍스트 장면 객체는 입력된 텍스트 데이터를 AR 시스템의 디스플 레이에서 사용자에게 제공한다.동작에서, 핸드-트래킹 텍스트 입력 애플리케이션은 제스처 인식 서비스로부터 수신된 현재 검 출된 제스처 데이터에 기초하여, 텍스트 입력 시작/종료 제스처와 같은, 그러나 이에 제한되지 않는, 텍스트 입력 종료 제스처를 검출한다. 텍스트 입력 종료 제스처를 검출하는 것에 응답하여, 핸드-트래킹 텍스 트 입력 애플리케이션은 가상 키보드 사용자 인터페이스를 닫고 종료한다. 일부 예들에서, 텍스트 입력 종료 제스처는 위로 스와이프 제스처, 아래로 스와이프 제스처, 좌측으로 스와이프 제스처, 우측으로 스와 이프 제스처, 주먹을 쥐는 것, \"정지 제스처\"에서 손을 들고 있는 것 등과 같은 임의의 제스처일 수 있다. 일부 예들에서, 핸드-트래킹 텍스트 입력 애플리케이션은 동작에서 텍스트 입력 시작/종료 제스처 와 같은 텍스트 입력 종료 제스처가 검출될 때까지 루프를 실행한다. 루프는 동작(선택된 가상 키들을 결정함) 및 동작(입력된 텍스트 데이터를 생성하고 556을 텍스트 장면 객체에 전달 함)을 포함한다. 이러한 방식으로, 핸드-트래킹 텍스트 입력 애플리케이션은 사용자가 다수의 캐릭터를 텍스트 장면 객체에 입력할 수 있게 한다. 일부 예들에서, 가상 키보드는 \"취소\" 또는 \"나가기\" 가상 키와 같이, 가상 키보드를 닫고 핸드-트래 킹된 키보드 프로세스를 종료하기 위해 사용자에 의해 선택가능한 가상 키를 포함한다. 일부 예들에서, 하나 이상의 카메라, 추적 서비스, 및 제스처 인식 서비스는 AR 시스템에 의해 연속적으로 실행되어, AR 시스템에 의해 실행되고 있는 임의의 애플리케이션에 대한 요구 시 현재 검출된 제스 처 데이터 및 현재 추적 데이터가 이용가능하게 된다. 일부 예들에서, 가상 키보드 사용자 인터페이스는 AR 시스템의 사용자의 시야 내에서 AR 시스템을 사용하 는 사용자의 관점으로부터 고정된 깊이(z-거리)에 유지된다. 일부 예들에서, 핸드-트래킹 텍스트 입력 애플리케이션은 AR 시스템이 사용자에게 제공되는 AR 경험 동안 사용자에게 제공하는 애플리케이션이다. AR 시스템은 사용자가 AR 경험의 텍스트 장면 객체 내에 입력된 텍스트 데이터를 입력하기 위한 입력 모달리티를 제공하기 위해 핸드-트래킹된 키보드 프로세스를 사 용한다. 일부 예들에서, AR 시스템의 핸드-트래킹 텍스트 입력 애플리케이션은 다양한 API들 및 시스템 라이브러리 들을 활용함으로써 제스처 인식 서비스 및 추적 서비스의 기능들을 수행한다. 도 6a는 안경과 같은 AR 시스템의 핸드-트래킹된 키보드 프로세스의 시퀀스다이어그램이고, 도 6b는 텍스트 입력 시작/종료 제스처의 도시이고, 도 6c는 일부 예들에 따른 가상 키보드 사용자 인터페이스 의 도시이다. 핸드-트래킹된 키보드 프로세스 동안, AR 시스템은 핸드-트래킹 텍스트 입력 애플리케 이션에 대한 가상 키보드 사용자 인터페이스를 구현하기 위해 제스처 인식 방법론들 및 DMVO 방법론 들을 활용한다. 핸드-트래킹된 키보드 프로세스 동안, 동작에서, AR 시스템의 하나 이상의 카메라는 AR 시스템 의 사용자의 관점에서 실세계 장면의 실세계 장면 비디오 프레임 데이터를 생성한다. 하나 이상의 카메라 는 실세계 장면 비디오 프레임 데이터를 추적 서비스에 전달한다. 실세계 장면 비디오 프레임 데이터에는 사용자의 상체, 팔들, 손들, 및 손가락들의 부분들을 포함하는 사용자의 신체의 검출가능한 부 분들의 추적 비디오 프레임 데이터가 포함된다. 추적 비디오 프레임 데이터는 사용자가 가상 키보드 사용자 인 터페이스와 상호작용하기 위해 제스처를 취하거나 그들의 손들 및 손가락들을 움직일 때의 사용자의 상체, 팔들 및 손들의 부분들의 움직임의 비디오 프레임 데이터; 사용자가 가상 키보드 사용자 인터페이스와 상 호작용하기 위해 제스처를 취하거나 그들의 손들 및 손가락들을 이동시킬 때의 공간 내의 사용자의 팔들 및 손 들의 위치들의 비디오 프레임 데이터; 및 사용자가 가상 키보드 사용자 인터페이스와 상호작용하기 위해 제스처를 취하거나 그들의 손들 및 손가락들을 움직일 때 사용자가 그들의 상체, 팔들, 손들 및 손가락들을 유 지하는 포지션들의 비디오 프레임 데이터를 포함한다. 동작에서, 추적 서비스는 실세계 장면에서 사용자의 상체, 팔들, 및 손들의 부분들 상의 랜드마크들 을 스캐닝하고, 검출하고, 추적한다. 일부 예들에서, 추적 서비스는 하나 이상의 카메라로부터 실세 계 장면 비디오 프레임 데이터를 수신하고, 실세계 장면 비디오 프레임 데이터에 포함된 추적 비디오 프레임 데이터로부터 사용자의 상체, 팔들, 및 손들의 특징들을 추출한다. 추적 서비스는 추출된 특징들 에 기초하여 현재 추적 데이터를 생성한다. 추적 데이터는 랜드마크 식별, 실세계 장면에서의 위치, 및 사용자의 상체, 팔들, 및 손들의 움직임과 연관된 하나 이상의 랜드마크를 식별하는 카테고리화 정보를 포함하 는 랜드마크 데이터를 포함한다. 추적 서비스는 현재 추적 데이터를 제스처 인식 서비스에 전달한다. 또한, 추적 서비스는 현재 추적 데이터를 핸드-트래킹 텍스트 입력 애플리케이션과 같 은 AR 시스템 상에서 실행되고 있는 애플리케이션에 이용가능하게 한다. 동작에서, 제스처 인식 서비스는 추적 서비스로부터 현재 추적 데이터를 수신하고, 현재 추적 데이터에 기초하여 현재 검출된 제스처 데이터를 생성한다. 일부 예들에서, 제스처 인식 서비 스는 현재 추적 데이터에 포함된 랜드마크들의 랜드마크 데이터에 기초하여 사용자의 상체, 팔들, 손 들, 및 손가락들의 하나 이상의 현재 골격 모델을 생성한다. 제스처 인식 서비스는 하나 이상의 현재 골 격 모델을 이전에 생성된 제스처 골격 모델들과 비교한다. 제스처 인식 서비스는 하나 이상의 현재 골격 모델과 제스처 골격 모델들의 비교에 기초하여 검출된 제스처를 결정하고, 검출된 제스처에 기초하여 현재 검출 된 제스처 데이터를 생성한다. 추가적인 예들에서, 제스처 인식 서비스는 랜드마크 데이터에 기초하 여 하나 이상의 현재 골격 모델을 생성한다. 제스처 인식 서비스는 인공 지능 방법론들을 사용하여 현재 골격 모델들을 카테고리화하는 것 및 머신 러닝 방법론들을 사용하여 이전에 생성된 제스처 모델에 기초하여 검 출된 제스처를 결정한다. 제스처 인식 서비스는 검출된 제스처에 기초하여 현재 검출된 제스처 데이터 를 생성한다. 일부 예들에서, 하나 이상의 카메라, 추적 서비스, 및 제스처 인식 서비스는 현재 검출된 제스 처 데이터 및 현재 추적 데이터가 AR 시스템에 의해 실행되는 임의의 애플리케이션에 대한 요구 시에 이용가능하도록 연속적으로 동작한다. AR 시스템에 의한 핸드-트래킹 텍스트 입력 애플리케이션의 실행 동안, 핸드-트래킹 텍스트 입력 애플리케 이션은, 동작에서, 제스처 인식 서비스로부터 수신된 현재 검출된 제스처 데이터에 기초하 여, 텍스트 입력 시작/종료 제스처와 같은 텍스트 입력 시작 제스처를 검출한다. 텍스트 입력 시작 제스 처는 AR 시스템에 의해 사용자에게 제공되는 AR 경험의 텍스트 장면 객체로의 텍스트 입력을 시작하라는 사용자에 의한 명령이다. 텍스트 입력 제스처를 검출하는 것에 응답하여, 동작에서, 핸드-트래킹 텍스트 입력 애플리케이션은 가상 키보드를 포함하는 가상 키보드 사용자 인터페이스를 생성한다. 가상 키보드는 가상 키보 드의 상호작용 가상 키들을 구성하는 복수의 가상 객체를 포함한다. 가상 키들은 가상 키보드 사용자 인터페이스에 의해 점유되는 실세계 장면에서의 공간의 볼륨에 대응하는 사용자 인터페이스 기하학 적 모델 또는 볼륨에서의 각각의 위치들을 갖는 기하학적 가상 객체들이다. 예로서, 사용자 인터페이스 기하학 적 모델의 폭(X) 및 높이(Y)는 AR 시스템의 사용자의 관점으로부터의 시야에 의해 정의되고 깊이(Z)는 사용자의 눈 포지션에서 원점을 갖는 100cm의 물리적 길이에 의해 정의된다. 가상 키보드는 사용자가 자신의 팔을 부분적으로 뻗으면서 자신의 손으로 가상 키보드에 도달하는 것을 가능하게 하는 사용자의 눈 포지션에 대 한 50cm의 깊이 위치를 사용자 인터페이스 기하학적 모델에서 할당받는다. 가상 키보드에 더하여, 핸드-트래킹 텍스트 입력 애플리케이션은 사용자의 왼손과 같은 사용자의 텍 스트 입력 손과 연관된 가상 키보드 사용자 인터페이스에서 무한 광선 커서를 생성한다. 핸드- 트래킹 텍스트 입력 애플리케이션은 추적 서비스로부터 수신된 현재 추적 데이터에 기초하여, 텍스트 입력 손의 검지 손가락 팁(fingertip)과 같은 텍스트 입력 손과 연관된 랜드마크를 결정한다. 핸드-트래킹 텍스트 입력 애플리케이션은 무한 광선 커서에 대한 원점을 사용자의 눈 포지션에 설정 한다. 동작 동안, 핸드-트래킹 텍스트 입력 애플리케이션은 사용자의 텍스트 입력 손과 연관된 랜드 마크를 통해 무한 광선 커서를 투영한다. 사용자가 그들의 텍스트 입력 손을 이동시킴에 따라, 무한 광선 커서는 사용자의 눈 포지션 및 랜드마크와 정렬되는 가상 키들 중 하나 이상과 교차 하여, 사용자로 하여금 사용자가 선택하기를 원하는 가상 키로 무한 광선 커서를 조향할 수 있게 한다. 동작의 일부로서, 핸드-트래킹 텍스트 입력 애플리케이션은 가상 키보드 사용자 인터페이스의 렌더링 데이터를 생성하고 렌더링 데이터를 AR 시스템의 광학 엔진에 전달한다. 동작에서, 광학 엔진은 렌더링 데이터에 기초하여 AR 시스템의 디스플레이에서 사용자에게 가상 키보드 사용자 인터페이스를 제공한다. 사용자는 가상 키들의 가상 키와 교차하도록 무한 광선 커서를 조향함으로써 가상 키들로부터 가상 키를 선택하기 위해 가상 키보드 사용자 인터페이스 내에서 랜드마크를 이동시키기 위해 그들의 텍스트 입력 손을 이동시킨다. 사용자는 무한 광선 커서가 현재 교차하고 있는 가상 키를 선택하도 록 핸드-트래킹 텍스트 입력 애플리케이션에 지시하기 위해 그들의 오른손과 같은 자유로운 손으로 제스처와 같은 키 선택 제스처를 행한다. 동작에서, 핸드-트래킹 텍스트 입력 애플리케이션은제스처 인식 서비스로부터 수신된 현재 검출된 제스처 데이터에 기초하여 선택 키 제스처를 검 출한다. 동작에서, 핸드-트래킹 텍스트 입력 애플리케이션은 선택된 가상 키의 사용자 선택을 결정한다. 일 부 예들에서, 핸드-트래킹 텍스트 입력 애플리케이션은 무한 광선 커서와 가상 키들의 가상 키 사이의 교차를 검출한다. 핸드-트래킹 텍스트 입력 애플리케이션은 교차된 가상 키를 선택된 가상 키로서 결정한다. 동작에서, 핸드-트래킹 텍스트 입력 애플리케이션은 선택된 가상 키에 기초하여 입력된 텍스트 데이 터를 생성한다. 일부 예들에서, 가상 키들의 각각의 가상 키는 캐릭터와 연관된다. 핸드-트래킹 텍 스트 입력 애플리케이션은 연관된 캐릭터들을 입력된 텍스트 데이터로 변환한다. 핸드-트래킹 텍스트 입력 애플리케이션은 입력된 텍스트 데이터를 텍스트 장면 텍스트 장면 객체 에 전달한다. 동작에서, 텍스트 장면 객체는 입력된 텍스트 데이터를 AR 시스템의 디스플 레이에서 사용자에게 제공한다. 동작에서, 핸드-트래킹 텍스트 입력 애플리케이션은 제스처 인식 서비스로부터 수신된 현재 검 출된 제스처 데이터에 기초하여, 텍스트 입력 시작/종료 제스처와 같은, 그러나 이에 제한되지 않는, 텍스트 입력 종료 제스처를 검출한다. 텍스트 입력 종료 제스처를 검출하는 것에 응답하여, 핸드-트래킹 텍스 트 입력 애플리케이션은 가상 키보드 사용자 인터페이스를 닫고 종료한다. 일부 예들에서, 텍스트 입력 종료 제스처는 위로 스와이프 제스처, 아래로 스와이프 제스처, 좌측으로 스와이프 제스처, 우측으로 스와 이프 제스처, 주먹을 쥐는 것, \"정지 제스처\"에서 손을 들고 있는 것 등과 같은 임의의 제스처일 수 있다. 일부 예들에서, 핸드-트래킹 텍스트 입력 애플리케이션은 텍스트 입력 시작/종료 제스처와 같은 텍스 트 입력 종료 제스처가 검출될 때까지 루프를 실행한다. 루프는 동작(텍스트 입력 제스처를 검 출함), 동작(선택된 가상 키를 결정함) 및 동작(입력된 텍스트 데이터를 생성하고 664를 텍스트 장면 객체에 전달함)을 포함한다. 이러한 방식으로, 핸드-트래킹 텍스트 입력 애플리케이션은 사용 자가 텍스트 장면 객체에 다수의 캐릭터를 입력할 수 있게 한다. 일부 예들에서, 무한 광선 커서는 활용되지 않는다. 대신에, 동작에서, 핸드-트래킹 텍스트 입력 애 플리케이션은 추적 서비스로부터 현재 추적 데이터를 수신한다. 핸드-트래킹 텍스트 입력 애플 리케이션은 현재 추적 데이터에 기초하여, 사용자의 텍스트 입력 손과 연관된 랜드마크, 예를 들어, 사용자의 텍스트 입력 손의 집게손가락의 끝을 검출한다. 핸드-트래킹 텍스트 입력 애플리케 이션은 랜드마크에 기초하여 가상 키보드 사용자 인터페이스에 랜드마크 충돌기를 생성한다. 가상 키들로부터 가상 키를 선택하기 위해, 사용자는 가상 키보드 사용자 인터페이스 내에서 랜드마 크 충돌기를 이동시키기 위해 그들의 텍스트 입력 손을 이동시킨다. 가상 키를 선택하지 않고 가상 키들 위에서 랜드마크 충돌기를 이동시키기 위해, 사용자는 사용자 인터페이스 기하학적 모델에서 가상 키보드 의 위치로부터 멀어지게 그들의 텍스트 입력 손을 후퇴시키고, 따라서 가상 키들을 클리어한다. 가상 키를 선택하기 위해, 사용자는 가상 키 위에 그들의 텍스트 입력 손을 포지셔닝시키고 랜드마크 충돌 기가 선택된 가상 키와 충돌할 때까지 가상 키를 \"누르거나\" \"찌르기\" 위해 그들의 텍스트 입력 손을 뻗는 다. 핸드-트래킹 텍스트 입력 애플리케이션은 랜드마크 충돌기와 선택된 가상 키 사이의 충돌을 검출함으 로써 선택된 가상 키의 사용자의 선택을 결정한다. 일부 예들에서, 가상 키보드 사용자 인터페이스는 \"완료\", \"취소\", 또는 \"나가기\" 버튼 또는 가상 키와 같 이, 사용자가 핸드-트래킹된 키보드 프로세스를 종료하기 위해 선택하는 사용자 선택가능 가상 객체를 포 함한다. 사용자 선택가능 가상 객체는 가상 키로서 가상 키보드에 포함될 수 있거나, 또는 사용자 선택가 능 버튼으로서 AR 경험에 포함될 수 있거나 텍스트 장면 객체에 포함될 수 있는 등이다. 일부 예들에서, 하나 이상의 카메라들, 추적 서비스, 및 제스처 인식 서비스는 AR 시스템에 의 해 연속적으로 실행되어, AR 시스템에 의해 실행되고 있는 임의의 애플리케이션에 대한 요구 시 현재 검출된 제 스처 데이터 및 현재 추적 데이터가 이용가능하게 된다. 일부 예들에서, 가상 키보드 사용자 인터페이스는 AR 시스템의 사용자의 시야 내에서 AR 시스템을 사용하 는 사용자의 관점으로부터 고정된 깊이(z-거리)에 유지된다. 일부 예들에서, 핸드-트래킹 텍스트 입력 애플리케이션은 AR 시스템이 사용자에게 제공되는 AR 경험 동안 사용자에게 제공하는 애플리케이션이다. AR 시스템은 사용자가 AR 경험의 텍스트 장면 객체 내에 입력된텍스트 데이터를 입력하기 위한 입력 모달리티를 제공하기 위해 핸드-트래킹된 키보드 프로세스를 사 용한다. 일부 예들에서, AR 시스템의 핸드-트래킹 텍스트 입력 애플리케이션은 다양한 API들 및 시스템 라이브러리 들을 활용함으로써 제스처 인식 서비스 및 추적 서비스의 기능들을 수행한다. 도 7은 본 명세서에 설명된 디바이스들 중 임의의 하나 이상에 설치될 수 있는 소프트웨어 아키텍처를 예 시하는 블록도이다. 소프트웨어 아키텍처는 프로세서들, 메모리, 및 I/O 컴포넌트들(73 8)을 포함하는 머신과 같은 하드웨어에 의해 지원된다. 이 예에서, 소프트웨어 아키텍처는 개별 계 층들이 특정 기능성을 제공하는 계층들의 스택으로서 개념화될 수 있다. 소프트웨어 아키텍처는 운영 체 제, 라이브러리들, 프레임워크들, 및 애플리케이션들과 같은 계층들을 포함한다. 동작적 으로, 애플리케이션들은 소프트웨어 스택을 통해 API 호출들을 인보크하고 API 호출들에 응답하 여 메시지들을 수신한다. 운영 체제는 하드웨어 자원들을 관리하고 공통 서비스들을 제공한다. 운영 체제는, 예를 들어, 커널 , 서비스들, 및 드라이버들을 포함한다. 커널은 하드웨어와 다른 소프트웨어 계층들 사이 의 추상화 계층으로서 작용한다. 예를 들어, 커널은, 다른 기능들 중에서도, 메모리 관리, 프로세서 관리 (예를 들어, 스케줄링), 컴포넌트 관리, 네트워킹, 및 보안 설정들을 제공한다. 서비스들은 다른 소프트 웨어 계층들에 대한 다른 공통 서비스들을 제공할 수 있다. 드라이버들은 기본 하드웨어를 제어하거나 그 와 인터페이싱하는 것을 담당한다. 예를 들어, 드라이버들은 디스플레이 드라이버들, 카메라 드라이버들, BLUETOOTH® 또는 BLUETOOTH® Low Energy 드라이버들, 플래시 메모리 드라이버들, 직렬 통신 드라이버들(예를 들어, USB(Universal Serial Bus) 드라이버들), WI-FI® 드라이버들, 오디오 드라이버들, 전력 관리 드라이버들 등을 포함할 수 있다. 라이브러리들은 애플리케이션들에 의해 사용되는 로우-레벨의 공통 인프라스트럭처를 제공한다. 라 이브러리들은 메모리 할당 기능들, 문자열 조작 기능들, 수학 기능들 및 그와 유사한 것과 같은 기능들을 제공하는 시스템 라이브러리들(예를 들어, C 표준 라이브러리)을 포함할 수 있다. 또한, 라이브러리들 은 미디어 라이브러리들(예를 들어, MPEG4(Moving Picture Experts Group-4), H.264 또는 AVC(Advanced Video Coding), MP3(Moving Picture Experts Group Layer-3), AAC(Advanced Audio Coding), AMR(Adaptive Multi-Rate) 오디오 코덱, JPEG 또는 JPG(Joint Photographic Experts Group), 또는 PNG(Portable Network Graphics)와 같은 다양한 미디어 포맷들의 제시 및 조작을 지원하는 라이브러리들), 그래픽 라이브러리들(예를 들어, 디스플레이 상에 2차원(2D) 및 3차원(3D) 그래픽 콘텐츠를 렌더링하는 데 사용되는 OpenGL 프레임워크, 사용자 인터페이스들을 구현하는 데 사용되는 GLMotif), 이미지 특징 추출 라이브러리들(예를 들어, OpenIMAJ), 데이터베이스 라이브러리들(예를 들어, 다양한 관계형 데이터베이스 기능들을 제공하는 SQLite), 웹 라이브러리 들(예를 들어, 웹 브라우징 기능성을 제공하는 WebKit) 등과 같은 API 라이브러리들을 포함할 수 있다. 라이브러리들은 또한 많은 다른 API들을 애플리케이션들에 제공하기 위해 매우 다양한 다른 라이브러 리들을 포함할 수 있다. 프레임워크들은 애플리케이션들에 의해 사용되는 하이-레벨의 공통 인프라스트럭처를 제공한다. 예 를 들어, 프레임워크들은 다양한 그래픽 사용자 인터페이스(GUI) 기능들, 하이-레벨 자원 관리, 및 하이- 레벨 위치 서비스들을 제공한다. 프레임워크들은 애플리케이션들에 의해 사용될 수 있는 광범위한 스펙트럼의 다른 API들을 제공할 수 있으며, 그 중 일부는 특정 운영 체제 또는 플랫폼에 특정적일 수 있다. 일부 예들에서, 애플리케이션들은 홈 애플리케이션, 연락처 애플리케이션, 브라우저 애플리케이 션, 북 리더 애플리케이션, 위치 애플리케이션, 미디어 애플리케이션, 메시징 애플리케이 션, 게임 애플리케이션, 및 제3자 애플리케이션들과 같은 광범위한 다른 애플리케이션들을 포함 할 수 있다. 애플리케이션들은 프로그램들에 정의된 기능들을 실행하는 프로그램들이다. 다양한 방식들 로 구조화된 애플리케이션들 중 하나 이상을 생성하기 위해, 객체 지향 프로그래밍 언어들(예를 들어, Objective-C, Java, 또는 C++) 또는 절차적 프로그래밍 언어들(예를 들어, C 또는 어셈블리 언어)과 같은 다양 한 프로그래밍 언어들이 이용될 수 있다. 특정 예에서, 제3자 애플리케이션들(예를 들어, 특정 플랫폼의 벤더 이외의 엔티티에 의해 ANDROID™ 또는 IOS™ 소프트웨어 개발 키트(SDK)를 사용하여 개발된 애플리케이션 들)은 IOS™, ANDROID™, WINDOWS® Phone, 또는 다른 모바일 운영 체제와 같은 모바일 운영 체제 상에서 실행 되는 모바일 소프트웨어일 수 있다. 이 예에서, 제3자 애플리케이션들은 본 명세서에 설명된 기능성을 용 이하게 하기 위해 운영 체제에 의해 제공되는 API 호출들을 인보크할 수 있다.도 8은 일부 예들에 따른, 안경의 세부사항들을 포함하는 네트워크화된 시스템을 예시하는 블록도이 다. 네트워크화된 시스템은 안경, 클라이언트 디바이스, 및 서버 시스템을 포함한다. 클 라이언트 디바이스는 스마트폰, 태블릿, 패블릿, 랩톱 컴퓨터, 액세스 포인트, 또는 저전력 무선 접속 및/또는 고속 무선 접속을 사용하여 안경과 접속할 수 있는 임의의 다른 그러한 디바이스일 수 있다. 클라이언트 디바이스는 네트워크를 통해 서버 시스템에 접속된다. 네트워크는 유 선 및 무선 연결들의 임의의 조합을 포함할 수 있다. 서버 시스템은 서비스 또는 네트워크 컴퓨팅 시스템 의 일부로서 하나 이상의 컴퓨팅 디바이스일 수 있다. 클라이언트 디바이스 및 서버 시스템 및 네트 워크의 임의의 요소들은 각각 도 7 및 도 3에 설명된 소프트웨어 아키텍처 또는 머신의 상세들 을 사용하여 구현될 수 있다. 안경은 데이터 프로세서, 디스플레이들, 하나 이상의 카메라, 및 추가적인 입력/출력 요소 들을 포함한다. 입력/출력 요소들은 마이크로폰들, 오디오 스피커들, 생체인식 센서들, 추가적인 센 서들, 또는 데이터 프로세서와 통합된 추가적인 디스플레이 요소들을 포함할 수 있다. 입력/출력 요소들 의 예들은 도 7 및 도 3과 관련하여 더 논의된다. 예를 들어, 입력/출력 요소들은 출력 컴포넌트들 , 모션 컴포넌트들 등을 포함하는 I/O 컴포넌트들 중 임의의 것을 포함할 수 있다. 디스플레이 들의 예들은 도 2에서 논의된다. 본 명세서에 설명된 특정 예들에서, 디스플레이들은 사용자의 좌안 및 우안을 위한 디스플레이를 포함한다. 데이터 프로세서는 이미지 프로세서(예를 들어, 비디오 프로세서), GPU 및 디스플레이 드라이버 , 추적 모듈, 인터페이스, 저전력 회로부, 및 고속 회로부를 포함한다. 데이터 프로 세서의 컴포넌트들은 버스에 의해 상호접속된다. 인터페이스는 데이터 프로세서에 제공되는 사용자 명령의 임의의 소스를 지칭한다. 하나 이상의 예 에서, 인터페이스는, 눌러질 때, 인터페이스로부터의 사용자 입력 신호를 저전력 프로세서에 전 송하는 물리적 버튼이다. 이러한 버튼의 누름에 이은 즉시 해제는 단일 이미지를 캡처하기 위한 요청으로서 저 전력 프로세서에 의해 처리될 수 있거나, 그 반대일 수 있다. 제1 기간 동안 그러한 버튼의 누름은 버튼 이 눌러진 동안 비디오 데이터를 캡처하고, 버튼이 해제될 때 비디오 캡처를 중단하라는 요청으로서 저전력 프 로세서에 의해 처리될 수 있으며, 버튼이 눌러진 동안 캡처된 비디오는 단일 비디오 파일로서 저장된다. 대안적으로, 연장된 기간 동안 버튼을 누르는 것은 정지 이미지를 캡처할 수 있다. 일부 예들에서, 인터페이스 는 카메라들로부터의 데이터에 대한 요청과 연관된 사용자 입력들을 수용할 수 있는 임의의 기계적 스위치 또는 물리적 인터페이스일 수 있다. 다른 예들에서, 인터페이스는 소프트웨어 컴포넌트를 가질 수 있거나, 클라이언트 디바이스와 같은 다른 소스로부터 무선으로 수신된 커맨드와 연관될 수 있다. 이미지 프로세서는 카메라들로부터 신호들을 수신하고 카메라들로부터의 그 신호들을 메모리 에 저장하기에 또는 클라이언트 디바이스로 송신하기에 적합한 포맷으로 처리하는 회로부를 포함한다. 하나 이상의 예에서, 이미지 프로세서(예를 들어, 비디오 프로세서)는 동작 중인 마이크로프로 세서에 의해 사용되는 휘발성 메모리와 함께, 카메라들로부터의 센서 데이터를 처리하기 위해 맞춤화된 마 이크로프로세서 집적 회로(IC)를 포함한다. 저전력 회로부는 저전력 프로세서 및 저전력 무선 회로부를 포함한다. 저전력 회로부의 이러한 요소들은 별개의 요소들로서 구현될 수 있거나 단일 칩 상의 시스템의 일부로서 단일 IC 상에 구현될 수 있다. 저전력 프로세서는 안경의 다른 요소들을 관리하기 위한 로직을 포함한다. 전술한 바와 같이, 예를 들어, 저전력 프로세서는 인터페이스로부터 사용자 입력 신호들을 수용할 수 있다. 저전 력 프로세서는 또한 저전력 무선 접속을 통해 클라이언트 디바이스로부터 입력 신호들 또는 명 령어 통신들을 수신하도록 구성될 수 있다. 저전력 무선 회로부는 저전력 무선 통신 시스템을 구현하기 위한 회로 요소들을 포함한다. 블루투스™ 저에너지(Bluetooth™ low energy)라고도 알려진 블루투스™ 스마트 (Bluetooth™ smart)는 저전력 무선 회로부를 구현하는 데 사용될 수 있는 저전력 무선 통신 시스템의 하 나의 표준 구현이다. 다른 예들에서, 다른 저전력 통신 시스템들이 사용될 수 있다. 고속 회로부는 고속 프로세서, 메모리, 및 고속 무선 회로부를 포함한다. 고속 프로세서 는 데이터 프로세서에 사용되는 임의의 일반 컴퓨팅 시스템의 고속 통신 및 동작을 관리할 수 있는 임의의 프로세서일 수 있다. 고속 프로세서는 고속 무선 회로부를 사용하여 고속 무선 접속 상 에서 고속 데이터 전송들을 관리하기 위해 사용되는 처리 자원들을 포함한다. 일부 예들에서, 고속 프로세서 는 LINUX 운영 체제와 같은 운영 체제 또는 도 7의 운영 체제와 같은 다른 그러한 운영 체제를 실행한다. 임의의 다른 책임들에 더하여, 데이터 프로세서에 대한 소프트웨어 아키텍처를 실행하는 고속 프로 세서는 고속 무선 회로부와의 데이터 전송들을 관리하기 위해 사용된다. 일부 예들에서, 고속 무선 회로부는 본 명세서에서 Wi-Fi라고도 지칭되는 IEEE(Institute of Electrical and Electronic Engineers) 802.11 통신 표준들을 구현하도록 구성된다. 다른 예들에서, 다른 고속 통신 표준들이 고속 무선 회로부 에 의해 구현될 수 있다. 메모리는 카메라들 및 이미지 프로세서에 의해 생성된 카메라 데이터를 저장할 수 있는 임의의 저장 디바이스를 포함한다. 메모리가 고속 회로부와 통합된 것으로 도시되어 있지만, 다른 예들에서, 메모리는 데이터 프로세서의 독립적인 독립형 요소일 수 있다. 일부 그러한 예들에서, 전 기 라우팅 라인들은 고속 프로세서를 포함하는 칩을 통해 이미지 프로세서 또는 저전력 프로세서 로부터 메모리로의 접속을 제공할 수 있다. 다른 예들에서, 고속 프로세서는 메모리를 수 반하는 판독 또는 기입 동작이 요구되는 임의의 시간에 저전력 프로세서가 고속 프로세서를 부팅하도 록 메모리의 어드레싱을 관리할 수 있다. 추적 모듈은 안경의 포즈를 추정한다. 예를 들어, 추적 모듈은 카메라들 및 포지션 컴포 넌트들로부터의 이미지 데이터 및 연관된 관성 데이터뿐만 아니라 GPS 데이터를 사용하여, 위치를 추적하 고 기준 프레임(예를 들어, 실세계 장면 환경)에 대한 안경의 포즈를 결정한다. 추적 모듈은 실세계 장면 환경에서 물리적 객체들에 대한 상대적 포지션 및 배향의 변화들을 나타내는 안경의 업데이트된 3차 원 포즈들을 결정하기 위해 안경의 움직임들을 설명하는 업데이트된 센서 데이터를 계속 수집하고 사용한 다. 추적 모듈은 디스플레이들을 통해 사용자의 시야 내에서 안경에 의한 물리적 객체들에 대 한 가상 객체들의 시각적 배치를 허용한다. GPU 및 디스플레이 드라이버는 안경이 전통적인 증강 현실 모드에서 기능하고 있을 때 디스플레이들 상에 제시될 가상 콘텐츠 또는 다른 콘텐츠의 프레임들을 생성하기 위해 안경의 포즈를 사용할 수 있다. 이 모드에서, GPU & 디스플레이 드라이버는 안경의 업데이트된 3차원 포즈들에 기초하여 가상 콘텐츠의 업데이트된 프레임들을 생성하며, 이는 사용자의 실세계 장면 환경에서 물리적 객체들과 관련하여 사 용자의 포지션 및 배향의 변화들을 반영한다. 본 명세서에 설명된 하나 이상의 기능 또는 동작은 또한 안경 상에 상주하는 애플리케이션에서 또는 클라 이언트 디바이스 상에서, 또는 원격 서버 상에서 수행될 수 있다. 예를 들어, 본 명세서에 설명된 하나 이상의 기능 또는 동작은 메시징 애플리케이션과 같은 애플리케이션들 중 하나에 의해 수행될 수 있 다. 도 9는 네트워크를 통해 데이터(예를 들어, 메시지들 및 연관된 콘텐츠)를 교환하기 위한 예시적인 메시징 시스 템을 도시하는 블록도이다. 메시징 시스템은 메시징 클라이언트 및 다른 애플리케이션들 을 포함하는 다수의 애플리케이션들을 호스팅하는 클라이언트 디바이스의 다수의 인스턴스들을 포함한다. 메시징 클라이언트는 네트워크(예를 들어, 인터넷)를 통해 메시징 클라이언트의 다른 인스턴스 들(예를 들어, 각자의 다른 클라이언트 디바이스들 상에서 호스팅됨), 메시징 서버 시스템 및 제3자 서버들에 통신가능하게 결합된다. 메시징 클라이언트는 또한 API들(Application Program Interfaces)을 사용하여 로컬 호스팅 애플리케이션들과 통신할 수 있다. 메시징 클라이언트는 네트워크를 통해 다른 메시징 클라이언트들과 그리고 메시징 서버 시스템 과 통신하고 데이터를 교환할 수 있다. 메시징 클라이언트들 사이에, 그리고 메시징 클라이언트 와 메시징 서버 시스템 사이에 교환되는 데이터는 기능들(예를 들어, 기능들을 인보크하기 위한 커맨 드들)뿐만 아니라 페이로드 데이터(예를 들어, 텍스트, 오디오, 비디오 또는 다른 멀티미디어 데이터)를 포함한 다. 메시징 서버 시스템은 네트워크를 통해 특정 메시징 클라이언트에 서버측 기능성을 제공한다. 메시징 시스템의 일부 기능들이 메시징 클라이언트에 의해 또는 메시징 서버 시스템에 의해 수 행되는 것으로 본 명세서에 설명되지만, 메시징 클라이언트 또는 메시징 서버 시스템 내의 일부 기능 성의 위치는 설계 선택일 수 있다. 예를 들어, 초기에 일부 기술 및 기능성을 메시징 서버 시스템 내에 배치하지만, 나중에 이 기술 및 기능성을 클라이언트 디바이스가 충분한 처리 용량을 갖는 메시징 클라이 언트로 옮기는 것이 기술적으로 바람직할 수 있다. 메시징 서버 시스템은 메시징 클라이언트에 제공되는 다양한 서비스들 및 동작들을 지원한다. 이러 한 동작들은 메시징 클라이언트에 데이터를 송신하는 것, 메시징 클라이언트로부터 데이터를 수신하 는 것, 및 메시징 클라이언트에 의해 생성된 데이터를 처리하는 것을 포함한다. 이 데이터는, 예로서, 메 시지 콘텐츠, 클라이언트 디바이스 정보, 지오로케이션 정보, 미디어 증강 및 오버레이들, 메시지 콘텐츠 지속 조건들, 소셜 네트워크 정보, 및 라이브 이벤트 정보를 포함할 수 있다. 메시징 시스템 내의 데이터 교환 들은 메시징 클라이언트의 사용자 인터페이스(UI)들을 통해 이용가능한 기능들을 통해 인보크되고 제어된 다. 이제 구체적으로 메시징 서버 시스템을 참조하면, API(Application Program Interface) 서버는 애플 리케이션 서버들에 결합되어 프로그램 방식의 인터페이스를 제공한다. 애플리케이션 서버들은 데이 터베이스 서버에 통신가능하게 결합되고, 이는 애플리케이션 서버들에 의해 처리되는 메시지들과 연 관된 데이터를 저장하는 데이터베이스에 대한 액세스를 용이하게 한다. 유사하게, 웹 서버는 애플리 케이션 서버들에 결합되고, 웹 기반 인터페이스들을 애플리케이션 서버들에 제공한다. 이를 위해, 웹 서버는 HTTP(Hypertext Transfer Protocol) 및 몇몇 다른 관련 프로토콜들을 통해 들어오는 네트워크 요청들을 처리한다. 애플리케이션 프로그램 인터페이스(API) 서버는 클라이언트 디바이스와 애플리케이션 서버들 사 이에서 메시지 데이터(예를 들어, 커맨드들 및 메시지 페이로드들)를 수신하고 송신한다. 구체적으로, 애플리 케이션 프로그램 인터페이스(API) 서버는 애플리케이션 서버들의 기능성을 인보크하기 위해 메시징 클라이언트에 의해 호출되거나 질의될 수 있는 인터페이스들(예를 들어, 루틴들 및 프로토콜들)의 세트를 제공한다. 애플리케이션 프로그램 인터페이스(API) 서버는 계정 등록, 로그인 기능성, 특정 메시징 클라 이언트로부터 다른 메시징 클라이언트로의, 애플리케이션 서버들을 통한 메시지들의 전송, 메시 징 클라이언트로부터 메시징 서버로의 미디어 파일들(예를 들어, 이미지들 또는 비디오)의 전송, 및 다른 메시징 클라이언트에 의한 가능한 액세스를 위해, 미디어 데이터의 컬렉션(예를 들어, 스토리)의 설 정들, 클라이언트 디바이스의 사용자의 친구들의 리스트의 검색, 그러한 컬렉션들의 검색, 메시지들 및 콘 텐츠의 검색, 엔티티 그래프(예를 들어, 소셜 그래프)에 대한 엔티티들(예를 들어, 친구들)의 추가 및 삭제, 소 셜 그래프 내의 친구들의 위치, 및 (예를 들어, 메시징 클라이언트에 관련된) 애플리케이션 이벤트를 여는 것을 포함하여, 애플리케이션 서버들에 의해 지원되는 다양한 기능들을 노출시킨다. 애플리케이션 서버들은 예를 들어 메시징 서버, 이미지 처리 서버, 및 소셜 네트워크 서버(92 2)를 포함하는 다수의 서버 애플리케이션들 및 서브시스템들을 호스팅한다. 메시징 서버는, 특히 메시징 클라이언트의 다수의 인스턴스들로부터 수신된 메시지들에 포함된 콘텐츠(예를 들어, 텍스트 및 멀티미디 어 콘텐츠)의 집성 및 다른 처리와 관련된 다수의 메시지 처리 기술들 및 기능들을 구현한다. 더 상세히 설명 되는 바와 같이, 다수의 소스들로부터의 텍스트 및 미디어 콘텐츠는 콘텐츠의 컬렉션들(예를 들어, 스토리들 또 는 갤러리들로 불림)로 집성될 수 있다. 다음으로, 이러한 컬렉션들은 메시징 클라이언트에 이용가능하게 된다. 데이터의 다른 프로세서 및 메모리 집약적 처리는 또한, 그러한 처리를 위한 하드웨어 요건들을 고려하 여, 메시징 서버에 의해 서버 측에서 수행될 수 있다. 애플리케이션 서버들은 또한, 전형적으로 메시징 서버로부터 전송되거나 메시징 서버에서 수신 되는 메시지의 페이로드 내의 이미지들 또는 비디오와 관련하여, 다양한 이미지 처리 동작들을 수행하는 데 전 용되는 이미지 처리 서버를 포함한다. 소셜 네트워크 서버는 다양한 소셜 네트워킹 기능들 및 서비스들을 지원하고, 이러한 기능들 및 서비스들 을 메시징 서버에 이용가능하게 한다. 이를 위해, 소셜 네트워크 서버는 데이터베이스 내의 엔 티티 그래프를 유지하고 액세스한다. 소셜 네트워크 서버에 의해 지원되는 기능들 및 서비스들의 예들은 특정 사용자가 관계들을 갖거나 \"팔로우하고 있는\" 메시징 시스템의 다른 사용자들의 식별, 및 또한 특정 사용자의 다른 엔티티들 및 관심들의 식별을 포함한다. 메시징 클라이언트는 클라이언트 디바이스의 사용자, 또는 그러한 사용자와 관련된 다른 사용자들(예 를 들어, \"친구들\")에게, 공유된 또는 공유가능한 세션들에서 발생하는 활동을 통지할 수 있다. 예를 들어, 메 시징 클라이언트는 메시징 클라이언트에서의 대화(예를 들어, 채팅 세션)의 참가자들에게 사용자들의 그룹의 하나 이상의 멤버에 의한 게임의 현재 또는 최근 사용에 관련된 통지들을 제공할 수 있다. 하나 이상의 사용자는 활성 세션에 참여하거나 새로운 세션을 시작하도록 초대될 수 있다. 일부 예들에서, 공유 세션들은 다수의 사람들이 협력하거나 참여할 수 있는 공유 증강 현실 경험을 제공할 수 있다. \"캐리어 신호\"는 머신에 의한 실행을 위한 명령어들을 저장, 인코딩, 또는 운반할 수 있는 임의의 무형 매체를 지칭하고, 이러한 명령어들의 통신을 용이하게 하기 위한 디지털 또는 아날로그 통신 신호들 또는 다른 무형 매 체를 포함한다. 명령어들은 네트워크 인터페이스 디바이스를 통해 송신 매체를 사용하여 네트워크를 통해 송신 또는 수신될 수 있다. \"클라이언트 디바이스\"는 하나 이상의 서버 시스템들 또는 다른 클라이언트 디바이스들로부터 자원들을 획득하 기 위해 통신 네트워크에 인터페이스하는 임의의 머신을 지칭한다. 클라이언트 디바이스는 모바일 폰, 데스크 톱 컴퓨터, 랩톱, PDA들(portable digital assistants), 스마트폰들, 태블릿들, 울트라북들, 넷북들, 랩톱들, 멀티-프로세서 시스템들, 마이크로프로세서 기반 또는 프로그래밍가능 소비자 전자기기들, 게임 콘솔들, 셋톱 박스들, 또는 사용자가 네트워크에 액세스하기 위해 사용할 수 있는 임의의 다른 통신 디바이스일 수 있지만, 이에 제한되지 않는다. \"통신 네트워크\"는 애드 혹 네트워크(ad hoc network), 인트라넷, 엑스트라넷, VPN(virtual private network), LAN(local area network), WLAN(wireless LAN), WAN(wide area network), WWAN(wireless WAN), MAN(metropolitan area network), 인터넷, 인터넷의 일부, PSTN(Public Switched Telephone Network)의 일부, POTS(plain old telephone service) 네트워크, 셀룰러 전화 네트워크, 무선 네트워크, Wi-Fi® 네트워크, 다른 유형의 네트워크, 또는 2개 이상의 이러한 네트워크의 조합일 수 있는 네트워크의 하나 이상의 부분을 지칭한다. 예를 들어, 네트워크 또는 네트워크의 일부는 무선 또는 셀룰러 네트워크를 포함할 수 있고, 결합은 CDMA(Code Division Multiple Access) 접속, GSM(Global System for Mobile communications) 접속, 또는 다른 타입들의 셀룰러 또는 무선 결합일 수 있다. 이 예에서, 결합은 1xRTT(Single Carrier Radio Transmission Technology), EVDO(Evolution-Data Optimized) 기술, GPRS(General Packet Radio Service) 기술, EDGE(Enhanced Data rates for GSM Evolution) 기술, 3G를 포함하는 3GPP(third Generation Partnership Project), 4G(fourth generation wireless) 네트워크들, UMTS(Universal Mobile Telecommunications System), HSPA(High Speed Packet Access), WiMAX(Worldwide Interoperability for Microwave Access), LTE(Long Term Evolution) 표준, 다양한 표준 설정 조직들에 의해 정의된 다른 것들, 다른 장거리 프로토콜들, 또는 다른 데이 터 전송 기술과 같은 다양한 타입들의 데이터 전송 기술 중 임의의 것을 구현할 수 있다. \"컴포넌트\"는 함수 또는 서브루틴 호출들, 분기 포인트들, API들, 또는 특정 프로세싱 또는 제어 기능들의 파티 셔닝 또는 모듈화를 제공하는 다른 기술들에 의해 정의되는 경계들을 갖는 디바이스, 물리적 엔티티, 또는 로직 을 지칭한다. 컴포넌트들은 머신 프로세스를 수행하기 위해 그들의 인터페이스들을 통해 다른 컴포넌트들과 결 합될 수 있다. 컴포넌트는 다른 컴포넌트들 및 관련 기능들 중 특정 기능을 일반적으로 수행하는 프로그램의 일부와 함께 사용하도록 설계된 패키징된 기능 하드웨어 유닛일 수 있다. 컴포넌트들은 소프트웨어 컴포넌트들 (예를 들어, 머신 판독가능 매체 상에 구현된 코드) 또는 하드웨어 컴포넌트들을 구성할 수 있다. \"하드웨어 컴포넌트\"는 일부 동작들을 수행할 수 있는 유형 유닛(tangible unit)이고, 특정 물리적 방식으로 구성되거나 배열될 수 있다. 다양한 예들에서, 하나 이상의 컴퓨터 시스템(예를 들어, 독립형 컴퓨터 시스템, 클라이언트 컴퓨터 시스템, 또는 서버 컴퓨터 시스템) 또는 컴퓨터 시스템의 하나 이상의 하드웨어 컴포넌트(예를 들어, 프 로세서 또는 프로세서들의 그룹)는 본 명세서에 설명된 바와 같은 일부 동작들을 수행하도록 동작하는 하드웨어 컴포넌트로서 소프트웨어(예를 들어, 애플리케이션 또는 애플리케이션 부분)에 의해 구성될 수 있다. 하드웨어 컴포넌트는 또한 기계적으로, 전자적으로, 또는 이들의 임의의 적절한 조합으로 구현될 수 있다. 예를 들어, 하드웨어 컴포넌트는 일부 동작들을 수행하도록 영구적으로 구성되는 전용 회로부 또는 로직을 포함할 수 있다. 하드웨어 컴포넌트는 FPGA(field-programmable gate array) 또는 ASIC(application specific integrated circuit)과 같은 특수 목적 프로세서일 수 있다. 하드웨어 컴포넌트는 또한 일부 동작들을 수행하기 위해 소프 트웨어에 의해 일시적으로 구성되는 프로그램가능 로직 또는 회로부를 포함할 수 있다. 예를 들어, 하드웨어 컴포넌트는 범용 프로세서 또는 다른 프로그램가능 프로세서에 의해 실행되는 소프트웨어를 포함할 수 있다. 일단 이러한 소프트웨어에 의해 구성되면, 하드웨어 컴포넌트들은 구성된 기능들을 수행하도록 맞춤화된 특정 머신들(또는 머신의 특정 컴포넌트들)이 되고 더 이상 범용 프로세서들이 아니다. 하드웨어 컴포넌트를 기계적 으로, 전용의 영구적으로 구성된 회로부에, 또는 일시적으로 구성된 회로부(예를 들어, 소프트웨어에 의해 구성 됨)에 구현하기로 하는 결정은 비용 및 시간 고려사항들에 의해 주도될 수 있다는 것을 이해할 것이다. 따라서, \"하드웨어 컴포넌트\"(또는 \"하드웨어 구현 컴포넌트\")라는 문구는 특정 방식으로 동작하거나 본 명세서 에 설명된 일부 동작들을 수행하도록 물리적으로 구성되거나, 영구적으로 구성되거나(예를 들어, 하드와이어드 (hardwired)), 또는 일시적으로 구성되는(예를 들어, 프로그래밍되는) 엔티티인 유형 엔티티를 포괄하는 것으로 이해되어야 한다. 하드웨어 컴포넌트들이 일시적으로 구성되는(예를 들어, 프로그래밍되는) 예들을 고려하면, 하드웨어 컴포넌트들은 임의의 하나의 시간 인스턴스에서 구성되거나 인스턴스화되지 않을 수 있다. 예를 들어, 하드웨어 컴포넌트가 특수 목적 프로세서가 되도록 소프트웨어에 의해 구성된 범용 프로세서를 포함하는경우, 범용 프로세서는 상이한 시간들에서 각각 상이한 특수 목적 프로세서들(예를 들어, 상이한 하드웨어 컴포 넌트들을 포함함)로서 구성될 수 있다. 소프트웨어는 그에 따라, 예를 들어, 하나의 시간 인스턴스에서 특정 하드웨어 컴포넌트를 구성하고 상이한 시간 인스턴스에서 상이한 하드웨어 컴포넌트를 구성하도록 특정 프로세 서 또는 프로세서들을 구성한다. 하드웨어 컴포넌트들은 다른 하드웨어 컴포넌트들에 정보를 제공하고 다른 하 드웨어 컴포넌트들로부터 정보를 수신할 수 있다. 따라서, 설명된 하드웨어 컴포넌트들은 통신가능하게 결합되 는 것으로 간주될 수 있다. 다수의 하드웨어 컴포넌트들이 동시에 존재하는 경우, 통신들은 하드웨어 컴포넌트 들 중 2개 이상 사이의 또는 그들 사이의 (예를 들어, 적절한 회로들 및 버스들을 통한) 신호 송신을 통해 달성 될 수 있다. 다수의 하드웨어 컴포넌트들이 상이한 시간들에서 구성되거나 인스턴스화되는 예들에서, 그러한 하드웨어 컴포넌트들 사이의 통신들은, 예를 들어, 다수의 하드웨어 컴포넌트들이 액세스하는 메모리 구조들에 서의 정보의 저장 및 검색을 통해 달성될 수 있다. 예를 들어, 하나의 하드웨어 컴포넌트는 동작을 수행하고 그 동작의 출력을 그것이 통신가능하게 결합되는 메모리 디바이스에 저장할 수 있다. 그 후, 추가 하드웨어 컴 포넌트는 나중에 저장된 출력을 검색하고 처리하기 위해 메모리 디바이스에 액세스할 수 있다. 하드웨어 컴포 넌트들은 또한 입력 또는 출력 디바이스들과의 통신들을 개시할 수 있고, 자원(예를 들어, 정보의 컬렉션) 상에 서 동작할 수 있다. 본 명세서에 설명된 예시적인 방법들의 다양한 동작들은 관련 동작들을 수행하도록 (예를 들어, 소프트웨어에 의해) 일시적으로 구성되거나 영구적으로 구성되는 하나 이상의 프로세서에 의해 수행될 수 있다. 일시적으로 또는 영구적으로 구성되든 간에, 그러한 프로세서들은 본 명세서에 설명된 하나 이상의 동작 또는 기능을 수행하도록 동작하는 프로세서 구현 컴포넌트들을 구성할 수 있다. 본 명세서에서 사용되는 바와 같이, \"프로세서 구현 컴포넌트\"는 하나 이상의 프로세서를 사용하여 구현되는 하드웨어 컴포넌트를 지칭한다. 유사하게, 본 명세서에 설명된 방법들은 부분적으로 프로세서-구현될 수 있으며, 특정 프로세서 또는 프로세서 들은 하드웨어의 예이다. 예를 들어, 방법의 동작들 중 일부는 하나 이상의 프로세서 또는 프로세서 구현 컴포 넌트에 의해 수행될 수 있다. 더욱이, 하나 이상의 프로세서는 또한 \"클라우드 컴퓨팅\" 환경에서 또는 \"서비스 로서의 소프트웨어\"(software as a service)(SaaS)로서 관련 동작들의 수행을 지원하도록 동작할 수 있다. 예 를 들어, 동작들 중 일부는 (프로세서들을 포함하는 머신들의 예들로서) 컴퓨터들의 그룹에 의해 수행될 수 있 고, 이러한 동작들은 네트워크(예를 들어, 인터넷)를 통해 그리고 하나 이상의 적절한 인터페이스(예를 들어, API)를 통해 액세스가능하다. 동작들 중 일부의 수행은 단일 머신 내에 상주할 뿐만 아니라 다수의 머신들에 걸쳐 배치되는 프로세서들 사이에 분산될 수 있다. 일부 예들에서, 프로세서들 또는 프로세서-구현된 컴포넌트 들은 단일 지리적 위치에(예를 들어, 가정 환경, 사무실 환경, 또는 서버 팜 내에) 위치될 수 있다. 다른 예들 에서, 프로세서들 또는 프로세서-구현된 컴포넌트들은 다수의 지리적 위치들에 걸쳐 분산될 수 있다. \"컴퓨터 판독가능 매체\"는 머신 저장 매체 및 송신 매체 둘 다를 지칭한다. 따라서, 용어들은 저장 디바이스들 /매체들 및 반송파들/변조된 데이터 신호들 둘 다를 포함한다. \"머신 판독가능 매체\", \"컴퓨터 판독가능 매체\" 및 \"디바이스 판독가능 매체\"라는 용어들은 동일한 것을 의미하고, 본 개시내용에서 상호교환가능하게 사용될 수 있다. \"머신 저장 매체\"는 실행가능 명령어들, 루틴들 및/또는 데이터를 저장하는 단일 또는 다수의 저장 디바이스들 및/또는 매체들(예를 들어, 중앙집중형 또는 분산형 데이터베이스, 및/또는 연관된 캐시들 및 서버들)을 지칭한 다. 이 용어는 솔리드-스테이트 메모리들, 및 프로세서들 내부 또는 외부의 메모리를 포함하는 광학 및 자기 매체를 포함하지만, 이에 제한되지 않는다. 머신 저장 매체들, 컴퓨터 저장 매체들 및/또는 디바이스 저장 매 체들의 특정 예들은 예로서 반도체 메모리 디바이스들, 예를 들어, EPROM(erasable programmable read-only memory), EEPROM(electrically erasable programmable read-only memory), FPGA, 및 플래시 메모리 디바이스들 을 포함하는 비휘발성 메모리; 내부 하드 디스크들 및 이동식 디스크들과 같은 자기 디스크들; 광자기 디스크들; 및 CD-ROM 및 DVD-ROM 디스크들을 포함한다. 용어들 \"머신 저장 매체\", \"디바이스 저장 매체\", \"컴 퓨터 저장 매체\"는 동일한 것을 의미하고 본 개시내용에서 상호교환가능하게 사용될 수 있다. \"머신 저장 매체 들\", \"컴퓨터 저장 매체들\", 및 \"디바이스 저장 매체들\"이라는 용어들은 구체적으로 반송파들, 변조된 데이터 신호들, 및 다른 그러한 매체들을 배제하며, 이들 중 일부는 \"신호 매체\"라는 용어 하에 커버된다. \"프로세서\"는 제어 신호들(예를 들어, \"명령들\", \"op 코드들\", \"머신 코드\" 등)에 따라 데이터 값들을 조작하고 머신을 동작시키기 위해 인가되는 연관된 출력 신호들을 생성하는 임의의 회로 또는 가상 회로(실제 프로세서 상에서 실행되는 로직에 의해 에뮬레이트(emulated)되는 물리적 회로)를 지칭한다. 프로세서는, 예를 들어, CPU(Central Processing Unit), RISC(Reduced Instruction Set Computing) 프로세서, CISC(Complex Instruction Set Computing) 프로세서, GPU(Graphics Processing Unit), DSP(Digital Signal Processor), ASIC(Application Specific Integrated Circuit), RFIC(Radio-Frequency Integrated Circuit) 또는 이들의 임 의의 조합일 수 있다. 프로세서는 또한 명령어들을 동시에 실행할 수 있는 2개 이상의 독립적인 프로세서들(때때로 \"코어들\"이라고 지칭됨)을 갖는 멀티-코어 프로세서일 수 있다. \"신호 매체\"는 머신에 의한 실행을 위한 명령어들을 저장, 인코딩, 또는 운반할 수 있는 임의의 무형 매체를 지 칭하고, 소프트웨어 또는 데이터의 통신을 용이하게 하기 위한 디지털 또는 아날로그 통신 신호들 또는 다른 무 형 매체를 포함한다. \"신호 매체\"라는 용어는 임의의 형태의 변조된 데이터 신호, 반송파 등을 포함하는 것으 로 간주될 수 있다. \"변조된 데이터 신호\"라는 용어는 신호에 정보를 인코딩하는 것과 같은 문제에서 그 특성 들 중 하나 이상이 설정되거나 변경된 신호를 의미한다. \"송신 매체\" 및 \"신호 매체\"라는 용어들은 동일한 것 을 의미하고, 본 개시내용에서 상호교환가능하게 사용될 수 있다. 본 개시내용의 범위를 벗어나지 않고 개시된 예들에 대해 변경들 및 수정들이 이루어질 수 있다. 이들 및 다른 변경들 또는 수정들은 다음의 청구항들에 표현된 바와 같이, 본 개시내용의 범위 내에 포함되도록 의도된다."}
{"patent_id": "10-2024-7042990", "section": "도면", "subsection": "도면설명", "item": 1, "content": "임의의 특정 요소 또는 동작의 논의를 용이하게 식별하기 위해, 참조 번호에서 최상위 숫자 또는 숫자들은 그 요소가 처음 도입되는 도면 번호를 지칭한다. 도 1은 몇몇 예에 따른, 머리 착용형 디바이스의 사시도이다. 도 2는 몇몇 예에 따른, 도 1의 머리 착용형 디바이스의 다른 도면을 도시하고 있다. 도 3은 일부 예들에 따라 머신으로 하여금 본 명세서에서 논의된 방법론들 중 임의의 하나 이상을 수행하게 하 기 위해 명령어들의 세트가 실행될 수 있는 컴퓨팅 장치의 형태의 머신의 도식적 표현이다. 도 4a는 일부 예들에 따른 AR 시스템의 제스처 기반 키보드 프로세스의 시퀀스 다이어그램이다. 도 4b는 일부 예들에 따른 AR 시스템에 지시하기 위해 사용되는 제스처를 도시한다. 도 4c는 일부 예들에 따른 AR 시스템의 가상 키보드 사용자 인터페이스를 도시한다. 도 5a는 일부 예들에 따른 AR 시스템의 핸드-트래킹된 키보드 프로세스의 시퀀스 다이어그램이다. 도 5b는 일부 예들에 따른 AR 시스템에 지시하기 위해 사용되는 다른 제스처를 도시한다. 도 5c는 일부 예들에 따른 AR 시스템의 다른 가상 키보드 사용자 인터페이스를 도시한다. 도 6a는 일부 예들에 따른 AR 시스템의 다른 핸드-트래킹된 키보드 프로세스의 시퀀스 다이어그램이다. 도 6b는 일부 예들에 따른 AR 시스템에 지시하기 위해 사용되는 다른 제스처를 도시한다. 도 6c는 일부 예들에 따른 AR 시스템의 다른 가상 키보드 사용자 인터페이스를 도시한다. 도 7은 일부 예들에 따른, 본 개시내용이 구현될 수 있는 소프트웨어 아키텍처를 도시하는 블록도이다. 도 8은 일부 예들에 따른, 머리 착용형 AR 시스템의 세부사항들을 포함하는 네트워크화된 시스템을 도시하는 블 록도이다.도 9는 일부 예들에 따른 네트워크를 통해 데이터(예를 들어, 메시지들 및 연관된 콘텐츠)를 교환하기 위한 예 시적인 메시징 시스템을 도시하는 블록도이다."}
