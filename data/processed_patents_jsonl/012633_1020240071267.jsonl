{"patent_id": "10-2024-0071267", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0173608", "출원번호": "10-2024-0071267", "발명의 명칭": "민간용 자동차의 보조 시스템을 교정하기 위한 방법", "출원인": "스플린랩 게엠베하", "발명자": "보러 4세, 존 제이"}}
{"patent_id": "10-2024-0071267", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "민간용 자동차(civilian motor vehicle)의 보조 시스템을 교정하기 위한 방법으로서, - 이미지 센서 좌표계에서, 민간용 자동차 상에 배열된 카메라 디바이스에 의해 상기 민간용 자동차의 주변(surroundings)에 대한 이미지 데이터를 캡처하는 단계;- 민간용 자동차 상에 배열된 깊이 센서 디바이스에 의해 상기 민간용 자동차의 주변에 대한 깊이 데이터를 캡처하는 단계 ― 상기 깊이 데이터는, 깊이 센서 좌표계에서, 상기 민간용 자동차와 상기 민간용 자동차의 주변에 있는 객체들 사이의 제1 거리들을 표시함 ―; - 데이터 프로세싱 디바이스에서의 인공 지능에 기반한 이미지 분석에 의해, 상기 이미지 데이터로부터, 상기민간용 자동차와 상기 이미지 데이터에 표현된 상기 민간용 자동차의 주변에 있는 객체들 사이의 제2 거리들을도출하고, 3-차원 이미지 센서 좌표계에서, 상기 이미지 데이터 및 상기 제2 거리들로부터 3-차원 이미지 데이터를 생성하는 단계;- 상기 데이터 프로세싱 디바이스에서 상기 이미지 데이터와 상기 깊이 데이터를 서로에 대해 교정하는 단계 ―상기 교정하는 단계는,- 상기 제1 거리들 및 상기 제2 거리들의 좌표들이 상기 깊이 센서 좌표계에서 일치하도록, 상기 3-차원 이미지데이터가 상기 깊이 센서 좌표계로 변환되거나;- 상기 제1 거리들 및 상기 제2 거리들의 좌표들이 상기 3-차원 이미지 센서 좌표계에서 일치하도록, 상기 깊이데이터가 상기 3-차원 이미지 센서 좌표계로 변환되거나; 또는- 상기 제1 거리들 및 상기 제2 거리들의 좌표들이 미리 결정된 좌표계에서 일치하도록, 상기 3-차원 이미지 데이터 및 상기 깊이 데이터가 상기 미리 결정된 좌표계로 변환됨으로써, 변환 규칙을 결정하는 단계를 포함함―; 및- 상기 데이터 프로세싱 디바이스에 의해 후속하여 획득된 이미지 데이터 및/또는 깊이 데이터에 상기 변환 규칙을 적용하는 단계를 포함하는, 민간용 자동차의 보조 시스템을 교정하기 위한 방법."}
{"patent_id": "10-2024-0071267", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 변환 규칙은 좌표 변환을 위한 행렬을 특정하는, 민간용 자동차의 보조 시스템을 교정하기 위한 방법."}
{"patent_id": "10-2024-0071267", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항 또는 제2 항에 있어서, 상기 이미지 데이터와 상기 깊이 데이터를 서로에 대해 교정하는 단계는 실시간으로 연속적으로 수행되는, 민간용 자동차의 보조 시스템을 교정하기 위한 방법."}
{"patent_id": "10-2024-0071267", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항 또는 제2 항에 있어서, 상기 변환 규칙을 적용함으로써 변환된 이미지 데이터 및/또는 상기 변환 규칙을 적용함으로써 변환된 깊이 데이터를 서로 또는 상기 변환 규칙이 적용되지 않는 나머지 이미지 데이터 또는 깊이 데이터와 융합시키는 단계를 포함하며, 일치하는 좌표들을 갖는 거리들 및 이미지 픽셀들이 서로 할당되는, 민간용 자동차의 보조 시스템을 교정하기 위한 방법."}
{"patent_id": "10-2024-0071267", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2024-0173608-3-제4 항에 있어서, 상기 융합된 데이터는 상기 민간용 자동차의 운전자 보조 시스템에서 사용되는, 민간용 자동차의 보조 시스템을교정하기 위한 방법."}
{"patent_id": "10-2024-0071267", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항 또는 제2 항에 있어서, 상기 후속하여 획득된 이미지 데이터에 상기 변환 규칙을 적용하는 것은 상기 변환 규칙의 2-차원 투영(projection)을 적용하는 것을 포함하고, 깊이 데이터에 상기 변환 규칙을 적용하는 것은 상기 변환 규칙을 적용하기 이전에 또는 적용한 이후에 상기 깊이 데이터가 2-차원 투영을 겪게 하는 것을 포함하는, 민간용 자동차의 보조 시스템을 교정하기 위한 방법."}
{"patent_id": "10-2024-0071267", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항 또는 제2 항에 있어서, 상기 방법은 상기 민간용 자동차의 주행 이동 동안 수행되는, 민간용 자동차의 보조 시스템을 교정하기 위한 방법."}
{"patent_id": "10-2024-0071267", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항 또는 제2 항에 있어서, 상기 방법은 교정 표준의 사용 없이 수행되는, 민간용 자동차의 보조 시스템을 교정하기 위한 방법."}
{"patent_id": "10-2024-0071267", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항 또는 제2 항에 있어서, 상기 깊이 데이터는 라이다 측정 디바이스, 비행 시간 측정 디바이스 및 레이더 측정 디바이스의 그룹으로부터상기 민간용 자동차 상에 배열된 적어도 하나의 깊이 센서 디바이스에 의해 캡처되는, 민간용 자동차의 보조 시스템을 교정하기 위한 방법."}
{"patent_id": "10-2024-0071267", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항 또는 제2 항에 있어서, 상기 이미지 데이터는 비디오 이미지 카메라 디바이스, 열 이미지 카메라 디바이스 및 적외선 카메라 디바이스의 그룹으로부터 상기 민간용 자동차 상에 배열된 적어도 하나의 카메라 디바이스에 의해 캡처되는, 민간용 자동차의 보조 시스템을 교정하기 위한 방법."}
{"patent_id": "10-2024-0071267", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1 항 또는 제2 항에 있어서, 상기 이미지 데이터로부터, 상기 민간용 자동차와 상기 이미지 데이터에 표현된 상기 민간용 자동차의 주변에있는 객체들 사이의 거리들을 도출할 때, 상기 이미지 분석은 뉴럴 네트워크, 특히 단일깊이(monodepth) 네트워크 형태의 인공 지능에 기반하는, 민간용 자동차의 보조 시스템을 교정하기 위한 방법."}
{"patent_id": "10-2024-0071267", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1 항 또는 제2 항에 있어서, 추가 이미지 센서 좌표계에서, 상기 민간용 자동차 상에 배열된 추가 카메라 디바이스에 의해 상기 민간용 자동차의 주변에 대한 추가 이미지 데이터를 캡처하는 단계를 포함하는, 민간용 자동차의 보조 시스템을 교정하기위한 방법."}
{"patent_id": "10-2024-0071267", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1 항 또는 제2 항에 있어서, 공개특허 10-2024-0173608-4-민간용 자동차 상에 배열된 추가 깊이 센서 디바이스에 의해 상기 민간용 자동차의 주변에 대한 추가 깊이 데이터를 캡처하는 단계를 포함하며, 상기 추가 깊이 데이터는, 추가 깊이 센서 좌표계에서, 상기 민간용 자동차와상기 민간용 자동차의 주변에 있는 객체들 사이의 거리들을 표시하는, 민간용 자동차의 보조 시스템을 교정하기위한 방법."}
{"patent_id": "10-2024-0071267", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "민간용 자동차로서,- 카메라 디바이스;- 깊이 센서 디바이스; 및- 데이터 프로세싱 디바이스를 포함하며,상기 민간용 자동차는 제1 항에 따른 방법을 수행하도록 구성되는, 민간용 자동차."}
{"patent_id": "10-2024-0071267", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "민간용 자동차의 보조 시스템을 교정하기 위한 방법이 제공된다. 방법은, 이미지 센서 좌표계에서, 카메라 디바 이스에 의해 민간용 자동차의 주변에 대한 이미지 데이터를 캡처하는 단계; 깊이 센서 디바이스에 의해, 민간용 자동차와 주변에 있는 객체들 사이의 제1 거리들을 표시하는 깊이 데이터를 캡처하는 단계; 데이터 프로세싱 디 바이스에서의 인공 지능에 기반한 이미지 분석에 의해, 민간용 자동차와 이미지 데이터에 표현된 객체들 사이의 제2 거리들을 도출하고, 3-차원 이미지 센서 좌표계에서, 이미지 데이터 및 제2 거리들로부터 3-차원 이미지 데 이터를 생성하는 단계; 변환 규칙을 결정하는 단계를 포함하는, 데이터 프로세싱 디바이스에서 이미지 데이터와 깊이 데이터를 서로에 대해 교정하는 단계; 및 데이터 프로세싱 디바이스에 의해 후속하여 획득된 이미지 데이터 및/또는 깊이 데이터에 변환 규칙을 적용하는 단계를 포함한다. 추가로, 민간용 자동차가 제공된다."}
{"patent_id": "10-2024-0071267", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은, 민간용 자동차(civilian motor vehicle)의 보조 시스템을 교정하기 위한 방법에 관한 것이다."}
{"patent_id": "10-2024-0071267", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "도로 교통에서의 안전성을 증가시키기 위해, 민간용 자동차들은 점점 더 깊이 데이터를 측정 및 분석하기 위한 디바이스들을 갖는다. 깊이 데이터는 특히 자동차 주변의 객체들을 검출하기 위해 사용되고, 예컨대 주차 보조 의 맥락에서, 자율 주행을 지원하고 사고들을 회피하는 운전자 보조 시스템들에 통합될 수 있다. 깊이 데이터 는 깊이 센서들에 의해 측정된다. 종래의 깊이 센서들의 예들은 라이다(lidar)(광 검출 및 레인징(ranging)) 및 레이더(radar)이다. 깊이 데이터에 부가하여, 민간용 자동차들에서의 이미지 데이터의 사용이 또한 알려져 있다. 이미지 데이터는 개별적인 정지 이미지들의 형태로 또는 또한 연속적인 이미지 시퀀스들(비디오)의 형태로 획득된다. 하나 이상 의 카메라들이 이미지들을 기록하기 위해 자동차 상에서 사용될 수 있다. 이미지 데이터는 운전자의 시계 (field of vision)를 보완 또는 개선하기 위해 사용될 수 있다. 특히, 깊이 데이터를 이미지 데이터와 결합하 고 이들을 운전자에게 디스플레이하는 것이 알려져 있다. 예로서, 운전자에게 위험한 상황들을 경고하기 위해, 더 가까운 객체들이 디스플레이된 표현에서 강조될 수 있다. 이미지 데이터와 깊이 데이터를 결합하기 위해, 이들은 교정되어야 한다. 알려진 교정 방법은 자동차로부터 알 려진 거리에 알려진 치수들을 갖는 객체를 제공하는 단계를 포함한다. 객체는 자동차의 깊이 센서들 및 카메라 들에 의해 기록된다. 후속하여, 이미지 데이터 및 깊이 데이터를 분석하기 위한 소프트웨어는, 기록된 객체의 특징들, 예컨대 에지들 및 코너들이 이미지 데이터 및 깊이 데이터에서 서로 연관될 수 있는 방식으로 세팅된다. 본 발명의 목적은 민간용 자동차의 보조 시스템을 교정하기 위한 방법을 제공하는 것이다. 이를 달성하기 위해, 독립 청구항 제1 항에 따른, 민간용 자동차의 보조 시스템을 교정하기 위한 방법이 제공된 다. 추가로, 독립 청구항 제14 항에 따른 민간용 자동차가 제공된다. 실시예들은 종속 청구항들의 청구 대상 이다. 일 양상에 따르면, 민간용 자동차의 보조 시스템을 교정하기 위한 방법이 제공되며, 방법은, 이미지 센서 좌표 계에서, 민간용 자동차 상에 배열된 카메라 디바이스에 의해 민간용 자동차의 주변(surroundings)에 대한 이미 지 데이터를 캡처하는 단계; 민간용 자동차 상에 배열된 깊이 센서 디바이스에 의해 민간용 자동차의 주변에 대 한 깊이 데이터를 캡처하는 단계 ― 깊이 데이터는, 깊이 센서 좌표계에서, 민간용 자동차와 민간용 자동차의 주변에 있는 객체들 사이의 제1 거리들을 표시함 ―; 데이터 프로세싱 디바이스에서의 인공 지능에 기반한 이미 지 분석에 의해, 이미지 데이터로부터, 민간용 자동차와 이미지 데이터에 표현된 민간용 자동차의 주변에 있는 객체들 사이의 제2 거리들을 도출하고, 3-차원 이미지 센서 좌표계에서, 이미지 데이터 및 제2 거리들로부터 3-차원 이미지 데이터를 생성하는 단계; 데이터 프로세싱 디바이스에서 이미지 데이터와 깊이 데이터를 서로에 대 해 교정하는 단계 ― 교정하는 단계는, 제1 거리들 및 제2 거리들의 좌표들이 깊이 센서 좌표계에서 일치하도록, 3-차원 이미지 데이터가 깊이 센서 좌표계로 변환되거나; 제1 거리들 및 제2 거리들의 좌표들이 3- 차원 이미지 센서 좌표계에서 일치하도록, 깊이 데이터가 3-차원 이미지 센서 좌표계로 변환되거나; 또는 제1 거리들 및 제2 거리들의 좌표들이 미리 결정된 좌표계에서 일치하도록, 3-차원 이미지 데이터 및 깊이 데이터가 미리 결정된 좌표계로 변환됨으로써, 변환 규칙을 결정하는 단계를 포함함 ―; 및 데이터 프로세싱 디바이스에 의해 후속하여 획득된 이미지 데이터 및/또는 깊이 데이터에 변환 규칙을 적용하는 단계를 포함한다. 이미지 데이터는 통상적으로 래스터(raster) 포맷으로 존재한다. 이미지 센서 좌표계는 2-차원이다. 그 원점 은, 예컨대, 래스터(또는 그리드)의 코너들 중 하나에, 래스터의 중심에, 또는 래스터 내의 미리 정의된 임의의 포인트에 있을 수 있다. 이미지 센서 좌표계의 수평 축은 카메라 디바이스의 수평 배향에 대응할 수 있고, 수 직 축은 수직 배향에 대응할 수 있다. 깊이 데이터는 3-차원이며, 포인트 클라우드 및/또는 벡터 데이터의 집합(collection)으로서 존재한다. 특히, 깊이 데이터는 라인들의 형태로 존재할 수 있으며, 라인 상의 모든 포인트들은 관찰자로부터 또는 깊이 센서로 부터 동일한 거리를 갖는다. 깊이 센서 좌표계의 원점은 깊이 센서의 위치에 대응할 수 있다. 수평 및 수직 축은 깊이 센서의 수평 및 수직 배향에 대응할 수 있고, 제3 축은 그 광학 축에 대응할 수 있다. 민간용 자동차와 이미지 데이터에 표현된 객체들 사이의 거리들을 도출할 때, 2-차원 데이터로부터 3-차원 데이 터가 생성된다. 이러한 목적을 위해 바람직하게 사용되는 인공 지능은, 예컨대, 2-차원 래스터에서의 각각의 픽셀에 대해, 이미지 센서 좌표계의 원점으로부터 특정 거리를 결정하기 위해 트레이닝 데이터에 의해 트레이닝 된 뉴럴 네트워크이다. 이는, 스테레오 기록들에 기초하여(2 개 이상의 카메라 디바이스들을 사용할 때) 또는 이미지 시퀀스의 연속적인 이미지들의 변화들에 기초하여 객체들의 거리들(간격)을 결정하는 것, 또는 거리를 결정하기 위해 다른 조치(measure)들을 취하는 것 또는 이들을 전술된 조치들과 결합하는 것을 포함할 수 있다. 도출된 거리들은 2-차원 데이터와 동일한 단위들, 예컨대 픽셀당 미터로 존재할 수 있다. 대안적으로, 이들은 다른 단위들로 존재할 수 있거나, 또는 그렇지 않으면, 2-차원 데이터와 비교하여, 확대된 또는 축소된 표현으 로 존재할 수 있지만; 두 경우들 모두에서, 거리 값들은 서로 합동(congruent)이며, 간격 관계들을 정확하게 재 현한다. 거리 값들이 2-차원 데이터와 합동이 될 수 있게 하는 컨버전 팩터가 설정 또는 결정될 수 있다. 서로에 대한 이미지 데이터와 깊이 데이터의 실제 교정은, 데이터 둘 모두의 포인트들, 벡터들, 라인들 및/또는 객체들을 서로 할당하고, 따라서 후속하여 기록된 데이터, 즉 이미지 데이터 또는 깊이 데이터에 적용될 수 있 는 규칙을 생성하여, 이들을 서로 매핑하는, 예컨대 이들을 중첩시키고 이들을 운전자에게 디스플레이하는 목적 을 위해 사용된다. 이와 관련하여, 본 개시내용의 의미에서, 거리들의 좌표들의 매칭은, 개개의 거리들이 끝나 는 좌표 포인트들(이들은 서로 대응하고 이로써 서로 할당됨)이 일치하는 것을 의미하는 것으로 이해되어야 한 다. 일 실시예에서, 교정하는 단계는 초기에, 이미지 데이터 및 깊이 데이터의 결정된 거리들로부터 매칭 특성 객체 섹션들을 결정하는 단계를 포함한다. 객체 섹션은, 예컨대, 객체들의 코너들 또는 에지들의 3-차원 좌표들, 또 는 그렇지 않으면, 개별적인 현저한 포인트들 또는 완전한 객체들을 포함한다. 특성 객체 섹션은, 특히 이미지 데이터 및/또는 깊이 데이터에서 객체를 표현하고 객체의 형상을 적어도 부분적으로 정의하기에 충분할 수 있는 객체의 그 부분이다. 특성 객체 섹션들의 예들은, 평면 표면들에 의해 한정되는 입방체, 직육면체 또는 다른 기하학적 바디의 코너들을 포함하고; 이러한 예들에서, 코너들은 에지들보다 그리고 바디 표면들의 개별적인 포 인트들 또는 부분들보다 더 특성적이다. 구체들 또는 일반적인 회전체들 또는 임의의 유기적 형상들의 경우, 특성 객체 섹션들은 이들의 윤곽들에 의해 또는 이들의 부분들에 의해 주어질 수 있다. 매칭 특성 객체 섹션들 은, 미리-정의된 허용오차 값 내에서 서로 매핑될 수 있고, 따라서, 높은 확률로 동일한 객체 또는 객체의 동일 한 부분을 표현하는 데이터 세트들 둘 모두의 특성 객체 섹션들이다. 변환 규칙은 적어도 3 개의 실시예들 중 하나에 의해 결정될 수 있다. 제1 실시예에서, 3-차원 이미지 데이터 는, 3-차원 이미지 데이터로부터의 제2 거리들이 깊이 데이터로부터의 거리들과 일치하는 방식으로 변환된다. 따라서, 변환 규칙은 데이터 둘 모두의 거리들에 기초하여 3-차원 공간에서 먼저 결정되고, 이어서, 2-차원 공 간으로 투영되고, 후속하여 추가 이미지 데이터에 적용된다. 여기서 적용되는 변환들은 병진(translation), 회 전(rotation), 전단(shearing), 스케일링(scaling) 등을 포함할 수 있다. 변환 규칙이 적용될 때, 깊이 센서 좌표계가 2 개의 차원들에 투영된 이후에, 이미지 데이터는 이 깊이 센서 좌표계로 변환된다. 위에서 설명된 특성 객체 섹션들의 결정을 포함하는 실시예들에서, 변환 규칙은 이미지 데이터의 거리들 대신에 특성 객체 섹션들에 기초하여 결정되고, 특성 객체 섹션들은 깊이 센서 데이터의 대응하는 좌표들과 부합하게 된다. 제2 실시예에서, 3-차원 깊이 데이터는, 3-차원 이미지 데이터로부터의 거리들이 깊이 데이터의 거리들과 일치 하는 방식으로 변환된다. 여기서, 깊이 데이터는 3-차원 이미지 데이터 좌표계에 매핑된다. 특성 객체 섹션들 을 갖는 실시예들에서, 거리들 대신에, 결정된 객체 섹션들은 깊이 데이터의 대응하는 좌표들과 부합하게 된다. 제3 실시예에서, 3-차원 이미지 데이터 및 깊이 데이터는 미리 결정된 좌표계로 변환되고, 이미지 센서 및 깊이 센서 좌표계의 거리들의 좌표들, 대안적으로 일 실시예에서 좌표계들 둘 모두의 특성 객체 섹션들은 미리 결정 된 좌표계에서 일치한다. 일 실시예에서, 미리 결정된 좌표계는 마찬가지로 3-차원이고; 일 실시예에서, 미리 결정된 좌표계는 2-차원이고, 변환 규칙은, 예컨대 투영에 의해, 2 개의 3-차원 좌표계들로부터 2-차원 공간으 로 매핑한다. 미리 결정된 좌표계는 사용자에 의해, 예컨대 디스플레이된 이미지 데이터에서 이미지 섹션을 선 택함으로써 미리 정의될 수 있다. 대안적으로, 미리 결정된 좌표계는, 예컨대 미리 결정된 좌표계의 원점으로 서 좌표계들 둘 모두의 오버랩의 중심을 결정함으로써, 3-차원 이미지 센서 좌표계 및 깊이 센서 좌표계의 평균 으로서 자동으로 생성될 수 있다. 일 실시예에서, 3-차원 공간에서 변환 규칙을 결정하는 것은, 깊이 데이터로부터의 포인트들을 2-차원 이미지 센서 좌표계로 투영하는 것, 및 이들을 이미지 데이터의 포인트 또는 객체에 할당하여 데이터 세트들 둘 모두의 데이터의 대응들을 결정하는 것을 포함할 수 있다. 할당은 데이터 세트들 둘 모두의 포인트들/객체들의 특정 유사성들, 예컨대 유사한 밝기 값들, 이웃들에서의 유사한 밝기 값들, 유사한 컬러 값들, 이웃들에서의 유사한 컬러 값들에 기초하여 수행될 수 있다. 할당은 깊이 데이터의 각각의 포인트에 대해 반복적으로 수행될 수 있 다. 반복들은 또한, 할당을 가속하기 위해, 서로 독립적으로 그리고 그에 따라 병렬로 수행될 수 있다. 이러한 방식으로 결정된 변환 규칙은 바람직하게는 행렬(변환 행렬)이다. 결국, 행렬은 복수의 행렬들의 곱 (product)일 수 있으며, 복수의 행렬들 각각은 변환, 예컨대 회전, 스케일링, 전단을 정의한다. 행렬은 애플리 케이션에 따라 2-차원 또는 3-차원 변환들을 수행할 수 있다. 3-차원의 경우, 행렬은 3 차원에 대한 파라미터 들/계수들에 의해 확장될 수 있고; 3 개의 차원들로의 변환을 위한 변환 행렬들에 대한 관련 포맷들은 당업자에 게 알려져 있다. 변환 행렬이 알려져 있는 경우, 데이터 둘 모두의 추가 분석들을 수행하기 위해 또는 데이터를 결합된 형태로 디스플레이하기 위해, 이는 후속하여 획득된 이미지 데이터 및/또는 깊이 데이터에 적용될 수 있다. 일 예에서, 관찰자에게 특정 객체들의 거리에 대한 인상을 주기 위해 데이터가 중첩되어 디스플레이될 수 있다. 대안적으로, 이미지 데이터의 객체들은 더 가까운 객체들로 관찰자의 주의를 끌고 더 멀리 있는 객체들로부터 관찰자를 산만하게 하지 않기 위해 이들의 더 작은 또는 더 큰 거리에 기초하여 강조되거나 또는 감쇠될 수 있 다. 이러한 목적을 위해, 상이한 세기들 또는 컬러들이 사용될 수 있으며: 예컨대, 더 멀리 있는 객체들보다 더 가까운 객체들에 대해 더 강한 세기 및/또는 컬러가 사용될 수 있거나, 또는 그 반대로도 마찬가지이다. 서로에 대한 이미지 데이터와 깊이 데이터의 교정은 실시간으로 연속적으로 수행될 수 있다. 대안적으로, 교정 은 규칙적인 간격들로 또는 미리 정의된 시간들에 수행될 수 있다. 일 실시예에서, 조명 조건들이 실질적으로 변화하면, 교정이 수행될 수 있다. 예컨대, 방법은 주변의 밝기를 연속적으로 측정하는 단계를 포함할 수 있고, 밝기가 미리 정의된 임계 값 미만으로 떨어지거나 (또는 다른) 임계 값을 초과하여 상승하면 교정을 반복 할 수 있다. 일 실시예에서, 복수의 변환 규칙들은 상이한 조명 조건들에서 결정될 수 있고; 밝기에 따라, 개 개의 변환 규칙이 이미지 데이터 및/또는 깊이 데이터에 적용된다. 방법은, 변환 규칙을 적용함으로써 변환된 이미지 데이터 및/또는 변환 규칙을 적용함으로써 변환된 깊이 데이 터를 서로 또는 변환 규칙이 적용되지 않는 나머지 이미지 데이터 또는 깊이 데이터와 융합시키는 단계를 포함 할 수 있으며, 일치하는 좌표들을 갖는 거리들 및 이미지 픽셀들이 서로 할당된다. 데이터를 융합시키는 것은, 예컨대 세기 또는 컬러 값들의 가산 또는 감산에 의해 중첩시키는 것을 포함할 수 있다. 대안적으로, 이미지 데이터의 개별적인 객체들은 이미 설명된 바와 같이 깊이 데이터에 따라 이들의 거리에 기초하여 강조되거나 또 는 감쇠될 수 있다. 특히, 융합된 데이터는 민간용 자동차의 운전자 보조 시스템에서 사용된다. 이는 데이터를 디스플레이하는 것 또는 또한 미리 결정된 최소 거리 내에 있는 객체들을 결정하는 것을 포함할 수 있다. 일 실시예에서, 객체가 자동차에 너무 근접하게 검출되면, 경고가 디스플레이될 수 있다. 이러한 경고는 관련 객체의 디스플레이 및 표시를 포함할 수 있다. 특정 실시예들에서, 특성 객체 섹션들이 결정된다. 이미지 데이터 및 깊이 데이터에서 매칭 특성 객체 섹션들 을 결정하는 것은 이미지 최적화 알고리즘에 의해 이미지 데이터를 최적화하는 것을 포함할 수 있다. 최적화는 특정 필터 동작들의 적용, 예컨대 에지 검출기들, 콘트라스트 필터들, 이미지 잡음을 억제하기 위한 필터들의 적용을 포함할 수 있다. 이러한 방식으로 필터링된 데이터는, 예컨대 로컬 또는 글로벌 최대치/최소치에 대한 세그먼트화 및/또는 분석에 의해 응집 픽셀(cohesive pixel)들에 대해 추가로 조사될 수 있다. 유사하게, 이미 지 데이터 및/또는 깊이 데이터는 또한, 특성 객체 섹션들의 사용 없이, 언급된 필터 동작들을 겪을 수 있다. 2-차원 이미지 데이터로부터 3-차원 이미지 데이터를 생성하고, 이미지 데이터로부터, 민간용 자동차와 이미지 데이터에 표현된 민간용 자동차의 주변의 객체들 사이의 결정된 거리들을 생성하는 것은, 제3 정보로서 이미 존 재하는 2-차원 이미지 데이터에 대한 제3 차원으로서 민간용 자동차로부터의 개개의 거리를 가산하는 것을 포함 할 수 있다. 3-차원 포인트 클라우드가 산출되며, 포인트들 각각은 대응하는 이미지 포인트의 세기 및/또는 컬 러와 연관된다. 후속하여 획득된 이미지 데이터에 변환 규칙을 적용하는 것은 변환 규칙의 2-차원 투영을 적용하는 것을 포함할 수 있다. 추가로, 깊이 데이터에 변환 규칙을 적용하는 것은 변환 규칙을 적용하기 이전에 또는 적용한 이후에 깊이 데이터가 2-차원 투영을 겪게 하는 것을 포함할 수 있다. 방법은 민간용 자동차의 주행 이동 동안 수행될 수 있다. 특히, 방법은 교정 표준의 사용 없이 수행될 수 있다. 그러한 교정 표준을 이용하면, 민간용 자동차로부터의 이전에 알려진 거리 및 이전에 알려진 치수들을 갖는 객체에 기초하여 당업자가 교정할 것이다. 위에서 설명된 바와 같이, 본 발명은 이미지 데이터 및 깊이 데이터에서 결정 또는 측정된 거리들, 일부 실시예들에서 대안적으로 특성 객체 섹션들을 결정하는 것, 및 이들 을 서로 자동으로 매핑하는 것을 포함하기 때문에, 본 발명에 의해 그러한 객체를 제공할 필요성이 생략된다. 따라서, 임의의 치수들 및 거리들을 갖는 임의의 객체들 및 임의의 주변이 사용될 수 있다. 부가하여, 교정 방 법은, 미리 결정된 주변을 셋업하거나 또는 방문할 필요 없이 임의의 시간에 반복될 수 있다. 깊이 데이터는 라이다 측정 디바이스, 비행 시간 측정 디바이스 및 레이더 측정 디바이스의 그룹으로부터 민간 용 자동차 상에 배열된 적어도 하나의 깊이 센서 디바이스에 의해 캡처될 수 있다. 특히, 이미지 데이터는 비 디오 이미지 카메라 디바이스, 열 이미지 카메라 디바이스 및 적외선 카메라 디바이스의 그룹으로부터 민간용 자동차 상에 배열된 적어도 하나의 카메라 디바이스에 의해 캡처될 수 있다. 이미지 데이터로부터, 민간용 자동차와 이미지 데이터에 표현된 민간용 자동차의 주변에 있는 객체들 사이의 거 리들을 도출할 때, 이미지 분석은 뉴럴 네트워크, 특히 단일깊이(monodepth) 네트워크 형태의 인공 지능에 기반 할 수 있다. 민간용 자동차의 주변에 대한 추가 이미지 데이터는, 추가 이미지 센서 좌표계에서, 민간용 자동차 상에 배열된 추가 카메라 디바이스에 의해 캡처될 수 있다. 복수의 카메라 디바이스들의 이미지 데이터를 사용할 때, 교정 단계들은 다음과 같이 수행될 수 있다. 먼저, 추가 카메라 디바이스의 이미지 데이터가 제2 이미지 데이터로서 캡처된다. 이러한 이미지 데이터 상에서, 민간용 자동차와 제2 이미지 데이터에 표현된 객체들 사이의 거리들 을 도출하기 위한 단계들은 위에서 설명된 도출과 유사하게 수행된다. 제1 실시예에서, 제2 이미지 데이터는 후속하여, 매칭 거리들을 결정함으로써, 일 실시예에서 대안적으로 또는 부가적으로 특성 객체 섹션들을 결정하 고, 변환 규칙을 결정함으로써, 제1 카메라 디바이스의 이미지 데이터로 교정되고; 제1 이미지 데이터 및 깊이 데이터에 기초하여 수행되는 이전에 설명된 단계들 대신에, 교정은 이제, 유사하게 제1 및 제2 이미지 데이터를 사용한다. 제2 실시예에서, 제2 이미지 데이터는 대신에 깊이 데이터로 교정되고; 이전에 설명된 단계들 대신 에, 교정은 이제, 유사하게 제2 이미지 데이터 및 깊이 데이터를 사용한다. 제3 실시예에서, 제2 이미지 데이 터는 제1 이미지 데이터 및 깊이 데이터로 연속적으로 교정된다. 따라서, 이러한 실시예들 각각에서, 후속하여 획득된 (제1 및 제2) 이미지 데이터 및/또는 깊이 데이터에 적용될 수 있는 적어도 하나의 변환 규칙이 결정된 다. 따라서, 그러한 변환 규칙들을 이용하여, 깊이 데이터로 이미지 데이터를 교정하는 것뿐만 아니라, 하나 초과의 소스로부터의 이미지 데이터를 교정하는 것이 가능하며, 이는 결국 깊이 데이터로 교정된다. 민간용 자동차 상에 배열된 추가 깊이 센서 디바이스에 의해 민간용 자동차의 주변에 대한 추가 깊이 데이터가 캡처될 수 있으며, 추가 깊이 데이터는, 추가 깊이 센서 좌표계에서, 민간용 자동차와 민간용 자동차의 주변에 있는 객체들 사이의 거리들을 표시한다. 따라서, 복수의 (제1 및 제2) 이미지 데이터에 대해 위에서 설명된 예 와 유사하게, 교정은 이미지 데이터 및 깊이 데이터 및 추가 깊이 데이터에 기초하여 수행될 수 있다. 여기서, 역시, 예컨대, 깊이 데이터와 추가 깊이 데이터 사이에서, 이미지 데이터와 추가 깊이 데이터 그리고 모든 3 개 의 데이터의 조합 사이에서, 복수의 변환 규칙들이 결정될 수 있다.여기서 개시되는 본 발명의 추가 양상은 부가적으로, 카메라 디바이스; 깊이 센서 디바이스; 및 데이터 프로세 싱 디바이스를 갖는 민간용 자동차에 관한 것이고, 민간용 자동차는 여기서 설명되는 방법들 중 하나 이상을 수 행하도록 구성된다. 민간용 자동차의 보조 시스템을 교정하기 위한 방법과 관련하여 위에서 설명된 실시예들은 대응적으로 민간용 자동차에 제공될 수 있고, 그 반대로도 마찬가지이다."}
{"patent_id": "10-2024-0071267", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 민간용 자동차의 보조 시스템을 교정하기 위한 알려진 방법에 대한 개략도를 도시한다. 단계에서, 민간용 자동차에 부착된 카메라 디바이스에 의해 이미지 데이터가 결정된다. 이러한 이미지 데이터는 특정 이 미지 특징들을 결정하기 위해 단계에서 밝기/세기 분석을 겪는다. 이러한 이미지 특징들은, 예컨대, 이미 징된 객체들의 에지들 또는 코너들이다. 단계는 예컨대 라이다 카메라 디바이스에 의한 3-차원 거리 데이터의 획득에 관한 것이다. 거리 데이터는 예컨대 포인트 클라우드의 형태로 존재하며, 마찬가지로 단계에서 밝기/세기 분석을 겪는다. 이는 일반적 으로 초기에, 거리 데이터의 2-차원 이미지 데이터로의 감소를 포함하고; 이어서, 이러한 2-차원 이미지 데이터 에서, 단계와 유사하게, 특징들이 검출된다. 단계에서, 데이터 세트들 둘 모두에 포함되고 따라서 서로 할당될 수 있는 그러한 특징들은 각각 검출된 특징들에서 결정된다. 이러한 할당들로부터, 단계에서, 이미지 데이터가 2-차원적으로 감소된 거리 데이 터에 매핑될 수 있게 하는 함수가 결정된다. 후속하여, 이 함수는 후속 이미지 데이터를 변환하기 위해 사용될 수 있다. 그러한 변환의 결과는, 이미지 데이터에 포함된 객체들의 거리들을 디스플레이 및/또는 강조하기 위 해 거리 데이터와 결합될 수 있다. 도 2는 민간용 자동차의 보조 시스템을 교정하기 위한 본 발명에 따른 방법에 대한 개략도를 도시한다. 단계 에서, 방법은 민간용 자동차에 부착된 카메라 디바이스에 의해 2-차원 이미지 데이터를 캡처한다. 이러한 이미지 데이터로부터, 단계에서 민간용 자동차와 이미지 데이터에 표현된 객체들 사이의 거리들이 도출되 고, 이러한 방식으로 3-차원 데이터가 생성된다. 도출은 바람직하게는, 인공 지능에 기반한 이미지 분석에 의 해, 특히, 특정 이미지 특징들로부터 개개의 객체들 또는 이들의 픽셀들의 거리들에 관한 정보를 도출하는 뉴럴 네트워크를 사용하여 수행된다. 도출은, 예컨대 민간용 자동차의 탑재형 전자장치의 컴포넌트이거나 또는 원격 서버 상에 수용되고 라디오를 통해 프로세싱을 위한 이미지 데이터를 수신하는 데이터 프로세싱 디바이스에 의 해 수행된다. 단계의 결과로서, 3-차원 이미지 데이터가 존재하며, 3-차원 이미지 데이터의 제3 차원은 결정된 거리들에 의해 주어진다. 일 실시예에서, 단계에서, 도출된 거리들로부터 그리고 선택적으로 또한 기본 이미지 데이터로부터 특성 객체 섹션들이 결정된다. 일 실시예에서, 단계는 방법에 절대적으로 필요한 것은 아니다. 특성 객 체 섹션들은 검출된 객체들의 부분들 또는 그렇지 않으면 완전한 객체들이다. 특성 객체 섹션들은 특히 객체들 의 코너들, 에지들 및/또는 경계 라인들을 포함한다. 특히, 특성 객체 섹션들은 각각, 동일한 객체에 속하는 복수의 좌표들을 포함한다. 이러한 결정은 예컨대 3-차원 에지 검출기들, 연결된 컴포넌트 분석 또는 다른 방 법들, 특히 또한 뉴럴 네트워크들에 의해 수행될 수 있다. 단계에서, 민간용 자동차의 주변에 대한 깊이 데이터가 캡처된다. 이러한 목적을 위해, 라이다 기능을 갖 는 레이저 스캐너 또는 레이더 디바이스가 바람직하게 사용된다. 거리 미터들을 측정하기 위한 각각의 디바이 스는 원칙적으로, 깊이 데이터를 캡처하는 데 적합하다. 깊이 데이터는 3 개의 차원들로 존재한다. 단계와 유사하게, 일 실시예에서, 분석에서 특성 객체 섹션들에 대해 깊이 데이터가 또한 조사된다. 이미 설명된 바와 같이, 이는 동일한 객체에 속하는 좌표들의 그룹들을 결정하는 것을 포함한다. 단계에서, 데이터 세트들 둘 모두의 상호 대응하는 거리들은 3-차원 이미지 데이터 및 깊이 데이터에서의 거리들의 좌표들로부터 결정된다. 이는 데이터 세트들 둘 모두의 상관을 통해 수행될 수 있다. 부가적으로 또 는 대안적으로, 통계적 분석 및/또는 최적화가 수행될 수 있다. 일 실시예에서, 데이터 세트들 둘 모두에서 이 러한 좌표들의 대응들은 변환 정보, 상호 정보 및/또는 시엔트로피(synentropy)에 의해 결정되고 최대화된다. 일 실시예에서, 거리 좌표들 대신에, 데이터 세트들 둘 모두에서 일치하는 그러한 객체 섹션들은 이미지 데이터 및 깊이 데이터로부터 도출된 거리들의 특성 객체 섹션들로서 결정될 수 있다. 예컨대, 하나의 데이터 세트 내 의 응집 좌표들 중 어느 것이다른 데이터 세트의 응집 좌표들과 일치하거나 또는 그에 대응하는지를 상관 방법 들에 의해 결정하는 것이 가능하다. 대응이 미리 결정된 임계 값을 초과하면, 데이터 세트들 둘 모두의 좌표들 은 서로 대응하는 것으로 마킹되거나 또는 그렇지 않으면 함께 저장된다. 단계는 이미지 데이터와 깊이 데이터를 서로 매핑하는 변환 규칙의 결정에 관한 것이다. 일 예에서, 변환 규칙은 이미지 좌표들 및/또는 깊이 좌표들을 상이한 좌표계로 컨버팅하는 하나 이상의 변환 행렬들을 포함한다. 변환 행렬들에 부가하여 또는 대안적으로, 비선형 변환들이 또한 수행될 수 있다. 일 예에서, 이미 지 데이터는 3-차원 이미지 센서 좌표계로부터 깊이 센서 좌표계로 변환된다. 이 변환은, 3-차원 이미지 센서 좌표계에서의 거리들의 3-차원 좌표들이, 변환 이후에, 3-차원 깊이 센서 좌표계에서의 거리 좌표들과 일치한다 는 것을 조건으로 수행된다. 이러한 방식으로 획득된 3-차원 변환 규칙은 2-차원 이미지 데이터에 후속하여 적 용될 수 있는 2-차원 변환 규칙으로 감소될 수 있다. 예컨대, 3-차원 변환 규칙은, 행렬 계수들을 생략함으로 써 2-차원 변환 규칙으로 컨버팅되는 하나 이상의 행렬들에 의해 표현될 수 있다. 비선형 변환 규칙들을 이용 하여 유사한 동작들이 또한 가능하다. 이러한 2-차원 변환 규칙은 이제, 2-차원 이미지 데이터를 깊이 센서 좌 표계로 변환하기 위해 2-차원 이미지 데이터에 적용될 수 있다. 일 실시예에서, 이미지 데이터는 깊이 센서 좌 표계의 2-차원 투영으로 변환될 수 있다. 추가 예에서, 단계는 좌표계들 둘 모두의 거리들의 좌표들이 일치하도록 깊이 데이터를 3-차원 이미지 센 서 좌표계로 변환하는 단계를 포함한다. 이 예에서, 역시, 변환 규칙은 초기에 3-차원이다. 이러한 형태에서, 이는, 후속 깊이 데이터를 후속(2-차원) 이미지 데이터와 부합하게 하기 위해 후속 깊이 데이터에 적용될 수 있 다. 이는, 후속 깊이 데이터를 초기에 3-차원으로 변환하고, 후속하여, 이를 이미지 데이터의 2 개의 차원들에 투영하는 것, 그렇지 않으면, 2-차원적으로 투영된 깊이 데이터에 변환 규칙의 2-차원 투영을 적용하는 것을 포 함할 수 있다. 추가 예에서, 단계는, 이미지 센서 및 깊이 센서 좌표계들의 거리들의 좌표들이 미리 결정된 좌표계에서 일치하도록, 3-차원 이미지 데이터 및 깊이 데이터를 미리 결정된 좌표계로 변환하는 단계를 포함한다. 일 실 시예에서, 미리 결정된 좌표계는 마찬가지로 3-차원이고, 결정된 변환 규칙은 또한 3 개의 차원들로부터 3 개의 차원들로 매핑된다. 대안적으로, 미리 결정된 좌표계는 2-차원일 수 있으며, 변환 규칙은 3 개의 차원들로부터 2 개의 차원들로 매핑된다. 단계에 후속하여, 결정된 변환 규칙은 후속하여 기록된 이미지 데이터 및/또는 깊이 데이터에 적용될 수 있다. 도 3a, 도 3b 및 도 3c는 예시적인 이미지 데이터 및 깊이 데이터를 도시한다. 도 3a는 여기서 그레이스케일 이미지로서 표현된 이미지 데이터(300A)를 도시한다. 각각의 픽셀은 밝기 값을 포함한다. 이미지 데이터는 또 한, 예컨대 RGB 이미지로서 컬러로 표현될 수 있다. 도 3b는 깊이 데이터(300B)를 도시한다. 각각의 픽셀은 기록 디바이스로부터 민간용 자동차의 주변의 개개의 위치의 거리를 정의하는 밝기 값을 포함한다. 예컨대, 더 밝은 값은 더 큰 근접도를 표현할 수 있으며, 그 반대로도 마찬가지이다. 여기서, 깊이 데이터(300B)는 그레이 스케일 이미지로서 도시되지만, 또한, 예컨대 RGB 코딩으로 컬러 데이터를 포함할 수 있다. 거리들은 마찬가지 로 컬러 값들에 의해 표현될 수 있다. 대안적으로, 컬러 값들은 추가 정보, 예컨대 이전에 기록된 깊이 데이터 와 관련된 변화를 코딩할 수 있다. 이미지 데이터(300A) 및 깊이 데이터(300B)에서 객체들, 예컨대 집 외관, 자동차, 사이클리스트 및 보행자가 식 별가능하다. 추가로, 이미지 데이터 및 깊이 데이터는, 카메라 디바이스 및 깊이 센서가 상이하게 배향되고 그리고/또는 상이한 위치들에 부착되기 때문에, 사용되는 기록 디바이스들의 주변의 상이한 섹션들을 보여준다. 도시된 이미지 데이터 및 깊이 데이터는 위에서 설명된 분석을 겪을 수 있으며, 카메라 디바이스와 표현된 객체 들 사이의 거리들은 이미지 데이터로부터 도출되고, 제3 차원으로서 이미지 데이터에 가산된다. 일 실시예에서, 특성 객체 섹션들은 3-차원 이미지 데이터 및 깊이 데이터 둘 모두에서 결정될 수 있다. 후속하여, 좌표계들 둘 모두에서 일치하는 그러한 특성 객체 섹션들이 결정될 수 있다. 이러한 매칭 특성 객체 섹션들로부터, 이미지 데이터 및/또는 깊이 데이터가 개개의 수정된 좌표계로 컨버팅되도록, 이미지 데이터 및/ 또는 깊이 데이터에 후속하여 적용되는 변환 규칙이 결정될 수 있다. 일 예에서, 모든 거리 데이터가 관찰되는 지 또는 단지 특성 객체 섹션들만이 관찰되는지에 관계없이, 결과적인 데이터는 중첩/융합될 수 있다. 그러한 중첩은 이미지(300C)로서 도 3c에 도시된다. 이미지(300C)는 이미지 데이터(300A)의 밝기 값들과 깊이 데이터 (300B)의 밝기 값들 둘 모두를 보여주고; 후자는 깊이 센서로부터의 거리들을 이들의 컬러들 및/또는 밝기 값들 에 의해 표시하는 연속적인 라인들로서 인식될 수 있다. 이미지(300C)로부터 알 수 있는 바와 같이, 기록 디바 이스들의 배향 및 설치 위치의 차이들은, 이미지 데이터 및 깊이 데이터가 정확하게 중첩될 수 있도록 변환 규 칙에 의해 개선되었다. 도 4는 여기서 설명되는 예들에서 사용되는 일부 좌표계들을 예로서 도시한다. 도 4는 카메라 디바이스 및 깊 이 센서 또는 이들이 부착된 민간용 자동차의 주변의 포인트(XL)를 도시한다. 도 4는 3-차원 깊이 센서 좌표계 및 2-차원 이미지 센서 좌표계를 추가로 도시한다. 좌표계에 포함될 수 있는 이미지 데이터로 부터 거리들이 도출되고, 따라서 3-차원 데이터가 생성된다. 이들은 3-차원 좌표계에 의해 표시된다. 일 실시예에서, 개개의 특성 객체 섹션들은 한편으로는 이미지 데이터 및 거리들로부터 그리고 다른 한편으로는 깊 이 데이터로부터 결정될 수 있다. 추가로, 좌표계들(410 및 430)에서 일치하는 그러한 특성 객체 섹션들이 결 정될 수 있다. 좌표계들 둘 모두의 거리 좌표들 또는 특성 객체 섹션들을 서로 매핑하기 위해, 변환 규칙(TCL) 이 결정될 수 있다. 이는 후속하여, 예컨대, 2 개의 치수들로 감소될 수 있고, 결국 이미지 센서 좌표계 에 적용될 수 있다. 결과적인 수정된 이미지 센서 좌표계는 u-축 및 v-축에 대한 좌표계의 x-축 및 y-축의 변 위에 의해 표시된다. 위의 설명, 청구항들 및 도면에 개시된 특징들은 개별적으로 그리고 다양한 실시예들을 구현하기 위한 임의의 원하는 조합에서 둘 모두에서 중요할 수 있다."}
{"patent_id": "10-2024-0071267", "section": "도면", "subsection": "도면설명", "item": 1, "content": "추가 예시적인 실시예들은 도면의 도해들을 참조하여 아래에서 더 상세히 설명된다. 도면들에서: 도 1은 데이터를 교정하기 위한 알려진 방법에 대한 개략도를 도시하고; 도 2는 데이터를 교정하기 위한 본 발명에 따른 방법에 대한 개략도를 도시하고; 도 3a는 이미지 데이터의 예를 도시하고; 도 3b는 깊이 데이터의 예를 도시하고; 도 3c는 융합된 이미지 데이터 및 깊이 데이터의 예를 도시하고; 도 4는 변환 규칙의 결정의 개략도를 도시한다."}
