{"patent_id": "10-2023-0123703", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0015651", "출원번호": "10-2023-0123703", "발명의 명칭": "이미지 데이터 증강 장치, 방법 및 이를 구현하기 위한 컴퓨터로 판독 가능한 저장 매체", "출원인": "경북대학교 산학협력단", "발명자": "정희철"}}
{"patent_id": "10-2023-0123703", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "원본 이미지를 입력하는 단계;상기 이미지를 캡션하여 문장을 생성하는 단계; 및상기 문장을 기반으로 합성 이미지를 생성하는 단계;를 포함하는, 이미지 데이터 증강 방법."}
{"patent_id": "10-2023-0123703", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 문장을 생성하는 단계는,BLIP를 사용하여 생성하는 단계인, 이미지 데이터 증강 방법."}
{"patent_id": "10-2023-0123703", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 문장을 생성하는 단계는,상기 이미지를 캡션하여 제 1 문장을 생성하는 단계;상기 제 1문장에 역번역 (Back Translation)을 사용하여 하나 이상의 제 2 문장을 생성하는 단계를 포함하며,상기 합성 이미지를 생성하는 단계는, 상기 제 1 문장 및 상기 제 2 문장을 기반으로 합성 이미지를 생성하는단계인,"}
{"patent_id": "10-2023-0123703", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,상기 원본 이미지는 복수이며,상기 이미지를 캡션하여 문장을 생성하는 단계는, 복수의 상기 원본 이미지 각각을 갭션하여 문장을 생성 후, 생성된 각각의 상기 문장을 혼합한 혼합 문장을 생성하는 단계인, 상기 합성 이미지를 생성하는 단계는, 상기 혼합 문장을 기반으로 합성 이미지를 생성하는 단계인,"}
{"patent_id": "10-2023-0123703", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항 또는 제 4항에 있어서,상기 합성 이미지를 생성하는 단계는스테이블 디퓨젼에서 제공하는 가중치를 사용하여 생성하는 단계인, 이미지 데이터 증강 방법.공개특허 10-2025-0015651-3-청구항 6 제 1항 또는 제 4항에 있어서,상기 합성 이미지를 형성하는 단계는,상기 문장 또는 상기 혼합 문장을 기반으로 복수의 합성 이미지를 생성하는 단계인, 이미지 데이터 증강 방법."}
{"patent_id": "10-2023-0123703", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 하나의 항에 따른 상기 이미지 데이터 증강 방법을 수행하기 위한 컴퓨터 프로그램이기록된 컴퓨터로 판독 가능한 저장 매체"}
{"patent_id": "10-2023-0123703", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "이미지 데이터 증강 장치로서, 프로세서; 상기 프로세서에 연결되는 메모리를 포함하되, 상기 메모리는, 원본 이미지를 입력하고,상기 이미지를 캡션하여 문장을 생성하며,상기 문장을 기반으로 합성 이미지를 생성하도록, 상기 프로세서에 의해 실행되는 프로그램 명령어들을 저장하는, 이미지 데이터 증강 장치"}
{"patent_id": "10-2023-0123703", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서,상기 문장을 생성하는 것은,BLIP를 사용하여 생성하는 것인, 이미지 데이터 증강 장치."}
{"patent_id": "10-2023-0123703", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 8항에 있어서,상기 문장을 생성하는 것은,상기 이미지를 캡션하여 제 1 문장을 생성하고;상기 제 1문장에 역번역 (Back Translation)을 사용하여 하나 이상의 제 2 문장을 생성하는 것을 포함하고,상기 합성 이미지를 생성하는 것은, 상기 제 1 문장 및 상기 제 2 문장을 기반으로 합성 이미지를 생성하는 것인, 이미지 데이터 증강 장치."}
{"patent_id": "10-2023-0123703", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 8항에 있어서,상기 원본 이미지는 복수이며,공개특허 10-2025-0015651-4-상기 이미지를 캡션하여 문장을 생성하는 것은, 복수의 상기 원본 이미지 각각을 갭션하여 문장을 생성 후, 생성된 각각의 상기 문장을 혼합한 혼합 문장을 생성하는 것이며, 상기 합성 이미지를 생성하는 것은, 상기 혼합 문장을 기반으로 합성 이미지를 생성하는 것인, 이미지 데이터증강 장치."}
{"patent_id": "10-2023-0123703", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 8항 또는 제 11항에 있어서,상기 합성 이미지를 생성하는 것은,스테이블 디퓨젼에서 제공하는 가중치를 사용하여 생성하는 것인, 이미지 데이터 증강 장치."}
{"patent_id": "10-2023-0123703", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 8항 또는 제 11항에 있어서,상기 합성 이미지를 형성하는 것은,상기 문장 또는 상기 혼합 문장을 기반으로 복수의 합성 이미지를 생성하는 것인, 이미지 데이터 증강 장치."}
{"patent_id": "10-2023-0123703", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 원본 이미지를 입력하는 단계; 상기 이미지를 캡션하여 문장을 생성하는 단계; 및 상기 문장을 기반으 로 합성 이미지를 생성하는 단계;를 포함하는, 이미지 데이터 증강 방법 및 장치에 관한 것이다. 이에 의해 이미 지 데이터의 절대적인 양이 많이 필요한 경우, 혹은 데이터의 다양성을 증가시켜야 할 경우, 적은 수의 원본 데 이터로 대용량의 이미지의 수를 증강시킬 수 있다. 또한, 이를 통해 컴퓨터 비전 분야의 기존 방법론에 비해 더 효율적인 방식으로 이미지 데이터를 확보하고 더 나은 성능 모델을 개발할 수 있다."}
{"patent_id": "10-2023-0123703", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이미지 데이터 증강 장치, 방법 및 이를 구현하기 위한 컴퓨터로 판독 가능한 저장 매체로서, 더욱 상세하게는 원본 이미지에서 생성된 합성 데이터를 생성하여 딥 러닝의 데이터 부족 문제를 해결하는 데 기여할 수 있는 이미지 데이터 증강 장치, 방법 및 이를 구현하기 위한 컴퓨터로 판독 가능한 저장 매체에 관한 것이다."}
{"patent_id": "10-2023-0123703", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 Diffusion 모델과 GAN 기반 생성 모델을 활용한 Dall-E2, GPT-4와 같은 인공지능 기술이 놀라운 성능을 보 여주고 있으며, 실제로 사람의 눈으로 구분하기 어려울 정도의 고품질 결과물을 생성하고 있다. 이러한 연구 흐 름 속에서 특히, CLIP 과 같은 텍스트와 이미지를 결합한 방식의 연구가 많이 진행되고 있다. 기존 딥러닝 기반 컴퓨터 비전 관련 연구는 데이터 중심적인 특징이 비교적 명확하며, 이로 인해 대량의 이미지 데이터가 필요하다. NLP 연구와는 달리 컴퓨터 비전 분야에서는 이미지의 용량이 크기 때문에 상당한 자원이 소모된다. 도 1은 기존의 이미지 데이터의 합성 방법을 나타낸다. 도 1을 참조하면, 강아지와 고양이 이미지가 있을 때 lambda 비율을 통하여 이미지를 단순 합성하는 기법을 사용한다. 즉, 개와 고양이와 같은 두 이미지와 라벨을 0~1 사이의 lambda 값을 통해 Weighted Linear Interpolation 해주는 기법을 사용하여 결과적으로 개와 고양이 의 모호한 이미지가 합성된다. 따라서, 이미지 데이터의 절대적인 양이 많이 필요한 경우, 혹은 데이터의 다양성을 증가시켜야 할 경우에는 기 존의 방법이 효율적이지 않다."}
{"patent_id": "10-2023-0123703", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기와 같은 문제점을 해결하기 위한 본 발명의 목적은 이미지 데이터의 절대적인 양이 많이 필요한 경우, 혹은 데이터의 다양성을 증가시켜야 할 경우, 적은 수의 원본 데이터로 대용량의 이미지의 수를 증강시킬 수 있는 이 미지 데이터 증강 장치, 방법 및 이를 구현하기 위한 컴퓨터로 판독 가능한 저장 매체를 제공하는 데 있다."}
{"patent_id": "10-2023-0123703", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 본 발명의 목적을 실현하기 위한 일 실시예에 따른 이미지 데이터 증강 방법은 원본 이미지를 입력하는 단계; 상기 이미지를 캡션하여 문장을 생성하는 단계; 및 상기 문장을 기반으로 합성 이미지를 생성하는 단계; 를 포함한다. 또한, 상기 문장을 생성하는 단계는, BLIP를 사용하여 생성하는 단계일 수도 있다. 또한, 상기 문장을 생성하는 단계는, 상기 이미지를 캡션하여 제 1 문장을 생성하는 단계; 상기 제 1문장에 역 번역 (Back Translation)을 사용하여 하나 이상의 제 2 문장을 생성하는 단계를 포함하며, 상기 합성 이미지를 생성하는 단계는, 상기 제 1 문장 및 상기 제 2 문장을 기반으로 합성 이미지를 생성하는 단계일 수도 있다. 또한, 상기 원본 이미지는 복수이며, 상기 이미지를 캡션하여 문장을 생성하는 단계는, 복수의 상기 원본 이미 지 각각을 갭션하여 문장을 생성 후, 생성된 각각의 상기 문장을 혼합한 혼합 문장을 생성하는 단계인, 상기 합 성 이미지를 생성하는 단계는, 상기 혼합 문장을 기반으로 합성 이미지를 생성하는 단계일 수도 있다. 또한, 상기 합성 이미지를 생성하는 단계는 스테이블 디퓨젼에서 제공하는 가중치를 사용하여 생성하는 단계일 수도 있다. 또한, 상기 합성 이미지를 형성하는 단계는, 상기 문장 또는 상기 혼합 문장을 기반으로 복수의 합성 이미지를 생성하는 단계일 수도 있다. 본 발명의 목적을 실현하기 위한 또 다른 실시예인 컴퓨터 프로그램이 기록된 컴퓨터로 판독 가능한 저장 매체 는 전술한 이미지 데이터 증강 방법을 수행하기 위한 컴퓨터 프로그램이 기록되어 있다. 본 발명의 목적을 실현하기 위한 또 다른 실시예인 이미지 데이터 증강 장치는, 프로세서; 및 상기 프로세서에 연결되는 메모리를 포함하되, 상기 메모리는, 원본 이미지를 입력하고, 상기 이미지를 캡션하여 문장을 생성하 며, 상기 문장을 기반으로 합성 이미지를 생성하도록, 상기 프로세서에 의해 실행되는 프로그램 명령어들을 저 장한다. 또한, 상기 문장을 생성하는 것은, BLIP를 사용하여 생성하는 것일 수도 있다. 또한, 상기 문장을 생성하는 것은, 상기 이미지를 캡션하여 제 1 문장을 생성하고; 상기 제 1문장에 역번역 (Back Translation)을 사용하여 하나 이상의 제 2 문장을 생성하는 것을 포함하고, 상기 합성 이미지를 생성하 는 것은, 상기 제 1 문장 및 상기 제 2 문장을 기반으로 합성 이미지를 생성하는 것일 수도 있다. 또한, 상기 원본 이미지는 복수이며, 상기 이미지를 캡션하여 문장을 생성하는 것은, 복수의 상기 원본 이미지 각각을 갭션하여 문장을 생성 후, 생성된 각각의 상기 문장을 혼합한 혼합 문장을 생성하는 것이며, 상기 합성 이미지를 생성하는 것은, 상기 혼합 문장을 기반으로 합성 이미지를 생성하는 것일 수도 있다. 또한, 상기 합성 이미지를 생성하는 것은, 스테이블 디퓨젼에서 제공하는 가중치를 사용하여 생성하는 것일 수 도 있다. 상기 합성 이미지를 형성하는 것은, 상기 문장 또는 상기 혼합 문장을 기반으로 복수의 합성 이미지를 생성하는 것일 수도 있다."}
{"patent_id": "10-2023-0123703", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의해, 이미지 데이터의 절대적인 양이 많이 필요한 경우, 혹은 데이터의 다양성을 증가시켜야 할 경 우, 적은 수의 원본 데이터로 대용량의 이미지의 수를 증강킬 수 있다. 또한, 이를 통해 컴퓨터 비전 분야의 기존 방법론에 비해 더 효율적인 방식으로 이미지 데이터를 확보하고 더 나은 성능 모델을 개발할 수 있다."}
{"patent_id": "10-2023-0123703", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명 의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의 해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된 다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유 사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 본 발명을 설 명함에 있어 전체적인 이해를 용이하게 하기 위하여 도면상의 동일한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 도 2는 본 발명의 일 실시예에 따른 이미지 데이터 증강 방법을 나타낸다. 도 2를 참조하면, 본 발명의 이미지 데이터 증강 방법은 원본 이미지 를 필요로 한다. 각 원본 이미지 에 대해, 캡션 생성 모델을 사용하 여 해당 이미지의 특성을 잘 표현할 수 있는 캡션 텍스트 를 생성한다. 이 과정에서는 효율적인 캡션 생성 모델을 선택하여 이미지의 세부적인 정보와 의미를 포착하는 텍스트를 얻을 수 있다. 본 발명에서는 오픈 라이 브러리인 LAVIS 의 MS COCO captioning dataset 에서 finetune 된 BLIP 를 사용하여 각 원본 이미지 에 해당하는 텍스트 캡션 을 생성한다. 그 후, 생성된 캡션 텍스트 를 입력으로 사용하여 텍스트에서 이미지로 변환하는 모델을 통해 새로운 합성 이미지를 생성한다. 이 과정에서는 GAN 기반 모델 또는 Diffusion 모델과 같은 다양한 생성 모델을 사용할 수 있다. 이를 통해 얻어진 합성 이미지는 원본 이미지와 캡션 텍스트 사이의 쌍을 이루게 된다. 본 발명의 경우 Stable Diffusion 에서 제공하는 가중치를 사용해 이미지 를 생성한다. 본 발명을 통해 생성된 합성 이미지 데이터셋은 기존의 이미지 데이터셋과 결합하여 사용할 수 있다. 또한, 사 용자의 필요에 따라 클래스 정보는 유지하며 단일 캡션에서 여러 버전의 합성 이미지를 생성하는 것이 가능하다. 도 3은 본 발명의 일 실시예에 따른 이미지 데이터 증강 방법의 순서도이다. 도 3을 참조하면, 원본 이미지, 예 를 들어 도 2와 같이 북극곰에 대한 원본 이미지를 입력한다 (S310). 그 후 BLIP를 사용하여 원본 이미지인 북 극곰 이미지를 캡션하여 \"A polar bear standing on a rock\" 과 같은 문장을 생성한다 (S320). 그 후, GAN 기 반 모델 또는 Diffusion 모델을 사용하여 합성 이미지, 예를 들어, 도 2에 도시된 우측의 북극곰 이미지 를 생성한다 (S330). 이와 같이 생성된 이미지에 대해 모델 트레이닝 및 평가가 더 이루어질 수도 있다 (S340) 아래의 표 1은 학습에 사용된 클래스 정보이며, 전술한 실시예에서는 'n0213408' 클래스 이미지 (polar bear) 하나를 본 발명의 방법에 따라 만들어낸 이미지의 예시이다. 표 1"}
{"patent_id": "10-2023-0123703", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 발명에서 제안하는 방법의 성능을 평가하기 위해, ImageNet1k 데이터셋을 사용한다. 모든 ImageNet1k 데이터 에 상응하는 합성 데이너셋을 생성하는 것은 Diffusion 모델의 특성상 이미지 생성에 많은 시간이 소요되므로, 임의로 선택한 10개 클래스 하나당 1300개 이미지를 원본 학습 데이터로 활용하였다. 또한, 원본 데이터를 본 논문의 알고리즘에 적용해 만들어진 합성 데이터셋을 추가하여 성능 검증을 진행하였다. 또한, 생성된 모든 합 성 데이터들은 원본 이미지의 클래스를 공유한다. 이 데이터셋을 활용하여 여러가지 기본적인 CNN 구조의 모델들을 사용하였고, 각 모델의 가중치 initialization 을 초기화하여 순수한 데이터셋의 효과를 입증하였다. 모든 이미지는 256×256 해상도로 크기 조정한 후, 224×224 해상도로 중앙 center crop를 진행하였다. 데이터 셋의 평균 및 표준편차로 정규화를 수행하였으며, 다른 증강 기법은 사용하지 않아 데이터셋만의 성능을 확인하 였다. 성능 검증은 각 클래스의 원본 validation 데이터를 이용하여 진행하였다. 학습에 사용된 모델들은 같은 구조를 가지더라도 모델의 복잡도에 따른 성능 차이를 알아보기 위해, 같은 구조"}
{"patent_id": "10-2023-0123703", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "를 가지는 다양한 복잡도의 모델을 사용하였다. 아래의 표 2는 각 모델의 성능을 요약한 것이다. 표 2 모델 합성 데이터 정확도 (S) (50 epoch)원본 데이터 정확도 (O) (50 epoch)원본 데이터 정확도 (O) (100 epoch)전체 데이터 정확도 (S+O) 정확도 상승 폭 (50 epoch) EfficientN et_B0 [9]0.546 0.808 0.842 0.858 / +0.016 EfficientN et_B30.584 0.828 0.836 0.840 / +0.004EfficientN et_B50.570 0.724 0.800 0.826 / +0.026 EfficientN et_B0.592 0.690 0.702 0.856 / +0.154 ResNet18"}
{"patent_id": "10-2023-0123703", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "[10]0.588 0.788 0.748 0.820 / +0.072 ResNet34 0.604 0.782 0.778 0.830 / +0.052 ResNet50 0.580 0.788 0.77 0.774 / +0.040 ResNet10 10.542 0.758 0.774 0.826 / +0.052 ResNet15 20.536 0.742 0.796 0.790 / -0.006 ResNeXt5 0_32×4d"}
{"patent_id": "10-2023-0123703", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "[11]0.600 0.770 0.818 0.860 / +0.042 ResNeXt1 01_32×8 d0.656 0.794 0.808 0.828/ +0.020 ResNeXt1 01_64×4 d0.614 0.790 0.784 0.826/ +0.042 모든 실험은 50 epoch 기준으로 진행되었으며, 데이터셋의 변화에 따른 성능을 보기 위해서 세 가지의 다른 데 이터 셋 조합을 각각 모델이 학습하도록 하고 성능을 측정했다. 하지만, 합성 데이터와 원본 데이터를 전부 쓰 게 되었을 경우, 데이터가 두 배로 늘어나게 되어 학습량이 기존의 같은 epoch을 돌리게 되었을 경우 학습 iteration 이 두 배가 되어 모델의 학습량의 변화가 생기는 것을 고려하여 원본 데이터만을 이용하여 두 배의 epoch를 학습해 S+O 와 같은 iteration 이 되도록 하는 실험을 추가하여 성은을 비교하였다. 이를 통해 모델이 underfitting 되었을 경우의 가능성을 배제하였다. 표 2에서 볼 수 있듯이 거의 모든 모델에서 성능 향상이 있음을 확인하였으며, EfficientNet의 경우 비교적 복 잡도가 높은 모델일수록 원본 데이터만을 사용했을 때 대비 높은 성능 향상폭을 보임을 확인하였다. 또한, 대부 분 모델의 같은 iteration 상황에서 원본 데이터만을 통한 학습과 합성 데이터를 함께 학습한 경우를 비교해 보 았을 경우 성은 향상이 있음을 확인하였다. 이를 통해 모델의 underfitting에 의한 성능 향상이 아닌 데이터의 다양성이 증가했음을 확인할 수 있다. 하지만, 합성 데이터만을 사용했을 경우 원본 데이터를 학습했을 경우보 다 좋지 않은 성능을 보였다. 이를 통해 합성 데이터와 원본 데이터 간의 데이터 분포의 차이로 인하여 성능 감 소가 발생하는 것으로 생각할 수 있다. 도 4는 본 발명의 일 실시예에 따른 BTIA 를 사용한 이미지 데이터 증강 방법을 나타낸다. 도 4를 참조하면, 원 본 이미지 를 BTIA (Back Translation Image Augmentation) 를 통해 합성 이미지 를 생성하는 것을 나타낸다. 원본 이미지 를 기존에 통용되는 이미지 증강법을 확률적으로 적용해 변조된 이미지 를 생성한다. 기 존의 이미지 증강법은 Data Augmentation은 데이터의 양을 늘리기 위해 원본에 각종 변환을 적용하여 개수를 증 강시키는 기법으로서 추가적인 설명은 생략한다. 이러한 변조된 이미지 를 문장 증가 를 통해 다수의 문장을 생성한다. 구체적으로는, 캡션 모델 을 사용하여 제 1 문장 을 생성한다. 본 도면에서는 고양 이에 대해 \"Cat is on the tree\"라는 제 1문장을 생성하였다. 이 제 1문장에 대해 역번역 (Back Translation)을 실행하여 제 2 문장 인 \"Cat is with the tree\"를 생성한다. 이 제 1문장 및 제 2 문장 에 대해 Stable Diffusion 을 적용하여 합성 이미지를 생성한다. 도 5는 도 4의 역번역 의 일 예를 나타낸다. 도 5를 참조하면, 역변역은 문장 분야에서 널리 사용되는 데이터 증강기법이다. 우선, 증강 대상 문장을 특정 언어로 번역. 이후 번역된 문장을 다시 원래 언어로 다시 번역하는것이다. 도 5에 도시된 바와 같이 증강 대상 문장인 제 1문장 에 대해 역변역을 수행하여 3개의 제 2 문장 가 생성되었다. 이와 같이 잘 학습된 번역 모델이 있다면 역번역을 수행한다고 해도 원래 문장의 의미를 보존한 상태로 새로운 문장을 만들 수 있다. 도 6은 본 발명의 일 실시예에 따른 BTIA 를 사용한 이미지 데이터 증강 방법의 순서도이다. 우선 원본 이미지, 예를 들어 도 4와 같이 고양이에 대한 원본 이미지를 입력한다 (S610). 그 후 원본 이미지 또는 증강된 이미지 를 캡션하여 제 1문장 생성한다 (S620). 여기서 원본 이미지인 고양이 이미지를 바로 캡션하여 제 1 문장을 생 성할 수도 있으며, 전술한 이미지 증강법에 의해 변조된 이미지를 캡션하여 제 1 문장을 생성할 수도 있다. 그 후 제 1문장에 대해 역변역을 사용하여 제 2문장을 생성한다 (S630). 여기서 제 2 문장은 도 4와 같이 한 개의 문장일 수도 있거나, 도 5와 같이 문장일 수도 있다. 그 후 제 1문장 및 제 2 문장에 대해 GAN 기반 모델 또는 Diffusion 모델을 사용하여 합성 이미지 생성한다 (S640). 그 결과 도 4에 도시된 바와 같이, 여러 나무에 다양 한 색상의 고양이가 있는 다수의 합성 이미지를 얻을 수 있다. 도 7은 본 발명의 일 실시예에 따른 CMIA 를 사용한 이미지 데이터 증강 방법을 나타낸다. 도 7을 참조하면, 다 수개의 원본 이미지 (211 및 212)가 CMIA (Caption MixUp Image Augmentation)를 통해 합성 이미지 를 생 성한다. 복수의 원본 이미지 각각에 대해 캡션 모델을 활용해서 각각의 문장을 생성한다. 도 7에 도시된 바와 같이, 원 본 이미지 에 캡션 모델 을 적용하여 제 3문장 을 생성하고, 원본 이미지 에 캡션 모델 을 적용하여 제 3문장 을 생성한다. 이 제 3문장 과 제 4문장 을 혼합하여 혼합 문장 을 생성한다. 캡션 모델 \"a polar bear is standing rock\" 와 문장 4 \"a small white dog laying on top of a wooden floor\"을 혼합하여 혼합 문장 \" Mixture of a polar bear is standing on a rock and a small white dog laying on top of a wooden floor\"을 생성하였다. 여기서 문장을 혼합시에 \"Mixture of\" 및 \"and\"와 같은 추가적 구문과 함께 하나의 문장 형태로 변환되며, 추가적인 구문은 원하는 데이 터 형식에 따라 변경 가능하다. 혼합 문장 에 대해 Stable Diffusion 을 적용하여, 북극곰과 하얀 개 가 함께 있는 합성 이미지를 생성한다. 도 8은 본 발명의 일 실시예에 따른 CMIA 를 사용한 이미지 데이터 증강 방법의 순서도이다. 우선 복수의 원본 이미지, 예를 들어 도 7과 같이 곰과 개에 대한 원본 이미지를 입력한다 (S810). 그 후 원본 이미지 각각을 갭 션하여 문장을 생성한다 (S820). 각 문장은 해당하는 원본 이미지의 개수에 상응한다. 그 후, 생성된 각각의 문 장을 혼합한 혼합 문장을 생성한다 (S830). 마지막으로 혼합 문장에 GAN 기반 모델 또는 Diffusion 모델을 사용 하여 합성 이미지 생성한다 (S840) 본 발명에서는 현재 딥 러닝을 통한 학습에서 고질적인 문제인 데이터의 부족 및 다양성 부족을 극복하기 위해 이미지 역번역 데이터 증강 알고리즘을 제안하였다. 합성 데이터 셋을 원본 데이터 셋과 함께 사용해 여러가지 모델의 성능을 향상시킬 수 있음을 보였고 데이터의 다양성 또한 증대되었음을 확인하였다. 이를 통해 컴퓨터 비전 분야의 기존 방법론에 비해 더 효율적인 방식으로 이미지 데이터를 확보하고 더 나은 성능 모델을 개발할 수 있다. 또한, 전술한 이미지 데이터 증강 방법은 애플리케이션으로 구현되거나 다양한 컴퓨터 구성요소를 통하여 수행 될 수 있는 프로그램 명령어의 형태로 구현되어 컴퓨터 판독 가능한 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체는 프로그램 명령어, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판독 가능한 기록 매체에 기록되는 프로그램 명령어는 본 발명을 위하여 특별히 설계되고 구성된 것들이거니와 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD_ROM, DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto- opticalmedia), 및 ROM, RAM, 플래시 메모리 등과 같은 프로그램 명령어를 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령어의 예에는, 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사 용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함된다. 상기 하드웨어 장치는 본 발명에 따른 처 리를 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 이상에서는 실시예들을 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2023-0123703", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 기존의 이미지 데이터의 합성 방법을 나타낸다. 도 2는 본 발명의 일 실시예에 따른 이미지 데이터 증강 방법을 나타낸다. 도 3은 본 발명의 일 실시예에 따른 이미지 데이터 증강 방법의 순서도이다. 도 4는 본 발명의 일 실시예에 따른 BTIA 를 사용한 이미지 데이터 증강 방법을 나타낸다. 도 5는 도 4의 BTIA 의 일 예를 나타낸다. 도 6은 본 발명의 일 실시예에 따른 BTIA 를 사용한 이미지 데이터 증강 방법의 순서도이다. 도 7은 본 발명의 일 실시예에 따른 CMIA 를 사용한 이미지 데이터 증강 방법을 나타낸다. 도 8은 본 발명의 일 실시예에 따른 CMIA 를 사용한 이미지 데이터 증강 방법의 순서도이다."}
