{"patent_id": "10-2014-0069443", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2015-0141019", "출원번호": "10-2014-0069443", "발명의 명칭": "깊이 정보를 활용하는 전자 장치 및 방법", "출원인": "삼성전자주식회사", "발명자": "윤영권"}}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치의 동작 방법에 있어서, 복수의 이미지(image)를 획득하는 동작;상기 획득된 복수의 이미지에 포함된 적어도 둘 이상의 피사체(subject)의 깊이 정보(depth information)를 추출하는 동작; 및 상기 추출된 깊이 정보에 기반하여, 상기 피사체에 이미지를 처리하는 동작을 포함하는 방법."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 복수의 이미지를 획득하는 동작은, 적어도 둘 이상의 이미지 센서를 이용하는 것을 포함하는 방법."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상면 위상 차 센서, 위상 차 센서, TOF(Time Of Flight) 센서, 적외선 센서 및 이미지 센서 중 적어도 하나를이용하여, 상기 피사체와의 거리를 계산하는 동작을 더 포함하는 방법."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 깊이 정보를 추출하는 동작은, 상기 획득된 복수의 이미지를 조합하는 동작;상기 조합된 복수의 이미지를 이용하여, 3차원의 이미지를 생성하는 동작을 포함하는 방법."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 피사체에 이미지를 처리하는 동작은,상기 피사체 중 근거리에 위치한 제1 피사체에 초점이 맞추어진 제1 이미지를 생성하는 동작;상기 피사체 중 원거리에 위치한 제2 피사체에 초점이 맞추어진 제2 이미지를 생성하는 동작; 및 상기 근거리 및 상기 원거리 사이에 위치한 제3 피사체에 초점이 맞추어진 제3 이미지를 생성하는 동작을 포함하는 방법."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2015-0141019-3-제5항에 있어서, 상기 제1 이미지 내지 제3 이미지 중 설정된 이미지를 디스플레이하는 동작을 더 포함하는 방법."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서, 상기 제1 이미지 내지 제3 이미지를 합성하는 동작; 및 상기 합성된 이미지를 디스플레이하는 동작을 더 포함하는 방법."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 피사체에 포함된 근거리에 위치한 제1 피사체에 초점이 맞추어진 제1 이미지, 원거리에 위치한 제2 피사체에 초점이 맞추어진 제2 이미지, 상기 근거리와 상기 원거리 사이에 위치한 제3 피사체에 초점이 맞추어진 제3이미지 및 상기 제1 이미지 내지 제3 이미지가 합성된 이미지 중, 어느 하나의 이미지를 디스플레이하는 동작;및 상기 디스플레이된 어느 하나의 이미지에 대한 편집을 감지하는 동작을 더 포함하는 방법."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 편집을 감지하는 동작은, 상기 디스플레이된 어느 하나의 이미지에 포함된 상기 제1 피사체 내지 제3 피사체 중 어느 하나를 선택받는 동작;상기 선택받은 피사체를 기준으로 선택받지 않은 나머지 피사체들의 상대적인 거리를 판단하는 동작; 및 상기 판단된 거리에 따라, 상대적인 거리가 먼 피사체에 상대적으로 큰 블러(blur)를 적용하고, 상대적인 거리가 가까운 피사체에 상대적으로 작은 블러를 적용하는 동작을 포함하는 방법."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 획득된 이미지의 크기(size)에 맞도록, 상기 추출된 깊이 정보를 스켈링(scaling)하는 동작을 더 포함하는방법."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치에 있어서, 복수의 이미지를 획득하는 적어도 둘 이상의 이미지 센서; 및 상기 획득된 복수의 이미지에 포함된 적어도 둘 이상의 피사체의 깊이 정보를 추출하고, 상기 추출된 깊이 정보에 기반하여, 상기 피사체에 이미지를 처리하는 프로세서를 포함하는 장치.공개특허 10-2015-0141019-4-청구항 12 제11항에 있어서, 상기 복수의 이미지를 획득하는 적어도 하나 이상의 카메라 모듈을 더 포함하는 장치."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 프로세서는, 상면 위상 차 센서, 위상 차 센서, TOF(Time Of Flight) 센서, 적외선 센서 및 이미지 센서중 적어도 하나를 이용하여, 상기 피사체와의 거리를 계산하는 것을 포함하는 장치."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서, 상기 프로세서는, 상기 획득된 복수의 이미지를 조합하고, 상기 조합된 복수의 이미지를 이용하여, 3차원의 이미지를 생성하는 것을 포함하는 장치."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서, 상기 프로세서는, 상기 피사체 중 근거리에 위치한 제1 피사체에 초점이 맞추어진 제1 이미지를 생성하고, 상기피사체 중 원거리에 위치한 제2 피사체에 초점이 맞추어진 제2 이미지를 생성하며, 상기 근거리 및 상기 원거리사이에 위치한 제3 피사체에 초점이 맞추어진 제3 이미지를 생성하는 것을 포함하는 장치."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 제1 이미지 내지 제3 이미지 중 설정된 이미지를 표시하는 디스플레이를 더 포함하는 장치."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서, 상기 프로세서는, 상기 제1 이미지 내지 제3 이미지를 합성하고, 상기 합성된 이미지를 표시하는 디스플레이를 더 포함하는 장치."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서, 상기 피사체에 포함된 근거리에 위치한 제1 피사체에 초점이 맞추어진 제1 이미지, 원거리에 위치한 제2 피사체에 초점이 맞추어진 제2 이미지, 상기 근거리와 상기 원거리 사이에 위치한 제3 피사체에 초점이 맞추어진 제3이미지 및 상기 제1 이미지 내지 제3 이미지가 합성된 이미지 중, 어느 하나의 이미지를 표시하는 디스플레이를더 포함하고,공개특허 10-2015-0141019-5-상기 프로세서는, 상기 디스플레이된 어느 하나의 이미지에 대한 편집을 감지하는 것을 포함하는 장치."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 디스플레이는 상기 표시된 어느 하나의 이미지에 포함된 상기 제1 피사체 내지 제3 피사체 중 어느 하나를선택받고, 상기 프로세서는, 상기 선택받은 피사체를 기준으로 선택받지 않은 나머지 피사체들의 상대적인 거리를 판단하고, 상기 판단된 거리에 따라, 상대적인 거리가 먼 피사체에 상대적으로 큰 블러를 적용하고, 상대적인 거리가가까운 피사체에 상대적으로 작은 블러를 적용하는 것을 포함하는 장치."}
{"patent_id": "10-2014-0069443", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서,상기 프로세서는, 상기 획득된 이미지의 크기에 맞도록, 상기 추출된 깊이 정보를 스켈링하는 것을 포함하는 장치."}
{"patent_id": "10-2014-0069443", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다양한 실시 예들에 따르면, 전자 장치의 동작 방법에 있어서, 복수의 이미지를 획득하는 동작; 상기 획득된 복 수의 이미지에 포함된 적어도 둘 이상의 피사체의 깊이 정보를 추출하는 동작; 및 상기 추출된 깊이 정보에 기반 하여, 상기 피사체에 이미지를 처리하는 동작을 포함할 수 있다. 다른 실시 예들이 가능하다."}
{"patent_id": "10-2014-0069443", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 다양한 실시 예들은 깊이 정보를 활용하는 전자 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2014-0069443", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자 장치의 기능이 발전하면서, 카메라 성능이 향상되어 높은 해상도로 사용자가 원하는 이미지를 촬영할 수 있게 되었다. 뿐만 아니라, 전자 장치에서는 전자 장치로부터 피사체들의 사이의 거리에 따른 깊이 정보를 활용 하여 사용자의 편의성을 향상시켜 주고 있다. 예를 들면, 전자 장치는 전자 장치에 구비된 어레이 카메라를 이용하여, 복수 개의 영상을 수집하여, 각각의 피 사체들의 깊이에 따른 정보를 얻을 수 있게 되었다."}
{"patent_id": "10-2014-0069443", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "현존하는 기술에 따르면, 전자 장치에 복수 개의 카메라 모듈을 이용하여, 다양한 피사체들의 깊이 정보를 추출 하고 있다. 그러나, 전자 장치에서 피사체들의 깊이 정보를 추출할 때, 필요 이상의 깊이 정보를 추출하여 영상 을 처리함으로써, 영상 처리량이 늘어나고 있는 것이 현실이다. 본 발명의 다양한 실시 예들은, 전자 장치를 기준으로, 전자 장치로부터 피사체들까지의 거리에 따라 근거리, 중간거리 및 원거리의 피사체들의 깊이 정보만을 추출함으로써, 영상 처리량을 효율적으로 줄일 수 있는 장치 및 방법을 제공할 수 있다. 본 발명의 다양한 실시 예들은, 설정된 방법에 따라 각각의 서브 이미지들을 하나의 이미지로 합성할 수 있는 사용자의 편의성을 향상시켜 줄 수 있는 장치 및 방법을 제공할 수 있다. 본 발명의 다양한 실시 예들은, 서브 이미지들 또는 합성된 이미지를 손쉽게 편집할 수 있는 사용자의 다양한 욕구를 충족시켜 줄 수 있는 장치 및 방법을 제공할 수 있다."}
{"patent_id": "10-2014-0069443", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예들에 따르면, 전자 장치의 동작 방법에 있어서, 복수의 이미지를 획득하는 동작; 상기 획득된 복수의 이미지에 포함된 적어도 둘 이상의 피사체의 깊이 정보를 추출하는 동작; 및 상기 추출된 깊이 정보에 기반하여, 상기 피사체에 이미지를 처리하는 동작을 포함할 수 있다. 본 발명의 실시 예들에 따르면, 전자 장치에 있어서, 복수의 이미지를 획득하는 적어도 둘 이상의 이미지 센서; 및 상기 획득된 복수의 이미지에 포함된 적어도 둘 이상의 피사체의 깊이 정보를 추출하고, 상기 추출된 깊이 정보에 기반하여, 상기 피사체에 이미지를 처리하는 프로세서를 포함할 수 있다."}
{"patent_id": "10-2014-0069443", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 다양한 실시 예들은, 전자 장치로부터 피사체들까지의 거리에 따라 근거리, 중간거리 및 원거리의 피 사체들의 깊이 정보만을 추출함으로써, 영상 처리량을 효율적으로 줄일 수 있다."}
{"patent_id": "10-2014-0069443", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 다양한 실시 예가 첨부된 도면과 연관되어 기재된다. 본 발명의 다양한 실시 예는 다양한 변경 을 가할 수 있고 여러 가지 실시 예를 가질 수 있는바, 특정 실시 예들이 도면에 예시되고 관련된 상세한 설명 이 기재되어 있다. 그러나, 이는 본 발명의 다양한 실시 예를 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 다양한 실시 예의 사상 및 기술 범위에 포함되는 모든 변경 및/또는 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용되었다.본 발명의 다양한 실시 예에서 사용될 수 있는“포함한다”또는“포함할 수 있다”등의 표현은 개시 (disclosure)된 해당 기능, 동작 또는 구성요소 등의 존재를 가리키며, 추가적인 하나 이상의 기능, 동작 또는 구성요소 등을 제한하지 않는다. 또한, 본 발명의 다양한 실시 예에서,\"포함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것 이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존 재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 발명의 다양한 실시 예에서 “또는” 등의 표현은 함께 나열된 단어들의 어떠한, 그리고 모든 조합을 포함한 다. 예를 들어,“A 또는 B”는, A를 포함할 수도, B를 포함할 수도, 또는 A 와 B 모두를 포함할 수도 있다. 본 발명의 다양한 실시 예에서 사용된 “제 1,”“제2,”“첫째,”또는“둘째,”등의 표현들은 다양한 실시 예 들의 다양한 구성요소들을 수식할 수 있지만, 해당 구성요소들을 한정하지 않는다. 예를 들어, 상기 표현들은 해당 구성요소들의 순서 및/또는 중요도 등을 한정하지 않는다. 상기 표현들은 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 수 있다. 예를 들어, 제1 사용자 기기와 제 2 사용자 기기는 모두 사용자 기기이며, 서로 다른 사용자 기기를 나타낸다. 예를 들어, 본 발명의 다양한 실시 예의 권리 범위를 벗어나지 않으면서 제1 구 성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요소 가 상기 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 상기 어떤 구성요소와 상기 다른 구성요소 사이에 새로운 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성 요소와 상기 다른 구성요소 사이에 새로운 다른 구성요소가 존재하지 않는 것으로 이해될 수 있어야 할 것이다. 본 발명의 다양한 실시 예에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명의 다양한 실시 예를 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용 어들은 본 발명의 다양한 실시 예가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 가지는 것으로 해석되어야 하며, 본 발명의 다양한 실시예에서 명백하게 정의되지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 본 발명의 다양한 실시 예에 따른 전자 장치는, 통신 기능이 포함된 장치일 수 있다. 예를 들면, 전자 장치는 스마트 폰(smartphone), 태블릿 PC(tablet personal computer), 이동 전화기(mobile phone), 화상전화기, 전자 북 리더기(e-book reader), 데스크탑 PC(desktop personal computer), 랩탑 PC(laptop personal computer), 넷 북 컴퓨터(netbook computer), PDA(personal digital assistant), PMP(portable multimedia player), MP3 플 레이어, 모바일 의료기기, 카메라(camera), 또는 웨어러블 장치(wearable device)(예: 전자 안경과 같은 head- mounted-device(HMD), 전자 의복, 전자 팔찌, 전자 목걸이, 전자 앱세서리(appcessory), 전자 문신, 또는 스마 트 와치(smart watch))중 적어도 하나를 포함할 수 있다. 어떤 실시 예들에 따르면, 전자 장치는 통신 기능을 갖춘 스마트 가전 제품(smart home appliance)일 수 있다. 스마트 가전 제품은, 예를 들자면, 전자 장치는 텔레비전, DVD(digital video disk) 플레이어, 오디오, 냉장고, 에어컨, 청소기, 오븐, 전자레인지, 세탁기, 공기 청정기, 셋톱 박스(set-top box), TV 박스(예를 들면, 삼성 HomeSyncTM, 애플TVTM, 또는 구글 TVTM), 게임 콘솔(game consoles), 전자 사전, 전자 키, 캠코더(camcorder), 또는 전자 액자 중 적어도 하나를 포함할 수 있다. 어떤 실시 예들에 따르면, 전자 장치는 각종 의료기기(예: MRA(magnetic resonance angiography), MRI(magnetic resonance imaging), CT(computed tomography), 촬영기, 초음파기 등), 네비게이션(navigation) 장치, GPS 수신기(global positioning system receiver), EDR(event data recorder), FDR(flight data recorder), 자동차 인포테인먼트(infotainment) 장치, 선박용 전자 장비(예: 선박용 항법 장치 및 자이로 콤파 스 등), 항공 전자기기(avionics), 보안 기기, 차량용 헤드 유닛, 산업용 또는 가정용 로봇, 금융 기관의 ATM(automatic teller뭩 machine) 또는 상점의 POS(point of sales) 중 적어도 하나를 포함할 수 있다. 어떤 실시 예들에 따르면, 전자 장치는 통신 기능을 포함한 가구(furniture) 또는 건물/구조물의 일부, 전자 보 드(electronic board), 전자 사인 입력장치(electronic signature receiving device), 프로젝터(projector), 또는 각종 계측기기(예: 수도, 전기, 가스, 또는 전파 계측 기기 등) 중 적어도 하나를 포함할 수 있다. 본 발명의 다양한 실시예에 따른 전자 장치는 전술한 다양한 장치들 중 하나 또는 그 이상의 조합일 수 있다. 또한, 본 발명의 다양한 실시 예에 따른 전자 장치는 플렉서블 장치일 수 있다. 또한, 본 발명의 다양한 실시 예에 따 른 전자 장치는 전술한 기기들에 한정되지 않음은 당업자에게 자명하다. 이하, 첨부된 도면을 참조하여 다양한 실시 예에 따른 전자 장치에 대해서 살펴본다. 다양한 실시 예에서 이용 되는 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전자 장치) 를 지칭할 수 있다. 도 1은 다양한 실시 예에 따른, 전자 장치 101를 포함하는 네트워크 환경 100을 도시한다. 도 1을 참조하면, 상 기 전자 장치 101는 버스 110, 프로세서 120, 메모리 130, 입출력 인터페이스 140, 디스플레이 150 및 통신 인 터페이스 160를 포함할 수 있다. 상기 버스 110는 전술한 구성요소들을 서로 연결하고, 전술한 구성요소들 간의 통신(예: 제어 메시지)을 전달하 는 회로일 수 있다. 상기 프로세서 120는, 예를 들면, 상기 버스 110를 통해 전술한 다른 구성요소들(예: 상기 메모리 130, 상기 입 출력 인터페이스 140, 상기 디스플레이 150 또는 상기 통신 인터페이스 160등)로부터 명령을 수신하여, 수신된 명령을 해독하고, 해독된 명령에 따른 연산이나 데이터 처리를 실행할 수 있다. 상기 메모리 130는, 상기 프로세서 120 또는 다른 구성요소들(예: 상기 입출력 인터페이스 140, 상기 디스플레 이 150 또는 상기 통신 인터페이스 160등)로부터 수신되거나 상기 프로세서 120 또는 다른 구성요소들에 의해 생성된 명령 또는 데이터를 저장할 수 있다. 상기 메모리 130는, 예를 들면, 커널 131, 미들웨어 132, 애플리케 이션 프로그래밍 인터페이스(API: application programming interface) 133 또는 애플리케이션 134등의 프로그 래밍 모듈들을 포함할 수 있다. 전술한 각각의 프로그래밍 모듈들은 소프트웨어, 펌웨어, 하드웨어 또는 이들 중 적어도 둘 이상의 조합으로 구성될 수 있다. 상기 커널 131은 나머지 다른 프로그래밍 모듈들, 예를 들면, 상기 미들웨어 132, 상기 API 133 또는 상기 애플 리케이션 134에 구현된 동작 또는 기능을 실행하는 데 사용되는 시스템 리소스들(예: 상기 버스 110, 상기 프로 세서 120 또는 상기 메모리 130 등)을 제어 또는 관리할 수 있다. 또한, 상기 커널 131은 상기 미들웨어 132, 상기 API 133 또는 상기 애플리케이션 134에서 상기 전자 장치 101의 개별 구성요소에 접근하여 제어 또는 관리 할 수 있는 인터페이스를 제공할 수 있다. 상기 미들웨어 132는 상기 API 133 또는 상기 애플리케이션 134이 상기 커널 131과 통신하여 데이터를 주고받을 수 있도록 중개 역할을 수행할 수 있다. 또한, 상기 미들웨어 132는 상기 애플리케이션 134로부터 수신된 작업 요청들과 관련하여, 예를 들면, 상기 애플리케이션 134 중 적어도 하나의 애플리케이션에 상기 전자 장치 101의 시스템 리소스(예: 상기 버스 110, 상기 프로세서 120 또는 상기 메모리 130등)를 사용할 수 있는 우선 순위를 배정하는 등의 방법을 이용하여 작업 요청에 대한 제어(예: 스케쥴링 또는 로드 밸런싱)을 수행할 수 있다. 상기 API 133는 상기 애플리케이션 134이 상기 커널 131 또는 상기 미들웨어 132에서 제공되는 기능을 제어하기 위한 인터페이스로, 예를 들면, 파일 제어, 창 제어, 화상 처리 또는 문자 제어 등을 위한 적어도 하나의 인터 페이스 또는 함수(예: 명령어)를 포함할 수 있다. 다양한 실시 예에 따르면, 상기 애플리케이션 134는 SMS/MMS 애플리케이션, 이메일 애플리케이션, 달력 애플리 케이션, 알람 애플리케이션, 건강 관리(health care) 애플리케이션(예: 운동량 또는 혈당 등을 측정하는 애플리 케이션) 또는 환경 정보 애플리케이션(예: 기압, 습도 또는 온도 정보 등을 제공하는 애플리케이션) 등을 포함 할 수 있다. 추가적으로 또는 대체적으로, 상기 애플리케이션 134은 상기 전자 장치 101와 외부 전자 장치(예: 전자 장치 104) 사이의 정보 교환과 관련된 애플리케이션일 수 있다. 상기 정보 교환과 관련된 애플리케이션은, 예를 들어, 상기 외부 전자 장치에 특정 정보를 전달하기 위한 알림 전달(notification relay) 애플리케이션, 또는 상기 외부 전자 장치를 관리하기 위한 장치 관리(device management) 애플리케이션을 포함할 수 있다. 예를 들면, 상기 알림 전달 애플리케이션은 상기 전자 장치 101의 다른 애플리케이션(예: SMS/MMS 애플리케이션, 이메일 애플리케이션, 건강 관리 애플리케이션 또는 환경 정보 애플리케이션 등)에서 발생한 알 림 정보를 외부 전자 장치(예: 전자 장치 104)로 전달하는 기능을 포함할 수 있다. 추가적으로 또는 대체적으로, 상기 알림 전달 애플리케이션은, 예를 들면, 외부 전자 장치(예: 전자 장치 104)로부터 알림 정보 를 수신하여 사용자에게 제공할 수 있다. 상기 장치 관리 애플리케이션은, 예를 들면, 상기 전자 장치 101와 통신하는 외부 전자 장치(예: 전자 장치 104)의 적어도 일부에 대한 기능(예: 외부 전자 장치 자체(또는, 일부 구 성 부품)의 턴온/턴오프 또는 디스플레이의 밝기(또는, 해상도) 조절), 상기 외부 전자 장치에서 동작하는 애플 리케이션 또는 상기 외부 전자 장치에서 제공되는 서비스(예: 통화 서비스 또는 메시지 서비스)를 관리(예: 설 치, 삭제 또는 업 데이트)할 수 있다. 다양한 실시 예에 따르면, 상기 애플리케이션 134은 상기 외부 전자 장치(예: 전자 장치 104)의 속성(예: 전자 장치의 종류)에 따라 지정된 애플리케이션을 포함할 수 있다. 예를 들어, 외부 전자 장치가 MP3 플레이어인 경 우, 상기 애플리케이션 134은 음악 재생과 관련된 애플리케이션을 포함할 수 있다. 유사하게, 외부 전자 장치가 모바일 의료기기인 경우, 상기 애플리케이션 134은 건강 관리와 관련된 어플리케이션을 포함할 수 있다. 한 실 시 예에 따르면, 상기 애플리케이션 134은 전자 장치 101에 지정된 애플리케이션 또는 외부 전자 장치(예: 서버 164 또는 전자 장치 104)로부터 수신된 애플리케이션 중 적어도 하나를 포함할 수 있다. 상기 입출력 인터페이스 140은, 입출력 장치(예: 센서, 키보드 또는 터치 스크린)를 통하여 사용자로부터 입력 된 명령 또는 데이터를, 예를 들면, 상기 버스 110를 통해 상기 프로세서 120, 상기 메모리 130 또는 상기 통신 인터페이스 160에 전달할 수 있다. 예를 들면, 상기 입출력 인터페이스 140은 터치 스크린을 통하여 입력된 사 용자의 터치에 대한 데이터를 상기 프로세서 120로 제공할 수 있다. 또한, 상기 입출력 인터페이스 140은, 예를 들면, 상기 버스 110을 통해 상기 프로세서 120, 상기 메모리 130 또는 상기 통신 인터페이스 160로부터 수신된 명령 또는 데이터를 상기 입출력 장치(예: 스피커 또는 디스플레이)를 통하여 출력할 수 있다. 예를 들면, 상기 입출력 인터페이스 140은 상기 프로세서 120를 통하여 처리된 음성 데이터를 스피커를 통하여 사용자에게 출력 할 수 있다. 상기 디스플레이 150은 사용자에게 각종 정보(예: 멀티미디어 데이터 또는 텍스트 데이터 등)을 표시할 수 있다. 상기 통신 인터페이스 160은 상기 전자 장치 101와 외부 장치(예: 전자 장치 104 또는 서버 106) 간의 통신을 연결할 수 있다. 예를 들면, 상기 통신 인터페이스 160은 무선 통신 또는 유선 통신을 통해서 네트워크 162에 연결되어 상기 외부 장치와 통신할 수 있다. 상기 무선 통신은, 예를 들어, Wifi(wireless fidelity), BT(Bluetooth), NFC(near field communication), GPS(global positioning system) 또는 cellular 통신(예: LTE, LTE-A, CDMA, WCDMA, UMTS, WiBro 또는 GSM 등) 중 적어도 하나를 포함할 수 있다. 상기 유선 통신은, 예 를 들어, USB(universal serial bus), HDMI(high definition multimedia interface), RS-232(recommended standard 232) 또는 POTS(plain old telephone service) 중 적어도 하나를 포함할 수 있다. 한 실시 예에 따르면, 상기 네트워크 162는 통신 네트워크(telecommunications network)일 수 있다. 상기 통신 네트워크는 컴퓨터 네트워크(computer network), 인터넷(internet), 사물 인터넷(internet of things) 또는 전 화망(telephone network) 중 적어도 하나를 포함할 수 있다. 한 실시예에 따르면, 상기 전자 장치 101와 외부 장치 간의 통신을 위한 프로토콜(예: transport layer protocol, data link layer protocol 또는 physical layer protocol))은 어플리케이션 134, 어플리케이션 프로그래밍 인터페이스 133, 상기 미들웨어 132, 커널 131 또는 통신 인터페이스 160 중 적어도 하나에서 지원될 수 있다. 도 2는 다양한 실시예들에 따른 전자 장치 201의 블록도 200를 도시한다. 상기 전자 장치 201는, 예를 들면, 도 1에 도시된 전자 장치 101의 전체 또는 일부를 구성할 수 있다. 도 2를 참조하면, 상기 전자 장치 201는 하나 이상의 어플리케이션 프로세서(AP: application processor) 210, 통신 모듈 220, SIM(subscriber identification module) 카드 224, 메모리 230, 센서 모듈 240, 입력 장치 250, 디스플레이 260, 인터페이스 270, 오디오 모듈 280, 카메라 모듈 291, 전력관리 모듈 295, 배터리 296, 인디케이터 297 및 모터 298를 포함 할 수 있다. 상기 AP 210는 운영체제 또는 응용 프로그램을 구동하여 상기 AP 210에 연결된 다수의 하드웨어 또는 소프트웨 어 구성요소들을 제어할 수 있고, 멀티미디어 데이터를 포함한 각종 데이터 처리 및 연산을 수행할 수 있다. 상 기 AP 210는, 예를 들면, SoC(system on chip) 로 구현될 수 있다. 한 실시예에 따르면, 상기 AP 210는 GPU(graphic processing unit, 미도시)를 더 포함할 수 있다. 상기 통신 모듈 220(예: 상기 통신 인터페이스 160)은 상기 전자 장치 201(예: 상기 전자 장치 101)와 네트워크 를 통해 연결된 다른 전자 장치들(예: 전자 장치 104 또는 서버 106) 간의 통신에서 데이터 송수신을 수행할 수 있다. 한 실시예에 따르면, 상기 통신 모듈 220은 셀룰러 모듈 221, Wifi 모듈 223, BT 모듈 225, GPS 모듈227, NFC 모듈 228 및 RF(radio frequency) 모듈 229를 포함할 수 있다. 상기 셀룰러 모듈 221은 통신망(예: LTE, LTE-A, CDMA, WCDMA, UMTS, WiBro 또는 GSM 등)을 통해서 음성 통화, 영상 통화, 문자 서비스 또는 인터넷 서비스 등을 제공할 수 있다. 또한, 상기 셀룰러 모듈 221은, 예를 들면, 가입자 식별 모듈(예: SIM 카드 224)을 이용하여 통신 네트워크 내에서 전자 장치의 구별 및 인증을 수행할 수 있다. 한 실시예에 따르면, 상기 셀룰러 모듈 221은 상기 AP 210가 제공할 수 있는 기능 중 적어도 일부 기능을 수행할 수 있다. 예를 들면, 상기 셀룰러 모듈 221은 멀티 미디어 제어 기능의 적어도 일부를 수행할 수 있다. 한 실시예에 따르면, 상기 셀룰러 모듈 221은 커뮤니케이션 프로세서(CP: communication processor)를 포함할 수 있다. 또한, 상기 셀룰러 모듈 221은, 예를 들면, SoC로 구현될 수 있다. 도 2에서는 상기 셀룰러 모듈 221 (예: 커뮤니케이션 프로세서), 상기 메모리 230 또는 상기 전력관리 모듈 295 등의 구성요소들이 상기 AP 210와 별개의 구성요소로 도시되어 있으나, 한 실시예에 따르면, 상기 AP 210가 전술한 구성요소들의 적어도 일부(예: 셀룰러 모듈 221)를 포함하도록 구현될 수 있다. 한 실시예에 따르면, 상기 AP 210 또는 상기 셀룰러 모듈 221(예: 커뮤니케이션 프로세서)은 각각에 연결된 비 휘발성 메모리 또는 다른 구성요소 중 적어도 하나로부터 수신한 명령 또는 데이터를 휘발성 메모리에 로드 (load)하여 처리할 수 있다. 또한, 상기 AP 210 또는 상기 셀룰러 모듈 221은 다른 구성요소 중 적어도 하나로 부터 수신하거나 다른 구성요소 중 적어도 하나에 의해 생성된 데이터를 비휘발성 메모리에 저장(store)할 수 있다. 상기 Wifi 모듈 223, 상기 BT 모듈 225, 상기 GPS 모듈 227 또는 상기 NFC 모듈 228 각각은, 예를 들면, 해당 하는 모듈을 통해서 송수신되는 데이터를 처리하기 위한 프로세서를 포함할 수 있다. 도 2에서는 셀룰러 모듈 221, Wifi 모듈 223, BT 모듈 225, GPS 모듈 227 또는 NFC 모듈 228이 각각 별개의 블록으로 도시되었으나, 한 실시예에 따르면, 셀룰러 모듈 221, Wifi 모듈 223, BT 모듈 225, GPS 모듈 227 또는 NFC 모듈 228 중 적어도 일부(예: 두 개 이상)는 하나의 integrated chip(IC) 또는 IC 패키지 내에 포함될 수 있다. 예를 들면, 셀룰러 모듈 221, Wifi 모듈 223, BT 모듈 225, GPS 모듈 227 또는 NFC 모듈 228 각각에 대응하는 프로세서들 중 적어 도 일부(예: 셀룰러 모듈 221에 대응하는 커뮤니케이션 프로세서 및 Wifi 모듈 223에 대응하는 Wifi 프로세서) 는 하나의 SoC로 구현될 수 있다. 상기 RF 모듈 229는 데이터의 송수신, 예를 들면, RF 신호의 송수신을 할 수 있다. 상기 RF 모듈 229는, 도시되 지는 않았으나, 예를 들면, 트랜시버(transceiver), PAM(power amp module), 주파수 필터(frequency filter) 또는 LNA(low noise amplifier) 등을 포함할 수 있다. 또한, 상기 RF 모듈 229는 무선 통신에서 자유 공간상의 전자파를 송수신하기 위한 부품, 예를 들면, 도체 또는 도선 등을 더 포함할 수 있다. 도 2에서는 셀룰러 모듈 221, Wifi 모듈 223, BT 모듈 225, GPS 모듈 227 및 NFC 모듈 228이 하나의 RF 모듈 229을 서로 공유하는 것으 로 도시되어 있으나, 한 실시예에 따르면, 셀룰러 모듈 221, Wifi 모듈 223, BT 모듈 225, GPS 모듈 227 또는 NFC 모듈 228 중 적어도 하나는 별개의 RF 모듈을 통하여 RF 신호의 송수신을 수행할 수 있다. 상기 SIM 카드 224는 가입자 식별 모듈을 포함하는 카드일 수 있으며, 전자 장치의 특정 위치에 형성된 슬롯에 삽입될 수 있다. 상기 SIM 카드 224는 고유한 식별 정보(예: ICCID(integrated circuit card identifier)) 또 는 가입자 정보(예: IMSI(international mobile subscriber identity))를 포함할 수 있다. 상기 메모리 230(예: 상기 메모리 130)는 내장 메모리 232 또는 외장 메모리 234를 포함할 수 있다. 상기 내장 메모리 232는, 예를 들면, 휘발성 메모리(예를 들면, DRAM(dynamic RAM), SRAM(static RAM), SDRAM(synchronous dynamic RAM) 등) 또는 비휘발성 메모리(non-volatile Memory, 예를 들면, OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, NAND flash memory, NOR flash memory 등) 중 적어도 하나를 포함할 수 있다. 한 실시예에 따르면, 상기 내장 메모리 232는 Solid State Drive (SSD)일 수 있다. 상기 외장 메모리 234는 flash drive, 예를 들면, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini- SD(mini secure digital), xD(extreme digital) 또는 Memory Stick 등을 더 포함할 수 있다. 상기 외장 메모리 234는 다양한 인터페이스를 통하여 상기 전자 장치 201과 기능적으로 연결될 수 있다. 한 실시예에 따르면, 상 기 전자 장치 201는 하드 드라이브와 같은 저장 장치(또는 저장 매체)를 더 포함할 수 있다. 상기 센서 모듈 240은 물리량을 계측하거나 전자 장치 201의 작동 상태를 감지하여, 계측 또는 감지된 정보를 전기 신호로 변환할 수 있다. 상기 센서 모듈 240은, 예를 들면, 제스처 센서 240A, 자이로 센서 240B, 기압 센서 240C, 마그네틱 센서 240D, 가속도 센서 240E, 그립 센서 240F, 근접 센서 240G, color 센서 240H(예: RGB(red, green, blue) 센서), 생체 센서 240I, 온/습도 센서 240J, 조도 센서 240K 또는 UV(ultra violet) 센 서 240M 중의 적어도 하나를 포함할 수 있다. 추가적으로 또는 대체적으로, 상기 센서 모듈 240은, 예를 들면, 후각 센서(E-nose sensor, 미도시), EMG 센서(electromyography sensor, 미도시), EEG 센서 (electroencephalogram sensor, 미도시), ECG 센서(electrocardiogram sensor, 미도시), IR(infra red) 센서 (미도시), 홍채 센서(미도시) 또는 지문 센서(미도시) 등을 포함할 수 있다. 상기 센서 모듈 240은 그 안에 속 한 적어도 하나 이상의 센서들을 제어하기 위한 제어 회로를 더 포함할 수 있다. 상기 입력 장치 250은 터치 패널(touch panel) 252, (디지털) 펜 센서(pen sensor) 254, 키(key) 256 또는 초 음파(ultrasonic) 입력 장치 258를 포함할 수 있다. 상기 터치 패널 252은, 예를 들면, 정전식, 감압식, 적외선 방식 또는 초음파 방식 중 적어도 하나의 방식으로 터치 입력을 인식할 수 있다. 또한, 상기 터치 패널 252은 제어 회로를 더 포함할 수도 있다. 정전식의 경우, 물리적 접촉 또는 근접 인식이 가능하다. 상기 터치 패널 252은 택타일 레이어(tactile layer)를 더 포함할 수도 있다. 이 경우, 상기 터치 패널 252은 사용자에게 촉각 반응을 제공할 수 있다. 상기 (디지털) 펜 센서 254는, 예를 들면, 사용자의 터치 입력을 받는 것과 동일 또는 유사한 방법 또는 별도의 인식용 쉬트(sheet)를 이용하여 구현될 수 있다. 상기 키 256는, 예를 들면, 물리적인 버튼, 광학식 키 또는 키 패드를 포함할 수 있다. 상기 초음파(ultrasonic) 입력 장치 258는 초음파 신호를 발생하는 입력 도구를 통해, 전자 장치 201에서 마이크(예: 마이크 288)로 음파를 감지하여 데이터를 확인할 수 있는 장치로서, 무선 인식이 가능하다. 한 실시예에 따르면, 상기 전자 장치 201는 상기 통신 모듈 220를 이용하여 이와 연결된 외부 장치 (예: 컴퓨터 또는 서버)로부터 사용자 입력을 수신할 수도 있다. 상기 디스플레이 260(예: 상기 디스플레이 150)은 패널 262, 홀로그램 장치 264 또는 프로젝터 266을 포함할 수 있다. 상기 패널 262은, 예를 들면, LCD(liquid-crystal display) 또는 AM-OLED(active-matrix organic light- emitting diode) 등일 수 있다. 상기 패널 262은, 예를 들면, 유연하게(flexible), 투명하게(transparent) 또 는 착용할 수 있게(wearable) 구현될 수 있다. 상기 패널 262은 상기 터치 패널 252과 하나의 모듈로 구성될 수 도 있다. 상기 홀로그램 장치 264은 빛의 간섭을 이용하여 입체 영상을 허공에 보여줄 수 있다. 상기 프로젝터 266는 스크린에 빛을 투사하여 영상을 표시할 수 있다. 상기 스크린은, 예를 들면, 상기 전자 장치 201의 내부 또는 외부에 위치할 수 있다. 한 실시예에 따르면, 상기 디스플레이 260은 상기 패널 262, 상기 홀로그램 장치 264, 또는 프로젝터 266를 제어하기 위한 제어 회로를 더 포함할 수 있다. 상기 인터페이스 270는, 예를 들면, HDMI(high-definition multimedia interface) 272, USB(universal serial bus) 274, 광 인터페이스(optical interface) 276 또는 D-sub(D-subminiature) 278를 포함할 수 있다. 상기 인 터페이스 270는, 예를 들면, 도 1에 도시된 통신 인터페이스 160에 포함될 수 있다. 추가적으로 또는 대체적으 로, 상기 인터페이스 270는, 예를 들면, MHL(mobile high-definition link) 인터페이스, SD(secure Digital) 카드/MMC(multi-media card) 인터페이스 또는 IrDA(infrared data association) 규격 인터페이스를 포함할 수 있다. 상기 오디오 모듈 280은 소리(sound)와 전기신호를 쌍방향으로 변환시킬 수 있다. 상기 오디오 모듈 280의 적어 도 일부 구성요소는, 예를 들면, 도 1 에 도시된 입출력 인터페이스 140에 포함될 수 있다. 상기 오디오 모듈 280은, 예를 들면, 스피커 282, 리시버 284, 이어폰 286 또는 마이크 288 등을 통해 입력 또는 출력되는 소리 정보를 처리할 수 있다. 상기 카메라 모듈 291은 정지 영상 및 동영상을 촬영할 수 있는 장치로서, 한 실시예에 따르면, 하나 이상의 이 미지 센서(예: 전면 센서 또는 후면 센서), 렌즈(미도시), ISP(image signal processor, 미도시) 또는 플래쉬 (flash, 미도시)(예: LED 또는 xenon lamp)를 포함할 수 있다. 상기 전력 관리 모듈 295은 상기 전자 장치 201의 전력을 관리할 수 있다. 도시하지는 않았으나, 상기 전력 관 리 모듈 295은, 예를 들면, PMIC(power management integrated circuit), 충전 IC(charger integrated circuit) 또는 배터리 또는 연료 게이지(battery or fuel gauge)를 포함할 수 있다. 상기 PMIC는, 예를 들면, 집적회로 또는 SoC 반도체 내에 탑재될 수 있다. 충전 방식은 유선과 무선으로 구분 될 수 있다. 상기 충전 IC는 배터리를 충전시킬 수 있으며, 충전기로부터의 과전압 또는 과전류 유입을 방지할 수 있다. 한 실시예에 따르면, 상기 충전 IC는 유선 충전 방식 또는 무선 충전 방식 중 적어도 하나를 위한 충 전 IC를 포함할 수 있다. 무선 충전 방식으로는, 예를 들면, 자기공명 방식, 자기유도 방식 또는 전자기파 방식등이 있으며, 무선 충전을 위한 부가적인 회로, 예를 들면, 코일 루프, 공진 회로 또는 정류기 등의 회로가 추 가될 수 있다. 상기 배터리 게이지는, 예를 들면, 상기 배터리 296의 잔량, 충전 중 전압, 전류 또는 온도를 측정할 수 있다. 상기 배터리 296는 전기를 저장 또는 생성할 수 있고, 그 저장 또는 생성된 전기를 이용하여 상기 전자 장치 201에 전원을 공급할 수 있다. 상기 배터리 296는, 예를 들면, 충전식 전지(rechargeable battery) 또는 태양 전지(solar battery)를 포함할 수 있다. 상기 인디케이터 297는 상기 전자 장치 201 혹은 그 일부(예: 상기 AP 210)의 특정 상태, 예를 들면, 부팅 상태, 메시지 상태 또는 충전 상태 등을 표시할 수 있다. 상기 모터 298는 전기적 신호를 기계적 진동으로 변환 할 수 있다. 도시되지는 않았으나, 상기 전자 장치 201는 모바일 TV 지원을 위한 처리 장치(예: GPU)를 포함할 수 있다. 상기 모바일 TV지원을 위한 처리 장치는, 예를 들면, DMB(digital multimedia broadcasting), DVB(digital video broadcasting) 또는 미디어플로우(media flow) 등의 규격에 따른 미디어 데이터를 처리할 수 있다. 본 발명의 다양한 실시예에 따른 전자 장치의 전술한 구성요소들 각각은 하나 또는 그 이상의 부품(component) 으로 구성될 수 있으며, 해당 구성 요소의 명칭은 전자 장치의 종류에 따라서 달라질 수 있다. 본 발명의 다양 한 실시예에 따른 전자 장치는 전술한 구성요소 중 적어도 하나를 포함하여 구성될 수 있으며, 일부 구성요소가 생략되거나 또는 추가적인 다른 구성요소를 더 포함할 수 있다. 또한, 본 발명의 다양한 실시예에 따른 전자 장치의 구성 요소들 중 일부가 결합되어 하나의 개체(entity)로 구성됨으로써, 결합되기 이전의 해당 구성 요소 들의 기능을 동일하게 수행할 수 있다. 도 3은 본 발명의 다양한 실시 예에 따른 전자 장치의 개괄적인 블록도를 도시한다. 다양한 실시 예에 따르면, 본 발명에 따른 전자 장치는 제1 카메라 모듈, 제2 카메라 모듈, 깊이 센서(depth sensor, 303), 제 어부, 디스플레이 및 메모리를 포함할 수 있다. 다양한 실시 예에 따르면, 제1 카메라 모듈 및 제2 카메라 모듈은 각각의 카메라 모듈의 각도에서 피 사체를 감지하여, 영상 정보를 획득할 수 있다. 한 실시 예에 따르면, 카메라 모듈(301, 302)은 피사체에 대한 촬영을 통해 획득한 수집 영상을 이미지 프로세서로 제공할 수 있다. 한 실시 예에 따르면, 카메라 모듈(301, 302)은 복수 개의 컬러 픽셀들을 포함하는 영상을 수집하여 제어부 또는 이미지 프로세서 중 적어도 하나 로 제공할 수 있다. 한 실시 예에 따르면, 카메라 모듈(301, 302)은 전자 장치에 연결된 적어도 하나의 이미지 센서 모듈을 포함할 수 있다. 한 실시 예에 따르면, 여러 개의 카메라 모듈을 배치하여 이들 동시에 촬영하는 어레이 카메라(array camera)를 포함할 수 있다. 다양한 실시 예에 따르면, 깊이 센서는 복수의 피사체의 깊이 정보(depth information)를 획득할 수 있다. 한 실시 예에 따르면, 깊이 센서는 비행시간(Time-of-Flight) 방식으로 작동하는 적외선 펄스 레이저로 구 현되어 측정 대상체의 깊이 정보를 출력하는 센서를 포함할 수 있다. 다양한 실시 예에 따르면, 제어부는 제1 카메라 모듈 및 제2 카메라 모듈에서 출력된 영상 정보 및 깊이 센서에서 출력된 깊이 정보를 이용하여, 이미지를 처리할 수 있다. 한 실시 예에 따르면, 제어부 는 상술한 구성 요소들(제1 카메라 모듈, 제2 카메라 모듈, 깊이 센서 및 디스플레이 )로부터 명령을 수신하여, 수신된 명령을 해독하고, 해독된 명령에 따른 연산이나 데이터 처리를 실행할 수 있다. 한 실시 예에 따르면, 제어부는 제1 카메라 모듈 및 제2 카메라 모듈로부터 입력된 영상의 이미 지 처리를 수행하는 이미지 처리 프로세서를 포함할 수 있다. 다양한 실시 예에 따르면, 이미지 처리 프로세서 는 제1 카메라 모듈 및 제2 카메라 모듈을 통해 연속 촬영된 복수 개의 이미지들을 합성하여 복수 개 의 서브 이미지들에 초점이 맞춰진 하나의 이미지를 생성할 수 있다. 한 실시 예에 따르면, 이미지 처리 프로세서는 이미지 변환 프로그램을 실행하여 연속 촬영된 복수 개의 이미지 들을 하나의 이미지로 합성할 수 있다. 한 실시 예에 따르면, 이미지 처리 프로세서는 각각의 이미지에 대한 화 각 차이로 인산 서브 이미지의 크기 차이를 보상하기 위해, 각각의 이미지에서 초점이 맞는 서브 이미지의 외곽 선에서 기준 간격만큼 이격된 테두리까지 해당 서브 이미지를 추출하여 하나의 이미지로 합성할 수 있다. 한 실시 예에 따르면, 이미지 처리 프로세서는 연속 촬영된 복수 개의 이미지들의 화각이 동일해지도록 화각이 가장 작은 이미지를 기준으로 적어도 하나의 나머지 이미지를 편집한 후, 각각의 이미지에서 초점이 맞는 서브 이미지를 추출하여 하나의 이미지로 합성할 수 있다. 한 실시 예에 따르면, 이미지 처리 프로세서는 화각이 가장 작은 이미지를 기준으로 적어도 하나의 나머지 이미 지의 테두리의 적어도 일부 영역을 잘라내기 한 후, 합성을 위한 서브 이미지를 추출할 수 있다. 다양한 실시 예에 따르면, 디스플레이는 멀티미디어 데이터 또는 텍스트 데이터와 같은 각종 정보 및 이미 지를 표시할 수 있다. 다양한 실시 예에 따르면, 메모리는 다른 구성 요소들(제1 카메라 모듈, 제2 카메라 모듈, 제어 부 및 디스플레이)로부터 수신되거나, 다른 구성 요소들로부터 생성된 명령 또는 데이터를 저장할 수 있다. 한 실시 예에 따르면, 메모리는 커널, 미들웨어, 애플리케이션 프로그래밍 인터페이스(Application Programming Interface) 또는 애플리케이션 등의 프로그래밍 모듈들을 포함할 수 있다. 상술한 프로그래밍 모듈 들은 소프트웨어, 펌웨어, 하드웨어 또는 이들 중 적어도 둘 이상의 조합으로 구성될 수 있다. 도 4는 본 발명의 다양한 실시 예에 따른 카메라 모듈을 구성을 도시한다. 다양한 실시 예에 따르면, 본 발명의 카메라 모듈은 전자 장치의 일 측면에 구비될 수 있다. 예를 들면, 도 4의(a)에 도시된 바와 같이, 카메라 모듈 (401, 402)은 전자 장치의 후면의 설정된 영역에 구비될 수 있다. 한 실시 예에 따르면, 제2 카메라 모듈 은 센싱부로 명명될 수 있다. 한 실시 예에 따르면, 센싱부는 적외선 펄스 레이저를 발광하여, 피사체에 반사되 어 입력되는 시간정보를 이용하여, 깊이 정보를 판단하는 TOF 방식의 센서를 포함할 수 있다. 한 실시 예에 따 르면, 제1 카메라 모듈과 제2 카메라 모듈은 인접한 거리에 구비될 수도 있고, 서로 최대한 먼 거리 에 구비될 수도 있다. 다양한 실시 예에 따르면, 제2 카메라 모듈은 복수 개의 어레이 카메라일 수 있다. 예를 들면, 도 4의(b) 에 도시된 바와 같이, 제2 카메라 모듈은 하나의 카메라만이 구비된 제1 카메라 모듈과는 다르게 복 수 개의 카메라가 구비된 어레이 카메라일 수 있다. 한 실시 예에 따르면, 제2 카메라 모듈은 복수의 카메 라로부터 획득된 영상을 이용하여 깊이 정보를 생성할 수 있다. 한 실시 예에 따르면, 전자 장치는 제1 카메라 모듈로부터 획득된 영상정보 및 제2 카메라 모듈로부터 획득된 복수의 이미지 정보를 이용하여, 하나 이상의 깊이 정보를 생성할 수 있다. 다양한 실시 예에 따르면, 제2 카메라 모듈은 적어도 두 개의 카메라가 구비된 3차원 카메라일 수 있다. 예를 들면, 도 4의(c)에 도시된 바와 같이, 제2 카메라 모듈은 촬영된 피사체의 영상을 3차원적으로 표시 할 수 있는 3차원 카메라일 수 있다. 한 실시 예에 따르면, 제2 카메라 모듈은 복수 개의 카메라에서 들어 오는 영상을 이용하여, 3차원적인 이미지를 생성할 수 있다. 본 발명의 다양한 실시 예에 따르면, 전자 장치에 있어서, 복수의 이미지를 획득하는 적어도 둘 이상의 이미지 센서; 및 상기 획득된 복수의 이미지에 포함된 적어도 둘 이상의 피사체의 깊이 정보를 추출하고, 상기 추출된 깊이 정보에 기반하여, 상기 피사체에 이미지를 처리하는 프로세서를 포함할 수 있다. 상기 복수의 이미지를 획득하는 적어도 하나 이상의 카메라 모듈을 더 포함할 수 있다. 상기 프로세서는, 상면 위상 차 센서, 위상 차 센서, TOF(Time Of Flight) 센서, 적외선 센서 및 이미지 센서 중 적어도 하나를 이용하여, 상기 피사체와의 거리를 계산하는 것을 포함할 수 있다. 상기 프로세서는, 상기 획득된 복수의 이미지를 조합하고, 상기 조합된 복수의 이미지를 이용하여, 3차원의 이 미지를 생성하는 것을 포함할 수 있다. 상기 프로세서는, 상기 피사체 중 근거리에 위치한 제1 피사체에 초점이 맞추어진 제1 이미지를 생성하고, 상기 피사체 중 원거리에 위치한 제2 피사체에 초점이 맞추어진 제2 이미지를 생성하며, 상기 근거리 및 상기 원거리 사이에 위치한 제3 피사체에 초점이 맞추어진 제3 이미지를 생성하는 것을 포함할 수 있다. 상기 제1 이미지 내지 제3 이미지 중 설정된 이미지를 표시하는 디스플레이를 더 포함할 수 있다. 상기 프로세서는, 상기 제1 이미지 내지 제3 이미지를 합성하고, 상기 합성된 이미지를 표시하는 디스플레이를 더 포함할 수 있다. 상기 피사체에 포함된 근거리에 위치한 제1 피사체에 초점이 맞추어진 제1 이미지, 원거리에 위치한 제2 피사체 에 초점이 맞추어진 제2 이미지, 상기 근거리와 상기 원거리 사이에 위치한 제3 피사체에 초점이 맞추어진 제3 이미지 및 상기 제1 이미지 내지 제3 이미지가 합성된 이미지 중, 어느 하나의 이미지를 표시하는 디스플레이를 더 포함하고, 상기 프로세서는, 상기 디스플레이된 어느 하나의 이미지에 대한 편집을 감지하는 것을 포함할 수 있다. 상기 디스플레이는 상기 표시된 어느 하나의 이미지에 포함된 상기 제1 피사체 내지 제3 피사체 중 어느 하나를 선택받고, 상기 프로세서는, 상기 선택받은 피사체를 기준으로 선택받지 않은 나머지 피사체들의 상대적인 거리 를 판단하고, 상기 판단된 거리에 따라, 상대적인 거리가 먼 피사체에 상대적으로 큰 블러를 적용하고, 상대적 인 거리가 가까운 피사체에 상대적으로 작은 블러를 적용하는 것을 포함할 수 있다. 상기 프로세서는, 상기 획득된 이미지의 크기에 맞도록, 상기 추출된 깊이 정보를 스켈링하는 것을 포함할 수 있다. 도 5는 본 발명의 다양한 실시 예에 따른 깊이 정보를 추출하는 일 실시 예를 도시한다. 다양한 실시 예에 따르 면, 전자 장치는 카메라 모듈로부터 복수의 이미지를 획득할 수 있다. 예를 들면, 도 5의(a)에 도시된 바와 같 이, 전자 장치는 제1 카메라 모듈로부터 제1 이미지를 획득할 수 있고, 제2 카메라 모듈로부터 제2 이미지 및 제3 이미지를 획득할 수 있다. 한 실시 예에 따르면, 전자 장치는 하나의 카메라가 구비된 제1 카메 라 모듈로부터 제1 이미지를 획득할 수 있고, 어레이 카메라가 구비된 제2 카메라 모듈로부터 제2 이 미지 및 제3 이미지를 획득할 수 있다. 또 다른 예를 들면, 도 5의(b)에 도시된 바와 같이, 전자 장치는 제1 카메라 모듈로부터 제1 이미지를 획 득할 수 있고, 제2 카메라 모듈로부터 제2 이미지 및 제3 이미지를 획득할 수 있다. 한 실시 예에 따르면, 전자 장치는 하나의 카메라가 구비된 제1 카메라 모듈로부터 제1 이미지를 획득할 수 있고, 두 개의 3차원 카메라가 구비된 제2 카메라 모듈로부터 제2 이미지 및 제3 이미지를 획득할 수 있다. 다양한 실시 예에 따르면, 전자 장치는 제1 카메라 모듈 및 제2 카메라 모듈로부터 획득된 복수의 이 미지로부터 하나 이상의 깊이 정보를 추출할 수 있다. 예를 들면, 도 5의(c)에 도시된 바와 같이, 전자 장치의 제1 이미지 센서, 제2 이미지 센서 및 제3 이미지 센서에서 각각 제1 이미지, 제2 이미지 및 제 3 이미지를 획득한 경우를 예를 들어 보겠다. 상술한 예에서, 전자 장치는 제1 이미지 센서에서 획득한 제1 이미지와 제2 이미지 센서에서 획득한 제2 이미지를 이용하여, 제1 깊이 정보를 추출할 수 있다. 한 실시 예에 따르면, 전자 장치는 제2 이미지 센서에서 획득한 제2 이미지와 제3 이미지 센서에서 획득한 제3이미지를 이용하여, 제2 깊이 정보 를 추출할 수 있다. 한 실시 예에 따르면, 전자 장치는 제1 이미지 센서에서 획득한 제1 이미지와 제 3 이미지 센서에서 획득한 제3이미지를 이용하여, 제3 깊이 정보를 추출할 수 있다. 도 6은 본 발명의 다양한 실시 예에 따른 피사체의 거리에 따라 깊이 정보를 추출하는 일 실시 예를 도시한다. 다양한 실시 예에 따르면, 전자 장치는 전자 장치에 구비된 제1 카메라 모듈(601, 602) 및 제2 카메라 모듈 을 이용하여, 피사체(604, 605, 606)의 이미지 정보를 획득할 수 있다. 한 실시 예에 따르면, 전자 장치는 제1 카메라 모듈(601, 602)에 포함된 제1 카메라 및 제2 카메라와 제2 카메라 모듈에 포함된 제3 카 메라 중 두 개의 카메라를 이용하여, 피사체(604, 605, 606)의 이미지 정보를 획득할 수 있다. 예를 들면, 도 6의(a)에 도시된 바와 같이, 전자 장치가 근거리에 위치한 피사체를 촬영할 경우, 전자 장 치는 전자 장치에 구비된 카메라(601, 602, 603) 중 상대적으로 가장 근거리에 위치한 제1 카메라 및 제2 카메라를 이용하여, 피사체의 이미지를 획득한 후, 획득된 이미지를 이용하여 피사체의 제1 깊이 정 보를 추출할 수 있다. 한 실시 예에 따르면, 전자 장치에서 획득된 제1 깊이 정보는 제1 카메라 및 제2 카 메라가 상대적으로 가장 근접한 거리에 위치하기 때문에 근거리에 대응되는 깊이 정보를 추출할 수 있다. 또 다른 예를 들면, 도 6의(b)에 도시된 바와 같이, 전자 장치가 근거리와 원거리의 중간에 해당하는 중간거리 에 위치한 피사체를 촬영할 경우, 전자 장치는 전자 장치에 구비된 카메라(601, 602, 603) 중 상대적으로 중간거리에 위치한 제2 카메라 및 제3 카메라를 이용하여, 피사체의 이미지를 획득한 후, 획득 된 이미지를 이용하여 제2 피사체의 깊이 정보를 추출할 수 있다. 한 실시 예에 따르면, 전자 장치에서 획득된 제2 깊이 정보는 제2 카메라 및 제3 카메라가 상대적으로 제1 깊이 정보를 추출한 카메라(601, 602)간의 거리에 비해 멀리 떨어져 있기 때문에, 상대적으로 중간거리에 대응되는 깊이 정보를 추출할 수 있다. 또 다른 예를 들면, 도 6의(c)에 도시된 바와 같이, 전자 장치가 원거리에 위치한 피사체를 촬영할 경우, 전자 장치는 전자 장치에 구비된 카메라(601, 602, 603) 중 상대적으로 가장 원거리에 위치한 제1 카메라 및 제3 카메라를 이용하여, 피사체의 이미지를 획득한 후, 획득된 이미지를 이용하여 피사체의 제3 깊이 정보를 추출할 수 있다. 한 실시 예에 따르면, 전자 장치에서 획득된 제3 깊이 정보는 제1 카메라 및 제3 카메라가 상대적으로 가장 멀리 위치하기 때문에, 원거리에 대응되는 깊이 정보를 추출할 수 있다. 도 7은 본 발명의 다양한 실시 예에 따른 획득된 정보를 저장 및 표시하는 일 실시 예를 도시한다. 다양한 실시 예에 따르면, 이미지 센서는 사용자의 선택에 따라 프리뷰 이미지를 출력할 수 있다. 이와 동시에 또 는 순차적으로 이미지 처리 프로세서는 추출된 피사체의 깊이 이미지를 출력할 수 있다. 다양한 실시 예에 따르면, 전자 장치가 프리뷰 이미지를 전자 장치의 디스플레이에 표시하고자 하는 경우, 전자 장치는 깊이 이미지의 크기를 스켈링(scaling)할 수 있다. 한 실시 예에 따르면, 이미지 센서에 서 출력된 프리뷰 이미지의 크기가 3.7MB(Mega Bite)인 경우, 전자 장치는 이미지 처리 프로세서에서 추출된 깊이 이미지의 크기를 프리뷰 이미지의 크기와 동일하게 하기 위하여, 깊이 이미지의 크 기를 3.7MB의 크기로 스켈링할 수 있다. 다양한 실시 예에 따르면, 전자 장치는 이미지 센서에서 출력된 프리뷰 이미지와 스켈링된 깊이 이미 지를 합성하여, 합성된 이미지를 전자 장치의 디스플레이에 표시할 수 있다. 다양한 실시 예에 따르면, 이미지 센서는 사용자의 선택에 따라 카메라 이미지를 출력할 수 있다. 이 와 동시에 또는 순차적으로 이미지 처리 프로세서는 추출된 피사체의 깊이 이미지를 출력할 수 있다. 다양한 실시 예에 따르면, 전자 장치가 출력된 카메라 이미지를 전자 장치의 메모리에 저장하고자 하는 경 우, 전자 장치는 깊이 이미지의 크기를 스켈링할 수 있다. 한 실시 예에 따르면, 이미지 센서에서 출 력된 카메라 이미지의 크기가 16MB인 경우, 전자 장치는 이미지 처리 프로세서에서 추출된 깊이 이미 지의 크기를 카메라 이미지의 크기와 동일하게 하기 위하여, 깊이 이미지의 크기를 16MB의 크기 로 스켈링할 수 있다. 다양한 실시 예에 따르면, 전자 장치는 이미지 센서에서 출력된 카메라 이미지와 스켈링된 깊이 이미 지를 합성하여, 합성된 이미지를 전자 장치의 메모리에 저장할 수 있다. 도 8은 본 발명의 다양한 실시 예에 따른 추출된 깊이 정보를 이용하여 이미지를 처리하는 일 실시 예를 도시한 다. 다양한 실시 예에 따르면, 전자 장치는 추출된 깊이 정보를 이용하여, 카메라 렌즈 구동부를 움직여 각각 다른 이미지에 초점이 맞는 이미지들을 촬영할 수 있다. 한 실시 예에 따르면, 전자 장치는 추출된 깊이 정보를 이용하여 연속 촬영을 위한 서브 이미지의 상대적인 거리를 추정한 경우, 서브 이미지의 상대적인 거리에 기반 하여 렌즈의 초점을 움직여 각각의 서브 이미지에 초점이 맞춰진 하나 이상의 이미지를 촬영할 수 있다. 예를 들면, 도 8의(a)에 도시된 바와 같이, 전자 장치로부터 각각 d1 거리 및 d2 거리에 제1 피사체 및 제2 피사체가 위치한 경우를 예를 들어 보겠다. 상술한 예에서, 전자 장치는 전자 장치로부 터 각각 d1 거리 및 d2 거리에 위치한 제1 피사체 및 제2 피사체에 초점이 맞춰진 서브 이미지들을 촬영할 수 있다. 또한, 전자 장치는 배경이 되는 이미지에 초점이 맞춰진 서브 이미지를 촬영할 수 있다. 다양한 실시 예에 따르면, 전자 장치에서 각각의 피사체 및 배경 이미지에 초점이 맞춰진 서브 이미지들을 촬영 한 경우, 전자 장치는 각각의 초점이 맞춰진 부분을 다른 부분보다 선명하게 표시할 수 있다. 한 실시 예에 따 르면, 전자 장치는 상대적인 거리가 먼 피사체에 상대적으로 큰 블러(blur)를 적용하고, 상대적인 거리가 가까 운 피사체에 상대적으로 작은 블러를 적용할 수 있다. 예를 들면, 도 8의(a) 및 (c)에 도시된 바와 같이, 전자 장치가 전자 장치로부터 d1 거리에 위치한 제1 피사체에 초점이 맞춰진 서브 이미지를 촬영한 경우, 전자 장치는 제2 피사체 및 배경 이미 지는 흐릿하게 표시하고, 제1 피사체는 가장 선명하게 표시할 수 있다. 또 다른 예를 들면, 도 8의(a) 및 (d)에 도시된 바와 같이, 전자 장치가 전자 장치로부터 d2 거리에 위치한 제2 피사체에 초점이 맞춰진 서브 이미지를 촬영한 경우, 전자 장치는 제1 피사체 및 배경 이미지는 흐릿하게 표시하고, 제2 피사체는 가장 선명하게 표시할 수 있다. 또 다른 예를 들면, 도 8의(a) 및 (e)에 도시된 바와 같이, 전자 장치가 전자 장치로부터 가장 원거 리에 위치한 배경 이미지에 초점이 맞춰진 서브 이미지를 촬영한 경우, 전자 장치는 제1 피사체 및 제2 피사체는 흐릿하게 표시하고, 배경 이미지는 가장 선명하게 표시할 수 있다. 다양한 실시 예에 따르면, 전자 장치는 사용자의 선택에 따라 촬영된 각각의 서브 이미지들을 하나의 이미지로 합성할 수 있다. 예를 들면, 도 8의(a) 및 (b)에 도시된 바와 같이, 전자 장치에서 제1 피사체, 제2 피사체 및 배경 이미지에 각각 초점이 맞춰진 서브 이미지를 촬영한 경우, 전자 장치는 각각의 서브 이미지를 합성하여 하나의 이미지로 합성할 수 있다. 도 9는 본 발명의 다양한 실시 예에 따른 서로 다른 초점 정보를 포함하는 이미지들을 합성하는 일 실시 예를 도시한다. 다양한 실시 예에 따르면, 전자 장치는 촬영된 각각의 서브 이미지들을 합성하도록 하는 이벤트가 발 생하였는지 확인할 수 있다. 한 실시 예에 따르면, 전자 장치는 입력 모듈을 통해 검출한 입력 정보에 기반하여, 이미지 합성에 대한 이벤트가 발생하였는지 확인할 수 있다. 예를 들면, 전자 장치는 입력 모듈을 통 해 촬영된 서브 이미지들을 합성하도록 하는 명령을 입력받았는지 여부를 확인할 수 있다. 한 실시 예에 따르면, 전자 장치는 이미지 합성에 대한 이벤트에 대응하는 사용자의 제스처가 감지되었는지 여 부를 확인할 수 있다. 예를 들면, 전자 장치는 설정된 사용자의 터치 입력, 드래그 및 제스처를 감지하여, 이미 지 합성을 수행할 수 있다. 한 실시 예에 따르면, 전자 장치는 초점이 다른 복수의 이미지들을 검출한 경우, 자동으로 이미지 합성에 대한 이벤트로 인지할 수 있다. 예를 들면, 전자 장치가 각각 제1 피사체, 제2 피사체 및 배경 이미지에 초점이 맞춰 진 서브 이미지들을 검출한 경우, 전자 장치는 자동으로 이미지 합성에 대한 이벤트로 인지하여, 각각의 서브 이미지들을 하나의 이미지로 합성할 수 있다. 상술한 예들을 통하여, 전자 장치는 촬영된 각각의 서브 이미지들을 합성하도록 하는 이벤트가 발생하였는지 확 인할 수 있다. 예를 들면, 도 9의(a) 내지 (d)에 도시된 바와 같이, 전자 장치가 각각 제1 피사체, 배경 이미지 및 제2 피사체에 초점이 맞춰져 서브 이미지들을 촬영한 후, 전자 장치에서 촬영된 서브 이미 지들(901, 902, 903)을 합성하도록 하는 이벤트를 감지한 경우, 전자 장치는 각각의 서브 이미지들(901, 902, 903)을 하나의 이미지로 합성할 수 있다. 도 10은 본 발명의 다양한 실시 예에 따른 이미지를 편집하는 일 실시 예를 도시한다. 다양한 실시 예에 따르면, 전자 장치에서 촬영된 각각의 서브 이미지들을 합성하도록 하는 이벤트를 감지한 경우, 전자 장치는 복 수의 서브 이미지들을 하나의 이미지로 합성할 수 있다. 예를 들면, 도 10의(a)에 도시된 바와 같이, 전자 장치 는 제1 피사체에 초점이 맞춰진 제1 이미지, 제2 피사체에 초점이 맞춰진 제2 이미지 및 배경 이미 지에 초점이 맞춰진 제3 이미지를 하나의 이미지로 합성할 수 있다. 다양한 실시 예에 따르면, 전자 장치가 전자 장치의 디스플레이에 표시된 이미지를 편집하도록 하는 이벤트를 감지한 경우, 전자 장치는 설정된 방법에 따라 표시된 이미지를 편집할 수 있다. 예를 들면, 도 10의(b) 및 (c)에 도시된 바와 같이, 전자 장치에서 제1 피사체, 제2 피사체 및 배경 이미지가 하나의 이미지로 합성된 이미지를 표시한 후, 사용자의 선택에 따라 이미지를 편집할 수 있다. 이하, 전자 장치를 기준 으로 전자 장치와 가장 가까운 위치부터 제1 피사체, 제2 피사체 및 배경 이미지가 있는 경 우를 예를 들어 설명하겠다. 한 실시 예에 따르면, 전자 장치가 전자 장치의 디스플레이에 합성된 이미지를 표시한 후, 사용자로부터 제1 피 사체를 선택받은 경우, 전자 장치는 선택받은 제1 피사체를 기준으로 선택받지 않은 나머지 피사체 (1002, 1003)의 상대적인 거리를 판단할 수 있다. 한 실시 예에 따르면, 전자 장치는 판단된 거리에 따라, 상대 적인 거리가 먼 배경 이미지에 상대적으로 큰 블러를 적용하고, 상대적인 거리가 가까운 제2 피사체 에 상대적으로 작은 블러를 적용할 수 있다. 한 실시 예에 따르면, 전자 장치가 전자 장치의 디스플레이에 합성된 이미지를 표시한 후, 사용자로부터 제2 피 사체를 선택받은 경우, 전자 장치는 선택받은 제2 피사체를 기준으로 선택받지 않은 나머지 피사체 (1001, 1003)의 상대적인 거리를 판단할 수 있다. 한 실시 예에 따르면, 전자 장치는 판단된 거리에 따라, 상대적인 거리가 먼 배경 이미지에 상대적으로 큰 블러를 적용하고, 상대적인 거리가 가까운 제1 피사체 에 상대적으로 작은 블러를 적용할 수 있다. 도 11은 본 발명의 다양한 실시 예에 따른 전자 장치의 제1 순서도를 도시한다. 도 11에 도시된 바와 같이, 동 작 1101에서, 전자 장치는 제1 카메라로부터 제1 이미지를 획득할 수 있다. 한 실시 예에 따르면, 전자 장치는 전자 장치의 설정된 위치에 구비된 복수의 카메라 중 제1 카메라로부터 수집한 제1 이미지를 획득할 수 있다. 동작 1002에서, 전자 장치는 제2 카메라로부터 제2 이미지를 획득할 수 있다. 한 실시 예에 따르면, 전자 장치 는 전자 장치의 설정된 위치에 구비된 복수의 카메라 중 제2 카메라로부터 수집한 제2 이미지를 획득할 수 있다. 동작 1003에서, 전자 장치는 제1 이미지와 제2 이미지를 이용하여, 3차원 이미지를 생성할 수 있다. 한 실시 예 에 따르면, 전자 장치는 제1 카메라 및 제2 카메라로부터 획득한 제1 이미지 및 제2 이미지를 합성하여, 3차원 적인 이미지를 생성할 수 있다. 동작 1004에서, 전자 장치는 생성된 3차원 이미지를 이용하여, 깊이 정보를 추출할 수 있다. 한 실시 예에 따르 면, 전자 장치를 기준으로 전자 장치와 가장 가까운 위치부터 제1 피사체, 제2 피사체 및 제3 피사체가 위치하 고 있는 경우, 전자 장치는 생성된 3차원 이미지를 이용하여, 근거리에 제1 피사체, 원거리에 제3 피사체 및 근 거리와 원거리 사이에 제2 피사체가 위치하고 있다는 깊이 정보를 추출할 수 있다. 한 실시 예에 따르면, 전자 장치는 상면 위상 차 센서, 위상 차 센서, TOF(Time Of Flight) 센서, 적외선 센서 및 이미지 센서 중 적어도 하나를 이용하여, 피사체와의 거리를 계산할 수 있다. 도 12는 본 발명의 다양한 실시 예에 따른 전자 장치의 제2 순서도를 도시한다. 도 12에 도시된 바와 같이, 동 작 1201에서, 전자 장치는 제1 카메라로부터 제1 이미지를 획득할 수 있다. 한 실시 예에 따르면, 전자 장치는 전자 장치의 설정된 위치에 구비된 복수의 카메라 중 제1 카메라로부터 수집한 제1 이미지를 획득할 수 있다. 동작 1202에서, 전자 장치는 어레이 카메라로부터 복수의 이미지를 획득할 수 있다. 한 실시 예에 따르면, 전자 장치는 전자 장치의 설정된 위치에 구비된 제2 카메라 역할을 수행하는 어레이 카메라로부터 복수의 이미지를 획득할 수 있다. 동작 1203에서, 전자 장치는 획득된 이미지를 조합하여, 깊이 정보를 추출할 수 있다. 한 실시 예에 따르면, 전 자 장치는 획득된 이미지를 조합하고, 구비된 다른 센서들을 이용하여, 깊이 정보를 추출할 수 있다. 예를 들면, 전자 장치는 전자 장치에서 획득된 이미지 및 상면 위상 차 센서, 위상 차 센서, TOF 센서, 적외선 센서 및 이미지 센서 중 적어도 하나를 이용하여, 피사체와의 거리를 계산할 수 있다. 동작 1204에서, 전자 장치는 깊이 정보를 제1 이미지의 크기에 맞게 스켈링할 수 있다. 다양한 실시 예에 따르 면, 전자 장치가 프리뷰 이미지를 전자 장치의 디스플레이에 표시하고자 하는 경우, 전자 장치는 깊이 정보를 제1 이미지의 크기에 맞게 스켈링할 수 있다. 한 실시 예에 따르면, 전자 장치의 이미지 센서에서 출력된 카메 라 이미지와 스켈링된 깊이 이미지를 합성하여, 합성된 이미지를 전자 장치의 메모리에 저장하고자 하는 경우, 전자 장치는 깊이 정보를 제1 이미지의 크기에 맞게 스켈링할 수 있다. 도 13은 본 발명의 다양한 실시 예에 따른 전자 장치의 제3 순서도를 도시한다. 도 13에 도시된 바와 같이, 동 작 1301에서, 전자 장치는 제1 카메라로부터 제1 이미지를 획득할 수 있다. 한 실시 예에 따르면, 전자 장치는 전자 장치의 설정된 위치에 구비된 복수의 카메라 중 제1 카메라로부터 수집한 제1 이미지를 획득할 수 있다. 동작 1302에서, 전자 장치는 깊이 센서를 이용하여 깊이 정보를 획득할 수 있다. 한 실시 예에 따르면, 전자 장 치는 상면 위상 차 센서, 위상 차 센서, TOF 센서, 적외선 센서 및 이미지 센서 등과 같은 깊이 센서를 이용하 여, 깊이 정보를 획득할 수 있다. 동작 1303에서, 전자 장치는 획득된 깊이 정보를 제1 이미지의 크기에 맞게 스켈링할 수 있다. 다양한 실시 예 에 따르면, 전자 장치가 프리뷰 이미지를 전자 장치의 디스플레이에 표시하고자 하는 경우, 전자 장치는 깊이 정보를 제1 이미지의 크기에 맞게 스켈링할 수 있다. 한 실시 예에 따르면, 전자 장치의 이미지 센서에서 출력 된 카메라 이미지와 스켈링된 깊이 이미지를 합성하여, 합성된 이미지를 전자 장치의 메모리에 저장하고자 하는경우, 전자 장치는 깊이 정보를 제1 이미지의 크기에 맞게 스켈링할 수 있다. 도 14는 본 발명의 다양한 실시 예에 따른 전자 장치의 제4 순서도를 도시한다. 도 14에 도시된 바와 같이, 전 자 장치는 복수의 카메라로부터 이미지를 획득할 수 있다. 한 실시 예에 따르면, 전자 장치는 전자 장치의 설정 된 위치에 구비된 복수의 카메라인 제1 카메라 및 제2 카메라로부터 수집한 제1 이미지 및 제2 이미지를 획득할 수 있다. 동작 1402에서, 전자 장치는 근거리용 깊이 정보를 생성할 수 있다. 한 실시 예에 따르면, 전자 장치는 획득된 복수의 이미지를 이용하여, 근거리용 깊이 정보를 생성할 수 있다. 동작 1403에서, 전자 장치는 원거리용 깊이 정보를 생성할 수 있다. 한 실시 예에 따르면, 전자 장치는 획득된 복수의 이미지를 이용하여, 원거리용 깊이 정보를 생성할 수 있다. 동작 1404에서, 전자 장치는 피사체의 거리를 측정할 수 있다. 한 실시 예에 따르면, 전자 장치는 전자 장치에 구비된 깊이 센서, 이미지 센서, 위상 차 센서, 상명 위상 차 센서 등이 이용하여, 피사체와의 상대적인 거리를 측정할 수 있다. 동작 1405에서, 전자 장치는 피사체가 근거리에 위치하고 있는지 여부를 판단할 수 있다. 동작 1406에서, 전자 장치에서 피사체가 근거리에 위치하고 있다고 판단한 경우, 전자 장치는 근거리용 깊이 정 보를 이용하여 이미지를 처리할 수 있다. 동작 1407에서, 전자 장치에서 피사체가 원거리에 위치하고 있다고 판단한 경우, 전자 장치는 원거리용 깊이 정 보를 이용하여 이미지를 처리할 수 있다. 도 15는 본 발명의 다양한 실시 예에 따른 전자 장치의 제5 순서도를 도시한다. 도 15에 도시된 바와 같이, 동 작 1501에서, 전자 장치는 제1 이미지 및 제2 이미지를 획득할 수 있다. 한 실시 예에 따르면, 전자 장치는 전 자 장치의 설정된 위치에 구비된 복수의 카메라인 제1 카메라 및 제2 카메라로부터 수집한 제1 이미지 및 제2 이미지를 획득할 수 있다. 동작 1502에서, 전자 장치는 제1 프리뷰 이미지 및 제2 프리뷰 이미지를 획득할 수 있다. 다양한 실시 예에 따 르면, 전자 장치의 이미지 센서는 사용자의 선택에 따라 프리뷰 이미지를 출력할 수 있다. 동작 1503에서, 전자 장치는 제1 프리뷰 이미지 및 제2 프리뷰 이미지를 이용하여 깊이 이미지를 생성할 수 있 다. 다양한 실시 예에 따르면, 전자 장치의 이미지 처리 프로세서는 추출된 피사체의 깊이 이미지를 출력할 수 있다. 동작 1504에서, 전자 장치는 사용자의 선택에 따라 제1 이미지에 맞게 깊이 이미지를 스켈링할 수 있다. 다양한 실시 예에 따르면, 전자 장치의 이미지 센서에서 출력된 제1 이미지의 크기가 3.7MB인 경우, 전자 장치는 이미 지 처리 프로세서에서 추출된 깊이 이미지의 크기를 제1 이미지의 크기와 동일하게 하기 위하여, 깊이 이미지의 크기를 3.7MB의 크기로 스켈링할 수 있다. 동작 1505에서, 전자 장치는 스켈링된 깊이 정보에 기반하여 이미지를 처리할 수 있다. 다양한 실시 예에 따르 면, 전자 장치는 서브 이미지들을 하나의 이미지로 합성할 수 있다. 동작 1506에서, 전자 장치는 처리된 이미지를 버퍼에 저장할 수 있다. 동작 1507에서, 전자 장치는 사용자의 선택에 따라 깊이 정보에 기반하여, 프리뷰 이미지를 처리할 수 있다. 동작 1508에서, 전자 장치는 처리된 프리뷰 이미지를 디스플레이에 표시할 수 있다. 동작 1509에서, 전자 장치는 디스플레이에 표시된 이미지가 캡처(촬영) 되었는지 판단할 수 있다. 동작 1510에서, 전자 장치가 디스플레이에 표시된 이미지가 캡처(촬영) 되었다고 판단한 경우, 전자 장치는 버 퍼 이미지를 인코딩하여 저장할 수 있다. 도 16은 본 발명의 다양한 실시 예에 따른 전자 장치의 방법의 흐름도를 도시한다. 도 16에 도시된 바와 같이, 동작 1601에서, 전자 장치는 복수의 이미지를 획득할 수 있다. 다양한 실시 예에 따르면, 전자 장치는 전자 장 치의 설정된 위치에 구비된 복수의 카메라인 제1 카메라 및 제2 카메라로부터 수집한 제1 이미지 및 제2 이미지 를 획득할 수 있다. 한 실시 예에 따르면, 상술한 카메라는 어레이 카메라를 포함할 수 있다. 동작 1602에서, 전자 장치는 획득된 복수의 이미지에 포함된 적어도 둘 이상의 피사체의 깊이 정보를 추출할 수 있다. 한 실시 예에 따르면, 전자 장치는 획득된 이미지를 조합하고, 구비된 다른 센서들을 이용하여, 깊이 정 보를 추출할 수 있다. 예를 들면, 전자 장치는 전자 장치에서 획득된 이미지 및 상면 위상 차 센서, 위상 차 센 서, TOF 센서, 적외선 센서 및 이미지 센서 중 적어도 하나를 이용하여, 피사체와의 거리를 계산할 수 있다. 동작 1603에서, 전자 장치는 추출된 깊이 정보에 기반하여, 피사체에 이미지를 처리할 수 있다. 예를 들면, 전 자 장치를 기준으로 전자 장치와 가장 가까운 위치부터 제1 피사체, 제2 피사체 및 배경 이미지가 있는 경우를 예를 들어 설명하겠다. 한 실시 예에 따르면, 전자 장치가 전자 장치의 디스플레이에 합성된 이미지를 표시한 후, 사용자로부터 제2 피사체를 선택받은 경우, 전자 장치는 선택받은 제2 피사체를 기준으로 선택받지 않은 나 머지 피사체의 상대적인 거리를 판단할 수 있다. 한 실시 예에 따르면, 전자 장치는 판단된 거리에 따라, 상대 적인 거리가 먼 배경 이미지에 상대적으로 큰 블러를 적용하고, 상대적인 거리가 가까운 제1 피사체에 상대적으 로 작은 블러를 적용할 수 있다. 본 발명의 따른 다양한 실시 예에 따르면, 전자 장치의 동작 방법에 있어서, 복수의 이미지를 획득하는 동작; 상기 획득된 복수의 이미지에 포함된 적어도 둘 이상의 피사체의 깊이 정보를 추출하는 동작; 및 상기 추출된 깊이 정보에 기반하여, 상기 피사체에 이미지를 처리하는 동작을 포함할 수 있다. 상기 복수의 이미지를 획득하는 동작은, 적어도 둘 이상의 이미지 센서를 이용하는 것을 포함할 수 있다. 상면 위상 차 센서, 위상 차 센서, TOF 센서, 적외선 센서 및 이미지 센서 중 적어도 하나를 이용하여, 상기 피 사체와의 거리를 계산하는 동작을 더 포함할 수 있다. 상기 깊이 정보를 추출하는 동작은, 상기 획득된 복수의 이미지를 조합하는 동작; 상기 조합된 복수의 이미지를 이용하여, 3차원의 이미지를 생성하는 동작을 포함할 수 있다. 상기 피사체에 이미지를 처리하는 동작은, 상기 피사체 중 근거리에 위치한 제1 피사체에 초점이 맞추어진 제1 이미지를 생성하는 동작; 상기 피사체 중 원거리에 위치한 제2 피사체에 초점이 맞추어진 제2 이미지를 생성하 는 동작; 및 상기 근거리 및 상기 원거리 사이에 위치한 제3 피사체에 초점이 맞추어진 제3 이미지를 생성하는 동작을 포함할 수 있다. 상기 제1 이미지 내지 제3 이미지 중 설정된 이미지를 디스플레이하는 동작을 더 포함할 수 있다. 상기 제1 이미지 내지 제3 이미지를 합성하는 동작; 및 상기 합성된 이미지를 디스플레이하는 동작을 더 포함할 수 있다. 상기 피사체에 포함된 근거리에 위치한 제1 피사체에 초점이 맞추어진 제1 이미지, 원거리에 위치한 제2 피사체 에 초점이 맞추어진 제2 이미지, 상기 근거리와 상기 원거리 사이에 위치한 제3 피사체에 초점이 맞추어진 제3 이미지 및 상기 제1 이미지 내지 제3 이미지가 합성된 이미지 중, 어느 하나의 이미지를 디스플레이하는 동작; 및 상기 디스플레이된 어느 하나의 이미지에 대한 편집을 감지하는 동작을 더 포함할 수 있다. 상기 편집을 감지하는 동작은, 상기 디스플레이된 어느 하나의 이미지에 포함된 상기 제1 피사체 내지 제3 피사 체 중 어느 하나를 선택받는 동작; 상기 선택받은 피사체를 기준으로 선택받지 않은 나머지 피사체들의 상대적 인 거리를 판단하는 동작; 및 상기 판단된 거리에 따라, 상대적인 거리가 먼 피사체에 상대적으로 큰 블러를 적 용하고, 상대적인 거리가 가까운 피사체에 상대적으로 작은 블러를 적용하는 동작을 포함할 수 있다. 상기 획득된 이미지의 크기에 맞도록, 상기 추출된 깊이 정보를 스켈링하는 동작을 더 포함할 수 있다. 그리고 본 명세서와 도면에 개시된 본 발명의 실시예들은 본 발명의 실시예에 따른 의 기술 내용을 쉽게 설명하 고 본 발명의 실시예의 이해를 돕기 위해 특정 예를 제시한 것일 뿐이며, 본 발명의 실시예의 범위를 한정하고 자 하는 것은 아니다. 따라서 본 발명의 다양한 실시예의 범위는 여기에 개시된 실시예들 이외에도 본 발명의 다양한 실시예의 기술적 사상을 바탕으로 도출되는 모든 변경 또는 변형된 형태가 본 발명의 다양한 실시예의 범위에 포함되는 것으로 해석되어야 한다.부호의 설명 100: 네트워크 환경 101: 전자 장치 104: 전자 장치 110: 버스 120: 프로세서 130: 메모리 131: 커널 132: 미들웨어 133: 애플리케이션 프로그래밍 인터페이스 134: 애플리케이션 140: 입출력 인터페이스 150: 디스플레이 160: 통신 인터페이스 164: 서버 200: 블록도 201: 전자 장치 210: 애플리케이션 프로세서 220: 통신 모듈 221: 셀룰러 모듈 223: Wifi 모듈 224: SIM 카드 225: BT 모듈 227: GPS 모듈 228: NFC 모듈 229: RF 모듈 230: 메모리 232: 내장 메모리 234: 외장 메모리 240: 센서 모듈 240A: 제스처 센서 240B: 자이로 센서 240C: 기압 센서 240D: 마그네틱 센서 240E: 가속도 센서 240F: 그립 센서 240G: 근접 센서 240H: RGB 센서 240I: 생체 센서 240J: 온/습도 센서 240K: 조도 센서 240M: UV 센서 250: 입력 장치 252: 터치 패널 254: 펜센서 256: 키 258: 초음파 입력 장치 260: 디스플레이 모듈 262: 패널 264: 홀로그램 장치 266: 프로젝터 270: 인터페이스 272: HDMI 274: USB 276: 광 인터페이스 278: D-SUB 280: 오디오 모듈 282: 스피커 284: 리시버 286: 이어폰 288: 마이크 291: 카메라 모듈 295: 전력 관리 모듈 296: 배터리 297: 인디케이터 298: 모터301: 제1 카메라 모듈 302: 제2 카메라 모듈 303: 깊이 센서 304: 제어부 305: 디스플레이 306: 메모리 401: 제1 카메라 모듈 402: 제2 카메라 모듈 501: 제1 카메라 모듈 502: 제2 카메라 모듈 503: 제1 카메라 모듈 504: 제2 카메라 모듈 505: 제1 이미지 센서 506: 제2 이미지 센서 507: 제3 이미지 센서 508: 제1 깊이 정보 509: 제2 깊이 정보 510: 제3 깊이 정보 601: 제1 카메라 602: 제2 카메라 603: 제3 카메라 604: 제1 피사체 605: 제2 피사체 606: 제3 피사체 701: 이미지 센서 702: 프리뷰 이미지 703: 이미지 처리 프로세서 704: 깊이 이미지 705: 깊이 이미지 706: 합성된 이미지 707: 디스플레이 708: 카메라 이미지 709: 깊이 이미지 710: 합성된 이미지 711: 메모리 801: 전자 장치 802: 제1 피사체 803: 제2 피사체 804: 배경 이미지 901: 제1 피사체 902; 배경 이미지 903: 제2 피사체 1001: 제1 피사체 1002: 제2 피사체 1003: 배경이미지도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16"}
{"patent_id": "10-2014-0069443", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 다양한 실시 예에 따른, 전자 장치 101를 포함하는 네트워크 환경 100을 도시한다. 도 2는 다양한 실시예들에 따른 전자 장치 201의 블록도 200를 도시한다. 도 3은 본 발명의 다양한 실시 예에 따른 전자 장치의 개괄적인 블록도를 도시한다. 도 4는 본 발명의 다양한 실시 예에 따른 카메라 모듈을 구성을 도시한다. 도 5는 본 발명의 다양한 실시 예에 따른 깊이 정보를 추출하는 일 실시 예를 도시한다. 도 6은 본 발명의 다양한 실시 예에 따른 피사체의 거리에 따라 깊이 정보를 추출하는 일 실시 예를 도시한다. 도 7은 본 발명의 다양한 실시 예에 따른 획득된 정보를 저장 및 표시하는 일 실시 예를 도시한다. 도 8은 본 발명의 다양한 실시 예에 따른 추출된 깊이 정보를 이용하여 이미지를 처리하는 일 실시 예를 도시한 다. 도 9는 본 발명의 다양한 실시 예에 따른 서로 다른 초점 정보를 포함하는 이미지들을 합성하는 일 실시 예를 도시한다. 도 10은 본 발명의 다양한 실시 예에 따른 이미지를 편집하는 일 실시 예를 도시한다. 도 11은 본 발명의 다양한 실시 예에 따른 전자 장치의 제1 순서도를 도시한다. 도 12는 본 발명의 다양한 실시 예에 따른 전자 장치의 제2 순서도를 도시한다. 도 13은 본 발명의 다양한 실시 예에 따른 전자 장치의 제3 순서도를 도시한다. 도 14는 본 발명의 다양한 실시 예에 따른 전자 장치의 제4 순서도를 도시한다. 도 15는 본 발명의 다양한 실시 예에 따른 전자 장치의 제5 순서도를 도시한다. 도 16은 본 발명의 다양한 실시 예에 따른 전자 장치의 방법의 흐름도를 도시한다."}
