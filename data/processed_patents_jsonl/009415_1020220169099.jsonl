{"patent_id": "10-2022-0169099", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0045043", "출원번호": "10-2022-0169099", "발명의 명칭": "인공 지능 모델을 훈련시키는 전자 장치 및 방법", "출원인": "삼성전자주식회사", "발명자": "이주영"}}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 지능(Artificial Intelligence, AI) 모델의 훈련 방법에 있어서,복수의 소스(source) 데이터 세트(110a, b, c, d)에 기초하여 병합 데이터 세트(110e)를 획득하고, 상기 병합 데이터 세트의 전체 클래스(135e)는 상기 복수의 소스 데이터 세트(110a, b, c, d)의 GT(Ground-Truth) 데이터가 존재하는 GT 클래스(130a, 130b, 130c, 130d)를 모두 포함하는, 단계; 상기 병합 데이터 세트(110e)에 포함된 제 1 데이터 샘플(120a, b, c, d)을 AI 모델에 적용하여 획득된 예측 결과(220) 및 상기 제 1 데이터 샘플의 GT 데이터(210)에 기초하여 제 1 로스(230)를 계산하는 단계;상기 제 1 로스(230) 및 상기 제 1 데이터 샘플(120a, b, c, d)에 대응되는 로스 가중치 정보(240)에 기초하여제 2 로스(250)를 계산하는 단계; 및상기 제 2 로스(250)에 기초하여 상기 AI 모델의 적어도 하나의 파라미터(parameter)를 업데이트하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 제 2 로스를 계산하는 단계는, 상기 제 1 데이터 샘플(120a, b, c, d)에 대응되는 소스 데이터 세트(110a, b, c, d)를 식별하는 단계;상기 식별된 소스 데이터 세트(110a, b, c, d)의 GT 클래스(130a, b, c, d)에 관한 정보 또는 AI 모델의 학습진행 정도(320, 330)에 관한 정보 중 적어도 하나에 기초하여 상기 식별된 소스 데이터 세트의 로스 가중치 정보(240)를 결정하는 단계; 및상기 제 1 로스(230) 및 상기 식별된 소스 데이터 세트의 로스 가중치 정보(240)에 기초하여 제 2 로스(250)를계산하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 식별된 소스 데이터 세트의 로스 가중치 정보(240)를 결정하는 단계는,상기 GT 클래스에 관한 정보에 기초하여 상기 전체 클래스(135e)가 식별된 소스 데이터 세트의 GT 클래스(130a,b, c, d)인지 여부를 식별하는 단계;상기 GT 클래스와 맵핑(mapping)되는 제 1 로스 가중치가 상기 GT 클래스가 제외된 상기 전체 클래스와 맵핑되는 제 2 로스 가중치보다 크거나 같도록 상기 제 1 로스 가중치 및 상기 제 2 로스 가중치를 결정하는 단계; 및상기 제 1 로스 가중치 및 상기 제 2 로스 가중치를 포함하는 상기 식별된 소스 데이터 세트의 로스 가중치 정보(240)를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 학습 진행 정도에 관한 정보(320, 330)는 상기 AI 모델의 정확도(330) 또는 상기 AI 모델의 학습 단계공개특허 10-2024-0045043-3-(320) 중 적어도 하나를 포함하고,상기 제 1 로스 가중치 및 상기 제 2 로스 가중치를 결정하는 단계는,상기 AI 모델의 정확도(330) 또는 상기 AI 모델의 학습 단계(320)를 판단하는 단계; 및상기 AI 모델의 정확도(330) 또는 상기 AI 모델의 학습 단계(320) 중 적어도 하나가 증가한 경우, 상기 제 2 로스 가중치가 작아지도록 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 상기 제 1 로스 가중치 및 상기 제 2 로스 가중치를 결정하는 단계는,상기 제 1 로스 가중치가 1 인 경우, 수학식 에 기초하여 상기 제 2 로스가중치를 계산하는 단계를 포함하고,상기 i는 클래스의 식별자, 상기 는 클래스 i와 맵핑되는 제 2 로스 가중치, 상기 는 클래스 i에 대응되는AI 모델의 정확도 (confidence), 상기 e는 1 이상의 정수로 표현되는 AI 모델의 학습 단계, 상기 는 제 1 설정값 (configured value), 상기 는 제 2 설정값으로 정의되는, 방법."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 AI 모델의 정확도 또는 상기 AI 모델의 학습 단계를 판단하는 단계는,클래스 i에 GT 데이터가 존재하는 복수의 제 2 데이터 샘플을 AI 모델에 적용하여 클래스 i에 관한 복수의 제 2예측 결과를 획득하는 단계; 및상기 복수의 제 2 예측 결과 및 상기 복수의 제 2 데이터 샘플의 GT 데이터에 기초하여 클래스 i와 대응되는 AI모델의 정확도를 판단하는 단계를 포함하고,상기 제 2 데이터 샘플은 상기 병합 데이터 세트에 포함되는, 방법."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 4 항 내지 제 5 항에 있어서,상기 제 1 데이터 샘플을 포함하는 복수의 데이터 샘플에 대하여 상기 AI 모델이 학습한 횟수에 기초하여 상기AI 모델의 학습 단계를 결정하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항 내지 제 7 항에 있어서,상기 제 1 로스는 상기 제 1 데이터 샘플의 예측 결과 및 상기 제 1 데이터 샘플의 GT 데이터를 로스 함수에 적용하여 계산되고,상기 로스 함수는 크로스엔트로피 로스(cross-entropy loss), 힌지 로스 (hinge loss), MAE (mean absolute공개특허 10-2024-0045043-4-error), MSE (mean squared error), KLD 로스 (Kullback-Leibler divergence loss), 후버 로스 (Huber loss)또는 RMSE (root mean squared error) 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항 내지 제 8 항에 있어서,상기 병합된 데이터 세트에 포함된 데이터 샘플에서 GT 데이터와 대응되는 GT 영역을 식별하는 단계;상기 GT 영역만을 포함하는 GT 데이터 샘플을 획득하는 단계;상기 GT 데이터 샘플에 기초하여 상기 AI 모델의 파라미터를 업데이트하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서, 상기 GT 데이터 샘플을 획득하는 단계는 GT 영역을 제외한 데이터 샘플의 영역이 제 3 설정값으로 설정된 GT 데이터 샘플을 획득하는 단계를포함하는, 방법."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항 내지 제 10 항에 있어서,상기 AI 모델은 분류(classification) 모델, 객체 검출 (object detection) 모델, 세그멘테이션(segmentation)모델, 포즈 추정(pose estimation) 모델, HOI(Human Object Interaction) 모델 또는 VRD (visual relationshipdetection) 모델 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "인공 지능(Artificial Intelligence, AI) 모델을 훈련시키는 전자 장치는,적어도 하나의 인스트럭션이 저장된 메모리; 및적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는 상기 적어도 하나의 인스트럭션을 실행하여,제 1 소스 데이터 세트(110a) 및 제 2 소스 데이터 세트(110b)가 포함된 복수의 소스(source) 데이터 세트(110a, b, c, d)에 기초하여 병합 데이터 세트(110e)를 획득하고, 상기 병합 데이터 세트(110e)에 포함된 제 1 데이터 샘플(120a, b, c, d)을 AI 모델에 적용하여 획득된 예측 결과(220) 및 상기 제 1 데이터 샘플의 GT(ground-truth) 데이터(210)에 기초하여 제 1 로스(230)를 계산하고,상기 제 1 로스(230) 및 상기 제 1 데이터 샘플(120a, b, c, d)에 대응되는 로스 가중치 정보(240)에 기초하여제 2 로스(250)를 계산하고,상기 제 2 로스(250)에 기초하여 상기 AI 모델의 적어도 하나의 파라미터(parameter)를 업데이트하고,상기 병합 데이터 세트의 전체 클래스(135e)는 상기 복수의 소스 데이터 세트(110a, b, c, d)의 GT(Ground-Truth) 데이터가 존재하는 GT 클래스(130a, 130b, 130c, 130d)를 모두 포함하는, 전자 장치."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,공개특허 10-2024-0045043-5-상기 적어도 하나의 프로세서는,상기 제 1 데이터 샘플(120a, b, c, d)에 대응되는 소스 데이터 세트(110a, b, c, d)를 식별하고,상기 식별된 소스 데이터 세트(110a, b, c, d)의 GT 클래스(130a, b, c, d)에 관한 정보 또는 AI 모델의 학습진행 정도(320, 330)에 관한 정보 중 적어도 하나에 기초하여 상기 식별된 소스 데이터 세트의 로스 가중치 정보를 결정하고,상기 제 1 로스(230) 및 상기 식별된 소스 데이터 세트의 로스 가중치 정보(240)에 기초하여 제 2 로스(250)를계산하는, 전자 장치."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 적어도 하나의 프로세서는,상기 GT 클래스에 관한 정보에 기초하여 전체 클래스(135e)가 식별된 소스 데이터 세트의 GT 클래스(130a, b,c, d)인지 여부를 식별하고,상기 GT 클래스(130a)와 맵핑(mapping)되는 제 1 로스 가중치가 상기 GT 클래스(130a)를 제외한 전체 클래스(135e)와 맵핑되는 제 2 로스 가중치보다 크거나 같도록 상기 제 1 로스 가중치 및 상기 제 2 로스 가중치를 결정하고상기 제 1 로스 가중치 및 상기 제 2 로스 가중치를 포함하는 상기 식별된 소스 데이터 세트의 로스 가중치 정보(240)를 결정하는, 전자 장치."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서,상기 학습 진행 정도에 관한 정보(320, 330)는 상기 AI 모델의 정확도(330) 또는 상기 AI 모델의 학습 단계(320) 중 적어도 하나를 포함하고,상기 적어도 하나의 프로세서는,상기 AI 모델의 정확도(330) 또는 상기 AI 모델의 학습 단계(320)를 판단하고,상기 AI 모델의 정확도(330) 또는 상기 AI 모델의 학습 단계(320) 중 적어도 하나가 증가한 경우, 상기 제 2 로스 가중치가 작아지도록 결정하는, 전자 장치."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서, 상기 적어도 하나의 프로세서는,상기 제 1 로스 가중치가 1 인 경우, 수학식 에 기초하여 상기 제 2 로스가중치를 계산하고,상기 i는 클래스의 식별자, 상기 는 클래스 i와 맵핑되는 제 2 로스 가중치, 상기 는 클래스 i에 대응되는AI 모델의 정확도 (confidence), 상기 e는 1 이상의 정수로 표현되는 AI 모델의 학습 단계, 상기 는 제 1 설공개특허 10-2024-0045043-6-정값 (configured value), 상기 는 제 2 설정값으로 정의되는, 전자 장치."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16 항에 있어서,상기 적어도 하나의 프로세서는,클래스 i에 GT 데이터가 존재하는 복수의 제 2 데이터 샘플을 AI 모델에 적용하여 클래스 i에 관한 복수의 제 2예측 결과를 획득하고,상기 복수의 제 2 예측 결과 및 상기 복수의 제 2 데이터 샘플의 GT 데이터에 기초하여 클래스 i와 대응되는 AI모델의 정확도를 판단하고,상기 복수의 제 2 데이터 샘플은 상기 병합 데이터 세트에 포함되는, 전자 장치."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 12 항 내지 제 17 항에 있어서,상기 적어도 하나의 프로세서는, 상기 병합된 데이터 세트에 포함된 데이터 샘플에서 GT 데이터와 대응되는 GT 영역을 식별하고,상기 GT 영역만을 포함하는 GT 데이터 샘플을 획득하고,상기 GT 데이터 샘플에 기초하여 상기 AI 모델의 파라미터를 업데이트하는, 전자 장치."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18항에 있어서,상기 프로세서는 GT 영역을 제외한 데이터 샘플의 영역이 제 3 설정값으로 설정된 GT 데이터 샘플을 획득하는,전자 장치."}
{"patent_id": "10-2022-0169099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 1 항 내지 제 11 항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2022-0169099", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "복수의 소스(source) 데이터 세트에 기초하여 병합 데이터 세트를 획득하고, 상기 병합 데이터 세트의 전체 클래 스는 상기 복수의 소스 데이터 세트의 GT(Ground-Truth) 데이터가 존재하는 GT 클래스를 모두 포함하는, 단계; 상기 병합 데이터 세트에 포함된 제 1 데이터 샘플을 AI 모델에 적용하여 획득된 예측 결과 및 상기 제 1 데이터 샘플의 GT 데이터에 기초하여 제 1 로스를 계산하는 단계; 상기 제 1 로스 및 상기 제 1 데이터 샘플에 대응되는 로스 가중치 정보에 기초하여 제 2 로스를 계산하는 단계; 및 상기 제 2 로스에 기초하여 상기 AI 모델의 적어도 하나의 파라미터(parameter)를 업데이트하는 단계를 포함하는, 방법이 제공된다."}
{"patent_id": "10-2022-0169099", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "복수의 데이터 세트에 기초하여 인공 지능 모델을 훈련시키는 전자 장치 및 방법이 제공된다."}
{"patent_id": "10-2022-0169099", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "복수의 데이터 세트에 기초하여 인공지능 모델을 훈련시키는 방법으로 각 데이터 세트마다 태스크를 두어 멀티- 태스크 형식으로 인공지능 모델을 훈련시킬 수 있다. 각 데이터 세트 별로 결과를 추론하는 부분에 해당하는 헤 드(head)가 추가되는 경우, 모델의 연산량이 증가하거나, 각 데이터 세트의 헤드에 대하여 각 데이터 세트가 출 연하는 빈도가 고르도록 조절이 필요하거나 각 데이터 세트의 클래스가 충분히 많은 개수의 클래스를 포함하고 있을 것이 요구될 수 있다. 본 개시의 다양한 실시예는, 복수의 데이터 세트에 기초하여 인공 지능 모델을 훈련시키는 방법에 있어서 각 데 이터 세트별로 헤드를 포함하지 않는 경우에도 로스(loss)를 개선하여 학습 효율을 증대시키는 방법을 제안하고 자 한다."}
{"patent_id": "10-2022-0169099", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 문서에서 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0169099", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 제 1 측면은 인공 지능(Artificial Intelligence, AI) 모델의 훈련 방법에 있어서, 복수의 소스 (source) 데이터 세트에 기초하여 병합 데이터 세트를 획득하고, 상기 병합 데이터 세트의 전체 클래스는 상기 복수의 소스 데이터 세트의 GT(Ground-Truth) 데이터가 존재하는 GT 클래스를 모두 포함하는, 단계; 상기 병합 데이터 세트에 포함된 제 1 데이터 샘플을 AI 모델에 적용하여 획득된 예측 결과 및 상기 제 1 데이터 샘플의 GT 데이터에 기초하여 제 1 로스를 계산하는 단계; 상기 제 1 로스 및 상기 제 1 데이터 샘플에 대응되는 로스 가중치 정보에 기초하여 제 2 로스를 계산하는 단계; 및 상기 제 2 로스에 기초하여 상기 AI 모델의 적어 도 하나의 파라미터(parameter)를 업데이트하는 단계를 포함하는, 방법을 제공할 수 있다. 또한, 본 개시의 제2 측면은, 인공 지능(Artificial Intelligence, AI) 모델을 훈련시키는 전자 장치에 있어서, 적어도 하나의 인스트럭션이 저장된 메모리 적어도 하나의 메모리; 및 적어도 하나의 프로세서를 포함하며, 상 기 프로세서는, 복수의 소스(source) 데이터 세트에 기초하여 병합 데이터 세트를 획득하되, 상기 병합 데이터 세트의 전체 클래스는 상기 복수의 소스 데이터 세트의 GT(Ground-Truth) 데이터가 존재하는 GT 클래스를 모두 포함하고, 상기 병합 데이터 세트에 포함된 제 1 데이터 샘플을 AI 모델에 적용하여 획득된 예측 결과 및 상기 제 1 데이터 샘플의 GT 데이터에 기초하여 제 1 로스를 계산하고, 상기 제 1 로스 및 상기 제 1 데이터 샘플에 대응되는 로스 가중치 정보에 기초하여 제 2 로스를 계산하고, 상기 제 2 로스에 기초하여 상기 AI 모델의 적어도 하나의 파라미터(parameter)를 업데이트하는, 전자 장치를 제공할 수 있다.. 또한, 본 개시의 제3 측면은, 제1 측면의 방법을 수행하도록 하는 프로그램이 저장된 기록매체를 제공할 수 있 다."}
{"patent_id": "10-2022-0169099", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에서, \"a, b 또는 c 중 적어도 하나\" 표현은 \" a\", \" b\", \" c\", \"a 및 b\", \"a 및 c\", \"b 및 c\", \"a, b 및 c 모두\", 혹은 그 변형들을 지칭할 수 있다.본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의 미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 또한, 본 명세서에서 사용되는 '제1' 또는 '제2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만 사용된다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소 프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시에 따른 인공지능(Artificial Intelligence, AI)과 관련된 기능은 프로세서와 메모리를 통해 동작될 수 있다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래 픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리 에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어할 수 있다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델 의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어질 수 있다. 여기서, 학습을 통해 만들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 이러 한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/또는 시스 템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습 (unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learnin g)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행할 수 있다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결 과에 의해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스 트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신 내지 업데이트될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q- Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 데이터 세트는 복수의 데이터 샘플을 포함하는 데이터의 집합일 수 있다. 데이터 샘플은 데이터 세트를 구성하 는 개별 데이터(datum)을 의미한다. 데이터 샘플은 통계 자료, 텍스트, 오디오, 이미지, 비디오 등을 포함하거 나 또는 이들에 대응될 수 있다. 데이터 샘플은 로우 데이터를 포함할 수 있다. 데이터 샘플은 로우 데이터를 전처리하여 획득한, 데이터의 특성을 나타내는 정보를 포함할 수 있다. 데이터 세트는 전자 장치 내의 메모리 또는 스토리지에 저장되어 있을 수 있다. 또는, 데이터 세트는 전자 장치 외부의 저장 장치에 저장되어 있을 수 있다. 레이블(label)은 일반적으로 데이터 샘플과 관련된 유의미한 정보일 수 있다. 레이블은 데이터 샘플의 속성을 나타내거나 정의하는 것일 수 있다. 일 실시예에서, 레이블은 데이터 샘플에 포함된 정보 또는 데이터 샘플과 연관된 정보일 수 있다. 레이블은 클래스 레이블(class label) 내지 클래스를 포함할 수 있고, 클래스는 데이터 샘플 내지 데이터 샘플 에 포함된 객체를 분류하거나 평가하는 기준이 될 수 있다. 레이블은 데이터 샘플을 기초로 추론 또는 예측을 수행한 결과를 포함할 수 있다. 그러나 상기의 실시예에 한정되지 않고, 데이터 샘플과 관련되는 어떤 유의미한 정보도 레이블로서 할당될 수 있다. 한편, 레이블을 할당하는 행위를 레이블링(labeling)으로 표현할 수 있다. GT(ground-truth) 데이터는 데이터 샘플의 실측 자료, 실측 데이터, 관측 데이터, 정답 데이터, 정답 정보, 관 찰 정보, 관측 정보, 실측 정보 또는 레이블링(labeling)된 결과 등 다양하게 표현될 수 있다. GT 데이터는 데 이터 샘플에 포함되는 정보이거나, 데이터 샘플과 대응되는 정보거나, 데이터 샘플과 연관되는 정보거나, 데이 터 샘플과 맵핑(mapping)되는 정보일 수 있다. GT 데이터는 하나 이상의 레이블(label)과 연관, 대응 또는 맵핑 될 수 있다. 일 실시예에서, GT 데이터와 대응되는 클래스 또는 GT 데이터와 맵핑되는 클래스를 GT 클래스로 표 현할 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1a 및 도 1b는 일 실시예에 따른 소스 데이터 세트 및 병합 데이터 세트를 설명하기 위한 도면이다. 데이터 세트는 복수의 데이터 샘플을 포함할 수 있고 예를 들어, 도 1a를 참조하면, 소스 데이터 세트(110a)는 데이터 샘플(120a)을 포함하는 복수의 데이터 샘플을 포함할 수 있다. 데이터 샘플은 통계 자료, 텍스트, 오디 오, 이미지, 비디오 등을 포함하거나 또는 이들에 대응될 수 있다. 예를 들어, 도 1a 및 1b를 참조하면, 데이터 샘플(120a, b, c, d)는 이미지와 대응될 수 있다. 소스 데이터 세트는 병합 데이터 세트 획득의 기초가 된 데이터 세트로 이해될 수 있다. 예를 들어, 도 1a 및 1b를 참조하면, 병합 데이터 세트(110e)는 4개의 소스 데이터 세트(110a, b, c, d)에 기초하여 획득될 수 있다. 소스 데이터 세트는 소정의 클래스에 GT(Ground-Truth) 데이터가 대응되는 복수의 데이터 샘플을 포함할 수 있 다. 소스 데이터 세트(110a)에 포함된 데이터 샘플의 경우, GT 데이터에 대응되는 GT클래스(130a)는 {고양이, 개}에 해당할 수 있다. GT 클래스는 GT 데이터에 대응되는 클래스, GT 데이터에 맵핑되는 클래스 또는 GT 데이 터가 존재하는 클래스 등으로 표현될 수 있다. 소스 데이터 세트(110b)는 데이터 샘플(120b)을 포함하는 복수의 데이터 샘플을 포함할 수 있고, 사람 클래스, 개 클래스, 보울(bowl) 클래스, TV 클래스, 모자(hat) 클래스, 냄비 클래스, 컵 클래스, 프라이팬 클래스, 냉장 고 클래스, 테이블 클래스 등에 GT 데이터가 대응될 수 있다. 소스 데이터 세트(110b)의 GT 클래스(130b)는 {사 람, 개, ... , TV, ... , 테이블}와 같이 표현될 수 있다. 소스 데이터 세트(110c)는 데이터 샘플(120c)을 포함하는 복수의 데이터 샘플을 포함할 수 있고, 사람 클래스, 소파 클래스, 식물(plant) 클래스, 문(door) 클래스, 테이블 클래스 등에 GT 데이터가 대응될 수 있다. 소스 데 이터 세트(110c)의 GT 클래스(130c)는 {사람, 소파, ... , 식물, ... ,문, ..., 테이블}와 같이 표현될 수 있 다. 소스 데이터 세트(110d)는 데이터 샘플(120d)를 포함하는 복수의 데이터 샘플을 포함할 수 있고, 사람 클래스에 GT 데이터가 대응될 수 있다. 예를 들어, 소스 데이터 세트(110d)의 GT 클래스(130d)는 {사람}과 같이 표현될 수 있다. 병합 데이터 세트는 각 소스 데이터 세트에 포함된 적어도 하나의 데이터 샘플을 포함할 수 있다. 예를 들어, 도 1a 및 1b를 참조하면, 병합 데이터 세트(110e)는 데이터 샘플(120a, b, c, d)를 포함할 수 있다. 병합 데이터 세트의 클래스는 소스 데이터 세트의 GT 클래스를 포함할 수 있다. 예를 들어, 도 1a 및 1b를 참조 하면, 병합 데이터 세트의 전체 클래스(135e)는 복수의 소스 데이터 세트(110a, b, c, d)의 GT 클래스(130a, b, c, d)를 모두 포함할 수 있고, {사람, 고양이, 개, ... , 소파, ..., TV, 식물, 문, ..., 테이블}와 같이 표현 될 수 있다. 다른 예를 들어, 전자 장치가 2개의 소스 데이터 세트(110a 및 110d)에 기초하여 병합 데이터 세트 를 획득한 경우, 병합 데이터 세트의 전체 클래스는 {사람, 고양이, 개}이다. 병합 데이터 세트의 전체 클래스는 GT 클래스와 GT 클래스가 제외된 전체 클래스로 구성될 수 있다. 예를 들어, 도 1a 및 도 1b를 참조하면, 4의 소스 데이터 세트(110a, b, c, d)에 기초하여 획득된 병합 데이터 세트의 전체 클래스(135e)는 GT 클래스(130a, b, c, d)와 GT 클래스가 제외된 전체 클래스(135a, b, c, d)로 구성될 수 있 다. 소스 데이터 세트(110a)의 GT 클래스가 제외된 전체 클래스(135a)는 {개, 고양이}가 제외된 {사람, ..., 소파, ... TV, 식물, ... , 문, ... 테이블}과 같이 표현될 수 있다. 소스 데이터 세트(110b)의 GT 클래스가 제외된 전체 클래스(135b)는 {고양이, 소파, ... , 식물, ... , 문, ...}과 같이 표현될 수 있다. 소스 데이터 세트 (110c)의 GT 클래스가 제외된 전체 클래스(135c)는 {고양이, 개, ... , TV, ...}과 같이 표현될 수 있다. 소스 데이터 세트(110d)의 GT 클래스가 제외된 전체 클래스(135d)는 {고양이, 개, ..., 소파, ... TV, 식물, ... , 문, ... 테이블}과 같이 표현될 수 있다. 설명의 편의를 위하여 클래스를 집합의 형태로 표현하였으나 클래스는 배열, 벡터 또는 행렬로 표현될 수 있고, 언급된 표현 방식에 한정되지 않는다. 한편, 클래스와 대응되는 예측 결과, 클래스와 대응되는 GT 데이터, 또는 로스 가중치 정보 역시 언급된 표현 방식을 포함하여 다양한 방법으로 표현될 수 있다. 도 2는 일 실시예에 따른 제 1 로스 및 제 2 로스를 판단하는 방법을 설명하기 위한 도면이다. 전자 장치는 제 1 로스 및 제 1 데이터 샘플과 대응되는 로스 가중치 정보에 기초하여 제 2 로스를 계산할 수 있다. 전자 장치는 병합 데이터 세트에 포함된 제 1 데이터 샘플을 AI 모델에 적용하여 획득된 예측 결과 및 제 1 데이터 샘플의 GT 데이터에 기초하여 제 1 로스를 계산할 수 있다. 예측 결과는 병합 데이터 세트의 전체 클래스와 대응되는 예측 결과를 포함할 수 있다. 예를 들어, 도 2를 참조 하면, 전자 장치는 제 1 데이터 샘플(120a)를 AI 모델에 입력하여 출력으로 예측 결과을 획득할 수 있다. 예측 결과는 사람 클래스와 대응되는 값 0.7, 고양이 클래스와 대응되는 값 0.5, 개 클래스와 대응되는 값 0.8 등을 포함할 수 있다. 제 1 데이터 샘플의 GT 데이터는 병합 데이터 세트의 전체 클래스와 대응되는 GT 데이터를 포함할 수 있다. 제 1 데이터 샘플의 GT 데이터는 GT 클래스와 대응되는 GT 데이터 및 GT 클래스가 제외된 전체 클래스와 대응되는 GT 데이터를 포함할 수 있다. 일 실시예에서, 제 1 데이터 샘플의 GT 데이터는 GT 클래스가 제외된 전체 클래스 에 대응되는 값으로 0과 같이 디폴트 값이 설정될 수 있다. 예를 들어, 도 2를 참조하면, 제 1 데이터 샘플(120a)의 GT 데이터는 GT 클래스(130a)와 관련하여 고양이 클래스와 대응되는 값 0, 개 클래스와 대응되는 값 1을 포함할 수 있다. 제 1 데이터 샘플(120a)의 GT 데이터 는 GT 클래스가 제외된 전체 클래스(135a) 와 관련하여 디폴트 값 0을 포함할 수 있다. 한편, 데이터 샘플(120a)의 GT 데이터는 고양이가 없음을 지시할 수 있고, 개에 해당하는 객체가 포함됨을 지시할 수 있다. 데이터 샘플(120a)의 GT 데이터는 개에 해당하는 바운딩 박스 또는 픽셀 등으로 객체의 위치를 지시할 수 있다. 일 실시예에서, 전자 장치는 예측 결과 및 GT 데이터의 차이에 기초하여 제 1 로스를 계산할 수 있다. 클래스 i 와 대응되는 로스값은 클래스 i와 대응되는 예측 결과 및 클래스 i와 대응되는 GT 데이터의 차이에 기초하여 계 산될 수 있다. 예를 들어, 도 2를 참조하면, 제 1 로스는 사람 클래스와 대응되는 예측 결과 0.7 및 사람 클래스와 대응 되는 GT 데이터 0의 차이에 해당하는 로스값 0.7을 포함할 수 있다. 제 1 로스는 고양이 클래스에 대응되 는 로스값 0.5, 개 클래스에 대응되는 로스값 0.2를 포함할 수 있다. 일 실시예에서, 전자 장치는 상기 제 1 데이터 샘플의 예측 결과 및 상기 제 1 데이터 샘플의 GT 데이터를 로스 함수(loss function)에 적용하여 제 1 로스를 계산할 수 있다. 로스 함수는 크로스엔트로피 로스(cross-entropy loss), 힌지 로스 (hinge loss), MAE (mean absolute error), MSE (mean squared error), KLD 로스 (Kullback-Leibler divergence loss), 후버 로스 (Huber loss) 또는 RMSE (root mean squared error) 중 적어도 하나를 포함할 수 있고, 언급된 로스 함수에 한하지 않고 다양한 로 스 함수 내지 코스트 함수(cost function)에 적용될 수 있다. 전자 장치는 제 1 데이터 샘플의 GT 클래스가 제외된 병합 데이터의 전체 클래스에 대하여, 제 2 로스가 제 1 로스보다 작거나 같도록 결정할 수 있다. AI 모델이 GT 데이터가 없는 클래스에 대하여 불확실한 예측 결과를출력하는 경우, AI 모델이 제 1 로스보다 작거나 같은 제 2 로스에 기초하여 업데이트될 수 있다. 전자 장치는 제 1 로스 및 제 1 데이터 샘플에 대응되는 로스 가중치 정보에 기초하여 제 2 로스를 계산할 수 있다. 로스 가중치 정보는 병합 데이터 세트의 클래스와 맵핑되는 로스 가중치를 포함할 수 있다. 로스 가중치 정보는 GT 클래스와 맵핑되는 제 1 로스 가중치 및 GT 클래스가 제외된 전체 클래스와 맵핑되는 제 2 로스 가중치를 포함할 수 있다. 일 실시예에서, 제 1 로스 가중치가 1 인 경우, 제 2 로스 가중치는 0이상 1 이하의 값으로 결정될 수 있다. 전자 장치는 제 2 로스가 제 1 로스보다 작거나 같도록 결정할 수 있다. 예를 들어, 도 2를 참조하면, 제 1 데이터 샘플(120a)에 대응되는 로스 가중치 정보는 제 1 데이터 샘플의 GT 클래스(130a)와 맵핑되는 제 1 로스 가중치는 1, GT 클래스가 제외된 전체 클래스(135a)와 맵핑되는 로스 가 중치는 0.2로 결정될 수 있다. 전자 장치는 로스 가중치 정보 및 제 1 로스에 기초하여 제 2 로스를 결정할 수 있다. 예를 들어, 도 2를 참조 하면, 전자 장치는 제 2 로스은 사람 클래스에 대응되는 제 1 로스의 로스값 0.7 및 사람 클래스에 대응되 는 로스 가중치 0.2의 곱에 기초하여 사람 클래스와 관련하여 0.14로 계산될 수 있다. 설명의 편의를 위해 곱으 로 표현하였으나, 통상의 지식을 가진 자는 여러 가지 상이한 형태로 로스 가중치 및 제 1 로스에 기초하여 제 2 로스를 계산할 수 있다. 전자 장치는 제 1 데이터 샘플을 AI 모델에 적용하여 획득한 예측 결과, 제 1 데이터 샘플의 GT 데이터 및 제 1 데이터 샘플의 로스 가중치 정보에 기초하여 제 2 로스를 계산할 수 있다. 일 실시예에서, 전자 장치는 병합 데이터 세트에 포함된 제 1 데이터 샘플을 AI 모델에 적용하여 획득된 예측 결과, 제 1 데이터 샘플의 GT 데이터 및 로스 가중치 정보를 로스 함수에 적용하여 제 2 로스를 계산할 수 있다. 로스 함수는 크로스엔트로피 로스(cross-entropy loss), 힌지 로스 (hinge loss), MAE (mean absolute error), MSE (mean squared error), KLD 로스 (Kullback-Leibler divergence loss), 후버 로스 (Huber loss) 또는 RMSE (root mean squared error) 중 적어도 하나를 포함할 수 있고, 언급된 로스 함수에 한하지 않고 다양한 로 스 함수 내지 코스트 함수(cost function)에 적용될 수 있다. 설명의 편의를 위해 제 1 로스 및 제 2 로스를 클래스 별로 나타내었으나, 제 1 로스 및 제 2 로스는 전체 클래 스에 대한 로스들의 평균이나 합 등으로 구해져서 하나의 값으로 나타날 수 있다. 예를 들어, 로스 함수가 MSE인 경우, 제 1 로스는 수학식 에 기초하여 계산될 수 있고 수 학식 제 2 로스는 다음의 수학식 에 기초하여 결정될 수 있다. 예를 들어, 로스 함수가 RMSE인 경우, 제 1 로스는 수학식 에 기초하여 계산될 수 있고 제 2 로스는 다음의 수학식 에 기초하여 결정될 수 있다. 예를 들어, 로스 함수가 MAE인 경우, 제 1 로스는 수학식 에 기초하여 계산될 수 있고 제 2 로스는 다음의 수학식 에 기초하여 결정될 수 있다. 예를 들어, 로스 함수가 크로스 엔트로피 로스인 경우, 제 1 로스는 수학식 에 기초하여 계산될 수 있고 제 2 로스는 다음의 수학식 에 기초하여 결정될 수 있다. 한편, i는 클래스의 식별자, 는 클래스 i와 맵핑되는 로스 가중치, 는 클래스 i와 대응되는 예측 결과, 는 클래스 i와 대응되는 GT 데이터, n은 클래스의 개수로 정의될 수 있다. 제 1 데이터 샘플(120a)에 사람과 관련된 객체가 있으나 사람 클래스에 대응되는 GT 데이터가 없거나 디폴트 값 으로 설정된 경우, AI 모델이 사람 클래스에 대하여 사람과 관련된 객체가 포함됨을 지시하는 예측 결과를 출력 할 수 있다. 제 1 로스에 기초하여 AI 모델이 업데이트되는 경우, 사람과 관련하여 AI 모델이 잘못 예측했다는 피드백을 주는 결과가 될 수 있다. 본 개시의 다양한 실시예는 제 1 로스보다 작은 제 2 로스에 기초하여 AI 모델을 업데이트하는 방법을 제공함으 로써 예측 결과가 실제 정답에 가까운 경우에도 큰 로스에 기초하여 업데이트되는 것을 방지할 수 있다. 본 개 시의 일 실시예에 따르면, 클래스와 대응되는 GT 데이터가 충분하지 않은 데이터 세트에 기초하여 AI 모델을 효 율적으로 훈련시킬 수 있다. 도 3은 일 실시예에 따른 학습 진행 정도에 관한 정보에 기초하여 로스 가중치를 결정하는 방법을 설명하기 위 한 도면이다. 일 실시예에서, 전자 장치는 학습 진행 정도에 관한 정보에 기초하여 로스 가중치를 결정할 수 있다. 일 실시예 에서, 학습 진행 정도에 관한 정보는 AI 모델의 정확도를 포함하는 AI 모델의 성능 지표 또는 AI 모델의 학습 단계 중 적어도 하나를 포함할 수 있다. AI 모델의 정확도 또는 AI 모델의 학습 단계 중 적어도 하나가 증가한 경우, 전자 장치는 GT 클래스가 제외된 전체 클래스와 맵핑되는 제 2 로스 가중치가 작아 지도록 결정할 수 있다. 전자 장치는 AI 모델의 정확도 또는 AI 모델의 학습 단계를 판단할 수 있다. AI 모델의 학습 단계 는 소정의 데이터 세트를 학습한 횟수 에포크(epoch) 혹은 스텝(step) 등에 기초하여 판단될 수 있다. 에 포크는 소정의 데이터 세트가 신경망을 통과한 횟수이고, 1 에포크는 소정의 데이터 샘플이 순전파와 역전파를 통해 신경망을 한번 통과한 경우로 이해될 수 있다. 예를 들어, AI 모델에 제 1 데이터 샘플이 적용되기 전을 학습 단계 1이라고 할 때, 제 1 데이터 샘플을 포함하 는 복수의 훈련용 데이터 샘플이 1회 AI 모델을 통과하거나 1 에포크인 경우, 학습 단계는 2로 증가할 수 있다. 다른 예를 들어, 학습 단계는 AI 모델을 업데이트한 횟수에 기초하여 결정될 수 있다. 도 3을 참조하면, 전자 장치는 학습 단계가 증가할수록 제 2 로스 가중치가 1에서 점차 0에 가까워지도록 결정할 수 있다. 학습 초기에는 AI 모델의 정확도가 떨어질 수 있으므로 GT 클래스와 맵핑되지 않는 제 2 로스 가중치를 1 또는 1에 가깝게 결정하여 AI 모델의 파라미터를 업데이트할 수 있다. 전자 장치는 AI 모델을 이용 하여 학습이 진행됨에 따라 GT 데이터가 없더라도 입력 데이터에 존재하는 객체를 검출할 수 있으므로 전자 장 치는 제 2 로스 가중치가 1에서 점차 0에 가까워지도록 결정할 수 있다. AI 모델의 정확도는 AI 모델의 성능을 평가하는 지표 중 하나가 될 수 있고, 클래스와 대응되는 AI 모델의 정확 도를 포함할 수 있다. 일 실시예에서, AI 모델의 정확도는 밸리데이션 세트(validation set) 또는 테스트 세트 (test set)의 제 2 데이터 샘플에 기초하여 획득될 수 있다. 일 실시예에서, 전자 장치는 클래스 i에 GT 데이터가 대응되는 복수의 제 2 데이터 샘플을 AI 모델에 적용하여 클래스 i에 대응되는 복수의 제 2 예측 결과를 획득할 수 있다. 전자 장치는 복수의 제 2 예측 결과 및 복수의 제 2 데이터 샘플의 GT 데이터에 기초하여 클래스 i와 대응되는 AI 모델의 정확도를 판단할 수 있다. 예를 들어, 전자 장치는 클래스 i와 대응되는 제 2 예측 결과 및 클래스 i에 대응되는 제 2 데이터 샘플의 GT 데이터를 비교하여 정확도를 계산할 수 있다. 복수의 제 2 데이터 샘플에 대하여 계산된 정확도의 평균을 클래 스 i와 대응되는 AI 모델의 정확도로 판단할 수 있다. 클래스 i와 대응되는 AI 모델의 정확도가 1에 가까울수록 GT 데이터와 모델의 예측 결과가 동일하고, AI 모델의 정확도가 0에 가까울수록 GT 데이터와 모델의 예측 결과가 차이가 있을 수 있다. 도 3을 참조하면, 전자 장치는 AI 모델의 정확도가 0.1, 0.3, 0.5, 1로 점차 증가할수록, 제 2 로스 가중 치가 점차 0에 가까워지도록 결정할 수 있다. 일 실시예에서, 제 1 로스 가중치가 1인 경우, 전자 장치는 수학식 에 기 초하여 제 2 로스 가중치를 계산할 수 있다. i는 클래스의 식별자, 상기 는 클래스 i와 맵핑되는 제 2 로스 가중치, 상기 는 클래스 i와 대응되는 AI 모 델의 정확도 (confidence), 상기 e는 1 이상의 정수로 표현되는 AI 모델의 학습 단계, 상기 는 제 1 설정값 (configured value), 상기 는 제 2 설정값으로 정의될 수 있다. 제 1 설정값 및 제 2 설정값은 서버 등의 다 른 전자 장치로부터 수신될 수 있다. 일 실시예에서, 전자 장치는 전자 장치는 수학식 또는 에 기초하여 제 2 로스 가중치를 계산할 수 있다. i는 클래스의 식별자, 상기 는 클래스 i와 맵핑되는 제 2 로스 가중치, 상기 는 클래스 i와 대응되는 AI 모 델의 정확도 (confidence), 상기 e는 1 이상의 정수로 표현되는 AI 모델의 학습 단계, 상기 는 제 1 설정값 (configured value), 상기 는 제 2 설정값으로 정의될 수 있다. 제 1 설정값 및 제 2 설정값은 서버 등의 다 른 전자 장치로부터 수신될 수 있고, 초기 설정에 따라 전자 장치에 의해 결정될 수 있다. 도 4a 및 도 4b는 일 실시예에 따른 GT 가공 데이터 샘플을 획득하는 방법을 설명하기 위한 도면이다. GT 가공 데이터 샘플은 데이터 샘플을 가공하여 GT 데이터에 대응되는 영역 외의 영역이 지워진 데이터 샘플을 포함할 수 있고, GT 데이터 샘플, 가공 데이터 샘플 등으로 표현될 수 있다. 전자 장치는 병합된 데이터 세트에 포함된 데이터 샘플에 기초하여 GT 데이터와 대응되는 GT 영역을 포함하는 GT 데이터 샘플을 획득할 수 있고, 병합 데이터 세트는 GT 데이터 샘플을 더 포함할 수 있다. 전자 장치는 병합 데이터 세트의 GT 영역 정보에 기초하여 GT 영역을 포함하는 GT 데이터 샘플을 획득할 수 있 다. GT 영역 정보는 GT 바운딩 박스 정보, GT 픽셀 정보 등을 포함할 수 있다. 일 실시예에서 전자 장치는 GT 영역 이외의 영역은 소정의 값으로 설정하여 GT 데이터 샘플을 획득할 수 있다. 전자 장치는 GT 영역을 제외한 데이터 샘플의 영역을 소정의 값으로 설정함으로써 GT 영역을 제외한 데이터 샘 플의 영역이 지워진 GT 데이터 샘플을 획득할 수 있다. GT 데이터 샘플은 GT 데이터와 대응되는 바운딩 박스 (bounding box)를 제외한 영역의 데이터가 지워지거나 소정의 값으로 설정된 데이터 샘플일 수 있다. GT 데이터 샘플은 GT 데이터와 대응되는 픽셀들을 제외한 픽셀들의 데이터가 지워지거나 소정의 값으로 설정된 데이터 샘 플일 수 있다. 예를 들어, 전자 장치는 데이터 샘플(120a)에 기초하여 개를 지시하는 바운딩 박스를 제외하고 지워진 GT 데이 터 샘플(420a)를 획득할 수 있다. 전자 장치는 데이터 샘플(120a)에 기초하여 소파를 지시(indication)하는 바 운딩 박스, 문을 지시하는 바운딩 박스, 및 와이어를 지시하는 바운딩 박스를 제외하고 지워진 GT 데이터 샘플 (420c)를 획득할 수 있다. 일 실시예에서, GT 데이터 샘플은 적어도 하나의 GT 영역이 추가로 지워지거나 소정의 값으로 설정될 수 있다. 예를 들어, 전자 장치는 데이터 샘플(120c)에 기초하여 문을 지시하는 바운딩 박스를 제외하고 지워진 GT 데이터 샘플(미도시)를 획득할 수 있다. GT데이터 샘플(420c)에서, GT 데이터와 대응되는 소파를 지시하는 바운딩 박스 및 와이어를 지시하는 바운딩 박스도 지워질 수 있다. 예를 들어, 전자 장치는 데이터 샘플(120b)에 기초하여 좌측 사람 및 우측 사람을 지시하는 바운딩 박스를 제외 하고 지워진 GT 데이터 샘플을 획득할 수 있다. 전자 장치는 데이터 샘플(120b)에 기초하여 좌측 사람을 지시하 는 바운딩 박스를 제외하고 지워진 GT 데이터 샘플 또는 우측 사람을 지시하는 바운딩 박스를 제외하고 지워진 GT 데이터 샘플을 획득할 수 있다. 전자 장치는 패딩(padding) 정보에 기초하여 GT 데이터 샘플을 획득할 수 있다. 예를 들어, 도 4b를 참조하면, GT 데이터 샘플(420a)보다 패딩의 크기가 큰 GT 데이터 샘플(425a)를 획득할 수 있다. 패딩의 크기는 바운딩 박 스의 1/10과 같이 소정의 값으로 고정될 수도 있고, AI를 훈련시키는 학습 단계마다 설정될 수 있다. 일 실시예 에서, 상기 전자 장치는 서버 등 다른 전자 장치로부터 패딩 정보를 수신할 수 있다. 전자 장치는 가우시안 필터(Gaussian filter)를 이용하여 GT 데이터 샘플을 획득할 수 있다. 예를 들어, 도 4b 를 참조하면, 전자 장치는 바운딩 박스의 중심에서 가우시안 필터(430a)를 이용하여 GT 데이터 샘플(435a)를 획 득할 수 있다. 전자 장치는 GT 데이터 샘플에 기초하여 상기 AI 모델의 파라미터를 업데이트할 수 있다. 예를 들어, 전자 장치 는 GT 데이터 샘플 및 기존 병합 데이터 세트에 포함된 데이터 샘플에 기초하여 AI 모델을 훈련시키고 AI 모델 의 성능을 평가할 수 있다. 또는 GT 데이터 샘플에 기초하여 AI 모델을 훈련시키고 기존 병합 데이터 세트에 포 함된 데이터 샘플에 기초하여 AI 모델의 성능을 평가할 수 있다. GT 데이터 샘플을 획득하여 AI 모델을 훈련시키는 경우, 입력 데이터의 다양한 변주(variation) 및 폐색 (occlusion)에 대해 AI 모델의 성능을 향상시킬 수 있다. 본 개시의 다양한 실시예는, 기존 병합 데이터 세트에 포함된 원본 데이터 샘플에 기초하여 AI 모델을 훈련시킬 수 있을 뿐만 아니라 GT 데이터 샘플에 기초하여 확실한 정답에 대해서 AI 모델을 훈련시킬 수 있다. 도 5는 일 실시예 따른 AI 모델을 이용하여 포즈 추정(pose estimation) 태스크를 수행하는 방법에 관한 도면이 다. 포즈 추정(pose estimation) 태스크는 입력 이미지에서 사람의 관절 위치 또는 신체 부위를 추정하는 태스크이 다. 전자 장치는 복수의 이미지를 포함하는 데이터 세트에 기초하여 AI 모델을 포즈 추정 태스크에 대응되는 결 과를 출력하도록 훈련시킬 수 있다. AI 모델은 포즈 추정 모델로 표현될 수 있다. 훈련된 AI 모델은 입력 이미지에 대한 응답으로 포즈 추정 태스크에 대응되는 예측 또는 추론 값을 출력할 수 있다. 예측 결과는 관절을 포함하는 신체 부위에 관한 정보를 포함할 수 있고, 신체 부위에 관한 정보는 신체 부위와 맵핑되는 위치 정보, 확률, 인덱스(index) 또는 식별자 중 적어도 하나를 포함할 수 있다. 데이터 세트에 포함된 데이터 샘플은 관절을 포함하는 신체 부위 또는 신체 부위의 위치 중 적어도 하나와 관련 하여 레이블링(labeling)이 될 수 있다. 포즈 추정 태스크와 관련하여 데이터 세트의 클래스는 신체 부위를 지 시(indicating)할 수 있다. 예를 들어, 도 5를 참조하면, 데이터 샘플을 포함하는 데이터 세트는 머리, 목, 어깨, 골반, 무릎 등과 관련하여 레이블링이 되어 있다. 데이터 샘플을 포함하는 데이터 세트의 GT 클래스는 {머리, 목, 어깨, 골 반, ... ,무릎}과 같이 표현될 수 있다. 데이터 샘플을 포함하는 데이터 세트는 어깨, 무릎, 골반, 손가락, 얼굴 등과 관련하여 레이블링이 되어있 다. 데이터 샘플을 포함하는 데이터 세트의 GT 클래스는 {어깨, 무릎, 골반, 손가락, ... , 얼굴}과 같이 표현될 수 있다. 전자 장치는 복수의 소스 데이터 세트에 기초하여 병합 데이터 세트를 획득할 수 있고, 이는 단계 S810과 대응 될 수 있다. 예를 들어, 전자 장치는 데이터 샘플을 포함하는 데이터 세트 및 데이터 샘플을 포함하 는 데이터 세트에 기초하여 병합 데이터 세트를 획득할 수 있다. 병합 데이터 세트의 클래스는 머리, 목, 어깨, 무릎, 골반, 손가락, 얼굴 등을 포함할 수 있다. 전자 장치는 병합 데이터 세트에 포함된 제 1 데이터 샘플을 AI 모델에 적용하여 획득된 예측 결과, GT 데이터 및 로스 가중치 정보에 기초하여 제 2 로스를 계산할 수 있고, 단계 S820 및 단계 S830과 대응될 수 있다.일 실시예에서, 전자 장치는 클래스 i에 GT 데이터가 대응되는 복수의 제 2 데이터 샘플을 AI 모델에 적용하여 복수의 제 2 예측 결과를 획득할 수 있다. 전자 장치는 복수의 제 2 예측 결과 및 복수의 제 2 데이터 샘플의 GT 데이터에 기초하여 클래스 i와 대응되는 AI 모델의 정확도를 판단할 수 있다. 예를 들어, 도 5를 참조하면, 무릎 클래스에 대하여, 데이터 샘플을 포함하는 데이터 세트 및 데이터 샘플 을 포함하는 데이터 세트와 같이 무릎 클래스에 GT 데이터 대응되는 데이터 샘플이 제 2 데이터 샘플로 사 용될 수 있다. 전자 장치는 제 2 데이터 샘플의 GT 데이터 및 제 2 데이터 샘플을 AI 모델에 적용하여 획득한 예측 결과 사이의 거리 차이에 기초하여 무릎 클래스와 대응되는 AI 모델의 정확도를 판단할 수 있다. 손가락 클래스에 대하여, 데이터 샘플을 포함하는 데이터 세트와 같이 손가락 클래스에 GT 데이터가 대응 되는 데이터 샘플이 제 2 데이터 샘플로 사용될 수 있다. 전자 장치는 상기 제 2 데이터 샘플의 GT 데이터 및 예측 결과의 거리 차이에 기초하여 손가락 클래스와 대응되는 AI 모델의 정확도를 판단할 수 있다. 전자 장치는 제 2 로스에 기초하여 AI 모델을 업데이트할 수 있고, 이는 단계 S840과 대응될 수 있다. 본 개시 의 다양한 실시예에 따르면, 얼굴 클래스 또는 손가락 클래스와 같이 복수의 데이터 세트가 공통적으로 GT 데이 터가 존재하지 않는 클래스가 있는 경우에도 복수의 데이터 세트에 기초하여 AI 모델을 훈련시킬 수 있다. 전자 장치는 이미지를 AI 모델에 입력하여 포즈 추정 태스크에 대응되는 예측 값을 획득할 수 있다. 도 5를 참 조하면, 데이터 샘플을 포함하는 데이터 세트 및 데이터 샘플을 포함하는 데이터 세트에 기초하여 AI 모델이 훈련된 경우, AI 모델은 입력된 이미지에 대한 응답으로 머리, 목, 어깨, 무릎, 골반, 손가락, 얼굴 등 과 맵핑되는 위치 정보 또는 확률 정보 중 적어도 하나를 출력할 수 있다. 도 6은 일 실시예 따른 AI 모델을 이용하여 세그멘테이션(segmentation) 태스크를 수행하는 방법에 관한 도면이 다. 세그멘테이션(segmentation) 태스크는 입력 이미지에 대하여 픽셀 별로 분류(classification)을 수행하는 태스 크이다. 전자 장치는 복수의 이미지를 포함하는 데이터 세트에 기초하여 AI 모델을 세그멘테이션(segmentation) 태스크에 대응되는 결과를 출력하도록 훈련시킬 수 있다. AI 모델은 세그멘테이션 모델로 표현될 수 있다. 훈련된 AI 모델은 입력 이미지에 대한 응답으로 포즈 추정 태스크에 대응되는 예측 또는 추론 값을 출력할 수 있다. 예측 결과는 픽셀이 전경(foreground)에 해당하는지 또는 픽셀이 배경(background)에 해당하는지를 지시 하는 정보를 포함할 수 있다. 전경은 사람, 개, 테이블 등과 같이 각 객체의 클래스로 구분될 수 있다. GT 데이터 및 예측 결과는 (W, H, C) 와 같이 표현될 수 있고, W는 너비, H는 높이, C는 채널로 정의될 수 있다. 세그멘테이션 태스크의 경우, 채널을 클래스로 이해할 수 있고, 채널 축의 길이 또는 채널의 개수를 클래 스의 개수로 이해할 수 있다. 예를 들어, 도 6을 참조하면, 데이터 샘플을 포함하는 데이터 세트는 사람, 테니스 라켓, 공에 레이블링이 되어있고, 모자에 대하여는 레이블링이 되어있지 않다. 데이터 샘플을 포함하는 데이터 세트의 GT 클래스 는 {사람, 테니스 라켓, 공, 배경}과 같이 표현될 수 있다. 데이터 샘플을 포함하는 데이터 세트는 사람, 과일에 레이블링이 되어 있다. 데이터 샘플을 포함하는 데이터 세트의 GT 클래스는 {사람, 과일, 배경}과 같이 표현될 수 있다. 데이터 샘플을 포함하는 데이터 세트의 GT 클래스는 {사람, 동물, 배경}과 같이 표현될 수 있다. 데이터 샘플을 포함하는 데이터 세트의 GT 클래스는 {사람, 차, 배경}와 같이 표현될 수 있다. 전자 장치는 복수의 소스 데이터 세트에 기초하여 병합 데이터 세트를 획득할 수 있고, 이는 단계 S810과 대응 될 수 있다. 예를 들어, 데이터 샘플을 포함하는 데이터 세트 및 데이터 샘플을 포함하는 데이터 세 트에 기초하여 병합 데이터 세트를 획득할 수 잇다. 병합 데이터 세트의 전체 클래스는 {사람, 테니스 라켓, 공, 차, 배경}과 같이 표현될 수 있다. 전자 장치는 병합 데이터 세트에 포함된 제 1 데이터 샘플을 AI 모델에 적용하여 획득된 예측 결과, GT 데이터 및 로스 가중치 정보에 기초하여 제 2 로스를 계산할 수 있고, 이는 단계 S820 및 단계 S830과 대응될 수 있다. 일 실시예에서, 전자 장치는 클래스 i에 GT 데이터가 대응되는 복수의 제 2 데이터 샘플을 AI 모델에 적용하여 복수의 제 2 예측 결과를 획득할 수 있다. 전자 장치는 복수의 제 2 예측 결과 및 복수의 제 2 데이터 샘플의 GT 데이터에 기초하여 클래스 i와 대응되는 AI 모델의 정확도를 판단할 수 있다. 예를 들어, 도 6을 참조하면, 전자 장치는 채널 별로 모든 픽셀에 대한 예측 결과 및 GT 데이터의 차이에 기초 하여 AI 모델의 정확도를 판단할 수 있다. 사람 채널에 대하여, 데이터 샘플(600, 610, 620, 630)과 같이 사람 채널이 존재하는 데이터 샘플이 제 2 데이터 샘플로 사용될 수 있다. 차 클래스에 대하여, 전자 장치는 데이터 샘플과 같이 차 채널이 존재하는 데이터 샘플이 제 2 데이터 샘플로 사용될 수 있다. 전자 장치는 제 2 로스에 기초하여 AI 모델을 업데이트할 수 있고, 이는 단계 S840과 대응될 수 있다. 본 개시 의 다양한 실시예에 따르면, 차 또는 테니스 라켓과 같이 복수의 데이터 세트가 공통적으로 GT 데이터가 존재하 지 않는 클래스가 있는 경우에도 복수의 데이터 세트에 기초하여 AI 모델을 훈련시킬 수 있다. 전자 장치는 이미지를 AI 모델에 입력하여 세그멘테이션 태스크에 대응되는 예측 값을 획득할 수 있다. 예를 들 어, 데이터 샘플을 포함하는 데이터 세트 및 데이터 샘플을 포함하는 데이터 세트에 기초하여 AI 모 델이 훈련된 경우, AI 모델은 입력된 이미지에 대한 응답으로 픽셀이 사람, 테니스 라켓, 공, 차 또는 배경 중 적어도 하나에 해당하는지를 지시하는 정보를 출력할 수 있다 도 7은 일 실시예에 따른 AI 모델을 이용하여 VRD(Visual relationship detection) 태스크를 수행하는 방법에 관한 도면이다. VRD(Visual relationship detection) 태스크는 입력 이미지에 대하여 (subject, predicate, object)로 표현될 수 있는 주어(subject), 술어(predicate) 목적어(object) 쌍을 식별하는 태스크이다. 주어에 해당하는 객체 및 목적어에 해당하는 객체는 객체 검출을 통해 검출될 수 있다. HOI(Human Object Interaction) 태스크는 VRD 태 스크에서 주어가 사람(human)으로 고정된 태스크이다. 전자 장치는 복수의 이미지를 포함하는 데이터 세트에 기초하여 AI 모델을 VRD 태스크에 대응되는 결과를 출력 하도록 훈련시킬 수 있다. 훈련된 AI 모델은 입력 이미지에 대한 응답으로 VRD 태스크에 대응되는 예측 또는 추 론 값을 출력할 수 있다. AI 모델은 VRD 모델 또는 HOI 모델로 표현될 수 있다. GT 데이터 및 예측 결과는 주어(subject), 술어(predicate) 목적어(object) 쌍에 관한 정보를 포함할 수 있다. VRD 태스크의 경우, 술어를 클래스로 이해할 수 있다. 술어의 종류를 클래스의 개수로 이해할 수 있다. 예를 들 어, 도 7을 참조하면, GT 클래스가 {on, wear}과 같이 표현될 수 있다. 전자 장치는 복수의 소스 데이터 세트에 기초하여 병합 데이터 세트를 획득할 수 있고, 이는 도 8의 단계 S810 과 대응될 수 있다. 전자 장치는 병합 데이터 세트에 포함된 제 1 데이터 샘플을 AI 모델에 적용하여 획득된 예 측 결과, GT 데이터 및 로스 가중치 정보에 기초하여 제 2 로스를 계산할 수 있고, 이는 단계 S820 및 단계 S830과 대응될 수 있다. 전자 장치는 제 2 로스에 기초하여 AI 모델을 업데이트할 수 있고, 단계 S840과 대응될 수 있다. 일 실시예에서, 전자 장치는 클래스 i에 GT 데이터가 대응되는 복수의 제 2 데이터 샘플을 AI 모델에 적용하여 복수의 제 2 예측 결과를 획득할 수 있다. 전자 장치는 복수의 제 2 예측 결과 및 복수의 제 2 데이터 샘플의 GT 데이터에 기초하여 클래스 i와 대응되는 AI 모델의 정확도를 판단할 수 있다. 예를 들어, 전자 장치는 술어 wear에 대하여 GT 데이터가 대응되는 데이터 샘플을 제 2 데이터 샘플로 사용하여 wear 클래스에 대한 AI 모델의 정확도를 판단할 수 있다. 일반적으로 VRD 태스크는 주어와 목적어 사이에 하나 이상의 술어가 존재할 수 있다. 서로 다른 데이터 세트에 대하여 다른 레이블이 존재하는 경우가 많다. VRD 태스크는 데이터 세트에 대한 레이블링 비용이 높아 다수의 데이터 샘플 확보가 곤란할 수 있다. 본 개시의 다양한 실시예에 따르면, 데이터 샘플이 부족한 경우에도 AI를 효율적으로 학습시킬 수 있다. 본 개 시의 다양한 실시예들을 활용하여 주어 및 목적어 쌍에 대한 술어와 관련하여 복수의 GT 데이터가 존재하는 경 우에도 AI 모델을 효율적으로 학습시킬 수 있다. 도 8은 본 개시의 일 실시예에 따른 AI 모델을 훈련시키는 방법에 관한 흐름도이다. 단계 S810에서, 전자 장치는 복수의 소스 데이터 세트에 기초하여 병합 데이터 세트를 획득한다. 전자 장치는 복수의 소스 데이터 세트에 기초하여 병합 데이터 세트를 획득할 수 있다. 병합 데이터 세트 획득 의 기초가 된 데이터 세트는 소스(source) 데이터 세트로 표현될 수 있다. 데이터 세트는 복수의 데이터 샘플을 포함할 수 있고, 데이터 샘플은 통계 자료, 텍스트, 오디오, 이미지, 비디오 등을 포함하거나 또는 이들에 대응 될 수 있다.전자 장치는 복수의 소스 데이터 세트에 포함된 데이터 샘플의 전부 또는 일부를 포함하는 병합 데이터 세트를 획득할 수 있다. 일 실시예에서, GT 데이터와 대응되는 클래스를 GT 클래스라고 할 때, 병합 데이터 세트의 클 래스는 복수의 소스 데이터 세트의 GT 클래스를 모두 포함할 수 있다. 일 실시 예에서, 병합 데이터 세트의 클 래스의 수는 소스 데이터 세트의 GT 클래스의 수보다 크거나 같다. 예를 들어, 복수의 소스 데이터 세트가 제 1 소스 데이터 세트 및 제 2 소스 데이터 세트를 포함하는 경우, 제 1 소스 데이터 세트의 GT 클래스가 {c1, c2, c3}, 제 2 소스 데이터 세트의 GT 클래스가 {c1, c2}라면 병합 데 이터 세트의 클래스는 {c1, c2, c3}일 수 있다. 다른 예를 들어, 제 1 소스 데이터 세트의 GT 클래스가 {c1, c2, c3}이고 제 2 소스 데이터 세트의 GT 클래스가 {c2, c3, c4} 또는 {c4}라면, 병합 데이터 세트의 클래스는 {c1, c2, c3, c4}일 수 있다. 일 실시예에서, 병합 데이터 세트는 트레인 세트(train set) 및 테스트 세트(test set)로 분할될 수 있다. 트레 인 세트에 포함된 데이터 샘플에 기초하여 AI 모델을 훈련시키고, 테스트 세트에 포함된 데이터 샘플에 기초하 여 AI 모델의 성능을 평가할 수 있다. 일 실시예에서, 병합 데이터 세트는 트레인 세트, 밸리데이션 세트(validation set) 및 테스트 세트로 분할될 수 있다. 트레인 세트에 포함된 데이터 샘플에 기초하여 AI 모델을 훈련시키고, 밸리데이션 세트에 포함된 데이 터 샘플에 기초하여 학습 중 AI 모델의 성능을 평가하고, 트레인 세트에 포함된 데이터 샘플에 기초하여 학습이 완료된 AI 모델의 성능을 평가할 수 있다. 일 실시예에서, 전자 장치는 병합 데이터 세트에 포함된 데이터 샘플에 기초하여 GT 데이터 샘플을 획득할 수 있고, 병합 데이터 세트는 GT 데이터 샘플을 더 포함할 수 있다. GT 데이터 샘플과 관련하여 도 4a 및 도 4b의 설명과 중복되는 부분은 명세서의 명확한 기재를 위하여 일부 생략될 수 있다 전자 장치는 병합 데이터 세트의 GT 영역 정보에 기초하여 GT 영역을 포함하는 GT 데이터 샘플을 획득할 수 있 다. GT 영역 정보는 GT 바운딩 박스 정보, GT 픽셀 정보 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 전자 장치는 GT 영역 이외의 영역은 일정한 값으로 설정하여 GT 데이터 샘플을 획득할 수 있다. 일 실시예에서, 전자 장치는 패딩(padding) 정보에 기초하여 GT 데이터 샘플을 획득할 수 있다. 일 실시예에서, 전자 장치는 가우시안 필터(Gaussian filter)를 이용하여 GT 데이터 샘플을 획득할 수 있다. 일 실시예에서, GT 데이터 샘플은 적어도 하나의 GT 영역이 추가로 지워지거나 소정의 값으로 설정될 수 있다. 전자 장치는 GT 데이터 샘플에 기초하여 상기 AI 모델의 파라미터를 업데이트할 수 있다. 예를 들어, 전자 장치 는 GT 데이터 샘플 및 기존 병합 데이터 세트에 포함된 데이터 샘플에 기초하여 AI 모델을 훈련시키고 AI 모델 의 성능을 평가할 수 있다. 또는 GT 데이터 샘플에 기초하여 AI 모델을 훈련시키고 기존 병합 데이터 세트에 포 함된 데이터 샘플에 기초하여 AI 모델의 성능을 평가할 수 있다. 단계 S820에서, 전자 장치는 병합 데이터 세트에 포함된 제 1 데이터 샘플을 AI 모델에 적용하여 획득된 예측 결과 및 GT 데이터에 기초하여 제 1 로스를 계산한다. 일 실시예에서, 제 1 데이터 샘플은 병합 데이터 세트의 트레인 세트에 포함된 데이터 샘플일 수 있다. 일 실시 예에서, AI 모델은 분류(classification) 모델, 객체 검출 (object detection) 모델, 세그멘테이션 (segmentation) 모델, 포즈 추정(pose estimation) 모델, HOI(Human Object Interaction) 모델 또는 VRD (visual relationship detection) 모델 중 적어도 하나를 포함할 수 있다. 예를 들어, AI 모델이 분류 모델인 경우 제 1 데이터 샘플을 AI 모델에 입력하여 획득된 예측 결과는 클래스와 대응되는 확률 정보를 포함할 수 있다. 클래스와 대응되는 확률은 이미지에 클래스에 해당하는 객체가 포함 가 능성을 지시할 수 있다. 제 1 데이터 샘플의 GT 데이터는 클래스에 해당하는 객체가 포함되는지를 지시할 수 있 다. 예를 들어, AI 모델이 객체 검출 모델인 경우, 제 1 데이터 샘플을 AI 모델에 입력하여 획득된 예측 결과는 객 체의 위치 정보 또는 객체에 대응되는 클래스 정보 중 적어도 하나를 포함할 수 있다. 객체의 위치 정보는 바운 딩 박스로 표현될 수 있다. 제 1 데이터 샘플의 GT 데이터는 객체의 위치 또는 객체에 대응되는 클래스 중 적어 도 하나를 지시할 수 있다. 포즈 추정 모델, 세그멘테이션 모델, VRD 모델, HOI 모델과 관련하여 도5 내지 도7 의 설명과 중복되는 부분은 명세서의 명확한 기재를 위해 일부 생략될 수 있다. 전자 장치는 제 1 데이터 샘플을 AI 모델에 적용하여 예측 결과를 획득할 수 있다. 일 실시예에서, 예측 결과는 병합 데이터 세트의 전체 클래스와 대응되는 예측 결과를 포함할 수 있다. 제 1 데이터 샘플의 GT 데이터는 병합 데이터 세트의 전체 클래스와 대응되는 GT 데이터를 포함할 수 있다. 제 1 데이터 샘플의 GT 데이터는 GT 클래스와 대응되는 GT 데이터 및 GT 클래스가 제외된 전체 클래스와 대응되는 GT 데이터를 포함할 수 있다. 일 실시예에서, 제 1 데이터 샘플의 GT 데이터는 GT 클래스가 제외된 전체 클래스 에 대응되는 값으로 0과 같이 디폴트 값이 설정될 수 있다. 일 실시예에서, 전자 장치는 상기 제 1 데이터 샘플의 예측 결과 및 상기 제 1 데이터 샘플의 GT 데이터를 로스 함수(loss function)에 적용하여 제 1 로스를 계산할 수 있다. 전자 장치는 클래스와 대응되는 예측 결과 및 클 래스와 대응되는 GT 데이터에 기초하여 제 1 로스를 계산할 수 있다. 예를 들어, gt는 GT 데이터, pred는 예측결과, L은 로스 함수라고 할 때, 제 1 로스 은 다음의 수학식 1에 기 초하여 계산될 수 있다. 수학식"}
{"patent_id": "10-2022-0169099", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "로스 함수는 크로스엔트로피 로스(cross-entropy loss), 힌지 로스 (hinge loss), MAE (mean absolute error), MSE (mean squared error), KLD 로스 (Kullback-Leibler divergence loss), 후버 로스 (Huber loss) 또는 RMSE (root mean squared error) 중 적어도 하나를 포함할 수 있고, 언급된 로스 함수에 한하지 않고 다양한 로 스 함수 내지 코스트 함수(cost function)에 적용될 수 있다. 예를 들어, 로스 함수가 MSE인 경우, 제 1 로스는 다음의 수학식 에 기초하여 계산될 수 있다. 예를 들어, 로스 함수가 RMSE인 경우, 제 1 로스는 다음의 수학식 에 기초하여 계산될 수 있다. 예를 들어, 로스 함수가 MAE인 경우, 제 1 로스는 수학식 에 기초하여 계 산될 수 있다. 예를 들어, 로스 함수가 크로스 엔트로피 로스인 경우, 제 1 로스는 수학식 에 기초하여 계산될 수 있다. 한편, i는 클래스의 식별자, 는 클래스 i와 맵핑되는 로스 가중치, 클래스 i와 대응되는 예측 결과,"}
{"patent_id": "10-2022-0169099", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "는 클래스 i와 대응되는 GT 데이터, n은 클래스의 개수로 정의될 수 있다. 일 실시예에서, 전자 장치는 병합 데이터 세트에 포함된 복수의 제 1 데이터 샘플을 AI 모델에 적용하여 획득된 예측 결과 및 복수의 제 1 데이터 샘플의 GT 데이터에 기초하여 제 1 로스를 계산할 수 있다. 복수의 제 1 데이터 샘플에 기초하여 제 1 로스를 계산하는 방법은 전술한 제 1 로스를 계산하는 방법과 대응될 수 있다. 복수의 제 1 데이터 샘플에 기초하여 계산된 제 1 로스는 평균이나 합으로 표현될 수 있다. 단계 S830에서, 전자 장치는 제 1 데이터 샘플에 대응되는 로스 가중치 정보 및 제 1 로스에 기초하여 제 2 로 스를 계산한다. 일 실시예에서, 전자 장치는 제 1 데이터 샘플을 AI 모델에 적용하여 획득한 예측 결과, 제 1 데이터 샘플의 GT 데이터 및 제 1 데이터 샘플의 로스 가중치 정보에 기초하여 제 2 로스를 계산할 수 있다. 일 실시예에서, 전자 장치는 병합 데이터 세트에 포함된 제 1 데이터 샘플을 AI 모델에 적용하여 획득된 예측 결과, 제 1 데이터 샘플의 GT 데이터 및 로스 가중치 정보를 로스 함수에 적용하여 제 2 로스를 계산할 수 있다. 전자 장치는 로스 함수에서 각 클래스 별로 로스 가중치를 곱하여 제 2 로스를 계산할 수 있다.로스 함수는 크로스엔트로피 로스(cross-entropy loss), 힌지 로스 (hinge loss), MAE (mean absolute error), MSE (mean squared error), KLD 로스 (Kullback-Leibler divergence loss), 후버 로스 (Huber loss) 또는 RMSE (root mean squared error) 중 적어도 하나를 포함할 수 있고, 언급된 로스 함수에 한하지 않고 다양한 로 스 함수 내지 코스트 함수(cost function)에 적용될 수 있다. 예를 들어, 로스 함수가 MSE인 경우, 제 2 로스는 다음의 수학식 에 기초하여 결정될 수 있다. 예를 들어, 로스 함수가 RMSE인 경우, 제 2 로스는 다음의 수학식 에 기초하 여 결정될 수 있다. 예를 들어, 로스 함수가 MAE인 경우, 제 2 로스는 다음의 수학식 에 기초하여 결정될 수 있다. 예를 들어, 로스 함수가 크로스 엔트로피 로스인 경우, 제 2 로스는 다음의 수학식 에 기초하여 결정될 수 있다. 한편, i는 클래스의 식별자, 는 클래스 i와 맵핑되는 로스 가중치, 클래스 i와 대응되는 예측 결과,"}
{"patent_id": "10-2022-0169099", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "는 클래스 i와 대응되는 GT 데이터, n은 클래스의 개수로 정의될 수 있다. 로스 가중치 정보는 병합 데이터 세트의 클래스와 맵핑되는 로스 가중치를 포함할 수 있다. 예를 들어, 병합 데 이터 세트의 클래스가 {c1, c2, c3}인 경우, 로스 가중치 정보는 {m1, m2, m3}와 같이 클래스 c1과 맵핑되는 로 스 가중치 m1, 클래스 c2와 맵핑되는 로스 가중치 m2, c3와 맵핑되는 로스 가중치 m3를 포함할 수 있다. 일 실시예에서, 로스 가중치 정보는 GT 클래스와 맵핑되는 제 1 로스 가중치 및 GT 클래스가 제외된 전체 클래 스와 맵핑되는 제 2 로스 가중치를 포함할 수 있다. 일 실시예에서, 전자 장치는 제 1 로스 가중치가 제 2 로스 가중치보다 크거나 같도록 로스 제 1 데이터 샘플에 대응되는 로스 가중치 정보를 결정할 수 있다. 일 실시예에서, 제 1 로스 가중치가 1 인 경우, 제 2 로스 가중 치는 0이상 1이하의 값으로 결정될 수 있다. 일 실시예에서, 전자 장치는 제 1 데이터 샘플에 대응되는 로스 가중치 정보 및 제 1 로스에 기초하여 제 2 로 스를 계산할 수 있다. 전자 장치는 복수의 소스 데이터 세트의 로스 가중치 정보를 획득 또는 결정할 수 있다. 예를 들어, 전자 장치 는 제 1 소스 데이터 세트의 로스 가중치 정보 및 제 2 소스 데이터 세트의 로스 가중치 정보를 획득 또는 결정 할 수 있다. 제 1 데이터 샘플에 대응되는 로스 가중치 정보는 제 1 데이터 샘플에 대응되는 소스 데이터 세트의 로스 가중 치 정보를 포함할 수 있다. 전자 장치는 제 1 데이터 샘플과 대응되는 소스 데이터 세트를 식별할 수 있다. 제 1 데이터 샘플과 대응되는 소스 데이터 세트는 제 1 데이터 샘플이 포함되었던 소스 데이터 세트로 이해될 수 있다. 예를 들어, 제 1 데이터 샘플이 제 1 소스 데이터 세트 포함된 데이터 샘플이었던 경우, 제 1 데이터 샘플과 대 응되는 소스 데이터 세트는 제 1 소스 데이터 세트이다. 다른 예를 들어, 제 1 데이터 샘플이 제 2 소스 데이터 세트에 포함된 데이터 샘플이었던 경우, 제 1 데이터 샘플과 대응되는 소스 데이터 세트는 제 2 소스 데이터 세 트이다. 전자 장치는 소스 데이터 세트의 GT 클래스에 관한 정보 또는 학습 진행 정도에 관한 정보 중 적어도 하나에 기 초하여 소스 데이터 세트의 로스 가중치 정보를 결정할 수 있다. 전자 장치는 소스 데이터 세트의 GT 클래스에 관한 정보에 기초하여 병합 데이터 세트의 전체 클래스가 소스 데이터 세트의 GT 클래스인지 여부를 식별할 수 있다. 소스 데이터 세트의 로스 가중치 정보는 소스 데이터 세트의 GT 클래스와 맵핑되는 제 1 로스 가중치 및 GT 클 래스를 제외한 전체 클래스와 맵핑되는 제 2 로스 가중치를 포함할 수 있다. 전자 장치는 학습 진행 정도에 관한 정보에 기초하여 GT 클래스와 맵핑되는 제 1 로스 가중치가 GT 클래스를 제 외한 전체 클래스와 맵핑되는 제 2 로스 가중치보다 크거나 같도록 제 1 로스 가중치 및 제 2 로스 가중치를 결 정할 수 있다. 예를 들어, 병합 데이터 세트의 클래스가 {c1, c2, c3}이고 제 1 소스 데이터 세트의 GT 클래스가 {c1, c2}인 경우, 전자 장치는 GT 클래스{c1, c2}와 맵핑되는 제 1 로스 가중치{m1, m2} 각각이 GT 클래스가 제외된 전체 클래스 {c3}와 맵핑되는 제 2 로스 가중치 {m3}보다 크거나 같도록 결정할 수 있다. 일 실시예에서, 학습 진행 정도에 관한 정보는 AI 모델의 정확도 또는 AI 모델의 학습 단계 중 적어도 하나를 포함할 수 있다. AI 모델의 정확도 또는 AI 모델의 학습 단계 중 적어도 하나가 증가한 경우, 전자 장치는 제 2 로스 가중치가 작아지도록 결정할 수 있다. 전자 장치는 AI 모델의 정확도 또는 AI 모델의 학습 단계를 판단할 수 있다. AI 모델의 학습 단계는 에포크 (epoch) 혹은 스텝(step) 등에 기초하여 판단될 수 있다. AI 모델의 정확도는 클래스와 대응되는 AI 모델의 정 확도를 포함할 수 있다. 일 실시예에서, AI 모델의 정확도는 밸리데이션 세트의 데이터 샘플 또는 테스트 세트 의 데이터 샘플에 기초하여 획득될 수 있다. 일 실시예에서, 제 1 로스 가중치가 1인 경우, 전자 장치는 수학식 에 기 초하여 제 2 로스 가중치를 계산할 수 있다. i는 클래스의 식별자, 상기 는 클래스 i와 맵핑되는 제 2 로스 가중치, 상기 는 클래스 i와 대응되는 AI 모 델의 정확도 (confidence), 상기 e는 1 이상의 정수로 표현되는 AI 모델의 학습 단계, 상기 는 제 1 설정값 (configured value), 상기 는 제 2 설정값으로 정의될 수 있다. 일 실시예에서, 전자 장치는 클래스 i에 GT 데이터가 대응되는 복수의 제 2 데이터 샘플을 AI 모델에 적용하여 복수의 제 2 예측 결과를 획득할 수 있다. 전자 장치는 클래스 i에 관한 복수의 제 2 예측 결과 및 복수의 제 2 데이터 샘플의 GT 데이터에 기초하여 클래스 i와 대응되는 AI 모델의 정확도를 판단할 수 있다. 클래스 i에 대응되는 제 2 예측결과 및 클래스 i에 대응되는 제 2 데이터 샘플의 GT 데이터를 비교하여 정확도 를 측정하고, 복수의 제 2 데이터 샘플에 대하여 계산된 정확도의 평균을 클래스 i와 대응되는 AI 모델의 정확 도로 판단할 수 있다. 예를 들어, AI 모델이 분류 모델인 경우, 클래스 i에 대응되는 GT 데이터가 존재하는 이미지를 제 2 데이터 샘 플로 사용할 수 있다. 사람 클래스에 대해 GT 데이터가 존재하는 데이터 샘플에 기초하여 AI 모델을 훈련시킬 수 있다. 클래스 i와 대응되는 AI 모델의 정확도가 1인 경우 AI 모델이 복수의 제 2 데이터 샘플을 GT 데이터 와 모두 동일하게 클래스를 분류한 것이고, AI 모델의 정확도가 0인 경우 복수의 제 2 데이터 샘플을 GT 데이터 와 모두 다르게 클래스를 분류한 것에 해당할 수 있다. 예를 들어, AI 모델이 객체 검출 모델인 경우, 클래스 i로 추론되는 바운딩 박스를 포함하는 데이터 샘플을 제 2 데이터 샘플로 사용할 수 있다. 클래스 i로 추론된 예측결과의 바운딩 박스 및 GT 데이터의 바운딩 박스에 기 초하여 IoU(intersection over union)을 계산할 수 있다. 복수의 제 2 데이터 샘플의 IoU 평균값에 기초하여 클래스 i와 대응되는 AI 모델의 정확도를 판단할 수 있다. 한편, 단계 S820이 먼저 수행되고 복수의 소스 데이터 세트의 로스 가중치 정보가 획득(또는 결정)될 수도 있고, 복수의 소스 데이터 세트의 로스 가중치 정보 획득(또는 결정)과 단계 S820이 동시에 수행될 수도 있고, 복수의 소스 데이터 세트의 로스 가중치 정보가 획득(또는 결정)되고 이후 단계 S820이 수행될 수도 있다. 일부 실시예에서는 단계 S820이 생략될 수 있다. 단계 S840에서, 전자 장치는 제 2 로스에 기초하여 AI 모델의 파라미터를 업데이트한다. AI 모델의 파라미터는 하나 이상의 가중치(weight), 하나 이상의 바이어스(bias)를 포함할 수 있다. 전자 장치 는 제 2 로스에 기초하여 적어도 하나의 가중치 또는 적어도 하나의 바이어스 중 적어도 하나를 업데이트할 수 있다. 전자 장치는 역전파(backpropagation)를 통해 AI 모델에 대해 제 2 로스가 줄어드는 방향으로 훈련시킬 수 있다. 전자 장치는 AI 모델을 비전 태스크를 처리할 수 있도록 훈련시킬 수 있다. 전자 장치는 AI 모델을 이용하여 비 전 태스크(vision task)를 처리할 수 있다. 태스크는 분류(classification), 객체 검출(object detection), 세 그멘테이션(segmentation), 포즈 추정(pose estimation), VRD, 또는 HOI 중 적어도 하나를 포함할 수 있다. AI 모델을 이용하여 태스크를 수행하는 방법은 도 5 내지 도 7의 설명과 대응될 수 있다. 이 외에도 전자 장치는 머신 러닝, 자연어 처리, 음성 인식, 음성 처리, 화자 인식 등 다양한 태스크를 처리할 수 있다. 전자 장치는 태스크의 처리에 필요한 입력 데이터를 획득할 수 있다. 예를 들어, 입력 데이터는 적어도 하나의 객체를 포함하는 이미지일 수 있다. 전자 장치는 입력 데이터를 AI 모델에 입력하여, 태스크에 대응되는 결과를 출력할 수 있다. 훈련된 AI 모델은 입력에 대한 응답으로 각 태스크에 대응되는 예측 또는 추론 값을 출력할 수 있다. 프로세서 또는 제2 프로세서는 출력 값에 대해 추가 프로세싱 작업을 거쳐 소정의 서비스를 제공할 수 있다. 예를 들어, 분류 태스크를 수행하는 경우, 태스크에 대응되는 결과는 이미지에 포함된 적어도 하나의 객체에 대 응되는 클래스와 연관된 예측 값을 출력할 수 있다. 설명의 편의상, 일부 설명에서 AI 모델이 컴퓨터 비전 분야의 태스크를 수행하는 모델인 것을 예로 들어 설명하 나, 본 개시에서 설명하는 AI 모델의 종류나 기능이 이에 한정되는 것은 아니며, 음성 인식, 자연어 처리 등 다 양한 분야에서 활용될 수 있는 인공지능 모델일 수 있다. 흐름도의 각 단계 내지 동작은 실제 구현 시 통합, 추가, 생략 또는 순서를 바꾸어 구현될 수 있다. 즉 필요에 따라 2 이상의 동작이 동시에 수행되거나, 혹은 하나의 동작이 2 이상의 동작으로 세분되어 수행될 수 있다. 도 9a 및 도 9b는 본 개시의 일 실시예에 따른 전자 장치에 관한 블록도이다. 도 9a를 참조하면, 일 실시예에 따른 전자 장치는 메모리, 프로세서를 포함할 수 있다. 메모리는 프로세서가 판독할 수 있는 명령어들, 데이터 구조, 및 프로그램 코드(program code)가 저 장될 수 있다. 프로세서가 수행하는 동작들은 메모리에 저장된 프로그램의 명령어들 또는 코드들을 실행함으로써 구현될 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등)를 포함할 수 있으며, 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나를 포함하는 비 휘 발성 메모리 및 램(RAM, Random Access Memory) 또는 SRAM(Static Random Access Memory)과 같은 휘발성 메모 리를 포함할 수 있다. 일 실시예에 따른 메모리는 전자 장치가 AI 모델의 학습 또는 훈련을 수행하도록 제어하는 하나 이상 의 인스트럭션 및/또는 프로그램을 저장할 수 있다. 예를 들어, 메모리에는 모델 학습 모듈이 저장될 수 있다. 프로세서는 메모리에 저장된 명령어들이나 프로그램화된 소프트웨어 모듈을 실행함으로써, 전자 장치 가 수행하는 동작이나 기능을 제어할 수 있다. 프로세서는 산술, 로직 및 입출력 연산과 시그널 프로 세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 예를 들어, 프로세서는 메모리에 저장된 모 델 학습 모듈을 불러와 실행할 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서(microprocessor), 그래픽 처리 장치(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 애플리케이션 프로세서(Application Processor), 신경망 처리 장치(Neural Processing Unit) 또는 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계된 인공지능 전 용 프로세서 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 프로세서를 구성하는 각 프로세서는 소정의 기능을 수행하기 위한 전용 프로세서일 수 있다. 프로세서는 메모리에 저장된 명령어들이나 프로그램화된 소프트웨어 모듈을 실행함으로써, 전자 장치 가 수행하는 동작이나 기능을 제어할 수 있다. 프로세서는 산술, 로직 및 입출력 연산과 시그널 프로 세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 예를 들어, 프로세서는 메모리에 저장된 모 델 학습 모듈을 불러와 실행할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션(instructions)을 실행함으로써, 전자 장치(90 0)가 AI 모델의 학습을 수행하거나 AI 모델을 이용하여 태스크를 처리하기 위한 전반적인 동작들을 제어할 수 있다. 전자 장치는 도 9b에 도시된 바와 같이, 일 실시예에 따른 전자 장치는 메모리, 프로세서, 카메라, 디스플레이, 통신 인터페이스를 포함할 수 있다. 메모리 및 프로세서에 대해서는 도 10에서 설명한 것과 중복되는 내용은 이하 그 설명을 제외한다. 메모리에는 모델 학습 모듈, 모델 실행 모듈 중 적어도 하나 저장될 수 있다. 프로세서는 메모리 로부터 모델 학습 모듈이나 모델 실행 모듈을 불러와 실행할 수 있다. 카메라는 이미지를 획득하는 하드웨어 모듈이다. 카메라는 사진이나 동영상과 같은 이미지를 촬영할 수 있다. 카메라는 적어도 하나의 카메라 모듈을 구비할 수 있으며, 전자 장치의 사양에 따라, 접사, 심도, 망원, 광각, 초광각 등의 기능을 지원할 수 있다. 디스플레이는 정보나 영상을 제공하는 출력부를 포함하며, 입력을 수신하는 입력부를 더 포함한 형태일 수 있다. 출력부는 표시 패널 및 표시 패널을 제어하는 컨트롤러를 포함할 수 있으며, OLED(Organic Light Emitting Diodes) 디스플레이, AM-OLED(Active-Matrix Organic Light-Emitting Diode) 디스플레이, LCD(Liquid Crystal Display) 등과 같은 다양한 방식으로 구현될 수 있다. 입력부는 사용자로부터 다양한 형태 의 입력을 받을 수 있으며, 터치 패널, 키패드, 펜 인식 패널 중 적어도 하나를 포함한 형태일 수 있다. 디스플 레이는 표시 패널과 터치 패널이 결합된 터치 스크린 형태로 제공될 수 있으며, 유연하게(flexible) 또는 접을 수 있게(foldable) 구현될 수 있다. 통신 인터페이스는 다른 장치 또는 네트워크와 유무선 통신을 수행할 수 있다. 통신 인터페이스는 다 양한 유무선 통신 방법 중 적어도 하나를 지원하는 통신 회로 또는 통신 모듈을 포함할 수 있다. 예를 들어, 통 신 인터페이스는 예를 들어, 유선 랜, 무선 랜(Wireless LAN), 와이파이(Wi-Fi), 블루투스(Bluetooth), 지그비(ZigBee), WFD(Wi-Fi Direct), 적외선 통신(IrDA, infrared Data Association), BLE (Bluetooth Low Energy), NFC(Near Field Communication), 와이브로(Wireless Broadband Internet, Wibro), 와이맥스(World Interoperability for Microwave Access, WiMAX), SWAP(Shared Wireless Access Protocol), 와이기그 (Wireless Gigabit Alliances, WiGig) 및 RF 통신을 포함하는 데이터 통신 방식 중 적어도 하나를 이용하여, 전자 장치와 다른 장치들 간의 데이터 통신을 수행할 수 있다. 일 실시예에 따른 통신 인터페이스는 AI 모델의 학습을 수행하기 위해 이용되는 인공지능 모델이나 훈련용 데이터 세트를 외부 장치와 송수신할 수 있다. 통신 인터페이스는 서버(미도시)로 전자 장치의 카메 라를 통해 촬영한 이미지를 전송하거나, 서버(미도시)에서 학습된 인공지능 모델이나 데이터 세트를 수신 할 수 있다. 프로세서 또는 프로세서를 구성하는 제1 프로세서는 모델 학습 모듈을 실행하여, AI 모델을 학습시킬 수 있다. 프로세서 또는 제1 프로세서는 병합 데이터 세트 또는 병합 데이터 세트 중 트레인 데이터 세트 를 이용하여 AI 모델을 학습시킬 수 있다. 병합 데이터 세트 또는 트레인 데이터 세트는 데이터가 생성된 시간 이나 장소, 크기, 생성자, 데이터 종류 등의 데이터 속성 정보에 따라 분류되어, 모델의 학습에 이용될 수 있다. 예를 들어, AI 모델이 비전 모델인 경우, 프로세서 또는 제1 프로세서는 모델의 학습을 위해 복수의 이미 지들을 획득할 수 있다. 프로세서 또는 제1 프로세서는 전자 장치의 카메라를 통해 이미지를 획 득하거나, 통신 인터페이스를 통해 외부 장치로부터 이미지를 획득할 수 있다. 프로세서 또는 제1 프 로세서는 획득된 이미지에 대해 전처리 과정을 거치거나 학습 데이터 세트에서 모델을 학습하기 위한 입력 데이 터들을 선별할 수 있다. 프로세서 또는 제1 프로세서는 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient descent)을 포함하는 학습 알고리즘 등을 이용하여 AI 모델을 학습 또는 훈련시킬 수 있다. 프로세서 또는 프로세서를 구성하는 제2 프로세서는 모델 실행 모듈을 실행하여, 태스크를 처리할 수 있다. 태스크는 분류(classification) 태스크, 객체 검출(object detection) 태스크, 세그멘테이션 (segmentation) 태스크, 포즈 추정(pose estimation) 태스크, VRD 태스크, 또는 HOI 태스크 중 적어도 하나를 포함할 수 있다. 각 태스크를 수행하는 방법은 도 5 내지 도 7의 설명과 대응될 수 있다. 프로세서 또는 제2 프로세서는 태스크의 처리에 필요한 입력 데이터를 획득할 수 있다. 프로세서 또 는 제2 프로세서는 입력 데이터를 AI 모델에 입력하여, 태스크에 대응되는 결과를 출력할 수 있다. 훈련된 AI 모델은 입력에 대한 응답으로 각 태스크에 대응되는 예측 또는 추론 값을 출력할 수 있다. 프로세서 또는 제2 프로세서는 출력 값에 대해 추가 프로세싱 작업을 거쳐 소정의 서비스를 제공할 수 있다. 모델 학습 모듈 및 모델 실행 모듈 중 하나는 전자 장치에 탑재되고, 나머지 하나는 서버에 탑재될 수 있 다. 이 경우, 전자 장치와 서버는 통신을 통하여, 어느 장치에 탑재된 모델 학습 모듈에서 구축된 모델에 관한 정보를 다른 장치에 탑재된 모델 실행 모듈에 제공할 수 있다. 또는, 전자 장치와 서버는 통신을 통 하여, 어느 장치에 탑재된 모델 실행 모듈에 입력된 데이터 세트를 다른 장치에 탑재된 모델 학습 모듈에 제공 할 수 있다. 블록도의 각 구성요소는 실제 구현되는 각 장치의 사양에 따라 통합, 추가 또는 생략될 수 있다. 즉 필요에 따 라 2 이상의 구성요소가 하나의 구성요소로 합쳐지거나, 혹은 하나의 구성요소가 2 이상의 구성요소로 세분되어 구성될 수 있다. 또한, 각 블록에서 수행하는 기능은 실시예들을 설명하기 위한 것이며, 그 구체적인 동작이나 장치는 본 발명의 권리범위를 제한하지 아니한다. 본 개시의 다양한 실시예에서 제공되는 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형 태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발 명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수 도 있다. 컴퓨터 판독 가능 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행 하도록 특별히 구성된 하드웨어 장치가 포함된다. 또는, 이들의 일부 또는 전부의 조합으로 구성된 메모리에 저 장될 수 있다. 또한, 각각의 구성 메모리는 다수 개 포함될 수도 있다. 프로그램 명령의 예에는 컴파일러에 의 해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 컴퓨터 판독 가능 매체는, 비일시적(non-transitory) 기록매체의 형태로 제공될 수 있다. 여기서, 비일시적 기 록매체는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 기록매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 또한, 프로그램은 인터넷 (Internet), 인트라넷 (Intranet), LAN (local area network), WAN (wide area network), 또는 SAN (storage area network)과 같은 통신 네트워크, 또는 이들의 조합으로 구성된 통신 네트워 크를 통하여 접근 (access)할 수 있는 부착 가능한 (attachable) 저장 장치 (storage device)에 저장될 수 있 다. 이러한 저장 장치는 외부 포트를 통하여 본 개시의 실시 예를 수행하는 장치에 접속할 수 있다. 또한, 통신 네트워크상의 별도의 저장장치가 본 개시의 실시 예를 수행하는 장치에 접속할 수도 있다. 또한, 개시된 실시예들에 따른 전자 장치의 동작 방법은 컴퓨터 프로그램 제품(computer program product)에 포 함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 S/W 프로그램, S/W 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체를 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 전자 장치의 제조사 또는 전자 마켓(예, 구글 플레이 스토어, 앱 스 토어)을 통해 전자적으로 배포되는 S/W 프로그램 형태의 상품(예, 다운로더블 앱)을 포함할 수 있다. 전자적 배 포를 위하여, S/W 프로그램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저 장 매체는 제조사의 서버, 전자 마켓의 서버, 또는 SW 프로그램을 임시적으로 저장하는 중계 서버의 저장매체가될 수 있다. 컴퓨터 프로그램 제품은, 서버 및 전자 장치로 구성되는 시스템에서, 서버의 저장매체 또는 전자 장치의 저장매 체를 포함할 수 있다. 또는, 서버 또는 전자 장치와 통신 연결되는 제3 장치(예, 스마트폰)가 존재하는 경우, 컴퓨터 프로그램 제품은 제3 장치의 저장매체를 포함할 수 있다. 또는, 컴퓨터 프로그램 제품은 서버로부터 전 자 장치 또는 제3 장치로 전송되거나, 제3 장치로부터 전자 장치로 전송되는 S/W 프로그램 자체를 포함할 수 있 다. 이 경우, 서버, 전자 장치 및 제3 장치 중 하나가 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방 법을 수행할 수 있다. 또는, 서버, 전자 장치 및 제3 장치 중 둘 이상이 컴퓨터 프로그램 제품을 실행하여 개시 된 실시예들에 따른 방법을 분산하여 실시할 수 있다. 예를 들면, 서버가 서버에 저장된 컴퓨터 프로그램 제품을 실행하여, 서버와 통신 연결된 전자 장치가 개시된 실시예들에 따른 방법을 수행하도록 제어할 수 있다. 인공 지능(Artificial Intelligence, AI) 모델을 훈련시키는 전자 장치는 적어도 하나의 인스트럭션이 저장된 메모리 및 적어도 하나의 프로세서를 포함할 수 있다. 적어도 하나의 프로세서는 복수의 소스(source) 데이터 세트에 기초하여 병합 데이터 세트를 획득할 수 있다. 병합 데이터 세트의 전체 클래스는 복수의 소스 데이터 세트의 GT(Ground-Truth) 데이터가 존재하는 GT 클래스 를 모두 포함할 수 있다. 적어도 하나의 프로세서는 병합 데이터 세트에 포함된 제 1 데이터 샘플을 AI 모델에 적용하여 획득된 예측 결과 및 제 1 데이터 샘플의 GT 데이터에 기초하여 제 1 로스를 계산할 수 있다. 적어도 하나의 프로세서는 제 1 로스 및 제 1 데이터 샘플에 대응되는 로스 가중치 정보에 기초하여 제 2 로스를 계산 할 수 있다. 적어도 하나의 프로세서는 제 2 로스에 기초하여 AI 모델의 적어도 하나의 파라미터(parameter)를 업데이트할 수 있다. 적어도 하나의 프로세서는 제 1 데이터 샘플에 대응되는 소스 데이터 세트를 식별할 수 있다. 적어도 하나의 프 로세서는 식별된 소스 데이터 세트의 GT 클래스에 관한 정보 또는 AI 모델의 학습 진행 정도에 관한 정보 중 적 어도 하나에 기초하여 식별된 소스 데이터 세트의 로스 가중치 정보를 결정할 수 있다 적어도 하나의 프로세서 는 제 1 로스 및 식별된 소스 데이터 세트의 로스 가중치 정보에 기초하여 제 2 로스를 계산할 수 있다. 적어도 하나의 프로세서는 GT 클래스에 관한 정보에 기초하여 전체 클래스가 식별된 소스 데이터 세트의 GT 클 래스인지 여부를 식별할 수 있다. 적어도 하나의 프로세서는 GT 클래스와 맵핑(mapping)되는 제 1 로스 가중치 가 GT 클래스가 제외된 전체 클래스와 맵핑되는 제 2 로스 가중치보다 크거나 같도록 제 1 로스 가중치 및 제 2 로스 가중치를 결정할 수 있다. 제 1 로스 가중치 및 제 2 로스 가중치를 포함하는 식별된 소스 데이터 세트의 로스 가중치 정보를 결정할 수 있다. 학습 진행 정도에 관한 정보는 AI 모델의 정확도 또는 AI 모델의 학습 단계 중 적어도 하나를 포함할 수 있다. 적어도 하나의 프로세서는 제 1 로스 가중치 및 제 2 로스 가중치를 결정할 수 있다. 적어도 하나의 프로세서는 AI 모델의 정확도 또는 AI 모델의 학습 단계를 판단할 수 있다. 적어도 하나의 프로세서는 AI 모델의 정확도 또 는 AI 모델의 학습 단계 중 적어도 하나가 증가한 경우, 제 2 로스 가중치가 작아지도록 결정할 수 있다. 적어도 하나의 프로세서는 제 1 로스 가중치가 1 인 경우, 수학식 에 기 초하여 제 2 로스 가중치를 계산할 수 있다. i는 클래스의 식별자, 는 클래스 i와 맵핑되는 제 2 로스 가중치, 는 클래스 i에 대응되는 AI 모델의 정확도 (confidence), e는 1 이상의 정수로 표현되는 AI 모델의 학습 단계, 는 제 1 설정값 (configured value), 는 제 2 설정값으로 정의될 수 있다. 적어도 하나의 프로세서는 클래스 i에 GT 데이터가 존재하는 복수의 제 2 데이터 샘플을 AI 모델에 적용하여 클 래스 i에 관한 복수의 제 2 예측 결과를 획득할 수 있다. 복수의 제 2 예측 결과 및 복수의 제 2 데이터 샘플의 GT 데이터에 기초하여 클래스 i와 대응되는 AI 모델의 정확도를 판단할 수 있다. 제 2 데이터 샘플은 병합 데이 터 세트에 포함될 수 있다.적어도 하나의 프로세서는 제 1 데이터 샘플을 포함하는 복수의 데이터 샘플에 대하여 AI 모델이 학습한 횟수에 기초하여 AI 모델의 학습 단계를 결정할 수 있다. 제 1 로스는 제 1 데이터 샘플의 예측 결과 및 제 1 데이터 샘플의 GT 데이터를 로스 함수에 적용하여 계산될 수 있다. 로스 함수는 크로스엔트로피 로스(cross-entropy loss), 힌지 로스 (hinge loss), MAE (mean absolute error), MSE (mean squared error), KLD 로스 (Kullback-Leibler divergence loss), 후버 로스 (Huber loss) 또는 RMSE (root mean squared error) 중 적어도 하나를 포함할 수 있다. 적어도 하나의 프로세서는 병합된 데이터 세트에 포함된 데이터 샘플에서 GT 데이터와 대응되는 GT 영역을 식별 할 수 있다. 적어도 하나의 프로세서는 GT 영역만을 포함하는 GT 데이터 샘플을 획득할 수 있다. 적어도 하나의 프로세서는 GT 데이터 샘플에 기초하여 AI 모델의 파라미터를 업데이트할 수 있다. 적어도 하나의 프로세서는 GT 영역을 제외한 데이터 샘플의 영역이 제 3 설정값으로 설정된 GT 데이터 샘플을 획득할 수 있다. AI모델은 분류(classification) 모델, 객체 검출 (object detection) 모델, 세그멘테이션(segmentation) 모델, 포즈 추정(pose estimation) 모델, HOI(Human Object Interaction) 모델 또는 VRD (visual relationship detection) 모델 중 적어도 하나를 포함할 수 있다. 상술한 본 개시의 구체적인 실시 예들에서, 개시에 포함되는 구성 요소는 제시된 구체적인 실시 예에 따라 단수 또는 복수로 표현되었다. 그러나, 단수 또는 복수의 표현은 설명의 편의를 위해 제시한 상황에 적합하게 선택된 것으로서, 본 개시가 단수 또는 복수의 구성 요소에 제한되는 것은 아니며, 복수로 표현된 구성 요소라 하더라 도 단수로 구성되거나, 단수로 표현된 구성 요소라 하더라도 복수로 구성될 수 있다. 이상에서 실시예들에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속한다.도면 도면1a 도면1b 도면2 도면3 도면4a 도면4b 도면5 도면6 도면7 도면8 도면9a 도면9b"}
{"patent_id": "10-2022-0169099", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a 및 도 1b는 일 실시예에 따른 소스 데이터 세트 및 병합 데이터 세트를 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 제 1 로스 및 제 2 로스를 판단하는 방법을 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 학습 진행 정도에 기초하여 로스 가중치를 결정하는 방법을 설명하기 위한 도면이다. 도 4a 및 도 4b는 일 실시예에 따른 GT 가공 데이터 샘플을 획득하는 방법을 설명하기 위한 도면이다. 도 5는 일 실시예 따른 AI 모델을 이용하여 포즈 추정(pose estimation) 태스크를 수행하는 방법에 관한 도면이 다. 도 6은 일 실시예 따른 AI 모델을 이용하여 세그멘테이션(segmentation) 태스크를 수행하는 방법에 관한 도면이 다. 도 7은 일 실시예에 따른 AI 모델을 이용하여 VRD(Visual relationship detection) 태스크를 수행하는 방법에 관한 도면이다. 도 8은 본 개시의 일 실시예에 따른 AI 모델을 훈련시키는 방법에 관한 흐름도이다. 도 9a 및 도 9b는 본 개시의 일 실시예에 따른 전자 장치에 관한 블록도이다."}
