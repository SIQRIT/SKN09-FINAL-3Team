{"patent_id": "10-2020-0056763", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0138439", "출원번호": "10-2020-0056763", "발명의 명칭": "실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템", "출원인": "부산대학교병원", "발명자": "박건형"}}
{"patent_id": "10-2020-0056763", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "특징 추출(feature extraction)을 수행하도록 안저사진이 입력되는 베이스모듈(100);상기 베이스모듈(100)의 출력에 두 개의 완전연결층(fully connected layer)이 병렬로 연결되는 브랜치모듈(200);상기 브랜치모듈(200)은,상기 안저사진의 품질을 추론하는 품질결정부(210); 및상기 안저사진에서 중심와 또는 시신경유두의 좌표를 추론하는 위치결정부(220);로 구성하되,상기 품질결정부(210) 및 위치결정부(220)는 상기 베이스모듈(100)의 평균 풀링(average pooling) 레이어 출력에 바로 연결되는 것을 특징으로 하는 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템."}
{"patent_id": "10-2020-0056763", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 브랜치모듈(200)은,시그모이드(sigmoid) 함수를 활성화 함수로 사용하는 것을 특징으로 하는 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템."}
{"patent_id": "10-2020-0056763", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 품질결정부(210)의 출력값(score)의 전체 합은 1.0이고,상기 위치결정부(220)의 출력값(score)은 각각 0~1.0 사이의 값인 것을 특징으로 하는 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템."}
{"patent_id": "10-2020-0056763", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,상기 품질결정부(210)는,[수학식 1]의 손실함수(loss function)에 의해 트레이닝 되는 것을 특징으로 하는 실시간 안저사진 품질 판독을위한 딥러닝 아키텍처 시스템 : [수학식 1](여기서, Ci는 실제 출력값(score)이고, Pi는 예상된 출력값(score)).공개특허 10-2021-0138439-3-청구항 5 제 1항에 있어서,상기 위치결정부(220)는,[수학식 2]의 손실함수(loss function)에 의해 트레이닝 되는 것을 특징으로 하는 실시간 안저사진 품질 판독을위한 딥러닝 아키텍처 시스템 : [수학식 2](여기서, px, py는 예상된 x, y좌표값이고, tx, ty는 실제 x, y 좌표값)."}
{"patent_id": "10-2020-0056763", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템에 관한 것으로, 더욱 상세하게는 안저 사 진 유무, 안저 사진의 품질 정보 및 안저 사진 내의 중요한 특징점인 시신경유두의 위치를 동시에 출력할 수 있 는 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템에 관한 것이다. (뒷면에 계속)"}
{"patent_id": "10-2020-0056763", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템에 관한 것으로, 더욱 상세하게는 안저 사 진 유무, 안저 사진의 품질 정보 및 안저 사진 내의 중요한 특징점인 시신경유두의 위치를 동시에 출력할 수 있 는 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템에 관한 것이다."}
{"patent_id": "10-2020-0056763", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "안저 사진기로 촬영을 할 때에는 사진이 의사가 판독할 수준의 충분한 화질을 갖추었는지에 대한 판단이 필요하 다. 또한, 대부분의 일반 안저 사진기는 기술적인 한계로 인해 전체 망막 중에서 극히 일부분만 촬영하게 되어 있는데, 이때 현재 촬영된 부분이 중심와와 시신경유두를 포함한 적절한 위치를 촬영하였는지도 판단하여야 한 다. 이러한 판단은 보통 숙련된 촬영 전문가에 의해 가능하지만, 만약 이것을 간단하면서도 빠르게 작동할 수 있는 딥러닝 인공지능에 의해 수행할 수 있다면 그 응용분야는 넓다. 특히, 이러한 인공지능 시스템을 안저 사진기 자체에 탑재하게 되면, 촬영 과정을 실시간으로 인공지능이 평가 하고 있다가 적절한 화질과 위치를 만족할 경우 자동으로 사진을 촬영하도록 할 수 있다. 이것은 상대적으로 까 다로운 안저사진 촬영 과정을 쉽고 편리하게 만들어줄 수 있다. 또한, 안저사진을 판독하는 대형 인공지능 시스템의 앞단에 사전 검열을 위한 시스템으로 사용할 경우, 입력된 안저사진을 미리 선별하여 화질이 도저히 판독을 하기에 불가능한 품질이거나, 적절한 위치에 촬영되지 않았다 면 판독을 거부하도록 하여 전체 판독 시스템이 과도한 부하가 걸리는 것을 방지하는데도 이용할 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 1020200005408 (2020.01.15.) “안저 이미지 관리 장치 및 안저 이미지의 품질 판단 방법”"}
{"patent_id": "10-2020-0056763", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기의 문제점을 해결하기 위해서 안출된 것으로서, 본 발명의 목적은 안저 사진이 의료진이 판독 가 능한 수준의 충분한 화질을 갖추었는지 딥러닝 알고리즘을 통해 수행할 수 있는 시스템을 제공하는 것이다. 또한, 본 발명의 목적은 일반 안저 사진기의 기술적인 한계로 인해 전체 망막 중 일부분만 촬영하는 경우가 있 어 촬영된 부분이 중심와와 시신경유두를 포함한 적절한 위치를 촬영하였는지 판단할 수 있는 딥러닝 알고리즘 시스템을 제공하는 것이다. 발명이 해결하고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또"}
{"patent_id": "10-2020-0056763", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0056763", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템은, 특징 추출(feature extraction)을 수행하도록 안저사진이 입력되는 베이스모듈; 상기 베이스모듈의 출력에 두 개의 완전연결층(fully connected layer)이 병렬로 연결되는 브랜치모듈 ; 상기 브랜치모듈은, 상기 안저사진의 품질을 추론하는 품질결정부; 및 상기 안저사진에서 중심와 또는 시신경유두의 좌표를 추론하는 위치결정부;로 구성하되, 상기 품질결정부 및 위치결정부는 상기 베이스모듈의 평균 풀링(average pooling) 레이어 출력 에 바로 연결되는 것을 특징으로 한다. 상기 브랜치모듈은 시그모이드(sigmoid) 함수를 활성화 함수로 사용하는 것을 특징으로 한다. 상기 품질결정부의 출력값(score)의 전체 합은 1.0이고, 상기 위치결정부의 출력값(score)은 각각 0~1.0 사이의 값인 것을 특징으로 한다. 상기 품질결정부는 [수학식 1]의 손실함수(loss function)에 의해 트레이닝 되는 것을 특징으로 한다. [수학식 1]"}
{"patent_id": "10-2020-0056763", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "(여기서, Ci는 정답(ground truth) 출력값(score)이고, Pi는 인공지능 출력값(score)). 상기 위치결정부는 [수학식 2]의 손실함수(loss function)에 의해 트레이닝 되는 것을 특징으로 한다. [수학식 2]"}
{"patent_id": "10-2020-0056763", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "(여기서, px, py는 인공지능이 예측한 x, y좌표값이고, tx, ty는 정답(ground truth) x, y 좌표값)."}
{"patent_id": "10-2020-0056763", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기 과제의 해결 수단에 의해, 본 발명은 안저 사진이 의료진이 판독 가능한 수준의 충분한 화질을 갖추었는지 딥러닝 알고리즘을 통해 수행할 수 있는 시스템을 제공할 수 있다. 또한, 본 발명은 일반 안저 사진기의 기술적인 한계로 인해 전체 망막 중 일부분만 촬영하는 경우가 있어 촬영 된 부분이 중심와와 시신경유두를 포함한 적절한 위치를 촬영하였는지 판단하는 딥러닝 알고리즘 시스템을 제공할 수 있다. 본 발명은 안저사진의 품질과 필요한 정보의 위치를 자동적으로 확인하는 딥러닝 알고리즘 시스템으로 본 발명 을 안저사진기에 적용하여 상대적으로 까다로운 안저사진 촬영 과정을 쉽고 편리하게 만들 수 있다. 본 발명을 안저사진을 판독하는 대형 인공지능 시스템의 앞단에 사전 검열을 위한 시스템으로 사용할 경우, 입 력된 안저사진을 미리 선별하여 전체 판독 시스템에 과도한 부하가 걸리지 않도록 방지할 수 있다. 본 발명은 안저사진 여부, 안저사진의 품질 정보 및 안저사진 내의 시신경유두 위치를 동시에 출력하면서도 간 단한 구조로 인해 핸드폰 수준의 하드웨어에서도 초당 수십장을 판독하는 것이 가능하다."}
{"patent_id": "10-2020-0056763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 발명에 대해 구체적으로 설명하기로 한다. 본 발명에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 발명의 전반 에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 “포함”한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 아래에서는 첨부한 도면을 참고하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다."}
{"patent_id": "10-2020-0056763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 발명에 대한 해결하고자 하는 과제, 과제의 해결 수단, 발명의 효과를 포함한 구체적인 사항들은 다음에 기 재할 실시 예 및 도면들에 포함되어 있다. 본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 이하, 첨부된 도면을 참조하여 본 발명을 보다 상세히 설명하기로 한다. 본 발명에 따른 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템은 안저사진의 품질정보와 시신경유 두 또는 중심와의 위치정보 두 가지를 동시에 곧바로(direct) 하나의 아키텍처에서 추론하는 알고리즘이다. 따 라서 이하 본 발명인 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템을 DirectNet으로 명명한다. 일반적인 합성곱신경망 아키텍처들은 크게 사진의 분류를 위한 분류(classify) 계열의 알고리즘과 사진 내에서 특정 물체의 위치를 찾는 객체 탐지(object detection) 계열의 알고리즘으로 나뉜다. 하지만 본 발명인 DirectNet은 상기 두 개의 역할을 하나의 아키텍처에서 곧바로(direct)로 출력하는 것이 큰 특징이라고 할 수 있다. 따라서 알고리즘 두 개를 하나로 압축하여 사용함으로써, 저사양의 하드웨어에서도 실시간으로 작동할 수 있게 된다. 그 구성은 도 1에 나타난 같이 크게 특징 추출(feature extraction)을 위한 베이스모듈 구조와 상기 베이 스모듈 뒤에 간단한 브랜치 구조를 연결한 브랜치모듈로 구성된다. 또한, 본 발명인 DirectNet의 전 체 구조를 도식화하여 도 2와 같이 나타내었다. 1) 베이스 모듈 먼저, 상기 베이스모듈은 특징 추출(feature extraction)을 수행하도록 안저사진이 입력된다. 상기 베이스 모듈은 MobileNet V1을 전신으로 한다. 즉, 상기 MobileNet V1의 원래 구조 전체는 도 3과 동일하며, 도 3에 도식화되어 있듯이 상기 MobileNet V1의 일부 구조는 본 발명인 DirectNet에서도 사용되었으며 이를 상기 베이스모듈이라 한다. 다만, 본 발명인 DirectNet은 상기 MobileNet V1에서 붉은색 점선으로 나타낸 구조를 새로운 구조로 대체되었으 며 이를 상기 브랜치모듈이라 한다. 상기 베이스모듈에 입력되는 안저사진의 입력 해상도는 상기 MobileNet V1의 입력 해상도인 224x224x3 (width x height x RGB)보다 다소 높은 250x250x3 (width x height x RGB)으로 설정한다. 이는 실험을 통하여 구해진 안저 사진을 처리하는 최적 해상도에 해당한다. 2). 브랜치 모듈 상기 브랜치모듈은 상기 베이스모듈의 출력에 두 개의 완전연결층(fully connected layer)이 병렬로 연결된다. 상기 브랜치모듈은 둘 다 시그모이드(sigmoid) 함수를 활성화 함수(activation function)로 사 용한다. 종래의 MobileNet V1과의 차이점은 품질추론을 위한 품질결정부(dense 1 layer, 210)과 좌표추론을 위한 위치결 정부(dense 2 layer, 220)이 병렬로 연결되었다는 점과, 상기 품질결정부(dense 1 layer, 210)과 상기 위치결 정부(dense 2 layer, 220)이 곧바로 상기 베이스모듈의 평균 풀링(average pooling) 레이어 출력에 바로 연결되어 있다는 것이다. 이것은 원본구조에서 FC layer를 제거한 것이며, 이로 인해 약 100만 번의 부동소수점 연산이 생략되어 속도를 빠르게 할 수 있게 된다. 또한 품질과 좌표를 동시에 하나의 네트워크에서 얻을 수 있 다는 장점이 있다. 상기 브랜치모듈은, 도 1에 나타난 바와 같이, 품질결정부 및 위치결정부로 구성된다. 상기 품질결정부는 상기 안저사진의 품질을 추론한다. 상기 위치결정부는 상기 안저사진에서 중심와 또는 시신경유두의 좌표를 추 론한다. [표 1]은 본 발명인 상기 품질결정부(dense 1 layer, 210)과 상기 위치결정부(dense 2 layer, 220)의 입력 (input) 및 출력(output) 구조를 나타내었다. 표 1 Activation function Input Output 품질결정부 (dense 1 layer)Sigmoid 1x1x1024 11위치결정부 (dense 2 layer)Sigmoid 1x1x1024 2 3) 브랜치 모듈 출력 구조 상기 브랜치 모듈의 최종 출력은 13(11+2)개로, 상기 품질결정부(dense 1 layer, 210)의 출력 11개와 상기 위치 결정부(dense 2 layer, 220)의 출력 2개로 구성된다. 먼저, 상기 품질결정부(dense 1 layer, 210) 구조는 도 4에 나타난 바와 같이, 컬러사진결정부, 흑백사진 결정부 및 안저사진결정부로 구성된다. 상기 컬러사진결정부는 컬러 안저사진에 대한 5단계의 품질 출력값(score)을 출력한다. 상기 컬러사진결정 부는 매우좋음, 좋음, 보통, 나쁨, 매우 나쁨으로 상기 안저사진의 품질을 출력한다. 상기 흑백사진결정부는 흑백 안저사진에 대한 5단계의 품질 출력값(score)을 출력한다. 상기 흑백사진결정 부는 매우좋음, 좋음, 보통, 나쁨, 매우 나쁨으로 상기 안저사진의 품질을 출력한다. 상기 안저사진결정부 는 안저사진 여부를 출력한다. 즉 안저사진일 경우 0에 가까운 값을, 안자사진이 아닐 경우 1에 가까운 값 을 출력한다. 일실시예로, 도 4에서 상기 품질결정부(dense 1 layer, 210)는 “좋은 품질로 촬영된 컬러 안저사진”이 입력되 었을 경우, 상기 컬러사진결정부는 0.31 / 0.11 / 0.12 / 0.12 / 0.05를 출력하고, 흑백사진결정부 는 0.05 / 0.12 / 0.03 / 0.04 / 0.04를 출력하며, 상기 안저사진결정부는 0.05를 출력하게 된다. 이것에 대한 해석을 하자면, 출력 값(score) 중에서 최대치는 상기 컬러사진결정부의 0.31 (매우좋음)이며, 따라 서 인공지능은 입력된 사진이 “컬러 안저사진 매우 좋은 품질” 이라고 판단하게 된다. 또한 상기 안저사진결 정부는 0.05를 출력하여 0.31에 비해 매우 작은 값이며, 따라서 안저사진이 아닐 가능성이 낮은 것으로 판 단하게 된다. 만약 고양이 사진과 같이 안저사진이 아닌 이미지가 입력되었을 경우, 반대로 상기 안저사진결정 부의 출력이 품질결정부의 11개 값(score) 중 가장 높은 값을 출력하게 되며, 이것이 안저사진이 아 니라고 결론을 내리게 된다. 다음으로, 상기 위치결정부(dense 2 layer, 220) 구조는 도 5에 나타난 바와 같이, 제1좌표부 및 제2좌표 부로 구성된다. 상기 위치결정부(dense 2 layer, 220)은 시신경유두 또는 중심와의 좌표를 결정하며 제1좌표부 및 제2좌표 부는 상기 시신경유두 또는 중심와의 x 및 y 좌푯값을 나타낸다. 상기 품질결정부(dense 1 layer, 210)과 상기 위치결정부(dense 2 layer, 220) 출력값에서 상기 두 레이어의 가장 큰 차이점은 상기 품질결정부(dense 1 layer, 210)의 출력은 softmax로 묶여있어 전체 스코어 합이 1.0인 반면, 상기 위치결정부(dense 2 layer, 220)은 각각의 시그모이드(sigmoid) 출력을 그대로 받기 때문에 출력값 이 각각 0~1.0 사이의 값이 된다는 것이다. 이렇게 하는 이유는 상기 품질결정부(dense 1 layer, 210)의 출력의 경우, 상기 안저사진에 대한 평가는 11개의 카테고리 중 1개에만 귀속될 수 있기 때문이며, 상기 위치결정부(dense 2 layer, 220)의 경우에는 각각이 X, Y 좌표를 의미하므로 각각 0~1.0 사이의 값을 가지도록 해야 하기 때문이다. 4) 모델 학습 방법과 손실함수(loss function) 설계 본 발명인 DirectNet을 이용한 딥러닝 모델 학습을 위해, 도 6에 나타난 바와 같이, 시신경유두 위치정보와 5가 지 품질정보로 분류된 안저사진 5만장과 안저사진이 아닌 사진세트 5만장을 포함하여 약 10만장의 이미지 데이 터를 확보하여 활용하였다. 이때 5가지 품질정보로 분류된 컬러 안저사진은 다시 내부적으로 흑백변환을 하여 5 개의 컬러품질 + 5개의 흑백품질을 합하여 총 10개의 품질 정보를 생성하여 트레이닝 한다. 딥러닝 학습 트레이닝을 위한 손실함수(loss function)의 설계는 도 7에 나타난 바와 같다. 상기 품질결정부 (dense 1 layer, 210)과 상기 위치결정부(dense 2 layer, 220)에 대해 각각 다른 손실함수(loss function)를 적용하여 합산한 값을 사용한다. Sigmoid 출력에 Softmax 연산을 처리해 출력된 안저사진의 품질 점수는 Categorical cross entropy를 사용하고, 안저사진의 시신경유두 좌표는 mean squared error (MSE)를 사용하여 계산한 각각의 손실(loss)을 합산한 값을 전체 손실(loss)값으로 계산하여 트레이닝 한다. 상기 품질결정부(dense 1 layer, 210)은 [수학식 1]의 손실함수(loss1)에 의해 트레이닝 되는 것을 특징으로 한 다. 수학식 1"}
{"patent_id": "10-2020-0056763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "(여기서, Ci는 정답(ground truth) 출력값(score)이고, Pi는 인공지능 출력값(score)). 상기 위치결정부(dense 2 layer, 220)은 [수학식 2]의 손실함수(loss2)에 의해 트레이닝 되는 것을 특징으로 한 다. 수학식 2"}
{"patent_id": "10-2020-0056763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "(여기서, px, py는 인공지능이 예측한 x, y좌표값이고, tx, ty는 정답(ground truth) x, y 좌표값). 5) 실제 코드 및 테스트 결과 도 8은 본 발명인 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템(DirctNet)의 구조에서 사용된 샘 플 코드이다. 도 9는 본 발명인 본 발명인 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템의 구조를 핸드폰에서 실행한 결과를 나타낸 사진이다. 흰색점이 시신경유두의 위치를 나타낸다."}
{"patent_id": "10-2020-0056763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "상기 과제의 해결 수단에 의해, 본 발명은 안저 사진이 의료진이 판독 가능한 수준의 충분한 화질을 갖추었는지 딥러닝 알고리즘을 통해 수행할 수 있는 시스템을 제공할 수 있다. 또한, 본 발명은 일반 안저 사진기의 기술적인 한계로 인해 전체 망막 중 일부분만 촬영하는 경우가 있어 촬영 된 부분이 중심와와 시신경유두를 포함한 적절한 위치를 촬영하였는지 판단하는 딥러닝 알고리즘 시스템을 제공 할 수 있다. 본 발명은 안저사진의 품질과 필요한 정보의 위치를 자동적으로 확인하는 딥러닝 알고리즘 시스템으로 본 발명 을 안저사진기에 적용하여 상대적으로 까다로운 안저사진 촬영 과정을 쉽고 편리하게 만들 수 있다. 본 발명을 안저사진을 판독하는 대형 인공지능 시스템의 앞단에 사전 검열을 위한 시스템으로 사용할 경우, 입 력된 안저사진을 미리 선별하여 전체 판독 시스템에 과도한 부하가 걸리지 않도록 방지할 수 있다. 본 발명은 안저사진 여부, 안저사진의 품질 정보 및 안저사진 내의 시신경유두 위치를 동시에 출력하면서도 간 단한 구조로 인해 핸드폰 수준의 하드웨어에서도 초당 수십장을 판독하는 것이 가능하다."}
{"patent_id": "10-2020-0056763", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이와 같이, 상술한 본 발명의 기술적 구성은 본 발명이 속하는 기술분야의 당업자가 본 발명의 그 기술적 사상 이나 필수적 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해되어야 하고, 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타나며, 특허청구범위의 의 미 및 범위 그리고 그 등가 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2020-0056763", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명인 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템의 구조를 나타내는 구조도이다. 도 2는 본 발명인 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템의 전체 구조를 레이어(layer), 필 터(filters), 입력(input) 및 출력(output) 해상도를 포함하는 전체 구조를 도식화하여 나타내었다. 도 3은 종래의 MobileNet 기본 구조를 나타내어 도식화한 것으로, 종래 MobileNet 기본 구조에서 변형된 구조 (붉은색 점선)를 표기하여 나타내었다. 도 4는 품질결정부의 출력 구조를 나타낸 구조도이다. 도 5는 위치결정부의 출력 구조를 나타낸 구조도이다. 도 6은 본 발명에서 딥러닝 기반 모델 학습을 위해 안저사진과 안저사진이 아닌 데이터를 확보하여 제공하는 사 진세트이다. 도 7은 본 발명인 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템의 구조의 출력 및 손실함수(loss function)를 나타낸 모식도이다. 도 8은 본 발명인 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템의 구조에서 사용된 샘플 코드이다. 도 9는 본 발명인 본 발명인 실시간 안저사진 품질 판독을 위한 딥러닝 아키텍처 시스템의 구조를 핸드폰에서 실행한 결과를 나타낸 사진이다."}
