{"patent_id": "10-2016-0020009", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2017-0098089", "출원번호": "10-2016-0020009", "발명의 명칭": "전자 장치 및 그의 동작 방법", "출원인": "삼성전자주식회사", "발명자": "이우용"}}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자장치에 있어서,카메라 모듈;메모리 모듈; 및카메라 모듈 및 메모리 모듈과 기능적으로 연결되는 프로세서를 포함하며,상기 프로세서는 상기 카메라 모듈을 통해 이미지 데이터를 획득하고;상기 획득되는 이미지 데이터에 기반하여 거리 정보를 추출하며; 상기 추출된 거리 정보에 기반하여 피사체의 이미지 처리 기법을 결정하고;상기 결정된 이미지 처리 기법을 상기 획득된 이미지에 적용하며; 및상기 적용된 이미지를 표시하는 장치."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 카메라 모듈은 이미지 데이터 및 상기 전자장치와 피사체 간의 거리 정보를 추출하기 위한 신호를 생성하는 이미지 센서를 포함하는 장치."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 카메라 모듈의 이미지 센서는 단위 픽셀 어레이를 포함하며, 상기 단위 픽셀은 적어도 두개의 서브 픽셀들을 포함하고,상기 프로세서는 상기 단위 픽셀의 서브 픽셀 신호들의 위상차에 기반하여 거리 정보를 추출하기 위한 신호를생성하고, 상기 서브 픽셀들의 신호들을 평균화하여 이미지 데이터를 생성하는 장치."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 카메라 모듈의 이미지 센서는 상면 위상차 센서 및 픽셀 센서들을 포함하며, 상기 프로세서는 상기 상면 위상차 센서 신호에 기반하여 거리 정보를 추출하기 위한 신호를 생성하고, 상기 픽셀 센서들의 신호들에 기반하여 이미지 데이터를 생성하는 장치."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 프로세서는공개특허 10-2017-0098089-3-상기 이미지 데이터에 기반하여 거리 정보를 추출하며, 상기 거리 정보에 기반하여 피사체를 인식하는 장치."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 이미지 처리 기법은 이미지 필터이며,상기 프로세서는상기 인식된 피사체의 구성 정보를 추출하며, 추출된 구성 정보에 기반하여 이미지 필터를 결정하고, 상기 결정된 이미지 필터를 상기 획득된 이미지 데이터에 적용하여 새로운 이미지를 생성하는 장치."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 프로세서는상기 이미지 처리 기법을 결정하는 동안에 프리뷰 이미지를 표시하며,상기 프리뷰 이미지는 블러 및/또는 노출 변경 등에 기반하는 동적 필터가 적용된 프리뷰 이미지인 장치."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서, 전자장치의 자세를 감지하는 센서 모듈을 더 포함하며,상기 프로세서는상기 프리뷰 이미지로 표시되는 새로운 이미지에 상기 전자장치의 자세 정보를 표시하는 장치."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서, 상기 프로세서는상기 구성 정보에서 리니어 필터, 방사형 필터, 라이팅 필터, 매크로 필터, 셀렉티브 포커스 필터들 중에 적어도 하나의 필터를 선택하여 이미지에 적용하는 장치."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 프로세서는 상기 생성되는 새로운 이미지는 이미지 필터의 포커스를 기준으로 주변 영역이 블러 처리되는 이미지인 장치."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제6항에 있어서, 상기 이미지 필터는 음식 이미지에 적용되는 이미지 필터인 장치."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제6항에 있어서, 상기 프로세서는공개특허 10-2017-0098089-4-캡쳐 요구시 상기 새로운 이미지를 상기 메모리 모듈에 저장하는 장치."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서, 상기 카메라 모듈은 2차원 이미지 데이터를 생성하는 이미지 센서를 포함하며,상기 프로세서는, 상기 이미지 데이터에 기반하여 피사체의 윤곽선 정보를 추출하고, 상기 윤곽선 정보에 기반하여 피사체의 구성 정보를 인식하며, 상기 구성 정보에 기반하여 결정된 이미지 필터를 상기 이미지 데이터에적용하는 장치."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "전자장치의 동작 방법에 있어서,이미지 센서를 통해 이미지 데이터를 획득하는 동작;상기 획득되는 이미지 데이터에서 거리 정보를 를 추출하는 동작; 상기 추출된 거리 정보에 기반하여 피사체의 이미지 처리 기법을 결정하는 동작; 상기 결정된 이미지 처리 기법을 상기 획득된 이미지에 적용하여 새로운 이미지를 생성하는 동작; 및상기 새로운 이미지를 이미지를 표시하는 동작을 포함하는 방법."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 이미지 데이터를 획득하는 동작은이미지 데이터를 획득하는 동작; 및 상기 전자장치와 피사체 간의 거리 정보를 추출하기 위한 신호를 획득하는 동작을 포함하는 방법."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 이미지 처리 기법을 결정하는 동작은상기 뎁스 맵에 기반하여 피사체의 구성 정보를 인식하는 동작; 및 상기 구성 정보에 기반하여 이미지를 처리하기 위한 이미지 필터를 설정하는 동작을 포함하는 방법."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,상기 이미지 처리 기법을 결정하는 동작은상기 이미지 데이터의 윤곽선에 기반하여 구성 정보를 인식하는 동작; 및 상기 구성 정보에 기반하여 이미지를 처리하기 위한 이미지 필터를 설정하는 동작을 포함하는 방법.공개특허 10-2017-0098089-5-청구항 18 제16항에 있어서,상기 이미지 필터를 설정하는 동작은인식된 피사체의 구성 정보에 기반하여 리니어 필터, 방사형 필터, 라이팅 필터, 매크로 필터, 셀렉티브 포커스필터들 중에 적어도 하나의 필터를 설정하는 방법."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제14항에 있어서,상기 새로운 이미지를 생성하는 동작은상기 이미지 필터의 포커스를 기준으로 주변 영역이 블러 처리되는 이미지를 생성하는 방법."}
{"patent_id": "10-2016-0020009", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제14항에 있어서,상기 이미지 처리 기법을 결정하는 동작은, 프리뷰 이미지를 표시하는 동작을 더 포함하며,상기 프리뷰 이미지를 표시하는 동작은,블러 및/또는 노출 변경 등에 기반하는 동적 필터가 적용된 프리뷰 이미지를 표시하는 방법."}
{"patent_id": "10-2016-0020009", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다양한 실시예들에 따른 전자 장치는, 카메라 모듈; 메모리 모듈; 및 카메라 모듈 및 메모리 모듈과 기능적으로 연결되는 프로세서를 포함할 수 있다. 상기 프로세서는, 상기 카메라 모듈을 통해 이미지를 획득하고; 상기 획득 되는 이미지에 기반하여 거리 정보를 추출하며; 상기 추출된 거리 정보에 기반하여 피사체의 이미지 처리 기법을 결정하고; 상기 결정된 이미지 처리 기법을 상기 획득된 이미지에 적용하며; 및 상기 적용된 이미지를 표시할 수 있다. 그 밖의 다양한 실시예가 가능하다."}
{"patent_id": "10-2016-0020009", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 다양한 실시예들은 이미지를 처리할 수 있는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2016-0020009", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자장치는 디지털 기술의 발달과 함께 이동통신 단말기, 스마트 폰(smart phone), 태블릿(tablet) PC(Personal Computer), PDA(Personal Digital Assistant), 전자수첩, 노트북(notebook) 또는 웨어러블 디바이스(wearable device) 등과 같은 다양한 유형으로 사용될 수 있다. 전자 장치는, 다른 장치들의 기능까지 아우르는 모바일 컨 버전스(mobile convergence) 단계에 이르고 있다. 전자장치는 카메라 모듈을 포함할 수 있다. 전자장치는 카메 라 모듈을 통해 피사체 이미지를 촬영할 수 있으며, 촬영된 이미지를 저장하거나 외부의 다른 전자장치로 전송 할 수 있다."}
{"patent_id": "10-2016-0020009", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "전자장치는 촬영되는 이미지를 처리할 때 메뉴 등을 통해 미리 준비된 이미지 처리 기능을 설정하고, 설정된 이 미지 처리 기능을 적용하여 카메라 모듈을 통해 획득되는 이미지를 처리할 수 있었다. 예를들면, 이미지 필터를 사용하는 경우 사용자는 미리 이미지 필터를 설정할 수 있으며, 전자장치는 카메라 모듈을 통해 획득되는 이미 지에 설정된 이미지 필터 기능을 적용하여 이미지를 처리할 수 있었다. 본 발명의 다양한 실시예에 따른 전자장치는 획득되는 이미지 데이터에서거리 정보를 추출하고, 추출된 거리정 보에 기반하여 이미지 처리 기법을 자동으로 결정하고, 결정된 이미지 처리 기법을 획득된 이미지에 적용하여 새로운 이미지를 생성할 수 있는 장치 및 방법을 제공할 수 있다. 본 발명의 다양한 실시예에 따른 전자장치는 이미지 센서를 통해 획득되는 이미지 데이터에서 거리 정보를 추출 하고, 추출된 거리 정보에 기반하여 이미지 필터를 자동으로 결정하고, 결정된 이미지 필터를 획득된 이미지에 적용하여 새로운 이미지를 생성할 수 있는 장치 및 방법을 제공할 수 있다. 본 발명의 다양한 실시예에 따른 전자장치는 이미지 센서를 통해 생성되는 이미지 데이터의 윤곽선을 추출하여 피사체의 구성 정보를 인식하고, 구성 정보에 기반하여 설정되는 이미지 필터를 이미지 데이터에 적용하여 새로 운 이미지를 생성할 수 있는 장치 및 방법을 제공할 수 있다."}
{"patent_id": "10-2016-0020009", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 다양한 실시예에 따른 전자장치는, 카메라 모듈; 메모리 모듈; 및 카메라 모듈 및 메모리 모듈과 기 능적으로 연결되는 프로세서를 포함할 수 있다. 상기 프로세서는, 상기 카메라 모듈을 통해 이미지 데이터를 획 득하고; 상기 획득되는 이미지 데이터에 기반하여 거리 정보를 추출하며; 상기 추출된 거리 정보에 기반하여 피 사체의 이미지 처리 기법을 결정하고; 상기 결정된 이미지 처리 기법을 상기 획득된 이미지에 적용하며; 및 상 기 적용된 이미지를 표시할 수 있다. 본 발명의 다양한 실시예에 따른 전자장치의 동작 방법은, 이미지 센서를 통해 이미지 데이터를 획득하는 동작; 상기 획득되는 이미지 데이터에서 거리 정보를 추출하는 동작; 상기 추출된 거리 정보에 기반하여 피사체의 이 미지 처리 기법을 결정하는 동작; 상기 결정된 이미지 처리 기법을 상기 획득된 이미지에 적용하여 새로운 이미 지를 생성하는 동작; 및 상기 새로운 이미지를 표시하는 동작을 포함할 수 있다."}
{"patent_id": "10-2016-0020009", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "다양한 실시예들에 따르면, 이미지 장치를 포함하는 전자장치는 획득되는 이미지를 분석하여 자동으로 이미지 처리 기법을 설정하고, 획득되는 이미지에 설정된 이미지 처리 기법을 적용하여 새로운 이미지를 생성할 수 있 다. 전자장치는 이미지 처리 기법을 적용하는 촬영 동작(예를들면, 음식 촬영)이 요구되면, 이미지 장치를 통해 획득되는 이미지 데이터에서 주 피사체의 구성 정보를 추출할 수 있으며, 추출된 구성 정보에 기반하여 적용할 이미지 필터를 자동으로 설정한 후 획득된 이미지에 적용하여 주 피사체가 강조되는 이미지를 표시할 수 있다."}
{"patent_id": "10-2016-0020009", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 문서의 다양한 실시예들이 첨부된 도면을 참조하여 기재된다. 실시예 및 이에 사용된 용어들은 본 문 서에 기재된 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 해당 실시예의 다양한 변경, 균등물, 및 /또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사 한 참조 부호가 사용될 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 본 문서에서, \"A 또는 B\" 또는 \"A 및/또는 B 중 적어도 하나\" 등의 표현은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. \"제 1,\" \"제 2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 해당 구성요소들을, 순서 또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요 소들을 한정하지 않는다. 어떤(예: 제 1) 구성요소가 다른(예: 제 2) 구성요소에 \"(기능적으로 또는 통신적으로) 연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소 에 직접적으로 연결되거나, 다른 구성요소(예: 제 3 구성요소)를 통하여 연결될 수 있다. 본 문서에서, \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, 하드웨어적 또는 소프 트웨어적으로 \"~에 적합한,\" \"~하는 능력을 가지는,\" \"~하도록 변경된,\" \"~하도록 만들어진,\" \"~를 할 수 있 는,\" 또는 \"~하도록 설계된\"과 상호 호환적으로(interchangeably) 사용될 수 있다. 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로 세서(예: 임베디드 프로세서), 또는 메모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(예: CPU 또는 application processor)를 의미할 수 있다. 본 문서의 다양한 실시예들에 따른 전자 장치는, 예를 들면, 스마트폰, 태블릿 PC, 이동 전화기, 영상 전화기, 전자책 리더기, 데스크탑 PC, 랩탑 PC, 넷북 컴퓨터, 워크스테이션, 서버, PDA, PMP(portable multimedia player), MP3 플레이어, 의료기기, 카메라, 또는 웨어러블 장치 중 적어도 하나를 포함할 수 있다. 웨어러블 장 치는 액세서리형(예: 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head- mounted-device(HMD)), 직물 또는 의류 일체형(예: 전자 의복), 신체 부착형(예: 스킨 패드 또는 문신), 또는 생체 이식형 회로 중 적어도 하나를 포함할 수 있다. 어떤 실시예들에서, 전자 장치는, 예를 들면, 텔레비전, DVD(digital video disk) 플레이어, 오디오, 냉장고, 에어컨, 청소기, 오븐, 전자레인지, 세탁기, 공기 청정기, 셋톱 박스, 홈 오토매이션 컨트롤 패널, 보안 컨트롤 패널, 미디어 박스(예: 삼성 HomeSyncTM, 애플TVTM, 또는 구글 TVTM), 게임 콘솔(예: XboxTM, PlayStationTM), 전자 사전, 전자 키, 캠코더, 또는 전자 액자 중 적어도 하나를 포함할 수 있다. 다른 실시예에서, 전자 장치는, 각종 의료기기(예: 각종 휴대용 의료측정기기(혈당 측정기, 심박 측정기, 혈압 측정기, 또는 체온 측정기 등), MRA(magnetic resonance angiography), MRI(magnetic resonance imaging), CT(computed tomography), 촬영기, 또는 초음파기 등), 네비게이션 장치, 위성 항법 시스템(GNSS(global navigation satellite system)), EDR(event data recorder), FDR(flight data recorder), 자동차 인포테인먼 트 장치, 선박용 전자 장비(예: 선박용 항법 장치, 자이로 콤파스 등), 항공 전자기기(avionics), 보안 기기, 차량용 헤드 유닛(head unit), 산업용 또는 가정용 로봇, 드론(drone), 금융 기관의 ATM, 상점의 POS(point of sales), 또는 사물 인터넷 장치 (예: 전구, 각종 센서, 스프링클러 장치, 화재 경보기, 온도조절기, 가로등, 토 스터, 운동기구, 온수탱크, 히터, 보일러 등) 중 적어도 하나를 포함할 수 있다. 어떤 실시예에 따르면, 전자 장치는 가구, 건물/구조물 또는 자동차의 일부, 전자 보드(electronic board), 전자 사인 수신 장치(electronic signature receiving device), 프로젝터, 또는 각종 계측 기기(예: 수도, 전기, 가스, 또는 전파 계측 기기 등) 중 적어도 하나를 포함할 수 있다. 다양한 실시예에서, 전자 장치는 플렉서블하거나, 또는 전술한 다양한 장치들 중 둘 이상의 조합일 수 있다. 본 문서의 실시예에 따른 전자 장치는 전술한 기기들에 한정되지 않는다. 본 문서에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전 자 장치)를 지칭할 수 있다. 도 1을 참조하여, 다양한 실시예에서의, 네트워크 환경 내의 전자 장치가 기재된다. 전자 장치 는 버스, 프로세서, 메모리, 입출력 인터페이스, 디스플레이, 및 통신 인터페이스 를 포함할 수 있다. 어떤 실시예에서는, 전자 장치는, 구성요소들 중 적어도 하나를 생략하거나 다른구성요소를 추가적으로 구비할 수 있다. 버스는 구성요소들(110-170)을 서로 연결하고, 구성요소들 간의 통신(예: 제어 메시지 또는 데이터)을 전달하는 회로를 포함할 수 있다. 프로세서는, 중앙처리장치, 어플 리케이션 프로세서, 또는 커뮤니케이션 프로세서(communication processor(CP)) 중 하나 또는 그 이상을 포함할 수 있다. 프로세서는, 예를 들면, 전자 장치의 적어도 하나의 다른 구성요소들의 제어 및/또는 통신 에 관한 연산이나 데이터 처리를 실행할 수 있다. 메모리는, 휘발성 및/또는 비휘발성 메모리를 포함할 수 있다. 메모리는, 예를 들면, 전자 장치(10 1)의 적어도 하나의 다른 구성요소에 관계된 명령 또는 데이터를 저장할 수 있다. 한 실시예에 따르면, 메모리 는 소프트웨어 및/또는 프로그램을 저장할 수 있다. 프로그램은, 예를 들면, 커널, 미들웨 어, 어플리케이션 프로그래밍 인터페이스(API), 및/또는 어플리케이션 프로그램(또는 \"어플리케이 션\") 등을 포함할 수 있다. 커널, 미들웨어, 또는 API의 적어도 일부는, 운영 시스템으로 지칭될 수 있다. 커널은, 예를 들면, 다른 프로그램들(예: 미들웨어, API, 또는 어플리케이션 프로그램)에 구현된 동작 또는 기능을 실행하는 데 사용되는 시스템 리소스들(예: 버스, 프로세서 , 또는 메모리 등)을 제어 또는 관리할 수 있다. 또한, 커널은 미들웨어, API, 또는 어플리케이션 프로그램에서 전자 장치의 개별 구성요소에 접근함으로써, 시스템 리소스들을 제어 또 는 관리할 수 있는 인터페이스를 제공할 수 있다. 미들웨어는, 예를 들면, API 또는 어플리케이션 프로그램이 커널과 통신하여 데이터를 주 고받을 수 있도록 중개 역할을 수행할 수 있다. 또한, 미들웨어는 어플리케이션 프로그램으로부터 수 신된 하나 이상의 작업 요청들을 우선 순위에 따라 처리할 수 있다. 예를 들면, 미들웨어는 어플리케이션 프로그램 중 적어도 하나에 전자 장치의 시스템 리소스(예: 버스, 프로세서, 또는 메모리 등)를 사용할 수 있는 우선 순위를 부여하고, 상기 하나 이상의 작업 요청들을 처리할 수 있다. API(14 5)는 어플리케이션이 커널 또는 미들웨어에서 제공되는 기능을 제어하기 위한 인터페이스로, 예 를 들면, 파일 제어, 창 제어, 영상 처리, 또는 문자 제어 등을 위한 적어도 하나의 인터페이스 또는 함수(예: 명령어)를 포함할 수 있다. 입출력 인터페이스는, 예를 들면, 사용자 또는 다른 외부 기기로부터 입력된 명령 또는 데이터를 전자 장치의 다른 구성요소(들)에 전달하거나, 또는 전자 장치의 다른 구성요소 (들)로부터 수신된 명령 또는 데이터를 사용자 또는 다른 외부 기기로 출력할 수 있다. 디스플레이는, 예를 들면, 액정 디스플레이(LCD), 발광 다이오드(LED) 디스플레이, 유기 발광 다이오드 (OLED) 디스플레이, 또는 마이크로 전자기계 시스템 (MEMS) 디스플레이, 또는 전자종이(electronic paper) 디스 플레이를 포함할 수 있다. 디스플레이는, 예를 들면, 사용자에게 각종 콘텐츠(예: 텍스트, 이미지, 비디오, 아이콘, 및/또는 심볼 등)을 표시할 수 있다. 디스플레이는, 터치 스크린을 포함할 수 있으며, 예 를 들면, 전자 펜 또는 사용자의 신체의 일부를 이용한 터치, 제스쳐, 근접, 또는 호버링 입력을 수신할 수 있 다. 통신 인터페이스는, 예를 들면, 전자 장치와 외부 장치(예: 제 1 외부 전자 장치, 제 2 외 부 전자 장치, 또는 서버) 간의 통신을 설정할 수 있다. 예를 들면, 통신 인터페이스는 무선 통 신 또는 유선 통신을 통해서 네트워크에 연결되어 외부 장치(예: 제 2 외부 전자 장치 또는 서버 )와 통신할 수 있다. 무선 통신은, 예를 들면, LTE, LTE-A(LTE Advance), CDMA(code division multiple access), WCDMA(wideband CDMA), UMTS(universal mobile telecommunications system), WiBro(Wireless Broadband), 또는 GSM(Global System for Mobile Communications) 등 중 적어도 하나를 사용하는 셀룰러 통신을 포함할 수 있다. 한 실시예 에 따르면, 무선 통신은, 예를 들면, WiFi(wireless fidelity), 블루투스, 블루투스 저전력(BLE), 지그비 (Zigbee), NFC(near field communication), 자력 시큐어 트랜스미션(Magnetic Secure Transmission), 라디오 프리퀀시(RF), 또는 보디 에어리어 네트워크(BAN) 중 적어도 하나를 포함할 수 있다. 한 실시예에 따르면, 무선 통신은 GNSS를 포함할 수 있다. GNSS는, 예를 들면, GPS(Global Positioning System), Glonass(Global Navigation Satellite System), Beidou Navigation Satellite System(이하 “Beidou”) 또는 Galileo, the European global satellite-based navigation system일 수 있다. 이하, 본 문서에서는, “GPS”는 “GNSS”와 상호 호환적으로 사용될 수 있다. 유선 통신은, 예를 들면, USB(universal serial bus), HDMI(high definition multimedia interface), RS-232(recommended standard232), 전력선 통신, 또는 POTS(plain old telephone service) 등 중 적어도 하나를 포함할 수 있다. 네트워크는 텔레커뮤니케이션 네트워크, 예를 들면, 컴퓨 터 네트워크(예: LAN 또는 WAN), 인터넷, 또는 텔레폰 네트워크 중 적어도 하나를 포함할 수 있다. 제 1 및 제 2 외부 전자 장치(102, 104) 각각은 전자 장치와 동일한 또는 다른 종류의 장치일 수 있다. 다 양한 실시예에 따르면, 전자 장치에서 실행되는 동작들의 전부 또는 일부는 다른 하나 또는 복수의 전자장치(예: 전자 장치(102,104), 또는 서버에서 실행될 수 있다. 한 실시예에 따르면, 전자 장치가 어 떤 기능이나 서비스를 자동으로 또는 요청에 의하여 수행해야 할 경우에, 전자 장치는 기능 또는 서비스를 자체적으로 실행시키는 대신에 또는 추가적으로, 그와 연관된 적어도 일부 기능을 다른 장치(예: 전자 장치 (102, 104), 또는 서버)에게 요청할 수 있다. 다른 전자 장치(예: 전자 장치(102, 104), 또는 서버(10 6))는 요청된 기능 또는 추가 기능을 실행하고, 그 결과를 전자 장치로 전달할 수 있다. 전자 장치는 수신된 결과를 그대로 또는 추가적으로 처리하여 요청된 기능이나 서비스를 제공할 수 있다. 이를 위하여, 예를 들면, 클라우드 컴퓨팅, 분산 컴퓨팅, 또는 클라이언트-서버 컴퓨팅 기술이 이용될 수 있다. 도 2는 다양한 실시예에 따른 전자 장치의 블록도이다. 전자 장치는, 예를 들면, 도 1에 도시된 전자 장치의 전체 또는 일부를 포함할 수 있다. 전자 장치는 하나 이상의 프로세서(예: AP), 통신 모 듈, (가입자 식별 모듈, 메모리, 센서 모듈, 입력 장치, 디스플레이, 인터페이 스, 오디오 모듈, 카메라 모듈, 전력 관리 모듈, 배터리, 인디케이터, 및 모터 를 포함할 수 있다. 프로세서는, 예를 들면, 운영 체제 또는 응용 프로그램을 구동하여 프로세서 에 연결된 다수의 하드웨어 또는 소프트웨어 구성요소들을 제어할 수 있고, 각종 데이터 처리 및 연산을 수행할 수 있다. 프로세서는, 예를 들면, SoC(system on chip) 로 구현될 수 있다. 한 실시예에 따르면, 프로세서는 GPU(graphic processing unit) 및/또는 이미지 신호 프로세서를 더 포함할 수 있다. 프로세서 는 도 2에 도시된 구성요소들 중 적어도 일부(예: 셀룰러 모듈)를 포함할 수도 있다. 프로세서 는 다른 구성요소들(예: 비휘발성 메모리) 중 적어도 하나로부터 수신된 명령 또는 데이터를 휘발성 메모리에 로드)하여 처리하고, 결과 데이터를 비휘발성 메모리에 저장할 수 있다. 통신 모듈(예: 통신 인터페이스)와 동일 또는 유사한 구성을 가질 수 있다. 통신 모듈은, 예를 들면, 셀룰러 모듈, WiFi 모듈, 블루투스 모듈, GNSS 모듈, NFC 모듈 및 RF 모듈 를 포함할 수 있다. 셀룰러 모듈은, 예를 들면, 통신망을 통해서 음성 통화, 영상 통화, 문자 서비스, 또는 인터넷 서비스 등을 제공할 수 있다. 한 실시예에 따르면, 셀룰러 모듈은 가입자 식별 모듈 (예: SIM 카드)을 이용하여 통신 네트워크 내에서 전자 장치의 구별 및 인증을 수행할 수 있다. 한 실시예에 따르면, 셀룰러 모듈은 프로세서가 제공할 수 있는 기능 중 적어도 일부 기능을 수행할 수 있다. 한 실시예에 따르면, 셀룰러 모듈은 커뮤니케이션 프로세서(CP)를 포함할 수 있다. 어떤 실시예에 따르면, 셀룰러 모듈, WiFi 모듈, 블루투스 모듈, GNSS 모듈 또는 NFC 모듈 중 적어 도 일부(예: 두 개 이상)는 하나의 integrated chip(IC) 또는 IC 패키지 내에 포함될 수 있다. RF 모듈은, 예를 들면, 통신 신호(예: RF 신호)를 송수신할 수 있다. RF 모듈은, 예를 들면, 트랜시버, PAM(power amp module), 주파수 필터, LNA(low noise amplifier), 또는 안테나 등을 포함할 수 있다. 다른 실 시예에 따르면, 셀룰러 모듈, WiFi 모듈, 블루투스 모듈, GNSS 모듈 또는 NFC 모듈 중 적어도 하나는 별개의 RF 모듈을 통하여 RF 신호를 송수신할 수 있다. 가입자 식별 모듈은, 예를 들면, 가입자 식별 모듈을 포함하는 카드 또는 임베디드 SIM을 포함할 수 있으며, 고유한 식별 정보(예: ICCID(integrated circuit card identifier)) 또는 가입자 정보(예: IMSI(international mobile subscriber identity))를 포함할 수 있다. 메모리(예: 메모리)는, 예를 들면, 내장 메모리 또는 외장 메모리를 포함할 수 있다. 내장 메모리는, 예를 들면, 휘발성 메모리(예: DRAM, SRAM, 또는 SDRAM 등), 비휘발성 메모리(예: OTPROM(one time programmable ROM), PROM, EPROM, EEPROM, mask ROM, flash ROM, 플래시 메모리, 하드 드라이브, 또는 솔 리드 스테이트 드라이브 (SSD) 중 적어도 하나를 포함할 수 있다. 외장 메모리는 플래시 드라이브(flash drive), 예를 들면, CF(compact flash), SD(secure digital), Micro-SD, Mini-SD, xD(extreme digital), MMC(multi-media card) 또는 메모리 스틱 등을 포함할 수 있다. 외장 메모리는 다양한 인터페이스를 통하 여 전자 장치와 기능적으로 또는 물리적으로 연결될 수 있다. 센서 모듈은, 예를 들면, 물리량을 계측하거나 전자 장치의 작동 상태를 감지하여, 계측 또는 감지된 정보를 전기 신호로 변환할 수 있다. 센서 모듈은, 예를 들면, 제스처 센서(240A), 자이로 센서(240B), 기 압 센서(240C), 마그네틱 센서(240D), 가속도 센서(240E), 그립 센서(240F), 근접 센서(240G), 컬러(color) 센 서(240H)(예: RGB(red, green, blue) 센서), 생체 센서(240I), 온/습도 센서(240J), 조도 센서(240K), 또는 UV(ultra violet) 센서(240M) 중의 적어도 하나를 포함할 수 있다. 추가적으로 또는 대체적으로, 센서 모듈 은, 예를 들면, 후각(e-nose) 센서, 일렉트로마이오그라피(EMG) 센서, 일렉트로엔씨팔로그램(EEG) 센서, 일렉트로카디오그램(ECG) 센서, IR(infrared) 센서, 홍채 센서 및/또는 지문 센서를 포함할 수 있다. 센서 모듈 은 그 안에 속한 적어도 하나 이상의 센서들을 제어하기 위한 제어 회로를 더 포함할 수 있다. 어떤 실시예에서는, 전자 장치는 프로세서의 일부로서 또는 별도로, 센서 모듈을 제어하도록 구성된 프로 세서를 더 포함하여, 프로세서가 슬립(sleep) 상태에 있는 동안, 센서 모듈을 제어할 수 있다. 입력 장치는, 예를 들면, 터치 패널, (디지털) 펜 센서, 키, 또는 초음파 입력 장치(25 8)를 포함할 수 있다. 터치 패널은, 예를 들면, 정전식, 감압식, 적외선 방식, 또는 초음파 방식 중 적어 도 하나의 방식을 사용할 수 있다. 또한, 터치 패널은 제어 회로를 더 포함할 수도 있다. 터치 패널 은 택타일 레이어(tactile layer)를 더 포함하여, 사용자에게 촉각 반응을 제공할 수 있다. (디지털) 펜 센서 는, 예를 들면, 터치 패널의 일부이거나, 별도의 인식용 쉬트를 포함할 수 있다. 키는, 예를 들면, 물리적인 버튼, 광학식 키, 또는 키패드를 포함할 수 있다. 초음파 입력 장치는 마이크(예: 마이크) 를 통해, 입력 도구에서 발생된 초음파를 감지하여, 상기 감지된 초음파에 대응하는 데이터를 확인할 수 있다. 디스플레이(예: 디스플레이)는 패널, 홀로그램 장치, 프로젝터, 및/또는 이들을 제어 하기 위한 제어 회로를 포함할 수 있다. 패널은, 예를 들면, 유연하게, 투명하게, 또는 착용할 수 있게 구 현될 수 있다. 패널은 터치 패널과 하나 이상의 모듈로 구성될 수 있다. 홀로그램 장치는 빛의 간섭을 이용하여 입체 영상을 허공에 보여줄 수 있다. 프로젝터는 스크린에 빛을 투사하여 영상을 표시할 수 있다. 스크린은, 예를 들면, 전자 장치의 내부 또는 외부에 위치할 수 있다. 인터페이스는, 예를 들면, HDMI, USB, 광 인터페이스(optical interface), 또는 D-sub(D-subminiature)를 포 함할 수 있다. 인터페이스는, 예를 들면, 도 1에 도시된 통신 인터페이스에 포함될 수 있다. 추가적 으로 또는 대체적으로, 인터페이스는, 예를 들면, MHL(mobile high-definition link) 인터페이스, SD카드 /MMC(multi-media card) 인터페이스, 또는 IrDA(infrared data association) 규격 인터페이스를 포함할 수 있 다. 오디오 모듈은, 예를 들면, 소리와 전기 신호를 쌍방향으로 변환시킬 수 있다. 오디오 모듈의 적어도 일부 구성요소는, 예를 들면, 도 1 에 도시된 입출력 인터페이스에 포함될 수 있다. 오디오 모듈은, 예를 들면, 스피커, 리시버, 이어폰, 또는 마이크 등을 통해 입력 또는 출력되는 소리 정 보를 처리할 수 있다. 카메라 모듈은, 예를 들면, 정지 영상 및 동영상을 촬영할 수 있는 장치로서, 한 실 시예에 따르면, 하나 이상의 이미지 센서(예: 전면 센서 또는 후면 센서), 렌즈, 이미지 시그널 프로세서(ISP), 또는 플래시(예: LED 또는 xenon lamp 등)를 포함할 수 있다. 전력 관리 모듈은, 예를 들면, 전자 장치 의 전력을 관리할 수 있다. 한 실시예에 따르면, 전력 관리 모듈은 PMIC(power management integrated circuit), 충전 IC, 또는 배터리 또는 연료 게이지를 포함할 수 있다. PMIC는, 유선 및/또는 무선 충전 방식을 가질 수 있다. 무선 충전 방식은, 예를 들면, 자기공명 방식, 자기유도 방식 또는 전자기파 방식 등을 포함하며, 무선 충전을 위한 부가적인 회로, 예를 들면, 코일 루프, 공진 회로, 또는 정류기 등을 더 포함 할 수 있다. 배터리 게이지는, 예를 들면, 배터리의 잔량, 충전 중 전압, 전류, 또는 온도를 측정할 수 있 다. 배터리는, 예를 들면, 충전식 전지 및/또는 태양 전지를 포함할 수 있다. 인디케이터는 전자 장치 또는 그 일부(예: 프로세서)의 특정 상태, 예를 들면, 부팅 상태, 메시 지 상태 또는 충전 상태 등을 표시할 수 있다. 모터는 전기적 신호를 기계적 진동으로 변환할 수 있고, 진 동, 또는 햅틱 효과 등을 발생시킬 수 있다. 전자 장치는, 예를 들면, DMB(digital multimedia broadcasting), DVB(digital video broadcasting), 또는 미디어플로(mediaFloTM) 등의 규격에 따른 미디어 데 이터를 처리할 수 있는 모바일 TV 지원 장치(예: GPU)를 포함할 수 있다. 본 문서에서 기술된 구성요소들 각각 은 하나 또는 그 이상의 부품(component)으로 구성될 수 있으며, 해당 구성요소의 명칭은 전자 장치의 종류에 따라서 달라질 수 있다. 다양한 실시예에서, 전자 장치(예: 전자 장치)는 일부 구성요소가 생략되거나, 추 가적인 구성요소를 더 포함하거나, 또는, 구성요소들 중 일부가 결합되어 하나의 개체로 구성되되, 결합 이전의 해당 구성요소들의 기능을 동일하게 수행할 수 있다. 도 3은 다양한 실시예에 따른 프로그램 모듈의 블록도이다. 한 실시예에 따르면, 프로그램 모듈(예: 프로 그램)은 전자 장치(예: 전자 장치)에 관련된 자원을 제어하는 운영 체제 및/또는 운영 체제 상에서 구동되는 다양한 어플리케이션(예: 어플리케이션 프로그램)을 포함할 수 있다. 운영 체제는, 예를 들면, AndroidTM, iOSTM, WindowsTM, SymbianTM, TizenTM, 또는 BadaTM를 포함할 수 있다. 도 3을 참조하면, 프로그 램 모듈은 커널(예: 커널), 미들웨어(예: 미들웨어), (API(예: API), 및/ 또는 어플리케이션(예: 어플리케이션 프로그램)을 포함할 수 있다. 프로그램 모듈의 적어도 일 부는 전자 장치 상에 프리로드 되거나, 외부 전자 장치(예: 전자 장치(102, 104), 서버 등)로부터 다운로 드 가능하다.커널은, 예를 들면, 시스템 리소스 매니저 및/또는 디바이스 드라이버를 포함할 수 있다. 시스 템 리소스 매니저는 시스템 리소스의 제어, 할당, 또는 회수를 수행할 수 있다. 한 실시예에 따르면, 시스 템 리소스 매니저는 프로세스 관리부, 메모리 관리부, 또는 파일 시스템 관리부를 포함할 수 있다. 디바이 스 드라이버는, 예를 들면, 디스플레이 드라이버, 카메라 드라이버, 블루투스 드라이버, 공유 메모리 드라 이버, USB 드라이버, 키패드 드라이버, WiFi 드라이버, 오디오 드라이버, 또는 IPC(inter-process communication) 드라이버를 포함할 수 있다. 미들웨어는, 예를 들면, 어플리케이션이 공통적으로 필 요로 하는 기능을 제공하거나, 어플리케이션이 전자 장치 내부의 제한된 시스템 자원을 사용할 수 있도록 API를 통해 다양한 기능들을 어플리케이션으로 제공할 수 있다. 한 실시예에 따르면, 미들웨어 는 런타임 라이브러리, 어플리케이션 매니저, 윈도우 매니저, 멀티미디어 매니저, 리소스 매니저, 파워 매니저, 데이터베이스 매니저, 패키지 매니저, 커넥티비티 매니저, 노 티피케이션 매니저, 로케이션 매니저, 그래픽 매니저, 또는 시큐리티 매니저 중 적어도 하 나를 포함할 수 있다. 런타임 라이브러리는, 예를 들면, 어플리케이션이 실행되는 동안에 프로그래밍 언어를 통해 새로운 기능을 추가하기 위해 컴파일러가 사용하는 라이브러리 모듈을 포함할 수 있다. 런타임 라이브러리는 입출 력 관리, 메모리 관리, 또는 산술 함수 처리를 수행할 수 있다. 어플리케이션 매니저는, 예를 들면, 어플 리케이션의 생명 주기를 관리할 수 있다. 윈도우 매니저는 화면에서 사용되는 GUI 자원을 관리할 수 있다. 멀티미디어 매니저는 미디어 파일들의 재생에 필요한 포맷을 파악하고, 해당 포맷에 맞는 코덱을 이 용하여 미디어 파일의 인코딩 또는 디코딩을 수행할 수 있다. 리소스 매니저는 어플리케이션의 소스 코드 또는 메모리의 공간을 관리할 수 있다. 파워 매니저는, 예를 들면, 배터리의 용량 또는 전원을 관리 하고, 전자 장치의 동작에 필요한 전력 정보를 제공할 수 있다. 한 실시예에 따르면, 파워 매니저는 바이 오스(BIOS: basic input/output system)와 연동할 수 있다. 데이터베이스 매니저는, 예를 들면, 어플리케 이션에서 사용될 데이터베이스를 생성, 검색, 또는 변경할 수 있다. 패키지 매니저는 패키지 파일의 형태로 배포되는 어플리케이션의 설치 또는 갱신을 관리할 수 있다. 커넥티비티 매니저는, 예를 들면, 무선 연결을 관리할 수 있다. 노티피케이션 매니저는, 예를 들면, 도착 메시지, 약속, 근접성 알림 등의 이벤트를 사용자에게 제공할 수 있다. 로케이션 매니저는, 예를 들 면, 전자 장치의 위치 정보를 관리할 수 있다. 그래픽 매니저는, 예를 들면, 사용자에게 제공될 그래픽 효 과 또는 이와 관련된 사용자 인터페이스를 관리할 수 있다. 보안 매니저는, 예를 들면, 시스템 보안 또는 사용자 인증을 제공할 수 있다. 한 실시예에 따르면, 미들웨어는 전자 장치의 음성 또는 영상 통화 기능을 관리하기 위한 통화(telephony) 매니저 또는 전술된 구성요소들의 기능들의 조합을 형성할 수 있는 하는 미들웨 어 모듈을 포함할 수 있다. 한 실시예에 따르면, 미들웨어는 운영 체제의 종류 별로 특화된 모듈을 제공할 수 있다. 미들웨어는 동적으로 기존의 구성요소를 일부 삭제하거나 새로운 구성요소들을 추가할 수 있다. API는, 예를 들면, API 프로그래밍 함수들의 집합으로, 운영 체제에 따라 다른 구성으로 제공될 수 있다. 예를 들면, 안드로이드 또는 iOS의 경우, 플랫폼 별로 하나의 API 셋을 제공할 수 있으며, 타이젠의 경우, 플랫 폼 별로 두 개 이상의 API 셋을 제공할 수 있다. 어플리케이션은, 예를 들면, 홈, 다이얼러, SMS/MMS, IM(instant message), 브라우 저, 카메라, 알람, 컨택트, 음성 다이얼, 이메일, 달력, 미디어 플레이어 , 앨범, 와치, 헬스 케어(예: 운동량 또는 혈당 등을 측정), 또는 환경 정보(예: 기압, 습도, 또는 온도 정보) 제공 어플리케이션을 포함할 수 있다. 한 실시예에 따르면, 어플리케이션은 전자 장치와 외부 전자 장치 사이의 정보 교환을 지원할 수 있는 정보 교환 어플리케이션을 포함할 수 있다. 정보 교환 어플 리케이션은, 예를 들면, 외부 전자 장치에 특정 정보를 전달하기 위한 노티피케이션 릴레이 어플리케이션, 또는 외부 전자 장치를 관리하기 위한 장치 관리 어플리케이션을 포함할 수 있다. 예를 들면, 알림 전달 어플리케이 션은 전자 장치의 다른 어플리케이션에서 발생된 알림 정보를 외부 전자 장치로 전달하거나, 또는 외부 전자 장 치로부터 알림 정보를 수신하여 사용자에게 제공할 수 있다. 장치 관리 어플리케이션은, 예를 들면, 전자 장치 와 통신하는 외부 전자 장치의 기능(예: 외부 전자 장치 자체(또는, 일부 구성 부품)의 턴-온/턴-오프 또는 디 스플레이의 밝기(또는, 해상도) 조절), 또는 외부 전자 장치에서 동작하는 어플리케이션을 설치, 삭제, 또는 갱 신할 수 있다. 한 실시예에 따르면, 어플리케이션은 외부 전자 장치의 속성에 따라 지정된 어플리케이션 (예: 모바일 의료 기기의 건강 관리 어플리케이션)을 포함할 수 있다. 한 실시예에 따르면, 어플리케이션 은 외부 전자 장치로부터 수신된 어플리케이션을 포함할 수 있다. 프로그램 모듈의 적어도 일부는 소프트 웨어, 펌웨어, 하드웨어(예: 프로세서), 또는 이들 중 적어도 둘 이상의 조합으로 구현(예: 실행)될 수 있으며, 하나 이상의 기능을 수행하기 위한 모듈, 프로그램, 루틴, 명령어 세트 또는 프로세스를 포함할 수 있다. 본 문서에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구성된 유닛을 포함하며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로 등의 용어와 상호 호환적으로 사용될 수 있다. \"모듈\"은, 일체로 구성된 부 품 또는 하나 또는 그 이상의 기능을 수행하는 최소 단위 또는 그 일부가 될 수 있다. \"모듈\"은 기계적으로 또 는 전자적으로 구현될 수 있으며, 예를 들면, 어떤 동작들을 수행하는, 알려졌거나 앞으로 개발될, ASIC(application-specific integrated circuit) 칩, FPGAs(field-programmable gate arrays), 또는 프로그램 가능 논리 장치를 포함할 수 있다. 다양한 실시예에 따른 장치(예: 모듈들 또는 그 기능들) 또는 방법(예: 동작 들)의 적어도 일부는 프로그램 모듈의 형태로 컴퓨터로 판독 가능한 저장 매체(예:메모리)에 저장된 명령 어로 구현될 수 있다. 상기 명령어가 프로세서(예: 프로세서)에 의해 실행될 경우, 프로세서가 상기 명령 어에 해당하는 기능을 수행할 수 있다. 컴퓨터로 판독 가능한 기록 매체는, 하드디스크, 플로피디스크, 마그네 틱 매체(예: 자기테이프), 광기록 매체(예: CD-ROM, DVD, 자기-광 매체 (예: 플롭티컬 디스크), 내장 메모리 등 을 포함할 수 있다. 명령어는 컴파일러에 의해 만들어지는 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 다양한 실시예에 따른 모듈 또는 프로그램 모듈은 전술한 구성요소들 중 적어도 하나 이상을 포함하거나, 일부가 생략되거나, 또는 다른 구성요소를 더 포함할 수 있다. 다양한 실시예에 따른, 모듈, 프로 그램 모듈 또는 다른 구성요소에 의해 수행되는 동작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거 나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 본 발명의 다양한 실시예에서 \"이미지 정보\"는 이미지 센서에서 출력되는 이미지 데이터 및 전자장치와 피사체 간의 거리 정보를 포함하는 용어로 사용될 수 있다. \"이미지 데이터\"는 이미지 센서에서 생성되는 컬러 이미지 가 될 수 있다. \"거리 정보(depth information)\"는 이미지 센서에서 생성되는 피사체와 전자장치 간의 거리 정 보가 될 수 있다. 거리 정보는 이미지 센서의 픽셀들 간의 위상차 정보를 통해 생성될 될 수 있다. 예를들면, 2 PD(photo detector) 이미지 센서 또는 4 PD 이미지 센서에서 서브 픽셀들 간의 위상차에 의해 거리 정보를 계산 할 수 있다. 상면 위상차 센서를 포함하는 이미지 센서는 상면 위상차 센서의 출력에 기반하여 거리 정보를 계 산할 수 있다. \"이미지 정보\"는 \"3 차원 정보\"가 같은 의미로 사용될 수 있다. \"구성 정보\"는 이미지에 포함되 는 피사체의 뎁스 맵에 기반하여 추정할 수 있는 정보가 될 수 있다. 구성 정보는 피사체의 영역(range), 이미 지 내의 피사체 위치 정보를 포함할 수 있다. 구성정보는 전자장치의 촬영 자세 정보를 더 포함할 수 있다. \"새 로운 이미지\"는 전자장치에서 자동으로 설정되는 이미지 처리 기법을 획득된 이미지에 적용하여 생성되는 이미 지가 될 수 있다. 이미지 처리 기법은 예를들면, 이미지 필터링 방법이 될 수 있다. 도 4는 본 발명의 다양한 실시예에 따른 전자장치의 구성을 도시하는 도면이다. 도 4를 참조하면, 전자장치는 프로세서, 메모리 모듈, 카메라 모듈, 센서 모듈, 입력 모듈 , 디스플레이 모듈을 포함할 수 있다. 어떤 실시예에서는, 전자 장치는, 구성요소들 중 적어도 하나 를 생략하거나 다른 구성요소를 추가적으로 구비할 수 있다. 프로세서는 전자장치의 적어도 하나의 다른 구성 요소들의 제어 및/또는 어플리케이션 실행에 따른 연산이 나 데이터 처리를 실행할 수 있다. 프로세서는 촬영 모드에서 획득되는 이미지 데이터를 분석하여 거리 정 보를 추출하고, 추출된 거리 정보에 기반하여 이미지를 처리할 수 있다. 프로세서는 촬영 조건을 설정할 수 있다. 프로세서는 촬영 조건에 기반하여 획득되는 이미지 데이터에 기반하여 이미지 데이터 내의 피사 체들의 구성 정보들을 인식할 수 있고, 피사체의 구성 정보에 기반하여 이미지 처리 기법(예를들면, 이미지 필 터)을 설정하고, 설정된 이미지 처리 기법을 획득된 이미지에 적용하여 새로운 이미지를 생성할 수 있다. 메모리 모듈은 휘발성 및/또는 비휘발성 메모리를 포함할 수 있다. 메모리 모듈은 전자장치의 적어도 하나의 다른 구성요소에 관계된 명령(command) 또는 데이터(data)를 저장할 수 있다. 메모리 모듈은 소프 트웨어(software) 및/또는 프로그램(program)을 저장할 수 있다. 프로그램은 커널(kernel), 미들웨어 (middleware), 어플리케이션 프로그래밍 인터페이스(application programming interface(API)) 및/또는 어플리 케이션 프로그램(또는 \"어플리케이션\") 등을 포함할 수 있다. 커널, 미들웨어, 또는 API의 적어도 일부는 운영 시스템(operating system(OS))으로 지칭될 수 있다. 본 발명의 다양한 실시예에 따른 메모리 모듈은 이미 지 필터들을 저장할 수 있다. 카메라 모듈은 렌즈 및 이미지 센서를 포함할 수 있으며, 피사체를 포함하는 이미지를 획득할 수 있다. 카 메라 모듈은 도 2의 카메라 모듈이 될 수 있다. 카메라 모듈은 이미지 장치로 칭할 수도 있다. 이미지 센서는 이미지 데이터를 생성할 수 있다. 이미지 데이터는 거리 정보(depth information)를 추출하기 위 한 신호를 포함할 수 있다.예를들면, 이미지 데이터는 픽셀 이미지 데이터 및 거리 정보를 추출(계산)하기 위한신호를 포함할 수 있다. 이미지 센서는 하나의 단위 픽셀이 복수의 서브 픽셀들을 포함하는 이미지 센서 구성 (예를들면, 2 PD(photo detector) image sensor, 4 PD image sensor 등)을 가질 수 있다. 이미지 센서는 픽셀 센서 및 상면 위상차 센서들을 포함하는 구성을 가질 수 있다. 이미지 센서는 전자장치와 피사체 간의 거리 정 보를 추출할 수 있는 TOF(time of flight) 방식의 이미지 센서 또는 구조 광(structured light) 방식의 이미지 센서가 될 수 있다. IR(infrared ray), 초음파 측정 장치 등을 포함하여 피사체의 거리 정보를 추출하기 위한 신호를 출력할 수 있다. 센서 모듈은 전자장치의 움직임이나 자세 등의 정보를 감지할 수 있는 센서들을 포함할 수 있다. 센서 모 듈은 도 2의 센서 모듈이 될 수 있다. 센서 모듈은 기울기 센서(tilting sensor), 가속도 센서 (acceleration sensor), 자이로 센서(gyro sensor) 등을 포함할 수 있다. 센서 모듏은 압력 센서 (pressure sensor), 근접 센서(proximity sensor), 기압 센서(barometer), 지자기 센서(terrestrial magnetism sensor, compass sensor), 초음파 센서(ultrasonic sensor), 영상을 이용하여 이동을 감지하는 옵티컬 플로 (optical flow), 온/습도 센서(temperature-humidity sensor), 조도 센서(illuminance sensor), UV(ultra violet) 센서, 제스처 센서(gesture sensor)들의 일부 또는 전부를 더 포함할 수 있다. 본 발명의 다양한 실시예에 따른 센서 모듈은 촬영 모드에서 전자장치의 기울기, 움직임, 파지들 중의 적 어도 하나를 인식할 수 있다. 기울기 센서는 전자장치의 기울기를 감지할 수 있다. 기울기 센서는 가속도 센서 및/또는 자이로 센서로 대체할 수도 있다. 입력 모듈은 도 1의 입출력 인터페이스 및 도 2의 입력 장치의 전부 또는 일부 구성이 될 수 있 다. 입력 모듈은 전자장치의 동작을 제어하기 위한 입력 및 데이터를 입력할 수 있다. 입력 모듈은 터치 패널(touch panel)이 될 수 있다. 입력 모듈은 (디지털) 펜 센서를 더 포함할 수 있다. 입력 모듈 은 키 버튼들을 더 포함할 수 있다. 디스플레이 모듈은 도 1의 디스플레이 및 도 2의 디스플레이이 될 수 있다. 디스플레이 모듈 은 액정 디스플레이(liquid crystal display(LCD)), 또는 발광 다이오드(light-emitting diode(LED)) 디 스플레이가 될 수 있다. LED 디스플레이는 OLED(organic light emitting diode) 및 AMOLED(active matrix OLED)를 포함할 수 있다. 입력 모듈 및 디스플레이 모듈은 터치 스크린(touch screen)으로 구성될 수 있다. 터치스크린은 프로 세서의 제어 하에 화면을 표시할 수 있으며, 전자 펜 또는 사용자의 신체의 일부를 이용한 터치(touch), 제스처(gesture), 근접(proximity), 또는 호버링(hovering) 입력을 검출할 수 있다. 본 발명의 다양한 실시예에 따른 전자장치는 통신 모듈을 더 포함할 수 있다. 통신 모듈은 무선 통신 모듈 및 유선 통신 모듈 중에 적어도 하나를 포함할 수 있다. 무선 통신 모듈은 RF 모듈, 셀룰러 모듈, wifi 모듈, 블루 투스 모듈, GPS 모듈의 일부 또는 전부를 포함할 수 있다. 셀룰러 모듈은 LTE(long-term evolution), LTE-A(LTE Advance), CDMA(code division multiple access), WCDMA(wideband CDMA), UMTS(universal mobile telecommunications system), WiBro(Wireless Broadband), 또 는 GSM(global system for mobile communications) 등 중 적어도 하나를 사용할 수 있다. 또한 통신 모듈은 WiFi(wireless fidelity) 모듈, 블루투스(Bluetooth, BT) 모듈, NFC(near field communication), 또는 GNSS(global navigation satellite system, 또는 GPS(global positioning system)) 등 중 적어도 하나를 포함할 수 있다. GNSS는 사용 지역 또는 대역폭 등에 따라, 예를들면, GPS(Global Positioning System), Glonass(Global Navigation Satellite System), Beidou Navigation Satellite System (이하 “Beidou”) 또는Galileo, the European global satellite-based navigation system중 적어도 하나를 포 함할 수 있다. 통신 모듈의 \"GNSS\"는 “GPS”와 혼용되어 사용(interchangeably used)될 수 있다. 도 5는 본 발명의 다양한 실시예에 따른 전자장치가 획득되는 이미지를 처리하여 새로운 이미지를 생성하는 구 성을 도시하는 도면이다. 도 5를 참조하면, 전자장치는 카메라 모듈, 촬영 설정 모듈, 정보 획득 모듈, 필터 결정 모듈 , 필터 적용 모듈, 디스플레이 모듈을 포함할 수 있다. 카메라 모듈은 도 4의 카메라 모듈이 될 수 있다. 카메라 모듈은 광신호를 전기적인 신호로 변 환하고, 전기적인 신호를 이미지 데이터로 출력할 수 있다. 카메라 모듈은 이미지 센서를 포함할 수 있다. 이미지 센서는 렌즈를 통해 입사되는 광신호로부터 이미지 데이터를 획득할 수 있다. 이미지 센서는 이미지 및 거리 정보를 추출하기 위한 신호를 생성할 수 있는 일체형의 이미지 센서와, 이미지 및 거리 정보를 추출하기 위한 신호를 각각 생성하는 스테레오 타입의 이미지 센서로 구성할 수 있다. 한 실시예에 따르면, 일체형의 이미지 센서는 하나의 단위 픽셀이 복수의 서브 픽셀들을 가지는 이미지 센서(예 를들면 2 PD 이미지 센서, 4 PD 이미지 센서 등), 상면 위상차 센서 및 픽셀 센서들로 구성되는 이미지 센서등 이 될 수 있다. 일체형의 이미지 센서는 거리 정보를 추출하기 위한 신호 및 이미지 데이터를 동일한 시간에 출 력할 수 있다. 이미지 센서에서 출력되는 이미지 및 거리 정보를 추출하기 위한 신호들은 서로 매핑될 수 있다. 한 실시예에 따르면, 스테레오 타입의 이미지 센서는 컬러 데이터를 생성하는 컬러 센서 어레이 및 거리 정보를 산출하기 위한 신호를 출력하는 뎁스 센서 어레이를 각각 독립적으로 구성할 수 있다. 예를들면 뎁스 센서 어레 이는 IR 센서 어레이가 될 수 있다. 스테레오 타입의 이미지 센서는 컬러 이미지 및 거리 정보를 추출하기 위한 신호를 각각 독립적으로 생성할 수 있다. 예를들면 이미지 센서는 컬러 이미지 및 거리 정보를 추출하기 위한 신호가 서로 다른 시간에서 생성될 수 있다. 본 발명의 다양한 실시예에 따른 카메라 모듈의 이미지 센서는 이미지 및 거리 정보를 계산하기 위한 신호 를 생성하는 센서들을 모두 포함하는 일체형의 이미지 센서가 될 수 있다. 본 발명의 다양한 실시예에 따른 카 메라 모듈의 이미지 센서는 이미지 및 거리 정보를 추출하기 위한 신호를 개별적으로 생성하는 스테레오 타입의 이미지 센서가 될 수도 있다. 본 발명의 다양한 실시예에 따른 이미지 센서는 이미지 및 거리 정보를 계산하기 위한 신호를 포함하는 이미지 데이터를 생성할 수 있다. 이미지 및 거리 정보를 계산하기 위한 신호는 동시에 생성될 수 있으며, 이미지 및 거리 정보를 계산하기 위한 신호는 개별적으로 생성될 수 있다. 또한 이미지 및 거리 정보를 계산하기 위한 신 호는 픽셀 또는 설정된 영역 별로 매핑되는 이미지일 수 있으며, 또는 매핑되지 않을 수 있다. 촬영 설정 모듈은 카메라 모듈의 초점, 노광, 화이트밸런스 등의 일반적인 촬영 조건을 설정할 수가 있다. 촬영 설정 모듈은 카메라 모듈에서 획득되는 이미지들의 이미지 처리 기법의 적용 여부를 설정 할 수 있다. 예를 들면, 이미지 처리 기법은 이미지 필터링이 될 수 있다. 촬영 설정 모듈은 이미지 필터 를 적용하는 촬영 동작이 설정되면, 카메라 모듈에서 설정된 촬영 조건을 세팅하고, 필터 결정 모듈 에서 이미지 필터를 결정하도록 세팅할 수 있다. 정보 획득 모듈은 피사계를 구성하는 피사체들 간의 위치관계, 피사체와 전자장치 간의 위치관계, 전자장 치의 촬영 자세 등의 정보를 취득할 수 있다. 예를들면, 정보 획득 모듈은 카메라 모듈에서 획득되는 이미지 데이터에서 거리 정보를 추출할 수 있는 신호를 감지(sensing)하여 피사체들의 거리 정보를 획득(계산) 할 수 있으며, 거리 정보(depth map)에 기반하여 전자장치와 피사체들 간의 위치관계를 알 수 있다. 거리 정보 는 하나의 픽셀 이미지를 추출하는 단위에서 복수의 서브 픽셀 검출소자들(photo diode, photo detector; PD)을 가지는 이미지 센서(예를들면 2 PD image sensor, 4 PD image sensor), 상면 위상차 센서를 포함하는 이미지 센서, TOF 방식의 이미지 센서, 구조광 방식의 이미지 센서, 초점조절 방식의 이미지 센서 및 IR, 초음파 등의 방식의 이미지 센서들을 사용하여 획득할 수 있다. 한 실시예에 따르면, 2 PD 이미지 센서인 경우, 정보 획득 모듈은 단위 픽셀 내의 2개의 서브 픽셀 신호들의 위상차를 계산하여 거리 정보를 추출하기 이한 신호를 획득할 수 있다. 한 실시예에 따르면, 상면 위상차 센서들을 구비하는 이미지 센서인 경우, 정보 획득 모듈 은 이미지 센서 내의 상면 위상차 센서들의 신호에 기반하여 거리 정보를 획득할 수 있다. 상기 정보 획득 모듈에서 획득되는 거리 정보는 뎁스 맵(depth map)이 될 수 있다. 한 실시예에 따르면, 상기 카메라 모듈의 이미지 센서는 이미지 데이터를 생성하는 2차원 이미지 센서일 수 있다. 예를들면, 이미지 센서는 컬러 픽셀 센서 어레이를 구비하며, 거리 정보를 추출하기 위한 신호를 생성 하지 않을 수 있다. 이미지 센서가 2차원 이미지 센서인 경우, 정보 획득 모듈은 이미지 센서에서 생성되 는 이미지 데이터의 경계(edge, boundary)를 추출(image image matching)할 수 있다. 이미지의 윤곽선은 이미 지의 윤곽선 및/또는 컬러 데이터의 변화 등에 기반하여 추출할 수 있다. 정보 획득 모듈은 전자장치의 촬영 자세 정보를 획득할 수 있다. 예를 들면, 정보 획득 모듈은 카메 라 모듈을 통해 촬영 동작을 수행할 때, 센서 모듈의 가속도 센서 및/또는 자이로 센서의 출력으로부 터 전자장치의 자세 및 자세의 변화를 감지할 수 있다. 필터 결정 모듈은 카메라 모듈에서 출력되는이미지 및/또는 정보 획득 모듈에서 출력되는 거리 정보(depth map)을 기반으로 이미지를 구성하는 피사체의 구성 정보를 판단할 수 있다. 피사체의 구성 정보는 이미지 영역(사진 영역)에서 피사체의 위치, 피사체의 크기 및/또는 피사체와 전자장치 간의 깊이 정보 등을 포함할 수 있다. 필터 결정 모듈은 피사체의 구성 정보에 기반하여 이미지 내의 피사체에 적합한 이미지 처 리 기법을 설정할 수 있다. 예를들면, 이미지 처리 기법은 이미지 필터가 될 수 있다. 설정되는 이미지 필터는 하나의 이미지 필터 또는 복수의 이미지 필터들이 될 수 있다. 필터 결정 모듈은 카메라 모듈에서 출 력되는 이미지 데이터 및/또는 정복 획득 모듈에서 출력되는 거리 정보(depth map)에 기반하여 주 피사체 의 구성 정보를 인식하는 인식 모듈 및 인식된 구성 정보에 기반하여 이미지 필터를 자동으로 설정하는 필터 판 단 모듈을 포함할 수 있다. 한 실시예에 따르면, 필터 결정 모듈의 인식 모듈은 정보 획득 모듈에서 출력되는 거리 정보(depth map)에 기반하여 피사체의 구성 정보를 인식할 수 있다. 예를들면, 필터 결정 모듈의 인식 모듈은 카메라 모듈에서 출력되는 이미지 데이터 및 정보 획득 모듈에서 출력되는 거리 정보에 기반하여 피사체의 구성 정보를 인식할 수 있다. 한 실시예에 따르면, 필터 결정 모듈의 인식 모듈은 카메라 모듈의 이미지 센서에서 거리 정보를 추 출하기 위한 신호 및 이미지 데이터를 서로 다른 시간에 생성하는 이미지 센서(예를들면 스테레오 구조의 이미 지 센서)이면, 이미지 데이터 및 거리 정보를 추출하는 신호의 프레임을 동기시켜 인식 동작을 수행할 수 있다. 한 실시예에 따르면, 필터 결정 모듈의 인식모듈은 카메라 모듈의 이미지 센서에서 거리 정보를 추출 하기 위한 신호 및 이미지 데이터가 픽셀별로 매핑되지 않을 때 이미지 데이터 및 거리 정보를 추출하기 위한 신호들을 설정된 형태로 매핑(예를들면 이미지 데이터의 영역과 거리 정보를 추출하기 위한 신호를 생성하는 영 역을 매핑)시켜 인식 동작을 수행할 수 있다. 를 서로 다른 시간에 생성하는 이미지 센서(예를들면 스테레오 구 조의 이미지 센서)이면, 이미지 데이터 및 거리 정보를 추출하는 신호의 프레임을 동기시켜 인식 동작을 수행할 수 있다. 필터 적용 모듈은 필터 결정 모듈에서 결정된 이미지 처리 기법에 따라 카메라 모듈에서 획득된 이미지 데이터를 처리할 수 있다. 상기 이미지 처리 기법이 이미지 필터링 방법이면, 필터 적용 모듈은 필 터 결정 모듈에서 결정된 이미지 필터에 대응되는 데이터를 메모리 모듈(4100에서 억세스할 수 있으며, 카 메라 모듈에서 획득되는 이미지 데이터에 설정된 이미지 필터를 적용하여 새로운 이미지를 생성할 수 있다. 디스플레이 모듈은 필터 적용 모듈에 의해 적용된 이미지(예를들면, 이미지에 이미지 필터를 적용한 새로운 이미지)를 표시할 수 있다. 디스플레이 모듈에 표시되는 이미지는 프리뷰 이미지(preview image, live image)가 될 수 있다. 전자장치 는 카메라 모듈에서 획득되는 이미지를 디스플레이 모듈에 프리뷰 이미지로 표시할 수 있으며, 캡쳐 요구가 발생되면 카메라 모듈에서 획득되는 이미지를 메모리 모듈에 저장할 수 있다. 예를들면, 이미 지 필터를 적용하는 촬영 동작이 요구되면, 촬영 설정 모듈에세 세팅하고, 필터 결정 모듈이 이미지 필터를 설정하도록 세팅할 수 있다. 카메라 모듈은 주 피사체를 포함하는 이미지 데이터를 생성할 수 있다. 이미지 데이터는 전자장치와 피사체들 간의 거리 정보를 추출할 수 있는 신호 및 피사체의 이미지 데이터 를 포함할 수 있다. 정보 획득 모듈은 카메라 모듈에서 출력되는 이미지 데이터에서 피사체의 거리 정보를 추출하여 전자장치와 피사체들 간의 거리 정보(depth map)을 생성할 수 있다. 정보 획득 모듈은 도 4의 센서 모듈의 출력에 기반하여 전자장치의 촬영 자세 정보들을 추출할 수 있다. 필터 결정 모듈은 촬영 설정 모듈의 출력에 의해 이미지 처리 기법(예를들면, 이미지 필터링 방법)의 설정을 인식하고, 정보 획득 모듈의 출력에 의해 피사체의 특징(이미지에 포함되는 피사체의 구성 요소, 위치 관계 등)을 인식할 수 있다. 정보 획득 모듈은 인식된 피사체의 특징에 기반하여 피사체의 범위 정보 (depth map)를 추출하고, 이에 근거하여 이미지에 적용할 필터를 결정할 수 있다. 필터 적용 모듈은 필터 결정 모듈에서 카메라 모듈에서 획득되는 이미지에 설정된 이미지 필터를 적용하여 새로운 이미지를 생성할 수 있다. 새로운 이미지는 획득된 이미지에 설정된 이미지 필터가 적용된 이미지가 될 수 있다. 디스플레이 모듈은 필터 적용 모듈에서 생성되는 새로운 이미지를 표시할 수 있다. 디스플레이 에 표시되는 새로운 이미지는 피사체와 전자장치의 거리에 기반하여 결정된 이미지 필터가 적용된 이미지며, 프 리뷰 이미지로 표시될 수 있다. 이때 디스플레이 모듈은 정보 획득 모듈에서 획득된 전자장치의 자세 정보를 표시할 수 있다. 사용자는 디스플레이 모듈에 표시되는 새로운 이미지를 확인하고 전자장치의 자세를 수정할 수 있다. 또한 사용자의 자세 수정에 따라 정보 획득 모듈은 이미지에 포함된 피사체의 거리 정보 및 전자장치의 자세 정보를 획득할 수 있다. 필터 결정 모듈은 정보 획득 모듈의 출력에 의해 수정된 거리 정보 및 자세 정 보에 따라 새로운 피사체의 범위 정보(depth map)을 결정할 수 있다. 원하는 이미지가 디스플레이 모듈에 표시되면, 사용자는 캡쳐(capture) 명령을 발생할 수 있다. 캡쳐 명령 이 발생되면, 프로세서은 디스플레이 모듈에 표시되는 새로운 이미지를 메모리 모듈에 저장할 수 있다. 메모리 모듈에 저장되는 이미지는 필터가 적용된 이미지가 될 수 있다. 메모리 모듈에 저장 되는 이미지는 이미지는 카메라 모듈에서 획득되는 이미지 및 필터가 적용된 이미지를 모두 포함할 수 있 다. 도 6a - 도 6e는 본 발명의 다양한 실시예에 따른 이미지 필터들을 도시하는 도면이다. 도 6a는 리니어 필터(linear filter)의 특성을 도시하는 도면이다. 리니어 필터는 포커스가 맞는 지점은 선명하 게 하고 포커스가 맞는 지점에서 멀어질수록 블러를 심하게 하는 필터가 될 수 있다. 블러는 한 축 방향으로 같 은 정도의 블러를 가질 수 있으며, 축에 수직하는 방향으로 블러의 정도가 변할 수 있다. 블러의 정도 변화는 전자장치(예를들면 카메라)의 자세(기울기)에 따라 달라질 수 있다. 리니어 필터는 이미지에서 포커스가 맞는 지점은 선명하게 처리하고 포커스에서 멀어질수록 blur의 강도가 강하게 할 수 있다. 즉 필터 마스크의 크기가 커지거나 마스크 계수의 형태가 달라집니다. 리니어 필터는 피사체를 강조하기 위한 리니어 필터, 배경을 흐리게할 수 있는 리니어 필터, 또는 피사체를 강 조하고 배경을 흐리게 할 수 있는 리니어 필터로 구성할 수 있다. 도 6b는 방사형 필터(radial filter, circular filter, polygonal filter)의 특성을 도시하는 도면이다. 이미 지를 보는 사람의 시선을 사로잡으려면 특정 피사체를 강조할 수 있다. 예를 들면, 방사형 필터는 피사체 주위 에 방사형 형태(예를들면, 원, 타원 또는 다각형)의 모양에 기반하여 피사체에 주목할 수 있도록 해당 도형 내 부 영역에 노출과 명확도를 증가시킬 수 있다. 방사형 필터는 이미지의 배경의 초점을 흐리게 할 수 있는 방사 형 필터, 피사체를 강조할 수 있는 방사형 필터, 또는 배경을 흐리게 하고 피사체를 강조할 수 있는 방사형 필 터로 구성할 수 있다. 도 6c는 라이팅 필터(lighting filter, lighting effect)의 특성을 도시하는 도면이다. 라이팅 필터를 사용하 면 RGB 이미지에 여러 가지 조명 효과를 적용할 수 있다. 또한 범프 맵이라고 하는 회색 음영 파일의 텍스처를 사용하여 3D 효과를 만들어 저장해 두었다가 다른 이미지에 사용할 수도 있다. 라이팅 필터는 광원을 사용할 수 있다. 라이팅 필터는 라이팅 범위를 조절할 수 있고, 방향을 변경할 수도 있다. 라이팅 필터는 라이팅 강도 (lighting intensity), 라이팅 범위(lighting range), 라이팅 밝기 조절(lighting exposure) 등을 할 수 있다. 도 6d는 매크로 필터(macro filter)의 특성을 도시하는 도면이다. 매크로 촬영은 피사체를 근접 촬영하여 이미 지 프레임 전체를 상기 피사체로 채우는 촬영이 될 수 있다. 예를들면, 매크로 촬영은 피사체에 가까이 갈수록 아웃포커스의 양이 많아지며, 전경과 배경을 모두 아웃포커스 처리한 이미지를 획득할 수 있다. 매크로 촬영은 촬영 각도와 구도를 자유롭게 변경할 수 있어 작은 물체를 촬영하기에 적합할 수 있다. 예를들면, 매크로 촬영 은 피사체와의 거리가 매우 가까운 거리에서의 촬영하는 방법이 될 수 있다. 매크로 촬영의 매력은 매우 가까운 피사체를 촬영함으로써 눈으로는 볼 수 없는 세밀한 세계를 알 수 있다. 본 발명의 다양한 실시예에서는 피사체와의 거리가 멀게 감지되면 주밍 동작을 수행하여 매크로 촬영할 수 있다. 그리고 매크로 촬영된 이미지를 매크로 필터를 적용하여 피사체를 강조할 수 있다. 예를들면, 전자장치와 피사체의 거리 정보를 분석한 결과 방사형 필터가결정되고 피사체와의 거리가 먼 것으로 인식되면, 전자장치는 줌 동작을 수행하여 피사체 이미지를 획득하고 방사형 필터 및 매크로 필터를 설정하여 이미지를 처리할 수 있 다. 매크로 필터는 피사체를 강조하기 위한 매크로 필터, 배경을 흐리게할 수 있는 매크로 필터, 또는 피사체를 강조하고 배경을 흐리게 할 수 있는 매크로 필터로 구성할 수 있다. 도 6e는 셀렉티브 포커스(selective focus, narrow depth of field(DOF)) 필터의 특성을 도시하는 도면이다. 이미지를 처리할 때, 피사체 전경 및/또는 배경을 흐리게 연출하면 피사체가 더욱 강조되는 효과를 가질 수 있 다. 본 발명의 다양한 실시예에 따른 전자장치는 획득되는 이미지에 기반하여 거리 정보(depth map)을 획득하고, 거 리 정보에 기반하여 피사체의 영역(range)을 인식하고, 인식된 피사체의 영역에 기반하여 이미지 처리 기법(예 를들면 이미지 필터 방법)을 자동으로 결정할 수 있다. 이미지 처리 기법은 도 6a - 도 6e와 같은 이미지 필터 들 중에 적어도 하나의 이미지 필터를 결정한 후, 결정된 이미지를 획득되는 이미지에 적용하여 새로운 이미지 를 생성할 수 있다. 이를 위하여 카메라 모듈은 이미지를 구성하는 피사체들의 거리 정보를 생성할 수 있다. 카메라 모듈의 이미지 센서는 단위 픽셀이 멀티 서브 픽셀 구성을 가지는 멀티 PD 이미지 센서, 상면 위상차 센서 를 포함하는 이미지 센서, 광신호를 출력하여 반사되어 오는 시간을 측정하여 거리(depth)를 계산하는 TOF(time of flight)의 이미지 센서, 구조 광(structured light) 방식의 이미지 센서, 초점 조절 방식의 이미지 센서, IR 방식의 이미지 센서, 초음파 방식의 이미지 센서가 될 수 있다. 도 7은 본 발명의 다양한 실시예에 따른 이미지 센서의 구성을 도시하는 도면이다. 도 7을 참조하면, 전자장치는 프로세서, 이미지 센서 및 디스플레이 모듈을 포함할 수 있다. 이 미지 센서는 픽셀 어레이(pixel array), 로우 드라이버(row driver), 리드아웃 드라이버 (readout driver), 타이밍 생성기(timing signal generator)을 포함할 수 있다. 다양한 실시 예에 따르면, 상기 이미지 센서는 입사되는 광 신호를 이미지 데이터로 생성할 수 있다. 프로 세서는 생성된 이미지 데이터를 처리하여 상기 전자 장치와 기능적으로 연결된 디스플레이에 표시되 도록 할 수 있다. 프로세서는 이미지 센서에서 획득되는 이미지 데이터를 처리하기 위한 모드를 확인 하고, 확인된 모드에 기반하여 이미지 데이터를 처리할 수 있다. 픽셀 어레이는 렌즈를 통해 촬상되는 피사체을 감지할 수 있다. 픽셀 어레이은 렌즈 의 광신호를 전기적인 신호로 변환하여 이미지 데이터를 생성할 수 있다. 타이밍 생성기은 로우 드라이버 에 픽셀 어레이의 로우 라인 픽셀들을 활성화하기 위한 타이밍 신호를 생성할 수 있으며, 픽셀 어레 이의 컬럼 라인 픽셀들을 리드아웃하기 위한 타이밍 신호를 생성할 수 있다. 픽셀 어레이은 로우 드 라이버에 의해 로우 라인 픽셀들을 활성화할 수 있으며, 리드아웃 드라이버에 의해 컬럼 라인의 픽셀 신호들을 리드아웃할 수 있다. 도 7에서 타이밍 생성기은 카메라 모듈에 포함되는 것으로 도시하고 있지만, 프로세서에 포함될 수 있다. 픽셀 어레이은 마이크로 렌즈, 컬러 필터 및 포토 다이오드들로 구성되는 픽셀들의 어레이가 될 수 있다. 픽셀 어레이는 복수의 단위 픽셀들로 구성될 수 있으며, 각각의 단위 픽셀은 복수의 서브 픽셀들을 포함할 수 있다. 서브 픽셀은 포토 다이오드를 포함할 수 있다. 이미지 센서는, 예를 들면, 하나의 단위 픽셀에 적어도 두 개 이상의 서브 픽셀들(예: photo diode; PD)을 가지는 구조를 포함할 수 있다. 상기 이미지 센서 는 R(red), G(green), B(blue) 중 적어도 하나의 색 정보를 포함하는 컬러 정보를 출력할 수 있다. 도 8은 본 발명의 일 실시예에 따른 이미지 센서의 픽셀 어레이의 구성을 도시하는 도면이다. 도 8을 참조하면, 픽셀 어레이은 매트릭스(matrix) 형태로 배열되는 복수의 단위 픽셀들(810 - 840)을 포 함할 수 있다. 각 단위 픽셀(810 - 840)은 복수의 서브 픽셀들을 포함할 수 있다. 픽셀 어레이는 전체 단 위 픽셀들과 각 단위 픽셀의 서브 픽셀들을 곱한 만큼의 서브 픽셀 레벨의 신호를 한번에 출력하거나, 또는 하 나의 단위 픽셀의 서브 픽셀 레벨의 신호를 합하여 전체 단위 픽셀들의 개수만큼 신호를 출력할 수 있다. 단위 픽셀은 적어도 두개의 서브 픽셀들을 포함할 수 있다. 도 8은 하나의 단위 픽셀이 4개의 단위 픽셀들을 포함하 는 예를 도시하고 있다. 도 8에서 제1 단위 픽셀은 4 개의 서브 픽셀들(811-814)을 포함할 수 있으며, 제2 단위 픽셀은 4 개의 서브 픽셀들(821-824)을 포함할 수 있고, 제3 단위 픽셀은 4 개의 서브 픽셀들 (831-834)을 포함할 수 있으며, 제4 단위 픽셀은 4 개의 서브 픽셀들(841-844)을 포함할 수 있다. 본 발명의 다양한 실시예에 따른 픽셀 어레이의 서브 픽셀 간격(sub-pixel pitch)은 통상적인 픽셀 어레이 의 픽셀 간격(pitch)보다 작을 수 있다. 도 8은 단위 픽셀들(810-840)이 각각 4 개씩의 서브 픽셀들을 포함하는 것으로 도시되었으나, 이에 한정되지 않는다. 단위 픽셀들은 2 개의 서브 픽셀들을 포함할 수 있다. 예를들면, 제1 단위 픽셀은 2 개의 서브 픽셀들(811-812)을 포함할 수 있으며, 제2 단위 픽셀은 2 개의 서브 픽 셀들(821-822)을 포함할 수 있고, 제3 단위 픽셀은 2 개의 서브 픽셀들(831-832)을 포함할 수 있으며, 제4 단위 픽셀은 2 개의 서브 픽셀들(841-842)을 포함할 수도 있다. 한 실시예에 따르면, 타이밍 생성기은 로우 드라이버 및 리드아웃 드라이버가 픽셀 어레이(73 0)의 로우 라인 및 컬럼 라인을 구동하기 위한 타이밍 신호를 생성할 수 있다. 픽셀 어레이는 로우 디코더 의 로우 라인 제어에 의해 따라 로우 라인 단위로 픽셀들을 활성화시킬 수 있으며, 리드아웃 드라이버(픽 셀 어레이의 픽셀 신호들은 타이밍 생성기의 제어에 따라 컬럼 라인을 따라 각각의 서브 픽셀 레벨의 신호를 출력할 수 있다. 픽셀 어레이를 구성하는 단위 픽셀(810-840)은 각각의 집광력(light gathering power)을 높이기 위한 마 이크로 렌즈, 상부에는 특정 스펙트럼 영역의 빛을 투과 시키거나 차단하기 위한 각각의 컬러 필터를 포함할 수 있다. 그리고 단위 픽셀 내의 서브 픽셀들은 포토 다이오드를 포함할 수 있다. 예를들면, 서브 픽셀들은 하나의마이크로 렌즈 및 컬러 필터를 공유할 수 있으며, 각각의 포토 다이오드를 이용할 수 있다. 예를들면, 하나의 단위 픽셀이 4개의 서브 픽셀들을 포함하는 경우, 4개의 서브 픽셀들은 하나의 마이크로 렌즈 및 컬러 필터들을 통해 수신되는 광신호를 각각 대응되는 포토 다이오드를 통해 전기적인 신호로 변환할 수 있다. 로우 드라이버는 타이밍 생성기의 제어에 따라 다수의 서브 픽셀들 각각의 동작을 제어하기 위한 제 어 신호들을 픽셀 어레이에 드라이빙할 수 있다. 예를 들면, 제어 신호들은 서브 픽셀들을 선택하기 위한 신호 및 리셋(reset)하기 위한 신호를 포함할 수 있다. 리드아웃 드라이버는 픽셀 어레이의 컬럼 라 인들을 선택하고, 선택된 컬럼 라인의 서브 픽셀 레벨의 신호를 리드아웃하기 위한 구성 요소들(예를 ADC(analog to digital converter) 등)을 포함할 수 있다. 한 실시예에 따르면, 리드아웃 드라이버는 단위 픽셀(810-840)들의 각 서브 픽셀 레벨의 신호를 출력할 수 있다. 예를들면, 리드아웃 드라이버(810-840)는 각 서브 픽셀에서 감지되는 이미지 신호들을 리드아웃할 수 있 다. 프로세서는 서브 픽셀 신호들을 가공 및/또는 처리하여 방향성 정보(angular information), 거리 정보 (depth data)들을 생성할 수 있다. 도 9a - 도 9c는 본 발명의 다양한 실시예에 따른 이미지 센서의 단위 픽셀 및 서브 픽셀들의 구조를 도시하는 도면이다. 도 9a는 이미지 센서의 단위 픽셀이 2개의 서브 픽셀들을 포함하는 예를 도시하는 도면이다. 도 9b는 이미지 센 서의 단위 픽셀이 4개의 서브 픽셀들을 포함하는 예를 도시하는 도면이다. 도 9c는 도 9a와 같은 두 개의 서브 픽셀을 가지는 단위 픽셀의 구조의 예를 도시하는 도면이다. 도 9a를 참조하면, 이미지 센서의 단위 픽셀은 적어도 하나의 마이크로 렌즈, 적어도 하나의 컬러 필 터, 두 개의 포토 다이오드 PD1-PD2를 포함하는 수광부를 포함할 수 있다. 예를들면, 도 9a와 같은 구성의 단위 픽셀은 2 개의 서브 픽셀 신호를 생성할 수 있다. 이하의 설명에서 도 9a와 같은 단위 픽셀 구조를 가지는 이미지 센서는 2PD 이미지 센서와 혼용되어 설명될 것이다. 도 9b를 참조하면, 이미지 센서의 단위 픽셀은 하나의 마이크로 렌즈, 하나의 컬러 필터, 4 개의 포토 다이오드 PD1-PD4를 포함하는 수광부 를 포함할 수 있다. 예를들면, 도 9b와 같은 구성의 단위 픽셀은 4 개의 서브 픽셀 신호를 생성할 수 있다. 이하의 설명에서 도 9b와 같은 단위 픽셀 구조를 가지는 이미지 센서는 4 PD 이미지 센서와 혼용되어 설 명될 것이다. 도 9a 또는 도 9b에서, 수광부(940, 950)는 입사된 광을 전기적 신호 변환하고, 변환된 전기적 신호를 발생시키 고, 적층된 형태의 도핑 영역들로 이루어질 수 있다. 그리고, 도핑 영역들은 입사광의 입사각에 기초하여 적층 될 수 있다. 도 9c를 참조하면, 이미지 센서는 복수의 단위 픽셀들을 포함할 수 있으며, 각 단위 픽셀은 적어도 둘 이상의 포토 다이오드를 포함할 수 있으며, 각각의 포토 다이오드 사이에는 배리어(barrier)가 위치할 수 있다. 그리고, 복수의 포토 다이오드 위에는, 예를 들면, 적어도 하나의 컬러 필터가 위치할 수 있다. 또한, 복수의 포토 다이오드 위에는, 예를 들면, 적어도 하나의 마이크로 렌즈가 위치할 수 있다. 상기 마 이크로 렌즈는, 예를 들면, 상기 컬러 필터 위에 위치할 수 있다. 각각의 단위 픽셀에 입사되는 빛은, 예를 들면, 적어도 하나의 마이크로 렌즈와 적어도 하나의 컬러 필터를 거쳐 각각의 다른 포토 다이오드 에 입사될 수 있으며, 각각의 포토 다이오드에 입사되는 빛의 위상 차이에 따라 초점 검출을 위한 정보를 출력 할 수 있다. 한 실시예에 따르면, 렌즈는 OIS(optical image stabilization) 또는 AF(auto focus)를 위한 액츄레이터 (actuator)와 기능적으로 연결될 수 있다. 한 실시예에 따르면, 컬러 필터는 R(예: 레드) 필터, G(예: 그린) 필터 또는 B(예: 블루) 필터이거나, 또 는 옐로우(yellow) 필터, 마젠타(magenta) 필터 및 시안(cyan) 필터일 수 있다. 한 실시예에 따르면, 컬러 필터는 입사광의 입사각에 기초하여 포토 다이오드(940, 950) 위에 형성될 수 있으며, 베이어 패턴을 가질 수 있다. 베이어 패턴은 대상의 밝기와 색상을 모아 점으로 이루어진 이미지 데이 터를 만들기 위해 2차원 평면상에 레드, 그린, 블루 각각의 밝기를 받아들이는 필터들을 배치할 수 있다. 베이 어 패턴 컬러 필터 아래서 격자망을 형성하는 각각의 단위 픽셀들은 총 천연색을 인식하는 것이 아니라 레드, 그린, 및/또는 블루 중 할당된 색만을 인식하고 이를 보간(interpolate)하여 천연색을 유추해 낼 수 있다. 한 실시예에 따르면, 마이크로 렌즈는 컬러 필터가 적층되는 경사각을 유지하면서, 컬러 필터 상에서 포토 다이오드(940, 950)에 대응되도록 형성될 수 있다. 또한, OIS 렌즈는, 예를 들면, 렌즈 마운 트(미도시)의 내측에 위치할 수 있으며, 빛을 모을 수 있다. 한 실시예에 따르면, 프로세서는 단위 픽셀의 각 서브 픽셀 신호들을 처리(예를들면, 가산, 평균화)하여 이미지 데이터로 출력할 수 있다. 한 실시예에 따르면, 프로세서는 단위 픽셀에 포함된 서브 픽셀 신호들 의 위상 차를 계산하하여 거리 정보(depth)를 생성할 수 있다. 예를 들면, 도 9a에서 프로세서는 단위 픽 셀의 두개의 서브 픽셀 신호들의 위상차를 계산하여 깊이 정보를 생성하고, 두 개의 서브 픽셀 신호들을 처리하 여 컬러 이미지 데이터를 생성할 수 있다. 예를들면, HD(1280x720) 크기의 픽셀 어레이을 구비하는 이미지 센서가 하나의 단위 픽셀이 4개의 서브 픽셀들을 4PD 구조를 가지면, 이미지 센서는 각각의 포토다이 오드에 대한 컬러 값을 읽어 들여 QHD(2590x1440)의 해상도를 가지는 이미지 데이터를 출력할 수도 있다. 도 10a는 본 발명의 다양한 실시 예에 따른 이미지 센서의 단위 픽셀 및 서브 픽셀들의 예를 도시하는 도면이다. 도 10a는 두 개의 서브 픽셀들을 포함하는 예시도이고, 도 10b는 이미지 센서의 단위 픽셀이 네 개의 서브 픽셀들을 포함하는 예시도이다. 이미지 센서는 복수 개의 단위 픽셀들을 포함하며, 각각의 단위 픽셀은 복수 개의 서브 픽셀들을 포함할 수 있다. R 픽셀은 적색(red color)에 관한 픽셀 이미지가 될 수 있으며, G 픽셀은 녹색(green color)에 관한 픽셀 이미지가 될 수 있으며, B 픽셀은 청색(blue color)에 관한 픽셀 이미지가 될 수 있다. 한 실시예에 따르면, 하나의 단위 픽셀은 적어도 둘 이상의 서브 픽셀(예: 포토 다이오드)을 포함할 수 있다. 각 단위 픽셀은 하나의 마이크로 렌즈 및 컬러 필터를 포함할 수 있다. 단위 픽셀은 하나의 서브 픽셀 레벨의 신호를 출력하여 하나의 픽셀에 복수의 데이터를 포함할 수 있다. 한 실시 예에 따르면, 단위 픽셀은 포함된 적어도 둘 이상의 서브 픽셀 레벨의 신호를 합하여 하나의 데이터로 출력할 수도 있다. 또한, 단위 픽셀은 적어도 두 개의 서브 픽셀들에 들어오는 빛의 위상 차이를 계산하기 위한 위상차 정보를 출력할 수도 있다. 예를들면, 위상차 정보는 도 10a와 같이 2개의 서브 픽셀들을 포함하는 픽셀 의 경우 좌우 픽셀의 위상 차이를 계산하기 위한 정보를 포함할 수 있다. 예를들면, 위상차 정보는 도 10b와 같 이 4 개의 서브 픽셀들을 포함하는 경우, 상하의 서브 픽셀을 이용하여 상하 픽셀의 위상 차이를 계산하기 위한 정보 또는 좌우의 서브 픽셀을 이용하여 좌우 픽셀의 위상 차이를 계산하기 위한 정보를 포함할 수도 있다. 예 를들면, 위상차 정보는 대각선에 위치한 서브 픽셀을 이용하여 위상 차이를 계산하기 위한 정보를 포함할 수 있 다. 예를들면, 위상차 특정 컬러의 픽셀에 대한 위상 차이를 계산하기 위한 정보만을 출력할 수도 있다. 예를 들어 RGB 픽셀 중 상대적으로 빛을 많이 받아들이는 G픽셀에서만 컬러정보 및 위상 차이를 계산하기 위한 정보 만을 출력하고 나머지 R 픽셀 및 B 픽셀에서는 컬러 정보만을 출력할 수도 있다. 도 10a 및 도 10b는 적색, 녹색, 청색에 기초한 베이어 패턴이 도시되었으나, 본 발명의 실시예는 이에 국한되 지 않고 다양한 필터 패턴들을 이용할 수 있다. 다양한 실시예에 따르면, 프로세서는 이미지 센서에서 출력되는 서브 픽셀 신호들에 기반하여 거리 정보 및/또는 이미지 데이터를 획득할 수 있다. 예를들면, 프로세서는 촬영 모드 및 조건에 따라 동작되어 거리 정보(깊이 정보) 정보 및/또는 이미지 데이터를 획득할 수 있다. 한 실시예에서, 프로세서는 이미지 센서의 각 서브 픽셀 신호들에 기반하여 위상 차이를 계산할 수 있다. 프로세서는 위상 차 정보를 이용하여 거리 정보를 추출할 수 있다. 한 실시예에서, 프로세서는 이미지 센서의 각 서브 픽셀 신호들에 기반하여 이미지 데이터를 생성할 수 있다. 예를들면, 2 PD 구조를 가지는 이미지 센서인 경우, 프로세서는 각 단위 픽셀의 제1 서브 픽셀 신호 및 제2 서브 픽셀 신호들을 처리(예를들면, 가산 또는 평균화)하여 단위 픽셀의 이미지 데이터를 생 성할 수 있다. 한 실시예에서, 프로세서는 이미지 센서의 각 서브 픽셀 신호들에 기반하여 위상차 정보 및 이미지 데이터를 생성할 수 있다. 예를들면, 2 PD 구조를 가지는 이미지 센서인 경우, 프로세서는 각 단위 픽셀의 제1 서브 픽셀 신호 및 제2 서브 픽셀 신호의 위상차를 계산하여 거리 정보를 생성할 수 있다. 제1 서브 픽셀 신호 및 제2 서브 픽셀 신호를 처리하여 이미지 데이터를 생성할 수 있다. 한 실시예에서 프로세서는 이미지 센서의 각 서브 픽셀 신호들에기반하여 위상 차 정보를 생성할 수 있다. 2 PD 구조를 가지는 이미지 센서인 경우, 프로세서는 제1 서브 픽셀 신호 및/또는 제2 서브 픽 셀 신호들을 선택적으로 처리할 수 있다. 예를 들면, 단위 픽셀의 속성(예: 색상)에 기반하여 이미지 데이터를처리하는 동작을 다르게 조정할 수 있다. 예를 들면, 단위 픽셀의 속성이 레드(red) 또는 블루(blue)인 경우, 각각의 서브 픽셀 레벨의 신호(예: 제 1 신호, 제 2 신호)를 합한 이미지 데이터를 출력하도록 상기 이미지 센 서을 제어할 수 있다. 또한 단위 픽셀의 속성이 그린(green)인 경우, 각각의 서브 픽셀 레벨의 데이터(예: 제 1 신호, 제 2 신호)를 단위 픽셀 레벨의 이미지 데이터로 처리하여 출력하도록 상기 이미지 센서를 제 어할 수 있다. 도 11a및 도 11b는 상면 위상차 센서를 포함하는 이미지 센서의 동작을 설명하기 위한 도면이다. 도 11a는 본 발명의 다양한 실시예에 따른 피사체들의 위치를 예시하는 도면이다. 먼저 도 11a와 같이 이미지 장치의 전면에 피사체(1110-1130)들이 배치된 상태에서 사용자는 원하는 피사 체에 초점을 맞춰 촬영할 수 있다. 이미지 장치는 도 7과 같은 구성을 가지는 이미지 센서을 포함할 수 있다. 도 11a는 이미지 장치의 위치에서 피사체이 거리 D1만큼 떨어져 가장 가깝게 위치되고, 피사체 은 거리 D3만큼 떨어져 가장 멀게 위치된 예를 도시하고 있다. 도 11a와 같이 피사체들이 이미지 장치의 전면에 배치된 상태에서 사용자가 특정 피사체에 초점을 맞추고 촬영하면, 촬영된 이미지는 초점 이 맞춰진 피사체는 선명하고 다른 피사체들은 초점이 맞춰진 피사체와의 이격된 거리에 따라 덜 선명하게 되는 이미지로 획득될 수 있다. 이미지 장치의 위상차 검출 픽셀은 피사체(1110-1130)에 대하여 각각 다른 위상차 값을 출력할 수 있다. 예를들면, 초점이 피사체 에 맞은 경우, 피사체은 제1초점영역의 피사체이며, 피사체은 제2 초점영역의 피사체가 될 수 있으며, 피사체은 제3초점영역의 피사체가 될 수 있다. 도 11b는 본 발명의 다양한 실시예에 따른 이미지 센서를 도시하는 도면이다. 도 11b를 참조하면, 이미지 장치는 적어도 하나의 위상차 검출 픽셀 (예: 상면 위상차 센서)과 적어도 하나의 이미지 픽셀 (예: 컬러 픽셀)을 포함할 수 있다. 도 11b에서 제1 이미지는 제 1 피사체(예: 도 11a의 피사체 1110)에 대응되는 이미지가 될 수 있으며, 제2 이미지는 제 2 피사체(예를들면, 도 11a 의 피사체 1120)에 대응되는 이미지가 될 수 있으며, 제3 이미지는 제 3 피사체(예를들면, 도 11a의 피사 체 1130)에 대응되는 이미지가 될 수 있다. 한 실시예에 따르면, 전자장치(예를들면, 도 4의 프로세서 400)는 적어도 하나의 위상차 검출 픽셀에서 감지되는 위상차 값에 기반하여, 이미지 센서에 맺힌 피사체들 (1110- 1130)의 상대적인 거리정보(depth information)를 획득할 수 있다. 예를 들면, 전자장치는 제 1 이미지 (117 0)에 포함된 적어도 하나의 위상차 검출 픽셀의 값에 기반하여, 제 1 피사체까지의 거리를 획득할 수 있 다. 예를들면, 제 1 이미지 에 대응하는 위상차 검출 픽셀의 값이 제 1 초점 영역에 대응하는 값인 경우, 전자장치는 제 1 이미지 에 초점이 맞은 것으로 판단할 수 있고, 렌즈 거리계에 기반하여 제 1 이미지 에 대응하는 제 1 피사체까지의 거리(예를들면, 도 11a의 D1)를 획득할 수 있다. 또는, 이미지 센 서를 서브영역(또는 복수의 영역) R11 - Rmn(로우 라인 R1-Rm, z컬럼 라인 R1-Rn)으로 나누고, 각각의 서브 영 역에 포함된 위상차 검출 픽셀들의 값에 기반하여, 각 서브 영역에 대응하는 피사체 간의 거리를 획득할 수 있 다. 예를 들면, 제 1 이미지 에 대응하는 위상차 검출 픽셀의 값이 제 1 초점 영역에 대응하는 값을 가지 고, 제 2 이미지 에 대응하는 위상차 검출 픽셀의 값이 제 2 초점 영역에 대응하는 값인 경우에는, 전자 장치는 제 1 이미지 과 제 2 이미지 간의 상대적인 거리를 획득할 수 있다. 도 12a 및 12b는 본 발명의 다양한 실시 예들 중 하나에 따른, 이미지 센서의 일부분을 확대하여 도시한다. 상기 도 12a를 참조하면, 이미지 센서(예를들면, 도 7의 픽셀 어레이 730)의 픽셀 , 들은 배선 영 역들, 수광 영역들 및 결상 렌즈, 예를 들면, 마이크로 렌즈들을 포함할 수 있다. 상기 배선 영역들은 이미지 센서의 기판의 일면에서 일정 간격을 두고 배치되며 배선 영역들 사이에 각각 수광 영역가 배치될 수 있다. 예컨대, 배선 영역들과 수광 영역들은 기판(121 1)의 일면에서 서로 번갈아가며 배치될 수 있다. 배선 영역들에는 전원 또는 신호 라인과 트랜지스터와 같은 소자들이 배치될 수 있다. 수광 영역들은 실질적으로 빛, 이미지를 검출하여 전기 신호로 변환하는 광전 변환 영역으로서, 검출된 이미지의 정보에 따른 전기 신호를 배선 영역으로 전달할 수 있다. 각각의 단위 픽셀, 들은 하나의 수광 영역와 그에 연결된 배선 영역의 배선 및 트랜지 스터, 해당 수광 영역에 상응하게 배치되는 마이크로 렌즈을 포함할 수 있다. 이러한 단위 픽셀 , 들 중 일부 픽셀(예: 1251)은 이미지 검출 픽셀(예: 컬러픽셀)로 동작하게 되며, 일부 픽셀(예: 1255)은 예를 들면, 위상 분리 구조를 가지는 위상차 검출 픽셀로 구성될 수 있다. 상기 위상차 검출 픽셀 은 수광 영역 상에 차광막을 설치한 위상 분리 구조를 포함할 수 있 다. 각각의 마이크로 렌즈은 그에 대응하는 수광 영역와 광축이 일치한 상태로 배치될 수 있다. 수 광 영역의 위쪽으로 배선 영역들 사이에는 빈 공간(cavity)가 형성되는데, 차광막은 배선 영역들 사이의 빈 공간에 배치될 수 있다. 차광막는 수광 영역의 일측에서 수광 영역의 표면적의 일부, 예를 들면, 약 절반 정도를 가려 수광 영역로 유입되는 빛을 일부 차단할 수 있다. 상기 도 12b를 참조하면, 위상차 검출 픽셀는 도 12b의 참조번호 (1255a) 및 (1255b)와 같이 쌍을 이루어 서로 인접하게 또는 일부 이격되게 배치될 수 있다. 쌍을 이룬 위상차 검출 픽셀들 중, 제1의 위상차 검 출 픽셀(1255a)에 배치된 차광막(1219a)는 제2의 위상차 검출 픽셀(1255b)에 배치된 차광막(1219b)에 대하여 겹 치지 않는, 예를 들면, 오프셋(offset)된 위치에 배치될 수 있다. 제1 위상차 검출 픽셀(1255a가 마이크로 렌즈 의 일측으로 통과하는 빛을 검출하면, 제2 위상차 검출 픽셀(1255b)는 마이크로 렌즈의 타측으로 통과하는 빛을 검출할 수 있다. 이미지 센서 및/또는 이미지 센서가 장착된 카메라나 휴대용 단말기와 같은 전 자 기기는, 위상차 검출 픽셀들 각각으로부터 검출된 값을 비교하여 이미지 센서의 초점 조절 상태를 측 정할 수 있다. 한 실시예에 따르면, 위상차 검출 픽셀은 피사체에 대한 초점이 이미지 센서에 위치 한 것에 대응되는 제 1 초 점 상태(예: 실선 1261), 피사체에 대한 초점이 이미지 센서와 피사체 사이에 위치 한 것에 대응되는 제 2 초점 상태(예: 점선1263) 및 피사체에 대한 초점이 이미지 센서 및 이미지 센서와 피사체 사이 이외 영역에 위치 한 것에 대응되는 제 3 초점 상태(예: 2점쇄선 1265)에 따라 다른 값을 출력할 수 있다. 전자 장치는 제 1 초점 상 태 내지 제 3 초점 상태에 기반하여, 피사체간의 상대적인 거리를 식별할 수 있다. 상기 도 12a 및 도 12b는 한 실시예로서, 위상차 검출 픽셀 구조와 동작을 설명하기 위하여, 예를 들어 차광막 을 가지는 위상차 검출 픽셀을 설명하였다. 그러나 다양한 실시예에 따른 위상차 검출 픽셀은 다양한 형태(또는 구조)의 위상차 분리 구조의 위상차 검출 픽셀을 포함할 수 있다. 상기와 같이 이미지 장치를 이용하여 이미지를 촬영할 때, 초점 은 설정된 피사체 위치에 맞춰질 수 있다. 이미지 센서에 배치되는 위상차 검출 픽셀(예: 상면 위상차 센서)은 초점이 맞은 피사체와 초점이 맞지 않은 다른 피사체들의 거리정보를 추출할 수 있다. 이때 전자장치는 위상차 검출 픽셀(또는 상면 위상차 센서)들의 각각의 쌍으로 위상차 값을 구할 수 있으며, 또한 도 11b와 같이 이미지센서의 영역을 서브 영 역들로 나누고, 각각의 서브 영역에 해당하는 위상차 검출 픽셀(또는 상면 위상차 센서)들을 이용하여 위상차 값을 구할 수 있다. 이하의 설명에서는 도 11b에 도시된 바와 같이 각각의 서브영역에 해당하는 위상차 검출 픽셀들을 이용하여 피 사체의 거리정보를 계산하는 것으로 예를 들어 설명하기로 한다. 또한 이미지는 두 개 이상의 피사체들을 포함 할 수 있으며, 이런 피사체들의 거리정보를 계산할 때, 전자장치는 초점이 맞춰진 피사체와 초점이 맞춰지지 않 은 피사체들(예컨대, 피사체의 앞에 초점이 맞춰지거나 또는 피사체의 뒤에 초점이 맞춰지는 피사체들) 간의 거 리를 구할 수 있다. 한 실시예에 따르면, 전자장치는 획득되는 이미지에 촬영 대상에 맞는(적합한) 이미지 처리 기법을 적용하여 사 용자의 기호에 맞는(사용자가 원하는) 새로운 이미지를 생성할 수 있다. 획득된 이미지에 적용하는 이미지 처리 기법은 전자장치가 자동으로 판단하여 결정할 수 있으며, 또는 전자 장치에서 분석한 이미지 처리 기법을 표시 하여 사용자가 선택할 수 있도록 활용할 수 있다. 한 실시에에 따르면, 전자장치는 이미지 센서에서 획득되는 이미지에 포함되는 피사체 정보를 분석하여 이미지 처리 기법을 결정하고, 결정된 이미지 처리 기법을 획득된 이미지에 적용하여 표시할 수 있다. 예를들면, 이미 지 처리 기법은 획득된 이미지에 적용할 수 있는 이미지 필터를 결정하는 방법이 될 수 있다. 예를들면, 획득되 는 이미지는 음식 이미지가 될 수 있다. 한 실시예에 따르면, 전자장치는 음식에 연관된 이미지 데이터를 획득하고, 음식 이미지 데이터 기반하여 음식 과 전자자장치 간의 거리 정보를 추출하고, 추출된 거리 정보에 기반하여 음식의 구성 정보(음식 이미지의 크기, 위치, 음식의 거리 정보 등)을 생성하고, 음식의 구성 정보에 기반하여 이미지 필터를 결정할 수 있다. 이미지 필터는 도 6a - 도 6e에 도시된 바와 같이, 리니어 필터, 방사형 필터, 라이팅 필터, 매크로 필터, 셀렉 티브 포커스 필터들 중에 하나 또는 복수의 필터들이 선택될 수 있다. 도 13a - 도 13b는 본 발명의 다양한 실시예에 따른 전자장치에 획득되는 이미지 및 획득되는 이미지 데이터에 기반하여 추출되는 거리 정보의 표시 예를 도시하는 도면이다.한 실시예에 따르면, 전자장치는 음식 촬영 모드(food mode)를 포함할 수 있다. 사용자가 음식 촬영 명령을 발 생하면, 전자장치(예를들면, 촬영 설정 모듈)는 카메라 모듈에서 출력되는 이미지 데이터에 이미지 처리 기법을 적용하여 새로운 이미지를 생성할 수 있다. 전자장치는 도 13a와 같은 이미지를 획득할 수 있다. 도 13a와 같은 이미지는 음식 이미지로써, 용기에 음식이 담겨진 구조를 가질 수 있다. 여기서 이미지를 구성하는 피사체는 용기 및 음식물 등이 될 수 있다. 카메라 모 듈의 이미지 센서는 도 13a와 같은 이미지를 리드아웃할 수 있다. 프로세서는 상기 카메라 모듈(51 0)의 출력에서 이미지 내에 포함되는 피사체들(예를들면, 용기 및/또는 음식물) 간의 위치관계, 피사체와 촬영 부(카메라)간의 위치관계, 촬영부의 자세 등의 정보를 추출할 수 있다. 예를들면, 도 8과 같이 단위 픽셀이 복 수의 서브 픽셀들을 포함하는 이미지 센서(예를들면, 2 PD 이미지 센서, 4 PD 이미지 센서 등)이면, 프로세서 은 서브 픽셀 신호들의 위상차에 기반하여 거리 정보를 획득(추정)할 수 있다. 프로세서는 추정된 거 리 정보로부터 전자장치와 피사체들 간의 위치관계를 알 수 있는 구성 정보(depth map)을 추정할 수 있다. 거리 정보의 추정 방법은 멀티 PD 이미지 센서 이외에, 상면 위상차를 포함한 그 외의 초점조절 방식 및 IR, 초음파 등의 방식의 이미지 센서를 사용할 수도 있다. 상기 이미지의 거리 정보(depth map)은 도 13b와 같은 형태로 표 현될 수도 있다. 도 14a - 도 14d는 본 발명의 다양한 실시예에 따른 전자장치의 이미지 처리 예를 도시하는 도면이다. 상기 프로세서는 센서 모듈의 출력에 기반하여 전자장치의 자세 및 자세의 변화를 감지할 수 있다. 프로세서는 이미지 센서로부터 출력되는 이미지 데이터와 추정된 구성 정보를 기반으로 피사체의 특징(구 성요소, 위치관계 등)을 판단할 수 있으며, 판단된 피사체의 특징에 기반하여 이미지 필터를 결정할 수 있다. 예를들면, 피사체의 특징이 가로, 세로 또는 대각선 방향으로 긴 형태를 가지면, 전자장치는 리니어 필터를 결 정할 수 있다. 예를들면, 도 14c에 도시된 바와 같이 피사체1450의 특징이 원형 또는 타원형(예를들면, 둥근 용 기에 담긴 음식물) 형태를 가지면 전자장치는 방사형 필터를 결정할 수 있다. 전자장치는 이미지 필터를 결정한 후, 이미지 센서에서 획득되는 이미지에 결정된 이미지 필터를 적용하여 새로운 이미지를 생성할 수 있다. 예를들면, 도 14a는 주 피사체 이미지 및 배경 이미지을 포함하는 이미지 데이터가 될 수 있다. 도 14a와 같은 이미지에 기반하여 리니어 필터가 결정되면, 전자장치는 도 14a와 같이 획득된 이미지에 리니어 필 터를 적용하여 도 14b와 같이 새로운 이미지를 생성할 수 있다. 도 14c는 주 피사체 이미지 및 배경 이미 지을 포함하는 이미지 데이터가 될 수 있다. 도 14c와 같은 이미지에 기반하여 방사형 필터가 결정되면, 전자장치는 도 14c와 같이 획득된 이미지에 방사형 필터를 적용하여 도 14d와 같이 새로운 이미지를 생성할 수 있다. 이미지 필터가 적용된 이미지에서 블러의 중심은 포커스된 지점이 기준이 될 수 있다. 포커스는 이미지의 센터 또는 터치 등에 기반하여 다양하게 할 수 있다. 이미지 필터 방법은 포커스 위치는 블러 처리하지 않고 포커스 위치의 주변부는 블러 처리할 수 있다. 도 15는 본 발명의 다양한 실시예에 따른 이미지 처리 장치의 구성을 도시하는 도면이다. 도 15를 참조하면, 전자장치는 획득되는 이미지에 적절한 이미지 처리 기법을 설정하고, 설정된 이미지 처리 기 법을 획득된 이미지에 적용하여 사용자가 원하는 새로운 이미지를 생성할 수 있다. 본 발명의 다양한 실시예에 따르면, 전자장치는 이미지 처리 기법은 전자장치가 획득된 이미지를 분석하여 자동으로 설정할 수 있다. 또한 전자장치에서 설정되는 이미지 처리 기법은 사용자가 원하는 이미지를 선택하는데 활용될 수 있다. 한 실시예에 따르면, 전자장치는 획득된 이미지 및 촬영 환경(예를들면, 초점, 노광, 화이트 밸런스 등의 촬영 조건, 전자잋 의 촬영 각도 및 움직임 등에 따른 촬영 자세 등)을 분석하여 이미지 처리 기법을 설정할 수 있다. 전자장치는 설정된 촬영 조건에 따라 카메라 모듈을 세팅하고, 카메라 모듈을 통해 이미지를 획득할 수 있다. 촬영 조건은 본 발명의 다양한 실시예에 따른 이미지 처리 기법을 사용하는 촬영 모드를 포함할 수 있다. 카메 라 모듈은 이미지 센서을 포함할 수 있다. 이미지 센서은 촬영 조건에 따라 피사체를 감지하여 전 기적인 이미지 신호로 변환할 수 있다. 이미지 데이터는 밝기 정보, 컬러 정보, 피사체와 전자장치의 거리 정보 를 추출하기 위한 신호 등을 포함할 수 있다. 전자장치는 이미지 처리 기법이 결정되면, 카메라 모듈을 구동하여 촬영 동작을 수행할 수 있다. 카메라 모듈의 동작은 프리뷰 이미지를 표시하는 동작이 될 수 있다. 프리뷰 이미지를 표시하는 동작은 이미지 센서에서 획득되는 이미지 데이터를 처리하여 디스플레이 모듈에 표시하는 동작이 될 수 있다. 이미지 센서는 도 8과 같은 구조를 가지는 이미지 센서(예를들면, 2 PD 이미지 센서 또는 4 PD 이미지 센 서)가 될 수 있다. 이미지 센서은 도 11b와 같이 픽셀 센서 및 상면 위상차 센서들을 포함하는 이미지 센 서가 될 수 있다. 이미지 센서은 TOF 방식의 이미지 센서, 구조광 방식의 이미지 센서, IR 또는 초음파와 같은 측정 장비를 포함할 수 있다. 한 실시예에 따르면, 이미지 센서은 이미지 및 거리 정보를 추출하기 위한 신호를 출력하는 구성을 하나 의 장치로 수행하는 일체형의 이미지 센서일 수 있다. 한 실시예에 따르면, 이미지 센서은 이미지 데이터 를 생성하는 이미지 센서와 거리 정보를 추출하기 위한 신호를 생성하는 센서(예를들면 depth sensor)가 각각 독립적으로 구성되는 스테레오 구조의 이미지 센서일 수 있다. 한 실시예에 따르면, 이미지 센서은 이미지 데이터 및 거리 정보를 추출하기 위한 신호들을 같은 시간에 생성할 수 있다. 한 실시예에 따르면, 이미지 센서은 이미지 데이터 및 거리 정보를 추출하기 위한 신호 들을 다른 시간에 생성할 수 있다. 한 실시예에 따르면, 이미지 센서은 이미지 데이터 및 거리 정보를 추출하기 위한 신호들을 픽셀 별 또는 영역 별로 매핑시켜 생성할 수 있다. 한 실시예에 따르면, 이미지 센서은 이미지 데이터 및 거리 정보를 추출하기 위한 신호들을 픽셀 별 또는 영역 별로 매핑되지 않게 생성할 수 있다. 이미지 처리 모듈은 이미지 센서로부터의 출력을 처리하여 이미지 데이터 및 거리 정보를 추출할 수 있다. 이미지 처리 모듈은 이미지 처리부(image signal processor; ISP) 및 정보 획득부를 포함할 수 있다. 이미지 처리부는 이미지 센서에서 출력되는 3D 이미지에서 이미지 데이터를 추출하여 처리할 수 있 다. 정보 획득부는 이미지 센서에서 출력되는 3D 이미지에서 거리 정보를 추출하기 위한 신호들을 추출하 여 피사체와 전자장치 간의 거리 정보를 추출할 수 있다. 이미지 처리부는 이미지 전처리 동작 및 후처리 동작을 수행할 수 있다. 먼저 이미지 전처리 동작은 이미지들에 대하여 AWB(Auto White Balance), AE(Auto Exposure), AF(Auto Focusing) 추출 및 처리, 렌즈 셰이딩 보상 (lens shading correction), 데드픽셀 보정(dead pixel correction), knee 보정 등을 수행할 수 있다. 이미지 후처리 동작은 색보간(color interpolatiion), IPC(image processing chain), 색변환기(color conversion) 등 을 포함할 수 있다. 색보간(color interpolation) 동작은 이미지 센서에서 출력되는 화소들이 3가지 색상 의 RGB를 포함하는 색으로 변환(full color 변환)하는 기능을 수행할 수 있다. IPC는 색 보간된 이미지들의 노 이즈 감소(noise reduction), 감마 보정(gramma correction), 휘도 보정(luminence correction) 등을 수행할 수 있다. 그리고 색변환 동작은 보정된 이미지(예를 들면, raw data, Bayer data)를 YUV (또는 YCbCr)이미지로 변환할 수 있다. 정보 획득부는 이미지 센서에서 출력되는 픽셀 신호들에 기반하여 피사체와 전자장치 간의 거리 정보를 계산할 수 있다. 예를들면, 이미지 센서이 상면 위상차 센서를 포함하는 이미지 센서인 경우, 정보 획득 부는 상면 위상차 센서의 신호들에 기반하여 피사체와 전자장치 간의 거리 정보를 추출할 수 있다. 또한 정보 획득부는 전자장치의 촬영 환경 정보를 생성할 수 있다. 촬영 환경 정보는 촬영 메터 데이터(예를들면, exif(exchangable image file format)), 전자장치의 촬영 자세 정보들을 포함할 수 있다. 정보 획득부에서 추 정되는 거리 정보는 뎁스 맵(depth map)이 될 수 있다. 뎁스 맵 정보는 이미지 데이터의 화소들과 맵핑될 수 있 다. 예를들면, 이미지 센서는 2PD 이미지 센서가 될 수 있다. 이미지 처리부는 2 PD 이미지 센서에서 출력되 는 서브 픽셀 신호들을 합하거나 평균화하여 단위 픽셀의 신호를 생성할 수 있다. 이후 이미지 처리부는 단위 픽셀 신호들을 전처리 및 후처리하여 이미지 데이터를 생성할 수 있다. 정보 획득부는 단위 픽셀의 제1 서브 픽 셀 신호 및 제2 서브 픽셀 신호의 위상차를 계산하여 거리 정보를 추정할 수 있다. 정보 획득부에서 계산되는 제1 및 제2 서브 픽셀 신호의 위상차는 전자장치와 피사체 간의 거리 정보로 사용될 수 있다. 한 실시예에 따르면, 상기 카메라 모듈의 이미지 센서는 이미지 데이터를 생성하는 2차원 이미지 센서일 수 있다. 이미지 센서가 2차원 이미지 센서이면, 이미지 처리 모듈은 이미지 데이터의 윤곽선을 추출하여 거리 정보와 유사한 정보를 생성할 수 있다. 예를들면, 이미지 센서가 2차원 이미지 센서인 경우, 정보 획득부 는 이미지 센서에서 생성되는 이미지 데이터의 윤곽선을 추출하여 거리 정보와 유사한 정보를 생성할 수 있다. 이미지의 윤곽선은 이미지의 윤곽선, 컬러 데이터의 변화 및/또는 이미지의 밝기 등에 기반하여 추출할 수 있다. 인식 모듈은 이미지 처리 모듈에서 생성되는 이미지 데이터 및 거리 정보(또는 이미지 데이터의 윤 곽선 정보)에 기반하여 피사체의 구성 정보(예를들면, 거리정보에 기반하여 피사체의 범위, 이미지 내의 피사체 의 위치 등)를 인식할 수 있다. 예를들면, 인식 모듈은 이미지 처리 모듈에서 출력되는 피사체와 전자장치의 거리 정보에 기반하여 이미지 내에 포함된 적어도 하나의 피사체를 인식할 수 있다. 한 실시예에 따 르면, 인식 모듈은 거리 정보에 기반하여 피사체의 구성 정보를 추정할 수 있다. 한 실시예에 따르면, 인 식 모듈은 이미지 데이터 및 거리 정보에 기반하여 피사체의 구성 정보를 추정할 수 있다. 인식 모듈에서 인식되는 피사체의 구성 정보는 뎁스 맵에 기반하여 추정될 수 있다. 피사체의 구성 정보 는 피사체의 형태(예를들면, 선형, 원형, 타원형 등), 피사체들의 깊이, 피사체의 크기, 피사체의 위치 등의 정 보들을 포함할 수 있다. 필터 판단 모듈은 피사체의 구성 정보에 기반하여 이미지 필터를 결정할 수 있다. 이미지 필터는 도 6a - 도 6e에 도시된 바와 같이 다양한 형태의 필터들이 될 수 있다. 필터 판단 모듈 은 피사체의 구성 정보에 기반하여 하나 또는 복수의 필터들을 선택할 수 있다. 필터 적용 모듈은 필터 판단 모듈에서 결정된 이미지 필터를 이미지 처리된 획득 이미지에 적용하 여 새로운 이미지를 생성할 수 있다. 디스플레이 모듈은 필터 적용 모듈에서 생성되는 새로운 이미 지를 프리뷰 이미지로 표시할 수 있다. 전자장치는 뎁스 맵과 이미지를 분석하여 피사체의 구성 정보(예를들면, object region)을 계산하는 기간 동안 디스플레이 모듈에 이미지 처리 중임을 알려주는 표시를 제공할 수 있다. 예를들면, 전자장치는 즉, Preview화면에 최종 촬영이미지에 적용할 또는 그와 유사한 이미지 처리 효과(filter 효과)를 적용하여 보여줌 으로써 현재 처리중임을 알려줌과 동시에 최종 결과물의 생성과정을 표시할 수 있다. 예를들면, 획득된 이미지 에 이미지 필터를 적용할 때, 프리뷰 표시되는 이미지의 크기를 변경하거나 또는 이미지의 속성(예를들면, blur 강도 및 exposure 값)을 변경시켜 사용자가 지루해 하지 않고 고급스러운 느낌을 가질 수 있게 할 수 있다. 한 실시예에 따르면, 이미지 센서에서 획득되는 이미지는 음식 이미지(food image)가 될 수 있다. 예를들 면, 피사체 중에 음식이 포함되어 있으면, 이미지 센서은 이미지 데이터를 생성할 수 있다. 이미지 데이 터는 음식 이미지 및/또는 음식의 거리 정보를 추출하기 위한 신호를 포함할 수 있다. 이미지 처리 모듈 은 음식 이미지 데이터를 처리할 수 있으며, 음식 이미지 데이터에 기반하여 거리 정보(뎁스 맵)을 생성할 수 있다. 음식 이미지는 피사체의 뎁스 맵과 전자장치의 자세 정보로 표현될 수 있다. 예를들면, 뎁스 맵은 2 PD 이미지센서을 감지하여 획득될 수 있으며,또는 상면위상차 방식, 또는 초점조절 방식을 통해서 획득될 수도 있 다. 또한 뎁스 맵은 IR, 초음파와 같은 별도의 측정 장비를 통해서 얻어질 수도 있다. 전자장치의 자세 정보는 전자장치에 탑재된 센서(예를들면, 가속도 센서 및/또는 자이로 센서)를 통해서 얻어질 수 있다. 인식 모듈은 뎁스 맵 정보 또는 음식 이미지 및 뎁스 맵 정보에 기반하여 음식 이미지의 구성 정보(음식 이미지의 범위(크기), 위치, 거리 등)를 인식할 수 있다. 예를들면, 인식 모듈은 획득된 거리 정보(Depth map, 전자장치 자세정보를 더 포함할 있음)를 기반으로 하여 피사체인 음식의 구성 정보를 인식할 수 있다. 필 터 판단 모듈은 피사체(예를들면, 음식)의 구성 정보에 기반하여 피사체에 적용될 가장 적합한 이미지 필 터를 결정할 수 있다. 결정되는 이미지 필터는 미리 준비된 복수의 이미지 필터들 중에서 하나 또는 둘 이상의 이미지 필터 조합이 될 수 있다. 예를들면, 인식 모듈은 거리 정보(예를들면, depth map)를 이용하여 피 사체인 음식 영역 및 위치를 추출할 수 있다. 필터 적용 모듈은 분할된 음식 영역 및 위치에 기반하여 가 장 적합한 이미지 필터를 결정할 수 있다. 예를들면, 인식 모듈에서 인식된 음식의 영역이 가로로 긴 형 태라면, 필터 판단 모듈은 도 14b와 같은 리니어 필터를 결정할 수 있다. 인식 모듈에서 인식된 음 식의 영역이 원형이라면, 필터 판단 모듈은 도 14d와 같은 방사형 필터를 결정할 수 있다. 필터 적용 모듈은 인식 모듈에서 출력되는 이미지 데이터에 필터 판단 모듈에서 결정된 이미 지 필터를 적용하여 새로운 이미지를 생성할 수 있다. 예를들면, 필터 적용 모듈은 이미지 필터가 적용되 는 영역의 이미지(예를들면, 인식모듈에서 인식된 주 피사체의 영역)은 선명하게 표시하고, 그 외의 주변 영역은 블러 효과를 줄 수 있다. 이미지 필터가 적용되는 영역은 거리 정보에 의해 인식되는 피사체 구성 요소 에 기반하여 설정될 수 있다. 예를들면, 이미지 필터에서 블러의 중심은 포커스된 지점이 기준이 될 수 있다. 포커스는 이미지 필터의 센터 또는 터치 등에 기반하여 다양하게 설정할 수 있다. 한 실시예에 따르면, 이미지 필터 방법은 포커스 위치는 블러 처리하지 않고 포커스 위치의 주변부는 블러 처리할 수 있다. 한 실시예에 따 르면, 이미지 필터 방법은 포커스 위치와 포커스의 주변부를 서로 강도로 블러 처리할 수 있다. 필터 적용 모듈은 이미지 필터를 적용하는 영역의 이미지들에 blur 효과와 다른 효과를 적용할 수도 있다. 예를들면, 밝은 느낌을 주는 라이팅 효과나 특정영역을 확대해주는 매크로 효과를 적용할 수도 있다. 예 를들면, 필터 판단 모듈은 음식 영역이 원형인 경우, 방사형 필터와 라이팅 필터를 결정할 수 있다. 그러면 필터 적용 모듈은 피사체가 위치되는 영역에 방사형 필터 영역을 설정하고, 피사체 이미지에 라이팅 효과를 적용할 수 있다. 상기 필터 적용 모듈에서 새로운 이미지가 생성되면, 디스플레이 모듈은 생성된 새로운 이미지를 표시할 수 있다. 디스플레이 모듈에 표시되는 이미지는 프리뷰 이미지가 될 수 있다. 전자장치는 이미지 필터를 적용하기 위해 거리 정보(depth map)을 추출하고 피사체 영역(objcet region)을 추정하는 동안, 디스플 레이 모듈을 통해 이미지 처리 중임을 표시할 수 있다. 한 실시예에 따르면, 전자장치는 이미지 필터를 적용할 피사체 영역을 계산하는 동안, 디스플레이 모듈에 이미지 처리되어 생성될 새로운 이미지와 유사한 효과를 가지는 프리뷰 이미지를 표시할 수 있다. 예를들면, 전 자장치는 프리뷰 이미지를 표시할 때, 획득된 이미지 필터(예를들면 리니어 필터, 방사형 필터 등)가 적용될 구 간을 변경하여 표시하거나, 주변 이미지의 블러 강도 및/또는 밝기(예를들면, exposure 값)를 변경시켜 표시할 수 있다. 이미지 필터가 적용되는 구간은 이미지 전체가 될 수 있다. 이미지 필터의 적용 구간 변경은 이미지 필터 내의 처리(효과)를 적용하는 구간의 변경을 의미할 수 있다. 따라서 사용자는 프리뷰 이미지를 통해 음식을 분석하여 이미지 필터 효과 및 최상의 화질로 자동 설정 (setting)되는 동작을 다이너믹하게 변경되는 과정을 확인할 수 있다. 한 실시예에 따르면, 프리뷰 이미지를 표 시할 때, 전자장치의 자세 정보에 기반하여 프리뷰 이미지를 표시할 수 있다. 예를들면, 전자장치의 자세 정보 는 센서모듈에 기반하여 획득할 수 있으며, 인식 모듈에서 필터 적용 모듈에 제공할 수 있다. 필 터 적용 모듈은 전자장치의 촬영 자세에 따라 획득되는 이미지에 이미지 필터를 적용하여 프리뷰 이미지 를 생성할 수 있다. 필터 적용 모듈은 전자장치의 자세 정보를 프리뷰 이미지와 함께 디스플레이 모듈 에 출력할 수 있으며, 디스플레이 모듈은 전자장치의 촬영 자세에 기반하는 프리뷰 이미지를 표시 할 수 있으며, 연관된 촬영 자세 정보를 표시할 수 있다. 한 실시예에서 전자장치는 프리뷰 이미지를 표시하는 중에 사용자의 선택에 따라 이미지 필터의 적용 영역(포커 스 위치)를 변경할 수 있다. 예를들면, 프리뷰 이미지에서 사용자의 지정(터치 등)에 의하여 이미지 필터 및 중 심위치를 변경할 수 있다. 예를들면, 사용자에 의해 필터 영역이 설정되면(예를들면 사용자의 드로잉(drawing) 입력이 인식되면) 인식 모듈은 사용자에 의해 설정된 영역을 구성 정보로 생성할 수 있으며, 필터 판단 모듈은 사용자에 의해 설정된 필터 영역에 기반하여 이미지 필터를 설정할 수 있다. 필터 적용 모듈 은 프리뷰 모드에서 사용자에 의해 설정된 이미지 필터를 적용하여 새로운 이미지(예를들면 프리뷰 이미 지)를 생성할 수 있다. 사용자는 터치 입력 등에 의해 이미지 필터의 포커스 지점을 설정할 수 있다. 포커스 지 점이 설정되면, 필터 적용 모듈은 사용자에 의해 설정된 포커스 지점을 중심으로 설정된 이미지 필터를 적용할 수 있다. 프리뷰 이미지를 표시하는 중에 사용자가 캡쳐 명령을 발생하면, 전자장치는 필터 적용 모듈에서 생성되 는 새로운 이미지를 메모리에 저장할 수 있다. 한 실시예에 따르면, 전자장치는 이미지 처리 모듈에서 획 득되는 이미지 데이터 및 필터 적용 모듈에서 생성되는 새로운 이미지를 모두 저장할 수 있다. 본 발명의 다양한 실시예에 따른 전자장치는, 카메라 모듈; 메모리 모듈; 및 카메라 모듈 및 메모리 모듈과 기 능적으로 연결되는 프로세서를 포함할 수 있다. 상기 프로세서는, 상기 카메라 모듈을 통해 이미지를 획득하고; 상기 획득되는 이미지에 기반하여 거리 정보를 추출하며; 상기 추출된 거리 정보에 기반하여 피사체의 이미지 처리 기법을 결정하고; 상기 결정된 이미지 처리 기법을 상기 획득된 이미지에 적용하며; 및 상기 적용된 이미 지를 표시할 수 있다. 상기 카메라 모듈은, 이미지 데이터 및 상기 전자장치와 피사체 간의 거리 정보를 추출하기 위한 신호를 생성하 는 이미지 센서를 포함할 수 있다 상기 카메라 모듈의 이미지 센서는 단위 픽셀 어레이를 포함하며, 상기 단위 픽셀은 적어도 두개의 서브 픽셀들 을 포함하고, 상기 프로세서는 상기 단위 픽셀의 서브 픽셀 신호들의 위상차에 기반하여 거리 정보를 추출하고, 상기 서브 픽셀들의 신호들을 평균화하여 이미지 데이터를 생성할 수 있다. 상기 카메라 모듈의 이미지 센서는 상면 위상차 센서 및 픽셀 센서들을 포함하며, 상기 프로세서는 상기 상면 위상차 센서 신호에 기반하여 거리 정보를 추출하고, 상기 픽셀 센서들의 신호들에 기반하여 이미지 데이터를 생성할 수 있다. 상기 프로세서는, 상기 이미지에 기반하여 거리 정보를 추출하며, 상기 거리 정보에 기반하여 피사체를 인식할 수 있다 상기 이미지 처리 기법은 이미지 필터이며, 상기 프로세서는, 상기 인식된 피사체의 구성 정보를 추출하며, 추 출된 구성 정보에 기반하여 이미지 필터를 결정하고, 상기 결정된 이미지 필터를 상기 획득된 이미지 데이터에 적용하여 새로운 이미지를 생성할 수 있다. 상기 프로세서는, 상기 이미지 처리 기법을 결정하는 동안에 프리뷰 이미지를 표시하며, 상기 프리뷰 이미지는 블러 및/또는 노출 변경 등에 기반하는 동적 필터가 적용된 프리뷰 이미지일 수 있다. 전자장치의 자세를 감지하는 센서 모듈을 더 포함하며, 상기 프로세서는, 상기 프리뷰 이미지로 표시되는 새로 운 이미지에 상기 전자장치의 자세 정보를 표시할 수 있다. 상기 프로세서는, 상기 구성 정보에서 리니어 필터, 방사형 필터, 라이팅 필터, 매크로 필터, 셀렉티브 포커스 필터들 중에 적어도 하나의 필터를 선택하여 이미지에 적용할 수 있다. 상기 프로세서는, 상기 생성되는 새로운 이미지는 이미지 필터의 포커스를 기준으로 주변 영역이 블러 처리되는 이미지일 수 있다. 상기 이미지 필터는 음식 이미지에 적용되는 이미지 필터일 수 있다. 상기 프로세서는, 캡쳐 요구시 상기 새로운 이미지를 상기 메모리 모듈에 저장할 수 있다 상기 카메라 모듈은 2차원 이미지 데이터를 생성하는 이미지 센서를 포함할 수 있다. 상기 프로세서는, 상기 이 미지 데이터에 기반하여 피사체의 윤곽선 정보를 추출하고, 상기 윤곽선 정보에 기반하여 피사체의 구성 정보를 인식하며, 상기 구성 정보에 기반하여 결정된 이미지 필터를 상기 이미지 데이터에 적용할 수 있다. 도 16은 본 발명의 다양한 전자장치에서 이미지를 처리하는 방법을 도시하는 흐름도이다. 도 16을 참조하면, 전자장치(예를들면, 도 4의 프로세서)는 동작 1611에서 촬영 명령이 발생되면 촬영 조 건을 설정하고, 카메라 모듈을 제어하여 촬영을 시작할 수 있다. 촬영 모드는 이미지 필터를 적용하는 촬영 모 드가 될 수 있다. 촬영이 시작되면, 전자장치의 이미지 센서는 렌즈를 통해 입사되는 광신호를 이미지 데이터로 변환할 수 있다. 이미지 데이터는 이미지의 밝기 정보 및 컬러 정보를 포함할 수 있으며, 피사체의 거리 정보를 추출하기 위한 신호를 포함할 수 있다. 한 실시예에서 전자장치는 이미지 데이터 및 거리 정보를 추출하기 위한 신호는 같은 시간에서 획득할 수 있다. 예를들면, 이미지 센서는 이미지 데이터를 생성하는 센서 및 거리 정보를 추출하는 센서들이 하나의 회로에 집 적되는 일체형 이미지 센서일 수 있다. 전자장치는 일체형 이미지 센서에서 이미지 데이터 및 거리정보를 추출 하기 위한 신호를 동일한 프레임 구간에서 획득할 수 있다. 한 실시예에서 전자장치는 이미지 데이터 및 거리 정보를 추출하기 위한 신호를 다른 시간에서 획득할 수 있다. 예를들면, 이미지를 센서는 이미지 데이터를 생성하는 센서 및 거리 정보를 추출하기 위한 신호를 생성하는 센 서들이 독립적으로 구성되는 스테레오 이미지 센서일 수 있다. 전자장치는 스테레오 이미지 센서에서 이미지 데 이터 및 거리 정보를 추출하기 위한 신호를 개별적으로 획득할 수 있다. 한 실시예에서 전자장치는 이미지 데이터 및 거리 정보를 추출하기 위한 신호가 맵핑되지 않을 수 있다. 예를들 면, 이미지 센서는 이미지 데이터를 생성하는 센서 및 거리 정보를 추출하기 위한 센서의 크기(해상도)가 다를 수 있다. 센서들의 크기가 다르면, 이미지 데이터 및 거리 정보를 추출하기 위한 신호들을 픽셀 단위로 맵핑할 수 있다. 전자장치는 이미지 데이터 및 거리 정보를 추출하기 위한 신호들을 영역 별로 매핑시킬 수 있다. 예를 들면 센서를 세그먼트로 분할하고, 세그먼트 별로 이미지 데이터 및 거리 정보를 추출하기 위한 신호들을 매핑 시킬 수 있다. 전자장치는 이미지 데이터를 획득하면, 동작 1615에서 3차원 이미지 데이터에 기반하여 피사체의 거리 정보를 추출할 수 있다. 피사체의 거리 정보(depth map)는 피사체와 전자장치 간의 거리 정보가 될 수 있다. 이미지 센서는 거리 정보를 추출하기 위한 신호를 생성하지 못하는 이미지 센서일 수 있다. 그러면 전자장치는 동작 1615에서 피사체의 윤곽선 정보를 추출할 수 있다. 예를들면, 전자장치는 동작 1615에서 이미지 센서에서 생성되는 이미지 데이터의 윤곽선을 추출하여 거리 정보와 유사한 정보를 생성할 수 있다. 이미지의 윤곽선은 이미지의 윤곽선, 컬러 데이터의 변화 및/또는 이미지의 밝기 등에 기반하여 추출할 수 있다. 피사체의 거리 정보를 추출한 후, 전자장치는 동작 1617에서 피사체의 거리 정보 및/또는 이미지 데이터에 기반 하여 피사체의 구성 정보를 인식할 수 있다. 예를들면, 피사체의 구성 정보는 피사체의 범위(크기), 이미지 영 역 내의 위치, 피사체와 깊이 등의 정보를 포함할 수 있다. 한 실시예에 따르면, 이미지 센서에 출력되는 이미 지 데이터 및 피사체의 거리 정보를 추출하기 위한 신호는 서로 다른 시간에 생성될 수 있다. 두 신호들을 생성 하는 시간의 동기가 이루어지 않으면, 전자장치는 동작 1617에서 이미지 데이터 및 피사체 거리 정보를 추출하 기 위한 신호의 프레임 동기를 맞춘 후, 두 신호들에 기반하여 피사체의 구성 정보를 인식할 수 있다. 한 실시예에 따르면, 이미지 센서에 출력되는 이미지 데이터 및 피사체의 거리 정보를 추출하기 위한 신호는 크 기(또는 해상도)가 서로 매핑되지 않는 신호 일 수 있다. 두 신호들이 픽셀 별 또는 영역 별로 매핑되지 않으면, 전자장치는 동작 1617에서 이미지 데이터 및 피사체 거리 정보를 추출하기 위한 신호들을 매핑하고, 매 핑되는 두 신호들에 기반하여 피사체의 구성 정보를 인식할 수 있다. 예를들면, 이미지 데이터의 해상도(센서의 사이즈)가 거리 정보를 추출하기 위한 신호들의 해상도보다 크면, 전자장치는 이미지의 사이즈를 세그먼트들로 분할하고, 이미지 세그먼트에 대응되는 거리 정보를 추출하기 위한 신호들을 매핑하고, 매핑된 두 신호들에 기 반하여 피사체의 구성 정보를 인식할 수 있다. 전자장치는 동작 1619에서 인식된 피사체의 구성정보에 기반하여 이미지 처리 기법을 결정할 수 있다. 이미지 처리 기법은 이미지 필터가 될 수 있다. 이미지 필터가 결정되면, 전자장치는 동작 1621에서 획득된 이미지 데 이터에 결정된 이미지 필터를 적용하여 새로운 이미지를 생성할 수 있다. 전자장치는 동작 1623에서 생성된 새 로운 이미지를 디스플레이에 표시할 수 있다. 디스플레이에 표시되는 이미지는 프리뷰 이미지일 수 있다. 프리뷰 이미지는 획득되는 이미지에 자동으로 설정된 이미지 필터가 적용된 이미지가 될 수 있다. 전자장치는 사용자의 촬영 자세(촬영 각도, 거리)에 따라 촬영 구도 및 초점이 변경되면, 동작 1613에서 촬영 자세에 의해 변경된 이미지를 획득할 수 있다. 전자장치는 이미지가 변경되면, 변경된 이미지 데이터에 기반하여 거리 정보 를 추출할 수 있으며, 추출된 거리 정보에 기반하여 새롭게 인식되는 피사체의 구성 정보를 인식하고, 인식된 구성정보에 기반하여 이미지 필터를 변경할 수 있다. 사용자는 디스플레이에 표시되는 프리뷰 이미지를 확인할 수 있다. 전자장치는 생성되는 이미지에 기반하여 피 사체 구성 정보의 인식 및 이미지 필터를 설정하는 동안, 이미지 필터가 적용된 이미지와 유사한 효과의 프리뷰 이미지를 표시할 수 있다. 예를들면, 전자장치는 이미지 필터를 결정하는 동안에 프리뷰 화면에 블러 및/또는 노출(exposure) 변경 등을 이용하여 프리뷰 이미지를 다양한 형태로 표시할 수 있다. 예를들면, 전자장치는 프 리뷰 화면에 변화감 있는 동적 필터(블러 적용, 노출 변경 등)를 적용하여 사용자에게 프로세싱을 통해 피사체 에 적당한 이미지필터를 추출함을 시각적으로 제공할 수 있다. 또한 프리뷰 이미지를 표시하는 중에 사용자가 드로잉 및/또는 터치 입력을 발생할 수 있다. 전자장치는 드로잉 입력이 감지되면 드로잉 입력에 기반하여 이미지 필터를 설정하고, 설정된 이미지 필터가 적용되는 이미지를 프 리뷰 이미지로 표시할 수 있다. 전자장치는 터치 입력이 감지되면, 터치 위치에 기반하여 이미지 필터의 포커스 위치를 설정하고, 설정된 이미지 필터가 적용되는 프리뷰 이미지를 표시할 수 있다. 사용자는 원하는 구도 및 이미지 필터가 적용된 새로운 이미지가 프리뷰 이미지로 표시되면 캡쳐 명령을 발생 할 수 있다. 캡쳐 명령이 발생되면, 전자장치는 동작 1625에서 이를 인식하고, 동작 1627에서 이미지 필터가 적 용된 새로운 이미지를 저장할 수 있다. 전자장치는 동작 1627에서 이미지 필터가 적용된 새로운 이미지 및 이미 지 센서에서 획득되는 이미지를 모두 저장할 수도 있다. 한 실시예에 따르면, 전자장치의 이미지 센서에서 획득되는 이미지는 음식 이미지가 될 수 있다. 사용자는 촬영 메뉴에서 음식 촬영 모드(food mode)를 설정할 수 있다. 음식 촬영 모드가 선택되면, 전자장치는 동작 1611에서 음식 촬영 모드의 설정을 인식하고, 이미지 필터를 적용하여 이미지를 생성하는 동작을 수행할 수 있다. 한 실 시예에 따르면, 2 PD 이미지 센서를 사용하는 경우, 전자장치는 이미지 데이터 및 거리 정보를 추출하기 위한 신호를 생성할 수 있다. 예를들면 단위 픽셀을 구성하는 서브 픽셀들의 신호는 거리 정보룰 추출하기 위한 신호 가 될 수 있으며, 서브 픽셀들의 평균값(또는 합) 신호는 이미지 데이터가 될 수 있다. 이미지 센서는 렌즈를 통해 입사되는 광신호를 변환하여 이미지 정보로 출력할 수 있다. 전자장치는 동작 1613에서 음식 이미지 정보 를 획득할 수 있다. 예를들면, 피사체는 음식이 될 수 있으며, 음식은 전자장치와 음식 간에 서로 다른 거리를 가질 수 있다. 예를들면, 용기 내에 음식이 들어있는 경우, 용기와 음식은 전자장치와 서로 다른 거리를 가질 수 있으며, 용기 내에 위치되는 음식들도 서로 다른 거리 정보를 가질 수 있다. 전자장치는 동작 1615에서 음식 의 이미지 데이터에서 거리 정보를 추출할 수 있다. 예를들면, 전자장치는 도 13a와 같은 음식 이미지가 획득되 면 도 13b와 같은 음식 이미지의 뎁스 맵을 추출할 수 있다. 전자장치는 동작 1617에서 뎁스 맵(또는 뎁스 맵 및 이미지 데이터)에 기반하여 이미지 필터를 적용할 음식의 구성 정보(예를들면, 음식 영역(range) 및/또는 위치, 음식 이미지의 거리 등)를 추정할 수 있다. 예를 들면, 이미지를 구성하는 피사체 중에 음식(food)이 포함되어 있다면, 전자장치는 음식의 형태, 위치 정보, 음식과 전자장치 간의 위치관계를 추정(또는 센싱)할 수 있다. 이미지에서 추출되는 거리 정보는 이미지 (예를들면, 획득되는 전체 이미지 내의 음식 이미지)의 뎁스 맵과 전자장치의 자세 정보로 표현될 수 있다. 예 를들면, 뎁스 맵은 2 PD 이미지 센서로부터 얻어질 수 있고, 또는 상면위상차 방식을 포함하는 이미지 센서를 통해 획득될 수도 있다. 또한 뎁스 맵은 IR 또는 초음파와 같은 별도의 측정 장비를 통해서 얻어질 수도 있다. 전자장치의 자세 정보는 전자장치에 탑재된 센서를 통해 획득될 수 있다. 전자장치는 동작 1619에서 거리 정보(Depth map, 전자장치 자세정보)를 기반으로 하여, 피사체에 적용될 가장 적합한 이미지 필터를 결정할 수 있다. 이미지 필터는 다양한 형태의 이미지 필터들이 될 수 있으며, 메모리에 저장될 수 있다. 전자장치는 인식된 피사체의 구성 정보(예를들면, 음식 이미지의 영역 및 위치 등)에 따라 미 리 준비된 복수의 이미지 필터들 중에서 중에서 하나 또는 둘 이상의 이미지 필터들을 설정할 수 있다. 한 실시예에 따르면, 음식 이미지가 선형 형태를 가지면 전자장치는 도 6a와 같은 리니어 필터를 설정할 수 있 다. 한 실시예에 따르면 전자장치는 음식 이미지가 원형 또는 다각형의 형태를 가지는 용기 내에 담겨 있으면 도 6b와 같은 방사형 필터를 설정할 수 있다. 한 실시예에 따르면, 전자장치는 상대적인 뎁스의 변화가 스무스 (smooth)한 경우에는 리니어 필터를 적용할 수 있다. 한 실시예에 따르면, 전자장치는 뎁스의 변화가 급격한 경 우는 그 영역을 기준으로 방사형 필터를 적용할 수 있다. 한 실시예에 따르면 음식 이미지의 밝기가 어두우면, 전자장치는 도 6c와 같은 라이팅 필터를 설정할 수 있다. 한 실시예에 따르면 음식 이미지가 이미지 내에서 작 은 크기를 가지면, 전자장치는 도 6d와 같은 매크로 필터를 설정할 수 있다. 한 실시예에 따르면, 음식 이미지 를 강조하는 경우, 전자장치는 도 6e와 같은 셀렉티브 포커스 필터를 설정할 수 있다. 한 실시예에 따르면 음식 이미지가 선형 형태를 가지며 밝기가 어두우면 전자장치는 리니어 필터 및 라이팅 필 터를 함께 설정할 수 있다. 한 실시예에 따르면 이미지가 원형의 용기에 담겨 있고 이미지 내에서 작은 크기를 가지면, 전자장치는 방사형 필터 및 매크로 필터를 함께 설정할 수 있다. 한 실시예에 따르면 이미지가 타원형 의 용기에 담겨 있고 타원형 내의 음식 이미지를 강조할 경우, 전자장치는 방사형 필터 및 셀렉티브 포커스 필 터를 함께 설정할 수 있다. 전자장치는 거리 정보에 기반하여 전체 이미지에서 음식 이미지 영역을 추정하고, 추정된 음식 이미지에 적용할 최적의 이미지 필터를 설정할 수 있다. 이미지 필터를 설정한 후, 전자장치는 동작 1621에서 음식 이미지에 설 정된 이미지 필터를 적용하여 새로운 이미지를 생성할 수 있다. 예를들면, 전자장치는 이미지 필터(예를들면, 리니어 필터, 방사형 필터)가 설정된 영역은 선명하게 표시하고, 음식 이미지 이외의 주변 영역 이미지들은 블 러 처리할 수 있다. 예를들면, 방사형 필터 및 라이팅 필터가 설정된 경우, 전자장치는 방사형 필터가 설정된 영역의 음식 이미지들에는 라이팅 효과를 주어 음식 이미지가 강조되게 표시할 수 있다. 그리고 이미지 필터가 설정되지 않은 영역의 이미지들은 블러 처리할 수 있다. 한 실시예에 따르면, 전자장치는 이미지 필터를 적용하 여 새로운 이미지를 생성할 때, 밝은 느낌을 주는 라이팅 효과나 특정영역을 확대해주는 매크로 효과를 적용할 수 있다. 전자장치는 동작 1623에서 이미지 필터가 적용된 새로운 이미지를 프리뷰 이미지로 표시할 수 있다. 전자장치는 이미지 필터가 적용된 프리뷰 이미지를 제공하기 전에 다른 이미지를 표시할 수 있다. 예를들면, 전자장치는 뎁 스 맵과 이미지를 분석하여 이미지 필터를 적용할 영역(object region)을 계산하는 기간 동안 사용자에게 처리 중임을 알려주는 표시를 제공할 수 있다. 즉, 전자장치는 이미지 필터가 적용된 새로운 이미지를 표시하기 전에 프리뷰 화면에 최종 촬영이미지에 적용할 효과 또는 그와 유사한 효과(filter효과)를 적용하여 표시할 수 있다. 전자장치는 이미지 필터를 적용하는 새로운 이미지를 생성하는 동안, 사용자에게0 현재 이미지 처리 중임을 알 려줌과 동시에 최종 결과물의 생성과정을 보여줌으로써, 사용자가 지루하지 않고, 이미지 처리 기능의 고급스러 움을 느끼게 해줄 수 있다. 예를들면, 이미지 필터를 적용할 때, 전자장치는 음식 이미지의 크기를 변경하거나 표시(blur 강도 및/또는 exposure 값)을 변경시켜 표시할 수 있다. 예를들면, 전자장치가 음식 이미지를 분석하 여 효과 및 최상의 화질로 자동 세팅됨을 알려주는 동작을 다이너믹하게 프리뷰 화면으로 표시할 수 있다. 본 발명의 다양한 실시예에 따른 전자장치의 동작 방법은, 이미지 센서를 통해 이미지를 획득하는 동작; 상기 획득되는 이미지에서 거리 정보를 추출하는 동작; 상기 추출된 거리 정보에 기반하여 피사체의 이미지 처리 기 법을 결정하는 동작; 상기 결정된 이미지 처리 기법을 상기 획득된 이미지에 적용하여 새로운 이미지를 생성하 는 동작; 및 상기 새로운 이미지를 이미지를 프리뷰 이미지로 표시하는 동작을 포함할 수 있다. 상기 이미지를 획득하는 동작은, 이미지 데이터를 획득하는 동작; 및 상기 전자장치와 피사체 간의 거리 정보를 추출하기 위한 신호를 획득하는 동작을 포함할 수 있다. 상기 이미지 처리 기법을 결정하는 동작은, 상기 뎁스 맵에 기반하여 피사체의 구성 정보를 인식하는 동작; 및 상기 구성 정보에 기반하여 이미지를 처리하기 위한 이미지 필터를 설정하는 동작을 포함할 수 있다. 상기 이미지 처리 기법을 결정하는 동작은, 상기 이미지 데이터의 윤곽선에 기반하여 구성 정보를 인식하는 동 작; 및 상기 구성 정보에 기반하여 이미지를 처리하기 위한 이미지 필터를 설정하는 동작을 포함할 수 있다 상기 이미지 필터를 설정하는 동작은, 인식된 피사체의 구성 정보에 기반하여 리니어 필터, 방사형 필터, 라이 팅 필터, 매크로 필터, 셀렉티브 포커스 필터들 중에 적어도 하나의 필터를 설정할 수 있다 상기 새로운 이미지를 생성하는 동작은, 상기 이미지 필터의 포커스를 기준으로 주변 영역이 블러 처리되는 이 미지를 생성할 수 있다. 상기 이미지 처리 기법을 결정하는 동작은, 프리뷰 이미지를 표시하는 동작을 더 포함하며, 상기 프리뷰 이미지 를 표시하는 동작은, 블러 및/또는 노출 변경 등에 기반하는 동적 필터가 적용된 프리뷰 이미지를 표시할 수 있 다. 도면 도면1 도면2 도면3 도면4 도면5 도면6a 도면6b 도면6c 도면6d 도면6e 도면7 도면8 도면9a 도면9b 도면9c 도면10a 도면10b 도면11a 도면11b 도면12a 도면12b 도면13a 도면13b 도면14a 도면14b 도면14c 도면14d 도면15 도면16"}
{"patent_id": "10-2016-0020009", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 다양한 실시예들에 따른 네트워크 환경 시스템의 블록도를 도시하는 도면이다. 도 2는 다양한 실시예들에 따른 전자 장치의 블록도를 도시하는 도면이다. 도 3은 다양한 실시예들에 따른 프로그램 모듈의 블록도를 도시하는 도면이다. 도 4는 본 발명의 다양한 실시예에 따른 전자장치의 구성을 도시하는 도면이다. 도 5는 본 발명의 다양한 실시예에 따른 전자장치가 획득되는 이미지를 처리하여 새로운 이미지를 생성하는 구 성을 도시하는 도면이다. 도 6a - 도 6e는 본 발명의 다양한 실시예에 따른 이미지 필터들을 도시하는 도면이다. 도 7은 본 발명의 다양한 실시예에 따른 이미지 센서의 구성을 도시하는 도면이다. 도 8은 본 발명의 일 실시예에 따른 이미지 센서의 픽셀 어레이의 구성을 도시하는 도면이다. 도 9a - 도 9c는 본 발명의 다양한 실시예에 따른 이미지 센서의 단위 픽셀 및 서브 픽셀들의 구조를 도시하는 도면이다. 도 10a는 본 발명의 다양한 실시 예에 따른 이미지 센서의 단위 픽셀 및 서브 픽셀들의 에를 도시하는 도면이다. 도 11a및 도 11b는 상면 위상차 센서를 포함하는 이미지 센서의 동작을 설명하기 위한 도면이다. 도 12a 및 12b는 본 발명의 다양한 실시 예들 중 하나에 따른, 이미지 센서의 일부분을 확대하여 도시한다. 도 13a - 도 13b는 본 발명의 다양한 실시예에 따른 전자장치에 획득되는 이미지 및 거리 정보의 표시 예를 도 시하는 도면이다. 도 14a - 도 14d는 본 발명의 다양한 실시예에 따른 전자장치의 이미지 처리 예를 도시하는 도면이다.도 15는 본 발명의 다양한 실시예에 따른 이미지 처리 장치의 구성을 도시하는 도면이다. 도 16은 본 발명의 다양한 전자장치에서 이미지를 처리하는 방법을 도시하는 흐름도이다."}
