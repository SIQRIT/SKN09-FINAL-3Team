{"patent_id": "10-2022-0161339", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0088252", "출원번호": "10-2022-0161339", "발명의 명칭": "딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 방법 및 장치", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "우 톈"}}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 방법에 있어서, 딥 러닝 모델의 전반적 생성 과정에 환경 준비를 제공하는 기초 실행 환경을 목표 장치에 구축하는 단계;서비스 수요 및 하드웨어 수요 중 적어도 하나에 따라, 상기 기초 실행 환경에서 딥 러닝 모델의 기초 기능을생성하여 제1 처리 결과를 얻는 단계; 상기 제1 처리 결과에 기반하여 상기 기초 실행 환경에서 상기 딥 러닝 모델의 확장 기능을 생성하여 제2 처리결과를 얻는 단계; 및 사전 설정 테스트 스크립트를 이용하여 상기 제2 처리 결과에 대해 기능 테스트를 진행하여 테스트 결과를 출력하는 단계;를 포함하는 방법."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 목표 장치에 상기 기초 실행 환경을 구축하는 단계는,상기 목표 장치의 하드웨어 구성 정보를 획득하는 단계;상기 하드웨어 구성 정보에 기반하여 상기 목표 장치의 소프트웨어 구성 정보를 결정하는 단계; 및상기 하드웨어 구성 정보와 상기 소프트웨어 구성 정보를 이용하여 상기 기초 실행 환경을 구축하는 단계;를 포함하는 방법."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 하드웨어 구성 정보에 기반하여 상기 목표 장치의 소프트웨어 구성 정보를 결정하는 단계는,상기 하드웨어 구성 정보에 기반하여, 상기 목표 장치의 운영 체제 정보, 딥 러닝 프레임워크 정보, 모델 베이스 정보, 사전 트레이닝 모델 및 상기 사전 트레이닝 모델에 대응되는 트레이닝 데이터와 예측 데이터를 결정하는 단계;를 포함하는 방법."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 서비스 수요 및 상기 하드웨어 수요에 따라, 상기 기초 실행 환경에서 상기 딥 러닝 모델의 기초 기능을생성하여 상기 제1 처리 결과를 얻는 단계는, 상기 딥 러닝 모델의 전반적 생성 과정에 포함되는 상기 딥 러닝 모델의 개발, 트레이닝 및 추론을 위한 복수의처리 단계를 결정하는 단계; 및상기 서비스 수요 및 상기 하드웨어 수요 중 적어도 하나에 따라, 상기 기초 실행 환경에서 상기 복수의 처리단계 중 각 처리 단계의 기초 기능을 생성하여 상기 제1 처리 결과를 얻는 단계;를 포함하는 방법."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 서비스 수요 및 상기 하드웨어 수요 중 적어도 하나에 따라, 상기 기초 실행 환경에서 상기 복수의 처리단계 중 각 처리 단계의 기초 기능을 생성하여 상기 제1 처리 결과를 얻는 단계는, 공개특허 10-2023-0088252-3-상기 서비스 수요에 따라 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 제1 부분 처리 단계의 기초 기능을 생성하여 제3 처리 결과를 얻는 단계;상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 제2 부분 처리 단계의 기초 기능을 생성하여 제4 처리 결과를 얻는 단계;상기 서비스 수요와 상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 제3 부분처리 단계의 기초 기능을 생성하여 제5 처리 결과를 얻는 단계; 및상기 제3 처리 결과, 상기 제4 처리 결과 및 상기 제5 처리 결과를 이용하여 상기 복수의 처리 단계 중 각 처리단계의 기초 기능을 생성하여 상기 제1 처리 결과를 얻는 단계;를 포함하는 방법."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 서비스 수요에 따라 상기 기초 실행 환경에서 상기 제1 부분 처리 단계의 기초 기능을 생성하여 상기 제3처리 결과를 얻는 단계는, 상기 서비스 수요에 따라 모델 베이스로부터 상기 기초 실행 환경에서 사용될 모델 알고리즘을 선택하는 단계;상기 서비스 수요에 따라 상기 기초 실행 환경에서 사용될 모델 압축 방식을 선택하는 단계;상기 서비스 수요에 따라 상기 기초 실행 환경에서 사용될 예측 배포 방식을 선택하는 단계; 및상기 모델 알고리즘, 상기 모델 압축 방식 및 상기 예측 배포 방식을 상기 제3 처리 결과로 결정하는 단계;를포함하는 방법."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 제2 부분 처리 단계의 기초 기능을 생성하여 제4 처리 결과를 얻는 단계는, 상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 사용될 제1 소프트웨어/하드웨어 환경과 제2 소프트웨어/하드웨어 환경을 구성하되, 상기 제1 소프트웨어/하드웨어 환경은 모델 트레이닝에 사용되는 소프트웨어/하드웨어 환경이고, 상기 제2 소프트웨어/하드웨어 환경은 모델 추론 배포에 사용되는 소프트웨어/하드웨어 환경인 단계; 및상기 제1 소프트웨어/하드웨어 환경과 상기 제2 소프트웨어/하드웨어 환경을 상기 제4 처리 결과로 결정하는 단계;를 포함하는 방법."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 서비스 수요와 상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 제3 부분처리 단계의 기초 기능을 생성하여 제5 처리 결과를 얻는 단계는, 상기 서비스 수요와 상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 사용될 모델 트레이닝 방식을 선택하는 단계; 및상기 모델 트레이닝 방식을 상기 제5 처리 결과로 결정하는 단계;를 포함하는 방법."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제4항에 있어서,상기 복수의 처리 단계는, 모델 알고리즘 선택 단계;모델 트레이닝 소프트웨어/하드웨어 환경 구성 단계;공개특허 10-2023-0088252-4-모델 트레이닝 방식 선택 단계;모델 압축 방식 선택 단계;모델 트레이닝 단계;모델 저장 단계;모델 예측 배포 방식 선택 단계; 및모델 추론 배포 소프트웨어/하드웨어 환경 구성 단계;를 포함하는 방법."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제4항에 있어서,상기 제1 처리 결과에 기반하여 상기 기초 실행 환경에서 상기 딥 러닝 모델의 확장 기능을 생성하여 상기 제2처리 결과를 얻는 단계는,상기 제1 처리 결과에 기반하여, 상기 복수의 처리 단계 중 각 처리 단계에 상기 기초 기능 외의 상기 확장 기능을 추가하고, 각 처리 단계에 대응되는 복수의 선택될 기능을 결정하는 단계; 및각 처리 단계에 대응되는 복수의 선택될 기능에서 각각 어느 한 기능을 선택하여 조합하고, 상기 딥 러닝 모델의 전반적 생성 과정을 수행하여 상기 제2 처리 결과를 얻는 단계;를 포함하는 방법."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,각 처리 단계에 대응되는 복수의 선택될 기능에서 각각 어느 한 기능을 선택하여 조합하고, 상기 딥 러닝 모델의 전반적 생성 과정을 수행하여 상기 제2 처리 결과를 얻는 단계는,모델 알고리즘 선택 단계에서, 조합될 모델 알고리즘을 랜덤으로 선택하는 단계;모델 트레이닝 소프트웨어/하드웨어 환경 구성 단계에서, 제1 조합될 소프트웨어/하드웨어 환경을 랜덤으로 결정하는 단계;모델 트레이닝 방식 선택 단계에서, 조합될 모델 트레이닝 방식을 랜덤으로 선택하는 단계;모델 압축 방식 선택 단계에서, 조합될 모델 압축 방식을 랜덤으로 선택하는 단계;모델 예측 배포 방식 선택 단계에서, 조합될 모델 예측 배포 방식을 랜덤으로 선택하는 단계;모델 추론 배포 소프트웨어/하드웨어 환경 구성 단계에서, 제2 조합될 소프트웨어/하드웨어 환경을 랜덤으로 결정하는 단계; 및각 처리 단계에 대응되는 복수의 선택될 기능 중 각 조합이 모두 수행 완료될 때까지 상기 조합될 모델 알고리즘, 상기 제1 조합될 소프트웨어/하드웨어 환경, 상기 조합될 모델 트레이닝 방식, 상기 조합될 모델 압축방식, 상기 조합될 모델 예측 배포 방식 및 상기 제2 조합될 소프트웨어/하드웨어 환경을 조합하고, 모델 개발,트레이닝 및 추론의 전반적 생성 과정을 수행하여 상기 제2 처리 결과를 얻는 단계;를 포함하는 방법."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제4항에 있어서,상기 사전 설정 테스트 스크립트를 이용하여 상기 제2 처리 결과에 대해 기능 테스트를 진행하여 상기 테스트결과를 출력하는 단계는, 상기 사전 설정 테스트 스크립트를 이용하여 상기 딥 러닝 모델의 전반적 생성 과정에서 적어도 하나의 테스트포인트를 설정하는 단계; 및상기 적어도 하나의 테스트 포인트에 기반하여 상기 제2 처리 결과에 대해 기능 테스트를 진행하여 상기 테스트결과를 출력하는 단계;를 포함하는 방법.공개특허 10-2023-0088252-5-청구항 13 제12항에 있어서,상기 제2 처리 결과는, 상기 복수의 처리 단계 중 각 처리 단계에 대응되는 복수의 선택될 기능 중 다양한 조합을 포함하고, 상기 적어도 하나의 테스트 포인트에 기반하여 상기 제2 처리 결과에 대해 기능 테스트를 진행하여 상기 테스트결과를 출력하는 단계는,상기 적어도 하나의 테스트 포인트에 기반하여 각 처리 단계에 대응되는 복수의 선택될 기능 중 다양한 조합에대해 기능 테스트를 진행하여 상기 테스트 결과를 출력하는 단계;를 포함하는 방법."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 테스트 결과는, 상기 딥 러닝 모델의 식별 정보;상기 딥 러닝 모델과 연관된 소프트웨어/하드웨어 구성 정보;상기 딥 러닝 모델의 속성 테스트 정보; 및상기 딥 러닝 모델의 예측 결과 정보;를 포함하는 방법."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 장치에 있어서, 딥 러닝 모델의 전반적 생성 과정에 환경 준비를 제공하는 기초 실행 환경을 목표 장치에 구축하는 구축 모듈;서비스 수요 및 하드웨어 수요 중 적어도 하나에 따라, 상기 기초 실행 환경에서 상기 딥 러닝 모델의 기초 기능을 생성하여 제1 처리 결과를 얻는 제1 생성 모듈; 상기 제1 처리 결과에 기반하여 상기 기초 실행 환경에서 상기 딥 러닝 모델의 확장 기능을 생성하여 제2 처리결과를 얻는 제2 생성 모듈; 및사전 설정 테스트 스크립트를 이용하여 상기 제2 처리 결과에 대해 기능 테스트를 진행하여 테스트 결과를 출력하는 테스트 모듈;을 포함하는 장치."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 구축 모듈은,상기 목표 장치의 하드웨어 구성 정보를 획득하고;상기 하드웨어 구성 정보에 기반하여 상기 목표 장치의 소프트웨어 구성 정보를 결정하며;상기 하드웨어 구성 정보와 상기 소프트웨어 구성 정보를 이용하여 상기 기초 실행 환경을 구축하는 장치."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 구축 모듈은,상기 하드웨어 구성 정보에 기반하여, 상기 목표 장치의 운영 체제 정보, 딥 러닝 프레임워크 정보, 모델 베이스 정보, 사전 트레이닝 모델 및 상기 사전 트레이닝 모델에 대응되는 트레이닝 데이터와 예측 데이터를 결정하는 장치.공개특허 10-2023-0088252-6-청구항 18 제15항에 있어서, 상기 제1 생성 모듈은, 상기 딥 러닝 모델의 전반적 생성 과정에 포함되는 상기 딥 러닝 모델의 개발, 트레이닝 및 추론을 위한 복수의처리 단계를 결정하고;상기 서비스 수요 및 상기 하드웨어 수요 중 적어도 하나에 따라, 상기 기초 실행 환경에서 상기 복수의 처리단계 중 각 처리 단계의 기초 기능을 생성하여 상기 제1 처리 결과를 얻는 장치."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 제1 생성 모듈은, 상기 서비스 수요에 따라 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 제1 부분 처리 단계의 기초 기능을 생성하여 제3 처리 결과를 얻고;상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 제2 부분 처리 단계의 기초 기능을 생성하여 제4 처리 결과를 얻으며;상기 서비스 수요와 상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 제3 부분처리 단계의 기초 기능을 생성하여 제5 처리 결과를 얻고;상기 제3 처리 결과, 상기 제4 처리 결과 및 상기 제5 처리 결과를 이용하여 상기 복수의 처리 단계 중 각 처리단계의 기초 기능을 생성하여 상기 제1 처리 결과를 얻는 장치."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 제1 생성 모듈은,상기 서비스 수요에 따라 모델 베이스로부터 상기 기초 실행 환경에서 사용될 모델 알고리즘을 선택하고;상기 서비스 수요에 따라 상기 기초 실행 환경에서 사용될 모델 압축 방식을 선택하며;상기 서비스 수요에 따라 상기 기초 실행 환경에서 사용될 예측 배포 방식을 선택하고;상기 모델 알고리즘, 상기 모델 압축 방식 및 상기 예측 배포 방식을 상기 제3 처리 결과로 결정하는 장치."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제19항에 있어서,상기 제1 생성 모듈은,상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 사용될 제1 소프트웨어/하드웨어 환경과 제2 소프트웨어/하드웨어 환경을 구성하되, 상기 제1 소프트웨어/하드웨어 환경은 모델 트레이닝에 사용되는 소프트웨어/하드웨어 환경이고, 상기 제2 소프트웨어/하드웨어 환경은 모델 추론 배포에 사용되는 소프트웨어/하드웨어 환경이고;상기 제1 소프트웨어/하드웨어 환경과 상기 제2 소프트웨어/하드웨어 환경을 상기 제4 처리 결과로 결정하는 장치."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제19항에 있어서, 상기 제1 생성 모듈은,상기 서비스 수요와 상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 사용될 모델 트레이닝 방식을 선택하고;공개특허 10-2023-0088252-7-상기 모델 트레이닝 방식을 상기 제5 처리 결과로 결정하는 장치."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제18항에 있어서,상기 복수의 처리 단계는, 모델 알고리즘 선택 단계;모델 트레이닝 소프트웨어/하드웨어 환경 구성 단계;모델 트레이닝 방식 선택 단계;모델 압축 방식 선택 단계;모델 트레이닝 단계;모델 저장 단계;모델 예측 배포 방식 선택 단계; 및모델 추론 배포 소프트웨어/하드웨어 환경 구성 단계;를 포함하는 장치."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제18항에 있어서, 상기 제2 생성 모듈은, 상기 제1 처리 결과에 기반하여, 상기 복수의 처리 단계 중 각 처리 단계에 상기 기초 기능 외의 상기 확장 기능을 추가하고, 각 처리 단계에 대응되는 복수의 선택될 기능을 결정하고;각 처리 단계에 대응되는 복수의 선택될 기능에서 각각 어느 한 기능을 선택하여 조합하고, 상기 딥 러닝 모델의 전반적 생성 과정을 수행하여 상기 제2 처리 결과를 얻는 장치."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제24항에 있어서, 상기 제2 생성 모듈은, 모델 알고리즘 선택 단계에서, 조합될 모델 알고리즘을 랜덤으로 선택하고;모델 트레이닝 소프트웨어/하드웨어 환경 구성 단계에서, 제1 조합될 소프트웨어/하드웨어 환경을 랜덤으로 결정하며;모델 트레이닝 방식 선택 단계에서, 조합될 모델 트레이닝 방식을 랜덤으로 선택하고;모델 압축 방식 선택 단계에서, 조합될 모델 압축 방식을 랜덤으로 선택하며;모델 예측 배포 방식 선택 단계에서, 조합될 모델 예측 배포 방식을 랜덤으로 선택하고;모델 추론 배포 소프트웨어/하드웨어 환경 구성 단계에서, 제2 조합될 소프트웨어/하드웨어 환경을 랜덤으로 결정하며;각 처리 단계에 대응되는 복수의 선택될 기능 중 각 조합이 모두 수행 완료될 때까지 상기 조합될 모델 알고리즘, 상기 제1 조합될 소프트웨어/하드웨어 환경, 상기 조합될 모델 트레이닝 방식, 상기 조합될 모델 압축방식, 상기 조합될 모델 예측 배포 방식 및 상기 제2 조합될 소프트웨어/하드웨어 환경을 조합하고, 모델 개발,트레이닝 및 추론의 전반적 생성 과정을 수행하여 상기 제2 처리 결과를 얻는 장치."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제18항에 있어서, 상기 테스트 모듈은,공개특허 10-2023-0088252-8-상기 사전 설정 테스트 스크립트를 이용하여 상기 딥 러닝 모델의 전반적 생성 과정에서 적어도 하나의 테스트포인트를 설정하고;상기 적어도 하나의 테스트 포인트에 기반하여 상기 제2 처리 결과에 대해 기능 테스트를 진행하여 상기 테스트결과를 출력하는 장치."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제26항에 있어서,상기 제2 처리 결과는, 상기 복수의 처리 단계 중 각 처리 단계에 대응되는 복수의 선택될 기능 중 다양한 조합을 포함하고, 상기 테스트 모듈은,상기 적어도 하나의 테스트 포인트에 기반하여 각 처리 단계에 대응되는 복수의 선택될 기능 중 다양한 조합에대해 기능 테스트를 진행하여 상기 테스트 결과를 출력하는 장치."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제26항에 있어서,상기 테스트 결과는, 상기 딥 러닝 모델의 식별 정보;상기 딥 러닝 모델과 연관된 소프트웨어/하드웨어 구성 정보;상기 딥 러닝 모델의 속성 테스트 정보; 및상기 딥 러닝 모델의 예측 결과 정보;를 포함하는 장치."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하는 전자기기에 있어서,상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되고, 상기 명령은 상기 적어도하나의 프로세서에 의해 실행되어 상기 적어도 하나의 프로세서가 제1항 내지 제14항 중 어느 한 항에 따른 방법을 수행할 수 있도록 하는 전자기기."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "컴퓨터 명령이 저장된 비일시적 컴퓨터 판독 가능 저장 매체에 있어서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제14항 중 어느 한 항에 따른 방법을 수행하도록 하는 비일시적컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2022-0161339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램에 있어서,프로세서에 의해 실행될 시 제1항 내지 제14항 중 어느 한 항에 따른 방법을 구현하는, 컴퓨터 판독가능 저장매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0161339", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 방법 및 장치를 제공하며, 컴퓨터 분야에 관한 것이다. 구체적인 구현 수단은, 딥 러닝 모델의 전반적 생성 과정에 환경 준비를 제공하는 기초 실 행 환경을 목표 장치에 구축하는 단계; 서비스 수요 및/또는 하드웨어 수요에 따라, 기초 실행 환경에서 딥 러닝 모델의 기초 기능을 생성하여 제1 처리 결과를 얻는 단계; 제1 처리 결과에 기반하여 기초 실행 환경에서 딥 러 닝 모델의 확장 기능을 생성하여 제2 처리 결과를 얻는 단계; 및 사전 설정 테스트 스크립트를 이용하여 제2 처 리 결과에 대해 기능 테스트를 진행하여 테스트 결과를 출력하는 단계;를 포함한다. 관련 기술에서 모델 구축 시 모델 설계의 전반적 프로세스를 설정할 수 없는 기술적 문제를 해결한다. 사전 설정 테스트 스크립트를 이용하여 제2 처리 결과에 대해 기능 테스트를 진행하여, 모델 설계의 전반적 프로세스의 신뢰성을 보장한다."}
{"patent_id": "10-2022-0161339", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 컴퓨터 기술 분야에 관한 것으로, 특히 딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용 하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0161339", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술의 발전과 더불어, 많은 기업들이 딥 러닝 프레임워크를 이용하여 딥 러닝 모델을 개발함으로써 각자 서비스 시나리오의 문제를 해결하고 있다. 전형적인 프로세스는, 서비스 수요 측에서 자체의 서비스 시나 리오에 따라 수요를 제출하고, 알고리즘 엔지니어가 적합한 기초 알고리즘을 선택하고, 적합한 데이터를 준비한 후, 딥 러닝 프레임워크를 이용하여 데이터 처리, 알고리즘 최적화, 파라미터 최적화, 모델 트레이닝 등 일련의 동작을 거쳐 수요에 부합되는 딥 러닝 모델을 트레이닝하며, 실제 서비스 생산 환경에 배포함으로써 최종적으로 서비스를 발표하는 것이다. 그러나 상기 해결수단을 이용하여 문제를 해결할 경우, 인공 처리 과정이 지나치게 복잡하며, 인공 처리를 거쳐 얻은 알고리즘이 서비스 환경에 적용되지 않는 문제가 존재할 수 있다. 상술한 문제에 대해, 아직 효과적인 해결수단이 제시되지 않고 있다. 본 발명은 딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 방법 및 장치를 제공한다. 본 발명의 일 측면에 따르면, 딥 러닝 모델의 전반적 생성 과정에 환경 준비를 제공하는 기초 실행 환경을 목표 장치에 구축하는 단계; 서비스 수요 및/또는 하드웨어 수요에 따라, 상기 기초 실행 환경에서 상기 딥 러닝 모 델의 기초 기능을 생성하여 제1 처리 결과를 얻는 단계; 상기 제1 처리 결과에 기반하여 상기 기초 실행 환경에 서 상기 딥 러닝 모델의 확장 기능을 생성하여 제2 처리 결과를 얻는 단계; 및 사전 설정 테스트 스크립트를 이 용하여 상기 제2 처리 결과에 대해 기능 테스트를 진행하여 테스트 결과를 출력하는 단계;를 포함하는 딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 방법을 제공한다. 바람직하게, 상기 목표 장치에 상기 기초 실행 환경을 구축하는 단계는, 상기 목표 장치의 하드웨어 구성 정보 를 획득하는 단계; 상기 하드웨어 구성 정보에 기반하여 상기 목표 장치의 소프트웨어 구성 정보를 결정하는 단 계; 및 상기 하드웨어 구성 정보와 상기 소프트웨어 구성 정보를 이용하여 상기 기초 실행 환경을 구축하는 단 계;를 포함한다. 바람직하게, 상기 하드웨어 구성 정보에 기반하여 상기 목표 장치의 소프트웨어 구성 정보를 결정하는 단계는, 상기 하드웨어 구성 정보에 기반하여, 상기 목표 장치의 운영 체제 정보, 딥 러닝 프레임워크 정보, 모델 베이 스 정보, 및 사전 트레이닝 모델 및 상기 사전 트레이닝 모델에 대응되는 트레이닝 데이터와 예측 데이터를 결 정하는 단계;를 포함한다. 바람직하게, 상기 서비스 수요 및 상기 하드웨어 수요에 따라, 상기 기초 실행 환경에서 상기 딥 러닝 모델의 기초 기능을 생성하여 상기 제1 처리 결과를 얻는 단계는, 상기 딥 러닝 모델의 전반적 생성 과정에 포함되는 상기 딥 러닝 모델의 개발, 트레이닝 및 추론을 위한 복수의 처리 단계를 결정하는 단계; 및 상기 서비스 수요 및/또는 상기 하드웨어 수요에 따라, 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 각 처리 단계의 기초 기능을 생성하여 상기 제1 처리 결과를 얻는 단계;를 포함한다. 바람직하게, 상기 서비스 수요 및/또는 상기 하드웨어 수요에 따라, 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 각 처리 단계의 기초 기능을 생성하여 상기 제1 처리 결과를 얻는 단계는, 상기 서비스 수요에 따라 상 기 기초 실행 환경에서 상기 복수의 처리 단계 중 제1 부분 처리 단계의 기초 기능을 생성하여 제3 처리 결과를 얻는 단계; 상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 제2 부분 처리 단계 의 기초 기능을 생성하여 제4 처리 결과를 얻는 단계; 상기 서비스 수요와 상기 하드웨어 수요에 따라 상기 기 초 실행 환경에서 상기 복수의 처리 단계 중 제3 부분 처리 단계의 기초 기능을 생성하여 제5 처리 결과를 얻는 단계; 및 상기 제3 처리 결과, 상기 제4 처리 결과 및 상기 제5 처리 결과를 이용하여 상기 복수의 처리 단계 중 각 처리 단계의 기초 기능을 생성하여 상기 제1 처리 결과를 얻는 단계;를 포함한다. 바람직하게, 상기 서비스 수요에 따라 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 제1 부분 처리 단계 의 기초 기능을 생성하여 제3 처리 결과를 얻는 단계는, 상기 서비스 수요에 따라 모델 베이스로부터 상기 기초 실행 환경에서 사용될 모델 알고리즘을 선택하는 단계; 상기 서비스 수요에 따라 상기 기초 실행 환경에서 사용 될 모델 압축 방식을 선택하는 단계; 상기 서비스 수요에 따라 상기 기초 실행 환경에서 사용될 예측 배포 방식 을 선택하는 단계; 및 상기 모델 알고리즘, 상기 모델 압축 방식 및 상기 예측 배포 방식을 상기 제3 처리 결과 로 결정하는 단계;를 포함한다.바람직하게, 상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 제2 부분 처리 단 계의 기초 기능을 생성하여 상기 제4 처리 결과를 얻는 단계는, 상기 하드웨어 수요에 따라 상기 기초 실행 환 경에서 사용될 제1 소프트웨어/하드웨어 환경과 제2 소프트웨어/하드웨어 환경을 구성하되, 상기 제1 소프트웨 어/하드웨어 환경은 모델 트레이닝에 사용되는 소프트웨어/하드웨어 환경이고, 상기 제2 소프트웨어/하드웨어 환경은 모델 추론 배포에 사용되는 소프트웨어/하드웨어 환경인 단계; 및 상기 제1 소프트웨어/하드웨어 환경과 상기 제2 소프트웨어/하드웨어 환경을 상기 제4 처리 결과로 결정하는 단계;를 포함한다. 바람직하게, 상기 서비스 수요와 상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 제3 부분 처리 단계의 기초 기능을 생성하여 제5 처리 결과를 얻는 단계는, 상기 서비스 수요와 상기 하드웨 어 수요에 따라 상기 기초 실행 환경에서 사용될 모델 트레이닝 방식을 선택하는 단계; 및 상기 모델 트레이닝 방식을 상기 제5 처리 결과로 결정하는 단계;를 포함한다. 바람직하게, 상기 복수의 처리 단계는, 모델 알고리즘 선택 단계; 모델 트레이닝 소프트웨어/하드웨어 환경 구 성 단계; 모델 트레이닝 방식 선택 단계; 모델 압축 방식 선택 단계; 모델 트레이닝 단계; 모델 저장 단계; 모 델 예측 배포 방식 선택 단계; 및 모델 추론 배포 소프트웨어/하드웨어 환경 구성 단계;를 포함한다. 바람직하게, 상기 제1 처리 결과에 기반하여 상기 기초 실행 환경에서 상기 딥 러닝 모델의 확장 기능을 생성하 여 상기 제2 처리 결과를 얻는 단계는, 상기 제1 처리 결과에 기반하여, 상기 복수의 처리 단계 중 각 처리 단 계에 상기 기초 기능 외의 상기 확장 기능을 추가하고, 각 처리 단계에 대응되는 복수의 선택될 기능을 결정하 는 단계; 및 각 처리 단계에 대응되는 복수의 선택될 기능에서 각각 어느 한 기능을 선택하여 조합하고, 상기 딥 러닝 모델의 전반적 생성 과정을 수행하여 상기 제2 처리 결과를 얻는 단계;를 포함한다. 바람직하게, 각 처리 단계에 대응되는 복수의 선택될 기능에서 각각 어느 한 기능을 선택하여 조합하고, 상기 딥 러닝 모델의 전반적 생성 과정을 수행하여 상기 제2 처리 결과를 얻는 단계는, 모델 알고리즘 선택 단계에서, 조합될 모델 알고리즘을 랜덤으로 선택하는 단계; 모델 트레이닝 소프트웨어/하드웨어 환경 구성 단 계에서, 제1 조합될 소프트웨어/하드웨어 환경을 랜덤으로 결정하는 단계; 모델 트레이닝 방식 선택 단계에서, 조합될 모델 트레이닝 방식을 랜덤으로 선택하는 단계; 모델 압축 방식 선택 단계에서, 조합될 모델 압축 방식 을 랜덤으로 선택하는 단계; 모델 예측 배포 방식 선택 단계에서, 조합될 모델 예측 배포 방식을 랜덤으로 선택 하는 단계; 모델 추론 배포 소프트웨어/하드웨어 환경 구성 단계에서, 제2 조합될 소프트웨어/하드웨어 환경을 랜덤으로 결정하는 단계; 및 각 처리 단계에 대응되는 복수의 선택될 기능 중 각 조합이 모두 수행 완료될 때까 지 상기 조합될 모델 알고리즘, 상기 제1 조합될 소프트웨어/하드웨어 환경, 상기 조합될 모델 트레이닝 방식, 상기 조합될 모델 압축 방식, 상기 조합될 모델 예측 배포 방식 및 상기 제2 조합될 소프트웨어/하드웨어 환경 을 조합하고, 모델 개발, 트레이닝 및 추론의 전반적 생성 과정을 수행하여 상기 제2 처리 결과를 얻는 단계;를 포함한다. 바람직하게, 상기 사전 설정 테스트 스크립트를 이용하여 상기 제2 처리 결과에 대해 기능 테스트를 진행하여 상기 테스트 결과를 출력하는 단계는, 상기 사전 설정 테스트 스크립트를 이용하여 상기 딥 러닝 모델의 전반적 생성 과정에서 적어도 하나의 테스트 포인트를 설정하는 단계; 및 상기 적어도 하나의 테스트 포인트에 기반하 여 상기 제2 처리 결과에 대해 기능 테스트를 진행하여 상기 테스트 결과를 출력하는 단계;를 포함한다. 바람직하게, 상기 제2 처리 결과는, 상기 복수의 처리 단계 중 각 처리 단계에 대응되는 복수의 선택될 기능 중 다양한 조합을 포함하고, 상기 적어도 하나의 테스트 포인트에 기반하여 상기 제2 처리 결과에 대해 기능 테스 트를 진행하여 상기 테스트 결과를 출력하는 단계는, 상기 적어도 하나의 테스트 포인트에 기반하여 각 처리 단 계에 대응되는 복수의 선택될 기능 중 다양한 조합에 대해 기능 테스트를 진행하여 상기 테스트 결과를 출력하 는 단계;를 포함한다. 바람직하게, 상기 테스트 결과는, 상기 딥 러닝 모델의 식별 정보; 상기 딥 러닝 모델과 연관된 소프트웨어/하 드웨어 구성 정보; 상기 딥 러닝 모델의 속성 테스트 정보; 및 상기 딥 러닝 모델의 예측 결과 정보;를 포함한 다. 본 발명의 다른 일 측면에 따르면, 딥 러닝 모델의 전반적 생성 과정에 환경 준비를 제공하는 기초 실행 환경을 목표 장치에 구축하는 구축 모듈; 서비스 수요 및/또는 하드웨어 수요에 따라, 상기 기초 실행 환경에서 상기 딥 러닝 모델의 기초 기능을 생성하여 제1 처리 결과를 얻는 제1 생성 모듈; 상기 제1 처리 결과에 기반하여 상 기 기초 실행 환경에서 상기 딥 러닝 모델의 확장 기능을 생성하여 제2 처리 결과를 얻는 제2 생성 모듈; 및 사 전 설정 테스트 스크립트를 이용하여 상기 제2 처리 결과에 대해 기능 테스트를 진행하여 테스트 결과를 출력하는 테스트 모듈;을 포함하는 딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 장치를 제공한다. 바람직하게, 상기 구축 모듈은, 상기 목표 장치의 하드웨어 구성 정보를 획득하고; 상기 하드웨어 구성 정보에 기반하여 상기 목표 장치의 소프트웨어 구성 정보를 결정하며; 상기 하드웨어 구성 정보와 상기 소프트웨어 구 성 정보를 이용하여 상기 기초 실행 환경을 구축한다. 바람직하게, 상기 구축 모듈은, 상기 하드웨어 구성 정보에 기반하여, 상기 목표 장치의 운영 체제 정보, 딥 러 닝 프레임워크 정보, 모델 베이스 정보, 사전 트레이닝 모델 및 상기 사전 트레이닝 모델에 대응되는 트레이닝 데이터와 예측 데이터를 결정한다. 바람직하게, 상기 제1 생성 모듈은, 상기 딥 러닝 모델의 전반적 생성 과정에 포함되는 상기 딥 러닝 모델의 개 발, 트레이닝 및 추론을 위한 복수의 처리 단계를 결정하고; 상기 서비스 수요 및/또는 상기 하드웨어 수요에 따라, 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 각 처리 단계의 기초 기능을 생성하여 상기 제1 처리 결과를 얻는다. 바람직하게, 상기 제1 생성 모듈은, 상기 서비스 수요에 따라 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 제1 부분 처리 단계의 기초 기능을 생성하여 제3 처리 결과를 얻고; 상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 제2 부분 처리 단계의 기초 기능을 생성하여 제4 처리 결과를 얻으며; 상기 서비스 수요와 상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 상기 복수의 처리 단계 중 제3 부분 처리 단계의 기초 기능을 생성하여 제5 처리 결과를 얻고; 상기 제3 처리 결과, 상기 제4 처리 결과 및 상기 제 5 처리 결과를 이용하여 상기 복수의 처리 단계 중 각 처리 단계의 기초 기능을 생성하여 상기 제1 처리 결과를 얻는다. 바람직하게, 상기 제1 생성 모듈은, 상기 서비스 수요에 따라 모델 베이스로부터 상기 기초 실행 환경에서 사용 될 모델 알고리즘을 선택하고; 상기 서비스 수요에 따라 상기 기초 실행 환경에서 사용될 모델 압축 방식을 선 택하며; 상기 서비스 수요에 따라 상기 기초 실행 환경에서 사용될 예측 배포 방식을 선택하고; 상기 모델 알고 리즘, 상기 모델 압축 방식 및 상기 예측 배포 방식을 상기 제3 처리 결과로 결정한다. 바람직하게, 상기 제1 생성 모듈은, 상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 사용될 제1 소프트웨 어/하드웨어 환경과 제2 소프트웨어/하드웨어 환경을 구성하되, 상기 제1 소프트웨어/하드웨어 환경은 모델 트 레이닝에 사용되는 소프트웨어/하드웨어 환경이고, 상기 제2 소프트웨어/하드웨어 환경은 모델 추론 배포에 사 용되는 소프트웨어/하드웨어 환경이고; 상기 제1 소프트웨어/하드웨어 환경과 상기 제2 소프트웨어/하드웨어 환 경을 상기 제4 처리 결과로 결정한다. 바람직하게, 상기 제1 생성 모듈은, 상기 서비스 수요와 상기 하드웨어 수요에 따라 상기 기초 실행 환경에서 사용될 모델 트레이닝 방식을 선택하고; 상기 모델 트레이닝 방식을 상기 제5 처리 결과로 결정한다. 바람직하게, 상기 복수의 처리 단계는, 모델 알고리즘 선택 단계; 모델 트레이닝 소프트웨어/하드웨어 환경 구 성 단계; 모델 트레이닝 방식 선택 단계; 모델 압축 방식 선택 단계; 모델 트레이닝 단계; 모델 저장 단계; 모 델 예측 배포 방식 선택 단계; 및 모델 추론 배포 소프트웨어/하드웨어 환경 구성 단계;를 포함한다. 바람직하게, 상기 제2 생성 모듈은, 상기 제1 처리 결과에 기반하여, 상기 복수의 처리 단계 중 각 처리 단계에 상기 기초 기능 외의 상기 확장 기능을 추가하고, 각 처리 단계에 대응되는 복수의 선택될 기능을 결정하고; 각 처리 단계에 대응되는 복수의 선택될 기능에서 각각 어느 한 기능을 선택하여 조합하고, 상기 딥 러닝 모델의 전반적 생성 과정을 수행하여 상기 제2 처리 결과를 얻는다. 바람직하게, 상기 제2 생성 모듈은, 모델 알고리즘 선택 단계에서, 조합될 모델 알고리즘을 랜덤으로 선택하고; 모델 트레이닝 소프트웨어/하드웨어 환경 구성 단계에서, 제1 조합될 소프트웨어/하드웨어 환경을 랜덤으로 결 정하며; 모델 트레이닝 방식 선택 단계에서, 조합될 모델 트레이닝 방식을 랜덤으로 선택하고; 모델 압축 방식 선택 단계에서, 조합될 모델 압축 방식을 랜덤으로 선택하며; 모델 예측 배포 방식 선택 단계에서, 조합될 모델 예측 배포 방식을 랜덤으로 선택하고; 모델 추론 배포 소프트웨어/하드웨어 환경 구성 단계에서, 제2 조합될 소 프트웨어/하드웨어 환경을 랜덤으로 결정하며; 각 처리 단계에 대응되는 복수의 선택될 기능 중 각 조합이 모두 수행 완료될 때까지 상기 조합될 모델 알고리즘, 상기 제1 조합될 소프트웨어/하드웨어 환경, 상기 조합될 모델 트레이닝 방식, 상기 조합될 모델 압축 방식, 상기 조합될 모델 예측 배포 방식 및 상기 제2 조합될 소프트웨어 /하드웨어 환경을 조합하고, 모델 개발, 트레이닝 및 추론의 전반적 생성 과정을 수행하여 상기 제2 처리 결과를 얻는다. 바람직하게, 상기 테스트 모듈은, 상기 사전 설정 테스트 스크립트를 이용하여 상기 딥 러닝 모델의 전반적 생 성 과정에서 적어도 하나의 테스트 포인트를 설정하고; 상기 적어도 하나의 테스트 포인트에 기반하여 상기 제2 처리 결과에 대해 기능 테스트를 진행하여 상기 테스트 결과를 출력한다. 바람직하게, 상기 제2 처리 결과는, 상기 복수의 처리 단계 중 각 처리 단계에 대응되는 복수의 선택될 기능 중 다양한 조합을 포함하고, 상기 테스트 모듈은, 상기 적어도 하나의 테스트 포인트에 기반하여 각 처리 단계에 대응되는 복수의 선택될 기능 중 다양한 조합에 대해 각각 기능 테스트를 진행하여 상기 테스트 결과를 출력한 다. 바람직하게, 상기 테스트 결과는, 상기 딥 러닝 모델의 식별 정보; 상기 딥 러닝 모델과 연관된 소프트웨어/하 드웨어 구성 정보; 상기 딥 러닝 모델의 속성 테스트 정보; 및 상기 딥 러닝 모델의 예측 결과 정보;를 포함한 다. 본 발명의 다른 일 측면에 따르면, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하는 전자기기를 제공하되, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명 령이 저장되고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행되어 상기 적어도 하나의 프로세서가 상 기 어느 한 항에 따른 방법을 수행할 수 있도록 한다. 본 발명의 다른 일 측면에 따르면, 컴퓨터 명령이 저장된 비일시적 컴퓨터 판독 가능 저장 매체를 제공하며, 상 기 컴퓨터 명령은 상기 컴퓨터가 상기 어느 한 항에 따른 방법을 수행하도록 한다. 본 발명의 다른 일 측면에 따르면, 프로세서에 의해 실행될 시 상기 어느 한 항에 따른 방법을 구현하는 컴퓨터 프로그램을 포함하는 컴퓨터 프로그램 제품을 제공한다. 여기서, 본 부분에 설명된 내용은 본 발명의 실시예의 관건적 또는 중요한 특징을 표시하기 위한 것이 아니며, 본 발명의 범위를 제한하는 것도 아니다. 본 발명의 기타 특징은 이하의 명세서를 통해 용이하게 이해될 수 있 을 것이다."}
{"patent_id": "10-2022-0161339", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면과 함께 본 발명의 예시적 실시예를 설명하며, 여기에는 본 발명의 실시예의 다양한 세부사항이 포함 되어 이해를 도우며, 이들은 단지 예시적인 것으로 이해되어야 한다. 따라서 당업자라면, 본 발명의 범위 및 사 상을 벗어나지 않으면서 여기서 설명된 실시예에 대해 다양한 변경 및 수정을 가할 수 있음을 이해해야 할 것이다. 마찬가지로, 간단명료하기 위해, 이하의 설명에서는 공지의 기능 및 구조에 대한 설명을 생략한다. 본 발명은 도 1에 도시된 바와 같은 딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 방법을 제공한다. 도 1은 본 발명의 실시예 1에 따른 딥 러닝 모델의 생성 방법의 흐름도이며, 도 1에 도시된 바와 같 이, 상기 방법은, 딥 러닝 모델의 전반적 생성 과정에 환경 준비를 제공하는 기초 실행 환경을 목표 장치에 구축하는 단계(S101); 서비스 수요 및/또는 하드웨어 수요에 따라, 기초 실행 환경에서 딥 러닝 모델의 기초 기능을 생성하여 제1 처 리 결과를 얻는 단계(S102); 제1 처리 결과에 기반하여 기초 실행 환경에서 딥 러닝 모델의 확장 기능을 생성하여 제2 처리 결과를 얻는 단 계(S103); 및 사전 설정 테스트 스크립트를 이용하여 제2 처리 결과에 대해 기능 테스트를 진행하여 테스트 결과를 출력하는 단계(S104);를 포함한다. 상기 단계를 통해, 목표 장치에 딥 러닝 모델의 전반적 생산 과정을 구축할 수 있는 기초 실행 환경을 구축하고, 서비스 수요 및/또는 하드웨어 수요에 따라 기초 실행 환경에서 딥 러닝 모델의 기초 기능을 생성하 여 제1 처리 결과를 얻으며, 제1 처리 결과에 기초하여 기초 실행 환경에서 딥 러닝 모델의 확장 기능을 생성하 여 제2 처리 결과를 얻은 다음, 사전 설정 테스트 스크립트를 이용하여 제2 처리 결과에 대해 기능 테스트를 하 여 테스트 결과를 출력한다. 실행 환경에서 딥 러닝의 기초 기능을 생성하는 것은 서비스 수요 및/또는 하드웨 어 수요에 따라 얻은 것이므로, 실제 시나리오와 서비스의 수요에 부합될 수 있다. 또한, 제1 처리 결과에 기반 하여 기초 실행 환경에서 딥 러닝 모델의 확장 기능을 생성함으로써 제1 처리 결과에 따라 맞춤형으로 확장 기 능의 설정을 진행할 수 있다. 최종적으로, 제2 결과에 대한 테스트를 통해, 모델의 기능을 효과적으로 검증할 수 있어, 관련 기술에서 모델의 환경과 기능 구축 시 모델 설계의 전반적 프로세스를 설정할 수 없는 기술적 문 제를 해결한다. 사전 설정 테스트 스크립트를 이용하여 제2 처리 결과에 대해 기능 테스트를 진행하고, 출력된 테스트 결과는 모델 설계의 전반적 프로세스의 신뢰성을 보장한다. 바람직한 실시예로, 목표 장치에 기초 실행 환경을 구축한다. 목표 장치는, 실행 환경을 구축할 수 있고, 모델 의 구축, 트레이닝과 검증을 수행할 수 있는 장치, 예를 들어, 호스트 등이며, 이에 대해 한정하지 않는다. 기 초 실행 환경은, 딥 러닝 모델의 전반적 생성 과정에 환경 준비를 제공하는 실행 환경이며, 즉, 개발 전에 기초 환경 준비 작업을 진행해야 한다. 실제 서비스와 수요가 다름에 따라, 목표 장치의 하드웨어 조건이 다르고, 구 축된 기초 실행 환경도 다르다. 따라서, 목표 장치에 기초 실행 환경 구축 시, 우선 목표 장치의 하드웨어 구성 정보를 획득하고, 상기 하드웨어 구성 정보에 기반하여 목표 장치의 소프트웨어 구성 정보를 결정할 수 있다. 하드웨어 구성 정보를 통해, 목표 장치의 다양한 소프트웨어 정보를 결정할 수 있고, 예를 들어, 목표 장치의 운영 체제 정보, 딥 러닝 프레임워크 정보, 모델 베이스 정보, 사전 트레이닝 모델 및 사전 트레이닝 모델에 대 응되는 트레이닝 데이터와 예측 데이터 등을 결정할 수 있다. 나아가, 하드웨어 구성 정보 및 소프트웨어 구성 정보를 이용하여, 기초 실행 환경을 구축한다. 하드웨어 구성 정보 및 소프트웨어 구성 정보를 통해 구축된 기 초 실행 환경은 상기 목표 장치에 적용됨을 보장하고, 후속 개발의 순서적 실행을 보장할 수 있으며, 관련 기술 에서 실제 서비스 환경 하드웨어 종류가 매우 다양하고, 소프트웨어 버전도 매우 다양하여 수많은 정보에서 적 용되는 실행 환경을 정확하게 구성할 수 없는 문제를 해결한다. 바람직한 실시예로, 서비스 수요 및/또는 하드웨어 수요에 따라 기초 실행 환경에서 딥 러닝 모델의 기초 기능 을 생성하여 제1 처리 결과를 얻는다. 서비스 수요 및/또는 하드웨어 수요를 통해 기초 기능을 결정하여, 기초 기능이 현재의 서비스 수요를 만족시키도록 보장할 수 있어, 모델이 순조롭고 순서적으로 동작되도록 할 수 있 다. 바람직한 실시예로, 딥 러닝 모델의 전반적 생성 과정은, 복수의 처리 단계를 포함하며, 예를 들어, 전반적 생 성 과정에서 모델 알고리즘 선택 단계, 모델 트레이닝 소프트웨어/하드웨어 환경 구성 단계, 모델 트레이닝 방 식 선택 단계, 모델 압축 방식 선택 단계, 모델 트레이닝 단계, 모델 저장 단계, 모델 예측 배포 방식 선택 단 계, 및 모델 추론 배포 소프트웨어/하드웨어 환경 구성 단계 등을 포함한다. 따라서, 상기 다양한 단계에 대해 상응한 설정을 진행하여 딥 러닝 모델을 생성해야 한다. 상기 다양한 처리 단계는 딥 러닝 모델의 개발, 딥 러 닝 모델의 트레이닝, 딥 러닝 모델의 추론에 이용되어 모델의 개발, 트레이닝, 추론, 검증의 전반적 프로세스를 구현할 수 있다. 따라서, 기초 실행 환경에서 딥 러닝 모델의 기초 기능을 생성하여 제1 처리 결과를 얻을 시, 우선 딥 러닝 모델의 전반적 생성 과정에 포함되는 복수의 처리 단계를 결정하고, 서비스 수요 및/또는 하드웨 어 수요에 따라, 상이한 처리 단계에 대해 기초 기능을 설계하며, 기초 실행 환경에서 복수의 처리 단계 중 각 처리 단계의 기초 기능을 생성하여 제1 처리 결과를 얻음으로써, 관련 기술에서 알고리즘 모델의 선택이 어렵고, 전반적 프로세스의 지원을 받을 수 없는 등 문제를 해결한다. 바람직한 실시예로, 서비스 수요 및/또는 하드웨어 수요에 따라 기초 실행 환경에서 복수의 처리 단계 중 각 처 리 단계의 기초 기능을 생성하여 제1 처리 결과를 얻는 단계는, 서비스 수요에 따라 기초 실행 환경에서 복수의 처리 단계 중 제1 부분 처리 단계의 기초 기능을 생성하여 제3 처리 결과를 얻는 단계; 하드웨어 수요에 따라 기초 실행 환경에서 복수의 처리 단계 중 제2 부분 처리 단계의 기초 기능을 생성하여 제4 처리 결과를 얻는 단 계; 및 서비스 수요와 하드웨어 수요에 따라 기초 실행 환경에서 복수의 처리 단계 중 제3 부분 처리 단계의 기 초 기능을 생성하여 제5 처리 결과를 얻는 단계;를 포함한다. 즉, 서비스 수요, 하드웨어 수요, 서비스 수요와하드웨어 수요에 따라 각각 기초 기능을 설정하고, 우선 대응되는 처리 결과를 각각 얻은 후, 각각 얻은 처리 결과, 즉, 제3 처리 결과, 제4 처리 결과 및 제5 처리 결과를 이용하여 복수의 처리 단계 중 각 처리 단계의 기 초 기능을 생성하여 제1 처리 결과를 얻는다. 서비스 수요, 하드웨어 수요, 서비스 수요와 하드웨어 수요에 대 한 상응한 설정을 통해, 얻어진 제1 처리 결과가 보다 적응적이고, 실제 시나리오와 수요에 보다 적용되도록 할 수 있다. 이하, 서비스 수요, 하드웨어 수요, 서비스 수요와 하드웨어 수요에 대해 각각 기초 기능을 설정하여, 우선 대응되는 처리 결과를 각각 얻는 과정에 대해 상세하게 설명한다. 1) 서비스 수요에 따라 기초 실행 환경에서 제1 부분 처리 단계의 기초 기능을 생성하여 제3 처리 결과를 얻는 다. 서비스 수요에 따라 기초 실행 환경에서 제1 부분 처리 단계의 기초 기능을 생성하는 것은, 모델 알고리즘, 모델 압축 방식, 예측 배포 방식 등을 포함할 수 있다. 즉, 상술한 과정은 서비스 수요에 따라 모델 베이스로부 터 기초 실행 환경에서 사용될 모델 알고리즘을 선택하고, 서비스 수요에 따라 기초 실행 환경에서 사용될 모델 압축 방식을 선택하며, 서비스 수요에 따라 기초 실행 환경에서 사용될 예측 배포 방식을 선택하는 것이다. 서 비스 수요에 따라 모델 알고리즘을 선택함으로써, 관련 기술에서 딥 러닝 오픈 소스 알고리즘 논문이 많아, 적 합하고 신뢰성 있는 알고리즘의 선택이 매우 어려운 문제를 해결한다. 서비스 수요에 따라 모델 압축 방식을 선 택하되, 모델 압축 방식은, Slim 기술을 이용할 수 있고, Slim 기술 모델 선택을 진행하여, 큰 트레이닝 모델을 압축해 모델 부피를 감소함으로써, 예측 속도를 향상시키는 효과를 달성한다. 서비스 수요에 따라 배포 방식을 예측하여, 실제 배포 시, 우선 모델을 Inference 모드와 같은 표준화 포맷으로 저장하고, 상기 포맷에 따라 전 환하여 배포를 구현함으로써, 관련 기술에서 예측 배포가 다양한 배포 방식과 관련된 경우 순조롭게 배포될 수 없는 문제를 해결한다. 2) 하드웨어 수요에 따라 기초 실행 환경에서 복수의 처리 단계 중 제2 부분 처리 단계의 기초 기능을 생성하여 제4 처리 결과를 얻는다. 하드웨어 수요에 따라 기초 실행 환경에서 제2 부분 처리 단계의 기초 기능을 생성하 는 것은, 소프트웨어/하드웨어 환경 등을 포함할 수 있다. 소프트웨어/하드웨어 환경은 상이한 상황에서의 소프 트웨어/하드웨어 환경, 예를 들어, 모델 트레이닝에 사용되는 소프트웨어/하드웨어 환경, 모델 추론 배포에 사 용되는 소프트웨어/하드웨어 환경 등으로 구분될 수 있다. 상이한 상황에서의 소프트웨어/하드웨어 환경에 대해 모두 설정해야 한다. 즉, 상술한 과정은, 하드웨어 수요에 따라 기초 실행 환경에서 사용될 제1 소프트웨어/하 드웨어 환경 및 제2 소프트웨어/하드웨어 환경을 구성하는 것이며, 제1 소프트웨어/하드웨어 환경은 모델 트레 이닝에 사용되는 소프트웨어/하드웨어 환경이고, 제2 소프트웨어/하드웨어 환경은 모델 추론 배포에 사용되는 소프트웨어/하드웨어 환경이다. 하드웨어 수요에 따라 소프트웨어/하드웨어 환경을 결정하여 모델이 상기 소프 트웨어/하드웨어 환경에서 사용 가능한 것이도록 하며, 즉, 상기 목표 장치는 모델이 상기 소프트웨어/하드웨어 환경에서 동작될 수 있도록 한다. 또한, 하드웨어 수요와 소프트웨어/하드웨어 환경은 서로 적응되므로, 모델 정상 동작을 보장하는 전제 하에, 모델 생성 속도를 효과적으로 가속화할 수 있고, 모델 생성 효율을 향상시킬 수 있다. 3) 서비스 수요 및 하드웨어 수요에 따라 기초 실행 환경에서 복수의 처리 단계 중 제3 부분 처리 단계의 기초 기능을 생성하여 제5 처리 결과를 얻는다. 서비스 수요 및 하드웨어 수요에 따라 기초 실행 환경에서 복수의 처 리 단계 중 제3 부분 처리 단계의 기초 기능을 생성하는 것은, 모델의 트레이닝 방식 등을 포함할 수 있다. 즉, 서비스 수요와 하드웨어 수요에 따라 기초 실행 환경 중 사용될 모델 트레이닝 방식을 선택한다. 서비스 수요와 하드웨어 수요를 통해 기초 실행 환경에서 사용될 모델 트레이닝 방식을 선택한다. 서비스 수요와 하드웨어 수 요에 따라 모델의 트레이닝 방식을 결정하여 관련 기술에서 모델 생성 시 지원이 불충분한 문제, 예를 들어, 트 레이닝 부분에 관한 분산식, 혼합 정밀도 능력 지원이 부족한 문제를 해결한다. 바람직한 실시예로, 제1 처리 결과에 기반하여 기초 실행 환경에서 딥 러닝 모델의 확장 기능을 생성하여 제2 처리 결과를 얻는다. 기초 기능 개발 기초 하에, 핵심 단계를 보완 보충하여 전반적 프로세스에서 보다 전면적 이고, 보다 보완된 기능 지원을 구현한다. 확장 기능 생성 시, 제1 처리 결과에 기반하여, 복수의 처리 단계 중 각 처리 단계에 기초 기능 외의 확장 기능을 추가하고, 각 처리 단계에 대응되는 복수의 선택될 기능을 결정하 며, 각 처리 단계 중 대응되는 복수의 선택될 기능으로부터 임의의 기능을 각각 선택하여 조합하고 딥 러닝 모 델의 전반적 생성 과정을 수행하여 제2 처리 결과를 얻는 단계를 포함할 수 있다. 또한, 복수의 처리 단계 중의 기능 확장 시, 인접한 두 처리 단계에 따라 각 단계의 상이한 상황을 결정하여 상이한 상황에 대해 상응한 설정 을 진행함으로써 처리 단계 중 확장된 기능들이 효과적이도록 보장할 수 있으며, 나아가 생성된 모델의 유효성 을 보장한다. 상기 단계를 통해, 모델의 기능을 확장할 수 있을 뿐만 아니라 모델 수량의 확장이 매우 용이해지 도록 할 수 있어, 실제 서비스 수요를 구현할 수 있는 복수의 모델을 편리하고 신속하게 생성할 수 있다. 바람직한 실시예로, 각 처리 단계에 대응되는 다양한 선택될 기능으로부터 임의의 기능을 각각 선택하여 조합하 고, 딥 러닝 모델의 전반적 생성 과정을 수행하여 제2 처리 결과를 얻는 것은, 예를 들어, 모델 알고리즘 선택 단계에서, 조합될 모델 알고리즘을 랜덤으로 선택하고, 모델 트레이닝 소프트웨어/하드웨어 환경 구성 단계에서, 제1 조합될 소프트웨어/하드웨어 환경을 랜덤으로 결정하며, 모델 트레이닝 방식 선택 단계에서, 조 합될 모델 트레이닝 방식을 랜덤으로 선택하고, 모델 압축 방식 선택 단계에서, 조합될 모델 압축 방식을 랜덤 으로 선택하며, 모델 예측 배포 방식 선택 단계에서, 조합될 모델 예측 배포 방식을 랜덤으로 선택하고, 모델 추론 배포 소프트웨어/하드웨어 환경 구성 단계에서, 제2 조합될 소프트웨어/하드웨어 환경을 랜덤으로 결정하 는 등을 포함한다. 나아가 각 처리 단계에 대응되는 다양한 선택될 기능 중 다양한 조합이 전부 수행 완료될 때 까지, 조합될 모델 알고리즘, 제1 조합될 소프트웨어/하드웨어 환경, 조합될 모델 트레이닝 방식, 조합될 모델 압축 방식, 조합될 모델 예측 배포 방식 및 제2 조합될 소프트웨어/하드웨어 환경을 조합하고 모델 개발, 트레 이닝 및 추론의 전반적 생성 과정을 수행하여, 제2 처리 결과를 얻는다. 이를 통해 모델의 수를 대량 확장하여, 가능한 경우에 대해 모두 검증함으로써, 실제 서비스 수요를 구현할 수 있는 모델을 편리하고 신속하게 생성하 고 결정할 수 있다. 바람직한 실시예로, 사전 설정 테스트 스크립트를 이용하여 제2 처리 결과에 대해 기능 테스트를 진행하고, 테 스트 결과를 출력한다. 테스트 결과는 딥 러닝 모델의 식별 정보; 딥 러닝 모델과 연관된 소프트웨어/하드웨어 구성 정보; 딥 러닝 모델의 속성 테스트 정보; 및 딥 러닝 모델의 예측 결과 정보를 포함한다. 예를 들어, 딥 러닝 모델의 식별 정보는 상기 모델 생성 과정에서 사용되는 소프트웨어 버전번호 정보를 포함할 수 있고; 소프 트웨어/하드웨어 구성 정보는 모델 트레이닝에 사용되는 소프트웨어/하드웨어 구성 정보, 모델 추론 배포에 사 용되는 소프트웨어/하드웨어 구성 정보를 포함할 수 있으며; 속성 테스트 정보는 모델 트레이닝 과정의 속도, 정밀도, 손실값, 소모시간, 모델의 성능 등 정보를 포함할 수 있고; 예측 결과 정보는 모델 명칭, 예측 데이터 등을 포함하는 예측 결과를 포함할 수 있다. 상이한 측면에 관한 테스트 결과를 출력함으로써 명확하고 명료하 게 각 측면의 정보를 이해할 수 있다. 사전 설정 테스트 스크립트를 이용하여 제2 처리 결과에 대해 기능 테스 트를 진행함으로써, 전면적으로 모델에 대해 평가하여, 정확하고 신뢰성이 높은 테스트 결과를 얻을 수 있다. 사전 설정 테스트 스트립트는 원 터치 동작될 수 있으며, 자동화로 동작될 수 있다. 원 터치 동작되는 사전 설 정 테스트 스크립트를 사용하여, 모델을 다양한 복잡한 소프트웨어/하드웨어 환경에 배포할 수 있고, 자동화 사 전 설정 테스트 스크립트를 이용하여, 모델 전반적 프로세스 기능 지원 검증을 신속하게 실행시키고 테스트 결 과를 출력할 수 있으며, 결과를 통해 다양한 환경에서의 수행 가능성 검증을 결정할 수 있다. 또한, 주기적으로 사전 설정 테스트 스크립트를 이용하여 테스트를 진행할 수 있고, 엄격한 진입 테스트 요구와 정기적인 테스트 실행을 통해 모델의 안정성과 신뢰성을 보장할 수 있다. 일 바람직한 실시예로, 사전 설정 테스트 스크립트를 이용하여 딥 러닝 모델의 전반적 생성 과정에서 적어도 하 나의 테스트 포인트를 설정하고, 적어도 하나의 테스트 포인트에 기반하여 제2 처리 결과에 대해 기능 테스트를 진행하여 테스트 결과를 출력한다. 즉, 테스트 포인트는 테스트를 수행하여 테스트 결과를 얻는 기능을 가지며, 예를 들어, 테스트 결과는 딥 러닝 모델의 속성 테스트 정보를 포함하고, 이를 통해 소모 시간 정보를 얻는다. 상기 소모 시간 정보는 테스트 포인트의 설정을 통해 얻을 수 있다. 예를 들어, 모델 생성 시, 하나의 테스트 포인트를 구축하고, 모델 트레이닝 마감 시 하나의 테스트 포인트를 구축하며, 이 두 개의 테스트 포인트는 각 각 당시의 시간을 기록하고, 이 두 개의 테스트 포인트를 감하면 모델 트레이닝의 소모 시간을 얻을 수 있어, 소모 시간의 테스트 결과를 얻는다. 또한 구체적인 상황에 따라 테스트 포인트에 기타 상응한 설정을 진행할 수 있으므로, 테스트 포인트는 다양한 기능 테스트를 수행할 수 있어 대응되는 다양한 테스트 결과를 얻는다. 테스 트 포인트 설정을 통해, 다양한 시나리오에서의 트레이닝으로부터 배포에 이르는 완전한 프로세스를 신속하게 완료할 수 있고, 모델이 순조롭게 개발, 트레이닝, 추론의 전반적 프로세서 기능을 완성하도록 보장할 수 있다. 그리고, 복수의 처리 단계 중 각 처리 단계에 대응되는 다양한 선택될 기능 중 다양한 조합은, 적어도 하나의 테스트 포인트에 기반하여 제2 처리 결과에 대해 기능 테스트 진행 시, 출력된 테스트 결과는 적어도 하나의 테 스트 포인트에 기반하여 각 처리 단계에 대응되는 복수의 선택될 기능 중 각 조합에 대해 각각 기능 테스트를 진행하여 출력한 테스트 결과도 포함한다. 상술한 실시예 및 바람직한 실시예에 기반하여 바람직한 실시형태를 제공하며, 이하에서 구체적으로 설명한다. 본 발명의 바람직한 실시형태에서는, 딥 러닝 프레임워크에 기반하여 모델 개발, 트레이닝, 추론의 전반적 프로 세스를 지원하는 해결수단을 제공하며, 상응한 시스템을 구성한다. 시스템은 완전한 코드, 파일, 보조 툴 및 규 범을 포함하며, 딥 러닝 모델의 개발, 트레이닝, 추론의 전반적 프로세스에 대한 딥 러닝 프레임워크의 지원을 보장한다.도 2는 본 발명의 바람직한 실시형태에 따른 시스템 구조도이다. 도 2에 도시된 바와 같이, 풍부한 산업 차원 모델 베이스로부터 모델 선택, 트레이닝 소프트웨어/하드웨어 환경 모델 선택, 모델 트레이닝, Slim 기술 모델 선택, 모델 저장, 예측 배포 방식 및 배포 소프트웨어/하드웨어 환경 모델 선택 등 단계를 포함한다. 도 2에 도 시된 시스템은, 상기 단계를 통해 딥 러닝 모델 개발, 트레이닝, 추론의 전반적 프로세스 기능의 지원을 커버한 다. 소프트웨어/하드웨어 환경은 Linux, windows, macOS에서의 GPU, CPU, NPU, DCU, XPU 등 환경을 포함하고; 모델 트레이닝은 분산식 트레이닝, 혼합 정밀도 트레이닝 등 트레이닝 방식을 포함하며; 예측 배포 방식은 Inference, serving, lite, js(JavaScrpit) 등 배포 방식을 포함하고; 소프트웨어/하드웨어 배포 환경은 Linux, windows, macOS에서의 GPU, CPU, NPU, DCU, XPU, ARM, Web 등 환경을 포함한다. Slim 기술 모델 선택은 주로 모델 압축(프루닝, 양자화 포함)을 표시하며, 주로 일반 트레이닝 모델이 비교적 크므로, 압축을 통해 모 델 부피를 감소시키고 예측 속도를 향상시킨다. 이하, 본 발명의 바람직한 실시형태를 상세하게 설명한다. (ㄱ) 기초 환경 준비 주로 개발 전 기초 환경 준비이며, 준비 단계는 하드웨어 장치를 준비하고, 기초 운영 체제를 설치하며, 딥 러 닝 프레임워크를 설치하고, 컴파일 예정 또는 컴파일된 제3자 베이스 등을 준비하며, 사전 트레이닝 모델의 다 운로드와 압축 풀기 및 기초 트레이닝, 예측 데이터의 다운로드와 압축 풀기를 포함한다. (ㄴ) 기초 기능 개발 S1, 각 부분의 개별 모델의 개발. 1) 모델 선택: 산업 차원 모델 베이스로부터 적합한 모델 알고리즘을 선택하되, 모델 알고리즘은 사용자 자체 경험에 따라 선택될 수 있고, 사용자에 의해 산업 차원 모델 베이스에서 추천된 알고리즘으로부터 선택될 수도 있다. 2) 트레이닝 소프트웨어/하드웨어 환경 선택: 실제 상황, 즉, 실제 응용 시의 소프트웨어/하드웨어 조건에 따라 적합한 소프트웨어/하드웨어 환경을 선택한다. 3) 모델 트레이닝 단계: 소프트웨어/하드웨어 환경 및 실제 서비스 수요에 따라 모델 트레이닝 방식을 선택한다. 4) 모델 압축 기술 모델 선택: 실제 서비스 수요에서 모델 크기와 속도에 대한 수요에 따라 적합한 모델 기술을 선택한다. S2, 모델 개발 프로세스를 완성하고, 모델 트레이닝을 실행한다. S3, 모델의 저장: 트레이닝된 모델을 기초 inference 모드로 저장한다. S4, 배포 측면의 처리를 진행한다. 1) 예측 배포 모델 선택: 실제 서비스 수요에 따라 적합한 예측 배포 방식을 선택한다. 2) 추론 배포 소프트웨어/하드웨어 환경 모델 선택: 실제 상황, 즉, 실제 응용 시의 소프트웨어/하드웨어 조건 에 따라 적합한 소프트웨어/하드웨어 환경을 선택한다. (ㄷ) 지원 기능 개발: 기초 기능 개발의 기초 하에 핵심 단계를 보완 보충하고, 전반적 프로세스를 진행하여 전반적 프로세스 기능의 지원을 구현한다. S1, (ㄱ)의 표준 환경에서, 하나의 모델을 선택하고, (ㄴ)의 각 단계를 연결하며, 각 단계의 일 선택에 기반하 여 단일 라인으로 전반적 프로세스를 진행한다. 표준 환경은 실제 상황에서 결정된 한 세트의 환경이며, 이하의 단계에서 더 이상 변하지 않는다. S2, 서브 단계의 다양한 선택을 확장하고, 인접한 두 조합마다 각 단계의 상이한 상황을 결정하며, 각 단계의 다양한 선택과 다음 단계의 각 조합의 기능이 모두 효과적으로 수행될 수 있도록 보장한다. S3, 개발, 트레이닝으로부터 추론에 이르는 전반적 프로세스에 걸쳐, 위의 전체 블록도의 효과성을 보장한다. S4, 모델 수량을 확장하여 최종적으로 전체 모델의 전반적 프로세스를 연결한다. (ㄹ) 전반적 프로세스 보고 출력: 주로(ㄴ), (ㄷ)의 핵심 프로세스 보고 출력이며, 출력되는 내용은 다음과 같다. 1) 개발된 자동화 테스트의 스크립트; 2) 자동화를 이용하여 트레이닝 및 추론 코드에서 지표 출력을 필요로 하는 위치에 소량의 테스트 포인트를 추 가하여, 테스트 포인트가 핵심 프린팅 정보의 다양한 정보를 포함할 수 있도록 하며; 3) 자동화 테스트 스크립트를 실행시켜 테스트 보고 결과를 출력하되, 테스트 보고 결과의 내용은, 트레이닝 관 련 속도, loss, 정밀도, 소모 시간, 관련 소프트웨어 버전번호 예측, 하드웨어, 구성 정보, 모델 명칭, 모델 트 레이닝 시의 데이터 집합 정보, 성능 정보(예를 들어, 비디오 메모리 리소스 소모 정보), 소모 시간 및 예측 결 과 등 정보를 포함하나 이에 한정되지 않는다. 상기 바람직한 실시형태를 통해 다음과 같은 유익한 효과를 달성할 수 있다. 본 발명의 바람직한 실시형태에 따른 방법 및 시스템은 다양한 오픈 소스 프로젝트의 개발 과정에 널리 응 용될 수 있으며, 트레이닝으로부터 추론에 이르는 전반적 프로세스 기능 지원을 제공한다. 본 발명의 바람직한 실시형태에 따른 방법 및 시스템은 기업 내부의 코드 유지 관리 프로세스에 널리 응용 될 수 있어, 기업 온라인 문제 리스크를 감소시킨다. 본 발명의 바람직한 실시형태에 따른 방법 및 시스템은 시스템에 미리 설정된 알고리즘을 이용하며, 산업 실천에 더 잘 응용될 수 있고, 기업 개발자는 실제 프로젝트에서 본 시스템에 응집된 모델 알고리즘, 그리고 개 발, 트레이닝으로부터 추론에 이르는 전반적 프로세스 기능 지원을 사용하여 개발 효율을 50% 넘어 향상시킬 수 있다. 본 발명의 바람직한 실시형태에 따른 방법 및 시스템을 사용하면, 기업 자체의 딥 러닝 개발 프로세스에 대 해 품질 관리를 진행할 수 있고, 과정에서의 호환성 문제, 적응성 문제를 효과적으로 감소시킬 수 있으며, 테스 트 일차 통과율을 20% 향상시킨다. 본 발명의 바람직한 실시형태에 따른 방법 및 시스템을 사용하면, 원 터치로 자동화 테스트 스크립트를 동 작시킬 수 있고, 모델이 새로운 소프트웨어/하드웨어 환경에서의 적응 능력을 신속하게 검증할 수 있으며, 다양 한 기업 공동 구매 입찰 평가 과정에 응용될 수 있고, 자동화 스크립트를 통해 소프트웨어/하드웨어 환경의 적 합율을 검증하며, 검증 비용을 30% 절감한다. 본 발명의 바람직한 실시형태에 따른 방법 및 시스템에 따른 규범, 툴은, 점진적으로 관련 분야의 단체 기 준 및 업계 기준으로 일반화될 수 있고, 전체 관련 업계에서 딥 러닝 프레임워크에 기반한 개발, 트레이닝, 추 론의 전반적 프로세스의 표준화 정도를 향상시킨다. 본 발명의 실시예에 따르면, 딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 장치를 더 제공 하며, 도 3은 본 발명의 실시예에 따른 딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 장치 의 구조 블록도이다. 도 3에 도시된 바와 같이, 상기 장치는, 구축 모듈, 제1 생성 모듈, 제2 생성 모듈 및 테스트 모듈을 포함하고, 이하, 상기 장치에 대해 설명한다. 구축 모듈은, 딥 러닝 모델의 전반적 생성 과정에 환경 준비를 제공하는 기초 실행 환경을 목표 장치에 구 축하고; 제1 생성 모듈은, 상기 구축 모듈에 연결되고, 서비스 수요 및/또는 하드웨어 수요에 따라, 기초 실행 환경에서 딥 러닝 모델의 기초 기능을 생성하여 제1 처리 결과를 얻으며; 제2 생성 모듈은, 상 기 제1 생성 모듈에 연결되고, 제1 처리 결과에 기반하여 기초 실행 환경에서 딥 러닝 모델의 확장 기능을 생성하여 제2 처리 결과를 얻고; 테스트 모듈은, 상기 제2 생성 모듈에 연결되고, 사전 설정 테스트 스크립트를 이용하여 제2 처리 결과에 대해 기능 테스트를 진행하여 테스트 결과를 출력한다. 여기서, 상기 구축 모듈, 제1 생성 모듈, 제2 생성 모듈 및 테스트 모듈은, 실시예 1의 단 계 S101 내지 단계 S104에 대응되며, 다수의 모듈에 대응되는 단계에 의해 구현되는 실예와 응용 시나리오는 동 일하나, 상기 실시예 1에서 개시된 내용에 한정되지 않는다. 본 발명의 기술적 해결수단에서 언급된 사용자 개인 정보의 획득, 저장 및 응용 등은 모두 관련 법률 법규의 규 정에 부합되며, 공서양속에 위배되지 않는다.본 발명의 실시예에 따르면, 본 발명은 전자기기, 판독 가능한 저장 매체 및 컴퓨터 프로그램 제품을 더 제공한 다. 도 4는 본 발명을 실시할 수 있는 실시예의 예시적 전자기기의 개략적 블록도를 도시한다. 전자기기는 랩 탑 컴퓨터, 데스크탑 컴퓨터, 워크스테이션, 퍼스널 디지털 어시스턴트, 서버, 블레이드 서버, 대형 컴퓨터 및 기타 적합한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 나타내기 위한 것이다. 전자기기는 퍼스널 디지털 프로세싱, 셀룰러 폰, 스마트 폰, 웨어러블 장치 및 기타 유사한 컴퓨터 장치와 같은 다양한 형태의 이동 장치 를 나타낼 수도 있다. 본 명세서에 도시된 부품, 이들의 연결과 관계, 그리고 이들의 기능은 예시적인 것일 뿐, 본 명세서에서 설명 및/또는 요구되는 본 발명의 구현을 한정하기 위한 것이 아니다. 도 4에 도시된 바와 같이, 전자기기는 컴퓨팅 유닛을 포함하며, 리드 온리 메모리(ROM)에 저장 된 컴퓨터 프로그램 또는 저장 유닛으로부터 랜덤 액세스 메모리(RAM)에 로딩된 컴퓨터 프로그램에 따라 다양한 적절한 동작 및 처리를 진행할 수 있다. RAM에는, 전자기기의 동작에 필요한 다양한 프 로그램 및 데이터가 저장될 수도 있다. 컴퓨팅 유닛, ROM 및 RAM은 버스를 통해 서로 연결 된다. 입출력(I/O) 인터페이스도 버스에 연결된다. 전자기기의 복수의 부품은 I/O 인터페이스에 연결되고, 키보드, 마우스 등과 같은 입력 유닛; 다양한 유형의 디스플레이, 스피커 등과 같은 출력 유닛; 자기 디스크, 광 디스크 등과 같은 저장 유닛 ; 및 네트워크 카드, 모뎀, 무선 통신 송수신기 등과 같은 통신 유닛을 포함한다. 통신 유닛은 전자기기가 인터넷과 같은 컴퓨터 네트워크 및/또는 다양한 전기통신 네트워크를 통해 기타 장치와 정보/ 데이터를 교환할 수 있도록 한다. 컴퓨팅 유닛은 처리 및 연산 능력을 구비하는 다양한 통용 및/또는 전용 처리 요소일 수 있다. 컴퓨팅 유 닛의 일부 예시로는, 중앙처리장치(CPU), 그래픽처리장치(GPU), 다양한 전용 인공지능(AI) 연산 칩, 머신 러닝 모델 알고리즘을 동작시키는 다양한 컴퓨팅 유닛, 디지털 신호 처리장치(DSP), 및 임의의 적절한 프로세서, 컨트롤러, 마이크로 컨트롤러 등을 포함하나 이에 한정되지 않는다. 컴퓨팅 유닛은 상술한 각 방법 및 처리를 수행하며, 예를 들어, 딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 방법을 수행한다. 예를 들어, 일부 실시예에서, 딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 방법 은, 컴퓨터 소프트웨어 프로그램으로 구현될 수 있고, 머신 판독 가능 매체, 예를 들어, 저장 유닛에 유형 적으로 포함된다. 일부 실시예에서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및/또는 통신 유닛을 통해 전자기기에 로딩 및/또는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되고 컴퓨팅 유닛(40 1)에 의해 실행될 시, 상술한 딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 방법의 하나 또 는 복수의 단계를 수행할 수 있다. 대안으로, 기타 실시예에서, 컴퓨팅 유닛은 기타 임의의 적절한 방식 (예를 들어, 펌웨어에 의해)을 통해 딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 방법을 수행하도록 구성된다. 본 명세서에서 상술한 시스템 및 기술의 각 실시형태는 디지털 전자 회로 시스템, 집적 회로 시스템, 필드 프로 그래머블 게이트 어레이(FPGA), 주문형 집적회로(ASIC), 특정 용도 표준 제품(ASSP), 시스템온칩(SOC), 복합 프 로그래머블 논리소자(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및/또는 이들의 조합에서 구현될 수 있다. 이러한 다양한 실시형태는 하나 또는 복수의 컴퓨터 프로그램에서 실시되고, 상기 하나 또는 복수의 컴퓨터 프 로그램은 적어도 하나의 프로그램 가능한 프로세서를 포함하는 프로그램 가능 시스템에서 실행 및/또는 해석될 수 있으며, 상기 프로그램 가능한 프로세서는 전용 또는 통용 프로그램 가능한 프로세서일 수 있고, 저장 시스 템, 적어도 하나의 입력 장치, 및 적어도 하나의 출력 장치로부터 데이터와 명령을 수신하고, 데이터와 명령을 상기 저장 시스템, 상기 적어도 하나의 입력 장치, 및 상기 적어도 하나의 출력 장치로 전송할 수 있다. 본 발명의 방법을 실시하는 프로그램 코드는 하나 또는 복수의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 이러한 프로그램 코드는 통용 컴퓨터, 전용 컴퓨터 또는 기타 프로그램 가능한 데이터 처리 장치의 프로 세서 또는 컨트롤러에 제공되어, 프로그램 코드가 프로세서 또는 컨트롤러에 의해 실행될 시 흐름도 및/또는 블 록도에 규정된 기능/동작이 실시되도록 할 수 있다. 프로그램 코드는 기기에서 완전히 실행되거나 일부가 기기 에서 실행될 수 있으며, 독립 소프트웨어 패키지로 일부가 기기에서 실행되고 일부가 원격 기기에서 실행되거나, 또는 완전히 원격 기기 또는 서버에서 실행될 수 있다. 본 발명의 문맥상, 머신 판독 가능 매체는 유형적 매체일 수 있고, 명령 실행 환경 시스템, 장치 또는 기기에 의해 사용되거나 또는 명령 실행 환경 시스템, 장치 또는 기기와 결합되어 사용되는 프로그램을 포함하거나 저 장할 수 있다. 머신 판독 가능 매체는 머신 판독 가능 신호 매체 또는 머신 판독 가능 저장 매체일 수 있다. 머신 판독 가능 매체는 전기적, 자기적, 광학적, 전자기적, 적외선, 또는 반도체 시스템, 장치 또는 기기 또는 상 기 내용들의 임의의 적합한 조합을 포함할 수 있으나 이에 한정되지 않는다. 머신 판독 가능 저장 매체의 보다 구체적인 예시로, 적어도 하나 또는 복수의 라인에 기반한 전기적 연결, 휴대식 컴퓨터 디스크, 하드 디스크, 랜덤 액세스 메모리(RAM), 리드 온리 메모리(ROM), 소거 및 프로그램 가능 판독 전용 메모리(EPROM 또는 플래시 이피롬), 광섬유, 읽기용 콤팩트 디스크 기억 장치(CD-ROM), 광학 저장 장치, 자기 저장 장치 또는 상기 내용의 임의의 적합한 조합을 포함할 수 있다. 사용자와의 인터랙션을 위해, 컴퓨터에서 상술한 시스템 및 기술을 실시할 수 있으며, 상기 컴퓨터는, 사용자에 게 정보를 표시하는 표시 장치(예를 들어, CRT(음극선관) 또는 LCD(액정 표시장치) 모니터); 및 키보드와 위치 결정 장치(예를 들어, 마우스 또는 트랙 볼)를 포함하며, 사용자는 상기 키보드 및 상기 위치 결정 장치를 통해 컴퓨터에 입력을 제공할 수 있다. 기타 종류의 장치는 사용자와의 인터랙션을 제공할 수 있으며, 예를 들어, 사 용자에게 제공되는 피드백은 임의의 형태의 센싱 피드백(예를 들어, 시각 피드백, 청각 피드백, 또는 촉각 피드 백)일 수 있고, 임의의 형태(소리 입력, 음성 입력 또는 촉각 입력)를 통해 사용자의 입력을 수신할 수 있다. 여기서 설명된 시스템 및 기술을 백그라운드 부품을 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서버) 또는 중 간 부품을 포함하는 컴퓨팅 시스템(예를 들어, 응용 서버), 또는 프런트 엔드 부품을 포함하는 컴퓨팅 시스템 (예를 들어, 그래프 사용자 화면 또는 네트워크 브라우저를 구비하는 사용자 컴퓨터, 사용자는 상기 그래프 사 용자 화면 또는 상기 네트워크 브라우저를 통해 상술한 시스템 및 기술의 실시형태와 인터랙션할 수 있음), 또 는 이러한 백그라운드 부품, 중간 부품 또는 프런트 엔드 부품의 임의의 조합을 포함하는 컴퓨팅 시스템에서 실 시될 수 있다. 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워크)을 통해 시스템 부품을 서로 연결할 수 있다. 통신 네트워크의 예시로는, 근거리 통신망(LAN), 광역 통신망(WAN) 및 인터넷을 포함한다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트와 서버는 일반적으로 서로 떨어져 있으며, 통상적으로 통신 네트워크를 통해 인터랙션한다. 상응한 컴퓨터에서 동작되고 서로 클라이언트-서버 관계를 구 비하는 컴퓨터 프로그램을 통해 클라이언트와 서버의 관계를 생성한다. 서버는 클라우드 서버일 수 있고, 분산 식 시스템의 서버일 수도 있으며, 또는 블록 체인을 결합한 서버일 수도 있다. 위에서 나타낸 다양한 형태의 프로세스를 이용하여 재배열, 증가 또는 삭제 단계를 진행할 수 있다. 예를 들어, 본 발명에 기재된 각 단계는 병렬로 수행될 수 있고, 순서적으로 수행될 수도 있으며, 상이한 순서에 따라 수행 될 수도 있다. 본 발명에서 개시된 기술적 해결수단이 기대하는 결과를 달성할 수 있다면, 본 명세서에서는 이 에 대해 한정하지 않는다. 상기 구체적인 실시형태는 본 발명의 보호 범위에 대한 제한이 아니다. 당업자라면, 설계 수요 및 기타 요소에 따라 다양한 수정, 조합, 서브 조합 및 대체를 진행할 수 있음을 이해해야 할 것이다. 본 발명의 사상 및 원칙 내에서 이루어진 어떠한 수정, 동등한 대체 및 개선 등은 모두 본 발명의 보호 범위 내에 포함되어야 할 것이다.도면 도면1 도면2 도면3 도면4"}
{"patent_id": "10-2022-0161339", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면은 본 해결수단을 보다 명확하게 이해하도록 제공되며, 본 발명을 한정하지 않는다. 도 1은 본 발명의 실시예 1에 따른 딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 방법의 흐 름도이다. 도 2는 본 발명의 바람직한 실시형태에 따른 시스템 구조도이다. 도 3은 본 발명의 실시예에 따른 딥 러닝 프레임워크에 기반하여 딥 러닝 모델을 생성 및 응용하는 장치의 구조 블록도이다. 도 4는 본 발명을 실시할 수 있는 실시예의 예시적 전자기기의 개략적 블록도를 도시한다."}
