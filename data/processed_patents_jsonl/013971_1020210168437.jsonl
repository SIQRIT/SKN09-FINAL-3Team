{"patent_id": "10-2021-0168437", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0080895", "출원번호": "10-2021-0168437", "발명의 명칭": "가상 디자인을 이용한 인테리어 시뮬레이션 방법", "출원인": "에이투아이 주식회사", "발명자": "박기태"}}
{"patent_id": "10-2021-0168437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "프로세서가, 카메라를 통해 촬영된 대상 공간 이미지에 대한 마스킹을 수행하는 단계; 및프로세서가, 마스킹 수행이 완료된 이미지에 기초하여, 상기 대상 공간에 적용되는 가상 디자인을 실현하는 단계;를 포함하는 가상 디자인을 이용한 인테리어 시뮬레이션 방법."}
{"patent_id": "10-2021-0168437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 마스킹을 수행하는 단계는,카메라를 통해 촬영된 대상 공간 이미지를 획득하는 단계; 및상기 이미지에 엣지를 보존하거나 강화하고 잡음을 제거하는 필터를 적용하는 단계;를 포함하는 가상 디자인을이용한 인테리어 시뮬레이션 방법."}
{"patent_id": "10-2021-0168437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 마스킹을 수행하는 단계는,상기 필터가 적용된 상태에서, 상기 이미지에 인공지능 SED(Structured Forest Edge Detect) 모델 또는HED(Holistically-Nested Edge Detection) 모델을 적용하는 단계;인공지능 SED 모델 또는 HED 모델이 적용된 상태에서, 상기 이미지에 엣지 디텍션을 수행하는 단계; 및엣지 디텍션이 수행된 상태에서, 상기 이미지에 외곽선 디텍션을 수행하는 단계;를 더 포함하는 가상 디자인을이용한 인테리어 시뮬레이션 방법."}
{"patent_id": "10-2021-0168437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 인공지능 SED 모델 또는 HED 모델을 적용하는 단계는,상기 이미지의 원본 사이즈, 원본의 n배 사이즈, 원본의 1/n배 사이즈 각각에 SED 모델 또는 HED 모델을 적용하여, 평균을 구한 이미지를 최종 결과물로 사용하는 가상 디자인을 이용한 인테리어 시뮬레이션 방법."}
{"patent_id": "10-2021-0168437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,가상 디자인을 실현하는 단계는,사용자 입력에 따라 이미지에서 가상 디자인이 적용될 영역을 선택하는 단계;사용자 입력에 따라 아이템을 선택하는 단계;플루드 필(Flood Fill) 알고리즘을 적용하여, 상기 아이템을 상기 영역에 적용한 이미지를 생성하는 단계; 및생성된 이미지에 원본 이미지의 명도를 적용하고 원본 이미지와의 블렌딩을 수행하하는 단계;를 포함하는 가상디자인을 이용한 인테리어 시뮬레이션 방법."}
{"patent_id": "10-2021-0168437", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 프로세서가, 카메라를 통해 촬영된 대상 공간 이미지에 대한 마스킹을 수행하는 단계; 및 프로세서가, 마스킹 수행이 완료된 이미지에 기초하여, 상기 대상 공간에 적용되는 가상 디자인을 실현하는 단계;를 포함하는 가상 디자인을 이용한 인테리어 시뮬레이션 방법에 관한 것이다."}
{"patent_id": "10-2021-0168437", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 가상 디자인을 이용한 인테리어 시뮬레이션 방법에 관한 것이다."}
{"patent_id": "10-2021-0168437", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 인테리어를 하기 위해서 소비자는 업장을 직접 방문하여 샘플을 보거나, 카탈로그 등의 홍보물을 열 람하여 인테리어 소재(인테리어 소재는 페인트, 벽지, 바닥재, 시트지, 몰딩 등 본 발명에서 가상 디자인이 적 용 가능한 인테리어 소재를 의미함)를 선택하였다. 그러나 이러한 방식은, 소비자의 시간이 소요되고 확인할 수 있는 인테리어 소재들이 제한적이라는 문제점이 있 었다. 또한, 소비자는 소비자의 공간에 맞춘 인테리어 소재를 확인하는 것이 아니라 다른 공간에 적용된 인테리어 소 재를 확인하고 선택하게 된다. 이경우, 비용을 지불하고 소비자의 공간에 인테리어 소재를 적용하였을 때, 소비 자의 생각과는 다른 경우가 있어 인테리어 결과에 대한 소비자의 만족도가 떨어지는 문제가 있었다. 이러한 문제점들을 기술적으로 해결하기 위한 방법이 요구된다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록번호 10-2114294"}
{"patent_id": "10-2021-0168437", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기한 문제점을 해결하기 위하여, 사용자의 공간에 맞춰 아이템(아이템이란 페인트 색상 및 벽지, 바닥재, 시트지 등 인테리어 소재에 사용되는 이미지 및 색상을 통칭함)을 적용하고 확인하여 선택할 수 있는 기술을 제공하는데 목적이 있다. 본 발명의 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제들은 아래의 기재 로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0168437", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 달성하기 위하여, 본 발명의 실시예에 따른 방법은 가상 디자인을 적용하여 시뮬레이션을 할 수 있 다. 본 발명의 실시예에 따른 가상 디자인을 이용한 인테리어 시뮬레이션 방법은, 프로세서가, 카메라를 통해 촬영 된 대상 공간 이미지에 대한 마스킹을 수행하는 단계; 및 프로세서가, 마스킹 수행이 완료된 이미지에 기초하여, 상기 대상 공간에 적용되는 가상 디자인을 실현하는 단계;를 포함한다. 상기 마스킹을 수행하는 단계는, 카메라를 통해 촬영된 대상 공간 이미지 또는 기 촬영된 이미지를 획득하는 단 계; 및 상기 이미지에 엣지를 보존하거나 강화하고 잡음을 제거하는 필터를 적용하는 단계;를 포함한다. 상기 마스킹을 수행하는 단계는, 상기 필터가 적용된 상태에서, 상기 이미지에 인공지능 SED(Structured Forest Edge Detect) 모델 또는 HED(Holistically-Nested Edge Detection) 모델을 적용하는 단계; 인공지능 SED 모델 또는 HED 모델이 적용된 상태에서, 상기 이미지에 엣지 디텍션을 수행하는 단계; 및 엣지 디텍션이 수행된 상태 에서, 상기 이미지에 외곽선 디텍션을 수행하는 단계;를 더 포함한다. 상기 인공지능 SED 모델 또는 HED 모델을 적용하는 단계는, 상기 이미지의 원본 사이즈, 원본의 n배 사이즈, 원 본의 1/n배 사이즈 각각에 SED 모델 또는 HED 모델을 적용하여, 평균을 구한 이미지를 최종 결과물로 사용하는 가상 디자인을 이용한다. (이미지의 사이즈는 설명을 위하여 과장 될 수 있으며, 실제로 적용되는 이미지의 사 이즈를 의미하는 것은 아니다.)가상 디자인을 실현하는 단계는, 사용자 입력에 따라 이미지에서 가상 디자인이 적용될 영역을 선택하는 단계; 사용자 입력에 따라 아이템을 선택하는 단계; 플루드 필(Flood Fill) 알고리즘을 적용하여, 상기 아이템을 상기 영역에 적용한 이미지를 생성하는 단계; 및 생성된 이미지에 원본 이미지의 명도를 적용하고, 원본 이미지와의 블렌딩을 적용하는 단계;를 포함한다. 기타 실시예들의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2021-0168437", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 다음과 같은 효과가 하나 혹은 그 이상 있다. 첫째, 사용자가 자신의 공간에 적용된 가상 디자인을 확인하고 인테리어 소재를 선택할 수 있어 사용자의 만족 도가 상승하는 효과가 있다. 둘째, 인테리어 소재의 공급자 입장에서는 가상 디자인을 확인하고 인테리어 소재을 구매하게 되므로 인테리어 소재에 대한 사용자의 불만이 줄어들게 되어 매출 상승으로 이어지게 되는 효과가 있다."}
{"patent_id": "10-2021-0168437", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 청구범위의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0168437", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 도 1은 본 발명의 실시예에 따른 방법을 설명하는데 참조되는 개념도이다. 도면을 참조하면, 본 발명의 실시예에 따른 인테리어 시뮬레이션 장치는, 가상 디자인을 이용하여 인테리어 시뮬레이션을 구현할 수 있다. 인테리어 시뮬레이션 장치는, 고정형 단말기 또는 이동형 단말기로 구현될 수 있다. 인테리어 시뮬레이션 장치는, 대상 공간(RS)에 대한 이미지를 획득할 수 있다. 인테리어 시뮬레이션 장치 는, 사용자 입력과 획득된 이미지에 대한 이미지 처리를 통해 대상 공간에 가상 디자인을 적용할 수 있다. 사용자는 대상 공간에 적용된 가상 디자인을 확인하고, 해당 인테리어 아이템의 구매 여부를 결정할 수 있다. 이와 같이, 인테리어 시공 이전에 시뮬레이션을 통해 가상으로 디자인을 적용해 볼 수 있어, 대상 공간에 대한 실제 인테리어 시공 시 사용자의 만족도가 증대된다. 도 2는 본 발명의 실시예에 따른 인테리어 시뮬레이션 장치의 제어 블럭도이다. 도면을 참조하면, 인테리어 시뮬레이션 장치는, 통신부, 위치 정보 모듈, 사용자 입력부, 센싱 부, 출력부, 메모리, 프로세서, 인터페이스부, 전원 공급부 및 카메라를 포함할 수 있다. 통신부는, 외부 디바이스와 무선 통신을 수행하기 위한 장치이다. 통신부는, 통신을 수행하기 위해 송신 안테나, 수신 안테나, 각종 통신 프로토콜이 구현 가능한 RF(Radio Frequency) 회로 및 RF 소자 중 적어도 어느 하나를 포함할 수 있다. 위치 정보 모듈은, 인테리어 시뮬레이션 장치의 위치(또는 현재 위치)를 획득하기 위한 모듈로서, 그의 대표적인 예로는 GPS(Global Positioning System) 모듈 또는 WiFi(Wireless Fidelity) 모듈이 있다. 예를 들어, GPS모듈을 활용하면, GPS 위성에서 보내는 신호를 이용하여 인테리어 시뮬레이션 장치의 위치를 획득 할 수 있다. 다른 예로서, Wi-Fi모듈을 활용하면, Wi-Fi모듈과 무선신호를 송신 또는 수신하는 무선 AP(Wireless Access Point)의 정보에 기반하여, 인테리어 시뮬레이션 장치의 위치를 획득할 수 있다. 사용자 입력부는, 사용자로부터 사용자로부터 정보를 입력받기 위한 것으로, 사용자 입력부에서 수집한 데이터는, 프로세서에 의해 분석되어, 사용자의 제어 명령으로 처리될 수 있다. 사용자 입력부는, 음성 입력부(예를 들면, 마이크로 폰), 터치 입력부(예를 들면, 터치 스크린) 및 기계식 입력부(예를 들면, 버튼)를 포함할 수 있다. 센싱부는 인테리어 시뮬레이션 장치 내 정보, 인테리어 시뮬레이션 장치를 둘러싼 주변 환경 정보 및 사용자 정보 중 적어도 하나를 센싱하기 위한 하나 이상의 센서를 포함할 수 있다. 예를 들어, 센싱부는 근접센서(proximity sensor), 조도 센서(illumination sensor), 터치 센서(touch sensor), 가속도 센서 (acceleration sensor), 자기 센서(magnetic sensor), 중력 센서(G-sensor), 자이로스코프 센서(gyroscope sensor), 모션 센서(motion sensor), RGB 센서, 적외선 센서(IR 센서: infrared sensor), 지문인식센서finger scan sensor), 초음파 센서(ultrasonic sensor), 광 센서(optical sensor, 예를 들어, 카메라), 마이크로폰 (microphone), 배터리 게이지(battery gauge), 환경 센서(예를 들어, 기압계, 습도계, 온도계, 방사능 감지 센 서, 열 감지 센서, 가스 감지 센서 등), 화학 센서(예를 들어, 전자 코, 헬스케어 센서, 생체 인식 센서 등) 중 적어도 하나를 포함할 수 있다. 한편, 본 명세서에 개시된 인테리어 시뮬레이션 장치는, 이러한 센서들 중 적어도 둘 이상의 센서에서 센싱되는 정보들을 조합하여 활용할 수 있다. 출력부는, 시각, 청각 또는 촉각 등과 관련된 출력을 발생시키기 위한 것으로, 디스플레이부, 음향 출력부, 햅팁 모듈, 광 출력부 중 적어도 하나를 포함할 수 있다. 디스플레이부는 터치 센서와 상호 레이어 구조를 이루 거나 일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있다. 이러한 터치 스크린은, 인테리어 시뮬레이션 장 치와 사용자 사이의 입력 인터페이스를 제공하는 사용자 입력부로써 기능함과 동시에, 인테리어 시뮬레 이션 장치와 사용자 사이의 출력 인터페이스를 제공할 수 있다. 디스플레이부는, 액정 디스플레이(liquid crystal display, LCD), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display, TFT LCD), 유기 발광 다이오드(organic light-emitting diode, OLED), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전자잉크 디스플레이(e-ink display) 중에서 적어도 하나를 포함할 수 있다. 메모리는, 프로세서와 전기적으로 연결된다. 메모리는 유닛에 대한 기본데이터, 유닛의 동작제어를 위한 제어데이터, 입출력되는 데이터를 저장할 수 있다. 메모리는, 프로세서에서 처리된 데이터를 저장할 수 있다. 메모리는, 하드웨어적으로, ROM, RAM, EPROM, 플래시 드라이브, 하드 드라이브 중 적어도 어느 하나로 구성될 수 있다. 메모리는 프로세서의 처리 또는 제어를 위한 프로그램 등, 인테리어 시뮬레이 션 장치 전반의 동작을 위한 다양한 데이터를 저장할 수 있다. 메모리는, 프로세서와 일체형으로 구현될 수 있다. 실시예에 따라, 메모리는, 프로세서의 하위 구성으로 분류될 수 있다. 인터페이스부는, 외부의 전자 장치와 유선 또는 무선으로 신호를 교환할 수 있다. 인터페이스부는, 단 자, 핀, 케이블, 포트, 회로, 소자 및 장치 중 적어도 어느 하나로 구성될 수 있다. 전원 공급부는, 인테리어 시뮬레이션 장치에 전원을 공급할 수 있다. 전원 공급부는, 배터리로부터 전원을 공급받아, 인테리어 시뮬레이션 장치의 각 유닛에 전원을 공급할 수 있다. 프로세서는, 통신부, 위치 정보 모듈, 사용자 입력부, 센싱부, 출력부, 메모리, 인터페이스부, 전원 공급부와 전기적으로 연결되어 신호를 교환할 수 있다. 프로세서는, ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서 (processors), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서 (microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 프로세서는, 전원 공급부로부터 제공되는 전원에 의해 구동될 수 있다. 프로세서는, 전원 공급부 에 의해 전원이 공급되는 상태에서 데이터를 수신하고, 데이터를 처리하고, 신호를 생성하고, 신호를 제공 할 수 있다. 프로세서는, 인테리어 시뮬레이션 장치 각 유닛의 전반적인 동작을 제어할 수 있다. 프로세서는, 도 3 내지 도 5를 참조하여 설명하는 방법의 각 동작을 수행할 수 있다. 인테리어 시뮬레이션 장치는, 적어도 하나의 인쇄 회로 기판(printed circuit board, PCB)을 포함할 수 있 다. 통신부, 위치 정보 모듈, 사용자 입력부, 센싱부, 출력부, 메모리, 프로세서 , 인터페이스부, 전원 공급부, 카메라는, 인쇄 회로 기판에 전기적으로 연결될 수 있다. 카메라는, 이미지 센서와 영상 처리 모듈을 포함할 수 있다. 카메라는 이미지 센서(예를 들면, CMOS 또 는 CCD)에 의해 얻어지는 정지영상 또는 동영상을 처리할 수 있다. 영상 처리 모듈은 이미지 센서를 통해 획득 된 정지영상 또는 동영상을 가공하여, 필요한 정보를 추출하고, 추출된 정보는 프로세서에서 이용될 수 있 다. 한편 영상 처리 모듈은, 프로세서 또는 카메라의 하위 구성으로 분류될 수 있다. 한편, 실시예에 따라, 카메라는, 스테레오 카메라로 구현될 수 있다. 스테레오 카메라는, 대상 공간에 대한 스테레오 이미지를 획득할 수 있다. 도 3은 본 발명의 실시예에 따른 방법을 설명하는데 참조되는 플로우 차트이다. 도면을 참조하면, 가상 디자인을 이용한 인테리어 시뮬레이션 방법은, 인테리어 시뮬레이션 장치에 의해 구 현될 수 있다. 예를 들면, 가상 디자인을 이용한 인테리어 시뮬레이션 방법은, 프로세서의 동작에 의해 구 현될 수 있다. 프로세서는, 이미지에 대한 마스킹을 수행할 수 있다(S310). 프로세서는, 카메라를 통해 촬영된 대 상 공간 이미지에 대한 마스킹을 수행할 수 있다. 마스킹 수행 동작은, 이미지 내 여러 오브젝트들 간의 경계를 명확하게 하는 작업으로 설명될 수 있다. 마스킹 수행 동작은, 복수의 오브젝트들 간의 경계를 기준으로 영역을 구분하는 작업으로 설명될 수 있다. 프로세서는, 카메라에 의해 획득된 이미지로 마스킹 동작을 수행할 수 있다. 카메라가 모노 카메라인 경우, 프로세서는, 모노 이미지로 마스킹 동작을 수행할 수 있다. 카메라가 스테레오 카메라인 경우, 프로세서는, 스테레오 이미지로 마스킹 동작을 수행할 수 있다. 예 를 들면, 프로세서는, 스테레오 카메라 중 제1 카메라의 제1 영상 및 제2 카메라의 제2 영상 각각을 처리하 여, 스테레오 영상을 획득할 수 있다. 프로세서는, 스테레오 영상에 기초하여, 대상 공간에 대한 디스패러 티 연산을 수행할 수 있다. 프로세서는, 스테레오 영상에서 오브젝트를 검출할 수 있다. 프로세서는, 디스패러티 연산에 기초하여 복수의 오브젝트를 구분지을 수 있다. 프로세서는, 디스패러티 연산에 기초하 여 복수 오브젝트의 뎁스 정보를 획득할 수 있다. 프로세서는 이미지 마스크 생성 단계(S310)에서 오브젝트들 간의 뎁스 정보를 이용할 수 있다. 프로세서 는 서로 겹쳐진 상태로 보이는 제1 오브젝트와 제2 오브젝트 간의 뎁스차를 기초로 제1 오브젝트와 제2 오 브젝트 사이의 경계선을 구분지을 수 있다. 프로세서는, 후술하는 S410 단계, S420 단계, S430 단계, S440 단계, S450 단계 중 어느 하나의 단계에서 뎁스 정보를 이용하여, 복수의 오브젝트 간의 경계를 보다 명확하게 할 수 있다. 프로세서는, 가상 디지인을 실현할 수 있다(S320). 프로세서는, 마스킹 수행이 완료된 이미지에 기초하 여, 대상 공간에 적용되는 가상 디자인을 실현할 수 있다. 프로세서는, 마스킹 수행이 완료된 이미지와 원본 이미지를 매칭하여, 가상 디자인을 실현할 수 있다. 가상 디자인에 대한 실현은, 인테리어 아이템(이하, 아이템은 페인트 색상 및 벽지, 바닥재, 시트지 등 인테리 어 소재에 사용되는 이미지 및 색상 중 적어도 어느 하나를 포함함)을 가상으로 대상 공간 이미지에 적용하는 것으로 이해할 수 있다. 예를 들면, 대상 공간 이미지 벽에 벽지 또는 페인트 등을 적용하는 것으로 설명될 수 있다. 예를 들면, 대상 공간 이미지 바닥에 타일을 적용하는 것으로도 설명될 수 있다. 한편, 아이템은, 실재 공간에서의 인테리어 소재(이하, 인테리어 소재는 페인트, 벽지, 바닥재, 시트지, 몰딩 등 본 발명에서 가상 디자인이 적용 가능한 인테리어 소재를 의미함)를 가상 공간에 표현하는 요소로 이해될 수 있다. 도 4는 도 3의 S310 단계의 상세 플로우 차트이다. 도면을 참조하면, 마스킹을 수행하는 단계(S310)는, 카메라를 통해 촬영된 대상 공간 이미지를 획득하는 단 계(S410), 이미지에 엣지를 보존하거나 강화하고 잡음을 제거하는 필터를 적용하는 단계(S420), 이미지에 인공 지능 SED(Structured Forest Edge Detect) 모델 또는 HED(Holistically-Nested Edge Detection) 모델을 적용하 는 단계(S430), 이미지에 엣지 디텍션을 수행하는 단계(S440), 이미지에 외곽선 디텍션을 수행하는 단계(S450) 를 포함할 수 있다. 프로세서는, 카메라를 통해 촬영된 대상 공간 이미지(410i)를 획득할 수 있다(S410). 카메라가 모노 카메라인 경우, 프로세서는, 대상 공간에 대한 모노 이미지를 획득할 수 있다. 카메라가 스테레오 카메라인 경우, 프로세서는, 대상 공간에 대한 스테레오 이미지를 획득할 수 있다. 프로세서는, 스테레오 이미지를 처리하여 복수 오브젝트의 뎁스 정보를 생성할 수 있다. 프로세서는, 뎁스 정보에 기초하여, 복수 오브젝트 사이의 상대 뎁스 정보를 생성할 수 있다. 프로세서는, 이미지(410i)에 엣지를 보존하거나 강화하고 잡음을 제거하는 필터를 적용(420i)할 수 있다 (S420). 예를 들면, 프로세서는, 이미지(410i)에 바이레터럴 필터(Bilateral Filter)를 적용할 수 있다. 이미지(410i)에는 사람의 눈으로 확인하기는 어렵지만 잡음이 존재한다. 이러한 잡음은 마스킹을 수행할 때, 경 계선이 아닌데 경계선처럼 인식되게 하는 요소이다. 프로세서가, 이미지(410i)에 엣지를 보존하거나 강화하 고 잡음을 제거하는 필터를 적용함으로써, 복수의 오브젝트들 간의 경계선을 명확하게 할 수 있다. 실시예에 따라, 프로세서는, 뎁스 정보를 이용하여, 복수의 오브젝트들 간의 경계를 명확하고, 잡음을 구별 할 수 있다. 엣지를 보존하거나 강화하고 잡음을 제거하는 필터가 적용(420i)된 상태에서, 프로세서는, 이미지(420i)에 인공지능 SED 모델(Structured Forest Edge Detect) 또는 HED(Holistically-Nested Edge Detection) 모델을 적 용(430i)할 수 있다(S430). 인공지능 SED 모델 또는 HED 모델은, 이미지(420i)에서 복수 오브젝트 간의 경계선을 찾기위한 목적으로 기계학 습이 수행된 것으로 설명될 수 있다. 마스킹 수행 시, 이미지(430i)는 경계선은 화이트로 경계선을 제외한 부분은 블랙으로 표시되게 된다. 본원 발 명의 경우, SED 모델 또는 HED 모델을 이용함으로써, 보다 효율성이 높은 결과를 얻을 수 있다. S430 단계에서, 프로세서는, 이미지(420i)의 원본 사이즈, 원본 n배 사이즈, 원본 1/n배 사이즈 각각에 SED 모델 또는 HED 모델을 적용하여, 평균을 구한 이미지를 최종 결과물로 사용할 수 있다. 예를 들면, 이미지(420i)를 픽셀로 표시하면 100X100일 수 있다. 100X100이미지, 200X200 이미지, 50X50 이미 지에 SED 모델 또는 HED 모델을 적용할 때, 결과값이 다를 수 있다. 프로세서는, 100X100 이미지, 200X200 이미지, 50X50 이미지에 SED 모델 또는 HED 모델을 적용한 다음 평균을 구한 이미지를 최종 결과물로 사용할 수 있다. 이와 같은 과정을 통해, 경계선이 보다 명확한 이미지(430i)를 확보할 수 있다. 실시예에 따라, 프로세서는, 뎁스 정보를 이용하여, 복수의 오브젝트들 간의 경계를 명확하고, SED 모델 또 는 HED 모델을 적용할 수 있다. 인공지능 SED 모델이 적용(430i)된 상태에서, 프로세서는, 이미지(430i)에 엣지 디텍션을 수행(440i)할 수 있다(S440). 예를 들면, 프로세서는, 이미지(430i)에 캐니 엣지 디텍트(Canny Edge Detect)를 적용할 수 있다. S430 단계가 수행된 이후에도, 이미지(430i)는 지저분하게 보일 수 있다. 이경우, 캐니 엣지 디텍트를 적용 (440i)하여, 보다 선명한 경계선을 찾을 수 있다. 실시예에 따라, 프로세서는, 뎁스 정보를 이용하여, 복수의 오브젝트들 간의 경계를 명확하고, 캐니 엣지 디텍트(Canny Edge Detect)를 적용할 수 있다. 엣지 디텍션이 수행(440i)된 상태에서, 프로세서는, 이미지(440i)에 외곽선 디텍션을 수행(450i)할 수 있다 (S450). 예를 들면, 프로세서는, 컨투어 디텍트(Contour Detect)를 적용하여, 최종 이미지 마스크(450i)를 생성할 수 있다. S440 단계까지 수행한 이후에도, 경계선에서 한두 픽셀이 누락될 수 있다. 이러한 경우, S450 단계를 거치면서 깨끗한 경계선이 그려지고, 이미지에서 오브젝트를 구성하는 영역이 다른 오브젝트와 구분되게 된다. 실시예에 따라, 프로세서는, 뎁스 정보를 이용하여, 복수의 오브젝트들 간의 경계를 명확하고, 컨투어 디텍 트(Contour Detect)를 적용할 수 있다. 도 5는 도 3의 S320 단계의 상세 플로우 차트이다. 도면을 참조하면, 가상 디자인을 실현하는 단계(S320)는, 이미지(450i)에서 가상 디자인을 적용할 포인트를 선 택하는 단계(S510), 사용자 입력에 따라 아이템을 선택하는 단계(S520), 플루드 필(Flood Fill) 알고리즘을 적 용하여, 상기 아이템을 상기 영역에 적용한 이미지를 생성하는 단계(S530) 및 생성된 이미지에 원본 이미지의 명도를 적용하고 원본 이미지와의 블렌딩을 적용하는 단계(S540)를 포함할 수 있다. 프로세서는, 카메라에 의해 획득된 이미지(410i)에서 사용자 입력에 따라, 가상 디자인이 적용될 영역 을 선택할 수 있다(S510). 프로세서는, 영역을 선택하는 사용자 입력(예를 들면, 터치 입력)을 수신할 수 있다. 프로세서는, 사용자 입력에 따라 선택된 영역을 가상 디자인이 적용될 영역으로 결정할 수 있다. 프로세서는, 사용자 입력에 따라, 아이템을 선택할 수 있다(S520). 프로세서는, 아이템을 선택하는 사 용자 입력(예를 들면, 터치 입력)을 수신할 수 있다. 프로세서는, 사용자 입력에 따라 선택된 아이템을 가 상 디자인이 적용될 아이템으로 결정할 수 있다. 한편, 아이템은, RGB로 구현될 수 있다. 아이템은, 색상, 명도, 채도로 표현될 수 있다. 프로세서는, 이미지(410i)에 아이템을 적용할 수 있다(S530). 프로세서는, 플루드 필(Flood Fill) 알고 리즘을 적용하여, 아이템을 영역에 적용한 이미지를 생성할 수 있다. 이때, 프로세서는, S310 단계에서 생 성한 마스크를 이용하여 플루드 필 알고리즘이 적용될 이미지 영역을 제한할 수 있다. 프로세서는, 카메라에 의해 획득된 이미지(410i)와 마스킹 이미지(450i)가 매칭시켜 플루드 필 알고리 즘 적용 영역을 선택할 수 있다. 프로세서는, 마스킹 작업에 의해 복수의 영역으로 구분된 상태에서, 특정 영역의 일 지점이 선택되는 경우, 해당 지점이 포함된 영역을 선택 영역으로 결정할 수 있다. 프로세서는, 카메라에 의해 획득된 이미지(410i) 중 마스킹 이미지(450i)의 선택 영역과 대응되는 영역 을 플루드 필 알고리즘 적용 영역으로 결정할 수 있다. 프로세서는, 플루드 필 알고리즘 적용 영역에 아이템을 적용할 수 있다. 예를 들면, 프로세서는, 벽 영 역에 색상(RGB) 색상이 적용된 벽지 또는 페인트에 대한 가상 디자인을 구현할 수 있다.프로세서는, S530 단계에서 생성된 이미지에 원본 이미지(410i)의 명도를 적용하고 원본 이미지(410i)와의 블렌딩을 수행(540i)할 수 있다(S540). 원본 이미지는, 카메라에 의해 획득된 이미지(410i)로 설명될 수 있다. 이미지에서 명도로 표현되는 요소(예를 들면, 그림자)들이 있다. S530 단계에서 플루드 필 알고리즘이 적용되면, 색상과 채도는 표현되지만 명도는 표현되지 않는다. 이경우, S530 단계까지 적용된 이미지는 그림자 가 표현되지 않는 등 어색한 이미지가 된다. S530 단계에서 생성된 이미지에 원본 이미지(410i)에서 명도를 가져와서 적용함으로써, 보다 자연스러운 최종 이미지를 생성할 수 있다. 또한 원본 이미지와의 블렌딩을 통해, 보다 다양한 느낌의 결과물을 확인할 수 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 상기 컴 퓨터는 프로세서 또는 제어부를 포함할 수도 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석 되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2021-0168437", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 방법을 설명하는데 참조되는 개념도이다. 도 2는 본 발명의 실시예에 따른 인테리어 시뮬레이션 장치의 제어 블럭도이다. 도 3은 본 발명의 실시예에 따른 방법을 설명하는데 참조되는 플로우 차트이다. 도 4는 도 3의 S310 단계의 상세 플로우 차트이다. 도 5는 도 3의 S320 단계의 상세 플로우 차트이다."}
