{"patent_id": "10-2020-0122526", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0039440", "출원번호": "10-2020-0122526", "발명의 명칭": "디스플레이 장치 및 그의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "엄기문"}}
{"patent_id": "10-2020-0122526", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디스플레이 장치에 있어서,카메라;디스플레이;이미지들에 포함된 사용자의 복수의 신체 부위에 대한 위치 데이터 및 상기 위치 데이터에 기초하여 획득된 추가 위치 데이터에 기초하여 상기 사용자의 자세를 식별하도록 훈련된 인공지능 모델이 저장된 메모리; 및트레이닝 영상 및 상기 카메라에 의해 촬영된 영상을 표시하도록 상기 디스플레이를 제어하고,상기 촬영된 영상에 포함된 사용자의 복수의 신체 부위에 대한 위치 데이터를 상기 인공지능 모델에 입력하여,상기 촬영된 영상에 포함된 사용자의 자세를 식별하고,상기 사용자의 자세와 상기 트레이닝 영상에 대응되는 자세의 매칭 여부에 기초하여 트레이닝 가이드를 표시하도록 상기 디스플레이를 제어하는 프로세서;를 포함하는 디스플레이 장치."}
{"patent_id": "10-2020-0122526", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 추가 위치 데이터는, 상기 위치 데이터를 회전시켜 획득되는 디스플레이 장치."}
{"patent_id": "10-2020-0122526", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는,상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되는 것으로 식별되면, 상기 사용자의 자세가상기 트레이닝 영상에 대응되는 자세와 매칭됨을 나타내는 정보를 포함하는 상기 트레이닝 가이드를 표시하고,상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않는 것으로 식별되면, 상기 사용자의자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않음을 나타내는 정보를 포함하는 상기 트레이닝 가이드를 표시하는 디스플레이 장치."}
{"patent_id": "10-2020-0122526", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 인공지능 모델은,이미지들에 포함된 제1 자세의 사용자의 복수의 신체 부위에 대한 위치 데이터 및 상기 위치 데이터에 기초하여획득된 추가 위치 데이터에 기초하여 상기 사용자의 제1 자세를 식별하도록 훈련되고, 상기 제1 자세는, 상기 트레이닝 영상에 대응되는 자세와 매칭되는 자세인 디스플레이 장치."}
{"patent_id": "10-2020-0122526", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 인공지능 모델은,상기 제1 자세에 따라 운동 효과가 나타나는 신체 부위를 식별하도록 훈련되고, 상기 프로세서는,공개특허 10-2022-0039440-3-상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되는 것으로 식별되면, 상기 인공지능 모델에서 출력되는 신체 부위에 대한 정보에 기초하여 상기 운동 효과가 나타나는 신체 부위에 대한 정보를 표시하도록 상기 디스플레이를 제어하는 디스플레이 장치."}
{"patent_id": "10-2020-0122526", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 인공지능 모델은,이미지들에 포함된 제2 자세의 사용자의 복수의 신체 부위에 대한 위치 데이터 및 상기 위치 데이터에 기초하여획득된 추가 위치 데이터에 기초하여 상기 사용자의 제2 자세를 식별하도록 훈련되고, 상기 제2 자세는, 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않는 자세인 디스플레이 장치."}
{"patent_id": "10-2020-0122526", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 인공지능 모델은,상기 제2 자세에 따라 부정적인 운동 효과가 나타나는 신체 부위를 식별하도록 훈련되고, 상기 프로세서는,상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않는 것으로 식별되면, 상기 인공지능모델에서 출력되는 신체 부위에 대한 정보에 기초하여 상기 부정적인 운동 효과가 나타나는 신체 부위에 대한정보를 표시하도록 상기 디스플레이를 제어하는 디스플레이 장치."}
{"patent_id": "10-2020-0122526", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "디스플레이 장치의 제어 방법에 있어서,트레이닝 영상 및 카메라에 의해 촬영된 영상을 표시하는 단계; 상기 촬영된 영상에 포함된 사용자의 복수의 신체 부위에 대한 위치 데이터를 인공지능 모델에 입력하여 상기촬영된 영상에 포함된 사용자의 자세를 식별하는 단계; 및상기 사용자의 자세와 상기 트레이닝 영상에 대응되는 자세의 매칭 여부에 기초하여 트레이닝 가이드를 표시하는 단계;를 포함하며,상기 인공지능 모델은, 이미지들에 포함된 사용자의 복수의 신체 부위에 대한 위치 데이터 및 상기 위치 데이터에 기초하여 획득된 추가 위치 데이터에 기초하여 사용자의 자세를 식별하도록 훈련된 모델인 제어 방법."}
{"patent_id": "10-2020-0122526", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 추가 위치 데이터는, 상기 위치 데이터를 회전시켜 획득되는 제어 방법."}
{"patent_id": "10-2020-0122526", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 표시하는 단계는,상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되는 것으로 식별되면, 상기 사용자의 자세가상기 트레이닝 영상에 대응되는 자세와 매칭됨을 나타내는 정보를 포함하는 상기 트레이닝 가이드를 표시하고,상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않는 것으로 식별되면, 상기 사용자의자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않음을 나타내는 정보를 포함하는 상기 트레이닝 가이드를 표시하는 제어 방법.공개특허 10-2022-0039440-4-청구항 11 제8항에 있어서,상기 인공지능 모델은,이미지들에 포함된 제1 자세의 사용자의 복수의 신체 부위에 대한 위치 데이터 및 상기 위치 데이터에 기초하여획득된 추가 위치 데이터에 기초하여 상기 사용자의 제1 자세를 식별하도록 훈련되고, 상기 제1 자세는, 상기 트레이닝 영상에 대응되는 자세와 매칭되는 자세인 제어 방법."}
{"patent_id": "10-2020-0122526", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 인공지능 모델은,상기 제1 자세에 따라 운동 효과가 나타나는 신체 부위를 식별하도록 훈련되고, 상기 표시하는 단계는,상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되는 것으로 식별되면, 상기 인공지능 모델에서 출력되는 신체 부위에 대한 정보에 기초하여 상기 운동 효과가 나타나는 신체 부위에 대한 정보를 표시하는디스플레이 장치."}
{"patent_id": "10-2020-0122526", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서,상기 인공지능 모델은,이미지들에 포함된 제2 자세의 사용자의 복수의 신체 부위에 대한 위치 데이터 및 상기 위치 데이터에 기초하여획득된 추가 위치 데이터에 기초하여 상기 사용자의 제2 자세를 식별하도록 훈련되고, 상기 제2 자세는, 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않는 자세인 제어 방법."}
{"patent_id": "10-2020-0122526", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 인공지능 모델은,상기 제2 자세에 따라 부정적인 운동 효과가 나타나는 신체 부위를 식별하도록 훈련되고, 상기 표시하는 단계는,상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않는 것으로 식별되면, 상기 인공지능모델에서 출력되는 신체 부위에 대한 정보에 기초하여 상기 부정적인 운동 효과가 나타나는 신체 부위에 대한정보를 표시하는 제어 방법."}
{"patent_id": "10-2020-0122526", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "디스플레이 장치가 개시된다. 본 디스플레이 장치는 카메라, 디스플레이, 이미지들에 포함된 사용자의 복수의 신 체 부위에 대한 위치 데이터 및 위치 데이터에 기초하여 획득된 추가 위치 데이터에 기초하여 사용자의 자세를 식별하도록 훈련된 인공지능 모델이 저장된 메모리 및 트레이닝 영상 및 카메라에 의해 촬영된 영상을 표시하도 록 디스플레이를 제어하고, 촬영된 영상에 포함된 사용자의 복수의 신체 부위에 대한 위치 데이터를 인공지능 모 델에 입력하여, 촬영된 영상에 포함된 사용자의 자세를 식별하고, 트레이닝 영상에 대응되는 자세와 사용자의 자 세의 매칭 여부에 기초하여 트레이닝 가이드를 표시하도록 디스플레이를 제어하는 프로세서를 포함한다."}
{"patent_id": "10-2020-0122526", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 디스플레이 장치 및 그의 제어 방법에 관한 것으로, 보다 상세하게는 트레이닝 영상을 제공하는 디스 플레이 장치 및 그의 제어 방법에 관한 것이다."}
{"patent_id": "10-2020-0122526", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근에는 건강 관리를 위해, 피트니스 센터에서 헬스 트레이닝, 요가, 필라테스 등의 운동을 하는 사람들이 점 차 증가하고 있다. 또한, 시간 등의 제한으로 인해 피트니스 센터를 방문하지 못하거나, 비대면 방식의 운동을 원하는 사람들은 그 대안으로 홈 트레이닝을 통해 운동을 하고 있다. 홈 트레이닝의 경우, 트레이너 없이 혼자서 운동을 하기 때문에, 사람들이 정확한 자세로 운동을 하고 있는지를 정확히 체크하고, 그에 대한 트레이닝 가이드를 제공받을 수 있는 것이 운동 효과에 있어 중요한 문제이다."}
{"patent_id": "10-2020-0122526", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 필요성에 따라 안출된 것으로, 인공지능 모델을 이용하여 사용자의 자세를 식별하고, 사용자 의 자세와 트레이닝 영상의 자세의 매칭 여부에 기초하여 트레이닝 가이드를 표시하는 디스플레이 장치 및 그의 제어 방법을 제공함에 있다."}
{"patent_id": "10-2020-0122526", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 디스플레이 장치는 카메라, 디스플레이, 이미지들에 포함된 사용자의 복수의 신체 부위에 대한 위치 데이터 및 상기 위치 데이터에 기초하여 획득된 추가 위치 데이터에 기초하여 상기 사용자의 자세를 식별하도록 훈련된 인공지능 모델이 저장된 메모리 및 트레이닝 영상 및 상기 카메라에 의해 촬영된 영 상을 표시하도록 상기 디스플레이를 제어하고, 상기 촬영된 영상에 포함된 사용자의 복수의 신체 부위에 대한 위치 데이터를 상기 인공지능 모델에 입력하여, 상기 촬영된 영상에 포함된 사용자의 자세를 식별하고, 상기 사 용자의 자세와 상기 트레이닝 영상에 대응되는 자세의 매칭 여부에 기초하여 트레이닝 가이드를 표시하도록 상 기 디스플레이를 제어하는 프로세서를 포함한다. 여기에서, 상기 추가 위치 데이터는 상기 위치 데이터를 회전시켜 획득될 수 있다. 또한, 상기 프로세서는 상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되는 것으로 식별되면, 상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭됨을 나타내는 정보를 포함하는 상 기 트레이닝 가이드를 표시하고, 상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않는 것으로 식별되면, 상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않음을 나타내는 정보 를 포함하는 상기 트레이닝 가이드를 표시할 수 있다. 그리고, 상기 인공지능 모델은 이미지들에 포함된 제1 자세의 사용자의 복수의 신체 부위에 대한 위치 데이터 및 상기 위치 데이터에 기초하여 획득된 추가 위치 데이터에 기초하여 상기 사용자의 제1 자세를 식별하도록 훈 련되고, 상기 제1 자세는 상기 트레이닝 영상에 대응되는 자세와 매칭되는 자세일 수 있다. 여기에서, 상기 인공지능 모델은 상기 제1 자세에 따라 운동 효과가 나타나는 신체 부위를 식별하도록 훈련되고, 상기 프로세서는 상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되는 것으로 식별 되면, 상기 인공지능 모델에서 출력되는 신체 부위에 대한 정보에 기초하여 상기 운동 효과가 나타나는 신체 부 위에 대한 정보를 표시하도록 상기 디스플레이를 제어할 수 있다. 또한, 상기 인공지능 모델은 이미지들에 포함된 제2 자세의 사용자의 복수의 신체 부위에 대한 위치 데이터 및 상기 위치 데이터에 기초하여 획득된 추가 위치 데이터에 기초하여 상기 사용자의 제2 자세를 식별하도록 훈련 되고, 상기 제2 자세는 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않는 자세일 수 있다. 여기에서, 상기 인공지능 모델은 상기 제2 자세에 따라 부정적인 운동 효과가 나타나는 신체 부위를 식별하도록 훈련되고, 상기 프로세서는 상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않는 것으로 식별되면, 상기 인공지능 모델에서 출력되는 신체 부위에 대한 정보에 기초하여 상기 부정적인 운동 효과가 나 타나는 신체 부위에 대한 정보를 표시하도록 상기 디스플레이를 제어할 수 있다. 한편, 본 개시의 일 실시 예에 따른 디스플레이 장치의 제어 방법은 트레이닝 영상 및 카메라에 의해 촬영된 영 상을 표시하는 단계, 상기 촬영된 영상에 포함된 사용자의 복수의 신체 부위에 대한 위치 데이터를 인공지능 모 델에 입력하여 상기 촬영된 영상에 포함된 사용자의 자세를 식별하는 단계 및 상기 사용자의 자세와 상기 트레 이닝 영상에 대응되는 자세의 매칭 여부에 기초하여 트레이닝 가이드를 표시하는 단계를 포함하며, 상기 인공지 능 모델은 이미지들에 포함된 사용자의 복수의 신체 부위에 대한 위치 데이터 및 상기 위치 데이터에 기초하여 획득된 추가 위치 데이터에 기초하여 사용자의 자세를 식별하도록 훈련된 모델이다. 여기에서, 상기 추가 위치 데이터는 상기 위치 데이터를 회전시켜 획득될 수 있다. 또한, 상기 표시하는 단계는 상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되는 것으로 식 별되면, 상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭됨을 나타내는 정보를 포함하는 상기 트레이닝 가이드를 표시하고, 상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않는 것으 로 식별되면, 상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않음을 나타내는 정보를 포함하는 상기 트레이닝 가이드를 표시할 수 있다. 그리고, 상기 인공지능 모델은 이미지들에 포함된 제1 자세의 사용자의 복수의 신체 부위에 대한 위치 데이터 및 상기 위치 데이터에 기초하여 획득된 추가 위치 데이터에 기초하여 상기 사용자의 제1 자세를 식별하도록 훈 련되고, 상기 제1 자세는 상기 트레이닝 영상에 대응되는 자세와 매칭되는 자세일 수 있다. 여기에서, 상기 인공지능 모델은 상기 제1 자세에 따라 운동 효과가 나타나는 신체 부위를 식별하도록 훈련되고, 상기 표시하는 단계는 상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되는 것으로 식별되면, 상기 인공지능 모델에서 출력되는 신체 부위에 대한 정보에 기초하여 상기 운동 효과가 나타나는 신 체 부위에 대한 정보를 표시할 수 있다. 또한, 상기 인공지능 모델은 이미지들에 포함된 제2 자세의 사용자의 복수의 신체 부위에 대한 위치 데이터 및 상기 위치 데이터에 기초하여 획득된 추가 위치 데이터에 기초하여 상기 사용자의 제2 자세를 식별하도록 훈련 되고, 상기 제2 자세는 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않는 자세일 수 있다. 여기에서, 상기 인공지능 모델은 상기 제2 자세에 따라 부정적인 운동 효과가 나타나는 신체 부위를 식별하도록 훈련되고, 상기 표시하는 단계는 상기 사용자의 자세가 상기 트레이닝 영상에 대응되는 자세와 매칭되지 않는 것으로 식별되면, 상기 인공지능 모델에서 출력되는 신체 부위에 대한 정보에 기초하여 상기 부정적인 운동 효 과가 나타나는 신체 부위에 대한 정보를 표시할 수 있다."}
{"patent_id": "10-2020-0122526", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 다양한 실시 예에 따르면, 사용자의 자세 식별을 위한 인공지능 모델이 위치 데이터 및 위치 데이터 를 회전시켜 획득된 추가 위치 데이터에 기초하여 학습된다. 사용자가 다양한 각도에서 촬영되더라고, 영상에 포함된 사용자의 자세를 보다 정확히 식별할 수 있게 된다."}
{"patent_id": "10-2020-0122526", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 다양한 실시 예가 첨부된 도면을 참조하여 기재된다. 그러나, 이는 본 문서에 기재된 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 문서의 실시 예의 다양한 변경(modifications), 균등물 (equivalents), 및/또는 대체물(alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다.본 개시에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제 3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메 모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 도 1은 본 개시의 일 실시 예에 따른 디스플레이 장치를 설명하기 위한 도면이다. 디스플레이 장치는 사용자의 홈 트레이닝을 위한 기능을 수행할 수 있다. 즉, 디스플레이 장치는 트레이닝 영상 즉, 운동 트레이너의 시범 영상을 디스플레이의 일 영역에 표시하고, 또한, 디스플레이 장치의 카메라를 통해 촬영된 영상을 디스플레이의 다른 영역에 표시할 수 있 다. 이에 따라, 사용자는 트레이닝 영상 속의 트레이너의 시범 자세를 따라하면서, 자신의 자세(또는, 운동 자세)를 확인할 수 있다. 한편, 디스플레이 장치는 사용자의 자세가 트레이닝 영상 속의 자세와 매칭되는지를 식별하고, 그에 대한 트레이닝 가이드를 제공할 수 있다. 여기에서, 트레이닝 가이드는 사용자의 자세가 트레이너의 자세와 매칭되는지 또는 매칭되지 않는지 등에 대한 정보를 포함할 수 있다. 이 경우, 디스플레이 장치는 인공지능 모델을 이용하여 사용자의 자세를 식별할 수 있다. 이때, 인공지능 모델은 다양한 각도에서 사용자가 촬영되더라고, 해당 영상으로부터 사용자의 자세를 식별할 수 있도록 훈련된 모델일 수 있다. 이에 따라, 본 개시의 일 실시 예에 따른 디스플레이 장치는 사용자의 자세를 보다 정확히 식별할 수 있으 며, 이하에서 보다 구체적으로 설명하도록 한다.도 2는 본 개시의 일 실시 예에 따른 디스플레이 장치의 구성을 설명하기 위한 블록도이다. 도 2를 참조하면, 디스플레이 장치는 카메라, 디스플레이, 메모리 및 프로세서를 포 함한다. 카메라는 촬영을 수행할 수 있다. 일 예로, 카메라는 디스플레이 장치의 전방에 대한 촬영을 수 행하여 이미지를 획득할 수 있다. 이를 위해, 카메라는 외부의 광을 수신하기 위한 이미지 센서를 포함할 수 있으며, 이미지 센서를 통해 촬 영된 이미지를 획득할 수 있다. 디스플레이는 영상을 표시할 수 있다. 이 경우, 디스플레이는 LCD, LED 또는 OLED 등과 같은 다양한 유형의 디스플레이로 구현될 수 있다. 메모리는 디스플레이 장치의 동작과 관련된 다양한 명령어, 프로그램 또는 데이터를 저장할 수 있다. 이를 위해, 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(flash-memory), 하드디스크 드라이브 (HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 여기에서, 메모리는 프로세서에 의해 액세스되며, 프로세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 특히, 메모리는 영상에 포함된 사용자의 자세를 식별하도록 훈련된 인공지능 모델을 포함할 수 있다. 이 경우, 인공지능 모델은 영상에 포함된 사용자의 자세를 식별하기 위한 분류기로 구현될 수 있으며, 이 때, 인공지능 모델은 사용자의 자세가 특정한 자세에 해당할 확률을 출력할 수 있다. 한편, 이하에서는 도 3 및 도 4를 참조하여, 인공지능 모델이 훈련되는 과정을 설명하도록 한다. 인공지능 모델은 이미지들에 포함된 사용자의 복수의 신체 부위에 대한 위치 데이터 및 위치 데이터에 기 초하여 획득된 추가 위치 데이터에 기초하여 사용자의 자세를 식별하도록 훈련된 모델일 수 있다. 여기에서, 이미지들은 인공지능 모델의 훈련을 위한 훈련 이미지들로, 이미지들에 포함된 사용자는 홈 트 레이닝을 수행하는 사용자와는 다른 사용자일 수 있다. 또한, 복수의 신체 부위에 대한 위치 데이터는 복수의 신체 부위에 대한 좌표 데이터로, 이미지에 포함된 사용 자의 복수의 관절 부위를 나타내는 복수의 키포인트(keypoints)를 포함할 수 있다. 이 경우, 위치 데이터의 획득을 위해, 이미지에서 사람의 관절의 포인트를 추출하기 위한 인공지능 모델(미도시)이 이용될 수 있다. 다만, 이는 일 예일 뿐이고, 위치 데이터는 다양한 방식으로 획득될 수 있음은 물론이다. 또한, 추가 위치 데이터는 위치 데이터를 회전시켜 획득된 데이터일 수 있다. 구체적으로, 이미지에서 획득된 복수의 키포인트는 2차원 좌표일 수 있는데, 이때, 2차원 좌표를 3차원으로 변 환하고, 3차원 좌표에 랜덤 회전 변환을 적용하여 복수의 3차원 좌표를 획득하고, 이를 다시 2차원로 변환하여 추가 위치 데이터를 획득할 수 있다. 이하에서, 본 개시의 일 실시 예에 따라 추가 위치 데이터를 획득하는 방법을 보다 구체적으로 살펴보도록 한다. 먼저, 이미지에서 획득된 복수의 키포인트에 대한 뎁스를 추정하고, 이를 이용하여 복수의 키포인트를 3차원으 로 변환할 수 있다. 구체적으로, 이미지에 포함된 사용자의 전체 크기에 대한 각 신체 부위의 크기의 비율을 통해, 각 신체 부위에 대한 예상 길이가 산출될 수 있다. 예를 들어, 전체 크기에 대한 신체 부위 별 크기의 비율에 따라, 신체 부위 별 길이가 미리 정의되어 있는 경우, 이미지에 포함된 사용자의 전체 크기에 대한 각 신체 부위의 크기의 비율을 통해, 각 신체 부위의 예상 길이가 산출될 수 있다. 여기에서, 신체 부위는 키포인트들에 의해 정의되는 신체 부위일 수 있다. 예를 들어, 키포인트가 손목과 팔꿈 치인 경우, 신체 부위는 이들 키포인트들에 의해 정의되는 손목과 팔목 사이의 팔 부분이 될 수 있다. 이후, 복수의 키포인트 중 어느 하나의 키포인트에 대한 뎁스 값 즉, z 값을 0으로 설정하고, 그와 인접한 키포 인트에 대한 뎁스 값을 산출할 수 있다. 예를 들어, 키포인트 (x1,y1)에 대해, z 값을 0으로 설정하는 경우, 키포인트의 3차원 좌표는 (x1,y1,z1)(여기에 서, z1=0)와 같이 나타낼 수 있다. 이 경우, 키포인트 (x1,y1) 및 키포인트 (x1,y1)와 인접한 키포인트 (x2,y2)에 의해 정의되는 신체 부위의 예상 거리를 L이라고 할 때, 인접한 키포인트 (x2,y2)의 뎁스 값 z2는 하기의 수학식 1에 기초하여 산출될 수 있다. 수학식 1"}
{"patent_id": "10-2020-0122526", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이에 따라, 키포인트 (x1,y1) 및 (x2,y2)는 각각 (x1,y1,z1) 및 (x2,y2,z2)와 같은 3차원 좌표로 변환될 수 있으며, 이러한 방법을 통해, z 값이 산출된 키포인트를 기초로 그와 인접한 키포인트의 z 값이 차례로 산출될 수 있다. 이에 따라, 결국, 복수의 키포인트 각각은 3차원으로 변환될 수 있다. 이후, 복수의 3차원 키포인트에 랜덤 회전 변환을 적용하여, 회전된 복수의 3차원 키포인트가 얻어질 수 있다. 구체적으로, 하기와 같은 수학식 2에 기초하여, 복수의 3차원 키포인트 각각에 대해 랜덤 회전 변환이 적용될 수 있다. 수학식 2"}
{"patent_id": "10-2020-0122526", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기에서, zy, ax, az는 각각 랜덤하게 선택된 각도, (x,y,z)는 3차원 키포인트, (x',y',z')는 랜덤 회전 변환 이 적용된 3차원 키포인트를 의미할 수 있다. 이에 따라, 복수의 3차원 키포인트 각각에 대해, 회전된 3차원 키포인트가 얻어질 수 있다. 이후, 복수의 회전된 3차원 키포인트를 2차원으로 변환하여, 추가 위치 데이터가 획득될 수 있다. 구체적으로, 복수의 회전된 3차원 키포인트 (x',y',z') 각각을 2차원으로 투영하여, (x',y')와 같은 2차원 키포 인트를 획득할 수 있다. 이에 따라, 복수의 회전된 3차원 키포인트가 2차원으로 변환된 복수의 2차원 키포인트를 획득할 수 있으며, 이 에 따라, 복수의 2차원 키포인트를 포함하는 추가 위치 데이터가 획득될 수 있다. 한편, 이미지들은 제1 자세 또는 제2 자세로 운동을 수행하는 사용자가 촬영된 이미지들일 수 있다. 먼저, 인공지능 모델은 이미지들에 포함된 제1 자세의 사용자의 복수의 신체 부위에 대한 위치 데이터 및 위치 데이터에 기초하여 획득된 추가 위치 데이터에 기초하여 사용자의 제1 자세를 식별하도록 훈련될 수 있다. 여기에서, 제1 자세는 트레이닝 영상에 대응되는 자세와 매칭되는 자세일 수 있다. 구체적으로, 제1 자세는 트레이닝 영상에 포함된 트레이너의 시범 자세와 동일한 자세이며, 얼굴, 목, 몸통, 팔, 다리 등의 방향 및 각도가 트레이너의 시범 자세와 기설정된 임계 범위 내인 자세일 수 있다. 즉, 인공지능 모델은 정확한 자세로 운동을 하는 사용자가 촬영된 이미지들을 이용하여, 트레이닝 영상에 매칭되는 사용자의 자세를 식별하도록 훈련될 수 있다. 예를 들어, 도 3을 참조하면, \"스쿼트\"를 하는 사용자가 촬영된 이미지들에서 위치 데이터가 획득되 고, 위치 데이터에 기초하여 추가 위치 데이터가 획득될 수 있다. 이 경우, 인공지능 모델은 위치 데이터 및 추가 위치 데이터를 입력 데이터로, \"스쿼트\" 자세를 출력 데이터로 하여 훈련될 수 있다. 이와 마찬가지로, 인공지능 모델은 \"런지\"를 하는 사용자가 촬영된 이미지들에서 획득된 위치 데이터 및 위치 데이터를 기초로 획득된 추가 위치 데이터를 입력 데이터로, \"런지\" 자세를 출력 데이 터로 하여 훈련될 수 있다. 또한, 인공지능 모델은 \"플랭크\"를 하는 사용자가 촬영된 이미지들에서 획득된 위치 데이터 및 위치 데이터를 기초로 획득된 추가 위치 데이터를 입력 데이터로, \"플랭 크\" 자세를 출력 데이터로 하여 훈련될 수 있다. 이와 같이, 인공지능 모델은 복수의 자세 별로, 각 자세를 취하는 사용자가 촬영된 이미지들로부터 획득된 위치 데이터 및 위치 데이터에 기초하여 획득된 추가 위치 데이터를 통해 훈련될 수 있다. 이에 따라, 인공지능 모델은 사용자를 촬영한 영상에서 획득된 사용자의 복수의 신체 부위에 대한 위치 데 이터가 입력되면, 영상에 포함된 사용자의 자세를 출력하도록 훈련될 수 있다. 한편, 실시 예에 따라, 인공지능 모델은 제1 자세에 따라 운동 효과가 나타나는 신체 부위를 식별하도록 훈련될 수 있다. 즉, 인공지능 모델은 위치 데이터 및 추가 위치 데이터뿐만 아니라, 사용자의 자세에 따라 효과가 나타내 는 신체 부위에 대한 정보를 입력 데이터로 하여 훈련될 수 있다. 예를 들어, \"스쿼트\"는 다리, 엉덩이 및 허벅지 안쪽이 효과적인 운동으로 볼 수 있다. 이 경우, 인공지능 모델은 \"스쿼트\"에 대한 위치 데이터 및 추가 위치 데이터뿐만 아니라, 다리, 엉덩이 및 허벅지 안쪽에 대한 정보를 입력 데이터로, \"스쿼트\" 자세 및 \"다리, 엉덩이 및 허벅지 안쪽\"을 출력 데이터 로 하여 훈련될 수 있다. 이에 따라, 인공지능 모델은 사용자를 촬영한 영상에서 획득된 사용자의 복수의 신체 부위에 대한 위치 데 이터가 입력되면, 영상에 포함된 사용자의 자세 및 해당 자세에서 운동 효과가 나타나는 신체 부위에 대한 정보 를 출력하도록 훈련될 수 있다. 한편, 인공지능 모델은 이미지들에 포함된 제2 자세의 사용자의 복수의 신체 부위에 대한 위치 데이터 및 위치 데이터에 기초하여 획득된 추가 위치 데이터에 기초하여 사용자의 제2 자세를 식별하도록 훈련될 수 있다. 여기에서, 제2 자세는 트레이닝 영상에 대응되는 자세와 매칭되지 않는 자세일 수 있다. 구체적으로, 제2 자세는 트레이닝 영상에 포함된 트레이너의 시범 자세와 동일한 자세이지만, 얼굴, 목, 몸통, 팔, 다리 등의 방향 및 각도가 트레이너의 시범 자세와 기설정된 임계 범위를 벗어난 자세일 수 있다. 즉, 인공지능 모델은 부정확한 자세로 운동을 하는 사용자가 촬영된 이미지들을 이용하여, 트레이닝 영상 에 매칭되지 않는 사용자의 자세를 식별하도록 훈련될 수 있다. 예를 들어, 도 4를 참조하면, 부정확한 자세로 \"스쿼트\"를 하는 사용자가 촬영된 이미지들에서 위치 데이 터가 획득되고, 위치 데이터에 기초하여 추가 위치 데이터가 획득될 수 있다. 이 경우, 인공지능 모델은 위치 데이터 및 추가 위치 데이터를 입력 데이터로, \"부정확한 스쿼 트\" 자세를 출력 데이터로 하여 훈련될 수 있다. 이와 마찬가지로, 인공지능 모델은 부정확한 자세로 \"런지\"를 하는 사용자가 촬영된 이미지들에서 획 득된 위치 데이터 및 위치 데이터를 기초로 획득된 추가 위치 데이터를 입력 데이터로, \"부정확 한 런지\" 자세를 출력 데이터로 하여 훈련될 수 있다. 또한, 인공지능 모델은 부정확하 자세로 \"플랭크\"를 하는 사용자가 촬영된 이미지들에서 획득된 위치 데이터 및 위치 데이터를 기초로 획득된 추가 위치 데이터를 입력 데이터로, \"부정확한 플랭크\" 자세를 출력 데이터로 하여 훈련될 수 있다. 이와 같이, 인공지능 모델은 복수의 자세 별로, 부정확한 자세를 취하는 사용자가 촬영된 이미지들로부터 획득된 위치 데이터 및 위치 데이터에 기초하여 획득된 추가 위치 데이터를 통해 훈련될 수 있다. 이에 따라, 인공지능 모델은 사용자를 촬영한 영상에서 획득된 사용자의 복수의 신체 부위에 대한 위치 데 이터가 입력되면, 영상에 포함된 사용자의 부정확한 자세를 출력하도록 훈련될 수 있다.한편, 실시 예에 따라, 인공지능 모델은 제2 자세에 따라 부정적인 운동 효과가 나타나는 신체 부위를 식 별하도록 훈련될 수 있다. 즉, 인공지능 모델은 위치 데이터 및 추가 위치 데이터뿐만 아니라, 사용자의 부정확한 자세에 따라 나쁜 효과를 미치는 신체 부위에 대한 정보를 입력 데이터로 하여 훈련될 수 있다. 예를 들어, \"부정확한 런지\"는 허리에 무리를 줄 수 있다. 이 경우, 인공지능 모델은 \"부정확한 런지\"에 대한 위치 데이터 및 추가 위치 데이터뿐만 아니라, 허리에 대한 정보를 입력 데이터로, \"스쿼트\" 자세 및 \"허 리\"를 출력 데이터로 하여 훈련될 수 있다. 이에 따라, 인공지능 모델은 사용자를 촬영한 영상에서 획득된 사용자의 복수의 신체 부위에 대한 위치 데 이터가 입력되면, 영상에 포함된 사용자의 부정확한 자세 및 해당 자세에서 부정적인 운동 효과가 나타나는 신 체 부위에 대한 정보를 출력하도록 훈련될 수 있다. 한편, 전술한 바와 같이, 본 개시의 일 실시 예에 따르면, 인공지능 모델은 위치 데이터 및 위치 데이터를 회전시켜 획득된 추가 위치 데이터에 기초하여 학습된다는 점에서, 사용자가 다양한 각도에서 촬영되더라고, 해 당 영상에 포함된 사용자의 자세를 식별할 수 있게 된다. 이에 따라, 본 개시의 일 실시 예에 따르면, 사용자가 디스플레이 장치의 정면이 아닌, 환경 여건에 따라 자신이 편한 위치에서 트레이닝 영상을 따라 운동을 수행하더라도, 사용자의 자세가 정확히 식별될 수 있게 된 다. 한편, 전술한 인공지능 모델의 훈련은 서버(미도시)에 의해 수행되고, 이후, 디스플레이 장치의 제조 시, 메모리에 저장될 수 있으며, 또한, 서버(미도시)로부터 다운로드되어 메모리에 저장될 수 있다. 또한, 이러한 훈련은 프로세서에 의해 수행될 수도 있다. 프로세서는 카메라, 디스플레이 및 메모리와 전기적으로 연결되어, 디스플레이 장치 의 전반적인 동작 및 기능을 제어할 수 있다. 여기에서, 프로세서는 중앙처리장치(central processing unit, CPU) 또는 어플리케이션 프로세서 (application processor, AP)를 포함할 수 있으며, 메모리에 저장된 하나 이상의 인스트럭션에 따라 메모 리에 저장된 하나 이상의 소프트웨어 프로그램을 실행할 수 있다. 먼저, 프로세서는 트레이닝 영상 및 카메라에 의해 촬영된 영상을 표시하도록 디스플레이를 제 어할 수 있다. 여기에서, 트레이닝 영상은 운동 트레이너의 시범 영상을 포함할 수 있다. 이 경우, 트레이닝 영상은 메모리 에 저장되어 있거나, 스트리밍 통해 디스플레이 장치로 제공될 수 있다. 예를 들어, 프로세서는 트레이닝 어플리케이션을 실행하기 위한 사용자 명령이 입력되면, 메모리에 저장된 트레이닝 어플리케이션을 실행할 수 있다. 여기에서, 트레이닝 어플리케이션은 디스플레이 장치의 제조 시, 메모리에 저장될 수 있으며, 또한, 다양한 어플리케이션을 제공하는 서버(미도시)로부터 어플리 케이션과 함께 다운로드되어 메모리에 저장될 수 있다. 그리고, 프로세서는 트레이닝 영상을 디스플레이의 일 영역에 표시할 수 있다. 또한, 프로세서 는 카메라를 통해 디스플레이 장치의 전방을 촬영하고, 촬영된 영상을 디스플레이의 다른 영역 에 표시할 수 있다. 그리고, 프로세서는 촬영된 영상에 포함된 사용자의 복수의 신체 부위에 대한 위치 데이터를 인공지능 모 델에 입력하여, 촬영된 영상에 포함된 사용자의 자세를 식별하고, 사용자의 자세가 트레이닝 영상에 대응 되는 자세와 매칭되는지를 식별할 수 있다. 여기에서, 복수의 신체 부위에 대한 위치 데이터는 복수의 신체 부위에 대한 좌표 데이터로, 이미지에 포함된 사용자의 복수의 관절 부위를 나타내는 복수의 키포인트를 포함할 수 있다. 이 경우, 위치 데이터의 획득을 위해, 이미지에서 사람의 관절의 포인트를 추출하기 위한 인공지능 모델(미도시)이 이용될 수 있다. 이 경우, 인공지능 모델(미도시)은 메모리에 저장되어 있을 수 있다. 즉, 프로세서는 촬영된 영상을 인공지능 모델(미도시)에 입력하여 촬영된 영상에 포함된 사용자의 복수의 신체 부위에 대한 위치 데이터를 획득하고, 획득된 위치 데이터를 인공지능 모델에 입력할 수 있다.다만, 이는 일 예일 뿐이고, 위치 데이터는 다양한 방식으로 획득될 수 있음은 물론이다. 그리고, 프로세서는 트레이닝 영상에 대응되는 자세를 식별할 수 있다. 이 경우, 트레이닝 영상에 대한 메 타데이터는 트레이닝 영상의 시간 별로 트레이닝 영상에 포함된 트레이너가 수행하는 자세에 대한 정보를 포함 할 수 있다. 이 경우, 프로세서는 트레이닝 영상에 대한 메타데이터를 이용하여, 트레이닝 영상 속의 트레이너가 수행 하는 자세를 판단할 수 있다. 또한, 프로세서는 촬영된 영상에 포함된 사용자의 자세를 식별할 수 있다. 구체적으로, 프로세서는 인공지능 모델에서 출력되는 확률에 기초하여 촬영된 영상에 포함된 사용자의 자세를 식별할 수 있다. 이 경우, 프로세서는 기설정된 임계 값보다 큰 확률을 갖는 자세를 사용자의 자세로 식별할 수 있다. 예를 들어, 인공지능 모델에서 출력된 \"스쿼트\" 자세에 해당하는 확률이 기설정된 임계 값보다 큰 경우, 프로세서는 사용자의 자세가 \"스쿼트\"인 것으로 식별할 수 있다. 이 경우, 프로세서는 사용자의 자세가 트레이닝 영상에 대응되는 자세와 매칭되는 것으로 식별할 수 있다. 다른 예로, 인공지능 모델에서 출력된 \"부정확한 런지\" 자세에 해당하는 확률이 기설정된 임계 값보다 큰 경우, 프로세서는 사용자의 자세가 확률이 \"부정확한 런지\"인 것으로 식별할 수 있다. 이 경우, 프로세서는 사용자의 자세가 트레이닝 영상에 대응되는 자세와 매칭되지 않는 것으로 식별할 수 있다. 그리고, 프로세서는 사용자의 자세와 트레이닝 영상에 대응되는 자세의 매칭 여부에 기초하여 트레이닝 가 이드를 표시하도록 디스플레이를 제어할 수 있다. 구체적으로, 프로세서는 사용자의 자세가 트레이닝 영상에 대응되는 자세와 매칭되는 것으로 식별되면, 사 용자의 자세가 트레이닝 영상에 대응되는 자세와 매칭됨을 나타내는 정보를 포함하는 트레이닝 가이드를 표시할 수 있다. 예를 들어, 도 5a와 같이, 프로세서는 디스플레이의 일 영역에 트레이닝 영상을 표시하고, 디스 플레이의 다른 영역에 사용자가 촬영된 영상을 표시할 수 있다. 이 경우, 프로세서는 사용자의 자세가 트레이닝 영상에 대응되는 자세와 매칭되는 것으로 식별되면, \"정확 한 스쿼트 자세입니다\"와 같은 텍스트를 포함하는 트레이닝 가이드를 디스플레이에 표시할 수 있다. 한편, 실시 예에 따라, 프로세서는 사용자의 자세가 트레이닝 영상에 대응되는 자세와 매칭되는 정도를 나 타내는 정확도에 대한 정보를 디스플레이에 표시할 수도 있다. 이 경우, 정확도는 사용자의 자세가 특정한 자세에 해당할 확률에 기초하여 결정될 수 있다. 예를 들어, 도 5b와 같이, 프로세서는 \"정확한 스쿼트 자세입니다\", \"정확도: 98점\"과 같은 텍스트를 포함 하는 트레이닝 가이드를 디스플레이에 표시할 수 있다. 한편, 프로세서는 사용자의 자세가 트레이닝 영상에 대응되는 자세와 매칭되는 것으로 식별되면, 인공지능 모델에서 출력되는 신체 부위에 대한 정보에 기초하여 운동 효과가 나타나는 신체 부위에 대한 정보를 표 시하도록 디스플레이를 제어할 수 있다. 즉, 인공지능 모델에서는 식별된 사용자의 자세에 대해 운동 효과가 있는 신체 부위에 대한 정보가 출력될 수 있으며, 이 경우, 프로세서는 인공지능 모델에서 출력된 정보에 기초하여 운동 효과가 나타나는 신체 부위에 대한 정보를 디스플레이에 표시할 수 있다. 예를 들어, 사용자의 자세가 \"스쿼트\" 자세인 것으로 식별되면, 인공지능 모델은 \"스쿼트\" 자세에 의해 운 동 효과가 나타내는 신체 부위에 대한 정보로서 \"다리, 엉덩이 및 허벅지 안쪽\"을 출력할 수 있다. 이에 따라, 도 6a와 같이, 프로세서는 사용자의 자세가 \"스쿼트\" 자세인 것으로 식별되면, \"다리, 엉덩이 및 허벅지 안쪽에 효과가 있습니다\"와 같은 텍스트를 포함하는 트레이닝 가이드를 디스플레이에 표시 할 수 있다. 다른 예로, 프로세서는 운동에 효과가 있는 부위를 하이라이트시켜 디스플레이에 표시할 수 있다. 예를 들어, 도 6b와 같이, 프로세서는 촬영된 영상에 포함된 사용자의 다리, 엉덩이 및 허벅지 안쪽 부분 을 하이라이트하여, 해당 신체 부위가 운동에 효과가 있는 부위임을 나타낼 수도 있다. 한편, 프로세서는 사용자의 자세가 트레이닝 영상에 대응되는 자세와 매칭되지 않는 것으로 식별되면, 사 용자의 자세가 트레이닝 영상에 대응되는 자세와 매칭되지 않음을 나타내는 정보를 포함하는 트레이닝 가이드를 표시할 수 있다. 예를 들어, 도 7과 같이, 프로세서는 디스플레이의 일 영역에 트레이닝 영상을 표시하고, 디스 플레이의 다른 영역에 사용자가 촬영된 영상을 표시할 수 있다. 이 경우, 프로세서는 사용자의 자세가 트레이닝 영상에 대응되는 자세와 매칭되지 않는 것으로 식별되면, \"부정확한 런지 자세입니다\"와 같은 텍스트를 포함하는 트레이닝 가이드를 디스플레이에 표시할 수 있다. 한편, 프로세서는 사용자의 자세가 트레이닝 영상에 대응되는 자세와 매칭되지 않는 것으로 식별되면, 인 공지능 모델에서 출력되는 신체 부위에 대한 정보에 기초하여 부정적인 운동 효과가 나타나는 신체 부위에 대한 정보를 표시하도록 디스플레이를 제어할 수 있다. 즉, 인공지능 모델에서는 식별된 사용자의 부정확한 자세에 대해 부정적인 운동 효과가 있는 신체 부위에 대한 정보가 출력될 수 있으며, 이 경우, 프로세서는 인공지능 모델에서 출력된 정보에 기초하여 안 좋은 영향을 받는 신체 부위에 대한 정보를 디스플레이에 표시할 수 있다. 예를 들어, 사용자의 자세가 \"부정확한 런지\" 자세인 것으로 식별되면, 인공지능 모델은 \"부정확한 런지\" 자세에 의해 부정적인 운동 효과가 나타내는 신체 부위에 대한 정보로서 \"허리\"를 출력할 수 있다. 이에 따라, 도 8a와 같이, 프로세서는 사용자의 자세가 \"부정확한 런지\" 자세인 것으로 식별되면, \"허리에 무리가 되는 자세입니다\"와 같은 텍스트를 포함하는 트레이닝 가이드를 디스플레이에 표시할 수 있다. 다른 예로, 프로세서는 운동에 부정적인 효과가 있는 부위를 하이라이트시켜 디스플레이에 표시할 수 있다. 예를 들어, 도 8b와 같이, 프로세서는 촬영된 영상에 포함된 사용자의 허리 부분을 하이라이트하여, 해당 신체 부위에 안 좋은 영향을 받을 수 있는 부위임을 나타낼 수도 있다. 이와 같이, 본 개시의 다양한 실시 예에 따르면, 디스플레이 장치는 사용자의 자세를 식별하고, 사용자의 자세가 트레이닝 영상에 포함된 트레이너의 자세와 매칭되는지에 따라 트레이닝 가이드를 제공할 수 있다. 도 9는 본 개시의 일 실시 예에 따른 디스플레이 장치의 세부 구성을 설명하기 위한 흐름도이다. 도 9를 참조하면, 디스플레이 장치는 카메라, 디스플레이, 메모리, 프로세서, 통신부 , 스피커 및 사용자 입력부를 포함할 수 있다. 여기에서, 이들 구성요소는 프로세서에 의 해 제어될 수 있다. 한편, 도 9에 도시된 구성요소는 일 예일 뿐이고, 실시 예에 따라 적어도 일부 구성요소가 생략되거나, 다른 구 성요소가 추가될 수 있음은 물론이다. 또한, 카메라, 디스플레이, 메모리 및 프로세서는 도 1 내지 도 8에서 설명한 바 있다는 점에서, 중복되는 부분에 대한 구체적인 설명은 생략하도록 한다. 통신부는 외부 기기와 통신을 수행하기 위한 구성이다. 구체적으로, 통신부는 네트워크를 통해 서버 (미도시) 등과 통신을 수행할 수 있다. 이를 위해, 통신부는 네트워크 카드 등과 같이, 네트워크에 접속하기 위한 다양한 모듈을 포함할 수 있다. 다른 예로, 통신부는 와이파이 통신을 수행하기 위한 와이파이 통신 모듈을 이용하여 네트워크에 접속할 수 있고, 이동통신을 수행하기 위한 이동통신 모듈을 이용하여 3G(Generation), LTE(Long Term Evolution), 5G 등과 같은 다양한 이동통신 방식을 통해 네트워크에 접속할 수도 있다. 이 경우, 프로세서는 통신부를 통해 다양한 어플리케이션을 제공하는 서버(미도시)에 접속하여, 어플 리케이션을 다운로드받을 수 있다. 일 예로, 프로세서는 통신부를 통해 서버(미도시)에 접속하여, 트레이닝 어플리케이션을 다운로드받을 수 있다. 또한, 프로세서는 통신부를 통해 서버(미도시)에 접속하여, 인공지능 모델을 다운로드받을 수도 있다. 스피커는 다양한 사운드를 출력할 수 있다. 예를 들어, 스피커는 트레이닝 영상에 대응되는 오디오를 출력할 수 있다. 사용자 입력부는 다양한 사용자 명령을 입력받기 위한 구성요소이다. 예를 들어, 사용자 입력부는 터 치 패널 등을 포함할 수 있으며, 또한, 디스플레이 장치를 제어하기 위한 리모컨 등으로부터 사용자 명령 을 수신할 수도 있다. 이 경우, 프로세서는 사용자 명령에 따라 각종 기능을 실행하도록 다른 구성요소를 제어할 수 있다. 예를 들어, 프로세서는 트레이닝 어플리케이션을 실행하기 위한 사용자 명령이 입력되면, 메모리에 저장된 트레이닝 어플리케이션을 실행할 수 있다. 그리고, 프로세서는 트레이닝 영상을 디스플레이의 일 영역에 표시하고, 카메라를 통해 촬영된 영상을 디스플레이의 다른 영역에 표시할 수 있다. 이 경우, 프로레서는 스피커를 통해 트레이 닝 영상에 대응되는 오디오를 출력할 수 있다. 이후, 프로세서는 카메라를 통해 촬영된 영상에 포함된 사용자의 자세를 식별하고, 사용자의 자세가 트레이닝 영상에 포함된 트레이너의 자세와 매칭되는지에 따라 트레이닝 가이드를 제공할 수 있다. 도 10은 본 개시의 일 실시 예에 따른 디스플레이 장치의 제어 방법을 설명하기 위한 흐름도이다. 먼저, 트레이닝 영상 및 카메라에 의해 촬영된 영상을 표시한다(S1010). 이후, 촬영된 영상에 포함된 사용자의 복수의 신체 부위에 대한 위치 데이터를 인공지능 모델에 입력하여 촬영 된 영상에 포함된 사용자의 자세를 식별한다(S1020). 여기에서, 인공지능 모델은 이미지들에 포함된 사용자의 복수의 신체 부위에 대한 위치 데이터 및 위치 데이터 에 기초하여 획득된 추가 위치 데이터에 기초하여 사용자의 자세를 식별하도록 훈련된 모델일 수 있다. 이 경우, 추가 위치 데이터는 위치 데이터를 회전시켜 획득될 수 있다. 그리고, 사용자의 자세와 트레이닝 영상에 대응되는 자세의 매칭 여부에 기초하여 트레이닝 가이드를 표시한다 (S1030). 한편, S1030 단계는 사용자의 자세가 트레이닝 영상에 대응되는 자세와 매칭되는 것으로 식별되면, 사용자의 자 세가 트레이닝 영상에 대응되는 자세와 매칭됨을 나타내는 정보를 포함하는 트레이닝 가이드를 표시하고, 사용 자의 자세가 트레이닝 영상에 대응되는 자세와 매칭되지 않는 것으로 식별되면, 사용자의 자세가 트레이닝 영상 에 대응되는 자세와 매칭되지 않음을 나타내는 정보를 포함하는 트레이닝 가이드를 표시할 수 있다. 또한, 인공지능 모델은 이미지들에 포함된 제1 자세의 사용자의 복수의 신체 부위에 대한 위치 데이터 및 위치 데이터에 기초하여 획득된 추가 위치 데이터에 기초하여 사용자의 제1 자세를 식별하도록 훈련될 수 있다. 여기에서, 제1 자세는 트레이닝 영상에 대응되는 자세와 매칭되는 자세일 수 있다. 또한, 인공지능 모델은 제1 자세에 따라 운동 효과가 나타나는 신체 부위를 식별하도록 훈련되고, S1030 단계는 사용자의 자세가 트레이닝 영상에 대응되는 자세와 매칭되는 것으로 식별되면, 인공지능 모델에서 출력되는 신 체 부위에 대한 정보에 기초하여 운동 효과가 나타나는 신체 부위에 대한 정보를 표시할 수 있다. 한편, 인공지능 모델은 이미지들에 포함된 제2 자세의 사용자의 복수의 신체 부위에 대한 위치 데이터 및 위치 데이터에 기초하여 획득된 추가 위치 데이터에 기초하여 사용자의 제2 자세를 식별하도록 훈련될 수 있다. 여기에서, 제2 자세는 트레이닝 영상에 대응되는 자세와 매칭되지 않는 자세일 수 있다. 또한, 인공지능 모델은 제2 자세에 따라 부정적인 운동 효과가 나타나는 신체 부위를 식별하도록 훈련되고, S1030 단계는 사용자의 자세가 트레이닝 영상에 대응되는 자세와 매칭되지 않는 것으로 식별되면, 인공지능 모 델에서 출력되는 신체 부위에 대한 정보에 기초하여 부정적인 운동 효과가 나타나는 신체 부위에 대한 정보를 표시할 수 있다.한편, 인공지능 모델을 이용하여 사용자의 자세를 식별하고, 그에 따라 가이드 정보를 제공하는 구체적인 방법 은 설명한 바 있다. 한편, 본 개시의 일시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기 기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 기기를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 프로세서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프 리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non- transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체 에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치들(예: 스 마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2020-0122526", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2020-0122526", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 디스플레이 장치를 설명하기 위한 도면, 도 2는 본 개시의 일 실시 예에 따른 디스플레이 장치의 구성을 설명하기 위한 블록도, 도 3 및 도 4는 본 개시의 일 실시 예에 따라 인공지능 모델이 훈련되는 과정을 설명하기 위한 도면들, 도 5a 및 도 5b는 본 개시의 일 실시 예에 따라 디스플레이 장치에서 트레이닝 가이드를 제공하는 방법을 설명 하기 위한 도면들, 도 6a 및 도 6b는 본 개시의 일 실시 예에 따라 디스플레이 장치에서 트레이닝 가이드를 제공하는 방법을 설명 하기 위한 도면들, 도 7은 본 개시의 일 실시 예에 따라 디스플레이 장치에서 트레이닝 가이드를 제공하는 방법을 설명하기 위한 도면, 도 8a 및 도 8b는 본 개시의 일 실시 예에 따라 디스플레이 장치에서 트레이닝 가이드를 제공하는 방법을 설명 하기 위한 도면들, 도 9는 본 개시의 일 실시 예에 따른 디스플레이 장치의 세부 구성을 설명하기 위한 블록도, 그리고 도 10은 본 개시의 일 실시 예에 따른 디스플레이 장치의 제어 방법을 설명하기 위한 흐름도이다."}
