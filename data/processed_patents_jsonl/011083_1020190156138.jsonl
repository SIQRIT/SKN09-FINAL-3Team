{"patent_id": "10-2019-0156138", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0066645", "출원번호": "10-2019-0156138", "발명의 명칭": "스탠드형 스마트 리딩 기기 및 그 제어 방법", "출원인": "네이버 주식회사", "발명자": "박지희"}}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라, 조명 및 스피커가 결합된 스마트 리딩 기기의 동작 방법에 있어서, 사용자의 명령을 기반으로, 상기 카메라를 통해 입력되는 영상을 획득하는 단계;상기 획득된 영상에서 인쇄물의 페이지를 검출하는 단계;상기 검출된 페이지를 기반으로, 상기 인쇄물과 상기 검출된 페이지를 검색하는 단계; 상기 검출된 페이지가 검색되면, 상기 스피커를 통해 상기 검색된 페이지에 대해 미리 설정된 음원을 재생하는단계; 상기 검출된 페이지가 검색되지 않으면, 상기 검출된 페이지의 텍스트를 인식하는 단계; 및상기 스피커를 통해 상기 인식된 텍스트에 대해 음성을 발화하는 단계를 포함하는 방법."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 텍스트를 인식하는 단계는,OCR(optical character reader)을 통해 상기 검출된 페이지를 스캔하여 상기 텍스트를 인식하는 방법."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 검출된 페이지를 검색하는 단계는, 인쇄물의 각 페이지에 대한 적어도 하나의 이미지와 각 이미지에 대응하여 미리 설정된 음원이 매핑되어 있는데이터베이스를 검색하여, 상기 검출된 페이지를 검색하는 방법."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 검출된 페이지를 검색하는 단계는,상기 데이터베이스로부터 상기 검출된 페이지와 유사도가 가장 높은 이미지를 선택하는 방법."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 데이터베이스로부터 상기 검출된 페이지와의 유사도가 미리 정해진 임계값을 초과하는 적어도 하나의 이미지를 검색하는 단계; 및상기 검색된 이미지 중 가장 높은 유사도의 이미지를 선택하는 단계를 포함하는 방법."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 데이터베이스는,공개특허 10-2021-0066645-3-상기 스마트 리딩 기기의 외부 서버에 저장되어 있는 방법."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 음성을 발화하는 단계는, 상기 텍스트를 분석하여, 각 문장에 대해 적어도 하나의 음성 태그를 검출하는 단계;상기 텍스트에 상기 음성 태그를 반영하여, 상기 음성을 합성하는 단계; 및상기 음성을 발화하는 단계를 포함하고, 상기 음성 태그는,상기 문장의 유형, 화자 또는 감정 중 적어도 어느 하나를 나타내는 방법."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 획득된 영상과 상기 카메라를 통해 입력되는 영상을 비교하여, 상기 검출된 페이지로부터 다른 페이지로의페이지 넘김을 감지하는 단계; 상기 입력되는 영상을 획득하여, 상기 다른 페이지의 텍스트를 인식하는 단계; 및상기 스피커를 통해 상기 인식된 텍스트에 대해 음성을 발화하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 페이지 넘김을 감지하는 단계는, 상기 획득된 영상에서 미리 정해진 위치의 일부 영역과 상기 입력되는 영상에서 상기 위치의 일부 영역을 비교하는 방법."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 텍스트를 인식하는 단계는,CGD(combination of multiple global descriptors) 프레임워크를 기반으로, 상기 텍스트를 인식하는 방법."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "스마트 리딩 기기에 있어서, 카메라, 조명 및 스피커; 및상기 카메라, 조명 및 스피커와 연결되고, 사용자의 명령을 기반으로, 상기 카메라를 통해 입력되는 영상을 획득하도록 구성되는 적어도 하나의 프로세서를 포함하고, 상기 프로세서는, 상기 획득된 영상에서 인쇄물의 페이지를 검출하고, 상기 검출된 페이지를 기반으로, 상기 인쇄물과 상기 검출된 페이지를 검색하고, 상기 검출된 페이지가 검색되면, 상기 스피커를 통해 상기 검색된 페이지에 대해 미리 설정된 음원을 재생하고,공개특허 10-2021-0066645-4-상기 검출된 페이지가 검색되지 않으면, 상기 검출된 페이지의 텍스트를 인식하고, 상기 스피커를 통해 상기 인식된 텍스트에 대해 음성을 발화하도록 구성되는 기기."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 프로세서는,OCR을 통해 상기 검출된 페이지를 스캔하여 상기 텍스트를 인식하도록 구성되는 기기."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 프로세서는,인쇄물의 각 페이지에 대한 적어도 하나의 이미지와 각 이미지에 대응하여 미리 설정된 음원이 매핑되어 있는데이터베이스를 검색하여, 상기 검출된 페이지를 검색하도록 구성되는 기기."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 프로세서는, 상기 데이터베이스로부터 상기 검출된 페이지와 유사도가 가장 높은 이미지를 선택하도록 구성되는 기기."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 데이터베이스로부터 상기 검출된 페이지와의 유사도가 미리 정해진 임계값을 초과하는 적어도 하나의 이미지를 검색하고, 상기 검색된 이미지 중 가장 높은 유사도의 이미지를 선택하도록 구성되는 기기."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서, 상기 프로세서와 연결되고, 상기 데이터베이스를 저장하고 있는 외부 서버와 통신하기 위한 통신 인터페이스 중적어도 어느 하나를 더 포함하는 기기."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서, 상기 프로세서는,상기 텍스트를 분석하여, 각 문장에 대해 적어도 하나의 음성 태그를 검출하고, 상기 텍스트에 상기 음성 태그를 반영하여, 상기 음성을 합성하고, 상기 음성을 발화하도록 구성되고, 상기 음성 태그는,상기 문장의 유형, 화자 또는 감정 중 적어도 어느 하나를 나타내는 기기. 공개특허 10-2021-0066645-5-청구항 18 제11항에 있어서, 상기 프로세서는, 상기 획득된 영상과 상기 카메라를 통해 입력되는 영상을 비교하여, 상기 검출된 페이지로부터 다른 페이지로의페이지 넘김을 감지하고, 상기 입력되는 영상을 획득하여, 상기 다른 페이지의 텍스트를 인식하고, 상기 스피커를 통해 상기 인식된 텍스트에 대해 음성을 발화하도록 구성되는 기기."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 프로세서는,상기 획득된 영상에서 미리 정해진 위치의 일부 영역과 상기 입력되는 영상에서 상기 위치의 일부 영역을 비교하도록 구성되는 기기."}
{"patent_id": "10-2019-0156138", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서, 상기 프로세서는, CGD 프레임워크를 기반으로, 상기 텍스트를 인식하도록 구성되는 기기."}
{"patent_id": "10-2019-0156138", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다양한 실시예들에 따른 스마트 리딩 기기 및 그 제어 방법이 개시된다. 다양한 실시예들에 따른 스마트 리딩 기 기는 카메라, 조명 및 스피커와 결합되고, 사용자의 명령을 기반으로, 카메라를 통해 입력되는 영상을 획득하고, 획득된 영상에서 인쇄물의 페이지를 검출하고, 검출된 페이지를 기반으로, 인쇄물과 검출된 페이지를 검색하고, 검출된 페이지가 검색되면, 스피커를 통해 검색된 페이지에 대해 미리 설정된 음원을 재생하고, 검출된 페이지 가 검색되지 않으면, 검출된 페이지의 텍스트를 인식하고, 스피커를 통해, 인식된 텍스트에 대해 음성을 발화하 도록 구성된다."}
{"patent_id": "10-2019-0156138", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 책을 읽어주는 기술에 관한 것이다."}
{"patent_id": "10-2019-0156138", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "유아나 저학년 아동과 같은 저연령 학습자를 위해 책을 읽어주는 기술이 제안되고 있다. 예를 들어, 한국등록특허 제10-0415236호(등록일 2004년 01월 02일)에는 정전유도방식을 이용하여 학습지에 인 쇄된 학습내용(글이나 그림 등)에 전자펜을 접촉하면 접촉 위치에 해당되는 관련 학습 내용을 음성으로 출력하 는 기술이 개시되어 있다."}
{"patent_id": "10-2019-0156138", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "카메라와 조명, 그리고 스피커가 결합된 스탠드 타입의 스마트 리딩 기기를 제공한다. 책을 스캔하여 인식된 텍스트를 음성으로 발화할 수 있는 스마트 리딩 기기 및 그 제어 방법을 제공한다. 원하는 목소리를 선택하여 책을 읽어줄 수 있는 스마트 리딩 기기 및 그 제어 방법을 제공한다. 책을 다양한 언어로 번역하여 읽어줄 수 있는 스마트 리딩 기기 및 그 제어 방법을 제공한다. 악보를 스캔하여 다양한 악기의 연주를 제공할 수 있는 스마트 리딩 기기 및 그 제어 방법을 제공한다. 피보호자의 실시간 모니터링과 보호자와 피보호자 간의 커뮤니케이션을 제공할 수 있는 스마트 리딩 기기 및 그 제어 방법을 제공한다. 영상 촬영을 통해 영상 컨텐츠를 제작할 수 있는 스마트 리딩 기기 및 그 제어 방법을 제공한다."}
{"patent_id": "10-2019-0156138", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "다양한 실시예들에 따르면, 카메라, 조명 및 스피커가 결합된 스마트 리딩 기기의 동작 방법은, 사용자의 명령 을 기반으로, 상기 카메라를 통해 입력되는 영상을 획득하는 단계, 상기 획득된 영상에서 인쇄물의 페이지를 검 출하는 단계, 상기 검출된 페이지를 기반으로, 상기 인쇄물과 상기 검출된 페이지를 검색하는 단계, 상기 검출 된 페이지가 검색되면, 상기 스피커를 통해 상기 검색된 페이지에 대해 미리 설정된 음원을 재생하는 단계, 상 기 검출된 페이지가 검색되지 않으면, 상기 검출된 페이지의 텍스트를 인식하는 단계, 및 상기 스피커를 통해 상기 인식된 텍스트에 대해 음성을 발화하는 단계를 포함한다. 다양한 실시예들에 따르면, 스마트 리딩 기기는, 카메라, 조명 및 스피커, 및 상기 카메라, 조명 및 스피커와 연결되고, 사용자의 명령을 기반으로, 상기 카메라를 통해 입력되는 영상을 획득하도록 구성되는 적어도 하나의 프로세서를 포함하고, 상기 프로세서는, 상기 획득된 영상에서 인쇄물의 페이지를 검출하고, 상기 검출된 페이 지를 기반으로, 상기 인쇄물과 상기 검출된 페이지를 검색하고, 상기 검출된 페이지가 검색되면, 상기 스피커를 통해 상기 검색된 페이지에 대해 미리 설정된 음원을 재생하고, 상기 검출된 페이지가 검색되지 않으면, 상기 검출된 페이지의 텍스트를 인식하고, 상기 스피커를 통해 상기 인식된 텍스트에 대해 음성을 발화하도록 구성된 다."}
{"patent_id": "10-2019-0156138", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들에 따르면, 카메라와 조명, 그리고 스피커가 결합된 스탠드 타입의 스마트 리딩 기기를 제공 할 수 있다. 본 발명의 실시예들에 따르면, 책을 스캔하여 인식된 텍스트를 음성으로 발화할 수 있다. 본 발명의 실시예들에 따르면, 원하는 목소리를 선택하여 책을 읽어줄 수 있다. 본 발명의 실시예들에 따르면, 책을 다양한 언어로 번역하여 읽어줄 수 있다. 본 발명의 실시예들에 따르면, 악보를 스캔하여 다양한 악기의 연주를 제공할 수 있다. 본 발명의 실시예들에 따르면, 피보호자의 실시간 모니터링과 보호자와 피보호자 간의 커뮤니케이션을 제공할 수 있다. 본 발명의 실시예들에 따르면, 영상 촬영을 통해 영상 컨텐츠를 제작할 수 있다."}
{"patent_id": "10-2019-0156138", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 본 발명의 실시예들은 책을 읽어주는 기술에 관한 것이다. 본 명세서에서 구체적으로 개시되는 것들을 포함하는 실시예들은 카메라와 조명, 그리고 스피커가 결합된 스마 트 리딩 기기로서 모든 책을 스캔하여 사용자가 원하는 목소리로 읽어줄 수 있는 스마트 리딩 기기를 제공할 수 있다. 도 1은 다양한 실시예들에 따른 컴퓨터 장치의 예를 도시한 블록도이다. 예를 들어, 본 발명의 실시예들에 따 른 스마트 리딩 기기는 도 1을 통해 도시된 컴퓨터 장치에 의해 구현될 수 있다. 도 1에 도시된 바와 같이 컴퓨터 장치는 본 발명의 실시예들에 따른 스마트 리딩 제어 방법을 실행하기 위 한 구성요소로서, 메모리, 프로세서, 통신 인터페이스 그리고 입출력 인터페이스를 포함할 수 있다. 메모리는 컴퓨터에서 판독 가능한 기록매체로서, RAM(random access memory), ROM(read only memory) 및 디스크 드라이브와 같은 비소멸성 대용량 기록장치(permanent mass storage device)를 포함할 수 있다. 여기서 ROM과 디스크 드라이브와 같은 비소멸성 대용량 기록장치는 메모리와는 구분되는 별도의 영구 저장 장치로 서 컴퓨터 장치에 포함될 수도 있다. 또한, 메모리에는 운영체제와 적어도 하나의 프로그램 코드가 저장될 수 있다. 이러한 소프트웨어 구성요소들은 메모리와는 별도의 컴퓨터에서 판독 가능한 기록매체로 부터 메모리로 로딩될 수 있다. 이러한 별도의 컴퓨터에서 판독 가능한 기록매체는 플로피 드라이브, 디 스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있다. 다른 실시예에서 소프트웨어 구성요소들은 컴퓨터에서 판독 가능한 기록매체가 아닌 통신 인터페이스를 통 해 메모리에 로딩될 수도 있다. 예를 들어, 소프트웨어 구성요소들은 네트워크를 통해 수신되는 파 일들에 의해 설치되는 컴퓨터 프로그램에 기반하여 컴퓨터 장치의 메모리에 로딩될 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리 또는 통신 인터페이스에 의해 프로세서로 제공될 수 있다. 예 를 들어 프로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 수신되는 명령을 실행 하도록 구성될 수 있다. 통신 인터페이스는 네트워크를 통해 컴퓨터 장치가 외부 기기, 예컨대 서버와 서로 통신하 기 위한 기능을 제공할 수 있다. 일 예로, 컴퓨터 장치의 프로세서가 메모리와 같은 기록 장치 에 저장된 프로그램 코드에 따라 생성한 요청이나 명령, 데이터, 파일 등이 통신 인터페이스의 제어에 따 라 네트워크를 통해 다른 장치들로 전달될 수 있다. 역으로, 다른 장치로부터의 신호나 명령, 데이터, 파 일 등이 네트워크를 거쳐 컴퓨터 장치의 통신 인터페이스를 통해 컴퓨터 장치로 수신될 수 있다. 통신 인터페이스를 통해 수신된 신호나 명령, 데이터 등은 프로세서나 메모리로 전달될 수 있고, 파일 등은 컴퓨터 장치가 더 포함할 수 있는 저장 매체(상술한 영구 저장 장치)로 저장될 수 있 다. 입출력 인터페이스는 입출력 장치와의 인터페이스를 위한 수단일 수 있다. 예를 들어, 입력 장치는 마이크, 키보드, 카메라 또는 마우스 등의 장치를, 그리고 출력 장치는 디스플레이, 스피커와 같은 장치를 포함 할 수 있다. 다른 예로 입출력 인터페이스는 터치스크린과 같이 입력과 출력을 위한 기능이 하나로 통합 된 장치와의 인터페이스를 위한 수단일 수도 있다. 입출력 장치는 컴퓨터 장치와 하나의 장치로 구 성될 수도 있다. 또한, 다른 실시예들에서 컴퓨터 장치는 도 1의 구성요소들보다 더 적은 혹은 더 많은 구성요소들을 포함 할 수도 있다. 그러나, 대부분의 종래기술적 구성요소들을 명확하게 도시할 필요성은 없다. 예를 들어, 컴퓨 터 장치는 상술한 입출력 장치 중 적어도 일부를 포함하도록 구현되거나 또는 트랜시버 (transceiver), 데이터베이스 등과 같은 다른 구성요소들을 더 포함할 수도 있다. 통신 방식은 제한되지 않으며, 네트워크가 포함할 수 있는 통신망(일 예로, 이동통신망, 유선 인터넷, 무 선 인터넷, 방송망)을 활용하는 통신 방식뿐만 아니라 기기들간의 근거리 유선/무선 통신 역시 포함될 수 있다. 예를 들어, 네트워크는, PAN(personal area network), LAN(local area network), CAN(campus area network), MAN(metropolitan area network), WAN(wide area network), BBN(broadband network), 인터넷 등의 네트워크 중 하나 이상의 임의의 네트워크를 포함할 수 있다. 또한, 네트워크는 버스 네트워크, 스타 네 트워크, 링 네트워크, 메쉬 네트워크, 스타-버스 네트워크, 트리 또는 계층적(hierarchical) 네트워크 등을 포 함하는 네트워크 토폴로지 중 임의의 하나 이상을 포함할 수 있으나, 이에 제한되지 않는다. 도 2는 다양한 실시예들에 있어서 스마트 리딩 기기를 예시적으로 도시한 사시도이다. 도 2를 참조하면, 본 발명의 실시예들에 따른 스마트 리딩 기기는 도 1을 통해 도시된 컴퓨터 장치로 구현될 수 있으며, 카메라, 조명, 그리고 스피커가 결합된 스탠드형 디바이스로 구성될 수 있다. 또한, 책이나 악보 같은 물체를 놓을 수 있는 패드 내지는 독서대 형태의 추가 구성(미도시)이 함께 구 비될 수 있다. 카메라와 조명이 포함된 헤드 부분은 수동 혹은 자동 회전이 가능한 구조물을 추가적으로 포함 할 수 있으며, 일 예로 X축과 Y축 및 Z축 중 적어도 둘 이상의 축을 중심으로 회전이 가능한 구조를 통해 카메 라와 조명이 바닥을 향하도록 회전하거나 혹은 정해진 곳(예컨대, 사용자 얼굴이나 움직임이 인식된 위치, 사용자가 디바이스와 연결된 앱을 이용하여 지정한 위치 등)을 향하도록 회전할 수 있다. 조명은 하나 이상의 LED를 배치하여 구성할 수 있다. 이 때 조명는 각각의 LED를 ON/OFF 하거나 밝 기, 색온도를 조절하여 필요에 따라 적절한 조명을 제공할 수 있다. 예를 들면, 카메라가 책을 촬영하는 중에 빛반사가 일어나는 경우 특정 위치의 LED를 OFF하거나 밝기를 조 절하여 빛반사를 없앨 수 있다. 카메라는 헤드 부분에 하나 위치하는 것으로 도시하였으나, 이 위치에 한정되는 것은 아니며, 필요에 따라 두 개 이상의 카메라가 구비될 수 있으며, 스탠드 본체 부분에 카메라가 위치할 수도 있다. 본 실시예들에서 스마트 리딩 기기는 음성 입력을 입력받기 위한 마이크(미도시), 영상을 입력받기 위한 카메라, 음성 출력을 위한 스피커를 입출력 장치로서 기본적으로 포함할 수 있다. 경우에 따라 서는 스마트 리딩 기기와의 인터페이스를 위한 수단으로서 디스플레이(미도시)나 입력 버튼 등이 더 포함 될 수 있다. 본 발명의 일 실시예에 따른 스마트 리딩 기기은 책 등의 인쇄물을 읽어주는 기능(독서 기능)을 제공한다. 스마트 리딩 기기는 이미지를 인식하여 해당 페이지에 맞는 음원을 재생할 수 있다. 만일 적절한 음원이 없는 경우 페이지 내의 텍스트를 인식하고, 음성 합성 기술을 통하여 해당 텍스트의 내용을 음성으로 출력한다. 이 때, 문장의 감정을 분석하거나, 화자가 누구인지를 파악하여 보다 자연스러운 합성 음성이 제공될 수 있도록 한다. 본 발명에 따른 스마트 리딩 기기는 그 외에도 악보 연주 기능, 커뮤니케이션 기능, 컨텐츠 제작 기능 등 사용자를 위한 다양한 기능을 제공할 수 있다. 본 발명에 따른 스마트 리딩 기기는 사용자의 활동을 기록 및 관리할 수 있다. 또한 이를 이용하여 사용 자의 취향이나 행동 패턴을 파악하거나 사용자에게 적합한 컨텐츠를 제공할 수 있다. 더 나아가, 스마트 리딩 기기는 음성 기반 인터페이스를 통해 사용자의 발화에 따라 입력되는 음성 입력을 포함하는 사용자 명령(이하, '음성 명령'이라 칭함)을 처리할 수 있는 인공지능(AI) 비서 서비스 기능을 포함할 수 있다. 스마트 리딩 기기는 직접 사용자의 음성 명령을 인식 및 분석하여 음성 명령에 알맞은 동작을 수행함으로 써 사용자 명령을 처리할 수도 있으나, 실시예에 따라서는 사용자의 음성 명령에 대한 인식이나 인식된 음성 명 령의 분석, 사용자에게 제공될 음성의 합성 등의 처리를 스마트 리딩 기기와 연계된 외부의 플랫폼을 통해 수행할 수도 있다. 본 발명에 따른 스마트 리딩 기기는 조명 기능을 제공할 수 있다. 사용자는 버튼, 음성 입력 또는 스마트 리딩 기기를 제어하는 별도 앱 등을 통하여 스마트 리딩 기기의 조명을 제어할 수 있다. 또한 일 실시예에 따 르면, 스마트 리딩 기기는 주변 환경에 따라 자동으로 적절하게 밝기 내지는 색온도 등 조명의 설정을 조절하거 나, 기 설정된 다양한 조명 모드를 사용자에게 제공 할 수 있다. 구체적으로 예를 들어, 현재 시간이나 위치에 따라, 조명을 조절할 수 있다. 예를 들면 위치에 따라 해가 뜨는 시간이 다르므로 이를 고려하고, 밝은 시간 대와 어두운 시간대의 조명의 밝기를 다르게 할 수 있다. 또한, 나 이대별로 선호하는 색온도가 다를 수 있으므로 음성 분석을 통해 현재 사용자를 파악하여 색온도를 조절할 수도 있다. 또한, 추가적으로 조도센서를 구비하여 정보를 획득하거나 카메라 내에 구비된 센서 정보를 활용하여, 입력된 정보에 따라 조명을 조절할 수도 있다. 예를 들면, 주변이 밝은 경우에 조명은 약하게, 주변이 어두운 경우에 조명은 밝게 자동으로 설정될 수 있다. 또한, 카메라 입력 영상을 통하여 주변 환경 정보를 획득하여 적 절한 상황에 맞는 조명을 제공할 수 있다. 예를 들어 입력된 영상을 통하여 주변이 어두운지 밝은지, 사람이 몇 명이 있는지, 사람이 어떤 행동을 하고 있는지 등을 분석하여 해당 상황에 맞는 조명을 설정할 수 있다. 사용자는 자동 조명 조정 기능을 사용할 것인지를 별도로 설정할 수 있으며, 만일 조명 자동 모드가 on 되어 있 는 경우, 현재 주변의 밝기를 감지하여 어두워지면 자동으로 적정 모드로 조명이 켜지게 된다. 스마트 리딩 기기는 적어도 하나 이상의 조명 모드(예를 들어 공부(학습)모드, 독서 모드, 창의력 모드, 취침(무드)모드, 명상 모드 등)를 제공할 수 있다. 각각의 조명 모드에서는 해당 모드에서 수행되는 동작에 적절한 색온도 및/또는 밝기의 조명을 제공할 수 있다. 예를 들어 공부 모드는 산수, 수학 등 문제 풀이에 적합한 환경을 의미하며 적절하게는 색온도 6500K~6900K 로, 독서 모드는 동화책 읽기나 영어 암기 등 언어를 읽는데 적합한 환경을 의미하며 적절하게는 색온도 4500K~4900K 로, 창의력 모드는 그림 그리기 등의 창의적 활동에 적합한 환경을 의미하며 색온도 적절하게는 색 온도 2600K~2900K 로, 취침 모드는 수면을 취하기에 적합한 환경을 의미하며 적절하게는 색온도 2200K~2800K로 설정할 수 있다. 밝기 조절 역시 각각의 모드에 대하여 적합한 값으로 설정될 수 있으며, 각 모드에 대한 색온 도 및 밝기/조도 값의 바람직한 일 예는 하기 [표 1]과 같다. 표 1"}
{"patent_id": "10-2019-0156138", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한편, 조도 센서를 이용하여 주변 조도에 따라 밝기를 조절할 경우, 이에 따라 설정되는 각 모드별 조명의 밝기 의 일 예는 하기 [표 2]와 같다. 표 2"}
{"patent_id": "10-2019-0156138", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 3, "content": "도 3은 도 1의 프로세서의 상세 구성을 도시한 도면이다. 도 3을 참조하면, 프로세서는 비전(vision) 모듈, 문자 인식 모듈, 문장 분석 모듈, 음성 처리 모듈 또는 대화 처리 모듈 중 적어도 어느 하나를 포함할 수 있다. 비전 모듈은 영상에서 인쇄물의 페이지를 검출할 수 있다. 그리고 비전 모듈은 검출된 페이지를 식별할 수 있다. 비전 모듈은 검출된 페이지에 대한 이미지를 획득하고, 검출된 페이지에 대한 이미지를 기반으로 데이터베 이스를 검색할 수 있다. 예를 들면, 비전 모듈은 딥러닝(deep learning)을 이용한 이미지 검색(image retrieval; IR) 기술을 이용하여, 적어도 하나의 인쇄물의 각 페이지에 대한 적어도 하나의 이미지들이 저장되 어 있는 데이터베이스를 검색하여 해당 페이지에 대한 정보가 기 저장되어있는지 확인할 수 있다. 이 때 데이터 베이스에는, 각 페이지에 대한 이미지에 대응하여 미리 설정된 음원이 매핑되어 저장되어 있을 수 있다. 데이터베이스는 스마트 리딩 기기의 내부의 메모리 및/또는 스마트 리딩 기기의 외부 기기, 예 컨대 서버나 플랫폼에 저장되어 있을 수 있다. 이러한 방식을 이용하여 이미 해당 페이지에 대한 음원 파일이 존재하는 경우 텍스트를 인식하고 음성을 하지 않더라도 빠르게 해당 페이지에 대한 소리를 사용자에게 제공할 수 있다. 또한 단순히 페이지 이미지 및 그에 대응하는 음원 파일을 데이터베이스에 추가하는 것만으로 제공 가능한 컨텐츠를 쉽게 확장할 수 있다. 본 발명의 일 실시예에 따르면, 데이터베이스 내에 검출된 페이지에 해당하는 정보가 저장되어있는지를 확인하 기 위하여 데이터베이스 내에 저장된 이미지들과의 유사도 검색을 수행할 수 있다. 예를 들어, 비전 모듈 은, 데이터베이스에 저장된 이미지들과 검출된 페이지 이미지 간의 유사도를 계산하고, 가장 유사도가 높은 이 미지를 선택할 수 있다. 가장 유사한 이미지가 미리 정해진 임계값 이상의 유사도를 만족하면, 검출된 페이지 의 이미지와 데이터베이스의 이미지는 동일한 인쇄물의 동일한 페이지를 촬영한 것으로 생각될 수 있고, 따라서 해당 이미지에 대한 정보를 검출된 페이지에 해당하는 페이지 정보로 식별할 수 있다. 이 때 가장 유사한 이미 지라 하더라도 미리 정해진 임계값을 초과하지 않는 경우에는 데이터베이스 내에 검출된 페이지에 해당하는 정 보가 존재하지 않는 것으로 판단할 수 있다. 인쇄물에 대한 특정 없이도 해당 페이지가 어떤 인쇄물의 어떤 페이지인지 알아내기 위하여는 이미지 검색을 빠 르고 정확하게 수행할 필요가 있다. 본 발명의 실시예에 따르면, 유사도 검색용 특징(feature)을 추출하기 위한 모델의 일 예로, 도 9b에 도시된 바와 같은 CGD(combination of multiple global descriptors) 프레임워크 를 이용할 수 있다. CGD 프레임워크는 하나의 백본 CNN에서 여러 가지 방법으로 global descriptor를 생성하고 이를 조합해서 유사도용 벡터로 사용하는 방법으로, 도메인에 적합한 모델로 fine tuning하기 위해 classification loss과 ranking loss를 함께 사용하여 한 번에 학습하는 방법으로, 여러 global descriptor 를 조합해서 사용할 수 있 어 실행 속도가 빠르면서도 좋은 성능을 낼 수 있다. 도 9b를 참조하여 보다 구체적으로 설명하면, 메인 모듈과 보조 모듈을 포함할 수 있다. 메인 모듈 은 CNN(convolution neural network)으로부터 추출된 서로 다른 복수의 글로벌 디스크립터(global descriptor; GD)(GD1, ..., GD N)들로부터 이미지 표현(image representation) 순위 손실(ranking loss)을 학 습할 수 있다. 여기서, 메인 모듈은 글로벌 디스크립터(GD1, ..., GD N)들을 FC 계층과 L2 계층을 기반으 로 각각 학습하고, 각각의 학습 결과를 결합시켜 이미지 표현의 순위 손실을 학습할 수 있다. 보조 모듈은 글로벌 디스크립터(GD1, ..., GD N)들 중 어느 하나로부터 이미지 표현의 분류 손실(classification loss)을 학습할 수 있다. 여기서, 보조 모듈은 글로벌 디스크립터(GD1, ..., GD N)들 중 어느 하나를 BN 계층과 FC 계층을 기반으로 학습하여, 이미지 표현의 분류 손실을 학습할 수 있다. 이 때 글로벌 디스크립터(GD1, ..., GD N)들은 글로벌 풀링 방법(global pooling method)에 의해 생성되며, 예컨대 콘볼루션의 합계 풀링(SPoC: sum pooling of convolution), 콘볼루션의 최대 활성화(MAC: maximum activation of convolution), 그리고 일반화 평균 풀링(GeM: generalized-mean pooling)을 포함할 수 있다. 본 발명의 일 실시예에서, 책 검색에 있어서는 GeM 을 단독으로 사용하는 것이 바람직할 수 있다. 문자 인식 모듈은 검출된 페이지의 텍스트를 인식할 수 있다. 예를 들면, 문자 인식 모듈은 OCR(optical character reader) 기술을 통해 검출된 페이지 내에 포함된 텍스트를 인식할 수 있다. OCR 기술을 이용하여 책 읽기를 제공하기 위해서는, 책 등 인쇄물의 경우 한 페이지 내에서 텍스트 배치가 다양 하여 어떤 부분을 어떻게, 어떤 순서로 읽어야하는지 문제가 될 수 있다. 도 9c는 본 발명의 일 실시예에 따른, 책 읽기에 적합한 문자 인식 모듈 내부 프로세스를 설명한 도면이다. 도면을 참조하면, 문자 인식 모듈은 이미지를 입력 받아, 딥러닝 기반의 글자 검출 모델을 이용 하여 이미지 내에 포함된 글자들이 이미지 내에 어떤 부분에 위치하는지를 검출(Text Detection)할 수 있다. 이렇게 검출된 부분에 대하여 딥러닝 기반의 글자 인식 모델을 이용하여 어떤 글자인지 글자를 인식(Text Recognition) 할 수 있다. 이 때 곡선이나 돌아가는 글자 등 다양한 방향의 텍스트 인식을 위해서나, 책이 다 양한 각도로 들어올 수 있기 때문에 글자를 검출하면서 글자의 방향도 함께 추정하도록 할 수 있다. 도 9d는 이렇게 페이지 별로 텍스트를 인식하고, 글자 방향을 인식한 결과의 일 예를 나타낸 것이다. 인식된 텍스트 사이의 거리를 이용해서 클러스터링(Text Clustering) 하여 하나 이상의 그룹을 결정 수 있다. 예를 들면, OCR 결과를 DBSCAN을 기반으로 하여 더 가까이 위치한 텍스트끼리 같은 그룹으로 묶어주도록 클러스 터링을 수행할 수 있다. 여기에 Line regression 기반의 정렬(Sorting) 모델을 이용하여 읽는 순서를 결정(Text Sorting) 할 수 있다. 즉, 입력 영상에서 책의 페이지가 휘어서 줄의 글들이 곡선으로 보일 때에도 각 단어들을 순서대로 읽을 수 있 도록 각 줄의 다항식을 회귀하여 단어들을 순서를 정할 수 있다. 나아가, 한국어/일본어/영어 등 여러 언어에 대하여 각 언어별 개별 모델이 아닌 언어 통합 단일 모델을 이용할 수 있으며, 이러한 방식을 이용하면 한 페이지 내에 다양한 언어가 혼재된 도서를 읽는 것도 가능하다. 필요에 따라 실제로 음성으로 읽을 필요가 없는 문자들은 후처리 작업을 통해 제외될 수 있다. 예를 들면, 책 의 페이지 번호, 배경에 사용된 문자, 책 내용과 무관한 책에 대한 정보 등에 대한 내용은 텍스트가 인식되었더 라도 제거할 수 있다. 문자 인식 모듈의 결과를 그대로 합성하여 사용자에게 제공하는 경우, 페이지 내에 내용이 길 경우 음성 합성에 조금 더 시간이 걸릴 수 있다는 문제가 있을 수 있다. 이러한 문제를 해결하고, 좀 더 자연스러운 책 읽기 기능을 수행하기 위하여 있다. 문장 분석 모듈이 추가로 사용될 수 있다. 문장 분석 모듈은 인식된 텍스트를 분석하여 문장별, 자연스럽게 끊어 읽을 수 있는 의미 단위로 구분할 수 있다. 나아가, 각 문장에 대해 감정을 분석할 수 있다. 이를 위해, 문장 분석 모듈은 텍스트를 분석할 수 있다. 이 때 문장 분석 모듈은 텍스트로부터 각 문장을 구분할 수 있다. 여기서, 문장 분석 모듈 은 문장부호, 띄어쓰기 등을 기반으로, 문장을 구분할 수 있다. 아울러, 문장 분석 모듈은 텍스트를 교정 할 수 있다. 이 때 문장 분석 모듈은 미리 설정된 규칙을 기반으로, 각 문장을 교정할 수 있다. 그리고, 문장 분석 모듈은 각 문장 내의 적어도 하나의 단어의 의미, 각 문장의 인접한 문장과의 문맥, 또는 인접 한 문장 내의 적어도 하나의 단어의 의미를 기반으로, 각 문장에 대해 감정을 분석할 수 있다. 예를 들면, 문장 분석 모듈은 각 문장의 감정을 긍정, 부정 및 중립 사이에서 분류할 수 있으며, 긍정의 감정을 감동과 기쁨 사이에서 추가로 분류하거나, 부정의 감정을 슬픔, 분노 및 짜증 사이에서 추가로 분류할 수도 있다. 일 예로, 어떤 문장이 '버럭', '찌푸리면서', '화를 버럭내며', 또는 '소리쳤다' 중 적어도 어느 하 나를 포함하면, 문장 분석 모듈은 해당 문장의 감정을 부정으로 분류할 수 있다. 이를 통해, 문장 분석 모 듈은 각 문장에 대해, 해당 문장의 감정을 나타내는 음성 태그를 부여할 수 있다. 본 발명의 일 실시예에 따르면, 문장의 감정 분석을 위한 딥러닝 모델을 이용할 수 있다. 감정 분석을 위한 모 델은 다수의 문장 및 해당 문장에 대한 감정 정보를 이용하여 학습된다. 학습된 모델은 입력된 문장에 대한 감 정이 긍정/중립/부정일 각각의 확률을 계산하며, 이 중 가장 높은 확률의 감정을 해당 문장의 감정으로 선택할 수 있다. 음성 처리 모듈은 인식된 텍스트에 대응하는 음성을 합성할 수 있다. 음성 처리 모듈은 인식된 텍스 트에 음성 태그를 반영하여, 음성을 합성할 수 있다. 이 때 음성 처리 모듈은 각 문장에 대해 음성 태그를 반영하여, 음성을 합성할 수 있다. 여기서, 음성 태그는 문장의 유형, 화자 또는 감정 중 적어도 어느 하나를 나타낼 수 있다. 이를 통해, 음성 처리 모듈은 각 문장을 해당 문장의 유형에 따라, 해당 문장의 화자에 따라 또는 해당 문장의 감정에 따라, 음성을 합성할 수 있다. 예를 들면, 음성 처리 모듈은 NES(natural end-to-end speech synthesis system) 기술을 통해, 자연스러운 음성을 합성할 수 있다. 대화 처리 모듈은 사용자의 음성 명령을 인식할 수 있다. 이 때 대화 처리 모듈은 음성 명령을 기반 으로, 사용자를 식별할 수 있다. 대화 처리 모듈은 음성 명령을 기반으로, 사용자의 성별, 연령 등을 구분 할 수 있다. 나아가, 대화 처리 모듈은 음성 명령을 기반으로, 사용자를 한 개인으로 특정할 수 있다. 예 를 들면, 복수의 사용자들이 미리 등록된 경우, 대화 처리 모듈이 음성 명령을 기반으로, 등록된 사용자들 중 한 명을 선택할 수 있다. 도 4는 일 실시예에 있어서, 클라우드 인공지능 플랫폼의 예를 도시한 도면이다. 도 4를 참조하면, 스마트 리딩 기기가 클라우드 인공지능 플랫폼과 연계되어 구현될 수 있다. 프로세서의 구성 요소들 중 적어 도 어느 하나가 클라우드 인공지능 플랫폼에 구현될 수 있다. 앞서 설명한 프로세서의 비전(vision) 모듈, 문자 인식 모듈, 문장 분석 모듈, 음성 처리 모듈 또는 대화 처리 모듈 중 적어도 어느 하나가 클라우드 인공지능 플랫폼에 구현될 수 있다. 스마트 리딩 기기나 스마트 리딩 기기에 설치 및 구동되는 어플리케이션들(이하, 앱들)은 인터페이스 커넥트를 통해 클라우드 인공지능 플랫폼과 연계될 수 있다. 여기서, 인터페이스 커넥트는 스 마트 리딩 기기나 스마트 리딩 기기에 설치 및 구동되는 앱들의 개발을 위한 SDK(Software Development Kit) 및/또는 개발 문서들을 개발자들에게 제공할 수 있다. 또한, 인터페이스 커넥트는 스마 트 리딩 기기나 스마트 리딩 기기에 설치 및 구동되는 앱들이 클라우드 인공지능 플랫폼이 제공 하는 기능들을 활용할 수 있는 API(Application Program Interface)를 제공할 수 있다. 구체적인 예로, 개발 자들은 인터페이스 커넥트가 제공하는 SDK(Software Development Kit) 및/또는 개발 문서를 이용하여 개발 한 기기나 앱은 인터페이스 커넥트가 제공하는 API를 이용하여 클라우드 인공지능 플랫폼이 제공하는 기능들을 활용할 수 있게 된다. 확장 키트는 컨텐츠 서비스, 예컨대 제3자 컨텐츠 개발자 또는 회사들이 클라우드 인공지능 플랫폼 에 기반하여 새로운 음성기반 기능을 구현할 수 있는 개발 키트를 제공할 수 있다. 이하에서는 스마트 리 딩 기기 및 그 제어 방법의 구체적인 실시예를 설명하기로 한다. 스마트 리딩 기기는 각 동작 모드에서 다르게 동작할 수 있다. 독서 모드에서, 스마트 리딩 기기는 인쇄물을 기반으로, 사용자를 위한 읽어주는 기능을 제공할 수 있다. 일 실시예에 따르면, 스마트 리딩 기기는 카메라를 통해 입력되는 영상에 포함된 인쇄물을 기반으로, 사용자를 위한 읽어주는 기능을 제공할 수 있다. 또한, 스마트 리딩 기기는 사용자의 독서 기록 및/또는 사용자가 속하는 그룹, 예컨대 연령, 성별, 성격 등에 따른 그룹의 독서 기록을 분석하여, 사용자를 위한 인쇄물을 추천할 수 있다. 그리고 스마트 리딩 기기 는 사용자에 의해 선택된 인쇄물을 기반으로, 사용자를 위한 읽어주는 기능을 제공할 수 있다. 한편, 독서 모드 종료 시, 스마트 리딩 기기는 인쇄물과 관련된 추가 기능을 수행할 수 있다. 이 때 스마트 리딩 기기 는 사용자와의 인터페이스를 통해, 추가 기능을 수행할 수 있다. 예를 들면, 추가 기능은 인쇄물에 대한 감상 또는 후기 작성 기능, 기 설정된 인쇄물과 관련된 활동들을 포함할 수 있다. 독서 모드에서, 스마트 리딩 기기는 사용자 별로 읽어주는 기능을 제공할 수 있다. 예를 들면, 스마트 리 딩 기기에 복수의 사용자들이 등록될 수 있으며, 스마트 리딩 기기는 사용자들을 식별할 수 있다. 일 예로, 스마트 리딩 기기는 음성 명령의 목소리를 기반으로, 사용자들 중 어느 하나를 식별할 수 있다. 다 른 예로, 스마트 리딩 기기는 음성 명령의 주체를 질의하고, 추가로 입력되는 음성 명령의 내용을 기반으 로, 사용자들 중 어느 하나를 식별할 수 있다. 이를 통해, 스마트 리딩 기기는 각 사용자를 위해 읽어주는 기능을 제공할 수 있다. 이 때 스마트 리딩 기기는 각 사용자에 대응하는 음성으로, 읽어주는 기능을 제공 할 수 있다. 인쇄물이 학습지인 경우, 스마트 리딩 기기의 독서 모드 중에, 사용자는 학습지를 풀 수 있다. 스마트 리 딩 기기는 입력되는 영상 분석을 통해 사용자가 인쇄물에 추가로 기재한 문제 풀이를 인식할 수 있다. 이 를 이용하여 해당 문제의 풀이가 올바른지 확인을 해준다던가, 틀린 부분을 확인해줄 수 있다. 또한 사용자가 장기간 풀이를 하지 않는 등 풀이에 어려움이 있다고 생각되거나 별도의 요청을 하는 경우 문제 풀이에 대한 힌 트를 제공할 수 있다. 독서 모드 종료 시, 스마트 리딩 기기는 사용자와의 인터페이스를 통해, 학습지와 관련된 추가 기능을 수 행할 수 있다. 이를 위해, 스마트 리딩 기기는 외부 기기, 예컨대 학습지와 관련된 서버로부터 학습 지와 관련된 데이터를 다운로드하고, 이를 기반으로 추가 기능을 수행할 수 있다. 스마트 리딩 기기는 학 습지에 대한 사용자의 독후 활동을 유도할 수 있다. 또는 스마트 리딩 기기는 학습지에서 틀린 문제에 대 한 풀이 및 해설을 제공할 수 있다. 또는 스마트 리딩 기기는 사용자의 학습 성취도를 평가하기 위해, 학 습지와 관련된 퀴즈를 제공할 수 있다. 또는 스마트 리딩 기기는 독서 모드 실행 중 카메라를 통해 입력되는 영상을 획득하여, 외부 기기, 예컨대 학습지와 관련된 서버를 통해 미리 정해진 교사나 강사에 제공할 수 있다. 그리고, 스마트 리딩 기기는 외부 기기를 통해 교사나 강사로부터 수신되는 파일을 제공 할 수 있다. 또는 스마트 리딩 기기는 학습지 내의 문제와 유사한 문제를 검색하여, 제공할 수 있다. 도 5는 제 1 실시예에 따른 스마트 리딩 기기의 동작 방법을 도시한 순서도이다. 도 5를 참조하면, 단계(S510)에서, 프로세서는 스마트 리딩 기기의 사용자의 명령을 인식할 수 있다. 사용자의 명령은 버튼 명령 또는 음성 명령 중 적어도 어느 하나를 포함할 수 있다. 일 실시예에 따르면, 프로세서는 입력된 음성을 분석하여, 사용자를 식별할 수 있다. 예를 들면, 스마트 리딩 기기에 복수의 사용자들이 등록된 경우, 프로세서는 음성 명령으로부터 사용자들 중 하나를 식별할 수 있다. 앞서 설명한 바와 같이, 스마트 리딩 기기는 복수 개의 동작 모드들을 포함할 수 있고, 각 동작 모드에서 다르게 동작 할 수 있다. 예를 들면, 동작 모드들은 취침 모드, 독서 모드, 공부 모드, 또는 명상 모드 중 적어도 어느 하 나를 포함할 수 있다. 도 6a는 도 5의 사용자의 명령 인식 동작을 도시한 순서도이다. 도 6a를 참조하면, 단계(S610)에서, 프로세서는 버튼 명령 또는 음성 명령을 입력받을 수 있다. 프로세서 는 대화 기반 인터페이스를 통해 사용자의 음성 명령을 입력받을 수 있다. 예를 들어, 프로세서는 대화 기반 인터페이스로서 스마트 리딩 기기가 포함하는 마이크 또는 스마트 리딩 기기와 연동된 마 이크와 같은 음성 입력 장치를 통해 사용자의 발화에 따른 음성 명령을 입력받을 수 있다. 또는 프로세서 는, 사용자의 버튼 명령을 입력받을 수 있다. 예를 들면, 프로세서는 스마트 리딩 기기가 포함하는 버튼 또는 스마트 리딩 기기와 연동된 키보드와 같은 버튼 입력 장치를 통해 버튼 명령을 입력받을 수 있 다. 단계(S610)에서 음성 명령 또는 버튼 명령을 입력받으면, 단계(S620)에서 프로세서는 스마트 리딩 기기 의 동작 모드들 중 어느 하나를 실행하기 위한 요청으로서 사용자의 명령을 인식할 수 있다. 이 때 프로세 서는, 사용자의 명령이 독서 모드를 실행하기 위한 요청인지의 여부를 판단할 수 있다. 일 실시예에 따르면, 프로세서는 사용자의 명령에 대응하여 카메라를 동작시키고, 카메라를 통 해 입력된 물체를 분석하여, 사용자의 명령을 인식할 수 있다. 일 예로, 카메라에 인식된 물체가 책인 경 우, 프로세서는 스피커를 통해 \"책을 읽어드릴까요?\" 와 같이 사용자에게 질의할 수 있다. 사용자로 부터 수신된 응답이 긍정적인 응답일 경우, 프로세서는 사용자의 명령이 독서 모드를 실행하기 위한 요청 인 것으로 판단할 수 있다. 다른 예로, 카메라에 인식된 물체가 악보인 경우, 프로세서는 스피커 를 통해 \"악보를 연주할까요?\" 와 같이 질의하여 긍정적 응답을 수신할 경우, 사용자의 명령이 악보 연주 기능을 실행하기 위한 다른 동작 모드를 실행하기 위한 요청인 것으로 판단할 수 있다. 또는, 사용자는 음성 명령을 통하여 특정 모드를 실행시킬 수 있다. 예를 들어 사용자로부터 \"독서 모드\"와 같 은 음성 명령이 입력될 경우 프로세서는 독서 모드를 실행시키기 위한 요청인 것으로 판단할 수 있다. 단계(S620)에서 사용자의 명령이 독서 모드를 실행하기 위한 요청인 것으로 판단되면, 단계(S630)에서, 프로세 서는 독서 모드를 실행할 수 있다. 이 때 프로세서는 독서 모드에 대응하여 설정된 조도 또는 색온도 중 적어도 어느 하나를 기반으로, 조명을 조절할 수 있다. 일 실시예에 따르면, 프로세서는 카메라 를 동작시킬 수 있다. 이 후 프로세서는 도 5로 리턴할 수 있다. 한편, 단계(S620) 동작에서 사용자의 명령이 독서 모드를 실행하기 위한 요청이 아닌 것으로 판단되면, 단계 (S640)에서 프로세서는 사용자의 명령에 대응하여, 해당 기능을 수행할 수 있다. 이 때 프로세서는 독서 모드 이외의 다른 동작 모드를 실행할 수 있다. 여기서, 프로세서는 다른 동작 모드에 대응하여 설정 된 조도 또는 색온도 중 적어도 어느 하나를 기반으로, 조명을 조절할 수 있다. 다시 도 5를 참조하면, 단계(S520)에서, 프로세서는 스마트 리딩 기기에 포함된 카메라를 통해 입력되는 영상을 획득할 수 있다. 프로세서는 카메라를 통해 인쇄물을 포함하는 영상을 획득할 수 있 다. 여기서, 인쇄물은 적어도 하나의 페이지를 포함할 수 있다. 페이지는 인쇄물의 표지와 내부 페이지를 포함 할 수 있다. 일 실시예에 따르면, 프로세서는 영상에서 책과 같은 인쇄물의 에지(edge)를 검출할 수 있다. 이 때 영상 에서 인쇄물의 에지가 검출되지 않으면, 프로세서는 스피커를 통해 \"책을 올바르게 놓아주세요\"와 같 이 사용자에게 안내할 수 있다. 이에 대응하여, 스마트 리딩 기기의 사용자는 인쇄물을 카메라를 마 주보는 위치에 놓을 수 있다. 다른 실시예에 따르면, 스마트 리딩 기기는, 도 6b에 도시된 바와 같이 헤드 부분에 설치된 레이저 를 더 포함하고, 레이저를 통해 사용자를 위해 인쇄물이 놓일 적절한 위치를 안내할 수 있다. 이에 대응하여, 스마트 리딩 기기의 사용자는 레이저를 통해 안내되는 위치에 인쇄물을 놓을 수 있다. 단계(S530)에서, 프로세서는 카메라를 통해 입력되는 영상과 관련하여 읽어주는 기능을 제공할 수 있 다. 일 실시예에 따르면, 프로세서는 사용자 특정으로 읽어주는 기능을 제공할 수 있다. 예를 들면, 프로 세서는 단계(S510)에서 식별된 사용자에 대응하여 미리 등록된 음성을 기반으로, 읽어주는 기능을 제공할 수 있다. 프로세서는 영상에서 인쇄물의 페이지 내 텍스트를 인식할 수 있다. 그리고 프로세서는 인식된 페이 지에 대해, 읽어주는 기능을 제공할 수 있다. 일 예로, 프로세서는 OCR(optical character reader) 기술을 통해 책의 텍스트와 그림을 구별하여 인식할 수 있다. 이를 통해, 프로세서는 스마트 리딩 기기에 포함된 스피커를 통해 텍스트에 대응하는 음성을 발화할 수 있다. 다른 예로, 프로세서는 페이지에 인쇄된 QR(quick response) 코드 내지는 바코드 를 인식하여 인식된 코드를 통해 스마트 리딩 기기에 포함된 데이터베이스 혹은 스마트 리딩 기기와 연동 가능한 서버나 플랫폼 상의 데이터베이스로부터 해당 페이지의 텍스트 또는 해당 페이지나 해당 페이 지를 포함하는 인쇄물의 음원을 획득할 수 있다. 이를 통해, 프로세서는 스피커를 통해 텍스트에 대 응하는 음성을 발화하거나, 음원을 재생할 수 있다. 다시 말해, 프로세서는 OCR 스캔이나 QR 코드 검색을 통해 획득한 인쇄물의 텍스트를 읽어줄 수 있다. 사용자에게 인쇄물의 페이지를 넘기도록 하여 스마트 리딩 기 기가 해당 페이지를 OCR로 스캔하여 읽어줄 수 있고, 혹은 QR 코드로 인쇄물의 각 페이지가 구분되는 경우 스마트 리딩 기기가 해당 페이지의 QR 코드를 인식하여 인식된 페이지의 텍스트를 획득하여 읽어줄 수 있 다. 프로세서는 저장되어있는 음원을 이용하거나, 저장된 음원이 없거나 사용자 요청이 있는 경우에는 음 성합성기를 통해 합성된 음성을 제공할 수 있다. 일 실시예에 따르면, 프로세서는 카메라를 통해 입력된 인쇄물의 표지가 포함된 영상을 분석하여 해 당 책이 무엇인지를 알아낼 수 있다. 구체적으로, 프로세서는 i) 책 표지에 기재된 텍스트 영역을 찾아내 서 해당 텍스트를 문자 인식, ii) 데이터베이스 내에 저장된 표지 이미지들과 비교, iii) 책 표지에 인쇄된 QR 코드 내지는 바코드 등을 이용하는 등 다양한 방법을 사용하여 해당 책에 대한 정보를 알아낼 수 있다. 책에 대한 정보를 이용하여, 다양한 방식으로 기 구축된 데이터베이스의 책 내용에 대한 정보(예를 들어 페이지 내 텍스트 및/또는 이미지 정보, 페이지 내 텍스트에 대한 음성 정보), 전체 줄거리 정보, 작가, 출판사 등 책에 대한 부가 정보, 사용자 선호도 정보 등) 들을 추가로 활용할 수 있다. 예를 들면, 스마트 리딩 기기는 책 표지를 통해 책 정보를 알아낸 후 데이터베이스 내에 저장된 해당 책에 대한 정보를 활용할 수 있다. 이후 페이지에 대한 영상이 입력되었을 때, 텍스트의 일부에 대한 문자 인식으로도 해당 책에 대한 데이터베이스 검 색을 통하여 어떤 페이지인지 알아내고, 해당 페이지 전체를 읽어줄 수 있다. 또한, 추가로 데이터 해당 페이 지에 적합한 컨텐츠(텍스트에 대한 음성, 부가적인 설명 정보 등)를 제공할 수도 있다. 그리고, 스마트 리딩 기기는 텍스트 이외에도 이미지 분석을 통해 카메라로 촬영된 사물 자체를 인식하거 나 책에 인쇄된 이미지를 인식하여 이미지 인식 결과를 음성 발화할 수 있다. 예를 들어, 책에 사과 이미지가 인쇄된 경우 이미지 인식 결과에 따라 '사과', 또는 '애플'과 같은 음성 발화를 출력할 수 있다. 본 발명에 따르면, 보다 실감나는 책읽기를 위하여 책 내의 추가적인 정보를 반영하여 음성을 합성하거나 기존 음성을 변조하여 제공할 수 있다. 예를 들면, 폰트사이즈가 큰 텍스트는 크게, 작은 텍스트는 작게 읽을 수 있 다. 또한 직접 인용 부호(\")가 있거나 말풍선 내의 문장은 등장인물의 직접 발화이므로 화자를 구분하여 다른 목소리로 읽을 수 있다. 또한 그림을 분석하여 인물의 표정이 우울하거나 울고 있는 경우에는 우는 목소리, 웃 고 있는 경우에는 밝은 목소리로 표현하는 등 감정을 파악하여 감정을 나타내는 음성을 제공할 수 있다. 단락 의 구분이 있거나 말줄임표가 있는 부분에서는 적절히 쉬어주면서 읽을 수도 있다. 상기한 텍스트와 이미지를 인식하는 방법은 예시적인 것으로 이에 한정되는 것은 아니며, 이미 잘 알려진 다른 기술들을 이용하는 것 또한 가능하다. 또한, 스마트 리딩 기기는 읽어주는 기능에 대해 각 책 별로 인식된 텍스트와 이미지를 인식 순서에 따라 차례로 저장할 수 있고, 사용자의 독서 횟수나 독서 중단 페이지 등을 포함한 사용자 이력 정보를 저장할 수 있 다. 이러한 정보를 바탕으로, 이후 동일한 책에 대해 OCR 스캔이나 QR 코드 검색 과정 없이, 즉 실물 책이 없 더라도 해당 책을 다시 읽어주는 기능을 제공할 수 있고, 다시 읽어주는 기능을 제공하는 과정에서 사용자가 동 일한 책을 몇 번 읽었는지, 어느 페이지까지 읽다 말았는지 등에 대한 정보를 활용할 수 있다. 상기한 스마트 리딩 기기의 동작 방법에 따른 시나리오 예시는 다음과 같다. 1. 스마트 리딩 기기가 사용자의 발화에 따라 입력되는 음성 명령 '책을 읽어줘'를 인식하는 경우 카메라 를 활성화시킨 후 '무슨 책을 읽어줄까? 책 표지를 보여줘'와 같이 읽어주는 기능을 위한 가이드를 음성으로 출력할 수 있다. 2. 사용자가 카메라 정면에 책을 놓고 '우리 이 책 읽은 적 있어?'라고 질의하는 경우 스마트 리딩 기기 는 저장된 정보를 검색하여 검색 결과에 따라 '아니, 처음 읽는 책이야!'와 같은 응답을 발화할 수 있다. 3. 스마트 리딩 기기는 책 표지를 인식한 후 '<브라운 무슨 생각해?>라는 책이구나. 책장을 천천히 넘기면 서 읽어보자. 시작할게.'와 같이 책 정보와 함께 가이드를 발화한 후 책 읽기를 시작할 수 있다. 스마트 리딩 기기는 텍스트를 읽어주는 것 이외에도 사용자가 이미지 카드를 카메라 정면에 놓고 '이 게 뭐야?'라고 물으면 이미지를 인식하여 '이것은 사과야'와 같이 이미지를 인식하여 읽어주는 것 또한 가능하 다. 프로세서는 사용자가 선택한 특정 목소리로 텍스트에 대응하는 음성을 발화할 수 있다. 이를 위해, 스마트 리딩 기기에 적어도 하나의 목소리가 미리 설정될 수 있다. 이 때 프로세서는, 독서 모드가 다른 동 작 모드를 수행하면서, 목소리를 설정할 수 있다. 예를 들면, 프로세서는 도 6의 단계(S640)에서 독서 모 드를 위한 목소리를 설정할 수도 있다. 이에 대해, 도 7을 참조하여, 보다 상세하게 후술된다. 도 7은 제 1 실시예에 따른 스마트 리딩 기기의 설정 단계를 도시한 순서도이다. 이 때 도 7의 설정 동작은 도 5의 동작 방법에 포함될 수 있다. 여기서, 도 7의 설정 동작은 도 5의 동작 방법 초기에 수행될 수 있다. 도 7을 참조하면, 단계(S710)에서 스마트 리딩 기기는 스마트 리딩 기기에 포함된 마이크를 통해 입 력되는 특정인의 음성을 녹음한 후 녹음된 음성으로부터 특정인의 목소리 데이터를 추출하여 저장 및 유지할 수 있다. 이때, 스마트 리딩 기기는 읽어주는 기능에 활용하기 위한 목소리로서 별도의 녹음 기능을 통해 특 정인(예컨대, 엄마, 아빠 등)의 목소리를 녹음하여 목소리 특징을 추출한 후 목소리 대상과 매칭하여 저장해 놓 을 수 있다. 단계(S720)에서 스마트 리딩 기기는 사용자의 음성 명령이 읽어주는 기능을 위한 요청에 해당되는 경우 읽 어주는 기능에 적용 가능한 목소리 목록 혹은 적어도 하나의 추천 목소리를 사용자에게 제공할 수 있다. 예를 들어, 스마트 리딩 기기는 음성 발화를 통해 '이 책은 브라운, 코니, 샐리 중 누구 목소리로 읽어줄까?'와 같이 목소리 목록을 제공하거나 '이 책은 엄마 목소리로 읽어줄까?'와 같이 추천 목소리를 제공할 수 있다. 이를 통해, 스마트 리딩 기기는 사용자와의 대화 기반으로 사용자가 선택한 특정 목소리로 단계(S530)에서 인식된 텍스트를 음성 발화하여 읽어주는 기능을 제공할 수 있다. 다시 말해, 스마트 리딩 기기는 읽어주 는 기능의 음성 발화에 엄마나 아빠 등 녹음된 목소리를 합성할 수 있다. 상기한 스마트 리딩 기기의 동작 방법에 따른 시나리오 예시는 다음과 같다. 1. 스마트 리딩 기기가 사용자의 발화에 따라 입력되는 음성 명령 '책을 읽어줘'를 인식하는 경우 카메라 를 활성화시킨 후 '무슨 책을 읽어줄까? 책 표지를 보여줘'와 같이 읽어주는 기능을 위한 가이드를 음성으 로 출력할 수 있다. 2. 사용자가 카메라 정면에 책을 놓고 '우리 이 책 읽은 적 있어?'라고 질의하는 경우 스마트 리딩 기기 는 저장된 정보를 검색하여 검색 결과에 따라 '아니, 처음 읽는 책이야!'와 같은 응답을 발화할 수 있다. 3. 스마트 리딩 기기는 책 표지를 인식한 후 '<브라운 무슨 생각해?>라는 책이구나. 이 책은 엄마 목소리 로 읽어줄까?'와 같이 책 정보와 함께 추천 목소리를 제공할 수 있다. 4. 사용자가 '응, 좋아.'와 같이 추천 목소리를 허용하면 스마트 리딩 기기는 '책장을 천천히 넘기면서 읽 어보자. 시작할게.'와 같이 가이드를 발화한 후 책 읽기를 시작할 수 있다. 또 다른 실시예에 따르면, 프로세서는 카메라를 통해 입력된 인쇄물의 페이지가 포함된 영상을 분석 하여, 인쇄물 및 인쇄물 내 해당 페이지를 식별할 수 있다. 즉 프로세서는 인쇄물의 표지를 기반으로, 인 쇄물을 식별할 수 있을 뿐 아니라, 인쇄물의 내부 페이지를 기반으로, 인쇄물을 식별할 수도 있다. 바꿔 말하면, 프로세서는 인쇄물의 표지를 기반으로 인쇄물을 식별한 다음, 인쇄물의 내부 페이지를 인식하는 것이 아니라, 인쇄물의 내부 페이지를 기반으로 인쇄물을 식별할 수도 있다. 이에 대해, 도 8을 참조하여, 보다 상세하게 후술된다. 도 8은 도 5의 읽어주는 기능 제공 단계를 도시한 순서도이다. 도 9는 도 8의 텍스트 인식 단계를 설명하기 위 한 도면이다. 도 10a, 도 10b, 도 10c 및 도 10d는 텍스트 인식 단계를 설명하기 위한 도면들이다. 도 13a 및도 13b는 도 8의 페이지 넘김 검출 단계를 설명하기 위한 도면이다. 도 8을 참조하면, 단계(S810)에서, 프로세서는 카메라를 통해 획득된 영상에서 인쇄물의 페이지를 검 출할 수 있다. 이 때 프로세서는 영상 내에서 검출되는 에지를 기반으로, 페이지를 검출할 수 있다. 여기 서, 페이지는 인쇄물의 표지 또는 내부 페이지 중 어느 하나일 수 있다. 단계(S820)에서, 프로세서는 검출된 페이지를 식별할 수 있다. 데이터베이스에는, 인쇄물의 각 페이지에 대한 적어도 하나의 이미지와 각 이미지에 대응하여 미리 설정된 음원이 매핑되어 있을 수 있다. 이를 통해, 프 로세서는 검출된 페이지에 대한 이미지를 기반으로 데이터베이스를 검색할 수 있다. 일 예로, 데이터베이 스는 스마트 리딩 기기의 내부에 저장되어 있을 수 있다. 이 때 프로세서는, 검출된 페이지가 데이터 베이스에 존재하는 지의 여부를 판단할 수 있다. 다른 예로, 데이터베이스는 스마트 리딩 기기의 외부 기 기, 예컨대 서버나 플랫폼에 저장되어 있을 수 있다. 이러한 경우, 프로세서는 검출된 페이지에 대한 이미지를 외부 기기로 전송하여, 데이터베이스를 검색할 수 있다. 이 때 프로세서는, 외부 기기를 통해, 검출된 페이지가 데이터베이스에 존재하는 지의 여부를 판단할 수 있다. 예를 들면, 프로세서는, 데이터베이스에 저장된 이미지들 중 검출된 페이지와 가장 유사한 이미지를 검색 할 수 있다. 일 예로, 프로세서는 데이터베이스에 저장된 이미지들과 검출된 페이지의 유사도를 계산하고, 저장된 이미지 중 가장 유사도가 높은 이미지를 선택할 수 있다. 이 때 가장 유사한 이미지라 하더라도 미리 정해진 임계값을 초과하지 않는 경우에는 데이터베이스에 해당 이미지가 존재하지 않는 것으로 판단할 수 있다. 단계(S820)에서 검출된 페이지가 데이터베이스에 존재하는 것으로 판단되면, 단계(S830)에서, 프로세서는 검출된 페이지에 대응하는 음원을 재생할 수 있다. 일 예로, 프로세서는 스마트 리딩 기기 내부의 데 이터베이스로부터 음원을 판독하여, 재생할 수 있다. 다른 예로, 프로세서는 외부 기기의 데이터베이스로 부터 음원을 전송 받아, 스피커를 통해 재생할 수 있다. 한편, 단계(S820)에서 검출된 페이지가 데이터베이스에 존재하지 않는 것으로 판단되면, 단계(S840)에서, 프로 세서는 검출된 페이지의 텍스트를 인식할 수 있다. 일 예로, 문자 인식 모듈은 검출된 페이지 전체에 걸쳐, 텍스트를 인식할 수 있다. 다른 예로, 문자 인식 모듈은, 도 9a에 도시된 바와 같이 검출된 페이지에서 가이더를 검출하고, 검출된 페이지에서 가이더 에 의해 지시되는 일부 영역의 텍스트를 인식할 수 있다. 여기서, 가이더는 미리 정해진 형상의 물체, 사용자의 손 또는 손가락 중 적어도 어느 하나를 포함할 수 있다. 일 예로, 가이더는 텍스트의 영역 을 가변적으로 정의 가능한 구조로 구현될 수 있다. 이 때 문자 인식 모듈은, 텍스트가 속하는 언어를 식 별하고, 식별된 언어를 기반으로, 텍스트를 식별할 수 있다. 일 실시예에 따르면, 문자 인식 모듈은 OCR(optical character reader) 기술을 통해 검출된 페이지의 텍스트를 인식할 수 있다. 프로세서는 텍스트의 음절들을 각각 검출하고, 음절들로부터 어절들 또는 문자들을 각각 인식할 수 있다. 여기서, 프로세서는 미리 정해진 값 보다 흐리거나 작은 음절은 무시할 수 있다. 그리고 프로세서는 어절들 또는 문자들을 클러스터링(clustering)하여, 텍스트 내에서 적어도 하나의 단락을 구분할 수 있다. 또한 프로세서는 어절들 또는 문자들을 분류(sorting)할 수 있다. 예를 들면, 프로세서는 어절들 또는 문 자들을 주어, 동사, 목적어, 형용사, 부사 등으로 분류할 수 있다. 이러한 방식으로, 프로세서는 도 10a에 도시된 바와 같이 가로로 쓰여진 텍스트, 도 10b에 도시된 바와 같이 세로로 쓰여진 텍스트, 도 10c에 도시된 바와 같이 인쇄물이 만곡됨에 따라 만곡된 텍스트, 및 도 10d에 도시된 바와 같이 원형 또는 나선형의 곡선을 따라 만곡된 텍스트를 모두 인식할 수 있다. 단계(S850)에서, 프로세서는 텍스트에 대응하는 음성을 발화할 수 있다. 프로세서는 스피커를 통해 텍스트에 대응하는 음성을 발화할 수 있다. 이 때 프로세서는 적어도 하나의 목소리를 사용하여, 텍 스트에 대응하는 음성을 발화할 수 있다. 일 실시예에 따르면, 프로세서는, 텍스트를 번역한 다음, 번역된 텍스트에 대응하는 음성을 발화할 수 있다. 이에 대해, 도 11을 참조하여, 보다 상세하게 후술된다. 다른 실시 예에 따르면, 프로세서는 텍스트와 관련하여 적어도 하나의 음성 태그를 검출하고, 텍스트에 음성 태그를 반영함으로써, 텍스트에 대응하는 음성을 발화할 수 있다. 이에 대해, 도 12를 참조하여, 보다 상세하게 후술된 다. 도 11은 도 8의 음성 발화 단계를 도시한 순서도이다. 단계(S1110)에서, 프로세서는 텍스트를 사용자에 의해 선택된 목적 언어로 번역할 수 있다. 프로세서 는 사용자와의 대화를 기반으로 사용자에 의해 선택된 목적 언어를 특정하거나 혹은 사용자에 의해 사전설정된 목적 언어를 특정할 수 있다. 프로세서는 스마트 리딩 기기에 포함된 사전 데이터베이스 혹 은 스마트 리딩 기기와 연동 가능한 서버나 플랫폼 상의 사전 데이터베이스를 통해 목적 언어로 검출 된 페이지의 텍스트를 번역할 수 있다. 단계(S1120)에서, 프로세서는 사용자의 음성 명령에 대한 응답으로, 목적 언어로 번역된 텍스트를 스마트 리딩 기기에 포함된 스피커를 통해 음성 발화하여 읽어주는 기능을 제공할 수 있다. 다시 말해, 프 로세서는 검출된 페이지의 텍스트를 사용자가 원하는 언어로 번역하여 읽어줄 수 있다. 이 후 프로세서 는 도 8로 리턴할 수 있다. 상기한 스마트 리딩 기기의 동작 방법에 따른 시나리오 예시는 다음과 같다. 1. 사용자가 음성 명령 '이 책을 영어로 읽어줘'를 발화하는 경우 스마트 리딩 기기는 카메라를 활성 화시켜 영상을 획득한 후 영상으로 촬영된 책의 텍스트를 인식할 수 있다. 2. 스마트 리딩 기기는 인식된 텍스트를 사용자의 음성 명령에 포함된 목적 언어, 즉 영어로 번역하여 번 역 결과를 음성 발화함으로써 읽어주는 기능을 제공할 수 있다. 다른 시나리오 예시는 다음과 같다. 1. 사용자가 카메라 정면에 사과 이미지 카드를 놓고 '이게 일본어로 뭐야?'라고 질의하는 경우 스마트 리 딩 기기는 카메라를 활성화시켜 이미지 카드를 스캔한 후 이미지 객체 '사과'를 인식할 수 있다. 2. 스마트 리딩 기기는 인식된 이미지 객체 '사과'를 사용자의 음성 명령에 포함된 목적 언어, 즉 일본어 로 번역하여 번역 결과 'リンゴ'를 음성 발화로 읽어줄 수 있다. 도 12는 도 8의 음성 발화 단계를 도시한 순서도이다. 도 12를 참조하면, 단계(S1210)에서, 프로세서는 텍스트를 분석할 수 있다. 문장 분석 모듈이 텍스트 내 각 문장을 분석할 수 있다. 이 때 문장 분석 모듈은 텍스트로부터 각 문장을 구분할 수 있다. 여기서, 문장 분석 모듈은 문장부호, 띄어쓰기 등을 기반으로, 문장을 구분할 수 있다. 단계(S1220)에서, 문장 분 석 모듈은 텍스트를 교정할 수 있다. 이 때 문장 분석 모듈은 미리 설정된 규칙을 기반으로, 각 문장 을 교정할 수 있다. 단계(S1230)에서, 문장 분석 모듈은 각 문장에 대해 감정을 분석할 수 있다. 이 때 문장 분석 모듈은 각 문장 내의 적어도 하나의 단어의 의미, 각 문장의 인접한 문장과의 문맥, 또는 인접한 문장 내의 적어도 하 나의 단어의 의미를 기반으로, 각 문장에 대해 감정을 분석할 수 있다. 예를 들면, 문장 분석 모듈은 각 문장의 감정을 긍정, 부정 및 중립 사이에서 분류할 수 있으며, 긍정의 감정을 감동과 기쁨 사이에서 추가로 분 류하거나, 부정의 감정을 슬픔, 분노 및 짜증 사이에서 추가로 분류할 수도 있다. 일 예로, 어떤 문장이 '버 럭', '찌푸리면서', '화를 버럭내며', 또는 '소리쳤다' 중 적어도 어느 하나를 포함하면, 프로세서는 해당 문장의 감정을 부정으로 분류할 수 있다. 단계(S1240)에서, 문장 분석 모듈은 각 문장에 대해 적어도 하나의 음성 태그를 검출할 수 있다. 음성 태 그는 문장의 유형, 화자 또는 감정 중 적어도 어느 하나를 나타낼 수 있다. 일 예로, 문장의 유형이 대화문이면, 음성 태그는 자연스러운 톤의 음성을 나타내고, 문장의 유형이 의문문이면, 음성 태그는 묻는 톤의 음성을 나타낼 수 있다. 다른 예로, 문장의 화자가 아빠이면, 음성 태그는 아빠의 음성을 나타내고, 문장의 화 자가 \"제인(Jane)\"이면 음성 태그는 여아의 음성을 나타낼 수 있다. 또 다른 예로, 문장의 감정이 긍정이면, 음 성 태그는 긍정의 음성을 나타내고, 문장의 감정이 분노이면, 음성 태그는 분노의 음성을 나타낼 수 있다. 단계(S1250)에서, 프로세서는 텍스트에 음성 태그를 반영하여, 음성을 합성할 수 있다. 이 때 프로세서 는 각 문장에 대해 음성 태그를 반영하여, 음성을 합성할 수 있다. 이를 통해, 프로세서는 각 문장을 해당 문장의 유형에 따라, 해당 문장의 화자에 따라 또는 해당 문장의 감정에 따라, 음성을 합성할 수 있다. 이 후 프로세서는 도 8로 리턴할 수 있다. 다시 도 8을 참조하면, 단계(S860)에서, 프로세서는 페이지 넘김을 감지할 수 있다. 이를 위해, 프로세서 는 카메라를 통해 입력되는 영상을 계속해서 모니터링할 수 있다. 이 때 프로세서는 이미 획득 된 영상과 카메라를 통해 입력되는 영상, 예컨대 프리뷰 영상을 비교할 수 있다. 이를 통해, 이미 획득된 영상에서 검출된 페이지로부터 다른 페이지로의 페이지 넘김을 감지할 수 있다. 일 예로, 프로세서는, 도 13a에 도시된 바와 같이 획득된 영상의 전체 영역과 프리뷰 영상의 전체 영역을 비교하여, 검출된페이지로부터 다른 페이지로의 변화를 확인할 수 있다. 이에 대응하여, 프로세서는 페이지 넘김을 감지할 수 있다. 다른 예로, 프로세서는, 도 13b에 도시된 바와 같이 획득된 영상에서 미리 정해진 위치 의 일부 영역과 프리뷰 영상에서 미리 정해진 위치의 일부 영역을 비교하여, 검 출된 페이지로부터 다른 페이지로의 변화를 확인할 수 있다. 여기서, 획득된 영상의 정해진 위치와 프리뷰 영상의 정해진 위치는 서로 대응될 수 있다. 이에 대응하여, 프로세서는 페이지 넘김 을 감지할 수 있다. 단계(S860)에서 페이지 넘김이 감지되면, 프로세서는 단계(S840)으로 복귀할 수 있다. 그리고 프로세서 는 다른 페이지에 대해, 단계(S840) 내지 단계(S860)를 반복하여 수행할 수 있다. 즉 프로세서는 다 른 페이지를 획득하고, 다른 페이지의 텍스트를 인식하여, 스피커를 통해 텍스트에 대응하는 음성을 발화 할 수 있다. 이 때 다른 페이지에서 텍스트의 방향이 변경되면, 프로세서는 다른 페이지의 텍스트에 대응 하는 음성을 발화하지 않을 수 있다. 한편, 단계(S860)에서 페이지 넘김이 감지되지 않으면, 단계(S870)에서, 프로세서는 독서 모드를 종료할 지의 여부를 판단할 수 있다. 일 예로, 프로세서는 사용자의 명령을 기반으로, 독서 모드를 종료할 지의 여부를 판단할 수 있다. 사용자의 명령은 버튼 명령 또는 음성 명령 중 적어도 어느 하나를 포함할 수 있다. 다 른 예로, 프로세서는 독서 모드의 실행 시간을 기반으로, 독서 모드를 종료할 지의 여부를 판단할 수 있다. 여기서, 독서 모드의 실행 시간이 미리 설정된 시간 간격 동안 지속되면, 프로세서는 독서 모드를 종료해야 하는 것으로 판단할 수 있다. 단계(S870)에서 독서 모드를 종료해야 하는 것으로 판단되면, 프로세서 는 독서 모드를 종료할 수 있다. 도 14는 제 2 실시예에 따른 스마트 리딩 기기의 동작 방법을 도시한 순서도이다. 도 14를 참조하면, 단계(S1410)에서, 프로세서는 대화 기반 인터페이스로서 스마트 리딩 기기에 포함 된 마이크 또는 스마트 리딩 기기와 연동된 마이크와 같은 음성 입력 장치를 통해 사용자의 발화에 따른 음성 명령을 입력받을 수 있다. 프로세서는 스마트 리딩 기기에서 제공 가능한 기능(읽어주는 기능, 악보 연주 기능, 커뮤니케이션 기능, 컨텐츠 제작 기능 등) 중 어느 하나의 기능을 위한 요청으로서 음성 명령 을 구분하여 인식할 수 있다. 단계(S1420)에서, 프로세서는 사용자의 음성 명령이 악보 연주 기능을 위한 요청에 해당되는 경우 스마트 리딩 기기에 포함된 카메라를 활성화시킨 후 카메라를 통해 영상을 입력받아 영상에 포함된 악 보를 인식할 수 있다. 스마트 리딩 기기의 사용자는 악보 인쇄물을 카메라를 마주보는 위치에 놓고 악보 연주 기능을 실행할 수 있으며, 이때 프로세서는 카메라를 통해 입력된 영상에 대해 OCR 스캔이 나 QR 코드 검색을 통해 악보를 인식할 수 있다. 단계(S1430)에서, 연주 제공부는 사용자의 음성 명령에 대한 응답으로, 단계(S1420)에서 인식된 악보를 사 용자에 의해 선택된 특정 악기로 연주하여 악보 연주 기능을 제공할 수 있다. 연주 제공부는 사용자와의 대화를 기반으로 사용자에 의해 선택된 악기를 특정하거나 혹은 사용자에 의해 사전 설정된 악기를 특정할 수 있다. 악기 별 소리 특징 데이터를 포함하는 데이터베이스가 스마트 리딩 기기에 포함되거나 혹은 스마트 리딩 기기와 연동 가능한 서버나 플랫폼 상에 포함될 수 있으며, 이를 통해 연주 제공부는 사용 자에 의해 특정된 악기의 소리 특징 데이터에 기초하여 카메라로 인식된 악보를 해당 악기로 자동 연주해 줄 수 있다. 상기한 스마트 리딩 기기의 동작 방법에 따른 시나리오 예시는 다음과 같다. 1. 사용자가 음성 명령 '이 악보를 피아노로 연주해줘'를 발화하는 경우 스마트 리딩 기기는 카메라 를 활성화시켜 영상을 획득한 후 영상으로 촬영된 악보를 인식할 수 있다. 2. 스마트 리딩 기기는 인식된 악보를 사용자의 음성 명령에 포함된 특정 악기, 즉 피아노 버전으로 연주 할 수 있다. 도 15는 제 3 실시예에 따른 스마트 리딩 기기의 동작 방법을 도시한 순서도이다. 도 15를 참조하면, 단계(S1510)에서, 프로세서는 커뮤니케이션을 위한 요청을 수신할 수 있다. 일 예로, 프로세서는 스마트 리딩 기기에 포함된 마이크 또는 스마트 리딩 기기와 연동된 마이크와 같은 음성 입력 장치를 통해 사용자의 발화에 따른 음성 명령으로서 타 사용자와의 커뮤니케이션을 요청하는 사용자 명령을 수신할 수 있다. 예를 들어, 집에 있는 아이가 스마트 리딩 기기를 통해 엄마와의 커뮤니케이션을요청할 수 있다. 다른 예로, 프로세서는 네트워크를 통해 스마트 리딩 기기에 접속한 타 사용 자로부터 스마트 리딩 기기의 사용자와의 커뮤니케이션을 요청하는 명령을 수신할 수 있다. 예를 들어, 외부에 있는 엄마가 스마트 리딩 기기에 접속 가능한 앱을 통해 집에 있는 아이와의 커뮤니케이션을 요청 할 수 있다. 단계(S1520)에서, 프로세서는 커뮤니케이션 기능에 해당되는 요청이 수신되는 경우 스마트 리딩 기기(20 0)가 CCTV와 같이 동작하도록 스마트 리딩 기기의 카메라가 포함된 헤드 부분의 기울기를 조정 할 수 있다. 일 예로, 프로세서는 사용자가 영상 촬영을 위한 방향으로 헤드 부분의 기울기를 조정 하도록 하는 가이드를 음성으로 발화할 수 있다. 다른 예로, 스마트 리딩 기기가 헤드 부분의 기울 기를 조정할 수 있는 회전 구조물을 포함하는 경우, 프로세서는 스마트 리딩 기기에 포함된 센서 혹 은 스마트 리딩 기기와 연동된 센서를 통해 주변의 움직임을 감지할 수 있고 움직임이 감지된 곳을 향하도 록 헤드 부분의 기울기를 자동 조정할 수 있다. 단계(S1530)에서 프로세서는 헤드 부분의 기울기 조정이 완료되면 스마트 리딩 기기의 카메라 를 통해 입력되는 영상을 네트워크를 통해 사전에 정해진 타 사용자의 전자 기기로 실시간 전송할 수 있다. 다시 말해, 프로세서는 스마트 리딩 기기의 사용자 혹은 사전에 정해진 타 사용자의 요청을 수신하는 경우 사용자와 타 사용자 간의 커뮤니케이션을 위해 카메라를 활성화시켜 스마트 리딩 기기(20 0)에서 촬영된 실시간 영상을 타 사용자의 전자 기기로 전달할 수 있다. 상기한 스마트 리딩 기기의 동작 방법에 따른 시나리오 예시는 다음과 같다. 1. 외부에 있는 엄마가 스마트폰을 통해 가정 내 스마트 리딩 기기에 접속하여 커뮤니케이션 기능을 요청 하는 경우 스마트 리딩 기기는 카메라와 마이크 등을 포함한 대화 기반 인터페이스를 활성화시킬 수 있다. 2. 엄마가 '우리 딸, 뭐하고 있어?'와 같이 음성이나 문자 메시지를 전송하는 경우 스마트 리딩 기기는 수 신된 메시지를 음성으로 출력함과 동시에, 카메라를 통해 촬영된 영상을 실시간으로 엄마의 스마트폰으로 전달할 수 있다. 3. 집에 있는 아이가 스마트 리딩 기기를 통해 '퍼즐 맞추기 하고 있어요.'와 같이 발화하는 경우 아이의 발화에 따라 입력된 음성을 엄마의 스마트폰으로 전달할 수 있다. 다른 시나리오 예시는 다음과 같다. 1. 집에 있는 아이가 스마트 리딩 기기를 통해 '엄마한테 연결해줘'와 같이 발화하는 경우 스마트 리딩 기 기는 커뮤니케이션을 위한 요청으로 인식하여 카메라와 마이크 등을 포함한 대화 기반 인터페이스를 활성화시킬 수 있다. 2. 스마트 리딩 기기는 사전에 정해진, 예컨대 엄마의 스마트폰으로 커뮤니케이션을 위한 요청을 전달한다. 엄마의 스마트폰에서는 스마트 리딩 기기와 연관된 앱을 통해 스마트 리딩 기기로부터 커 뮤니케이션을 위한 요청을 수신했음을 알림으로 표시할 수 있다. 3. 스마트 리딩 기기는 엄마가 커뮤니케이션 요청을 수락하는 경우 카메라를 통해 촬영된 영상을 실 시간으로 엄마의 스마트폰으로 전달할 수 있다. 그리고, 스마트 리딩 기기는 아이가 '엄마 몇 시쯤 와 요?' 와 같이 발화하는 경우 아이의 발화 음성을 엄마의 스마트폰으로 전달할 수 있다. 도 16은 제 4 실시예에 따른 스마트 리딩 기기의 동작 방법을 도시한 순서도이다. 도 16을 참조하면, 단계(S1610)에서, 프로세서는 컨텐츠 제작을 위한 요청을 수신할 수 있다. 일 예로, 프로세서는 스마트 리딩 기기에 포함된 마이크 또는 스마트 리딩 기기와 연동된 마이크와 같은 음성 입력 장치를 통해 사용자의 발화에 따른 음성 명령으로서 컨텐츠 제작을 요청하는 사용자 명령을 수신할 수 있다. 단계(S1620)에서, 프로세서는 컨텐츠 제작 기능에 해당되는 요청이 수신되는 경우 스마트 리딩 기기 의 카메라가 포함된 헤드 부분의 기울기를 조정할 수 있다. 일 예로, 프로세서는 사용자가 영 상 촬영을 위한 방향으로 헤드 부분의 기울기를 조정하도록 하는 가이드를 음성으로 발화할 수 있다. 다 른 예로, 스마트 리딩 기기가 헤드 부분의 기울기를 조정할 수 있는 회전 구조물을 포함하는 경우, 프로세서는 스마트 리딩 기기에 포함된 센서 혹은 스마트 리딩 기기와 연동된 센서를 통해 주변의 움직임을 감지할 수 있고 움직임이 감지된 곳을 향하도록 헤드 부분의 기울기를 자동 조정할 수 있다. 단계(S1630)에서 프로세서는 헤드 부분의 기울기 조정이 완료되면 스마트 리딩 기기의 카메라 를 이용한 영상 촬영을 통해 영상 컨텐츠를 제작할 수 있다. 프로세서 음성 기반 인터페이스를 통해 컨텐츠 제작과 관련된 사용자 명령을 수신할 수 있으며, 사용자 명령에 따라 카메라를 통해 촬영된 영상을 이용하여 컨텐츠를 제작할 수 있다. 그리고, 프로세서 영상 컨텐츠의 제작이 완료되면 사용자의 요청에 따라 네트워크를 통해 사전에 정해진 외부 서버로 업로드할 수 있다. 프로세서 SNS 서버, 클라우드 서버 등 사용자가 영상 컨텐츠를 게재하기 위해 사전에 정해놓은 외부 서버로 영상 컨텐츠를 자동 업로드할 수 있다. 상기한 스마트 리딩 기기의 동작 방법에 따른 시나리오 예시는 다음과 같다. 1. 사용자가 스마트 리딩 기기를 통해 '카메라 켜줘'와 같이 발화하는 경우 스마트 리딩 기기는 컨텐 츠 제작을 위한 요청으로 인식하여 카메라와 마이크 등을 포함한 대화 기반 인터페이스를 활성화시킬 수 있다. 2. 스마트 리딩 기기는 대화 기반 인터페이스를 활성화시킨 후 '카메라 켰어. 준비되면 말해줘.'와 같이 가이드를 발화한 후 컨텐츠 제작을 위한 대기 상태를 유지할 수 있다. 3. 사용자가 '동영상 시작'과 같이 발화하는 경우 스마트 리딩 기기는 카메라를 통해 동영상 촬영을 시작할 수 있고, 이후 동영상 촬영 도중에 사용자가 '동영상 종료'와 같이 발화하는 경우 스마트 리딩 기기 는 '동영상 종료' 발화 시점 이전까지 촬영된 동영상을 제작 컨텐츠로서 저장할 수 있다. 4. 사용자가 '내 SNS 채널에 올려줘'와 같이 발화하는 경우 스마트 리딩 기기는 미리 설정해 놓은 사용자 의 SNS 채널에 해당 동영상 컨텐츠를 업로드할 수 있다. 이처럼 본 발명의 실시예들에 따르면, 책이나 카드 등 모든 인쇄물을 스캔하여 읽어주는 기기로서 카메라와 조 명, 그리고 AI 스피커가 결합된 스탠드 타입의 스마트 리딩 기기를 제공할 수 있으며, 이를 통해 단순히 텍스트 나 이미지를 인식하여 읽어주는 기능뿐만 아니라, 사용자가 원하는 목소리로 읽어주는 기능, 목소리를 녹음하여 읽어주는 목소리로 활용하는 기능, 사용자가 원하는 언어로 번역하여 읽어주는 기능, 악보를 인식하여 다양한 악기로 자동 연주해주는 기능, CCTV 용도로 활용하여 커뮤니케이션을 제공하는 기능, 영상 기반의 컨텐츠를 제 작하는 기능 등을 제공할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 프로세서, 콘트롤 러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2019-0156138", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 컴퓨 터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분 산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 이때, 매체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것일 수도 있다. 또한, 매체는 단일 또는 수 개의 하드웨어가 결합된 형태의다양한 기록수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트 워크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같 은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예시로, 어플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어 를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다."}
{"patent_id": "10-2019-0156138", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2019-0156138", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 다양한 실시예들에 있어서 컴퓨터 장치의 내부 구성의 일례를 설명하기 위한 블록도이다. 도 2는 다양한 실시예들에 있어서 스마트 리딩 기기를 예시적으로 도시한 사시도이다. 도 3은 도 1의 프로세서의 상세 구성을 도시한 도면이다. 도 4는 일 실시예에 있어서, 클라우드 인공지능 플랫폼의 예를 도시한 도면이다. 도 5는 제 1 실시예에 따른 스마트 리딩 기기의 동작 방법을 도시한 순서도이다. 도 6a는 도 5의 사용자의 명령 인식 단계를 도시한 순서도이다. 도 6b는 도 5의 영상 획득 단계를 설명하기 위한 도면이다. 도 7은 제 1 실시예에 따른 스마트 리딩 기기의 설정 단계를 도시한 순서도이다. 도 8은 도 5의 읽어주는 기능 제공 단계를 도시한 순서도이다. 도 9a는 도 8의 텍스트 인식 단계를 설명하기 위한 도면이다. 도 9b는 도 8의 텍스트 인식 단계를 설명하기 위한 도면이다. 도 10a, 도 10b, 도 10c 및 도 10d는 텍스트 인식 단계를 설명하기 위한 도면들이다. 도 11은 도 8의 음성 발화 단계를 도시한 순서도이다. 도 12는 도 8의 음성 발화 단계를 도시한 순서도이다. 도 13a 및 도 13b는 도 8의 페이지 넘김 검출 단계를 설명하기 위한 도면이다. 도 14는 제 2 실시예에 따른 스마트 리딩 기기의 동작 방법을 도시한 순서도이다.도 15는 제 3 실시예에 따른 스마트 리딩 기기의 동작 방법을 도시한 순서도이다. 도 16은 제 4 실시예에 따른 스마트 리딩 기기의 동작 방법을 도시한 순서도이다."}
