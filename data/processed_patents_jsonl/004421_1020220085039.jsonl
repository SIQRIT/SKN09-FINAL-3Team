{"patent_id": "10-2022-0085039", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0008091", "출원번호": "10-2022-0085039", "발명의 명칭": "디포커스 학습 장치 및 이와 통신하는 카메라 장치", "출원인": "한화비전 주식회사", "발명자": "변재운"}}
{"patent_id": "10-2022-0085039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "프로세서와, 상기 프로세서에 의해 실행 가능한 인스트럭션들을 저장하는 메모리를 포함하는 디포커스 학습 장치로서,학습 이미지를 입력받는 이미지 입력부;상기 입력된 학습 이미지에 대한 촬영 정보를 생성하는 촬영 정보 생성부;상기 학습 이미지와 상기 촬영 정보를 이용하여, 디포커스 정도를 포함하는 라벨링 데이터를 생성하는 오토 라벨링부; 및상기 촬영된 학습 이미지와 이에 대응되는 라벨링 데이터의 조합을 입력으로 하여 지도 AI 러닝을 수행함으로써네트워크 파라미터를 획득하는 AI 러닝부를 포함하되,상기 디포커스 정도는, 상기 학습 이미지의 포커스 위치가 정초점 위치로부터 이격된 정도를 나타내는 제1 데이터와, 상기 포커스 위치가 상기 정초점을 향하는 방향을 나타내는 제2 데이터를 포함하는, 디포커스 학습 장치."}
{"patent_id": "10-2022-0085039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 촬영 정보는상기 촬영된 학습 이미지의 포커스 위치;상기 촬영된 학습 이미지에 대응되는 정초점 위치; 및상기 학습 이미지를 촬영한 카메라의 줌 배율에 따른 렌즈 심도를 포함하는, 디포커스 학습 장치."}
{"patent_id": "10-2022-0085039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 오토 라벨링부는, 상기 학습 이미지의 포커스 위치와 상기 정초점 위치 간의 차이값을 상기 렌즈 심도로나눈 값을 상기 제1 데이터로 생성하고, 상기 학습 이미지의 포커스 위치에서 상기 정초점 위치를 차분한 값의부호를 상기 제2 데이터로 생성하는, 디포커스 학습 장치."}
{"patent_id": "10-2022-0085039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 촬영 정보 생성부는 동일한 카메라에서 다양한 줌 배율에 따라 촬영된 학습 이미지의 정초점 위치, 포커스위치 및 포커스 값을 분석하여 상기 렌즈 심도를 산출하는, 디포커스 학습 장치."}
{"patent_id": "10-2022-0085039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 촬영 정보 생성부는 상기 렌즈 심도를 해당 카메라의 사양으로부터 획득하는, 디포커스 학습 장치."}
{"patent_id": "10-2022-0085039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 학습 이미지는저조도 이미지, 스팟 라이트 이미지, 고주파 이미지 및 저주파 이미지를 포함하는, 디포커스 학습 장치."}
{"patent_id": "10-2022-0085039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2024-0008091-3-프로세서와, 상기 프로세서에 의해 실행 가능한 인스트럭션들을 저장하는 메모리를 포함하는 카메라 장치로서,실제 이미지를 촬영하는 이미지 센서;디포커스 추정을 위한 네트워크 파라미터를 수신하는 통신부;상기 네트워크 파라미터를 상기 실제 이미지에 적용하는 AI 추론 과정을 통해, 상기 실제 이미지의 디포커스 정도를 추정하는 디포커스 추론부; 및상기 추정된 디포커스 정도에 기초하여 정초점 위치를 산출하고, 상기 산출된 정초점 위치로 렌즈를 이동시키는제어부를 포함하되, 상기 디포커스 정도는, 상기 실제 이미지의 포커스 위치가 정초점 위치로부터 이격된 정도를 나타내는 제1 데이터와, 상기 포커스 위치가 상기 정초점을 향하는 방향을 나타내는 제2 데이터를 포함하는, 카메라 장치."}
{"patent_id": "10-2022-0085039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제1 데이터는 상기 실제 이미지의 포커스 위치와 상기 정초점 위치 간의 차이값을 상기 렌즈 심도로 나눈값으로 정의되고, 상기 제2 데이터는 상기 실제 이미지의 포커스 위치에서 상기 정초점 위치를 차분한 값의 부호로 정의되는, 카메라 장치."}
{"patent_id": "10-2022-0085039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 디포커스 정도를 사용자에게 표시하는 디스플레이를 더 포함하는, 카메라 장치."}
{"patent_id": "10-2022-0085039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서, 상기 산출된 정초점 위치와 상기 렌즈의 로커스 데이터에 기초하여 상기 실제 이미지에 포함된 피사체와의 거리를 산출하는 거리 산출부를 더 포함하는, 카메라 장치."}
{"patent_id": "10-2022-0085039", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "디포커스 학습 장치는, 학습 이미지를 입력받는 이미지 입력부와, 상기 입력된 학습 이미지에 대한 촬영 정보를 생성하는 촬영 정보 생성부와, 상기 학습 이미지와 상기 촬영 정보를 이용하여, 디포커스 정도를 포함하는 라벨 링 데이터를 생성하는 오토 라벨링부와, 상기 촬영된 학습 이미지와 이에 대응되는 라벨링 데이터의 조합을 입력 으로 하여 지도 AI 러닝을 수행함으로써 네트워크 파라미터를 획득하는 AI 러닝부로 이루어진다. 여기서, 상기 디포커스 정도는, 상기 학습 이미지의 포커스 위치가 정초점 위치로부터 이격된 정도를 나타내는 제1 데이터와, 상기 포커스 위치가 상기 정초점을 향하는 방향을 나타내는 제2 데이터를 포함한다."}
{"patent_id": "10-2022-0085039", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이미지의 디포커스(defocus)를 추정하는 기술에 관한 것으로, 더욱 상세하게는, AI 러닝을 이용하여 현재 촬영된 이미지의 디포커스 정도를 추정하는 장치에 관한 것이다."}
{"patent_id": "10-2022-0085039", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "디지털카메라나 디지털 비디오 카메라 등으로 대표되는 전자기기에는 예를 들면 CCD(Charge Coupled Device)나 CMOS(Complementary Metal-Oxide Semiconductor) 이미지 센서 등의 촬영 장치가 탑재된다. 촬영 장치는 자동으 로 초점 조정을 하는 오토 포커스(AF) 기능을 가진다. 자동 초점에서는 렌즈를 구동함으로써 초점이 적절하게 조정되고, 이렇게 초점이 조정된(focused) 화상을 취득하는 것이 가능하게 된다. 그러나 종래의 자동 초점에서는 대상이 되는 피사체에 의해 반드시 사용자가 희망하는 부분에 자동으로 초점 조 정이 되지 못한다. 이 경우, 촬영 시에 사용자가 초점 조정을 위한 조작을 하지 않으면 안 되기 때문에 사용자 는 촬영 자체에 전념하여 촬영할 수 없게 된다. 뿐만 아니라 이러한 오토 포커스 기능을 사용하기 위해서는 렌즈의 위치를 가변함으로써 렌즈와 이미지센서 간 의 거리를 조정하고 피사체의 이미지의 포커싱을 수행해야 하므로, 최적의 포커스 위치, 즉 정초점 위치를 찾기 위한 시간 지연이 발생하게 된다. 이러한 점을 고려하여, 상기 최적의 포커스 위치를 신속하게 찾아내기 위해서 실제 정초점 위치에 근접한 기준 점으로부터 그 주변 범위를 탐색하는 방식을 사용할 수 있다. 그러나, 이질적인 환경에서 촬영되는 다양한 이미지에 대해 상기 기준점을 정확하게 결정하기는 어렵고, 이를 위해 초음파, 레이저, 라이다와 같은 별도의 거리 센서를 사용하면 제조 비용이나 장치의 소형화 면에서 불리하다는 문제가 있다. 따라서, 별도의 장치나 오토 포커스를 위한 렌즈 구동 동작 없이도, 단순히 입력된 이미지 자체의 분석만으로 상기 이미지의 디포커스 정도를 결정할 수 있는 방안을 개발할 필요가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국특허공개공보 10-2021-0086493호 (2021.7.8 공개)"}
{"patent_id": "10-2022-0085039", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적 과제는, AI 러닝을 통해 촬영되는 실시간 이미지에 대한 디포커스 정도를 상기 이미지 자체만으로 결정할 수 있는 장치를 제공하고자 하는 것이다. 본 발명이 이루고자 하는 다른 기술적 과제는, 상기 추정된 디포커스 정도를 이용하여 빠른 오토 포커스(AF) 동 작을 수행할 수 있는 장치를 제공하고자 하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과 제들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0085039", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 달성하기 위한 본 발명의 일 실시예에 따른, 프로세서와, 상기 프로세서에 의해 실행 가능 한 인스트럭션들을 저장하는 메모리를 포함하는 디포커스 학습 장치는, 학습 이미지를 입력받는 이미지 입력부; 상기 입력된 학습 이미지에 대한 촬영 정보를 생성하는 촬영 정보 생성부; 상기 학습 이미지와 상기 촬영 정보 를 이용하여, 디포커스 정도를 포함하는 라벨링 데이터를 생성하는 오토 라벨링부; 및 상기 촬영된 학습 이미지 와 이에 대응되는 라벨링 데이터의 조합을 입력으로 하여 지도 AI 러닝을 수행함으로써 네트워크 파라미터를 획 득하는 AI 러닝부를 포함하되, 상기 디포커스 정도는, 상기 학습 이미지의 포커스 위치가 정초점 위치로부터 이 격된 정도를 나타내는 제1 데이터와, 상기 포커스 위치가 상기 정초점을 향하는 방향을 나타내는 제2 데이터를 포함한다. 상기 촬영 정보는, 상기 촬영된 학습 이미지의 포커스 위치; 상기 촬영된 학습 이미지에 대응되는 정초점 위치; 및 상기 학습 이미지를 촬영한 카메라의 줌 배율에 따른 렌즈 심도를 포함한다. 상기 오토 라벨링부는, 상기 학습 이미지의 포커스 위치와 상기 정초점 위치 간의 차이값을 상기 렌즈 심도로 나눈 값을 상기 제1 데이터로 생성하고, 상기 학습 이미지의 포커스 위치에서 상기 정초점 위치를 차분한 값의 부호를 상기 제2 데이터로 생성한다. 상기 촬영 정보 생성부는 동일한 카메라에서 다양한 줌 배율에 따라 촬영된 학습 이미지의 정초점 위치, 포커스 위치 및 포커스 값을 분석하여 상기 렌즈 심도를 산출한다. 상기 촬영 정보 생성부는 상기 렌즈 심도를 해당 카메라의 사양으로부터 획득한다. 상기 학습 이미지는, 저조도 이미지, 스팟 라이트 이미지, 고주파 이미지 및 저주파 이미지를 포함한다. 상기 기술적 과제를 달성하기 위한 본 발명의 일 실시예에 따른, 프로세서와, 상기 프로세서에 의해 실행 가능 한 인스트럭션들을 저장하는 메모리를 포함하는 카메라 장치는, 실제 이미지를 촬영하는 이미지 센서; 디포커스 추정을 위한 네트워크 파라미터를 수신하는 통신부; 상기 네트워크 파라미터를 상기 실제 이미지에 적용하는 AI 추론 과정을 통해, 상기 실제 이미지의 디포커스 정도를 추정하는 디포커스 추론부; 및 상기 추정된 디포커스 정도에 기초하여 정초점 위치를 산출하고, 상기 산출된 정초점 위치로 렌즈를 이동시키는 제어부를 포함하되, 상기 디포커스 정도는, 상기 실제 이미지의 포커스 위치가 정초점 위치로부터 이격된 정도를 나타내는 제1 데이 터와, 상기 포커스 위치가 상기 정초점을 향하는 방향을 나타내는 제2 데이터를 포함한다.상기 제1 데이터는 상기 실제 이미지의 포커스 위치와 상기 정초점 위치 간의 차이값을 상기 렌즈 심도로 나눈 값으로 정의되고, 상기 제2 데이터는 상기 실제 이미지의 포커스 위치에서 상기 정초점 위치를 차분한 값의 부 호로 정의된다. 상기 카메라 장치는 상기 디포커스 정도를 사용자에게 표시하는 디스플레이를 더 포함한다. 상기 카메라 장치는 상기 산출된 정초점 위치와 상기 렌즈의 로커스 데이터에 기초하여 상기 실제 이미지에 포 함된 피사체와의 거리를 산출하는 거리 산출부를 더 포함한다."}
{"patent_id": "10-2022-0085039", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 라벨링 된 인포커스 이미지 및 디포커스 이미지를 AI 러닝 기반으로 학습하고 상기 학습된 정보를 기반으로 보다 정확한 디포커스 정도를 감지할 수 있고, 이를 이용하여 신속한 AF 동작을 수행할 수 있 다는 장점이 있다. 본 발명에 따르면, 상기 디포커스 정도를 기반으로 카메라와 피사체 간의 거리를 신속하게 산출할 수 있다는 장 점도 있다."}
{"patent_id": "10-2022-0085039", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2022-0085039", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해 석되지 않는다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 이하 첨부된 도면들을 참조하여 본 발명의 일 실시예를 상세히 설명한다. 도 1은 본 발명의 실시예에 따른 영상 감시 시스템의 구성을 도시한 도면이다. 도 1에 따르면, 상기 시스템 은 복수의 카메라 장치(200: 200A, 200B, 200C), 네트워크 비디오 레코더, 사용자 단말 장치 및 디포커스 학습 장치를 포함하며, 각각의 장치들은 상호 간에 인터넷, 인트라넷과 같은 네트워크를 통해 연결되어 상호 통신 가능한 상태에 있다. 상기 카메라 장치는 네트워크 상의 다양한 위치에서 감시 영역을 촬상하며, 네트워크 비디오 레코더는 다양한 카메라 장치들로부터 제공된 영상들을 저장하는 기능을 갖는다. 또한, 사용자 단말 장치는 개 인용 컴퓨터, 모바일 단말 등으로 구현될 수 있으며, 상기 네트워크를 통해 카메라 장치 및/또는 네트 워크 비디오 레코더와 접속되어 촬상된 영상을 검색하고 디스플레이 할 수 있는 기능을 갖는다. 본 발명에 서 \"영상(image)\"은 비디오(video)와 같은 동화상(moving picture)이나 정지 영상(still image)을 모두 포함하 는 개념으로 사용될 것이다. 도 1에서, 디포커스 학습 장치는 촬영된 학습 이미지에 대한 촬영 정보를 이용하여, 디포커스 정도를 포함 하는 라벨링 데이터를 생성하고, 상기 촬영된 학습 이미지와 이에 대응되는 라벨링 데이터의 조합을 입력으로 하여 AI 러닝을 수행함으로써 네트워크 파라미터를 획득한다(AI 학습 과정). 이러한 네트워크 파라미터는 AI 파 라미터라고도 불리며 디포커스 추정을 위한 학습 모델을 결정하는 데이터이다. 한편, 카메라 장치는 상기 획득된 네트워크 파라미터(즉, 학습 데이터)를 제공받아 이를 실제 촬상된 이미 지에 적용하여 상기 촬상된 이미지의 디포커스 정도를 추정한다(AI 추론 과정). 이와 같이 AI 학습 과정과 AI 추론 과정은 각각 다른 장치(100, 200)에 의해 구현될 수 있다. 물론, 2개의 과정 이 모두 카메라 장치 내에서 수행되도록 구성할 수도 있으나 카메라 장치의 컴퓨팅 파워나 리소스의 제약을 고려할 때 바람직하지 않다. 따라서, 상대적으로 방대한 데이터 처리 및 연산이 필요한 AI 학습 과정은 별도의 서버에서 수행하고, 그 결과 얻어지는 네트워크 파라미터(학습 데이터)를 카메라 장치가 이용 하여 실제 이미지에 대한 디포커스 추정하는 것이 보다 현실적일 것이다. 도 2는 본 발명의 일 실시예에 따른 디포커스 학습 장치의 구성을 도시한 블록도이다. 디포커스 학습 장치는 제어부, 저장부, 촬영 정보 생성부, 오토 라벨링부, AI 러닝부 , 통신부, 이미지 입력부를 포함하여 구성될 수 있다. 또한, 디포커스 학습 장치가 직접 학습 이미지를 생성하는 실시예에서는 이미지 캡쳐부를 더 구비될 수 있다. 물론, 상기 학습 이미지가 별 도의 외부 장치로부터 제공된다면 상기 이미지 캡쳐부는 생략될 수 있을 것이다. 제어부(controller, 110)는 디포커스 학습 장치의 다른 구성요소들의 동작을 제어하는 컨트롤러 역할을 하 며, 일반적으로 CPU(central processing unit), 마이크로프로세서(microprocessor) 등으로 구현될 수 있다. 도 2에서 실선은 데이터의 흐름 방향을 나타내고 점선은 컨트롤의 방향을 나타낸다. 또한, 저장부는 제어부 에서 수행된 결과를 저장하거나 제어부의 동작을 위해 필요한 데이터를 저장하는 저장 매체로서, 휘 발성 메모리 또는 비휘발성 메모리로 구현될 수 있다. 또한, 통신부는 외부 장치와 통신 가능하게 접속하 여 전송 패킷을 송수신하기 위한 인터페이스를 포함하며, 유선 회선과 접속하기 위한 유선 네트워크 인터페이스 또는 무선 회선과 접속하기 위한 무선 네트워크 인터페이스로 구현될 수 있다. 이미지 입력부는 디포커스 학습 장치 내에서 디포커스 학습을 수행하기 위한 로(raw) 데이터로서 다 수의 학습 이미지를 입력 받는다. 이러한 학습 이미지는 디포커스 학습 장치 외부의 장치(외부 장치)로부터 제 공받을 수도 있고(이미지 1), 디포커스 학습 장치 내에 포함된 이미지 캡쳐부에 의해 직접 촬상될 수 도 있다(이미지 2). 상기 외부 장치는 다양한 카메라 장치를 포함할 수 있다. 예를 들어, 디포커스 학습 장치 외부에 존재하는 적어도 하나의 카메라 장치에서 캡쳐된 학습 이미지(이미지 2)가 이미지 입력부에 제공될 수 있는 것이다. 이 때, 상기 카메라 장치는 디포커스 학습 장치와 네트워크로 연결되어 직접 학습 이미지를 송신할 수도 있고, 오프라인으로 별도의 저장 매체를 통해 학습 이미지를 제공할 수도 있다. 촬영 정보 생성부는 상기 학습 이미지로부터 메타데이터에 해당하는 촬영 정보를 생성하여 오토 라벨링부 에 제공할 수 있다. 상기 학습 이미지는 후술하는 AI 러닝에 사용되는 입력 데이터이므로, 그 정확도를 높 이기 위해서는 다양한 촬영 조건에서 촬영된 방대한 학습 이미지를 확보하는 것이 중요하다. 따라서, 상기 학습 이미지는 저조도 이미지, 스팟 라이트 이미지, 고주파 이미지 및 저주파 이미지 등 다양한 타입의 이미지들을 포함하는 것이 바람직할 것이다. 상기 촬영 정보 생성부는 학습 이미지로부터 디포커스 학습 장치 내에 존재할 수도 있지만, 상기 학 습 이미지 및 촬영 정보를 다른 장치에서 생성하여 제공하는 경우에는 생략될 수도 있다. 이러한 촬영 정보는 동일한 카메라에서 다양한 줌 배율에 따라 촬영된 학습 이미지의 상기 촬영된 학습 이미지 의 포커스 위치와 포커스 값, 상기 촬영된 학습 이미지에 대응되는 정초점 위치, 및 상기 학습 이미지를 촬영한 카메라의 줌 배율에 따른 렌즈 심도를 포함할 수 있다. 여기서, 상기 렌즈 심도는 상기 학습 이미지에 대한 정초점 위치, 포커스 위치 및 포커스 값을 분석하여 산출될 수도 있다. 상기 렌즈 심도는 렌즈별로 상이하고, 동일한 렌즈라도 광학 줌 배율에 따라서도 상이하다. 일반적 으로 렌즈 심도란 정초점 위치로부터 포커스 위치의 이동량에 따라 이미지의 디포커스 정도가 얼마나 급격한가 에 따라 정의되며, 정초점으로부터 이격된 거리를 렌즈 심도로 나눔으로써 렌즈와 무관하게 디포커스 정도를 정 규화할 수 있다. 예를 들어, 렌즈 심도가 50인 렌즈와 렌즈 심도가 100인 렌즈가 있다고 할 때, 렌즈 심도가 50 인 렌즈의 이동량이 m일 때, 렌즈 심도가 100인 렌즈의 이동량이 2m이면 여기서 촬영된 이미지의 디포커스 정도 는 동일하다고 가정된다. 따라서, 상기 학습 이미지에 대한 현재 포커스 위치와 실제 정초점 위치 간의 차이를 디포커스 정도(예: 정초점 위치의 포커스 값과 현재 포커스 위치의 포커스 값의 차이)로 나눔으로써, 역으로 렌즈 심도를 구할 수도 있다. 또는, 촬영 정보 생성부는 상기 렌즈 심도를 해당 카메라로부터 직접 전달받을 수도 있다. 이러한 렌즈 심 도는 상기 로커스 데이터와 같은 사양 정보로부터 직접 얻을 수 있다. 오토 라벨링부는 촬영된 학습 이미지에 대한 촬영 정보를 이용하여, 디포커스 지표를 포함하는 라벨링 데 이터를 자동으로 생성한다. 상기 디포커스 지표란, 상기 학습 이미지의 포커스 위치가 정초점(infocus) 위치로부터 이격된 정도를 나타내는 제1 데이터와, 상기 학습 이미지의 포커스 위치가 상기 정초점을 향하는 방향을 나타내는 제2 데이터로 구성될 수 있다. 구체적으로, 오토 라벨링부는, 상기 학습 이미지의 포커스 위치와 상기 정초점 위치 간의 차이값 을 상기 렌즈 심도로 나눈 값(즉, 정규화 된 디포커스 정도)을 상기 제1 데이터로 생성하고, 상기 학습 이미지 의 포커스 위치에서 상기 정초점 위치를 차분한 값의 부호를 상기 제2 데이터로 생성할 수 있다. 따라서, 상기 부호는 정초점보다 포커스 위치가 원거리(Far position)에 가까우면 플러스, 근거리(Near position)에 가까우면 마이너스로 정의될 수 있다(물론, 반대로 정의해도 무방함). AI 러닝부는 상기 촬영된 학습 이미지와 이에 대응되는 라벨링 데이터의 조합을 입력으로 하여 지도 AI 러 닝(supervised AI learning)을 수행함으로써 네트워크 파라미터(AI 파라미터)를 획득한다. 이러한 레이블 입력 을 통한 머신 러닝은 정답치를 알고 있는 다수의 학습 데이터를 통해 AI가 원하는 답을 낼 때까지 다수의 반복 학습을 수행하는 과정이다. 통상 이러한 머신 러닝 기법은 소위 지도 학습(supervised learning) 분야에 속한다. 지도 학습이란 예제를 통 해 학습하는 것으로, 러닝 데이터에는 명확하게 레이블(정답치)이 부가되어 있다. 즉, 입력 데이터가 이미 원하 는 출력 결과와 쌍을 이루고 있다. 지도 학습은 일반적으로 매우 많은 양의 주석 데이터가 필요하며 훈련된 알 고리즘의 성능은 러닝 데이터의 품질에 직접적으로 의존한다. 따라서, 다양한 촬영 사례, 방향, 배율, 조명 상 황, 배경 등과 같은, 이미지가 처한 환경을 나타내는 이미지 속성을 사용하여 다양한 이미지로 알고리즘을 훈련 시켜야 한다. 러닝 데이터가 계획된 사용 사례를 대표하는 경우에만, 최종 분석 애플리케이션이 훈련 단계에서 볼 수 없는 새로운 데이터를 처리할 때도 정확한 예측을 할 수 있는 것이다. 본 발명에서 상기 레이블에 속하는 타겟 값은 디포커스 지표이지만, 보다 정확한 머신 러닝을 위해서는 다양한 이미지 속성별 분류에 속하는 이미지들을 통해 반복적인 학습이 필요하다. 결국, 본 발명에서의 머신 러닝은 이 러한 다양한 이미지 속성을 갖는 매우 많은 학습 이미지에 대해서 상기 디포커스 지표를 레이블로 입력하고 신 경망 학습을 반복함으로써 보다 정확한 학습 모델 즉, 네트워크 파라미터를 얻을 수 있다. 특히, AI 러닝부는, 신경망 학습을 수행하여 얻어지는 디포커스 지표와, 오토 라벨링부에서 산출된 라벨 즉, 디포커스 지표 간의 차이가 허용 범위 이내로 될 때까지, 상기 네트워크 파라미터를 변경하면서 상기 신경망 학습을 반복한다. 이러한 반복 학습을 통해, AI 러닝부는 본 발명에서 의도하는 목적에 최적화된 네트워크 파라미터(AI 파라미터)를 구할 수 있다. 이와 같이 AI 러닝부에서 구한 네트워크 파라미터는 통신부를 통해 다양한 카메라 장치들에 제 공될 수 있다. 카메라 장치들은 이러한 네트워크 파라미터를 실제 촬상된 이미지에 적용하는 AI 추론 과정 을 통해 상기 촬상된 이미지의 디포커스 지표를 추정할 수 있게 된다 도 3은 포커스 값이 가장 큰 최적 포커스 위치를 찾는 과정을 보여주는 도면이다. 촬영 정보 생성부는 산 출된 정초점 위치(F1)를 적어도 포함하는 포커스 위치의 범위(R) 내에서 이미지 캡쳐부의 렌즈를 이동시키면서 포커스 값이 피크가 되는 지점(k)을 탐색할 수 있다. 도 3에서는 산출된 정초점 위치(F1)보다 원거리(Far position) 방향으로 약간 이격된 위치에서 실제 정초점 위치(Fo)가 발견됨을 알 수 있다. 도 4는 카메라에서 포커스 값과 포커스 위치의 상관 관계를 예시하는 도면이고, 도 5a 내지 도 5c는 각각 도 4 의 A, B 및 C 위치에서 촬영된 학습 이미지를 도시한 도면들이다. 예시된 바와 같이, 도 5a에 도시된 학습 이미지는 도 4의 A 위치, 즉 포커스 위치가 732인 근거리에 위치하고 그 포커스 값은 1566이다(defocus at near position). 또한, 도 5b에 도시된 학습 이미지는 도 4의 B 위치, 즉 포커스 위치가 1029이고 포커스 값이 피크치인 2977인 정초점(infocus)에 위치한다. 그리고, 도 5c에 도시된 학 습 이미지는 도 4의 C 위치, 즉 포커스 위치가 1327인 원거리(Far position)에 위치하고 그 포커스 값은 1608이 다(defocus at far position). 이와 같이, 학습 이미지는 특정 렌즈로 특정 피사체를 촬영함에 있어서, 적어도 정초점, 근거리 디포커스, 원거 리 디포커스 학습 이미지를 적어도 포함하고, 각각의 학습 이미지에 대한 포커스 값, 포커스 위치가 촬영 정보 로서 상기 학습 이미지에 대응되어 함께 제공된다. 이 때, 렌즈 심도 데이터도 상기 촬영 정보에 포함되어 함께 제공될 수 있다. 인간의 시각으로 관찰할 때, 도 5b의 정초점 위치의 학습 이미지는 분명하게 식별될 수 있다. 하지만, 도 5a의 학습 이미지와 도 5c의 학습 이미지는 비슷한 정도의 디포커스 정도를 갖는다는 정도만 알 수 있을 뿐이고 어느 것이 근거리 이미지인지 원거리 이미지인지 식별하기는 불가능하다. 그러나, 본 발명에서는 사람의 수작업에 의 한 라벨링이 아니라 미리 알 수 있는 근거리 이미지, 원거리 이미지에 관한 방향 정보까지 라벨링에 포함시킴으 로써 AI 러닝에 의해 근거리/원거리 사이의 정확한 구분이 가능해진다 이는 단순히 하나의 실제 이미지를 촬영 하는 것만으로 단순히 디포커스 정도뿐만 아니라 방향까지 함께 알 수 있다는 점에서 정확한 AF 동작에 기여할 수 있는 요소이다. 도 6은 도 4의 AI 러닝부의 보다 자세한 구성을 도시한 블록도이다. AI 러닝부는 AI 처리를 수행할 수 있는 AI 모듈을 포함하는 통신 장치, AI 모듈을 포함하는 서버 등을 포 함한다. AI 러닝부는 AI 프로세서, 메모리 및/또는 통신부를 포함한다. AI 러닝부는 신 경망을 학습할 수 있는 컴퓨팅 장치로서, 서버, 데스크탑 PC, 노트북 PC, 태블릿 PC 등 다양한 전자 장치로 구 현된다. AI 프로세서는 메모리에 저장된 프로그램을 이용하여 신경망(neural network)을 학습한다. 특히, AI 프 로세서는 차량 관련 데이터를 인식하기 위한 신경망을 학습한다. 여기서, 차량 관련 데이터를 인식하기 위 한 신경망은 컴퓨터 상에서 인간의 뇌 구조를 모사(simulation)하도록 설계될 수 있으며, 인간 신경망의 뉴런을 모사하는 가중치를 갖는 복수의 네트워크 노드를 포함한다. 복수의 네트워크 노드는 각각의 연결 관계에 따라 데이터를 교환하여 뉴런이 시냅스를 통해 신호를 주고받는 뉴런의 시냅스 활동을 모사한다. 여기서, 신경망은 신경망 모델로부터 개발된 딥 러닝 모델을 포함한다. 딥 러닝 모델에서 복수의 네트워크 노드는 서로 다른 계층 에 위치하여 컨볼루션(convolution) 연결 관계에 따라 데이터를 교환한다. 신경망 모델의 예로는 심층 신경망 (DNN), 컨볼루션 심층 신경망(CNN), 순환 신경망(RNN), 제한적 볼츠만 기계(RBM), 심층신뢰신경망(DBN)과 같은 다양한 심층 학습 기술이 있다. Deep Q-Networks는 컴퓨터 비전, 음성 인식, 자연어 처리, 음성/신호 처리 등의 분야에 적용될 수 있다. 한편, 상기와 같은 기능을 수행하는 프로세서는 범용 프로세서(예: CPU)일 수 있으나, 인공지능 학습을 위한 AI 전용 프로세서(예: GPU)일 수도 있다. 메모리는 AI 러닝부의 동작에 필요한 각종 프로그램 및 데이터 를 저장한다. 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시 메모리, 하드디스크 드라이브(HDD), 솔리 드 스테이트 드라이브(SDD) 등으로 구현된다. 메모리는 AI 프로세서에 의해 액세스되고, AI 프로세서 에 의한 데이터 읽기/쓰기/편집/삭제/갱신이 수행된다. 또한, 메모리는 본 발명의 일 실시예에 따른 데 이터 분류/인식을 위한 학습 알고리즘을 통해 생성된 신경망 모델(예: 딥 러닝 모델)을 저장한다. 한편, AI 프로세서는 데이터 분류/인식을 위한 신경망 학습을 위한 데이터 러닝부를 포함한다. 데이터 러닝부는 데이터 분류/인식을 결정하기 위해 어떤 트레이닝 데이터를 사용할 것인지, 트레이닝 데이터를 이 용하여 데이터를 어떻게 분류하고 인식하는지에 대한 기준을 학습한다. 데이터 러닝부는 학습에 사용할 학 습 데이터를 획득하고 획득한 학습 데이터를 딥 러닝 모델에 적용하여 딥 러닝 모델을 학습한다. 데이터 러닝부는 적어도 하나의 하드웨어 칩 형태로 제작되어 AI 러닝부에 탑재된다. 예를 들어, 데이 터 러닝부는 인공지능 전용 하드웨어 칩 형태로 제작된다. 인공지능(AI) 또는 범용 프로세서(CPU) 또는 전 용 그래픽 프로세서(GPU)의 일부로 제작되어 AI 러닝부에 탑재된다. 또한, 데이터 러닝부는 소프트웨 어로 구현될 수 있다. 기준 치수. 소프트웨어 모듈(또는 명령어를 포함하는 프로그램 모듈)로 구현되는 경우, 상기 소프트웨어 모듈은 컴퓨터 판독 가능 매체에 저장된다. 이 경우, 적어도 하나의 소프트웨어 모듈은 운영체 제(OS) 또는 애플리케이션에 의해 제공된다. 데이터 러닝부는 러닝 데이터 획득부 및 모델 러닝부를 포함한다. 러닝 데이터 획득부는 데이터 분류 및 인식을 위한 신경망 모델에 대해 요청된 학습 데이터를 획득한다. 예 를 들어, 러닝 데이터 획득부는 신경망 모델에 학습 데이터로 입력하기 위한 차량 데이터 및/또는 샘플 데 이터를 획득한다. 모델 러닝부는 획득한 트레이닝 데이터를 이용하여 신경망 모델이 소정의 데이터를 어떻게 분류하는지 판단 하는 기준을 갖도록 학습한다. 이 경우, 모델 러닝부는 학습 데이터의 적어도 일부를 판단 기준으로 하여 감독 학습(supervised learning)을 통해 신경망 모델을 학습시킬 수 있다. 또는, 모델 러닝부는 비지도 학 습을 통해 신경망 모델을 학습시켜 감독 없이 학습 데이터를 사용하여 자가 학습하여 기준을 발견한다. 또한, 모델 러닝부는 학습 기반의 상황 판단 결과가 정확한지 피드백을 이용하여 강화 학습을 통해 신경망 모델을 학습시킬 수 있다. 또한, 모델 러닝부는 오차 역전파(back-propagation) 방법 또는 그래디언트 디센트 (gradient decent) 방법을 포함하는 학습 알고리즘을 이용하여 신경망 모델을 학습시킬 수 있다. 신경망 모델이 학습되면, 모델 러닝부는 학습된 신경망 모델을 메모리에 저장한다. 모델 러닝부는 학습 된 신경망 모델을 AI 러닝부와 유무선 네트워크로 연결된 서버의 메모리에 저장한다. 데이터 러닝부는 학습 데이터 전처리기(미도시) 및 학습 데이터 선택부(미도시)를 더 포함하여 인식 모델의 분석 결과를 향상시키거나 생성에 필요한 자원 또는 시간을 절약한다. 학습 데이터 전처리기는 획득된 데이터가 상황을 결정하기 위한 학습에 사용될 수 있도록 획득된 데이터를 전처 리한다. 예를 들어, 학습 데이터 전처리부는 획득된 데이터를 미리 설정된 포맷으로 처리하여 모델 러닝부 가 학습을 위해 획득한 학습 데이터를 이미지 인식에 사용할 수 있도록 한다. 또한, 학습 데이터 선택부는 러닝 데이터 획득부에 의해 획득된 학습 데이터 또는 전처리기에 의해 전처리 된 학습 데이터로부터 학습에 필요한 데이터를 선택한다. 선택된 학습 데이터는 모델 러닝부로 제공된다. 예를 들어, 학습 데이터 선택부는 차량 카메라를 통해 획득한 이미지 중 특정 영역을 검출하여 특정 영역에 포 함된 객체에 대한 데이터만을 학습 데이터로 선택한다. 또한, 데이터 러닝부는 신경망 모델의 분석 결과를 향상시키기 위해 모델 평가부(미도시)를 더 포함한다. 모델 평가부는 평가 데이터를 신경망 모델에 입력하고, 평가 데이터로부터 출력된 분석 결과가 소정의 기준을 만족하지 않는 경우 모델 러닝부가 신경망 모델을 재학습시키도록 한다. 이 경우, 평가 데이터는 인식 모델 을 평가하기 위한 미리 정의된 데이터일 수 있다. 예를 들어, 모델 평가부는 평가 데이터에 대한 학습된 인식 모델의 분석 결과 중 분석 결과가 부정확한 평가 데이터의 개수 또는 비율이 기설정된 기준을 초과하는 경우 해 당 모델을 소정 기준을 만족하지 않는 것으로 평가한다. 통신부는 AI 프로세서에 의한 AI 처리 결과를 외부의 통신 장치로 전송한다. 도 7은 도 4의 AI 러닝부가 이용하는 DNN 모델의 예시이다. 도 7를 참조하면, 심층신경망(DNN)은 입력 계 층과 출력 계층 사이에 여러 개의 은닉 계층을 포함하는 인공신경망(ANN)이다. 심층 신경망은 일반적인 인공 신 경망에서와 같이 복잡한 비선형 관계를 모델링할 수 있다. 예를 들어, 객체 식별 모델을 위한 심층 신경망 구조에서 각 객체는 기본 이미지 요소의 계층적 구성으로 표현 된다. 이 경우, 추가 레이어는 점차적으로 모이는 하위 레이어의 특성을 통합할 수 있다. 심층 신경망의 이러한 기능을 통해 유사하게 수행되는 인공 신경망보다 더 적은 수의 단위(노드)로 더 복잡한 데이터를 모델링할 수 있다. 은닉 계층이 증가함으로써 충분히 심화된 인공신경망을 학습 모델로 사용하는 머신 러닝 패러다임을 딥러닝 (deep learning)이라고 한다. 또한 딥 러닝에 사용되는 충분히 깊은 인공 신경망을 일반적으로 DNN(Deep Neural Network)이라고 한다. 본 발명에서 오토 라벨링부에 의한 객체 데이터 생성 모델을 학습시키는 데 필요한 라벨링 데이터는 DNN의 입력 계층에 입력될 수 있고, 데이터가 은닉 계층들을 통과하는 동안 출력 계층을 통해 사용자가 사용할 수 있 는 의미 있는 라벨링 데이터가 생성된다. 이와 같이, 신경망 모델을 통과하여 학습된 라벨링 데이터는 그 정확 도가 확률에 의해 표시될 수 있으며, 상기 확률이 높을수록 평가된 결과의 정확도가 높다는 것을 의미한다. 도 8은 본 발명의 일 실시예에 따른 카메라 장치의 구성을 도시한 블록도이다. 카메라 장치는 렌즈, 이미지 센서, 이미지 처리부, 렌즈 구동부, 제어부, 저장 부, 통신부, 디포커스 추론부, 디스플레이 및 거리 산출부를 포함하여 구성될 수 있 다. 제어부(controller, 250)는 카메라 장치의 다른 구성요소들의 동작을 제어하는 컨트롤러 역할을 하며, 일 반적으로 CPU(central processing unit), 마이크로프로세서(microprocessor) 등으로 구현될 수 있다. 도 2에서 실선은 데이터의 흐름 방향을 나타내고 점선은 컨트롤의 방향을 나타낸다. 또한, 저장부는 제어부에 서 수행된 결과를 저장하거나 제어부의 동작을 위해 필요한 데이터를 저장하는 저장 매체로서, 휘발성 메 모리 또는 비휘발성 메모리로 구현될 수 있다. 또한, 통신부는 외부 장치와 통신 가능하게 접속하여 전송 패킷을 송수신하기 위한 인터페이스를 포함하며, 유선 회선과 접속하기 위한 유선 네트워크 인터페이스 또는 무 선 회선과 접속하기 위한 무선 네트워크 인터페이스로 구현될 수 있다. 통신부는 전술한 디포커스 학습 장 치에서 생성된, 디포커스 추정을 위한 네트워크 파라미터를 수신한다. 렌즈는 셔터(미도시 됨)에 의해 열리거나 닫힐 수 있고, 상기 셔터가 열린 상태에서 피사체에서 반사된 광 을 유입한다. 렌즈는 포커스 조절을 위해 렌즈 구동부에 의해 소정 범위 내에서 이동(전진 또는 후진)할 수 있다. 렌즈 구동부는 일반적으로, 회전 모터, 리니어 모터 또는 다른 형태의 다양한 액츄에이 터(actuator)로 구현될 수 있다. 이미지 센서는 상기 셔터의 개방 상태에서 렌즈로 입력되는 광을 포착하여 전기적 신호로 출력하는 방식으로 이미지를 캡쳐한다. 이러한 이미지는 아날로그 신호 또는 디지털 신호로 표시될 수 있지만 최근에는 디지털 신호로 표시되는 것이 일반적이다. 상기 디지털 신호는 이미지 처리부 내지 ISP(image signal processor)에 의해 전처리 된 후 제어부에 제공되며, 저장부에 일시적 또는 영구적으로 저장된다. 디포커스 추론부는 이미지 처리부로부터 현재 촬영된 실제 이미지를 수신받고, 디포커스 학습 장치 로부터 제공된 네트워크 파라미터를 이용하여 상기 실제 이미지에 대한 디포커스 지표를 추정한다. 상기 디포커스 지표는, 상기 실제 이미지의 포커스 위치가 정초점(infocus) 위치로부터 이격된 정도를 나타내는 제1 데이터와, 상기 실제 이미지의 포커스 위치가 상기 정초점을 향하는 방향을 나타내는 제2 데이터로 구성될 수 있다. 상기 방향이란 부호의 개념으로서, 정초점보다 포커스 위치가 원거리(Far position)에 가까우면 플러스, 근거리(Near position)에 가까우면 마이너스로 정의될 수 있다(물론, 반대로 정의해도 무방함). 디포커스 추론 부에 의해 수행되는 이러한 머신 추론 과정은 디포커스 학습 장치에서 수행되는 머신 러닝 과정과 대 응되는 과정을 통해 이루어진다. 즉, 머신 러닝이 레이블링 된 정답치를 찾기 위하 수많은 로 데이터(raw data) 영상에 대해 반복적인 러닝을 거쳐서 네트워크 파라미터를 결정하는 과정이라면, 머신 추론은 상기 AI 파라미터, 즉 확정된 학습 모델을 이용하여 마찬가지의 절차를 수행함으로써, 특정한 실제 영상에 대해 최종적 인 결과값에 해당하는 디포커스 지표를 추정하는 과정으로서, 상기 머신 추론에 의해 추정된 디포커스 지표는 확률의 형태로 표현될 수 있다. 이와 같이, 디포커스 추론부는 제어부에 디포커스 지표, 즉 디포커스 차이값 및 디포커스 방향을 제 공할 수 있다. 이에 따라, 제어부는 어느 방향으로 얼마만큼 렌즈를 이동하여야 정초점에 근접할 수 있는 지를 즉시 판단할 수 있는 것이다. 다른 실시예로서, 디포커스 추론부는 디포커스 지표 대신에 이진 분류 결과만을 제어부에 제공할 수도 있다. 이러한 이진 분류 결과는 단순히 현재 촬영된 이미지가 인포커스 위 치에 있는가 디포커스 위치에 있는가에 관한 정보만을 포함한다(추가로 확률 정보도 더 포함할 수 있음). 제어부는 상기 추정된 디포커스 지표로부터 정초점(infocus)을 산출할 수 있다. 상기 디포커스 지표가 정 초점으로부터 이격된 정도 및 방향을 모두 포함하므로 상기 정초점은 간단한 가감 연산에 의해 계산될 수 있다. 제어부는 이와 같이 산출된 정초점 위치를 정답으로 생각하고 이에 대응되는 위치로 렌즈를 이동하여 AF 동작을 완료할 수도 있지만, 상기 산출된 정초점 위치가 실제와 오차가 있을 수 있다는 점에서 보다 더 정확 한 포커스를 찾기 위해, 상기 산출된 정초점 위치를 기준점으로 하여 실제 정초점 위치를 탐색할 수도 있다. 구체적으로, 제어부는 상기 산출된 정초점 위치를 적어도 포함하는 범위 내에서 상기 렌즈를 이동시 키도록 렌즈 구동부를 구동하면서, 그 중에서 포커스 값이 가장 큰 포커스 위치를 탐색한다. 상기 포커스값으로는 일반적으로 콘트라스트(contrast) 데이터 내지 에지 데이터를 이용할 수 있다. 이러한 콘트라스트 데 이터는 관심 영역 내의 픽셀과 주변 픽셀과의 차이값의 합(SAD: Sum of Absolute Difference)으로 정의될 수 있 으며, 이 값이 클수록 에지 데이터 또는 영상의 디테일(detail)이 많다는 의미이다. 일반적으로 에지 데이터는 포커스가 정확할수록 보다 높은 값을 갖는다. 이러한 탐색을 통해 가장 큰 포커스 값을 갖는 포커스 위치가 정확한 정초점 위치로 결정되고, 상기 결정된 위 치를 기준으로 렌즈를 이동시킴으로써 AF 동작이 완료될 수 있다. 전술한 도 3과 같이, 제어부는 상 기 산출된 정초점 위치(F1)를 적어도 포함하는 포커스 위치의 범위(R) 내에서 렌즈를 이동시키면서 포커스 값이 피크가 되는 지점(k)을 탐색한다. 도 3에서는 산출된 정초점 위치(F1)보다 원거리(Far position) 방향으로 약간 이격된 위치에서 실제 정초점 위치(Fo)가 발견됨을 알 수 있다. 한편, 이러한 산출된 정초점 위치(F1)를 이용하여, 카메라 장치와 촬영되는 이미지 내에서 포커스가 맞는 객체 까지의 거리를 개략적으로 산출할 수 있다. 거리 산출부는 상기 객체가 상기 캡쳐된 이미지 내에서 차지하 는 비율에 기초하여 상기 카메라 장치와 상기 식별된 객체와의 거리를 산출할 수 있다. 예를 들어, 거리 산출부 는 해당 이미지의 화각 내에서 상기 객체가 상하 방향으로 차지하는 비율을 이용하여 상기 거리를 산출할 수 있다. 도 9는 도 2 및 도 8의 장치들(100, 200)을 실현하는 컴퓨팅 장치의 하드웨어 구성을 예시하는 도면이다. 컴퓨팅 장치은 버스, 프로세서, 메모리, 스토리지, 입출력 인터페이스 및 네트 워크 인터페이스를 가진다. 버스는 프로세서, 메모리, 스토리지, 입출력 인터페이스 및 네트워크 인터페이스가 서로 데이터를 송수신하기 위한 데이터 전송로이다. 단, 프로세서 등을 서로 접속하는 방법은 버스 연결로 제한되지 않는다. 프로세서는 CPU (Central Processing Unit)나 GPU (Graphics Processing Unit) 등의 연산 처리 장치이다. 메모리은 RAM (Random Access Memory)나 ROM (Read Only Memory) 등의 메모리이다. 스토리지는 하드 디스크, SSD (Solid State Drive), 또는 메모리 카드 등의 저장 장치이다. 또한 스토리지은 RAM 나 ROM 등의 메모리일 수 있다. 입출력 인터페이스는 컴퓨팅 장치와 입출력 디바이스를 접속하기 위한 인터페이스이다. 예를 들면 입 출력 인터페이스에는 키보드나 마우스 등이 접속된다. 네트워크 인터페이스는 컴퓨팅 장치를 외부 장치와 통신 가능하게 접속하여 전송 패킷을 송수신하기 위한 인터페이스이다. 네트워크 인터페이스는 유선 회선과 접속하기 위한 네트워크 인터페이스라도 좋고 무선 회선과 접속하기 위한 네트워크 인터페이스라도 좋다. 예를 들면, 컴퓨팅 장치는 네트워크를 통 해 다른 컴퓨팅 장치(300-1)와 접속될 수 있다. 스토리지는 컴퓨팅 장치의 각 기능을 구현하는 프로그램 모듈을 기억하고 있다. 프로세서는 이 들 각 프로그램 모듈을 실행함으로써, 그 프로그램 모듈에 대응하는 각 기능을 구현한다. 여기서 프로세서(33 0)는 상기 각 모듈을 실행할 때, 이 모듈들을 메모리 상으로 읽어낸 후 실행할 수 있다. 다만, 컴퓨팅 장치의 하드웨어 구성은 도 9에 나타낸 구성으로 제한되지 않는다. 예를 들면 각 프로그램 모듈은 메모리에 저장되어도 좋다. 이 경우, 컴퓨팅 장치는 스토리지를 구비하지 않아도 된다. 이와 같이, 카메라 장치는 적어도, 프로세서와 상기 프로세서에 의해 실행 가능한 인스트럭션들 (instructions)을 저장하는 메모리를 포함한다. 특히, 도 2 및 도 8의 장치들(100, 200)은 포함된 다양한 기능 블록들 내지 단계들을 포함하는 인스트럭션들이 상기 프로세서에 의해 수행됨으로써 동작된다."}
{"patent_id": "10-2022-0085039", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상 첨부된 도면을 참조하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있 다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적 이 아닌 것으로 이해해야 한다.도면 도면1 도면2 도면3 도면4 도면5a 도면5b 도면5c 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2022-0085039", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명을 구현하는 전체 시스템 환경을 도시한 도면이다. 도 2는 본 발명의 일 실시예에 따른 디포커스 학습 장치의 구성을 도시한 블록도이다. 도 3은 포커스 값이 가장 큰 최적 포커스 위치를 찾는 과정을 보여주는 도면이다. 도 4는 카메라에서 포커스 값과 포커스 위치의 상관 관계를 예시하는 도면이다. 도 5a 내지 도 5c는 각각 도 4의 A, B 및 C 위치에서 촬영된 이미지를 도시한 도면들이다. 도 6은 도 2의 AI 러닝부의 보다 자세한 구성을 도시한 블록도이다. 도 7은 도 2의 AI 러닝부가 이용하는 DNN 모델의 예시이다. 도 8은 본 발명의 일 실시예에 따른 카메라 장치의 구성을 도시한 블록도이다. 도 9는 도 2 및 도 8의 장치들을 실현하는 컴퓨팅 장치의 하드웨어 구성을 예시하는 도면이다."}
