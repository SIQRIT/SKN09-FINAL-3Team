{"patent_id": "10-2021-0182784", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0002823", "출원번호": "10-2021-0182784", "발명의 명칭": "딥러닝 프레임워크에서의 연산자의 배치 방법, 장치 및 전자 기기", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "쟝, 리우제"}}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "딥러닝 프레임워크에서의 연산자의 배치 방법에 있어서, 연산자의 소스 파일을 획득하는 단계;상기 연산자의 소스 파일을 편역하여 상기 연산자의 동적 링크 라이브러리를 형성하는 단계;상기 연산자의 동적 링크 라이브러리의 인터페이스 파일을 생성하는 단계;상기 동적 링크 라이브러리 및 상기 인터페이스 파일에 따라 설치 가능한 라이브러리 파일을 생성하는 단계; 및상기 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치하는 단계; 를 포함하는,것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 방법."}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 연산자의 소스 파일을 편역하여 상기 연산자의 동적 링크 라이브러리를 형성하는 단계는, 상기 연산자의 소스 파일에 대해 헤더 파일 확장 및 매크로 대체를 수행하여 편역할 코드를 생성하는 단계;상기 편역할 코드를 어셈블리 코드로 편역하고, 상기 어셈블리 코드를 한 줄씩 바이트 코드로 변환하여 타겟 파일을 생성하는 단계; 및 상기 타겟 파일을 링크 조작하여 링크된 타겟 파일을 획득하고, 상기 링크된 타겟 파일에 따라 상기 동적 링크라이브러리를 생성하는 단계; 를 포함하는,것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 방법."}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 동적 링크 라이브러리 및 상기 인터페이스 파일에 따라 설치 가능한 라이브러리 파일을 생성하는 단계는, 사전 설정된 패키징 전략에 따라 상기 동적 링크 라이브러리 및 상기 인터페이스 파일을 패키징하여 상기 설치가능한 라이브러리 파일을 생성하는 단계를 포함하는,것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 방법."}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치하는 단계는, 상기 설치 가능한 라이브러리 파일을 상기 타겟 프로그래밍 언어 라이브러리의 타겟 목록에 설치하는 단계를 포함하는,것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 방법."}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 타겟 연산자의 임포트 어구를 획득하는 단계 - 상기 임포트 어구는 상기 타겟 연산자의 설치 가능한 라이브러리파일이 위치한 프로그래밍 언어 라이브러리에 대응되는 정보를 휴대함 -;공개특허 10-2022-0002823-3-상기 임포트 어구를 해석하여 상기 타겟 연산자의 설치 가능한 라이브러리 파일이 위치한 타겟 서브목록을 결정하는 단계; 및 상기 타겟 서브목록에서 상기 타겟 연산자의 설치 가능한 라이브러리 파일을 읽고 임포트하는 단계; 를 더 포함하는,것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 방법."}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 동적 링크 라이브러리에 대응되는 주입할 함수 코드를 획득하는 단계;상기 주입할 함수 코드를 입구 파일에 주입하여 상기 동적 링크 라이브러리의 타겟 호출 함수 코드를 생성하는단계; 및 상기 타겟 호출 함수 코드를 상기 인터페이스 파일에 쓰는 단계; 를 더 포함하는,것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 방법."}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 주입할 함수 코드를 입구 파일에 주입하여 상기 동적 링크 라이브러리의 타겟 호출 함수 코드를 생성하는단계는,상기 입구 파일로부터 상기 동적 링크 라이브러리의 묵인 호출 함수 코드를 획득하는 단계; 및상기 묵인 호출 함수 코드를 상기 주입할 함수 코드로 대체하여 상기 동적 링크 라이브러리의 타겟 호출 함수코드를 생성하는 단계; 를 포함하는,것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 방법."}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "딥러닝 프레임워크에서의 연산자의 배치 장치에 있어서, 연산자의 소스 파일을 획득하는 제1 획득 모듈;상기 연산자의 소스 파일을 편역하여 상기 연산자의 동적 링크 라이브러리를 형성하는 형성 모듈;상기 연산자의 동적 링크 라이브러리의 인터페이스 파일을 생성하는 제1 생성 모듈;상기 동적 링크 라이브러리 및 상기 인터페이스 파일에 따라 설치 가능한 라이브러리 파일을 생성하는 제2 생성모듈; 및상기 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치하는 설치 모듈; 을 포함하는,것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 장치."}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 형성 모듈은, 상기 연산자의 소스 파일에 대해 헤더 파일 확장 및 매크로 대체를 수행하여 편역할 코드를 생성하는 제1 생성서브모듈;상기 편역할 코드를 어셈블리 코드로 편역하고, 상기 어셈블리 코드를 한 줄씩 바이트 코드로 변환하여 타겟 파일을 생성하는 제2 생성 서브모듈; 및 상기 타겟 파일을 링크 조작하여 링크된 타겟 파일을 획득하고, 상기 링크된 타겟 파일에 따라 상기 동적 링크공개특허 10-2022-0002823-4-라이브러리를 생성하는 제3 생성 서브모듈; 을 포함하는,것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 장치."}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 상기 제2 생성 모듈은, 사전 설정된 패키징 전략에 따라 상기 동적 링크 라이브러리 및 상기 인터페이스 파일을 패키징하여 상기 설치가능한 라이브러리 파일을 생성하는 제4 생성 서브모듈을 포함하는,것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 장치."}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 상기 설치 모듈은, 상기 설치 가능한 라이브러리 파일을 상기 타겟 프로그래밍 언어 라이브러리의 타겟 목록에 설치하는 제1 설치서브모듈을 포함하는,것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 장치."}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서, 타겟 연산자의 임포트 어구를 획득하는 제2 획득 모듈 - 상기 임포트 어구는 상기 타겟 연산자의 설치 가능한라이브러리 파일이 위치한 프로그래밍 언어 라이브러리에 대응되는 정보를 휴대함 -;상기 임포트 어구를 해석하여 상기 타겟 연산자의 설치 가능한 라이브러리 파일이 위치한 타겟 서브목록을 결정하는 결정 모듈; 및 상기 타겟 서브목록에서 상기 타겟 연산자의 설치 가능한 라이브러리 파일을 읽고 임포트하는 임포트 모듈; 을더 포함하는,것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 장치."}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서, 상기 동적 링크 라이브러리에 대응되는 주입할 함수 코드를 획득하는 제3 획득 모듈;상기 주입할 함수 코드를 입구 파일에 주입하여 상기 동적 링크 라이브러리의 타겟 호출 함수 코드를 생성하는주입 모듈; 및 상기 타겟 호출 함수 코드를 상기 인터페이스 파일에 쓰는 쓰기 모듈; 을 더 포함하는,것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 장치."}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 쓰기 모듈은,상기 입구 파일로부터 상기 동적 링크 라이브러리의 묵인 호출 함수 코드를 획득하는 제1 획득 서브모듈; 및상기 묵인 호출 함수 코드를 상기 주입할 함수 코드로 대체하여 상기 동적 링크 라이브러리의 타겟 호출 함수코드를 생성하는 제5 생성 서브모듈; 을 포함하는,것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 장치.공개특허 10-2022-0002823-5-청구항 15 전자 기기에 있어서, 프로세서 및 메모리를 포함하고; 상기 프로세서는 상기 메모리에 저장된 수행 가능한 프로그램 코드를 읽어 상기 수행 가능한 프로그램 코드에대응되는 프로그램을 수행하여, 제1항 내지 제7항 중 어느 한 항에 따른 딥러닝 프레임워크에서의 연산자의 배치 방법을 구현하는,것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "컴퓨터 프로그램이 저장되어 있는 컴퓨터 판독 가능 저장 매체에 있어서,상기 컴퓨터 프로그램이 프로세서에 의해 수행될 경우, 제1항 내지 제7항 중 어느 한 항에 따른 딥러닝 프레임워크에서의 연산자의 배치 방법이 구현되는,것을 특징으로 하는 컴퓨터 프로그램이 저장되어 있는 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2021-0182784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램중의 명령이 실행될 경우, 제1항 내지 제7항 중 어느 한 항에 따른 딥러닝 프레임워크에서의 연산자의 배치 방법이 구현되는,것을 특징으로 하는 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2021-0182784", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 딥러닝 프레임워크에서의 연산자의 배치 방법, 장치 및 전자 기기를 개시하고, 딥러닝 등 인공지능"}
{"patent_id": "10-2021-0182784", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것이다. 구체적인 구현 수단은 연산자의 소스 파일을 획득하는 단계; 상기 연산자의 소스 파일을 편역하여 상기 연산자의 동적 링크 라이브러리를 형성하는 단계; 상기 연산자의 동적 링크 라이브러리 전환의 인 터페이스 파일을 생성하는 단계; 상기 동적 링크 라이브러리 및 상기 인터페이스 파일에 따라 설치 가능한 라이 브러리 파일을 생성하는 단계; 및 상기 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치 하는 단계를 포함하고, 연산자 설치의 모든 과정을 완전히 은닉할 수 있으며, 사용자의 러닝 비용을 크게 저감할 수 있는 동시에, 딥러닝 프레임워크에서의 연산자의 배치 과정의 효율성, 융통성 및 신뢰성을 향상시킬 수 있다. 대 표 도 - 도1"}
{"patent_id": "10-2021-0182784", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2022-0002823 CPC특허분류 G06F 8/54 (2013.01) 발명자 쩡, 후이황 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 1 0번가, 10, 바이두 캠퍼스 2층 리우, 홍위 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 1 0번가, 10, 바이두 캠퍼스 2층 저우, 웨이 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 1 0번가, 10, 바이두 캠퍼스 2층마, 옌쥔 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 1 0번가, 10, 바이두 캠퍼스 2층 위, 디엔하이 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 1 0번가, 10, 바이두 캠퍼스 2층 왕, 하이펑 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 1 0번가, 10, 바이두 캠퍼스 2층명 세 서 청구범위 청구항 1 딥러닝 프레임워크에서의 연산자의 배치 방법에 있어서, 연산자의 소스 파일을 획득하는 단계; 상기 연산자의 소스 파일을 편역하여 상기 연산자의 동적 링크 라이브러리를 형성하는 단계; 상기 연산자의 동적 링크 라이브러리의 인터페이스 파일을 생성하는 단계; 상기 동적 링크 라이브러리 및 상기 인터페이스 파일에 따라 설치 가능한 라이브러리 파일을 생성하는 단계; 및 상기 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치하는 단계; 를 포함하는, 것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 방법. 청구항 2 제1항에 있어서, 상기 연산자의 소스 파일을 편역하여 상기 연산자의 동적 링크 라이브러리를 형성하는 단계는, 상기 연산자의 소스 파일에 대해 헤더 파일 확장 및 매크로 대체를 수행하여 편역할 코드를 생성하는 단계; 상기 편역할 코드를 어셈블리 코드로 편역하고, 상기 어셈블리 코드를 한 줄씩 바이트 코드로 변환하여 타겟 파 일을 생성하는 단계; 및 상기 타겟 파일을 링크 조작하여 링크된 타겟 파일을 획득하고, 상기 링크된 타겟 파일에 따라 상기 동적 링크 라이브러리를 생성하는 단계; 를 포함하는, 것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 방법. 청구항 3 제1항에 있어서, 상기 동적 링크 라이브러리 및 상기 인터페이스 파일에 따라 설치 가능한 라이브러리 파일을 생성하는 단계는, 사전 설정된 패키징 전략에 따라 상기 동적 링크 라이브러리 및 상기 인터페이스 파일을 패키징하여 상기 설치 가능한 라이브러리 파일을 생성하는 단계를 포함하는, 것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 방법. 청구항 4 제1항에 있어서, 상기 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치하는 단계는, 상기 설치 가능한 라이브러리 파일을 상기 타겟 프로그래밍 언어 라이브러리의 타겟 목록에 설치하는 단계를 포 함하는, 것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 방법. 청구항 5 제1항에 있어서, 타겟 연산자의 임포트 어구를 획득하는 단계 - 상기 임포트 어구는 상기 타겟 연산자의 설치 가능한 라이브러리 파일이 위치한 프로그래밍 언어 라이브러리에 대응되는 정보를 휴대함 -;상기 임포트 어구를 해석하여 상기 타겟 연산자의 설치 가능한 라이브러리 파일이 위치한 타겟 서브목록을 결정 하는 단계; 및 상기 타겟 서브목록에서 상기 타겟 연산자의 설치 가능한 라이브러리 파일을 읽고 임포트하는 단계; 를 더 포함 하는, 것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 방법. 청구항 6 제1항에 있어서, 상기 동적 링크 라이브러리에 대응되는 주입할 함수 코드를 획득하는 단계; 상기 주입할 함수 코드를 입구 파일에 주입하여 상기 동적 링크 라이브러리의 타겟 호출 함수 코드를 생성하는 단계; 및 상기 타겟 호출 함수 코드를 상기 인터페이스 파일에 쓰는 단계; 를 더 포함하는, 것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 방법. 청구항 7 제6항에 있어서, 상기 주입할 함수 코드를 입구 파일에 주입하여 상기 동적 링크 라이브러리의 타겟 호출 함수 코드를 생성하는 단계는, 상기 입구 파일로부터 상기 동적 링크 라이브러리의 묵인 호출 함수 코드를 획득하는 단계; 및 상기 묵인 호출 함수 코드를 상기 주입할 함수 코드로 대체하여 상기 동적 링크 라이브러리의 타겟 호출 함수 코드를 생성하는 단계; 를 포함하는, 것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 방법. 청구항 8 딥러닝 프레임워크에서의 연산자의 배치 장치에 있어서, 연산자의 소스 파일을 획득하는 제1 획득 모듈; 상기 연산자의 소스 파일을 편역하여 상기 연산자의 동적 링크 라이브러리를 형성하는 형성 모듈; 상기 연산자의 동적 링크 라이브러리의 인터페이스 파일을 생성하는 제1 생성 모듈; 상기 동적 링크 라이브러리 및 상기 인터페이스 파일에 따라 설치 가능한 라이브러리 파일을 생성하는 제2 생성 모듈; 및 상기 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치하는 설치 모듈; 을 포함하는, 것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 장치. 청구항 9 제8항에 있어서, 상기 형성 모듈은, 상기 연산자의 소스 파일에 대해 헤더 파일 확장 및 매크로 대체를 수행하여 편역할 코드를 생성하는 제1 생성 서브모듈; 상기 편역할 코드를 어셈블리 코드로 편역하고, 상기 어셈블리 코드를 한 줄씩 바이트 코드로 변환하여 타겟 파 일을 생성하는 제2 생성 서브모듈; 및 상기 타겟 파일을 링크 조작하여 링크된 타겟 파일을 획득하고, 상기 링크된 타겟 파일에 따라 상기 동적 링크라이브러리를 생성하는 제3 생성 서브모듈; 을 포함하는, 것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 장치. 청구항 10 제8항에 있어서, 상기 제2 생성 모듈은, 사전 설정된 패키징 전략에 따라 상기 동적 링크 라이브러리 및 상기 인터페이스 파일을 패키징하여 상기 설치 가능한 라이브러리 파일을 생성하는 제4 생성 서브모듈을 포함하는, 것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 장치. 청구항 11 제8항에 있어서, 상기 설치 모듈은, 상기 설치 가능한 라이브러리 파일을 상기 타겟 프로그래밍 언어 라이브러리의 타겟 목록에 설치하는 제1 설치 서브모듈을 포함하는, 것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 장치. 청구항 12 제8항에 있어서, 타겟 연산자의 임포트 어구를 획득하는 제2 획득 모듈 - 상기 임포트 어구는 상기 타겟 연산자의 설치 가능한 라이브러리 파일이 위치한 프로그래밍 언어 라이브러리에 대응되는 정보를 휴대함 -; 상기 임포트 어구를 해석하여 상기 타겟 연산자의 설치 가능한 라이브러리 파일이 위치한 타겟 서브목록을 결정 하는 결정 모듈; 및 상기 타겟 서브목록에서 상기 타겟 연산자의 설치 가능한 라이브러리 파일을 읽고 임포트하는 임포트 모듈; 을 더 포함하는, 것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 장치. 청구항 13 제8항에 있어서, 상기 동적 링크 라이브러리에 대응되는 주입할 함수 코드를 획득하는 제3 획득 모듈; 상기 주입할 함수 코드를 입구 파일에 주입하여 상기 동적 링크 라이브러리의 타겟 호출 함수 코드를 생성하는 주입 모듈; 및 상기 타겟 호출 함수 코드를 상기 인터페이스 파일에 쓰는 쓰기 모듈; 을 더 포함하는, 것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 장치. 청구항 14 제13항에 있어서, 상기 쓰기 모듈은, 상기 입구 파일로부터 상기 동적 링크 라이브러리의 묵인 호출 함수 코드를 획득하는 제1 획득 서브모듈; 및 상기 묵인 호출 함수 코드를 상기 주입할 함수 코드로 대체하여 상기 동적 링크 라이브러리의 타겟 호출 함수 코드를 생성하는 제5 생성 서브모듈; 을 포함하는, 것을 특징으로 하는 딥러닝 프레임워크에서의 연산자의 배치 장치.청구항 15 전자 기기에 있어서, 프로세서 및 메모리를 포함하고; 상기 프로세서는 상기 메모리에 저장된 수행 가능한 프로그램 코드를 읽어 상기 수행 가능한 프로그램 코드에 대응되는 프로그램을 수행하여, 제1항 내지 제7항 중 어느 한 항에 따른 딥러닝 프레임워크에서의 연산자의 배 치 방법을 구현하는, 것을 특징으로 하는 전자 기기. 청구항 16 컴퓨터 프로그램이 저장되어 있는 컴퓨터 판독 가능 저장 매체에 있어서, 상기 컴퓨터 프로그램이 프로세서에 의해 수행될 경우, 제1항 내지 제7항 중 어느 한 항에 따른 딥러닝 프레임 워크에서의 연산자의 배치 방법이 구현되는, 것을 특징으로 하는 컴퓨터 프로그램이 저장되어 있는 컴퓨터 판독 가능 저장 매체. 청구항 17 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램중의 명령이 실행될 경우, 제1항 내지 제7항 중 어느 한 항에 따른 딥러닝 프레임워크에서 의 연산자의 배치 방법이 구현되는, 것을 특징으로 하는 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램. 발명의 설명 기 술 분 야 본 출원의 실시예는 총체적으로 데이터 처리 기술 분야에 관한 것으로, 더 구체적으로 딥러닝 등 인공지능 기술 분야에 관한 것이다."}
{"patent_id": "10-2021-0182784", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재 주요 추세의 딥러닝 프레임워크는 연산자라고 통칭하는 풍부한 텐서 계산 처리 유닛을 포함하며, 풍부한 연산자 라이브러리는 딥러닝 모델을 빠르게 구축하기 위해 강력한 기본 도구를 제공하지만 딥러닝 프레임워크의 연산자 라이브러리는 일반적으로 완전성을 달성할 수 없고, 특히 프론티어 학술 연구 분야에서 현재 연산자 라 이브러리가 특정 논리 계산 조작을 만족할 수 없는 상황이 종종 있다. 따라서 주요한 딥러닝 프레임워크는 모두 사용자에게 자체 정의 연산자의 메커니즘을 제공한다. 자체 정의 연산자는 대부분 C++ 언어(The C++ Programming Language/c plus plus)로 구현되어, 소스 코드 편역 을 단독으로 수행해야 하고, 동적 라이브러리로 링크한 다음 프런트엔드에 로딩 및 임포트되어 사용된다. 이를 위해, 사용자는 당해 프레임워크에 대해 어느 정도 이해해야 할 뿐만 아니라 C++ 소스 코드 편역에 대한 기본 지식도 구비해야한다. GPU(Graphics Processing Unit, 그래픽 프로세서) 기기를 지원하는 연산자의 구현과 관련 될 경우, 사용자는 CUDA(Compute Unified Device Architecture, 통합 계산 기기 아키텍쳐) 편역에 대한 배경 지식도 이해해야 한다. 그 결과, 불가피하게 극도로 높은 사용자 사용 비용, 타사 라이브러리(예컨대, 라이브러 리 pybind11)에 대한 강력한 의존성, 융통성 부족, 낮은 효율성과 같은 기술적 문제를 야기한다. 따라서, 딥러 닝 프레임워크에서의 연산자의 배치 과정의 효율성, 융통성 및 디커플링 성능을 개선하고 사용자 사용 비용을 줄이는 방법이 중요한 연구 방향 중의 하나가 됐다. 본 출원은 딥러닝 프레임워크에서의 연산자의 배치 방법, 장치 및 전자 기기를 제공한다. 제1 측면에 따라 제공되는 딥러닝 프레임워크에서의 연산자의 배치 방법은, 연산자의 소스 파일을 획득하는 단계; 상기 연산자의 소스 파일을 편역하여 상기 연산자의 동적 링크 라이브러리를 형성하는 단계; 상기 연산자의 동적 링크 라이브러리의 인터페이스 파일을 생성하는 단계; 상기 동적 링크 라이브러리 및 상기 인터페이스 파일에 따라 설치 가능한 라이브러리 파일을 생성하는 단계; 및 상기 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치하는 단계; 를 포함한다. 제2 측면에 따라 제공되는 딥러닝 프레임워크에서의 연산자의 배치 장치는, 연산자의 소스 파일을 획득하는 제1 획득 모듈; 상기 연산자의 소스 파일을 편역하여 상기 연산자의 동적 링크 라이브러리를 형성하는 형성 모듈; 상기 연산자의 동적 링크 라이브러리의 인터페이스 파일을 생성하는 제1 생성 모듈; 상기 동적 링크 라이브러리 및 상기 인터페이스 파일에 따라 설치 가능한 라이브러리 파일을 생성하는 제2 생성 모듈; 및 상기 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치하는 설치 모듈; 을 포함한다. 제3 측면에 따라 제공되는 전자 기기는, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 가능 하게 연결되는 메모리를 포함하고; 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 수행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 수행되어, 상기 적어도 하나의 프로세서가 본 출원의 제1 측면에 따른 상기 딥러닝 프레임워크에서의 연산자의 배치 방법을 수행하도록 한다. 제4 측면에 따라 제공되는 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체에 있어서, 상기 컴퓨터 명령이 실행될 경우 본 출원의 제1 측면에 따른 상기 딥러닝 프레임워크에서의 연산자의 배치 방법이 수 행된다. 제5 측면에 따라 제공되는 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로 그램중의 명령이 실행될 경우, 본 출원의 제1 측면에 따른 상기 딥러닝 프레임워크에서의 연산자의 배치 방법이 수행된다. 이해 가능한 바로는 본 부분에서 설명된 내용은 본 출원의 실시예의 핵심 또는 중요한 특징을 식별하기 위한 것 이 아니며, 본 출원의 범위를 한정하지도 않는다. 본 출원의 기타 특징들은 하기의 명세서에 의해 쉽게 이해될 것이다."}
{"patent_id": "10-2021-0182784", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 결합하여 본 출원의 예시적인 실시예에 대해 설명하며, 여기에는 이해를 돕기 위해 본 출 원의 실시예의 다양한 세부 사항을 포함하므로, 이는 단지 예시적인 것으로 이해해야 한다. 따라서, 당업자는 본 출원의 범위 및 사상을 벗어나지 않는 한 여기에 설명된 실시예에 대해 다양한 변경 및 수정이 이루어질 수 있음을 인식해야 한다. 마찬가지로, 명확성과 간결성을 위해, 하기의 설명에서는 공지된 기능 및 구조에 대한 설명을 생략한다. 이하, 본 출원의 수단에 언급된 기술 분야에 대해 간단히 설명한다. 데이터 처리(Data Processing)는 데이터에 대한 수집, 저장, 검색, 처리, 변경 및 전송 등 처리를 포함하며, 목 적은 무질서하고 이해할 수 없는 대량의 데이터로부터 특정 사용자에게 가치 있고 의미 있는 데이터를 추출하고 도출하는 것이다. AI(Artificial Intelligence, 인공지능)은 인간의 특정 사유 과정 및 지능 행위(예컨대, 러닝, 추리, 사고, 계 획 등)를 컴퓨터로 시뮬레이션하기 위해 연구하는 학과이며, 하드웨어 층면의 기술 뿐만 아니라 소프트웨어 층 면의 기술도 포함한다. 인공지능 하드웨어 기술은 일반적으로 컴퓨터 시각 기술, 음성 인식 기술, 자연 언어 처 리 기술 및 기계 러닝/딥러닝, 빅데이터 처리 기술, 지식 그래프 기술 등 몇 가지 주요 방향을 포함한다. DL(Deep Learning, 딥러닝)은 ML(Machine Learning, 기계 러닝) 분야의 새로운 연구 방향이며, 기계 러닝에 인 입되어 기계 러닝을 최초의 타겟 - 인공지능에 더 가까워지도록 한다. 딥러닝은 샘플 데이터의 내재적 법칙 및 표현 계층을 러닝하는 것이며, 이러한 러닝 과정에서 획득된 정보는 문자, 이미지 및 소리 등과 같은 데이터의 해석에 대해 큰 도움이 된다. 딥러닝의 최종 타겟은 기계로 하여금 인간과 같은 분석 러닝 능력을 구비할 수 있 고, 문자, 이미지 및 소리 등과 같은 데이터를 인식할 수 있도록 한다. 딥러닝은 복잡한 기계 러닝 알고리즘이 며, 음성 및 이미지 인식 측면에서 달성한 효과는 기존의 관련 기술을 훨씬 초과한다. 설명해야 하는 바로는, 관련 기술에서 자체 정의 연산자 기능을 지원하는 딥러닝 프레임워크에 대하여 편역 설 치의 구현에서 다르며, 주로 setup.py(파일 편집)를 기반하는 방식 및 JIT(Just-In-Time, 즉시 편역)의 프런트 엔드 로드(load) 인터페이스를 기반하는 방식의 두가지 방식을 포함한다. 여기서, setup.py를 기반하는 방식에 대하여, Pytorch 프레임워크를 예로 들어, 프런트엔드 언어 python의 setuptools 라이브러리에 의하여 사용자가 설치(install) 명령 편역을 수행하도록 지원하고, 자체 정의 연산자 라이브러리를 생성하여 사용자가 임포트(import)하여 사용하도록 지원한다. 하지만, 이러한 상황하에서 자체 정의 연산자는 Pybind11 모듈을 의존해야 하고, 사용자가 미리 설치해야 하며, 자체 정의 연산자는 Pybind11과 명시적으로 바인딩되어야 하며, 그렇지 않으면 프런트엔드에 노출되어 사용될 수 없다. 여기서, JIT의 프런트엔드 load 인터페이스를 기반하는 방식에 대하여, 인터페이스 최하위 계층은 CMake, Ninja 와 같은 타사 도구에 의존하여, 사용자가 미리 설치해야 한다. 따라서, 본 출원은 딥러닝 프레임워크에서의 연산자의 배치 방법을 제공하여, 더는 Pybind11 및 기타 타사 모듈 에 의존하지 않고, setuptools를 고도로 캡슐화하고, 편역, 링크, 설치의 모든 과정을 완전히 은닉하여, 사용자 는 의존하는 프레임워크 최하위 계층 링크 라이브러리, 편역 옵션 등 개념적 지식을 이해할 필요가 없다. 더 나 아가, 코드 주입 원리에 의하여 융통성 있는 자체 정의 python 라이브러리 설치 파일의 생성 방식을 지원하여 사용자의 러닝 비용을 크게 줄이는 동시에 딥러닝 프레임워크에서의 연산자의 배치 과정의 효율성, 융통성 및 신뢰성을 향상시킨다. 이하, 첨부된 도면을 참조하여 본 출원의 실시예에서 제공되는 딥러닝 프레임워크에서의 연산자의 배치 방법, 장치 및 전자 기기를 설명한다. 도1은 본 출원의 제1 실시예에 따른 개략도이다. 여기서, 설명해야 하는 바로는, 본 실시예의 딥러닝 프레임워 크에서의 연산자의 배치 방법의 수행 주체는 딥러닝 프레임워크에서의 연산자의 배치 장치이며, 구체적으로 하 드웨어 기기 또는 하드웨어 기기 중의 소프트웨어 등일 수 있다. 여기서, 하드웨어 기기는 예컨대 단말 기기, 서버 등이다. 도1에 도시된 바와 같이, 본 실시예에서 제공되는 딥러닝 프레임워크에서의 연산자의 배치 방법은 단계S101 내지 단계S105를 포함한다. S101, 연산자의 소스 파일을 획득한다. 설명해야 하는 바로는, 현재 주요 추세의 딥러닝 프레임워크는 연산자라고 통칭하는 풍부한 텐서 계산 처리 유 닛을 포함하며, 예컨대 시각 분야의 컨볼루션 Conv2D 연산자, 자연 언어 처리 분야의 LSTM(Long Short-Term Memory, 장단기 기억 인공 신경망) 연산자, 및 기초적인 함수 활성화 ReLU(Rectified Linear Unit, 선형 정류 함수) 연산자 등이다. 여기서, 연산자의 소스 파일은 사용자가 편역할 자체 정의 연산자(Operator, 약어 OP)에 대응되는 CPP/C++ 언어 (The C++ Programming Language/c plus plus), 또는 CUDA(Compute Unified Device Architecture, 통합 계산 기기 아키텍쳐) 소스 코드 파일일 수 있다. 설명해야 하는 바로는, CPP 파일은 일반적으로 .cc 또는 .cpp로 끝나며; GPU(Graphics Processing Unit, 그래 픽 처리 유닛) 기기를 지원하려면 .cu로 끝나는 CUDA 소스 코드 파일이 필요하다. S102, 연산자의 소스 파일을 편역하여 연산자의 동적 링크 라이브러리를 형성한다. 설명해야 하는 바로는, 딥러닝 프레임워크는 일반적으로 프런트엔드 시스템(Python) 및 백엔드 시스템(C++)에 관련되여해야 한다. 사용자 자체 정의 연산자는 백엔드 C++ 코드를 편집한다. 이러한 상황하에서, 프런트엔드 Python에 의해 호출될 수 있도록 이를 특정 격식의 파일로 편역해야하고, Python 프런트엔드 시스템에서 메모리 에 로딩되고, C++ 백엔드 시스템에서 구현되는 연산자 계산 논리 함수(예컨대, 컨볼루션 Conv)로 호출되도록 한 다. 예를 들어, 사용자 고유의 편역 명령(즉 연산자의 소스 파일) 예컨대 Linux(전체 이름 GNU/Linux) 시스템의 gcc/g++/nvcc 명령을 호출한 후, 연산자의 동적 링크 라이브러리를 편역하여 생성할 수 있다. 본 출원의 실시예에서, 처리 대상은 C++ 또는 CUDA 소스 코드 파일이며, 전처리(Pre-processing), 편역, 어셈블 리 및 링크(Linking)를 통해 연산자의 소스 파일을 편역할 수 있고, 연산자의 동적 링크 라이브러리를 형성할 수 있다. S103, 연산자의 동적 링크 라이브러리의 인터페이스 파일을 생성한다. 설명해야 하는 바로는, 관련 기술에서 딥러닝 프레임워크는 모두 프런트엔드 시스템 및 백엔드 시스템을 포함한 다. 여기서, 백엔드 시스템은 대부분 C++ 언어로 구현되는데, 여기에는 많은 연산자의 구체적인 논리 연산을 포 함하는 바, 예를 들어 컨볼루션 조작 Conv의 실제 데이터 연산 조작은 C++를 통해 구현된 것이다. 이러한 상황 하에서, 장점은 높은 연산 효율성 및 우수한 수행 성능에 있고; 프런트엔드 시스템은 대부분 Python 언어로 구 현되고, 간단한 API(Application Programming Interface, 응용프로그램 작성 인터페이스) 인터페이스를 패키징 하여 백엔드 연산자 Kernel에 대한 호출을 구현하도록 한다. 이러한 상황하에서, 장점은 낮은 구현 비용 및 좋 은 사용자 체험에 있다. 본 출원의 실시예에서, 사용자가 백엔드 시스템에 대해 편집한 자체 정의 연산자에 대응되는 C++ 언어의 연산 관련 코드에만 따르면, 프런트엔드 시스템의 API 인터페이스는 자동으로 생성될 수 있으며, 즉 연산자의 동적 링크 라이브러리의 인터페이스 파일은 자동으로 생성될 수 있다. S104, 동적 링크 라이브러리 및 인터페이스 파일에 따라 설치 가능한 라이브러리 파일을 생성한다. 여기서, 설치 가능한 라이브러리 파일은 파일 확장자가 .egg인 파일일 수 있다. 파일 확장자가 .egg인 파일은 Python 프로그래밍 언어가 타사 설치 가능한 라이브러리를 관리하기 위한 파일 격식이다. 본 출원의 실시예에서, 사전 설정된 패키징 전략에 따라 동적 링크 라이브러리 및 인터페이스 파일을 패키징하 여 설치 가능한 라이브러리 파일을 생성하도록 한다. S105, 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치한다. 설명해야 하는 바로는, 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치한 다음, 사용 자 자체 정의 연산자를 타겟 프로그래밍 언어 라이브러리에 바로 설치할 수 있으며 사용자 후속 호출을 지원하 도록 한다. 본 출원의 실시예에서, 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리의 타겟 목록에 설치할 수 있다. 본 출원의 실시예의 딥러닝 프레임워크에서의 연산자의 배치 방법에 따르면, 연산자의 소스 파일을 획득할 수 있고, 연산자의 소스 파일을 편역하여 연산자의 동적 링크 라이브러리를 형성하고, 연산자의 동적 링크 라이브러리의 인터페이스 파일을 생성한 다음, 동적 링크 라이브러리 및 인터페이스 파일에 따라 설치 가능한 라이브 러리 파일을 생성하고, 더 나아가 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치함으 로써, 딥러닝 프레임워크에서의 연산자의 배치를 구현하여, 더는 타사 모듈에 의존하지 않고, 연산자 설치의 모 든 과정을 완전히 은닉할 수 있으며, 사용자의 러닝 비용을 크게 저감할 수 있는 동시에, 딥러닝 프레임워크에 서의 연산자의 배치 과정의 효율성, 융통성 및 신뢰성을 향상시킬 수 있다. 설명해야 하는 바로는, 본 출원에서, 연산자의 소스 파일을 편역하여 연산자의 동적 링크 라이브러리를 형성하 도록 시도할 때, 전처리, 편역, 어셈블리 및 링크를 통해 연산자의 소스 파일을 편역할 수 있다. 도2는 본 출원의 제2 실시예에 따른 개략도이다. 도2에 도시된 바와 같이, 상기 실시예를 기반하여 본 실시예에 서 제공되는 딥러닝 프레임워크에서의 연산자의 배치 방법은 단계S201 내지 단계S207을 포함한다. S201, 연산자의 소스 파일을 획득한다. 당해 단계 S201은 상기 실시예의 단계 S101과 같으므로, 여기서 더 이상 설명하지 않는다. 상기 실시예의 단계 S102는 구체적으로 하기 단계 S202~S204를 포함할 수 있다. S202, 연산자의 소스 파일에 대해 헤더 파일 확장 및 매크로 대체를 수행하여 편역할 코드를 생성하도록 한다. 본 출원의 실시예에서, 전처리 조작을 통해 편역할 코드를 생성할 수 있다. 선택적으로, 전처리기를 사용하여 소스 파일에서 \"#\"으로 시작하는 코드 행에 대해 헤더 파일 확장 및 매크로 대체를 수행하여 편역할 코드를 생성할 수 있다. 여기서, 파라미터를 텍스트에 대체할 수 있으며 이러한 구현은 일반적으로 정의 매크로 또는 매크로 대체, 약어 매크로라고 한다. S203, 편역할 코드를 어셈블리 코드로 편역하고, 어셈블리 코드를 한 줄씩 바이트 코드로 변환하여 타겟 파일을 생성하도록 한다. 본 출원의 실시예에서, 전처리에 의해 생성된 편역할 코드를 편역 및 어셈블리하여 타겟 파일(Object File)을 생성할 수 있다. 여기서, 타겟 파일은 수행 가능한 파일 또는 라이브러리 파일(예컨대, 정적 라이브러리 또는 동적 라이브러리)일 수 있다. 선택적으로, 편역 단계에 대하여 편역할 코드를 최하위 계층 어셈블리 코드로 편역할 수 있다. 더 나아가, 어셈블리 단계에 대하여 어셈블리 기기를 사용하여 어셈블리 코드를 한 줄씩 바이트 코드(즉, 기계 코드)로 변환하여 타겟 파일을 생성할 수 있다. S204, 타겟 파일을 링크 조작하여 링크된 타겟 파일을 획득하고, 링크된 타겟 파일에 따라 동적 링크 라이브러 리를 생성한다. 본 출원의 실시예에서, 타겟 파일을 연결하여 동적 링크 라이브러리를 생성할 수 있다. 선택적으로, 전술한 과정에서 생성된 타겟 파일을 통합 링크하여 수행 가능한 파일 또는 라이브러리 파일(예컨 대, 정적 라이브러리 또는 동적 라이브러리)을 생성할 수 있다. 설명해야 하는 바로는, 당해 단계에서 정의되지 않은 식별자의 인용은 전부 대응되는 올바른 주소로 대체된다. S205, 연산자의 동적 링크 라이브러리의 인터페이스 파일을 생성한다. 당해 단계 S205는 상기 실시예의 단계 S103과 같으므로, 여기서 더 이상 설명하지 않는다. S206, 동적 링크 라이브러리 및 인터페이스 파일에 따라 설치 가능한 라이브러리 파일을 생성한다. 선택적으로, 사전 설정된 패키징 전략에 따라 동적 링크 라이브러리 및 인터페이스 파일을 패키징하여 설치 가 능한 라이브러리 파일을 생성할 수 있다. 예를 들어 설명하면, 동적 링크 라이브러리 파일 및 Python API 파일을 프런트엔드 설치 가능한 python 라이브 러리 파일로 패키징할 수 있다. 선택적으로, 예컨대 setuptools와 같은 Python 언어의 고유 라이브러리에 의해 install, build, extracting(설치, 구축, 추출) 등 단계를 통해 패키징할 수 있다. 여기서, 전술한 단계는 모두 여러개의 처리 함수로 구성된다. S207, 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치한다. 당해 단계 S207은 상기 실시예의 단계 S105와 같으므로, 여기서 더 이상 설명하지 않는다. 본 출원의 실시예의 딥러닝 프레임워크에서의 연산자의 배치 방법에 따르면, 전처리, 편역, 어셈블리 및 링크를 통해 연산자의 소스 파일을 편역하여, 모든 조작이 사용자에게 완전히 은닉되어, 사용자의 러닝 및 사용 비용을 크게 저감하고, 사용 편의성을 개선한다. 더 나아가, 임의의 타사 편역 도구 및 모듈에 의존하지 않고, 더 강한 디커플링 성능을 구비한다. 설명해야 하는 바로는, 본 출원에서 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치하 려고 시도할 때, 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리의 타겟 목록에 설치할 수 있 다. 사이트 소프트웨어 패키지(site-package)를 예로 들어, 파일 확장자가 .egg 격식인 설치 가능한 라이브러리 파 일은 python의 표준 설치 협의 파일 격식이고, site-package에 설치될 수 있다. 여기서, Python 언어에는 많은 패키징된 타사 라이브러리를 포함하고, 각 라이브러리에는 많은 호출 가능한 API 를 포함한다. 이러한 타사 라이브러리는 Python 설치 경로의 site-package 목록에 있다. 즉, site-package 목 록은 많은 타사 라이브러리를 포함하는 \"리포지토리\"이고, Python의 모든 설치가능한 라이브러리를 관리하도록 사용될 수 있다. 더 나아가, 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치한 다음 사용자의 자체 정 의 연산자를 임포트하여 사용할 수 있다. 도3은 본 출원의 제3 실시예에 따른 개략도이다. 도3에 도시된 바와 같이, 상기 실시예를 기반하여 본 실시예에 서 제공되는 딥러닝 프레임워크에서의 연산자의 배치 방법은 단계S301 내지 단계S303을 포함한다. S301, 타겟 연산자의 임포트 어구를 획득하며, 여기서, 임포트 어구는 타겟 연산자의 설치 가능한 라이브러리 파일이 위치한 프로그래밍 언어 라이브러리에 대응되는 정보를 휴대하고 있다. 설명해야 하는 바로는, python의 임포트는 키워드 \"import\"에 의해 구현된다. 예를 들어, A가 사전 설치된 타사 라이브러리인 경우, 사용자에 의해 편집된 임포트 어구인 import A를 획득할 수 있다. 본 출원의 실시예에서, 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치한 다음, 사용 자의 자체 정의 연산자는 사용자가 편집한 import 임포트 어구에 의해 임포트되어 사용될 수 있다. S302, 임포트 어구를 해석하여 타겟 연산자의 설치 가능한 라이브러리 파일이 위치한 타겟 서브목록을 결정한다. 예를 들어 설명하면, 임포트 어구 import A를 해석하면, 타겟 연산자의 설치 가능한 라이브러리 파일이 위치한 타겟 서브목록은 site-package 목록의 서브목록 site-package/A인 것을 결정할 수 있다. S303, 타겟 서브목록에서 타겟 연산자의 설치 가능한 라이브러리 파일을 읽고 임포트한다. 선택적으로, import를 수행하여 임포트할 경우, 타겟 서브목록에서 타겟 연산자의 관련 설치 가능한 라이브러리 파일을 읽을 수 있고, 이를 임포트하여 후속에서 사용하도록 한다. 설명해야 하는 바로는, 본 출원에서 설치 가능한 라이브러리 파일을 설치하는 것을 통해 A와 유사하는 서브목록 을 자동으로 생성할 수 있다. 예를 들어 설명하면, A.egg를 설치할 경우, 자동으로 A.egg를 디스태킹하고 대응되는 서브목록, 즉 site- package/A의 서브목록에 복사할 수 있다. 본 출원의 실시예의 딥러닝 프레임워크에서의 연산자의 배치 방법에 따르면, 타겟 연산자의 임포트 어구를 획득 하고, 임포트 어구를 해석하여 타겟 연산자의 설치 가능한 라이브러리 파일이 위치한 타겟 서브목록을 결정할 수 있고, 더 나아가 타겟 서브목록에서 타겟 연산자의 설치 가능한 라이브러리 파일을 읽고 임포트하여, 일관성 및 사용 편의성이 더 향상된다. 더 나아가, 본 출원에서 코드 주입하는 방식을 통해 프레임워크와 과련된 인터페이스 파일을 입구 파일에 주입 하고, 동적 링크 라이브러리의 로딩 과정 및 인터페이스 파일의 호출 방식을 커스터마이징할 수 있다. 도4는 본 출원의 제4 실시예에 따른 개략도이다. 도4에 도시된 바와 같이, 상기 실시예를 기반하여 본 실시예에 서 제공되는 딥러닝 프레임워크에서의 연산자의 배치 방법은 단계S401 내지 단계S403을 포함한다. S401, 동적 링크 라이브러리에 대응되는 주입할 함수 코드를 획득한다. 여기서, 주입할 함수 코드는 사용자가 입력한 임의의 함수 코드일 수 있다. S402, 주입할 함수 코드를 입구 파일에 주입하여 동적 링크 라이브러리의 타겟 호출 함수 코드를 생성한다. 가능한 구현 방식으로서, 도5에 도시된 바와 같이, 상기 실시예를 기반하여 상기 단계 S402에서 주입할 함수 코 드를 입구 파일에 주입하여 동적 링크 라이브러리의 타겟 호출 함수 코드를 생성하는 단계는 단계S501 내지 단 계S502를 포함한다. S501, 입구 파일로부터 동적 링크 라이브러리의 묵인 호출 함수 코드를 획득한다. 도6에 도시된 바와 같이, 묵인 호출 함수 6-1은 __bootstrap__임을 예로 들어, __bootstrap__는 python 프런트 엔드가 자체 정의 연산자 라이브러리를 임포트할 때 동적 링크 라이브러리를 로딩하는 묵인 호출 함수이고, 당 해 묵인 호출 함수 Python 고유의 논리이다. 설명해야 하는 바로는, 묵인 호출 함수 코드는 api.py에 배치될 수 있다. 예를 들어 설명하면, conv.py에 대하 여 사용자가 import conv 어구를 수행할 때 conv.py의 __bootstrap__ 함수를 호출할 것이다. S502, 묵인 호출 함수 코드를 주입할 함수 코드로 대체하여 동적 링크 라이브러리의 타겟 호출 함수 코드를 생 성한다. 본 출원의 실시예에서, Python 고유의 묵인 호출 함수를 동적으로 대체하여 그의 함수 코드를 사용자가 실제 요 구에 따라 주입하려는 함수 코드로 수정할 수 있다. 예를 들어 설명하면, Python 고유의 __bootstrap__ 함수를 동적으로 대체하여 그의 함수 코드를 주입할 함수 코 드로 수정할 수 있다. S403, 타겟 호출 함수 코드를 인터페이스 파일에 쓴다. 예를 들어 설명하면, 완전한 코드 주입 과정을 구현하도록 수정된 __bootstrap__ 함수 코드를 특정한 인터페이 스 api.py, 예컨대 conv.py에 쓸 수 있다. 본 출원의 실시예의 딥러닝 프레임워크에서의 연산자의 배치 방법에 따르면, 동적 링크 라이브러리에 대응되는 주입할 함수 코드를 획득하고, 주입할 함수 코드를 입구 파일에 주입하여 동적 링크 라이브러리의 타겟 호출 함 수 코드를 생성하고, 더 나아가 타겟 호출 함수 코드를 인터페이스 파일에 쓰고, 코드 주입하는 방식을 통해 프 레임워크와 과련된 인터페이스 파일을 입구 파일에 주입하고, 동적 링크 라이브러리의 로딩 과정 및 인터페이스 파일의 호출 방식을 커스터마이징할 수 있다. 코드 주입하는 방식을 통해 원생의 동적 라이브러리 로딩 및 API 호출 방식을 대체하고, 딥러닝 프레임워크를 결합하여 python 설치 가능한 라이브러리 생성 기능을 커스터마이 징하기 위해 새로운 기술적 아이디어를 제공한다. 상기 복수의 실시예에서 제공되는 딥러닝 프레임워크에서의 연산자의 배치 방법에 대응되도록, 본 출원의 실시 예에서 또한 딥러닝 프레임워크에서의 연산자의 배치 장치를 제공한다. 본 출원의 실시예에서 제공되는 딥러닝 프레임워크에서의 연산자의 배치 장치는 상기 복수의 실시예에서 제공되는 딥러닝 프레임워크에서의 연산자의 배치 방법에 대응되기 때문에, 딥러닝 프레임워크에서의 연산자의 배치 방법의 실시 방식은 본 실시예에서 제공 되는 딥러닝 프레임워크에서의 연산자의 배치 장치에도 적용되어, 본 실시예에서 더는 상세히 설명하지 않는다. 도7은 본 출원의 실시예에 따른 딥러닝 프레임워크에서의 연산자의 배치 장치의 구조 개략도이다. 도7에 도시된 바와 같이, 당해 딥러닝 프레임워크에서의 연산자의 배치 장치는 제1 획득 모듈, 형성 모듈, 제1 생성 모듈, 제2 생성 모듈, 및 설치 모듈을 포함한다. 제1 획득 모듈은 연산자의 소스 파일을 획득하도록 사용된다. 형성 모듈은 상기 연산자의 소스 파일을 편역하여 상기 연산자의 동적 링크 라이브러리를 형성하도록 사용 된다. 제1 생성 모듈은 상기 연산자의 동적 링크 라이브러리의 인터페이스 파일을 생성하도록 사용된다. 제2 생성 모듈은 상기 동적 링크 라이브러리 및 상기 인터페이스 파일에 따라 설치 가능한 라이브러리 파 일을 생성하도록 사용된다. 설치 모듈은 상기 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치하도록 사용된 다. 도8은 본 출원의 다른 실시예에 따른 딥러닝 프레임워크에서의 연산자의 배치 장치의 구조 개략도이다. 도8에 도시된 바와 같이, 당해 딥러닝 프레임워크에서의 연산자의 배치 장치는 제1 획득 모듈, 형성 모듈, 제1 생성 모듈, 제2 생성 모듈, 및 설치 모듈을 포함한다. 형성 모듈은, 상기 연산자의 소스 파일에 대해 헤더 파일 확장 및 매크로 대체를 수행하여 편역할 코드를 생성하는 제1 생성 서브모듈; 상기 편역할 코드를 어셈블리 코드로 편역하고, 상기 어셈블리 코드를 한 줄씩 바이트 코드로 변환하여 타겟 파 일을 생성하는 제2 생성 서브모듈; 및 상기 타겟 파일을 링크 조작하여 링크된 타겟 파일을 획득하고, 상기 링크된 타겟 파일에 따라 상기 동적 링크 라이브러리를 생성하는 제3 생성 서브모듈; 을 포함한다. 제2 생성 모듈은, 사전 설정된 패키징 전략에 따라 상기 동적 링크 라이브러리 및 상기 인터페이스 파일을 패키징하여 상기 설치 가능한 라이브러리 파일을 생성하는 제4 생성 서브모듈을 포함한다. 설치 모듈은, 상기 설치 가능한 라이브러리 파일을 상기 타겟 프로그래밍 언어 라이브러리의 타겟 목록에 설치하는 설치 서브 모듈을 포함한다. 딥러닝 프레임워크에서의 연산자의 배치 장치는, 타겟 연산자의 임포트 어구를 획득하는 제2 획득 모듈 - 상기 임포트 어구는 상기 타겟 연산자의 설치 가 능한 라이브러리 파일이 위치한 프로그래밍 언어 라이브러리에 대응되는 정보를 휴대함 -; 상기 임포트 어구를 해석하여 상기 타겟 연산자의 설치 가능한 라이브러리 파일이 위치한 타겟 서브목록을 결정 하는 결정 모듈; 상기 타겟 서브목록에서 상기 타겟 연산자의 설치 가능한 라이브러리 파일을 읽고 임포트하는 임포트 모듈 ; 상기 동적 링크 라이브러리에 대응되는 주입할 함수 코드를 획득하는 제3 획득 모듈; 상기 주입할 함수 코드를 입구 파일에 주입하여 상기 동적 링크 라이브러리의 타겟 호출 함수 코드를 생성하는 주입 모듈; 상기 타겟 호출 함수 코드를 상기 인터페이스 파일에 쓰는 쓰기 모듈; 을 더 포함한다. 쓰기 모듈은, 상기 입구 파일로부터 상기 동적 링크 라이브러리의 묵인 호출 함수 코드를 획득하는 제1 획득 서브모듈; 상기 묵인 호출 함수 코드를 상기 주입할 함수 코드로 대체하여 상기 동적 링크 라이브러리의 타겟 호출 함수 코드를 생성하는 제5 생성 서브모듈을 포함한다. 본 출원의 실시예의 딥러닝 프레임워크에서의 연산자의 배치 장치에 따르면, 연산자의 소스 파일을 획득할 수 있고, 연산자의 소스 파일을 편역하여 연산자의 동적 링크 라이브러리를 형성하고, 연산자의 동적 링크 라이브 러리의 인터페이스 파일을 생성한 다음, 동적 링크 라이브러리 및 인터페이스 파일에 따라 설치 가능한 라이브 러리 파일을 생성하고, 더 나아가 설치 가능한 라이브러리 파일을 타겟 프로그래밍 언어 라이브러리에 설치함으 로써, 딥러닝 프레임워크에서의 연산자의 배치를 구현하여, 더는 타사 모듈에 의존하지 않고, 연산자 설치의 모 든 과정을 완전히 은닉할 수 있으며, 사용자의 러닝 비용을 크게 저감할 수 있는 동시에, 딥러닝 프레임워크에 서의 연산자의 배치 과정의 효율성, 융통성 및 신뢰성을 향상시킬 수 있다. 본 출원의 실시예에 따라 본 출원은 또한 전자 기기, 판독 가능 저장 매체 및 컴퓨터 프로그램을 제공한다. 도9는 본 출원의 실시예를 실시하기 위한 예시적인 전자 기기의 개략적 블록도이다. 전자 기기는 랩톱 컴 퓨터, 데스크톱 컴퓨터, 워크 스테이션, 개인용 디지털 비서, 서버, 블레이드 서버, 메인 프레임워크 컴퓨터 및 기타 적합한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 나타내기 위한 것이다. 전자 기기는 또한 개인용 디 지털 처리, 셀룰러 폰, 스마트 폰, 웨어러블 기기 및 기타 유사한 컴퓨팅 장치와 같은 다양한 형태의 모바일 장 치를 나타낼 수도 있다. 본 명세서에서 제시된 구성 요소, 이들의 연결 및 관계, 또한 이들의 기능은 단지 예일 뿐이며 본문에서 설명되거나 및/또는 요구되는 본 출원의 구현을 제한하려는 의도가 아니다. 도9에 도시된 바와 같이, 기기는 컴퓨팅 유닛을 포함하며, 읽기 전용 메모리(ROM)에 저장된 컴 퓨터 프로그램에 의해 또는 저장 유닛으로부터 랜덤 액세스 메모리(RAM)에 로딩된 컴퓨터 프로그램에 의해 수행되어 각종 적절한 동작 및 처리를 수행할 수 있다. RAM에, 또한 기기가 오퍼레이션을 수행 하기 위해 필요한 각종 프로그램 및 데이터가 저장되어 있다. 컴퓨팅 유닛, ROM 및 RAM은 버스 를 통해 서로 연결되어 있다. 입력/출력(I/O) 인터페이스도 버스에 연결되어 있다. 키보드, 마우스 등과 같은 입력 유닛; 각종 유형의 모니터, 스피커 등과 같은 출력 유닛; 자기 디스 크, 광 디스크 등과 같은 저장 유닛; 및 네트워크 카드, 모뎀, 무선 통신 트랜시버 등과 같은 통신 유닛 을 포함하는 기기 중의 복수의 부품은 I/O 인터페이스에 연결된다. 통신 유닛은 장치(90 0)가 인터넷과 같은 컴퓨터 네트워크 및/또는 다양한 통신 네트워크를 통해 다른 기기와 정보/데이터를 교환하 도록 허락한다. 컴퓨팅 유닛은 프로세싱 및 컴퓨팅 능력을 구비한 다양한 범용 및/또는 전용 프로세싱 컴포넌트일 수 있다. 컴퓨팅 유닛의 일부 예시는 중앙 처리 유닛(CPU), 그래픽 처리 유닛(GPU), 다양한 전용 인공 지능 (AI) 컴퓨팅 칩, 기계 러닝 모델 알고리즘을 수행하는 다양한 컴퓨팅 유닛, 디지털 신호 처리기(DSP), 및 임의 의 적절한 프로세서, 컨트롤러, 마이크로 컨트롤러 등을 포함하지만, 이에 제한되지 않는다. 컴퓨팅 유닛 은 예를 들어 딥러닝 프레임워크에서의 연산자의 배치 방법과 같은 윗글에서 설명한 각각의 방법 및 처리를 수 행한다. 예를 들어, 일부 실시예에서, 딥러닝 프레임워크에서의 연산자의 배치 방법은 저장 유닛과 같은 기계 판독 가능 매체에 유형적으로 포함되어 있는 컴퓨터 소프트웨어 프로그램으로 구현될 수 있다. 일부 실시 예에서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및/또는 통신 유닛을 통해 기기에 로드 및/또 는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되고 컴퓨팅 유닛에 의해 수행되는 경우, 전술한 딥러닝 프레임워크에서의 연산자의 배치 방법의 하나 또는 하나 이상의 단계를 수행할 수 있다. 대안적으로, 다 른 실시예에서, 컴퓨팅 유닛은 임의의 다른 적절한 방식(예를 들어, 펌웨어에 의해)을 통해 구성되어 딥러 닝 프레임워크에서의 연산자의 배치 방법을 수행하도록 한다. 여기서 설명되는 시스템 및 기술의 다양한 실시 방식은 디지털 전자 회로 시스템, 집적 회로 시스템, 필드 프로 그래머블 게이트 어레이(FPGA), 주문형 집적 회로(ASIC), 특정 용도 표준 제품(ASSP), 시스템온칩(SOC), 복합 프로그래머블 논리 소자(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및 이들의 조합 중의 적어도 하나로 구현 될 수 있다. 이러한 다양한 실시 방식은 하나 또는 하나 이상의 컴퓨터 프로그램에서의 구현을 포함할 수 있으 며, 당해 하나 또는 하나 이상의 컴퓨터 프로그램은 적어도 하나의 프로그램 가능 프로세서를 포함하는 프로그 램 가능 시스템에서 수행 및/또는 해석될 수 있고, 당해 프로그램 가능 프로세서는 전용 또는 일반용일 수 있고, 저장 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장치로부터 데이터 및 명령을 수신하고 또 한 데이터 및 명령을 당해 저장 시스템, 당해 적어도 하나의 입력 장치 및 당해 적어도 하나의 출력 장치에 전 송할 수 있다. 본 출원의 방법을 구현하기 위해 사용되는 프로그램 코드는 하나 또는 하나 이상의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 전용 컴퓨터 또는 기타 프로그래머블 데이터 처리 장치의 프로세서 또는 컨트롤러에 제공될 수 있으므로, 프로그램 코드가 프로세서 또는 컨트롤러에 의해 수행되는 경우, 흐름도 및/또는 블록도에서 규정한 기능/조작을 구현하도록 한다. 프로그램 코드는 전체적으로 기계에서 수행되거나, 부분적으로 기계에서 수행되거나, 독립 소프트웨어 패키지로서 부분적으로 기계에서 수행 되고 부분적으로 원격 기계에서 수행되거나 또는 전체적으로 원격 기계 또는 서버에서 수행될 수 있다. 본 출원의 문맥에서, 기계 판독 가능 매체는 명령 수행 시스템, 장치 또는 기기에 의해 사용되거나 명령 수행 시스템, 장치 또는 기기와 결합하여 사용되는 프로그램을 포함하거나 저장할 수 있는 유형의 매체일 수 있다. 기계 판독 가능 매체는 기계 판독 가능 신호 매체 또는 기계 판독 가능 저장 매체일 수 있다. 기계 판독 가능 매체는 전자, 자기, 광학, 전자기, 적외선 또는 반도체 시스템, 장치 또는 기기, 또는 상기 내용의 임의의 적절한 조합을 포함할 수 있지만 이에 제한되지 않는다. 기계 판독 가능 저장 매체의 더 구체적인 예시는 하나 또는 하나 이상의 전선을 기반하는 전기 연결, 휴대용 컴퓨터 디스크, 하드 디스크, 랜덤 액세스 메모리(RAM), 읽기 전용 메모리(ROM), 지울 수 있는 프로그래머블 읽기 전용 메모리(EPROM 또는 플래시 메모리), 광섬유, 휴대용 컴팩트 디스크 읽기 전용 메모리(CD-ROM), 광학 저장 기기, 자기 저장 기기 또는 상기 내용의 임의의 적절한 조 합을 포함할 수 있지만 이에 제한되지 않는다. 사용자와의 인터랙션을 제공하기 위해 여기에 설명된 시스템 및 기술은 컴퓨터에서 실시될 수 있다. 당해 컴퓨 터는 사용자에게 정보를 디스플레이하기 위한 디스플레이 장치(예를 들어, CRT(음극선관) 또는 LCD(액정 디스플 레이) 모니터); 및 키보드 및 포인팅 장치(예를 들어, 마우스 또는 트랙볼)를 구비하며, 사용자는 당해 키보드 및 당해 포인팅 장치를 통해 컴퓨터에 입력을 제공할 수 있다. 다른 유형의 장치를 사용하여 사용자와의 인터랙 션을 제공할 수도 있으며, 예를 들어, 사용자에게 제공되는 피드백은 임의의 형태의 감지 피드백(예를 들어, 시 각적 피드백, 청각적 피드백 또는 촉각적 피드백)일 수 있고; 임의의 형태(소리 입력, 음성 입력 또는 촉각 입 력을 포함)로 사용자로부터의 입력을 수신할 수 있다. 여기서 설명된 시스템 및 기술은 백엔드 부품을 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서버로서), 또는 미 들웨어 부품을 포함하는 컴퓨팅 시스템(예를 들어, 응용 서버), 또는 프런트 엔드 부품을 포함하는 컴퓨팅 시스 템(예를 들어, 그래픽 사용자 인터페이스 또는 네트워크 브라우저를 구비하는 사용자 컴퓨터인 바, 사용자는 당 해 그래픽 사용자 인터페이스 또는 네트워크 브라우저를 통해 여기서 설명된 시스템 및 기술의 실시 방식과 인 터랙션할 수 있음), 또는 이러한 백엔드 부품, 미들웨어 부품 또는 프런트 엔드 부품의 임의의 조합을 포한하는 컴퓨팅 시스템에서 실시될 수 있다. 시스템의 부품은 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워크)을 통해 서로 연결될 수 있다. 통신 네트워크의 예시는 근거리 통신망(LAN), 광역 통신망(WAN), 인터넷 및 블록체인 네트워크를 포함한다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 고, 통신 네트워크를 통해 인터랙션한다. 서로 클라이언트-서버 관계를 가지는 컴퓨터 프로그램을 대응되는 컴 퓨터에서 수행하여 클라이언트와 서버 간의 관계를 생성한다. 서버는 클라우드 컴퓨팅 서버 또는 클라우드 호스 트라고도 하는 클라우드 서버일 수 있고, 클라우드 컴퓨팅 서비스 시스템 중의 일종의 호스트 제품이고, 기존의 물리적 호스트 및 VPS(Virtual Private Server, 가상 사설 서버) 서비스에 존재하고 있는 관리가 어렵고 비즈니 스 확장이 약한 결점을 해결하기 위한 것이다. 서버는 또한 분산 시스템의 서버, 또는 블록체인을 결합한 서버 일 수 있다. 이해 가능한 바로는, 전술한 다양한 형식의 프로세스에 있어서 단계 재정렬, 추가 또는 삭제를 할 수 있다. 예 를 들어, 본 출원에 개시된 기술 솔루션이 이루고자 하는 결과를 구현할 수 있는 한, 본 출원에 기재된 각 단계 들은 병렬로, 순차적으로 또는 다른 순서로 수행될 수 있으나, 본 명세서에서 이에 대해 한정하지 않는다. 전술한 구체적인 실시 방식들은 본 출원의 보호 범위에 대한 한정을 구성하지 않는다. 당업자라면 본 출원의 설 계 요건 및 기타 요인에 따라 다양한 수정, 조합, 서브 조합 및 대체가 이루어질 수 있음을 이해해야 한다. 본 출원의 정신과 원칙 내에서 이루어진 모든 수정, 동등한 대체 및 개선은 본 출원의 보호 범위에 포함된다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2021-0182784", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부된 도면은 본 출원의 수단을 더 잘 이해하기 위한 것으로, 본 출원에 대한 한정이 구성되지 않는다. 여기서, 도1은 본 출원의 제1 실시예에 따른 개략도이다. 도2는 본 출원의 제2 실시예에 따른 개략도이다. 도3은 본 출원의 제3 실시예에 따른 개략도이다. 도4는 본 출원의 제4 실시예에 따른 개략도이다. 도5는 본 출원의 제5 실시예에 따른 개략도이다. 도6은 Python 패키지 퍼블리싱에 따른 흐름도이다. 도7은 본 출원의 실시예의 딥러닝 프레임워크에서의 연산자의 배치 방법을 구현하기 위한 딥러닝 프레임워크에 서의 연산자의 배치 장치의 블록도이다. 도8은 본 출원의 실시예의 딥러닝 프레임워크에서의 연산자의 배치 방법을 구현하기 위한 딥러닝 프레임워크에 서의 연산자의 배치 장치의 블록도이다. 도9는 본 출원의 실시예의 딥러닝 프레임워크에서의 연산자의 배치를 구현하기 위한 전자 기기의 블록도이다."}
