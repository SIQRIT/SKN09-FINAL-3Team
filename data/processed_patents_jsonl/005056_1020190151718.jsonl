{"patent_id": "10-2019-0151718", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0063151", "출원번호": "10-2019-0151718", "발명의 명칭": "데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치 및 그 제어 방", "출원인": "숙명여자대학교산학협력단", "발명자": "심준호"}}
{"patent_id": "10-2019-0151718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "변분 오토 인코더(VAE)에 기초하여 학습된 기계학습 모델을 이용하여 제1 데이터와 제2 데이터의 의미론적 유사여부를 확인하는 과정을 포함하며, 상기 제1 데이터와 제2 데이터의 의미론적 유사 여부를 확인하는 과정은,상기 제1 데이터와 상기 제2 데이터를 획득하는 과정;상기 제1 데이터를 상기 학습된 기계학습 모델을 이용하여 제1 확인 해시 코드를 결정하는 과정;상기 제2 데이터를 상기 학습된 기계학습 모델을 이용하여 제2 확인 해시 코드를 결정하는 과정;상기 제1 및 제2 확인 해시 코드에 기초하여 상기 제1 및 제2 데이터 사이의 유사도를 획득하는 과정; 및상기 제1 및 제2 데이터 사이의 유사도에 기초하여 상기 제1 및 제2 데이터의 의미론적 유사 여부를 결정하는과정을 포함하는,데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0151718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,훈련 데이터 세트를 이용하여 상기 기계학습 모델을 훈련하는 훈련 과정을 더 포함하며, 상기 훈련 과정은,동일한 훈련 레이블 정보를 가지는 제1 훈련 데이터와 제2 훈련 데이터를 포함하는 상기 훈련 데이터 세트를 획득하는 과정;상기 제1 훈련 데이터를 상기 변분 오토 인코더(VAE)를 이용하여 훈련하고, 상기 제1 훈련 데이터의 제1 훈련해시 코드인 제1 훈련 잠재 변수(latent variable)를 결정하는 과정;상기 제2 훈련 데이터를 상기 VAE를 이용하여 훈련하고, 상기 제2 훈련 데이터의 제2 훈련 해시 코드인 제2 훈련 잠재 변수를 결정하는 과정;상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수, 및 상기 제2 훈련 잠재 변수에 기초하여 손실 함수(lossfunction)을 결정하는 과정; 및상기 손실 함수에 기초하여 기계학습 모델을 학습하는 과정을 포함하는,데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0151718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수, 및 상기 제2 훈련 잠재 변수에 기초하여 손실 함수(lossfunction)을 결정하는 과정은,상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수의 평균 및 분산, 및 상기 제2 훈련 잠재 변수의 평균 및 분산을 사용하여 상기 손실 함수를 결정하는 과정을 포함하는, 데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0151718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수, 및 상기 제2 훈련 잠재 변수에 기초하여 손실 함수(loss공개특허 10-2021-0063151-3-function)을 결정하는 과정은,상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수의 평균, 및 상기 제2 훈련 잠재 변수의 평균을 사용하여 상기손실 함수를 결정하는 과정을 포함하는,데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0151718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수, 및 상기 제2 훈련 잠재 변수에 기초하여 손실 함수(lossfunction)을 결정하는 과정은,상기 훈련 과정의 경과 시간이 기 설정된 시간 보다 큰지 확인하는 과정;상기 훈련 과정의 경과 시간이 기 설정된 시간 보다 작은 경우에 상기 손실 함수에 대한 레이블 가중치(Wt)가 0으로 설정되는 과정; 및 상기 훈련 과정의 경과 시간이 기 설정된 시간 보다 큰 경우에 상기 손실 함수에 대한 레이블 가중치가 기 설정된 값 또는 기 설정된 함수로 설정되는 과정을 포함하는,데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0151718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 기 설정된 시간은 비지도 학습의 영향도에 따라서 결정되는 것을 특징으로 하는,데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0151718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서,상기 훈련 과정 이후에, 평가 데이터 세트를 이용하여 상기 학습된 기계학습 모델을 평가하는 평가 과정을 더포함하며, 상기 평가 과정은,동일한 평가 레이블 정보를 가지는 제1 평가 데이터와 제2 평가 데이터를 포함하는 상기 평가 데이터 세트를 획득하는 과정;상기 제1 평가 데이터를 상기 학습된 기계학습 모델을 이용하여 상기 제1 평가 데이터의 제1 평가 해시 코드를결정하는 과정;상기 평가 제2 데이터를 상기 학습된 기계학습 모델을 이용하여 상기 제2 평가 데이터의 제2 평가 해시 코드를결정하는 과정;상기 제1 및 제2 평가 해시 코드에 기초하여 상기 제1 평가 데이터와 상기 제2 평가 데이터 사이의 유사도를 획득하는 과정; 및상기 제1 평가 데이터와 상기 제2 평가 데이터 사이의 유사도 및 상기 평가 레이블 정보에 기초하여 상기 기계학습 모델을 재 학습하는 과정을 포함하는,데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0151718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "변분 오토 인코더(VAE)에 기초하여 학습된 기계학습 모델을 이용하여 제1 데이터와 제2 데이터의 의미론적 유사여부를 확인하는 프로세서를 포함하며,상기 프로세서에 의해서 수행되는 상기 제1 데이터와 제2 데이터의 의미론적 유사 여부를 확인하는 과정은,공개특허 10-2021-0063151-4-상기 제1 데이터와 상기 제2 데이터를 획득하는 과정;상기 제1 데이터를 상기 학습된 기계학습 모델을 이용하여 제1 확인 해시 코드를 결정하는 과정;상기 제2 데이터를 상기 학습된 기계학습 모델을 이용하여 제2 확인 해시 코드를 결정하는 과정;상기 제1 및 제2 확인 해시 코드에 기초하여 상기 제1 및 제2 데이터 사이의 유사도를 획득하는 과정; 및상기 제1 및 제2 데이터 사이의 유사도에 기초하여 상기 제1 및 제2 데이터의 의미론적 유사 여부를 결정하는과정을 포함하는,데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치."}
{"patent_id": "10-2019-0151718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 프로세서는 훈련 데이터 세트를 이용하여 상기 기계학습 모델을 훈련하는 훈련 과정을 더 수행하며, 상기 프로세서에 수행되는 상기 훈련 과정은,동일한 훈련 레이블 정보를 가지는 제1 훈련 데이터와 제2 훈련 데이터를 포함하는 상기 훈련 데이터 세트를 획득하는 과정;상기 제1 훈련 데이터를 변분 오토 인코더(VAE)를 이용하여 훈련하고, 상기 제1 훈련 데이터의 제1 훈련 해시코드인 제1 훈련 잠재 변수(latent variable)를 결정하는 과정;상기 제2 훈련 데이터를 상기 VAE를 이용하여 훈련하고, 상기 제2 훈련 데이터의 제2 훈련 해시 코드인 제2 훈련 잠재 변수를 결정하는 과정;상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수, 및 상기 제2 훈련 잠재 변수에 기초하여 손실 함수(lossfunction)을 결정하는 과정; 및상기 손실 함수에 기초하여 기계학습 모델을 학습하는 과정을 포함하는,데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치."}
{"patent_id": "10-2019-0151718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수, 및 상기 제2 훈련 잠재 변수에 기초하여 손실 함수(lossfunction)을 결정하는 과정은,상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수의 평균 및 분산, 및 상기 제2 훈련 잠재 변수의 평균 및 분산을 사용하여 상기 손실 함수를 결정하는 과정을 포함하는, 데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치."}
{"patent_id": "10-2019-0151718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수, 및 상기 제2 훈련 잠재 변수에 기초하여 손실 함수(lossfunction)을 결정하는 과정은,상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수의 평균, 및 상기 제2 훈련 잠재 변수의 평균을 사용하여 상기손실 함수를 결정하는 과정을 포함하는,데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치."}
{"patent_id": "10-2019-0151718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수, 및 상기 제2 훈련 잠재 변수에 기초하여 손실 함수(loss공개특허 10-2021-0063151-5-function)을 결정하는 과정은,상기 훈련 과정의 경과 시간이 기 설정된 시간 보다 큰지 확인하는 과정;상기 훈련 과정의 경과 시간이 기 설정된 시간 보다 작은 경우에 상기 손실 함수에 대한 레이블 가중치(Wt)가 0으로 설정되는 과정; 및 상기 훈련 과정의 경과 시간이 기 설정된 시간 보다 큰 경우에 상기 손실 함수에 대한 레이블 가중치가 기 설정된 값 또는 기 설정된 함수로 설정되는 과정을 포함하는,데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치."}
{"patent_id": "10-2019-0151718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 기 설정된 시간은 비지도 학습의 영향도에 따라서 결정되는 것을 특징으로 하는,데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치."}
{"patent_id": "10-2019-0151718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,상기 프로세서는 상기 훈련 과정을 수행한 이후에, 평가 데이터 세트를 이용하여 상기 학습된 기계학습 모델을평가하는 평가 과정을 더 수행하며, 상기 프로세서에 의해서 수행되는 상기 평가 과정은,동일한 평가 레이블 정보를 가지는 제1 평가 데이터와 제2 평가 데이터를 포함하는 상기 평가 데이터 세트를 획득하는 과정;상기 제1 평가 데이터를 상기 학습된 기계학습 모델을 이용하여 상기 제1 평가 데이터의 제1 평가 해시 코드를결정하는 과정;상기 평가 제2 데이터를 상기 학습된 기계학습 모델을 이용하여 상기 제2 평가 데이터의 제2 평가 해시 코드를결정하는 과정;상기 제1 평가 해시 코드 및 상기 제2 평가 해시 코드에 기초하여 상기 제1 평가 데이터와 상기 제2 평가 데이터 사이의 유사도를 획득하는 과정; 및상기 제1 평가 데이터와 상기 제2 평가 데이터 사이의 유사도 및 상기 평가 레이블 정보에 기초하여 상기 기계학습 모델을 재 학습하는 과정을 포함하는,데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치."}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따른 일 실시예는, 변분 오토 인코더(VAE)에 기초하여 학습된 기계학습 모델을 이용하여 제1 및 제2 데이터의 의미론적 유사 여부를 확인하는 과정을 포함하며, 상기 과정은, 상기 제1 및 제2 데이터를 상기 학습된 기계학습 모델을 이용하여 각각 상기 제1 및 제2 데이터의 제1 및 제2 해시 코드를 결정하는 과정; 상기 제1 및 제2 해시 코드에 기초하여 상기 제1 및 제2 데이터 사이의 유사도를 획득하는 과정; 및 상기 제1 및 제2 데이터 사이의 유사도에 기초하여 상기 제1 및 제2 데이터의 의미론적 유사 여부를 결정하는 과정을 포함하는, 데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치의 제어 방법을 제공할 수 있다."}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치 및 그 제어 방법에 관 한 것으로, 구체적으로 2개 텍스트 사이의 의미론적 유사 여부를 빠른 시간내에 판단하기 위하여 기계학습을 이 용한 전자 장치 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 Rule 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용 할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 Rule 기반 스마트 시스템은 점차 기계학습 기반 인공지능 시스템으로 대체되고 있다.인공지능 기술은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제 어 등의 기술 분야로 구성된다. 인공지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 시각적 이해 는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술 로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험정보 를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함 한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임을 제어하는 기술로서, 움직임 제어(항법, 충돌, 주행), 조 작 제어(행동 제어) 등을 포함한다. 웹의 급속한 성장에 따라, 지난 몇 년 동안 텍스트 데이터의 양이 폭발적으로 증가했다. 많은 분야에서 텍스트 에 대한 빠른 유사도(similarity) 검색들이 필수적인 요건이 되고 있다. 의미론적 해싱(Semantic hashing)은 빠 른 유사도 검색을 위한 가장 강력한 솔루션들 중 하나이다. 의미론적 해싱은 대규모 유사도 검색들의 근사치를 내기 위해 널리 활용되어 왔다. 해싱을 통해 최소(compact) 이진 코드들을 사용하여 원본 텍스트를 표현할 수 있다. 신경 네트워크 아키텍처의 최근 발전은 더 나은 해시 함수들을 학습하는 이 방법의 효과와 기능을 보여주 고 있다. 대부분, 범주형(categorical) 레이블과 같은, 명시적(explicit, 정확한, 분명한) 기능들을 인코딩한다. 그러나, 텍스트 데이터의 특수한 특성으로 인해, 이전의 의미론적 텍스트 해싱 접근법들은 범주형 레이블 데이 터보다 유사도를 더 직관적으로 반영하는 쌍별 레이블 정보를 활용하지 않는다. 또한, 종래 기술에 대한 특허문헌1은 인물의 움직임 데이터와 같은 제1 관측 데이터 및 인물의 음성 데이터와 같은 제2 관측 데이터를 취득하고, 취득된 제1 및 제2 관측 데이터의 훈련 데이터를 변분 오토 인코더 (variational auto encoder : VAE)를 이용하여 잠재변수를 추정하고, 추정된 잠재변수로부터 제1 관측 데이터를 생성하고, 생성된 제1 관측 데이터를 이용하여 취득된 제2 관측 데이터의 결손부분을 보간하여 출력하는 점을 개시할 뿐이다. 선행기술문헌 특허문헌 (특허문헌 0001) 일본 공개특허공보 2018-152004 (정보처리 장치 및 프로그램)"}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 기계학습 모델은 제1 데이터 및 제2 데이터 사이의 유사 여부를 판별하는 것을 목 적으로 할 수 있다. 본 발명의 일 실시 예에 따른 기계학습 모델은 2개의 텍스트 데이터의 유사 여부를 판별하는 것을 목적으로 할 수 있다. 본 발명의 일 실시 예에 따른 기계학습 모델은 VAE를 이용하여 동일한 레이블 정보를 가지는 제1 데이터 및 제2 데이터에 기초하여 기계학습 모델을 학습하는 것을 목적으로 할 수 있다. 본 발명의 일 실시 예에 따른 기계학습 모델은 쌍별 레이블 정보를 활용하는 지도 의미론 텍스트 해싱 방법 (supervised semantic text hashing method)을 제안하는 것을 목적으로 할 수 있다. 본 발명의 일 실시 예에 따른 기계학습 모델은 이전의 해싱 접근법들보다 쌍별 레이블 정보를 잘 이용하는 텍스 트 해싱 방법을 제공하는 것을 목적으로 할 수 있다. 본 발명의 일 실시 예에 따른 기계학습 모델은 데이터들 사이의 유사 여부를 판단하기 위하여 데이터들의 해시 코드를 이용하여 보다 빠르고 신속하게 데이터들의 유사 여부를 판단하는 텍스트 해싱 방법을 제공하는 것을 목 적으로 할 수 있다."}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치의 제어 방법은, 변분 오토 인코더(VAE)에 기초하여 학습된 기계학습 모델을 이용하여 제1 데이터와 제2 데이터의 의미론적 유사 여부를 확인하는 과정을 포함할 수 있다. 상기 제1 데이터와 제2 데이터의 의미론적 유사 여부를 확인하는 과정은, 상기 제1 데이터와 상기 제2 데이터를 획득하는 과정; 상기 제1 데이터를 상기 학습된 기계학습 모델을 이용하여 상기 제1 데이터의 제1 확인 해시 코 드를 결정하는 과정; 상기 제2 데이터를 상기 학습된 기계학습 모델을 이용하여 상기 제2 데이터의 제2 확인 해시 코드를 결정하는 과정; 상기 제1 확인 해시 코드 및 상기 제2 확인 해시 코드에 기초하여 상기 제1 데이터 와 상기 제2 데이터 사이의 유사도를 획득하는 과정; 및 상기 제1 데이터와 상기 제2 데이터 사이의 유사도에 기초하여 상기 제1 데이터와 상기 제2 데이터의 의미론적 유사 여부를 결정하는 과정을 포함할 수 있다. 본 발명의 일 실시 예에 따른 데이터의 의미론적 유사 여부를 분석하기 위하여 상기 기계학습을 이용한 전자 장 치의 제어 방법은, 훈련 데이터 세트를 이용하여 기계학습 모델을 훈련하는 훈련 과정을 포함할 수 있다. 상기 훈련 과정은, 동일한 훈련 레이블 정보를 가지는 제1 훈련 데이터와 제2 훈련 데이터를 포함하는 상기 훈 련 데이터 세트를 획득하는 과정; 상기 제1 훈련 데이터를 상기 변분 오토 인코더(VAE)를 이용하여 훈련하고, 상기 제1 훈련 데이터의 제1 훈련 해시 코드인 제1 훈련 잠재 변수(latent variable)를 결정하는 과정; 상기 제 2 훈련 데이터를 상기 VAE를 이용하여 훈련하고, 상기 제2 훈련 데이터의 제2 훈련 해시 코드인 제2 훈련 잠재 변수를 결정하는 과정; 상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수, 및 상기 제2 훈련 잠재 변수에 기초 하여 손실 함수(loss function)을 결정하는 과정; 및 상기 손실 함수에 기초하여 기계학습 모델을 학습하는 과 정을 포할 수 있다. 상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수, 및 상기 제2 훈련 잠재 변수에 기초하여 손실 함수(loss function)을 결정하는 과정은, 상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수의 평균 및 분산, 및 상기 제2 훈련 잠재 변수의 평균 및 분산을 사용하여 상기 손실 함수를 결정하는 과정을 포함할 수 있다. 또는, 상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수, 및 상기 제2 잠재 훈련 변수에 기초하여 손실 함수 (loss function)을 결정하는 과정은, 상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수의 평균, 및 상기 제2 훈 련 잠재 변수의 평균을 사용하여 상기 손실 함수를 결정하는 과정을 포함할 수 있다. 또는, 상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수, 및 상기 제2 훈련 잠재 변수에 기초하여 손실 함수 (loss function)을 결정하는 과정은, 상기 훈련 과정의 경과 시간이 기 설정된 시간 보다 큰지 확인하는 과정; 상기 훈련 과정의 경과 시간이 기 설정된 시간 보다 작은 경우에 상기 손실 함수에 대한 레이블 가중치(Wt)가 0 으로 설정되는 과정; 및 상기 훈련 과정의 경과 시간이 기 설정된 시간 보다 큰 경우에 상기 손실 함수에 대한 레이블 가중치가 기 설정된 값 또는 기 설정된 함수로 설정되는 과정을 포함할 수 있다. 상기 기 설정된 시간은 비지도 학습의 영향도에 따라서 결정되는 것을 특징으로 할 수 있다. 본 발명의 일 실시 예에 따른 데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치의 제어 방법은, 상기 훈련 과정 이후에, 평가 데이터 세트를 이용하여 상기 학습된 기계학습 모델을 평가하는 평 가 과정을 더 포함할 수 있다. 상기 평가 과정은, 동일한 평가 레이블 정보를 가지는 제1 평가 데이터와 제2 평가 데이터를 포함하는 상기 평 가 데이터 세트를 획득하는 과정; 상기 제1 평가 데이터를 상기 학습된 기계학습 모델을 이용하여 상기 제1 평 가 데이터의 제1 평가 해시 코드를 결정하는 과정; 상기 평가 제2 데이터를 상기 학습된 기계학습 을 이용하여 상기 제2 평가 데이터의 제2 평가 해시 코드를 결정하는 과정; 상기 제1 평가 해시 코드 및 상기 제2 평가 해시 코드에 기초하여 상기 제1 평가 데이터와 상기 제2 평가 데이터 사이의 유사도를 획득하는 과정; 및 상기 제1 평가 데이터와 상기 제2 평가 데이터 사이의 유사도 및 상기 평가 레이블 정보에 기초하여 상기 기계학습 모델 을 재 학습하는 과정을 포함할 수 있다.한편, 한편, 본 발명의 일 실시 예에 따른 데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치는, 변분 오토 인코더(VAE)에 기초하여 학습된 기계학습 모델을 이용하여 제1 데이터와 제2 데이터의 의미론적 유사 여부를 확인하는 프로세서를 포함할 수 있다. 상기 프로세서에 의해서 수행되는 상기 제1 데이터와 제2 데이터의 의미론적 유사 여부를 확인하는 과정은, 상 기 제1 데이터와 상기 제2 데이터를 획득하는 과정; 상기 제1 데이터를 상기 학습된 기계학습 모델을 이용하여 상기 제1 데이터의 제1 확인 해시 코드를 결정하는 과정; 상기 제2 데이터를 상기 학습된 기계학습 모델을 이용 하여 상기 제2 데이터의 제2 확인 해시 코드를 결정하는 과정; 상기 제1 확인 해시 코드 및 상기 제2 확인 해 시 코드에 기초하여 상기 제1 데이터와 상기 제2 데이터 사이의 유사도를 획득하는 과정; 및 상기 제1 데이터와 상기 제2 데이터 사이의 유사도에 기초하여 상기 제1 데이터와 상기 제2 데이터의 의미론적 유사 여부를 결정하 는 과정을 포함할 수 있다. 한편, 본 발명의 일 실시 예에 따른 데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치에서, 상기 프로세서는 훈련 데이터 세트를 이용하여 기계학습 모델을 훈련하는 훈련 과정을 수행할 수 있 다. 상기 프로세서에 수행되는 상기 훈련 과정은, 동일한 훈련 레이블 정보를 가지는 제1 훈련 데이터와 제2 훈련 데이터를 포함하는 상기 훈련 데이터 세트를 획득하는 과정; 상기 제1 훈련 데이터를 변분 오토 인코더(VAE)를 이용하여 훈련하고, 상기 제1 훈련 데이터의 제1 훈련 해시 코드인 제1 훈련 잠재 변수(latent variable)를 결 정하는 과정; 상기 제2 훈련 데이터를 상기 VAE를 이용하여 훈련하고, 상기 제2 훈련 데이터의 제2 훈련 해시 코드인 제2 훈련 잠재 변수를 결정하는 과정; 상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수, 및 상기 제2 훈련 잠재 변수에 기초하여 손실 함수(loss function)을 결정하는 과정; 및 상기 손실 함수에 기초하여 기계학 습 모델을 학습하는 과정을 포함할 수 있다. 본 발명의 일 실시 예에 따른 데이터의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치에 서, 상기 프로세서는 상기 훈련 과정을 수행한 이후에, 평가 데이터 세트를 이용하여 상기 학습된 기계학습 모 델을 평가하는 평가 과정을 더 수행할 수 있다. 상기 프로세서에 의해서 수행되는 상기 평가 과정은, 동일한 평가 레이블 정보를 가지는 제1 평가 데이터와 제2 평가 데이터를 포함하는 상기 평가 데이터 세트를 획득하는 과정; 상기 제1 평가 데이터를 상기 학습된 기계학 습 모델을 이용하여 상기 제1 평가 데이터의 제1 평가 해시 코드를 결정하는 과정; 상기 평가 제2 데이터를 상 기 학습된 기계학습 모델을 이용하여 상기 제2 평가 데이터의 제2 평가 해시 코드를 결정하는 과정; 상기 제1 평가 해시 코드 및 상기 제2 평가 해시 코드에 기초하여 상기 제1 평가 데이터와 상기 평가 제2 데이터 사이의 유사도를 획득하는 과정; 및 상기 제1 평가 데이터와 상기 평가 제2 데이터 사이의 유사도 및 상기 평가 레이블 정보에 기초하여 상기 기계학습 모델을 재 학습하는 과정을 포함할 수 있다."}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 기계학습 모델은 제1 데이터 및 제2 데이터 사이의 유사 여부를 판별하는 효과를 가질 수 있다. 본 발명의 일 실시 예에 따른 기계학습 모델은 2개의 텍스트 데이터의 유사 여부를 판별하는 효과를 가질 수 있 다. 본 발명의 일 실시 예에 따른 기계학습 모델은 VAE를 이용하여 동일한 레이블 정보를 가지는 제1 데이터 및 제2 데이터에 기초하여 기계학습 모델을 학습하는 효과를 가질 수 있다. 본 발명의 일 실시 예에 따른 기계학습 모델은 쌍별 레이블 정보를 활용하는 지도 의미론 텍스트 해싱 방법 (supervised semantic text hashing method)을 제안하는 효과를 가질 수 있다. 본 발명의 일 실시 예에 따른 기계학습 모델은 이전의 해싱 접근법들보다 쌍별 레이블 정보를 잘 이용하는 텍스 트 해싱 방법을 제공하는 효과를 가질 수 있다. 본 발명의 일 실시 예에 따른 기계학습 모델은 데이터들 사이의 유사 여부를 판단하기 위하여 데이터들의 해시 코드를 이용하여 보다 빠르고 신속하게 데이터들의 유사 여부를 판단하는 텍스트 해싱 방법을 제공하는 효과를 가질 수 있다."}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 개시되어 있는 본 발명의 개념에 따른 실시 예들에 대해서 특정한 구조적 또는 기능적 설명은 단지 본 발명의 개념에 따른 실시 예들을 설명하기 위한 목적으로 예시된 것으로서, 본 발명의 개념에 따른 실시 예 들은 다양한 형태들로 실시될 수 있으며 본 명세서에 설명된 실시 예들에 한정되지 않는다. 제1 또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용어 들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로 만, 예컨대 본 발명의 개념에 따른 권리 범위로부터 벗어나지 않은 채, 제1구성 요소는 제2구성 요소로 명명될 수 있고 유사하게 제2구성 요소는 제1구성 요소로도 명명될 수 있다. 본 명세서에서 사용한 기술적 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로서, 본 발명을 한정하 려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세 서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 본 명세서에 기재된 특징, 숫자, 단계, 동작, 구성 요소, 부분 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성 요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 도 1a는 일 실시예에 따른 변분 쌍별 지도 텍스트 해싱 방법(variational pairwise supervised text hashing : VPSH) 중 확률론적(stochastic) 방법(VPSH-ST)에 대한 블록도이다. 도 1b는 일 실시예에 따른 변분 쌍별 지도 텍스트 해싱 방법(variational pairwise supervised text hashing : VPSH) 중 결정론적(deterministic) 방법 (VPSH-DE)에 대한 블록도이다. 도 2는 각 훈련 시대마다 MSRP 데이터 세트에서 레이블 가중치 어닐링 없는 최악의 테스트 정확도 사례(The worst test accuracy case without label weight annealing in the MSRP dataset for each training epoch)를 도시한 것이다. 도 3은 레이블 가중치 어닐링이 있는 및 레이블 가중치 어닐링이 없는 각 훈련 시대에 대한 MSRP 데이터 세트의 정확도(Accuracy with the MSRP dataset for each training epoch with label weight annealing and without label weight annealing)를 도시한 것이다. 도 4는 확률론적 방법 및 결정론적 방법으로 각 훈련 시대에 대한 Quora 데이터 세트의 정확도(Accuracy with the Quora dataset for each training epoch with the stochastic method and the deterministic method)를 도시한 것이다. 도 1a 내지 도 4를 참조하여, 일 실시예 따른 전자장치 및 그 제어방법에 의해서 구현되는 기계학습 모델(방법) 알고리즘에 대해서 설명한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되 는 모든 용어들은 본 명세서에서 특별히 다른 의미로 정의되지 않는 한, 본 명세서에 개시된 기술이 속하는 분 야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 나타낸다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해 석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않아야 한다. 1. 소개 최근 들어, 웹 문서의 수가 급격히 증가하고 있다. 텍스트 데이터는 인터넷에서 가장 기본적인 데이터 유형이며 대량으로 존재한다. 텍스트 형식의 빅 데이터를 기반으로 하는 많은 응용 프로그램이 있다. 단어 임베딩의 출현 으로, 텍스트 데이터는 희소 원-핫 벡터 또는 고차원 데이터에 중점을 둔 것을 포함하여 다양한 연구에서 조사 되었다. 텍스트 데이터가 고차원 데이터가 되면서, 많은 문서 임베딩 접근법은 데이터의 크기를 줄이기 위해 문 서의 모든 단어를 고정된 크기의 표현으로 변환하는데 사용될 수 있다. 이 프로세스가 실행된 후의 텍스트 데이 터는 적은 양의 데이터로 표시될 수 있지만, 이 방법은 대규모 텍스트 데이터와 함께 사용할 수 있을 정도로 정 확하지 않다. 많은 응용 프로그램에서 대량의 텍스트 빅 데이터가 널리 보급되는 반면, 증가하는 관심은 계산 효율과 검색 품 질 수준이 모두 개선된 텍스트 데이터의 근사치 (approximate nearest neighbors : ANN) 검색에서 작동하는 것 에 쏠렸다. 최소 이진 코드들(compact binary codes)의 계산 및 저장 효율성으로 인해 해싱은 텍스트 ANN 검색 에 적합한 해결책이며, 이는 이 방법이 고차원 데이터를 최소 이진 코드로 변환하고 유사한 데이터 항목에 대해 유사한 이진 코드를 생성할 수 있기 때문이었다. 크기가 작은 해시 코드를 사용하면, 대량의 텍스트 데이터에서 가장 가까운 이웃을 실시간으로 결정할 수 있다. 해싱 방법은 크게 데이터 종속적 접근과 데이터 독립적 접근 방식으로 나눌 수 있다. 데이터 독립적 접근 방식 에서, 잘 알려진 locality-sensitive hashing(LSH) 접근 방식은 해시 함수가 일반적으로 무작위로 생성되어 어 떤 훈련 데이터와도 독립적으로 만들어지기 때문에 사전 훈련 데이터 세트가 없는 경우에 유용하다. 데이터 종 속적 접근 방식은 훈련 데이터를 활용하여 해싱 함수를 배우려고 시도한다. 최근에는 딥 러닝에서 해싱에 이르 는 분야에서 특징 표현과 해시 코드들 모두는 딥 뉴럴 네트워크를 사용하여 보다 효과적으로 학습될 수 있는 것 이 나타났다. 데이터 종속적 텍스트 해싱 방식은 일반적으로 클래스 레이블 데이터로부터 해시 함수를 학습한다. 이러한 접근 방식에서 평가 지표(metric)는 쿼리 문서와 동일한 레이블을 가진 100 개의 검색된(retrieved) 문서 중 문서의 백분율이다. 이 평가 지표는 동일한 클래스 데이터의 결과를 적절히 시뮬레이션 할 수 있지만, 실제 어플리케이션에서는, 쌍별 레이블 데이터를 사용하는 것이 요구 사항을 고려할 때 더 적합하다. 예를 들어, 질의 응답 시 스템에서, 사용자에 의해 새로운 질문이 제출될 때, 시스템은 동일한 클래스의 질문 대신 의미적으로 유사한 질 문을 찾으려고 시도한다. 의미론적 유사도는 종종 말뭉치에 쌍별 레이블로 표시된다. 의역 식별 데이터 세트 (paraphrase identification dataset)는 전형적인 쌍별 레이블된 데이터 세트입니다. 2개의 기사들(articles) 이 의미론적 중복(duplicate)이라면, 이 데이터 세트들은 1의 태그가 할당되고 의미론적으로 중복이 아니라면 0 의 태그가 할당된다. 이는 태그가 지정된 클래스 레이블과 하나의 기사가 본질적으로 다른 것을 나타냅니다. 많 은 실제 사례에서 ANN 검색을 배우기 위해 쌍별 정보를 사용하는 것이 더 의미가 있다. 본 발명의 일 실시예에 따른 기계학습 모델은, 최소 이진 텍스트 해싱 함수를 학습하기 위해 쌍별 레이블 정보 를 활용하는 변분 쌍별 지도로 지정된 텍스트 해싱 (variational pairwise supervised text hashing: VPSH) 방 법을 제안할 수 있다. 또한, 본 발명의 일 실시 예에 따른 기계학습 모델은 다음과 같은 목적을 가질 수 있다. 첫째, 일 실시 예에 따른 기계학습 모델은 성능을 개선하기 위해 쌍별 레이블 정보를 학습하는 최초의 VAE 기반 쌍별 지도 텍스트 의미론적 해싱 방법(pairwise supervised text semantic hashing method)을 제안할 수 있다. 둘째, 일 실시 예에 따른 기계학습 모델은 잘 알려진 쌍별 레이블된(분류된) 말뭉치(corpus)에 대한 소형 이진 코드를 배우는 방법을 제안할 수 있다. 일 실시 예에 따른 기계학습 모델은 종래의 해싱 접근 방식 보다 우수한 것으로 나타났다. 마지막으로, 일 실시 예에 따른 기계학습 모델은 쌍별 레이블 정보를 배우고 실험 평가를 통해 그 효율성을 입 증할 수 있도록 레이블 가중치 어닐링 기술을 제안할 수 있다. 이하에서 섹션 2에서 이전 해싱 접근 방식을 검토하고, 섹션 3에서 본 발명의 일 실시 예에 따른 기계학습 모델 로서 의미론적인 텍스트 해싱 방식을 제안하고, 섹션 4에서 본 발명의 일 실시 예에 따른 기계학습 모델과 이전 해싱 접근 방식의 실험 결과를 설명한다. 2. 이전 해싱 접근 방식(Related Work) 의역 식별 작업(paraphrase identification task)은 텍스트 데이터의 쌍별 레이블링을 처리하는데 사용되는 가 장 일반적인 작업 중 하나이다. 이 작업에서 한 문장이 다른 문장의 의역이면 레이블이 1이고 그렇지 않으면 레 이블이 0이다. 가장 가까운 이웃 텍스트 검색 문제의 경우, 의미론적으로 유사한 텍스트를 찾는 것이 실제로는 의역-식별 작업(paraphrase-identification task)이다. 이 문제와 관련하여 많은 딥 러닝 모델이 제안되었다. 이러한 작업은 일반적으로 복잡한 신경망 구조를 사용하여 모델을 작업에 더 일관성 있게 만들고 예측 정확도를 높입니다. 그러나 모델이 점점 더 복잡해진다. 모델을 단순화하기 위해, 의역 식별을 위한 잠재 변수 모델이 연 구되었다. 이 방법은 컨볼루션-디컨볼루션 오토 인코더를 사용하여 반-지도 학습에 대한 문장 표현을 유추한다. 새로운 인코더-디코더의 힘으로 이 모델은 제한된 양의 레이블이 지정된 데이터와 잘 작동한다. 그럼에도 불구 하고, 이것들은 모두 결과를 계산하기 위한 입력으로 원시(raw) 텍스트 데이터의 2개의 예들(instances)을 사용 한다. 많은 양의 데이터가 있어 시간이 많이 걸리는 작업이 되더라도 대량의 데이터에 대해서도 예측이 정확할 수 있다. 큰 데이터 세트에 대한 실시간 ANN 검색을 실행하는 것은 실용적이지 않다. 최소 이진 코드의 계산 및 저장 효율성 수준으로 인해, 해싱이 ANN 검색에 널리 사용되었다. LSH 및 스펙트럼 해싱(Spectral hashing)과 같은 전통적인 데이터 해싱 방법이 널리 사용되었다. 클래스 레이블 또는 상대 유사 도와 같은 지도된 정보를 사용할 수 있는 경우 지도된 해싱 방법이 더 좋다. 지도 해싱은 해싱 함수를 배우는 데 필요한 정보를 활용하는 데에도 사용되었다. 신경망의 부활과 함께, 딥퍼 러닝 모델이 해싱에 사용되었다. 이러한 방법은 일반적인 고차원 데이터 또는 이미지 데이터에 적용될 수 있다. 그러나 텍스트 키워드 벡터 공간에서 직접 사용하는 경우 그들은 일반적으로 원래(original) 텍스트와 관련하여 의미론적 유사도를 완전히 포착하지 못한다. 따라서 많은 텍스트 해싱 방법이 제안되었다. 처음에는 해시 함수 를 배우기 위해 오토-엔코더(autoencoder)를 사용한 텍스트 의미론적 해싱이 개발되었다. 이 방법은 입력 텍스 트 단어 수 데이터를 모델링 할 수 있는 이진 단위를 학습하기 위해 여러 개의 볼츠만(Boltzmann) 머신을 구축 한다. 학습 후에는 가장 깊은 레이어의 출력을 임계 값으로 지정하여 모든 문서의 이진 해시 코드를 얻는다. 또 한 여러 연구에서 단어 임베딩을 통해 텍스트 해싱을 위한 CNN (Convolutional Neural Network)의 힘을 탐색했 다. 최근에, 확률론적 생성 모델은 많은 관심을 끌었다. 변분 오토-인코더 (variational auto-encoder : VAE)는 변 이 추론(variational inference)을 딥 신경망과 결합하기 때문에 생성 모델링을 위한 매력적인 프레임 워크이다. VAE는 딥 러닝 및 확률적 생성 모델의 장점을 모두 얻을 수 있다. VAE는 특히 이미지 데이터와 함께 많은 문제에서 최첨단 성능을 달성한다. 자연어 처리 영역에서, 신경 답변 선택 모델 (neural answer selection model : NASM)은 텍스트의 조건부 모델에 대한 일반적인 변형 추론 프레임 워크이다. 이 모델은 질문과 답변 쌍 사이의 의미를 추출할 수 있다. 질문 및 답변 텍스트 데이터를 입력으로 사용하여 해시 코드 대신 관계 결과를 계산하지만, 이 모델은 대량의 데이터를 처리하기에 적합하지 않다. 텍스트 해싱의 경우, 텍스트 해싱 프로세스 동안 문서에서 각 내용을 보존하기 위해 비 지도 및 지도 변형 심층 의미론적 해싱 (variational deep semantic hashing : VDSH) 방법이 개발되었다. 이러한 접근 방식은 VAE 프레임 워크를 사용한다. 그러나 VDSH는 의미론적 텍스트 해싱의 정확성을 향상시키기 위해 범주 형(categorical class) 클래스 레이블 데이터 만 사용한다. 이전 해싱 방법에서는 쌍별 레이블 데이터가 사용되지 않았다. 3 제안 방법(Proposed Method) 3.1 VAE를 사용한 텍스트 해싱 x는 입력 텍스트를 나타내고 z는 주어진 입력 텍스트의 해시 코드를 나타낸다. z는 n의 실수 값 또는 이진 코드 를 갖는다. 또한 n을 비트 수라고 할 수 있다. VAE의 인코딩 프로세스는 문서 x에서 z를 추론하는 반면, VAE의 디코딩 프로세스는 잠재 변수 z에서 x를 재구성하는 것이다. 직관적으로 잠재 변수(latent variabl)는 x의 주요(key) 의미론적 특징들(features)을 캡처한 것으로 코퍼스 (corpus)로부터 학습한다. 해시 함수는 인코딩 p (z | x)의 분포이다. 이전의 모든 연구는 코퍼스로부터 이 분 포를 배우려고 시도했다. x를 문서의 백오프워드(bag-of-words) 표현으로 보자. x의 길이는 | V |이며, 여기서 V는 코퍼스에 나타난 단어의 어휘이다. TF-IDF 체계는 x 표현의 무게 측정에 사용된다. 의미론적 텍스트 해싱을 위한 VAE의 최근 발전은 지도된 텍스트 해싱에서 모델의 효과를 입증했다. 이 모델에서, 근사 인코딩 분포는 qφ (z | x)이고 디코딩 분포는 qθ (x | z)이며, 여기서 φ 및 θ는 각각 인코더 및 디코더의 파라미터이다. VAE 프 레임 워크에 기초하여, 우리는 한계(marginal) 분포 대신 변동 하한(variational lower bound)을 최대화한다. 마지막으로 텍스트 해싱의 목적 함수는 다음의 수식과 같다."}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "Kullback-Leibler(KL) 발산 DKL은 사후(posterior) 분포 qθ (z | x)와 이전(prior) 분포 p (z)를 커버한다. 여 기서, VDSH의 p (z)는 다변량(multivariate) 표준 분포이다. 이 모델(이전 분포)은 사후 분포 qθ (z | x)의 근 사치이고, 이것은 신경망의 도메인에서 전형적으로 φ에 의해 매개변수화된(parameterized) 인코더의 출력으로 서 평균 μ 및 분산 σ2를 갖는 가우스 N (μ, σ2) 분포인 것으로 가정된다. 인코더 출력으로부터 해시 코드 z를 결정하기 위해 N (μ, σ2)으로부터 z를 샘플링할 수 있다. 그러나, 샘플링 동작은 그레디언트(gradient)를 유발하지 않을 수 있고, 이는 신경망을 훈련시킬 수 없게 만든다. 실제로, 우리 는 구분할 수 없는(non-differentiable) 샘플링 동작을 네트워크 밖으로 전환하게 하기 위해 재파라미터화 (reparameterization) 트릭을 사용할 수 있다. 이러한 트릭의 동작은 도 12a 및 도 12b에서 μ1 및 σ1에서부터 z1까지의 점선으로 표시된다. 이 트릭은 초기에 샘플링 ε ~ Ｎ (0, 1)을 수행한 후 다음의 수식와 같이 z1의 샘플링 작업을 구현한다."}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "해시 함수가 랜덤성을 적절하게 처리할 수 없기 때문에 μ를 해시 코드로 간주한다는 것을, 추론과정에서 유의 해야 한다. 3. 2 쌍별 지도 해싱 지도 학습을 위해, 이전의 연구들은 범주형 레이블 정보 y를 활용한다. 범주형 레이블 정보의 경우, 최소 식별 손실(minimizing discriminate loss) p (y | z)을 직접 추가할 수 있고 레이블 가중치 Wlabel을 사용하여 이것 (지도 학습)의 영향(influence)을 제어할 수 있다. 지도 해싱은 학습에 의해 유사한 문서의 해시 코드가 유사해 지도록 활용된다. 범주형 레이블 정보를 사용하는 이전 작업들은 동일한 범주에서 문서가 유사한 해시 코드를 갖도록 단순히 허용한다. 텍스트 데이터에서, 쌍별 레이블 정보는 두 텍스트들 사이의 유사도 또는 관계를 표시하는 가장 직접적인 방법 을 포함해야 한다. 여기서, 이 데이터 세트는 유사한 컨텐트 또는 또다른 의미론적 관계로 표시되어 있기 때문 에 해시 함수를 학습하기 위해 보다 직접적인 쌍별 레이블 정보를 사용한다. 우리는 공동(joint) 식별된 쌍별 목적 관점으로부터 의미론적 텍스트 해싱에 접근한다. x1 및 x2를 2개의 입력 텍스트들로 하고, z1 및 z2는 이러한 입력들의 해시 코드를 각각 나타낸다. 이 경우, 상 기의 수식 은 다음과 수식 과 같이 확장될 수 있다."}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "매개변수들 φ 및 θ는, 도 12a 및 도 12b에 도시된 바와 같이, x1 및 x2 처리를 위해 공유된다. 또한, 이 방법 에서 p(z1) 및 p(z2)는 다변량 표준 분포들이다. 쌍별 지도 해싱의 경우, 여기서 목표는 분포 p (y | z1, z2)를 다루는 것으로, y는 텍스트 x1 및 x2의 레이블 정 보이다. 레이블 정보는 이진(y는 0 또는 1)이라고 가정한다. 모델이 변동 하한 및 식별된 목적의 균형을 맞추게 하기 위해, 토탈 목적 (함수)은 다음의 수식 와 같다."}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서 Wt는 지도 영향을 제어하는 레이블 가중치이다. 디코더의 입력은 잠재 변수 분포의 샘플이며, 이는 인코더 출력에 의해 매개변수화된다. 도 12a에 도시된 바와 같이, 판별기(discriminator) 객체들로서 z1 및 z2를 직접적으로 비교하는 것이 가능하다. 생성된 해시 코드가 유사한 특성을 갖기 위해, 직접적으로 판별기 상에서 z1 및 z2 사이의 유사도를 사용할 수 있다. z1 및 z2는 N(μ1, σ12) 및 N (μ2, σ22)으로부터의 샘플링 결과로 간주될 수 있기 때문에 이 방법은 확률론적이 라고 언급된다. 이 방법의 손실 함수는 다음의 수식 와 같다."}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서 z1 및 z2는 길이 n을 갖는 실수 값(real value) 벡터들 일 수 있고, sim( )은 두 입력들의 유사도 함수 (similarity function)이다. 이 작업에서, 유사도 함수가 실제 요건에 따라 실제는 다를 수 있지만, 코사인 유 사도를 사용할 수 있다.상기 수식 로 표현된, 재매개변수화 트릭에 따라, Llabel은 다음과 같이 정의될 수 있다."}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "즉, 확률론적 방법은 인코더의 모든 출력들(μ1, μ2, σ1, σ2)을 활용한다. 이전의 지도 의미론적 텍스트 해싱 방법에서, 완전히 연결된 소프트맥스(softmax) 레이어는 해시 코드 z 및 레 이블 정보 y를 매핑하는데 종종 사용되었다. 본 발명의 일 실시 예에 따른 기계학습 모델에는 두 개의 z 변수들 이 있다. 따라서, 소프트맥스 레이어의 입력으로서 z1 및 z2만 연결하는(concatenate) 경우, z1 및 z2는 서로 유 사하지 않을 것이다. 텍스트 해싱의 추론 동안, 인코더의 출력에서 해시 코드 z는 μ이다. 따라서, μ1 및 μ2 사이의 유사도를 지표 (indicator)로서 사용할 수도 있다. 결정론적(deterministic) 방법은, 도 12b에 도시된 바와 같이, μ1 및 μ2 사이의 유사도를 계산하는 또 다른 접근법이다. 이 경우에서 μ1 및 μ2는 샘플링 동작 전의 값들이므로, 유사도 가 인코더 매개변수에 더 직접적으로 반영된다. 이 방법의 손실 함수는 다음의 수식 과 같다."}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "3. 3 레이블 가중치 어닐링(Label Weight Annealing) KL 비용(cost) 어닐링은 소실 잠재 변수(vanishing latent variable) 문제를 다루는 간단한 접근법이다. 이 문 제는 디코더가 의미있는 정보를 인코딩하지 못하는 간단한 VAE들로 종종 이어집니다. 이 KL 비용 어닐링 테크닉 은 훈련 과정 동안 KL 발산의 가중치를 0으로부터 1로 증가시킨다. KL 비용 어닐링 방법을 사용할 때, 쌍별 유 사도의 추가로 비슷한 문제가 또한 야기된다. 유사도는 훈련 도중 다른 경우들에 비해 수렴하기 쉬워지고, 본 발명은 이러한 문제를 해결하기 위해 레이블 가중치 어닐링을 테크닉을 제안한다. 이 레이블 가중치 어닐링 테 크닉은 가장 적절한 지도 학습을 얻기 위하여 훈련 도중에 레이블 정보 가중치를 제어한다. KL 비용 어닐링에서 KL 비용 가중치와 유사하게, 상기 수식 의 Wt는 쌍별 지도 영향의 효과를 제어하는 레이 블 가중치이다. KL 비용 가중치는 훈련 단계 0에서 0으로부터 증가한다. 그러나, 레이블 가중치 어닐링 동안 레 이블 가중치 (Wt)는 KL 비용 어닐링과 동일하지 않으며, 반드시 훈련의 시작부터 증가할 필요는 없다. 잠시동안 훈련 후에 기 설정된 시간(tstart)부터 증가할 수도 있다(수식 ):"}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서, tstart는 훈련 동안 레이블 가중치의 증가가 시작하는 단계이고 c는 각 단계 t에서 증가의 비율이다. tstart 값은 비지도(unsupervised) 학습의 영향에 따라 결정된다. 예를 들어, 과도한 비지도 학습이 성능을 저하 시키는 경우, tstart 값을 더 작게 설정한다. 지도 학습의 영향이 비지도 학습에 대한 보충일 뿐인 경우, tstart의 값을 더 크게 설정한다. C 값은, 지도 학습 및 비지도 학습이 동시에 수행되는 경우 지도 학습이 비지도 학습을 파괴할 지 여부를 고려 하여 결정한다. 그 것(비지도 학습)이 파괴되는 경우, c는 이러한 충돌을 최소화하기 위해 더 작아야 한다. 비 트 수 n이 클 때 c는 큰 값을 가져서는 안된다는 것을 보여준다. 유사도의 수렴이 다른 경우들과 완전하게 다르기 때문에, 처음부터 큰 가중치로 레이블 정보를 학습하는 것은 이 방법을 훈련 동안 초기 변수에 의존하게 할 것이다. 초기 값이 다소 낮으면 전체 훈련 과정에 치명적일 수 있다. 4. 실험 4. 1 데이터 세트 세부사항 본 발명의 일 실시 예에 따른 기계학습 모델의 효과를 입증하기 위해서, 훈련 및 평가를 위한 두 가지 작업에서 세 가지 표준 공개 데이터 세트를 사용한다. 먼저, 바꾸어 표현하기(paraphrase, 또는 의역) 식별 작업 동안 본 발명의 일 실시 예에 따른 모델의 결과를 다 른 모델들의 결과들과 비교한다. 이 (의역 식별) 작업은, 자연어 이해에서 기준(touchstone)으로 간주되는 문제 로서, 두 문장들의 바꾸어 표현하기를 결정하는 것을 목표로 한다. MSRP(Microsoft Research Paraphrase Corpus) 데이터 세트는 훈련을 위한 4,076쌍의 문장과 테스트를 위한 1,725쌍의 문장을 포함하는 대중적인 기준(benchmark)이다. 인간의 주석이 있는 각 텍스트 쌍은 각 쌍이 바꾸어 표현하기/의미론적 등가 관계를 캡처하는지 여부를 나타낸다. Quora Question Pairs4 데이터 세트는 수많은 질 문 쌍을 포함하고, 각 질문은 2개의 질문이 서로 바꾸어 표현한 것인지 여부를 나타내는 이진 값이 주석으로 표 시되어 있다. 보다 구체적으로, 이 데이터 세트는 훈련을 위한 384,348쌍의 문장과 테스트를 위한 10,000쌍의 문장으로 구성된다. 이러한 데이터 세트에서 이 알고리즘의 정확도 성능을 측정한다. 또한 후보 답변 순위 작업에 대해 본 발명의 일 실시예에 따른 방법을 평가한다. WikiQA는 공개-도메인 질문-답 변 데이터 세트이다. 이 (후보 답변 순위) 작업은 질문에 대한 관련성에 기초하여 후보 답변들의 순위를 정하는 것이다. 이 경우에서 질문과 답변 쌍은 일반적으로 이해되는 것과 유사한 쌍이 아님이 중요하다. 질문과 정확한 답은 종종 같은 단어를 갖지 않으며, 질문과 정확한 답은 같은 의미를 갖지 않는다. 부정적인 표본 효과로 인해, 질문에 대해 적어도 하나의 정답이 있다고 가정한다. 필터링 후, 대응하는 데이터 세트는 훈련을 위한 20,360 쌍의 질문-답, 및 테스트를 위한 2,352 쌍의 질문-답으로 구성된다. WikiQA 상에서 사용되는 성능 측정 값은 평균 평균 예측(mean average precision, MAP) 및 평균 쌍곡선 계수(mean reciprocal rank, MRR)이다. 4. 2 기준 및 설정 비교를 위해 다음 기준들을 추가로 평가한다: LSH(Locality Sensitive Hashing), Spectral Hashing (SpH), Variational Deep Semantic Hashing(VDSH). 이전의 지도 방법들은 쌍별 레이블 정보를 활용하지 않기 때문에, 이러한 방법들과 성능을 비교하지 않는다. Adam optimizer는 VAE에서 널리 사용된다. 0.001의 학습 속도로 Adam optimizer를 사용하고 10,000 단계마다 0.96의 계수(factor)로 학습 속도 지수 감쇠(learning rate exponential decay)를 사용한다. 대규모 데이터 세 트의 경우, 빠른 훈련을 위한 Quora에서 학습 속도를 0.08로 설정한다. 또한 초과-피팅을 완화하기 위해 0.9의 값으로 드롭아웃(dropout) 테크닉을 사용한다. 드롭아웃은 딥 러닝에서 기본적으로 표준이 되었다. 텍스트 해싱에 기반한 VAE 및 같은 데이터 세트를 이용하는 다른 여러 모델들이 공통적으로 0.9에서 드롭아웃을 사용한다는 것을 발견했다. 따라서, 동일한 값을 사용했다. 확률론적 방법과 결정론적 방법에 대해 상기 수식 에서 시작 레이블 가중치 매개변수 tstart를 각각 40 및 30으로 설정했다. 모든 실험들은 Tensorflow에서 구현되며, Intel i7-6850K CPU, NVIDIA GeForce GTX TITAN X GPU 및 16GB의 메 인 메모리가 장착된 서버에서 수행된다. 4. 3 바꾸어 표현하기(의역) 식별 작업 이 의역 식별 작업에서, 모든 방법은 훈련 문장을 이진 코드로 변환하고, 훈련 데이터 세트의 레이블 정보는 유 사도의 최적 임계 값을 학습하는 데 사용된다. 테스트에서, 한 쌍의 문장의 유사도가 상기 임계 값을 초과하면, 바꾸어 표현하기로서 상기 문장 쌍을 예측한다. 따라서, 기준(baselines)은 이진 코드의 구성(construction) 동 안 훈련 세트 레이블 정보에 적용되지 않지만, 레이블 정보 데이터는 바꾸어 표현하기의 판단의 과정 동안 참조 된다. 표 1 및 표 2는 본 모델의 결과와 Quora 및 MSRP의 기준을 보여준다.표 1"}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "표 2"}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "표 1을 참고하면 Quora 데이터 세트에서, 본 발명의 일 실시예로서 제안된 VPSH-ST 및 VPSH-DE 방법은 다양한 비트 수에서 기준을 능가한다. 모두 훈련 세트의 레이블 정보를 사용하지만, 본 발명의 일 실시 예에 따른 방법 들은 Quora 데이터 세트에서 다른 방법보다 훨씬 잘 작동하여, 본 발명의 일 실시 예에 따른 모델이 유익하고 의미있는 해싱 코드로 문서를 효과적으로 할당할 수 있음을 나타낸다. 본 발명의 일 실시 예에 따른 두 방법(VPSH-ST, VPSH-DE)을 비교하면, 확률론적 방법이 결정론적 방법보다 더 효과적이라는 것을 알 수 있다. 충분한 수의 훈련 세트를 사용하면, μ 및 σ를 사용한 확률론적 방법이 잠재 변수 분포로부터의 평균값 μ만 있는 결정론적 방법보다 낫다는 것을 나타낸다. 표 2를 참조하면 MSRP 데이터 세트에서, 본 발명의 일 실시예에 따른 VDSH 및 VPSH-ST 방법은 다양한 비트 수에 서 기존 LSH 및 SpH 방법들보다 나쁘다. 이는, 주로 결과 훈련 정보 문제로 인해, VAE 기반 방법이 이러한 데이 터 세트에서 완전히 훈련되지 않았음을 나타낸다. 훈련 세트의 부재에서, 더 많은 잠재 변수를 설정하는 경우, 불량한 훈련 세트는 모델 훈련을 성공적으로 수행할 수 없다. MSRP 데이터 세트에는 훈련을 위한 단지 4,076 쌍의 문장을 가지고, 여기에 사용된 bag-of-words 표현 방식은 단어 순서를 무시한다. 본 발명의 일 실시 예에 따른 VPSH-DE 방법은 32 비트 및 64 비트에서 기준을 능가하는 반면, 본 발명의 일 실시 예에 따른 VPSH-DE 방법을 사용할 때 다른 수의 비트를 사용하면 LSH보다 정확도가 나쁘다. 따라서, 훈련 정보가 부족한 때, VPSH-DE가 VDSH 또는 VPSH-ST 보다 훈련하기 더 쉽다. 두 개의 데이터 세트로 결과를 비교하면, 대량의 훈련 데이터는 확률 생성 모델이 더 안정적인 매개변수를 학습 하게 하므로, 본 발명의 일 실시예에 따른 모델이 큰 데이터 세트(Quora)에서 더 잘 작동한다는 것을 알 수 있 다. 이미지 데이터와 비교할 때, 텍스트 데이터에서 훈련 정보는 극히 드물다. 요컨대, 많은 양의 훈련 데이터 로, 본 발명의 일 실시예에 따른 방법은 쌍별 정보를 학습하는데 적합하다. 4.4 후보 답변 순위 작업(Candidate Answer Ranking Task) WikiQA 데이터 세트에서, 후보 답변은 2개의 이진 코드들 해밍(hamming) 거리에 따라 순위가 결정된다. 이 (후 보 답변 순위) 작업에서, MAP 계산은 정렬에 대한 신뢰도 값을 요구하며, 기준(baseline)은 이 (후보 답변 순위) 작업에서 훈련 데이터를 간접적으로 활용할 수 없다. 섹션 3.2에 설명된 확률론적 방법 VPSH-ST 및 결정 론적 방법 VPSH-DE을 테스트한다. 앞에서 언급했듯이, WikiQA 데이터 세트에서 질문과 답변은 의미론적으로 유사하지 않을 수 있다. 따라서, 지도 학습을 너무 많이 수행하면 모델이 정확한 훈련으로부터 빗나갈 수 있다. 이 데이터에서 tstart에 작은 값을 할당 하여 본 방법이 가능한 한 빨리 쌍별 레이블 정보를 도입하도록 한다. 표 3"}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "표 4 표 3 및 표 4는 본 발명의 일 실시예에 따른 방법의 MAP 및 MRR 결과, 및 WikiQA 데이터 세트의 기준을 보여준 다. 먼저, 본 발명의 일 실시예에 따른 두 가지 방법이 기준(baseline) 해싱 방법보다 훨씬 낫다는 것을 관찰했 다. 이는 본 발명의 일 실시예에 따른 방법이 쌍별 데이터 세트로부터 질문-응답 관계를 캡처할 수 있음을 나타 낸다. 더 중요한 것은, 후보 답변 순위 작업에서 최근의 접근법의 MAP 결과는 0.7069로 알려져 있다. 이것은 본 실험 결과와 크게 다르지 않다. 본 해싱 방법은 상당한 MAP 감소 없이 계산 시간 규모와 저장 공간을 변경할 수 있다. 두번째로, 본 발명의 일 실시예에 따른 VPSH-ST는 64 비트, 128 비트 및 256 비트에서 본 발명의 일 실시예에 따른 VPSH-DE보다 낫고, 이는 VPSH-DE 방법이 상대적으로 적은 비트에서 잘 작동함을 나타낸다. 한편, 비트 수 가 증가함에 따라 VPSH-ST 방법이 더 낫다. 후보 응답 순위 과제에서 VPSH-ST 방법과 최근의 접근법의 차이는 비트 수가 더 클수록 더 작아질 것으로 보인다. 마지막으로, VDSH 및 VPSH-DE는, 아마도 모델 오버 피팅으로 인해, 비트 수가 증가함에 따라 성능이 항상 향상 되는 것은 아니다. 이것은 긴 해시 코드를 사용이 이러한 방법들의 결과가 항상 향상되는 것은 아니라는 것을 제안한다. 이러한 결과들은 VPSH-ST가 오버 피팅을 방지하는 데 더 도움이 된다는 것을 보여준다. 4. 5 레이블 가중치 어닐링의 효과 단순한 방식으로 지도 학습을 적용하는 것은 실제로 예상보다 나쁘다. 도 13은 소량 데이터 세트 (MSRP)에서 레 이블 가중치 어닐링이 없는 최악의 테스트 정확도 케이스(사례)를 보여준다. 레이블 가중치 어닐링이 없는 케 이스에서 레이블 가중치 Wt는 어닐링이 있는 케이스에서 최대 값과 동일하도록 설정하는 상수 값이라는 것을 참 고해야 한다. 유사도의 정도는 가중치 초기화 상에 크게 의존한다. 도 13에 도시된 바와 같이, 약간 잘못된 시 작 및 공동 학습 쌍별 레이블은 훈련의 종료까지 정확도를 높이지 않을 것이다. 즉, 레이블 가중치 어닐링 테크 닉이 없는 경우, 본 발명의 일 실시예에 따른 방법은 아주 잘 학습하지는 못할 확률이 있다. 도 14는 레이블 가중치 어닐링을 사용할 때 및 레이블 가중치 어닐링을 사용하지 않을 때의 최상의 케이스들의 레이블 가중치 어닐링 테크닉의 비교 결과를 보여준다. 레이블 가중치 어닐링이 있는 경우, 본 실험에서 tstart는 40이며, 정확도는 40 에포크(epoch, 시대)에서 증가하기 시작한다. 이 테크닉이 없으면, 본 발명의 일 실시예에 따른 방법은 처음 몇 에포크에서 최고의 정확도를 달성하는 반면, 후속하는 훈련 동안 본 발명의 일 실시예에 따른 모델의 정확도는 점차 감소한다. 이러한 모든 관찰은 레이블 가중치 어닐링 테크닉이 더 많은 쌍별 레이블 정보를 용이하게 한다는 것을 나타낸다. 4.6 확률론적 vs 결정론적 제안된 두 가지 방법들을 보다 직관적으로 비교하기 위해, 도 5에 도시된 바와 같이, 큰 데이터 세트(Quora) 상 에서 훈련할 때 두 방법(확률론적 방법 및 결정론적 방법) 사이의 차이점을 제시한다. 두 방법 모두 레이블 어 닐링 테크닉을 사용하며, 본 실험에서 tstart는 30 epoch로 설정된다. 30 에포크 이전에 두 방법 사이에는 차이가 없음을 관찰한다. 쌍별 레이블 손실이 30 에포크부터 추가될 때, 확 률론적 방법이 결정론적 방법보다 명백하게 낫다. 앞서 언급했듯이, 확률론적 방법은 잠재 변수의 확률 분포에 서 무작위로 선택된 값을 사용하는데, 이는 훈련 세트가 작을 때 문제가 될 수 있다. 훈련 세트가 충분히 클 때, 확률론적 방법은 오버 피팅을 효과적으로 방지할 수 있다. 훈련 데이터의 크기가 확률론적 또는 결정론적 방법의 성능에 영향을 미치는지 여부를 결정하기 위하여, 여러 비교 실험을 수행했다. 많은 양의 훈련 데이터가 있는 확률론적 방법이 더 우수하지만, 적은 양의 훈련 데이터 가 있는 확률론적 방법 및 결정론적 방법 사이에는 큰 차이가 없다. 결정론적 방법은 인코더에서 유사성을 보다 직접적으로 캡처할 수 있음으로 인해 수렴을 더 쉽게 보여준다. 대량 훈련 세트 상에서, 빠른 수렴 기능은 모델 이 로컬 최적으로 떨어질 수 있게 한다. 4. 7 사례 연구 표 5는 Quora 데이터 세트 상에서 각 해싱 방법에 대한 입력 문장들 및 예측 레이블의 일부 예들을 보여줍니다. 먼저, 표 5의 예 1과 2와 같이, 두 문장들이 공통된 단어를 몇 개만 가지면, 이전의 해싱 방법은 False를 예측 한다는 것을 발견했다. TF-IDF 웨이트 체계는 이러한 동일한 단어들을 키워드로서 취급하지 않으므로, 이러한 단어들의 웨이트는 높지 않다. 이러한 경우에서, 이전의 방법은 부정확하게 수행되고 0의 레이블이 할당될 수 있다. 둘째, 두 문장이 더 높은 정도의 단어 중첩을 갖는 경우 이전의 해싱 방법은 True를 예측한다는 것을 발견했 다. 표 5의 예 3에서, 첫 번째 문장에서의 필리핀어(philippines) 단어가 두 번째 문장에서 노르웨이어(norway) 단어로 대체되는 경우 두 기사의 유사도가 높다. 따라서, LSH와 SpH는 이 예에 대해 1의 값을 할당한다. 표 5의 예 4에서, 두 번째 문장은 첫 번째 문장에 여러 단어를 추가한다. 이 유형의 예는, 예 3과 유사하게, 두 문장의 유사도를 매우 높일 수 있다. 일반적으로, 어휘는 문장 길이보다 길고, bag-of-words 표현은 매우 드문 표현이다. 이 표현으로부터 해시 함수를 학습할 때, 오버랩은 매우 강력한 기능이 된다. 본 발명의 일 실시예에 따른 VPSH 방법은 보상 수단으로서 많은 거짓 예들을 직접적으로 사용할 것이고, 이는 예 3 및 예 4에서 거짓의 결과를 정확하게 반환할 것이다. 표 5"}
{"patent_id": "10-2019-0151718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "5. 결론 본 발명의 일 실시예에 따른 기계학습의 모델은, 쌍별 레이블 정보를 이용하는 신규한 의미론적 텍스트 해싱 방 법을 제시한다. 보다 구체적으로, 본 발명의 일 실시예에 따른 방법은 보다 직접적인 방식으로 레이블 정보를 학습할 수 있다. 본 발명의 일 실시예에 따른 방법에서, 해싱 함수는 쌍별 레이블 정보를 캡처하기 위하여 보다 유익한 해시 코드들을 생성할 수 있다. 본 발명의 일 실시예에 따른 방법에서, 이 이진 해시 코드를 사용하여, 제안된 방법의 유효성을 다른 최근의 접근법들의 성능과 비교한 실험을 통해 확인했다. 또한 본 발명의 일 실시 예에 따른 방법에서, 쌍별 레이블 정보를 보다 효율적으로 해시 코드에 통합하기 위한 레이블 정보 어닐링 테크 닉을 제안한다. 도 5는 일 실시 예에 따른 데이터 사이의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치 의 제어 방법의 흐름도를 도시한 것이다. 도 5를 참고하면, 일 실시 예에 따른 전자 장치의 제어 방법은, 기계학습 모델을 훈련하는 과정(S200), 학습된 기계학습 모델을 평가하는 과정(S400), 학습된 기계학습 모델을 이용하여 데이터를 분석하는 과정(S600) 중 적 어도 하나를 포함할 수 있다. 훈련 과정(S200)은 섹션 3에 소개된 기계학습 모델을 훈련시키는 내용에 관련되며, 평가 과정(S400) 및 분석 과 정(S600)은 섹션 4에 소개된 학습된 기계학습 모델을 평가하고 이용하여 데이터를 분석하는 내용에 관련된다. 한편, 훈련 과정(S200) 및 평가 과정(S400)은 후술한 데이터 학습부에 의해서 수행될 수 있다. 또한, 분 석 과정(S600)은 후술한 데이터 인식부에 의해서 수행될 수 있다. 자세한 사항은 후술하도록 한다. 도 6 및 도 7는 일 실시 예에 다른 데이터 사이의 의미론적 유사 여부를 분석하기 위한 기계학습 모델을 훈련하 는 방법의 흐름도를 도시한 것이다. 도 6을 참조하면, 기계학습 모델을 훈련하는 과정(S200)은, 훈련 데이터 세트를 이용하여 기계학습 모델을 훈련 하는 훈련 과정일 수 있다. 상기 훈련 과정(S200)은, 동일한 훈련 레이블 정보를 가지는 제1 훈련 데이터와 제2 훈련 데이터를 포함하는 상 기 훈련 데이터 세트를 획득하는 과정(S220), 상기 제1 훈련 데이터를 변분 오토 인코더(VAE)를 이용하여 훈련 하고, 상기 제1 훈련 데이터의 제1 훈련 잠재 변수(latent variable)를 결정하는 과정(S240), 상기 제2 훈련 데 이터를 상기 VAE를 이용하여 훈련하고, 상기 제2 훈련 데이터의 제2 훈련 잠재 변수를 결정하는 과정(S260), 상 기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수, 및 상기 제2 훈련 잠재 변수에 기초하여 손실 함수(loss function)을 결정하는 과정(S280) 및 상기 손실 함수에 기초하여 기계학습 모델을 학습하는 과정(S290)을 포함 할 수 있다. 과정 S220에서, 전자 장치는 외부 서버(미도시)로부터 수신된 혹은 메모리에 저장된 제1 및 제2 훈 련 데이터를 획득할 수 있다. 혹은 전자 장치는 외부 서버(미도시)로부터 수신된 쌍별 레이블 정보를 전 처리 과정 및 훈련에 사용된 데이터를 선택하여 제1 및 제2 훈련 데이터를 메모리에 저장할 수 있으며, 메모리에 저장된 제1 및 제2 훈련 데이터를 획득할 수 있다. 또한, 제 상기 섹션 3(제안 방법)의 x1 및 x2은 동일한 훈련 레이블 정보(y)를 가지는 제1 훈련 데이터, 제2 훈 련 데이터에 각각 대응될 수 있다. 과정 S240 및 S260에서, 전자 장치는 제1 및 제2 훈련 데이터를 VAE를 통해서 인코딩 및 디코딩을 수행할 수 있다. 인코딩 네트워크의 입력 값으로 각각 제1 및 제2 훈련 데이터를 입력하면 출력 값은 각각 제1 훈련 잠 재 변수 및 제2 훈련 잠재 변수로 결정될 수 있다. 디코딩 네트워크의 입력 값으로 각각 제1 훈련 잠재 변수 및 제2 훈련 잠재 변수를 입력하면 출력 값은 각각 제1 및 제2 훈련 데이터로 결정될 수 있다. 한편, 상기 섹션 3(제안 방법)의 z1 및 z2은 VAE를 이용하여 결정된 제1 훈련 데이터의 제1 훈련 잠재 변수 및 제2 훈련 데이터의 제2 훈련 잠재 변수에 각각 대응될 수 있다. 상기 제1 훈련 잠재 변수는 제1 훈련 데이터에 관한 제1 훈련 해시 코드 일 수 있다. 상기 제2 훈련 잠재 변수 는 제2 훈련 데이터에 관한 제2 훈련 해시 코드 일 수 있다. 또한, 제1 훈련 해시 코드와 훈련 레이블 정보를 쌍으로, 제2 훈련 해시 코드와 훈련 레이블 정보를 쌍으로 된 해시 테이블이 저장될 수 있다. 또는 제1 훈련 해 시 코드 및 제2 훈련 해시 코드와 훈련 레이블 정보를 쌍 별 레이블 정보로 해시 테이블에 저장될 수 있다. 해시 함수(hash function)는 임의의 길이의 데이터를 고정된 길이의 데이터로 매핑하는 함수이다. 해시 함수에 의해 얻어지는 값은 해시 값, 해시 코드, 해시 체크섬 또는 간단하게 해시라고 한다. 그 용도 중 하나는 해시 테이블이라는 자료구조에 사용되며, 매우 빠른 데이터 검색을 위한 컴퓨터 소프트웨어 에 널리 사용된다. 해시 함수의 질은 입력 영역에서의 해시 충돌 확률로 결정되는데, 해시 충돌의 확률이 높을 수록 서로 다른 데이터를 구별하기 어려워지고 검색하는 비용이 증가하게 된다. 해시 테이블은 키(key)-값(value) 쌍에서 key를 테이블의 배열의 인덱스로 저장하는 것이 아니라, key를 입력으 로 한 해시함수를 이용해서 해시코드를 계산하고, 해시코드를 배열의 인덱스로 사용하여 저장하는 방식이다. 해 시코드는 0부터 배열의 크기 -1 사이의 값이다. key에 대한 해시함수를 적용하면 h(k)라고 하며, h(k)는 k의 해시 코드라 할 수 있다. k의 해시 코드가 배열의 인덱스로 사용되므로, 해시 테이블의 저장 공간은 h(k) 만큼의 공간만 있으면 된다. 따라서, key를 배열의 인덱 스로 바로 사용할 때에 비하여 적은 공간의 메모리를 사용하고, 탐색의 시간을 줄일 수 있다. 과정 S280에서, 손실 함수는 전체 손실함수(Ltotal) 또는 레이블 손실함수(Llavel) 중 하나에 대응할 수 있다. 전체 손실함수(Ltotal)는 레이블 손실함수(Llavel)의 값을 포함하는 함수 일 수 있다. 전체 손실함수(Ltotal) 또는 레이블 손실함수(Llavel)에 대한 상술한 수식 , 수식 , 수식 , 수식 중 하나에 대응할 수 있다. 손실 함수는 훈련 레이블 정보(y), 제1 훈련 잠재 변수(z1), 및 제2 훈련 잠재 변수(z2)에 기초하여 결정될 수 있다. 나아가, 손실 함수는 훈련 레이블 정보(y), 제1 훈련 잠재 변수(z1), 및 제2 훈련 잠재 변수(z2) 뿐만 아 니라, 제1 훈련 데이터, 제2 훈련 데이터, 인코더 및 디코더의 파라미터에 의해서 결정될 수 있다. 제1 훈련 잠재 변수(z1) 및 제2 훈련 잠재 변수(z2)는 상술한 제1 훈련 데이터와 제2 훈련 데이터에 대한 각각의 제1 훈련 해시 코드와 제2 훈련 해시 코드 일 수 있으며, 이 때문에 데이터를 탐색하고 계산하는데 짧은 시간 안에 신속하게 손실 함수를 결정할 수 있다. 한편, 레이블 손실 함수는 상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수의 평균 및 분산, 및 상기 제2 훈련 잠재 변수의 평균 및 분산을 사용하여 결정될 수 있다. 이 경우 손실 함수는 확률론적 방법에 의해 결정된 것이다. 또는, 레이블 손실 함수는 상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수의 평균, 및 상기 제2 훈련 잠재 변 수의 평균을 사용하여 결정될 수 있다. 이 경우 손실 함수는 결정론적 방법에 의해서 결정된 것이다. 도 7을 참조하면, 상기 훈련 레이블 정보, 상기 제1 잠재 변수, 및 상기 제2 잠재 변수에 기초하여 손실 함수 (loss function)을 결정하는 과정(S280)은, 상기 훈련 과정의 경과 시간(t)이 기 설정된 시간(tstart) 보다 큰지 확인하는 과정(S310), 상기 훈련 과정의 경과 시간(t)이 기 설정된 시간(tstart) 보다 작은 경우에 상기 손실 함 수에 대한 레이블 가중치(Wt)가 0으로 설정되는 과정(S320) 및 상기 훈련 과정의 경과 시간(t)이 기 설정된 시 간(tstart) 보다 큰 경우에 상기 손실 함수에 대한 레이블 가중치(Wt)가 기 설정된 값(constant) 또는 기 설정된 함수(function)로 설정되는 과정(S330)을 포함할 수 있다. 상기 레이블 가중치(Wt)는 전체 손실함수(Ltotal)에서 레이블 손실함수(Llavel)에 대한 영향도를 나타낸다. 전체 손 실함수(Ltotal)가 레이블 손실함수(Llavel)을 포함할 경우 레이블 손실함수(Llavel)는 레이블 가중치(Wt)가 곱해져서 포함되며, 레이블 가중치(Wt)의 크기에 따라서 레이블 손실함수(Llavel)의 영향도가 결정된다. 기 설정된 함수는 일차 함수 c*t로 설정될 수 있다. 이 경우, 레이블 가중치(Wt)는 비지도 학습과 지도 학습의 영향도에 따라서 결정될 수 있다. 비지도 학습으로 기계학습 모델을 장시간 훈련시킴으로써 기계학습 모델의 성 능의 떨어지면, 비지도 학습의 시간을 줄이기 위하여 tstart 값을 더 작게 설정하고, tstart 이후 부터는 지도 학습 으로 기계학습 모델을 훈련시킬 수 있다. 또는, 지도 학습의 영향이 크지 않을 경우에는 지도 학습의 시간을 줄 이기 위하여 tstart 값을 크게 설정할 수 있다. 상기 기설정된 함수가 c*t로 설정된 경우, c는 비지도 학습과 지도 학습의 영향도에 기초하여 결정될 수 있다. 예를 들어, tstart 이후부터 수행되는 지도 학습에 의해서 비지도 학습이 파괴되는 경우에는, 비지도 학습과 지도 학습 사이의 충돌을 최소화하기 위하여 c 값을 작게 설정하여 tstart 이후부터 지도 학습에 의한 영향을 줄일 수 있다. 도 8은 일 실시 예에 다른 데이터 사이의 의미론적 유사 여부를 분석하기 위한 기계학습 모델을 평가하는 방법 의 흐름도를 도시한 것이다. 도 8을 참조하면, 학습된 기계학습 모델을 평가하는 과정(S400)은, 상기 훈련 과정 이후에, 평가 데이터 세트를 이용하여 상기 학습된 기계학습 모델을 평가하는 평가 과정일 수 있다. 상기 평과 과정(S400)은, 동일한 평가 레이블 정보를 가지는 제1 평가 데이터와 제2 평가 데이터를 포함하는 상 기 평가 데이터 세트를 획득하는 과정(S420), 상기 제1 평가 데이터와 상기 평가 제2 데이터를 상기 학습된 기 계학습 모델에 입력함으로써(S440), 상기 제1 평가 데이터와 상기 평가 제2 데이터 사이의 유사도를 획득하는과정(S460), 및 상기 제1 평가 데이터와 상기 평가 제2 데이터 사이의 유사도 및 상기 평가 레이블 정보에 기초 하여 상기 기계학습 모델을 재 학습하는 과정(S480)을 포함할 수 있다. 과정 S420에서, 전자 장치는 외부 서버(미도시)로부터 수신된 혹은 메모리에 저장된 제1 및 제2 평 가 데이터를 획득할 수 있다. 혹은 전자 장치는 외부 서버(미도시)로부터 수신된 쌍별 레이블 정보를 전 처리 과정 및 평가에 사용된 데이터를 선택하여 제1 및 제2 평가 데이터를 메모리에 저장할 수 있으며, 메모리에 저장된 제1 및 제2 평가 데이터를 획득할 수 있다. 과정 S440에서, 전자 장치는 제1 평가 데이터를 학습된 기계학습 모델을 이용하여 상기 제1 평가 데이터 의 제1 평가 해시 코드를 결정할 수 있다. 또한, 전자 장치는 제2 평가 데이터를 학습된 기계학습 모델을 이용하여 제2 평가 데이터의 제2 평가 해시 코드를 결정할 수 있다. 제1 및 제2 평가 해시 코드는 제1 및 제2 평가 데이터의 제1 및 제2 평가 잠재 변수에 대응할 수 있다. 과정 S440 및 S460에서, 훈련 과정에서 학습된 기계학습 모델에 제1 및 제2 평가 데이터를 입력하면, 학습된 기 계학습 모델을 통해서 제1 및 제2 평가 해시 코드에 기초하여 제1 및 제2 평가 데이터 사이의 유사도를 구할 수 있다. 제1 및 제2 평가 데이터는 서로 동일한 평가 레이블 정보를 가지고 있다. 그러므로, 상기 제1 및 제2 평 가 데이터 사이의 유사도가 제1 및 제2 평가 데이터가 서로 유사함을 의미하는 값 내지 정보를 포함해야 함에도 불구하고 서로 비유사함을 의미하는 값 내지 정보가 포함되어 있다면, 전자장치는 기계학습 모델을 재 학 습하는 과정을 수행한다. 과정 S480에서, 전자 장치는 제1 및 제2 평가 데이터의 유사도 및 평가 레이블 정보에 기초하여 기계학습 모델을 재 학습할 수 있다. 예를 들어, 제1 및 제2 평가 데이터 사이의 유사도와 제1 및 제2 평가 데이터의 평 가 레이블 정보를 대비하여 양자 사이의 차이가 감소하는 방향으로 기계학습 모델을 재 학습할 수 있다. 또한, 전자 장치는 레이블 가중치를 변경함으로써 기계학습 모델을 재 학습시킬 수 있으며, 구체적으로, c의 값 및 tstart의 값 중 적어도 하나를 변경하여 기계학습 모델을 재 학습시킬 수 있다. 과정 S420에서, 상기 섹션 3(제안 방법)의 x1 및 x2은 동일한 평가 레이블 정보(y)를 가지는 제1 평가 데이터, 제2 평가 데이터에 각각 대응될 수 있다. 과정 S240 및 S260에서, 상기 섹션 3(제안 방법)의 z1 및 z2은 VAE를 이용하여 결정된 제1 훈련 데이터의 제1 훈련 해시 코드인 제1 훈련 잠재 변수 및 제2 훈련 데이터의 제2 훈련 해시 코드인 제2 훈련 잠재 변수에 각각 대응될 수 있다. 과정 S280에서 손실 함수는 전체 손실함수(Ltotal) 또는 레이블 손실함수(Llavel) 중 하나에 대응할 수 있다. 또는 전체 손실함수(Ltotal)는 레이블 손실함수(Llavel)를 포함하는 함수 일 수 있다. 손실 함수는 훈련 레이블 정보, 제1 훈련 잠재 변수, 및 제2 훈련 잠재 변수에 기초하여 결정될 수 있다. 레이 블 손실 함수는 상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수의 평균 및 분산, 및 상기 제2 훈련 잠재 변수 의 평균 및 분산을 사용하여 결정될 수 있다. 이 경우 손실 함수는 확률론적 방법에 의해 결정된 것이다. 또는, 레이블 손실 함수는 상기 훈련 레이블 정보, 상기 제1 훈련 잠재 변수의 평균, 및 상기 제2 훈련 잠재 변 수의 평균을 사용하여 결정될 수 있다. 이 경우 손실 함수는 결정론적 방법에 의해서 결정된 것이다. 도 9는 일 실시 예에 다른 데이터 사이의 의미론적 유사 여부를 분석하기 위하여 기계학습 모델을 이용하는 방 법의 흐름도를 도시한 것이다. 도 9를 참조하면, 학습된 기계학습 모델을 이용하여 데이터를 분석하는 과정(S600)은, 상기 훈련 과정 이후에, 상기 학습된 기계학습 모델을 이용하여 제1 데이터와 제2 데이터의 의미론적 유사 여부를 확인하는 과정일 수 있다. 상기 제1 데이터와 제2 데이터의 의미론적 유사 여부를 확인하는 과정(S600)은, 상기 제1 데이터와 상기 제2 데 이터를 획득하는 과정(S620), 상기 제1 데이터와 상기 제2 데이터를 상기 학습된 기계학습 모델에 입력함으로써 (S640), 상기 제1 데이터와 상기 제2 데이터 사이의 유사도를 획득하는 과정(S660) 및 상기 제1 데이터와 상기 제2 데이터 사이의 유사도에 기초하여 상기 제1 데이터와 상기 제2 데이터의 의미론적 유사 여부를 결정하는 과 정(S680)을 포함할 수 있다. 과정 S600는 학습된 기계학습 모델을 사용하여 실제 케이스에 적용하는 것이다. 예를 들어, 대표 질의 및 대표 응답이 매칭된 테이블 정보가 있는 경우 대표 질의에 유사한 유사 질의가 입력된 경우 대표 질의에 매칭된 대표 응답을 출력하는 질의-응답 서비스에 적용될 수 있다. 또는 코드, 음악, 서적 등의 컨텐츠들 사이의 유사 여부 를 판별하는데도 사용될 수 있다. 과정 S620에서, 전자 장치는 외부 서버(미도시)로부터 수신된 혹은 메모리에 저장된 제1 및 제2 데 이터를 획득할 수 있다. 제1 및 제2 데이터 중 하나의 데이터는 미리 외부 서버(미도시) 혹은 메모리에 저장되어 있고 다른 하나 의 데이터는 사용자로부터 입력되어 저장된 데이터일 수 있다. 혹은, 제1 및 제2 데이터는 사용자로부터 모두 입력되어 저장된 데이터일 수도 있다. 사용자는 사용자 입력부을 통해서 제1 데이터 혹은 제2 데이터를 전자장치에 입력할 수 있다. 과정 S640에서, 전자 장치는 제1 데이터를 학습된 기계학습 모델을 이용하여 상기 제1 데이터의 제1 확인 해시 코드를 결정할 수 있다. 또한, 전자 장치는 제2 데이터를 학습된 기계학습 모델을 이용하여 제2 데 이터의 제2 확인 해시 코드를 결정할 수 있다. 제1 및 제2 확인 해시 코드는 제1 및 제2 데이터의 제1 및 제2 확인 잠재 변수에 대응할 수 있다. 과정 S640 및 S660에서, 전자 장치는 이미 학습된 기계학습 모델을 이용하여 제1 및 제2 확인 해시 코드 에 기초하여 제1 및 제2 데이터 사이의 유사도를 결정할 수 있다. 제1 및 제2 데이터 사이의 유사도는 일정한 수치 값 또는 이진코드(1 or 0)의 값을 가질 수 있다. 과정 S680에서, 전자 장치는 제1 및 제2 데이터 사이의 유사도에 기초하여 제1 데이터와 상기 제2 데이터 의 의미론적 유사 여부를 결정할 수 있다. 예를 들어, 제1 및 제2 데이터 사이의 유사도가 0.5 이상의 값을 가 질 경우 또는 제1 및 제2 데이터 사이의 유사도가 1인 경우 제1 데이터는 제2 데이터와 유사한 의미를 가진다 고 결정할 수 있다. 나아가, 전자 장치는 제1 및 제2 데이터 사이의 의미론적 유사 여부에 대한 정보를 출력부를 통하 여 사용자에게 나타낼 수 있다. 도 10은 일부 실시예에 따른 프로세서의 블록도이다. 도 10을 참조하면, 일부 실시예에 따른 프로세서는 데이터 학습부 및 데이터 인식부를 포함 할 수 있다. 데이터 학습부는 2개 데이터 사이의 유사 여부의 판단을 위한 기계학습 모델을 훈련시키고 평가할 수 있다. 데이터 인식부는 학습된 기계학습 모델을 이용하여 2개 데이터 사이의 의미론적 유사 여 부를 판단할 수 있다. 데이터 학습부은 상술한 훈련과정(S200) 및 평가과정(S400) 중 적어도 하나를 수행할 수 있다. 또한, 데 이터 인식부는 상술한 데이터 분석 과정(S600)을 수행할 수 있다. 데이터 학습부 및 데이터 인식부 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 학습부 및 데이터 인식부 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로 세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각 종 전자 장치에 탑재될 수도 있다. 데이터 학습부 및 데이터 인식부는 하나의 전자 장치에 탑재될 수도 있다. 예를 들어 데이터 학습 부 및 데이터 인식부은 하나의 디바이스 또는 하나의 서버 중 하나에 포함될 수 있다. 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 학습부 및 데이터 인식부 중 하나는 전자 장치에 포함되고, 나머지 하나는 서버에 포함될 수 있다. 또한, 데이터 학습부 및 데이터 인식부는 유선 또는 무선으로 통하여, 데이터 학습부가 구축한 모델 정보를 데이터 인식부로 제공할 수도 있고, 데이터 인식부로 입력된 데이터가 추가 학습 데이터로서 데이터 학습부로 제공 될 수도 있다. 한편, 데이터 학습부 및 데이터 인식부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이 터 학습부 및 데이터 인식부 중 적어도 하나가 소프트웨어 모듈(또는, 인스터력션(instruction) 포 함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소 프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는,적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플 리케이션에 의해 제공될 수 있다. 도 11은 일부 실시예에 따른 데이터 학습부의 블록도이다. 도 11을 참조하면, 일부 실시예에 따른 데이터 학습부는 데이터 획득부(1310-1), 전처리부(1310-2), 학습 데이터 선택부(1310-3), 모델 학습부(1310-4) 및 모델 평가부(1310-5)를 포함할 수 있다. 데이터 획득부(1310-1)는 쌍별 레이블 데이터 세트를 획득할 수 있다. 쌍별 레이블 데이터 세트는 동일한 레이 블 정보를 가지는 제1 데이터와 제2 데이터를 포함할 수 있다. 제1 데이터(X1)와 제2 데이터(X2)는 동일한 값(Y)으로 레이블된 쌍별 레이블 정보일 수 있으며, 서로 의미론적 으로 유사한 데이터일 수 있다. 예를 들어, 제1 데이터는 제1 텍스트 문장이고, 제2 데이터는 제1 텍스트 문장 을 의역한 제2 텍스트 문장일 수 있다. 쌍별 레이블 데이터 세트는 외부 서버(미도시)로부터 수신할 수 있다. 쌍별 레이블 데이터 세트는 텍스트, 동영 상, 이미지, 컨텍스트 중 적어도 하나를 포함할 수 있다. 전처리부(1310-2)는 쌍별 레이블 데이터 세트를 전처리할 수 있다. 전처리부(1310-2)는 쌍별 레이블 데이터 세 트를 기 설정된 포맷으로 가공할 수 있다. 전처리부(1310-2)는 코퍼스(corpus)를 토큰(token) 단위(예. 단어(word))로 나누는 토큰화(tokenization), 노 이즈 데이터를 제거하는 정제(cleaning), 표현 방법이 다른 단어들을 통합시켜서 같은 단어로 만드는 정규화 (normalization), 단어들의 표제어를 추출하는 표제어 추출(lemmatization), 어간을 추출하는 어간 추출 (stemming), 불용어(stopword) 제거, 백오프워드(bag-of-word), 단어 빈도-역 문서 빈도(Term Frequency- Inverse Document Frequency: TF-IDF) 중 적어도 하나를 이용하여 쌍별 레이블 훈련 데이터 세트를 전처리할 수 있다. 학습 데이터 선택부(1310-3)는 전처리된 데이터 중에서 학습에 필요한 훈련데이터 세트를 선택할 수 있다. 선택 된 훈련 데이터 세트는 모델 학습부(1310-4)에 제공될 수 있다. 학습 데이터 선택부(1310-3)는 제1 데이터와 제 2 데이터의 의미론적 유사 여부를 확인하기 위한 기 설정된 기준에 따라, 전처리된 데이터 중에서 학습에 필요 한 훈련 데이터 세트를 선택할 수 있다. 모델 학습부(1310-4)는 훈련 데이터 세트에 기초하여 기계학습 모델을 훈련할 수 있다. 모델 학습부(1310-4)는, 동일한 훈련 레이블 정보를 가지는 제1 훈련 데이터와 제2 훈련 데이터를 포함하는 상 기 훈련 데이터 세트를 획득하고, 상기 제1 훈련 데이터를 변분 오토 인코더(VAE)를 이용하여 훈련하고, 상기 제1 훈련 데이터의 제1 훈련 잠재 변수(latent variable)를 결정하고, 상기 제2 훈련 데이터를 상기 VAE를 이용 하여 훈련하고, 상기 제2 훈련 데이터의 제2 훈련 잠재 변수를 결정하고, 상기 훈련 레이블 정보, 상기 제1 훈 련 잠재 변수 및 상기 제2 훈련 잠재 변수에 기초하여 손실 함수(loss function)을 결정하고, 상기 손실 함수에 기초하여 기계학습 모델을 학습할 수 있다. 또한, 기계학습 모델이 학습되면, 모델 학습부(1310-4)는 학습된 기계학습 모델을 저장할 수 있다. 이 경우, 모 델 학습부(1310-4)는 학습된 기계학습 모델을 데이터 인식부를 포함하는 전자 장치의 메모리에 저장할 수 있다. 또는, 모델 학습부(1310-4)는 학습된 데이터 인식 모델을 전자 장치와 유선 또는 무선 네트워크로 연결되 는 서버의 메모리에 저장할 수도 있다. 이 경우, 학습된 기계학습 모델이 저장되는 메모리는, 예를 들면, 전자 장치의 적어도 하나의 다른 구성요소에 관계된 명령 또는 데이터를 함께 저장할 수도 있다. 또한, 메모리는 소프트웨어 및/또는 프로그램을 저장할 수 도 있다. 프로그램은, 예를 들면, 커널, 미들웨어, 어플리케이션 프로그래밍 인터페이스(API) 및/또는 어플리케 이션 프로그램(또는 \"어플리케이션\") 등을 포함할 수 있다. 모델 평가부(1310-5)는 기계학습 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 인식 결과가 소 정 기준을 만족하지 못하는 경우, 모델 학습부(1310-4)로 하여금 다시 학습하도록 할 수 있다. 모델 평가부(1310-5)는 상기 훈련 과정을 수행한 이후에, 평가 데이터 세트를 이용하여 상기 학습된 기계학습 모델을 평가할 수 있다. 모델 평가부(1310-5)는 동일한 평가 레이블 정보를 가지는 제1 평가 데이터와 제2 평가 데이터를 포함하는 상기 평가 데이터 세트를 획득하고, 상기 제1 평가 데이터와 상기 평가 제2 데이터를 상기 학습된 기계학습 모델에 입력함으로써, 상기 제1 평가 데이터와 상기 평가 제2 데이터 사이의 유사도를 획득하고, 상기 제1 평가 데이터와 상기 평가 제2 데이터 사이의 유사도 및 상기 평가 레이블 정보에 기초하여 상기 기계학습 모델을 재 학습할 수 있다. 예를 들어, 모델 평가부(1310-5)는 평가 데이터에 대한 학습된 기계학습 모델의 인식 결과 중에서, 인식 결과가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정된 임계치를 초과하는 경우 소정 기준을 만족하지 못 한 것으로 평가할 수 있다. 한편, 데이터 학습부 내의 데이터 획득부(1310-1), 전처리부(1310-2), 학습 데이터 선택부(1310-3), 모델 학습부(1310-4) 및 모델 평가부(1310-5) 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 획득부(1310-1), 전처리부(1310-2), 학습 데이터 선택부(1310-3), 모델 학습부(1310-4) 및 모델 평가부(1310-5) 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위 한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 또한, 데이터 획득부(1310-1), 전처리부(1310-2), 학습 데이터 선택부(1310-3), 모델 학습부(1310-4) 및 모델 평가부(1310-5)는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 획득부(1310-1), 전처리부(1310-2), 학습 데이터 선택부(1310-3), 모델 학습부(1310-4) 및 모델 평가부(1310-5) 중 일부는 전자 장치에 포함되고, 나머지 일부는 서버에 포함될 수 있다. 또한, 데이터 획득부(1310-1), 전처리부(1310-2), 학습 데이터 선택부(1310-3), 모델 학습부(1310-4) 및 모델 평가부(1310-5) 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부(1310-1), 전처리부(1310- 2), 학습 데이터 선택부(1310-3), 모델 학습부(1310-4) 및 모델 평가부(1310-5) 중 적어도 하나가 소프트웨어 모듈(또는, 인스터력션(instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 도 12는 일부 실시예에 따른 데이터 인식부의 블록도이다. 도 12를 참조하면, 일부 실시예에 따른 데이터 인식부는 데이터 획득부(1320-1), 전처리부(1320-2), 인식 데이터 선택부(1320-3), 인식 결과 제공부(1320-4) 및 모델 갱신부(1320-5)를 포함할 수 있다. 데이터 획득부(1320-1)는 쌍별 레이블 데이터 세트를 획득할 수 있다. 쌍별 레이블 데이터 세트는 동일한 레이 블 정보를 가지는 제1 데이터와 제2 데이터를 포함할 수 있다. 제1 데이터(X1)와 제2 데이터(X2)는 동일한 값(Y)으로 레이블된 쌍별 레이블 정보일 수 있으며, 서로 의미론적 으로 유사한 데이터일 수 있다. 예를 들어, 제1 데이터는 제1 텍스트 문장이고, 제2 데이터는 제1 텍스트 문장 을 의역한 제2 텍스트 문장일 수 있다. 쌍별 레이블 데이터 세트는 외부 서버(미도시)로부터 수신할 수 있다. 쌍별 레이블 데이터 세트는 텍스트, 동영 상, 이미지, 컨텍스트 중 적어도 하나를 포함할 수 있다. 전처리부(1320-2)는 쌍별 레이블 데이터 세트를 전처리할 수 있다. 전처리부(1310-2)는 쌍별 레이블 데이터 세 트를 기 설정된 포맷으로 가공할 수 있다. 전처리부(1320-2)는 코퍼스(corpus)를 토큰(token) 단위(예. 단어(word))로 나누는 토큰화(tokenization), 노 이즈 데이터를 제거하는 정제(cleaning), 표현 방법이 다른 단어들을 통합시켜서 같은 단어로 만드는 정규화 (normalization), 단어들의 표제어를 추출하는 표제어 추출(lemmatization), 어간을 추출하는 어간 추출 (stemming), 불용어(stopword) 제거, 백오프워드(bag-of-word), 단어 빈도-역 문서 빈도(Term Frequency- Inverse Document Frequency: TF-IDF) 중 적어도 하나를 이용하여 쌍별 레이블 훈련 데이터 세트를 전처리할 수 있다. 인식 데이터 선택부(1320-3)는 전처리된 데이터 중에서 제1 데이터와 제2 데이터의 의미론적 유사 여부의 확인 에 필요한 데이터를 선택할 수 있다. 선택된 데이터는 인식 결과 제공부(1320-4)에게 제공될 수 있다. 인식 데 이터 선택부(1320-3)는 제1 데이터와 제2 데이터의 의미론적 유사 여부를 확인하기 위한 기 설정된 기준에따라, 전처리된 데이터 중에서 일부 또는 전부를 선택할 수 있다. 인식 결과 제공부(1320-4)는 상기 학습된 기계학습 모델을 이용하여 제1 데이터와 제2 데이터의 의미론적 유사 여부를 확인할 수 있다. 인식 결과 제공부(1320-4)는 상기 제1 데이터와 상기 제2 데이터를 획득하고, 상기 제1 데이터와 상기 제2 데이 터를 상기 학습된 기계학습 모델에 입력함으로써, 상기 제1 데이터와 상기 제2 데이터 사이의 유사도를 획득하 고, 상기 제1 데이터와 상기 제2 데이터 사이의 유사도에 기초하여 상기 제1 데이터와 상기 제2 데이터의 의미 론적 유사 여부를 결정할 수 있다. 모델 갱신부(1320-5)는 인식 결과 제공부(1320-4)에 의해 제공되는 상기 제1 데이터와 상기 제2 데이터의 의미 론적 유사 여부에 기초하여, 기계 학습 모델이 갱신되도록 할 수 있다. 한편, 데이터 인식부 내의 데이터 획득부(1320-1), 전처리부(1320-2), 인식 데이터 선택부(1320-3), 인식 결과 제공부(1320-4) 및 모델 갱신부(1320-5) 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 획득부(1320-1), 전처리부(1320-2), 인식 데이터 선택부(1320- 3), 인식 결과 제공부(1320-4) 및 모델 갱신부(1320-5) 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재 될 수도 있다. 또한, 데이터 획득부(1320-1), 전처리부(1320-2), 인식 데이터 선택부(1320-3), 인식 결과 제공부(1320-4) 및 모델 갱신부(1320-5)는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 획득부(1320-1), 전처리부(1320-2), 인식 데이터 선택부(1320-3), 인식 결과 제공부 (1320-4) 및 모델 갱신부(1320-5) 중 일부는 전자 장치에 포함되고, 나머지 일부는 서버에 포함될 수 있다. 또한, 데이터 획득부(1320-1), 전처리부(1320-2), 인식 데이터 선택부(1320-3), 인식 결과 제공부(1320-4) 및 모델 갱신부(1320-5) 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부(1320-1), 전처리부 (1320-2), 인식 데이터 선택부(1320-3), 인식 결과 제공부(1320-4) 및 모델 갱신부(1320-5) 중 적어도 하나가 소프트웨어 모듈(또는, 인스터력션(instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 도 13 및 도 14는 일 실시예에 따른 전자장치의 블록도를 도시한 것이다. 도 13을 참조하면, 일 실시예에 따른 전자 장치는, 단말기, 디바이스, 전자기기, 서버, 스마트폰, 태블릿 PC, PC, 스마트 TV, 휴대폰, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레 이어, 디지털 카메라, 가전기기 및 기타 컴퓨팅 장치 중 하나일 수 있으나, 이에 한정되는 것은 아니다. 또한, 전자 장치는 디스플레이 기능 및 데이터 프로세싱 기능을 구비한 시계, 안경, 헤어 밴드 및 반지 등의 웨 어러블 디바이스일 수 있다. 그러나, 이에 한정되지 않으며, 전자 장치는 데이터를 처리하고, 처리된 데이 터를 제공할 수 있는 모든 종류의 기기를 포함할 수 있다. 일 실시 예에 따른 전자 장치는 메모리, 출력부, 통신부 및 프로세서를 포함할 수 있다. 그러나, 도시된 구성 요소 모두가 전자 장치의 필수 구성 요소인 것은 아니며, 보다 많은 구성 요소에 의해 전자 장치가 구현될 수도 있고, 보다 적은 구성 요소에 의해 전자 장치가 구현될 수도 있다. 예를 들어, 도 14에 도시된 바와 같이, 일 실시 예에 따른 전자 장치는, 메모리, 출력부, 프 로세서, 센싱부, 통신부, A/V 입력부 및 사용자 입력부를 포함할 수도 있다. *메모리 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 전자 장치로 입력되 는 정보 또는 전자 장치로부터 출력되는 정보를 저장할 수도 있다.메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 메모리에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있는데, 예를 들어, UI 모 듈, 터치 스크린 모듈, 알림 모듈 등으로 분류될 수 있다. UI 모듈은, 애플리케이션 별로 전자 장치와 연동되는 특화된 UI, GUI 등을 제공할 수 있다. 터치 스크린 모듈은 사용자의 터치 스크린 상의 터치 제스처를 감지하고, 터치 제스처에 관한 정보를 프 로세서로 전달할 수 있다. 일 실시예에 따른 터치 스크린 모듈은 터치 코드를 인식하고 분석할 수 있다. 터치 스크린 모듈은 컨트롤러를 포함하는 별도의 하드웨어로 구성될 수도 있다. 알림 모듈은 전자 장치의 이벤트 발생을 알리기 위한 신호를 발생할 수 있다. 전자 장치에서 발생되는 이벤트의 예로는 호 신호 수신, 메시지 수신, 키 신호 입력, 일정 알림 등이 있다. 알림 모듈은 디스플레이부를 통해 비디오 신호 형태로 알림 신호를 출력할 수도 있고, 음향 출력부를 통해 오디 오 신호 형태로 알림 신호를 출력할 수도 있고, 진동 모터를 통해 진동 신호 형태로 알림 신호를 출력할 수도 있다. 예를 들어, 알림 모듈은 추정된 차선 정보에 기초하여 가이드 정보를 출력하기 위한 신호를 발생할 수 있다. *출력부 출력부는, 오디오 신호 또는 비디오 신호 또는 진동 신호를 출력할 수 있으며, 출력부는 디스플레 이부, 음향 출력부, 및 진동 모터를 포함할 수 있다. 디스플레이부는 전자 장치에서 처리되는 정보를 표시 출력한다. 구체적으로, 디스플레이부는 카메라에서 촬영된 이미지를 출력할 수 있다. 디스플레이부는, 사용자의 입력에 대한 응답으로, 응 답에 관련된 동작을 실행하기 위한 사용자 인터페이스를 디스플레이할 수 있다. 음향 출력부는 통신부로부터 수신되거나 메모리에 저장된 오디오 데이터를 출력한다. 또한, 음향 출력부는 전자 장치에서 수행되는 기능(예를 들어, 호신호 수신음, 메시지 수신음, 알림음)과 관련된 음향 신호를 출력한다. *프로세서 프로세서는, 통상적으로 전자 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 메 모리에 저장된 프로그램들을 실행함으로써, 사용자 입력부, 출력부, 센싱부, 통신부 , A/V 입력부 등을 전반적으로 제어할 수 있다. *센싱부 센싱부는, 전자 장치의 상태 또는 전자 장치 주변의 상태를 감지하고, 감지된 정보를 프로세 서로 전달할 수 있다. 센싱부는, 지자기 센서(Magnetic sensor), 가속도 센서(Acceleration sensor), 온/습도 센 서, 적외선 센서, 자이로스코프 센서, 위치 센서(예컨대, GPS), 기압 센서, 근 접 센서, 및 RGB 센서(RGB sensor) 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니 다. 각 센서들의 기능은 그 명칭으로부터 당업자가 직관적으로 추론할 수 있으므로, 구체적인 설명은 생략하기 로 한다. *통신부 통신부는, 전자 장치가 다른 장치(미도시) 및 서버(미도시)와 통신을 하게 하는 하나 이상의 구성 요소를 포함할 수 있다. 다른 장치(미도시)는 전자 장치와 같은 컴퓨팅 장치이거나, 센싱 장치일 수 있으 나, 이에 한정되는 것은 아니다. 예를 들어, 통신부는, 근거리 통신부, 이동 통신부, 방송 수신부를 포함할 수 있다. 근거리 통신부(short-range wireless communication unit)는, 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, 근거리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 지그비 (Zigbee) 통신부, 적외선(IrDA, infrared Data Association) 통신부, WFD(Wi-Fi Direct) 통신부, UWB(ultra wideband) 통신부, Ant+ 통신부 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한 다. 여기에서, 무선 신호는, 음성 호 신호, 화상 통화 호 신호 또는 문자/멀티미디어 메시지 송수신에 따른 다 양한 형태의 데이터를 포함할 수 있다. 방송 수신부는, 방송 채널을 통하여 외부로부터 방송 신호 및/또는 방송 관련된 정보를 수신한다. 방송 채널은 위성 채널, 지상파 채널을 포함할 수 있다. 구현 예에 따라서 전자 장치가 방송 수신부를 포함하지 않을 수도 있다. *A/V(Audio/Video) 입력부* A/V(Audio/Video) 입력부는 오디오 신호 또는 비디오 신호 입력을 위한 것으로, 이에는 카메라와 마이크로폰 등이 포함될 수 있다. 카메라는 화상 통화모드 또는 촬영 모드에서 이미지 센서를 통해 정지영상 또는 동영상 등의 화상 프레임 을 얻을 수 있다. 이미지 센서를 통해 캡처된 이미지는 프로세서 또는 별도의 이미지 처리부(미도시)를 통해 처리될 수 있다. 마이크로폰은, 외부의 음향 신호를 입력 받아 전기적인 음성 데이터로 처리한다. 예를 들어, 마이크로폰 은 외부 디바이스 또는 사용자로부터 음향 신호를 수신할 수 있다. 마이크로폰은 사용자의 음성 입 력을 수신할 수 있다. 마이크로폰은 외부의 음향 신호를 입력 받는 과정에서 발생 되는 잡음(noise)을 제 거하기 위한 다양한 잡음 제거 알고리즘을 이용할 수 있다. *사용자 입력부 사용자 입력부는, 사용자가 전자 장치를 제어하기 위한 데이터를 입력하는 수단을 의미한다. 예를 들어, 사용자 입력부에는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방 식 등), 조그 휠, 조그 스위치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 도 15는 일부 실시예에 따른 디바이스 및 서버가 서로 연동함으로써 데이터를 학습하고 인식하는 예시를 나타내는 도면이다. 디바이스 및 서버는 상술한 전자장치의 일 예로서 전자장치의 구성요소 중 적어도 일 부를 포함할 수 있다. 상술하였지만, 데이터 학습부 및 데이터 인식부는 하나의 전자 장치에 탑재될 수도 있다. 예를 들 어 데이터 학습부 및 데이터 인식부은 하나의 디바이스 또는 하나의 서버 중 하나에 포함될 수 있다. 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 학습부 및 데이 터 인식부 중 하나는 전자 장치에 포함되고, 나머지 하나는 서버에 포함될 수 있다. 일 예로, 도 15를 참조하면, 서버는 2개의 데이터의 의미론적 유사 여부를 판단할 수 있는 기계학습 모델 을 학습할 수 있으며, 디바이스는 서버에 의한 학습된 기계학습 모델을 이용하여 2개의 데이터의 의미론적 유사 여부를 판단할 수 있다. 이 경우, 서버의 데이터 학습부는 전술한 데이터 학습부의 기능을 수행할 수 있다. 서버 의 데이터 학습부의 각 구성요소들은 전술한 데이터 학습부의 각 구성요소들의 기능을 수행 할 수 있다. 또한, 디바이스의 데이터 인식부는 전술한 데이터 인식부의 기능을 수행할 수 있다. 디바이 스의 데이터 인식부의 각 구성요소들은 전술한 데이터 인식부의 각 구성요소들의 기능을 수 행할 수 있다. 또는, 디바이스의 인식 결과 제공부(2320-4)는 서버에 의해 학습되 기계학습 모델을 서버로 부터 수신하고, 수신된 기계학습 모델을 이용하여 2개 데이터의 유사 여부를 판단할 수 있다.본 발명은 도면에 도시된 실시 예를 참고로 설명되었으나 이는 예시적인 것에 불과하며, 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시 예가 가능하다는 점을 이해할 것이다. 따라서, 본 발명의 진정한 기술적 보호 범위는 첨부된 등록청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2019-0151718", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 일 실시예에 따른 변분 쌍별 지도 텍스트 해싱 방법(variational pairwise supervised text hashing : VPSH) 중 확률론적(stochastic) 방법(VPSH-ST)에 대한 블록도이다. 도 1b는 일 실시예에 따른 변분 쌍별 지도 텍스트 해싱 방법(variational pairwise supervised text hashing : VPSH) 중 결정론적(deterministic) 방법(VPSH-DE)에 대한 블록도이다. 도 2는 각 훈련 시대마다 MSRP 데이터 세트에서 레이블 가중치 어닐링 없는 최악의 테스트 정확도 사례(The worst test accuracy case without label weight annealing in the MSRP dataset for each training epoch)를 도시한 것이다. 도 3은 레이블 가중치 어닐링이 있는 및 레이블 가중치 어닐링이 없는 각 훈련 시대에 대한 MSRP 데이터 세트의 정확도(Accuracy with the MSRP dataset for each training epoch with label weight annealing and without label weight annealing)를 도시한 것이다. 도 4는 확률론적 방법 및 결정론적 방법으로 각 훈련 시대에 대한 Quora 데이터 세트의 정확도(Accuracy with the Quora dataset for each training epoch with the stochastic method and the deterministic method)를 도시한 것이다. 도 5는 일 실시 예에 따른 데이터 사이의 의미론적 유사 여부를 분석하기 위하여 기계학습을 이용한 전자 장치 의 제어 방법의 흐름도를 도시한 것이다. 도 6 및 도 7은 일 실시 예에 다른 데이터 사이의 의미론적 유사 여부를 분석하기 위한 기계학습 모델을 훈련하 는 방법의 흐름도를 도시한 것이다. 도 8은 일 실시 예에 다른 데이터 사이의 의미론적 유사 여부를 분석하기 위한 기계학습 모델을 평가하는 방법 의 흐름도를 도시한 것이다. 도 9는 일 실시 예에 다른 데이터 사이의 의미론적 유사 여부를 분석하기 위하여 기계학습 모델을 이용하는 방 법의 흐름도를 도시한 것이다. 도 10은 일부 실시예에 따른 프로세서의 블록도이다. 도 11은 일부 실시예에 따른 데이터 학습부의 블록도이다. 도 12는 일부 실시예에 따른 데이터 인식부의 블록도이다. 도 13 및 도 14는 일 실시예에 따른 전자장의 블록도를 도시한 것이다. 도 15는 일부 실시예에 따른 디바이스 및 서버가 서로 연동함으로써 데이터를 학습하고 인식하는 예시를 나타내 는 도면이다."}
