{"patent_id": "10-2020-0144563", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0059224", "출원번호": "10-2020-0144563", "발명의 명칭": "딥러닝 연산 수행 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "권형달"}}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "딥러닝 연산을 수행하는 전자 장치(electronic device)에 있어서,복수의 딥러닝 연산을 동시에 수행하는 프로세서를 포함하고,상기 프로세서는복수의 프로세싱 엘리먼트들(Processing Elements; PEs)을 포함하는 시스톨릭 어레이(systolic array); 및상기 프로세싱 엘리먼트들 사이의 데이터 전파(propagate)를 수행하는 제1 온칩 네트워크(on-chip network)를 포함하는 전자 장치."}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는복수의 인공신경망들의 특성에 기초하여, 상기 복수의 인공신경망들의 딥러닝 연산을 동시에 수행할 수 있도록상기 프로세싱 엘리먼트들을 분배하는, 전자 장치."}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는복수의 인공신경망들의 특성에 기초하여, 입력 데이터 및 부분합(partial sum)의 전파 방향을 설정하는, 전자장치."}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 프로세서는하나의 인공신경망을 복수의 서브 인공신경망들로 분리하고, 상기 서브 인공신경망들의 딥러닝 연산을 동시에수행할 수 있도록 상기 프로세싱 엘리먼트들을 분배하는, 전자 장치."}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 프로세서는상기 서브 인공신경망들의 특성에 기초하여, 입력 데이터 및 부분합(partial sum)의 전파 방향을 설정하는, 전자 장치.공개특허 10-2022-0059224-3-청구항 6 제1항에 있어서,상기 프로세서는제1 입력 데이터를 상기 시스톨릭 어레이의 좌우변으로 입력하기 위한 제1 입력 데이터 전달 모듈을 더 포함하는, 전자 장치."}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제1 입력 데이터 전달 모듈은상기 제1 입력 데이터를 상기 시스톨릭 어레이의 좌변으로 입력하는 타이밍을 조절하고, 상기 제1 입력 데이터를 상기 시스톨릭 어레이의 좌변으로 전달하는 제1 시스톨릭 데이터 셋업 모듈(systolic data setup module);상기 제1 입력 데이터를 상기 시스톨릭 어레이의 우변으로 입력하는 타이밍을 조절하는 제2 시스톨릭 데이터 셋업 모듈; 및상기 제1 입력 데이터를 상기 시스톨릭 어레이의 우변으로 전달하는 제2 온칩 네트워크를 포함하는, 전자 장치."}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 프로세서는제2 입력 데이터를 상기 프로세싱 엘리먼트들의 상하단으로 입력하기 위한 제2 입력 데이터 전달 모듈을 더 포함하는, 전자 장치."}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 제2 입력 데이터 전달 모듈은상기 제2 입력 데이터를 상기 프로세싱 엘리먼트들로 입력하는 타이밍을 조절하고, 상기 제2 입력 데이터를 상기 프로세싱 엘리먼트들의 상단으로 전달하는 웨이트 버퍼(weight buffer); 및상기 제2 입력 데이터를 상기 프로세싱 엘리먼트들의 하단으로 전달하는 제3 온칩 네트워크"}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 프로세서는제1 입력 데이터 및 제2 입력 데이터 사이의 연산 결과인 출력 데이터를 상기 시스톨릭 어레이의 상하변으로부터 수신하기 위한 출력 데이터 수신 모듈공개특허 10-2022-0059224-4-을 더 포함하는, 전자 장치."}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 출력 데이터 수신 모듈은출력 결과 누적 레지스터(output accumulators); 및상기 시스톨릭 어레이의 상변으로 전파되는 부분합을 상기 출력 결과 누적 레지스터의 하단으로 전달하는 제4온칩 네트워크를 포함하고,상기 시스톨릭 어레이의 하변으로 전파되는 부분합은 상기 출력 결과 누적 레지스터의 상단으로 전달되는, 전자장치."}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "실행 중인 제1 인공신경망이 있는지 판단하는 단계;상기 실행 중인 제1 인공신경망이 있는 경우, 상기 제1 인공신경망의 특성 및 새롭게 실행될 제2 인공신경망의특성에 기초하여 상기 제1 인공신경망의 딥러닝 연산 및 상기 제2 인공신경망의 딥러닝 연산을 동시에 수행할수 있도록 프로세싱 엘리먼트들을 분배하는 단계;상기 제1 인공신경망의 특성 및 상기 제2 인공신경망의 특성에 기초하여, 입력 데이터 및 부분합(partial sum)의 전파 방향을 설정하는 단계; 및상기 분배된 프로세싱 엘리먼트들을 이용하여, 상기 제1 인공신경망의 딥러닝 연산 및 상기 제2 인공신경망의딥러닝 연산을 동시에 수행하는 단계를 포함하는 딥러닝 연산 수행 방법."}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 프로세싱 엘리먼트들을 분배하는 단계는상기 제1 인공신경망의 특성 및 상기 제2 인공신경망의 특성에 기초하여, 상기 프로세싱 엘리먼트들의 분배 방식 및 분배 비율을 결정하는 단계를 포함하는, 딥러닝 연산 수행 방법."}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 프로세싱 엘리먼트들을 분배하는 단계는상기 분배 방식 및 상기 분배 비율에 기초하여, 상기 제1 인공신경망의 딥러닝 연산을 프리엠트(preempt)하는단계; 및상기 제2 인공신경망의 딥러닝 연산을 수행하기 위하여, 상기 프리엠트를 통해 확보된 프로세싱 엘리먼트들을할당하는 단계공개특허 10-2022-0059224-5-를 포함하는, 딥러닝 연산 수행 방법."}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 실행 중인 제1 인공신경망이 없는 경우, 상기 제2 인공신경망이 복수의 배치(batch)를 갖는지 판단하는 단계;상기 제2 인공신경망이 복수의 배치를 갖는 경우, 상기 제2 인공신경망을 복수의 서브 인공신경망들로 분리하는단계;상기 서브 인공신경망들의 특성에 기초하여, 상기 서브 인공신경망들의 딥러닝 연산을 동시에 수행할 수 있도록프로세싱 엘리먼트들을 분배하는 단계;상기 서브 인공신경망들의 특성에 기초하여, 입력 데이터 및 부분합의 전파 방향을 설정하는 단계; 및상기 분배된 프로세싱 엘리먼트들을 이용하여, 상기 서브 인공신경망들의 딥러닝 연산을 동시에 수행하는 단계를 더 포함하는 딥러닝 연산 수행 방법."}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 프로세싱 엘리먼트들을 분배하는 단계는상기 서브 인공신경망들의 특성에 기초하여, 상기 프로세싱 엘리먼트들의 분배 방식 및 분배 비율을 결정하는단계를 포함하는, 딥러닝 연산 수행 방법."}
{"patent_id": "10-2020-0144563", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "하드웨어와 결합되어 제12항 내지 제16항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2020-0144563", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "딥러닝 연산 수행 방법 및 장치가 개시된다. 일 실시예에 따른 딥러닝 연산을 수행하는 전자 장치(electronic device)에 있어서, 복수의 딥러닝 연산을 동시에 수행하는 프로세서를 포함하고, 상기 프로세서는 복수의 프로세 싱 엘리먼트들(Processing Elements; PEs)을 포함하는 시스톨릭 어레이(systolic array); 및 상기 프로세싱 엘 리먼트들 사이의 데이터 전파(propagate)를 수행하는 제1 온칩 네트워크(on-chip network)를 포함한다."}
{"patent_id": "10-2020-0144563", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래 실시예들은 딥러닝 연산 수행 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2020-0144563", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공신경망(Artificial Neural Network)은 컴퓨터 과학적 아키텍쳐(computational architecture)를 참조하여 구현된다. 최근 인공신경망 기술이 발전함에 따라, 다양한 종류의 전자 시스템에서 인공신경망을 활용하여 입 력 데이터를 분석하고 유효한 정보를 추출하는 연구가 활발히 진행되고 있다. 인공신경망을 처리하는 장치는 복잡한 입력 데이터에 대한 많은 양의 연산을 필요로 한다. 따라서, 인공신경망을 이용하여 대량의 입력 데이 터를 실시간으로 분석하여, 원하는 정보를 추출하기 위해서는 인공신경망에 관한 연산을 효율적으로 처리할 수 있는 기술이 요구된다."}
{"patent_id": "10-2020-0144563", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 딥러닝 연산을 수행하는 전자 장치(electronic device)에 있어서, 복수의 딥러닝 연산을 동시 에 수행하는 프로세서를 포함하고, 상기 프로세서는 복수의 프로세싱 엘리먼트들(Processing Elements; PEs)을 포함하는 시스톨릭 어레이(systolic array); 및 상기 프로세싱 엘리먼트들 사이의 데이터 전파(propagate)를 수 행하는 제1 온칩 네트워크(on-chip network)를 포함한다. 상기 프로세서는 복수의 인공신경망들의 특성에 기초하여, 상기 복수의 인공신경망들의 딥러닝 연산을 동시에 수행할 수 있도록 상기 프로세싱 엘리먼트들을 분배할 수 있다. 상기 프로세서는 복수의 인공신경망들의 특성에 기초하여, 입력 데이터 및 부분합(partial sum)의 전파 방향을 설정할 수 있다. 상기 프로세서는 하나의 인공신경망을 복수의 서브 인공신경망들로 분리하고, 상기 서브 인공신경망들의 딥러닝 연산을 동시에 수행할 수 있도록 상기 프로세싱 엘리먼트들을 분배할 수 있다. 상기 프로세서는 상기 서브 인공신경망들의 특성에 기초하여, 입력 데이터 및 부분합(partial sum)의 전파 방향 을 설정할 수 있다. 상기 프로세서는 제1 입력 데이터를 상기 시스톨릭 어레이의 좌우변으로 입력하기 위한 제1 입력 데이터 전달 모듈을 더 포함할 수 있다. 상기 제1 입력 데이터 전달 모듈은 상기 제1 입력 데이터를 상기 시스톨릭 어레이의 좌변으로 입력하는 타이밍 을 조절하고, 상기 제1 입력 데이터를 상기 시스톨릭 어레이의 좌변으로 전달하는 제1 시스톨릭 데이터 셋업 모 듈(systolic data setup module); 상기 제1 입력 데이터를 상기 시스톨릭 어레이의 우변으로 입력하는 타이밍을 조절하는 제2 시스톨릭 데이터 셋업 모듈; 및 상기 제1 입력 데이터를 상기 시스톨릭 어레이의 우변으로 전달하 는 제2 온칩 네트워크를 포함할 수 있다. 상기 프로세서는 제2 입력 데이터를 상기 프로세싱 엘리먼트들의 상하단으로 입력하기 위한 제2 입력 데이터 전 달 모듈을 더 포함할 수 있다. 상기 제2 입력 데이터 전달 모듈은 상기 제2 입력 데이터를 상기 프로세싱 엘리먼트들로 입력하는 타이밍을 조 절하고, 상기 제2 입력 데이터를 상기 프로세싱 엘리먼트들의 상단으로 전달하는 웨이트 버퍼(weight buffer); 및 상기 제2 입력 데이터를 상기 프로세싱 엘리먼트들의 하단으로 전달하는 제3 온칩 네트워크를 포함하고, 상 기 프로세서는 제1 입력 데이터 및 제2 입력 데이터 사이의 연산 결과인 출력 데이터를 상기 시스톨릭 어레이의 상하변으로부터 수신하기 위한 출력 데이터 수신 모듈을 더 포함할 수 있다. 상기 출력 데이터 수신 모듈은 출력 결과 누적 레지스터(output accumulators); 및 상기 시스톨릭 어레이의 상 변으로 전파되는 부분합을 상기 출력 결과 누적 레지스터의 하단으로 전달하는 제4 온칩 네트워크를 포함하고, 상기 시스톨릭 어레이의 하변으로 전파되는 부분합은 상기 출력 결과 누적 레지스터의 상단으로 전달될 수 있다. 일 실시예에 따른 딥러닝 연산 수행 방법은 실행 중인 제1 인공신경망이 있는지 판단하는 단계; 상기 실행 중인 제1 인공신경망이 있는 경우, 상기 제1 인공신경망의 특성 및 새롭게 실행될 제2 인공신경망의 특성에 기초하여 상기 제1 인공신경망의 딥러닝 연산 및 상기 제2 인공신경망의 딥러닝 연산을 동시에 수행할 수 있도록 프로세 싱 엘리먼트들을 분배하는 단계; 상기 제1 인공신경망의 특성 및 상기 제2 인공신경망의 특성에 기초하여, 입력 데이터 및 부분합(partial sum)의 전파 방향을 설정하는 단계; 및 상기 분배된 프로세싱 엘리먼트들을 이용하여, 상기 제1 인공신경망의 딥러닝 연산 및 상기 제2 인공신경망의 딥러닝 연산을 동시에 수행하는 단계 를 포함한다. 상기 프로세싱 엘리먼트들을 분배하는 단계는 상기 제1 인공신경망의 특성 및 상기 제2 인공신경망의 특성에 기 초하여, 상기 프로세싱 엘리먼트들의 분배 방식 및 분배 비율을 결정하는 단계를 포함할 수 있다. 상기 프로세싱 엘리먼트들을 분배하는 단계는 상기 분배 방식 및 상기 분배 비율에 기초하여, 상기 제1 인공신 경망의 딥러닝 연산을 프리엠트(preempt)하는 단계; 및 상기 제2 인공신경망의 딥러닝 연산을 수행하기 위하여, 상기 프리엠트를 통해 확보된 프로세싱 엘리먼트들을 할당하는 단계를 포함할 수 있다. 일 실시예에 따른 딥러닝 연산 수행 방법은 상기 실행 중인 제1 인공신경망이 없는 경우, 상기 제2 인공신경망 이 복수의 배치(batch)를 갖는지 판단하는 단계; 상기 제2 인공신경망이 복수의 배치를 갖는 경우, 상기 제2 인 공신경망을 복수의 서브 인공신경망들로 분리하는 단계; 상기 서브 인공신경망들의 특성에 기초하여, 상기 서브 인공신경망들의 딥러닝 연산을 동시에 수행할 수 있도록 프로세싱 엘리먼트들을 분배하는 단계; 상기 서브 인공 신경망들의 특성에 기초하여, 입력 데이터 및 부분합의 전파 방향을 설정하는 단계; 및 상기 분배된 프로세싱 엘리먼트들을 이용하여, 상기 서브 인공신경망들의 딥러닝 연산을 동시에 수행하는 단계를 더 포함할 수 있다. 상기 프로세싱 엘리먼트들을 분배하는 단계는 상기 서브 인공신경망들의 특성에 기초하여, 상기 프로세싱 엘리 먼트들의 분배 방식 및 분배 비율을 결정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2020-0144563", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "실시예들에 대한 특정한 구조적 또는 기능적 설명들은 단지 예시를 위한 목적으로 개시된 것으로서, 다양한 형 태로 변경되어 구현될 수 있다. 따라서, 실제 구현되는 형태는 개시된 특정 실시예로만 한정되는 것이 아니며, 본 명세서의 범위는 실시예들로 설명한 기술적 사상에 포함되는 변경, 균등물, 또는 대체물을 포함한다. 제1 또는 제2 등의 용어를 다양한 구성요소들을 설명하는데 사용될 수 있지만, 이런 용어들은 하나의 구성요소 를 다른 구성요소로부터 구별하는 목적으로만 해석되어야 한다. 예를 들어, 제1 구성요소는 제2 구성요소로 명 명될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 설명된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 으로 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들 을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 해당 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되 는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지않는다. 이하, 실시예들을 첨부된 도면들을 참조하여 상세하게 설명한다. 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조 부호를 부여하고, 이에 대한 중복되는 설명은 생략하기로 한 다. 도 1a는 인공신경망(Artificial Neural Network)를 이용한 딥러닝 연산 방법을 설명하기 위한 도면이다. 딥러닝(Deep Learning) 등을 포함하는 인공지능(AI) 알고리즘은 인공신경망(Artificial Neural Network, ANN) 에 입력 데이터를 입력시키고, 컨볼루션 등의 연산을 통해 출력 데이터를 학습하는 것을 특징으로 한다. 인공신경망은 생물학적 뇌를 모델링한 컴퓨터 과학적 아키텍쳐(Computational Architecture)를 의미할 수 있다. 인공신경망 내에서, 뇌의 뉴런들에 해당되는 노드들은 서로 연결되어 있고, 입력 데이터를 처리하기 위하여 집합적으로 동작한다. 다양한 종류의 뉴럴 네트워크들을 예로 들면, 컨볼루션 뉴럴 네트워크 (Convolutional Neural Network, CNN), 회귀 뉴럴 네트워크(Recurrent Neural Network, RNN), 딥 빌리프 네트 워크(Deep Belief Network, DBN), 제한된 볼츠만 기계(Restricted Boltzman Machine, RBM) 방식 등이 있으나, 이에 제한되지 않는다. 피드-포워드(feed-forward) 뉴럴 네트워크에서, 뉴럴 네트워크의 뉴런들은 다른 뉴런들 과의 연결들(links)을 갖는다. 이와 같은 연결들은 뉴럴 네트워크를 통해, 한 방향으로, 예를 들어 순방향 (forward direction)으로 확장될 수 있다. 도 1a를 참조하면, 인공신경망에 입력 데이터가 입력되고, 하나 이상의 레이어(layer)를 포함하는 인공 신 경망(예를 들어, 컨볼루션 뉴럴 네트워크(Convolution Neural Network, CNN))를 통해 출력 데이터가 출력되는 구조가 도시된다. 인공신경망은 2개 이상의 레이어를 보유한 딥 뉴럴 네트워크(deep neural networ k)일 수 있다. 컨볼루션 뉴럴 네트워크는 입력 데이터로부터 테두리, 선 색 등과 같은 \"특징들(features)\"을 추출하기 위해 이용될 수 있다. 컨볼루션 뉴럴 네트워크는 복수의 레이어를 포함할 수 있다. 각각의 레이어는 데이 터를 수신할 수 있고, 해당 레이어에 입력되는 데이터를 처리하여 해당 레이어에서 출력되는 데이터를 생성할 수 있다. 레이어에서 출력되는 데이터는, 컨볼루션 뉴럴 네트워크에 입력된 이미지 또는 입력된 특징 맵 (feature map)을 하나 이상의 필터(filter)의 웨이트(weight) 값과 컨볼루션 연산하여 생성한 특징 맵일 수 있 다. 컨볼루션 뉴럴 네트워크의 초기 레이어들은 입력으로부터 에지들 또는 그레디언트들과 같은 낮은 레벨 의 특징들을 추출하도록 동작될 수 있다. 컨볼루션 뉴럴 네트워크의 다음 레이어들은 이미지 내의 눈, 코 등과 같은 점진적으로 더 복잡한 특징들을 추출할 수 있다. 도 1b는 딥 러닝 연산에서 입력으로 제공되는 입력 특징 맵의 데이터와 필터를 설명하기 위한 도면이다. 도 1b를 참조하면, 입력 특징 맵은 인공신경망에 입력되는 이미지의 픽셀 값 또는 수치 데이터의 집합일 수 있으나, 이에 제한되지 않는다. 도 1b에서 입력 특징 맵은 인공신경망을 통해 학습할 대상이 되는 이 미지의 픽셀 값으로 정의될 수 있다. 예를 들어, 입력 특징 맵은 256×256의 픽셀과 K의 깊이(depth)를 가질 수 있다. 그러나, 상기 값은 예시적인 것이고, 입력 특징 맵의 픽셀 크기가 상기 예시로 한정되는 것은 아니다. 필터(110-1 내지 110-n)은 N개로 형성될 수 있다. 복수의 필터(110-1 내지 110-n) 각각은 n by n(n×n)의 웨 이트(weight) 값을 포함할 수 있다. 예를 들어, 복수의 필터(110-1 내지 110-n) 각각은 3×3의 픽셀과 K의 깊 이값을 가질 수 있다. 그러나, 상기 필터의 크기는 예시적인 것이고, 복수의 필터(110-1 내지 110-n) 각각의 크기가 상기 예시로 한정되는 것은 아니다. 도 1c는 딥러닝 기반에서 컨볼루션 연산을 수행하는 과정을 설명하기 위한 도면이다. 도 1c를 참조하면, 인공신경망에서 컨볼루션 연산을 수행하는 과정은, 각각의 레이어에서 입력 특징 맵과 필터와의 곱셈 및 덧셈 연산을 하여 출력 값을 생성하고, 출력 값을 누적하여 합산함으로써, 출력 특징 맵 을 생성하는 과정을 의미할 수 있다. 컨볼루션 연산 수행 과정은, 현재 레이어에서 입력 특징 맵의 좌측 상단으로부터 우측 하단까지 일정한 크 기, 즉 n×n 크기의 필터를 적용하여 곱셈 및 덧셈 연산을 수행하는 과정이다. 이하에서는, 필터의 크기가 3×3인 경우에 컨볼루션 연산을 수행하는 과정을 설명하기로 한다. 예를 들어, 먼저 입력 특징 맵의 좌측 상단 제1 영역에서 3×3, 즉 제1 방향으로 3개의 데이터와 제2 방향으로 3개의 데이터를 포함한 총 9개의 데이터(x11 내지 x33)를 각각 필터의 웨이트 값(weight)(w11 내지 w33)과 곱하는 연산을 수행한다. 이후, 곱셈 연산의 출력 값, 즉 x11*w11, x12*w12, x13*w13, x21*w21, x22*w22, x23*w23, x31*w31, x32*w32, x33*w33을 모두 누적하여 합산하면 출력 특징 맵의 제1-1 출력 데 이터(y11)가 생성된다. 이후, 입력 특징 맵의 좌측 상단의 제1 영역에서 제2 영역으로 데이터의 단위만큼 이동하면서 연산한다. 이 때, 컨볼루션 연산 과정에서 입력 특징 맵 내의 데이터가 이동하는 개수를 스트라이드 (stride)라고 하며, 스트라이드의 크기에 따라 생성되는 출력 특징 맵의 크기가 결정될 수 있다. 예를 들 어, 스트라이드가 1인 경우, 제2 영역에 포함된 총 9개의 입력 데이터(x12 내지 x34)를 필터의 웨이 트 값(w11 내지 w33)과 곱하는 연산을 수행하고, 곱셈 연산의 출력 값인 x12*w11, x13*w12, x14*w13, x22*w21, x23*w22, x24*w23, x32*w31, x33*w32, x34*w33을 모두 누적하여 합산하면 출력 특징 맵의 제1-2 출력 데 이터(y12)가 생성된다. 도 1d는 시스톨릭 어레이(systolic array)을 이용하여 컨볼루션 연산을 수행하는 방법을 설명하기 위한 도면이 다. 도 1d를 참조하면, 입력 특징 맵의 각 데이터는 일정한 레이턴시(latency)를 갖는 클럭(clock)에 따라 순 차적으로 프로세싱 엘리먼트들(Processing Elements; PEs)(141 내지 149)에 입력되는 시스톨릭 어레이로 매핑 (mapping)될 수 있다. 프로세싱 엘리먼트는 곱셈 덧셈 연산기일 수 있다. 제1 클럭에는 시스톨릭 어레이의 제1 행(①)의 제1-1 데이터(x11)가 제1 프로세싱 엘리먼트에 입력될 수 있다. 도 1d에는 도시되지 않았지만, 제1-1 데이터(x11)는 제1 클럭에서 w11의 웨이트 값과 곱해질 수 있다. 이후 제2 클럭에서는 제1-1 데이터(x11)는 제2 프로세싱 엘리먼트에 입력되고, 제2-1 데이터(x21)는 제1 프로세싱 엘리먼트에 입력되며, 제1-2 데이터(x12)는 제4 프로세싱 엘리먼트에 입력될 수 있다. 마 찬가지로, 제3 클럭에서 제1-1 데이터(x11)는 제3 프로세싱 엘리먼트에 입력되고, 제2-1 데이터(x21)는 제 2 프로세싱 엘리먼트에 입력되며, 제1-2 데이터(x12)는 제5 프로세싱 엘리먼트에 입력 될 수 있다. 제3 클럭에서 제3-1 데이터(x31)는 제1 프로세싱 엘리먼트에 입력되고, 제2-2 데이터(x22)는 제4 프로세싱 엘리먼트에 입력되며, 제1-3 데이터(x13)는 제7 프로세싱 엘리먼트에 입력될 수 있다. 전술한 바와 같이, 입력 특징맵은 순차적인 클럭에 따라 프로세싱 엘리먼트(141 내지 149) 내의 각 프로세 싱 엘리먼트에 입력되고, 각 클럭에 따라 입력된 웨이트 값과 곱셈 및 덧셈 연산이 수행될 수 있다. 순차적으 로 입력된 입력 특징 맵의 각 데이터와 웨이트 값의 곱셈 및 덧셈 연산을 통해 출력된 값들을 누적 합산함 에 따라 출력 특징 맵이 생성될 수 있다. 도 2a는 시스톨릭 어레이 상에서 복수의 인공신경망들의 우선순위를 고려한 시간적 멀티태스킹 구현방법을 설명 하기 위한 도면이다. 도 2a를 참조하면, 딥러닝 연산 장치는 시간적 멀티태스킹을 이용하여 하나의 시스톨릭 어레이에서 복수의 인공 신경망들을 실행할 수 있다. 딥러닝 연산 장치는 제1 시간 구간(t0 내지 t1)에는 A 인공신경망을 실행하고, 시간 t1에 컨텍스트 스위칭 (Context Switching)하여 제2 시간 구간(t1 내지 t2)에는 B 인공신경망을 실행하고, 시간 t2에 컨텍스트 스위칭하여 제3 시간 구간(t2 내지 t3)에는 다시 A 인공신경망을 실행할 수 있다. 인공신경망을 실행하는 것은 인공신경망의 딥러닝 연산을 수행하는 것을 의미할 수 있다. 그러나, 딥러닝 연산 장치는 시간적 멀티태스킹을 활용하여도 여전히 하나의 시스톨릭 어레이에서 동시에 복수 의 인공신경망을 실행할 수는 없다. 시간적 멀티태스킹의 특성 상 동일한 시스톨릭 어레이의 프로세싱 엘리먼 트들을 복수의 인공신경망들에게 분배가 불가능하다. 이로 인해, 시간적 멀티태스킹을 지원하는 딥러닝 연산 장치는 하나의 인공신경망만 실행시킬 경우 대비 높은 처리량(throughput) 및 단위 전력 당 인공 신경망 처리 (TOPS/Watt)를 달성하지 못하는 단점이 있다. 나아가, 시간적 멀티태스킹을 지원하는 딥러닝 연산 장치는 인공 신경망 간 컨텍스트 스위칭(Context Switching) 시간이 길기 때문에, 높은 실시간성을 보장할 수 없다. 도 2b는 일 실시예에 따른 공간적 멀티태스킹을 지원하는 딥러닝 연산 장치의 동작을 설명하기 위한 도면이다. 도 2b를 참조하면, 일 실시예에 따른 딥러닝 연산 장치는 공간적 멀티태스킹을 통해 시스톨릭 어레이의 프로세 싱 엘리먼트들을 복수의 인공신경망들에게 분배하여 동시에 복수의 인공신경망들을 실행할 수 있다. 딥러닝 연산 장치는 제1 시간 구간(t0 내지 t1)에는 A 인공신경망만 실행하고, 제2 시간 구간(t1 내지 t 2)에는 A 인공신경망 및 B 인공신경망을 동시에 실행하고, 제3 시간 구간(t2 내지 t3)에는 A 인공신경망 및 C 인공신경망을 동시에 실행할 수 있다. 딥 러닝 연산 장치는 하나의 시스톨릭 어레이에서 복수의 인공신경망들을 동시에 실행하여 인공신경망 처리량을 향상 시킬 수 있고, 높은 우선순위를 갖는 인공신경망의 실시간성을 보장할 수 있다. 아래에서 도 3a 내지 도 3b를 참조하여 공간적 멀티태스킹 동작 방법을, 도 4를 참조하여 일 실시예에 따른 딥 러닝 연산 장치의 하드웨어 구현의 예를, 도 5a 내지 도 5f를 참조하여 일 실시예에 따른 딥러닝 연산 장치의 구체적인 동작 방법을, 도 6을 참조하여 공간적 멀티태스킹을 통해 딥러닝 연산을 수행하는 방법을, 도 7을 참 조하여 공간적 멀티태스킹을 위한 뉴럴 프로세싱 유닛을 활용하는 방법을 설명한다. 도 3a는 일 실시예에 따른 공간적 멀티태스킹 동작 방법을 설명하기 위한 도면이다. 공간적 멀티태스킹을 지원하는 딥러닝 연산 장치는 2차원으로 프로세싱 엘리먼트들이 배치된 시스톨릭 어레이의 특성을 활용하여 프로세싱 엘리먼트들을 임의의 비율로 복수의 인공신경망에게 분배할 수 있다. 도 3a를 참조하면, A 인공신경망 및 B 인공신경망이 동시에 실행될 경우, A 인공신경망의 입력 데이터는 시스톨릭 어레이의 좌변으로 입력되고, B 인공신경망의 입력 데이터는 시스톨릭 어레이의 우변으로 입력될 수 있다. A 인공신경망의 입력 데이터 및 B 인공신경망의 입력 데이터는 각각 A 인공신경망의 입력 특징 맵 데이터 및 B 인공신경망의 입력 특징 맵 데이터일 수 있다. 시스톨릭 어레이의 양변에서 제공된 입력 데이터(310, 320)는 A인공신경망과 B인공신경망이 프로세싱 엘리먼트 들을 나눠 갖는 비율에 맞추어 횡으로 입력 데이터를 전파(propagate)하고, 연산 결과를 종으로 전파할 수 있다. 구체적으로, A인공신경망의 입력 데이터는 좌에서 우로 전파되고, 각 클럭에 따라 입력된 웨이트 값과 곱 셈 및 덧셈 연산이 수행될 수 있고, 순차적으로 입력된 입력 데이터와 웨이트 값의 곱셈 및 덧셈 연산을 통해 출력된 값들을 위에서 아래로 전파하며 누적 합산함에 따라 출력 데이터가 생성될 수 있다. B인공신경망의 입력 데이터는 우에서 좌로 전파되고, 각 클럭에 따라 입력된 웨이트 값과 곱셈 및 덧셈 연 산이 수행될 수 있고, 순차적으로 입력된 입력 데이터와 웨이트 값의 곱셈 및 덧셈 연산을 통해 출력된 값 들을 위에서 아래로 전파하며 누적 합산함에 따라 출력 데이터가 생성될 수 있다. 도 3b는 다른 실시예에 따른 공간적 멀티태스킹 동작 방법을 설명하기 위한 도면이다. 도 3b를 참조하면, A 인공신경망 및 B 인공신경망이 동시에 실행될 경우, A 인공신경망의 입력 데이터 및 B 인공신경망의 입력 데이터 모두 시스톨릭 어레이의 좌변으로 입력되고, 프로세싱 엘리먼트들을 나눠 갖 는 비율에 따라 횡으로 입력 데이터를 전파하고, 연산 결과를 종으로 전파할 수 있다. 구체적으로, A인공신경망의 입력 데이터는 우에서 좌로 전파되고, 각 클럭에 따라 입력된 웨이트 값과 곱 셈 및 덧셈 연산이 수행될 수 있고, 순차적으로 입력된 입력 데이터와 웨이트 값의 곱셈 및 덧셈 연산을 통해 출력된 값들을 아래에서 위로 전파하며 누적 합산함에 따라 출력 데이터가 생성될 수 있다. B 인공신경망의 입력 데이터는 좌에서 우로 전파되고, 각 클럭에 따라 입력된 웨이트 값과 곱셈 및 덧셈 연산이 수행될 수 있고, 순차적으로 입력된 입력 데이터와 웨이트 값의 곱셈 및 덧셈 연산을 통해 출력된 값들을 위에서 아래로 전파하며 누적 합산함에 따라 출력 데이터가 생성될 수 있다. 도 3a 및 도 3b와 같은 공간적 멀티태스킹을 지원하기 위해 일 실시예에 따른 딥러닝 연산 장치는 프로세서를 포함할 수 있다. 프로세서는 프로세싱 엘리먼트들을 나누는 방향(예를 들어, 상하, 좌우) 및 분배 비율을 결정 하고, 이를 고려하여 시스톨릭 어레이에 입력 데이터를 제공할 수 있다. 프로세서는 뉴럴 프로세싱 유닛(NPU; Neural Processing Unit)일 수 있다. 딥러닝 연산 장치는 시스톨릭 어레이의 각 프로세싱 엘리먼트들이 단방향이 아닌 양방향으로 입력 데이터를 전 파할 수 있는 구조가 필요할 수 있다. 이를 위해, 딥러닝 연산 장치는 시스톨릭 어레이의 좌우변으로부터 횡으 로 입력 데이터를 전파할 수 있는 하드웨어 유닛과 온칩 네트워크(Network-on-a-Chip, NoC) 및 시스톨릭 어레이 의 상하변으로부터 출력 데이터를 수신할 수 있는 하드웨어 유닛과 온칩 네트워크를 포함할 수 있다. 아래에서, 도 4를 참조하여 복수의 딥러닝 연산을 동시에 수행하는 딥러닝 연산 장치의 구체적인 구성요소를 설 명한다. 도 4는 일 실시예에 따른 복수의 딥러닝 연산을 동시에 수행하는 딥러닝 연산 장치의 하드웨어 구현의 예를 도 시한 도면이다. 도 4를 참조하면, 일 실시예에 따른 딥러닝 연산 장치는 메인 메모리, 글로벌 버퍼, 제1 시스톨릭 데 이터 셋업 모듈, 웨이트 버퍼, 시스톨릭 어레이 및 출력 결과 누적 레지스터를 포함할 수 있다. 딥러닝 연산 장치는 신경망 장치, 신경망 회로, 하드웨어 가속기, 프로세싱 유닛 등과 같이 신경망 연산을 수행 하기 위해 하드웨어적으로 구현된 연산 장치일 수 있다. 예를 들어, 딥러닝 연산 장치는 SoC(System on Chip), ASIC(application specific integrated circuit), CPU(Central Processing Unit), GPU(Graphics Processing Unit), VPU(Vision Processing Unit), 및 NPU(Neural Processing Unit) 등과 같은 다양한 반도체 장치를 이용 하여 구현될 수 있다. 시스톨릭 어레이는 좌우 및 상하 방향을 따라 배치되는 복수의 프로세싱 엘리먼트들을 포함할 수 있다. 시스톨릭 어레이는 동기 신호(예를 들면, 클럭 신호)에 맞추어서 연산을 수행할 수 있다. 시스톨릭 어레이는 프로세싱 엘리먼트 어레이(PE array)로 지칭될 수 있다. 시스톨릭 어레이는 클럭 신호에 따라 순차적으로 제1 시스톨릭 데이터 셋업 모듈 및 버퍼로부터 각각 제1 입력 데이터 및 제2 입력 데이터를 수신할 수 있다. 제1 입력 데이터는 입력 특징 맵 데이터일 수 있 고, 제2 입력 데이터는 웨이트 값일 수 있다. 시스톨릭 어레이는 입력 특징 맵 데이터와 웨이트 값을 이용하여 딥러닝 연산을 수행할 수 있다. 시스톨 릭 어레이의 연산 결과는 피처 맵 데이터를 생성하기 위한 중간 연산 결과인 부분합(Partial Sum)일 수 있 고, 부분합은 특정 방향으로 전파되어 출력 결과 누적 레지스터에 누적될 수 있다. 제1 시스톨릭 데이터 셋업 모듈은 입력 특징 맵(예를 들어, 도 1의 100) 데이터를 저장할 수 있다. 제1 시스톨릭 데이터 셋업 모듈은 시스톨릭 어레이의 좌변으로 입력 특징 맵의 데이터를 전달할 수 있다. 웨이트 버퍼는 필터(예를 들어, 도 1의 110-1 내지 110-n)의 웨이트 값을 저장할 수 있다. 웨이트 버퍼 는 시스톨릭 어레이의 상변으로 웨이트 값을 전달할 수 있다. 실시예에 있어서, 제1 시스톨릭 데이터 셋업 모듈 및 웨이트 버퍼는 서로 다른 메모리 장치들에서 각 각 구현되거나 또는 하나의 메모리 장치의 서로 다른 영역들에서 각각 구현될 수 있다. 딥러닝 연산 장치는 공간적 멀티태스킹을 지원하기 위해 제1 온칩 네트워크, 제2 시스톨릭 데이터 셋업 모듈 , 제2 온칩 네트워크(460 및 460-1 내지 460-n), 제3 온칩 네트워크(450-1 내지 450-n) 및 제4 온칩 네트 워크(455-1 내지 455-n)를 더 포함할 수 있다. 딥러닝 연산 장치는 제1 온칩 네트워크를 통해 프로세싱 엘리먼트들 사이의 상하좌우 데이터 전파를 수행할 수 있다. 종래의 딥러닝 연산 장치는 프로세싱 엘리먼트들 사이의 위에서 아래 방향 및 왼쪽에서 오른쪽 방향의 데이터 전파만 수행할 수 있는 반면에, 일 실시예에 따른 딥러닝 연산 장치는 제1 온칩 네트워크를 통해 프로세 싱 엘리먼트들 사이의 아래에서 위 방향 및 오른쪽에서 왼쪽 방향의 데이터 전파도 수행할 수 있다. 딥러닝 연산 장치는 제2 시스톨릭 데이터 셋업 모듈, 제2 온칩 네트워크(460 및 460-1 내지 460-n)를 통해 입력 특징 맵의 데이터를 시스톨릭 어레이의 우변으로 전달할 수 있다. 제2 시스톨릭 데이터 셋업 모듈 은 입력 특징 맵의 데이터를 시스톨릭 어레이의 우변으로 입력하는 타이밍을 조절하고, 제2 온칩 네 트워크(460 및 460-1 내지 460-n)는 입력 특징 맵의 데이터를 시스톨릭 어레이의 우변으로 전달할 수 있다. 딥러닝 연산 장치는 제3 온칩 네트워크(450-1 내지 450-n)를 통해 웨이트 값을 시스톨릭 어레이를 구성하 는 프로세싱 엘리먼트들의 하단으로 전달할 수 있다. 종래의 딥러닝 연산 장치는 프로세싱 엘리먼트들의 상단 으로만 웨이트 값을 전달할 수 있었지만, 일 실시예에 따른 딥러닝 연산 장치는 제3 온칩 네트워크(450-1 내지 450-n)를 통해 프로세싱 엘리먼트들의 하단으로도 웨이트 값을 전달할 수 있다. 딥러닝 연산 장치는 제4 온칩 네트워크(455-1 내지 455-n)를 통해 출력 결과 누적 레지스터를 수정할 수 있다. 종래의 딥러닝 연산 장치는 부분합이 시스톨릭 어레이의 하변으로만 전파되고, 전파된 부분합은 출 력 결과 누적 레지스터의 상단으로 전달되어 누적될 수 있다. 반면에, 일 실시예에 따른 딥러닝 연산 장 치는 시스톨릭 어레이의 상변으로도 부분합이 전파될 수 있다. 이에, 딥러닝 연산 장치는 제4 온칩 네트 워크(455-1 내지 455-n)를 통해 시스톨릭 어레이의 상변으로 전파되는 부분합을 출력 결과 누적 레지스터의 하단으로 전달할 수 있다. 딥러닝 연산 장치는 메인 메모리, 글로벌 버퍼, 제1 시스톨릭 데이터 셋업 모듈, 웨이트 버퍼 , 시스톨릭 어레이, 출력 결과 누적 레지스터, 제1 온칩 네트워크, 제2 시스톨릭 데이터 셋업 모듈, 제2 온칩 네트워크(460 및 460-1 내지 460-n), 제3 온칩 네트워크(450-1 내지 450-n) 및 제4 온칩 네트워크(455-1 내지 455-n)를 제어하기 위한 명령들을 생성할 수 있다. 예를 들어, 프로세서는 복수의 인공신 경망들의 특성에 기초하여, 상기 복수의 인공신경망들의 딥러닝 연산을 동시에 수행할 수 있도록 상기 프로세싱 엘리먼트들을 분배할 수 있고, 입력 데이터 및 부분합의 전파 방향을 설정할 수 있다. 제1 입력 데이터 전달 모듈은 제1 시스톨릭 데이터 셋업 모듈 및 제2 온칩 네트워크(460 및 460-1 내지 460-n)를 포함하는 개념이고, 제2 입력 데이터 전달 모듈은 웨이트 버퍼 및 제3 온칩 네트워크(450-1 내지 450-n)를 포함하고, 출력 데이터 수신 모듈은 출력 결과 누적 레지스터 및 제4 온칩 네트워크(455-1 내지 455-n)를 포함하는 개념일 수 있다. 도 4의 실시예에서 구성요소를 별도로 구성하여 도시한 것은 각 기능들을 구별하여 설명하기 위함이다. 따라서 실제로 제품을 구현하는 경우에 이들 모두를 프로세서에서 처리하도록 구성할 수도 있으며, 이들 중 일부만을 프로세서에서 처리하도록 구성할 수도 있다. 실시예에 있어서, 시스톨릭 어레이에 대한 웨이트 버퍼 및 출력 결과 누적 레지스터와 제1 시스 톨릭 데이터 셋업 모듈 및 제2 시스톨릭 데이터 셋업 모듈의 위치들은 도 4에서 도시된 것으로 한정 되지 않는다. 예를 들어, 웨이트 버퍼 및 출력 결과 누적 레지스터는 각각 시스톨릭 어레이의 왼쪽, 오른쪽 또는 오른쪽, 왼쪽 또는 아래쪽, 위쪽에 위치할 수도 있고 제1 시스톨릭 데이터 셋업 모듈 및 제2 시스톨릭 데이터 셋업 모듈은 각각 시스톨릭 어레이의 위쪽, 아래쪽 또는 아래쪽, 위쪽 또는 오른쪽, 왼쪽에 위치할 수도 있다. 도 5a 내지 도 5f는 일 실시예에 따른 딥러닝 연산 장치의 구체적인 연산 수행 과정을 예시적으로 도시한 도면 이다. 도 2b 내지 도 4의 설명은 도 5a 내지 도 5f에도 적용 가능하므로, 중복되는 내용의 설명은 생략한다. 도 5a 내지 도 5b는 시스톨릭 어레이의 프로세싱 엘리먼트들을 횡분배하여 2개의 인공신경망을 동시에 실행하는 딥러닝 연산 장치를, 도 5c 내지 도 5d는 시스톨릭 어레이의 프로세싱 엘리먼트들을 종분배하여 2개의 인공신경 망을 동시에 실행하는 딥러닝 연산 장치를, 도 5e 내지 도 5f는 시스톨릭 어레이의 프로세싱 엘리먼트들을 4분 할하여 4개의 인공신경망을 동시에 실행하는 딥러닝 연산 장치를 도시한다. 도 5a 및 도 5b를 참조하면, 딥러닝 연산 장치는 시스톨릭 어레이를 제1 영역 및 제2 영역로 횡분배 하여, 제1 영역에는 A 인공신경망을 실행하고, 제2 영역에는 B 인공신경망을 실행할 수 있다. 도 5a를 참조하면, 딥러닝 연산 장치는 제1 영역에는 A 인공신경망의 웨이트 값을, 제2 영역에는 B 인공신경망의 웨이트 값을 미리 전파할 수 있다. 딥러닝 연산 장치의 웨이트 버퍼는 메인 메모리로부터 A 인공신경망의 웨이트 값을 수신하여 저장하 고, 클럭 신호에 따라 A 인공신경망의 웨이트 값을 제1 영역의 프로세싱 엘리먼트들의 상단으로 전달할 수 있다. 또한, 딥러닝 연산 장치의 웨이트 버퍼는 메인 메모리로부터 B 인공신경망의 웨이트 값도 수신하여 저장할 수 있다. 딥러닝 연산 장치는 제3 온칩 네트워크를 통해 클럭 신호에 따라 B 인공신경망의 웨이트 값을 제2 영역의 프로세싱 엘리먼트들의 하단으로 전달할 수 있다. 도 5b를 참조하면, 웨이트 값을 전파한 후에 딥러닝 연산 장치는 제1 영역에 A 인공신경망의 입력 특징 맵 데이터를, 제2 영역에 B 인공신경망의 입력 특징 맵 데이터를 전파할 수 있다. 전술한 제1 시스톨릭 데이터 셋업 모듈은 제1-1 시스톨릭 데이터 셋업 모듈(520-1) 및 제 1-2 시스톨릭 데이터 셋업 모듈(520-2)을 포함할 수 있다. 다만, 제1 시스톨릭 데이터 셋업 모듈을 제1-1 시스톨릭 데이터 셋업 모 듈(520-1) 및 제 1-2 시스톨릭 데이터 셋업 모듈(520-2)로 구분한 것은 각각의 모듈이 논리적으로 분리될 수 있 음을 나타나기 위해 별도로 도면에 표시한 것이며, 물리적으로 반드시 별도의 구성요소임을 의미하는 것은 아니 다. 딥러닝 연산 장치의 제1-1 시스톨릭 데이터 셋업 모듈(520-1)은 메인 메모리로부터 A 인공신경망의 입력 특징 맵 데이터를 수신하여 저장하고, 클럭 신호에 따라 A 인공신경망의 입력 특징 맵 데이터를 제1 영역의 좌변으로 전달할 수 있다. 이를 통해, 제1 영역의 프로세싱 엘리먼트들은 왼쪽에서 오른쪽 방향으로 A 인공신경망의 입력 특징 맵 데이터를 전파할 수 있다. 딥러닝 연산 장치의 제1-2 시스톨릭 데이터 셋업 모듈(520-2)은 메인 메모리로부터 B 인공신경망의 입력 특징 맵 데이터를 수신하여 저장하고, 클럭 신호에 따라 B 인공신경망의 입력 특징 맵 데이터를 제2 영역 의 좌변으로 전달할 수 있다. 이를 통해, 제2 영역의 프로세싱 엘리먼트들은 왼쪽에서 오른쪽 방향으로 B 인공신경망의 입력 특징 맵 데이터를 전파할 수 있다. 제1 영역의 프로세싱 엘리먼트들은 순차적으로 입력된 A 인공신경망의 입력 특징 맵 데이터와 웨이트 값의 곱셈 및 덧셈 연산을 수행하여 획득한 부분합을 아래에서 위 방향으로 전파할 수 있다. 딥러닝 연산 장치는 제 4 온칩 네트워크를 이용하여 제1 영역의 상변으로 전파되는 부분합을 출력 결과 누적 레지스터의 하 단으로 전달할 수 있다. 제2 영역의 프로세싱 엘리먼트들은 순차적으로 입력된 B 인공신경망의 입력 특징 맵 데이터와 웨이트 값의 곱셈 및 덧셈 연산을 수행하여 획득한 부분합을 위에서 아래 방향으로 전파할 수 있고, 제2 영역의 하변으 로 전파되는 부분합은 출력 결과 누적 레지스터의 상단으로 전달될 수 있다. 도 5c 및 도 5d를 참조하면, 딥러닝 연산 장치는 시스톨릭 어레이를 제3 영역 및 제4 영역로 종분배 하여, 제3 영역에는 A 인공신경망을 실행하고, 제4 영역에는 B 인공신경망을 실행할 수 있다. 도 5c를 참조하면, 딥러닝 연산 장치는 제3 영역에는 A 인공신경망의 웨이트 값을, 제4 영역에는 B 인공신경망의 웨이트 값을 미리 전파할 수 있다. 딥러닝 연산 장치의 웨이트 버퍼는 메인 메모리로부터 A 인공신경망 및 B 인공신경망의 웨이트 값을 수신하여 저장하고, 클럭 신호에 따라 A 인공신경망의 웨이트 값을 제3 영역의 프로세싱 엘리먼트들의 상 단으로, B인공신경망의 웨이트 값을 제4영역(555의 프로세싱 엘리먼트들의 상단으로 전달할 수 있다. 도 5d를 참조하면, 웨이트 값을 전파한 후에 딥러닝 연산 장치는 제3 영역에 A 인공신경망의 입력 특징 맵 데이터를, 제4 영역에 B 인공신경망의 입력 특징 맵 데이터를 전파할 수 있다. 딥러닝 연산 장치의 제1 시스톨릭 데이터 셋업 모듈(520-1 및 520-2)은 메인 메모리로부터 A 인공신경망의 입력 특징 맵 데이터를 수신하여 저장하고, 클럭 신호에 따라 A 인공신경망의 입력 특징 맵 데이터를 제3 영역 의 좌변으로 전달할 수 있다. 이를 통해, 제3 영역의 프로세싱 엘리먼트들은 왼쪽에서 오른쪽 방향 으로 A 인공신경망의 입력 특징 맵 데이터를 전파할 수 있다. 딥러닝 연산 장치의 제2 시스톨릭 데이터 셋업 모듈(545-1 및 545-2)은 메인 메모리로부터 B 인공신경망의 입력 특징 맵 데이터를 수신하여 저장할 수 있다. 제1 시스톨릭 데이터 셋업 모듈(545-1 및 545-2)과 마찬가지 로, 전술한 제2 시스톨릭 데이터 셋업 모듈은 제2-1 시스톨릭 데이터 셋업 모듈(545-1) 및 제 2-2 시스톨릭 데 이터 셋업 모듈(545-2)을 포함할 수 있다. 다만, 제2 시스톨릭 데이터 셋업 모듈을 제2-1 시스톨릭 데이터 셋 업 모듈(545-1) 및 제 2-2 시스톨릭 데이터 셋업 모듈(545-2)로 구분한 것은 각각의 모듈이 논리적으로 분리될 수 있음을 나타나기 위해 별도로 도면에 표시한 것이며, 물리적으로 반드시 별도의 구성요소임을 의미하는 것은 아니다. 딥러닝 연산 장치는 제2 온칩 네트워크를 이용하여 B 인공신경망의 입력 특징 맵 데이터를 제4 영역의 우 변으로 입력할 수 있다. 이를 통해, 제4 영역의 프로세싱 엘리먼트들은 오른쪽에서 왼쪽 방향으로 B 인공 신경망의 입력 특징 맵 데이터를 전파할 수 있다. 제3 영역의 프로세싱 엘리먼트들은 순차적으로 입력된 A 인공신경망의 입력 특징 맵 데이터와 웨이트 값의 곱셈 및 덧셈 연산을 수행하여 획득한 부분합을 아래에서 위 방향으로 전파할 수 있다. 제4 영역의 프로세싱 엘리먼트들은 순차적으로 입력된 B 인공신경망의 입력 특징 맵 데이터와 웨이트 값의 곱셈 및 덧셈 연산을 수행하여 획득한 부분합을 위에서 아래 방향으로 전파할 수 있고, 제4 영역의 하변으 로 전파되는 부분합은 출력 결과 누적 레지스터의 상단으로 전달될 수 있다. 도 5e 및 도 5f를 참조하면, 딥러닝 연산 장치는 시스톨릭 어레이를 제5 영역, 제6 영역, 제7 영역 및 제8 영역으로 4분할하여, 제5 영역에는 A 인공신경망을 실행하고, 제6 영역에는 B 인 공신경망을 실행하고, 제7 영역에는 C 인공신경망을 실행하고, 제8 영역에는 D 인공신경망을 실행할 수 있다.도 5e를 참조하면, 딥러닝 연산 장치는 제5 영역에는 A 인공신경망의 웨이트 값을, 제6 영역에는 B 인공신경망의 웨이트 값을, 제7 영역에는 C 인공신경망의 웨이트 값을, 제8 영역에는 D 인공신경망의 웨이트 값을 미리 전파할 수 있다. 딥러닝 연산 장치의 웨이트 버퍼는 메인 메모리로부터 A 인공신경망 및 B 인공신경망의 웨이트 값을 수신하여 저장하고, 클럭 신호에 따라 각각 A 인공신경망 및 B 인공신경망의 웨이트 값을 제5 영역 및 제6 영역의 프로세싱 엘리먼트들의 상단으로 전달할 수 있다. 또한, 딥러닝 연산 장치의 웨이트 버퍼는 메인 메모리로부터 C 인공신경망 및 D 인공신경망의 웨이트 값도 수신하여 저장할 수 있다. 딥러닝 연산 장치는 제3 온칩 네트워크를 통해 클럭 신호에 따라 C 인공신경망 및 D 인공신경망의 웨이트 값을 제7 영역 및 제8 영역의 프로세싱 엘리먼트들의 하단으로 전달할 수 있다. 도 5f를 참조하면, 웨이트 값을 전파한 후에 딥러닝 연산 장치는 제5 영역에는 A 인공신경망의 입력 특징 맵 데이터를, 제6 영역에는 B 인공신경망의 입력 특징 맵 데이터를, 제7 영역에는 C 인공신경망의 입 력 특징 맵 데이터를, 제8 영역에는 D 인공신경망의 입력 특징 맵 데이터를 전파할 수 있다. 딥러닝 연산 장치의 제1-1 시스톨릭 데이터 셋업 모듈(520-1)은 메인 메모리로부터 A 인공신경망의 입력 특징 맵 데이터를 수신하여 저장하고, 클럭 신호에 따라 A 인공신경망의 입력 특징 맵 데이터를 제5 영역 의 좌변으로 전달할 수 있다. 이를 통해, 제5 영역의 프로세싱 엘리먼트들은 왼쪽에서 오른쪽 방향으로 A 인공신경망의 입력 특징 맵 데이터를 전파할 수 있다. 딥러닝 연산 장치의 제1-2 시스톨릭 데이터 셋업 모듈(520-2)은 메인 메모리로부터 C 인공신경망의 입력 특징 맵 데이터를 수신하여 저장하고, 클럭 신호에 따라 C 인공신경망의 입력 특징 맵 데이터를 제7 영역 의 좌변으로 전달할 수 있다. 이를 통해, 제7 영역의 프로세싱 엘리먼트들은 왼쪽에서 오른쪽 방향으로 C 인공신경망의 입력 특징 맵 데이터를 전파할 수 있다. 딥러닝 연산 장치의 제2-1 시스톨릭 데이터 셋업 모듈(545-1)은 메인 메모리로부터 B 인공신경망의 입력 특징 맵 데이터를 수신하여 저장할 수 있다. 딥러닝 연산 장치는 제2 온칩 네트워크를 이용하여 B 인공신경망 의 입력 특징 맵 데이터를 제6 영역의 우변으로 입력할 수 있다. 이를 통해, 제6 영역의 프로세싱 엘리먼트들은 오른쪽에서 왼쪽 방향으로 B 인공신경망의 입력 특징 맵 데이터를 전파할 수 있다. 딥러닝 연산 장치의 제2-2 시스톨릭 데이터 셋업 모듈(545-2)은 메인 메모리로부터 D 인공신경망의 입력 특징 맵 데이터를 수신하여 저장할 수 있다. 딥러닝 연산 장치는 제2 온칩 네트워크를 이용하여 D 인공신경망 의 입력 특징 맵 데이터를 제8 영역의 우변으로 입력할 수 있다. 이를 통해, 제8 영역의 프로세싱 엘리먼트들은 오른쪽에서 왼쪽 방향으로 D 인공신경망의 입력 특징 맵 데이터를 전파할 수 있다. 제5 영역의 프로세싱 엘리먼트들은 순차적으로 입력된 A 인공신경망의 입력 특징 맵 데이터와 웨이트 값의 곱셈 및 덧셈 연산을 수행하여 획득한 부분합을 아래에서 위 방향으로 전파할 수 있다. 딥러닝 연산 장치는 제 4 온칩 네트워크를 이용하여 제5 영역의 상변으로 전파되는 부분합을 출력 결과 누적 레지스터의 좌 측 하단으로 전달할 수 있다. 제7 영역의 프로세싱 엘리먼트들은 순차적으로 입력된 C 인공신경망의 입력 특징 맵 데이터와 웨이트 값의 곱셈 및 덧셈 연산을 수행하여 획득한 부분합을 위에서 아래 방향으로 전파할 수 있고, 제7 영역의 하변으 로 전파되는 부분합은 출력 결과 누적 레지스터의 좌측 상단으로 전달될 수 있다. 제6 영역의 프로세싱 엘리먼트들은 순차적으로 입력된 B 인공신경망의 입력 특징 맵 데이터와 웨이트 값의 곱셈 및 덧셈 연산을 수행하여 획득한 부분합을 아래에서 위 방향으로 전파할 수 있다. 딥러닝 연산 장치는 제 4 온칩 네트워크를 이용하여 제6 영역의 상변으로 전파되는 부분합을 출력 결과 누적 레지스터의 우 측 하단으로 전달할 수 있다. 제8 영역의 프로세싱 엘리먼트들은 순차적으로 입력된 D 인공신경망의 입력 특징 맵 데이터와 웨이트 값의 곱셈 및 덧셈 연산을 수행하여 획득한 부분합을 위에서 아래 방향으로 전파할 수 있고, 제8 영역의 하변으 로 전파되는 부분합은 출력 결과 누적 레지스터의 우측 상단으로 전달될 수 있다. 도 6은 공간적 멀티태스킹을 통해 딥러닝 연산을 수행하는 방법을 설명하기 위한 순서도이다. 도 6을 참조하면, 단계들(610 내지 655)는 도 2b 내지 도 5f를 참조하여 전술한 딥러닝 연산 장치에 의해 수행 될 수 있다. 단계에서, 딥러닝 연산 장치는 실행 중인 제1 인공신경망이 있는지 판단할 수 있다. 단계에서, 실행 중인 제1 인공신경망이 있는 경우, 딥러닝 연산 장치는 제1 인공신경망의 특성 및 새롭게 실행될 제2 인공신경망의 특성에 기초하여 제1 인공신경망의 딥러닝 연산 및 제2 인공신경망의 딥러닝 연산을 동시에 수행할 수 있도록 프로세싱 엘리먼트들을 분배할 수 있다. 딥러닝 연산 장치는 제1 인공신경망의 특성 및 제2 인공신경망의 특성에 기초하여, 프로세싱 엘리먼트들의 분배 방식 및 프로세싱 엘리먼트들의 분배 비율을 결정할 수 있다. 인공신경망의 특성은 예를 들어, 인공 신경망 레 이어 개수, 각 레이어 별 입력, 웨이트 값, 출력 데이터의 크기 등을 포함할 수 있다. 딥러닝 연산 장치는 결정된 분배 방식 및 분배 비율에 기초하여, 제1 인공신경망의 딥러닝 연산을 프리엠트 (preempt)하여, 프로세싱 엘리먼트들을 확보하고, 프리엠트를 통해 확보된 프로세싱 엘리먼트들을 제2 인공신경 망의 딥러닝 연산에 할당할 수 있다. 단계에서, 딥러닝 연산 장치는 제1 인공신경망의 특성 및 상기 제2 인공신경망의 특성에 기초하여, 입력 데이터 및 부분합의 전파 방향을 설정할 수 있다. 딥러닝 연산 장치는 제1 인공신경망 및 제2 인공신경망의 입 력 데이터를 좌우 중 어느 방향으로 전파할지, 부분합을 상하 중 어느 방향으로 전파할지 설정할 수 있다. 단계에서, 딥러닝 연산 장치는 분배된 프로세싱 엘리먼트들을 이용하여, 제1 인공신경망의 딥러닝 연산 및 제2 인공신경망의 딥러닝 연산을 동시에 수행할 수 있다. 실행 중인 제1 인공신경망이 없는 경우, 딥러닝 연산 장치는 시스톨릭 어레이의 모든 프로세싱 엘리먼트들을 이 용하여 제2 인공신경망을 실행할 수도 있다. 나아가, 딥러닝 연산 장치는 단일 인공신경망 실행하는 경우에도 인공신경망 처리량(Throughput) 향상, 단위전 력 당 인공신경망 처리량(TOPS/Watt) 향상을 위해 하나의 인공신경망을 복수의 서브 인공신경망들로 분리하여, 서브 인공신경망들을 동시에 실행할 수도 있다. 단계에서, 딥러닝 연산 장치는 제2 인공신경망이 복수의 배치(batch)를 갖는지 판단할 수 있다. 단계에서, 제2 인공신경망이 복수의 배치를 갖는 경우(예를 들어, 이미지 인식(Image Recognition)을 수행 할 이미지의 수가 여러 개인 경우), 딥러닝 연산 장치는 제2 인공신경망을 복수의 서브 인공신경망들로 분리할 수 있다. 예를 들어, 딥러닝 연산 장치는 배치를 반씩 나눠 갖는 2개의 서브 인공신경망으로 분리할 수 있다. 단계에서, 딥러닝 연산 장치는 서브 인공신경망들의 특성에 기초하여, 서브 인공신경망들의 딥러닝 연산을 동시에 수행할 수 있도록 프로세싱 엘리먼트들을 분배할 수 있다. 단계에서, 딥러닝 연산 장치는 서브 인공신경망들의 특성에 기초하여, 입력 데이터 및 부분합의 전파 방향 을 설정할 수 있다. 예를 들어, 딥러닝 연산 장치는 시스톨릭 어레이의 프로세싱 엘리먼트들을 2개의 서브 인 공신경망들에게 동일하게 분배할 수 있다.인 단계에서, 딥러닝 연산 장치는 분배된 프로세싱 엘리먼트들을 이용하여, 상기 서브 인공신경망들의 딥러닝 연산을 동시에 수행할 수 있다. 단일 인공신경망을 복수의 서브 인공신경망들로 분리하여, 서브 인공신경망들을 동시에 실행하는 방법은 인공신 경망을 구성하는 다양한 레이어들의 형태가 극단적일 때 큰 효과를 발휘할 수 있다. 예를 들어, 웨이트 고정 (weight-stationary) 뉴럴 프로세싱 유닛의 경우, 출력 채널(Output Channel)의 수가 프로세싱 엘리먼트의 가 로변 길이보다 작으면 계산 자원을 충분히 활용하지 못하는 단점이 존재한다. 서브 인공신경망들을 동시에 실 행하는 방법에 따르면, 위 예시와 같이 프로세싱 엘리먼트를 충분히 활용 못하는 경우에 대하여 인공신경망을 복수의 서브 인공신경망으로 분할 및 동시 실행함으로써 기존의 단일 인공신경망만 실행하는 경우에 비하여 높 은 성능을 달성할 수 있다. 단계에서, 제2 인공신경망이 하나의 배치를 갖는 경우 딥러닝 연산 장치는 시스톨릭 어레이의 모든 프로세 싱 엘리먼트들을 이용하여 제2 인공신경망을 실행할 수 있다. 도 7은 일 실시예에 따른 공간적 멀티태스킹을 위한 뉴럴 프로세싱 유닛을 활용하는 방법을 설명하기 위한 도면 이다. 도 7을 참조하면, 일 실시예에 따른 딥러닝 연산 장치는 공간적 멀티태스킹을 위한 뉴럴 프로세싱 유닛이 부착 된 서버, 데스크탑 등 다중 사용자 환경에서 복수의 인공신경망(예를 들어, A 인공신경망(710-1) 및 B 인공신경 망(710-2))을 동시에 실행할 수 있다. 복수의 인공신경망들은 TensorFlow, PyTorch와 같은 인공신경망 프레임워크(Neural Network Framework)를 통해 뉴럴 프로세싱 유닛을 활용 요청을 할 수 있다. 이러한 요청은 더 낮은 단계의 소프트웨어인 인공신경망 스케쥴러(Neural Network Scheduler)에게 전달될 수 있다. 종래 뉴럴 프로세싱 유닛은 공간적 멀티태스킹을 지원하지 않기에 뉴럴 프로세싱 유닛에 하나의 인공신경망 실 행 명령을 보낸 후, 해당 인공신경망의 실행이 완료될 때 까지 이후의 인공신경망들의 실행 요청을 뉴럴 프로세 싱 유닛에게 보내지 않았다. 반면에, 일 실시예에 따른 딥러닝 연산 장치는 공간적 멀티태스킹을 위하여 여러 인공신경망들을 동시에 실행할 수 있으므로, 공간적 멀티태스킹을 고려한 인공신경망 스케쥴러가 복수의 인공신경망 실행 명령을 뉴럴 프 로세싱 유닛에게 전달할 수 있다. 이때, 뉴럴 프로세싱 유닛은 하드웨어이고 인공신경망 스케쥴러는 소프트웨어이기에 이 둘 간의 통신을 가능케 하는 뉴럴 프로세싱 유닛 디바이스 드라이버(Neural Processing Unit Device Driver)를 거쳐 인공신경망 실행 명령들을 전달할 수 있다. 딥러닝 연산 장치는 공간적 멀티태스킹을 지원하는 뉴럴 프로세싱 유닛이 공간적 멀티태스킹을 고려한 인 공신경망 스케쥴러가 실행 명령을 보낸 복수의 인공신경망들을 동시에 실행할 수 있다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리 케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처 리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2020-0144563", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하 나의 프로세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단 독으로 또는 조합하여 포함할 수 있으며 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구 성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 위에서 설명한 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 또는 복수의 소프트웨어 모듈로서 작동하 도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2020-0144563", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 이를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2020-0144563", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 인공신경망(Artificial Neural Network)를 이용한 딥러닝 연산 방법을 설명하기 위한 도면이다. 도 1b는 딥 러닝 연산에서 입력으로 제공되는 입력 특징 맵의 데이터와 필터를 설명하기 위한 도면이다. 도 1c는 딥러닝 기반에서 컨볼루션 연산을 수행하는 과정을 설명하기 위한 도면이다. 도 1d는 시스톨릭 어레이(systolic array)을 이용하여 컨볼루션 연산을 수행하는 방법을 설명하기 위한 도면이 다. 도 2a는 시스톨릭 어레이 상에서 복수의 인공신경망들의 우선순위를 고려한 시간적 멀티태스킹 구현방법을 설명 하기 위한 도면이다. 도 2b는 일 실시예에 따른 공간적 멀티태스킹을 지원하는 딥러닝 연산 장치의 동작을 설명하기 위한 도면이다. 도 3a는 일 실시예에 따른 공간적 멀티태스킹 동작 방법을 설명하기 위한 도면이다. 도 3b는 다른 실시예에 따른 공간적 멀티태스킹 동작 방법을 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 복수의 딥러닝 연산을 동시에 수행하는 딥러닝 연산 장치의 하드웨어 구현의 예를 도 시한 도면이다. 도 5a 내지 도 5f는 일 실시예에 따른 딥러닝 연산 장치의 구체적인 연산 수행 과정을 예시적으로 도시한 도면 이다. 도 6은 공간적 멀티태스킹을 통해 딥러닝 연산을 수행하는 방법을 설명하기 위한 순서도이다. 도 7은 일 실시예에 따른 공간적 멀티태스킹을 위한 뉴럴 프로세싱 유닛을 활용하는 방법을 설명하기 위한 도면 이다."}
