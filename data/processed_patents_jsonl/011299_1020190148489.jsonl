{"patent_id": "10-2019-0148489", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0060923", "출원번호": "10-2019-0148489", "발명의 명칭": "의료용 인공 신경망 기반 대표 영상을 제공하는 의료 영상 판독 지원 장치 및 방법", "출원인": "주식회사 코어라인소프트", "발명자": "이상민"}}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "의료용 인공 신경망에 기반하여 의료 영상의 판독을 지원하는 의료 영상 판독 지원 장치로서, 상기 의료 영상판독 지원 장치는 컴퓨팅 시스템을 포함하며 상기 컴퓨팅 시스템은 적어도 하나 이상의 프로세서를 포함하고,상기 적어도 하나 이상의 프로세서는 제1 의료 영상에 대한 제1 인공 신경망의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신하고,상기 제1 분석 결과에 기반하여 상기 제1 의료 영상의 대표적인 시각화 형태인 제1 시각화 형태를 생성하고,상기 제1 의료 영상 및 상기 제1 분석 결과를 상기 제1 시각화 형태에 기반하여 시각화하는 인공 신경망 기반의료 영상 판독 지원 장치."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 적어도 하나 이상의 프로세서는 상기 제1 시각화 형태에 기반하여 시각화된 상기 제1 분석 결과에 대한 사용자의 승인 여부를 수신할 수 있는제1 사용자 메뉴를 제공하는 인공 신경망 기반 의료 영상 판독 지원 장치."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과에 대하여 상기 사용자가 승인하지 않은 경우, 상기 제1 의료 영상에 대하여 상기 제1 분석결과와 대응하는 제2 분석 결과를 상기 제1 분석 결과와는 독립적으로 생성할 수 있는 제2 사용자 메뉴를 제공하는 인공 신경망 기반 의료 영상 판독 지원 장치."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과에 대하여 상기 사용자가 승인한 경우, 상기 제1 분석 결과를 상기 제1 의료 영상과 관련시켜 데이터베이스에 저장하는 인공 신경망 기반 의료 영상 판독 지원 장치."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과를 상기 제1 의료 영상의 상기 제1 시각화 형태에 오버레이하여 시각화하는 인공 신경망 기반 의료 영상 판독 지원 장치."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과가 상기 제1 시각화 형태에 포함되도록 상기 제1 의료 영상 및 상기 제1 분석 결과에 기반한공개특허 10-2021-0060923-3-상기 제1 시각화 형태를 생성하는 인공 신경망 기반 의료 영상 판독 지원 장치."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과가 포함하는 상기 제1 의료 영상에 대한 영상 분할, 임상적 진단, 및 상기 제1 의료 영상 내에서 분할된 객체에 대한 정량적 측정 결과 중 적어도 하나 이상에 기반하여 상기 제1 시각화 형태를 생성하는인공 신경망 기반 의료 영상 판독 지원 장치."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 제1 시각화 형태는 상기 제1 의료 영상의 적어도 하나 이상의 뷰, 상기 제1 의료 영상 중에서 상기 제1 분석 결과와의 관련도에 기반하여 선택되는 상기 제1 의료 영상의 적어도 일부, 및 상기 제1 의료 영상의 재구성 중 적어도 하나 이상을포함하고,상기 제1 분석 결과는 상기 제1 분석 결과가 포함하는 정량화된 정보에 기반하여 구분될 수 있도록 시각화되는인공 신경망 기반 의료 영상 판독 지원 장치."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 제1 인공 신경망은 상기 제1 의료 영상에 대한 영상 분할, 임상적 진단, 및 상기 제1 의료 영상 내에서 분할된 객체에 대한 정량적 측정 결과 중 적어도 하나 이상을 상기 제1 분석 결과로서 제공하는 인공 신경망 기반의료 영상 판독 지원 장치."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 컴퓨팅 시스템은 복수의 제2 의료 영상들 각각에 대하여 분석된 복수의 제3 분석 결과에 대하여 전문가가 선택한 복수의 제2 시각화 형태를 입력받고, 상기 복수의 제3 분석 결과와 상기 복수의 제2 시각화 형태 간의 관련성에 기반한 시각화 형태를 생성하는 기능을 학습한 인공 신경망인 제2 인공 신경망을 더 포함하고,상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과를 상기 제2 인공 신경망에 입력하고, 상기 제2 인공 신경망의 추론에 의하여 상기 제1 시각화 형태를 획득하도록 상기 제2 인공 신경망을 제어하는 인공 신경망 기반 의료 영상 판독 지원 장치."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 컴퓨팅 시스템은 외부의 상기 제1 인공 신경망과 데이터를 송수신하는 통신 모듈;을 더 포함하고,상기 적어도 하나 이상의 프로세서는 상기 통신 모듈을 경유하여 상기 제1 의료 영상에 대한 상기 제1 인공 신경망의 추론에 의하여 얻어지는 상기제1 분석 결과를 획득하거나 수신하는 인공 신경망 기반 의료 영상 판독 지원 장치."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2021-0060923-4-제4항에 있어서,상기 컴퓨팅 시스템은 외부의 상기 데이터베이스와 데이터를 송수신하는 통신 모듈;을 더 포함하고,상기 적어도 하나 이상의 프로세서는 상기 통신 모듈을 경유하여 상기 제1 분석 결과를 상기 제1 의료 영상과 관련시켜 상기 데이터베이스에 저장하는 인공 신경망 기반 의료 영상 판독 지원 장치."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "컴퓨팅 시스템에서 실행되는 인공 신경망 기반 의료 영상 판독 지원 방법에 있어서, 상기 컴퓨팅 시스템은 적어도 하나 이상의 프로세서를 포함하고,상기 적어도 하나 이상의 프로세서가, 제1 의료 영상에 대한 제1 인공 신경망의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신하는 단계; 상기 적어도 하나 이상의 프로세서가, 상기 제1 분석 결과에 기반하여 상기 제1 의료 영상의 대표적인 시각화형태인 제1 시각화 형태를 생성하는 단계; 및상기 적어도 하나 이상의 프로세서가, 상기 제1 의료 영상 및 상기 제1 분석 결과를 상기 제1 시각화 형태에 기반하여 시각화하는 단계; 를 포함하는 인공 신경망 기반 의료 영상 판독 지원 방법."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 적어도 하나 이상의 프로세서가, 상기 제1 의료 영상의 상기 제1 시각화 형태에 기반하여 시각화된 상기제1 분석 결과에 대한 사용자의 승인 여부를 수신할 수 있는 제1 사용자 메뉴를 제공하는 단계;를 더 포함하는 인공 신경망 기반 의료 영상 판독 지원 방법."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 제1 분석 결과에 대하여 상기 사용자가 승인하지 않은 경우, 상기 적어도 하나 이상의 프로세서가, 상기제1 의료 영상에 대하여 상기 제1 분석 결과와 대응하는 제2 분석 결과를 상기 제1 분석 결과와는 독립적으로생성할 수 있는 제2 사용자 메뉴를 제공하는 단계;를 더 포함하는 인공 신경망 기반 의료 영상 판독 지원 방법."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 제1 분석 결과에 대하여 상기 사용자가 승인한 경우, 상기 적어도 하나 이상의 프로세서가, 상기 제1 분석결과를 상기 제1 의료 영상과 관련시켜 데이터베이스에 저장하는 단계;를 더 포함하는 인공 신경망 기반 의료 영상 판독 지원 방법."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 제1 시각화 형태는 상기 제1 의료 영상의 적어도 하나 이상의 뷰, 상기 제1 의료 영상 중에서 상기 제1 분석 결과와의 관련도에 기반하여 선택되는 상기 제1 의료 영상의 적어도 일부, 상기 제1 의료 영상의 재구성 중 적어도 하나 이상을 포함공개특허 10-2021-0060923-5-하고,상기 적어도 하나 이상의 프로세서가, 상기 제1 의료 영상 및 상기 제1 분석 결과를 상기 제1 시각화 형태에 기반하여 시각화하는 단계는, 상기 제1 분석 결과가 포함하는 정량화된 정보에 기반하여 구분될 수 있도록 상기 제1 분석 결과를 시각화하는인공 신경망 기반 의료 영상 판독 지원 방법."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서,상기 컴퓨팅 시스템은 복수의 제2 의료 영상들 각각에 대하여 분석된 복수의 제3 분석 결과에 대하여 전문가가 선택한 복수의 제2 시각화 형태를 입력받고, 상기 복수의 제3 분석 결과와 상기 복수의 제2 시각화 형태 간의 관련성에 기반한 시각화 형태를 생성하는 기능을 학습한 인공 신경망인 제2 인공 신경망을 더 포함하고,상기 적어도 하나 이상의 프로세서가, 상기 제1 분석 결과에 기반하여 상기 제1 의료 영상의 대표적인 시각화형태인 제1 시각화 형태를 생성하는 단계는, 상기 적어도 하나 이상의 프로세서가, 상기 제1 분석 결과를 상기 제2 인공 신경망에 입력하고, 상기 제2 인공신경망의 추론에 의하여 상기 제1 시각화 형태를 획득하도록 상기 제2 인공 신경망을 제어하는 인공 신경망 기반 의료 영상 판독 지원 방법."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제13항에 있어서,상기 적어도 하나 이상의 프로세서가, 상기 제1 의료 영상에 대한 상기 제1 인공 신경망의 추론에 의하여 얻어지는 상기 제1 분석 결과를 획득하거나 수신하는 단계는 상기 컴퓨팅 시스템 외부의 상기 제1 인공 신경망과 데이터를 송수신하는 통신 모듈을 경유하여, 상기 적어도하나 이상의 프로세서가 상기 제1 분석 결과를 획득하거나 수신하는 인공 신경망 기반 의료 영상 판독 지원 방법."}
{"patent_id": "10-2019-0148489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제16항에 있어서,상기 적어도 하나 이상의 프로세서가, 상기 제1 분석 결과를 상기 제1 의료 영상과 관련시켜 상기 데이터베이스에 저장하는 단계는상기 컴퓨팅 시스템 외부의 상기 데이터베이스와 데이터를 송수신하는 통신 모듈을 경유하여 상기 적어도 하나이상의 프로세서가 상기 제1 분석 결과를 상기 제1 의료 영상과 관련시켜 상기 데이터베이스에 저장하는 인공신경망 기반 의료 영상 판독 지원 방법."}
{"patent_id": "10-2019-0148489", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "컴퓨팅 시스템을 포함하는 의료용 인공 신경망에 기반하여 의료 영상 판독을 지원하는 장치가 개시된다. 본 발명 의 일 실시예에 따른 장치는 컴퓨팅 시스템을 포함하며 상기 컴퓨팅 시스템은 적어도 하나 이상의 프로세서를 포 함한다. 상기 적어도 하나 이상의 프로세서는 제1 의료 영상에 대한 제1 인공 신경망의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신하고, 상기 제1 분석 결과에 기반하여 상기 제1 의료 영상의 대표적인 시각화 형태인 제1 시각화 형태를 생성하고, 상기 제1 의료 영상 및 상기 제1 분석 결과를 상기 제1 시각화 형태에 기반 하여 시각화한다."}
{"patent_id": "10-2019-0148489", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 피검체의 의료 영상의 판독을 지원하는 장치 및 방법에 관한 것이다. 구체적으로는 본 발명은 의료용 인공 신경망의 분석 결과를 이용하여 의료 영상의 판독을 지원하는 컴퓨팅 시스템 및 그 컴퓨팅 시스템에서 실 행되는 소프트웨어에 관한 것이다. 본 발명은 과학기술정보통신부 및 정보통신기술진흥센터의 SW 컴퓨팅산업원천기술개발사업의 일환으로 수행한 연구로부터 도출된 것이다[과제관리번호: 2018-0-00861, 과제명: 의료데이터 분석 지능형 SW 기술개발]."}
{"patent_id": "10-2019-0148489", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재, 병변을 분석함으로써 진단에 이용하기 위하여 CT(computed tomography; 전산화 단층 촬영) 등의 의료 영 상이 널리 이용되고 있다. 예를 들어, 흉부 CT 영상은 신체의 내부, 예컨대, 폐, 기관지, 심장 등의 이상을 관찰할 수 있어 판독용으로 빈번히 이용된다. 흉부 CT 영상을 통하여 판독될 수 있는 몇몇 소견들은 영상의학과 의사도 다년 간의 수련을 통하여야만 그 특징 및 형태를 구분해낼 수 있을 정도로 그 판독이 용이하지 않아 인간인 의사가 쉽게 간과할 수 있다. 특히, 폐결 절(lung nodule)과 같이 그 판독의 난이도가 높으면 의사가 고도의 주의를 기울여도 미처 보지 못하고 넘어가는 경우가 발생할 수 있어 문제가 될 소지가 있다. 이 같이 인간이 쉽게 간과할 수 있는 영상의 판독을 보조하기 위하여, 컴퓨터 보조 진단(CAD; computer aided diagnosis)의 필요성이 대두되었는데, 종래의 CAD 기술은 매우 한정된 영역에서 의사의 판단을 보조함에 그친다. 예를 들어, 한국공개특허 KR 10-2014-0091176호 및 미국등록특허 US 9,773,305에는, 종래의 병변 진단 을 보조하기 위한 장치 및 방법이 개시되어 있다. 컴퓨터 보조 진단을 이용한 병변의 판독은 우선 병변으로 의심되는 부위를 특정하고, 그 부위에 대한 점수{예컨 대, 신뢰도(confidence), 악성도(malignity) 등}을 평가하는 프로세스로 이루어질 수 있다. 예를 들어, 폐부에 서 복수의 결절이 발견되는 경우, 그 중 악성도가 높을 것으로 예상되는 결절을 특정하여 추후의 치료 방안을 결정할 필요가 있을 것이다. 그런데, 복수의 결절이 있기 때문에 그 중 어떤 결절이 가장 악성도가 높은지는 판독 이전에 알 수가 없고 실제 악성도가 높지 않거나 악성이 아닐 것이라 예상되는 결절부터 진단이 수행되어 판독 효율이 떨어지게 되는 경우 가 산재한다. 또한 어떤 결절이 실제 결절인지 판독 이전에 알기 어렵고 신뢰도가 높지 않아 실제 결절이 아닐 것이라 예상되는 부분에서부터 진단이 수행되어도 판독 효율이 떨어진다. 선행 문헌인 한국등록특허 KR 10-1943011호 \"피검체의 의료 영상 판독을 지원하는 방법 및 이를 이용한 장치\"에 서는 종래의 병변 검출 시스템에 대하여 점수 평가 방식을 도입하고 검출된 병변들 중에서 점수(예컨대, 신뢰도, 악성도 등)가 가장 높은 병변들부터 판독할 수 있게 하여 판독 효율을 증진하는 방법 및 이를 이용한 장치를 제안하였다. KR 10-1943011에서는 단일 종류의 질환에 대해서 다수의 병변이 검출되었을 때 단일 디스플레이 설정 내에서 신 뢰도, 악성도 등의 점수가 가장 높은 병변들부터 배치되는 리스트를 디스플레이하고, 사용자가 리스트에서 해당 병변을 선택하면 병변과 관련된 영상을 디스플레이하는 구성을 개시한다. KR 10-1943011에서는 단일 종류의 질 환에 대해서 여러 종류의 병변이 검출되었을 때만을 가정하므로, 복수 개의 종류의 질환에 대한 병변들이 검출 되었을 때 대응하는 방법이 제시되지 않는다. 또한 한국등록특허 KR 10-1938992 \"진단 이유 설명이 생성되는 CAD 시스템 및 그 방법\" 에서는 병변 진단에 대 한 근거 정보를 도출하기 위하여 DNN 및 GAN 기반으로 추출된 특징 정보를 연쇄적으로 융합하여 특징 벡터를 생 성하는 기술이 소개되었다. 그러나 KR 10-1938992는 인공 신경망이 스스로 영상 내 검출된 특징과 진단 결과 간 의 유사도에 기반하여 설명 정보를 추출할 뿐이고, 추출된 설명 정보와 진단 결과 간의 관련성에 대해서도 인공 신경망 내에서만 연관성을 계산할 뿐이다. 따라서 KR 10-1938992에 의하여 추출된 설명 정보가 임상적으로 유용 한 정보인 지에 대한 검증이 전혀 이루어지지 않기 때문에, 인공 신경망의 진단 결과에 대한 설명으로 인간이 인식할 수 있으리라는 근거가 희박하다. CT(Computed Tomography) 또는 MRI(Magnetic Resonance Image)와 같은 최근의 의료 영상은 한 번의 획득 (Acquisition)을 통하여 의료 영상 시리즈(Series)를 획득하고, 의료 영상 시리즈는 한 종류의 병변 뿐에만 국 한되지 않고 여러 종류의 병변을 검출하는 데에 이용될 수 있다. 임상의(clinician) 또는 영상의(radiologist)가 하나의 의료 영상 시리즈 상에서 여러 종류의 병변을 확인하고 자 할 때에는 임상의 또는 영상의의 워크플로우(workflow) 및 행잉 프로토콜(Hanging Protocol)을 개선해야 한 다. 행잉 프로토콜은 의료 영상의 디스플레이 설정을 의미한다. 워크플로우 및 행잉 프로토콜을 개선하고자 하는 종래 기술은 다수 있어 왔다. 예를 들어, 미국등록특허 US 8,165,368호 \"Systems and Methods for Machine Learning Based Hanging Protocols\" 및 US 8,923,580호 \"Smart PACS Workflow Systems and Methods Driven by Explicit Learning from Users\" 에서는 사용자의 선호 도 또는 사용자의 과거의 디스플레이 조작 과정을 학습하여 사용자에 특화된 행잉 프로토콜을 제공하는 기술을 제안한다. 상기 선행 문헌들은 사용자의 선호도(user preference), 의료 영상이 얻어진 바디 파트(body part), 과거의 병 력에 기반하여 워크플로우 및 행잉 프로토콜을 최적화할 수 있지만 현재 제공된 의료 영상 내에 포함된 진단 정보 또는 병변 정보에 기반한 워크플로우 및 행잉 프로토콜을 제안하지 못한다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 KR 10-2014-0091176호 \"병변 진단 장치 및 방법\" (2014.07.21) (특허문헌 0002) 미국등록특허 US 9,773,305호 \"Lesion diagnosis apparatus and method\" (2017.09.26) (특허문헌 0003) 한국등록특허 KR 10-1943011호 \"피검체의 의료 영상 판독을 지원하는 방법 및 이를 이용한 장 치\" (2019.01.22) (특허문헌 0004) 한국등록특허 KR 10-1938992 \"진단 이유 설명이 생성되는 CAD 시스템 및 그 방법\" (2019년 1월 9일) (특허문헌 0005) US 8,165,368호 \"Systems and Methods for Machine Learning Based Hanging Protocols\" (2012.04.24) (특허문헌 0006) US 8,923,580호 \"Smart PACS Workflow Systems and Methods Driven by Explicit Learning from Users\" (2014.12.30)"}
{"patent_id": "10-2019-0148489", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "CT(Computed Tomography) 또는 MRI(Magnetic Resonance Image)와 같은 최근의 의료 영상은 한 번의 획득 (Acquisition)을 통하여 의료 영상 시리즈(Series)를 획득하고, 의료 영상 시리즈는 한 종류의 병변 뿐에만 국 한되지 않고 여러 종류의 병변을 검출하는 데에 이용될 수 있다. 예를 들어 폐(lung)에 대해서는 폐결절(lung nodule)이 진단될 수 있는 동시에 만성 폐쇄성 폐질환(COPD, Chronic Obstructive Pulmonary Disease), 또는 폐기종(emphysema)이 진단될 수 있고, 만성 기관지염 또는 기도(airway)와 관련된 질환도 진단될 수 있다. 임상의 또는 영상의에게 종래 기술에서처럼 병변의 진단 목록만이 제공되는 경우, 임상의 또는 영상의는 목록에 서 각 병변을 선택하여 그에 맞는 디스플레이 설정을 찾아 실행해야 하는데, 이 경우 판독과 직접 관련성이 떨 어지는 작업을 실행하거나 대기하는 데에 소요되는 시간이 증가하여 워크플로우의 효율이 저하되는 문제점이 있 다. 임상의 또는 영상의가 판독과 직접 관련성이 높은 작업에만 시간을 할애할 수 있으면 판독 시간을 단축하고 워 크플로우의 효율을 높일 수 있을 것이다. 본 발명의 목적은 의료 영상에 대한 다수의 기능의 분석을 수행할 수 있는 인공 지능을 보유한 환경에서, 의료 영상에 기반한 분석 결과에 기반하여 임상의 또는 영상의가 판독과 직접 관련성이 높은 작업에만 시간을 할애할 수 있도록 판독 시간을 단축하고 워크플로우의 효율을 높이는 것이다. 본 발명의 목적은 판독의 효율을 높이고 짧은 시간에 임상의 또는 영상의가 더 정확한 진단 결과를 도출할 수 있도록 보조하며 분석의 정확도를 높이는 사용자 인터페이스 및 디스플레이 환경을 제공하는 것이다. 한편 최근의 인공 지능 기술의 발전은 의료 영상 분야에서도 종래의 진단, 및 병변 검출 뿐만 아니라 특정 영역 에 대한 분석 및 정량화된 정보를 얻을 수 있는 다양한 수단으로 확장되고 있다. 이때 의료 영상의 분석 결과 및 정량화된 정보에 대한 대표적인 시각화 형태를 제공함으로써 의료 전문가가 인공 지능에 의한 의료 영상의 분석 결과 및 정량화된 정보에 대하여 임상적 판단 및 의사 결정을 할 수 있는 메뉴에 대한 수요가 존재한다. 본 발명은 이러한 수요에 응답하여, 인공 지능 기반의 의료 영상 분석 결과 및 정량화 결과에 대한 임상적 판단 및 의사 결정에 용이한 대표적인 시각화 형태를 제공하는 것을 목적으로 한다. 한편 인공 지능 기반의 의료 영상의 분석 결과 및 정량화 결과는 영상 분할(image segmentation)과 같은 전처리 과정을 거쳐 도출된다. 이때 워크플로우 상 전처리 과정에 오류가 있으면 이후의 분석 과정은 오류를 포함하게 된다. 따라서 영상에 대 한 분석 결과 및 워크플로우 상 분석 결과를 도출하기 위한 전처리 과정들의 결과를 함께 제시하여 의료 전문가 가 분석 결과에 대한 임상적 판단 및 의사 결정을 할 수 있는 메뉴에 대한 수요가 존재한다. 본 발명은 이러한 수요에 응답하기 위한 것으로서, 본 발명의 목적은 인공 지능 기반 의료 영상 분석 결과 및 정량화 결과를 시각 화하고, 또한 워크플로우 상 분석 결과 및 정량화 결과를 제공하기 위한 전처리 결과를 함께 시각화하여 의료 전문가의 임상적 판단 및 의사 결정을 지원하는 것이다. 본 발명의 목적은 의료 전문가가 인공 지능 기반 분석 결과 및 정량화 결과를 거부한 경우, 분석 결과 및 정량 화 결과가 도출되는 기반이 되는 전처리 결과에 대한 거부도 가능하고, 전처리 과정, 분석 과정, 및 정량화 과 정을 인공 지능과 독립적인 방법으로 다시 수행할 수 있는 사용자 메뉴를 제공하는 것이다."}
{"patent_id": "10-2019-0148489", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 상기의 목적을 달성하기 위하여 도출된 구성으로서, 본 발명의 일 실시예에 따른 의료용 인공 신경망 에 기반하여 대표적인 시각화 형태를 제공하는 의료 영상 판독 지원 장치는 컴퓨팅 시스템을 포함하며 상기 컴 퓨팅 시스템은 적어도 하나 이상의 프로세서를 포함한다. 상기 적어도 하나 이상의 프로세서는 제1 의료 영상에 대한 제1 인공 신경망의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신하고, 상기 제1 분석 결과에 기반하여 상기 제1 의료 영상의 대표적인 시각화 형태인 제1 시각화 형태를 생성하고, 상기 제1 의료 영상 및 상기 제1 분석 결과를 상기 제1 시각화 형태에 기반하여 시각화한다. 상기 적어도 하나 이상의 프로세서는 상기 제1 시각화 형태에 기반하여 시각화된 상기 제1 분석 결과에 대한 사 용자의 승인 여부를 수신할 수 있는 제1 사용자 메뉴를 제공할 수 있다. 제1 사용자 메뉴는 \"Confirm\" 또는 \"Reject\" 중 어느 한 쪽을 사용자가 선택할 수 있도록 하는 사용자 인터페이스로 제공될 수 있다. 상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과에 대하여 상기 사용자가 승인하지 않은 경우, 상기 제 1 의료 영상에 대하여 상기 제1 분석 결과와 대응하는 제2 분석 결과를 상기 제1 분석 결과와는 독립적으로 생 성할 수 있는 제2 사용자 메뉴를 제공할 수 있다. 상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과에 대하여 상기 사용자가 승인한 경우, 상기 제1 분석 결과를 상기 제1 의료 영상과 관련시켜 데이터베이스에 저장할 수 있다. 상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과를 상기 제1 의료 영상의 상기 제1 시각화 형태에 오버 레이하여 시각화할 수 있다. 상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과가 상기 제1 시각화 형태에 포함되도록 상기 제1 의료 영상 및 상기 제1 분석 결과에 기반한 상기 제1 시각화 형태를 생성할 수 있다. 상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과가 포함하는 상기 제1 의료 영상에 대한 영상 분할 (image segmentation), 임상적 진단, 및 상기 제1 의료 영상 내에서 분할된 객체에 대한 정량적 측정 결과 중 적어도 하나 이상에 기반하여 상기 제1 시각화 형태를 생성할 수 있다. 상기 제1 시각화 형태는 상기 제1 의료 영상의 적어도 하나 이상의 뷰, 상기 제1 의료 영상 중에서 상기 제1 분 석 결과와의 관련도에 기반하여 선택되는 상기 제1 의료 영상의 적어도 일부, 상기 제1 의료 영상의 재구성 중 적어도 하나 이상을 포함할 수 있고, 상기 제1 분석 결과는 상기 제1 분석 결과가 포함하는 정량화된 정보에 기 반하여 구분될 수 있도록 시각화될 수 있다. 상기 제1 인공 신경망은 상기 제1 의료 영상에 대한 영상 분할(image segmentation), 임상적 진단, 및 상기 제1 의료 영상 내에서 분할된 객체에 대한 정량적 측정 결과 중 적어도 하나 이상을 상기 제1 분석 결과로서 제공할 수 있다. 상기 컴퓨팅 시스템은 복수의 제2 의료 영상들 각각에 대하여 분석된 복수의 제3 분석 결과에 대하여 전문가가 선택한 복수의 제2 시각화 형태를 입력받고, 상기 복수의 제3 분석 결과와 상기 복수의 제2 시각화 형태 간의 관련성에 기반한 시각화 형태를 생성하는 기능을 학습한 인공 신경망인 제2 인공 신경망을 더 포함할 수 있다. 상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과를 상기 제2 인공 신경망에 입력하고, 상기 제2 인공 신경망의 추론에 의하여 상기 제1 시각화 형태를 획득하도록 상기 제2 인공 신경망을 제어할 수 있다. 상기 컴퓨팅 시스템은 외부의 상기 제1 인공 신경망과 데이터를 송수신하는 통신 모듈;을 더 포함할 수 있다. 상기 적어도 하나 이상의 프로세서는 상기 통신 모듈을 경유하여 상기 제1 의료 영상에 대한 상기 제1 인공 신 경망의 추론에 의하여 얻어지는 상기 제1 분석 결과를 획득하거나 수신할 수 있다. 상기 컴퓨팅 시스템은 외부의 상기 데이터베이스와 데이터를 송수신하는 통신 모듈;을 더 포함할 수 있다. 상기 적어도 하나 이상의 프로세서는 상기 통신 모듈을 경유하여 상기 제1 분석 결과를 상기 제1 의료 영상과 관련시 켜 상기 데이터베이스에 저장할 수 있다. 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 판독 지원 방법은 컴퓨팅 시스템에 의하여 실행되고, 상기 컴퓨팅 시스템은 적어도 하나 이상의 프로세서를 포함한다. 본 발명의 방법은 상기 적어도 하나 이상의 프 로세서가, 제1 의료 영상에 대한 제1 인공 신경망의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신 하는 단계; 상기 적어도 하나 이상의 프로세서가, 상기 제1 분석 결과에 기반하여 상기 제1 의료 영상의 대표적 인 시각화 형태인 제1 시각화 형태를 생성하는 단계; 및 상기 적어도 하나 이상의 프로세서가, 상기 제1 의료 영상 및 상기 제1 분석 결과를 상기 제1 시각화 형태에 기반하여 시각화하는 단계를 포함한다."}
{"patent_id": "10-2019-0148489", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 임상의(clinician) 또는 영상의(radiologist)를 위한 워크플로우(workflow) 내에서 임상의 또 는 영상의가 인공 지능 기반 영상 분석 결과를 판정하거나 분석 결과에 대한 의사 결정을 하기에 적절하게 설계 된 대표적인 시각화 형태를 제공할 수 있다. 본 발명에 따르면 의료 영상에 대한 다수의 기능의 분석을 수행할 수 있는 인공 지능을 보유한 환경에서, 의료 영상에 기반한 분석 결과에 기반하여 임상의 또는 영상의가 판독과 직접 관련성이 높은 작업에만 시간을 할애할 수 있도록 판독 시간을 단축하고 워크플로우의 효율을 높일 수 있다. 본 발명에 따르면 판독의 효율을 높이고 짧은 시간에 임상의 또는 영상의가 더 정확한 진단 결과를 도출할 수 있도록 보조하며 분석의 정확도를 높이는 사용자 인터페이스 및 디스플레이 환경을 제공할 수 있다. 본 발명에 따르면 인공 지능 기반의 의료 영상 분석 결과 및 정량화 결과에 대한 임상적 판단 및 의사 결정에 용이한 대표적인 시각화 형태를 제공할 수 있다. 본 발명에 따르면 인공 지능 기반 의료 영상 분석 결과 및 정량화 결과를 시각화할 수 있고, 또한 워크플로우 상 분석 결과 및 정량화 결과를 제공하기 위한 전처리 결과를 함께 시각화하여 의료 전문가의 임상적 판단 및 의사 결정을 지원할 수 있다. 본 발명에 따르면 의료 전문가가 인공 지능 기반 분석 결과 및 정량화 결과를 거부한 경우, 분석 결과 및 정량 화 결과가 도출되는 기반이 되는 전처리 결과에 대한 거부도 가능하고, 전처리 과정, 분석 과정, 및 정량화 과 정을 인공 지능과 독립적인 방법으로 다시 수행할 수 있는 사용자 메뉴를 제공할 수 있다."}
{"patent_id": "10-2019-0148489", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "상기 목적 외에 본 발명의 다른 목적 및 특징들은 첨부 도면을 참조한 실시예에 대한 설명을 통하여 명백히 드 러나게 될 것이다. 본 발명의 바람직한 실시예를 첨부된 도면들을 참조하여 상세히 설명한다. 본 발명을 설명함에 있어, 관련된 공 지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설 명은 생략한다. 최근 급속히 발전한 딥러닝/CNN 기반 인공 신경망 기술은 영상 분야에 적용할 경우, 인간의 육안으로 구분하기 어려운 시각적 요소를 구분하는 용도로 고려되고 있다. 이러한 기술의 적용 분야는 보안, 의료 영상, 비파괴 검 사 등 다양한 분야로 확대될 가능성이 기대되고 있다. 예를 들어 의료 영상 분야에서, 암 조직 중 생검(biopsy) 상태에서 즉시 암으로 판정되지 않고, 병리학적 (pathology) 관점에서 추적 모니터링된 이후에 비로소 암인지 여부가 판정되는 경우가 있다. 인간의 육안으로는 의료 영상에서 해당 세포가 암인지 여부를 확진하기 어려우나, 인공 신경망 기술을 적용할 경우 인간의 육안으 로 관찰하는 것보다 더 정확한 예측 결과를 얻을 수 있을 것이라는 기대가 있다. 이러한 인공 신경망 기술이 적용되어 의료 영상 내에서 인간의 육안으로 식별하기 어려운 질환이나 병변을 검출 하고, 특정 조직 등 관심 영역을 분할하며(segmentation), 분할된 영역에 대한 측정 등 분석 과정을 수행할 수 있을 것으로 기대된다. 본 발명은 이러한 인공 신경망 기술이 적용된 다양한 분석 기술을 인간 전문가가 판독할 수 있는 가장 적절한 형태로 시각화하는 구성을 제공하는 의료 영상 판독 지원 시스템에 관한 것이다. 도 1은 본 발명의 일 실시예에 따른 의료용 인공 신경망의 분석 결과에 기반하여 대표 영상을 제공하는 의료 영 상 판독 지원 장치를 도시하는 도면이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 의료 영상 판독 지원 장치는 컴퓨팅 시스템을 포함하며 상 기 컴퓨팅 시스템은 적어도 하나 이상의 프로세서를 포함한다. 컴퓨팅 시스템은 시각화 형태 정 보 데이터베이스를 더 포함할 수 있다. 적어도 하나 이상의 프로세서는 제1 의료 영상에 대한 제1 인공 신경망의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신하고, 시각화 형태 정보 데이터베이스와 협력하여 제1 분석 결과에 기반하여 제1 의료 영상의 대표적인 시각화 형태인 제1 시각화 형태를 생성하고, 제1 시각화 형태에 기반하여 제1 의료 영상 및 제1 분석 결과 가 화면에 디스플레이되는 시각화 정보를 생성한다. 제1 시각화 형태는 제1 의료 영상의 판독을 지원하기에 가장 적절한 형태로 생성될 수 있다. 제1 의 료 영상에 대한 제1 분석 결과에 따라서도 제1 시각화 형태는 달라질 수 있다. 제1 의료 영상 및 제1 분석 결과에 기반하여 제1 시각화 형태가 생성된다. 제1 시각화 형태는 사용자인 의료 전문가가 제1 분석 결과를 판정하거나, 제1 분석 결과에 대한 의사 결정을 수행하기에 적합한 형태로 도출될 수 있다. 제1 분석 결과의 종류, 제1 분석 결과가 포함하는 분석 내용, 및/또는 정량화 정보에 기반하여 적합 한 제1 시각화 형태의 종류가 미리 추출되어 시각화 형태 정보 데이터베이스에 저장될 수 있다. 이때 프로세서는 제1 분석 결과를 수신한 후, 제1 분석 결과가 포함하는 분석 내용, 및 제1 분석 결 과가 관련되는 제1 의료 영상의 콘텐츠에 기반하여 시각화 형태 정보 데이터베이스에 데이터를 요청할 수 있고, 시각화 형태 정보 데이터베이스는 프로세서의 요청에 응답하여 제1 분석 결과 및 제1 의료 영상에 대응하는 시각화 형태 정보를 프로세서로 전달할 수 있다. 프로세서는 시각 화 형태 정보 데이터베이스로부터 수신한 시각화 형태 정보에 기반하여 제1 분석 결과 및 제1 의료 영상에 적합한 시각화 형태를 생성하고, 시각화 형태를 제1 의료 영상에 적용하여 제1 시각화 형태 를 생성하여 통신 모듈로 전달할 수 있다. 시각화 형태 정보를 시각화 형태 정보 데이터베이스 로부터 수신하고 제1 시각화 형태를 생성하는 과정은 rule-based로 실행될 수 있다. 적어도 하나 이상의 프로세서는 제1 시각화 형태에 기반하여 상기 화면에 디스플레이된 제1 분석 결 과에 대한 사용자의 승인 여부를 수신할 수 있는 제1 사용자 메뉴를 제공할 수 있다. 제1 사용자 메뉴는 \"Confirm\" 또는 \"Reject\" 중 어느 한 쪽을 사용자가 선택할 수 있도록 하는 사용자 인터페이스로 제공될 수 있다. 적어도 하나 이상의 프로세서는 제1 분석 결과에 대하여 사용자가 승인하지 않은 경우, 제1 의료 영 상에 대하여 제1 분석 결과와 대응하는 제2 분석 결과를 제1 분석 결과와는 독립적으로 생성할 수 있는 제2 사용자 메뉴를 제공할 수 있다. 제2 사용자 메뉴는 제1 분석 결과를 대체하는 제2 분석 결과 를 생성할 수 있는 메뉴일 수 있다. 제2 사용자 메뉴는 제2 분석 결과를 수동 또는 반자동으로(semi- automatically) 생성할 수 있는 메뉴일 수 있으며, 부분적으로 자동 실행되고, 간헐적으로 인터랙티브하게 사용 자 입력을 받아 제2 분석 결과를 생성하여 제1 분석 결과를 대체할 수 있는 사용자 메뉴일 수 있다. 또한 제1 분석 결과를 사용자가 승인하지 않은 경우, 제1 분석 결과를 생성하는 기반이 된 전처리 결과에 대해서도 사용자가 독립적으로, 생성할 수 있는 사용자 메뉴를 제공할 수 있다. 전처리 결과 역시 수동 또는 반 자동으로 사용자 메뉴에 의하여 생성될 수 있다. 컴퓨팅 시스템은 외부의 제1 인공 신경망과 데이터를 송수신하는 통신 모듈을 더 포함할 수 있 다. 적어도 하나 이상의 프로세서는 통신 모듈을 경유하여 제1 의료 영상에 대한 제1 인공 신경 망의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신할 수 있다. 도 1에서는 제1 인공 신경망이 컴퓨팅 시스템의 외부에 위치하는 실시예가 도시된다. 컴퓨팅 시스템 의 외부와 연결되는 프로세스는 통신 모듈을 경유하여 수행된다. 따라서 프로세서는 제1 인공 신경망에 의하여 생성되는 제1 분석 결과를 통신 모듈을 경유하여 수신하고, 제1 의료 영상 을 통신 모듈을 경유하여 수신하거나, 획득하거나, 입력받을 수 있다. 프로세서가 생성한 제1 시각화 형태는 제1 의료 영상 및/또는 제1 분석 결과와 결합하여 시각화 정보로서 생성되 고 통신 모듈을 경유하여 컴퓨팅 시스템의 외부의 디스플레이(도시되지 않음)로 전달될 수 있다. 제1 시각화 형태에 기반하여 시각화 정보가 생성되는 과정은 프로세서에 의하여 실행될 수도 있고, 프로세서의 제어에 의하여 통신 모듈에 의하여 실행될 수도 있다. 본 발명의 일 실시예에 따르면 제1 시각화 형태는 제1 의료 영상의 재구성 또는 리포맷을 포함할 수 있다. 이때 제1 분석 결과의 종류에 따라서는 적어도 하나 이상의 프로세서는 제1 분석 결과를 제1 의료 영상의 제1 시각화 형태에 오버레이하여 시각화 정보를 생성하고, 시각화할 수 있다. 예를 들어 제1 분석 결과가 병변의 검출, 또는 병변의 진단에 관련된 분석인 경우 제1 분석 결과가 제1 의료 영상의 제1 시각화 형태에 오버레이될 수 있다. 본 발명의 다른 일 실시예에 따르면 제1 시각화 형태는 제1 의료 영상의 재구성 또는 리포맷을 포함 하며, 제1 분석 결과의 종류에 따라서는 제1 분석 결과가 제1 의료 영상과 함께 제1 시각화 형 태에 포함되도록 제1 시각화 형태가 생성될 수 있다. 이때 적어도 하나 이상의 프로세서는 제1 분석 결과가 제1 시각화 형태에 포함되도록 제1 의료 영상 및 제1 분석 결과에 기반한 제1 시각화 형태를 생성할 수 있다. 예를 들어 제1 분석 결과는 기도(airway)의 분할(segmentation) 및 정량화에 관련되는 분석이고, 전처리 과정으로서 기도의 분할이 필요하다. 이때 제1 분석 결과, 및 전처리 결과가 함께 제1 시각화 형태에 포함되도록 제1 시각화 형태가 생성될 수 있다. 전처리 결과인 제1 의료 영상의 기도의 분할 결과를 3차원 볼륨 렌더링 영상으로 표현하고, 3차원 볼륨 렌더링 영상에 색상, 명도, 채도, 패턴 등의 시각화 요소를 부가하여 제1 분석 결과인 정량화 결과를 제1 의료 영상의 3차 원 볼륨 렌더링 영상에 함께 시각화할 수 있다. 이때 제1 시각화 형태는 제1 의료 영상의 3차원 볼륨 렌더링 영상 및 그에 부가된 시각화 요소를 포함할 수 있으며, 이때 제1 시각화 형태는 제1 의료 영상 의 정보, 전처리 결과, 및 제1 분석 결과를 함께 시각화할 수 있는 대표적인 시각화 형태로서 도출될 수 있다. 적어도 하나 이상의 프로세서는 제1 분석 결과가 포함하는 제1 의료 영상에 대한 영상 분할 (image segmentation), 임상적 진단, 및 제1 의료 영상 내에서 분할된 객체에 대한 정량적 측정 결과 중 적어도 하나 이상에 기반하여 제1 시각화 형태를 생성할 수 있다. 제1 의료 영상 내에서 검출된 질환 의 종류, 병변의 종류, 및 병변에 대한 정량적 측정 결과 중 적어도 하나 이상이 문맥 정보(context information)로서 프로세서가 제1 시각화 형태를 생성하는 데에 영향을 줄 수 있다. 제1 시각화 형태는 제1 의료 영상의 적어도 하나 이상의 뷰, 제1 의료 영상 중에서 제1 분석 결 과와의 관련도에 기반하여 선택되는 제1 의료 영상의 적어도 일부, 제1 의료 영상의 재구성, 및 제1 의료 영상의 리포맷 중 적어도 하나 이상을 포함할 수 있고, 제1 분석 결과는 제1 분석 결과 가 포함하는 정량화된 정보에 기반하여 구분될 수 있도록 시각화될 수 있다. 제1 인공 신경망은 제1 의료 영상에 대한 영상 분할(image segmentation), 임상적 진단, 및 제1 의 료 영상 내에서 분할된 객체에 대한 정량적 측정 결과 중 적어도 하나 이상을 제1 분석 결과로서 제 공할 수 있다. 제1 시각화 형태는 제1 분석 결과와 관련된 제1 의료 영상의 적어도 하나 이상의 뷰, 제1 의료 영상 내에서 제1 분석 결과를 표시하는 메뉴, 제1 의료 영상의 적어도 하나 이상의 뷰의 레이아 웃, 및 제1 의료 영상 내에서 표시된 제1 분석 결과에 대하여 사용자가 응답할 수 있는 사용자 메뉴 에 대한 설정을 포함할 수 있다. 제1 시각화 형태와 유사한 디스플레이 설정으로서 의료 분야에 특화된 것 은 행잉 프로토콜(Hanging Protocol)이라 불리기도 한다. 제1 시각화 형태는 행잉 프로토콜과 동일한 것은 아니고, 다만 제1 시각화 형태는 행잉 프로토콜에 국한되는 것은 아니고, 제1 분석 결과를 적절하게 표시하기 위하여 제1 의료 영상의 영상 처리된 뷰, 볼륨 렌더링, 재구성 또는 리포맷되는 영상을 모두 포 함할 수 있다. 행잉 프로토콜은 좀 더 구체적으로는 제1 분석 결과와 관련된 제1 의료 영상의 복수의 뷰(view), 제1 의료 영상의 복수의 뷰 중 적어도 하나 이상의 뷰 내에서 제1 분석 결과를 표시하는 시각화된 메뉴, 제1 분석 결과와 임상적으로 연관성이 있는 제1 의료 영상 내의 관련 부위를 표시하는 시각화된 메뉴, 제1 의료 영상의 복수의 뷰의 레이아웃, 제1 의료 영상의 복수의 뷰 사이에서 제1 분석 결과 및 제1 분석 결과와 임상적으로 연관성이 있는 제1 의료 영상 내의 관련 부위와의 동기화된 시 각적/청각적 표현, 및 제1 의료 영상의 복수의 뷰 중 적어도 하나 이상의 뷰 내에서 표시된 제1 분석 결과 및/또는 제1 의료 영상 내에서 표시된 제1 분석 결과와 임상적으로 연관성이 있는 관련 부위에 대하여 사용자가 응답할 수 있는 사용자 메뉴에 대한 설정을 포함할 수 있다. 행잉 프로토콜에 관한 일반적인 사항은 앞서 언급한 미국등록특허 US 8,165,368호 \"Systems and Methods for Machine Learning Based Hanging Protocols\" 및 US 8,923,580호 \"Smart PACS Workflow Systems and Methods Driven by Explicit Learning from Users\" 등에서 참고할 수 있다. 이 같은 행잉 프로토콜의 적어도 일부는 제1 분석 결과에 대한 사용자의 판정 및 의사 결정을 지원할 수 있는 범위에서 제1 시각화 형태 내에 포함될 수 있다. 다만 제1 시각화 형태는 주어진 행잉 프로토콜 내에서 제1 분석 결과 또는 그 전처리 결과를 표시하는 데에 특화된 뷰, 재구성, 리포맷 영상일 수 있다. 이 경우에는 제1 시각화 형태는 행잉 프로토콜에서 정의되지 않는 구체화된 시각화 형태를 더욱 다양하게 포함할 수 있을 것이다. 프로세서는 시각화 형태 정보 데이터베이스에 저장된 시각화 형태를 생성하는 규칙(rule)에 기반하여 제1 시각화 형태를 생성할 수 있다. 즉, 제1 분석 결과 또는 제1 분석 결과의 주요 특징을 추출 하여 시각화 형태 정보 데이터베이스에 쿼리를 보낼 수 있다. 시각화 형태 정보 데이터베이스는 쿼리 에 응답하여, 시각화 형태 정보 데이터베이스에 저장된 규칙에 기반하여 쿼리에 관련된 행잉 프로토콜 응 답을 프로세서로 제공할 수 있다. 프로세서는 제1 분석 결과가 복수 개의 전처리 결과에 기반하 여 생성되는 것일 경우, 복수 개의 전처리 결과 각각에 대한 쿼리를 생성하여 시각화 형태 정보 데이터베이스 로 전송하고, 시각화 형태 정보 데이터베이스로부터 수신된 시각화 형태 정보 응답을 조합하거나 우 선 순위를 부가하여 제1 시각화 형태를 생성할 수 있다. 프로세서는 제1 시각화 형태를 통신 모 듈을 경유하여 외부의 디스플레이 장치로 전송하여 디스플레이 장치의 화면 상에서 제1 시각화 형태 가 시각화되도록 디스플레이 장치를 제어할 수 있다. 제1 인공 신경망은 복수의 훈련용 의료 영상들 각각에 포함되는 단일 바디 파트에 대한 복수 개의 종류의 질환을 전문가가 진단한 정보를 입력받아 상기 복수의 훈련용 의료 영상들 각각에 포함되는 복수 개의 종류의 질환을 진단하는 기능을 학습한 인공 신경망일 수 있다. 이때 제1 인공 신경망은 복수 개의 종류의 질환을 하나의 신경망 모델에서 진단할 수 있는 기능을 학습한 경우일 수 있다. 프로세서에 의하여 제공되는 제1 시각화 형태를 결정하는 요인은 제1 의료 영상에 포함되는 정 보로서, 제1 인공 신경망의 분석 및 추론에 의한 제1 분석 결과에 포함되는 정보이다. 또한 제1 분석 결과에 포함되는 임상적 특징(질환 코드) 또는 기능적 특징(분할(segmentation), 검출(detection), 식별 (identification), 진단(diagnosis), 또는 측정(measurement))과 시각화 형태 정보 데이터베이스에 저장 된 규칙이 호응하여 제1 분석 결과에 기반한 제1 시각화 형태가 도출될 수 있다. 제1 분석 결과에 따른 제1 시각화 형태의 예시는 도 7 내지 도 14와 관련하여 후술될 것이다. 도 2는 본 발명의 일 실시예에 따른 의료용 인공 신경망의 분석 결과에 기반하여 대표 영상을 제공하는 의료 영 상 판독 지원 장치를 도시하는 도면이다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 의료 영상 판독 지원 장치는 컴퓨팅 시스템을 포함하며 컴 퓨팅 시스템은 적어도 하나 이상의 프로세서를 포함한다. 컴퓨팅 시스템은 시각화 형태 정보 데 이터베이스를 더 포함할 수 있다. 적어도 하나 이상의 프로세서는 제1 의료 영상에 대한 제1 인 공 신경망의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신하고, 시각화 형태 정보 데이 터베이스와 협력하여 제1 분석 결과에 기반하여 제1 의료 영상의 대표적인 시각화 형태인 제1 시각화 형태를 생성하고, 제1 시각화 형태에 기반하여 제1 의료 영상 및 제1 분석 결과가 화면에 디스플레이되는 시각화 정보를 생성한다. 도 2에서는 제1 인공 신경망이 컴퓨팅 시스템 내에 포함되는 실시예가 도시된다. 통신 모듈은 외부로부터 제1 의료 영상을 획득하거나 수신할 수 있다. 통신 모듈은 제1 의료 영상을 프로세 서의 제어에 의하여 제1 인공 신경망으로 전달하고, 제1 의료 영상을 프로세서로 전달할 수 있다. 제1 인공 신경망은 프로세서의 제어에 의하여 제1 의료 영상에 대한 제1 분석 결과를 생성 하고 프로세서의 제어에 의하여 제1 분석 결과를 프로세서로 전달할 수 있다. 프로세서는 제1 분석 결과 및 제1 의료 영상에 기반하여 제1 시각화 형태를 생성하고, 제1 시각화 형태를 통신 모듈로 전달할 수 있다. 프로세서, 통신 모듈, 제1 인공 신경망, 시각화 형태 정보 데이터베이스의 나머지 동작은 도 1의 프로세서, 통신 모듈, 제1 인공 신경망, 및 시각화 형태 정보 데이터베이스와 동일 하므로 중복되는 설명은 생략한다. 도 3은 본 발명의 일 실시예에 따른 의료용 인공 신경망의 분석 결과에 기반하여 대표 영상을 제공하는 의료 영 상 판독 지원 장치를 도시하는 도면이다. 도 3을 참조하면, 본 발명의 일 실시예에 따른 의료 영상 판독 지원 장치는 컴퓨팅 시스템을 포함하며 컴 퓨팅 시스템은 적어도 하나 이상의 프로세서를 포함한다. 도 3에서는 제2 인공 신경망이 포함되는 실시예가 도시된다. 컴퓨팅 시스템은 제2 인공 신경망 을 더 포함할 수 있다. 적어도 하나 이상의 프로세서는 제1 의료 영상에 대한 제1 인공 신경망 의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신하고, 제1 분석 결과를 제2 인공 신경망 의 입력으로 제공하여 제2 인공 신경망의 추론에 의하여 제1 의료 영상의 대표적인 시각화 형태 인 제1 시각화 형태를 생성하고, 제1 시각화 형태에 기반하여 제1 의료 영상 및 제1 분석 결과 가 화면에 디스플레이되는 시각화 정보를 생성한다. 제2 인공 신경망은 또 다른 훈련용 영상들인 복수의 제2 의료 영상들 각각에 대하여 분석된 복수의 제3 분 석 결과에 대하여 전문가가 선택한 복수의 제2 시각화 형태를 입력받고, 복수의 제3 분석 결과와 복수의 제2 시 각화 형태 간의 관련성에 기반한 시각화 형태를 생성하는 기능을 학습한 인공 신경망일 수 있다. 적어도 하나 이상의 프로세서는 제1 분석 결과를 제2 인공 신경망에 입력하고, 제2 인공 신경망의 추론 에 의하여 제1 시각화 형태를 획득하도록 제2 인공 신경망을 제어할 수 있다. 본 발명의 변형된 실시 예에 따르면 프로세서는 제2 인공 신경망의 추론에 의한 출력 결과를 수신하고, 제2 인공 신경망 의 추론에 의한 출력 결과에 기반하여 제1 시각화 형태를 생성할 수 있다. 이때 프로세서는 제2 인공 신경망의 추론에 의한 출력 결과 및 제1 의료 영상에 대하여 도출되는 문맥 정보(context information)에 기반하여 제1 시각화 형태를 생성할 수 있다. 프로세서, 통신 모듈, 및 제1 인공 신경망의 나머지 동작은 도 1의 프로세서, 통신 모듈 , 및 제1 인공 신경망와 동일하므로 중복되는 설명은 생략한다. 도 4는 본 발명의 일 실시예에 따른 의료용 인공 신경망의 분석 결과에 기반하여 대표 영상을 제공하는 의료 영 상 판독 지원 장치를 도시하는 도면이다. 도 4를 참조하면, 본 발명의 일 실시예에 따른 의료 영상 판독 지원 장치는 컴퓨팅 시스템을 포함하며 컴 퓨팅 시스템은 적어도 하나 이상의 프로세서를 포함한다. 도 4에서는 제1 인공 신경망과 제2 인공 신경망이 컴퓨팅 시스템 내에 포함되는 실시예가 도시 된다. 적어도 하나 이상의 프로세서는 제1 의료 영상에 대한 제1 인공 신경망의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신하고, 제1 분석 결과를 제2 인공 신경망의 입력으로 제공하여 제2 인공 신경망의 추론에 의하여 제1 의료 영상의 대표적인 시각화 형태인 제1 시각화 형 태를 생성하고, 제1 시각화 형태에 기반하여 제1 의료 영상 및 제1 분석 결과가 화면에 디 스플레이되는 시각화 정보를 생성한다. 프로세서, 통신 모듈, 제1 인공 신경망, 및 제2 인공 신경망의 나머지 동작은 도 3의 프로 세서, 통신 모듈, 제1 인공 신경망, 및 제2 인공 신경망와 동일하므로 중복되는 설명은 생 략한다. 도 5는 본 발명의 일 실시예에 따른 의료용 인공 신경망의 분석 결과에 기반하여 대표 영상을 제공하는 의료 영 상 판독 지원 장치를 도시하는 도면이다. 도 5를 참조하면, 본 발명의 일 실시예에 따른 의료 영상 판독 지원 장치는 컴퓨팅 시스템을 포함하며 컴 퓨팅 시스템은 적어도 하나 이상의 프로세서를 포함한다. 컴퓨팅 시스템은 시각화 형태 정보 데 이터베이스를 더 포함할 수 있다. 적어도 하나 이상의 프로세서는 제1 의료 영상에 대한 제1 인 공 신경망의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신하고, 시각화 형태 정보 데이 터베이스와 협력하여 제1 분석 결과에 기반하여 제1 의료 영상의 대표적인 시각화 형태인 제1 시각화 형태를 생성하고, 제1 시각화 형태에 기반하여 제1 의료 영상 및 제1 분석 결과가 화면에 디스플레이되는 시각화 정보를 생성한다. 도 5에서는 컴퓨팅 시스템이 사용자 입력을 수신하는 사용자 인터페이스 모듈을 더 포함하는 실 시예가 도시된다. 적어도 하나 이상의 프로세서는 제1 시각화 형태에 기반하여 상기 화면에 디스플레이된 제1 분석 결 과에 대한 사용자의 승인 여부를 수신할 수 있는 제1 사용자 메뉴를 사용자 인터페이스 모듈을 경유 하여 디스플레이 화면 상에 시각화 정보와 함께 제공할 수 있다. 제1 사용자 메뉴는 \"Confirm\" 또는 \"Reject\" 중 어느 한 쪽을 사용자가 선택할 수 있도록 하는 사용자 메뉴일 수 있다. 본 발명의 다른 실시예에 따라서는 제1 사용자 메뉴는 시각적, 청각적, 촉각적 수단 또는 이들 중 둘 이상의 조합으로 제공될 수도 있다. 사용자 인터페이스 모듈은 사용자 입력을 수신하고 사용자 입력을 프로세서로 전달한다. 적어도 하나 이상의 프로세서는 사용자 입력을 해석하여 제1 분석 결과에 대하여 사용자가 승인 하지 않은 경우, 제1 의료 영상에 대하여 제1 분석 결과와 대응하는 제2 분석 결과를 제1 분석 결과 와는 독립적으로 생성할 수 있는 제2 사용자 메뉴를 사용자 인터페이스 모듈 및/또는 통신 모듈(54 0)을 경유하여 디스플레이 화면 또는 추가적인 사용자 인터페이스 메뉴를 이용하여 제공할 수 있다. 제2 사용자 메뉴는 제1 분석 결과를 대체하는 제2 분석 결과를 생성할 수 있는 인터페이스 메뉴일 수 있다. 제2 사용 자 메뉴는 제2 분석 결과를 수동 또는 반자동으로 생성할 수 있는 인터페이스 메뉴일 수 있다. 또한 제2 사용자 메뉴는 부분적으로 자동 실행되고, 간헐적으로 인터랙티브하게 사용자 입력을 받아 제2 분석 결과를 생성하여 제1 분석 결과를 대체할 수 있는 사용자 메뉴일 수 있다. 또한 제1 분석 결과를 사용자가 승인하지 않은 경우, 제1 분석 결과를 생성하는 기반이 된 전처리 결과에 대해서도 사용자가 독립적으로, 생성할 수 있는 사용자 메뉴를 제공할 수 있다. 전처리 결과 역시 수동 또는 반자동으로 사용자 메뉴에 의하여 생성될 수 있다. 프로세서, 통신 모듈, 제1 인공 신경망, 및 시각화 형태 정보 데이터베이스의 나머지 동작 은 도 1의 프로세서, 통신 모듈, 제1 인공 신경망, 및 시각화 형태 정보 데이터베이스와 동일하므로 중복되는 설명은 생략한다. 도 6은 본 발명의 일 실시예에 따른 의료용 인공 신경망의 분석 결과에 기반하여 대표 영상을 제공하는 의료 영 상 판독 지원 장치를 도시하는 도면이다. 도 6을 참조하면, 본 발명의 일 실시예에 따른 의료 영상 판독 지원 장치는 컴퓨팅 시스템을 포함하며 컴 퓨팅 시스템은 적어도 하나 이상의 프로세서를 포함한다. 적어도 하나 이상의 프로세서는 제1 의료 영상에 대한 제1 인공 신경망의 추론에 의하여 얻어지는 제1 분석 결과를 통신 모듈 을 경유하여 획득하거나 수신한다. 적어도 하나 이상의 프로세서는 제1 분석 결과에 기반하여 제1 의 료 영상의 대표적인 시각화 형태인 제1 시각화 형태를 생성하고, 제1 시각화 형태에 기반하여제1 의료 영상 및 제1 분석 결과가 화면에 디스플레이되는 시각화 정보를 생성할 수 있다. 이때 도 6에 도시되지는 않았지만 도 1, 도 2, 및 도 5의 실시예에서처럼 적어도 하나 이상의 프로세서는 시각 화 형태 정보 데이터베이스(도시되지 않음)와 협력하여 제1 분석 결과에 기반하여 제1 의료 영상의 대표적인 시각화 형태인 제1 시각화 형태를 생성하고, 제1 시각화 형태에 기반하여 제1 의료 영상 및 제1 분석 결과가 화면에 디스플레이되는 시각화 정보를 생성할 수 있다. 도 5의 실시예에와 마찬가지로, 도 6의 적어도 하나 이상의 프로세서는 제1 시각화 형태에 기반하여 상기 화면에 디스플레이된 제1 분석 결과에 대한 사용자의 승인 여부를 수신할 수 있는 제1 사용자 메뉴를 사용자 인터페이스 모듈을 경유하여 디스플레이 화면 상에 시각화 정보와 함께 제공할 수 있다. 제1 사용자 메뉴는 \"Confirm\" 또는 \"Reject\" 중 어느 한 쪽을 사용자가 선택할 수 있도록 하는 사용자 메뉴일 수 있 다. 사용자 인터페이스 모듈은 사용자 입력을 수신하고 사용자 입력을 프로세서로 전달한다. 적어도 하나 이상의 프로세서는 사용자 입력을 해석하여 제1 분석 결과에 대하여 사용자가 승인 한 경우, 제1 분석 결과를 제1 의료 영상과 관련시켜 데이터베이스에 저장할 수 있다. 도 6에서는 데이터베이스가 컴퓨팅 시스템의 외부에 위치하는 경우의 실시예를 도시한다. 데이터베이 스는 의료 영상 저장 전송 시스템(PACS) 데이터베이스일 수도 있고, 클라우드 기반 데이터베이스일 수도 있다. 도 6의 실시예에서는 컴퓨팅 시스템은 외부의 데이터베이스와 통신 모듈을 경유하여 데이터를 송수신할 수 있다. 적어도 하나 이상의 프로세서는 통신 모듈을 경유하여 제1 분석 결과를 제1 의료 영상과 관련시켜 데이터베이스에 저장할 수 있다. 프로세서, 통신 모듈, 제1 인공 신경망, 및 사용자 인터페이스 모듈의 나머지 동작은 도 5 의 프로세서, 통신 모듈, 제1 인공 신경망, 및 사용자 인터페이스 모듈와 동일하므로 중복 되는 설명은 생략한다. 도 6에서는 데이터베이스가 외부에 위치하는 실시예가 도시되었으나, 본 발명의 다른 실시예에 따르면 데 이터베이스(도시되지 않음)가 컴퓨팅 시스템의 내부에 위치하는 경우의 실시예도 구현할 수 있음은 당업자 에게 자명하게 이해될 것이다. 도 1 내지 도 6의 실시예에서 의료 기관에서 의료 영상에 기반한 진단 및 영상 분석 워크플로우를 개선하고 의 료 전문가의 영상 진단을 지원하는 의료 영상 판독 지원 장치가 개시된다. 의료 영상 분석 기술이 발전함에 따라, 인공 지능 또는 인공 신경망 기반의 영상 분석 알고리듬은 영상 내의 특 정 병변을 검출/진단할 뿐 아니라 분할된 영역에 대한 정량화된 정보를 얻을 수 있다. 이러한 정량화된 정보를 얻는 과정은 측정이라고 불리기도 한다. 측정 결과는 의료 전문가의 영상 판독을 지원하는 정보로서 작용할 수 있다. 영상 분석 및/또는 영상 분할이 아무리 정확하더라도 현재 기술 수준에서 100% 정확도를 달성할 수는 없 으며, 의료 영상 분석에서는 한 번의 실패라도 치명적인 결과를 초래할 수 있기 때문에 영상 분석의 실패에 대 한 대안을 마련하는 것은 매우 중요하다. 측정 결과가 부정확하거나 합리적인 수준을 벗어나는 경우에는 전처리 과정인 영상 분할(image segmentation)이 실패하거나 부정확한 경우일 수 있다. 예를 들어 폐 영상에서는 폐엽 분할(lung lobe segmentation), 기도 분할(airway segmentation)이 중요하다. 이들 분할 결과들에 기반하여 의료 영상 분석 알고리듬 또는 인공 신경망을 이용하여 폐기종(emphysema), 기도 벽 두께(airway wall thickness) 등과 관련된 정량화된 정보를 얻을 수 있다. 심장 영상에서는 동맥/정맥 등 혈관 분할(blood vessel segmentation)이 중요하다. 이들 분할 결과들에 기반하 여 의료 영상 분석 알고리듬 또는 인공 신경망을 이용하여 칼슘 스코어링 등에 관련된 정량화된 정보를 얻을 수 있다. 정랑화된 정보를 얻는 측정 과정의 결과들은 그 전처리 과정인 영상 분할 과정이 정확하지 않거나 영상 분할이 실패하는 경우, 정량화된 측정 결과가 너무 낮거나 너무 높은 등, 합리적인 범위를 넘어서는 경우가 있을 수 있 다. 정량화된 측정 결과가 합리적인 범위를 넘어서서 너무 높은 경우에는 의료 전문가가 의료 영상을 한번 더 확인 하여 잘못된 측정을 바로잡을 가능성이 높겠지만, 정량화된 측정 결과가 합리적인 범위를 넘어서서 너무 낮은 경우가 문제될 수 있다. 이때에는 의료 전문가가 의료 영상 분석 알고리듬 또는 인공 신경망의 분석 결과만을 참고한다면 실제 질환이 있는 데도 발견하지 못한 채로 지나치게 될 가능성이 있다. 그러나 위와 같은 이유로 정량화된 분석 결과를 제공하는 모든 경우에 의료 전문가가 의료 영상 원본을 다시 한 번씩 모두 살펴보는 것은 매우 부담스러운 일이 될 것이며, 자동으로 제공되는 정량화된 분석 결과를 이용하는 취지에 전혀 부합하지 않는다. 따라서 정량화된 분석 결과를 제공하되, 정량화된 분석 결과가 정확한지 또는 합 리적인 수준을 벗어난 오류가 있지는 않은 지에 대한 판단을 지원할 수 있도록 대표 영상을 정량화된 분석 결과 와 함께 시각화하고, 사용자인 의료 전문가가 대표 영상과 함께 시각화된 정량화된 분석 결과를 확인할 수 있도 록 하는 사용자 인터페이스를 제공하는 것은 워크플로우를 개선하고 오류를 방지할 수 있는 효과적인 수단일 것 이다. 이때 사용자는 의료 전문가인 임상의(clinician) 또는 영상의(radiologist)일 수도 있지만, 진단하고자 하는 대 상에 따라서는 영상 분할 등 기본적인 전처리 과정이 합리적인 범위 내에서 수행되었는 지를 확인하는 정도의 지식만 가지고 있는 지원 스태프일 수도 있다. 즉, 임상적인 지식을 가지고 있지 않더라도 영상 내 특정 영역의 분할이 정확히 수행되었는 지를 확인할 수 있는 정도의 대표성을 가지고 있다면 본 발명의 대표적인 시각화 형 태로 도출될 수 있다. 또한 도 1 내지 도 6의 실시예에 도시된 것처럼, 사용자가 거부한 분석 결과에 대해서는 수동 또는 반자동으로 다시 분석하여 올바른 분석 결과를 측정할 수 있도록 지원하는 사용자 메뉴를 제공하는 것도 워크플로우로서 중 요하다. 사용자가 승인한 분석 결과는 원래의 진단 목적으로 이용할 수 있도록(의료기관 내에서 진단 목적으로 이용할 수 있도록) PACS 데이터베이스 등에 저장하는 구성도 워크플로우로서 중요하다. 도 1 내지 도 6의 실시예들에 도시된 제1 인공 신경망(110, 210. 310, 410, 510, 610)은 복수의 질환들 또는 병변들에 관련된 영상 분석 기능을 가질 수 있다. 이때 제1 인공 신경망(110, 210. 310, 410, 510, 610)은 내부 에 복수 개의 영상 분석 모듈을 포함하고 있을 수도 있다. 본 발명의 시각화 형태 정보 데이터베이스(120, 220, 520) 또는 제2 인공 신경망(320, 420)은 복수의 영상 분석 모듈들, 복수의 질환들, 복수의 병변들, 또는 복수의 영상 분석 결과들에 대한 대표적인 시각화 형태의 정보를 보유하고 있을 수 있다. 이때 본 발명의 컴퓨팅 시스 템(100, 200, 300, 400, 500, 600)은 현재 입력된 분석 결과가 어떤 종류의 분석 결과이고, 어떤 병변 또는 질 환에 관련되어 생성된 분석 결과인 지를 문맥 정보(context information)로서 생성하고, 문맥 정보에 대응하여 최적화된 대표적인 시각화 형태를 도출할 수 있다. 대표적인 시각화 형태(160, 260, 360, 460, 560, 660)를 결정하는 요인은 제1 의료 영상(150, 250, 350, 450, 550, 650)에 포함되어 있는 정보로서, 제1 인공 신경망(110, 210. 310, 410, 510, 610)의 분석에 의하여 생성 되는 제1 분석 결과(112, 212, 312, 412, 512, 612)에 포함된 정보이다. 또한 제1 분석 결과(112, 212, 312, 412, 512, 612)에 대한 대표적인 시각화 형태(160, 260, 360, 460, 560, 660)가 의료 영상의 복수의 재구성 또는 리포맷 영상을 포함하는 경우, 이들을 시각화하기 위하여 복수의 재구 성 또는 리포맷 영상들이 디스플레이되는 화면 레이아웃 등이 시각화 정보(162, 262, 362, 462, 562, 662)에 포 함될 수 있다. 이때에는 시각화 정보(162, 262, 362, 462, 562, 662)가 행잉 프로토콜이 정의하는 정보 중 일부 를 포함할 수 있다. 한편 시각화 형태 정보는 행잉 프로토콜에서 정의되는 재구성 또는 리포맷의 종류 뿐만 아 니라, 의료 영상 및 분석 결과에 기반하여 도출되는 뷰의 방향 등의 정보를 추가적으로 포함하므로, 행잉 프토 토콜에서 정의되는 정보보다 구체화된 정보를 더 포함할 수 있다. 도 7은 본 발명의 일 실시예에 따른 제1 인공 신경망의 제1 분석 결과에 기반한 대표적인 시각화 형태가 도출된 일 예를 도시하는 도면이다. 도 7에 따르면 폐엽 분할 및 LAA(Low Attenuation Area) 분석 결과에 기반하여 대표적인 시각화 형태로서 도출 된 좌폐 중심부의 Sagittal 영상이 도시된다. 좌폐 중심부의 Sagittal 영상은 좌폐가 3개의 폐엽(710, 720, 730)으로 분할된 결과와 함께 도시된다. 이 경우 좌폐 중심부의 Sagittal 영상은 분석 결과에 따른 대표적인 시각화 형태 중 하나이고, 영상 분석 결과에 대응하 는 전처리 결과로서, 또는 영상 분석 결과에 포함되는 전처리 결과로서 좌폐의 3개의 폐엽(710, 720, 730) 분할 결과가 오버레이되어 시각화된다.LAA는 폐를 포함하는 CT 영상에 대하여 분석된 결과로서 CT 영상 내의 밝기값이 기준값보다 어두운 영역을 의미 할 수 있다. 정상적인 폐포는 호흡의 페이즈에 따라서 CT 영상 내에서 밝기값이 변할 수 있다. 그러나 폐의 CT 영상 내에서 특정한 기준값 미만의 밝기값으로 계속 유지되는 영역은 공기로 채워진 영상이고 폐포가 터졌거나 비활성화된 것으로 간주되므로 호흡에 도움이 되지 않는 영역으로 판단될 수 있다. LAA에 대한 정량 분석 결과는 특정한 영역(region) 내에서 밝기값이 기준값(예를 들어 -950 HU) 이하로 유지되 는 영역의 부피의 해당 영역의 부피에 대한 비율로 나타낼 수 있다. 또 다른 LAA에 대한 정량 분석 결과는 LAA 영역의 크기를 구분하여 크기 별로 LAA 영역의 개수를 카운트하여 표시하는 방법으로도 나타낼 수 있다. 이러한 정량화 결과는 환자의 호흡 레벨(호흡을 어느 정도까지 들이마셨는지)에 따라 달라지며, Log 연산을 이용하여 가공할 경우 호흡 레벨과 무관한 일정한 값을 도출하여 환자의 폐의 전체적인 능력에 대한 지표로서 제공될 수 있다. 이러한 LAA에 대한 정량적 측정 결과는 만성 폐쇄성 폐질환(COPD) 등의 진단을 위하여 사용자에게 제공되 며, 진단을 지원할 수 있다. 이러한 LAA 분석 결과는 복수의 단계의 영상 처리 과정을 거쳐서 얻어진다. 폐 CT 영상은 Whole Lung, Left Lung, Right Lung으로 분할될(segmented) 수 있다. Left Lung과 Right Lung 각 각의 폐엽이 분할될 수 있다. LAA 분석 결과 중 영역 별로 LAA 영역의 비율을 도출하기 위한 기준 영역은 이렇게 구분된 폐엽 또는 좌폐/우폐 일 수 있다. LAA 분석 결과를 도출하기 위해 필요한 복수의 전처리 과정들에 오류가 있으면 LAA 분석 결과에 대해서도 신뢰 성이 낮아질 수 있다. 따라서 분석 결과에 기반하여, 분석 결과에 도달하기 위한 복수의 전처리 과정들의 전처리 결과들이 대표적인 시각화 형태와 함께 시각화되어 분석 결과와 함께 제공될 수 있다. 이처럼 도 7은 LAA 분석 결과에 기반하여, LAA 분석 결과에 대한 대표적인 시각화 형태 중 하나로서 사용자에게 제공될 수 있는 실시예이다. 도 8은 본 발명의 일 실시예에 따른 제1 인공 신경망의 제1 분석 결과에 기반한 대표적인 시각화 형태가 도출된 일 예를 도시하는 도면이다. 도 8은 우폐 중심부의 Sagittal 영상으로서, 우폐에서 분할된 2개의 폐엽들(810, 820)이 도시된다. 도 8은 LAA 분석 결과에 도달하기 위한 전처리 과정의 결과로서, LAA 분석 결과에 기반하여 도출되는 대표적인 시각화 형태 중 하나로서 사용자에게 제공될 수 있다. 도 9는 본 발명의 일 실시예에 따른 제1 인공 신경망의 제1 분석 결과에 기반한 대표적인 시각화 형태가 도출된 일 예를 도시하는 도면이다. 도 9는 기관 분지부(tracheal branches)의 Coronal 영상으로서, 폐엽 분할의 결과를 사용자가 평가하기에 효과 적인 대표적인 시각화 형태의 하나로서 사용자에게 제공될 수 있다. 본 발명의 일 실시예에 따르면 도 7 및 도 8을 대체하여 도 9의 실시예가 LAA 분석 결과와 함께 사용자에게 제공될 수 있다. 또 다른 실시예에 따르면 도 7 내지 도 9가 모두 함께 사용자에게 제공될 수 있다. 도 9는 영상 분할 결과를 모두 나타내기보다는 영상 분할 이 실패할 가능성이 높은 영역을 대표적으로 시각화하여 사용자가 폐엽 분할의 결과를 효과적으로 평가할 수 있 도록 지원하는 시각화 형태일 수 있다. 도 10은 본 발명의 일 실시예에 따른 제1 인공 신경망의 제1 분석 결과에 기반한 대표적인 시각화 형태가 도출 된 일 예를 도시하는 도면이다. 도 10은 기관 분지부(tracheal branches)의 Coronal 영상에 검출된 LAA 영역을 표시하기 위한 대표적인 시각화 형태 중 하나이다. 도 11은 본 발명의 일 실시예에 따른 제1 인공 신경망의 제1 분석 결과에 기반한 대표적인 시각화 형태가 도출 된 일 예를 도시하는 도면이다. 도 11은 도 10의 대표적인 시각화 형태 영상에 분석 결과인 검출된 LAA 영역을 오버레이하여 시각화하는 일 예 를 도시한다. 특정 영역 내 LAA 영역의 비율을 산출하는 분석 결과와 함께 도 11의 영상이 표시되면, 본 발명의 의료 영상 판독 지원 장치는 도 11에서 좌폐/우폐, 및 그 좌폐/우폐 내에서 폐엽으로 분할되어야 할 부분과 LAA영역의 비율이 합리적으로 산출되었는지를 사용자가 판단할 수 있도록 지원할 수 있다. 도 11에 도시되지는 않았으나, 본 발명의 또 다른 일 실시예에 따르면 검출된 LAA 영역을 LAA 영역의 크기에 기 반하여 구분되는 시각화 요소(색상, 패턴, 명도)를 이용하여 시각화할 수도 있다. 도 12는 본 발명의 일 실시예에 따른 제1 인공 신경망의 제1 분석 결과에 기반한 대표적인 시각화 형태가 도출 된 일 예를 도시하는 도면이다. 분석 결과가 기도 분할(airway segmentation) 및 기도 분할에 기반한 정량화에 관련되는 분석인 경우, 기도 분 할은 분석 결과이면서 전처리 결과일 수 있다. 이때 분석 결과 및 전처리 결과가 함께 대표적인 시각화 형태에 포함되도록 대표적인 시각화 형태가 생성될 수 있다. 도 12에서는 전처리 결과인 제1 의료 영상(150, 250, 350, 450, 550, 650)의 기도 분할 결과를 3차원 볼륨 렌더링 영상으로 표현하고, 3차원 볼륨 렌더링 영상에 색상, 명 도, 채도, 패턴 등의 시각화 요소를 부가하여 제1 분석 결과(112, 212, 312, 412, 512, 612)인 정량화 결과를 제1 의료 영상(150, 250, 350, 450, 550, 650)의 3차원 볼륨 렌더링 영상에 함께 시각화할 수 있다. 이때 제1 시각화 형태(160, 260, 360, 460, 560, 660)는 제1 의료 영상(150, 250, 350, 450, 550, 650)의 3차원 볼륨 렌 더링 영상 및 그에 부가된 시각화 요소를 포함할 수 있으며, 이때 제1 시각화 형태(160, 260, 360, 460, 560, 660)는 제1 의료 영상(150, 250, 350, 450, 550, 650)의 정보, 전처리 결과, 및 제1 분석 결과(112, 212, 312, 412, 512, 612)를 함께 시각화할 수 있는 대표적인 시각화 형태로서 도출될 수 있다. 도 12에서는 기도 분할 결과와 함께 기도 벽 두께(Airway Wall Thickness) 측정 분석 값이 함께 시각화되어 표 시된다. 이때 정량화된 기도 벽 두께 정보는 색상과 함께 시각화되어 구분될 수 있다. 사용자는 기도 분할 결과를 정량화 분석 결과와 함께 볼 수 있으므로 기도 분할 결과가 정확한 지 여부에 대하 여 판단할 수 있고, 정량화 분석 결과를 그대로 수용할 수 있을 지에 대한 근거 정보를 제공받을 수 있다. 사용 자의 의료 영상 판독 과정은 대표적인 시각화 형태로서 제공되는 도 12의 영상에 기반하여 본 발명의 의료 영상 판독 지원 장치에 의하여 지원받을 수 있다. 기도 벽이 두꺼워지면 환자는 호흡을 내뱉기 어려워질 수 있다고 알려져 있다. 일반적으로 trachea 쪽은 기도 내강(airway lumen)과 기도 벽의 두께가 모두 크고, 미세 기관지 쪽으로 갈수록 lumen과 기도 벽의 두께가 작은 것으로 알려져 있다. 도 12에서 기도 벽의 두께가 기도 내의 상대적인 위치를 고려할 때 적절히 정량화되었는지 를 사용자가 판단할 수 있도록 정량화 결과 및 대표적인 시각화 형태가 도시된다. 도 13은 본 발명의 일 실시예에 따른 제1 인공 신경망의 제1 분석 결과에 기반한 대표적인 시각화 형태가 도출 된 일 예를 도시하는 도면이다. 도 13에서는 기도 분할 결과와 함께 기도 벽 면적%(Airway Wall Area %) 측정 분석 값이 함께 시각화되어 표시 된다. 이때 정량화된 기도 벽 면적% 정보는 색상과 함께 시각화되어 구분될 수 있다. 도 12에서와 마찬가지로 사용자는 기도 분할 결과를 정량화 분석 결과와 함께 볼 수 있으므로 기도 분할 결과가 정확한 지 여부에 대하여 판단할 수 있고, 정량화 분석 결과를 그대로 수용할 수 있을 지에 대한 근거 정보를 제공받을 수 있다. 사용자의 의료 영상 판독 과정은 대표적인 시각화 형태로서 제공되는 도 13의 영상에 기반하 여 본 발명의 의료 영상 판독 지원 장치에 의하여 지원받을 수 있다. 도 13에서 기도 벽 면적%가 기도 내의 상대적인 위치를 고려할 때 적절히 정량화되었는지를 사용자가 판단할 수 있도록 정량화 결과 및 대표적인 시각화 형태가 도시된다. 또한 기도 벽 면적% 정보가 100%이거나 100%에 가까 운 영역에 대해서는 사용자가 임상의(clinician) 또는 전문의(radiologist)인 경우 분석 결과 및 도 13에서 시 각화된 대표적인 시각화 형태를 고려하여 환자의 질환을 진단할 수 있다. 도 14는 본 발명의 일 실시예에 따른 제1 인공 신경망의 제1 분석 결과에 기반한 대표적인 시각화 형태가 도출 된 일 예를 도시하는 도면이다. 도 14는 관상 동맥의 석회화(CAC, Coronary Artery Calcification) 분석/측정 결과를 도시하는 대표적인 시각 화 형태의 일 예를 도시한다. 분석 결과가 CAC인 경우, 심혈관 분할 과정이 전처리 과정으로서 실행된다. 이때 심혈관 분할 과정에 오류가 있 어 갈비뼈 영역이 혈관 영역으로 편입되는 경우 CAC 측정값은 실제보다 매우 크게 측정되는 오류가 발생할 수 있다. 분석 결과가 CAC인 경우 대표적인 시각화 형태는 흉부 쪽의 뼈 영역이 혈관 분할 영역으로 편입되어 calcification으로 분류된 것을 확인할 수 있는 영상으로 제공될 수 있다. 예를 들어, CT 영상의 slice thickness가 50 mm로 설정된 Axial 영상 위에 검출된 calcification 영역을 모두 표시한 하나의 영상이 대표적 인 시각화 형태 및 분석 결과의 시각화 정보로 생성될 수 있다. 이 경우 CT 영상의 Axial 영상이 대표적인 시각 화 형태이고, 검출된 calcification 영역 전부가 대표적인 시각화 형태 위에 오버레이되어 시각화 정보로서 생 성된다. 도 15는 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 판독 지원 방법을 도시하는 동작 흐름도이다. 도 15와 도 1 내지 도 6을 함께 참고하면, 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 판독 지원 방법은 컴퓨팅 시스템(100, 200, 300, 400, 500, 600)에 의하여 실행되고, 상기 컴퓨팅 시스템(100, 200, 300, 400, 500, 600)은 적어도 하나 이상의 프로세서(130, 230, 330, 430, 530, 630)를 포함한다. 본 발명의 방법은 적어도 하나 이상의 프로세서(130, 230, 330, 430, 530, 630)가, 제1 의료 영상(150, 250, 350, 450, 550, 650)에 대한 제1 인공 신경망(110, 210, 310, 410, 510, 610)의 추론에 의하여 얻어지는 제1 분석 결과(112, 212, 312, 412, 512, 612)를 획득하거나 수신하는 단계(S1510); 적어도 하나 이상의 프로세서(130, 230, 330, 430, 530, 630)가, 제1 분석 결과(112, 212, 312, 412, 512, 612)에 기반하여 제1 의료 영상(150, 250, 350, 450, 550, 650)의 대표적인 시각화 형태인 제1 시각화 형태(160, 260, 360, 460, 560, 660)을 생성하는 단계 (S1520); 및 적어도 하나 이상의 프로세서(130, 230, 330, 430, 530, 630)가, 제1 시각화 형태(160, 260, 360, 460, 560, 660)에 기반하여 제1 의료 영상(150, 250, 350, 450, 550, 650) 및 제1 분석 결과(112, 212, 312, 412, 512, 612)가 화면에 디스플레이되도록 제1 의료 영상(150, 250, 350, 450, 550, 650) 및 제1 분석 결과 (112, 212, 312, 412, 512, 612)를 시각화하는 단계(S1530)를 포함한다. 제1 의료 영상(150, 250, 350, 450, 550, 650) 및 제1 분석 결과(112, 212, 312, 412, 512, 612)를 제1 시각화 형태(160, 260, 360, 460, 560, 660)에 기반하여 시각화하는 단계(S1530)에서, 적어도 하나 이상의 프로세서 (130, 230, 330, 430, 530, 630)가, 제1 시각화 형태(160, 260, 360, 460, 560, 660)에 기반하여 화면에 디스 플레이된 제1 분석 결과(112, 212, 312, 412, 512, 612)에 대한 사용자의 승인 여부를 수신할 수 있는 제1 사용 자 메뉴를 포함하도록 제1 의료 영상(150, 250, 350, 450, 550, 650) 및 제1 분석 결과(112, 212, 312, 412, 512, 612)를 제1 시각화 형태(160, 260, 360, 460, 560, 660)에 기반하여 시각화할 수 있다. 제1 분석 결과(112, 212, 312, 412, 512, 612)에 대하여 사용자가 승인하지 않은 경우, 적어도 하나 이상의 프 로세서(130, 230, 330, 430, 530, 630)가, 제1 의료 영상(150, 250, 350, 450, 550, 650)에 대하여 제1 분석 결과(112, 212, 312, 412, 512, 612)를 대체할 수 있는 제2 분석 결과를 제1 분석 결과(112, 212, 312, 412, 512, 612)와는 독립적으로 생성할 수 있는 제2 사용자 메뉴를 제공하는 단계가 더 포함될 수 있다. 제2 사용자 메뉴는 제2 분석 결과를 수동 또는 반자동으로 생성할 수 있는 사용자 메뉴일 수 있다. 제1 시각화 형태(160, 260, 360, 460, 560, 660)를 생성하는 단계(S1520)에서, 적어도 하나 이상의 프로세서 (130, 230, 330, 430, 530, 630)가, 제1 분석 결과(112, 212, 312, 412, 512, 612)가 포함하는 제1 의료 영상 (150, 250, 350, 450, 550, 650)에 대한 영상 분할, 임상적 진단, 및 제1 의료 영상(150, 250, 350, 450, 550, 650) 내에서 분할된 객체에 대한 정량적 측정 결과 중 적어도 하나 이상에 기반하여 제1 시각화 형태(160, 260, 360, 460, 560, 660)가 생성될 수 있다. 제1 시각화 형태(160, 260, 360, 460, 560, 660)는 제1 분석 결과(112, 212, 312, 412, 512, 612)와 관련된 제 1 의료 영상(150, 250, 350, 450, 550, 650)의 적어도 하나 이상의 뷰, 제1 의료 영상(150, 250, 350, 450, 550, 650) 중에서 제1 분석 결과(112, 212, 312, 412, 512, 612)와의 관련도에 기반하여 선택되는 제1 의료 영 상(150, 250, 350, 450, 550, 650)의 적어도 일부, 제1 의료 영상(150, 250, 350, 450, 550, 650)의 재구성 중 적어도 하나 이상을 포함할 수 있다. 제1 분석 결과(112, 212, 312, 412, 512, 612)는 제1 분석 결과(112, 212, 312, 412, 512, 612)가 포함하는 정량화된 정보에 기반하여 구분될 수 있도록 제1 시각화 형태(160, 260, 360, 460, 560, 660)와 함께 시각화될 수 있다. 도 15와 도 3 및 도 4를 함께 참고하면, 컴퓨팅 시스템(300, 400)은 복수의 제2 의료 영상들 각각에 대하여 분 석된 복수의 제3 분석 결과들에 대하여 전문가가 선택한 복수의 제2 시각화 형태를 입력받고, 복수의 제3 분석 결과들과 복수의 제2 시각화 형태들 간의 관련성에 기반한 시각화 형태를 생성하는 기능을 학습한 인공 신경망 인 제2 인공 신경망(320, 420)을 더 포함할 수 있다. 이때 제1 분석 결과(312, 412)에 기반한 제1 시각화 형태 (360, 460)을 생성하는 단계(S1520)에서, 적어도 하나 이상의 프로세서(330, 430)가, 제1 분석 결과(312, 41 2)를 제2 인공 신경망(320, 420)에 입력하고, 제2 인공 신경망(320, 420)의 추론에 의하여 제1 시각화 형태(360, 460)을 획득하도록 제2 인공 신경망(320, 420)을 제어할 수 있다. 도 15와 도 1, 도 3, 도 5, 및 도 6을 함께 참고하면, 적어도 하나 이상의 프로세서(130, 330, 530, 630)가, 제1 의료 영상(150, 350, 550, 650)에 대한 제1 인공 신경망(110, 310, 510, 610)의 추론에 의하여 얻어지는 제1 분석 결과(112, 312, 512, 612)를 획득하거나 수신하는 단계(S1510)에서는, 컴퓨팅 시스템(100, 300, 500, 600)의 외부의 제1 인공 신경망(110, 310, 510, 610)과 데이터를 송수신하는 통신 모듈(140, 340, 540, 640)을 경유하여, 적어도 하나 이상의 프로세서(130, 330, 530, 630)가 제1 분석 결과(112, 312, 512, 612)를 획득하 거나 수신할 수 있다. 도 15와 도 6을 함께 참고하면, 제1 분석 결과에 대하여 사용자가 승인한 경우, 적어도 하나 이상의 프로 세서가, 제1 분석 결과를 제1 의료 영상과 관련시켜 데이터베이스에 저장하는 단계가 더 포함될 수 있다. 이때 적어도 하나 이상의 프로세서가 컴퓨팅 시스템 외부의 데이터베이스와 데이터를 송수신하 는 통신 모듈을 경유하여 적어도 하나 이상의 프로세서가 제1 분석 결과를 제1 의료 영상 과 관련시켜 데이터베이스에 저장할 수 있다. 본 발명의 일 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되 어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이 터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하 여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행 하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같 은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함 한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 그러나, 본 발명이 실시예들에 의해 제한되거나 한정되는 것은 아니다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다. 본 발명의 실시예와 도면에 소개된 길이, 높이, 크기, 폭 등은 이해를 돕기 위해 과장 된 것일 수 있다. 이상과 같이 본 발명에서는 구체적인 구성 요소 등과 같은 특정 사항들과 한정된 실시예 및 도면에 의해 설명되 었으나 이는 본 발명의 보다 전반적인 이해를 돕기 위해서 제공된 것일 뿐, 본 발명은 상기의 실시예에 한정되 는 것은 아니며, 본 발명이 속하는 분야에서 통상적인 지식을 가진 자라면 이러한 기재로부터 다양한 수정 및 변형이 가능하다. 따라서, 본 발명의 사상은 설명된 실시예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐 아니라 이 특허청구범위와 균등하거나 등가적 변형이 있는 모든 것들은 본 발명 사상의 범주에 속한다고 할 것이다."}
{"patent_id": "10-2019-0148489", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 의료용 인공 신경망 기반 대표 영상을 제공하는 의료 영상 판독 지원 장치 를 도시하는 도면이다. 도 2는 본 발명의 일 실시예에 따른 의료용 인공 신경망 기반 대표 영상을 제공하는 의료 영상 판독 지원 장치 를 도시하는 도면이다. 도 3은 본 발명의 일 실시예에 따른 의료용 인공 신경망 기반 대표 영상을 제공하는 의료 영상 판독 지원 장치 를 도시하는 도면이다. 도 4는 본 발명의 일 실시예에 따른 의료용 인공 신경망 기반 대표 영상을 제공하는 의료 영상 판독 지원 장치 를 도시하는 도면이다. 도 5는 본 발명의 일 실시예에 따른 의료용 인공 신경망 기반 대표 영상을 제공하는 의료 영상 판독 지원 장치 를 도시하는 도면이다. 도 6은 본 발명의 일 실시예에 따른 의료용 인공 신경망 기반 대표 영상을 제공하는 의료 영상 판독 지원 장치 를 도시하는 도면이다. 도 7 내지 도 14는 본 발명의 일 실시예에 따른 제1 인공 신경망의 제1 분석 결과에 기반한 대표적인 시각화 형 태가 도출된 일 예를 도시하는 도면들이다. 도 15는 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 판독 지원 방법을 도시하는 동작 흐름도이다."}
