{"patent_id": "10-2020-0021746", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0106790", "출원번호": "10-2020-0021746", "발명의 명칭": "서버, 전자 장치 및 그들의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "권재현"}}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "서버에 있어서,페이크 영상을 식별하도록 학습된 인공지능 모델이 저장된 메모리; 및상기 메모리와 연결되어, 상기 서버를 제어하는 프로세서;를 포함하며,상기 프로세서는, 영상을 상기 인공지능 모델에 입력하여 상기 영상이 페이크 영상인지를 식별하며, 상기 인공지능 모델은,각각 얼굴 영역의 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들에 기초하여 학습된 모델인서버."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인공지능 모델은,상기 원본 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로조정된 상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로 조정된 상기 페이크 영상들에 기초하여 학습된 모델인 서버."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 인공지능 모델은,상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴 영역의 색상 값의 범위 및 상기 얼굴 영역에서 이마 영역과 볼 영역 간의 밝기 값의 차이 중 적어도 하나에 기초하여 학습된 모델인 서버."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 인공지능 모델은, 상기 메모리에 저장된 복수의 인공지능 모델 중 하나이고, 상기 복수의 인공지능 모델 각각은, 상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴의 포즈에 따라 상기 원본 영상들 및 상기 페이크영상들이 분류된 복수의 그룹 각각에 기초하여 학습된 모델이고,상기 프로세서는,상기 영상에 포함된 얼굴의 포즈를 판단하고, 상기 복수의 인공지능 모델 중 상기 판단된 포즈에 대응되는 인공지능 모델에 상기 영상을 입력하여 상기 영상이 페이크 영상인지를 식별하는 서버."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "전자 장치에 있어서,디스플레이;통신 인터페이스;공개특허 10-2021-0106790-3-페이크 영상을 식별하도록 학습된 인공지능 모델이 저장된 메모리; 및상기 디스플레이, 상기 통신 인터페이스 및 상기 메모리와 연결되어, 상기 전자 장치를 제어하는 프로세서;를포함하며,상기 인공지능 모델은, 각각 얼굴 영역의 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들에 기초하여 학습된 모델이고, 상기 프로세서는,상기 전자 장치 및 서버 중에서 영상이 페이크 영상인지를 식별할 기기를 판단하고, 상기 전자 장치가 상기 영상이 페이크 영상인지를 식별할 기기인 것으로 판단되면, 상기 영상을 상기 인공지능 모델에 입력하여 상기 영상이 페이크 영상인지를 식별하고, 상기 서버가 상기 영상이 페이크 영상인지를 식별할 기기인 것으로판단되면, 상기 영상을 상기 통신 인터페이스를 통해 상기 서버로 전송하고, 상기 영상이 페이크 영상인 경우,상기 영상이 페이크 영상인 것을 나타내는 UI 화면을 상기 디스플레이에 표시하는 전자 장치."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 인공지능 모델은,상기 원본 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로조정된 상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로 조정된 상기 페이크 영상들에 기초하여 학습된 모델인 전자 장치."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 프로세서는,상기 전자 장치 및 상기 서버 중에서 사용자 명령에 따라 설정된 기기, 상기 전자 장치의 네트워크 상태, 상기영상의 사이즈, 상기 영상의 타입, 상기 영상에 포함된 얼굴 영역의 사이즈 및 상기 얼굴 영역의 개수 중 적어도 하나에 기초하여, 상기 전자 장치 및 상기 서버 중에서 상기 영상이 페이크 영상인지를 식별할 기기를 판단하는 전자 장치."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 프로세서는,상기 사용자 명령에 따라 설정된 기기가 상기 전자 장치인 경우, 상기 전자 장치를 상기 영상이 페이크 영상인지를 식별할 기기인 것으로 판단하고, 상기 사용자 명령에 따라 설정된 기기가 상기 서버인 경우, 상기 서버를상기 영상이 페이크 영상인지를 식별할 기기인 것으로 판단하는 전자 장치."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 프로세서는,상기 메모리에 저장된 룩업 테이블을 이용하여, 상기 전자 장치의 네트워크 상태, 상기 영상의 사이즈, 상기 영상의 타입, 상기 영상에 포함된 얼굴 영역의 사이즈 및 상기 얼굴 영역의 개수 중 적어도 하나에 따라 상기 전자 장치 및 상기 서버 중에서 상기 영상이 페이크 영상인지를 식별할 기기를 판단하는 전자 장치."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제5항에 있어서,상기 메모리에 저장된 인공지능 모델은, 상기 서버에 저장된 인공지능 모델이 압축된 모델인 전자 장치.공개특허 10-2021-0106790-4-청구항 11 서버의 제어 방법에 있어서,페이크 영상을 식별하도록 학습된 인공지능 모델에 영상을 입력하는 단계; 및상기 인공지능 모델의 출력 값에 기초하여, 상기 입력된 영상이 페이크 영상인지를 식별하는 단계;를 포함하며, 상기 인공지능 모델은,각각 얼굴 영역의 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들에 기초하여 학습된 모델인제어 방법."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 인공지능 모델은,상기 원본 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로조정된 상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로 조정된 상기 페이크 영상들에 기초하여 학습된 모델인 제어 방법."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 인공지능 모델은,상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴 영역의 색상 값의 범위 및 상기 얼굴 영역에서 이마 영역과 볼 영역 간의 밝기 값의 차이 중 적어도 하나에 기초하여 학습된 모델인 제어 방법."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 인공지능 모델은, 상기 서버에 저장된 복수의 인공지능 모델 중 하나이고, 상기 복수의 인공지능 모델 각각은, 상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴의 포즈에 따라 상기 원본 영상들 및 상기 페이크영상들이 분류된 복수의 그룹 각각에 기초하여 학습된 모델이고,상기 입력하는 단계는,상기 영상에 포함된 얼굴의 포즈를 판단하고, 상기 복수의 인공지능 모델 중 상기 판단된 포즈에 대응되는 인공지능 모델에 상기 영상을 입력하는 제어 방법."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "페이크 영상을 식별하도록 학습된 인공지능 모델이 저장된 전자 장치의 제어 방법에 있어서,상기 전자 장치 및 서버 중에서 영상이 페이크 영상인지를 식별할 기기를 판단하는 단계;상기 전자 장치가 상기 영상이 페이크 영상인지를 식별할 기기인 것으로 판단되면, 상기 영상을 상기 인공지능모델에 입력하여 상기 영상이 페이크 영상인지를 식별하는 단계; 상기 서버가 상기 영상이 페이크 영상인지를 식별할 기기인 것으로 판단되면, 상기 영상을 상기 서버로 전송하는 단계; 및상기 영상이 페이크 영상인 경우, 상기 영상이 페이크 영상임을 나타내는 UI 화면을 표시하는 단계;를포함하며,상기 인공지능 모델은, 각각 얼굴 영역의 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들에 기초하여 학습된 모델인 제어 방법.공개특허 10-2021-0106790-5-청구항 16 제15항에 있어서,상기 인공지능 모델은,상기 원본 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로조정된 상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로 조정된 상기 페이크 영상들에 기초하여 학습된 모델인 제어 방법."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 판단하는 단계는,상기 전자 장치 및 상기 서버 중에서 사용자 명령에 따라 설정된 기기, 상기 전자 장치의 네트워크 상태, 상기영상의 사이즈, 상기 영상의 타입, 상기 영상에 포함된 얼굴 영역의 사이즈 및 상기 얼굴 영역의 개수 중 적어도 하나에 기초하여, 상기 전자 장치 및 상기 서버 중에서 상기 영상이 페이크 영상인지를 식별할 기기를 판단하는 제어 방법."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 판단하는 단계는,상기 사용자 명령에 따라 설정된 기기가 상기 전자 장치인 경우, 상기 전자 장치를 상기 영상이 페이크 영상인지를 식별할 기기인 것으로 판단하고, 상기 사용자 명령에 따라 설정된 기기가 상기 서버인 경우, 상기 서버를상기 영상이 페이크 영상인지를 식별할 기기인 것으로 판단하는 제어 방법."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서,상기 판단하는 단계는,상기 전자 장치에 저장된 룩업 테이블을 이용하여, 상기 전자 장치의 네트워크 상태, 상기 영상의 사이즈, 상기영상의 타입, 상기 영상에 포함된 얼굴 영역의 사이즈 및 상기 얼굴 영역의 개수 중 적어도 하나에 따라 상기전자 장치 및 상기 서버 중에서 상기 영상이 페이크 영상인지를 식별할 기기를 판단하는 제어 방법."}
{"patent_id": "10-2020-0021746", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항에 있어서,상기 전자 장치에 저장된 인공지능 모델은, 상기 서버에 저장된 인공지능 모델이 압축된 모델인 제어 방법."}
{"patent_id": "10-2020-0021746", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "서버가 개시된다. 본 서버는 페이크 영상을 식별하도록 학습된 인공지능 모델이 저장된 메모리 및 메모리와 연결 되어, 서버를 제어하는 프로세서를 포함하며, 프로세서는 영상을 인공지능 모델에 입력하여 영상이 페이크 영상 인지를 식별하며, 인공지능 모델은 각각 얼굴 영역의 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들에 기초하여 학습된 모델이다."}
{"patent_id": "10-2020-0021746", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 서버, 전자 장치 및 그들의 제어 방법에 관한 것으로, 보다 상세하게는 페이크 영상을 식별하기 위한 서버, 전자 장치 및 그들의 제어 방법에 관한 것이다."}
{"patent_id": "10-2020-0021746", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "페이크 영상은 원본 영상에 포함된 얼굴 또는 얼굴 부위가 다른 사람의 얼굴 또는 얼굴 부위로 합성된 영상을 의미할 수 있다. 최근 립러닝 기술의 발전으로, 일반인들도 정교한 페이크 영상을 생성이 가능하게 되었고, 이에 따라, 페이크 영상으로 생성된 가짜 뉴스, 음란물 등의 유통으로 인한 피해 사례 역시 증가하게 되었다. 이에 따라, 페이크 영상을 식별하기 위한 방안이 모색이 요청된다."}
{"patent_id": "10-2020-0021746", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 필요성에 따라 안출된 것으로, 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상 들에 의해 학습된 인공지능 모델을 이용하여 영상이 페이크 영상인지를 식별할 수 있는 서버, 전자 장치 및 그 들의 제어 방법을 제공함에 있다."}
{"patent_id": "10-2020-0021746", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 서버는 페이크 영상을 식별하도록 학습된 인공지능 모델이 저장된 메모리 및 상기 메모리와 연결되어, 상기 서버를 제어하는 프로세서를 포함하며, 상기 프로세서는 영상을 상기 인공지능 모델에 입력하여 상기 영상이 페이크 영상인지를 식별하며, 상기 인공지능 모델은 각각 얼굴 영역의 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들에 기초하여 학습된 모델이다. 여기에서, 상기 인공지능 모델은 상기 원본 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로 조정된 상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로 조정된 상기 페이크 영상들에 기초하여 학습된 모 델일 수 있다. 또한, 상기 인공지능 모델은 상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴 영역의 색상 값의 범 위 및 상기 얼굴 영역에서 이마 영역과 볼 영역 간의 밝기 값의 차이 중 적어도 하나에 기초하여 학습된 모델일 수 있다. 또한, 상기 인공지능 모델은 상기 메모리에 저장된 복수의 인공지능 모델 중 하나이고, 상기 복수의 인공지능 모델 각각은 상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴의 포즈에 따라 상기 원본 영상들 및 상기 페이크 영상들이 분류된 복수의 그룹 각각에 기초하여 학습된 모델이고, 상기 프로세서는 상기 영상에 포 함된 얼굴의 포즈를 판단하고, 상기 복수의 인공지능 모델 중 상기 판단된 포즈에 대응되는 인공지능 모델에 영 상을 입력하여 상기 영상이 페이크 영상인지를 식별할 수 있다. 한편, 본 개시의 일 실시 예에 따른 전자 장치는 디스플레이, 통신 인터페이스, 페이크 영상을 식별하도록 학습 된 인공지능 모델이 저장된 메모리 및 상기 디스플레이, 상기 통신 인터페이스 및 상기 메모리와 연결되어, 상 기 전자 장치를 제어하는 프로세서를 포함하며, 상기 인공지능 모델은 각각 얼굴 영역의 랜드마크에 대한 정보 를 포함하는 원본 영상들 및 페이크 영상들에 기초하여 학습된 모델이고, 상기 프로세서는 상기 전자 장치 및 서버 중에서 영상이 페이크 영상인지를 식별할 기기를 판단하고, 상기 전자 장치가 상기 영상이 페이크 영상인 지를 식별할 기기인 것으로 판단되면, 상기 영상을 상기 인공지능 모델에 입력하여 상기 영상이 페이크 영상인 지를 식별하고, 상기 서버가 상기 영상이 페이크 영상인지를 식별할 기기인 것으로 판단되면, 상기 영상을 상기 통신 인터페이스를 통해 상기 서버로 전송하고, 상기 영상이 페이크 영상인 경우, 상기 영상이 페이크 영상인 것을 나타내는 UI 화면을 상기 디스플레이에 표시한다. 여기에서, 상기 인공지능 모델은 상기 원본 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로 조정된 상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로 조정된 상기 페이크 영상들에 기초하여 학습된 모 델일 수 있다. 또한, 상기 프로세서는 상기 전자 장치 및 상기 서버 중에서 사용자 명령에 따라 설정된 기기, 상기 전자 장치 의 네트워크 상태, 상기 영상의 사이즈, 상기 영상의 타입, 상기 영상에 포함된 얼굴 영역의 사이즈 및 상기 얼 굴 영역의 개수 중 적어도 하나에 기초하여, 상기 전자 장치 및 상기 서버 중에서 상기 영상이 페이크 영상인지 를 식별할 기기를 판단할 수 있다. 여기에서, 상기 프로세서는 상기 사용자 명령에 따라 설정된 기기가 상기 전자 장치인 경우, 상기 전자 장치를 상기 영상이 페이크 영상인지를 식별할 기기인 것으로 판단하고, 상기 사용자 명령에 따라 설정된 기기가 상기 서버인 경우, 상기 서버를 상기 영상이 페이크 영상인지를 식별할 기기인 것으로 판단할 수 있다.또한, 상기 프로세서는 상기 메모리에 저장된 룩업 테이블을 이용하여, 상기 전자 장치의 네트워크 상태, 상기 영상의 사이즈, 상기 영상의 타입, 상기 영상에 포함된 얼굴 영역의 사이즈 및 상기 얼굴 영역의 개수 중 적어 도 하나에 따라 상기 전자 장치 및 상기 서버 중에서 상기 영상이 페이크 영상인지를 식별할 기기를 판단할 수 있다. 또한, 상기 메모리에 저장된 인공지능 모델은, 상기 서버에 저장된 인공지능 모델이 압축된 모델일 수 있다. 한편, 본 개시의 일 실시 예에 따른 서버의 제어 방법은 페이크 영상을 식별하도록 학습된 인공지능 모델에 영 상을 입력하는 단계 및 상기 인공지능 모델의 출력 값에 기초하여, 상기 입력된 영상이 페이크 영상인지를 식별 하는 단계를 포함하며, 상기 인공지능 모델은 각각 얼굴 영역의 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들에 기초하여 학습된 모델일 수 있다. 여기에서, 상기 인공지능 모델은 상기 원본 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로 조정된 상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로 조정된 상기 페이크 영상들에 기초하여 학습된 모 델일 수 있다. 또한, 상기 인공지능 모델은 상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴 영역의 색상 값의 범 위 및 상기 얼굴 영역에서 이마 영역과 볼 영역 간의 밝기 값의 차이 중 적어도 하나에 기초하여 학습된 모델일 수 있다. 또한, 상기 인공지능 모델은 상기 서버에 저장된 복수의 인공지능 모델 중 하나이고, 상기 복수의 인공지능 모 델 각각은 상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴의 포즈에 따라 상기 원본 영상들 및 상 기 페이크 영상들이 분류된 복수의 그룹 각각에 기초하여 학습된 모델이고, 상기 입력하는 단계는 상기 영상에 포함된 얼굴의 포즈를 판단하고, 상기 복수의 인공지능 모델 중 상기 판단된 포즈에 대응되는 인공지능 모델에 영상을 입력할 수 있다. 한편, 본 개시의 일 실시 예에 따른 페이크 영상을 식별하도록 학습된 인공지능 모델이 저장된 전자 장치의 제 어 방법은 상기 전자 장치 및 서버 중에서 영상이 페이크 영상인지를 식별할 기기를 판단하는 단계, 상기 전자 장치가 상기 영상이 페이크 영상인지를 식별할 기기인 것으로 판단되면, 상기 영상을 상기 인공지능 모델에 입 력하여 상기 영상이 페이크 영상인지를 식별하는 단계, 상기 서버가 상기 영상이 페이크 영상인지를 식별할 기 기인 것으로 판단되면, 상기 영상을 상기 서버로 전송하는 단계 및 상기 영상이 페이크 영상인 경우, 상기 영상 이 페이크 영상임을 나타내는 UI 화면을 표시하는 단계를 포함하며, 상기 인공지능 모델은 각각 얼굴 영역의 랜 드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들에 기초하여 학습된 모델이다. 여기에서, 상기 인공지능 모델은 상기 원본 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로 조정된 상기 원본 영상들 및 상기 페이크 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로 조정된 상기 페이크 영상들에 기초하여 학습된 모 델일 수 있다. 또한, 상기 판단하는 단계는 상기 전자 장치 및 상기 서버 중에서 사용자 명령에 따라 설정된 기기, 상기 전자 장치의 네트워크 상태, 상기 영상의 사이즈, 상기 영상의 타입, 상기 영상에 포함된 얼굴 영역의 사이즈 및 상 기 얼굴 영역의 개수 중 적어도 하나에 기초하여, 상기 전자 장치 및 상기 서버 중에서 상기 영상이 페이크 영 상인지를 식별할 기기를 판단할 수 있다. 여기에서, 상기 판단하는 단계는 상기 사용자 명령에 따라 설정된 기기가 상기 전자 장치인 경우, 상기 전자 장 치를 상기 영상이 페이크 영상인지를 식별할 기기인 것으로 판단하고, 상기 사용자 명령에 따라 설정된 기기가 상기 서버인 경우, 상기 서버를 상기 영상이 페이크 영상인지를 식별할 기기인 것으로 판단할 수 있다. 또한, 상기 판단하는 단계는 상기 전자 장치에 저장된 룩업 테이블을 이용하여, 상기 전자 장치의 네트워크 상 태, 상기 영상의 사이즈, 상기 영상의 타입, 상기 영상에 포함된 얼굴 영역의 사이즈 및 상기 얼굴 영역의 개수 중 적어도 하나에 따라 상기 전자 장치 및 상기 서버 중에서 상기 영상이 페이크 영상인지를 식별할 기기를 판 단할 수 있다. 또한, 상기 전자 장치에 저장된 인공지능 모델은 상기 서버에 저장된 인공지능 모델이 압축된 모델일 수 있다."}
{"patent_id": "10-2020-0021746", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상과 같은 본 개시의 다양한 실시 예에 따르면, 페이크 영상을 보다 정확하게 식별할 수 있다."}
{"patent_id": "10-2020-0021746", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 다양한 실시 예가 첨부된 도면을 참조하여 기재된다. 그러나, 이는 본 문서에 기재된 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 문서의 실시 예의 다양한 변경(modifications), 균등물 (equivalents), 및/또는 대체물(alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 본 개시에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제 3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메 모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 도 1은 본 개시의 일 실시 예에 따른 서버의 구성을 설명하기 위한 블록도이다. 도 1을 참조하면, 서버는 메모리 및 프로세서를 포함할 수 있다. 메모리는 서버의 동작과 관련된 다양한 명령어, 프로그램 또는 데이터를 저장할 수 있다. 이를 위해, 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(flash-memory), 하드디스크 드라이브 (HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 여기에서, 메모리는 프로세서에 의해 액세스되며, 프로세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 한편, 본 개시에서 메모리라는 용어는 메모리, 프로세서 내 롬(미도시), 램(미도시) 또는, 서버(10 0)에 장착되는 메모리 카드(미도시) 등을 포함할 수 있다. 특히, 메모리는 페이크 영상을 식별하도록 학습된 인공지능 모델을 저장할 수 있다. 여기에서, 페이크 영상은 원본 영상에서 얼굴이나 눈, 코, 입 등과 같은 얼굴 부위가 다른 사람의 얼굴이나 얼 굴 부위로 합성된 사진이나 동영상을 의미할 수 있다. 이러한 페이크 영상은 Deepfake, FaceSwap, Face2Face 등 과 같은 다양한 딥러닝 영상 합성 기술에 의해 생성될 수 있다. 프로세서는 메모리와 연결되어, 서버를 제어할 수 있다. 즉, 프로세서는 메모리와 전 기적으로 연결되어, 서버의 전반적인 동작 및 기능을 제어할 수 있다. 여기에서, 프로세서는 중앙처리장치(central processing unit, CPU) 또는 어플리케이션 프로세서 (application processor, AP)를 포함할 수 있으며, 메모리에 저장된 하나 이상의 인스트럭션에 따라 메모 리에 저장된 하나 이상의 소프트웨어 프로그램을 실행할 수 있다. 특히, 프로세서는 영상을 인공지능 모델에 입력하여, 영상이 페이크 영상인지를 식별할 수 있다. 여기에서, 인공지능 모델은 원본 영상들 및 페이크 영상들에 기초하여 학습된 모델일 수 있다. 구체적으로, 인공지능 모델은 원본 영상을 입력하였을 때, 인공지능 모델에서 출력되는 확률 값 즉, 입력된 영상이 원본 영상임을 나타내는 확률 값이 기설정된 임계 값 이상이 되도록 학습될 수 있다. 또한, 인공 지능 모델은 페이크 영상을 입력하였을 때, 인공지능 모델에서 출력되는 확률 값 즉, 입력된 영상이 페이크 영상임을 나타내는 확률 값이 기설정된 임계 값 이상이 되도록 학습될 수 있다. 이때, 원본 영상들 및 페이크 영상들은 각각 랜드마크에 대한 정보를 포함하는 영상일 수 있다. 즉, 인공지능 모델은 각각 얼굴 영역의 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들에 기초하여 학습된 모델일 수 있다. 여기에서, 랜드마크는 얼굴의 특징 포인트로, 눈, 코, 입, 턱선, 눈썹 등을 포함할 수 있다. 또한, 랜드마크에 대한 정보를 포함한다는 것은 얼굴 영역에서 랜드마크에 해당하는 픽셀의 픽셀 값이 기설정된 픽셀 값을 갖도록 랜드마크에 해당하는 픽셀의 픽셀 값이 조정(또는, 설정)된 것을 의미할 수 있다. 여기에서, 기설정된 픽셀 값은 R,G,B 픽셀 값이 각각 0,0,0이거나, 또는 255,255,255일 수 있다. 다만, 이는 일 예일 뿐이고, 기설정된 픽셀 값은 R,G,B 픽셀 별로 다양한 픽셀 값을 가질 수 있다. 즉, 인공지능 모델은 원본 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기 설정된 픽셀 값으로 조정된 원본 영상들 및 페이크 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설정된 픽셀 값으로 조정된 페이크 영상에 기초하여 학습된 모델일 수 있다. 예를 들어, 도 2a와 같이, 원본 영상들에서 얼굴 영역들이 검출되고, 얼굴 영역들 각각에서 랜드마 크를 포함하는 픽셀의 픽셀 값이 기설정된 픽셀 값으로 조정될 수 있다. 이 경우, 인공지능 모델은 픽셀 값이 조정된 원본 영상들에 의해 학습될 수 있다. 또한, 도 2b과 같이, 페이크 영상들에서 얼굴 영역들이 검출되고, 얼굴 영역들 각각에서 랜드마크 를 포함하는 픽셀의 픽셀 값이 기설정된 픽셀 값으로 조정될 수 있다. 이 경우, 인공지능 모델은 픽셀 값 이 조정된 페이크 영상들에 의해 학습될 수 있다. 즉, 본 개시의 일 실시 예에 따르면, 얼굴 영역에서 랜드마크로 검출된 위치는 페이크 영상에서 합성된 영역의 경계 부분을 포함할 수 있다는 점에서, 랜드마크 지점의 픽셀들의 픽셀 값이 조정된 영상들을 이용하여 인공지 능 모델을 학습시키는 경우, 인공지능 모델은 더 적은 양의 학습 데이터로도 페이크 영상을 보다 정확하게 식별 할 수 있게 된다. 한편, 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들을 생성하는 방법은 다음과 같다. 예를 들어, 얼굴 검출 알고리즘을 통해 원본 영상들 및 페이크 영상들 각각에서 얼굴 영역이 검출되고, face landmark estimation 등과 같은 알고리즘을 통해 얼굴 영역에서 랜드마크에 해당하는 특정한 포인트들(가령, 눈 바깥의 가장자리, 눈썹 안쪽의 가장자리, 콧등, 코 끝 가장자리, 턱선 등)이 검출될 수 있다. 그리고, 원본 영 상들 및 페이크 영상들 각각에서 검출된 포인트들을 포함하는 픽셀들의 픽셀 값을 기설정된 값으로 조정하여, 랜드마크에 대한 정보를 포함하는 영상이 생성될 수 있다. 한편, 본 개시의 일 실시 예에 따르면, 인공지능 모델은 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들뿐만 아니라, 이들 영상으로부터 획득되는 데이터에 기초하여 학습될 수도 있다. 구체적으로, 인공지능 모델은 원본 영상들 및 페이크 영상들 각각에 포함된 얼굴 영역의 색상 값의 범위 및 얼굴 영역에 포함된 이마 영역과 볼 영역 간의 밝기 값의 차이 중 적어도 하나에 기초하여 학습될 수 있다. 먼저, 인공지능 모델은 원본 영상들, 페이크 영상들 및 이들 영상 각각에 포함된 얼굴 영역의 색상 값의 범위에 대한 데이터에 기초하여 학습된 모델일 수 있다. 여기에서, 색상 값은 HSV 색공간에서 정의되는 색상 값(hue)일 수 있고, 색상 값의 범위는 얼굴 영역에 포함된 픽셀들의 색상 값들 중 최소 값 및 최대 값을 포함할 수 있다. 이에 따라, 도 3a와 같이, 인공지능 모델은 랜드마크에 대한 정보를 포함하는 원본 영상(23-1) 및 원본 영 상(23-1)의 얼굴 영역으로부터 획득된 최소 색상 값 및 최대 색상 값에 대한 데이터(즉, x1, y1)에 의해 학습되 고, 랜드마크에 대한 정보를 포함하는 원본 영상(23-2) 및 원본 영상(23-2)의 얼굴 영역으로부터 획득된 최소 색상 값 및 최대 색상 값에 대한 데이터(즉, x2, y2)에 의해 학습되고,..., 랜드마크에 대한 정보를 포함하는 원 본 영상(23-n) 및 원본 영상(23-n)의 얼굴 영역으로부터 획득된 최소 색상 값 및 최대 색상 값에 대한 데이터 (즉, xn, yn)에 의해 학습될 수 있다. 또한, 도 3b와 같이, 인공지능 모델은 랜드마크에 대한 정보를 포함하는 페이크 영상(26-1) 및 페이크 영 상(26-1)의 얼굴 영역으로부터 획득된 최소 색상 값 및 최대 색상 값에 대한 데이터(즉, x'1, y'1)에 의해 학습 되고, 랜드마크에 대한 정보를 포함하는 페이크 영상(26-2) 및 페이크 영상(26-2)의 얼굴 영역으로부터 획득된 최소 색상 값 및 최대 색상 값에 대한 데이터(즉, x'2, y'2)에 의해 학습되고,..., 랜드마크에 대한 정보를 포함 하는 페이크 영상(26-m) 및 페이크 영상(23-m)의 얼굴 영역으로부터 획득된 최소 색상 값 및 최대 색상 값에 대 한 데이터(즉, x'm, y'm)에 의해 학습될 수 있다(여기에서, n과 m은 같거나 다를 수 있다). 즉, 본 개시의 일 실시 예에 따르면, 페이크 영상은 일반적으로 원본 영상에서 눈썹 이하의 얼굴 부위가 합성되 어 생성될 수 있고, 또한, 페이크 영상에서 합성된 부분은 원본 영상과 피부색 차이가 있을 수 있다는 점에서, 원본 영상들과 페이크 영상들 각각의 얼굴 피부색의 범위에 대한 데이터를 이용하여 인공지능 모델을 학습시키 는 경우, 인공지능 모델은 페이크 영상을 보다 정확하게 식별할 수 있게 된다. 한편, 얼굴 영역의 색상 값 및 색상 값의 범위를 판단하는 방법은 다음과 같다. 예를 들어, 얼굴 검출 알고리즘을 통해 원본 영상들 및 페이크 영상들 각각에서 얼굴 영역이 검출되고, 검출된 얼굴 영역에 포함된 픽셀들의 R,G,B 픽셀 값에 따라 얼굴 영역에 포함된 각 픽셀의 HSV 색 공간에서의 색상 값 을 결정될 수 있다. 그리고, 얼굴 영역에 포함된 픽셀들의 색상 값들 중 최소 값 및 최대 값이 색상 값의 범위 로서 결정될 수 있다. 한편, 인공지능 모델은 원본 영상들, 페이크 영상들 및 이들 영상 각각에 포함된 얼굴 영역에서 검출된 이 마 영역과 볼 영역 간의 밝기의 차이에 대한 데이터에 기초하여 학습된 모델일 수 있다. 여기에서, 이마 영역은 얼굴에서 눈썹 위에 위치하는 영역이고, 볼 영역은 얼굴에서 코 양 옆에 위치하는 영역 일 수 있다. 그리고, 밝기 값 간의 차이는 이마 영역의 밝기 값과 2 개의 볼 영역 중 어느 하나의 영역의 밝기 값 간의 차이일 수 있다. 예를 들어, 도 4a와 같이, 인공지능 모델은 랜드마크에 대한 정보를 포함하는 원본 영상(23-1) 및 원본 영 상(23-1)의 얼굴 영역으로부터 획득된 밝기 값의 차이에 대한 데이터(즉, z1)에 의해 학습되고, 랜드마크에 대 한 정보를 포함하는 원본 영상(23-2) 및 원본 영상(23-2)의 얼굴 영역으로부터 획득된 밝기 값의 차이에 대한 데이터(즉, z2)에 의해 학습되고,..., 랜드마크에 대한 정보를 포함하는 원본 영상(23-n) 및 원본 영상(23-n)의 얼굴 영역으로부터 획득된 밝기 값의 차이에 대한 데이터(즉, zn)에 의해 학습될 수 있다. 또한, 도 4b와 같이, 인공지능 모델은 랜드마크에 대한 정보를 포함하는 페이크 영상(26-1) 및 페이크 영 상(26-1)의 얼굴 영역으로부터 획득된 밝기 값의 차이에 대한 데이터(즉, z'1)에 의해 학습되고, 랜드마크에 대 한 정보를 포함하는 페이크 영상(26-2) 및 페이크 영상(26-2)의 얼굴 영역으로부터 획득된 밝기 값의 차이에 대 한 데이터(즉, z'2)에 의해 학습되고,..., 랜드마크에 대한 정보를 포함하는 원본 영상(26-m) 및 원본 영상(26- m)의 얼굴 영역으로부터 획득된 밝기 값의 차이에 대한 데이터(즉, z'm)에 의해 학습될 수 있다. 즉, 본 개시의 일 실시 예에 따르면, 페이크 영상은 일반적으로 원본 영상에서 눈썹 이하의 얼굴 부위를 합성하 여 생성될 수 있고, 페이크 영상에서 합성된 부분은 원본 영상과 밝기 차이가 있을 수 있다는 점에서, 원본 영 상들과 페이크 영상들 각각의 얼굴 영역의 밝기 값의 차이에 대한 데이터를 이용하여 인공지능 모델을 학습시키 는 경우, 인공지능 모델은 페이크 영상을 보다 정확하게 식별할 수 있게 된다. 한편, 얼굴 영역에서 이마 영역 및 볼 영역 간의 밝기 차이를 판단하는 방법은 다음과 같다. 예를 들어, 얼굴 검출 알고리즘을 통해 원본 영상들 및 페이크 영상들 각각의 얼굴 영역에서 이마 영역 및 볼 영역이 검출될 수 있다. 이때, 이마 영역의 밝기 값은 이마 영역에 포함된 픽셀들의 R,G,B 픽셀 값들의 평균으 로 산출되고, 볼 영역의 밝기 값은 볼 영역에 포함된 픽셀들의 R,G,B 픽셀 값들의 평균으로 산출될 수 있다. 이 에 따라, 산출된 밝기 값 간의 차이를 산출하여 이마 영역과 볼 영역 간의 밝기 값의 차이가 산출될 수 있다. 한편, 도 3 및 도 4에서는, 얼굴 영역의 색상 값의 범위에 대한 데이터와 이마 영역과 볼 영역 간의 밝기 값의 차이에 대한 데이터를 개별적으로 이용하여 인공지능 모델이 학습되는 것으로 설명하였으나, 이는 일 예에 불과하다. 즉, 인공지능 모델은 원본 영상들, 페이크 영상들 및 이들 영상 각각에 포함된 얼굴 영역의 색상 값의 범 위에 대한 데이터 및 이들 영상 각각에 포함된 얼굴 영역에서 검출된 이마 영역과 볼 영역 간의 밝기 값의 차이 에 대한 데이터에 기초하여 학습된 모델일 수 있다. 또한, 인공지능 모델은 얼굴 영역의 색상 값의 범위에 대한 데이터 및 이마 영역과 볼 영역 간의 밝기 값 의 차이에 대한 데이터뿐만 아니라, 원본 영상들 및 페이크 영상들 각각의 아티펙트(Artifact) 데이터에 기초하 여 학습될 수도 있다. 한편, 본 개시의 일 실시 예에 따르면, 메모리는 복수의 인공지능 모델을 저장할 수 있다. 예를 들어, 도 5와 같이, 제1 내지 제5 인공지능 모델(111-1 내지 111-5)이 메모리에 저장되어 있을 수 있 다. 여기에서, 제1 내지 제5 인공지능 모델(111-1 내지 111-5) 각각은 영상에 포함된 얼굴의 포즈(pose)에 따라 원 본 영상들 및 페이크 영상들이 분류된 복수의 그룹 각각에 포함된 영상들에 의해 학습된 모델일 수 있다. 예를 들어, 원본 영상들 및 페이크 영상들 각각에 포함된 얼굴이 바라보는 방향에 따라, 원본 영상들 및 페이크 영상들은 5 개의 그룹으로 구분될 수 있다. 구체적으로, 원본 영상들 및 페이크 영상들은 얼굴이 정면 방향을 바라보는 영상들을 포함하는 제1 그룹, 얼굴 이 우측 방향을 바라보는 영상들을 포함하는 제2 그룹, 얼굴이 좌측 방향을 바라보는 영상들을 포함하는 제3 그 룹, 얼굴이 상측 방향을 바라보는 영상들을 포함하는 제4 그룹 및 얼굴이 하측 방향을 바라보는 영상들을 포함 하는 제5 그룹으로 구분될 수 있다. 여기에서, 얼굴이 바라보는 방향에 따라 영상들을 분류하는 방법은 다음과 같다. 예를 들어, 원본 영상들 및 페이크 영상들 각각에 대해, 각 영상에 포함된 얼굴의 롤각(roll angle)(φ), 피치 각(pitch angle)(θ) 및 요각(yaw angle)(ψ)이 검출되고, 검출된 롤각, 피치각 및 요각에 기초하여 각 영상에 서 얼굴이 바라보는 방향이 결정될 수 있다. 예를 들어, 도 6을 참조하면, 영상에서 검출된 얼굴의 피치각이 θ1 범위 내에 있고, 요각이 ψ1 범위 내에 있는 경우, 해당 영상은 얼굴이 정면 방향을 바라보는 영상으로 분류될 수 있다. 또한, 영상에서 검출된 얼굴의 피치각이 θ1 범위 내에 있고, 요각이 ψ2 범위 내에 있는 경우, 해당 영상은 얼 굴이 우측 방향을 바라보는 영상으로 분류될 수 있다. 그리고, 영상에 검출된 얼굴의 피치각이 θ1 범위 내에 있 고, 요각이 ψ3 범위 내에 있는 경우, 해당 영상은 얼굴이 좌측 방향을 바라보는 영상으로 분류될 수 있다. 또한, 영상에 검출된 얼굴의 피치각이 θ2 범위 내에 있는 경우, 해당 영상은 얼굴이 상측 방향을 바라보는 영상 으로 분류될 수 있다. 그리고, 영상에 검출된 얼굴의 피치각이 θ3 범위 내에 있는 경우, 해당 영상은 얼굴이 하 측 방향을 바라보는 영상으로 분류될 수 있다. 결국, 이러한 방식에 따라, 얼굴의 포즈에 따라 원본 영상들 및 페이크 영상들은 5 개의 그룹으로 구분될 수 있 다. 여기에서, 제1 내지 제5 인공지능 모델(111-1 내지 111-5) 각각은 각 그룹에 포함된 영상들에 의해 학습된 모델 일 수 있다. 예를 들어, 도 7a와 같이, 제1 인공지능 모델(111-1)은 얼굴이 정면 방향을 바라보는 원본 영상들 및 페이크 영 상들에 의해 학습된 모델일 수 있다. 또한, 도 7b와 같이, 제2 인공지능 모델(111-2)은 얼굴이 우측 방향을 바라보는 원본 영상들 및 페이크 영상들 에 의해 학습된 모델일 수 있다. 또한, 도 7c와 같이, 제3 인공지능 모델(111-3)은 얼굴이 좌측 방향을 바라보는 원본 영상들 및 페이크 영상들 에 의해 학습된 모델일 수 있다. 또한, 도 7d와 같이, 제4 인공지능 모델(111-4)은 얼굴이 상측 방향을 바라보는 원본 영상들 및 페이크 영상들 에 의해 학습된 모델일 수 있다. 또한, 도 7e와 같이, 제5 인공지능 모델(111-5)은 얼굴이 하측 방향을 바라보는 원본 영상들 및 페이크 영상들 에 의해 학습된 모델일 수 있다. 이때, 각 그룹에 포함된 영상들은 랜드마크에 대한 정보를 포함하는 영상들일 수 있다. 또한, 제1 내지 제5 인공지능 모델(111-1 내지 111-5) 각각은 각 그룹에 포함된 영상들로부터 획득된 얼굴 영역 의 색상 값의 범위에 대한 데이터 및 이마 영역과 볼 영역 간의 밝기 차이에 대한 데이터 중 적어도 하나와, 각 그룹에 포함된 영상들에 의해 학습된 모델일 수 있다. 또한, 제1 내지 제5 인공지능 모델(111-1 내지 111-5) 각각은 각 그룹에 포함된 영상들로부터 획득된 아티펙트 데이터에 기초하여 학습될 수도 있다.이와 같이, 본 개시의 일 실시 예에 따르면, 복수의 인공지능 모델은 얼굴의 포즈에 따라 구분된 영상들에 의해 학습된 모델들일 수 있다. 이에 따라, 영상에 포함된 얼굴의 포즈에 따라 이러한 모델들을 선택적으로 이용하여 페이크 영상인지를 식별하는 경우, 식별의 정확도가 향상될 수 있다. 한편, 프로세서는 영상을 인공지능 모델에 입력하여, 영상이 페이크 영상인지를 식별할 수 있다. 여기에서, 영상은 전자 장치로부터 수신된 영상일 수 있다. 또는, 프로세서는 전자 장치로부터 수신된 URL(uniform resource locator)을 이용하여 웹 페이지에 접속하고, 웹 페이지를 제공하는 서버(미도시) 로부터 영상을 수신받을 수 있다. 즉, 프로세서는 영상을 인공지능 모델에 입력하고, 인공지능 모델에서 출력되는 확률 값에 기초 하여 입력된 영상이 원본 영상 또는 페이크 영상인지를 식별할 수 있다. 구체적으로, 프로세서는 인공지능 모델에서 출력되는, 영상이 원본 영상임을 나타내는 확률 값이 기 설정된 임계 값 이상인 경우, 입력된 영상이 원본 영상인 것으로 판단할 수 있다. 또한, 프로세서는 인공 지능 모델에서 출력되는, 영상이 페이크 영상임을 나타내는 확률 값이 기설정된 임계 값 이상인 경우, 입 력된 영상이 페이크 영상인 것으로 판단할 수 있다. 이 경우, 프로세서는 인공지능 모델에 따라 영상 이외에 영상으로부터 획득된 다양한 데이터를 인공 지능 모델에 입력할 수 있다. 예를 들어, 인공지능 모델이 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들에 기초하여 학습된 모델인 경우, 프로세서는 영상을 인공지능 모델에 입력할 수 있다. 다른 예로, 인공지능 모델이 랜드마크에 대한 정보를 포함하는 원본 영상들, 페이크 영상들 및 이들 영상 각각에 포함된 얼굴 영역의 색상 값의 범위에 대한 데이터에 기초하여 학습된 모델인 경우, 프로세서는 영 상 및 영상으로부터 획득한 얼굴 영역의 색상 값의 범위에 대한 데이터를 인공지능 모델에 입력할 수 있다. 이를 위해, 프로세서는 얼굴 검출 알고리즘 등을 이용하여 영상에서 얼굴 영역을 검출하고, 검출된 얼굴 영역에 포함된 픽셀들의 R,G,B 픽셀 값을 이용하여 얼굴 영역에 포함된 각 픽셀의 HSV 색 공간에서의 색상 값을 판단할 수 있다. 그리고, 프로세서는 얼굴 영역에 포함된 픽셀들의 색상 값들 중 최소 값 및 최대 값을 판 단하여, 영상에 포함된 얼굴 영역의 색상 값의 범위를 판단할 수 있다. 다른 예로, 인공지능 모델이 랜드마크에 대한 정보를 포함하는 원본 영상들, 페이크 영상들 및 이들 영상 각각에 포함된 이마 영역과 볼 영역 간의 밝기 값의 차이에 대한 데이터에 기초하여 학습된 모델인 경우, 프로 세서는 영상 및 영상으로부터 획득한 이마 영역과 볼 영역 간의 밝기 값의 차이에 대한 데이터를 인공지능 모델에 입력할 수 있다. 이를 위해, 프로세서는 얼굴 검출 알고리즘을 이용하여 영상에서 얼굴 영역을 검출하고, 얼굴 영역에서 이 마 영역과 볼 영역을 판단할 수 있다. 예를 들어, 프로세서는 얼굴에서 눈썹 위에 위치한 영역을 이마 영 역으로 판단하고, 얼굴에서 코 양 옆에 위치한 영역을 볼 영역으로 판단할 수 있다. 그리고, 프로세서는 이미 영역에 포함된 픽셀들의 R,G,B 픽셀 값의 평균을 산출하여 이마 영역의 밝기 값 을 판단하고, 볼 영역에 포함된 픽셀들의 R,G,B 픽셀 값의 평균을 산출하여 볼 영역의 밝기 값을 판단하고, 이 들 밝기 값 간의 차이를 산출하여, 이마 영역과 볼 영역 간의 밝기 값의 차이를 판단할 수 있다. 이 경우, 프로 세서는 이마 영역의 밝기 값과 2 개의 볼 영역 중 어느 하나의 영역의 밝기 값 간의 차이를 산출할 수 있 다. 다른 예로, 인공지능 모델이 랜드마크에 대한 정보를 포함하는 원본 영상들, 페이크 영상들, 이들 영상 각 각에 포함된 얼굴 영역의 색상 값의 범위에 대한 데이터 및 이들 영상 각각에 포함된 이마 영역과 볼 영역 간의 밝기 값의 차이에 대한 데이터에 기초하여 학습된 모델인 경우, 프로세서는 영상, 영상에 포함된 얼굴 영 역의 색상 값의 범위에 대한 데이터 및 얼굴 영역에서 검출된 이마 영역과 볼 영역 간의 밝기 값의 차이에 대한 데이터를 인공지능 모델에 입력할 수 있다. 다른 예로, 인공지능 모델은 원본 영상들 및 페이크 영상들 각각의 아티펙트 데이터에 기초하여 학습된 경 우, 프로세서는 전술한 데이터 이외에도 영상에서 획득한 아티펙트 데이터를 인공지능 모델에 입력할 수 있다.한편, 프로세서는 영상에 포함된 얼굴의 포즈를 판단하고, 복수의 인공지능 모델(111-1 내지 111-5) 중 판 단된 포즈에 대응되는 인공지능 모델을 판단하고, 판단된 인공지능 모델에 영상을 입력하여, 영상이 페이크 영 상인지를 식별할 수 있다. 이를 위해, 프로세서는 영상에 포함된 얼굴의 포즈를 판단할 수 있다. 구체적으로, 프로세서는 얼굴 검출 알고리즘을 이용하여 영상에서 얼굴 영역을 검출하고, 얼굴 영역에 포 함된 얼굴의 롤각, 피치각 및 요각을 검출할 수 있다. 그리고, 프로세서는 검출된 롤각, 피치각 및 요각에 기초하여 영상에 포함된 얼굴이 바라보는 방향을 결정 하여, 얼굴의 포즈를 판단할 수 있다. 한편, 롤각, 피치각 및 요각에 따라 얼굴이 바라보는 방향을 결정하는 방 법에 대해서는 전술한 바 있다. 이후, 프로세서는 복수의 인공지능 모델(111-1 내지 111-5) 중에서, 영상에 포함된 얼굴이 바라보는 방향 과 같은 방향의 얼굴을 포함하는 원본 영상들 및 페이크 영상들에 의해 학습된 인공지능 모델을 판단하고, 판단 된 인공지능 모델에 영상을 입력하여, 영상이 페이크 영상인지를 식별할 수 있다. 예를 들어, 프로세서는 영상에 포함된 얼굴이 정면 방향을 바라보는 경우, 복수의 인공지능 모델(111-1 내 지 111-5) 중 제1 인공지능 모델(111-1)에 영상을 입력할 수 있다. 또한, 프로세서는 영상에 포함된 얼굴이 우측 방향을 바라보는 경우, 복수의 인공지능 모델(111-1 내지 111-5) 중 제2 인공지능 모델(111-2)에 영상을 입력할 수 있다. 또한, 프로세서는 영상에 포함된 얼굴이 좌측 방향을 바라보는 경우, 복수의 인공지능 모델(111-1 내지 111-5) 중 제3 인공지능 모델(111-3)에 영상을 입력할 수 있다. 또한, 프로세서는 영상에 포함된 얼굴이 상측 방향을 바라보는 경우, 복수의 인공지능 모델(111-1 내지 111-5) 중 제4 인공지능 모델(111-4)에 영상을 입력할 수 있다. 또한, 프로세서는 영상에 포함된 얼굴이 하측 방향을 바라보는 경우, 복수의 인공지능 모델(111-1 내지 111-5) 중 제5 인공지능 모델(111-5)에 영상을 입력할 수 있다. 한편, 프로세서는 복수의 인공지능 모델(111-1 내지 111-5)의 학습에 이용된 학습 데이터에 따라, 영상뿐 만 아니라, 영상으로부터 획득한 데이터(즉, 얼굴 영역의 색상 값의 범위에 대한 데이터, 이마 영역과 볼 영역 간의 밝기 값의 차이에 대한 데이터)를 영상의 얼굴 포즈에 대응되는 인공지능 모델에 입력할 수도 있다. 이와 같이, 프로세서는 인공지능 모델(또는, 복수의 인공지능 모델(111-1 내지 111-5) 중 하나의 인 공지능 모델)을 이용하여 영상이 원본 영상 또는 페이크 영상인지를 식별할 수 있다. 한편, 실시 예에 따라, 프로세서는 복수의 인공지능 모델(111-1 내지 111-5) 중 적어도 2 개를 이용하여 영상이 원본 영상 또는 페이크 영상인지를 식별할 수 있다. 즉, 프로세서는 복수의 인공지능 모델(111-1 내지 111-5) 중 적어도 2 개의 인공지능 모델에 영상을 입력 하고, 인공지능 모델 각각에서 출력되는 확률 값을 이용하여 영상이 원본 영상 또는 페이크 영상인지를 식별할 수 있다. 이 경우, 프로세서는 영상에 포함된 얼굴이 바라보는 방향에 따라, 영상이 입력될 적어도 2 개의 인공지능 모델을 판단할 수 있다. 예를 들어, 프로세서는 영상에서 검출된 얼굴의 피치각이 θ2 범위 내에 있고, 요각이 ψ2 범위 내에 있는 경우, 얼굴이 우상측 방향을 바라보는 것으로 판단하고, 복수의 인공지능 모델(111-1 내지 111-5) 중 제2 인공 지능 모델(111-2) 및 제4 인공지능 모델(111-4)을 영상이 입력될 인공지능 모델인 것으로 식별하고, 제2 및 제4 인공지능 모델(111-2, 111-4)에 영상을 입력할 수 있다. 다른 예로, 프로세서는 영상에서 검출된 얼굴의 피치각이 θ2 범위 내에 있고, 요각이 ψ3 범위 내에 있는 경우, 얼굴이 좌상측 방향을 바라보는 것으로 판단하고, 복수의 인공지능 모델(111-1 내지 111-5) 중 제3 인공 지능 모델(111-3) 및 제4 인공지능 모델(111-4)을 영상이 입력될 인공지능 모델인 것으로 식별하고, 제3 및 제4 인공지능 모델(111-3, 11104)에 영상을 입력할 수 있다. 다른 예로, 프로세서는 영상에서 검출된 얼굴의 피치각이 θ3 범위 내에 있고, 요각이 ψ2 범위 내에 있는 경우, 얼굴이 우하측 방향을 바라보는 것으로 판단하고, 복수의 인공지능 모델(111-1 내지 111-5) 중 제2 인공 지능 모델(111-2) 및 제5 인공지능 모델(111-5)을 영상이 입력될 인공지능 모델인 것으로 식별하고, 제2 및 제5 인공지능 모델(111-2, 111-5)에 영상을 입력할 수 있다. 다른 예로, 프로세서는 영상에서 검출된 얼굴의 피치각이 θ3 범위 내에 있고, 요각이 ψ3 범위 내에 있는 경우, 얼굴이 좌하측 방향을 바라보는 것으로 판단하고, 복수의 인공지능 모델(111-1 내지 111-5) 중 제3 인공 지능 모델(111-3) 및 제5 인공지능 모델(111-5)을 영상이 입력될 인공지능 모델인 것으로 식별하고, 제3 및 제5 인공지능 모델(111-3, 111-5)에 영상을 입력할 수 있다. 그리고, 프로세서는 이들 인공지능 모델에서 출력되는 확률 값을 이용하여 영상이 원본 영상 또는 페이크 영상인지를 식별할 수 있다. 예를 들어, 프로세서는 인공지능 모델 각각에서 출력되는 확률 값에 가중치를 부여하고, 가중치가 부여된 확률 값들의 평균 값을 산출하고, 평균 값을 기설정된 임계 값과 비교하여 영상이 원본 영상 또는 페이크 영상 인지를 식별할 수 있다. 이와 같이, 본 개시의 일 실시 예에 따르면, 영상에 포함된 얼굴이 복수의 방향을 바라보는 것으로 볼 수 있을 때, 복수의 인공지능 모델을 이용하여 영상이 페이크 영상인지를 식별한다는 점에서, 페이크 영상 식별에 대한 정확도가 향상될 수 있다. 한편, 프로세서는 페이크 영상인지에 대한 식별 결과를 전자 장치로 전송할 수 있다. 구체적으로, 프로세서는 영상이 원본 영상인 것으로 식별되면, 영상이 원본 영상임을 나타내는 정보를 포 함하는 UI(user interface) 화면을 전자 장치로 전송하고, 영상이 페이크 영상인 것으로 식별되면, 영상이 페이크 영상임을 나타내는 정보를 포함하는 UI 화면을 전자 장치로 전송할 수 있다. 이 경우, 전자 장치는 서버로부터 수신된 UI 화면을 전자 장치의 디스플레이에 표시할 수 있다. 도 8은 본 개시의 일 실시 예에 따른 서버의 세부 구성을 설명하기 위한 블록도이다. 도 8을 참조하면, 서버는 메모리, 프로세서 및 통신 인터페이스를 포함할 수 있다. 여기에 서, 이들 구성요소는 프로세서에 의해 제어될 수 있다. 한편, 도 8에 도시된 구성요소는 일 예일 뿐이고, 실시 예에 따라 적어도 일부 구성요소가 생략되거나, 다른 구 성요소가 추가될 수 있음은 물론이다. 또한, 메모리 및 프로세서는 도 1 내지 도 7에서 설명한 바 있다는 점에서, 구체적인 중복 설명은 생 략하도록 한다. 통신 인터페이스는 외부 기기와 통신을 수행하기 위한 구성이다. 예를 들어, 통신 인터페이스는 네트 워크를 통해 전자 장치, 서버(미도시) 등과 통신을 수행할 수 있다. 이를 위해, 통신 인터페이스는 네트워크 카드 등과 같이, 네트워크에 접속하기 위한 다양한 모듈을 포함할 수 있다. 이 경우, 프로세서는 통신 인터페이스를 통해 전자 장치로부터 영상을 수신할 수 있다. 또한, 프로세서는 통신 인터페이스를 통해 전자 장치로부터 영상을 제공하는 URL에 대한 정보를 수신하고, URL을 이용하여 통신 인터페이스를 통해 웹 페이지에 접속하여, 웹 페이지를 제공하는 서버(미 도시)로부터 영상을 수신받을 수 있다. 도 9는 본 개시의 일 실시 예에 따른 페이크 영상 식별을 위한 시스템을 나타낸다. 도 9를 참조하면, 시스템은 서버 및 전자 장치를 포함할 수 있다. 여기에서, 서버는 도 1 내지 도 8에서 설명한 바와 있다는 점에서, 구체적인 중복 설명은 생략하도록 한다. 전자 장치는 영상이 페이크 영상인지에 대한 식별을 요청하는 사용자 명령을 입력받을 수 있다. 여기에서, 전자 장치는 도 9에 도시된 바와 같이, 스마트폰으로 구현될 수 있다. 다만, 이는 일 예일 뿐이 고, 전자 장치는 노트북, PDA, 미디어 플레이어, MP3 플레이어, 마이크로 서버, GPS 장치, 전자책 단말기, 디지털방송용 단말기, 키오스크, 전자 액자, 네비게이션, 손목 시계(Wrist watch) 또는 HMD(Head-Mounted Display)와 같은 웨어러블 디바이스(Wearable device) 및 기타 모바일 또는 비모바일 컴퓨팅 장치 등으로 구현 될 수도 있다. 한편, 전자 장치는 사용자 명령이 입력되면, 전자 장치 및 서버 중 어떠한 기기가 영상이 페이 크 영상인지를 식별할 기기인지를 판단할 수 있다. 이에 따라, 전자 장치는 전자 장치가 페이크 영상인지를 식별할 기기인 것으로 판단되면, 전자 장치 에 저장된 인공지능 모델을 이용하여 영상이 페이크 영상인지를 식별하고, 식별 결과에 대한 정보를 포함 하는 UI 화면을 전자 장치의 디스플레이에 표시할 수 있다. 또한, 전자 장치는 서버가 페이크 영상인지를 식별할 기기인 것으로 판단되면, 영상을 서버로 전송하거나, 영상을 제공하는 URL을 서버로 전송할 수 있다. 이에 따라, 서버는 영상이 페이크 영상 인지를 식별하고, 식별 결과에 대한 정보를 포함하는 UI 화면을 전자 장치로 전송할 수 있다. 이 경우, 전 자 장치는 서버로부터 수신되는 UI 화면을 전자 장치의 디스플레이에 표시할 수 있다. 도 10은 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 도 10을 참조하면, 전자 장치는 디스플레이, 통신 인터페이스, 메모리 및 프로세서를 포함할 수 있다. 디스플레이는 다양한 화면을 표시할 수 있다. 이를 위해, 디스플레이는 LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 및 AM-OLED(Active-Matrix Organic Light-Emitting Diode) 등과 같은 다양한 형태의 디스플레이로 구현될 수 있다. 여기에서, 디스플레이는 그 구현 방식에 따라 부가적인 구성을 추가적으로 포함할 수 있다. 예를 들어, 디 스플레이가 액정 방식인 경우, 디스플레이는 LCD 디스플레이 패널(미도시), 이에 광을 공급하는 백라 이트 유닛(미도시) 및 패널(미도시)을 구동시키는 패널 구동기판(미도시)을 포함할 수 있다. 또한, 디스플레이는 터치 센서(미도시)와 결합되어, 터치 스크린으로 구현될 수 있다. 이에 따라, 디스플 레이는 디스플레이를 터치하는 사용자 명령을 수신하고, 수신된 사용자 명령을 프로세서로 전달 할 수 있다. 통신 인터페이스는 외부 기기와 통신을 수행하기 위한 구성이다. 예를 들어, 통신 인터페이스는 네트 워크를 통해 서버(미도시)와 통신을 수행할 수 있다. 여기에서, 서버(미도시)는 페이크 영상의 식별을 수행하는 서버 뿐만 아니라, 웹 페이지를 통해 영상을 제 공하는 서버(미도시)를 포함할 수 있다. 이를 위해, 통신 인터페이스는 와이파이 모듈(미도시) 및 이동통신 모듈(미도시)를 포함할 수 있다. 여기에서, 와이파이 모듈(미도시)은 와이파이 방식으로 통신을 수행할 수 있다. 예를 들어, 와이파이 모듈(미도 시)은 액세스 포인트(미도시)에 연결되어, 액세스 포인트(미도시)를 통해 서버(미도시)와 통신을 수행할 수 있 다. 또한, 이동통신 모듈(미도시)은 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), 5G(5th Generation) 등과 같은 이동통신 방식을 이용하여 서버(미도시)와 통신을 수행할 수 있다. 메모리는 전자 장치의 동작과 관련된 다양한 명령어, 프로그램 또는 데이터를 저장할 수 있다. 이를 위해, 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(flash-memory), 하드디스크 드라이브 (HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 여기에서, 메모리는 프로세서에 의해 액세스되며, 프로세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 한편, 본 개시에서 메모리라는 용어는 메모리, 프로세서 내 롬(미도시), 램(미도시) 또는, 전자 장치 에 장착되는 메모리 카드(미도시) 등을 포함할 수 있다. 특히, 메모리는 페이크 영상을 식별하도록 학습된 인공지능 모델을 저장할 수 있다. 또한, 메모리 는 도 10b와 같이, 각각 페이크 영상을 식별하도록 복수의 인공지능 모델(231-1 내지 231-5)을 저장할 수있다. 여기에서, 인공지능 모델(또는, 복수의 인공지능 모델(231-1 내지 231-5))은 서버에 저장된 인공지능 모델(또는, 복수의 인공지능 모델(111-1 내지 111-5))이 압축된 형태일 수 있다. 예를 들어, 인공지능 모델(또는, 복수의 인공지능 모델(231-1 내지 231-5))은 프루닝(pruning) 또는 퀀타 이제이션(quantization) 등의 방식에 따라 인공지능 모델(또는, 복수의 인공지능 모델(111-1 내지 111- 5))이 압축된 모델일 수 있다. 이에 따라, 인공지능 모델(또는, 복수의 인공지능 모델(231-1 내지 231-5))은 인공지능 모델(또는, 복수의 인공지능 모델(111-1 내지 111-5))과 용량, 처리 속도 및 정확도 등에서만 차이가 있을 뿐, 동일한 학습 데이터(가령, 각각 얼굴 영역의 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들, 얼굴 영역의 색상 값의 범위에 대한 데이터, 이마 영역과 볼 영역 간의 밝기 값의 차이에 대한 데이터 및 원본 영상들 및 페 이크 영상들 각각에서 획득된 아티팩트에 대한 데이터)를 기반으로 학습된 모델인 것으로 볼 수 있다. 프로세서는 디스플레이, 통신 인터페이스 및 메모리와 연결되어, 전자 장치를 제어할 수 있다. 즉, 프로세서는 디스플레이, 통신 인터페이스 및 메모리와 전기적으로 연결되어, 전자 장치의 전반적인 동작 및 기능을 제어할 수 있다. 여기에서, 프로세서는 CPU 또는 AP를 포함할 수 있으며, 메모리에 저장된 하나 이상의 인스트럭션에 따라 메모리에 저장된 하나 이상의 소프트웨어 프로그램을 실행할 수 있다. 특히, 프로세서는 전자 장치 및 서버 중에서 영상이 페이크 영상인지를 식별할 기기를 판단할 수 있다. 여기에서, 영상은 메모리에 저장된 영상일 수 있다. 또는, 프로세서는 URL을 이용하여 통신 인터페이 스를 통해 웹 페이지에 접속하여, 웹 페이지를 제공하는 서버(미도시)로부터 영상을 수신받을 수 있다. 즉, 프로세서는 영상이 페이크 영상인지에 대한 식별을 요청하는 사용자 명령이 입력되면, 전자 장치 및 서버 중에서 어떠한 기기가 영상이 페이크 영상인지를 식별할 기기인지를 판단할 수 있다. 구체적으로, 프로세서는 전자 장치 및 서버 중에서 사용자 명령에 따라 설정된 기기, 전자 장치 의 네트워크 상태, 영상의 사이즈, 영상의 타입, 영상에 포함된 얼굴 영역의 사이즈 및 얼굴 영역의 개수 중 적어도 하나에 기초하여, 전자 장치 및 서버 중 페이크 영상인지를 식별할 기기를 판단할 수 있다. 먼저, 프로세서는 사용자 명령에 따라 전자 장치 및 서버 중 하나의 기기가 페이크 영상을 식별 할 기기로 설정되어 있는 경우, 사용자 명령에 따라 설정된 기기를 페이크 영상을 식별할 기기인 것으로 판단할 수 있다. 예를 들어, 프로세서는 사용자 명령에 따라 설정된 기기가 전자 장치인 경우, 전자 장치를 페이 크 영상을 식별할 기기인 것으로 판단하고, 사용자 명령에 따라 설정된 기기가 서버인 경우, 서버를 페이크 영상을 식별할 기기인 것으로 판단할 수 있다. 한편, 프로세서는 사용자 명령에 따라 페이크 영상을 식별할 기기가 설정되어 있지 않은 경우, 전자 장치 의 네트워크 상태, 영상의 타입, 영상의 용량, 영상에 포함된 얼굴 영역의 사이즈 및 얼굴 영역의 개수 중 적어도 하나에 기초하여, 페이크 영상을 식별할 기기를 판단할 수 있다. 이를 위해, 메모리는 이러한 조건들의 조합에 따라 어떠한 기기가 페이크 영상을 식별할 기기인지가 미리 정의되어 있는 룩업 테이블(구체적으로, 다차원 룩업 테이블(multi dimensional look up table))을 저장하고 있 을 수 있다. 이에 따라, 프로세서는 메모리에 저장된 룩업 테이블을 이용하여, 전자 장치의 네트워크 상태, 영상의 사이즈, 영상의 타입, 영상에 포함된 얼굴 영역의 사이즈 및 얼굴 영역의 개수 중 적어도 하나에 따라 전자 장치 및 서버 중에서 영상이 페이크 영상인지를 식별할 기기를 판단할 수 있다. 이를 위해, 먼저, 프로세서는 전자 장치의 네트워크 상태를 판단할 수 있다. 여기에서, 네트워크 상태는 통신 인터페이스의 활성화 여부(즉, 와이파이 모듈 및 이동통신 모듈의 활성화 여부) 및 활성화된 통신 인터페이스의 네트워크 속도(즉, 와이파이 모듈이 활성화된 경우, 와이파이 모듈의 네트워크 속도이고, 이동통신 모듈이 활성화된 경우, 이동통신 모듈의 네트워크 속도를 포함할 수 있다). 또한, 프로세서는 영상의 타입 및 용량을 판단할 수 있다. 여기에서, 영상의 타입은 영상이 이미지 또는 동영상인지를 의미하고, 영상의 용량은 이미지 파일 또는 동영상 파일의 용량을 의미할 수 있다. 이 경우, 프로세서는 메모리 또는 서버(미도시)로부터 영상의 메타데이터를 획득하고, 획득된 메타데 이터를 이용하여 영상의 타입 및 용량을 판단할 수 있다. 또한, 프로세서는 얼굴 검출 알고리즘을 이용하여 영상에서 얼굴 영역을 검출하고, 검출된 얼굴 영역의 사 이즈 및 개수를 판단할 수 있다. 그리고, 프로세서는 룩업 테이블을 이용하여, 전자 장치의 네트워크 상태, 영상의 타입, 영상의 용량, 영상에 포함된 얼굴 영역의 사이즈 및 얼굴 영역의 개수 중 적어도 하나에 따라, 전자 장치 및 서버 중에서 어떠한 기기가 페이크 영상인지를 식별할 기기인지를 판단할 수 있다. 예를 들어, 전자 장치의 이동통신 모듈이 활성화되어 있고, 이동통신 모듈의 네트워크 속도가 10Mbps이고, 영상이 1Mb의 이미지이고, 이미지에서 200×200 사이즈를 갖는 1 개의 얼굴 영역이 검출되고, 룩업 테이블에 이 러한 조건인 경우 전자 장치가 페이크 영상을 식별할 기기로 설정되어 있는 경우, 프로세서는 전자 장치를 페이크 영상을 식별할 기기인 것으로 판단할 수 있다. 다른 예로, 와이파이 모듈이 활성화되어 있고, 와이파이 모듈의 네트워크 속도가 250Mbps이고, 영상이 100Mb의 동영상이고, 동영상을 구성하는 복수의 영상 프레임 중에서 검출된 얼굴 영역의 최대 사이즈가 250×200이고, 영상 프레임 별로 검출된 얼굴 영역의 최대 개수가 3이고, 룩업 테이블에 이러한 조건인 경우 서버가 페이 크 영상을 식별할 기기로 설정되어 있는 경우, 프로세서는 서버를 페이크 영상을 식별할 기기인 것으 로 판단할 수 있다. 이와 같이, 프로세서는 룩업 테이블을 이용하여 전자 장치와 서버 중에서 페이크 영상을 식별할 기기를 판단할 수 있다. 여기에서, 룩업 테이블에는 전자 장치의 네트워크 상태, 서버와 전자 장치의 하드웨어 시스템 성능 및 각 기기에 저장된 인공지능 모델(111, 231)의 성능을 고려할 때, 얼굴 영역의 개수 및 사이즈에 따른 특성을 갖는 영상이 어떠한 기기에서 처리되는 것이 효율적인지가 미리 정의되어 있을 수 있다. 이에 따라, 본 개시의 일 실시 예에 따르면, 이러한 룩업 테이블을 통해 보다 효율적인 기기에서 페이크 영상에 대한 식별이 이루어질 수 있다. 이와 같이, 전술한 예에서는, 사용자 명령에 따라 전자 장치 및 서버 중에서 하나의 기기가 페이크 영상인지를 식별할 기기로 결정되는 것으로 설명하였다. 다만, 이는 일 예일 뿐이고, 프로세서는 사용자가 어떠한 영상에 대해 페이크 영상인지의 식별을 요청하였 는지에 따라, 전자 장치 및 서버 중에서 하나를 페이크 영상인지를 식별할 기기로 판단할 수 있다. 구체적으로, 프로세서는 메모리에 저장된 영상에 대해 페이크 영상인지의 식별을 요청하는 사용자 명 령이 수신된 경우, 전자 장치를 페이크 영상인지를 식별할 기기인 것으로 판단할 수 있다. 또한, 프로세서 는 웹 페이지를 통해 제공되는 영상에 대해 페이크 영상인지의 식별을 요청하는 사용자 명령이 수신된 경 우, 서버를 페이크 영상인지를 식별할 기기인 것으로 판단할 수 있다. 한편, 프로세서는 전자 장치가 페이크 영상인지를 식별할 기기인 것으로 판단되면, 영상을 인공지능 모델에 입력하여, 영상이 페이크 영상인지를 식별할 수 있다. 그리고, 프로세서는 영상이 원본 영상 또는 페이크 영상임을 나타내는 정보를 포함하는 UI 화면을 디스플레이에 표시할 수 있다. 여기에서, 인공지능 모델(또는, 복수의 인공지능 모델 중 어느 하나의 인공지능 모델)을 이용하여 영상이 페이 크 영상인지를 식별하는 방법은 서버에서 설명한 바와 동일하다는 점에서, 구체적인 중복 설명은 생략하도 록 한다. 한편, 프로세서는 서버가 페이크 영상인지를 식별할 기기인 것으로 판단되면, 영상 또는 영상을 제공 하는 URL을 통신 인터페이스를 통해 서버로 전송할 수 있다. 그리고, 프로세서는 영상이 원본 영상 또는 페이크 영상임을 나타내는 정보를 포함하는 UI 화면이 통신 인 터페이스를 통해 서버로부터 수신되면, 수신된 UI 화면을 디스플레이에 표시할 수 있다.한편, 전술한 바와 같이, 프로세서는 전자 장치가 페이크 영상인지를 식별할 기기인 것으로 판단되면, 인공지능 모델을 이용하여 영상이 페이크 영상인지를 식별하게 된다. 구체적으로, 프로세서는 인공지능 모델에서 출력되는, 영상이 페이크 영상임을 나타내는 확률 값이 기설정된 임계 값 이상인 경우, 입력된 영상이 페이크 영상인 것으로 판단할 수 있다. 이 경우, 실시 예에 따라, 프로세서는 인공지능 모델에서 출력되는, 영상이 페이크 영상임을 나타내 는 확률 값이 기설정된 범위에 속하는 경우, 영상을 통신 인터페이스를 통해 서버로 전송할 수 있다. 여기에서, 일 예로, 기설정된 범위는 50%를 포함하고, 기설정된 범위의 최대 값은 기설정된 임계 값보다 작은 값일 수 있다. 예를 들어, 기설정된 임계 값은 60%이고, 기설정된 범위는 40%를 초과하고 60% 미만인 범위인 경우를 가정한다. 이 경우, 프로세서는 인공지능 모델에서 출력되는, 영상이 페이크 영상임을 나타내는 확률 값이 70% 인 경우, 영상이 페이크 영상인 것으로 판단할 수 있다. 다만, 프로세서는 인공지능 모델에서 출력되 는, 영상이 페이크 영상임을 나타내는 확률 값이 55%인 경우, 영상을 통신 인터페이스를 통해 서버로 전송할 수 있다. 이는, 인공지능 모델에서 출력되는 확률 값이 영상이 페이크 영상인 것으로 판단하기에 명확하지 않은 범 위에 속하는 경우, 인공지능 모델 보다 성능이 우수한 인공지능 모델에 의해 영상이 페이크 영상인지 에 대한 판별을 받아보기 위함이다. 한편, 실시 예에 따라, 프로세서는 영상에서 얼굴 영역이 검출되지 않는 경우, 영상이 페이크 영상인지를 식별하는 프로세스를 수행하지 않을 수 있다. 즉, 프로세서는 페이크 영상인지를 식별할 기기를 별도로 판 단하지 않고, 해당 프로세스를 종료할 수 있다. 또한, 프로세서는 영상에서 얼굴 영역이 검출되더라도, 얼굴 영역이 사용자 명령에 따라 설정된 조건에 부 합하지 않는 경우에는, 영상이 페이크 영상인지를 식별하는 프로세스를 수행하지 않을 수 있다. 예를 들어, 프로세서는 영상에서 검출된 얼굴 영역의 사이즈가 사용자 명령에 따라 설정된 최대 사이즈보 다 크거나, 또는, 영상에서 검출된 얼굴 영역의 개수가 사용자 명령에 따라 설정된 최대 개수보다 많은 경우, 영상이 페이크 영상인지를 식별하는 프로세스를 종료할 수 있다. 한편, 프로세서는 페이크 영상인지를 식별하는 프로세스를 종료하는 경우, 이를 나타내기 위한 UI 화면(가 령, \"영상은 입력하신 조건에 부합하지 않는 영상으로, 페이크 영상인지를 판별하지 않았습니다.\"와 같은 메시 지를 포함하는 UI 화면)을 디스플레이에 표시할 수 있다. 한편, 프로세서는 전술한 동작을 메모리에 저장된 어플리케이션을 통해 수행할 수 있다. 구체적으로, 프로세서는 페이크 영상의 식별을 위한 어플리케이션을 실행하기 위한 사용자 명령이 입력되 면, 해당 어플리케이션을 실행할 수 있다. 여기에서, 사용자 명령은 디스플레이에 표시된 홈 화면에서 아이콘을 선택하는 사용자 명령일 수 있다. 예를 들어, 도 11과 같이, 프로세서는 전자 장치에 설치된 복수의 어플리케이션을 나타내는 복수의 아이콘을 포함하는 홈 화면을 디스플레이에 표시할 수 있다. 그리고, 프로세서는 복수의 아이 콘 중 페이크 영상의 식별을 위한 어플리케이션을 나타내는 아이콘을 선택하는 사용자 명령이 입력되면, 해당 어플리케이션을 실행할 수 있다. 한편, 어플리케이션이 실행되면, 프로세서는 UI 화면을 통해, 영상을 선택하기 위한 사용자 명령을 입력받 을 수 있다. 이 경우, 프로세서는 사용자 명령에 따라 선택된 영상을 페이크 영상인지에 대한 식별이 수행 될 영상으로 결정할 수 있다. 여기에서, 사용자는 메모리에 저장된 복수의 영상 중에서 영상을 선택하거나, 또는, 웹 페이지에서 제공되 는 영상을 선택할 수 있다. 이를 위해, 일 예로, 프로세서는 도 12와 같이, 저장된 영상에서 선택하기 위한 UI 요소 및 웹 페이 지에서 선택하기 위한 UI 요소를 포함하는 UI 화면를 디스플레이에 표시할 수 있다. 여기에서, 프로세서는 UI 요소를 선택하는 사용자 명령이 입력되면, 메모리에 저장된 복수의 영상을 디스플레이에 표시할 수 있다. 그리고, 프로세서는 복수의 영상 중에서 하나를 선택하는 사용 자 명령을 수신되면, 선택된 영상을 페이크 영상인지를 식별할 대상이 되는 영상으로 판단할 수 있다. 또한, 프로세서는 UI 요소를 선택하는 사용자 명령이 입력되면, 통신 인터페이스부를 통해 인 터넷에 접속하고, 사용자 명령에 따라 인터넷을 통해 영상을 제공하는 웹 페이지에 접속할 수 있다. 그리고, 프 로세서는 웹 페이지를 선택하기 위한 사용자 명령이 입력되면, 선택된 웹 페이지에서 제공하는 영상을 페 이크 영상인지를 식별할 대상이 되는 영상으로 판단할 수 있다. 이후, 프로세서는 UI 화면을 통해, 파라미터를 설정하기 위한 사용자 명령을 입력받을 수 있다. 여기에서, 파라미터는 페이크 영상인지를 식별할 기기를 판단하기 위한 파라미터 및 얼굴 영역의 개수 및 사이 즈를 설정하기 위한 파라미터를 포함할 수 있다. 이를 위해, 일 예로, 프로세서는 도 13과 같이, 페이크 영상을 식별할 기기를 전자 장치로 설정하기 위한 UI 요소, 페이크 영상을 식별할 기기를 서버로 설정하기 위한 UI 요소, 얼굴 영역의 개 수를 설정하기 위한 UI 요소 및 얼굴 영역의 사이즈를 설정하기 위한 UI 요소를 포함하는 UI 화면 을 디스플레이에 표시할 수 있다. 이 경우, 프로세서는 UI 요소를 선택하는 사용자 명령이 입력되면, 전자 장치를 페이크 영상을 식별할 기기로 설정할 수 있다. 또한, 프로세서는 UI 요소를 선택하는 사용자 명령이 입력되면, 서 버를 페이크 영상을 식별할 기기로 설정할 수 있다. 또한, 프로세서는 UI 요소를 선택하기 위한 사용자 명령이 입력되면, 얼굴 영역의 개수를 설정하기 UI 화면(미도시)를 디스플레이에 표시하고, UI 화면(미도시)를 통해 입력된 사용자 명령에 기초하여, 얼굴 영역의 개수를 설정할 수 있다. 또한, 프로세서는 UI 요소를 선택하기 위한 사용자 명령이 입력되면, 얼굴 영역의 사이즈를 설정하 기 UI 화면(미도시)를 디스플레이에 표시하고, UI 화면(미도시)를 통해 입력된 사용자 명령에 기초하여, 얼굴 영역의 사이즈를 설정할 수 있다. 한편, 프로세서는 영상에서 검출된 얼굴 영역이 UI 화면(미도시)를 통해 설정된 얼굴 영역의 개수 및 사이 즈에 부합하지는지를 판단하고, 영상에서 검출된 얼굴 영역의 개수 및 사이즈가 사용자 명령에 따라 설정된 조 건에 부합하지 않는 경우에는, 영상이 페이크 영상인지를 식별하는 프로세스를 수행하지 않을 수 있다. 한편, 프로세서는 페이크 영상을 식별할 기기를 판단할 수 있다. 예를 들어, 프로세서는 도 12에 도시된 UI 화면을 통해, 메모리에 저장된 영상이 선택된 경우, 전자 장치를 페이크 영상을 식별할 기기인 것으로 판단할 수 있고, 웹 페이지를 통해 제공되는 영상이 선 택된 경우, 서버를 페이크 영상을 식별할 기기인 것으로 판단할 수 있다. 또한, 프로세서는 도 13에 도시된 UI 화면을 통해, 사용자 명령에 따라 전자 장치가 페이크 영 상을 식별할 기기로 설정된 경우, 전자 장치를 페이크 영상을 식별할 기기인 것으로 판단할 수 있고, 사용 자 명령에 따라 서버가 페이크 영상을 식별할 기기로 설정된 경우, 서버를 페이크 영상을 식별할 기 기인 것으로 판단할 수 있다. 다만, 프로세서는 사용자 명령에 따라 페이크 영상을 식별할 기기가 설정되지 않은 경우(가령, 도 13에서 UI 요소 및 UI 요소가 선택되지 않고 \"완료\"가 선택된 경우), 전자 장치의 네트워크 상태, 영 상의 사이즈, 영상의 타입, 영상에 포함된 얼굴 영역의 사이즈 및 얼굴 영역의 개수 중 적어도 하나에 기초하여 전자 장치 및 서버 중 페이크 영상인지를 식별할 기기를 판단할 수 있다. 한편, 프로세서는 전자 장치가 페이크 영상을 식별할 기기로 판단되면, 영상을 인공지능 모델에 입력하여, 영상이 페이크 영상인지를 식별할 수 있다. 그리고, 프로세서는 영상이 페이크 영상인 것으로 식별되면, 영상이 페이크 영상임을 나타내는 UI 화면(미 도시)을 디스플레이에 표시할 수 있다. 한편, 프로세서는 서버가 페이크 영상을 식별할 기기로 판단되면, 사용자 명령에 따라 선택된 영상 또는 영상을 제공하는 URL을 통신 인터페이스를 통해 서버로 전송할 수 있다. 그리고, 프로세서는 영상이 페이크 영상인 것으로 식별되면, 영상이 페이크 영상임을 나타내는 UI 화면(미 도시)을 통신 인터페이스를 통해 서버로부터 수신하고, 수신된 UI 화면(미도시)을 디스플레에 표시할 수 있다. 한편, 영상이 페이크 영상인 경우, 디스플레에 표시되는 UI 화면의 일 예는 다음과 같다. 예를 들어, 도 14a와 같이, 프로세서는 영상 및 영상이 페이크 영상임을 나타내는 확률 값을 포함하는 UI 화면을 디스플레이에 표시할 수 있다. 이 경우, 실시 예에 따라, 도 14b와 같이, 프로세서는 영상이 페이크 영상임을 나타내는 이모티콘을 디스플레이에 표시할 수 있다. 또한, 실시 예에 따라, 도 14c와 같이, 프로세서는 \"페이크 영상 입니다\"와 같이, 영상이 페이크 영상임을 나타내는 오디오를 전자 장치의 스피커(미도시)를 통해 출력할 수도 있다. 한편, 본 개시에 따른 인공지능과 관련된 기능은 프로세서(120, 240)와 메모리(110, 230)를 통해 동작된다. 여기에서, 프로세서(120, 240)는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세 서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU(Graphics Processing Unit), VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU(Neural Network Processing Unit)와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 한편, 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만들어진다는 것은 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모 델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수 있다. 가령, 서버에서 학습이 이루어지는 경우, 예를 들어, 프로세서는 원본 영상들 및 페이크 영상들 각각 에서 랜드마크에 해당하는 픽셀들을 판단하고, 판단된 픽셀들의 픽셀 값을 기설정된 픽셀 값으로 조정하여, 랜 드마크에 대한 정보를 포함하는 영상들을 생성할 수 있다. 그리고, 프로세서(120, 240)는 각각 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들을 이용하여 인공지능 모델을 학습시킬 수 있다. 또한, 프로세서는 원본 영상들 및 페이크 영상들 각각에서 얼굴 영역의 색상 값의 범위 및 이마 영역과 볼 영역 간의 밝기 값의 차이 중 적어도 하나를 판단하고, 이러한 데이터를 랜드마크에 대한 정보를 포함하는 영상 들과 함께 이용하여 인공지능 모델을 학습시킬 수 있다. 또한, 프로세서는 원본 영상들 및 페이크 영상들 각각에 포함된 얼굴의 포즈에 따라 원본 영상들 및 페이 크 영상들을 복수의 그룹으로 분류하고, 각 그룹에 포함된 영상들을 이용하여 각 인공지능 모델(111-1 내지 111-5)을 학습시킬 수 있다. 다만, 이는 일 예일 뿐이고, 학습은 전자 장치, 별도의 서버 및/또는 시스템을 통해 이루어 질 수도 있다. 한편, 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한 정되지 않는다. 인공지능 모델은 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 한편, 인공 신경망은 CNN(Convolutional Neural Network) 기반의 AlexNet, VGGNet, GoogLeNet, Inception, Xception, ShuffleNet, MesoNet, MobileNet, SqueezeNet 등을 포함할 수 있다. 뿐만 아니라, 인공 신경망은 DNN(Deep Neural Network), RNN(Recurrent Neural Network), RBM(Restricted Boltzmann Machine), DBN(DeepBelief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q- Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 도 15는 본 개시의 일 실시 예에 따른 서버의 제어 방법을 설명하기 위한 흐름도이다. 먼저, 페이크 영상을 식별하도록 학습된 인공지능 모델에 영상을 입력할 수 있다(S1510). 이후, 인공지능 모델의 출력 값에 기초하여, 입력된 영상이 페이크 영상인지를 식별할 수 있다(S1520). 여기에서, 인공지능 모델은 각각 얼굴 영역의 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들 에 기초하여 학습된 모델일 수 있다. 또한, 인공지능 모델은 원본 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설 정된 픽셀 값으로 조정된 원본 영상들 및 페이크 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽 셀의 픽셀 값이 기설정된 픽셀 값으로 조정된 페이크 영상들에 기초하여 학습된 모델일 수 있다. 또한, 인공지능 모델은 원본 영상들 및 페이크 영상들 각각에 포함된 얼굴 영역의 색상 값의 범위 및 얼굴 영역 에서 이마 영역과 볼 영역 간의 밝기 값의 차이 중 적어도 하나에 기초하여 학습된 모델일 수 있다. 또한, 인공지능 모델은 서버에 저장된 복수의 인공지능 모델 중 하나이고, 복수의 인공지능 모델 각각은 원본 영상들 및 페이크 영상들 각각에 포함된 얼굴의 포즈에 따라 원본 영상들 및 페이크 영상들이 분류된 복수의 그 룹 각각에 기초하여 학습된 모델이고, S1510 단계는 영상에 포함된 얼굴의 포즈를 판단하고, 복수의 인공지능 모델 중 판단된 포즈에 대응되는 인공지능 모델에 영상을 입력할 수 있다. 한편, 인공지능 모델 및 인공지능 모델을 이용하여 페이크 영상을 식별하는 구체적인 내용은 전술한 바 있다. 도 16은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 여기에서, 전자 장치는 페이크 영상을 식별하도록 학습된 인공지능 모델을 저장하고 있을 수 있다. 먼저, 전자 장치 및 서버 중에서 영상이 페이크 영상인지를 식별할 기기를 판단할 수 있다(S1610). 한편, 전자 장치가 영상이 페이크 영상인지를 식별할 기기인 것으로 판단되면, 영상을 인공지능 모델에 입력하 여 영상이 페이크 영상인지를 식별할 수 있다(S1620). 그리고, 서버가 영상이 페이크 영상인지를 식별할 기기인 것으로 판단되면, 영상을 서버로 전송할 수 있다 (S1630). 한편, 영상이 페이크 영상인 경우, 영상이 페이크 영상임을 나타내는 UI 화면을 표시할 수 있다(S1640). 여기에서, 인공지능 모델은 각각 얼굴 영역의 랜드마크에 대한 정보를 포함하는 원본 영상들 및 페이크 영상들 에 기초하여 학습된 모델일 수 있다. 또한, 인공지능 모델은 원본 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽셀의 픽셀 값이 기설 정된 픽셀 값으로 조정된 원본 영상들 및 페이크 영상들 각각에 포함된 얼굴 영역에서 랜드마크에 대응되는 픽 셀의 픽셀 값이 기설정된 픽셀 값으로 조정된 페이크 영상들에 기초하여 학습된 모델일 수 있다. 한편, S1610 단계는 전자 장치 및 서버 중에서 사용자 명령에 따라 설정된 기기, 전자 장치의 네트워크 상태, 영상의 사이즈, 영상의 타입, 영상에 포함된 얼굴 영역의 사이즈 및 얼굴 영역의 개수 중 적어도 하나에 기초하 여, 전자 장치 및 서버 중에서 영상이 페이크 영상인지를 식별할 기기를 판단할 수 있다. 또한, S1610 단계는 사용자 명령에 따라 설정된 기기가 전자 장치인 경우, 전자 장치를 영상이 페이크 영상인지 를 식별할 기기인 것으로 판단하고, 사용자 명령에 따라 설정된 기기가 서버인 경우, 서버를 영상이 페이크 영 상인지를 식별할 기기인 것으로 판단할 수 있다. 또한, S1610 단계는 전자 장치에 저장된 룩업 테이블을 이용하여, 전자 장치의 네트워크 상태, 영상의 사이즈, 영상의 타입, 영상에 포함된 얼굴 영역의 사이즈 및 얼굴 영역의 개수 중 적어도 하나에 따라 전자 장치 및 서 버 중에서 영상이 페이크 영상인지를 식별할 기기를 판단할 수 있다. 한편, 전자 장치에 저장된 인공지능 모델은 서버에 저장된 인공지능 모델이 압축된 모델일 수 있다. 한편, 전자 장치에서 페이크 영상을 식별할 기기를 판단하고, 그에 따른 동작을 수행하는 구체적인 내용에 대해 서는 전술한 바 있다.한편, 본 개시의 일시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기 기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 기기를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 프로세서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프 리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non- transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체 에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치들(예: 스 마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2020-0021746", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2020-0021746", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 서버의 구성을 설명하기 위한 블록도, 도 2a 및 도 2b는 본 개시의 일 실시 예에 따라 인공지능 모델이 학습되는 방법을 설명하기 위한 도면들, 도 3a 및 도 3b는 본 개시의 일 실시 예에 따라 인공지능 모델이 학습되는 방법을 설명하기 위한 도면들, 도 4a 및 도 4b는 본 개시의 일 실시 예에 따라 인공지능 모델이 학습되는 방법을 설명하기 위한 도면들, 도 5는 본 개시의 일 실시 예에 따른 인공지능 모델의 일 예를 설명하기 위한 도면, 도 6은 본 개시의 일 실시 예에 따른 얼굴의 포즈를 판단하는 방법을 설명하기 위한 도면, 도 7a 내지 도 7e는 본 개시의 일 실시 예에 따라 인공지능 모델이 학습되는 방법을 설명하기 위한 도면들, 도 8은 본 개시의 일 실시 예에 따른 서버의 세부 구성을 설명하기 위한 블록도, 도 9는 본 개시의 일 실시 예에 따른 페이크 영상 식별을 위한 시스템을 설명하기 위한 도면, 도 10은 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도, 도 11은 본 개시의 일 실시 예에 따른 페이크 영상의 식별을 위한 어플리케이션을 실행하는 방법을 설명하기 위 한 도면, 도 12는 본 개시의 일 실시 예에 따른 영상을 선택하는 사용자 명령을 입력받기 위한 UI 화면의 일 예를 나타낸 도면, 도 13은 본 개시의 일 실시 예에 따른 페이크 영상을 식별할 기기를 설정하는 사용자 명령을 입력받기 위한 UI 화면의 일 예를 나타낸 도면, 도 14a 내지 도 14c는 본 개시의 일 실시 예에 따라 영상이 페이크 영상인 경우 제공되는 유저 인터페이스의 일 예를 나타내는 도면들, 도 15는 본 개시의 일 실시 예에 따른 서버의 제어 방법을 설명하기 위한 흐름도, 그리고 도 16은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다."}
