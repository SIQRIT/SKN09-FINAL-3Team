{"patent_id": "10-2022-0080152", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0003090", "출원번호": "10-2022-0080152", "발명의 명칭": "이어 트레이닝을 제공하는 전자 장치, 이어 트레이닝 제공 방법, 및 컴퓨터 프로그램", "출원인": "벨테라퓨틱스 주식회사", "발명자": "박종화"}}
{"patent_id": "10-2022-0080152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치의 이어 트레이닝(Ear Training) 제공 방법에 있어서,악보를 디스플레이하고, 상기 악보에 대응되는 박자에 대한 가이드를 제공하는, 가이드 단계;상기 디스플레이 된 악보를 따라 부르는 사용자 음성을 입력 받는, 시창 단계;상기 가이드가 제공된 박자를 기반으로, 상기 입력된 사용자 음성을 상기 디스플레이 된 악보와 비교하여 오차를 식별하는, 분석 단계; 및상기 식별된 오차를 나타내는 첨삭 내용을 상기 악보 상에 추가하여 디스플레이하는, 첨삭 단계;를 포함하는,전자 장치의 이어 트레이닝 제공 방법."}
{"patent_id": "10-2022-0080152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 분석 단계는,상기 가이드가 제공된 박자 및 상기 악보를 구성하는 음표들을 기반으로, 상기 사용자 음성을 상기 음표들 각각에 매칭되는 복수의 부분 음성으로 구분하고,상기 복수의 부분 음성 각각을 상기 음표들과 비교하여, 상기 음표들 각각에 대한 상기 사용자 음성의 오차를식별하는, 전자 장치의 이어 트레이닝 제공 방법."}
{"patent_id": "10-2022-0080152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 분석 단계는,상기 입력된 사용자 음성을 상기 디스플레이 된 악보를 정확하게 따라 부른 시범 음성과 비교하여 상기 사용자음성의 오차를 식별하는, 전자 장치의 이어 트레이닝 제공 방법."}
{"patent_id": "10-2022-0080152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 분석 단계는,악보를 따라 부르는 음성의 오차를 식별하도록 구성된 인공지능 모델에, 상기 디스플레이 된 악보 및 상기 입력된 사용자 음성을 입력하여, 상기 입력된 사용자 음성의 오차를 식별하는, 전자 장치의 이어 트레이닝 제공 방법."}
{"patent_id": "10-2022-0080152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 인공지능 모델은,하나 이상의 악보, 상기 하나 이상의 악보를 따라 부른 음성, 및 상기 음성에 대한 전문가의 첨삭 내용을 기반으로 훈련된, 전자 장치의 이어 트레이닝 제공 방법."}
{"patent_id": "10-2022-0080152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,공개특허 10-2024-0003090-3-상기 전자 장치의 이어 트레이닝 제공 방법은,악보를 디스플레이하고, 상기 악보와 적어도 일부분이 매칭되지 않는 음악을 출력하는, 내청 단계;상기 디스플레이 된 악보 내에서 상기 출력된 음악과 매칭되지 않는 부분을 선택하는 사용자 입력을 수신하는,선택 단계; 및상기 악보와 상기 음악이 서로 매칭되지 않는 부분과 상기 사용자 입력을 통해 선택된 부분을 비교하는, 확인단계;를 더 포함하는, 전자 장치의 이어 트레이닝 제공 방법."}
{"patent_id": "10-2022-0080152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 선택 단계는,상기 악보가 디스플레이 된 상태에서 상기 음악이 출력되는 동안 사용자의 뇌파를 측정하고,상기 측정된 뇌파의 MMN(Mismatch Negativity)을 기반으로, 상기 사용자에 의해 상기 악보와 상기 음악이 서로매칭되지 않는 것으로 식별된 부분을 판단하는, 전자 장치의 이어 트레이닝 제공 방법."}
{"patent_id": "10-2022-0080152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "전자 장치에 있어서,디스플레이;스피커; 마이크; 및프로세서;를 포함하고,상기 프로세서는,상기 디스플레이를 통해 악보를 디스플레이하고, 상기 악보에 대응되는 박자에 대한 가이드를 제공하는, 가이드단계를 수행하고,상기 마이크를 통해 상기 디스플레이 된 악보를 따라 부르는 사용자 음성을 입력 받는, 시창 단계를 수행하고,상기 가이드가 제공된 박자를 기반으로, 상기 입력된 사용자 음성을 상기 디스플레이 된 악보와 비교하여 오차를 식별하는, 분석 단계를 수행하고,상기 디스플레이를 통해, 상기 식별된 오차를 나타내는 첨삭 내용을 상기 디스플레이 된 악보 상에 추가하여 디스플레이하는, 첨삭 단계를 수행하는, 전자 장치."}
{"patent_id": "10-2022-0080152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "컴퓨터 판독 가능 매체에 저장된 컴퓨터 프로그램에 있어서,전자 장치의 프로세서에 의해 실행되어, 상기 전자 장치로 하여금 제1항의 이어 트레이닝 제공 방법을 수행하도록 하는, 컴퓨터 프로그램."}
{"patent_id": "10-2022-0080152", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치의 이어 트레이닝 제공 방법이 개시된다. 본 이어 트레이닝 제공 방법은, 악보를 디스플레이하고, 악보 에 대응되는 박자에 대한 가이드를 제공하는, 청음 단계, 디스플레이 된 악보를 따라 부르는 사용자 음성을 입력 받는, 시창 단계, 가이드가 제공된 박자를 기반으로, 입력된 사용자 음성을 디스플레이 된 악보와 비교하여 오차 를 식별하는, 분석 단계, 식별된 오차를 나타내는 첨삭 내용을 악보 상에 추가하여 디스플레이하는, 첨삭 단계를 포함한다."}
{"patent_id": "10-2022-0080152", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 이어 트레이닝을 제공하는 전자 장치에 관한 것으로, 보다 상세하게는, 시창 훈련 및/또는 내청 훈련 을 제공하는 전자 장치에 관한 것이다."}
{"patent_id": "10-2022-0080152", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음악을 듣고 표현하는 개인의 기술을 향상시키기 위해 시창 훈련, 청음 훈련, 내청 훈련, 절대음감 훈련 등 다 양한 형태의 이어 트레이닝(Ear Training)이 이용되고 있다. 다만, 일반적인 이어 트레이닝의 경우 전문가가 직접 교육생과 만나 1대1로 이루어진다는 점에서, 비용과 시간 의 문제가 있었다. 관련하여, 사용자 단말을 통해 이용될 수 있는 애플리케이션 또는 웹 페이지를 통해 이어 트레이닝을 제공하는 일부 플랫폼들이 개발된 이력이 있으나, 실제 전문가가 제공하는 것만큼 효율적인 이어 트레이닝 제공 플랫폼은 거의 전무한 실정이다. 일 예로, 종래 기술인 등록 특허 제10-20776420000호(시창평가 시스템 및 그것을 이용한 시창평가방법)의 경우, 특정 악보의 곡을 따라 부른 사용자 음성의 음높이 및 길이를 분석하여 이를 새로운 악보로 표현(변환)하는 기 술 내용을 개시하고 있다. 이 경우, 사용자가 본인이 부른 음성의 악보와 정답 악보를 비교할 수 있다는 특징이 있다. 그러나, 상술한 종래 기술과 같이 사용자가 부른 음성이 그대로 악보로 표현되는 경우, 사용자 음성이 표현된 악보는 매우 난잡해질 가능성이 높다. 특히, 전문적으로 이어 트레이닝을 받는 음악 전공생들의 경우, 음정을 틀리더라도 미분음 단위 이하만큼만 틀 리는 경우가 대부분이고 리듬의 경우도 매우 미세하게 틀리는 경우가 대부분이기 때문에, 상술한 종래 기술을 통해 사용자 음성이 악보로 변환되는 경우, 미분음 단위 이하의 음정을 모두 표현하기 힘들 뿐만 아니라 사용자 음성의 실제 리듬을 정확하게 표현하는 과정에서 악보 내 음표 구성이 매우 복잡해질 수밖에 없다. 이 경우, 변 환된 악보는 정답 악보와 비교되기에는 너무 복잡하고 지저분하게 생성될 가능성이 높다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록 특허 공보 제10-20776420000호(시창평가 시스템 및 그것을 이용한 시창평가방법)"}
{"patent_id": "10-2022-0080152", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 사용자 음성을 자동으로 분석하여 정답 악보에 대한 첨삭 형태로 피드백을 제공하는 전자 장치 및 제 어 방법을 제공한다. 본 개시는 새로운 방법론이 적용된 내청 훈련을 제공하는 전자 장치 및 제어 방법을 제공한다. 본 개시의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 개시의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 개시의 실시 예에 의해 보다 분명하게 이해될 것이다. 또한, 본 개시의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2022-0080152", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 전자 장치의 이어 트레이닝(Ear Training) 제공 방법은, 악보를 디스플레이하고, 상기 악보에 대응되는 박자에 대한 가이드를 제공하는, 가이드 단계, 상기 디스플레이 된 악보를 따라 부르는 사용자 음성을 입력 받는, 시창 단계, 상기 가이드가 제공된 박자를 기반으로, 상기 입력된 사용자 음성을 상기 디스플레이 된 악보와 비교하여 오차를 식별하는, 분석 단계, 상기 식별된 오차를 나타내는 첨삭 내용을 상기 악보 상에 추가하여 디스플레이하는, 첨삭 단계를 포함한다. 상기 분석 단계는, 상기 가이드가 제공된 박자 및 상기 악보를 구성하는 음표들을 기반으로, 상기 사용자 음성 을 상기 음표들 각각에 매칭되는 복수의 부분 음성으로 구분하고, 상기 복수의 부분 음성 각각을 상기 음표들과 비교하여, 상기 음표들 각각에 대한 상기 사용자 음성의 오차를 식별할 수 있다. 또한, 상기 분석 단계는, 상기 입력된 사용자 음성을 상기 디스플레이 된 악보를 정확하게 따라 부른 시범 음성 과 비교하여 상기 사용자 음성의 오차를 식별할 수도 있다.또한, 상기 분석 단계는, 악보를 따라 부르는 음성의 오차를 식별하도록 구성된 인공지능 모델에, 상기 디스플 레이 된 악보 및 상기 입력된 사용자 음성을 입력하여, 상기 입력된 사용자 음성의 오차를 식별할 수도 있다. 이 경우, 상기 인공지능 모델은, 하나 이상의 악보, 상기 하나 이상의 악보를 따라 부른 음성, 및 상기 음성에 대한 전문가의 첨삭 내용을 기반으로 훈련된 것일 수 있다. 한편, 상기 전자 장치의 이어 트레이닝 제공 방법은, 악보를 디스플레이하고, 상기 악보와 적어도 일부분이 매 칭되지 않는 음악을 출력하는, 내청 단계, 상기 디스플레이 된 악보 내에서 상기 출력된 음악과 매칭되지 않는 부분을 선택하는 사용자 입력을 수신하는, 선택 단계, 상기 악보와 상기 음악이 서로 매칭되지 않는 부분과 상 기 사용자 입력을 통해 선택된 부분을 비교하는, 확인 단계를 포함할 수 있다. 여기서, 상기 선택 단계는, 상기 악보가 디스플레이 된 상태에서 상기 음악이 출력되는 동안 사용자의 뇌파를 측정하고, 상기 측정된 뇌파의 MMN(Mismatch Negativity)을 기반으로, 상기 사용자에 의해 상기 악보와 상기 음 악이 서로 매칭되지 않는 것으로 식별된 부분을 판단할 수도 있다. 본 개시의 일 실시 예에 따른 전자 장치는, 디스플레이, 스피커, 마이크, 프로세서를 포함한다. 상기 프로세서 는, 상기 디스플레이를 통해 악보를 디스플레이하고, 상기 악보에 대응되는 박자에 대한 가이드를 제공하는, 가 이드 단계를 수행하고, 상기 마이크를 통해 상기 디스플레이 된 악보를 따라 부르는 사용자 음성을 입력 받는, 시창 단계를 수행하고, 상기 가이드가 제공된 박자를 기반으로, 상기 입력된 사용자 음성을 상기 디스플레이 된 악보와 비교하여 오차를 식별하는, 분석 단계를 수행하고, 상기 디스플레이를 통해, 상기 식별된 오차를 나타내 는 첨삭 내용을 상기 디스플레이 된 악보 상에 추가하여 디스플레이하는, 첨삭 단계를 수행한다."}
{"patent_id": "10-2022-0080152", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따른 전자 장치 및 이어 트레이닝 제공 방법은, 교육생의 시창 훈련을 자동으로 평가하여 첨삭 형태 로 피드백을 제공함으로써 교육생이 시창 훈련의 결과를 어려움없이 확인할 수 있도록 한다는 효과가 있다. 본 개시에 따른 전자 장치 및 이어 트레이닝 제공 방법은, 시창 훈련 및 내청 훈련의 과정에서 교육생의 UI 조 작 과정을 최소화하여 훈련 준비 및 이해에 필요한 시간/과정을 최소화했다는 장점이 있다."}
{"patent_id": "10-2022-0080152", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에 대하여 구체적으로 설명하기에 앞서, 본 명세서 및 도면의 기재 방법에 대하여 설명한다. 먼저, 본 명세서 및 청구범위에서 사용되는 용어는 본 개시의 다양한 실시 예들에서의 기능을 고려하여 일반적 인 용어들을 선택하였다. 하지만, 이러한 용어들은 당해 기술 분야에 종사하는 기술자의 의도나 법률적 또는 기 술적 해석 및 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 일부 용어는 출원인이 임의로 선정한 용어 도 있다. 이러한 용어에 대해서는 본 명세서에서 정의된 의미로 해석될 수 있으며, 구체적인 용어 정의가 없으 면 본 명세서의 전반적인 내용 및 당해 기술 분야의 통상적인 기술 상식을 토대로 해석될 수도 있다. 또한, 본 명세서에 첨부된 각 도면에 기재된 동일한 참조번호 또는 부호는 실질적으로 동일한 기능을 수행하는 부품 또는 구성요소를 나타낸다. 설명 및 이해의 편의를 위해서 서로 다른 실시 예들에서도 동일한 참조번호 또 는 부호를 사용하여 설명한다. 즉, 복수의 도면에서 동일한 참조 번호를 가지는 구성요소를 모두 도시되어 있다 고 하더라도, 복수의 도면들이 하나의 실시 예를 의미하는 것은 아니다. 또한, 본 명세서 및 청구범위에서는 구성요소들 간의 구별을 위하여 \"제1\", \"제2\" 등과 같이 서수를 포함하는 용어가 사용될 수 있다. 이러한 서수는 동일 또는 유사한 구성요소들을 서로 구별하기 위하여 사용하는 것이며 이러한 서수 사용으로 인하여 용어의 의미가 한정 해석되어서는 안 된다. 일 예로, 이러한 서수와 결합된 구성 요소는 그 숫자에 의해 사용 순서나 배치 순서 등이 제한되어서는 안 된다. 필요에 따라서는, 각 서수들은 서로 교체되어 사용될 수도 있다. 본 명세서에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성 요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 실시 예에서 \"모듈\", \"유닛\", \"부(part)\" 등과 같은 용어는 적어도 하나의 기능이나 동작을 수행하는 구성요소를 지칭하기 위한 용어이며, 이러한 구성요소는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\", \"유닛\", \"부(part)\" 등은 각각이 개별적인 특정 한 하드웨어로 구현될 필요가 있는 경우를 제외하고는, 적어도 하나의 모듈이나 칩으로 일체화되어 적어도 하나 의 프로세서로 구현될 수 있다. 또한, 본 개시의 실시 예에서, 어떤 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적인 연결뿐 아니라, 다른 매체를 통한 간접적인 연결의 경우도 포함한다. 또한, 어떤 부분이 어떤 구성요소를 포함한다는 의미는, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것 을 의미한다. 도 1a는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 도 1a를 참조하면, 전자 장치는 디스플레이, 스피커, 마이크, 프로세서 등을 포함할 수 있다. 전자 장치는 스마트폰, 태블릿 PC, 노트북 PC, PDA, 모니터 및/또는 스피커와 연결된 데스크탑 PC, 키오스 크, 음향 모니터링 장치, VR/AR 기기 등 다양한 장치에 해당할 수 있으나, 이에 한정되지 않는다. 디스플레이는 다양한 정보를 시각적으로 제공하기 위한 구성이다. 디스플레이는 LCD(Liquid Crystal Display), PDP(Plasma Display Panel), OLED(Organic Light Emitting Diodes), TOLED(Transparent OLED), Micro LED 등으로 구현될 수 있으나, 이에 한정되는 것은 아니고 이밖에 종래 알려진 다양한 형태의 디스플레이를 포함할 수 있다. 디스플레이는, 사용자의 터치 조작을 감지할 수 있는 터치스크린 형태로 구현될 수 있으며, 접히거나 구부 러질 수 있는 플렉서블 디스플레이로 구현될 수도 있다. 스피커는 다양한 정보를 청각적으로 제공하기 위한 구성으로, 전기적인 오디오 신호를 변환하여 소리를 출 력하기 위한 종래의 다양한 구성을 포함할 수 있다. 도 1a와 달리, 전자 장치는 스피커 외에 적어도 하나의 스피커 장치와 연결될 수 있는 오디오 출력 단자를 포함할 수도 있다. 마이크는 외부로부터 다양한 정보를 청각적으로 입력 받기 위한 구성이다. 마이크는 입력된 소리를 전기적인 오디오 신호로 변환하기 위한 적어도 하나의 회로를 포함할 수 있다. 프로세서는 전자 장치에 포함된 구성들과 연결되어 전자 장치를 전반적으로 제어하기 위한 구성 이다. 프로세서는 전자 장치의 메모리에 저장된 적어도 하나의 인스트럭션을 실행함으로써 후술할 다양한 실시 예들에 따른 이어 트레이닝 제공 방법을 수행할 수 있다. 또한, 프로세서는 적어도 하나의 서버와 통신을 수행함으로써 애플리케이션 및/또는 웹 페이지에 접속하여 후술할 다양한 실시 예들에 따른 이어 트레이닝 제공 방법을 수행할 수도 있다. 프로세서는 CPU(Central Processing Unit), AP(Application Processor) 등과 같은 범용 프로세서, GPU(Graphic Processing Unit), VPU(Vision Processing Unit) 등과 같은 그래픽 전용 프로세서 또는 NPU(Neural Processing Unit)와 같은 인공지능 전용 프로세서 등으로 구현될 수 있다. 또한, 프로세서는 SRAM 등의 휘발성 메모리를 포함할 수 있다. 한편, 도 1a와 달리, 전자 장치는 적어도 하나의 사용자 단말과 통신을 수행하는 서버로 구현될 수도 있다. 도 1b를 참조하면, 전자 장치는 메모리(110'), 프로세서(120'), 통신부(130') 등을 포함하는 서버로 구현 될 수 있다. 전자 장치는 통신부(130')를 통해 적어도 하나의 사용자 단말과 통신을 수행할 수 있다. 여기서, 사용자 단말은, 스마트폰, 태블릿 PC, 노트북 PC, PDA 등 다양한 단말 장치에 해당할 수 있다. 구체적으로, 전자 장치는 디스플레이, 스피커, 마이크, 프로세서, 통신부 등을 포함하는 적어도 하나의 사용자 단말과 통신을 수행함으로써 후술할 다양한 실시 예들에 따른 동작을 수행할 수 도 있다. 구체적인 예로, 사용자 단말에 저장된 애플리케이션이 실행됨에 따라 사용자 단말은 서버에 접속할 수 있으며, 서버는 애플리케이션을 통해 사용자 단말을 제어하여 후술할 다양한 실시 예들에 따른 이어 트 레이닝 제공 방법을 수행할 수 있다. 이하 도면들을 통해, 도 1a 또는 도 1b의 전자 장치가 제공하는 이어 트레이닝 제공 방법에 대한 구체적인 실시 예들을 설명한다. 도 2는 본 개시의 일 실시 예에 따라 시창 훈련을 제공하는 전자 장치의 동작을 설명하기 위한 흐름도이다. 도 2를 참조하면, 전자 장치는 먼저 시창을 위한 가이드 단계를 수행할 수 있다. 구체적으로, 전자 장치 는 디스플레이를 통해 악보를 디스플레이하고, 악보에 대응되는 박자에 대한 가이드를 제공할 수 있다 (S210). 악보는, 복수의 음표 외에 오선, 음자리표, 박자표, 세로줄, 쉼표, 임시표, 이음줄, 붙임줄, 셈여림표, 빠르기 말, 기타 악상 기호 등 음악/노래를 구성하는 다양한 정보를 포함할 수 있다. 악보는 다양한 음악/노래에 대한 악보일 수 있으며, 전자 장치에 기저장된 악보일 수 있다. 일 예로, 전자 장치에 복수의 악보가 기저장되어 있을 수 있다. 여기서, 복수의 악보는 장르, 길이, 난이 도, 시대 등에 따라 구분될 수 있다. 여기서, 복수의 악보 중 적어도 하나가 사용자 입력에 따라 선택될 수 있다. 또는. 사용자의 ID 및 패스워드 등이 입력됨에 따라 로그인이 수행된 경우, 전자 장치는 로그인 된 사용자 의 사용자 정보를 기반으로 사용자의 과거 훈련 이력, 훈련 결과, 선호도 등에 대한 정보를 획득할 수 있다. 이 경우, 전자 장치는 사용자의 과거 훈련 이력, 훈련 결과(평가 결과), 선호도 등에 따라 적어도 하나의 악 보를 선택할 수도 있다. 그리고, 전자 장치는 선택된 악보를 디스플레이할 수 있다. 전자 장치는 사운드 또는 시각적 UI를 이용하여 박자를 가이드할 수 있다. 박자를 가이드하기 위한 사운드는, 악보를 통해 표현된 음악/노래의 리듬/박자를 가이드하기 위한 다양한 사운 드에 해당할 수 있다. 예를 들어, 전자 장치는 박자에 따른 메트로놈 사운드, 드럼 사운드, 기타 퍼커션 사운드 등을 스피커를 통해 출력할 수 있고, 이 밖에 노래에 대한 반주음, 배경음, 코러스 등에 해당하는 사운드를 출력할 수도 있다. 박자를 가이드하기 위한 시각적 UI는, 화면 상에서 시각적으로 특정한 주기에 맞게 박자를 안내하는 다양한 시 각적 요소를 포함할 수 있다. 예를 들어, 전자 장치는 박자에 맞게 주기적으로 형상 또는 모양이 변하는 다양한 UI를 디스플레이 상에 표시할 수 있다.한편, 전자 장치는 노래를 따라 부르기 시작할 정확한 시작 타이밍을 알려주기 위한 적어도 하나의 시각적 UI 또는 청각적 UI를 제공할 수 있다. 이 경우, 전자 장치는 시작 타이밍을 기준으로 박자에 대한 청각적/시각적 가이드를 제공하기 시작할 수 있다. 그리고, 상술한 악보와 가이드가 제공되면, 사용자는 악보를 통해 표현된 노래/음악을 따라 부르거나 연주할 수 있다(시창). 한편, 시창이 진행되는 동안, 전자 장치는 일정 주기마다 다음 악보를 디스플레이할 수 있다. 여기서, 일 정 주기는 악보를 통해 표현된 곡의 속도에 따라 기설정된 것일 수 있고, 가이드되는 박자와 매칭될 수 있으며, 한 화면에 표시되는 악보 내 마디의 수에 따라 기설정될 수도 있다. 일 예로, 처음에는 악보의 첫 네 마디가 디스플레이 되고, 템포에 따라 다음 네 마디가 순차적으로 표시될 수 있다. 다른 예로, 처음에는 악보의 첫 네 마디가 디스플레이 되고, 시작 타이밍 이후 네 번째 마디에 도입하는 시점이 되면, 첫 번째 마디 및 두 번째 마디가 사라지고 다섯 번째 마디 및 여섯 번째 마디가 디스플레이 될 수 있다. 다만, 상술한 예들에만 한정되지 않고 이밖에도 다양한 실시 예가 가능하다. 전자 장치는, 마이크를 통해, 악보를 따라 부르는(따라 연주하는) 사용자 음성(또는 연주음)을 입력 받을 수 있다(S220). 일 예로, 시작 타이밍을 알려주기 위한 UI가 제공된 경우, 전자 장치는 해당 시작 타이밍 을 기점으로 사용자 음성을 녹음할 수 있다. 관련하여, 도 3은 본 개시의 일 실시 예에 따른 전자 장치가 시창 훈련을 위한 다양한 UI(User Interface)를 제 공하는 동작을 설명하기 위한 도면이다. 도 3은 전자 장치가 태블릿 PC로 구현된 경우를 가정한다. 도 3을 참조하면, 전자 장치는 시창 훈련을 위한 UI를 디스플레이할 수 있다. 본 UI는 시창의 대상이 되는 곡을 표현하는 악보를 포함할 수 있으며, 해당 악보를 따라 부르도록 요청하는 안내문을 포함할 수 있다. 여기서, 전자 장치는 해당 악보의 박자를 가이드하기 위한 메트로놈 사운드를 출력할 수 있다. 그리고, 전자 장치는 메트로놈 사운드를 기반으로 악보의 노래를 따라 부르는 사용자 음성을 입 력 받을 수 있다. 여기서, 전자 장치는 입력된 사용자 음성을 악보에 해당하는 기설정된 시간동안 수신하여 적어도 하 나의 오디오 신호로 변환할 수 있다. 그리고, 전자 장치는 변환된 오디오 신호를 사용자 정보(ex. 이름, ID 등)와 함께 적어도 하나의 메모리에 저장할 수 있다. 그 결과, 특정한 사용자의 사용자 음성에 대한 녹음이 수행될 수 있다. UI에 포함된 “다시 부르기” 항목이 선택되는 경우, 전자 장치는 메트로놈 신호를 다시 출력하는 한 편 사용자 음성을 새롭게 녹음하여 오디오 신호를 획득할 수 있다. 한편, 만약 도 3과 달리 전자 장치가 서버로 구현된 경우, 전자 장치는 디스플레이, 스피커, 마이크 등을 구비한 사용자 단말과 통신을 수행함으로써, 사용자 단말을 통해 상술한 UI 및 사운드를 제공하고 사용자 음성을 입력 받을 수 있다. 한편, 상술한 실시 예들을 통해 악보를 따라 부르는 사용자 음성이 획득되면, 전자 장치는 입력된 사용자 음성을 악보와 비교하여 오차를 식별하는 분석 단계를 수행할 수 있다(S230). 이때, 전자 장치는 사용자 음성 및 악보를 다양한 방식에 따라 비교하여 오차를 식별할 수 있다. 일 실시 예로, 전자 장치는 가이드가 제공된 박자(ex. 메트로놈 사운드의 박자) 및 악보를 구성하는 음표 들을 기반으로, 사용자 음성을 음표들 각각에 매칭되는 복수의 부분 음성으로 구분할 수 있다. 구체적인 예로, 전자 장치는, 사용자 음성을 피치(진동수)에 따라 복수의 부분 음성으로 구분할 수 있다. 이때, 전자 장치는 사용자 음성의 오디오 신호를 주파수 변환(ex. FFT(Fourier Frequency Transform), HPF(High Pass Filter), LPF(Low Pass Filter) 등)함으로써 각 피치를 식별할 수 있으나, 이에 한정되지 않는 다. 복수의 부분 음성 각각은, 연속되는 하나의 음에 해당할 수 있다. 일 예로, 사용자 음성이 순차적으로 도-레-미 에 해당하는 각 피치와 매칭되는 경우, 도, 레, 미 각각에 해당하는 부분 음성들이 식별될 수 있다. 그리고, 전자 장치는, 가이드가 제공된 박자를 기준으로, 악보에 포함된 음표들 각각을 복수의 부분 음성 각각과 매칭시킬 수 있다. 구체적으로, 복수의 부분 음성 각각이 입력된 시간을 악보에 포함된 음표들의 위치 및 길이와 비교하여 각 부분 음성을 각 음표와 매칭시킬 수 있다. 여기서, 전자 장치는 사용자 음성에 포 함된 각 피치가 악보 내 어떤 음표를 노래한 것인지 식별할 수 있다. 그리고, 전자 장치는 복수의 부분 음성 각각을 매칭된 음표들과 비교하여, 음표들 각각에 대한 사용자 음 성의 오차를 식별할 수 있다. 구체적으로, 전자 장치는 악보 내 음표들 각각에 대한 부분 음성 각각의 길이(리듬), 음정, 세기, 연속되 는 다른 부분 음성과의 연결성(ex. 이음줄(slur)이 있는 경우) 등에 대한 오차를 식별할 수 있다. 또한, 일 실시 예로, 전자 장치는 입력된 사용자 음성을 시범 음성과 비교하여 사용자 음성의 오차를 식별 할 수도 있다. 여기서, 시범 음성은, 디스플레이 된 해당 악보를 정확하게 따라 부른 표본 음성에 해당하며, 전자 장치에 기저장되어 있을 수 있다. 구체적으로, 전자 장치는 입력된 사용자 음성의 오디오 신호를 시범 음성의 오디오 신호와 비교하여 임계 치 이상의 차이를 보이는 시간 구간을 식별할 수 있다. 이때, 전자 장치는 타임 도메인 또는 주파수 도메 인으로 오디오 신호들을 비교할 수 있다. 그리고, 전자 장치는 사용자 음성의 오디오 신호 중 식별된 시간 구간에 대한 오디오 신호가 악보 중 어느 음표에 매칭되는지 식별할 수 있다. 그 결과, 사용자가 부른 노래가 악보의 어느 부분(어떤 음표)에 대하여 어 떠한 오차를 가지는지 식별될 수 있다. 또한, 일 실시 예로, 전자 장치는 악보를 따라 부르는 음성의 오차를 식별하도록 구성된 인공지능 모델에, 디스플레이 된 악보 및 입력된 사용자 음성을 입력하여, 입력된 사용자 음성의 오차를 식별할 수도 있다. 본 인공지능 모델은, 음성에 대한 오디오 신호 및 악보가 입력되면, 악보에 대한 음성의 오차를 출력하도록 구 성된 모델일 수 있다. 본 인공지능 모델은 DNN(Deep Neural Networks) 기반의 데이터로 구현되어 훈련된 모델일 수 있으나, 이에 한정되지는 않는다. 일 예로, 본 인공지능 모델은, 적어도 하나의 컨볼루션 레이어를 통해 오디오 신호(음성)에 포함된 각 피치 및 리듬/길이에 대한 특징 정보를 획득할 수 있다. 그리고, 본 인공지능 모델은, 오디오 신호에 포함된 각 피치를 시간 정보에 따라 악보 내 각 음표와 매칭시켜 비교할 수도 있다. 한편, 본 인공지능 모델은, 하나 이상의 악보, 해당 악보를 따라 부른 음성, 및 해당 음성에 대하여 전문가를 통해 식별된 오차 내용을 기반으로 훈련된 모델일 수도 있다. 여기서, 악보 및 해당 악보를 따라 부른 음성은 인공지능 모델의 입력 데이터에 해당하는 훈련 데이터이고, 오 차 내용은 인공지능 모델의 출력 데이터에 해당하는 훈련 데이터일 수 있다. 오차 내용은, 해당 음성이 악보 내 어떤 음표와의 관계에서 어떤 점(ex. 음정, 리듬, 세기 등)이 어떻게 잘못되 었는지(ex. 음정이 높음/낮음 등)에 대한 정보를 포함할 수 있다. 앞선 실시 예들과 같이 사용자 음성의 오디오 신호가 기계적으로 분석되는 경우, 노이즈 또는 인간 음성의 불완 전성 때문에 리듬 및 음정이 악보와 백퍼센트 일치하는 것으로 판명되기는 쉽지 않다. 오히려, 전문가가 문제 삼지 않은 아주 미세하거나 또는 필연적인(자연스러운) 오차까지도 식별될 가능성이 생길 수 있다. 다만, 상술한 바와 같이 인공지능 모델이 전문가가 판단한 오차 내용을 기반으로 훈련되는 경우, 인공지능 모델 은 전문가의 시각과 유사한 시각(ex. 일정치 이상의 오차 범위) 내에서만 오차를 식별할 수 있고, 그 결과 마치 실제 전문가로부터 시창 지도를 받는 것과 같은 효과가 기대될 수 있다. 한편, 일 실시 예로, 전자 장치는 사용자 음성을 악보로 변환한 뒤, 변환된 악보의 적어도 하나의 음표를 사용자가 따라 부른 악보의 각 음표와 비교함으로써 오차를 식별할 수도 있다. 구체적인 예로, 전자 장치는 사용자 음성을 피치(진동수)에 따라 복수의 부분 음성으로 구분할 수 있다. 그리고, 전자 장치는 복수의 부분 음성 각각을 피치 및 길이 요소를 포함하는 음표로 변환함으로써, 사용자 음성이 변환된 악보를 획득할 수 있다. 여기서, 전자 장치는 변환된 악보의 각 음표의 위치 및 길이에 따라, 변환된 악보의 적어도 하나의 음표를 기존에 디스플레이 된 악보의 각 음표와 비교할 수 있다. 이 경우, 전자 장치는, 기존에 디스플레이 된 악보 내 음표와의 차이를 이용하여, 변환된 악보에 포함된 적어도 하나의 음표의 오차를 식별할 수 있다. 즉, 전자 장치는 사용자 음성(: 변환된 악보)이 기존에 디 스플레이 된 악보의 어떤 음표에 대하여 어떤 오차(ex. 피치, 길이, 세기 등)를 가지는지 식별할 수 있다. 상술한 다양한 실시 예들에 따라 사용자 음성의 오차가 식별되면, 전자 장치는 식별된 오차를 나타내는 첨 삭 내용을 (기존에 디스플레이 되었던) 악보 상에 추가하여 디스플레이 함으로써 첨삭 단계를 수행할 수 있다 (S240). 첨삭 내용은, 오차의 내용에 따라 기설정된 텍스트 또는 기호일 수 있다. 첨삭 내용을 구성할 수 있는 기설정된 텍스트는, 오차의 구체적인 내용에 따라 달라질 수 있다. 일 예로, 특정 음표에 대하여 임계 범위 내(ex. 95%~99% 길이)에서 해당 음표보다 짧게 부른 경우, 첨삭 내용은 “음가를 다소 짧게 부름”과 같은 텍스트로 구성될 수 있다. 또한, 일 예로, 특정 음표에 대하여 임계 범위 내(ex. 97~99.8% 피치)에서 해당 음표보다 낮게 부른 경우, 첨삭 내용은 “음고를 다소 낮게 부름”과 같은 텍스트로 구성될 수 있다. 또는, 특정 음표에 대하여 피치 또는 길이의 오차가 발생하면, 첨삭 내용은 해당 음표의 오차를 나타내는 기호 (ex. 화살표, 컬러 표시, 기타 다양한 기호)로 구성될 수 있다. 여기서, 피치의 오차를 나타내는 기호와 길이의 오차를 나타내는 기호는 서로 다르게 구성될 수 있으며, 피치가 높음을 나타내는 기호와 피치가 낮음을 나타내는 기호 역시 서로 다르게 구성될 수 있다. 일 예로, 악보에 기재된 음정보다 사용자 음성의 음정이 반의 반음 높은 경우, 전자 장치는, 악보의 해당 음정을 나타내는 음표보다 조금 높은 위치에 악보와 다른 컬러로 음표를 표시할 수 있다. 또한, 일 예로, 악보에 기재된 음표의 박자보다 사용자 음성의 특정 음정의 박자가 조금 빠른 경우, 전자 장치 는, 악보의 해당 음표보다 조금 왼쪽의 위치에 악보와 다른 컬러로 음표를 표시할 수 있다. 도 4는 본 개시의 일 실시 예에 따른 전자 장치가 시창 훈련의 결과를 제공하는 동작을 설명하기 위한 도면이다. 도 4는, 도 3의 실시 예에 따라 시창이 수행된 다음 단계를 도시한 것으로, 시창에 대한 첨삭 내용이 텍스트로 표현되는 일 실시 예에 따른 전자 장치의 화면이 도시된 것이다. 도 4를 참조하면, 전자 장치는 시창의 대상으로서 기존에 디스플레이 되어 있었던 악보 외에 다양한 첨삭 내용(411-1, 2, 3, …)을 포함하는 UI를 디스플레이할 수 있다. 도 4를 참조하면, 첨삭 내용(411-1, 2, 3, …)은 악보 내의 음표들 별로 매칭되어 표시될 수 있으며, 구체 적인 오차 내용에 따라 텍스트의 내용이 달라질 수 있다. 구체적으로, “음가를 다소 짧게 부름”, “음가를 다 소 길게 부름”, “Count 고르지 못함”, “triple과 division 인지가 다소 미흡” 등과 같은 다양한 첨삭 내용 이 제공될 수 있다. 이렇듯, 본 개시에 따른 전자 장치는 정답에 해당하는 악보 상에 첨삭 형태로 시창에 대한 피드백을 추가하여 제공할 수 있으므로, 사용자는 육안으로 판별하기 용이하며 마치 실제로 전문가의 1대1 지도를 받는 것과 같은 시창 훈련을 체험할 수 있다. 한편, 비록 도시되지는 않았으나, 일 실시 예로, 전자 장치는, 악보의 음표들 각각에 대한 사용자 음성의 음정 또는 길이의 오차를 식별하고, 식별된 오차에 따라 음정/길이의 정확도(accuracy), 분산치, 내지는 분포 (distribution) 등을 포함하는 도표 내지는 그래프를 디스플레이할 수도 있다. 이 경우, 사용자의 전반적인 시창 능력이 정량적으로 수치화 된 형태로 제공될 수 있다. 한편, 전자 장치는 상술한 시창 훈련 외에 내청 훈련을 제공할 수 있다. 관련하여, 도 5는 본 개시의 일 실시 예에 따라 내청 훈련을 제공하는 전자 장치의 동작을 설명하기 위한 흐름 도이다. 도 5를 참조하면, 전자 장치는 악보를 디스플레이하고, 악보와 적어도 일부분이 매칭되지 않는 음악을 출 력하는, 내청 단계를 수행할 수 있다(S510). 구체적으로, 전자 장치는 악보와 적어도 하나의 음표의 음정 또는 길이가 조금 다른 음악을 출력할 수 있 다. 즉, 대부분의 음표들에 대해서는 악보와 매칭되지만, 일부 소수의 음표들에 대해서는 오차를 가지는 음악이 출력될 수 있다. 또는, 전자 장치는 내청 훈련을 수행하는 교육생 본인이나 다른 교육생이 해당 악보를 시창한 음성으로 구 성된 음악을 출력할 수도 있다. 여기서, 사용자는 악보를 보면서 음악을 들을 수 있고, 음악이 틀린 부분에 대해 인지할 수 있다. 그리고, 전자 장치는, 디스플레이 된 악보 내에서 출력된 음악과 매칭되지 않는 부분을 선택하기 위한 사 용자 입력을 수신하는, 선택 단계를 수행할 수 있다(S520). 일 예로, 전자 장치는 디스플레이 된 악보 내에서 적어도 하나의 음표를 포함하는 영역을 터치하는 사용자 입력을 수신할 수 있다. 즉, 사용자는 음악을 들으면서 악보와 다른 부분을 인지하고, 인지된 부분에 매칭되는 음표를 악보 상에서 선택할 수 있다. 한편, 터치 방식 외에도, 버튼 조작, 마우스/키보드와 같은 입력 장치를 이용한 조작 등 다양한 형태로 사용자 입력이 수신될 수 있다. 다른 예로, 음악이 출력되는 동안 특정한 시점에 사용자의 버튼 또는 터치 조작이 입력되면, 전자 장치는 해당 시점을 기준으로 기설정된 시간 이전(ex. 1.5초)까지의 시간 구간에 매칭되는 악보 상의 부분이 선택된 것으로 식별할 수도 있다. 다른 예로, 전자 장치는 뇌파를 이용하여, 사용자가 인지한 틀린 부분이 어느 부분인지 식별할 수도 있다. 음악과 악보가 서로 다르다고 느껴지는 지점에서 사용자의 뇌파에 이질적인 변화가 감지될 수 있다는 점이 이용 된 것이다. 구체적인 예로, 전자 장치는 악보가 디스플레이 된 상태에서 음악이 출력되는 동안 사용자의 뇌파를 측정 할 수 있다. 이를 위해, 전자 장치는 뇌파 측정용 센서를 포함하는 적어도 하나의 장치와 연결될 수 있다. 그리고, 전자 장치는 측정된 뇌파의 MMN(Mismatch Negativity)을 기반으로, 사용자에 의해 악보와 음악이 서로 매칭되지 않는 것으로 식별된 부분을 판단할 수 있다. 즉, 전자 장치는, 사용자가 음악의 틀린 부분을 인지함에 따라 획득되는 사용자 뇌파의 변화를 이용하여, 사용자가 악보 상의 어느 부분이 음악과 다르다고 느끼는지 식별할 수 있다. 이렇듯 매칭되지 않는 부분을 인지한 사용자 입력(ex. 터치, 뇌파 등)이 수신되면, 전자 장치는 실제로 악 보와 음악이 서로 매칭되지 않는 부분과 사용자 입력을 통해 선택된 부분을 비교하는, 확인 단계를 수행할 수 있다(S530). 즉, 전자 장치는 사용자가 악보 및 음악 간의 차이점을 느낀 부분이 실제로 차이를 가지는 부분에 해당하 는지 확인하여, 사용자의 내청 결과를 평가할 수 있다. 관련하여, 도 6은 본 개시의 일 실시 예에 따른 전자 장치가 내청 훈련을 위한 다양한 UI를 제공하는 동작을 설 명하기 위한 도면이다. 도 6을 참조하면, 전자 장치는 악보를 포함하는 UI를 디스플레이할 수 있으며, 악보와 적 어도 일부분이 다른 음악을 출력할 수 있다. 도 6을 참조하면, UI는 악보와 음악 간에 차이가 있는 부분을 악보 상에서 선택하도록 요청하는 안내문을 포함할 수 있다. 이 경우, 악보 내 적어도 하나의 음표를 포함하는 부분이 사용자의 터치 또는 뇌파에 따라 선택될 수 있다. 여기서, 선택된 음표의 컬러가 변경되거나 해당 음표가 선택되었음을 알리는 별도의 지시자가 추가로 디 스플레이 될 수 있다. 그리고, 전자 장치는 선택된 부분이 실제로 음악과 다른 부분인지 여부를 식별할 수 있다. 이후, 전자 장치는 실제로 다른 부분들이 어디인지 나타내는 모범 답안을 악보 상에 디스플레이할 수 있다. 또한, 전자 장치는 출력된 음악과 일치하는 다른 악보를 디스플레이하여 제공할 수도 있다. 또한, 전자 장치는 실제로 악보와 음악이 매칭되지 않는 부분과 (사용자에 의해) 선택된 부분 간의 일치율 에 따라 내청 훈련의 정답율을 산정하여 제공할 수도 있다. 또한, 사용자가 정확히 선택하지 못한 부분에 대해서, 전자 장치는 출력되었던 음악의 해당 부분을 다시 출력하는 등 반복훈련을 수행할 수도 있다. 이때, 전자 장치는 해당 부분을 악보와 매칭되는 정확한 음악 으로 출력하여, 정확한 음정이 무엇인지 알려줄 수도 있다. 한편, 일 실시 예에 따르면, 전자 장치는, 복수의 교육생에 대하여 상술한 도 2의 시창 훈련과 상술한 도 5의 내청 훈련을 동시에 제공할 수도 있다. 구체적인 예로, 스마트폰에 해당하는 전자 장치는 도 2의 단계들을 수행함으로써 제1 교육생으로 하여금 시창을 하도록 유도할 수 있다. 동시에, 제1 교육생이 시창한 노래를 제2 교육생이 들으면서 틀린 부분을 찾는 내청 훈련이 진행될 수 있다. 즉, 내청 훈련을 위해 출력되는 음악(도 5의 S510 단계)은, 제1 교육생이 시창하는 노래로 대체된다. 구체적으로, 전자 장치는 제1 교육생이 시창한 노래와 악보 간의 오차를 식별할 수 있다(시창 훈련). 또한, 전자 장치는, 제1 교육생이 시창한 노래와 악보 간의 오차가 존재하는 경우, 오차가 존재하는 악보 상의 부분이 제2 교육생이 선택한 부분과 일치하는지 여부를 식별할 수 있다. 그 결과, 전자 장치는 제1 교육생의 시창 훈련 및 제2 교육생의 내청 훈련을 동시에 진행할 수 있다. 그리 고, 전자 장치는 시창 훈련 및 내청 훈련의 결과를 각각 제공할 수 있다. 다른 예로, 서버에 해당하는 전자 장치는 제1 교육생의 사용자 단말 및 제2 교육생의 사용자 단말과 각각 통신을 수행함으로써, 시창 훈련과 내청 훈련을 동시에 제공할 수도 있다. 구체적으로, 전자 장치는 제1 교육생의 사용자 단말을 통해 도 2의 시창 훈련을 제공하는 한편, 제2 교육 생의 사용자 단말을 통해서는 도 5의 내청 훈련을 제공할 수 있다. 내청 훈련 과정에서, 전자 장치는, 제2 교육생의 사용자 단말을 통해, 악보와 함께 제1 교육생의 사용자 음성으로 구성된 음악을 들려줌으로써, 내청 훈련을 진행할 수 있다. 그리고, 전자 장치는 제1 교육생의 사용자 단말 및 제2 교육생의 사용자 단말을 통해 시창 훈련 및 내청 훈련의 결과를 각각 제공할 수 있다. 또한, 전자 장치는 교육생들의 시창 훈련 및 내청 훈련의 결과를 교 육자(ex. 교수, 선생님 등)의 사용자 단말로 제공할 수도 있다. 상술한 실시 예에 따라, 복수의 교육생에 대한 복수의 이어 트레이닝(시창 훈련, 내청 훈련)이 함께 진행될 수 있으며, 특히 시창 훈련을 수행하는 교육생이 시창한 음악이 내청 훈련에 이용됨으로써, 교육 과정의 지루함이 나 내청 훈련에 이용되는 음악의 반복을 피하고 교육생들 간의 유대감 및 단체 학습 분위기 조성에 기여할 수 있다. 한편, 상술한 실시 예에서는 악보 및 음악이 출력되는 실시 예만이 설명되었으나, 악보 및 음악이 동시에 출력 되는 상술한 내청 훈련은, 악기/성악 전공자 및 일반인을 위한 방식이지 작곡 전공자에게 최적화된 방식은 아닐 수 있다. 작곡 전공자들에 대해서는, 이하와 같은 방식의 내청 훈련이 제공될 수도 있다. 일 실시 예로, 전자 장치는 악보를 디스플레이하면서 한편 해당 악보의 박자에 대한 가이드를 제공할 수 있다(ex. 박자에 맞는 메트로놈 사운드 출력). 이 경우, 사용자는 마음 속으로 해당 악보의 음악을 직접 노래/연주하면서 스스로 들을 수 있다(내청). 이때, 사용자는 디스플레이된 악보 상에서 내청이 잘 되지 않은 부분을 터치할 수 있으며, 전자 장치는 터 치된 해당 부분을 저장하는 한편, 해당 부분을 포함하는 악보의 일부분을 반복적으로 디스플레이하며 반복적인 내청 훈련을 제공할 수 있다. 한편, 도 7은 본 개시의 다양한 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 도 7을 참조하면, 전자 장치는 디스플레이, 스피커, 마이크, 프로세서 외에도 메모리 , 사용자 입력부, 통신부 등을 더 포함할 수 있다. 메모리는 전자 장치의 구성요소들의 전반적인 동작을 제어하기 위한 운영체제(OS: Operating System) 및 전자 장치의 구성요소와 관련된 적어도 하나의 인스트럭션 또는 데이터를 저장하기 위한 구성이다. 메모리는 ROM, 플래시 메모리 등의 비휘발성 메모리를 포함할 수 있으며, DRAM 등으로 구성된 휘발성 메모 리를 포함할 수 있다. 또한, 메모리는 하드 디스크, SSD(Solid state drive) 등을 포함할 수도 있다. 프로세서는 메모리에 저장된 적어도 하나의 인스트럭션을 실행함으로써 본 개시의 다양한 실시 예들 에 따른 동작을 수행할 수 있다. 일 예로, 메모리는 본 개시에 따른 상술한 이어 트레이닝을 제공하기 위한 적어도 하나의 애플리케이션 또 는 컴퓨터 프로그램에 대한 정보를 포함할 수 있다. 이때, 프로세서는 해당 애플리케이션 또는 컴퓨터 프 로그램을 실행함으로써 본 개시의 다양한 실시 예에 따른 이어 트레이닝 제공 방법을 수행할 수 있다. 사용자 입력부는 전자 장치에 대한 사용자의 명령 및/또는 전자 장치의 동작에 필요한 사용자 정보를 수신하기 위한 구성이다. 사용자 입력부는 하나 이상의 버튼, 터치스크린, 마이크, 카메라 등 다양한 구성을 포함할 수 있다. 일 예로, 사용자 입력부를 통해 상술한 애플리케이션 또는 컴퓨터 프로그램을 실행하기 위한 사용자 명령 이 수신되면, 프로세서는 본 개시에 따른 이어 트레이닝 제공 방법을 수행할 수 있다. 통신부는 전자 장치가 적어도 하나의 외부 장치와 통신을 수행하기 위한 구성으로 회로를 포함할 수 있다. 통신부는 유선 통신 및/또는 무선 통신을 통해 구현된 네트워크를 기반으로, 외부 장치와 연결될 수 있다. 이때, 통신부는 외부 장치와 직접적으로 연결될 수도 있지만, 네트워크를 제공하는 하나 이상의 외부 서버 (ex. ISP(Internet Service Provider))를 통해서 외부 전자 장치와 연결될 수도 있다. 네트워크는 영역 또는 규모에 따라 개인 통신망(PAN; Personal Area Network), 근거리 통신망(LAN; Local Area Network), 광역 통신망(WAN; Wide Area Network) 등일 수 있으며, 네트워크의 개방성에 따라 인트라넷 (Intranet), 엑스트라넷(Extranet), 또는 인터넷(Internet) 등일 수 있다. 무선 통신은 LTE(long-term evolution), LTE-A(LTE Advance), 5G(5th Generation) 이동통신, CDMA(code division multiple access), WCDMA(wideband CDMA), UMTS(universal mobile telecommunications system), WiBro(Wireless Broadband), GSM(Global System for Mobile Communications), DMA(Time Division Multiple Access), WiFi(Wi-Fi), WiFi Direct, Bluetooth, NFC(near field communication), Zigbee 등의 통신 방식 중 적어도 하나를 포함할 수 있다. 유선 통신은 이더넷(Ethernet), 광 네트워크(optical network), USB(Universal Serial Bus), 선더볼트 (ThunderBolt) 등의 통신 방식 중 적어도 하나를 포함할 수 있다. 여기서, 통신부는 상술한 유무선 통신 방식에 따른 네트워크 인터페이스(Network Interface) 또는 네트워크 칩을 포함할 수 있다. 한편, 통신 방식은 상술한 예에 한정되지 아니하고, 기술의 발전에 따라 새롭게 등장하는 통신 방식을 포함할 수 있다. 일 예로, 프로세서는 본 개시에 따른 이어 트레이닝 제공 방법을 수행하기 위한 애플리케이션을 실행함으 로써 통신부를 통해 적어도 하나의 외부 서버와 연결될 수 있다. 이때, 프로세서는 통신부를 통해 외부 서버로부터 애플리케이션과 관련된 정보(ex. 웹 페이지, 사운 드 정보(노래), UI 정보 등)를 수신할 수 있다. 또한, 일 실시 예로, 상술한 도 2의 단계들 중 가이드 단계(S210), 시창 단계(S220), 첨삭 단계(S240) 등은 사 용자 단말로 구현된 전자 장치를 통해 수행되고, 사용자 음성의 오차를 식별하기 위한 분석 단계(S230)는 전자 장치와 통신을 수행하는 서버(ex. 서비스 제공자)를 통해 수행될 수도 있다. 이밖에, 전자 장치는 통신부를 통해 뇌파를 측정하기 위한 장치, 스피커 장치 등 다양한 장치와 통신 을 수행할 수 있다. 한편, 이상에서 설명된 다양한 실시 예들은 서로 저촉되지 않는 한 두 개 이상이 결합되어 수행될 수 있다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합된 것 을 이용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 본 개시에서 설명되는 실시 예들은 ASICs(Application Specific Integrated Circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processors), 제어기 (controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행 을 위한 전기적인 유닛(unit) 중 적어도 하나를 이용하여 구현될 수 있다. 일부의 경우에 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 상술한 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 작동을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 전자 장치에서의 처리동작을 수행하기 위한 컴퓨터 명령 어(computer instructions) 또는 컴퓨터 프로그램은 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium)에 저장될 수 있다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어 또는 컴퓨터 프로그램은 특정 기기의 프로세서에 의해 실행되었을 때 상술한 다양한 실시 예에 따른 전자 장치 에서의 처리 동작을 상술한 특정 기기가 수행하도록 한다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등 이 있을 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2022-0080152", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어서는 안될 것이다."}
{"patent_id": "10-2022-0080152", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도, 도 1b는 본 개시의 일 실시 예에 따라 적어도 하나의 사용자 단말과 통신을 수행하는 서버로 구현된 전자 장치 의 구성을 설명하기 위한 블록도, 도 2는 본 개시의 일 실시 예에 따라 시창 훈련을 제공하는 전자 장치의 동작을 설명하기 위한 흐름도, 도 3은 본 개시의 일 실시 예에 따른 전자 장치가 시창 훈련을 위한 다양한 UI(User Interface)를 제공하는 동 작을 설명하기 위한 도면, 도 4는 본 개시의 일 실시 예에 따른 전자 장치가 시창 훈련의 결과를 제공하는 동작을 설명하기 위한 도면, 도 5는 본 개시의 일 실시 예에 따라 내청 훈련을 제공하는 전자 장치의 동작을 설명하기 위한 흐름도, 도 6은 본 개시의 일 실시 예에 따른 전자 장치가 내청 훈련을 위한 다양한 UI를 제공하는 동작을 설명하기 위 한 도면, 그리고 도 7은 본 개시의 다양한 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다."}
