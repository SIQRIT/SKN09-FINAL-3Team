{"patent_id": "10-2022-0183246", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0102070", "출원번호": "10-2022-0183246", "발명의 명칭": "과실 수확 장치 및 그 제어 방법", "출원인": "한국생산기술연구원", "발명자": "고광은"}}
{"patent_id": "10-2022-0183246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "프로세서, 로봇 암, 로봇 암의 단부에 배치된 엔드 이펙터, 및 로봇 암의 단부에 배치된 카메라 모듈을 포함하고, 수확 대상 작물의 이미지 정보를 수집하고,상기 이미지 정보에 포함된 하나 이상의 작물의 위치 정보, 상기 카메라 모듈의 위치 정보, 및 기준점의 위치정보에 기초하여, 각 작물 별 수확 가능도를 정량화하도록 구성된 수확 장치."}
{"patent_id": "10-2022-0183246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 이미지 정보에 포함된 하나 이상의 작물의 위치 정보, 상기 카메라 모듈의 위치 정보, 및 상기 기준점의위치 정보에 기초하여, 각 작물 별 수확 가능도를 정량화하는 것은,각 작물의 이미지 내 2차원 픽셀 좌표 정보(xp1,yp1)를 도출하고,각 작물의 상기 기준점 기준 3차원 공간 좌표 정보(xb1,yb1,zb1)를 도출하고, 각 작물의 상기 픽셀 좌표 정보와 공간 좌표 정보에 기초하여 정량화하는 것을 포함하는, 수확 장치."}
{"patent_id": "10-2022-0183246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 기준점 기준 3차원 공간 좌표 정보를 도출하는 것은,상기 2차원 픽셀 좌표 정보(xp1,yp1), 각 작물의 이미지 내 이미지 깊이 정보(zd1), 및 상기 카메라 모듈의 상기기준점 기준 3차원 공간 좌표 정보(xb2,yb2,zb2)에 기초하여 도출되는 수확 장치."}
{"patent_id": "10-2022-0183246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,각 작물의 상기 픽셀 좌표 정보와 공간 좌표 정보에 기초하여 정량화하는 것은,상기 각 작물에 대해, 상기 이미지의 2차원 픽셀 좌표(xp,yp)의 축 별 미리 지정된 확률 함수(f1, f2)에 대한 우도(likelihood)(P(xp1|f1), P(yp1|f2)) 기반 제1 스코어(S1) 및 제2 스코어(S2)를 도출하고,상기 각 작물에 대해, 상기 기준점 기준 3차원 공간 좌표(xb,yb,zb)의 미리 지정된 확률 함수(f3)에 대한 우도(P(||xb1,yb1,zb1|||,f3)) 기반 제3 스코어(S3)를 도출하고,상기 제1 스코어, 제2 스코어 및 제3 스코어에 기초하여 정량화하는 것을 포함하는 수확 장치."}
{"patent_id": "10-2022-0183246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 제1 스코어, 제2 스코어 및 제3 스코어에 기초하여 정량화하는 것은, 하기 수식을 통해 최종 스코어(S)로정량화되는 수확 장치.S = αS1 × βS2 × γS3 × δ(여기서, 공개특허 10-2024-0102070-3-α, β, γ는 각각 가중치로서 서로 동일하거나 상이한 임의의 양수이고,δ는 추가적인 고려 변수로서 1, 또는 임의의 양수, 또는 기도출된 변수에 대한 함수임)"}
{"patent_id": "10-2022-0183246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 이미지 정보의 수집은,상기 카메라 모듈이 미리 지정된 상기 기준점 기준 3차원 공간 좌표(xb2,yb2,zb2)에 위치한 상태에서 수행되고,상기 작물 별 수확 가능도를 정량화하는 것은, 상기 카메라의 3차원 공간 좌표(xb2,yb2,zb2)에 기초하여 수행되는수확 장치."}
{"patent_id": "10-2022-0183246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 작물 별 수확 가능도를 정량화하는 것은, 어느 작물에 대한 로봇 암의 조작도(manipulability, m(θ))에더 기초하는 수확 장치."}
{"patent_id": "10-2022-0183246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "수확 대상 작물의 RGB-D 이미지를 수집하는 이미지 정보 수집부;상기 수집된 이미지 정보에서, 상기 작물의 이미지 내 2차원 픽셀 좌표 정보(xp1,yp1)를 도출하는 픽셀 좌표 생성부;상기 수집된 이미지 정보에서, 상기 작물의 거리 정보(zd1)를 도출하는 깊이 정보 생성부;적어도 상기 2차원 픽셀 좌표와 거리 정보에 기초하여, 상기 작물의 임의의 원점 기준 3차원 공간 좌표 정보(xb1,yb1,zb1)를 도출하는 공간 좌표 생성부;상기 작물의 상기 x축 픽셀 좌표 정보(xp1)의 미리 지정된 확률 함수에 대한 우도 기반 제1 스코어를 생성하는제1 스코어 생성부;상기 작물의 상기 y축 픽셀 좌표 정보(yp1)의 미리 지정된 확률 함수에 대한 우도 기반 제2 스코어를 생성하는제2 스코어 생성부; 및상기 작물의 상기 3차원 공간 좌표 정보(xb1,yb1,zb1)의 미리 지정된 확률 함수에 대한 우도 기반 제3 스코어를생성하는 제3 스코어 생성부를 포함하는 수확 장치."}
{"patent_id": "10-2022-0183246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 제1 스코어 내지 제3 스코어를 소정의 방법으로 연산하여 최종 스코어를 생성하는 최종 스코어 생성부를더 포함하되, 상기 소정의 방법은 상기 제1 스코어, 제2 스코어 및 제3 스코어 각각이 증가할 경우 최종 스코어가 더 커지도록 구성된 수확 장치."}
{"patent_id": "10-2022-0183246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "적어도 하나의 프로세서를 포함하는 컴퓨팅 장치에 의해 수행되는 방법으로,수확 대상 작물의 이미지 정보를 수집하고,상기 이미지 정보에 포함된 하나 이상의 작물의 위치 정보, 상기 카메라 모듈의 위치 정보, 및 기준점의 위치정보에 기초하여, 각 작물 별 수확 가능도를 정량화하는 것을 포함하는 수확 대상 작물의 정량화 방법."}
{"patent_id": "10-2022-0183246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2024-0102070-4-컴퓨팅 장치와 결합되어, 수확 대상 작물의 이미지 정보를 수집하고,상기 이미지 정보에 포함된 하나 이상의 작물의 위치 정보, 상기 카메라 모듈의 위치 정보, 및 기준점의 위치정보에 기초하여, 각 작물 별 수확 가능도를 정량화하는 동작을 수행하도록 구성된 기록매체에 기록된프로그램."}
{"patent_id": "10-2022-0183246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "미리 지정된 경로를 따라 이동하는 제1항의 수확 장치를 포함하는 수확 시스템."}
{"patent_id": "10-2022-0183246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 수확 장치는,제1 단계에서, 상기 경로를 따라 이동하고, 어느 제1 위치에서 정지하여 작물의 이미지 정보를 수집하고, 해당이미지 내 작물의 수확 가능도를 정량화하고, 정량화된 스코어가 기준치 이상인 작물을 수확하고,제2 단계에서, 상기 경로를 따라 이동하고, 상기 제1 위치와 상이한 제2 위치에서 정지하여 작물의 이미지 정보를 수집하고, 해당 이미지 내 작물의 수확 가능도를 정량화하고, 정량화된 스코어가 기준치 이상인 작물을 수확하도록 구성된 수확 시스템."}
{"patent_id": "10-2022-0183246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 제2 단계에서 수집된 이미지 정보에는, 상기 제1 단계에서 수집된 이미지 정보에 포함된 작물이 적어도 하나 포함되는 수확 시스템."}
{"patent_id": "10-2022-0183246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 수확 장치는 상기 경로를 따라 이동하며 복수의 이미지 정보를 수집하고, 각 이미지 내 작물의 수확 가능도를 정량화하되, 어느 이미지 내에 기준치 이상의 정량화된 스코어를 갖는 작물이 존재할 경우, 정지하여 해당작물을 수확하도록 구성된 수확 시스템."}
{"patent_id": "10-2022-0183246", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "수확 대상 과실의 수확 가능도 또는 우선 순위를 판단하도록 구성된 과실 수확 장치, 그리고 수확 가능도 또는 우선 순위의 판단 방법을 포함하는 수확 장치의 제어 방법이 제공된다. 상기 과실 수확 장치는 프로세서, 로봇 암, 로봇 암의 단부에 배치된 엔드 이펙터, 및 로봇 암의 단부에 배치된 카메라 모듈을 포함하고, 수확 대상 작 물의 이미지 정보를 수집하고, 상기 이미지 정보에 포함된 하나 이상의 작물의 위치 정보, 상기 카메라 모듈의 위치 정보, 및 기준점의 위치 정보에 기초하여, 각 작물 별 수확 가능도를 정량화하도록 구성된다."}
{"patent_id": "10-2022-0183246", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 과실 수확 장치 및 그 제어 방법에 관한 것이다. 상세하게는, 수확 대상 과실의 수확 가능도 또는 우 선 순위를 판단하도록 구성된 과실 수확 장치, 그리고 수확 가능도 또는 우선 순위의 판단 방법을 포함하는 수 확 장치의 제어 방법에 관한 것이다."}
{"patent_id": "10-2022-0183246", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "소위 스마트팜은 농업 등의 생산, 가공 및 유통 단계에서 정보 통신 기술(ICT)을 접목하여 지능화된 농업 시스 템을 지칭한다. 최근 사물 인터넷, 빅데이터, 인공 지능 기술 등의 발전에 따라 농산물의 생산 효율성을 높이기 위한 연구가 이루어지고 있다. 농업 분야는 노동 집약적인 특성을 갖는다. 그러나 최근 인구의 고령화, 높은 노동 강도로 인한 농업 기피 현상 등으로 인해 농업의 생산성이 점차 저하되는 추세에 있어 보다 지능화된 스마트팜 관련 기술 발전이 절실히 요 구된다. 선행기술문헌 특허문헌(특허문헌 0001) KR 10-2022-0162483 A"}
{"patent_id": "10-2022-0183246", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "스마트팜의 한 분야로서, 과실 또는 과일 등의 농작물의 수확을 자동화하기 위한 연구가 이루어지고 있다. 예를 들어, 특허문헌 1은 통로를 통해 로봇 암 등이 구비된 수확 장치가 이동하며 수확 대상 과실을 수확하는 기술을 개시한다. 이 때 수확 대상 과실 내지는 수확 후보 과실의 수확 여부, 또는 숙도 판별을 위한 이미지 정보의 수집을 위해 카메라를 이용한 비전 기술이나 인공지능 기술을 사용하는 것을 고려할 수 있다. 이 경우 수확 장치가 이동함에 따라 어느 시점에서 카메라를 이용해 이미지 정보를 수집할 것인지가 문제된다. 다시 말해서, 과실 등의 작물이 일렬로 배열되어 있을 때 어느 위치에서 이미지 정보의 수집 및/또는 수확 동작을 수행할 것인지 특정할 필요가 있다. 즉, 수확 장치의 이동에 따라 카메라의 위치가 변화하는데, 이동 과정마다 이미지 정보를 수집하고 과실의 위치 등을 인식하는 것은 데이터 처리양의 방대한 증가를 야기하고, 명확한 기준을 제시하지 않을 경우 수확 작업의 진전이 이루어지지 않거나, 더디게 만들 수 있다. 한편, 농작물 수확의 자동화를 위해 고려되어야 할 중요한 요소 중 하나는 카메라의 위치이다. 본 발명은 로봇 암의 단부에 매니퓰레이터 뿐 아니라 카메라를 배치하고자 한다. 로봇 암의 단부에 카메라를 배치할 경우 작물 에 매달린 과실을 다양한 각도에서 촬영하고 이를 통해 과실의 숙도 판별에 활용할 수 있다. 그러나 로봇 암의 단부에 카메라를 배치할 경우 로봇 암의 베이스, 예컨대 수확 장치의 절대적 위치와 카메라의 상대적 위치 간에 차이가 발생할 수 있다. 이 때 문제가 되는 것은, 로봇 암의 가동 범위, 그리고 로봇 암과 작 물의 간섭 등이다. 이에 본 발명의 발명자들은 미리 지정된 위치에서 정지하여 하나 이상의 수확 대상 과실을 포함하는 씬(scene) 을 촬영하고 과실을 수확하되, 해당 위치에서 수확 장치와 과실의 손상을 야기하지 않으며 무리 없이 수확 작업 을 수행할 수 있고, 효율적이고 신속하게 수확 작업을 수행하는 방법을 제안하고자 한다. 즉, 본 발명이 해결하고자 하는 과제는 장치, 예컨대 로봇 암과 과실, 작물 등에 손상을 야기하지 않으며 신속 하고 효율적으로 수확 동작을 수행할 수 있는 수확 장치를 제공하는 것이다. 본 발명이 해결하고자 하는 다른 과제는 상기 수확 장치의 제어 방법 또는 과실 수확도(예컨대, 수확 가능도 또 는 수확 우선순위도)를 판별하는 방법을 제공하는 것이다. 본 발명이 해결하고자 하는 또 다른 과제는 상기 과실 수확도를 판별하는 방법을 포함하는 수확 방법을 제공하 는 것이다. 본 발명이 해결하고자 하는 또 다른 과제는 상기의 방법을 수행하는 기록매체에 기록된 컴퓨터로 판독 가능한 프로그램을 제공하는 것이다. 본 발명이 해결하고자 하는 또 다른 과제는 상기 수확 장치를 이용한 과실 수확 시스템을 제공하는 것이다. 본 발명의 과제들은 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0183246", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 해결하기 위한 본 발명의 일 실시예에 따른 수확 장치는 프로세서, 로봇 암, 로봇 암의 단부에 배 치된 엔드 이펙터, 및 로봇 암의 단부에 배치된 카메라 모듈을 포함하고, 수확 대상 작물의 이미지 정보를 수집 하고, 상기 이미지 정보에 포함된 하나 이상의 작물의 위치 정보, 상기 카메라 모듈의 위치 정보, 및 기준점의 위치 정보에 기초하여, 각 작물 별 수확 가능도를 정량화하도록 구성된다. 상기 이미지 정보에 포함된 하나 이상의 작물의 위치 정보, 상기 카메라 모듈의 위치 정보, 및 상기 기준점의 위치 정보에 기초하여, 각 작물 별 수확 가능도를 정량화하는 것은, 각 작물의 이미지 내 2차원 픽셀 좌표 정보(xp1,yp1)를 도출하고, 각 작물의 상기 기준점 기준 3차원 공간 좌표 정보(xb1,yb1,zb1)를 도출하고, 각 작물의 상 기 픽셀 좌표 정보와 공간 좌표 정보에 기초하여 정량화하는 것을 포함할 수 있다. 상기 기준점 기준 3차원 공간 좌표 정보를 도출하는 것은, 상기 2차원 픽셀 좌표 정보(xp1,yp1), 각 작물의 이미 지 내 이미지 깊이 정보(zd1), 및 상기 카메라 모듈의 상기 기준점 기준 3차원 공간 좌표 정보(xb2,yb2,zb2)에 기 초하여 도출될 수 있다. 또, 각 작물의 상기 픽셀 좌표 정보와 공간 좌표 정보에 기초하여 정량화하는 것은, 상기 각 작물에 대해, 상기 이미지의 2차원 픽셀 좌표(xp,yp)의 축 별 미리 지정된 확률 함수(f1, f2)에 대한 우도(likelihood)(P(xp1|f1), P(yp1|f2)) 기반 제1 스코어(S1) 및 제2 스코어(S2)를 도출하고, 상기 각 작물에 대해, 상기 기준점 기준 3차원 공간 좌표(xb,yb,zb)의 미리 지정된 확률 함수(f3)에 대한 우도(P(||xb1,yb1,zb1|||,f3)) 기반 제3 스코어(S3)를 도출하고, 상기 제1 스코어, 제2 스코어 및 제3 스코어에 기초하여 정량화하는 것을 포함할 수 있다. 상기 제1 스코어, 제2 스코어 및 제3 스코어에 기초하여 정량화하는 것은, 하기 수식을 통해 최종 스코어(S)로 정량화될 수 있다. S = αS1 × βS2 × γS3 × δ 여기서, α, β, γ는 각각 가중치로서 서로 동일하거나 상이한 임의의 양수이고, δ는 추가적인 고려 변수로서 1, 또는 임의의 양수, 또는 기도출된 변수에 대한 함수일 수 있다. 또 상기 이미지 정보의 수집은, 상기 카메라 모듈이 미리 지정된 상기 기준점 기준 3차원 공간 좌표(xb2,yb2,zb 2)에 위치한 상태에서 수행될 수 있다. 그리고 상기 작물 별 수확 가능도를 정량화하는 것은, 상기 카메라의 3차원 공간 좌표(xb2,yb2,zb2)에 기초하여 수행될 수 있다. 몇몇 실시예에서, 상기 작물 별 수확 가능도를 정량화하는 것은, 어느 작물에 대한 로봇 암의 조작도 (manipulability, m(θ))에 더 기초할 수 있다. 상기 과제를 해결하기 위한 본 발명의 다른 실시예에 따른 수확 장치는 수확 대상 작물의 RGB-D 이미지를 수집 하는 이미지 정보 수집부; 상기 수집된 이미지 정보에서, 상기 작물의 이미지 내 2차원 픽셀 좌표 정보(xp1,yp 1)를 도출하는 픽셀 좌표 생성부; 상기 수집된 이미지 정보에서, 상기 작물의 거리 정보(zd1)를 도출하는 깊이 정보 생성부; 적어도 상기 2차원 픽셀 좌표와 거리 정보에 기초하여, 상기 작물의 임의의 원점 기준 3차원 공간 좌표 정보(xb1,yb1,zb1)를 도출하는 공간 좌표 생성부; 상기 작물의 상기 x축 픽셀 좌표 정보(xp1)의 미리 지정된 확률 함수에 대한 우도 기반 제1 스코어를 생성하는 제1 스코어 생성부; 상기 작물의 상기 y축 픽셀 좌표 정보 (yp1)의 미리 지정된 확률 함수에 대한 우도 기반 제2 스코어를 생성하는 제2 스코어 생성부; 및 상기 작물의 상 기 3차원 공간 좌표 정보(xb1,yb1,zb1)의 미리 지정된 확률 함수에 대한 우도 기반 제3 스코어를 생성하는 제3 스 코어 생성부를 포함한다. 몇몇 실시예에서 상기 수확 장치는 상기 제1 스코어 내지 제3 스코어를 소정의 방법으로 연산하여 최종 스코어 를 생성하는 최종 스코어 생성부를 더 포함할 수 있다. 이 때 상기 소정의 방법은 상기 제1 스코어, 제2 스코어 및 제3 스코어 각각이 증가할 경우 최종 스코어가 더 커지도록 구성될 수 있다. 상기 다른 과제를 해결하기 위한 본 발명의 일 실시예에 따른 수확 대상 작물의 정량화 방법은 적어도 하나의 프로세서를 포함하는 컴퓨팅 장치에 의해 수행되는 방법으로, 수확 대상 작물의 이미지 정보를 수집하고, 상기 이미지 정보에 포함된 하나 이상의 작물의 위치 정보, 상기 카메라 모듈의 위치 정보, 및 기준점의 위치 정보에 기초하여, 각 작물 별 수확 가능도를 정량화하는 것을 포함한다. 상기 또 다른 과제를 해결하기 위한 본 발명의 일 실시예에 따른 기록 매체에 기록된 프로그램은 컴퓨팅 장치와 결합되어, 수확 대상 작물의 이미지 정보를 수집하고, 상기 이미지 정보에 포함된 하나 이상의 작물의 위치 정 보, 상기 카메라 모듈의 위치 정보, 및 기준점의 위치 정보에 기초하여, 각 작물 별 수확 가능도를 정량화하는동작을 수행하도록 구성된다. 상기 또 다른 과제를 해결하기 위한 본 발명의 일 실시예에 따른 수확 시스템은 미리 지정된 경로를 따라 이동 하는 본 발명의 어느 실시예에 따른 수확 장치를 포함한다. 이 때 상기 수확 장치는, 제1 단계에서, 상기 경로를 따라 이동하고, 어느 제1 위치에서 정지하여 작물의 이미 지 정보를 수집하고, 해당 이미지 내 작물의 수확 가능도를 정량화하고, 정량화된 스코어가 기준치 이상인 작물 을 수확하고, 제2 단계에서, 상기 경로를 따라 이동하고, 상기 제1 위치와 상이한 제2 위치에서 정지하여 작물 의 이미지 정보를 수집하고, 해당 이미지 내 작물의 수확 가능도를 정량화하고, 정량화된 스코어가 기준치 이상 인 작물을 수확하도록 구성될 수 있다. 또, 상기 제2 단계에서 수집된 이미지 정보에는, 상기 제1 단계에서 수집된 이미지 정보에 포함된 작물이 적어 도 하나 포함될 수 있다. 또는 상기 수확 장치는 상기 경로를 따라 이동하며 복수의 이미지 정보를 수집하고, 각 이미지 내 작물의 수확 가능도를 정량화하되, 어느 이미지 내에 기준치 이상의 정량화된 스코어를 갖는 작물이 존재할 경우, 정지하여 해당 작물을 수확하도록 구성될 수 있다. 기타 실시예의 구체적인 사항들은 상세한 설명에 포함되어 있다."}
{"patent_id": "10-2022-0183246", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들에 따르면, 적어도, 촬영된 이미지에서 과실 객체의 좌표, 그리고 로봇 암의 우효 작업 공간 을 가우시안 확률 분포에 기초해 정량화하여 수확 가능도를 정량화할 수 있다. 본 실시예에 따른 과실 수확 시스템은 어느 작업 단계에서, 지정된 위치에서 과실의 이미지 정보를 수집하고 정 량화된 수확 가능도에 기반하여 수확 작업을 수행한 후, 상기 단계에서 미수확된 과실은 다음 작업 단계에서 수 확하도록 구성하여 수확 장치 및 작물, 과실의 손상 없이 효율적이고 신속하게 수확 작업을 수행할 수 있다. 본 발명의 실시예들에 따른 효과는 이상에서 예시된 내용에 의해 제한되지 않으며, 더욱 다양한 효과들이 본 명 세서 내에 포함되어 있다."}
{"patent_id": "10-2022-0183246", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는 기 술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청 구항의 범주에 의해 정의될 뿐이다. 즉, 본 발명이 제시하는 실시예들에는 다양한 변경이 가해질 수 있다. 아 래 설명하는 실시예들은 실시 형태에 대해 한정하려는 것이 아니며, 이들에 대한 모든 변경, 균등물 내지 대체 물을 포함하는 것으로 이해되어야 한다.다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해 석되지 않는다. 본 명세서에서, '및/또는'은 언급된 아이템들의 각각 및 하나 이상의 모든 조합을 포함한다. 또, 단수형은 문구 에서 특별히 언급하지 않는 한 복수형도 포함한다. 본 명세서에서 사용되는 '포함한다(comprises)' 및/또는 '포 함하는(comprising)'은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. '내지'를 사용하여 나타낸 수치 범위는 그 앞과 뒤에 기재된 값을 각각 하한과 상한으로서 포함하는 수치 범위 를 나타낸다. '약' 또는 '대략'은 그 뒤에 기재된 값 또는 수치 범위의 20% 이내의 값 또는 수치 범위를 의미한 다. 본 명세서에서, 구성요소를 지칭함에 있어 '제1 구성요소', '제2 구성요소', '제1-1 구성요소' 등과 같이 서수 적 수식어는 어느 구성요소와 다른 구성요소를 구별하기 위해 사용되는 것일 뿐이다. 따라서 이하에서 지칭되는 제1 구성요소는 본 발명의 기술적 사상의 범위 내에서 제2 구성요소로 바꾸어 지칭될 수도 있다. 예를 들어, 어 느 실시예에서 제1 구성요소로 지칭되는 것은 다른 실시예에서 제2 구성요소로 지칭될 수 있다. 또, 발명의 설 명에서 제1 구성요소로 지칭되는 것은 청구항에서 제2 구성요소로 지칭될 수 있음은 물론이다. 이하 첨부된 도면을 참조하여 본 발명에 대하여 상세하게 설명한다. 도 1은 본 발명의 일 실시예에 따른 작물 수확 시스템을 나타낸 모식도이다. 도 2는 도 1의 수확 장치의 로봇 암의 단부를 나타낸 모식도이다. 도 3은 도 1의 수확 장치의 논리적 구성도이다. 우선 도 1 내지 도 3을 참조하면, 본 실시예에 따른 과실 등의 작물 수확 시스템은 작물(P)들 및 미리 지정 되거나 지정되지 않은 경로를 따라 주행하는 수확 장치를 포함할 수 있다. 작물(P)은 소정의 높이에 수확 대상, 예컨대 과실이 매달린 상태일 수 있다. 즉, 어느 하나의 나무에 하나 이상의 과실이 다양한 높이에 매달 릴 수 있다. 또, 작물(P)은 적어도 일렬로 배열되고, 작물(P)의 배열 방향으로 수확 장치가 이동하도록 구 성될 수 있다. 수확 장치는 주행 휠 등을 포함하는 주행부를 포함하고, 주행부 상에 배치된 유틸리티부를 포함할 수 있다. 또, 유틸리티부는 로봇 장치를 포함할 수 있다. 예를 들어, 상기 로봇 장치는 로봇 암, 로봇 암의 단 부에 결합된 엔드 이펙터 및 로봇 암의 단부에 결합된 카메라 모듈을 포함할 수 있다. 로봇 암은 다축 자유도(Degree Of Freedom, DOF)를 가질 수 있다. 로봇 암은 단부의 엔드 이펙터 가 공간 좌표, 예를 들어 가로, 세로, 높이 방향으로 다양한 좌표에 접근 가능하도록 구성될 수 있다. 엔드 이펙터는 수확 동작을 수행하는 구성을 의미할 수 있다. 엔드 이펙터는 로봇 암의 단부에 배치될 수 있다. 본 실시예에서, 엔드 이펙터는 작물(P)의 줄기 등을 절단할 수 있는 커터, 작물(P)의 과 실 등을 파지할 수 있는 그리퍼 등의 로봇 핸드를 포함할 수 있다. 카메라 모듈은 로봇 암의 단부에 배치되어 영상 이미지(IMG) 정보를 수집할 수 있다. 상기 이미지 정 보는 RGB-D 이미지일 수 있다. 카메라 모듈의 위치는 수확 장치의 수확 작업 방법을 결정하는 요인일 수 있다. 과실의 종류에 따라 어느 하나의 작물(P)에 열린 과실의 숙도가 전체적으로 대략 유사한 경우도 있지 만, 예를 들어 토마토 등의 경우 하나의 뿌리를 갖는 작물(P)에 열린 복수의 과실 개체들이 숙도 편차를 가질 수 있다. 이 경우 다관절을 갖는 로봇 암 단부에 배치된 카메라 모듈을 이용해 다양한 각도에서 이미 지 정보를 수집하고, 이에 기초하여 비젼 인식 또는 인공지능 기술을 통해 숙도를 판별할 수 있다. 본 실시예에 따른 수확 장치, 또는 로봇 장치는 프로세서 및 메모리를 포함하는 컴퓨팅 장치로 이해될 수 있다. 프로세서는 메모리에 상주된 본 발명에 따른 방법이 구현된 소프트웨어에 따른 명령어를 기초로 본 발명에 따른 방법과 관련된 동작 및/또는 기능을 구현할 수 있다. 예를 들어, 소프트웨어를 실행하여 프로세서와 연결된 하 드웨어적 구성요소 및/또는 소프트웨어적 구성요소를 제어할 수 있고, 데이터의 처리 또는 연산을 수행할 수 있 다. 즉, 프로세서는 데이터의 처리 또는 연산의 일부로서 다른 구성요소로부터 수신된 명령이나 데이터를 메모 리에 저장하거나, 메모리에 저장된 명령 또는 데이터를 처리하거나, 결과 데이터를 스토리지에 저장할 수 있다. 프로세서는 공지의 것을 이용할 수 있으나, 예를 들어 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable LogicDevices), FPGAs(Field Programmable Gate Arrays), 프로세서, 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세 서, 또는 인공지능을 위한 전용 하드웨어 칩셋 중 하나 이상에 의해 구현될 수 있다. 또, 프로세서는 중앙 처리 장치 등의 메인 프로세서 및 이와는 독립적으로 운영 가능한 보조 프로세서를 포함할 수 있다. 상기 보조 프로 세서의 예로는 그래픽 처리 장치, 신경망 처리 장치, 이미지 시그널 프로세서 등을 예시할 수 있다. 상기 소프트웨어는 본 발명에 따른 방법을 수행하기 위해 저장 매체에 저장된 컴퓨터로 판독 가능한 프로그램일 수 있다. 메모리는 적어도 하나의 구성요소에 사용되는 다양한 데이터를 저장할 수 있다. 상기 데이터는 소프트웨어 및 이와 관련된 명령에 대한 입력 데이터 또는 출력 데이터를 포함할 수 있다. 메모리에는 상기 방법이 구현된 소 프트웨어 또는 명령어가 상주(loading)될 수 있다. 메모리는 공지의 것을 이용할 수 있으나, 예를 들어 ROM(Read-Only Memory), RAM(Random Access Memory), 플래쉬 메모리, 메모리 카드, 저장 매체 및/또는 다른 저 장 장치를 통해 구현될 수 있다. 스토리지는 상기 방법이 구현된 소프트웨어의 실행을 위해 필요한 애플리케이션 프로그래밍 인터페이스(API), 라이브러리(library), 리소스 파일(resource file) 등을 저장할 수 있다. 또, 스토리지는 본 발명에 따른 방법 을 수행하기 위한 데이터베이스를 저장할 수도 있다. 후술할 방법 및 방법과 관련된 동작 및/또는 기능을 수행 하기 위해 요구되는 다양한 데이터베이스의 내용이 이해될 수 있을 것이다. 도면으로 표현하지 않았으나, 수확 장치는 다양한 센서 모듈, 통신 모듈, 입출력 인터페이스 등을 더 포함 할 수 있다. 상기 센서 모듈은 수확 장치와 관련된 다양한 물리량을 측정하거나 수확 장치의 작동 상태를 측정하고, 측정된 데이터를 전기 신호로 변환할 수 있다. 센서 모듈의 예로는 가속도 센서, 각속도 센서, 지자기 센서, 제 스처 센서, 근접 센서, 조도 센서, 컬러 센서, 마그네틱 센서, 기압 센서, 광 센서 중 하나 이상을 들 수 있다. 상기 예시된 센서가 측정하는 대상 물리량 및 그 측정 방식은 공지의 것을 이용할 수 있다. 또는 상기 예시된 센서들은 복수개가 조합되어 구성될 수도 있다. 상기 통신 모듈은 유무선 통신 모듈을 포함할 수 있다. 통신 모듈은 수확 장치와 외부의 다른 전자 장치, 예컨 대 서버와의 유무선 통신 채널의 수립과 수립된 통신 채널을 통한 통신의 수행을 지원할 수 있다. 무선 통신 모 듈의 예로는 와이파이 모듈, 또는 블루투스나 NFC 등의 근거리 통신 모듈, GNSS 모듈, 코드 분할 다중 접속 (Code Division Multiple Access, CDMA), 와이드 밴드 코드 분할 다중 접속 (Wideband CDMA, WCDMA), 고속 패 킷 접속(High Speed Packet Access, HSPA), 롱텀 에볼루션(Long Term Evolution, LTE) 등과 같은 네트워크 인 터페이스를 포함할 수 있다. 입출력 인터페이스는 관리자가 수확 장치의 제어에 필요한 명령을 입력하거나, 수확 장치로부터 정보를 전달받기 위한 키보드, 마우스, 터치 패널, 조이스틱, 마이크, 디스플레이, 스피커 등을 포함할 수 있다. 전술한 다양한 하드웨어적 구성요소들은 데이터 버스를 통해 연결되고, 데이터 버스를 통해 각 구성요소들 사이 에 데이터를 전달할 수 있다. 또, 전술한 것과 같이 프로세서를 포함하여 본 발명에 따른 방법이 구현된 소프트 웨어에 따른 명령어를 기초로 상기 방법과 관련된 동작 및/또는 기능을 구현하는 수확 장치는 기능적 요소 내지는 논리적 요소 측면에서 설명될 수도 있다. 예시적인 실시예에서, 수확 장치는 자세 제어부(L100), 이미지 수집부(L200), 픽셀 좌표 생성부(L310), 깊 이 정보 생성부(L320), 공간 좌표 생성부(L400), 조작도 정보 생성부(L450), 제1 스코어 생성부(L510), 제2 스 코어 생성부(L520), 제3 스코어 생성부(L530), 제4 스코어 생성부(L540), 최종 스코어 생성부(L550)를 포함하고, 주행 제어부(L600), 스코어 판별부(L700) 및 엔드 이펙터 제어부(L800)를 더 포함할 수 있다. 다만, 본 발명이 이에 제한되는 것은 아니며, 전술한 하드웨어 및 후술할 방법을 구현하기 위한 다양한 논리적 구성에 대한 개시가 본 명세서에 포함되어 있다. 또, 도 3에 도시된 다양한 구성요소들은 다양한 수단, 예를 들어 하드웨어, 펌웨어(firmware), 소프트웨어 또는 그것들의 결합 등에 의해 구현될 수 있다. 즉, 또, 도 3의 '~부'는 프로세서 또는 회로와 같은 하드웨어적 구성 및/또는 하드웨어적 구성에 의해 실행되는 소프트웨어적 구성을 포함하는 의미로 사용될 수 있다. 구체적으로, '~부'로 지칭되는 구성요소의 하드웨어에 의한 구현의 경우, 전술한 프로세서를 통해 구현될 수 있 다. 또는 펌웨어나 소프트웨어에 의한 구현의 경우, 설명된 기능 또는 동작들을 수행하는 인스트럭션을 포함하 는 모듈, 코드들, 코드 세그먼트들, 절차, 함수 등의 형태로 구현되어, 다양한 컴퓨터 수단을 통하여 판독 가능한 기록매체에 기록될 수 있다. 여기서, 기록매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 이 경우 구성도 또는 블록도 상의 각 구성요소는 특정된 논리 기능을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 의미할 수 있다. 따라서 구성도 또는 블록도 상의 구성요소가 제공하는 기능은 더 세분화된 복수의 구성요소에 의해 구현되거나, 또는 구성도 또는 블록도 상의 복수의 구성요소들은 일체화된 하나의 구성요소에 의하여 구현될 수도 있음은 물 론이다. 즉, 본 발명의 목적 범위 내에서 각 구성요소들이 하나 이상으로 선택적으로 결합하여 동작할 수 있다. 또, 모든 구성요소들이 각각 하나의 독립된 하드웨어로 구현될 수 있고, 각 구성요소들의 그 일부 또는 전부가 선택적으로 조합되어 하나 또는 복수개의 하드웨어에서 조합된 일부 또는 전부의 기능을 수행하는 프로그램 모 듈을 갖는 컴퓨터 프로그램으로서 구현될 수도 있다. 그 컴퓨터 프로그램을 구성하는 코드들 및 코드 세그먼트"}
{"patent_id": "10-2022-0183246", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "들은 본 발명의 기술분야에 속하는 통상의 기술자에게 용이하게 추론될 수 있을 것이다. 기록매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 예컨대 기록매체는 하드 디스크, 플로피 디스크 및 자기 테 이프와 같은 자기 매체(Magnetic Media), CD-ROM(Compact Disk Read Only Memory), DVD(Digital Video Disk) 와 같은 광 기록 매체(Optical Media), 플롭티컬 디스크(Floptical Disk)와 같은 자기-광 매체(Magneto- Optical Media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치를 포함한다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드 뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 이 러한, 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어로서 작동하도록 구성될 수 있 으며, 그 역도 마찬가지이다. 이하, 본 발명의 실시예에 따른 수확 대상 작물의 수확 가능도를 정량화하는 방법 내지는 수확 장치의 제어 방 법에 대해 설명한다. 도 4는 본 발명의 일 실시예에 따른 수확 방법을 나타낸 순서도이다. 도 4를 더 참조하면, 본 실시예에 따른 작물의 수확 가능도 정량화 방법(S10)은 초기 자세를 제어하는 단계 (S100), 작물 이미지 정보를 수집하는 단계(S200), 작물 이미지 내 2차원 픽셀 좌표(xp1,yp1)를 도출하는 단계 (S310), 이에 기초하여 제1 스코어와 제2 스코어를 도출하는 단계(S510, S520), 작물의 이미지 깊이 정보(zd1) 를 도출하는 단계(S320), 작물의 3차원 공간 좌표(xb1,yb1,zb1)를 도출하는 단계(S400), 이에 기초하여 제3 스코 어와 제4 스코어를 도출하는 단계(S530, S540), 도출된 제1 스코어 내지 제4 스코어 중 적어도 일부에 기초하여 최종 스코어를 도출하는 단계(S550)를 포함할 수 있다. 앞서 설명한 것과 같이 수확 장치는 로봇 암, 엔드 이펙터 및 카메라 모듈을 포함하는 로봇 장치를 포함하며 주행 휠 등에 의해 이동할 수 있다. 이 때 로봇 암은 베이스를 통해 수확 장치 에 고정된 상태일 수 있다. 다시 말해서, 수확 장치의 이동을 야기하는 주행 휠 등의 주행부를 기준으로, 로봇 암의 각 관절, 엔드 이펙터 및 카메라 모듈의 위치는 변화할 수 있으나, 베이스의 위 치는 변화하지 않을 수 있다. 또는 베이스는 수확 장치 내에서 위치가 변화하지 않는 임의의 기준점을 지칭할 수도 있다. 이 경우 자세 제어부(L100)는 미리 지정된 초기 자세로 로봇 암의 각 관절과 링크를 조절할 수 있다 (S100). 예를 들어, 로봇 암의 베이스와 엔드 이펙터, 또는 베이스와 카메라 모듈 간의 상대 적인 위치가 미리 설정된 위치에 있도록 할 수 있다. 즉, 후술할 이미지 정보의 수집 단계(S200) 전에, 대략 로 봇 암의 베이스를 원점으로 할 때 엔드 이펙터 및/또는 카메라 모듈의 공간 좌표가 미리 설정된 좌표에 있도록 할 수 있다. 관련하여 도 5 및 도 6을 더 참조한다. 도 5는 Y축과 Z축이 속하는 평면을 바라본 방향에서의 도면이다. 도 6은 X축과 Z축이 속하는 평면을 바라본 방 향에서의 도면이다. 본 명세서에서, X축은 카메라 모듈이 촬영한 2차원 이미지에서의 가로 방향을 의미하고, Y 축은 카메라 모듈이 촬영한 2차원 이미지에서의 세로 방향을 의미한다. 또, Z축은 카메라 모듈이 촬영한 이미지 에서 작물의 거리, 즉 이미지의 깊이 방향을 의미한다. 도 5 및 도 6은 베이스의 위치를 원점으로 할 때, 즉 베이스를 기준으로 카메라 모듈의 3차원 공간 좌표가 (xb2,yb2,zb2)에서 초기 자세가 제어된 경우를 나타낸다. 본 명세서에서, (xb,yb,zb)는 베이스(base) 기준 3차원 공간 좌표계를 의미한다. 또, 첨자 2는 카메라 모듈을 지칭한다. 도면에 표현된 것과 같이, 위치가 고정된 베이스에 로봇 암이 결합됨에 따라, 로봇 암은 소정의 가동 범위(L1~L2) 내지는 작업 공간(work space)을 가질 수 있다. 작업 공간의 형상은 베이스를 중심으로 하는 대략 반구 형상일 수 있다. 그리고 이미지 수집부(L200)는 상기 초기 자세를 유지한 상태에서, 카메라 모듈을 이용해 작물의 영상 또 는 이미지 정보를 수집할 수 있다(S200). 이미지 정보의 수집은 수확 장치가 정지한 상태에서, 또는 이동 중에 수행될 수 있다. 예시적인 실시예에서, 이미지 수집부(L200)가 수집하는 이미지 정보는 RGB-D 이미지 정보를 포함할 수 있다. 또, 이미지 정보의 수집 단계(S200)는 이미지의 인스턴스 분할(instance segmentation)을 통해 개별 작물, 구체 적으로 하나의 줄기에 매달린 과실 객체 각각을 감지하는 것을 포함할 수 있다. 인스턴스 분할은 Mask R-CNN 등 의 인공지능 알고리즘을 사용하여 수행될 수 있다. 그리고 픽셀 좌표 생성부(L310)는 수집된 2차원 이미지에 포함된 각 과실, 즉 인스턴스 분할로 인식된 개별 과 실들의 2차원 픽셀 좌표(xp1,yp1)를 도출할 수 있다(S310). 관련하여 도 7을 더 참조한다. 도 7은 수집된 RGB-D 이미지를 나타낸 도면이다. 전술한 바와 같이 도 7에 예시된 이미지에서 가로 방향이 X축 방향이고 세로 방향이 Y축 방향일 수 있다. 또, 도 7은 하나의 영상 이미지에 포함된 복수의 과실 중에, 임의의 제1 객체(P1)와 제2 객체(P2)의 픽셀 좌표를 도출한 경우를 예시한다. 제1 객체(P1)는 (xp1a,yp1a)의 픽셀 좌표를 가지고, 제2 객체(P2)는 (xp1b,yp1b)의 픽셀 좌표를 가질 수 있다. 본 명세서에서, (xp,yp)는 이미지 내 2차원 픽 셀 좌표계를 의미한다. 또, 첨자 1은 과실을 지칭하고, 구체적으로 1a는 제1 객체(P1), 1b는 제2 객체(P2)를 지 칭한다. 예시적인 실시예에서, 제1 스코어 생성부(L510)는 어느 객체에 대해 도출된 X축 픽셀 좌표 정보(xp1)를 이용해 미리 지정된 제1 확률 함수(f1)에 대한 우도(likelihood) 기반 제1 스코어(S1)를 도출하고(S510), 제2 스코어 생성부(L520)는 상기 어느 객체에 대해 도출된 Y축 픽셀 좌표 정보(yp1)를 이용해 미리 지정된 제2 확률 함수 (f2)에 대한 우도 기반 제2 스코어를 도출할 수 있다(S520). 제1 확률 함수(f1) 및 제2 확률 함수(f2)는 각각 2차원 이미지 내 직교 좌표계에서 가우시안 분포를 나타내는 확률 분포 곡선일 수 있다. 즉, 제1 확률 함수(f1) 및 제2 확률 함수(f2)는 각각 하나의 봉우리를 가지며 우도 를 계산하기 위한 확률 밀도 함수(Probability Density Funcion, PDF)일 수 있다. 본 명세서에서, 용어 확률 함수, 확률 밀도 함수, 또는 우도 함수는 혼용될 수 있다. 도 7에 표현된 것과 같이, 제1 확률 함수(f1)는 2차원 이미지의 X축, 즉 가로 방향 길이값에 대한 분포 곡선일 수 있다. 비제한적인 예시로, 제1 확률 함수(f1)는 이미지의 가로 방향 정중앙에서 가장 높은 우도를 가질 수 있다. 또, 정중앙에서 멀어질수록 우도는 연속적 또는 불연속적으로 단조 감소할 수 있다. 마찬가지로 제2 확률 함수(f2)는 2차원 이미지의 Y축, 즉 세로 방향 길이값에 대한 분포 곡선일 수 있다. 비제한적인 예시로, 제2 확 률 함수(f2)는 이미지의 세로 방향 정중앙에서 가장 높은 우도를 가질 수 있다. 또, 정중앙에서 멀어질수록 우 도는 연속적 또는 불연속적으로 단조 감소할 수 있다. 이 때 제1 스코어(S1)는 X축에 대한 제1 우도(P(xp1|f1))에 기반하여 도출될 수 있다. 예를 들어, 제1 스코어 (S1)는 제1 우도 값과 동일하거나, 또는 비례할 수 있다. 마찬가지로, 제2 스코어(S2)는 Y축에 대한 제2 우도 (P(yp1|f2))에 기반하여 도출될 수 있다. 예를 들어, 제2 스코어(S2)는 제2 우도 값과 동일하거나, 또는 비례할 수 있다. 본 실시예에 따를 경우, 수확 장치의 카메라 모듈을 이용해 수집된 이미지 정보 내 작물 객체 별 픽셀 좌표(xp1,yp1)의 우도들을 도출하고 이에 기반하여 제1 스코어(S1)와 제2 스코어(S2)를 도출할 수 있다. 그리고 후술할 바와 같이, 적어도 제1 스코어(S1)와 제2 스코어(S2)가 반영된 최종 스코어(S)를 산출할 수 있다. 여기 서 제1 스코어(S1) 및/또는 제2 스코어(S2)가 높은 것, 나아가 최종 스코어(S)가 높은 것은 수집된 영상 이미지 를 기준으로 과실이 정중앙에 가까이 위치하는 것을 의미하며, 다시 말해서 스코어가 높은 것은 하나의 영상 이 미지 내에 포함된 다수의 작물 객체들 중에 상대적으로 수확이 쉬운 객체를 의미할 수 있다. 따라서 작물에 복 수개의 과실이 매달린 경우 수확이 상대적으로 용이한 것을 우선적으로 판별하고 우선적인 수확을 수행할 수 있어 효율적이고 신속한 수확 작업을 수행할 수 있다. 또, 본 발명의 발명자들은 각 과실의 이미지 내 픽셀 좌표(xp1,yp1)에만 기초하지 않고, 각 과실의 3차원 공간 좌표(xb1,yb1,zb1) 정보에 더 기초할 경우 수확 장치 및 과실에 손상을 야기하지 않을 수 있음에 착안하여 본 발명을 완성하기에 이르렀다. 이하 이에 대해 설명한다. 예를 들어 도 8에 도시된 것과 같이, 카메라 모듈이 촬영한 2차원 이미지에서, 제1 객체(P1)(즉, 과실)와 제2 객체(P2)는 실질적으로 가로 방향(즉, X축 방향)으로 대칭적 위치에 존재할 수 있다. 또, 도면으로 표현하 지 않았으나 제1 객체(P1)와 제2 객체(P2)는 실질적으로 세로 방향(즉, Y축 방향) 높이가 같을 수 있다. 이 경 우 제1 객체(P1)와 제2 객체(P2)에 대한 제1 우도와 제2 우도는 동일하거나, 극히 유사하고 이로부터 도출된 제 1 스코어(S1)와 제2 스코어(S2) 또한 동일할 수 있다. 그러나 제1 객체(P1)는 로봇 암의 가동 범위(L1~L 2)를 벗어나는 공간에 위치하여 수확 작업이 불가능할 수 있다. 심지어 제1 객체(P1)의 Y축 방향에 대한 제2 우 도가 제2 객체(P2)의 제2 우도 보다 높아 제1 객체(P1)의 최종 스코어가 제2 객체(P2)의 최종 스코어 보다 높은 경우에도 제1 객체(P1)의 수확 작업은 곤란할 수 있다. 다른 예를 들어 도 9에 도시된 것과 같이, 카메라 모듈이 촬영한 이미지에서, 제1 객체(P1)는 가로 방향과 세로 방향의 실질적으로 정중앙에 위치하여 달성 가능한 가장 높은 스코어가 도출되는 경우에도 제1 객체(P1)는 로봇 암의 가동 범위(L1~L2)를 벗어나는 공간에 위치하여 수확 작업이 불가능할 수 있다. 이와 같은 문제는 카메라 모듈이 로봇 암의 단부에 배치된 경우, 비제한적인 예시로 숙도 판별의 정 밀도를 높이기 위해 카메라 모듈을 로봇 암의 단부에 배치한 경우에 특유하게 발생하는 문제일 수 있 다. 이를 해결하기 위해 본 발명의 발명자들은 각 과실의 3차원 공간 좌표(xb1,yb1,zb1)를 활용하는 방법을 제안한다. 이하, 축의 방향으로 인한 혼동을 피하기 위해 이미지 내 픽셀 좌표의 X-Y축 방향과 공간 좌표의 X-Y 축 방향을 동일하게 설명하나, 픽셀 좌표계의 X축 좌표값 및 Y축 좌표값은 공간 좌표의 X축 좌표값 및 Y축 좌표값과 상이 할 수 있은 자명하다. 즉, 어느 과실에 대한 픽셀 좌표 (xp1) 및 (yp1)은 각각 공간 좌표 (xb1) 및 (yb1)과 상이할 수 있다. 즉, 깊이 정보 생성부(L320)는 수집된 이미지에서 인식된 각 과실, 즉 인스턴스 분할로 인식된 개별 과실들의 깊이 정보(zd1)를 도출할 수 있다(S320). 깊이 정보(zd1)는 카메라 모듈의 위치로부터 과실까지의 Z축 방향 거리 정보가 내포된 위치 정보일 수 있다. 깊이 정보(zd1)의 도출은 공지의 방법을 사용할 수 있다. 그리고 3차원 공간 좌표 생성부(L400)는 앞서 설정된 로봇 암의 초기 자세에 따른 카메라 모듈의 공 간 좌표(xb2,yb2,zb2) 정보, 이미지 내 포함된 각 과실의 2차원 픽셀 좌표(xp1,yp1) 정보, 및/또는 이미지 내 포함 된 각 과실의 깊이 정보(zd1)에 기초하여 각 작물의 베이스 기준 3차원 공간 좌표 정보(xb1,yb1,zb1)를 도출 할 수 있다(S400). 예시적인 실시예에서, 제3 스코어 생성부(L530)는 어느 객체에 대해 도출된 3차원 공간 좌표 정보(xb1,yb1,zb1)를 이용해 미리 지정된 제3 확률 함수(f3)에 대한 우도 기반 제3 스코어(S3)를 도출할 수 있다(S530). 제3 확률 함수(f3)는 3차원 공간 내에서 원통 좌표계의 R축(거리 축)과 Z축(높이 축, 즉 본 명세서의 Y축)이 속 하는 면 내에서 가우시안 분포를 나타내는 확률 분포 곡선일 수 있다. 즉, 도 5 및 도 6에 표현된 것과 같이, 제3 확률 함수(f3)는 원점(O)으로 정의된 베이스로부터의 거리 값 에 대한 분포 곡선일 수 있다. 비제한적인 예시로, 제3 확률 함수(f3)는 베이스와 가동 한계 범위(L1~ L2) 사이의 어느 위치(Lmax)에서 가장 높은 우도를 가질 수 있다. 또, 최대 우도를 갖는 위치(Lmax)에서 베이스 방향 또는 그 반대 방향으로 갈수록 우도는 연속적 또는 불연속적으로 단조 감소할 수 있다. 예를 들어 최대 우 도를 갖는 위치(Lmax)에서 베이스 방향의 어느 위치(Lmid1)에서 최대 우도 보다 작은 소정의 우도가 정의되고, 최대 우도를 갖는 위치(Lmax)에서 베이스로부터 멀어지는 방향의 어느 위치(Lmid2)에서 상기 소정 의 우도가 정의될 수 있다. 또한 비제한적인 예시로서, 로봇 암의 관절 요소로 인해, 베이스와 가까운 어느 위치(L1)에서 우도는 불연속적으로 감소하여 0이 되는 것으로 정의되고, 로봇 암이 수평 방향으로 완전히 뻗어졌을 때의 위치 (L2)에서 우도가 0이 되는 것으로 정의될 수 있으나, 본 발명이 이에 제한되는 것은 아니다. 이 때 제3 스코어(S3)는 3차원 공간 좌표(xb1,yb1,zb1)에 대한 제3 우도(P(||xb1,yb1,zb1|||,f3))에 기반하여 도출 될 수 있다. 예를 들어, 제3 스코어(S3)는 제3 우도 값과 동일하거나, 또는 비례할 수 있다. 본 실시예에 따를 경우, 수확 장치의 카메라 모듈을 이용해 수집된 이미지 정보 내 작물 객체 별 3차 원 공간 좌표(xb1,yb1,zb1)의 우도를 도출하고 이에 기반하여 제3 스코어(S3)를 더 도출할 수 있다. 그리고 전술 한 제1 스코어(S1)와 제2 스코어(S2), 및/또는 제3 스코어(S3)가 반영된 최종 스코어(S)를 산출할 수 있다. 비 제한적인 예시로, 적어도 제1 스코어(S1)와 제3 스코어(S3), 또는 제2 스코어(S2)와 제3 스코어(S3), 바람직하 게는 제1 스코어(S1) 내지 제3 스코어(S3)를 이용해 최종 스코어(S)를 산출할 수 있다. 여기서 제3 스코어(S3) 가 높은 것은 사용하는 로봇 암의 접근이 용이할 확률이 높은 공간에 과실이 가까이 위치하는 것을 의미하 며, 다시 말해서 최종 스코어(S)가 높은 것은 하나의 영상 이미지 내에 포함된 다수의 작물 객체들 중에 상대적 으로 수확이 쉬운 객체를 의미할 수 있다. 관련하여 도 8을 다시 참조하면, 설령 제1 객체(P1)가 제2 객체(P2)와 동일한 제1 우도(또는 제1 스코어(S1)) 및 제2 우도(또는 제2 스코어(S2))를 갖거나, 또는 Y축 높이에 의해 제1 객체(P1)가 제2 객체(P2)에 비해 더 큰 제2 우도를 갖는 경우에도, 3차원 공간 좌표 정보(xb1,yb1,zb1)가 반영된 제3 우도(또는 제3 스코어(S3))를 이용 해 이를 보정하여 제2 객체(P2)가 제1 객체(P1)에 비해 더 수확 가능도가 높은 과실로 판별하도록 할 수 있다. 또, 도 9를 다시 참조하면, 설령 제1 객체(P1)가 제2 객체(P2)에 비해 월등히 높은 제1 우도(또는 제1 스코어 (S1))를 갖는 경우에도, 3차원 공간 좌표 정보(xb1,yb1,zb1)가 반영된 제3 우도(또는 제3 스코어(S3))를 이용해 이를 보정하여 제2 객체(P2)가 제1 객체(P1)에 비해 더 수확 가능도가 높은 과실로 판별하도록 할 수 있다. 몇몇 실시예에서, 조작도 정보 생성부(L450)는 개별 과실에 대한 조작도(manipulability, m(θ))를 도출하고, 제4 스코어 생성부(L540)는 어느 객체에 대해 도출된 조작도(m(θ)) 정보를 이용해 제4 스코어(S4)를 도출할 수 있다(S540). 조작도 및 제4 스코어(S4)는 큰 것이 바람직할 수 있다. 예를 들어, 제4 스코어(S4)는 조작도(m(θ))와 동일하거나, 또는 비례할 수 있다. 조작도(m(θ))는 다관절 로봇 암의 특이점(singularity)이 발생하지 않을 확률이 높은 자세를 설명하기 위 한 개념이다. 특이점은 로봇 암의 각 관절의 축 방향이 일치하도록 배열하는 등의 경우에 발생하여 다수의 축 중 적어도 일부의 자유도를 잃게되는 것을 설명하는 개념이다. 본 실시예에서 조작도(m(θ))는 인식된 과실 객체가 매달린 상태에 기초하여 도출될 수 있다. 예를 들어, 어느 과실, 예컨대 토마토의 꼭지가 작물 줄기와 연결되어 있는 경우, 토마토의 꼭지 방향, 즉 연결된 작물 줄기 방 향을 (zm)으로 하고 그에 수직한 직교 좌표를 (xm,ym)으로 할 때, 다시 말해서 과실의 수확을 위해 작업의 대상 이 되는 꼭지의 방향을 고려한 직교 좌표(xm,ym,zm)에서 로봇 암의 접근성을 내포하는 정보일 수 있다. 조 작도(m(θ))의 도출 방법은 공지의 것을 이용할 수 있다. 그리고 최종 스코어 생성부(L550)는 앞서 도출된 제1 스코어(S1) 내지 제4 스코어(S4) 중 하나 이상, 또는 2개 이상에 기초하여 최종 스코어를 도출하여 정량화할 수 있다(S550). 예를 들어, 최종 스코어(S)는 제1 스코어 (S1) 내지 제4 스코어(S4) 중 하나 이상의 함수일 수 있다. 비제한적인 예를 들어, 최종 스코어(S)는 하기 수식을 통해 정량화될 수 있다. S = αS1 × βS2 × γS3 × δ 여기서 α, β, γ는 각각 가중치로서 서로 동일하거나 상이한 임의의 양수일 수 있다. 예를 들어 α, β, γ는 각각 1일 수 있다. 또, δ는 추가적인 고려 변수로서 1, 또는 임의의 양수, 또는 기도출된 변수에 대한 함수일 수 있다. 다른 비제한적인 예를 들어, 최종 스코어(S)는 하기 수식을 통해 정량화될 수 있다. S = αS1 × βS2 × γS3 × δ1S4 × δ2 여기서 α, β, γ, δ1은 각각 가중치로서 서로 동일하거나 상이한 임의의 양수일 수 있다. 예를 들어 α, β, γ, δ1은 각각 1일 수 있다. 또, δ2는 추가적인 고려 변수로서 1, 또는 임의의 양수, 또는 기도출된 변수에대한 함수일 수 있다. 또, 본 실시예에 따른 제1 스코어(S1) 내지 제4 스코어(S4), 그리고 최종 스코어(S)는 모두 양수일 수 있다. 상 기 수식들에 의할 경우, 제1 스코어(S1) 내지 제4 스코어(S4) 각각 중 어느 하나가 증가할 경우 최종 스코어 (S)가 커질 수 있다. 예를 들어, 어느 제1 객체(P1)와 다른 제2 객체(P2)의 제2 스코어(S2) 내지 제4 스코어 (S4)가 동일한 경우에도, 제2 객체(P2)의 제1 스코어(S1)가 제1 객체(P1)의 제1 스코어(S1) 보다 클 경우 제2 객체(P2)의 최종 스코어가 제1 객체(P1)의 최종 스코어 보다 클 수 있다. 본 실시예에 따른 작물 또는 그 과실에 대한 수확 가능도의 판별 방법은 카메라 모듈을 통해 수집된 이미 지 정보의 픽셀 좌표(xp1,yp1) 뿐 아니라 3차원 공간 좌표(xb1,yb1,zb1) 정보를 도출하고 이를 이용해 로봇 암 의 가동이 용이할 확률이 높은 위치에 존재하는 과실의 스코어를 높게 부여하고, 우선적으로 수확하도록 구성할 수 있다. 따라서 상당수의 과실이 매달려 있는 경우에도 이들을 개별적으로 모두 인식하고 수확을 위한 동작을 수행하는 것이 아니라, 수확 작업을 수행할 객체를 선별하거나, 또는 수확 작업을 위한 후보 객체를 선 별할 수 있어 데이터 처리양을 감소시키고 신속한 작업이 이루어지게 할 수 있다. 이하, 전술한 수확 가능도의 판별 방법을 포함하거나 이용한 작물의 수확 방법 및 그 시스템에 대해 설명한다. 도 10 및 도 11은 본 발명의 일 실시예에 따른 수확 방법 및 그 시스템을 설명하기 위한 도면들로서, 도 10은 본 실시예에 따른 수확 방법을 설명하기 위한 순서도이고, 도 11은 도 10의 방법에 따라 수확 장치가 정지하는 위치를 나타낸 도면이다. 도 10 및 도 11을 더 참조하면, 본 실시예에 따른 수확 방법 또는 수확 장치의 제어 방법은 수확 장치를 미리 지정된 위치로 이동 및 정지시키는 단계(S610), 정지된 상태에서, 도 4와 함께 설명한 방법에 따라 수확 대상 작물 객체 별 수확 가능도를 정량화하는 단계(S10), 최종 스코어와 기준 스코어를 비교하는 단계(S700) 및 엔드 이펙터를 이용해 수확하는 단계(S800)를 포함할 수 있다. 수확 장치의 주행은 주행 제어부(L600)에 의해 수행될 수 있다. 주행 제어부(L600)는 작물의 배열 방향, 즉 X축 방향을 따라 수확 장치를 이동시킬 수 있다. 예시적인 실시예에서, 어느 작업 단계, 예컨대 처음 수행되는 제1 작업 단계(즉, 페이즈 1)에서 주행 제어부 (L600)는 수확 장치가 제1 단계 제1 위치(A1)로 이동 후 정지하도록 할 수 있다(S610). 그리고 제1 단계 제1 위치(A1)에서 전술한 바와 같이 이미지 정보를 수집하고, 소정의 과정을 거쳐 이미지 내에 포함된 각 작물들의 최종 스코어(S)를 도출할 수 있다(S10). 그리고 스코어 판별부(L700)는 각 작물들의 최종 스코어(S)를 각각 기준 스코어와 비교할 수 있다(S700). 만일 하나 이상의 작물의 최종 스코어(S)가 기준 스코어 보다 크거나, 또는 초과일 경우 로봇 암의 관절과 링크 를 제어해 해당 작물에 엔드 이펙터를 근접시키고, 엔드 이펙터 제어부(L800)는 엔드 이펙터, 예컨대 커터와 그리퍼를 이용해 해당 작물을 수확할 수 있다(S800). 반면, 제1 단계 제1 위치(A1)에서 수집한 이미지 정보 내에 기준 스코어 보다 크거나 같은, 즉 수확 가능도가 충분한 정도로 높은 작물이 존재하지 않은 경우, 주행 제어부(L600)는 수확 장치를 제1 단계 제2 위치(A2) 로 이동 후 정지시킨다(S610). 그리고 전술한 과정을 반복하여 X축 방향으로 일렬로 배열된 복수의 작물들에 대 해 신속하고 효율적으로 수확을 수행할 수 있다. 상기 제1 작업 단계를 통해 일렬로 배열된 복수의 작물들 중 소정의 기준을 만족하는 작물들을 수확한 후, 수확 장치는 제2 작업 단계(즉, 페이즈 2)를 수행할 수 있다. 제2 작업 단계에서 주행 제어부(L600)는 수확 장치가 제2 단계 제1 위치(B1)로 이동 후 정지하도록 할 수 있다(S610). 여기서 제2 단계 제1 위치(B1)는 제1 단계에서 정지하였던 위치들과 적어도 부분적으로 상이한 위 치일 수 있다. 다시 말해서, 제2 단계 제1 위치(B1)는 제1 단계 제1 위치(A1) 및 제1 단계 제2 위치(A2)와 상이 할 수 있다. 그리고 이미지 정보를 수집하고, 이미지 내에 포함된 각 작물들의 최종 스코어를 도출하고(S10), 최종 스코어를 기준 스코어와 비교하여(S700), 기준 스코어를 만족하는 작물에 대해서는 수확 동작을 수행하고(S800), 기준 스 코어를 만족하는 작물이 존재하지 않을 경우 제2 단계 제2 위치(B2)로 이동하여(S610) 동일 작업을 반복할 수 있다. 앞서 설명한 것과 같이 본 실시예에 따른 수확 장치는 정지된 상태에서 촬영한 이미지 내의 복수의 작물들 에 대해 최종 스코어(S)를 산출하여 수확 우선순위를 부여할 수 있다. 이 때 최종 스코어(S)에 영향을 미치는 요인으로, 이미지를 수집하는 수확 장치 또는 그 카메라 모듈을 기준으로 한 픽셀 좌표 정보(xp1,yp1) 와 3차원 공간 좌표 정보(xb1,yb1,zb1)를 설명하였다. 또, 픽셀 좌표 정보(xp1,yp1)와 3차원 공간 좌표 정보 (xb1,yb1,zb1)에는 수확 장치, 그리고 초기 자세에서의 카메라 모듈의 X축 위치에 관한 정보가 내포되어 있다. 따라서 어느 위치(또는 스팟), 예컨대 제1 단계 제1 위치(A1)에서 낮은 최종 스코어를 갖는 작물이라 하더라도, 제2 단계 제1 위치(B1)에서는 기준 스코어를 만족할 수 있다. 이에 본 실시예에 따른 수확 방법은 제1 작업 단 계, 제2 작업 단계를 나누어 수행하되, 연속되는 각 작업 단계 별로 수확 장치가 적어도 부분적으로 상이한 X축 방향 위치에서 정지 후 수확 가능도를 정량화하도록 구성하여 신속하고 효율적인 작업을 수행할 수 있다. 또, 제1 작업 단계에서 이미 촬영되었으나 수확 가능도가 낮은 것으로 판단된 과실, 다시 말해서 수확 장치의 해당 위치에서는 수확이 용이하지 않을 가능성이 높은 것으로 판단된 과실은 무리해서 수확하기 보다 남겨두고, 제2 작업 단계에서 해당 과실을 다시 촬영하여 해당 위치에서 수확이 가능할 것으로 판단되는 경우 비로소 수확 할 수 있다. 도 12는 본 발명의 다른 실시예에 따른 수확 방법을 설명하기 위한 순서도이다. 도 12를 참조하면, 본 실시예에 따른 수확 방법은 미리 지정된 위치(또는 스팟)에 정지하여 이미지 정보를 수집 하는 것이 아니라, 미리 지정된 경로를 따라 주행하며 연속적으로 이미지 정보를 수집하고, 기준 스코어를 만족 하는 작물이 인식될 경우 정지하는 점이 도 10의 실시예에 따른 수확 방법과 상이한 점이다. 즉, 주행 제어부(L600)는 작물의 배열 방향과 같은 미리 지정된 경로를 따라 수확 장치를 이동시키고 (S620), 이동 중에 미리 지정된 프레임 마다 이미지 정보를 수집하며 소정의 과정을 거쳐 이미지 내에 포함된 각 작물들의 최종 스코어(S)를 도출할 수 있다(S10). 그리고 스코어 판별부(L700)는 이동 중의 어느 프레임에 수집된 이미지 내 작물의 최종 스코어(S)와 기준 스코 어를 비교하여(S700), 수집된 이미지 내 작물 중에 기준 스코어를 만족하는 최종 스코어(S)를 갖는 작물이 존재 할 경우 주행 제어부(L600)는 수확 장치를 정지시킬 수 있다(S625). 그리고 엔드 이펙터 제어부(L800)는 해 당 작물을 수확할 수 있다(S800). 본 실시예에 따른 수확 방법은 수확 장치의 이동 중에 미리 지정된 프레임 마다 이미지 정보를 수집하고, 수집된 이미지 중에 기준 스코어를 만족하는 작물이 인식될 때까지 이동함으로써, 본 발명이 이에 제한되는 것 은 아니나, 예를 들어 과실의 숙도 초기 등에 활용할 경우 신속하고 효율적인 수확을 수행할 수 있다. 이상에서 본 발명의 실시예를 중심으로 설명하였으나 이는 단지 예시일 뿐 본 발명을 한정하는 것이 아니며, 본 발명이 속하는 분야에서 통상의 지식을 가진 자라면 본 발명의 실시예의 본질적인 특성을 벗어나지 않는 범위에 서 이상에 예시되지 않은 여러 가지의 변형과 응용이 가능함을 알 수 있을 것이다. 따라서 본 발명의 범위는 이상에서 예시된 기술 사상의 변경물, 균등물 내지는 대체물을 포함하는 것으로 이해 되어야 한다. 예를 들어, 본 발명의 실시예에 구체적으로 나타난 각 구성요소는 변형하여 실시할 수 있다. 그리 고 이러한 변형과 응용에 관계된 차이점들은 첨부된 청구 범위에서 규정하는 본 발명의 범위에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2022-0183246", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 작물 수확 시스템을 나타낸 모식도이다. 도 2는 도 1의 수확 장치의 로봇 암의 단부를 나타낸 모식도이다. 도 3은 도 1의 수확 장치의 논리적 구성도이다. 도 4는 본 발명의 일 실시예에 따른 수확 가능도 정량화 방법을 나타낸 순서도이다. 도 5 및 도 6은 각각 로봇 암의 초기 자세, 공간 좌표 및 제3 확률 함수를 설명하기 위한 도면들이다. 도 7은 수집된 이미지 정보에서의 픽셀 좌표, 제1 확률 함수 및 제2 확률 함수를 설명하기 위한 도면이다. 도 8 및 도 9는 각각 도 4의 방법을 통해 산출된 스코어의 의미를 설명하기 위한 도면들이다. 도 10 및 도 11은 본 발명의 일 실시예에 따른 수확 방법 및 그 시스템을 설명하기 위한 도면들이다. 도 12는 본 발명의 다른 실시예에 따른 수확 방법을 설명하기 위한 순서도이다."}
