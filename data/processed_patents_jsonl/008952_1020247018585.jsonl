{"patent_id": "10-2024-7018585", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0118770", "출원번호": "10-2024-7018585", "발명의 명칭": "비디오 스트림을 생성하기 위한 시스템 및 방법", "출원인": "라이브아레나 테크놀로지스 에이비", "발명자": "비에르크만, 안드레아스"}}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제2 디지털 비디오 스트림을 제공하는 방법에 있어서, 상기 방법은:수집 단계에서, 제1 참여 클라이언트(121)로부터 제1 기본 디지털 비디오 스트림을 수집하고, 제2 참여 클라이언트(121)로부터 제2 기본 디지털 비디오 스트림을 수집하고, 제3 참여 클라이언트(121)로부터 제3 기본 디지털비디오 스트림을 수집하는 단계;게시 단계에서, 상기 제1 참여 클라이언트(121) 및 상기 제2 참여 클라이언트(121) 중 적어도 하나에, 상기 제1기본 디지털 비디오 스트림, 상기 제2 기본 디지털 비디오 및 상기 제1 및 제2 기본 비디오 스트림 중 적어도하나에 기초하여 생성된 제1 생성된 비디오 스트림 중 적어도 하나를 제공하는 단계; 및제2 생성 단계(135\")에서, 상기 제1 기본 디지털 비디오 스트림, 상기 제2 기본 디지털 비디오 스트림 및 상기제3 기본 디지털 비디오 스트림을 기반으로 제2 생성된 비디오 스트림을 디지털 비디오 스트림으로 자동으로 생성하는 단계 - 상기 제2 생성 단계(135\")는 상기 기본 디지털 비디오 스트림의 이벤트 및/또는 패턴에 기반하는자동 생성 결정을 자동으로 감지하여 기반으로 하는 단계를 포함하고, 상기 제2 생성 단계(135\")는 상기 제2 생성된 비디오 스트림이 상기 게시 단계에서 상기 제1 또는 제2 참여 클라이언트(121)에 제공되는 모든 비디오 스트림과 시간 비동기화되도록 시간 지연을 도입함 -를 포함하고, 상기 게시 단계는 상기 제1 또는 제2 참여 클라이언트가 아닌 적어도 하나의 소비 클라이언트(121, 150)에 상기제2 생성된 비디오 스트림을 연속적으로 제공하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제2 디지털 비디오 스트림을 제공하는 방법에 있어서, 상기 방법은:수집 단계에서, 적어도 2개의 서로 다른 디지털 비디오 소스(121)로부터 제1 기본 디지털 비디오 스트림 및 제2기본 디지털 비디오 스트림을 수집하는 단계;제1 생성 단계(135')에서, 상기 제1 및 제2 기본 디지털 비디오 스트림에 기초하여 디지털 비디오 스트림으로서제1 생성된 비디오 스트림을 생성하는 단계;제2 생성 단계(135\")에서, 상기 제1 생성된 비디오 스트림과 상기 제1 및 제2 기본 디지털 비디오 스트림을 기반으로 상기 제2 생성된 비디오 스트림을 디지털 비디오 스트림으로 자동 생성하는 단계 - 상기 제2 생성 단계(135\")는 상기 기본 디지털 비디오 스트림의 이벤트 및/또는 패턴에 기반하는 자동 생성 결정을 자동으로 감지하고 기반으로 하는 단계를 포함함 - ; 및상기 제2 생성 단계(135\")에서, 상기 제1 생성 단계(135')에서 발생하는 상기 제1 생성된 비디오 스트림의 대기시간을 고려하여, 상기 제1 생성된 비디오 스트림과 시간을 동기화하도록 상기 제1 및 제2 기본 디지털 비디오스트림을 시간 지연시키는 단계 - 상기 제2 생성된 비디오 스트림은 상기 시간 지연된 제1 및 제2 기본 디지털비디오 스트림을 기반으로 생성됨 - 을 포함하는, 방법."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 방법은:게시 단계(136')에서, 상기 제1 생성된 비디오 스트림을 제1 참여 클라이언트(121) 및 제2 참여 클라이언트(121) 중 적어도 하나에 연속적으로 제공하는 단계를 더 포함하는, 방법.공개특허 10-2024-0118770-3-청구항 4 제3항에 있어서, 상기 방법은:상기 제1 참여 클라이언트(121)가 상기 제1 기본 디지털 비디오 스트림을 제공하고 상기 제2 참여 클라이언트(121)가 상기 제2 기본 디지털 비디오 스트림을 제공하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2 디지털 비디오 스트림을 제공하는 방법에 있어서, 상기 방법은: 수집 단계(131)에서, 제1 참여 클라이언트(121)로부터 제1 기본 디지털 비디오 스트림을 수집하고, 제2 참여 클라이언트(121)로부터 제2 기본 디지털 비디오 스트림을 수집하고, 제3 참여 클라이언트(121)로부터 제3 기본 디지털 비디오 스트림을 수집하는 단계;제1 생성 단계(135')에서, 상기 제1 및 제2 기본 디지털 비디오 스트림에 기반하여 디지털 비디오 스트림으로서제1 생성된 비디오 스트림을 생성하는 단계 - 상기 제1 생성된 디지털 비디오 스트림은 제1 대기 시간을 가진게시를 위해 연속적으로 생성됨 - ;제2 생성 단계(135\")에서, 상기 제1, 제2 및 제3 기본 디지털 비디오 스트림을 기반으로 제2 생성된 비디오 스트림을 디지털 비디오 스트림으로 자동 생성하는 단계 - 상기 제2 생성 단계(135\")는 상기 기본 디지털 비디오스트림의 이벤트 및/또는 패턴에 기반하는 자동 생성 결정을 자동으로 감지하고 기반으로 하는 단계를포함하고, 상기 제2 생성된 디지털 비디오 스트림은 제2 대기 시간을 가진 게시를 위해 연속적으로 생성되며,상기 제2 대기 시간은 상기 제1 대기 시간보다 더 큼 - ; 및게시 단계(136')에서, 상기 제1 기본 디지털 비디오 스트림, 상기 제2 기본 디지털 비디오 스트림 및 상기 제1생성된 비디오 스트림 중 적어도 하나를 상기 제1 참여 클라이언트(121) 및 상기 제2 참여 클라이언트(121) 중적어도 하나에 연속적으로 제공하고 상기 제2 생성된 비디오 스트림을 적어도 하나의 다른 참여 클라이언트(121)에 연속적으로 제공하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항 내지 제5항 중 어느 한 항에 있어서, 상기 방법은:상기 게시 단계(136\")에서, 상기 제2 생성된 비디오 스트림을 상기 제1 또는 제2 참여 클라이언트가 아닌 적어도 하나의 소비 클라이언트(121, 150)에 연속적으로 제공하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 또는 제3항 내지 제6항 중 어느 한 항에 있어서, 상기 방법은:상기 제1 및 제2 기본 디지털 비디오 스트림이 공유 디지털 비디오 통신 서비스(110)의 일부로서 제공되는 단계를 더 포함하고, 상기 제1 참여 클라이언트(121)와 상기 제2 참여 클라이언트(121)는 모두 상기 공유 디지털 비디오 통신 서비스(110)에 각각 원격으로 연결된 참여 클라이언트인, 방법."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 수집 단계(131)는 상기 공유 디지털 비디오 통신 서비스(110)로부터 상기 제1 및/또는 제2 기본 디지털 비디오 스트림을 수집하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항 또는 제8항에 있어서,상기 수집 단계(131)는 상기 공유 디지털 비디오 통신 서비스(110) 외부의 정보 소스(300)로부터 수집된 외부공개특허 10-2024-0118770-4-디지털 비디오 스트림(301)으로서 적어도 하나의 기본 디지털 비디오 스트림을 수집하는 단계를 포함하고, 상기 제1 및/또는 제2 생성된 비디오 스트림은 상기 외부 디지털 비디오 스트림(301)에 기초하여 생성되는, 방법."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "선행 항들 중 어느 한 항에 있어서, 제1 생성 단계(135') 및/또는 제2 생성 단계(135\")는 상기 생성된 디지털비디오 스트림의 시각적 및/또는 청각적 비디오 콘텐츠 배열에서 상기 제1 및/또는 제2 기본 디지털 비디오 스트림의 개별적인 것의 가시성; 시각 또는 청각 효과 사용; 및/또는 상기 생성된 디지털 비디오 스트림의 출력모드와 관련한 미리 결정된 및/또는 동적으로 가변적인 매개변수 세트를 기반으로 하여 해당하는 상기 각각의생성된 비디오 스트림을 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "선행 항들 중 어느 한 항에 있어서, 제1 생성 단계(135') 및/또는 제2 생성 단계(135\")는 중앙 서버(130)에 의해 수행되어, 상기 제2 생성된 비디오 스트림(230)을 API(137)를 통해 라이브 비디오 스트림으로 하나 또는 여러 동시 소비자 클라이언트에 제공하는, 방법."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "선행 항들 중 어느 한 항에 있어서, 상기 방법은:할당 단계에서, 상기 참여 클라이언트(121) 중 적어도 두 그룹(121', 121\", 121'\")에 걸쳐 복수의 참여 클라이언트(121)를 할당하는 단계 - 상기 제1 및 제2 기본 비디오 스트림은 상기 수집 단계(131)에서 참여 클라이언트(121)의 제1 그룹(121')에 할당된 참여 클라이언트(121)로부터 수집되고, 제4 및 제5 기본 비디오 스트림은 참여 클라이언트(121)의 제3 그룹(121\"')에 할당된 참여 클라이언트(121)로부터 수집됨 - ;상기 제2 생성 단계(135\")에서, 상기 제1 및 제2 기본 비디오 스트림 중 적어도 하나에 기초하고, 상기 제4 및제5 기본 비디오 스트림 중 적어도 하나에 더욱 기초하여 상기 제2 생성된 비디오 스트림을 생성하는 단계; 및제3 생성 단계(135\"')에서, 상기 제4 및 제5 기본 비디오 스트림을 기반으로 제3 생성된 비디오 스트림을 생성하는 단계 - 상기 제3 생성 단계(135\")는 상기 제3 생성된 비디오 스트림이 상기 제1 생성된 비디오 스트림과시간 비동기화되도록 상기 제4 및 제5 기본 비디오 스트림을 시간 지연시키는 단계를 포함함 -; 및게시 단계(136\"')에서, 상기 제3 그룹에 할당된 적어도 하나의 참여 클라이언트에게 상기 제3 생성된 비디오 스트림을 연속적으로 제공하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 제1 생성 단계(135')는 상기 제1 및 제2 기본 비디오 스트림을 서로 동기화하기 위해 시간을 지연시키는단계를 포함하고, 상기 제3 생성 단계(135\"')는 상기 제1 생성 단계에서 상기 제1 및 제2 기본 비디오 스트림을 시간 지연하는 데에 사용되는 최대 시간 지연보다 더 작은 최대 시간 지연을 사용하여, 상기 제4 및 제5 기본 비디오 스트림을서로 시간 동기화하도록 시간 지연시키는 단계를 포함하여, 상기 제1 생성된 비디오 스트림이 상기 제3 생성된비디오 스트림과 시간이 동기화되지 않는, 방법."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항 또는 제13항에 있어서,상기 그룹(121', 121\", 121'\") 각각에 할당된 참여 클라이언트(121)는 상기 제2 생성된 비디오 스트림이 게시되는 비디오 통신 서비스(110)에 참여하고; 상기 방법은:상기 그룹(121', 121\", 121'\") 중 서로 다른 그룹을 상기 비디오 통신 서비스(110)의 서로 다른 참가자 상호작용 권한에 연관시키는 단계; 및공개특허 10-2024-0118770-5-상기 그룹(121', 121\", 121'\")의 서로 다른 그룹을 해당하는 상기 그룹(121', 121\", 121'\")에 할당된 참여 클라이언트(121)에게 게시된 각각의 생성된 비디오 스트림을 생성하는 데 사용되는 서로 다른 최대 시간 지연에연관시키는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 그룹(121', 121\", 121'\") 각각에 대한 상기 각각의 최대 시간 지연은 모든 기본 비디오 스트림과 해당하는상기 그룹(121', 121\", 121'\")의 참여 클라이언트(121)에 연속적으로 게시되는 임의의 생성된 비디오 스트림에걸쳐 가장 큰 대기 시간 차이로 결정되는, 방법."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제2 디지털 비디오 스트림을 제공하기 위한 컴퓨터 소프트웨어 제품에 있어서, 상기 컴퓨터 소프트웨어 기능은실행 시:제1 기본 디지털 비디오 스트림이 제1 참여 클라이언트(121)로부터 수집되고, 제2 기본 디지털 비디오 스트림이제2 참여 클라이언트(121)로부터 수집되며, 제3 기본 디지털 비디오 스트림이 제3 참여 클라이언트(121)로부터수집되는 수집 단계;상기 제1 기본 디지털 비디오 스트림, 상기 제2 기본 디지털 비디오 및 상기 제1 및 제2 기본 비디오 스트림 중적어도 하나에 기초하여 생성된 제1 생성된 비디오 스트림 중 적어도 하나가 상기 제1 참여 클라이언트(121) 및상기 제2 참여 클라이언트(121) 중 적어도 하나에 제공되는 게시 단계; 및제2 생성된 비디오 스트림이 상기 제1 기본 디지털 비디오 스트림, 상기 제2 기본 디지털 비디오 스트림 및 상기 제3 기본 디지털 비디오 스트림을 기반으로 디지털 비디오 스트림으로 자동으로 생성되는 제2 생성 단계(135\") - 상기 제2 생성 단계(135\")는 상기 기본 디지털 비디오 스트림의 이벤트 및/또는 패턴에 기반하는 자동생성 결정을 자동으로 감지하고 기반으로 하는 단계를 포함하며, 상기 제2 생성 단계(135\")는 상기 제2 생성된비디오 스트림이 상기 게시 단계에서 상기 제1 또는 제2 참여 클라이언트(121)에 제공되는 모든 비디오 스트림과 시간 비동기화되도록 시간 지연을 도입함 - 를 수행하도록 구성되고,상기 게시 단계는 상기 제2 생성된 비디오 스트림을 상기 제1 또는 제2 참여 클라이언트가 아닌 적어도 하나의소비 클라이언트(121, 150)에 연속적으로 제공하는 단계를 더 포함하는, 컴퓨터 소프트웨어 제품"}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "공유된 디지털 비디오 스트림을 제공하기 위한 컴퓨터 소프트웨어 제품에 있어서, 상기 컴퓨터 소프트웨어 기능은 실행 시:제1 기본 디지털 비디오 스트림 및 제2 기본 디지털 비디오 스트림이 적어도 두 개의 서로 다른 디지털 비디오소스(121)로부터 수집되는 수집 단계; 제1 생성된 비디오 스트림이 상기 제1 및 제2 기본 디지털 비디오 스트림에 기초하여 디지털 비디오 스트림으로서 생성되는 제1 생성 단계(135'); 및제2 생성된 비디오 스트림이 상기 제1 생성된 비디오 스트림에 기초하고 상기 제1 및 제2 기본 디지털 비디오스트림에 더욱 기초하여 디지털 비디오 스트림으로서 자동으로 생성되는 제2 생성 단계(135\") - 상기 제2 생성단계(135\")는 상기 기본 디지털 비디오 스트림의 이벤트 및/또는 패턴에 기반하는 자동 생성 결정을 자동으로감지하고 기반으로 하는 단계를 포함함 - 를 수행하도록 구성되고,상기 제2 생성 단계(135\")에서, 상기 제1 및 제2 기본 디지털 비디오 스트림은 제1 생성 단계(135')에서 결과되는 상기 제1 생성된 비디오 스트림의 대기 시간을 고려하여, 상기 제1 생성된 비디오 스트림과 시간을 동기화하도록 시간 지연되며, 상기 제2 생성된 비디오 스트림은 상기 시간 지연된 제1 및 제2 기본 디지털 비디오 스트공개특허 10-2024-0118770-6-림을 기반으로 생성되는, 컴퓨터 소프트웨어 제품."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "공유된 디지털 비디오 스트림을 제공하기 위한 컴퓨터 소프트웨어 제품에 있어서, 상기 컴퓨터 소프트웨어 기능은 실행 시:제1 기본 디지털 비디오 스트림이 제1 참여 클라이언트(121)로부터 수집되고, 제2 기본 디지털 비디오 스트림이제2 참여 클라이언트(121)로부터 수집되며, 제3 기본 디지털 비디오 스트림이 제3 참여 클라이언트(121)로부터수집되는, 수집 단계(131);제1 생성된 비디오 스트림이 상기 제1 및 제2 기본 디지털 비디오 스트림을 기반으로 디지털 비디오 스트림으로생성되는 제1 생성 단계(135') - 상기 제1 생성된 디지털 비디오 스트림은 제1 대기 시간을 갖는 게시를 위해연속적으로 생성됨 - ;제2 생성된 비디오 스트림이 상기 제1, 제2 및 제3 기본 디지털 비디오 스트림을 기반으로 디지털 비디오 스트림으로 자동 생성되는 제2 생성 단계(135\") - 상기 제2 생성 단계(135\")는 상기 기본 디지털 비디오 스트림의이벤트 및/또는 패턴에 기반하는 자동 생성 결정을 자동으로 감지하고 기반으로 하는 단계를 포함하며, 제2 생성된 디지털 비디오 스트림은 제2 대기 시간을 갖는 게시를 위해 연속적으로 생성되며, 제2 대기 시간은 제1 대기 시간보다 더 큼 - ; 및상기 제1 기본 디지털 비디오 스트림, 상기 제2 기본 디지털 비디오 스트림 및 상기 제1 생성된 비디오 스트림중 적어도 하나가 상기 제1 참여 클라이언트(121) 및 제2 참여 클라이언트(121) 중 적어도 하나에 연속적으로제공되고, 상기 제2 생성된 비디오 스트림은 적어도 하나의 다른 참여 클라이언트(121)에 연속적으로 제공되는게시 단계(136')를 포함하는, 컴퓨터 소프트웨어 제품."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제2 디지털 비디오 스트림을 제공하기 위한 시스템(100)에 있어서, 상기 시스템(100)은 중앙 서버(130)를 포함하고, 상기 중앙 서버(130)는:제1 기본 디지털 비디오 스트림이 제1 참여 클라이언트(121)로부터 수집되고, 제2 기본 디지털 비디오 스트림이제2 참여 클라이언트(121)로부터 수집되며, 제3 기본 디지털 비디오 스트림이 제3 참여 클라이언트(121)로부터수집되는 수집 기능;상기 제1 기본 디지털 비디오 스트림, 상기 제2 기본 디지털 비디오 및 상기 제1 및 제2 기본 비디오 스트림 중적어도 하나를 기반으로 생성된 제1 생성된 비디오 스트림 중 적어도 하나가 상기 제1 참여 클라이언트(121) 및상기 제2 참여 클라이언트(121) 중 적어도 하나에 제공되는 게시 기능; 및제2 생성된 비디오 스트림이 상기 제1 기본 디지털 비디오의 스트림, 상기 제2 기본 디지털 비디오 스트림 및상기 제3 기본 디지털 비디오 스트림을 기반으로 디지털 비디오 스트림으로 자동으로 생성되는 제2 생성 기능(135\") - 상기 제2 생성 기능(135\")은 상기 기본 디지털 비디오 스트림의 이벤트 및/또는 패턴에 기반하는 자동생성 결정을 자동으로 감지하고 기반으로 하도록 구성되며, 상기 제2 생성 기능(135\")은 제2 생성된 비디오 스트림이 상기 게시 기능에서 상기 제1 또는 제2 참여 클라이언트(121)에 제공되는 임의의 비디오 스트림과 시간비동기화되도록 시간 지연을 도입함 - 을 포함하고, 상기 게시 기능은 상기 제2 생성된 비디오 스트림을 상기 제1 또는 제2 참여 클라이언트가 아닌적어도 하나의 소비 클라이언트(121, 150)에 연속적으로 제공하는 단계를 포함하는, 시스템(100)."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "공유 디지털 비디오 스트림을 제공하기 위한 시스템(100)에 있어서, 상기 시스템(100)은 중앙 서버(130)를 포함하고, 상기 중앙 서버(130)는: 제1 기본 디지털 비디오 스트림 및 제2 기본 디지털 비디오 스트림이 적어도 두 개의 서로 다른 디지털 비디오소스(121)로부터 수집되는 수집 기능; 제1 생성된 비디오 스트림이 상기 제1 및 제2 기본 디지털 비디오 스트림에 기초하여 디지털 비디오 스트림으로공개특허 10-2024-0118770-7-생성되는 제1 생성 기능(135'); 및제2 생성된 비디오 스트림이 상기 제1 생성된 비디오 스트림에 기초하고 상기 제1 및 제2 기본 디지털 비디오스트림에 더욱 기초하여 디지털 비디오 스트림으로서 자동으로 생성되는 제2 생성 기능(135\") - 상기 제2 생성기능(135\")은 상기 기본 디지털 비디오 스트림의 이벤트 및/또는 패턴에 기반하는 자동 생성 결정을 자동으로감지하고 기반으로 하도록 구성됨 - 을 포함하고, 상기 제2 생성 기능(135\")에서, 상기 제1 및 제2 기본 디지털 비디오 스트림은 상기 제1 생성 기능(135')에서결과된 상기 제1 생성된 비디오 스트림의 대기 시간을 고려하여, 상기 제1 생성된 비디오 스트림과 시간 동기화되도록 시간 지연되고, 상기 제2 생성된 비디오 스트림은 상기 시간 지연된 제1 및 제2 기본 디지털 비디오 스트림을 기반으로 생성되는, 시스템(100)."}
{"patent_id": "10-2024-7018585", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "공유 디지털 비디오 스트림을 제공하기 위한 시스템(100)에 있어서, 상기 시스템(100)은 중앙 서버(130)를 포함하고, 상기 중앙 서버(130)는:제1 기본 디지털 비디오 스트림이 제1 참여 클라이언트(121)로부터 수집되고, 제2 기본 디지털 비디오 스트림이제2 참여 클라이언트(121)로부터 수집되며, 제3 기본 디지털 비디오 스트림이 제3 참여 클라이언트(121)로부터수집되는 수집 기능(131);제1 생성된 비디오 스트림이 상기 제1 및 제2 기본 디지털 비디오 스트림을 기반으로 디지털 비디오 스트림으로생성되고, 상기 제1 생성된 디지털 비디오 스트림이 제1 대기 시간을 갖는 게시를 위해 연속적으로 생성되는 제1 생성 기능(135');제2 생성된 비디오 스트림이 상기 제1, 제2 및 제3 기본 디지털 비디오 스트림을 기반으로 디지털 비디오 스트림으로 자동 생성되는 제2 생성 기능(135\") - 상기 제2 생성 기능(135\")은 상기 기본 디지털 비디오 스트림의이벤트 및/또는 패턴을 기반으로 자동 생성 결정을 자동으로 감지하고 기반으로 삼도록 구성되며, 제2 생성된디지털 비디오 스트림은 제2 대기 시간을 갖는 게시를 위해 연속적으로 생성되며, 제2 대기 시간은 제1 대기 시간보다 더 큼 - ; 및상기 제1 기본 디지털 비디오 스트림, 상기 제2 기본 디지털 비디오 스트림 및 상기 제1 생성된 비디오 스트림중 적어도 하나가 상기 제2 참여 클라이언트(121) 및 제2 참여 클라이언트(121) 중 적어도 하나에게 연속적으로제공되고, 상기 제2 생성된 비디오 스트림은 적어도 하나의 다른 참여 클라이언트(121)에게 연속적으로 제공되는 게시 기능(136')을 포함하는, 시스템(100)."}
{"patent_id": "10-2024-7018585", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "제2 디지털 비디오 스트림을 제공하는 방법은, 적어도 두 개의 다른 디지털 비디오 소스로부터 제1 및 제2 기본 디지털 비디오 스트림을 수집하는 수집 단계; 상기 제1 및 제2 기본 스트림에 기반하여 제1 생성된 비디오 스트림을 생성하는 제1 생성 단계(135'); 상기 제1 생성된 스트림에 기반하고 상기 제1 및 제2 기본 스트림에 더 욱 기반하여 제2 스트림을 생성하는 제2 생성 단계(135\"); 상기 제2 생성 단계(135\")에서 상기 제1 생성 단계 (135')에서 결과된 제1 생성된 스트림의 대기 시간을 고려하여 상기 제1 및 제2 기본 스트림을 상기 제1 생성된 스트림과 시간 동화하도록 시간 지연하는 상기 제2 생성 단계(135\")를 포함하고, 상기 제2 생성된 스트림은 상기 시간 지연된 제1 및 제2 기본 스트림에 기반하여 생성된다. 본 발명은 또한 시스템 및 컴퓨터 소프트웨어 제품에 관한 것이다."}
{"patent_id": "10-2024-7018585", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 디지털 비디오 스트림을 생성하기 위한 시스템, 컴퓨터 소프트웨어 제품 및 방법에 관한 것이며, 특 히 둘 이상의 서로 다른 디지털 입력 비디오 스트림을 기반으로 디지털 비디오 스트림을 생성하기 위한 방법에 관한 것이다. 바람직한 실시 예에서, 디지털 비디오 스트림은 특히 복수의 서로 다른 동시 사용자를 포함하는, 디지털 비디오 회의 또는 디지털 비디오 회의나 미팅 시스템의 맥락에서 생성된다. 생성된 디지털 비디오 스트 림은 디지털 비디오 회의 또는 디지털 비디오 회의 시스템 외부로 또는 내부에 게시될 수 있다."}
{"patent_id": "10-2024-7018585", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "다른 실시 예에서, 본 발명은 디지털 비디오 회의는 아니지만 여러 디지털 비디오 입력 스트림이 동시에 처리되 어 생성된 디지털 비디오 스트림으로 결합되는 상황에 적용된다. 예를 들어, 그러한 맥락은 교육적이거나 교육 적일 수 있다. Microsoft® Teams®, Zoom® 및 Google® Meet®과 같이, 두 명 이상의 참가자에게 로컬로 녹음된 디지털 비디 오 및 오디오를 사용하여 가상으로 만나고 실제 회의를 에뮬레이트하도록 모든 참가자에게 방송하도록제공하는, 많은 공지의 디지털 비디오 화상 시스템이 있다. 특히, 누구에게 언제, 어떤 배포 채널을 통해 무엇이 표시되는와 같이, 특히 시청한 콘텐츠의 생성과 관련하여 이러한 디지털 화상 회의 솔루션을 개선할 필요성이 대두되고 있이다. 예를 들어, 일부 시스템은 현재 말하는 참가자를 자동으로 감지하고 말하는 참가자의 해당 비디오 피드를 다른 참가자에게 보여준다. 많은 시스템에서 현재 표시된 화면, 보기 창 또는 디지털 프리젠테이션과 같은 그래픽을 공유하는 것이 가능하다. 그러나 가상 회의가 더욱 복잡해짐에 따라, 서비스가 현재 사용 가능한 모든 정보 중 각 시점에 각 참가자에게 표시할 정보가 무엇인지를 파악하는 것이 점점 더 어려워지고 있다. 다른 예에서는 발표 참가자가 디지털 프레젠테이션의 슬라이드에 관해 이야기하면서 무대 위를 돌아다닌다. 다 음에 시스템은 프레젠테이션, 발표자 또는 둘 다를 표시할지, 아니면 둘 사이를 전환할지 결정해야 한다. 자동 생성 프로세스에 의해 다수의 입력 디지털 비디오 스트림을 기반으로 하나 또는 여러 개의 출력 디지털 비 디오 스트림을 생성하고, 이렇게 생성된 디지털 비디오 스트림을 한 명 또는 여러 명의 소비자에게 제공하는 것 이 바람직할 수 있다. 그러나, 많은 경우 이러한 디지털 화상 회의 시스템이 직면한 수많은 기술적인 어려움으로 인해, 동적 회의 화 면 레이아웃 관리자나 기타 자동화된 생성 기능을 사용하여 어떤 정보를 표시할지 선택하는 것이 어렵다. 첫째로, 디지털 화상 회의는 실시간이라는 측면이 있기 때문에, 대기 시간이 짧은 것이 중요하다. 이것은 서로 다른 하드웨어를 사용하여 참여하는 서로 다른 참가자와 같이 서로 다른 수신 디지털 비디오 스트림이 서로 다 른 대기 시간, 프레임 속도, 종횡비 또는 해상도와 연관될 때 문제를 야기한다. 이러한 수신 디지털 비디오 스 트림은 잘 구성된 사용자 경험을 위해 처리가 필요한 경우가 많다. 둘째, 시간 동기화에 문제가 있다. 외부 디지털 비디오 스트림 또는 참가자가 제공하는 디지털 비디오 스트림과 같은 다양한 입력 디지털 비디오 스트림은 일반적으로 중앙 서버 또는 이와 유사한 서버로 공급되기 때문에, 이 러한 각 디지털 비디오 피드를 동기화할 절대적인 시간이 없다. 대기 시간이 너무 길면 동기화되지 않은 디지털 비디오 피드로 인해 사용자 경험이 저하된다. 셋째, 다자간 디지털 화상 회의에는 서로 다른 인코딩이나 형식을 갖는 다양한 디지털 비디오 스트림이 포함될 수 있으며, 이로 인해 디코딩 및 재인코딩이 필요하고 결과적으로 대기 시간 및 동기화 측면에서 문제가 발생한 다. 이러한 인코딩은 계산적으로 부담스럽기 때문에 하드웨어 요구 사항 측면에서도 비용이 많이 든다. 넷째, 서로 다른 디지털 비디오 소스가 서로 다른 프레임 속도, 종횡비 및 해상도와 연관될 수 있다는 사실은 메모리 할당 요구 사항이 예측할 수 없을 정도로 달라질 수 있는 결과를 초래하므로 지속적인 균형 조정을 필요 로 한다. 이로 인해 잠재적으로 추가 대기 시간 및 동기화 문제가 발생할 수 있다. 결과적으로 버퍼 요구 사항 이 커진다. 다섯째, 참가자는 다양한 연결성, 이탈/재연결 등의 측면에서 다양한 문제를 경험할 수 있으므로, 이는 잘 구성 된 사용자 경험을 자동으로 생성하는 데 더 많은 문제를 야기한다. 이러한 문제는 예를 들어 많은 참가자가 참여하는 경우; 참여자가 접속할 다양한 하드웨어 및/또는 소프트웨어 를 사용하는 경우; 외부에서 제공되는 디지털 비디오 스트림; 화면 공유; 또는 다중 호스트와 같은 보다 복잡한 회의 상황에서 증폭된다. 대응하는 문제는 교육 및 강의용 디지털 비디오 생성 시스템에서와 같이 출력 디지털 비디오 스트림이 여러 입 력 디지털 비디오 스트림을 기반으로 생성되는 다른 상황에서 발생한다. 본 출원의 효력일에 공개되지 않았던 스웨덴 출원 SE 2151267-8은 상기 논의된 문제에 대한 다양한 해결책을 개 시한다. 다수의 참여자가 참여하는 디지털 비디오 환경에서는 대기 시간과 관련된 추가 문제가 있다. 특히 대기 시간 요 구 사항은 참가자마다 다를 수 있다. 이러한 환경에서는 시간 지연이 의사소통에 부정적인 영향을 미치지 않는 잘 동기화된 경험을 모든 참가자에게 제공하는 것이 어려운 것으로 나타났다. 특히 이것은 중간에 생성된 다중 참가자 비디오 스트림을 사용하거나 여러 유형의 참가자를 포함하는 복잡한 구성의 비디오 환경에서 그렇다."}
{"patent_id": "10-2024-7018585", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2024-7018585", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제 중 하나 또는 여러개를 해결한다."}
{"patent_id": "10-2024-7018585", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 제2 디지털 비디오 스트림을 제공하는 방법에 관한 것으로, 상기 방법은: 수집 단계에서, 제1 참여 클라이언트로부터 제1 기본 디지털 비디오 스트림을 수집하고, 제2 참여 클라이언트로부터 제2 기본 디지털 비 디오 스트림을 수집하고, 제3 참여 클라이언트로부터 제3 기본 디지털 비디오 스트림을 수집하는 단계; 게시 단 계에서, 상기 제1 참여 클라이언트 및 상기 제2 참여 클라이언트 중 적어도 하나에, 상기 제1 기본 디지털 비디 오 스트림, 상기 제2 기본 디지털 비디오 및 상기 제1 및 제2 기본 비디오 스트림 중 적어도 하나에 기초하여 생성된 제1 생성된 비디오 스트림 중 적어도 하나를 제공하는 단계; 및 제2 생성 단계에서, 상기 제1 기본 디지 털 비디오 스트림, 상기 제2 기본 디지털 비디오 스트림 및 상기 제3 기본 디지털 비디오 스트림을 기반으로 제 2 생성된 비디오 스트림을 디지털 비디오 스트림으로 자동으로 생성하는 단계 - 상기 제2 생성 단계는 상기 제2 생성된 비디오 스트림이 상기 게시 단계에서 상기 제1 또는 제2 참여 클라이언트에 제공되는 모든 비디오 스트 림과 시간 비동기화되도록 시간 지연을 도입함 - 를 포함하고, 상기 게시 단계는 상기 제1 또는 제2 참여 클라 이언트가 아닌 적어도 하나의 소비 클라이언트에 상기 제2 생성된 비디오 스트림을 연속적으로 제공하는 단계를 더 포함한다. 본 발명은 또한 제2 디지털 비디오 스트림을 제공하는 방법에 관한 것으로, 상기 방법은: 수집 단계에서, 적어 도 2개의 서로 다른 디지털 비디오 소스로부터 제1 기본 디지털 비디오 스트림 및 제2 기본 디지털 비디오 스트 림을 수집하는 단계; 제1 생성 단계에서, 상기 제1 및 제2 기본 디지털 비디오 스트림에 기초하여 디지털 비디 오 스트림으로서 제1 생성된 비디오 스트림을 생성하는 단계; 제2 생성 단계에서, 상기 제1 생성된 비디오 스트 림과 상기 제1 및 제2 기본 디지털 비디오 스트림을 기반으로 상기 제2 생성된 비디오 스트림을 디지털 비디오 스트림으로 자동 생성하는 단계; 및 상기 제2 생성 단계에서, 상기 제1 생성 단계에서 발생하는 상기 제1 생성 된 비디오 스트림의 대기 시간을 고려하여, 상기 제1 생성된 비디오 스트림과 시간을 동기화하기 위해 상기 제1 및 제2 기본 디지털 비디오 스트림을 시간 지연시키는 단계 - 상기 제2 생성된 비디오 스트림은 상기 시간 지연 된 제1 및 제2 기본 디지털 비디오 스트림을 기반으로 생성됨 - 을 포함한다. 본 발명은 또한 제2 디지털 비디오 스트림을 제공하는 방법에 관한 것으로, 상기 방법은: 수집 단계에서, 제1 참여 클라이언트로부터 제1 기본 디지털 비디오 스트림을 수집하고, 제2 참여 클라이언트로부터 제2 기본 디지 털 비디오 스트림을 수집하고, 제3 참여 클라이언트로부터 제3 기본 디지털 비디오 스트림을 수집하는 단계; 제 1 생성 단계에서, 상기 제1 및 제2 기본 디지털 비디오 스트림에 기반하여 디지털 비디오 스트림으로서 제1 생 성된 비디오 스트림을 생성하는 단계 - 상기 제1 생성된 디지털 비디오 스트림은 제1 대기 시간을 가진 게시를 위해 연속적으로 생성됨 - ; 제2 생성 단계에서, 상기 제1, 제2 및 제3 기본 디지털 비디오 스트림을 기반으로 상기 제2 생성된 비디오 스트림을 디지털 비디오 스트림으로 생성하는 단계 - 상기 제2 생성된 디지털 비디오 스트림은 제2 대기 시간을 가진 게시를 위해 연속적으로 생성되며, 상기 제2 대기 시간은 상기 제1 대기 시간보 다 더 큼 - ; 및 게시 단계에서, 상기 제1 기본 디지털 비디오 스트림, 상기 제2 기본 디지털 비디오 스트림 및 상기 제1 생성된 비디오 스트림 중 적어도 하나를 상기 제1 참여 클라이언트 및 상기 제2 참여 클라이언트 중 적어도 하나에 연속적으로 제공하고 상기 제2 생성된 비디오 스트림을 적어도 하나의 다른 참여 클라이언트에 연속적으로 제공하는 단계를 포함한다. 본 발명은 또한 제2 디지털 비디오 스트림을 제공하기 위한 컴퓨터 소프트웨어 제품에 관한 것으로, 상기 컴퓨 터 소프트웨어 기능은 실행 시: 제1 기본 디지털 비디오 스트림이 제1 참여 클라이언트로부터 수집되고, 제2 기 본 디지털 비디오 스트림이 제2 참여 클라이언트로부터 수집되며, 제3 기본 디지털 비디오 스트림이 제3 참여 클라이언트로부터 수집되는 수집 단계; 상기 제1 기본 디지털 비디오 스트림, 상기 제2 기본 디지털 비디오 및 상기 제1 및 제2 기본 비디오 스트림 중 적어도 하나에 기초하여 생성된 제1 생성된 비디오 스트림 중 적어도 하나가 상기 제1 참여 클라이언트 및 상기 제2 참여 클라이언트 중 적어도 하나에 제공되는 게시 단계; 및 제2 생성된 비디오 스트림이 상기 제1 기본 디지털 비디오 스트림, 상기 제2 기본 디지털 비디오 스트림 및 상기 제 3 기본 디지털 비디오 스트림을 기반으로 디지털 비디오 스트림으로 자동으로 생성되는 제2 생성 단계 - 상기 제2 생성 단계는 상기 제2 생성된 비디오 스트림이 상기 게시 단계에서 상기 제1 또는 제2 참여 클라이언트에 제공되는 모든 비디오 스트림과 시간 비동기화되도록 시간 지연을 도입함 - 를 수행하도록 구성되고, 상기 게 시 단계는 상기 제2 생성된 비디오 스트림을 상기 제1 또는 제2 참여 클라이언트가 아닌 적어도 하나의 소비 클라이언트에 연속적으로 제공하는 단계를 더 포함한다. 본 발명은 또한 공유된 디지털 비디오 스트림을 제공하기 위한 컴퓨터 소프트웨어 제품에 관한 것으로, 상기 컴 퓨터 소프트웨어 기능은 실행 시: 제1 기본 디지털 비디오 스트림 및 제2 기본 디지털 비디오 스트림이 적어도 두 개의 서로 다른 디지털 비디오 소스로부터 수집되는 수집 단계; 제1 생성된 비디오 스트림이 상기 제1 및 제 2 기본 디지털 비디오 스트림에 기초하여 디지털 비디오 스트림으로서 생성되는 제1 생성 단계; 제2 생성된 비 디오 스트림이 상기 제1 생성된 비디오 스트림에 기초하고 상기 제1 및 제2 기본 디지털 비디오 스트림에 더욱 기초하여 디지털 비디오 스트림으로서 자동으로 생성되는 제2 생성 단계를 수행하도록 구성되고, 상기 제2 생성 단계에서, 상기 제1 및 제2 기본 디지털 비디오 스트림은 제1 생성 단계에서 결과되는 상기 제1 생성된 비디오 스트림의 대기 시간을 고려하여, 상기 제1 생성된 비디오 스트림과 시간을 동기화하도록 시간 지연되며, 상기 제2 생성된 비디오 스트림은 상기 시간 지연된 제1 및 제2 기본 디지털 비디오 스트림을 기반으로 생성된다. 본 발명은 또한 공유된 디지털 비디오 스트림을 제공하기 위한 컴퓨터 소프트웨어 제품에 관한 것으로, 상기 컴 퓨터 소프트웨어 기능은 실행 시: 제1 기본 디지털 비디오 스트림이 제1 참여 클라이언트로부터 수집되고, 제2 기본 디지털 비디오 스트림이 제2 참여 클라이언트로부터 수집되며, 제3 기본 디지털 비디오 스트림이 제3 참여 클라이언트로부터 수집되는, 수집 단계; 제1 생성된 비디오 스트림이 상기 제1 및 제2 기본 디지털 비디오 스트 림을 기반으로 디지털 비디오 스트림으로 생성되는 제1 생성 단계 - 상기 제1 생성된 디지털 비디오 스트림은 제1 대기 시간을 갖는 게시를 위해 연속적으로 생성됨 - ; 제2 생성된 비디오 스트림이 상기 제1, 제2 및 제3 기본 디지털 비디오 스트림을 기반으로 디지털 비디오 스트림으로 자동 생성되는 제2 생성 단계 - 제2 생성된 디지털 비디오 스트림은 제2 대기 시간을 갖는 게시를 위해 연속적으로 생성되며, 제2 대기 시간은 제1 대기 시 간보다 더 큼 - ; 상기 제1 기본 디지털 비디오 스트림, 상기 제2 기본 디지털 비디오 스트림 및 상기 제1 생 성된 비디오 스트림 중 적어도 하나가 상기 제1 참여 클라이언트 및 제2 참여 클라이언트 중 적어도 하나에 연 속적으로 제공되고, 상기 제2 생성된 비디오 스트림은 적어도 하나의 다른 참여 클라이언트에 연속적으로 제공 되는, 게시 단계를 포함한다. 본 발명은 또한 제2 디지털 비디오 스트림을 제공하기 위한 시스템에 있어서, 상기 시스템은 중앙 서버를 포함 하고, 상기 중앙 서버는: 제1 기본 디지털 비디오 스트림이 제1 참여 클라이언트로부터 수집되고, 제2 기본 디 지털 비디오 스트림이 제2 참여 클라이언트로부터 수집되며, 제3 기본 디지털 비디오 스트림이 제3 참여 클라이 언트로부터 수집되는, 수집 기능; 상기 제1 기본 디지털 비디오 스트림, 상기 제2 기본 디지털 비디오 및 상기 제1 및 제2 기본 비디오 스트림 중 적어도 하나를 기반으로 생성된 제1 생성된 비디오 스트림 중 적어도 하나가 상기 제1 참여 클라이언트 및 상기 제2 참여 클라이언트 중 적어도 하나에 제공되는, 게시 기능; 제2 생성된 비 디오 스트림이 상기 제1 기본 디지털 비디오의 스트림, 상기 제2 기본 디지털 비디오 스트림 및 상기 제3 기본 디지털 비디오 스트림을 기반으로 디지털 비디오 스트림으로 자동으로 생성되는, 제2 생성 기능 - 상기 제2 생 성 기능은 제2 생성된 비디오 스트림이 상기 게시 기능에서 상기 제1 또는 제2 참여 클라이언트)에 제공되는 임 의의 비디오 스트림과 시간 비동기화되도록 시간 지연을 도입함 - 을 포함하고, 상기 게시 기능은 상기 제2 생 성된 비디오 스트림을 상기 제1 또는 제2 참여 클라이언트가 아닌 적어도 하나의 소비 클라이언트에 연속적으로 제공하는 단계를 포함한다. 또한, 본 발명은 공유 디지털 비디오 스트림을 제공하기 위한 시스템에 관한 것으로, 상기 시스템은 중앙 서버 를 포함하고, 상기 중앙 서버는: 제1 기본 디지털 비디오 스트림 및 제2 기본 디지털 비디오 스트림이 적어도 두 개의 서로 다른 디지털 비디오 소스로부터 수집되는, 수집 기능; 제1 생성된 비디오 스트림이 상기 제1 및 제2 기본 디지털 비디오 스트림에 기초하여 디지털 비디오 스트림으로 생성되는, 제1 생성 기능; 및 제2 생성된 비디오 스트림이 상기 제1 생성된 비디오 스트림에 기초하고 상기 제1 및 제2 기본 디지털 비디오 스트림에 더 욱 기초하여 디지털 비디오 스트림으로서 생성되는, 제2 생성 기능을 포함하고, 상기 제2 생성 기능에서, 상기 제1 및 제2 기본 디지털 비디오 스트림은 상기 제1 생성 기능에서 결과된 상기 제1 생성된 비디오 스트림의 대 기 시간을 고려하여, 상기 제1 생성된 비디오 스트림과 시간 동기화되도록 시간 지연되고, 상기 제2 생성된 비 디오 스트림은 상기 시간 지연된 제1 및 제2 기본 디지털 비디오 스트림을 기반으로 생성된다. 본 발명은 또한 공유 디지털 비디오 스트림을 제공하기 위한 시스템에 관한 것으로, 상기 시스템은 중앙 서버를 포함하고, 상기 중앙 서버는: 제1 기본 디지털 비디오 스트림이 제1 참여 클라이언트로부터 수집되고, 제2 기본 디지털 비디오 스트림이 제2 참여 클라이언트로부터 수집되며, 제3 기본 디지털 비디오 스트림이 제3 참여 클라 이언트로부터 수집되는, 수집 기능; 제1 생성된 비디오 스트림이 상기 제1 및 제2 기본 디지털 비디오 스트림을 기반으로 디지털 비디오 스트림으로 생성되고, 상기 제1 생성된 디지털 비디오 스트림이 제1 대기 시간을 갖는 게시를 위해 연속적으로 생성되는, 제1 생성 기능; 제2 생성된 비디오 스트림이 상기 제1, 제2 및 제3 기본 디지털 비디오 스트림을 기반으로 디지털 비디오 스트림으로 자동 생성되는 제2 생성 기능 - 제2 생성된 디지털 비디오 스트림은 제2 대기 시간을 갖는 게시를 위해 연속적으로 생성되며, 제2 대기 시간은 제1 대기 시간보다 더 큼 - ; 및 상기 제1 기본 디지털 비디오 스트림, 상기 제2 기본 디지털 비디오 스트림 및 상기 제1 생성된 비디오 스트림 중 적어도 하나가 상기 제2 참여 클라이언트 및 제2 참여 클라이언트 중 적어도 하나에게 연속적으로 제공되고, 상기 제2 생성된 비디오 스트림은 적어도 하나의 다른 참여 클라이언트에게 연속적으로 제공되는, 게시 기능을 포함한다. 또한, 본 발명은 시스템에 관한 것이다."}
{"patent_id": "10-2024-7018585", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "모든 도면은 동일하거나 해당하는 부분에 대해서는 참조번호를 공유한다. 도 1은 공유 디지털 비디오 스트림과 같은 디지털 비디오 스트림을 제공하기 위해 본 발명에 따른 방법을 수행 하도록 구성된 본 발명에 따른 시스템을 도시한다. 시스템은 비디오 통신 서비스를 포함할 수 있지만, 일부 실시 예에서는 비디오 통신 서비스가 시스템 외부에 있을 수도 있다. 논의되는 바와 같이, 하나 이상의 비디오 통신 서비스가 있을 수 있 다. 시스템은 하나 또는 여러 참여 클라이언트를 포함할 수 있지만, 일부 실시 예에서는 하나, 일부 또는 모든 참여 클라이언트가 시스템 외부에 있을 수도 있다. 시스템은 중앙 서버를 포함할 수 있다. 본 명세서에 사용된 바와 같이, \"중앙 서버\"라는 용어는 잘 정의된 API(응용 프로그래밍 인터페이스)를 통해 논 리적으로 중앙화된 방식으로 액세스되도록 배열된 컴퓨터로 구현된 기능이다. 이러한 중앙 서버의 기능은 순수 하게 컴퓨터 소프트웨어로 구현되거나 소프트웨어와 가상 및/또는 물리적 하드웨어의 조합으로 구현될 수 있다. 이는 독립형 물리적 또는 가상 서버 컴퓨터에서 구현되거나 상호 연결된 여러 물리적 및/또는 가상 서버 컴퓨터 에 걸쳐 분산될 수 있다. 중앙 서버가 실행되는 물리적 또는 가상 하드웨어, 즉 중앙 서버의 기능을 정의하는 컴퓨터 소프트웨 어는, 자체 기존 CPU, 자체 기존 GPU, 자체 기존 RAM/ROM 메모리, 자체 기존 컴퓨터 버스, 인터넷 연결과 같은 자체 기존 외부 통신 기능을 포함할 수 있다. 각 비디오 통신 서비스는 사용되는 정도에 따라 상기 의미에서는 또한 중앙 서버이며, 이는 중앙 서버 또는 중앙 서버의 일부와는 다른 중앙 서버일 수 있다. 이에 따라, 상기 참여 클라이언트 각각은 해당 해석에 의하면 상기 의미에서는 중앙 서버일 수 있으며, 각 각의 참여 클라이언트가 실행되는 물리적 또는 가상 하드웨어, 즉 참여 클라이언트의 기능을 정의하 는 컴퓨터 소프트웨어는 자체 기존 CPU/GPU, 자체 기존 RAM/ROM 메모리, 일반적인 컴퓨터 버스와 인터넷 연결과같은 자체 기존 외부 통신 기능을 포함할 수 있다. 각 참여 클라이언트는 또한 일반적으로 진행 중인 비디오 통신의 일부로서 참여 클라이언트에 제공되 는 비디오 콘텐츠를 표시하도록 구성된 컴퓨터 화면; 상기 비디오 통신의 일부로서 참여 클라이언트에 제 공되는 사운드 콘텐츠를 방출하도록 배열된 확성기; 비디오 카메라; 및 상기 비디오 통신에 참여하는 사람(12 2)에게 로컬로 사운드를 녹음하도록 배열된 마이크를 포함하거나 이들과 통신하고, 참가자는 해당 참여 클 라이언트를 사용하여 상기 비디오 통신에 참여한다. 다시 말해서, 각각의 참여 클라이언트의 각각의 인간-기계 인터페이스는 각각의 참가자가 비디오 통 신에서 해당 클라이언트와, 다른 참가자 및/또는 다양한 소스에 의해 제공되는 오디오/비디오 스트림과 상 호작용할 수 있게 해준다. 일반적으로, 참여 클라이언트 각각은 상기 비디오 카메라, 마이크; 키보드; 컴퓨터 마우스 또는 트랙패드; 및/또는 디지털 비디오 스트림, 디지털 오디오 스트림 및/또는 기타 디지털 데이터를 수신하기 위한 API를 포함 할 수 있는 각각의 입력 수단을 포함한다. 입력 수단은 특히 비디오 통신 서비스 및/또는 중앙 서버와 같은 중앙 서버로부터 비디오 스트림 및/또는 오디오 스트림을 수신하도록 구성되고, 이러한 비디 오 스트림 및/또는 오디오 스트림은 비디오 통신의 일부로 제공되고 이러한 디지털 데이터 입력 스트림의 적어 도 2개의 소스, 예를 들어 참여 클라이언트 및/또는 외부 소스(아래 참조)로부터 상기 중앙 서버에 제공되 는 해당 디지털 데이터 입력 스트림을 기반으로 바람직하게 생성된다. 더 일반적으로, 각각의 참여 클라이언트는 상기 컴퓨터 화면; 상기 스피커; 디지털 비디오 및/또는 오디오 스트림을 내보내는 API를 포함할 수 있는 각각의 출력 수단을 포함하고, 이러한 스트림은 해당 참여 클라 이언트를 사용하여 참가자에게 로컬로 캡처된 비디오 및/또는 오디오를 나타낸다. 실제로, 각 참여 클라이언트는 스크린, 확성기, 마이크 및 인터넷 연결을 갖춘 휴대폰과 같은 모바일 장치 일 수 있고, 모바일 장치는 로컬로 컴퓨터 소프트웨어를 실행하거나 원격으로 실행되는 컴퓨터 소프트웨어에 액 세스하여 해당 참여 클라이언트의 기능을 수행한다. 이에 따라, 참여 클라이언트는 경우에 따라 웹 브라우저를 통해 원격으로 액세스되는 기능 등을 사용하여 로컬 설치된 애플리케이션을 실행하는 두껍거나 얇은 랩톱 또는 고정 컴퓨터일 수도 있다. 현재 유형의 하나의 동일한 비디오 통신에 사용되는 참여 클라이언트는 적어도 3개 또는 심지어 적어도 4 개와 같이 하나 이상일 수 있다. 적어도 두 개의 서로 다른 참여 클라이언트 그룹이 있을 수 있다. 참여 클라이언트 각각은 그러한 각각의 그룹 에 할당될 수 있다. 그룹은 참여 클라이언트의 다양한 역할, 참여 클라이언트의 다양한 가상적이거나 물리적인 위치 및/또는 참여 클라이언트의 다양한 상호 작용 권리를 반영할 수 있다. 예를 들어 \"리더\" 또는 \"회의자\", \"연사\", \"패널 참가자\", \"상호작용 청중\" 또는 \"원격 청취자\" 등 다양한 역할 이 가능하다. 다양한 이용 가능한 물리적 위치는 예를 들어 \"무대 위\", \"패널 내\", \"물리적으로 존재하는 청중 내\" 또는 \"물 리적으로 멀리 떨어진 청중 내\"일 수 있다. 가상의 위치는 물리적 위치 측면에서 정의될 수 있지만, 상기 물리적 위치와 부분적으로 겹칠 수 있는 가상 그 룹화도 포함될 수 있다. 예를 들어, 물리적으로 참석한 관객은 제1 및 제2 가상 그룹으로 나누어질 수 있고, 물 리적으로 참석한 일부 관객 참가자는 물리적으로 멀리 떨어져 있는 일부 관객 참가자와 함께 하나의 동일한 가 상 그룹으로 그룹화될 수 있다. 이러한 상호 작용 권리는 예를 들어 \"완전한 상호 작용\"(제한 없음), \"마이크 요청 후에만 말할 수 있음 \"(화상 회의 서비스에서 가상의 손 들기와 같은), \"공통 채팅에서는 말은 못하고 글은 쓸 수 있음\" 또는 \"보기/듣는 것 만\".일 수 있다. 어떤 경우에, 정의된 각 역할 및/또는 물리적/가상 위치는 특정 사전 결정된 상호 작용 권리의 관점에서 정의될 수 있다. 다른 경우에는 동일한 상호 작용 권한을 가진 모든 참가자가 그룹을 형성한다. 따라서 정의된 역할, 위치 및/또는 상호 작용 권리는 다양한 그룹 할당을 반영할 수 있으며, 경우에 따라 서로 다른 그룹이 분리되거 나 겹칠 수 있다. 이는 아래에 예시되어 있다. 본 명세서에 기술되고 도시되는 바와 같이, 비디오 통신은 적어도 부분적으로 비디오 통신 서비스에 의해 그리고 적어도 부분적으로 중앙 서버에 의해 제공될 수 있다. 본 명세서에서 용어가 사용되는 바와 같이, \"비디오 통신\"은 적어도 2개, 바람직하게는 적어도 3개 또는 심지어 적어도 4개의 비디오 스트림, 및 바람직하게는 하나 또는 여러 개의 혼합 또는 결합 디지털 비디오/오디오 스트 림을 생성하는 데 사용되고 다음에 한 명 또는 여러 명의 소비자(예를 들어, 논의된 유형의 참여 클라이언트)에 의해 소비되어, 비디오 및/또는 오디오를 통한 비디오 통신에 기여할 수도 있고 그렇지 않을 수도 있는 매칭 오 디오 스트림을 포함하는 대화형 디지털 통신 세션이다. 이러한 비디오 통신은 특정 대기 시간이나 지연이 있거 나 없이 실시간으로 이루어진다. 그러한 비디오 통신에는 적어도 한 명, 바람직하게는 적어도 2명, 심지어 적어 도 4명의 참가자가 비디오/오디오 정보를 제공하고 소비하는 대화형 방식으로 비디오 통신에 참여한다. 참여 클라이언트 중 적어도 하나 또는 모든 참여 클라이언트는 로컬 동기화 소프트웨어 기능을 포함할 수 있고, 이는 아래에서 더 자세히 설명된다. 비디오 통신 서비스는 아래에서 더 자세히 설명되는 바와 같이 공통 시간 기준을 포함하거나 그에 대한 액 세스를 가질 수 있다. 적어도 하나의 중앙 서버 각각은 해당 중앙 서버 외부의 개체들과 디지털 방식으로 통신하기 위한 각 각의 API를 포함할 수 있다. 그러한 통신은 입력과 출력이 모두 포함될 수 있다. 상기 중앙 서버와 같은 시스템은 또한 디지털 방식으로 통신하고 특히 외부에서 제공되는 비디오 스 트림과 같은 외부 정보 소스로부터 오디오 및/또는 비디오 스트림 데이터와 같은 디지털 정보를 수신하도 록 배열될 수 있다. 정보 소스가 \"외부\"라는 것은 중앙 서버로부터 또는 중앙 서버의 일부로서 제공되지 않는다는 것을 의미한다. 바람직하게는, 외부 정보 소스가 제공하는 디지털 데이터는 중앙 서버 와 독립적이며, 중앙 서버는 그 정보 내용에 영향을 미칠 수 없다. 예를 들어, 외부 정보 소스 는 공개 스포츠 이벤트, 진행 중인 뉴스 이벤트 또는 보고 등의 실시간 캡처된 비디오 및/또는 오디오일 수 있 다. 외부 정보 소스는 웹 카메라 등을 통해 캡쳐될 수도 있지만, 참여 클라이언트 중 어느 하나에 의 해서는 캡쳐될 수 없다. 따라서 이러한 캡처된 비디오는 참여 클라이언트 중 어느 하나와 동일한 위치를 묘사할 수 있지만 참여 클라이언트 자체의 활동의 일부로 캡처되지는 않는다. 외부에서 제공되는 정보 소 스와 내부적으로 제공되는 정보 소스 사이의 한 가지 가능한 차이점은, 내부적으로 제공되는 정보 소 스가 위에 정의된 유형의 비디오 통신에 대한 참가자로서, 및 그들의 능력으로 참가로서 제공되는 반면, 외부에 서 제공되는 정보 소스는 그렇지 않고 대신 상기 화상 회의 외부에 있는 컨텍스트의 일부로 제공된다. 오디오 및/또는 비디오 스트림과 같은 상기 유형의 디지털 정보를 중앙 서버에 병렬로 제공하는 여러 외부 정보 소스가 또한 있을 수 있다. 도 1에 도시된 바와 같이, 각각의 참여 클라이언트는 설명된 바와 같이 해당 참여 클라이언트에 의해 비디오 통신 서비스에 제공되는 각각의 정보(비디오 및/또는 오디오) 스트림의 소스를 구성할 수 있 다. 중앙 서버와 같은 시스템은 외부 소비자와 디지털 방식으로 통신하고, 특히 외부 소비자에 게 디지털 정보를 방출하도록 추가로 구성될 수 있다. 예를 들어, 중앙 서버에 의해 생성된 디지털 비디오 및/또는 오디오 스트림은 상기 API를 통해 하나 또는 여러 외부 소비자에게 실시간 또는 거의 실시간 으로 연속적으로 제공될 수 있다. 다시 말하면, 소비자가 \"외부\"에 있다는 것은 소비자가 중앙 서버 의 일부로 제공되지 않거나, 상기 비디오 통신의 당사자가 아니라는 것을 의미한다. 달리 명시하지 않는 한, 본 명세서에서의 모든 기능과 통신은 디지털 및 전자적으로 제공되며, 적절한 컴퓨터 하드웨어에서 실행되는 컴퓨터 소프트웨어에 의해 영향을 받고 인터넷과 같은 디지털 통신 네트워크 또는 채널 을 통해 통신된다. 따라서, 도 1에 도시된 시스템 구성에서, 다수의 참여 클라이언트는 비디오 통신 서비스에 의해 제공되는 디지털 비디오 통신에 참여한다. 따라서 각 참여 클라이언트는 진행 중인 로그인, 세션 또는 비 디오 통신 서비스와 유사한 것을 가질 수 있으며, 비디오 통신 서비스가 제공하는 하나의 진행 중인 비디오 통신에 참여할 수 있다. 즉, 비디오 통신은 참여 클라이언트 사이에서 \"공유\"되므로 대응하는 인간 참가자에 의해서도 공유된다. 도 1에서, 중앙 서버는 참여 클라이언트에 대응하지만 인간 참가자와 연관되지 않은 자동화 클 라이언트인 자동 참여 클라이언트를 포함한다. 대신에, 자동 참여 클라이언트는 비디오 통신 서비스 에 참여 클라이언트로 추가되어 참여 클라이언트와 동일한 공유 비디오 통신에 참여하게 된다. 이러 한 참여 클라이언트로서, 자동 참여 클라이언트는 비디오 통신 서비스에 의해 진행 중인 비디오 통신 의 일부로 제공되는 연속적으로 생성되는 디지털 비디오 및/또는 오디오 스트림(들)에 대한 액세스가 승인되고, 자동 참여 클라이언트를 통해 중앙 서버에 의해 소비될 수 있다. 바람직하게, 자동 참여 클라이언트 는 비디오 통신 서비스로부터 각 참여 클라이언트에 배포되거나 배포될 수 있는 공통 비디오 및 /또는 오디오 스트림; 하나 또는 여러 참여 클라이언트 각각으로부터 비디오 통신 서비스에 제공되고 원시 또는 수정된 형태로 비디오 통신 서비스에 의해 모든 또는 요청한 참여 클라이언트에게 중계되 는 각각의 비디오 및/또는 오디오 스트림; 및/또는 공통 시간 참조를 수신한다. 중앙 서버는 아래 설명된 처리를 위해, 자동 참여 클라이언트로부터 및 가능하게는 상기 외부 정보 소스(들)로부터 상기 유형의 비디오 및/또는 오디오 스트림을 수신한 다음에, API를 통해 공유된 것 과 같이 생성된 비디오 스트림을 제공하도록 구성된 수집 기능을 포함할 수 있다. 예를 들어, 이렇게 생성 된 비디오 스트림은 외부 소비자 및/또는 비디오 통신 서비스에 의해 소비되고 다음에 비디오 통신 서비스에 의해 참여 클라이언트 중 모든 요청자에게 배포될 수 있다. 도 2는 도 1과 유사하지만, 자동 클라이언트 참가자를 사용하는 대신에, 중앙 서버가 비디오 통신 서 비스의 API를 통해 진행 중인 비디오 통신으로부터 비디오 및/또는 오디오 스트림 데이터를 수신한다. 도 3 역시 도 1과 유사하지만, 비디오 통신 서비스를 도시하지 않는다. 이 경우, 참여 클라이언트는 중앙 서버의 API와 직접 통신하며, 예를 들어 비디오 및/또는 오디오 스트림 데이터를 중앙 서버 에 제공하고/하거나 중앙 서버로부터 비디오 및/또는 오디오 스트림 데이터를 수신한다. 그 다음에, 생성된 공유 스트림은 외부 소비자 및/또는 클라이언트 참가자 중 하나 또는 여러 명에게 제공될 수 있다. 도 4는 중앙 서버를 더 자세히 도시한다. 예시된 바와 같이, 상기 수집 기능은 하나 또는 바람직하게 는 여러 개의 형식별 수집 기능(131a)을 포함할 수 있다. 상기 포맷별 수집 기능(131a) 각각은 미리 결정된 바 이너리 인코딩 포맷 및/또는 미리 결정된 스트림 데이터 컨테이너와 같은 미리 결정된 포맷을 갖는 비디오 및/ 또는 오디오 스트림을 수신하도록 배열될 수 있으며, 특히 상기 형식의 이진 비디오 및/또는 오디오 데이터를 개별 비디오 프레임, 비디오 프레임 시퀀스 및/또는 시간 슬롯으로 구문 분석하도록 배열될 수 있다. 중앙 서버는 수집 기능으로부터 이진 스트림 데이터와 같은 비디오 및/또는 오디오 스트림 데이터를 수신하고 수신된 데이터 스트림 중 각각의 개별적인 하나에 대해 각각의 이벤트 감지를 수행하도록 구성된 이벤 트 감지 기능을 더 포함할 수 있다. 이벤트 감지 기능은 상기 이벤트 감지을 수행하기 위한 A1(인공 지능) 구성요소(132a)를 포함할 수 있다. 이벤트 감지는 수집된 개별 스트림을 처음으로 시간 동기화하지 않고 발생할 수 있다. 중앙 서버는 수집 기능에 의해 제공되는 데이터 스트림을 시간 동기화하도록 구성되고, 이벤트 감지 기능에 의해 처리될 수 있는 동기화 기능을 더 포함한다. 동기화 기능은 상기 시간 동기화를 수 행하기 위한 Al 구성요소(133a)를 포함할 수 있다. 중앙 서버는 수신된 데이터 스트림 중 적어도 하나, 많은 경우에는 적어도 2개, 예를 들어 적어도 3개 또 는 심지어 적어도 4개, 예를 들어, 전체의 조합에 기초하여 패턴 감지를 수행하도록 구성되는, 패턴 감지 기능 을 더 포함할 수 있다. 패턴 감지는 또한 이벤트 감지 기능에 의해 상기 데이터 스트림 중 각각의 개 별적인 하나에 대해 검출된 하나, 또는 어떤 경우에는 적어도 2개 이상의 이벤트에 기초할 수 있다. 상기 패턴 감지 기능에 의해 고려된 이러한 감지된 이벤트는 각각의 수집된 스트림에 대해 시간에 걸쳐 분포될 수 있 다. 패턴 감지 기능은 상기 패턴 감지를 수행하기 위한 Al 구성요소(134a)를 포함할 수 있다. 패턴 감지는 위에서 논의된 그룹화에 더욱 기초할 수 있고, 특히 하나의 그룹에 대해서만; 모든 그룹이 아닌 일부 그룹에 대 해서만; 또는 모든 그룹과 관련하여 발생하는 특정 패턴을 감지하도록 구성된다. 중앙 서버는 수집 기능으로부터 제공된 데이터 스트림에 기초하고, 가능하게는 임의의 검출된 이벤트 및/또는 패턴에 더 기초하여 공유 디지털 비디오 스트림과 같은 생성된 디지털 비디오 스트림을 생성하도록 구 성된 생성 기능을 더 포함한다. 이러한 생성된 비디오 스트림은 수집 기능에 의해 제공되는 원시, 재 형식화 또는 변환된 비디오 스트림 중 하나 또는 여러 개를 포함하도록 생성된 비디오 스트림을 적어도 포함할수 있고, 또한 해당 오디오 스트림 데이터를 포함할 수도 있다. 아래 예시된 바와 같이, 여러 개의 비디오 스트 림이 생성될 수 있고, 이 때 이렇게 생성된 비디오 스트림 중 하나는 위에서 논의된 방식으로 생성될 수 있지만, 또한 이미 생성된 다른 비디오 스트림에 기초할 수도 있다. 생성된 모든 비디오 스트림은 바람직하게는 연속적으로, 바람직하게는 거의 실시간으로 생성된다(아래에서 논의 되는 유형의 대기 시간 및 지연에 대해서는 제외함). 중앙 서버는 상술된 바와 같이 API를 통해 해당 생성된 디지털 비디오 스트림을 발행하도록 구성된 발행 기능을 더 포함할 수 있다. 도 1, 2 및 3은 본 명세서에 설명된 원리를 구현하기 위해 특히 본 발명에 따른 방법을 제공하기 위해 중앙 서 버가 어떻게 사용될 수 있는지에 대한 세 가지 다른 예를 도시하지만, 하나 또는 여러 개의 비디오 통신 서비스를 사용하거나 사용하지 않고 다른 구성도 가능하다는 것에 유의한다. 따라서, 도 5는 상기 생성된 디지털 비디오 스트림을 제공하는 방법을 도시한다. 도 6a-6f는 도 5에 도시된 방 법의 단계로부터 발생하는 다양한 디지털 비디오/오디오 데이터 스트림 상태를 도시한다. 제1 단계에서 방법이 시작된다. 후속 수집 단계에서, 각각의 기본 디지털 비디오 스트림(210, 301)은 상기 수집 기능에 의해 상기 디지털 비디오 소스(120, 300) 중 적어도 2개로부터 수집된다. 이러한 기본 데이터 스트림(210, 301) 각각은 오디오 부 분 및/또는 비디오 부분을 포함할 수 있다. 이러한 맥락에서, \"비디오\"는 그러한 데이터 스트림의 동 영상 및/또는 정지 이미지 콘텐츠를 의미하는 것으로 이해된다. 각각의 기본 데이터 스트림(210, 301)은 임의의 비디오/오디오 인코딩 사양에 따라 인코딩될 수 있고(해당 기본 스트림(210, 301)을 제공하는 개체에 의해 사용 되는 각각의 코덱을 사용), 인코딩 형식은 하나의 동일한 비디오 통신에서 동시에 사용되는 상기 기본 스트림 (210, 301) 중 서로 다른 스트림에 걸쳐 다를 수 있다. 경품 데이터 스트림(210, 301) 중 적어도 하나, 예를 들 어, 모두는 이진 데이터 스트림으로 제공되며, 아마도 그 자체로 종래의 데이터 컨테이너 데이터 구조로 제공될 수 있는 것이 바람직하다. 1차 데이터 스트림(210, 301) 중 적어도 하나, 예를 들어, 적어도 2개 또는 심지어 전부가 각각의 라이브 비디오 녹화로서 제공되는 것이 바람직하다. 기본 스트림(210, 301)은 수집 기능에 의해 수신될 때 시간 측면에서 비동기화될 수 있다는 것에 유의한다. 이것은 이들이 서로 다른 대기 시간 또는 지연과 연관되어 있다는 것을 의미할 수 있다. 예를 들어, 2개의 기본 비디오 스트림(210, 301)이 라이브 녹화인 경우, 이것은 이들이 수집 기능에 의해 수신될 때 녹화 시간과 관련하여 서로 다른 대기 시간과 연관되어 있다는 것을 의미할 수 있다. 수집 단계는 도 6a 및 6b에 도시된다. 도 6b에서, 또한 수집 기능이 각각의 기본 비디오 스트림(210, 30 1)을 번들 오디오/비디오 정보로서 또는 관련 비디오 스트림 데이터로부터 분리된 오디오 스트림 데이터로서 저 장할 수 있는 방법에 대해 설명된다. 도 6b는 기본 비디오 스트림(210, 301) 데이터가 개별 프레임 또는 프레임의 컬렉션/클러스터로 저장되는 방법을 도시하고, 여기서 \"프레임\"은 이미지 데이터 및/또는 관련 오디오 데이터의 시간 제한된 부분을 의미하고, 예를 들어, 각 프레임은 동영상 비디오 콘텐츠를 형성하는 것과 함께 개별 정지 이미지이거나 연속적인 일련의 이미지(예를 들어, 이 일련의 이미지는 최대 1초의 동영상을 구성함) 를 형성한다. 이벤트 감지 기능에 의해 수행되는 후속 이벤트 감지 단계에서, 상기 기본 디지털 비디오 스트림(210, 301)은 상기 이벤트 감지 기능 및 특히 상기 AI 구성요소(132a)에 의해 분석되어 제1 이벤트 세트로부터 선택된 적어도 하나의 이벤트를 검출한다. 이는 도 6c에 도시된다. 이 이벤트 감지 단계는 적어도 하나, 예를 들어 적어도 두 개, 전체 기본 비디오 스트림(210, 301)에 대해 수행 될 수 있고, 각각의 기본 비디오 스트림(210, 301)에 대해 개별적으로 수행될 수 있다는 것이 바람직하다. 다시 말해서, 이벤트 감지 단계는 바람직하게는 해당 특정 기본 비디오 스트림(210, 301)의 일부로서 포함된 정보만 을 고려하여, 특히 다른 기본 비디오 스트림의 일부로 포함된 정보를 고려하지 않고, 상기 개별 기본 비디오 스 트림(210, 301)에 대해 발생한다. 더욱이, 이벤트 감지는 바람직하게 여러 기본 비디오 스트림(210, 301)과 관 련된 공통 시간 기준을 고려하지 않고 발생한다. 반면에, 이벤트 감지는 특정 시간 간격, 예를 들어 0초보다 긴, 예를 들어, 적어도 0.1초, 적어도 1초인 기본 비디오 스트림의 과거 시간 간격에 걸쳐 개별적으로 분석된 해당 기본 비디오 스트림의 일부로서 포함된 정보를 고려하는 것이 바람직하다. 이벤트 감지는 상기 기본 비디오 스트림(210, 301)의 일부로서 포함된 오디오 및/또는 비디오 데이터에 포함된 정보를 고려할 수 있다. 상기 제1 이벤트 세트는 임의의 수의 이벤트 유형, 예를 들어, 해당 기본 비디오 스트림(210, 301)을 구성하거 나 그 일부인 슬라이드 프리젠테이션의 슬라이드 변경; 해당 기본 비디오 스트림(210, 301)을 제공하는 소스 (120, 300)의 연결 품질 변경, 이로 인해 이미지 품질 변경, 이미지 데이터 손실 또는 이미지 데이터 회복이 발 생함; 및 예를 들어 영상 속 사람이나 사물의 움직임, 영상 속 조명의 변화, 오디오의 갑작스러운 날카로운 소 음, 오디오 품질의 변화 등과 같은, 해당 기본 비디오 스트림(210, 301)에서 감지된 움직임 물리적 이벤트를 포 함할 수 있다. 이는 완전한 목록으로 의도한 것은 아니며, 이들 예시는 현재 설명된 원리의 적용 가능성을 이해 하기 위해 제공되었다는 것을 알 수 있다. 동기화 기능에 의해 수행되는 후속 동기화 단계에서, 기본 디지털 비디오 스트림은 시간 동기화된다. 이러한 시간 동기화는 공통 시간 기준에 관한 것일 수 있다. 도 6d에 도시된 바와 같이, 시간 동기화는 예 를 들어 상기 공통 시간 기준을 사용하여 기본 비디오 스트림(210, 301)을 서로 관련하여 정렬하는 것을 포함할 수 있으므로, 이들이 결합되어 시간 동기화된 컨텍스트를 형성할 수 있다. 공통 시간 기준은 데이 터 스트림, 하트비트 신호 또는 기타 펄스 데이터, 또는 개별 기본 비디오 스트림(210, 301) 각각에 적용 가능 한 시간 앵커일 수 있다. 공통 시간 기준은 해당 기본 비디오 스트림(210, 301)의 정보 콘텐츠가 공통 시간 축 에 대한 공통 시간 기준과 명확하게 관련될 수 있도록 하는 방식으로 개별 기본 비디오 스트림(210, 301) 각각 에 적용될 수 있다. 즉, 공통 시간 기준은 기본 비디오 스트림(210, 301)이 시간 이동을 통해 정렬되어 현재의 의미에서 시간 동기화되도록 허용할 수 있다. 다른 실시 예에서, 시간 동기화는 측정에 기초하는 것과 같이 해 당 기본 비디오 스트림(210, 301) 사이의 시간 차이에 대해 알려진 정보에 기초할 수 있다. 도 6d에 도시된 바와 같이, 시간 동기화는 하나 또는 여러 개의 타임스탬프를, 각각의 기본 비디오 스트림 (210, 301)에 대해서는, 예를 들어, 공통 시간 기준과 관련하여, 또는 각 비디오 스트림(210, 301)에 대해 서는 다른 비디오 스트림과 관련되거나 다른 비디오 스트림(210, 301)과 관련하여 결정하는 단계를 포함할 수 있다. 패턴 감지 기능에 의해 수행되는 후속 패턴 감지 단계에서, 시간 동기화된 기본 디지털 비디오 스트림 (210, 301)은 제1 패턴 세트로부터 선택된 적어도 하나의 패턴을 검출하기 위해 분석된다. 이는 도 6e에 도시된다. 이벤트 감지 단계와 대조적으로, 패턴 감지 단계는 공동으로 고려되는 시간 동기화된 기본 비디오 스트림(210, 301) 중 적어도 2개의 부분으로 포함된 비디오 및/또는 오디오 정보에 기초하여 수행되는 것이 바람직할 수 있 다. 상기 제1 패턴 세트는 임의의 수의 패턴 유형, 예를 들어, 여러 참가자가 상호 교환적으로 또는 동시에 말하는 것; 또는 프리젠테이션 슬라이드 변경이 여러 참가자가 말하는 것과 같이 다른 이벤트로 동시에 발생하는 것을 포함할 수 있다. 이 목록은 배타적인 것이 아니고 설명을 위한 것이다. 대안적인 실시 예에서, 감지된 패턴은 상기 기본 비디오 스트림(210, 301) 중 여러 개에 포함된 정보와 관 련되지 않고 상기 기본 비디오 스트림(210, 301) 중 하나에만 포함된 정보와 관련될 수 있다. 이 경우에, 이러 한 패턴은 적어도 두 개의 감지된 이벤트, 예를 들어 두 번 이상 연속으로 감지된 프레젠테이션 슬라 이드 변경 또는 연결 품질 변경에 걸쳐 있는 단일 기본 비디오 스트림(210, 301)에 포함된 비디오 및/또는 오디 오 정보에 기초하여 감지된다. 일 예로서, 시간이 지남에 따라 서로 빠르게 이어지는 여러 연속 슬라이드 변경 은 감지된 각 슬라이드 변경 이벤트에 대한 하나의 개별 슬라이드 변경 패턴과 달리, 하나의 단일 슬라이드 변 경 패턴으로 감지될 수 있다. 제1 이벤트 세트 및 상기 제1 패턴 세트는 각각의 매개변수 세트 및 매개변수 간격을 사용하여 정의된 미리 결 정된 유형의 이벤트/패턴을 포함할 수 있다는 것을 알 수 있다. 아래에 설명되는 바와 같이, 상기 세트의 이벤 트/패턴은 또한 또는 추가적으로 다양한 AI 도구를 사용하여 정의되고 감지될 수 있다. 생성 기능에 의해 수행되는 후속 생성 단계에서, 공유 디지털 비디오 스트림은 시간 동기화된 기본 디지 털 비디오 스트림(210, 301)의 연속적으로 고려되는 프레임 및 상기 검출된 패턴에 기초하여 출력 디 지털 비디오 스트림으로서 생성된다. 이하 상세히 설명되는 바와 같이, 본 발명은 출력 디지털 비디오 스트림과 같은 비디오 스트림의 완전 자 동 생성을 가능하게 한다. 예를 들어, 이러한 생성은 어떤 기본 비디오 스트림(210, 301)으로부터 어떤 비디오 및/또는 오디오 정보를 그 러한 출력 비디오 스트림; 출력 비디오 스트림의 비디오 화면 레이아웃; 시간에 따른 다양한 용도 또 는 레이아웃 사이의 전환 패턴 등에서 어느 정도까지 사용할 것인지에 대한 선택을 포함할 수 있다. 이는 또한 예를 들어, (공통 시간 기준에 대해서와 같이) 시간 동기화될 수 있고 출력 비디오 스트림(23 0)의 생성 시 시간 동기화된 기본 비디오 스트림(210, 301)과 함께 사용될 수 있는 추가적인 디지털 비디오 정 보 스트림과 같은, 시간 관련(공통 시간 기준과 관련될 수 있음) 디지털 비디오 정보의 하나 또는 여 러 개의 추가 부분을 보여주는 도 6f에 도시된다. 예를 들어, 추가 스트림은 예를 들어 감지된 패턴을 동 적으로 기반으로 하는 것; 비디오 통화를 위해 계획된 시간 일정 등과 같이, 사용할 임의의 비디오 및/또는 오 디오 특수 효과에 관한 정보를 포함할 수 있다. 게시 기능에 의해 수행되는 후속 게시 단계에서, 생성된 출력 디지털 비디오 스트림은 전술한 바와 같이 생성된 디지털 비디오 스트림의 소비자(110, 150)에게 연속적으로 제공된다. 생성된 디지털 비디오 스트림 은 비디오 통신 서비스 등을 통해 하나 또는 여러 참여 클라이언트에 제공될 수 있다. 후속 단계에서, 방법은 종료된다. 그러나 먼저 이 방법은 연속적으로 제공되는 스트림으로서 출력 비디오 스트 림을 생성하기 위해 도 5에 도시된 바와 같이 임의의 횟수만큼 반복될 수 있다. 바람직하게, 출력 비디오 스트림은 실시간 또는 거의 실시간으로 (모든 단계에서 추가되는 총 대기 시간을 고려) 및 연속적으로(더 많은 정보가 제공되면 즉시 게시가 이루어지지만 아래 설명된 의도적으로 추가된 대기 시간 또는 지연은 계산되 지 않음) 소비되도록 생성된다. 이러한 방식으로, 출력 비디오 스트림은 대화형 방식으로 소비될 수 있으 므로, 출력 비디오 스트림은 비디오 통신 서비스로 다시 피드백되거나 기본 비디오 스트림의 생 성을 위한 기반을 형성하는 다른 컨텍스트로 피드백되어 폐쇄 피드백 루프를 형성하기 위해 수집 기능으로 다시 공급될 수 있거나; 출력 비디오 스트림이 다른(시스템 외부 또는 적어도 중앙 서버 외부) 컨텍스트로 소비될 수 있지만 실시간 대화형 비디오 통신의 기초를 형성하도록 할 수 있다. 위에서 언급한 바와 같이, 일부 실시 예에서는 상기 기본 디지털 비디오 스트림(210, 301) 중 적어도 2개, 예를 들어 적어도 3개, 적어도 4개 또는 심지어 적어도 5개는 상기 비디오 통신 서비스에 의해 제공되는 것과 같은 공유 디지털 비디오 통신의 일부로 제공되고, 비디오 통신은 해당 기본 디지털 비디오 스트림을 제공 하는 각각의 원격 연결된 참여 클라이언트를 포함한다. 그런 경우에, 수집 단계는 예를 들어, 자동 참여 클라이언트를 통해 (다음에 해당 비디오 통신 서비스 내로부터 비디오 및/또는 오디오 스트림 데이터 에 대한 액세스가 승인됨); 및/또는 비디오 통신 서비스의 API를 통해, 공유 디지털 비디오 통신 서 비스 자체로부터 상기 기본 디지털 비디오 스트림 중 적어도 하나를 수집하는 단계를 포함할 수 있다. 또한, 이 경우 및 다른 경우, 수집 단계는 공유 디지털 비디오 통신 서비스 외부에 있는 정보 소스로 부터 수집된 각각의 외부 디지털 비디오 스트림으로서 상기 기본 디지털 비디오 스트림(210, 301) 중 적어 도 하나를 수집하는 단계를 포함할 수 있다. 이러한 사용되는 외부 비디오 소스 중 하나 또는 여러 개는 또한 중앙 서버 외부에 있을 수도 있다는 점에 유의한다. 일부 실시 예에서, 기본 비디오 스트림(210, 301)은 동일한 방식으로 포맷되지 않는다. 이러한 서로 다른 포맷 은 서로 다른 유형의 데이터 컨테이너(AVI 또는 MPEG 등)로 수집 기능에 전달되는 형태일 수 있지만, 바람 직한 실시 예에서 기본 비디오 스트림(210, 301) 중 적어도 하나는 이탈하는 비디오 인코딩; 이탈하는 고정 또 는 가변 프레임 속도; 이탈하는 종횡비; 이탈하는 비디오 해상도; 및/또는 이탈하는 오디오 샘플 속도를 갖는 상기 이탈하는 기본 디지털 비디오 스트림(210, 301)의 관점에서, (상기 기본 비디오 스트림(210, 301) 중 적어 도 하나와 비교하여) 이탈 포맷에 따라 포맷된다. 수집 기능은 수집된 모든 기본 비디오 스트림(210, 301)에서 발생하는 모든 인코딩 형식, 컨테이너 표준 등을 읽고 해석하도록 미리 구성되어 있다. 이는 본 명세서에 설명된 처리를 수행하는 것을 가능하게 하며 프로 세스의 상대적으로 늦은 시점까지 어떤 디코딩도 요구하지 않는다(예를 들어, 해당 기본 스트림이 해당 버퍼에 배치된 후, 이벤트 감지 단계가 끝날 때까지 또는 이벤트 감지 단계가 끝날 때까지). 그러나 기본 비디오 피드 (210, 301) 중 하나 또는 여러 개가 수집 기능이 디코딩 없이 해석할 수 없는 코덱을 사용하여 인코딩되는 드문 경우에, 수집 기능은 이러한 기본 비디오 스트림(210, 301)의 디코딩 및 분석을 수행한 후, 예를 들 어 이벤트 감지 기능에 의해 처리될 수 있는 형식으로의 변환을 수행하도록 배열될 수 있다. 이 경우에도 현 단계에서 재인코딩을 수행하지 않는 것이 바람직하다는 점에 유의한다. 예를 들어, 비디오 통신 서비스에 의해 제공되는 것과 같이, 다자간 비디오 이벤트로부터 가져오는 기본 비디오 스트림은 일반적으로 낮은 대기 시간에 대한 요구 사항이 있으므로 일반적으로 참가자가 효과 적인 통신을 할 수 있도록 가변 프레임 속도 및 가변 픽셀 해상도와 연관된다. 즉, 전체 비디오 및 오디오 품질 이 낮은 대기 시간을 위해 필요에 따라 저하된다. 반면, 외부 비디오 피드는 일반적으로 더 안정적인 프레임 속도, 더 높은 품질을 갖지만, 이에 따라 더 높 은 대기 시간을 가질 수 있다. 따라서, 비디오 통신 서비스는 매 순간 외부 비디오 소스와는 다른 인코딩 및/또는 컨테이너를 사용 할 수 있다. 따라서 이 경우에 설명된 분석 및 비디오 생성 프로세스는 서로 다른 형식의 스트림(210, 301)을 결합된 경험을 위한 새로운 스트림으로 결합해야 한다. 상술된 바와 같이, 수집 기능은 형식별 수집 기능(131a)의 세트를 포함할 수 있고, 각각은 특정 형식의 기 본 비디오 스트림(210, 301)을 처리하도록 배열되어 있다. 예를 들어, 이러한 형식별 수집 기능(131a) 각각은 Windows® Media® 또는 DivX®와 같이, 서로 다른 비디오 각각의 인코딩 방법/코덱을 사용하여 인코딩된 기본 비디오 스트림(210, 301)을 처리하도록 배열될 수 있다. 그러나 바람직한 실시 예에서, 수집 단계는 기본 디지털 비디오 스트림(210, 301) 중 적어도 2개 또는 모두를 공통 프로토콜로 변환하는 단계를 포함한다. 이 맥락에서 사용된 바와 같이, \"프로토콜\"이라는 용어는 디지털 비디오/오디오 스트림에 포함된 정보를 저장하 는 방법을 지정하는 정보 구조 표준 또는 데이터 구조를 나타낸다. 그러나 공통 프로토콜은 바람직하게는 디지 털 비디오 및/또는 오디오 정보를 바이너리 레벨(즉, 사운드 및 이미지 자체를 지시하는 인코딩/압축 데이터)로 저장하는 방법을 지정하지 않고, 대신에 그러한 데이터를 저장하기 위해 미리 결정된 형식의 구조를 형성한다. 다시 말해서, 공통 프로토콜은 아마도 바이너리 형식 바이트 시퀀스를 연결 및/또는 분리하는 것 외에는 기존 바이너리 형식을 전혀 수정하지 않음으로써, 디지털 비디오 데이터를 저장과 관련하여 디지털 비디오 디코딩 또 는 디지털 비디오 인코딩을 수행하지 않고 원시 바이너리 형식으로 저장하도록 규정한다. 대신에, 해당 기본 비 디오 스트림(210, 301)의 원시(인코딩/압축된) 바이너리 데이터 콘텐츠는 프로토콜에 의해 정의된 데이터 구조 에 이 원시 바이너리 데이터를 다시 압축하는 동안 유지된다. 일부 실시 예에서, 공통 프로토콜은 비디오 파일 컨테이너 형식을 정의한다. 도 7은 각각의 형식별 수집 기능(131a)에 의해 재구성되고 상기 공통 프로토콜을 사용하여 도 6a에 도시된 기본 비디오 스트림(210, 301)을 예로서 도시한다. 따라서, 공통 프로토콜은 디지털 비디오 및/또는 오디오 데이터를, 바람직하게는 해당 기본 비디오 스트림 (210, 301)과 관련된 타임 라인을 따라 개별적이고 연속적인 데이터 세트로 나뉜 데이터 세트에 저장하는 것을 규정한다. 이러한 각 데이터 세트는 하나 또는 여러 개의 비디오 프레임과 관련 오디오 데이터를 포함할 수 있다. 공통 프로토콜은 또한 저장된 디지털 비디오 및/또는 오디오 데이터 세트와 관련하여 지정된 시점과 연관된 메타데이터를 저장하도록 규정할 수 있다. 메타데이터는 예를 들어, 원시 바이너리 데이터; 비디오 데이터의 해상도; 비디오 프레임 속도; 프레임 속 도 가변성 플래그; 비디오 해상도; 비디오 종횡비; 오디오 압축 알고리즘; 또는 오디오 샘플링 속도를 생성하는 데 사용되는 디지털 비디오 인코딩 방법 또는 코덱과 관련하여, 해당 기본 디지털 비디오 스트림의 원시 바이너리 포맷에 관한 정보를 포함할 수 있다. 메타데이터는 또한 해당 기본 비디오 스트림(210, 301)의 시간 참조 또는 위에서 논의된 바와 같은 다른 비디오 스트림과 관련된 저장된 데이터의 타임스탬프에 대한 정 보를 포함할 수 있다. 상기 공통 프로토콜과 결합하여 상기 형식별 수집 기능(131a)을 사용하면 수신된 비디오/오디오 데이터를 디코딩/재인코딩하여 대기 시간을 추가하지 않고 기본 비디오 스트림(210, 301)의 정보 콘텐츠를 신속하게 수집 하는 것이 가능해진다. 따라서, 수집 단계는 해당 기본 비디오 스트림(210, 301)을 구문 분석하고 관련 메타데이터와 함께 공통 프로토 콜을 사용하여 구문 분석된 원시 및 바이너리 데이터를 데이터 구조에 저장하기 위해서, 서로 다른 이진 비디오 및/또는 오디오 인코딩 형식을 사용하여 인코딩되는 기본 디지털 비디오 스트림(210, 301)을 수집하기 위해 상기 형식별 수집 기능(131a) 중 서로 다른 기능을 사용하는 것을 포함할 수 있다. 당연하게도, 어떤 형식별 수집 기능(131a)이 어떤 기본 비디오 스트림(210, 301)에 사용할지에 대한 결정은 해당 각 기본 비디오 스트림(210, 301)의 미리 결정된 및/또는 동적으로 검출된 속성에 기초하여 수집 기능에 의해 수행될 수 있다. 따라서 수집된 각각의 기본 비디오 스트림(210, 301)은 중앙 서버의 RAM 메모리 버퍼와 같은 그 자신의 별 도 메모리 버퍼에 저장될 수 있다. 따라서 각 형식별 수집 기능(131a)에 의해 수행되는 기본 비디오 스트림(210, 301)을 변환하는 단계는 이렇게 변환된 각각의 기본 디지털 비디오 스트림(210, 301)의 원시 이진 데이터를 상기 더 작은 데이터 세트의 정렬된 세트로 분할하는 단계를 포함할 수 있다. 게다가, 상기 변환 단계는 또한 예를 들어 상기 공통 시간 기준과 관련하여, 상기 작은 세트의 각각 (또는 해당 기본 스트림(210, 301)의 각각의 타임 라인을 따라 정기적으로 분포된 서브세트와 같은 서브세트)을 공유 타임 라인을 따른 각각의 시간과 연관시키는 단계를 포함할 수 있다. 이러한 연관시키는 단계는 아래 설명 된 기본 방식 중 하나 또는 다른 방식으로 원시 바이너리 비디오 및/또는 오디오 데이터를 분석하여 수행될 수 있으며, 기본 비디오 스트림(210, 301)의 후속 시간 동기화를 수행할 수 있도록 수행될 수 있다. 사용되는 공통 시간 참조 유형에 따라, 각각의 데이터 세트의 이러한 연관의 적어도 일부는 또한 또는 대신에 동기화 기 능에 의해 수행될 수 있다. 후자의 경우, 수집 단계는 대신 해당 기본 스트림(210, 301)에 특정한 타임 라 인의 각각의 시간과 더 작은 세트의 각각 또는 서브세트를 연관시키는 단계를 포함할 수 있다. 일부 실시 예에서, 수집 단계는 또한 기본 비디오 스트림(210, 301)으로부터 수집된 원시 바이너리 비디오 및/ 또는 오디오 데이터를 균일한 품질 및/또는 업데이트 빈도로 변환하는 단계를 포함한다. 이는 필요에 따라 기본 디지털 비디오 스트림(210, 301)의 원시 바이너리 디지털 비디오 및/또는 오디오 데이터를, 일반적인 비디오 프 레임 속도로; 일반적인 비디오 해상도로; 또는 일반적인 오디오 샘플링 속도로 다운 샘플링 또는 업 샘플링하는 단계를 포함할 수 있다. 이러한 리샘플링은 전체 디코딩/재인코딩을 수행하지 않고 수행될 수 있거나 심지어 어 떤 디코딩도 전혀 수행하지 않고 수행될 수 있으며, 이는 해당 형식 특정 수집 기능(131a)은 올바른 이진 인코 딩 대상 형식에 따라 원시 이진 데이터를 직접 처리할 수 있기 때문인 것에 유의한다. 상기 기본 디지털 비디오 스트림(210, 301) 각각은 위에서 설명한 바와 같이 개별 프레임 또는 프레임 의 시퀀스로서 개별 데이터 저장 버퍼에 저장될 수 있으며, 또한 각각 상기 공통 시간 기준과 연관된 대응 타임 스탬프와 연관되어 있다. 이러한 원리를 설명하기 위해 제공된 구체적인 예에서, 비디오 통신 서비스는 동시 참가자가 참여하 는 비디오 회의를 실행하는 Microsoft® Teams®이다. 자동 참가 클라이언트는 TeamsTeems® 회의에 회의 참가자로 등록된다. 그 다음에, 기본 비디오 입력 신호는 자동 참여 클라이언트를 통해 수집 기능에 의해 이용 가능 하고 획득된다. 이는 H264 형식의 원시 신호이며 모든 비디오 프레임에 대한 타임스탬프 정보를 포함한다. 관련 형식별 수집 기능(131a)은 구성 가능한 사전 정의된 TCP 포트에서 IP(클라우드의 LAN 네트워크)를 통해 원 시 데이터를 선택한다. 모든 Teems® 회의 참가자와 관련 오디오 데이터는 별도의 포트와 연결된다. 그런 다음 수집 기능은 오디오 신호(50Hz)의 타임스탬프를 사용하고 비디오 스트림을 각각의 개별 버퍼에 저장하기 전에 비디오 데이터를 25Hz의 고정 출력 신호로 다운샘플링한다. 말한 바와 같이, 공통 프로토콜은 원시 바이너리 형태로 데이터를 저장할 수 있다. 이는 매우 낮은 수준으 로 비디오/오디오 데이터의 원시 비트와 바이트를 처리하도록 설계될 수 있다. 바람직한 실시 예에서, 데이터는 일반 프로토콜에 단순 바이트 배열 또는 해당 데이터 구조(예: 슬라이스)로 저장된다. 이는 데이터가 기존 비디오 컨테이너에 전혀 포함될 필요가 없음(공통 프로토콜은 이러한 맥락에서 이러한 기존 컨테이너를 구 성하지 않음)을 의미한다. 또한 비디오 인코딩 및 디코딩은 계산량이 많은데, 이는 지연이 발생하고 값비싼 하 드웨어를 필요로 한다. 게다가 이 문제는 참가자 수에 따라 확장된다. 공통 프로토콜을 사용하여, 각 Teams® 회의 참가자와 관련된 기본 비디오 스트림 및 외부 비디 오 소스에 대해 수집 기능에서 메모리를 예약하고, 그런 다음 프로세스 중에 즉시 할당된 메모리 양 을 변경하는 것이 가능해진다. 이러한 방식으로, 입력 스트림 수를 변경하고 결과적으로 각 버퍼를 효과적으로 유지하는 것이 가능해진다. 예를 들어, 해상도, 프레임 속도 등과 같은 정보는 가변적일 수 있지만 공통 프로토 콜에 메타데이터로 저장될 수 있기 때문에, 이 정보는 필요에 따라 각 버퍼의 크기를 빠르게 조정하는 데사용될 수 있다. 다음은 현재 유형의 공통 프로토콜 사양의 예이다: 바이트 예 설명 1바이트 1 0=비디오; l=오디오 4바이트 1234567 버퍼 길이(int) 8바이트 424234234 수신 오디오/비디오 버퍼의타임스탬프 틱 단위로 측정, l틱 = 100ns(긴 정수) 1바이트 0 VideoColorFormat { NV12 = 0, Rgb24 = 1, Yuy2 = 2, H264 = 3 } 4바이트 720 비디오 프레임 픽셀 높이(정수) 4바이트 640 비디오 프레임 픽셀 너비(정수) 4바이트 25.0 비디오 프레임 속도 초당 프레임 수(부동) 1바이트 0 오디오는 무음? 1 = 사실; 0 = 거짓 1바이트 0 오디오 형식 { 0 = Pcml6K 1 = Pcm44KStereo } 1바이트 0 감지된 이벤트(있는 경우) 0 = 이벤트 없음 1, 2, 3 등=지정 유형의 이벤트 감지 30바이트 향후 사용을 위해 예약 8바이트 1000000 바이트 단위의 이진 데이터 길이 (긴 정수) 변수 0x87A879... 이 프레임의 원시 바이너리 비디오/오디오 데이터 4바이트 1234567 주 스피커 포트 4바이트 1234567 활성 발언자 위에서 \"감지된 이벤트가 있는 경우\" 데이터는 공통 프로토콜 260 사양의 일부로 포함되어 있다. 그러나 일부 실시 예에서, (감지된 이벤트에 관한) 이 정보는 대신 별도의 메모리 버퍼에 저장될 수 있다.일부 실시 예에서, 오버레이 또는 효과일 수 있는 적어도 하나의 추가 디지털 비디오 정보는 또한, 공통 시간 기준과 연관된 해당 타임 스탬프와 각각 연관된 개별 프레임 또는 프레임 시퀀스로서 각각의 개별 버 퍼에 저장된다. 위에서 예시한 바와 같이, 이벤트 감지 단계는 상기 공통 프로토콜을 사용하여 해당 이벤트가 검출된 기본 디지털 비디오 스트림(210, 301)과 연관된 검출된 이벤트를 설명하는 메타데이터를 저장하는 단 계를 포함할 수 있다. 이벤트 감지는 다양한 방법으로 수행될 수 있다. Al 구성요소(132a)에 의해 수행되는, 일부 실시 예에서, 이벤 트 감지 단계는 제1 훈련된 신경망 또는 기타 기계 학습 구성 요소가 이벤트 중 임의의 것을 자동으로 감 지하기 위해 기본 디지털 비디오 스트림(210, 301) 중 적어도 하나, 예를 들어, 여러 개 또는 심지어 전체를 개 별적으로 분석하는 단계를 포함한다. 이는 기본 비디오 스트림(210, 301) 데이터를, 관리형 분류에서는 사전 정 의된 이벤트 세트로 및/또는 비관리형 분류에서는 동적으로 결정된 이벤트 세트로 분류하는 A1 구성요소(132a) 를 포함할 수 있다. 일부 실시 예에서, 감지된 이벤트는 해당 기본 비디오 스트림(210, 301)에 포함되어 있거나 포함되어 있는 프리젠테이션의 프리젠테이션 슬라이드의 변경이다. 예를 들어, 프레젠테이션 발표자가 당시 청중에게 제공하고 있는 프레젠테이션의 슬라이드를 변경하기로 결정한 다면, 이것은 특정 시청자에게 흥미로운 것이 바뀔 수 있다는 것을 의미한다. 새로 표시된 슬라이드는 소위 \"나 비\" 모드에서 잠깐 볼 수 있는 가장 좋은 수준의 사진일 뿐일 수도 있다(예를 들어, 출력 비디오 스트림에 서 슬라이드를 발표자의 비디오와 나란히 표시함). 다르게, 이 슬라이드는 많은 세부 정보, 작은 글꼴 크기의 텍스트 등을 포함할 수 있다. 후자의 경우, 슬라이드는 전체 화면으로 표시되어야 하며 일반적으로 나타나는 시 간보다 다소 긴 시간 동안 표시되어야 한다. 이 경우 슬라이드가 프레젠테이션을 보는 사람에게는 발표자의 얼 굴보다 더 흥미로울 수 있기 때문에, 나비 모드는 적절하지 않을 수 있다. 실제로, 이벤트 감지 단계는 다음 중 적어도 하나를 포함할 수 있다: 첫째로, 이벤트는 감지된 슬라이드의 제1 이미지와 감지된 슬라이드의 다음 제2 이미지 간의 차이에 대한 이미지 분석을 기반으로 감지될 수 있다. 슬라이드를 보여주는 특성인 기본 비디오 스트림(220, 301)의 특성은 자체 기존 디지털 이미지 처리를 사용하여, 예를 들어 예를 들어 OCR(광학 문자 인식)과 함께 동작 감지를 사용 하여 자동으로 결정될 수 있다. 이것은 자동 컴퓨터 이미지 처리 기술을 사용하여 감지된 슬라이드가 실제로 슬라이드 변경으로 분류될 만큼 크 게 변경되었는지 확인하는 작업을 포함할 수 있다. 이는 RGB 색상 값과 관련하여 현재 슬라이드와 이전 슬라이 드 사이의 델타를 확인하여 수행할 수 있다. 예를 들어, 해당 슬라이드로 덮힌 화면 영역에서 RGB 값이 전역적 으로 얼마나 변경되었는지, 함께 속해 있고 동시에 변경되는 픽셀 그룹을 찾는 것이 가능한지 여부를 평가할 수 있다. 이러한 방식으로 관련 슬라이드 변경 사항을 감지하는 동시에 화면 전체에 표시된 컴퓨터 마우스 움직임 과 같은 관련 없는 변경 사항을 필터링할 수 있다. 이 접근 방식은 완전한 구성 가능성을 허용하고, 예를 들어 발표자가 다른 항목을 가리키기위해 컴퓨터 마우스를 사용하면서 무언가를 자세히 발표하려는 경우, 때로는 컴 퓨터 마우스 움직임을 캡처할 수 있는 것이 바람직하다. 둘째, 이벤트는 상기 제2 이미지 자체의 정보적 복잡성에 대한 이미지 분석을 기반으로 검출되어, 보다 구 체적으로 이벤트 유형을 결정할 수 있다. 이것은 예를 들어, 해당 슬라이드에 있는 텍스트 정보의 총량, 뿐만 아니라 관련 글꼴 크기를 평가하는 작업을 포함할 수 있다. 이는 딥러닝 기반 문자 인식 기술과 같은 기존 OCR 방법을 사용하여 수행될 수 있다. 평가된 비디오 스트림(210, 301)의 원시 바이너리 형식이 알려져 있기 때문에, 이는 먼저 비디오 데이터를 디코 딩하거나 재인코딩하지 않고 이진 도메인에서 직접 수행될 수 있다는 것에 유의한다. 예를 들어, 이벤트 감지 기능은 이미지 해석 서비스에 대한 관련 형식별 수집 기능을 호출할 수 있거나, 이벤트 감지 기능 자 체는 지원되는 다양한 원시 바이너리 비디오 데이터 형식에 대해, 예를 들어 개별 픽셀 수준에 대한 이미지 정 보를 평가하는 기능을 포함할 수도 있다. 또 다른 예에서, 감지된 이벤트는 참여 클라이언트와 디지털 비디오 통신 서비스와의 통신 연결 이 끊어진 것이다. 그 다음, 감지 단계는 상기 참여 클라이언트가 해당 참여 클라이언트에 대응하는 기본 디지털 비디오 스트림의 일련의 후속 비디오 프레임의 이미지 분석에 기초하여 통신 연결이 끊어졌음을 검출하는 단계를 포함할 수 있다. 참여 클라이언트는 서로 다른 물리적 위치와 서로 다른 인터넷 연결과 연관되어 있으므로, 누군가가 비디 오 통신 서비스 또는 중앙 서버에 대한 연결이 끊어지는 것을 발생할 수 있다. 이러한 상황에서, 생 성된 출력 비디오 스트림에서 검은 화면이나 빈 화면을 표시하는 것을 피하는 것이 바람직한다. 대신에, 이러한 연결 끊김은 사용된 2개의 클래스가 연결/연결되지 않은(데이터 없음) 2-클래스 분류 알고리즘 을 적용하는 것에 의해서와 같이 이벤트 감지 기능에 의해 이벤트로 감지될 수 있다. 이 경우, \"데이터 없 음\"은 발표자가 의도적으로 검은 화면을 보내는 것과 다른 것으로 이해된다. 단 1개 또는 2개의 프레임과 같은 짧은 블랙 스크린은 최종 생성 스트림에서 눈에 띄지 않을 수 있기 때문에, 시계열을 생성하기 위해 시간 이 지남에 따라 상기 2클래스 분류 알고리즘을 적용할 수 있다. 그런 다음 연결 중단의 최소 길이를 지정하는 임계값을 사용하여 연결이 끊어졌는지 여부를 결정할 수 있다. 다음에 설명하는 바와 같이, 이러한 예시된 유형의 감지된 이벤트는 적절하고 원하는 대로 다양한 조치를 취하 기 위해 패턴 감지 기능에 의해 사용될 수 있다. 말한 바와 같이, 개별 기본 비디오 스트림(210, 301)은 각각 공통 시간 기준에 관련되거나 시간 도메인에 서 서로 관련될 수 있으므로, 동기화 기능이 서로에 관련하여 이들을 시간 동기화하는 것을 가능하게 한다. 일부 실시 예에서, 공통 시간 기준은 공통 오디오 신호에 기초하거나 이를 포함하고(도 1 내지 3 참 조), 공통 오디오 신호는 위에서 설명된 바와 같이 적어도 두 개의 원격으로 연결된 참여 클라이언트(12 1)를 포함하는 공유 디지털 비디오 통신 서비스에 공통이며, 각각은 상기 기본 디지털 비디오 스트림 중 하나를 제공한다. 위에서 논의된 Microsoft® Teams®의 예에서, 공통 오디오 신호가 생성되고 자동 참여 클라이언트 및/또 는 API를 통해 중앙 서버에 의해 캡처될 수 있다. 이 예와 다른 예에서, 그러한 공통 오디오 신호는 이 하트비트 신호에 기초하여 개별의 기본 비디오 스트림의 각각을 특정 시점에 바인딩함으로써 이들을 시 간 동기화하기 위해 하트비트 신호로 사용될 수 있다. 이러한 공통 오디오 신호는 (다른 기본 비디오 스트림 각각과 관련하여) 별도의 신호로 제공될 수 있고, 이에 의해 다른 기본 비디오 스트림은 각각 해당 다른 기본 비디오 스트림에 포함된 오디오에 기초하여, 또는 또는 그 안에 포함된 이미지 정보에 기초하여 (예: 자동 이미지 처리 기반 립싱크 기술 사용), 공통 오디오 신호와 개별적으로 시간 상관될 수 있다. 다시 말해서, 개별적인 기본 비디오 스트림과 관련된 임의의 변수 및/또는 다른 대기 시간을 처리하고 결 합된 비디오 출력 스트림에 대한 시간 동기화를 달성하기 위해, 이러한 공통 오디오 신호는 중앙 서버 의 모든 기본 비디오 스트림(외부 기본 비디오 스트림은 아닐 수도 있음)에 대한 하트비트로 사 용된다. 즉, 다른 모든 신호는 이 공통 오디오 시간 하트비트에 매핑되어 모든 것이 시간 동기화되도록 한다. 다른 예에서, 시간 동기화는 출력 디지털 비디오 스트림에 도입되고 참여 클라이언트 중 하나 또는 여러 개별 클라이언트의 일부로 제공된 각각의 로컬 시간 동기화 소프트웨어 기능에 의해 감지되는 시간 동기화 요소를 사용하여 달성되고, 로컬 소프트웨어 기능은 출력 비디오 스트림에서 시간 동기 화 요소의 도착 시간을 검출하도록 배열된다. 이해되는 바와 같이, 이러한 실시 예에서 출력 비디오 스트 림은 비디오 통신 서비스로 피드백되거나 그렇지 않으면 각 참여 클라이언트 및 해당 로컬 소프 트웨어 기능에 이용 가능하게 된다. 예를 들어, 시간 동기화 요소는 일정한 시간 간격으로 출력 비디오에 배치되거나 업데이트되는, 미리 결정된 순서 또는 방식으로 색상을 변경하는 픽셀과 같은 시각적 마커; 출력 비디오에 업데이트되어 표시 되는 시각적 시계; 출력 비디오 스트림의 오디오 형성 부분에 추가되는 사운드 신호(예를 들어 충분히 낮 은 진폭 및/또는 충분히 높은 주파수를 가짐으로써 참가자가 들을 수 없도록 설계될 수 있음)일 수 있다. 로컬 소프트웨어 기능은 적절한 이미지 및/또는 오디오 처리를 사용하여 각각의 시간 동기화 요소 (들)의 각각의 도착 시간을 자동으로 감지하도록 구성된다. 그러면, 공통 시간 기준은 상기 검출된 도착 시간에 기초하여 적어도 당사자에 의해 결정될 수 있다. 예를 들어, 로컬 소프트웨어 기능 각각은 상기 검출된 도착 시간을 나타내는 각각의 정보를 중앙 서버에 통신할 수 있다. 이러한 통신은 해당 참여 클라이언트와 중앙 서버 사이의 직접 통신 링크를 통해 이루어질 수 있다. 하지만, 통신은 해당 참여 클라이언트와 연관된 기본 비디오 스트림을 통해 이루어질 수도 있다. 예 를 들어, 참여 클라이언트는 중앙 서버에 의한 자동 감지를 위해 해당 참여자 클라이언트에 의 해 생성되어 공통 시간 기준을 결정하는 데 사용되는 기본 비디오 스트림에, 위에서 설명한 유형과 같은 시각적 또는 청각적 코드를 도입할 수 있다. 추가적인 예에서는, 각 참여 클라이언트는 위에서 논의된 것들에 대응하는 방식으로, 모든 참여 클라이언 트가 시청할 수 있는 공통 비디오 스트림에서 비디오 통신 서비스에 대한 이미지 검출을 수행하고, 이러한 이미지 검출 결과를 중앙 서버에 중계하여, 시간이 지남에 따라 서로 관련하여 각 참여 클라이언트 의 개별 오프셋을 결정하는 데 사용된다. 이러한 방식으로, 공통 시간 기준은 개별 상대 오프셋의 세 트로서 결정될 수 있다. 예를 들어, 일반적으로 사용 가능한 비디오 스트림의 선택된 기준 픽셀은 상기 로컬 소 프트웨어 기능에 의해서와 같이, 여러 또는 모든 참여 클라이언트에 의해 모니터링될 수 있으며, 해 당 픽셀의 현재 색상이 중앙 서버에 통신될 수 있다. 중앙 서버는 다수의 (또는 전체) 참여 클라이언 트 각각으로부터 연속적으로 수신된 이러한 색상 값을 기초로 각각의 시계열을 계산하고, 상호 상관을 수 행하여 서로 다른 참여 클라이언트에 대해 추정된 세트의 상대적인 시간 오프셋이 결과된다. 실제로, 비디오 통신 서비스에 공급되는 출력 비디오 스트림은 해당 비디오 통신의 모든 참여 클 라이언트의 공유 화면의 일부로서 포함될 수 있고, 따라서 참여 클라이언트와 관련된 시간 오프셋을 평가 하는 데 사용될 수 있다. 특히, 비디오 통신 서비스에 공급되는 출력 비디오 스트림은 자동 참여 클 라이언트 및/또는 API를 통해 중앙 서버에 다시 이용 가능할 수 있다. 일부 실시 예에서, 공통 시간 기준은 상기 기본 디지털 비디오 스트림(210, 301) 중 제1 스트림의 오디오 부분과 상기 기본 디지털 비디오 스트림(210, 301)의 이미지 부분 사이의 검출된 불일치에 적어도 부 분적으로 기초하여 결정될 수 있다. 이러한 불일치는 예를 들어, 해당 상기 제1 기본 디지털 비디오 스트림 (210, 301)에서 보이는 말하는 참가자의 디지털 립싱크 비디오 이미지 분석에 기초할 수 있다. 이러한 립 싱크 분석은 그 자체로 기존 방식이며, 예를 들어 훈련된 신경망을 사용할 수 있다. 분석은 이용 가능한 공통 오디오 정보와 관련하여 각 기본 비디오 스트림(210, 301)에 대한 동기화 기능에 의해 수행될 수 있고, 개 별 기본 비디오 스트림(210, 301)에 대한 상대적인 오프셋은 이 정보에 기초하여 결정될 수 있다. 일부 실시 예에서, 동기화 단계는 최대 30, 예를 들어, 최대 5초의 지연, 예를 들어 최대 1초, 최대 0.5초로, 0 초보다 긴 시간의 지연(이 문맥에서 \"지연\"과 \"대기시간\"이라는 용어는 동일한 의미로 사용됨)을 의도적으로 도 입하는 것을 포함하므로, 출력 디지털 비디오 스트림에는 적어도 상기 지연이 제공된다. 여하튼, 의도적으 로 도입된 지연은 수집 단계에서 리샘플링 후에 저장된 프레임(또는 개별 이미지)의 수와 같이 적어도 3개, 심 지어는 적어도 5개 또는 심지어 10개의 비디오 프레임과 같은 적어도 몇 개의 비디오 프레임이다. 본 명세서에 사용된 바와 같이, \"의도적으로\"라는 용어는 동기화 문제 등에 기초하여 그러한 지연을 도입할 필요성과 관계없 이 지연이 도입된다는 것을 의미한다. 다시 말해서, 의도적으로 도입된 지연은 기본 비디오 스트림(210, 301)의 동기화의 일부로서 도입된 지연에 더해 서로에 대해 시간 동기화하기 위해 도입된다. 의도적으로 도입된 지연은 공통 시간 기준과 관련하여 미리 결정되거나 고정되거나 가변적일 수 있다. 지연 시간은 기본 비디오 스트 림(210, 301) 중 최소 잠재 스트림과 관련하여 측정될 수 있으므로, 상기 시간 동기화의 결과로 이들 스트림 (210, 301) 중 더 많은 잠재 스트림이 상대적으로 더 적은 의도적으로 추가된 지연과 연관된다. 일부 실시 예에서는 0.5초 이하와 같은 상대적으로 적은 지연이 도입된다.이러한 지연은 출력 비디오 스트림 을 사용하는 비디오 통신 서비스에 대한 참가자가 거의 인지할 수 없을 것이다. 출력 비디오 스트림 이 대화형 컨텍스트에서 사용되지 않고 대신 외부 소비자에 대한 단방향 통신으로 게시되는 경우와 같은 다른 실시 예에서는, 더 큰 지연이 도입될 수 있다. 이러한 의도적으로 도입된 지연은 동기화 기능이 수집된 개별 기본 스트림(210, 301) 비디오 프레임을 올 바른 공통 시간 기준 타임스탬프에 매핑하는 데 충분한 시간을 달성하기에 충분할 수 있다. 이는 또 한 손실된 기본 스트림(210, 301) 신호, 슬라이드 변경, 해상도 변경 등을 검출하기 위해 위에서 설명된 이벤트 감지을 수행하는 데 충분한 시간을 허용하기에 충분할 수 있다. 더욱이, 의도적으로 상기 지연을 도입하는 것은 다음에 설명되는 바와 같이 개선된 패턴 감지 기능을 허용하기에 충분할 수 있다. 상기 지연의 도입은 해당 버퍼링된 프레임을 사용하여 출력 비디오 스트림을 게시하기 전에 수집되고 시간 동기화된 기본 비디오 스트림(210, 301) 각각을 버퍼링하는 단계를 포함할 수 있다는 것을 알았다. 다시 말해서, 기본 비디오 스트림(210, 301) 중 적어도 하나, 여러 개 또는 심지어 모두의 비디오 및/또는 오디 오 데이터는 캐시와 마찬가지로 버퍼링된 방식으로 중앙 서버에 존재할 수 있지만, (기존 캐시 버퍼와 같이) 다양한 대역폭 상황을 처리할 수 있는 의도로 사용되지는 않고, 상기 이유로 특히 패턴 감지 기능에 의해 사용된다. 따라서 일부 실시 예에서, 상기 패턴 감지 단계는 기본 디지털 비디오 스트림(210, 301) 중 적어도 하나, 예를 들어, 적어도 4개, 또는 심지어는 전부의 특정 정보를 고려하는 것을 포함하고, 특정 정보는 아직 출력 디지털 비디오 스트림의 생성에 사용될 시간 동기화된 기본 디지털 비디오 스트림의 프레임보다 나중 프레임 에 존재한다. 따라서 새로 추가된 프레임은 출력 비디오 스트림의 일부(또는 기초)를 형성하기 전에 특정 대기 시간 동안 해당 버퍼에 존재할 것이다. 이 기간 동안, 해당 프레임에 있는 정보는 출 력 비디오 스트림의 현재 프레임을 생성하기 위해 현재 사용되는 프레임과 관련된 \"향후\" 정보를 구성할 것이다. 출력 비디오 스트림 타임라인이 해당 프레임에 도달하면, 이는 출력 비디오 스트림의 해당 프레임을 생성하는 데 사용되게 되고, 그 후에는 폐기될 수 있다. 다시 말해서, 패턴 감지 기능은 출력 비디오 스트림을 생성하기 위해 아직 사용되지 않은 비디오/오 디오 프레임 세트를 처리할 수 있고, 이 데이터를 사용하여 상기 패턴을 검출할 수 있다. 패턴 감지는 다양한 방식으로 수행될 수 있다. Al 성분(134a)에 의해 수행되는 일부 실시 예에서, 패턴 감지 단 계는 상기 패턴을 자동으로 검출하기 위해 협력하여, 상기 기본 디지털 비디오 스트림(120, 301) 중 적어 도 2개, 적어도 3개, 적어도 4개 또는 심지어 전부를 분석하는 제2 훈련된 신경망 또는 다른 기계 학습 구성요 소를 포함한다. 일부 실시 예에서, 검출된 패턴은 적어도 2명, 예를 들어 적어도 3명, 적어도 4명의 서로 다른 발언 참가 자를 포함하는 발언 패턴을 포함하고, 각각은 각각의 참여 클라이언트와 연관되어 공유 비디오 통신 서비스에 연결되고, 상기 발언 참가자 각각은 상기 기본 디지털 비디오 스트림(210, 301) 각각에서 시각적으로 보여진다. 생성 단계는 바람직하게는 출력 비디오 스트림의 현재 생성 상태를 결정하고, 추적하고, 업데이트하는 것 을 포함한다. 예를 들어, 이러한 상태는 참가자가 출력 비디오 스트림에서 볼 수 있는 것이 무엇인지, 그리고 화면의 어디에 있는지; 외부 비디오 스트림이 출력 비디오 스트림에 표시되는지, 그리고 화면의 어디에 있는지; 슬라이드나 공유 화면이 전체 화면 모드로 표시되거나 라이브 비디오 스트림과 함께 표시되는지 등을 나타낼 수 있다. 그러므로, 생성 기능은 생성된 출력 비디오 스트림에 관한 상 태 머신으로 볼 수 있다. 예를 들어, 최종 소비자가 볼 수 있는 결합된 비디오 경험으로 출력 비디오 스트림을 생성하기 위해 서는, 개별 기본 비디오 스트림(210, 301)과 관련된 개별 이벤트를 단순히 감지하는 것보다 더 깊은 수준에서 무슨 일이 일어나는지 중앙 서버가 이해할 수 있는 것이 바람직하다. 제1 예에서, 발표 참여 클라이언트는 현재 보고 있는 슬라이드를 변경하고 있다. 이러한 슬라이드 변화는 전술한 바와 같이 이벤트 감지 기능에 의해 검출되고, 슬라이드 변화가 발생했음을 나타내는 메타데이터 가 해당 프레임에 추가된다. 이는 프레젠테이션 참여 클라이언트가 빠르게 연속해서 앞으로 여러 슬 라이드를 건너뛰는 것으로 밝혀졌기 때문에 여러 번 발생하고, 결과적으로 짝수 감지 기능에 의해 감지되 고 해당 기본 비디오 스트림에 대한 개별 버퍼에 해당 메타데이터와 함께 저장되는 일련의 \"슬 라이드 변경\" 이벤트가 발생한다. 실제로 이렇게 빠르게 앞으로 건너뛴 슬라이드는 단 몇 분의 1초 동안만 보일 수 있다. 패턴 감지 기능은 이러한 감지된 슬라이드 변화 중 여러 개에 걸쳐 해당 버퍼에 있는 정보를 보고, 숫자나 빠르게 수행되는 슬라이드 변경보다는, 하나의 단일 슬라이드 변경에 해당하는 패턴을 감지한다(즉, 앞 으로 건너뛰기의 마지막 슬라이드로, 빠른 건너뛰기가 끝나면 슬라이드가 다시 표시된다). 즉, 패턴 감지 기능 은 예를 들어 매우 짧은 시간 내에 10개의 슬라이드 변경이 있으며, 왜 이러한 변경이 하나의 단일 슬라이 드 변경을 나타내는 감지된 패턴으로 처리되는지를 알 수 있다. 결과적으로, 패턴 감지 기능에 의해 감지 된 패턴에 액세스하는 생성 기능은 몇 초 동안 출력 비디오 스트림에서 전체 화면 모드로 최종 슬라 이드를 표시하도록 선택할 수 있으며, 이는 이 슬라이드가 상기 상태 머신에서 잠재적으로 중요하다고 판단했기 때문이다. 또한 출력 스트림에서 중간에 본 슬라이드를 전혀 표시하지 않도록 선택할 수도 있다. 여러 개의 빠르게 변화하는 슬라이드의 패턴은 간단한 규칙 기반 알고리즘으로 감지될 수 있지만, 분류에 따라 움직이는 이미지에서 그러한 패턴을 감지하도록 설계되고 훈련된 훈련된 신경망을 사용하여 대안적으로 탐지될 수도 있다.비디오 통신이 토크쇼, 패널 토론 또는 이와 유사한 경우에 유용할 수 있는, 다른 예에서, 조용하고 부드러운 출력 비디오 스트림을 생성하고 게시함으로써 소비자에게 적절한 시청 경험을 여전히 제공하면서, 현 재 화자 간 시각적 주의를 빠르게 전환하는 것이 바람직할 수 있다. 이 경우, 이벤트 감지 기능은 특정 기 본 비디오 스트림(210, 301)에서 보고 있는 사람이 현재 말하고 있는지 여부를 항상 결정하기 위해서, 각 기본 비디오 스트림(210, 301)을 연속적으로 분석할 수 있다. 이는 예를 들어, 자체 기존의 이미지 처리 도구를 사용 하여 위에서 설명한 대로 수행될 수 있다. 그 다음, 패턴 감지 기능은 상기 기본 비디오 스트림(210, 301) 중 몇몇을 포함하는 특정 전체 패턴을 검출하도록 동작가능하고, 상기 패턴은 원활한 출력 비디오 스트림 을 생성하는 데 유용하다. 예를 들어, 패턴 감지 기능은 현재 화자 간 매우 빈번한 전환 패턴 및/또는 여 러 동시 화자와 관련된 패턴을 감지할 수 있다. 그러면, 생성 기능은 예를 들어 0.5초 동안만 말하고 다시 침묵하는 화자에게 시각적 초점을 자동으로 전 환하지 않거나, 두 사람이 서로 번갈아 가거나 동시에 말하는 경우 일정 시간 동안 여러 명의 화자가 나란히 표 시되는 상태로 전환함으로써, 상기 생성 상태와 관련하여 자동화된 결정을 내릴 때 이러한 감지된 패턴을 고려 할 수 있다. 결정 프로세스가 포함된 이 상태는 시계열 패턴 인식 기술을 사용하거나 훈련된 신경망을 사용하여 자체적으로 수행될 수 있지만, 미리 결정된 규칙 세트에 적어도 부분적으로 기초할 수도 있다. 일부 실시 예에서, 병렬로 검출되어 생성 기능 상태 머신에 대한 입력을 형성하는 다수의 패턴이 있을 수 있다. 이러한 다중 패턴은 생성 기능에 의해 다양한 AI 구성 요소, 컴퓨터 비전 감지 알고리즘 등에 의해 사용될 수 있다. 일 예로서, 일부 참여 클라이언트의 불안정한 연결을 동시에 감지하면서 영구적인 슬라이 드 변경이 감지될 수 있는 반면, 다른 패턴은 현재 주요 발언 참가자를 감지한다. 이러한 사용 가능한 모 든 패턴 데이터를 사용하여, 그러한 패턴 데이터의 시계열 분석을 위해 분류기 신경망이 훈련될 수 있고/있거나 규칙 세트가 개발될 수 있다. 이러한 분류는 적어도 부분적으로, 예를 들어 완전히 감독되어 상기 생성에 사용 될 결정된 원하는 상태 변경이 발생하도록 할 수 있다. 예를 들어, 다양하고 다른 생성 스타일 및 요구에 따라 출력 비디오 스트림을 자동으로 생성하도록 구체적으로 배열된 서로 다른 미리 결정된 분류기가 생성될 수 있다. 훈련은 원하는 출력으로 알려진 생성 상태 변경 시퀀스와 훈련 데이터로 알려진 패턴 시계열 데이터를 기 반으로 할 수 있다. 일부 실시 예에서, 베이지안 모델은 이러한 분류기를 생성하는 데 사용될 수 있다. 구체적 인 예를 들면, 정보는 숙련된 생성자로부터 선험적으로 수집되어, \"토크쇼에서 나는 화자 A에서 화자 B로 직접 전환하지 않지만 다른 화자 매우 지배적이고 큰 소리로 말하지 않는 한, 다른 화자에게 집중하기 전에 먼저 개 요를 표시한다.\" 과 같은 입력을 제공할 수 있다. 이 생성 로직은 \"X가 참인 경우 | Y가 참이라는 사실을 고려 하여 | Z를 수행한다\" 와 같은 일반 형식의 베이지안 모델로 표현된다. 실제 감지(누군가 큰 소리로 말하고 있 는지 등)는 분류자 또는 임계값 기반 규칙을 사용하여 수행될 수 있다. 대규모 데이터 세트(패턴 시계열 데이터)를 사용하면, 딥 러닝 방법을 사용하여 비디오 스트림의 자동화된 생성 에 사용할 정확하고 매력적인 생성 형식을 개발할 수 있다."}
{"patent_id": "10-2024-7018585", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "요약하자면, 개별 기본 비디오 스트림(210, 301)에 기초한 이벤트 감지; 의도적으로 도입된 지연; 여러 시간 동 기화된 기본 비디오 스트림(210, 301) 및 감지된 이벤트에 기초한 패턴 감지; 및 감지된 패턴에 기반한 생성 공 정의 조합을 사용하게 되면, 다양한 취향과 스타일 선택에 따라 출력 디지털 비디오 스트림의 자동화된 생 성을 달성하는 것을 가능하게 한다. 이 결과는 광범위한 가능한 신경망에 걸쳐 유효하고 및/또는 이벤트 감지 기능, 패턴 감지 기능 및 생성 기능에 의해 사용되는 규칙 기반 분석 기술이다. 특히, 이는 제1 생성된 비디오 스트림이 제2 생성된 비디오 스트림의 자동 생성에 사용된 것과 다양한 참여 클라이언트 그룹에 대해 의도적으로 추가된 다양한 지연의 사용을 특징으로 하는 아래 설명된 실시 예에서 유효한다. 위에서 예시한 바와 같이, 생성 단계는 상기 출력 디지털 비디오 스트림에 있는 상기 기본 디지털 비디오 스트림(210, 301) 중 개별 스트림의 가시성에 관한 사전 결정된 및/또는 동적으로 가변적인 매개변수 세트; 시 각적 및/또는 청각적 비디오 콘텐츠 배열; 시각 또는 청각 효과 사용; 및/또는 출력 디지털 비디오 스트림(23 0)의 출력 모드에 기초하여 출력 디지털 비디오 스트림을 생성하는 단계를 포함할 수 있다. 이러한 매개변 수는 상기 생성 기능 상태 기계에 의해 자동으로 결정될 수 있고/있거나 생성을 제어하는 조작자(반자동으 로 만듦)에 의해 설정될 수 있되고 및/또는 특정한 선험적 구성 요구(예를 들어 출력 비디오 스트림 레이 아웃 변경 또는 위에서 예시된 유형의 상태 변경 사이의 최단 시간)에 기초하여 미리 결정될 수 있다. 실제적인 예에서, 상태 머신은 출력 비디오 스트림에 적용될 수 있는 미리 결정된 표준 레이아웃 세트, 예 를 들어, 전체 화면 발표자 보기(현재 말하고 있는 참가자를 전체 화면으로 표시); 슬라이드 보기(현재 공 유된 프레젠테이션 슬라이드를 전체 화면으로 표시); 현재 말하고 있는 참가자와 현재 공유된 프리젠테이션 슬라이드를 나란히 표시하는 \"나비 보기\"; 참가자의 전체 또는 선택된 하위 집합을 나란히 또는 매트릭 스 레이아웃으로 보여주는 다중 화자 보기 등을 지원할 수 있다. 다양한 이용 가능한 생성 포맷은 이용 가능한 상태 세트(예를 들어, 상기 표준 레이아웃 세트)와 함께 상태 머신 상태 변경 규칙 세트(상기 예시된 바와 같음)에 의해 정의될 수 있다. 예를 들어, 이러한 생성 형식 중 하나는 \"패널 토론\", 다른 \"프리젠테이션\" 등일 수 있다. GUI 또는 중앙 서버에 대한 다른 인터페이스를 통해 특정 생성 형식을 선택함으로써, 시스템 의 운영자는 미리 정의된 생성 형식 세트 중 하나를 신속하게 선택할 수 있고, 다음에 중앙 서버로 하여금 위에서 설명된 이용 가능한 정보에 기초하여 해당 생성 포맷에 따라 출력 비디오 스트림을 완전 자 동으로 생성하도록 할 수 있다. 뿐만 아니라, 생성 동안, 전술한 바와 같이 각각의 미팅 참여 클라이언트 또는 외부 비디오 소스에 대해 각각의 인메모리 버퍼가 생성되고 유지된다. 이러한 버퍼는 즉시 쉽게 제거, 추가 및 변경할 수 있다. 그 러면 중앙 서버은 출력 비디오 스트림을 생성하는 동안, 추가/탈락 참여 클라이언트 및 연설 예 정 참가자; 계획된 또는 예상치 못한 프레젠테이션의 일시 중지/재개; 현재 사용되는 생성 형식에 대한 원 하는 변경 사항 등에 관하여, 정보를 수신하도록 배열될 수 있다. 그러한 정보는 예를 들어 전술한 바와 같이 운영자 GUI 또는 인터페이스를 통해 중앙 서버에 공급될 수 있다. 위에 예시된 바와 같이, 일부 실시 예에서 기본 디지털 비디오 스트림(210, 301) 중 적어도 하나는 디지털 비디 오 통신 서비스에 제공되고, 발행 단계는 상기 출력 디지털 비디오 스트림을 동일한 통신 서비스 에 제공하는 단계를 포함할 수 있다. 예를 들어, 출력 비디오 스트림은 비디오 통신 서비스의 참여 클라이언트에 제공될 수 있거나, 외부 비디오 스트림으로서 API를 통해 비디오 통신 서비스 에 제공될 수 있다. 이러한 방식으로, 출력 비디오 스트림은 현재 비디오 통신 서비스에 의해 달성되고 있는 비디오 통신 이벤트에 대한 참가자 중 일부 또는 모두에게 이용 가능하게 될 수 있다. 위에서 논의한 바와 같이, 추가적으로 또는 대안적으로 출력 비디오 스트림은 하나 또는 여러 외부 소비자 에게 제공될 수 있다. 일반적으로, 생성 단계는 중앙 서버에 의해 수행될 수 있으며, 상기 출력 디지털 비디오 스트림을 API를 통해 라이브 비디오 스트림으로서 하나 또는 여러 동시 소비자에게 제공할 수 있다. 도 8a는 본 발명의 제1 측면에 따른 방법을 도시하며, 이는 위에서 설명한 내용을 참조하여 다음에 설명될 것이다. 즉, 디지털 비디오 스트림(이하 \"제2\" 디지털 비디오 스트림으로 표시됨)을 제공하기 위한 도 8a에 도시된 방법에서, 디지털 비디오 스트림 수집, 이벤트 감지, 동기화, 패턴 감지, 생성 및 게시와 관련하여 위에서 설명 한 모든 메커니즘과 원칙이 적용될 수 있다. 해당 내용은 일반적으로 본 발명의 제2 측면에 따른 방법을 설명하는 도 8b에 대해, 본 발명의 제3 측면에 따른 방법을 도시하는 도 8c에 대해, 및 본 발명의 제4 측면에 따른 방법을 도시하는 도 8d에 대해 말해질 수 있다. 상기 제1, 제2, 제3 및 제4 측면은 자유롭게 결합될 수 있다. 특히, 제4 측면에 따른 방법 5는 제1, 제2 및 제3 측면 중 어느 하나에 따른 방법과 조합하여 사용될 수 있다. 또한, 도 9는 도 8a-8d에 도시된 방법을 수행하기 위한 구성의 시스템의 단순화된 도면이다. 중앙 서버는 상술한 바와 같을 수 있는 수집 기능을 포함한다. 중앙 서버는 또한 제1 생성 기능(135'), 제2 생성 기능(135\") 및 제3 생성 기능(135\")을 포함한다. 각각의 이러한 생성 기능(135', 135\", 135'\")은 생성 기능에 대응하고, 생성 기능과 관련하여 위에서 언급한 내용은 생성 기능(135', 135\", 135'\")에도 동일하게 적용된다. 생성 기능(135', 135\", 135'\")은 여러 기능을 갖는 하나의 단일 논리 기능으로 별개적으로 또는 함께 배열될 수 있으며, 중앙 서버의 세부 구성에 따라 3개 이상의 생성 기능이 있을 수도 있다. 생성 기능(135', 135\", 135'\")은 경우에 따라 하나의 동일한 생성 기 능의 서로 다른 기능적 측면일 수 있다. 생성 기능(135', 135\", 135'\")과 다른 개체 간의 다양한 통신은 적절한 API를 통해 이루어질 수 있다. 각각의 생성 기능(135', 135\", 135'\") 또는 이런 생성 기능의 그룹에 대해 별도의 수집 기능이 있을 수 있 고, 세부 구성에 따라 각각 수집 기능을 갖춘 논리적으로 분리된 여러 개의 중앙 서버가 있을 수 있 다는 것이 또한 인식된다. 게다가, 중앙 서버는 제1 게시 기능(136'), 제2 게시 기능(136\") 및 제3 게시 기능(136'')을 포함한다. 각 각의 이러한 게시 기능(136', 136\", 136'\")은 게시 기능에 대응하고, 게시 기능과 관련하여 위에서언급한 내용은 게시 기능(136', 136\", 136'\")에도 동일하게 적용된다. 게시 기능(136', 136\", 136'\")은 여러 기능을 갖는 하나의 단일 논리 기능으로 구별되거나 공동 배열될 수 있고, 중앙 서버의 세부 구성에 따라 3개 이상의 게시 기능이 있을 수도 있다. 게시 기능(136', 136\", 136'\")은 경우에 따라 하나의 동일한 게시 기 능의 다른 기능적 측면일 수 있다. 도 9에는, 본 명세서에서 설명된 원리를 설명하기 위해 참여 클라이언트의 3개 세트 또는 그룹이 표시되어 있으 며, 각각은 위에서 설명된 참여 클라이언트에 해당한다. 따라서, 이러한 참여 클라이언트의 제1 그룹 (121')이 존재하며; 이러한 참여 클라이언트의 제2 그룹(121\"); 및 이러한 참여 클라이언트의 제3 그룹(121\"') 이 있다. 이들 그룹 각각은 하나 또는 바람직하게는 적어도 두 명의 참여 클라이언트를 포함할 수 있다. 세부 구성에 따라 이러한 그룹은 2개만 있을 수도 있고 3개 이상 있을 수도 있다. 그룹(121', 121\", 121'\") 간의 할 당은 각 참여 클라이언트가 최대 하나의 그룹(121', 121\", 121'\")에 할당된다는 점에서 배타적일 수 있다. 대안적인 구성에서, 적어도 하나의 참여 클라이언트는 하나 이상의 그룹(121', 121\", 121\"')에 동시에 할 당될 수 있다. 도 9는 또한 외부 소비자를 도시하며, 전술한 바와 같은 외부 소비자가 둘 이상 있을 수 있다는 것이 인식된다. 도 9는 단순성의 이유로, 비디오 통신 서비스를 도시하는 것이 아니고, 위에서 설명한 방식으로 중앙 서버 를 이용하여 참여하는 각 클라이언트에 공유 비디오 통신 서비스를 제공하는 것과 같이, 전술한 일반 적인 형태의 비디오 통화 서비스가 중앙 서버로 이용될 수 있는 것이 인식된다. 도 8a로 돌아가서 제1 단계에서 방법이 시작된다. 후속 수집 단계에서는, 다수의 상기 기본 비디오 스트림, 이 예시의 경우, 각각 참여 클라이언트로부터 수집된, 적어도 제1 기본 디지털 비디오 스트림, 제2 기본 디지털 비디오 스트림 및 제3 기본 디지털 비디오 스 트림이 수집된다. 따라서, 제1 기본 디지털 비디오 스트림은 제1 참여 클라이언트로부터 수집되고; 제2 기본 디 지털 비디오 스트림은 제2 참여 클라이언트로부터 수집되고; 제3 기본 디지털 비디오 스트림은 제3 참여 클라이 언트로부터 수집된다. 후속 게시 단계에서, 적어도 하나의 비디오 스트림이 상기 제1 참여 클라이언트 및 상기 제2 참여 클라이언트 중 적어도 하나에 제공된다. 즉, 비디오 스트림은 상기 제1 기본 디지털 비디오 스트림 중 적어도 하나이고, 상 기 제2 기본 디지털 비디오와 상기 제1 및 제2 기본 비디오 스트림 중 적어도 하나에 기초하여 생성된 제1 생성 된 비디오 스트림이다. 그러한 기본 비디오 스트림의 생성은 아래 설명된 바와 같이 제1 생성 기능(135')에 의 해 수행될 수 있으며, 예를 들어, 해당 생성 결과로 처음 생성된 디지털 비디오 스트림의 대기 시간을 도입하는 것을 포함할 수 있다. 해당 제공 및 게시 단계는 지속적일 수 있으며, 실시간일 수 있다. 예를 들어, 제1 및 제2 참가자는 본 명세서의 다른 곳에서도 설명된 바와 같이 비디오 회의와 같은 동일한 비디 오 통신 서비스에 참여할 수 있다. 그러면, 예를 들어 제1 참여 클라이언트는 제1 참여 클라이언트의 화면에서 시청하기 위한 제2 디지털 비디오 스트림을 제공받을 수 있고, 그 반대의 경우도 마찬가지이므로, 제1 및 제2 참여 클라이언트 사용자가 서로를 보고 상호작용할 수 있도록 한다. 추 가적으로 또는 대신에, 제1 및 제2 참여 클라이언트 각각 또는 이들 중 하나는 해당 참여 클라이언트의 각 각의 화면에서 시청하기 위해 상기 제1 생성된 디지털 비디오 스트림을 제공받을 수 있다. 제1 생성된 디 지털 비디오 스트림과 제1 및 제2 기본 비디오 스트림 중 어느 하나가 동시에 제공되는 경우, 해당 참여 클라이 언트에 표시되는 비디오 스트림을 시간 동기화하기 위해서, 아래 설명과 같이 해당 기본 비디오 스트림이 지연될 수 있다. 제2 생성 기능(135\")에 의해 수행되는 후속 제2 생성 단계에서, 제2 생성된 비디오 스트림은 상기 제1 기본 디 지털 비디오 스트림, 상기 제2 기본 디지털 비디오 스트림 및 또한 상기 제3 기본 디지털 비디오 스트림을 기반 으로 하여 디지털 비디오 스트림으로 생성된다. 제3 기본 디지털 비디오 스트림은 그 자체로도 또는 생성된 디 지털 비디오 스트림의 일부로도 제1 또는 제2 참여 클라이언트에 제공되지 않는다는 점에 유의한다. 본 문서의 다른 곳에 설명된 바와 같이, 제1 및 제2 참여 클라이언트는 제3 참여 클라이언트와 비교하여 다른 그룹의 참여 클라이언트에 할당될 수 있다. 제2 생성 단계는 시간 지연의 도입으로 구성되므로, 제2 생성된 비디오 스트림은 상기 게시 단계에서 상기 제1 또는 제2 참여 클라이언트에 제공될 수 있는 비디오 스트림 중 임의의 것과 시간 비동기화되도록 한다. 이러한시간 지연은 본 문서에 설명된 방식 중 하나로 의도적으로 추가되거나 제2 생성된 디지털 비디오 스트림 생성의 직접적인 결과일 수 있다. 바람직하게는, 제2 생성된 디지털 비디오 스트림은 제1 및/또는 제2 참여 클라이언트 에서 게시된 임의의 비디오 스트림과 관련하여 지연된 게시가 가능한다. 이에 대해 생각하는 한 가지 방법은 제 2 생성된 디지털 비디오 스트림을 소비하는 클라이언트가 제1 및 제2 참여 클라이언트의 비디오 스트림 소비 \" 시간대\"보다 (시간 기준으로) 약간 늦은 \"시간대\"에서 제2 생성된 디지털 비디오 스트림을 소비한다는 것이다. 예를 들어, 하나 또는 여러 개의 기본 디지털 비디오 스트림이 제1 및/또는 제2 참여 클라이언트에 제공되는 경 우, 그러한 제공은 (의도적으로 도입된 시간 지연을 사용하지 않고) 직접적일 수 있으며/또는 해당 참여 클라이 언트에 제공하기 전에 계산적으로 상대적으로 가벼운 처리만을 포함할 수 있는 반면; 제2 생성된 디지털 비디오 스트림의 생성은 의도적으로 도입된 시간 지연 및/또는 상대적으로 무거운 처리를 포함할 수 있으므로 제1 및/ 또는 제2 기본 디지털 비디오 스트림의 게시를 위한 가장 빠른 지연과 관련된 지연으로 가장 빠른 게시를 위해 제2 생성된 디지털 비디오 스트림이 생성되도록 한다. 제1 생성된 비디오 스트림이 제1 및/또는 제2 참여 클라 이언트에 제공되는 경우, 제1 생성된 디지털 비디오 스트림은 의도적으로 추가된 상대적으로 짧은 시간 지연 및 /또는 상대적으로 가벼운 처리를 사용하여 생성되는 반면, 제2 생성된 디지털 비디오 스트림은 상대적으로 길고 의도적으로 추가된 시간 지연 및/또는 상대적으로 무거운 처리를 사용하여 생성되며, 그 결과, 제2 생성된 디지 털 비디오 스트림은 제1 생성된 디지털 비디오 스트림의 가장 빠른 지연과 관련된 지연 시 가장 빠른 게시를 위 해 상응하여 생성된다. 일반적으로, 제2 생성된 디지털 비디오 스트림은 게시를 위해 제1 또는 제2 참여 클라이언트에서 제공되지 않고, 대신에 (제2 그룹(121\")과 같은 다른 그룹에 할당되는) 제3 참여 클라이언트 및/또는 외부 소비 클라이언 트와 같이, 제1 및 제2 클라이언트가 속한 그룹과 다른 그룹(예를 들어, 제1 그룹(121'))에 할당된 참여 클라이언트에서 제공된다. 따라서 도 8a에 도시된 바와 같이, 상기 게시 단계는 제1 또는 제2 참여 클라이언트가 아닌 적어도 하나의 소비 클라이언트(121, 150)에 제2 생성된 비디오 스트림을 연속적으로 제공하는 단계를 더 포함한다. 도 8a에도 도시된 바와 같이, 방법을 반복하여 해당 디지털 비디오 스트림을 연속적으로 생성 및 제공/게시할 수 있다. 후속 단계에서 방법이 종료된다. 도 8b는 상기 제2 측면에 따른 방법을 도시한다. 제1 단계에서 방법이 시작된다. 후속 수집 단계에서, 다수의 상기 기본 비디오 스트림이, 이 예시의 경우에는, 상기 제1 그룹의 참여 클라이언 트로부터 선택된 각각의 참여 클라이언트(121')로부터 수집된 적어도 제1 기본 디지털 비디오 스트림 및 제2 기 본 디지털 비디오 스트림이 수집된다. 도 8a에 예시된 방법의 경우와 같이, 수집은 위에서 설명한 바와 같을 수 있으며, 수집 기능은 예를 들어 재인코딩을 수행하지 않고 원시 데이터를 처리한다. 또한, 제1 생성된 디지털 비디오 스트림을 생성할 목적으로 참여 클라이언트의 제1 그룹(121')으로부터 수집된 기본 디지털 비디오 스트림에 적용된, 전술한 일반적인 형태 의 이벤트 감지 단계, 동기화 단계, 패턴 감지 단계가 있을 수 있다. 즉, 후속 제1 생성 단계에서, 제1 생성 기능(135')은 수집 기능으로부터 각각의 디지털 비디오 스트림으로 서 상기 제1 및 제2 기본 비디오 스트림을 수신하고, 상기 제1 및 제2 기본 디지털 비디오 스트림에 기초하여 상기 제1 생성된 디지털 비디오 스트림을 생성한다. 바람직하게, 제1 디지털 비디오 스트림은 다른 참여 클라이 언트가 상기 비디오 통신 서비스에서 제1 그룹(121') 구성원과 상호 작용할 수 있도록 허용하는 방식 으로 상기 제1 그룹(121')에 할당된 참여 클라이언트를 제외하고 하나의 동일한 비디오 통신 서비스에 연 결된 다른 참여 클라이언트를 기반으로 생성되지 않는다. 반면에, 처음 생성된 비디오 스트림은 외부 비디 오 피드; 정적 데이터 또는 그래픽과 같은 다른 정보를 기반으로 생성될 수 있다. 명확하게 말하면, 도 8b와 관 련하여 설명된 이들 및 다른 사항은 도 8a, 8c 및 8d에 설명된 방법에도 적용될 수 있다. 따라서 이 제1 생성의 결과는 예를 들어 해당 기본 비디오 스트림 중 하나 또는 여러 개를 처리되거나 처리되지 않은 형태로 하위 부분으로 시각적으로 포함할 수 있는, 위에 설명된 유형의 생성된 디지털 비디오 스트림이다. 제1 생성된 비디오 스트림은 중앙 서버에 의해 생성된 비디오 출력 스트림과 관련하여 위에서 일반적으로 설명한 바와 같이, 실시간으로 캡처된 비디오 스트림, 슬라이드, 외부에서 제공되는 비디오 또는 이미지 등을포함할 수 있다. 제1 생성된 비디오 스트림은 또한 위에서 설명한 일반적인 방식으로 제1 그룹(121') 참여 클라 이언트에 의해 제공되는, 의도적으로 지연되거나 실시간인 제1 및/또는 제2 기본 비디오 스트림의 감지된 이벤 트 및/또는 패턴을 기반으로 생성될 수 있다. 후속하는 제2 생성 단계에서, 제2 생성된 디지털 비디오 스트림은 상기 제1 생성된 비디오 스트림 모두에 기초 하고 또한 참여 클라이언트(121')의 제1 그룹 으로부터 수집된 상기 제1 및 제2 기본 디지털 비디오 스트림에 기초하여 디지털 비디오 스트림으로 생성된다. 제1 및 제2 기본 디지털 비디오 스트림은 수집 기능으로부 터 제2 생성 기능(135\")으로 제공될 수 있는 반면; 제1 생성된 비디오 스트림은 제1 생성 기능(135')에서 제2 생성 기능(135\")으로 제공될 수 있다. 제1 및 제2 생성 기능(135', 135\")이 하나의 동일한 논리 유닛인 경우(가 능성 있음), 생성은 단순히 해당 생성 기능에서 두 개의 연속 단계에서 발생한다. 후속 단계에서, 방법이 종료된다. 제2 생성 단계(135'')에 공급되는 상기 제1 및/또는 제2 기본 비디오 스트림은 제2 생성 단계(135'') 이전에 다 양한 방식으로 사전 포맷될 수 있다는 것이 인식된다. 또한 위에서 일반적으로 설명한 대로 이벤트 및/또는 패 턴을 감지하기 위해 의도적으로 지연될 수도 있다. 제2 생성 단계는 위에 설명된 임의의 생성 단계와 유사할 수 있으며, 생성 기능(135, 135')의 기능과 관련하여 위에서 언급한 모든 내용은 또한 제2 생성 기능(135'')에도 상응하게 적용 가능하다. 예를 들어, 제2 생성 기능 (135')은 생성 프로세스의 일부로서 다양한 방식으로 기본 비디오 스트림을 포맷함으로써 제2 생성된 비디오 스 트림을 생성할 수 있다. 언급한 바와 같이, 제1 및 제2 기본 비디오 스트림은 제1 생성 기능(135')에 공급되기 전에, 위에서 설명한 방 식 중 임의의 방식으로 공통 시간 기준을 사용하는 등에 의해 서로 시간 동기화될 수 있다. 그러나, 상기 제2 생성 단계에서, 제1 및 제2 기본 디지털 비디오 스트림은 의도적으로 시간이 지연될 수 있다 (예를 들어, 기본 비디오 스트림을 서로 시간 동기화하고/하거나 제1 생성 기능(135')에서 사용하기 위한 이벤 트 및/또는 패턴을 감지할 수 있도록 수행된 이미 적용된 시간 지연에 더하여 의도적으로 시간을 지연됨). 이제 이 의도적으로 도입된 시간 지연의 목적과 결과는 제2 생성된 비디오 스트림에 사용되기 전에 제1 생성된 비디 오 스트림과 시간을 동기화하는 것이다. 따라서, 제1 및 제2 기본 비디오 스트림과 관련하여 도입된 추가 지연 은 제1 생성 단계를 수행하는 것과 관련된 대기 시간과 같거나, 실질적으로 같거나, 적어도 그 함수로서 결정된 다. 추가할 정확한 대기 시간은 예를 들어 위에 설명된 일반 유형의 감지된 공통 시간 기준에 기초하여 결정될 수 있다. 즉, 제1 생성된 비디오를 생성하는 제1 생성 단계는 일반적으로 예를 들어 사용 가능한 컴퓨터 성능 및 제1 생 성 단계(135')의 복잡성에 따라 달라질 수 있는, (제1 생성 단계(135') 자체의 데이터 처리로 인한) 특정 대기 시간과 연관된다. 이 대기 시간은 일반적으로 간단히 캡처되고 언급된 방식으로 선택적으로 처리되고, 그 후 수 집 기능에 의해 제공되어 제2 생성 기능(135')에 의해 사용되는, 상기 제1 및 제2 비디오 스트림 자체에는 존재하지 않는다(또는 대기 시간이 있더라도 적다). 이 세 가지 비디오 스트림을 시간 동기화하기 위해, 제1 생성 단계에서 결과되는 제1 생성된 비디오 스트림의 대기 시간을 고려하여, 의도적으로 제1 및 제2 기본 비디오 스트림에 이러한 (추가) 지연을 도입함으로써, 제2 생성된 비디오 스트림이 제1 및 제2 기본 비디오 스트림을 기반으로 생성될 뿐만 아니라 제1 생성된 비디오 스 트림을 기반으로 생성되고, 차례로 동일한 제1 및 제2 기본 비디오 스트림을 기반으로 생성되는 경우에도, 동기 화 문제 없이 제2 비디오 스트림을 생성하는 것이 가능하다. 즉 시간 지연된 제1 및 제2 기본 디지털 비디오 스 트림을 기반으로 제2 생성된 비디오 스트림이 생성된다. 따라서, 제1 생성된 비디오 스트림은 제2 생성 단계(135'')로 공급될 수 있으며, 제2 생성된 비디오 스트림은 두 개(또는 그 이상의) 생성 단계(135', 135')를 사용하여 생성되고 여기서 동일한 기본 비디오 스트림은 수집 기능에 의해 제공되는 기본 비디오 스트림의 공통 시간 기준과 관련하여 서로 다른 지연 시간과 관련된 적 어도 두 개의 생성 단계에서 사용된다. 예시적인 예에서, 제1 그룹(121') 참여 클라이언트는 상대적으로 낮은 대기 시간으로 비디오 통신 서비스 를 사용하여 통신하는 토론 패널의 일부이며, 이 참여 클라이언트 각각은 처음으로 생성된 비디오 스트림을 연 속적으로 공급받는다(또는 위의 도 8a와 관련하여 설명된 바와 같이 서로의 각각의 기본 비디오 스트림). 토론 패널의 청중은 제2 그룹(121\") 참여 클라이언트로 구성되며, 제2 생성된 비디오 스트림을 연속적으로 공급받으 며 결과적으로 대기 시간이 약간 더 길어진다. 제2 생성된 비디오 스트림은 위에서 논의한 일반적인 방식으로자동으로 생성되어, 개별 토론 패널 발언자의 보기(제1 그룹(121')에 할당된 참여 클라이언트, 이러한 뷰는 수 집 기능에서 직접 제공됨)와 모든 토론 패널 발언자를 보여주는 생성된 보기(이 보기는 처음으로 생성된 비디오 스트림임) 사이에서 자동으로 전환할 수 있다. 제1 및/또는 제2 측면에 따른 발명을 사용하여, 청중은 잘 만들어진 경험을 할 수 있고 패널 스피커는 최소한의 대기 시간으로 서로 상호 작용할 수 있다. 제2 생성 단계와 관련하여 제1 및 제2 기본 비디오 스트림에 의도적으로 추가된 지연은 적어도 0.1초, 예를 들 어 적어도 0.2초, 예를 들어 적어도 0.5초; 최대 5초, 최대 2초, 최대 1초일 수 있다. 또한 제1 및 제2 기본 비 디오 스트림과 제1 생성된 비디오 스트림 간의 전체 시간 동기화를 달성하기 위해서, 각 기본 비디오 스트림과 관련된 상속 지연 시간에 따라 달라질 수도 있다. 제1 및 제2 기본 비디오 스트림은 물론 제1 생성된 비디오 스 트림도 모두 추가로 의도적으로 지연되어 위에서 설명한 일반적인 방식으로 제2 생성 기능(135\")에서 사용하기 위한 패턴 감지를 향상시킬 수 있다는 것이 이해된다. 도 9는 중앙 서버에 의해 생성된 다양한 생성된 비디오 스트림을 게시하는 다수의 대안적 또는 동시 방식 을 도시한다. 일반적으로, 제1 생성 기능(135')으로부터 처음으로 생성된 비디오 스트림을 수신하도록 배열된 제1 게시 기능 (136')에 의해 수행되는 후속 게시 단계에서, 상기 제1 생성된 비디오 스트림은 제1 참여 클라이언트 및 제2 참여 클라이언트 중 적어도 하나에게 연속적으로 제공될 수 있다. 예를 들어, 이 제1 참여 클라이언트 는 제1 기본 디지털 비디오 스트림을 제공하는 그룹(121')의 참여 클라이언트일 수 있고/또는 제2 참여 클라이 언트는 제2 기본 디지털 비디오 스트림을 제공하는 그룹(121\")의 참여 클라이언트일 수 있다. 다시 말해서, 제1 생성된 비디오 스트림은 상기 제1 참여 클라이언트 및 상기 제2 참여 클라이언트 중 적어도 하나에게 연속적으로 제공될 수 있다. 일부 실시 예에서, 그룹(121')의 참여 클라이언트 중 하나 또는 여러 개는 또한 제2 게시 기능(136\")에 의해 제 2 생성된 비디오 스트림을 수신할 수 있으며, 차례로 제2 생성 기능(135\")으로부터 제2 생성된 비디오 스트림을 수신하도록 구성된다. 따라서, 상기 기본 디지털 비디오 스트림이 직접 제공되지 않는 경우, 제1 그룹(121')에 할당된 각각의 기본 비 디오 스트림 제공 참여 클라이언트는 위에서 설명한 바와 같이, 상기 기본 비디오 스트림 간의 동기화로 인한 특정 지연 또는 대기 시간, 및 또한 의도적으로 추가된 지연 또는 이벤트 및/또는 패턴 감지를 위한 충분한 시 간을 허용하기 위해 추가된 대기 시간을 포함하는, 제1 생성된 비디오 스트림이 제공될 수 있다. 이에 따라, 제2 그룹(121\")에 할당되어 있는 각각의 참여 클라이언트는 제1 생성된 비디오 스트림을 제1 및 제2 기본 비디오 스트림과 시간 동기화할 목적으로 추가된, 제2 생성 단계와 관련하여 상기 의도적으로 추가된 지연 을 포함하는, 제2 생성된 비디오 스트림을 제공받을 수 있다. 이러한 추가 지연은 예를 들어 제2 그룹(121\")의 참여 클라이언트들 사이에서 통신 문제를 야기할 수도 있고 하지 않을수도 있는데, 왜냐하면 이들은 비디오 통 신 서비스와 제1 그룹(121') 참여자들과는 다른 방식으로 상호 작용하기 때문이다(아래 참조). (제1 그룹 (121') 참여 클라이언트가 기본 디지털 비디오 스트림을 직접 제공받는 경우와 같은) 다른 실시 예에서, 제2 그 룹(121\")에 할당된 각 참여 클라이언트는 처음 생성된 비디오 스트림을 직접 제공받을 수 있다. 따라서, 제1 그룹(121') 참여 클라이언트는 생성된 비디오 스트림, 예를 들어 제1 또는 제2 생성된 비디오 스트 림을 연속적으로 제공받는 대신 참여 클라이언트보다 약간 빠른 (예를 들어, 1~3초 앞선) \"시간대\"에서 해당 서 비스에 존재하고 이를 사용하는, 해당 비디오 통신 서비스에 현재 참여하고 있는 모든 참여 클라이언트 의 하위 그룹을 형성한다. 여전히, 다른 참여 클라이언트(제1 그룹(121')에 할당되지 않고 대신 제2 그룹 (121\")에 할당됨)에는 제1 및 제2 기본 비디오 스트림을 기반으로(각 시점에서 이들 중 하나 또는 둘 다를 포함 할 수 있음) 생성되지만 약간 늦은 \"시간대\"에 생성되는 제2 생성된 비디오 스트림이 연속적으로 제공된다. 기 본 비디오 스트림 자체를 기반으로 이미 생성된 비디오 스트림에 시간을 동기화하기 위해 추가되는 지연이나 대 기 시간이 없이, 제1 생성된 비디오 스트림은 제1 및 제2 기본 비디오 스트림을 기반으로 직접 생성되기 때문에, 보다 직접적이고 대기 시간이 짧은 비디오 통신 서비스 경험이 이러한 참여 클라이언트에 이 용 가능하게 된다. 이것은 또한 제1 그룹(121')에 할당된 참여 클라이언트에 제2 생성된 비디오 스트림에 대한 액세스가 제공 되지 않음을 의미할 수도 있다.즉, 상기 제1 및 제2 기본 디지털 비디오 스트림은 위에서 논의된 일반적인 유형의 공유 디지털 비디오 통신 서 비스의 일부로 제공될 수 있고, 상기 제1 참여 클라이언트 및 상기 제2 참여 클라이언트(동일한 제1 그룹 (121')에 속함)는 둘 다 각각 상기 공유 디지털 비디오 통신 서비스에 원격으로 연결된 참여 클라이언트일 수 있다. 상기 제2 그룹(121\")의 참여 클라이언트(또한 제3 그룹(121\"')의 참여 클라이언트))은 또한 상기 공유 디지털 비디오 통신 서비스에 원격으로 연결된 참여 클라이언트일 수 있다. 이러한 맥락에서, \"원격 연결\"은 반드시 이러한 참여 클라이언트 또는 해당 사용자가 다른 방, 건물 또는 지리적 위치에 위치한다는 것을 의미하지 않고, 사용자는 해당 참여 클라이언트를 사용하여 비 디오 통신 서비스와 오디오/시각적으로 상호 작용한다. 상기 수집 단계는 위에서 설명한 임의의 방식과 같이 공유 디지털 비디오 통신 서비스로부터 상기 제1 및/ 또는 제2 기본 디지털 비디오 스트림을 수집하는 것을 포함할 수 있다. 도 8c는 상기 제3 측면에 따른 방법을 도시한다. 말한 바와 같이, 도 8c에 도시된 방법은 도 8d에 도시된 방법 의 경우와 마찬가지로 도 8a 및 8b에 도시된 것과 유사하며, 본 발명의 이들 4가지 측면은 자유롭게 조합 가능 하다. 이러한 측면 중 하나와 관련하여 언급된 모든 내용은 호환성을 가지고 다른 측면에도 대응하는 방식으로 쉽게 적용 가능하다. 제1 단계에서 방법이 시작된다. 후속 수집 단계에서, 상기 제1 그룹(121')에 할당된 상기 제1 참여 클라이언트로부터, 제1 기본 디지털 비디오 스트림이 수집되고, 제2 참여 클라이언트로부터 제2 기본 디지털 비디오 스트림이 수집되어, 역시 동일한 제1 그룹(121')에 할당된다. 또한, 제3 디지털 비디오 스트림은 제3 참여 클라이언트로부터 수집되고, 이것은 제1 그룹(121')에 할당되지 않을 수 있다. 예를 들어, 제3 참여 클라이언트는 제2 그룹(121\")에 할당될 수 있다. 이 수집 단계는 도 8b와 관련하여 설명된 수집 단계와 유사할 수 있다. 도 8b와 관련하여 설명된 제1 생성 단계와 유사할 수 있는 후속 제1 생성 단계에서, 제1 생성된 비디오 스트림 은 상기 수집된 제1 및 제2 기본 디지털 비디오 스트림을 기반으로 디지털 비디오 스트림으로 생성될 수 있다. 본 명세서에서 제1 생성된 비디오 스트림은 상기 제3 기본 비디오 스트림에 기초하여 생성되지 않을 수도 있다 는 점에 유의한다. 제1 생성된 디지털 비디오 스트림은 일부 소비 클라이언트에 게시하기 위해 제1 대기 시간이 있는 상태로 연속 적으로 생성된다. 즉, 이 제3 측면에 따르면, 제1 생성된 디지털 비디오 스트림이 생성되므로, 제1 생성된 디지 털 비디오 스트림의 새로 생성된 각 프레임이 해당 프레임 생성 즉시 게시되는 경우, 해당 프레임의 게시는 제1 지연 시간에 발생한다. 도 8b와 관련하여 설명된 제2 생성 단계와 유사할 수 있는 후속 제2 생성 단계에서, 제2 생성된 비디오 스트림 은 세 가지 기본 디지털 스트림 모두, 즉 상기 제1, 제2 및 제3 기본 디지털 비디오 스트림 모두를 기반으로 하 는 디지털 비디오 스트림으로 생성된다. 제1 생성된 비디오 스트림과 제1 대기 시간에 대응하는 방식으로, 제2 생성된 디지털 비디오 스트림은 제2 대기 시간으로 게시를 위해 연속적으로 생성된다. 제2 대기 시간은 제1 대기 시간보다 크다. 이는 제1 및 제2 생성된 비디오 스트림이 모두 예를 들어 제1 기본 비디오 스트림의 프레임을 포함하는 경우 이러한 프레임은 제2 생성 된 비디오 스트림의 즉시 게시와 비교하여 제1 생성된 비디오 스트림의 즉시 게시에서 더 일찍 표시되는 것을 의미한다. 도 8b와 관련하여 설명된 게시 단계와 유사할 수 있는 후속 게시 단계에서, 상기 제1 기본 디지털 비디오 스트 림, 상기 제2 기본 디지털 비디오 스트림 및 상기 제1 생성된 비디오 스트림 중 적어도 하나(예를 들어, 이들 스트림 중 하나 이상의 임의의 세트)는 제1 참여 클라이언트와 제2 참여 클라이언트 중 적어도 하나에게 연속적 으로 제공된다. 이는 상기 도 8a와 관련하여 설명된 방법과 유사한다. 또한, 상기 제2 생성된 비디오 스트림은 적어도 하나의 다른 참여 클라이언트에게 연속적으로 제공된다. 후속 단계에서 방법이 종료된다. 제2 측면 솔루션의 실제 적용을 설명하는 데 사용된 동일한 예를 사용하여 이 제3 측면이 어떻게 실행될 수 있 는지 설명할 수도 있다. 제3 기본 비디오 스트림은 제1 및 제2 기본 비디오 스트림을 제공하는 제1 그룹(121') 참여 클라이언트보다 대기 시간에 대한 요구 사항이 더 낮은, 제2 그룹(121\") 참여 클라이언트에서 수집되므로,제2 생성된 비디오 스트림은 지연 시간이 더 긴 방식으로 제공되어, 원하는 자동 생성을 달성하는 것을 가능하 게 하는 반면, 제1 그룹(121') 패널 토론 발표자들은 더 짧은 대기 시간으로 서로 상호 작용할 수 있다. 당연히, 제3 기본 비디오 스트림 외에도 더 많은 제2 그룹(121\") 제공되는 기본 비디오 스트림이 있을 수 있으 며, 이는 이후에 상응하게 사용될 것이다. 도 8b 및 8c와 관련하여 설명한 게시 단계에서, 제2 생성된 비디오 스트림은 제1 또는 제2 참여 클라이언트가 아닌 적어도 하나의 소비 클라이언트에 연속적으로 제공될 수 있다. 보다 일반적으로, 이것은 제1 그룹(121') 및/또는 외부 소비자에 할당되지 않은 참여 클라이언트에 연속적으로 제공될 수 있다. 상술한 바와 같이, 수집 단계는 상기 공유 디지털 비디오 통신 서비스 외부의 정보 소스로부터 수집된, 위에서 논의된 유형의 외부 디지털 비디오 스트림으로서, 제1 및 제2 기본 비디오 스트림에 추가 하여 추가적인 기본 비디오 스트림과 같은 상기 기본 디지털 비디오 스트림 중 적어도 하나를 수집하는 단계를 포함할 수 있다. 위에서도 설명한 바와 같이, 그러한 외부 비디오 스트림은 수집 기능과 제1 생성 기 능(135') 사이에 (데이터 흐름의 측면에서) 논리적으로 위치한 동기화 기능에 의해 제1 및 제2 기본 비디 오 스트림에 시간 동기화될 수 있다. 대응하는 내용은 여기에 설명된 제3, 제4 및 제5 기본 비디오 스트림에 적 용된다. 그러면 제1 및/또는 제2 생성된 비디오 스트림은 상기 외부 디지털 비디오 스트림을 기반으로 생 성될 수 있다. 위에서 일반적으로 논의한 바와 같이, 제1 및 제2 생성 단계(135' 및/또는 135\")는 해당 상기 생성된 디지털 비디오 스트림에서 상기 제1 및/또는 제2 기본 디지털 비디오 스트림의 개별 스트림의 가시성; 시각적 및/ 또는 청각적 비디오 콘텐츠 배열; 시각 또는 청각 효과 사용; 및/또는 해당 생성된 디지털 비디오 스트림의 출 력 모드에 관한 미리 결정된 및/또는 동적으로 가변적인 매개변수 세트에 기초하여 해당 각각의 생성된 (제1 및 /또는 제2) 비디오 스트림을 생성하는 단계를 더 포함할 수 있다. 또한 논의한 바와 같이, 제1 및 제2 생성 단계(135' 및/또는 135\")는 위에서 논의된 일반 유형의 API를 통 해 라이브 비디오 스트림으로서 하나 이상의 동시(외부 및/또는 참여) 소비자 클라이언트에게 상기 제2 생성된 비디오 스트림을 제공하는 중앙 서버에 의해 수행될 수 있다. 따라서, 참여 클라이언트의 서로 다른 그룹(121', 121\", 121\"')은 지연 허용 오차 측면에서 서로 다른 요 구 사항을 가질 수 있다. 이는 특히 그들이 서비스에 참여하는 클라이언트와 동일한 하나의 라이브 비디오 통신 서비스에 참여하는 경우에 해당될 수 있다. 이에 대해서는 아래에서 추가로 예시한다. 도 8d는 본 발명의 상기 제4 측면에 따른 방법을 도시한다. 제1 단계에서 방법이 시작된다. 일반적으로, 도 8d에 예시된 바와 같이, 상기 제2 생성된 디지털 비디오 스트림을 생성하는 방법은 초기 단계일 수 있지만, 예를 들어 재할당 단계와 같이 방법 중 언제든지 수행될 수도 있는 후속 할당 단계를 포함할 수 있 다. 이 할당 단계에서, 복수의 참여 클라이언트는 적어도 이러한 참여 클라이언트의 두 그룹(121', 121\", 121\"')에 할당될 수 있다. 본 예에서, 할당은 적어도 제1 그룹(121') 및 제3 그룹(121\"')으로 이루어지지만, 참 여 클라이언트는 물론 제3 그룹(121\"')에 할당될 수도 있다. 특히, 제1 기본 디지털 비디오 스트림 및 제2 기본 디지털 비디오 스트림은 수집 기능에 의해 그리고 후속 수집 단계에서와 같이, 참여 클라이언트의 상기 제1 그룹(121')에 할당된 각각의 참여 클라이언트로부터 수집될 수 있다. 하지만, 제4 기본 디지털 비디오 스트림 및 제5 기본 디지털 비디오 스트림은 또한 수집 기능 에 의해 상기 수집 단계에서, 참여 클라이언트의 제3 그룹(121\"')에 할당된 각각의 참여 클라이언트 로부터 수집될 수 있다. 도 9에 도시된 예에서, 제3 그룹(121\"')에 할당된 참여 클라이언트는 제1 그룹(121')에 할당된 참여 클라 이언트보다 덜 엄격한 대기 시간 요구사항을 가질 수 있다. 예를 들어, 제1 그룹(121') 참여 클라이언트 는 위에서 논의된 토론 패널의 구성원일 수 있는 반면(서로 실시간으로 상호 작용하므로 낮은 대기 시간이 필요함), 제3 그룹(121\"') 참여 클라이언트는 패널과 상호 작용하지만 보다 구조화된 방식(예를 들어, 명 확한 질문/답변 사용하여)으로 상호 작용하는 전문가 또는 이와 유사한 패널로 구성할 수 있으므로, 제1 그룹 (121')보다 더 높은 대기 시간을 허용할 수 있다.제1 생성된 비디오 스트림은 전술한 바와 같이, 제1 생성 기능(135')에 의해 그리고 제1 및 제2 기본 비디오 스 트림(및 논의된 추가 입력 콘텐츠)에 기초하여 생성될 수 있다. 제3 생성된 비디오 스트림은 대응하는 방식으로, 제3 생성 기능(135'')에 의해 그리고 (적어도) 제4 및 제5 기본 비디오 스트림을 기반으로 하여 생성 된다. 제1 생성된 비디오 스트림 및 제3 생성된 비디오 스트림은 모두 경우에 따라 제2 생성 기능(135')에 공급되어 제2 생성된 비디오 스트림의 생성을 기반으로 할 수 있다. 그러나 이 제4 측면에 따르면, 제2 생성 기능(135')에 의해 수행되는 제2 생성 단계에서, 제2 생성된 비디오 스 트림은 상기 제1 및 제2 기본 비디오 스트림 중 적어도 하나에 기초하여 생성되고, 또한 위에서 설명한 방식과 같이 상기 제4 및 제5 기본 비디오 스트림 중 적어도 하나에 기초하여 생성된다. 제2 생성 기능(135\")에는 교차 스트림 시간 동기화, 이벤트 감지 등을 포함하여, 제1 및 제2 기본 비디오 스트림과 대응하는 방식으로 수집 기 능으로부터 제4 및 제5 기본 비디오 스트림이 제공될 수 있다. 특히 제2 생성된 비디오 스트림은 제1 및/ 또는 제2 기본 비디오 스트림에 직접적 또는 간접적으로 기초할 수 있으며, 예를 들어, 제2 생성된 비디오 스트 림은 제1 생성된 비디오 스트림에 기초하고, 다음에 제1 및 제2 기본 비디오 스트림에 기초하고; 제4 및 제5 기 본 비디오 스트림 및 제3 생성된 비디오 스트림에 대해서도 이에 대응한다. 상기 제3 생성된 비디오 스트림은 후속하는 제3 생성 단계에서 생성된다. 제4 측면에 따르면, 제3 생성 단계는 서로 시간 동기화되지만 제1 생성된 비디오 스트림과는 시간 동기화되지 않도록(시간 동기화되지 않음) 상기 제4 및 제5 기본 비디오 스트림에 대해 의도적으로 시간 지연을 도입하는 단계를 포함한다. 이러한 시간 지연은 제3 생성 기능(135\"') 자체에 도입되거나, 해당 제3 생성 기능(135\"')의 업스트림에 대응하는 동기화 기능에 도입될 수 있다고 이해된다. 그러므로, 제1 생성 단계(135')는 제1 및 제2 기본 비디오 스트림의 동기화의 일부로서 도입된 임의의 지연에 더하여 도입되고, 예를 들어 효율적인 이벤트 및/또는 패턴 감지를 수행하는 데 충분한 시간을 확보하기 위해 도입된, 위에서 논의된 유형의 의도적인 지연 또는 대기 시간을 도입하는 단계를 포함할 수 있다. 이러한 의도 적인 지연 또는 대기 시간 도입은 상기 동기화 기능(간단함을 이유로 도 9에는 도시되지 않음)에 의해 수 행되는 동기화의 일부로서 발생할 수 있다. 이는 제3 생성 단계(135'')에 대해 해당될 수 있지만, 제1 생성 단 계(135'')에 대해 의도적으로 도입된 지연 또는 대기 시간과 다른 의도적인 지연 또는 대기 시간을 도입한다. 특히, 의도적으로 도입된 지연 또는 대기 시간으로 인해 제1 생성된 비디오 스트림과 제3 생성된 비디오 스트림 간의 시간 비동기화가 발생한다. 이는 제1 및 제3 생성된 비디오 스트림이 각 개별 프레임 생성 시 즉시 연속적 으로 게시되는 경우 공통 타임라인을 따르지 않음을 의미한다. 위에서 논의한 바와 같이, 제2 생성된 비디오 스트림은 제1 생성된 비디오 스트림보다 더 높은 대기 시간과 연 관될 수 있으며, 아마도 제3 생성된 비디오 스트림보다 더 높은 대기 시간과 연관될 수도 있다. 따라서, 제2 생 성 기능(135')은 제2 생성된 비디오 스트림에 통합하기 전에 추가적인 각각의 지연을 추가함으로써 제1, 제2, 제4 및 제5 기본 비디오 스트림을 동기화하도록 구성될 수 있다. 게시 단계에서, 제3 생성된 비디오 스트림은 상기 제3 그룹(121\"')에 할당된 적어도 하나의 참여 클라이언트에 게 연속적으로 제공되고, 여기서 이것은 해당 사용자에게 연속적으로 게시될 수 있다. 비슷하게, 제1 생성 된 비디오 스트림은 제1 그룹(121')에 할당된 적어도 하나의 참여 클라이언트에 연속적으로 제공될 수 있고, 여 기서 이것은 해당 사용자에게 게시될 수 있고; 및/또는 제2 생성된 비디오 스트림은 위에서 설명한 대로 제공되고 게시될 수 있다. 후속 단계에서, 방법이 종료된다. 따라서, 이 제4 측면에서는 세 개의 개별 생성된 비디오 스트림이 동시에 생성되고 소비/게시될 수 있지만, 서 로 다른 \"시간대\"에 있다. 적어도 부분적으로 동일한 기본 비디오 자료를 기반으로 하고 있지만, 생성된 비디오 스트림은 다른 대기 시간으로 게시된다. 가장 낮은 대기 시간을 요구하는 제1 그룹(121')은 처음 생성된 비디오 스트림을 사용하여 상호 작용할 수 있어 매우 낮은 대기 시간을 제공하고; 약간 더 큰 대기 시간을 기꺼이 수용 하는 제3 그룹(121\"')은 제2 생성된 비디오 스트림을 사용하여 상호 작용하여, 본 명세서의 다른 부분에서 설명 한 대로 더 나은 자동 생성을 달성하기 위해서 더 많은 대기 시간을 제공하지만 의도적으로 추가된 지연 측면에 서 더 큰 유연성을 제공하는 반면; 지연 시간에 그다지 민감하지 않은 제2 그룹(121\")은 제1 그룹(121') 및 제3 그룹(121\"')의 재료를 통합할 수 있으며 매우 유연한 방식으로 자동 생성될 수도 있는 제2 생성된 비디오 스트림을 사용하여 상호 작용을 즐길 수 있다. 특히 참가자 사용자의 이러한 모든 그룹(121', 121\", 121'\")은 상기 다양한 대기 시간을 사용하고 따라서 서로 다른 \"시간대\"에서 작동함에도 불구하고 상기 비디오 통신 서비스 를 사용하여 서로 상호 작용한다는 것에 유의한다. 그러나 각 생성 기능에서 개별 입력 비디오 스트림의 동기화로 인해, 참가자 사용자는 각자의 관점에서 다른 대기 시간을 인식하지 못할 것이다. 상기 제1 생성 단계(135')는 전술한 바와 같이 제1 및 제2 기본 비디오 스트림을 서로 시간 동기화하기 위해 시 간 지연을 포함할 수 있다. 이에 따라, 상기 제3 생성 단계(135'')(또는 대응하는 동기화 단계)는 상기 제1 생성 단계(135')(또는 대 응하는 동기화 단계)에서 상기 제1 및 제2 기본 비디오 스트림을 시간 지연시키는 데 사용되는 최대 시간 지연보다 더 큰 최대 시간 지연을 사용하여, 상기 제4 및 제5 기본 비디오 스트림을 서로 시간 동기화하기 위해 시간 지연을 포함할 수 있고, 결과적으로 제1 생성된 비디오 스트림은 설명된 방식으로 제3 생성된 비디오 스트 림과 시간 동기화되지 않는다. 위에서 논의한 바와 같이, 상기 그룹(121', 121\", 121\"') 각각에 할당된 각각의 참여 클라이언트는 제2 생 성된 비디오 스트림이 연속적으로 게시되는 하나의 동일한 비디오 통신 서비스에 참여할 수 있다. 그러면, 상기 그룹(121', 121\", 121'\") 중 서로 다른 그룹은 상기 비디오 통신 서비스의 서로 다른 참가자 상호 작용 권한과 연관될 수 있고, 상기 그룹(121', 121\", 121'\") 중 서로 다른 그룹은 해당 그룹(121', 121\", 121'\")에 할당된 참여 클라이언트에게 게시된 각각의 생성된 비디오 스트림을 생성하는 데 사용되는 서로 다른 최대 시간 지연(대기 시간)과 연관될 수 있다. 예를 들어, 패널 토론 참여 클라이언트의 제1 그룹(121')은 완전한 상호 작용 권한을 갖고 연관될 수 있으며 원 할 때마다 말할 수 있다. 참여 클라이언트의 제3 그룹(121\"')은 약간 제한된 상호작용 권한과 연관될 수 있다. 예를 들어 그들은 마이크 음소거를 해제하는 비디오 통신 서비스에 의해 말할 수 있기 전에 발언권을 요청 할 필요가 있다. 청중 참가자 사용자의 제2 그룹(121\")은 공동 채팅방에서 서면으로 질문을 할 수는 있지만 말 할 수 없는 등 훨씬 더 제한된 상호작용 권리와 연관될 수 있다. 따라서, 다양한 그룹의 참가자 사용자는 서로 다른 상호 작용 권한 및 그들에게 게시되는 각각의 생성된 비디오 스트림에 대한 서로 다른 대기 시간과 연관될 수 있으며, 이러한 방식으로 대기 시간은 상호 작용 권한을 감소 시키는 증가 함수이다. 해당 참가자 사용자가 비디오 통신 서비스에 의해 다른 사용자와 상호 작용하 는 것이 더 자유롭게 허용될수록 허용되는 대기 시간은 낮아진다. 허용되는 대기 시간이 낮을수록, 대응하는 자 동 생성 기능이 감지된 이벤트나 패턴과 같은 것을 고려할 가능성이 적어진다. 대기 시간이 가장 큰 그룹은 시청자 전용 그룹일 수 있고, 비디오 통신 서비스에 수동적으로 참여하는 것 외에 상호작용 권한이 없다. 특히, 상기 그룹(121', 121\", 121'\") 각각에 대한 각각의 최대 시간 지연(대기 시간)은 해당 그룹의 참여 클라 이언트에게 연속적으로 게시되는 모든 기본 비디오 스트림과 임의의 생성된 비디오 스트림에 걸쳐 가장 큰 대기 시간 차이로 결정될 수 있다. 이 합계에는 위에서 설명한 이벤트 및/또는 패턴을 감지할 목적으로 의도적으로 추가된 추가 시간 지연이 추가될 수 있다. 본 명세서에 사용된 바와 같이, \"생성\" 및 \"생성된 디지털 비디오 스트림\"이라는 용어는 다양한 유형의 생성을 의미할 수 있다. 한 가지 예에서, 단일의 잘 정의된 디지털 비디오 스트림은 해당 생성된 디지털 비디오 스트림 을 소비할 참여 클라이언트의 특정 세트 각각에 대한 제공 및 발행을 위해, 해당 생성된 디지털 비디오 스 트림을 형성하기 위해 중앙 서버와 같은 중앙 개체에 의해 생성된다. 다른 경우, 참여 클라이언트와 같은 다른 개인은 해당 생성된 디지털 비디오 스트림의 약간 다른 버전을 볼 수 있다. 예를 들어, 생성된 디지 털 비디오 스트림은 참여 클라이언트 로컬 소프트웨어 기능이 해당 사용자가 전환하고; 화면 에 배열하고; 또는 다른 방식으로 구성하거나 처리하도록 허용할 수 있는 여러 개별 또는 결합된 디지털 비디오 스트림을 포함할 수 있다. 많은 경우 중요한 것은 어느 \"시간대\"(즉, 대기 시간)에 시간 동기화된 하위 구성 요소를 포함하여 생성된 디지털 비디오 스트림이 제공되느냐 하는 것이다. 따라서, 도 8a와 관련하여 전술한 바와 같이, 제1 및 제2 참여 클라이언트가 서로의 기본 비디오 스트림을 제공 받는 경우가 제1 및 제2 참여 클라이언트에 제공되는 제1 생성된 디지털 비디오 스트림으로 볼 수 있다(시간 동 기화된 원시 또는 처리된 제1 및 제2 기본 디지털 비디오 스트림 세트가 제1 및 제2 참여 클라이언트 모두에게 제공된다는 의미에서).위에서 설명된 참여 클라이언트 그룹(121', 121\", 121'\")의 사용을 더 명확하게 하고 예시하기 위해, 다음 예는 세 가지 다른 동시 \"시간대\"를 포함하는 비디오 통신 서비스 회의의 형태로 제공된다: 참여 클라이언트의 제1 그룹(121')은 실시간으로 또는 적어도 거의 실시간으로 서로 상호작용을 경험하고 있다 (피할 수 없는 하드웨어 및 소프트웨어 지연 시간에 따라 다름). 이러한 참여 클라이언트에게는 해당 사용자 간의 상호 작용 및 통신을 달성하기 위해 소리를 포함하여 비디오가 제공된다. 제1 그룹(121')은 회의의 핵심에서 사용자에게 서비스를 제공할 수 있으며, 그 상호작용은 참여할 다른(비-제1 그룹(121')) 참여 클 라이언트가 관심을 가질 수 있다. 다른 참여 클라이언트의 제2 그룹(121\")은 동일한 회의에 참여하지만, 다른 \"시간대\"에 있어 제1 그룹(121')의 참여 클라이언트보다 실시간에서 더 멀다. 예를 들어, 제2 그룹(121\")은 제1 그룹(121')에게 질문을 할 수 있는 등의 상호작용 특권을 가진 청중일 수 있다. 제2 그룹(121\")의 \"시간대\"는 제1 그룹(121')의 \"시간대\"에 비해 지연을 가질 수 있으므로 제기된 질문과 답변이 눈에 띄지만 짧은 지연과 연관될 수 있다. 반면, 이러한 약간 더 큰 지연에 의하면 이 제2 그룹(121\") 참여 클라이언트가 더 복잡한 방식으로 자동 생성된 생성된 디지털 비 디오 스트림을 경험할 수 있게 하므로, 보다 쾌적한 사용자 경험을 제공할 수 있다. 다른 참여 클라이언트의 제3 그룹(121\"')도 동일한 회의에 시청자로서만 참여할 수 있다. 이 제3 그룹(121\"')은 훨씬 더 정교하고 복잡한 방식으로 자동으로 생성될 수 있는 생성된 디지털 비디오 스트림을 소비하며, 제2 \"시 간대\"보다 훨씬 더 지연되는 제3 \"시간대\"에서 소비한다. 그러나, 제3 그룹(121\"')은 제1 그룹(121\")과 제2 그 룹(121\")에 영향을 미치는 방식으로 통신 서비스에 대한 입력을 제공할 수 없으므로, 제3 그룹(121\"')은 '실시 간'으로 진행되는 회의를 기분 좋은 연출로 경험할 예정이다. 물론 본 명세서에서 설명된 원리를 사용하게 되면, 점점 더 큰 시간 지연과 생성 복잡성이 증가하는 각각의 회 의 \"시간대\"와 연관되는 3개 이상의 참여 클라이언트 그룹이 있을 수 있다. 본 발명은 또한 전술한 내용에 따라 제2 디지털 비디오 스트림을 제공하기 위한 컴퓨터 소프트웨어 기능에 관한 것이다. 그런 다음 이러한 컴퓨터 소프트웨어 기능은 실행 시 특히 제1, 제2, 제3 및/또는 제4 측면과 관련하여, 위에서 설명한 수집, 이벤트 감지, 동기화, 패턴 감지, 생성 및 게시 단계 중 적어도 일부를 수행하 도록 배열될 수 있다. 컴퓨터 소프트웨어 기능은 전술한 바와 같이 중앙 서버의 물리적 또는 가상 하드웨 어에서 실행되도록 배열될 수 있다. 본 발명은 또한 제2 디지털 비디오 스트림을 제공하고 중앙 서버를 포함하는 시스템인 시스템에 관한 것이다. 중앙 서버는 특히 제1, 제2, 제3 및/또는 제4 측면과 관련하여, 위에서 설명한 수집, 이벤트 감지, 동기화, 패턴 감지, 생성 및 게시 단계 중 적어도 일부를 수행하도록 배열될 수 있다. 예를 들어, 이들 단계는 위에서 설명한 바와 같이 상기 단계를 수행하기 위해 상기 컴퓨터 소프트웨어 기능을 실행하는 중앙 서 버에 의해 수행될 수 있다. 입력 비디오 스트림의 시간 동기화, 이벤트 및/또는 패턴 감지 등을 포함하는 위에서 설명한 사용 가능한 입력 비디오 스트림 세트를 기반으로 하는 자동 생성 원리는 서로 다른 수준에서 동시에 적용될 수 있다는 것이 이해 된다. 따라서, 이러한 자동 생성된 비디오 스트림 중 하나는 다운스트림 자동 생성 기능에 대한 이용 가능한 입 력 비디오 스트림을 형성하고 이어서 비디오 스트림 등을 생성할 수 있다. 중앙 서버는 개별 참여 클라이언트에 대한 그룹(121', 121\", 121\"') 할당을 제어하도록 배열될 수 있 다. 예를 들어, 라이브 비디오 통신 서비스 세션 중에 특정 참여 클라이언트에 대한 그룹 할당을 동적으로 변경 하는 것은 중앙 서버에 의한 상기 비디오 통신 서비스의 자동 생성의 일부일 수 있다. 이러한 재할당은 예 를 들어 (해당 클라이언트을 통해 제공되는) 개별 참여 클라이언트 사용자의 요청에 따라, 미리 결정 된 시간표에 기초하여 또는 동적으로, 예를 들어 시간이 지남에 따라 동적으로 변할 수 있는 매개변수 데이터의 함수로 트리거될 수 있다. 이에 따라, 중앙 서버는 미리 결정된 시간 슬롯(예를 들어, 계획된 패널 토론 동안) 동안 특정 그룹만을 사용하는 것과 같이, 비디오 통신 서비스 과정 동안 그룹 구조를 동적으로 변경하도록 배열될 수 있다. 그룹 할당에 대한 가능한 실용적인 솔루션 중 하나는 일부 화상 회의 시스템에서 사용 가능한 \"브레이크아웃 룸\"의 개념을 사용하는 것이다. 그러면, 특정 그룹(121', 121\", 121\"')에 할당된 참여 클라이언트는 이러 한 브레이크아웃 룸에 할당될 수 있고, 중앙 서버는 중앙 서버의 다운스트림 생성 단계에서 사용할 해당 브레이크 룸으로부터 개별 기본 비디오 스트림 또는 생성된 비디오 스트림과 같은 비디오 스트림 데이터를얻을 수 있다. 그러한 비디오 스트림 추출은 위에서 설명된 바와 같이 그 자체로 일어날 수 있다. 위에서 설명한 모든 측면에서, 본 발명은 제1 그룹의 적어도 하나의 참여 클라이언트(제1 그룹은 제1 대기 시간 과 연관됨)가 제2 그룹의 적어도 하나의 참여 클라이언트와 두 방향(양방향) 방식으로 상호작용하는 상호작용 단계를 더 포함할 수 있으며, 제2 그룹은 제2 대기 시간과 연관되어 있으며, 제2 대기 시간은 제1 대기 시간과 다르다. 이러한 참여 클라이언트는 모두 위에서 설명한 유형의 동일한 통신 서비스에 대한 참여자가 될 수 있다 는 것이 이해된다. 이런 경우, 상기 참여 클라이언트는 서로 다른 지연 시간(또는 위에서 논의한 \"시간대\")과 연관되어 일시적으로 동일한 \"시간대\"에 놓이고, 즉, 동일한 대기 시간과 관련되는 것이 바람직하다. 예를 들어, 이는 더 큰 대기 시 간과 관련된 상기 참여 클라이언트 중 하나에 의해 일시적으로 발생할 수 있으며 해당 참여 클라이언트와 관련 된 대기 시간보다 더 작은 대기 시간을 사용하여 생성되는 하나 이상의 기본/생성 디지털 비디오 스트림이 일시 적으로 제공된다. 다시 말해서, 일반적으로 더 큰 지연 시간을 갖는 하나 이상의 비디오 스트림을 연속적으로 제공받는 참여 클라이언트가 더 짧은 지연 시간을 갖는 하나 이상의 비디오 스트림을 연속적으로 제공받는 참여 클라이언트와 상호작용을 원하는 경우, 전자의 참여 클라이언트에게는 후자의 비디오 스트림 중 하나 또는 여러 개가 일시적으로 연속적으로 제공된다. 따라서 대기 시간이 긴 참여 클라이언트는 대기 시간이 짧은 참여 클라 이언트와 연결된 대기 시간이 짧은 \"시간대\"로 일시적으로 전환된다. 상호 작용 후 대기 시간이 긴 참여 클라이 언트는 상호 작용 전에 사용된 대기 시간이 높은 통신 환경으로 다시 전환된다. 예를 들어, 위에서 논의된 패널 토론의 청중 중 한 구성원이 질문을 제기하기를 원할 수 있다. 이 경우, 청중 구성원에게 낱말이 주어지고 패널 토론 \"시간대\"로 전환된다. 이는 청중 구성원이 대기 시간이 짧지만 덜 정교 한 생성 과정에서 패널을 보게 된다는 것을 의미한다. 보다 구체적으로, 청중 구성원은 상호 작용 중에 패널 구 성원에게 제공되는 동일한 비디오 스트림 중 하나 또는 여러 개를 볼 수 있다. 나머지 청중은 지연 시간이 더 긴 청중 \"시간대\"에 남아 있으므로 아무런 차이도 느끼지 못할 것이다. 발언하는 청중 구성원과 패널 사이의 상 호 작용 후, 발언하는 청중 구성원에게는 상호 작용 이전과 마찬가지로 지연 시간이 더 긴 비디오 스트림이 다 시 제공된다. 서로 다른 \"시간대\" 사이의 전환은 중앙 서버에 의해 자동으로 이루어질 수 있다. 이상, 바람직한 실시 예가 설명되었다. 그러나, 본 발명의 기본 사상에서 벗어나지 않고 개시된 실시 예에 많은 수정이 이루어질 수 있다는 것이 당업자에게 명백하다. 예를 들어, 본 명세서에서 설명된 시스템의 일부로서 많은 추가 기능이 제공될 수 있으며, 이는 본 명세서 에서 설명되지 않는다. 일반적으로, 현재 설명된 솔루션은 비디오 데이터 스트림이 통신에 사용되는 매우 다양 하고 구체적인 애플리케이션을 충족하기 위해 세부 기능 및 특징이 구축될 수 있는 프레임워크를 제공한다. 한 가지 예는 시연 상황이고, 여기에서 기본 비디오 스트림은 발표자의 모습, 공유된 디지털 슬라이드 기반 프 리젠테이션, 시연 중인 제품의 라이브 비디오를 포함한다. 또 다른 예는 교육 상황이고, 여기에서 기본 비디오 스트림에는 교사의 모습, 교육 주제가 되는 물리적 실체의 라이브 비디오, 교사와 질문을 하고 대화에 참여할 수 있는 여러 학생의 각각의 라이브 비디오를 포함한다. 이 두 가지 예 중 하나에서, (시스템의 일부일 수도 있고 아닐 수도 있는) 비디오 통신 서비스는 기본 비디오 스트림 중 하나 또는 여러 개를 제공할 수 있고, 및/또는 기본 비디오 스트림 중 몇 개가 여기에 설명된 유형의 외부 비디오 소스로 제공될 수 있다. 다양한 그룹이 토론 패널, 전문가 패널, 청중으로 예시되었다. 그러나, 디지털 비디오 통신 서비스에 참여하는 사용자를 현재 수행되는 통신의 목적과 구조를 반영하여 둘 이상의 그룹으로 나누는 것은 얼마든지 가능하다는 것이 현실이다. 예를 들어, 하나 이상의 그룹은 다른 지리적 위치에서 원격으로 비디오 통신 서비스에 액세스하 는 참가자 사용자가 포함할 수 있는 반면, 하나 이상의 다른 그룹에는 강의실과 같은 공통 중앙 위치에서 비디 오 통신 서비스에 액세스하는 참가자 사용자가 포함된다. 위에서 설명한 것과 동일한 원칙이 이러한 모든 경우 에 적용된다. 일반적으로, 현재 방법과 관련하여 언급된 모든 내용은 현재 시스템 및 컴퓨터 소프트웨어 제품에 적용 가능하 며 그 반대의 경우도 마찬가지이다. 따라서, 본 발명은 설명된 실시 예에 제한되지 않고, 첨부된 청구범위의 범위 내에서 변경될 수 있다. 도면 도면1 도면2 도면3 도면4 도면5 도면6a 도면6b 도면6c 도면6d 도면6e 도면6f 도면7 도면8a 도면8b 도면8c 도면8d 도면9"}
{"patent_id": "10-2024-7018585", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이하에서, 본 발명의 예시적인 실시 예 및 첨부된 도면을 참조하여 본 발명을 상세히 설명할 것이다: 도 1은 제1 예시 시스템을 도시한다; 도 2는 제2 예시 시스템을 도시한다; 도 3은 제3 예시 시스템을 도시한다; 도 4는 중앙 서버를 도시한다; 도 5는 제1 방법을 도시한다; 도 6a-6f는 도 5에 도시된 방법의 다양한 방법 단계와 관련된 후속 상태를 도시한다; 도 7은 개념적으로 공통 프로토콜을 도시한다; 도 8a-8d는 제2, 제3, 제4 및 제5 방법을 도시한다; 및 도 9는 제4 예시 시스템을 도시한다."}
