{"patent_id": "10-2020-0186663", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0094932", "출원번호": "10-2020-0186663", "발명의 명칭": "AI 영상인식을 활용한 드론영상 공간정보화 서비스 방법 및 시스템", "출원인": "주식회사 플로다", "발명자": "고경석"}}
{"patent_id": "10-2020-0186663", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "공간정보화 대상 지역을 비행하면서 촬영하여 획득한 드론 영상을 지장물 조사서버로 전송하는 드론 장치;상기 드론 장치로부터 수신한 드론 영상을 래스터 형태의 영상 데이터로 전환하고, 전환된 영상 데이터를 인공지능의 딥러닝 기술을 활용하여 벡터 형태의 영상 데이터로 생성하고, 생성된 벡터 형태의 영상 데이터를 활용하여 공간 정보 기반 분석 서비스를 제공하는 지장물 조사 서버; 및 상기 드론 영상, 상기 래스터 형태의 영상 데이터 및 상기 벡터 형태의 영상 데이터를 저장하는 데이터베이스;를 포함하고,상기 벡터 형태의 영상 데이터는 지장물에 대한 좌표 정보, 도형 정보, 면적 정보를 포함하며,상기 공간정보화 서버는, 상기 공간 정보 기반 분석 서비스에 대하여, 상기 래스터 형태의 영상 데이터를 인공지능으로 딥러닝 학습하고, 학습한 결과와 공공 데이터를 융합하여 웹 GIS 기반 서비스로 제공하는, AI 영상인식을 활용한 드론영상 공간정보화 서비스 시스템."}
{"patent_id": "10-2020-0186663", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 지장물 조사 대상 지역을 촬영한 드론 영상을 래스터 형태의 드론 영상으로 전환하여 인공지능의 딥러 닝 기술을 활용하여 벡터 형태의 데이터로 생성하고, 생성된 데이터를 활용하여 공간 정보 기반 분석 서비스를 제공할 수 있도록 하는, 딥러닝 영상인식을 활용한 지장물 조사 서비스 방법 및 시스템이 개시된다. 개시된 딥러닝 영상인식을 활용한 지장물 조사 서비스 시스템은, 지장물 조사 대상 지역을 비행하면서 촬영하여 획득한 드론 영상을 지장물 조사서버로 전송하는 드론 장치; 및 상기 드론 장치로부터 수신한 드론 영상을 래스 터 형태의 영상 데이터로 전환하고, 전환된 영상 데이터를 인공지능으로 딥러닝 학습하여 벡터 형태의 영상 데이 터(좌표정보, 도형정보, 면적정보 등)로 생성하고, 생성된 벡터 형태의 영상 데이터를 공공 데이터와 융합하여 공간 정보 기반 분석 서비스를 웹 GIS 기반 서비스로 제공하는 지장물 조사 서버를 포함할 수 있다."}
{"patent_id": "10-2020-0186663", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 AI 영상인식을 활용한 드론영상 공간정보화 서비스 방법 및 시스템에 관한 것으로서, 더욱 자세하게 는 공간정보화 대상 지역을 촬영한 드론 영상을 래스터 형태의 드론 영상으로 전환하여 인공지능의 딥러닝 기술 을 활용하여 벡터 형태의 데이터(좌표정보, 도형정보, 면적정보 등)로 생성하고, 생성된 데이터를 활용하여 공 간 정보 기반 분석 서비스를 제공할 수 있도록 하는, AI 영상인식을 활용한 드론영상 공간정보화 서비스 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2020-0186663", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "우리나라는 주택 가격 급증의 해결책으로 공급을 위한 택지 개발과 산업단지 조성을 위해 꾸준히 공공 택지 등 을 개발하여 왔다. 이러한 개발과정 중에는 기존 토지를 소유 또는 점유한 자에게 적절한 토지보상이 이루어지 고 있다. 그러나, 토지보상을 위한 조사 과정 중에는 불법 사례가 높아 늘 개발사업의 잡음이 존재하여 이를 해 결할 방안이 필요한 것이 사실이다. 최근 정부의 부동산 투지 억제 정책 및 '주거복지로드맵'등으로 공공 택지 개발이 본격적으로 증가되어 이에 따 른 보상액이 높은 증가세를 보이고 있다. 특히, 2020년 3기 신도시 개발 정책에 따라 역대 최대의 전국 45조원 의 토지 보상금이 지급될 예정이다. 이러한 토지 보상 절차 중 가장 민원의 소지가 높은 것은 토지 및 물건 등 기본 조사에 해당하는 지장물 조사로 써 이에 대한 합리적이고 공정한 조사 필요성이 증대되고 있다. 지장물은 공익사업시행지구 내의 토지에 정착한 건축물공작물시설입목죽목 및 농작물 그 밖의 물건 중에서 당해 공익사업의 수행을 위하여 직접 필요하지 않은 물건을 의미한다. 공익사업시행지구에서는 건축물 불법 증축이나 토지의 무단 형질변경, 개집양봉 등 불법 시설물 설치, 농작물 무단식재 등 불법보상 투기행위가 빈번히 발생함에 따라 문제의 소지가 발생되고 있다. 토지 보상금 중 지장물 보상 비율이 높기 때문에 지장물 조사 과정에서 불법 사례가 높아 늘 개발사업의 잡음이 존재하여 객관적인 근 거 기반 마련이 필요한 상황이다. 종래의 지장물 조사방법은 드론을 통해 확보한 영상을 담당자가 일일이 수동으로 검토하기 때문에 시간이 오래 걸리고 부정확한 문제가 있어서, 영상 분석을 통해서 자동으로 분류할 필요성이 있다. 그러나 드론을 통해 촬영한 영상이미지 내의 많은 종류의 지장물이 혼재하고 그 형태도 다양하기 때문에 종래의 영상 인식 알고리즘만으로는 지장물의 형태와 면적을 정확하게 도출하기 어려운 문제가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허공보 제10-2085418호(등록일: 2020.02.28), 상기 문헌에는 건설 인허가 협의 서류 작성을 위한 지장물 조서 자동 생성 방법이 기재되어 있다."}
{"patent_id": "10-2020-0186663", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "전술한 문제점을 해결하기 위한 본 발명의 목적은, 공간정보화 대상 지역을 촬영한 드론 영상을 래스터 형태의 드론 영상으로 전환하여 인공지능의 딥러닝 기술을 활용하여 벡터 형태의 데이터(좌표정보, 도형정보, 면적정보 등)로 생성하고, 생성된 데이터를 활용하여 공간 정보 기반 분석 서비스를 제공할 수 있도록 하는 AI 영상인식 을 활용한 드론영상 공간정보화 서비스 방법 및 시스템을 제공함에 있다."}
{"patent_id": "10-2020-0186663", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 목적을 달성하기 위한 본 발명의 실시 예에 따른 AI 영상 인식을 활용한 드론영상 공간정보화 서비스 시 스템은, 공간정보화 대상 지역을 비행하면서 촬영하여 획득한 드론 영상을 지장물 조사서버로 전송하는 드론 장 치; 상기 드론 장치로부터 수신한 드론 영상을 래스터 형태의 영상 데이터로 전환하고, 전환된 영상 데이터를 인공지능의 딥러닝 기술을 활용하여 벡터 형태의 영상 데이터로 생성하고, 생성된 벡터 형태의 영상 데이터를 활용하여 공간 정보 기반 분석 서비스를 제공하는 지장물 조사 서버; 및 상기 드론 영상, 상기 래스터 형태의 영상 데이터 및 상기 벡터 형태의 영상 데이터를 저장하는 데이터베이스;를 포함하고, 상기 벡터 형태의 영상 데이터는 지장물에 대한 좌표 정보, 도형 정보, 면적 정보를 포함하며, 상기 공간정보화 서버는, 상기 공간 정 보 기반 분석 서비스에 대하여, 상기 래스터 형태의 영상 데이터를 인공지능으로 딥러닝 학습하고, 학습한 결과 와 공공 데이터를 융합하여 웹 GIS 기반 서비스로 제공할 수 있다."}
{"patent_id": "10-2020-0186663", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 시범대상 지역의 실측 자료(Ground Truth) 값(실제값 정보)을 통해 검증한 결과, 건물 92.07%, 비닐하우스 96.06%, 묘지 87.82%의 정확도를 도출할 수 있다. 또한, 본 발명의 실시 예에 따른 결과물의 모델 자체로의 활용 뿐만 아니라 외부 공공 데이터(건축물정보, 지적 도)와의 융합을 통해 효과적인 조사 지원 서비스로 활용될 수 있다. 또한, 본 발명의 실시 예에 따른 딥러닝 영상 인식 지장물 조사 시스템을 통하여 토지 보상금을 공정하게 집행 함에 따라 실제 지장물 조사에 대해 약 250억원의 절약 효과가 있다. 또한, 본 발명에 의하면, 지장물 조사의 빈도 및 수요가 높은 건물, 비닐하우스, 수목, 분묘 4가지 분류의 카테 고리를 설정하고 라벨링을 통한 학습 데이터를 구축할 수 있으며, 최적의 딥러닝 알고리즘을 구현할 수 있다. 또한, 본 발명에 의하면, 딥러닝 분류 알고리즘을 활용한 드론 촬영 지장물 조사의 업무 효율성을 향상시킬 수 있다. 또한, 본 발명에 의하면, 토지 보상 체계를 공정하고 효율적으로 활용하기 위해 드론을 활용함으로써 특정한 시 간대에 촬영 정보를 확보하는 장점과 더불어 드론 촬영으로 매우 정밀도가 높은 사진 취득이 가능하다는 장점이 있다. 또한, 본 발명에 의하면, 공익사업 수행시 토지보상 현장 조사의 효율성을 높이고, 지장물 조사에 드론을 적극 적으로 활용함에 따라 불법 보상 투기를 방지할 수 있다. 또한, 본 발명에 의하면, 기존 항공사진(네이버 등 포털에서 활용되는 50cm급 영상) 보다 높은 해상도로 판별력 향상과 정확한 촬영 시간을 통해 필요한 시계절적 정보를 획득할 수 있다.또한, 본 발명에 의하면, 딥러닝 영상인식을 활용한 효율적 지장물 조사 실증으로 융복합 지능정보 사업화를 이 룰 수 있다. 또한, 본 발명에 의하면, 국내 드론 영상이미지를 활용한 한국형 영상인식 학습 DB를 구축할 수 있다. 즉, 국내 지역의 드론 촬영으로 한국적 특성의 건물 학습이 가능한 DB를 구축할 수 있다. 또한, 본 발명에 의하면, 국내 지형과 지장물 종류(건물, 비닐하우스, 수목, 분묘 4가지 분류)에 맞는 한국형 분석 모델 생성을 위한 DB를 구축할 수 있다. 또한, 본 발명에 의하면, 드론 촬영 이미지 기반의 인공지능 영상인식 분류 알고리즘을 구현할 수 있다. 즉, 지 장물 조사의 빈도 및 수요가 높은 건물, 비닐하우스, 수목, 분묘 4가지 분류의 카테고리를 설정하고 라벨링을 통한 학습 데이터 구축, 최적의 딥러닝 알고리즘을 구현할 수 있다. 또한, 본 발명에 의하면, 딥러닝 분류 알고리즘을 활용한 드론 촬영 지장물 조사의 업무 효율성을 향상시킬 수 있다. 또한, 본 발명에 의하면, 기존 방식보다 드론 촬영 방식의 장점을 극대화 하기 위해 수작업 판독에 대하여 인공 지능 기술을 적용하여 효과적인 분류 검증을 수행할 수 있다. 그리고, 본 발명에 의하면, 드론을 통해 확보된 초정밀 정사영상을 제작하고, 이를 딥러닝 학습하여 기존 지장 물 조사의 비효율성을 해결할 수 있다."}
{"patent_id": "10-2020-0186663", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 동일 또는 유사한 구성요소에 대해서는 동일한 참조 부호를 붙이도록 한다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우 뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분 이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 어느 부분이 다른 부분의 \"위에\" 있다고 언급하는 경우, 이는 바로 다른 부분의 위에 있을 수 있거나 그 사이에 다른 부분이 수반될 수 있다. 대조적으로 어느 부분이 다른 부분의 \"바로 위에\" 있다고 언급하는 경우, 그 사이 에 다른 부분이 수반되지 않는다. 제1, 제2 및 제3 등의 용어들은 다양한 부분, 성분, 영역, 층 및/또는 섹션들을 설명하기 위해 사용되나 이들에 한정되지 않는다. 이들 용어들은 어느 부분, 성분, 영역, 층 또는 섹션을 다른 부분, 성분, 영역, 층 또는 섹션 과 구별하기 위해서만 사용된다. 따라서, 이하에서 서술하는 제1 부분, 성분, 영역, 층 또는 섹션은 본 발명의 범위를 벗어나지 않는 범위 내에서 제2 부분, 성분, 영역, 층 또는 섹션으로 언급될 수 있다. 여기서 사용되는 전문 용어는 단지 특정 실시예를 언급하기 위한 것이며, 본 발명을 한정하는 것을 의도하지 않 는다. 여기서 사용되는 단수 형태들은 문구들이 이와 명백히 반대의 의미를 나타내지 않는 한 복수 형태들도 포 함한다. 명세서에서 사용되는 \"포함하는\"의 의미는 특정 특성, 영역, 정수, 단계, 동작, 요소 및/또는 성분을 구체화하며, 다른 특성, 영역, 정수, 단계, 동작, 요소 및/또는 성분의 존재나 부가를 제외시키는 것은 아니다. \"아래\", \"위\" 등의 상대적인 공간을 나타내는 용어는 도면에서 도시된 한 부분의 다른 부분에 대한 관계를 보다 쉽게 설명하기 위해 사용될 수 있다. 이러한 용어들은 도면에서 의도한 의미와 함께 사용 중인 장치의 다른 의 미나 동작을 포함하도록 의도된다. 예를 들면, 도면 중의 장치를 뒤집으면, 다른 부분들의 \"아래\"에 있는 것으 로 설명된 어느 부분들은 다른 부분들의 \"위\"에 있는 것으로 설명된다. 따라서 \"아래\"라는 예시적인 용어는 위 와 아래 방향을 전부 포함한다. 장치는 90˚ 회전 또는 다른 각도로 회전할 수 있고, 상대적인 공간을 나타내는 용어도 이에 따라서 해석된다. 다르게 정의하지는 않았지만, 여기에 사용되는 기술용어 및 과학용어를 포함하는 모든 용어들은 본 발명이 속하"}
{"patent_id": "10-2020-0186663", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자가 일반적으로 이해하는 의미와 동일한 의미를 가진다. 보통 사용되는 사전에 정의된 용어들은 관련 기술문헌과 현재 개시된 내용에 부합하는 의미를 가지는 것으로 추가 해석되고, 정의되지 않는 한 이상적이거나 매우 공식적인 의미로 해석되지 않는다."}
{"patent_id": "10-2020-0186663", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이하, 첨부한 도면을 참조하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으 며 여기에서 설명하는 실시 예에 한정되지 않는다. 도 1은 본 발명의 실시 예에 따른 딥러닝 영상 인식 지장물 조사 시스템의 전체적인 구성을 개략적으로 나타낸 구성도이다. 도 1을 참조하면, 본 발명의 실시 예에 따른 딥러닝 영상 인식 지장물 조사 시스템은, 드론 장치, 스 마트 단말기, 지장물 조사서버, 지장물 데이터베이스 및 국가공간정보 포털서버 등을 포함 할 수 있다.드론 장치는 지장물 조사 대상 지역을 비행하면서 촬영하여 획득한 드론 영상을 지장물 조사서버로 전송할 수 있다. 이하에서는 드론 영상을 제1 지장물 영상 또는 제1 영상이라 칭하여 설명한다. 스마트 단말기는 지장물 조사 대상 지역을 방문하는 사용자의 조작에 따라 촬영하여 획득한 제2 지장물 영 상을 지장물 조사서버로 전송할 수 있다. 이때, 제2 지장물 영상은 드론 장치에서 획득하는 제1 영상과 구 분하기 위해 제2 영상이라 칭할 수 있다. 지장물 조사서버는 드론 장치로부터 수신한 드론 영상을 래스터 형태의 영상 데이터로 전환하고, 전 환된 영상 데이터를 인공지능의 딥러닝 기술을 활용하여 벡터 형태의 영상 데이터로 생성하고, 생성된 벡터 형 태의 영상 데이터를 활용하여 공간 정보 기반 분석 서비스를 제공할 수 있다. 여기서, 벡터 형태의 영상 데이터 는 지장물에 대한 좌표 정보, 도형 정보, 면적 정보 등을 포함할 수 있다. 또한, 지장물 조사서버는 공간 정보 기반 분석 서비스에 대하여, 래스터 형태의 영상 데이터를 인공지능으 로 딥러닝 학습하고, 학습한 결과와 공공 데이터를 융합하여 웹 GIS 기반 서비스로 제공할 수 있다. 예를 들면, 지장물 조사 서버는 드론 장치로부터 수신한 제1 지장물 영상 및 스마트 단말기로부터 수신한 제2 지장물 영상을 정사 영상으로 변환하고 이미지 리사이징(Image Resizing)과 분할(Cropping)을 통하여 전처 리를 수행하며, 전처리 된 영상 데이터에 대하여 건물, 비닐하우스, 수목, 분묘로 분류하여 라벨링을 수행하고, 마스크(Mask) 영역 기반 컨볼루션 뉴럴 네트워크(R-CNN: Region Based Convolutional Neural Networks)를 이용 하여 지장물 모델을 생성하고, 생성된 지장물 모델에 대하여 파라미터를 설정하며, 훈련 데이터(Training Dat e)를 활용하여 지장물 모델을 학습하고, 학습한 결과와 공공 데이터를 융합하여 웹 GIS 기반 서비스로 제공할 수 있다. 또한, 지장물 조사서버는 오픈 소스(Open source) 기반의 Web GIS 서비스 아키텍처 기반으로 Web GIS 기반 웹 서비스를 제공하고, 공간 정보를 웹 서비스 가능한 Geo server로 구현하며, 오픈 레이어스(Open Layers) 클 라이언트 라이브러리를 활용하여 시각화 기능을 제공할 수 있다. 지장물 데이터베이스는 제1 지장물 영상, 제2 지장물 영상, 상기 생성된 지장물 모델, 상기 훈련 데이터 및 상기 학습한 결과와 상기 공공 데이터를 융합한 융합 데이터를 저장할 수 있다. 국가공간정보 포털서버는 GIS 건물 통합 정보, 개별 공시 지가, 건축물 연령 정보를 포함하는 공간 정보 기반의 공공 데이터를 제공할 수 있다. 공간 정보 기반의 공공 데이터는 건물 속성 정보 및 건물 공간 정보를 포함할 수 있다. 건물 속성 정보는 GIS 건물통합 정보, 개별공시지가 및 건축물 연령 정보를 포함하고, 건물 공간 정보는 건물명칭, 동명칭 및 건물 고 유번호를 포함할 수 있다. 건물 정보(Building information)는 사용 연한(usage), 구조(structure), 완공 일자(completion date), 건폐율 (coverage ratio), 용적율(floor area ratio)등을 포함할 수 있으며, 건물 지리 정보(total building GIS)는 건물 위치(position), 우편 번호(code), 면적(area) 등의 정보를 포함할 수 있다. GIS 건물 통합 정보는 국가공간정보(국가 중점 데이터) 포털서버에서 제공하는 정보로서, GIS 건물통합 식 별번호, 고유번호, 법정동 코드 등을 포함할 수 있다. 또한, 개별 공시지가 정보도 국가공간정보(국가 중점 데이터) 포털서버에서 제공하는 정보로서, 개별공시 지가, 표준지 여부, 토지 면적 등을 포함할 수 있다. 또한, 건축물 연령 정보도 국가공간정보(국가 중점 데이터) 포털서버에서 제공하는 정보로서, 건물 높이, 건물 연령, 연령대 구분명, 건물 연면적 등을 포함할 수 있다. 또한, GIS 건물통합 정보마스터는 국가공간정보(오픈 마켓) 포털서버에서 제공하는 정보로서, 건물명칭, 동명칭, UFID 등을 포함할 수 있다. 도 2는 본 발명의 실시 예에 따른 지장물 조사서버의 내부 구성을 개략적으로 나타낸 구성도이다. 도 2를 참조하면, 본 발명의 실시 예에 따른 지장물 조사서버는, 데이터 수집부, 이미지 전처리부 , 라벨링부, 통신부, 제어부, 모델 학습부, 모델 검증부 및 프로토타입부 등을 포함할 수 있다. 데이터 수집부는 드론 장치로부터 제1 지장물 영상을 수집하고, 스마트 단말기로부터 제2 지장 물 영상을 수집하고, 수집한 영상 데이터를 필터링한다. 이미지 전처리부는 필터링된 영상 데이터를 정사 영상으로 변환하고, 이미지 리사이징(Image Resizing)과 분할(Cropping)을 통하여 전처리를 수행한다. 또한, 이미지 전처리부는, 필터링된 영상 데이터에서 학습할 데이터의 최적 해상도를 확보하여 효율적 학 습을 위한 이미지 용량을 조절하는 이미지 리사이징(Image Resizing)을 수행함과 더불어, 상기 필터링된 영상 데이터를 학습 가능한 데이터로 세부적으로 나누는 분할(Image Cropping)을 실행하여 이미지 전처리를 수행할 수 있다. 라벨링부는 전처리 된 영상 데이터에 대하여 건물, 비닐하우스, 수목, 분묘로 분류하여 라벨링을 수행한다. 또한, 라벨링부는, 전처리 된 영상 데이터를 입력(Import)하여 영역을 설정하고, 건물, 비닐하우스, 수목, 분묘로 분류하여 라벨링 한 후 제이슨(JSON: JavaScript Object Notation) 형태로 저장할 수 있다. 통신부는 드론 장치 및 스마트 단말기와 무선으로 통신하며, 데이터를 송수신한다. 제어부는 서버 내부의 각 구성 요소에 대하여 동작 및 기능에 관한 전반적인 제어를 수행한다. 모델 학습부는 인스턴스 세그멘테이션(Instance Segmentation)이 가능한 마스크(Mask) 영역 기반 컨볼루션 뉴럴 네트워크(R-CNN)를 이용하여 지장물 모델을 생성하고, 생성된 지장물 모델에 대하여 배치 사이즈(Batch Size), 에포크(Epoch)를 포함하는 파라미터를 설정하며, 훈련 데이터(Training Date)를 활용하여 지장물 모델을 학습한다. 또한, 모델 학습부는, 전처리 된 영상 데이터에 대하여 지장물들을 카테고리 별로 분리하는 디텍션 (Detection)을 수행함과 동시에 해당 지장물들의 면적을 도출할 수 있도록 세그멘테이션(Segmentation)을 수행 할 수 있다. 또한, 모델 학습부는, 마스크(Mask) 영역 기반 컨볼루션 뉴럴 네트워크(R-CNN)에 대하여, Faster R-CNN에 각 픽셀이 객체인지 아닌지를 마스킹(masking)하는 CNN을 추가하거나, 상기 Faster R-CNN에 존재하는 \"bbox 인 식을 위한 브랜치\"에 병렬로 \"오브젝트 마스크 예측 브랜치\"를 추가하거나, 상기 Faster R-CNN을 오브젝트 디텍 션(Object Detection) 역할을 하도록 하고 각각의 RoI(Region of Interest)에 마스크 세그멘테이션(Mask segmentation)을 해주는 FCN(Fully Connectd Network)을 추가하며, 상기 전처리 된 영상 데이터에서 컨볼루션 레이어(Convolution Layer)를 이용해 특징맵을 뽑아내고, 상기 특징맵 상에서 관심영역(ROI: Region Of Interest)을 뽑아내어 분류(classification)와 상기 Faster R-CNN의 선형 회귀 모델(Bounding Box Regression), 그리고 상기 Mask R-CNN의 마스킹(masking)을 수행하고, 상기 특징맵(Feature Map) 위에 있는 그 리드 포인트로부터 이중선형 보간법(bilinear interpolation)을 통하여 각 샘플링 포인트의 값을 계산하며, 마 스크 예측(Mask prediction)과 클래스 예측(Class Prediction)을 분리(Decouple)할 수 있다. 모델 검증부는 지장물 모델의 정확도를 실측 자료 방식(Ground Truth)을 이용하여 검증한다. 프로토타입부는 지장물 모델을 학습한 결과와 공공 데이터를 융합하여 웹 GIS 기반 서비스의 프로토타입으 로 생성하고, 그 결과를 DB로 저장하며, 시각화 및 데이터 조회 기능을 제공할 수 있다. 도 3은 본 발명의 실시 예에 따른 딥러닝 영상 인식을 활용한 지장물 조사 서비스 방법을 설명하기 위한 동작 흐름도를 나타낸 도면이다. 도 3을 참조하면, 본 발명의 실시 예에 따른 딥러닝 영상 인식 지장물 조사 시스템은, 지장물 조사 대상 지역에 위치해 있는 드론 장치 또는 스마트 단말기에서 지장물 조사 대상 지역을 촬영하여 획득한 지 장물 영상을 지장물 조사서버로 전송한다(S310). 예를 들면, 드론 장치는 도 4a에 도시된 바와 같이, 수치지도 DEM을 이용하여 표고를 확인해 적정 촬영 고 도를 설정하고, 지형지물 및 가상 특성을 고려한 중복도를 설정한 후 지장물 조사 대상 지역을 비행하면서 촬영 하여 지장물이 포함된 지장물 영상을 획득하여 지장물 조사서버로 전송하는 것이다. 도 4a는 본 발명의 실 시 예에 따른 지장물 조사 대상 지역을 드론 장치가 비행하면서 촬영하는 예를 나타낸 도면이고, 도 4b는 본 발 명의 실시 예에 따른 드론 장치에서 촬영한 지장물 영상을 정사 영상으로 나타낸 것이다. 이때, 드론 장치(11 0)는 다양한 여러 시점에서 촬영한 수많은 2D 영상으로부터 카메라 포즈를 추정하고, 촬영된 물체나 장면의 3차 원 구조를 복원한 지장물 영상을 지장물 조사서버로 전송할 수 있다. 이때, 지장물 조사 서버는 드론장치으로부터 수신한 지장물 영상을 도 4b에 도시된 바와 같이 정사 영상으로 변환하여 사용한다. 정사 영 상은 수직에서 바라본 왜곡 없는 사진으로, 기복 변위에 대한 편위 수정을 통해 얻을 수 있다. 영상을 활용한 지도 제작과 다른 주제도와의 중첩을 위해서는 반드시 정사 영상이 필요하다. 또한, 드론 장치는 사용자 또는 관리자의 비행 조작에 따라 지장물 조사 대상 지역을 비행하면서 카메라를 통하여 지장물 조사 지역을 촬영하여 도 5에 도시된 바와 같이 지장물이 포함된 국내 농촌 건물 영상을 획득한 후 지장물 조사서버로 무선으로 전송하게 되는 것이다. 도 5는 본 발명의 실시 예에 따른 드론 장치에서 지장물 조사 대상 지역을 촬영하여 획득한 국내 농촌 건물 영상을 나타낸 도면이다. 물론, 조사자가 지장물 조 사 대상 지역에 직접 방문한 경우, 조사자가 휴대하는 스마트 단말기를 통하여 조사 지역을 촬영하고 획득 한 지장물이 포함된 건물 영상 등을 무선으로 지장물 조사서버로 전송할 수도 있다. 이때, 지장물 조사 서버에서 데이터수집부는 드론 영상 촬영을 통해 확보한 정사 영상의 고해상도 드 론 영상을 확보하고, 국가공간정보 포털서버로부터 건축물 데이터와 연속지적도 데이터를 포함하는 공공 데이터를 수집할 수 있다. 여기서, 정사 영상은 드론을 통해 촬영된 다량의 사진을 중첩하여 하나의 사진으로 융합하고, 지형의 기복의 편 위를 제거하여 일반지도와 같은 평면과 축적이 일정하도록 만든 사진 영상을 의미한다. 또한, 지장물 조사 서버는 상공에서 드론이 찍은 사진을 중첩하여 수직으로 얼굴이 보이지 않고 왜곡 없는 고해상도 이미지 확보를 통한 개인 비식별화 및 해상도 높은 정사 영상을 확보할 수 있다. 본 발명의 실시 예에 따라 지장물 조사 대상 지역을 드론 장치를 이용하여 조사하게 됨으로써 토지 조사에 대하여 개별토지에 대한 현장방문 없이도 일괄 토지 현황 조사가 가능하고, 업무량이 경감되며, 드론 측량 방식 으로 대체가 가능한 장점이 있다. 또한, 건축물 등 조사에 있어서, 건축물 측정자료는 현장조사 검증 자료로 활용되고, 집단 대규모 비닐하우스 등 시설물의 조사 및 측정에 효율적이며, 업무량도 또한 경감되는 장점이 있다. 그리고, 드론 장치를 통하여 수목 및 분묘 조사도 효율적으로 수행할 수 있으며, 분묘는 위치좌표를 등록 하여 분쟁을 방지할 수 있다. 이어, 지장물 조사서버는 지장물 영상을 정사 영상으로 변환하고 이미지 리사이징(Image Resizing)과 분할 (Cropping)을 통하여 전처리를 수행한다(S320). 즉, 지장물 조사서버에서 이미지 전처리부는 확보된 대용량 영상 이미지 데이터에 대하여, 도 6a 및 도 6b에 도시된 바와 같이 Resizing, Cropping을 거쳐 학습 데이터의 조건을 만들고, 건물, 비닐하우스, 수목, 묘지(분묘)의 4가지 분류 카테고리로 분류한 후 라벨링 작업을 통해 25,000개 데이터 셋(Data Set)을 생성할 수 있다. 도 6a는 본 발명의 실시 예에 따른 지장물 조사서버에서 획득한 지장물 영상을 리사이징, 분할 및 라벨링 하는 과정을 나타낸 도면이고, 도 6b는 본 발명의 실시 예에 따른 지장물 조사서버에서 이미지 전처리부가 지장 물 영상을 분할(Cropping)하는 예를 나타낸 도면이다. 이어, 지장물 조사서버는 전처리 된 영상 데이터에 대하여 건물, 비닐하우스, 수목, 분묘로 분류하여 라벨 링을 수행한다(S330). 즉, 지장물 조사서버에서 라벨링부는, 전처리 된 영상 데이터를 입력(Import)하여 영역을 설정하고, 도 6c에 도시된 바와 같이 건물, 비닐하우스, 수목, 분묘로 분류하여 라벨링 한 후 제이슨(JSON: JavaScript Object Notation) 형태로 저장할 수 있다. 도 6c는 본 발명의 실시 예에 따른 지장물 조사서버에서 라벨링부가 영상 데이터를 건물, 비닐하우스, 수목, 분묘로 분류하여 라벨링하는 예를 나타낸 도면이다. 또한, 지장물 조사서버에서 라벨링부는, 전처리 된 영상 데이터에서 도 7a에 도시된 바와 같이 건물 외곽선을 폴리곤 형태로 라벨링함으로써 건물 영상을 라벨링 할 수 있다. 도 7a는 본 발명의 실시 예에 따른 지 장물 조사서버가 건물에 대하여 라벨링하는 예를 나타낸 도면이다. 또한, 라벨링부는, 전처리 된 영상 데이터에서 도 7b에 도시된 바와 같이 비닐 하우스에 대하여 흰색, 검 은색 비닐하우스 테두리를 라벨링함으로써 비닐하우스 영상을 라벨링 할 수 있다. 도 7b는 본 발명의 실시 예에 따른 지장물 조사서버가 비닐하우스에 대하여 라벨링하는 예를 나타낸 도면이다. 또한, 라벨링부는, 전처리 된 영상 데이터에서 도 7c에 도시된 바와 같이 무덤에 대하여 무덤의 형태대로 라벨링함으로써 무덤 영상을 라벨링 할 수 있다. 도 7c는 본 발명의 실시 예에 따른 지장물 조사서버가 무덤에대하여 라벨링하는 예를 나타낸 도면이다. 또한, 라벨링부는, 전처리 된 영상 데이터에서 도 7d에 도시된 바와 같이 수목에 대하여 나무 각각의 테두 리를 라벨링하고 숲의 경우 덩어리 형태로 라벨링함으로써 수목 영상을 라벨링 할 수 있다. 도 7d는 본 발명의 실시 예에 따른 지장물 조사서버가 수목에 대하여 라벨링하는 예를 나타낸 도면이다. 이어, 지장물 조사서버는 마스크(Mask) 영역 기반 컨볼루션 뉴럴 네트워크(R-CNN: Region Based Convolutional Neural Networks)를 이용하여 지장물 모델을 생성한다(S340). 이때, 지장물 조사서버에서 모델 학습부는 지장물 모델에 대하여 배치 사이즈(Batch Size), 에포크 (Epoch)를 포함하는 파라미터를 설정하며, 훈련 데이터(Training Date)를 활용하여 지장물 모델을 학습하고, 전 처리 된 영상 데이터에 대하여 지장물들을 카테고리 별로 분리하는 디텍션(Detection)을 수행함과 동시에 해당 지장물들의 면적을 도출할 수 있도록 세그멘테이션(Segmentation)을 수행할 수 있다. 여기서, 지장물 조사서버는 지장물 영상에 대하여 도 8a 및 도 8b에 도시된 바와 같이 지장물의 면적 분석 을 위한 Segmentation을 수행할 수 있다. 도 8a 및 도 8b는 본 발명의 실시 예에 따른 지장물 조사서버가 지장 물 영상에 대하여 세그멘테이션을 실행하는 과정과 그 면적을 도출하는 과정을 나타낸 도면이다. 비닐하우스, 건물 등 지장물의 면적을 계산하기 위해서 U-Net 등 정확도를 고려한 이미지 segmentation 수행이 필요하다. 지 장물 서버는 Semantic Segmentation Network 기법을 활용하여 오브젝트가 아닌 픽셀별로 어떤 카테고리로 분류되는지 인식할 수 있다. 본 발명의 실시 예에서는 지장물 모델의 정확도를 정확도를 검증하기 위해 Ground Truth 데이터를 활용하여 모 델을 검증할 수 있다. Ground Truth 방식은 실제 지장물의 데이터와 알고리즘을 통해 확보된 정보와의 일치성을 보는 방식으로 진행하는 것이다. 이어, 지장물 조사서버는 생성된 지장물 모델에 대하여 파라미터를 설정하며, 훈련 데이터(Training Dat e)를 활용하여 지장물 모델을 학습한다(S350). 이때, 지장물 조사서버에서 모델 학습부는, 마스크(Mask) 영역 기반 컨볼루션 뉴럴 네트워크(R- CNN)에 대하여, Faster R-CNN에 각 픽셀이 객체인지 아닌지를 마스킹(masking)하는 CNN을 추가할 수 있다. 또한, 모델 학습부는, Faster R-CNN에 존재하는 \"bbox 인식을 위한 브랜치\"에 병렬로 \"오브젝트 마스크 예 측 브랜치\"를 추가할 수 있다. 또한, 모델 학습부는, Faster R-CNN을 오브젝트 디텍션(Object Detection) 역할을 하도록 하고 각각의 RoI(Region of Interest)에 마스크 세그멘테이션(Mask segmentation)을 해주는 FCN(Fully Connectd Network)을 추가할 수 있다. 또한, 모델 학습부는, 전처리 된 영상 데이터에서 컨볼루션 레이어(Convolution Layer)를 이용해 특징맵을 뽑아내고, 특징맵 상에서 관심영역(ROI: Region Of Interest)을 뽑아내어 분류(classification)와 Faster R- CNN의 선형 회귀 모델(Bounding Box Regression), 그리고 Mask R-CNN의 마스킹(masking)을 수행할 수 있다. 또한, 모델 학습부는, 특징맵(Feature Map) 위에 있는 그리드 포인트로부터 이중선형 보간법(bilinear interpolation)을 통하여 각 샘플링 포인트의 값을 계산하며, 마스크 예측(Mask prediction)과 클래스 예측 (Class Prediction)을 분리(Decouple)할 수 있다. 이어, 지장물 조사서버는 학습한 결과와 공공 데이터를 융합하여 웹 GIS 기반 서비스를 제공한다(S360). 즉, 지장물 조사서버에서 프로토타입부는 학습한 결과와 공공 데이터를 융합하여 도 9a에 도시된 바 와 같이 지장물 대상 지역의 현황을 쉽게 파악하는 프로토타입의 웹 GIS 기반 서비스를 제공하는 것이다. 도 9a 는 본 발명의 실시 예에 따른 지장물 조사서버가 지장물 조사 대상 지역에 대한 영상 데이터를 프로토타입의 웹 GIS 서비스로 제공하는 예를 나타낸 도면이다. 본 발명에 따른 지장물 조사서버는 서비스 초기 화면에서 도 9b 및 도 9c에 도시된 바와 같이 지장물 조사 대상 지역을 확인한다. 도 9b 및 도 9c는 본 발명의 실시 예에 따른 지장물 조사서버의 웹 GIS 기반 서비스에서 지장물 조사 대상 지역을 확인하는 예를 나타낸 도면이다. 이어, 본 발명에 따른 지장물 조사서버는 도 9d에 도시된 바와 같이 드론 영상과 해당 지역의 공공 데이터 와 융합하여 효과적인 시각화를 구현할 수 있다. 도 9d는 본 발명의 실시 예에 따른 지장물 조사 서버가 드론및 분석 영상과 건축물 대장 정보와의 융합을 실행하는 예를 나타낸 도면이다. 즉, 지장물 조사서버는 도 9d에 도시된 바와 같이 좌측의 드론 및 분석 영상과 우측의 실제 건축물 대장의 건축물의 종류와 면적을 비교한 다. 따라서 본 발명에 따른 지장물 조사서버는 도 9e에 도시된 바와 같이 실제 건축물 대장 정보(건축물 등록 DB)를 가지고 가건물 및 무허가 건물을 파악하는데 활용한다. 도 9e는 본 발명의 실시 예에 따른 지장물 조사 서버가 드론 영상과 실제 건축물 대장 정보를 비교하여 무허가 건물로 추출하는 예를 나타낸 도면이다. 또한, 본 발명에 따른 지장물 조사서버는 토지 정보와의 융합으로 효과적인 지장물 조사를 지원할 수 있다. 토지 위의 지장물 조사 뿐 아니라 도 9f에 도시된 바와 같이 토지 지적도를 통해 지목 및 소유관계, 공시 지가 등을 융합하여 사업 예산 계획 수립과 업무 추진에 활용할 수 있다. 도 9f는 본 발명의 실시 예에 따른 지 장물 조사 서버가 드론 영상과 연속 지적도를 융합하는 예를 나타낸 도면이다. 연속 지적도를 레이어로 추가하 여 국유지, 공유지, 사유지 등의 불법 지장물, 점유 상황을 파악하는데 활용할 수 있다. 또한, 본 발명에 따른 지장물 조사서버는 드론 영상을 지역의 격자로 분리하여 실제 지도와 100% link하여 확인할 수 있고, 모델을 적용하여 실제 1개의 도곽(1개의 격자 단위. 조정 가능, 240m*280m, 한 픽셀당 4cm로 설정)에 건물, 묘지, 비닐하우스, 나무 등의 개수와 면적을 분석하고 DB화하여 시각화 할 수 있다. 예를 들어, 도곽 3570114934의 경우는 빌딩 188개, 묘지 2개, 나무 67그루, 비닐하우스 30개로 각각 면적의 합을 구할 수 있다. 특히, 각각의 구분되는 속성의 구체적인 카테고리별로 예측 정확도 점수와 면적, BBOX의 좌표 등 세부적 인 정보를 확보하여 시각화 할 수 있다. 분석 이전과 분석 이후의 이미지 비교를 위해 Swipe기능을 제공하여 편 한 UI 기능을 제공할 수 있다. 본 발명의 실시 예에 따른 지장물 조사서버에서 모델 학습부가 시각지능 딥러닝 기술로 사용하는 컨 볼루션 뉴럴 네트워크(CNN)는 이미지·동영상을 입력하면 특징을 학습하여 데이터를 분류하는 딥러닝 기술이다. 인간의 시신경 세포의 구조를 모방한 컨볼루션 뉴럴 네트워크는 입력된 이미지(STFT Image)나 동영상을 인간이 사물을 보듯 색상, 형상, 원근 등을 행렬연산을 통해 분석된다. 행렬 연산량을 줄이기 위해 곱하고 더하는 컨볼 루션 행렬 연산(Convolution/Nonlinearity/Max Pooling)으로 데이터를 줄이고, 인접 행렬값 중 큰 값을 선택하 는 기법(Fully connected layers) 등을 활용한 성능 개선이 특징이다. 행렬연산을 반복하면서 이미지동영상은"}
{"patent_id": "10-2020-0186663", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "요약되는데, 전체 형상을 파악할 수 있는 형태로 요약변환되게 되는데, 최종 결과물은 분류함수 (Classification)를 통해 예측할 수 있다. 또한, 본 발명의 실시 예에 따른 지장물 조사서버의 모델 학습부는 GAN(Generative Adversarial Network)과 영상처리에 특화된 딥러닝 기술인 CNN을 결합한 DC-GAN(Deep Convolutional Generative Adversarial Networks)을 이용할 수 있다. DC-GAN은 예를 들면, 오바마 대통령의 목소리만을 가지고 입 모양을 생성해 오바마 대통령의 전혀 다른 연설 영상에 합성하는 등 단순 합성을 넘어 실시간 영상 변형, 합성까지 가 능한 딥러닝 기술이다. 또한, DC-GAN은 도 10에 도시된 바와 같이 찍는 순간 눈을 감은 사진에 가짜 눈을 생성하여 눈을 뜨고 있는 사 진으로 합성할 수 있다. 도 10은 본 발명의 실시 예에 따른 지장물 조사서버가 이용하는 DC-GAN을 통해 사진에 원하는 이미지를 합성하여 새로운 얼굴 영상을 생성한 예를 나타낸 도면이다. 도 10에 도시된 바와 같이, 원하 는 눈 모양을 사진 이미지에 반영하여 새로운 얼굴 전체를 생성할 수 있다. 도 10에서, (a)와 (b)는 실제 사진 이며 (c)는 단순히 포토삽을 이용해 (b)에 (a)를 합성한 결과이며, (d)는 GAN을 이용해 합성한 결과이며, (c)는 합성한 눈과 얼굴 사이의 경계가 부자연스러운 데 비해 (d)는 훨씬 자연스럽고 실제 사람의 사진과 유사한 결과 를 나타내고 있다. 또한, 본 발명의 실시 예에 따른 지장물 조사서버에서 모델 학습부가 이용하는 GAN은, 영상 생성이나, 영상간 변환, 해상도 향상을 목적으로 사용되고 있으며, 인공 의료 데이터를 생성하는 방법으로 활용 이 증가하고 있다. 예를 들어, CT 영상은 방사선량을 줄일 경우, 영상 품질이 저하되는 문제가 있는데, GAN을 통해 환자의 피폭량을 줄이면서도 일반선량 영상수준으로 품질을 개선할 수 있다. 또 다른 예는 자기공명영상 (MRI) 촬영을 위해 환자가 밀폐된 공간에 고정된 자세로 장시간 촬영이 이루어지는데, GAN을 활용하여 단시간 촬영으로도 영상품질을 보장할 수 있다. 또한, 본 발명의 실시 예에 따른 지장물 조사서버에서 모델 학습부가 이용하는 GAN은, 뇌 MRI 영상판 독을 통한 알츠하이머 진단, 안저 영상 촬영 이상 여부 확인을 통한 녹내장 진단과 시신경 이상 등 안저 질환 진단, 뼈스캔 영상판독을 통한 유방암 전이 여부 진단에 활용되고 있다. 또한, 본 발명의 실시 예에 따른 지장물 조사서버에서 모델 학습부가 이용하는 Faster R-CNN은, Deep Convolution Network로서 Region Proposal Network (RPN) 및 Fast R-CNN Detector로서 앞의 proposed regions 을 사용하여 object를 감지하는 2개의 네트워크로 구성된다. R-CNN에서는 Region proposal을 진행하기 위해 selective search를 사용하고, Selective search를 통해서 나온 수천 개 각각의 region proposals마다 CNN(AlexNet)을 활용하여 forward pass를 진행한다. 또한 3개의 모델(feature를 뽑아내는 CNN, 어떤 class인지 알아내는 classifier, bounding boxes를 예측하는 regression model)을 각각 학습한다. Fast R-CNN는 3개의 모 델을 학습하는 과정 중에 중복되는 연산을 하나의 CNN으로 해결한다. 즉, 이미지를 가장 먼저 받아서 feature를 뽑아내는 일을 하기 때문에 base network 또는 중복되는 일을 하나의 CNN에서 처리하기 때문에 shared network 이라고도 한다. 또한, 본 발명의 실시 예에 따른 지장물 조사서버에서 모델 학습부가 이용하는 Region Proposal Network(RPN)은 convolution을 사용하여 구현이 되며, input 값은 이전 base network에서 뽑아낸 feature maps 을 사용한다. Region proposals을 생성하기 위해서는 base network에서 생성한 feature maps위에 n × n spatial window (보통 3 × 3)를 슬라이드 시키고, 각각의 sliding-window가 찍은 지점마다, 한 번에 여러 개 의 region proposals을 예측한다. Region proposals의 최고 갯수는 kk 로 나타내며, 이것을 Anchor 라고하며, 보통 각 sliding window의 지점마 다 9개의 anchors가 존재하고, 3개의 서로 다른 종횡비(aspect ratios) 그리고 3개의 서로 다른 크기(scales) 가 조합되며 모두 동일한 중앙 지점(xa,ya)(xa,ya)을 가진다. Sliding window를 통해서 나온 feature map의 depth는 더 낮은 차원이다(예, 512 depth > 256 depth) 이후의 output값은 1 × 1 kernel을 갖고 있는 두 개의 convolutional layers로 양분되어 들어감). Classification layer에서는 anchor당 2개의 predictions값을 내놓 으며, 객체인지 아니면 객체가 아닌지(그냥 배경인지)에 관한 확률 값이다. Regression layer (또는 bounding box adjustment layer)는 각 anchor당 델타값들 ΔxcenterΔxcenter, ΔycenterΔycenter, ΔwidthΔwidth, Δ heightΔheight 4개의 값을 도출하고, 이 델타 값들은 anchors에 적용이 되어서 최종 proposals을 제시한다. 또한, 본 발명의 실시 예에 따른 지장물 조사서버에서 모델 학습부가 이용하는 Classifier of Background and Foreground는, Classifier를 학습시키기 위한 training data는 바로 위의 RPN으로 부터 얻은 anchors와 ground-truth boxes (실제 사람이 직접 박스 처리한 데이터)로써, 모든 anchors를 foreground 또는 background로 분류해야 한다. 분류를 하는 기준은 어떤 anchor가 ground-truth box와 오버랩 (중복되는 면적) 되는 부분이 크면 foreground이고, 적으면 background로써 각각의 anchor마다 foreground인지 아니면 background인지 구별하는 값을 p*p* 값이라고 했을 때 구체적인 공식은 다음 수학식 1과 같다. 수학식 1"}
{"patent_id": "10-2020-0186663", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 1에서, IoU값이 가장 높은 값을 1값으로 설정하지만, 0.7이상으로 설정할 수 있다. 또한 하나의 ground- truth box는 여러 개의 anchors에 1값을 줄 수가 있다. 0.3 이하의 값으로 떨어지는 anchor는 -1값으로 설정하 고, 그 외 IoU 값이 높지도 정확하게 낮지도 않은 anchors들 같은 경우는 학습 시 사용하지 않는다. 또한, 본 발명의 실시 예에 따른 지장물 조사서버에서 모델 학습부가 이용하는 Bounding Box Regression은, 4개의 좌표값을 사용하며, tt 라는 값 자체가 4개의 좌표 값을 갖고 있는 하나의 벡터이며 다음 수학식 2와 같은 element 값을 갖고 있다.수학식 2"}
{"patent_id": "10-2020-0186663", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 2에서, tx, tytx, ty는 박스의 center coordinates를 나타내고, tw, thtw, th는 박스의 width, height 를 나타내며, x, y, w, hx, y, w, h는 predicted box를 나타내며, xa, ya, wa, haxa, ya, wa, ha는 anchor box 를 나타내며, x*, y*, w*, h*x*, y*, w*, h*는 ground-truth box를 나타낸다. 또한, ground-truth vector t*t*는 위와 유사하게 다음 수학식 3과 같은 값을 갖고 있다. 수학식 3"}
{"patent_id": "10-2020-0186663", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 3에서, tx, tytx, ty는 박스의 center coordinates를 나타내고, tw, thtw, th는 박스의 width, height 를 나타내며, x, y, w, hx, y, w, h는 predicted box를 나타내며, xa, ya, wa, haxa, ya, wa, ha는 anchor box 를 나타내며, x*, y*, w*, h*x*, y*, w*, h*는 ground-truth box를 나타낸다. 또한, Region of Interest Pooling은, RPN 이후 서로 다른 크기의 proposed regions값을 output으로 받는다. 여기서 서로 다른 크기라는 의미는 CNN에서 output으로 나온 feature maps 또는 제각각 다른 크기라는 뜻으로써 일반적으로 feature maps을 flatten시켜서 딥러닝을 통해 추후 classification을 할 때는 더더욱 어렵게 되므로 새로운 기법이 필요하다. 이때 사용하는 기법이 Region of Interest Pooling(ROI) 기법으로 ROI를 사용하게 되 면 서로 다른 크기의 feature maps을 동일한 크기로 변환할 수 있다. ROI를 구현하기 위해서는 다음의 2개의 inputs이 필요하며, 하나는 Deep convolutions 그리고 max pooling layers를 통해 나온 feature map이며, 다른 하나는 N × 4 매트릭스 -> N은 RoI의 갯수, 4는 region의 위치를 나타내는 coordinates이다. ROI의 로직은 각 각의 region proposal을 동일한 크기의 sections으로 나누고(section의 크기는 RoI pooling의 output크기가 동 일), 각각의 section마다 가장 큰 값을 찾으며, 각각의 찾은 maximum값을 output 으로 만든다. 또한, 본 발명의 실시 예에 따른 지장물 조사서버에서 모델 학습부가 트레이닝(Training)을 수행할 때, Loss function은 다음 수학식 4과 같이 구현할 수 있다. 수학식 4"}
{"patent_id": "10-2020-0186663", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "수학식 4에서, ii는 mini-batch 안에서의 anchor의 index를 나타내고, pipi는 anchor ii 가 객체인지 배경인지 의 예측값을 나타내고, p*ipi*는 ground-truth label 로서 1이면 해당 anchor가 positive(객체), 0이면 negative(배경)이라는 것을 나타내고, titi는 4개의 bounding box의 값을 갖고 있는 벡터를 나타내고, t*iti* 는 ground-truth box 로서 positive anchor와 관련된 것을 나타내고, LclsLcls는 log loss (object이나 또는 아니냐의 두 클래스 간의 손실 함수)를 나타내고, LregLreg는 smooth l1 loss function (오직 positive anchors p*i=1pi*=1 에만 사용됨)을 나타내고, NclsNcls는 normalization. mini-batch 크기와 동일(i.e. Ncls=256Ncls=256 )한 것을 나타내고, NregNreg : normalization. anchor locations의 갯수와 동일(i.e. Nreg~2400Nreg∼2400)인 것을 나타내고, λ는 기본값으로 10 (목표는 cls 그리고 reg 둘다 거의 동등하게 가중 치를 갖도록 함)을 나타낸다.또한, Training RPN은 하나의 이미지에서 random 으로 256개(batch 크기)의 anchors를 샘플링하고, 이때 positive anchors(객체)와 negative anchors(배경)의 비율은 1:1이 되도록 한다. 만약 랜덤으로 진행시, negative anchors의 갯수가 더 많기 때문에 학습은 어느 한쪽으로 편향되게 학습이 진행된다. 하지만 현실적으 로 1:1 비율을 지속적으로 유지시키는 것은 매우 어렵기 때문에 대부분의 경우 positive samples의 수가 128개 를 넘지 못하는 경우가 발생하고, 이 경우 zero-padding을 시켜주거나, 아예 없는 경우는 IoU값이 가장 높은 값 을 사용한다. 추가되는 새로운 레이어의 weights값은 0 mean, 0.01 standard deviation을 갖고 있는 gaussian distribution으로 부터 초기화를 하고,(BaseNet 에 해당되는 ImageNet 을 제외, 즉 pre-trained model을 사용 하기 때문) Learning rate의 경우 처음 60k mini-batches에 대해서는 0.001, 그 다음 20k mini-batches에 대해 서는 0.0001을 PASCAL VOC dataset에 적용한다. 또한, 본 발명의 실시 예에 따른 지장물 조사서버에서 모델 학습부는 Faster R-CNN을 확장하여 Segmentation을 위한 확장형 Mask R-CNN을 사용할 수 있다. 확장형 Mask R-CNN은 R-CNN 기술의 변천에 따라 Mask R-CNN은 Faster R-CNN을 확장하여 Instance Segmentation에 적용하고자 하는 모델이다. Mask R-CNN은 Faster R-CNN에 각 픽셀이 객체인지 아닌지를 masking하는 CNN을 추가하는 Binary Mask이다. 모델 학습부는, 마스크(Mask) 영역 기반 컨볼루션 뉴럴 네트워크(R-CNN)에 대하여, Faster R-CNN에 각 픽 셀이 객체인지 아닌지를 마스킹(masking)하는 CNN을 추가할 수 있다. 또한, 모델 학습부는, Faster R-CNN에 존재하는 \"bbox 인식을 위한 브랜치\"에 병렬로 \"오브젝트 마스크 예 측 브랜치\"를 추가할 수 있다. 또한, 모델 학습부는, Faster R-CNN을 오브젝트 디텍션(Object Detection) 역할을 하도록 하고 각각의 RoI(Region of Interest)에 마스크 세그멘테이션(Mask segmentation)을 해주는 FCN(Fully Connectd Network)을 추가할 수 있다. 또한, 모델 학습부는, ROI Pooling 대신 ROI Align을 사용할 수 있다. Fast R-CNN은 object detection을 위한 모델이었기 때문에 RoI Pooling에서 정확한 위치 정보를 담는 것이 중요하지 않았으나, 소수점을 반올림한 좌표를 가지고 Pooling을 해주면 input image의 원본 위치 정보가 왜곡되는 문제가 발생되므로, 이를 해결하기 위해 Mask R-CNN 에서는 RoI Pooling 대신에 RoI Align을 사용하는 것이다. 또한, 모델 학습부는, Mask prediction과 class prediction을 decouple 함으로써 클래스 상관없이 masking을 수행할 수 있다. 이는 ROI 내에서 클래스 예측하는 네트워크와 masking하는 네트워크를 분리함으로써 mask prediction에서 다른 클래스를 고려할 필요 없이 binary mask 를 predict 하면 되기 때문에 성능의 향상 을 기대할 수 있다. 전술한 바와 같이 본 발명에 따른 모델 학습부가 지장물 모델을 학습한 결과, epoch가 3,800번 내외에서 Loss가 수렴되는 결과를 도출할 수 있다. 또한, 세부적인 BBox loss는 epoch가 400번 내외에서 Loss가 수렴되는 결과 도출되어 상대적으로 효과적인 학습 결과를 도출할 수 있다. 본 발명의 실시 예는 영상이미지를 1000*1000으로 cropping 후 학습하면서 잘린 이미지까지 학습에 반영되어 inference 결과 오브젝트가 잘려서 여러 개로 detection 할 수 있다. 또한, OpenCV 이미지처리 라이브러리를 활 용하여 인접 오브젝트를 병합하고 다시 BBox를 drawing 할 수 있다. 이를 통해 Rotation 한 효과를 얻고 중첩된 영역이 축소되는 효과를 얻었음. 이를 통해서 ground truth 와 비교를 통해서 면적비교 결과 정확도를 개선하는 효과가 있다. Rotation에 따른 정확도를 상승시킬 수 있다. 또한, 본 발명에 따른 모델 학습부는 비닐하우스에 대하여, 일반적인 영상인식 방식으로 비닐하우스를 분 석하는 것보다는 객체에 맞게 Bounding한 Rotation 방식을 채택함으로써 정확도를 향상시킬 수 있다. 또한, 본 발명에 따른 모델 학습부는 분묘에 대하여, 일반적인 영상인식 방식으로 분묘(묘지)를 분석하는 것보다는 객체에 맞게 Bounding한 Rotation 방식을 채택함으로써 정확도를 향상시킬 수 있다. 또한, 본 발명에 따른 모델 학습부는 수목에 대하여, 계절적 요인 및 수종에 따라 특정 기간에 잎이 있는 가와 없는가에 따라 분석 케이스가 매우 다양하게 발생하는 특징을 가질 수 있다. 따라서, 학습 데이터의 수종 별, 계절별 데이터 확보가 우선되어야 한다. 또한, 본 발명에 따른 지장물 조사서버에서 모델 검증부는 학습에 사용하지 않은 별도의 Ground Truth 데이터를 활용하여 검증할 수 있다. 1000개의 이미지파일과 json 파일을 gt 로 만들어서 검증을 수행할수 있다. test 데이터의 inference 결과와 gt 의 면적비교 검증결과는 다음 표 1과 같다. 표 1"}
{"patent_id": "10-2020-0186663", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "한편, 본 발명에 따른 지장물 조사서버는 Postgis 에서 Geoserver 라는 서버를 거쳐 OpenLayers 라는 스 크립트 라이브러리를 통해 웹브라우저에 웹 GIS 기반 서비스를 제공할 수 있다. Geoserver는 지리공간 데이터를 공유하고 편집할 수 있는 Java로 개발된 오픈소스 GIS 소프트웨어 서버로 상호 운용성을 전제로 개발되었기 때 문에, 개방형 표준을 사용하여 다양한 공간 데이터 소스를 제공한다. OpenLayers는 자바스크립트 라이브러리의 일종으로 Geoserver 를 통해 생성된 레이어를 스크립트 언어를 이용하여 시각적으로 가공하여 웹 상에 표시할 수 있다. OpenLayers의 장점은 우선 오픈소스이기 때문에 다양한 지도 (Google Maps, OSM, Bing Maps) 서비스 들과 호환이 잘 되고 거의 모든 OGC(Open Geospatial Consortium) 표준을 지원하여 사용이 가능하다. 또한, 본 발명에 따른 지장물 조사서버는 Web Map Service(WMS), Web Feature Service(WFS), Web Coverage Service(WCS), Web Processing Service(WPS)를 제공하고, Post GIS를 이용할 수 있다. Web Map Service(WMS)는 GIS 데이터에 접근하기 위한 인터페이스로써 웹을 통해 지도 이미지(형식)로 서비스함. 다시 말해, 데이터서버에 저장된 레이어 또는 분석을 통해 생성된 벡터 및 래스터 데이터를 시각화 하는 서비스 이다. Web Feature Service(WFS)는 웹을 통해 벡터형식으로 GIS 데이터를 제공하기 위한 인터페이스로, 데이터서버에 저장된 벡터 레이어를 공간 및 속성조건을 이용해서 불러오거나 관리(피쳐의 추가, 수정, 삭제) 하기 위한 서비 스이다. Web Coverage Service(WCS)는 웹을 통해 래스터 형식을 GIS 데이터로 제공하기 위한 인터페이스, 위성영상 등과 같은 자료를 서비스한다. Web Processing Service(WPS)는 지리정보에 대한 다양한 처리 서비스(Geo-Processing Service)를 웹상에서 정 의하고 접근할 수 있도록 하기 위한 인터페이스, 모든 OGC 표준 웹 서비스들과 상호 호환성을 갖도록 정의된다. Post GIS는 공간적으로 사용 가능한 객체 관계형 데이터베이스이다. 객체 관계형 데이터베이스 시스템인 PostgreSQL의 확장 프로그램으로, 데이터베이스에 GIS(지리정보시스템) 객체를 저장하는 것이 가능하다. Gist 기반 R-Tree 공간 인덱스를 지원하며, GIS 객체의 분석 및 공간 처리를 위한 기능을 포함한다. Post GIS는 리프 랙션스 리서치(Refractions Research Inc.)가 개발한 공간 데이터베이스로서, 사용자 인터페이스 도구, 웹 기반 접근 도구를 포함하는 일련의 중요 GIS 기능을 지원한다. 전술한 바와 같이 본 발명에 의하면, 지장물 조사 대상 지역을 촬영한 드론 영상을 래스터 형태의 드론 영상으 로 전환하여 인공지능의 딥러닝 기술을 활용하여 벡터 형태의 데이터(좌표정보, 도형정보, 면적정보 등)로 생성 하고, 생성된 데이터를 활용하여 공간 정보 기반 분석 서비스를 제공할 수 있도록 하는 딥러닝 영상인식을 활용 한 지장물 조사 서비스 방법 및 시스템을 제공할 수 있다. 본 발명이 속하는 기술 분야의 당업자는 본 발명이 그 기술적 사상이나 필수적 특징을 변경하지 않고서 다른 구 체적인 형태로 실시될 수 있으므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범위는 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내 어지며, 특허청구범위의 의미 및 범위 그리고 그 등가개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다. 부호의 설명100 : 딥러닝 영상 인식 지장물 조사 시스템 110 : 드론 장치 120 : 스마트 단말기 130 : 지장물 조사 서버 140 : 지장물 DB 150 : 국가공간정보 포털서버 210 : 데이터 수집부 220 : 이미지 전처리부 230 : 라벨링부 240 : 통신부 250 : 제어부 260 : 모델 학습부 270 : 모델 검증부 280 : 프로토타입부"}
{"patent_id": "10-2020-0186663", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 딥러닝 영상 인식 지장물 조사 시스템의 전체적인 구성을 개략적으로 나타낸 구성도이다. 도 2는 본 발명의 실시 예에 따른 지장물 조사서버의 내부 구성을 개략적으로 나타낸 구성도이다. 도 3은 본 발명의 실시 예에 따른 딥러닝 영상 인식을 활용한 지장물 조사 서비스 방법을 설명하기 위한 동작 흐름도를 나타낸 도면이다. 도 4a는 본 발명의 실시 예에 따른 지장물 조사 대상 지역을 드론 장치가 비행하면서 촬영하는 예를 나타낸 도 면이고, 도 4b는 본 발명의 실시 예에 따른 드론 장치에서 촬영한 지장물 영상을 정사 영상으로 나타낸 것이다. 도 5는 본 발명의 실시 예에 따른 드론 장치에서 지장물 조사 대상 지역을 촬영하여 획득한 국내 농촌 건물 영 상을 나타낸 도면이다. 도 6a는 본 발명의 실시 예에 따른 지장물 조사서버에서 획득한 지장물 영상을 리사이징, 분할 및 라벨링하는 과정을 나타낸 도면이고, 도 6b는 본 발명의 실시 예에 따른 지장물 조사서버에서 이미지 전처리부가 지장물 영 상을 분할(Cropping)하는 예를 나타낸 도면이다. 도 7a는 본 발명의 실시 예에 따른 지장물 조사서버가 건물에 대하여 라벨링하는 예를 나타낸 도면이다. 도 7b는 본 발명의 실시 예에 따른 지장물 조사서버가 비닐하우스에 대하여 라벨링하는 예를 나타낸 도면이다. 도 7c는 본 발명의 실시 예에 따른 지장물 조사서버가 무덤에 대하여 라벨링하는 예를 나타낸 도면이다. 도 7d는 본 발명의 실시 예에 따른 지장물 조사서버가 수목에 대하여 라벨링하는 예를 나타낸 도면이다. 도 8a 및 도 8b는 본 발명의 실시 예에 따른 지장물 조사서버가 지장물 영상에 대하여 세그멘테이션을 실행하는 과정과 그 면적을 도출하는 과정을 나타낸 도면이다. 도 9a는 본 발명의 실시 예에 따른 지장물 조사서버가 지장물 조사 대상 지역에 대한 영상 데이터를 프로토타입 의 웹 GIS 서비스로 제공하는 예를 나타낸 도면이다. 도 9b 및 도 9c는 본 발명의 실시 예에 따른 지장물 조사서버의 웹 GIS 기반 서비스에서 지장물 조사 대상 지역 을 확인하는 예를 나타낸 도면이다. 도 9d는 본 발명의 실시 예에 따른 지장물 조사 서버가 드론 및 분석 영상과 건축물 대장 정보와의 융합을 실행 하는 예를 나타낸 도면이다. 도 9e는 본 발명의 실시 예에 따른 지장물 조사 서버가 드론 영상과 실제 건축물 대장 정보를 비교하여 무허가건물로 추출하는 예를 나타낸 도면이다. 도 9f는 본 발명의 실시 예에 따른 지장물 조사 서버가 드론 영상과 연속 지적도를 융합하는 예를 나타낸 도면 이다. 도 10은 본 발명의 실시 예에 따른 지장물 조사서버가 이용하는 DC-GAN을 통해 사진에 원하는 이미지를 합성하 여 새로운 얼굴 영상을 생성한 예를 나타낸 도면이다."}
