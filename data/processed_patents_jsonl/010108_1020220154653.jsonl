{"patent_id": "10-2022-0154653", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0075362", "출원번호": "10-2022-0154653", "발명의 명칭": "오프로딩된 데이터를 처리하는 방법, 서버 장치, 및 시스템", "출원인": "서울대학교산학협력단", "발명자": "이경한"}}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "오프로딩된(offloaded) 데이터를 처리하는 방법에 있어서, 단말 장치로부터 오프로딩된 데이터를 수신하는 단계;디코더 모델을 이용하여, 상기 오프로딩된 데이터를 디코딩하는 단계;;상기 디코딩된 데이터를 입력으로 하는 심층신경망 모델을 이용하여, 상기 오프로딩된 데이터에 대응하는 추론데이터를 출력하는 단계를 포함하되,상기 오프로딩된 데이터는, 원본 데이터를 입력으로 하는 추출기 모델에 의해 생성된 잠재 표현(latentrepresentation) 데이터를 포함하고,상기 추출기 모델, 상기 디코더 모델, 및 상기 심층신경망 모델은, 상기 심층신경망 모델의 손실 정보를 이용하여 합동 훈련(joint training)되는, 방법."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 추출기 모델과 디코더 모델은 오토인코더(autoencoder) 모델로 구현되는, 방법."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 잠재 표현 데이터의 크기는 미리 정의되는, 방법."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 디코딩하는 단계는,상기 오프로딩된 데이터를 상기 심층신경망 모델의 입력 값의 형태로 변형하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 디코더 모델은, 단일의 업샘플링 레이어 및 단일의 컨볼루셔널 레이어로 구성되는, 방법."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 심층신경망 모델은 제1 심층신경망 모델이고,상기 추론 데이터는 제1 추론 데이터고,공개특허 10-2023-0075362-3-상기 디코딩된 데이터를 입력으로 하는 제2 심층신경망 모델을 이용하여, 상기 오프로딩된 데이터에 대응하는제2 추론 데이터를 출력하는 단계를 더 포함하되,상기 추출기 모델, 상기 디코더 모델은, 상기 제1 심층신경망 모델의 손실 정보 및 상기 제2 심층신경망 모델의손실 정보를 이용하여 합동 훈련되는, 방법."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 추출기 모델은, 지식 증류(knowledge distillation) 기법을 이용하여 학습되는, 방법."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 원본 데이터는, 상기 심층신경망 모델을 이용한 애플리케이션에 사용되는 이미지, 영상, 오디오, 텍스트,센서 값 중 적어도 하나의 데이터를 포함하는, 방법."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 심층신경망 모델은, 원본 데이터에 기초하여 이미지 분류(classification), 이미지 분할(segmentation),이미지 캡셔닝(captioning) 객체 탐지(detection), 깊이 추정(depth estimation), 위치 추정(localization) 또는 자세 추정(pose estimation)을 수행하는 모델인, 방법."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 단말 장치로, 상기 추론 데이터를 전송하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "오프로딩된(offloaded) 데이터를 처리하는 서버 장치에 있어서,하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서를 포함하되, 상기 적어도 하나의 프로세서는:단말 장치로부터 오프로딩된 데이터를 수신하고,디코더 모델을 이용하여, 상기 오프로딩된 데이터를 디코딩하고,상기 디코딩된 데이터를 입력으로 하는 심층신경망 모델을 이용하여, 상기 오프로딩된 데이터에 대응하는 추론데이터를 출력하는, 상기 하나 이상의 인스트럭션을 실행하되,상기 오프로딩된 데이터는, 원본 데이터를 입력으로 하는 추출기 모델에 의해 생성된 잠재 표현(latentrepresentation) 데이터를 포함하고,상기 추출기 모델, 상기 디코더 모델, 및 상기 심층신경망 모델은, 상기 심층신경망 모델의 손실 정보를 이용하여 합동 훈련(joint training)되는, 서버 장치.공개특허 10-2023-0075362-4-청구항 12 제11항에 있어서,상기 추출기 모델과 디코더 모델은 오토인코더(autoencoder) 모델로 구현되는, 서버 장치."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 잠재 표현 데이터의 크기는 미리 정의되는, 서버 장치."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 디코딩하는, 상기 하나 이상의 인스트럭션은,상기 오프로딩된 데이터를 상기 심층신경망 모델의 입력 값의 형태로 변형하는, 상기 하나 이상의 인스트럭션을포함하는, 서버 장치."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 디코더 모델은, 단일의 업샘플링 레이어 및 단일의 컨볼루셔널 레이어로 구성되는, 서버 장치."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 심층신경망 모델은 제1 심층신경망 모델이고,상기 추론 데이터는 제1 추론 데이터고,상기 적어도 하나의 프로세서는:상기 디코딩된 데이터를 입력으로 하는 제2 심층신경망 모델을 이용하여, 상기 오프로딩된 데이터에 대응하는제2 추론 데이터를 출력하는, 상기 하나 이상의 인스트럭션을 더 포함하되,상기 추출기 모델, 상기 디코더 모델은, 상기 제1 심층신경망 모델의 손실 정보 및 상기 제2 심층신경망 모델의손실 정보를 이용하여 합동 훈련되는, 서버 장치."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,상기 추출기 모델은, 지식 증류(knowledge distillation) 기법을 이용하여 학습되는, 서버 장치."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서,공개특허 10-2023-0075362-5-상기 원본 데이터는, 상기 심층신경망 모델을 이용한 애플리케이션에 사용되는 이미지, 영상, 오디오, 텍스트,센서 값 중 적어도 하나의 데이터를 포함하는, 서버 장치."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 심층신경망 모델은, 원본 데이터에 기초하여 이미지 분류(classification), 이미지 분할(segmentation),이미지 캡셔닝(captioning) 객체 탐지(detection), 깊이 추정(depth estimation), 위치 추정(localization) 또는 자세 추정(pose estimation)을 수행하는 모델인, 서버 장치."}
{"patent_id": "10-2022-0154653", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "오프로딩 시스템에 있어서,단말 장치; 및서버 장치를 포함하되,상기 단말 장치는:원본 데이터에 대응하는 이미지를 획득하는 카메라;하나 이상의 인스트럭션을 저장하는 제1 메모리; 및상기 제1 메모리에 저장된 하나 이상의 인스트럭션을 실행하는 적어도 하나의 제1 프로세서를 포함하되, 상기적어도 하나의 제1 프로세서는,상기 원본 데이터를 입력으로 하는 추출기 모델을 이용하여 잠재 표현(latent representation) 데이터를 생성하고,상기 잠재 표현 데이터를 상기 서버 장치로 오프로딩하는, 상기 하나 이상의 인스트럭션을 실행하고,상기 서버 장치는:하나 이상의 인스트럭션을 저장하는 제2 메모리; 및상기 제2 메모리에 저장된 하나 이상의 인스트럭션을 실행하는 적어도 하나의 제2 프로세서를 포함하되, 상기적어도 하나의 제2 프로세서는,상기 단말 장치로부터 상기 오프로딩된 데이터를 수신하고,디코더 모델을 이용하여, 상기 오프로딩된 데이터를 디코딩하고,상기 디코딩된 데이터를 입력으로 하는 심층신경망 모델을 이용하여, 상기 오프로딩된 데이터에 대응하는 추론데이터를 출력하는, 상기 하나 이상의 인스트럭션을 실행하되,상기 추출기 모델, 상기 디코더 모델, 및 상기 심층신경망 모델은, 상기 심층신경망 모델의 손실 정보를 이용하여 합동 훈련(joint training)되는, 시스템."}
{"patent_id": "10-2022-0154653", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 오프로딩된 데이터를 처리하는 방법, 서버 장치, 및 시스템에 관한 것이다. 일 실시예에 따른 오프로 딩된 데이터를 처리하는 방법은, 단말 장치로부터 오프로딩된 데이터를 수신하는 단계, 디코더 모델을 이용하여, 오프로딩된 데이터를 디코딩하는 단계, 디코딩된 데이터를 입력으로 하는 심층신경망 모델을 이용하여, 오프로딩 된 데이터에 대응하는 추론 데이터를 출력하는 단계를 포함할 수 있다. 오프로딩된 데이터는, 원본 데이터를 입 력으로 하는 추출기 모델에 의해 생성된 잠재 표현 데이터를 포함할 수 있다. 추출기 모델, 디코더 모델, 및 심 층신경망 모델은, 심층신경망 모델의 손실 정보를 이용하여 합동 훈련될 수 있다."}
{"patent_id": "10-2022-0154653", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 오프로딩된 데이터를 처리하는 방법, 서버 장치, 및 시스템에 관한 것으로, 더욱 상세하게는 추출기 모델, 디코더 모델, 및 심층신경망 모델을 합동 훈련(joint training)할 수 있는 오프로딩된 데이터를 처리하는 방법, 서버 장치, 및 시스템에 관한 것이다."}
{"patent_id": "10-2022-0154653", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 들어, IoT 기기와 스마트폰 등 무선 통신이 가능한 기기들에서 심층신경망 기반의 서비스들이 널리 사용되 고 있다. 이런 기기들의 부족한 연산 자원 문제를 해결하기 위해서 오프로딩이 대두되고 있다. 그러나 수많은 기기에서의 과도한 오프로딩 요청들은 네트워크 대역폭 활용에 큰 문제를 야기하고 있다. 도심과 같이 큰 네트워크 대역폭을 가진 경우 심층신경망(DNN) 오프로딩을 위해 전송되는 데이터양을 충분히 감 당할 수는 있지만, 이러한 데이터들이 네트워크 대역폭의 큰 부분을 차지하면서 다른 유저들이 활용할 수 있는 사용가능한 네트워크 대역폭을 감소시키고, 이는 사용자 경험(user experience)을 떨어트리는 요인으로 작용하 고 있다. 달동네와 같이 적은 네트워크 대역폭을 가진 경우의 문제는 더욱 심각해진다. 네트워크 대역폭이 애초에 심층신 경망 오프로딩을 위해 전송되는 데이터양을 충분히 감당할 수 없어서 심층신경망 서비스를 제대로 제공하지 못 하고, 또한 사용가능한 네트워크 대역폭을 없앰으로써 사용자들의 네트워크 사용자 경험을 크게 감소시킨다. 이러한 문제를 해결하기 위해서는 대역폭을 효율적으로 활용해야 하는데, 이를 위한 하나의 유망한 솔루션은 압 축된 데이터를 오프로딩하는 것이다. 그러나, 기존의 이미지 압축 기술은 사람의 눈에 맞춰 설계되었기 때문에 압축률에 한계가 있다. 도 1은 복원했을 시 사람 눈으로 보기에 차이가 없도록 압축이 되는 경우를 설명하기 위한 개념도이다. 도 1에서와 같이 복원했을 시 사람 눈으로 보기에 차이가 없도록 압축이 되어 있고, 이는 즉 심층신경망에 필요 한 정보가 아닌 사람 눈에 필요한 정보가 포함되어 있다는 것이다. 도 2는 심층신경망을 돌려서 결과를 알고 싶은 부분만 잘라내어 압축하는 방식을 설명하기 위한 개념도이다. 도 2를 참조하면, 심층신경망에 불필요한 정보를 공간 부분에서 잘라냄으로써 도 2의 방식보다 상대적으로 높은 압축률을 달성할 수 있다. 그러나, 도 2의 방식은 심층신경망의 불필요한 정보를 공간이라는 작은 부분에서만 찾았기 때문에 실제로 복원 된 이미지는 사람 눈으로 알아볼 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-1778214호(공고일 : 2017. 09. 14.)"}
{"patent_id": "10-2022-0154653", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 심층신경망 기반의 인코더와 심층신경망을 연결하여 심층신경망 손실함수로 합동 훈련(joint trainning)을 진행할 수 있는 심층신경망 기반의 데이터 압축 방법 및 시스템을 제공하고자 한다. 본 개시는 추출기 모델, 디코더 모델, 및 심층신경망 모델을 합동 훈련(joint training)할 수 있는 오프로딩된 데이터를 처리하는 방법, 서버 장치, 및 시스템을 제공하고자 한다. 본 개시가 해결하고자 하는 과제는 상기에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른 해결하고 자 하는 과제는 아래의 기재들로부터 본 개시가 속하는 통상의 지식을 가진 자에 의해 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0154653", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 심층신경망을 이용한 응용 서비스에 사용되는 데이터를 압축하는 방법에 있어서, 사용되는 기 계학습 기반의 인코더와 응용 서비스에 활용되는 심층신경망을 결합하여 심층신경망의 성능을 위한 손실함수를활용하여 합동 훈련(Joint training)하는 심층신경망 기반의 데이터 압축 방법을 제공할 수 있다. 일 실시예에 따른 상기 인코더는, 오토인코더(Autoencoder), 생성 모델(Generative Model)로 활용되는 오토인코 더(Autoencoder) 또는 생성 모델(Generative Model)과 같이 인코더로 활용되는 심층학습 기법들을 포함할 수 있 다. 일 실시예에 따른 상기 데이터는, 상기 응용 서비스에 사용되는 이미지, 비디오, 텍스트, 센서 값 중 적어도 하 나 이상의 데이터를 포함할 수 있다. 일 실시예에 따른 상기 합동 훈련에 사용되는 상기 손실함수는, 상기 심층신경망의 손실함수를 단독으로 활용하 거나 또는 상기 심층신경망의 손실함수를 포함하여 다른 손실함수와 결합될 수 있다. 일 실시예에 따르면, 상기 인코더에 포함된 디코더 대신에 상기 응용 서비스에 활용되는 상기 심층신경망이 디 코더의 역할을 수행할 수 있다. 일 실시예에 따르면, 상기 디코더를 완전히 제거하거나 일부를 남길 수 있다. 일 실시예에 따르면, 압축된 데이터를 상기 심층신경망의 입력값의 형태로 변형하기 위한 입력 구조 변형부를 더 포함할 수 있다. 일 실시예에 따른 상기 입력 구조 변형부는, 업샘플링(upsampling) 및 리쉐이프(reshape)와 같은 기계학습 기반 이 아닌 기법과 컨볼루셔널 레이어(convolutional layer)를 갖는 기계학습 기반의 기법을 포함할 수 있다. 일 실시예에 따른 응용 서비스에 사용되는 데이터를 압축하는 시스템에 있어서, 사용되는 기계학습 기반의 인코 더와 응용 서비스에 활용되는 심층신경망을 결합하여 심층신경망의 성능을 위한 손실함수를 활용하여 합동 훈련 (Joint training)하는 압축 기법을 포함하는 심층신경망 기반의 데이터 압축 시스템을 제공할 수 있다. 일 실시예에 따른 오프로딩된 데이터를 처리하는 방법은, 단말 장치로부터 오프로딩된 데이터를 수신하는 단계, 디코더 모델을 이용하여, 상기 오프로딩된 데이터를 디코딩하는 단계, 상기 디코딩된 데이터를 입력으로 하는 심층신경망 모델을 이용하여, 상기 오프로딩된 데이터에 대응하는 추론 데이터를 출력하는 단계를 포함할 수 있 다. 일 실시예에 따르면, 상기 오프로딩된 데이터는, 원본 데이터를 입력으로 하는 추출기 모델에 의해 생성된 잠재 표현(latent representation) 데이터를 포함할 수 있다. 일 실시예에 따르면, 상기 추출기 모델, 상기 디 코더 모델, 및 상기 심층신경망 모델은, 상기 심층신경망 모델의 손실 정보를 이용하여 합동 훈련(joint training)될 수 있다. 일 실시예에 따른 오프로딩된 데이터를 처리하는 서버 장치는, 하나 이상의 인스트럭션을 저장하는 메모리, 및 상기 메모리에 저장된 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적 어도 하나의 프로세서는, 단말 장치로부터 오프로딩된 데이터를 수신하고, 디코더 모델을 이용하여, 상기 오프 로딩된 데이터를 디코딩하고, 상기 디코딩된 데이터를 입력으로 하는 심층신경망 모델을 이용하여, 상기 오프로 딩된 데이터에 대응하는 추론 데이터를 출력하는, 상기 하나 이상의 인스트럭션을 실행할 수 있다. 일 실시예에 따르면, 상기 오프로딩된 데이터는, 원본 데이터를 입력으로 하는 추출기 모델에 의해 생성된 잠재 표현(latent representation) 데이터를 포함할 수 있다. 일 실시예에 따르면, 상기 추출기 모델, 상기 디코더 모델, 및 상기 심층신경망 모델은, 상기 심층신경망 모델의 손실 정보를 이용하여 합동 훈련(joint training)될 수 있다. 일 실시예에 따른 오프로딩 시스템은, 단말 장치, 및 서버 장치를 포함할 수 있다. 상기 단말 장치는, 원본 데 이터에 대응하는 이미지를 획득하는 카메라, 하나 이상의 인스트럭션을 저장하는 제1 메모리, 및 상기 제1 메모 리에 저장된 하나 이상의 인스트럭션을 실행하는 적어도 하나의 제1 프로세서를 포함할 수 있다. 상기 적어도 하나의 제1 프로세서는, 상기 원본 데이터를 입력으로 하는 추출기 모델을 이용하여 잠재 표현(latent representation) 데이터를 생성하고, 상기 잠재 표현 데이터를 상기 서버 장치로 오프로딩하는, 상기 하나 이상 의 인스트럭션을 실행할 수 있다. 상기 서버 장치는, 하나 이상의 인스트럭션을 저장하는 제2 메모리, 및 상기 제2 메모리에 저장된 하나 이상의 인스트럭션을 실행하는 적어도 하나의 제2 프로세서를 포함할 수 있다. 상기 적어도 하나의 제2 프로세서는, 상기 단말 장치로부터 상기 오프로딩된 데이터를 수신하고, 디코더 모델을 이용 하여, 상기 오프로딩된 데이터를 디코딩하고, 상기 디코딩된 데이터를 입력으로 하는 심층신경망 모델을 이용하 여, 상기 오프로딩된 데이터에 대응하는 추론 데이터를 출력하는, 상기 하나 이상의 인스트럭션을 실행할 수 있 다. 일 실시예에 따르면, 상기 오프로딩된 데이터는, 원본 데이터를 입력으로 하는 추출기 모델에 의해 생성된 잠재 표현(latent representation) 데이터를 포함할 수 있다. 일 실시예에 따르면, 상기 추출기 모델, 상기 디 코더 모델, 및 상기 심층신경망 모델은, 상기 심층신경망 모델의 손실 정보를 이용하여 합동 훈련(jointtraining)될 수 있다."}
{"patent_id": "10-2022-0154653", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시예에 따르면, 심층신경망 기반의 인코더와 심층신경망을 연결하여 심층신경망 손실함수로 합동 훈련(joint training)을 진행할 수 있으며, 이를 위해 심층신경망 서비스를 위한 압축 기법을 통하여 높은 압축 률을 달성함으로써, 심층신경망을 이용한 대규모 응용 서비스를 가능하게 할 수 있다. 본 개시의 실시예에 따르면, 높은 압축률을 통해 전송할 데이터의 양을 줄임으로써 전송 시간을 감소시켜 저지 연 서비스 실현을 효과적으로 지원할 수 있다."}
{"patent_id": "10-2022-0154653", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "먼저, 본 개시의 장점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되는 실 시 예들을 참조하면 명확해질 것이다. 여기에서, 본 개시는 이하에서 개시되는 실시 예들에 한정되는 것이 아니 라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시 예들은 본 개시의 개시가 완전하도록 하고, 본 개 시가 속하는 기술 분야에서 통상의 지식을 가진 자가 발명의 범주를 명확하게 이해할 수 있도록 하기 위해 예시 적으로 제공되는 것이므로, 본 개시의 기술적 범위는 청구항들에 의해 정의되어야 할 것이다. 아울러, 아래의 본 개시를 설명함에 있어서 공지 기능 또는 구성 등에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고, 후술되는 용어들은 본 개시에서의 기능을 고려하여 정의된 용어들인 것으로, 이는 사용자, 운용자 등의 의도 또는 관례 등에 따라 달 라질 수 있음은 물론이다. 그러므로, 그 정의는 본 명세서의 전반에 걸쳐 기술되는 기술사상을 토대로 이루어져야 할 것이다. 이하, 첨부된 도면을 참조하여 본 개시의 바람직한 실시 예에 대하여 상세하게 설명한다. 기존의 압축 기법을 활용한 심층신경망(DNN) 오프로딩 기법들의 경우, 인코더는 인코더 따로 심층신경망은 심층 신경망 따로 독립적으로 학습을 진행하는데, 이 경우 인코더는 원본 복원을 위하여 학습되어 심층신경망에 불필 요한 정보들이 되어 압축률 상승에 걸림돌이 된다. 본 개시에서 제안하는 기법은 기계학습 기반의 인코더와 심층신경망 서비스에 활용되는 신경망을 연결하여 심층 신경망의 성능을 나타내는 손실함수로 합동훈련(Joint training)을 진행하여 원본 복원을 고려하지 않고 심층신 경망의 성능에 불필요한 정보를 제거(즉, 인코더가 심층신경망에 필요한 정보만을 압축)함으로써, 기존의 압축 기법에 비해 상대적으로 높은 압축률을 실현할 수 있다. 본 개시에 따르면, 추가적으로 심층학습 기반의 인코더(압축기)의 디코더(복원기)와 응용 서비스에 활용되는 심 층신경망이 같은 신경망임을 활용하여 디코더를 압축된 데이터로서 심층신경망에 입력하는 기법을 제안할 수 있 다. 도 3은 본 개시에 따라 심층신경망에 필수적인 정보만을 추출하여 압축 및 전송하는 것을 설명하기 위한 개념도 이다. 도 3을 참조하면, 본 개시에서 제안하고자 하는 방식은 사람 눈을 신경 쓰지 말고, 정말 심층신경망에 필수적인 정보만을 추출하여 압축함으로써 심층신경망의 성능을 유지하면서 최대의 압축률을 달성하고자 하는 것이다. 본 개시에 따른 압축 기법의 경우는 복원시에 사람 눈으로 알아볼 수 없는 형태가 되지만, 최근 심층신경망의 경우 자율주행 자동차에서 거리를 제고 어떠한 방식으로 움직일지를 알아내는 것처럼, 원본 이미지가 필요 없는 경우에는 전혀 문제가 없다. 도 4는 심층신경망별로 필요로 하는 정보가 다름을 설명하기 위한 예시도이다. 도 4를 참조하면, 공을 제외한 배경을 제거했을 경우, 물체 분류(Object classification)를 위한 심층신경망은 축구공이라 정확히 판단할 수 있다. 그러나, 분할(segmentation)을 위한 심층신경망의 경우, 골대부분이 사라져서 잘못된 결과가 도출될 수 있다. 도 5는 심층신경망별로 필요로 하는 정보가 다름을 설명하기 위한 예시도이다. 도 5를 참조하면, 도 5의 예시와 달리 축구공의 패턴을 지우게 되면, 물체 분류를 위한 심층신경망의 경우 하얀 원이 축구공인지 야구공인지 골프공인지 알 수가 없는 결과가 초래된다. 그러나, 분할을 위한 심층신경망의 경우 골대부분과 공의 태두리가 존재하기 때문에 옳은 결과가 도출될 수 있 다. 기존의 이미지 압축 기법은 무손실 압축 기법(lossless codec)과 손실 압축 기법(lossy codec)이 존재하는데, 예컨대 이미지 압축 기법의 경우, 손실 압축 기법은 복원한 이미지가 사람 눈으로 봤을 때 원본과의 차이가 느 껴지지 않도록 사람 눈이 인지하지 못하는 정보들을 제거함으로써 압축률을 높이고 사람 눈으로 봤을 때 원본처 럼 보이도록 하는 기법을 의미한다. 즉, 압축 이미지에 심층신경망에 불필요한 이미지 복원을 위한 정보들이 포함되어 있기 때문에 압축률을 상승시 킬 수 있는 여지가 있다. 또한, 심층신경망별로 필요로 하는 정보가 다른데, 도 4를 참조하면, 공의 패턴과 같이 이미지의 디테일을 제거 하더라도 분할을 위한 심층신경망의 경우 정확한 판단을 할 수 있다. 그러나, 공의 종류를 분류하는 범주를 위한 심층신경망의 경우는 공의 패턴이 제거되었기 때문에 흰색 원을 축 구공으로 판단할 수 없다. 따라서, 각 심층학습 응용에 맞게 불필요한 정보를 제거하여 높은 압축률을 달성할 수 있는 압축 기법이 요구되고 있다. 이를 위해, 본 개시에서는 심층신경망별로 다른 필수 정보를 추출하고 불필요한 정보를 제거하는 압축 기법을 설계하기 위하여 심층신경망 기반의 압축 기법을 제안한다. 도 6은 기존의 심층신경망 기반의 압축 기법을 설명하기 위한 구성도로서, 인코더와 디코더가 심층신 경망에 결합되는 구조를 갖는다. 도 6을 참조하면, 기존 심층신경망 기반 압축 기법의 경우, 심층신경망 기반의 인코더는 원본과 복원된 이 미지의 차를 나타내는 손실함수(reconstruction loss)로 학습하고, 심층신경망의 경우는 심층신경망 의 성능을 위한 심층신경망 손실함수로 각각 학습하게 된다. 디코더를 통해 복원된 데이터(예컨대, 이미지)는 원본과 유사한 형태를 띄게 된다. 여기에서, 데이터는 응 용 서비스에 사용되는 이미지, 비디오, 텍스트, 센서 값 중 적어도 하나 이상의 데이터를 포함할 수 있다. 도 7은 일 실시예에 따른 심층신경망 기반의 압축 기법을 설명하기 위한 구성도로서, 인코더 및 디코더 가 심층신경망에 결합되는 구조를 갖는다. 여기에서, 인코더 및 디코더는, 예컨대 오토인 코더(Autoencoder) 또는 생성 모델(Generative Model)로 활용되는 기계학습 기법들을 포함할 수 있다. 도 7을 참조하면, 일 실시예에 따른 압축 기법의 학습 과정은 심층신경망 기반의 인코더와 디코더를 심층신경망에 연결하여 심층신경망 손실함수로 합동 훈련(joint training)을 진행한다. 이를 통하여 심층 신경망 기반의 인코더가 심층신경망의 성능에 불필요한 정보를 제거하게 된다. 그래서, 인코더와 디코더를 통해 복원된 이미지의 경우, 사람 눈으로 알아볼 수 없는 심층신경망 을 위한 특징(feature)의 형태로 보이게 된다. 합동 훈련에 사용되는 손실함수는, 예컨대 심층신경망의 손실함수를 단독으로 활용하거나 또는 심층신경망 의 손실함수를 포함하여 다른 손실함수와 결합될 수 있다. 또한, 디코더 대신에 심층신경망을 이용한 응용 서비스에 활용되는 심층신경망이 디코더의 역할을 수행할 수 있 도록 설계될 수도 있으며, 디코더는 완전히 제거되거나 혹은 일부만이 남겨질 수 있다. 그러나, 이러한 형태임에도 불구하고 심층신경망 성능을 위한 정보를 포함하고 있기 때문에 심층신경망 성능은 온전히 유지될 수 있다. 도 8은 일 실시예에 따른 심층신경망 기반의 압축 기법을 설명하기 위한 구성도로서, 인코더 및 입력 구조 변형부가 심층신경망에 결합되는 구조를 갖는다. 여기에서, 인코더는, 예컨대 오토인코더 (Autoencoder) 또는 생성 모델(Generative Model)로 활용되는 기계학습 기법들을 포함할 수 있다. 도 9는 도 8의 입력 구조 변형부가 업샘플링 형태로 구현될 수 있음을 보여주는 구성도이다. 도 9를 참조하면, 업샘플링으로 구현되는 압축 기법은 이의 실현을 위해, 인코더 및 업샘플링가 심층 신경망에 결합되는 구조를 갖는다. 도 10은 컨볼루셔널 레이어(convolutional layer)의 계층 구조도이고, 도 11은 트랜스포즈 컨볼루셔널 레이어 (Transposed convolutional layer)의 계층 구조도이다. 도 8을 참조하면, 입력 구조 변형부는 심층학습 기반의 인코더의 디코더와 응용 서비스에 활용되는 심층신 경망이 같은 신경망임을 활용하여 디코더의 압축된 데이터를 심층신경망의 입력하기 위한 구조를 가질 수 있다. 예컨대, 인코더와 응용 서비스에 활용되는 심층신경망의 종류가 합성곱 신경망(Convolutional neural network : CNN)인 경우, CNN 기반 인코더를 구성하는 트랜스포즈 컨볼루셔널 레이어(Transposed convolutional layer)는 컨볼루셔널 레이어(convolutional layer)와 업샘플링(upsampling)`의 조합으로 구성되어 있기 때문에 디코더를 업샘플링 레이어로 대체하고 디코딩 부분을 기존의 심층신경망에 전가할 수 있다. 즉, 업샘플링 레이어가 입력 구조 변형부가 되는데, 일반적으로 설명하면, 디코더 대신에 압축된 데이터를 심층 신경망의 입력 구조에 맞게 변형하는 입력 구조 변형부를 추가함으로써, 압축된 데이터를 디코딩하지 않고 직접 적으로 심층신경망에 입력할 수 있으며, 이를 통해 디코딩에 사용되는 시간과 연산 자원을 단축 및 절약할 수 있다. 입력 구조 변형부는, 예컨대 업샘플링(upsampling) 및 리쉐이프(reshape)와 같은 기계학습 기반이 아닌 기 법과 컨볼루셔널 레이어를 갖는 기계학습 기반의 기법을 포함할 수 있다. 도 12는 본 개시의 실시예에 따른 데이터 압축 방법을 적용시킬 수 있는 계통도이다. 도 12를 참조하면, 일 실시예에 따른 데이터 압축 방법은 다음과 같은 방식으로 동작할 수 있다. 1) 본 실시예에 따른 심층신경망의 손실함수를 활용하여 인코더, 디코더와 심층신경망을 합동 훈련하는 방식을 통해 오프라인으로 학습을 진행할 수 있다. 2) 서버는 학습된 인코더를 단말로 전송한다. 3) 단말에서 심층신경망 오프로딩 서비스를 실행할 경우, 입력 데이터를 학습된 인코더로 압축한 후 서버 로 전송한다. 4) 일 실시예에 따른 입력 구조 변형부(도 8, 804)를 활용할 경우, 서버는 단말로부터 수신한 압축 데이터를 디코딩 과정 없이 심층신경망에 입력하여 심층신경망 연산을 진행할 수 있다. 만약, 일 실시예에 따른 입력 구조 변형부를 활용하지 않을 경우, 서버는 단말로부터 수신한 압 축데이터를 디코더를 통하여 복원한 후 심층신경망에 입력하여 심층신경망 연산을 진행할 수 있다. 도 13은 일 실시 예에 따른 오프로딩 시스템을 보여주는 블록도이다. 오프로딩 시스템은 단말 장치 및 서버 장치를 포함할 수 있다. 오프로딩(offloading) 시스템은 단말 장치에서 실행되는 애플리케이션의 작업 중 적어도 일부를 서 버 장치에서 처리하도록 하는 시스템일 수 있다. 오프로딩 시스템은 애플리케이션의 작업 중 심층 신경망(deep neural network; DNN) 기반의 작업 중 적어도 일부를 서버 장치에서 처리하도록 하는 시스템 일 수 있다. 단말 장치는 원본 데이터를 획득할 수 있다. 예를 들어, 원본 데이터는 이미지, 영상, 오디오, 텍스트, 센서 값 중 적어도 하나일 수 있다. 일 실시예에 있어서, 단말 장치는 외부 장치 또는 입력 장치(예컨대, 카메라, 센서, 마이크 등)를 이용하여 원본 데이터를 획득할 수 있다. 예를 들어, 단말 장치는 카메라를 통해 원본 데이터(예컨대, 이미지)를 획득할 수 있다. 일 실시예에 있어서, 단말 장치는 메모리 또는 스 토리지에 저장된 데이터를 로드함으로써 원본 데이터를 획득할 수 있다. 단말 장치는 원본 데이터을 입력으로 하는 추출기 모델을 이용하여 잠재 표현(latent representation) 데이터를 생성할 수 있다. 추출기 모델은 원본 데이터에서 필수 정보, 즉 잠재 표현 데 이터를 추출할 수 있다. 여기서, 필수 정보는 심층신경망을 이용한 추론에 필요한 최소한의 정보를 나타 낼 수 있다. 잠재 표현 데이터는 잠재 벡터로도 지칭될 수 있다. 일 실시예에 있어서, 추출기 모델는 오토인코더(Autoencoder)의 인코더(encoder) 부분일 수 있다. 예를 들어, 추출기 모델는 적어도 하나의 컨볼루셔널 레이어를 포함할 수 있다. 단말 장치는 잠재 표현 데이터를 서버 장치로 오프로딩할 수 있다. 단말 장치는 네트워크를 통해 잠재 표현 데이터를 서버 장치에 전송할 수 있다. 서버 장치는 네트워크를 통해 오프로딩된 데이터(즉, 잠재 표현 데이터)를 수신할 수 있다. 일 실시예에 있어서, 잠재 표현 데이터의 크기는 미리 정의될 수 있다. 따라서, 잠재 표현 데이터의 크기는 제 조사 또는 사용자의 설정에 따른 값으로 고정될 수 있다. 일 실시예에 따르면, 잠재 표현 데이터의 크기가 미리 정의됨으로써, 잠재 표현 데이터를 송수신하는 통신 채널의 대역폭 적응성(bandwidth adaptability)을 높일 수 있다. 일 실시예에 따른 단말 장치는 다양한 형태로 구현될 수 있다. 예를 들어, 단말 장치는 스마트 폰 (smart phone), 노트북 컴퓨터(laptop computer), PC(Personal Computer), 태블릿 PC, 디지털 카메라, CCTV(Closed-Circuit Television), 전자북 단말기, 디지털방송용 단말기, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 네비게이션, 또는 MP3 플레이어 등을 포함할 수 있으나, 이에 한정되는 것 은 아니다. 서버 장치는 단말 장치로부터 오프로딩된 데이터를 수신할 수 있다. 서버 장치는 디코더 (decoder) 모델을 이용하여, 오프로딩된 데이터를 디코딩할 수 있다. 디코더 모델는 오토인코더의 디코더 부분일 수 있다. 예를 들어, 디코더 모델는 적어도 하나의 컨볼루셔널 레이어를 포함할 수 있다. 일 실시예에 있어서, 추출기 모델과 디코더 모델는 오토인코더 모델로 구현될 수 있다. 일 실시예에 있어서, \"디코딩\"은 작은 차원의 데이터를 큰 차원의 데이터로 변환하는 작업(예컨대, 데이터 포맷 변환 작업)을 나타낼 수 있다. 예를 들어, 서버 장치는 오프로딩된 데이터를 심층신경망 모델의 입 력 값의 형태로 변형하는 방식으로, 오프로딩된 데이터를 디코딩할 수 있다. 따라서, 오프로딩된 잠재 표현 데 이터이 재구성될 수 있다. 일 실시예에 따르면, 디코더 모델이 단순한 데이터 포맷 변환기로 동작함으로 써, 심층신경망의 추론 정확도를 저하시키지 않으면서 서버 장치의 연산 부하를 완화시킬 수 있다.서버 장치는 디코딩된 데이터를 입력으로 하는 심층신경망 모델을 이용하여, 원본 데이터(또는 오 프로딩된 데이터)에 대응하는 추론 데이터를 출력할 수 있다. 예를 들어, 심층신경망 모델은 이미지 분류 (classification), 이미지 분할(segmentation), 이미지 캡셔닝(captioning) 객체 탐지(detection), 깊이 추정 (depth estimation), 위치 추정(localization) 또는 자세 추정(pose estimation)을 수행하는 모델일 수 있으나, 본 개시는 이제 제한되지 않는다. 예를 들어, 심층신경망 모델이 동물을 분류하는 모델인 경우, 심층신경망 모델은 고양이가 있는 이미지 또는 영상을 입력으로 하여 이미지 또는 영상의 객체를 고양이 로 추론할 수 있다. 예를 들어, 심층신경망 모델이 CCTV의 장면을 분류하는 모델인 경우, 범죄 장면의 이 미지 또는 영상을 입력으로 하여, 이미지 또는 영상의 장면을 범죄 장면으로 추론할 수 있다. 서버 장치는 단말 장치로 추론 데이터를 전송할 수 있다. 단말 장치는 추론 데이터를 수신할 수 있다. 단말 장치는 추론 데이터를 이용하여 애플리케이션 서비스를 제공할 수 있다. 일 실시예에 있어서, 추출기 모델, 디코더 모델, 및 심층신경망 모델은, 심층신경망 모델의 손실 정보를 이용하여 합동 훈련(joint training)될 수 있다. 추출기 모델, 디코더 모델, 및 심층 신경망 모델이 합동 훈련되는 예시는, 도 14에서 구체적으로 설명한다. 도 14는 일 실시 예에 따른 학습 서버 장치를 보여주는 블록도이다. 도 13의 추출기 모델, 디코더 모델 , 및 심층신경망 모델은 추출기 모델, 디코더 모델, 및 심층신경망 모델이 훈련 (또는 학습으로도 지칭될 수 있음)된 결과에 대응할 수 있다. 설명의 편의를 위해, 도 13에서 설명한 내용과 중 복되는 내용은 이하 생략한다. 학습 서버 장치는 훈련 데이터셋을 입력으로 하여, 추출기 모델, 디코더 모델, 및 심층신경 망 모델을 합동 훈련시킬 수 있다. 일 실시예에 있어서, 추출기 모델 및 디코더 모델는 오토 인코더 모델의 학습 방식으로 학습될 수 있다. 학습 서버 장치는 손실 함수를 이용하여, 추론 데이터와 훈련 데이터셋에 대응하는 그라운드 트루 스(Ground Truth) 값을 비교할 수 있다. 본 명세서에서, 손실 함수의 결과 값은 손실 정보로 지칭될 수 있다. 학습 서버 장치는 심층신경망 모델의 손실 정보를 이용하여 추출기 모델, 디코더 모델 , 및 심층신경망 모델을 합동 훈련시킬 수 있다. 일 실시예에 따르면, 추출기 모델 및 디코 더 모델의 학습에 있어 심층신경망 모델의 손실 정보가 활용될 뿐, 추출기 모델 및 디코더 모델 각각에 대한 손실 정보가 활용되지 않을 수 있다. 일 실시예에 따른 심층신경망 모델의 손실 정보를 이용하여 추출기 모델, 디코더 모델, 및 심층신경망 모델을 합동 훈련시키기 위한 파라미터 최적화(optimization) 방정식은 수학식 1으로 표현될 수 있다. 수학식 1"}
{"patent_id": "10-2022-0154653", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1을 참고하면, 는 심층신경망 모델의 (현재) 훈련 파라미터 셋으로 정의되고, 는 추출기 모델 및 디코더 모델의 (현재) 훈련 파라미터 셋으로 정의되고, DL은 심층신경망 모델의 손 실 함수로 정의되고, 는 를 이용하여 출력된 추론 데이터의 값으로 정의되고, 는 를 이용하여 출력된 디코딩된 데이터의 값으로 정의되고, H는 엔트로피 함수로 정의되고, α는 가중치 값으로 정의 되고, x는 원본 데이터로 정의되고, y는 그라운드 트루스 값으로 정의되고, z는 잠재 표현 데이터로 정의된다. 는 심층신경망 모델의 최적화된 훈련 파라미터 셋으로 정의되고, 는 추출기 모델 및 디코 더 모델의 최적화된 훈련 파라미터 셋으로 정의된다. 일 실시예에 있어서, 를 구하기 위한 방정식의첫번째 항은 데이터 왜곡에 관련한 항이고, 두번째 항은 인코더 모델의 압축 능력에 관련한 항일 수 있다. 일 실시예에 있어서, α는 0 이상 1 이하의 수일 수 있으며, 사용자 또는 제조사의 설정에 따라 변경될 수 있다. 따라서, 학습 서버 장치는 현재 훈련 파라미터 셋을, 심층신경망 모델의 손실 함수의 값을 최솟값으로 만드는, 추출기 모델, 디코더 모델, 및 심층신경망 모델의 훈련 파라미터 셋으로 업데이트할 수 있다. 일 실시예에 있어서, 잠재 표현 데이터의 크기가 미리 정의될 수 있다. 이 경우, 수학식 1의 를 구하기 위한 방정식에서 두번째 항을 생략할 수 있으며, 파라미터 최적화(optimization) 방정식은 수학식 2로 표현될 수 있 다. 수학식 2"}
{"patent_id": "10-2022-0154653", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2를 참고하면, 수학식 1과 달리 을 구하기 위한 방정식과 를 구하기 위한 방정식이 동일하다. 일 실시예에 따르면, 잠재 표현 데이터의 크기를 미리 정의된 크기로 한정함으로써, 심층신경망 모델의 손실 을 최소화함에 있어서 정보의 유용성을 극대화할 수 있다. 일 실시예에 있어서, 학습 서버 장치는 도 13의 서버 장치와 동일한 장치일 수 있으나, 본 개시는 이에 한정되지 않는다. 따라서, 학습 서버 장치는 도 13의 서버 장치와 별개의 장치일 수 있다. 이 경우, 학습 서버 장치는 합동 훈련이 완료된 추출기 모델, 디코더 모델, 및 심층신경망 모델 을 도 13의 서버 장치로 전송할 수 있다. 도 15는 일 실시 예에 따른 오프로딩 시스템을 보여주는 블록도이다. 도 13의 단말 장치 및 서버 장치 의 구성(예컨대, 1301, 1302, 1304), 기능, 동작은 단말 장치 및 서버 장치의 구성(예컨대, 1501, 1502, 1504), 기능, 동작에 대응할 수 있다. 도 13의 심층신경망 모델은 복수의 심층신경망 모델들 (1506_1, 1506_2, ..., 1506_n) 각각에 대응할 수 있다. 설명의 편의를 위해, 도 13에서 설명한 내용과 중복되 는 내용은 이하 생략한다. 일 실시예에 있어서, 서버 장치는 디코딩된 데이터를 입력으로 하는 복수의 심층신경망 모델들(1506_1, 1506_2, ..., 1506_n)을 이용하여, 원본 데이터(또는 오프로딩된 데이터)에 대응하는 추론 데이터를 출력할 수 있다. 예를 들어, 서버 장치는 디코딩된 데이터를 입력으로 하는 제1 심층신경망 모델(1506_1)을 이용하 여, 제1 추론 데이터를 출력할 수 있다. 예를 들어, 서버 장치는 디코딩된 데이터를 입력으로 하는 제2 심층신경망 모델(1506_2)을 이용하여, 제2 추론 데이터를 출력할 수 있다. 예를 들어, 서버 장치는 디코 딩된 데이터를 입력으로 하는 제n 심층신경망 모델(1506_n)을 이용하여, 제n 추론 데이터를 출력할 수 있다. 예 를 들어, n은 2 이상의 자연수일 수 있다. 서버 장치는 단말 장치로 제1 내지 제n 추론 데이터를 전송할 수 있다. 단말 장치는 제1 내 지 제n 추론 데이터를 수신할 수 있다. 단말 장치는 제1 내지 제n 추론 데이터를 이용하여 애플리케이션 서비스를 제공할 수 있다. 일 실시예에 있어서, 추출기 모델 및 디코더 모델은, 복수의 심층신경망 모델들(1506_1, 1506_2, ..., 1506_n)의 손실 정보를 이용하여 합동 훈련(joint training)될 수 있다. 일 실시예에 있어서, 복수의 심층 신경망 모델들(1506_1, 1506_2, ..., 1506_n) 각각은, 복수의 심층신경망 모델들(1506_1, 1506_2, ..., 1506_n) 각각의 손실 정보를 이용하여 훈련될 수 있다. 추출기 모델, 디코더 모델 및 복수의 심층 신경망 모델들(1506_1, 1506_2, ..., 1506_n)이 합동 훈련되는 예시는, 도 16에서 구체적으로 설명한다.도 16은 일 실시 예에 따른 학습 서버 장치를 보여주는 블록도이다. 도 15의 추출기 모델, 디코더 모델 , 및 복수의 심층신경망 모델들(1506_1, 1506_2, ..., 1506_n)은 추출기 모델, 디코더 모델 , 및 복수의 심층신경망 모델들(1606_1, 1606_2, ..., 1606_n)이 훈련된 결과에 대응할 수 있다. 설명의 편의를 위해, 도 15에서 설명한 내용과 중복되는 내용은 이하 생략한다. 학습 서버 장치는 훈련 데이터셋을 입력으로 하여, 추출기 모델, 디코더 모델, 및 복수의 심 층신경망 모델들(1606_1, 1606_2, ..., 1606_n)을 합동 훈련시킬 수 있다. 일 실시예에 있어서, 추출기 모델 및 디코더 모델는 오토인코더 모델의 학습 방식으로 학습될 수 있다. 학습 서버 장치는 복수의 심층신경망 모델들(1606_1, 1606_2, ..., 1606_n) 각각에 대응하는 복수의 손실 함수들(1608_1, 1608_2, ..., 1608_n)을 이용하여, 제1 내지 제n 추론 데이터와 훈련 데이터셋에 대응하는 그라 운드 트루스 값을 비교할 수 있다. 학습 서버 장치는 복수의 심층신경망 모델들(1606_1, 1606_2, ..., 1606_n)의 손실 정보를 이용하여 추출 기 모델 및 디코더 모델, 및 복수의 심층신경망 모델들(1606_1, 1606_2, ..., 1606_n)을 합동 훈 련시킬 수 있다. 예를 들어, 제1 심층신경망 모델(1606_1)은 제1 손실 함수(1608_1)에 의한 제1 손실 정보를 이 용하여 훈련될 수 있다. 예를 들어, 제2 심층신경망 모델(1606_2)은 제2 손실 함수(1608_2)에 의한 제2 손실 정 보를 이용하여 훈련될 수 있다. 예를 들어, 제n 심층신경망 모델(1606_n)은 제n 손실 함수(1608_n)에 의한 제n 손실 정보를 이용하여 훈련될 수 있다. 학습 서버 장치는 종합 손실 함수를 이용하여 종합 손실 정보를 획득할 수 있다. 종합 손실 정보는 복수의 손실 함수들(1608_1, 1608_2, ..., 1608_n)의 손실 정보의 가중합일 수 있다. 학습 서버 장치는 종합 손실 정보를 이용하여 추출기 모델 및 디코더 모델를 훈련시킬 수 있다. 일 실시예에 따르면, 추출기 모델 및 디코더 모델가 복수의 심층신경망 모델들(1606_1, 1606_2, ..., 1606_n)에 대응하는 손실 정보를 모두 포함하는 종합 손실 정보를 이용하여 학습됨으로써, 복수의 심층신 경망 모델들(1606_1, 1606_2, ..., 1606_n) 각각에 대한 추출기 모델 및 디코더 모델을 학습시킬 필요가 없다. 일 실시예에 따르면, 복수의 심층신경망 모델들(1606_1, 1606_2, ..., 1606_n) 각각에 입력할 잠재 표현 데이터 를 수신할 필요가 없어 네트워크 전송량을 줄일 수 있다. 일 실시예에 따른 종합 손실 함수는 수학식 3으로 표현될 수 있다. 수학식 3"}
{"patent_id": "10-2022-0154653", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 3을 참고하면, DLi는 제i 심층신경망 모델에 대응하는 손실 함수(즉, 제i 손실 함수)로 정의되고, yi는 제i 심층신경망 모델에 대응하는 그라운드 트루스 값으로 정의되고, 는 제i 심층신경망 모델이 출력하는 추 론 데이터로 정의되고, 는 제i 손실 함수에 대응하는 가중치로 정의되고, N은 심층신경망 모델의 수로 정의 되고, ML은 종합 손실 함수로 정의되고, Y는 yi의 셋으로 정의되고, 는 의 셋으로 정의된다. 일 실 시예에 있어서, 제i 심층신경망 모델은 DLi를 이용하여 학습되고, 추출기 모델 및 디코더 모델은 ML을 이용하여 학습될 수 있다. 도 17은 일 실시 예에 따른 추출기 모델 및 디코더 모델을 좀 더 상세하게 보여주는 블록도이다. 추출기 모델 , 디코더 모델, 심층신경망 모델의 기능 및 동작은 도 13 내지 16에서 설명한 추출기 모델 (1302, 1402, 1502, 1602), 디코더 모델(1304, 1404, 1504, 1604), 심층신경망 모델(1306, 1406, 1506_1, 1506_2, ..., 1506_n, 1606_1, 1606_2, ..., 1606_n)의 기능 및 동작에 대응되므로, 상술한 내용과 중복되는 내용은 이하 생략한다.도 17을 참조하면, 일 실시예에 따른 추출기 모델는 복수의 컨볼루셔널 레이어들을 포함할 수 있다. 컨볼 루셔널 레이어들 각각은 미리 결정된 크기의 필터로 입력 데이터를 처리하여 특징 데이터를 획득한다. 도 17에 서, 추출기 모델은 컨볼루셔널 레이어 33개로 구성되는 것으로 도시되었으나, 이는 일 예시이며, 본 개시 는 이에 제한되지 않는다. 따라서, 추출기 모델에 포함되는 컨볼루셔널 레이어의 개수는 다양하게 변형될 수 있다. 각 컨볼루셔널 레이어에서 이용되는 필터의 개수 및 크기도 다양하게 변경될 수 있고, 각 컨볼루셔널 레이어 간의 연결 순서 및 방식도 다양하게 변경될 수 있다. 일 실시예에 있어서, 복수의 컨볼루셔널 레이어들 중 적어도 일부는 레지듀얼 블록(residual block)으로 구성될 수 있다. 예를 들어, 두 개의 컨볼루셔널 레이어 들이 하나의 레지듀얼 블록을 구성할 수 있다. 추출기 모델은 레지듀얼 블록의 입력 데이터를 레지듀얼 블록의 출력 데이터에 가산할 수 있다. 일 실시예에 따른 디코더 모델는 복수의 트랜스포즈드(tranposed) 컨볼루셔널 레이어들을 포함할 수 있다. 디코더 모델은 추출기 모델의 구조가 트랜스포즈된 구조로 구현될 수 있다. 따라서, 디코더 모델의 복수의 트랜스포즈드(tranposed) 컨볼루셔널 레이어들은 추출기 모델의 복수의 컨볼루셔널 레이어들에 대응되므로, 상술한 내용과 중복되는 내용은 생략한다. 도 18은 일 실시 예에 따른 추출기 모델 및 디코더 모델을 좀 더 상세하게 보여주는 블록도이다. 추출기 모델 , 디코더 모델, 심층신경망 모델의 기능 및 동작은 도 13 내지 16에서 설명한 추출기 모델 (1302, 1402, 1502, 1602), 디코더 모델(1304, 1404, 1504, 1604), 심층신경망 모델(1306, 1406, 1506_1, 1506_2, ..., 1506_n, 1606_1, 1606_2, ..., 1606_n)의 기능 및 동작에 대응되므로, 상술한 내용과 중복되는 내용은 이하 생략한다. 일 실시예에 있어서, 추출기 모델은 지식 증류(knowledge distillation) 기법을 이용하여 학습될 수 있다. 예를 들어, 도 17의 추출기 모델이 선생 모델(teacher model)인 경우, 추출기 모델은 학생 모델(student model)일 수 있다. 일 실시예에 따르면, 지식 증류 기법에 의해, 추출기 모델이 경량화될 수 있다. 일 실시예에 있어서, 디코더 모델은 오토인코더의 복잡한 디코더 구조가 아니라, 단순한 데이터 포맷 변 환기 형태로 구현될 수 있다. 예를 들어, 디코더 모델는 잠재 표현 데이터를 심층싱경망 모델의 입 력 값의 형태로 변형할 수 있다. 도 18에서, 디코더 모델는 단일의 업샘플링 레이어 및 단일의 컨볼루셔 널 레이어로 구성될 수 있으나, 이는 일 예시이며, 본 개시는 이에 제한되지 않는다. 일 실시예에 따르면, 디코 더 모델의 구조가 단순화됨으로써, 디코더 모델이 경량화될 수 있다. 도 19는 일 실시 예에 따른 오프로딩 시스템을 보여주는 블록도이다. 도 19를 참조하면, 오프로딩 시스템(190 0)은 단말 장치 및 서버 장치를 포함할 수 있다. 본 명세서에서 소개되는 실시예들에 따른 오프로 딩된 데이터를 처리하는 방법은, 서버 장치에 의해 수행될 수도 있고, 서버 장치 및 별도의 서버 장치에 의해 공동으로 수행될 수도 있다. 이하에서 설명되는 실시예들에서 오프로딩 시스템이 수행하는 동작들은, 별다른 설명이 없더라도 별도의 서버 장치 등과 같은 별도의 컴퓨팅 장치에 의해 수행될 수도 있다고 해석되어야 한다. 도 13 및 15의 단말 장치(1310, 1510) 및 서버 장치(1320, 1520)는 단말 장치 및 서버 장치에 대응되므로, 중복되는 내용은 이하 생략한다. 도 19를 참조하면, 일 실시예에 따른 단말 장치는 메모리, 프로세서, 입출력 인터페이스 , 및 통신 인터페이스를 포함할 수 있다. 다만, 단말 장치의 구성 요소는 전술한 예에 한정 되는 것은 아니고, 단말 장치는 전술한 구성 요소들보다 더 많은 구성 요소를 포함하거나, 더 적은 구성 요소를 포함할 수도 있다. 일 실시예에 있어서, 메모리, 프로세서, 입출력 인터페이스, 및 통신 인터페이스 중 적어도 일부는 하나의 칩 형태로 구현될 수도 있으며, 프로세서은 하나 이상의 프로세서를 포함할 수도 있다. 메모리는 다양한 프로그램이나 데이터를 저장하기 위한 구성으로서, 롬(ROM), 램(RAM), 하드디스크, CD- ROM 및 DVD 등과 같은 저장 매체 또는 저장 매체들의 조합으로 구성될 수 있다. 메모리는 별도로 존재하 지 않고 프로세서에 포함되도록 구성될 수도 있다. 메모리는 휘발성 메모리, 비휘발성 메모리 또는 휘발성 메모리와 비휘발성 메모리의 조합으로 구성될 수도 있다. 메모리에는 전술한 또는 후술할 실시예 들에 따른 동작들을 수행하기 위한 프로그램이 저장될 수 있다. 메모리는 프로세서의 요청에 따라저장된 데이터(예컨대, 이미지, 영상, 오디오, 텍스트, 센서 값)를 프로세서에 제공할 수도 있다. 메모리는 추출 모듈을 포함할 수 있다. 추출 모듈는 원본 데이터를 입력으로 하는 추출기 모 델을 이용하여 잠재 표현 데이터를 생성하는, 적어도 하나의 인스트럭션에 대응할 수 있다. 프로세서는 도 13 내지 18에서 설명된 실시예들에 따라 단말 장치가 동작하도록 일련의 과정을 제 어하는 구성으로서, 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래 픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 프로세서는 메모리에 데이터를 기록하거나, 메모리에 저장된 데이터를 읽을 수 있으며, 특히 메모리에 저장된 프로그램을 실행함으로써 미리 정의된 동작 규칙 또는 인공지능 모델(예컨대, 추출기 모 델)에 따라 데이터를 처리할 수 있다. 따라서, 프로세서는 상술한 실시예들에서 설명되는 동작들을 수행 할 수 있으며, 상술한 실시예들에서 단말 장치가 수행한다고 설명되는 동작들은 특별한 설명이 없는 한 프로세서가 수행하는 것으로 볼 수 있다. 예를 들어, 하나 또는 복수의 프로세서가 인공지능 전용 프로세 서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델(예컨대, 추출기 모델)의 처리에 특화된 하드웨어 구 조로 설계될 수 있다. 입출력 인터페이스는 사용자로부터 제어 명령이나 정보 등을 입력받기 위한 입력 인터페이스(예컨대, 터 치 스크린, 하드 버튼, 마이크 등)와, 사용자의 제어에 따른 동작의 실행 결과나 단말 장치의 상태를 표 시하기 위한 출력 인터페이스(예컨대, 디스플레이 패널, 스피커 등)를 포함할 수 있다. 통신 인터페이스는 외부의 장치와 유선 또는 무선으로 신호(제어 명령 및 데이터 등)를 송수신하기 위한 구성으로서, 다양한 통신 프로토콜을 지원하는 통신 칩셋을 포함하도록 구성될 수 있다. 통신 인터페이스(191 5)는 외부로부터 신호를 수신하여 프로세서로 출력하거나, 프로세서로부터 출력된 신호를 외부로 전송할 수 있다. 예를 들어, 통신 인터페이스는 잠재 표현 데이터를 서버 장치로 전송할 수 있다. 예를 들어, 통신 인터페이스는 서버 장치로부터 추론 데이터를 수신할 수 있다. 일 실시예에 있어서, 단말 장치는 카메라를 더 포함할 수 있다. 카메라는 렌즈를 통해 광을 수신할 수 있다. 카메라는 이미지 처리기를 포함할 수 있다. 이미지 처리기(미도시)는 수신된 광에 기초 하여, 외부 객체에 관한 이미지 데이터를 생성할 수 있다. 이미지 데이터는 추출기 모델의 입력이 되는 데이터 일 수 있다. 일 실시예에 따른 서버 장치는 스토리지, 메모리, 프로세서, 및 통신 인터페이스 을 포함할 수 있다. 다만, 서버 장치의 구성 요소는 전술한 예에 한정되는 것은 아니고, 서버 장치 는 전술한 구성 요소들보다 더 많은 구성 요소를 포함하거나, 더 적은 구성 요소를 포함할 수도 있다. 일 실시예에 있어서, 스토리지, 메모리, 프로세서, 및 통신 인터페이스 중 적어도 일부는 하나의 칩 형태로 구현될 수도 있으며, 프로세서는 하나 이상의 프로세서를 포함할 수도 있다. 스토리지는 프로세서에 의해 사용되는 다양한 데이터의 원본 또는 백업본을 저장할 수 있다. 스토 리지는 서버 장치의 보조 기억 장치로 이용될 수 있다. 예를 들어, 스토리지는 하드 디스크 드라이브(hard disk drive; HDD) 또는 솔리드 스테이트 드라이브(solid state drive; SSD)로 구현될 수 있다. 도시된 바와 달리, 스토리지는 서버 장치 외부에 배치될 수 있다. 일 실시예에 있어서, 스토리지 는 합동 훈련된 추출기 모델, 디코더 모델, 심층 신경망 모델 데이터베이스(database; DB)를 포함 할 수 있다. 합동 훈련된 추출기 모델, 디코더 모델, 심층 신경망 모델 DB는 특정 애플리케이션에 대응하는 합 동 훈련된 추출기 모델, 디코더 모델, 심층 신경망 모델을 포함할 수 있다. 메모리는 다양한 프로그램이나 데이터를 저장하기 위한 구성으로서, 롬(ROM), 램(RAM), 하드디스크, CD- ROM 및 DVD 등과 같은 저장 매체 또는 저장 매체들의 조합으로 구성될 수 있다. 메모리는 별도로 존재하 지 않고 프로세서에 포함되도록 구성될 수도 있다. 메모리는 휘발성 메모리, 비휘발성 메모리 또는 휘발성 메모리와 비휘발성 메모리의 조합으로 구성될 수도 있다. 메모리에는 전술한 또는 후술할 실시예 들에 따른 동작들을 수행하기 위한 프로그램이 저장될 수 있다. 메모리는 프로세서의 요청에 따라 저장된 데이터(예컨대, 이미지, 영상, 오디오, 텍스트, 센서 값)를 프로세서에 제공할 수도 있다. 메모리는 추론 모듈을 포함할 수 있다. 추론 모듈은 디코더 모델을 이용하여 오프로딩된 데 이터를 디코딩하고, 디코딩된 데이터를 입력으로 하는 심층신경망 모델을 이용하여 오프로딩된 데이터에 대응하는 추론 데이터를 출력하는, 적어도 하나의 인스트럭션에 대응할 수 있다. 프로세서는 도 13 내지 18에서 설명된 실시예들에 따라 서버 장치가 동작하도록 일련의 과정을 제 어하는 구성으로서, 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래 픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 프로세서는 스토리지 또는 메모리에 데이터를 기록하거나, 스토리지또는 메모리(192 3)에 저장된 데이터를 읽을 수 있으며, 특히 스토리지 또는 메모리에 저장된 프로그램을 실행함으 로써 미리 정의된 동작 규칙 또는 인공지능 모델(예컨대, 디코더 모델 또는 심층신경망 모델)에 따라 데이터를 처리할 수 있다. 따라서, 프로세서는 상술한 실시예들에서 설명되는 동작들을 수행할 수 있으며, 상술한 실시예들에서 서버 장치가 수행한다고 설명되는 동작들은 특별한 설명이 없는 한 프로세서가 수행 하는 것으로 볼 수 있다. 예를 들어, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델(예컨대, 디코더 모델 또는 심층신경망 모델)의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 통신 인터페이스는 외부의 장치와 유선 또는 무선으로 신호(제어 명령 및 데이터 등)를 송수신하기 위한 구성으로서, 다양한 통신 프로토콜을 지원하는 통신 칩셋을 포함하도록 구성될 수 있다. 통신 인터페이스(192 6)는 외부로부터 신호를 수신하여 프로세서로 출력하거나, 프로세서로부터 출력된 신호를 외부로 전송할 수 있다. 예를 들어, 통신 인터페이스는 단말 장치로부터 잠재 표현 데이터를 수신할 수 있 다. 예를 들어, 통신 인터페이스는 추론 데이터를 단말 장치로 전송할 수 있다. 도 20은 일 실시 예에 따른 오프로딩된 데이터를 처리하는 방법을 보여주는 흐름도이다. 도 19를 참조하여, 오 프로딩된 데이터를 처리하는 방법(또는 오프로딩 시스템의 동작 방법)을 설명한다. 설명의 편의를 위해, 도 13 내지 18에서 설명한 내용과 중복되는 내용은 생략한다.도 20을 참조하면, 오프로딩된 데이터를 처리하는 방법은 단계 S2010 내지 S2080을 포함할 수 있다. 단계 S2010 내지 S2080은 단말 장치(또는 단말 장치의 프로세서) 및/또는 서버 장치(또는 서버 장치의 프로세서)에 의해 수행될 수 있다. 본 개시의 오프 로딩된 데이터를 처리하는 방법은 도 20에 도시된 바에 한정되지 않으며, 도 20에 도시된 단계 중 어느 하나를 생략할 수도 있고, 도 20에 도시되지 않은 단계를 더 포함할 수도 있다. 단계 S2010에서, 단말 장치는 애플리케이션 정보를 서버 장치에 전송할 수 있다. 서버 장치 는 애플리케이션 정보를 수신할 수 있다. 예를 들어, 애플리케이션 정보는 단말 장치에서 실행되는 애플 리케이션에 대한 정보를 포함할 수 있다. 예를 들어, 임의의 애플리케이션은, 합동 훈련된 추출기 모델, 디코더 모델, 및 심층신경망 모델에 대응할 수 있다. 단계 S2020에서, 서버 장치는 애플리케이션 정보에 대응하는 추출기 모델을 전송할 수 있다. 서버 장치 는 데이터베이스로부터 추출기 모델을 로드할 수 있다. 단계 S2030에서, 단말 장치는 원본 데이터에 대응하는 이미지를 획득할 수 있다. 단계 S2040에서, 단말 장치는 원본 데이터를 입력으로 하는 추출기 모델을 이용하여 잠재 표현 데이터를 생성할 수 있다. 단계 S2050에서, 단말 장치는 잠재 표현 데이터를 서버 장치로 오프로딩(또는 전송)할 수 있다. 서 버 장치는 오프로딩된 잠재 표현 데이터를 수신할 수 있다. 단계 S2060에서, 서버 장치는 디코더 모델을 이용하여, 오프로딩된 데이터를 디코딩할 수 있다. 서버 장 치는 데이터베이스로부터 디코더 모델을 로드할 수 있다. 단계 S2070에서, 서버 장치는 디코딩된 데이터를 입력으로 하는 심층신경망 모델을 이용하여, 추론 데이 터를 출력할 수 있다. 서버 장치는 데이터베이스로부터 심층신경망 모델을 로드할 수 있다. 단계 S2080에서, 서버 장치는 추론 데이터를 단말 장치로 전송할 수 있다. 단말 장치는 추론 데이터를 수신할 수 있다. 본 개시에서, 도 1 내지 도 12에서 설명된 인코더, 디코더, 심층신경망은 각각 도 13 내지 20에서 설명된 추출 기 모델, 디코더 모델, 심층신경망 모델에 대응할 수 있다.일 실시예에 따른 오프로딩된 데이터를 처리하는 방법은, 단말 장치로부터 오프로딩된 데이터를 수신하는 단계, 디코더 모델을 이용하여, 상기 오프로딩된 데이터를 디코딩하는 단계, 상기 디코딩된 데이터를 입력으로 하는 심층신경망 모델을 이용하여, 상기 오프로딩된 데이터에 대응하는 추론 데이터를 출력하는 단계를 포함할 수 있 다. 일 실시예에 따르면, 상기 오프로딩된 데이터는, 원본 데이터를 입력으로 하는 추출기 모델에 의해 생성된 잠재 표현(latent representation) 데이터를 포함할 수 있다. 일 실시예에 따르면, 상기 추출기 모델, 상기 디 코더 모델, 및 상기 심층신경망 모델은, 상기 심층신경망 모델의 손실 정보를 이용하여 합동 훈련(joint training)될 수 있다. 일 실시예에 따르면, 상기 추출기 모델과 디코더 모델은 오토인코더(autoencoder) 모델로 구현될 수 있다. 일 실시예에 따르면, 상기 잠재 표현 데이터의 크기는 미리 정의될 수 있다. 일 실시예에 따르면, 상기 디코딩하는 단계는, 상기 오프로딩된 데이터를 상기 심층신경망 모델의 입력 값의 형 태로 변형하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 디코더 모델은, 단일의 업샘플링 레이어 및 단일의 컨볼루셔널 레이어로 구성될 수 있다. 일 실시예에 따르면, 상기 심층신경망 모델은 제1 심층신경망 모델이고, 상기 추론 데이터는 제1 추론 데이터고, 상기 디코딩된 데이터를 입력으로 하는 제2 심층신경망 모델을 이용하여, 상기 오프로딩된 데이터에 대응하는 제2 추론 데이터를 출력하는 단계를 더 포함하되, 상기 추출기 모델, 상기 디코더 모델은, 상기 제1 심층신경망 모델의 손실 정보 및 상기 제2 심층신경망 모델의 손실 정보를 이용하여 합동 훈련될 수 있다. 일 실시예에 따르면, 상기 추출기 모델은, 지식 증류(knowledge distillation) 기법을 이용하여 학습될 수 있다. 일 실시예에 따르면, 상기 원본 데이터는, 상기 심층신경망 모델을 이용한 애플리케이션에 사용되는 이미지, 영 상, 오디오, 텍스트, 센서 값 중 적어도 하나의 데이터를 포함할 수 있다. 일 실시예에 따르면, 상기 심층신경망 모델은, 원본 데이터에 기초하여 이미지 분류(classification), 이미지 분할(segmentation), 이미지 캡셔닝(captioning) 객체 탐지(detection), 깊이 추정(depth estimation), 위치 추정(localization) 또는 자세 추정(pose estimation)을 수행하는 모델일 수 있다. 일 실시예에 따르면, 상기 단말 장치로, 상기 추론 데이터를 전송하는 단계를 더 포함할 수 있다. 일 실시예에 따른 오프로딩된 데이터를 처리하는 서버 장치는, 하나 이상의 인스트럭션을 저장하는 메모리, 및 상기 메모리에 저장된 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적 어도 하나의 프로세서는, 단말 장치로부터 오프로딩된 데이터를 수신하고, 디코더 모델을 이용하여, 상기 오프 로딩된 데이터를 디코딩하고, 상기 디코딩된 데이터를 입력으로 하는 심층신경망 모델을 이용하여, 상기 오프로 딩된 데이터에 대응하는 추론 데이터를 출력하는, 상기 하나 이상의 인스트럭션을 실행할 수 있다. 일 실시예에 따르면, 상기 오프로딩된 데이터는, 원본 데이터를 입력으로 하는 추출기 모델에 의해 생성된 잠재 표현(latent representation) 데이터를 포함할 수 있다. 일 실시예에 따르면, 상기 추출기 모델, 상기 디코더 모델, 및 상기 심층신경망 모델은, 상기 심층신경망 모델의 손실 정보를 이용하여 합동 훈련(joint training)될 수 있다. 일 실시예에 따른 오프로딩 시스템은, 단말 장치, 및 서버 장치를 포함할 수 있다. 상기 단말 장치는, 원본 데 이터에 대응하는 이미지를 획득하는 카메라, 하나 이상의 인스트럭션을 저장하는 제1 메모리, 및 상기 제1 메모 리에 저장된 하나 이상의 인스트럭션을 실행하는 적어도 하나의 제1 프로세서를 포함할 수 있다. 상기 적어도 하나의 제1 프로세서는, 상기 원본 데이터를 입력으로 하는 추출기 모델을 이용하여 잠재 표현(latent representation) 데이터를 생성하고, 상기 잠재 표현 데이터를 상기 서버 장치로 오프로딩하는, 상기 하나 이상 의 인스트럭션을 실행할 수 있다. 상기 서버 장치는, 하나 이상의 인스트럭션을 저장하는 제2 메모리, 및 상기 제2 메모리에 저장된 하나 이상의 인스트럭션을 실행하는 적어도 하나의 제2 프로세서를 포함할 수 있다. 상기 적어도 하나의 제2 프로세서는, 상기 단말 장치로부터 상기 오프로딩된 데이터를 수신하고, 디코더 모델을 이용 하여, 상기 오프로딩된 데이터를 디코딩하고, 상기 디코딩된 데이터를 입력으로 하는 심층신경망 모델을 이용하 여, 상기 오프로딩된 데이터에 대응하는 추론 데이터를 출력하는, 상기 하나 이상의 인스트럭션을 실행할 수 있 다. 일 실시예에 따르면, 상기 오프로딩된 데이터는, 원본 데이터를 입력으로 하는 추출기 모델에 의해 생성된 잠재 표현(latent representation) 데이터를 포함할 수 있다. 일 실시예에 따르면, 상기 추출기 모델, 상기 디 코더 모델, 및 상기 심층신경망 모델은, 상기 심층신경망 모델의 손실 정보를 이용하여 합동 훈련(jointtraining)될 수 있다. 일 실시 예에 있어서, 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하 지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저 장되는 경우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시 예에 있어서, 본 명세서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래 될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD- ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간 에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품 (예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중 계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있 다. 이상의 설명은 본 개시의 기술사상을 예시적으로 설명한 것에 불과한 것으로서, 본 개시가 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 개시의 본질적인 특성에서 벗어나지 않는 범위 내에서 여러 가지 치환, 변형 및 변경 등이 가능함을 쉽게 알 수 있을 것이다. 즉, 본 개시에 개시된 실시 예들은 본 개시의 기술 사상을 한 정하기 위한 것이 아니라 설명하기 위한 것으로서, 이러한 실시 예에 의하여 본 개시의 기술 사상의 범위가 한 정되는 것은 아니다. 따라서, 본 개시의 보호 범위는 후술되는 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모 든 기술사상은 본 개시의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0154653", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 복원했을 시 사람 눈으로 보기에 차이가 없도록 압축이 되는 경우를 설명하기 위한 개념도이다. 도 2는 심층신경망을 돌려서 결과를 알고 싶은 부분만 잘라내어 압축하는 방식을 설명하기 위한 개념도이다. 도 3은 심층신경망에 필수적인 정보만을 추출하여 압축 및 전송하는 것을 설명하기 위한 개념도이다. 도 4는 심층신경망별로 필요로 하는 정보가 다름을 설명하기 위한 예시도이다. 도 5는 심층신경망별로 필요로 하는 정보가 다름을 설명하기 위한 예시도이다. 도 6은 기존의 심층신경망 기반의 압축 기법을 설명하기 위한 구성도이다. 도 7은 일 실시예에 따른 심층신경망 기반의 압축 기법을 설명하기 위한 구성도이다. 도 8은 일 실시예에 따른 심층신경망 기반의 압축 기법을 설명하기 위한 구성도이다. 도 9는 도 8의 입력 구조 변형부가 업샘플링 형태로 구현될 수 있음을 보여주는 구성도이다. 도 10은 일 실시예에 따른 컨볼루셔널 레이어(convolutional layer)의 계층 구조도이다. 도 11은 일 실시예에 따른 트랜스포즈 컨볼루셔널 레이어(Transposed convolutional layer)의 계층 구조도이다. 도 12는 일 실시예에 따른 데이터 압축 방법을 적용시킬 수 있는 계통도이다. 도 13은 일 실시 예에 따른 오프로딩 시스템을 보여주는 블록도이다. 도 14는 일 실시 예에 따른 학습 서버 장치를 보여주는 블록도이다. 도 15는 일 실시 예에 따른 오프로딩 시스템을 보여주는 블록도이다. 도 16은 일 실시 예에 따른 학습 서버 장치를 보여주는 블록도이다. 도 17은 일 실시 예에 따른 추출기 모델 및 디코더 모델을 좀 더 상세하게 보여주는 블록도이다. 도 18은 일 실시 예에 따른 추출기 모델 및 디코더 모델을 좀 더 상세하게 보여주는 블록도이다. 도 19는 일 실시 예에 따른 오프로딩 시스템을 보여주는 블록도이다. 도 20은 일 실시 예에 따른 오프로딩된 데이터를 처리하는 방법을 보여주는 흐름도이다."}
