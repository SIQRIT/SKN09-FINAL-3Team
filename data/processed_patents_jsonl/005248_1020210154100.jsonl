{"patent_id": "10-2021-0154100", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0068115", "출원번호": "10-2021-0154100", "발명의 명칭": "자동차 번호판 인식 장치", "출원인": "주식회사 케이티", "발명자": "이윤정"}}
{"patent_id": "10-2021-0154100", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수개의 자동차 번호판 이미지 프레임들을 입력받고, 입력받은 이미지 프레임들로부터 번호판 영역들을 추출하며, 추출한 번호판 영역에서 사전 정의된 기준에 의해 블러가 적게 발생한 임계 개수의 이미지 프레임들을 선정하는 전처리부, 상기 선정한 이미지 프레임들로부터 특징맵들을 각각 추출하고, 추출한 각각의 특징맵들을 하나의 특징맵으로압축하고, 압축된 특징맵으로부터 이미지 프레임을 복원하는 추론부, 그리고 딥러닝 기반의 문자 인식 기술(Optimal Character Recognition, OCR)을 이용하여 복원한 이미지 프레임으로부터자동차 번호판을 판독하는 인식부를 포함하는, 자동차 번호판 인식 장치."}
{"patent_id": "10-2021-0154100", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에서,상기 추론부가 복원한 이미지 프레임을 구성하는 픽셀 별로 문자 또는 배경으로 분류를 수행하고, 분류에 따른이미지 프레임을 생성하며, 상기 복원한 이미지 프레임과 상기 분류에 따라 생성한 이미지 프레임에 대해 픽셀별로 손실을 계산하는 학습부를 더 포함하고,상기 학습부는, 상기 손실을 상기 학습부의 학습에 사용하고 상기 추론부에 제공하는, 자동차 번호판 인식 장치."}
{"patent_id": "10-2021-0154100", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에서,상기 전처리부는, 상기 선정한 이미지 프레임들에 대해 정렬을 수행하고, 정렬된 이미지 프레임들을 상기 추론부로 출력하는, 자동차 번호판 인식 장치."}
{"patent_id": "10-2021-0154100", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에서,상기 전처리부는, 사전 학습된 블러 강도 측정 모델을 토대로, 상기 추출한 번호판 영역 별로 블러 정도에 따른 클래스를 분류하고, 분류된 클래스에 매칭되는 환산 점수를 부여하여 각 번호판 영역 별로 블러 지수를 산출하며, 각 클래스 별로 해당하는 번호판 영역의 개수와 상기 환산 점수를 토대로, 전체 번호판 영역에 대한 최종 블러 점수를 계산하고, 계산된 최종 블러 점수를 토대로, 상기 임계 개수의 이미지 프레임들을 선정하는, 자동차 번호판 인식 장치."}
{"patent_id": "10-2021-0154100", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에서,상기 추론부는,최대-디블러드 풀링(Max-deblurred pooling)을 통해 블러가 적은 특징들을 추출하는, 자동차 번호판 인식 장치."}
{"patent_id": "10-2021-0154100", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "자동차 번호판 인식 장치가 개시된다. 이 장치는 복수개의 자동차 번호판 이미지 프레임들을 입력받고, 입력받은 이미지 프레임들로부터 번호판 영역들을 추출하며, 추출한 번호판 영역에서 사전 정의된 기준에 의해 블러가 적 게 발생한 임계 개수의 이미지 프레임들을 선정하는 전처리부, 상기 선정한 이미지 프레임들로부터 특징맵들을 각각 추출하고, 추출한 각각의 특징맵들을 하나의 특징맵으로 압축하고, 압축된 특징맵으로부터 이미지 프레임을 복원하는 추론부, 그리고 딥러닝 기반의 문자 인식 기술(Optimal Character Recognition, OCR)을 이용하여 복원 한 이미지 프레임으로부터 자동차 번호판을 판독하는 인식부를 포함한다."}
{"patent_id": "10-2021-0154100", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 자동차 번호판 인식 장치에 관한 것이다."}
{"patent_id": "10-2021-0154100", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재, 통상적으로 사용되는 자동차 번호판 인식 기술에 따르면, 차량 촬영, 번호판 영역 추출, 전처리, 번호판 인식, 최종 결과의 과정으로 구성된다. 번호판 영역 추출 과정의 경우, 차량을 촬영한 동영상에서 분석할 이미지 한 장을 선택 후, 선택 이미지 내에서 번호판 영역을 추출한다. 전처리 과정의 경우, 밝기(brightness) & 대비(contrast) 조정, 잡음 제거, 기울기 보 정 등을 수행한다. 번호판 인식 과정의 경우, 딥러닝 기반의 문자 인식 기술(Optimal Character Recognition, OCR)을 사용하여 문자를 인식할 수 있다. FHD(Full High Definition) 화질 및 초당 프레임 수(Frames Per Second, 이하, 'FPS'라 통칭함)가 100을 초과 하는 높은 FPS를 지원하는 고성능 CCTV(Closed-circuit Television)에서는 종래의 자동차 번호판 인식 기술을 사용할 수 있다. 그러나, 높은 FPS 제공이 불가능한 HD(High Definition) 화질 CCTV(closed circuit television)에 대해 문자 인식을 할 경우 다음과 같은 상황으로 인한 한계점을 갖는다. 첫째로, 차량의 빠른 움직임으로 인해 특정 방향 으로 숫자가 번져(Motion blurring), 올바른 인식이 불가능하다. 둘째로, 카메라 자체의 낮은 화질로 인해 번호 판 내 특정 구역에서 계단 현상(Defocusing)이 발생하여 문자 인식이 어렵다. 또한, 종래의 차량 번호판 인식 기술은 단일 이미지 프레임을 사용하여 문자 인식을 진행하므로, 단일 이미지 프레임에 대한 의존도가 높아진다. 또한, 종래의 차량 번호판 인식 기술은 문자 단위의 예측에 딥러닝을 활용하 는데, 저화질 영상에 서 발생하는 디포커스 블러링(defocusing blurring), 물체가 빠르게 움직일 경우 발생한 모션 블러링(motion blurring)에 대한 처리를 학습 DB에 의존하므로, 한계가 있다."}
{"patent_id": "10-2021-0154100", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "해결하고자 하는 과제는 다수의 프레임을 사용하여 새로운 자동차 번호판 이미지를 생성하고, 생성한 자동차 번 호판 이미지에 OCR(Optimal Character Recognition)을 수행하여 자동차 번호판을 인식함으로써, 저화질 영상에 서도 번호판 인식이 가능한 장치를 제공하는 것이다."}
{"patent_id": "10-2021-0154100", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "한 특징에 따르면, 자동차 번호판 인식 장치는 복수개의 자동차 번호판 이미지 프레임들을 입력받고, 입력받은 이미지 프레임들로부터 번호판 영역들을 추출하며, 추출한 번호판 영역에서 사전 정의된 기준에 의해 블러가 적 게 발생한 임계 개수의 이미지 프레임들을 선정하는 전처리부, 상기 선정한 이미지 프레임들로부터 특징맵들을 각각 추출하고, 추출한 각각의 특징맵들을 하나의 특징맵으로 압축하고, 압축된 특징맵으로부터 이미지 프레임 을 복원하는 추론부, 그리고 딥러닝 기반의 문자 인식 기술(Optimal Character Recognition, OCR)을 이용하여 복원한 이미지 프레임으로부터 자동차 번호판을 판독하는 인식부를 포함한다. 상기 자동차 번호판 인식 장치는 상기 추론부가 복원한 이미지 프레임을 구성하는 픽셀 별로 문자 또는 배경으 로 분류를 수행하고, 분류에 따른 이미지 프레임을 생성하며, 상기 복원한 이미지 프레임과 상기 분류에 따라 생성한 이미지 프레임에 대해 픽셀 별로 손실을 계산하는 학습부를 더 포함하고, 상기 학습부는, 상기 손실을 상기 학습부의 학습에 사용하고 상기 추론부에 제공할 수 있다. 상기 전처리부는, 상기 선정한 이미지 프레임들에 대해 정렬을 수행하고, 정렬된 이미지 프레임들을 상기 추론 부로 출력할 수 있다. 상기 전처리부는, 사전 학습된 블러 강도 측정 모델을 토대로, 상기 추출한 번호판 영역 별로 블러 정도에 따른 클래스를 분류하고, 분류된 클래스에 매칭되는 환산 점수를 부여하여 각 번호판 영역 별로 블러 지수를 산출하 며, 각 클래스 별로 해당하는 번호판 영역의 개수와 상기 환산 점수를 토대로, 전체 번호판 영역에 대한 최종 블러 점수를 계산하고, 계산된 최종 블러 점수를 토대로, 상기 임계 개수의 이미지 프레임들을 선정할 수 있다.상기 추론부는, 최대-디블러드 풀링(Max-deblurred pooling)을 통해 블러가 적은 특징들을 추출할 수 있다."}
{"patent_id": "10-2021-0154100", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예에 따르면, 다수의 프레임을 사용하여 새로운 자동차 번호판 이미지를 생성하고, 생성한 자동차 번호판 이미지에 OCR을 수행하여 자동차 번호판을 인식함으로써, 모션 블러링(motion blurring) 및 디포커스 블러링 (defocusing blurring) 문제를 해결할 수 있다. 따라서, 저화질 영상 뿐만 아니라 블러링이 발생한 영상에서도 자동차 번호판을 인식할 수 있다. 또한, 원본 입력 영상의 길이에 제한이 없어 양질의 입력 영상들을 인식을 위해 사용할 수 있다. 또한, 딥러닝을 문자 단위의 인식이 아니라 픽셀 단위로 인식 단위를 낮추어 문자 영역내 일부 구역만 블러로 손상 되었다면, 손상되지 않은 영역을 활용할 수 있고, 이를 통해 인식을 위한 새로운 번호판을 생성하여 인식 을 위한 양질의 번호판 인식 결과를 제공할 수 있다."}
{"patent_id": "10-2021-0154100", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였 다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재된 \"…부\", \"…기\", \"…모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 본 발명에서 설명하는 장치들은 적어도 하나의 프로세서, 메모리 장치, 통신 장치 등을 포함하는 하드웨어로 구 성되고, 지정된 장소에 하드웨어와 결합되어 실행되는 프로그램이 저장된다. 하드웨어는 본 발명의 방법을 실행 할 수 있는 구성과 성능을 가진다. 프로그램은 도면들을 참고로 설명한 본 발명의 동작 방법을 구현한 명령어 (instructions)를 포함하고, 프로세서와 메모리 장치 등의 하드웨어와 결합하여 본 발명을 실행한다. 본 명세서에서 \"전송 또는 제공\"은 직접적인 전송 또는 제공하는 것 뿐만 아니라 다른 장치를 통해 또는 우회 경로를 이용하여 간접적으로 전송 또는 제공도 포함할 수 있다. 본 명세서에서 단수로 기재된 표현은 \"하나\" 또는 \"단일\" 등의 명시적인 표현을 사용하지 않은 이상, 단수 또는 복수로 해석될 수 있다. 본 명세서에서 도면에 관계없이 동일한 도면번호는 동일한 구성요소를 지칭하며, \"및/또는\" 은 언급된 구성 요 소들의 각각 및 하나 이상의 모든 조합을 포함한다. 본 명세서에서, 제1, 제2 등과 같이 서수를 포함하는 용어들은 다양한 구성요소들을 설명하는데 사용될 수 있지 만, 상기 구성요소들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요 소로부터 구별하는 목적으로만 사용된다. 예를들어, 본 개시의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 본 명세서에서 도면을 참고하여 설명한 흐름도에서, 동작 순서는 변경될 수 있고, 여러 동작들이 병합되거나, 어느 동작이 분할될 수 있고, 특정 동작은 수행되지 않을 수 있다. 도 1은 실시예에 따른 자동차 번호판 인식 장치의 구성을 나타낸 블록도이고, 도 2는 실시예에 따른 블러 지수 계산을 위한 학습 데이터 생성 과정을 나타낸 예시도이며, 도 3은 실시예에 따른 블러 지수맵 산출 예시도이고, 도 4는 실시예에 따른 이미지 프레임에 대한 정렬(Alignment)을 설명하는 예시도이고, 도 5는 실시예에 따른 최 대-디블러드 필터(max-deblurred filter)의 동작을 설명하는 도면이고, 도 6은 실시예에 따른 복수 이미지로부 터 특징을 추출하여 압축 및 복원하는 내용을 설명하는 예시도이고, 도 7은 실시예에 따른 학습부의 동작을 설 명하는 예시도이다. 도 1을 참조하면, 자동차 번호판 인식 장치는 전처리부, 추론부, 인식부 및 학습부를 포함하고, 추론부는 특징 추출부, 시간 도메인 압축부 및 복원부를 포함한다. 자동차 번호판 인식 장치는 메모리 및 적어도 하나의 프로세서를 포함하는 컴퓨팅 장치로 구현된다. 프로 세서는 메모리에 로드된 프로그램의 명령(Instruction)을 실행하여, 전처리부, 추론부, 인식부 및 학습부로서 동작할 수 있다. 전처리부는 불특정 길이의 입력 이미지 프레임들로부터 이미 알려진 딥러닝 기반의 문자 인식 기술 (Optimal Character Recognition, 이하, 'OCR'로 통칭하여 기재함)을 이용하여 번호판 영역을 추출한다. 이때, 이미 알려진 딥러닝 기술은 YOLO(You Only Look Once), CNN(Convolutional Neural Network) 등이 활용될 수 있 다. 전처리부는 추출한 번호판 영역들 중에서 블러(blur)가 적게 발생한 상위 10개의 이미지 프레임들을 선정 하고, 선정한 이미지 프레임들을 대상으로 정렬(alignment) 과정을 수행한다. 정렬된 10장의 이미지 프레임들은 복원부의 입력 영상으로 사용된다. 구체적으로, 전처리부는 일련의 입력 이미지 프레임들(f1~ft), 예컨대, t 시간 동안 각각 생성된 이미지 프 레임들(f1~ft)로부터 자동차 번호판 영역을 추출한다. 여기서, 입력 이미지 프레임들은 차량 번호판을 촬영하여 획득된다. 전처리부는 추출한 자동차 번호판 영역에서 블러(blur) 지수를 산출하기 위해 학습된 인공지능 네트워크 또는 인공지능 모델(Artificial Intelligence Model, 이하, AI 모델로 통칭하여 기재함)을 사용하여 블러 (blur) 지수를 계산한다. 이때, AI 모델은 자동차 번호판 영역을 소분한 구역내에서 블러(blur) 지수를 산출하 도록 학습된다. AI 모델의 입력은 문자가 포함된 단일 이미지 프레임이고, AI 모델의 출력은 각 소분한 구역에 대한 블러(blur) 지수를 5개의 클래스로 분류한 결과이다. 전처리부는 블러(Blur) 지수를 계산하기 위해 AI 모델을 학습시키기 위한 학습 데이터를 구성한다. 학습 데이터를 구성하는 과정은 다음과 같다. 먼저, 블러(Blur) 지수 산출을 위한 데이터 생성 과정으로서, 전처리부는 도 2의 (A)와 같이 사용할 글자 또는 숫자(예, 5)를 정해진 크기, 예컨대, 60pixel×90pixel 크기의 이미지로 변환한다. 전처리부는 변환된 이미지에 블러(blur) 효과를 줄 수 있는 필터를 적용한다. 예를들어, 가우시안 필터를 사용할 경우, θ값을 5단계(1~5)로 다르게 설정하고, 이러한 값을 변환된 이미지에 적용하여 도 2의 (B)와 같이 하나의 문자에 대해 블러(Blur)된 여러 이미지들을 획득한다. 전처리부는 블러(Blur)된 이미지를 10pixel×10pixel 크기를 가지는 복수개의 영역으로 소분한다. 도 2의 (C)를 참고하면, 60pixel ×90pixel 크기의 문자 이미지는 54(=6×9)개의 영역으로 소분된다. 전처리부는 도 2의 (D)와 같이 적용 필터의 세기(가우시안의 경우 θ)의 순서대로 소분된 영역의 클래스를 설정한다. 클래스 값이 클수록 블러(blur)가 많이 발생한 이미지이고, 클래스 값이 작을수록 블러(blur)가 적게 발생한 이미지이다. 따라서, 만약 가우시안 필터로 학습 데이터를 구성할 경우, 강한 블러(blur) 필터(θ=4)를적용한 이미지는 5번 클래스, 즉, 예측 목표값=5에 속하고, 약한 블러(blur) 필터(θ=0)를 적용한 이미지 일 경 우 1번 클래스 즉, 예측 목표값=1에 속한다. 전술한 과정을 통해 생성된 학습 데이터를 사용하여, 전처리부는 블러(blur) 정도에 따라 이미지의 클래스 를 구분하도록 AI 모델을 학습시킬 수 있다. 이때, AI 모델은 인공신경망 혹은 CNN등이 사용될 수 있다. AI 모 델은 10×10사이즈의 이미지를 입력 영상으로 가지며, 입력 영상의 블러(blur) 정도를 1~5의 클래스로 분류하도 록 학습될 수 있다. 따라서, 이러한 AI 모델을 블러 강도 측정 모델로 호칭할 수 있다. 전처리부는 입력 영상으로부터 추출한 번호판들에 대해 상기한 바와 같이 소분 작업후 도 3의 과정을 수행 하여 블러(blur) 점수를 계산하고, 전체 입력 영상 N개 중 상위 블러(blur) 점수가 낮은 M개의 이미지를 선정할 수 있다. 전처리부가 처리하고자 하는 동영상의 길이, 예를들어, 1초, 3초 등..에 따라 프레임 개수 N은 달라 질 수 있다. 전처리부는 불특정한 프레임 개수 N으로부터 양질의 고정 프레임 개수를 추출할 수 있다. 도 3을 참조하면, 전처리부는 입력 이미지들로부터 추출한 여러 번호판 이미지 중에서 임의로 선택한 하나 의 번호판 이미지(P1)를 소분한다. 전처리부는 소분된 개별 영역에 대해 앞서 학습된 인공지능 네트워크, 즉, 블러 강도 측정 모델을 통해 블 러(blur) 지수를 추출하고, 추출한 블러 지수를 토대로 블러(blur) 지수맵(P3)을 생성한다. 이때, 블러 지수맵(P3)에서 선명한 영역, 즉, 번짐이 적은 영역은 블러 지수가 낮다. 블러 지수맵(P3)에서 뭉개 진 영역, 즉, 번짐이 많은 영역은 블러 지수가 높다. 또한, 블러 지수맵(P3)에서 뭉개진 영역에 가까운 영역 일 수록 상대적으로 블러 지수가 높다. 전처리부는 블러(blur) 지수의 1~5 클래스 각각에 [0.1, 0.3, 0.4, 0.6, 0,7]를 할당한다. 즉, 1 클래스 에 0.1의 값을 할당하고, 2 클래스에 0.3의 값을 할당할 수 있다. 이러한 방식으로 할당된 값들을 합산하여 하 나의 번호판 이미지 프레임에 대한 최종 블러(blur) 점수를 계산한다. 예시로, 도 3의 블러 지수맵에서 1~5번 클래스에 속하는 영역의 개수가 각각 [4,28,39,56,335]이면, 최종 블러(blur) 점수는 수학식 1을 통해 수학식 2 와 같이 계산된다. [수학식 1]"}
{"patent_id": "10-2021-0154100", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, n은 클래스 넘버를 의미한다. 은 각 클래스에 속하는 영역의 개수를 의미한다. 은 각 클래스에 할당된 값을 의미한다. 앞서 기재한 바와 같이, 1~5개의 클래스 넘버(n), 은 [0.1, 0.3, 0.4, 0.6, 0,7]이고, 은 [4,28,39,56,335]를 수학식 1에 적용하면, 최종 블러 점수는 수학식 2와 같이 계산된다. [수학식 2]"}
{"patent_id": "10-2021-0154100", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이러한 방식으로, 전처리부는 t개의 이미지 프레임에 대해서 각각의 최종 블러(blur) 점수를 계산한다. 전 처리부는 블러 점수들중에서 가장 점수가 낮은 순서대로, 임계 개수, 예컨대, 10개의 이미지 프레임을 선 정할 수 있다. 이러한 10개의 이미지 프레임은 학습부의 학습 데이터로 사용된다. 전처리부는 선정한 임계 개수의 이미지 프레임들에 대해 정렬(Alignment)을 수행한다. 도 4의 (A)를 참조 하면, 입력되는 자동차 번호판 이미지의 각도가 틀어져 있기 때문에 이에 대한 정렬이 필요할 수 있다. 한 실시예에 따르면, 전처리부는 도 4의 (A)에서 인식한 자동차 번호판의 4개의 꼭지점에 대해서 타겟 목 표로 원근 변환(Perspective transform)과 같은 변환을 통해 도 4의 (B)와 같이 정렬을 진행할 수 있다. 추론부는 전처리부에서 입력받은 임계 개수, 예컨대, 10장의 이미지 프레임들을 토대로, 하나의 신규 이미지 프레임을 생성한다. 추론부는 전처리부가 선정한 이미지 프레임들로부터 특징맵들을 각각 추출하고, 추출한 각각의 특징 맵들을 하나의 특징맵으로 압축하여, 압축된 특징맵으로부터 이미지 프레임을 복원할 수 있다.추론부는 특징 추출부, 압축부 및 복원부로 구성된다. 특징 추출부는 일련의 자동차 번호판 이미지들에 딥러닝 모델을 적용하여 특징배열들을 추출하고, 압축부에서는 추출한 특징 배열들 합 쳐 하나의 특징 배열로 생성한다. 복원부는 하나의 특징 배열로부터 신규 자동차 번호판 이미지를 복원한 다. 특징 추출부는 입력받은 이미지 프레임에 도 5와 같이 컨벌루션 필터(convolution filter) 및 맥스 풀링 (max pooling) 과정을 반복하여 특징을 추출한다. 여기서, 컨벌루션 필터(convolution filter)를 적용하여 특징을 추출하는 방법은 통상적인 방법, 즉 공지된 방 법을 활용할 수 있다. 맥스 풀링(Max pooling) 방법은 필터내 픽셀의 최댓값을 대푯값으로 하여 차원 축소하는 방법이며, 필터내 의미 있는 특징을 추출해내는 방법이다. 하지만, 블러(blur)가 발생한 영상에서 단순히 픽셀의 값의 큰 것이 의미있 는 값이라고 볼 수 없다. 따라서, 실시예에 따르면, 풀링(pooling)시 영상에서 의미있는 특징값들을 추출하기 위해 기존의 맥스 풀링(Max pooling) 방법을 보정한 맥스 디블러드 필터(max-deblurred filter)를 사용할 수 있다. 3×3 필터 스트라이드(Stride) 1을 가진 맥스 디블러드(Max-deblurred) 풀링을 통해 도 5의 (A)는 도 5의 (B) 와 같이 변환된다. 특징 추출부는 영상내 블러가 적은 특징을 추출하기 위해 기존의 맥스 풀링에서 단순 최댓값을 고르는 대신 블러(blur) 지수맵을 함께 활용하여 맥스 디블러드 풀링(max-deblurred pooling)을 진행 한다. 맥스 풀링(Max pooling)이 3×3 컨벌루션(convolution)으로 픽터내 픽셀의 최댓값을 뽑는 것과 다르게, 맥스 디 블러드 풀링(max-deblurred pooling)은 필터 내에서 픽셀값을 0 혹은 255와 가까운 정도를 측정하기 위해 값을 보정하고 해당 픽셀의 블러(blur) 지수의 역수를 가중치로 곱하여 최종적인 값을 추출하는 필터이다. 이에 따른 동작은 수학식 3과 같이 표현될 수 있다. [수학식 3]"}
{"patent_id": "10-2021-0154100", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, xi, yj는 픽셀 좌표값을 의미하고, w는 가중치를 의미한다. 도 5의 (A)를 참조하면, 각 픽셀값들에 대해 수학식 3을 통해 맥스 디블러드 풀링 연산을 통해 연산값을 도출한 다. 예를들어, 137을 기준으로 주위 픽셀들, 즉, '99, 100, 7, 144, 137, 8, 154, 128, 11'과 같이 9개 픽셀값 들을 대상으로 수학식 3을 통해 도출한 연산값들을 나열하면 도 5B와 같다. 맥스 디블러드(max-deblurred) 연산 과정 중에서 도 5의 (A)의 픽셀값 '8'은 '255-8=247'로 계산후 '247×1=247'로 계산된다. 도 5의 (B)를 참조하면, 특징 추출부는 연산값들 중에서 연산값이 제일 높은 '247'을 선택한다. 수학식 3 을 적용했을 때, 가장 높은 연산값은 가장 블러링이 적게된 픽셀을 의미하고, 결국, 블러링이 적게된 선명도가 높은 픽셀을 의미한다. 특징 추출부는 픽셀 137을 연산값이 가장 높은 247의 복원된 픽셀값인 8로 대체한다. 즉, 도 5의 (C)를 참 조하면 해당 픽셀의 맥스 디블러드 필터(max-deblurred filter)를 통한 값은 247의 원래값인 8이 된다. 이 와 같이, 픽셀들 별로 맥스 디블러드 필터(max-deblurred filter)를 통해 도출한 연산값들 중에서 가장 높은 연 산값에 대응하는 블러링이 적게된 선명도가 높은 픽셀로 대체함으로써, 선명도를 개선할 수 있다. 도 6의 (A)를 참조하면, 특징 추출부는 전처리부로터 추출한 w×h×t×k개의 특징들을 일렬로 재배열 한다. 이미지 프레임의 블러(Blur) 정도를 측정한 특징 추출부의 입력은 전처리부에서 얻은 일련의 영상들이므로, 단일 영상에서 딥러닝을 통해 w×h×k개 특징들을 추출했었다면, 이를 t개의 프레임에 적용했으 므로 w×h×t×k개의 특징들이 추출된다. 여기서, t는 프레임 개수를 의미하며, 전처리부에서 블러 점수를 기반으로 선정한 10개의 이미지다. 예를 들어, 하나의 입력 이미지의 크기가 N×M일 경우, 이에 대해 맥스 디블 러드 풀링(max-deblurred pooling) 및 컨벌루션(convolution)을 사용해 w×h×k개의 특징을 얻었다면, t 개의프레임을 사용 할 경우 w×h×t×k개의 특징을 얻을 수 있다. 압축부는 시간 도메인에서의 압축을 담당하며, 압축 과정을 통해 도 6의 (B)와 같이 촬영 시각이 다른 t개 의 프레임들로부터 추출한 w×h×t×k개의 특징들을 w×h개로 압축할 수 있다. 시간 도메인에서의 압축 방법으 로 1×1 convolution를 사용하였고, 2번의 압축을 진행할 수 있다. 도 6의 (B)를 참조하면, 압축부는 길이 가 t×k인 1×1 컨볼루션(convolution) 필터를 N개 사용하여 w×h×t×k 개의 특징들을 w×h×n 개로 압축한다. 압축부는 w×h×n 특징들에 길이가 N인 1×1 컨볼루션 필터를 1개 사용하여 w×h로 압축 할 수 있다. 도 6의 (C)를 참조하면, 복원부는 추출한 특징들(w×h)로부터 영상을 복원한다. 맥스 디블러드 풀링(Max- deblurred pooling) 및 컨벌루션(convolution) 필터를 적용하면, 원본 영상내 이미지내 특징들을 추출하며, 이 미지 크기가 줄어들게 된다. 복원부는 줄어든 특징맵 크기를 원본 영상 크기로 복원한다. 추출된 특징맵 크기를 원본과 같은 사이즈로 키우기 위한 방법으로 언풀링(unPoolling) 또는 디컨볼루션(deconvolution)을 사 용할 수 있다. 디컨볼루션(deconvolution)은 통상적인 방법과 같으며, 언풀링(unPoolling)시, 맥스 디블러드 풀 링(max-deblurred pooling)을 통해 추출했던 최대값 인덱스(index)들을 활용하여 복원할 수 있다. 인식부는 복원된 새로운 이미지 프레임에 대해 OCR을 수행하고 최종 인식 결과를 출력한다. 학습부는 추론부가 복원한 이미지 프레임을 구성하는 픽셀 별로 문자 또는 배경으로 분류를 수행하고, 분류에 따른 이미지 프레임을 생성한다. 학습부는 추론부에 의해 복원된 이미지 프레임, 그리고 분류에 따라 생성한 이미지 프레임에 대해 픽셀 별로 손실을 계산할 수 있다. 학습부는 특징 추출부, 압축부가 출력하는 원본 이미지 크기와 동일한 특징맵에 분류 (classfication)를 통해 픽셀별 문자, 배경을 추출한다. 즉, 도 7과 같이, 번호판 이미지에 대해 추론부를 거쳐 학습부를 통과하면, 픽셀별로 문자와 배경을 추출한 이미지를 획득할 수 있다. 학습부는 입력받 은 번호판 이미지와 추출한 번호판 이미지 간에 픽셀별로 손실(Loss)을 계산하고, 이러한 손실을 각각 추론부 와 학습부에 가중치로 업데이트할 수 있다. 손실은 추론부 중에서도 특징 추출부와 복원부 에서 사용될 수 있다. 손실은 복원부의 분류(Classfication)를 위한 가중치(weight)값을 업데이트하 는데 사용될 수 있다."}
{"patent_id": "10-2021-0154100", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 5, "content": "도 8은 실시예에 따른 자동차 번호판 인식 방법을 나타낸 순서도로서, 학습부를 제외한 전처리부, 추 론부 및 인식부의 일련의 동작을 나타낸다. 도 8을 참조하면, 전처리부는 t개의 이미지 프레임을 수집(S101)하고, 딥러닝 기반의 OCR 기술을 이용하여 번호판 영역을 추출한다(S102). 전처리부는 추출한 번호판 영역에 대해 블러 점수를 계산(S103)하고, 블러 점수가 낮은 순서대로 상위 n개 의 이미지 프레임을 선정한다(S104). 전처리부는 선정한 상위 n개의 이미지 프레임들에 대해 정렬을 수행한다(S105). 추론부의 특징 추출부는 정렬한 이미지 프레임들로부터 특징맵들을 추출한다(S106). 추론부의 압축부는 추출한 특징맵들을 하나의 특징맵으로 압축(S107)한다. 추론부의 복원부는 압축된 특징맵을 원본 영상 크기로 복원하여 하나의 이미지 프레임을 생성한다 (S108). 인식부는 S108에서 생성한 이미지 프레임으로부터 딥러닝 기반의 OCR 기술을 적용하여 번호판을 인식한다 (S109). 이상에서 설명한 본 발명의 실시예는 장치 및 방법을 통해서만 구현이 되는 것은 아니며, 본 발명의 실시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2021-0154100", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 자동차 번호판 인식 장치의 구성을 나타낸 블록도이다. 도 2는 실시예에 따른 블러 지수 계산을 위한 학습 데이터 생성 과정을 나타낸 예시도이다. 도 3은 실시예에 따른 블러 지수맵 산출 예시도이다. 도 4는 실시예에 따른 이미지 프레임에 대한 정렬(Alignment)을 설명하는 예시도이다. 도 5는 실시예에 따른 최대-디블러드 필터(max-deblurred filter)의 동작을 설명하는 도면이다. 도 6은 실시예에 따른 복수 이미지로부터 특징을 추출, 압축 및 복원하는 내용을 설명하는 예시도이다. 도 7은 실시예에 따른 학습부의 동작을 설명하는 예시도이다. 도 8은 실시예에 따른 자동차 번호판 인식 방법을 나타낸 순서도이다."}
