{"patent_id": "10-2023-7035642", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0173668", "출원번호": "10-2023-7035642", "발명의 명칭": "AI 기반 객체인식을 통한 감시 카메라 영상의 노이즈제거", "출원인": "한화비전 주식회사", "발명자": "정영제"}}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 촬영부; 및저조도 환경에서 상기 영상 촬영부를 통해 획득한 영상에서 센서 이득 증폭양에 따라 제1 노이즈 제거 강도를선형적으로 제어하는 프로세서;를 포함하되,상기 프로세서는,상기 영상에서 객체를 인식하는 경우, 상기 객체의 이동 속도에 따라 노이즈 제거 강도를 상기 제1 노이즈 제거강도에서 상기 제1 노이즈 제거 강도보다 낮은 제2 노이즈 제거 강도 사이에서 동적으로 제어하는 것을 특징으로 하는 감시 카메라 영상의 처리 장치."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 프로세서는,상기 영상에서 상기 객체를 인식하지 못한 경우, 상기 저조도 환경의 구간이 시작됨에 따라 상기 영상 촬영부의셔터 속도를 제1 셔터 속도에서, 상기 센서 이득 증폭양에 증가되어 제1 센서 이득값에 도달함 따라 제2 셔터속도까지 선형적으로 감소시키되,상기 객체를 인식한 경우, 상기 제2 셔터 속도에 도달하는 상기 센서 이득 증폭양을 상기 제1 센서 이득값 보다큰 제2 센서 이득값으로 설정하는 것을 특징으로 하는 감시 카메라 영상의 처리 장치."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 프로세서는,딥러닝 기반의 YOLO(You Only Look Once) 알고리즘을 적용하여 상기 객체를 인식하고, 상기 인식된 객체별로 ID를 부여하고, 상기 객체의 좌표를 추출하고, 제1 영상 프레임 및 상기 제1 영상 프레임 보다 후순위의 제2 영상프레임에 포함된 객체의 좌표정보에 기초하여 상기 객체의 이동속도를 산출하는 것을 특징으로 하는 감시 카메라 영상의 처리장치."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 제1 노이즈 제거 강도는 상기 영상에 상기 객체가 존재하지 않는 경우 노이즈 제거 강도이고, 상기 제2 노이즈 제거 강도는 상기 객체의 이동 속도에 따라 상기 제1 노이즈 제거강도에서 감소되는 비율이 달라지는 것을특징으로 하는 감시 카메라 영상의 처리 장치."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 프로세서는,상기 객체의 이동속도가 증가되어 상기 영상 촬영부에서 인식 가능한 최대 한계속도에 도달한 경우, 상기 제1노이즈 제거강도를 기준으로 최대 감소 비율로 노이즈 제거강도를 제어하는 것을 특징으로 하는 감시 카메라 영상의 처리 장치."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2023-0173668-3-제 5 항에 있어서,상기 프로세서는,상기 센서 이득 증폭양이 증가되어 제1 이득값에 도달한 경우, 상기 제2 노이즈 제거강도를 선형적으로 증가시키고, 상기 제1 이득값을 초과하여 상기 제2 이득값에 도달한 경우 상기 제1 노이즈 제거강도와 동일한 강도로노이즈가 제거되도록 제어하는 것을 특징으로 하는 감시 카메라 영상의 처리 장치."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 프로세서는,상기 영상에서 객체를 인식하는 경우, 상기 이동 속도에 따라 2D DNR(Digital Noise Reduction) 및 3D DNR를위한 각각의 필터의 제어 강도를 미리 정해진 비율로 감소시키는 것을 특징으로 하는 감시 카메라 영상의 처리장치."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 프로세서는,상기 영상 촬영부에서 획득한 영상에서 상기 객체의 움직임이 발생하지 않는 제1 영역과, 상기 움직임이 발생하는 제2 영역으로 구분하고, 상기 제1 영역에 대해서는 상기 제1 노이즈 제어강도를 적용하고, 상기 제2 영역에대해서는 상기 제2 노이즈 제어강도를 적용하는 것을 특징으로 하는 감시 카메라 영상의 처리 장치."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 프로세서는,상기 객체의 움직임을 검출한 경우 또는 상기 객체의 이동속도가 증가하는 경우, 즉시 현재 노이즈 제어강도에서 미리 정해진 감소 비율에 따라 노이즈 제어강도를 줄이는 것을 특징으로 하는 감시 카메라 영상의 처리장치."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 프로세서는,상기 검출된 객체의 움직임이 사라지거나, 상기 객체의 이동속도가 감소하는 경우, 미리 정해진 휴지 시간이 경과된 후, 상기 객체의 이동속도를 반영하여 상기 노이즈 제거강도를 선형적으로 증가시키는 것을 특징으로 하는감시 카메라 영상의 처리 장치."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항에 있어서,통신부;를 더 포함하고,상기 프로세서는,상기 영상 촬영부를 통해 획득한 영상 데이터를 상기 통신부를 통해 외부 서버로 전송하고, 상기 통신부를 통해외부 서버로부터 인공지능 기반의 객체 인식결과를 수신하는 것을 특징으로 하는 감시 카메라 영상의 처리장치."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "영상 촬영부; 및공개특허 10-2023-0173668-4-저조도 환경에서 상기 영상 촬영부를 통해 획득한 영상에서 센서 이득 증폭양에 노이즈 제거 강도를 선형적으로제어하되, 상기 영상에서 인식된 객체의 이동 속도에 따라 노이즈 제거 강도를 동적으로 제어하는 프로세서;를포함하고,상기 프로세서는,상기 영상 촬영부에서 획득한 영상을 입력 데이터로 설정하고, 객체 인식을 출력 데이터로 설정하여 기 학습된신경망 모델을 적용하여 상기 객체를 인식하는 것을 특징으로 하는 감시 카메라 영상의 처리 장치."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,상기 프로세서는,제1 노이즈 제거강도와 제2 노이즈 제거강도 사이에서 상기 객체의 이동 속도에 따라 동적으로 노이즈 제거강도를 제어하되,상기 제1 노이즈 제거강도는 상기 영상에서 상기 객체 또는 상기 객체의 움직임이 검출되지 않은 경우에 대응하고, 상기 제2 노이즈 제거강도는 상기 객체의 이동속도가 증가되어 상기 영상 촬영부에서 인식 가능한 최대 한계속도에 도달한 경우 상기 제1 노이즈 제거강도 기준으로 최대 감소비율로 감소된 노이즈 제거강도에 대응되는것을 특징으로 하는 감시 카메라 영상의 처리 장치."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "영상 촬영부를 통해 획득한 영상에서 센서 이득 증폭양에 따라 제1 노이즈 제거 강도를 선형적으로 제어하는 단계;상기 영상에서 객체를 인식한 경우, 상기 객체의 이동 속도를 산출하는 단계; 및상기 이동 속도에 따라 노이즈 제거 강도를 상기 제1 노이즈 제거 강도에서 상기 제1 노이즈 제거강도 보다 낮은 제2 노이즈 제거 강도 사이에서 동적으로 제어하는 단계;를 포함하는 감시 카메라 영상의 처리 방법."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서,상기 영상에서 상기 객체를 인식하지 못한 경우, 저조도 환경의 구간이 시작됨에 따라 상기 영상 촬영부의 셔터속도를 제1 셔터 속도에서, 상기 센서 이득 증폭양에 증가되어 제1 센서 이득값에 도달함 따라 제2 셔터 속도까지 선형적으로 감소시키되,상기 객체를 인식한 경우, 상기 제2 셔터 속도에 도달하는 상기 센서 이득 증폭양을 상기 제1 센서 이득값 보다큰 제2 센서 이득값으로 설정하는 것을 특징으로 하는 감시 카메라 영상의 처리 방법."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 14 항에 있어서,딥러닝 기반의 YOLO(You Only Look Once) 알고리즘을 적용하여 상기 객체를 인식하는 단계; 및상기 인식된 객체별로 ID를 부여하고, 상기 객체의 좌표를 추출하고, 제1 영상 프레임 및 상기 제1 영상 프레임보다 후순위의 제2 영상 프레임에 포함된 객체의 좌표정보에 기초하여 상기 객체의 이동속도를 산출단계;를 포함하는 것을 특징으로 하는 감시 카메라 영상의 처리 방법."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 14 항에 있어서,상기 제1 노이즈 제거 강도는 상기 영상에 상기 객체가 존재하지 않는 경우 노이즈 제거 강도이고, 상기 제2 노이즈 제거 강도는 상기 객체의 이동 속도에 따라 상기 제1 노이즈 제거강도에서 감소되는 비율이 달라지는 것을공개특허 10-2023-0173668-5-특징으로 하는 감시 카메라 영상의 처리 방법."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 객체의 이동속도가 증가되어 상기 영상 촬영부에서 인식 가능한 최대 한계속도에 도달한 경우, 상기 제1노이즈 제거강도를 기준으로 최대 감소 비율로 노이즈 제거강도를 제어하는 것을 특징으로 하는 감시 카메라 영상의 처리 방법."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18 항에 있어서,상기 센서 이득 증폭양이 증가되어 제1 이득값에 도달한 경우, 상기 제2 노이즈 제거강도를 선형적으로 증가시키고, 상기 제1 이득값을 초과하여 상기 제2 이득값에 도달한 경우 상기 제1 노이즈 제거강도와 동일한 강도로노이즈가 제거되도록 제어하는 것을 특징으로 하는 감시 카메라 영상의 처리 방법."}
{"patent_id": "10-2023-7035642", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 14 항에 있어서,상기 검출된 객체의 움직임이 사라지거나, 상기 객체의 이동속도가 감소하는 경우, 미리 정해진 휴지 시간이 경과된 후, 상기 객체의 이동속도를 반영하여 상기 노이즈 제거강도를 선형적으로 증가시키는 단계;를 더 포함하는 것을 특징으로 하는 감시 카메라 영상의 처리 방법."}
{"patent_id": "10-2023-7035642", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "감시 카메라 영상의 처리 장치가 개시된다. 본 명세서의 일 실시예에 따른 감시 카메라 영상의 처리 장치는, 저 조도 환경에서 영상 촬영부를 통해 획득한 영상에서 센서 이득 증폭양에 따라 노이즈 제거 강도를 선형적으로 제 어하되, 영상에서 객체를 인식하는 경우, 객체의 이동 속도에 따라 노이즈 제거강도를 감소시켜 움직임 잔상이 최소화된 노이즈 제거 강도를 유지할 수 있다. 본 명세서는 감시용 카메라, 자율주행 차량, 사용자 단말기 및 서 버 중 하나 이상이 인공 지능(Artificial Intelligence) 모듈, 로봇, 증강현실(Augmented Reality, AR) 장치, 가상 현실(Virtual reality, VT) 장치, 5G 서비스와 관련된 장치 등과 연계될 수 있다."}
{"patent_id": "10-2023-7035642", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서는 감시 카메라 영상 처리 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-7035642", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "저조도 환경의 감시 카메라에서 영상을 촬영할 경우, 어두운 화면을 밝게 하기 위하여 센서이득을 강제적으로 높게 설정할 필요가 있다. 이 때 영상에 노이즈가 발생하게 된다. 이러한 노이즈를 제거하기 위하여 2D DNR(Digital Noise Reduction) 및 3D DNR 방법이 적절하게 조합되어 사용되고 있다. 2D DNR은 노이즈 픽셀이 있을 때, 노이즈 픽셀의 주변 픽셀을 참고하여 보정하는 방법으로, 움직이는 물체의 노 이즈를 제거하는 데는 효과적이지만 배경과 같은 고정된 물체의 노이즈를 제거할 경우 번짐 현상과 같이 해상도 가 저하되는 단점이 있다. 3D DNR은 노이즈 픽셀이 발생하였을 때, 동일 위치에 있는 앞/뒤 프레임의 픽셀을 참 고하여 보정하는 방법이다. 감시 카메라의 경우 저조도 환경에서 센서이득 증폭으로 발생하는 노이즈를 기존 노이즈 제거 기술인 2D 및 3D 노이즈 필터를 사용하여 제거하고 있다. 객체의 유무와 관계없이 사전에 정의된 제거 강도로 노이즈를 줄이기 때문에 필연적으로 객체가 흐릿해 지고 움직임 잔상(Motion Blur)도 많이 발생하게 된다. 잔상 효과(Motion Blur)가 적게 보이도록 노이즈 제거 강도를 줄이면 필연적으로 노이즈가 많아지고 이것은 영상 전송 정보가 많 아져 대역폭(Band Width)를 높이는 결과를 초래한다. 따라서, 기존 노이즈 제거 기술은 화면상에 객체의 유무 에 상관없이 객체가 움직임 잔상(Motion Blur) 보이더라도 일정 수준으로 노이즈를 제어하고 있다. 이에 따라 객체의 움직임이 많을 경우 움직임 잔상(motion blur)가 많아져서 객체를 구분하기 어려울 수 있다. 따라서, 주 감시 대상인 사람과 객체에 대한 인식률도 높이면서 잔상 효과를 최소화하는 방안이 필요하다."}
{"patent_id": "10-2023-7035642", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "전술한 문제를 해결하기 위해 객체의 움직임 정보를 이용하여 움직임이 없을 경우는 노이즈가 많이 제거되도록 제어하고, 움직임이 있을 경우 노이즈를 적게 제거하는 방법이 고려될 수 있지만, 자연환경에서 발생하는 움직임 알람 오류의 문제점으로 인한 기능적 한계가 또한 존재할 수 있다. 이에 따라, 본 명세서는 감시 카메라의 영상 처리 분야에 인공지능 기술을 적용함으로써, 종래의 움직임 데이터에 의존함으로 인해 생기는 움직임 알람 오류를 최소화할 수 있으며, 객체의 움직임 정보를 보다 정확하게 인식함으로써, 객체의 인식율을 높이면서 동 시에 객체의 움직임 잔상을 최소화할 수 있도록 노이즈 제거 강도를 동적으로 제어하는 장치, 방법 및 시스템을 제공할 수 있다. 본 명세서는 전술한 문제점을 해결하기 위한 것으로서, 화면상의 객체의 존재 여부에 따라 노이즈 제거 강도를 동적으로 제어함으로써, 움직임 잔상(motion blur)를 최소화할 수 있는 감시 카메라의 영상 처리 장치 및 방법 을 제공하는 것을 목적으로 한다. 또한, 본 명세서는 저조도 조건에서 화면상의 객체의 움직임 여부에 따라 움직임 잔상 및 노이즈를 최소화할 수 있는 감시 카메라의 영상 처리 장치 및 방법을 제공하는 것을 목적으로 한다. 본 발명이 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은"}
{"patent_id": "10-2023-7035642", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 이하의 발명의 상세한 설명으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가 진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-7035642", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 명세서의 일 실시예에 따른 감시 카메라 영상의 처리장치는, 영상 촬영부; 및 저조도 환경에서 상기 영상 촬영부를 통해 획득한 영상에서 센서 이득 증폭양에 따라 제1 노이즈 제거 강도를 선형적으로 제어하는 프로세서;를 포함하되, 상기 프로세서는, 상기 영상에서 객체를 인식하는 경우, 상기 객체 의 이동 속도에 따라 노이즈 제거 강도를 상기 제1 노이즈 제거 강도에서 상기 제1 노이즈 제거 강도보다 낮은 제2 노이즈 제거 강도 사이에서 동적으로 제어한다. 상기 프로세서는, 상기 영상에서 상기 객체를 인식하지 못한 경우, 상기 저조도 환경의 구간이 시작됨에 따라 상기 영상 촬영부의 셔터 속도를 제1 셔터 속도에서, 상기 센서 이득 증폭양에 증가되어 제1 센서 이득값에 도 달함 따라 제2 셔터 속도까지 선형적으로 감소시키되, 상기 객체를 인식한 경우, 상기 제2 셔터 속도에 도달하 는 상기 센서 이득 증폭양을 상기 제1 센서 이득값 보다 큰 제2 센서 이득값으로 설정할 수 있다. 상기 프로세서는, 딥러닝 기반의 YOLO(You Only Look Once) 알고리즘을 적용하여 상기 객체를 인식하고, 상기 인식된 객체별로 ID를 부여하고, 상기 객체의 좌표를 추출하고, 제1 영상 프레임 및 상기 제1 영상 프레임 보다 후순위의 제2 영상 프레임에 포함된 객체의 좌표정보에 기초하여 상기 객체의 이동속도를 산출할 수 있다. 상기 제1 노이즈 제거 강도는 상기 영상에 상기 객체가 존재하지 않는 경우 노이즈 제거 강도이고, 상기 제2 노 이즈 제거 강도는 상기 객체의 이동 속도에 따라 상기 제1 노이즈 제거강도에서 감소되는 비율이 달라질 수 있 다. 상기 프로세서는, 상기 객체의 이동속도가 증가되어 상기 영상 촬영부에서 인식 가능한 최대 한계속도에 도달한 경우, 상기 제1 노이즈 제거강도를 기준으로 최대 감소 비율로 노이즈 제거강도를 제어할 수 있다. 상기 프로세서는, 상기 센서 이득 증폭양이 증가되어 제1 이득값에 도달한 경우, 상기 제2 노이즈 제거강도를 선형적으로 증가시키고, 상기 제1 이득값을 초과하여 상기 제2 이득값에 도달한 경우 상기 제1 노이즈 제거강도 와 동일한 강도로 노이즈가 제거되도록 제어할 수 있다. 여기서, 상기 제1 이득값은 42dB이며, 상기 제2 이득값은 60dB일 수 있다. 상기 프로세서는, 상기 영상에서 객체를 인식하는 경우, 상기 이동 속도에 따라 2D DNR(Digital Noise Reduction) 및 3D DNR를 위한 각각의 필터의 제어 강도를 미리 정해진 비율로 감소시킬 수 있다. 상기 프로세서는, 상기 영상 촬영부에서 획득한 영상에서 상기 객체의 움직임이 발생하지 않는 제1 영역과, 상 기 움직임이 발생하는 제2 영역으로 구분하고, 상기 제1 영역에 대해서는 상기 제1 노이즈 제어강도를 적용하고, 상기 제2 영역에 대해서는 상기 제2 노이즈 제어강도를 적용할 수 있다. 상기 프로세서는, 상기 객체의 움직임을 검출한 경우 또는 상기 객체의 이동속도가 증가하는 경우, 즉시 현재 노이즈 제어강도에서 미리 정해진 감소 비율에 따라 노이즈 제어강도를 줄일 수 있다. 상기 프로세서는, 상기 검출된 객체의 움직임이 사라지거나, 상기 객체의 이동속도가 감소하는 경우, 미리 정해 진 휴지 시간이 경과된 후, 상기 객체의 이동속도를 반영하여 상기 노이즈 제거강도를 선형적으로 증가시킬 수있다. 상기 감시 카메라는 통신부;를 더 포함하고, 상기 프로세서는, 상기 영상 촬영부를 통해 획득한 영상 데이터를 상기 통신부를 통해 외부 서버로 전송하고, 상기 통신부를 통해 외부 서버로부터 인공지능 기반의 객체 인식결 과를 수신할 수 있다. 본 명세서의 다른 실시예에 따른 감시 카메라 영상의 처리 장치는, 영상 촬영부; 및 저조도 환경에서 상기 영상 촬영부를 통해 획득한 영상에서 센서 이득 증폭양에 따라 제1 노이즈 제거 강도를 선형적으로 제어하는 프로세 서;를 포함하되, 상기 프로세서는, 상기 영상에서 객체를 인식하는 경우, 상기 객체의 이동 속도에 따라 노이즈 제거 강도를 상기 제1 노이즈 제거 강도에서 상기 제1 노이즈 제거 강도보다 낮은 제2 노이즈 제거 강도 사이에 서 동적으로 제어할 수 있다. 상기 프로세서는, 제1 노이즈 제거강도와 제2 노이즈 제거강도 사이에서 상기 객체의 이동 속도에 따라 동적으 로 노이즈 제거강도를 제어하되, 상기 제1 노이즈 제거강도는 상기 영상에서 상기 객체 또는 상기 객체의 움직 임이 검출되지 않은 경우에 대응하고, 상기 제2 노이즈 제거강도는 상기 객체의 이동속도가 증가되어 상기 영상 촬영부에서 인식 가능한 최대 한계속도에 도달한 경우 상기 제1 노이즈 제거강도 기준으로 최대 감소비율로 감 소된 노이즈 제거강도에 대응될 수 있다. 본 명세서의 다른 실시예에 따른 감시 카메라 영상의 처리 방법은, 영상 촬영부를 통해 획득한 영상에서 센서 이득 증폭양에 따라 제1 노이즈 제거 강도를 선형적으로 제어하는 단계; 상기 영상에서 객체를 인식한 경우, 상 기 객체의 이동 속도를 산출하는 단계; 및 상기 이동 속도에 따라 노이즈 제거 강도를 상기 제1 노이즈 제거 강 도에서 상기 제1 노이즈 제거강도 보다 낮은 제2 노이즈 제거 강도 사이에서 동적으로 제어하는 단계;를 포함한 다. 상기 영상에서 상기 객체를 인식하지 못한 경우, 저조도 환경의 구간이 시작됨에 따라 상기 영상 촬영부의 셔터 속도를 제1 셔터 속도에서, 상기 센서 이득 증폭양에 증가되어 제1 센서 이득값에 도달함 따라 제2 셔터 속도까 지 선형적으로 감소시키되, 상기 객체를 인식한 경우, 상기 제2 셔터 속도에 도달하는 상기 센서 이득 증폭양을 상기 제1 센서 이득값 보다 큰 제2 센서 이득값으로 설정할 수 있다. 상기 감시 카메라 영상의 처리 방법은, 딥러닝 기반의 YOLO(You Only Look Once) 알고리즘을 적용하여 상기 객 체를 인식하는 단계; 및 상기 인식된 객체별로 ID를 부여하고, 상기 객체의 좌표를 추출하고, 제1 영상 프레임 및 상기 제1 영상 프레임 보다 후순위의 제2 영상 프레임에 포함된 객체의 좌표정보에 기초하여 상기 객체의 이 동속도를 산출단계;를 포함할 수 있다. 상기 감시 카메라 영상의 처리 방법은, 상기 제1 노이즈 제거 강도는 상기 영상에 상기 객체가 존재하지 않는 경우 노이즈 제거 강도이고, 상기 제2 노이즈 제거 강도는 상기 객체의 이동 속도에 따라 상기 제1 노이즈 제거 강도에서 감소되는 비율이 달라지도록 제어할 수 있다. 상기 감시 카메라 영상의 처리 방법은, 상기 객체의 이동속도가 증가되어 상기 영상 촬영부에서 인식 가능한 최 대 한계속도에 도달한 경우, 상기 제1 노이즈 제거강도를 기준으로 최대 감소 비율로 노이즈 제거강도를 제어할 수 있다. 상기 감시 카메라 영상의 처리 방법은, 상기 센서 이득 증폭양이 증가되어 제1 이득값에 도달한 경우, 상기 제2 노이즈 제거강도를 선형적으로 증가시키고, 상기 제1 이득값을 초과하여 상기 제2 이득값에 도달한 경우 상기 제1 노이즈 제거강도와 동일한 강도로 노이즈가 제거되도록 제어할 수 있다. 상기 감시 카메라 영상의 처리 방법은, 상기 검출된 객체의 움직임이 사라지거나, 상기 객체의 이동속도가 감소 하는 경우, 미리 정해진 휴지 시간이 경과된 후, 상기 객체의 이동속도를 반영하여 상기 노이즈 제거강도를 선 형적으로 증가시키는 단계;를 더 포함할 수 있다. 본 명세서의 다른 실시예에 따른 감시 카메라 시스템은, 미리 정해진 조도 이하의 환경에서 감시 영역의 영상을 촬영하는 감시 카메라; 및 통신부를 통해 상기 감시 카메라로부터 촬영된 상기 영상을 수신하고, 상기 영상에서 인공지능 기반의 객체인식 알고리즘을 통해 객체를 인식하고, 상기 인식된 객체의 이동속도를 산출하여 상기 감 시 카메라로 전송하는 컴퓨팅 장치;를 포함하고, 상기 감시 카메라는, 상기 객체의 이동 속도에 따라 노이즈 제 거 강도를 제1 노이즈 제거 강도에서 상기 제1 노이즈 제거 강도보다 낮은 제2 노이즈 제거 강도 사이에서 동적 으로 제어한다. 본 명세서의 다른 실시예에 따른 감시 카메라 영상의 처리 방법은, 영상 촬영부를 통해 획득된 영상에서 객체를 인식하는 단계; 상기 객체의 이동속도를 산출하는 단계; 및 상기 객체의 이동 속도에 따라 제1 노이즈 제거강도 와 제2 노이즈 제거강도 사이에서 동적으로 상기 영상의 노이즈 제거 강도를 제어하는 단계;를 포함하되, 상기 제1 노이즈 제거강도는 상기 영상에서 상기 객체 또는 상기 객체의 움직임이 검출되지 않은 경우에 대응하고, 상기 제2 노이즈 제거강도는 상기 객체의 이동속도가 증가되어 상기 영상 촬영부에서 인식 가능한 최대 한계속 도에 도달한 경우 상기 제1 노이즈 제거강도 기준으로 40%의 감소비율로 감소된 노이즈 제거강도에 대응된다."}
{"patent_id": "10-2023-7035642", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 명세서의 일 실시예에 따르면, 객체의 움직임 정보를 보다 정확하게 인식함으로써, 객체의 인식율을 높이면 서 동시에 객체의 움직임 잔상을 최소화할 수 있도록 노이즈 제거 강도를 동적으로 제어할 수 있다. 또한, 본 명세서는 저조도 조건에서 화면상의 객체의 움직임 여부에 따라 움직임 잔상 및 노이즈를 최소화할 수 있다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2023-7035642", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-7035642", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 전술한 본 명세서, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있으며, 또한 캐리어 웨이브(예를 들어, 인터넷을 통한 전송)의 형태로 구현되는 것도 포함한다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 명세서의 범위는 첨부된 청구 항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 명세서의 범위에 포함된다. 자동 노출(AE) 제어 기술은 카메라의 영상 밝기를 일정하게 유지하는 기술로 고휘도(야회의 밝은 조도)의 경우 셔터스피드/조리개(iris)를 사용하여 밝기를 제어하고, 저조도(어두운 조도) 조건은 이미지 센서의 이득(Gain) 을 증폭하여 영상의 밝기를 보정하는 기술을 의미한다. 그리고 셔터 스피드는 카메라가 빛에 노출되는 시간을 의미한다. 셔터 스피드가 저속(1/30 sec)일 경우 노출시 간이 길어서 영상은 밝아지지만, 노출 시간 동안 객체의 움직임도 누적되어 모션 블러(motion blur)가 발생되는 문제가 있다. 반대로 셔터 스피드가 고속(1/200 sec 이상)인 경우 카메라 노출 시간이 짧아 영상이 어두워질 수 있지만 객체의 움직임 누적도 짧아져서 모션 블러 현상은 적어진다. 감시카메라는 주 감시 대상인 사람과 객체가 모션 블러 현상 없이 감시해야 하므로 고속 셔터를 유지하는 것이 유리하다. 하지만 셔터 스피드가 고속일 경우 짧은 노출 시간으로 인해 영상도 어두워져 저조도에서는 이미지 센서의 이득 증폭량을 증가시켜야 밝기가 보정되기 때문에 노이즈를 상대적으로 많이 일으킬 수 있다. 일반적으 로 이미지 센서의 이득 증폭이 많아질수록 화면상에 노이즈도 함께 증가한다. 결국, 저조도 조건에서 고속 셔터 스피드의 사용은 모션 블러의 감소 효과는 주지만 화면에 노이즈를 증가시키는 원인이 될 수도 있다. 한편, 실제 감시카메라가 촬영하는 감시 영역에서는 감시해야 할 객체가 항상 존재하는 것은 아니지만 언제든지 랜덤하게 발생하는 객체를 모션 블러없이 모니터링할 수 있어야 하기 때문에 항상 고속 셔터를 유지할 수밖에 없다. 물론 고속 셔터의 유지는 저조도 조건에서 많은 노이즈를 발생시키기 때문에 노이즈에 따른 부작용(side effect)도 많이 발생시킬 수 있다. 예를 들어, 노이즈가 많아지면 영상 압축 전송 데이터도 많아져서 영상 전송 대역(Bandwidth)가 높아지고 객체도 노이즈로 인해 윤곽이 흐려지는 문제가 생길 수 있다. 본 명세서의 일 실시예에 따른 감시 카메라 영상 처리 방법은 감시 카메라의 목적에 부합되도록 화면상의 객체 의 존재여부에 따라 자동으로 셔터 스피드를 제어할 필요성이 있다. 하지만, 객체의 존재여부를 판단하기 위해 서 종래에는 모션 정보를 많이 이용하였으나 자연환경(바람, 나뭇잎 흔들림 등등)에 의해 False Alarm 이 많이발생하는 문제가 있었다. 이에 따라 본 명세서는 AI 영상 분석을 통해 객체를 인식하고 객체마다 ID를 부여하고, ID가 부여된 객체에 대하여 평균 이동속도를 산출한다. 산출된 객체의 평균 이동속도는 모션 블러가 발생하지 않는 적절한 셔터 스피드를 산출하는데 활용될 수 있다. 한편, 일반적으로 고휘도(야외 또는 밝은 조도 조건) 조건은 고속 셔터를 사용하여 밝기 보정을 하기 때문에 객 체의 모션 블러가 거의 발생하지 않는다. 따라서, 본 명세서의 일 실시예에 따른 감시 카메라 영상의 처리 방법 은 고속 셔터 사용으로 인해 이미지 센서이득을 증폭시킬 수밖에 없으며, 이미지 센서 이득이 증폭되어 노이즈 가 많아지는 저조도 조건에서 셔터를 제어하기 위해 적용될 수 있다. 도 1은 본 명세서의 일 실시예에 따른 감시 카메라의 영상 처리 방법을 구현하기 위한 감시 카메라 시스템을 설 명하기 위한 도면이다. 도 1을 참조하면, 본 명세서의 일 실시예에 따른 영상 관리 시스템은 촬영 장치 및 영상 관리 서버 을 포함할 수 있다. 촬영 장치는 특정 장소의 고정된 위치에 배치되는 촬영용 전자 장치일 수도 있고, 일정한 경로를 따라 자 동 또는 수동으로 움직일 수 있는 촬영용 전자 장치일 수도 있고, 사람 또는 로봇 등에 의하여 이동될 수 있는 촬영용 전자 장치일 수도 있다. 촬영 장치는 유무선 인터넷에 연결하여 사용 하는 IP 카메라일 수 있다. 촬영 장치는 팬(pan), 틸트(tilt), 및 줌(zoom) 기능을 갖는 PTZ 카메라일 수 있다. 촬영 장치는 감시 하는 영역을 녹화하거나 사진을 촬영하는 기능을 가질 수 있다. 촬영 장치는 감시하는 영역에서 발생하는 소리를 녹음하는 기능을 가질 수 있다. 촬영 장치는 감시하는 영역에서 움직 임 또는 소리 등 변화가 발생 할 경우, 이에 대한 알림을 발생시키거나 녹화 또는 사진 촬영을 수행하는 기능을 가질 수 있다. 영상 관리 서버는 촬영 장치를 통하여 촬영된 영상 자체 및/또는 해당 영상을 편집하여 얻어지는 영 상을 수신하여 저장하는 장치일 수 있다. 영상 관리 서버는 수신한 용도에 대응되도록 분석할 수 있다. 예 를 들어, 영상 관리 서버는 영상에서 객체를 검출하기 위해 객체 검출 알고리즘을 이용하여 객체를 검출할 수 있다. 상기 객체 검출 알고리즘은 AI 기반 알고리즘이 적용될 수 있으며, 미리 학습된 인공신경망 모델을 적 용하여 객체를 검출할 수 있다. 한편, 영상 관리 서버는 영상 분석 목적에 맞는 다양한 학습 모델을 저장하고 있을 수 있다. 전술한 객체 검출을 위한 학습 모델 외에, 검출된 객체의 이동 속도를 획득할 수 있는 모델을 저장하고 있을 수도 있다. 여 기서 상기 학습된 모델들은 객체의 이동 속도에 대응되는 셔터 속도, 저속 셔터에 진입하는 최대 센서 이득값을 출력하는 학습 모델을 포함할 수도 있다. 또한, 상기 학습된 모델들은 상기 객체의 이동 속도에 대응되는 노이 즈 제거 강도 조절값을 출력하는 학습 모델을 포함할 수도 있다. 또한, 영상 관리 서버는 수신한 영상을 분석하여 메타 데이터와 해당 메타 데이터에 대한 인덱스 정보를 생성할 수 있다. 영상 관리 서버는 수신한 영상에 포함된 영상 정보 및 /또는 음향 정보를 함께 또는 별도 로 분석하여 메타 데이터와 해당 메타 데이터에 대한 인덱스 정보를 생성할 수 있다. 영상 관리 시스템은 촬영 장치 및/또는 영상 관리 서버와 유무선 통신을 수행할 수 있는 외부 장 치를 더 포함할 수 있다. 외부 장치는 영상 관리 서버로 영상 전체 또는 일부의 제공을 요청하는 정보 제공 요청 신호를 송신 할 수 있다. 외부 장치는 영상 관리 서버로 영상 분석 결과 객체의 존재 여부, 객체의 이동 속도, 객 체의 이동 속도에 따른 셔터 속도 조절값, 객체의 이동 속도에 따른 노이즈 제거값 등을 요청하는 정보 제공 요 청 신호를 송신할 수 있다. 또한 외부 장치는 영상 관리 서버로 영상을 분석하여 얻어진 메타 데이터 및/또는 메타 데이터에 대한 인덱스 정보를 요청하는 정보 제공 요청 신호를 송신할 수 있다. 영상 관리 시스템은 촬영 장치, 영상 관리 서버, 및/또는 외부 장치 간의 유무선 통신 경로 인 통신망을 더 포함할 수 있다. 통신망은 예컨대 LANs(Local Area Networks), WANs(Wide Area Networks), MANs(Metropolitan Area Networks), ISDNs(Integrated Service Digital Networks) 등의 유선 네트 워크나, 무선 LANs, CDMA, 블루투스, 위성 통신 등의 무선 네트워크를 망라할 수 있으나, 본 명세서의 범위가 이 에 한정되는 것은 아니다. 도 2는 본 명세서의 일 실시예에 따른 감시 카메라의 개략적인 블록도이다. 도 2는 도 1에 도시된 카메라의 구성을 나타내는 블록도이다. 도 2를 참조하면,카메라는 지능형 영상분석 기능을 수행하여 상기 영상분석 신호를 생성하는 네트워크 카메라임을 그 예로 설명하나, 본 발명의 실시예에의한 네트워크 감시 카메라 시스템의 동작이 반드시 이에 한정되는 것은 아니다. 카메라는 이미지 센서, 인코더, 메모리, 이벤트 센서, 프로세서, 및 통신 인터 페이스를 포함한다. 이미지 센서는 감시 영역을 촬영하여 영상을 획득하는 기능을 수행하는 것으로서, 예컨대, CCD(Charge- Coupled Device) 센서, CMOS(Complementary Metal-Oxide-Semiconductor) 센서 등으로 구현될 수 있다. 인코더는 이미지 센서를 통해 획득한 영상을 디지털 신호로 부호화하는 동작을 수행하며, 이는 예컨 대, H.264, H.265, MPEG(Moving Picture Experts Group), M-JPEG(Motion Joint Photographic Experts Group) 표준 등을 따를 수 있다. 메모리는 영상 데이터, 음성 데이터, 스틸 이미지, 메타데이터 등을 저장할 수 있다. 앞서 언급한 바와 같 이, 상기 메타데이터는 상기 감시영역에 촬영된 객체 검출 정보(움직임, 소리, 지정지역 침입 등), 객체 식별 정보(사람, 차, 얼굴, 모자, 의상 등), 및 검출된 위치 정보(좌표, 크기 등)을 포함하는 데이터일 수 있다. 또한, 상기 스틸 이미지는 상기 메타데이터와 함께 생성되어 메모리에 저장되는 것으로서, 상기 영상분석 정보들 중 특정 분석 영역에 대한 이미지 정보를 캡쳐하여 생성될 수 있다. 일 예로, 상기 스틸 이미지는 JPEG 이미지 파일로 구현될 수 있다. 일 예로, 상기 스틸 이미지는 특정 영역 및 특정 기간 동안 검출된 상기 감시영역의 영상 데이터들 중 식별 가 능한 객체로 판단된 영상 데이터의 특정영역을 크롭핑(cropping)하여 생성될 수 있으며, 이는 상기 메타데이터 와 함께 실시간으로 전송될 수 있다. 통신부는 상기 영상 데이터, 음성 데이터, 스틸 이미지, 및/또는 메타데이터를 영상수신/검색장치에 전송한다. 일 실시예에 따른 통신부는 영상 데이터, 음성 데이터, 스틸 이미지, 및/또는 메타데이터를 영 상수신장치에 실시간으로 전송할 수 있다. 통신 인터페이스는 유무선 LAN(Local Area Network), 와이 파이(Wi-Fi), 지그비(ZigBee), 블루투스(Bluetooth), 근거리 통신(Near Field Communication) 중 적어도 하나 의 통신 기능을 수행할 수 있다. AI 프로세서는 인공지능 영상 처리를 위한 것으로서, 본 명세서의 일 실시예에 따라 감시 카메라 시스템을 통해 획득된 영상에서 관심객체로 학습된 딥러닝 기반의 객체 탐지(Objection Detection) 알고리즘을 적용한다. 상기 AI 프로세서는 시스템 전반에 걸쳐 제어하는 프로세서와 하나의 모듈로 구현되거나 독립된 모듈 로 구현될 수 있다. 본 명세서의 일 실시예들은 객체 탐지에 있어서 YOLO(You Only Lock Once) 알고리즘을 적용 할 수 있다. YOLO은 객체 검출 속도가 빠르기 때문에 실시간 동영상을 처리하는 감시 카메라에 적당한 AI 알고 리즘이다. YOLO 알고리즘은 다른 객체 기반 알고리즘들(Faster R-CNN, R_FCN, FPN-FRCN 등)과 달리 한 장의 입 력 영상을 리사이즈(Resize)후 단일 신경망을 단 한 번 통과킨 결과로 각 객체의 위치를 인디케이팅하는 바운딩 박스(Bounding Box)와 객체가 무엇인지 분류 확률을 출력한다. 최종적으로 Non-max suppression을 통해 하나의 객체를 한번 인식(detection)한다. 한편, 본 명세서에 개시되는 객체 인식 알고리즘은 전술한 YOLO에 한정되지 않고 다양한 딥러닝 알고리즘으로 구현될 수 있음을 밝혀둔다. 한편, 본 명세서에 적용되는 객체 인식을 위한 학습 모델은 카메라 성능, 감시 카메라에서 모션 블러 현상 없이 인식 가능한 객체의 움직임 속도 정보 등을 학습 데이터로 정의하여 훈련된 모델일 수 있다. 이에 따라 학습된 모델은 입력 데이터가 객체의 이동 속도일 수 있으며, 출력 데이터가 객체의 이동 속도에 최적화된 셔터 속도를 출력 데이터로 할 수 있다. 도 3은 본 명세서의 일 실시예에 따른 감시 카메라 영상의 분석에 적용되는 AI 장치(모듈)을 설명하기 위한 도 면이다. 도 3을 살펴보면, AI 장치는 AI 프로세싱을 수행할 수 있는 AI 모듈을 포함하는 전자 기기 또는 AI 모듈을 포함하는 서버 등을 포함할 수 있다. 또한, AI 장치는 감시 카메라 또는 영상 관리 서버의 적어도 일부의 구성으로 포함되어 AI 프로세싱 중 적어도 일부를 함께 수행하도록 구비될 수도 있다. AI 프로세싱은 감시카메라 또는 영상 관리 서버의 제어부와 관련된 모든 동작들을 포함할 수 있다. 예를 들어, 감시 카메라 또는 영상 관리 서버는 획득된 영상 신호를 AI 프로세싱 하여 처리/판단, 제어 신호 생성 동작을 수행할 수 있다. AI 장치는 AI 프로세싱 결과를 직접 이용하는 클라이언트 디바이스이거나, AI 프로세싱 결과를 다른 기기에 제공하는 클라우드 환경의 디바이스일 수도 있다. AI 장치는 신경망을 학습할 수 있는 컴퓨팅 장치로서, 서 버, 데스크탑 PC, 노트북 PC, 태블릿 PC 등과 같은 다양한 전자 장치로 구현될 수 있다. AI 장치는 AI 프로세서, 메모리 및/또는 통신부를 포함할 수 있다. AI 프로세서는 메모리에 저장된 프로그램을 이용하여 신경망을 학습할 수 있다. 특히, AI 프로세서(2 1)는 감시 카메라의 관련 데이터를 인식하기 위한 신경망을 학습할 수 있다. 여기서, 감시 카메라의 관련 데이 터를 인식하기 위한 신경망은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며, 인간의 신경망의 뉴런(neuron)을 모의하는, 가중치를 갖는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 모드들은 뉴런이 시냅스(synapse)를 통해 신호를 주고 받는 뉴런의 시냅틱 활동을 모의하도록 각각 연결 관계에 따라 데 이터를 주고 받을 수 있다. 여기서 신경망은 신경망 모델에서 발전한 딥러닝 모델을 포함할 수 있다. 딥러닝 모 델에서 복수의 네트워크 노드들은 서로 다른 레이어에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데 이터를 주고 받을 수 있다. 신경망 모델의 예는 심층 신경망(DNN, deep neural networks), 합성곱 신경망(CNN, convolutional deep neural networks), 순환 신경망(RNN, Recurrent Boltzmann Machine), 제한 볼츠만 머신 (RBM, Restricted Boltzmann Machine), 심층 신뢰 신경망(DBN, deep belief networks), 심층 Q-네트워크(Deep Q-Network)와 같은 다양한 딥 러닝 기법들을 포함하며, 컴퓨터비젼, 음성인식, 자연어처리, 음성/신호처리 등의 분야에 적용될 수 있다. 한편, 전술한 바와 같은 기능을 수행하는 프로세서는 범용 프로세서(예를 들어, CPU)일 수 있으나, 인공지능 학 습을 위한 AI 전용 프로세서(예를 들어, GPU)일 수 있다. 메모리는 AI 장치의 동작에 필요한 각종 프로그램 및 데이터를 저장할 수 있다. 메모리는 비 휘발 성 메모리, 휘발성 메모리, 플래시 메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드 라이브(SDD) 등으로 구현할 수 있다. 메모리는 AI 프로세서에 의해 액세스되며, AI 프로세서에 의 한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 또한, 메모리는 본 발명의 일 실시예에 따른 데이터 분류/인식을 위한 학습 알고리즘을 통해 생성된 신경망 모델(예를 들어, 딥 러닝 모델)을 저장할 수 있다. 한편, AI 프로세서는 데이터 분류/인식을 위한 신경망을 학습하는 데이터 학습부를 포함할 수 있다. 데 이터 학습부는 데이터 분류/인식을 판단하기 위하여 어떤 학습 데이터를 이용할지, 학습 데이터를 이용하여 데이터를 어떻게 분류하고 인식할지에 관한 기준을 학습할 수 있다. 데이터 학습부는 학습에 이용될 학습 데이터를 획득하고, 획득된 학습데이터를 딥러닝 모델에 적용함으로써, 딥러닝 모델을 학습할 수 있다. 데이터 학습부는 적어도 하나의 하드웨어 칩 형태로 제작되어 AI 장치에 탑재될 수 있다. 예를 들어, 데이터 학습부는 인공지능(AI)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 범용 프로세서(CPU) 또 는 그래픽 전용 프로세서(GPU)의 일부로 제작되어 AI 장치에 탑재될 수도 있다. 또한, 데이터 학습부 는 소프트웨어 모듈로 구현될 수 있다. 소프트웨어 모듈(또는 인스트럭션(instruction)을 포함하는 프로그램 모 듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록 매체 (non-transitory computer readable media)에 저장될 수 있다. 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 애플리케이션에 의해 제공될 수 있다. 데이터 학습부는 학습 데이터 획득부 및 모델 학습부를 포함할 수 있다. 학습 데이터 획득부는 데이터를 분류하고 인식하기 위한 신경망 모델에 필요한 학습 데이터를 획득할 수 있 다. 모델 학습부는 획득된 학습 데이터를 이용하여, 신경망 모델이 소정의 데이터를 어떻게 분류할지에 관한 판 단 기준을 가지도록 학습할 수 있다. 이 때 모델 학습부는 학습 데이터 중 적어도 일부를 판단 기준으로 이 용하는 지도 학습(supervised learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 또는 모델 학습부는 지도 없이 학습 데이터를 이용하여 스스로 학습함으로써, 판단 기준을 발견하는 비지도 학습(unsupervised learning)을 통해 신경망 모델을 학습시킬 수 있다. 또한, 모델 학습부는 학습에 따른 상황 판단의 결과가 올바른지에 대한 피드백을 이용하여 강화 학습(reinforcement learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 또한, 모델 학습부는 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient decent)을 포함하는 학습 알고리즘을 이용하여 신경망 모델을 학습시킬 수 있다.신경망 모델이 학습되면, 모델 학습부는 학습된 신경망 모델을 메모리에 저장할 수 있다. 모델 학습부 는 학습된 신경망 모델을 AI 장치와 유선 또는 무선 네트워크로 연결된 서버의 메모리에 저장할 수도 있다. 데이터 학습부는 인식 모델의 분석 결과를 향상시키거나, 인식 모델의 생성에 필요한 리소스 또는 시간을 절약하기 위해 학습 데이터 전처리부(미도시) 및 학습 데이터 선택부(미도시)를 더 포함할 수도 있다. 학습 데이터 전처리부는 획득된 데이터가 상황 판단을 위한 학습에 이용될 수 있도록, 획득된 데이터를 전처리 할 수 있다. 예를 들어, 학습 데이터 전처리부는, 모델 학습부가 이미지 인식을 위한 학습을 위하여 획득된 학습 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다. 또한, 학습 데이터 선택부는, 학습 데이터 획득부에서 획득된 학습 데이터 또는 전처리부에서 전처리된 학 습 데이터 중 학습에 필요한 데이터를 선택할 수 있다.선택된 학습 데이터는 모델 학습부에 제공될 수 있다. 또한, 데이터 학습부는 신경망 모델의 분석 결과를 향상시키기 위하여 모델 평가부(미도시)를 더 포함할 수 도 있다. 모델 평가부는, 신경망 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 분석 결과가 소정 기준을 만족하지 못하는 경우, 모델 학습부로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가 데이터는 인식 모델을 평가하기 위한 기 정의된 데이터일 수 있다. 일 예로, 모델 평가부는 평가 데이터에 대한 학습된 인식 모델의 분석 결과 중, 분석 결과가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정되 임계치를 초과 하는 경우, 소정 기준을 만족하지 못한 것으로 평가할 수 있다. 통신부는 AI 프로세서에 의한 AI 프로세싱 결과를 외부 전자 기기로 전송할 수 있다. 예를 들어, 외부 전자 기기는 감시카메라, 블루투스 장치, 자율주행 차량, 로봇, 드론, AR 기기, 모바일 기기, 가전 기기 등을 포함할 수 있다. 한편, 도 3에 도시된 AI 장치는 AI 프로세서와 메모리, 통신부 등으로 기능적으로 구분하여 설 명하였지만, 전술한 구성요소들이 하나의 모듈로 통합되어 AI 모듈로 호칭될 수도 있음을 밝혀둔다. 본 명세서는 감시용 카메라, 자율주행 차량, 사용자 단말기 및 서버 중 하나 이상이 인공 지능(Artificial Intelligence) 모듈, 로봇, 증강현실(Augmented Reality, AR) 장치, 가상 현실(Virtual reality, VT) 장치, 5G 서비스와 관련된 장치 등과 연계될 수 있다. 도 4는 본 명세서의 일 실시예에 따른 감시 카메라의 영상 처리 방법의 흐름도이다. 도 4에 도시된 영상 처리 방법은 도 1 내지 도 3을 통해 설명한 감시 카메라 시스템, 감시 카메라 장치, 감시 카메라 장치에 포함된 프로 세서 또는 제어부를 통해 구현될 수 있다. 설명의 편의를 위해 상기 영상 처리 방법은 도 2에 도시된 감시 카메 라의 프로세서를 통해 다양한 기능들이 제어될 수 있음을 전제로 설명하나, 본 명세서는 이에 한정되 는 것이 아님을 밝혀둔다. 도 4를 참조하면, 프로세서는 감시 카메라 영상을 획득한다(S400). 상기 감시 카메라 영상은 동영상을 포 함할 수 있다. 프로세서는 상기 획득된 영상을 AI 영상 분석 시스템을 통해 객체 인식 동작이 수행되도록 제어할 수 있다 (S410). 상기 AI 영상 분석 시스템은 감시 카메라에 포함된 영상 처리 모듈일 수 있다. 이 경우, 상기 영상 처리 모듈에 포함된 AI 프로세서는 입력된 영상(동영상)에서 기 정의된 객체 인식 알고리즘을 적용하여 영상 내의 객체를 인 식함으로써, 객체의 존재 여부를 판단할 수 있다. 또한, 상기 AI 영상 분석 시스템은 감시 카메라와 통신 연결 된 외부 서버에 구비된 영상 처리 모듈일 수 있다. 이 경우, 감시 카메라의 프로세서는 입력된 영상을 통 신부를 통해 상기 외부 서버로 전송하면서 객체인식 요청 명령 및/또는 인식된 객체의 움직임 정도(객체의 이동 속도, 객체의 평균 이동속도 정보 등) 등을 함께 요청할 수도 있다. 일 실시예에 따르면 상기 요청에 객체의 이 동 속도에 따른 최적의 노이즈 제거강도 정보를 포함할 수 있으며, 여기서 상기 노이즈 제거강도는 감시 카메라 의 영상에서 노이즈를 제거하는데 이용되는 노이즈 제거 필터 계수정보를 포함할 수 있다. 즉, 본 명세서의 일 실시예에 따르면 감시카메라 및/또는 외부 서버는 영상 분석을 통해 객체의 이동 속도에 따른 노이즈 제거 필터 계수 획득할 수 있다. 상기 노이즈 제거 필터 계수는 본 명세서 전체를 통해 설명되는 노이즈 제거 강도 제어에 적용되는 알고리즘을 통해 획득될 수 있다.프로세서는 상기 인식된 객체의 평균 이동속도를 산출할 수 있다(S420). 상기 인식된 객체의 평균 이동속 도를 산출하는 과정은 도 7 및 8을 통해 보다 구체적으로 설명하기로 한다. 프로세서는 산출된 객체의 평균 이동속도에 대응하는 셔터 스피드를 적용할수 있다(S430). 객체의 이동속 도가 클수록 잔상 효과는 심해지기 때문에 셔터 스피드를 높일 수밖에 없다. 여기서 셔터 스피드를 높이는 정도 또는 객체의 특정 이동속도에서 잔상효과를 최소화시키기 위한 최적의 셔터스피드 값을 적용하는 과정에 대해서 는 도 9를 통해 보다 구체적으로 설명한다. 프로세서는 산출된 객체의 이동 속도 고려하여 노이즈를 제거하도록 제어할 수 있다(S400). 전술한 바와 같이, 프로세서는 객체의 이동속도에 따라 노이즈 제거 강도를 제어한다. 본 명세서의 일 실시예에 따른 영상 처리 방법은 상대적으로 저조도 환경에서 유리하게 적용될 수 있다. 특히 조도가 밝은 환경에서는 보통 고속 셔터를 사용하므로 객체의 움직임으로 인한 잔상 효과는 크게 문제되지 않을 수 있다. 그러나 저조도 환경에서는 노출시간 보다는 센서 이득에 민감한 구간으로 센서이득 제어를 통해 자동 노출제어가 이루어질 수 있다. 이에 따라 저조도 환경에서는 센서이득 제어로 인한 노이즈가 문제가 될 수 있으 며 이러한 노이즈를 줄이기 위해서는 최대한 밝기를 확보해야 하며 결국, 저속 셔터를 유지하는 것이 유리할 수 있다. 그러나, 일반 카메라와는 달리 감시 카메라의 경우 저조도 환경에서도 빠른 속도로 움직이는 객체를 명확 하게 인식해야 하는 필요성으로 인해 고속 셔터를 유지하여 최대한 객체의 잔상효과를 제거하는 것이 우선순위 로 고려될 수밖에 없다. 따라서, 저조도 환경의 감시카메라는, 밝기 및 객체의 움직임 정도에 따른 최적의 셔터 값을 결정하는 것이 무엇보다 중요하다. 또한, 저조도 환경의 감시카메라는, 상기 최적의 셔터값 결정 외에 움 직임 잔상이 최대한 적어지도록 하기 위해서 노이즈 제거 강도를 적절하게 낮추어야 할 필요성이 있다. 이상, 본 명세서의 실시예를 통해 감시 카메라 영상에서 객체를 인식하고, 인식된 객체의 움직임 여부, 객체의 움직임 정도(객체의 평균 이동속도), 객체의 존재 여부에 따른 최적의 셔터값을 적용하되, 객체의 움직임 정도 에 따라 노이즈 제거 강도를 제어하는 개략적인 순서에 대하여 살펴보았다. 이하, 객체인식, 객체의 평균이동속도 산출, 객체의 움직임 정도에 따른 노이즈 제거강도의 조절에 대하여 구체 적으로 설명하기로 한다. 도 5는 본 명세서의 일 실시예에 따라 객체 인식 방법의 일 예를 설명하기 위한 도면이다. 도 6은 본 명세서의 일 실시예에 따라 객체 인식 방법의 다른 예를 설명하기 위한 도면이다. 도 7은 본 명세서의 일 실시예에 따라 인공지능 알고리즘을 이용한 객체 인식 과정을 설명하기 위한 도면이다. 도 8은 도 7에서 인식된 객체의 평균 이동속도를 산출하는 과정을 설명하기 위한 도면이다. 이하 도 5 내지 도 8을 참조하여 AI 알고리즘을 이용하여 객체인식 및 객체의 평균이동속도를 산출하는 과정을 설명한다. 도 5를 참조하면, 감시 카메라의 프로세서는 영상 프레임을 인공 신경망(Artificial Neural Network, 이하 신경망이라 함) 모델에 입력한다(S500). 상기 신경망 모델은 카메라 영상을 입력 데이터로 하고 상기 입력된 영상 데이터에 포함된 객체(사람, 자동차 등)를 인식하도록 훈련된 모델일 수 있다. 전술한 바와 같이 본 명세서의 일 실시예에 따라 상기 신경망 모델은 YOLO 알고리즘이 적용될 수 있다. 프로세서는 신경망 모델의 출력 데이터를 통해 객체의 종류 및 객체의 위치를 인식할 수 있다(S510). 도 7 을 참조하면 신경망 모델의 출력 결과 객체인식 결과를 바운딩 박스(B1,B2)로 표시하고, 각 바운딩 박스의 모서 리(C11,C12/ C21, C22)의 좌표값을 포함할 수 있다. 프로세서는 상기 바운딩 박스의 모서리 정보를 통해 각 바운딩 박스의 중심 좌표를 산출할 수 있다. 프로세서는 제1 영상 프레임 및 제2 영상 프레임에서 각각 검출된 객체의 좌표를 인식할 수 있다(S520). 프로세서는 객체의 이동속도를 산출하기 위하여 제1 영상 프레임 및 상기 제1 영상 프레임 이후에 획득되 는 제2 영상 프레임을 분석할 수 있다. 프로세서는 각 영상 프레임에서의 특정 객체의 좌표 변화를 감지하고, 객체의 움직임 검출 및 이동속도를 산출할 수 있다(S530) 한편, 도 5는 감시 카메라에서 AI 프로세싱 결과를 통해 객체를 인식하는 과정을 설명하였으나, 도 6는 상기 AI 프로세싱 동작을 네트워크 즉 외부 서버를 통해 수행하는 경우를 예시한다. 도 6을 참조하면, 감시 카메라는 영상을 획득한 경우, 획득한 영상 데이터를 네트워크(외부 서버 등)로 전송한 다(S600). 여기서 감시 카메라는 영상 데이터 전송과 함께 영상에 포함된 객체의 존재 유무, 객체가 존재하는 경우, 객체의 평균 이동속도 정보를 함께 요청할 수도 있다. 외부 서버는 AI 프로세서를 통해 감시 카메라로부터 수신된 영상 데이터로부터 신경망 모델에 입력할 영상 프레 임을 확인하고, AI 프로세서는 상기 영상 프레임을 신경망 모델에 적용하도록 제어할 수 있다(S610). 또한 외부 서버에 포함된 AI 프로세서는 신경망 모델의 출력 데이터를 통해 객체의 종류 및 객체의 위치를 인식할 수 있다 (S620). 외부 서버는 신경망 모델의 출력값을 통해 인식된 객체에 대하여 평균 이동속도를 산출할 수 있다(S630). 객체 인식 및 객체의 평균 이동속도 산출은 전술한 바와 같다. 감시 카메라는 외부 서버로부터 객체 인식 결과 및/또는 객체의 평균이동속도 정보를 수신할 수 있다(S650). 감시 카메라는 객체의 평균 이동속도 정보에 기초하여 셔터속도를 제어한다 (S650). 여기서 프로세서는 최 대 센서이득값을 증가시킴으로써, 고속 셔터가 유지되는 구간을 늘릴 수 있다. 감시 카메라는 객체의 평균 이동속도에 따라 노이즈 제거 강도를 동적으로 가변 적용할 수 있다(S560) 도 8의 (a)를 참조하면, 프로세서는 신경망 모델을 통해 객체를 인식한 경우 인식된 객체의 테두리에 바운 딩 박스를 표시하고, 각 객체들에 대하여 ID를 부여할 수 있다. 이에 따라 프로세스는 인식된 각각의 객체 를 ID 및 바운딩 박스의 중심 좌표를 통해 객체 인식 결과를 확인할 수 있다. 상기 객체인식 결과는 상기 제1 영상 프레임 및 제2 영상 프레임 각각에 대하여 제공될 수 있다. 여기서 제2 영상 프레임의 경우, 이전 영상인 제1 영상 프레임에서 인식된 객체가 아닌 신규 객체를 인식한 경우 새로운 ID를 부여하게 되고, 동일하게 바운 딩 박스 좌표를 통해 객체의 중심좌표를 획득할 수 있다. 도 8의 (b)를 참조하면, 프로세서는 적어도 둘 이상의 영상 프레임에서 획득된 객체의 중심좌표가 획득되 면 상기 중심좌표의 변화를 기준으로 인식된 객체의 이동속도를 산출할 수 있다. [수학식 1]"}
{"patent_id": "10-2023-7035642", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, (X1,Y1)은 제1 객체(ID1)의 중심좌표이며, (X2,V2)는 제2 객체(ID2)의 중심좌표이다. 그리고 프로세서는 산출된 객체별 이동 속도에 평균 필터를 적용하여 객체의 평균 이동속도를 산출할 수 있다(아래 수식 참조) [수학식 2]"}
{"patent_id": "10-2023-7035642", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "프로세서는 감시 카메라로부터 입력되는 모든 영상 프레임 마다 전술한 과정을 통해 객체인식 및 인식된 객체의 평균이동속도를 산출한다. 산출된 평균객체속도는 도 10 내지 12에서 설명할 노이즈 제거강도 조절에 활 용될 수 있다. 한편, 프로세서는 현재 프레임, 이전 프레임, 다음 프레임 등의 순차적인 영상 프레임을 각각 확인하여 인 식된 객체 ID 가 화면에서 사라지게 되면 부여한 객체 ID를 삭제한다. 이에 따라 총 객체수도 감소될 수 있다. 반대로 이전 영상 프레임에서 존재하지 않았던 객체가 새롭게 인식된 경우, 신규 객체 ID를 부여하고, 객체의평균 이동속도에 포함시키고, 총 객체수도 증가시킨다. 프로세서는 영상 프레임 내에 포함된 객체 ID가 0 개인 경우, 획득된 영상 내에 객체가 존재하지 않는 것으로 판단한다. 도 9는 본 명세서의 일 실시예에 따라 객체 인식 유무에 따른 셔터 속도 변경을 설명하기 위한 도면이다. 도 9의 그래프는 X 축이 센서 이득값이고, Y축이 감시 카메라의 셔터속도 값이다. X 축의 원점은 0dB로 도 9의 그래프는 저조도 환경에서 감시 카메라의 셔터 속도 그래프를 의미할 수 있다. 저조도 환경에서 감시 카메라의 셔터는 센서 이득이 0dB 일 때 고속 셔터(일반적으로 1/200sec)값으로 시작하며, 센서 이득과 셔터 속도는 반비 례한다. 즉, 조도가 낮을수록 센서 이득값은 높아지며 저조도 환경을 극복하기 위해 셔터 속도는 점차적으로 저 속 셔터로 진행된다. 다만, 저조도 환경을 극복하기 위해 센서 이득을 점차적으로 높이되 센서 이득이 증가될 수 있는 최대 이득값이 존재하며, 상기 최대 이득값에 대응하는 셔터 속도는 저속 셔터(일반적으로 1/30sec)로 줄어든다. 도 9에 개시된 그래프 중 L1은 감시 카메라 영상에서 객체를 인식한 경우의 셔터 속도 곡선이며, L2는 감시 카 메라 영상에서 객체를 인식하지 않은 경우의 셔터 속도 곡선이다. 본 명세서는 전술한 AI 객체 인식 알고리즘 등을 통해 객체 ID가 0 보다 클 경우 객체가 존재하는 것으로 인식하고, 도 9에 도시된 바와 같이 저속 셔터 속 도에 대응하는 최대 이득값을 제1 최대 이득값 G1에서 제2 최대 이득값 G2로 증가시킬 수 있다. 즉, 저조도 환 경이 시작되는 0dB 구간의 시작 시점에는 고속 셔터(예를 들어, 1/200sec)가 적용되지만, 조도가 점차적으로 낮 아짐에 따라 저속 셔터(예를 들어, 1/2sec) 구간으로 진입하는 조도 구간을 G1에서 G2로 더 낮춤으로써 저조도 환경에서 고속 셔터 유지 시간을 좀 더 길게 확보할 수 있다. 이로 인해, 고속 셔터값이 유지되는 조도 구간이 늘어나 노이즈가 많아질 수 있지만 상대적으로 움직임 잔상 제거 효과는 저도도 구간에서 보다 오랫동안 유지될 수 있다. 본 명세서는 감시 카메라 영상 처리에 관한 것으로서, 감시 카메라는 저조도 환경에서 랜덤한 객체의 움직임을 최대한 고려해야 하는 바, 고속 셔터 유지시간이 상대적으로 길어짐으로 인한 노이즈 증가 보다는 그로 인한 모 션 블러 제거 효과가 더 클 수 있다. 도 10은 본 명세서의 일 실시예에 따라 노이즈 제거 강도를 조절하기 위한 감시 카메라의 영상 처리 방법의 흐 름도이다. 상기 노이즈 제거 강도 제어 방법은 감시 카메라의 프로세서(또는 제어부) 또는 영상 관리 서버의 프로세서(또 는 제어부)를 통해 구현될 수 있다. 이하 각 동작을 수행하는 프로세서(또는 제어부)는 감시 카메라 및/또는 영 상 관리 서버에 포함된 모듈 등일 수 있음을 밝혀둔다. 설명의 편의를 위해 이하, 감시 카메라의 프로세서에서 노이즈 제거 강도를 제어하는 것으로 설명한다. 감시 카메라의 프로세서는 감시 카메라의 영상 촬상부를 통해 획득된 영상 신호를 수신하고, 영상 프레임 에서 객체가 존재하는지 여부를 판단할 수 있다. 프로세서는 전술한 딥러닝 객체 인식 알고리즘(예를 들어, YOLO 알고리즘)을 이용하여 객체의 존재여부를 확인할 수 있다(S1000). 프로세서는 객체가 인식된 경우, 바운딩 박스(bounding box)를 객체 주변에 출력하고, 바운딩 박스의 꼭지점 좌표를 출력할 수 있다. 또한 제어부는 각 객체의 바운딩 박스 내의 중심 좌표를 산출할 수 있다. 프로세서는 제1 영상 프레임 및 제2 영상 프레임에서 각각 검출된 객체 정보에 기초하여 객체의 이동 속도 를 획득할 수 있다(S1010). 객체의 이동 속도를 산출하기 위해 프로세서는 제1 영상 프레임에서 검출된 적 어도 하나의 객체들에 순차적으로 객체 ID를 부여할 수 있다. 프로세서는 제1 영상 프레임의 후순위로 입 력되는 제2 영상 프레임에서도 동일하게 객체 ID를 부여하고, 각 객체의 중심 좌표를 출력할 수 있다. 프로세서 는 제1 영상 프레임 및 제2 영상 프레임의 중심 좌표의 변화(위치 변화)와, 영상 프레임의 획득 시간에 기 초하여 각 객체들의 이동 속도를 산출할 수 있다. 프로세서는 산출된 객체별 이동 속도에 평균 필터를 적 용함으로써, 객체의 평균 이동 속도를 산출할 수 있다. 프로세서는 영상에 포함된 객체의 이동 속도가 미리 정해진 값 이상인지 판단할 수 있다(S1020). 프로세서는 영상에 포함된 객체의 이동 속도가 ‘0’ 또는 미리 정해진 값 이하인 경우 기존 노이즈 제거 강도를 유지할 수 있다(S1030). 객체의 이동 속도가 0은 아니지만 노이즈 제거 강도를 변경할 필요가 없을 만큼 객체의 움직임 속도가 매우 느린 경우 노이즈 제거 강도를 변경하지 않을 수 있다. 한편, 프로세서는 영상에 포함된 객체의 이동 속도가 미리 정해진 값 이상으로 판단한 경우, 노이즈 제거 강도를 미리 정해진 비율만큼 낮출 수 있다(S1040). 예를 들어, 객체의 이동 속도에 따라 현재 설정된 노이즈제거 강도 대비 40%까지 감소될 수 있다. 한편, 본 명세서의 일 실시예는 객체의 이동이 처음 감지된 경우, 혹은 객체 이동 속도가 미리 정해진 임계치를 처음 초과한 경우 노이즈 제거 강도를 미리 정해진 제어폭 만큼 낮출 뿐 아니라, 노이즈 제거 강도가 감소된 이 후, 객체의 실시간 이동 상태를 즉각적으로 노이즈 제거 강도 제어에 반영할 수 있다. 프로세서는 객체의 출현 및/또는 움직임 등에 기초하여 처음 노이즈 제거 강도를 낮춘 후에, 추가적인 객 체의 이동 속도를 실시간으로 확인할 수 있다. 실시간 객체의 이동 속도 모니터링은 전술한 AI 객체 감지 알고 리즘을 통해 확인 가능하다. 프로세서는 추가적인 객체의 이동속도 변경 여부를 확인한 결과, 객체의 이동 속도가 추가적으로 증가하는 것으로 판단한 경우(S1050: 속도 증가), 속도 증가 비율에 대응하는 제어비율만큼 즉시 노이즈 제거 강도를 감소하도록 제어할 수 있다(S1060). 프로세서는 객체의 이동속도가 기 측정된 속 도에 비해 감소하는 것으로 판단한 경우(S1050: 속도 감소), 속도 감소 비율에 대응하는 제어 비율만큼 노이즈 제거 강도를 증가시키되, 객체 인식 오류에 따른 오작동을 최소화하기 위해 노이즈 제거 필터의 현재 강도를 일 정 시간 유지하는 휴지시간을 거친 후에, 선형적으로 최종 목표 강도만큼 선형적으로 증가되도록 제어할 수 있 다(S1070). 이에 따라, 본 명세서는 최초 객체 출현 및/또는 이동속도 증가에 따른 노이즈 제거 강도 감소 후에도 객체의 이동 속도가 실시간으로 변경됨에 따라 노이즈 제거 강도를 동적으로 변화시키되, 속도 증감 여부에 따라 노이 즈 제거 강도 제어 속도를 조절함으로써, 노이즈 제거 강도 변화에 따른 객체 인식 오류를 최소화할 수 있다. 이하 도 11 및 도 12를 통해 도 10에서 설명한 노이즈 제거 강도 제어 방법에 대하여 보다 구체적으로 설명한다. 도 11은 본 명세서의 일 실시예에 따라 객체 인식 유무에 따른 노이즈 제거 강도 변경을 설명하기 위한 도면이 다. 본 명세서의 일 실시에 따르면 감시 카메라 영상의 노이즈 제거 강도를 결정하는 요인은 센서 이득값과 영상 내 에서 인식된 객체의 이동 속도일 수 있다. 도 11을 참조하면, 감시 카메라 영상에 객체가 존재하지 않는 경우는 제1 노이즈 제거 강도 제어곡선(PN)에 따라 노이즈 제거 강도가 제어될 수 있다. 여기서 제1 노이즈 제거 강도 제어곡선은 객체의 유무와 관계없이 고정된 필터계수를 적용하는 경우일 수 있다. 한편, 감시 카메라 영상에 객체가 존재하는 경우, 객체의 이동 속도에 변화(증가, 감소 등)가 있는 경우, 프로 세서는 제2 노이즈 제거강도 제어곡선(NN)에 따라 노이즈 제거 강도를 제어할 수 있다. 여기서 제2 노이즈 제거강도 제어 곡선(NN)은 필터계수가 객체의 이동 속도에 따라 가변되므로 도 11의 그래프에서 노이즈 제거강 도가 동적으로 가변될 수 있다(참조 번호 1101). 여기서 제2 노이즈 제거강도 제어곡선(NN)의 최저값은 제1 노 이즈 제거강도 제어곡선(PN) 기준 60% 수준일 수 있으며, 객체의 평균 이동속도가 변화됨에 따라 참조번호 1101 범위에서 강도가 변경될 수 있다. 즉, 객체가 빠르게 움직일 경우 기존 강도에서 최대 40%까지 줄여 영상의 움 직임 잔상 현상을 제거한다. 그러나, 저조도 환경 중에서도 센서 이득값이 일정 수준 이상의 높은 값을 적용해야 하는 경우, 센서 신호 증폭 에 따라 발생하는 부가적인 노이즈로 인해 객체의 구분이 어려울 수 있다. 이 경우, 노이즈 제거강도를 추가적 으로 제어할 필요가 있다. 본 명세서의 일 실시예에 따르면 프로세서는 센서 이득 증폭양이 점차적으로 증 가되어 제1 이득값 G3에 도달한 경우(예를 들어, 42dB 이상의 센서 이득을 사용해야 하는 환경) 점차적으로 노 이즈 필터의 강도를 기존의 강도와 같은 수준으로 회복하여 제2 이득값 G4(예를 들어, 60dB)을 사용하는 시점 부터는 제1 노이즈 제거강도 제어곡선(PN)과 동일한 강도의 노이즈 제거필터를 적용할 수 있다. 즉, 이득값이 G3 이하의 환경에서 영상에 객체가 인식되지 않은 경우 제1 노이즈 제거강도 제어곡선(PN)에 따르고, 이득값이 G3과 G4 사이 구간에서 획득된 영상에서 객체의 이동을 감지하는 경우 프로세서는 노이즈 제거강도의 감소 폭을 최대 40%보다 작은 감소폭(예를 들어, 참조번호 1102)에 따라 노이즈 제거강도를 줄일 수 있다. 도 12는 본 명세서의 일 실시예에 따라 객체의 이동 속도에 따른 노이즈 제거 강도 변경을 설명하기 위한 도면 이다. 3D 노이즈 필터(3DNR)는 객체의 속도에 따라 동적으로 변화될 수 있다. 객체의 속도가 증가하면 동적 객체의 끌 림없는 영상을 획득할 수 있도록 노이즈 필터의 강도가 감소하며, 객체의 속도가 감소하면 깨끗한 영상을 획득 할 수 있도록 노이즈 필터의 강도가 증가될 수 있다. 반면 동적 객체의 영상 획득에 영향을 미치지 않는 2D 노 이즈 필터(2DNR) 필터는 객체의 움직임과 관계없이 도 11에서 설명한 제1 노이즈 제거강도 제어곡선(NN)에 따른노이즈 제어를 진행할 수 있다. 도 12를 참조하면, T1 시간에 객체의 움직임이 발생한 경우(GM) 프로세서는, 노이즈 필터의 강도는 즉시 감소시킨다. 이 때 노이즈 필터 강도의 감소량(RR1)은 객체의 속도에 비례하여 선형적으로 증가될 수 있다. T1~T2 구간에서 객체의 이동속도가 유지되는 경우 노이즈 필터 강도는 유지될 수 있다. 일 실시예에 따라, T2 시간에 객체의 이동 속도가 증가하는 경우(VI1, 프로세서는 노이즈 필터의 강도를 추가적으로 낮출 수 있다. 전술한 바와 같이, 노이즈 필터의 최대 감소량(MRR)은 객체가 존재하지 않은 상태에 서의 노이즈 필터 강도의 40% 수준일 수 있다. 일 실시예에 따라, T3 시간에 객체의 이동속도가 감소하거나, 객체의 움직임이 사라지는 경우 프로세서는 이동속도 증가의 경우와 달리 즉시 노이즈 필터의 강도를 높이지는 않는다. 프로세서는 객체의 이동속도 가 감소되는 경우(VD1),일정 시간 동안의 휴지시간(R)을 거친 후, 감소되는 이동속도의 추이에 따라 선형적으로 노이즈 제거 강도를 증가시킬 수 있다. 상기 휴지 시간은 감시 카메라 자체의 객체 인식 오류에 따른 오작동을 최소한으로 방지하기 위한 시간일 수 있다. 상기 휴지 시간 동안은 객체의 이동속도가 변경되기 전에 적용된 노 이즈 제거강도가 지속될 수 있다. 일 실시예에 따라, T4 및 T5 시간에서 각각 객체의 이동속도가 재차 증가(VI2,VI3) 경우 프로세서는 각각 의 객체 이동속도 변화에 따라 결정되는 감소폭에 따라 노이즈 제거강도를 줄일 수 있다. 일 실시예에 따라 전술한 휴지 시간(R) 동안은 객체의 속도 변화 전에 적용되는 노이즈 필터 강도가 지속되지만, 휴지 시간(R) 동안에 객체의 이동속도가 변화되는 경우가 있을 수 있다. 예를 들어, 프로세서(26 0)는 T6 시간에 객체의 이동속도 감소(VD2)를 감지한 후, 일정 시간의 휴지시간(R)을 적용하지만 상기 휴지 시 간(R) 동안 객체의 이동 속도가 증가함을 감지할 수 있다(VI4). 이 경우, 프로세서는 휴지시간(R)에도 불 구하고 즉시 노이즈 제거 강도를 객체의 이동 속도에 따라 감소시킬 수 있다. 일 실시예에 따라, 프로세서는 감시 카메라 영상에서 객체가 사라짐을 인식하는 경우(OD), 일정 시간의 휴 지시간(R)이 경과된 후 노이즈 제거 필터의 강도를 선형적으로 회복시킬 수 있다. 도 13은 객체 유무와 관계없이 고정된 노이즈 제거강도를 적용하는 예(a)와 본 명세서의 일 실시예에 따라 AI 자동 객체 인식 결과에 따른 노이즈 제거강도의 동적 변화 알고리즘을 적용한 영상(b) 비교한 것이다. (b)는 (a) 보다 상대적으로 모션 블러현상이 없으며 노이즈 최소화에 따른 보다 선명한 영상일 수 있다. 이상, 인공 지능 기반의 객체인식을 통해 객체의 유무에 따라, 객체의 이동속도에 따라 노이즈 제거강도를 동적 으로 가변 제어함으로써, 노이즈 및 모션 블러 효과를 최소화 시킬 수 있는 감시 카메라 영상의 처리 방법에 대 하여 설명하였다. 본 명세서는 AI 기반의 객체인식 알고리즘을 적용하는 것으로 설명하였으나, 인식된 객체의 평균 이동속도 값에 따른 노이즈 필터 강도의 감소폭의 산출과정에서도 인공지능이 적용될 수 있다. 일 실시예 에 따라, 전술한 객체의 평균 이동속도에 따른 노이즈 제거 강도의 제어폭은 최대 40% 의 감소폭을 가지며, 저 조도 환경이 더욱 심해지는 경우 미리 정해진 임계치(예를 들어, 42dB, 60dB)를 기준으로 노이즈 제거강도의 제 어폭을 달리 적용되도록(40% 미만의 감소폭 적용) 학습 모델을 훈련하여 학습 모델을 생성할 수도 있다. 상기 학습 모델은 객체의 이동속도 및 조도값이 입력 데이터로 입력된 경우, 상기 이동속도에 따른 노이즈 필터 감소 량을 자동으로 산출할 수 있으며, 저조도 조건에 따라 노이즈와 모션 블러를 최소화할 수 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있으며, 또한 캐리어 웨이브(예를 들어, 인터넷을 통한 전송)의 형태로 구현되는 것도 포함한다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항 의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함 된다. 산업상 이용가능성 본 명세서는 감시 영상 카메라, 감시 영상 카메라시스템, 감시 영상 카메라를 이용한 서비스 제공 분야 등에 적 용될 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13"}
{"patent_id": "10-2023-7035642", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 관한 이해를 돕기 위해 상세한 설명의 일부로 포함되는, 첨부 도면은 본 명세서에 대한 실시예를 제공하고, 상세한 설명과 함께 본 명세서의 기술적 특징을도 설명한다. 도 1은 본 명세서의 일 실시예에 따른 감시 카메라의 영상 처리 방법을 구현하기 위한 감시 카메라 시스템을 설 명하기 위한 도면이다. 도 2는 본 명세서의 일 실시예에 따른 감시 카메라의 개략적인 블록도이다. 도 3은 본 명세서의 일 실시예에 따른 감시 카메라 영상의 분석에 적용되는 AI 장치(모듈)을 설명하기 위한 도 면이다. 도 4는 본 명세서의 일 실시예에 따른 감시 카메라의 영상 처리 방법의 흐름도이다. 도 5는 본 명세서의 일 실시예에 따라 객체 인식 방법의 일 예를 설명하기 위한 도면이다. 도 6은 본 명세서의 일 실시예에 따라 객체 인식 방법의 다른 예를 설명하기 위한 도면이다. 도 7은 본 명세서의 일 실시예에 따라 인공지능 알고리즘을 이용한 객체 인식 과정을 설명하기 위한 도면이다. 도 8은 도 7에서 인식된 객체의 평균 이동속도를 산출하는 과정을 설명하기 위한 도면이다. 도 9는 본 명세서의 일 실시예에 따라 객체 인식 유무에 따른 셔터 속도 변경을 설명하기 위한 도면이다. 도 10은 본 명세서의 일 실시예에 따라 노이즈 제거 강도를 조절하기 위한 감시 카메라의 영상 처리 방법의 흐 름도이다. 도 11은 본 명세서의 일 실시예에 따라 객체 인식 유무에 따른 노이즈 제거 강도 변경을 설명하기 위한 도면이 다. 도 12는 본 명세서의 일 실시예에 따라 객체의 이동 속도에 따른 노이즈 제거 강도 변경을 설명하기 위한 도면 이다. 도 13은 객체 유무와 관계없이 고정된 노이즈 제거강도를 적용하는 예와 본 명세서의 일 실시예에 따라 AI 자동 객체 인식 결과에 따른 노이즈 제거강도의 동적 변화 알고리즘을 적용한 영상을 비교한 것이다. 본 발명에 관한 이해를 돕기 위해 상세한 설명의 일부로 포함되는, 첨부 도면은 본 발명에 대한 실시예를 제공 하고, 상세한 설명과 함께 본 발명의 기술적 특징을 설명한다."}
