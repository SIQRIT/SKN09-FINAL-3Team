{"patent_id": "10-2022-0173274", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0087983", "출원번호": "10-2022-0173274", "발명의 명칭": "인공지능을 이용한 호흡상태 예측 시스템 및 그 방법", "출원인": "(주)비타", "발명자": "정기섭"}}
{"patent_id": "10-2022-0173274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "천장 또는 벽면에 설치되며 사용자의 움직임을 감지하는 움직임 감지 부;상기 움직임 감지센서로부터 측정된 상기 사용자의 데이터를 이용하여 사용자의 호흡, 심박 및 공간데이터를 추출하는 데이터 추출부; 상기 기 저장되어 있는 호흡, 심박 및 공간데이터에 따른 사용자의 상태 데이터를 CNN(Convolutional NeuralNetwork) 및 RNN(Recurrent neural network)을 이용하여 각각 학습하여 하나 이상의 인공지능을 제작하는 인공지능 제작부; 및상기 하나 이상의 인공지능에 상기 추출된 호흡, 심박 및 공간데이터를 입력하여 상기 사용자의 상태 데이터를추출하고, 추출된 하나이상의 데이터를 트리알고리즘에 적용하여 상기 사용자의 상태를 추출하는 상태 추출부를포함하는 호흡상태 예측 시스템."}
{"patent_id": "10-2022-0173274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "에 있어서, 상기 상태 추출부는, 상기 인공지능 제작부로부터 제작된 하나 이상의 인공지능 별로 가중치를 적용하여 상기 사용자의 호흡 상태를예측하는 호흡상태 예측 시스템."}
{"patent_id": "10-2022-0173274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서, 상기 인공지능 제작부는, 상기 호흡 및 심박데이터에 대한 시계열 데이터를 CNN을 이용하여 학습하고, 상기 호흡 및 심박데이터에 대한주파수 스펙토그램 데이터를 RNN을 이용하여 각각 학습하는 호흡상태 예측 시스템."}
{"patent_id": "10-2022-0173274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서, 상기 인공지능 제작부는, 호흡 및 심박데이터에 대한 시계열 데이터를 CNN을 이용하여 학습한 데이터와 상기 모션 데이터와 거리 데이터를 RNN을 이용하여 각각 학습한 데이터를 이용하여 인공지능을 제작하는 호흡상태 예측 시스템."}
{"patent_id": "10-2022-0173274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서, 상기 인공지능 제작부는, 호흡 및 심박데이터에 대한 시계열 데이터를 RNN을 이용하여 학습한 데이터와 상기 모션 데이터와 거리 데이터를 RNN을 이용하여 각각 학습한 데이터를 이용하여 인공지능을 제작하는 호흡상태 예측 시스템. 공개특허 10-2024-0087983-3-청구항 6"}
{"patent_id": "10-2022-0173274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서, 상기 인공지능별 가중치의 합은 1인 호흡상태 예측 시스템."}
{"patent_id": "10-2022-0173274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "천장 또는 벽면에 설치되며 사용자의 움직임을 감지하는 감지단계;상기 움직임 감지센서로부터 측정된 상기 사용자의 데이터를 이용하여 사용자의 호흡, 심박 및 공간데이터를 추출하는 데이터 추출단계;상기 기 저장되어 있는 호흡, 심박 및 공간데이터에 따른 사용자의 상태 데이터를 CNN(Convolutional NeuralNetwork) 및 RNN(Recurrent neural network)을 이용하여 각각 학습하여 하나 이상의 인공지능을 제작하는 인공지능 제작단계; 및 상기 하나 이상의 인공지능에 상기 추출된 호흡, 심박 및 공간데이터를 입력하여 상기 사용자의 상태 데이터를추출하고, 추출된 하나이상의 데이터를 트리알고리즘에 적용하여 상기 사용자의 상태를 추출하는 상태추출단계;를 포함하는 호흡상태 예측 방법."}
{"patent_id": "10-2022-0173274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서, 상기 데이터 추출단계는, 상기 호흡 및 심박 데이터를 시계열 데이터와 주파수 스펙토그램 데이터로 각각 분류하고, 상기 공간데이터는모션 데이터와 거리 데이터인 호흡상태 예측 방법."}
{"patent_id": "10-2022-0173274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서, 상기 인공지능 제작단계는, 상기 호흡 및 심박데이터에 대한 시계열 데이터를 CNN을 이용하여 학습하고, 상기 호흡 및 심박데이터에 대한주파수 스펙토그램 데이터를 RNN을 이용하여 각각 학습하는 호흡상태 예측 방법."}
{"patent_id": "10-2022-0173274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 10에 있어서, 상기 인공지능 제작단계는, 공개특허 10-2024-0087983-4-호흡 및 심박데이터에 대한 시계열 데이터를 CNN을 이용하여 학습한 데이터와 상기 모션 데이터와 거리 데이터를 RNN을 이용하여 각각 학습한 데이터를 이용하여 인공지능을 제작하는 호흡상태 예측 방법."}
{"patent_id": "10-2022-0173274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서, 상기 인공지능 제작단계는, 호흡 및 심박데이터에 대한 시계열 데이터를 RNN을 이용하여 학습한 데이터와 상기 모션 데이터와 거리 데이터를 RNN을 이용하여 각각 학습한 데이터를 이용하여 인공지능을 제작하는 호흡상태 예측 방법."}
{"patent_id": "10-2022-0173274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 9에 있어서, 상기 상태 추출단계는, 상기 인공지능 제작부로부터 제작된 하나 이상의 인공지능 별로 가중치를 적용하여 상기 사용자의 호흡 상태를예측하는 호흡상태 예측 방법."}
{"patent_id": "10-2022-0173274", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 13에 있어서, 상기 인공지능별 가중치의 합은 1인 호흡상태 예측 방법."}
{"patent_id": "10-2022-0173274", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 수면단계 예측 시스템 및 그 방법에 관한 것이다. 이러한 본 발명의 실시예에 따르면, 천장 또는 벽면에 설치되며 사용자의 움직임을 감지하는 움직임 감지 부, 상 기 움직임 감지센서로부터 측정된 상기 사용자의 데이터를 이용하여 사용자의 호흡, 심박 및 공간데이터를 추출 하는 데이터 추출부, 상기 기 저장되어 있는 호흡, 심박 및 공간데이터에 따른 사용자의 상태 데이터를 CNN(Convolutional Neural Network) 및 RNN(Recurrent neural network)을 이용하여 각각 학습하여 하나 이상의 인공지능을 제작하는 인공지능 제작부 및 상기 인공지능 제작부에 상기 추출된 호흡, 심박 및 공간데이터를 입력 하여 상기 사용자의 상태 데이터를 추출하고, 추출된 하나이상의 데이터를 트리알고리즘에 적용하여 상기 사용자 의 상태를 추출하는 상태 추출부를 포함한다."}
{"patent_id": "10-2022-0173274", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 호흡상태 예측 시스템 및 그 방법에 관한 것이다."}
{"patent_id": "10-2022-0173274", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "수면 다원 검사(Polysomnography)는 수면장애를 진단하기 위한 검사로서, 수면 중 뇌파, 안구운동, 근육의 움직 임, 호흡, 심전도 등을 종합적으로 측정하고 동시에 수면 상태를 비디오로 녹화한 후, 측정 및 녹화된 기록을 분석하여 수면과 관련된 질환을 진단하고 치료방침을 정하는데 사용되고 있다. 전술한 수면 다원 검사는 수면 무호흡증, 수면 장애, 수면 보행증 등의 증상을 진단할 수 있으며, 이러한 질환 들을 판단하기 위한 지수로서, 수면단계(Sleep stage), 무호흡 지수(Apnea-hypopnea index, AHI), 상기도 저항 증후군(Respiratory effort-related arousals; RERA) 지수 등이 사용되고 있다. 한편, 수면 다원 검사는 전문 인력들이 다양한 센서를 통해 측정된 환자의 생체 데이터들을 조합하여 전술한 지수들을 판단하는 매뉴얼 수면 스코어링(Manual sleep scoring) 방법을 이용하고 있다. 또한, 수면 스코어링은 전문 인력에 의해 수작업으로 진행 됨에 따라, 소요 시간이 너무 길어진다는 문제가 있 다. 실제, 숙련된 전문 인력이 한명의 환자에 대한 수면 스코어링을 진행하는데 소요되는 시간은 약 3시간 내지 4시간인 것으로 알려져 있다. 결과적으로, 수면 질환의 정확한 진단을 받기 위해서는 훈련 받은 전문가 있는 특별한 시설 및 장비를 갖춘 수 면센터에서 1박 2일의 시간을 가지고 실시 해야 만 한다. 불면증, 기면증 등 수면 관련 질환을 진단하는데 있어 서 환자의 수면단계를 분석하기 위해 주로 이용되는 생체신호모니터링 장치는 EEG이다. 이외에도 보조적으로EOG와 chin-EMG를 이용하여 수면단계에 대한 판단을 진행할 수 있다. 일반적으로 불면증 등과 같은 수면 질환을 판정하는 절차는 다음과 같다. 일반적으로 수면 다원 검사 센터를 보 유한 병원에서 일정 시간 수면 중 EEG, EOG, Chin-EMG를 측정, 측정된 결과에 대해 자격을 가진 전문 기사가 수 면 전문의의 감독하에 수면단계 분석을 수작업으로 진행하여결과 도출, 도출된 결과를 토대로 수면 전문의가 수 면 질환에 대해 진단, 불면증, 기면증 등 수면 질환 유무를 진단, 즉, 수면단계의 판정은 수면 관련 질환의 판 정을 하는데 있어서 진단을 위한 기본 데이터가 되기 때문에 수면단계 판정의 정확도는 진단을 위해 매우 중요 한 자료가 된다. 그러나 앞선 언급한 바와 같이, 비록 훈련된 전문가들에 의해서 수면단계 분석을 수작업으로 진행하더라도 환자 마다 다른 뇌파의 비 정형성 및 판정의 기준이 되는 AASM의 스코어링 룰(scoring rule)의 복잡함 등으로 인해 오차가 크게 발생할 수 밖에 없다. 특히, 수면 방추(sleep spindle) 및 K-complexes 신호에 따른 판정 유무로 인해 수면단계를 나누는데 있어서 전문가간 판정이 일치하지 않는 경우가 종종 발생한다. 이와 더불어 평균 8시 간 정도의 수면 다원 검사 결과를 일일이 사람이 판독하면서 발생하는 휴먼 에러 역시 오차에 영향을 준다. 이러한, 수면 다원 검사의 문제점은 특별히 훈련 받은 사람과 시설을 이용함에 따른 경제적 문제가 있고, 익숙 하지 않은 환경과 장비를 갖춘 상태에서 1박 2일 수면을 취함에 따른 환경 변화에 따른 부정확한 실험 결과를 제시하여 first night effect 및 개인별 육체적 심리적 상태에 따른 수면 변화를 부정확한 실험 결과로 제시하 는 문제점이 있다. 또한, 검사 결과 확인을 위해 환자가 여러 번 병원을 방문해야하는 불편함이 있고, 개인별로 장시간 저렴한 가 격으로 수면에 관한 질환 진단에 대한 필요성이 의사 및 환자들로부터 요구되는 문제점이 존재한다. 기존에는 수면 단계를 예측하는데 EEG, EOG, EMG 등 PSG를 활용하여, 수면의 단계를 계산하여, 수면의 질을 측 정하여, 수면질병의 원인 및 치료후 개선효과를 확인하였으나, 기존 PSG검사를 위한 센서 착용은 수면자체의 질 을 떨어 뜨리며, 연속적인 장기 모니터링이 어렵다. 그리고 수면 단계에는 AASM의 표준이 존재하지만, 수면 기사별로 일치율이 61% 수준에 불과하며, 레이더의 HR의 RRI(R to R peak Interval)는 정확도가 떨어진다. 본 발명의 배경이 되는 기술은 대한민국 등록특허 제10-23714436호(2022.03.08. 공고) 및 등록특허 10- 1235441(2013.02.20. 공고)에 개시되어 있다."}
{"patent_id": "10-2022-0173274", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기 문제점을 해결하기 위해 도출된 것으로, 인공지능을 통해 사용자의 호흡상태와 수면장애를 함께 확인가능하도록하고, 인공지능의 정확도를 향상시키기 위한 인공지능을 이용한 호흡상태 예측 시스템 및 그 방 법의 제공을 목적으로 한다."}
{"patent_id": "10-2022-0173274", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 천장 또는 벽면에 설치되며 사용자의 움직임을 감지하는 움직임 감지 부, 상기 움 직임 감지센서로부터 측정된 상기 사용자의 데이터를 이용하여 사용자의 호흡, 심박 및 공간데이터를 추출하는 데이터 추출부, 상기 기 저장되어 있는 호흡, 심박 및 공간데이터에 따른 사용자의 상태 데이터를 CNN(Convolutional Neural Network) 및 RNN(Recurrent neural network)을 이용하여 각각 학습하여 하나 이상의 인공지능을 제작하는 인공지능 제작부 및 상기 하나 이상의 인공지능에 상기 추출된 호흡, 심박 및 공간데이터 를 입력하여 상기 사용자의 상태 데이터를 추출하고, 추출된 하나이상의 데이터를 트리알고리즘에 적용하여 상 기 사용자의 상태를 추출하는 상태 추출부를 포함한다. 상기 데이터 추출부는 상기 호흡 및 심박 데이터를 시계열 데이터와 주파수 스펙토그램 데이터로 각각 분류하고, 상기 공간데이터는 모션 데이터와 거리 데이터일 수 있다. 상기 인공지능 제작부는 상기 호흡 및 심박데이터에 대한 시계열 데이터를 CNN을 이용하여 학습하고, 상기 호흡 및 심박데이터에 대한 주파수 스펙토그램 데이터를 RNN을 이용하여 각각 학습할 수 있다. 상기 인공지능 제작부는 호흡 및 심박데이터에 대한 시계열 데이터를 CNN을 이용하여 학습한 데이터와 상기 모 션 데이터와 거리 데이터를 RNN을 이용하여 각각 학습한 데이터를 이용하여 인공지능을 제작할 수 있다. 상기 인공지능 제작부는 호흡 및 심박데이터에 대한 시계열 데이터를 RNN을 이용하여 학습한 데이터와 상기 모 션 데이터와 거리 데이터를 RNN을 이용하여 각각 학습한 데이터를 이용하여 인공지능을 제작할 수 있다. 상기 상태 추출부는 상기 인공지능 제작부로부터 제작된 하나 이상의 인공지능 별로 가중치를 적용하여 상기 사 용자의 호흡 상태를 예측할 수 있다. 상기 인공지능별 가중치의 합은 1일 수 있다. 본 발명의 다른 실시예에 따르면, 천장 또는 벽면에 설치되며 사용자의 움직임을 감지하는 감지단계, 상기 움직 임 감지센서로부터 측정된 상기 사용자의 데이터를 이용하여 사용자의 호흡, 심박 및 공간데이터를 추출하는 데 이터 추출단계, 상기 기 저장되어 있는 호흡, 심박 및 공간데이터에 따른 사용자의 상태 데이터를 CNN(Convolutional Neural Network) 및 RNN(Recurrent neural network)을 이용하여 각각 학습하여 하나 이상의 인공지능을 제작하는 인공지능 제작단계 및 상기 하나 이상의 인공지능에 상기 추출된 호흡, 심박 및 공간데이 터를 입력하여 상기 사용자의 상태 데이터를 추출하고, 추출된 하나이상의 데이터를 트리알고리즘에 적용하여 상기 사용자의 상태를 추출하는 상태 추출단계;를 포함한다."}
{"patent_id": "10-2022-0173274", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기 방법 및 특징을 갖는 본 발명에 따르면, 복수의 데이터를 서로다른 인공지능으로 학습하여 사용하기 때문 에 기존의 하나의 데이터만을 이용하여 학습하는 인공지능보다 정확도가 높은 인공지능을 제작할 수 있다. 또한, 사용자의 움직임과 호흡 및 심박을 이격된 위치에서 측정하기 때문에 사용자 친화적으로 데이터를 획득할 수 있다. 또한, 본 발명에 따른 인공지능을 이용함으로써, 사용자의 호흡상태와 호흡 중증도를 제공할 수 있다."}
{"patent_id": "10-2022-0173274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있는 바, 구현예(態樣, aspect)(또는 실시 예)들을 본문에 상세하게 설명하고자 한다. 그러나 이는 본 발명을 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 명세서에서 사용한 용어는 단지 특정한 구현예(태양, 態樣, aspect)(또는 실시예)를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, ~포함하다~ 또는 ~이루어진다~ 등의 용어는 명세서 상에 기재된 특징, 숫자, 단 계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배 제하지 않는 것으로 이해되어야 한다.다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 본 명세서에서 기재한 ~제1~, ~제2~ 등은 서로 다른 구성 요소들임을 구분하기 위해서 지칭할 것일 뿐, 제조된 순서에 구애받지 않는 것이며, 발명의 상세한 설명과 청구범위에서 그 명칭이 일치하지 않을 수 있다. 도 1은 본 발명의 실시예에 따른 호흡상태 예측 시스템을 설명하기 위한 도면이고, 도 2는 본 발명의 실시예에 따른 추출된 데이터를 설명하기 위한 도면이며, 도 3은 본 발명의 실시예에 따른 주파수 스펙트럼 데이터를 설 명하기 위한도면이고, 도 4는 본 발명의 실시예에 따른 트리 알고리즘을 설명하기 위한 도면이다. 도 1에서 나타낸 것처럼, 본 발명의 실시예에 따른 호흡상태 예측 시스템은 움직임 감지 부, 데이터 추출부, 인공지능 제작부, 및 상태 추출부를 포함한다. 먼저, 움직임 감지 부는 실내의 천장 또는 벽면에 부착되어 레이더를 이용하여 실내에서의 움직임을 감지 한다. 이때, 움직임 감지센서는 실외의 다른 위치에 설치될 수 있으며, 특히 빌딩이나 다른 건물이 붕괴되 었을 때, 설치하여 사용할 수 있다. 즉, 본 발명의 실시예에 따른 비접촉 호흡상태 모니터링 시스템은 실 내외 없이 모든곳에 설치되어 운용될 수 있다. 또한, 움직임 감지센서는 레이더를 사용하는데 레이더의 경 우, 음파나 라이다를 사용하는 경우 건물이 붕괴되었을시에는 사용을 못한다는 단점이 있어, 본 발명에서는 레 이더만을 사용한다. 다음으로, 데이터 추출부는 움직임 감지센서로부터 움직임 감지센서로부터 측정된 상기 사용자의 데 이터를 이용하여 사용자의 호흡, 심박 및 공간데이터를 추출한다. 이때, 데이터 추출부를 통해 추출된 데 이터는 도 2에서 나타낸 것처럼, 각각 심박데이터, 호흡데이터를 추출할 수 있으며, 공간데이터는 사용자의 움 직임 데이터와 움직임 감지센서로부터 사용자 까지의 거리 데이터를 의미한다. 이러한 데이터 추출부(12 0)는 호흡 및 심박 데이터를 시계열 데이터와 주파수 스펙토그램 데이터로 각각 분류한다. 도 2에서 나타낸 데 이터는 시간에 따른 데이터를 의미하며, 데이터 추출부는 도 3에서 나타낸 것과 같이 주파수 스펙토그램 데이터를 추출할 수 있다. 다음으로, 인공지능 제작부는 기 저장되어 있는 호흡, 심박 및 공간데이터에 따른 사용자의 상태 데이터를 CNN(Convolutional Neural Network) 및 RNN(Recurrent neural network)을 이용하여 각각 학습하여 하나 이상의 인공지능을 제작한다. 즉, 인공지능 제작부는 기 저장되어 있는 호흡 및 심박데이터에 대한 시계열 데이터를 CNN을 이용하여 학 습하고, 기 저장되어 있는 호흡 및 심박데이터에 대한 주파수 스펙토그램 데이터를 RNN을 이용하여 각각 학습한 다. 그리고 모션 데이터와 거리 데이터는 RNN을 이용하여 학습한다. 호흡 및 심박데이터의 경우 시계열적 데이 터와 주파수 스펙토그램 데이터를 함께 포함하고 있어 각각을 CNN 및 RNN을 이용하여 학습하고, 모션데이터와 거리데이터는 주파수 계열 데이터만 포함하고있어 RNN을 이용하여 학습한다. 이러한 인공지능 제작부는 호 흡 및 심박데이터에 대한 시계열 데이터를 CNN을 이용하여 학습한 데이터와 모션 데이터와 거리 데이터를 RNN을 이용하여 각각 학습한 데이터를 이용하여 인공지능을 제작하고, 호흡 및 심박데이터에 대한 주파수 스펙토그램 데이터를 RNN을 이용하여 학습한 데이터와 모션 데이터와 거리 데이터를 RNN을 이용하여 각각 학습한 데이터를 이용하여 인공지능을 제작한다. 또한, 인공지능 제작부는 호흡 데이터에 대한 시계열 데이터를 CNN, 심박 데이터에 대한 주파수 스펙토그램 데이터를 RNN, 모션 데이터와 거리 데이터를 RNN를 이용하여 인공지능을 제작 하고, 심박 데이터에 대한 시계열 데이터를 CNN, 호흡 데이터에 대한 주파수 스펙토그램 데이터를 RNN, 모션 데 이터와 거리 데이터를 RNN를 이용하여 인공지능을 제작한다. 이렇게 인공지능 제작부는 각각의 데이터를 이용하여 복수개의 인공지능을 제작할 수 있다. 이때, 인공지능 제작부는 기 저장되어 있는 데이터 뿐만 아니라 후술할 상태 추출부를 통해 형성된 결과를 함께 학습 데이터로 이용하여 인공지능의 정확도를 높이도록 함께 학습할 수 있다. 즉, 인공지능 제작부는 복수의 데이터를 서로다른 데이터로 학습하여 하나 이상의 인공지능을 제작할 수 있다. 본 발명의 실시예에서 인공지능 제작부는 4개의 인공지능을 제작한 것으로 설명하였지만, 4개보다 더 많은 수의 인공지능을 제작 할 수 있다. 본 발명에서 사용되는 학습모델인 CNN과 RNN의 경우 현재 널리 사용되는 것으로써, CNN(Convolutional Neural Networks)은 이미지의 패턴을 분석하는 것으로, 하나 이상의 convolutional layer를이용하여 각각의 이미지에 대한 패턴을 분석하여, 각각의 이미지에 대한 특징을 추출하는 것이며, RNN(Recurrent Neural Networks)은 히든 노드가 방향을 가진 엣지로 연결돼 순환구조를 이루는(directed cycle) 인공신경망의 한 종류로 음성, 문자 등 순차적으로 등장하는 데이터 처리를 위해 사용한다. 이러한 알고 리즘은 본 발명에서는 시계열 데이터 및 프리퀀시 스펙토그램을 학습하기 위해 CNN과 RNN을 이용하고, 모션데이 터와 거리데이터는 RNN을 이용하여 학습한다. 다음으로, 상태 추출부는 인공지능 제작부를 통해 제작된 하나 이상의 인공지능에 추출된 호흡, 심박 및 공간데이터를 입력하여 사용자의 상태 데이터를 추출하고, 추출된 하나이상의 데이터를 트리알고리즘에 적용 하여 사용자의 상태를 추출한다. 이때, 사용자의 상태는 호흡 상태에 따라 0, 1, 2로 나타낼 수 있으며, 중증도 에 따라, 0, 1, 2 및 3으로 각각 나타낼 수 있다. 도 4에서 나타낸 것처럼, 상태 추출부는 N개의 인공지능 을 통해 나온 결과값(Result-1, Result-2 내지 Result-N)을 이용하여 사용자의 현재 상태를 추출한다. 이때, 도 4에서 나타낸 것과 같이 트리 알고리즘은 majority voting(최대값) 또는 averaging(평균)을 이용하여 최종 결과 물을 추출할 수 있다. 이때, 각각의 인공지능1 내지 인공지능N은 서로다른 크기를 가지는 가중치 값을 가질 수 있으며, N개의 가중치 값의 합은 1로 설정될 수 있다. 이하에서는 도 5 내지 도 7을 이용하여 본 발명의 실시예에 따른 호흡상태 예측 방법을 설명한다. 도 5는 본 발 명의 실시예에 따른 호흡상태 예측 방법을 설명하기 위한 순서도이고, 도 6 및 도 7은 본 발명의 실시예에 따른 감지 단계를 설명하기 위한 도면이다. 도 5에서 나타낸 것처럼, 호흡상태 예측 방법은 감지단계(S510), 추출단계(S520), 인공지능 제작단계(S530), 상 태 추출단계(S540)를 포함한다. 먼저, 감지단계(S510)는 움직임 감지 부를 이용하여 천장 또는 벽면에 설치되며 사용자의 움직임을 감지한 다. 이때, 움직임 감지 부는 획득된 거리 방위각 히트맵의 범위 내에 있는 가장 큰 신호 2개를 각각 가슴 움직임 데이터 및 복부 움직임 데이터로 설정한다. 즉, 움직임 감지 부는 측정된 움직임 데이터 중에서 최 대값으로 측정되는 부분의 위치를 사용자의 가슴이 움직이는 위치로 설정하고, 설정된 위치의 움직임에 대한 값 을 가슴 움직임 데이터로 추출하고, 측정된 움직임 데이터 중에서 다음번째 최대값으로 측정되는 부분의 위치를 사용자의 복부가 움직이는 위치로 설정하고, 설정된 위치의 움직임에 대한 값을 상기 복부 움직임 데이터로 추 출한다. 즉, 도 4에서 나타낸 것과 같이 기준점인 움직임 감지센서로부터 각각의 거리에 존재하는 푸리에 트랜스폼 데이터를 획득하고, 획득한 상태에서 피크 알고리즘을 이용하여 최대 값과 다음번째 최대 값을 추출한다. 이때, 도 4에서 나타낸 것과 같은 붉은색 선 사이의 거리는 사용자의 가슴과 복부사이의 거리를 의미하며 평균 70cm사 이의 거리일 수 있으며, 사용자에 따라서 가변될 수 있는 거리를 의미한다. 즉, 움직임 감지 부는 도 4에 서 나타낸 것과 같이 붉은색선 사이에서 피크 알고리즘을 이용하여 최대값과 다음번째 최대 값을 각각 획득한다. 그리고, 움직임 감지 부는 최대값이 있는 위치를 가슴의 위치로 다음번째 최대값이 있는 위치를 복부의 위치고 설정한다. 그리고 움직임 감지 부는 도 5에서 나타낸 것과 같이 시간에 따라 측정된 가슴 및 복부의 움직임 데이터를 그래프화하여 나타낼 수 있다. 다음으로, 움직임 감지 부는 추출된 복부 움직임 데이터 및 가슴 움직임 데이터를 분석하여 사용자의 호흡 상태를 분석한다. 먼저, 움직임 감지 부는 측정된 각각의 복부 움직임 데이터 및 가슴 움직임 데이터의 미분값을 연산하고, 연산된 미분값을 이용하여 가슴 각도값 및 복부 각도값을 아래의 수학식 1 및 수학식 2와 같이 연산한다. 수학식 1 수학식 2"}
{"patent_id": "10-2022-0173274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이때, 은 가슴 각도값이고, 는 복부 각도값을 나타내며, 및 는 각각 가슴 움직임 데이터 및 복부 움직임 데이터의 미분값을 의미한다. 즉, 호흡상태 분석장치는 도 4에서 나타낸 것과 같이 시간에 따라 측정된 데이터에 대하여 가슴 각도값과 복부 각도값을 실시간으로 연산할 수 있다. 이렇게 연산된 가슴 각도값과 복부 각도값은 측정시간에 따른 값으로 실시간으로 측정되는 데이터 값을 이용하여 연산할 수 있다. 그러면, 움직임 감지 부는 연산된 가슴 각도값과 복부 각도값을 아래의 수학식 3에 적용하여 호흡역학불안 전성(Respiratory mechanic instability, RMI)값을 추출한다. 수학식 3"}
{"patent_id": "10-2022-0173274", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "즉, 수학식 3에서 나타낸 것과 같이 호흡역학불안전성(RMI) 값은 가슴 각도값과 복부 각도값의 차의 절대값이다. 여기서, 호흡역학불안전성(RMI)의 경우 사람이 호흡시 가슴과 복부의 움직임이 동일한 경우에는 정 상이지만, 가슴과 복부의 움직임이 다른 경우에는 비정상 상태를 의미한다. 그러면, 움직임 감지 부는 연산된 호흡역학불안전성(RMI)의 값이 임계값( )보다 크게 연산되는 시간대의 값을 추출한다. 이때, 임계값( )은 기 설정된 각도값을 의미하며, 본 발명의 실시예에서는 10°로 설정되어 사용되지만, 임계값( )은 호흡상태 예측 시스템이 사용되는 위치에 따라 변경되어 사용될 수 있다. 다음으로, 데이터 추출단계(S520)는 움직임 감지센서로부터 측정된 상기 사용자의 데이터를 이용하여 사용자의 호흡, 심박 및 공간데이터를 추출하고, 인공지능 제작단계(S530)는 기 저장되어 있는 호흡, 심박 및 공간데이터 에 따른 사용자의 상태 데이터를 CNN(Convolutional Neural Network) 및 RNN(Recurrent neural network)을 이 용하여 각각 학습하여 하나 이상의 인공지능을 제작한다. 그러면 상기에서 설명한 바와동일하며 각각의 데이터 추출단계(S520) 및 인공지능 제작단계(S530)의 설명은 생 략하기로 한다. 다음으로, 상태 추출단계(S540)는 제작된 하나 이상의 인공지능에 추출된 호흡, 심박 및 공간데이터를 입력하여 사용자의 상태 데이터를 추출하고, 추출된 하나이상의 데이터를 트리알고리즘에 적용하여 사용자의 상태를 추출 한다. 예를 들어, 제작된 인공지능의 개수가 6개이고 각각의 인공지능을 통해 추출된 사용자의 상태 데이터가 0,0,1,0,2,1 이라고 하면, 상태 추출부는 추출된 데이터 중에서 가장 많은 0을 현재 사용자의 상태로 추출 한다.또한, 본 발명의 실시예에 따른 호흡상태 예측 시스템은 학습하는 데이터에 따라 호흡상태 또는 호흡장애 지수 값을 추출할 수 잇다. 이때, 호흡장애지수 값(RDI)은 수면장애를 진단하기 위한 기준으로 정상, 경증, 중 증도, 중증 상태를 제공할 수 있다. 이렇게 사용자의 상태를 추출함으로써, 호흡상태 예측 시스템의 정확 도를 향상시킬 수 있을 뿐만 아니라 학습되는 데이터의 결과를 변경함으로써, 사용자의 수면장애를 함께 진단할 수 있다. 이상에서 첨부된 도면을 참조하여 설명한 본 발명은 통상의 기술자에 의하여 다양한 변형 및 변경이 가능하고, 청구범위를 통해 한정되지 않은 이러한 변형 및 변경은 본 발명의 권리범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2022-0173274", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 호흡상태 예측 시스템을 설명하기 위한 도면이다. 도 2는 본 발명의 실시예에 따른 추출된 데이터를 설명하기 위한 도면이다. 도 3은 본 발명의 실시예에 따른 주파수 스펙트럼 데이터를 설명하기 위한도면이다. 도 4는 본 발명의 실시예에 따른 트리 알고리즘을 설명하기 위한 도면이다. 도 5는 본 발명의 실시예에 따른 호흡상태 예측 방법을 설명하기 위한 순서도이다. 도 6 및 도 7은 본 발명의 실시예에 따른 감지 단계를 설명하기 위한 도면이다."}
