{"patent_id": "10-2023-0001007", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0166865", "출원번호": "10-2023-0001007", "발명의 명칭": "영상에서 통계모델기반 오검출 제거 알고리즘", "출원인": "한화비전 주식회사", "발명자": "박성연"}}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 처리장치에서 오검출 제거 방법에 있어서,촬영장치로부터 획득된 영상에서 관심객체 인식모델에 기초하여 관심객체를 검출하는 단계;제1 오검출 필터링 모델에 기초하여 상기 관심객체의 특징기반의 오검출을 제거하는 단계;제2 오검출 필터링 모델에 기초하여 상기 관심객체의 색상 기반 오검출을 제거하는 단계; 및상기 오검출이 제거된 최종 관심객체를 획득하는 단계;를 포함하는 영상 처리장치의 오검출 제거 방법."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 제1 오검출 필터링 모델을 학습시키는 단계;를 더 포함하고,상기 제1 오검출 필터링 모델을 학습시키는 단계는,미리 지정된 상기 관심 객체의 특정 벡터를 추출하는 단계; 및상기 특징 벡터에 기초하여 상기 관심 객체의 좌표 공간상 분포를 모델링하는 단계;를 포함하는 것을 특징으로 하는 영상 처리장치의 오검출 제거 방법."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 관심객체 인식모델에 의해 검출된 상기 관심객체의 특징 벡터의 마하라노비스 거리(mahalanobis distance)가 임계거리 이상인 경우, 오검출 객체로 판단하는 단계;를 포함하는 것을 특징으로 하는 영상 처리장치의 오검출 제거 방법."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 제2 오검출 필터링 모델을 학습시키는 단계;를 더 포함하고,상기 제2 오검출 필터링 모델을 학습시키는 단계는,미리 지정된 상기 관심 객체의 색상정보를 추출하는 단계; 및상기 색상정보에 기초하여 CIE-LAB 색공간에서의 색상을 분석하여 상기 관심객체의 주요색상을 획득하는 단계;를 포함하는 것을 특징으로 하는 영상 처리장치의 오검출 제거 방법."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 관심객체 인식모델을 학습시키는 단계;를 더 포함하고,상기 관심객체 인식모델을 학습시키는 단계는,상기 영상에서 상기 관심객체를 지정하는 사용자 입력을 수신하는 단계;공개특허 10-2023-0166865-3-상기 영상에서 상기 관심객체를 제외한 영역 중 적어도 일부에서 비관심 객체를 생성하는 단계;상기 관심객체 및 비관심 객체를 학습 데이터로 하여 상기 관심객체 인식모델을 학습시키는 단계;를 포함하는 것을 특징으로 하는 영상 처리장치의 오검출 제거 방법."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 학습된 객체 인식모델을 이용하여 제1 학습을 수행하는 단계; 및상기 제1 학습 이후 N번의 학습을 추가적으로 수행하되, 매번의 학습마다 직전 학습결과에 기초한 오검출 객체의 위치정보를 자동으로 추출하여 상기 비관심 객체로 변경하는 단계;를 포함하는 것을 특징으로 하는 영상 처리장치의 오검출 제거 방법."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "영상 획득부;사전에 학습된 관심객체 인식모델, 제1 오검출 필터링 모델 및 제2 오검출 필터링 모델을 저장하는 저장부; 및상기 영상 획득부로부터 획득된 영상에서 상기 관심객체 인식모델에 기초하여 관심객체를 검출하고, 상기 검출된 관심객체에서 상기 제1 오검출 필터링 모델을 적용하여 상기 관심객체의 특징기반의 오검출을 제거하고, 상기 제2 오검출 필터링 모델을 적용하여 상기 관심객체에 대하여 색상 기반 오검출을 제거하는 프로세서;를 포함하는 영상 처리장치."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 프로세서는,미리 지정된 상기 관심 객체의 특징 벡터를 추출하고, 상기 특징 벡터에 기초하여 상기 관심 객체의 좌표 공간상의 분포를 모델링하도록 제1 오검출 필터링 모델을 학습시키는 것을 특징으로 하는 영상 처리장치."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 프로세서는,상기 관심객체 인식모델에 의해 검출된 상기 관심객체의 특징 벡터의 마하라노비스 거리(mahalanobis distance)가 임계거리 이상인 경우, 오검출 객체로 판단하는 것을 특징으로 하는 영상 처리장치."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 7 항에 있어서,상기 프로세서는,미리 지정된 상기 관심 객체의 색상정보를 추출하고, 상기 색상정보에 기초하여 CIE-LAB 색공간에서의 색상을분석하여 상기 관심객체의 주요색상을 획득하도록 상기 제2 오검출 필터링 모델을 학습시키는 것을 특징으로 하는 영상 처리장치."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 7 항에 있어서,상기 프로세서는,상기 영상에서 상기 관심객체를 지정하는 사용자 입력을 수신하고, 상기 영상에서 상기 관심객체를 제외한 영역중 적어도 일부에서 비관심 객체를 생성하고, 상기 관심객체 및 비관심 객체를 학습 데이터로 하여 상기 관심객공개특허 10-2023-0166865-4-체 인식모델을 학습시키는 것을 특징으로 하는 영상 처리장치."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 프로세서는,상기 학습된 객체 인식모델을 이용하여 제1 학습을 수행하고, 상기 제1 학습 이후 N번의 학습을 추가적으로 수행하되, 매번의 학습마다 직전 학습결과에 기초한 오검출 객체의 위치정보를 자동으로 추출하여 상기 비관심 객체로 변경하는 것을 특징으로 하는 영상 처리장치."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 7 항에 있어서,무선 통신부;를 더 포함하고, 상기 영상 획득부는, 상기 무선 통신부를 통해 외부의 촬영장치로부터 촬영된 영상을 획득하는 것을 특징으로하는 영상 처리장치."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 7 항에 있어서,무선 통신부;를 더 포함하고,상기 프로세서는,상기 저장부에 저장된 관심객체 인식모델, 제1 오검출 필터링 모델 및 제2 오검출 필터링 모델을 상기 무선 통신부를 통해 영상 촬영장치로 전송하는 것을 특징으로 하는 영상 처리장치."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "영상 획득부;통신부;상기 통신부를 통해 사전에 학습된 관심객체 인식모델, 오검출 필터링 모델을 수신하여 저장하는 저장부; 및상기 영상 획득부를 통해 획득된 영상에 대하여 상기 관심객체 인식모델을 적용하여 객체를 인식하고, 상기 인식된 객체에서 오검출 필터링 모델을 적용하여 오검출이 제거된 최종 관심객체를 획득하는 프로세서;를 포함하고,상기 오검출 필터링 모델은,미리 지정된 상기 관심객체의 특징벡터의 좌표 공간 상의 분포가 모델링된 제1 오검출 필터링 모델, 상기 관심객체의 색상을 측정하여 대표색으로 객체를 분류하는 제2 오검출 필터링 모델 중 적어도 하나를 포함하는 것을특징으로 하는 영상 처리장치."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서,상기 프로세서는,상기 관심객체 인식모델을 통해 검출된 관심 객체에 대하여 상기 제1 오검출 필터링 모델을 적용하고, 상기 제1오검출 필터링 모델의 적용 결과에 대하여 상기 제2 오검출 필터링 모델을 적용하는 것을 특징으로 하는 영상처리장치."}
{"patent_id": "10-2023-0001007", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 15 항에 있어서,상기 영상 처리장치는 모바일 단말, 감시 카메라 중 적어도 하나를 포함하는 것을 특징으로 하는 영상공개특허 10-2023-0166865-5-처리장치."}
{"patent_id": "10-2023-0001007", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "영상 처리장치의 오검출 제거방법이 개시된다. 본 명세서는 관심객체를 검출된 상태에서 관심객체의 특징벡터 기 반의 오검출 제거 단계, 색상 기반의 오검출 제거 단계의 동작이 수행됨에 따라, 최종 관심객체가 획득될 수 있 다. 이에 따라 적은 데이터 또는 간단한 기법으로 관심 객체 검출기를 학습하더라도 검출 성능을 향상시킬 수 있 으며, 사용자가 검출하고자 하는 특정 색상의 관심 객체로도 검출이 가능하게 된다. 본 명세서는 감시용 카메라, 자율주행 차량, 사용자 단말기 및 서버 중 하나 이상이 인공 지능(Artificial Intelligence) 모듈, 로봇, 증강 현실(Augmented Reality, AR) 장치, 가상 현실(Virtual reality, VT) 장치, 5G 서비스와 관련된 장치 등과 연계 될 수 있다."}
{"patent_id": "10-2023-0001007", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서는 통계모델 기반 오검출 제거 방법에 관한 것이다."}
{"patent_id": "10-2023-0001007", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상 내에서 객체를 검출하여, 객체의 존재 여부를 판단하고, 객체가 존재할 경우 객체를 분류하여 객체의 종류 를 출력하도록 학습된 학습 기반의 다양한 영상 분석 기술이 존재한다. 인공 지능 기반의 객체 검출 기술은 새로운 객체의 종류를 분류, 새로운 객체의 객체정보를 수집하고, 모델을 학습 하는 과정에서 상당한 자원이 소요될 수 있다. 특히, 객체 인식을 위한 모델을 학습하는 과정에서 모델의 신뢰도를 높이기 위해 오검출된 객체를 반영하여 재학습 하는 과정이 필요할 수 있다. 다만, 객체 검출 결과에 대한 모니터링을 통해 해당 결과를 즉시 수정하기 어려운 문제가 있으며, 모델 학습 과정에서 오검출 객체를 수 동으로 인덱싱하는 과정 또한 상당한 자원과 시간이 소요되는 과정일 수 있다."}
{"patent_id": "10-2023-0001007", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 명세서는 전술한 문제점을 해결하기 위한 것으로서, 본 명세서의 일 실시예에 따른 영상 처리장치의 오검출 제어 방법에 따르면, 적은 데이터는 간단한 기법으로 관심 객체 검출기를 학습하더라도 검출 성능을 향상시킬 수 있는 영상 처리장치의 오검출 제거방법을 제공하는 것을 목적으로 한다. 본 발명이 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은"}
{"patent_id": "10-2023-0001007", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 이하의 발명의 상세한 설명으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가 진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0001007", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 명세서의 일 실시예에 따른 영상 처리장치의 오검출 제거방법은, 영상 처리장치에서 오검출 제거 방법에 있 어서, 촬영장치로부터 획득된 영상에서 관심객체 인식모델에 기초하여 관심객체를 검출하는 단계; 제1 오검출 필터링 모델에 기초하여 상기 관심객체의 특징기반의 오검출을 제거하는 단계; 제2 오검출 필터링 모델에 기초 하여 상기 관심객체의 색상 기반 오검출을 제거하는 단계; 및 상기 오검출이 제거된 최종 관심객체를 획득하는 단계;를 포함한다. 상기 영상 처리장치의 오검출 제거방법은,상기 제1 오검출 필터링 모델을 학습시키는 단계;를 더 포함하고, 상 기 제1 오검출 필터링 모델을 학습시키는 단계는, 미리 지정된 상기 관심 객체의 특정 벡터를 추출하는 단계; 및 상기 특징 벡터에 기초하여 상기 관심 객체의 좌표 공간상 분포를 모델링하는 단계;를 포함할 수 있다. 상기 영상 처리장치의 오검출 제거방법은, 상기 관심객체 인식모델에 의해 검출된 상기 관심객체의 특징 벡터의 마하라노비스 거리(mahalanobis distance)가 임계거리 이상인 경우, 오검출 객체로 판단하는 단계;를 포함할 수 있다. 상기 영상 처리장치의 오검출 제거방법은, 상기 제2 오검출 필터링 모델을 학습시키는 단계;를 더 포함하고, 상 기 제2 오검출 필터링 모델을 학습시키는 단계는, 미리 지정된 상기 관심 객체의 색상정보를 추출하는 단계; 및 상기 색상정보에 기초하여 CIE-LAB 색공간에서의 색상을 분석하여 상기 관심객체의 주요색상을 획득하는 단계;를 포함할 수 있다. 상기 영상 처리장치의 오검출 제거방법은, 상기 관심객체 인식모델을 학습시키는 단계;를 더 포함하고, 상기 관 심객체 인식모델을 학습시키는 단계는, 상기 영상에서 상기 관심객체를 지정하는 사용자 입력을 수신하는 단계; 상기 영상에서 상기 관심객체를 제외한 영역 중 적어도 일부에서 비관심 객체를 생성하는 단계; 상기 관심객체 및 비관심 객체를 학습 데이터로 하여 상기 관심객체 인식모델을 학습시키는 단계;를 포함할 수 있다. 상기 영상 처리장치의 오검출 제거방법은, 상기 학습된 객체 인식모델을 이용하여 제1 학습을 수행하는 단계; 및 상기 제1 학습 이후 N번의 학습을 추가적으로 수행하되, 매번의 학습마다 직전 학습결과에 기초한 오검출 객 체의 위치정보를 자동으로 추출하여 상기 비관심 객체로 변경하는 단계;를 포함할 수 있다. 본 명세서의 다른 실시예에 따른 영상 처리장치는, 영상 획득부; 사전에 학습된 관심객체 인식모델, 제1 오검출 필터링 모델 및 제2 오검출 필터링 모델을 저장하는 저장부; 및 상기 영상 획득부로부터 획득된 영상에서 상기 관심객체 인식모델에 기초하여 관심객체를 검출하고, 상기 검출된 관심객체에서 상기 제1 오검출 필터링 모델을 적용하여 상기 관심객체의 특징기반의 오검출을 제거하고, 상기 제2 오검출 필터링 모델을 적용하여 상기 관심 객체에 대하여 색상 기반 오검출을 제거하는 프로세서;를 포함한다. 상기 프로세서는, 미리 지정된 상기 관심 객체의 특징 벡터를 추출하고, 상기 특징 벡터에 기초하여 상기 관심 객체의 좌표 공간 상의 분포를 모델링하도록 제1 오검출 필터링 모델을 학습시킬 수 있다. 상기 프로세서는, 상기 관심객체 인식모델에 의해 검출된 상기 관심객체의 특징 벡터의 마하라노비스 거리 (mahalanobis distance)가 임계거리 이상인 경우, 오검출 객체로 판단할 수 있다. 상기 프로세서는, 미리 지정된 상기 관심 객체의 색상정보를 추출하고, 상기 색상정보에 기초하여 CIE-LAB 색공 간에서의 색상을 분석하여 상기 관심객체의 주요색상을 획득하도록 상기 제2 오검출 필터링 모델을 학습시킬 수 있다. 상기 프로세서는, 상기 영상에서 상기 관심객체를 지정하는 사용자 입력을 수신하고, 상기 영상에서 상기 관심 객체를 제외한 영역 중 적어도 일부에서 비관심 객체를 생성하고, 상기 관심객체 및 비관심 객체를 학습 데이터 로 하여 상기 관심객체 인식모델을 학습시킬 수 있다. 상기 프로세서는, 상기 학습된 객체 인식모델을 이용하여 제1 학습을 수행하고, 상기 제1 학습 이후 N번의 학습 을 추가적으로 수행하되, 매번의 학습마다 직전 학습결과에 기초한 오검출 객체의 위치정보를 자동으로 추출하 여 상기 비관심 객체로 변경할 수 있다. 상기 영상 처리장치는, 무선 통신부;를 더 포함하고, 상기 영상 획득부는, 상기 무선 통신부를 통해 외부의 촬 영장치로부터 촬영된 영상을 획득할 수 있다. 상기 영상 처리장치는, 무선 통신부;를 더 포함하고, 상기 프로세서는, 상기 저장부에 저장된 관심객체 인식모 델, 제1 오검출 필터링 모델 및 제2 오검출 필터링 모델을 상기 무선 통신부를 통해 영상 촬영장치로 전송할 수 있다. 본 명세서의 다른 실시예에 따른 영상 처리장치는, 영상 획득부; 통신부; 상기 통신부를 통해 사전에 학습된 관 심객체 인식모델, 오검출 필터링 모델을 수신하여 저장하는 저장부; 및 상기 영상 획득부를 통해 획득된 영상에 대하여 상기 관심객체 인식모델을 적용하여 객체를 인식하고, 상기 인식된 객체에서 오검출 필터링 모델을 적용 하여 오검출이 제거된 최종 관심객체를 획득하는 프로세서;를 포함하고, 상기 오검출 필터링 모델은, 미리 지정 된 상기 관심객체의 특징벡터의 좌표 공간 상의 분포가 모델링된 제1 오검출 필터링 모델, 상기 관심객체의 색 상을 측정하여 대표색으로 객체를 분류하는 제2 오검출 필터링 모델 중 적어도 하나를 포함할 수 있다. 상기 프로세서는, 상기 관심객체 인식모델을 통해 검출된 관심 객체에 대하여 상기 제1 오검출 필터링 모델을 적용하고, 상기 제1 오검출 필터링 모델의 적용 결과에 대하여 상기 제2 오검출 필터링 모델을 적용할 수 있다. 상기 영상 처리장치는 모바일 단말, 감시 카메라 중 적어도 하나를 포함할 수 있다."}
{"patent_id": "10-2023-0001007", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 명세서의 일 실시예에 따른 영상 처리장치의 오검출 제어 방법에 따르면, 적은 데이터는 간단한 기법으로 관 심 객체 검출기를 학습하더라도 검출 성능을 향상시킬 수 있다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2023-0001007", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0001007", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여, 본 명세서에 개시된 실시예를 상세히 설명하되, 도면부호에 관계없이 동일하거나 유사한 구성요소는 동일한 참조번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다.또한, 본 명세서에 개시된 실시예를 설 명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 명세서 의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소에 \"직접 연결되어\" 있다거 나 \"직접 접속되어\" 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요서, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 도 1은 본 명세서의 일 실시예에 따라 학습되는 객체인식 모델이 적용되어 객체를 인식하고, 그 결과를 활용하 는 감시 카메라 시스템을 설명하기 위한 도면이다. 도 1을 참조하면, 본 명세서의 일 실시예에 따른 감시 카메라 시스템 은 촬영 장치 및 영상 관리 서버 을 포함할 수 있다. 촬영 장치는 특정 장소의 고정된 위치에 배치되는 촬영용 전자 장치일 수도 있고, 일정한 경로를 따라 자동 또는 수동으로 움직일 수 있는 촬영용 전자 장치일 수도 있고, 사람 또는 로봇 등에 의하여 이동될 수 있는 촬영용 전자 장치일 수도 있다. 촬영 장치는 유무선 인터넷에 연결하여 사용 하는 IP 카메라일 수 있다. 촬영 장치는 팬(pan), 틸트(tilt), 및 줌(zoom) 기능을 갖는 PTZ 카메라일 수있다. 촬영 장치는 감시 하는 영역을 녹화하거나 사진을 촬영하는 기능을 가질 수 있다. 촬영 장치는 감시하는 영역에서 발생하는 소리를 녹음하는 기능을 가질 수 있다. 촬영 장치는 감시하는 영역에서 움직 임 또는 소리 등 변화가 발생 할 경우, 이에 대한 알림을 발생시키거나 녹화 또는 사진 촬영을 수행하는 기능을 가질 수 있다. 촬영 장치는 영상 관리 서버에서 학습된 객체인식 학습 모델을 수신하여 저장할 수 있 다. 이에 따라 촬영 장치는 상기 객체인식 학습 모델을 이용하여 객체인식 동작을 수행할 수도 있다. 영상 관리 서버는 촬영 장치를 통하여 촬영된 영상 자체 및/또는 해당 영상을 편집하여 얻어지는 영 상을 수신하여 저장하는 장치일 수 있다. 영상 관리 서버는 수신한 용도에 대응되도록 분석할 수 있다. 예 를 들어, 영상 관리 서버는 영상에서 객체를 검출하기 위해 객체 검출 알고리즘을 이용하여 객체를 검출할 수 있다. 상기 객체 검출 알고리즘은 AI 기반 알고리즘이 적용될 수 있으며, 미리 학습된 인공신경망 모델을 적 용하여 객체를 검출할 수 있다. 한편, 영상 관리 서버는 영상 분석 목적에 맞는 다양한 학습 모델을 저장하고 있을 수 있다. 전술한 객체 검출을 위한 학습 모델 외에, 검출된 객체를 활용할 수 있도록 하는 객체특성 정보를 획득할 수 있는 모델을 저 장하고 있을 수도 있다. 영상 관리 서버는 전술한 객체인식을 위한 학습모델을 학습하는 동작을 수행할 수 있다. 한편, 상기 객체인식을 위한 모델은 전술한 영상 관리 서버에서 학습하여 촬영 장치로 전송할 수도 있지만, 상기 촬영장치에서 객체인식 모델의 학습, 모델의 재학습 등이 수행될 수도 있다. 또한, 영상 관리 서버는 수신한 영상을 분석하여 메타 데이터와 해당 메타 데이터에 대한 인덱스 정보를 생성할 수 있다. 영상 관리 서버는 수신한 영상에 포함된 영상 정보 및 /또는 음향 정보를 함께 또는 별도 로 분석하여 메타 데이터와 해당 메타 데이터에 대한 인덱스 정보를 생성할 수 있다. 영상 관리 시스템은 촬영 장치 및/또는 영상 관리 서버와 유무선 통신을 수행할 수 있는 외부 장 치를 더 포함할 수 있다. 외부 장치는 영상 관리 서버로 영상 전체 또는 일부의 제공을 요청하는 정보 제공 요청 신호를 송신 할 수 있다. 외부 장치는 영상 관리 서버로 영상 분석 결과 객체의 존재 여부 등을 요청하는 정보 제 공 요청 신호를 송신할 수 있다. 또한 외부 장치는 영상 관리 서버로 영상을 분석하여 얻어진 메타 데이터 및/또는 메타 데이터에 대한 인덱스 정보를 요청하는 정보 제공 요청 신호를 송신할 수 있다. 영상 관리 시스템은 촬영 장치, 영상 관리 서버, 및/또는 외부 장치 간의 유무선 통신 경로 인 통신망을 더 포함할 수 있다. 통신망은 예컨대 LANs(Local Area Networks), WANs(Wide Area Networks), MANs(Metropolitan Area Networks), ISDNs(Integrated Service Digital Networks) 등의 유선 네트 워크나, 무선 LANs, CDMA, 블루투스, 위성 통신 등의 무선 네트워크를 망라할 수 있으나, 본 명세서의 범위가 이 에 한정되는 것은 아니다. 촬영장치는 영상 관리 서버에서 학습된 객체인식 학습모델을 수신하여 저장할 수 있다. 이에 따라 촬 영장치는 상기 객체인식 학습모델을 이용하여 객체인식 동작을 수행할 수도 있다. 또한, 촬영장치는 관심객체로 검출한 후보들 중에 미리 정해진 기준에 따라 오검출 여부를 판단할 수 있다. 여기서 상기 오검출 (False Positive)는 음성을 양성으로 탐지한 상태(오탐지)을 의미하는데 사용자에 의해 지정된 관심 객체가 아 닌 비관심 객체를 관심 객체로 검출한 상태를 의미할 수 있다. 상기 미리 정해진 기준은 오검출 객체를 필터링 하기 위한 기준으로서, 영상 관리 서버로부터 오검출 필터링을 위한 기준 데이터를 사전에 수신할 수 있다. 촬영장치는 상기 오검출 필터링 동작을 통해 최종 관심객체 검출 결과를 출력할 수 있다. 일 실시예에 따라, 상기 영상 관리 서버는 오검출 객체의 필터링을 위한 오검출 필터링 데이터를 생성할 수 있다. 상기 오검출 필터링 데이터는 관심 객체의 특징 벡터의 확률적 분포를 모델링한 데이터일 수 있다. 상 기 오검출 필터링 데이터는 상기 관심 객체의 색상정보를 추출하여 주 색상 정보로 획득한 데이터일 수 있다. 영상 관리 서버는 상기 오검출 필터링 데이터를 객체인식 학습모델과 함께 촬영 장치에 전송함으로써, 촬영장치에서 객체 검출과정에서 오검출을 보다 용이하게 수행할 수 있도록 한다. 본 명세서는 상기 관심객체 검출모델의 학습을 위해 관심 객체의 특징 벡터를 추출하는 동작, 관심객체의 주 색 상 정보를 추출하여 관심 객체의 색상정보를 분석하는 동작을 전술한 바와 같이 영상 관리 서버에서 수행 하는 것으로 설명하였으나, 본 명세서는 이에 한정되는 것은 아니다. 일 실시예예 따라 본 명세서는 상기 관심 객체 검출모델의 학습 또한 촬영장치에서 수행할 수도 있다. 일 실시예예 따라 촬영장치는 영상 관리 서버로부터 추출된 관심객체의 특징벡터 정보를 수신하고, 수신된 특징벡터 정보에 기초하여 관심객체의좌표공간 상에서의 분포모델을 학습할 수도 있다. 또한, 촬영장치는 영상 관리 서버로부터 추출된 관 심 객체의 주요 색상 정보를 수신하여 관심 객체의 색상모델을 학습할 수도 있다. 도 2는 본 명세서의 일 실시예에 따른 객체인식 모델을 학습하는데 적용되는 AI 장치(모듈)을 설명하기 위한 도 면이다. 본 명세서의 실시예들은 객체인식을 위한 모델을 학습하는 컴퓨팅 장치를 통해 구현될 수 있으며, 상기 컴퓨팅 장치는, 도 1에서 설명한 영상 관리 서버(도 1의 200)를 포함할 수도 있으나, 본 명세서는 이에 한정되지 않고 영상에서 객체를 인식하는 인공지능 모델을 학습하기 위한 전용 장치 또한 포함될 수 있다. 상기 전용 장치는 프로세서에 의해 실행되는 소프트웨어 모듈이나 하드웨어 모듈 형태로 구현되거나 또는 소프트웨어 모듈과 하드 웨어 모듈이 조합된 형태로 구현될 수 있다. 이하 도 2에서는 객체인식 학습 모델 구현을 위한 전용 AI 장치에 대하여 설명하며, 도 3에서는 영상 관리 서버(도 1의 200) 내에서 본 명세서의 일 실시예에 따른 객체인식 학습 모델 구현을 위한 블록 구성을 설명하기 로 한다. 도 2에서 설명하는 모델 학습 기능과 공통된 기능 중 전부 또는 적어도 일부가 도 3에 그대로 적용될 수 있는 바, 도 3의 설명 과정에서 도 2와 공통되는 기능은 중복기재로 생략하기로 한다. 도 2를 살펴보면, AI 장치는 AI 프로세싱을 수행할 수 있는 AI 모듈을 포함하는 전자 기기 또는 AI 모듈을 포함하는 서버 등을 포함할 수 있다. 또한, AI 장치는 영상 촬영 장치 또는 영상 관리 서버의 적어도 일부의 구성으로 포함되어 AI 프로세싱 중 적어도 일부를 함께 수행하도록 구비될 수도 있다. AI 프로세싱은 영상 촬영 장치 또는 영상 관리 서버의 제어부와 관련된 모든 동작들을 포함할 수 있 다. 예를 들어, 영상 촬영 장치 또는 영상 관리 서버는 획득된 영상 신호를 AI 프로세싱 하여 처리/ 판단, 제어 신호 생성 동작을 수행할 수 있다. AI 장치는 AI 프로세싱 결과를 직접 이용하는 클라이언트 디바이스이거나, AI 프로세싱 결과를 다른 기기에 제공하는 클라우드 환경의 디바이스일 수도 있다. AI 장치는 신경망을 학습할 수 있는 컴퓨팅 장치로서, 서 버, 데스크탑 PC, 노트북 PC, 태블릿 PC 등과 같은 다양한 전자 장치로 구현될 수 있다. AI 장치는 AI 프로세서, 메모리 및/또는 통신부를 포함할 수 있다. AI 프로세서는 메모리에 저장된 프로그램을 이용하여 신경망을 학습할 수 있다. 특히, AI 프로세서(2 1)는 영상 촬영 장치의 관련 데이터를 인식하기 위한 신경망을 학습할 수 있다. 여기서, 영상 촬영 장치 의 관련 데이터를 인식하기 위한 신경망은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며, 인간의 신경망의 뉴런(neuron)을 모의하는, 가중치를 갖는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 모드들은 뉴런이 시냅스(synapse)를 통해 신호를 주고 받는 뉴런의 시냅틱 활동을 모의하도록 각각 연 결 관계에 따라 데이터를 주고 받을 수 있다. 여기서 신경망은 신경망 모델에서 발전한 딥러닝 모델을 포함할 수 있다. 딥러닝 모델에서 복수의 네트워크 노드들은 서로 다른 레이어에 위치하면서 컨볼루션(convolution) 연 결 관계에 따라 데이터를 주고 받을 수 있다. 신경망 모델의 예는 심층 신경망(DNN, deep neural networks), 합 성곱 신경망(CNN, convolutional deep neural networks), 순환 신경망(RNN, Recurrent Boltzmann Machine), 제 한 볼츠만 머신(RBM, Restricted Boltzmann Machine), 심층 신뢰 신경망(DBN, deep belief networks), 심층 Q- 네트워크(Deep Q-Network)와 같은 다양한 딥 러닝 기법들을 포함하며, 컴퓨터비젼, 음성인식, 자연어처리, 음성 /신호처리 등의 분야에 적용될 수 있다. 한편, 전술한 바와 같은 기능을 수행하는 프로세서는 범용 프로세서(예를 들어, CPU)일 수 있으나, 인공지능 학 습을 위한 AI 전용 프로세서(예를 들어, GPU)일 수 있다. 메모리는 AI 장치의 동작에 필요한 각종 프로그램 및 데이터를 저장할 수 있다. 메모리는 비 휘발 성 메모리, 휘발성 메모리, 플래시 메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드 라이브(SDD) 등으로 구현할 수 있다. 메모리는 AI 프로세서에 의해 액세스되며, AI 프로세서에 의 한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 또한, 메모리는 본 발명의 일 실시예에 따른 데이터 분류/인식을 위한 학습 알고리즘을 통해 생성된 신경망 모델(예를 들어, 딥 러닝 모델)을 저장할 수 있다. 한편, AI 프로세서는 데이터 분류/인식을 위한 신경망을 학습하는 데이터 학습부를 포함할 수 있다. 데 이터 학습부는 데이터 분류/인식을 판단하기 위하여 어떤 학습 데이터를 이용할지, 학습 데이터를 이용하여 데이터를 어떻게 분류하고 인식할지에 관한 기준을 학습할 수 있다. 데이터 학습부는 학습에 이용될 학습데이터를 획득하고, 획득된 학습데이터를 인공 신경망 모델 및/또는 딥러닝 모델에 적용함으로써, 신경망 모델 을 학습할 수 있다. 데이터 학습부는 적어도 하나의 하드웨어 칩 형태로 제작되어 AI 장치에탑재될 수 있다. 예를 들어, 데 이터 학습부는 인공지능(AI)을 위한 전용 하드웨어칩 형태로 제작될 수도 있고, 범용 프로세서(CPU) 또는 그래픽 전용 프로세서(GPU)의 일부로 제작되어 AI 장치에 탑재될 수도 있다. 또한, 데이터 학습부는 소프트웨어 모듈로 구현될 수 있다. 소프트웨어 모듈(또는 인스트럭션(instruction)을 포함하는 프로그램 모 듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록 매체 (non-transitory computer readable media)에 저장될 수 있다. 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 애플리케이션에 의해 제공될 수 있다. 데이터 학습부는 학습 데이터 획득부 및 모델 학습부를 포함할 수 있다. 학습 데이터 획득부는 데이터를 분류하고 인식하기 위한 신경망 모델에 필요한 학습 데이터를 획득할 수 있 다. 본 명세서의 일 실시예에 따라 상기 학습 데이터는 촬영 장치에서 촬영된 영상에서 사용자에 의해 지정되 는 관심 객체 정보, 상기 영상에서 관심 객체를 제외한 영역에서 선택되는 비관심 객체 정보를 포함할 수 있다. 상기 관심 객체 정보는 상기 영상 내에서 상기 관심 객체의 위치 정보를 포함할 수 있다. 상기 위치 정보는 상 기 관심 객체의 바운딩 박스(bounding box)의 좌표 정보를 포함할 수 있다. 상기 좌표 정보는 상기 바운딩 박스 의 꼭지점 좌표, 중심 좌표 등을 포함할 수 있다. 한편, 상기 학습 데이터 중 비관심 객체는 프로세서에 의해 랜덤하게 지정되거나, 소정 기준에 따라 선택될 수 있다. 모델 학습부는 획득된 학습 데이터를 이용하여, 신경망 모델이 소정의 데이터를 어떻게 분류할지에 관한 판 단 기준을 가지도록 학습할 수 있다. 이 때 모델 학습부는 학습 데이터 중 적어도 일부를 판단 기준으로 이 용하는 지도 학습(supervised learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 또는 모델 학습부는 지도 없이 학습 데이터를 이용하여 스스로 학습함으로써, 판단 기준을 발견하는 비지도 학습(unsupervised learning)을 통해 신경망 모델을 학습시킬 수 있다. 또한, 모델 학습부는 학습에 따른 상황 판단의 결과가 올바른지에 대한 피드백을 이용하여 강화학습(reinforcement learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 또한, 모델 학습부는 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient decent)을 포함하는 학습 알고리즘을 이용하여 신경망 모델을 학습시킬 수 있다. 본 명세서의 일 실시예에 따라 상기 모델 학습부는 학습 데이터에 기초하여 학습한 결과 관심 객체로 지정되지 않은 객체가 관심 객체로 인식된 경우, 이를 오검출 객체로 판단하고 오검출 객체를 비관심 객체로 변경한 후, 모델 재학습 과정에 적용할 수 잇 다. 한편, 본 명세서는 객체인식 과정에서 오검출을 최소화하기 위하여 오검출 객체를 학습 또는 재학습에 이용할 수 있다. 또한, 본 명세서의 객체인식 기술이 적용되는 제품은 감시 카메라에 적용될 수 있으며, 특히 개인용 감시 카메라의 경우 관심 객체의 종류와 수가 한정적일 수 있다. 이에 따라 학습 데이터의 종류와 량이 제한적 일 수 있는 점에 기초하여 학습 데이터의 이용을 최소화하는 메타 러닝(meta learning) 방법이 적용될 수 있다. 메타러닝은 사람이 통제하던 기계학습 과정을 자동화함으로써, 기계 스스로 학습 규칙(메타 지식)을 익힐 수 있 는 방법론이다. 이와 같은 메타러닝의 한 분야로서, 퓨샷 러닝(Few-Shot Learning)은 주어진 데이터가 다른 데이터들과 얼마나 비슷한지(또는 다른지)를 학습하는 방법이다. 데이터 수가 매우 적은 퓨샷 러닝 문제는 훈련 데이터와 테스트 데이터(쿼리 데이터)로 구성될 수 있으며, 이러한 퓨샷 러닝 태스크를 'N-way K-shot'으로 호칭한다. 여기서 N 은 범주(클래스)를 의미하며, K는 클래스별 훈련 데이터의 수를 의미할 수 있다. 또한, 샷(shot)의 개수인 K가 커질수록 데이터의 예측성능(추론의 정확도)는 높아질 수 있으며, 퓨샷 러닝은 K가 적은 상황에서의 모델학습을 의미할 수 있다. 본 명세서의 일 실시예는 사용자에 의해 지정되는 관심 객체의 양이 제한적이므로, 퓨샷 러닝 을 통해 오검출 객체인식 알고리즘을 학습할 수 있다.신경망 모델이 학습되면, 모델 학습부는 학습된 신경 망 모델을 메모리에 저장할 수 있다. 모델 학습부는 학습된 신경망 모델을 AI 장치와 유선 또는 무선 네트워크로 연결된 서버의 메모리에 저장할 수도 있다. 데이터 학습부는 인식 모델의 분석 결과를 향상시키거나, 인식 모델의 생성에 필요한 리소스 또는 시간을 절약하기 위해 학습 데이터 전처리부(미도시) 및 학습 데이터 선택부(미도시)를 더 포함할 수도 있다. 학습 데이터 전처리부는 획득된 데이터가 상황 판단을 위한 학습에 이용될 수 있도록, 획득된 데이터를 전처리 할 수 있다. 예를 들어, 학습 데이터 전처리부는, 모델 학습부가 이미지 인식을 위한 학습을 위하여 획득된학습 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다. 또한, 학습 데이터 선택부는, 학습 데이터 획득부에서 획득된 학습 데이터 또는 전처리부에서 전처리된 학 습 데이터 중 학습에 필요한 데이터를 선택할 수 있다.선택된 학습 데이터는 모델 학습부에 제공될 수 있다. 또한, 데이터 학습부는 신경망 모델의 분석 결과를 향상시키기 위하여 모델 평가부(미도시)를 더 포함할 수 도 있다. 모델 평가부는, 신경망 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 분석 결과가 소정 기준을 만족하지 못하는 경우, 모델 학습부로 하여금 다시학습하도록 할 수 있다. 이 경우, 평가 데이터는 인식 모 델을 평가하기 위한 기 정의된 데이터일 수 있다. 일 예로, 모델 평가부는 평가 데이터에 대한 학습된 인식 모 델의 분석 결과 중, 분석 결과가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정되 임계치를 초과하 는 경우, 소정 기준을 만족하지 못한 것으로 평가할 수 있다. 본 명세서의 일 실시예에 따라 상기 모델 평가부 는 학습된 모델을 기초로 객체 검출 동작을 수행한 결과 오검출 객체가 발견된 경우, 오검출 객체를 비관심 객 체로 전환하여 재학습하도록 할 수 있다. 통신부는 AI 프로세서에 의한 AI 프로세싱 결과를 외부 전자 기기로 전송할 수 있다. 예를 들어, 외부 전자 기기는 감시카메라, 블루투스 장치, 자율주행 차량, 로봇, 드론, AR 기기, 모바일 기기, 가전 기기 등을 포함할 수 있다. 한편, 도 2에 도시된 AI 장치는 AI 프로세서와 메모리, 통신부 등으로 기능적으로 구분하여 설 명하였지만, 전술한 구성요소들이 하나의 모듈로 통합되어 AI 모듈로 호칭될 수도 있음을 밝혀둔다. 본 명세서는 감시용 카메라, 자율주행 차량, 사용자 단말기 및 서버 중 하나 이상이 인공 지능(Artificial Intelligence) 모듈, 로봇, 증강현실(Augmented Reality, AR) 장치, 가상 현실(Virtual reality, VT) 장치, 5G 서비스와 관련된 장치 등과 연계될 수 있다. 도 3은본 명세서의 일 실시예에 따른 감시 카메라의 개략적인 블록도이다. 도 3은 도 1에 도시된 영상 촬영 장치의 구성을 나타내는 블록도이다. 도 3을 참조하면, 영상촬영 장치 는 지능형 영상분석 기능을 수행하여 상기 영상분석 신호를 생성하는 네트워크 카메라임을 그 예로 설명 하나, 본 발명의 실시예에 의한 네트워크 감시 카메라 시스템의 동작이 반드시 이에 한정되는 것은 아니다. 영상촬영 장치는 이미지 센서, 인코더, 메모리, 이벤트 센서, 통신부 및 프로세 서를 포함한다. 이미지 센서는 감시 영역을 촬영하여 영상을 획득하는 기능을 수행하는 것으로서, 예컨대, CCD(Charge- Coupled Device) 센서, CMOS(Complementary Metal-Oxide-Semiconductor) 센서 등으로 구현될 수 있다. 인코더는 이미지 센서를 통해 획득한 영상을 디지털 신호로 부호화하는 동작을 수행하며, 이는 예컨 대, H.264, H.265, MPEG(Moving Picture Experts Group), M-JPEG(Motion Joint Photographic Experts Group) 표준 등을 따를 수 있다. 메모리는 영상 데이터, 음성 데이터, 스틸 이미지, 메타데이터 등을 저장할 수 있다. 앞서 언급한 바와 같 이, 상기 메타데이터는 상기 감시영역에 촬영된 객체 검출 정보(움직임, 소리, 지정지역 침입 등), 객체 식별 정보(사람, 차, 얼굴, 모자, 의상 등), 및 검출된 위치 정보(좌표, 크기 등)을 포함하는 데이터일 수 있다. 또한, 상기 스틸 이미지는 상기 메타데이터와 함께 생성되어 메모리에 저장되는 것으로서, 상기 영상분석 정보들 중 특정 분석 영역에 대한 이미지 정보를 캡쳐하여 생성될 수 있다. 일 예로, 상기 스틸 이미지는 JPEG 이미지 파일로 구현될 수 있다. 일 예로, 상기 스틸 이미지는 특정 영역 및 특정 기간 동안 검출된 상기 감시영역의 영상 데이터들 중 식별 가 능한 객체로 판단된 영상 데이터의 특정영역을 크롭핑(cropping)하여 생성될 수 있으며, 이는 상기 메타데이터 와 함께 실시간으로 전송될 수 있다. 통신부는 상기 영상 데이터, 음성 데이터, 스틸 이미지, 및/또는 메타데이터를 영상수신/검색장치에 전송 한다. 일 실시예에 따른 통신부는 영상 데이터, 음성 데이터, 스틸 이미지, 및/또는 메타데이터를 영상수 신장치에 실시간으로 전송할 수 있다. 통신 인터페이스는 유무선 LAN(Local Area Network), 와이파이(Wi-Fi), 지그비(ZigBee), 블루투스(Bluetooth), 근거리 통신(Near Field Communication) 중 적어도 하나의 통신 기능을 수행할 수 있다. AI 프로세서는 인공지능 영상 처리를 위한 것으로서, 본 명세서의 일 실시예에 따라 감시 카메라 시스템을 통해 획득된 영상에서 관심객체로 학습된 신경망 기반의 객체 탐지(Objection Detection) 알고리즘을 적용한다. 상기 AI 프로세서는 시스템 전반에 걸쳐 제어하는 프로세서와 하나의 모듈로 구현되거나 독립된 모듈 로 구현될 수 있다. 도 4는 본 명세서의 일 실시예에 따른 객체인식 모델을 학습하는 컴퓨팅 장치를 설명하기 위한 도면이다. 컴퓨팅 장치는 영상 촬영 장치(도 1의 100) 또는 통신부를 통해 획득된 영상을 처리하고, 각종 연산 을 수행하는 장치로, 본 명세서의 일 실시예에 따르면 도 1에 도시된 영상 관리 서버에 해당될 수 있다. 다만, 상기 컴퓨팅 장치는 이에 한정되지 않으며, 스마트폰(smartphone), 태블릿 PC(tablet personal computer), 이동 전화기(mobile phone), 영상 전화기, 전자책 리더기(e-book reader), 데스크탑 PC(desktop personal computer), 랩탑 PC(laptop personal computer), 넷북 컴퓨터(netbook computer), 워크스테이션 (workstation), PDA(personal digital assistant), PMP(portable multimedia player), MP3 플레이어, 모바일 의료기기, 웨어러블 장치(wearable device), 또는 IP 카메라 중 적어도 하나일 수 있다. 도 4를 참조하면, 컴퓨팅 장치는 통신부, 입력부, 메모리, 학습 데이터 저장부, 프로 세서를 포함할 수 있다. 통신부는 컴퓨팅 장치와 다른 전자 장치 간의 데이터 송수신을 수행하도록 구성된다. 통신부는 영상촬영 장치로부터 영상을 수신하고, 객체인식 학습 모델을 학습하여 영상촬영 장치로 전송할 수 있다. 통신 부는 예를 들어, 이더넷(Ethernet), 유무선 LAN(Local Area Network), 와이파이(Wi-Fi), WFD(Wi-Fi Direct), 및 와이기그(Wireless Gigabit Allicance, WiGig)를 포함하는 유무선 데이터 통신 방식 중 적어도 하 나를 이용하여 서버 또는 타 디바이스와 데이터 통신을 수행할 수 있다. 입력부는 사용자 입력부를 포함할 수 있으며, 본 명세서의 일 실시예에 따라 사용자 입력부를 통해 학습 대상이 되는 영상에서 관심 객체를 지정하는 입력을 수신할 수 있다. 상기 사용자 입력부는 키 입력부, 디스플 레이에 구비된 터치 스크린 등을 포함할 수 있다. 프로세서는 터치 스크린에 표시된 영상에서 관심 객체를 선택 하는 입력을 수신한 경우, 해당 객체를 관심 객체로 지정할 수 있다. 프로세서는 상기 터치 스크린에 입력되는 객체의 위치 정보를 추출하여 관심 객체의 위치 정보를 저장할 수 있다. 메모리는 를 들어, 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디 어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나로 구성될 수 있다. 메모리에는 통신부를 통해 영상 촬영 장치로부터 수신한, 영상으로부터 학습 데이터를 생성하고, 생 성된 학습 데이터에 기초하여 객체인식 모델의 학습을 수행하고, 모델 학습 과정에서 오검출 객체를 자동으로 처리할 수 있는 기능 또는 동작의 수행과 관련된 명령어들(instruction)을 포함하는 프로그램이 저장될 수 있다. 메모리에 저장되는 명령어들, 알고리즘, 데이터 구조 및 프로그램 코드는 예를 들어, , C, C++, 자 바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 메모리는 학습 데이터를 관리하는 다양한 모듈들을 포함할 수 있는데, 메모리에 포함된 복수의 모듈은 프 로세서에 의해 수행되는 기능이나 동작을 처리하는 단위를 의미하고, 이는 명령어들 또는 프로그램 코드와 같은 소프트웨어로 구현될 수 있다. 본 명세서에 기술되는 객체인식 모델 학습방법은 메모리에 저장된 프로그램의 명령어들 또는 프로그램 코드들을 실행함으로써 구현될 수 있다. 학습 데이터 관리 모듈은 관심객체 검출모듈, 비관심 객체 지정모듈, 객체인식모델 학습모듈, 오검출 판단모듈을 포함할 수 있다. 관심객체 검출모듈은 영상 촬영 장치로부터 촬영된 영상에서 미리 정해진 입력을 통해 지정되는 관심 객체 를 검출한다. 상기 관심 객체는 사용자가 영상으로부터 검출하고자 하는 관심있는 객체를 의미할 수 있다. 본 명세서는 상기 관심 객체를 포지티브(positive) 객체로 호칭할 수도 있다. 상기 관심 객체는 예를 들어, 사람,동물, 차량, 보다 구체적으로 사람의 얼굴 등 영상 촬영 장치로부터 검출하고자 하는 어떠한 객체도 포함될 수 있다. 관심객체 검출모듈은 지정된 객체에 대하여 바운딩 박스를 표시하고, 각 바운딩 박스의 모서리의 좌 표값으로 객체의 위치 정보를 추출할 수 있다. 관심객체 검출모듈에서 추출된 객체의 위치 정보는 학습 데 이터 저장부에 저장될 수 있다. 프로세서는 관심객체 검출모듈과 관련된 명령어들 또는 프로그램 코드를 실행함으로써, 기 준비된 영 상으로부터 관심 객체를 검출할 수 있다. 비관심 객체 검출모듈은 영상에서 상기 관심객체를 제외한 영역 중 적어도 일부를 지정하여 비관심 객체를 생성할 수 있다. 상기 비관심 객체는 상기 지정된 관심 객체를 제외한 모든 객체를 의미할 수 있다. 다만, 학습 된 모델에 기초하여 객체인식을 수행하는 중 상기 관심객체로 지정되지 않은 객체가 관심 객체로 인식되는 경우 가 있을 수 있다. 이 경우 학습 모델의 신뢰성이 저하되므로 비관심 객체를 네거티브 객체로 독립된 학습 데이 터로 지정하여 객체인식 모델학습에 이용하는 경우, 모델을 활용한 관심 객체의 인식률을 높일 수 있다. 본 명세서는 비관심 객체 지정모듈에서 랜덤하게 비관심 객체를 생성하거나, 미리 정해진 기준에 따라 비 관심 객체를 생성하여, 기 지정된 관심 객체와 함께 학습 데이터로 활용할 수 있다. 비관심객체 지정모듈 을 통해 생성된 비관심 객체 데이터들은 학습 데이터 저장부에 저장될 수 있다. 한편, 비관심 객체 지정모 듈은 학습된 모델을 통해 객체인식 동작을 수행하는 중 오검출 객체를 비관심 객체로 추가적으로 지정하는 동작을 수행할 수도 있다. 즉, 본 명세서의 일 실시예에서 비관심 객체는 객체인식 모델 학습을 시작하기 전(학 습 데이터 준비과정)에 생성되거나, 모델 학습 과정 중에 추가적으로 지정될 수 있다. 여기서 모델 학습 과정 중에 추가적으로 지정되는 비관심 객체는, 오검출된 객체가 비관심 객체로 전환되는 객체 또는 상기 오검출된 객체는 아니지만 기 학습된 모델의 신뢰도 스코어(confidence score)에 기초하여 비관심 객체로 추가되는 객체 를 포함할 수 있다. 비관심객체 지정모듈은 서로 다른 속성을 갖는 N개의 비관심 객체 세트를 생성할 수 있다. 여기서 상기 N 개의 비관심 객체세트는 프로세서에 의해 상기 관심 객체를 제외한 영역에서 랜덤하게 지정된 제1 비관심 객체세트를 포함할 수 있다. 또한, 상기 N개의 비관심 객체세트는 영상을 소정 간격으로 분할한 그리드 영역을 생성하고, 상기 그리드 영역 중 지정된 관심객체를 제외한 영역에서 그리드 간격을 변경하면서 생성된 복수의 제2 비관심 객체세트를 포함할 수도 있다. 예를 들어, 프로세서는 비관심 객체를 생성하기 위해 영상을 제 1 그리드 간격으로 분할하고, 관심 객체를 제외한 영역에서 복수의 특정 단위 셀(cell)을 지정할 수 있다. 또는 프로세서는 단위 그리드를 조합한 복수의 조합 셀(cell)을 지정할 수도 있다. 여기서 선택되는 셀(cell)은 영상에서 픽셀 단위의 셀 또는 상기 영상 전체 영역에서 분할된 단위 그리드를 의미할 수도 있다. 프로세서는 상기 그리드 영역에서 적어도 하나의 비관심 객체 영역을 지정하는 과정에서 특정 단위 셀 또 는 특정 조합 셀을 선택한 후, 선택된 셀을 기준으로 미리 정해진 거리 기준으로 인접한 셀을 비관심 객체 영역 으로 선택할 수 있다. 프로세서는 비관심객체 검출모듈과 관련된 명령어들 또는 프로그램 코드를 실행함으로써, 기 준비된 영상으로부터 비관심 객체를 생성할 수 있다. 객체인식 모델 학습모듈은 학습 데이터 저장부에 저장된 관심객체, 비관심 객체에 기초하여 인공 신 경망 모델을 학습시킬 수 있다. 객체인식 모델 학습모듈은 오검출 결과를 반영하기 위해 반복적으로 학습 을 수행할 수 있다. 일 실시예에 따라, 객체인식 모델 학습모듈은 지정된 관심 객체 및 영상에서 관심객체 영역을 제외한 영역 에서 랜덤하게 비관심 객체를 선택하여 객체인식 모델을 학습시킬 수 있다. 객체인식 모델 학습모듈은 학 습된 모델에 기초하여 객체인식 동작을 수행한 결과 오검출 객체가 존재하는지 판단할 수 있다. 객체인식 모델 학습모듈은 상기 오검출 객체에 대하여 자동으로 비관심 객체로 변경할 수 있다. 객체인식 모델 학습모듈 상기 관심 객체, 랜덤하게 지정된 비관심 객체, 추후 변경된 비관심 객체를 학습 데이터로 하여 객체인식 모델을 재학습시킬 수 있다. 또한, 일 실시예에 따라, 객체인식 모델 학습모듈은 초기 학습이 시작되기 전에 관심 객체 정보만을 획득 한 상태에서 객체인식 모델을 학습시킬 수 있다. 객체인식 모델 학습모듈는 비관심 객체정보 없이 모델 학 습 동작을 수행한 후, 학습된 모델에 기초한 객체인식 동작을 수행하여 오검출 객체가 검출되는 경우, 오검출 객체를 비관심 객체로 전환하여 학습데이터로 추가하여 재학습시킬 수 있다. 객체인식 모델 학습모듈을 통해 학습된 객체인식 모델은 신경망 모델로 구성되어 메모리에 저장될 수 있다. 또한, 일 실시예에 따라, 객체인식 모델 학습모듈은 지정된 관심 객체, 영상을 소정 간격의 그리드로 분할 한 후, 그리드 간격을 변경시키면서 복수의 비관심 객체 세트를 생성할 수 있다. 상기 복수의 비관심 객체 세트 가 5세트인 경우, 객체인식 모델 학습모듈은 총 5개의 객체인식 모델을 학습하여 생성할 수 있다. 상기 학 습된 5개의 객체인식 모델은 학습데이터로 이용된 비관심 객체의 종류가 서로 다르므로 객체인식 모델의 신뢰도 또한 모두 다를 수 있다. 이에 따라, 객체인식 모델 학습모듈은 상기 서로 다른 복수의 객체인식 모델 중 어느 하나의 모델을 선택하여 신경망 모델로 구성할 수 있다. 객체인식 모델 학습모듈은 학습 데이터를 기 반으로 검증 데이터(validation set)을 생성하여 5개의 모델 중 어느 하나의 객체인식 모델을 생성하여 신경망 모델로 구성할 수 있다. 프로세서는 객체인식 모델 학습모듈과 관련된 명령어들 또는 프로그램 코드를 실행함으로써, 객체인 식 모델을 학습시킬 수 있다. 신경망 모델은 저장된 학습 데이터를 이용하여 학습(training)을 수행함으로써 획득되는 인공지능 모델 이다. 일 실시예에서, 신경망 모델은 객체인식 동작을 수행하기 전에 수행된 학습을 통해 획득된 모델 파 라미터를 포함할 수 있다. 여기서, 상기 모델 파라미터는 신경망 모델에 포함되는 복수의 레이어에 관한 가중치 (weight) 및 편향(bias)을 포함할 수 있다. 기 학습된 모델 파라미터는 복수의 원본 영상을 입력으로 적용하고, 복수의 원본 영상에서 지정된 관심 객체정보에 관한 라벨(label)을 정답값(groundtruth)로 적용하는 지도 학습(supervised learning)을 수행함으로써, 획득할 수 있다. 한편, 본 명세서의 일 실시예에 따라 학습되는 객체인식 모델을 감시 카메라 시스템을 통해 획득된 영상에서 관 심객체로 학습된 기계학습 기반의 객체 탐지(Objection Detection) 알고리즘을 적용한다. 한편, 본 명세서의 일 실시예에 따라 기계학습 기반의 오검출 객체 탐지 과정에서 학습된 방법은 딥러닝 기반의 학습 모델 구현 과정에서도 적용될 수 있다. 예를 들어, 본 명세서의 일 실시예 적용된 학습 방법은 YOLO(You Only Lock Once) 알고리즘을 구현하는 과정에 적용할 수 있다. YOLO은 객체 검출 속도가 빠르기 때문에 실시간 동영상을 처리하는 감시 카메라에 적당한 AI 알고리즘이다. YOLO 알고리즘은 다른 객체 기반 알고리즘들(Faster R-CNN, R_FCN, FPN-FRCN 등)과 달리 한 장의 입력 영상을 리사이즈(Resize)후 단일 신경망을 단 한 번 통과시킨 결과로 각 객체의 위치를 인디케이팅하는 바운딩 박스(Bounding Box)와 객체가 무엇인지 분류 확률을 출력한다. 최종적으로 Non-max suppression을 통해 하나의 객체를 한번 인식(detection)한다. 한편, 본 명세서에 개시되는 객체인식 모델의 학습 방법은 전술한 YOLO에 한정되지 않고 다양한 딥러닝 알고리즘으로 구현될 수 있음을 밝혀 둔다. 학습데이터 저장부는 관심객체 검출모듈, 비관심객체 지정모듈에 의해 생성된 학습 데이터를 저 장하는 데이터베이스이다. 일 실시예에서, 학습 데이터 저장부는 비휘발성 메모리로 구성될 수 있다. 비 휘발성 메모리(Non-volatile memory)는 전원이 공급되지 않은 상태에서도 정보를 저장 및 유지하고, 전원이 공 급되면 다시 저장된 정보를 사용할 수 있는 기억 매체를 의미한다. 학습 데이터 저장부는 예를 들어, 플 래시 메모리(flash memory), 하드디스크(hard disk), SSD(Solid State Drive), 멀티미디어 카드 마이크로 타입 (multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 롬(Read Only Memory; ROM), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나로 구성될 수 있다. 도 4에서 학습 데이터 저장부는 컴퓨팅 장치의 메모리가 아닌, 별개의 구성 요소로 도시되었 지만, 이에 한정되는 것은 아니다. 일 실시예에서, 학습 데이터 저장부는 메모리 내에 포함될 수도 있다. 또는 학습 데이터 저장부는 컴퓨팅 장치에 포함되지 않은 구성 요소로서 통신부를 통해 유무선 통신을 통해 연결될 수도 있다. 오검출 필터링 모델은 사용자에 의해 지정된 관심 객체의 특징벡터를 추출하고, 상기 추출된 특징벡터의 확률분포를 구성할 수 있다. 상기 확률분포는 복수의 관심 객체의 특징벡터의 좌표값이 이루는 분포를 의미할 수 있다. 또한, 오검출 필터링 모델은 상기 특징벡터의 확률 분포에 기초하여 관심객체를 결정짓는 임계거 리를 결정할 수 있다. 이에 따라 오검출 필터링 모델은 지정된 관심 객체의 특징벡터 분포의 모델링을 통 해 인식된 특정 객체의 특징벡터가 상기 관심 객체의 특징벡터 분포에서 기 정의된 상기 임계거리와 비교하여 오검출 여부를 필터링할 수 있는 기준을 제공할 수 있다. 또한, 오검출 필터링 모델은 관심 객체로부터 색상정보를 추출하여 분석하고, 주 색상정보를 획득할 수 있 다. 이에 따라 오검출 필터링 모델은 관심객체의 색상 정보에 기초하여 오검출 여부를 필터링할 수 있는기준을 제공할 수 있다. 상기 오검출 필터링 모델에서 모델링되는 데이터들은 기 학습된 관심객체 인식모델과 함께 영상 촬영 장치 로 전송될 수 있다. 영상 촬영 장치(100에서 관심 객체 검출 과정에서 전술한 데이터를 활용할 수도 있다. 도 5는 본 명세서의 일 실시예에 따른 오검출 필터링 방법을 설명하기 위한 전체 순서도를 나타낸다. 도 5를 참조하면, 영상 촬영 장치에서 객체 인식 과정 동안 오검출을 수행하기 위해서는, 객체 인식 모델 및 오 검출을 필터링할 수 있는 모델이 구비되어 있어야 한다. 본 명세서는 설명의 편의를 위하여 학습 단계와 추론 단계로 구분하여 설명하지만, 객체인식 모델을 학습하는 학습장치와, 학습된 모델을 이용하여 객체를 검출하고 오검출을 제거하는 추론장치로 구분될 수도 있다. 다만, 전술한 학습단계, 추론단계, 학습장치, 추론장치의 구 분은 설명의 편의를 위한 것이며, 학습장치와 추론장치 각각의 적어도 일부의 기능은 각 단계(또는 각 장치)에 서 서로 혼용되거나 조합되어 구현될 수 있음은 물론이다. 상기 학습 장치는, 도 5에 도시된 바와 같이 크게 S300 및 S310 단계를 수행함으로써, 정확한 객체 인식을 위한 모델을 학습할 수 있다. S300 에서는 관심객체 및 비관심 객체에 기초하여 객체인식 모델을 학습시킬 수 있다. 또한, S310 에서는 S300에서 학습된 객체인식 모델에 기초하여 검출되는 객체가 사용자가 원하는 관심객체가 아 닌 경우 이를 필터링하여 최종 관심객체를 획득하기 위해 오검출 모델을 학습시킬 수 있다. 상기 오검출 모델은 관심객체의 특징벡터 분포 및 색상정보에 기초하여 검출된 객체 중 최종 관심객체를 필터링할 수 있다. 상기 학습 장치는, 학습한 데이터를 기반으로 관심 객체를 확률적으로 모델링하여 오검출을 분류할 수 있는 모 델 및 주색상 정보를 분석할 수 있는 모델을 생성할 수 있다. 객체인식 모델은 기계학습 분야 중 하나로 패턴인 식, 자료분석을 위한 지도학습 모델인 서포트 벡터 머신(support vector machine, SVM)이 적용될 수 있다. 상기 학습장치는 사용자에 의해 지정되는 관심 객체, 그리고 미리 정해진 기준에 따라 생성되는 비관심 객체를 이용 하여 객체 인식 모델을 학습할 수 있다. 상기 학습장치는, 상기 관심객체의 분포에 대한 모델을 구성할 수 있다. 예를 들어, 학습 장치는 주성분 분석기 법(Principal component analysis, PCA)을 이용하여 관심객체의 특징벡터 데이터들이 공간상에 분포되어 있는 상태에서 퍼짐의 주성분(Principal component, PC)를 확인할 수 있다. 관심객체의 특징벡터가 좌표공간 상에 퍼 져있을 때, 데이터들의 분산을 가장 잘 표현하는 축을 찾음으로써, 차원을 축소할 수 있다. 상기 학습장치는 관 심 객체의 평균, 분산에 기초하여 관심 객체에 대한 분포를 설정함으로써, 관심객체로 판단 가능한 임계거리를 결정할 수 있다. 또한, 상기 학습장치는, 관심객체가 주로 나타내는 색을 측정하여 관심 객체의 대표색으로 객체를 분류하는 색 상 분류 모델을 구성할 수도 있다. 상기 학습장치는 색상분류 모델을 통해 색상 정보를 추출하여 관심객체의 주 색상 정보를 획득할 수 있다. 일 실시예에 따라 상기 학습 장치는, 학습 단계에서 PCA 기반의 제1 오검출 모델과, 색상기준의 제2 오검출 모 델을 생성할 수 있으며, 영상 촬영 장치에서 객체검출 시 상기 제1 오검출 모델과 제2 오검출 모델을 이용하여 오검출 필터링에 활용할 수 있다. 추론장치는 상기 학습 단계에서 학습한 객체인식 모델 및 오검출 모델을 기반으로 관심객체 검출 결과를 필터링 하여 최종 관심 객체 결과를 획득할 수 있다. 상기 추론장치는 학습단계에서 생성된 객체인식 모델(관심객체 인 식모델)에 기초하여 관심 객체를 검출한다(S320). 그리고 추론장치는 학습단계에서 생성된 제1 오검출 모델에 기초하여 특징기반의 오검출을 제거하는 동작을 수행할 수 있다(S321). 추론장치는 학습단계에서 생성된 제2 오 검출 모델에 기초하여 색상 기반 오검출을 제거하는 동작을 수행할 수 있다(S322). 추론 장치는 상기 오검출 제 거 동작에 기초하여 최종 관심객체의 결과를 출력할 수 있다(S323). 상기 추론단계를 수행할 수 있는 추론장치는 도 1에서 설명한 영상 촬영 장치일 수 있으며, 본 명세서는 이에 한정되지 않고, 객체 검출 동작이 영상 관리 서버에서 수행될 경우 상기 추론단계를 수행하는 추론장 치는 영상 관리 서버가 될 수도 있다. 본 명세서에서 사용된 AI 시스템은 감시(Surveillance) 카메라에 관심 객체로 학습된 딥러닝 기반의 객체 탐지 (Object Detection) 알고리즘을 사용할 수 있다. 주로 사용하는 객체탐지(Object Detection) 알고리즘은 YOLO(You Only Look Once)를 포함할 수 있다. YOLO은 정확성은 떨어지지만 객체 검출 속도가 빠르기 때문에 실 시간 동영상인 감시 카메라에 적당한 AI 알고리즘이다. YOLO 알고리즘은 다른 객체 기반 알고리즘들(Faster R- CNN, R_FCN, FPN-FRCN etc..)과 달리 한 장의 입력 영상을 리사이즈(Resize)후 단일 신경망을 단 한번 통과시키며 결과로 각 객체의 위치를 알려 줄 바운딩 박스(Bounding Box)와 객체가 무엇인지 분류 확률을 출력한다. 도 6은 본 명세서의 일 실시예에 따른 객체인식 모델 학습방법의 흐름도이다. 도 7은 본 명세서의 일 실시예에 따라 객체인식 모델의 학습 과정에서 비관심 객체를 학습 데이터로 이용하는 과정을 설명하기 위한 도면이다. 도 8은 본 명세서의 일 실시예에 따른 객체인식 모델의 학습 데이터를 생성하는 예를 설명하기 위한 도면이다. 상기 객체인식 모델 학습방법은 전술한 컴퓨팅 장치(도 1 및 4의 200)의 프로세서가 관심객체 검출모듈 , 비관심객체 지정모듈, 객체인식 모델 학습모듈, 오검출 판단모듈과 관련된 명령어들 또 는 프로그램 코드를 실행함으로써 수행할 수 있다. 이하, 설명의 편의를 위해 상기 객체인식 모델 학습방법은 프로세서(도 4의 250)를 통해 구현되는 것으로 설명한다. 도 6 내지 도 8을 참조하면, 프로세서는 카메라를 통해 획득한 영상에서 관심 객체를 지정하는 입력을 수 신할 수 있다(S400). 컴퓨팅 장치는 입력장치와 연계된 디스플레이를 포함할 수 있으며, 프로세서는 상기 입력장치를 통해 관심 객체를 지정하는 사용자 입력을 수신할 수 있다. 프로세서는 상기 사용자 입력 이 수신됨에 따라 선택된 관심 객체(도 8의 OB1,OB2,OB3)에 대하여 바운딩 박스(I)를 표시하고, 상기 바운딩 박 스의 위치정보(좌표 정보)를 추출할 수 있다(도 8의 (a)). 프로세서는 상기 영상에서 상기 관심 객체를 제외한 영역 중 적어도 일부를 지정하여 비관심 객체를 생성 할 수 있다(S410). 프로세서는 도 8의 (b)에 도시된 바와 같이, 복수의 비관심 객체(Nr)를 생성할 수 있다. 다만, 도 8의 (b)는 설명의 편의를 위해 비관심 객체(Nr)의 바운딩 박스를 표시하였으나, 컴퓨팅 장치 는 생성된 비관심 객체에 대해서는 별도의 바운딩 박스를 표시하지 않을 수 있다. 상기 비관심 객체의 생 성은 도 4의 비관심 객체 지정모듈의 동작을 참조할 수 있다. 프로세서는 상기 관심 객체와 비관심 객체를 학습 데이터로 이용하여 개체인식 모델을 학습할 수 있다 (S420). 일 실시예에 따라, 프로세서는 사전에 마련된 학습데이터를 이용하여 첫번째 학습(학습 1)을 수행할 수 있 다(S421). 프로세서는 상기 첫번째 학습된 모델을 이용하여 객체인동작을 수행할 수 있다. 프로세서는 상기 객체인식 결과 오검출이 존재하는지 여부를 판단할 수 있다(S423). 오검출(false positive)은, 학습된 객체인식 모델을 적용하여 객체인식 동작을 수행한 결과, 관심 객체로 지정되지는 않은 객 체가 인식된 경우를 의미할 수 있다. 일 실시예에 따라, 프로세서는 기 지정된 관심 객체와 상기 객체인식 동작을 수행한 결과 인식된 객체에 대하여 중첩도를 산출하여 오검출 여부를 확인할 수 있다. 프로세서는 IoU(Intersection Over Union) 방식 을 이용하여 관심 객체와 객체인식 동작 수행 결과의 중첩도를 계산할 수 있다. 일 실시예에 따라, 프로세서는 관심 객체와 객체인식 동작 결과 인식된 객체 간의 유사도를 산출할 수도 있다. 프로세서 상기 관심객체의 제1 특징벡터와 객체인식 동작결과 인식된 객체의 제2 특징벡터 간의 상 관관계(correlation)을 수치값으로 나타내는 유사도를 계산할 수 있다. 프로세서는 상기 유사도에 따라 오 검출 여부를 확인할 수도 있다. 일 실시예에 따라, 프로세서는 상기 중첩도 및 유사도에 기초하여 관심 객체가 정상적으로 인식되었는지 여부를 판단할 수 있다. 프로세서는 오검출 객체가 존재하는 것으로 판단한 경우(S423:Y) 오검출 객체를 비관심 객체로 변경할 수 있다(S425). 일 실시예에 따라, 프로세서는 객체인식 결과 오검출 객체의 존재 여부 및/또는 비관심 객체 로의 전환 상태를 사용자가 확인할 수 있도록 컴퓨팅 장치의 디스플레이에 나타내지 않은 상태에서, 오검출 객 체를 비관심 객체로 지정하는 명령어들 또는 프로그램 코드를 실행함으로써 수행할 수 있다. 프로세서는 오검출 객체에서 비관심 객체로 변경된 객체를 학습 데이터로 이용하여 객체인식 모델에 대하 여 반복학습시킬 수 있다(S427). 프로세서는 S421, S423, S427 단계를 반복적으로 수행할 수 있으며 오검출이 존재하지 않는 경우(S423:N), 학습을 종료하고 학습 모델을 신경망 모델로 저장할 수 있다(S430). 즉, 프로세서는 학습 1 부터 학습 N 까지 반복 학습을 수행하는 과정에서 N번째 반복학습 결과에 기초한 객체인식 결과 오검출이 발생되지 않은 경 우, 상기 반복학습을 종료하고 N번째 까지 학습된 객체인식 모델(신경망 모델)을 저장할 수 있다. 프로세서는 반복되는 학습 과정에서 이전 학습 모델을 기반으로 오검출 위치 정보를 자동으로 추출하여 비 관심 객체로 변경할 수 있다. 또한, 프로세서 반복되는 학습 과정에서 이전에 학습한 모델을 기반으로 학습에 도움이 되는 비관심 객체 를 선정할 수도 있다. 일 실시예에 따라 프로세서는 이전 학습된 모델의 신뢰도 스코어(confidence scor e)에 기초하여 비관심 객체를 선정할 수 있다. 도 7은 본 명세서의 일 실시예에 따라 객체인식 모델의 학습 과정에서 비관심 객체를 학습 데이터로 이용하는 과정을 설명하기 위한 도면이다. 도 7을 참조하면, 프로세서는 관심 객체가 지정된 이후 영상에서 관심 객체를 제외한 비관심 영역에서 랜 덤하게 제1 비관심 객체를 생성할 수 있다(S510). 프로세서는 기 지정된 관심 객체와 상기 제1 비관심 객 체를 학습 데이터로 하여 제1 객체인식 모델을 학습시킬 수 있다. 프로세서는 그리드 간격을 변경하면서 복수의 제2 비관심 객체 세트를 생성할 수 있다(S520). 프로세서는 복수의 비관심 객체 세트에 기초하여 학습된 복수의 객체인식 모델(객체인식 모델 #1, 객체인 식 모델 #2, 객체인식 모델 #3,쪋, 객체인식 모델 #n) 중 신뢰도가 가장 높은 모델을 선정하여 신경망 모델로 저장할 수 있다. 일 실시예에 따라 프로세서는 기 마련된 학습 데이터를 기반으로 검증 데이터(validation set)를 생성하고, 검증 데이터에 기초하여 N개의 객체인식 모델 중 신뢰도가 가장 높은 모델을 선택할 수 있다. 한편, 도 7에서 프로세서가 영상의 그리드 간격을 N번 변경하면서 서로 다른 비관심 객체세트를 생성하는 과정을 설명하였으나, 여기서 N은 객체인식 모델을 학습하는 과정에서 프로세서에 의해 유동적으로 선택될 수 있다. 프로세서는 제1 그리드 간격 상태에서 생성된 비관심 객체 세트에 기초한 객체인식 모델의 컨피 던스 스코어(confidence score)가 미리 정해진 임계값 이상인 경우, 비관심 객체세트 생성을 종료할 수 있다. 즉, 프로세서는 상기 미리 정해진 컨피던스 스코어값에 도달하는 객체인식 학습모델이 구현될 때 까지 비 관심 객체세트 생성횟수를 조정할 수 있다. 본 명세서의 일 실시예에서, N개의 비관심 객체세트를 생성하여 N개의 객체인식 모델을 학습하는 것은, 비관심 객체는 프로세서에 의해 랜덤하게 지정되거나, 프로세서가 미리 정해진 그리드 간격을 변경하면서 지정된다 하 더라도 비관심 객체 선택의 불확실성을 완벽하게 제거할 수 없다. 프로세서에 의해 랜덤하게 지정되는 비관심 객체세트는 오검출의 확률을 줄이는데 한계가 있을 수 있다. 이에 따라, 본 명세서는 복의 서로 다른 속성의 비 관심 객체 세트에 기초한 객체인식 모델을 독립적으로 학습하고, 검증 데이터(validation set) 기반의 최적 모 델 선택 과정을 통해 객체인식 모델의 신뢰성을 높일 수 있다. 도 9는 본 명세서의 일 실시예에 따른 객체 검출 장치에서 객체 검출 방법의 흐름도이다. 상기 객체 검출 장치 는 영상 촬영 장치(도 1의 100)일 수 있으며, 상기 도 9에 도시된 객체 검출 방법은 영상촬영 장치의 프로세서 및/또는 AI 프로세서를 통해 구현될 수 있다. 설명의 편의를 위해 상기 객체 검출 방법은 프로세서 의 명령을 통해 수행되는 것으로 설명한다. 프로세서은 학습 장치로부터 관심 객체 인식 모델 및 오검출 필터링 모델을 수신할 수 있다(S700). 상기 학습장치는 영상관리 서버(도 1의 200)에 대응될 수 있으며, 객체인식 모델 및/또는 오검출 필터링 모델을 학습 할 수 있는 모든 컴퓨팅 장치를 포함할 수 있다. 상기 학습장치에서 학습된 관심객체 인식모델은 영상촬영 장치를 통해 획득된 영상에서 사용자에 의해 지정된 관심객체 및 상기 관심객체를 제외한 나머지 영역 중 미리 정해진 기준에 따라 생성된 비관심 객체에 기초하여 학습된 신경망 모델을 의미할 수 있다. 상기 오검출 필터링 모델은 상기 관심 객체의 객체 정보에 기초하여 생성된 필터링 데이터 또는 필터링 모델을 의미할 수 있다. 상기 필터링 데이터는, 관심 객체의 특징분포를 모델링하여 생성된 특징벡터 기반의 확률분포 데이터를 포함할 수 있다. 또한 상기 필터링 데이터는 관심 객체의 주요 색상 정보를 의미하며, 관심 객체와 다 른 색상을 오검출 객체로 필터링하기 위한 필터링 데이터를 포함할 수 있다. 상기 학습장치는 특징벡터 기반의 오검출 필터링 모델과 색상 기반의 오검출 필터링 모델을 각각 구현하여 영창 촬영장치로 전송하면, 영상 촬영 장치에서 객체인식 동작을 수행하는 중 오검출 여부를 판단하는 과정에서 이를 적용할 수 있다. 본 명세서는 오검출 여부 판단 과정은 크게 두 가지로 구분될 수 있다. 첫번째 오검출 여부 판단은 관심객체 인 식 모델을 학습하는 과정에서 사용자에 의해 지정되는 관심객체가 아닌 객체가 검출되는지를 판단하는 과정일 수 있다. 또한, 두 번째 오검출 여부 판단은 오검출 객체를 필터링하는 과정으로서, 학습 단계가 아닌 실제 추론 단계에서 검출된 객체의 특징정보(특징벡터 정보, 색상정보)에 기초하여 오검출을 제거하는 과정일 수 있다. 프로세서는 관심 객체인식 모델에 기초하여 촬영한 영상에서 관심 객체를 검출할 수 있다(S710). 프로세서는 적어도 하나의 검출된 관심객체 후보에 대하여 본 명세서의 일 실시예에 따른 오검출 필터링 모델을 적용하여 오검출 객체의 존재여부를 확인하고, 제거할 수 있다(S720). 프로세서는 상기 수신된 특 징벡터 기반의 오검출 모델을 적용하여 오검출 객체를 필터링할 수 있다. 프로세서는 상기 수신된 색상 기 반의 오검출 모델을 적용하여 오검출 객체를 필터링할 수 있다. 이하, 학습단계에서 오검출 필터링 모델을 구성 하는 방법에 대하여 도 10을 참조하여 보다 구체적으로 설명한다. 본 명세서에서 오검출 필터링 모델은 오검출 제거 모델, 오검출 모델 등의 용어와 동일한 의미로 사용되는 용어 일 수 있다. 도 10은 본 명세서의 일 실시예에 따른 객체인식 방법의 흐름도이다. 도 10을 참조하면, 오검출 제거모델 구성 과 객체검출 동작이 구분될 수 있다. 오검출 제거모델 구성은 전술한 바와 같이 학습 장치에서 구현될 수 있으 며 상기 학습장치는 도 1에서 도시한 영상관리 서버, VMS(Video Management System) 등을 포함할 수 있으 며, 학습 기능을 포함하는 어떠한 컴퓨팅 장치도 포함될 수 있음은 물론이다. 그리고, 객체검출 동작은 전술한 바와 같이 영상 촬영장치(도 1의 100)에서 수행될 수 있으며 상기 영상 촬영 장치는 감시 카메라를 포함할 수 있다. 그러나, 상기 본 명세서에서 상기 객체 검출 동작은 상기 감시 카메라 외에 영상 관리 서버 등에서 수행 할 수도 있다. 설명의 편의를 위해 오검출 필터링 모델 구성은 학습 기능이 있는 컴퓨팅 장치에서 수행하는 것으로 설명하고, 객체 인식(검출) 동작은 감시 카메라에서 수행하는 것으로 설명한다. 컴퓨팅 장치는 특징 벡터 기반의 오검출 모델을 구성하기 위하여 관심객체의 특징 벡터를 추출한다(S810). 여기 서 상기 관심객체는 사용자에 의해 지정된 객체일 수 있다. 컴퓨팅 장치는 PCA 분석 기법에 기초하여 상기 특징 벡터의 확률분포를 설정할 수 있다(S811). 컴퓨팅 장치는 상기 설정된 특징벡터의 확률분포에 기초하여 오검출 판단을 위한 임계거리를 결정할 수 있다(S812). 일 실시예에 따라, 컴퓨팅 장치는 상기 관심객체 분포에 대한 모델의 분포 외부에 존재하는 객체를 오검출로 판단하여 제거할 수 있다. 컴퓨팅 장치는 수집된 관심객체들의 평균(mean), 분산(variance) 기반 분포를 관심객체에 대한 분포를 설정할 수 있다. 컴퓨팅 장치는, 상기 추론단계에서 관심객체가 상기 관심객체 분포에 속하는지는 마할라노비스 거리 (mahalanobis distance)에 기초하여 판단할 수 있다. 컴퓨팅 장치는, 상기 마할라노비스 거리가 임계거리 이하 일 경우 관심객체로 판단하고, 임계거리 이상인 경우 오검출 객체로 판단할 수 있다. 컴퓨팅 장치는 수집된 관심객체(positive sample)들에 대한 분포값을 바탕으로 오검출 필터링 모델의 안정성을 판단할 수 있다. 컴퓨팅 장치는 공분산 행렬(Covariance matrix)에 대한 트레이스(trace) 값에 기초하여 특정 임계치 이하로 안정성을 판단할 수 있다. 컴퓨팅 장치는 색상 기반의 오검출 모델을 구성하기 위하여 관심객체가 주로 나타내는 색을 측정하고, 대표색으 로 객체를 분류하기 위한 색상정보를 추출할 수 있다(S820). 컴퓨팅 장치는 CIE-LAB 색공간에서의 색상을 분석 하여 관심객체의 주요 색상 정보를 획득할 수 있다(S821). CIE-LAB 색공간에서의 색상 분석 및 분류는 색상별 L,A,B 채널 픽셀의 평균 및 표준편차를 통해 분석이 가능하며, 밝기 레벨을 3단계로 나누어 각 레벨에서의 A,B 값에 따른 색상을 분류하고, 각각의 픽셀별로 가장 가까운 색상이 선택될 수 있다. 상기 컴퓨팅 장치에서 구성된 특징벡터 기반의 오검출 필터링 모델(제1 오검출 모델)과 색상기반 오검출 필터링 모델(제1 오검출 모델)은 객체인식 모델과 함께 영상촬영 장치에 전달될 수 있다. 영상촬영 장치는 촬상된 영상으로부터 객체인식 모델 기반의 객체인식 동작을 수행하기 위해 객체를 검출할 수 있다(S830). 영상촬영 장치는 수신한 특징벡터 기반 오검출 제거모델을 이용하여 오검출 제거 동작을 수행할 수 있다(S840). 영상촬영 장치는 수신한 색상 기반 오검출 제거모델을 이용하여 오검출 제거 동작을 수행할 수 있 다(S850). 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있으며, 따라서, 상 기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2023-0001007", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 관한 이해를 돕기 위해 상세한 설명의 일부로 포함되는, 첨부 도면은 본 명세서에 대한 실시예를 제공하고, 상세한 설명과 함께 본 명세서의 기술적 특징을도 설명한다.도 1은 본 명세서의 일 실시예에 따라 학습되는 객체인식 모델이 적용되어 객체를 인식하고, 그 결과를 활용하 는 감시 카메라 시스템을 설명하기 위한 도면이다. 도 2는 본 명세서의 일 실시예에 따른 객체인식 모델을 학습하는데 적용되는 AI 장치(모듈)을 설명하기 위한 도 면이다. 도 3은 본 명세서의 일 실시예에 따른 영상 촬영장치를 설명하기 위한 도면이다. 도 4는 본 명세서의 일 실시예에 따른 객체인식 모델을 학습하는 컴퓨팅 장치를 설명하기 위한 도면이다. 도 5는 본 명세서의 일 실시예에 따른 오검출 필터링 방법을 설명하기 위한 전체 순서도를 나타낸다. 도 6은 본 명세서의 일 실시예에 따른 객체인식 모델 학습방법의 흐름도이다. 도 7은 본 명세서의 일 실시예에 따라 객체인식 모델의 학습 과정에서 비관심 객체를 학습 데이터로 이용하는 과정을 설명하기 위한 도면이다. 도 8은 본 명세서의 일 실시예에 따른 객체인식 모델의 학습 데이터를 생성하는 예를 설명하기 위한 도면이다. 도 9는 본 명세서의 일 실시예에 따른 객체 검출 장치에서 객체 검출 방법의 흐름도이다. 도 10은 본 명세서의 일 실시예에 따른 객체인식 방법의 흐름도이다. 본 명세서에 관한 이해를 돕기 위해 상세한 설명의 일부로 포함되는 첨부 도면은 본 명세서에 대한 실시예를 제 공하고, 상세한 설명과 함께 본 명세서의 기술적 특징을 설명한다."}
