{"patent_id": "10-2022-0032631", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0135319", "출원번호": "10-2022-0032631", "발명의 명칭": "인공지능 기반 강화된 안저영상 생성 방법, 컴퓨터 판독 가능한 기록 매체, 컴퓨터 프로그램", "출원인": "성균관대학교산학협력단", "발명자": "추현승"}}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "초광각 안저영상(UFI:Ultra-wide field Funds Image)인 제1 안저영상으로부터 제1 속성 영역을 검출하는, 검출단계;상기 검출된 제1 속성 영역을 기반으로 실제 CFI(Conventional Fundus Image)인 제2 안저영상이 촬상된 영역에대응하는 상기 제1 안저영상의 일부를 크롭핑하는, 크롭핑 단계;상기 제2 안저영상의 제2 속성정보를 강화하여 만든 제3 속성정보를 가지는 제3 안저영상을 획득하는, 강화 단계;상기 제1 안저영상을 마스킹하는, 마스킹 단계; 및상기 제3 안저영상을 레이블 데이터로서, 마스킹된 상기 제1 안저영상을 학습용 입력 데이터로서 이용하여, 임의의 제1 안저영상 입력으로부터 제 3안저영상을 생성하는 인공지능 모델을 학습시키는, 학습 단계;를 포함하는것을 특징으로 하는 인공지능 기반 위조 안저영상 생성방법."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 검출 단계는,상기 상기 제2 안저영상에 포함된 상기 제1 속성 영역에 기초하여, Faster RCNN검출기를 통해 상기 제1 안저영상에서 상기 제1 속성 영역을 검출하는 것을 특징으로 하는 인공지능 기반 위조 안저영상 생성방법."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 크롭핑 단계는,시신경 유두 및 황반을 포함하는 상기 제1 속성 영역에 대응하는 상기 제1 안저영상의 일부 영역을 크롭핑하는것을 특징으로 하는 인공지능 기반 위조 안저영상 생성방법."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 크롭핑 단계는,상기 제2 안저영상의 중심이 되는 황반의 중심에 위치한 포비아(Fovea), 시신경 유두 중심 및 시신경 유두 반경중 적어도 둘 이상 간의 길이 관계를 기준으로 상기 제1 안저영상에서 크롭핑할 영역을 결정하는 것을 특징으로하는 인공지능 기반 위조 안저영상 생성방법."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 크롭핑 단계는,상기 제1 안저영상에서 크롭핑할 영역을 결정하는데 있어서, 시신경 유두가 상기 제2 안저영상에 포함되도록 하기 위해, 상기 제2 안저영상의 반경()이 하기의 관계식을만족하는 파라미터 α를 설정하되, 공개특허 10-2023-0135319-3-[관계식 1] (상기 관계식 1에서, F는 중심와, O는 시신경 유두 중심, 는 시신경 유두 반경) 상기 파라미터 α 설정에따라 상기 크롭핑된 제1 안저영상에 시신경 유두가 반드시 포함되도록 하는 것을 특징으로 하는 인공지능 기반위조 안저영상 생성방법."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 강화 단계는,상기 크롭핑된 제1 안저영상 또는 상기 제2 안저영상의 입력 이미지에 대해 전방 조도를 추정하여 노출 부족 영역을 보정하고, 반전된 상기 입력 이미지로부터 역조도를 얻어 과다 노출 영역을 보정하며, 두 개의 보정된 이미지를 상기 입력 이미지와 융합하여 최종 개선된 이미지를 획득하는 것을 특징으로 하는 인공지능 기반 위조안저영상 생성방법."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 마스킹 단계는,마스크와 상기 강화된 제1 안저영상 간에 요소별 곱셈을 수행하여 실행하고, 상기 마스크는 흰색의 경우 원의 모양을 가지며, 상기 원 내부의 모든 픽셀은 1의 값을 갖고, 상기 마스킹된 제1 안저영상에서 상기 원 내부는 상기 강화된 제3 안저영상에서와 동일하며, 상기 원 외부에서 픽셀값은 0이며검은색으로 표시되는 것을 특징으로 하는 인공지능 기반 위조 안저영상 생성방법."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 학습 단계는,기계 학습 모델로서 CBAM(Convolutional Block Attention Module)을 사용하여 CycleGAN의 성능을 높인Attention aided CycleGAN을 채용하는 것을 특징으로 하는 인공지능 기반 위조 안저영상 생성방법."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "초광각 안저영상(UFI:Ultra-wide field Funds Image)인 제1 안저영상으로부터 제1 속성 영역을 검출하는, 검출부;상기 검출된 제1 속성 영역을 기반으로 실제 CFI(Conventional Fundus Image)인 제2 안저영상이 촬상된 영역에대응하는 상기 제1 안저영상의 일부를 크롭핑하는, 크롭핑부;상기 제2 안저영상의 제2 속성정보를 강화하여 만든 제3 속성정보를 가지는 제3 안저영상을 획득하는, 강화부;상기 제1 안저영상을 마스킹하는, 마스킹부; 및상기 제3 안저영상을 레이블 데이터로서, 마스킹된 상기 제1 안저영상을 학습용 입력 데이터로서 이용하여, 임의의 제1 안저영상 입력으로부터 강화된 안저영상제3 안저영상을 생성하는 인공지능 모델을 학습시키는, 학습부를 포함하는 것을 특징으로 하는 인공지능 기반 위조 안저영상 생성장치."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 검출부는,공개특허 10-2023-0135319-4-상기 제2 안저영상에 포함된 상기 제1 속성 영역에 대응하여, Faster RCNN 검출기를 이용하여 상기 제1 안저영상에서 상기 제1 속성 영역을 검출하는 것을 특징으로 하는 인공지능 기반 위조 안저영상 생성장치."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 9 항에 있어서,상기 크롭핑부는,시신경 유두 및 황반을 포함하는 상기 제1 속성 영역에 대응하는 상기 제1 안저영상의 일부 영역을 크롭핑하는것을 특징으로 하는 인공지능 기반 위조 안저영상 생성장치."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 크롭핑부는,상기 제2 안저영상의 중심이 되는 황반의 중심에 위치한 포비아(Fovea), 시신경 유두 중심 및 시신경 유두 반경중 적어도 둘 이상 간의 길이 관계를 기준으로 상기 제1 안저영상에서 크롭핑할 영역을 결정하는 것을 특징으로하는 인공지능 기반 위조 안저영상 생성장치."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,상기 크롭핑부는,시신경 유두가 상기 제2 안저영상에 포함되도록 하기 위해, 상기 제2 안저영상의 반경()이 하기의 관계식을만족하는 파라미터 α를 설정하되, [관계식 1] (상기 관계식 1에서, F는 중심와, O는 시신경 유두 중심, 는 시신경 유두 반경) 상기 파라미터 α 설정에따라 상기 크롭핑된 제1 안저영상에 시신경 유두가 반드시 포함되도록 하는 것을 특징으로 하는 인공지능 기반위조 안저영상 생성장치."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 9 항에 있어서,상기 강화부는,상기 크롭핑된 제1 안저영상 및 상기 제2 안저영상의 입력 이미지에 대해 전방 조도를 추정하여 노출 부족 영역을 보정하고, 반전된 상기 입력 이미지로부터 역조도를 얻어 과다 노출 영역을 보정하며, 상기 두 개의 보정된이미지를 상기 입력 이미지와 융합하여 최종 개선된 이미지로서, 상기 제3 안저영상을 획득하는 것을 특징으로하는 인공지능 기반 위조 안저영상 생성장치."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 9 항에 있어서,상기 마스킹부는,마스크와 상기 강화된 제1 안저영상 간에 요소별 곱셈을 수행하여 실행하고, 상기 마스크는 흰색의 경우 원의모양을 가지며, 상기 원 내부의 모든 픽셀은 1의 값을 갖고, 상기 마스킹된 UFI에서 원 내부는 상기 강화된 제1안저영상에서와 동일하고, 상기 원 외부에서 픽셀값은 0이며 검은색으로 표시되는 것을 특징으로 하는 인공지능기반 위조 안저영상 생성장치. 공개특허 10-2023-0135319-5-청구항 16 제 9 항에 있어서,상기 학습부는,상기 인공지능 모델로서 CBAM(Convolutional Block Attention Module)을 사용하여 CycleGAN의 성능을 높인Attention aided CycleGAN을 채용하는 것을 특징으로 하는 인공지능 기반 위조 안저영상 생성장치."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "컴퓨터 프로그램을 저장하고 있는 컴퓨터 판독 가능 기록매체로서,상기 컴퓨터 프로그램은, 프로세서에 의해 실행되면,강화된 안저영상을초광각 안저영상(UFI:Ultra-wide field Funds Image)인 제1 안저영상으로부터 제1 속성 영역을 검출하는, 검출단계;상기 검출된 제1 속성 영역을 기반으로 실제 CFI(Conventional Fundus Image)인 제2 안저영상이 촬상된 영역에대응하는 상기 제1 안저영상의 일부를 크롭핑하는, 크롭핑 단계;상기 제2 안저영상의 제2 속성정보를 강화하여 만든 제3 속성정보를 가지는 제3 안저영상을 획득하는, 강화 단계;상기 제1 안저영상을 마스킹하는, 마스킹 단계; 및상기 제3 안저영상을 레이블 데이터로서, 마스킹된 상기 제1 안저영상을 학습용 입력 데이터로서 이용하여, 임의의 제1 안저영상 입력으로부터 제 3안저영상을 생성하는 인공지능 모델을 학습시키는, 학습 단계;를 포함하는방법을 상기 프로세서가 수행하도록 하기 위한 명령어를 포함하는, 컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2022-0032631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "컴퓨터 판독 가능한 기록매체에 저장되어 있는 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램은, 프로세서에 의해 실행되면,초광각 안저영상(UFI:Ultra-wide field Funds Image)인 제1 안저영상으로부터 제1 속성 영역을 검출하는, 검출단계;상기 검출된 제1 속성 영역을 기반으로 실제 CFI(Conventional Fundus Image)인 제2 안저영상이 촬상된 영역에대응하는 상기 제1 안저영상의 일부를 크롭핑하는, 크롭핑 단계;상기 제2 안저영상의 제2 속성정보를 강화하여 만든 제3 속성정보를 가지는 제3 안저영상을 획득하는, 강화 단계;상기 제1 안저영상을 마스킹하는, 마스킹 단계; 및상기 제3 안저영상을 레이블 데이터로서, 마스킹된 상기 제1 안저영상을 학습용 입력 데이터로서 이용하여, 임의의 제1 안저영상 입력으로부터 제 3안저영상을 생성하는 인공지능 모델을 학습시키는, 학습 단계;를 포함하는방법을 상기 프로세서가 수행하도록 하기 위한 명령어를 포함하는, 컴퓨터 프로그램."}
{"patent_id": "10-2022-0032631", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 기반 위조 안저영상 생성 방법, 컴퓨터 판독 가능한 기록 매체, 컴퓨터 프로그램 및 장치에 관한 것으로, 더욱 상세하게는 UFI로부터 강화된 안저영상을 획득할 수 있는 인공지능 기반 위조 안저영상 생성 방법, 컴퓨터 판독 가능한 기록 매체, 컴퓨터 프로그램 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0032631", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반 강화된 안저영상 생성 방법, 컴퓨터 판독 가능한 기록 매체, 컴퓨터 프로그램 및 장치 에 관한 것으로, 더욱 상세하게는 UFI로부터 인공지능 모델 기반으로 강화된 안저영상을 획득할 수 있는 인공지 능 기반 강화된 안저영상 생성 방법, 컴퓨터 판독 가능한 기록 매체, 컴퓨터 프로그램 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0032631", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "안과 질환의 조기 진단은 환자의 시력 상실 예방을 가능하게 한다. 대부분의 안과 검진 시스템은 기존의 안저영상(Conventional Fundus Image, 이하 CFI) 촬영 기법을 통해 촬영된 영상이 이용되지만, CFI를 얻는 과정에서 환자의 동공 확장을 위해 약물을 투여하고, 15~30분 동안 기다려야 하 는 단점이 있다. 즉, 투여한 약물에 의해 환자의 시력이 흐려지고 눈이 빛에 민감해지게 되며 이러한 현상이 장시간 동안 지속되 어 환자에게 신체적 부담을 주게 되는 것이다. 반면, 초광각 안저영상(Ultra-wide field Funds Image: 이하 UFI)의 경우에는 동공 확장이 필요하지 않은 검사 유형 중 하나로써, 촬영 영역은 매우 광범위하여 CFI에서 촬영되는 영역을 포괄할 수 있는 장점이 있지만, 해상 도나 영상 결함 측면에서 CFI보다 품질이 떨어지는 단점이 있다. 따라서, 이러한 안저영상들의 문제를 상호 보완할 수 있는 기술적 사상이 필요한 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 제10-2306279호 (특허문헌 0002) 대한민국 등록특허 제10-2122302호"}
{"patent_id": "10-2022-0032631", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명은 상술한 바와 같은 문제점을 해결하기 위하여 제안된 것으로, 환자에게 약물 투여를 통한 동 공 확장을 요하는 검사를 실행하지 않고도, UFI로부터 강화된 안저영상을 획득함으로써, 해상도가 높은 CFI를 구현할 수 있는 인공지능 기반 위조 안저영상 생성 방법, 컴퓨터 판독 가능한 기록 매체, 컴퓨터 프로그램 및 장치를 제공하는데 목적이 있다. 본 발명의 목적은 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아래의 기재로부 터 본 발명이 속하는 기술 분야의 통상의 지식을 가진 자에게 명확히 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0032631", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위한 본 발명의 실시예에 따른 인공지능 기반 강화된 안저영상 생성 방법은, 초 광각 안저영상(UFI:Ultra-wide field Funds Image)인 제1 안저영상으로부터 제1 속성 영역을 검출하는, 검출 단계; 상기 검출된 제1 속성 영역을 기반으로 실제 CFI(Conventional Fundus Image)인 제2 안저영상이 촬상된 영역에 대응하는 상기 제1 안저영상의 일부를 크롭핑하는, 크롭핑 단계; 상기 제2 안저영상의 제2 속성정보를 강화하여 만든 제3 속성정보를 가지는 제3 안저영상을 획득하는, 강화 단계; 상기 제1 안저영상을 마스킹하는, 마스킹 단계; 및 상기 제3 안저영상을 레이블 데이터로서, 마스킹된 상기 제1 안저영상을 학습용 입력 데이터로 서 이용하여, 임의의 제1 안저영상 입력으로부터 제 3안저영상을 생성하는 인공지능 모델을 학습시키는, 학습 단계;를 포함한다. 상기와 같은 목적을 달성하기 위한 본 발명의 실시예에 따른 인공지능 기반 강화된 안저영상 생성 장치는, 초광 각 안저영상(UFI:Ultra-wide field Funds Image)인 제1 안저영상으로부터 제1 속성 영역을 검출하는, 검출부; 상기 검출된 제1 속성 영역을 기반으로 실제 CFI(Conventional Fundus Image)인 제2 안저영상이 촬상된 영역에 대응하는 상기 제1 안저영상의 일부를 크롭핑하는, 크롭핑부; 강화부상기 제2 안저영상의 제2 속성정보를 강화 하여 만든 제3 속성정보를 가지는 제3 안저영상을 획득하는, 강화부; 상기 제1 안저영상을 마스킹하는, 마스킹 부; 및 상기 제3 안저영상을 레이블 데이터로서, 마스킹된 상기 제1 안저영상을 학습용 입력 데이터로서 이용하 여, 임의의 제1 안저영상 입력으로부터 제3 안저영상을 생성하는 인공지능 모델을 학습시키는, 학습부를 포함한 다."}
{"patent_id": "10-2022-0032631", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 의한 인공지능 기반 강화된 안저영상 생성 방법에 따르면, 환자에게 약물 투여를 통한 동공 확장을 요하는 검사를 실행하지 않고도, UFI로부터 인공지능 모델 기반으로강화된 안저영상을 획득함으로 써, 해상도가 높은 CFI 품질로 환자의 안과 질환을 검사하는 데에 정확도를 높일 수 있다."}
{"patent_id": "10-2022-0032631", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로부 터 본 발명이 속하는 기술 분야의 통상의 지식을 가진 자에게 명확히 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0032631", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 목적 및 효과, 그리고 그것들을 달성하기 위한 기술적 구성들은 첨부되는 도면과 함께 상세하게 뒤에 설명이 되는 실시 예들을 참조하면 명확해질 것이다. 본 발명을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것 이다. 그리고 뒤에 설명되는 용어들은 본 발명에서의 구조, 역할 및 기능 등을 고려하여 정의된 용어들로서 이 는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있"}
{"patent_id": "10-2022-0032631", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "다. 단지 본 실시 예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술분야에서 통상의 지식을 가 진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 오로지 특허청구범위에 기재된 청구항의 범주에 의하여 정의될 뿐이다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 이하에서는 첨부한 도면을 참조하며, 본 발명의 바람직한 실시예들을 보다 상세하게 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 인공지능 기반 강화된 안저영상 생성장치의 구성을 개략적으로 도시한 블록 도이고, 도 2는 인공지능 기반 강화된 안저영상을 생성하기 위한 전체 프레임워크를 도시한다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 인공지능 기반 강화된 안저영상 생성장치는 검출부, 크롭핑부, 강화부, 마스킹부, 학습부 및 이미지 변환부를 포함하고, 이외에도 촬영부, 통신부, 메모리 등이 더 포함될 수 있다. 인공지능 기반 강화된 안저영상 생성장치는 인공지능 기반으로 초광각 안저영상 변환을 수행하기 위한 소 프트웨어(애플리케이션)가 설치되어 실행될 수 있으며, 검출부, 크롭핑부, 강화부, 마스킹부 , 학습부 및 이미지 변환부의 구성은 장치에서 실행되는 인공지능 기반의 초광각 안저영상 변환을 수행하기 위한 소프트웨어에 의해 제어될 수 있다. 장치는 별도의 단말이거나 또는 단말의 일부 모듈일 수 있다. 또한, 검출부, 크롭핑부, 강화부 , 마스킹부, 학습부 및 이미지 변환부의 구성은 통합 모듈로 형성되거나, 하나 이상의 모 듈로 구비될 수 있다. 그러나, 이와 반대로 각 구성은 별도의 모듈로 이루어질 수도 있다. 장치는 이동성을 갖거나 고정될 수 있으며, 서버(server) 또는 엔진(engine) 형태일 수 있으며, 디바이스 (device), 기구(apparatus), 단말(terminal), UE(User equipment), MS(Mobile station), 무선기기(wireless device), 휴대기기(handheld device) 등 다른 용어로 불릴 수 있다. 장치는 운영체제(Operation system: OS), 즉 시스템을 기반으로 다양한 소프트웨어를 실행하거나 제작할 수 있다. 상기 운영체제는 소프트웨어가 장치의 하드웨어를 사용할 수 있도록 하기 위한 시스템 프로그램으로서, 안드로이드 OS, 윈도우 모바일 OS 등 모바일 컴퓨터 운영체제 및 윈도우 계열, 리눅스 계열, 유닉스 계열, MAC, AIX, HP-UX 등 컴퓨터 운영체제를 모두 포함할 수 있다. 도 3은 기존의 실제 CFI(Conventional Fundus Image, 안저영상)과 UFI(Ultra-wide field Fundus Image, 초광각 안저영상)를 도시한다. 실제 CFI는 시신경 유두, 황반 및 주변 영역만으로 구성되지만, UFI는 실제 CFI가 포함 하는 영역 외에도 더 넓은 영역을 포함하고 있음을 알 수 있다. 전술했듯이, UFI는 환자에게 약물 투여를 통한 동공 확장이 필요하지 않은 검사 유형으로서 촬영 영역이 광범위 하지만, 해상도나 영상 결함 측면에서 CFI보다 품질이 떨어지기 때문에 이와 같은 문제를 해결하기 위해 본 발 명의 일 실시 예에서는 인공지능 기반으로 UFI로부터 강화된 안저영상을 생성하는 기술을 개시하고자 한다. 이를 위해 먼저, 검출부는 UFI로부터 제1 속성 영역을 검출한다. 일 실시예로, 검출부는 인공지능 딥 러닝 알고리즘 기반의 검출기를 이용하여 UFI에서 시신경 유두 및 황반을 포함하는 제1 속성 영역을 검출할 수 있다. 검출부는 인공지능 딥 러닝 알고리즘으로서 일 예로, CNN, R-CNN, Fast RCNN, 및 Faster RCNN 중 어느 하 나를 채용할 수 있다. 도 4는 전술한 인공지능 딥 러닝 알고리즘 중 Faster RCNN에 기반한 검출 프레임워크를 도시하는 도면이다. 도 4를 참조하면 먼저, Faster RCNN은 입력된 UFI에서 CNN(Convolutional Neural Network)을 통하여 특징을 추출 하고, 관심 영역의 특징들에 대한 특징 지도(feature maps)을 만들어, 특징 지도에서 RPN(Region Proposal Network)이 전경 또는 배경을 포함할 수 있는 256개의 ROI(Region of Interesting, 관심영역)을 출력한다. RPN의 제안은 원시 예측이므로 마지막 단계에서 정확한 분류를 위해 분류기에 입력된다. 각 ROI가 시신경 유두, 황반 및 배경의 세 가지 클래스 중 하나로 분류되며, 이때 시신경 유두, 황반 및 배경에 해당하는 바운딩 박스 (bounding box)의 좌표도 분류기에 의해 제공된다. 많은 개체를 제1 속성 영역에 포함되는 시신경 유두와 황반을 기준으로 분류할 수 있고, 이에 UFI에는 정확히 하나의 시신경 유두와 황반을 기반으로 확률이 가장 높은 개체를 최종 결과로 유지할 수 있다. 그리고, 지도 학습에 사용되는 UFI 영상의 레이블 데이터로서 시신경 유두 및 황반에 해당하는 바운딩 박스의 좌표를 이용할 수 있다. 도 10은 저화질의 UFI에서 전술한 Faster RCNN을 기반으로 검출된 시신경 유두와 황반을 도시하고, 도 11은 반 대로 시신경 유두 및 황반 검출에 실패한 사례를 도시하는 예시를 나타낸다. 크롭핑부는 검출부에서 검출된 제1 속성 영역을 기반으로 실제 CFI가 촬상된 영역에 대응하는 UFI의 일부를 크롭핑한다. 즉, 크롭핑부는 시신경 유두 및 황반을 포함하는 제1 속성 영역에 대응하는 UFI의 일부 영역을 크롭핑할 수 있다. 도 5를 참조하면, 크롭핑부는 실제 CFI의 중심이 되는 황반의 중심에 위치한 포비아(Fovea: F), 시신경 유 두 중심(Optic disc center: O) 및 시신경 유두 반경 중 적어도 둘 이상 간의 길이 관계를 설정할 수 있고, 실제 CFI에서 설정된 상기 길이 관계를 UFI에 적용함으로써, UFI에서 실제 CFI와 유사한 영역을 절취하기 위한 크롭핑 영역을 결정할 수 있다. 일 실시예로, 크롭핑부는 UFI에서 절취할 영역을 결정하는데 있어서, 시신경 유두가 실제 CFI에 포함되도 록 하기 위해, 실제 CFI의 반경( )이 하기의 관계식을 만족하는 파라미터 α를 설정하되, 상기 파라미터 α 설정에 따라 상기 크롭핑된 UFI에 시신경 유두가 반드시 포함되도록 할 수 있다. [관계식 1]"}
{"patent_id": "10-2022-0032631", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기 관계식 1에서, F는 중심와, O는 시신경 유두 중심, 는 시신경 유두 반경을 의미한다. 일 예로, 관계식 1에서 상기 파라미터 α를 1보다 크게 설정하여 상기 크롭핑된 UFI에서도 시신경 유두가 반드 시 포함되도록 할 수 있다. 다른 실시에로서, 크롭핑부는 실제 CFI의 중심이 되는 황반의 중심에 위치한 포비아(F), 시신경 유두 중심 (O) 및 시신경 유두 반경 중 적어도 둘 이상 간의 길이 비율을 설정할 수 있고, 실제 CFI에서 설정된 상기 길이 비율을 UFI에 적용함으로써, UFI에서 실제 CFI와 유사한 영역을 절취하기 위한 크롭핑 영역을 결정할 수 있다. 이어, 크롭핑된 UFI와 실제 CFI는 각각 밝기 조정이 필요한 상태로서, 대부분의 UFI는 노출 부족 (underexposure)으로 밝기가 낮고, CFI는 밝기가 낮거나 노출과다(overexposure)에 의해 밝기가 과도하다. 따라 서, 본 발명의 일 실시예에서는 강화부를 통해 노출 부족 이미지와 과다 노출 이미지를 모두 보정하기로 한다. 도 6에 도시된 이중 조도 추정에 의한 밝기 조정 절차에 따르면, 강화부는 첫 번째 행에서 크롭핑된 UFI 또는 실제 CFI의 입력 이미지(input image)에 대해 전방 조도를 추정하여 노출 부족 영역을 보정하고, 반전된 입력 이미지(Inverted input image)로부터 역조도를 얻어 과다 노출 영역을 보정하며, 상기 두 개의 보정된 이 미지를 상기 입력 이미지와 융합하여 최종 개선된 이미지(Final enhanced image)를 획득할 수 있다. 한편, 밝기 조정 절차에 의해 강화된 UFI는 실제 CFI와 같이 마스크가 부재하기 때문에, 아직까지는 이미지 변 환 모델이 마스크를 제대로 생성할 수 없는 바, 마스킹부를 통해 강화 UFI를 미리 마스킹하기로 한다. 마스킹부는 강화된 UFI를 마스킹하기 위해, 도 7에 도시된 바와 같이 마스크와 강화된 UFI 간에 요소별 곱 셈을 수행하여 실행한다. 여기서, 마스크는 흰색의 경우 원의 모양을 가지고, 원 내부의 모든 픽셀은 1의 값을 갖고, 상기 마스킹된 UFI 에서 원 내부는 상기 강화된 UFI에서와 동일하며, 상기 원 외부에서 픽셀값은 0이며 검은색으로 표시된다. 학습부는 강화된 CFI를 레이블 데이터로서, 마스킹된 상기 UFI를 학습용 입력 데이터로서 이용하여, 임의 의 UFI입력으로부터 강화된 안저영상을 생성하는 인공지능 모델을 학습시킨다. 본 발명의 일 실시예에 따른 인공지능 모델은 이미지 간 변환(image-to-image translation)을 위한 모델로서, 서로 다른 도메인의 데이터 셋의 스타일을 바꿀 수 있다. 인공지능 모델은 Attention aided CycleGAN을 채용할 수 있다. Attention aided CycleGAN는 CycleGAN을 근간으로 한다. 이하, CycleGAN에 관해 개략적으로 설명하기로 한다. 기본적으로 뉴럴 네트워크의 성능을 향상시키려면 많은 양의 트레이닝 데이터가 필요하다. 이를 위해서, 여러 데이터 세트가 작성 및 공유된다. 특히 이종의 도메인 데이터 간의 변환을 학습하기 위해서는 대량의 페어드된 (Paired) 데이터가 필요할 수 있다. 그러나, 페어드된 데이터를 얻기 어렵고 비용이 많이 발생하는 문제가 있다. 또한 페어드된 데이터 자체가 존재하지 않을 수 있다. 따라서, 언페어드된 데이터를 이용하여 이종의 도 메인 간의 데이터 변환을 학습시키기 위한 CycleGAN이 개발되었다. 도 8에 도시된 본 발명의 일 실시예에 따른 CycleGAN의 구조를 참조하면, GCFI는 실제 UFI를 강화된 안저영상으 로 변환하는 생성자이고, GUFI는 강화된 안저영상을 UFI로 변환하는 생성자이며, D CFI 및 D UFI는 판별기이다. 반대 도메인을 위한 판별자를 속이도록 학습하는 GAN의 기본 구조가 적용되기 때문에, 서로 적대적 학습을 수행 한다. 다만, 페어드된 이미지가 아니기 때문에 CycleGAN이 입력된 UFI를 전혀 상관없는 이미지로 변경을 수행하여 변 환 정확도가 크게 낮아질 수 있기 때문에, 이를 방지하기 위하여, CycleGAN에서는 GAN과 다르게 추가적인 손실 함수가 적용될 수 있다. 이를 순환 일관성(Cycle Consistency)이라 한다. 그리고, 단순히 UFI 도메인의 이미지를 실제 CFI의 이미지로 매핑하는 것이 아니라, 재변환 했을 때의 동일성까 지 고려하는 제약 조건인 순환 일관성을 CycleGAN에 적용함으로써 학습을 수행할 수 있다. 이는 정확한 페어드 된 데이터가 없기 때문에, 변환된 데이터를 재변환하여 일관성을 유지시킴으로써 뉴럴 네트워크가 정확한 도메 인간의 변환을 수행할 수 있도록 제어하기 위해서이다. 부연하자면, CycleGAN에서는 두 도메인간 이미지 데이터셋을 매핑하고, 순환 일관성 손실(Cycle consistency loss)을 학습하며, 각 도메인을 서로 다른 도메인의 스타일로 이미지간 변환을 하는 적대적(adversarial) 생성 신경망 모델을 개시하고 있다. 적대적(adversarial) 생성 신경망 모델에서 무작위 잡음(random noise)을 입력으로 받은 생성자(Generator)는 무작위 잡음을 통해 위조 이미지, 다시 말해 생성자를 통해 생성된 이미지(Generated image)를 생성하기 위한 학습을 한다. 반대로, 판별자(Discfiminator)는 생성자가 생성한 위조 이미지와 제공되는 데이터 셋의 실제 이 미지(Real image)를 구분한다. 이 과정에서 생성자는 위조 이미지가 판별자를 속이기 위해 실제 이미지와 구별이 가지 않는 이미지를 생성하는 쪽으로 학습되고, 판별자는 위조 이미지와 실제 이미지를 구분하기 위한 방향으로 학습된다. 생성자와 판별자는 서로 적대적(adversarial)인 관계이기 때문에 서로 배반적인 관계라 할 수 있다. 이처럼 CycleGAN은 페어링되지 않은 데이터셋을 사용하기 때문에 데이터셋을 빌드하는데 있어서 큰 강점을 가지 고 있다. 이어서, 전술한 CycleGAN을 근간으로 하는 Attention aided CycleGAN은 출력되는 데이터를 문맥(context)을 고 려한 주의 기반 맵으로 출력하는 CBAM(Convolutional Block Attention Module, 주의 영상 모듈)을 사용하여 cycleGAN의 성능을 높인 프레임워크이다. 본 발명에서 cycleGAN의 장점으로 작용하는 부분은 UFI와 실제 CFI가 동일한 눈의 이미지이거나 다른 눈의 이미 지일 수 있다는 것이다. 생성자 GCFI는 CFI를 생성하는데 사용되고, 판별자 DCFI는 이미지를 실제 CFI와 위장 CFI로 분류한다. 정리하자면, 본 발명의 일 실시예에 의한 cycleGAN의 주요 목표 기능은 실제 UFI를 강화된 안저영상인 위장 CFI 로 변환한 다음, 위장 CFI를 다음 UFI 도메인으로 다시 번역하면 실제 CFI와 마찬가지로 결과가 실제 UFI과 같 아야 하는 것이다. 도 14는 본 발명의 일 실시예에 따른 인공지능 기반 위조 안저영상 생성 방법에 의해 생성된 강화된 안저영상과 실제 CFI를 비교한 사진을 도시한다. 강화된 안저영상과 실제 CFI의 제1 속성 영역이 거의 유사한 것을 확인할 수 있다. 이미지 변환부는 학습부를 통해 학습된 인공지능 모델에 임의의 UFI를 입력하여, 강화된 안저영상을 결과물로 생성함으로써, 초광각 안저영상을 위조 안저영상으로 변환할 수 있다. 도 9는 전술한 생성자와 판별자의 네트워크 아키텍처를 도시한다. 도 9를 참조하면, 본 발명의 일 실시예에서 생성자는 U자형 네트워크인 반면, 판별자는 컨볼루션 계층과 CBAM의 조합으로 구비된다. CBAM은 출력되는 데이터를 문맥(context)과 공간적 특성(Spatial properties)을 고려한 주의 기반 맵으로 출력 하는 CBAM은 분류 작업의 성능을 향상시키기 위해 채용되었기 때문에 판별자의 분류 능력을 향상시키는데 활용한다. CBAM은 이미지의 공간 크기를 절반으로 줄이는 컨볼루션 레이어 다음에 주입된다. CBAM은 특징 지도를 입력으로 수신하고, 이어 일 차원 채널 인식 지도와 이 차원 인식 지도를 추론한다. 채널 인식 모듈은 주어진 입력 영상에 대해서 의미있는 것에 초점을 맞춘다. 공간 인식 모듈은 정보 부분이 있는 곳 에 초점을 맞추며, 채널 인식과는 상호 보완적이다. 채널 인식과 공간 인식을 계산하는 특정한 방법이 알려져 있으며, Woo, “CBAM: Convolutional Block Attention Module” ECCV 2018 등의 간행물에서 찾을 수 있다. 도 12는 본 발명의 일 실시예에 따라 생성된 강화된 안저영상을 활용하는 일 예를 도시한다. 도 12를 참조하면, 본 발명의 일 실시예에 따른 인공지능 기반 강화된 안저영상 생성 장치에 의해 생성된 강화된 안저영상은 질병 의 조기 발견을 위한 자동 진단 도구의 입력으로 활용될 수 있다. 즉, 환자에게 약물 투여를 통한 동공 확장이 필요한 검사를 실행하지 않고도 UFI로부터 강화된 안저영상을 구현 함으로써, 해상도가 높은 CFI 품질로 환자의 안과 질환을 검사하는 데에 정확도를 높일 수 있다. 도 13은 본 발명의 일 실시예에 따른 인공지능 기반 강화된 안저영상 생성 방법을 설명하기 위한 순서도이다. 본 발명의 일 실시예에 따른 인공지능 기반 강화된 안저영상 생성 방법은, 도 1의 장치와 실질적으로 동일 한 구성에서 진행될 수 있다. 따라서, 도 1의 장치와 동일한 구성요소는 동일한 도면부호를 부여하고, 반 복되는 설명은 생략한다. 또한, 본 발명의 일 실시예에 따른 인공지능 기반 강화된 안저영상 생성 방법은 인공지능을 활용한 위조 안저영 상 생성을 수행하기 위한 소프트웨어(어플리케이션)에 의해 실행될 수 있다. 먼저, 초광각 안저영상(UFI)으로부터 제1 속성 영역을 검출한다(S110). 일 실시예로, 검출부는 인공지능 딥 러닝 알고리즘 기반의 검출기를 이용하여 UFI에서 시신경 유두 및 황 반을 포함하는 제1 속성 영역을 검출할 수 있다. 검출부는 인공지능 딥 러닝 알고리즘으로서 일 예로, CNN, R-CNN, Fast RCNN, 및 Faster RCNN 중 어느 하나를 채용할 수 있다. 도 4는 전술한 인공지능 딥 러닝 알고리즘 중 Faster RCNN에 기반한 검출 프레임워크를 도시하는 도면이다. 도 4를 참조하면 먼저, Faster RCNN은 입력된 UFI에서 CNN(Convolutional Neural Network)을 통하여 특징을 추출 하고, 관심 영역의 특징들에 대한 특징 지도(feature maps)을 만들어, 특징 지도에서 RPN(Region Proposal Network)이 전경 또는 배경을 포함할 수 있는 256개의 ROI(Region of Interesting, 관심영역)을 출력한다. RPN의 제안은 원시 예측이므로 마지막 단계에서 정확한 분류를 위해 분류기에 입력된다. 각 ROI가 시신경 유두, 황반 및 배경의 세 가지 클래스 중 하나로 분류되며, 이때 시신경 유두, 황반 및 배경에 해당하는 바운딩 박스 (bounding box)의 좌표도 분류기에 의해 제공된다. 많은 개체를 제1 속성 영역에 포함되는 시신경 유두와 황반을 기준으로 분류할 수 있고, 이에 UFI에는 정확히 하나의 시신경 유두와 황반을 기반으로 확률이 가장 높은 개체를 최종 결과로 유지할 수 있다. 그리고, 지도 학습에 사용되는 UFI 영상의 레이블 데이터로서 시신경 유두 및 황반에 해당하는 바운딩 박스의 좌표를 이용할 수 있다. 도 10은 저화질의 UFI에서 전술한 Faster RCNN을 기반으로 검출된 시신경 유두와 황반을 도시하고, 도 11은 반 대로 시신경 유두 및 황반 검출에 실패한 사례를 도시하는 예시를 나타낸다. 다음으로, 상기 검출된 제1 속성 영역을 기반으로 실제 CFI(Conventional Fundus Image)가 촬상된 영역에 대응 하는 상기 UFI의 일부를 크롭핑하는 크롭핑 단계를 실행한다(S120). 즉, 크롭핑부는 시신경 유두 및 황반을 포함하는 제1 속성 영역에 대응하는 UFI의 일부 영역을 크롭핑할 수 있다. 도 5를 참조하면, 크롭핑부는 실제 CFI의 중심이 되는 황반의 중심에 위치한 포비아(Fovea: F), 시신경 유 두 중심(Optic disc center: O) 및 시신경 유두 반경 중 적어도 둘 이상 간의 길이 관계를 설정할 수 있고, 실제 CFI에서 설정된 상기 길이 관계를 UFI에 적용함으로써, UFI에서 실제 CFI와 유사한 영역을 절취하기 위한 크롭핑 영역을 결정할 수 있다. 일 실시예로, 크롭핑부는 UFI에서 절취할 영역을 결정하는데 있어서, 시신경 유두가 실제 CFI에 포함되도 록 하기 위해, 실제 CFI의 반경( )이 하기의 관계식을 만족하는 파라미터 α를 설정하되, 상기 파라미터 α 설정에 따라 상기 크롭핑된 UFI에 시신경 유두가 반드시 포함되도록 할 수 있다. [관계식 1]"}
{"patent_id": "10-2022-0032631", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "상기 관계식 1에서, F는 중심와, O는 시신경 유두 중심, 는 시신경 유두 반경을 의미한다. 일 예로, 관계식 1에서 상기 파라미터 α를 1보다 크게 설정하여 상기 크롭핑된 UFI에서도 시신경 유두가 반드 시 포함되도록 할 수 있다. 다른 실시에로서, 크롭핑부는 실제 CFI의 중심이 되는 황반의 중심에 위치한 포비아(F), 시신경 유두 중심 (O) 및 시신경 유두 반경 중 적어도 둘 이상 간의 길이 비율을 설정할 수 있고, 실제 CFI에서 설정된 상기 길이 비율을 UFI에 적용함으로써, UFI에서 실제 CFI와 유사한 영역을 절취하기 위한 크롭핑 영역을 결정할 수 있다. 다음으로, 크롭핑된 상기 UFI와 상기 실제 CFI의 속성정보를 강화하여 새로운 속성정보를 갖는 안저영상을 획득 하는 강화 단계를 실행한다(S130) 일 실시예로, 크롭핑된 상기 UFI와 상기 실제 CFI의 밝기를 조정하여 강화된 UFI 및 강화된 CFI를 획득할 수 있 다. 크롭핑된 UFI와 실제 CFI는 각각 밝기 조정이 필요한 상태로서, 대부분의 UFI는 노출 부족(underexposure)으로 밝기가 낮고, CFI는 밝기가 낮거나 노출과다(overexposure)에 의해 밝기가 과도하다. 따라서, 본 발명의 일 실 시예에서는 강화부를 통해 CFI의 속성정보를 강화하여 새로운 속성정보를 가지는 안저영상을 획득하기로 한다. 일 실시예로, 강화부는 노출 부족 이미지와 과다 노출 이미지를 모두 보정하기로 한다. 도 6에 도시된 이중 조도 추정에 의한 밝기 조정 절차에 따르면, 강화부는 첫 번째 행에서 크롭핑된 UFI 또는 실제 CFI의 입력 이미지(input image)에 대해 전방 조도를 추정하여 노출 부족 영역을 보정하고, 반전된 입력 이미지(Inverted input image)로부터 역조도를 얻어 과다 노출 영역을 보정하며, 상기 두 개의 보정된 이 미지를 상기 입력 이미지와 융합하여 최종 개선된 이미지(Final enhanced image)를 획득할 수 있다. 다음으로, 강화된 UFI를 마스킹하는 마스킹 단계를 실행한다(S140). 강화 절차에 의해 강화된 UFI는 실제 CFI와 같이 마스크가 부재하기 때문에, 아직까지는 이미지 변환 모델이 마 스크를 제대로 생성할 수 없는 바, 마스킹부를 통해 강화 UFI를 미리 마스킹하기로 한다. 마스킹부는 강화된 UFI를 마스킹하기 위해, 도 7에 도시된 바와 같이 마스크와 강화된 UFI 간에 요소별 곱 셈을 수행하여 실행한다. 여기서, 마스크는 흰색의 경우 원의 모양을 가지고, 원 내부의 모든 픽셀은 1의 값을 갖고, 상기 마스킹된 UFI 에서 원 내부는 상기 강화된 UFI에서와 동일하며, 상기 원 외부에서 픽셀값은 0이며 검은색으로 표시된다. 다음으로, 상기 강화된 CFI를 레이블 데이터로서, 마스킹된 상기 UFI를 학습용 입력 데이터로서 이용하여, 임의 의 UFI입력으로부터 강화된 안저영상을 생성하는 인공지능 모델을 학습시키는 학습 단계를 실행한다(S150). 학습부는 강화된 CFI 및 마스킹된 UFI를 기반으로 인공지능 모델을 학습시킨다. 본 발명의 일 실시예에 따 른 인공지능 모델은 이미지 간 변환(image-to-image translation)을 위한 모델로서, 서로 다른 도메인의 데이터 셋의 스타일을 바꿀 수 있다. 기계 학습 모델은 Attention aided CycleGAN을 채용할 수 있다. Attention aided CycleGAN는 CycleGAN을 근간으로 한다. 이하, CycleGAN에 관해 개략적으로 설명하기로 한다. 기본적으로 뉴럴 네트워크의 성능을 향상시키려면 많은 양의 트레이닝 데이터가 필요하다. 이를 위해서, 여러 데이터 세트가 작성 및 공유된다. 특히 이종의 도메인 데이터 간의 변환을 학습하기 위해서는 대량의 페어드된 (Paired) 데이터가 필요할 수 있다. 그러나, 페어드된 데이터를 얻기 어렵고 비용이 많이 발생하는 문제가 있다. 또한 페어드된 데이터 자체가 존재하지 않을 수 있다. 따라서, 언페어드된 데이터를 이용하여 이종의 도메인 간의 데이터 변환을 학습시키기 위한 CycleGAN이 개발되었다. 도 8에 도시된 본 발명의 일 실시예에 따른 CycleGAN의 구조를 참조하면, GCFI는 실제 UFI를 강화된 안저영상으 로 변환하는 생성자이고, GUFI는 강화된 안저영상을 UFI로 변환하는 생성자이며, D CFI 및 D UFI는 판별기이다. 반대 도메인을 위한 판별자를 속이도록 학습하는 GAN의 기본 구조가 적용되기 때문에, 서로 적대적 학습을 수행 한다. 다만, 페어드된 이미지가 아니기 때문에 CycleGAN이 입력된 UFI를 전혀 상관없는 이미지로 변경을 수행하여 변 환 정확도가 크게 낮아질 수 있기 때문에, 이를 방지하기 위하여, CycleGAN에서는 GAN과 다르게 추가적인 손실 함수가 적용될 수 있다. 이를 순환 일관성(Cycle Consistency)이라 한다. 그리고, 단순히 UFI 도메인의 이미지를 실제 CFI의 이미지로 매핑하는 것이 아니라, 재변환 했을 때의 동일성까 지 고려하는 제약 조건인 순환 일관성을 CycleGAN에 적용함으로써 학습을 수행할 수 있다. 이는 정확한 페어드 된 데이터가 없기 때문에, 변환된 데이터를 재변환하여 일관성을 유지시킴으로써 뉴럴 네트워크가 정확한 도메 인간의 변환을 수행할 수 있도록 제어하기 위해서이다. 부연하자면, CycleGAN에서는 두 도메인간 이미지 데이터셋을 매핑하고, 순환 일관성 손실(Cycle consistency loss)을 학습하며, 각 도메인을 서로 다른 도메인의 스타일로 이미지간 변환을 하는 적대적(adversarial) 생성 신경망 모델을 개시하고 있다. 적대적(adversarial) 생성 신경망 모델에서 무작위 잡음(random noise)을 입력으로 받은 생성자(Generator)는 무작위 잡음을 통해 강화된 이미지, 다시 말해 생성자를 통해 생성된 이미지(Generated image)를 생성하기 위한 학습을 한다. 반대로, 판별자(Discfiminator)는 생성자가 생성한 강화된 이미지와 제공되는 데이터 셋의 실제 이미지(Real image)를 구분한다. 이 과정에서 생성자는 강화된 이미지가 판별자를 속이기 위해 실제 이미지와 구별이 가지 않는 이미지를 생성하 는 쪽으로 학습되고, 판별자는 강화된 이미지와 실제 이미지를 구분하기 위한 방향으로 학습된다. 생성자와 판 별자는 서로 적대적(adversarial)인 관계이기 때문에 서로 배반적인 관계라 할 수 있다. 이처럼 CycleGAN은 페어링되지 않은 데이터셋을 사용하기 때문에 데이터셋을 빌드하는데 있어서 큰 강점을 가지 고 있다. 이어서, 전술한 CycleGAN을 근간으로 하는 Attention aided CycleGAN은 출력되는 데이터를 문맥(context)을 고 려한 주의 기반 맵으로 출력하는 CBAM(Convolutional Block Attention Module, 주의 영상 모듈)을 사용하여 cycleGAN의 성능을 높인 프레임워크이다. 본 발명에서 cycleGAN의 장점으로 작용하는 부분은 UFI와 실제 CFI가 동일한 눈의 이미지이거나 다른 눈의 이미 지일 수 있다는 것이다. 생성자 GCFI는 CFI를 생성하는데 사용되고, 판별자 DCFI는 이미지를 실제 CFI와 위장 CFI로 분류한다. 정리하자면, 본 발명의 일 실시예에 의한 cycleGAN의 주요 목표 기능은 실제 UFI를 위장 CFI로 변환한 다음, 위 장 CFI를 다음 UFI 도메인으로 다시 번역하면 실제 CFI와 마찬가지로 결과가 실제 UFI과 같아야 하는 것이다. 도 14는 본 발명의 일 실시예에 따른 인공지능 기반 강화된 안저영상 생성 방법에 의해 생성된 강화된 안저영상 과 실제 CFI를 비교한 사진을 도시한다. 강화된 안저영상과 실제 CFI의 제1 속성 영역이 거의 유사한 것을 확인 할 수 있다. 이후, 학습된 인공지능 모델에 임의의 UFI를 입력하여, 강화된 안저영상을 결과물로 생성함으로써, 초광각 안저 영상을 강화된 안저영상으로 변환할 수 있다. 도 9는 전술한 생성자와 판별자의 네트워크 아키텍처를 도시한다. 도 9를 참조하면, 본 발명의 일 실시예에서 생성자는 U자형 네트워크인 반면, 판별자는 컨볼루션 계층과 CBAM의 조합으로 구비된다. 출력되는 데이터를 문맥을 고려한 주의 기반 맵으로 출력하는 CBAM은 분류 작업의 성능을 향상시키기 위해 채용 되었기 때문에 판별자의 분류 능력을 향상시키는데 활용한다. CBAM은 이미지의 공간 크기를 절반으로 줄이는 컨 볼루션 레이어 다음에 주입된다. CBAM은 특징 지도를 입력으로 수신하고, 이어 일 차원 채널 인식 지도와 이 차원 인식 지도를 추론한다. 채널 인식 모듈은 주어진 입력 영상에 대해서 의미있는 것에 초점을 맞춘다. 공간 인식 모듈은 정보 부분이 있는 곳 에 초점을 맞추며, 채널 인식과는 상호 보완적이다. 채널 인식과 공간 인식을 계산하는 특정한 방법이 알려져 있으며, Woo, “CBAM: Convolutional Block Attention Module” ECCV 2018 등의 간행물에서 찾을 수 있다. 이상, 본 발명의 특정 실시예에 대하여 상술하였다. 그러나, 본 발명의 사상 및 범위는 이러한 특정 실시예에 한정되는 것이 아니라, 본 발명의 요지를 변경하지 않는 범위 내에서 다양하게 수정 및 변형이 가능하다는 것을 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자라면 이해할 것이다."}
{"patent_id": "10-2022-0032631", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "따라서, 이상에서 기술한 실시예들은 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이므로, 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 하 며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다."}
{"patent_id": "10-2022-0032631", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 인공지능 기반 강화된 안저영상 생성장치의 구성을 개략적으로 도시한 블록 도이다. 도 2는 인공지능 기반 강화된 안저영상을 생성하기 위한 전체 프레임워크를 도시하는 도면이다. 도 3은 기존의 실제 CFI 및 UFI를 도시하는 도면이다. 도 4는 Faster RCNN에 기반한 검출 프레임워크를 도시하는 도면이다. 도 5는 CFI가 포함하는 영역을 도시하는 도면이다. 도 6은 본 발명의 일 실시예에 따른 이중 조도 추정에 의한 밝기 조정을 진행하는 플로우 챠트이다. 도 7은 본 발명의 일 실시예에 따른 마스킹 과정을 설명하기 위한 예시도이다. 도 8은 본 발명의 일 실시예에 따른 CycleGAN의 프레임워크를 도시하는 도면이다. 도 9는 본 발명의 일 실시예에서 채용된 생성기와 판별기의 네트워크 아키텍쳐를 도시한다. 도 10은 Faster RCNN을 기반으로 검출된 시신경 유두와 황반을 도시한다. 도 11은 시신경 유두 및 황반 검출에 실패한 사례를 도시하는 예시도이다. 도 12는 본 발명의 일 실시예에 따라 생성된 강화된 안저영상을 활용하는 일 예를 도시한다. 도 13은 본 발명의 일 실시예에 따른 인공지능 기반 강화된 안저영상 생성 방법을 설명하기 위한 순서도이다. 도 14는 본 발명의 일 실시예에 따른 인공지능 기반 강화된 안저영상 생성 방법에 의해 생성된 CFI와 실제 CFI 를 비교한 사진이다."}
