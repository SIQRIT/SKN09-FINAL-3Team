{"patent_id": "10-2021-0179973", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0090852", "출원번호": "10-2021-0179973", "발명의 명칭": "복수의 카메라를 이용하여 촬영된 손의 3차원 골격 데이터를 획득하는 전자 장치 및 방법", "출원인": "삼성전자주식회사", "발명자": "김덕호"}}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 복수의 카메라를 이용하여 촬영된 손의 3차원 골격 데이터(skeleton data)를 획득하는 방법에 있어서,제1 카메라를 통해 제1 이미지를 획득하고 제2 카메라를 통해 제2 이미지를 획득하는 단계;상기 제1 이미지로부터 상기 손이 포함된 제1 관심 영역(region of interest, ROI)을 획득하는 단계;상기 제1 관심 영역으로부터, 상기 손의 적어도 하나의 특징점을 포함하는 제1 골격 데이터를 획득하는 단계;상기 제1 골격 데이터, 및 상기 제1 카메라 및 제2 카메라의 상대적 위치 정보에 기초하여 상기 제2 이미지로부터 제2 관심 영역을 획득하는 단계;상기 제2 관심 영역으로부터 상기 손의 적어도 하나의 특징점을 포함하는 제2 골격 데이터를 획득하는 단계; 및상기 제1 골격 데이터 및 상기 제2 골격 데이터에 기초하여, 상기 손의 3차원 골격 데이터를 획득하는 단계를포함하는, 방법."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 이미지로부터 상기 제1 관심 영역을 획득하는 단계는, 상기 제1 이미지를 입력 값으로 하여 상기 손이포함된 이미지 영역을 상기 제1 관심 영역으로 출력하도록 훈련된, 제1 딥러닝(deep learning) 모델을 이용하는것인, 방법."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제1 관심 영역으로부터 상기 제1 골격 데이터를 획득하는 단계는, 상기 제1 관심 영역을 입력 값으로 하여상기 손의 적어도 하나의 특징점을 조인트(joint)로 포함하는 그래프를 상기 제1 골격 데이터로 출력하도록 훈련된, 제2 딥러닝 모델을 이용하는 것인, 방법."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제1 골격 데이터는 상기 적어도 하나의 특징점의 공간 내 기 설정된 원점에 대한 3차원 위치 좌표를 포함하는, 방법."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 제1 골격 데이터, 및 상기 제1 카메라 및 제2 카메라의 상대적 위치 정보에 기초하여 상기 제2 이미지로부터 제2 관심 영역을 획득하는 단계는,상기 제1 골격 데이터에 포함된 적어도 하나의 특징점의 3차원 위치 좌표를 상기 제2 이미지 상의 2차원 위치좌표로 투영(projection) 시키는 단계;상기 제2 이미지로부터, 상기 제1 골격 데이터에 포함된 특징점의 상기 2차원 위치 좌표를 포함하는 블록을 식별하는 단계; 및상기 식별된 블록을 상기 제2 관심 영역으로 결정하는 단계를 포함하는, 방법.공개특허 10-2023-0090852-3-청구항 6 제1항에 있어서,상기 제2 골격 데이터는 상기 적어도 하나의 특징점의 상기 제2 이미지 평면 상 기 설정된 원점에 대한 2차원위치 좌표를 포함하는, 방법."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제2 관심 영역으로부터 상기 제2 골격 데이터를 획득하는 단계는, 상기 제2 관심 영역을 입력 값으로 하여상기 손의 적어도 하나의 특징점을 조인트로 포함하는 그래프를 상기 제2 골격 데이터로 출력하도록 훈련된 제3딥러닝 모델을 이용하는 것인, 방법."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 제1 골격 데이터는 상기 적어도 하나의 특징점의 공간 내 기 설정된 원점에 대한 3차원 위치 좌표를 포함하고,상기 제1 골격 데이터 및 상기 제2 골격 데이터에 기초하여 상기 손의 3차원 골격 데이터를 획득하는 단계는,상기 적어도 하나의 특징점에 대해, 상기 제1 골격 데이터에 포함된 3차원 위치 좌표를 상기 제1 이미지 평면상 2차원 위치 좌표로 투영(projection) 시키는 단계; 및상기 제1 이미지 평면 상에 투영된 2차원 위치 좌표 및 상기 제2 골격 데이터에 포함된 2차원 위치 좌표에 기초하여, 3차원 위치 좌표를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 제2 골격 데이터는 상기 적어도 하나의 특징점의 공간 내 기 설정된 원점에 대한 3차원 위치 좌표를 포함하는, 방법."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 제2 관심 영역으로부터 상기 제2 골격 데이터를 획득하는 단계는, 상기 제2 관심 영역을 입력 값으로 하여상기 손의 적어도 하나의 특징점을 조인트로 포함하는 그래프를 상기 제2 골격 데이터로 출력하도록 훈련된 제2딥러닝 모델을 이용하는 것인, 방법."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 제1 골격 데이터는 상기 적어도 하나의 특징점의 공간 내 기 설정된 원점에 대한 3차원 위치 좌표를 포함하고,상기 제1 골격 데이터 및 상기 제2 골격 데이터에 기초하여 상기 손의 3차원 골격 데이터를 획득하는 단계는,상기 적어도 하나의 특징점에 대해, 상기 제1 골격 데이터에 포함된 3차원 위치 좌표 및 상기 제2 골격 데이터에 포함된 3차원 위치 좌표의 평균(average)값에 기초하여, 3차원 위치 좌표를 획득하는 단계를 포함하는,방법."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 제1 골격 데이터 및 상기 제2 골격 데이터에 기초하여 상기 손의 3차원 골격 데이터를 획득하는 단계는,상기 적어도 하나의 특징점에 대해, 상기 제1 골격 데이터에 포함된 위치 좌표 및 상기 제2 골격 데이터에 포함공개특허 10-2023-0090852-4-된 위치 좌표의 가중치 결합에 기초하여, 3차원 위치 좌표를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "전자 장치에 있어서,제1 카메라;제2 카메라;적어도 하나의 명령어(instruction)를 저장하는 저장부; 및상기 저장부에 저장된 적어도 하나의 명령어를 실행하는 적어도 하나의 프로세서를 포함하고,상기 프로세서는 상기 적어도 하나의 명령어를 실행함으로써,상기 제1 카메라를 통해 제1 이미지를 획득하고 상기 제2 카메라를 통해 제2 이미지를 획득하고,상기 제1 이미지로부터, 손이 포함된 제1 관심 영역(region of interest, ROI)을 획득하고,상기 제1 관심 영역으로부터, 상기 손의 적어도 하나의 특징점을 포함하는 제1 골격 데이터를 획득하고,상기 제1 골격 데이터, 및 상기 제1 카메라 및 제2 카메라의 상대적 위치 정보에 기초하여 상기 제2 이미지로부터 제2 관심 영역을 획득하고,상기 제2 관심 영역으로부터 상기 손의 적어도 하나의 특징점을 포함하는 제2 골격 데이터를 획득하고,상기 제1 골격 데이터 및 상기 제2 골격 데이터에 기초하여, 상기 손의 3차원 골격 데이터를 획득하는, 전자 장치."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 프로세서는 상기 적어도 하나의 명령어들을 실행하여, 상기 제1 이미지를 입력 값으로 하여 상기 손이 포함된 이미지 영역을 상기 제1 관심 영역으로 출력하도록 훈련된, 제1 딥러닝(deep learning) 모델을 이용하여,상기 제1 이미지로부터 상기 제1 관심 영역을 획득하는, 전자 장치."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 프로세서는 상기 적어도 하나의 명령어들을 실행하여, 상기 제1 관심 영역을 입력 값으로 하여 상기 손의적어도 하나의 특징점을 조인트로 포함하는 그래프를 상기 제1 골격 데이터로 출력하도록 훈련된, 제2 딥러닝모델을 이용하여, 상기 제1 관심 영역으로부터 상기 제1 골격 데이터를 획득하는, 전자 장치."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서,상기 제1 골격 데이터는 상기 적어도 하나의 특징점의 공간 내 기 설정된 원점에 대한 3차원 위치 좌표를 포함하고,상기 프로세서는 상기 적어도 하나의 명령어들을 실행하여,상기 제1 골격 데이터에 포함된 적어도 하나의 특징점의 3차원 위치 좌표를 상기 제2 이미지 상의 2차원 위치좌표로 투영(projection) 시키고,상기 제2 이미지로부터, 상기 제1 골격 데이터에 포함된 특징점들의 상기 2차원 위치 좌표를 포함하는 블록을식별하고,상기 식별된 블록을 상기 제2 관심 영역으로 결정하는, 전자 장치."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "공개특허 10-2023-0090852-5-제13항에 있어서,상기 제2 골격 데이터는 상기 적어도 하나의 특징점의 상기 제2 이미지 평면 상 기 설정된 원점에 대한 2차원위치 좌표를 포함하는, 전자 장치."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 프로세서는 상기 적어도 하나의 명령어들을 실행하여, 상기 제2 관심 영역을 입력 값으로 하여 상기 손의적어도 하나의 특징점을 조인트로 포함하는 그래프를 상기 제2 골격 데이터로 출력하도록 훈련된 제3 딥러닝 모델을 이용하여, 상기 제2 관심 영역으로부터 상기 제2 골격 데이터를 획득하는, 전자 장치."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서,상기 제1 골격 데이터는 상기 적어도 하나의 특징점의 공간 내 기 설정된 원점에 대한 3차원 위치 좌표를 포함하고,상기 프로세서는 상기 적어도 하나의 명령어들을 실행하여,상기 적어도 하나의 특징점에 대해, 상기 제1 골격 데이터에 포함된 3차원 위치 좌표를 상기 제1 이미지 평면상 2차원 위치 좌표로 투영(projection) 시키고,상기 제1 이미지 평면 상에 투영된 2차원 위치 좌표 및 상기 제2 골격 데이터에 포함된 2차원 위치 좌표에 기초하여, 3차원 위치 좌표를 획득하는, 전자 장치."}
{"patent_id": "10-2021-0179973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항 내지 제12항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2021-0179973", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 복수의 카메라를 이용하여 촬영된 손의 3차원 골격 데이터를 획득하는 방법이 제공된다. 방법은, 제 1 카메라를 통해 제1 이미지를 획득하고 제2 카메라를 통해 제2 이미지를 획득하는 단계, 제1 이미지로부터 손이 포함된 제1 관심 영역(region of interest, ROI)을 획득하는 단계, 제1 관심 영역으로부터, 손의 적어도 하나의 특징점을 포함하는 제1 골격 데이터를 획득하는 단계, 제1 골격 데이터, 및 제1 카메라 및 제2 카메라의 상대적 위치 정보에 기초하여 제2 이미지로부터 제2 관심 영역을 획득하는 단계, 제2 관심 영역으로부터, 손의 적어도 하나의 특징점을 포함하는 제2 골격 데이터를 획득하는 단계, 및 제1 골격 데이터 및 제2 골격 데이터에 기초하 여, 손의 3차원 골격 데이터를 획득하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0179973", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 한정된 전력 예산(power budget) 내에서 복수의 카메라를 통해 촬영된 이미지로부터 사용자 손의 3차 원 골격 데이터를 획득하는 전자 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0179973", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기술의 발달로 가상 현실(virtual reality, VR) 또는 증강 현실(augmented reality, AR)을 제공하는 컨텐츠 (content)의 보급이 증가하고 있다. VR 또는 AR을 제공하기 위한 전자 장치들 중에는 신체에 착용할 수 있는 형 태로 제공되는 전자 장치들이 있다. 이러한 전자 장치들은 통상적으로 웨어러블 디바이스(wearable device)라고 할 수 있다. 신체에 착용할 수 있는 전자 장치들의 형태들 중에 HMD(head mounted device)와 같은 헤드 장착형 전자 장치가 포함될 수도 있다. 헤드 장착형 전자 장치는 사용자의 신체 일부(예를 들면, 사용자의 머리)에 착 용되어 사용자에게 VR 또는 AR 환경을 제공할 수 있다. AR 환경의 제공이란 예를 들어, 증강 현실을 구현할 수 있는 디스플레이 및 다양한 사용자 인터페이스의 제공을 포함할 수 있다. 증강 현실 기술은 현실의 환경에 가상 사물이나 정보를 합성하여, 가상 사물이나 정보가 현실의 물리적 환경에 존재하는 사물처럼 보이도록 하는 기술이다. 현대의 컴퓨팅 및 디스플레이 기술은 증강 현실 경험을 위한 시스 템의 개발을 가능하게 하였는데, 증강 현실 경험에서는, 디지털적으로 재생성된 이미지 또는 그 일부가, 현실인 것처럼 생각되거나 또는 현실로서 인식될 수 있는 방식으로 사용자에게 제시될 수 있다. 터치 조작이 불가능하며, 별도의 입력 장치를 사용하기도 용이하지 않은 헤드 장착형 웨어러블 디바이스에서는, 사용자의 손의 3차원적 포즈(pose)와 제스처(gesture)를 이용하는 핸드 인터랙션(hand interaction)이 입력 인 터페이스로서 중요하다. 따라서, 보다 실감나는 증강 현실 기술의 구현을 위해서는 손의 3차원적 포즈(형태)를 정확히 추정하고 제스처를 정확히 인식하는 기술이 요구된다.증강 현실 기술에 대한 관심이 높아짐에 따라, 증강 현실을 구현하는 다양한 기술들에 대한 개발이 활발하게 이 루어지고 있다. 특히 경량의 헤드 장착형 전자 장치에서는 배터리 용량이 한정적이다. 이에 따라, 복수의 카메 라를 이용해 사용자의 손의 포즈 및 제스처를 인식할 때 전자 장치에서 소비하는 전력의 양을 줄일 수 있는 기 술이 요구된다."}
{"patent_id": "10-2021-0179973", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일 실시예는, 전자 장치에 포함된 복수의 카메라들 중 어느 하나를 통해 획득한 이미지에 대해서만, 손에 대응되는 이미지가 포함된 관심 영역을 검출하는 동작을 수행함으로써, 이미지에서 손의 위치를 찾는 검출 동작의 수행 횟수를 줄여, 손의 3차원 골격 데이터를 획득하는 동작의 총 연산 시간을 줄일 수 있고, 전자 장치 에서 소비하는 전력의 양을 줄일 수 있는, 전자 장치 및 방법을 제공할 수 있다. 본 개시의 일 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제로 한정되지 않으며, 이하의 실시예들로부터 또 다른 기술적 과제들이 유추될 수 있다."}
{"patent_id": "10-2021-0179973", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 개시된 전자 장치가 복수의 카메라를 이용하여 촬영된 손의 3차원 골격 데이터(skeleton data)를 획득하는 방법은, 제1 카메라를 통해 제1 이미지를 획득하고 제2 카 메라를 통해 제2 이미지를 획득하는 단계, 제1 이미지로부터 손이 포함된 제1 관심 영역(region of interest, ROI)을 획득하는 단계, 제1 관심 영역으로부터, 손의 적어도 하나의 특징점을 포함하는 제1 골격 데이터를 획득 하는 단계, 제1 골격 데이터, 및 제1 카메라 및 제2 카메라의 상대적 위치 정보에 기초하여 제2 이미지로부터 제2 관심 영역을 획득하는 단계, 제2 관심 영역으로부터, 손의 적어도 하나의 특징점을 포함하는 제2 골격 데이 터를 획득하는 단계, 및 제1 골격 데이터 및 제2 골격 데이터에 기초하여, 손의 3차원 골격 데이터를 획득하는 단계를 포함할 수 있다. 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 개시된 복수의 카메라를 이용하여 손의 3차원 좌표를 획득하는 전자 장치는, 제1 카메라, 제2 카메라, 적어도 하나의 명령어(instruction)를 저장하는 저장부, 및 저 장부에 저장된 적어도 하나의 명령어를 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 프로세서는 적어도 하나의 명령어를 실행함으로써, 제1 카메라를 통해 제1 이미지를 획득하고 제2 카메라를 통해 제2 이미지를 획 득하고, 제1 이미지로부터 손이 포함된 제1 관심 영역을 획득하고, 제1 관심 영역으로부터 손의 적어도 하나의 특징점을 포함하는 제1 골격 데이터를 획득하고, 제1 골격 데이터, 및 상기 제1 카메라 및 제2 카메라의 상대적 위치 정보에 기초하여 제2 이미지로부터 제2 관심 영역을 획득하고, 제2 관심 영역으로부터 손의 적어도 하나의 특징점을 포함하는 제2 골격 데이터를 획득하고, 제1 골격 데이터 및 제2 골격 데이터에 기초하여 손의 3차원 골격 데이터를 획득할 수 있다. 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 개시된, 컴퓨터로 읽을 수 있는 기록 매체는, 개시된 방법의 실시예들 중에서 적어도 하나를 컴퓨터에서 실행시키기 위한 프로그램이 저장된 것일 수 있다."}
{"patent_id": "10-2021-0179973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시의 실시예들에서 사용되는 용어는 본 개시의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용 어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라 질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 실시예의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 본 명세서에 기재 된 \"~부\", \"~모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적 합한(suitable for)\", \"~하는 능력을 가지는(having the capacity to)\", \"~하도록 설계된(designed to)\", \"~하 도록 변경된(adapted to)\", \"~하도록 만들어진(made to)\", 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용 될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 시스템\"이라는 표현은, 그 시스템이 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C 를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로 세서), 또는 메모리에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있 는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델(또는, 딥러닝 모델)이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모 델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습 (supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또 는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델(또는, 딥러닝 모델)은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각 은 복수의 가중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간 의 연산을 통해 신경망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모 델의 학습 결과에 의해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경 망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q- Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 개시에서 카메라의 ‘시야(Field of View, FOV)’는 카메라를 통해 촬영된 이미지 또는 영상의 영역을 나타 낸다. 시야는 시야각(FOV degree)으로 지칭될 수도 있다. 카메라를 통해 촬영된 이미지 또는 영상의 영역은, 곧 디스플레이 화면 범위(screen area) 내에 표시되는 이미지 또는 영상의 영역을 나타낼 수도 있다. 본 개시에서 ‘영상(video)’ 또는 ‘이미지 시퀀스(image sequence)’는 움직이는 화상 또는 동영상을 나타낼 수 있다. 영상 또는 이미지 시퀀스는 시간적 선후관계를 가지는 일련의 정지 화상들을 포함할 수 있다. 본 개시에서 ‘영상의 프레임(video frame)’ 또는 ‘이미지(image)’는 디스플레이에 출력되는 정지 이미지의 낱장을 나타낼 수 있다. 즉, 연속된 장면을 짧은 시간 간격으로 표시하여 움직이는 화상을 만들어내는 영상에 있어서, 각각의 장면의 낱장을 나타낼 수 있다. 본 개시에서 ‘특징점(keypoint, feature point)’은 영상 또는 이미지 내에서 주위 배경과 구분되거나 식별이 용이한 지점을 나타낼 수 있다. 특징점은 영상에서 물체를 추적하거나 인식 할 때 이용될 수 있다. 예를 들어, 물체의 형태나 크기나 위치가 변해도 쉽게 식별이 가능한 점(point), 또는 카메라의 시점이나 조명이 변해도 쉽 게 식별이 가능한 점(point)을 특징점으로 설정할 수 있다. 예를 들어, 객체 이미지의 코너점(comer point)이나 객체의 경계선 상에 위치하는 점들이 특징점이 될 수 있다. 추적 대상이 되는 물체가 사용자의 손(hand)인 경우, 관절 부분에 특징점이 포함될 수 있다. 본 개시에서 '그래프(graph)'는 점(노드, node)들과 점들을 연결하는 선(엣지, edge)들로 구성된 구조화된 정보 의 집합을 나타낼 수 있다. 그래프를 통해 노드들 간의 연결 관계를 구조적으로 나타낼 수 있다. 그래프는 노드 들 및 노드들 간의 관계를 계층화 하여 표현함으로써 생성될 수 있으며, 노드들이 엣지를 통해 연결되는 트리플 구조를 가질 수 있다. 본 개시에서 손의 '골격 데이터(skeleton data)'는 손의 적어도 하나의 특징점들을 조인트(joint)로 포함할 수 있다. 골격 데이터는 복수의 조인트들에 대한 좌표 정보를 포함하는 '데이터 세트(data set)'일 수 있다. 본 개 시에서 골격 데이터는 '골격 그래프(skeleton graph)'를 포함할 수 있다. 골격 그래프는 손의 적어도 하나의 특 징점들을 노드로 포함할 수 있다. 즉, 골격 그래프의 노드는 손의 조인트(특징점)에 대응될 수 있다. 손의 특징 점은 손의 관절 부위에 포함될 수 있다. 골격 그래프는 동일한 손가락에서 인접한 관절 쌍에 대응되는 노드들을 연결하는 엣지를 포함할 수 있다. 손의 골격 그래프는 손의 3차원적 포즈를 결정하는 동작에 이용될 수 있다. 본 개시에서 ‘제스처(gesture)’는 손, 발 등의 신체 일부 또는 특정한 물건과 같은 객체(object)의 움직임을 나타낼 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 본 개시의 일 실시예에 따른 전자 장치가 복수의 카메라를 이용하여 손(H)의 3차원 골격 데이터(H C)를 획득하는 방법의 개요도이다.본 개시의 일 실시예에 따른 전자 장치는, 복수의 카메라를 이용하여 영상 또는 이미지 시퀀스를 획득할 수 있는 증강 현실 장치(augmented reality device, AR device)를 포함할 수 있다. 증강 현실 장치는 증강 현실 (augmented reality, AR)을 표현할 수 있는 장치로서, 현실에 존재하는 물리적 대상체(physical object) 및 가 상 대상체(virtual object)를 포함하는 이미지를 표시할 수 있다. 전자 장치는 예를 들어, 사용자가 안면부에 착용하는 안경 형상의 증강 현실 안경 장치(augmented reality glasses), 두부에 착용하는 헤드 마운트 디스플레이 장치(head mounted display, HMD), 가상 현실 헤드셋 (virtual reality headset, VRH), 또는 증강 현실 헬멧(augmented reality helmet) 등을 포함할 수 있다. 한편, 본 개시의 전자 장치는 전술한 예시로 한정되는 것은 아니며, 사용자에게 가상 현실 서비스 또는 증강 현 실 서비스를 제공하거나, 복수의 카메라를 이용해 손의 3차원 포즈(pose) 및 손의 제스처(gesture)를 인식하는 다양한 종류의 기기를 포함할 수 있다. 일 실시예에서, 손(H)의 3차원 포즈는 ‘손 골격 감지 및 추적(hand skeleton detection and tracking)’기술 을 통해 인식될 수 있다. 손 골격 감지 및 추적 기술은, 사람의 손(H) 이미지 상에서 움직이는 관절 부위를 탐 지하여, 미리 정해진 골격(skeleton) 구조를 분할해서 투영해 주는 기술이다. 일 실시예에서, 사람의 손의 골격 구조는 각 손가락의 끝점(5개), 각 손가락의 관절점(5*3=15개), 및 손바닥 점(1개)을 포함할 수 있으나, 이에 한정되는 것은 아니다. 증강 현실 서비스를 제공하는 전자 장치에서 사용자의 손(H)의 3차원적 포즈와 제스처를 이용하는 핸드 인 터랙션(hand interaction)은 주요한 입력 인터페이스 중 하나로 기능한다. 일 실시예에서, 전자 장치는 사 용자의 손(H)의 3차원 이미지를 획득하기 위한 복수의 카메라를 포함할 수 있다. 복수의 카메라를 이용하는 경 우, 복수의 카메라 각각으로부터 획득된 복수의 상으로부터 촬영 대상 객체까지의 거리를 계산할 수 있고, 촬영 대상 객체에 대한 3차원 이미지를 획득할 수 있다. 특정 물체의 3차원 이미지는, 해당 물체에 대응되는 이미지에 포함된 각 픽셀의 깊이 정보를 포함할 수 있다. 복수의 카메라들의 집합은 연산 카메라(computational camera)에 대응될 수 있고, 피사체들로부터 복수의 카메 라들 각각의 카메라의 렌즈를 통해 들어오는 이미지를 연산을 통해 재가공하여 깊이 정보를 포함하는 3차원 이 미지를 생성할 수 있다. 일 실시예에서, 특정 물체의 3차원 이미지는 해당 물체의 특징점들의 3차원 좌표 정보 를 포함할 수 있다. 예를 들어, 사용자 손(H)은 복수의 관절(조인트)들에 각각 대응되는 복수의 특징점들을 포함할 수 있고, 복수의 카메라들을 통해 획득된 사용자 손(H)의 3차원 이미지는 복수의 관절들 각각에 대한 기 설정된 원점으로부터의 3차원 좌표 정보를 포함할 수 있다. 도 1을 참조하면 단계 110에서 전자 장치는 복수의 카메라를 이용하여 전자 장치를 착용한 사용자의 손 (H)을 촬영할 수 있다. 일 실시예에서, 전자 장치는 두 개의 카메라를 포함할 수 있다. 전자 장치는 제 1 카메라를 통해 제1 이미지(IM1)를 획득하고, 제2 카메라를 통해 제2 이미지(IM2)를 획득할 수 있다. 제1 이미 지(IM1) 및 제2 이미지(IM2)는 각각 사용자의 손(H)에 대응되는 이미지를 포함할 수 있다. 단계 120에서, 전자 장치는 제1 이미지(IM1)로부터 사용자의 손(H)에 대응되는 손 이미지가 포함된 제1 관 심 영역(region of interest 1, ROI1)을 획득할 수 있다. 예를 들어, 제1 관심 영역(ROI1)은 손 이미지를 포함 하는 블록(block) 또는 윈도우(window) 형태를 가질 수 있다. 일 실시예에서, 제1 이미지(IM1)로부터 제1 관심 영역(ROI1)을 획득하는 동작에서는, 제1 이미지(IM1)를 입력 값으로 하여 손 이미지를 포함하는 이미지 영역을 제1 관심 영역(ROI1)으로 출력하도록 훈련된, 제1 딥러닝(deep learning) 모델이 이용될 수 있다. 제1 이미지 (IM1)로부터 제1 관심 영역(ROI1)을 획득하는 동작에 대해서는 후술할 도 3을 참조하여 보다 자세히 설명하도록 한다. 단계 130에서, 전자 장치는 제1 관심 영역(ROI1)으로부터, 손(H)의 적어도 하나의 특징점을 포함하는 제1 골격 데이터(HC1)를 획득할 수 있다. 예를 들어, 제1 골격 데이터(HC1)는 엣지와 노드를 포함하는 골격 그래프 일 수 있다. 손(H)의 적어도 하나의 특징점은 손의 관절 부분에 포함될 수 있다. 예를 들어, 제1 골격 데이터 (HC1)는 손의 적어도 하나의 특징점(예를 들어, 조인트)에 대한 좌표 정보를 포함하는 데이터 세트일 수 있다. 손의 특징점에 대한 좌표 정보는 2차원 좌표 값 또는 3차원 좌표 값을 포함할 수 있다. 일 실시예에서, 제1 관심 영역(ROI1)으로부터 제1 골격 데이터(HC1)를 획득하는 동작에서는, 제2 딥러닝 모델이 이용될 수 있다. 제2 딥러닝 모델은 제1 관심 영역(ROI1)을 입력 값으로 하여 손(H)의 제1 골격 데이터(HC1)를 출력하도록 훈련될 수 있다. 예를 들어, 제2 딥러닝 모델은 제1 관심 영역(ROI1)을 입력 값으로 하여 손(H)의적어도 하나의 특징점에 대한 좌표 값을 포함하는 제1 골격 데이터(HC1)를 출력하도록 훈련될 수 있다. 일 실시 예에서, 제2 딥러닝 모델을 이용하여 획득된 제1 골격 데이터(HC1)에 포함된 각각의 특징점들은, 공간 내의 기 설정된 원점에 대한 3차원 위치 좌표에 대응될 수 있다. 제1 관심 영역(ROI1)으로부터, 손(H)의 적어도 하나의 특징점을 포함하는 제1 골격 데이터(HC1)를 획득하는 동 작에 대해서는 후술할 도 4를 참조하여 보다 자세히 설명하도록 한다. 단계 140에서, 전자 장치는 제1 골격 데이터(HC1), 및 제1 카메라와 제2 카메라의 상대적 위치 정보에 기초 하여 제2 이미지(IM2)로부터 제2 관심 영역(ROI2)을 획득할 수 있다. 제2 관심 영역(ROI2)은 제2 이미지(IM2) 내에서 사용자의 손(H)에 대응되는 이미지가 포함되는 영역을 나타낼 수 있다. 일 실시예에서, 제1 골격 데이터 (HC1)에 기초하여 제2 이미지(IM2)로부터 제2 관심 영역(ROI2)을 획득하는 동작은, 제1 골격 데이터(HC1)에 포 함된 적어도 하나의 특징점에 대해, 대응되는 3차원 위치 좌표를 제2 이미지(IM2) 상의 2차원 위치 좌표로 투영 (projection) 시키는 단계, 제2 이미지(IM2)로부터, 제1 골격 데이터(HC1)에 포함된 특징점들의 2차원 위치 좌 표들을 포함하는 블록을 식별하는 단계, 및 식별된 블록을 제2 관심 영역(ROI2)으로 결정하는 단계를 포함할 수 있다. 이 때, 제1 골격 데이터(HC1)에 포함된 특징점의 3차원 위치 좌표를 제2 이미지(IM2) 상의 2차원 위치 좌 표로 투영(projection) 시키는 단계에서, 제1 카메라와 제2 카메라의 상대적인 위치 정보가 이용될 수 있다. 제 1 카메라와 제2 카메라의 상대적인 위치 정보는, 제1 카메라와 제2 카메라의 간격 또는 베이스라인(baseline)에 대응될 수 있다. 제1 골격 데이터(HC1)에 기초하여 제2 이미지(IM2)로부터 제2 관심 영역(ROI2)을 획득하는 동 작에 대해서는 후술할 도 5를 참조하여 보다 자세히 설명하도록 한다. 단계 150에서, 전자 장치는 제2 관심 영역(ROI2)으로부터 손(H)의 적어도 하나의 특징점을 포함하는 제2 골 격 데이터(HC2)를 획득할 수 있다. 예를 들어, 제2 골격 데이터(HC2)는 엣지와 노드를 포함하는 골격 그래프일 수 있다. 손(H)의 적어도 하나의 특징점은 손의 관절 부분에 포함될 수 있다. 예를 들어, 제2 골격 데이터(HC 2)는 손의 적어도 하나의 특징점(예를 들어, 조인트)에 대한 좌표 정보를 포함하는 데이터 세트일 수 있다. 일 실시예에서, 제2 관심 영역(ROI2)으로부터 제2 골격 데이터(HC2)를 획득하는 동작에서는, 제3 딥러닝 모델이 이용될 수 있다. 제3 딥러닝 모델은 제2 관심 영역(ROI2)을 입력 값으로 하여 손(H)의 제2 골격 데이터(HC2)를 출력하도록 훈련될 수 있다. 예를 들어, 제3 딥러닝 모델은 제2 관심 영역(ROI2)을 입력 값으로 하여 손(H)의 적어도 하나의 특징점에 대한 좌표 값을 포함하는 제2 골격 그래프(HC2)를 출력하도록 훈련될 수 있다. 일 실시 예에서, 제3 딥러닝 모델을 이용하여 획득된 제2 골격 데이터(HC2)에 포함된 각각의 특징점들은, 제2 이미지 (IM2)를 포함하는 평면 상의 기 설정된 원점에 대한 2차원 위치 좌표에 대응될 수 있다. 제2 관심 영역(ROI2)으로부터, 손(H)의 적어도 하나의 특징점을 포함하는 제2 골격 데이터(HC2)를 획득하는 동 작에 대해서는 후술할 도 6을 참조하여 보다 자세히 설명하도록 한다. 단계 160에서, 전자 장치는 제1 골격 데이터(HC1) 및 제2 골격 데이터(HC2)에 기초하여, 손(H)의 3차원 골 격 데이터(HC)를 획득할 수 있다. 일 실시예에서, 제1 골격 데이터(HC1)에 포함된 특징점들은, 공간 내의 기 설정된 원점에 대한 3차원 위치 좌표 에 대응되고, 제2 골격 데이터(HC2)에 포함된 특징점들은, 제2 이미지(IM2)를 포함하는 평면 상의 기 설정된 원 점에 대한 2차원 위치 좌표에 대응될 수 있다. 이 경우, 전자 장치는 제1 골격 데이터(HC1)에 포함된 각각 의 특징점에 대해, 대응되는 3차원 위치 좌표를 제1 이미지(IM1) 상의 2차원 위치 좌표로 투영(projection) 시 킬 수 있다. 이후, 제1 골격 데이터(HC1)에 포함된 각각의 특징점에 대해, 제1 이미지(IM1) 상에 투영된 2차원 위치 좌표와 제2 골격 데이터(HC2)에서 대응되는 특징점의 2차원 위치 좌표를 이용하여, 3차원 위치 좌표를 획 득할 수 있다. 예를 들어, 두 개의 2차원 위치 좌표를 이용하여 3차원 위치 좌표를 획득하는 동작에는 삼각측량 법이 이용될 수 있다. 제1 골격 데이터(HC1) 및 제2 골격 데이터(HC2)에 기초하여, 손(H)의 3차원 골격 데이터(HC)를 획득하는 동작에 대해서는 후술할 도 7 및 도 8을 참조하여 보다 자세히 설명하도록 한다. AR 안경 등 사용자에게 증강 현실 서비스를 제공하는 전자 장치에서 핸드 인터랙션은 중요한 입력 인터페이 스 중 하나로 기능한다. AR 안경 등의 전자 장치에서는 사용자 손의 추정된 3차원 포즈 및 인식된 제스처를 통해 제어 신호를 획득할 수 있다. 일 실시예에서, 전자 장치는 사용자 손의 3차원 포즈를 정확히 추정하기 위해 복수의 카메라를 사용하고, 다양한 시점의 카메라 이미지들로부터 손의 관절들의 깊이(z축 상의 상대적인 위치)를 추정한 후, 추정된 깊이 정보를 이용하여 2차원의 카메라 이미지를 3차원 이미지로 복원할 수 있다. 이와 같이 복수의 카메라를 이용하여 손의 3차원 골격 구조 정보를 획득하는 일련의 동작들 중에서, 각각의 카메라 이미지로부터 손의 위치를 찾 는 동작에 특히 소모되는 전력량이 크다. 따라서, 본 개시의 일 실시예에 따르면, 전자 장치에 포함된 복수의 카메라들 중 어느 하나를 통해 획득한 이미지에 대해서만, 사용자 손(H)에 대응되는 이미지가 포함된 관심 영역(ROI)을 검출하는 동작을 수행함으로써, 이미지에서 손(H)이 포함된 위치를 찾는 검출 동작의 수행 횟수를 줄일 수 있다. 나아가 손의 3 차원 골격 데이터를 획득하는 동작의 총 연산 시간을 줄일 수 있고, 전자 장치에서 소비하는 전력의 양을 줄일 수 있다. 도 2는 본 개시의 일 실시예에 따른 전자 장치가 복수의 카메라를 이용하여 손의 3차원 골격 데이터를 획득하는 방법의 흐름도이다. 단계 S210에서, 전자 장치는 제1 카메라를 통해 제1 이미지를 획득하고, 제2 카메라를 통해 제2 이미지를 획득 한다. 제1 이미지 및 제2 이미지는 각각 사용자의 손에 대응되는 이미지를 포함할 수 있다. 단계 S220에서, 전자 장치는 제1 이미지로부터 사용자의 손에 대응되는 이미지가 포함된 제1 관심 영역을 획득 한다. 일 실시예에서, 제1 이미지로부터 제1 관심 영역을 획득하는 동작에서는, 제1 이미지를 입력 값으로 하여 손 이미지를 포함하는 이미지 영역을 제1 관심 영역으로 출력하도록 훈련된 제1 딥러닝 모델이 이용될 수 있다. 단계 S230에서, 전자 장치는 제1 관심 영역으로부터 손의 적어도 하나의 특징점을 포함하는 제1 골격 데이터를 획득한다. 일 실시예에서, 제1 관심 영역으로부터 제1 골격 데이터를 획득하는 동작에는, 제1 관심 영역을 입력 값으로 하여 손의 적어도 하나의 특징점에 대한 좌표 값을 포함하는 제1 골격 데이터를 출력하도록 훈련된, 제2 딥러닝 모델이 이용될 수 있다. 일 실시예에서, 제2 딥러닝 모델을 이용하여 획득된 제1 골격 데이터는, 각각의 특징점들의 공간 내의 기 설정 된 원점에 대한 3차원 위치 좌표를 포함할 수 있다. 예를 들어, 제1 골격 데이터는 특정 조인트 n에 대응되는 3 차원 좌표 값 (xn,yn,zn)을 가질 수 있다. 특정 조인트 n에 대응되는 3차원 좌표 값 (xn,yn,zn)은 해당 조인트 의 기 설정된 원점으로부터의 3차원 공간 상 상대적인 위치를 나타낼 수 있다. 단계 S240에서, 전자 장치는 제1 골격 데이터에 기초하여 제2 이미지로부터 제2 관심 영역을 획득할 수 있다. 일 실시예에서, 제1 골격 데이터에 기초하여 제2 이미지로부터 제2 관심 영역을 획득하는 동작은, 제1 골격 데 이터에 포함된 특징점의 3차원 위치 좌표를 제2 이미지(IM2) 상의 2차원 위치 좌표로 투영(projection) 시키는 단계, 제2 이미지로부터, 투영된 2차원 위치 좌표들을 포함하는 블록을 식별하는 단계, 및 식별된 블록을 제2 관심 영역으로 결정하는 단계를 포함할 수 있다. 일 실시예에서, 제1 골격 데이터에 포함된 특징점의 3차원 위치 좌표를 제2 이미지 상의 2차원 위치 좌표로 투 영 시키는 단계에서, 제1 카메라와 제2 카메라의 상대적인 위치 정보(예를 들어, 베이스라인(baseline))가 이용 될 수 있다. 예를 들어, '스테레오 비전(stereo vision)' 기술에 따라, 서로 다른 위치에 배치된 두 개의 카메 라를 통해 획득된 2차원의 영상들로부터, 시차(disparity) 계산을 통해 3차원의 깊이 정보를 획득할 수 있다. 시차는 제1 카메라와 제2 카메라가 특정 축에 대해 이격된 정도에 따라, 제1 이미지 및 제2 이미지에서 발생하 는 해당 축의 위치 차이를 나타낼 수 있다. 따라서, 2차원의 제1 이미지를 통해 예측된 3차원 위치 좌표와, 제1 카메라와 제2 카메라의 화각 및 상대적인 위치 정보를 통해 제1 이미지 상 사용자의 손 이미지가 표시된 영역이 제2 이미지 상 어떤 부분에 대응될지 예측할 수 있다. 단계 S250에서, 전자 장치는 제2 관심 영역으로부터 손의 적어도 하나의 특징점을 포함하는 제2 골격 데이터를 획득할 수 있다. 일 실시예에서, 제2 관심 영역으로부터 제2 골격 데이터를 획득하는 동작에서는, 제2 관심 영 역을 입력 값으로 하여 손의 적어도 하나의 특징점에 대한 좌표 값을 포함하는 제2 골격 데이터로 출력하도록 훈련된, 제3 딥러닝 모델이 이용될 수 있다. 일 실시예에서, 제3 딥러닝 모델을 이용하여 획득된 제2 골격 데이터는, 각각의 특징점들의 제2 이미지 평면 상 기 설정된 원점에 대한 2차원 위치 좌표를 포함할 수 있다. 예를 들어, 제2 골격 데이터는 특정 조인트 m에 대 응되는 2차원 좌표 값 (xm,ym)을 가질 수 있다. 특정 조인트 m에 대응되는 2차원 좌표 값 (xm,ym)은 해당 조인 트의 기 설정된 원점으로부터의 2차원 평면 상 상대적인 위치를 나타낼 수 있다. 단계 S260에서, 전자 장치는 제1 골격 데이터 및 제2 골격 데이터에 기초하여, 손의 3차원 골격 데이터를 획득 할 수 있다. 일 실시예에서, 제1 골격 데이터는 특징점의 공간 내 기 설정된 원점에 대한 3차원 위치 좌표를 포함하고, 제2 골격 데이터는 특징점의 제2 이미지 평면 상 기 설정된 원점에 대한 2차원 위치 좌표를 포함할 수 있다. 이 경 우, 전자 장치는 제1 골격 데이터에 포함된 특징점들의 3차원 위치 좌표를, 제1 이미지 평면 상의 2차원 위치 좌표로 투영(projection) 시킬 수 있다. 이후, 제1 골격 그래프의 각각의 특징점에 대해, 제1 이미지 평면 상에 투영된 2차원 위치 좌표와 제2 골격 데이터에 포함된 대응되는 2차원 위치 좌표를 이용하여, 3차원 위치 좌표를 획득할 수 있다. 예를 들어, 두 개의 2차원 위치 좌표를 이용하여 3차원 위치 좌표를 획득하는 동작에는 삼각측 량법이 이용될 수 있다. 예를 들어, '스테레오 비전(stereo vision)' 기술에 따라, 서로 다른 위치에 배치된 두 개의 카메라를 통해 획득된 2차원의 영상들로부터, 시차(disparity) 계산을 통해 3차원의 깊이 정보를 획득할 수 있다. 따라서, 제1 이미지 평면 상으로 투영된 2차원 위치 좌표, 제2 이미지에서 획득된 2차원 위치 좌표, 및 제1 카메라와 제2 카메라의 상대적인 위치 정보를 통해 사용자의 손에 대한 3차원 구조 정보를 획득할 수 있 다. 일 실시예에서, 제1 골격 데이터가 특징점들의 공간 내의 기 설정된 원점에 대한 3차원 위치 좌표를 포함하고, 제2 골격 데이터 또한 대응되는 특징점들의 동일한 원점에 대한 3차원 위치 좌표를 포함할 수도 있다. 이 경우, 전자 장치는 각각의 특징점들에 대해, 제1 골격 데이터에서의 3차원 위치 좌표와 제2 골격 그래프에서의 3차원 위치 좌표를 평균(average)한 값을 해당 특징점의 3차원 위치 좌표로 결정할 수 있다. 일 실시예에서, 제2 관심 영역으로부터 제2 골격 데이터를 획득하는 동작에서는, 제2 관심 영역을 입력 값으로 하여 손의 적어도 하나의 특징점을 조인트로 포함하는 그래프를 제2 골격 데이터로 출력하도록 훈련된, 제2 딥 러닝 모델이 이용될 수 있다. 제2 딥러닝 모델은 골격 데이터의 특징점들에 3차원 위치 좌표를 대응시켜 출력하 고, 제3 딥러닝 모델은 골격 데이터의 특징점들에 2차원 위치 좌표를 대응시켜 출력할 수 있다. 일 실시예에서, 전자 장치는 각각의 특징점에 대해, 제1 골격 데이터에서의 위치 좌표와, 제2 골격 데이터에서 의 동일 차원 위치 좌표를 가중치 결합한 값을 해당 특징점의 3차원 위치 좌표로 결정할 수도 있다. 도 3은 본 개시의 일 실시예에 따른 하나의 카메라 이미지(제1 카메라 이미지, IM1)에서 관심 영역(제1 관심 영 역, ROI1)을 획득하는 동작을 설명하기 위한 도면이다. 본 개시의 일 실시예에 따른 전자 장치는, 제1 카메라를 통해 획득된 제1 이미지(IM1) 및 제2 카메라를 통해 획 득된 제2 이미지(IM2) 중 제1 이미지(IM1)로부터 사용자의 손(H)에 대응되는 손 이미지가 포함된 제1 관심 영역 (ROI1)을 획득할 수 있다. 예를 들어, 제1 관심 영역(ROI1)은 손 이미지를 포함하는 블록(block) 또는 윈도우 (window) 형태를 가질 수 있다. 일 실시예에서, 제1 이미지(IM1)로부터 제1 관심 영역(ROI1)을 획득하는 동작에 서는, 제1 이미지(IM1)를 입력 값으로 하여 손 이미지를 포함하는 이미지 영역을 제1 관심 영역(ROI1)으로 출력 하도록 훈련된, 제1 딥러닝(deep learning) 모델이 이용될 수 있다. 일 실시예에서, 제1 이미지(IM1)에서 제1 관심 영역(ROI1)을 검출하는 동작에는 프레임 스캐닝(frame scanning) 동작 또는 엣지 분석법이 이용될 수도 있다. 프레임 스캐닝 동작에서는 일정 크기의 블록을 설정한 후, 좌측 상 단으로부터 우측 하단까지 스캐닝을 통해 손이 포함된 영역을 검색하는 방법을 나타낸다. 이 때, 블록의 크기는 기 설정될 수 있다. 블록의 크기가 작아서 손이 포함되는 영역이 복수 개인 것으로 판단될 경우, 블록 사이즈를 늘려서 스캐닝 동작을 재차 수행할 수 있고, 블록 크기가 커서 특정 블록에서 손이 포함되는 픽셀 영역이 작다 고 판단될 경우 (해당 블록 내에서) 블록 사이즈를 줄여서 스캐닝 동작을 재차 수행할 수도 있다. 예를 들어, 최종 선택되는 제1 관심 영역(ROI1)의 크기는 전자 장치로부터의 손까지의 거리에 따라 달라질 수 있다. 예를 들어, 손이 카메라에 가까이 위치한 경우에는 손에 대응되는 이미지가 클 것이고, 따라서 제1 관심 영역(ROI1) 의 블록(윈도우) 크기가 클 수 있다. 예를 들어, 손이 카메라로부터 멀리 위치한 경우, 제1 관심 영역(ROI1)의 블록(윈도우) 크기가 작게 설정될 수도 있다. 일 실시예에서, 제1 이미지(IM1)로부터 제1 관심 영역(ROI1)의 위치를 검출하는 동작에는 제1 딥러닝 또는 기타 알고리즘이 이용될 수도 있다. 종래 기술에서는 서로 다른 카메라로부터 획득된 복수의 이미지 마다 손의 위치 (즉, 관심 영역)을 검출하는 동작을 수행하였다. 한편, 본 개시의 일 실시예에 따른 방법에 따르면, 전자 장치 는 복수의 카메라로부터 획득된 복수의 이미지들 중 하나의 이미지(제1 이미지, IM1)에 대해서만 사용자의 손에 대응되는 이미지가 포함된 제1 관심 영역(ROI1)을 검출할 수 있다. 따라서, 본 개시의 일 실시예에 따르면, 모 든 복수의 카메라로부터 각각 획득된 복수의 이미지들에 대해 전부 관심 영역을 검출하는 동작을 수행하지 않을 수 있고, 따라서, 보다 적은 전력 소비가 가능하다. 도 4는 본 개시의 일 실시예에 따른 제1 카메라 이미지(IM1)의 관심 영역(ROI1)으로부터 손의 제1 골격 데이터 (HC1)를 획득하는 동작을 설명하기 위한 도면이다.도 4를 참조하면, 전자 장치는 제1 관심 영역(ROI1)으로부터, 손(H)의 제1 골격 데이터(HC1)를 획득할 수 있다. 제1 골격 데이터(HC1)는 조인트를 노드로, 조인트를 연결한 선을 엣지로 포함하는 그래프(graph)로 표현될 수 있다. 제1 골격 데이터(HC1)는 조인트를 특징점으로 하고, 각각의 특징점들에 대한 좌표 값을 포함하는 '데이터 세트(set)'를 나타낼 수 있다. 즉, 본 개시의 일 실시예에 따른 전자 장치는 제1 관심 영역(ROI1)으로부터 조인 트(또는 특징점 또는 노드)에 대한 좌표 정보를 포함하는 제1 골격 데이터(HC1)(또는 제1 골격 그래프 또는 제1 데이터 세트)를 획득할 수 있다. 손(H)의 적어도 하나의 특징점은 손의 관절 부분에 포함될 수 있다. 예를 들어, 손 관절 그래프는 21개의 점을 포함할 수 있다. 21개의 점은 각각 5개의 손가락의 관절들 및 손바닥에 위 치할 수 있다. 일 실시예에서, 제1 관심 영역(ROI1)으로부터 제1 골격 데이터(HC1)를 획득하는 동작에서는, 제1 관심 영역 (ROI1)을 입력 값으로 하여 손(H)의 적어도 하나의 특징점을 노드로 포함하는 그래프를 제1 골격 데이터(HC1)로 출력하도록 훈련된, 제2 딥러닝 모델이 이용될 수 있다. 일 실시예에서, 제2 딥러닝 모델을 이용하여 획득된 제 1 골격 데이터(HC1)는 각각의 특징점들의 공간 내 기 설정된 원점에 대한 3차원 위치 좌표를 포함할 수 있다. 일 실시예에서 제1 이미지 상 손의 위치(제1 관심 영역, ROI1)로부터 손 관절(skeleton)에 대한 3차원 좌표 정 보를 검출할 수 있다. 손 관절에 대한 3차원 좌표 값을 검출하는 동작에는 제2 딥러닝 알고리즘 또는 기타 알고 리즘이 이용될 수 있다. 일 실시예에서 단일한 2차원 카메라 이미지로부터 예측된 손의 3차원 구조는 2개의 2차 원 이미지를 이용해 획득된 손의 3차원 구조에 비해 정확도가 낮을 수 있다. 일 실시예에서, 단일한 카메라 이미지로부터 손의 3차원 구조를 획득하는 동작에는, 관절(조인트)들 간의 상대 적인 위치에 따라 손의 3차원 구조를 추정하는 방법 등이 이용될 수 있다. 관절들 간의 상대적인 위치에 따라 손의 3차원 좌표를 추정하는 방법에서는, '관절들 간의 상대적인 위치 관계'와 '손의 3차원 포즈'가 매칭되어 저장된 데이터베이스를 통한 확률적인 추정 방법이 이용될 수 있다. 도 5는 본 개시의 일 실시예에 따른 제1 카메라 이미지(IM1)의 제1 관심 영역(ROI1)으로부터 획득된 손의 제1 골격 데이터(HC1)에 기초하여 다른 카메라 이미지(제2 카메라 이미지, IM2)의 제2 관심 영역(ROI2)을 획득하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 하나의 카메라 이미지(제1 카메라 이미지, IM1)로부터 획득된 손의 3차원 골격 데이터(HC1)를 이용해 다른 카메라 이미지(제2 카메라 이미지, IM2) 상에서 사용자 손에 대응되는 이미지가 포함될 것으로 예 측되는 제2 관심 영역(ROI2)을 산출할 수 있다. 예를 들어, 다른 카메라 상의 손의 위치에 대응되는 제2 관심 영역(ROI2)은 사각형 블록(박스 또는 윈도우) 형태를 가질 수 있다. 일 실시예에서, 제1 골격 데이터(HC1)에 포함된 특징점의 3차원 위치 좌표를 제2 이미지(IM2) 상의 2차원 위치 좌표로 투영 시키는 단계에서, 제1 카메라와 제2 카메라의 상대적인 위치 정보(예를 들어, 베이스라인 (baseline))가 이용될 수 있다. 예를 들어, 서로 다른 위치에 배치된 두 개의 카메라를 통해 획득된 2차원의 영 상들로부터, 시차(disparity) 계산을 통해 3차원의 깊이 정보를 획득할 수 있다. 시차는 제1 카메라와 제2 카메 라가 특정 축에 대해 이격된 정도에 따라, 제1 이미지(IM1) 및 제2 이미지(IM2)에서 발생하는 해당 축의 위치 차이를 나타낼 수 있다. 따라서, 2차원의 제1 이미지(IM1)를 통해 예측된 3차원 위치 좌표와, 제1 카메라와 제2 카메라의 화각 및 상대적인 위치 정보를 통해 제1 이미지(IM1) 상 사용자의 손 이미지가 표시된 영역(관심 영역, ROI1)이 제2 이미지(IM2) 상 어떤 부분에 대응될지 예측할 수 있다. 일 실시예에서, 산출된 제2 관심 영역(ROI2)에 다시 제1 딥러닝 모델을 적용하여 실제 사용자의 손 이미지가 포 함되는 정확한 영역을 결정할 수도 있다. 이 경우, 손 위치 검출을 위한 동작에 이용되는 이미지의 크기(산출된 제2 관심 영역(ROI2)의 크기)가 원본 이미지(제2 이미지(IM2))에 비해 감소함으로써, 전체적인 전자 장치의 연 산 로드는 줄어들 수 있다. 하나의 카메라 이미지(제1 카메라 이미지, ROI1)로부터 획득된 손의 3차원 골격 데이터(HC1)로부터 다른 카메라 이미지 상 제2 관심 영역(ROI2)을 획득하는 동작에는 아래의 수학식 1이 이용될 수 있다.수학식 1"}
{"patent_id": "10-2021-0179973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, (X,Y,Z)는 제1 관심 영역(ROI1)으로부터 획득된 제1 골격 데이터(HC1)의 3차원 좌표 값이며, (u,v)는 제1 관심 영역(ROI1)으로부터 획득된 제1 골격 데이터(HC1)의 3차원 좌표 값을 제2 이미지(IM2) 평면 상으로 투 영(projection)시킨 2차원 좌표 값을 나타낸다. 수학식 1에서 fx, fy, cx, cy는 전자 장치의 내부 요인에 따라 결정되는 속성으로서, 카메라 내부의 파라미터 공 간 좌표(3차원)를 이미지 픽셀 좌표(2차원)로 변환하는 동작에서 이용될 수 있고, 카메라 모듈의 제조 단계에서 기 설정될 수 있다. 예를 들어, fx 및 fy는 카메라(예를 들어, 제2 카메라)의 초점거리에 기초하여 결정될 수 있 고, cx 및 cy는 이미지(예를 들어, 제2 이미지)의 중심으로부터 좌측상단까지의 거리에 기초하여 결정될 수 있다. 수학식 1에서 rij 및 tk(i,j,k = 1 or 2 or 3)는 전자 장치의 외부 요인에 따라 결정되는 속성으로서, 전자 장치 의 제조 단계에서 기 설정될 수 있다. 예를 들어, rij는 기 설정된 원점(예를 들어, 전자 장치의 중심점 또는 제 1 카메라 및 제2 카메라의 중간 지점)으로부터 카메라(예를 들어, 제2 카메라)까지의 축 회전 각도 파라미터를 나타낼 수 있고, tk는 기 설정된 원점(예를 들어, 전자 장치의 중심점 또는 제1 카메라 및 제2 카메라의 중간 지점)으로부터 카메라(예를 들어, 제2 카메라)까지의 거리 파라미터를 나타낼 수 있다. 일 실시예에서, 각각의 3차원 손 관절 좌표들에 대해 제2 이미지 상 투영된 2차원 좌표가 계산될 수 있다. 본 개시의 일 실시예에 따른 전자 장치는, 각각의 손가락 관절들에 대한 2차원 좌표 값들 중 x축 상 최소 값 및 최 대 값, y축 상 최소 값 및 최대 값을 식별할 수 있다."}
{"patent_id": "10-2021-0179973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, n은 손가락 관절의 개수(또는 조인트의 개수 또는 손가락 특징점의 개수)(예를 들어, n=21)를 나타낼 수 있고, (xmin,ymin)과 (xmax,ymax)를 잇는 선을 하나의 대각선으로 하는 직사각형 형태의 블록이 제2 이미지(IM2) 내의 제2 관심 영역(ROI2)으로 결정될 수 있다. 도 6은 본 개시의 일 실시예에 따른 다른 카메라 이미지(제2 카메라 이미지, IM2)의 제2 관심 영역(ROI2)으로부 터 손의 골격 데이터(HC2)를 획득하는 동작을 설명하기 위한 도면이다. 도 6을 참조하면, 손의 위치(관심 영역)로부터 손의 관절(skeleton)을 검출할 수 있다. 손의 관절을 검출하는 동작에는 제3 딥러닝 또는 기타 알고리즘이 이용될 수 있다. 검출된 손의 관절은 2차원 좌표 정보를 포함할 수 있다. 일 실시예에서, 제2 카메라 이미지(IM2)의 제2 관심 영역(ROI2)으로부터 손의 제2 골격 데이터(HC2)를 획득하는 동작은 도 4를 참조하여 전술한, 제1 카메라 이미지(IM1)의 제1 관심 영역(ROI1)으로부터 손의 제1 골격 데이터 (HC1)를 획득하는 동작과 유사하게 수행될 수 있다. 예를 들어, 제2 골격 데이터(HC2)를 검출하는 동작에는 제2 딥러닝 알고리즘 또는 기타 알고리즘이 이용될 수도 있고, 이 경우 검출된 손의 관절은 3차원 좌표 정보를 포함 할 수도 있다. 일 실시예에서, 제1 골격 데이터(HC1)와 제2 골격 데이터(HC2)는 동일한 손에 대한 골격 데이터이고, 제1 골격 데이터(HC1)에 포함된 특징점들과 제2 골격 데이터(HC2)에 포함된 특징점들은 각각 1대1로 대응될 수 있다. 따라서, 사용자의 손의 3차원 골격 데이터를 획득하기 위한 이후 동작들에서, 각각 1대1로 대응되는 2차원 관절 좌표 쌍(pair)의 시차에 기초하여 사용자의 손에 대한 3차원 골격 구조를 산출할 수 있다. 도 7은 본 개시의 일 실시예에 따른 서로 다른 카메라 이미지로부터 획득된 손의 골격 데이터들에 기초하여 손 의 3차원 골격 데이터를 획득하는 동작을 설명하기 위한 도면이고, 도 8은 본 개시의 일 실시예에 따른 서로 다 른 카메라 이미지로부터 획득된 손의 골격 데이터들에 기초하여 손의 3차원 골격 데이터를 획득하는 동작을 설 명하기 위한 도면이다. 도 7 및 도 8을 참조하여 제2 카메라 이미지로부터 획득된 제2 손 위치 좌표가 2차원 좌표 정보에 대응되는 경 우 손의 3차원 좌표를 획득하는 동작이 설명될 수 있다. 예를 들어, 제2 이미지로부터 획득된 제2 골격 데이터 가 조인트들의 2차원 좌표 값을 포함할 수 있다. 제1 이미지로부터 획득된 제1 골격 데이터는 조인트들의 2차원 좌표 값 또는 3차원 좌표 값을 포함할 수 있다. 제1 이미지로부터 획득된 제1 골격 데이터가 조인트들의 3차원 좌표 값을 포함하는 경우, 스테레오 비전에 따라 시차를 이용해 조인트의 3차원 좌표 값을 산출하기 위해, 제1 골격 데이터의 3차원 좌표 값들을 제1 이미지 평면 상의 2차원 좌표 값으로 투영시킬 수 있다. 이후, 제1 카메 라와 제2 카메라의 상대적인 위치 정보로부터 한 쌍의 2차원 좌표의 시차(disparity) 계산을 통해 각각의 조인 트들의 3차원의 깊이 정보를 획득할 수 있다. 이하, 도 7 및 도 8을 참조하여 특징점에 대한 2차원 좌표 쌍을 이용해 3차원 좌표를 생성하는 동작을 구체적으로 설명하도록 한다. 도 7은 두 개의 카메라 및 사용자의 손을 x-z 평면에서 바라본 모습을 도시한다. 사용자의 손은 P점에 위치할 수 있다. 예를 들어, 특정 특징점에 대해 3차원 깊이 정보를 계산할 때, 해당 특징점의 위치를 P점으로 나타낼 수 있다. 도 7을 참조하면, (P, xl, xr)이 이루는 삼각형과, (P, Left camera, Right camera)가 이루는 삼각형 으로부터 다음과 같은 비례식이 획득될 수 있다."}
{"patent_id": "10-2021-0179973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, Z는 카메라로부터 특정 포인트 P까지의 깊이를 나타낸다. Z 값은 D+f 값에 대응될 수 있다. 깊이 Z는 비례식에 따라 다음과 같이 계산될 수 있다."}
{"patent_id": "10-2021-0179973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이후, 제1 카메라(예를 들어, 좌측 카메라)로부터 획득된 2차원 좌표 (xl, yl) 및 획득한 깊이 값 Z를 이용하여 p=(xl, yl, Z, 1)를 구성할 수 있다. 다음으로, p에 기초하여 제1 카메라로부터 획득된 2차원 좌표를 3차원 좌표로 변환할 수 있다."}
{"patent_id": "10-2021-0179973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, R은 제1 카메라로부터 기 설정된 원점(예를 들어, 전자 장치의 중심점 또는 제1 카메라 및 제2 카메라 의 중간 지점)까지의 축 회전 각도 파라미터를 나타낼 수 있고, T는 제1 카메라로부터 기 설정된 원점(예를 들 어, 전자 장치의 중심점 또는 제1 카메라 및 제2 카메라의 중간 지점)까지의 거리 파라미터를 나타낼 수 있다. 도 8을 참조하면, 두 이미지(IMl,IMr)에서 쌍을 이루는 특징점의 2차원 x좌표(xl 및 xr)로부터 해당 특징점의 3 차원 좌표를 계산할 수 있다. 특징점의 3차원 좌표 계산에는 삼각측량법이 이용될 수 있다. Ol, Or 지점에 각각 제1 카메라 및 제2 카메라가 배치될 수 있다. 이 때, 삼각형의 비율에 따라 다음과 같은 수학식이 획득될 수 있 다."}
{"patent_id": "10-2021-0179973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, b는 제1 카메라 및 제2 카메라 사이의 거리를 나타낸다. b는 제1 카메라 및 제2 카메라의 상대적인 위 치에 따라 결정될 수 있다. b는 전술한 도 7의 'b'에 대응될 수 있고, 베이스라인(baseline)으로 표현될 수 있 다. 좌측 카메라(제1 카메라)로 촬영한 이미지를 제1 이미지라고 할 때, 제1 이미지의 좌측 하단을 원점으로 하는 제1 손 관절의 2차원 좌표(xl,yl)를 획득할 수 있다. 마찬가지로, 우측 카메라(제2 카메라)로 촬영한 이미지를 제2 이미지라고 할 때, 제2 이미지의 좌측 하단을 원점으로 하는 제2 손 관절의 2차원 좌표(xr,yr)를 획득할 수 있다. 특정 포인트 P의 x축 좌표 값에 대해서만 연산 수행하여 깊이 값(뎁스) Z를 획득할 경우, Z는 z축 좌표 값이 되 고, 이를 이용하여 y축 좌표 값을 산출할 수 있다. 따라서 x축 좌표 값에 대해서만 연산을 수행하여도 특징점에 대한 3차원 좌표 (xp,yp,zp)를 획득할 수 있다. 일 실시예에서, 제1 이미지로부터 획득된 제1 골격 데이터가 조인트들의 3차원 좌표 값을 포함하고, 제2 이미지 로부터 획득된 제2 골격 데이터가 조인트들의 3차원 좌표 값을 포함할 수도 있다. 이러한 경우, 전자 장치는 제 1 골격 데이터의 좌표 값 및 제2 골격 데이터의 좌표 값의 평균을 산출함으로써 손의 3차원 골격 데이터를 획득 할 수 있다. 일 실시예에서, 전자 장치는 제1 골격 데이터의 3차원 좌표 값 및 제2 골격 데이터의 3차원의 좌표 값을 가중치 결합하여 손의 3차원 골격 데이터를 획득할 수도 있다. 예를 들어, 3차원의 제1 조인트 좌표 값 및 3차원의 제2 조인트 좌표 값을 결합하기 위한 가중치(weight)는 시간 축 상 이전 프레임에서의 3차원 조인트 좌 표 값에 기초하여 결정될 수 있다. 본 개시의 일 실시예에서, 안정적인 손 위치 추적 및 제스처 인식을 위해 이 전 프레임의 3차원 손 관절 좌표가 고려될 수 있다. 이는 연속적인 영상에서 사용자의 손 위치 및 형태가 불연 속적으로 계산되는 것을 방지하기 위함이다. 도 9는 본 개시의 일 실시예에 따른 복수의 카메라를 포함하는 전자 장치가 복수의 카메라 이미지들 중 손의 3 차원 골격 데이터를 획득하는 방법에 이용하기 위한 적어도 하나의 카메라 이미지를 결정하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 서로 다른 위치에 배치된 4개의 카메라를 포함할 수 있고, 4개의 카메라는 각각 이 미지 (a), 이미지 (b), 이미지 (c), 및 이미지(d)를 획득할 수 있다. 전자 장치는 전술한 도 1의 단계 120에 대 응되는 동작, 즉 제1 이미지로부터 사용자의 손에 대응되는 손 이미지가 포함된 제1 관심 영역을 획득하는 동작 을 수행하기에 앞서, 4개의 카메라를 통해 획득된 4개의 이미지 중 제1 이미지 및 제2 이미지를 결정할 수 있다. 예를 들어, 도 9에 도시된 경우, 전자 장치는 이미지 (b)를 제1 이미지로 결정하고 이미지 (c)를 제2 이 미지로 결정할 수 있다. 이후, 전자 장치는, 제1 이미지인 이미지(b)로부터 제1 관심 영역을 획득할 수 있다. 일 실시예에서, 복수의 카메라 중 사용자의 손을 추적하기 위한 주 카메라인 제1 카메라는 기 설정되어 있을 수 있다. 예를 들어, 제1 카메라는 사용자의 제스처 인터랙션이 주로 발생하는 전방 하부 영역을 촬영하는 카메라 로 기 설정될 수 있다. 전자 장치는 제1 카메라를 제외한 다른 카메라들 중에서 제2 카메라를 결정할 수 있다. 제2 카메라는 제1 카메라를 통해 촬영된 이미지에서 획득된 제1 관심 영역의 제1 이미지 내의 상대적인 위치, 제1 카메라가 배치된 위치, 및 제2 카메라가 배치된 위치에 따라 결정될 수 있다. 제1 카메라가 기 설정되어 있 는 경우, 전자 장치가 제1 카메라를 제외한 다른 카메라들 중 제2 카메라를 결정하는 동작은, 전술한 도 1에서 단계 120 및 단계 140의 사이에서 수행될 수 있다. 도 10은 본 개시의 일 실시예에 따른 전자 장치의 블록도이다. 전자 장치는 복수의 카메라를 통해 획득된 2차원의 영상 또는 이미지로부터 사용자 손의 3차원 골격 데이 터를 획득하는 장치일 수 있다. 전자 장치는 예를 들어, 사용자가 안면부에 착용하는 안경 형상의 AR 안 경(AR glasses), 두부에 착용하는 헤드 마운트 디스플레이(head mounted display, HMD), 가상 현실 헤드셋(virtual reality headset, VRH), 또는 AR 헬멧(AR helmet) 등의 다양한 웨어러블 장치(wearable device)로 구 성될 수 있다. 한편, 본 개시의 일 실시예에 따른 전자 장치가 전술한 예시로 한정되는 것은 아니며, 전 자 장치는 복수의 카메라를 포함하고, 영상 또는 이미지를 획득 및 처리하는 다양한 종류의 기기를 포함 할 수 있다. 도 10을 참조하면, 전자 장치는 제1 카메라, 제2 카메라, 프로세서, 및 저장부(103 0)를 포함할 수 있다. 도 10에 도시된 구성 요소 모두가 전자 장치의 필수 구성 요소인 것은 아니다. 도 10에 도시된 구성 요소보다 많은 구성 요소들에 의해 전자 장치가 구현될 수도 있고, 도 10에 도시된 구 성 요소보다 적은 구성 요소에 의해 전자 장치가 구현될 수도 있다. 제1 카메라 및 제2 카메라는 디지털 촬영 장치를 포함할 수 있다. 일 실시예에서, 제1 카메라 및 제2 카메라는 각각 입력 영상 또는 입력 이미지를 획득할 수 있다. 일 실시예에서, 제1 카메라 및 제2 카메라는 각각의 화각에 대응되는 영상을 촬영할 수 있다. 일 실시예에서, 제1 카메라 및 제2 카메라는 각각 2차원 이미지를 획득할 수 있다. 전자 장치 는 제1 카메라 및 제2 카메라를 이용하여 사용자의 손에 대응되는 이미지를 포함하는 전방 영역 이미지를 획득할 수 있다. 저장부는 전자 장치의 동작을 제어하기 위해 후술할 프로세서에 의해 실행될 프로그램을 저 장할 수 있다. 저장부는 전자 장치의 동작을 제어하기 위한 적어도 하나의 명령어들(instruction s)을 포함하는 프로그램을 저장할 수 있다. 저장부에는 프로세서가 판독할 수 있는 명령어들 및 프 로그램 코드(program code)가 저장될 수 있다. 일 실시예에서, 프로세서는 저장부에 저장된 프로그 램의 명령어들 또는 코드들을 실행하도록 구현될 수 있다. 저장부는 전자 장치로 입력되거나 전자 장치로부터 출력되는 데이터를 저장할 수 있다. 저장부는 예를 들어, 플래시 저장부(flash memory), 하드디스크(hard disk), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 저장부(예를 들어, SD 또는 XD 저장부 등), 램(RAM, Random Access Memory), SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 저장부, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장 매체를 포함할 수 있다. 다만 저장부는 전술한 예시로 한정되는 것은 아니며, 데이터가 저장될 수 있는 모든 종류의 저장 매체를 포함할 수 있다. 프로세서는, 전자 장치의 전반적인 동작을 제어할 수 있다. 예를 들어, 프로세서는 저장부 에 저장된 프로그램들을 실행함으로써, 제1 카메라, 제2 카메라, 및 저장부 등을 전반 적으로 제어할 수 있다. 프로세서는 산술, 로직 및 입출력 연산과 시그널 프로세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서 (microprocessor), 그래픽 프로세서(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), 및 FPGAs(Field Programmable Gate Arrays) 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 프로세서는, 저장부에 저장된 적어도 하나의 명령어들을 실행함으로써, 제1 카메라를 통해 획득된 제1 이미지에 대해서만 사용자의 손에 대응되는 이미지가 포함된 관심 영역을 검출하는 동작을 수행하더 라도, 손의 전체적인 3차원 관절 구조를 획득할 수 있다. 예를 들어 프로세서는, 저장부에 저장된 적어도 하나의 명령어들을 실행함으로써, 제1 카메라를 통해 제1 이미지를 획득하고 제2 카메라를 통해 제2 이미지를 획득하고, 제1 이미지로부터 손 이미지가 포함된 제1 관심 영역을 획득하고, 제1 관심 영역 으로부터 손의 적어도 하나의 특징점을 포함하는 제1 골격 데이터를 획득하고, 제1 골격 데이터, 및 제1 카메라 와 제2 카메라의 상대적 위치 정보에 기초하여 제2 이미지로부터 제2 관심 영역을 획득하고, 제2 관심 영역으로 부터 손의 적어도 하나의 특징점을 포함하는 제2 골격 데이터를 획득하고, 제1 골격 데이터 및 제2 골격 데이터 에 기초하여 손의 3차원 골격 데이터를 획득할 수 있다. 프로세서가 제1 카메라를 통해 제1 이미지를 획득하고 제2 카메라를 통해 제2 이미지를 획득 하는 동작은 전술한 도 2의 단계 S210에 대응될 수 있다. 프로세서가 제1 이미지로부터 손 이미지가 포함 된 제1 관심 영역을 획득하는 동작은 전술한 도 2의 단계 S220에 대응될 수 있다. 프로세서가 제1 관심영역으로부터 손의 적어도 하나의 특징점을 포함하는 제1 골격 데이터를 획득하는 동작은 전술한 도 2의 단계 S230에 대응될 수 있다. 프로세서가 제1 골격 데이터에 기초하여 제2 이미지로부터 제2 관심 영역을 획득 하는 동작은 전술한 도 2의 단계 S240에 대응될 수 있다. 프로세서가 제2 관심 영역으로부터 손의 적어도 하나의 특징점을 포함하는 제2 골격 데이터를 획득하는 동작은 전술한 도 2의 단계 S250에 대응될 수 있다. 프 로세서가 제1 골격 데이터 및 제2 골격 데이터에 기초하여 손의 3차원 골격 데이터를 획득하는 동작은 전 술한 도 2의 단계 S260에 대응될 수 있다. 이와 같이, 본 개시의 일 실시예에 따르면, 전자 장치에 포함된 복수의 카메라들 중 어느 하나를 통해 획득한 이미지에 대해서만 손에 대응되는 이미지가 포함된 관심 영역을 검출하는 동작을 수행함으로써, 이미지에서 손 의 위치를 찾는 검출 동작의 수행 횟수를 줄여, 손의 3차원 골격 데이터를 획득하는 동작의 총 연산 시간을 줄 일 수 있고, 전자 장치에서 소비하는 전력의 양을 줄일 수 있다. 본 개시의 다양한 실시예들은 하나 이상의 컴퓨터 프로그램들에 의해 구현 또는 지원될 수 있고, 컴퓨터 프로그 램들은 컴퓨터 판독 가능한 프로그램 코드(code)로부터 형성되고, 컴퓨터로 판독 가능한 매체에 수록될 수 있다. 본 개시에서, \"애플리케이션(application)\" 및 \"프로그램(program)\"은 컴퓨터 판독 가능한 프로그램 코드 에서의 구현에 적합한 하나 이상의 컴퓨터 프로그램, 소프트웨어 컴포넌트, 명령어 세트, 프로시저(procedure), 함수, 개체(object), 클래스, 인스턴스, 관련 데이터, 또는 그것의 일부를 나타낼 수 있다. \"컴퓨터 판독 가능 한 프로그램 코드\"는, 소스 코드, 목적 코드, 및 실행 가능한 코드를 포함하는 다양한 유형의 컴퓨터 코드를 포 함할 수 있다. \"컴퓨터 판독 가능한 매체\"는, ROM(read only memory), RAM(random access memory), 하드 디스 크 드라이브(HDD), CD(compact disc), DVD(digital video disc), 또는 다양한 유형의 메모리와 같이, 컴퓨터에 의해 액세스될 수 있는 다양한 유형의 매체를 포함할 수 있다. 또한, 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장 매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 저장 매체'는 실재(tangible)하는 장치이고, 일시적인 전기적 또는 다른 신호들을 전송하는 유선, 무선, 광학적, 또는 다른 통신 링크들을 배제할 수 있다. 한편, 이 '비일시적 저장 매체'는 데이터가 저 장 매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 예를 들어, '비일시적 저장 매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 컴퓨터 판독 가능한 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포 함할 수 있다. 컴퓨터 판독 가능한 매체는, 데이터가 영구적으로 저장될 수 있는 매체와 데이터가 저장되고 나 중에 덮어쓰기 될 수 있는 매체, 이를테면 재기입 가능한 광 디스크 또는 소거 가능한 메모리 디바이스를 포함 한다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예를 들어, compact disc read only memory (CD- ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두 개의 사용자 장치들(예를 들어, 스마트 폰) 간에 직접, 온라인으로 배포(예를 들어, 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예를 들어, 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스 토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시 적으로 생성될 수 있다."}
{"patent_id": "10-2021-0179973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2021-0179973", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 전자 장치가 복수의 카메라를 이용하여 손의 3차원 골격 데이터를 획득하는 방법의 개요도이다. 도 2는 본 개시의 일 실시예에 따른 전자 장치가 복수의 카메라를 이용하여 손의 3차원 골격 데이터를 획득하는 방법의 흐름도이다. 도 3은 본 개시의 일 실시예에 따른 하나의 카메라 이미지에서 관심 영역(region of interest, ROI)을 획득하는 동작을 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시예에 따른 카메라 이미지의 관심 영역으로부터 손의 골격 데이터를 획득하는 동작을 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시예에 따른 하나의 카메라 이미지의 관심 영역으로부터 획득된 손의 골격 데이터에 기 초하여 다른 카메라 이미지의 관심 영역을 획득하는 동작을 설명하기 위한 도면이다.도 6은 본 개시의 일 실시예에 따른 다른 카메라 이미지의 관심 영역으로부터 손의 골격 데이터를 획득하는 동 작을 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시예에 따른 서로 다른 카메라 이미지로부터 획득된 손의 골격 데이터들에 기초하여 손 의 3차원 골격 데이터를 획득하는 동작을 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시예에 따른 서로 다른 카메라 이미지로부터 획득된 손의 골격 데이터들에 기초하여 손 의 3차원 골격 데이터를 획득하는 동작을 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시예에 따른 복수의 카메라를 포함하는 전자 장치가 복수의 카메라 이미지들 중 손의 3 차원 골격 데이터를 획득하는 방법에 이용하기 위한 적어도 하나의 카메라 이미지를 결정하는 동작을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시예에 따른 전자 장치의 블록도이다."}
