{"patent_id": "10-2022-0095795", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0088223", "출원번호": "10-2022-0095795", "발명의 명칭": "텍스트 처리 방법, 장치, 시스템, 기기 및 저장 매체", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "첸, 즈위우"}}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "텍스트 처리 방법에 있어서,텍스트 처리 가속 연산자를 이용하여 제1 텍스트에 대해 텍스트 처리를 수행하는 단계; 및 상기 텍스트 처리 가속 연산자를 이용하여, 텍스트 처리된 콘텐츠에 대해 병행으로 가속을 수행하는 단계를 포함하는 텍스트 처리 방법."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 텍스트 처리 가속 연산자를 이용하여 제1 텍스트에 대해 텍스트 처리를 수행하는 단계는,상기 제1 텍스트에 대응되는 제1 텐서를 획득하는 단계;상기 제1 텐서를 분할하여 복수의 분할 결과를 얻는 단계; 상기 분할 결과에 대해 각각 식별자 매핑을 수행하는 단계; 및 매핑 결과를 이용하여 제2 텐서를 생성하는 단계를 포함하되,상기 제1 텍스트는 문자열을 포함하고, 상기 제1 텐서는 문자열 텐서이고, 상기 제2 텐서는 정수 텐서이며, 상기 제2 텐서의 각 행 수치와 상기 제1 텐서의 각 행 문자열은 대응 관계를 갖는 텍스트 처리 방법."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 제1 텐서를 분할하여 복수의 분할 결과를 얻는 단계는,상기 제1 텐서에 대해 글자 분할 처리를 수행하여 복수의 글자를 얻는 단계; 및 상기 제1 텐서에 대해 단어 분할 처리를 수행하여 복수의 단어를 얻는 단계 중 적어도 하나를 포함하는 텍스트처리 방법."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 분할 결과에 대해 각각 식별자 매핑을 수행하는 단계는,매핑 관계에 따라 각 분할된 글자 및/또는 단어를 수치로 매핑하는 단계를 포함하는 텍스트 처리 방법."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 매핑 결과를 이용하여 제2 텐서를 생성하는 단계는,상기 제1 텐서의 각 행 문자열의 매핑 결과에 기반하여 상기 제2 텐서의 각 행 수치를 구하는 단계를 포함하고, 공개특허 10-2023-0088223-3-상기 제1 텐서는 N행 문자열을 포함하고, 상기 제2 텐서는 상기 N행 문자열에 대응되는 N행 수치를 포함하되, N은 양의 정수인 텍스트 처리 방법."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서, 상기 텍스트 처리 가속 연산자를 이용하여, 텍스트 처리된 콘텐츠에 대해 병행으로 가속을 수행하는 단계는,멀티 스레드를 이용하여 상기 제2 텐서를 병행으로 처리하는 단계를 포함하는 텍스트 처리 방법."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 텍스트 처리는 제1 언어 실행에서 제2 언어 실행으로 변환되고,상기 제1 언어는 해석형 언어이고, 상기 제2 언어는 컴파일러형 언어인 텍스트 처리 방법."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 텍스트 처리 가속 연산자에 의해 가속된 콘텐츠에 대해 자연어 이해 모델을 이용하여 자연어 이해 처리를수행하는 단계를 더 포함하되,상기 자연어 이해 모델은 상기 텍스트 처리 가속 연산자 및 변환 인코더 연산자를 포함하되,상기 변환 인코더 연산자는 융합된 어텐션 메커니즘 연산자와 융합된 피드포워드 연산자를 포함하는 텍스트 처리 방법."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 자연어 생성 모델을 이용하여 상기 자연어 이해 모델에 의해 처리된 콘텐츠에 대해 자연어 생성 처리를 수행하는 단계를 더 포함하되,상기 자연어 생성 모델은 변환 디코더 연산자 및 디코딩 전략 연산자를 포함하는 텍스트 처리 방법."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 자연어 생성 모델을 이용하여 상기 자연어 이해 모델에 의해 처리된 콘텐츠에 대해 자연어 생성 처리를 수행하는 단계는,상기 변환 디코더 연산자를 이용하여 디코더 코드 특징을 식별함으로써 사용되는 생성 네트워크 타입을 식별하고, 상기 생성 네트워크 타입에 대응되는 사전에 설정된 디코딩 연산자를 호출하는 단계를 포함하되,상기 생성 네트워크 타입은, 디코더(Decoder) 타입； 접두사 언어 모델링 (Prefix LM) 타입; 및 인코더-디코더(Encoder-Decoder) 타입 중 적어도 하나를 포함하는 텍스트 처리 방법. 공개특허 10-2023-0088223-4-청구항 11 제9항 또는 제10항에 있어서, 자연어 생성 모델을 이용하여 상기 자연어 이해 모델에 의해 처리된 콘텐츠에 대해 자연어 생성 처리를 수행하는 단계는,상기 디코딩 전략 연산자를 이용하여 디코딩 전략 특징을 식별함으로써 사용하는 디코딩 알고리즘을 식별하고,상기 디코딩 알고리즘을 이용하여, 제1 언어에서 실행되는 루프 코드를 제2 언어의 코드로 자동 번역하는 단계를 더 포함하되,상기 디코딩 알고리즘은, 검색 기반 디코딩 알고리즘 및 샘플링 기반 디코딩 알고리즘 중 적어도 하나를 포함하는 텍스트 처리 방법."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 자연어 생성 모델을 이용하여 상기 자연어 이해 모델에 의해 처리된 콘텐츠에 대해 자연어 생성 처리를 수행하는 단계는,딥 러닝 프레임워크의 JIT 컴파일 기능(Just In-time Compiler ability）을 호출하여 상기 제2 언어의 코드를컴파일하여 동적 링크 라이브러리를 획득하고, 상기 동적 링크 라이브러리와 상기 딥 러닝 프레임워크를 링크시키는 단계를 더 포함하는 텍스트 처리 방법."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서, 상기 텍스트 처리 가속 연산자의 단어 테이블을 도출하는 단계를 더 포함하는 텍스트 처리 방법."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 도출된 단어 테이블을 바이너리 직렬화 방식으로 저장하는 단계; 및 도출된 단어 테이블을 압축 알고리즘으로 압축 저장하는 단계 중 적어도 하나를 더 포함하는 텍스트 처리 방법."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항에 있어서, 상기 텍스트 처리 가속 연산자와 변환 인코더 연산자를 하나의 연산자로 통합하여 자연어 이해 모델 계산 그래프를 도출하는 단계를 더 포함하거나, 또는,디코딩 전략에 따라 순환 디코딩된 프레임워크 계산 그래프를 생성하는 단계;상기 순환 디코딩된 프레임워크 계산 그래프에 변환 디코더 연산자를 삽입하는 단계; 및 자연어 생성 모델 계산 그래프를 도출하는 단계를 더 포함하거나, 또는, 자연어 이해 모델 계산 그래프와 자연어 생성 모델 계산 그래프를 통합하여 얻은 계산 그래프를 포함하는 자연공개특허 10-2023-0088223-5-어 처리 통합 계산 그래프를 도출하는 단계를 더 포함하거나,상기 자연어 이해 모델 계산 그래프는 텍스트 처리 가속 연산자와 변환 인코더 연산자를 포함하고, 상기 자연어생성 모델 계산 그래프는 변환 디코더 연산자와 디코딩 전략 연산자를 포함하되,또는,자연어 이해 모델 계산 그래프, 자연어 생성 모델 계산 그래프 및 통합된 계산 그래프 중 적어도 하나를 복수의디바이스의 딥 러닝 프레임워크에 도입하는 단계를 더 포함하는 텍스트 처리 방법."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "텍스트 처리 장치에 있어서,텍스트 처리 가속 연산자에 적용되어 제1 텍스트에 대해 텍스트 처리를 수행하는 텍스트 처리 모듈; 및 상기 텍스트 처리 가속 연산자를 이용하여 텍스트 처리된 콘텐츠에 대해 병행으로 가속을 수행하는 병행 가속모듈을 포함하는 텍스트 처리 장치."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "딥 러닝 프레임워크 기반 시스템에 있어서,제1 텍스트에 대해 텍스트 처리를 수행하고 텍스트 처리된 콘텐츠에 대해 병행으로 가속을 수행하는 텍스트 처리 가속 연산자를 포함하는 딥 러닝 프레임워크 기반 시스템."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함는 전자 기기에 있어서, 상기 메모리에 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되고, 상기 명령이 상기 적어도 하나의 프로세서에 의해 실행되어 상기 적어도 하나의 프로세서가 제1항 내지 제10항 중 어느 한 항에 따른 방법을 실행하도록 하는 전자 기기."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "컴퓨터 명령이 저장된 비 일시적 컴퓨터 판독 가능한 저장 매체에 있어서, 상기 컴퓨터 명령은 제1항 내지 제10항 중 어느 한 항에 따른 방법을 상기 컴퓨터에서 실행시키는 비 일시적 컴퓨터 판독 가능한 저장 매체."}
{"patent_id": "10-2022-0095795", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램에 있어서,상기 컴퓨터 프로그램 중의 명령이 프로세서에 의해 실행될 경우, 제1항 내지 제10항 중 어느 한 항에 따른 방법을 구현하는 것을 특징으로 하는 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0095795", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 텍스트 처리 방법, 장치, 시스템, 기기 및 저장 매체를 제공하되, 컴퓨터"}
{"patent_id": "10-2022-0095795", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것으로, 특히 자연어 처리, 딥 러닝 등 인공 지능 분야에 관한 것이다. 구체적인 실시형태에 있어서, 텍스트 처리 가속 연산자를 이용하여 제1 텍스트에 대해 텍스트 처리를 수행하고; 상기 텍스트 처리 가속 연산자를 이용하여, 텍스 트 처리된 콘텐츠에 대해 병행으로 가속을 수행한다. 본 발명의 실시예는 텍스트 처리 가속 연산자에 의해 텍스 트 처리 및 병행 가속을 수행함으로써 텍스트 처리 속도를 향상시킬 수 있다. 대 표 도 - 도1"}
{"patent_id": "10-2022-0095795", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2023-0088223 CPC특허분류 G06F 40/289 (2020.01) G06N 3/04 (2023.01) G06N 3/08 (2023.01) 발명자 우, 티앤 중국 베이징 하이디안 디스트릭트 샹디 10번가 넘 버 10, 바이두 캠퍼스 2층 위우, 띠앤하이 중국 베이징 하이디안 디스트릭트 샹디 10번가 넘 버 10, 바이두 캠퍼스 2층마, 이앤쥔 중국 베이징 하이디안 디스트릭트 샹디 10번가 넘 버 10, 바이두 캠퍼스 2층 후, 시아오구왕 중국 베이징 하이디안 디스트릭트 샹디 10번가 넘 버 10, 바이두 캠퍼스 2층명 세 서 청구범위 청구항 1 텍스트 처리 방법에 있어서, 텍스트 처리 가속 연산자를 이용하여 제1 텍스트에 대해 텍스트 처리를 수행하는 단계; 및 상기 텍스트 처리 가속 연산자를 이용하여, 텍스트 처리된 콘텐츠에 대해 병행으로 가속을 수행하는 단계를 포 함하는 텍스트 처리 방법. 청구항 2 제1항에 있어서, 텍스트 처리 가속 연산자를 이용하여 제1 텍스트에 대해 텍스트 처리를 수행하는 단계는, 상기 제1 텍스트에 대응되는 제1 텐서를 획득하는 단계; 상기 제1 텐서를 분할하여 복수의 분할 결과를 얻는 단계; 상기 분할 결과에 대해 각각 식별자 매핑을 수행하는 단계; 및 매핑 결과를 이용하여 제2 텐서를 생성하는 단계를 포함하되, 상기 제1 텍스트는 문자열을 포함하고, 상기 제1 텐서는 문자열 텐서이고, 상기 제2 텐서는 정수 텐서이며, 상 기 제2 텐서의 각 행 수치와 상기 제1 텐서의 각 행 문자열은 대응 관계를 갖는 텍스트 처리 방법. 청구항 3 제2항에 있어서, 상기 제1 텐서를 분할하여 복수의 분할 결과를 얻는 단계는, 상기 제1 텐서에 대해 글자 분할 처리를 수행하여 복수의 글자를 얻는 단계; 및 상기 제1 텐서에 대해 단어 분할 처리를 수행하여 복수의 단어를 얻는 단계 중 적어도 하나를 포함하는 텍스트 처리 방법. 청구항 4 제3항에 있어서, 상기 분할 결과에 대해 각각 식별자 매핑을 수행하는 단계는, 매핑 관계에 따라 각 분할된 글자 및/또는 단어를 수치로 매핑하는 단계를 포함하는 텍스트 처리 방법. 청구항 5 제2항에 있어서, 매핑 결과를 이용하여 제2 텐서를 생성하는 단계는, 상기 제1 텐서의 각 행 문자열의 매핑 결과에 기반하여 상기 제2 텐서의 각 행 수치를 구하는 단계를 포함하고, 상기 제1 텐서는 N행 문자열을 포함하고, 상기 제2 텐서는 상기 N행 문자열에 대응되는 N행 수치를 포함하되, N 은 양의 정수인 텍스트 처리 방법. 청구항 6 제2항에 있어서, 상기 텍스트 처리 가속 연산자를 이용하여, 텍스트 처리된 콘텐츠에 대해 병행으로 가속을 수행하는 단계는, 멀티 스레드를 이용하여 상기 제2 텐서를 병행으로 처리하는 단계를 포함하는 텍스트 처리 방법. 청구항 7 제1항에 있어서, 상기 텍스트 처리는 제1 언어 실행에서 제2 언어 실행으로 변환되고, 상기 제1 언어는 해석형 언어이고, 상기 제2 언어는 컴파일러형 언어인 텍스트 처리 방법. 청구항 8 제1항에 있어서, 상기 텍스트 처리 가속 연산자에 의해 가속된 콘텐츠에 대해 자연어 이해 모델을 이용하여 자연어 이해 처리를 수행하는 단계를 더 포함하되, 상기 자연어 이해 모델은 상기 텍스트 처리 가속 연산자 및 변환 인코더 연산자를 포함하되, 상기 변환 인코더 연산자는 융합된 어텐션 메커니즘 연산자와 융합된 피드포워드 연산자를 포함하는 텍스트 처 리 방법. 청구항 9 제1항에 있어서, 자연어 생성 모델을 이용하여 상기 자연어 이해 모델에 의해 처리된 콘텐츠에 대해 자연어 생성 처리를 수행하 는 단계를 더 포함하되, 상기 자연어 생성 모델은 변환 디코더 연산자 및 디코딩 전략 연산자를 포함하는 텍스트 처리 방법. 청구항 10 제9항에 있어서, 자연어 생성 모델을 이용하여 상기 자연어 이해 모델에 의해 처리된 콘텐츠에 대해 자연어 생성 처리를 수행하 는 단계는, 상기 변환 디코더 연산자를 이용하여 디코더 코드 특징을 식별함으로써 사용되는 생성 네트워크 타입을 식별하 고, 상기 생성 네트워크 타입에 대응되는 사전에 설정된 디코딩 연산자를 호출하는 단계를 포함하되, 상기 생성 네트워크 타입은, 디코더(Decoder) 타입； 접두사 언어 모델링 (Prefix LM) 타입; 및 인코더-디코더 (Encoder-Decoder) 타입 중 적어도 하나를 포함하는 텍스트 처리 방법. 청구항 11 제9항 또는 제10항에 있어서, 자연어 생성 모델을 이용하여 상기 자연어 이해 모델에 의해 처리된 콘텐츠에 대해 자연어 생성 처리를 수행하 는 단계는, 상기 디코딩 전략 연산자를 이용하여 디코딩 전략 특징을 식별함으로써 사용하는 디코딩 알고리즘을 식별하고, 상기 디코딩 알고리즘을 이용하여, 제1 언어에서 실행되는 루프 코드를 제2 언어의 코드로 자동 번역하는 단계 를 더 포함하되, 상기 디코딩 알고리즘은, 검색 기반 디코딩 알고리즘 및 샘플링 기반 디코딩 알고리즘 중 적어도 하나를 포함하 는 텍스트 처리 방법. 청구항 12 제11항에 있어서, 자연어 생성 모델을 이용하여 상기 자연어 이해 모델에 의해 처리된 콘텐츠에 대해 자연어 생성 처리를 수행하 는 단계는, 딥 러닝 프레임워크의 JIT 컴파일 기능(Just In-time Compiler ability）을 호출하여 상기 제2 언어의 코드를 컴파일하여 동적 링크 라이브러리를 획득하고, 상기 동적 링크 라이브러리와 상기 딥 러닝 프레임워크를 링크시 키는 단계를 더 포함하는 텍스트 처리 방법. 청구항 13 제1항에 있어서, 상기 텍스트 처리 가속 연산자의 단어 테이블을 도출하는 단계를 더 포함하는 텍스트 처리 방법. 청구항 14 제13항에 있어서, 도출된 단어 테이블을 바이너리 직렬화 방식으로 저장하는 단계; 및 도출된 단어 테이블을 압축 알고리즘으로 압축 저장하는 단계 중 적어도 하나를 더 포함하는 텍스트 처리 방법. 청구항 15 제1항에 있어서, 상기 텍스트 처리 가속 연산자와 변환 인코더 연산자를 하나의 연산자로 통합하여 자연어 이해 모델 계산 그래 프를 도출하는 단계를 더 포함하거나, 또는, 디코딩 전략에 따라 순환 디코딩된 프레임워크 계산 그래프를 생성하는 단계; 상기 순환 디코딩된 프레임워크 계산 그래프에 변환 디코더 연산자를 삽입하는 단계; 및 자연어 생성 모델 계산 그래프를 도출하는 단계를 더 포함하거나, 또는, 자연어 이해 모델 계산 그래프와 자연어 생성 모델 계산 그래프를 통합하여 얻은 계산 그래프를 포함하는 자연어 처리 통합 계산 그래프를 도출하는 단계를 더 포함하거나, 상기 자연어 이해 모델 계산 그래프는 텍스트 처리 가속 연산자와 변환 인코더 연산자를 포함하고, 상기 자연어 생성 모델 계산 그래프는 변환 디코더 연산자와 디코딩 전략 연산자를 포함하되, 또는, 자연어 이해 모델 계산 그래프, 자연어 생성 모델 계산 그래프 및 통합된 계산 그래프 중 적어도 하나를 복수의 디바이스의 딥 러닝 프레임워크에 도입하는 단계를 더 포함하는 텍스트 처리 방법. 청구항 16 텍스트 처리 장치에 있어서, 텍스트 처리 가속 연산자에 적용되어 제1 텍스트에 대해 텍스트 처리를 수행하는 텍스트 처리 모듈; 및 상기 텍스트 처리 가속 연산자를 이용하여 텍스트 처리된 콘텐츠에 대해 병행으로 가속을 수행하는 병행 가속 모듈을 포함하는 텍스트 처리 장치. 청구항 17 딥 러닝 프레임워크 기반 시스템에 있어서, 제1 텍스트에 대해 텍스트 처리를 수행하고 텍스트 처리된 콘텐츠에 대해 병행으로 가속을 수행하는 텍스트 처 리 가속 연산자를 포함하는 딥 러닝 프레임워크 기반 시스템. 청구항 18 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함는 전자 기기에 있어서, 상기 메모리에 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되고, 상기 명령이 상기 적어도 하 나의 프로세서에 의해 실행되어 상기 적어도 하나의 프로세서가 제1항 내지 제10항 중 어느 한 항에 따른 방법 을 실행하도록 하는 전자 기기. 청구항 19 컴퓨터 명령이 저장된 비 일시적 컴퓨터 판독 가능한 저장 매체에 있어서, 상기 컴퓨터 명령은 제1항 내지 제10항 중 어느 한 항에 따른 방법을 상기 컴퓨터에서 실행시키는 비 일시적 컴 퓨터 판독 가능한 저장 매체. 청구항 20 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램 중의 명령이 프로세서에 의해 실행될 경우, 제1항 내지 제10항 중 어느 한 항에 따른 방 법을 구현하는 것을 특징으로 하는 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램. 발명의 설명 기 술 분 야본 발명은 컴퓨터 기술 분야에 관한 것으로, 특히 자연어 처리, 딥 러닝 등 인공 지능 분야에 관한 것이다."}
{"patent_id": "10-2022-0095795", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자연어 처리(Natural Language Processing, NLP)는 딥 러닝 프레임워크의 응용 시나리오 중 하나이다. 사전 트 레이닝 모델 기술의 급속한 보급에 따라 자연어의 이해 및 생성 두 가지 핵심 과제의 응용 패러다임이 점차적으 로 통일되고, 그의 성능과 용이성에 대한 개발자와 비즈니스 시나리오의 요구도 점차 증가되고 있다."}
{"patent_id": "10-2022-0095795", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 텍스트 처리 방법, 장치, 시스템, 기기 및 저장 매체를 제공한다."}
{"patent_id": "10-2022-0095795", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, 텍스트 처리 방법에 있어서, 텍스트 처리 가속 연산자를 이용하여 제1 텍스트에 대해 텍스트 처리를 수행하는 단계; 및 상기 텍스트 처리 가속 연산자를 이용하여, 텍스트 처리된 콘텐츠에 대 해 병행으로 가속을 수행하는 단계를 포함하는 텍스트 처리 방법을 제공한다. 본 발명의 다른 측면에 따르면, 텍스트 처리 장치에 있어서, 텍스트 처리 가속 연산자를 이용하여 제1 텍스트에 대해 텍스트 처리를 수행하는 텍스트 처리 모듈; 및 상기 텍스트 처리 가속 연산자를 이용하여, 텍스트 처리된 콘텐츠에 대해 병행으로 가속을 수행하는 병행 가속 모듈을 포함하는 텍스트 처리 장치를 제공한다. 본 발명의 다른 측면에 따르면, 딥 러닝 프레임워크 기반 시스템에 있어서, 제1 텍스트에 대해 텍스트 처리를 수행하고 텍스트 처리된 콘텐츠에 대해 병행으로 가속을 수행하는 텍스트 처리 가속 연산자를 포함하는 딥 러닝 프레임워크 기반 시스템를 제공한다. 본 발명의 다른 측면에 따르면, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 연결되는 메 모리를 포함는 전자 기기에 있어서, 상기 메모리에 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저 장되고, 상기 명령이 상기 적어도 하나의 프로세서에 의해 실행되어 상기 적어도 하나의 프로세서가 본 발명의 임의의 실시예에 따른 방법을 실행하도록 하는 전자 기기를 제공한다. 본 발명의 다른 측면에 따르면, 컴퓨터 명령이 저장된 비 일시적 컴퓨터 판독 가능한 저장 매체에 있어서, 상기 컴퓨터 명령은 본 발명의 임의의 실시예에 따른 방법을 상기 컴퓨터에서 실행시키는 비 일시적 컴퓨터 판독 가 능한 저장 매체를 제공한다. 본 발명의 다른 측면에 따르면, 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램 중의 명령이 프로세서에 의해 실행될 경우, 본 발명의 임의의 실시예에 따른 방법을 구현하는 것을 특징으로 하는 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램을 제공한다. 본 명세서에 기재된 내용은 본 발명의 실시예의 키 포인트 또는 중요 특징을 표시하는 것이 아니며, 본 발명의 범위를 한정하는 것도 아님을 이해해야 한다. 본 발명의 기타 특징은 하기 기재에 의해 용이하게 이해될 것이다."}
{"patent_id": "10-2022-0095795", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 예시적인 실시예를 설명한다. 이해에 도움이 되도록 본 발명 실시예의 다양한 세부 사항을 포함하되, 이는 단지 예시적인 것으로 간주되어야 한다. 따라서, 본 발명이 속하는 기술 분 야에서 통상의 지식을 가진 자는 본 발명의 범위 및 사상을 벗어나지 않으면서 설명된 실시예의 다양한 변경 및 수정이 이루어질 수 있음을 인식할 것이다. 또한, 이하의 설명에서는 명료함과 간결함을 위하여 공지 기능 및 구성에 대한 설명을 생략한다. 도 1은 본 발명의 일 실시예에 따른 텍스트 처리 방법의 흐름 사시도이다. 상기 방법은 다음과 같은 단계를 포 함할 수 있다. 단계(S101)에서, 텍스트 처리 가속 연산자를 이용하여 제1 텍스트에 대해 텍스트 처리를 수행한다. 단계(S102)에서, 상기 텍스트 처리 가속 연산자를 이용하여, 텍스트 처리된 콘텐츠를 병행으로 가속한다. 구체적으로, 제1 텍스트에는 예컨대 하나 이상의 문자열 텍스트(String Text)와 같은 처리를 계속할 특정 콘텐 츠가 포함될 수 있다. 가속 토크나이저 연산자(Faster Tokenizer Operator)와 같은 텍스트 처리 가속 연산자는 복수의 문자열 텍스트에 대해 일련의 텍스트 처리를 수행하여 각 문자열 텍스트에 대응되는 정수（Integer）형 태의 콘텐츠를 얻을 수 있다. 다음, 텍스트 처리 가속 연산자는 텍스트 처리된 정수 형태의 콘텐츠를 병행으로 가속할 수도 있다. 이와 같이 텍스트 처리 가속 연산자에 의해 텍스트 처리와 병행 가속을 수행함으로써 텍스트 처리 속도를 향상시킬 수 있다. 도 2는 본 발명의 다른 실시예에 따른 텍스트 처리 방법의 흐름 사시도이다. 본 실시예의 텍스트 처리 방법은 상술한 방법의 실시예의 특징들 중 하나 이상을 포함할 수 있다. 일 실시형태에서, 단계(S101)에서 텍스트 처리 가속 연산자를 이용하여 제1 텍스트에 대해 텍스트 처리를 수행하는 단계는 하기와 같은 단계를 포함한다. 단계(S201)에서, 상기 제1 텍스트에 대응되는 제1 텐서를 획득한다. 단계(S202)에서, 상기 제1 텐서를 분할하여 복수의 분할 결과를 얻는다. 단계(S203)에서, 상기 분할 결과에 대하여 각각 식별자 매핑을 수행한다. 단계(S204)에서, 매핑 결과를 이용하여 제2 텐서를 생성한다. 예시적으로, 제1 텐서 연산자에 의해 제1 텍스트의 텐서 표현을 획득될 수 있고, 제1 텍스트를 제1 텐서로 변환 할 수 있다. 텐서란 신경망 내의 일종 데이터 구조로서, 다차원 배열이나 행렬 등과 같은 하나의 데이터 컨테이 너로 이해될 수 있다. 제1 텐서는 문자열 텐서를 포함하고, 문자열 텐서는 제1 텍스트 중 하나 이상의 문자열 텍스트(문자열로 약칭)를 포함할 수 있다. 예컨대, 제1 텐서에는 제1 텍스트에 의해 분할된 N행 문자열이 포함 될 수 있다. 분할 연산자에 의해 제1 텐서를 분할하는 단계는 제1 텐서 중 문자열을 분할하는 단계를 포함할 수 있다. 다음, 매핑 연산자에 의해 분할 결과를 각각 매핑한 후, 제2 텐서 연산자에 의해 매핑 결과에 기반하여 제2 텐서를 얻을 수 있다. 제2 텐서에는 N행 문자열에 대응되는 N행 정수 형태의 수치를 포함할 수 있다. 본 발 명의 실시예에 따르면, 제1 텐서에 의해 텍스트를 정렬할 수 있으므로 처리 결과의 정확성을 높이는데 도움이되 고, 텍스트 처리 과정을 연산자화하여 처리 속도를 높이는데 도움이 된다. 일 실시형태에서, 단계（S202）에서 상기 제1 텐서를 분할하여 복수의 분할 결과를 얻는 단계는 하기와 같은 단 계 중 적어도 하나를 포함한다. 상기 제1텐서에 대해 글자 분할 처리를 수행하여 복수의 글자를 얻는다. 상기 제1텐서에 대해 단어 분할 처리를 수행하여 복수의 단어를 얻는다. 예컨대, 글자 분할 연산자에 의해 제1 텐서 중 어느 문자열 ‘오늘 날씨 좋아요’에 대해 글자 분할을 수행하여, 당해 문자열의 복수의 글자 ‘오’, ‘늘’, ‘날’, ‘씨’, ‘좋’, ‘아’, ‘요’를 얻는다. 또한, 단어 분할 연산자에 의해 제1 텐서 중 어느 문자열 ‘같이 여행가자’에 대해 단어 분할을 수행하여, 당 해 문자열의 복수의 단어 ‘같이’, ‘여행’, ‘가자’를 얻는다. 본 발명의 실시예에서, 구체적으로 글자 분할, 단어 분할, 또는 글자 분할과 과 단어 분할을 모두 수행하는지는 실제 응용되는 시나리오의 요구에 따라 처리할 수 있으나, 이에 한정되는 것은 아니다. 본 발명의 일 실시예에 서, 제1 텐서를 글자 분할 및/또는 단어 분할 처리하여 더 많은 텍스트 처리 시나리오에 유연하게 대응할 수 있 다. 일 실시형태에서, 단계(S203)에서 상기 분할 결과에 대하여 각각 식별자 매핑을 수행하는 단계는, 매핑 관계에 따라 각 분할된 글자 및/또는 단어를 수치로 매핑하는 단계를 포함할 수 있다. 예컨대, 자전, 사전, 용어집 등 을 매핑 관계로 미리 설정할 수 있으며, 자전, 사전, 용어집 등에서 당해 정수 형태의 수치를 찾을 수 있다. 본 발명의 일 실시예에 따르면, 매핑 관계에 의해 제1 텐서의 각 분할된 글자 및/또는 단어에 해당하는 수치를 찾 아냄으로써 기계 처리를 용이하게 하고, 처리 속도 및 정확성을 향상시킬 수 있다. 일 실시형태에서, 단계(S204)에서, 매핑 결과를 이용하여 제2 텐서를 생성하는 단계는, 상기 제1 텐서의 각 행 문자열의 매핑 결과에 기반하여 상기 제2 텐서의 각 행 수치를 구하는 단계를 포함하고, 상기 제1 텐서는 N행 문자열을 포함하고, 상기 제2 텐서는 상기 N행 문자열에 대응되는 N행 수치를 포함하되, N은 양의 정수이다. 예컨대, 제1 텐서가 N행 문자열을 포함하는 경우, 상술한 매핑 관계에 의해 각 행 문자열에 대응되는 수치를 찾 아 N행 수치를 구할 수 있다. 당해 N행 수치로 구성된 행렬을 제2 텐서로 할 수 있다. 본 발명의 일 실시예에 따르면, 제1 텍스트를 변환하여 얻은 수치를 제2 턴서에 의해 정열함으로써, 후속 가속 처리를 용이하게 할 수있다. 일 실시형태에서, 상기 제1 텍스트는 문자열을 포함하고, 상기 제1 텐서는 문자열 텐서이고, 상기 제2 텐서는 정수 텐서이며, 상기 제2 텐서의 각 행 수치와 상기 제1 텐서의 각 행 문자열은 대응 관계를 갖는다. 본 발명의 일 실시예에서, 제1 텐서에 의해 문자열을 정열할 수 있으며, 문자열을 변환하여 얻은 정수 수치를 제2 텐서에 의해 정열할 수 있어 후속 가속 처리를 용이하게 할 수 있다. 일 실시형태에서, 단계(S102)에서 상기 텍스트 처리 가속 연산자를 이용하여, 텍스트 처리된 콘텐츠를 병행으로 가속하는 단계는 하기와 같은 단계를 포함한다. 단계(S205)에서, 멀티 스레드를 이용하여 상기 제2 텐서를 병행으로 처리한다. 예컨대, 멀티 스레드 병행 가속 연산자에 의해 복수의 스레드를 호출하고, 각 스레드가 제2 텐서의 1 행 수치를 처리할 수 있다면, 제2 텐서의 복수의 행 수치를 병행 처리할 수 있다. 본 발명의 실시예에서, 멀티 스레드에 의해 텍스트 처리 속도를 크게 향상시킬 수 있으며, 고성능의 문자 코덱 구현에 유리하다. 일반적으로 동시에 호출할 수 있는 스레드가 많을수 록 병행 처리의 속도가 빨라진다. 일 실시형태에서, 상기 텍스트 처리는 제1 언어 실행에서 제2 언어 실행으로 변환된다. 본 발명의 실시예에서 텍스트 처리를 제1 언어 실행에서 제2 언어 실행으로 변환하여 멀티 스레드 병행 가속이 이용 가능함으로, 다양 한 언어 환경에 유연하게 대응할 수 있고, 처리 속도를 더욱 향상시킬 수 있다. 일 실시형태에서, 상기 제1 언어는 해석형 언어이고, 상기 제2 언어는 컴파일러형 언어이다. 예컨대, 본래 해석 형 언어 실행에 의해 수행되는 텍스트 처리 프로세스를 컴파일러형 언어 실행에 의해 수행되도록 변환하고, 컴 파일러형 언어가 멀티 스레드를 호출할 수 있는 특징을 이용하여 병행 가속이 가능하다. 예컨대, 해석형 언어는 Python, Java 등을 포함할 수 있고, 컴파일러형 언어는 C++ 등을 포함할 수 있다. 해석형 언어와 컴파일러형 언 어는 상기 예시 이외의 다른 타입의 언어일 수 있으며, 이에 한정되는 것은 아니다. 이에 따라, 다양한 언어 환 경에 유연하게 대응할 수 있고 개발의 난이도를 감소할 수 있으며, 컴파일러형 언어를 이용하여 처리 속도를 향 상시킬 수 있다. 도 3은 본 발명의 다른 실시예에 따른 텍스트 처리 방법의 흐름 사시도이다. 본 실시예의 텍스트 처리 방법은 상술한 방법의 실시예의 특징들 중 하나 이상을 포함할 수 있다. 일 실시형태에서, 당해 방법은 다음과 같은 단 계를 더 포함할 수 있다. 단계(S301)에서, 상기 텍스트 처리 가속 연산자에 의해 가속된 콘텐츠에 대해 자연어 이해 모델을 이용하여 자 연어 이해 처리를 수행한다. 본 발명의 실시예에서 텍스트 처리 가속 연산자를 자연어 이해 모델에 적용함으로 써 자연어 이해의 처리 속도를 향상시킬 수 있다. 일 실시형태에서, 상기 자연어 이해 모델은 상기 텍스트 처리 가속 연산자 및 변환 인코더 연산자를 포함한다. 본 실시예에서 텍스트 처리 가속 연산자의 구체적인 기능은 도 1 및 도 2의 실시예에 대한 설명을 참조할 수 있 다. 예컨대, 텍스트 처리 가속 연산자 중 멀티 스레드 병행 가속 연산자는 제2 텐서에서 수치를 병행으로 판독 한 후, 변환(Transformer) 인코더 연산자로 전달할 수 있으며, 변환 인코더 연산자는 수신된 수치에 대해 문자 열 인코딩을 수행한다. 변환 인코더 연산자는 다계층 변환 인코더를 포함할 수 있다. 본 발명의 실시예에서 텍 스트 처리 가속 연산자와 변환 인코더 연산자에 의해 신속하고 정확하게 자연어 이해 처리를 수행할 수 있다. 일 실시형태에서, 상기 변환 인코더 연산자는 융합된 어텐션 메커니즘 연산자와 융합된 피드포워드 연산자를 포 함한다. 예컨대, 융합된 어텐션 메커니즘 연산자는 어텐션 메커니즘의 OP 수를 줄일 수 있다. 구체적으로, 멀티 헤드 어 텐션 메커니즘 중 GEMM(General Matrix-matrix Multiplication), 편향 추가(bias add), 전치(transpose) 등을 3에서 1로 줄이고, 데이터 재사용율을 높여 융합된 어텐션 메커니즘(Fused Attention) 연산자를 얻을 수 있다. 또 다른 예로, 커널(Kernels)을 융합하여 Fused Dropout Act Bias, Fused Ln Add Dropout Bias, Fused Add Dropout Bias 등의 융합된 피드포워드Fused Feedforward）연산자를 얻을 수 있다. 본 발명의 일 실시예에서, 융합된 어텐션 메커니즘에 의해 프레임워크 스케줄링 오버헤드를 줄일 수 있고, 융합 된 피드포워드 연산자에 의해 액세스 오버헤드를 줄일 수 있다. 일 실시형태에서, 상기 방법은 다음과 같은 단계를 더 포함할 수 있다. 단계(S302)에서, 자연어 생성 모델을 이용하여 상기 자연어 이해 모델에 의해 처리된 콘텐츠에 대해 자연어 생 성 처리를 수행한다. 예컨대, 자연어 생성 모델의 변환 인코더 연산자가 자연어 이해 결과를 출력한 후, 자연어 생성 모델은 디코더를 이용하여 자연어 생성 모델에 대해 디코딩 및 예측 등 처리를 수행함으로써 자연어 생성 결과를 얻을 수 있다. 본 발명의 일 실시예에서, 자연어 생성 모델을 통해, 자연어 이해 결과에 기반하여 생성 결과를 정확하게 예측할 수 있다. 일 실시형태에서, 상기 자연어 생성 모델은 변환 디코더 연산자 및 디코딩 전략 연산자를 포함한다. 본 발명의 일 실시예에서, 자연어 생성 모델은 변환(Transformer) 디코더 연산자와 디코딩 전략 연산자에 의해 신속하고 정확하게 자연어 생성 처리를 수행할 수 있다. 일 실시형태에서, 단계(S302)에서 자연어 생성 모델을 이용하여 상기 자연어 이해 모델에 의해 처리된 콘텐츠에 대해 자연어 생성 처리를 수행하는 단계는, 상기 변환 디코더 연산자를 이용하여 디코더 코드 특징을 식별함으 로써 사용되는 생성 네트워크 타입을 식별하는 단계; 및 상기 생성 네트워크 타입에 대응되는 사전에 설정된 디 코딩 연산자를 호출하는 단계를 포함한다. 예컨대, 생성 네트워크 타입 별로 고성능의 디코딩 연산자를 사전 설정할 수 있다. 사용자가 어느 한 타입의 디 코더 코드를 선택하면, 변환 디코더 연산자는 당해 디코더 코드에 기반하여 사용자가 사용하는 생성 네트워크의 타입을 식별할 수 있다. 그리고, 변환 디코더 연산자는 식별된 생성 네트워크 타입에 대응되는 사전 설정된 고 성능의 디코딩 연산자를 호출할 수 있다. 따라서, 본 발명의 실시예에서 다양한 생성 네트워크 타입을 지원할 수 있을 뿐 만 아니라 보다 많은 디코딩 기능을 지원할 수 있다. 일 실시형태에서, 상기 생성 네트워크 타입은, 디코더(Decoder) 타입； 접두사 언어 모델링(Prefix LM) 타입; 및 인코더-디코더(Encoder-Decoder) 타입 중 적어도 하나를 포함할 수 있다. 예컨대, Decoder 타입의 생성 네트워크는 디코더 계층, Transformer 계층 등을 포함할 수 있다. 또 다른 예로, Prefix LM 타입의 생성 네트워크는 Prefix LM 계층 및 Transformer 계층 등을 포함할 수 있다. 또 다른 예로, Encoder-Decoder 타입의 생성 네트워크는 디코더 계층, Transformer 계층, 인코더-디코더 계층, 및 인코더 계층 등을 포함할 수 있다. 본 발명의 실시예에서, 보다 포괄적인 생성 네트워크 타입을 지원함으로써 보다 풍부한 디코딩 기능을 제공할 수 있다. 일 실시형태에서, 단계(S302)에서 자연어 생성 모델을 이용하여 상기 자연어 이해 모델에 의해 처리된 콘텐츠에 대해 자연어 생성 처리를 수행하는 단계는, 상기 디코딩 전략 연산자를 이용하여 디코딩 전략 특징을 식별함으 로써 사용하는 디코딩 알고리즘을 식별하는 단계; 및 상기 디코딩 알고리즘을 이용하여, 제1 언어에서 실행되는 루프 코드를 제2 언어의 코드로 자동 번역하는 단계를 더 포함할 수 있다. 예컨대, 사용자가 어느 디코딩 알고리즘을 선택하면, 디코딩 전략 연산자는 디코딩 전략 특징을 식별하여 사용 자가 사용하는 암호화 알고리즘을 식별하고, 나아가 제1 언어의 루프 코드를 제2 언어의 코드로 자동 번역한다. 상술한 예를 참조하면, 제1 언어는 해석형 언어일 수 있고, 제2 언어는 컴파일러형 언어일 수 있다. 인식된 디 코딩 알고리즘을 이용하여 해석형 언어에서 실행되는 루프 코드를 컴파일러형 언어의 코드로 자동 번역할 수 있 다. 따라서, 서로 다른 언어간의 코드 변환을 자동으로 수행는데 유리하고, 자연어 생성 처리의 성능을 향상시 키고 개발의 난이도를 감소할 수 있다. 일 실시형태에서, 상기 디코딩 알고리즘은, 검색 기반 디코딩 알고리즘; 및 샘플링 기반 디코딩 알고리즘 중 적 어도 하나를 포함할 수 있다. 예컨대, 검색 기반 디코딩 알고리즘에는 그리디 서치, 빔 서치 등이 포함될 수 있다. 여기서, 그리디 서치는 각 단계에서 최대 가능한 단어를 예측하고, 당해 단어를 다음 예측시 입력으로 사용할 수 있다. 빔 서치는 먼저 인 코더-디코더에 의해 입력되는 문법 문장이 주어지고, 첫번째 단어의 최대 가능한 확률값을 출력한 다음, 선택된 첫 번째 가능한 단어별로 두번째 단어가 무엇인지를 고려한다. 또 다른 예로, 샘플링 기반 디코딩 알고리즘은 랜덤 샘플링, 상위 K개의 샘플링(Top-K Sampling), 핵 샘플링 (Top-P（nucleus） Sampling)을 포함할 수 있다. 여기서, 랜덤 샘플링은, 전체 단어 테이블에서의 언어 모델에 의해 얻어진 다음 단어의 확률 분포에 따라 랜덤 샘플링을 수행하여, 다음 단어로 무엇을 생성하는지 결정하는 단계를 포함할 수 있다. Top-K Sampling은, 확률이 가장 큰 K개의 단어를 추출한 후, 당해 K개의 단어 확률을 정규화하여 샘플링하는 단계를 포함할 수 있다. Top-P 샘플링은, 현재의 모든 단어들의 확률들을 큰 확률부터 작은 확률 순서로 누적하고, 누적된 값이 임계값P보다 크면, 다음으로 작은 확률의 단어은 사용하지 않고 이전 의 단어에 대해 다시 샘플링한다. 본 발명의 일 실시예에 따르면, 서로 다른 디코딩 알고리즘에 의해 보다 풍부한 자동 디코딩 기능을 지원하여 코드 변환 성능을 향상시킬 수 있다. 일 실시형태에서, 단계(S302)에서 자연어 생성 모델을 이용하여 상기 자연어 이해 모델에 의해 처리된 콘텐츠에 대해 자연어 생성 처리를 수행하는 단계는, 딥 러닝 프레임워크의 JIT 컴파일 기능을 호출하여 상기 제2 언어의 코드를 컴파일하여 동적 링크 라이브러리를 획득하고, 상기 동적 링크 라이브러리와 상기 딥 러닝 프레임워크를 링크시키는 단계를 더 포함한다. 상술한 예를 참조하면, 제2 언어는 컴파일러형 언어일 수 있다. 딥 러닝 프레임워크의 JIT 컴파일 기능을 호출 하여, 당해 컴파일러형 언어의 코드를 자동 컴파일하여 동적 링크 라이브러리를 획득하고, 나아가 딥 러닝 프레 임워크과 동적 링크 라이브러리를 링크시켜 고성능의 변환 디코더 연산자를 얻을 수 있다. 도 4는 본 발명의 다른 실시예에 따른 텍스트 처리 방법의 흐름 사시도이다. 본 실시예의 텍스트 처리 방법은 상술한 방법의 실시예의 특징들 중 하나 이상을 포함할 수 있다. 일 실시형태에서, 상기 방법은 다음과 같은 단 계를 더 포함할 수 있다. 단계(S401)에서, 상기 텍스트 처리 가속 연산자의 단어 테이블을 도출한다. 예컨대, 텍스트 처리 가속 연산자의 단어 테이블은 당해 텍스트 처리 가속 연산자가 사용하는 각 단어와 수치의 매핑 관계를 포함할 수 있다. 자연 어 이해 모델의 사용된 텍스트 처리 가속 연산자의 단어 테이블은 부동할 수 있고, 일부 또는 전부가 부동할 수 있으며, 구체적으로 자연어 이해 모델이 구체적으로 구현하고자 하는 기능에 따라 결정된다. 본 발명의 실시예 에서 텍스트 처리 가속 연산자의 단어 테이블을 도출한 후 중복 사용이 가능하므로, 후속 배치 속도를 높이고 배치 난이도를 감소할 수 있다. 일 실시형태에서, 상기 방법은 다음 단계 중 적어도 하나를 더 포함할 수 있다. 단계(S402)에서, 도출된 단어 테이블을 바이너리 직렬화 방식으로 저장한다. 단계(S403)에서, 도출된 단어 테이블을 압축 알고리즘으로 압축 저장한다. 직렬화 저장에 의해 단어 테이블의 판독 속도를 향상시킬 수 있고, 나아가 텍스트 처리 속도를 향상시킬 수 있 다. 압축 저장에 의해 테이블이 차지하는 저장 공간을 줄임으로써 저장 자원을 절약할 수 있다. 도 5는 본 발명의 다른 실시예에 따른 텍스트 처리 방법의 흐름 사시도이다. 본 실시예의 텍스트 처리 방법은 상술한 방법의 실시예의 특징들 중 하나 이상을 포함할 수 있다. 일 실시형태에서, 상기 방법은 다음과 같은 단 계를 더 포함할 수 있다. 단계(S501)에서, 상기 텍스트 처리 가속 연산자와 변환 인코더 연산자를 하나의 연산자로 통합하여 자연어 이해 모델 계산 그래프를 도출한다. 본 발명의 일 실시예에서, 계산 그래프는 유향 그래프일 수 있으며, 그 중 노드는 수학적 연산에 대응될 수 있 다. 계산 그래프는 수학식을 표현하고 평가하는 방식 중 하나이다. 본 발명의 실시예에서 텍스트 처리 가속 연 산자와 변환 인코더 연산자를 자연어 이해 모델 계산 그래프에 통합함으로써 자연어 이해의 속도를 높이고 정확 한 자연어 이해 결과를 얻을 수 있다. 도 6은 본 발명의 다른 실시예에 따른 텍스트 처리 방법의 흐름 사시도이다. 본 실시예의 텍스트 처리 방법은 상술한 방법의 실시예의 특징들 중 하나 이상을 포함할 수 있다. 일 실시형태에서, 상기 방법은 다음과 같은 단 계를 더 포함할 수 있다. 단계(S601)에서, 디코딩 전략에 따라 순환 디코딩된 프레임워크 계산 그래프를 생성한다. 단계(S602)에서, 상기 순환 디코딩된 프레임워크 계산 그래프에 변환 디코더 연산자를 삽입한다. 단계(S603)에서, 자연어 생성 모델 계산 그래프를 도출한다. 예컨대, 먼저 디코딩 전략에 따라 순환 디코딩된 프레임워크 계산 그래프(디코딩 프레임워크 계산 그래프로 약 칭)를 생성한다. 당해 디코딩 프레임워크 계산 그래프는 주로 루프 흐름도를 포함한다. 다음, 디코딩 프레임워 크 계산 그래프에 디코더의 계산 구조를 보완한다. 예컨대, 디코더의 계산 구조는 변환 디코더 연산자에 의해 디코더 코드 특징을 식별하여 얻은 생성 네트워크 구조를 포함할 수 있다. 본 발명의 실시예에서 변환 디코더 연산자를 디코딩 프레임워크 계산 그래프에 삽입함으로써 자연어 생성 모델 계산 그래프를 빠르게 도출할 수 있고, 후속 배치 난이도를 감소하고 배치 속도를 향상시는데 유리하다. 일 실시형태에서, 상기 방법은 자연어 이해 모델 계산 그래프와 자연어 생성 모델 계산 그래프를 통합하여 얻은 계산 그래프를 포함하는 자연어 처리 통합 계산 그래프를 도출하는 단계를 더 포함한다. 여기서 상기 자연어 이 해 모델 계산 그래프는 텍스트 처리 가속 연산자와 변환 인코더 연산자를 포함하고, 상기 자연어 생성 모델 계 산 그래프는 변환 디코더 연산자와 디코딩 전략 연산자를 포함한다. 여기서 통합된 계산 그래프는 자연어 이해 모델 계산 그래프의 연산자와 자연어 생성 모델 계산 그래프의 연산자를 포함할 수 있다. 본 발명의 실시예에서 통합된 계산 그래프를 도출함으로써 통합 저장이 가능하고, 도출 방식이 간단하며, 도출 된 계산 그래프가 풍부한 자연어 이해 및 생성 기능을 지원할 수 있다. 일 실시형태에서, 상기 방법은 자연어 이해 모델 계산 그래프, 자연어 생성 모델 계산 그래프 및 통합된 계산 그래프 중 적어도 하나를 복수의 디바이스의 딥 러닝 프레임워크에 도입하는 단계를 더 포함할 수 있다. 이와 같이, 한번의 도출이 가능하고 다중 배치가 가능하여, 복수의 디바이스의 트레이닝-푸시 일체화 통합 배치의 필 요성을 충족시킬 수 있다. 도 7은 본 발명의 일 실시예에 따른 텍스트 처리 장치의 구조 사시도이다. 상기 장치는 텍스트 처리 가속 연산 자를 이용하여 제1 텍스트에 대해 텍스트 처리를 수행하는 텍스트 처리 모듈; 및 상기 텍스트 처리 가속 연산자를 이용하여 텍스트 처리된 콘텐츠를 병행으로 가속하는 병행 가속 모듈을 포함할 수 있다. 본 발명의 일 실시예에 따르면, 텍스트 처리 가속 연산자에 의해 텍스트 처리 및 가속을 수행함으로써 텍스트 처리 속도를 향상시킬 수 있다. 도 8은 본 발명의 다른 실시예에 따른 텍스트 처리 장치의 구조 사시도이다. 본 실시예의 텍스트 처리 장치는 상술한 장치의 실시예 중 하나 이상의 특징들을 포함할 수 있다. 일 실시형태에서, 상기 텍스트 처리 모듈(70 1)은 상기 제1 텍스트에 대응되는 제1 텐서를 획득하는 제1 텐서 서브 모듈; 상기 제1 텐서를 분할하여 복 수의 분할 결과를 얻는 분할 서브 모듈; 상기 분할 결과에 대하여 각각 식별자 매핑을 수행하는 매핑 서브 모듈; 및 매핑 결과를 이용하여 제2 텐서를 생성하는 제2 텐서 서브 모듈를 포함한다. 일 실시형태에서, 상기 분할 서브 모듈은 구체적으로 상기 제1텐서에 대해 글자 분할 처리를 수행하여 복 수의 글자를 얻는 단계; 및 상기 제1텐서에 대해 단어 분할 처리를 수행하여 복수의 단어를 얻는 단계 중 적어 도 하나를 수행할 수 있다. 일 실시형태에서, 상기 매핑 서브 모듈은 구체적으로 매핑 관계에 따라 각 분할된 글자 및/또는 단어를 수 치로 매핑하도록 구성된다. 일 실시형태에서, 상기 제2 텐서 서브 모듈은 구체적으로 상기 제1 텐서의 각 행 문자열의 매핑 결과에 기 반하여 상기 제2 텐서의 각 행 수치를 구하도록 구성되고, 상기 제1 텐서는 N행 문자열을 포함하고, 상기 제2 텐서는 상기 N행 문자열에 대응되는 N행 수치를 포함하되, N은 양의 정수이다. 일 실시형태에서, 상기 제1 텍스트는 문자열을 포함하고, 상기 제1 텐서는 문자열 텐서이고, 상기 제2 텐서는 정수 텐서이며, 상기 제2 텐서의 각 행 수치와 상기 제1 텐서의 각 행 문자열은 대응 관계를 갖는다. 일 실시형태에서, 상기 병행 가속 모듈은 구체적으로 멀티 스레드를 이용하여 상기 제2 텐서를 병행으로 처리한다. 일 실시형태에서, 상기 텍스트 처리 모듈은 텍스트 처리를 수행하여 제1 언어 실행에서 제2 언어 실행으로 변환한다. 도 9는 본 발명의 다른 실시예에 따른 텍스트 처리 장치의 구조 사시도이다. 본 실시예의 텍스트 처리 장치는 상술한 장치의 실시예들 중 하나 이상의 특징들을 포함할 수 있다. 일 실시형태에서, 상기 장치는 상기 텍스트 처리 가속 연산자에 의해 가속된 콘텐츠를 자연어 이해 모델을 이용하여 자연어 이해 처리하는 자연어 이해 모 듈을 더 포함할 수 있다. 일 실시형태에서, 상기 자연어 이해 모델은 상기 텍스트 처리 가속 연산자 및 변환 인코더 연산자를 포함한다. 일 실시형태에서, 상기 변환 인코더 연산자는 융합된 어텐션 메커니즘 연산자와 융합된 피드포워드 연산자를 포 함한다. 일 실시형태에서, 상기 장치는 상기 자연어 이해 모델에 의해 처리된 콘텐츠를 자연어 생성 모델을 이용하여 자 연어 생성 처리하는 자연어 생성 모듈을 더 포함한다. 일 실시형태에서, 상기 자연어 생성 모델은 변환 디코더 연산자 및 디코딩 전략 연산자를 포함한다. 일 실시형태에서, 자연어 생성 모듈은 상기 변환 디코더 연산자를 이용하여 디코더 코드 특징을 식별함으 로써 사용되는 생성 네트워크 타입을 식별하고, 상기 생성 네트워크 타입에 대응되는 사전에 설정된 디코딩 연 산자를 호출하는 변환 디코딩 서브 모듈을 포함한다. 일 실시형태에서, 상기 생성 네트워크 타입은, 디코더(Decoder) 타입； 접두사 언어 모델링(Prefix LM) 타입; 및 인코더-디코더(Encoder-Decoder) 타입 중 적어도 하나를 포함할 수 있다. 일 실시형태에서, 자연어 생성 모듈은 상기 디코딩 전략 연산자를 이용하여 디코딩 전략 특징을 식별함으 로써 사용하는 디코딩 알고리즘을 식별하고, 상기 디코딩 알고리즘을 이용하여, 제1 언어에서 실행되는 루프 코 드를 제2 언어의 코드로 자동 번역하는 디코딩 전략 서브 모듈을 포함한다. 일 실시형태에서, 상기 디코딩 알고리즘은, 검색 기반 디코딩 알고리즘; 및 샘플링 기반 디코딩 알고리즘 중 적 어도 하나를 포함할 수 있다. 일 실시형태에서, 자연어 생성 모듈은 딥 러닝 프레임워크의 JIT 컴파일 기능을 호출하여 상기 제2 언어의 코드를 컴파일하여 동적 링크 라이브러리를 획득하고, 상기 동적 링크 라이브러리와 상기 딥 러닝 프레임워크를 링크시키는 컴파일 서브 모듈을 더 포함한다. 일 실시형태에서, 상기 제1 언어는 해석형 언어이고, 상기 제2 언어는 컴파일러형 언어이다. 도 10은 본 발명의 다른 실시예에 따른 텍스트 처리 장치의 구조 사시도이다. 본 실시예의 텍스트 처리 장치는 상술한 장치의 실시예들 중 하나 이상의 특징들을 포함할 수 있다. 일 실시형태에서, 상기 장치는 텍스트 처리 가속 연산자의 단어 테이블을 도출하는 제1 도출 모듈을 더 포함한다. 일 실시형태에서, 상기 장치는 도출된 단어 테이블을 바이너리 직렬화 방식으로 저장하는 동작; 및 도출된 단어 테이블을 압축 알고리즘으로 압축 저장하는 동작 중 적어도 하나를 수행하는 저장 모듈을 더 포함한다. 일 실시형태에서, 상기 장치는 상기 텍스트 처리 가속 연산자와 변환 인코더 연산자를 하나의 연산자로 통합하 여 자연어 이해 모델 계산 그래프를 도출하는 제2 도출 모듈을 더 포함한다. 일 실시형태에서, 상기 장치는 디코딩 전략에 따라 순환 디코딩된 프레임워크 계산 그래프를 생성하고, 상기 순 환 디코딩된 프레임워크 계산 그래프에 변환 디코더 연산자를 삽입하여 자연어 생성 모델 계산 그래프를 도출하 는 제3 도출 모듈을 더 포함한다. 일 실시형태에서, 상기 장치는 자연어 이해 모델 계산 그래프와 자연어 생성 모델 계산 그래프를 통합하여 얻은 계산 그래프를 포함하는 자연어 처리 통합 계산 그래프를 도출하는 제4 도출 모듈을 더 포함한다. 여기서, 상기 자연어 이해 모델 계산 그래프는 텍스트 처리 가속 연산자와 변환 인코더 연산자를 포함하고, 상 기 자연어 생성 모델 계산 그래프는 변환 디코더 연산자와 디코딩 전략 연산자를 포함한다. 일 실시형태에서, 상기 장치는 자연어 이해 모델 계산 그래프, 자연어 생성 모델 계산 그래프 및 통합된 계산 그래프 중 적어도 하나를 복수의 디바이스의 딥 러닝 프레임워크에 도입하는 배치 모듈을 더 포함한다. 본 발명의 실시예에 따른 텍스트 처리 장치의 각 모듈의 구체적인 기능 및 예시는 상술한 텍스트 처리 방법의 실시예에 대한 설명을 참조할 수 있으며, 이에 대한 설명을 생략한다. 도 11은 본 발명의 일 실시예에 따른 딥 러닝 프레임워크 기반 시스템의 구조 사시도이다. 상기 시스템은 제1 텍스트에 대해 텍스트 처리를 수행하고, 텍스트 처리된 콘텐츠에 대해 병행 가속을 수행하는 텍스트 처리 가속 연산자를 포함할 수 있다. 본 발명의 일 실시예에 있어서, 텍스트 처리 가속 연산자에 의해 텍스트 처리 및 가속을 수행함으로써 딥 러닝 프레임워크 기반 시스템의 텍스트 처리 속도를 향상시킬 수 있다. 도 12는 본 발명의 다른 실시예에 따른 딥 러닝 프레임워크 기반 시스템의 구조 사시도이다. 본 실시예에 따른 딥 러닝 프레임워크 기반 시스템은 상술한 시스템의 실시예들 중 하나 이상의 특징들을 포함할 수 있다. 일 실 시형태에서, 텍스트 처리 가속 연산자는, 상기 제1 텍스트에 대응되는 제1 텐서를 획득하는 제1 텐서 연 산자; 상기 제1 텐서를 분할하여 복수의 분할 결과를 얻는 분할 연산자; 상기 분할 결과에 대하여각각 식별자 매핑을 수행하는 매핑 연산자; 및 매핑 결과를 이용하여 제2 텐서를 생성하는 제2 텐서 연산 자를 포함한다. 일 실시형태에서, 분할 연산자는 구체적으로 상기 제1 텐서에 대해 글자 분할 처리를 수행하여 복수의 글 자를 얻는 동작; 및 상기 제1 텐서에 대해 단어 분할 처리를 수행하여 복수의 단어를 얻는 동작 중 적어도 하나 를 수행할 수 있다. 일 실시형태에서, 매핑 연산자는 구체적으로 매핑 관계에 따라 각 분할된 글자 및/또는 단어를 수치로 매 핑한다. 일 실시형태에서, 제2 텐서 연산자는 구체적으로 상기 제1 텐서의 각 행 문자열의 매핑 결과에 기반하여 상기 제2 텐서의 각 행 수치를 구하도록 구성되고, 상기 제1 텐서는 N행 문자열을 포함하고, 상기 제2 텐서는 상기 N행 문자열에 대응되는 N행 수치를 포함하되, N은 양의 정수이다. 일 실시형태에서, 상기 제1 텍스트는 문자열을 포함하고, 상기 제1 텐서는 문자열 텐서이고, 상기 제2 텐서는 정수 텐서이며, 상기 제2 텐서의 각 행 수치와 상기 제1 텐서의 각 행 문자열은 대응 관계를 갖는다. 일 실시형태에서, 텍스트 처리 가속 연산자는 멀티 스레드를 이용하여 상기 제2 텐서를 병행으로 처리하 는 멀티 스레드 병행 가속 연산자를 더 포함한다. 일 실시형태에서, 상기 제1 텐서 연산자, 분할 연산자, 매핑 연산자 및 제2 텐서 연산자는 제1 언어를 실행하여 수행되는 연산자이고, 상기 멀티 스레드 병행 가속 연산자는 제2 언어를 실행하여 수행되는 연산자이다. 도 13은 본 발명의 다른 실시예에 따른 딥 러닝 프레임워크 기반 시스템의 구조 사시도이다. 본 실시예에 따른 딥 러닝 프레임워크 기반 시스템은 상술한 시스템의 실시예들 중 하나 이상의 특징들을 포함할 수 있다. 일 실 시형태에서, 상기 시스템은 상기 장치는 상기 텍스트 처리 가속 연산자에 의해 가속된 콘텐츠를 자연어 이해 처 리하는 자연어 이해 모델을 더 포함한다. 일 실시형태에서, 자연어 이해 모델은 텍스트 처리 가속 연산자및 변환 인코더 연산자를 포 함한다. 일 실시형태에서, 변환 인코더 연산자는 융합된 어텐션 메커니즘 연산자와 융합된 피드포워드 연산자를 포함한다. 일 실시형태에서, 상기 시스템은 상기 자연어 이해 모델에 의해 처리된 콘텐츠를 자연어 생성 처리하는 자연어 생성 모델을 더 포함한다. 일 실시형태에서, 자연어 생성 모델은 변환 디코더 연산자및 디코딩 전략 연산자를 포함한 다. 일 실시형태에서, 변환 디코더 연산자는 디코더 코드 특징을 식별하여, 사용된 생성 네트워크 타입을 식 별하고, 상기 생성 네트워크 타입에 대응되는 사전에 설정된 디코딩 연산자를 호출하도록 사용된다. 일 실시형태에서, 상기 생성 네트워크 타입은, 디코더(Decoder) 타입； 접두사 언어 모델링(Prefix LM) 타입; 및 인코더-디코더(Encoder-Decoder) 타입 중 적어도 하나를 포함할 수 있다. 일 실시형태에서, 디코딩 전략 연산자는 디코딩 전략 특징을 식별함으로써 사용하는 디코딩 알고리즘을 식별하고, 상기 디코딩 알고리즘을 이용하여, 제1 언어에서 실행되는 루프 코드를 제2 언어의 코드로 자동 번역 하도록 사용된다. 일 실시형태에서, 상기 디코딩 알고리즘은, 검색 기반 디코딩 알고리즘; 및 샘플링 기반 디코딩 알고리즘 중 적 어도 하나를 포함할 수 있다. 일 실시형태에서, 당해 자연어 생성 모델은 딥 러닝 프레임워크의 JIT 컴파일 기능을 호출하여 상기 제2 언어의 코드를 컴파일하여 동적 링크 라이브러리를 획득하고, 상기 동적 링크 라이브러리와 상기 딥 러닝 프레임워크를 링크시키는 컴파일 연산자를 더 포함한다. 일 실시형태에서, 상기 제1 언어는 해석형 언어이고, 상기 제2 언어는 컴파일러형 언어이다. 도 14는 본 발명의 다른 실시예에 따른 딥 러닝 프레임워크 기반 시스템의 구조 사시도이다. 본 실시예에 따른 딥 러닝 프레임워크 기반 시스템은 상술한 시스템의 실시예들 중 하나 이상의 특징들을 포함할 수 있다. 일 실시형태에서, 상기 시스템은 상기 텍스트 처리 가속 연산자의 단어 테이블을 도출하는 제1 도출 모듈을 더 포함할 수 있다. 일 실시형태에서, 상기 시스템은 도출된 단어 테이블을 바이너리 직렬화 방식으로 저장하는 동작; 및 도출된 단 어 테이블을 압축 알고리즘으로 압축 저장하는 동작 중 적어도 하나를 수행하는 저장 모듈을 더 포함한다. 일 실시형태에서, 상기 시스템은 상기 텍스트 처리 가속 연산자와 변환 인코더 연산자를 하나의 연산자로 통합 하여 자연어 이해 모델 계산 그래프를 도출하는 제2 도출 모듈을 더 포함한다. 일 실시형태에서, 상기 시스템은 디코딩 전략에 따라 순환 디코딩된 프레임워크 계산 그래프를 생성하고, 상기 순환 디코딩된 프레임워크 계산 그래프에 변환 디코더 연산자를 삽입하여 자연어 생성 모델 계산 그래프를 도출 하는 제3 도출 모듈을 더 포함한다. 일 실시형태에서, 상기 시스템은 자연어 이해 모델 계산 그래프와 자연어 생성 모델 계산 그래프를 통합하여 얻 은 계산 그래프를 포함하는 자연어 처리 통합 계산 그래프를 도출하는 제4 도출 모듈을 더 포함한다. 여기서, 상기 자연어 이해 모델 계산 그래프는 텍스트 처리 가속 연산자와 변환 인코더 연산자를 포함하고, 상 기 자연어 생성 모델 계산 그래프는 변환 디코더 연산자와 디코딩 전략 연산자를 포함한다. 일 실시형태에서, 상기 시스템은 자연어 이해 모델 계산 그래프, 자연어 생성 모델 계산 그래프 및 통합된 계산 그래프 중 적어도 하나를 복수의 디바이스의 딥 러닝 프레임워크에 도입하는 배치 모듈을 더 포함한다. 본 발명의 일 실시예에 따른 딥 러닝 프레임워크 기반 시스템의 각 연산자 및/또는 모듈의 구체적인 기능 및 예 시는 상술한 텍스트 처리 방법의 실시예들에 대한 설명을 참조할 수 있으므로 여기서는 그 상세한 설명을 생략 한다. 현재 딥 러닝 프레임워크는 프리-트레이닝 모델의 NLP 시나리오에 대한 적용을 해결하는 경우, 트레이닝 및 추 론 성능에 여전히 최적화할 공간이 크게 존재하며, 트레이닝 및 배치 시 개발 경험이 불균일하여, 실제 산업 시 나리오에서 실현 및 배치 비용도 증가된다. PyTorch와 같은 딥 러닝 프레임워크는 프레임워크 외부에서 해석형 언어(예컨대 Python)를 사용하여 처리를 수 행하며, 딥 러닝 프레임워크가 딥 러닝 모델, 예컨대 DNN(Deep Neural Networks) 모델, 변환(Transformer) 모 델, ERNIE 모델, BERT(Bi-Directional Encoder Representation From Transformers)부분의 고성능 계산에 초점 을 맞추도록 한다. 하지만, 인터넷 회사와 같은 산업 분야의 시나리오에서 최고의 성능과 코스트를 추구하고, 모델이 라인 배치 시 C++와 같은 컴파일러형 언어를 사용하여 모델에 대해 엔드-투-엔드의 개발이 이루어져야 한다. 이때 C++ 측을 시용하여 텍스트 처리 부분의 로직을 구현해야 한다. 그러나 딥 러닝 프레임워크가 (DNN/Transformer/BERT/ERNIE)와 같은 프리-트레이닝 모델에 대해서만 C++ 추론을 수행하는 경우, 개발자는 Python의 복잡한 텍스트 처리 로직에 대해 C++ 버전 세트를 다시 작성하고, 정렬과 테스트를 엄격히 수행해야 된다. 한편, 모델과 응용 시나리오의 이전에 따라 텍스트 처리의 프로세스가 크게 달라질 수 있다(예컨대, 텍스 트 분류에서 기계 번역으로 이전되는 경우, 두 세트의 텍스트 처리 로직이 완전히 상이함). 이러한 경우 개발 코스트가 매우 높고, 코딩 등 세부 문제가 쉽게 발생하여 라인 배치 효과에 착오가 발생되거나 정렬되지 않는다. 예컨대, BERT 모델 트레이닝 및 추론된 텍스트 처리 모듈을 참조하면, 순수한 Python 버전 처리를 사용 하고, C++ 버전이 없고, TensorFlow 프레임워크와 분리되어 있다. 일부 프레임워크는 텍스트 처리(Tokenizer 부분) 구현의 로직이 복잡하고 개발 코스트가 높아서 대부분 해석형 언어(예컨대 Python)를 사용하여 구현되므로 구현 성능이 모두 상대적으로 낮다. 또한 해석형 언어에 의존하여 멀티 스레드 병행 가속이 어렵다. 이를 위해, 본 발명의 실시예는 프리-트레이닝 모델에 대한 텍스트 처리 연산 자를 프레임워크 내에 제공할 수 있고, 컴파일러형 언어를 이용하여 멀티 스레드 병행 가속을 구현할 수 있는 텍스트 처리 자동 연산자의 프로세스를 제안한다. 자연어 생성 모델은 디코딩 전략의 복잡성으로 인하여 대부분의 프레임워크들이 디코딩된 루프를 모두 해석형 언어로 수행하므로, 많은 프레임워크 스케줄링 오버헤드가 발생하여 GPU 이용률이 낮고 텍스트 생성 속도가 느 리다. 이를 위해, 본 발명의 실시예는 네트워크 식별 자동 생성, 디코딩 전략 식별, 컴파일러형 코드 생성, JIT 컴파일 등의 가속 프로세스를 제안한다. 다른 프레임워크 NLP의 산업수준 배치 프로세스는 복잡하고 비용이 많이 든다. 이를 위해, 본 발명의 실시예는 NLP 모델의 도출 배치를 위해 텍스트 처리 연산자와 계산 그래프를 융합하여 도출할 수 있으며, 텍스트 처리,자연어 이해와 계산 그래프 생성의 통합 도출을 포함하는 프로세스를 제안하여 배치 비용을 절감한다. 본 발명의 일 실시예는 바이두 패들 딥 러닝 프레임워크과 같은 딥 러닝 프레임워크에 의존하는 방법 및 시스템 을 제공하여, 자연어 이해 및 생성 두 주요 응용 시나리오의 일련의 효율적인 개발, 트레이닝 및 추론을 만족시 킬 수 있다. 본 발명 실시예의 방안은 텍스트 분류, 서열 태그, 기계 번역, 텍스트 생성, 독해, 일반 대화 등 다양한 자연어 처리 산업화 시나리오에 폭넓게 적용될 수 있다. 본 발명의 실시예는 딥 러닝 프레임워크 상에서 자연어 처리의 적용 특성을 고려하여, 엔드 투 엔드 텍스트 처 리 연산자, 자연어 이해 모델 및 생성 모델의 연합 가속 및 트레이닝 통합 배치 방안 중 적어도 하나를 포함하 는 하기와 같은 적용 프로세스를 제안한다. 1. 딥 러닝용 프레임워크 엔드 투 엔드 텍스트 처리 연산화 프로세스 딥 러닝 프레임워크가 전체적으로 텐서(Tensor) 가속을 이용 가능한 특징을 고려하여, 원본 텍스트(Raw Text)타 입에 대한 한 세트의 텐서 표현을 제공한다. 이와 같은 방식은 문자열 텐서의 협의에 의해 컴파일러 기술의 코 드 생성(Code Gen) 원리와 결합하여, 해석형 언어(예컨대, Python)상에서 구현되는 저성능 프로세스를 자동으로 융합하고 대응되는 고성능 C++ 코드를 자동으로 생성할 수 있다. MKLDNN과 같은 CPU의 고성능 가속 라이브러리 의 자동 병행화를 통해 기존의 해석형(예컨대, Python) 코드에 비해 약 100배 이상 빠른 속도를 구현할 수 있다. 예시적으로, 상술한 저성능 프로세스는 기본 단어 분할 모듈, 식별자Identifier，ID） 매핑 모듈 등 정밀 도 모듈의 기능과 같은 복수의 복잡한 텍스트 처리 프로세스를 포함할 수 있다. 도 15에 도시된 바와 같이, 딥 러닝용 프레임워크 엔드 투 엔드 텍스트 처리 연산화 프로세스는 텍스트 처리를 자동으로 연산자화하여 멀티 스레드에 의해 병행으로 가속시킨다. 예컨대, 텍스트 처리 자동 연산자화에서, 먼 저 문자열 텐서 연산자는 원본 문자열 텍스트(String Text)를 문자열 텐서(String Tensor)로 변환하고, 분할 연 산자는 기본 글자 분할 모듈을 이용하여 문자열 텐서에 대해 글자 분할 처리를 수행한다. 다음, 매핑 연산자는 각 글자 분할 결과에 대하여 각각 ID 매핑을 수행하여 각 글자 분할 결과에 대응되는 정수 수치를 구하고, 이에 따라 정수 텐서 연산자는 원본 문자열에 대응되는 정상 수치를 이용하여 정수 텐서 양(Integer Tensor)을 구한 다. 멀티 스레드를 이용하여 정수 텐서에 대해 병행 처리을 수행할 수 있다. 텍스트 처리 자동 연산자화 프로세 스는, 예컨대 가속 토크나이저 연산자(Faster Tokenizer Operator)를 통해 상술한 텍스트 처리와 병행 가속을 구현할 수 있으며, 해석형 언어 실행시 구현되는 기본 텍스트 처리 기능을 컴파일러형 언어 실행시 구현되도록 변환하며, 컴파일러형 언어가 멀티 스레드 병행 처리 가능한 특징을 이용하여 텍스트 처리 속도를 크게 향상시 킬 수 있다. 가속 토크나이저 연산자는 가속 버전 토큰화 연산자, 가속 버전 토크나이저, 토크나이저 등으로 지 칭될 수 있다. 2. 자연어 이해 및 생성 태스크 자동화 가속 프로세스 자연어 이해 모델의 종류로는 주로 변환 모델 기반 인코더(Transformer Encoder)타입이 있다. 도 16에 도시된 바와 같이, 예시적인 변환（Transformer） 인코더의 구조 사시도이다. 당해 Transformer 인코더 는 Add & Norm, 피드포워드(Feed Forward)를 포함할 수 있다. 예컨대, 자연어 생성 모델의 종류는 인코더 타입에 따라 다음과 같은 타입을 포함할 수 있다. 순수 디코더(Decoder)타입은은 도 17a에 도시된 바와 같이, 순수 Decoder 타입의 자연어 생성 모델은 변환 (Transformer) 계층, 디코더(Decoder) 계층 및 Transformer 계층을 포함할 수 있다. 순수 Decoder 타입의 대표 모델 구조는 예컨대 GPT(Generator Pre-Training) 모델이다. 접두사 언어 모델링(Prefix Language Model， Prefix LM) 타입은 도 17b에 도시된 바와 같이 순수 Prefix LM 타입의 자연어 생성 모델은 Transformer 계층, Prefix LM 계층 및 Transformer 계층을 포함할 수 있다. Prefix LM 타입의 대표 모델로는 UniLM 모델(Unified Language Model), PLATO 모델 등이 있다. 인커더-디코더(Encoder-Decoder) 타입은 도 17c에 도시된 바와 같이, Encoder-Decoder 타입의 자연어 생성 모 델은 Transformer 계층, Decoder 계층, Transformer 계층, Encoder-Decoder 계층, Transformer 계층, Encoder 계층, 인코더(Encoder) 계층 및 Transformer 계층을 포함할 수 있다. Encoder-Decoder 타입의 대표 모델로는 BART(Bidirectional and Auto-Regressive Transformers, 양방향 및 자동 회귀 변환) 모델이 있다. 예컨대, 생성된 디코딩 전략은 다음과 같은 타입을 포함할 수 있다. 검색 기반 디코딩 알고리즘은 빔 서치(Beam Search), 그리디 서치(Greedy Search), 다양한 셀 검색(Diverse Sibling Search) 등이 있다. 도 18a에 도시된 바와 같이, 빔 서치의 일 예시가 도시된다. 먼저 인코더-디코더에 의해 입력되는 문법 문장이 주어지고, 첫번째 단어의 최대 가능한 확률값을 출력하고, 예컨대 단어 1 투 단어 2 의 확률은 0.4, 단어 1 투 단어 3의 확률은 0.5, 단어 1 투 단어 4의 확률값은 0.1이다. 그리고, 선택된 첫 번 째 가능한 단어별로 두번째 단어가 무엇인지를 고려한다. 예컨대, 단어 2 투 단어 5의 확률은 0.05, 단어 2 투 단어 6의 확률은 0.05, 단어 2 투 단어 7의 확률은 0.9, 단어 3 투 단어 8의 확률은 0.4, 단어 3 투 단어 9의 확률은 0.4, 단어 3 투 단어 20의 확률은 0.3, 단어 4 투 단어 11의 확률은 0.3, 단어 4 투 단어 12의 확률은 0.5, 단어 4 투 단어 13의 확률은 0.2이다. 샘플링 기반 디코딩 모듈은 예컨대 상위 K개의 샘플링(Top-K Sampling), 핵 샘플링(Top-P Sampling) 등이 있다. 도 18b에 도시된 바와 같이 샘플링 검색의 일 예시가 도시된다. 본 발명의 일 실시예에서, 자연어 이해 모델(이해 모듈로 약칭)과 자연어 생성 모델(생성 모듈로 약칭)을 겸비 하여 통합 가속하는 프로세스를 제공한다. 도 19에 도시된 바와 같이 당해 프로세스는 다음과 같은 부분을 포함 할 수 있다. 1. 이해 모델 Transformer 인코더의 가속 최적화에 대해, 도 19에 도시된 바와 같이 다음과 같은 단계를 포함할 수 있다. 단계(S11)에서, 프레임워크는 문자열(String Text)과 같은 원본 텍스트 입력에 대하여 자동으로 가속 버전 토큰 화 연산자(Faster Tokenizer Operator)를 삽입하여 원본 텍스트에 대해 고성능 처리를 수행할 수 있다. 단계(S12)에서, 다계층 Transformer 인코더를 호출하여 문자열 인코딩을 수행한다. 예컨대, 이해 모델 중 인코더 최적화를 위해, 어텐션 메커니즘 융합과 피드포워드 융합을 포함할 수 있다. 인코딩 과정에서 프레임워크 스케줄링 오버헤드를 줄이기 위하여 멀티 헤드 어텐션 메커니즘에 대하여 융합 최적화를 수행할 수 있다. 예컨대, 연산자 수를 1/3로 줄일 수 있으며, 도 20a, 도 20b 및 도 20c에 도시된 바 와 같이, 멀티 헤드 어텐션 메커니즘 중 GEMM, 편향 추가(bias add), 전치(transpose) 등을 3에서 1로 줄이고, 데이터 재사용율을 높여 융합된 어텐션 메커니즘(Fused Attention) 연산자를 얻을 수 있다. Feedforward 계층에 대해 융합 최적화를 수행한다. 예컨대, 도 20c에 도시된 바와 같이, 종래 3개 GPU의 커 널(Kernel) 연산자를 1개로 융합시키고, 예컨대, 융합된 커널 연산자에 Fused Dropout Act Bias, Fused Ln Add Dropout Bias, Fused Add Dropout Bias 등이 포함될 수 있으며, 융합된 피드포워드(Fused Feedforward) 연산자 를 얻을 수 있다. 액세스 동작 오버헤드를 예컨대 8 load/store에서 4load/store로 현저하게 줄일 수 있다. 2. 생성 모델 중 Transformer 디코더의 가속 최적화에 대해 도 20a, 20b 및 20c를 참조할 수도 있다. 예컨대, 당해 가속 최적화 과정은 다음과 같은 단계를 포함할 수 있다. 단계(S21)에서 생성 네트워크 타입을 식별하여 임계값 디코딩 연산자를 호출한다. 구체적으로, 다계층 Transformer 디코더 연산자는 사용자 디코더 코드 특징을 식별하여 생성 네트워크 타입을 분류한다. 예컨대, 도 17a, 도 17b 및 도 17c에 도시된 타입에 따라 사용자 디코더 코드 특징이 3가지 타입의 생성 네트워크 중 어느 하나로 식별될 수 있다. 다음, 식별된 생성 네트워크에 대응되는 미리 설정된 고성능 디코딩 연산자들을 자동으 로 호출하여 계산을 수행할 수 있다. 단계(S22)에서 디코딩 전략을 식별하여 컴파일러형 언어를 자동으로 생성한다. 구체적으로, 디코딩 전략 연산자 는 사용자 디코딩 전략의 특징을 식별하여 사용자 디코딩 전략이 검색 기반 알고리즘인지 샘플링 기반 알고리즘 인지를 결정할 수 있다. 검색 기반 알고리즘과 샘플링 기반 알고리즘의 차이에 대하여, 해석형 언어 상의 루프 코드를 컴파일러형 언어의 코드로 자동 번역하여 성능을 향상시킬 수 있다. 단계(S23)에서, 프레임워크가 자동으로 JIT 컴파일되고, 연산자가 자동으로 생성되어 링크된다. 예컨대, 패들 프레임워크와 같은 딥 러닝 프레임워크의 JIT 컴파일(Just In-time Compiler) 기능을 호출하여 동적 링크 라이 브러리를 빠르게 획득하고, 링크시켜 고성능의 디코더 연산자들을 얻는다. 프로세스는 텍스트 생성이 완료될 때까지 순환적으로 N 회 수행될 수 있다. 3. 이해 및 생성 모델의 트레이닝-푸시 일체형 통합 배치 방안 프로세스에 대해 다음과 같은 부분을 포함할 수 있다. 제1 부분은 이해 모델의 도출로서 하기와 같은 단계를 포함할 수 있다. 단계(S1.1)에서 먼저 토크나이저 중 단 어 테이블을 도출해야 하며, 바이너리 직렬화 방식으로 저장된다. 단계(S1.2)(선택 사항)에서, 단어 테이블 텍 스트의 특성에 대해 일련의 압축 알고리즘을 사용하여 단어 테이블 파일의 저장을 줄일 수도 있다. 다음, 단계 (S1.3)에서 토크나이저와 다중 계층 Transformer 인코더를 하나의 연산자로 결합하여 전체적 이해 모델 계산 그 래프로 도출한다. 제2 부분은 생성 모델의 도출로서 하기와 같은 단계를 포함할 수 있다. 단계(S2.1)에서 먼저 디코딩 전략에 따 라 순환 디코딩된 프레임워크 계산 그래프(순환 프레임워크 계산 그래프로 약칭)을 생성한다. 단계(S2.2)에서 다중 계층 Transformer 디코더의 연산자를 디코딩 전략 순환, 즉 순환 프레임워크 계산 그래프에 삽입한다. 단 계(S2.3)에서 생성 모델 계산 그래프를 생성한다. 제3 부분은 서비스의 필요에 따라 계산 그래프 결합을 수행한다. 자연어 이해 모듈 부분만 필요한 경우 이해 모 델 계산 그래프만을 이용한다. 생성 모델 부분의 계산 그래프가 필요한 경우, 이해 모델 계산 그래프와 생성 모 델 계산 그래프를 하나의 계산 그래프로 통합함으로써, 다중 장비의 트레이닝-푸시 일체형 통합 배치의 필요성 을 충족시킬 수 있다. 본 발명의 실시예에 따르면, 자연어 이해 전역 시나리오 응용의 트레이닝 모델 속도, 추론 속도, 배치 코스트를 효과적으로 향상시켜 트레이닝-푸시 일체형 배치 경험을 얻을 수 있다. 도 21a에 도시된 바와 같이, 상이한 프레임워크의 텍스트 처리 성능 비교 도면으로서, 빠른 버전 토크화(본 방 안)을 이용하여 기타 프레임워크의 텍스트 처리 속도를 현저하게 초과할 수 있다. 예컨대, 본 방안은 Paddle Faster Tokenizer 일 수 있다. 비교예 1은 Hugging Face Tokenizers(Rust)이고, 비교예 2는 Hugging Face Tokenizers(Python)이고, 비교예 3은 Tensor Flow Text이다. 본 방안의 모델 포워드 계산은 원본 텍스트의 입력을 지원하고, 텍스트 처리 및 모델 계산은 전체적 맵의 도출 을 지원한다. 본 방안의 트레이닝 속도와 추론 속도는 종래에 비해 200% 이상, 추론 속도는 160% 이상 향상될 수 있으며, 기록은 21b 및 도 21c에 도시된 바와 같다. 동시 배치 코스트는 트레이닝되지 않은 일체형 버전에 비해 코드량을 94% 줄일 수 있다. 예컨대, C++ 배치 코드 는 800 행에서 48행으로 줄어든다. 도 21d를 참조하면, 생성 태스크가 기계 번역인 경우, 본 방안의 생성 및 이해 모델의 융합 최적화 전략을 사용 한 후, 가속도가 PyTorch와 같은 동종 프레임워크의 네이티브 구현에 비해 최고 10배 이상 향상될 수 있다. 본 발명의 실시예는 딥 러닝용 프레임워크를 중심으로 자연어 이해 및 자연어 생성 전역적 응용 시나리오 상의 전체 프로세스 개발 패러다임을 제의함으로써 모델 트레이닝 및 추론 성능을 크게 향상시킬 수 있고, 배치 비용 을 절감할 수 있다. 딥 러닝 텐서화 계산 특성에 의존하여, 해석형 언어의 텍스트 처리 프로세스에 대해 컴파일 러형 언어를 자동으로 생성하고, 병행 가속 기능을 텐서화할 수 있다. 자연어 이해 및 생성 계산 그래프의 연산 자를 유합하여 연합 최적화함으로써, 프레임워크 스케줄링 및 액세스 오버헤드를 줄이고 성능을 크게 향상시킬 수 있다. 텍스트 처리, 자연어 이해, 자연어 생성에 대한 계산 그래프의 연합 도출, 전체 프로세스의 일체화 저 장 및 한번 도출의 형성, 다중 배치와 같은 트레이닝-푸시 일체화 특색 개발 경험은 배치 비용을 절감할 수 있 다. 본 발명의 기술적 해결수단에 있어서, 사용자의 개인정보 획득, 저장 및 활용 등은 모두 관계법령을 준수하며 공서양속에 반하지 않는다. 본 발명의 실시예에 따르면, 본 발명은 전자 기기, 저장 매체 및 판독 가능한 저장 매체 및 컴퓨터 프로그램 제 품을 제공한다. 도 22는 본 발명의 실시예를 구현하는 예시적 전자 기기의 예시적 블록도를 도시한다. 전자 기기는 랩톱 컴퓨터, 데스크톱 컴퓨터, 운영 플랫폼, 개인 정보 단말기, 서버, 블레이드 서버, 대형 컴퓨터, 및 다른 적합한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 의미한다. 전자 기기는 개인 디지털 처리, 셀룰러폰, 스마트폰, 웨어러블 기기 및 다른 유사한 컴퓨팅 장치와 같은 다양한 형태의 이동 장치를 의미할 수도 있다. 본문에서 나 타낸 부재, 이들의 연결과 관계, 및 이들의 기능은 단지 예시적인 것으로, 본문에서 설명 및/또는 요구된 본 발 명의 구현을 한정하지 않는다. 도 22에 도시된 바와 같이, 전자 기기는 읽기 전용 메모리(ROM)에 저장된 컴퓨터 프로그램 또는 저 장 유닛으로부터 랜덤 액세스 메모리(RAM)로 로딩된 컴퓨터 프로그램에 따라 다양하고 적절한 동작 및 처리를 수행할 수 있는 컴퓨팅 유닛을 포함한다. RAM에는 또한 전자 기기의 조작에 필요한 다양한 프로그램 및 데이터가 저장될 수 있다. 컴퓨팅 유닛, ROM 및 RAM은 버스를 통해 서로 연결된다. 입력/출력(I/O) 인터페이스도 버스에 연결된다. 키보드, 마우스와 같은 입력 유닛; 다양한 유형의 디스플레이, 스피커와 같은 출력 유닛; 자기 디 스크, 광 디스크와 같은 저장 유닛; 및 네트워크 카드, 모뎀, 무선 통신 트랜시버와 같은 통신 유닛 을 포함하는 전자 기기 중의 다수의 부재는 I/O 인터페이스에 연결된다. 통신 유닛은 전자 기기가 인터넷과 같은 컴퓨터 네트워크 및/또는 다양한 통신 네트워크를 통해 다른 기기와 정보/데 이터를 교환하도록 허용한다. 컴퓨팅 유닛은 프로세싱 및 컴퓨팅 기능을 갖는 범용 및/또는 전용 프로세싱 컴포넌트일 수 있다. 컴퓨팅 유닛의 일부 예는 중앙 처리 유닛(CPU), 그래픽 처리 유닛(GPU), 다양한 전용 인공 지능(AI) 컴퓨팅 칩, 머신 러닝 모델 알고리즘을 실행하는 다양한 컴퓨팅 유닛, 디지털 신호 프로세서(DSP) 및 임의의 적절한 프로세 서, 컨트롤러, 마이크로 컨트롤러 등을 포함하지만 이에 한정되지 않는다. 컴퓨팅 유닛은 자율 주행 방법 과 같은 상기에 설명된 각 방법과 프로세싱을 수행한다. 예를 들어, 일부 실시예에서 자율 주행 방법은 컴퓨터 소프트웨어 프로그램으로 구현될 수 있고, 이는 저장 유닛과 같은 기계 판독 가능 매체에 유형적으로 포 함된다. 일부 실시예에서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및/또는 통신 유닛을 통해 전 자 기기에 로드 및/또는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되고 컴퓨팅 유닛에 의해 실행될 경우, 상기에 설명된 자율 주행 방법의 하나 이상의 단계를 수행할 수 있다. 대안적으로, 다른 실 시예에서, 컴퓨팅 유닛은 다른 임의의 적절한 방식(예를 들어, 펌웨어에 의해)을 통해 자율 주행 방법을 수행하도록 구성될 수 있다. 본문에서 설명된 시스템 및 기술의 다양한 실시형태는 디지털 전자 회로 시스템, 집적 회로 시스템, 필드 프로 그램 가능 게이트 어레이(FPGA), 전용 집적 회로(ASIC), 전용 표준 제품(ASSP), 시스템 온 칩의 시스템(SOC), 복합 프로그램 가능 논리 소자(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및/또는 이들의 조합에서 구현될 수 있다. 이러한 다양한 실시형태는 하나 이상의 컴퓨터 프로그램에서의 구현을 포함할 수 있고, 상기 하나 이 상의 컴퓨터 프로그램은 적어도 하나의 프로그램 가능 프로세서를 포함하는 프로그램 가능 시스템에서 실행 및/ 또는 해석될 수 있으며, 상기 프로그램 가능 프로세서는 전용 또는 범용 프로그램 가능 프로세서일 수 있고, 저 장 시스템, 적어도 하나의 입력 장치, 및 적어도 하나의 출력 장치로부터 데이터 및 명령을 수신할 수 있으며, 데이터 및 명령을 상기 저장 시스템, 상기 적어도 하나의 입력 장치, 및 상기 적어도 하나의 출력 장치에 전송 할 수 있다. 본 발명의 방법을 구현하는 프로그램 코드는 하나 이상의 프로그래밍 언어의 임의의 조합으로 편집할 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 전용 컴퓨터 또는 다른 프로그램 가능 데이터 처리 장치의 프로세서 또는 컨트롤러에 제공될 수 있으며, 프로그램 코드는 프로세서 또는 컨트롤러에 의해 실행될 경우, 흐름도 및/또는 블록도에 지정된 기능/작동이 구현되도록 할 수 있다. 프로그램 코드는 완전히 기계에서 실행되거나, 부분적으 로 기계에서 실행되거나, 독립형 소프트웨어 패키지로서 기계에서 실행되며, 일부는 원격 기계에서 실행되거나 완전히 원격 기계 또는 서버에서 실행될 수 있다. 본 발명의 컨텍스트에서, 기계 판독 가능 매체는 명령 실행 시스템, 장치 또는 기기에 의해 또는 명령 실행 시 스템, 장치 또는 기기와 조합하여 사용하기 위한 프로그램을 포함하거나 저장할 수 있는 유형 매체일 수 있다. 기계 판독 가능 매체는 기계 판독 가능 신호 매체 또는 기계 판독 가능 저장 매체일 수 있다. 기계 판독 가능 매체는 전자, 자기, 광학, 전자기, 적외선 또는 반도체 시스템, 장치 또는 기기, 또는 상기 내용의 임의의 적절 한 조합을 포함할 수 있지만 이에 한정되지 않는다. 기계 판독 가능 저장 매체의 보다 구체적인 예는 하나 이상 의 와이어에 기반한 전기 연결, 휴대용 컴퓨터 디스크, 하드 디스크, 랜덤 액세스 메모리(RAM), 읽기 전용 메모 리(ROM), 소거 가능 프로그램 가능 읽기 전용 메모리(EPROM 또는 플래시 메모리), 광섬유, CD-ROM, 광학 저장 기기, 자기 저장 기기 또는 상술한 내용의 임의의 적절한 조합을 포함한다. 사용자와의 인터랙션을 제공하기 위하여, 컴퓨터에서 여기서 설명된 시스템 및 기술을 실시할 수 있고, 상기 컴 퓨터는 사용자에게 정보를 표시하기 위한 표시 장치(예를 들어, CRT(음극선관) 또는 LCD(액정 표시 장치) 모니 터); 및 키보드 및 지향 장치(예를 들어, 마우스 또는 트랙 볼)를 구비하며, 사용자는 상기 키보드 및 상기 지 향 장치를 통해 컴퓨터에 입력을 제공한다. 다른 타입의 장치는 또한 사용자와의 인터랙션을 제공할 수 있는데, 예를 들어, 사용자에게 제공된 피드백은 임의의 형태의 감지 피드백(예를 들어, 시각 피드백, 청각 피드백, 또 는 촉각 피드백)일 수 있고; 임의의 형태(소리 입력, 음성 입력, 또는 촉각 입력)로 사용자로부터의 입력을 수 신할 수 있다.여기서 설명된 시스템 및 기술을 백그라운드 부재를 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서버), 또는 미 들웨어 부재를 포함하는 컴퓨팅 시스템(예를 들어, 응용 서버), 또는 프론트 엔드 부재를 포함하는 컴퓨팅 시스 템(예를 들어, 그래픽 사용자 인터페이스 또는 웹 브라우저를 구비하는 사용자 컴퓨터이고, 사용자는 상기 그래 픽 사용자 인터페이스 또는 웹 브라우저를 통해 여기서 설명된 시스템 및 기술의 실시형태와 인터랙션할 수 있 음), 또는 이러한 백그라운드 부재, 미들웨어 부재, 또는 프론트 엔드 부재의 임의의 조합을 포함하는 컴퓨팅 시스템에서 실시할 수 있다. 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워크)을 통해 시스템의 부재를 서로 연결시킬 수 있다. 통신 네트워크의 예시로 근거리 통신망(LAN), 광역 통신망(WAN), 및 인터넷을 포함한다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 고 일반적으로 통신 네트워크를 통해 서로 인터랙션한다. 대응되는 컴퓨터에서 실행되고 또한 서로 클라이언트- 서버 관계를 가지는 컴퓨터 프로그램을 통해 클라이언트 및 서버의 관계를 생성한다. 서버는 클라우드 서버, 분 산 시스템 서버 또는 블록체인이 조합된 서버일 수 있다. 위에서 설명한 다양한 형태의 프로세스를 사용하여 단계를 재배열, 추가 또는 삭제할 수 있음을 이해해야 한다. 예를 들어, 본 발명에 기재된 각 단계는 동시에 수행될 수 있거나 순차적으로 수행될 수 있거나 상이한 순서로 수행될 수 있고, 본 발명에서 공개된 기술적 해결수단이 이루고자 하는 결과를 구현할 수만 있으면, 본문은 여 기서 한정하지 않는다."}
{"patent_id": "10-2022-0095795", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상기 구체적인 실시형태는 본 발명의 보호 범위를 한정하지 않는다. 본 기술분야의 통상의 기술자는 설계 요구 및 다른 요소에 따라 다양한 수정, 조합, 서브 조합 및 대체를 진행할 수 있음을 이해해야 한다. 본 발명의 정 신 및 원칙 내에서 진행한 임의의 수정, 등가적 대체 및 개선 등은 모두 본 발명의 보호 범위 내에 속해야 한다."}
{"patent_id": "10-2022-0095795", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면은 본 방안의 이해를 돕기 위한 것으로서 본 발명을 한정하지 않는다. 도 1은 본 발명의 일 실시예에 따른 텍스트 처리 방법의 흐름 사시도이다. 도 2는 본 발명의 다른 실시예에 따른 텍스트 처리 방법의 흐름 사시도이다.도 3은 본 발명의 다른 실시예에 따른 텍스트 처리 방법의 흐름 사시도이다. 도 4는 본 발명의 다른 실시예에 따른 텍스트 처리 방법의 흐름 사시도이다. 도 5는 본 발명의 다른 실시예에 따른 텍스트 처리 방법의 흐름 사시도이다. 도 6은 본 발명의 다른 실시예에 따른 텍스트 처리 방법의 흐름 사시도이다. 도 7은 본 발명의 일 실시예에 따른 텍스트 처리 장치의 구조 사시도이다. 도 8은 본 발명의 다른 실시예에 따른 텍스트 처리 장치의 구조 사시도이다. 도 9는 본 발명의 다른 실시예에 따른 텍스트 처리 장치의 구조 사시도이다. 도 10은 본 발명의 다른 실시예에 따른 텍스트 처리 장치의 구조 사시도이다. 도 11은 본 발명의 일 실시예에 따른 딥 러닝 프레임워크 기반 시스템의 구조 사시도이다. 도 12는 본 발명의 다른 실시예에 따른 딥 러닝 프레임워크 기반 시스템의 구조 사시도이다. 도 13은 본 발명의 다른 실시예에 따른 딥 러닝 프레임워크 기반 시스템의 구조 사시도이다. 도 14는 본 발명의 다른 실시예에 따른 딥 러닝 프레임워크 기반 시스템의 구조 사시도이다. 도 15는 엔드 투 엔드 텍스트 처리의 연산자화 과정의 사시도이다. 도 16은 예시적인 변환（Transformer） 인코더 연산자의 구조 사시도이다. 도 17a는 디코더 타입의 생성망의 사시도이다. 도 17b는 접두사 언어 모델링 타입의 생성망의 사시도이다. 도 17c는 인코더-디코더 타입의 생성망의 사시도이다. 도 18a는 디코딩 전략이 빔 서치인 경우의 사시도이다. 도 18b는 디코딩 전략이 샘플링 검색인 경우의 사시도이다. 도 19는 딥 러닝 프레임워크의 이해와 생성 모델 연합 최적화의 흐름 사시도이다. 도 20a, 도 20b, 및 도 20c는 변환(Transformer) 인코더 연산자 융합의 흐름 사시도이다. 도 21a는 상이한 프레임워크 텍스트 처리 성능 비교의 예시도이다. 도 21b는 트레이닝 속도 향상의 예시도이다. 도 21c는 추론 속도 향상의 예시도이다. 도 21d는 변환 인코딩 속도 비교의 예시도이다. 도 22는 본 발명의 실시예를 실시하기 위한 예시 전자 기기의 사시적인 블록도이다."}
