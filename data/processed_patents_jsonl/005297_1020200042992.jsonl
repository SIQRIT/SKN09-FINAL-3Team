{"patent_id": "10-2020-0042992", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0125366", "출원번호": "10-2020-0042992", "발명의 명칭": "신경망 분류기를 이용하여 녹음 장치 고장을 탐지하는 방법, 이를 구현한 서버 및 스마트 디", "출원인": "주식회사 케이티", "발명자": "금명철"}}
{"patent_id": "10-2020-0042992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "서버가 스마트 디바이스의 녹음 장치의 고장을 탐지하는 방법으로서, 고장 유형별 학습용 오디오 신호들을 입력 받아, 각 학습용 오디오 신호에 대한 적어도 하나의 스펙트로그램과오디오 정보들을 각각 추출하는 단계,각 학습용 오디오 신호들에 대한 적어도 하나의 스펙트로그램과 오디오 정보들을 해당 고장 유형에 매핑한 학습데이터를 생성하는 단계,상기 학습 데이터를 이용하여 신경망 분류기를 학습시키는 단계, 그리고상기 스마트 디바이스로부터 오디오 신호를 수신하고, 학습된 신경망 분류기를 이용하여 상기 오디오 신호의 고장 유형을 탐지하여 상기 스마트 디바이스로 전달하는 단계를 포함하고, 상기 학습된 신경망 분류기는, 상기 고장 유형별 학습용 오디오 신호들의 스펙트로그램 특징 값을 출력하도록학습된 제1 신경망 모델,상기 고장 유형별 학습용 오디오 신호들의 오디오 정보 특징 값을 출력하도록 학습된 제2 신경망 모델, 그리고상기 제1 신경망 모델 및 제2 신경망 모델에서 출력된 특징 값들을 연결하여, 해당 학습용 오디오 신호의 고장유형이 출력되도록 학습된 분류 모델을 포함하는, 고장 탐지 방법."}
{"patent_id": "10-2020-0042992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 신경망 모델은 합성곱 재귀 신경망(CRNN: Convolutional Recurrent Neural Network) 기반의모델이고, 상기 제2 신경망 모델은 재귀 신경망(RNN: Recurrent Neural Network) 기반의 모델인, 고장 탐지 방법."}
{"patent_id": "10-2020-0042992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서상기 고장 유형은 정상 유형, 순간성 고장 유형, 또는 지속성 고장 유형 중 적어도 하나를 포함하는, 고장 탐지방법."}
{"patent_id": "10-2020-0042992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서상기 스펙트로그램과 오디오 정보들을 각각 추출하는 단계는,각 학습용 오디오 신호에서 복수의 시간 구간 신호들을 추출하는 단계, 그리고각 시간 구간 신호를 주파수 도메인으로 변환하여, 해당 시간 구간 신호의 스펙트로그램과 오디오 정보들을 추출하는 단계를 포함하고,상기 복수의 시간 구간 신호들 각각은 이전 시간 구간 또는 이후 시간 구간과 적어도 일부의 시간 구간이 중복되도록 추출되는, 고장 탐지 방법.공개특허 10-2021-0125366-3-청구항 5 녹음 장치를 포함하는 스마트 디바이스가 상기 녹음 장치의 고장을 탐지하는 방법으로서,녹음 장치에서 수집된 오디오 신호를 입력 받는 단계, 상기 오디오 신호에 대한 적어도 하나의 스펙트로그램과 오디오 정보들을 추출하는 단계, 그리고상기 오디오 신호의 스펙트로그램과 오디오 정보들을, 고장 유형별 학습용 오디오 신호들로 학습된 신경망 모델로 입력하고, 상기 신경망 모델을 통해 상기 오디오 신호의 고장 유형을 탐지하는 단계를 포함하는, 고장 탐지 방법."}
{"patent_id": "10-2020-0042992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 오디오 신호를 입력 받는 단계 이전에,고장 유형별 학습용 오디오 신호들을 입력 받아, 각 학습용 오디오 신호에 대한 적어도 하나의 스펙트로그램과오디오 정보들을 각각 추출하는 단계,각 학습용 오디오 신호들에 대한 적어도 하나의 스펙트로그램과 오디오 정보들을 해당 고장 유형에 매핑한 학습데이터를 생성하는 단계, 그리고상기 학습 데이터를 이용하여 신경망 분류기를 학습시키는 단계를 포함하고,상기 신경망 분류기를 학습시키는 단계는,상기 스펙트로그램이 입력되면 스펙트로그램 특징 값을 출력하도록 상기 신경망 분류기에 포함된 제1 신경망 모델을 학습시키는 단계,상기 오디오 정보들이 입력되면 오디오 정보 특징 값을 출력하도록 상기 신경망 분류기에 포함된 제2 신경망 모델을 학습시키는 단계, 그리고제1 신경망 모델에서 출력된 스펙트로그램 특징 값 및 상기 제2 신경망 모델에서 출력된 오디오 정보 특징 값을연결하여 계산한 확률 값을 기초로 입력 오디오 신호의 고장 유형을 출력하도록 분류 모델을 학습시키는 단계를 더 포함하는, 고장 탐지 방법."}
{"patent_id": "10-2020-0042992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 오디오 신호를 입력 받는 단계 이전에,상기 스마트 디바이스와 연동하는 서버로부터, 상기 서버에서 학습된 신경망 모델을 수신하는 단계를 더 포함하는, 고장 탐지 방법."}
{"patent_id": "10-2020-0042992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서상기 스펙트로그램과 오디오 정보들을 추출하는 단계는,상기 입력 받은 오디오 신호로에서 복수의 시간 구간 신호들을 추출하는 단계, 그리고각 시간 구간 신호를 주파수 도메인으로 변환하여, 해당 시간 구간 신호의 스펙트로그램과 오디오 정보들을 추출하는 단계를 포함하고,상기 복수의 시간 구간 신호들 각각은 이전 시간 구간 또는 이후 시간 구간과 적어도 일부의 시간 구간이 중복공개특허 10-2021-0125366-4-되도록 추출되는, 고장 탐지 방법."}
{"patent_id": "10-2020-0042992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 제1 신경망 모델은 합성곱 재귀 신경망(CRNN: Convolutional Recurrent Neural Network) 기반의모델이고, 상기 제2 신경망 모델은 재귀 신경망(RNN: Recurrent Neural Network) 기반의 모델인, 고장 탐지 방법."}
{"patent_id": "10-2020-0042992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서,상기 분류 모델을 학습시키는 단계는,상기 스펙트로그램 특징 값과 오디오 정보 특징 값을 완전 연결 연산 처리하여 연결 맵을 생성하고, 상기 생성한 연결 맵에 활성화 함수를 적용하여 상기 확률 값으로 계산하는, 고장 탐지 방법."}
{"patent_id": "10-2020-0042992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제5항에 있어서,상기 녹음 장치가 복수 개이면, 상기 고장 유형을 획득하는 단계는,상기 복수의 녹음 장치들 중 제1 녹음 장치가 수집한 제1 오디오 신호의 스펙트로그램과 오디오 정보, 제2 녹음장치가 수집한 제2 오디오 신호의 스펙트로그램과 오디오 정보, 그리고 상기 제1 오디오 신호와 제2 오디오 신호의 차이값을 입력 정보로 추출하는 단계, 그리고상기 입력 정보를, 상기 학습된 신경망 모델로 입력하고, 상기 신경망 모델로부터 상기 제1 오디오 신호와 제2오디오 신호의 고장 유형을 획득하는 단계를 포함하는, 고장 탐지 방법."}
{"patent_id": "10-2020-0042992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 입력 정보로 추출하는 단계는,상기 제1 오디오 신호와 제2 오디오 신호로부터 제1 주파수 도메인 값과 제2 주파수 도메인 값을 생성하는단계,상기 제1 주파수 도메인 값과 제2 주파수 도메인 값의 제1 차이값을 계산하는 단계, 그리고상기 제1 오디오 신호와 제2 오디오 신호를 n 제곱하고, n 제곱된 제1 오디오 신호와 제2 오디오 신호의 각 주파수 도메인 값들로부터 제2 차이값을 계산하는 단계를 포함하는, 고장 탐지 방법."}
{"patent_id": "10-2020-0042992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "스마트 디바이스에 포함된 녹음 장치의 고장을 탐지하는 서버로서,적어도 하나의 명령어를 포함하고, 고장 유형별 학습용 오디오 신호들을 저장하는 메모리, 상기 스마트 디바이스로부터 오디오 신호를 수신하는 인터페이스, 그리고프로세서를 포함하고,상기 프로세서는,상기 고장 유형별 학습용 오디오 신호로부터 스펙트로그램과 오디오 정보들을 추출하고, 상기 스펙트로그램과공개특허 10-2021-0125366-5-오디오 정보들을 이용하여 신경망 분류기를 학습시키고, 학습된 신경망 분류기로 상기 수신한 오디오 신호를 입력하여 상기 오디오 신호의 고장 유형을 탐지하는, 서버."}
{"patent_id": "10-2020-0042992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 프로세서는,상기 수신한 오디오 신호로부터 일정 구간이 중복되도록 복수의 구간 신호들을 추출하고, 추출한 상기 구간 신호들을 주파수 도메인 값으로 변환하여 상기 복수의 오디오 정보들을 추출하는, 서버."}
{"patent_id": "10-2020-0042992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 프로세서는,상기 스마트 디바이스의 녹음 장치가 복수 개이면, 복수 개의 녹음 장치가 각각 수집한 오디오 신호들 사이의차이값을 계산하는, 서버."}
{"patent_id": "10-2020-0042992", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 프로세서는,상기 스펙트로그램 특징 값과 오디오 정보 특징 값을 완전 연결 연산 처리하여 연결 맵을 생성하고, 상기 생성한 연결 맵에 활성화 함수를 적용하여 상기 확률 값을 계산하는, 서버."}
{"patent_id": "10-2020-0042992", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "서버가 스마트 디바이스의 녹음 장치의 고장을 탐지하는 방법으로서, 고장 유형별 학습용 오디오 신호들을 입력 받아, 각 학습용 오디오 신호에 대한 적어도 하나의 스펙트로그램과 오디오 정보들을 각각 추출하고, 각 학습용 오디오 신호들에 대한 적어도 하나의 스펙트로그램과 오디오 정보들을 해당 고장 유형에 매핑한 학습 데이터를 (뒷면에 계속)"}
{"patent_id": "10-2020-0042992", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 녹음 장치가 구비된 있는 스마트 디바이스에서, 녹음 장치의 고장을 판별하고 사용자나 서비스 제공 자에게 통보하는 신경망 분류기를 이용하여 녹음 장치 고장을 탐지하는 방법, 이를 구현한 서버 및 스마트 디바 이스에 관한 것이다."}
{"patent_id": "10-2020-0042992", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기술의 발전으로 인하여, 다양한 제품에 음성인식 기능이 탑재되고 있다. 전 세계의 인공지능 스피커의 보급 대 수만 해도 이미 1억이 넘는다. 기타 IoT 제품까지 생각하면, 엄청난 수의 음성인식 디바이스들이 이미 우리 주 위에 보급되어 있는 것이다. 이와 같은 스마트 디바이스에서 마이크의 성능은 곧 음성 인식의 정확도로 이어진다. 음성이 깨끗하게 들어오면, 스마트 디바이스는 더 정확한 결과를 도출한다. 따라서 스마트 디바이스에 마이크 개수를 늘리고, 최 신 음성처리 기술을 사용하는 등, 음성 품질을 향상시키기 위해 많은 노력을 투자한다. 이러한 노력에도 불구하고, 마이크의 고장이나 이물질 등 이상이 발생하면 스마트 디바이스는 왜곡된 음성을 수 집하게 된다. 이런 경우, 스마트 디바이스는 문장을 엉뚱하게 알아듣는다. 하지만 사용자 입장에서는 녹음 장치의 고장 여부를 알기 힘들다. 이는 사용자가 녹음되는 목소리를 직접 들어 볼 수 없기 때문이다. 또한, 사용자는 부정확한 음성인식의 원인이 마이크인지, 소음인지, 음성인식 소프트웨어 의 성능 부족인지를 알 방법이 없다. 또한 종래에는, 스마트 기기의 스피커에서 특수하게 제작한 기준 신호를 재생하고, 스마트 기기의 마이크로 들 어오는 신호가 기준 신호와 일정 이상 다른 경우 고장으로 판별하고 있다. 이를 위해, 정상 기기의 스피커에서 기준 신호를 재생 후, 동일 기기의 마이크로 들어오는 신호를 녹음시료로 녹음해둔다. 시험할 기기에서 기준 신호를 재생 후, 마이크로 들어오는 신호를 녹음시료와 비교하여 일정 이상 다른 경우 고장으로 판별한다.이와 같은 종래 기술은, 기준 신호를 가지고 비교를 해야 하기 때문에 소음이 심한 환경에서 사용하기 힘들다. 따라서, 소음이나 신호 왜곡에 의한 영향을 최소화하기 위해 사인파 등의 인위적인 소리를 재생해야만 한다. 그 리고, 신호가 유사한지 아닌지 여부만을 판단하므로, 어떤 유형의 고장인지에 대해서는 판별할 수 없는 문제가 있으며, 마이크 간 신호를 비교해야 하므로 비교할 대상이 없는 하나의 녹음 장치가 적용된 스마트 기기에는 적 용이 불가능하다."}
{"patent_id": "10-2020-0042992", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명은 고장 유형별 학습용 오디오 신호들을 사용하여 고장 유형이 출력되도록 학습된 신경망 분류 기를 이용하여, 스마트 기기가 수집한 오디오 신호의 고장 유형을 탐지하는 신경망 분류기를 이용하여 녹음 장 치 고장을 탐지하는 방법, 이를 구현한 서버 및 스마트 디바이스를 제공한다."}
{"patent_id": "10-2020-0042992", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 본 발명의 기술적 과제를 달성하기 위한 본 발명의 하나의 특징인 서버가 스마트 디바이스의 녹음 장치의 고장을 탐지하는 방법으로서, 고장 유형별 학습용 오디오 신호들을 입력 받아, 각 학습용 오디오 신호에 대한 적어도 하나의 스펙트로그램과 오디오 정보들을 각각 추출하는 단계, 각 학습용 오디오 신호들에 대한 적어도 하나의 스펙트로그램과 오디오 정보들을 해당 고장 유형에 매핑한 학습 데이터를 생성하는 단계, 상기 학습 데이터를 이용하여 신경망 분류기 를 학습시키는 단계, 그리고 상기 스마트 디바이스로부터 오디오 신호를 수신하고, 학습된 신경망 분류기를 이 용하여 상기 오디오 신호의 고장 유형을 탐지하여 상기 스마트 디바이스로 전달하는 단계를 포함하고, 상기 학 습된 신경망 분류기는, 상기 고장 유형별 학습용 오디오 신호들의 스펙트로그램 특징 값을 출력하도록 학습된 제1 신경망 모델, 상기 고장 유형별 학습용 오디오 신호들의 오디오 정보 특징 값을 출력하도록 학습된 제2 신 경망 모델, 그리고 상기 제1 신경망 모델 및 제2 신경망 모델에서 출력된 특징 값들을 연결하여, 해당 학습용 오디오 신호의 고장 유형이 출력되도록 학습된 분류 모델을 포함한다. 상기 제1 신경망 모델은 합성곱 재귀 신경망(CRNN: Convolutional Recurrent Neural Network) 기반의 모델이고, 상기 제2 신경망 모델은 재귀 신경망(RNN: Recurrent Neural Network) 기반의 모델일 수 있다. 상기 고장 유형은 정상 유형, 순간성 고장 유형, 또는 지속성 고장 유형 중 적어도 하나를 포함할 수 있다. 상기 스펙트로그램과 오디오 정보들을 각각 추출하는 단계는, 각 학습용 오디오 신호에서 복수의 시간 구간 신 호들을 추출하는 단계, 각 시간 구간 신호를 주파수 도메인으로 변환하여, 해당 시간 구간 신호의 스펙트로그램 과 오디오 정보들을 추출하는 단계를 포함하고, 상기 복수의 시간 구간 신호들 각각은 이전 시간 구간 또는 이 후 시간 구간과 적어도 일부의 시간 구간이 중복되도록 추출될 수 있다. 상기 본 발명의 기술적 과제를 달성하기 위한 본 발명의 또 다른 특징인 녹음 장치를 포함하는 스마트 디바이스 가 상기 녹음 장치의 고장을 탐지하는 방법으로서, 녹음 장치에서 수집된 오디오 신호를 입력 받는 단계, 상기 오디오 신호에 대한 적어도 하나의 스펙트로그램과 오디오 정보들을 추출하는 단계, 그리고 상기 오디오 신호의 스펙트로그램과 오디오 정보들을, 고장 유형별 학 습용 오디오 신호들로 학습된 신경망 모델로 입력하고, 상기 신경망 모델을 통해 상기 오디오 신호의 고장 유형 을 탐지하는 단계를 포함한다. 상기 오디오 신호를 입력 받는 단계 이전에, 고장 유형별 학습용 오디오 신호들을 입력 받아, 각 학습용 오디오 신호에 대한 적어도 하나의 스펙트로그램과 오디오 정보들을 각각 추출하는 단계, 각 학습용 오디오 신호들에 대한 적어도 하나의 스펙트로그램과 오디오 정보들을 해당 고장 유형에 매핑한 학습 데이터를 생성하는 단계, 상기 학습 데이터를 이용하여 신경망 분류기를 학습시키는 단계를 포함하고, 상기 신경망 분류기를 학습시키는 단계는, 상기 스펙트로그램이 입력되면 스펙트로그램 특징 값을 출력하도록 상기 신경망 분류기에 포함된 제1 신경망 모델을 학습시키는 단계, 상기 오디오 정보들이 입력되면 오디오 정보 특징 값을 출력하도록 상기 신경 망 분류기에 포함된 제2 신경망 모델을 학습시키는 단계, 그리고 제1 신경망 모델에서 출력된 스펙트로그램 특 징 값 및 상기 제2 신경망 모델에서 출력된 오디오 정보 특징 값을 연결하여 계산한 확률 값을 기초로 입력 오 디오 신호의 고장 유형을 출력하도록 분류 모델을 학습시키는 단계를 더 포함할 수 있다.상기 오디오 신호를 입력 받는 단계 이전에, 상기 스마트 디바이스와 연동하는 서버로부터, 상기 서버에서 학습 된 신경망 모델을 수신하는 단계를 더 포함할 수 있다. 상기 스펙트로그램과 오디오 정보들을 추출하는 단계는, 상기 입력 받은 오디오 신호로에서 복수의 시간 구간 신호들을 추출하는 단계, 각 시간 구간 신호를 주파수 도메인으로 변환하여, 해당 시간 구간 신호의 스펙트로그 램과 오디오 정보들을 추출하는 단계를 포함하고, 상기 복수의 시간 구간 신호들 각각은 이전 시간 구간 또는 이후 시간 구간과 적어도 일부의 시간 구간이 중복되도록 추출될 수 있다. 상기 분류 모델을 학습시키는 단계는, 상기 스펙트로그램 특징 값과 오디오 정보 특징 값을 완전 연결 연산 처 리하여 연결 맵을 생성하고, 상기 생성한 연결 맵에 활성화 함수를 적용하여 상기 확률 값으로 계산할 수 있다. 상기 녹음 장치가 복수 개이면, 상기 고장 유형을 획득하는 단계는, 상기 복수의 녹음 장치들 중 제1 녹음 장치 가 수집한 제1 오디오 신호의 스펙트로그램과 오디오 정보, 제2 녹음 장치가 수집한 제2 오디오 신호의 스펙트 로그램과 오디오 정보, 그리고 상기 제1 오디오 신호와 제2 오디오 신호의 차이값을 입력 정보로 추출하는 단계, 그리고 상기 입력 정보를, 상기 학습된 신경망 모델로 입력하고, 상기 신경망 모델로부터 상기 제1 오디 오 신호와 제2 오디오 신호의 고장 유형을 획득하는 단계를 포함할 수 있다. 상기 입력 정보로 추출하는 단계는, 상기 제1 오디오 신호와 제2 오디오 신호로부터 제1 주파수 도메인 값과 제 2 주파수 도메인 값을 생성하는 단계, 상기 제1 주파수 도메인 값과 제2 주파수 도메인 값의 제1 차이값을 계산 하는 단계, 그리고 상기 제1 오디오 신호와 제2 오디오 신호를 n 제곱하고, n 제곱된 제1 오디오 신호와 제2 오 디오 신호의 각 주파수 도메인 값들로부터 제2 차이값을 계산할 수 있다. 상기 본 발명의 기술적 과제를 달성하기 위한 본 발명의 또 다른 특징인 스마트 디바이스에 포함된 녹음 장치의 고장을 탐지하는 서버로서, 적어도 하나의 명령어를 포함하고, 고장 유형별 학습용 오디오 신호들을 저장하는 메모리, 상기 스마트 디바이 스로부터 오디오 신호를 수신하는 인터페이스, 그리고 프로세서를 포함하고, 상기 프로세서는, 상기 고장 유형 별 학습용 오디오 신호로부터 스펙트로그램과 오디오 정보들을 추출하고, 상기 스펙트로그램과 오디오 정보들을 이용하여 신경망 분류기를 학습시키고, 학습된 신경망 분류기로 상기 수신한 오디오 신호를 입력하여 상기 오디 오 신호의 고장 유형을 탐지한다. 상기 프로세서는, 상기 수신한 오디오 신호로부터 일정 구간이 중복되도록 복수의 구간 신호들을 추출하고, 추 출한 상기 구간 신호들을 주파수 도메인 값으로 변환하여 상기 복수의 오디오 정보들을 추출할 수 있다. 상기 프로세서는, 상기 스마트 디바이스의 녹음 장치가 복수 개이면, 복수 개의 녹음 장치가 각각 수집한 오디 오 신호들 사이의 차이값을 계산할 수 있다. 상기 프로세서는, 상기 스펙트로그램 특징 값과 오디오 정보 특징 값을 완전 연결 연산 처리하여 연결 맵을 생 성하고, 상기 생성한 연결 맵에 활성화 함수를 적용하여 상기 확률 값을 계산할 수 있다."}
{"patent_id": "10-2020-0042992", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 특별히 제작한 별도의 기준 신호를 재생할 필요가 없이 녹음 장치 고장을 판별할 수 있기 때 문에, 평소에 음악을 재생하거나 사용자의 음성을 통하여 특별한 조작 없이 녹음 장치의 고장 여부를 꾸준히 모 니터링 할 수 있다. 또한, 단순히 녹음 장치의 고장 여부뿐만 아니라, 어떤 유형의 고장이 발생했는지 탐지할 수 있어, 서비스 제공 자가 해당 소리 데이터를 전송 받아 더 자세한 문제 분석이 가능하다. 또한, 녹음 장치의 개수에 상관없이 적용 가능하기 때문에, 모든 녹음 장치가 동일하게 고장 나서 동일한 신호 가 들어오더라도 녹음 장치가 고장 난 경우에도, 대응 가능하다. 또한, 기존 음성 분류기에서 흔하게 사용되는 멜 스펙트로그램(Mel Spectrogram)이나 음성 특징 데이터에, 추가 적으로 스펙트럼 특성과 차등 값을 사용하여 더욱 정확한 검출이 가능하다. 멜 스펙트로그램과 기타 특성을 고려하여 CRNN(Convolutional Recurrent Neural Network)과 RNN으로 분할 처리 하는 독자적인 신경망 구조를 사용하여, 더 적은 연산량으로도 더욱 정확한 결과를 얻을 수 있다."}
{"patent_id": "10-2020-0042992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위 해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 이하, 도면을 참조로 하여, 본 발명의 실시예에 따른 서버, 스마트 디바이스, 이를 이용한 신경망 분류기 학습 방법 및 녹음 장치 고장 자가 탐지 방법에 대해 설명한다. 본 발명의 제1 실시예에서는 스마트 디바이스가 녹음 장치의 고장 여부를 탐지하기 위해 고장 유형별 학습용 오디오 신호로 신경망 분류기를 학습시킨다. 그리고, 학습시킨 신경망 분류기로 녹음 장치가 수신 한 오디오 신호의 고장 여부 및 고장 유형을 탐지한다. 또한, 본 발명의 제2 실시예에서는 스마트 디바이스와 연동한 서버이 고장 유형별 학습용 오디오 신 호로 신경망 분류기를 학습시킨다. 그리고 스마트 디바이스로부터 수신한 오디오 신호의 고장 여부 및 고 장 유형을 탐지한 후, 스마트 디바이스로 그 결과를 제공한다. 이와 같은 실시예에 따라 신경망 분류기가 녹음 장치의 고장을 탐지하는 환경에 대해 도 1을 참조로 설명한다. 도 1은 본 발명의 실시예에 따른 녹음 장치의 고장을 탐지하는 신경망 분류기가 적용된 환경의 예시도이다. 도 1에 도시된 바와 같이, 스마트 디바이스는 하나의 녹음 장치 또는 복수의 녹음 장치(200')들을 포 함한다. 본 발명의 실시예에서는 녹음 장치로 마이크를 예로 하여 설명하나, 소리를 수집할 수 있는 수단 이면 무엇이든 대체 가능하다. 녹음 장치는 스마트 디바이스에 구비된 스피커(도면 미도시)를 통해 발생한 음성이나 음원, 또는 외 부에서 발생한 음원, 음성, 잡음 등의 오디오 신호를 수집한다. 본 발명의 실시예에서는 설명의 편의를 위하여 스마트 디바이스에 녹음 장치만 포함된 것으로 도시하였으나, 사용자에게 스마트 디바이스를 통 해 서비스를 제공하는 다양한 구성들이 포함될 수 있다. 스마트 디바이스는 제1 실시예에 따라 녹음 장치가 수집한 오디오 신호를 서버로 전달하여, 녹 음 장치의 고장 여부 및 고장 유형을 탐지하도록 요청한다. 서버가 학습된 신경망 분류기를 사용하여 오디오 신호를 수집한 녹음 장치의 고장 여부와 고장 유형을 탐지한 후, 스마트 디바이스로 결과를제공한다. 또한, 스마트 디바이스는 제2 실시예에 따라 녹음 장치가 수집한 오디오 신호로부터 멜 스팩트로그램 과 오디오 정보를 포함하는 입력 정보를 추출하고, 추출한 입력 정보를 학습된 신경망 분류기를 사용하여 이상 여부를 확인한다. 그리고 스마트 디바이스는 입력 정보에 이상이 있는 것으로 판단하면, 이상 발생 빈도를 모니터링한다. 스마트 디바이스는 미리 설정한 임계 빈도 수 이상으로 소리에 이상이 있는 것으로 확인하면, 소리를 수집 한 녹음 장치에 이상이 있는 것으로 판단한다. 그리고, 스마트 디바이스는 서비스 제공자 또는 스마 트 디바이스를 사용하는 사용자에게 녹음 장치에 고장이 있음을 알린다. 이때, 제1 실시예에 따른 서버와 제2 실시예에 따른 스마트 디바이스는 오디오 신호의 이상 여부를 감지하기 위하여, 스마트 디바이스 또는 서버 내에서 별도의 기준 신호를 생성하지 않는다. 그리고, 스마트 디바이스 또는 서버는 수신한 오디오 신호의 오디오 정보를 신경망 분류기를 통해 이상 여부 를 분류하고 이상 발생 빈도를 확인하여 고장 여부를 판별할 수 있다. 따라서, 특별히 제작한 기준 신호를 재생할 필요가 없이 녹음 장치의 고장을 판별할 수 있기 때문에, 평소에 음 악을 재생하거나 사용자가 발화하는 음성 등의 소리를 통하여 특별한 조작 없이 녹음 장치의 고장 여부를 꾸준 히 모니터링 할 수 있다. 또한, 단순히 녹음 장치의 고장 여부뿐만 아니라, 어떤 유형의 고장이 발생했는 지 탐지할 수 있어, 서비스 제공자가 해당 소리 데이터를 전송 받아 더 자세한 문제 분석이 가능하다. 여기서, 녹음 장치는 도 1의 (a)에 도시된 바와 같이 스마트 디바이스에 한 개 구비될 수도 있다. 또 한, 도 1의 (b)에 도시된 바와 같이 복수 개 구비될 수도 있다. 만약 도 1의 (b)와 같이 복수 개의 녹음 장치(200')들이 스마트 디바이스(100')에 구비될 경우, 스마트 디바이 스(100')는 소리로부터 추출한 오디오 신호의 처리를 위한 연산량을 줄이기 위하여, 미리 설정된 순서 또는 랜 덤하게 두 개의 녹음 장치(200')들을 선택한다. 그리고 스마트 디바이스(100')에 포함된 복수의 녹음 장치 (200')들 중 적어도 하나의 녹음 장치에 대한 고장 여부를 탐지한다. 이에 대해서는, 이후 상세히 설명한다. 본 발명의 실시예에서는 하나 또는 복수 개의 녹음 장치들이 구비된 스마트 디바이스에서 신경망 분류기를 학습시키고, 수집한 오디오 신호를 학습된 신경망 분류기로 입력하여 오디오 신호가 수집된 녹음 장치의 고장 유형을 판별할 수 있다. 또한, 본 발명의 실시예에서는 서버에서 신경망 분류기를 학습시키고, 스마트 디 바이스로부터 오디오 신호를 수신하여 학습된 신경망 분류기를 통해 오디오 신호를 수집한 녹음 장치의 고 장 유형을 판별할 수 있다. 또한, 본 발명의 실시예에서는 서버에서 신경망 분류기를 학습시켜 스마트 디 바이스로 전달하고, 스마트 디바이스에서 오디오 신호를 수집하여 서버에서 학습된 신경망 분류 기를 통해 녹음 장치의 고장 유형을 판별할 수 있다. 이상의 환경에서, 본 발명의 제1 실시예에 따라 서버가 신경망 분류기를 학습시키고 녹음 장치의 고장을 탐지하는 방법에 대해 도 2를 참조로 설명한다. 도 2는 본 발명의 제1 실시예에 따라 서버가 녹음 장치의 고장을 탐지하는 방법을 나타낸 흐름도이다. 도 2에 도시된 바와 같이, 서버는 고장 유형별로 수집된 학습용 오디오 신호들을 입력으로 받으면, 학습용 오디오 신호에서 적어도 하나의 스펙트로그램과 오디오 정보들을 추출한다(S100). 여기서, 스펙트로그램과 오디 오 정보들이 해당 고장 유형에 매핑된 형태를 학습 데이터라 지칭하며, 학습용 오디오 신호에서 학습 데이터를 추출하는 방법은, 이후 녹음 장치의 고장을 탐지하는 방법을 설명할 때 함께 설명한다. 서버는 S100 단계에서 추출한 스펙트로그램을 신경망 분류기를 구성하는 제1 신경망 모델로 입력하여 스펙 트로그램 특징 값이 출력되도록 제1 신경망 모델을 학습시킨다(S101). 그리고 서버는 S100 단계에서 추출 한 오디오 정보를 신경망 분류기를 구성하는 제2 신경망 모델로 입력하여, 오디오 정보 특징값이 출력되도록 제 2 신경망 모델을 학습시킨다(S102). 서버는 스펙트로그램 특징 값과 오디오 정보 특징 값을 연결하여, 해 당 학습용 오디오 신호의 고장 유형이 출력되도록 신경망 분류기를 구성하는 분류 모델을 학습시킨다(S103). 이와 같이, 서버가 신경망 분류기를 학습시키면, 스마트 디바이스는 녹음 장치를 이용하여 오디 오 신호를 수신하고(S104), 수신한 오디오 신호를 서버로 전달하여 녹음 장치의 고장 여부와 고장 유 형의 탐지를 요청한다(S105). 서버는 S105 단계에서 스마트 디바이스로부터 오디오 신호를 수신하면, 오디오 신호로부터 입력 정보 인 스펙트로그램과 오디오 정보들을 추출한다(S106). 입력 정보를 추출하기 위해, 서버는 학습용 오디오 신호가 입력되면 일정 구간의 시간 구간 신호 즉, 오디오 프레임을 추출한다. 본 발명의 실시예에서는 설명의 편의를 위하여 오디오 프레임을 추출하는 것으로 설명하나, 오디오 신호가 일정 시간 구간이 중복되도록 중복된 시간 구간 신호를 추출하는 것으로도 표현될 수 있다. 본 발명의 실시예에서는 30ms 길이의 오디오 신호를 10ms마다 오디오 프레임으로 추출하는 것을 예로 하여 설명 한다. 즉, 30ms 길이의 하나의 오디오 신호는 세 개의 오디오 프레임들로 추출될 수 있다. 본 발명의 실시예에 서는 오디오 신호의 길이를 30ms로 하고, 하나의 오디오 프레임의 길이를 10ms로 정의하나 반드시 이와 같이 한 정되는 것은 아니다. 그리고, 서버는 추출한 오디오 프레임들에 윈도잉(windowing) 함수를 적용한다. 윈도잉 함수는 등간격의 자료 즉 오디오 프레임을, 미리 설정한 가중치(window function)를 이용하여 평활화시키는 기법이다. 윈도우의 급격한 차단효과를 줄이기 위해 윈도잉 함수를 적용하면, 서버는 윈도우 크기와 일부 중첩된 오디오 프레 임들을 획득할 수 있다. 본 발명의 실시예에서는 오디오 프레임들을 획득하는 과정에 윈도잉 함수 중 윈도우 해닝(hanning)을 적용하는 것을 예로 하여 설명한다. 그러나, 해밍(Hamming), 블랙맨(Blackman), 가우시안(Gaussian) 등의 다양한 윈도우 함수를 사용할 수 있으며, 윈도우 함수가 어느 하나로 한정되는 것은 아니다. 윈도잉 함수를 적용하여 오디오 프레임들을 획득한 후, 서버는 오디오 프레임들을 고속 푸리에 변환(FFT: Fast Fourier Transform)한다. 고속 푸리에 변환을 토대로 서버는 시간과 음량으로 나타낸 타임 도메인 (Time domain)의 오디오 프레임을, 주파수와 음량으로 나타낸 주파수 도메인(Frequency domain)의 오디오 프레 임으로 변환한다. 서버가 오디오 신호로부터 일정 간격의 오디오 프레임을 추출하거나 고속 푸리에 변환하 는 방법은 이미 알려진 것으로, 본 발명의 실시예에서는 상세한 설명을 생략한다. 서버는 주파수 도메인으로 변환된 오디오 프레임들의 면적의 합을 구하여, 오디오 신호의 신호 세기를 측 정한다. 오디오 프레임들의 면적의 합으로부터 오디오 신호의 신호 세기를 측정하는 방법은 이미 알려진 것으로, 본 발명의 실시예에서는 상세한 설명을 생략한다. 그리고 측정한 신호 세기가 미리 설정한 신호 세기보다 큰 경우에만, 해당 오디오 프레임을 고장 여부를 탐지하 는 데 사용한다. 서버가 주파수 도메인의 오디오 프레임들의 면적 합을 구하는 방법은 이미 알려진 것으로, 본 발명의 실시예에서는 상세한 설명을 생략한다. 서버는 오디오 프레임들을 이용하여, 멜 스펙트로그램(Mel-scaled spectrogram)과 오디오 정보를 추출한다. 본 발명의 실시예에서는, 서버가 추출한 오디오 정보로, 전체적인 소리의 높낮이를 확인하는 스 펙트럼 무게중심(spectral centroid), 스펙트럼 확산(spectral spread), 스펙트럼 왜곡도(spectral skewness), 스펙트럼 첨도(spectral kurtosis), 스펙트럼 감소(spectral decrease), 소리의 변화가 심한지 일정한지를 나 타내는 스펙트럼 플럭스(spectral flux), 스펙트럼 롤-오프(spectral roll-off), 음고(pitch) 등을 예로 하여 설명하나, 반드시 이와 같은 오디오 정보들로 한정하는 것은 아니다. 서버가 각각의 오디오 정보를 추출하기 위해, 다음 수학식들을 이용한다. 수학식 1"}
{"patent_id": "10-2020-0042992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 2 수학식 3"}
{"patent_id": "10-2020-0042992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 4"}
{"patent_id": "10-2020-0042992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 5"}
{"patent_id": "10-2020-0042992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 6"}
{"patent_id": "10-2020-0042992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 7"}
{"patent_id": "10-2020-0042992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, f(n)은 n번째 주파수 값, x(n)은 n번째 FFT 값을 의미한다. 그리고 x(T-1)(n)은 직전 프레임의 FFT 값 을 의미한다. 그리고, 서버는 음고 값 추출을 위해 YIN 알고리즘 또는 MPM 알고리즘 등 음고 탐지 알고리즘을 사용한다. 음고 탐지 알고리즘은 이미 알려진 것으로, 본 발명의 실시예에서는 상세한 설명을 생략한다. 이상의 절차를 통해 멜 스펙트로그램과 오디오 정보들이 추출되면, 서버는 신경망 분류기에 멜 스펙트로그 램과 오디오 정보들을 입력하여, S105 단계에서 스마트 디바이스로부터 수신한 오디오 신호에 이상이 있는 지 여부를 확인한다(S107). 만약 오디오 신호에 이상이 있는 것으로 확인하면, 소리를 녹음한 녹음 장치에 이상이 있는 것으로 확인한 다. 따라서, 서버는 학습된 신경망 분류기를 통해, 녹음 장치의 고장 유형 정의에 따라 오디오 신호의 고 장 형태를 분류한다. 여기서, 서버는, 인접한 필터 뱅크(filter bank) 간 상관 관계를 가지는 멜 스펙트로그램을 학습된 제1 신 경망 모델로 입력하여 멜 스펙트로그램 특징을 출력하여 이상 여부를 확인한다. 그리고 인접한 필터 뱅크간 상 관 관계가 적은 오디오 정보는, 학습된 제2 신경망 모델로 입력한다. 본 발명의 실시예에 따른 제1 신경망은 합성곱 재귀 신경망(CRNN: Convolution Recurrent Neural Network)을 이용하고, 제2 신경망은 재귀 신경망(RNN: Recurrent Neural Network) 기반의 모델 중 GRU(Gated RecurrentUnit)을 이용하는 것을 예로 하여 설명한다. 서버는 S106 단계에서 입력 정보로 추출한 멜 스펙트로그램과 오디오 정보를 이용하여, 녹음 장치에 이상이 있는지 판별하기 위해 사전에 녹음 장치의 고장 유형을 다음 표 1과 같이 정의해 둔다. 표 1 고장 유형 정의 0 정상 1 순간 잡음 2 순간 신호 누락 3 지속성 가산 잡음 4 지속성 신호 누락 5 특정 주파수 대역 누락 6 마이크 실링 불량 7 마이크 회로 불량 서버는 오디오 신호의 이상 여부를 확인하고 분류한 뒤, 오디오 신호에 이상이 있다고 분류된 이상 빈도를 확인한다(S108). 그리고 오디오 신호에 이상이 있다고 확인한 횟수가 미리 설정한 횟수 이상이면, 서버는 스마트 디바이스로 녹음 장치의 고장 여부 및 고장 유형을 알린다(S109). 스마트 디바이스는 서버 로부터 수신한 고장 여부와 고장 유형을 스마트 디바이스를 사용하는 사용자 또는 스마트 디바이스 를 통해 서비스를 제공하는 서비스 제공자에게 고장 발생을 통보한다(S110). 이상에서는 서버가 신경망 분류기를 학습시키고, 학습된 신경망 분류기를 이용하여 녹음 장치의 고장 여부와 고장 유형을 알리는 제1 실시예를 설명하였다. 그러나, 신경망 분류기를 학습시키고 녹음 장치의 고장 여부와 고장 유형을 스마트 디바이스에서 수행할 수도 있다. 이에 대해 도 3을 참조로 설명한다. 도 3은 본 발명의 제2 실시예에 따라 단일 마이크가 구비된 스마트 디바이스가 녹음 장치의 고장 여부를 탐지하 는 방법에 대한 흐름도이다. 여기서, 각각의 절차의 상세한 방법은 상기 도 2에서 설명한 방법과 동일하므로, 도 3에서는 상세한 설명을 생 략한다. 도 3에 도시된 바와 같이, 외부로부터 입력된 학습용 오디오 신호로부터 스펙트로그램과 오디오 정보를 추출하 고(S200), 추출한 스펙트로그램과 오디오 정보를 이용하여 신경망 분류기를 학습시킨다(S210). 스마트 디바이스는 하나 또는 복수의 녹음 장치를 통해 오디오 신호를 수집한다(S220). 여기서 오디 오 신호는 스마트 디바이스에서 재생한 음성이나 음악, 또는 외부에서 발생된 잡음이나 사용자의 음성에 해당한다. 스마트 디바이스는 S220 단계에서 수집한 오디오 신호로부터 오디오 신호의 입력 정보를 추출한다(S230). 그리고 추출한 입력 정보를 S210 단계에서 학습된 신경망 분류기로 입력하여, 오디오 신호를 수집한 녹음 장치 의 고장 여부와 고장 유형을 분류한다(S240). 스마트 디바이스는 S240 단계를 통해 오디오 신호의 이상 여부를 확인하고 분류한 뒤, 오디오 신호에 이상 이 있다고 분류된 이상 빈도를 확인한다(S250). 그리고 오디오 신호에 이상이 있다고 확인한 횟수가 미리 설정 한 횟수 이상이면, 스마트 디바이스는 녹음 장치에 고장이 발생한 것으로 판단한다. 그리고 스마트 디바이스를 사용하는 사용자 또는 스마트 디바이스를 통해 서비스를 제공하는 서비스 제공자에게 고 장 발생을 통보한다(S260). 이상의 절차를 통해 서버 또는 스마트 디바이스가 녹음 장치의 고장 여부를 자가 진단하는 과정 중에서 오디오 신호의 입력 정보를 추출할 때, 오디오 신호에서 추출한 오디오 프레임의 예에 대해 도 4를 참조 로 설명한다. 본 발명의 실시예에서는 설명의 편의를 위하여 '오디오 프레임'을 추출한다고 표현하나, 오디오 신호에서 구간들을 추출하는 것으로 표현될 수도 있다. 그리고 설명의 편의를 위하여 서버에서 오디오 프 레임을 추출하는 것으로 나타내나, 스마트 디바이스에서 추출할 수도 있다. 도 4는 본 발명의 실시예에 따른 오디오 프레임의 예시도이다. 도 4에 도시된 바와 같이, 오디오 신호를 분석하기 위하여 서버는 오디오 신호를 수신하면, 미리 설정한 일정 간격으로 복수의 오디오 프레임들을 추출한다. 이때, 본 발명의 실시예에서는 30ms 길이의 오디오 신호를 매 10ms 마다 오디오 프레임으로 추출하는 것을 예로 하여 설명한다. 서버가 제1 시점(t=1)에 수집한 제1 오디오 신호와 제1 시점 직후인 제2 시점(t=2)에 수집한 제2 오디오 신호는, 일정 부분의 오디오 프레임들이 중복된다. 이는, 윈도우 크기가 일부 중첩되도록 오디오 프레임들을 획 득하여, 윈도우의 급격한 차단효과를 줄이기 위함이다. 다음은 오디오 신호의 입력 정보 중, 멜 스펙트로그램에 대해 도 5를 참조로 설명한다. 도 5는 본 발명의 실시예에 따른 멜 스펙트로그램의 예시도이다. 도 5에 도시된 바와 같이, 서버는 오디오 신호를 고속 푸리에 변환한 결과를 사용하여, 40차의 멜 스펙트 로그램을 추출한다. 도 5에 도시된 멜 스펙트로그램의 x축은 시간축이고, y축은 주파수축이다. 이때, 3개의 프레임으로 구성된 n번째 오디오 프레임을 예로 하면, n번째 오디오 프레임의 시작 위치인 제n 시 점에 앞선 15 프레임(제n-15 프레임 ~ 제n-1 프레임), n번째 오디오 프레임에서 1 프레임(제n+1 프레임)부터 뒤 의 15 프레임(제n+2 프레임 ~ 제n+16 프레임)을 이어 붙인다. 이렇게 총 31개의 프레임(제n-15 프레임 ~ 제n+16 프레임)의 멜 스펙트로그램인 31*40의 2차원 행렬로 구하여 시각화한 것이 도 5에 도시된 예시도이다. 다음은 본 발명의 실시예에서, 녹음 장치가 한 개 구비된 스마트 디바이스에서 오디오 신호를 수집하 고, 서버가 오디오 신호의 이상 여부를 확인할 때, 서버에 구현된 신경망 분류기에 대해 도 6을 참조 로 설명한다. 도 6은 본 발명의 실시예에 따른 신경망 분류기의 하나의 예시도이다. 도 6에 도시된 바와 같이, 신경망 분류기는 멜 스펙트로그램을 입력으로 받는 제1 입력 레이어와 오디오 정보를 입력으로 받는 제2 입력 레이어로 이루어진 입력 레이어를 포함한다. 제1 입력 레이어로 입력된 멜 스펙트로그램은 인공지능 알고리즘으로 학습된 제1 신경망 모델로 입력 되고, 제2 입력 레이어로 입력된 오디오 정보들은 인공지능 알고리즘으로 학습된 제2 신경망 모델로 입력된다. 여기서, 제1 신경망 모델은 합성곱 재귀 신경망(CRNN: Convolutional Recurrent Neural Network) 기반의 모델이고, 제2 신경망 모델은 재귀 신경망(RNN: Recurrent Neural Network) 기반의 모델 이다. 본 발명의 실시예에서는 신경망 분류기의 입력 레이어로 입력되는 입력 정보에 따라 적합한 신경망 모델 (120, 130)을 통과시켜 특징 값들을 출력한다. 출력한 특징 값들을 연결 레이어인 분류 모델에서 연결하여 하나의 연결 맵을 생성한다. 그리고 연결 맵에 활성화 함수인 소프트맥스(softmax)를 이용하여 확률값을 계산한다. 이때 확률값은 기 설정된 고장 유형별로 확률 값들이 계산된다. 여기서, 연결 레이어인 분류 모델은 완전 연결 레이어로 구현되는 것을 예로 하여 설명한다. 도 6에서 괄호 안의 숫자들은 해당 레이어의 노드(node) 개수를 의미한다. 예를 들어, 제1 신경망 모델의 CNN 5*5은 5*5 필터를 사용하는 CNN 레이어를 8개 사용하여 하나의 멜 스펙트로그램을 각각 처리한다는 것을 의미한다. 신경망 분류기의 각 레이어들에 대해 설명하면, 입력 레이어는 멜 스펙트로그램과 오디오 정보를 수신하면, 배치 정규화(batch normalization) 알고리즘으로 멜 스펙트로그램과 오디오 정보를 정규화한다. 배치 정규화는 각 레이어에서의 활성화 값이 적당히 분포되도록 조정하는 것으로, 배치 정규화 방법은 이미 알려진 것으로, 본 발명의 실시예에서는 상세한 설명을 생략한다. 제1 신경망 모델에 해당하는 합성곱 재귀 신경망 레이어는, 합성 곱 레이어, 활성화 레이어, 그리고 풀링 레이어로 이루어진다. 합성 곱 레이어는 배치 정규화된 멜 스펙트로그램에 합성 곱 연산을 적용한다. 합성곱 연 산은 이미지 처리에서 말하는 필터 연산에 해당하는 것으로, 필터의 윈도우를 일정 간격으로 이동해가며 입력 데이터인 배치 정규화된 멜 스펙트로그램과 필터에 대응하는 원소끼리 곱한 후 총 합을 구한다. 활성화 레이어는 합성 곱 연산을 적용한 멜 스펙트로그램에 활성화 함수(activation function)을 적용한다. 여 기서 활성화 함수로 하이퍼볼릭 탄젠트 함수(tanh(x))를 사용하는 것을 예로 하여 설명하나, 반드시 이와 같이 한정되는 것은 아니다. 풀링 레이어는, 활성화 합수가 적용된 멜 스펙트로그램의 주파수 도메인의 세로와 가로 방향의 공간을 줄인다. 이를 위해, 본 발명의 실시예에서는 최대 풀링(max pooling)을 사용하여, 멜 스펙트로그램의 크기를 줄여준다. 본 발명의 실시예에서 제1 신경망 모델은 합성곱 재귀 신경망 구조를 사용하는 것을 예로 하여 설명하며, 제1 신경망 모델에 포함된 GRU 대신 RNN, LSTM 등의 순환 신경망 구조를 사용할 수 있다. 또한, 제1 신경 망 모델의 세부적인 노드 개수나 레이어 개수는 도 6에 도시한 수로 한정하지 않고, 변경될 수 있다. 제2 신경망 모델에 해당하는 순환 신경망 레이어는, 그래디언트 소실(vanishing gradient) 문제가 없고 연 산량이 적은 GRU 셀을 활용한다. GRU 셀에 대한 사항은 이미 알려진 것으로, 본 발명의 실시예에서는 상세한 설 명을 생략한다. 본 발명의 실시예에서 제2 신경망 모델은 RNN구조를 사용하는 것을 예로 하여 설명하며, GRU 대신 RNN, LSTM 등의 순환 신경망 구조를 사용할 수 있다. 그리고 제2 신경망 모델의 세부적인 노드 개수나 레이어 개수는 도 6에 도시한 수로 한정하지 않고, 변경될 수 있다. 또한 이상에서 언급한 신경망 분류기를 사전에 고장난 녹음 장치로 수집한 소리를 데이터 입력으로 하고, 고장 유형을 원 핫 벡터(one-hot-vector) 출력으로 하여 학습한다. 학습된 신경망 분류기는 매 프레임마다, 미 리 정의해 둔 고장 유형들의 확률 값들을 출력한다. 이상에서는 스마트 디바이스에 하나의 마이크가 구비된 경우의 고장 여부를 탐지하는 예에 대해 설명하였 다. 한편, 스마트 디바이스(100')에 복수의 마이크가 구비되었을 경우, 스마트 디바이스(100')가 고장 여부를 탐지하는 또 다른 실시예에 대해 도 7을 참조로 설명한다. 도 7을 설명하기 앞서, 복수의 녹음 장치(200')들이 구비되어 있는 스마트 디바이스(100')의 신경망 분류기는 상기 도 2에서 설명한 바와 같이 서버에서 고장 유형별로 학습되거나, 스마트 디바이스(100')에서 학습될 수 있다. 본 발명의 실시예에서는 설명의 편의를 위하 여 스마트 디바이스(100')에서 신경망 분류기를 학습시킨 것을 예로 하여 설명한다. 도 7은 본 발명의 실시예에 따른 복수의 마이크들이 구비된 스마트 디바이스가 녹음 장치의 고장 여부를 자가 탐지하는 방법에 대한 흐름도이다. 도 7에 도시된 바와 같이, 스마트 디바이스(100')는 외부로부터 입력된 학습용 오디오 신호로부터 스펙트로그램 과 오디오 정보를 추출하고(S300), 추출한 스펙트로그램과 오디오 정보를 이용하여 신경망 분류기를 학습시킨다 (S310). 스마트 디바이스는 복수의 녹음 장치를 통해 오디오 신호를 수집한다. 이때, 복수의 녹음 장치(20 0')들 중 선택한 두 개의 녹음 장치들을 통해 오디오 신호를 각각 수집한다(S320). 여기서 스마트 디바이스(100')는 미리 설정된 순서로 복수의 녹음 장치(200')들 중 두 개의 녹음 장치를 선택하 거나, 또는 랜덤하게 두 개의 녹음 장치를 선택할 수 있다. 그리고, 녹음 장치(200')가 복수 개이므로, 스마트 디바이스(100')는 수집한 소리로부터 추출한 오디오 신호에 각각의 녹음 장치(200')의 식별 정보를 포함하여 수 집한다. 스마트 디바이스(100')는 S320 단계에서 수집한 두 개의 오디오 신호에서 입력 정보를 각각 추출한다(S330). 여 기서 입력 정보는 두 오디오 신호의 스펙트로그램과 오디오 정보들을 포함한다. 스마트 디바이스(100')가 두 개 의 오디오 신호로부터 입력 정보를 추출하기 위하여, 두 개의 소리로부터 각각 획득한 두 개의 오디오 신호를 일정한 간격의 프레임 단위로 잘라 오디오 프레임으로 추출한다. 본 발명의 실시예에서는 30ms 길이의 두 개의 오디오 신호를 각각 10ms마다 오디오 프레임으로 추출하는 것을 예로 하여 설명한다. 따라서, 본 발명의 실시예에서의 1 프레임을 10ms로 정의하나 반드시 이와 같이 한정되는 것은 아니다. 그리고, 스마트 디바이스(100')는 추출한 오디오 프레임들에 윈도잉(windowing)을 각각 적용한다. 윈도잉 함수 를 각각 적용하여 두 오디오 신호로부터 오디오 프레임들을 획득한 후, 스마트 디바이스(100')는 오디오 프레임 들을 고속 푸리에 변환(FFT: Fast Fourier Transform)하여, 시간과 음량으로 나타낸 타임 도메인(Time domai n)의 오디오 프레임을 주파수와 음량으로 나타낸 주파수 도메인(Frequency domain)의 오디오 프레임으로 변환한 다. 스마트 디바이스(100')는 주파수 도메인으로 변환된 두 개의 오디오 프레임들의 면적의 합을 구하여, 두 오디오 신호의 신호 세기를 각각 측정한다. 그리고 측정한 신호 세기가 미리 설정한 신호 세기보다 큰 경우에만, 해당오디오 프레임을 고장 여부를 탐지하는 데 사용한다. 스마트 디바이스(100')는 오디오 프레임들을 이용하여, 멜 스펙트로그램(Mel-scaled spectrogram)과 오디오 정 보를 추출한다. 스마트 디바이스(100')가 추출한 오디오 정보는 상기 도 2에서 설명한 오디오 정보들과 같다. 그리고 두 개의 녹음 장치(200')들 사이의 두 개의 차등 값(Difference measure)을 계산한다(S340). 이상의 절차를 통해 멜 스펙트로그램과 오디오 정보들을 추출하고 차등 값을 계산하면, 스마트 디바이스(100') 는 신경망 분류기를 통해 S320 단계에서 수집한 오디오 신호들에 이상이 있는지 여부를 확인한다. 그리고 오디 오 신호들에 이상이 있는 것으로 확인하면, 오디오 신호들을 수집한 두 개의 녹음 장치(200') 중 어느 하나에 이상이 있는 것으로 확인한다. 본 발명의 실시예에서는 스마트 디바이스(100')에 포함된 복수의 녹음 장치(200')들 중 적어도 하나의 녹음 장 치에 이상이 있는지 여부만 탐지하는 것을 예로 하여 설명한다. 그러나, 두 오디오 프레임을 비교한 두 개의 녹 음 장치(200') 각각의 고장 여부를 따로 검출한 후, 어떤 녹음 장치에서 어떠한 오류가 발생하였는지 확인할 수 도 있다. 따라서 스마트 디바이스(100')는 두 개의 녹음 장치(200')들 사이의 차등 값을 토대로, 두 개의 녹음 장치 (200') 중 어느 하나의 녹음 장치에 고장이 발생한 것으로 파악한다. 그리고, 기 정의된 녹음 장치의 고장 유형 정의에 따라 S320 단계에서 수집한 오디오 신호의 고장 형태를 분류한다(S350). 여기서, 스마트 디바이스(100')는 인접한 필터 뱅크(filter bank) 간 상관 관계를 가지는 멜 스펙트로그램은 제 1 신경망 모델을 통해 학습하여 이상 여부를 확인한다. 그리고 인접한 필터 뱅크간 상관 관계가 적은 오디오 정 보는 제2 신경망 모델을 통해 학습한다. 이때, 스마트 디바이스(100')는 S330 단계에서 입력 정보로 추출한 멜 스펙트로그램과 오디오 정보, 그리고 S340 단계에서 계산한 녹음 장치(200')들의 차등 값을 이용하여, 녹음 장치에 이상이 있는지 판별하기 위 한 고장 유형은 상기 표 1에 정의한 바와 같다. 스마트 디바이스(100')는 S350 단계를 통해 오디오 신호의 이상 여부를 확인하고 분류한 뒤, 이상 빈도를 확인 한다(S360). 그리고 오디오 신호에 이상이 있다고 확인한 횟수가 미리 설정한 빈도 이상이면, 녹음 장치(200') 에 고장이 발생한 것으로 판단하여 스마트 디바이스(100')를 사용하는 사용자 또는 스마트 디바이스를 통 해 서비스를 제공하는 서비스 제공자에게 고장 발생을 통보한다(S370). 이상의 절차를 통해 스마트 디바이스(100')가 녹음 장치(200')의 고장 여부를 자가 진단할 때, 스마트 디바이스 (100')는 선택한 두 개의 녹음 장치(200')들 사이의 두 개의 차등 값을 추출해야 한다. 이에 대해 도 8을 참조 로 설명한다. 도 8은 본 발명의 실시예에 따른 차등 값 추출을 위한 두 녹음 장치의 신호들을 나타낸 예시도이다. 도 8의 (a)는 두 녹음 장치들이 수집한 소리의 오디오 신호들을 나타낸 것이고, 도 8의 (b)는 오디오 신호들에 n 제곱하여 확인한 오디오 신호들을 나타낸 예시도이다. 스마트 디바이스(100')는 제1 녹음 장치가 수집한 소리의 제1 오디오 신호와, 제2 녹음 장치가 수집한 소리의 제2 오디오 신호의 차등 값을 두 신호 사이의 면적을 구하여 얻을 수 있다. 녹음 장치가 정상 상태인 경우라도, 녹음 장치가 설치된 위치에 따라 도 8의 (a)와 같이 두 오디오 신호들은 어느 정도의 차이를 보인다. 오디오 신호들 사이의 차이는 오디오 신호의 진폭에 비례하는 성향을 보인다. 따라서 다음 수학식 8 및 수학식 9와 같이 스마트 디바이스는 두 신호간의 크기(에너지) 차이를 전체 신호 크기의 합으로 나누고 정규화하 여, 차등 값을 구한다. 수학식 8 수학식 9"}
{"patent_id": "10-2020-0042992", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "본 발명의 실시예에서는 스마트 디바이스는 두 개의 차등 값을 구한다. 두 개의 녹음 장치(200') 중 적어 도 하나의 녹음 장치에 이상이 있을 경우, 각 녹음 장치(200')로 들어오는 신호들 사이의 차이가 발생하고, 차 등 값은 커진다. 도 8의 (a)에 나타낸 정상 그래프는 아래 면적이 거의 비슷하나, 도 8의 (b)에 나타낸 바와 같 이 두 개의 녹음 장치(200') 중 하나가 고장 난 경우, 면적 차이가 크게 나타난다. 이런 값의 변화를 신경망에 추가 정보 입력으로 사용하여 신경망의 정확도를 올릴 수 있습니다 즉, 제1 오디오 신호와 제2 오디오 신호의 제1 차등 값을 수학식 8을 이용하여 구하고, 제1 오디오 신호와 제2 오디오 신호를 2 제곱하여 제2 차등 값을 수학식 9를 이용하여 구한다. 그러나, 반드시 이와 같이 한정되는 것 은 아니다. 다음은 복수개의 녹음 장치(200')를 구비한 스마트 디바이스(100')가 오디오 신호의 이상 여부를 확인하기 위한 신경망 분류기에 대해 도 9를 참조로 설명한다. 도 9는 본 발명의 실시예에 따른 신경망 분류기의 또 다른 예시도이다. 본 발명의 실시예에서는 복수의 녹음 장치들이 구비되어 있다고 하더라도, 스마트 디바이스가 임의의 두 개의 녹음 장치를 선택하여 오디오 신호의 이상 여부를 확인하는 것을 예로 하여 설명한다. 따라서, 두 개의 오 디오 신호의 이상 여부를 확인하는 신경망 구조는 도 8에 도시된 바와 같다. 도 9에 도시된 바와 같이, 신경망 분류기는 입력 레이어(110')를 통해 멜 스펙트로그램과 오디오 정보를 입력으 로 받는다. 이때, 녹음 장치(200')가 복수 개 이므로, 입력 레이어(110')는 각각 복수의 녹음 장치(200')가 획 득한 소리의 음성 신호를 처리한 처리 정보를 각각 수신한다. 또한, 두 오디오 신호를 통해 계산된 두 개의 차 등 값도 입력으로 수신한다. 각각의 레이어의 기능은 상기 도 5에서 설명한 바와 동일하다. 즉, 입력부(110')로 입력된 멜 스펙트로그램은 인공지능 알고리즘으로 학습되었으며 합성곱 재귀 신경망 기반의 모델인 제1 신경망 모델(120')로 입력된다. 그 리고, 오디오 정보들과 차등 값들은 인공지능 알고리즘으로 학습되었으며 재귀 신경망 기반의 모델인 제2 신경 망 모델(130')로 입력된다. 본 발명의 실시예에서는 신경망 분류기의 입력 레이어(110')로 입력되는 입력 정보에 따라 적합한 신경망 모델 (120', 130')을 통과시켜 각 입력되는 정보에 따른 특징 값들을 출력한다. 그리고, 신경망 모델(120', 130')에 서 출력된 특징 값들을 연결 레이어인 분류 모델(140')에서 연결하여 하나의 연결 맵을 생성한다. 연결 맵에 활성화 함수인 소프트맥스(softmax)를 이용하여 확률값을 계산한다. 이때 확률값은 기 설정된 고장 유형별로 확률 값들이 계산된다. 여기서, 분류 모델(140')은 완전 연결 레이어로 구현되는 것을 예로 하여 설명 한다. 이때, 신경망 분류기가 출력한 확률 값들을 시각화한 그래프에 대해 도 10을 참조로 설명한다. 도 10은 본 발명의 실시예에 따라 출력된 고장 유형별 확률 값을 시각화한 그래프의 예시도이다. 도 10에서는 상기 표 1에서 설명한 8개의 고장 유형들 중, 정상일 때의 확률 값, 순간성 고장과 지속성 고장의 확률 값을 시각화하여 나타내었으며, 8개의 고장 유형들별로 모두 확률 값이 계산된다. 신경망 분류기를 사용하여 입력된 오디오 신호를 분류하면, 오류 검출 결과가 일정 기간(10ms) 간격으로 생성된 다. 신경망 분류기에서는 각 고장 유형별로 확률값이 출력되고, 이를 시간에 따라 변화를 볼 수 있도록 시각화 하면 도 9에 도시된 바와 같다. 도 10에서는 하나의 녹음 장치에 대한 고장 유형별 확률 값을 나타내었다. 그러나, 복수의 녹음 장치 (200')를 사용하는 경우에는 녹음 장치(200')의 수만큼의 그래프가 생성된다.여기서, 임의의 시점에서의 정상 확률값, 지속성 고장 확률값, 순간성 고장 확률값의 합은 1이 된다. 그리고 점 선으로 표시한 시점과 같이, 정상일 경우의 확률 값은 대략 0.1이나, 순간성 고장의 확률 값이 0.9인 경우, 스 마트 디바이스는 해당 시점에 녹음 장치에 순간성 고장이 발생한 것으로 판단할 수 있다. 즉, 순간성 고장과 지속성 고장의 확률값은 판이하게 다르다. 이에 따라, 순간성 고장과 지속성 고장 유형에 따 라 서로 다른 고장 판별 기준이 필요하다. 순간성 고장의 경우 아주 짧은 시간 동안만, 간헐적으로 이상이 발생한다. 이를 검출하기 위하여, 스마트 디바 이스는 신경망 분류기에서 계산한 확률값들 중 최대값을 갖는 고장 유형을 찾는다. 만일 최대값을 가지는 고장 유형이 순간성 고장인 경우, 해당 고장 유형의 고장이 발생했다 판별한다. 스마트 디바이스는 오검출을 막기 위하여, 긴 시간 동안 일정 회수 초과하여 같은 이상이 발생하는 경우에 만 고장으로 통보한다. 예를 들어, 30분 동안 10 프레임을 초과하여 이상이 발생할 경우, 녹음 장치에 고 장이 있는 것으로 통보한다. 한편, 지속성 고장의 경우, 연속하여 이상 증상이 발생한다. 보통, 녹음 장치가 정상적인 상황에서도, 순 간적으로 고장 유형의 확률 값이 계산될 수 있다. 이런 경우를 모두 고장으로 감지하는 경우, 녹음 장치가 정상임에도 오검출을 할 수 있다. 이를 방지하기 위하여, 일정 시간 동안 계속하여 이상이 발생하는 경우 고장으로 검출한다. 예를 들어, 5분 이 상 지속적으로 오디오 신호에 오류가 발생한 것으로 인지하면, 녹음 장치에 지속성 고장이 발생한 것으로 통보한다. 이와 같은 방법으로 스마트 디바이스가 스마트 디바이스의 녹음 장치의 고장을 자가 탐지한다면, 녹음 장치가 불량인 경우 고객에게 바로 알려서 조치를 받도록 유도할 수 있다. 그리고, 스마 트 디바이스를 회수하지 않고도 녹음 장치의 불량을 알 수 있다. 또한, 특수한 신호의 재생 없이도 스마트 디바이스에서 출력되는 소리나 사용자의 음성 등 일반적인 소리 를 통해 녹음 장치의 불량을 감지할 수 있다. 그리고, 감지한 녹음 장치의 고장 종류를 명확하게 파 악함으로써, 스마트 디바이스를 개선하는데 사용할 수 있다. 도 11은 본 발명의 실시예에 따른 컴퓨터 시스템의 구조도이다. 도 11을 참고하면, 적어도 하나의 프로세서에 의해 동작하는 컴퓨터 시스템에서, 본 발명의 동작을 실행하 도록 기술된 명령들(instructions)이 포함된 프로그램을 실행한다. 프로그램은 컴퓨터 판독 가능한 저장매체에 저장될 수 있고, 유통될 수 있다. 여기서, 컴퓨터 시스템의 구조는 본 발명의 실시예에 따른 스마트 디바 이스의 구조일 수도 있고, 서버의 구조일 수도 있다. 컴퓨터 시스템의 하드웨어는 적어도 하나의 프로세서, 메모리, 스토리지, 통신 인터페이스 를 포함할 수 있고, 버스를 통해 연결될 수 있다. 이외에도 입력 장치 및 출력 장치 등의 하드웨어가 포함 될 수 있다. 컴퓨터 시스템는 프로그램을 구동할 수 있는 운영 체제를 비롯한 각종 소프트웨어가 탑재될 수 있다. 프로세서는 컴퓨터 시스템의 동작을 제어하는 장치로서, 프로그램에 포함된 명령들을 처리하는 다양 한 형태의 프로세서일 수 있고, 예를 들면, CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 등 일 수 있다. 메모리는 본 발명의 동작을 실행하도록 기술된 명령들이 프로세서에 의해 처리되도록 해당 프로그램 을 로드한다. 메모리는 예를 들면, ROM(read only memory), RAM(random access memory) 등 일 수 있다. 스토리지는 본 발명의 동작을 실행하는데 요구되는 각종 데이터, 프로그램 등을 저장한다. 통신 인터페이 스는 유/무선 통신 모듈일 수 있다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2020-0042992", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 녹음 장치의 고장을 탐지하는 신경망 분류기가 적용된 환경의 예시도이다. 도 2는 본 발명의 재1 실시예에 따라 서버가 녹음 장치의 고장을 탐지하는 방법을 나타낸 흐름도이다. 도 3은 본 발명의 제2 실시예에 따라 단일 마이크가 구비된 스마트 디바이스가 녹음 장치의 고장 여부를 탐지하 는 방법에 대한 흐름도이다. 도 4는 본 발명의 실시예에 따른 오디오 프레임의 예시도이다. 도 5는 본 발명의 실시예에 따른 멜 스펙트로그램의 예시도이다. 도 6은 본 발명의 실시예에 따른 신경망 분류기의 하나의 예시도이다. 도 7은 본 발명의 실시예에 따른 복수의 마이크들이 구비된 스마트 디바이스가 녹음 장치의 고장 여부를 자가 탐지하는 방법에 대한 흐름도이다. 도 8은 본 발명의 실시예에 따른 차등 값 추출을 위한 두 녹음 장치의 신호들을 나타낸 예시도이다. 도 9는 본 발명의 실시예에 따른 신경망 분류기의 또 다른 예시도이다. 도 10은 본 발명의 실시예에 따라 출력된 고장 유형별 확률 값을 시각화한 그래프의 예시도이다. 도 11은 본 발명의 실시예에 따른 스마트 디바이스의 구조도이다."}
