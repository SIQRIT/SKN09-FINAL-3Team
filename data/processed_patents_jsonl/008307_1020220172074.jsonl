{"patent_id": "10-2022-0172074", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0086958", "출원번호": "10-2022-0172074", "발명의 명칭": "신경망을 이용한 소프트웨어 테스팅 방법 및 이를 이용한 장치", "출원인": "연세대학교 산학협력단", "발명자": "권태경"}}
{"patent_id": "10-2022-0172074", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "소프트웨어 테스팅을 위한 시드를 인코딩하는 전처리부;상기 전처리부로부터 제1 시드를 제공받아 인공지능 모델을 학습시키는 사전 학습부;학습된 상기 인공지능 모델을 이용하여 상기 전처리로부터 제공받은 제2 시드를 재구성하여 토큰을 생성하는 마스킹 전략부; 및상기 마스킹 전략부로부터 생성된 토큰을 소프트웨어에 입력하여 퍼징(fuzzing)을 실행하는 퍼징부를 포함하는소프트웨어 테스팅 장치."}
{"patent_id": "10-2022-0172074", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 전처리부는,시드 풀(seed pool)로부터 유효 시드를 선별하는 시드 선별부;유효 시드를 단어 단위의 토큰으로 파싱(parsing)하는 토큰화부; 및토큰화된 시드를 숫자로 변환하는 인코딩부를 포함하는소프트웨어 테스팅 장치."}
{"patent_id": "10-2022-0172074", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제1 시드 및 상기 제2 시드는 상기 인코딩부에 의해 변환된 숫자 형태인소프트웨어 테스팅 장치."}
{"patent_id": "10-2022-0172074", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 사전 학습부는,상기 제1 시드의 적어도 일부를 마스킹하는 학습 마스킹부; 및상기 학습 마스킹부로부터 마스킹된 상기 제1 시드를 이용하여 마스킹된 부분을 예측하도록 인공지능 모델을 학습시키는 예측 학습부를 포함하는소프트웨어 테스팅 장치."}
{"patent_id": "10-2022-0172074", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 마스킹 전략부는,공개특허 10-2024-0086958-3-상기 제2 시드의 적어도 일부를 마스킹하는 전략 마스킹부;상기 전략 마스킹부로부터 마스킹된 상기 제2 시드를 상기 인공지능 모델에 입력하여 재구성된 상기 제2 시드를획득하는 마스킹 예측부; 및상기 재구성된 상기 제2 시드를 디코딩하여 상기 토큰을 획득하는 결과 디코딩부를 포함하는소프트웨어 테스팅 장치."}
{"patent_id": "10-2022-0172074", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 제2 시드의 길이가 길수록 상기 전략 마스킹부에 의해 마스킹되는 단어의 개수는 많아지는소프트웨어 테스팅 장치."}
{"patent_id": "10-2022-0172074", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서,상기 인코딩부는 단어에 대응되는 숫자 목록을 포함하는 사전(dictionary)에 기초하여 상기 토큰화된 시드를 숫자로 변환하는소프트웨어 테스팅 장치."}
{"patent_id": "10-2022-0172074", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 전략 마스킹부는 단어에 대응되는 숫자 목록을 포함하는 사전(dictionary)에 기초하여 상기 제2 시드의 적어도 일부를 마스킹하는소프트웨어 테스팅 장치."}
{"patent_id": "10-2022-0172074", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제2항에 있어서,상기 퍼징부로부터 상기 소프트웨어의 퍼징 실행 결과에 대한 커버리지 정보를 수신하여 커버리지의 증가 여부를 판단하는 커버리지 분석부를 더 포함하는소프트웨어 테스팅 장치."}
{"patent_id": "10-2022-0172074", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 커버리지 분석부는 수신한 커버리지가 이전의 커버리지보다 증가한 경우, 수신한 커버리지에 대응되는 토큰을 상기 시드 풀에 추가하는소프트웨어 테스팅 장치."}
{"patent_id": "10-2022-0172074", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2024-0086958-4-제7항에 있어서,상기 퍼징부로부터 상기 소프트웨어의 퍼징 실행 결과에 대한 커버리지 정보를 수신하여 커버리지의 증가 여부를 판단하는 커버리지 분석부를 더 포함하고,상기 커버리지 분석부는 상기 커버리지의 증가 여부에 기초하여 상기 사전에 포함된 숫자 목록을 재구성하는소프트웨어 테스팅 장치."}
{"patent_id": "10-2022-0172074", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "적어도 하나 이상의 프로세서에 의해 수행되는 소프트웨어 테스팅 방법에 있어서,시드 풀로부터 유효 시드를 선별하여 제1 시드 및 제2 시드를 제공하는 단계;상기 제1 시드를 이용하여 인공지능 모델을 학습시키는 단계;학습된 상기 인공지능 모델을 이용하여 상기 제2 시드를 재구성하여 토큰을 생성하는 단계; 및상기 토큰을 소프트웨어에 입력하여 퍼징(fuzzing)을 수행하는 단계를 포함하는소프트웨어 테스팅 방법."}
{"patent_id": "10-2022-0172074", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 기재된 소프트웨어 테스팅 방법을 실행시키도록 컴퓨터로 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0172074", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 소프트웨어 테스팅 장치는 소프트웨어 테스팅을 위한 시드를 인코딩하는 전처리부; 상기 전처리부로부 터 제1 시드를 제공받아 인공지능 모델을 학습시키는 사전 학습부; 학습된 상기 인공지능 모델을 이용하여 상기 전처리로부터 제공받은 제2 시드를 재구성하여 토큰을 생성하는 마스킹 전략부; 및 상기 마스킹 전략부로부터 생 성된 토큰을 소프트웨어에 입력하여 퍼징(fuzzing)을 실행하는 퍼징부를 포함할 수 있다."}
{"patent_id": "10-2022-0172074", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 소프트웨어 테스팅 방법에 관한 것으로, 보다 상세하게는, 무작위 전략을 사용한 변이 기법 대신 마 스킹된 토큰을 삽입하여 이를 인공지능 모델이 예측하게 함으로써 토큰을 생성하는 방법에 관한 것이다."}
{"patent_id": "10-2022-0172074", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "소프트웨어에 존재하는 버그는 단순히 프로그램의 기능을 방해할 뿐만 아니라 악의적인 공격자를 통해 사용자의 장치를 공격할 수 있다. 그러나, 개발 단계에서 소프트웨어에 존재하는 모든 버그를 찾는 것은 현실적으로 어려 우므로, 개발 단계에서 찾지 못한 소프트웨어의 버그를 찾기 위해 퍼징과 기호 실행 등 다양한 동적 분석 기술 이 사용되고 있다. 소프트웨어에 내재된 버그를 찾기 위한 동적 분석 기술 중에는 퍼징(Fuzzing) 기법이 존재한다. 퍼징은 무작위 로 입력 값을 생성하거나 기본 입력 값을 토대로 변형하여 테스트 대상 소프트웨어의 입력값으로 제공하였을 때, 비정상적인 동작을 수행하는지에 대한 여부를 탐지하는 동적 분석 방법이다. 소프트웨어의 비정상적 동작은 개발자가 예상한대로 프로그램이 동작하지 않으며 예상치 못한 값이 출력되거나 실행되지 못한 채 강제 종료되 는 것을 의미한다. 퍼징 기법은 짧은 시간 내에 빠르게 다양한 입력값을 생성하여 테스트할 수 있다는 장점이 있어 널리 사용되고 있으나 무작위로 입력값을 생성하거나 변형하기 때문에 하는 특정 소프트웨어에 대해서는 입력 조건에 적합하지 않아 진입하지 못한다는 한계가 있다. 이러한 퍼징의 구조적인 입력을 요구하는 소프트웨어에 대한 테스팅적 한 계 해결하기 위하여 토큰 수준 퍼징(Token-level Fuzzing) 전략이 제안되었다. 토큰 수준 퍼징(Token-level Fuzzing)은 구조적인 입력을 요구하는 소프트웨어에 적합한 테스팅을 수행하기 위 한 퍼징 전략이다. 이 중 토큰 수준 퍼징은 입력 시드를 단어 단위로 조각내어 토큰들로 구성된 사전을 구성한 다. 사전에 구성된 순서대로 토큰에 숫자를 부여한 후, 입력 시드에 존재하는 토큰을 해당하는 숫자로 변환하여 숫자의 배열로 인코딩한다. 토큰 수준 퍼징은 인코딩된 시드에 숫자를 바꾸거나 추가로 삽입하거나 삭제하고 교체하는 등의 변이를 통해 새로운 테스트케이스를 생성한다. 하지만 토큰 수준 퍼징은 단순히 최대 65535개의 단어 사전을 무작위로 선택하여 입력 시드를 변이하는 방식을 따르기 때문에 여전히 문법 수준 퍼징에 비하면 에러율이 높으며 유효한 새로운 구조의 테스트케이스를 생성하 기가 어렵다. 때문에 초기 시드에 대한 의존성이 높아 토큰 수준 퍼징만으로는 문법 수준 퍼저가 찾아내는 특정 순서의 입력을 필요로 하는 버그는 찾아내지 못한다는 한계가 있다. 이러한 한계를 개선하기 위해서는 토큰 수 준 퍼징의 변이 기법을 개선할 필요가 있다."}
{"patent_id": "10-2022-0172074", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 과제는 마스킹된 토큰을 삽입하여 이를 인공지능 모델이 예측하게 함으로써 토큰을 생성하는 방법 에 관한 것이다."}
{"patent_id": "10-2022-0172074", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 소프트웨어 테스팅 장치는 소프트웨어 테스팅을 위한 시드를 인코딩하는 전처리부; 상기 전처 리부로부터 제1 시드를 제공받아 인공지능 모델을 학습시키는 사전 학습부; 학습된 상기 인공지능 모델을 이용 하여 상기 전처리로부터 제공받은 제2 시드를 재구성하여 토큰을 생성하는 마스킹 전략부; 및 상기 마스킹 전략 부로부터 생성된 토큰을 소프트웨어에 입력하여 퍼징(fuzzing)을 실행하는 퍼징부를 포함할 수 있다. 여기서, 상기 전처리부는, 시드 풀(seed pool)로부터 유효 시드를 선별하는 시드 선별부; 유효 시드를 단어 단 위의 토큰으로 파싱(parsing)하는 토큰화부; 및 토큰화된 시드를 숫자로 변환하는 인코딩부를 포함할 수 있다. 여기서, 상기 제1 시드 및 상기 제2 시드는 상기 인코딩부에 의해 변환된 숫자 형태일 수 있다. 여기서, 상기 사전 학습부는, 상기 제1 시드의 적어도 일부를 마스킹하는 학습 마스킹부; 및 상기 학습 마스킹 부로부터 마스킹된 상기 제1 시드를 이용하여 마스킹된 부분을 예측하도록 인공지능 모델을 학습시키는 예측 학 습부를 포함할 수 있다. 여기서, 상기 마스킹 전략부는, 상기 제2 시드의 적어도 일부를 마스킹하는 전략 마스킹부; 상기 전략 마스킹부 로부터 마스킹된 상기 제2 시드를 상기 인공지능 모델에 입력하여 재구성된 상기 제2 시드를 획득하는 마스킹 예측부; 및 상기 재구성된 상기 제2 시드를 디코딩하여 상기 토큰을 획득하는 결과 디코딩부를 포함할 수 있다. 여기서, 상기 제2 시드의 길이가 길수록 상기 전략 마스킹부에 의해 마스킹되는 단어의 개수는 많아질 수 있다. 여기서, 상기 인코딩부는 단어에 대응되는 숫자 목록을 포함하는 사전(dictionary)에 기초하여 상기 토큰화된 시드를 숫자로 변환할 수 있다. 여기서, 상기 전략 마스킹부는 단어에 대응되는 숫자 목록을 포함하는 사전(dictionary)에 기초하여 상기 제2 시드의 적어도 일부를 마스킹할 수 있다. 여기서, 상기 퍼징부로부터 상기 소프트웨어의 퍼징 실행 결과에 대한 커버리지 정보를 수신하여 커버리지의 증 가 여부를 판단하는 커버리지 분석부를 더 포함할 수 있다. 여기서, 상기 커버리지 분석부는 수신한 커버리지가 이전의 커버리지보다 증가한 경우, 수신한 커버리지에 대응 되는 토큰을 상기 시드 풀에 추가할 수 있다. 여기서, 상기 퍼징부로부터 상기 소프트웨어의 퍼징 실행 결과에 대한 커버리지 정보를 수신하여 커버리지의 증 가 여부를 판단하는 커버리지 분석부를 더 포함하고, 상기 커버리지 분석부는 상기 커버리지의 증가 여부에 기 초하여 상기 사전에 포함된 숫자 목록을 재구성할 수 있다. 일 실시예에 따른 소프트웨어 테스팅 방법은 적어도 하나 이상의 프로세서에 의해 수행되는 소프트웨어 테스팅 방법에 있어서, 시드 풀로부터 유효 시드를 선별하여 제1 시드 및 제2 시드를 제공하는 단계; 상기 제1 시드를 이용하여 인공지능 모델을 학습시키는 단계; 학습된 상기 인공지능 모델을 이용하여 상기 제2 시드를 재구성하 여 토큰을 생성하는 단계; 및 상기 토큰을 소프트웨어에 입력하여 퍼징(fuzzing)을 수행하는 단계를 포함할 수 있다.여기서, 상기 소프트웨어 테스팅 방법을 실행시키도록 컴퓨터로 판독 가능한 기록 매체에 저장된 컴퓨터 프로그 램이 제공될 수 있다."}
{"patent_id": "10-2022-0172074", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면 마스킹된 토큰을 삽입하여 이를 인공지능 모델이 예측하게 함으로써 토큰을 생성 하는 방법이 제공될 수 있다."}
{"patent_id": "10-2022-0172074", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 기재된 실시예는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 본 발명의 사상을 명 확히 설명하기 위한 것이므로, 본 발명이 본 명세서에 기재된 실시예에 한정되는 것은 아니며, 본 발명의 범위 는 본 발명의 사상을 벗어나지 아니하는 수정예 또는 변형예를 포함하는 것으로 해석되어야 한다. 본 명세서에서 사용되는 용어는 본 발명에서의 기능을 고려하여 가능한 현재 널리 사용되고 있는 일반적인 용어 를 선택하였으나 이는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자의 의도, 판례 또는 새로운 기술 의 출현 등에 따라 달라질 수 있다. 다만, 이와 달리 특정한 용어를 임의의 의미로 정의하여 사용하는 경우에는 그 용어의 의미에 관하여 별도로 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌 그 용어가 가진 실질적인 의미와 본 명세서의 전반에 걸친 내용을 토대로 해석되어야 한다. 본 명세서에 첨부된 도면은 본 발명을 용이하게 설명하기 위한 것으로 도면에 도시된 형상은 본 발명의 이해를 돕기 위하여 필요에 따라 과장되어 표시된 것일 수 있으므로 본 발명이 도면에 의해 한정되는 것은 아니다. 본 명세서에서 본 발명에 관련된 공지의 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있 다고 판단되는 경우에 이에 관한 자세한 설명은 필요에 따라 생략하기로 한다. 버그 탐색은 소프트웨어의 실행뿐만 아니라 장치의 보완과도 관련이 있는 중요한 작업이다. 버그 탐색을 위한 동적 분석 방법 중 퍼징(fuzzing)은 입력값을 무작위로 생성하거나 주어진 입력값을 변형하여 소프트웨어의 비 정상적인 동작을 탐지하는 동적 분석 방법이다. 이때, 소프트웨어의 비정상적인 동작이란, 개발자가 고려한대로 소프트웨어가 실행되지 않고 버그가 발생하는 것을 의미한다. 예를들어, 비정상적인 동작은 예상치 못한 값이 출력되는 등의 동작이나, 비정상 종료를 하는 등의 동작일 수 있다. 퍼징은 속도가 빨라 수많은 입력값들을 짧은 시간 내에 테스트할 수 있다는 장점이 있다. 반면, 퍼징은 입력값 을 무작위로 생성하거나 정해진 규칙대로 주어진 입력값을 변형시키기 때문에, 조건이 복잡하거나 한정적인 분 기문에는 진입하기 어렵다는 단점이 있다. 퍼징의 구조적인 입력을 요구하는 소프트웨어에 대한 테스팅적 한계 해결하기 위하여 문법 수준 퍼징(Grammar- level Fuzzing)과 토큰 수준 퍼징(Token-level Fuzzing) 전략이 제안되었다. 문법 수준 퍼징은 퍼저에 문법 템 플릿이나 AST(Abstract Syntax Tree)의 조각을 제공하여 문법에 적합하게 재조합하여 테스트케이스를 생성하는 기법이다. 문법 수준 퍼징(Grammar-level Fuzzing)과 토큰 수준 퍼징(Token-level Fuzzing)은 구조적인 입력을 요구하는 소프트웨어에 적합한 테스팅을 수행하기 위한 퍼징 전략이다. 문법 수준 퍼징은 입력 시드를 시드의 구조 정보 를 담고 있는 IR(Intermediate Representation)이나 AST(Abstract Syntax Tree)로 변환한 후, 조각내어 코퍼스 (corpus)를 구성한다. 또한, 문법 수준 퍼징은 코퍼스에서 조각을 무작위로 선택하여 IR과 AST의 구조에 적합하도록 재조합하여 테스트케이스를 생성하는 기법이다. 처음부터 문법에 적합하지 않는 요소는 조합하지 않기 때 문에 문법 수준 퍼징은 구문론(syntax), 의미론(semantic)적으로 에러를 발생시키지 않으면서도 보안에 위협이 되는 버그를 찾을 수 있다. 하지만 AST나 IR은 특정 대상에 맞춘 특수성을 지니고 있기 때문에 범용적으로 적용하기가 어렵다. 또한 주어진 문법에 준수하지 않는 테스트케이스는 생성하지 못하기 때문에, 문법 수준 퍼징은 문법에 준수하지 않으면서도 발생하는 버그는 찾아내지 못한다는 한계가 있다. 문법 수준 퍼징이 문법을 준수하지 않는 테스트케이스는 생성하지 못한다는 한계를 개선하기 위해서, 토큰 기반 의 토큰 수준 퍼징 기법을 제안되었다. 토큰 수준 퍼징은 입력 시드를 단어 단위로 조각내어 토큰들로 구성된 사전을 구성한다. 사전에 구성된 순서대로 토큰에 숫자를 부여한 후, 입력 시드에 존재하는 토큰을 해당하는 숫 자로 변환하여 숫자의 배열로 인코딩한다. 토큰 수준 퍼징은 인코딩된 시드에 숫자를 바꾸거나 추가로 삽입하거나 삭제하고 교체하는 등의 변이를 통해 새 로운 테스트케이스를 생성한다. 해당 기법은 토큰 단위로 변이를 수행하기 때문에 기존의 비트/바이트 (bit/byte) 수준 퍼징 보다 구문론적인 에러(syntax error)를 적게 발생시키며 문법 수준 퍼징과는 달리 문법에 자유로운 테스트케이스를 생성할 수 있다는 장점이 있다. 또한 단어 단위의 사전만 구성하면 된다는 점에서 AST 나 IR을 구성해야하는 노력보다 훨씬 범용적인 소프트웨어를 대상으로 사용될 수 있다. 하지만 토큰 수준 퍼징은 단순히 최대 65535개의 단어 사전을 무작위로 선택하여 입력 시드를 변이하는 방식을 따르기 때문에 여전히 문법 수준 퍼징에 비하면 에러율이 높으며 유효한 새로운 구조의 테스트케이스를 생성하 기가 어렵다. 때문에 초기 시드에 대한 의존성이 높아 토큰 수준 퍼징만으로는 문법 수준 퍼저가 찾아내는 특정 순서의 입력을 필요로 하는 버그는 찾아내지 못한다는 한계가 있다. 각 퍼징 전략의 분명한 한계로 인하여 구조적인 입력을 필요로하는 소프트웨어에 대한 테스팅은 여전한 도전과 제로 남아있다. 문법 수준 퍼징은 문법에 적합하지 않는 테스트케이스를 생성하지 못하며 토큰 수준 퍼징은 문 법 수준 퍼징의 한계를 개선하였으나 여전히 성능면에서는 문법 수준 퍼징보다 좋다고 보기엔 어렵다. 이러한 한계를 개선하기 위해서는 보다 토큰 수준 퍼징의 변이 기법을 개선할 필요가 존재한다. 위 한계를 극복하기 위해서 본원 발명은 인공지능 모델(딥러닝)을 이용한 퍼징 기술에 대해 제안한다. 도 1은 일 실시예에 따른 소프트웨어 테스팅 장치의 블록도이다. 도 1을 참조하면, 일 실시예에 따른 소프트웨어 테스팅 장치는 전처리부, 사전 학습부, 마스 킹 전략부, 퍼징부 및 커버리지 분석부를 포함할 수 있다. 소프트웨어 테스팅 장치는 도 1의 도시에 한정되지 않고, 이보다 적거나 많은 구성 요소를 포함할 수 있다. 예를 들어, 소프트웨어 테스팅 장치는 단어에 대응되는 숫자 목록을 포함하는 사전(dictionary)을 생성하는 사전화부(도시되지 않음)를 포함할 수 있다. 도 1은 각각의 구성 요소가 별도의 부서 또는 장치인 것으로 도시하였으나, 이에 한정되지 않고, 일부 구성 요 소가 하나의 장치로 구성될 수도 있다. 예를 들어, 전처리부 및 사전 학습부가 하나의 장치(전처리 장치)로 표현될 수 있으나, 이에 한정되지 않는다. 또한 예를 들어, 마스킹 전략부, 퍼징부 및 커 버리지 분석부가 하나의 장치(퍼징 실행 장치)로 표현될 수 있으나, 이에 한정되지 않는다. 소프트웨어 테스팅 장치는 소프트웨어 테스팅 장치의 동작을 총괄하는 제어 프로세서를 포함할 수 있다. 구체적으로, 제어 프로세서는 전처리부, 사전 학습부, 마스킹 전략부, 퍼징부 및 커버리지 분석부에 제어 명령을 보내 각 부서의 동작을 실행할 수 있다. 이하에서 특별한 언급이 없는 경우에는, 소프트웨어 테스팅 장치의 동작은 제어 프로세서의 제어에 의해 수행되는 것으로 해석될 수 있다. 전처리부는 소프트웨어 테스팅을 위한 시드를 인코딩할 수 있다. 전처리부는 퍼징부에서 소 프트웨어 테스팅을 위해 사용될 시드를 제공할 수 있다. 전처리부는 유효한 시드를 선별하고, 시드를 토 큰화 및 인코딩할 수 있다. 구체적으로, 전처리부는 시드 선별부, 토큰화부 및 인코딩부를 포함할 수 있다. 시드 선별부는 시드 풀(seed pool)로부터 유효 시드를 선별할 수 있다. 시드 선별부는 시드가 에러를 유발하지 않는지, 의존성이 존재하는지 여부를 확인하는 과정을 통해 유효 시드를 선별할 수 있다. 시드 선별부 는 시드가 유효하지 않은 비유효 시드로 판별되면, 해당 시드를 시드 풀로부터 제거할 수 있다. 토큰화부는 시드 풀로부터 유효 시드를 획득하여, 시드를 단어 단위의 토큰으로 파싱(parsing)할 수 있다. 구체적으로, 토큰화부는 문장 단위의 단어를 단어 단위로 토큰화할 수 있다. 토큰화부는 유 효 시드를 단어 단위의 토큰 집합으로 분리하여, 토큰화된 시드를 생성할 수 있다. 토큰화부는 토큰을 수 집하여 토큰 사전을 생성할 수 있다. 토큰 사전은 복수의 단어에 대해 각 단어에 대응되는 숫자 목록을 포함할 수 있다. 예를 들어, 토큰 사전은 int 단어에 대해 매칭되는 숫자 10, ; 단어에 매칭되는 숫자 12를 포함할 수 있으나, 이에 한정되지 않는다. 토큰 사전은 각 단어마다 매칭되는 숫자에 대한 정보를 포함할 수 있다. 이때, 토큰 사전은 토큰이 중복되지 않도록 토큰들을 수집할 수 있다. 또한, 토큰 사전은 모든 토큰에 대한 정 보가 아닌 유효 시드들의 토큰 빈도 수에 기초하여 빈도 수가 일정 횟수 이상인 토큰에 대한 정보만을 포함할 수 있다. 구체적으로, 토큰화부는 유효 시드들의 토큰 빈도 수를 확인하고, 빈도 수가 일정 횟수 이상인 경우에만 토큰 사전에 해당 토큰을 추가할 수 있다. 만약, 토큰의 빈도 수가 일정 횟수를 넘지 않는 경우, 퍼징 에 유효하지 않는 토큰으로 판단될 수 있다. 이때, 토큰화부는 해당 토큰을 무명 토큰(unknown 토큰)으로 명명하여 토큰 사전에 무명 토큰으로 추가할 수 있다. 토큰 사전은 마스킹에 대응되는 숫자를 포함할 수 있다. 예를 들어, 토큰 사전은 마스킹(masking)에 대해 0을 매칭하도록 하는 정보를 포함할 수 있다. 마스킹에 대응되는 숫자는 사전 학습부의 학습 마스킹부 및 마스킹 전략부의 전략 마스킹부에 의해 사용될 수 있다. 위 예시에서는 토큰화부가 토큰 사전을 생성하는 것으로 설명하였으나, 이에 한정되지 않고, 토큰 사전을 생성하는 사전화부가 별도로 존재할 수도 있다. 인코딩부는 토큰화부에 의해 토큰화된 시드를 숫자로 변환할 수 있다. 구체적으로, 인코딩부(113 0)는 토큰 사전에 기초하여 토큰화된 시드를 대응되는 숫자로 매칭하는 인코딩 작업을 수행할 수 있다. 인코딩 부에 의해 숫자로 변환된 시드는 수집되어 사전 학습부 및 마스킹 전략부의 작업에 사용될 수 있다. 사전 학습부는 전처리부로부터 시드를 제공받아 인공지능 모델을 학습시킬 수 있다. 사전 학습부 는 전처리된 시드를 데이터로 사용하여 자연어 처리 딥러닝 모델이 마스킹된 토큰을 예측하도록 딥러닝 모델을 학습시킬 수 있다. 구체적으로, 사전 학습부는 시드의 적어도 일부를 마스킹하는 학습 마스킹부 및 학습 마스킹부로부터 마스킹된 시드를 이용하여 마스킹된 부분을 예측하도록 인공지능 모델을 학습시키는 예측 학습부를 포함할 수 있다. 마스킹 전략부는 사전 학습부에 의해 학습된 인공지능 모델을 이용하여 전처리부로부터 제공 받은 시드를 재구성하고, 재구성된 시드에 기초하여 토큰을 생성할 수 있다. 구체적으로, 마스킹 전략부 는 시드의 적어도 일부를 마스킹하는 전략 마스킹부, 전략 마스킹부로부터 마스킹된 시드를 인공지 능 모델에 입력하여 시드를 재구성시키는 마스킹 예측부 및 재구성된 시드를 디코딩하여 토큰을 획득하는 결과 디코딩부를 포함할 수 있다. 전략 마스킹부는 전처리부로부터 시드를 획득하고, 토큰 사전에 기초하여 시드의 적어도 일부를 마 스킹할 수 있다. 예를 들어, 전략 마스킹부는 토큰화된 시드인 int, a, =, ;가 인코딩 10, 30, 21, 12를 전처리부로부터 획득할 수 있다. 전략 마스킹부는 10, 30, 21, 12의 인코딩된 시드를 10, masking, 21, 12로 마스킹처리 할 수 있고, 토큰 사전에 기초하여 이를 10, 0, 21, 12로 변환시킬 수 있다. 마스킹의 위치 및 마스킹되는 토큰의 개수는 환경에 따라 설정될 수 있다. 예를 들어, 시드의 길이가 길수록 마 스킹의 개수는 많아질 수 있다. 또한 예를 들어, 시드의 길이의 0.1배수 미만을 마스킹의 개수로 설정할 수도 있다. 이때, 인공지능 모델의 실행 속도 및 에너지 자원을 고려하여 마스킹의 최대 개수가 설정될 수 있다. 예 를 들어, 마스킹의 개수는 최대 3개로 설정될 수 있으나, 이에 한정되지 않는다. 마스킹의 위치는 전략 마스킹부에 의해 랜덤하게 설정될 수 있다. 마스킹의 개수가 많아질수록 인공지능 모델의 학습 난이도는 높아질 수 있다. 즉, 인공지능 모델의 학습 난이도는 마스킹의 개수에 의해 조절될 수 있 다. 마스킹 예측부는 전략 마스킹부로부터 마스킹된 시드를 사전 학습부에 의해 학습된 인공지능 모델에 입력할 수 있다. 인공지능 모델은 마스킹된 부분을 예측하여 결과를 산출할 수 있다. 예를 들어, 위 예 시에서 10, 0, 21, 12를 입력받은 인공지능 모델은 결과로 마스킹 전의 인코딩된 시드와 동일한 10, 30, 21, 12 를 출력할 수 있다. 또는 인공지능 모델은 결과로 마스킹 전의 인코딩된 시드와 상이한 10, 11, 21, 12를 출력 할 수 있다. 인공지능 모델의 결과값은 재구성된 시드일 수 있다. 위 예시에서 인공지능 모델은 마스킹된 부분을 정확하게 예측할 수도 있으나, 오답을 제시할 수도 있다. 그러나, 본원 발명에서는 인공지능 모델이 정확하게 정답을 예 측하는 것은 중요하지 않다. 인공지능 모델이 정확하게 정답을 예측하지 않더라도, 시드는 새롭게 재구성되어 소프트웨어에 대한 퍼징을 수행할 수 있는 입력값을 제시할 수 있기 때문이다. 즉, 본원 발명은 인공지능 모델 이 재구성한 시드에 기초하여 소프트웨어의 취약점을 찾아내는 것이 중요하다. 따라서, 인공지능 모델이 정답을 출력하지 않더라도, 최대 65535개의 단어 사전을 사용하는 토큰 수준 퍼징보다는 새로운 구조의 테스트케이스를 생성할 수 있으므로, 본원 발명의 장치는 종래의 토큰 수준 퍼징보다 개선된 결과를 도출할 수 있다. 결과 디코딩부는 인공지능 모델이 출력한 재구성된 시드를 획득하고, 토큰 사전에 기초하여 재구성된 시 드를 디코딩할 수 있다. 구체적으로, 결과 디코딩부는 토큰 사전에 기초하여 숫자로 인코딩된 토큰을 단 어 토큰으로 변환할 수 있다. 예를 들어, 위 예시에서 결과 디코딩부는 10, 30, 21, 12를 int, a, =, ; 로 디코딩하여 토큰을 획득할 수 있다. 또는 위 예시에서 결과 디코딩부는 10, 11, 21, 12를 int, b, =, ;로 디코딩하여 토큰을 획득할 수 있다. 퍼징부는 마스킹 전략부로부터 생성된 토큰을 소프트웨어에 입력하여 퍼징(fuzzing)을 실행할 수 있다. 구체적으로, 퍼징부는 인공지능 모델에 의해 재구성되고 결과 디코딩부에 의해 디코딩된 단 어 형태의 토큰을 테스트 대상 소프트웨어에 입력할 수 있다. 퍼징부는 소프트웨어 실행 결과인 커버리지 를 출력할 수 있다. 커버리지 분석부는 퍼징부의 소프트웨어 퍼징 실행 결과에 대한 커버리지 정보를 수신할 수 있다. 커버리지 분석부는 커버리지의 증가 여부를 판단하여 재구성 및 디코딩된 토큰을 시드 풀에 추가하거나 해당 토큰을 이용하여 인공지능 모델을 재학습시킬 수 있다. 도 2는 일 실시예에 따른 소프트웨어 테스팅 방법의 순서도이다. 도 2를 참조하면, 일 실시예에 따른 소프트웨어 테스팅 방법은 전처리된 시드를 제공하는 단계(S100), 인공지능 모델을 학습시키는 단계(S200), 인공지능 모델을 이용하여 시드를 재구성하고 토큰을 생성하는 단계(S300), 생 성된 토큰을 이용하여 소프트웨어를 테스트하는 단계(S400), 커버리지를 분석하는 단계(S500) 및 인공지능 모델 을 재학습시키는 단계(S600)를 포함할 수 있다. 도 2는 단계 S100 내지 단계 S600이 순서대로 수행되는 것을 도 시하였으나, 이에 한정되지 않고 각 단계의 순서가 변경되거나 일부 단계가 생략되거나 새로운 단계가 추가될 수 있다. 예를 들어, 커버리지 분석 결과에 따라 단계 S600이 생략될 수 있다. 전처리된 시드를 제공하는 단계(S100)는 전처리부에서 시드 풀로부터 유효 시드를 선별하고 유효 시드를 토큰화 및 인코딩하는 단계일 수 있다. 이에 대한 자세한 설명은 도 3을 참조하여 후술한다. 인공지능 모델을 학습시키는 단계(S200)는 사전 학습부가 시드의 적어도 일부가 마스킹된 시드를 이용하 여, 인공지능 모델이 마스킹된 부분을 예측할 수 있도록 인공지능 모델을 학습시키는 단계일 수 있다. 이에 대 한 자세한 설명은 도 4를 참조하여 후술한다. 인공지능 모델을 이용하여 시드를 재구성하고 토큰을 생성하는 단계(S300)는 마스킹 전략부가 시드의 적 어도 일부를 마스킹하고, 인공지능 모델을 이용하여 마스킹된 부분을 예측하고, 예측된 부분을 이용하여 시드를 재구성 및 디코딩하는 단계일 수 있다. 이에 대한 자세한 설명은 도 5를 참조하여 후술한다. 생성된 토큰을 이용하여 소프트웨어를 테스트하는 단계(S400)는 퍼징부가 마스킹 전략부에 의해 재 구성 및 디코딩된 시드를 소프트웨어에 입력하여 소프트웨어에 대해 퍼징을 수행하는 단계일 수 있다. 퍼징부 는 퍼징의 탐색 지표로 활용될 수 있는 소프트웨어에서 실행된 코드의 범위인 커버리지를 측정할 수 있다. 커버리지를 분석하는 단계(S500)는 커버리지 분석부가 퍼징부로부터 커버리지 정보를 수신하여 이 를 분석하는 단계일 수 있다. 인공지능 모델을 재학습시키는 단계(S600)는 커버리지 분석부의 분석 결과 에 기초하여 퍼징부가 사용한 토큰을 이용해 인공지능 모델을 재학습시키는 단계일 수 있다. 단계 S500및 단계 S600에 대한 자세한 설명은 도 6을 참조하여 후술한다. 도 3은 일 실시예에 따른 시드 제공을 위한 전처리 방법의 순서도이다. 도 3은 일 실시예에 따른 시드 제공을 위한 전처리 방법은 유효 시드를 선별하는 단계(S110), 시드를 토큰화하 는 단계(S120), 토큰화된 시드를 인코딩하는 단계(S130), 인코딩된 시드 풀에 인코딩된 시드를 추가하는 단계 (S140) 및 인코딩된 시드 풀로부터 시드를 제공하는 단계(S150)를 포함할 수 있다. 도 3은 단계 S110 내지 단계 S150이 순서대로 수행되는 것을 도시하였으나, 이에 한정되지 않고 각 단계의 순서가 변경되거나 일부 단계가 생략되거나 새로운 단계가 추가될 수 있다. 예를 들어, 단계 S140 및 단계 S150이 동시에 수행될 수 있으나, 이 에 한정되지 않는다. 유효 시드를 선별하는 단계(S110)는 시드 선별부가 시드 풀로부터 유효 시드를 선별하는 단계일 수 있다. 이때, 시드 풀은 테스트 대상 소프트웨어에서 제공하는 테스트 묶음(testsuite)을 수집하여 생성될 수 있다. 테 스트 묶음은 소프트웨어가 자체적으로 소프트웨어를 테스트하기 위해 생성한 회귀 테스트(regression test) 등 을 의미하는 것일 수 있다. 시드 선별부는 시드 풀의 시드가 에러를 유발하지 않는지, 의존성이 존재하는지에 대한 여부를 확인할 수 있다. 해당 과정을 통해 시드 선별부는 유효하지 않은 시드를 시드 풀로부터 제거할 수 있다. 이때, 시드 풀은 테스트 대상 소프트웨어에서 제공하는 테스트 묶음(testsuite)을 수집하여 생성될 수 있다. 테스트 묶음은 소프트웨어가 자체적으로 소프트웨어를 테스트하기 위해 생성한 회귀 테스트(regression test) 등을 의미하는 것일 수 있다. 시드를 토큰화하는 단계(S120)는 단계 S110에서 선별된 유효 시드를 토큰화부가 단어 단위의 토큰 집합으 로 분리하는 단계일 수 있다. 유효 시드는 문장 단위 형태이기 때문에, 이를 단어 단위로 분리하는 토큰화 단계 가 필요하다. 단계 S130 수행 전, 토큰화된 시드를 이용하여 토큰 사전을 생성하는 단계가 추가될 수 있다. 토 큰 사전은 토큰화부 또는 별도의 사전화부에 의해 생성될 수 있다. 토큰 사전에 대한 내용은 전술한 내용 과 중복될 수 있어, 자세한 설명은 생략한다. 토큰화된 시드를 인코딩하는 단계(S130)는 인코딩부가 토큰 사전에 기초하여 단어 형태의 토큰화된 시드 를 숫자 형태로 변환하는 단계일 수 있다. 인코딩부는 토큰 사전에 기초하여 토큰들을 각 토큰의 단어에 대응되는 숫자로 변환할 수 있다. 인코딩부는 최종적으로 숫자가 배열된 형태의 시드를 생성할 수 있다. 인코딩된 시드 풀에 인코딩된 시드를 추가하는 단계(S140)는 인코딩부에 의해 생성된 숫자 형태의 시드가 시드 풀에 저장되는 단계일 수 있다. 인코딩된 시드 풀로부터 시드를 제공하는 단계(S150)는 시드 풀에 저장된 숫자 형태의 시드가 사전 학습부 및 마스킹 전략부에 제공되는 단계일 수 있다. 구체적으로, 사전 학습부에는 제1 시드를 포 함하는 복수의 시드가 제공되어 인공지능 모델의 학습에 이용될 수 있다. 또한, 마스킹 전략부에는 제2 시드가 제공되어 소프트웨어의 퍼징을 위해 제2 시드가 재구성될 수 있다. 이때, 제1 시드 및 제2 시드는 동일 한 시드일 수도 있고, 상이한 시드일 수도 있다. 도 4는 일 실시예에 따른 시드를 이용한 인공지능 모델 학습 방법의 순서도이다. 도 4를 참조하면, 일 실시예에 따른 시드를 이용한 인공지능 모델 학습 방법은 시드 풀로부터 시드를 획득하는 단계(S210), 시드를 마스킹하는 단계(S220), 마스킹된 시드를 이용하여 인공지능 모델을 학습시키는 단계(S230) 및 학습된 인공지능 모델을 저장하는 단계(S240)를 포함할 수 있다. 도 4는 단계 S210 내지 단계 S240이 순서대 로 수행되는 것을 도시하였으나, 이에 한정되지 않고 각 단계의 순서가 변경되거나 일부 단계가 생략되거나 새 로운 단계가 추가될 수 있다. 시드 풀로부터 시드를 획득하는 단계(S210)는 학습 마스킹부가 전처리부로부터 시드 풀의 유효 시 드를 획득하는 단계일 수 있다. 시드를 마스킹하는 단계(S220)는 학습 마스킹부가 획득한 유효 시드의 적어도 일부를 마스킹하는 단계일 수 있다. 구체적으로, 학습 마스킹부는 유효 시드의 적어도 일부를 마스킹하여 토큰 사전에 따라 숫자로 변환할 수 있다(단어로 마스킹 후 인코딩). 또는 학습 마스킹부는 유효 시드의 적어도 일부를 마스킹에대응되는 숫자로 변환할 수도 있다(숫자로 마스킹). 이때, 학습 마스킹부는 마스킹의 위치 및 마스킹의 개수를 환경에 따라 설정할 수 있다. 구체적으로, 학 습 마스킹부는 마스킹되는 토큰의 위치를 랜덤하게 설정할 수 있다. 또한, 학습 마스킹부는 마스킹 의 개수를 시드의 길이에 기초하여 설정할 수 있다. 마스킹된 시드를 이용하여 인공지능 모델을 학습시키는 단계(S230)는 학습 마스킹부에 의해 적어도 일부 가 마스킹된 시드를 예측 학습부가 인공지능 모델에 입력시키는 단계일 수 있다. 인공지능 모델은 마스킹 된 위치에 어떤 토큰이 위치하는지를 예측함으로써 학습될 수 있다. 학습된 인공지능 모델을 저장하는 단계(S240)는 단계 S230에 의해 학습된 모델이 소프트웨어 테스팅 장치(100 0)의 데이터베이스부 내에 저장되는 단계일 수 있다. 이때, 데이터베이스부는 소프트웨어 테스팅 장치가 동작하는데 필요한 각종 데이터 및 프로그램을 저장할 수 있다. 데이터베이스부는 소프트웨어 테스팅 장 치가 획득하는 정보 및 처리하는 정보 모두를 저장할 수 있다. 데이터베이스부는 데이터를 임시적으로 또는 반영구적으로 저장할 수 있다. 예를 들어, 데이터베이스부는 하드 디스크(HDD: Hard Disk Drive), SSD(Solid State Drive), 플래쉬 메모리(flash memory), 롬(ROM: Read-Only Memory), 램(RAM: Random Access Memory) 또는 클라우드 스토리지(Cloud Storage) 등일 수 있으나, 이에 한정 되지 않고 데이터를 저장하기 위한 다양한 모듈로 구현될 수 있다. 도 5는 일 실시예에 따른 시드 재구성 및 토큰 생성 방법의 순서도이다. 도 5를 참조하면, 일 실시예에 따른 시드 재구성 및 토큰 생성 방법은 시드 풀로부터 시드를 획득하는 단계 (S310), 시드를 마스킹하는 단계(S320), 마스킹된 시드를 인공지능 모델에 입력하여 시드를 재구성하는 단계 (S330), 재구성된 시드를 디코딩하여 토큰을 생성하는 단계(S340) 및 생성된 토큰을 제공하는 단계(S350)를 포 함할 수 있다. 도 5는 단계 S310 내지 단계 S350이 순서대로 수행되는 것을 도시하였으나, 이에 한정되지 않고 각 단계의 순서가 변경되거나 일부 단계가 생략되거나 새로운 단계가 추가될 수 있다. 시드 풀로부터 시드를 획득하는 단계(S310)는 전략 마스킹부가 전처리부로부터 시드 풀의 유효 시 드를 획득하는 단계일 수 있다. 시드를 마스킹하는 단계(S320)는 전략 마스킹부가 획득한 유효 시드의 적어도 일부를 마스킹하는 단계일 수 있다. 구체적으로, 전략 마스킹부는 유효 시드의 적어도 일부를 마스킹하여 토큰 사전에 따라 숫자로 변환할 수 있다(단어로 마스킹 후 인코딩). 또는 학습 마스킹부는 유효 시드의 적어도 일부를 마스킹에 대응되는 숫자로 변환할 수도 있다(숫자로 마스킹). 이때, 전략 마스킹부는 마스킹의 위치 및 마스킹의 개수를 환경에 따라 설정할 수 있다. 구체적으로, 전 략 마스킹부는 마스킹되는 토큰의 위치를 랜덤하게 설정할 수 있다. 또한, 전략 마스킹부는 마스킹 의 개수를 시드의 길이에 기초하여 설정할 수 있다. 전략 마스킹부는 학습 마스킹부와 동일한 작업을 수행할 수 있다. 따라서, 경우에 따라 전략 마스 킹부 및 학습 마스킹부는 하나의 마스킹부로 통합될 수 있다. 예를 들어, 통합된 마스킹부는 사전 학습부 및 마스킹 전략부의 과정 중 마스킹 과정을 담당할 수 있다. 그러나, 이에 한정되지 않고, 두 마스킹부가 통합되지 않고 도 1과 같이 각각 사전 학습부 및 마스킹 전략부에 포함될 수도 있다. 마스킹된 시드를 인공지능 모델에 입력하여 시드를 재구성하는 단계(S330)는 마스킹 예측부가 전략 마스 킹부에 의해 적어도 일부가 마스킹된 시드를 인공지능 모델에 입력시키는 단계일 수 있다. 이때, 인공지 능 모델은 사전 학습부에 의해 학습된 모델로서, 마스킹된 시드의 마스킹 부분에 어떤 토큰이 위치하는지 를 예측할 수 있다. 인공지능 모델은 토큰을 예측하여 결과로 재구성된 토큰을 출력할 수 있다. 재구성된 시드를 디코딩하여 토큰을 생성하는 단계(S340)는 결과 디코딩부가 인공지능 모델의 결과인 재 구성된 토큰을 디코딩하여 숫자 형태에서 단어 형태로 변환하는 단계일 수 있다. 생성된 토큰을 제공하는 단계(S350)는 결과 디코딩부가 디코딩된 토큰을 소프트웨어 테스팅 장치의 데이터베이스부에 저장하고 이를 퍼징부에 제공하는 단계일 수 있다. 퍼징부는 재구성 및 디코딩된 시드인 토큰을 획득하여 소프트웨어의 테스팅을 위해 사용할 수 있다. 구체적으로, 퍼징부는 테스팅 대상소트프웨어에 토큰을 입력하여 퍼징을 실행함으로써 소프트웨어를 테스트하고, 퍼징 실행 결과인 커버리지를 측 정할 수 있다. 퍼징부의 실행에 오류가 있거나, 커버리지에 에러 값이 도출되는 경우, 테스트 대상 소프트웨어의 퍼징에 버그가 생긴 것으로 판단될 수 있다. 이때, 퍼징부는 버그에 관한 알림을 제공할 수 있다. 소프트웨어 검 수자는 퍼징부로부터 버그에 관한 알림을 수신하여 소프트웨어 및 퍼징과 관련된 오류를 검출 및 수정할 수 있다. 도 6은 일 실시예에 따른 커버리지 분석 및 인공지능 모델 재학습 방법의 순서도이다. 도 6을 참조하면, 일 실시예에 따른 커버리지 분석 및 인공지능 모델 재학습 방법은 퍼징 실행 결과에 대한 커 버리지 정보를 수신하는 단계(S510), 커버지리가 증가했는지 여부를 판단하는 단계(S520), 커버리지가 증가한 경우, 토큰을 시드 풀에 추가하는 단계(S530), 커버지리가 증가하지 않은 경우, 단계 S310을 실행하는 단계 및 추가된 토큰을 이용하여 인공지능 모델을 재학습시키는 단계(S600)를 포함할 수 있다. 퍼징 실행 결과에 대한 커버리지 정보를 수신하는 단계(S510)는 커버리지 분석부가 퍼징부로부터 커버리지 정보를 수신하는 단계일 수 있다. 이때, 커버리지 정보는 테스트 대상 소프트웨어의 소스 코드의 함수, 라인, 블록, 결정, 엣지, 분기 및 조건 중 적어도 하나와 관련된 커버리지일 수 있다. 커버지리가 증가했는지 여부를 판단하는 단계(S520)는 커버리지 분석부가 이전 퍼징 실행 결과에 대한 커 버리지와 현재 퍼징 실행 결과에 대한 커버리지를 비교하여, 이전보다 커버리지가 증가했는지 여부를 판단하는 단계일 수 있다. 커버리지가 증가했다는 것은 입력한 토큰에 대해 테스트 대상 소프트웨어가 많이 실행되었다는 것을 의미하는 것이므로, 커버리지가 계속적으로 증가하게 되는 토큰은 유효 시드 중 특별한 시드로 분류될 수 있다. 따라서, 상기 토큰을 계속적으로 재구성하거나 상기 토큰을 이용하여 인공지능 모델을 재학습시켜 소프트 웨어 테스팅 장치의 성능을 증가시킬 수 있다. 커버리지가 증가한 경우, 토큰을 시드 풀에 추가하는 단계(S530)는 커버리지 분석부의 판단 결과 커버리 지가 증가한 경우, 토큰에 대한 재구성 및 이를 이용한 인공지능 모델 재학습이 수행될 수 있도록, 커버리지를 증가시킨 토큰을 시드 풀에 추가하는 단계일 수 있다. 커버지리가 증가하지 않은 경우, 단계 S310을 실행하는 단계는 커버리지 분석부의 판단 결과 커버리지가 더 이상 증가하지 않는다거나 커버리지가 감소하게 되는 경우, 다른 토큰을 이용할 수 있도록 도 5의 단계 S310 을 실행하는 단계일 수 있다. 커버리지가 감소하는 경우, 소프트웨어를 테스팅하는 데에 적합하지 않은 시드로 판단될 수 있다. 따라서, 시드 풀에서 다른 시드를 선택할 수 있도록 단계 S310이 실행될 수 있다. 또는 커버리지가 증가하다가 일정 수치에 수렴하여 더 이상 증가하지 않거나, 최대 커버리지 수치를 가지게 될 경우, 해당 토큰으로 더 나은 결과를 얻지 못하는 상황일 수 있다. 따라서, 시드 풀에서 다른 시드를 선택할 수 있도록 단계 S310이 실행될 수 있다. 추가된 토큰을 이용하여 인공지능 모델을 재학습시키는 단계(S600)는 단계 S530에서 시드 풀에 추가된 토큰을 이용하여 사전 학습부가 인공지능 모델을 재학습시키는 단계일 수 있다. 사전 학습부는 재학습시킨 인공지능 모델을 데이터베이스부에 새롭게 저장하고, 저장된 인공지능 모델은 마스킹 전략부의 마스킹 예 측부를 통해 마스킹된 부분을 예측하는 데에 사용될 수 있다. 본원 발명은 토큰 수준 퍼징의 변이 기법에 대해 무작위로 토큰을 바꾸는 것이 아니라, 먼저 마스크 토큰으로 대체하고 마스크를 인공지능 모델(딥러닝 모델)이 예측하게 하여 변이를 최적화할 수 있다. 대상 소프트웨어의 테스트 묶음(testsuite)을 수집하는 것으로 신경망을 학습시켜, 커버리지가 증가하는 변이된 테스트케이스를 추 가적으로 학습하는 종래의 기술보다 효과적으로 변이를 수행하도록 할 수 있다. 따라서, 종래의 토큰 수준 퍼징 보다 더 효과적인 퍼징이 수행될 수 있다. 규모가 방대한 소프트웨어를 개발 단계에서 모두 찾는 것은 거의 불가능에 가까운 일이며 자동화하지 않고 찾는 것은 많은 인력과 비용이 든다. 때문에 다양한 소프트웨어에서 버그를 비교적 빠른 시간 내에 탐지할 수 있는 기술이 필요하다. 따라서, 본원 발명은 효율적인 성능을 초래할 수 있는 소프트웨어 테스팅 장치를 제공함으로 써 소프트웨어 보안 시장 전체에 기여할 수 있는 바가 클 것이다.실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD- ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다"}
{"patent_id": "10-2022-0172074", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2022-0172074", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 소프트웨어 테스팅 장치의 블록도이다. 도 2는 일 실시예에 따른 소프트웨어 테스팅 방법의 순서도이다. 도 3은 일 실시예에 따른 시드 제공을 위한 전처리 방법의 순서도이다. 도 4는 일 실시예에 따른 시드를 이용한 인공지능 모델 학습 방법의 순서도이다. 도 5는 일 실시예에 따른 시드 재구성 및 토큰 생성 방법의 순서도이다. 도 6은 일 실시예에 따른 커버리지 분석 및 인공지능 모델 재학습 방법의 순서도이다."}
