{"patent_id": "10-2021-0078468", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0168681", "출원번호": "10-2021-0078468", "발명의 명칭": "인공신경망 연산 장치", "출원인": "서강대학교산학협력단", "발명자": "최우영"}}
{"patent_id": "10-2021-0078468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 방향 및 상기 제1 방향과 수직한 제2 방향을 따라 일정간격 이격되어 배치된 시냅스 어레이를 포함하는 이진 신경망 아키텍쳐에 있어서,상기 시냅스 어레이는 다수의 시냅스 소자를 포함하며,각각의 시냅스 소자는 상기 제1 방향을 따라 인접하여 배치된 제1터널링 전계 효과 트랜지스터(TFET) 및 제2 터널링 전계 효과 트랜지스터(TFET)들을 포함하고, 상기 제1 터널링 전계 효과 트랜지스터 및 상기 제2 터널링 전계 효과 트랜지스터는 각각 게이트 전극, 드레인 단자 및 소스 단자를 포함하는 것을 특징으로 하는 인공연산망장치."}
{"patent_id": "10-2021-0078468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 이진 신경망 아키텍쳐는상기 제1 방향을 따라 연장되어 배치된 복수의 비트라인; 및상기 제2 방향을 따라 연장되어 배치된 복수의 워드라인을 포함하며, 상기 시냅스 소자는 상기 비트라인과 워드라인이 교차하는 영역에 위치된 것을 특징으로 하는 인공연산망 장치."}
{"patent_id": "10-2021-0078468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 제1 터널링 전계 효과 트랜지스터 및 상기 제2 터널링 전계 효과 트랜지스터의 상기 게이트는 상기 워드라인과 접속하는 것을 특징으로 하는 인공신경망 연산 장치."}
{"patent_id": "10-2021-0078468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 제1 터널링 전계 효과 트랜지스터 및 상기 제2 터널링 전계 효과 트랜지스터의 상기 드레인 단자는 상기비트라인과 연결된 것을 특징으로 하는 인공신경망 연산 장치."}
{"patent_id": "10-2021-0078468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 제1 터널링 전계 효과 트랜지스터 및 상기 제2 터널링 전계 효과 트랜지스터의 상기 소스 단자는 메탈 라인과 접속되어 그라운드(GND)에 연결된 것을 특징으로 하는 인공신경망 연산 장치."}
{"patent_id": "10-2021-0078468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 제1 터널링 전계 효과 트랜지스터 및 제2 터널링 전계 효과 트랜지스터는 반도체 기판 상부에 형성된 게이트 패턴;공개특허 10-2022-0168681-3-상기 게이트 패턴 하부에 위치한 채널 영역; 및상기 게이트 패턴 양측의 상기 반도체 기판 내에 형성된 소스 영역 및 드레인 영역을 포함하며, 상기 게이트 패턴은 하부 산화막, 질화막, 상부 산화막 및 게이트 전극층의 적층 구조로 형성된 것을 특징으로 하는 인공신경망 연산 장치."}
{"patent_id": "10-2021-0078468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 제1 터널링 전계 효과 트랜지스터 및 제2 터널링 전계 효과 트랜지스터의 상기 드레인 영역은 콘택 플러그를 통해 비트라인과 연결되고, 상기 소스 영역은 콘택 플러그를 통해 메탈 라인과 연결되며, 상기 게이트 전극층은 콘택 플러그를 통해 워드라인과 연결되어 시냅스 소자를 구성하는 것을 특징으로 하는 인공신경망 연산 장치."}
{"patent_id": "10-2021-0078468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 시냅스 소자로 활용되는 터널링 전계 효과 트랜지스터는 프로그램(program) 및 이레이즈(erase) 동작을 수행하며, XNOR 동작 구현을 통해 이진 신경망 연산을 수행하는 것을 특징으로 하는 인공신경망 연산 장치."}
{"patent_id": "10-2021-0078468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 각각의 시냅스 소자들의 가중치(Weight) 값을 개별적으로 제어하여 입력(Input) 값에 따른 출력(Output)값을 나타내는 것을 특징으로 하는 인공신경망 연산 장치."}
{"patent_id": "10-2021-0078468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 시냅스 어레이는 비트라인에 흐르는 전류 값(IBL)과 기준 전류 값(IREF)에 따라 출력 값이 결정하는 CSA 블록(Conditional sumadder); 및 각 시냅스 소자에 대한 비교 결과값들을 순차적으로 입력 받아 처리하고, 최종 결과값을 출력하는 가산기(Adder)와 비교회로(Comparator)를 더 포함하는 것을 특징으로 하는 인공신경망 연산 장치."}
{"patent_id": "10-2021-0078468", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공연산망 장치에 관한 것으로, 제1 방향 및 상기 제1 방향과 수직한 제2 방향을 따라 일정간격 이격 되어 배치된 시냅스 어레이를 포함하는 이진 신경망 아키텍쳐에 있어서, 상기 시냅스 어레이는 다수의 시냅스 소 자를 포함하며, 각각의 시냅스 소자는 상기 제1 방향을 따라 인접하여 배치된 제1터널링 전계 효과 트랜지스터 (TFET) 및 제2 터널링 전계 효과 트랜지스터(TFET)들을 포함하고, 상기 제1 터널링 전계 효과 트랜지스터 및 상 기 제2 터널링 전계 효과 트랜지스터는 각각 게이트 전극, 드레인 단자 및 소스 단자를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2021-0078468", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공신경망 연산 장치에 관한 것으로, 보다 상세하게는 터널링 전계 효과 트랜지스터(TFET)를 이용한 초저전력 시냅스 소자를 기반으로 하는 인경신경망 연산 장치에 관한 것이다."}
{"patent_id": "10-2021-0078468", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "무어의 법칙이 종말을 맞이하고 기존의 von Neumann 구조의 한계가 명확해짐에 따라 이를 극복하고자 인공 신경 망 (인공지능) 및 이를 구현하기 위한 시냅스 소자에 대한 연구가 활발하게 이루어지고 있다. 기존 von Neumann 구조의 경우 비록 CPU를 통한 고속 연산이 가능하지만 근본적으로 메모리와 CPU가 분리되어 있기에 병렬 연산이어려운 단점이 존재하며, 이는 향후 big data를 처리하는데 있어서 장애물이 될 것으로 예상된다. 그러나 신경 망 구조의 경우에는 개별 시냅스 소자의 속도는 기존 CPU의 연산 처리 속도에 훨씬 미치지 못하지만 병렬 연산 이 가능하다는 장점이 있으며, 이에 하드웨어 기반 인공 신경망 연산 체계는 neuromorphic computing system이 라 불리며, 기존 반도체 소자 기술을 이용하여 하드웨어가 인간의 신경계인 synapse, neuron, axon 등을 모방하 고자 하는 새로운 개념으로 제안되고 있다. 하드웨어 기반의 시냅스 소자를 통해 학습을 진행하는 방식에는 크게 on-chip learning과 off-chip learning의 두 가지 방식이 존재하며, 전자는 생물학적 학습 특성을 그대로 모방하는 방식으로 학습의 전반적인 과정이 각 각의 소자 내부에서 동시 다발적으로 일어나며 주로 STDP 방식을 차용한다. 그러나 그 학습 방법이 완벽하다 할 지라도 학습 횟수가 이를 구성하는 시냅스 소자의 endurance 특성에 의해 크게 제한된다는 명확한 단점이 존재 한다. 반면, 후자는 기존 von Neumann 기반의 소프트웨어 인공지능 알고리즘을 통해 미리 학습을 진행하고 그 결과 (synaptic weight)를 하드웨어에 이식하는 형태로, 이때 하드웨어 상에 이식된 결과에 대해 주로 추론만을 진행하므로 전자의 방식과는 달리 소자의 신뢰성에 의한 영향을 크게 줄일 수 있다는 장점이 있다. 이는 기존 소프트웨어와 하드웨어 기반의 인공 신경망 형성 기술의 장점을 결합한 형태로 주로 edge computing 구현을 목 적으로 하여 활발하게 연구되고 있다. 기존 하드웨어 기반 인공지능 연구에서는 생물학적 시냅스 특성을 구현하기 위해 저항성 메모리 (RRAM)을 비롯 한 MRAM, PCRAM 등의 다양한 메모리 소자들에 대한 연구가 활발히 진행 중이나, 이와 같은 memristor라 불리는 메모리 소자들은 모두 2단자 형태로 구성되어 있으므로 이에 대한 제어(read/write)를 위한 회로들이 반드시 필 요하며, 또한 소자의 신뢰성이 지극히 낮다는 단점이 있다. 그리고 memristor를 형성하기 위해 사용되는 대부분 의 물질들은 기존 반도체 공정과 호환되지 않는다는 큰 단점이 존재하여 이에 기존 MOSFET 기반의 flash memory 를 이용한 시냅스 소자 연구 또한 진행되고 있는 상태이다. 한국등록특허 제10-1950786호는 분산처리용 인공신경망 연산 가속화 방법에 관한 것으로, 단일의 호스트 가속화 장치와 복수개의 슬레이브 가속화 장치를 포함하여 입력 뉴런들에 대한 입력데이터가 M개의 깊이와 N개의 계층 으로 구성되는 인공신경망 처리를 가속화하는 방법에 있어서, 인공신경망을 구성하는 뉴런들에 대한 입력데이터 와 시냅스 가중치를 입력데이터를 구성하는 깊이, 계층 구조, 신경망 네트워크 또는 이들의 조합 단위로 나누어 각각의 가속화장치에서 연산이 가능하게 하는 것을 특징으로 한다. 한국 공개특허 제10-2019-0007143호는 뉴로모픽 연산 장치에 관한 것으로, 펄스폭 변조기, 시냅스 어레이, 발진 기, 카운터, 및 보상기를 포함한다. 펄스폭 변조기는 입력 데이터 값에 근거하여 펄스폭 변 조 신호를 생성한다. 시냅스 어레이는 펄스폭 변조 신호 및 가중치의 곱셈 연산에 근거하여 시냅스 연산 신호를 생성한다. 발진기는 시냅스 연산 신호의 크기에 의존하는 출력 주파수를 갖는 발진 신호를 생성한다. 카운터는 발진 신호 에 포함된 펄스의 개수를 카운팅하여 카운팅 데이터를 생성한다. 보상기는 선형적으로 증가하는 값을 갖는 기준 데이터가 저장된 메모리를 포함한다. 보상기는 기준 데이터와 카운팅 데이터를 비교하여 카운팅 데이터 값을 보 상하는 것을 특징으로 한다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-1950786호(2019.02.15) (특허문헌 0002) 한국 공개특허 제10-2019-0007143호(2019.01.22) (특허문헌 0003)"}
{"patent_id": "10-2021-0078468", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예는 CMOS와 공정 호환성이 매우 높은 TFET를 이용한 초저전력 시냅스 소자를 제안함으로써, 하드웨어 기반의 인공 신경망 형성 시 전력 소모를 절감하고 신뢰성을 향상시키는 인공신경망 연산 장치를 제공하고자 한다. 본 발명의 일 실시예는 TFET를 이용한 초저전력 시냅스 소자를 제안함으로써, 휴대용 전자기기, 사물 인터넷 등 과 함께 항공, 우주, 의료 분야 등 높은 에너지 효율이 필요하면서 실시간으로 학습이 필요한 응용분야까지 기 술 확장이 가능한 인공신경망 연산 장치를 제공하고자 한다."}
{"patent_id": "10-2021-0078468", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예들 중에서, 본 발명은 제1 방향 및 상기 제1 방향과 수직한 제2 방향을 따라 일정간격 이격되어 배치된 시냅스 어레이를 포함하는 이진 신경망 아키텍쳐에 있어서, 상기 시냅스 어레이는 다수의 시냅스 소자를 포함하 며, 각각의 시냅스 소자는 상기 제1 방향을 따라 인접하여 배치된 제1터널링 전계 효과 트랜지스터(TFET) 및 제 2 터널링 전계 효과 트랜지스터(TFET)들을 포함하고, 상기 제1 터널링 전계 효과 트랜지스터 및 상기 제2 터널 링 전계 효과 트랜지스터는 각각 게이트 전극, 드레인 단자 및 소스 단자를 포함하는 것을 특징으로 한다. 상기 이진 신경망 아키텍쳐는 상기 제1 방향을 따라 연장되어 배치된 복수의 비트라인과, 상기 제2 방향을 따 라 연장되어 배치된 복수의 워드라인을 포함하며, 상기 시냅스 소자는 상기 비트라인과 워드라인이 교차하는 영 역에 위치된 것을 특징으로 한다. 상기 제1 터널링 전계 효과 트랜지스터 및 상기 제2 터널링 전계 효과 트랜지스터의 상기 게이트는 상기 워드라 인과 접속하는 것을 특징으로 한다. 상기 제1 터널링 전계 효과 트랜지스터 및 상기 제2 터널링 전계 효과 트랜지스터의 상기 드레인 단자는 상기 비트라인과 연결된 것을 특징으로 한다. 상기 제1 터널링 전계 효과 트랜지스터 및 상기 제2 터널링 전계 효과 트랜지스터의 상기 소스 단자는 메탈 라 인과 접속되어 그라운드(GND)에 연결된 것을 특징으로 한다. 상기 제1 터널링 전계 효과 트랜지스터 및 제2 터널링 전계 효과 트랜지스터는 반도체 기판 상부에 형성된 게 이트 패턴, 상기 게이트 패턴 하부에 위치한 채널 영역, 상기 게이트 패턴 양측의 상기 반도체 기판 내에 형성 된 소스 영역 및 드레인 영역을 포함하며, 상기 게이트 패턴은 하부 산화막, 질화막, 상부 산화막 및 게이트 전 극층의 적층 구조로 형성된 것을 특징으로 한다. 상기 제1 터널링 전계 효과 트랜지스터 및 제2 터널링 전계 효과 트랜지스터의 상기 드레인 영역은 콘택 플러그 를 통해 비트라인과 연결되고, 상기 소스 영역은 콘택 플러그를 통해 메탈 라인과 연결되며, 상기 게이트 전극 층은 콘택 플러그를 통해 워드라인과 연결되어 시냅스 소자를 구성하는 것을 특징으로 한다. 상기 시냅스 소자로 활용되는 터널링 전계 효과 트랜지스터는 프로그램(program) 및 이레이즈(erase) 동작을 수 행하며, XNOR 동작 구현을 통해 이진 신경망 연산을 수행하는 것을 특징으로 한다. 상기 각각의 시냅스 소자들의 가중치(Weight) 값을 개별적으로 제어하여 입력(Input) 값에 따른 출력(Output) 값을 나타내는 것을 특징으로 한다. 상기 시냅스 어레이는 비트라인에 흐르는 전류 값(IBL)과 기준 전류 값(IREF)에 따라 출력 값이 결정하는 CSA 블 록(Conditional sum adder)과, 각 시냅스 소자에 대한 비교 결과값들을 순차적으로 입력 받아 처리하고, 최종 결과값을 출력하는 가산기(Adder)와 비교회로(Comparator)를 더 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2021-0078468", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시된 기술은 다음의 효과를 가질 수 있다. 다만, 특정 실시예가 다음의 효과를 전부 포함하여야 한다거나 다 음의 효과만을 포함하여야 한다는 의미는 아니므로, 개시된 기술의 권리범위는 이에 의하여 제한되는 것으로 이 해되어서는 아니 될 것이다. 본 발명의 일 실시예에 따른 인공신경망 연산 장치는 CMOS와 공정 호환성이 매우 높은 TFET를 이용한 초저전력 시냅스 소자를 제안함으로써, 하드웨어 기반의 인공 신경망 형성 시 전력 소모를 절감하고 신뢰성을 향상시키는 효과를 얻을 수 있다. 본 발명의 일 실시예에 따른 인공신경망 연산 장치는 TFET를 이용한 초저전력 시냅스 소자를 제안함으로써, 휴 대용 전자기기, 사물 인터넷 등과 함께 항공, 우주, 의료 분야 등 높은 에너지 효율이 필요하면서 실시간으로 학습이 필요한 응용분야까지 기술 확장이 가능한 효과를 얻을 수 있다."}
{"patent_id": "10-2021-0078468", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에 관한 설명은 구조적 내지 기능적 설명을 위한 실시예에 불과하므로, 본 발명의 권리범위는 본문에 설 명된 실시예에 의하여 제한되는 것으로 해석되어서는 아니 된다. 즉, 실시예는 다양한 변경이 가능하고 여러 가 지 형태를 가질 수 있으므로 본 발명의 권리범위는 기술적 사상을 실현할 수 있는 균등물들을 포함하는 것으로 이해되어야 한다. 또한, 본 발명에서 제시된 목적 또는 효과는 특정 실시예가 이를 전부 포함하여야 한다거나 그러한 효과만을 포함하여야 한다는 의미는 아니므로, 본 발명의 권리범위는 이에 의하여 제한되는 것으로 이해 되어서는 아니 될 것이다. 한편, 본 출원에서 서술되는 용어의 의미는 다음과 같이 이해되어야 할 것이다. \"제1\", \"제2\" 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위한 것으로, 이들 용어들에 의해 권리범위가 한정되어서는 아니 된다. 예를 들어, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\"있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결될 수 도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\"있다고 언급된 때에는 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 한편, 구성요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃 하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함하는 것으로 이해되어야 하고, \"포함 하다\"또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 각 단계들에 있어 식별부호(예를 들어, a, b, c 등)는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단 계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순 서와 다르게 일어날 수 있다. 즉, 각 단계들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수 행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 여기서 사용되는 모든 용어들은 다르게 정의되지 않는 한, 본 발명이 속하는 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 용어들은 관 련 기술의 문맥상 가지는 의미와 일치하는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한 이 상적이거나 과도하게 형식적인 의미를 지니는 것으로 해석될 수 없다. 이하 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 이하 도면상의 동일한 구성 요소에 대하여는 동일한 참조 부호를 사용하고, 동일한 구성 요소에 대해서 중복된 설명은 생략한 다. 도 1은 본 발명의 일 실시예에 따른 인공신경망 연산 장치의 이진 신경망 구조를 도시한 개념도이다. 도 1을 참조하면, 인공신경망 연산 장치는 터널링 전계 효과 트랜지스터(TFET)를 이용한 시냅스 소자를 기반으 로 하는 이진 신경망(binary neural network) 구조를 포함한다. 이진 신경망 구조는 비트라인 스위치 매트릭스(BL switch matrix), 워드라인 스위치 매트릭스(WL switch matrix), 시냅스 어레이, CSA 블록(Conditional sum adder), 합산기(Adder) 및 비교 회로(Comparator)로 구성 된다. 먼저, 비트라인 스위치 매트릭스는 다수의 비트라인(BL)과 연결되며, 워드라인 스위치 매트릭스는 비트라인 스 위치 매트릭스와 수직한 방향에 위치하며, 워드라인 스위치 매트릭스에 다수의 워드라인(WL)이 연결된다. 시냅스 어레이는 제1 방향으로 연장된 다수의 비트라인(BL)과 상기 제1 방향과 수직한 제2 방향으로 연장 되어 배치된 다수의 워드라인(WL)으로 구성되고, 비트라인과 워드라인이 교차하는 영역마다 시냅스 소자가 위치한다. 시냅스 소자는 적어도 두 개 이상의 트랜지스터를 포함한다. 여기서, 트랜지스터는 터널링 전계 효과 트랜 지스터(TFET)로 구성되는 것이 바람직하며, TFET는 NOR 타입으로 설계할 수 있다. 시냅스 소자를 구성하는 두개 이상의 트랜지스터는 제1 방향을 따라 인접하여 배치된다. 여기서는 제1 트랜지스터(TR1) 및 제2 트랜지스 터(TR2)로 정의하도록 한다. 제1 트랜지스터(TR1) 및 제2 트랜지스터(TR2)의 게이트는 각각 워드라인과 연결되 고, 제1 트랜지스터(TR1) 및 제2 트랜지스터(TR2)의 드레인 단자는 비트라인과 연결된다. 또한, 제1 트랜지스터 (TR1) 및 제2 트랜지스터(TR2)의 소스 단자는 메탈라인과 접속되어 그라운드(GND)에 연결된다. CSA 블록(Conditional sum adder)은 비트라인에 흐르는 전류 값(IBL)과 기준 전류 값(IREF)에 따라 출력 값이 결 정된다. 가산기(Adder) 및 비교회로(Comparator)는 각 시냅스 소자에 대한 비교 결과값들을 순차적으로 입 력 받아 처리하고, 최종 결과값을 출력한다. 이때 한 column 당 하나의 출력 값을 내는 과정에서 시냅스 소자들 에 각기 저장된 가중치(weight)값에 따라 해당 column에 흐르는 전류량이 결정되며 (summation of synaptic current), 일반적으로 가장 많은 전류가 흐르는 column의 결과가 출력 값(neuron output)으로 결정된다. 따라서 다양한 입력 및 출력 값(neuron input/output)을 가지는 정교한 인공 신경망 연산 체계를 구축하기 위해서는 매 트릭스의 크기가 가능한 한 커질 수밖에 없으며, 한 시냅스 소자에 흐르는 전류가 지극히 작아야 유리하다. 한 편, Ioff 또한 마찬가지로 인공 신경망 전체 전력 소모량에 영향을 미치므로 가능한 한 아주 작은 값을 가져야 한다. 본 발명에서 사용된 TFET은 Ioff가 ~10-14 μA/μm 수준의 매우 낮은 값을 가지며 dynamic range는 2,700 정도로 상당히 우수한 특성을 가지므로, TFET 기반의 초저전력 시냅스 소자를 하드웨어 기반의 인공 신경망 연 산 장치에 활용함으로써, 전력 소모를 절감하며 동시에 신뢰성이 향상되는 효과를 얻을 수 있다. 도 2는 본 발명의 일 실시예에 따른 인공신경망 연산 장치의 시냅스 소자를 구성하는 터널링 전계 효과 트랜지 스터의 구조를 도시한 단면도이다. 도 2를 참조하면, 터널링 전계 효과 트랜지스터는 매몰 산화막을 포함하는 반도체 기판 상부에 게이 트 패턴이 형성된다. 반도체 기판은 Si, SiGe, Ge, CNT, graphene, MoS2 등을 포함하는 물질로 형성 될 수 있다. 게이트 패턴은 하부 산화막(220a), 질화막(220b), 상부 산화막(220c) 및 게이트 전극층(220 d)의 적층 구조를 포함한다. 하부 산화막(220a) 및 상부 산화막(220c)은 실리콘 산화막(SiO2), 스트론튬 산화막 (SrO), 알루미늄 산화막(A12O3), 마그네슘 산 화막(MgO), 스칸듐 산화막(Sc2O3), 가돌리늄 산화막(Gd2O3), 이 트륨 산화막(Y2O3), 사마륨 산화막(Sm2O3), 하프늄 산화막(HfO2), 지르코늄 산화막(ZrO2), 탄탈 산화막 (Ta2O5), 바륨 산화막(BaO) 및 비스무스 산화막(Bi2O3) 중에서 선택하여 형성할 수 있다. 게이트 패턴은 산화막, 질화막 및 산화막이 적층된 ONO 구조를 적용하며, 게이트 패턴 하부의 반도체 기판은 실리콘 기판(Silicon) 및 매몰 산화막(Buried OXide)을 포함하는 구조이므로, 본 발명의 일 실시예에 따른 TFET는 SONOS 구조인 것이 바람직하나 반드시 이에 한정하지는 않는다. 또한, 터널링 전계 효과 트랜지스터는 게이트 패턴 양측의 반도체 기판 상에 소스 영역 및 드레 인 영역이 형성된다. 소스 영역은 P+ 영역이고, 드레인 영역 은 N+ 영역으로 형성할 수 있다. 소스 영역 및 드레인 영역 은 확산(Diffusion) 공정 또는 이온 주입(Ion Implantation) 공정을 통해 불순물을 도핑하여 형성할 수 있다. 소스 영역 및 드레인 영역 사이의 반도체 기판 상에는 채널 영역이 형성된다. 채널 영역 은 소스 영역보다 P형 불순물이 약하게 도핑(P-)되거나, 도핑되지 않은 진성 영역(intrinsic regio n)으로 형성될 수 있고, 드레인 영역보다 N형 불순물이 약하게 도핑(N- 영역)되거나, 도핑되지 않은 진성 영역으로 형성될 수도 있다. 기타 공정이나 각 단계의 미설명된 부분은 알려진 일반적인 CMOS 공정이나 TFET 공정에 따르면 되므로, 자세한 설명은 생략한다. 상기와 같은 제조 공정은 Ⅲ-Ⅴ족 반도체 물질, CNT, 그래핀(graphene), 이황화몰리브덴 (MoS2) 등을 기반으로 하는 TFET 소자에도 적용될 수 있다. 도 3은 도 2의 터널링 전계 효과 트랜지스터를 이용한 시냅스 소자를 포함하는 시냅스 어레이를 도시한 사시도 이다. 도 3을 참조하면, 시냅스 어레이는 매몰 산화막을 포함하는 반도체 기판 상부에 다수의 트랜지스터가 배치되는 구조로 형성된다. 시냅스 어레이를 구성하는 트랜지스터(TR1, TR2)는 도 2에 도시된 바와 같은 터널링 전계 효과 트랜지스터(TFET)로 형성할 수 있으며, 다수의 트랜지스터는 제1 방향 및 제1 방향과 수직한 제2 방 향을 따라 일정 간격 이격되어 배치된다. 이때, 제1 방향을 따라 인접한 두 개의 트랜지스터(TR1, TR2)가 하나 의 시냅스 소자로 사용된다. 도시된 바와 같이, 하나의 시냅스 소자는 두 개의 트랜지스터로 구성되 며, 여기서는 프로그램 동작을 진행하는 제1 트랜지스터(TR1) 및 이레이즈 동작을 진행하는 제2 트랜지스터 (TR2)로 정의하도록 한다. 시냅스 소자는 적어도 두 개의 트랜지스터를 포함하는 것이 바람직하나 이진신 경망 (binary neural networks)이 구현 가능한 범위 내에서 트랜지스터의 개수를 조절할 수 있다. 제1 트랜지스터(TR1) 및 제2 트랜지스터(TR2)의 드레인 영역(Drain)은 콘택 플러그를 통해 제1 방향으로 연장된 비트라인과 연결되며, 소스 영역(Source)은 콘택 플러그를 통해 비트라인과 평행하게 위치하는 메탈 라인과 접속되며, 메탈라인은 그라운드에 연결된다. 그리고, 제1 트랜지스터(TR1) 및 이레이즈 동작 을 진행하는 제2 트랜지스터(TR2)의 게이트 전극은 메탈 콘택을 통해 비트라인과 수직한 제2 방향으 로 연장된 워드라인과 연결된다. 도 2 및 도 3에 도시된 TFET는 기존 실리콘 기반의 MOSFET를 형성하기 위한 과정을 그대로 이용 가능하며, 동시 집적도 가능하기 때문에 시냅스 소자로의 활용에 용이한 장점이 있다. 도 2 및 도 3에 도시된 TFET를 이용한 시 냅스 소자 기반의 인공신경망 장치를 통해 이진 신경망(binary neural network)을 구축할 수 있다. 도 4는 본 발명의 일 실시예에 따른 인공 신경망 장치의 시냅스 소자로 활용되는 TFET에 대한 프로그램 (program) 및 이레이즈(erase) 매커니즘을 설명하기 위한 도면이다. 먼저, 도 4a는 TFET 기반 시냅스 소자의 프로그램 동작 특성에 대한 설명을 나타낸 것으로, 도 4a (i)는 A - A'에 따른 측면 에너지 밴드 다이어그램을 나타내며, 도 4a (ii)는 B - B'에 따른 수직 에너지 밴드 다이어그램 을 나타낸다. TFET는 도 4a에 도시된 같이 밴드간 터널링(BTBT;Band-to-band tunneling)에 의해 캐리어 이동이 일어난다. TFET는 MOSFET과 달리 소스, 드레인이 비대칭적인 구조로 형성되어 있으므로 핫 캐리어(hot carrier) 주입 효율이 우수하다. 따라서, 프로그램 동작 시 소수의 핫 캐리어 만으로도 메모리 특성을 얻을 수 있으며, 이에 따라 프로그램, 이레이즈 동작 과정에서 소모되는 에너지 또한 MOSFET에 비해 작게 나타난다. 또한, 도 4b는 TFET 기반 시냅스 소자의 이레이즈 동작 특성에 대한 설명을 나타낸 것으로, B - B'에 따른 수직 에너지 밴드 다이어그램을 도시한 것이다. TFET는 MOSFET과 마찬가지로 어레이 형태로 구성되어 있으므로 페이 지 이레이즈 방식을 사용하며, 도 4b에 도시된 바와 같이 FN-터널링(tunneling) 방식으로 이레이즈가 진행된다. 도 5는 본 발명의 이진 신경망을 이용한 XNOR 동작 구현 방식을 설명하기 위한 개념도이다. 도 5를 참조하면, TFET를 이용한 초저전력 시냅스 소자를 사용하여 이진 신경망의 XNOR 동작을 구현하기 위한 개념도이다. 구체적으로 설명하면, 시냅스 소자를 구성하는 2개의 트랜지스터와 전압이 인가되는 비트라인(BL) 과 반대의 전압이 인가되는 2개의 워드라인(WL)이 배치된다. 입력(Input)과 가중치(Weight)는 +1 또는 -1의 두 가지 값을 가질 수 있다. 도 5a 내지 도 5d를 참조하여 입력 값과 가중치 값에 따른 출력 값을 설명하면 다음과 같다. 도 5a및 도 5b는 가중치(Weight)값이 +1로 프로그램된 상태를 나타낸 1것이다. 먼저, 도 5a와 같이 이레이즈 동 작을 수행하는 제1 트랜지스터(TR1)에 저전압(Low Vt)이 인가되고, 프로그램 동작을 수행하는 제2 트랜지스터 (TR2)에 고전압(High V t)이 인가된다. 그리고 제1 트랜지스터와 연결된 제1 워드라인(WL1)의 전압이 온(On) 상 태이고, 제2 트랜지스터와 연결된 제2 워드라인(WL2)의 전압이 오프(Off) 상태인 경우, 입력(Input) 값이 +1이 된다. 이 경우, 입력 값과 가중치 값이 일치하므로, 출력(Output)값은 +1로 표현된다. 한편, 도 5b와 같이 제1 트랜지스터에 저전압, 제2 트랜지스터에 고전압 형태의 가중치가 인가되고, 제1 트랜지 스터에 연결된 제1 워드라인의 전압이 오프 상태이고, 제2 트랜지스터와 연결된 제2 워드라인의 전압이 온 상태 인 경우, 입력 값이 -1된다. 이 경우, 입력 값과 가중치 값이 일치하지 않으므로, 출력값은 -1로 표현될 수 있 다. 도 5c 및 도 5d는 가중치(Weight)값이 -1로 프로그램된 상태를 나타낸 것이다. 먼저, 도 5c와 같이 프로그램 동 작을 수행하는 제1 트랜지스터에 고전압이 인가되고, 이레이즈 동작을 수행하는 제2 트랜지스터에 저전압이 인 가된다. 그리고 제1 트랜지스터와 연결된 제1 워드라인의 전압이 온 상태이고, 제2 트랜지스터와 연결된 제2 워 드라인의 전압이 오프 상태인 경우, 입력 값이 +1이 된다. 이 경우, 입력 값과 가중치 값이 일치하지 않으므로, 출력(Output)값은 -1로 표현된다. 한편, 도 5d와 같이 제1 트랜지스터에 고전압, 제2 트랜지스터에 저전압이 인가되고, 제1 트랜지스터에 연결된 제1 워드라인의 전압이 오프 상태이고, 제2 트랜지스터와 연결된 제2 워드라인의 전압이 온 상태이 경우, 인풋 값이 -1 이 되며, 입력 값과 가중치 값이 일치하므로 출력값은 +1로 표현될 수 있다. 이와 같이, 각각의 시냅스 소자들의 가중치 값을 개별적으로 제어함과 동시에 해당 소자들에 대해서만 리드 (read)가 가능한 것을 알 수 있다. 도 6은 본 발명의 일 실시예에 따른 인공 신경망 장치를 구성하는 SONOS TFET의 특성을 나타내는 그래프로, SONOS MOSFET 소자와 SONOS TFET 소자의 전류-전압 전달 특성 곡선(transfer characteristics)을 도시한 것이다. 도 6을 참조하면, SONOS TFET는 기존에 사용되던 MOSFET 대비 매우 낮은 구동 전류(Ion)와 오프 상태 전류(Iof f)를 나타내는 것을 알 수 있다. TFET는 Ion이 MOSFET 대비 약 105가량 낮으며, 이는 TFET이 시냅스 소자로써 활 용 가능성이 매우 높다는 점을 의미한다. 또한 TFET의 경우 전류량이 매우 낮은 대신 MOSFET과 달리 소스, 드레인이 비대칭적인 구조로 형성되어 있으므 로 TFET은 소스-채널 접합에서의 전기장이 MOSFET 대비 더 크기 때문에 핫 캐리어(hot carrier) 주입 효율 또한 더 크게 나타난다. 따라서 프로그램 시 소수의 핫 캐리어 만으로도 메모리 특성을 얻을 수 있는 장점이 있다. 상기에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특 허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2021-0078468", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 인공신경망 연산 장치의 이진 신경망 아키텍쳐를 도시한 개념도이다. 도 2는 본 발명의 일 실시예에 따른 인공 신경망 연산 장치의 시냅스 소자를 구성하는 터널링 전계 효과 트랜지 스터를 도시한 단면도이다. 도 3은 도 2의 터널링 전계 효과 트랜지스터를 이용한 시냅스 소자를 포함하는 시냅스 어레이를 도시한 사시도 이다. 도 4는 본 발명의 일 실시예에 따른 인공 신경망 장치의 시냅스 소자로 활용되는 SONOS TFET에 대한 프로그램, 이레이즈 매커니즘을 설명하기 위한 도면이다. 도 5는 본 발명의 이진 신경망을 이용한 XNOR 동작 구현 방식을 설명하기 위한 개념도이다. 도 6은 본 발명의 일 실시예에 따른 인공 신경망 장치를 구성하는 SONOS TFET의 특성을 나타내는 그래프이다."}
