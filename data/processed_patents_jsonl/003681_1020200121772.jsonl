{"patent_id": "10-2020-0121772", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0039101", "출원번호": "10-2020-0121772", "발명의 명칭": "로봇 및 그의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "김명곤"}}
{"patent_id": "10-2020-0121772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "로봇에 있어서,뎁스 카메라; 구동부; 및상기 뎁스 카메라를 통해 촬영을 수행하여 뎁스 이미지를 획득하고,상기 뎁스 이미지의 복수의 픽셀의 뎁스 정보에 기초하여 상기 복수의 픽셀에 대응되는 3D(three-dimensional)공간 상의 복수의 3D 포인트를 생성하고,상기 복수의 3D 포인트 중 상기 3D 공간 상에서 상기 로봇의 주행하는 바닥면을 기준으로 기설정된 높이 값을갖는 복수의 3D 포인트를 식별하고,상기 식별된 복수의 3D 포인트에 기초하여 상기 로봇이 주행하도록 상기 구동부를 제어하는 프로세서;를 포함하는 로봇."}
{"patent_id": "10-2020-0121772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 3D 공간 상의 상기 복수의 3D 포인트의 분포에 기초하여, 상기 3D 공간 상에서 상기 로봇이 주행하는 바닥면을 판단하는 로봇."}
{"patent_id": "10-2020-0121772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는,상기 판단된 바닥면이 상기 3D 공간 상의 기설정된 평면에 맵핑되도록, 상기 3D 공간 상의 복수의 3D 포인트를회전시키고, 상기 회전된 복수의 3D 포인트 중 상기 기설정된 평면을 기준으로 상기 기설정된 높이 값을 갖는 복수의 3D 포인트를 식별하는 로봇."}
{"patent_id": "10-2020-0121772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 기설정된 평면은, XYZ 축으로 정의되는 상기 3D 공간 상의 XZ 평면에 해당하고, 상기 프로세서는,상기 회전된 복수의 3D 포인트 중 Y 축의 값이 기설정된 값을 갖는 상기 복수의 3D 포인트를 식별하는 로봇."}
{"patent_id": "10-2020-0121772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 프로세서는,상기 복수의 3D 포인트 중 상기 바닥면을 기준으로 기설정된 높이 값을 포함하는 기설정된 임계 범위 내의 높이값을 갖는 복수의 3D 포인트를 식별하고,공개특허 10-2022-0039101-3-상기 식별된 복수의 3D 포인트에 기초하여 상기 로봇이 주행하도록 상기 구동부를 제어하는 로봇."}
{"patent_id": "10-2020-0121772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 프로세서는,상기 식별된 복수의 3D 포인트의 X 축의 값 및 Z 축의 값에 기초하여 상기 식별된 복수의 3D 포인트를 2D 데이터로 변환하고,상기 2D 데이터에 기초하여 상기 로봇이 주행하도록 상기 구동부를 제어하는 로봇."}
{"patent_id": "10-2020-0121772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,기설정된 높이 값은,상기 로봇의 높이 값에 기초하여 설정된 높이 값인, 로봇."}
{"patent_id": "10-2020-0121772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "로봇의 제어 방법에 있어서, 상기 로봇에 구비된 뎁스 카메라를 통해 촬영을 수행하여 뎁스 이미지를 획득하는 단계;상기 뎁스 이미지의 복수의 픽셀의 뎁스 정보에 기초하여 상기 복수의 픽셀에 대응되는 3D(three-dimensional)공간 상의 복수의 3D 포인트를 생성하는 단계;상기 복수의 3D 포인트 중 상기 3D 공간 상에서 상기 로봇의 주행하는 바닥면을 기준으로 기설정된 높이 값을갖는 복수의 3D 포인트를 식별하는 단계; 및상기 식별된 복수의 3D 포인트에 기초하여 상기 로봇이 주행하도록 상기 로봇에 구비된 구동부를 제어하는단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2020-0121772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 식별하는 단계는,상기 3D 공간 상의 상기 복수의 3D 포인트의 분포에 기초하여, 상기 3D 공간 상에서 상기 로봇이 주행하는 바닥면을 판단하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2020-0121772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 식별하는 단계는,상기 판단된 바닥면이 상기 3D 공간 상의 기설정된 평면에 맵핑되도록, 상기 3D 공간 상의 복수의 3D 포인트를회전시키고, 상기 회전된 복수의 3D 포인트 중 상기 기설정된 평면을 기준으로 상기 기설정된 높이 값을 갖는 복수의 3D 포인트를 식별하는, 제어 방법."}
{"patent_id": "10-2020-0121772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 기설정된 평면은, XYZ 축으로 정의되는 상기 3D 공간 상의 XZ 평면에 해당하고, 상기 식별하는 단계는,상기 회전된 복수의 3D 포인트 중 Y 축의 값이 기설정된 값을 갖는 상기 복수의 3D 포인트를 식별하는 것을 포공개특허 10-2022-0039101-4-함하는, 제어 방법."}
{"patent_id": "10-2020-0121772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서,상기 식별하는 단계는,상기 복수의 3D 포인트 중 상기 바닥면을 기준으로 기설정된 높이 값을 포함하는 기설정된 임계 범위 내의 높이값을 갖는 복수의 3D 포인트를 식별하는, 제어 방법."}
{"patent_id": "10-2020-0121772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 식별하는 단계는,상기 식별된 복수의 3D 포인트의 X 축의 값 및 Z 축의 값에 기초하여 상기 식별된 복수의 3D 포인트를 2D 데이터로 변환하고,상기 제어하는 단계는, 상기 2D 데이터에 기초하여 상기 로봇이 주행하도록 상기 구동부를 제어하는 것을 포함하는, 제어 방법."}
{"patent_id": "10-2020-0121772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서,상기 기설정된 높이 값은,상기 로봇의 높이 값에 기초하여 설정된 높이 값인, 제어 방법."}
{"patent_id": "10-2020-0121772", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시에서는 로봇 및 그 제어 방법이 제공된다. 본 개시의 로봇은 뎁스 카메라, 구동부, 및 뎁스 카메라를 통 해 촬영을 수행하여 뎁스 이미지를 획득하고, 뎁스 이미지의 복수의 픽셀의 뎁스 정보에 기초하여 복수의 픽셀에 대응되는 3D(three-dimensional) 공간 상의 복수의 3D 포인트를 생성하고, 복수의 3D 포인트 중 3D 공간 상에서 로봇의 주행하는 바닥면을 기준으로 기설정된 높이 값을 갖는 복수의 3D 포인트를 식별하고, 식별된 복수의 3D 포인트에 기초하여 로봇이 주행하도록 구동부를 제어하는 프로세서를 포함할 수 있다."}
{"patent_id": "10-2020-0121772", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 로봇 및 그의 제어 방법에 관한 것으로, 보다 상세하게는 뎁스 이미지를 이용하여 주행하는 로봇 및 그의 제어 방법에 관한 것이다."}
{"patent_id": "10-2020-0121772", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 스스로 주행할 수 있는 로봇 및 그의 응용기술이 개발되고 있다. 로봇은 자율적으로 이동하기 위해 실시간 으로 로봇의 위치를 추정함(Localization)과 동시에 지도를 작성(Mapping)하는 SLAM(Simultaneous Localization and Mapping) 기술을 사용하고 있다. 이를 위해, 로봇은 다양한 센서들을 이용하여 획득된 데이터를 통해 위치 추정을 수행할 수 있다. 이때, 위치 추정에는 일반적으로 카메라의 화각 내에 존재하는 공간을 평면으로 투영한 이미지를 획득하는 비전 센서와 360 도 방향에 대해 물체와의 거리를 스캔한 데이터를 획득하는 라이다(Light Detection And Ranging, LiDAR)와 같 은 거리 센서가 이용될 수 있다. 카메라 등의 비전 센서의 경우 가격이 저렴하고 센서의 소형화가 가능하다는 장점이 있으나, 데이터 처리에 많 은 계산량이 요구되며, 로봇이 고속으로 이동하거나 회전할 경우에 획득되는 이미지에는 블러(blur)가 발생한다 는 단점이 있다. 라이다 등의 거리 센서의 경우, 모터 등의 회전 기구를 통해 센서를 회전시켜 360도 방향에 대해 거리를 감지하 는 등의 이유로 수명이 짧고, 가격이 고가이며, 센서의 소형화가 어렵다는 단점이 있다. 특히, 2D(two- dimensional) 라이다는 고정된 높이(라이다가 탑재된 높이)에 대해서만 거리를 감지할 수 있다는 점에서 로봇 주변의 다양한 환경 또는 객체를 감지하기에 어려움이 있으며, 다채널의 3D(three-dimensional) 라이다의 경우 비용이 매우 고가라는 점과 센서의 크기 및 무게가 크다는 단점이 있다."}
{"patent_id": "10-2020-0121772", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "이와 같은 센서들의 단점을 보완하여 로봇의 위치 추정을 수행하기 위한 방안이 요구되고 있다. 발명의 내용"}
{"patent_id": "10-2020-0121772", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 필요성에 의해 안출된 것으로, 본 개시의 목적은 뎁스 이미지를 이용하여 주행하는 로봇 및 그의 제어 방법을 제공함에 있다."}
{"patent_id": "10-2020-0121772", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한, 본 개시의 일 실시 예에 따른 로봇은 뎁스 카메라, 구동부, 및 뎁스 카메라를 통해 촬영을 수행하여 뎁스 이미지를 획득하고, 뎁스 이미지의 복수의 픽셀의 뎁스 정보에 기초하여 복수의 픽셀에 대응되는 3D(three-dimensional) 공간 상의 복수의 3D 포인트를 생성하고, 복수의 3D 포인트 중 3D 공간 상에서 로봇의 주행하는 바닥면을 기준으로 기설정된 높이 값을 갖는 복수의 3D 포인트를 식별하고, 식별된 복수의 3D 포인트에 기초하여 로봇이 주행하도록 구동부를 제어하는 프로세서를 포함할 수 있다. 프로세서는, 3D 공간 상의 복수의 3D 포인트의 분포에 기초하여, 3D 공간 상에서 로봇이 주행하는 바닥면을 판 단할 수 있다. 프로세서는, 판단된 바닥면이 3D 공간 상의 기설정된 평면에 맵핑되도록, 3D 공간 상의 복수의 3D 포인트를 회 전시키고, 회전된 복수의 3D 포인트 중 기설정된 평면을 기준으로 기설정된 높이 값을 갖는 복수의 3D 포인트를 식별할 수 있다. 기설정된 평면은, XYZ 축으로 정의되는 3D 공간 상의 xz 평면에 해당하고, 프로세서는, 회전된 복수의 3D 포인 트 중 Y 축의 값이 기설정된 값을 갖는 복수의 3D 포인트를 식별할 수 있다. 프로세서는, 복수의 3D 포인트 중 바닥면을 기준으로 기설정된 높이 값을 포함하는 기설정된 임계 범위 내의 높 이 값을 갖는 복수의 3D 포인트를 식별하고, 식별된 복수의 3D 포인트에 기초하여 로봇이 주행하도록 구동부를 제어할 수 있다. 프로세서는, 식별된 복수의 3D 포인트의 X 축의 값 및 Z 축의 값에 기초하여 식별된 복수의 3D 포인트를 2D 데 이터로 변환하고, 2D 데이터에 기초하여 로봇이 주행하도록 구동부를 제어할 수 있다. 기설정된 높이 값은, 로봇의 높이 값에 기초하여 설정된 높이 값일 수 있다. 본 개시의 일 실시 예에 따른 로봇의 제어 방법에 있어서, 로봇에 구비된 뎁스 카메라를 통해 촬영을 수행하여 뎁스 이미지를 획득하는 단계, 뎁스 이미지의 복수의 픽셀의 뎁스 정보에 기초하여 복수의 픽셀에 대응되는 3D(three-dimensional) 공간 상의 복수의 3D 포인트를 생성하는 단계, 복수의 3D 포인트 중 3D 공간 상에서 로 봇의 주행하는 바닥면을 기준으로 기설정된 높이 값을 갖는 복수의 3D 포인트를 식별하는 단계, 및 식별된 복수 의 3D 포인트에 기초하여 로봇이 주행하도록 로봇에 구비된 구동부를 제어하는 단계를 포함할 수 있다. 식별하는 단계는, 3D 공간 상의 복수의 3D 포인트의 분포에 기초하여, 3D 공간 상에서 로봇이 주행하는 바닥면 을 판단하는 단계를 포함할 수 있다. 식별하는 단계는, 판단된 바닥면이 3D 공간 상의 기설정된 평면에 맵핑되도록, 3D 공간 상의 복수의 3D 포인트 를 회전시키고, 회전된 복수의 3D 포인트 중 기설정된 평면을 기준으로 기설정된 높이 값을 갖는 복수의 3D 포 인트를 식별할 수 있다. 기설정된 평면은, XYZ 축으로 정의되는 3D 공간 상의 XZ 평면에 해당하고, 식별하는 단계는, 회전된 복수의 3D 포인트 중 Y 축의 값이 기설정된 값을 갖는 복수의 3D 포인트를 식별하는 것을 포함할 수 있다. 식별하는 단계는, 복수의 3D 포인트 중 바닥면을 기준으로 기설정된 높이 값을 포함하는 기설정된 임계 범위 내 의 높이 값을 갖는 복수의 3D 포인트를 식별할 수 있다. 식별하는 단계는, 식별된 복수의 3D 포인트의 X 축의 값 및 Z 축의 값에 기초하여 식별된 복수의 3D 포인트를 2D 데이터로 변환하고, 제어하는 단계는, 2D 데이터에 기초하여 로봇이 주행하도록 구동부를 제어하는 것을 포 함할 수 있다. 기설정된 높이 값은, 로봇의 높이 값에 기초하여 설정된 높이 값일 수 있다."}
{"patent_id": "10-2020-0121772", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상과 같은 본 개시의 다양한 실시 예에 따르면, 뎁스 이미지를 이용하여 주행하는 로봇 및 그의 제어 방법을 제공할 수 있다. 본 개시의 일 실시 예에 따르면, 라이다에 비해 특별한 제약 없이 다양한 높이에 대한 지도 데이터의 획득이 가 능하고, 가격 경제성이 있으며, 센서의 소형화가 가능하다는 장점이 있다. 본 개시의 일 실시 예에 따르면, 로봇의 위치 추정을 위한 연산량을 감소시킬 수 있다. 또한, 블러의 발생을 최 소화시키는 뎁스 이미지를 활용하여 로봇의 위치 추정에 대한 정확도를 향상시킬 수 있다."}
{"patent_id": "10-2020-0121772", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시를 설명함에 있어서, 관련된 공지 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그에 대한 상세한 설명은 생략한다. 덧붙여, 하기 실시 예는 여러 가지 다른 형 태로 변형될 수 있으며, 본 개시의 기술적 사상의 범위가 하기 실시 예에 한정되는 것은 아니다. 오히려, 이들 실시 예는 본 개시를 더욱 충실하고 완전하게 하고, 당업자에게 본 개시의 기술적 사상을 완전하게 전달하기 위 하여 제공되는 것이다. 본 개시에 기재된 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 개시의 실시 예의 다양한 변경 (modifications), 균등물(equivalents), 및/또는 대체물(alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 상기 구성요소들을 한정하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \" 포함하다\" 또는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들 을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요 소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제 3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 상기 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메 모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 상기 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 도 1은 본 개시의 일 실시 예에 따른 로봇을 설명하기 위한 도면이다. 도 1을 참조하면, 본 개시의 일 실시 예에 따른 로봇은 특정한 구역을 주행할 수 있는 장치이다. 이 경우, 로봇은 특정한 구역을 이동하면서 사용자에게 특정한 서비스를 제공할 수 있다. 예를 들어, 로봇은 청소 로봇, 수리 로봇, 탐사 로봇, 운송 로봇 등과 같이 다양한 서비스를 제공할 수 있는 장치로 구현될 수 있 다. 로봇은 다양한 센싱 데이터에 기초하여 다양한 주행 방식에 따라 주행할 수 있다. 센싱 데이터는 로봇 의 주변 환경을 센싱한 데이터로서 지도의 데이터로 활용될 수 있으며, 센싱 데이터는 뎁스 이미지를 포함 할 수 있다. 또한, 센싱 데이터는 로봇의 위치를 추정하거나 지도를 생성하는데 이용될 수 있다. 주행 방 식은 인간 또는 동물과 같이 다리를 이용하는 보행형, 바퀴의 회전을 이용하는 바퀴형(또는 캐터필러형), 날개 의 회전 또는 연료의 분사를 이용하는 비행형 등 중에서 적어도 하나를 포함할 수 있다. 본 개시의 일 실시 예에 따른 로봇은 뎁스 이미지에 기초하여 특정한 높이에 대한 지도를 생성하고, 지도 에 기초하여 주행할 수 있다. 구체적으로, 로봇은 뎁스 카메라를 통해 주변 환경에 대한 촬영을 수행하여 뎁스 이미지를 획득할 수 있다. 여기서, 뎁스 이미지는 복수의 픽셀 각각에 맵핑된 뎁스 정보를 포함할 수 있다. 뎁스 정보는 뎁스 카메 라의 위치 및 객체의 위치 사이의 거리를 나타낼 수 있다. 예를 들어, 도 1과 같이 로봇과 객체 가 동일한 축 상에 놓인 경우를 가정하면, 뎁스 이미지는 로봇의 위치(예: 높이 y2의 위치) 및 객체 의 위치(예: 높이 y1, y2, y3의 위치) 사이의 거리(예: d1, d2, d3)를 나타내는 뎁스 정보를 포함할 수 있 다. 이때, 객체는 로봇의 주변 환경에 존재하는 사물 또는 동물을 말하며, 예를 들어 벽, 문, 테이블, 의자, 카페트, 고양이, 사람 등을 의미할 수 있다. 그리고, 로봇은 뎁스 이미지를 기초로 복수의 3D(three-dimensional; 3D) 포인트를 생성할 수 있다. 여기 서, 3D 포인트는 가상의 3D 공간의 좌표(예: x, y, z의 좌표)로 정의되며, 3D 포인트의 좌표는 현실 공간의 위 치에 대응될 수 있다. 또한, 뎁스 이미지를 기반으로 생성된(또는 변환된) 3D 포인트는 대응되는 위치에 어떤 객체가 존재한다는 정보를 나타낼 수 있다. 즉, 뎁스 이미지의 복수의 픽셀에 맵핑된 객체와의 거리 및 각 픽셀 좌표를 이용하여, 객체를 3D 공간 상에서 각각 특정한 위치를 갖는 복수의 3D 포인트로 생성할 수 있 다. 이와 같이 로봇은 뎁스 이미지를 복수의 3D 포인트로 변환할 수 있다. 이 경우, 복수의 3D 포인트는 포인트 클라우드(point cloud)라고 명명할 수 있다. 그리고, 로봇은 복수의 3D 포인트 중에서 바닥면을 기준으로 기설정된 높이에 대한 복수의 3D 포인트를 식 별하고, 식별된 복수의 3D 포인트를 기초로 주행할 수 있다. 여기서, 바닥면은 기설정된 높이에 대한 지도 데이터를 생성하기 위해 기준면으로 이용될 수 있다. 기설정된 높 이는 로봇의 높이일 수 있으나, 이는 일 실시 예일 뿐이며, 로봇이 주행하는 환경을 고려한 높이로 설정될 수 있다. 예를 들어, 로봇이 가정과 같은 환경에서 주행하는 청소 로봇 등인 경우에는, 기설정된 높이는 가정 내의 구조물 중 문턱(문지방)의 높이로 설정될 수 있다. 식별된 복수의 3D 포인트는 기설정된 높이에 대한 지도를 생성하거나, 지도 상에서 로봇의 위치를 추정하 는데 이용될 수 있다. 예를 들어, 로봇은 주행하는 중에 뎁스 카메라를 통해 시간에 따라 연속적으로 뎁스 이미지가 획득되면, 전술한 동작을 반복적으로 수행하여 뎁스 이미지에 대응되는 기설정된 높이의 복수의 3D 포인트를 식별하고, 시간에 따라 연속적으로 식별된 복수의 3D 포인트를 하나의 3D 공간에 정합함으로써 기 설정된 높이에 대한 지도를 생성할 수 있다. 또한, 로봇은 가장 최근에 획득된 뎁스 이미지에 대응되는 기 설정된 높이의 복수의 3D 포인트를 식별하고, 기생성된 지도에서 식별된 복수의 3D 포인트와 일치하는 부분의 위치 및 배향을 판단하여 로봇의 위치 및 배향을 추정할 수 있다. 이상과 같은 본 개시의 다양한 실시 예에 따르면, 뎁스 이미지를 이용하여 주행하는 로봇 및 그의 제어 방 법을 제공할 수 있다. 또한, 본 개시의 일 실시 예에 따르면, 라이다에 비해 특별한 제약 없이 다양한 높이에 대한 지도 데이터의 획득이 가능하고, 가격 경제성이 있으며, 센서의 소형화가 가능하다는 장점이 있다. 이하에서는 첨부된 도면을 참조하여 본 개시에 대해 보다 구체적으로 설명하도록 한다. 도 2는 본 개시의 일 실시 예에 따른 로봇의 구성을 설명하기 위한 블록도이다. 도 2를 참조하여, 본 개시의 일 실시 예에 따른 로봇은 뎁스 카메라, 구동부 및 프로세서 를 포함할 수 있다. 뎁스 카메라는 뎁스 카메라의 화각(Field of View; FoV) 내에 영역에 대한 촬영을 수행하여 뎁스 이 미지를 획득할 수 있다. 여기서, 뎁스 이미지는 현실의 3D 공간이 2D 평면(즉, 이미지 평면)으로 투영된 복수의 픽셀을 포함할 수 있다. 복수의 픽셀은 2D 평면 상에 매트릭스 형태로 배열될 수 있으며, 각 픽셀의 위치 또는 각 픽셀의 좌표는 뎁스 카메라의 위치를 중심으로 3D 공간 상의 방향을 나타낼 수 있다. 또한, 복수의 픽셀 각각에는 뎁스 정보가 맵핑될 수 있으며, 뎁스 정보는 뎁스 카메라의 위치를 중심으로 픽셀의 위치에 대응되는 방향에 존재하는 객체와의 거리를 나타낼 수 있다. 이를 위해, 뎁스 카메라는 객체에 의해 반사되어 수신되는 가시광 또는 신호를 이미지 센서로 포커싱 하는 렌즈 및 가시광 또는 신호를 감지할 수 있는 이미지 센서를 포함할 수 있다. 여기서, 이미지 센서는 복수 의 픽셀로 구분되는 2D의 픽셀 어레이를 포함할 수 있다. 뎁스 카메라는 스테레오(Stereo) 방식, ToF(Time-Of-Flight) 방식, 구조광 방식 등으로 구현될 수 있다. 스테레오 방식은 사람의 눈처럼 2개의 카메라(또는 그 이상의 카메라)가 서로 다른 위치에서 객체를 동시 에 촬영하여 획득된 복수의 이미지의 시차(disparity)(즉, 복수의 이미지에 포함된 동일한 객체에 대한 위 치 차이)를 이용하여 객체와의 거리(또는 뎁스)를 산출하는 방식을 나타낸다. ToF 방식은 신호(예: 적외선, 초음파, 레이저 등)를 방출한 시간 및 방출된 신호가 객체에 의해 반사되어 검출된 시간의 차이 및 신호의 속도를 이용하여 객체와의 거리(또는 뎁스)를 산출하는 방식을 나타낸다. 특히, ToF 방식은 객 체의 거리를 식별할 수 있는 거리가 길고, 전력 소모가 적으며, 부피가 작아 제품의 소형화가 가능하다는 장점이 있다. 구조광 방식은 가시광선, 적외선 등의 레이저와 같이 주변 조명과 구별되는 구조광을 객체에 조사하고, 객체에 의해 반사된 구조광의 왜곡을 검출하여 객체와의 거리를 산출하는 방식을 나타낸다. 또한, 뎁스 카메라는 복수의 픽셀 각각에 대해 뎁스 정보 및 색상 정보(즉, Red, Green, Blue의 색상 값) 가 맵핑된 뎁스 이미지를 획득할 수 있는 RGB-D 카메라로 구현될 수도 있다. 한편, 뎁스 카메라는 연속적인 촬영을 통해 복수의 뎁스 이미지를 순차적으로 획득할 수 있다. 이때, 뎁스 이미지 또는 뎁스 이미지와는 별도의 메타 데이터는 뎁스 카메라에 의해 촬영된 시간, 프레임 레이트, 시 점, 화각, 픽셀 해상도 및 픽셀 피치 중에서 적어도 하나에 대한 정보를 포함할 수 있다. 프레임 레이트(Frame Rate)는 1초당(또는 1분당) 획득되는 프레임의 수(이미지의 수)를 나타내며, 화각은 뎁스 카메라의 렌즈의초점 거리(focal length) 및 뎁스 카메라의 이미지 센서의 크기(예: 대각 길이)에 따라 결정되는 값을 나 타낼 수 있다. 또한, 시점은 뎁스 카메라의 내부 또는 외부에 구비된 센서(예: 자이로 센서, 가속도 센서 등)에 의해 감지될 수 있다. 다만, 이는 일 실시 예일 뿐이며, 시점은 복수의 3D 포인트를 정합하여 생성된 지 도 상에서 뎁스 이미지에 기초하여 생성된 복수의 3D 포인트와 일치하는 부분을 식별하고 이들의 틀어진 정도를 이용하여 식별될 수 있다. 픽셀 해상도는 예를 들어 640 * 480과 같이 가로 방향으로 배치된 픽셀의 수(예: 640 개) 및 세로 방향으로 배치된 픽셀의 수(예: 480 개)를 나타내며, 픽셀 피치는 인접한 픽셀 간의 이격된 거리 (예: 50um 등)를 나타낼 수 있다. 한편, 본 개시의 일 실시 예에 따른 뎁스 카메라는 글로벌 셔터 방식에 따라 촬영을 수행하여 뎁스 이미지 를 획득할 수 있다. 글로벌 셔터는 이미지 센서의 전체를 동시에 노출시킨 후 한꺼번에 닫아버려 촬영을 수행하 는 방식이며, 한 프레임(frame)의 촬영 시점이 동일하기 때문에 시차에 따른 왜곡이 발생하지 않을 수 있다. 즉, 획득되는 뎁스 이미지에서 블러를 포함하는 왜곡이 발생되는 것을 방지할 수 있다. 이와 달리, 롤링 셔터는 이미지 센서의 수평 라인(line) 또는 수직 라인 별로 순차적으로 노출을 달리하여 촬영 을 수행하는 방식이며, 빠르게 움직이는 객체의 경우 이러한 방식을 통해 획득된 뎁스 이미지가 왜곡될 수 있다. 다만, 본 개시에서는 경제성, 소형화 등의 다양한 이유로 뎁스 카메라에 이러한 롤링 셔터 방식이 적용되는 것을 배제하는 것은 아니라고 할 것이다. 구동부는 로봇을 주행시킬 수 있는 장치이며, 프로세서의 제어에 따라 구동부는 주행 방향 및 주행 속도를 조절할 수 있다. 이를 위해, 구동부는 로봇이 주행하기 위한 동력을 발생시키는 동력 발생장치(예: 사용 연료(또는 에너지원)에 따라 가솔린 엔진(engine), 디젤 엔진, LPG(liquefied petroleum gas) 엔진, 전기 모터 등), 주행 방향을 조절하기 위한 조향 장치(예: 기계식 스티어링(manual steering), 유압 식 스티어링(hydraulics steering), 전자식 스티어링(electronic control power steering; EPS) 등), 동력에 따라 로봇을 주행시키는 주행 장치(예: 바퀴, 프로펠러 등) 등을 포함할 수 있다. 여기서, 구동부는 로봇의 주행 타입(예: 휠 타입, 보행 타입, 비행 타입 등)에 따라 변형 실시될 수 있다. 프로세서는 뎁스 카메라를 통해 촬영을 수행하여 뎁스 이미지를 획득하고, 뎁스 이미지의 복수의 픽 셀의 뎁스 정보에 기초하여 복수의 픽셀에 대응되는 3D(three-dimensional) 공간 상의 복수의 3D 포인트를 생성 하고, 복수의 3D 포인트 중 3D 공간 상에서 로봇의 주행하는 바닥면을 기준으로 기설정된 높이 값을 갖는 복수의 3D 포인트를 식별하고, 식별된 복수의 3D 포인트에 기초하여 로봇이 주행하도록 구동부를 제 어할 수 있다. 구체적으로, 프로세서는 뎁스 카메라를 통해 촬영을 수행하여 뎁스 이미지를 획득할 수 있다. 프로세 서는 뎁스 이미지의 복수의 픽셀의 뎁스 정보에 기초하여 복수의 픽셀에 대응되는 3D 공간 상의 복수의 3D 포인트를 생성할 수 있다. 이는 도 3a 및 도 3b를 참조하여 구체적으로 설명하도록 한다. 그리고, 프로세서는 복수의 3D 포인트 중 3D 공간 상에서 로봇의 주행하는 바닥면을 기준으로 기설정 된 높이 값을 갖는 복수의 3D 포인트를 식별할 수 있다. 구체적인 일 실시 예로서, 프로세서는 3D 공간 상의 복수의 3D 포인트의 분포에 기초하여, 3D 공간 상에서 로봇이 주행하는 바닥면을 판단할 수 있다. 이는 도 4a 및 도 4b를 참조하여 구체적으로 설명하도록 한다. 여기서, 프로세서는 판단된 바닥면이 3D 공간 상의 기설정된 평면에 맵핑되도록, 3D 공간 상의 복수의 3D 포인트를 회전시킬 수 있다. 이 경우, 기설정된 평면은 XYZ 축으로 정의되는 3D 공간 상의 XZ 평면에 해당할 수 있다. 이는 도 5a 내지 도 5c를 참조하여 구체적으로 설명하도록 한다. 여기서, 프로세서는 회전된 복수의 3D 포인트 중 기설정된 평면을 기준으로 기설정된 높이 값을 갖는 복수 의 3D 포인트를 식별할 수 있다. 이 경우, 프로세서는 회전된 복수의 3D 포인트 중 Y 축의 값이 기설정된 값을 갖는 복수의 3D 포인트를 식별할 수 있다. 이는 도 6a 및 도 6b를 참조하여 구체적으로 설명하도록 한다. 그리고, 프로세서는 식별된 복수의 3D 포인트에 기초하여 로봇이 주행하도록 구동부를 제어할 수 있다. 일 실시 예로서, 프로세서는 식별된 복수의 3D 포인트의 X 축의 값 및 Z 축의 값에 기초하여 식별된 복수 의 3D 포인트를 2D 데이터로 변환할 수 있다. 그리고, 프로세서는 2D 데이터에 기초하여 로봇이 주행 하도록 구동부를 제어할 수 있다. 이는 도 7을 참조하여 구체적으로 설명하도록 한다. 한편 본 개시의 일 실시 예로서, 프로세서는 복수의 3D 포인트 중 바닥면을 기준으로 기설정된 높이 값을 포함하는 기설정된 임계 범위 내의 높이 값을 갖는 복수의 3D 포인트를 식별할 수 있다. 이 경우, 프로세서 는 식별된 복수의 3D 포인트에 기초하여 로봇이 주행하도록 구동부를 제어할 수 있다. 도 3a 및 도 3b는 본 개시의 일 실시 예에 따른 뎁스 이미지를 통해 3D 포인트를 생성하는 방법을 설명하기 위 한 도면이다. 도 3a의 을 참조하면, 본 개시의 일 실시 예에 따른 프로세서는 뎁스 카메라를 통해 촬영을 수행 하여 뎁스 이미지를 획득할 수 있다. 여기서, 뎁스 이미지는 픽셀 단위로 맵핑된 뎁스 정보를 포함할 수 있다. 일 실시 예로서, 뎁스 이미지는 매트릭스 형태로 배열된 데이터로 구현될 수 있다. 여기서, 뎁스 이미지 에서 열은 픽셀의 x축의 좌표를 나타내고, 뎁스 이미지에서 행은 픽셀의 y축의 좌표를 나타낼 수 있 다. 뎁스 이미지에서 특정한 행과 열에 맵핑된 값은 해당 좌표를 갖는 픽셀에 맵핑된 뎁스 정보일 수 있다. 예를 들어, 뎁스 이미지에 포함되는 복수의 픽셀(예: 640 * 480 의 픽셀) 중에서 (1, 1) 픽셀에는 1 미터, (1, 2) 픽셀에는 1.2미터와 같은 뎁스 정보가 맵핑되어 저장될 수 있다. 도 3a의 를 참조하면, 프로세서는 뎁스 이미지에 포함된 복수의 픽셀의 뎁스 정보 및 픽셀의 좌표 에 기초하여, 3D 공간 상에서 복수의 3D 포인트를 생성할 수 있다. 여기서, 복수의 3D 포인트 각각은 뎁스 이미지의 각 픽셀에 대응될 수 있다. 3D 포인트는 X축, Y축 및 Z축의 좌표계를 갖는 3D 공간 상에서 위치하며, 3D 포인트의 위치는 객체가 존재하는 위치에 대응될 수 있다. 이하에서는, 복수의 3D 포인트를 생성하는 과정을 대표하여 복수의 3D 포인트 중 하나인 제1 3D 포인 트를 생성하는 과정을 설명하도록 한다. 예를 들어, 프로세서는 뎁스 이미지에 포함된 제1 픽셀에 매 핑된 좌표(예: (x1, y1)) 및 뎁스 정보(예: d1)에 기초하여, 다음과 같은 수학식 1에 따른 위치(X1, Y1, Z1)를 갖 는 제1 3D 포인트를 생성할 수 있다. 수학식 1"}
{"patent_id": "10-2020-0121772", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 3D 공간은 뎁스 카메라의 렌즈의 중심을 기준으로 뎁스 카메라의 수평 방향을 X축으로, 뎁스 카메라의 수직 방향을 Y축으로, 광학축 방향을 Z축으로 설정한 것이다. 여기서, x1, y1는 뎁스 이미지의 픽셀의 행 좌표 및 열 좌표를 나타내며, d1는 해당 픽셀에 맵핑된 뎁스 정 보를 나타낸다. 또한, fx, fy는 X축과 Y축에 대한 뎁스 카메라의 초점거리(focal length)를 나타내며, cx, cy는 X축과 Y축에 대한 주점(principal point)의 위치를 나타내며, 이는 뎁스 카메라 내부 또는 외부의 메 모리에 기저장된 정보일 수 있다. 이와 같은 동작에 의해 도 3b의 의 뎁스 이미지(310F)에 포함된 복수의 픽셀에 맵핑된 좌표 및 뎁스 정보에 따라, 도 3b의 의 복수의 3D 포인트(320F)가 생성될 수 있다. 여기서, 복수의 3D 포인트(320F)는 도 3b의 와 같이 각 픽셀에 맵핑된 뎁스 정보를 시각적으로 표현하는 이미지 형태로 구현될 수 있다. 이때, 뎁스 정 보는 객체와의 거리에 대응되는 명암 값(또는 그레이스케일)을 포함할 수 있다. 한편, 상술한 예는 일 실시 예일 뿐, 프로세서는 다양한 기하학적인 관계 또는 다양한 알고리즘을 통해 뎁 스 이미지에 포함된 픽셀의 좌표 및 뎁스 정보에 기초하여 3D 포인트를 생성할 수 있다. 또한, 상술한 동 작은 프로세서에서 수행하는 것으로 기술하였으나 이는 일 실시 예일 뿐이며, 뎁스 이미지를 기초로 복수의 3D 포인트를 생성하는 동작은 뎁스 카메라 내부에서 수행되는 것 또한 가능하다. 한편, 상술한 복수의 3D 포인트의 높이는 일반적으로 Y축의 값이 될 수 있다. 다만, 바닥면이 기울어져 있거나, 바닥면의 높이가 0미터가 아닌 값으로 측정될 가능성이 존재한다는 점에서, 특정한 높이의 3D 포인트를 추출하 기 위해서는 높이를 판단하는 기준이 되는 바닥면을 식별하는 과정이 요구될 수 있다. 이하에서는 바닥면을 식 별하는 방법에 대해 도 4a 및 도 4b를 참조하여 구체적으로 설명하기로 한다. 도 4a 및 도 4b는 본 개시의 일 실시 예에 따른 바닥면을 식별하는 방법을 설명하기 위한 도면이다. 도 4b는 도 4a의 제1 평면(430G)를 측면에서 바라본 도면이다. 도 4a를 참조하여, 프로세서는 3D 공간 상의 복수의 3D 포인트의 분포에 기초하여, 3D 공간 상에서 로봇이 주행하는 바닥면(430G)을 판단할 수 있다. 예를 들어, 프로세서는 복수의 3D 포인트 중에서 랜덤으로 복수의 3D 포인트(예: 3개의 3D 포인트)를 선정할 수 있다. 그리고, 프로세서는 3개의 3D 포인트의 위치와 다음과 같은 수학식 2를 통해 제1 평면 (430G)을 식별할 수 있다. 수학식 2"}
{"patent_id": "10-2020-0121772", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, <A, B, C>는 제1 평면(430G)에 수직하는 법선 벡터 n을 나타낼 수 있다. A, B, C, D의 값은 다양한 방 식을 통해 구할 수 있다. 예를 들어, 제1 3D 포인트가 (X1, Y1, Z1)에 위치하고, 제2 3D 포인트가 (X2, Y2, Z2)에 위치하고, 제3 3D 포인트가 (X3, Y3, Z3)에 위치하는 경우를 가정하고, 제1 내지 제3 3D 포인트를 수학식 2의 X, Y, Z에 각각 대입하여 연립 방정식을 풀면, 그 결과로 A, B, C, D의 값을 구할 수 있다. 도 4b를 참조하여, 프로세서는 복수의 3D 포인트 중에서 제1 평면(430G)과의 거리가 기설정된 거리 (예: t) 이내에 위치한 3D 포인트를 정상점(inlier)로 간주하고, 이들을 제외한 나머지 3D 포인트는 이상점 (Outlier)으로 간주할 수 있다. 프로세서는 정상점으로 식별된 3D 포인트의 분포(즉, 개수)를 산출하여 메 모리에 저장할 수 있다. 프로세서는 상술한 동작을 반복하여 랜덤으로 식별된 제2 내지 제n 평면(n은 2 이상의 자연수)에 대한 정 상점의 분포를 산출할 수 있다. 그리고, 프로세서는 제1 평면(430G) 내지 제n 평면에 대한 정상점의 분포 중에서 가장 큰 분포를 갖는 평면을 바닥면으로 판단할 수 있다. 한편, 본 개시의 일 실시 예에 따른 프로세서는 랜덤으로 3D 포인트를 선정할 경우에, 복수의 3D 포인트 중에서 Y 값이 기설정된 값 이하인 3D 포인트를 식별하고, 식별된 3D 포인트 중에서 랜덤으로 3D 포인트 를 선정할 수 있다. 이는 바닥면이 대부분 아래 쪽에 위치하는 것이 일반적이라는 점을 고려하여 바닥면 판단 과정에 대한 연산 횟수를 줄일 수 있는 효과가 있다. 한편, 상술한 실시 예는 일 실시 예일 뿐이며, 프로세서는 RANSAC(Random sample consensus), 고유치 분 석 등의 다양한 알고리즘을 통해 바닥면을 판단할 수 있다. 그리고, 프로세서는 바닥면을 기준으로 기설정된 높이 값을 갖는 3D 포인트를 식별하기 위해, 바닥면을 기 준으로 복수의 3D 포인트를 정렬할 수 있다. 즉, 바닥면에 해당하는 3D 포인트들이 Y축의 값이 0이 되도록, 전 체 3D 포인트를 정렬할 수 있다. 이는 도 5a 내지 도 5c를 참조하여 구체적으로 설명하도록 한다. 도 5a 내지 도 5c는 본 개시의 일 실시 예에 따른 복수의 3D 포인트를 정렬하는 방법을 설명하기 위한 도면이다. 도 5a의 을 참조하면, 프로세서는 판단된 바닥면(530G)이 3D 공간 상의 기설정된 평면(G')에 맵핑되도 록, 3D 공간 상의 복수의 3D 포인트를 회전시킬 수 있다. 여기서, 기설정된 평면(G')은 XYZ 축으로 정의되는 3D 공간 상의 XZ 평면에 해당할 수 있다. 여기서, XZ 평면은 Y=0과 같이 Y축의 값이 0을 갖는 평면이다. 구체적으로, 프로세서는 판단된 바닥면(530G)에 수직하는 법선 벡터 n 및 Y축의 방향 벡터를 벡터의 내적 또는 외적 등의 다양한 방식을 이용하여, 법선 벡터 n 및 Y축의 방향 벡터 사이의 각도 θ를 산출할 수 있다.그리고, 프로세서는 법선 벡터 n 및 Y축의 방향 벡터 사이의 각도 θ가 0이 되도록 복수의 3D 포인트 전체를 회전시킬 수 있다. 이 경우, 복수의 포인트 및 바닥면(540G)은 도 5a의 와 같이 회전을 통해 정렬될 수 있다. 이때, 3D 포 인트의 Y축의 값은 바닥면(540G)을 기준으로 하는 객체의 높이를 나타낼 수 있다. 도 5b 및 도 5c를 참조하여, 본 개시의 일 실시 예에 따라 복수의 3D 포인트가 정렬되는 예를 설명하기로 한다. 도 5b는 복수의 3D 포인트를 객체의 정면 방향에서 나타낸 것이며, 도 5c는 복수의 3D 포인트를 객체의 측면 방 향에서 나타낸 것이다. 예를 들어, 도 5b의 및 도 5c의 과 같이 뎁스 이미지에 기초하여 생성된 복수의 3D 포인트(520F, 520S) 중에서 바닥면(530G)이 판단된 경우를 가정하면, 바닥면(530G)은 Y축의 값이 0을 갖는 평면에 맵핑될 수 있다. 이 경우, 도 5b의 및 도 5c의 와 같이 바닥면(540G)은 Y축의 값이 0을 갖는 평면에 맵핑된 상태로 복수 의 3D 포인트(540F, 540S)가 정렬될 수 있다. 그리고, 프로세서는 복수의 3D 포인트 중 3D 공간 상에서 로봇의 주행하는 바닥면을 기준으로 기설정 된 높이 값을 갖는 복수의 3D 포인트를 식별할 수 있다. 이는 도 6a 및 도 6b를 참조하여 구체적으로 설명하도 록 한다. 도 6a 및 6b는 본 개시의 일 실시 예에 따른 특정한 높이의 3D 포인트를 식별하는 방법을 설명하기 위한 도면이 다. 도 6a를 참조하여, 프로세서는 회전된 복수의 3D 포인트 중에서 기설정된 평면(G')을 기준으로 기설 정된 높이 값을 갖는 복수의 3D 포인트를 식별할 수 있다. 이때, 복수의 3D 포인트는 바닥면(640G)이 3D 공간 상의 기설정된 평면(G')에 맵핑되도록 회전된 것이다. 여기서, 기설정된 평면(G')은 바닥면(640G)과 동일한 XZ 평면(Y=0인 평면)에 해당할 수 있다. 식별된 복수의 3D 포인트는 로봇의 바닥면을 기준으로 기설정된 높이 값을 갖는 평면에서의 객체의 위치를 나타낼 수 있다. 즉, 프로세서는 회전된 복수의 3D 포인트 중 Y 축의 값이 기설정된 값을 갖는 복수의 3D 포인트를 식 별할 수 있다. 예를 들어, Y 축의 값이 기설정된 값 h를 갖는 복수의 3D 포인트는 Y=h인 H 평면(650H) 상에 위 치하는 3D 포인트이다. 상술한 바닥면(640G)를 기준으로 기설정된 높이 값을 갖는 H 평면(650H) 상에 위치한 3D 포인트를 식별하는 일 실시 예는 도 6b의 및 에 도시된 바와 같이 나타날 수 있다. 도 6b의 는 복수의 3D 포인트를 객체의 정면 방향에서 나타낸 것이며, 도 6b의 는 복수의 3D 포인트를 객체의 측면 방향에서 나타낸 것이다. 한편, 일 실시 예로서, 기설정된 높이 값은 로봇의 높이에 기초한 값일 수 있다. 예를 들어, 기설정된 높 이 값은 0 이상 및 로봇의 높이 값 이하인 범위 내의 값일 수 있다. 이는 로봇의 위치 추정 또는 로 봇과 충돌가능한 객체의 위치를 판단하기 위한 것이다. 다른 실시 예로서, 기설정된 높이 값은 사람의 키에 기초한 높이 값일 수 있다. 예를 들어, 기설정된 높이 값은 일반적인 사람의 키보다 큰 높이 값(예: 2미터)에 대응되는 Y 값일 수 있다. 이는, 동적인 객체를 배제하여 실 내 구조를 파악함으로써 로봇의 위치 추정을 보다 정확하게 수행하기 위함이다. 나아가, 기설정된 높이 값은 하나의 값으로 설정된 것으로 설명하였으나, 이는 일 실시 예일 뿐이며, 기설정된 높이 값은 복수의 값으로 설정될 수도 있다. 이 경우, 각각의 높이 값에 대한 3D 포인트는 로봇의 위치 추 정에 이용될 수 있다. 한편, 상술한 기설정된 높이 값에 대한 실시 예들은 일 실시 예일 뿐 다양한 변형 실시 예가 가능하다 할 것이다. 한편 본 개시의 일 실시 예로서, 프로세서는 복수의 3D 포인트 중 바닥면을 기준으로 기설정된 높이 값을 포함하는 기설정된 임계 범위 내의 높이 값을 갖는 복수의 3D 포인트를 식별할 수 있다. 예를 들어, 기설정된 임계 범위 내의 높이 값은 기설정된 높이 값 h를 기준으로 기설정된 임계 값 a를 뺀 h-a 및 기설정된 임계 값 a 를 더한 h+a 사이의 높이 값을 나타낼 수 있다. 즉, 기설정된 임계 범위 내의 높이 값은 h-a 이상 및 h+a 미만 범위의 값일 수 있다. 그리고, 프로세서는 식별된 복수의 3D 포인트에 기초하여 로봇이 주행하도록 구동부를 제어할 수 있다. 이는 도 7을 참조하여 함께 설명하도록 한다. 도 7은 본 개시의 일 실시 예에 따른 2D 데이터를 생성하는 방법을 설명하기 위한 도면이다. 도 7의 은 정렬 된 복수의 3D 포인트(740T)를 XZ 평면 상에 투영한 탑뷰로 나타낸 것이며, 도 7의 는 기설정된 높이를 갖는 복수의 3D 포인트(750T)를 XZ 평면 상에 투영한 탑뷰로 나타낸 것이다. 도 7의 및 를 참조하면, 프로세서는 정렬된 복수의 3D 포인트(740T) 중에서 식별된 기설정된 높이 를 갖는 복수의 3D 포인트(750T)의 X 축의 값 및 Z 축의 값에 기초하여 식별된 복수의 3D 포인트(750T)를 2D 데 이터로 변환할 수 있다. 예를 들어, 프로세서는 기설정된 높이 h를 갖는 3D 포인트의 (X, h, Z) 값 중에서 Y축의 값인 h를 생략(또는 제거)하여 X축 및 Z축의 값인 (X, Z)을 갖는 2D 포인트로 변환할 수 있다. 즉, 2D 데 이터는 복수의 2D 포인트를 포함할 수 있다. 또한 2D 데이터는 높이에 대한 정보를 포함할 수 있다. 이러한 2D 데이터는 2D 라이다 센서의 출력 값(또는 입력 값 등)과 동일한 포맷으로 변환됨으로써 2D 라이다 기반의 SLAM 으로 활용될 수 있다. 그리고, 프로세서는 2D 데이터에 기초하여 로봇이 주행하도록 구동부를 제어할 수 있다. 구체적으로, 프로세서는 주기적으로 획득되는 뎁스 이미지에 기초하여 복수의 3D 포인트를 생성하고, 정렬 된 복수의 3D 포인트 중에서 기설정된 높이를 갖는 복수의 3D 포인트를 식별하고, 식별된 복수의 3D 포인트를 2D 데이터로 변환할 수 있다. 이 경우, 프로세서는 주기적으로 변환된 2D 데이터를 정합하여 2D 지도로 생 성(또는 업데이트)할 수 있다. 또한, 프로세서는 현재(또는 가장 최근 시간에) 획득된 뎁스 이미지에 기초하여 복수의 3D 포인트를 생성 하고, 정렬된 복수의 3D 포인트 중에서 기설정된 높이를 갖는 복수의 3D 포인트를 식별하고, 식별된 복수의 3D 포인트를 2D 데이터로 변환할 수 있다. 이 경우, 프로세서는 현재(또는 가장 최근 시간에) 변환된 2D 데이 터를 2D 지도와 비교하여, 2D 지도 상에서의 로봇의 위치를 식별할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는 상술한 상술한 2D 지도를 생성하는 동작 및 위치를 추정하는 동 작을 동시에 수행할 수 있다. 그리고, 프로세서는 2D 지도 상에서 로봇의 위치로부터 목적지까지의 주행 경로를 결정(또는 계획)할 수 있다. 이때, 최단 거리의 주행 경로를 탐색하는 알고리즘, 주행 방향의 전환을 최소화하는 경로를 탐색하는 알고리즘 등의 다양한 경로 탐색 알고리즘이 이용될 수 있다. 그리고, 프로세서는 주행 경로를 따라 목적지까지 주행하도록 구동부를 제어할 수 있다. 이상과 같은 본 개시의 다양한 실시 예에 따르면, 뎁스 이미지를 이용하여 주행하는 로봇 및 그의 제어 방법을 제공할 수 있다. 또한, 뎁스 이미지를 활용한다는 점에서 라이다에 비해 특별한 제약 없이 다양한 높이에 대한 지도 데이터의 획 득이 가능하다. 또한, 뎁스 이미지를 획득할 수 있는 뎁스 카메라의 경우 라이다에 비해 가격 경제성이 있 으며, 센서의 소형화가 가능하다는 장점이 있다. 또한, 뎁스 이미지에 기초하여 생성된 복수의 3D 포인트 전부를 처리하는 것이 아니라, 특정한 높이를 갖는 복 수의 3D 포인트를 처리한다는 점에서 연산량를 감소시킬 수 있다. 도 8은 본 개시의 일 실시 예에 따른 로봇의 부가적인 구성을 설명하기 위한 블록도이다. 도 8을 참조하면, 본 개시의 일 실시 예에 따른 로봇은 뎁스 카메라, 구동부 및 프로세서 외에도, 입력 인터페이스, 출력 인터페이스, 메모리, 센서, 통신부 및 전원부 중에서 적어도 하나를 더 포함할 수 있다. 도 2에서 설명한 내용과 중복되는 내용은 생략하기로 한다. 프로세서는 CPU(Central Processing Unit), AP(Application Processor) 등과 같은 범용 프로세서, GPU(Graphic Processing Unit), VPU(Vision Processing Unit) 등과 같은 그래픽 전용 프로세서, NPU(Neural Processing Unit)와 같은 인공지능 전용 프로세서 등으로 구현될 수 있다. 또한, 프로세서는 적어도 하나 의 인스트럭션 또는 모듈을 로드하기 위한 휘발성 메모리를 포함할 수 있다. 입력 인터페이스는 다양한 사용자 명령을 수신하여 프로세서로 전달할 수 있다. 즉, 프로세서는 입력 인터페이스를 통해 사용자로부터 입력된 사용자 명령을 인지할 수 있다. 여기서, 사용자 명령은 사용 자의 터치 입력(터치 패널), 키(키보드) 또는 버튼(물리 버튼 또는 마우스 등) 입력, 사용자 음성(마이크) 등다양한 방식으로 구현될 수 있다. 출력 인터페이스는 정보를 출력할 수 있는 구성이며, 예를 들어 디스플레이, 또는 스피커 등으로 구현될 수 있다. 디스플레이는 정보 또는 데이터를 시각적인 형태로 출력하는 장치이다. 디스플레이는 이미지 프레임을 픽셀로 구동될 수 있는 디스플레이의 일 영역 또는 전체 영역에 표시할 수 있다. 디스플레이의 적어도 일부는 플렉서블 디스플레이(flexible display)의 형태로 로봇의 전면 영역 및, 측면 영역 및 후면 영역 중 적어 도 하나에 결합될 수도 있다. 플렉서블 디스플레이는 종이처럼 얇고 유연한 기판을 통해 손상 없이 휘거나 구부 리거나 말 수 있는 것을 특징으로 할 수 있다. 스피커는 오디오 처리부(미도시)에 의해 디코딩이나 증폭, 노이 즈 필터링과 같은 다양한 처리 작업이 수행된 각종 오디오 데이터뿐만 아니라 각종 알림 음이나 음성 메시지를 직접 소리로 출력할 수 있다. 메모리는 로봇의 구성요소들의 전반적인 동작을 제어하기 위한 운영체제(OS: Operating System) 및 로봇의 구성요소와 관련된 다양한 데이터를 저장하기 위한 구성이다. 이를 위해, 메모리는 데이터 또는 정보를 일시적 또는 영구적으로 저장하는 하드웨어로 구성될 수 있다. 예를 들어, 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(Flash Memory), 하드디스크 드라이브 (HDD) 또는 솔리드 스테이트 드라이브(SSD), RAM, ROM 등 중에서 적어도 하나의 하드웨어로 구현될 수 있다. 메모리에는 로봇 또는 프로세서의 동작에 필요한 적어도 하나의 인스트럭션(instruction), 프로 그램 또는 데이터가 저장될 수 있다. 여기서, 인스트럭션은 로봇 또는 프로세서의 동작을 지시하는 부호 단위로서, 컴퓨터가 이해할 수 있는 언어인 기계어로 작성된 것일 수 있다. 프로그램은 작업 단위의 특정 작업을 수행하는 일련의 인스트럭션의 집합체(instruction set)일 수 있다. 데이터는 문자, 수, 영상 등을 나타 낼 수 있는 비트 또는 바이트 단위의 상태 정보일 수 있다. 센서는 카메라, 마이크, 근접 센서, 조도 센서, 모션 센서, ToF 센서, GPS 센서 등 다양한 센서로 구현될 수 있다. 예를 들어, 카메라는 빛을 픽셀 단위로 구분하고, 각 픽셀마다 R(Red), G(Green), B(Blue) 색상에 대 한 빛의 세기를 감지하여, 빛의 세기를 전기적 신호로 변환하여 객체의 색상, 형상, 명암 등을 표현하는 데이터 를 획득할 수 있다. 이때, 데이터의 타입은 복수의 픽셀 각각에 대해 R, G, B 색상 값을 갖는 이미지일 수 있다. 마이크는 사용자의 음성과 같은 음파를 감지하여, 음파를 전기적 신호로 변환하여 데이터를 획득할 수 있 다. 이때, 데이터의 타입은 다양한 포맷의 오디오 신호일 수 있다. 근접 센서(proximity sensor)는 주변 물체의 존재를 감지하여, 주변 물체의 존재 여부 또는 주변 물체의 근접 여부에 대한 데이터를 획득할 수 있다. 조도 센서는 로봇의 주변 환경에 대한 광량(또는 밝기)을 감지하여, 조도에 대한 데이터를 획득할 수 있다. 모 션 센서는 로봇의 이동 거리, 이동 방향, 기울기 등을 감지할 수 있다. 이를 위해, 모션 센서는 가속도 센 서, 자이로(gyro) 센서, 지자기 센서 등의 결합으로 구현될 수 있다. TOF(Time Of Flight) 센서는 특정한 속도 를 갖는 다양한 전자기파(예: 초음파, 적외선, 레이저, UWB(Ultra-Wideband) 등)를 방출한 후 되돌아오는 비행 시간을 감지하여, 대상과의 거리(또는 위치)에 대한 데이터를 획득할 수 있다. GPS(Global Positioning System) 센서는 복수의 위성으로부터 전파 신호를 수신하고, 수신된 신호의 전달 시간을 이용하여 각 위성과의 거리를 각각 산출하고, 산출된 거리를 삼각측량을 이용하여 로봇의 현재 위치에 대한 데이터를 획득할 수 있다. 다만, 상술한 센서의 구현 예는 일 실시 예일 뿐이며, 이에 제한되지 아니하고 다양한 유형의 센서로 구현 되는 것이 가능하다 할 것이다. 통신부는 다양한 유형의 통신 방식에 따라 다양한 유형의 외부 장치와 통신을 수행하여 다양한 유형의 데 이터를 송수신할 수 있다. 통신부는 다양한 방식의 무선 통신을 수행하는 회로로서 블루투스 모듈(블루투 스 방식), 와이파이 모듈(와이파이 방식), 무선 통신 모듈(3G, 4G, 5G 등의 셀룰러 방식), NFC 모듈(NFC 방식), IR 모듈(적외선 방식), Zigbee 모듈(Zigbee 방식) 및 초음파 모듈(초음파 방식) 등과 유선 통신을 수행하는 이 더넷 모듈, USB 모듈, HDMI(High Definition Multimedia Interface), DP(DisplayPort), D-SUB(D- subminiature), DVI(Digital Visual Interface), 썬더볼트(Thunderbolt) 및 컴포넌트 중 적어도 하나를 포함할 수 있다. 전원부는 로봇의 각 구성에 대해 전원을 공급할 수 있다. 예를 들어, 전원부는 외부 상용 전원 에 의해 충전 가능한 배터리를 포함할 수 있다. 도 9는 본 개시의 일 실시 예에 따른 흐름도를 설명하기 위한 도면이다. 도 9를 참조하여, 로봇의 제어 방법은 로봇에 구비된 뎁스 카메라를 통해 촬영을 수행하여 뎁스 이미지를 획득하는 단계(S910), 뎁스 이미지의 복수의 픽셀의 뎁스 정보에 기초하여 복수의 픽셀에 대응되는3D(three-dimensional) 공간 상의 복수의 3D 포인트를 생성하는 단계(S920), 복수의 3D 포인트 중 3D 공간 상 에서 로봇의 주행하는 바닥면을 기준으로 기설정된 높이 값을 갖는 복수의 3D 포인트를 식별하는 단계 (S930), 및 식별된 복수의 3D 포인트에 기초하여 로봇이 주행하도록 로봇에 구비된 구동부를 제 어하는 단계(S940)를 포함할 수 있다. 구체적으로, 로봇의 제어 방법은 먼저 로봇에 구비된 뎁스 카메라를 통해 촬영을 수행하여 뎁스 이미지를 획득할 수 있다(S910). 다음으로, 뎁스 이미지의 복수의 픽셀의 뎁스 정보에 기초하여 복수의 픽셀에 대응되는 3D(three-dimensional) 공간 상의 복수의 3D 포인트를 생성할 수 있다(S920). 다음으로, 복수의 3D 포인트 중 3D 공간 상에서 로봇의 주행하는 바닥면을 기준으로 기설정된 높이 값을 갖는 복수의 3D 포인트를 식별할 수 있다(S930). 여기서, 기설정된 높이 값은 로봇의 높이 값에 기초하여 설정 된 높이 값일 수 있다. 일 실시 예로서, 식별하는 단계는 3D 공간 상의 복수의 3D 포인트의 분포에 기초하여, 3D 공간 상에서 로봇 이 주행하는 바닥면을 판단하는 단계를 포함할 수 있다. 여기서 식별하는 단계는, 판단된 바닥면이 3D 공간 상의 기설정된 평면에 맵핑되도록, 3D 공간 상의 복수의 3D 포인트를 회전시키고, 회전된 복수의 3D 포인트 중 기설정된 평면을 기준으로 기설정된 높이 값을 갖는 복수의 3D 포인트를 식별할 수 있다. 한편, 기설정된 평면은 XYZ 축으로 정의되는 3D 공간 상의 XZ 평면에 해당할 수 있다. 이 경우, 식별하는 단계 는 회전된 복수의 3D 포인트 중 Y 축의 값이 기설정된 값을 갖는 복수의 3D 포인트를 식별하는 것을 포함할 수 있다. 여기서, 식별하는 단계는, 식별된 복수의 3D 포인트의 X 축의 값 및 Z 축의 값에 기초하여 식별된 복수의 3D 포 인트를 2D 데이터로 변환할 수 있다. 한편, 식별하는 단계는, 복수의 3D 포인트 중 바닥면을 기준으로 기설정된 높이 값을 포함하는 기설정된 임계 범위 내의 높이 값을 갖는 복수의 3D 포인트를 식별할 수 있다. 다음으로, 식별된 복수의 3D 포인트에 기초하여 로봇이 주행하도록 로봇에 구비된 구동부를 제 어할 수 있다(S940). 여기서, 제어하는 단계는 2D 데이터에 기초하여 로봇이 주행하도록 구동부를 제어할 수 있다. 본 개시의 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는 저장 매체로부터 저장된 명령 어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 전자 장치(예: 로봇 )를 포함할 수 있다. 상기 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 상기 프로세서의 제어 하에 다른 구성요소들을 이용하여 상기 명령에 상기하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인 터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는 비일시적(non- transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하지 않 으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽 을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으 며, 전술한 상기 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나 의 개체로 통합되어, 통합되기 이전의 각각의 상기 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다."}
{"patent_id": "10-2020-0121772", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 로봇을 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 로봇의 구성을 설명하기 위한 블록도이다. 도 3a는 본 개시의 일 실시 예에 따른 뎁스 이미지를 통해 3D 포인트를 생성하는 방법을 설명하기 위한 도면이 다. 도 3b는 본 개시의 일 실시 예에 따른 뎁스 이미지를 통해 3D 포인트를 생성하는 방법을 설명하기 위한 도면이 다. 도 4a는 본 개시의 일 실시 예에 따른 바닥면을 식별하는 방법을 설명하기 위한 도면이다. 도 4b는 본 개시의 일 실시 예에 따른 바닥면을 식별하는 방법을 설명하기 위한 측면도이다. 도 5a는 본 개시의 일 실시 예에 따른 복수의 3D 포인트를 정렬하는 방법을 설명하기 위한 도면이다. 도 5b는 본 개시의 일 실시 예에 따른 복수의 3D 포인트를 정렬하는 방법을 설명하기 위한 정면도이다. 도 5c는 본 개시의 일 실시 예에 따른 복수의 3D 포인트를 정렬하는 방법을 설명하기 위한 측면도이다. 도 6a는 본 개시의 일 실시 예에 따른 특정한 높이의 3D 포인트를 식별하는 방법을 설명하기 위한 도면이다. 도 6b는 본 개시의 일 실시 예에 따른 특정한 높이의 3D 포인트를 식별하는 방법을 설명하기 위한 정면도 및 측 면도이다. 도 7은 본 개시의 일 실시 예에 따른 2D 데이터를 생성하는 방법을 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시 예에 따른 로봇의 부가적인 구성을 설명하기 위한 블록도이다. 도 9는 본 개시의 일 실시 예에 따른 흐름도를 설명하기 위한 도면이다."}
