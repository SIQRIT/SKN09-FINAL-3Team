{"patent_id": "10-2023-0009684", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0117392", "출원번호": "10-2023-0009684", "발명의 명칭": "유연한 뉴럴 네트워크 장치 및 이의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "김민제"}}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "뉴럴 네트워크 모델의 레이어의 연산에 필요한 가중치를 저장하고 연산하는 연산 모듈;상기 레이어의 연산을 수행할 때 필요한 설정 정보를 생성하는 제어 모듈;상기 설정 정보에 기초하여 상기 레이어의 연산에 필요한 입력 데이터를 수신하는 입력 모듈;상기 연산 모듈로부터 상기 레이어의 연산 결과를 수신하고, 상기 수신한 레이어의 연산 결과를 병합하는 병합모듈;상기 병합 모듈로부터 상기 레이어의 연산 결과를 수신하고, 상기 수신한 레이어의 병합된 연산 결과를 후처리하는 후처리 모듈; 및상기 후처리된 연산 결과를 상기 설정 정보에 기초하여 변환 및 저장하는 출력 스트림 모듈을 포함하는뉴럴 네트워크 장치."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제어 모듈은,상기 레이어의 연산에 필요한 설정 데이터에 기초하여 상기 뉴럴 네트워크 장치를 구동하는 구성 레지스터(configure register)에 대한 정보를 생성하고, 상기 뉴럴 네트워크 장치의 사이클에 따른 동작을 제어하는 제어 신호(control signal)에 대한 정보를 생성하는 동작을 수행하는,뉴럴 네트워크 장치."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제어 신호는,서로 다른 종류의 버퍼 간 입력 특징 맵 데이터의 이동을 할 수 있도록 제어하는 신호,동일 종류의 버퍼 간 입력 특징 맵 데이터의 이동을 할 수 있도록 제어하는 신호, 및특정 사이클에 발생한 출력 값이 유효하다는 점을 알리는 신호를 포함하는,뉴럴 네트워크 장치."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 연산 모듈은,보정 범위 값이 미리 정해진 제1 값인 경우, 상기 연산의 결과의 디지털 값의 크기를 축소하는 동작을수행하고,상기 보정 범위 값이 미리 정해진 제2 값인 경우, 상기 연산의 결과의 디지털 값의 크기를 확장하는 동작을 수공개특허 10-2024-0117392-3-행하는,뉴럴 네트워크 장치."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 연산 모듈은,중심값 이동 범위 값에 기초하여 상기 연산의 중심값을 이동하는 동작을 수행하는뉴럴 네트워크 장치."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 후처리 모듈은,풀링(pooling), 배치 정규화(batch normalization), 활성화(activation) 및 출력 결과 비트 변환(selector)의후처리 연산을 수행하는 동작 및상기 후처리 연산의 결과를 상기 설정 정보에 기초하여 변환된 상기 연산의 결과 값을 저장하는 동작을 수행하는,뉴럴 네트워크 장치."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 후처리 모듈은,특정 사이클에 발생한 출력 값이 유효하다는 점을 알리는 신호 값을 받는 경우에 상기 후처리 연산을 수행하는,뉴럴 네트워크 장치."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 수신한 데이터와 관련한 입력 데이터를 컬럼(column) 방향으로 변환하는 동작을 수행하는 인터페이스 모듈을 더 포함하는,뉴럴 네트워크 장치."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,시프트 버퍼(shift buffer)를 통해 데이터를 재사용하면서 가공하는 동작을 수행하는 메모리를 더 포함하는,뉴럴 네트워크 장치.공개특허 10-2024-0117392-4-청구항 10 제1항에 있어서,상기 입력 모듈은,상기 연산의 결과를 버퍼에 저장하는 동작; 및상기 저장된 연산의 결과를 미리 정해진 순서에 따라 수신하는 동작을 수행하는,뉴럴 네트워크 장치."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 연산 모듈은,계층적 구조를 포함하는,뉴럴 네트워크 장치."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "뉴럴 네트워크 모델의 레이어의 연산에 필요한 가중치를 저장하는 동작;상기 뉴럴 네트워크 모델이 상기 저장된 가중치를 이용하여 상기 레이어의 연산을 수행할 때 필요한 설정 정보를 생성하는 동작;상기 설정 정보에 기초하여 상기 연산에 필요한 입력 데이터를 수신하는 동작;상기 입력 데이터에 기초하여 상기 뉴럴 네트워크 모델의 레이어를 연산하는 동작;상기 연산의 결과 값을 후처리하는 동작 및상기 연산의 결과 값을 저장하는 동작을 포함하는,뉴럴 네트워크 장치의 제어 방법."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 설정 정보를 생성하는 동작은,상기 레이어의 연산에 필요한 설정 데이터에 기초하여 상기 뉴럴 네트워크 장치를 구동하는 구성 레지스터(configure register)에 대한 정보를 생성하고, 상기 뉴럴 네트워크 장치의 사이클에 따른 동작을 제어하는 제어 신호(control signal)에 대한 정보를 생성하는 동작을 포함하는,뉴럴 네트워크 장치의 제어 방법."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 제어 신호는,서로 다른 종류의 버퍼 간 입력 특징 맵 데이터의 이동을 할 수 있도록 제어하는 신호,공개특허 10-2024-0117392-5-동일 종류의 버퍼 간 입력 특징 맵 데이터의 이동을 할 수 있도록 제어하는 신호,특정 사이클에 발생한 출력 값이 유효하다는 점을 알리는 신호를 포함하는,뉴럴 네트워크 장치의 제어 방법."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 뉴럴 네트워크 모델의 레이어를 연산하는 동작은,보정 범위 값이 미리 정해진 제1 값인 경우, 상기 연산의 결과의 디지털 값의 크기를 축소하는 동작을포함하고,상기 보정 범위 값이 미리 정해진 제2 값인 경우, 상기 연산의 결과의 디지털 값의 크기를 확장하는 동작을 포함하는,뉴럴 네트워크 장치의 제어 방법."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,상기 뉴럴 네트워크 모델의 레이어를 연산하는 동작은,중심값 이동 범위 값에 기초하여 상기 연산의 중심값을 이동하는 동작을 포함하는뉴럴 네트워크 장치의 제어 방법."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서,상기 연산의 결과 값을 후처리하는 동작은,풀링(pooling), 배치 정규화(batch normalization), 활성화(activation) 및 출력 결과 비트 변환(selector)의후처리 연산을 수행하는 동작 및상기 후처리 연산의 결과를 상기 설정 정보에 기초하여 변환된 상기 연산의 결과 값을 저장하는 동작을 포함하는,뉴럴 네트워크 장치의 제어 방법."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서,상기 후처리 연산을 수행하는 동작은,특정 사이클에 발생한 출력 값이 유효하다는 점을 알리는 신호 값을 받는 경우에 수행되는 것인,뉴럴 네트워크 장치의 제어 방법."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서,공개특허 10-2024-0117392-6-상기 연산에 필요한 입력 데이터를 수신하는 동작은,상기 수신한 데이터와 관련한 입력 데이터를 컬럼(column) 방향으로 변환하는 동작을 포함하는,뉴럴 네트워크 장치의 제어 방법."}
{"patent_id": "10-2023-0009684", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제12항에 있어서,상기 연산에 필요한 입력 데이터를 수신하는 동작은, 시프트 버퍼(shift buffer)를 통해 데이터를 재사용하면서가공하는 동작을 포함하는,뉴럴 네트워크 장치의 제어 방법."}
{"patent_id": "10-2023-0009684", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "유연한 뉴럴 네트워크 장치 및 이의 제어 방법이 개시된다. 뉴럴 네트워크 장치는 뉴럴 네트워크 모델의 레이어 의 연산에 필요한 가중치를 저장하고 연산하는 연산 모듈, 레이어의 연산을 수행할 때 필요한 설정 정보를 생성 하는 제어 모듈, 설정 정보에 기초하여 레이어의 연산에 필요한 입력 데이터를 수신하는 입력 모듈, 연산 모듈로 부터 레이어의 연산 결과를 수신하고, 수신한 레이어의 연산 결과를 병합하는 병합 모듈, 병합 모듈로부터 레이 어의 연산 결과를 수신하고, 수신한 레이어의 병합된 연산 결과를 후처리하는 후처리 모듈 및 후처리된 연산 결 과를 설정 정보에 기초하여 변환 및 저장하는 출력 스트림 모듈을 포함한다."}
{"patent_id": "10-2023-0009684", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 유연한 뉴럴 네트워크 장치 및 이의 제어 방법에 관한 것이다."}
{"patent_id": "10-2023-0009684", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 거대 딥 러닝 모델의 등장으로 기존에 풀지 못했던 문제들을 해결하고 있어 많은 관심을 받고 있다. 하지 만 최신 언어 모델의 파라미터 개수는 기존 언어 모델보다 최소 수백, 수천 배가 많아져 대규모 데이터를 학습 시키고 추론하기 위한 고성능 컴퓨팅 파워와 연산 가속이 필수적이다. 이에 인메모리 컴퓨팅으로 뉴럴 네트워크 연산들을 병렬로 수행하는 뉴로모픽 프로세서(neuromorphic processor)와 같은 저전력 인공지능 프로세서에 대 한 관심 또한 증가하고 있다. 뉴로모픽 프로세서는 인메모리 컴퓨팅 모듈을 기반으로 저전력으로 뉴럴 네트워크를 운용하는 뉴럴 네트워크 장 치로 이용될 수 있고, 데이터 분류(classification), 이미지 인식(recognition) 또는 자연어 처리를 포함하는 분야들에서 다양하게 활용될 수 있다."}
{"patent_id": "10-2023-0009684", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 뉴럴 네트워크 장치는, 뉴럴 네트워크 모델의 레이어의 연산에 필요한 가중치를 저장하고 연 산하는 연산 모듈; 상기 레이어의 연산을 수행할 때 필요한 설정 정보를 생성하는 제어 모듈; 상기 설정 정보에 기초하여 상기 레이어의 연산에 필요한 입력 데이터를 수신하는 입력 모듈; 상기 연산 모듈로부터 상기 레이어 의 연산 결과를 수신하고, 상기 수신한 레이어의 연산 결과를 병합하는 병합 모듈; 상기 병합 모듈로부터 상기 레이어의 연산 결과를 수신하고, 상기 수신한 레이어의 병합된 연산 결과를 후처리하는 후처리 모듈; 및 상기 후처리된 연산 결과를 상기 설정 정보에 기초하여 변환 및 저장하는 출력 스트림 모듈을 포함할 수 있다. 상기 제어 모듈은, 상기 레이어의 연산에 필요한 설정 데이터에 기초하여 상기 뉴럴 네트워크 장치를 구동하는 구성 레지스터(configure register)에 대한 정보를 생성하고, 상기 뉴럴 네트워크 장치의 사이클에 따른 동작을 제어하는 제어 신호(control signal)에 대한 정보를 생성하는 동작을 수행할 수 있다. 상기 제어 신호는, 서로 다른 종류의 버퍼 간 입력 특징 맵 데이터의 이동을 할 수 있도록 제어하는 신호, 동일 종류의 버퍼 간 입력 특징 맵 데이터의 이동을 할 수 있도록 제어하는 신호, 특정 사이클에 발생한 출력 값이 유효하다는 점을 알리는 신호를 포함할 수 있다. 상기 연산 모듈은, 보정 범위 값이 미리 정해진 제1 값인 경우, 상기 연산의 결과의 디지털 값의 크기를 축소하 는 동작을 수행하고, 상기 보정 범위 값이 미리 정해진 제2 값인 경우, 상기 연산의 결과의 디지털 값의 크기를 확장하는 동작을 수행할 수 있다. 상기 연산 모듈은, 중심값 이동 범위 값에 기초하여 상기 연산의 중심값을 이동하는 동작을 수행할 수 있다. 상기 후처리 모듈은, 풀링(pooling), 배치 정규화(batch normalization), 활성화(activation) 및 출력 결과 비 트 변환(selector)의 후처리 연산을 수행하는 동작 및 상기 후처리 연산의 결과를 상기 설정 정보에 기초하여 변환된 상기 연산의 결과 값을 저장하는 동작을 수행할 수 있다. 상기 후처리 모듈은, 특정 사이클에 발생한 출력 값이 유효하다는 점을 알리는 신호 값을 받는 경우에 상기 후 처리 연산을 수행할 수 있다. 상기 뉴럴 네트워크 장치는, 상기 수신한 데이터와 관련한 입력 데이터를 컬럼(column) 방향으로 변환하는 동작 을 수행하는 인터페이스 모듈을 더 포함할 수 있다. 상기 뉴럴 네트워크 장치는, 시프트 버퍼(shift buffer)를 통해 데이터를 재사용하면서 가공하는 동작을 수행하 는 메모리를 더 포함할 수 있다. 상기 입력 모듈은, 상기 연산의 결과를 버퍼에 저장하는 동작; 및 상기 저장된 연산의 결과를 미리 정해진 순서 에 따라 수신하는 동작을 수행할 수 있다. 상기 연산 모듈은, 계층적 구조를 포함할 수 있다. 일 실시예에 따른 뉴럴 네트워크 장치의 제어 방법은, 뉴럴 네트워크 모델의 레이어의 연산에 필요한 가중치를 저장하는 동작; 상기 뉴럴 네트워크 모델이 상기 저장된 가중치를 이용하여 상기 레이어의 연산을 수행할 때 필 요한 설정 정보를 생성하는 동작; 상기 설정 정보에 기초하여 상기 연산에 필요한 입력 데이터를 수신하는 동작; 상기 입력 데이터에 기초하여 상기 뉴럴 네트워크 모델의 레이어를 연산하는 동작; 상기 연산의 결과 값 을 후처리하는 동작 및 상기 연산의 결과 값을 저장하는 동작을 포함할 수 있다. 상기 설정 정보를 생성하는 동작은, 상기 레이어의 연산에 필요한 설정 데이터에 기초하여 상기 뉴럴 네트워크 장치를 구동하는 구성 레지스터(configure register)에 대한 정보를 생성하고, 상기 뉴럴 네트워크 장치의 사이 클에 따른 동작을 제어하는 제어 신호(control signal)에 대한 정보를 생성하는 동작을 포함할 수 있다. 상기 제어 신호는, 서로 다른 종류의 버퍼 간 입력 특징 맵 데이터의 이동을 할 수 있도록 제어하는 신호, 동일 종류의 버퍼 간 입력 특징 맵 데이터의 이동을 할 수 있도록 제어하는 신호, 특정 사이클에 발생한 출력 값이 유효하다는 점을 알리는 신호를 포함할 수 있다. 상기 뉴럴 네트워크 모델의 레이어를 연산하는 동작은, 보정 범위 값이 미리 정해진 제1 값인 경우, 상기 연산 의 결과의 디지털 값의 크기를 축소하는 동작을 포함하고, 상기 보정 범위 값이 미리 정해진 제2 값인 경우, 상 기 연산의 결과의 디지털 값의 크기를 확장하는 동작을 포함할 수 있다. 상기 뉴럴 네트워크 모델의 레이어를 연산하는 동작은, 중심값 이동 범위 값에 기초하여 상기 연산의 중심값을 이동하는 동작을 포함할 수 있다. 상기 연산의 결과 값을 후처리하는 동작은, 풀링(pooling), 배치 정규화(batch normalization), 활성화 (activation) 및 출력 결과 비트 변환(selector)의 후처리 연산을 수행하는 동작 및 상기 후처리 연산의 결과를 상기 설정 정보에 기초하여 변환된 상기 연산의 결과 값을 저장하는 동작을 포함할 수 있다. 상기 후처리 연산을 수행하는 동작은, 특정 사이클에 발생한 출력 값이 유효하다는 점을 알리는 신호 값을 받는 경우에 수행되는 것일 수 있다. 상기 연산에 필요한 입력 데이터를 수신하는 동작은, 상기 수신한 데이터와 관련한 입력 데이터를 컬럼(column) 방향으로 변환하는 동작을 포함할 수 있다."}
{"patent_id": "10-2023-0009684", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 개시되어 있는 특정한 구조적 또는 기능적 설명들은 단지 기술적 개념에 따른 실시예들을 설명하 기 위한 목적으로 예시된 것으로서, 실제로 구현된 형태는 다양한 다른 모습을 가질 수 있으며 본 명세서에 설 명된 실시예로만 한정되지 않는다. 제1 또는 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 이런 용어들은 하나의 구성요소 를 다른 구성요소로부터 구별하는 목적으로만 이해되어야 한다. 예를 들어 제1 구성요소는 제2 구성요소로 명명 될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관계를 설명하는 표현들, 예를 들어 \"~간의\"와 \"바로~간의\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 해당 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되 는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 도 1은 생물학적 뉴런과 그 동작을 설명하기 위한 도면이다. 도 1을 참고하면, 생물학적 뉴런은 인간의 신경계에 존재하는 세포를 의미하며, 기초적인 생물학적 계산 개 체의 하나이다. 인간의 두뇌는 대략 1000억개 정도의 생물학적 뉴런들과 그 사이에 위치하는 100조개 정도의 연 결들(Interconnections)을 포함하고 있다. 생물학적 뉴런은 단일 세포이며 세포핵(Nucleus) 및 다양한 세포기관(Organelles)을 포함하는 세포체 (Neuron Cell Body)를 포함한다. 다양한 세포기관은 미토콘드리아, 세포체로부터 방사되는 다수의 수상돌기들(Dendrites) 및 많은 분기 확장선(Extension)들에서 종단하는 축색돌기(Axon)를 포함한다. 일반적으로, 축색돌기는 뉴런으로부터 다른 뉴런으로 신호들을 송신하는 기능을 수행하고, 수상돌기는 다른 뉴 런으로부터 신호를 수신하는 기능을 수행한다. 예를 들어, 서로 다른 뉴런들이 연결되어 있는 경우 뉴런의 축색 돌기를 통해 전달된 신호는 다른 뉴런의 수상돌기에 의해 수신될 수 있다. 이때, 뉴런들 사이에서 신호는 시냅 스(Synapse)라 지칭되는 특화된 연결을 통해 전달되며, 여러 뉴런들이 서로 연결되어 신경망(Neural Network)을 형성한다. 시냅스를 기준으로 신경전달물질(Neurotransmitter)을 분비하는 뉴런은 프리 시냅틱 뉴런(Pre- synaptic Neuron)으로 지칭되고, 신경전달물질을 통해 전달되는 정보를 받는 뉴런은 포스트 시냅틱 뉴런(Post- synaptic Neuron)이라고 지칭될 수 있다. 인간의 두뇌는 이러한 많은 수의 뉴런들이 서로 연결되어 형성되는 신경망을 통해 다양한 신호들을 전달 및 처 리함으로써 방대한 양의 정보를 학습하고 기억할 수 있다. 이러한 생물학적 신경망을 모사하여 방대한 양의 정 보를 효율적으로 처리하기 위한 프로세싱 장치 또는 컴퓨팅 장치를 개발하기 위한 다양한 시도들이 지속되고 있 다. 도 2는 뉴럴 네트워크의 일 예를 설명하기 위한 도면이다. 도 2를 참조하면, 뉴럴 네트워크는 앞서 서술한 생물학적 신경망을 모사한 인공 신경망(Artificial Neural Network)의 일 예이며, 딥 뉴럴 네트워크(DNN, Deep Neural Network)에 해당할 수 있다. 설명의 편의를 위해 뉴럴 네트워크가 2개의 히든 레이어들(Hidden Layers)을 포함하는 것으로 도시되었으나, 다양한 수의 히든 레이어들을 포함할 수 있다. 또한, 도 2에서 뉴럴 네트워크는 입력 데이터를 수신하기 위한 별도의 입력 레 이어(Input Layer)를 포함하는 것으로 도시되었으나, 입력 데이터가 히든 레이어에 직접 입력될 수도 있다. 뉴럴 네트워크에서 출력 레이어(Output Layer)를 제외한 레이어들의 인공 노드들은 출력 신호를 전송하기 위한 링크들을 통해 다음 레이어의 인공 노드들과 연결될 수 있다. 이들 링크를 통해 하나의 인공 노드에는 이 전 레이어에 포함된 인공 노드들의 노드 값과 각 링크에 할당된 웨이트가 곱해진 값들이 입력될 수 있다. 이전 레이어의 노드 값들은 액손 값들에 해당하고, 웨이트는 시냅틱 웨이트들에 해당한다. 웨이트는 뉴럴 네트워크 의 파라미터로 지칭될 수 있다. 활성 함수는 시그모이드(Sigmoid), 하이퍼볼릭 탄젠트(Hyperbolic Tangent; Tanh) 및 렐루(Rectified Linear Unit; ReLU)를 포함할 수 있고, 활성 함수에 의해 뉴럴 네트워크에 비선 형성이 형성될 수 있다. 이러한 뉴럴 네트워크에 포함된 임의의 한 노드의 출력은 아래 수학식 1과 같이 나타낼 수 있다. 수학식 1"}
{"patent_id": "10-2023-0009684", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1은 임의의 레이어에서 m개의 입력 값에 대한 i번째 노드의 출력 값 를 나타낼 수 있다. 는 이 전 레이어의 j번째 노드의 출력 값을 나타낼 수 있고, 는 이전 레이어의 j번째 노드와 현재 레이어의 i번째 노드의 연결부에 적용되는 웨이트를 나타낼 수 있다. f()는 활성 함수를 나타낼 수 있다. 수학식 2에 나타 난 바와 같이, 활성 함수에 대해, 입력값 및 웨이트 의 곱셈 누적 결과가 사용될 수 있다. 다시 말해, 원 하는 시점에 적절한 입력 값 및 웨이트 를 곱하고 더하는 연산(MAC 연산)이 반복될 수 있다. 이러한 용도 외에도, MAC 연산을 필요로 하는 다양한 응용분야가 있으며, 이를 위해 아날로그 회로 영역에서 MAC 연산을 처 리할 수 있는 프로세싱 장치가 사용될 수 있다. 뉴럴 네트워크의 뉴런은 가중치 또는 편향의 조합을 포함할 수 있다. 뉴럴 네트워크는 복수의 뉴런들 또는 노 드들로 구성된 복수의 레이어(layer)들을 포함할 수 있다. 뉴럴 네트워크는 뉴런의 가중치를 학습을 통해 변화시킴으로써 임의의 입력으로부터 예측하고자 하는 결과를 추론할 수 있다. 뉴럴 네트워크는 심층 뉴럴 네트워크 (deep neural network)를 포함할 수 있다. 뉴럴 네트워크는 CNN(convolutional neural network), RNN(recurrent neural network), 퍼셉트론(perceptron), 다층 퍼셉트론 (multilayer perceptron), FF(feed forward), RBF(radial basis network), DFF(deep feed forward), LSTM(long short term memory), GRU(gated recurrent unit), AE(auto encoder), VAE(variational auto encoder), DAE(denoising auto encoder), SAE(sparse auto encoder), MC(markov chain), HN(hopfield network), BM(boltzmann machine), RBM(restricted boltzmann machine), DBN(deep belief network), DCN(deep convolutional network), DN(deconvolutional network), DCIGN(deep convolutional inverse graphics network), GAN(generative adversarial network), LSM(liquid state machine), ELM(extreme learning machine), ESN(echo state network), DRN(deep residual network), DNC(differentiable neural computer), NTM(neural turning machine), CN(capsule network), KN(kohonen network) 및 AN(attention network)를 포함 할 수 있다. 도 3은 일 실시예에 따른 유연한 뉴럴 네트워크 장치의 구성을 설명하기 위한 도면이다. 프로세서의 종류 중 하나인 범용 프로세서(general-purpose processor; GPP)는 다양한 응용분야에 활용될 수 있 는 장점이 있으나, 여러 개의 복잡한 구성요소를 포함하고 있다. 범용 프로세서는 공통의 데이터 패스로 운용 이 되며, 프로그램 메모리, 데이터 메모리, 레지스터 파일, 컨트롤러, 공용 산술연산 장치 등 범용 계산이 가능 한 회로로 구성되어 있다. 또한, 연산장치와 기억장치가 분리되어 있는 폰 노이만 구조의 컴퓨팅 시스템에서는 데이터를 기억장치에서 연산장치로 이동시킬 때 병목현상이 발생하여, 전체 소모 전력이 크게 발생하고, 시스템 의 성능이 저하되는 경우가 있다. 다른 프로세서의 종류인 전용 프로세서(single-purpose processor; SPP)는 단일 목적 칩으로 목적에 따라 고속 칩, 저전력 칩, 소형 칩 등으로 개발이 가능하며, 목적에 따라 필요한 단위회로로 프로세서를 구성하여 개발한 다. 뉴로모픽 프로세서는 저전력 인공지능 가속 칩으로 얼굴 검출(Face Detection) 응용분야의 경우, 컨볼루션, 풀링, 액티베이션 등 특화된 회로를 개발하여 효율적인 기능으로 구동될 수 있게 시스템을 구성할 수 있다. 전용 프로세서로 범용적인 응용을 구동하기 위해서는 칩 외부에서 추가적인 후처리 연산을 하거나, 디지 털 신호 처리 장치(Digital Signal Processing, DSP), 마이크로 컨트롤 유닛(Micro Control Unit, MCU) 등의 Co-processor의 도움을 받아야 한다. 이러한 경우, 추가적인 연산 장치간에 입력값/결과값 이동이 필요하고, 처리할 데이터가 큰 경우, 중간 결과값들의 저장해야하는 상황도 발생한다. 추가적인 입력값, 중간값, 결과값 이 이동에 비례하여 통신 비용이 증가하여 비효율적인 시스템이 될 수 있다. 본 개시에서는 이러한 전용 프로세서와 범용 프로세서의 장단점을 절충하여, 다양한 뉴럴 네트워크 모델을 구동 함에 있어서 범용적인 응용이 가능한 전자 장치를 제안한다. 도 3을 참조하면, 유연한 뉴럴 네트워크 장치를 구동하는 전자 장치는 마이크로 프로세서, 프로그램 메모리, 센서 모듈, 데이터 메모리, 인터페이스 모듈 및 뉴럴 네트워크 장치를 포함 할 수 있다. 마이크로 프로세서는 뉴럴 네트워크 장치를 구동하는 전자 장치의 전반적인 동작을 제어할 수 있다. 마이크로 프로세서는 하나의 프로세서 코어를 포함하거나, 복수의 프로세서 코어들을 포함할 수 있 다. 마이크로 프로세서는 프로그램 메모리, 데이터 메모리에 저장된 프로그램들을 실행할 수 있다. 마이크로 프로세서는 센서 모듈과 인터페이스 모듈의 기능을 제어할 수 있다. 마이크로 프로세서는 마이크로 컨트롤 유닛(MCU) 등으로 구현될 수 있다. 프로그램 메모리는 전자 장치를 제어하기 위한 명령들(Instructions) 또는 데이터를 일시적으로 저장 할 수 있다. 프로그램 메모리에 저장된 명령들 또는 데이터는 마이크로 프로세서의 제어에 따라 뉴럴 네트워크 모델을 구동하는 전자 장치에 포함된 뉴럴 네트워크 장치로 이동할 수 있다. 프로그램 메 모리는 DRAM(Dynamic RAM) 또는 SRAM(Static RAM) 등의 메모리로 구현될 수 있다. 센서 모듈은 뉴럴 네트워크 시스템이 탑재되는 전자 장치 주변의 정보를 수집할 수 있다. 센서 모듈 은 전자 장치의 외부로부터 발생하는 음성 신호, 영상 신호 등을 센싱 또는 수신하고, 센싱 또는 수 신된 신호는 1차적으로 센서 모듈 내에서 뉴럴 네트워크 장치에서 사용할 수 있는 입력 데이터 형태 로 가공 및 변환하여 데이터 메모리로 송신될 수 있다. 예를 들어, 센서 모듈은 카메라 이미지 센서를 포함할 수 있으며, 전자 장치의 외부 환경을 촬영하여 비디오 스트림을 생성하고, 연속하는 데이터 프 레임을 뉴럴 네트워크 장치에서 필요한 특정한 패턴의 입력 데이터로 제공할 수 있다. 센서 모듈은 마이 크, 카메라 이미지 센서 등 다양한 종류의 센싱 장치를 포함할 수 있다. 데이터 메모리는 데이터를 저장하기 위한 저장 장소로서 뉴럴 네트워크 장치에서 필요한 입력 데이터, 출력 데이터 등의 각종 데이터를 저장할 수 있다. 데이터 메모리는 센서 모듈 에서 전달된 데이터를 입력 데이터로 저장해 놓을 수도 있고, 인터페이스 모듈을 통해 외부 호스트 컴퓨터에서 입력 데 이터를 전달받아 저장할 수도 있다. 데이터 메모리는 뉴럴 네트워크 장치 내에서 연산을 수행한 결 과 데이터를 저장할 수 있다. 인터페이스 모듈은 뉴럴 네트워크 시스템이 탑재되는 전자 장치와 외부와의 통신 기능을 수행할 수 있다. 인터페이스 모듈은 시리얼 페리페럴 인터페이스(Serial Peripheral Interface; SPI), 선입선출 인 터페이스(First-in First-out Interface; FIFO) 등의 통신 방식을 제공할 수 있다. 인터페이스 모듈은 데이터 메모리에 직접 접근하여 데이터를 사용할 수 있다. 센서 모듈에서 데이터 변환 처리가 어려 운 경우 인터페이스 모듈에 카메라 인터페이스 기능을 추가하여 센싱 기능을 구현할 수 도 있다. 뉴럴 네트워크 장치는 뉴럴 네트워크 모델의 레이어의 연산에 필요한 가중치를 저장하고 연산하는 연산 모 듈((crossbar core; XCORE), (crossbar adder-tree unit array; XAA)(365-1), (crossbar adder-tree unit; XAU)(365-2), (crossbar; XBAR)(365-3)) 레이어의 연산을 수행할 때 필요한 설정 정보를 생성하는 제어 모듈(programmable top control unit; PTCU), 설정 정보에 기초하여 레이어의 연산에 필요한 입력 데이터 를 수신하는 입력 모듈(Input Fetcher Unit; IFU), 연산 모듈로부터 레이어의 연산 결과를 수신하고, 수신 한 레이어의 연산 결과를 병합하는 병합 모듈(Merger), 병합 모듈로부터 레이어의 연산 결과를 수신하고, 수신한 레이어의 병합된 연산 결과를 후처리하는 후처리 모듈(Post-processing Unit; PPU) 및 후처리된 연 산 결과를 설정 정보에 기초하여 변환하는 출력 스트림 모듈(Output Stream Unit; OSU)을 포함할 수 있다. 제어 모듈은 레이어의 연산에 필요한 설정 데이터에 기초하여 뉴럴 네트워크 장치를 구동하는 구성 레지스 터(configure register)에 대한 정보를 생성하고, 뉴럴 네트워크 장치의 사이클에 따른 동작을 제어하는 제어 신호(control signal)에 대한 정보를 생성하는 동작을 수행할 수 있다. 제어 모듈은 프로그램 메모리로부터 가져온 프로그램 데이터와 명령들을 제어 신호와 구성 레지스터 로 변환하여 뉴럴 네트워크 장치가 작동할 수 있도록 할 수 있다. 뉴럴 네트워크 장치는 제어 모듈 를 통해 다양한 운용 시나리오별 연산 모듈을 구동할 수 있다. 구성 레지스터는 제어 모듈이 변환한 레지스터(register) 정보를 일시적으로 저장할 수 있다. 뉴럴 네트워크 장치는 제어 신호에 따라 구동될 때 저장된 구성 레지스터를 참조하여 동작할 수 있다. 입력 모듈은 데이터 메모리에 저장되어 있는 입력 데이터인 입력 특징 맵(input feature map)(IFM)을 읽어와 Pre-fetcher Buffer로 전달해주는 역할을 할 수 있다. 입력 모듈는 데이터 메모리에서 읽어야 할 메모리 주소와 관련된 제어 정보를 생성할 수 있다. 입력 모듈는 생성된 정보를 기준으로 실제 데이터 메모리에서 입력 특징 맵을 가져와 입력 모듈 내부에 있는 버퍼에 저장할 수 있다. 버퍼에 저장된 데이터는 제어 모듈의 제어 신호에 따라 Pre-fetch Buffer로 순차적으로 전달될 수 있다. 이 때, 센서 모듈로부터 데이터 메모리에 뉴럴 네트워크 장치에서 사용할 패턴으로 변환되어 직접 저장된 입력 데이터인 경우, 입력 데이터를 쉬프트(shift)하여 데이터 형태를 재구성할 수 있으며 이에 대해서 는 도 8a 및 도 8b에서 자세히 살핀다. 데이터 형태의 재구성을 통해 전자 장치는 필요한 입력 데이터를 반복적으로 사용할 수 있기 때문에 데이터 메모리의 공간을 효율적으로 운용할 수 있게 된다. 뉴럴 네트워크 장치는 입력 모듈로부터 전달받은 데이터를 일시적으로 내부에 있는 버퍼에 저장하고, XCORE에 전달하는 역할을 하는 Pre-fetch Buffer를 더 포함할 수 있다. 이때 Pre-fetch Buffer 내부 버퍼에 있는 데이터의 할당 상태에 따라 입력 모듈와 제어 모듈 사이 제어 신호를 주고받을 수 있다. 뉴럴 네트워크 장치의 MAC연산은 다수의 연산 모듈(365; 365-1; 365-2; 365-3)을 통해 수행될 수 있다. 연산 모듈은 계층적 구조를 포함할 수 있다. 연산은 XCORE를 통해서 수행될 수 있다. 하나의 XCORE(36 5)내에는 다수의 XAA(365-1)이 포함될 수 있다. 하나의 XAA(365-1)내에 다수의 XAU(365-2)가 포함될 수 있다. 하나의 XAU(365-2)에는 다수의 XBAR(365-3)가 포함될 수 있다. 뉴럴 네트워크 장치는 AdderTree(미도시)를 통해서 다수의 XAA(365-1), 다수의 XAU(365-2), 다수의 XBAR(365-3)의 연산 결과를 합칠 수 있 다. 뉴럴 네트워크 장치는 MUX(미도시)를 통해 다수의 연산 결과들 중 하나를 선택할 수 도 있다. 뉴럴 네트워크 장치는 XCORE, XAA(365-1), XAU(365-2), XBAR(365-3)의 계층적인 구조를 통해 유연한 인메 모리 컴퓨팅(flexible in-memory computing) 연산을 구현할 수 있다. 특히, XBAR(365-3)는 뉴럴 네트워크 모 델의 레이어별 가중치를 저장하고, 행렬 곱셈과 합계(MAC 연산)를 동시에 수행할 수 있는 MAC 연산 장치의 기능 을 수행할 수 있다. 병합 모듈은 다수의 XCORE의 출력 데이터를 합쳐서 병렬화 된 연산 결과값을 병합하는 역할을 할 수 있다. 병합 모듈은 PSDMA를 사용하여 PSDMA가 데이터 메모리로부터 가져온 중간 데이터를 XCORE의 출력 데이터와 병합할 수도 있다. 뉴럴 네트워크 장치는 뉴럴 네트워크 모델의 이전 레이어에서 수행한 중간 결과 데이터를 데이터 메모리 로부터 읽어와 병합 모듈에 전달하는 PSDMA를 더 포함할 수 있다. 병합 모듈과 PSDMA를 통해 뉴럴 네트워크 장치는 채널이 긴 뉴럴 네트워크 모델을 구동할 수 있게 된다. 후처리 모듈은 MAC 연산한 결과값에 추가적인 뉴럴 네트워크 연산을 수행하는 역할을 한다. 추가적인 뉴 럴 네트워크 연산은 Pooling, Batch Normalization, Activation 연산 등을 포함할 수 있다. 후처리 모듈 내의 다수의 뉴럴 네트워크 연산은 Programmable TCU 제어 신호에 따라 적어도 한 개 이상으로 구동이 가능하다. 또한, Programmable TCU 제어 신호가 모두 disable신호이면, 후처리 모듈내의 뉴럴 네트워크 연 산을 하지 않고, MAC 연산한 결과값만 OSU로 보낼 수 도 있다. Output Stream Unit(OSU)는 뉴럴 네트워크 장치 또는 후처리 모듈 의 출력 데이터를 데이터 메모리에 저장하는 기능을 수행할 수 있다. OSU는 출력 데이터의 비트 표현을 4bit, 8bit, 16bit 등 으로 조정하여 데이터 메모리에 저장할 수 있다. 출력 데이터의 비트 표현의 조정을 통해, OSU는 뉴럴 네트워크 모델의 레이어 별 특징 정보량을 조정할 수 있다. 도 4a 및 4b는 일 실시예에 따른 유연한 뉴럴 네트워크 장치의 전체적인 동작을 설명하기 위한 도면들이다. 도 4a을 참조하면, 뉴럴 네트워크 장치에 XCORE 2개, 하나의 XCORE내 XAA(365-1)가3개, 하나의 XAA(365-1)내에 XAU(365-2)가 4개, 하나의 XAU(365-2)내에 XBAR(365-3)가 3개로 구성된 실시예를 확인할 수 있 다. 그러나 이하에서 설명할 본 개시에 따른 실시예가 위 같은 특정 경우에 한정되는 것은 아니다. 뉴럴 네트워크 장치는 전자 장치가 구동하기 전에 뉴럴 네트워크의 레이어의 연산에 필요한 가중치를 MAC 연산하는 XBAR(365-3)에 저장할 수 있다. 제어 모듈은 전자 장치의 XCORE, 입력 모듈, 후처리 모듈, PSDMA, OSU가 구동할 때 필요한 설정 정보인 구성 레지스터(configure register)와 제어 신호(control signal)을 생성할 수 있다. 입 력 모듈는 구성 레지스터와 제어 신호에 따라 데이터 메모리로부터 MAC연산에 필요한 입력 데이 터를 가져올 수 있다. 입력 모듈는 Pre-fetch Buffer에 MAC연산에 필요한 입력 데이터를 전달할 수 있다. Pre-fetch Buffer는 입력 모듈로부터 전달받은 데이터를 일시적으로 내부에 있는 버퍼에 저장 하고, XCORE에 전달하는 역할을 할 수 있다. 이때 Pre-fetch Buffer 내부 버퍼에 있는 데이터의 할 당 상태에 따라 입력 모듈과 제어 모듈 사이 제어 신호를 주고받을 수 있다. 제어 신호에 따라 XBAR(365-3)에서 MAC연산이 수행될 수 있다. MAC 연산의 결과값은 병합 모듈에서 합쳐 질 수 있다. 구성 레지스터에 PSDMA의 설정 정보가 포함되어 있는 경우, 설정 정보에 따라 PSDMA는 이전 레이어에서 연산한 중간 결과 데이터를 데이터 메모리로부터 가져와 병합 모듈에 전달할 수 있 다. 병합 모듈에서 합쳐진 MAC연산의 결과값은 후처리 연산을 위해 후처리 모듈 로 보내질 수 있다. 구성 레지스터의 설정 정보에 따라 후처리 모듈에서 풀링(pooling), 배치 정규화(batch normalization), 활성화(activation) 및 출력 결과 비트 변환(selector)의 후처리 연산이 완료되면, OSU가 구성 레지스터 값에 따라 비트 표현으로 변환된 출력 데이터를 데이터 메모리에 저장할 수 있다. 도 4b를 참조하면, 동작에서 뉴럴 네트워크 장치는 레이어의 연산에 필요한 가중치를 저장할 수 있다. 연 산에 필요한 가중치는 연산 모듈에 저장될 수 있다. 동작에서 뉴럴 네트워크 장치는 저장된 가중치를 이용하여 레이어의 연산을 수행할 때 필요한 설정 정보를 생성할 수 있다. 설정 정보는 구성 레지스터 및 제어 신호를 포함할 수 있다. 동작에서 뉴럴 네트워크 장치는 설정 정보에 기초하여 연산에 필요한 입력 데이터를 수신할 수 있다. 뉴 럴 네트워크 장치의 입력 모듈은 구성 레지스터와 제어 신호에 따라 데이터 메모리로부터 MAC연산에 필요한 입 력 데이터를 가져올 수 있다. 동작, 동작 및 동작은 각각 서로 영향을 주지 않기 때문에 반드 시 언급한 순서대로 수행될 필요는 없으며, 동작의 수행이전에 동작, 동작 및 동작이 임의 의 순서에 따라 모두 수행되는 것으로 족하다. 발명의 설명 및 도면에서는 언급한 동작, 동작 및 동 작이 순차적으로 수행되는 것처럼 표현되었으나, 본 개시에 따른 실시예가 이 같은 특정 순서에 따라 동작 이 수행되는 것에 제한되는 것은 아니다. 동작에서 뉴럴 네트워크 장치는 입력 데이터에 기초하여 뉴럴 네트워크 모델의 레이어를 연산할 수 있다. 뉴럴 네트워크 모델의 레이어의 연산은 연산 결과의 분산과 평균을 보정하는 동작을 포함할 수 있다. 동작에서 뉴럴 네트워크 장치는 뉴럴 네트워크 모델의 레이어의 연산 결과 값을 후처리할 수 있다. 뉴럴 네트워크 모델의 레이어의 연산 결과 값을 후처리하는 동작은, 풀링(pooling), 배치 정규화(batch normalization), 활성화(activation) 및 출력 결과 비트 변환(selector)의 후처리 연산을 수행하는 동작 및 상 기 후처리 연산의 결과를 상기 설정 정보에 기초하여 변환된 상기 연산의 결과 값을 저장하는 동작을 포함할 수 있다. 동작에서 뉴럴 네트워크 장치는 뉴럴 네트워크 모델의 레이어 연산의 결과 값을 저장할 수 있다. 레이어 연산의 결과 값의 저장은 병합 모듈을 통해 뉴럴 네트워크 모델의 이전 레이어의 결과 값을 병합하는 동작을 포 함할 수 있다. 레이어 연산의 결과 값의 저장은 후처리 모듈 및 출력 스트림 모듈을 통해 레이어 연산의 결과 값을 데이터 메모리에 저장하는 동작을 포함할 수 있다. 도 5a 및 도 5b는 일 실시예에 따른 유연한 뉴럴 네트워크 장치에서 제어 신호(control signal) 및 구성 레지스 터(configure register)를 생성하는 동작을 설명하기 위한 도면들이다. 뉴럴 네트워크 장치를 구동하기 위해서는 제어 신호와 구성 레지스터가 필요하다. 도 5a를 참조하면, 제어 모 듈은 DMA와 같은 형태로 동작하여 레이어별로 프로그램 메모리(361-1)에서 필요한 정보를 읽어와 구성 레 지스터를 설정할 수 있다. 제어 모듈은 미리 정해진 범위 이하의 비트수(예: 20 비트)를 갖는 데이 터에 대해서는 직접 데이터를 읽고 쓸 수 있다. 제어 모듈은 하나의 레이어에 대한 설정과 대기를 수행하 여 레이어 간 동작 플로우를 제어할 수 있다. 제어 모듈은 하나의 레이어 내에서 뉴럴 네트워크 장치 내에 포함된 모듈을 동작 시키기 위한 제어 신호를 생성할 수 있다. 제어 신호는 라인 컨트롤러(line controller)(361-2)에 대한 신호, 및 로우 컨트롤러(raw controller)(361- 3)에 대한 신호를 포함할 수 있다. 제어 신호는, 서로 다른 종류의 버퍼 간 입력 특징 맵 데이터의 이동을 할 수 있도록 제어하는 신호, 동일 종류의 버퍼 간 입력 특징 맵 데이터의 이동을 할 수 있도록 제어하는 신호, 특 정 사이클에 발생한 출력 값이 유효하다는 점을 알리는 신호를 포함할 수 있다. 라인 컨트롤러(361-2)에 대한 신호는 제어 모듈의 프로세서가 별도의 작은 하드웨어 엔진을 운용하고 운용 이 끝날때까지 기다리는 형태의 신호일 수 있다. 제어 모듈은 매 사이클마다 연산을 위해 라인 컨트롤러 (361-2)에 대한 신호를 생성할 수 있다. 라인 컨트롤러(361-2)에 대한 신호 중 ifm_pop신호는 Pre-fetch Buffer의 데이터를 IFM_BUFFER로 옮겨오도록 할 수 있다. 라인 컨트롤러(361-2)에 대한 신호 중 shift_en신호 는 IFM_BUFFER간 데이터 이동(shift)을 발생시키는 신호일 수 있으며, 해당 데이터로 연산을 수행하기 위해서 먼저 생성될 수 있다. 라인 컨트롤러(361-2)에 대한 신호 중 out_valid신호는 출력이 유효(valid) 하다는 것을 의미하는 신호일 수 있다. 라인 컨트롤러(361-2)에 대한 신호는 적절하게 지연(delay)되어 최종 출력단에서 사 용되어야 한다. 만약 ifm_pop 신호가 Pre-fetch Buffer로 전달되면, Pre-fetch Buffer는 데이터를 읽어와 IFM_BUFFER로 전달할 수 있는데, 만약 Pre-fetch Buffer에 데이터가 없다면 해당 신호는 데이터가 준비될 때까 지 대기할 수 있다. 로우 컨트롤러(361-3)에 대한 신호는 제어 모듈이 연산 모듈을 제어하기 위해 직접 생성한 신호일 수 있다. Read/Write sequencer 및 Read/Write unit은 구성 레지스터와 관련한 값의 읽기/쓰기 동작을 수행할 수 있다. Register file은 execution logic에 따라 산술 논리 장치(ALU)에서 연산될 수 있으며, instructiondecoder는 instruction fetch unit과 execution logic에 대한 정보를 공유할 수 있다. Read/Write sequencer 에 관한 데이터를 관리하는 data FIFO는 data fetch unit에 의해 관리될 수 있으며, instruction fetch unit 및 data fetch unit 모두 MUX를 통해 단일 회선의 신호가 되어 프로그램 메모리(361-1)에 전달될 수 있다. 제어 신호를 포함하여 제어 모듈가 제공 가능한 명령(instruction)들은 다음 표 1과 같다. 표 1"}
{"patent_id": "10-2023-0009684", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "표 1에 나타난 제어 모듈가 제공 가능한 명령어들의 데이터 구성은 다음 표 2와 같다. 표 2"}
{"patent_id": "10-2023-0009684", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "표 2를 참조하면, 제어 모듈의 RD명령은 주어진 20bit 주소(address)로 구성 레지스터에 접근하여 데 이터를 읽어 Ra에 지정된 레지스터에 저장할 수 있다. RD 연산은 주소와 관련한 주소 Issue를 위해 1 사이클, 데이터를 읽어서 레지스터에 업데이트 하는데 1 사이클을 소모하여 총 2사이클을 소모할 수 있다. WR명령은 R_BASE(R5)와 ADDR_OFFSET(8b)을 더한값을 주소로 사용하여 구성 레지스터에 쓰기(write)를 수 행할 수 있다. 이때 데이터는 명령의 WDATA(20b) 필드에 있는 값을 사용할 수 있으며 미리 정해진 범위 이하의 비트수(예: 20 비트)를 초과하는 상위 비트들은 0으로 패딩(padding)할 수 있다. MOV명령은 레지스터에서 레지스터로의 데이터 전달(register to register transfer)과 레지스터에 20b 임시 (immediate) 값을 저장하는데 사용될 수 있다. ALUR명령은 ARITH field를 참고하여 SUB, ADD, AND 그리고 OR 연산을 수행할 수 있다. ALUI명령은 ARITH field를 참고하여 SUB, ADD, AND 그리고 OR 연산을 수행할 수 있다. 이때 ALUR과 다르게 Ra 대신 Immediate 값을 사용할 수 있다. SHIFT명령은 LEFT/RIGHT field가 '0'이면 데이터를 왼쪽으로 1b 쉬프트(shift left)하고 LEFT/RIGHT field 가 '1' 이면 데이터를 오른쪽으로 1b 쉬프트(shift right)할 수 있다. SWR명령은 마치 구성 레지스터를 설정하기 위한 DMA와 같은 기능을 제공할 수 있다. 즉 Ra 레지스터에 저 장된 값 +1 만큼의 데이터를 프로그램 메모리에서 주소(20b)부터 읽어 R_BASE 주소부터 순차적으로 구성 레지스터에 쓰기를 수행할 수 있다. 즉, SWR명령을 통해 레이어 별 구성 데이터를 프로그램 메모리 의 특정영역에 저장한 후, 이들을 구성 레지스터에 설정 할 수 있게 된다. JMP명령은 COND와 DEC에 따라 타겟 주소로 점프(jump)를 수행할 수 있다. 브랜치(branch)를 하게 되면 next_pc 로 읽은 이전 명령은 사용할 수 없기 때문에 폐기하며, 1사이클의 스톨(stall)이 필요하게 된다. 만약 COND==0 이면 조건없이 타겟 주소로 프로그램 카운터(program counter, PC)값을 변경할 수 있고, COND==1이면 Ra와 Rb 값이 같은 경우에 타겟 주소로 이동한다. 그렇지 않으면 다음 PC(next_pc)의 명령을 수행할 수 있다. DEC가 1 인 경우 Ra값은 Ra-1로 갱신될 수 있다. REG[Ra]와 REG[Rb]가 다른 경우, 타겟 주소로 이동하고, REG[Ra]와 REG[Rb]가 같을 경우 PC를 1씩 증가시켜 다음 주소로 이동할 수 있다. 또한 DEC가 '1' 인 경우, REG[Ra] 값을 1씩 감소시킬 수 있다. SEV명령은 MCU로의 인터럽트(interrupt)를 발생시킬 수 있다. 이때 EVENT_VALUE의 20b 값은 구성 레지스터 에 전달되어, MCU 및 HOST가 값을 읽을 수 있도록 할 수 있다. WFI명령은 PTCU가 별도의 IRQ신호를 받을 때까지 대기하도록 할 수 있다. WFI명령 상태에서는 대부분의기능이 게이팅(gating) 된 상태가 될 수 있다. HALT명령은 PTCU가 모든 명령을 완료하고 프로그램이 끝났다는 것을 의미할 수 있다. 제어 모듈 수행과 관련된 구성 레지스터는 표 3과 같을 수 있다. 표 3"}
{"patent_id": "10-2023-0009684", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 5, "content": "도 5b를 참조하면, 동작에서 뉴럴 네트워크 장치는 프로그램 메모리로부터 뉴럴 네트워크의 레이어별 필요 한 데이터를 수신할 수 있다. 뉴럴 네트워크 장치의 운용 시나리오에 따라 뉴럴 네트워크의 레이어별 필요한 데이터를 수신하는 동작은 데이터를 전처리하는 동작을 포함할 수 있다. 동작에서 뉴럴 네트워크 장치는 뉴럴 네트워크 레이어를 뉴럴 네트워크 장치에서 동작시키기 위한 제어 신 호를 생성할 수 있다. 제어 신호는 서로 다른 종류의 버퍼 간 입력 특징 맵 데이터의 이동을 할 수 있도록 제 어하는 신호, 동일 종류의 버퍼 간 입력 특징 맵 데이터의 이동을 할 수 있도록 제어하는 신호 및 특정 사이클 에 발생한 출력 값이 유효하다는 점을 알리는 신호를 포함할 수 있다. 동작에서 뉴럴 네트워크 장치는 뉴럴 네트워크 레이어 정보 순서대로 데이터를 구성 레지스터에 기록할 수 있다. 구성 레지스터에 기록될 정보는 뉴럴 네트워크 장치의 운용 시나리오에 따라 다를 수 있다. 도 6a 및 도 6b는 일 실시예에 따른 유연한 뉴럴 네트워크 장치의 연산 결과 값을 보정하는 동작을 설명하기 위 한 도면이다. 도 6a를 참조하면, 뉴럴 네트워크 장치에서 MAC연산을 수행하는 XBAR는 MRAM, PRAM, ReRAM, SRAM 등 여러가지 메모리 소자를 사용하여 인메모리 컴퓨팅 형태로 구현될 수 있다. 아날로그 메모리 소자를 이용하는 경우, 소 자 특성에 따라 노이즈가 발생할 수 있으며, 노이즈로 인하여 계산된 중심값이 한쪽으로 치우치는 현상이나 계 산값의 범위가 너무 크거나 작게 나타나는 현상이 나타날 수 있다. 이러한 문제를 해결하기 위해 COL_SHIFT_EN(365-3-1)과 XAU내부의 XBAR_BIAS(365-3-2)를 사용하여 데이터를 정상 출력하거나 보정하여 출력 할 수 있다. 도 6b를 참조하면, 동작에서 뉴럴 네트워크 장치의 연산 모듈은 보정 범위 값이 미리 정해진 제1 값인 경 우, 연산의 결과의 디지털 값의 크기를 축소하는 동작을 수행하고, 보정 범위 값이 미리 정해진 제2 값인 경우, 연산의 결과의 디지털 값의 크기를 확장하는 동작을 수행할 수 있다. 연산 모듈은 보정할 XBAR에 COL_SHIFT_EN 을 설정할 수 있다. COL_SHIFT_EN은 구성 레지스터에 포함되어 XBAR에 가중치를 쓸 때, 비트 위치를 조절 할 수 있는 신호일 수 있다. 동작에서 뉴럴 네트워크 장치는 COL_SHIFT_EN 값이 '0' 인지 여부를 판단하고, COL_SHIFT_EN값이 '0'인 경우, 동작에서 아날로그 XBAR의 아날로그-디지털 변환값의 오른쪽 비트에 '0'을 추가하여 비트를 확장하 고, 데이터 값의 크기는 유지하면서 정상 출력을 수행할 수 있다. 동작에서 뉴럴 네트워크 장치는 COL_SHIFT_EN 값이 '0' 인지 여부를 판단하고, COL_SHIFT_EN값이 '0'이 아니고 '1'인 경우, 아날로그 XBAR의 아날로그 값에서 디지털 값으로 변환된 값의 왼쪽 비트에 부호 비트를 적용하여(sign extension), 값의 크기를 1/2로 축소하는 방법으로 MAC 연산 결과값의 산포를 보정하여 산포 보정 출력을 수행할 수 있다. 즉, COL_SHIFT_EN 값을 적용하므로써 아날로그 XBAR의 MAC 연산값의 범위가 너무 크거나, 작게 나타나는 문제를 해 결할 수 있다. 동작에서 뉴럴 네트워크 장치는 XBAR_BIAS 값을 MAC연산 값에 더하여 평균값을 이동시켜 보정하는 평균 보정 출력을 수행할 수 있다. 동작에서 뉴럴 네트워크 장치는 중심값 이동 범위 값에 기초 하여 연산의 중심값을 이동하는 동작을 수행할 수 있다. 뉴럴 네트워크 장치는 구성 레지스터에 있는 설정값인XBAR_BIAS을 이용하여 COL_SHIFT_EN으로 값의 크기가 보정된 값에 XBAR_BIAS값 만큼 중심값을 이동하여, 중심값 이 한쪽으로 치우치는 현상을 해결할 수 있다. 도 7a 및 도 7b는 일 실시예에 따른 유연한 뉴럴 네트워크 장치의 후처리 동작을 설명하기 위한 도면들이다. 도 7a를 참조하면, 뉴럴 네트워크 장치에서 MAC 연산 출력 데이터는 병합 모듈를 통해 후처리 모듈로 전달될 수 있다. 후처리 모듈은, 풀링(pooling), 배치 정규화(batch normalization), 활성화 (activation) 및 출력 결과 비트 변환(selector)의 후처리 연산을 수행하는 동작 및 후처리 연산의 결과를 설정 정보에 기초하여 변환된 연산의 결과 값을 저장하는 동작을 수행할 수 있다. 후처리 모듈은, 특정 사이클 에 발생한 출력 값이 유효하다는 점을 알리는 신호 값을 받는 경우에 후처리 연산을 수행할 수 있다. POOL(366-1)은 구성 레지스터에 따라 선택적으로 구동이 가능할 수 있다. 예를 들어 2x2 MAX Pooling을 할 지, 1x2 MAX Pooling을 할지도 구성 레지스터에 따라 실행할 수 있어 유연하게 뉴럴 네트워크의 레이어를 구성할 수 있다. 후처리 모듈은 배치 정규화 연산과 활성화 연산을 벡터 유닛(vector unit; VU)(366-2)으로 묶어서 구현할 수 있다. 벡터 유닛에서 배치 정규화 연산을 하는 MUL-ADDER(366-2-1)와 활성화 연산을 하는 ACT-UNIT(366-2- 3)을 직접 연결하게 되면, 별도의 중간 버퍼없이 뉴럴 네트워크의 후처리 연산을 바로 수행할 수 있기 때문에 데이터의 이동을 효율적으로 운용할 수 있다. 또한, 배치 정규화 연산과 활성화 연산 사이를 MUX(366-2-2)로 구성하여 보다 유연하게 운용할 수 도 있다. 구성 레지스터에 따라 후처리 연산은 바이패스(by pass) 이후 활 성화 연산, 바이패스 이후 Selector(366-2-4)에서의 연산, MUL-ADDER(366-2-1)에서의 연산 이후 ACT- UNIT(366-2-3) 에서의 연산 및 MUL-ADDER(366-2-1)에서의 연산 이후 Selector(366-2-4)에서의 연산의 4가지로 뉴럴 네트워크의 후처리 연산 조합을 구성할 수 있다. Selector(366-2-4)는 구성 레지스터 중 OSU_BIT_MODE, PP_VU_SELECT_MODE에 따라 출력할 비트 형태로 후처리 모듈의 결과 값을 변환할 수 있다. Selector(366- 2-4)는 결과 값의 비트형태 변환시, 비트별 정수부와 소수부의 자리를 조정할 수 있기 때문에 레이어 특성에 따 라 선택적으로 특징 정보량을 조정하여 다양한 운용방법을 구성할 수도 있도록 한다. 도 7b를 참조하면 동작에서 뉴럴 네트워크 장치는 후처리 장치의 구성 레지스터 값을 가져올 수 있다. 동작에서 뉴럴 네트워크 장치는 CNN, RNN, LSTM 등의 응용에 맞는 배치 정규화(BN)를 위한 스케일(scale) 값과 바이어스(bias)값을 적용할 수 있다. 뉴럴 네트워크 장치는 벡터 유닛에서 배치 정규화 연산을 구동할 때 제어 모듈에서 생성한 scale_bias_sel 신호에 따라 다수의 스케일값과 바이어스값을 선택적으로 사용할 수 있다. 구성 레지스터를 통한 스케일 값과 바이어스 값의 공급을 통해 뉴럴 네트워크 장치는 후처리 연산시 추 가적인 데이터의 이동을 줄일 수 있다. 동작에서 뉴럴 네트워크 장치는 응용에 따라 사전 정의된 activation_table의 값을 가져와 활성화 연산을 수행할 수 있다. 활성화 연산을 수행할 때도 제어 모듈에서 생성한 act_sel 신호에 따라 다수의 activation_table 값을 선택적으로 사용할 수도 있다. 구성 레지스터를 통한 activation_table 값의 공급을 통해 뉴럴 네트워크 장치는 후처리 연산시 추가적인 데이터의 이동을 줄일 수 있다. 동작에서 뉴럴 네트워크 장치는 후처리된 값을 레이어별 설정 값에 따라 출력 결과의 비트로 변환하는 동 작을 수행할 수 있다. 뉴럴 네트워크 장치는 레이어 별 구성 레지스터를 포함하는 설정 값에 따라 다양한 시나 리오별로 출력 결과의 비트 값을 획득할 수 있다. 도 8a 및 도 8b는 일 실시예에 따른 유연한 뉴럴 네트워크 장치를 통해 영상 이미지를 전처리 하는 동작을 설명 하기 위한 도면들이다. 다채널 입력 데이터의 경우 얼굴 검출, 영상 인식 등의 뉴럴 네트워크 응용분야에서 주로 사용하는 컨볼루션 뉴 럴 네트워크 모델(CNN)은 첫번째 입력 데이터로 RGB 3개 입력 채널의 영상 이미지를 사용할 수 있다. 이러한 응 용에서 XBAR의 사용률이 떨어지는 문제와 데이터 메모리를 최소 사용 비트에 맞추어서 저장해야 하는 문제의 두 가지 문제가 있을 수 있다. 이러한 문제들을 해결하기 위해 다채널 입력 데이터를 선형 데이터의 형태로 전처 리할 수 있다. 도 8a를 참조하면 영상 이미지의 연산 이전 이미지의 센서 모듈, 인터페이스 모듈, 데이터 메모리 및 입력 모듈에서 데이터의 전처리를 수행하는 과정을 볼 수 있다. 도 8a의 (a)를 살피면, 뉴럴 네트워크 장치는 수신한 데이터와 관련한 입력 데이터를 컬럼(column) 방향으로 변 환하는 동작을 수행하는 인터페이스 모듈을 더 포함할 수 있다. 인터페이스 모듈은 입력 데이터를 컬럼 방향으 로 묶고, (b)에서와 같이 선형 데이터의 형태로 변환할 수 있다. 변환된 데이터는 (c)에서와 같이 시프트 버퍼 를 통해 수평 방향으로 전달되어 처리될 수 있다. 도 8b를 참조하면, 동작에서 뉴럴 네트워크 장치의 인터페이스 모듈은 통해 센서 모듈로부터 입력 받은 이 미지를 수직 방향으로 1차원 변환할 수 있다. 이미지의 1차원 변환은 예를 들어 도 8a의 (a) 및 (b)에서의 변 환과 대응될 수 있다. 동작에서 뉴럴 네트워크 장치는 시프트 버퍼(shift buffer)를 통해 데이터를 재사용하면서 가공하는 동작 을 수행하는 메모리를 더 포함할 수 있다. 뉴럴 네트워크 장치는 인터페이스 모듈을 통해 통신 어세스(access) 단위 크기별로 데이터를 데이터 메모리에 저장할 수 있다. 뉴럴 네트워크 장치는 입력 데이터를 컬럼 방향으로 3개씩 데이터를 묶어서 데이터 메모리의 최소 사용 비트인 128비트 단위로 나누어서 저장할 수 있다. 동작에서 뉴럴 네트워크 장치는 데이터 메모리에 저장되어 있는 데이터를 입력 모듈을 통해 가공 (reformat) 후, 시프트 버퍼를 사용하여 수평방향으로 데이터를 재사용하면서 Pre-fetcher Buffer에서 사용할 데이터로 가공하여 사용할 수 있다. 도 9는 일 실시예에 따른 유연한 뉴럴 네트워크 장치의 인풋 피딩(input feeding) 방식을 설명하기 위한 도면이 다. 도 9를 참조하면, 장치의 인풋 피딩(input feeding) 방식을 확인할 수 있다. 인풋 피딩(input feeding) 방식은 자연어 처리 등에 주로 활용되는 RNN(recurrent neural network) 및 LSTM(long short term memory)의 학습을 위해 데이터를 전처리하는 과정을 포함할 수 있다. RNN 및 LSTM은 이전 시간에서의 히든 레이어의 상태와 현재 입력 벡터 값에 따라 파라미터를 업데이트 하는 뉴럴 네트워크 모델에 해당한다. 뉴럴 네트워크 장치의 입력 모듈은 연산의 결과를 버퍼에 저장하는 동작 및 저장된 연산의 결과를 미리 정해진 순서에 따라 수신하는 동작을 수행할 수 있다. 뉴럴 네트워크 장치는 동일 입력을 한번에 연산한 결과를 버퍼에 저장 후 순차적으로 가져오는 구조를 통해 다 수의 XAA(365-1)에 입력을 쉬프트 버퍼(shift buffer)형태로 연결하여 4라인 입력이 3라인씩 XAA(365-1)로 전 달되도록 할 수 있다. 즉 입력 모듈이 입력 벡터 Xt 와 이전 시간에서의 히든 레이어의 상태를 Pre-fetch Buffer에 동일한 데이터로 넣어주면, 이를 전달 받은 다수의 XAA(365-1)는 동일한 입력과 서로 다른 가중 치를 이용하여 선형 연산을 수행할 수 있다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 실시예들에서 설명된 장치, 방법 및 구성요소는, 프로세서, 컨트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 범용 컴퓨터 또는 특수 목적 컴퓨터를 이 용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리케 이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만, 해"}
{"patent_id": "10-2023-0009684", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복 수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성 (processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있 다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수 도 있다. 소프트웨어 및 데이터는 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단 독으로 또는 조합하여 저장할 수 있으며 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구 성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 위에서 설명한 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 또는 복수의 소프트웨어 모듈로서 작동하 도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2023-0009684", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 이를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 설명된 기술들이 설명된 방법과 다른 순서로 수행 되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조 합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2023-0009684", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 생물학적 뉴런과 그 동작을 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 뉴럴 네트워크의 일 예를 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 유연한 뉴럴 네트워크 장치의 구성을 설명하기 위한 도면이다. 도 4a 및 4b는 일 실시예에 따른 유연한 뉴럴 네트워크 장치의 전체적인 동작을 설명하기 위한 도면들이다. 도 5a 및 도 5b는 일 실시예에 따른 유연한 뉴럴 네트워크 장치에서 제어 신호(control signal) 및 구성 레지스 터(configure register)를 생성하는 동작을 설명하기 위한 도면들이다. 도 6a 및 도 6b는 일 실시예에 따른 유연한 뉴럴 네트워크 장치의 연산 결과 값을 보정하는 동작을 설명하기 위 한 도면들이다. 도 7a 및 도 7b는 일 실시예에 따른 유연한 뉴럴 네트워크 장치의 후처리 동작을 설명하기 위한 도면들이다. 도 8a 및 도 8b는 일 실시예에 따른 유연한 뉴럴 네트워크 장치를 통해 영상 이미지를 전처리 하는 동작을 설명 하기 위한 도면들이다. 도 9는 일 실시예에 따른 유연한 뉴럴 네트워크 장치의 인풋 피딩(input feeding) 방식을 설명하기 위한 도면이 다."}
