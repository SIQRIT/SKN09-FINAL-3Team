{"patent_id": "10-2022-0137774", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0057254", "출원번호": "10-2022-0137774", "발명의 명칭": "인공지능 기반 동영상 구간 검색 방법 및 장치", "출원인": "주식회사 카카오", "발명자": "민규식"}}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서에 의해 동작하는 동영상 구간 검색 장치의 동작 방법으로서,텍스트 질의를 입력받는 단계,상기 텍스트 질의에 해당하는 적어도 하나의 입력 텍스트를 텍스트 인코더로 입력하여, 상기 텍스트 질의에 해당하는 적어도 하나의 텍스트 특징 벡터를 획득하는 단계, 소스 동영상을 구성하는 복수의 프레임들을 이미지 인코더로 입력하여, 상기 복수의 프레임들의 프레임 특징 벡터들을 획득하는 단계, 그리고상기 적어도 하나의 텍스트 특징 벡터와 상기 프레임 특징 벡터들의 상관 관계를 기초로, 상기 복수의 프레임들중에서, 상기 입력 텍스트에 해당하는 대표 프레임을 결정하는 단계를 포함하는 동작 방법."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에서,상기 텍스트 인코더와 상기 이미지 인코더는 텍스트-이미지 쌍들을 기초로 입력에 대한 특징 벡터를 출력하도록훈련된 인공지능 모델인, 동작 방법."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에서,상기 텍스트 인코더와 상기 이미지 인코더 각각은쌍으로 묶인 텍스트와 이미지의 상관 관계를 최대화하고, 쌍으로 묶이지 않은 텍스트와 이미지의 상관 관계를최소화는 태스크에 따라, 입력에 대한 특징 벡터를 출력하도록 훈련된 인공지능 모델인, 동작 방법."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에서,상기 적어도 하나의 텍스트 특징 벡터를 획득하는 단계는상기 텍스트 질의를 복수의 텍스트 문장들로 분해해서, 상기 텍스트 인코더로 입력하는, 동작 방법."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에서,상기 적어도 하나의 텍스트 특징 벡터와 상기 프레임 특징 벡터들의 상관 관계는 벡터간 유사도로 계산되는, 동작 방법."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에서,상기 대표 프레임은 상기 소스 동영상의 썸네일 이미지로 제공되는, 동작 방법."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에서,검색 조건에 따라, 상기 소스 동영상에서 상기 대표 프레임이 포함된 동영상 구간을 추출하고, 상기 동영상 구공개특허 10-2024-0057254-3-간을 상기 텍스트 질의에 대한 검색 결과로 출력하는 단계를 더 포함하는, 동작 방법."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에서,상기 검색 결과로 출력하는 단계는상기 프레임 특징 벡터들을 군집화한 후, 상기 대표 프레임이 포함된 특정 군집의 적어도 일부 프레임들을 상기동영상 구간을 추출하는, 동작 방법."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에서,상기 검색 결과로 출력하는 단계는복수의 대표 프레임을 이용해서 추출한 동영상 구간들을 상기 검색 조건에 따라 조합해서, 최종 동영상 구간을추출하는, 동작 방법."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "적어도 하나의 프로세서에 의해 동작하는 동영상 구간 검색 장치로서,텍스트-이미지 쌍들을 기초로 입력에 대한 특징 벡터를 출력하도록 훈련된 텍스트 인코더와 이미지 인코더, 그리고상기 텍스트 인코더를 이용하여 텍스트 질의에 해당하는 적어도 하나의 텍스트 특징 벡터를 획득하고, 상기 이미지 인코더를 이용하여 소스 동영상을 구성하는 복수의 프레임들의 프레임 특징 벡터들을 획득하며, 상기 적어도 하나의 텍스트 특징 벡터와 상기 프레임 특징 벡터들의 상관 관계를 기초로, 상기 복수의 프레임들 중에서,상기 텍스트 질의에 해당하는 적어도 하나의 대표 프레임을 결정하는 대표 프레임 결정부를 포함하는 동영상 구간 검색 장치."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에서,검색 조건에 따라, 상기 소스 동영상에서 상기 대표 프레임이 포함된 동영상 구간을 추출하고, 상기 동영상 구간을 상기 텍스트 질의에 대한 검색 결과로 출력하는 결과 제공부를 더 포함하는, 동영상 구간 검색 장치."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에서,상기 결과 제공부는상기 대표 프레임이 포함된 군집의 적어도 일부 프레임들을 상기 동영상 구간을 추출하는, 동영상 구간 검색 장치."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에서,상기 결과 제공부는복수의 대표 프레임을 이용해서 추출한 동영상 구간들을 상기 검색 조건에 따라 조합해서, 최종 동영상 구간을추출하는, 동영상 구간 검색 장치."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공개특허 10-2024-0057254-4-제11항에서,상기 결과 제공부는상기 검색 조건에 따라 적어도 하나의 대표 프레임을 검색 결과로 출력하는, 동영상 구간 검색 장치."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에서,상기 검색 결과에 의해, 상기 소스 동영상의 재생바에 상기 동영상 구간이 표시되거나, 상기 소스 동영상의 재생 마커가 상기 동영상 구간의 시작 시점으로 이동되거나, 상기 동영상 구간이 동영상 클립으로 생성되는, 동영상 구간 검색 장치."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에서,상기 텍스트 질의를 복수의 텍스트 문장들로 분해해서, 상기 텍스트 인코더로 입력하는 질의 전처리부를 더 포함하는, 동영상 구간 검색 장치."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "적어도 하나의 프로세서에 의해 동작하는 동영상 구간 검색 장치의 동작 방법으로서,동영상 서비스 화면으로 진입한 사용자의 개인화 정보를 획득하는 단계,상기 개인화 정보를 텍스트 질의로 생성하는 단계,텍스트 인코더 및 이미지 인코더를 이용하여, 상기 동영상 서비스 화면에 표시된 동영상의 프레임들에서, 상기텍스트 질의에 해당하는 대표 프레임을 결정하는 단계, 그리고상기 동영상 서비스 화면에서, 상기 대표 프레임을 상기 동영상의 썸네일 이미지로 표시하는 단계를 포함하는, 동작 방법."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에서,상기 대표 프레임을 결정하는 단계는상기 텍스트 인코더를 이용하여 상기 텍스트 질의에 해당하는 적어도 하나의 텍스트 특징 벡터를 획득하고, 상기 이미지 인코더를 이용하여 상기 동영상을 구성하는 복수의 프레임들의 프레임 특징 벡터들을 획득하며, 상기적어도 하나의 텍스트 특징 벡터와 상기 프레임 특징 벡터들의 상관 관계를 기초로, 상기 복수의 프레임들 중에서, 상기 텍스트 질의에 해당하는 상기 대표 프레임 결정하는, 동작 방법."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에서,상기 텍스트 인코더와 상기 이미지 인코더는 텍스트-이미지 쌍들을 기초로 입력에 대한 특징 벡터를 출력하도록훈련된 인공지능 모델인, 동작 방법."}
{"patent_id": "10-2022-0137774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17항에서,상기 대표 프레임 또는 새로운 텍스트 질의로부터 추출한 새로운 대표 프레임을 기초로, 상기 동영상에서 텍스트 질의에 해당하는 동영상 구간을 추출하고, 상기 동영상 구간을 검색 결과로 출력하는 단계를 더 포함하고,상기 검색 결과에 따라, 상기 동영상의 재생바에 상기 동영상 구간이 표시되거나, 상기 동영상의 재생 마커가상기 동영상 구간의 시작 시점으로 이동되는, 동작 방법.공개특허 10-2024-0057254-5-"}
{"patent_id": "10-2022-0137774", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "적어도 하나의 프로세서에 의해 동작하는 동영상 구간 검색 장치의 동작 방법으로서, 텍스트 질의를 입력받는 단 계, 상기 텍스트 질의에 해당하는 적어도 하나의 입력 텍스트를 텍스트 인코더로 입력하여, 상기 텍스트 질의에 해당하는 적어도 하나의 텍스트 특징 벡터를 획득하는 단계, 소스 동영상을 구성하는 복수의 프레임들을 이미지 인코더로 입력하여, 상기 복수의 프레임들의 프레임 특징 벡터들을 획득하는 단계, 그리고 상기 적어도 하나의 텍스트 특징 벡터와 상기 프레임 특징 벡터들의 상관 관계를 기초로, 상기 복수의 프레임들 중에서, 상기 입력 텍스트에 해당하는 대표 프레임 결정하는 단계를 포함한다."}
{"patent_id": "10-2022-0137774", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 동영상 구간 검색에 관한 것이다."}
{"patent_id": "10-2022-0137774", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인간이 다양한 감각 기관을 통해 획득한 정보를 복합적으로 이용하는 인지적 학습을 모방하여, 인공지능 모델이 다른 형태(modality)의 데이터를 사용하여 학습하는 멀티모달 학습(multimodal learning)이 연구되고 있다. 멀 티모달 학습을 위해, 서로 다른 특성을 가지는 멀티모달 데이터를 통합하는 방식에 대한 연구가 진행되고 있다. 한편, 검색 기술의 경우, 키워드 기반 검색 기술이나 이미지 기반 검색 기술에서, 서로 다른 종류의 데이터를 복합적으로 이용하는 멀티모달 검색 기술로 발전함으로써 고도화되고 있다. 검색 결과로서 텍스트나 이미지를 출력할 뿐만 아니라, 최근에는 동영상 내 검색에 대한 연구도 진행되고 있다. 하지만, 동영상에서 출현하는 명 확한 객체 검색이 가능한 정도이고, 복잡한 질의에 맞는 동영상 구간을 검색하지 못하고, 인공지능 모델의 훈련 을 위해 대량의 어노테이션이 필요한 한계가 있다."}
{"patent_id": "10-2022-0137774", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 인공지능 기반 동영상 구간 검색 방법 및 장치를 제공하는 것이다. 본 개시는 텍스트-이미지 쌍의 유사도를 기초로 텍스트 인코더와 이미지 인코더를 훈련시키고, 훈련된 텍스트 인코더와 이미지 인코더를 이용하여 동영상의 프레임들에서 텍스트 질의에 해당하는 대표 프레임을 검색하는 방 법 및 장치에 관한 것이다. 본 개시는 동영상의 프레임들을 군집화하고, 텍스트 질의에 해당하는 군집을 동영상 구간으로 추출하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0137774", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "한 실시예에 따라 적어도 하나의 프로세서에 의해 동작하는 동영상 구간 검색 장치의 동작 방법으로서, 텍스트 질의를 입력받는 단계, 상기 텍스트 질의에 해당하는 적어도 하나의 입력 텍스트를 텍스트 인코더로 입력하여, 상기 텍스트 질의에 해당하는 적어도 하나의 텍스트 특징 벡터를 획득하는 단계, 소스 동영상을 구성하는 복수 의 프레임들을 이미지 인코더로 입력하여, 상기 복수의 프레임들의 프레임 특징 벡터들을 획득하는 단계, 그리 고 상기 적어도 하나의 텍스트 특징 벡터와 상기 프레임 특징 벡터들의 상관 관계를 기초로, 상기 복수의 프레 임들 중에서, 상기 입력 텍스트에 해당하는 대표 프레임을 결정하는 단계를 포함한다. 상기 텍스트 인코더와 상기 이미지 인코더는 텍스트-이미지 쌍들을 기초로 입력에 대한 특징 벡터를 출력하도록 훈련된 인공지능 모델일 수 있다. 상기 텍스트 인코더와 상기 이미지 인코더 각각은 쌍으로 묶인 텍스트와 이미지의 상관 관계를 최대화하고, 쌍 으로 묶이지 않은 텍스트와 이미지의 상관 관계를 최소화는 태스크에 따라, 입력에 대한 특징 벡터를 출력하도 록 훈련된 인공지능 모델일 수 있다. 상기 적어도 하나의 텍스트 특징 벡터를 획득하는 단계는 상기 텍스트 질의를 복수의 텍스트 문장들로 분해해서, 상기 텍스트 인코더로 입력할 수 있다. 상기 적어도 하나의 텍스트 특징 벡터와 상기 프레임 특징 벡터들의 상관 관계는 벡터간 유사도로 계산될 수 있 다. 상기 대표 프레임은 상기 소스 동영상의 썸네일 이미지로 제공될 수 있다. 상기 동작 방법은 검색 조건에 따라, 상기 소스 동영상에서 상기 대표 프레임이 포함된 동영상 구간을 추출하고, 상기 동영상 구간을 상기 텍스트 질의에 대한 검색 결과로 출력하는 단계를 더 포함할 수 있다.상기 검색 결과로 출력하는 단계는 상기 프레임 특징 벡터들을 군집화한 후, 상기 대표 프레임이 포함된 특정 군집의 적어도 일부 프레임들을 상기 동영상 구간을 추출할 수 있다. 상기 검색 결과로 출력하는 단계는 복수의 대표 프레임을 이용해서 추출한 동영상 구간들을 상기 검색 조건에 따라 조합해서, 최종 동영상 구간을 추출할 수 있다. 한 실시예에 따라 적어도 하나의 프로세서에 의해 동작하는 동영상 구간 검색 장치로서, 텍스트-이미지 쌍들을 기초로 입력에 대한 특징 벡터를 출력하도록 훈련된 텍스트 인코더와 이미지 인코더, 그리고 상기 텍스트 인코 더를 이용하여 텍스트 질의에 해당하는 적어도 하나의 텍스트 특징 벡터를 획득하고, 상기 이미지 인코더를 이 용하여 소스 동영상을 구성하는 복수의 프레임들의 프레임 특징 벡터들을 획득하며, 상기 적어도 하나의 텍스트 특징 벡터와 상기 프레임 특징 벡터들의 상관 관계를 기초로, 상기 복수의 프레임들 중에서, 상기 텍스트 질의 에 해당하는 적어도 하나의 대표 프레임을 결정하는 대표 프레임 결정부를 포함한다. 상기 동영상 구간 검색 장치는 검색 조건에 따라, 상기 소스 동영상에서 상기 대표 프레임이 포함된 동영상 구 간을 추출하고, 상기 동영상 구간을 상기 텍스트 질의에 대한 검색 결과로 출력하는 결과 제공부를 더 포함할 수 있다. 상기 결과 제공부는 상기 대표 프레임이 포함된 군집의 적어도 일부 프레임들을 상기 동영상 구간을 추출할 수 있다. 상기 결과 제공부는 복수의 대표 프레임을 이용해서 추출한 동영상 구간들을 상기 검색 조건에 따라 조합해서, 최종 동영상 구간을 추출할 수 있다. 상기 결과 제공부는 상기 검색 조건에 따라 적어도 하나의 대표 프레임을 검색 결과로 출력할 수 있다. 상기 검색 결과에 의해, 상기 소스 동영상의 재생바에 상기 동영상 구간이 표시되거나, 상기 소스 동영상의 재 생 마커가 상기 동영상 구간의 시작 시점으로 이동되거나, 상기 동영상 구간이 동영상 클립으로 생성될 수 있다. 상기 동영상 구간 검색 장치는 상기 텍스트 질의를 복수의 텍스트 문장들로 분해해서, 상기 텍스트 인코더로 입 력하는 질의 전처리부를 더 포함할 수 있다. 한 실시예에 따라 적어도 하나의 프로세서에 의해 동작하는 동영상 구간 검색 장치의 동작 방법으로서, 동영상 서비스 화면으로 진입한 사용자의 개인화 정보를 획득하는 단계, 상기 개인화 정보를 텍스트 질의로 생성하는 단계, 텍스트 인코더 및 이미지 인코더를 이용하여, 상기 동영상 서비스 화면에 표시된 동영상의 프레임들에서, 상기 텍스트 질의에 해당하는 대표 프레임을 결정하는 단계, 그리고 상기 동영상 서비스 화면에서, 상기 대표 프레임을 상기 동영상의 썸네일 이미지로 표시하는 단계를 포함할 수 있다. 상기 대표 프레임을 결정하는 단계는 상기 텍스트 인코더를 이용하여 상기 텍스트 질의에 해당하는 적어도 하나 의 텍스트 특징 벡터를 획득하고, 상기 이미지 인코더를 이용하여 상기 동영상을 구성하는 복수의 프레임들의 프레임 특징 벡터들을 획득하며, 상기 적어도 하나의 텍스트 특징 벡터와 상기 프레임 특징 벡터들의 상관 관계 를 기초로, 상기 복수의 프레임들 중에서, 상기 텍스트 질의에 해당하는 상기 대표 프레임 결정할 수 있다. 상기 텍스트 인코더와 상기 이미지 인코더는 텍스트-이미지 쌍들을 기초로 입력에 대한 특징 벡터를 출력하도록 훈련된 인공지능 모델일 수 있다. 상기 동작 방법은 상기 대표 프레임 또는 새로운 텍스트 질의로부터 추출한 새로운 대표 프레임을 기초로, 상기 동영상에서 텍스트 질의에 해당하는 동영상 구간을 추출하고, 상기 동영상 구간을 검색 결과로 출력하는 단계를 더 포함할 수 있다. 상기 검색 결과에 따라, 상기 동영상의 재생바에 상기 동영상 구간이 표시되거나, 상기 동 영상의 재생 마커가 상기 동영상 구간의 시작 시점으로 이동될 수 있다."}
{"patent_id": "10-2022-0137774", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예에 따르면 동영상에서 검색하고자 하는 장면을 설명하는 텍스트 질의를 기초로, 동영상에서 원하는 동영 상 구간을 검색해서 검색 결과로 제공할 수 있다. 실시예에 따르면 소스 동영상의 프레임들에 레이블이나 참고 정보가 없더라도, 텍스트 질의에 관련된 대표 프레 임이나 동영상 구간을 추출할 수 있다. 실시예에 따르면 복수의 키워드들로 구성된 텍스트 질의를 입력받을 수 있기 때문에, 질의자는 검색하고자 하는 장면을 구체적으로 질의할 수 있고, 동영상에서 원하는 장면을 자유롭게 검색할 수 있다."}
{"patent_id": "10-2022-0137774", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위 해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재 된 \"…부\", \"…기\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드 웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 장치는 하나 이상의 프로세서, 프로세서에 의하여 수행되는 컴퓨터 프로그램을 로드하는 메모리, 컴퓨터 프로그 램 및 각종 데이터를 저장하는 저장 장치, 통신 인터페이스를 포함하는 컴퓨팅 장치일 수 있다. 이외에도, 장치 는 다양한 구성 요소가 더 포함될 수 있다. 프로세서는 장치의 동작을 제어하고, 컴퓨터 프로그램에 포함된 명 령어들을 처리하는 다양한 형태의 프로세서일 수 있고, 예를 들면, CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 개시의 기술 분야에 잘 알려진 임의 형태의 프로세서 중 적어도 하나를 포함하여 구성될 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리는 본 개시의 동작을 실행하도록 기술된 명령어들이 프로세서에 의해 처리되도록 해당 컴퓨터 프로그램을 저장 장치로부터 로드할 수 있다. 메모리는 예를 들면, ROM(read only memory), RAM(random access memory) 등 일 수 있다. 저장 장치는 컴퓨터 프로그램, 각종 데이터를 비임시적으로 저장할 수 있다. 저 장 장치는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 개시가 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 통신 인터페이스는 유/무선 통신을 지원하는 유/무선 통신 모듈일 수 있다. 컴퓨터 프로그램은, 프로세서에 의 해 실행되는 명령어들(instructions)을 포함하고, 비일시적-컴퓨터 판독가능 저장매체(non-transitory computer readable storage medium)에 저장되며, 명령어들은 프로세서가 본 개시의 동작을 실행하도록 만든다. 도 1은 한 실시예에 따른 동영상 구간 검색 장치의 개념도이다. 도 1을 참고하면, 동영상 구간 검색 장치(간단히, 검색 장치라고 한다)는 적어도 하나의 프로세서에 의해 동작하는 컴퓨팅 장치이다. 검색 장치는 인공지능(Artificial Intelligence, AI) 모델을 이용하여, 소스 동 영상(source video)에서 텍스트 질의(text query)에 해당하는 동영상 구간을 검색한다. 검색 장치는 검색된동영상 구간을 검색 결과로 출력할 수 있다. 검색 결과를 출력하는 방법은 검색 목적이나 검색 결과를 이용하는 연동 장치에 맞게 다양하게 변경될 수 있다. 예를 들어, 검색 장치는 소스 동영상에서 대표 프레임이나 동 영상 구간을 추출해서 별도의 콘텐츠(썸네일 이미지, 동영상 클립)를 생성할 수 있다. 검색 장치는 소스 동 영상의 재생 위치를, 검색한 동영상 구간의 시작 프레임이나 대표 프레임으로 이동시킬 수 있다. 검색 장치(1 0)는 소스 동영상의 재생 바에, 검색된 동영상 구간을 시각적으로 표시할 수 있다. 검색 장치는 텍스트 질의에 해당하는 적어도 하나의 동영상 구간을 검색할 수 있고, 검색된 모든 동영상 구 간들을 검색 결과로 출력하거나, 텍스트 질의에 가장 유사한 동영상 구간을 검색 결과로 출력할 수 있다. 검색 장치는 검색된 동영상 구간들을 우선 순위나 시간 순서에 따라 정렬해서 검색 결과로 출력할 수 있고, 우선 순위는 텍스트 질의와의 유사도, 동영상 길이 등과 같이 검색 목적에 맞게 다양하게 설정될 수 있다. 검색 장치는 검색할 동영상 구간 길이(검색 길이)나, 길이 범위를 검색 조건으로 설정할 수 있다. 여기서, 길이는 프레임 수나 재생 시간 등으로 설정될 수 있다. 예를 들어, 검색 길이가 한 프레임으로 설정되면, 검색 장치는 동영상에서 텍스트 질의에 해당하는 한 프레임을 검색 결과로 출력할 수 있다. 따라서, 검색 장치 가 반드시 복수의 프레임들로 구성된 동영상 구간을 검색하는 것으로 한정될 필요는 없다. 텍스트 질의는 적어도 하나의 키워드를 포함하는데, 키워드들을 포함하는 문장으로 표현될 수 있다. 예를 들면, 텍스트 질의는 '교실에서 수업을 받는 학생들'과 같은 단일 문장이라든지, '교실에서 수업을 받고 있는 학생들 이 있는데 일부는 돌아다니고 있고 일부는 앉아서 책을 읽고 있다'와 같이 다중 문장일 수 있다. 텍스트 질의를 입력하는 질의자는 일반 사용자일 수 있고, 또는 검색 결과를 응용하여 서비스를 제공하는 서비 스 제공자일 수 있다. 검색 장치는 적어도 하나의 소스 동영상에서 동영상 구간을 검색할 수 있다. 소스 동영상은 텍스트 질의를 입력하는 질의자에 의해 선택될 수 있다. 또는 소스 동영상은 텍스트 질의에 따라 결정되거나, 미리 동영상 데 이터베이스에서 분류될 수 있다. 검색 장치는 훈련된 인공지능 모델을 포함하는데, 인공지능 모델은 텍스트 질의와 동영상 프레임을 벡터화 하는 텍스트 인코더와 이미지 인코더를 포함할 수 있다. 텍스트 인코더는 입력 텍스트를 인코딩 (압축)해서 텍스트 특징 벡터를 출력할 수 있다. 텍스트 인코더는 텍스트 처리를 위한 딥러닝 기반의 모델 (예를 들면, Transformer 등)을 기초로 구현될 수 있다. 이미지 인코더는 입력 이미지(동영상 프레임)를 인코딩해서 이미지 특징 벡터를 출력할 수 있다. 이미지 인코더는 이미지 처리를 위한 딥러닝 기반의 모델 (예를 들면, ResNet, Vision Transformer 등)을 기초로 구현될 수 있다. 여기서, 텍스트 특징 벡터는 텍스트 임 베딩 벡터, 이미지 특징 벡터는 이미지 임베딩 벡터로 부를 수 있다. 텍스트 인코더와 이미지 인코더는 텍스트-이미지 쌍들을 포함하는 훈련 데이터를 기초로, 쌍으로 묶 인 텍스트와 이미지의 상관 관계를 최대화하고, 쌍으로 묶이지 않은 텍스트와 이미지의 상관 관계를 최소화하는 방향으로, 텍스트 특징 벡터와 이미지 특징 벡터를 출력하도록 훈련될 수 있다. 텍스트와 이미지의 상관 관계는 벡터간 유사도로 계산될 수 있고, 예를 들면, 코사인 유사도(cosine similarity)로 계산될 수 있다. 검색 장치는 훈련된 텍스트 인코더를 이용하여 텍스트 질의의 특징 벡터를 획득하고, 훈련된 이미지 인코더를 이용하여 소스 동영상의 프레임들의 특징 벡터들을 획득할 수 있다. 검색 장치는 텍스트 질 의와 프레임들의 특징 벡터들의 상관 관계를 비교해서, 텍스트 질의에 해당하는 적어도 하나의 대표 프레임 (best frame)를 결정할 수 있다. 검색 장치는 텍스트 질의와의 상관 관계가 가장 높은 프레임(가장 유사한 프레임), 또는 텍스트 질의와의 상관 관계가 기준 이상인 적어도 하나의 프레임을 대표 프레임으로 결정할 수 있다. 검색 장치는 소스 동영상에서 대표 프레임 주변의 일정 구간을 검색 결과로 출력할 수 있다. 검색 장치(1 0)는 동영상 프레임들의 특징 벡터 분포를 기초로 프레임들을 나누어 군집화(clustering)할 수 있다. 검색 장치 는 대표 프레임이 포함된 군집(cluster)을 결정하고, 군집의 적어도 일부 프레임들을 검색된 동영상 구간으 로 출력할 수 있다. 여기서, 군집으로 분류된 모든 프레임들이 동영상 구간으로 출력될 필요가 없고, 대표 프레 임이 포함된 연속된 일부 프레임들이 동영상 구간으로 출력될 수 있다. 검색 장치는 검색된 동영상 구간을 나타내는 식별 정보를 검색 결과로 출력할 수 있다. 또는, 검색 장치는 군집의 적어도 일부 프레임들을 동 영상 클립으로 변환하고, 동영상 클립을 검색 결과로 출력할 수 있다. 도 2는 한 실시예에 따른 동영상 구간 검색 장치의 구성도이고, 도 3은 한 실시예에 따른 군집화 기반 동영상 구간 검색 방법을 설명하는 도면이며, 도 4는 한 실시예에 따른 동영상 구간 검색 방법을 설명하는 도면이다. 도 2를 참고하면, 검색 장치는 텍스트 인코더, 질의 전처리부, 이미지 인코더, 동영상 전처 리부, 대표 프레임 결정부, 군집화부, 그리고 결과 제공부를 포함할 수 있다. 먼저, 텍스트 인코더와 이미지 인코더는 텍스트-이미지 쌍들을 포함하는 훈련 데이터를 기초로, 쌍으 로 묶인 텍스트와 이미지의 유사도를 최대화하고, 쌍으로 묶이지 않은 텍스트와 이미지의 유사도를 최소화하는 방향으로, 텍스트 특징 벡터와 이미지 특징 벡터를 출력하도록 훈련된 인공지능 모델일 수 있다. 텍스트 인코더는 입력된 텍스트 질의를 인코딩(압축)해서 텍스트 질의의 특징 벡터를 출력할 수 있다. 텍 스트 질의가 복수의 텍스트 문장들로 분해된 경우, 텍스트 인코더는 복수의 텍스트 특징 벡터들을 출력할 수 있다. 텍스트 인코더는 텍스트 처리를 위한 딥러닝 기반의 모델(예를 들면, Transformer 등)을 기초로 구현될 수 있다. 이미지 인코더는 입력된 각 프레임을 인코딩해서 이미지 특징 벡터를 출력할 수 있다. 이미지 인코더(20 0)는 이미지 처리를 위한 딥러닝 기반의 모델(예를 들면, ResNet, Vision Transformer 등)을 기초로 구현될 수 있다. 질의 전처리부는 텍스트 질의를 전처리하여 적어도 하나의 텍스트 문장(Text1, Text2, …)을 텍스트 인코 더로 입력할 수 있다. 여기서, 텍스트 문장은 단일 키워드(예를 들면, 교실)보다 긴 텍스트를 나타내기 위 해 도입한 용어라서, 반드시 주어와 서술어를 포함하는 완결된 형태일 필요는 없고, 적어도 하나의 키워드를 포 함하는 어절이나 구절이어도 무방하다. 예를 들어, 텍스트 질의가 '교실에서 수업을 받고 있는 학생들이 있는데 일부는 돌아다니고 있고 일부는 앉아서 책을 읽고 있다'와 같이 다중 문장인 경우, 질의 전처리부는 '교실 에서 수업을 받고 있는 학생들', '교실에서 돌아다니고 있는 학생들', '교실에서 앉아서 책을 읽고 있는 학생들'로 텍스트 질의를 변환한 후, 텍스트 인코더로 개별적으로 입력할 수 있다. 질의 전처리부는 긴 텍스트 질의를 짧게 분해하는 전처리를 수행할 수 있고, 또는 의미 기반 자연어 처리를 통해 주요한 키워드 들이 포함되도록 텍스트 질의를 분해할 수 있다. 동영상 전처리부는 소스 동영상을 전처리하여 복수의 프레임들을 이미지 인코더로 입력할 수 있다. 동영상 전처리부는 소스 동영상에서 시간 순서대로 프레임들을 추출할 수 있다. 소스 동영상 전체에서 텍 스트 질의에 해당하는 동영상 구간을 검색할 필요가 없는 경우라면, 동영상 전처리부는 소스 동영상의 일 부 구간에서 프레임들을 추출할 수 있다. 동영상 전처리부는 소스 동영상에서 초당 재생되는 모든 프레임 들을 추출할 수 있다. 또는, 연속된 프레임들에서 유사한 장면이 재생되는 동영상의 특성을 고려하여, 동영상 전처리부는 일정 시간 간격(예를 들면, 1초)으로 검색에 사용될 프레임을 추출할 수 있다. 프레임을 추출 하는 시간 간격은 소스 동영상이나 텍스트 질의의 특성, 검색 결과의 정확도, 요구되는 검색 결과 제공 시간, 가용 자원에 따라 가변될 수 있다. 여기서, 소스 동영상은 텍스트 질의를 입력하는 질의자에 의해 선택될 수 있 다. 또는 소스 동영상은 텍스트 질의에 따라 결정되거나, 미리 동영상 데이터베이스에서 분류될 수 있다. 텍스트 인코더나 이미지 인코더에서 출력되는 특징 벡터는 차원 축소된 후 대표 프레임 결정부 이나 군집화부로 입력될 수 있다. 차원 축소 알고리즘은 PCA(Principal Component Analysis), LDA(Linear Discriminant Analysis), SVD(Singular Value Decomposition) 등이 활용될 수 있다. 대표 프레임 결정부는 텍스트 인코더로부터 텍스트 질의의 특징 벡터를 획득하고, 이미지 인코더 로부터 소스 동영상을 구성하는 프레임들의 특징 벡터들을 획득할 수 있다. 대표 프레임 결정부는 텍 스트 질의와 프레임들의 특징 벡터들의 관계를 비교해서, 텍스트 질의와의 상관 관계가 가장 높은 프레임(가장 유사한 프레임), 또는 텍스트 질의와의 상관 관계가 기준 이상인 적어도 하나의 프레임을 대표 프레임으로 결정 할 수 있다. 군집화부는 프레임들의 특징 벡터들을 공간에 배치하고, 프레임 특징 벡터들의 분포를 기초로, 프레임 특 징 벡터들을 군집화할 수 있다. 군집화 알고리즘으로서, K-means, DBSCAN 등이 활용될 수 있다. 결과 제공부는 소스 동영상에서 대표 프레임 주변의 일정 구간을 검색 결과로 출력할 수 있다. 한 실시예 에 따르면, 결과 제공부는 군집화부에서의 프레임 특징 벡터들에 의한 군집화 결과를 이용하여, 대표 프레임을 포함하는 동영상 구간을 결정할 수 있다. 결과 제공부는 대표 프레임이 속한 군집으로 분류된 프 레임들을 시간축에 나열하고, 대표 프레임이 포함된 연속된 프레임들 동영상 구간으로 출력할 수 있다. 다른 실 시예에 따르면, 결과 제공부는 대표 프레임을 기준으로 일정 시간 구간을 검색 결과로 출력할 수 있다. 이 때 결과 제공부는 대표 프레임 주변의 프레임들(예를 들면, 5분 구간)을 비교해서, 대표 프레임과의 유사도가 기준 이상인 프레임들까지를 검색 결과로 출력할 수 있다. 결과 제공부는 검색된 동영상 구간을 나타내는 식별 정보(예를 들면, 소스 동영상의 30분부터 32분 시간 구간)를 검색 결과로 출력할 수 있다. 또는, 결과 제공부는 검색된 동영상 구간에 해당하는 동영상 클립을 생성해서 검색 결과로 출력할 수 있다. 동영상 클립은 소스 동영상에서 동영상 구간에 해당하는 부분을 추출해 서 생성될 수 있고, 동영상 전처리부에서 생성된 프레임들을 이용해서 생성될 수 있다. 도 3을 참고하면, 프레임 특징 벡터들에 의한 군집화를 통해 소스 동영상의 프레임들이 복수의 군집들(cluster 1, cluster 2, cluster 3, …)로 군집화되고, 대표 프레임이 군집1(cluster 1)에 속한다고 가정한다. 결과 제공부는 군집들에서, 대표 프레임이 속한 군집1(cluster 1)을 확인하고, 군집1에 포함된 프레임들을 시간축에 나열할 수 있다. 공간에서의 벡터 유사도로 군집화된 프레임들은 시간축에서 연속적으로 나열될 수 있 고, 다른 시간에 불연속적으로 나열될 수 있다. 따라서, 결과 제공부는 대표 프레임이 포함된 연속된 프레 임들을 동영상 구간으로 결정하고, 이를 텍스트 질의의 검색 결과로 제공할 수 있다. 또한, 결과 제공부는 대표 프레임이 포함된 동영상 구간을 동영상 클립으로 생성할 수 있다. 도 4를 참고하면, 텍스트 질의가 복수의 텍스트 문장(Text1, Text2, Text3)으로 분해되는 경우, 결과 제공부 는 각 텍스트 문장의 대표 프레임을 이용해서, 각 텍스트 문장에 해당하는 동영상 구간을 검색하고, 이들 을 조건에 따라 조합해서 최종 동영상 구간을 출력할 수 있다. 예를 들면, 결과 제공부는 텍스트 문장1(Text1)에 해당하는 동영상 구간, 텍스트 문장2(Text2)에 해 당하는 동영상 구간, 그리고 텍스트 문장3(Text3)에 해당하는 동영상 구간을 검색할 수 있다. 그리고, 결과 제공부는 검색된 동영상 구간들(600, 610, 620) 중 적어도 일부가 겹치는 구간을 텍스트 질 의에 해당하는 최종 동영상 구간으로 결정할 수 있다. 예를 들면, 결과 제공부는 동영상 구간들(600, 610, 620)이 모두 겹치는 구간을 최종 동영상 구간으로 결정할 수 있다. 또는, 결과 제공부는 검색된 동영 상 구간들(600, 610, 620)의 모든 구간들을 최종 동영상 구간으로 결정할 수 있다. 이처럼, 긴 텍스트 질 의를 여러 문장으로 분해해서 동영상 구간을 검색하는 경우, 개별 동영상 구간들을 조합하는 방법은 다양하게 설정될 수 있다. 도 5는 한 실시예에 따른 인공지능 모델의 훈련을 설명하는 도면이고, 도 6은 텍스트-이미지의 상관 관계 테이 블의 예시이다. 도 5를 참고하면, 텍스트 인코더와 이미지 인코더 각각은 복수의 텍스트-이미지 쌍들을 포함하는 훈 련 데이터를 이용하여, 입력에 해당하는 특징이 임베딩된 벡터를 출력하도록 훈련된다. 텍스트-이미지 쌍 에서, 텍스트는 이미지를 설명하는 텍스트 정보를 포함할 수 있다. 텍스트 인코더는 N개의 텍스트들에 대한 특징 벡터들을 출력하고, 이미지 인코더는 N개의 텍스트들에 대응하는 N개의 이미지들에 대한 특징 벡터들을 출력한다. 적어도 하나의 프로세서에 의해 동작하는 훈련 장치는 N개의 텍스트들에 대한 특징 벡터들과 N개의 이미지 들에 대한 특징 벡터들 사이의 상관 관계를 계산하고, 텍스트-이미지 상관 관계 테이블을 생성할 수 있다. 텍스트와 이미지의 상관 관계는 벡터간 유사도로 계산될 수 있다. 훈련 장치는 텍스트-이미지 상관 관계 테이블을 이용하여, 태스크에 해당하는 특징 벡터를 출력하도록 텍스트 인코더와 이미지 인코더(20 0)를 훈련시킬 수 있고, 훈련 방법은 다양할 수 있다. 텍스트-이미지의 상관 관계 테이블은 쌍으로 묶인 텍스트와 이미지의 상관 관계뿐만 아니라, 쌍으로 묶이 지 않은 텍스트와 이미지의 상관 관계도 포함한다. 상관 관계 테이블에서, (1,1), (2,2), …, (N,N) 셀들 에 쌍으로 묶인 텍스트와 이미지의 상관 관계 값이 기재되고, 나머지 셀들에는 쌍으로 묶이지 않은 텍스트와 이 미지의 상관 관계 값이 기재된다. 따라서, 텍스트 인코더와 이미지 인코더는 텍스트-이미지의 상관 관계 테이블에서 대각선 셀들의 상관 관계를 최대화하고, 나머지 셀들의 상관 관계를 최소화하는 태스크에 따라, 텍스트 특징 벡터와 이미지 특징 벡터를 출력하는 훈련을 할 수 있다. 도 6을 참고하면, 훈련된 텍스트 인코더와 이미지 인코더의 특징 벡터들을 이용하여 텍스트에 해당하 는 이미지를 찾은 결과를 예로 들어 설명한다. 텍스트-이미지의 상관 관계 테이블(710A)에서 값이 큰 셀 (1,1), (2,2), (3,6), (4,3), (5,4), (6,5)에 매핑된 텍스트와 이미지를 살펴보면, 각 텍스트에 해당하는 이미지인 것 을 확인할 수 있다. 즉, 대표 프레임 결정부는, 소스 동영상을 구성하는 프레임1부터 프레임N에 대해 별도의 레이블이 없는 상 태에서, ‘drinking beer’나 ‘a couple with beer bottle’ 등의 텍스트 질의의 특징 벡터와 상관 관계 높은 프레임 특징 벡터를 찾고, 이를 대표 프레임으로 결정할 수 있다. 도 7은 한 실시예에 따른 인공지능 모델 훈련 방법의 흐름도이다. 도 7을 참고하면, 훈련 장치는 복수의 텍스트-이미지 쌍들을 포함하는 훈련 데이터에서 추출한 텍스 트들을 텍스트 인코더로 입력해서, 텍스트들의 특징 벡터들을 획득한다(S110). 훈련 장치는 훈련 데이터에서 추출한 이미지들을 이미지 인코더로 입력해서, 이미지들의 특징 벡터들을 획득한다(S120). 훈련 장치는 텍스트들에 대한 특징 벡터들과 이미지들에 대한 특징 벡터들 사이의 상관 관계를 계산하고, 텍스트-이미지 상관 관계 테이블을 생성한다(S130). 훈련 장치는 텍스트-이미지 상관 관계 테이블을 기초로, 쌍으로 묶인 텍스트와 이미지의 상관 관계가 최대 화되고, 쌍으로 묶이지 않은 텍스트와 이미지의 상관 관계가 최소화되도록 텍스트 인코더와 이미지 인코더 를 훈련시킨다(S140). 이렇게 텍스트 인코더와 이미지 인코더는 동일한 태스크를 통해 텍스트-이미지의 관계를 동시에 훈련 할 수 있다. 도 8은 한 실시예에 따른 동영상 구간 검색 방법의 흐름도이다. 도 8을 참고하면, 검색 장치는 텍스트 질의를 입력받는다(S210). 텍스트 질의를 입력하는 질의자는 일반 사용자일 수 있고, 또는 검색 결과를 응용하여 서비스를 제공하는 서비스 제공자일 수 있다. 검색 장치는 텍스트 질의에 해당하는 적어도 하나의 입력 텍스트를 텍스트 인코더로 입력한다(S220). 검색 장치는 텍스트 질의를 거의 그대로 텍스트 인코더로 입력할 수 있고, 또는 텍스트 질의를 복수의 텍스트 문장들로 분해해서, 텍스트 인코더로 입력할 수 있다. 텍스트 문장별로 검색 결과가 획득될 수 있 다. 검색 장치는 긴 텍스트 질의를 일정 길이 이하로 짧게 분해하는 전처리를 수행할 수 있고, 또는 의미 기반 자연어 처리를 통해 주요한 키워드들이 포함되도록 텍스트 질의를 분해할 수 있다. 검색 장치는 소스 동영상에서 복수의 프레임들을 추출하고, 각 프레임을 이미지 인코더로 입력한다 (S230). 검색 장치는 소스 동영상에서 초당 재생되는 모든 프레임들을 추출할 수 있지만, 검색에 사용될 프 레임을 일정 시간 간격(예를 들면, 1초)으로 추출할 수 있다. 검색 장치는 텍스트 인코더로부터 텍스트 질의에 해당하는 적어도 하나의 텍스트 특징 벡터를 획득하 고, 이미지 인코더로부터 소스 동영상을 구성하는 프레임들의 프레임 특징 벡터들을 획득한다(S240). 검색 장치는 적어도 하나의 텍스트 특징 벡터와 프레임 특징 벡터들의 상관 관계를 계산한다(S250). 검색 장치는 텍스트 특징 벡터와 프레임 특징 벡터 간의 상관 관계를 계산하는데, 상관 관계는 코사인 유사도와 같은 유사도 계산 알고리즘으로 계산될 수 있다. 검색 장치는 특징 벡터들 간의 상관 관계를 기초로, 복수의 프레임들 중에서, 입력 텍스트에 해당하는 적어 도 하나의 대표 프레임을 결정한다(S260). 여기서, 검색 장치는 검색 조건에 따라, 대표 프레임을 검색 결 과로 제공할 수 있다. 검색 장치는 검색 조건을 기초로, 소스 동영상에서, 대표 프레임이 포함된 동영상 구간을 추출하고, 동영상 구간을 텍스트 질의에 대한 검색 결과로 출력한다(S270). 여기서, 동영상 구간은 반드시 복수의 프레임들로 구 성될 필요 없이, 검색 조건에 따라서는 단일 프레임일 수 있고, 이 경우, 대표 프레임이 검색 결과로 출력될 수 있다. 검색 장치는 프레임 특징 벡터들의 분포를 기초로, 프레임 특징 벡터들을 군집화한 후, 대표 프레임 을 포함하는 특정 군집의 적어도 일부 프레임들로 구성된 동영상 구간을 추출할 수 있다. 예를 들면, 검색 장치 는 특정 군집으로 분류된 프레임들을 시간축에 나열하면, 연속되지 않은 프레임들도 포함될 수 있기 때문에, 대표 프레임이 포함된 연속된 프레임들을 동영상 구간으로 결정할 수 있다. 대표 프레임이 포함된 동영 상 구간을 결정하는 방법, 그리고 동영상 구간을 검색 결과로 출력하는 방법은, 검색 조건에 따라 설정될 수 있 는데, 검색 목적이나 검색 결과를 이용하는 연동 장치에 맞게 다양하게 변경될 수 있다. 예를 들면, 검색 결과 에 의해 소스 동영상의 재생바에 동영상 구간이 표시되거나, 소스 동영상의 재생 마커가 동영상 구간의 시작 시 점으로 이동되거나, 동영상 구간이 동영상 클립으로 생성될 수 있다. 한편, 텍스트 질의가 복수의 텍스트 문장들로 분해되어 텍스트 인코더로 입력되는 경우, 검색 장치는 각 입력 텍스트의 대표 프레임을 이용해 서 검색한 동영상 구간들을 조건에 따라 조합해서, 최종 동영상 구간을 추출할 수 있다. 이러한 검색 장치는 검색 목적이나 검색 결과를 이용하는 방법에 따라 다음과 같이 다양하게 활용될 수 있 다. 도 9는 한 실시예에 따른 썸네일 이미지 제공 방법의 흐름도이다. 도 9를 참고하면, 검색 장치는 동영상 서비스 화면으로 진입한 사용자의 개인화 정보를 획득한다(S310). 동 영상 서비스 화면은 적어도 하나의 동영상을 썸네일 이미지로 표시한 화면으로서, 예를 들면, 넷플릭스나 유튜 브에서 제공하는 화면일 수 있다. 개인화 정보는 사용자 개인 정보(나이, 성별 등), 관심사 정보, 재생 목록 등 과 같이 동영상 서비스 회사에서 관리하는 정보일 수 있다. 검색 장치는 사용자의 개인화 정보를 텍스트 질의로 생성한다(S320). 검색 장치는 텍스트 인코더 및 이미지 인코더를 이용하여, 동영상 서비스 화면에 표시된 각 동영 상의 프레임들에서, 텍스트 질의에 해당하는 대표 프레임을 결정한다(S330). 검색 장치는 도 1부터 도 8을 참고로 설명한 대표 프레임 추출 방법에 따라, 각 동영상의 대표 프레임을 추출할 수 있다. 이때, 텍스트 인코 더 및 이미지 인코더는 동영상 서비스에 맞는 텍스트-이미지 쌍들로 훈련될 수 있다. 이를 통해, 검 색 장치는 사용자의 개인화 정보를 기초로, 사용자가 좋아하는 배우가 야외에서 커피를 마시는 프레임을 대 표 프레임으로 추출하거나, 사용자가 관심있는 자동차가 나오는 프레임을 대표 프레임으로 추출할 수 있다. 검색 장치는 동영상 서비스 화면에서, 텍스트 질의로 추출한 각 동영상의 대표 프레임을 해당 동영상의 썸 네일 이미지로 표시한다(S340). 동영상의 썸네일 이미지는 사용자의 개인화 정보를 기초로 추출된 것이므로, 동 일한 동영상이라고 하더라도, 사용자마다의 개인화 정보에 따라 다르게 표시될 수 있다. 이를 통해, 동영상에 대한 사용자의 관심도를 높일 수 있고, 동영상 클릭 및 재생을 유도할 수 있다. 썸네일 이미지를 표시한 이후 어느 동영상이 선택되면, 검색 장치는 선택된 동영상에서 대표 프레임이 포함 된 동영상 구간을 추출하고, 화면에서 동영상 구간을 표시할 수 있다. 검색 결과에 따라, 동영상의 재생바에 동 영상 구간이 표시되거나, 동영상의 재생 마커가 동영상 구간의 시작 시점으로 이동될 수 있다. 여기서, 대표 프 레임은 개인화 정보로 추출된 프레임일 수 있고, 사용자의 새로운 텍스트 질의로부터 추출된 프레임일 수 있다. 도 10은 한 실시예에 따른 동영상 구간 표시 방법의 흐름도이다. 도 10을 참고하면, 검색 장치는 소스 동영상에 대한 텍스트 질의를 입력받는다(S410). 검색 장치는 소스 동영상에서 텍스트 질의에 해당하는 적어도 하나의 동영상 구간을 검색한다(S420). 검색 장치는 도 1부터 도 8을 참고로 설명한 대표 프레임 추출 방법에 따라, 적어도 하나의 동영상 구간을 추출 할 수 있다. 이때, 텍스트 인코더 및 이미지 인코더는 동영상 서비스에 맞는 텍스트-이미지 쌍들로 훈련될 수 있다. 검색 장치는 소스 동영상의 플레이어와 연동하여, 소스 동영상의 재생바에 검색한 동영상 구간이 식별되도 록 표시하거나, 검색한 동영상 구간의 시작 시점으로 이동된 재생 마커를 표시한다(S430). 도 11은 한 실시예에 따른 동영상 클립 생성 방법의 흐름도이다. 도 11을 참고하면, 검색 장치는 소스 동영상에 대한 텍스트 질의를 입력받는다(S510). 검색 장치는 소스 동영상에서 텍스트 질의에 해당하는 적어도 하나의 동영상 구간을 검색한다(S520). 검색 장치는 도 1부터 도 8을 참고로 설명한 대표 프레임 추출 방법에 따라, 적어도 하나의 동영상 구간을 추출 할 수 있다. 이때, 텍스트 인코더 및 이미지 인코더는 동영상 서비스에 맞는 텍스트-이미지 쌍들로 훈련될 수 있다. 검색 장치는 소스 동영상에서, 검색된 동영상 구간을 추출해서, 텍스트 질의에 해당하는 동영상 클립을 생 성한다(S530). 종래의 검색 기술은 텍스트나 이미지 기반 데이터베이스에서 검색 결과를 추출하는데, 영상 플랫폼의 발전으로 방대하게 생성된 동영상 데이터베이스에서 원하는 장면을 찾고자 하는 필요성이 높아지고 있다. 하지만, 대량의 프레임들로 구성된 동영상에서 원하는 장면을 찾는 것은 쉽지 않다. 왜냐하면, 종래 검색 기술의 경우, 사람이모든 동영상의 장면들을 확인하고 각 장면에 어노테이션(annotation) 혹은 태그 등을 입력해 두면, 장치가 입력 키워드와 장면별 어노테이션의 유사도를 계산해서, 높은 유사도의 어노테이션이 부착된 장면을 검색하는 방식이 다. 따라서, 사람이 어노테이션을 하는 데 시간 및 비용이 많이 필요하고, 새로운 동영상이 나올 때마다 계속 새롭게 어노테이션을 해야 하므로 늘어나는 모든 동영상들에서 검색하는 것이 불가능하고, 기존 동영상의 어노 테이션으로 검색 범위가 제한될 수밖에 없다. 이와 달리, 본 개시의 검색 장치는 검색하고자 하는 장면(예 를 들어, 청소하는 부부가 나오는 장면)을 설명하는 텍스트 질의를 입력받고, 어노테이션이 없는 동영상에서 원 하는 장면을 검색 결과로 제공할 수 있다. 또한, 검색 장치는 텍스트-이미지 쌍들을 이용해서, 텍스트-이미지의 관계가 반영된 특징 벡터를 생성하도 록 훈련된 텍스트 인코더와 이미지 인코더를 이용하므로, 소스 동영상의 프레임들에 레이블이나 참고 정보가 없더라도, 텍스트 질의에 관련된 대표 프레임이나 동영상 구간을 추출할 수 있다. 예를 들어, 소스 동영 상의 프레임들에 청소나 부부 등이 어노테이션되어 있지 않아도, 검색 장치는 소스 동영상에서, 청소하는 부부가 나오는 장면을 찾을 수 있다. 따라서, 검색 장치는 어노테이션 작업을 줄일 수 있고, 계속해서 늘어 나는 새로운 동영상들에서도 원하는 검색 결과를 얻을 수 있다. 검색 장치는 간단한 키워드 텍스트(예를 들면, 사과) 뿐만 아니라, 복수의 키워드들로 구성된 텍스트 질의 를 입력받을 수 있기 때문에, 질의자는 검색하고자 하는 장면을 구체적으로 질의할 수 있고, 동영상에서 원하는 장면을 자유롭게 검색할 수 있다. 이상에서 설명한 본 개시의 실시예는 장치 및 방법을 통해서만 구현이 되는 것은 아니며, 본 개시의 실시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있다. 이상에서 본 개시의 실시예에 대하여 상세하게 설명하였지만 본 개시의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 개시의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 개시의 권리범위에 속하는 것이다."}
{"patent_id": "10-2022-0137774", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 한 실시예에 따른 동영상 구간 검색 장치의 개념도이다. 도 2는 한 실시예에 따른 동영상 구간 검색 장치의 구성도이다. 도 3은 한 실시예에 따른 군집화 기반 동영상 구간 검색 방법을 설명하는 도면이다. 도 4는 한 실시예에 따른 동영상 구간 검색 방법을 설명하는 도면이다. 도 5는 한 실시예에 따른 인공지능 모델의 훈련을 설명하는 도면이다. 도 6은 텍스트-이미지의 상관 관계 테이블의 예시이다. 도 7은 한 실시예에 따른 인공지능 모델 훈련 방법의 흐름도이다. 도 8은 한 실시예에 따른 동영상 구간 검색 방법의 흐름도이다. 도 9는 한 실시예에 따른 썸네일 이미지 제공 방법의 흐름도이다. 도 10은 한 실시예에 따른 동영상 구간 표시 방법의 흐름도이다. 도 11은 한 실시예에 따른 동영상 클립 생성 방법의 흐름도이다."}
