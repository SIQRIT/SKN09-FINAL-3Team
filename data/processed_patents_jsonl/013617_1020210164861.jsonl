{"patent_id": "10-2021-0164861", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0077824", "출원번호": "10-2021-0164861", "발명의 명칭": "청소 로봇과 인터랙션", "출원인": "삼성전자주식회사", "발명자": "김상헌"}}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 청소 로봇과의 인터랙션(interaction)을 수행하는 방법에 있어서,카메라를 통해 촬영된 실내 공간 이미지로부터 상기 청소 로봇을 인식하는 단계; 서버로부터 상기 인식된 청소 로봇의 디바이스 식별 정보, 타입, 및 기능 정보 중 적어도 하나를 포함하는 디바이스 정보를 획득하는 단계; 복수의 UWB(Ultra Wide Band) 안테나 엘리먼트를 통해 상기 청소 로봇으로부터 수신된 UWB 신호에 기초하여, 상기 청소 로봇의 위치 정보를 획득하는 단계; 상기 디바이스 정보 및 상기 위치 정보에 기초하여, 상기 청소 로봇을 상기 청소 로봇에 대응되는 증강 현실 이미지로 매핑하는 단계; 및상기 실내 공간 이미지 내의 상기 청소 로봇에 대응되는 이미지 상에 상기 증강 현실 이미지를 오버랩(overlap)하여 디스플레이하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 청소 로봇의 위치 정보를 획득하는 단계는, 상기 UWB 신호로부터 획득된 레인징(ranging) 정보 및 AOA(Arrival of Angle) 정보에 기초하여, 이동 중인 상기 청소 로봇의 위치를 트래킹(tracking)하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 청소 로봇의 위치 이동에 대응되는 기 설정된 동작을 수행하기 위한 증강 현실 컨텐트를 디스플레이하는단계;를 더 포함하는, 방법."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 청소 로봇의 위치 이동에 따라 상기 실내 공간 이미지에서 상기 청소 로봇이 인식되지 않는 경우, 상기 전자 장치의 카메라의 FOV(Field Of View)를 변경하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2023-0077824-3-제4 항에 있어서,상기 카메라는 서로 다른 FOV를 갖는 복수의 렌즈 모듈을 포함하고, 상기 카메라의 FOV를 변경하는 단계는, 상기 청소 로봇의 위치 이동에 의해 변경되는 상기 전자 장치와 상기 청소 로봇 간의 거리 및 방향에 따라 상기복수의 렌즈 모듈의 동작 모드를 전환함으로써 상기 카메라의 FOV를 변경하는, 방법."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 청소 로봇의 위치 이동에 따른 상기 전자 장치와 상기 청소 로봇 간의 거리에 기초하여, 상기 전자 장치의카메라의 줌 인(zoom in) 또는 줌 아웃(zoom out)을 수행하기 위한 줌 배율을 조절하는 단계; 를 더 포함하는, 방법."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서, 상기 카메라의 조절된 줌 배율에 기초하여, 상기 청소 로봇으로 전송되는 UWB 신호에 포함되는 레인징 제어 메시지(ranging control message, RCM)의 레인징 간격(ranging interval)을 조절하는 단계; 를 더 포함하고, 상기 청소 로봇의 위치 정보를 획득하는 단계는, 상기 조절된 레인징 간격에 기초하여, 상기 청소 로봇과 상기 레인징 제어 메시지를 송수신함으로써, 이동 중인상기 청소 로봇의 위치를 트래킹하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서, 상기 증강 현실 이미지를 디스플레이하는 단계는, 상기 실내 공간 이미지 내의 상기 청소 로봇에 대응되는 이미지를 가상의 아바타 이미지로 대체하여 디스플레이하는, 방법."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "전자 장치가 청소 로봇과의 인터랙션을 수행하는 방법에 있어서,상기 청소 로봇의 카메라를 통해 촬영된 실내 공간 이미지를 수신하는 단계; 상기 실내 공간 이미지로부터 적어도 하나의 객체를 인식하는 단계; 서버로부터 상기 인식된 적어도 하나의 객체의 식별 정보, 타입, 및 기능 정보 중 적어도 하나를 포함하는 객체정보를 획득하는 단계; 상기 청소 로봇과 상기 적어도 하나의 객체 간 UWB 신호의 송수신을 통해 획득된 상기 적어도 하나의 객체의 위치 정보를 상기 청소 로봇으로부터 수신하는 단계; 상기 적어도 하나의 객체에 관한 상기 객체 정보 및 상기 위치 정보에 기초하여, 상기 적어도 하나의 객체를 증강 현실 이미지와 매핑하는 단계; 및공개특허 10-2023-0077824-4-상기 매핑된 증강 현실 이미지를 상기 실내 공간 이미지 내의 상기 적어도 하나의 객체에 대응되는 객체 이미지상에 오버랩하여 디스플레이하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서, 상기 증강 현실 이미지를 통해 상기 적어도 하나의 객체에 관한 사용자 입력을 수신하는 단계; 상기 수신된 사용자 입력에 대응되는 상기 적어도 하나의 객체의 기능 또는 동작을 식별하는 단계; 상기 서버로부터 상기 식별된 기능 또는 동작에 관한 제어 명령을 획득하는 단계; 및상기 획득된 제어 명령을 상기 청소 로봇에 전송하는 단계;를 더 포함하고, 상기 청소 로봇은 근거리 통신 네트워크를 통해 상기 제어 명령을 상기 적어도 하나의 객체에 전송함으로써, 상기 적어도 하나의 객체가 상기 제어 명령에 대응되는 기능 또는 동작을 수행하도록 제어하는, 방법."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청소 로봇과 인터랙션(interaction)을 수행하는 전자 장치에 있어서, 카메라;디스플레이부; 무선 통신 네트워크를 이용하여 서버 또는 상기 청소 로봇과 데이터 송수신을 수행하는 통신 인터페이스; 적어도 하나의 명령어들(instructions)를 저장하는 메모리; 및상기 적어도 하나의 명령어들을 실행하는 적어도 하나의 프로세서; 를 포함하고, 상기 적어도 하나의 프로세서는, 상기 카메라를 통해 상기 실내 공간을 촬영함으로써 획득된 실내 공간 이미지로부터 상기 청소 로봇을인식하고, 상기 통신 인터페이스를 통해 상기 서버로부터 상기 인식된 청소 로봇의 디바이스 식별 정보, 타입, 및 기능 정보 중 적어도 하나를 포함하는 디바이스 정보를 획득하고, 상기 통신 인터페이스에 포함되는 UWB 통신 모듈을 통해 상기 청소 로봇으로부터 수신된 UWB 신호에 기초하여,상기 청소 로봇의 위치 정보를 획득하고, 상기 디바이스 정보 및 상기 위치 정보에 기초하여, 상기 청소 로봇을 상기 청소 로봇에 대응되는 증강 현실 이미지로 매핑하고, 상기 실내 공간 이미지 내의 상기 청소 로봇에 대응되는 이미지 상에 상기 증강 현실 이미지를 오버랩(overlap)하여 디스플레이하도록 상기 디스플레이부를 제어하는, 전자 장치."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서, 상기 적어도 하나의 프로세서는,공개특허 10-2023-0077824-5-상기 UWB 신호로부터 획득된 레인징(ranging) 정보 및 AOA(Arrival of Angle) 정보에 기초하여, 이동 중인 상기 청소 로봇의 위치를 트래킹(tracking)하는, 전자 장치."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서,상기 적어도 하나의 프로세서는, 상기 청소 로봇의 위치 이동에 대응되는 기 설정된 동작을 수행하기 위한 증강 현실 컨텐트를 상기 디스플레이부 상에 디스플레이하는, 전자 장치."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11 항에 있어서,상기 적어도 하나의 프로세서는, 상기 청소 로봇의 위치 이동에 따라 상기 실내 공간 이미지에서 상기 청소 로봇이 인식되지 않는 경우, 상기 카메라의 FOV(Field Of View)를 변경하도록 상기 카메라를 제어하는, 전자 장치."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14 항에 있어서,상기 카메라는 서로 다른 FOV를 갖는 복수의 렌즈 모듈을 포함하고, 상기 적어도 하나의 프로세서는, 상기 청소 로봇의 위치 이동에 의해 변경되는 상기 전자 장치와 상기 청소 로봇 간의 거리 및 방향에 따라 상기복수의 렌즈 모듈의 동작 모드를 전환함으로써 상기 카메라의 FOV를 변경하는, 전자 장치."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11 항에 있어서,상기 적어도 하나의 프로세서는, 상기 청소 로봇의 위치 이동에 따른 상기 전자 장치와 상기 청소 로봇 간의 거리에 기초하여, 상기 카메라의 줌인(zoom in) 또는 줌 아웃(zoom out)을 수행하기 위한 줌 배율을 조절하는, 전자 장치."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16 항에 있어서, 상기 적어도 하나의 프로세서는, 상기 카메라의 조절된 줌 배율에 기초하여, 상기 청소 로봇으로 전송되는 UWB 신호에 포함되는 레인징 제어 메시지(ranging control message, RCM)의 레인징 간격(ranging interval)을 조절하고, 상기 조절된 레인징 간격에 기초하여, 상기 청소 로봇과 상기 레인징 제어 메시지를 송수신하도록 상기 통신 인터페이스를 제어함으로써, 이동 중인 상기 청소 로봇의 위치를 트래킹하는, 전자 장치. 공개특허 10-2023-0077824-6-청구항 18 제11 항에 있어서, 상기 적어도 하나의 프로세서는,상기 실내 공간 이미지 내의 상기 청소 로봇에 대응되는 이미지를 가상의 아바타 이미지로 대체하여 디스플레이하도록 상기 디스플레이부를 제어하는, 전자 장치."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "청소 로봇과의 인터랙션을 수행하는 전자 장치에 있어서, 디스플레이부; 무선 통신 네트워크를 이용하여 서버 또는 상기 청소 로봇과 데이터 송수신을 수행하는 통신 인터페이스; 적어도 하나의 명령어들(instructions)를 저장하는 메모리; 및상기 적어도 하나의 명령어들을 실행하는 적어도 하나의 프로세서; 를 포함하고, 상기 적어도 하나의 프로세서는, 상기 통신 인터페이스를 통해, 상기 청소 로봇의 카메라에 의해 촬영된 실내 공간 이미지를 수신하고, 상기 실내 공간 이미지로부터 적어도 하나의 객체를 인식하고, 상기 통신 인터페이스를 통해, 서버로부터 상기 인식된 적어도 하나의 객체의 식별 정보, 타입, 및 기능 정보중 적어도 하나를 포함하는 객체 정보를 획득하고, 상기 청소 로봇과 상기 적어도 하나의 객체 간 UWB 신호의송수신을 통해 획득된 상기 적어도 하나의 객체의 위치 정보를 상기 청소 로봇으로부터 수신하고, 상기 적어도 하나의 객체에 관한 상기 객체 정보 및 상기 위치 정보에 기초하여, 상기 적어도 하나의 객체를 증강 현실 이미지와 매핑하고,상기 매핑된 증강 현실 이미지를 상기 실내 공간 이미지 내의 상기 적어도 하나의 객체에 대응되는 객체 이미지상에 오버랩하여 디스플레이하도록 상기 디스플레이부를 제어하는, 전자 장치."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19 항에 있어서, 상기 증강 현실 이미지를 통해 상기 적어도 하나의 객체에 관한 사용자 입력을 수신하는 사용자 입력부;를 더 포함하고, 상기 적어도 하나의 프로세서는, 상기 사용자 입력부를 통해 수신된 사용자 입력에 대응되는 상기 적어도 하나의 객체의 기능 또는 동작을 식별하고, 상기 통신 인터페이스를 통해 상기 서버로부터 상기 식별된 기능 또는 동작에 관한 제어 명령을 획득하고, 상기획득된 제어 명령을 상기 청소 로봇에 전송하며, 상기 청소 로봇은 근거리 통신 네트워크를 통해 상기 제어 명령을 상기 적어도 하나의 객체에 전송함으로써, 상기 적어도 하나의 객체가 상기 제어 명령에 대응되는 기능 또는 동작을 수행하도록 제어하는, 전자 장치."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "공개특허 10-2023-0077824-7-제1 항 내지 제8 항 중 어느 하나의 항에 기재된 방법을 구현하기 위한 적어도 하나의 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2021-0164861", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제9 항 및 제10 항 중 어느 하나의 항에 기재된 방법을 구현하기 위한 적어도 하나의 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2021-0164861", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "증강 현실(Augmented Reality, AR) 기술을 이용하여 청소 로봇과 인터랙션(interaction)을 수행하는 전자 장치 및 그 동작 방법을 제공한다. 본 개시의 일 실시예에 따른 전자 장치는, 실내 공간 내의 청소 로봇을 가상의 이 미지로 구성된 증강 현실 이미지(Augmented Reality image)와 매핑(mapping)하고, 매핑된 증강 현실 이미지를 디스플레이하며, 증강 현실 이미지를 통해 청소 로봇과의 상호 동작을 수행할 수 있다."}
{"patent_id": "10-2021-0164861", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 청소 로봇과 인터랙션하는 전자 장치 및 그 동작 방법에 관한 것이다. 구체적으로, 본 개시는 현실 공간 내의 청소 로봇을 가상의 이미지 컨텐트인 증강 현실 이미지(Augmented Reality image)와 매핑(mapping)하 고, 매핑된 증강 현실 이미지를 디스플레이하며, 증강 현실 이미지를 통해 청소 로봇과의 상호 동작을 수행하는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2021-0164861", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "청소 로봇은 실내 공간 내의 영역을 스스로 주행하면서, 실내 공간의 먼지 도는 이물질을 흡입함으로써 해당 영 역을 청소하는 전자 장치이다. 전자 장치는 청소 로봇과 근거리 무선 통신 네트워크를 통해 연결되며, 애플리케 이션(예를 들어, SmartThings 애플리케이션)을 실행함으로써 청소 로봇과 인터랙션(interaction)을 수행하며, 청소 로봇의 기능 또는 동작을 제어할 수 있다. 종래 기술에 따른 전자 장치는 청소 로봇을 전진, 좌회전, 우회 전 등 이동시키거나, 청소 로봇의 청소 영역을 결정하거나, 또는 청소 로봇에 장착된 카메라를 이용하여 원격으 로 집안 등 실내 공간을 모니터링하는 등 한정된 인터랙션만을 제공하였다. 최근에는, 통신 기술이 발달함에 따라 메타버스(Metaverse) 및 확장 현실(XR: eXtended Reality) 서비스 제공에 대한 수요가 증가하고 있다. '메타버스(Metaverse)'는 가상 또는 초월을 뜻하는 '메타(Meta)'와 세계 또는 우주 를 의미하는 '유니버스(Universe)'의 합성어로서, 현실 세계(Real world)와 같은 사회, 경제, 문화 활동이 이루 어지는 3차원의 가상 세계를 의미한다. 메타버스는 시간적인 개념을 추가함으로써, 가상 세계와 현실 세계의 흐 름을 아우르는 통칭으로 사용된다. 반면, 가상 현실(Virtual Reality, VR)은 완전한 메타버스를 전제로 한 가상 적인 것을 현실 세계에 적용하여 경험하는 것을 뜻한다. VR에서 파생된 개념으로는 '증강 현실(Augmented Reality, AR)', '혼합 현실(Mixed Reality, MR)', 및 확장 현실(XR)이 있다. '확장 현실(XR)'은 가상 현실(VR: Virtual Reality), 증강 현실(AR: Augmented Reality) 또는 혼합 현실(MR: Mixed Reality) 중 적어도 하나를 포함할 수 있다. 증강 현실(AR)이란, 사용자가 눈으로 보는 현실 공간에 존재 하는 현실 객체에 가상의 이미지 컨텐트를 합성함으로써, 현실 세계만으로는 얻기 어려운 부가적인 정보를 제공 하는 기술이다. 증강 현실 서비스는 복수의 가상 이미지 컨텐트를 제공할 수 있으며, 장면 묘사(scene description) 기술을 사용하여 가상 이미지 컨텐트 간의 물리적 관계를 기술할 수 있다. 가상의 이미지 컨텐트 는 3D 모델로 제공될 수 있으며, 증강 현실 서비스 이용자는 현실 공간을 분석하여 3D 모델을 합성할 위치 (anchor)를 결정하고, 식별된 위치에 3D 모델을 렌더링할 수 있다. 전술한 바와 같이, 기존의 전자 장치는 청소 로봇의 이동, 청소 영역 결정, 또는 실내 공간 모니터링 등 청소 로봇과의 제한적인 인터랙션만을 수행하므로, 사용자 편의성이 낮고, 증강 현실 서비스와 같은 확장 현실(XR)에 관한 사용자 경험(User eXperience, UX)을 제공하지 못하는 문제점이 있다. 따라서, 청소 로봇과의 인터랙션에 있어서 증강 현실 기술을 접목하여 가상 이미지 컨텐트를 통해 증강 현실 서비스를 제공하는 전자 장치가 요구 되고 있다."}
{"patent_id": "10-2021-0164861", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 다양한 실시예는 증강 현실 기술을 이용하여 청소 로봇과의 인터랙션(interaction)을 수행하는 전자 장치 및 그 동작 방법을 제공하는 것을 목적으로 한다. 본 개시의 일 실시예에 의하면, 현실 공간 내의 청소 로 봇을 가상의 이미지 컨텐트인 증강 현실 이미지(Augmented Reality image)와 매핑(mapping)하고, 매핑된 증강 현실 이미지를 디스플레이하며, 증강 현실 이미지를 통해 청소 로봇과의 상호 동작을 수행하는 전자 장치 및 그 동작 방법이 제공된다."}
{"patent_id": "10-2021-0164861", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 해결하기 위하여 본 개시는 일 실시예는 전자 장치가 청소 로봇과의 인터랙션 (interaction)을 수행하는 방법을 제공한다. 본 개시의 일 실시예에 따르면, 상기 방법은 카메라를 통해 촬영된 실내 공간 이미지로부터 상기 청소 로봇을 인식하는 단계, 서버로부터 상기 인식된 청소 로봇의 디바이스 식별 정보, 타입, 및 기능 정보 중 적어도 하나를 포함하는 디바이스 정보를 획득하는 단계, 복수의 UWB(Ultra Wide Band) 안테나 엘리먼트를 통해 상기 청소 로봇으로부터 수신된 UWB 신호에 기초하여, 상기 청소 로봇의 위치 정 보를 획득하는 단계, 상기 디바이스 정보 및 상기 위치 정보에 기초하여, 상기 청소 로봇을 상기 청소 로봇에 대응되는 증강 현실 이미지로 매핑하는 단계, 및 상기 실내 공간 이미지 내의 상기 청소 로봇에 대응되는 이미 지 상에 상기 증강 현실 이미지를 오버랩(overlap)하여 디스플레이하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 상기 청소 로봇의 위치 정보를 획득하는 단계는, 상기 UWB 신호로부터 획득된 레인징 (ranging) 정보 및 AOA(Arrival of Angle) 정보에 기초하여, 이동 중인 상기 청소 로봇의 위치를 트래킹 (tracking)하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 상기 방법은 상기 청소 로봇의 위치 이동에 대응되는 기 설정된 동작을 수행하기 위 한 증강 현실 컨텐트를 디스플레이하는 단계를 더 포함할 수 있다. 본 개시의 일 실시예에서, 상기 방법은 상기 청소 로봇의 위치 이동에 따라 상기 실내 공간 이미지에서 상기 청 소 로봇이 인식되지 않는 경우, 상기 전자 장치의 카메라의 FOV(Field Of View)를 변경하는 단계를 더 포함할 수 있다. 본 개시의 일 실시예에서, 상기 카메라는 서로 다른 FOV를 갖는 복수의 렌즈 모듈을 포함하고, 상기 카메라의 FOV를 변경하는 단계는 상기 청소 로봇의 위치 이동에 의해 변경되는 상기 전자 장치와 상기 청소 로봇 간의 거 리 및 방향에 따라 상기 복수의 렌즈 모듈의 동작 모드를 전환함으로써 상기 카메라의 FOV를 변경하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 상기 방법은 상기 청소 로봇의 위치 이동에 따른 상기 전자 장치와 상기 청소 로봇 간의 거리에 기초하여, 상기 전자 장치의 카메라의 줌 인(zoom in) 또는 줌 아웃(zoom out)을 수행하기 위한 줌 배율을 조절하는 단계를 더 포함할 수 있다. 본 개시의 일 실시예에서, 상기 방법은 상기 카메라의 조절된 줌 배율에 기초하여 상기 청소 로봇으로 전송되는 UWB 신호에 포함되는 레인징 제어 메시지(ranging control message, RCM)의 레인징 간격(ranging interval)을 조절하는 단계를 더 포함하고, 상기 청소 로봇의 위치 정보를 획득하는 단계는 상기 조절된 레인징 간격에 기초 하여, 상기 청소 로봇과 상기 레인징 제어 메시지를 송수신함으로써, 이동 중인 상기 청소 로봇의 위치를 트래 킹하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 상기 증강 현실 이미지를 디스플레이하는 단계는 상기 실내 공간 이미지 내의 상기 청소 로봇에 대응되는 이미지를 가상의 아바타 이미지로 대체하여 디스플레이할 수 있다. 상술한 기술적 과제를 해결하기 위하여 본 개시의 다른 실시예는, 전자 장치가 청소 로봇과의 인터랙션을 수행 하는 방법을 제공한다. 본 개시의 일 실시예에 따른 방법은, 상기 청소 로봇의 카메라를 통해 촬영된 실내 공간 이미지를 수신하는 단계, 상기 실내 공간 이미지로부터 적어도 하나의 객체를 인식하는 단계, 서버로부터 상기 인식된 적어도 하나의 객체의 식별 정보, 타입, 및 기능 정보 중 적어도 하나를 포함하는 객체 정보를 획득하는 단계, 상기 청소 로봇과 상기 적어도 하나의 객체 간 UWB 신호의 송수신을 통해 획득된 상기 적어도 하나의 객 체의 위치 정보를 상기 청소 로봇으로부터 수신하는 단계, 상기 적어도 하나의 객체에 관한 상기 객체 정보 및 상기 위치 정보에 기초하여, 상기 적어도 하나의 객체를 증강 현실 이미지와 매핑하는 단계, 및 상기 매핑된 증 강 현실 이미지를 상기 실내 공간 이미지 내의 상기 적어도 하나의 객체에 대응되는 객체 이미지 상에 오버랩하여 디스플레이하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 상기 방법은, 상기 증강 현실 이미지를 통해 상기 적어도 하나의 객체에 관한 사용자 입력을 수신하는 단계, 상기 수신된 사용자 입력에 대응되는 상기 적어도 하나의 객체의 기능 또는 동작을 식별 하는 단계, 상기 서버로부터 상기 식별된 기능 또는 동작에 관한 제어 명령을 획득하는 단계, 및 상기 획득된 제어 명령을 상기 청소 로봇에 전송하는 단계를 더 포함하고, 상기 청소 로봇은 근거리 통신 네트워크를 통해 상기 제어 명령을 상기 적어도 하나의 객체에 전송함으로써, 상기 적어도 하나의 객체가 상기 제어 명령에 대응 되는 기능 또는 동작을 수행하도록 제어할 수 있다. 상술한 기술적 과제를 해결하기 위하여 본 개시의 다른 실시예는, 청소 로봇과 인터랙션(interaction)을 수행하 는 전자 장치를 제공한다. 본 개시의 일 실시예에 따른 전자 장치는 카메라, 디스플레이부, 무선 통신 네트워크 를 이용하여 서버 또는 상기 청소 로봇과 데이터 송수신을 수행하는 통신 인터페이스, 적어도 하나의 명령어들 (instructions)를 저장하는 메모리, 및 상기 적어도 하나의 명령어들을 실행하는 적어도 하나의 프로세서를 포 함하고, 상기 적어도 하나의 프로세서는 상기 카메라를 통해 상기 실내 공간을 촬영함으로써 획득된 실내 공간 이미지로부터 상기 청소 로봇을 인식하고, 상기 통신 인터페이스를 통해 상기 서버로부터 상기 인식된 청소 로 봇의 디바이스 식별 정보, 타입, 및 기능 정보 중 적어도 하나를 포함하는 디바이스 정보를 획득하고, 상기 통 신 인터페이스에 포함되는 UWB 통신 모듈을 통해 상기 청소 로봇으로부터 수신된 UWB 신호에 기초하여, 상기 청 소 로봇의 위치 정보를 획득하고, 상기 디바이스 정보 및 상기 위치 정보에 기초하여, 상기 청소 로봇을 상기 청소 로봇에 대응되는 증강 현실 이미지로 매핑하고, 상기 실내 공간 이미지 내의 상기 청소 로봇에 대응되는 이미지 상에 상기 증강 현실 이미지를 오버랩(overlap)하여 디스플레이하도록 상기 디스플레이부를 제어할 수 있다. 본 개시의 일 실시예에서, 상기 적어도 하나의 프로세서는 상기 UWB 신호로부터 획득된 레인징(ranging) 정보 및 AOA(Arrival of Angle) 정보에 기초하여, 이동 중인 상기 청소 로봇의 위치를 트래킹(tracking)할 수 있다. 본 개시의 일 실시예에서, 상기 적어도 하나의 프로세서는 상기 청소 로봇의 위치 이동에 대응되는 기 설정된 동작을 수행하기 위한 증강 현실 컨텐트를 상기 디스플레이부 상에 디스플레이할 수 있다. 본 개시의 일 실시예에서, 상기 적어도 하나의 프로세서는 상기 청소 로봇의 위치 이동에 따라 상기 실내 공간 이미지에서 상기 청소 로봇이 인식되지 않는 경우, 상기 카메라의 FOV(Field Of View)를 변경하도록 상기 카메 라를 제어할 수 있다. 본 개시의 일 실시예에서, 상기 카메라는 서로 다른 FOV를 갖는 복수의 렌즈 모듈을 포함하고, 상기 적어도 하 나의 프로세서는 상기 청소 로봇의 위치 이동에 의해 변경되는 상기 전자 장치와 상기 청소 로봇 간의 거리 및 방향에 따라 상기 복수의 렌즈 모듈의 동작 모드를 전환함으로써 상기 카메라의 FOV를 변경할 수 있다. 본 개시의 일 실시예에서, 상기 적어도 하나의 프로세서는 상기 청소 로봇의 위치 이동에 따른 상기 전자 장치 와 상기 청소 로봇 간의 거리에 기초하여, 상기 카메라의 줌 인(zoom in) 또는 줌 아웃(zoom out)을 수행하기 위한 줌 배율을 조절할 수 있다. 본 개시의 일 실시예에서, 상기 적어도 하나의 프로세서는 상기 카메라의 조절된 줌 배율에 기초하여, 상기 청 소 로봇으로 전송되는 UWB 신호에 포함되는 레인징 제어 메시지(ranging control message, RCM)의 레인징 간격 (ranging interval)을 조절하고, 상기 조절된 레인징 간격에 기초하여 상기 청소 로봇과 상기 레인징 제어 메시 지를 송수신하도록 상기 통신 인터페이스를 제어함으로써, 이동 중인 상기 청소 로봇의 위치를 트래킹할 수 있 다. 본 개시의 일 실시예에서, 상기 적어도 하나의 프로세서는 상기 실내 공간 이미지 내의 상기 청소 로봇에 대응 되는 이미지를 가상의 아바타 이미지로 대체하여 디스플레이하도록 상기 디스플레이부를 제어할 수 있다. 상술한 기술적 과제를 해결하기 위하여 본 개시의 다른 실시예는, 청소 로봇과 인터랙션(interaction)을 수행하 는 전자 장치를 제공한다. 본 개시의 일 실시예에 따른 전자 장치는 디스플레이부, 무선 통신 네트워크를 이용 하여 서버 또는 상기 청소 로봇과 데이터 송수신을 수행하는 통신 인터페이스, 적어도 하나의 명령어들 (instructions)를 저장하는 메모리, 및 상기 적어도 하나의 명령어들을 실행하는 적어도 하나의 프로세서를 포 함하고, 상기 적어도 하나의 프로세서는 상기 통신 인터페이스를 통해 상기 청소 로봇의 카메라에 의해 촬영된 실내 공간 이미지를 수신하고, 상기 실내 공간 이미지로부터 적어도 하나의 객체를 인식하고, 상기 통신 인터페 이스를 통해, 서버로부터 상기 인식된 적어도 하나의 객체의 식별 정보, 타입, 및 기능 정보 중 적어도 하나를 포함하는 객체 정보를 획득하고, 상기 청소 로봇과 상기 적어도 하나의 객체 간 UWB 신호의 송수신을 통해 획득된 상기 적어도 하나의 객체의 위치 정보를 상기 청소 로봇으로부터 수신하고, 상기 적어도 하나의 객체에 관한 상기 객체 정보 및 상기 위치 정보에 기초하여, 상기 적어도 하나의 객체를 증강 현실 이미지와 매핑하고, 상기 매핑된 증강 현실 이미지를 상기 실내 공간 이미지 내의 상기 적어도 하나의 객체에 대응되는 객체 이미지 상에 오버랩하여 디스플레이하도록 상기 디스플레이부를 제어할 수 있다. 본 개시의 일 실시예에서, 상기 전자 장치는 상기 증강 현실 이미지를 통해 상기 적어도 하나의 객체에 관한 사 용자 입력을 수신하는 사용자 입력부를 더 포함하고, 상기 적어도 하나의 프로세서는 상기 사용자 입력부를 통 해 수신된 사용자 입력에 대응되는 상기 적어도 하나의 객체의 기능 또는 동작을 식별하고, 상기 통신 인터페이 스를 통해 상기 서버로부터 상기 식별된 기능 또는 동작에 관한 제어 명령을 획득하고, 상기 획득된 제어 명령 을 상기 청소 로봇에 전송하며, 상기 청소 로봇은 근거리 통신 네트워크를 통해 상기 제어 명령을 상기 적어도 하나의 객체에 전송함으로써, 상기 적어도 하나의 객체가 상기 제어 명령에 대응되는 기능 또는 동작을 수행하 도록 제어할 수 있다. . 상술한 기술적 과제를 해결하기 위하여, 본 개시의 다른 실시예는 컴퓨터에서 실행시키기 위한 프로그램을 기록 한 컴퓨터로 읽을 수 있는 기록매체를 제공한다."}
{"patent_id": "10-2021-0164861", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서의 실시예들에서 사용되는 용어는 본 개시의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 실시예의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 본 명세서에 기재 된 \"...부\", \"...모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for)\", \"~하는 능력을 가지는(having the capacity to)\", \"~하도록 설계된(designed to)\", \"~하도 록 변경된(adapted to)\", \"~하도록 만들어진(made to)\", 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 시스템\"이라는 표현은, 그 시 스템이 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수 행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 또한, 본 개시에서 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존 재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것 이다. 본 개시에서, '전자 장치'는 설치된 특정 애플리케이션을 실행함으로써, 서버 또는 외부 장치(예를 들어, 청소 로봇)와 데이터를 송수신하고, 청소 로봇의 기능 또는 동작을 제어함으로써 청소 로봇과 인터랙션(interactio n)을 수행하는 장치를 의미한다. 본 개시의 일 실시예에서, 특정 애플리케이션은 사용자가 청소 동작, 청소 영역 설정, 실내 공간 모니터링, 또는 펫 케어(pet care) 등 청소 로봇의 기능 또는 동작을 제어하는 애플리케이 션일 수 있다. 예를 들어, 애플리케이션은 SmartThings 애플리케이션일 수 있으나, 이에 한정되는 것은 아니다. 본 개시에서, '청소 로봇'은 구동 모터 및 바퀴 등을 이용하여 스스로 이동할 수 있는 로봇 장치로서, 실내 공 간을 이동하면서 청소 동작을 수행할 수 있다. 본 개시에서, '인터랙션(interaction)'은 전자 장치와 청소 로봇 간의 상호 동작을 의미한다. 본 개시의 일 실 시예에서, 인터랙션은 전자 장치가 청소 로봇을 제어함으로써, 청소 동작을 수행하거나, 청소 영역을 결정하는 동작 및 청소 로봇이 실내 공간을 모니터링하여 전자 장치에 실내 공간에 관한 데이터를 전송하는 동작을 포함 할 수 있다. 그러나, 이에 한정되는 것은 아니고, '인터랙션'은 전자 장치와 청소 로봇 간의 모든 동작 및 제어 를 포함하는 개념이다. 본 개시에서, '증강 현실(AR : Augmented Reality)'은 현실 세계의 물리적 환경 공간 내에 가상 이미지를 함께 보여주거나 현실 객체와 가상 이미지를 함께 보여주는 것을 의미한다. 본 개시에서, '현실 공간'이란 사용자가 현실 세계의 공간으로서, 현실 객체(real world object)(들)를(을) 포 함할 수 있다. 본 개시에서, '증강 현실 이미지(Augmented Reality image)'는 현실 객체와 매핑되는 가상의 이미지이다. 증강 현실 이미지는 예를 들어, 캐릭터, 아바타(avatar), 또는 카툰 이미지로 구성될 수 있다. 그러나, 이에 한정되 는 것은 아니고, 증강 현실 이미지는 현실 공간 내의 현실 객체에 대한 정보 또는 현실 객체의 동작에 대한 제 어 메뉴 등을 나타내는 가상의 UI(User Interface) 이미지일 수 있다. 본 개시의 일 실시예에서, 증강 현실 이 미지는 전자 장치의 메모리, 청소 로봇 내의 저장부, 또는 서버에 저장되어 있을 수 있다. 그러나, 이에 한정되 는 것은 아니고, 증강 현실 이미지는 전자 장치 또는 청소 로봇에 의해 생성될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 이하에서는 도면을 참조하여 본 개시의 실시예들을 상세하게 설명한다. 도 1은 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇과의 인터랙션을 수행하는 동작을 도시 한 개념도이다. 도 1을 참조하면, 전자 장치는 설치된 특정 애플리케이션(예를 들어, SmartThings 애플리케이션)을 실행 함으로써, 청소 로봇과 인터랙션(interaction)을 수행할 수 있다. 일 실시예에서, 전자 장치는 애 플리케이션을 통해 청소 로봇을 촬영함으로써 이미지 데이터를 획득하고, 이미지 데이터 내의 청소 로봇 을 청소 로봇에 대응되는 가상의 이미지인 증강 현실 이미지로 매핑하여 디스플레이할 수 있 다. 일 실시예에서, 전자 장치는 디스플레이되는 증강 현실 이미지를 통해 사용자 입력을 수신하고, 사용자 입력에 기초하여 청소 로봇의 기능 또는 동작을 제어할 수 있다. 본 개시의 일 실시예에 의하면, 전자 장치는 청소 로봇과 동일한 사용자 계정 정보(user account) 로 연결된 장치일 수 있다. 전자 장치는 청소 로봇과 근거리 통신 네트워크를 통해서 직접 연결될 수도 있고, 서버를 통해 청소 로봇과 간접적으로 연결될 수도 있다. 전자 장치는 예를 들어, 무선 랜(Wireless LAN), 와이파이(Wi-Fi), WFD(Wi-Fi Direct), 블루투스(Bluetooth), BLE (Bluetooth Low Energy), 지그비(zigbee), 와이브로(Wireless Broadband Internet, Wibro), 와이맥스(World Interoperability for Microwave Access, WiMAX), SWAP(Shared Wireless Access Protocol), 와이기그(Wireless Gigabit Allicance, WiGig) 및 RF 통신 중 적어도 하나의 데이터 통신 네트워크를 이용하여 청소 로봇, 서버, 또는 외부 장치 들과 연결되고, 데이터 송수신을 수행할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 다양한 형태로 구현될 수 있다. 예를 들어, 본 개시의 전자 장 치는 스마트 폰(smart phone), 태블릿 PC, 노트북 컴퓨터(laptop computer), 디지털 카메라, 전자북 단 말기, 디지털방송용 단말기, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 차량용 네 비게이션, 또는 차량의 인포테인먼트 시스템(infotainment system) 중 어느 하나일 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 웨어러블 디바이스(wearable device)일 수 있다. 웨어러블 디 바이스는 액세서리 형 장치(예컨대, 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈), 머리 착용형 장치(head-mounted-device(HMD)), 직물 또는 의류 일체형 장치(예: 전자 의복), 신체 부착형 장치(예컨대, 스킨 패 드(skin pad)), 또는 생체 이식형 장치(예: implantable circuit) 중 적어도 하나를 포함할 수 있다. 다른 실 시예에서, 전자 장치는 TV, 스마트 TV, 디스플레이를 포함하는 냉장고, 또는 디스플레이를 포함하는 오븐 등 가전기기로 구현될 수도 있다. 이하에서는, 설명의 편의상 전자 장치가 스마트 폰인 경우를 예로 들어 설명하기로 한다. 본 개시의 일 실시예에서, 청소 로봇은 구동 모터 및 바퀴 등을 이용하여 스스로 이동할 수 있는 로봇 장 치로서, 실내 공간을 이동하면서 청소 동작을 수행할 수 있다. 도 1을 참조하면, 전자 장치는 청소 로봇을 촬영함으로써 청소 로봇을 포함하는 실내 공간 이미지를 획득하고, 실내 공간 이미지 상에서 청소 로봇 이미지를 인식하며, 인식된 청소 로봇 이미지 를 현실 공간 내의 청소 로봇에 대응되는 가상 이미지인 증강 현실 이미지로 매핑하여 디스플 레이할 수 있다. 구체적으로, 단계 S110에서, 전자 장치는 카메라(1100, 도 2 참조)를 이용하여 청소 로봇이 위치하 는 실내 공간을 촬영함으로써, 실내 공간 이미지를 획득한다. 단계 S120에서, 전자 장치는 획득된 실내 공간 이미지로부터 청소 로봇을 인식할 수 있다. 일 실시예에서, 전자 장치는 인공지능 모델(Artificial Intelligent model, AI model)을 이용하여 실내 공 간 이미지로부터 청소 로봇을 인식할 수 있다. 인공지능 모델은 딥 러닝(Deep Learning) 기반의 객 체 인식 모델로 구성될 수 있다. 일 실시예에서, 객체 인식 모델은 수만 내지 수억 장의 이미지를 입력 데이터 로 적용하고, 이미지에 포함되는 객체의 라벨 값(label)을 출력 정답값(groundtruth)로 적용하여 학습된 (trained) 모델 파라미터로 구성되는 심층 신경망 모델(Deep Neural Network)을 포함할 수 있다. 심층 신경망 모델은 예를 들어, 컨볼루션 신경망 모델(Convolutional Neural Network; CNN), 순환 신경망 모델(Recurrent Neural Network; RNN), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크 (Deep Q-Networks) 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 전자 장치는 객체 인식 모델을 이용한 추론을 통해 실내 공간 이미지로부터 청소 로봇 을 인식할 수 있다. 그러나, 이에 한정되는 것은 아니고, 전자 장치는 공지의 이미지 프로세싱(image processing) 기술을 이 용하여 실내 공간 이미지로부터 청소 로봇을 인식할 수 있다. 전자 장치는 디스플레이부 상에 실내 공간 이미지를 디스플레이할 수 있다. 일 실시예에서, 전자 장치는 실내 공간 이미지 내에서 청소 로봇에 대응되는 청소 로봇 이미지에 마커 (marker)를 표시할 수 있다. 전자 장치는 청소 로봇의 인식 결과를 서버에 전송하고, 서버로부터 청소 로봇에 관한 디바 이스 정보를 획득할 수 있다. 일 실시예에서, 서버는 사용자 계정 정보와 연동되어 등록된 디바이스에 관한 정 보를 저장하고 있는 IoT 클라우드 서버일 수 있다. 서버는 예를 들어, 디바이스의 식별 정보(예를 들어, 디바이 스 id), 디바이스의 타입, 디바이스의 기능 수행 정보(capability), 및 프로파일 정보 중 적어도 하나를 저장할 수 있다. 일 실시예에서, 전자 장치는 청소 로봇의 디바이스 식별 정보, 타입, 및 기능 수행 정보 중 적어도 하나를 포함하는 디바이스 정보를 서버로부터 수신할 수 있다. 단계 S130에서, 전자 장치는 UWB(Ultra Wide Band) 신호를 통해 청소 로봇의 위치 정보를 획득할 수 있다. 전자 장치는 BLE(Bluetooth Low Energy) 신호를 이용하여 UWB 통신을 수행할 수 있는 청소 로 봇을 식별하고, 청소 로봇과 UWB 신호를 송수신함으로써, 청소 로봇의 위치 정보를 획득할 수 있다. 일 실시예에서, 전자 장치는 TWR(Two Way Ranging) 방식을 이용한 레인징(Ranging)을 수행함으 로써, 청소 로봇의 위치 정보를 획득할 수 있다. 전자 장치는 예를 들어, SS-TWR(Single Sided Two Way Ranging) 또는 DS-TWR(Double-Sided Two Way Ranging) 중 어느 하나의 방식을 이용하여 레인징 동작을 수행할 수 있다. 일 실시예에서, 전자 장치는 복수의 UWB 안테나 엘리먼트를 이용하여 청소 로봇에 레인징 요청 메시지(Poll message)를 전송하고, 레인징 요청 신호에 응답하여 청소 로봇으로부터 응답 메 시지(Response message)를 수신할 수 있다. 전자 장치는 레인징 요청 메시지와 응답 메시지 간의 시간 차 이를 이용하는 TOA(Time of Arrival) 또는 TDOA(Time Difference of Arrival) 방법을 통해 청소 로봇의 위치 정보를 획득할 수 있다. 일 실시예에서, 전자 장치는 청소 로봇과 전자 장치 간의 상대 적 거리에 관한 정보인 레인징 정보(Ranging) 및 청소 로봇의 방향 정보인 AOA 정보(Arrival of Angle)를 획득할 수 있다. 단계 S140에서, 전자 장치는 증강 현실 매핑(Augmented Reality Mapping)을 수행한다. 일 실시예에서, 전자 장치는 청소 로봇의 디바이스 정보 및 위치 정보에 기초하여, 현실 공간 내의 청소 로봇 을 증강 현실 이미지로 매핑할 수 있다. 증강 현실 이미지는 청소 로봇에 대응되는 가상 의 이미지로서, 예를 들어 캐릭터, 아바타, 또는 카툰 이미지로 구성될 수 있다. 전자 장치는 메모리 (1400, 도 2 참조) 또는 저장 공간 내에 증강 현실 이미지의 이미지 데이터를 저장할 수 있으나, 이에 한 정되는 것은 아니다. 일 실시예에서, 전자 장치는 청소 로봇에 대응되는 가상 이미지를 생성함으로 써, 증강 현실 이미지를 획득하거나, 서버 또는 청소 로봇으로부터 증강 현실 이미지의 이미지 데이터를 수신할 수도 있다. 단계 S150에서, 전자 장치는 증강 현실 이미지를 디스플레이한다. 일 실시예에서, 전자 장치 는 디스플레이부를 통해 디스플레이되는 실내 공간 이미지 내의 청소 로봇 이미지 상에 증강 현실 이미지를 오버랩(overlap)하여 디스플레이할 수 있다. 다른 실시예에서, 전자 장치는 실내 공 간 이미지 내의 청소 로봇 이미지를 증강 현실 이미지로 대체하여 디스플레이할 수 있다. 전자 장치는 증강 현실 이미지를 통해 청소 로봇과의 인터랙션을 수행할 수 있다. 일 실시예 에서, 전자 장치는 증강 현실 이미지를 통해 사용자 입력을 수신하고, 수신된 사용자 입력에 기초하 여 청소 로봇의 기능 또는 동작을 제어할 수 있다. 기존 기술에서는, 전자 장치와 청소 로봇 간의 인터랙션이 청소 로봇의 이동(예를 들어, 직 진, 좌회전, 우회전), 청소 영역 결정, 또는 실내 공간 모니터링 등 제한적인 제어 동작만을 포함하므로, 사용 자 편의성이 낮은 문제점이 있었다. 또한, 전자 장치가 청소 로봇을 제어하는 경우에도 청소 로봇 의 이미지를 통해 제어 명령을 전송하거나, 실내 공간 지도(map)를 통해 청소 영역을 설정하여야 하는 등 UI적인 측면에서 불편함이 있었다. 본 개시의 일 실시예에 따른 전자 장치는 청소 로봇을 포함하는 실내 공간을 촬영함으로써 실내 공 간 이미지를 획득하고, 실내 공간 이미지로부터 청소 로봇을 인식하며, 인식된 청소 로봇 의 디바이스 정보 및 위치 정보에 기초하여 증강 현실 이미지와 청소 로봇을 매핑하여 디스플 레이함으로써, 사용자에게 증강 현실 서비스와 같은 확장 현실(XR)에 관한 사용자 경험(User eXperience, UX)을 제공할 수 있다. 본 개시의 전자 장치는 증강 현실 이미지를 통해 사용자 입력을 수신하고, 사용자 입력에 기초하여 청소 로봇의 기능 또는 동작을 제어함으로써, 사용자 편의성 및 만족도를 향상시킬 수 있다. 예를 들어, 전자 장치는 현실 세계(Real world)에 존재하는 청소 로봇에 아바타 이미지로 구성되는 증강 현실 이미지를 매핑시킴으로써, 아바타를 통해 현실 세계의 청소 로봇을 제어하는 메타버스에 관한 경험 을 사용자에게 제공할 수 있다. '메타버스(Metaverse)'는 가상 또는 초월을 뜻하는 '메타(Meta)'와 세계 또는 우주를 의미하는 '유니버스(Universe)'의 합성어로서, 현실 세계(Real world)와 같은 사회, 경제, 문화 활동이 이루어지는 3차원의 가상 세계를 의미한다. 또한, 본 개시의 전자 장치는 청소 로봇과 UWB 신호를 송수신하여 청소 로봇의 위치 정보를 획득하므로, 청소 로봇의 위치를 보다 정확하게 측정할 수 있고, 따라서 청소 로봇과 증강 현실 이 미지 간의 매핑 정확도를 향상시킬 수 있다. 도 2는 본 개시의 일 실시예에 따른 전자 장치의 구성 요소를 도시한 블록도이다. 도 2를 참조하면, 전자 장치는 카메라, 통신 인터페이스, 프로세서, 메모리, 및 디스플레이부를 포함할 수 있다. 카메라, 통신 인터페이스, 프로세서, 메모리 , 및 디스플레이부는 각각 전기적 및/또는 물리적으로 서로 연결될 수 있다. 도 2에 도시된 구성 요소는 본 개시의 일 실시예에 따른 것일 뿐, 전자 장치가 포함하고 있는 구성 요소 가 도 2에 도시된 것으로 한정되는 것은 아니다. 전자 장치는 도 2에 도시된 구성 요소 중 일부를 포함하 지 않을 수 있고, 도 2에 도시되지 않은 구성 요소를 더 포함할 수도 있다. 예를 들어, 전자 장치는 지자 기 센서(geomagnetic sensor), 자이로 센서(gyro sensor), 및 가속도 센서(accelerometer)로 구성되는 센서 모 듈을 더 포함할 수 있다. 다른 실시예에서, 전자 장치는 GPS(Global Positioning System) 센서를 더 포함할 수 있다. 카메라는 현실 공간을 촬영함으로써, 현실 공간 내의 현실 객체에 관한 이미지를 획득하도록 구성된다. 일 실시예에서, 카메라는 렌즈 모듈, 이미지 센서, 및 영상 처리 모듈을 포함할 수 있다. 카메라는 이미지 센서(예를 들어, CMOS 또는 CCD)에 의해 얻어지는 정지 이미지 또는 동영상을 획득할 수 있다. 영상 처 리 모듈은 이미지 센서를 통해 획득된 정지 이미지 또는 동영상을 가공하여, 필요한 정보를 추출하고, 추출된 정보를 프로세서에 전달할 수 있다. 일 실시예에서, 카메라는 서로 다른 FOV(Field Of View)를 갖는 복수의 렌즈 모듈을 포함할 수 있다. 본 개시에서, 'FOV'는 카메라의 렌즈를 통해 한번에 관측할 수 있는 화각 내의 영역을 의미한다. 예를 들어, 카메라는 제1 FOV를 갖는 광각 렌즈 모듈(Wide-angle lens module), 제2 FOV를 갖는 초광각 렌즈 모듈 (Ultra Wide-angle lens module), 및 제3 FOV를 갖는 망원 렌즈 모듈(Telephoto lens)을 포함할 수 있다. 광각 렌즈 모듈, 초광각 렌즈 모듈, 및 망원 렌즈 모듈 각각의 FOV에 관해서는 도 11에서 상세하게 설명하기로 한다. 일 실시예에서, 카메라는 프로세서의 제어에 의해 청소 로봇(2000, 도 1 참조)가 위치하는 실내 공 간을 촬영함으로써, 실내 공간 이미지에 관한 이미지 데이터를 획득할 수 있다. 카메라는 획득된 실내 공 간 이미지의 이미지 데이터를 프로세서에 제공할 수 있다. 통신 인터페이스는 청소 로봇, 서버, 또는 외부 장치(예를 들어, 위치 추적 태그 장치(4100, 도 20 참조) 또는 가전기기와 데이터 통신을 수행하도록 구성된다. 통신 인터페이스는 UWB 통신 모듈, 근 거리 무선 통신 모듈, 및 이동 통신 모듈을 포함할 수 있다. UWB(Ultra Wide Band) 통신 모듈은 3.1GHz 내지 10.6GHz 사이의 초 광대역 주파수 대역을 이용하여 데이 터 송수신을 수행하는 통신 모듈이다. UWB 통신 모듈은 최대 500Mbps 속도로 데이터를 송수신할 수 있다. 일 실시예에서, UWB 통신 모듈은 초 광대역 주파수를 이용하여, 청소 로봇으로부터 청소 로봇 의 위치 정보를 수신할 수 있다. 일 실시예에서, UWB 통신 모듈은 프로세서의 제어에 의해 청소 로봇에 레인징 요청 메시지(Poll message)를 전송하고, 레인징 요청 신호에 응답하여 청소 로봇 으로부터 응답 메시지(Response message)를 수신할 수 있다. UWB 통신 모듈은 레인징 요청 메시지 와 응답 메시지 간의 시간 차이에 관한 정보를 프로세서에 제공할 수 있다. 일 실시예에서, UWB 통신 모듈은 복수의 안테나 엘리먼트를 포함할 수 있다. 복수의 안테나 엘리먼트는 패치 안테나로 구성될 수 있으나, 이에 한정되는 것은 아니다. 근거리 무선 통신 모듈(short-range wireless communication unit)은 무선 통신 네트워크를 이용하여 청 소 로봇, 서버, 또는 외부 장치와 연결하고, 데이터 송수신을 수행하도록 구성된다. 근거리 무선 통신 모 듈은 예를 들어, 와이파이(WiFi), WFD(Wi-Fi Direct) 통신부, 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, NFC(Near Field Communication unit), 지그비(Zigbee) 통신부, Ant+ 통신부, 또는 마이크로 웨이브(μWave) 통신부 중 적어도 하나의 하드웨어 모듈로 구성될 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 근거리 무선 통신 모듈은 BLE 통신부를 이용하여 실내 공간에 포함되는 청소 로봇에 BLE 통신 연결을 수행하기 위한 어드버타이징 신호(advertising signal)을 전송하고, 청소 로봇으로부터 어드버타이징 신호에 응답하는 신호를 수신함에 따라 청소 로봇과 블루투스 채널을 통한 통신 연결을 수 립할 수 있다. 일 실시예에서, 근거리 무선 통신 모듈은 게이트웨이(gateway) 또는 라우터(router)를 통해 외부 서버와 데이터 통신을 수행할 수도 있다. 이동 통신 모듈은 이동 통신망 상에서 기지국, 외부 디바이스, 또는 서버 중 적어도 하나와 무선 신호를 송수신하도록 구성되는 통신 모듈이다. 이동 통신 모듈은 예를 들어, 5G mmWave 통신, 5G Sub 6 통신, LTE(Long Term Evolution) 통신, 또는 3G 이동 통신 중 적어도 하나의 통신 방식을 이용하여 데이터를 송수신할 수 있다. 일 실시예에서, 이동 통신 모듈은 프로세서의 제어에 의해 서버와 데이터를 송수신할 수 있다. 프로세서는 메모리에 저장된 프로그램의 하나 이상의 명령어들(instructions)을 실행할 수 있다. 프로세서는 산술, 로직 및 입출력 연산과 시그널 프로세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서 (microprocessor), 그래픽 프로세서(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices),PLDs(Programmable Logic Devices), 및 FPGAs(Field Programmable Gate Arrays) 중 적어도 하나로 구성될 수 있으나, 이에 한정되는 것은 아니다. 도 2에는 프로세서가 하나의 엘리먼트로 도시되었으나, 이에 한정되는 것은 아니다. 일 실시예에서, 프로 세서는 하나 또는 하나 이상의 복수 개로 구성될 수 있다. 일 실시예에서, 프로세서는 인공 지능(Artificial Intelligence; AI) 학습을 수행하는 AI 프로세서를 포 함할 수 있다. 이 경우, AI 프로세서는 인공지능(AI) 시스템의 학습 네트워크 모델을 이용하여 실내 공간에 존 재하는 객체 또는 장애물의 타입을 인식할 수 있다. AI 프로세서는, 인공 지능(AI)을 위한 전용 하드웨어 칩 형 태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프 로세서(예: GPU)의 일부로 제작되어 전자 장치 내의 프로세서에 탑재될 수 있다. 메모리에는 전자 장치가 청소 로봇과의 인터랙션을 수행하기 위한 애플리케이션을 구성하는 명령어들(instructions)이 저장될 수 있다. 일 실시예에서, 메모리에는 프로세서가 판독할 수 있는 명령어들 및 프로그램 코드(program code)가 저장될 수 있다. 이하의 실시예에서, 프로세서는 메모리 에 저장된 명령어들 또는 프로그램 코드들을 실행함으로써 구현될 수 있다. 메모리는 예를 들어, 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티 미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 또는 광 디스크 중 적어도 하나의 타입의 저장매체로 구성될 수 있다. 일 실시예에서, 전자 장치는 네트워크를 통해 접속 가능하고, 저장 기능을 수행하는 웹 스토리지(web storage) 또는 클라우드 서버를 운영할 수도 있다. 프로세서는 메모리에 저장된 명령어들 또는 프로그램 코드들을 실행함으로써 이하의 실시예들을 구 현할 수 있다. 프로세서는 카메라로부터 실내 공간 이미지에 관한 이미지 데이터를 획득할 수 있다. 일 실시예에 서, 실내 공간 이미지는 청소 로봇이 위치하는 현실 공간에 관한 이미지일 수 있다. 프로세서는 카 메라를 제어하여 청소 로봇이 위치하는 실내 공간을 촬영함으로써, 실내 공간 이미지를 획득할 수 있다. 프로세서는 실내 공간 이미지로부터 청소 로봇을 인식할 수 있다. 일 실시예에서, 프로세서 는 인공지능 모델(Artificial Intelligent model, AI model)을 이용하여 실내 공간 이미지로부터 청소 로봇 을 인식할 수 있다. '인공지능 모델'은 카메라로부터 입력받은 이미지 데이터로부터 객체를 인식하 고, 객체를 타입에 따라 분류(classify)하도록 학습된 심층 신경망 모델을 포함할 수 있다. 인공지능 모델은 메 모리에 저장될 수 있지만, 이에 한정되는 것은 아니다. 일 실시예에서, 인공지능 모델은 외부 서버에 저 장되어 있고, 전자 장치는 서버에 이미지 데이터를 전송하고, 서버의 인공지능 모델로부터 추론 결과인 객체의 타입에 관한 정보를 수신할 수도 있다. 인공지능 모델은 수만 내지 수억장의 이미지를 입력 데이터로 적용하고, 이미지에 포함되는 객체의 라벨값 (label)을 출력 정답값(groundtruth)로 적용하여 학습된(trained) 모델 파라미터로 구성되는 심층 신경망 모델 (Deep Neural Network)을 포함할 수 있다. 심층 신경망 모델은 예를 들어, 컨볼루션 신경망 모델 (Convolutional Neural Network; CNN), 순환 신경망 모델(Recurrent Neural Network; RNN), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심 층 Q-네트워크 (Deep Q-Networks) 중 적어도 하나를 포함할 수 있다. 그러나, 인공지능 모델이 심층 신경망 모 델만을 포함하는 것은 아니고, SVM(Support Vector Machine), 선형 회귀(linear regression), 로지스틱 회귀 (logistic regression), 나이브 베이즈 분류(Naive Bayes), 랜덤 포레스트(random forest), decision tree, 또 는 k-nearest neighbor algorithm 중 적어도 하나로 구성될 수도 있다. 프로세서는 인공지능(AI) 프로세서를 포함할 수 있다. 인공 지능(AI) 프로세서는, 인공 지능(AI)을 위한 전용 하드웨어 칩 형태로 구성될 수도 있고, 범용 프로세서(예를 들어, CPU 또는 애플리케이션 프로세서) 또는 그래픽 전용 프로세서(예를 들어, GPU)의 일부로서 프로세서에 포함될 수 있다. 인공지능 프로세서는 인 공지능 모델을 이용하여, 카메라를 통해 획득된 실내 공간 이미지로부터 청소 로봇을 인식할 수 있 다. 인공지능 프로세서는 인공지능 모델을 이용하여 실내 공간 이미지로부터 인식된 객체의 타입(type)을 분류할 수 있다. 일 실시예에서, 인공지능 모델의 객체 인식 결과는 입력받은 실내 공간 이미지로부터 추론된 객체의 타입 에 관한 적어도 하나의 라벨값 및 적어도 하나의 라벨값에 관한 신뢰도 값을 포함할 수 있다. 여기서, '신뢰도 값'은 실내 공간 이미지로부터 추론된 객체의 타입에 특정 타입으로 추론될 수 있는 확률값을 나타낸다. 인공지 능 프로세서는 인공지능 모델에 의해 출력된 라벨값과 신뢰도 값에 기초하여, 객체의 타입에 관한 정보를 획득 할 수 있다. 예를 들어, 인공지능 프로세서는 실내 공간 이미지로부터 인식된 객체인 청소 로봇의 타입을 가전 제품 중 청소 동작을 수행하는 로봇 청소기로 분류할 수 있다. 프로세서는 디스플레이부 상에 실내 공간 이미지를 디스플레이하고, 인식된 청소 로봇에 대응되는 이미지 상에 마커(marker)를 표시할 수 있다. 프로세서는 통신 인터페이스를 통해 실내 공간 이미지의 인식 결과를 서버에 전송하고, 서버로부터 청소 로봇에 관한 디바이스 정보를 획득할 수 있다. 일 실시예에서, 전자 장치는 근거리 무선 통신 모듈을 통해 외부의 서버와 연결되고, 프로세서는 근거리 무선 통신 모듈을 제어함으로써 서 버에 실내 공간 이미지의 인식 결과 및 사용자 계정 정보(예를 들어, user id)를 전송할 수 있다. 서버는 사용자 계정 정보와 연동되어 등록된 디바이스에 관한 정보를 저장하고 있는 IoT 클라우드 서버일 수 있 다. 서버는 예를 들어, 사용자 계정 정보와 연결되어 등록된 디바이스의 식별 정보(예를 들어, 디바이스 id), 타입, 기능 수행 정보(capability), 및 프로파일 정보 중 적어도 하나를 포함하는 디바이스 정보를 저장할 수 있다. 일 실시예에서, 프로세서는 근거리 무선 통신 모듈을 통해, 전자 장치에 로그인된 사 용자 계정 정보와 연결되어 서버에 등록된 청소 로봇의 디바이스 식별 정보, 타입, 및 기능 수행 정보 중 적어도 하나를 서버로부터 수신할 수 있다. 일 실시예에서, 프로세서는 서버로부터 청소 로봇이 UWB 통신 연결을 수행할 수 있는지 여부에 관한 UWB 통신 기능 정보를 수신할 수 있다. 프로세서는 UWB 통신 모듈을 제어함으로써, 청소 로봇의 위치 정보를 획득할 수 있다. 일 실시예에서, 프로세서는 근거리 무선 통신 모듈의 BLE(Bluetooth Low Energy) 통신 모듈을 이 용하여 실내 공간 내의 청소 로봇과 블루투스 페어링(Bluetooth pairing)을 수립할 수 있다. 프로세서 는 UWB 통신 모듈을 이용하여, 청소 로봇과 UWB 신호를 송수신함으로써, 청소 로봇의 위치 정보를 획득할 수 있다. 프로세서는 TWR(Two Way Ranging) 방식을 이용한 레인징(Ranging)을 수행함으로써, 청소 로봇의 위치 정보를 획득할 수 있다. 프로세서는 예를 들어, SS-TWR(Single Sided Two Way Ranging) 또는 DS- TWR(Double-Sided Two Way Ranging) 중 어느 하나의 방식을 이용하여 레인징 동작을 수행할 수 있다. 일 실시 예에서, 프로세서는 UWB 통신 모듈에 포함된 복수의 UWB 안테나 엘리먼트를 이용하여 청소 로봇 에 레인징 요청 메시지(Poll message)를 전송하고, 레인징 요청 신호에 응답하여 청소 로봇으로부 터 응답 메시지(Response message)를 수신할 수 있다. 프로세서는 레인징 요청 메시지와 응답 메시지 간 의 시간 차이를 이용하는 TOA(Time of Arrival) 또는 TDOA(Time Difference of Arrival) 방법을 통해 청소 로 봇의 위치 정보를 획득할 수 있다. 일 실시예에서, 프로세서는 청소 로봇과 전자 장치 간의 상대적 거리에 관한 정보인 레인징 정보(Ranging) 및 청소 로봇의 방향 정보인 AOA 정보(Arrival of Angle)를 획득할 수 있다. 일 실시예에서, 전자 장치는 가속도 센서(accelerometer), 지자계 센서(magnetometer) 및 GPS 센서를 더 포함할 수 있다. 프로세서는 레인징 정보 및 AOA 정보 뿐만 아니라, 가속도 센서 및 지자계 센서를 이용 하여 측정된 센서 값 및 GPS 센서로부터 획득된 GNSS(Global Navigation Satellite System) 좌표 측정값을 이 용하여 청소 로봇의 위치 정보를 획득할 수도 있다. 가속도 센서 및 지자계 센서의 센서 값 및 GNSS 좌표 측정값을 이용함으로써, 프로세서는 레인징 정보 및 AOA 정보만을 이용하는 경우와 비교하여 정확한 청소 로봇의 위치 정보를 획득할 수 있다. 프로세서가 UWB 신호를 이용하여 청소 로봇의 위치 정보를 획득하는 구체적인 실시예에 대해서는 도 4 내지 도 6에서 상세하게 설명하기로 한다. 프로세서는 서버로부터 수신한 청소 로봇의 디바이스 정보 및 UWB 통신 모듈을 통해 획득한 청소 로봇의 위치 정보에 기초하여, 청소 로봇을 가상 이미지인 증강 현실 이미지와 매핑할 수 있 다. 증강 현실 이미지는 청소 로봇에 대응되는 가상의 이미지로서, 예를 들어 캐릭터, 아바타, 또는 카툰 이미지로 구성될 수 있다. 일 실시예에서, 증강 현실 이미지의 이미지 데이터는 메모리에 저장되고, 프로 세서는 메모리에 저장된 증강 현실 이미지를 불러와서 청소 로봇에 매핑할 수 있으나, 이에한정되는 것은 아니다. 다른 실시예에서, 증강 현실 이미지는 서버에 저장되어 있고, 프로세서는 통신 인 터페이스를 제어함으로써 서버로부터 증강 현실 이미지의 이미지 데이터를 수신할 수도 있다. 그러나, 이 에 한정되는 것은 아니고, 프로세서는 청소 로봇의 형태 및 크기에 기초하여, 청소 로봇에 대응되는 증강 현실 이미지를 생성할 수도 있다. 프로세서는 디스플레이부를 통해 디스플레이되는 실내 공간 이미지 내의 청소 로봇에 대응되 는 이미지 상에 증강 현실 이미지를 오버랩(overlap)하여 디스플레이할 수 있다. 프로세서는 디스플레이 부가 청소 로봇의 이미지와 증강 현실 이미지를 겹쳐서 디스플레이하도록 디스플레이부를 제 어할 수 있다. 다른 실시예에서, 프로세서는 실내 공간 이미지 내의 청소 로봇에 대응되는 이미지 를 증강 현실 이미지로 대체하여 디스플레이하도록 디스플레이부를 제어할 수 있다. 프로세서가 청 소 로봇에 증강 현실 이미지를 매핑하여 디스플레이하는 구체적인 실시예에 대해서는 도 7a 및 도 7b에서 상세하게 설명하기로 한다. 프로세서는 증강 현실 이미지를 통해 청소 로봇과의 인터랙션을 수행할 수 있다. 일 실시예에서, 프로세서는 청소 로봇의 기능 또는 동작을 제어하는 사용자 입력을 수신하기 위한 증강 현실 컨텐 트를 디스플레이부 상에 디스플레이할 수 있다. 예를 들어, 프로세서는 아바타 이미지로 구성된 증 강 현실 이미지와 함께, \"주인님 무엇을 도와드릴까요?\"와 같은 문구 또는 이미지로 구성된 증강 현실 컨텐트를 디스플레이할 수 있다. 일 실시예에서, 프로세서는 UWB 통신 모듈을 통해 기 설정된 레인징 간격(Ranging interval)에 따 라 청소 로봇에 레인징 요청 메시지(Poll message)를 전송하고, 청소 로봇으로부터 레인징 요청 메 시지에 응답하는 응답 메시지(response message)를 수신할 수 있다. 프로세서는 복수의 레인징 요청 메시 지 및 복수의 응답 메시지에 기초하여, 레인징 정보 및 AOA 정보를 획득하고, 획득된 레인징 정보 및 AOA 정보 를 통해 청소 로봇의 위치를 실시간으로 트래킹(tracking)할 수 있다. 트래킹 결과, 청소 로봇의 위치 이동이 감지된 경우 프로세서는 청소 로봇의 위치 이동에 대 응되는 기 설정된 동작을 수행하기 위한 증강 현실 컨텐트를 디스플레이부 상에 디스플레이할 수 있다. 일 실시예에서, 청소 로봇이 전자 장치를 향하는 방향으로 접근하여 청소 로봇과 전자 장치 간의 거리가 기 설정된 임계치 미만으로 감소되는 경우, 프로세서는 청소 로봇의 접근에 대 응되는 동작(예를 들어, 청소 시작 또는 충전 스테이션으로 복귀)을 수행하기 위한 증강 현실 컨텐트를 디스플 레이하도록 디스플레이부를 제어할 수 있다. 프로세서가 청소 로봇의 위치 이동에 따라 증강 현실 컨텐트를 디스플레이하는 구체적인 실시예에 대해서는 도 8에서 상세하게 설명하기로 한다. 청소 로봇의 위치 이동에 따라 실내 공간 이미지에서 청소 로봇이 인식되지 않는 경우, 프로세서 는 카메라의 FOV(Field Of View)를 변경할 수 있다. 일 실시예에서, 프로세서는 청소 로봇 의 위치를 트래킹하고, 청소 로봇의 위치 이동에 의해 변경되는 전자 장치와 청소 로봇 간의 거리 및 방향에 기초하여 카메라에 포함되는 복수의 렌즈 모듈의 동작 모드를 전환함으로써 FOV를 변경하도록 카메라를 제어할 수 있다. 예를 들어, 카메라의 복수의 렌즈 모듈 중 광각 렌즈 모듈을 이용하는 제1 모드로 동작 중에 청소 로봇의 위치 이동으로 인하여 광각 렌즈 모듈의 제1 FOV를 통해서는 청소 로봇을 촬영하지 못할 수 있다. 이 경우, 프로세서는 청소 로봇의 위치 이동 으로 인한 거리 및 방향 정보에 기초하여, 제2 FOV를 갖는 망원 렌즈 모듈로 동작되는 제2 모드로 전환하거나 또는 제3 FOV를 갖는 초광각 렌즈 모듈로 동작되는 제3 모드로 전환할 수 있다. 예를 들어, 광각 렌즈 모듈의 제1 FOV는 83˚이고, 망원 렌즈 모듈의 제2 FOV는 45˚이며, 초광간 렌즈 모듈의 제3 FOV는 123˚일 수 있다. 그러나, 이에 한정되는 것은 아니다. 일 실시예에서, 청소 로봇이 전자 장치로부터 멀어지는 방향으로 이동하는 경우, 프로세서는 청소 로봇을 촬영하기 위하여 광각 렌즈 모듈로 동작되는 제1 모드로부터 제2 FOV를 갖는 망원 렌즈 모듈 로 동작되는 제2 모드로 전환할 수 있다. 다른 실시예에서, 청소 로봇이 전자 장치에 다가오는 방 향으로 이동하는 경우, 프로세서는 인접하게 이동하는 청소 로봇을 촬영하기 위하여 제1 모드로부 터 제3 FOV를 갖는 초광각 렌즈 모듈로 동작되는 제3 모드로 전환할 수 있다. 프로세서가 청소 로봇 의 위치 이동을 트래킹하고, 트래킹된 청소 로봇의 위치에 따른 거리 및 방향에 기초하여 카메라 의 FOV를 변경하는 구체적인 실시예에 대해서는 도 9 내지 도 12b에서 상세하게 설명하기로 한다. 프로세서는 청소 로봇의 위치 이동에 따른 전자 장치와 청소 로봇 간의 거리에 기초하 여, 카메라의 줌 인(zoom in) 또는 줌 아웃(zoom out)을 수행하기 위한 줌 배율을 조절할 수 있다. 일 실시예에서, 청소 로봇이 전자 장치로부터 멀리 이동하는 경우, 프로세서는 카메라의 줌 인 동작을 수행하기 위하여 줌 배율을 높게 조절할 수 있다. 다른 실시예에서, 청소 로봇이 전자 장치 를 향하는 방향으로 인접하게 이동하는 경우, 프로세서는 카메라의 줌 아웃 동작을 수행하기 위하여 줌 배율을 낮게 조절할 수 있다. 프로세서는 청소 로봇의 위치 이동에 따라 조절된 줌 배율에 기초하여, 청소 로봇으로 전송 되는 UWB 신호의 전송 주기를 변경할 수 있다. 일 실시예에서, 프로세서는 청소 로봇으로 전송되는 UWB 신호에 포함되는 레인징 제어 메시지(ranging control message, RCM)의 레인징 간격(ranging interval)을 조절하고, 조절된 레인징 간격에 기초하여 UWB 신호의 전송 주기를 변경할 수 있다. 일 실시예에서, 프로세서 는 UWB 신호에 포함되는 RIU(Ranging Interval Update) 메시지의 듀레이션 옥텟(Duration Octet) 및 스 트라이딩 옥텟(Striding Octet)의 값을 조절함으로써, 청소 로봇에 전송되는 UWB 신호의 전송 주기를 변 경할 수 있다. 예를 들어, 청소 로봇이 전자 장치로부터 멀리 떨어진 위치로 이동하는 경우, 프로 세서는 카메라의 줌 배율을 높은 값으로 증가시키는 줌 인 동작을 수행하고, 증가된 줌 배율에 기 초하여 UWB 신호의 전송 주기를 감소시킬 수 있다. 다른 예를 들어, 청소 로봇이 전자 장치와 인접 한 방향으로 이동하는 경우, 프로세서는 카메라의 줌 배율을 낮은 값으로 감소시키는 줌 아웃을 수 행하고, 감소된 줌 배율에 기초하여 UWB 신호의 전송 주기를 증가시킬 수 있다. 프로세서가 줌 배율에 기 초하여 청소 로봇에 전송되는 UWB 신호의 전송 주기를 조절하는 구체적인 실시예에 대해서는 도 13 내지 도 16에서 상세하게 설명하기로 한다. 전술한 실시예에서, 프로세서는 카메라를 이용하여 청소 로봇을 촬영하여 실내 공간 이미지 를 획득하지만, 본 개시의 실시예가 이에 한정되는 것은 아니다. 다른 실시예에서, 프로세서는 청소 로봇 에 포함된 카메라(2122, 도 20 참조)에 의해 촬영된 실내 공간 이미지를 청소 로봇으로부터 획득할 수 있다. 프로세서는 청소 로봇으로부터 획득된 실내 공간 이미지로부터 적어도 하나의 객체를 인 식할 수 있다. 일 실시예에서, 프로세서는 인공지능 모델로 구성된 객체 인식 모델을 이용하거나, 또는 공지의 이미지 프로세싱 기술을 이용하여 실내 공간 이미지로부터 적어도 하나의 객체를 인식할 수 있다. 여기 서, '적어도 하나의 객체'는 실내 공간 내에 배치된 TV, 에어컨, 냉장고, 또는 전기 오븐 등과 같은 가전기기 뿐만 아니라, 소파, 의자, 식탁 등 가구, 또는 반려견을 포함할 수 있다. 그러나, 이에 한정되는 것은 아니다. 프로세서는 통신 인터페이스를 통해 서버로부터 적어도 하나의 객체에 관한 객체 정보를 획득할 수 있다. 일 실시예에서, 프로세서는 적어도 하나의 객체의 식별 정보(예를 들어, 객체의 id 정보), 타입, 및 기능 수행 정보 중 적어도 하나를 포함하는 객체 정보를 획득할 수 있다. 청소 로봇은 적어도 하나의 객체와 UWB 신호를 송수신함으로써, 적어도 하나의 객체의 위치 정보를 획득 할 수 있다. 프로세서는 통신 인터페이스를 통해 청소 로봇으로부터 적어도 하나의 객체 각 각의 위치 정보를 수신할 수 있다. 프로세서는 적어도 하나의 객체에 관한 객체 정보 및 적어도 하나의 객체의 위치 정보에 기초하여, 적어 도 하나의 객체를 증강 현실 이미지와 매핑할 수 있다. 증강 현실 이미지는 적어도 하나의 객체에 대응되는 가 상의 이미지로서, 예를 들어 캐릭터, 아바타, 또는 아이콘으로 구성될 수 있다. 예를 들어, 적어도 하나의 객체 가 TV인 경우, 증강 현실 이미지는 TV를 나타내는 아이콘일 수 있다. 일 실시예에서, 프로세서는 적어도 하나의 객체에 대응되는 가상 이미지를 생성함으로써, 증강 현실 이미지를 획득할 수 있다. 그러나, 이에 한정 되는 것은 아니고, 프로세서는 통신 인터페이스를 통해 서버 또는 청소 로봇으로부터 증강 현실 이미지의 이미지 데이터를 수신할 수도 있다. 프로세서는 매핑된 증강 현실 이미지를 디스플레이부 상에 디스플레이되는 실내 공간 이미지 내의 적어도 하나의 객체에 대응되는 객체 이미지 상에 오버랩하여 디스플레이할 수 있다. 프로세서가 청소 로 봇을 통해 획득된 실내 공간 이미지로부터 적어도 하나의 객체를 인식하고, 인식된 적어도 하나의 객체에 증강 현실 이미지를 매핑하여 디스플레이하는 구체적인 실시예에 대해서는 도 17 및 도 20에서 상세하게 설명하 기로 한다. 일 실시예에서, 전자 장치는 적어도 하나의 객체가 특정 기능 또는 동작을 수행하도록 제어하는 사용자의 명령을 수신하는 사용자 입력부를 더 포함할 수 있다. 일 실시예에서, 사용자 입력부는 터치 입력을 수신하는 터치 스크린을 포함할 수 있다. 그러나, 이에 한정되지 않으며, 사용자 입력부는 음성 입력을 수신하기 위한 음 성 입력부(예를 들어, 마이크로폰)를 포함할 수 있다. 프로세서는 사용자 입력부를 적어도 하나의 객체에 관한 사용자 입력을 수신하고, 사용자 입력에 대응되는 적어도 하나의 객체의 기능 또는 동작을 식별할 수있다. 프로세서는 통신 인터페이스를 통해 서버로부터 기능 또는 동작에 대응되는 제어 명령을 획 득할 수 있다. 프로세서는 통신 인터페이스를 통해, 서버로부터 획득된 제어 명령을 청소 로봇 에 전송할 수 있다. 청소 로봇은 전자 장치로부터 획득한 제어 명령을 적어도 하나의 객체에 전송함으로써, 적어도 하나의 객체가 제어 명령에 기초한 기능 또는 동작을 수행하도록 제어할 수 있다. 프로세 서가 적어도 하나의 객체의 기능 또는 동작을 수행하기 위한 제어 명령을 전송하는 구체적인 실시예에 대 해서는 도 18 및 도 19에서 상세하게 설명하기로 한다. 디스플레이부는 카메라를 통해 촬영된 실내 공간 이미지 및 프로세서에 의해 매핑된 증강 현 실 이미지를 디스플레이하도록 구성된다. 디스플레이부는 프로세서의 제어에 의해 증강 현실 이미 지 컨텐트를 디스플레이할 수 있다. 일 실시예에서, 디스플레이부는 청소 로봇의 카메라에 의해 촬 영된 실내 공간을 나타내는 실내 공간 이미지를 디스플레이할 수도 있다. 디스플레이부는 예를 들어, 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이 (thin film transistor-liquid crystal display), 유기 발광 다이오드(organic light-emitting diode, OLED), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전기영동 디스플레이 (electrophoretic display) 중에서 적어도 하나를 포함하는 물리적 장치로 구성될 수 있으나, 상기 나열된 예시 로 한정되는 것은 아니다. 일 실시예에서, 디스플레이부는 터치 인터페이스를 포함하는 터치스크린으로 구성될 수도 있다. 디스플레이부가 터치스크린으로 구성되는 경우, 디스플레이부는 터치 패널로 구 성되는 사용자 입력부와 통합되는 구성 요소일 수 있다. 도 3은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시한 흐름도이다. 단계 S310에서, 전자 장치는 카메라를 통해 촬영된 실내 공간 이미지로부터 청소 로봇을 인식한다. 전자 장치는 카메라를 이용하여 청소 로봇(2000, 도 1 참조)가 위치하는 실내 공간을 촬영함으로써, 실내 공간 이미지를 획득할 수 있다. 전자 장치는 인공지능 모델을 이용하여 실내 공간 이미지로부터 청소 로봇 을 인식할 수 있다. '인공지능 모델'은 이미지 데이터로부터 객체를 인식하고, 객체를 타입에 따라 분류 (classify)하도록 학습된 심층 신경망 모델을 포함할 수 있다. 인공지능 모델은 전자 장치의 메모리 (1400, 도 2 참조)에 저장될 수 있지만, 이에 한정되는 것은 아니다. 일 실시예에서, 인공지능 모델은 외부 서 버에 저장되어 있고, 전자 장치는 서버에 이미지 데이터를 전송하고, 서버의 인공지능 모델로부터 추론 결과인 객체의 타입에 관한 정보를 수신할 수도 있다. 인공지능 모델은 수만 내지 수억장의 이미지를 입력 데이터로 적용하고, 이미지에 포함되는 객체의 라벨값 (label)을 출력 정답값(groundtruth)로 적용하여 학습된(trained) 모델 파라미터로 구성되는 심층 신경망 모델 (Deep Neural Network)을 포함할 수 있다. 심층 신경망 모델은 예를 들어, 컨볼루션 신경망 모델 (Convolutional Neural Network; CNN), 순환 신경망 모델(Recurrent Neural Network; RNN), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심 층 Q-네트워크 (Deep Q-Networks) 중 적어도 하나를 포함할 수 있다. 그러나, 인공지능 모델이 심층 신경망 모 델만을 포함하는 것은 아니고, SVM(Support Vector Machine), 선형 회귀(linear regression), 로지스틱 회귀 (logistic regression), 나이브 베이즈 분류(Naive Bayes), 랜덤 포레스트(random forest), decision tree, 또 는 k-nearest neighbor algorithm 중 적어도 하나로 구성될 수도 있다. 전자 장치는 인공지능 모델을 이 용하여 실내 공간 이미지로부터 인식된 객체의 타입(type)을 분류할 수 있다. 일 실시예에서, 전자 장치는 실내 공간 이미지로부터 인식된 객체인 청소 로봇의 타입을 가전 제품 중 청소 동작을 수행하는 로봇 청소기로 분류할 수 있다. 다른 실시예에서, 전자 장치는 공지의 이미지 프로세싱 기술을 이용하여 실내 공간 이미지로부터 청소 로 봇을 인식할 수 있다. 단계 S320에서, 전자 장치는 서버로부터 청소 로봇의 디바이스 정보를 획득한다. 일 실시예에서, 전자 장치는 실내 공간 이미지의 인식 결과 및 사용자 계정 정보(예를 들어, user id)를 서버에 전송하고, 서버로부터 청소 로봇에 관한 디바이스 정보를 획득할 수 있다. 서버는 사용자 계정 정보와 연동되어 등록된 디바이스에 관한 정보를 저장하고 있는 IoT 클라우드 서버일 수 있 다. 서버는 예를 들어, 사용자 계정 정보와 연결되어 등록된 디바이스의 식별 정보(예를 들어, 디바이스 id), 타입, 기능 수행 정보(capability), 및 프로파일 정보 중 적어도 하나를 포함하는 디바이스 정보를 저장할 수있다. 일 실시예에서, 전자 장치는 무선 랜, 와이파이, 또는 블루투스 등을 통해 서버와 연결되고, 서버 로부터 사용자 계정 정보와 연결되어 서버에 등록된 청소 로봇의 디바이스 식별 정보, 타입, 및 기능 수 행 정보 중 적어도 하나를 수신할 수 있다. 일 실시예에서, 전자 장치는 서버로부터 청소 로봇이 UWB 통신 연결 기능을 지원하는지 여부에 관한 UWB 통신 기능 정보를 수신할 수 있다. 단계 S330에서, 전자 장치는 청소 로봇으로부터 수신된 UWB 신호에 기초하여 청소 로봇의 위 치 정보를 획득한다. 일 실시예에서, 전자 장치는 청소 로봇과 UWB 신호를 송수신함으로써, 청소 로봇의 위치 정보를 획득할 수 있다. 일 실시예에서, 전자 장치는 TWR(Two Way Ranging) 방식을 이용한 레인징(Ranging)을 수행함으로써, 청소 로봇의 위치 정보를 획득할 수 있다. 전자 장치는 예를 들어, SS-TWR(Single Sided Two Way Ranging) 또는 DS-TWR(Double-Sided Two Way Ranging) 중 어느 하나 의 방식을 이용하여 레인징 동작을 수행할 수 있다. 일 실시예에서, 전자 장치는 UWB 통신 모듈(1210, 도 2 참조)에 포함된 복수의 UWB 안테나 엘리먼트를 이용하여 청소 로봇에 레인징 요청 메시지(Poll message)를 전송하고, 레인징 요청 신호에 응답하여 청소 로봇으로부터 응답 메시지(Response message)를 수신할 수 있다. 전자 장치는 레인징 요청 메시지와 응답 메시지 간의 시간 차이를 이용하는 TOA(Time of Arrival) 또는 TDOA(Time Difference of Arrival) 방법을 통해 청소 로봇의 위치 정보를 획득할 수 있다. 일 실시예에서, 전자 장치는 청소 로봇과 전자 장치 간의 상대적 거리에 관한 정보인 레인징 정보(Ranging) 및 청소 로봇의 방향 정보인 AOA 정보(Arrival of Angle)를 획득할 수 있다. 단계 S340에서, 전자 장치는 청소 로봇의 디바이스 정보 및 위치 정보에 기초하여, 청소 로봇 을 증강 현실 이미지로 매핑한다. 증강 현실 이미지는 청소 로봇에 대응되는 가상의 이미지로서, 예를 들어 캐릭터, 아바타, 또는 카툰 이미지로 구성될 수 있다. 일 실시예에서, 전자 장치는 내부의 메 모리(1400, 도 2 참조)에 증강 현실 이미지의 이미지 데이터를 저장하고, 메모리로부터 이미지 데이터를 불러와서 청소 로봇에 매핑할 수 있으나, 이에 한정되는 것은 아니다. 다른 실시예에서, 증강 현실 이미 지는 서버에 저장되어 있고, 전자 장치는 서버로부터 증강 현실 이미지의 이미지 데이터를 수신하고, 수 신된 이미지 데이터를 이용하여 청소 로봇에 증강 현실 이미지를 매핑할 수도 있다. 그러나, 이에 한정되 는 것은 아니고, 전자 장치는 청소 로봇의 형태 및 크기에 기초하여, 청소 로봇에 대응되는 증강 현실 이미지를 생성할 수도 있다. 단계 S350에서, 전자 장치는 실내 공간 이미지 내의 청소 로봇에 대응되는 이미지 상에 증강 현실 이미지를 오버랩(overlap)하여 디스플레이한다. 일 실시예에서, 전자 장치는 실내 공간 이미지 내의 청소 로봇에 대응되는 이미지와 증강 현실 이미지를 겹쳐서 디스플레이할 수 있다. 다른 실시예에서, 전자 장 치는 실내 공간 이미지 내의 청소 로봇에 대응되는 이미지를 증강 현실 이미지로 대체하여 디스플 레이할 수 있다. 도 4는 본 개시의 일 실시예에 따른 전자 장치가 UWB 신호에 기초하여 청소 로봇(2000, 도 1 참조)의 위 치 정보를 획득하는 방법을 도시한 흐름도이다. 단계 S410에서, 전자 장치는 청소 로봇과 근거리 무선 통신 연결을 수립한다. 일 실시예에서, 전자 장치는 BLE(Bluetooth Low Energy) 통신 모듈을 이용하여 실내 공간 내의 청소 로봇에 어드버타이 징 신호(advertising signal)를 전송하고, 청소 로봇으로부터 어드버타이징 신호에 응답하는 신호를 수신 할 수 있다. 전자 장치는 청소 로봇으로부터 수신된 신호에 기초하여, 청소 로봇과 블루투스 페어링(Bluetooth pairing)을 수립할 수 있다. 단계 S420에서, 전자 장치는 청소 로봇에 UWB 기능 활성 요청 신호를 전송한다. 'UWB 기능 활성 요 청 신호'는 청소 로봇에 포함된 UWB 통신 모듈을 활성화하여 청소 로봇과의 UWB 통신을 수행하기 위한 신호이다. 전자 장치는 서버로부터 수신된 청소 로봇의 디바이스 정보로부터 청소 로봇(200 0)이 UWB 통신 연결을 수행할 수 있는지 여부에 관한 UWB 기능 정보를 획득할 수 있다. 일 실시예에서, 전자 장 치는 청소 로봇의 디바이스 정보를 통해 UWB 통신 연결 가능 여부가 식별된 경우에만 UWB 기능 활 성 요청 신호를 전송할 수 있다. 일 실시예에서, 전자 장치는 단계 S410에서 근거리 무선 통신 연결이 수립된 이후, 즉시 청소 로봇(200 0)에 UWB 기능 활성 요청 신호를 전송할 수 있다. 그러나 이에 한정되는 것은 아니고, 전자 장치는 UWB 통신이 가능한 범위 내로 청소 로봇이 이동한 이후, 청소 로봇에 UWB 기능 활성 요청 신호를 전송할 수도 있다. 단계 S430에서, 청소 로봇은 UWB 기능을 활성화한다. 일 실시예에서, 청소 로봇은 UWB 기능 활성 요청 신호를 수신함에 따라 UWB 통신 모듈을 활성화하여 UWB 레인징 요청 신호를 수신할 수 있는 상태로 천이할 수 있다. 단계 S440에서, 전자 장치는 청소 로봇에 UWB 레인징 요청 신호(Poll message)를 전송한다. 일 실 시예에서, 전자 장치는 UWB 통신 모듈(1220, 도 2 참조)을 통해 설정된 레인징 간격(Ranging interval) 에 따라 UWB 레인징 요청 메시지(Poll message)를 청소 로봇에 전송할 수 있다. 단계 S450에서, 청소 로봇은 UWB 레인징 응답 신호(Response message)를 전자 장치에 전송한다. 이 경우, 전자 장치는 복수의 안테나 엘리먼트(1211 내지 1213, 도 5 참조)를 이용하여, 청소 로봇(200 0)으로부터 UWB 레인징 응답 신호를 수신할 수 있다. 일 실시예에서, 전자 장치는 청소 로봇에 UWB 레인징 요청 신호를 전송하는 동작 및 청소 로봇 으로부터 UWB 레인징 응답 신호를 수신하는 동작을 복수 회 반복적으로 수행할 수 있다. 단계 S460에서, 전자 장치는 UWB 레인징 요청 신호 및 UWB 레인징 응답 신호에 기초하여, 청소 로봇 의 레인징 정보 및 AOA(Angle Of Arrival) 정보를 획득한다. 일 실시예에서, 전자 장치는 레인징 요청 메시지와 응답 메시지 간의 시간 차이를 이용하는 TOA(Time of Arrival) 또는 TDOA(Time Difference of Arrival) 방법을 통해, 청소 로봇과 전자 장치 간의 상대 적 위치 관계에 관한 정보인 레인징 정보를 획득할 수 있다. 전자 장치가 청소 로봇의 레인징 정보 를 획득하는 구체적인 실시예에 대해서는 도 5를 함께 참조하여 설명한다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 복수의 안테나 엘리먼트(1211 내지 1213)를 포함하는 UWB 통신 모듈을 이용하여 청소 로봇의 위치 정보를 획득하는 동작을 설명하기 위한 도면이다. 도 5를 함께 참조하면, UWB 통신 모듈은 제1 안테나 엘리먼트 내지 제3 안테나 엘리먼트를 포함할 수 있다. 제1 안테나 엘리먼트 내지 제3 안테나 엘리먼트는 패치 안테나(patch antenna)로 구성될 수 있으나, 이에 한정되는 것은 아니다. 도 5에서 UWB 통신 모듈은 3개의 안테나 엘리먼트를 포함 하는 것으로 도시되었으나, UWB 통신 모듈이 포함하는 안테나 엘리먼트의 개수는 도시된 바와 같이 한정 되는 것은 아니다. 전자 장치는 TWR(Two Way Ranging) 방식을 이용한 레인징(Ranging)을 수행함으로써, 청소 로봇의 위치 정보를 획득할 수 있다. 전자 장치의 프로세서(1300, 도 2 참조)는 예를 들어, SS-TWR(Single Sided Two Way Ranging) 또는 DS-TWR(Double-Sided Two Way Ranging) 중 어느 하나의 방식을 이용하여 레인징 동작을 수행할 수 있다. 일 실시예에서, 프로세서는 UWB 통신 모듈을 이용하여 청소 로봇에 레인징 요청 메시지(Poll message)를 전송하고, 제1 안테나 엘리먼트 및 제2 안테나 엘리먼트를 통 해 청소 로봇으로부터 응답 메시지(Response message)를 수신할 수 있다. 프로세서는 레인징 요청 메시지와 응답 메시지 간의 시간 차이를 이용하는 TOA(Time of Arrival) 또는 TDOA(Time Difference of Arrival) 방법을 통해 청소 로봇의 위치 정보를 획득할 수 있다. 프로세서는 예를 들어, UWB 데이 터 프레임에 포함된 R마커(Ranging Marker) 간의 시간 차이를 이용하여 ToF(Time of Flight)를 결정할 수 있다. 전자 장치의 프로세서는 복수의 안테나 엘리먼트(1211 및 1212)를 통해 수신된 응답 신호에 기초하 여, 청소 로봇의 방향 정보인 AOA 정보를 획득할 수 있다. 프로세서가 청소 로봇의 AOA 정보 를 획득하는 구체적인 실시예에 대해서는 도 6을 함께 참조하여 설명한다. 도 6은 본 개시의 일 실시예에 따른 전자 장치가 복수의 안테나 엘리먼트(1211, 1212)를 이용하여 수신된 UWB 신호를 이용하여 청소 로봇의 위치 정보를 획득하는 동작을 설명하기 위한 도면이다. 도 6을 참조하면, UWB 통신 모듈은 제1 안테나 엘리먼트 및 제2 안테나 엘리먼트를 포함할 수 있다. 일 실시예에서, 제1 안테나 엘리먼트 및 제2 안테나 엘리먼트는 패치 안테나로 구성될 수 있으나, 이에 한정되는 것은 아니다. 전자 장치의 메모리(1400, 도 2 참조)에는 제1 안테나 엘리먼트와 제2 안테나 엘리먼트 간의 길이(D)에 관한 정보가 저장되어 있을 수 있다. 전자 장치의 프로세서(1300, 도 2 참조)는 제1 안테나 엘 리먼트 및 제2 안테나 엘리먼트를 통해 각각 수신된 동일 UWB 응답 신호에 대한 수신 시간 차이를 이용하여, 청소 로봇으로부터 전자 장치 간의 도달 거리 차이(△d)를 계산할 수 있다. 일 실시예에 서, 프로세서는 하기의 수식 1에 기초하여, 청소 로봇과 전자 장치 간의 도달 거리 차이(△ d)를 계산할 수 있다. 수학식 1"}
{"patent_id": "10-2021-0164861", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "일 실시예에서, 프로세서는 하기 수식 2에 따라 제1 안테나 엘리먼트과 제2 안테나 엘리먼트(121 2)로부터 각각 수신된 UWB 응답 신호의 위상차(△φ)를 계산할 수 있다. 수학식 2"}
{"patent_id": "10-2021-0164861", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "프로세서는 상기 수식 1에 의해 계산된 도달 거리 차이(△d) 및 상기 수식 2에 의해 계산된 위상차(△ φ)에 기초하여, 청소 로봇의 방향을 나타내는 AOA 정보를 획득할 수 있다. 일 실시예에서, 프로세서 는 하기의 수식 3에 따라, 청소 로봇의 AOA(Arrival of Angle) 값을 계산할 수 있다. 수학식 3"}
{"patent_id": "10-2021-0164861", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "다시 도 4를 참조하면, 단계 S470에서, 전자 장치는 청소 로봇의 레인징 정보 및 AOA 정보에 기초 하여, 전자 장치와 청소 로봇 간의 상대적 거리 및 방향 정보를 획득한다. 일 실시예에서, 전자 장 치는 지자계 센서 및 GPS 센서를 더 포함할 수 있다. 전자 장치는 지자계 센서를 이용하여 지자계 센서 값을 획득하고, GPS 센서를 통해 GNSS(Global Navigation Satellite System) 위치 좌표 측정값을 획득할 수 있다. 전자 장치는 AOA 정보, 지자계 센서 값 및 GNSS 위치 좌표 측정값에 기초하여, 나침반이 가리키 는 북극 방향인 자북(磁北) 방향에 대한 제2 방위각(2nd Azimuth)를 결정할 수 있다. 일 실시예에서, 전자 장치 는 지자계 센서를 통해 획득된 지자계 센서 값의 로 데이터(Raw Data)를 통해 제1 방위각(1st Azimuth)을결정하고, 제1 방위각 및 제2 방위각(2nd Azimuth)에 기초하여 청소 로봇과 전자 장치 간의 상대적 인 위치 정보를 획득할 수 있다. 도 7a는 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇에 매핑된 증강 현실 이미지를 디 스플레이하는 동작을 도시한 도면이다. 도 7a를 참조하면, 전자 장치는 디스플레이부 상에 실내 공간 이미지를 디스플레이할 수 있다. 전자 장치는 실내 공간 이미지 내에 청소 로봇(2000, 도 1 참조)에 대응되는 이미지 상에 증 강 현실 이미지를 오버랩하여 디스플레이할 수 있다. 증강 현실 이미지는 청소 로봇에 매핑된 가상의 이미지로서, 예를 들어 캐릭터, 아바타, 또는 카툰 이미지로 구성될 수 있다. 도 7a에 도시된 실시예에 서, 증강 현실 이미지는 여성의 얼굴을 포함하는 상체 이미지로 구성된 아바타 이미지일 수 있다. 그러나, 증강 현실 이미지가 도 7a에 도시된 바와 같이 한정되는 것은 아니다. 일 실시예에서, 증강 현실 이미지는 청소 로봇을 통해 수행하고자 하는 기능 또는 동작에 관한 사용 자 입력을 수신하기 위한 증강 현실 이미지 컨텐트를 포함할 수 있다. 도 7a에 도시된 실시예에서, 증강 현실 이미지는 \"무엇을 도와드릴까요?\"와 같은 청소 로봇의 기능 또는 동작을 제어하기 위한 사용자 입력 을 수신하기 위한 문구로 된 증강 현실 컨텐트를 포함할 수 있다. 도 7b는 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇에 매핑된 증강 현실 이미지를 디 스플레이하는 동작을 도시한 도면이다. 도 7b를 참조하면, 전자 장치는 디스플레이부 상에 실내 공간 이미지를 디스플레이할 수 있다. 전자 장치는 실내 공간 이미지 내에 청소 로봇 이미지와 함께 증강 현실 이미지를 디스플레이할 수 있다. 일 실시예에서, 전자 장치는 청소 로봇 이미지가 표시되는 위치와 인접한 위 치에 증강 현실 이미지를 디스플레이할 수 있다. 도 7b에 도시된 실시예에서, 전자 장치는 청소 로 봇 이미지에서 청소 로봇 상단에 증강 현실 이미지의 일부가 중첩되도록 증강 현실 이미지를 디 스플레이할 수 있다. 증강 현실 이미지는 청소 로봇에 매핑된 가상의 이미지로서, 예를 들어 캐릭터, 아바타, 또는 카툰 이미지 로 구성될 수 있다. 도 7b에 도시된 실시예에서, 증강 현실 이미지는 여성의 전신을 포함하는 아바타 이미 지일 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 증강 현실 이미지는 청소 로봇을 통해 수행 하고자 하는 기능 또는 동작에 관한 사용자 입력을 수신하기 위한 증강 현실 이미지 컨텐트를 포함할 수 있다. 도 7a 및 도 7b에 도시된 실시예에 따른 전자 장치는 현실 세계(Real world)에 존재하는 청소 로봇(200 0)에 아바타 이미지로 구성되는 증강 현실 이미지(700, 710)를 매핑시킴으로써, 사용자에게 아바타를 통해 현실 세계의 청소 로봇을 제어하는 메타버스에 관한 경험을 제공할 수 있다. 도 8은 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇의 위치 이동에 따른 증강 현실 컨텐트 를 디스플레이하는 동작을 설명하기 위한 도면이다. 도 8을 참조하면, 청소 로봇은 전자 장치와 제1 거리(d1) 만큼 이격된 위치에 배치될 수 있다. 청 소 로봇과 전자 장치 간의 거리가 제1 거리(d1)인 경우, 전자 장치는 청소 로봇에 매 핑된 증강 현실 이미지를 디스플레이할 수 있다. 도 8에 도시된 실시예에서, 증강 현실 이미지는 여 성의 전신을 포함하는 아바타 이미지로 구성될 수 있다. 그러나, 이에 한정되는 것은 아니다. 청소 로봇은 청소 동작을 수행하거나, 충전 스테이션으로 복귀하기 위하여 이동할 수 있다. 전자 장치 는 청소 로봇과 송수신하는 UWB 신호에 기초하여 청소 로봇의 위치를 트래킹하고, 청소 로봇 의 위치 이동을 감지할 수 있다. 전자 장치가 UWB 신호에 기초하여 청소 로봇의 위치 정보를 획득하는 구체적인 방법은 도 4 내지 도 6에서 설명한 것과 동일하므로, 중복되는 설명은 생략한다. 도 8에 도 시된 실시예에서, 청소 로봇은 전자 장치를 향하는 방향으로 이동할 수 있다. 청소 로봇의 위치 이동으로 인하여, 청소 로봇과 전자 장치 간의 거리는 제2 거리(d2)로 변 경될 수 있다. 전자 장치는 청소 로봇의 위치 이동에 대응되는 기 설정된 동작을 수행하기 위한 증 강 현실 컨텐트를 디스플레이할 수 있다. 일 실시예에서, 전자 장치는 청소 로봇의 위치 이동 으로 인하여 청소 로봇과 전자 장치 간의 거리가 제2 거리(d2)로 변경되었음을 감지한 경우, 제2 거리(d2)에 대응되도록 설정된 동작으로서 '청소 시작' 및 '충전 스테이션으로 복귀'를 포함하는 동작들을 실행 시키는 사용자 입력을 수신하기 위한 증강 현실 컨텐트를 디스플레이할 수 있다. 예를 들어, 증강 현실 컨 텐트는 사용자 입력을 수신하기 위한 그래픽 UI일 수 있다. 일 실시예에서, 증강 현실 컨텐트는 그래 픽 UI 뿐만 아니라 \"어떤 동작을 실행할까요?\"와 같은 문구로 구성된 UI를 더 포함할 수 있다. 일 실시예에서, 청소 로봇과 전자 장치 간의 거리가 제2 거리(d2)로 변경되었음을 감지한 경우, 전 자 장치는 증강 현실 이미지를 디스플레이할 수 있다. 증강 현실 이미지는 청소 로봇과 전자 장치 간의 거리가 제1 거리(d1)인 경우와는 달리, 여성의 얼굴로 구성된 아바타 이미지로 구성될 수 있다. 다시 말하면, 전자 장치는 청소 로봇이 전자 장치로 인접한 방향으로 이동함으로써, 상대적인 거리가 줄어드는 경우 여성의 전신을 나타내는 아바타 이미지로 구성된 증강 현실 이미지를 얼굴 만을 포함하는 아바타 이미지인 증강 현실 이미지로 변경하여 디스플레이하고, 증강 현실 이미지와 함께 사용자 입력을 수신하기 위한 그래픽 UI로 구성된 증강 현실 컨텐트를 디스플레이할 수 있다. 도 9는 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇의 위치 이동을 감지하는 동작을 설명하 기 위한 도면이다. 도 9를 참조하면, 전자 장치는 청소 로봇를 촬영함으로써, 실내 공간 이미지를 획득하고, 획 득된 실내 공간 이미지를 디스플레이할 수 있다. 일 실시예에서, 전자 장치는 서로 다른 FOV(Field Of View)를 갖는 복수의 렌즈 모듈을 포함하는 카메라를 포함하고, 카메라에 포함되는 복수의 렌즈 모듈 중 소 정 각도(θ)의 FOV를 갖는 렌즈 모듈을 이용하여 실내 공간 이미지를 획득할 수 있다. 청소 동작 또는 충전 스테이션으로의 이동 등으로 인하여 청소 로봇의 위치는 이동되고, 청소 로봇(200 0)의 위치 이동에 따라 청소 로봇이 카메라의 FOV 내의 범위를 이탈할 수 있다. 도 9에 도시된 실시예에 서, 청소 로봇은 오른쪽 방향으로 이동하고, 소정 각도(θ)의 FOV를 벗어날 수 있다. 이 경우, 실내 공간 이미지 내에서 청소 로봇의 이미지가 포함되어 있지 않게 되고, 전자 장치는 실내 공간 이미 지로부터 청소 로봇을 인식할 수 없게 된다. 전자 장치는 청소 로봇의 위치 이동에 따라 실내 공간 이미지에서 청소 로봇을 인식할 수 없는 경우, 카메라의 FOV를 변경할 수 있다. 일 실시예에서, 전자 장치는 카메라에 포함되는 복수의 렌즈 모듈의 동작 모드를 변경함으로써 카메라의 FOV를 변경할 수 있다. 전자 장치가 청소 로봇의 위치 이동에 따라 카메라의 FOV를 변경하는 구체적인 실시예에 대해서는 도 10 내지 도 12b에서 상세하게 설명 하기로 한다. 도 10은 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇의 위치 이동에 따라 카메라의 FOV(Field Of View)를 변경하는 방법을 도시한 흐름도이다. 단계 S1010에서, 전자 장치는 제1 모드에서 제1 FOV를 갖는 제1 렌즈 모듈을 이용하여 실내 공간 이미지 를 획득한다. 일 실시예에서, 카메라(1100, 도 11 참조)는 복수의 렌즈 모듈(1110, 1120, 1130, 도 11 참조)를 포함할 수 있다. 카메라에 포함되는 복수의 렌즈 모듈(1110, 1120, 1130)에 대해서는 도 11을 참조하여 설명한다. 도 11은 본 개시의 일 실시예에 따른 전자 장치의 카메라에 포함되는 복수의 렌즈 모듈(1110, 1120, 1130)의 FOV를 도시한 도면이다. 도 11을 참조하면, 전자 장치에 포함되는 카메라는 복수의 렌즈 모듈(1110, 1120, 1130)을 포함할 수 있다. 일 실시예에서, 카메라는 초광각 렌즈 모듈, 광각 렌즈 모듈, 및 망원 렌즈 모듈 을 포함할 수 있다. 그러나, 이에 한정되는 것은 아니고, 카메라는 초광각 렌즈 모듈, 광각 렌즈 모듈 및 망원 렌즈 모듈 중 적어도 하나의 렌즈 모듈을 포함하거나, 도면에 도시되지 않은 렌즈 모듈을 더 포함할 수도 있다. 초광각 렌즈 모듈, 광각 렌즈 모듈, 및 망원 렌즈 모듈은 각각 서로 다른 FOV를 갖도록 구성 된다. 본 개시에서, 'FOV'는 카메라의 렌즈 모듈을 통해 한번에 관측할 수 있는 화각 내의 영역을 의미한 다. 일 실시예에서, 초광각 렌즈 모듈은 29˚ 내지 152˚의 범위 내의 약 123˚의 FOV를 갖고, 광각 렌즈 모 듈은 48˚ 내지 131˚의 범위 내의 약 83˚의 FOV를 갖고, 초광각 렌즈 모듈은 67˚ 내지 112˚의 범위 내의 약 45˚의 FOV를 갖도록 구성될 수 있다. 그러나, 전술한 각도 값은 예시적인 것이며, 초광각 렌즈 모듈, 광각 렌즈 모듈, 및 망원 렌즈 모듈의 FOV가 나열된 각도 값으로 한정되는 것은 아니 다. 다시 도 10을 참조하면, 전자 장치는 카메라를 제1 모드로 동작시킴으로써, 제1 FOV를 갖는 광각 렌즈 모듈(1120, 도 11 참조)를 이용하여 실내 공간 이미지를 획득할 수 있다. 단계 S1020에서, 전자 장치는 청소 로봇(2000, 도 9 참조)의 위치 이동을 감지한다. 일 실시예에서, 청소 로봇과 송수신하는 UWB 신호에 기초하여 청소 로봇의 위치를 트래킹하고, 청소 로봇의 위치 이동을 감지할 수 있다. 전자 장치가 UWB 신호에 기초하여 청소 로봇의 위치 정보를 획득하는 구체 적인 방법은 도 4 내지 도 6에서 설명한 것과 동일하므로, 중복되는 설명은 생략한다. 단계 S1030에서, 전자 장치는 청소 로봇의 위치 이동에 따라 실내 공간 이미지에서 청소 로봇 이 인식되는지 판단한다. 일 실시예에서, 전자 장치는 인공지능 모델로 구성된 객체 인식 모델을 이용하여 실내 공간 이미지로부터 청소 로봇을 인식할 수 있다. 다른 실시예에서, 전자 장치는 공 지의 이미지 프로세싱 기술을 이용하여 실내 공간 이미지로부터 청소 로봇을 인식할 수 있다. 청소 로봇의 위치 이동에 따라 실내 공간 이미지로부터 청소 로봇이 인식되는 경우(YES), 전자 장 치는 단계 S1010으로 돌아가서 단계 S1010부터 다시 수행한다. 청소 로봇의 위치 이동에 따라 실내 공간 이미지로부터 청소 로봇이 인식되지 않는 경우(NO), 전자 장치는 청소 로봇의 이동 거리 및 방향에 기초하여 카메라의 FOV를 제1 FOV로부터 제2 FOV로 변경할 것을 결정한다(단계 S1040). 일 실시예에서, 청소 로봇이 전자 장치로부터 멀어지는 방향으 로 이동하는 경우, 전자 장치는 카메라의 FOV를 제1 FOV 보다 더 작은 제2 FOV로 변경하도록 결정 할 수 있다. 다른 실시예에서, 청소 로봇이 전자 장치와 인접하는 방향으로 이동하는 경우, 전자 장치는 카메라의 FOV를 제1 FOV 보다 큰 제2 FOV로 변경하도록 결정할 수 있다. 단계 S1050에서, 전자 장치는 카메라의 동작 모드를 제1 모드에서 제2 모드로 전환함으로써 제2 FOV를 갖는 제2 렌즈 모듈을 이용하여 실내 공간 이미지를 획득한다. 전자 장치가 청소 로봇의 이 동 거리 및 이동 방향에 기초하여 카메라의 동작 모드를 전환함으로써 카메라의 FOV를 변경하는 구 체적인 실시예에 대해서는 도 12a 및 도 12b에서 상세하게 설명하기로 한다. 도 12a는 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇의 위치 이동에 따라 카메라의 FOV를 변경하는 동작을 설명하기 위한 도면이다. 도 12a를 참조하면, 전자 장치는 청소 로봇이 제1 위치(P1)에 있는 경우, 카메라를 제1 모드 로 동작하도록 제어할 수 있다. 일 실시예에서, 카메라는 초광각 렌즈 모듈, 광각 렌즈 모듈 , 및 망원 렌즈 모듈을 포함할 수 있다. 전자 장치의 프로세서(1300, 도 2 참조)는 복수의 렌즈 모듈(1110, 1120, 1130) 중 광각 렌즈 모듈을 이용하는 제1 모드로 동작하도록 카메라를 제어 함으로써, 제1 위치(P1)에 위치하는 청소 로봇을 촬영할 수 있다. 청소 로봇은 청소 동작을 수행하거나, 또는 충전 스테이션으로 복귀하기 위하여 제1 위치(P1)로부터 제2 위치(P2)로 이동할 수 있다. 프로세서는 UWB 통신 모듈(1210, 도 2 참조)을 이용하여 청소 로봇과 UWB 신호를 송수신하고, 송수신된 UWB 신호에 기초하여 청소 로봇의 위치 이동을 감지할 수 있다. 도 12a 에 도시된 실시예에서, 청소 로봇은 전자 장치로부터 멀어지는 방향으로 이동할 수 있다. 예를 들어, 청소 로봇은 실내 공간 내에서 전자 장치의 위치를 기준으로 11시 방향을 따라 전자 장치 와의 상대적 거리가 멀어지도록 이동할 수 있다. 전자 장치의 프로세서는 청소 로봇의 이동 거리 및 방향에 기초하여, 카메라의 동작 모드를 전환할 수 있다. 일 실시예에서, 청소 로봇이 전자 장치와 멀어지는 방향으로 이동함에 따 라 전자 장치와 청소 로봇 간의 상대적 거리가 늘어나는 경우, 프로세서는 복수의 렌즈 모듈 (1110, 1120, 1130) 중 망원 렌즈 모듈을 이용하여 촬영을 수행하는 제2 동작 모드로 전환하도록 카메라 를 제어할 수 있다. 망원 렌즈 모듈은 초광각 렌즈 모듈 및 광각 렌즈 모듈 보다는 좁 은 FOV를 갖지만, 멀리 떨어진 객체도 촬영할 수 있도록 줌 인(zoom in) 기능을 수행할 수 있으므로, 프로세서 는 망원 렌즈 모듈을 이용하는 제2 모드로 카메라의 동작 모드를 전환할 수 있다. 도 12b는 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇의 위치 이동에 따라 카메라의 FOV를 변경하는 동작을 설명하기 위한 도면이다. 도 12b를 참조하면, 전자 장치는 청소 로봇이 제1 위치(P1)에 있는 경우, 카메라를 제1 모드 로 동작하도록 제어할 수 있다. 일 실시예에서, 카메라는 초광각 렌즈 모듈, 광각 렌즈 모듈 , 및 망원 렌즈 모듈을 포함할 수 있다. 전자 장치의 프로세서(1300, 도 2 참조)는 복수의 렌즈 모듈(1110, 1120, 1130) 중 광각 렌즈 모듈을 이용하는 제1 모드로 동작하도록 카메라를 제어 함으로써, 제1 위치(P1)에 위치하는 청소 로봇을 촬영할 수 있다. 청소 로봇은 제1 위치(P1)로부터 제2 위치(P2)로 이동할 수 있다. 도 12a에 도시된 실시예와는 달리, 도 12b의 실시예에서 청소 로봇은 전자 장치를 향하는 방향으로 전자 장치와 인접한 제2 위치 (P2)로 이동할 수 있다. 예를 들어, 청소 로봇은 실내 공간 내에서 전자 장치의 위치를 기준으로 5 시 방향을 따라 전자 장치와의 상대적 거리가 가까워지도록 이동할 수 있다. 전자 장치는 청소 로봇과의 송수신된 UWB 신호에 기초하여 청소 로봇의 위치 이동을 감지할 수 있다. 전자 장치의 프로세서는 청소 로봇의 이동 거리 및 방향에 기초하여, 카메라의 동작 모드를 전환할 수 있다. 일 실시예에서, 청소 로봇이 전자 장치를 향하는 방향으로 이동함에 따라 전자 장치와 청소 로봇 간의 상대적 거리가 줄어드는 경우, 프로세서는 복수의 렌즈 모듈 (1110, 1120, 1130) 중 초광각 렌즈 모듈을 이용하여 촬영을 수행하는 제3 동작 모드로 전환하도록 카메 라를 제어할 수 있다. 초광각 렌즈 모듈은 약 123˚의 FOV를 갖는 렌즈 모듈이므로, 전자 장치 에 인접하게 이동한 청소 로봇도 촬영할 수 있다. 따라서, 프로세서는 카메라의 동작 모드를 광각 렌즈 모듈을 이용하는 제1 모드로부터 초광각 렌즈 모듈을 이용하는 제3 모드로 전환 할 수 있다. 도 12a에 도시된 실시예는 청소 로봇이 전자 장치로부터 멀어지는 방향으로 이동하여 카메라(110 0)가 청소 로봇을 촬영할 수 없는 경우, 전자 장치가 카메라의 FOV를 줄이더라도 줌 인 기능 을 수행할 수 있는 망원 렌즈 모듈로 전환하는 동작과 관련된다. 도 12b에 도시된 실시예는 청소 로봇 이 전자 장치와 가까워지는 방향으로 이동하여 카메라의 FOV 범위에서 벗어남에 따라 청소 로봇을 촬영할 수 없는 경우, 전자 장치가 카메라의 FOV를 넓힐 수 있도록 초광각 렌즈 모듈 로 전환하는 동작과 관련된다. 도 12a 및 도 12b는 모두 청소 로봇의 위치 이동에 따라 카메라 가 청소 로봇을 촬영할 수 없는 경우 카메라의 FOV를 변경함으로써, 전자 장치가 실내 공간 이미지로부터 청소 로봇을 인식하는 인식 정확도를 향상시키는 기술적 효과를 제공한다. 도 13은 본 개시의 일 실시예에 따른 전자 장치가 이동 중인 청소 로봇(2000, 도 9 참조)의 위치를 트래 킹하는 방법을 도시한 흐름도이다. 도 13에 도시된 단계 S1310 내지 S1330은 도 3에 도시된 단계 S330을 구체화한 단계들이다. 도 13의 단계 S1310 은 도 3의 단계 S320이 수행된 이후에 수행된다. 도 13의 단계 S1330이 수행된 이후에는 도 3의 단계 S340이 수 행된다.단계 S1310에서, 전자 장치는 청소 로봇의 위치 이동에 의해 변경되는 전자 장치와 청소 로 봇 간의 거리에 기초하여, 카메라의 줌 배율을 변경한다. 일 실시예에서, 전자 장치는 청소 로봇과 전자 장치 간의 거리가 변경됨에 따라 줌 인(zoom in) 또는 줌 아웃(zoom out)을 수행하도 록 카메라를 제어할 수 있다. 예를 들어, 청소 로봇이 전자 장치로부터 멀어지는 경우, 청소 로봇과 전자 장치 간의 상대적 거리가 증가되므로 전자 장치는 줌 인 동작을 수행하도록 카 메라의 줌 배율을 높게 조절할 수 있다. 예를 들어, 전자 장치는 망원 렌즈 모듈(1130, 도 12a 참 조)을 이용하여 줌 배율을 4배 줌(4x zoom)으로 조절할 수 있다. 다른 예를 들어, 청소 로봇이 전자 장치 와 인접한 위치로 이동하는 경우, 청소 로봇과 전자 장치 간의 상대적 거리가 감소되므로 전 자 장치는 줌 아웃 동작을 수행하도록 카메라의 줌 배율을 낮게 조절할 수 있다. 예를 들어, 전자 장치는 초광각 렌즈 모듈(1130, 도 12b 참조)을 이용하여 줌 배율을 1/2배 줌(1/2x zoom)으로 조절할 수 있다. 그러나, 본 개시의 전자 장치가 청소 로봇의 위치 이동에 따라 카메라의 렌즈의 줌 배율을 자동으로 조절하는 것으로 한정되는 것은 아니다. 다른 실시예에서, 전자 장치는 카메라의 줌 배율 을 조절하는 사용자 입력을 수신하고, 수신된 사용자 입력에 기초하여 카메라의 줌 배율을 조절할 수도 있다. 예를 들어, 전자 장치는 두 개의 손가락을 이용하여 터치 스크린을 터치하는 핀치 인(pinch in) 또 는 핀치 아웃(pinch out) 입력을 수신하고, 핀치 인 입력에 따라 카메라의 줌 배율을 높게 조절하고, 핀 치 아웃 입력에 따라 카메라의 줌 배율을 낮게 조절할 수 있다. 단계 S1320에서, 전자 장치는 조절된 줌 배율에 기초하여, 청소 로봇으로 전송되는 UWB 신호에 포 함되는 레인징 제어 메시지(Ranging Control Message, RCM)의 레인징 간격(Ranging interval)을 조절한다. 일 실시예에서, 청소 로봇에 전송되는 UWB 신호는 레인징 블록(Ranging Block) 구조로 형성되고, 레인징 블 록에는 레인징 간격을 조절하기 위한 레인징 간격 업데이트(Ranging Interval Update, RIU) 메시지가 포함될 수 있다. 전자 장치는 레인징 간격 업데이트 메시지의 설정값을 변경함으로써, 청소 로봇으로 전송되 는 UWB 신호의 레인징 간격을 조절할 수 있다. 예를 들어, 청소 로봇의 이동에 따라 카메라의 줌 배율이 증가된 경우(줌 인 동작), 전자 장치는 줌 인 동작에 기초하여 UWB 신호의 레인징 간격을 짧게 조 절함으로써, 청소 로봇에 전송되는 UWB 신호의 전송 빈도(frequency)를 증가시킬 수 있다. 다른 예를 들 어, 청소 로봇의 이동에 따라 카메라의 줌 배율이 감소된 경우(줌 아웃 동작), 전자 장치는 줌 아웃 동작에 기초하여 UWB 신호의 레인징 간격을 길게 조절함으로써, 청소 로봇에 전송되는 UWB 신호 의 전송 빈도를 감소시킬 수 있다. 전자 장치가 UWB 신호에 포함되는 레인징 제어 메시지(RCM)의 레인징 간격(Ranging interval)을 조절하는 구체적인 실시예에 대해서는 도 14 내지 도 16에서 상세하게 설명하기로 한 다. 단계 S1330에서, 전자 장치는 조절된 레인징 간격에 기초하여, 청소 로봇과 레인징 제어 메시지 (RCM)를 송수신함으로써, 이동 중인 청소 로봇의 위치를 트래킹한다. 예를 들어, 청소 로봇이 전자 장치로부터 멀어지는 방향으로 이동하는 경우, 전자 장치는 카메라의 줌 배율을 증가시키고, 증가된 줌 배율에 기초하여 청소 로봇으로 전송되는 UWB 신호의 레인징 간격을 짧게 조절함으로써 동일 시간 동안 많은 UWB 신호가 청소 로봇에 전송되도록 제어할 수 있다. 다른 예를 들어, 청소 로봇이 전자 장치와 가까워지는 방향으로 이동하는 경우, 전자 장치는 카메라의 줌 배율을 감소시키 고, 감소된 줌 배율에 기초하여 청소 로봇으로 전송되는 UWB 신호의 레인징 간격을 길게 조절함으로써 동 일 시간 동안 적은 수의 UWB 신호가 청소 로봇에 전송되도록 제어할 수 있다. 전술한 방법을 통해, 전자 장치는 이동 중인 청소 로봇의 위치를 실시간으로 트래킹할 수 있고, 이에 따라 청소 로봇의 위치 정보의 정확도가 향상될 수 있다. 도 14는 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇에 전송하는 UWB 신호의 레인징 블록(Ranging Block) 구조를 도시한 도면이다. 도 14를 참조하면, 전자 장치에 의해 청소 로봇으로 전송되는 UWB 신호는 복수의 레인징 라운 드(Ranging Round)를 포함하는 레인징 블록 구조로 형성될 수 있다. 복수의 레인징 라운드 각각은 복수의 레인징 슬롯을 포함할 수 있다. 복수의 레인징 슬롯 각각은 레인징 제어 메시지, 레인징 요청 메시지, 응답 메시지, 및 레 인징 간격 업데이트 메시지를 포함할 수 있다. 레인징 제어 메시지(Ranging Control Message, RCM)는 UWB 신호의 레인징 파라미터(Ranging parameters)를 설정하고, 레인징 과정(Ranging procedure)을 제어하도록 구성되는 신호이다. 레인징 요청 메시지(Poll message)는 객체(예를 들어, 청소 로봇)의 레인징 정보 및 AOA 정보를 획 득하기 위하여 객체에 전송되는 신호이다. 응답 메시지는 레인징 요청 메시지에 응답하여 객체로부터 수신되는 응답 신호이다. 레인징 간격 업데이트 메시지(Ranging Interval Update message, RIU)는 UWB 신호가 전송되는 간격 (interval)을 업데이트하기 위한 신호이다. 레인징 간격 업데이트 메시지는 듀레이션 옥텟 및 스트라 이딩 옥텟을 포함할 수 있다. 듀레이션 옥텟(Duration Octet)은 레인징 블록의 주기(period)를 변경함으로써, UWB 신호의 전송 빈도 (frequency)를 업데이트하는 신호이다. 일 실시예에서, 전자 장치는 듀레이션 옥텟의 데이터를 변경 함으로써, UWB 신호의 레인징 라운드의 간격을 조절할 수 있다. 예를 들어, 카메라(1100, 도 2 참 조)의 줌 배율이 증가되는 줌 인 동작이 수행되는 경우, 전자 장치의 프로세서(1300, 도 2 참조)는 레인 징 간격 업데이트 메시지의 듀레이션 옥텟의 데이터를 조절함으로써, 레인징 라운드의 간격을 좁게 조절할 수 있다. 레인징 라운드의 간격이 좁게 조절됨에 따라, 동일 시간 동안 전송되는 레인징 라운 드의 개수는 증가될 수 있다. 다른 예를 들어, 카메라의 줌 배율이 감소되는 줌 아웃 동작이 수행되 는 경우, 프로세서는 레인징 간격 업데이트 메시지의 듀레이션 옥텟의 데이터를 조절함으로써, 레인징 라운드의 간격을 넓게 조절할 수 있다. 레인징 라운드의 간격이 넓게 조절됨에 따라, 동일 시 간 동안 전송되는 레인징 라운드의 개수는 감소될 수 있다. 스트라이딩 옥텟은 레인징 블록 시퀀스(Ranging Block Sequence)에 포함되는 복수의 레인징 라운드를 포함하는 건너뛰도록(skipping) 제어하는 신호이다. 일 실시예에서, 프로세서는 스트라이딩 옥텟의 값을 통해 레인징 블록 시퀀스에 포함되는 복수의 레인징 라운드 중 스트라이딩 옥텟 이후에 배열되 는 적어도 하나의 레인징 라운드를 건너뛰고 최종 레인징 라운드로 이동하도록 하는 호핑 모드(Hopping mode)를 실행할 수 있다. 프로세서가 듀레이션 옥텟 및 스트라이딩 옥텟의 설정값을 이용하여 레인징 간격을 조절함으로 써, UWB 신호의 전송 주기를 변경하는 구체적인 실시예에 대해서는 도 15 및 도 16에서 상세하게 설명하기 로 한다. 도 15는 본 개시의 일 실시예에 따른 전자 장치가 UWB 신호의 레인징 간격(Ranging interval)을 조 절함으로써 UWB 신호의 전송 주기를 변경하는 동작을 설명하기 위한 도면이다. 도 15를 참조하면, 전자 장치는 복수의 레인징 블록을 포함하는 UWB 신호를 청소 로봇(2000, 도 1 참조)에 전송할 수 있다. 복수의 레인징 블록은 시간 순서에 따라 순차적으로(sequentially) 배열될 수 있다. 복수의 레인징 블록 각각은 레인징 라운드, 듀레이션 옥텟, 스트라이딩 옥텟, 및 최종 레인징 라운드(End Ranging Round, ER)를 포함할 수 있다. N-1 번째 레인징 블록(Ranging Block N-1)은 제1 레인징 라운드 및 제1 듀레이션 옥텟을 포함할 수 있다. 도면에는 도시되지 않았지만, N-1 번째 레인징 블록(Ranging Block N-1)은 최종 레인징 라운드(ER)를 더 포함할 수 있다. 제1 레인징 라운드는 전자 장치의 카메라가 제1 줌 배율로 줌 인 또는 줌 아웃 동작을 수행하 는 경우의 레인징 간격(Ranging Interval)을 가질 수 있다. 카메라가 제1 줌 배율로 동작되는 경우의 레 인징 간격에 관한 정보는 제1 듀레이션 옥텟에 설정값으로서 저장될 수 있다. N번째 레인징 블록(R.B N)의 제2 레인징 라운드가 청소 로봇에 전송되는 시점에, 청소 로봇의 위치 이동 또는 사용자 입력에 의해 카메라의 줌 배율이 제1 줌 배율에서 제2 줌 배율로 변경될 수 있다. 전자 장치의 프로세서(1300, 도 2 참조)는 제2 듀레이션 옥텟의 설정값을 변경함으로써 N번째 레인 징 블록(R.B N) 이후의 레인징 블록에 포함되는 복수의 레인징 라운드의 레인징 간격을 조절할 수 있다. 도 15 에 도시된 실시예에서, 프로세서는 카메라의 줌 배율이 제1 줌 배율로부터 제2 줌 배율로 변경됨에따라 복수의 레인징 라운드의 레인징 간격을 제1 레인징 간격으로부터 제2 레인징 간격으로 조절할 수 있다. 제 2 듀레이션 옥텟의 설정값이 변경됨에 따라 N번째 레인징 블록(R.B N) 이후에 전송되는 복수의 레인징 블 록(R.B N+1, R.B N+2, R.B N+3, R.B N+4, ...)은 제2 레인징 간격을 갖는 레인징 라운드를 포함할 수 있다. 스트라이딩 옥텟은 레인징 블록 내에 포함되는 복수의 레인징 라운드 중 스트라이딩 옥텟 이후에 배 치되는 적어도 하나의 레인징 라운드를 건너뛰는 호핑 모드(Hopping Mode)로 동작되도록 제어한다. 도 15에 도 시된 실시예에서, 프로세서는 스트라이딩 옥텟에 따라 N번째 레인징 블록(R.B N)에 포함된 복수의 레인징 라운드 중 스트라이딩 옥텟 이후에 배치되는 적어도 하나의 레인징 라운드를 모두 건너뛰어 (skipping), 최종 레인징 라운드로 이동시킬 수 있다. 프로세서는 스트라이딩 옥텟을 통해 N번 째 레인징 블록(R.B N)으로부터 N+1 번째 레인징 블록(R.B N+1)로 빠른 천이(Fast transition)를 수행할 수 있 다. 도 15에 도시된 실시예에 따르면, 전자 장치는 카메라의 줌 배율이 변경되는 경우, 제2 듀레이션 옥텟의 설정값을 변경함으로써 복수의 레인징 라운드의 레인징 간격을 조절하고, 스트라이딩 옥텟을 통해 다음 레인징 블록으로의 빠른 천이를 수행할 수 있다. 따라서, 본 개시의 일 실시예에 따른 전자 장치 는 카메라의 줌 배율이 변경됨에 따라 UWB 신호의 전송 주기를 동적으로(dynamically) 조절 가능하고, 이에 따라 동일 시간 동안 전송되는 UWB 신호의 전송 빈도 수를 조절할 수 있다. 전자 장치는 청소 로봇과 전자 장치 간의 거리에 따라 카메라의 줌 배율을 변경하고, 변경된 카메라의 줌 배율에 기초하여 UWB 신호의 전송 주기를 동적으로 조절할 수 있다. 전자 장치 가 카메라의 줌 배율에 기초하여 UWB 신호의 전송 주기를 조절하는 구체적인 실시예에 대해서 는 도 16에서 상세하게 설명하기로 한다. 도 16은 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇의 위치 이동에 따라 UWB 신호의 RIU(Ranging Interval Update)를 변경하는 동작을 설명하기 위한 도면이다. 도 16을 참조하면, 청소 로봇이 전자 장치로부터 제1 레인징 거리(1st Ranging distance) 만큼 이 격된 위치에 배치된 경우, 전자 장치는 제1 UWB 신호를 청소 로봇에 전송할 수 있다. 제1 UWB 신호는 복수의 레인징 블록을 포함하고, 복수의 레인징 블록은 시간 순서에 따라 순차적으로 배열될 수 있 다. 제1 UWB 신호에 포함되는 복수의 레인징 블록 각각은 제1 레인징 간격(1st Ranging Interval)을 갖도 록 구성될 수 있다. 청소 로봇이 제2 레인징 거리(2nd Ranging distance) 만큼 이격된 위치로 이동하는 경우, 전자 장치 는 카메라의 줌 배율을 높게 조절하는 줌 인(zoom-in) 동작을 수행할 수 있다. 그러나, 이에 한정 되는 것은 아니고, 일 실시예에서, 전자 장치는 사용자 입력에 기초하여 카메라의 줌 배율을 조절 할 수도 있다. 예를 들어, 전자 장치는 터치 스크린 상에 디스플레이되는 실내 공간 이미지를 두 개의 손 가락을 이용하여 터치하는 핀치 인(pinch in) 입력을 수신하고, 핀치 인 입력에 기초하여 줌 인 동작을 수행하 도록 카메라를 제어할 수 있다. 카메라의 줌 배율이 조절되는 경우, 전자 장치는 복수의 레인징 블록의 레인징 간격을 조절한 제2 UWB 신호를 청소 로봇에 전송할 수 있다. 일 실시예에서, 제2 UWB 신호는 순차적으로 배열되는 복수의 레인징 블록을 포함하고, 복수의 레인징 블록 각각은 제2 레인징 간격(2nd Ranging Interval)을 갖도록 구성될 수 있다. 도 16에 도시된 실시예에서, 제2 레인징 간격(2nd Ranging Interval)은 제1 레인징 간격(1st Ranging Interval) 보다 작을 수 있다. 도 14 내지 도 16에 도시된 실시예에 따른 전자 장치는 청소 로봇이 제1 레인징 거리 보다 먼 제2 레인징 거리로 이동한 경우, 줌 인 동작을 수행하여 카메라의 줌 배율을 높게 조절하고, 조절된 줌 배율 에 기초하여 복수의 레인징 블록의 레인징 간격을 좁게 조절할 수 있다. 전자 장치는 복수의 레인징 블록 각각의 레인징 간격을 좁게 조절함으로써, UWB 신호의 전송 빈도수를 증가시키고, 이에 따라 동일 시간 동안 더 많은 개수의 UWB 신호를 청소 로봇에 전송할 수 있다. 전자 장치는 UWB 신호의 레인징 간격을 동적 으로 조절함으로써, 이동 중인 청소 로봇의 위치를 실시간으로 트래킹할 수 있고, 청소 로봇의 위치 정보의 정확도를 향상시킬 수 있다. 반대의 경우, 즉 청소 로봇이 전자 장치를 향하는 방향을 따라 전자 장치와 인접한 위치로 이동하는 경우, 전자 장치는 복수의 레인징 블록 각각의 레인징 간격을 넓게 조절함으로써, UWB 신호의 전송 빈도수를 감소시킬 수 있다. 도 17은 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇을 이용하여 실내 공간 내의 적어도 하 나의 객체(4001 내지 4004)를 제어하는 동작을 설명하기 위한 개념도이다. 도 17을 참조하면, 전자 장치는 청소 로봇과 네트워크를 통해서 직접 연결될 수 있다. 전자 장치 는 예를 들어, 무선 랜(Wireless LAN), 와이파이(Wi-Fi), WFD(Wi-Fi Direct), 블루투스(Bluetooth), BLE (Bluetooth Low Energy), 지그비(zigbee), 와이브로(Wireless Broadband Internet, Wibro), 와이맥스(World Interoperability for Microwave Access, WiMAX), SWAP(Shared Wireless Access Protocol), 와이기그 (Wireless Gigabit Allicance, WiGig) 및 RF 통신 중 적어도 하나의 데이터 통신 네트워크를 이용하여 청소 로 봇과 연결되고, 데이터 송수신을 수행할 수 있다. 일 실시예에서, 전자 장치는 청소 로봇과 동일한 사용자 계정 정보(user account)로 연결된 장치일 수 있다. 전자 장치는 설치된 특정 애플리케이션(예를 들어, SmartThings 애플리케이션)을 실행함으로써, 청소 로봇과 인터랙션(interaction)을 수행하고, 청소 로봇을 통해 실내 공간 내의 적어도 하나의 객체(4001 내지 4004)를 제어할 수 있다. 일 실시예에서, 전자 장치는 애플리케이션을 통해 원격 모니터 링 기능(예를 들어, Smart Things 애플리케이션의 '우리 집 AR 홈 어시스턴트' 또는 '우리 집 AR 홈 모니터링' 기능)을 실행함으로써, 청소 로봇에 의해 촬영된 실내 공간 이미지의 이미지 데이터를 획득할 수 있다. 전자 장치는 이미지 데이터 내에 포함되는 적어도 하나의 객체(4001 내지 4004)를 인식할 수 있다. 적어 도 하나의 객체(4001 내지 4004)는 실내 공간 내에 배치되는 가전기기, 물건, 가구, 또는 반려 동물일 수 있으 나, 이에 한정되는 것은 아니다. 도 17에 도시된 실시예에서, 제1 객체는 소파이고, 제2 객체는 테 이블이고, 제3 객체는 반려견 식기이며, 제4 객체는 가전기기(예를 들어, 스마트 TV)일 수 있다. 전자 장치는 디스플레이부를 통해 실내 공간 이미지를 디스플레이할 수 있다. 전자 장치 는 실내 공간 이미지로부터 인식된 적어도 하나의 객체(4001 내지 4004)를 가상의 이미지인 증강 현 실 이미지로 매핑할 수 있다. 증강 현실 이미지는 적어도 하나의 객체(4001 내지 4004)와 매핑되는 가상의 이미지로서, 캐릭터, 아바타, 또는 카툰 이미지로 구성될 수 있다. 그러나, 이에 한정되는 것은 아니고, 증강 현실 이미지는 적어도 하나의 객체(4001 내지 4004)에 대응되는 아이콘일 수도 있다. 도 17에 도시된 실시예에서, 전자 장치는 인식된 적어도 하나의 객체(4001 내지 4004) 중 스마트 TV인 제3 객체를 TV 아이콘인 증강 현실 이미지로 매핑할 수 있다. 전자 장치는 매핑된 증강 현실 이미지를 실내 공간 이미지 내의 적어도 하나의 객체(4001 내지 4004)에 대응되는 객체 이미지 상에 오버랩(overlap)하여 디스플레이할 수 있다. 도 17에 도시된 실시예에서, 전자 장치는 실내 공간 이미지 내에 포함된 제3 객체에 대응되는 이미지 상에 TV 아이콘인 증 강 현실 이미지를 오버랩하여 디스플레이할 수 있다. 전자 장치는 증강 현실 이미지를 통해 적어도 하나의 객체(4001 내지 4004)의 기능 또는 동작을 실 행시키는 사용자 입력을 수신하기 위한 증강 현실 컨텐트를 디스플레이할 수 있다. 도 17에 도시된 실시예 에서, 전자 장치는 스마트 TV인 제3 객체의 기능 또는 동작을 실행시키기 위한 사용자 입력을 수신 하기 위한 증강 현실 컨텐트를 디스플레이할 수 있다. 예를 들어, 증강 현실 컨텐트는 TV 전원 켜기, TV 볼륨 조절, 및 TV 채널 변경을 포함하는 기능 또는 동작을 실행하는 사용자 입력을 수신하기 위한 그래픽 UI 를 포함할 수 있다. 전자 장치는 서버로부터 적어도 하나의 객체(4001 내지 4004)의 기능 또는 동작을 제어하기 위한 제어 명령을 수신하고, 수신된 제어 명령을 청소 로봇에 전송할 수 있다. 청소 로봇은 실내 공간을 이동하면서 적어도 하나의 객체(4001 내지 4004)에 UWB 신호를 전송하고, 적어도 하나의 객체(4001 내지 4004) 로부터 수신된 UWB 응답 신호에 기초하여 적어도 하나의 객체(4001 내지 4004) 각각의 위치 정보를 획득할 수 있다. 청소 로봇은 획득된 위치 정보에 기초하여, 적어도 하나의 객체(4001 내지 4004)에 제어 명령을 전 송함으로써, 적어도 하나의 객체(4001 내지 4004)의 기능 또는 동작을 제어할 수 있다. 도 17에 도시된 실시예 에서, 전자 장치가 증강 현실 컨텐트를 통해 'TV 볼륨 업'이라는 사용자 입력을 수신한 경우, 청소 로봇은 전자 장치로부터 TV 볼륨 업에 대응되는 제어 명령을 수신하고, 수신된 제어 명령을 스마트TV인 제3 객체에 전송함으로써, 제3 객체가 볼륨 업 동작을 수행하도록 제어할 수 있다. 도 17에 도시된 실시예에 따른 전자 장치는 도 1에 도시된 전자 장치의 동작과는 달리, 청소 로봇 을 촬영하지 않고, 청소 로봇에 의해 촬영된 실내 공간 이미지를 획득할 수 있다. 전자 장치 는 청소 로봇으로부터 획득한 실내 공간 이미지로부터 적어도 하나의 객체(4001 내지 4004)를 인식하고, 인식된 적어도 하나의 객체(4001 내지 4004)를 증강 현실 이미지로 매핑하여 디스플레이할 수 있다. 이를 통해 전자 장치는 청소 로봇을 통해 실내 공간(예를 들어, 집, 또는 사무실)을 실시간 으로 모니터링할 수 있다. 일 실시예에서, 전자 장치는 증강 현실 이미지 뿐만 아니라 적어도 하나의 객체(4001 내지 4004)를 제어하기 위한 사용자 입력을 수신하는 증강 현실 컨텐트를 디스플레이할 수 있다. 전자 장치는 적 어도 하나의 객체(4001 내지 4004) 중 사용자 입력에 의해 선택된 객체(도 17에서는 '제3 객체)에 관한 제어 명령을 청소 로봇에 전송함으로써, 선택된 객체의 기능 또는 동작을 제어할 수 있다. 이를 통해 전 자 장치는 실내 공간 모니터링 기능을 수행하는 것에 제한되지 않고, 청소 로봇을 통해 실내 공간 내의 적어도 하나의 객체(4001 내지 4004)의 기능 또는 동작을 제어할 수 있다. 도 18은 본 개시의 일 실시예에 따른 전자 장치, 청소 로봇, 서버, 및 객체의 동작 방 법을 도시한 흐름도이다. 단계 S1810에서, 청소 로봇은 카메라(2122, 도 20 참조)를 이용하여 실내 공간을 촬영함으로써, 실내 공 간 이미지를 획득한다. 단계 S1820에서, 청소 로봇은 실내 공간 이미지의 이미지 데이터를 전자 장치에 전송한다. 일 실시 예에서, 청소 로봇은 근거리 무선 통신 네트워크를 통해 전자 장치와 연결될 수 있다. 청소 로봇 은 예를 들어, 와이파이(WiFi), WFD(Wi-Fi Direct), 블루투스, BLE(Bluetooth Low Energy), NFC(Near Field Communication), 지그비(Zigbee), Ant+, 또는 마이크로 웨이브(μWave) 중 적어도 하나를 포함하는 근거 리 무선 통신 네트워크를 통해 전자 장치와 연결될 수 있다. 청소 로봇은 근거리 무선 통신 네트워 크를 통해 전자 장치에 실내 공간 이미지의 이미지 데이터를 전송할 수 있다. 단계 S1830에서, 전자 장치는 실내 공간 이미지로부터 적어도 하나의 객체를 인식한다. 일 실시예에서, 전자 장치는 인공지능 모델을 이용하여 실내 공간 이미지로부터 적어도 하나의 객체를 인식할 수 있다. '인공지능 모델'은 이미지 데이터로부터 객체를 인식하고, 객체를 타입에 따라 분류(classify)하도록 학습된 심층 신경망 모델을 포함할 수 있다. 인공지능 모델은 전자 장치의 메모리(1400, 도 2 참조)에 저장될 수 있지만, 이에 한정되는 것은 아니다. 일 실시예에서, 인공지능 모델은 외부 서버에 저장되어 있고, 전자 장치 는 서버에 이미지 데이터를 전송하고, 서버의 인공지능 모델로부터 추론 결과인 객체의 타입에 관한 정보 를 수신할 수도 있다. 인공지능 모델은 수만 내지 수억장의 이미지를 입력 데이터로 적용하고, 이미지에 포함되는 객체의 라벨값 (label)을 출력 정답값(groundtruth)로 적용하여 학습된(trained) 모델 파라미터로 구성되는 심층 신경망 모델 (Deep Neural Network)을 포함할 수 있다. 심층 신경망 모델은 예를 들어, 컨볼루션 신경망 모델 (Convolutional Neural Network; CNN), 순환 신경망 모델(Recurrent Neural Network; RNN), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심 층 Q-네트워크 (Deep Q-Networks) 중 적어도 하나를 포함할 수 있다. 그러나, 인공지능 모델이 심층 신경망 모 델만을 포함하는 것은 아니고, SVM(Support Vector Machine), 선형 회귀(linear regression), 로지스틱 회귀 (logistic regression), 나이브 베이즈 분류(Naive Bayes), 랜덤 포레스트(random forest), decision tree, 또 는 k-nearest neighbor algorithm 중 적어도 하나로 구성될 수도 있다. 일 실시예에서, 적어도 하나의 객체는 실내 공간 내에 배치되는 가전기기, 물건, 가구, 또는 반려 동물일 수 있 으나, 이에 한정되는 것은 아니다. 전자 장치는 인공지능 모델을 이용하여 실내 공간 이미지로부터 인식 된 적어도 하나의 객체를 타입 별로 분류할 수 있다. 다른 실시예에서, 전자 장치는 공지의 이미지 프로세싱 기술을 이용하여 실내 공간 이미지로부터 청소 로 봇을 인식할 수 있다. 단계 S1840에서, 전자 장치는 객체 인식 결과를 서버에 전송한다. 전자 장치는 통신 인터페 이스(1200, 도 2 참조)를 통해 서버와 연결되고, 서버에 객체 인식 결과를 전송할 수 있다. 일 실 시예에서, 전자 장치는 실내 공간 이미지로부터 인식된 적어도 하나의 객체의 타입에 관한 정보를 서버 에 전송할 수 있다. 일 실시예에서, 전자 장치는 객체 인식 결과와 함께, 전자 장치에 로그 인 된 사용자 계정 정보(예를 들어, user id)를 서버에 전송할 수 있다. 단계 S1842에서, 서버는 적어도 하나의 객체의 객체 정보를 전자 장치에 전송한다. 서버는 전자 장치로부터 수신된 적어도 하나의 객체에 관한 객체 인식 결과에 응답하여, 적어도 하나의 객체에 관한 객체 정보를 전자 장치에 전송할 수 있다. 일 실시예에서, 서버는 전자 장치의 사용자 계정 정보와 연동되어 서버에 등록되어 있는 디바이스에 관한 객체 정보를 전자 장치에 전송할 수 있다. 일 실시예에서, 객체 정보는 적어도 하나의 객체 각각의 식별 정보(예를 들어, 디바이스 id), 타입, 및 기능 수행 정보(capability) 중 적어도 하나를 포함할 수 있다. 단계 S1850에서, 청소 로봇은 객체에 UWB 신호(Poll message)를 전송한다. 객체는 실내 공 간 내에 위치하는 가전기기, 물건, 가구, 또는 반려 동물일 수 있다. 일 실시예에서, 객체는 청소 로봇 과 BLE 통신을 통해 연결되고, UWB 통신을 수행할 수 있는 가전기기일 수 있다. 예를 들어, 객체는 스마트 TV, 디스플레이를 포함하는 냉장고, 또는 디스플레이를 포함하는 전기 오븐 등 가전기기일 수 있다. 청 소 로봇은 레인징 요청 신호를 객체에 전송할 수 있다. 단계 S1852에서, 객체는 청소 로봇에 UWB 응답 신호(Response message)를 전송한다. 객체는 청소 로봇으로부터 수신한 레인징 요청 신호에 응답하여, UWB 응답 신호를 청소 로봇에 전송할 수 있다. 단계 S1860에서, 청소 로봇은 송수신된 UWB 신호에 기초하여, 객체의 위치 정보를 획득한다. 일 실 시예에서, 청소 로봇은 레인징 요청 메시지와 응답 메시지 간의 시간 차이를 이용하는 TOA(Time of Arrival) 또는 TDOA(Time Difference of Arrival) 방법을 통해 객체의 위치 정보를 획득할 수 있다. 일 실시예에서, 청소 로봇은 객체와 청소 로봇 간의 상대적 거리에 관한 정보인 레인징 정보 (Ranging) 및 객체의 방향 정보인 AOA 정보(Arrival of Angle)를 획득할 수 있다. 단계 S1862에서, 청소 로봇는 객체의 위치 정보를 전자 장치에 전송한다. 단계 S1870에서, 전자 장치는 객체의 객체 정보 및 위치 정보에 기초하여, 객체를 증강 현실 이미지와 매핑한다. 증강 현실 이미지는 객체에 대응되는 가상의 이미지로서, 예를 들어, 캐릭터, 아바타, 또는 카툰 이미지로 구성될 수 있다. 그러나, 이에 한정되는 것은 아니고, 증강 현실 이미지는 객체 를 나타내는 아이콘일 수 있다. 일 실시예에서, 전자 장치는 내부의 메모리(1400, 도 2 참조)에 증 강 현실 이미지의 이미지 데이터를 저장하고, 메모리로부터 이미지 데이터를 불러와서 객체에 매핑 할 수 있으나, 이에 한정되는 것은 아니다. 다른 실시예에서, 증강 현실 이미지는 서버에 저장되어 있고, 전자 장치는 서버로부터 증강 현실 이미지의 이미지 데이터를 수신하고, 수신된 이미지 데이터를 이용하여 객 체에 증강 현실 이미지를 매핑할 수도 있다. 그러나, 이에 한정되는 것은 아니고, 전자 장치는 객 체의 형태 및 크기에 기초하여, 객체에 대응되는 증강 현실 이미지를 생성할 수도 있다. 단계 S1880에서, 전자 장치는 실내 공간 이미지 내의 객체 이미지 상에 증강 현실 이미지를 오버랩 (overlap)하여 디스플레이한다. 일 실시예에서, 전자 장치는 실내 공간 이미지 내의 객체에 대응되 는 객체 이미지와 증강 현실 이미지를 겹쳐서 디스플레이할 수 있다. 다른 실시예에서, 전자 장치는 실내 공간 이미지 내의 객체 이미지를 증강 현실 이미지로 대체하여 디스플레이할 수 있다. 도 19는 본 개시의 일 실시예에 따른 전자 장치, 청소 로봇, 서버, 및 객체의 동작 방 법을 도시한 흐름도이다. 도 19는 전자 장치가 사용자 입력에 기초하여 객체를 제어하기 위한 제어 명령을 청소 로봇 을 통해 객체에 전송하는 실시예를 도시한다. 도 19의 단계 S1910은 도 18에 도시된 단계 S1880이 수행된 이후에 수행될 수 있다. 단계 S1910에서, 전자 장치는 증강 현실 이미지를 통해 객체에 관한 사용자 입력을 수신한다. 일 실시예 에서, 전자 장치는 객체에 매핑되는 증강 현실 이미지를 디스플레이할 뿐 아니라, 객체의 기 능 또는 동작을 실행시키는 사용자 입력을 수신하기 위한 증강 현실 컨텐트를 디스플레이할 수 있다. 예를들어, 객체가 스마트 TV인 경우, 전자 장치는 TV 전원 켜기, TV 볼륨 조절, 및 TV 채널 변경을 포 함하는 기능 또는 동작을 실행시키기 위한 사용자 입력을 수신하는 그래픽 UI로 구성된 증강 현실 컨텐트를 디 스플레이할 수 있다. 전자 장치는 증강 현실 컨텐트를 통해 사용자 입력을 수신할 수 있다. 일 실시예에 서, 전자 장치는 디스플레이부(1500, 도 17 참조)에 디스플레이되는 증강 현실 컨텐트(172, 도 17 참조) 중 어느 하나의 UI를 터치하는 사용자의 터치 입력을 수신할 수 있다. 그러나, 이에 한정되는 것은 아니고, 전 자 장치는 음성 입력부(예를 들어, 마이크로폰 및 음성 입력 수신 모듈)를 더 포함하고, 음성 입력부를 통해 사용자의 음성 명령을 수신할 수 있다. 단계 S1920에서, 전자 장치는 사용자 입력에 대응되는 객체의 기능 또는 동작을 식별한다. 예를 들 어, 증강 현실 컨텐트에 포함되는 복수의 UI 중 'TV 볼륨 업' UI를 선택하는 사용자 입력을 수신한 경우, 전자 장치는 TV 볼륨 업에 대응되는 'TV의 볼륨 상향 조절 기능'을 식별할 수 있다. 단계 S1930에서, 전자 장치는 식별된 기능 또는 동작을 수행하기 위한 제어 명령 요청 신호를 서버(300 0)에 전송한다. 일 실시예에서, 전자 장치는 식별된 기능 또는 동작에 관한 정보와 함께, 기능 또는 동작 에 대응되는 제어 명령을 전송해줄 것을 요청하는 신호를 서버에 전송할 수 있다. '제어 명령'은 동작 수 행 장치인 객체가 기능 또는 동작에 관한 정보 내에 포함되는 세부 동작들을 수행할 수 있도록, 객체 가 판독하고, 실행할 수 있는 명령어를 의미한다. 일 실시예에서, 전자 장치는 제어 명령 요청 신 호와 함께 객체의 객체의 식별 정보 및 타입 정보를 함께 서버에 전송할 수 있다. 단계 S1932에서, 서버는 객체의 기능 또는 동작을 제어하기 위한 제어 명령을 전자 장치에 제공한다. 서버는 전자 장치로부터 수신된 제어 명령 요청 신호에 응답하여 객체의 기능 또 는 동작을 제어하기 위한 제어 명령을 로드(load)하고, 로드된 제어 명령을 전자 장치에 전송할 수 있다. 일 실시예에서, 서버는 객체의 식별 정보 및 타입 정보에 기초하여, 객체를 식별하고, 식별 된 객체의 기능 또는 동작에 관한 제어 명령을 서버 내부의 메모리 또는 저장 장치로부터 불러올 수 있다. 단계 S1940에서, 전자 장치는 객체의 기능 또는 동작을 제어하기 위한 제어 명령을 청소 로봇 에 전송한다. 일 실시예에서, 전자 장치는 서버로부터 수신한 제어 명령을 청소 로봇 에 전송할 수 있다. 전자 장치는 예를 들어, 와이파이(WiFi), WFD(Wi-Fi Direct), 블루투스, BLE(Bluetooth Low Energy), NFC(Near Field Communication), 지그비(Zigbee), Ant+, 또는 마이크로 웨이브(μ Wave) 중 적어도 하나를 포함하는 근거리 무선 통신 네트워크를 통해 청소 로봇에 제어 명령을 전송할 수 있다. 단계 S1950에서, 청소 로봇은 객체의 기능 또는 동작을 제어하기 위한 제어 명령을 객체에 전송한다. 일 실시예에서, 청소 로봇은 객체와 송수신한 UWB 신호를 이용하여 객체의 위치 정보를 획득할 수 있다. 청소 로봇은 획득된 객체의 위치 정보를 이용하여, 실내 공간 내에서 객체 의 위치와 인접한 위치로 이동할 수 있다. 청소 로봇은 객체와 인접한 위치로 이동한 이후, UWB 통신 연결을 통해 객체에 제어 명령을 전송할 수 있다. 단계 S1960에서, 객체는 제어 명령에 따른 기능 또는 동작을 수행한다. 예를 들어, 객체가 스마트 TV이고, 제어 명령이 'TV 볼륨 상향 조절'에 관한 명령어인 경우, 객체는 TV 볼륨을 높게 조절하는 동작 을 수행할 수 있다. 도 20은 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇을 이용하여 촬영된 실내 공간 내의 객 체를 증강 현실 이미지로 매핑하여 디스플레이하는 동작을 설명하기 위한 도면이다. 도 20을 참조하면, 청소 로봇은 카메라를 이용하여 실내 공간을 촬영함으로써, 실내 공간 이미지 를 획득할 수 있다. 전자 장치는 청소 로봇으로부터 실내 공간 이미지에 관한 이미지 데 이터를 수신하고, 실내 공간 이미지를 디스플레이할 수 있다. 전자 장치는 인공지능 모델을 이용하거나, 또는 공지의 이미지 프로세싱 기술을 이용하여 실내 공간 이미 지로부터 객체를 인식할 수 있다. 객체는 예를 들어, 실내 공간 내에 배치되는 가전기기, 물 건, 가구, 또는 반려 동물일 수 있으나, 이에 한정되는 것은 아니다. 도 20에 도시된 실시예에서, 객체는 반려 동물(예를 들어, 강아지)일 수 있다. 전자 장치가 실내 공간 이미지로부터 객체를 인식하는 구체적인 방법은 도 18의 단계 S1830에서 설명한 것과 동일하므로, 중복되는 설명은 생략한다. 일 실시예에서, 전자 장치는 실내 공간 이미지와 함께, 인식된 객체에 관한 객체 이미지(21 0)를 디스플레이할 수 있다. 청소 로봇은 실내 공간을 이동하면서, 실내 공간 내에서 UWB 통신 연결이 가능한 UWB 디바이스와 UWB 신호를 송수신할 수 있다. 도 20에 도시된 실시예에서, UWB 디바이스는 객체에 장착되고, UWB 신호를 송수신할 수 있는 장치이다. UWB 디바이스는 다양한 형태의 통신 장치로 구현될 수 있다. 예를 들 면, UWB 디바이스는 스마트 태그 또는 웨어러블 디바이스 등의 형태로 구현될 수 있다. UWB 디바이스는 UWB 통신 모듈을 포함할 수 있다. UWB 통신 모듈은 UWB 신호를 출력할 수 있다. 일 실시 예에서, UWB 디바이스에 포함된 통신 모듈은 청소 로봇으로부터 레인징 요청 신호(Poll message)를 수신하고, 레인징 요청 신호에 응답하여 응답 메시지(Response message)를 청소 로봇에 전송할 수 있다. UWB 디바이스는 UWB 통신 모듈 이외에 프로세서, 메모리, 배터리 등의 구성요소를 더 포함할 수 있다. 청소 로봇은 UWB 디바이스와 송수신한 UWB 신호에 기초하여, UWB 디바이스의 위치 정보를 획 득할 수 있다. 청소 로봇이 UWB 신호를 이용하여 UWB 디바이스의 위치 정보를 획득하는 구체적인 방법은 도 18의 단계 S1860에서 설명한 방법과 동일하므로, 중복되는 설명은 생략한다. 청소 로봇은 UWB 디바이스의 위치 정보를 전자 장치에 전송할 수 있다. 전자 장치는 청소 로봇으로부터 획득한 UWB 디바이스의 위치 정보에 기초하여, 객체의 위치 정보를 추정할 수 있다. 도 20에 도시된 실시예에서, 반려 동물인 객체가 UWB 디바이스를 목 걸이 형태로 차고 있으므로, 전자 장치는 UWB 디바이스의 위치 정보에 기초하여 객체의 위치 정보를 추정할 수 있다. 전자 장치는 객체의 위치 정보에 기초하여, 객체를 증강 현실 이미지로 매핑하여 디스 플레이할 수 있다. 일 실시예에서, 전자 장치는 실내 공간 이미지 내의 객체 이미지를 객체 에 대응되는 가상의 이미지인 증강 현실 이미지로 매핑하고, 매핑된 증강 현실 이미지를 디스 플레이할 수 있다. 증강 현실 이미지는 객체와 매핑되는 가상의 이미지로서, 캐릭터, 아바타, 또는 카툰 이미지로 구성될 수 있다. 도 20에 도시된 실시예에서, 증강 현실 이미지는 강아지를 나타내는 카툰 이미지일 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 매핑된 증강 현실 이미지를 실내 공 간 이미지 내의 객체 이미지 상에 오버랩(overlap)하여 디스플레이할 수 있다. 일 실시예에서, 전자 장치는 증강 현실 이미지를 구성하는 카툰 이미지에 다양한 모션 또는 문자를 추가하거나, 표정 등 을 다르게 함으로써, 반려 동물의 다양한 행동이나 표정을 재미있게 표현할 수 있다. 도 20에 도시된 실시예에서, 전자 장치는 단순히 실내 공간의 객체를 모니터링하는 데에 한정되지 않고, 강아지 또는 고양이 등과 같은 반려 동물에 대응되는 카툰 이미지로 구성된 증강 현실 이미지를 디 스플레이함으로써, 사용자로 하여금 마치 만화 영화를 보는 듯한 재미를 느낄 수 있게 할 수 있다. 이를 통해 전자 장치는 사용자에게 친근감 및 유희감을 제공할 수 있다. 또한, 도 20에 도시된 실시예에 따른 전자 장치는 실내 공간에 존재하는 현실 객체인 반려 동물을 가상의 카툰 이미지로 구성된 증강 현실 이미지 로 디스플레이함으로써, 사용자에게 메타버스에 관한 경험을 제공할 수 있다. 도 21은 본 개시의 일 실시예에 따른 청소 로봇의 구성 요소를 도시한 블록도이다. 도 21을 참조하면, 청소 로봇은 센서, 출력 인터페이스, 입력 인터페이스, 메모리 , 통신 인터페이스, 청소 어셈블리, 이동 어셈블리, 전력 모듈, 및 프로세서 를 포함할 수 있다. 청소 로봇은 도 21에 도시된 구성요소들의 다양한 조합으로 구성될 수 있으며, 도 21에 도시된 구성요소가 모두 필수적인 구성은 아니다. 센서는 다양한 종류의 센서를 포함할 수 있으며, 예를 들면, 추락 방지 센서, 이미지 센서, 적외선 센서, 초음파 센서, 라이다 센서, 장애물 센서, 또는 주행거리 검출 센서(미도 시) 중 적어도 하나 또는 이들의 조합을 포함할 수 있다. 주행거리 검출 센서는 바퀴의 회전수를 계산하는 회전 검출 센서를 포함할 수 있다. 예를 들면, 회전 검출센서는 모터의 회전수를 검출하도록 설치된 엔코더가 있을 수 있다. 이미지 센서는 구현 예에 따라서 청소 로봇에 여러 개가 배치될 수도 있다. 이미지 센서는 카메라(2122, 도 20 참조)를 포함할 수 있다. 각 센서들의 기능은 그 명칭으로부터 당업자가 직관적으로 추론할 수 있으므로, 구체적인 설명은 생략하기로 한 다. 출력 인터페이스는 디스플레이 또는 스피커 중 적어도 하나 또는 이들의 조합을 포함할 수 있다. 출력 인터페이스는 프로세서에서 생성된 다양한 알림, 메시지, 정보 등을 출력한다. 입력 인터페이스는 키, 터치스크린, 터치패드 등을 포함할 수 있다. 입력 인터페이스 는 사용자 입력을 수신하여 프로세서로 전달한다. 메모리는 청소 로봇의 동작에 필요한 다양한 정보, 데이터, 명령어, 프로그램 등을 저장한다. 메모 리는 휘발성 메모리 또는 비휘발성 메모리 중 적어도 하나 또는 이들의 조합을 포함할 수 있다. 메모리 는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크 로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 또한, 청소 로봇은 인터넷 (internet)상에서 저장 기능을 수행하는 웹 스토리지(web storage) 또는 클라우드 서버를 운영할 수도 있다. 통신 인터페이스는 UWB 통신 모듈, 근거리 통신부 또는 이동 통신부 중 적어도 하나 또는 이들의 조합을 포함할 수 있다. 통신 인터페이스는 다른 장치와 무선으로 통신하기 위한 적어도 하 나의 안테나를 포함할 수 있다. UWB(Ultra Wide Band) 통신 모듈은 3.1GHz 내지 10.6GHz 사이의 초 광대역 주파수 대역을 이용하여 데이 터 송수신을 수행하는 통신 모듈이다. UWB 통신 모듈은 최대 500Mbps 속도로 데이터를 송수신할 수 있다. 일 실시예에서, UWB 통신 모듈은 초 광대역 주파수를 이용하여, 객체(4000, 도 17 및 도 20 참조)로부터 객체의 위치 정보를 수신할 수 있다. 일 실시예에서, UWB 통신 모듈은 프로세서의 제어에 의 해 객체에 레인징 요청 메시지(Poll message)를 전송하고, 레인징 요청 신호에 응답하여 객체로부 터 응답 메시지 (Response message)를 수신할 수 있다. UWB 통신 모듈은 레인징 요청 메시지와 응답 메시 지 간의 시간 차이에 관한 정보를 프로세서에 제공할 수 있다. 근거리 통신부(short-range wireless communication unit)는, 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, 근거리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 지그비 (Zigbee) 통신부, 적외선(IrDA, infrared Data Association) 통신부, WFD(Wi-Fi Direct) 통신부, UWB(ultra wideband) 통신부, Ant+ 통신부, 마이크로 웨이브(uWave) 통신부 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한 다. 여기에서, 무선 신호는, 음성 호 신호, 화상 통화 호 신호 또는 문자/멀티미디어 메시지 송수신에 따른 다 양한 형태의 데이터를 포함할 수 있다. 청소 어셈블리는 본체의 하부에 설치되어 바닥의 먼지를 쓸거나 비산시키고, 쓸거나 비산된 먼지를 흡입 하는 메인 브러시 어셈블리와, 본체의 하부에 설치되되 외부로 돌출 가능하게 설치되고 메인 브러시 어셈블리에 의해 청소되는 영역과 다른 영역의 먼지를 쓸어 메인 브러시 어셈블리로 전달하는 사이드 브러시 어셈블리를 포 함할 수 있다. 또한, 청소 어셈블리는 진공 흡입을 수행하는 진공 청소 모듈 또는 물걸레 청소를 수행하 는 물걸레 청소 모듈을 포함할 수 있다. 이동 어셈블리는 청소 로봇 본체를 이동시킨다. 이동 어셈블리는 청소 로봇을 전진, 후진, 및 회전시키는 한 쌍의 휠, 각 휠에 이동력을 인가하는 휠 모터, 본체의 전방에 설치되어 청소 로봇이 이 동하는 바닥 면의 상태에 따라 회전하여 각도가 변화하는 캐스터 휠 등을 포함할 수 있다. 이동 어셈블리(270 0)는 프로세서의 제어에 따라 청소 로봇을 이동시킨다. 프로세서는 주행 경로를 결정하고, 결정된 주행 경로로 청소 로봇을 이동시키도록 이동 어셈블리를 제어한다. 전력 모듈은 청소 로봇에 전력을 공급한다. 전력 모듈은 배터리, 전력 구동 회로, 컨버터, 변압 회로 등을 포함한다. 전력 모듈은 충전 스테이션에 접속하여 배터리를 충전하고, 배터리에 충전된전력을 청소 로봇의 구성 요소들에 공급한다. 프로세서는 청소 로봇 전반의 동작을 제어한다. 프로세서는 메모리에 저장된 프로그램 을 실행하여, 청소 로봇의 구성 요소들을 제어할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 기계학습 모델의 동작을 수행하는 별도의 NPU를 포함할 수 있 다. 또한, 프로세서는 중앙 처리부(CPU), 그래픽 전용 프로세서(GPU; Graphic Processing Unit) 등을 포 함할 수 있다. 프로세서는 청소 로봇의 동작 모드 제어, 주행 경로 결정 및 제어, 장애물 인식, 청소 동작 제어, 위치 인식, 외부 서버와 통신, 배터리 잔량 모니터링, 배터리 충전 동작 제어 등의 동작을 수행할 수 있다. 본 개시의 다양한 실시예들에서 사용된 용어 '모듈'은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함 할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로와 같은 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부 가 될 수 있다. 예를 들면, 일실시예에 따르면, 모듈은 ASIC(application-specific integrated circuit)의 형 태로 구현될 수 있다."}
{"patent_id": "10-2021-0164861", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "본 개시에서 설명된 전자 장치에 의해 실행되는 프로그램은 하드웨어 구성요소, 소프트웨어 구성요소, 및 /또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 프로그램은 컴퓨터로 읽을 수 있 는 명령어들을 수행할 수 있는 모든 시스템에 의해 수행될 수 있다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령어(instruction), 또는 이들 중 하나 이상 의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어는, 컴퓨터로 읽을 수 있는 저장 매체(computer-readable storage media)에 저장된 명령어를 포함하 는 컴퓨터 프로그램으로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록 매체로는, 예를 들어 마그네틱 저장 매체 (예컨대, ROM(read-only memory), RAM(random-access memory), 플로피 디스크, 하드 디스크 등) 및 광학적 판 독 매체(예컨대, 시디롬(CD-ROM), 디브이디(DVD: Digital Versatile Disc)) 등이 있다. 컴퓨터가 읽을 수 있 는 기록 매체는 네트워크로 연결된 컴퓨터 시스템들에 분산되어, 분산 방식으로 컴퓨터가 판독 가능한 코드가 저장되고 실행될 수 있다. 매체는 컴퓨터에 의해 판독가능하며, 메모리에 저장되고, 프로세서에서 실행될 수 있다. 컴퓨터로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비 일시적'은 저장매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매 체에 반영구적 또는 임시적으로 저장되는 경우를 구분하지 않는다. 예를 들어, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 또한, 본 명세서에 개시된 실시예들에 따른 프로그램은 컴퓨터 프로그램 제품(computer program product)에 포 함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 소프트웨어 프로그램, 소프트웨어 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체 를 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 전자 장치의 제조사 또는 전자 마켓(예를 들어, 삼성 갤럭시 스토어)을 통해 전자적으로 배포되는 소프트웨어 프로그램 형태의 상품(예를 들어, 다운로드 가능 한 애플리케이션(downloadable application))을 포함할 수 있다. 전자적 배포를 위하여, 소프트웨어 프로그램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저장 매체는 전자 장치의 제조사의 서버, 전자 마켓의 서버, 또는 소프트웨어 프로그램을 임시적으로 저장하는 중계 서버의 저장매체가 될 수 있다. 컴퓨터 프로그램 제품은, 전자 장치, 청소 로봇, 및/또는 서버(3000, 도 17 내지 도 19 참조)로 구 성되는 시스템에서, 서버의 저장매체 또는 전자 장치의 저장매체를 포함할 수 있다. 또는, 전자 장치과 통신 연결되는 제3 장치(예를 들어, 청소 로봇)가 존재하는 경우, 컴퓨터 프로그램 제품은 제3 장치의 저장매체를 포함할 수 있다. 또는, 컴퓨터 프로그램 제품은 전자 장치으로부터 전자 장치 또는 제3 장치로 전송되거나, 제3 장치로부터 전자 장치로 전송되는 소프트웨어 프로그램 자체를 포함할 수 있다. 이 경우, 전자 장치, 청소 로봇, 및 제3 장치 중 하나가 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방법을 수행할 수 있다. 또는, 전자 장치, 청소 로봇, 및 제3 장치 중 둘 이상이 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방법을 분산하여 실시할 수 있다. 예를 들면, 전자 장치이 메모리(1400, 도 2 참조)에 저장된 컴퓨터 프로그램 제품을 실행하여, 전자 장치 와 통신 연결된 타 전자 장치(예를 들어, 청소 로봇)가 개시된 실시예들에 따른 방법을 수행하도록 제어할 수 있다. 또 다른 예로, 제3 장치가 컴퓨터 프로그램 제품을 실행하여, 제3 장치와 통신 연결된 전자 장치가 개시된 실시 예에 따른 방법을 수행하도록 제어할 수 있다. 제3 장치가 컴퓨터 프로그램 제품을 실행하는 경우, 제3 장치는 전자 장치으로부터 컴퓨터 프로그램 제품 을 다운로드하고, 다운로드된 컴퓨터 프로그램 제품을 실행할 수 있다. 또는, 제3 장치는 프리로드(pre-load)된 상태로 제공된 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방법을 수행할 수도 있다."}
{"patent_id": "10-2021-0164861", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 컴퓨터 시스템 또는 모듈 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7a 도면7b 도면8 도면9 도면10 도면11 도면12a 도면12b 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21"}
{"patent_id": "10-2021-0164861", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시는, 다음의 자세한 설명과 그에 수반되는 도면들의 결합으로 쉽게 이해될 수 있으며, 참조 번호 (reference numerals)들은 구조적 구성요소(structural elements)를 의미한다. 도 1은 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇과의 인터랙션을 수행하는 동작을 도시한 개념도이다. 도 2는 본 개시의 일 실시예에 따른 전자 장치의 구성 요소를 도시한 블록도이다. 도 3은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시한 흐름도이다. 도 4는 본 개시의 일 실시예에 따른 전자 장치가 UWB 신호에 기초하여 청소 로봇의 위치 정보를 획득하는 방법 을 도시한 흐름도이다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 복수의 안테나 엘리먼트를 포함하는 UWB 통신 모듈을 이용하여 청소 로봇의 위치 정보를 획득하는 동작을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시예에 따른 전자 장치가 복수의 안테나 엘리먼트를 이용하여 수신된 UWB 신호를 이용하 여 청소 로봇의 위치 정보를 획득하는 동작을 설명하기 위한 도면이다. 도 7a는 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇에 매핑된 증강 현실 이미지를 디스플레이하는 동작 을 도시한 도면이다. 도 7b는 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇에 매핑된 증강 현실 이미지를 디스플레이하는 동작 을 도시한 도면이다. 도 8은 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇의 위치 이동에 따른 증강 현실 컨텐트를 디스플레이 하는 동작을 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇의 위치 이동을 감지하는 동작을 설명하기 위한 도면 이다. 도 10은 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇의 위치 이동에 따라 카메라의 FOV(Field Of View) 를 변경하는 방법을 도시한 흐름도이다. 도 11은 본 개시의 일 실시예에 따른 전자 장치에 포함되는 복수의 카메라 모듈의 FOV를 도시한 도면이다. 도 12a는 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇의 위치 이동에 따라 카메라의 FOV를 변경하는 동 작을 설명하기 위한 도면이다. 도 12b는 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇의 위치 이동에 따라 카메라의 FOV를 변경하는 동 작을 설명하기 위한 도면이다. 도 13은 본 개시의 일 실시예에 따른 전자 장치가 이동 중인 청소 로봇의 위치를 트래킹하는 방법을 도시한 흐 름도이다. 도 14는 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇에 전송하는 UWB 신호의 레인징 블록(Ranging Block) 구조를 도시한 도면이다. 도 15는 본 개시의 일 실시예에 따른 전자 장치가 UWB 신호의 레인징 간격(ranging interval)을 조절함으로써 UWB 신호의 전송 주기를 변경하는 동작을 설명하기 위한 도면이다. 도 16은 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇의 위치 이동에 따라 UWB 신호의 RIU(Ranging Interval Update)를 변경하는 동작을 설명하기 위한 도면이다. 도 17은 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇을 이용하여 실내 공간 내의 적어도 하나의 객체를 제어하는 동작을 설명하기 위한 개념도이다. 도 18은 본 개시의 일 실시예에 따른 전자 장치, 청소 로봇, 서버, 및 객체의 동작 방법을 도시한 흐름도이다. 도 19는 본 개시의 일 실시예에 따른 전자 장치, 청소 로봇, 서버, 및 객체의 동작 방법을 도시한 흐름도이다. 도 20은 본 개시의 일 실시예에 따른 전자 장치가 청소 로봇을 이용하여 촬영된 실내 공간 내의 객체를 증강 현 실 이미지로 매핑하여 디스플레이하는 동작을 설명하기 위한 도면이다. 도 21은 본 개시의 일 실시예에 따른 청소 로봇의 구성 요소를 도시한 블록도이다."}
