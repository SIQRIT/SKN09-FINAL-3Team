{"patent_id": "10-2024-7032742", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0154076", "출원번호": "10-2024-7032742", "발명의 명칭": "적은 훈련 지연과 통신 오버헤드를 갖는 머신 러닝을 위한 장치 및 방법", "출원인": "후아웨이 테크놀러지 컴퍼니 리미티드", "발명자": "탕 하오"}}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "무선 통신 네트워크에서 인공지능 또는 머신 러닝(AI/ML) 데이터 전송을 위한 방법으로서,제1 디바이스의 AI/ML 모델 훈련 능력을 결정하는 단계- 상기 AI/ML 모델 훈련 능력은 상기 무선 통신 네트워크에서 적어도 제2 디바이스와의 AI/ML 모델 훈련 프로세스에 기여하여 참여할 수 있는 상기 제1 디바이스의 능력을 나타내고, 상기 AI/ML 모델 훈련 능력은,i) 상기 제1 디바이스의 현재 처리 능력,ii) 상기 제1 디바이스에서 상기 AI/ML 모델 훈련 프로세스에 사용할 수 있는 훈련 데이터의 현재 양, iii) 상기 AI/ML 모델 훈련 프로세스를 위한 훈련 데이터를 수집하는 상기 제1 디바이스의 센싱 능력중 적어도 하나에 기초하여 결정됨 -와,상기 AI/ML 모델 훈련 능력을 상기 제2 디바이스로 전송하는 단계를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있에서, 상기 제1 디바이스의 AI/ML 모델 훈련 능력을 결정하는 단계는 미리 정의되거나 구성된 AI/ML 모델 훈련 능력타입의 계층 구조 중에서 AI/ML 모델 훈련 능력 타입을 선택하는 단계를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 AI/ML 모델 훈련 능력을 상기 제2 디바이스로 전송하는 단계는, 상기 미리 정의되거나 구성된 AI/ML 모델훈련 능력 타입의 계층 구조 중에서 선택된 AI/ML 모델 훈련 능력 타입에 대응하는 인덱스를 전송하는 단계를포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,상기 AI/ML 모델 훈련 능력을 상기 제2 디바이스로 전송하는 단계는, 상기 제1 디바이스의 AI/ML 모델 훈련 능력이 변경되었다고 판단하는 단계와,상기 제1 디바이스의 AI/ML 모델 훈련 능력이 변경되었다고 판단한 후 상기 변경된 AI/ML 모델 훈련 능력을 상기 제2 디바이스로 전송하는 단계를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 제1 디바이스의 AI/ML 모델 훈련 능력이 변경되었다고 판단하는 단계는,i) 상기 제1 디바이스의 현재 처리 능력,공개특허 10-2024-0154076-3-ii) 상기 제1 디바이스에서 상기 AI/ML 모델 훈련 프로세스에 사용 가능한 훈련 데이터의 현재 양, iii) 상기 AI/ML 모델 훈련 프로세스에 대한 훈련 데이터를 수집하는 상기 제1 디바이스의 센싱 용량중 적어도 하나 이상의 변화를 식별하는 단계를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제3항 중 어느 한 항에 있어서, 상기 AI/ML 모델 훈련 능력을 상기 제2 디바이스로 전송하는 단계는 상기 AI/ML 모델 학습 프로세스 중에 상기제2 디바이스로부터 데이터 또는 제어 정보를 수신한 후에 이루어지는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 AI/ML 모델 학습 프로세스 중에 상기 제2 디바이스로부터 데이터 또는 제어 정보를 수신한 후에 상기AI/ML 모델 훈련 능력을 상기 제2 디바이스로 전송하는 단계는,상기 제1 디바이스에 의해 사용될 물리적 업링크 제어 채널(PUCCH) 자원을 식별하는 제어 시그널링을 상기 제2디바이스로부터 수신하는 단계와,상기 PUCCH 자원을 이용하여 상기 AI/ML 모델 훈련 능력을 상기 제2 디바이스로 전송하는 단계를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제2 디바이스로부터, 상기 제1 디바이스에 의해 사용될 PUCCH 자원을 식별하는 제어 시그널링을 수신하는단계는, 상기 제2 디바이스로부터, 상기 AI/ML 모델 훈련 프로세스 동안 상기 제2 디바이스로부터의 상기 데이터 또는제어 정보의 다운링크 전송을 스케줄링하는 다운링크 제어 정보(DCI)를 수신하는 단계를 포함하되, 상기 DCI는상기 제1 디바이스에 의해 사용될 상기 PUCCH 자원을 나타내는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항 내지 제8항 어느 한 항에 있어서, 상기 제2 디바이스로부터 수신되는 상기 데이터 또는 제어 정보는 상기 AI/ML 모델 훈련 프로세스를 위한 상기제2 디바이스로부터의 AI/ML 모델 업데이트 정보를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항 내지 제9항 중 어느 한 항에 있어서,상기 제2 디바이스로부터, 상기 AI/ML 모델 훈련 프로세스의 반복에 대해, 상기 제1 디바이스가 상기 반복에 참여할지 여부를 결정하기 위한 규칙으로 상기 제1 디바이스를 구성하는 제어 시그널링을 수신하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2024-0154076-4-제10항에 있어서,상기 구성된 규칙에 따라 상기 AI/ML 모델 훈련 프로세스의 하나 이상의 반복에 참여하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항 또는 제11항에 있어서,상기 AI/ML 모델 훈련 프로세스의 반복이 반복 식별자(ID)의 각 값과 연관되어 상기 반복 ID의 각 값이 후속 반복마다 1씩 증가되고,상기 제어 시그널링은 주어진 반복과 연관된 상기 반복 ID의 각 값에 따라 상기 주어진 반복에 선택적으로 참여하도록 상기 제1 디바이스를 구성하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항 내지 제12항 어느 한 항에 있어서, 상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해, 상기 제2 디바이스로부터, 상기 주어진 반복과 관련된반복 ID의 값을 나타내는 제어 정보를 수신하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제2항 또는 제3항에 있어서, 상기 AI/ML 모델 학습 프로세스의 주어진 반복에 대해, 상기 제2 디바이스로부터, 상기 주어진 반복에참여하는, 미리 정의되거나 구성된 AI/ML 모델 훈련 능역 타입의 계층 구조 중에서의 적어도 하나의 AI/ML 모델훈련 능력 타입을 나타내는 제어 정보를 수신하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항 내지 제9항 어느 한 항에 있어서, 상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대한 데이터 또는 제어 정보가 상기 제2 디바이스로부터 전송되는 것은 제1 다운링크 제어 정보(DCI)에 의해 스케줄링되고, 상기 제1 DCI의 순환 중복 검사(CRC) 값이 제1무선 네트워크 임시 식별자(RNTI)와 스크램블링되고, 상기 방법은,제1 모니터링 주기에 따라 상기 제1 DCI를 모니터링하도록 상기 제1 디바이스를 구성하는 제어 시그널을 상기제2 디바이스로부터 수신하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 제2 디바이스로부터 다른 데이터 또는 제어 정보가 전송되는 것은 제2 DCI에 의해 스케줄링되고, 상기 제2DCI의 CRC 값이 상기 제1 RNTI와 다른 제2 RNTI와 스크램블링되고, 상기 방법은,상기 제2 디바이스로부터, 제2 모니터링 주기에 따라 상기 제2 DCI를 모니터링하도록 상기 제1 디바이스를 구성하는 디바이스별 제어 시그널링을 수신하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "공개특허 10-2024-0154076-5-제16항에 있어서, 상기 제2 모니터링 주기는 상기 제1 모니터링 주기와 별도로 구성되는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항 내지 제17항 어느 한 항에 있어서, 상기 제1 RNTI는 셀 RNTI(C-RNTI)와는 다른,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제1항 내지 제11항 어느 한 항에 있어서, 상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해, 로컬 AI/ML 모델 업데이트 정보를 상기 제2 디바이스로전송하는 단계를 더 포함하되, 상기 로컬 AI/ML 모델 업데이트 정보는 상기 제1 디바이스에서의 로컬 AI/ML 모델의 훈련에 기초한 AI/ML 모델 파라미터 업데이트를 포함하고, 상기 제1 디바이스에서의 상기 로컬 AI/ML 모델의 훈련은 상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해 상기 제2 디바이스로부터 수신된 데이터 또는제어 정보에 기초하고, 상기 로컬 AI/ML 모델 업데이트 정보는 상기 제1 디바이스가 상기 제2 디바이스로부터데이터 또는 제어 정보를 수신한 상기 주어진 반복과 연관된 반복 ID의 값을 나타내는 정보를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항 내지 제11항 어느 한 항에 있어서, 상기 AI/ML 모델 훈련 프로세스에 참여하기 위한 요청을 상기 제2 디바이스로 전송하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서, 상기 AI/ML 모델 훈련 프로세스의 반복이 반복 식별자(ID)의 각 값과 연관되어 상기 반복 ID의 각각의 값이 후속 반복마다 1씩 증가되고, 상기 방법은,상기 AI/ML 모델 훈련 프로세스의 현재 반복과 연관된 반복 ID의 값을 나타내는 전송을 상기 제2 디바이스로부터 수신하는 단계를 더 포함하되,상기 AI/ML 모델 훈련 프로세스에 참여하기 위한 요청을 전송하는 단계는 상기 /ML 모델 훈련 프로세스의 현재반복과 연관된 상기 반복 ID의 값에 기초하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제20항에 있어서, 상기 AI/ML 모델 학습 프로세스에 참여하기 위한 요청을 상기 제2 디바이스로 전송하는 단계는,상기 제1 디바이스의 AI/ML 모델 훈련 능력이 변경되었다고 판단한 후, 상기 AI/ML 모델 학습 프로세스에 참여하기 위한 요청을 상기 제2 디바이스로 전송하는 단계를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제20항 내지 제22항 어느 한 항에 있어서, 공개특허 10-2024-0154076-6-상기 제1 디바이스에서 로컬 AI/ML 모델의 파라미터의 부분적 서브세트를 포함하는 부분적 AI/ML 모델을 훈련하도록 상기 제1 디바이스를 구성하는 제어 시그널링을 상기 제2 디바이스로부터 수신하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 로컬 AI/ML 모델 업데이트 정보를 상기 제2 디바이스로 전송하는 단계를 더 포함하되, 상기 로컬 AI/ML 모델 업데이트 정보는 상기 부분적 AI/ML 모델의 훈련에 기반한 상기 파라미터의 부분적 서브세트에 대한 AI/ML 모델파라미터 업데이트를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제1항 내지 제24항 어느 한 항에 있어서, 상기 AI/ML 모델 훈련 프로세스에 참여하지 않도록 상기 제1 디바이스를 구성하는 제어 시그널링을 상기 제2 디바이스로부터 수신하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제1항 내지 제24항 어느 한 항에 있어서, 상기 제1 디바이스가 상기 AI/ML 모델 훈련 프로세스에 참여하지 않기 위한 요청을 상기 제2 디바이스로 전송하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제1항 내지 제18항 어느 한 항에 있어서, 상기 AI/ML 모델 훈련 프로세스의 주어진 반복을 위해, 로컬 AI/ML 모델 업데이트 정보를 상기 제2 디바이스로전송하는 단계를 더 포함하되, 상기 로컬 AI/ML 모델 업데이트 정보는 상기 제1 디바이스에서의 로컬 AI/ML 모델의 훈련에 기초하고 상기 제1 디바이스에서 상기 로컬 AI/ML 모델을 특징짓는 모든 AI/ML 모델 파라미터보다적은 부분적 서브세트에 대해서만 AI/ML 모델 파라미터 업데이트를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제27항에 있어서, 상기 로컬 AI/ML 모델 업데이트 정보는,상기 제1 디바이스에서 상기 로컬 AI/ML 모델을 특징짓는 모든 AI/ML 모델 파라미터보다 적은 부분적 서브세트에 대한 AI/ML 모델 파라미터 업데이트 값을 포함하는 값 정보, 및상기 로컬 AI/ML 모델의 대응하는 AI/ML 모델 파라미터에 상기 AI/ML 모델 업데이트 값을 매핑하는 할당 정보를포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제28항에 있어서, 상기 AI/ML 모델 파라미터 업데이트 값은 상기 값 정보에 미리 정의되거나 구성된 순서로 배열되는,공개특허 10-2024-0154076-7-방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제29항에 있어서, 상기 할당 정보는 상기 로컬 AI/ML 모델의 파라미터 그룹(PG)을 상기 값 정보 내의 대응하는 AI/ML 모델 파라미터 업데이트 값에 매핑하는 비트맵을 포함하고, 각 PG는 상기 로컬 AI/ML 모델의 연속적인 파라미터 세트인,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제30항에 있어서, 각 PG의 크기는 상기 제2 디바이스에 의해 미리 정의되거나 구성되는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제29항에 있어서, 상기 할당 정보는 상기 로컬 AI/ML 모델의 연속적인 AI/ML 모델 파라미터 세트를 나타내며, 상기 할당 정보는상기 세트 내의 상기 AI/ML 모델 파라미터의 시작 위치 및 상기 세트 내의 상기 AI/ML 모델 파라미터의 수를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "제29항에 있어서, 상기 할당 정보는 상기 로컬 AI/ML 모델의 연속적인 AI/ML 모델 파라미터의 다수의 세트를 나타내며, 각 세트에대해, 상기 할당 정보는 상기 세트 내 상기 AI/ML 모델 파라미터의 시작 위치 및 상기 세트 내 상기 AI/ML 모델파라미터의 수를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제29항에 있어서, 상기 로컬 AI/ML 모델은 다층 구조를 가지며, 상기 할당 정보는 상기 로컬 AI/ML 모델의 두 개의 층 사이의 하나 이상의 AI/ML 모델 파라미터 세트를 나타내는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "제28항 내지 제34항 어느 한 항에 있어서, 상기 값 정보는 하나 이상의 AI/ML 모델 파라미터 업데이트 값 세트를 포함하며, 상기 값 정보는, 각 AI/ML 모델 파라미터 업데이트 값 세트에 대해,상기 AI/ML 모델 파라미터 업데이트 값 세트 내의 각각의 AI/ML 모델 파라미터 업데이트 값에 대해 비트-스트링으로 표현되는 각각의 값 표시, 및상기 AI/ML 모델 파라미터 업데이트 값 세트와 연관된 범위 ID 값을 나타내고,상기 범위 ID 값은 하나 이상의 비트로 표현되고 복수의 범위 ID 값으로부터 선택되며, 상기 복수의 범위 ID 값의 각각의 범위 ID 값은 상이한 각각의 값 범위에 매핑되고,상기 AI/ML 모델 파라미터 업데이트 값 세트와 연관된 상기 범위 ID 값에 매핑되는 상기 각각의 값 범위는 상기AI/ML 모델 파라미터 업데이트 값 세트 내의 상기 AI/ML 모델 파라미터 업데이트 값의 비트 스트링의 범위 및공개특허 10-2024-0154076-8-비트 의미를 결정하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "제35항에 있어서, 상기 값 정보는 적어도 제1 AI/ML 모델 파라미터 업데이트 값 세트와 제2 AI/ML 모델 파라미터 업데이트 값 세트를 포함하고, 상기 제1 AI/ML 모델 파라미터 업데이트 값 세트에 대해, 상기 값 정보는,상기 제1 AI/ML 모델 파라미터 업데이트 값 세트 내의 각각의 AI/ML 모델 파라미터 업데이트 값에 대해 비트 스트링으로 표현되는 각각의 값 표시, 및상기 제1 AI/ML 모델 파라미터 업데이트 값 세트와 연관된 제1 범위 ID 값- 상기 제1 범위 ID 값은 하나 이상의비트로 표현되고 상기 복수의 범위 ID 값으로부터 선택되며, 상기 제1 범위 ID 값은 제1 값 범위에 매핑됨 -을나타내고,상기 제2 AI/ML 모델 파라미터 업데이트 값 세트에 대해, 상기 값 정보는,상기 제2 AI/ML 모델 파라미터 업데이트 값 세트 내의 각각의 AI/ML 모델 파라미터 업데이트 값에 대해 비트 스트링으로 표현되는 각각의 값 표시, 및상기 제2 AI/ML 모델 파라미터 업데이트 값 세트와 연관된 제2 범위 ID 값- 상기 제2 범위 ID 값은 하나 이상의비트로 표현되고 상기 복수의 범위 ID 값으로부터 선택되며, 상기 제2 범위 ID 값은 상기 제1 범위 ID 값과 다르고 상기 제1 값 범위와 다른 제2 값 범위에 매핑됨 -을 나타내는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_37", "content": "제35항 또는 제36항에 있어서, 범위 ID와 각각의 값 범위 사이의 매핑은 상기 제2 디바이스에 의해 미리 정의되거나 구성되는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_38", "content": "무선 통신 네트워크에서 인공 지능 또는 머신 러닝(AI/ML) 데이터 전송을 위한 방법으로서,제1 디바이스로부터 AI/ML 모델 훈련 능력을 수신하는 단계- 상기 제1 디바이스로부터의 상기 AI/ML 모델 훈련능력은 상기 무선 통신 네트워크에서 적어도 제2 디바이스와 AI/ML 모델 훈련 프로세스에 기여하여 참여하는 상기 제1 디바이스의 능력을 나타냄 -와,상기 제1 디바이스로부터 수신된 상기 AI/ML 모델 훈련 능력에 기초하여, 상기 제1 디바이스가 상기 AI/ML 모델훈련 프로세스의 적어도 하나의 반복마다, 상기 제1 디바이스가 상기 반복에 참여할지 여부를 결정할 수 있도록해주는 정보를 전송하는 단계를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_39", "content": "제38항에 있어서,상기 AI/ML 모델 훈련 능력은,i) 상기 제1 디바이스의 현재 처리 능력,ii) 상기 제1 디바이스에서 반복적인 상기 AI/ML 모델 훈련 프로세스에 사용 가능한 훈련 데이터의 현재 양, iii) 반복적인 상기 AI/ML 모델 훈련 프로세스에 대한 훈련 데이터를 수집하는 상기 제1 디바이스의 센싱 용량공개특허 10-2024-0154076-9-중 적어도 하나를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_40", "content": "제38항 또는 제39항에 있에서, 상기 제1 디바이스의 AI/ML 모델 훈련 능력은 미리 정의되거나 구성된 AI/ML 모델 훈련 능력 타입의 계층 구조중에서 선택된 AI/ML 모델 훈련 능력 타입을 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_41", "content": "제40항에 있어서,상기 제1 디바이스로부터 상기 AI/ML 모델 훈련 능력을 수신하는 단계는, 상기 미리 정의되거나 구성된 AI/ML모델 훈련 능력 타입의 계층 구조 중에서 선택된 상기 AI/ML 모델 훈련 능력 타입에 대응하는 인덱스를 수신하는 단계를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_42", "content": "제38항 내지 제41항 중 어느 한 항에 있어서, 상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해 데이터 또는 제어 정보의 전송을 스케줄링하는 제어 시그널링을 전송하는 단계를 더 포함하되, 상기 제1 디바이스로부터 상기 AI/ML 모델 훈련 능력을 수신하는 단계는상기 주어진 반복에 대한 상기 데이터 또는 제어 정보의 전송을 스케줄링하는 제어 시그널링이 전송된 후에 상기 제1 디바이스로로부터 상기 AI/ML 모델 훈련 능력을 수신하는 것을 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_43", "content": "제42항에 있어서,상기 주어진 반복에 대한 상기 데이터 또는 제어 정보의 전송을 스케줄링하는 상기 제어 시그널링은 상기 주어진 반복에 대해 상기 제1 디바이스에 의해 사용되는 물리적 업링크 제어 채널(PUCCH) 자원을 식별하는 제어 정보를 포함하고,상기 제1 디바이스로부터 상기 AI/ML 모델 훈련 능력을 수신하는 단계는 상기 PUCCH 자원에서 상기 주어진 반복에 대한 상기 AI/ML 모델 훈련 능력을 수신하는 것을 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_44", "content": "제43항에 있어서,상기 주어진 반복에 대한 상기 데이터 또는 제어 정보의 전송을 스케줄링하는 제어 시그널링은 다운링크 제어정보(DCI)를 포함하며, 상기 DCI는 상기 주어진 반복에 대해 상기 제1 디바이스에 의해 사용될 상기 PUCCH 자원을 나타내는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_45", "content": "제42항 내지 제44항 중 어느 한 항에 있어서, 상기 데이터 또는 제어 정보는 상기 제2 디바이스에서의 AI/ML 모델의 훈련에 기초한 AI/ML 모델 파라미터 업데이트를 포함하는 상기 제2 디바이스로부터의 AI/ML 모델 업데이트 정보를 포함하는,공개특허 10-2024-0154076-10-방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_46", "content": "제38항 내지 제45항 중 어느 한 항에 있어서, 상기 제1 디바이스로부터 AI/ML 모델 훈련 능력을 수신하는 단계는, 상기 제1 디바이스를 포함하는 복수의 디바이스 중 각 디바이스로부터 각각의 AI/ML 모델 훈련 능력을 수신하는 단계를 포함하고,상기 제1 디바이스로부터 수신된 상기 AI/ML 모델 훈련 능력에 기초하여, 상기 제1 디바이스가 상기 AI/ML 모델훈련 프로세스의 적어도 하나의 반복마다, 상기 제1 디바이스가 상기 반복에 참여할지 여부를 결정할 수 있도록해주는 정보를 전송하는 단계는, 상기 복수의 디바이스 중 각각의 디바이스로부터 수신된 상기 각각의 AI/ML 모델 훈련 능력에 기초하여, 상기 복수의 디바이스 중 각각의 디바이스가 상기 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복마다, 상기 각각의 디바이스가 상기 반복에 참여할지 여부를 결정할 수 있도록 해주는 정보를 전송하는 단계를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_47", "content": "제46항에 있어서,각각의 디바이스가 상기 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복마다, 상기 각각의 디바이스가 상기 반복에 참여할지 여부를 결정할 수 있도록 해주는 정보를 전송하는 단계는,상기 AI/ML 모델 훈련 프로세스의 각 반복에 대해, 상기 복수의 디바이스 중 각각의 디바이스가 상기 반복에 참여할지 여부를 결정하기 위한 디바이스별 규칙으로 상기 복수의 디바이스 중 각각의 디바이스를 구성하기 위해상기 복수의 디바이스 중 각각의 디바이스용 제어 시그널링을 전송하는 단계를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_48", "content": "제47항에 있어서,상기 AI/ML 모델 훈련 프로세스의 반복이 반복 식별자(ID)의 각 값과 연관되어 상기 반복 ID의 각 값이 후속 반복마다 1씩 증가되고,상기 복수의 디바이스가 구성되는 상기 디바이스별 규칙은 주어진 반복과 연관된 상기 반복 ID의 각각의 값에기초하여 상기 주어진 반복에 선택적으로 참여하도록 상기 복수의 디바이스 중 각각의 디바이스를 구성하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_49", "content": "제48항에 있어서, 상기 AI/ML 모델 훈련 프로세스의 반복에 대해, 상기 주어진 반복과 연관된 상기 반복 ID의 값을 나타내는 제어정보를 전송하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_50", "content": "제40항 또는 제41항에 있어서, 상기 제1 디바이스가 상기 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복마다, 상기 제1 디바이스가 상기 반복에 참여할지 여부를 결정할 수 있게 해주는 정보를 전송하는 단계는,상기 AI/ML 모델 훈련 프로세스의 반복에 대해, 상기 반복에 참여하는, 상기 AI/ML 모델 훈련 능력 타입의 미리정의되거나 구성된 계층 구조 중의 적어도 하나의 AI/ML 모델 훈련 능력 타입을 나타내는 제어 정보를 전송하는단계를 포함하는,공개특허 10-2024-0154076-11-방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_51", "content": "제38항 내지 제45항 중 어느 한 항에 있어서,상기 제1 디바이스가 상기 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복마다, 상기 제1 디바이스가 상기 반복에 참여할지 여부를 결정할 수 있도록 해주는 정보를 전송하는 단계는,상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해 데이터 또는 제어 정보의 전송을 스케줄링하기 위한 제1스케줄링 정보를 포함하는 제1 다운링크 제어 정보(DCI)를 전송하는 단계- 상기 제1 DCI의 순환 중복 검사(CRC)값은 제1 무선 네트워크 임시 식별자(RNTI)와 스크램블링됨 -와,제1 모니터링 주기에 따라 상기 제1 DCI를 모니터링하도록 상기 제1 디바이스를 구성하기 위한 제어 시그널링을전송하는 단계를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_52", "content": "제51항에 있어서, 다른 데이터 또는 제어 정보의 전송을 스케줄링하기 위한 제2 스케줄링 정보를 포함하는 제2 DCI를 전송하는 단계- 상기 제2 DCI의 CRC 값이 상기 제1 RNTI와 다른 제2 RNTI와 스크램블링됨 -와,제2 모니터링 주기에 따라 상기 제2 DCI를 모니터링하도록 상기 제1 디바이스를 구성하는 디바이스별 제어 시그널링을 전송하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_53", "content": "제52항에 있어서, 상기 제2 모니터링 주기는 상기 제1 모니터링 주기와 별도로 구성되는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_54", "content": "제51항 내지 제53항 중 어느 한 항에 있어서, 상기 제1 디바이스가 상기 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복마다, 상기 제1 디바이스가 상기 반복에 참여할지 여부를 결정할 수 있도록 해주는 정보를 전송하는 단계는,상기 제1 모니터링 주기와는 다른 제3 모니터링 주기에 따라 상기 제1 DCI를 모니터링하도록 제3 디바이스를 구성하기 위한 제어 시그널링을 전송하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_55", "content": "제51항 내지 제54항 중 어느 한 항에 있어서, 상기 제1 RNTI는 셀 RNTI(C-RNTI)와 다른,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_56", "content": "제38항 내지 제47항 중 어느 한 항에 있어서, 상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해, 로컬 AI/ML 모델 업데이트 정보를 상기 제1 디바이스로부터 수신하는 단계를 더 포함하되, 상기 제1 디바이스로부터의 상기 로컬 AI/ML 모델 업데이트 정보는 상기 제1 디바이스에서의 로컬 AI/ML 모델의 훈련에 기초한 AI/ML 모델 파라미터 업데이트를 포함하고, 상기 제1 디바공개특허 10-2024-0154076-12-이스에서의 상기 로컬 AI/ML 모델의 훈련은 상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해 상기 제2 디바이스로부터 전송된 데이터 또는 제어 정보에 기초하고, 상기 제1 디바이스로부터의 상기 로컬 AI/ML 모델 업데이트 정보는 상기 제1 디바이스가 상기 제2 디바이스로부터 상기 데이터 또는 제어 정보를 수신한 상기 주어진 반복과 연관된 반복 ID의 값을 나타내는 정보를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_57", "content": "제38항 내지 제47항 중 어느 한 항에 있어서, 상기 제1 디바이스로부터 상기 AI/ML 모델 훈련 프로세스에 참여하기 위한 요청을 수신하는 단계를 더포함하되, 상기 제1 디바이스로부터의 요청은 상기 AI/ML 모델 훈련 프로세스의 주어진 반복과 연관된 반복 ID의 값을 나타내는 정보를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_58", "content": "제57항에 있어서, 상기 제1 디바이스에서 로컬 AI/ML 모델의 파라미터의 부분적 서브세트를 포함하는 부분적 AI/ML 모델을 훈련하도록 상기 제1 디바이스를 구성하기 위한 상기 제1 디바이스용 제어 시그널링을 전송하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_59", "content": "제58항에 있어서, 상기 제1 디바이스로부터 로컬 AI/ML 모델 업데이트 정보를 수신하는 단계를 더 포함하되, 상기 제1 디바이스로부터의 상기 로컬 AI/ML 모델 업데이트 정보는 상기 제1 디바이스에서의 상기 부분적 AI/ML 모델의 훈련에 기반한 상기 파라미터의 부분적 서브세트에 대한 AI/ML 모델 파라미터 업데이트를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_60", "content": "제38항 내지 제59항 중 어느 한 항에 있어서, 상기 제1 디바이스가 상기 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복마다, 상기 제1 디바이스가 상기 반복에 참여할지 여부를 결정할 수 있도록 해주는 정보를 전송하는 단계는,상기 제1 디바이스로부터 수신된 상기 AI/ML 모델 훈련 능력에 기초하여, 상기 AI/ML 모델 훈련 프로세스에 참여하지 않도록 상기 제1 디바이스를 구성하기 위한 상기 제1 디바이스용 제어 시그널링을 전송하는 단계를 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_61", "content": "제38항 내지 제59항 중 어느 한 항에 있어서, 상기 AI/ML 모델 훈련 프로세스에 참여하지 않기 위한 요청을 상기 제1 디바이스로부터 수신하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_62", "content": "디바이스로서,프로세서와,공개특허 10-2024-0154076-13-프로세서 실행가능 명령어를 저장하는 메모리를 포함하되,상기 프로세서 실행가능 명령어는 실행되는 경우, 상기 프로세서로 하여금,상기 디바이스의 인공지능 또는 머신 러닝(AI/ML) 모델 훈련 능력을 결정하게 하고- 상기 AI/ML 모델 훈련 능력은 무선 통신 네트워크에서 적어도 하나의 다른 디바이스와의 AI/ML 모델 훈련 프로세스에 기여하여 참여할 수있는 상기 디바이스의 능력을 나타내고, 상기 AI/ML 모델 훈련 능력은,i) 상기 디바이스의 현재 처리 능력,ii) 상기 디바이스에서 상기 AI/ML 모델 훈련 프로세스에 사용할 수 있는 훈련 데이터의 현재 양, iii) 상기 AI/ML 모델 훈련 프로세스를 위한 훈련 데이터를 수집하는 상기 디바이스의 센싱 능력중 적어도 하나에 기초하여 결정됨 -,상기 AI/ML 모델 훈련 능력을 상기 다른 디바이스로 전송하게 하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_63", "content": "제62항에 있에서, 상기 디바이스의 AI/ML 모델 훈련 능력을 결정하는 것은 미리 정의되거나 구성된 AI/ML 모델 훈련 능력 타입의계층 구조 중에서 AI/ML 모델 훈련 능력 타입을 선택하는 것을 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_64", "content": "제63항에 있어서,상기 AI/ML 모델 훈련 능력을 상기 다른 디바이스로 전송하는 것은, 상기 미리 정의되거나 구성된 AI/ML 모델훈련 능력 타입의 계층 구조 중에서 선택된 AI/ML 모델 훈련 능력 타입에 대응하는 인덱스를 전송하는 것을 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_65", "content": "제62항 내지 제64항 중 어느 한 항에 있어서,상기 AI/ML 모델 훈련 능력을 상기 다른 디바이스로 전송하는 것은, 상기 디바이스의 AI/ML 모델 훈련 능력이 변경되었다고 판단하는 것과,상기 디바이스의 AI/ML 모델 훈련 능력이 변경되었다고 판단한 후 변경된 AI/ML 모델 훈련 능력을 상기 다른 디바이스로 전송하는 것을 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_66", "content": "제65항에 있어서, 상기 디바이스의 AI/ML 모델 훈련 능력이 변경되었다고 판단하는 것은,i) 상기 디바이스의 현재 처리 능력,ii) 상기 디바이스에서 상기 AI/ML 모델 훈련 프로세스에 사용 가능한 훈련 데이터의 현재 양, iii) 상기 AI/ML 모델 훈련 프로세스에 대한 훈련 데이터를 수집하는 상기 디바이스의 센싱 용량중 적어도 하나 이상의 변화를 식별하는 것을 포함하는,디바이스.공개특허 10-2024-0154076-14-청구항 67 제62항 내지 제64항 중 어느 한 항에 있어서, 상기 AI/ML 모델 훈련 능력을 상기 다른 디바이스로 전송하는 것은 상기 AI/ML 모델 학습 프로세스 중에 상기다른 디바이스로부터 데이터 또는 제어 정보를 수신한 후에 이루어지는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_68", "content": "제67항에 있어서,상기 AI/ML 모델 학습 프로세스 중에 상기 다른 디바이스로부터 데이터 또는 제어 정보를 수신한 후에 상기AI/ML 모델 훈련 능력을 상기 다른 디바이스로 전송하는 것은,상기 디바이스에 의해 사용될 물리적 업링크 제어 채널(PUCCH) 자원을 식별하는 제어 시그널링을 상기 다른 디바이스로부터 수신하는 것과,상기 PUCCH 자원을 이용하여 상기 AI/ML 모델 훈련 능력을 상기 다른 디바이스로 전송하는 것을 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_69", "content": "제68항에 있어서,상기 다른 디바이스로부터, 상기 디바이스에 의해 사용될 PUCCH 자원을 식별하는 제어 시그널링을 수신하는 것은, 상기 다른 디바이스로부터, 상기 AI/ML 모델 훈련 프로세스 동안 상기 다른 디바이스로부터의 상기 데이터 또는제어 정보의 다운링크 전송을 스케줄링하는 다운링크 제어 정보(DCI)를 수신하는 것을 포함하되, 상기 DCI는 상기 디바이스에 의해 사용될 상기 PUCCH 자원을 나타내는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_70", "content": "제67항 내지 제69항 어느 한 항에 있어서, 상기 다른 디바이스로부터 수신되는 상기 데이터 또는 제어 정보는 상기 AI/ML 모델 훈련 프로세스를 위한 상기다른 디바이스로부터의 AI/ML 모델 업데이트 정보를 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_71", "content": "제62항 내지 제70항 중 어느 한 항에 있어서,상기 프로세서 실행가능 명령어는, 실행되는 경우 상기 프로세서로 하여금,상기 다른 디바이스로부터, 상기 AI/ML 모델 훈련 프로세스의 반복에 대해, 상기 디바이스가 상기 반복에 참여할지 여부를 결정하기 위한 규칙으로 상기 디바이스를 구성하는 제어 시그널링을 수신하게 하는 프로세서 실행가능 명령어를 더 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_72", "content": "제71항에 있어서,상기 프로세서 실행가능 명령어는, 실행되는 경우 상기 프로세서로 하여금,상기 구성된 규칙에 따라 상기 AI/ML 모델 훈련 프로세스의 하나 이상의 반복에 참여하게 하는 프로세서 실행가공개특허 10-2024-0154076-15-능 명령어를 더 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_73", "content": "제71항 또는 제72항에 있어서,상기 AI/ML 모델 훈련 프로세스의 반복이 반복 식별자(ID)의 각 값과 연관되어 상기 반복 ID의 각 값이 후속 반복마다 1씩 증가되고,상기 제어 시그널링은 주어진 반복과 연관된 상기 반복 ID의 각 값에 따라 상기 주어진 반복에 선택적으로 참여하도록 상기 디바이스를 구성하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_74", "content": "제71항 내지 제73항 어느 한 항에 있어서, 상기 프로세서 실행가능 명령어는, 실행되는 경우 상기 프로세서로 하여금,상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해, 상기 다른 디바이스로부터, 상기 주어진 반복과 관련된반복 ID의 값을 나타내는 제어 정보를 수신하게 하는 프로세서 실행가능 명령어를 더 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_75", "content": "제63항 또는 제64항에 있어서, 상기 프로세서 실행가능 명령어는, 실행되는 경우 상기 프로세서로 하여금,상기 AI/ML 모델 학습 프로세스의 주어진 반복에 대해, 상기 다른 디바이스로부터, 상기 주어진 반복에 참여하는, 미리 정의되거나 구성된 AI/ML 모델 훈련 능역 타입의 계층 구조 중에서의 적어도 하나의 AI/ML 모델 훈련능력 타입을 나타내는 제어 정보를 수신하게 하는 프로세서 실행가능 명령어를 더 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_76", "content": "제62항 내지 제70항 어느 한 항에 있어서, 상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대한 데이터 또는 제어 정보가 상기 다른 디바이스로부터 전송되는 것은 제1 다운링크 제어 정보(DCI)에 의해 스케줄링되고, 상기 제1 DCI의 순환 중복 검사(CRC) 값이 제1무선 네트워크 임시 식별자(RNTI)와 스크램블링되고, 상기 프로세서 실행가능 명령어는, 실행되는 경우 상기 프로세서로 하여금,제1 모니터링 주기에 따라 상기 제1 DCI를 모니터링하도록 상기 디바이스를 구성하는 제어 시그널을 상기 다른디바이스로부터 수신하게 하는 프로세서 실행가능 명령어를 더 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_77", "content": "제76항에 있어서, 상기 다른 디바이스로부터 다른 데이터 또는 제어 정보가 전송되는 것은 제2 DCI에 의해 스케줄링되고, 상기 제2 DCI의 CRC 값이 상기 제1 RNTI와 다른 제2 RNTI와 스크램블링되고,상기 프로세서 실행가능 명령어는, 실행되는 경우 상기 프로세서로 하여금,상기 다른 디바이스로부터, 제2 모니터링 주기에 따라 상기 제2 DCI를 모니터링하도록 상기 디바이스를 구성하는 디바이스별 제어 시그널링을 수신하게 하는 프로세서 실행가능 명령어를 더 포함하는,공개특허 10-2024-0154076-16-디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_78", "content": "제77항에 있어서, 상기 제2 모니터링 주기는 상기 제1 모니터링 주기와 별도로 구성되는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_79", "content": "제76항 내지 제78항 어느 한 항에 있어서, 상기 제1 RNTI는 셀 RNTI(C-RNTI)와는 다른,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_80", "content": "제62항 내지 제72항 어느 한 항에 있어서, 상기 프로세서 실행가능 명령어는, 실행되는 경우 상기 프로세서로 하여금,상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해, 로컬 AI/ML 모델 업데이트 정보를 상기 다른 디바이스로전송하게 하는 프로세서 실행가능 명령어를 더 포함하되, 상기 로컬 AI/ML 모델 업데이트 정보는 상기 디바이스에서의 로컬 AI/ML 모델의 훈련에 기초한 AI/ML 모델 파라미터 업데이트를 포함하고, 상기 디바이스에서의 상기로컬 AI/ML 모델의 훈련은 상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해 상기 다른 디바이스로부터 수신된 데이터 또는 제어 정보에 기초하고, 상기 로컬 AI/ML 모델 업데이트 정보는 상기 디바이스가 상기 다른 디바이스로부터 데이터 또는 제어 정보를 수신한 상기 주어진 반복과 연관된 반복 ID의 값을 나타내는 정보를 더포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_81", "content": "제62항 내지 제72항 어느 한 항에 있어서, 상기 프로세서 실행가능 명령어는, 실행되는 경우 상기 프로세서로 하여금,상기 AI/ML 모델 훈련 프로세스에 참여하기 위한 요청을 상기 다른 디바이스로 전송하게 하는 프로세서 실행가능 명령어를 더 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_82", "content": "제81항에 있어서, 상기 AI/ML 모델 훈련 프로세스의 반복이 반복 식별자(ID)의 각 값과 연관되어 상기 반복 ID의 각각의 값이 후속 반복마다 1씩 증가되고,상기 프로세서 실행가능 명령어는, 실행되는 경우 상기 프로세서로 하여금,상기 AI/ML 모델 훈련 프로세스의 현재 반복과 연관된 반복 ID의 값을 나타내는 전송을 상기 다른 디바이스로부터 수신하게 하는 프로세서 실행가능 명령어를 더 포함하되,상기 AI/ML 모델 훈련 프로세스에 참여하기 위한 요청을 전송하는 것은 상기 /ML 모델 훈련 프로세스의 현재 반복과 연관된 상기 반복 ID의 값에 기초하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_83", "content": "공개특허 10-2024-0154076-17-제81항에 있어서, 상기 AI/ML 모델 학습 프로세스에 참여하기 위한 요청을 상기 다른 디바이스로 전송하는 것은,상기 디바이스의 AI/ML 모델 훈련 능력이 변경되었다고 판단한 후, 상기 AI/ML 모델 학습 프로세스에 참여하기위한 요청을 상기 다른 디바이스로 전송하는 것을 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_84", "content": "제81항 내지 제83항 어느 한 항에 있어서, 상기 프로세서 실행가능 명령어는, 실행되는 경우 상기 프로세서로 하여금,상기 디바이스에서 로컬 AI/ML 모델의 파라미터의 부분적 서브세트를 포함하는 부분적 AI/ML 모델을 훈련하도록상기 디바이스를 구성하는 제어 시그널링을 상기 다른 디바이스로부터 수신하게 하는 프로세서 실행가능 명령어를 더 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_85", "content": "제84항에 있어서, 상기 프로세서 실행가능 명령어는, 실행되는 경우 상기 프로세서로 하여금,로컬 AI/ML 모델 업데이트 정보를 상기 다른 디바이스로 전송하게 하는 프로세서 실행가능 명령어를 더 포함하되, 상기 로컬 AI/ML 모델 업데이트 정보는 상기 부분적 AI/ML 모델의 훈련에 기반한 상기 파라미터의 부분적서브세트에 대한 AI/ML 모델 파라미터 업데이트를 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_86", "content": "제62항 내지 제85항 어느 한 항에 있어서, 상기 프로세서 실행가능 명령어는, 실행되는 경우 상기 프로세서로 하여금,상기 AI/ML 모델 훈련 프로세스에 참여하지 않도록 상기 디바이스를 구성하는 제어 시그널링을 상기 다른 디바이스로부터 수신하게 하는 프로세서 실행가능 명령어를 더 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_87", "content": "제62항 내지 제85항 어느 한 항에 있어서, 상기 프로세서 실행가능 명령어는, 실행되는 경우 상기 프로세서로 하여금,상기 디바이스가 상기 AI/ML 모델 훈련 프로세스에 참여하지 않기 위한 요청을 상기 다른 디바이스로 전송하게하는 프로세서 실행가능 명령어를 더 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_88", "content": "제62항 내지 제79항 어느 한 항에 있어서, 상기 프로세서 실행가능 명령어는, 실행되는 경우 상기 프로세서로 하여금,상기 AI/ML 모델 훈련 프로세스의 주어진 반복을 위해, 로컬 AI/ML 모델 업데이트 정보를 상기 다른 디바이스로전송하게 하는 프로세서 실행가능 명령어를 더 포함하되, 상기 로컬 AI/ML 모델 업데이트 정보는 상기 디바이스에서의 로컬 AI/ML 모델의 훈련에 기초하고 상기 디바이스에서 상기 로컬 AI/ML 모델을 특징짓는 모든 AI/ML 모델 파라미터보다 적은 부분적 서브세트에 대해서만 AI/ML 모델 파라미터 업데이트를 포함하는,공개특허 10-2024-0154076-18-디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_89", "content": "제88항에 있어서, 상기 로컬 AI/ML 모델 업데이트 정보는,상기 디바이스에서 상기 로컬 AI/ML 모델을 특징짓는 모든 AI/ML 모델 파라미터보다 적은 부분적 서브세트에 대한 AI/ML 모델 파라미터 업데이트 값을 포함하는 값 정보, 및상기 로컬 AI/ML 모델의 대응하는 AI/ML 모델 파라미터에 상기 AI/ML 모델 업데이트 값을 매핑하는 할당 정보를포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_90", "content": "제89항에 있어서, 상기 AI/ML 모델 파라미터 업데이트 값은 상기 값 정보에 미리 정의되거나 구성된 순서로 배열되는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_91", "content": "제90항에 있어서, 상기 할당 정보는 상기 로컬 AI/ML 모델의 파라미터 그룹(PG)을 상기 값 정보 내의 대응하는 AI/ML 모델 파라미터 업데이트 값에 매핑하는 비트맵을 포함하고, 각 PG는 상기 로컬 AI/ML 모델의 연속적인 파라미터 세트인,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_92", "content": "제91항에 있어서, 각 PG의 크기는 상기 다른 디바이스에 의해 미리 정의되거나 구성되는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_93", "content": "제90항에 있어서, 상기 할당 정보는 상기 로컬 AI/ML 모델의 연속적인 AI/ML 모델 파라미터 세트를 나타내며, 상기 할당 정보는상기 세트 내의 상기 AI/ML 모델 파라미터의 시작 위치 및 상기 세트 내의 상기 AI/ML 모델 파라미터의 수를 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_94", "content": "제90항에 있어서, 상기 할당 정보는 상기 로컬 AI/ML 모델의 연속적인 AI/ML 모델 파라미터의 다수의 세트를 나타내며, 각 세트에대해, 상기 할당 정보는 상기 세트 내 상기 AI/ML 모델 파라미터의 시작 위치 및 상기 세트 내 상기 AI/ML 모델파라미터의 수를 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_95", "content": "제90항에 있어서, 공개특허 10-2024-0154076-19-상기 로컬 AI/ML 모델은 다층 구조를 가지며, 상기 할당 정보는 상기 로컬 AI/ML 모델의 두 개의 층 사이의 하나 이상의 AI/ML 모델 파라미터 세트를 나타내는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_96", "content": "제89항 내지 제95항 어느 한 항에 있어서, 상기 값 정보는 하나 이상의 AI/ML 모델 파라미터 업데이트 값 세트를 포함하며, 상기 값 정보는, 각 AI/ML 모델 파라미터 업데이트 값 세트에 대해,상기 AI/ML 모델 파라미터 업데이트 값 세트 내의 각각의 AI/ML 모델 파라미터 업데이트 값에 대해 비트-스트링으로 표현되는 각각의 값 표시, 및상기 AI/ML 모델 파라미터 업데이트 값 세트와 연관된 범위 ID 값을 나타내고,상기 범위 ID 값은 하나 이상의 비트로 표현되고 복수의 범위 ID 값으로부터 선택되며, 상기 복수의 범위 ID 값의 각각의 범위 ID 값은 상이한 각각의 값 범위에 매핑되고,상기 AI/ML 모델 파라미터 업데이트 값 세트와 연관된 상기 범위 ID 값에 매핑되는 상기 각각의 값 범위는 상기AI/ML 모델 파라미터 업데이트 값 세트 내의 상기 AI/ML 모델 파라미터 업데이트 값의 비트 스트링의 범위 및비트 의미를 결정하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_97", "content": "제96항에 있어서, 상기 값 정보는 적어도 제1 AI/ML 모델 파라미터 업데이트 값 세트와 제2 AI/ML 모델 파라미터 업데이트 값 세트를 포함하고, 상기 제1 AI/ML 모델 파라미터 업데이트 값 세트에 대해, 상기 값 정보는,상기 제1 AI/ML 모델 파라미터 업데이트 값 세트 내의 각각의 AI/ML 모델 파라미터 업데이트 값에 대해 비트 스트링으로 표현되는 각각의 값 표시, 및상기 제1 AI/ML 모델 파라미터 업데이트 값 세트와 연관된 제1 범위 ID 값- 상기 제1 범위 ID 값은 하나 이상의비트로 표현되고 상기 복수의 범위 ID 값으로부터 선택되며, 상기 제1 범위 ID 값은 제1 값 범위에 매핑됨 -을나타내고,상기 제2 AI/ML 모델 파라미터 업데이트 값 세트에 대해, 상기 값 정보는,상기 제2 AI/ML 모델 파라미터 업데이트 값 세트 내의 각각의 AI/ML 모델 파라미터 업데이트 값에 대해 비트 스트링으로 표현되는 각각의 값 표시, 및상기 제2 AI/ML 모델 파라미터 업데이트 값 세트와 연관된 제2 범위 ID 값- 상기 제2 범위 ID 값은 하나 이상의비트로 표현되고 상기 복수의 범위 ID 값으로부터 선택되며, 상기 제2 범위 ID 값은 상기 제1 범위 ID 값과 다르고 상기 제1 값 범위와 다른 제2 값 범위에 매핑됨 -을 나타내는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_98", "content": "제96항 또는 제97항에 있어서, 범위 ID와 각각의 값 범위 사이의 매핑은 상기 다른 디바이스에 의해 미리 정의되거나 구성되는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_99", "content": "제1항 내지 제37항 중 어느 한 항에 따른 방법을 수행하는 하나 이상의 유닛을 포함하는 장치.공개특허 10-2024-0154076-20-청구항 100 디바이스로서,프로세서와,프로세서 실행가능 명령어를 저장하는 메모리를 포함하되,상기 프로세서 실행가능 명령어는 실행되는 경우, 상기 프로세서로 하여금,인공지능 또는 머신 러닝(AI/ML) 모델 훈련 능력을 제1 디바이스로부터 수신하게 하고- 상기 제1 디바이스로부터의 상기 AI/ML 모델 훈련 능력은 상기 무선 통신 네트워크에서 적어도 상기 디바이스와 AI/ML 모델 훈련 프로세스에 기여하여 참여하는 상기 제1 디바이스의 능력을 나타냄 -와,상기 제1 디바이스로부터 수신된 상기 AI/ML 모델 훈련 능력에 기초하여, 상기 제1 디바이스가 상기 AI/ML 모델훈련 프로세스의 적어도 하나의 반복마다, 상기 제1 디바이스가 상기 반복에 참여할지 여부를 결정할 수 있도록해주는 정보를 전송하게 하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_101", "content": "제100항에 있어서,상기 AI/ML 모델 훈련 능력은,i) 상기 제1 디바이스의 현재 처리 능력,ii) 상기 제1 디바이스에서 반복적인 상기 AI/ML 모델 훈련 프로세스에 사용 가능한 훈련 데이터의 현재 양, iii) 반복적인 상기 AI/ML 모델 훈련 프로세스에 대한 훈련 데이터를 수집하는 상기 제1 디바이스의 센싱 용량중 적어도 하나를 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_102", "content": "제100항 또는 제101항에 있에서, 상기 제1 디바이스의 AI/ML 모델 훈련 능력은 미리 정의되거나 구성된 AI/ML 모델 훈련 능력 타입의 계층 구조중에서 선택된 AI/ML 모델 훈련 능력 타입을 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_103", "content": "제102항에 있어서,상기 제1 디바이스로부터 상기 AI/ML 모델 훈련 능력을 수신하는 것은, 상기 미리 정의되거나 구성된 AI/ML 모델 훈련 능력 타입의 계층 구조 중에서 선택된 상기 AI/ML 모델 훈련 능력 타입에 대응하는 인덱스를 수신하는것을 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_104", "content": "제100항 내지 제103항 중 어느 한 항에 있어서, 상기 프로세서 실행가능 명령어는 실행되는 경우, 상기 프로세서로 하여금,상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해 데이터 또는 제어 정보의 전송을 스케줄링하는 제어 시그널링을 전송하게 하는 프로세서 실행가능 명령어를 더 포함하되, 상기 제1 디바이스로부터 상기 AI/ML 모델 훈련 능력을 수신하는 것은 상기 주어진 반복에 대한 상기 데이터 또는 제어 정보의 전송을 스케줄링하는 제어 시그널링이 전송된 후에 상기 제1 디바이스로로부터 상기 AI/ML 모델 훈련 능력을 수신하는 것을 포함하는,공개특허 10-2024-0154076-21-디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_105", "content": "제104항에 있어서,상기 주어진 반복에 대한 상기 데이터 또는 제어 정보의 전송을 스케줄링하는 상기 제어 시그널링은 상기 주어진 반복에 대해 상기 제1 디바이스에 의해 사용되는 물리적 업링크 제어 채널(PUCCH) 자원을 식별하는 제어 정보를 포함하고,상기 제1 디바이스로부터 상기 AI/ML 모델 훈련 능력을 수신하는 것은 상기 PUCCH 자원에서 상기 주어진 반복에대한 상기 AI/ML 모델 훈련 능력을 수신하는 것을 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_106", "content": "제105항에 있어서,상기 주어진 반복에 대한 상기 데이터 또는 제어 정보의 전송을 스케줄링하는 제어 시그널링은 다운링크 제어정보(DCI)를 포함하며, 상기 DCI는 상기 주어진 반복에 대해 상기 제1 디바이스에 의해 사용될 상기 PUCCH 자원을 나타내는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_107", "content": "제104항 내지 제106항 중 어느 한 항에 있어서, 상기 데이터 또는 제어 정보는 상기 디바이스에서의 AI/ML 모델의 훈련에 기초한 AI/ML 모델 파라미터 업데이트를 포함하는 상기 디바이스로부터의 AI/ML 모델 업데이트 정보를 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_108", "content": "제100항 내지 제107항 중 어느 한 항에 있어서, 상기 제1 디바이스로부터 AI/ML 모델 훈련 능력을 수신하는 것은, 상기 제1 디바이스를 포함하는 복수의 디바이스 중 각 디바이스로부터 각각의 AI/ML 모델 훈련 능력을 수신하는 것을 포함하고,상기 제1 디바이스로부터 수신된 상기 AI/ML 모델 훈련 능력에 기초하여, 상기 제1 디바이스가 상기 AI/ML 모델훈련 프로세스의 적어도 하나의 반복마다, 상기 제1 디바이스가 상기 반복에 참여할지 여부를 결정할 수 있도록해주는 정보를 전송하는 것은, 상기 복수의 디바이스 중 각각의 디바이스로부터 수신된 상기 각각의 AI/ML 모델훈련 능력에 기초하여, 상기 복수의 디바이스 중 각각의 디바이스가 상기 AI/ML 모델 훈련 프로세스의 적어도하나의 반복마다, 상기 각각의 디바이스가 상기 반복에 참여할지 여부를 결정할 수 있도록 해주는 정보를 전송하는 것을 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_109", "content": "제108항에 있어서,각각의 디바이스가 상기 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복마다, 상기 각각의 디바이스가 상기 반복에 참여할지 여부를 결정할 수 있도록 해주는 정보를 전송하는 것은,상기 AI/ML 모델 훈련 프로세스의 각 반복에 대해, 상기 복수의 디바이스 중 각각의 디바이스가 상기 반복에 참여할지 여부를 결정하기 위한 디바이스별 규칙으로 상기 복수의 디바이스 중 각각의 디바이스를 구성하기 위해상기 복수의 디바이스 중 각각의 디바이스용 제어 시그널링을 전송하는 것을 포함하는,디바이스.공개특허 10-2024-0154076-22-청구항 110 제109항에 있어서,상기 AI/ML 모델 훈련 프로세스의 반복이 반복 식별자(ID)의 각 값과 연관되어 상기 반복 ID의 각 값이 후속 반복마다 1씩 증가되고,상기 복수의 디바이스가 구성되는 상기 디바이스별 규칙은 주어진 반복과 연관된 상기 반복 ID의 각각의 값에기초하여 상기 주어진 반복에 선택적으로 참여하도록 상기 복수의 디바이스 중 각각의 디바이스를 구성하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_111", "content": "제110항에 있어서, 상기 프로세서 실행가능 명령어는 실행되는 경우, 상기 프로세서로 하여금,상기 AI/ML 모델 훈련 프로세스의 반복에 대해, 상기 주어진 반복과 연관된 상기 반복 ID의 값을 나타내는 제어정보를 전송하게 하는 프로세서 실행가능 명령어를 더 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_112", "content": "제102항 또는 제103항에 있어서, 상기 제1 디바이스가 상기 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복마다, 상기 제1 디바이스가 상기 반복에 참여할지 여부를 결정할 수 있게 해주는 정보를 전송하는 것은,상기 AI/ML 모델 훈련 프로세스의 반복에 대해, 상기 반복에 참여하는, 상기 AI/ML 모델 훈련 능력 타입의 미리정의되거나 구성된 계층 구조 중의 적어도 하나의 AI/ML 모델 훈련 능력 타입을 나타내는 제어 정보를 전송하는것을 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_113", "content": "제100항 내지 제107항 중 어느 한 항에 있어서,상기 제1 디바이스가 상기 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복마다, 상기 제1 디바이스가 상기 반복에 참여할지 여부를 결정할 수 있도록 해주는 정보를 전송하는 것은,상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해 데이터 또는 제어 정보의 전송을 스케줄링하기 위한 제1스케줄링 정보를 포함하는 제1 다운링크 제어 정보(DCI)를 전송하는 것- 상기 제1 DCI의 순환 중복 검사(CRC)값은 제1 무선 네트워크 임시 식별자(RNTI)와 스크램블링됨 -과,제1 모니터링 주기에 따라 상기 제1 DCI를 모니터링하도록 상기 제1 디바이스를 구성하기 위한 제어 시그널링을전송하는 것을 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_114", "content": "제113항에 있어서, 상기 프로세서 실행가능 명령어는 실행되는 경우, 상기 프로세서로 하여금,다른 데이터 또는 제어 정보의 전송을 스케줄링하기 위한 제2 스케줄링 정보를 포함하는 제2 DCI를 전송하고-상기 제2 DCI의 CRC 값이 상기 제1 RNTI와 다른 제2 RNTI와 스크램블링됨 -,제2 모니터링 주기에 따라 상기 제2 DCI를 모니터링하도록 상기 제1 디바이스를 구성하는 디바이스별 제어 시그널링을 전송하게 하는 프로세서 실행가능 명령어를 더 포함하는,공개특허 10-2024-0154076-23-디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_115", "content": "제114항에 있어서, 상기 제2 모니터링 주기는 상기 제1 모니터링 주기와 별도로 구성되는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_116", "content": "제113항 내지 제115항 중 어느 한 항에 있어서, 상기 프로세서 실행가능 명령어는 실행되는 경우, 상기 프로세서로 하여금,상기 제1 모니터링 주기와는 다른 제3 모니터링 주기에 따라 상기 제1 DCI를 모니터링하도록 제3 디바이스를 구성하기 위한 제어 시그널링을 전송하게 하는 프로세서 실행가능 명령어를 더 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_117", "content": "제113항 내지 제116항 중 어느 한 항에 있어서, 상기 제1 RNTI는 셀 RNTI(C-RNTI)와 다른,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_118", "content": "제100항 내지 제109항 중 어느 한 항에 있어서, 상기 프로세서 실행가능 명령어는 실행되는 경우, 상기 프로세서로 하여금,상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해, 로컬 AI/ML 모델 업데이트 정보를 상기 제1 디바이스로부터 수신하게 하는 프로세서 실행가능 명령어를 더 포함하되, 상기 제1 디바이스로부터의 상기 로컬 AI/ML 모델 업데이트 정보는 상기 제1 디바이스에서의 로컬 AI/ML 모델의 훈련에 기초한 AI/ML 모델 파라미터 업데이트를 포함하고, 상기 제1 디바이스에서의 상기 로컬 AI/ML 모델의 훈련은 상기 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해 상기 디바이스로부터 전송된 데이터 또는 제어 정보에 기초하고, 상기 제1 디바이스로부터의 상기 로컬 AI/ML 모델 업데이트 정보는 상기 제1 디바이스가 상기 디바이스로부터 데이터 또는 제어 정보를 수신한 상기 주어진 반복과 연관된 반복 ID의 값을 나타내는 정보를 더 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_119", "content": "제100항 내지 제109항 중 어느 한 항에 있어서, 상기 프로세서 실행가능 명령어는 실행되는 경우, 상기 프로세서로 하여금,상기 제1 디바이스로부터 상기 AI/ML 모델 훈련 프로세스에 참여하기 위한 요청을 수신하게 하는 프로세서 실행가능 명령어를 더 포함하되, 상기 제1 디바이스로부터의 요청은 상기 AI/ML 모델 훈련 프로세스의 주어진 반복과 연관된 반복 ID의 값을 나타내는 정보를 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_120", "content": "제119항에 있어서, 상기 프로세서 실행가능 명령어는 실행되는 경우, 상기 프로세서로 하여금,상기 제1 디바이스에서 로컬 AI/ML 모델의 파라미터의 부분적 서브세트를 포함하는 부분적 AI/ML 모델을 훈련하도록 상기 제1 디바이스를 구성하기 위한 상기 제1 디바이스용 제어 시그널링을 전송하게 하는 프로세서 실행가공개특허 10-2024-0154076-24-능 명령어를 더 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_121", "content": "제120항에 있어서,상기 프로세서 실행가능 명령어는 실행되는 경우, 상기 프로세서로 하여금,상기 제1 디바이스로부터 로컬 AI/ML 모델 업데이트 정보를 수신하게 하는 프로세서 실행가능 명령어를 더 포함하되, 상기 제1 디바이스로부터의 상기 로컬 AI/ML 모델 업데이트 정보는 상기 제1 디바이스에서의 상기 부분적AI/ML 모델의 훈련에 기반한 상기 파라미터의 부분적 서브세트에 대한 AI/ML 모델 파라미터 업데이트를 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_122", "content": "제100항 내지 제121항 중 어느 한 항에 있어서, 상기 제1 디바이스가 상기 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복마다, 상기 제1 디바이스가 상기 반복에 참여할지 여부를 결정할 수 있도록 해주는 정보를 전송하는 것은,상기 제1 디바이스로부터 수신된 상기 AI/ML 모델 훈련 능력에 기초하여, 상기 AI/ML 모델 훈련 프로세스에 참여하지 않도록 상기 제1 디바이스를 구성하기 위한 상기 제1 디바이스용 제어 시그널링을 전송하는 것을 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_123", "content": "제100항 내지 제121항 중 어느 한 항에 있어서, 상기 프로세서 실행가능 명령어는 실행되는 경우, 상기 프로세서로 하여금,상기 AI/ML 모델 훈련 프로세스에 참여하지 않기 위한 요청을 상기 제1 디바이스로부터 수신하게 하는 프로세서실행가능 명령어를 더 포함하는,디바이스."}
{"patent_id": "10-2024-7032742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_124", "content": "제38항 내지 제61항 중 어느 한 항에 따른 방법을 수행하는 하나 이상의 유닛을 포함하는 장치."}
{"patent_id": "10-2024-7032742", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "무선 통신을 위한 인공지능/머신 러닝(AI/ML) 모델에 대한 현재의 온라인 훈련 절차는, 특히 훈련 절차에 참여하 는 하나 이상의 디바이스가 제한된 처리 능력, 훈련 데이터에 대한 제한된 액세스 및/또는 훈련 데이터를 수집하 는 제한된 센싱 능력과 같은 제한된 학습 능력을 갖는 경우, 일반적으로 훈련시 높은 통신 오버헤드 및/또는 커 다란 지연으로 어려움을 겪는다. 일부 실시예에서, 오버헤드 감소와 훈련 성능 간의 균형을 제공하기 위해 디바 이스의 현재 보고된 학습 능력에 기초하여 디바이스가 온라인 훈련 절차 참여에 선택적으로 포함되거나 제외된다."}
{"patent_id": "10-2024-7032742", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 일반적으로 무선 통신에 관한 것이며, 특히 실시예에서는 적은 훈련 지연과 적은 통신 오버헤드를 갖 는 머신 러닝을 위한 방법 및 장치에 관한 것이다"}
{"patent_id": "10-2024-7032742", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능(AI) 기술은 물리 계층에서의 AI 기반 통신 및/또는 매체 액세스 제어(MAC) 계층에서의 AI 기반 통신 을 포함하는 통신에 적용될 수 있다. 예를 들어, 물리 계층에서, AI 기반 통신은 컴포넌트 설계를 최적화하고 및/또는 알고리즘 성능을 개선하는 것을 목표로 할 수 있다. MAC 계층의 경우, AI 기반 통신은 더 나은 전략 및/또는 최적의 솔루션으로 복잡한 최적화 문제를 해결하기 위한 학습, 예측 및/또는 의사결정을 위해 AI 기능 을 활용하여, 예를 들어 MAC 계층의 기능을 최적화하는 것을 목표로 할 수 있다. 일부 구현에서, 무선 통신 네트워크에서의 AI 아키텍처는 다수의 노드를 포함할 수 있되, 다수의 노드는 두 가 지 모드, 즉 중앙 집중형 및 분산형 중 하나로 구성될 수 있으며, 둘 다 액세스 네트워크, 코어 네트워크 또는엣지 컴퓨팅 시스템 또는 제3자 네트워크에 배치될 수 있다. 중앙 집중형 훈련 및 컴퓨팅 아키텍처는 큰 통신 오버헤드 및 엄격한 사용자 데이터 프라이버시에 의해 제한될 수 있다. 분산형 훈련 및 컴퓨팅 아키텍처는 분산 형 머신 러닝 및 연합 학습과 같은 여러 프레임워크를 포함할 수 있다. 그러나, 다수의 노드에서의 AI 훈련과 연관된 통신을 포함한 무선 통신 시스템의 통신은 일반적으로 비-이상적 채널을 통해 이루어진다. 예를 들어, 전자기 간섭, 신호 저하, 위상 지연, 페이딩 및 기타 비이상성과 같은 비 이상적인 조건은 통신 신호를 감쇠 및/또는 왜곡하거나 시스템의 통신 기능을 방해하거나 저하시킬 수 있다. 기존의 AI 훈련 프로세스는 일반적으로 하이브리드 자동 반복 요청(HARQ) 피드백 및 재전송 프로세스에 의존하 여 AI 훈련에 관련된 디바이스들 간에 통신되는 데이터가 성공적으로 수신되도록 보장하려 한다. 그러나, 이러 한 재전송과 관련된 통신 오버헤드와 지연은 문제가 될 수 있다. 본 개시의 제1 광의의 양상에 따르면, 무선 통신 네트워크에서 인공지능 또는 머신 러닝(AI/ML) 데이터 전송을 위한 방법이 본 명세서에서 제공된다. 본 개시의 제1 광의의 양상에 따른 방법은, 제1 디바이스의 AI/ML 모델 훈련 능력을 결정하는 단계를 포함할 수 있으며, AI/ML 모델 훈련 능력은 무선 통신 네트워크에서 적어도 제2 디바이스와의 AI/ML 모델 훈련 프로세스에 기여하여 참여하는 제1 디바이스의 능력을 나타낸다. 예를 들어, AI/ML 모델 훈련 능력은: i) 제1 디바이스의 현재 처리 능력; ii) 제1 디바이스에서 AI/ML 모델 훈련 프로세스 에 이용 가능한 훈련 데이터의 현재 양; 및/또는 iii) AI/ML 모델 훈련 프로세스를 위한 훈련 데이터를 수집하 는 제1 디바이스의 센싱 능력에 기초하여 결정될 수 있다. 본 개시의 제1 광의의 양상에 따른 방법은 AI/ML 모 델 훈련 능력을 제2 디바이스로 전송하는 단계를 더 포함할 수 있다. 본 개시의 제1 광의의 양상에 따라 AI/ML 모델 훈련 능력 피드백을 제공하는 것은 몇 가지 장점을 가질 수 있다. 예를 들어, AI/ML 모델 훈련 능력 피드백은 본 명세서에서 더 상세히 논의되는 바와 같이, 잠재적으로 훈 련 레이턴시를 감소시켜 빠른 훈련 수렴을 달성하고 및/또는 AI/ML 모델 훈련 절차에 관련된 통신 오버헤드를 감소시킬 수 있도록, 디바이스의 현재 보고된 AI/ML 모델 훈련 능력에 기초하여 AI/ML 모델 훈련 절차의 하나 이상의 반복에 제1 디바이스가 참여하는 것을 선택적으로 포함하거나 제외시키는 데 활용될 수 있다. 일부 실시예에서, 제1 디바이스의 AI/ML 모델 훈련 능력을 결정하는 것은, 미리 정의되거나 구성된 AI/ML 모델 훈련 능력 타입의 계층 구조 중에서 AI/ML 모델 훈련 능력 타입을 선택하는 것을 포함한다. 이러한 실시예들에 서, AI/ML 모델 훈련 능력을 제2 디바이스로 전송하는 것은 미리 정의되거나 구성된 AI/ML 모델 훈련 능력 타입 의 계층 구조 중에서 선택된 AI/ML 모델 훈련 능력 타입에 대응하는 인덱스를 전송하는 것을 포함할 수 있다. 일부 실시예에서, AI/ML 모델 훈련 능력을 제2 디바이스로 전송하는 단계는 제1 디바이스의 AI/ML 모델 훈련 능 력이 변경된 것을 결정하는 단계와, 제1 디바이스의 AI/ML 모델 훈련 능력이 변경된 것을 결정한 후 변경된 AI/ML 모델 훈련 능력을 제2 디바이스로 전송하는 단계를 포함한다. 이러한 실시예에서, 제1 디바이스의 AI/ML 모델 훈련 능력이 변경되었다고 결정하는 단계는 예를 들어, i) 제1 디바이스의 현재 처리 능력, ii) 제1 디바 이스에서 AI/ML 모델 훈련 프로세스에 이용 가능한 훈련 데이터의 현재 양; 및/또는 iii) AI/ML 모델 훈련 프로 세스를 위한 훈련 데이터를 수집하는 제1 디바이스의 센싱 능력 중 적어도 하나의 변화를 식별하는 단계를 포함 할 수 있다. 일부 실시예에서, AI/ML 모델 훈련 능력을 제2 디바이스로 전송하는 단계는 AI/ML 모델 훈련 프로세스 동안 제2 디바이스로부터 데이터 또는 제어 정보를 수신한 후에 수행된다. 예를 들어, 일부 실시예에서, 제1 디바이스는 제1 디바이스에 의해 사용될 물리적 업링크 제어 채널(PUCCH) 자원을 식별하는 제어 시그널링을 제2 디바이스로 부터 수신하고, PUCCH 자원을 사용하여 AI/ML 모델 훈련 능력을 제2 디바이스로 전송할 수 있다. 이러한 실시 예에서, 제1 디바이스에 의해 사용될 PUCCH 자원을 식별하는 제어 시그널링을 제2 디바이스로부터 수신하는 것 은, 제2 디바이스로부터, AI/ML 모델 훈련 프로세스 동안 제2 디바이스로부터 데이터 또는 제어 정보의 다운링 크 전송을 스케줄링하는 다운링크 제어 정보(DCI)를 수신하는 것을 포함하되, DCI는 제1 디바이스에 의해 사용 될 PUCCH 자원을 나타낸다. 일부 실시예에서, 제2 디바이스로부터 수신된 데이터 또는 제어 정보는 AI/ML 모델 훈련 프로세스를 위한 제2 디바이스로부터의 AI/ML 모델 업데이트 정보를 포함한다. 일부 실시예에서, 본 개시의 제1 광의의 양상에 따른 방법은, AI/ML 모델 훈련 프로세스의 반복에 대해, 제1 디 바이스가 그 반복에 참여할지를 결정하기 위한 규칙으로 제1 디바이스를 구성하는 제어 시그널링을 제2 디바이스로부터 수신하는 단계를 더 포함한다. 일부 실시예에서, 본 개시의 제1 광의의 양상에 따른 방법은 구성된 규칙에 따라 AI/ML 모델 훈련 프로세스의 하나 이상의 반복에 참여하는 단계를 더 포함한다. 일부 실시예에서, AI/ML 모델 훈련 프로세스의 반복은 반복 식별자(ID)의 각각의 값과 연관되되 반복 ID의 각각 의 값은 각각의 후속 반복에 대해 1씩 증가한다. 이러한 실시예에서, 제어 시그널링은 주어진 반복과 연관된 반복 ID의 각각의 값에 기초하여 주어진 반복에 선택적으로 참여하도록 제1 디바이스를 구성할 수 있다. 일부 실시예에서, 본 개시의 제1 광의의 양상에 따른 방법은 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해, 제2 디바이스로부터, 주어진 반복과 연관된 반복 ID의 값을 나타내는 제어 정보를 수신하는 단계를 더 포함한다. 일부 실시예에서, 본 개시의 제1 광의의 양상에 따른 방법은 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해, 제2 디바이스로부터, 미리 정의되거나 구성된 AI/ML 모델 훈련 능력 타입의 계층구조 중에서 주어진 반복에 참 여하는 적어도 하나의 AI/ML 모델 훈련 능력 타입을 나타내는 제어 정보를 수신하는 단계를 더 포함한다. 일부 실시예에서, AI/ML 모델 훈련 프로세스의 주어진 반복에 대한 데이터 또는 제어 정보가 제2 디바이스로부 터 전송되는 것은 제1 다운링크 제어 정보(DCI)에 의해 스케줄링되는데, 여기서 제1 DCI의 순환 중복 검사(CRC) 값은 제1 무선 네트워크 임시 식별자(RNTI)와 스크램블링된다. 이러한 실시예에서, 본 개시의 제1 광의의 양상 에 따른 방법은 제1 모니터링 주기성에 따라 제1 DCI를 모니터링하도록 제1 디바이스를 구성하기 위한 제어 신 호를 제2 디바이스로부터 수신하는 단계를 더 포함할 수 있다. 일부 실시예에서, 다른 데이터 또는 제어 정보가 제2 디바이스로부터 전송되는 것은 제2 DCI에 의해 스케줄링되 며, 여기서, 제2 DCI의 CRC 값은 제1 RNTI와 다른 제2 RNTI로 스크램블링된다. 이러한 실시예에서, 본 개시의 제1 광의 양상에 따른 방법은 제2 모니터링 주기성에 따라 제2 DCI를 모니터링하도록 제1 디바이스를 구성하는 디바이스별 제어 신호를 제2 디바이스로부터 수신하는 단계를 더 포함할 수 있다. 일부 실시예에서, 제2 모니터링 주기성은 제1 모니터링 주기성과 별도로 구성된다. 일부 실시예에서, 제1 RNTI는 셀 RNTI(C-RNTI)와 상이하다. 일부 실시예에서, 본 개시의 제1 광의의 양상에 따른 방법은 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해, 로컬 AI/ML 모델 업데이트 정보를 제2 디바이스로 전송하는 단계를 더 포함하되, 이 로컬 AI/ML 모델 업데이트 정보는 제1 디바이스에서의 로컬 AI/ML 모델의 훈련에 기초한 AI/ML 모델 파라미터 업데이트를 포함한다. 이러 한 실시예에서, 제1 디바이스에서의 로컬 AI/ML 모델의 훈련은 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해 제2 디바이스로부터 수신된 데이터 또는 제어 정보에 기초할 수 있다. 예를 들어, 로컬 AI/ML 모델 업데이트 정보는 제1 디바이스가 제2 디바이스로부터 데이터 또는 제어 정보를 수신한 주어진 반복과 연관된 반복 ID의 값을 나타내는 정보를 더 포함할 수 있다. 일부 실시예에서, 본 개시의 제1 광의의 양상에 따른 방법은 AI/ML 모델 훈련 프로세스에 참여하기 위한 요청을 제2 디바이스로 전송하는 단계를 더 포함한다. 일부 실시예에서, AI/ML 모델 훈련 프로세스의 반복은 반복 식별자(ID)의 각각의 값과 연관되되, 반복 ID의 각 각의 값이 각각의 후속 반복에 대해 1씩 증가된다. 이러한 실시예에서, 본 개시의 제1 광의의 양상에 따른 방 법은 AI/ML 모델 훈련 프로세스의 현재 반복과 연관된 반복 ID의 값을 나타내는 전송을 제2 디바이스로부터 수 신하는 단계를 더 포함할 수 있으며, 여기서, AI/ML 모델 훈련 프로세스에 참여하기 위한 요청을 전송하는 것은 AI/ML 모델 훈련 프로세스의 현재 반복과 연관된 반복 ID의 값에 기초한다. 일부 실시예에서, AI/ML 모델 훈련 프로세스에 참여하기 위한 요청을 제2 디바이스로 전송하는 것은 제1 디바이 스의 AI/ML 모델 훈련 능력이 변경된 것으로 결정한 후에 AI/ML 모델 훈련 프로세스에 참여하기 위한 요청을 제 2 디바이스로 전송하는 것을 포함한다. 일부 실시예에서, 본 개시의 제1 광의의 양상에 따른 방법은 제1 디바이스에서 로컬 AI/ML 모델의 파라미터의 부분적 서브세트를 포함하는 부분적 AI/ML 모델을 훈련하도록 제1 디바이스를 구성하는 제어 시그널링을 제2 디 바이스로부터 수신하는 단계를 더 포함한다. 일부 실시예에서, 본 개시의 제1 광의의 양상에 따른 방법은 로컬 AI/ML 모델 업데이트 정보를 제2 디바이스로 전송하는 단계를 더 포함하되, 로컬 AI/ML 모델 업데이트 정보는 부분적 AI/ML 모델의 훈련에 기초한 파라미터의 부분적 서브세트에 대한 AI/ML 모델 파라미터 업데이트를 포함한다. 일부 실시예에서, 본 개시의 제1 광의의 양상에 따른 방법은 AI/ML 모델 훈련 프로세스에 참여하지 않도록 제1 디바이스를 구성하는 제어 시그널링을 제2 디바이스로부터 수신하는 단계를 더 포함한다. 일부 실시예에서, 본 개시의 제1 광의의 양상에 따른 방법은 제1 디바이스가 AI/ML 모델 훈련 프로세스에 참여 하지 않도록 하는 요청을 제2 디바이스로 전송하는 단계를 더 포함한다. 일부 실시예에서, 본 개시의 제1 광의의 양상에 따른 방법은 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해, 로컬 AI/ML 모델 업데이트 정보를 제2 디바이스로 전송하는 단계를 더 포함한다. 이러한 일부 실시예에서, 로 컬 AI/ML 모델 업데이트 정보는 제1 디바이스에서의 로컬 AI/ML 모델의 훈련에 기초할 수 있고, 제1 디바이스에 서 로컬 AI/ML 모델을 특징짓는 모든 AI/ML 모델 파라미터보다 적은 일부 서브세트에 대해서만의 AI/ML 모델 파 라미터 업데이트를 포함할 수 있다. 일부 실시예에서, 로컬 AI/ML 모델 업데이트 정보는 제1 디바이스에서 로컬 AI/ML 모델을 특징짓는 모든 AI/ML 모델 파라미터보다 적은 일부 서브세트에 대해서만의 AI/ML 모델 파라미터 업데이트 값을 포함하는 값 정보, 및 로컬 AI/ML 모델의 대응하는 AI/ML 모델 파라미터에 AI/ML 모델 파라미터 업데이트 값을 매핑하는 할당 정보를 포함한다. 일부 실시예에서, AI/ML 모델 파라미터 업데이트 값은 값 정보 내의 미리 정의되거나 구성된 순서로 배열된다. 일부 실시예에서, 할당 정보는 로컬 AI/ML 모델의 파라미터 그룹(PG)을, 값 정보 내의 대응하는 AI/ML 모델 파 라미터 업데이트 값에 매핑하는 비트맵을 포함하며, 여기서 각 PG는 로컬 AI/ML 모델의 연속적인 파라미터 세트 이다. 일부 실시예에서, 각 PG의 크기는 제2 디바이스에 의해 미리 정의되거나 구성된다. 일부 실시예에서, 할당 정보는 로컬 AI/ML 모델의 연속적인 AI/ML 모델 파라미터 세트를 나타내며, 여기서, 할 당 정보는 세트 내의 AI/ML 모델 파라미터의 시작 위치 및 세트 내의 AI/ML 모델 파라미터의 수를 포함한다. 일부 실시예에서, 할당 정보는 로컬 AI/ML 모델의 연속적인 AI/ML 모델 파라미터의 다수의 세트를 나타내며, 여 기서, 각 세트에 대해, 할당 정보는 세트 내 AI/ML 모델 파라미터의 시작 위치 및 세트 내 AI/ML 모델 파라미터 의 수를 포함한다. 일부 실시예에서, 로컬 AI/ML 모델은 다중 계층 구조를 가지며, 할당 정보는 로컬 AI/ML 모델의 두 계층 사이에 있는 하나 이상의 AI/ML 모델 파라미터 세트를 나타낸다. 일부 실시예에서, 값 정보는 하나 이상의 AI/ML 모델 파라미터 업데이트 값 세트를 포함하며, 각각의 AI/ML 모 델 파라미터 업데이트 값 세트에 대해, 값 정보는: AI/ML 모델 파라미터 업데이트 값 세트의 각각의 AI/ML 모델 파라미터 업데이트 값에 대해 비트 스트링으로 표현되는 각각의 값 표시, 및 AI/ML 모델 파라미터 업데이트 값 세트와 연관된 범위 ID 값을 나타낸다. 예를 들어, 일부 실시예에서, 범위 ID 값은 하나 이상의 비트로 표현될 수 있고 복수의 범위 ID 값으로부터 선택될 수 있으며, 복수의 범위 ID 값의 각 범위 ID 값은 상이한 각각의 값 범위에 매핑될 수 있다. 이러한 실시예에서, AI/ML 모델 파라미터 업데이트 값 세트와 연관된 범위 ID 값에 매 핑되는 각각의 값 범위는 AI/ML 모델 파라미터 업데이트 값 세트에서 AI/ML 모델 파라미터 업데이트 값의 비트- 스트링의 범위 및 비트 의미를 결정할 수 있다. 일부 실시예에서, 값 정보는 적어도 제1 AI/ML 모델 파라미터 업데이트 값 세트 및 제2 AI/ML 모델 파라미터 업 데이트 값 세트를 포함한다. 이러한 실시예에서, 제1 AI/ML 모델 파라미터 업데이트 값 세트에 대한 값 정보는 제1 AI/ML 모델 파라미터 업데이트 값 세트의 각 AI/ML 모델 파라미터 업데이트 값에 대해 비트 스트링으로 표 현되는 각각의 값 표시와, 제1 AI/ML 모델 파라미터 업데이트 값 세트와 연관된 제1 범위 ID 값을 나타내고, 여 기서 제1 범위 ID 값은 하나 이상의 비트로 표현되고 복수의 범위 ID 값으로부터 선택되고, 제1 범위 ID 값은 제1 값 범위에 매핑된다. 또한, 또는 대신하여, 그러한 실시예에서, 제2 AI/ML 모델 파라미터 업데이트 값 세 트에 대한 값 정보는 제2 AI/ML 모델 파라미터 업데이트 값 세트의 각 AI/ML 모델 파라미터 업데이트 값에 대해 비트 스트링으로 표현되는 각각의 값 표시와, 제2 AI/ML 모델 파라미터 업데이트 값 세트와 연관된 제2 범위 ID 값을 포함하고, 여기서 제2 범위 ID 값은 하나 이상의 비트로 표현되고 복수의 범위 ID 값으로부터 선택된다. 예를 들어, 일부 실시예에서, 제2 범위 ID 값은 제1 범위 ID 값과 상이할 수 있고, 제1 값 범위와 상이한 제2 값 범위에 매핑될 수 있다.일부 실시예에서, 범위 ID와 각각의 값 범위 사이의 매핑은 제2 디바이스에 의해 미리 정의되거나 구성된다. 본 개시의 제2 광의의 양상에 따르면, 무선 통신 네트워크에서 인공 지능 또는 머신 러닝(AI/ML) 데이터 전송을 위한 또 다른 방법이 제공된다. 본 개시의 제2 광의의 양상에 따른 방법은 제1 디바이스로부터 AI/ML 모델 훈련 능력을 수신하는 단계- 제1 디바이스로부터의 AI/ML 모델 훈련 능력은 무선 통신 네트워크에서 적어도 제2 디바 이스와의 AI/ML 모델 훈련 프로세스에 기여하여 참여할 수 있는 제1 디바이스의 능력을 나타냄 -와, 제1 디바이 스로부터 수신된 AI/ML 모델 훈련 능력에 기초하여, 제1 디바이스가 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복 각각에 대해, 제1 디바이스가 그 반복에 참여할지를 결정할 수 있게 하는 정보를 전송하는 단계를 포함할 수 있다. 본 개시의 제2 광범위한 양상에 따라, 제1 디바이스가 AI/ML 모델 훈련 절차의 하나 이상의 반복에 참여할지 여 부를 디바이스들이 결정할 수 있게 하는 정보를 제공하고, 디바이스들로부터의 AI/ML 모델 훈련 능력 피드백에 그 정보를 근거로 사용하는 것은 몇 가지 장점을 가질 수 있다. 예를 들어, 현재 보고된 해당 AI/ML 모델 훈련 능력에 기초하여 AI/ML 모델 훈련 절차의 하나 이상의 반복에 참여하도록 디바이스를 선택적으로 포함하거나 제 외하면, 본 명세서에서 더 상세하게 논의되는 바와 같이, 잠재적으로 훈련 레이턴시를 감소시켜 빠른 훈련 수렴 을 달성하고 및/또는 AI/ML 모델 훈련 절차와 관련된 통신 오버헤드를 감소시킬 수 있다. 일부 실시예에서, AI/ML 모델 훈련 능력은: i) 제1 디바이스의 현재 처리 능력; ii) 제1 디바이스에서 반복적인 AI/ML 모델 훈련 프로세스를 위해 이용 가능한 훈련 데이터의 현재 양; 및/또는 iii) 반복적인 AI/ML 모델 훈련 프로세스를 위한 훈련 데이터를 수집하기 위한 제1 디바이스의 센싱 능력을 포함한다. 일부 실시예에서, 제1 디바이스의 AI/ML 모델 훈련 능력은 미리 정의되거나 구성된 AI/ML 모델 훈련 능력 타입 의 계층 구조 중에서 선택된 AI/ML 모델 훈련 능력 타입을 포함한다. 일부 실시예에서, 제1 디바이스로부터 AI/ML 모델 훈련 능력을 수신하는 것은, 미리 정의되거나 구성된 AI/ML 모델 훈련 능력 타입의 계층 구조 중에서 선택된 AI/ML 모델 훈련 능력 타입에 대응하는 인덱스를 수신하는 것 을 포함한다. 일부 실시예에서, 본 개시의 제2 광의의 양상에 따른 방법은 AI/ML 모델 훈련 프로세스의 주어진 반복을 위한 데이터 또는 제어 정보의 전송을 스케줄링하는 제어 시그널링을 전송하는 단계를 포함한다. 이러한 실시예들에 서, 제1 디바이스로부터 AI/ML 모델 훈련 능력을 수신하는 것은, 주어진 반복을 위한 데이터 또는 제어 정보의 전송을 스케줄링하는 제어 시그널링이 전송된 후에, 제1 디바이스로부터 AI/ML 모델 훈련 능력을 수신하는 것을 포함할 수 있다. 일부 실시예에서, 주어진 반복을 위한 데이터 또는 제어 정보의 전송을 스케줄링하는 제어 시그널링은 주어진 반복에 대해 제1 디바이스에 의해 사용될 물리적 업링크 제어 채널(PUCCH) 자원을 식별하는 제어 정보를 포함한 다. 이러한 실시예들에서, 제1 디바이스로부터 AI/ML 모델 훈련 능력을 수신하는 것은 PUCCH 자원 상에서 주어 진 반복에 대한 AI/ML 모델 훈련 능력을 수신하는 것을 포함할 수 있다. 일부 실시예에서, 주어진 반복에 대한 데이터 또는 제어 정보의 전송을 스케줄링하는 제어 시그널링은 다운링크 제어 정보(DCI)를 포함하며, 여기서 DCI는 주어진 반복을 위해 제1 디바이스에 의해 사용될 PUCCH 자원을 나타 낸다. 일부 실시예에서, 데이터 또는 제어 정보는 제2 디바이스에서의 AI/ML 모델의 훈련에 기초한 AI/ML 모델 파라미 터 업데이트를 포함하는 제2 디바이스로부터의 AI/ML 모델 업데이트 정보를 포함한다. 일부 실시예에서, 제1 디바이스로부터 AI/ML 모델 훈련 능력을 수신하는 것은, 제1 디바이스를 포함하는 복수의 디바이스들 중 각 디바이스로부터 각각의 AI/ML 모델 훈련 능력을 수신하는 것을 포함한다. 이러한 실시예에서, 제2 디바이스는 복수의 디바이스의 각 디바이스로부터 수신된 각각의 AI/ML 모델 훈련 능력에 기초하여, 복수의 디바이스의 각 디바이스가 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복마다, 디바이스가 반복에 참여할지를 결정할 수 있도록 하는 정보를 전송할 수 있다. 일부 실시예에서, 각 디바이스가 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복마다, 디바이스가 반복에 참여 할지 여부를 결정할 수 있도록 하는 정보를 전송하는 것은, 복수의 디바이스의 각 디바이스에 대한 제어 시그널 링을 전송하여, 복수의 디바이스의 각 디바이스를 AI/ML 모델 훈련 프로세스의 각 반복마다, 디바이스가 반복에 참여할지를 결정하기 위한 디바이스별 규칙으로 구성하는 것을 포함한다. 일부 실시예에서, AI/ML 모델 훈련 프로세스의 반복은 반복 식별자(ID)의 각각의 값과 연관되되, 반복 ID의 각 각의 값은 각 후속 반복에 대해 1씩 증가되도록 한다. 이러한 실시예에서, 복수의 디바이스가 구성되는 디바이 스별 규칙은 복수의 디바이스의 각 디바이스가 주어진 반복과 연관된 반복 ID의 각각의 값에 기초하여 주어진 반복에 선택적으로 참여하도록 구성할 수 있다. 일부 실시예에서, 본 개시의 제2 광의의 양상에 따른 방법은 AI/ML 모델 훈련 프로세스의 반복을 위해, 주어진 반복과 연관된 반복 ID의 값을 나타내는 제어 정보를 전송하는 단계를 더 포함한다. 일부 실시예에서, 제1 디바이스가 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복 각각에 대해, 제1 디바이스 가 그 반복에 참여할지 여부를 결정할 수 있게 하는 정보를 전송하는 것은, AI/ML 모델 훈련 프로세스의 반복에 대해, AI/ML 모델 훈련 능력 타입의 미리 정의되거나 구성된 계층구조 중에서 반복에 참여할 적어도 하나의 AI/ML 모델 훈련 능력 타입을 나타내는 제어 정보를 전송하는 것을 포함한다. 일부 실시예에서, 제1 디바이스가 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복마다, 제1 디바이스가 반복에 참여할지를 결정할 수 있게 하는 정보를 전송하는 것은, AI/ML 모델 훈련 프로세스의 주어진 반복에 대해 데이 터 또는 제어 정보의 전송을 스케줄링하기 위한 제1 스케줄링 정보를 포함하는 제1 다운링크 제어 정보(DCI)를 전송하는 것을 포함한다. 이러한 실시예들에서, 제1 DCI의 순환 중복 검사(CRC) 값은 제1 무선 네트워크 임시 식별자(RNTI)와 스크램블링될 수 있고, 제2 디바이스는 제1 모니터링 주기성에 따라 제1 디바이스가 제1 DCI를 모니터링하도록 구성하기 위한 제어 시그널링을 전송할 수 있다. 일부 실시예에서, 본 개시의 제2 광의의 양상에 따른 방법은 다른 데이터 또는 제어 정보의 전송을 스케줄링하 기 위한 제2 스케줄링 정보를 포함하는 제2 DCI를 전송하는 단계를 더 포함한다. 이러한 실시예들에서, 제2 DCI 의 CRC 값은 제1 RNTI와 다른 제2 RNTI로 스크램블될 수 있고, 제2 디바이스는 제2 모니터링 주기성에 따라 제2 DCI를 모니터링하도록 제1 디바이스를 구성하기 위한 디바이스별 제어 시그널링을 전송할 수 있다. 일부 실시예에서, 제2 모니터링 주기성은 제1 모니터링 주기성과 별도로 구성된다. 일부 실시예에서, 제1 디바이스가 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복마다, 제1 디바이스가 반복에 참여할지 여부를 결정할 수 있게 하는 정보를 전송하는 것은, 제1 모니터링 주기성과 다른 제3 모니터링 주기성 에 따라 제1 DCI를 모니터링하도록 제3 디바이스를 구성하기 위한 제어 시그널링을 전송하는 것을 더 포함한다. 일부 실시예에서, 제1 RNTI는 셀 RNTI(C-RNTI)와 상이하다. 일부 실시예에서, 본 개시의 제2 광의의 양상에 따른 방법은 AI/ML 모델 훈련 프로세스의 주어진 반복에 대해, 제1 디바이스로부터 로컬 AI/ML 모델 업데이트 정보를 수신하는 단계를 더 포함하고, 제1 디바이스로부터의 로 컬 AI/ML 모델 업데이트 정보는 제1 디바이스에서의 로컬 AI/ML 모델의 훈련에 기초한 AI/ML 모델 파라미터 업 데이트를 포함하고, 제1 디바이스에서의 로컬 AI/ML 모델의 훈련은 AI/ML 모델 훈련 프로세스의 주어진 반복을 위해 제2 디바이스로부터 전송되는 데이터 또는 제어 정보에 기초한다. 이러한 실시예에서, 제1 디바이스로부 터의 로컬 AI/ML 모델 업데이트 정보는 제1 디바이스가 제2 디바이스로부터 데이터 또는 제어 정보를 수신한 주 어진 반복과 연관된 반복 ID의 값을 나타내는 정보를 더 포함할 수 있다. 일부 실시예에서, 본 개시의 제2 광의의 양상에 따른 방법은 제1 디바이스로부터 AI/ML 모델 훈련 프로세스에 참여하기 위한 요청을 수신하는 단계를 더 포함한다. 예를 들어, 제1 디바이스로부터의 요청은 AI/ML 모델 훈 련 프로세스의 주어진 반복과 연관된 반복 ID의 값을 나타내는 정보를 포함할 수 있다. 일부 실시예에서, 본 개시의 제2 광의의 양상에 따른 방법은 제1 디바이스에서의 로컬 AI/ML 모델의 파라미터의 부분적 서브세트를 포함하는 부분적 AI/ML 모델을 훈련하도록 제1 디바이스를 구성하기 위한 제1 디바이스용 제 어 시그널링을 전송하는 단계를 더 포함한다. 일부 실시예에서, 본 개시의 제2 광의의 양상에 따른 방법은 제1 디바이스로부터 로컬 AI/ML 모델 업데이트 정 보를 수신하는 단계를 더 포함하되, 제1 디바이스로부터의 로컬 AI/ML 모델 업데이트 정보는 제1 디바이스에서 의 부분적 AI/ML 모델의 훈련에 기초한 파라미터의 부분적 서브세트에 대한 AI/ML 모델 파라미터 업데이트를 포 함한다. 일부 실시예에서, 제1 디바이스가 AI/ML 모델 훈련 프로세스의 적어도 하나의 반복 각각에 대해, 제1 디바이스 가 그 반복에 참여할지 여부를 결정할 수 있게 하는 정보를 전송하는 것은, 제1 디바이스로부터 수신된 AI/ML 모델 훈련 능력에 기초하여, 제1 디바이스가 AI/ML 모델 훈련 프로세스에 참여하지 않도록 구성하기 위한 제1디바이스용 제어 시그널링을 전송하는 것을 포함한다. 일부 실시예에서, 본 개시의 제2 광의의 양상에 따른 방법은 AI/ML 모델 훈련 프로세스에 참여하지 않기 위한 요청을 제1 디바이스로부터 수신하는 단계를 더 포함한다. 방법들을 수행하기 위한 대응하는 장치 및 디바이스가 개시된다. 예를 들어, 본 개시의 다른 양상에 따르면, 프로세서 및 프로세서 실행가능 명령어를 저장하는 메모리를 포함하 는 장치가 제공되며, 프로세서 실행가능 명령어는 실행될 때, 프로세서로 하여금 전술한 본 개시의 제1 광의의 양상에 따른 방법을 수행하게 한다. 다른 예로서, 본 개시의 다른 양상에 따르면, 프로세서 및 프로세서 실행가능 명령어를 저장하는 메모리를 포함 하는 장치가 제공되며, 프로세서 실행가능 명령어는 실행될 때, 프로세서로 하여금 전술한 본 개시의 제2 광의 의 양상에 따른 방법을 수행하게 한다. 본 개시의 다른 양상에 따르면, 본 개시에 개시된 방법 양상 중 임의의 양상을 구현하기 위한 하나 이상의 유닛 을 포함하는 장치가 제공된다. “유닛\"이라는 용어는 넓은 의미로 사용되며, 예를 들어, 모듈, 컴포넌트, 요소, 수단 등을 포함하는 다양한 명칭으로 지칭될 수 있다. 유닛은 하드웨어, 소프트웨어, 펌웨어 또는 이들의 임의 의 조합을 사용하여 구현될 수 있다. 방법들을 수행하기 위한 대응하는 장치 및 디바이스가 개시된다. 예를 들어, 본 개시의 다른 양상에 따르면, 프로세서 및 프로세서 실행가능 명령어를 저장하는 메모리를 포함하 는 디바이스가 제공되며, 프로세서 실행가능 명령어는 실행될 때, 프로세서로 하여금 전술한 본 개시의 제1 광 의의 양상에 따른 방법을 수행하게 한다. 본 개시의 다른 양상에 따르면, 본 개시에 개시된 방법 양상 중 임의의 양상을 구현하기 위한 하나 이상의 유닛 을 포함하는 장치가 제공된다. “유닛\"이라는 용어는 넓은 의미로 사용되며, 예를 들어, 모듈, 컴포넌트, 요소, 수단 등을 포함하는 다양한 명칭으로 지칭될 수 있다. 유닛은 하드웨어, 소프트웨어, 펌웨어 또는 이들의 임의 의 조합을 사용하여 구현될 수 있다."}
{"patent_id": "10-2024-7032742", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "예시적인 목적을 위해, 이제 구체적인 실시예들이 도면과 함께 아래에서 보다 상세하게 설명될 것이다. 예시적인 통신 시스템 및 디바이스 도 1을 참조하여, 제한이 아닌 예시적인 예로서, 통신 시스템의 단순화된 개략도가 제공된다. 통신 시스템 은 무선 액세스 네트워크를 포함한다. 무선 액세스 네트워크는 차세대(예컨대, 6세대(6G) 이상) 무선 액세스 네트워크 또는 레거시(예컨대, 5G, 4G, 3G 또는 2G) 무선 액세스 네트워크일 수 있다. 하나 이상의 통신 전기 디바이스(ED)(110a-120j)(일반적으로 110으로 지칭됨)는 서로 상호 연결되거나 무선 액세스 네트워크 에서 하나 이상의 네트워크 노드(170a, 170b, 일반적으로 170으로 지칭됨)에 연결될 수 있다. 코어 네트워 크는 통신 시스템의 일부일 수 있으며, 통신 시스템에서 사용되는 무선 액세스 기술에 의존적이거나 독립적일 수 있다. 또한, 통신 시스템은 공중 교환 전화망(PSTN), 인터넷 및 기타 네트워크 를 포함한다. 도 2는 예시적인 통신 시스템을 도시한다. 일반적으로, 통신 시스템은 다수의 무선 또는 유선 요소 들이 데이터 및 기타 콘텐츠를 통신할 수 있도록 한다. 통신 시스템의 목적은 브로드캐스트, 멀티캐스트 및 유니캐스트 등을 통해 음성, 데이터, 비디오 및/또는 텍스트와 같은 컨텐츠를 제공하는 것일 수 있다. 통신 시스템은 컴포넌트들 간에 반송파 스펙트럼 대역폭과 같은 자원을 공유함으로써 작동할 수 있다. 통신 시 스템은 지상 통신 시스템 및/또는 비지상 통신 시스템을 포함할 수 있다. 통신 시스템은 광범위한 통신 서비스 및 애플리케이션(예컨대, 지구 모니터링, 원격 감지, 수동 감지 및 위치 파악, 내비게이션 및 추적, 자율 배송 및 이동성 등)을 제공할 수 있다. 통신 시스템은 지상 통신 시스템과 비지상 통신 시스템 의 공동 운영을 통해 높은 수준의 가용성 및 견고성을 제공할 수 있다. 예를 들어, 비지상 통신 시스템(또는 그 의 컴포넌트)을 지상 통신 시스템에 통합하면 여러 계층으로 구성된 이기종 네트워크로 간주될 수 있다. 종래의 통신 네트워크와 비교하여, 이종 네트워크는 지상 네트워크와 비지상 네트워크 사이에서 효율적인 다중 링크 공 동 운영, 보다 유연한 기능 공유 및 보다 빠른 물리 계층 링크 스위칭을 통해 전반적인 성능을 향상시킬 수 있 다. 지상 통신 시스템과 비지상 통신 시스템은 통신 시스템의 서브 시스템으로 간주될 수 있다. 도시된 예에서, 통 신 시스템은 전자 디바이스(ED)(110a-110d)(일반적으로 ED이라고 지칭함), 무선 액세스 네트워크 (RAN)(120a-120b), 비지상 통신 네트워크(120c), 코어 네트워크, 공중 교환 전화 네트워크(PSTN), 인터넷 및 기타 네트워크를 포함한다. RAN(120a-120b)은 일반적으로 지상 송수신 지점(T-TRP)(170a- 170b)으로 지칭될 수 있 각각의 기지국(BS)(170a-170b)을 포함한다. 비지상 통신 네트워크(120c)는 일반적으로 비지상 송신 및 수신 지점(NT-TRP)으로 지칭될 수 있는 액세스 노드(120c)를 포함다. 임의의 ED는 대안적으로 또는 추가적으로, 임의의 다른 T-TRP(170a-170b) 및 NT-TRP, 인터넷, 코어 네트워크, PSTN, 다른 네트워크 또는 전술한 것들의 임의의 조합과 인터페이싱하도록, 그 에 액세스하도록 또는 그와 통신하도록 구성될 수 있다. 일부 예에서, ED(110a)는 인터페이스(190a)를 통해 업 링크 및/또는 다운링크 전송을 T-TRP(170a)와 통신할 수 있다. 일부 예에서, ED(110a, 110b 및 110d)는 또한 하나 이상의 사이드 링크 무선 인터페이스(190b)를 통해 서로 직접 통신할 수도 있다. 일부 예에서, ED(110d)는 인터페이스(190c)를 통해 업링크 및/또는 다운링크 전송을 NT-TRP와 통신할 수 있다. 무선 인터페이스(190a 및 190b)는 임의의 적합한 무선 액세스 기술과 같은 유사한 통신 기술을 사용할 수 있다. 예를 들어, 통신 시스템은 무선 인터페이스(190a 및 190b)에서 코드 분할 다중 액세스(CDMA), 시분할 다중 액세스(TDMA), 주파수 분할 다중 액세스(FDMA), 직교 FDMA(OFDMA) 또는 단일 반송파 FDMA(SC-FDMA)와 같은 하 나 이상의 채널 액세스 방법을 구현할 수 있다. 무선 인터페이스(190a 및 190b)는 직교 및/또는 비직교 차원의 조합을 포함할 수 있는 다른 고차원 신호 공간을 활용할 수 있다. 무선 인터페이스(190c)는 무선 링크 또는 단순히 링크를 통해 ED(110d)와 하나 또는 다수의 NT-TRP 사이의 통신을 가능하게 할 수 있다. 일부 예에서, 링크는 유니캐스트 전송을 위한 전용 연결, 브로드캐스트 전송을 위 한 연결, 또는 멀티캐스트 전송을 위한 ED 그룹과 하나 또는 다수의 NT-TRP 사이의 연결이다. RAN(120a 및 120b)은 코어 네트워크와 통신하여 음성, 데이터 및 기타 서비스와 같은 다양한 서비스를 ED(110a, 110b 및 110c)에 제공한다. RAN(120a 및 120b) 및/또는 코어 네트워크는, 코어 네트워크에 의해 직접 서비스될 수도 있고 그렇지 않을 수도 있고, 또한 RAN(120a), RAN(120b) 또는 둘 다와 동일한 무 선 액세스 기술을 사용할 수도 또는 사용하지 않을 수도 있는 하나 이상의 다른 RAN(도시되지 않음)과 직접 또 는 간접 통신할 수 있다. 코어 네트워크는 또한 (i) RAN(120a 및 120b) 또는 ED(110a 110b 및 110c) 또 는 둘 모두와 (ii) 다른 네트워크(예컨대, PSTN, 인터넷 및 기타 네트워크) 사이의 게이트웨이 액세스 역할을 할 수도 있다. 또한, ED(110a 110b 및 110c)의 일부 또는 전부는 상이한 무선 기술 및/또는 프 로토콜을 사용하여 상이한 무선 링크를 통해 상이한 무선 네트워크와 통신하는 기능을 포함할 수 있다. 무선 통신 대신(또는 이에 부가하여), ED(110a, 110b 및 110c)는 유선 통신 채널을 통해 서비스 제공자 또는 스위치 (도시되지 않음) 및 인터넷과 통신할 수 있다. PSTN은 전통 아날로그 전화 서비스(POTS)를 제공하기 위한 회로 전환 전화 네트워크를 포함할 수 있다. 인터넷은 컴퓨터들의 네트워크 및 서브넷(인트라넷) 또 는 둘 다를 포함할 수 있으며, 인터넷 프로토콜(IP), 전송 제어 프로토콜(TCP), 사용자 데이터그램 프로토콜 (UDP)과 같은 프로토콜들을 통합할 수 있다. ED(110a, 110b, 및 110c)는 다수의 무선 액세스 기술에 따라 동작 할 수 있는 멀티모드 디바이스일 수 있고, 이를 지원하는 데 필요한 다수의 트랜시버를 통합할 수 있다. 도 3은 ED 및 기지국(170a, 170b 및/또는 170c)의 또 다른 예를 도시한다. ED는 사람, 물체, 머신 등을 연결하는 데 사용된다. ED는 셀룰러 통신, 디바이스 대 디바이스(D2D), 차량 대 모든 것(V2X), 피어 투 피어(P2P), 머신 대 머신(M2M), 머신형 통신(MTC), 사물 인터넷(IOT), 가상 현실(VR), 증강 현실(AR), 산업 제어, 자율주행, 원격 의료, 스마트 그리드, 스마트 가구, 스마트 오피스, 스마트 웨어러블, 스마트 교통, 스마 트 시티, 드론, 로봇, 원격 감지, 수동 감지, 포지셔닝, 내비게이션 및 추적, 자율 배송 및 모빌리티 등과 같은 다양한 시나리오에서 널리 사용될 수 있다. 각 ED는 무선 작동을 위한 임의의 적합한 최종 사용자 디바이스를 나타내며, 다른 가능성 중에서도, 사용 자 장비/디바이스(UE), 무선 송수신 유닛(WTRU), 모바일 스테이션, 고정 또는 이동 가입자 유닛, 셀룰러 전화, 스테이션(STA), 머신형 통신(MTC) 디바이스, 개인 디지털 비서(PDA), 스마트폰, 랩탑, 컴퓨터, 태블릿, 무선 센 서, 소비자 가전 디바이스, 스마트 북, 차량, 자동차, 트럭, 버스, 기차 또는 IoT 디바이스, 산업용 디바이스 또는 전술한 디바이스 내의 장치(예를 들어, 통신 모듈, 모뎀, 또는 칩)과 디바이스를 포함할 수 있다(또는 그 와 같이 지칭될 수 있다). 미래 세대 ED는 다른 용어를 사용하여 언급될 수 있다. 기지국(170a 및 170 b)은 T-TRP이며, 이하에서는 T-TRP로 지칭될 것이다. 또한, 도 3에 도시된 바와 같이, NT-TRP는 이후 NT-TRP로 지칭될 것이다. T-TRP 및/또는 NT-TRP에 연결된 각 ED는 동적 또는 반정적으로 켜지고(즉, 설정, 활성화 또는 인에이블), 꺼지고(즉, 해제, 비활성화 또는 디스에이블), 및/또는 연결 가용성 및 연결 필요성 중 하나 이상에 대응하여 구성될 수 있다. ED는 하나 이상의 안테나에 결합된 송신기 및 수신기를 포함한다. 하나의 안테나만 이 도시된다. 안테나의 하나, 일부 또는 전부는 대안적으로 패널일 수 있다. 송신기와 수신기는 예 를 들어 트랜시버로 통합될 수 있다. 트랜시버는 적어도 하나의 안테나 또는 네트워크 인터페이스 제어기 (NIC)에 의해 전송하기 위해 데이터 또는 기타 콘텐츠를 변조하도록 구성된다. 트랜시버는 또한 적어도 하나의 안테나에 의해 수신된 데이터 또는 다른 콘텐츠를 복조하도록 구성된다. 각 트랜시버는 무선 또는 유선 전 송을 위한 신호를 생성 및/또는 무선 또는 유선으로 수신된 신호를 처리하기 위한 임의의 적합한 구조를 포함한 다. 각 안테나는 무선 또는 유선 신호를 송신 및/또는 수신하기 위한 임의의 적합한 구조를 포함한다. ED는 적어도 하나의 메모리를 포함한다. 메모리는 ED에 의해 사용, 생성 또는 수집된 명령 어 및 데이터를 저장한다. 예를 들어, 메모리는 본 명세서에 설명된 기능 및/또는 실시예들의 일부 또는 전부를 구현하도록 구성되고 처리 유닛(들)에 의해 실행되는 소프트웨어 명령어 또는 모듈을 저장할 수 있 다. 각 메모리는 임의의 적합한 휘발성 및/또는 비휘발성 저장 및 검색 디바이스(들)를 포함한다. 랜덤 액세스 메모리(RAM), 읽기 전용 메모리(ROM), 하드 디스크, 광 디스크, 가입자 식별 모듈(SIM) 카드, 메모리 스 틱, 보안 디지털(SD) 메모리 카드, 온-프로세서 캐시 등과 같은 임의의 적합한 타입의 메모리가 사용될 수 있다. ED는 하나 이상의 입력/출력 디바이스(도시되지 않음) 또는 인터페이스(예컨대, 도 1의 인터넷에 대 한 유선 인터페이스)를 더 포함할 수 있다. 입력/출력 디바이스는 사용자 또는 네트워크의 다른 디바이스와의 상호작용을 허용한다. 각 입력/출력 디바이스는 네트워크 인터페이스 통신을 포함하여, 스피커, 마이크, 키패 드, 키보드, 디스플레이 또는 터치 스크린과 같이 사용자에게 정보를 제공하거나 사용자로부터 정보를 수신하기 위한 임의의 적합한 구조를 포함한다. ED는 NT-TRP 및/또는 T-TRP로의 업링크 전송물의 전송을 준비하는 것과 관련된 동작, NT- TRP 및/또는 T-TRP로부터 수신된 다운링크 전송물을 처리하는 것과 관련된 동작, 및 다른 ED와 의 사이드링크 전송물을 처리하는 것과 관련된 동작을 포함하는 동작들을 수행하기 위한 프로세서를 더 포 함한다. 업링크 전송물의 전송을 준비하는 것과 관련된 처리 동작은 인코딩, 변조, 전송 빔포밍 및 전송용 심 볼의 생성 등의 동작을 포함할 수 있다. 다운링크 전송물을 처리하는 것과 관련된 처리 동작은 수신 빔포밍, 수신된 심볼의 복조 및 디코딩과 같은 동작을 포함할 수 있다. 실시예에 따라, 다운링크 전송물은 수신기(20 3)에 의해 아마도 수신 빔포밍을 사용하 수신될 수 있고, 프로세서는 다운링크 전송물로부터 (예를 들어, 시그널링을 검출 및/또는 디코딩하여) 시그널링을 추출할 수 있다. 시그널링의 예는 NT-TRP 및/또는 T- TRP에 의해 전송되는 참조 신호일 수 있다. 일부 실시예에서, 프로세서는 T-TRP로부터 수신된 빔 방향의 표시, 예를 들어 빔 각도 정보(BAI)에 기초하여 송신 빔포밍 및/또는 수신 빔포밍을 구현한다. 일부 실시예에서, 프로세서는 네트워크 액세스(예컨대, 초기 액세스) 및/또는 다운링크 동기화와 관련된 동작들, 예를 들어 동기화 시퀀스의 검출, 시스템 정보의 디코딩 및 획득 등과 관련된 동작들을 수행할 수 있다. 일부 실시예에서, 프로세서는 예를 들어, NT-TRP 및/또는 T-TRP로부터 수신된 참조 신호 를 사용하여, 채널 추정을 수행할 수 있다. 예시되지는 않았지만, 프로세서는 송신기 및/또는 수신기의 일부를 형성할 수 있다. 도시되지는 않았지만, 메모리는 프로세서의 일부를 형성할 수 있다. 프로세서, 및 송신기 및 수신기의 처리 컴포넌트들은 각각 메모리(예컨대, 메모리)에 저장 된 명령어들을 실행하도록 구성되는 동일하거나 다른 하나 이상의 프로세서에 의해 구현될 수 있다. 대안적으로, 프로세서, 및 송신기 및 수신기의 처리 컴포넌트의 일부 또는 전부는 프로그래밍된 필드 프로그래머블 게이트 어레이(FPGA), 그래픽 처리 유닛(GPU) 또는 애플리케이션별 집적 회로(ASIC)와 같은 전용 회로를 사용하여 구현될 수 있다. T-TRP는 일부 구현에서 다양한 가능성 중에서도, 기지국, 베이스 트랜시버 스테이션(BTS), 무선 기지국, 네트워크 노드, 네트워크 디바이스, 네트워크 측 디바이스, 송신/수신 노드, 노드 B, 진화된 노드B(eNodeB 또는 eNB), 홈 eNodeB, 차세대 노드B(gNB), 전송 지점(TP), 사이트 제어기, 액세스 포인트(AP), 또는 무선 라우터, 중계 스테이션, 원격 무선 헤드, 지상 노드, 지상 네트워크 디바이스 또는 지상 기지국, 베이스 밴드 유닛 (BBU), 원격 무선 유닛(RRU), 액티브 안테나 유닛(AAU), 원격 무선 헤드(RRH), 중앙 유닛(CU), 분산 유닛(DU), 포지셔닝 노드 등과 같은 다른 명칭으로 알려질 수 있다. T-TRP는 매크로 BS, 피코 BS, 중계 노드, 도너 노드 등, 또는 이들의 조합일 수 있다. T-TRP는 전술한 디바이스들 또는 전술한 디바이스들 내의 장치(예 컨대, 통신 모듈, 모뎀, 또는 칩)를 지칭할 수 있다. 일부 실시예에서, T-TRP의 부분들은 분산될 수 있다. 예를 들어, T-TRP의 일부 모듈들은 T- TRP의 안테나들을 하우징하는 장비로부터 원거리에 위치할 수 있고, 공용 무선 인터페이스(CPRI)와 같은 프론트 홀이라고도 하는 통신 링크(도시되지 않음)를 통해 안테나들을 하우징하는 장비에 결합될 수 있다. 따라 서, 일부 실시예에서, T-TRP라는 용어는 ED의 위치 결정, 자원 할당(스케줄링), 메시지 생성 및 인코 딩/디코딩과 같은 처리 동작을 수행하고, 반드시 T-TRP의 안테나들을 하우징하는 장비의 일부일 필요는 없 는 네트워크 측의 모듈을 지칭할 수도 있다. 모듈들은 또한 다른 T-TRP에 결합될 수도 있다. 일부 실시예에서, T-TRP는, 예를 들어, 조정된 멀티포인트 전송을 통해, ED에 서비스를 제공하기 위해 함께 동작하는 복수의 T-TRP일 수 있다. T-TRP는 하나 이상의 안테나에 결합된 적어도 하나의 송신기 및 적어도 하나의 수신기를 포함한다. 하나의 안테나만이 도시된다. 대안으로, 안테나들 중 하나, 일부 또는 전부는 패널일 수도 있 다. 송신기와 수신기는 트랜시버로서 통합될 수 있다. T-TRP는 또한 ED로의 다운링크 전 송물의 전송을 준비하는 것, ED로부터 수신된 업링크 전송물을 처리하는 것, NT-TRP로의 백홀 전송물 의 전송을 준비하는 것, 및 NT-TRP로부터 백홀을 통해 수신된 전송물을 처리하는 것과 관련된 동작들을 포 함하는 동작들을 수행하기 위한 프로세서를 더 포함한다. 다운링크 또는 백홀 전송물의 전송을 준비하는 것과 관련된 처리 동작은 인코딩, 변조, 프리코딩(예컨대, MIMO 프리코딩), 전송 빔포밍 및 전송용 심볼 생성 등의 동작을 포함할 수 있다. 업링크 또는 백홀을 통해 수신된 전송물을 처리하는 것과 관련된 처리 동작은 수 신 빔포밍, 수신된 심볼의 복조 및 디코딩과 같은 동작을 포함할 수 있다. 프로세서는 또한 동기화 신호 블록(SSB)의 컨텐츠 생성, 시스템 정보 생성 등과 같은, 네트워크 액세스(예를 들어, 초기 액세스) 및/또는 다 운링크 동기화와 관련된 동작을 수행할 수 있다. 일부 실시예에서, 프로세서는 또한 스케줄러에 의해 전송을 위해 스케줄링될 수 있는 BAI와 같은 빔 방향의 표시를 생성한다. 프로세서는 ED의 위치 결정, NT-TRP를 배치할 위치 결정 등과 같이 본 명세서에 설명된 다른 네트워크 측 처리 동작을 수행한다.일부 실시예에서, 프로세서는 예를 들어, ED의 하나 이상의 파라미터 및/또는 NT-TRP의 하나 이 상의 파라미터를 구성하기 위한 시그널링을 생성할 수 있다. 프로세서에 의해 생성된 모든 시그널링은 송 신기에 의해 전송된다. 본 명세서에서 사용되는 \"시그널링\"은 제어 시그널링이라고도 불릴 수 있음에 유의 한다. 동적 시그널링은 제어 채널, 예를 들어 물리적 다운링크 제어 채널(PDCCH)에서 전송될 수 있고, 정적 또 는 반정적 상위 계층 시그널링은 데이터 채널, 예를 들어 물리적 다운링크 공유 채널(PDSCH)에서 전송되는 패킷 에 포함될 수 있다. 스케줄러는 프로세서에 결합될 수 있다. 스케줄러는 T-TRP 내에 포함되거나 이와 별도로 동작할 수 있으며, 스케줄링 그랜트(grant)를 발행하고 및/또는 스케줄링이 필요없는(\"구성된 그랜트\") 자원을 구성하는 것을 포함하여, 업링크, 다운링크 및/또는 백홀 전송을 스케줄링할 수 있다. T-TRP는 정보 및 데이터를 저장하기 위한 메모리를 더 포함한다. 메모리는 T-TRP에 의해 사용, 생성 또는 수집된 명령어 및 데이터를 저장한다. 예를 들어, 메모리는 본 명세서에 설명된 기능 및/또는 실시예들의 일부 또 는 전부를 구현하도록 구성되고 프로세서에 의해 실행되는 소프트웨어 명령어 또는 모듈을 저장할 수 있다. 예시되지는 않았지만, 프로세서는 송신기 및/또는 수신기의 일부를 형성할 수 있다. 또한, 예시 되지는 않았지만, 프로세서는 스케줄러를 구현할 수 있다. 도시되지는 않았지만, 메모리는 프로 세서의 일부를 형성할 수 있다. 프로세서, 스케줄러, 및 송신기 및 수신기의 처리 컴포넌트들은 각각 메모리, 예를 들어 메모리에 저장된 명령어를 실행하도록 구성되는 동일하거나 다른 하나 이상의 프로세서에 의해 구현될 수 있다. 대안적으로, 프로세서, 스케줄러, 및 송신기 및 수신기의 처리 컴포넌트들의 일부 또는 전부는 FPGA, GPU 또는 ASIC과 같은 전용 회로를 사용하여 구현될 수 있다. NT-TRP는 예시로서만 드론으로 도시되었지만, NT-TRP는 임의의 적합한 비지상 형태로 구현될 수 있다. 또한, NT-TRP는 일부 구현에서 비지상 노드, 비지상 네트워크 디바이스, 또는 비지상 기지국과 같 은 다른 명칭으로 알려질 수 있다. NT-TRP는 하나 이상의 안테나에 결합된 송신기 및 수신기 를 포함한다. 도면에는 하나의 안테나만 도시되어 있다. 대안으로, 안테나들 중 하나, 일부 또는 전 부가 패널일 수도 있다. 송신기와 수신기는 트랜시버로 통합될 수 있다. NT-TRP는 또한 ED(11 0)로의 다운링크 전송물의 전송을 준비하는 것, ED로부터 수신된 업링크 전송물을 처리하는 것, T- TRP로의 백홀 전송물의 전송을 준비하는 것, 및 T-TRP로부터 백홀을 통해 수신된 전송물의 처리와 관 련된 동작들을 포함하는 동작들을 수행하기 위한 프로세서를 더 포함한다. 다운링크 또는 백홀 전송물의 전송을 준비하는 것과 관련된 처리 동작은 인코딩, 변조, 프리코딩(예컨대, MIMO 프리코딩), 전송 빔포밍 및 전 송용 심볼 생성 등의 동작을 포함할 수 있다. 업링크 또는 백홀을 통해 수신된 전송물을 처리하는 것과 관련된 처리 동작은 수신 빔포밍, 수신된 심볼의 복조 및 디코딩과 같은 동작을 포함할 수 있다. 일부 실시예에서, 프 로세서는 T-TRP로부터 수신된 빔 방향 정보(예를 들어, BAI)에 기초하여 송신 빔포밍 및/또는 수신 빔포밍을 구현한다. 일부 실시예에서, 프로세서는 예를 들어, ED의 하나 이상의 파라미터를 구성하 기 위한 시그널링을 생성할 수 있다. 일부 실시예에서, NT-TRP는 물리 계층 처리를 구현하지만, 매체 액 세스 제어(MAC) 또는 무선 링크 제어(RLC) 계층에서의 기능과 같은 상위 계층 기능들을 구현하지는 않는다. 이 는 단지 예시일 뿐이므로, 보다 일반적으로, NT-TRP 172는 물리 계층 처리 이외에 상위 계층 기능을 구현할 수 도 있다. NT-TRP는 정보 및 데이터를 저장하기 위한 메모리를 더 포함한다. 예시되지는 않았지만, 프로세서 는 송신기 및/또는 수신기의 일부를 형성할 수 있다. 도시되지는 않았지만, 메모리는 프로 세서의 일부를 형성할 수 있다. 프로세서, 및 송신기 및 수신기의 처리 컴포넌트들은 각각 메모리, 예를 들어 메모리에 저 장된 명령어들을 실행하도록 구성되는 동일하거나 다른 하나 이상의 프로세서에 의해 구현될 수 있다. 대안적으 로, 프로세서, 및 송신기 및 수신기의 처리 컴포넌트들 중 일부 또는 전부는 프로그래밍된 FPGA, GPU 또는 ASIC과 같은 전용 회로를 사용하여 구현될 수 있다. 일부 실시예에서, NT-TRP는 실제로, 예를 들어 조정된 멀티포인트 전송을 통해, ED에 서비스를 제공하기 위해 함께 동작하는 복수의 NT-TRP일 수 있다. 본 명세서에서 사용되는 \"TRP\"는 T-TRP 또는 NT-TRP를 지칭할 수 있음에 유의한다. T-TRP, NT-TRP 및/또는 ED는 다른 컴포넌트들을 포함할 수 있지만, 명확성을 위해 이들은 생략 되었다. 도 4에 따르면, 본 명세서에 제공된 실시예 방법의 하나 이상의 단계는 대응하는 유닛 또는 모듈에 의해 수행될 수 있다. 도 4는 디바이스, 예를 들어 ED, T-TRP, 또는 NT-TRP 내의 유닛들 또는 모듈들을 예 시한다. 예를 들어, 신호는 송신 유닛 또는 송신 모듈에 의해 전송될 수 있다. 예를 들어, 신호는 송신 유닛 또는 송신 모듈에 의해 전송될 수 있다. 신호는 수신 유닛 또는 수신 모듈에 의해 수신될 수 있다. 신호는 처 리 유닛 또는 처리 모듈에 의해 처리될 수 있다. 다른 단계는 인공 지능(AI) 또는 머신 러닝(ML) 모듈에 의해 수행될 수 있다. 각 유닛 또는 모듈은 소프트웨어를 실행하는 하드웨어, 하나 이상의 컴포넌트 또는 디바이스 또는 이들의 조합을 사용하여 구현될 수 있다. 예를 들어, 하나 이상의 유닛 또는 모듈은 프로그래밍된 FPGA, GPU 또는 ASIC과 같은 집적 회로일 수 있다. 예를 들어, 모듈이 프로세서에 의해 실행되는 소프트웨어를 사용하 여 구현되는 경우, 모듈은 프로세서에 의해, 필요에 따라 전체적으로 또는 부분적으로, 단일 또는 다수의 인스 턴스에서 개별적으로 또는 함께 처리를 위해 검색될 수 있으며, 모듈 자체는 추가 배치 및 인스턴스화를 위한 명령어를 포함할 수 있다는 것이 이해될 것이다. ED, T-TRP 및 NT-TRP에 관한 추가 세부 사항은 당업자에게 공지되어 있다. 따라서, 이러한 세부 사항은 여기서 생략한다. 제어 시그널링은 본 명세서에서의 일부 실시예에서 논의된다. 제어 시그널링은 때때로 시그널링, 제어 정보, 구 성 정보, 또는 구성으로 대신 언급될 수 있다. 일부 경우, 제어 시그널링은 예를 들어 제어 채널의 물리 계층에 서 동적으로 표시될 수 있다. 동적으로 표시되는 제어 시그널링의 예로는 물리 계층 제어 시그널링으로 전송되 는 정보, 예컨대, 다운링크 제어 정보(DCI)가 있다. 제어 시그널링은 예를 들어, RRC 시그널링 또는 MAC 제어 요소(CE)에서는 때때로 반정적으로 표시될 수도 있다. 동적 표시는 상위 계층(예컨대, RRC 시그널링 또는 MAC CE)보다는, 하위 계층(예컨대, 물리 계층/계층 1 시그널링)(가령, DCI)에서 표시될 수 있다. 반정적 표시는 반 정적 시그널링에서의 표시일 수 있다. 여기서 사용되는 반정적 시그널링은 동적이지 않은 시그널링, 예컨대, 상위 계층 시그널링, RRC 시그널링 및/또는 MAC CE를 지칭할 수 있다. 본 명세서에서 사용되는 동적 시그널링 은 동적인 시그널링, 예를 들어, 물리 계층에서 전송되는 물리 계층 제어 시그널링, 가령, DCI를 지칭할 수 있 다. 무선 인터페이스는 일반적으로 둘 이상의 통신 디바이스들 사이에서 무선 통신 링크를 통해 전송물이 송신 및/ 또는 수신되는 방법을 집합적으로 지정하는 다수의 컴포넌트 및 관련 파라미터를 포함한다. 예를 들어, 무선 인터페이스는 무선 통신 링크를 통해 정보(예컨대, 데이터)를 전달하기 위한 파형, 프레임 구조, 다중 액세스 체계, 프로토콜, 코딩 체계 및/또는 변조 체계를 정의하는 하나 이상의 컴포넌트를 포함할 수 있다. 무선 통신 링크는 무선 액세스 네트워크와 사용자 장비 간의 링크(예컨대, \"Uu\" 링크)를 지원할 수 있고, 및/또는 무선 통 신 링크는 두 사용자 장비 간의 링크(예컨대, \"사이드 링크\")와 같이 디바이스와 디바이스 간의 링크를 지원할 수 있고, 및/또는 무선 통신 링크는 비지상(NT)-통신 네트워크와 사용자 장비(UE) 간의 링크를 지원할 수 있다. 다음은 위의 컴포넌트에 대한 몇 가지 예이다: - 파형 컴포넌트는 전송되는 신호의 모양과 형태를 지정할 수 있다. 파형 옵션에는 직교 다중 액세스 파형과 비 직교 다중 액세스 파형이 포함될 수 있다. 이러한 파형 옵션의 비제한적인 예로는 직교 주파수 분할 다중화 (OFDM), 필터링 OFDM(f-OFDM), 타임 윈도우 OFDM, 필터 뱅크 멀티반송파(FBMC), 범용 필터링 멀티반송파 (UFMC), 일반화된 주파수 분할 다중화(GFDM), 웨이블릿 패킷 변조(WPM), 니퀴스트보다 빠른(FTN) 파형, 및 낮은 피크 대 평균 전력 비율 파형(낮은 PAPR WF) 등이 있다. - 프레임 구조 컴포넌트는 프레임 또는 프레임 그룹의 구성을 지정할 수 있다. 프레임 구조 컴포넌트는 시간, 주파수, 파일럿 서명, 코드, 또는 프레임 또는 프레임 그룹의 기타 파라미터 중 하나 이상을 나타낼 수 있다. 프레임 구조에 대한 자세한 내용은 아래에서 설명된다. - 다중 액세스 방식 컴포넌트는 다음과 같이 통신 디바이스가 공통의 물리적 채널을 공유하는 방법을 정의하는 기술을 포함하여 여러 액세스 기술 옵션을 지정할 수 있다: 시분할 다중 액세스(TDMA), 주파수 분할 다중 액세 스(FDMA), 코드 분할 다중 액세스(CDMA), 단일 반송파 주파수 분할 다중 액세스(SC-FDMA), 저밀도 서명 다중 반 송파 코드 분할 다중 액세스(LDS-MC-CDMA), 비직교 다중 액세스(NOMA), 패턴 분할 다중 액세스(PDMA), 격자 분 할 다중 액세스(LPMA), 자원 확산 다중 액세스(RSMA) 및 스파스 코드 다중 액세스(SCMA) 등이 이에 해당한다. 또한, 다중 액세스 기술 옵션에는 스케줄링된 액세스 대 스케줄링되지 않은 액세스(무허가 액세스라고도 함); 예컨대, 비직교 다중 액세스 대 직교 다중 액세스(예컨대, 전용 채널 자원을 통해 이루어짐(예를 들어, 여러 통신 디바이스 간에 공유 없음)); 경합 기반 공유 채널 자원과 비경합 기반 공유 채널 자원, 및 인지 무선 기반 액세스가 포함될 수 있다. - 하이브리드 자동 반복 요청(HARQ) 프로토콜 컴포넌트는 전송 및/또는 재전송 방법을 지정할 수 있다. 전송 및/또는 재전송 메커니즘 옵션의 비제한적인 예는 스케줄링된 데이터 파이프 크기, 전송 및/또는 재전송을 위한 시그널링 메커니즘, 및 재전송 메커니즘을 지정하는 옵션을 포함한다. - 코딩 및 변조 컴포넌트는 전송되는 정보가 전송/수신 목적으로 인코딩/디코딩 및 변조/복조되는 방법을 지정 할 수 있다. 코딩은 오류 감지 및 순방향 오류 수정 방법을 지칭할 수 있다. 코딩 옵션의 예는 터보 트렐리스 코드, 터보 제품 코드, 파운틴 코드, 저밀도 패리티 검사 코드, 폴라 코드 등을 포함한다. 변조는 단순히, 별 자리(예를 들어, 변조 기술 및 순서를 포함)를 지칭할 수도 있고, 또는 보다 구체적으로 계층적 변조 및 낮은 PAPR 변조와 같은 다양한 유형의 고급 변조 방법을 지칭할 수도 있다. 일부 실시예에서, 무선 인터페이스는 \"일괄적인 개념(one-size-fits-all concept)\"일 수 있다. 예를 들어, 무선 인터페이스 내의 컴포넌트들은 일단 무선 인터페이스가 정의되면 변경되거나 조정될 수 없다. 일부 구현에서는, 순환 접두사(CP) 길이 또는 다중 입력 다중 출력(MIMO) 모드와 같은 무선 인터페이스의 제한된 파라미터 또는 모드만이 구성될 수 있다. 일부 실시예에서, 무선 인터페이스 설계는 면허 액세스 및 비면허 액세스 모두를 위 해 6GHz 미만 및 6GHz 초과의 주파수(예컨대, mmWave) 대역을 지원하기 위한 통합 또는 유연한 프레임워크를 제 공할 수 있다. 예를 들어, 확장 가능한 수치학 및 심볼 지속시간에 의해 제공되는 구성 가능한 무선 인터페이 스의 유연성은 다양한 스펙트럼 대역과 다양한 서비스/디바이스에 대한 전송 파라미터 최적화를 허용할 수 있다. 또 다른 예로, 통합 무선 인터페이스는 주파수 영역에 자체적으로 포함될 수 있으며, 주파수 영역의 자 체 포함 설계는 주파수 및 시간 모두에서 서로 다른 서비스 간의 채널 자원 공유를 통해 보다 유연한 무선 액세 스 네트워크(RAN) 슬라이싱을 지원할 수 있다. 프레임 구조 프레임 구조는 시간 영역 신호 전송 구조를 정의하는 무선 통신 물리 계층의 특징으로, 예를 들어 기본 시간 영 역 전송 유닛의 타이밍 참조 및 타이밍 정렬을 허용한다. 통신 디바이스들 간의 무선 통신은 프레임 구조에 의 해 관리되는 시간 주파수 자원에서 발생할 수 있다. 프레임 구조는 때때로 대신 무선 프레임 구조라고 불릴 수 있다. 프레임 구조 및/또는 프레임 구조 내의 프레임 구성에 따라, 주파수 분할 이중(FDD) 및/또는 시분할 이중(TDD) 및/또는 전이중(FD) 통신이 가능할 수 있다. FDD 통신은 서로 다른 주파수 대역에서 서로 다른 방향(예컨대, 업 링크와 다운링크)의 전송이 발생하는 경우이다. TDD 통신은 서로 다른 방향(예컨대, 업링크와 다운링크)의 전 송이 서로 다른 시간 동안 발생하는 경우이다. FD 통신은 동일한 시간 주파수 자원에서 전송 및 수신이 발생하 는 경우, 즉, 디바이스가 동일한 주파수 자원에서 동시에 전송 및 수신할 수 있는 경우이다. 프레임 구조의 일 예는 후속하는 사양을 갖는 롱텀에볼루션(LTE)의 프레임 구조이다: 각 프레임은 지속시간이 10ms이고, 각 프레임은 10개의 서브프레임을 가지며, 각 서브프레임은 각각 지속시간이 1ms이고, 각 서브프레임 은 2개의 슬롯을 포함하며, 각각의 슬롯은 지속시간이 0.5ms이며, 각 슬롯은 7개의 OFDM 심볼의 전송을 위한 슬 롯이고(일반 CP를 가정함), 각 OFDM 심볼은 부반송파의 수 및 부반송파 간격과 관련된 심볼 지속시간 및 특정 대역폭(또는 부분적 대역폭 또는 대역폭 분할)을 가지며, 프레임 구조는 부반송파 간격 및 CP 길이(CP는 고정 길이 또는 제한된 길이 옵션을 가짐)와 같은 OFDM 파형 파라미터에 기초하고, TDD에서 업링크와 다운링크 사이 의 전환 갭은 OFDM 심볼 지속시간의 정수 시간이어야만 한다. 프레임 구조의 또 다른 예는 후속하는 사양을 갖는 뉴 라디오(NR)의 프레임 구조이다: 다수의 부반송파 간격이 지원되고, 각각의 부반송파 간격은 각각의 수비학에 대응하고, 프레임 구조는 수비학에 의존하지만 어떤 경우에 도 프레임 길이는 10ms로 설정되고, 각각 1ms의 10개의 서브프레임으로 구성되고, 슬롯은 14개의 OFDM 심볼로 정의되고, 슬롯 길이는 수비학에 따라 달라진다. 예를 들어, 일반 CP 15kHz 부반송파 간격의 NR 프레임 구조 (\"수비학(numerology) 1\")와 일반 CP 30kHz 부반송파 간격의 NR 프레임 구조(\"수비학 2\")는 다르다. 15kHz 부 반송파 간격의 경우 슬롯 길이는 1ms이고, 30kHz 부반송파 간격의 경우 슬롯 길이는 0.5ms이다. NR 프레임 구 조는 LTE 프레임 구조보다 유연성이 더 높을 수 있다. 프레임 구조의 또 다른 예는 예를 들어, 6G 네트워크 이상에서 사용하기 위한 예시적인 유연한 프레임 구조이다. 유연한 프레임 구조에서, 심볼 블록은 유연한 프레임 구조에서 스케줄링될 수 있는 최소 지속시간으 로 정의될 수 있다. 심볼 블록은 선택적 리던던시 부분(예컨대, CP 부분)과 정보(예컨대, 데이터) 부분을 갖는전송 단위일 수 있다. OFDM 심볼이 심볼 블록의 예이다. 심볼 블록은 대안으로, 심볼이라고도 불릴 수 있다. 유연한 프레임 구조의 실시예는 프레임 길이, 서브프레임 길이, 심볼 블록 길이 등과 같이 구성 가능한 다양한 파라미터를 포함한다. 유연한 프레임 구조의 일부 실시예에서 구성 가능한 파라미터의 비배타적인 목록은 다음 과 같다: 프레임: 프레임 길이는 10ms로 제한될 필요는 없으며, 프레임 길이는 구성 가능하고 시간이 지남에 따라 변 경될 수 있다. 일부 실시예에서, 각 프레임은 하나 이상의 다운링크 동기화 채널 및/또는 하나 이상의 다운링크 방송 채널을 포함하며, 각 동기화 채널 및/또는 방송 채널은 다른 빔포밍에 의해 다른 방향으로 전송될 수 있다. 프레임 길이는 둘 이상의 가능한 값일 수 있으며 적용 시나리오에 기초하여 구성될 수 있다. 예를 들어, 자율 주행 차량은 비교적 빠른 초기 액세스를 요구할 수 있으며, 이 경우 자율 주행 차량 애플리케이션의 프레임 길이는 5ms로 설정될 수 있다. 또 다른 예로, 주택의 스마트 미터는 빠른 초기 액세스를 필요하지 않을 수 있으며, 이 경우 스마트 미터 애플리케이션의 경우 프레임 길이는 20ms로 설정될 수 있다. 서브프레임 지속시간: 서브프레임은 구현에 따라 유연한 프레임 구조에 정의될 수도 있고 정의되지 않을 수 도 있다. 예를 들어, 슬롯은 포함하지만 서브프레임은 포함하지 않도록 프레임이 정의될 수 있다. 예를 들어, 시간 영역 정렬을 위해 서브프레임이 정의된 프레임에서는, 서브프레임의 지속시간은 구성가능할 수 있다. 예 를 들어, 서브프레임은 0.1ms, 0.2ms, 0.5ms, 1ms, 2ms, 5ms 등의 길이를 갖도록 구성될 수 있다. 일부 실시 예에서, 특정 시나리오에서 서브프레임이 필요하지 않은 경우, 서브프레임 길이는 프레임 길이와 동일하도록 정 의될 수 있고 또는 정의되지 않을 수 있다. 슬롯 구성: 슬롯은 구현에 따라 유연한 프레임 구조에 정의될 수도 있고 정의되지 않을 수도 있다. 슬롯이 정의된 프레임에서, (예를 들어, 지속시간 및/또는 심볼 블록의 수에서의) 슬롯의 정의가 구성가능할 수 있다. 일 실시예에서, 슬롯 구성은 모든 UE 또는 UE 그룹에 공통적이다. 이 경우, 슬롯 구성 정보는 브로드캐스트 채 널 또는 공통 제어 채널(들)에서 UE에게 전송될 수 있다. 다른 실시예에서, 슬롯 구성은 UE 특정적일 수 있으 며, 이 경우, 슬롯 구성 정보는 UE 특정 제어 채널에서 전송될 수 있다. 일부 실시예에서, 슬롯 구성 시그널링 은 프레임 구성 시그널링 및/또는 서브프레임 구성 시그널링과 함께 전송될 수 있다. 다른 실시예들에서, 슬롯 구성은 프레임 구성 시그널링 및/또는 서브프레임 구성 시그널링과 독립적으로 전송될 수 있다. 일반적으로, 슬롯 구성은 시스템 공통, 기지국 공통, UE 그룹 공통, 또는 UE 특정적일 수 있다. 부반송파 간격(SCS): SCS는 확장 가능한 수비학의 한 파라미터로, SCS가 15KHz ~ 480KHz의 범위를 갖는 것 을 허용할 수 있다. SCS는 도플러 편이 및 위상 노이즈의 영향을 최소화하기 위해 스펙트럼의 주파수 및/또는 최대 UE 속도에 따라 달라질 수 있다. 일부 예들에서, 별도의 전송 프레임과 수신 프레임이 있을 수 있으며, 수신 프레임 구조의 심볼의 SCS는 전송 프레임 구조의 심볼의 SCS와 독립적으로 구성될 수 있다. 수신 프레임 의 SCS는 전송 프레임의 SCS와 다를 수 있다. 일부 예에서, 각 전송 프레임의 SCS는 각 수신 프레임의 SCS의 절 반일 수 있다. 수신 프레임과 전송 프레임 간의 SCS가 다르다면, 그 차이는, 예를 들어 고속 푸리에 변환(FFT) 대신 역 이산 푸리에 변환(IDFT)을 사용하여 보다 유연한 심볼 지속시간이 구현되는 경우, 반드시 2배로 확장될 필요는 없다. 프레임 구조의 추가 예는 다른 SCS와 함께 사용될 수 있다. 기본 전송 유닛의 유연한 전송 지속시간: 기본 전송 유닛은 심볼 블록(또는 심볼이라고도 함)일 수 있으며, 이는 일반적으로 중복 부분(CP라고 함)과 정보(예컨대, 데이터) 부분을 포함하지만, 일부 실시예에서는 CP가 심 볼 블록에서 생략될 수 있다. CP 길이는 유연하고 구성 가능할 수 있다. CP 길이는 프레임 내에서 고정되거나 프레임 내에서 유연할 수 있으며, CP 길이는 한 프레임에서 다른 프레임으로, 또는 한 프레임 그룹에서 다른 프 레임 그룹으로, 또는 한 서브프레임에서 다른 서브프레임으로, 또는 한 슬롯에서 다른 슬롯으로, 또는 한 스케 줄링에서 다른 스케줄링으로 동적으로 변경될 수 있다. 정보(예컨대, 데이터) 부분은 유연하고 구성가능할 수 있다. 정의될 수 있는 심볼 블록과 관련된 또 다른 가능한 파라미터는 정보(예컨대, 데이터) 지속시간에 대한 CP 지속시간의 비율이다. 일부 실시예에서, 심볼 블록 길이는 채널 조건(예컨대, 다중 경로 지연, 도플러), 및 /또는 레이턴시 요건, 및/또는 가용 지속시간에 따라 조정될 수 있다. 또 다른 예로, 심볼 블록 길이는 프레임 에서 사용 가능한 지속시간에 맞게 조정될 수 있다. 유연한 전환 갭(Flexible switch gap): 프레임은 기지국으로부터의 다운링크 전송을 위한 다운링크 부분과 UE로부터의 업링크 전송을 위한 업링크 부분을 모두 포함할 수 있다. 각 업링크 부분과 다운링크 부분 사이에 갭이 존재할 수 있으며, 이를 전환 갭이라고 한다. 전환 갭 길이(지속시간)는 구성가능할 수 있다. 전환 갭 지속시간은 프레임 내에서 고정되거나 프레임 내에서 유연할 수 있으며, 전환 갭 지속시간은 한 프레임에서 다 른 프레임으로, 한 프레임 그룹에서 다른 프레임 그룹으로, 한 서브프레임에서 다른 서브프레임으로, 한 슬롯에서 다른 슬롯으로, 또는 한 스케줄링에서 다른 스케줄링으로 동적으로 변경될 수 있다. 셀/반송파/대역폭 부분(BWP)/점유 대역폭 기지국과 같은 디바이스는 셀을 통해 커버리지를 제공할 수 있다. 디바이스와의 무선 통신은 하나 이상의 반송 파 주파수를 통해 발생할 수 있다. 반송파 주파수는 반송파로 지칭될 것이다. 반송파는 대안으로, 컴포넌트 반송파(CC)라고도 한다. 반송파는 그 대역폭과 기준 주파수(예컨대, 반송파의 중심 또는 최저 또는 최고 주파 수)로 특징지어질 수 있다. 반송파는 면허 또는 비면허 스펙트럼에 있을 수 있다. 디바이스와의 무선 통신은 또한 또는 대신에, 하나 이상의 대역폭 부분(BWP)을 통해 이루어질 수 있다. 예를 들어, 반송파는 하나 이상의 BWP를 보유할 수 있다. 보다 일반적으로, 디바이스와의 무선 통신은 스펙트럼을 통해 이루어질 수 있다. 스펙트 럼은 하나 이상의 반송파 및/또는 하나 이상의 BWP를 포함할 수 있다. 셀은 하나 또는 다수의 다운링크 자원 및 선택적으로 하나 또는 다수의 업링크 자원을 포함할 수 있고, 또는 셀 은 하나 또는 다수의 업링크 자원 및 선택적으로 하나 또는 다수의 다운링크 자원을 포함할 수 있고, 또는 셀은 하나 또는 다수의 다운링크 자원 및 하나 또는 다수의 업링크 자원을 모두 포함할 수 있다. 예를 들어, 셀은 하 나의 다운링크 반송파/BWP만을 포함하거나, 하나의 업링크 반송파/BWP만을 포함하거나, 다수의 다운링크 반송파 /BWP를 포함하거나, 다수의 업링크 반송파/BWP를 포함하거나, 하나의 다운링크 반송파/BWP 및 하나의 업링크 반 송파/BWP를 포함하거나, 하나의 다운링크 반송파/BWP 및 다수의 업링크 반송파/BWP를 포함하거나, 다수의 다운 링크 반송파/BWP 및 하나의 업링크 반송파/BWP를 포함하거나, 다수의 다운링크 반송파/BWP 및 다수의 업링크 반 송파/BWP를 포함할 수 있다. 일부 실시예에서, 셀은 대신 또는 부가적으로, 사이드 링크 송신 및 수신 자원을 포함하는 하나 또는 다수의 사이드 링크 자원을 포함할 수 있다. BWP는 반송파 상의 연속 또는 비연속 주파수 부반송파의 세트, 또는 다수의 반송파 상의 연속 또는 비연속 주파 수 부반송파의 세트, 또는 하나 이상의 반송파를 가질 수 있는 비연속 또는 연속 주파수 부반송파의 세트이다. 일부 실시예에서, 반송파는 하나 이상의 BWP를 가질 수 있는데, 예를 들어, 반송파는 20MHz의 대역폭을 가지며 하나의 BWP로 구성되거나, 반송파는 80MHz의 대역폭을 가지며 2개의 인접한 연속적인 BWP로 구성되는 등일 수 있다. 다른 실시예에서, BWP는 하나 이상의 반송파를 가질 수 있는데, 예를 들어, BWP는 40MHz의 대역폭을 가질 수 있고 2개의 인접한 연속 반송파로 구성되며, 여기서 각 반송파는 20MHz의 대역폭을 갖는다. 일부 실시예에 서, BWP는 비연속 다중 반송파로 구성된 비연속 스펙트럼 자원을 포함할 수 있으며, 여기서 비연속 다중 반송파 의 제1 반송파는 mmW 대역에 있을 수 있고, 제2 반송파는 낮은 대역(예컨대, 2GHz 대역)에 있을 수 있고, 제3 반송파(존재하는 경우)는 THz 대역에 있을 수 있으며, 제4 반송파(존재하는 경우)는 가시광 대역에 있을 수 있 다. BWP에 속하는 한 반송파에서의 자원들은 연속적이거나 비연속적일 수 있다. 일부 실시예에서, BWP는 하나 의 반송파에서의 비연속적인 스펙트럼 자원을 갖는다. 무선 통신은 점유된 대역폭 상에서 발생할 수 있다. 점유 대역폭은 주파수 대역의 폭으로 정의될 수 있되, 주파 수 하한 아래 및 주파수 상한 위에서, 방출되는 평균 전력은 각각 총 평균 송신 전력의 지정된 퍼센트 □/2와 같으며, 예를 들어, □/2의 값은 0.5%로 취해진다. 반송파, BWP, 또는 점유 대역폭은 네트워크 디바이스(예컨대, 기지국)에 의해 동적으로, 예를 들어 다운링크 제 어 정보(DCI)와 같은 물리 계층 제어 시그널링에서, 또는 반정적으로, 예를 들어 무선 자원 제어(RRC) 시그널링 에서 또는 매체 액세스 제어(MAC) 계층에서 시그널링될 수 있거나, 애플리케이션 시나리오에 따라 미리 정의될 수 있고, 또는 UE가 알고 있는 다른 파라미터의 함수로서 UE에 의해 결정될 수도 있고, 또는 예컨대 표준에 의 해 고정될 수 있다. 인공 지능(AI) 및/또는 머신 러닝(ML) 미래 무선 네트워크에서 새로운 디바이스의 수는 기하급수적으로 증가할 것으로 예상되며, 디바이스의 기능도 점점 더 다양해질 것으로 예상된다. 또한 5G 애플리케이션/사용 사례보다 더 다양한 서비스 품질 요구 사항을 가진 새로운 애플리케이션과 사용 사례가 많이 등장할 것으로 예상된다. 이로 인해 미래 무선 네트워크(예컨대, 6G 네트워크)에 대한 새로운 핵심 성과 지표(KPI)가 생겨날 것이며, 이는 매우 까다로울 수 있다. ML 기술(예컨대, 딥러닝)과 같은 AI 기술은 시스템 성능 및 효율성을 개선하기 위한 목적으로 통신 애플 리케이션에 도입되고 있다. 또한, 안테나와 대역폭 성능도 계속 발전하여, 무선 링크를 통해 더 많은 및/또는 더 나은 통신을 가능하게 한 다. 또한, 컴퓨터 아키텍처 및 연산 능력 분야에서도, 예를 들어, 범용 그래픽 처리 장치(GP-GPU)의 도입을 통 해, 발전이 계속되고 있다. 미래 세대의 통신 디바이스는 이전 세대보다 더 많은 연산 및/또는 통신 능력을 갖추고 있어 무선 인터페이스 컴포넌트를 구현하는 데 AI를 채택할 수 있을 것이다. 미래 세대의 네트워크는 또 한 AI 모델에 대한 입력의 토대를 형성할 수 있는 (이전 네트워크에 비해) 더 정확하고 및/또는 새로운 정보, 예를 들어, 디바이스가 움직이는 물리적 스피드/속도, 디바이스의 링크 예산, 디바이스의 채널 조건, 하나 이상 의 디바이스 능력 및/또는 지원될 서비스 타입, 센싱 정보 및/또는 위치 정보 등에 액세스할 수 있다. 센싱 정 보를 얻기 위해, TRP는 대상 객체(예컨대, 의심되는 UE)에 신호를 전송할 수 있으며, 신호의 반사를 기반으로, TRP 또는 다른 네트워크 디바이스는 각도(디바이스의 빔포밍용), 디바이스와 TRP 간의 거리 및/또는 도플러 시 프트 정보를 계산할 수 있다. 위치 정보는 때때로 로컬라이제이션이라고도 하며, 예를 들어, UE로부터의 위치 보고(예를 들어, UE의 GPS 좌표 보고), 위치 기준 신호(PRS)의 사용, 전술한 센싱 사용, 디바이스의 위치 추적 및/또는 예측 등 다양한 방법으로 획득될 수 있다. (ML 기술을 포함하는) AI 기술들은 물리 계층에서의 AI 기반 통신 및/또는 MAC 계층에서의 인공지능 기반 통신 을 포함하는 통신에 적용될 수 있다. 물리 계층의 경우, AI 통신은 컴포넌트 설계를 최적화하고 및/또는 알고리 즘 성능을 향상시키는 것을 목표로 할 수 있다. 예를 들어, 채널 코딩, 채널 모델링, 채널 추정, 채널 디코딩, 변조, 복조, MIMO, 파형, 다중 액세스, 물리 계층 요소 파라미터 최적화 및 업데이트, 빔포밍, 추적, 센싱 및/ 또는 위치 지정 등의 구현과 관련하여 AI가 적용될 수 있다. MAC 계층의 경우, AI 통신은 더 나은 전략 및/또 는 최적의 솔루션으로 복잡한 최적화 문제를 해결하기 위한 학습, 예측 및/또는 의사결정을 위해 AI 기능을 활 용하여, 예를 들어 MAC 계층의 기능을 최적화하는 것을 목표로 할 수 있다. 예를 들어, AI는 지능형 TRP 관리, 지능형 빔 관리, 지능형 채널 자원 할당, 지능형 전력 제어, 지능형 스펙트럼 활용, 지능형 MCS, 지능형 HARQ 전략 및/또는 지능형 송/수신 모드 적응 등을 구현하기 위해 적용될 수 있다. 일부 실시예에서, AI 아키텍처는 다수의 노드를 포함할 수 있는데, 여기서 다수의 노드는 두 가지 모드, 즉 중 앙 집중형 모드 및 분산형 모드 중 하나로 구성될 수 있고, 이들 모두는 액세스 네트워크, 코어 네트워크, 또는 엣지 컴퓨팅 시스템 또는 제3자 네트워크에 배치될 수 있다. 중앙 집중형 훈련 및 컴퓨팅 아키텍처는 통신 오버 헤드가 크고 엄격한 사용자 데이터 개인정보 보호에 의해 제한될 수 있다. 분산형 훈련 및 컴퓨팅 아키텍처는 분산형 머신 러닝 및 연합 학습과 같은 여러 프레임워크를 포함할 수 있다. 일부 실시예에서, AI 아키텍처는 공 동 최적화 또는 개별 최적화를 기반으로 단일 에이전트 또는 다중 에이전트로서 수행할 수 있는 지능형 제어기 를 포함할 수 있다. 개인화된 AI 기술에 의해 시그널링 오버헤드를 최소화하고 전체 시스템 스펙트럼 효율을 최대화하면서 특정 요건을 충족시키기 위해 해당 인터페이스 링크가 맞춤형 파라미터로 개인화될 수 있도록 하 는 새로운 프로토콜 및 시그널링 메커니즘이 요구된다. 본 명세서의 일부 실시예에서, 훈련 모드와 정상 작동 모드 사이를 포함하여, AI 훈련을 위한 상이한 작동 모드 내에서 작동하고 그 사이에서 전환하며, 구현에 따라 피드백되어야 할 수 있는 다양한 가능한 측정 및 정보를 수용하기 위한 측정 및 피드백을 위한 새로운 프로토콜 및 시그널링 메커니즘이 제공된다. AI 훈련 도 1 및 도 2를 다시 참조하면, 본 개시의 실시예들은 통신 시스템에서 둘 이상의 통신 디바이스들과 관련 된 AI 훈련을 구현하는 데 사용될 수 있다. 예를 들어, 도 5는 일 실시예에 따라, 통신 시스템 내의 네트 워크 디바이스와 통신하는 4개의 ED를 예시한다. 4개의 ED는 각각 다른 UE로 도시되며, 이하에서는 UE(402, 404, 406, 및 408)로 지칭될 것이다. 그러나, ED는 반드시 UE일 필요는 없다. 네트워크 디바이스는 네트워크(예컨대, 무선 액세스 네트워크)의 일부이다. 네트워크 디바이스(45 2)는 구현에 따라 액세스 네트워크, 코어 네트워크, 또는 엣지 컴퓨팅 시스템 또는 제3자 네트워크에 배치될 수 있다. 네트워크 디바이스는 T-TRP 또는 서버일 수 있다(또는 그 일부일 수 있다). 일 예에서, 네트워크 디 바이스는 T-TRP 또는 NT-TRP일 수 있다(또는 그 내에 구현될 수 있다). 다른 예에서, 네트워크 디바이스는 T-TRP 또는 NT-TRP를 관리할 수 있는 T-TRP 제어기 및/또는 NT-TRP 제어기일 수 있 다. 일부 실시예에서, 네트워크 디바이스의 컴포넌트들은 분산될 수 있다. 예를 들어, 네트워크 디바이스 가 UE(402, 404, 406, 및 408)에 서비스를 제공하는 T-TRP의 일부인 경우, UE(402, 404, 406, 및 408)는 네트워크 디바이스와 직접 통신할 수 있다. 대안으로, UE(402, 404, 406, 및 408)는 하나 이상의 중개 컴 포넌트, 예를 들어, T-TRP 및/또는 NT-TRP 등을 통해 네트워크 디바이스와 통신할 수 있다. 예를 들어, 네 트워크 디바이스는 네트워크 디바이스와 UE(402, 404, 406, 및 408) 사이에 삽입된 백홀 링크 및 무 선 채널을 통해 UE(402, 404, 406, 및 408) 중 하나 이상에 대해 정보(예를 들어, 제어 시그널링, 데이터, 훈련 시퀀스 등)를 송신 및/또는 수신할 수 있다. 각 UE(402, 404, 406, 및 408)는 전술한 바와 같이 각각의 프로세서, 메모리, 송신기, 수신기 및 하나 이상의 안테나(또는 대안적으로 패널)를 포함한다. 단순화를 위해 UE용 프로세서, 메 모리, 송신기, 수신기 및 안테나만이 예시되지만, 다른 UE(404, 406 및 408) 역시 동일한 각각의 컴포넌트를 포함한다. 각 UE(402, 404, 406, 및 408)에 대해, 네트워크 내에서 해당 UE와 각 TRP 사이의 통신 링크는 무선 인터페이스 이다. 무선 인터페이스는 일반적으로 무선 매체를 통해 전송이 송신 및/또는 수신되는 방법을 집합적으로 지정 하는 다수의 컴포넌트 및 관련 파라미터를 포함한다. 도 5의 UE의 프로세서는 UE 측에서 하나 이상의 무선 인터페이스 컴포넌트를 구현한다. 무선 인터페이스 컴포넌트는 무선 인터페이스를 통한 송신 및/또는 수신을 구성 및/또는 구현한다. 무선 인터페이스 컴포넌트의 예시들이 본 명세서에 설명되어 있다. 무선 인터페이스 컴포넌트는 물리 계층에 있을 수 있는데, 예를 들어, UE를 위한 무선 인터페이스의 코딩 컴포넌트를 구현하는 채널 인코더(또는 디코더) 및/또는 UE를 위한 무선 인 터페이스의 변조 컴포넌트를 구현하는 변조기(또는 복조기), 및/또는 UE를 위한 무선 인터페이스의 파형 컴포넌 트를 구현하는 파형 발생기 등에 있을 수 있다. 무선 인터페이스 컴포넌트는, 예를 들어, 채널 예측/추적을 구 현하는 모듈 및/또는 재전송 프로토콜을 구현하는(예를 들어, UE용 무선 인터페이스의 HARQ 프로토콜 컴포넌트 를 구현하는) 모듈 등과 같은 상위 계층, 예컨대, MAC 계층에 있거나 그의 일부가 될 수 있다. 또한, 프로세서 는 본 명세서에 설명된 UE 측 동작을 직접 수행한다(또는 수행하도록 UE를 제어한다). 네트워크 디바이스는 프로세서 , 메모리 및 입력/출력 디바이스를 포함한다. 프로세서 는 네트워크 측에서 하나 이상의 무선 인터페이스 컴포넌트를 구현하도록 다른 네트워크 디바이스들(예를 들어, T-TRP)을 구현하거나 지시한다. 무선 인터페이스 컴포넌트는 네트워크 측에서 한 UE에 대해 다른 UE에 비해 다르게 구현될 수 있다. 프로세서는 본 명세서에 설명된 네트워크 측 동작들을 직접 수행한다(또는 수행하도록 네트워크 컴포넌트를 제어한다). 프로세서는 메모리(예컨대, 메모리)에 저장된 명령어들을 실행하도록 구성되는 동일하거나 다른 하나 이상의 프로세서에 의해 구현될 수 있다. 대안으로, 프로세서의 일부 또는 전부는 프로그래밍된 FPGA, GPU, 또는 ASIC과 같은 전용 회로를 사용하여 구현될 수 있다. 메모리는 휘발성 및/또는 비휘발성 저장소 에 의해 구현될 수 있다. RAM, ROM, 하드 디스크, 광 디스크, 온-프로세서 캐시 등과 같은 임의의 적절한 타입 의 메모리가 사용될 수 있다. 입력/출력 디바이스는 정보를 수신(입력) 및 전송(출력)함으로써 다른 디바이스와의 상호작용을 허용한다. 일부 실시예에서, 입력/출력 디바이스는 송신기 및/또는 수신기(또는 트랜시버) 및/또는 하나 이상의 인터 페이스(예를 들어, 내부 네트워크 또는 인터넷 등에 대한 유선 인터페이스 등)에 의해 구현될 수 있다. 일부 실시예에서, 입력/출력 디바이스는 네트워크 인터페이스에 의해 구현될 수 있으며, 이 네트워크 인터페이 스는 구현에 따라 네트워크 인터페이스 카드(NIC) 및/또는 컴퓨터 포트(예를 들어, 플러그 또는 케이블이 연결 되는 물리적 콘센트) 및/또는 네트워크 소켓 등으로서 구현될 수 있을 것이다. 네트워크 디바이스 및 UE는 하나 이상의 인공지능-가능 프로세스를 구현할 수 있다. 특히, 도 5의 실시예에서, 네트워크 디바이스 및 UE는 각각 ML 모듈(410 및 460)을 포함한다. ML 모듈은 UE의 프로세서에 의해 구현되고 ML 모듈은 네트워크 디바이스의 프로세서에 의해 구 현되므로, 도 5에서 ML 모듈은 프로세서 내에 있는 것으로 표시되고 ML 모듈은 프로세서와 함께 있는 것으로 표시된다. ML 모듈(410 및 460)은 하나 이상의 AI/ML 알고리즘을 실행하여 하나 이상의 AI 가 능 프로세스, 예를 들어, 네트워크와 UE 사이의 통신 링크를 최적화하기 위한 AI 가능 링크 적응을 수행한 다. ML 모듈(410 및 460)은 AI 모델을 사용하여 구현될 수 있다. AI 모델이라는 용어는 정의된 입력 데이터를 수신 하고 정의된 추론 데이터를 출력하도록 구성된 컴퓨터 알고리즘을 지칭할 수 있으며, 알고리즘의 파라미터(예를 들어, 가중치)는 훈련(예를 들어, 훈련 데이터세트를 사용하거나, 또는 실생활에서 수집된 데이터를 사용함)을 통해 업데이트 및 최적화될 수 있다. AI 모델은 하나 이상의 신경망(예컨대, 딥 신경망(DNN), 순환 신경망 (RNN), 콘볼루션 신경망(CNN) 및 이들의 조합을 포함함)을 사용하고 다양한 신경망 아키텍처(예컨대, 자동 인코 더, 생성적 적대 신경망 등)를 사용하여 구현될 수 있다. 파라미터를 업데이트하고 최적화하기 위해 다양한 기 술을 사용하여 AI 모델을 훈련시킬 수 있다. 예를 들어, 역전파는 DNN을 훈련하는 일반적인 기법으로, DNN이 생성한 추론 데이터와 일부 목표 출력(예컨대, 실제 데이터) 사이에서 손실 함수가 계산된다. 손실 함수의 기 울기는 DNN의 파라미터에 대하여 계산되고, 계산된 기울기는 (예를 들어, 기울기 하강 알고리즘을 사용하여) 손 실 함수를 최소화하는 것을 목표로 파라미터를 업데이트하는 데 사용된다.일부 실시예에서, AI 모델은 머신 러닝에 사용되는 신경망을 포함한다. 신경망은 하나 이상의 계층에 배열된 복 수의 계산 유닛(뉴런이라고도 할 수 있음)으로 구성된다. 입력 계층에서 입력을 수신하고 출력 계층에서 출력 을 생성하는 프로세스를 순방향 전파라고 할 수 있다. 순방향 전파에서, 각 계층은 입력(벡터, 행렬 또는 다차 원 배열 등 적합한 데이터 형식일 수 있음)을 수신하고 계산을 수행하여 출력(입력과 다른 차원을 가질 수 있음)을 생성한다. 계층이 수행하는 계산에는 일반적으로 입력에 일련의 가중치(계수라고도 함)를 적용(예컨대, 곱하기)하는 동작이 포함된다. 신경망의 제1 계층(즉, 입력 계층)을 제외하고, 각 계층에 대한 입력은 이전 계층의 출력이다. 신경망은 제1 계층(즉, 입력 계층)과 마지막 계층(즉, 출력 계층) 사이에 하나 이상의 계층을 포함할 수 있으며, 이러한 계층을 내부 계층 또는 은닉 계층이라고 할 수 있다. 예를 들어, 도 6a는 입력 계층, 출력 계층 및 2개의 은닉 계층을 포함하는 신경망의 예를 도시한다. 이 예에서, 신경망 의 입력 계층에 있는 3개의 뉴런 각각의 출력은 제1 은닉 계층에 있는 3개의 뉴런 각각의 입력 벡터에 포 함되는 것을 알 수 있다. 마찬가지로, 제1 은닉 계층의 3개의 뉴런 각각에 대한 출력은 제2 은닉 계층의 3개의 뉴런 각각에 대한 입력 벡터에 포함되고, 제2 은닉 계층의 3개의 뉴런 각각에 대한 출력은 출력 계층의 2개의 뉴런 각각에 대한 입력 벡터에 포함된다. 위에서 언급한 바와 같이, 신경망의 기본 계산 단위는 도 6a의 650에 표시된 것처럼 뉴런이다. 도 6b는 신경망의 빌딩 블록으로 사용될 수 있는 뉴런의 예를 도시한다. 도 6b에 도시된 바와 같이, 이 예에서, 뉴런은 벡터를 입력으로 취하고 연관된 가중치 벡터(w)와의 내적을 수행한다. 뉴런의 최종 출력(z)은 내적에 대한 활성화 함수 의 결과이다. 다양한 신경망은 다양한 아키텍처 (예를 들어, 다양한 수의 계층, 각 계층에 의해 다양한 기능이 수행됨)로 설계될 수 있다. 신경망은 신경망의 파라미터(예컨대, 가중치)를 최적화하도록 훈련된다. 이러한 최적화는 자동화된 방식으로 수 행되며, 머신 러닝이라고 지칭될 수 있다. 신경망의 훈련에는 입력 데이터 샘플을 순방향 전파하여 출력 값(예 측 출력 값 또는 추론 출력 값이라고도 함)을 생성하고 생성된 출력 값을 알려진 또는 원하는 목표 값(예컨대, 실제 값)과 비교하는 과정이 포함된다. 생성된 출력 값과 목표 값 간의 차이를 정량적으로 나타내기 위해 손실 함수가 정의되며, 신경망 훈련의 목표는 손실 함수를 최소화하는 것이다. 역전파는 신경망을 훈련하기 위한 알 고리즘이다. 역전파는 신경망에서 파라미터(예컨대, 가중치)의 값을 조정(업데이트라고도 함)하여 계산된 손실 함수가 작아지도록 하는 데 사용된다. 역전파에는 최적화할 파라미터에 대한 손실 함수의 기울기를 계산하는 동작이 포함되며, 기울기 알고리즘(예컨대, 경사 하강법)이 사용되어 손실 함수를 줄이도록 파라미터를 업데이 트한다. 역전파는 반복적으로 수행되며, 그 결과 손실 함수는 여러 번의 반복을 통해 수렴되거나 최소화된다. 훈련 조건이 충족되면(예컨대, 손실 함수가 수렴되거나, 미리 정의된 횟수의 훈련 반복이 수행된 경우), 신경망 은 훈련된 것으로 간주된다. 훈련된 신경망은 입력 데이터로부터 추론된 출력 데이터를 생성하기 위해 배치(또 는 실행)될 수 있다. 일부 실시예에서, 신경망의 훈련은 신경망이 배치된 후에도 계속될 수 있으며, 그 결과 신 경망의 파라미터는 최신 훈련 데이터로 반복적으로 업데이트될 수 있다. 도 5를 다시 참조하면, 일부 실시예에서, UE 및 네트워크 디바이스는 훈련의 목적을 위해 정보를 교 환할 수 있다. UE와 네트워크 디바이스 사이에서 교환되는 정보는 구현 특정적이며, 이는 사람이 이 해할 수 있는 의미를 갖지 않을 수 있다(예를 들어, 이는 ML 알고리즘의 실행 중에 생성되는 중간 데이터일 수 있다). 또한, 또는 그 대신에, 교환되는 정보는 표준에 의해 미리 정의되지 않을 수도 있고, 예를 들어 비트가 교환될 수 있지만, 그 비트는 미리 정의된 의미와 연관되지 않을 수도 있다. 일부 실시예에서, 네트워크 디바 이스는 UE에서 구현되는 ML 모듈에서 사용될 하나 이상의 파라미터를 UE에 제공하거나 표 시할 수 있다. 일 예로서, 네트워크 디바이스는 UE 측에서 ML 모듈에 의해 실행되는 신경망에서 구 현될 업데이트된 신경망 가중치를 전송하거나 나타낼 수 있으며, 이는 UE와 T-TRP 또는 NT-TRP 사이의 통 신에 사용되는 변조 및/또는 코딩의 하나 이상의 측면을 최적화하기 위한 것이다. 일부 실시예에서, UE는 AI 자체를 구현할 수 있는데, 예를 들어 학습을 수행할 수 있는 반면, 다른 실시예 들에서, UE는 학습 자체를 수행하지 않을 수 있지만, 예를 들어, ML 모듈에 의해 구현된 AI 모델(예 를 들어, 신경망 또는 다른 ML 알고리즘)에 대해 네트워크로부터 구성을 수신함으로써, 및/또는 요청된 측정 결 과 또는 관찰을 제공함에 따라 다른 디바이스(예를 들어, 네트워크 디바이스 또는 다른 AI 가능 UE)가 AI 모델 (예를 들어, 신경망 또는 다른 ML 알고리즘)을 훈련하도록 지원함으로써, 네트워크 측의 AI 구현과 함께 동작할 수 있을 수 있다. 예를 들어, 일부 실시예에서, UE 자체는 학습 또는 훈련을 구현하지 않을 수 있지만, UE는 네트워크 디바이스에 의해 결정된 ML 모델에 대한 훈련된 구성 정보를 수신하여 모델을 실행할 수 있다. 도 5의 실시예는 네트워크 측의 AI/ML 기능을 가정하고 있지만, 네트워크가 스스로 학습/훈련을 수행하지 않고, 대신 네트워크에서 전송되는 전용 훈련 신호를 통해 UE가 스스로 학습/훈련을 수행할 수도 있다. 다른 실시예들에서, 엔드-투-엔드(E2E) 학습은 UE 및 네트워크 디바이스에 의해 구현될 수 있다. AI를 사용함으로써, 예를 들어, 전술한 바와 같이 AI 모델을 구현함으로써, 링크 적응과 같은 다양한 프로세스 가 AI에 의해 가능해진다. 본 개시의 실시예들에 따른 AI 가능 프로세스를 용이하게 하기 위한 훈련 단계 동안 디바이스들 간의 가능한 AI/ML 훈련 프로세스 및 무선 정보 교환 절차의 일부 예들이 아래에 설명된다. 도 5를 다시 참조하면, 무선 연합 학습(FL)을 위해, 네트워크 디바이스 는 ML 모듈에 의해 구현된 글 로벌 AI/ML 모델을 초기화하고, 도 5에 도시된 4개의 UE(402, 404, 406 및 408)와 같은 UE 그룹을 샘플링하고, 글로벌 AI/ML 모델 파라미터를 UE에 브로드캐스트할 수 있다. 그러면 각 UE(402, 404, 406, 408)는 글로벌 AI/ML 모델 파라미터를 사용하여 자신의 로컬 AI/ML 모델을 초기화하고, 자체 데이터를 사용하여 자신의 로컬 AI/ML 모델을 업데이트(훈련)할 수 있다. 그런 다음, 각 UE(402, 404, 406 및 408)는 자신의 업데이트된 로컬 AI/ML 모델의 파라미터를 네트워크 디바이스에 보고할 수 있다. 그러면 네트워크 디바이스는 UE(402, 404, 406 및 408)로부터 보고된 업데이트된 파라미터들을 취합하여 글로벌 AI/ML 모델을 업데이트할 수 있다. 전술한 절차는 FL 기반 AI/ML 모델 훈련 절차의 하나의 반복이다. 네트워크 디바이스 및 UE(402, 404, 406 및 408)는 AI/ML 모델이 하나 이상의 훈련 목표/기준을 만족시키기에 충분히 수렴되고 AI/ML 모델이 확정될 때까지 다수의 반복을 수행한다. 종래의 FL 프로세스에는 동기식 FL 및 비동기식 FL의 두 가지 타입이 있다. 반복 훈련 프로세스인 종래의 동기식 FL에서는, 각 훈련 반복에 대해, BS와 같은 네트워크 디바이스가 동기식 FL 훈련 프로세스에 참여하는 모든 UE로부터 업데이트를 수신한 후 글로벌 모델(예컨대, 집계 및 평균)을 업데 이트한다. 예를 들어, 도 7은 동기식 FL 훈련 프로세스의 한 반복에 대해 4개의 UE(UE 1, UE 2, UE 3 및 UE 4)가 수행하는 동작의 타임라인을 도시한다. 특히, 도 7은 N번째 반복에 대해 4개의 UE가 수행하는 동작 을 도시한 것으로서, 여기서 N≥1이다. 도 7에서는, 전송 지연, 재전송 지연, 신호 처리 지연 등을 포함하여, N번째 반복에 대해 BS와 4개의 UE 각각 간의 통신 지연은 BS와 각 UE 간의 DL 통신의 경우에는 7021,N, 7022,N, 7023,N, 7024,N으로 표시되고, BS와 각 UE 간의 UL 통신의 경우에는 7061,N, 7062,N, 7063,N, 7064,N으로 표시된다. 또한, 예를 들어, N번째 반복에 대한 로컬 AI/ML 모델 업데이트를 결정하기 위한 지연을 포함하여, 4개의 UE 각 각에서의 AI/ML 처리 지연은 4개의 UE 각각에 대해 7041,N, 7042,N, 7043,N 및 7044,N으로 표시된다. 또한, 예를 들어, UE로부터 수신된 로컬 AI/ML 모델 업데이트 파라미터에 따른 글로벌 모델 업데이트 지연을 포함하여, BS 측에서의 AI/ML 처리 지연은 708로 표시된다. 그러나, 종래의 동기식 FL 훈련 프로세스의 한 가지 중요한 문제점은, 예를 들어, 채널 품질이 낮거나 계산 능 력이 떨어지는 UE와 같은 지연되는 UE에 의해 발생할 수 있는 큰 훈련 지연이다. 이는 모든 UE가 DL 전송을 성 공적으로 디코딩하고 로컬 모델을 업데이트하고 로컬 모델 파라미터를 BS에 보고할 때까지 BS가 다음 훈련 반복, 예컨대, 도 7의 710에 표시된 (N+1)번째 반복을 시작하지 않기 때문이다. 즉, 통신 및 계산 지연이 가장 큰 최악의 UE가 훈련 지연을 주도하여 AI 모델 훈련에 큰 지연을 초래한다. 이에 대한 예가 도 7에 도시되어 있 는데, UE 4는 7024,N과 7064,N으로 표시된 현저히 긴 DL 및 UL 통신 지연, 및 7044,N으로 표시된 현저히 긴 계산 지연을 가지기 때문에, (N+1)번째 반복은 UE 1, UE 2 및 UE 3이 그들의 로컬 모델 파라미터를 BS에 성공적으로 보고한 시간에 비해 지연되게 된다. 비동기 FL에서, BS는 UE로부터 업데이트를 수신할 때마다 즉시 글로벌 AI/ML 모델을 업데이트한다. 예를 들어, 도 8은 비동기 FL 훈련 프로세스의 여러 반복에 걸쳐 4개의 UE(UE 1, UE 2, UE 3 및 UE 4)에 의해 수행되는 동 작의 타임라인을 도시한다. 도 8에서, 글로벌 AI/ML 모델의 초기 DL 전송에 대한 BS와 4개의 UE 각각 간 의 통신 지연은 8021,1, 8022,1, 8023,1 및 8024,1로 표시되고, 그들의 로컬 모델의 제1 업데이트에 대한 계산 지연 은 8041,1, 8042,1, 8043,1 및 8044,1로 표시되고, 그들의 초기 로컬 AI/ML 모델 파라미터 업데이트를 보고하기 위 한 초기 UL 전송에 대한 각 UE와 BS 간의 통신 지연은 각각 8061,1, 8062,1, 8063,1 및 8064,1로 표시된다. 이 예에서, UE 3은 가장 짧은 결합된 통신 및 계산 지연을 가지는데, 이는 도 8의 8081에 표시된 바와 같이, BS 가 UE 3으로부터 로컬 AI/ML 모델 파라미터 업데이트를 수신한 후에 먼저 글로벌 AI/ML 모델을 업데이트하고, 그 후에 BS가 UE 3과 함께 제2 반복을 시작한다는 것을 의미한다. UE 1은 두 번째로 가장 짧은 결합된 통신 및 계산 지연을 가지는데, 이는 8082에 표시된 바와 같이, BS가 UE 1 로부터 제1 로컬 AI/ML 모델 파라미터 업데이트를 수신한 후에 다음으로 글로벌 AI/ML 모델을 업데이트하고, 그후에 BS가 UE 1과 함께 제2 반복을 시작한다는 것을 의미한다. UE 2는 두 번째로 가장 짧은 결합된 통신 및 계산 지연을 가지는데, 이는 8083에 표시된 바와 같이, BS가 UE 2 로부터 제1 로컬 AI/ML 모델 파라미터 업데이트를 수신한 후에 다음으로 글로벌 AI/ML 모델을 업데이트하고, 그 후에 BS가 UE 2와 함께 제2 반복을 시작한다는 것을 의미한다. BS는 UE 3에 대한 제2 반복에 대해 8023,2, 8043,2 및 8063,2에 표시된 통신 및 계산 지연 후에 UE 3으로부터 업데 이트된 로컬 AI/ML 파라미터를 수신하면, 8084에 표시된 바와 같이 네 번째로 글로벌 AI/ML 모델을 업데이트하 고, 그 후 BS는 UE 3 과 함께 제3 반복을 개시한다. BS는 UE 1에 대한 제2 반복에 대해 8021,2, 8041,2 및 8061,2로 표시된 통신 및 계산 지연 후에 UE 1로부터 업데이 트된 로컬 AI/ML 파라미터를 수신하면, 8085에 표시된 바와 같이 다섯 번째로 글로벌 AI/ML 모델을 업데이트한 다. 8085에 표시된 바와 같이 다섯 번째로 글로벌 AI/ML 모델을 업데이트한 후 ,BS는 UE 1과 함께 제3 반복을 개시한다(미도시). BS는 UE 3에 대한 제3 반복에 대해 8023,3, 8043,3 및 8063,3로 표시된 통신 및 계산 지연 후에 UE 3으로부터 업데 이트된 로컬 AI/ML 파라미터를 수신하면, 8086에 표시된 바와 같이 여섯 번째로 글로벌 AI/ML 모델을 업데이트 한다. 8056에 표시된 바와 같이 여섯 번째로 글로벌 AI/ML 모델을 업데이트한 후 ,BS는 UE 3과 함께 제4 반복을 개시한다(미도시). UE 4는 가장 긴 결합된 통신 및 계산 지연을 가지며, 이 예에서 그 지연은, BS가 글로벌 AI/ML 모델의 여섯 번 째 업데이트를 완료할 때까지 UE 4로부터 초기 로컬 AI/ML 모델 파라미터 업데이트를 수신하지 못할 만큼 길다. 따라서, BS는 UE 4에 대한 제1 반복에 대해 8024,1, 8044,1 및 8064,1로 표시된 통신 및 계산 지연 후에 UE 4로부 터 업데이트된 로컬 AI/ML 파라미터를 수신하면 8087로 표시된 것처럼 글로벌 AI/ML 모델을 일곱 번째로 업데이 트한다. 비동기 FL 훈련 프로세스는 일반적으로 동기 FL 훈련 프로세스에 비해 적은 훈련 레이턴시를 갖는데, 그 이유는 일반적으로 동기 FL을 괴롭히는 대기 지연을 피할 수 있기 때문이다. 그러나, 종래의 비동기 FL 훈련 프로세스 에는 두 가지 주요 단점이 있다. 첫 번째 단점은 비동기 DL 전송으로 인한 통신 오버헤드가 크다는 점이다. 두 번째 단점은 지연 UE로부터의 로컬 AI/ML 모델 파라미터 업데이트가 오래되었을 수 있으며, 이는 지연 UE의 오 래된 업데이트를 BS가 글로벌 AI/ML 모델을 업데이트하는 데 사용할 경우 글로벌 AI/ML 모델의 정확도에 부정적 인 영향을 미칠 수 있다는 것이다. 예를 들어, 도 8에 표시된 것처럼, BS는 다른 UE로부터 여러 업데이트를 이 미 수신하여 통합할 때까지는 UE4로부터 제1 로컬 AI/ML 모델 업데이트를 수신하지 못한다. 따라서, UE 4에 의 해 제공되는 로컬 AI/ML 모델 파라미터에 기초하여 글로벌 AI/ML 모델을 업데이트하는 것은 글로벌 AI/ML 모델 의 정확도에 해로운 영향을 미칠 수 있다. 전술한 바와 같이, 동기식 FL과 비동기식 FL 모두 그들의 단점을 가지고 있음을 알 수 있다. FL 외에도, 다른 학습 방법에서 큰 통신 오버헤드와 큰 학습 지연이 또한 존재한다. 예를 들어, 분산 학습에서, UE와 네트워크 디바이스는 FL과 유사한 방식으로 AI 모델을 공동으로 훈련한다. FL과 분산 학습의 주요 차이점은, FL에서는 DL 전송이 브로드캐스트 또는 그룹캐스트 전송을 통해 이루어지는 반면, 분산 학습에 서는 유니캐스트 전송이 DL에 사용된다는 것이다. 기존 AI/ML 모델 훈련 절차의 또 다른 단점은 일반적으로 매우 큰 교환 데이터의 페이로드 크기와 관련이 있다. 예를 들어, 많은 경우에, 교환된 데이터는 수백 또는 수천 개의 AI/ML 모델 파라미터, 예를 들어 기울기, 연결 가중치, 바이어스 등을 포함한다. 따라서, 무선 통신에서 전송의 불안정한 특성과 AI 훈련을 위해 디바이스들 간에 교환되는 데이터의 양이 일반적으로 크기 때문에, AI/ML 모델 훈련에 필요한 무선 인터페이스 자원 오버헤 드는 매우 클 수 있다. 따라서, 온라인 AI/ML 모델 훈련과 관련된 오버헤드 및 지연을 감소시키는 기술이 매우 바람직하다. 본 개시는 종래의 AI/ML 모델 훈련 절차에서 전술한 문제들 중 하나 이상을 피하거나 적어도 완화하는 AI/ML 모 델 훈련 절차의 예들을 설명한다. 예를 들어, 아래에서 더 상세히 논의되는 바와 같이, 본원에 설명된 일부 실 시예에서는, 반복 AI/ML 모델 훈련 절차에 선택적으로 참여하도록 UE를 구성하기 위해 다양한 기법들이 사용된 다. 예를 들어, 본 개시의 제1 양상은 주어진 반복에 참여하도록 UE 그룹이 구성되는 준동기 연합 학습 프로세스를 제공한다. 이러한 실시예는 UE가 자신의 현재 처리 지연 및/또는 훈련 데이터 양을 BS에 보고하고, 이어 서 BS는 해당 정보를 사용하여 AI/ML 모델 훈련 프로세스의 주어진 반복에 참여할 UE 그룹을 결정하는 새로운 피드백 신호 메커니즘에 기초한다. 본 개시의 제2 양상은 AI/ML 모델 훈련 프로세스 동안 서로 다른 UE에 대해 다수의 비동기 훈련 반복을 제공한다. 이러한 실시예에서, AI/ML 모델 훈련 프로세스는 하나 이상의 반복에 대 한 훈련 프로세스에서 개별 UE의 동적 결합, 일시 중지(suspending) 또는 탈락(dropping)을 지원한다. 또한, 일부 실시예에서, 훈련 프로세스에 동적으로 참여하는 UE는 오버헤드를 줄이기 위해 부분적 모델(파라미터의 서 브세트)만 훈련하도록 구성될 수 있다. 다음의 예들 중 다수는 연합 학습 기반 또는 분산 학습 기반 AI/ML 모델 훈련 절차의 맥락에서 설명되지만, 본 원에 설명된 기술들은 다른 학습 방법, 예를 들어 중앙 집중식 학습, 자동 인코더, DNN(딥 신경망), CNN(컨볼루 션 신경망) 등의 AI 훈련에도 적용될 수 있음에 유의해야 한다. 준동기 연합 학습 전술한 바와 같이, 본 개시의 일 양상은 AI/ML 모델 훈련을 위한 준동기식 FL 프로세스를 제공하는데, 여기서, UE들로부터의 반정적 및/또는 동적 피드백에 기초하여, BS가 각 학습 반복에 대해 참여 UE들의 그룹을 정적 및/ 또는 동적으로 결정할 수 있다. 예를 들어, 도 9는 일 실시예에 따른 준동기 연합 학습 절차의 여러 반복에 걸 쳐 4개의 UE(UE 1, UE 2, UE 3 및 UE 4)가 수행하는 동작의 타임라인을 예시한다. 특히, 도 9는 N번째 및 (N+1)번째 반복에 대해 4개의 UE에 의해 수행되는 동작을 도시하며, 여기서 N≥1이다. UE로부터의 준정적 및/ 또는 동적 피드백은 UE의 현재 처리 능력, UE에서 반복적인 AI/ML 모델 훈련 프로세스를 위해 이용 가능한 훈련 데이터의 현재 양, 또는 반복적인 AI/ML 모델 훈련 프로세스를 위해 훈련 데이터를 수집하는 UE의 센싱 능력 중 적어도 하나를 포함할 수 있다. 도 9에서는, 전송 지연, 재전송 지연, 신호 처리 지연 등을 포함하여, N번째 반복에 대해 BS와 4개의 UE 각각 간의 통신 지연은 BS와 각 UE 간의 DL 통신의 경우에는 9021,N, 9022,N,9023,N,9024,N으로 표시되고, BS와 각 UE 간 의 UL 통신의 경우에는 9061,N, 9062,N,9063,N,9064,N으로 표시된다. 또한, 예를 들어, N번째 반복에 대한 로컬 AI/ML 모델 업데이트를 결정하기 위한 지연을 포함하여, 4개의 UE 각각에서의 AI/ML 처리 지연은 4개의 UE 각각 에 대해 9041,N, 9042,N, 9043,N 및 9044,N으로 표시된다. 또한, 예를 들어, UE로부터 수신된 로컬 AI/ML 모델 업 데이트 파라미터에 따른 글로벌 모델 업데이트 지연을 포함하여, N번째 반복에 대한 BS 측에서의 AI/ML 처리 지 연은 908로 표시된다. 설명을 위해, 이 예에서 UE 1과 UE 2는 높은 처리 능력을 가지며, 낮은 통신 및 AI/ML 처리 지연과 대량의 훈련 데이터 양을 갖는다. 이와 대조적으로, UE 3 은 낮은 통신 및 AI/ML 처리 지연을 갖지만 적은 훈련 데이터의 양만을 가지며, UE 4는 높은 통신 및 처리 지연을 갖는다. 낮은 통신 및 AI/ML 처리 지연과 큰 데이터 양을 갖는 UE들(도 9에 도시된 예에서 UE 1 및 UE 2)의 경우, BS는 빠른 훈련 수렴을 달성하기 위해 다른 UE들에 비해 더 많은 수의 학습 반복을 구현하도록 해당 UE들을 (예를 들 어, 제어 시그널링을 통해) 지시/구성할 수 있다. 예를 들어, 도 9에 표시된 바와 같이, BS는 도 9의 908N에 표시된 것처럼 UE1 및 UE 2로부터 제1 로컬 AI/ML 모델 파라미터 업데이트를 수신한 후 글로벌 AI/ML 모델을 업 데이트하고, 그 후 BS는 UE 1 및 UE 2와 함께 제2 반복을 시작한다. (N+1)번째 반복에 대한 BS와 UE1 및 UE 2 간의 통신 지연은 BS와 UE 간의 DL 통신의 경우 9021,N+1 및 9022,N+1로 표시되고, UE와 BS 간의 UL 통신의 경우 9061,N+1 및 9062,N+1로 표시된다. 또한, (N+1)번째 반복에 대한 UE 1과 UE 2에서의 AI/ML 처리 지연은 각각 9041,N+1과 9042,N으로 표시된다. 높은 통신 및 AI/ML 처리 지연을 갖는 UE들(도 9에 도시된 예에서 UE 4)의 경우, BS는 이러한 지연 UE들로 인한 대기 지연을 줄이기 위해 더 적은 수의 학습 반복을 구현하도록 해당 UE들에게 지시한다. 마찬가지로, 적은 데 이터 양을 갖는 UE(도 9의 예시에서 UE 3)의 경우, BS는 이러한 UE로부터 로컬 AI/ML 모델 파라미터 업데이트를 위한 UL 보고서의 통신 오버헤드를 줄이기 위해 더 적은 수의 학습 반복을 구현하도록 해당 UE에 지시할 수 있 는데, 그 이유는 그러한 업데이트에 기반을 둔 글로벌 AI/ML 모델에 대한 기여도가 그 업데이트가 기반을 두고 있는 훈련 데이터의 적은 양으로 인해 미미할 수 있기 때문이다. 예를 들어, 도 9에 표시된 바와 같이, BS는 도 9의 908N+1에 표시된 바와 같이, UE 1과 UE 2로부터 제2 로컬 AI/ML 모델 파라미터 업데이트를 수신하고 UE 3 과 UE 4로부터 제1 로컬 AI/ML 모델 파라미터 업데이트를 수신한 후 글로벌 AI/ML 모델을 업데이트하여, UE 3과 UE 4가 하나의 학습 반복에만 참여하는 시간 내에서 UE 1과 UE 2가 두 개의 학습 반복에 참여하도록 한다.(N+1)번째 반복에 대한 UE 1 및 UE 2로부터의 업데이트와 N번째 반복에 대한 UE 3 및 UE 4로부터의 업데이트에 기초하여 글로벌 AI/ML 모델을 업데이트한 후, BS는 UE 1, UE 2, UE 3 및 UE 4과 함께 (N+2)번째 반복을 시작 할 수 있다. 도 9에 도시된 예와 같은 준동기식 FL은 종래의 동기식 및 비동기식 FL에 비해 몇 가지 잠재적인 이점을 갖는다. 예를 들어, 동기식 FL과 비교하여, 본원에 개시된 준동기식 FL은 잠재적으로 동기식 FL에서 지연 UE로 인해 발생하는 훈련 레이턴시를 감소시켜 빠른 훈련 수렴을 달성할 수 있다. 예를 들어, 도 9에 도시된 바와 같이, 글로벌 AI/ML 모델을 업데이트하기 전에 지연 UE 4의 통신 및 계산 지연을 기다릴 필요 없이, BS는 N번째 반복에 대해 UE 1 및 UE 2로부터 수신한 업데이트를 기반으로 글로벌 AI/ML 모델을 업데이트하고, (N+1)번째 반 복에 대한 UE 1 및 UE 2로부터의 업데이트와 N번째 반복에 대한 UE 3 및 UE 4로부터의 업데이트를 기반으로 글 로벌 AI/ML 모델을 다시 업데이트할 수 있다. 또한, 비동기 FL에 비해, 본 명세서에 개시된 준동기 FL은 비동 기 FL에서 글로벌 AI/ML 모델 표시의 DL 전송과 관련된 통신 오버헤드를 잠재적으로 감소시킬 수 있다. 주어진 반복에 대한 참여 UE 그룹을 결정하는 데 있어서 BS를 지원하기 위해, 각 UE는 BS에 일부 지원 정보를 전송한다. 예를 들어, 전술한 바와 같이, 지원 정보는 UE에서 이용 가능한 훈련 데이터의 양 및/또는 UE의 AI/ML 처리 능력을 나타내는 정보를 포함할 수 있다. 상이한 UE에서 사용 가능한 훈련 데이터의 양이 불균형한 경우가 많으며, 상이한 UE는 상이한 AI/ML 처리 능력을 갖는 경우가 많다. 또한, 특정 UE의 경우, 훈련 데이터 양은 일반적으로 시간에 따라 변화하고, UE의 AI/ML 처리 능력은 동적으로 달라질 수 있다. 예를 들어, UE가 센싱을 수행한 후에는 AI/ML 모델 훈련에 사용할 수 있는 대량의 훈련 데이터가 있을 수 있다. 그러나, UE가 비교적 긴 간격으로 일부 기본 채널 정보만을 주기적으로 측정하는 경우, UE에서 사용 가능한 훈 련 데이터는 소량만 존재할 수 있다. 마찬가지로, UE의 AI/ML 처리 능력은 다른 태스크/서비스에 의해 활용되고 있는 처리 자원에 따라 및/또는 UE의 절전 상태에 따라 달라질 수 있다. 예를 들어, UE가 절전 모드에 있을 때 및/또는 UE가 다른 컴퓨팅 태스크, 예 를 들어 센싱 처리를 처리하고 있을 때 UE의 AI/ML 처리 능력은 더 낮을 수 있다. 따라서, 일부 실시예에서, UE가 초기에 BS에 액세스한 후에, UE는 자신의 AI/ML 모델 훈련 능력 및 훈련 데이터 획득 능력을 BS에 보고할 수 있다. 예를 들어, 데이터 획득 능력은 훈련 데이터를 위한 센싱 능력 및/또는 데이 터 버퍼 능력을 포함할 수 있다. 또한 UE는 자신의 현재 학습 능력을 반정적 또는 동적으로 BS에 전송할 수 있 다. 훈련 능력은 UE의 현재 AI/ML 처리 능력 또는 현재 훈련 데이터 양, 또는 UE의 현재 AI/ML 처리 능력과 훈 련 데이터 양의 조합에 기초할 수 있고 및/또는 그를 포함할 수 있다. 각 UE에 의해 제공된 AI/ML 모델 훈련 능력 피드백에 기초하여, BS는 하나의 훈련 반복에 대한 참여하는 UE 그룹을 반정적 또는 동적으로 결정할 수 있다. 일부 실시예에서, UE는 예를 들어, AI/ML 처리 지연 및/또는 훈련 데이터 양 및/또는 통신 채널 품질을 포함하 는 UE 훈련 능력의 변화와 같은 이벤트 트리거에 대한 응답으로, 반정적으로 자신의 AI/ML 모델 훈련 능력을 보 고할 수 있다. 예를 들어, UE가 절전 모드에 진입하면, AI 학습에 사용할 수 있는 전력이 줄어들 수 있으므로 더 높은 처리 지연, 즉 더 낮은 AI/ML 처리 능력을 보고할 수 있다. 다른 예로서, 예를 들어, UE가 최근 센싱 을 통해 많은 양의 훈련 데이터를 수집한 경우, UE는 더 큰 훈련 데이터 양을 보고할 수 있다. 일부 실시예에서, UE는 또한 또는 대신에, 반복적인 AI/ML 모델 훈련 프로세스 동안 각 DL 수신에 대해 동적으 로 AI/ML 모델 훈련 능력 피드백을 제공할 수 있다. 예를 들어, 일부 실시예에서, UE는 동적 학습 능력 피드백 을 위해 DL 전송을 스케줄링하는 DCI에 표시된 PUCCH 자원을 사용할 수 있거나, UE는 피드백을 위해 RRC/MAC-CE 또는 다른 DCI에 의해 BS에 의해 구성된 특정 PUCCH 자원을 사용할 수 있다. 앞서 논의된 바와 같이, 그러한 동적 피드백의 내용은 현재 AI/ML 처리 지연(예를 들어, 이 반복의 로컬 모델 업데이트에 대한 처리 지연) 및/ 또는 이 반복의 현재 훈련 데이터 양(예를 들어, UE에서 이용 가능한 잔여 훈련 데이터의 양 또는 UE가 획득할 수 있을 것으로 예상되는 훈련 데이터의 양)을 포함할 수 있다. 일부 실시예에서, 훈련 능력은 미리 정의되거나 구성된 AI/ML 모델 훈련 능력 타입의 계층 구조 중에서 선택된 AI/ML 모델 훈련 능력 타입으로 전달될 수 있다. 예를 들어, 표 1에는 AI/ML 모델 훈련 능력이 증가 또는 감소 하는 4개의 레벨(즉, 레벨 1 ~ 레벨 4)을 포함하는 AI/ML 모델 훈련 능력 타입의 계층 구조의 예가 나와 있다. 표 1 훈련 능력 표 1에서, 각 AI/ML 모델 훈련 능력 레벨은 해당 레벨 ID와 연관되어 있다. 미리 정의되거나 구성된 레벨/타입 중 하나에 대응하는 주어진 현재 AI/ML 모델 훈련 능력을 갖는 UE는, UE의 현재 AI/ML 모델 훈련 능력을 BS에 알리기 위해 해당 레벨 ID 를 BS에 표시할 수 있다. 도 9를 다시 참조하면, 준동기식 FL에서, 주어진 훈련 반복에 대해, 일부 UE들만이 참여할 수 있음을 알 수 있 는데, 예를 들어, 도 9에서, UE1 및 UE2만이 (N+1)번째 반복에 참여한다. 주어진 반복에서 이러한 선택적 참여 를 달성하기 위한 메커니즘의 세 가지 예가 아래에 설명되어 있다. 이러한 예들은 제한적이지 않으며 예시적인 목적으로만 제공된다는 점에 유의한다. 예를 들어, 제1 옵션으로서, BS는 UE가 주어진 반복에 참여할지 여부를 결정할 수 있게 하는 규칙으로 각 UE를 개별적으로 구성함으로써 주어진 반복에 참여하도록 UE의 그룹을 구성할 수 있다. 예를 들어, 이러한 실시예에 서, 업데이트된 글로벌 AI/ML 모델 파라미터를 나타내기 위한 각 DL 전송에 대해, BS는 다음 반복에서 1씩 증가 되는 반복 ID 값을 나타낼 수 있다. 또한 BS는 UE가 무시하거나 응답해야 하는 반복 ID를 나타내는 규칙으로 각 UE를 구성한다. 예를 들어, 도 9를 다시 참조하면, UE 1과 UE 2는 모든 반복 ID가 무시되어서는 안 된다는 규칙으로 구성될 수 있는 반면, UE 3과 UE 4는 반복 ID가 짝수인 반복(예를 들어, (N+1)번째 반복, N이 홀수라 고 가정)은 무시되어야 한다는 규칙으로 구성될 수 있다. 다른 옵션으로서, BS는 또한 또는 대신에, DCI(예를 들어, 모델 업데이트를 위한 DL 전송을 스케줄링하는 DCI 또는 모델 업데이트를 위한 DL 전송을 스케줄링하는 데 사용되는 스케줄링 DCI가 아닌 다른 전용 DCI) 또는 RRC 또는 MAC-CE로 반복에 참여할 UE의 타입을 나타낼 수 있다. 예를 들어, 위의 표 1에 표시된 것처럼 UE는 해당 훈련 레벨 ID를 BS에 전송하여 자신의 훈련 능력을 보고할 수 있다. 주어진 반복에 대해, BS는 모든 UE 또는 학 습 능력이 임계값(예컨대, 레벨 2)보다 큰 UE에게 반복에 참여하도록 표시할 수 있다. 예를 들어, 도 9를 다시 참조하면, UE 1과 UE 2는 레벨 ID 3을 BS에 보고할 수 있고(이는 UE 1과 UE 2가 현재 높은 AI/ML 모델 훈련 능 력과 많은 양의 훈련 데이터와 같이, 레벨 4의 AI/ML 모델 훈련 능력을 가지고 있음을 나타냄), UE 3은 레벨 ID 1을 보고할 수 있고(이는 UE 3이 현재 높은 AI/ML 모델 훈련 능력, 그러나 적은 양의 훈련 데이터와 같이, 레벨 2의 AI/ML 모델 훈련 능력을 가지고 있음을 나타냄), UE 4는 레벨 ID 0을 보고할 수 있다(이는 UE 4가 현재 낮 은 AI/ML 모델 훈련 능력과 적은 양의 훈련 데이터와 같은 레벨 1의 AI/ML 모델 훈련 능력을 가지고 있음을 나 타냄). 이 시나리오에서, (N+1)번째 반복에 대해, BS는 레벨 2보다 큰 훈련 능력을 가진 모든 UE(즉, 이 예시 시나리오에서는 UE 1과 UE 2만)를 (N+1)번째 반복에 참여하도록 지시할 수 있다. 세 번째 옵션으로서, BS는 또한 또는 대신에, 각 반복에 대해 글로벌 AI/ML 모델 업데이트의 DL 전송을 스케줄 링하는 DCI에 대한 UE별 모니터링 기회로 UE를 구성할 수도 있다. 예를 들어, 훈련 프로세스 동안 글로벌 AI/ML 모델 업데이트의 DL 전송을 스케줄링하기 위해, DL 전송을 스케줄링하는 데 사용되는 DCI의 순환 중복 검 사(CRC)는 예를 들어, 셀 무선 네트워크 임시 식별자(C-RNTI)와는 다른 새로운 RNTI와 같은 새로운 RNTI와 스크 램블링될 수 있다. 예를 들어, 새로운 RNTI는 무선 통신 네트워크에서 AI/ML 훈련 관련 통신을 위해 특별히 사 용되는 RNTI일 수 있다. DCI의 모니터링 기회(예컨대, 모니터링 심볼 및 모니터링 주기)는 UE별로 구성될 수 있다. 예를 들어, 도 9를 다시 참조하면, UE 1과 UE 2는 각각 글로벌 AI/ML 모델 업데이트의 DL 전송을 스케줄 링하는 DCI에 대해 더 짧은 DCI 모니터링 주기로 구성될 수 있는 반면, UE 3과 UE 4는 각각 더 긴 DCI 모니터링 주기로 구성될 수 있다. 예를 들어, 4개의 UE가 모두 N번째 반복에 대해 DL 전송을 스케줄링하는 DCI를 모니터 링한 후에는, UE 1과 UE 2만이 (N+1)번째 반복에 대해 DL 전송을 스케줄링하는 DCI를 모니터링한다. 4개의 UE 는 (N+2)번째 반복에 대해 DL 전송을 스케줄링하는 DCI를 다시 모니터링할 수 있다. 다른 DL 스케줄링의 경우, DCI의 CRC는 다른 RNTI, 예를 들어 C-RNTI와 스크램블링될 수 있다. 그리고, 이러한 타입의 DCI와 CRC가 새로운 RNTI와 스크램블링되는 DCI에 대한 모니터링 기회는 개별적으로 구성될 수 있다. 예 를 들어, BS는 UE 1, UE 2, UE 3 및 UE 4에 대해 C-RNTI와 스크램블링된 DCI에 대해 동일한 모니터링 기회를 구성할 수 있다.앞서 논의한 바와 같이, 예를 들어, 긴 통신 및/또는 계산 지연으로 인해, 지연 UE가 BS에 오래된 업데이트를 제공하는 경우, 오래된 업데이트를 활용하는 것은 글로벌 AI/ML 모델의 수렴에 해로울 수 있다. 일부 UE로부터 의 비동기 업데이트로 인해 발생할 수 있는 이러한 단점을 피하거나 적어도 완화하기 위해, 일부 실시예에서, UE가 업데이트가 기반을 두는 반복을 BS에 알리기 위해 자신의 업데이트된 로컬 AI/ML 모델 파라미터를 보고하 는 경우, UE는 UL 보고시 대응하는 반복 ID의 표시를 포함하도록 구성된다. 예를 들어, 도 9를 다시 참조하면, 9061,N, 9061,N+1, 9062,N, 9062,N+1, 9063,N 및 9064,N으로 표시된 각 UL 전송은, 9101,N, 9101,N+1, 9102,N, 9102,N+1, 9103,N 및 9104,N으로 표시된 것처럼, UL 전송에 포함된 로컬 AI/ML 모델 업데이트의 기반이 되는 해당 반복 ID를 나타내는 정보를 포함하는 것으로 표시되어 있다. 따라서, 보고된 반복 ID에 기초하여, BS는 로컬 업데이트가 오래된 것인지 여부를 식별하고 보고된 데이터를 폐기할지 또는 활용할지 여부를 결정할 수 있다. 도 10은 일 실시예에 따른 준동기 연합 학습을 위한 흐름도의 일 예를 도시한다. 블록에서, UE는 자신의 AI/ML 모델 훈련 능력을 BS에 보고한다. 앞서 설명한 바와 같이, AI/ML 모델 훈련 능력은 UE에 대한 AI/ML 처리 능력 및/또는 훈련 데이터 양을 기반으로 하거나 그를 포함할 수 있으며, 표 1에 나열된 AI/ML 모델 훈련 능력의 계층 구조를 참조하여 전술한 바와 같이 AI/ML 모델 훈련 능력 레벨 ID를 전송 함으로써 전달될 수 있다. 블록에서, BS는 UE에 의해 보고된 AI/ML 모델 훈련 능력에 기초하여, 훈련 프로세스에 참여할 UE를 선택 한다. 블록에서, BS는 훈련에 참여할 UE를 나타내고, UE가 훈련 프로세스의 주어진 반복에 참여할지를 결정할 수 있도록 하는 하나 이상의 규칙을 나타낸다. 예를 들어, 위에서 설명한 것처럼, 여기에는 BS가 UE로 하여금 주어진 반복에 참여할지 여부를 결정할 수 있도록 해주는 규칙으로 각 UE를 개별적으로 구성하는 것이 포함될 수 있다. 또는 대신, 여기에는, DCI(예컨대, 업데이트 모델에 대한 DL 전송을 스케줄링하는 DCI) 또는 RRC 또는 MAC-CE를 통해 반복에 참여할 UE의 타입을 표시하는 것이 포함될 수도 있다. 또 다른 옵션으로서, BS는 또한 또는 대신, 각 반복에 대해 글로벌 AI/ML 모델 업데이트의 DL 전송을 스케줄링하는 DCI에 대한 UE별 모니터링 기회로 UE를 구성할 수도 있다. 블록에서, UE는 UE의 AI/ML 모델 훈련 능력이 변경되었는지(증가 또는 감소)를 결정한다. 그렇지 않은 경 우, 블록에서, UE는 블록에서 구성된 훈련 규칙(들)에 따라 블록에서 주어진 훈련 반복에 선 택적으로 참여한다. 만약 훈련 규칙이 UE가 현재 훈련 반복에 참여하도록 나타내는 경우, 블록에서, UE는 현재 훈련 반복에 대해 BS로부터 업데이트된 글로벌 AI/ML 모델 파라미터를 수신하고, BS로부터의 업데이트된 글로벌 AI/ML 모델 파라미터에 기초하여 로컬 AI/ML 모델을 훈련한 후 로컬 AI/ML 모델 업데이트 파라미터를 BS 에 보고하고, 그 후에 UE는 블록으로 복귀한다. 대신에, UE가 블록에서 자신의 AI/ML 모델 훈련 능력이 변경되었다고 판단하면, 블록에서 UE는 자 신의 업데이트된 AI/ML 모델 훈련 능력을 BS에 보고하고, 이에 대한 응답으로 BS는 블록에서 선택적으로 표시된 바와 같이 업데이트된 AI/ML 모델 훈련 규칙을 UE에 표시할 수 있으며, 방법은 블록로 진행하여 업데이트된 훈련 규칙에 따라 선택적으로 훈련 프로세스에 참여하게 된다. 앞서 논의된 바와 같이, 도 10에 도시된 흐름도에 의해 표현된 예와 같은 준동기식 FL 훈련 프로세스는, 반복 간 훈련 레이턴시를 감소시킴으로써 잠재적으로 더 빠른 훈련 수렴을 달성하고, 및/또는 잠재적으로 글로벌 AI/ML 모델 파라미터의 DL 전송 및/또는 로컬 AI/ML 모델 파라미터의 UL 전송과 관련된 통신 오버헤드를 감소시 키는 것과 같은 종래 동기 및 비동기 FL보다 몇 가지 잠재적인 이점을 갖는다. 서로 다른 UE들에 대한 비동기 학습 횟수 본 개시의 제2 양상은, AI/ML 모델 훈련 프로세스 동안 상이한 UE들에 대해 비동기적인 훈련 반복 횟수를 갖는 메커니즘을 제공한다. 이러한 실시예들에서, AI/ML 모델 훈련 프로세스는 하나 이상의 반복에 대한 훈련 프로 세스에서 개별 UE의 동적 결합, 일시 중지 또는 탈락을 지원한다. 본 개시의 이러한 양상에서는, 동기식 FL의 경우에도, 서로 다른 UE에 대한 학습 횟수가 다를 수 있다. 특히, 본 개시의 이러한 양상은 예를 들어, UE의 AI/ML 모델 훈련 능력의 동적 보고에 기초하여, UE가 학습으로부터 동적으로 일시 중지/탈락되고 학습에 동적으 로 참여할 수 있도록 한다. 예를 들어, 낮은 AI/ML 또는 훈련 능력을 가진 UE의 경우, 이 UE는 학습 프로세스의 후반 단계에서 훈련 프로세스에 참여하여 훈련 프로세스 초기의 훈련 레이턴시를 줄일 수 있다. 또한, 일부 실 시예에서, 훈련 프로세스에 동적으로 참여하는 UE는 오버헤드를 줄이기 위해 부분적 모델(파라미터의 서브세트)만을 훈련하도록 구성될 수 있다. 반면에, 높은 AI/ML 모델 훈련 능력을 갖는 UE의 경우, 이 UE는 통신 및 컴퓨팅 오버헤드를 줄이기 위해 훈련 데이터의 가용성에 기초하여 훈련 프로세스를 동적으로 일시 중지하거나 훈련 프로세스에 합류할 수 있다. 도 11은 일 실시예에 따라, 비동기 연합 학습 절차의 다수의 반복에 걸쳐 4개의 UE(UE 1, UE 2, UE 3 및 UE 4) 에 의해 수행되는 동작들( 1100)의 타임라인을 도시한다. 특히, 도 11은 제1, 제2, N번째, (N+1)번째 및 (N+ 2)번째 반복에 대해 4개의 UE가 수행하는 동작을 보여주며, 여기서 비동기 연합 학습 절차의 N은 3이상이다. UE로부터의 반정적 및/또는 동적 피드백은 UE의 현재 처리 능력, UE에서의 반복적인 AI/ML 모델 훈련 프로세스 를 위해 이용 가능한 훈련 데이터의 현재 양, 또는 반복적인 AI/ML 모델 훈련 프로세스를 위한 훈련 데이터를 수집하는 UE의 센싱 능력 중 적어도 하나를 포함할 수 있다. 도 11에서, 제1 반복에 앞서, UE 1, UE 2, UE 3 및 UE 4는 각각 11021,1, 11022,1, 11023,1 및 11024,1에 표시된 바와 같이, 현재 AI/ML 모델 훈련 능력을 BS에 보고한다. 앞서 논의된 바와 같이, UE들에 의해 보고되는 AI/ML 모델 훈련 능력은 UE의 현재 처리 능력, UE에서의 반복적인 AI/ML 모델 훈련 프로세스에 이용 가능한 훈련 데이 터의 현재 양, 또는 반복적인 AI/ML 모델 훈련 프로세스를 위한 훈련 데이터를 수집하는 UE의 센싱 능력 중 적 어도 하나를 포함할 수 있다. 예시적인 목적을 위해, 이 예에서, 11021,1, 11022,1 및 11023,1에서 UE 1, UE 2 및 UE 3이 보고한 AI/ML 모델 훈 련 능력은 UE 1, UE 2 및 UE 3이 높은 처리 능력 및 대량의 훈련 데이터를 가짐을 나타낸다. 반대로, 11024,1에 서 UE 4가 보고한 AI/ML 모델 훈련 능력은 UE 4가 낮은 처리 능력(높은 처리 지연) 및/또는 소량의 훈련 데이터 를 가짐을 나타낸다. 낮은 통신 및 AI/ML 처리 지연과 대량의 데이터를 갖는 UE들(도 11에 도시된 예에서 UE 1, UE 2 및 UE 3)의 경 우, BS는 해당 UE들이 훈련 프로세스에 참여하고 제1 반복에 참여하도록 (예를 들어, 제어 시그널링을 통해) 지 시/구성한다. 반면에, 높은 AI/ML 처리 지연 및/또는 소량의 훈련 데이터를 갖는 UE(도 11 에 도시된 예에서의 UE 4)의 경우, BS는 대신에 훈련 프로세스로부터 UE를 일시 중지/탈락시킬 수 있으며, 이는 이 예에서 UE 4가 다른 UE와 함께 제1 반복에 참여하지 않음을 의미한다. 훈련 프로세스의 제1 반복에 대한 UE 1, UE 2 및 UE 3의 참여는 각각 11041,1, 11042,1 및 11043,1로 표시된다. 이 예에서는, 훈련 프로세스의 제1 반복에서의 UE 1, UE 2 및 UE 3의 참여가 각각 11041,2...N-1, 11042,2...N-1 및 11043,2...N-1로 표시된 것처럼 제2 내지 (N-1)번째 반복에서 계속 훈련 프로세스에 참여하게 된다. 그러나, N번째 반복에 앞서, UE 3은 11043,N로 표시된 것처럼 AI/ML 모델 훈련 능력의 변경을 보고하며, 이는 현재 UE 3의 처리 지연이 높거나 훈련 데이터 양이 적음을 나타낸다. 또는, 아래에서 더 상세히 논의되는 바와 같이, BS에 그의 업데이트된 AI/ML 모델 훈련 능력을 제공하기 보다는, UE 3은 또한, 또는 대신에, 학습 상태를 변경하라는 명시 적 요청을 BS에 전송할 수도 있다. 11023,N에서 UE 3에 의해 제공된 피드백에 대한 응답으로, UE 3은 N번째 반복에 대한 훈련 프로세스로부터 동적 으로 일시 중지/탈락된다. 반면, UE 1과 UE 2는 각각 11041,N과 11042,N에 표시된 것처럼 N번째 반복에 계속 참 여한다. UE가 학습을 일시 중지하면, 일반적으로 UE는 로컬 AI/ML 모델 업데이트를 수행하지 않으며 로컬 모델 파라미터를 보고하지 않는다. 그러나, 경우에 따라서는, 일시 중지된 UE 가 DL 글로벌 AI/ML 모델 업데이트를 수신하고 향후 학습을 위해 최신 DL AI/ML 모델 업데이트를 저장할 수 있다. (N+1)번째 반복에 앞서, UE 3은 11043,N+1에 표시된 바와 같이, AI/ML 모델 훈련 능력의 추가 변경을 보고하는데, 이는 UE 3이 현재 낮은 처리 지연 및/또는 높은 훈련 데이터 양을 갖는다는 것을 나타낸다. 예를 들어, UE 3가 훈련 프로세스 참여에 대한 최소 임계값을 충족할 만큼 충분한 훈련 데이터를 수집했고 및/또는 절전 모드를 종 료했을 수 있다. 또는, 아래에서 더 자세히 설명하는 바와 같이, BS에 그의 업데이트된 AI/ML 모델 훈련 능력을 제공하기보다, UE 3은 또한, 또는 대신에, 훈련 프로세스에 다시 참여하기 위해 학습 상태를 변경하라는 명시적 요청을 BS에 전송할 수도 있다. 예를 들어, 도 11 에 도시된 바와 같이, UE 4 의 AI/ML 모델 훈련 능력이 변경 되지 않았음에도 불구하고(즉, UE 4는 여전히 높은 처리 지연 및/또는 적은 훈련 데이터 양을 가지고 있음), UE 4는 훈련 프로세스가 후반 단계에 있다고 판단하여 (N+1)번째 반복에 대한 훈련 프로세스에 동적으로 참여하라 는 요청을 UE에게 전송할 수 있다. 예를 들어, 임계 횟수의 훈련 반복이 발생하면(예를 들어, 이 경우 임계 횟 수는 N일 수 있음), UE가 훈련 프로세스에 동적으로 참여하도록 요청하도록 구성될 수 있다. 앞서 설명한 바와같이, BS는 UE가 현재 훈련 단계를 알 수 있도록 UE에게 현재 반복 ID를 알릴 수 있다. 훈련 프로세스에 동적으 로 참여하도록 요청할 때, UE는 BS에 UE가 참여하고 있는 반복의 수(즉, 반복 ID)를 알려주어, BS가 해당 반복 에 참여하는 UE들을 인지할 수 있도록 할 수 있다. UE 3과 UE 4가 각각 11023,N+1과 11024,N+1에서 제공한 피드백에 응답하여, UE 3과 UE 4는 (N+1)번째 반복에 대해 UE 1과 UE 2와 함께 훈련 프로세스에 동적으로 참여한다. (N+1)번째 반복에서 UE 1, UE 2, UE 3 및 UE 4의 참 여는 각각 11041,N+1 11042,N+1, 11043,N+1 및 11044,N+1로 표시된다. 앞서 설명한 바와 같이, 후반 단계에서 훈련 프 로세스에 동적으로 참여하는 UE는 오버헤드를 줄이기 위해 부분적 모델(로컬 AI/ML 모델의 파라미터 서브세트) 만을 훈련하도록 구성될 수 있다. 예를 들어, 도 11에서, UE 4는 훈련 프로세스의 (N+1)번째 반복에 동적으로 참여한 후 부분적 모델만을 훈련한다. 예를 들어, UE 4는 BS에서 글로벌 AI/ML 모델에서 안정적이지 않은 로컬 AI/ML 모델의 더 적은 기울기/가중치를 훈련할 수 있다. 도 12는 일 실시예에 따라, 서로 다른 디바이스에 대해 비동기 학습 반복 횟수를 제공하기 위한 흐름도의 일 예 를 도시한다. 블록에서, UE는 자신의 AI/ML 모델 훈련 능력을 BS에 보고한다. 앞서 설명한 바와 같이, AI/ML 모델 훈련 능력은 UE에 대한 AI/ML 처리 능력 및/또는 학습 데이터 양을 기반으로 하거나 그를 포함할 수 있고, 표 1에 나 열된 AI/ML 모델 훈련 능력의 계층 구조를 참조하여 전술한 바와 같이 AI/ML 모델 훈련 능력 레벨 ID를 전송함 으로써 전달될 수 있다. 블록에서, BS는 UE에 의해 보고된 AI/ML 모델 훈련 능력에 기초하여, 훈련 프로세스에 참여할 UE를 선택 한다. 블록에서, BS는 훈련에 참여할 각 UE에 현재 AI/ML 모델 훈련 상태(예컨대, 참여 또는 일시 중지/탈락)를 나타낸다. 블록에서, UE는 자신의 현재 AI/ML 훈련 상태가 일시 중지/탈락인지 여부를 결정하며, 이는 UE가 훈련 프 로세스의 현재 반복에 참여해서는 안됨을 나타낸다. UE의 현재 AI/ML 훈련 상태가 일시 중지/탈락이 아닌 경우, 이 방법은 블록으로 진행하여 UE는 자신의 AI/ML 훈련 능력이 변경되었는지 여부를 확인한다. UE 의 AI/ML 훈련 능력이 변경되지 않은 경우, UE는 블록에서 훈련 프로세스의 현재 반복을 위한 훈련 절차, 예를 들어 업데이트된 글로벌 AI/ML 모델의 DL 전송을 수신하는 동작, 그의 로컬 AI/ML 모델을 훈련하는 것, 및 로컬 AI/ML 모델 업데이트를 BS에 보고하는 것을 구현한 후, 방법은 블록으로 복귀하여 현재 AI/ML 훈련 상태가 일시 중지/탈락인지 확인한다. 블록에서 UE가 자신의 AI/ML 훈련 능력이 변경되었다고 판단하면, 블록에서 UE는 자신의 변경된 AI/ML 모델 훈련 능력을 BS에 보고하고 및/또는 BS에게 자신의 AI/ML 훈련 상태를 변경하기 위한 요청을 전송한 다. 블록에서, 블록에서 UE가 제공한 피드백에 기초하여, BS는 업데이트된 AI/ML 훈련 상태를 UE 에 표시하고, 방법은 블록에서 블록으로 복귀하여 현재 AI/ML 훈련 상태가 일시 중지/탈락인지 확 인한다. 블록에서 UE가 자신의 현재 학습 상태가 일시 중지/탈락이라고 판단하면, 방법은 블록으로 진행하 여, UE는 자신의 로컬 AI/ML 모델을 업데이트하지 않고 자신의 로컬 AI/ML 모델 업데이트를 BS에 보고하지 않으 며, UE는 블록에서 자신의 AI/ML 모델 훈련 능력이 변경되었는지 또는 훈련 프로세스가 후반 단계에 있는 지 여부를 확인한다. 그렇지 않은 경우, 방법은 블록에서 블록으로 돌아간다. 반면에, UE가 블록 에서 자신의 AI/ML 모델 훈련 능력이 변경되었거나 훈련 프로세스이 후반 단계에 있다고 판단하는 경우, 블록의 일부 실시예에서, UE는 선택적으로 자신의 변경된 AI/ML 모델 훈련 능력을 BS에 보고하고 및/또는 BS에게 자신의 AI/ML 훈련 상태를 변경하기 위한 요청을 전송할 수 있다. 이 시나리오에서, 블록에서, BS는 선택적으로 블록에서 UE에 의해 제공된 피드백에 기초하여 업데이트된 AI/ML 훈련 상태를 UE에 표시 하고, 방법은 블록에서 블록으로 복귀하여 현재 AI/ML 훈련 상태가 일시 중지/탈락 상태인지 여부 를 확인한다. 앞서 논의한 바와 같이, 서로 다른 UE들이 서로 다른 횟수의 학습 반복에 비동기적으로 참여할 수 있도록 훈련 의 동적 결합 및/또는 일시 중지/탈락을 활성화하는 것은 일부 UE들에 대한 UL 통신 오버헤드를 감소시키고, FL 에서의 훈련 레이턴시를 감소시키는 것과 같은 몇 가지 잠재적인 이점을 가질 수 있다. 압축 피드백 파라미터 종래의 FL, 분산 학습 및 기타 학습 프로세스에서는, 예를 들어, 다수의 뉴런 노드 및 뉴런 노드들 간의 연결을 포함하는 대규모 신경망의 사용으로 인해, 일반적으로 다수의 파라미터(예를 들어, 기울기, 가중치, 바이어스) 가 보고되기 때문에, UE의 모델 파라미터 보고에 활용되는 통신 오버헤드는 매우 높을 수 있다. 그러나, 대부분 의 교환된 파라미터들은 중복된다. 따라서, UE는 잠재적으로 훈련 프로세스에 해로운 영향을 미치지 않으면서 보고된 AI/ML 파라미터들을 압축하여, 예를 들어, 일부 중요한 파라미터들만 보고함으로써 통신 오버헤드를 절약할 수 있다. 본 개시의 또 다른 양상은 보고될 필요가 있는 파라미터 및 그 값을 나타내는 메커니즘을 제공한다. 예를 들어, 일반적인 AI/ML 모델의 예를 나타내는 도 6a를 다시 참조하면, 파라미터 보고(예컨대 , 기울기, 가 중치, 바이어스)의 경우, UE는 표시 신호를 전송하여 BS에게 AI/ML 모델에 대해 보고된 파라미터를 알릴 수 있 다. 파라미터 유형(예컨대, 가중치)의 경우, UE는 사전 정의된 순서 또는 BS가 구성한 순서(예컨대, w1, w2, ..., wn)로 파라미터를 정렬할 수 있다. 그런 다음 UE는 보고되는 파라미터를 결정하고 해당 파라미터에 대한 할당 정보를 BS에 전송할 수 있다. 어떤 파라미터가 보고되는지 결정하고 할당 정보를 BS로 전송하는 메커니즘 의 네 가지 예가 아래에 설명되어 있다. 이러한 예는 제한이 없으며 설명 목적으로만 제공되었음을 알아야 한다. 파라미터 그룹(PG) 기반: 제1 옵션으로, 할당 정보는 PG가 연속된 파라미터 세트인 경우 보고되는 PG를 나타내 는 비트맵을 포함할 수 있다. PG의 크기는 BS에 의해 구성되거나 미리 정의될 수 있다. 예를 들어, 비트맵의 해당 비트 값이 1이면 PG는 BS에 보고되고, 그렇지 않으면 PG는 보고되지 않거나, 그 반대의 경우도 마찬가지이 다. 연속 파라미터 보고: 이 옵션에서, 할당 정보는 연속적으로 보고된 파라미터 세트를 나타내며, 할당 정보는 파 라미터의 시작 위치 및 보고된 파라미터 수를 포함한다. 연속된 파라미터의 여러 클러스터: 이 옵션에서, 할당 정보는 연속적으로 보고된 여러 개의 파라미터 세트를 나 타낸다. 각 세트에 대해, 할당 정보는 파라미터의 시작 위치와 보고된 파라미터 수를 나타낸다. 일부 계층 간의 파라미터: 이 옵션에서, UE는 AI/ML 모델의 일부 계층 간에 하나 또는 여러 개의 파라미터 세트 를 보고한다. 예를 들어, 계층 N과 계층 M 사이의 세트가 보고되며, 여기서 1≤ N이고 M≤AI/ML 모델의 총 계층 수이다. 또한, UE는 보고된 파라미터의 값을 알려야 한다. 통신 오버헤드를 줄이기 위해, 일부 실시예에서, UE는 범위 ID와 값 범위 사이의 미리 정의되거나 구성된 매핑에 기초하여 범위 ID를 표시함으로써 보고된 값의 범위를 나 타낼 수 있다. 이러한 실시예들에서, 파라미터 세트는 하나의 범위 ID에 연관되며, 즉 세트 내의 파라미터들은 동일한 값 범위를 가지며, 세트 내의 각 파라미터에 대해 개별적인 정확한 값 표시가 제공된다. 또한, 보고시에 보고된 다수의 파라미터 세트는 서로 다른 값 범위에 매핑될 수 있으며, 여기서 하나의 세트가 하나의 범위 ID 에 연관된다. 범위 ID를 활용하는 것의 이점은 비트 오버헤드를 감소시킨다는 것이다. 예를 들어, 범위 ID를 사용하지 않으면, -2에서 2까지의 값을 나타내기 위해 각 파라미터에 3 비트가 필요하며, 이는 N개의 파라미터의 경우, 3N 비트가 필요하다는 것을 의미한다. 반면, 표 2에 표시된 범위 ID를 파라미터 세트에 사용하면, 1 비트는 범 위 ID 표시용이고, 2 비트는 세트의 각 파라미터에 사용되는데, 이는 N개의 파라미터에 대해, 총 2N+1 비트가 필요하다는 것을 의미한다. 따라서, N이 클 경우 오버헤드가 크게 감소할 수 있다. 표 2 ID와 값 범위 간 매핑 표 2에 도시된 범위 ID와 값 범위 사이의 매핑 예시를 참조하여, 범위 ID 값(하나 이상의 비트로 표현)을 AI/ML 모델 파라미터 세트와 연결하면, AI/ML 모델 파라미터 세트와 연관된 범위 ID 값에 매핑되는 각각의 값 범위는 AI/ML 모델 파라미터 세트 내의 AI/ML 모델 파라미터 값의 비트 스트링의 범위 및 비트 의미를 결정함을 알 수 있다. 예를 들어, 주어진 AI/ML 모델 파라미터 값이 비트 스트링 \"10\"으로 표현되고 범위 ID 값이 \"0\"인 경우, 비트 스트링 \"10\"은 십진수 값 1에 매핑되는 반면, 범위 ID 값이 \"1\"인 경우, 동일한 비트 스트링 \"10\"은 십진 수 값 2에 매핑된다. 전술한 바와 같이, UE의 보고의 헤더는 표시 방법, 및/또는 보고된 파라미터들, 및/또는 파라미터 세트에 대한 범위 ID를 알려줄 수 있다. 또한, UL 파라미터 전송의 맥락에서 전술한 바와 같은 범위 ID 및 할당 정보의 사용은 DL 파라미터 전송에도 적 용될 수 있으며, 이는 DL 및 UL에서의 AI/ML 파라미터 전송을 위한 UE 및 BS 간의 통신 오버헤드를 감소시키기 위한 것임에 유의해야 한다. 본원에 개시된 방법들을 수행함으로써, 무선 인터페이스 자원 오버헤드 및 온라인 AI/ML 모델 훈련과 관련된 지 연을 감소시키면서 오버헤드 감소와 훈련 성능 사이의 절충을 제공할 수 있다. 본 명세서에 개시된 다양한 방법들을 수행하기 위한 디바이스들(예컨대, ED 또는 UE 및 TRP 또는 네트워크 디바 이스)의 예시들도 개시된다. 예를 들어, 제1 디바이스는 프로세서 실행가능 명령어들을 저장하는 메모리, 및 프로세서 실행가능 명령어들을 실행하는 프로세서를 포함할 수 있다. 프로세서가 프로세서 실행가능 명령어들을 실행할 때, 프로세서는, 예를 들어, 도 1 내지 도 12와 관련하여, 본원에 설명된 하나 이상의 디바이스들의 방법 단계들을 수행하게 된다. 예를 들어, 프로세서는 디바이스로 하여금, 동작 모드에 대해 구성된 바와 같이 필요한 측정을 수행하고, 그러 한 측정으로부터 콘텐츠를 생성하고, 업링크 전송을 준비하고, 인코딩, 디코딩 등과 같은 다운링크 전송을 처리 하며, RF 체인(들) 및 안테나(들)에서의 송수신을 구성 및/또는 지시하는 등의 동작을 구현함으로써 동작 모드 에서 무선 인터페이스를 통해 통신하게 한다. 본 명세서에서 사용되는 \"적어도 하나의 A 또는 B\"라는 표현은 \"A 및/또는 B\"라는 표현과 상호 교환이 가능하다 는 점에 유의한다. 이는 A 또는 B 또는 A와 B 모두를 선택할 수 있는 목록을 지칭한다. 마찬가지로, 본 명세서 에서 사용되는 \"A, B 또는 C 중 적어도 하나\"는 \"A 및/또는 B 및/또는 C\" 또는 \"A, B 및/또는 C\"와 상호 교환가 능하다. 이는 A 또는 B 또는 C, 또는 A와 B 둘 다, 또는 A와 C 둘 다, 또는 B와 C 둘 다, 또는 A, B 및 C 모 두를 선택할 수 있는 목록을 지칭한다. 동일한 형식을 갖는 긴 목록에도 동일한 원칙이 적용된다. 본 발명은 특정 특징 및 실시예를 참조하여 설명되었지만, 본 발명을 벗어나지 않는 범위 내에서 다양한 수정 및 조합이 이루어질 수 있다. 따라서, 설명 및 도면은 첨부된 청구범위에 의해 정의된 본 발명의 일부 실시예를 단순히 예시하는 것으로 간주되어야 하며, 본 발명의 범위에 속하는 모든 수정, 변형, 조합 또는 균등물을 포함 하는 것으로 간주된다. 따라서, 본 발명과 그 장점이 상세히 설명되었지만, 첨부된 청구범위에 의해 정의된 본 발명을 벗어나지 않는 범위 내에서 다양한 변경, 치환 및 변경이 본 명세서에서 이루어질 수 있다. 또한, 본 출 원의 범위는 본 명세서에 기재된 프로세스, 머신, 제조, 물질의 구성, 수단, 방법 및 단계의 특정 실시예에 한정되는 것은 아니다. 당업자가 본 발명의 개시를 통해 쉽게 이해할 수 있듯이, 본 명세서에 설명된 해당 실시 예와 실질적으로 동일한 기능을 수행하거나 실질적으로 동일한 결과를 달성하는 현재 존재하거나 향후 개발될 프로세스, 머신, 제조, 물질의 구성, 수단, 방법 또는 단계가 본 발명에 따라 이용될 수 있다. 따라서, 첨부된 청구범위는 그러한 프로세스, 머신, 제조, 물질의 구성, 수단, 방법 또는 단계를 그 범위 내에 포함하도록 의도 된다. 또한, 명령어를 실행하는 본원에 예시된 임의의 모듈, 컴포넌트 또는 디바이스는 컴퓨터/프로세서 판독가능 명 령어, 데이터 구조, 프로그램 모듈 및/또는 기타 데이터와 같은 정보의 저장을 위한 비일시적 컴퓨터/프로세서 판독가능 저장 매체 또는 매체들을 포함하거나 그에 대한 액세스를 가질 수 있다. 비일시적 컴퓨터/프로세서 판 독가능 저장 매체의 예로는 자기 카세트, 자기 테이프, 자기 디스크 저장소 또는 기타 자기 저장 디바이스, 컴 팩트 디스크 읽기 전용 메모리(CD-ROM), 디지털 비디오 디스크 또는 디지털 다목적 디스크(DVD), 블루레이 디스 크™ 또는 기타 광학 저장소, 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 이동식 및 비이동식 매체, 액세스 메모리(RAM), 읽기 전용 메모리(ROM), 전기 삭제 가능한 프로그래밍 가능 읽기 전용 메모리(EEPROM), 플 래시 메모리 또는 기타 메모리 기술 등을 포함한다. 이러한 비일시적 컴퓨터/프로세서 저장 매체는 디바이스의 일부이거나 이에 액세스하거나 연결가능하다. 본 명세서에서 설명된 임의의 애플리케이션 또는 모듈은 그러한 비일시적 컴퓨터/프로세서 읽기가능 저장 매체에 저장되거나 달리 보유될 수 있는 컴퓨터/프로세서 읽기가능/실 행가능 명령어를 사용하여 구현될 수 있다. 약어의 정의 LTE: 롱텀에볼루션 NR: 뉴 라디오 BWP: 대역폭 부분 BS: 기지국 CA: 반송파 집성 CC: 컴포넌트 반송파 CG: 셀 그룹 CSI: 채널 상태 정보 CSI-RS: 채널 상태 정보 참조 신호 DC: 이중 연결성 DCI: 다운링크 제어 정보 DL: 다운링크 DL-SCH: 다운링크 공유 채널 EN-DC: E-UTRA E-UTRA를 사용하는 MCG와 NR을 사용하는 SCG의 이중 연결 gNB: 차세대(또는 5G) 기지국 HARQ-ACK: 하이브리드 자동 반복 요청 승인 MCG: 마스터 셀 그룹 MCS: 변조 및 코딩 기법 MAC-CE: 매체 액세스 제어-제어 요소 PBCH: 물리적 브로드캐스트 채널 PCell: 1차 셀 PDCCH: 물리적 다운링크 제어 채널 PDSCH: 물리적 다운링크 공유 채널 PRACH: 물리적 랜덤 액세스 채널 PRG: 물리적 자원 블록 그룹 PSCell: 1차 SCG 셀 PSS: 기본 동기화 신호 PUCCH: 물리적 업링크 제어 채널 PUSCH: 물리적 업링크 공유 채널 RACH: 랜덤 액세스 채널 RAPID: 랜덤 액세스 프리앰블 ID RB: 자원 블록 RE: 자원 요소 RRM: 무선 자원 관리 RMSI: 잔여 시스템 정보 RS: 참조 신호 RSRP: 참조 신호 수신 전력 RRC: 무선 자원 제어 SCG: 2차 셀 그룹 SFN: 시스템 프레임 번호 SL: 사이드 링크 SCell: 2차 셀 SPS: 반-지속적 스케줄링 SR: 스케줄링 요청 SRI: SRS 자원 표시기 SRS: 소리 기준 신호 SSS: 보조 동기화 신호 SSB: 동기화 신호 블록 SUL: 보충 업링크 TA: 타이밍 조정 TAG: 타이밍 조정 그룹 TUE: 대상 UE UCI: 업링크 제어 정보 UE: 사용자 장비 UL: 업링크 UL-SCH: 업링크 공유 채널 도면 도면1 도면2 도면3 도면4 도면5 도면6a 도면6b 도면7 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2024-7032742", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이제, 본 출원의 예시적인 실시예들을 보여주는 첨부된 도면들을 예시적으로만 참조할 것이며, 그 도면들은 다 음과 같다: 도 1은 일 예에 따른 통신 시스템의 단순화된 개략도이다. 도 2는 통신 시스템의 다른 예를 도시한다. 도 3은 전자 디바이스(ED), 지상 송수신 지점(T-TRP) 및 비지상 송수신 지점(NT-TRP)의 일 예를 도시한다. 도 4는 디바이스 내의 예시적인 유닛 또는 모듈을 도시한다. 도 5는 일 실시예에 따라, 통신 시스템에서 네트워크 디바이스와 통신하는 4개의 ED를 예시적으로 도시한다. 도 6a는 일 실시예에 따른, 다수의 뉴런 층을 갖는 신경망의 예를 도시한다. 도 6b는 일 실시예에 따라, 신경망의 빌딩 블록으로 사용될 수 있는 뉴런의 일 예를 도시한다. 도 7은 동기 연합 학습 절차의 한 반복에 대해 4개의 ED에 의해 수행되는 동작의 타임라인을 예시한다. 도 8은 비동기 연합 학습 절차의 복수의 반복에 대해 4개의 ED에 의해 수행되는 동작의 타임라인을 도시한다. 도 9는 일 실시예에 따라, 준동기 연합 학습 절차의 복수의 반복에 걸쳐 4개의 ED에 의해 수행되는 동작의 타임 라인을 도시한다. 도 10은 일 실시예에 따른 준동기 연합 학습을 위한 흐름도의 일 예를 도시한다. 도 11은 일 실시예에 따른, 비동기 연합 학습 절차의 복수의 반복에 걸쳐 4개의 ED에 의해 수행되는 동작의 타 임라인을 도시한다. 도 12는 일 실시예에 따른 비동기 연합 학습을 위한 흐름도의 일 예를 도시한다.상이한 도면에서 유사한 컴포넌트를 나타내기 위해 유사한 참조 번호가 사용되었다."}
