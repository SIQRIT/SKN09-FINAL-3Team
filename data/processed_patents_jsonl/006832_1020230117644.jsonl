{"patent_id": "10-2023-0117644", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0035240", "출원번호": "10-2023-0117644", "발명의 명칭": "얼굴 기반의 이모티콘 생성 장치", "출원인": "주식회사 엘리펀트에이아이", "발명자": "김동래"}}
{"patent_id": "10-2023-0117644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "얼굴 영상을 입력 받는 얼굴 영상 입력부;표정 변화가 있는 기준 얼굴 영상의 얼굴 움직임 정보를 상기 얼굴 영상에 적용하여 상기 얼굴 영상 내 얼굴이서로 다른 다수의 표정을 갖도록 변화된 다수의 얼굴 표정 영상을 생성하는 얼굴 표정 영상 생성부; 및상기 얼굴 표정 영상에 대한 그래픽 처리를 각각 수행하여 다수의 얼굴 이모티콘을 생성하는 얼굴 이모티콘 생성부를 포함하는 얼굴 기반의 이모티콘 생성 장치."}
{"patent_id": "10-2023-0117644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 얼굴 영상 입력부는,얼굴 표정 변화가 적용될 인물의 실제 얼굴 사진 파일 또는 캐릭터 얼굴 이미지 파일을 입력 받는 것을 특징으로 하는 얼굴 기반 이모티콘 생성 장치."}
{"patent_id": "10-2023-0117644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 얼굴 표정 영상 생성부는,상기 얼굴 영상으로부터 미리 정의된 위치의 얼굴 특징점을 인식하고, 인식된 다수의 제1 얼굴 특징점을 추출하는 제1 얼굴 특징점 인식부;시간의 흐름에 따라 얼굴 표정 변화가 있는 인물의 얼굴 동영상 파일을 포함하는 상기 기준 얼굴 영상을 저장하는 기준 얼굴 영상 저장부;상기 기준 얼굴 영상으로부터 미리 정의된 위치의 얼굴 특징점 인식을 통해 추출된 다수의 제2 얼굴 특징점을저장하는 제2 얼굴 특징점 관리부;상기 제2 얼굴 특징점에 대한 움직임 분석을 통해 생성된 제2 얼굴 특징점 움직임 정보를 저장하는 제2 얼굴 특징점 움직임 정보 관리부;상기 제1 얼굴 특징점 및 상기 제2 얼굴 특징점 간을 서로 1:1 매칭하는 얼굴 특징점 매칭부; 및상기 제2 얼굴 특징점 움직임 정보를 상기 제1 얼굴 특징점에 반영하여 상기 얼굴 영상 내 얼굴에 각기 다른 시점의 표정이 각각 적용된 다수의 얼굴 표정 이미지 파일 및 시간의 흐름에 따른 변화하는 표정이 각각 적용된다수의 얼굴 표정 동영상 파일 중 적어도 하나를 생성하는 얼굴 표정 영상 파일 생성부를 포함하는 것을 특징으로 하는 얼굴 기반 이모티콘 생성 장치."}
{"patent_id": "10-2023-0117644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,사용자로부터 목표 연령대를 선택 받고, 상기 얼굴 표정 영상 생성부를 통해 생성된 얼굴 표정 영상의 얼굴에대하여 사용자에 의해 선택된 목표 연령대의 나이로 변환하고, 변환된 얼굴 표정 영상을 상기 얼굴 이모티콘 생성부로 제공하는 얼굴 나이 변환부를 더 포함하는 것을 특징으로 하는 얼굴 기반 이모티콘 생성 장치.공개특허 10-2025-0035240-3-청구항 5 제1 항에 있어서,사용자로부터 캐리커처 변환 및 애니메이션 효과를 포함하는 특수 효과를 선택 받고, 상기 얼굴 표정 영상 생성부를 통해 생성된 얼굴 표정 영상의 얼굴에 대하여 사용자에 의해 선택된 특수 효과를 적용하고, 특수 효과가적용된 얼굴 표정 영상을 상기 얼굴 이모티콘 생성부로 제공하는 특수 효과 적용부를 더 포함하는 것을 특징으로 하는 얼굴 기반 이모티콘 생성 장치."}
{"patent_id": "10-2023-0117644", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 얼굴 기반의 이모티콘 생성 장치에 관한 것으로, 해결하고자 하는 과제는 사용자가 자신의 실제 사진 을 이용하여 다수의 이모티콘을 생성 가능하도록 함으로써, 제한된 이모티콘의 캐릭터를 넘어서 사용자의 개성을 반영한 얼굴 이모티콘을 생성하는데 있다. 일례로, 얼굴 영상을 입력 받는 얼굴 영상 입력부; 표정 변화가 있는 기준 얼굴 영상의 얼굴 움직임 정보를 상기 얼굴 영상에 적용하여 상기 얼굴 영상 내 얼굴이 서로 다른 다수의 표정을 갖도록 변화된 다수의 얼굴 표정 영상 을 생성하는 얼굴 표정 영상 생성부; 및 상기 얼굴 표정 영상에 대한 그래픽 처리를 각각 수행하여 다수의 얼굴 이모티콘을 생성하는 얼굴 이모티콘 생성부를 포함하는 얼굴 기반의 이모티콘 생성 장치를 개시한다."}
{"patent_id": "10-2023-0117644", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예는 얼굴 기반의 이모티콘 생성 장치에 관한 것이다."}
{"patent_id": "10-2023-0117644", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "근래 많은 사람들이 인터넷에 접속 가능하거나 또는 다양한 콘텐츠의 이용을 지원하는 다양한 모바일 기기를 사 용하고 있고, 해당 기기에서 다양한 메신저 및 메일 등의 어플리케이션을 사용한다. 사용자들은 메신저 등의 어플리케이션에서 다양한 이모티콘(Emoticon)을 사용하여 자신의 상태 또는 기분을 표 현한다. 이모티콘은 감정을 뜻하는 단어(Emotion)과 아이콘(Icon)의 합성어를 의미한다. 인터넷 초기에는 초기에는 사용자들이 문자와 기호, 숫자 등을 조합하여 만든 텍스트(Text) 기반의 이모티콘이 사용되었다. 그러나, 최근에 멀티미디어 방식을 지원하는 메신저 등의 다양한 어플리케이션에서 그림 형식의 이모티콘을 지 원하고 있고, 사용자들은 감정을 나타내는 다양한 종류의 이모티콘을 이용하여 서로 교류하고 있다. 종래 메신저 등의 어플리케이션은 캐릭터에 기반한 이모티콘들을 지원한다. 그림 방식의 이모티콘들은 캐릭터의 웃는 표정, 찡그린 표정, 우는 표정 등 캐릭터에 기반한 것이다. 또한, 종래 메신저 등의 어플리케이션에서 사 용되는 이모티콘의 종류 및 표정은 한정되어 있다. 그러나, 사용자들은 다양한 이모티콘을 원하고 있으며, 특히 자신의 실제 얼굴 사진을 이용하여 생성된 이모티 콘을 사용할 경우 자신의 개성을 반영하여 감정을 표현할 수 있다. 또한, 사용자들은 미리 정해진 표정뿐만 아니라 다양한 표정에 대한 이모티콘을 스스로 만들고 싶은 욕구를 가 지고 있다. 따라서, 사용자가 자신의 실제 사진을 가지고 이모티콘을 생성할 수 있으며, 사용자가 원하는 표정의 이모티콘 을 생성할 수 있는 이모티콘 생성 장치 및 방법이 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제10-2014-0049340호(공개일자: 2014년04월25일) (특허문헌 0002) 공개특허공보 제10-2010-0028689호(공개일자: 2010년03월15일)"}
{"patent_id": "10-2023-0117644", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예는, 사용자가 자신의 실제 사진을 이용하여 다수의 이모티콘을 생성 가능하도록 함으로써, 제 한된 이모티콘의 캐릭터를 넘어서 사용자의 개성을 반영할 수 있는 얼굴 기반의 이모티콘 생성 장치를제공한다."}
{"patent_id": "10-2023-0117644", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 얼굴 기반의 이모티콘 생성 장치는, 얼굴 영상을 입력 받는 얼굴 영상 입력부; 표정 변화가 있는 기준 얼굴 영상의 얼굴 움직임 정보를 상기 얼굴 영상에 적용하여 상기 얼굴 영상 내 얼굴이 서로 다른 다수의 표정을 갖도록 변화된 다수의 얼굴 표정 영상을 생성하는 얼굴 표정 영상 생성부; 및 상기 얼굴 표 정 영상에 대한 그래픽 처리를 각각 수행하여 다수의 얼굴 이모티콘을 생성하는 얼굴 이모티콘 생성부를 포함한 다. 또한, 상기 얼굴 영상 입력부는, 얼굴 표정 변화가 적용될 인물의 실제 얼굴 사진 파일 또는 캐릭터 얼굴 이미 지 파일을 입력 받을 수 있다. 또한, 상기 얼굴 표정 영상 생성부는, 상기 얼굴 영상으로부터 미리 정의된 위치의 얼굴 특징점을 인식하고, 인 식된 다수의 제1 얼굴 특징점을 추출하는 제1 얼굴 특징점 인식부; 시간의 흐름에 따라 얼굴 표정 변화가 있는 인물의 얼굴 동영상 파일을 포함하는 상기 기준 얼굴 영상을 저장하는 기준 얼굴 영상 저장부; 상기 기준 얼굴 영상으로부터 미리 정의된 위치의 얼굴 특징점 인식을 통해 추출된 다수의 제2 얼굴 특징점을 저장하는 제2 얼 굴 특징점 관리부; 상기 제2 얼굴 특징점에 대한 움직임 분석을 통해 생성된 제2 얼굴 특징점 움직임 정보를 저 장하는 제2 얼굴 특징점 움직임 정보 관리부; 상기 제1 얼굴 특징점 및 상기 제2 얼굴 특징점 간을 서로 1:1 매 칭하는 얼굴 특징점 매칭부; 및 상기 제2 얼굴 특징점 움직임 정보를 상기 제1 얼굴 특징점에 반영하여 상기 얼 굴 영상 내 얼굴에 각기 다른 시점의 표정이 각각 적용된 다수의 얼굴 표정 이미지 파일 및 시간의 흐름에 따른 변화하는 표정이 각각 적용된 다수의 얼굴 표정 동영상 파일 중 적어도 하나를 생성하는 얼굴 표정 영상 파일 생성부를 포함할 수 있다. 또한, 사용자로부터 목표 연령대를 선택 받고, 상기 얼굴 표정 영상 생성부를 통해 생성된 얼굴 표정 영상의 얼 굴에 대하여 사용자에 의해 선택된 목표 연령대의 나이로 변환하고, 변환된 얼굴 표정 영상을 상기 얼굴 이모티 콘 생성부로 제공하는 얼굴 나이 변환부를 더 포함할 수 있다. 또한, 사용자로부터 캐리커처 변환 및 애니메이션 효과를 포함하는 특수 효과를 선택 받고, 상기 얼굴 표정 영 상 생성부를 통해 생성된 얼굴 표정 영상의 얼굴에 대하여 사용자에 의해 선택된 특수 효과를 적용하고, 특수 효과가 적용된 얼굴 표정 영상을 상기 얼굴 이모티콘 생성부로 제공하는 특수 효과 적용부를 더 포함할 수 있다. 또한, 상기 제2 얼굴 특징점 움직임 정보 관리부는, 2차원 공간 상에서 인식된 상기 제2 얼굴 특징점 각각에 대 하여 시간 변화량에 따른 벡터값을 추출하여 상기 제2 얼굴 특징점 움직임 정보를 생성하거나, 3차원 공간 상에 서의 얼굴 특징점 움직임 정보에 대하여 기계 학습된 인공지능 알고리즘이 미리 구축되고, 상기 인공지능 알고 리즘에 상기 제2 얼굴 특징점 움직임 정보를 입력하여 Z축에 대한 추가 얼굴 특징점 움직임 정보를 출력하고, 상기 추가 얼굴 특징점 움직임 정보를 상기 제2 얼굴 특징점 움직임 정보와 결합하여 3차원 공간 상에서의 얼굴 특징 움직임 정보를 생성할 수 있다. 또한, 상기 기준 얼굴 영상 저장부는, 상기 기준 얼굴 영상을 등록하되, 서로 다른 인물 또는 서로 다른 표정 변화가 있는 적어도 두 개의 기준 얼굴 영상을 등록하고, 상기 얼굴 표정 영상 생성부는, 상기 적어도 두 개의 기준 얼굴 영상을 대상으로 서로 다른 얼굴 영역에 대한 얼굴 특징점을 각각 나누어 인식하도록 상기 제2 얼굴 특징점 관리부의 기능 동작을 설정하는 제2 얼굴 특징점 인식 설정부를 더 포함하고, 상기 제2 얼굴 특징점 관 리부는, 상기 제2 얼굴 특징점 인식 설정부의 기능 동작 설정에 따라 상기 적어도 두 개의 기준 얼굴 영상 중 어느 한 영상의 얼굴에 대하여 특정 얼굴 영역에 대한 얼굴 부분 특징점을 인식 및 추출하고, 나머지 다른 영상 의 얼굴에 대하여 나머지 특정 얼굴 영역에 대한 얼굴 부분 특징점을 인식 및 추출하는 방식으로 동작하고, 얼 굴 부분 특징점들을 취합하여 상기 제2 얼굴 특징점으로서 상기 얼굴 특징점 매칭부와 공유하고, 상기 제2 얼굴 특징점 인식 설정부는, 상기 적어도 두 개의 기준 얼굴 영상에 대하여 얼굴 특징점에 각각 할당된 고유번호의 범위를 서로 다르게 설정하여 상기 적어도 두 개의 기준 얼굴 영상에 대하여 서로 다른 얼굴 영역을 각각 지정 할 수 있다."}
{"patent_id": "10-2023-0117644", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 사용자가 자신의 실제 사진을 이용하여 다수의 이모티콘을 생성 가능하도록 함으로써, 제한 된 이모티콘의 캐릭터를 넘어서 사용자의 개성을 반영할 수 있는 얼굴 기반의 이모티콘 생성 장치를 제공할 수있다."}
{"patent_id": "10-2023-0117644", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 발명에 대해 구체적으로 설명하기로 한다. 본 발명에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나 이상의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 본 발명의 실시예에 따른 얼굴 기반의 이모티콘 생성 장치의 개요도이다. 도 1을 참조하면, 본 발명의 실시예에 따른 얼굴 기반의 이모티콘 생성 장치는 사용자 통신단말를 포 함할 수 있으며, 추가적으로 인공지능 서버를 더 포함할 수 있다. 상기 사용자 통신단말은 적어도 하나의 얼굴 영상 파일(실제 얼굴 사진 파일 또는 캐릭터 얼굴 이미지 파일)을 입력 받고, 미리 구비된 기준 얼굴 영상의 얼굴 움직임 정보를 입력된 얼굴 영상에 적용하여 사용자가 입력한 얼굴 영상 내 얼굴이 서로 다른 다수의 표정(ex. 슬픈 표정, 기쁜 표정, 바쁜 표정 등의 감정이 적용된 표정)을 갖도록 변화된 다수의 얼굴 표정 영상을 생성할 수 있으며, 생성된 얼굴 표정 영상들에 대한 그래픽 처 리(이모티콘 제작을 위한 그래픽 처리)를 각각 수행하여 다양한 표정을 갖는 다수의 얼굴 이모티콘을 생성할 수 있다. 이러한 사용자 통신단말은 스마트폰(smartphone), 스마트 패드(smartpad), 타블렛 PC(Tablet PC), PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말 등 서비스 요청자가 휴대 가능한 무선 통신 장치 및 거치 형 PC, 노트북과 같은 휴대용 컴퓨팅 장치를 포괄할 수 있다. 상기 인공지능 서버는 사용자 통신단말의 일부 기능을 처리하거나 분업하는 형태로 얼굴 표정 생성 프 로세스의 처리가 가능하도록 구성될 수 있다. 예를 들어, 사용자 통신단말에서 사용자 옵션에 따라 기준 얼 굴 영상으로부터의 3차원 얼굴 표정을 생성하는 기능, 얼굴 나이를 목표 연령대로 변환하여 얼굴 영상에 적용하 는 기능, 얼굴 영상에 특수 효과를 적용하는 기능 등 프로세서와 데이터 소스에 대한 지속적인 업데이트를 필요 로 하는 구성이나 대용량의 처리 공간이 요구되는 구성에 대해서는 인공지능 기반의 웹 서버에서 그 기능을 지 원하는 형태로 운영될 수도 있다. 이러한 인공지능 서버는, 하드웨어적으로 통상적인 웹 서버와 동일한 구 성을 가지며, 소프트웨어적으로는 C, C++, Java, Visual Basic, Visual C 등과 같은 다양한 형태의 언어를 통 해 구현되어 여러 가지 기능을 하는 프로그램 모듈을 포함할 수 있으며, 인공지능 기술(머신러닝 알고리즘)이 탑재되어 얼굴의 표정 변화에 대한 벡터값 추정과 관련된 다양한 기능을 수행할 수 있다. 또한, 일반적인 서버 용 하드웨어에 도스(dos), 윈도우 (window), 리눅스(linux), 유닉스(unix), 매킨토시(macintosh), 안드로이드 (Android), 아이오에스(iOS) 등의 운영 체제에 따라 다양하게 제공되고 있는 웹 서버 프로그램을 이용하여 구현 될 수 있다. 본 실시예에 따른 사용자 통신단말 및 인공지능 서버 간을 연결하는 네트워크 통신의 일 예로는, 이동 통신을 위한 기술표준들 또는 통신방식(예를 들어, GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), CDMA2000(Code Division Multi Access 2000), EV-DO(Enhanced Voice-Data Optimized or Enhanced Voice-Data Only), WCDMA(Wideband CDMA), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced), 5G 등)에 따라 구축된 이동 통신망을 포함할 수 있으나, 특별히 한정하는 것은 아니다. 또한, 유선 통신망의 일 예로는, LAN(Local Area Network), WAN(Wide Area Network)등의 폐쇄형 네트워크일 수 있으며, 인터넷과 같은 개방형 네트워크인 것이 바람직하다. 인터넷은 TCP/IP 프로토콜 및 그 상위계층에 존재하는 여러 서비스, 즉 HTTP(HyperText Transfer Protocol), Telnet, FTP(File Transfer Protocol), DNS(Domain Name System), SMTP(Simple Mail Transfer Protocol), SNMP(Simple Network Management Protocol), NFS(Network File Service), NIS(Network Information Service)를 제공하는 전세계적인 개방형 컴퓨터 네트워크 구조를 의미한다. 도 2는 본 발명의 실시예에 따른 얼굴 기반의 이모티콘 생성 장치의 구성을 나타낸 블록도이고, 도 3은 본 발명 의 실시예에 따른 얼굴 표정 영상 생성부의 구성을 나타낸 블록도이고, 도 4는 본 발명의 실시예에 따른 제1 얼 굴 특징점 인식부를 통한 제1 얼굴 특징점들의 인식 결과에 대한 일례를 나타낸 도면이고, 도 5는 본 발명의 실 시예에 따른 기준 얼굴 영상 저장부에서 제공하는 기준 얼굴 영상, 제2 얼굴 특징점 관리부를 통해 관리되는 기 준 얼굴 영상의 제2 얼굴 특징점, 및 제2 얼굴 특징점 움직임 정보 관리부를 통해 관리되는 제2 얼굴 특징점 움 직임 정보의 일례를 나타낸 도면이고, 도 6은 본 발명의 실시예에 따른 제2 얼굴 특징점 움직임 정보 관리부를 통한 2차원 및 3차원 얼굴 특징점 움직임 정보를 생성 및 관리하는 기능을 설명하기 위해 나타낸 도면이고, 도 7은 본 발명의 실시예에 따른 제1 얼굴 특징점과 제2 얼굴 특징점 간의 1:1 매칭을 보여주기 위해 나타낸 도면 이고, 도 8은 본 발명의 실시예에 따른 제2 얼굴 특징점 움직임 정보를 제1 얼굴 특징점에 반영하여 표정 변화를 적용한 과정을 설명하기 위해 나타낸 도면이고, 도 9는 본 발명의 실시예에 따른 입력 데이터(얼굴 영상)와 출력 데이터(얼굴 표정 영상 또는 얼굴 이모티콘)에 대한 이해를 돕기 위해 예시한 도면이고, 도 10은 본 발명 의 실시예에 따른 제2 얼굴 특징점 인식 설정부의 기능 구성을 설명하기 위해 나타낸 도면이고, 도 11 및 도 12 는 본 발명의 실시예에 따른 제2 얼굴 특징점 인식 설정부의 ROI 설정에 따른 얼굴 특징점 매칭부 및 얼굴 표정 영상 파일 생성부의 기능 구성을 설명하기 위해 나타낸 도면이고, 도 13은 본 발명의 실시예에 따른 얼굴 나이 변환부를 통해 얼굴의 나이가 변환된 얼굴 표정 영상에 대한 이해를 돕기 위해 예시한 도면이며, 도 14는 본 발 명의 실시예에 따른 특수 효과 적용부를 통해 특수 효과가 적용된 얼굴 표정 영상에 대한 이해를 돕기 위해 예 시한 도면이다. 도 2를 참조하면, 본 발명의 실시예에 따른 얼굴 기반의 이모티콘 생성 장치는 얼굴 영상 입력부, 얼 굴 표정 영상 생성부, 얼굴 나이 변환부, 특수 효과 적용부 및 얼굴 이모티콘 생성부 중 적어도 하나를 포함할 수 있다. 상기 얼굴 영상 입력부는 사용자로부터 적어도 하나의 얼굴 영상 파일을 입력 받을 수 있다. 이때, 입력 가능한 얼굴 영상 파일은 얼굴 표정 변화가 적용될 인물의 실제 얼굴 사진 파일 또는 캐릭터 얼굴 이미지 파일 을 포함할 수 있다. 여기서 실제 얼굴 사진은 사용자 본인뿐만 아니라, 이모티콘화 하고자 하는 대상의 인물 사 진이 적용될 수 있으며, 사람뿐만 아니라 반려동물의 얼굴 또한 적용 가능하다. 또한, 실제 얼굴 사진은 표정이 없는 사진인 경우 추후 다양한 표정 변화를 인위적으로 생성할 수 있으며, 특정한 표정을 갖는 사진인 경우, 사 용자의 선택에 따라 해당 표정 그대로의 얼굴 영상을 그래픽 처리를 통해 얼굴 이모티콘으로 바로 변환할 수도 있다. 상기 얼굴 표정 영상 생성부는, 다양한 표정 변화가 있는 기준 얼굴 영상의 얼굴 움직임(표정 변화) 정보 (얼굴 특징점 벡터 정보)를 얼굴 영상에 적용하여 얼굴 영상 내 얼굴이 서로 다른 다수의 표정을 갖도록 변화된 다수의 얼굴 표정 영상을 생성할 수 있다. 이를 위해 얼굴 이모티콘 생성부는 도 3에 도시된 바와 같이, 제1 얼굴 특징점 인식부, 기준 얼굴 영 상 저장부, 제2 얼굴 특징점 관리부, 제2 얼굴 특징점 움직임 정보 관리부, 얼굴 특징점 매칭부 , 얼굴 표정 영상 파일 생성부 및 제2 얼굴 특징점 인식 설정부 중 적어도 하나를 포함할 수 있 다. 상기 제1 얼굴 특징점 인식부는, 사용자가 입력한 얼굴 영상으로부터 미리 정의된 위치의 얼굴 특징점을 인식하고, 인식된 다수의 제1 얼굴 특징점을 추할 수 있다. 좀 더 구체적으로, 제1 얼굴 특징점 인식부는 얼굴 영상(실제 얼굴 사진 또는 캐릭터 얼굴 이미지)로부터 미리 정의된 위치의 얼굴 특징점들(이하 제1 얼굴 특징점이라고 함)을 각각 인식하고, 도 4에 도시된 바와 같이 인식된 다수의 제1 얼굴 특징점(예를 들어 68개)을 추출할 수 있다. 제1 얼굴 특징점은 영상 내의 얼굴 영역에 서 눈썹, 눈, 코, 입술, 턱 라인 등 그 위치가 미리 정의되어 있으며, 영상 속 인물의 얼굴 영역으로부터 인식 되는 다수 개(예를 들어 68개)의 점 분포도로서 표출될 수 있다. 이와 같이 얼굴 영상에서 제1 얼굴 특징점을 인식하기 위해서는, 우선 영상 속 인물(실제 사람, 캐릭터)의 얼굴 영역을 찾아 동일한 형태의 정면 얼굴을 추출하는 전처리 과정이 선행돼야 한다. 이러한 전처리 과정은 입력된 사진 또는 이미지에서 얼굴 영역을 찾는 얼굴 검출 과정(face detection), 눈과 코 등 얼굴의 특징을 나타내는 점을 찾는 얼굴 정렬 과정(face alignment), 얼굴 정렬 과정의 특징점을 이용해 얼굴 영역을 동일한 형태와 크 기로 변경하는 정규화 과정(normalization)을 포함할 수 있다. 상기 기준 얼굴 영상 저장부는, 시간의 흐름에 따라 얼굴 표정 변화가 있는 인물의 얼굴 동영상 파일을 포 함하는 기준 얼굴 영상을 생성하여 저장 관리할 수 있다. 좀 더 구체적으로, 기준 얼굴 영상 저장부는 다양한 기준 얼굴 영상들을 등록하여 저장할 수 있다. 이때, 기준 얼굴 영상은 도 5에 도시된 모델 한 명을 대상으로 다양한 표정(슬픈 표정, 기쁜 표정, 바쁜 표정 등의 감 정이 적용된 표정)을 촬영한 영상들일 수 있으나, 반드시 이에 한정되는 것은 아니며, 서로 다른 다수의 인물이 각각의 표정을 짓는 다수의 영상일 수 있으며, 서로 다른 표정 변화가 있는 적어도 두 개의 영상일 수도 있다. 이러한 기준 얼굴 영상은 사용자가 입력한 얼굴 영상에 다양한 표정(슬픈 표정, 기쁜 표정, 바쁜 표정 등의 감 정이 적용된 표정)에 대한 기준 정보를 제공할 수 있으며, 주기적으로 업데이트 될 수 있다. 즉, 다양한 기준 표정 정보를 제공할 모델이 추가되거나, 기존 모델이 갖는 표정이 추가되는 등의 기준 표정 정보에 대한 업데이 트가 주기적으로 수행될 수 있다.상기 제2 얼굴 특징점 관리부는, 기준 얼굴 영상으로부터 미리 정의된 위치의 얼굴 특징점 인식을 통해 추 출된 다수의 제2 얼굴 특징점을 생성 및 저장 관리할 수 있다. 이를 위해 제2 얼굴 특징점 관리부는 미리 저장된 기준 얼굴 영상으로부터 미리 정의된 위치의 얼굴 특징 점들(이하 제2 얼굴 특징점이라고 함)을 각각 인식하고, 도 5에 도시된 바와 같이 인식된 다수의 제2 얼굴 특징 점(예를 들어 68개)을 추출할 수 있다. 상술한 바와 같이 제2 얼굴 특징점들은 영상 내의 얼굴 영역에서 눈썹, 눈, 코, 입술, 턱 라인 등 그 위치가 미리 정의되어 있으며, 제2 인물의 얼굴 영역으로부터 인식되는 다수 개 (예를 들어 68개)의 점 분포도로서 표출될 수 있다. 이와 같이 기준 얼굴 영상에서 제2 얼굴 특징점을 인식하기 위해서는 상술한 바와 같이 전처리 과정을 수행해야 하지만, 이에 앞서 동영상을 일정 시간 단위의 영상 프레임으로 나눈 후 각 영상 프레임 별로 전처리 과정을 수 행해야 한다. 상기 제2 얼굴 특징점 움직임 정보 관리부는, 제2 얼굴 특징점에 대한 움직임 분석을 통해 생성된 제2 얼 굴 특징점 움직임 정보를 생성 및 저장 관리할 수 있다. 좀 더 구체적으로는, 도 6에 도시된 바와 같이 2차원 공간 상에서 인식된 제2 얼굴 특징점 각각에 대하여 시간 변화량에 따른 벡터값(XY)을 추출하여 제2 얼굴 특징점 움직임 정보를 생성할 수 있다. 이러한 제2 얼굴 특징점 의 움직임 분석 결과는 제2 얼굴 특징점 각각에 대한 XY 값을 갖는 벡터로 도출될 수 있으며, 이를 위해 전후 또는 인접한 영상 프레임 내 제2 얼굴 특징점들을 추적하고, 그에 따라 각 제2 얼굴 특징점에 대한 위치 변화와 속도 변화 등에 대한 벡터값을 계산할 수 있다. 또한, 제2 얼굴 특징점 움직임 정보 관리부는, 도 7에 도시된 바와 같이 3차원 공간 상에서의 얼굴 특징점 움직임 정보에 대하여 기계 학습된 인공지능 알고리즘이 미리 구축되고, 미리 구축된 인공지능 알고리즘에 제2 얼굴 특징점 움직임 정보를 입력하여 Z축에 대한 추가 얼굴 특징점 움직임 정보를 출력하고, 출력된 추가 얼굴 특징점 움직임 정보(Z축 벡터값)를 제2 얼굴 특징점 움직임 정보(XY축 벡터값)에 결합 또는 추가하여 3차원 공 간 상에서의 얼굴 특징 움직임 정보를 생성할 수 있다. 본 실시예에서는 2차원 공간 상에서 나타나는 제2 얼굴 특징점 움직임 정보(XY축 벡터값)을 이용하는 것을 기본 설정으로 이루어지나, 사용자 옵션에 따라 Z축 방향(화면 상에서 전후방 방향)에 대한 얼굴 움직임 정보까지 예 측하여 추가할 수 있다. 일반적으로 촬영은 3차원 상의 인물을 촬영하지만 촬영된 결과물인 동영상은 2차원 상 에서 표출되므로, 하나의 영상물을 기반으로 3차원의 움직임까지 인식하기는 상당히 어렵다. 예를 들어, 입술 부위를 특정하는 특징점이 있다고 가정했을 때, 기준 얼굴 영상의 모델이 어떠한 표정을 지었지만 XY축 방향으 로 나타나는 움직임이 거의 없고 X축 방향으로 나타나는 움직임만 있는 경우가 있다(예를 들어 입술 모양을 유 지한 채 입술을 앞으로만 내미는 표정). 이러한 경우, 제2 얼굴 특징점 움직임 분석 결과로는 해당 입술의 움직임이 없는 것으로 인식되기 때문에, 실제 로 해당 모델이 Z축 방향으로 얼굴 특정 부위를 움직였음에도 불구하고 사용자가 입력한 얼굴 영상 속 인물의 표정에는 반영될 정보가 없게 된다. 이러한 문제를 해결하기 위하여, XY축 방향에 대한 벡터값으로 Z축 방향에 대한 벡터값을 기계 학습한 인공지능 알고리즘을 활용하여 미세한 XY축 벡터값만으로 Z축 벡터값을 추정하고, 추정된 값을 적용함으로써 보다 정교한 표정 변화에 대한 검출이 가능해진다. 예를 들어, XY축 벡터값이 원을 그리며 미세하게 회전하는 방향을 갖거나 미리 정의된 특정 패턴을 갖는 방향을 갖는지를 인공지능 알고리즘을 통해 검출하여 특정 위치에 대한 Z축 방향에 대한 벡터값을 추정할 수 있다. 상기 얼굴 특징점 매칭부는, 제1 얼굴 특징점 인식부를 통해 추출된 제1 얼굴 특징점과, 미리 구비된 제2 얼굴 특징점 간을 서로 1:1 매칭할 수 있다. 이때, 얼굴 영역에서 인식되는 제1 얼굴 특징점 및 제2 얼굴 특징점 각각은 68개의 점 분포도로서 각각의 점들은 고유번호가 미리 할당되어 있다. 이에 따라 68개의 제1 얼 굴 특징점과 68개의 제2 얼굴 특징점을 각 고유번호 별로 1:1 매칭할 수 있다. 상기 얼굴 표정 영상 파일 생성부는, 제2 얼굴 특징점 움직임 정보를 제1 얼굴 특징점에 반영하여 얼굴 영 상 내 얼굴(얼굴 영역)에 각기 다른 시점의 표정이 각각 적용된 다수의 얼굴 표정 이미지 파일 및 시간의 흐름 에 따른 변화하는 표정이 각각 적용된 다수의 얼굴 표정 동영상 파일 중 적어도 하나를 생성할 수 있다. 예를 들어 도 9에 도시된 바와 같이, 무표정의 얼굴을 촬영한 실제 얼굴 사진을 입력 받으면, 실제 얼굴 사진 속 인물의 얼굴에 얼굴 표정 1 내지 5을 갖도록 변환된 얼굴 표정 영상을 각각 생성하여 출력할 수 있으며, 각 각의 얼굴 표정 영상은 각각의 특정 시점에서 각기 다른 표정을 갖는 이미지 파일일 수 있으며, 짧은 동영상 형태의 파일일 수 있다. 이러한 동영상 파일에는 해당 인물의 표정 변화가 나타날 수 있으며, 일례로, 방긋 웃는 표정 변화, 슬프게 우는 표정 변화, 한숨 쉬며 우울해하는 표정 변화 등 다양한 표정의 변화가 적용될 수 있다. 상기 제2 얼굴 특징점 인식 설정부는, 적어도 두 개의 기준 얼굴 영상을 대상으로 서로 다른 얼굴 영역에 대한 얼굴 특징점을 각각 나누어 인식하도록 제2 얼굴 특징점 관리부의 기능 동작을 설정할 수 있다. 이에 앞서, 도 10에 도시된 바와 같이, 기준 얼굴 영상 저장부를 통하여 특정한 표정 또는 표정 변화를 갖 는 제1 인물의 기준 얼굴 영상과, 또 다른 표정 또는 표정 변화를 갖는 제2 인물의 기준 얼굴 영상을 입력 받을 수 있으며, 본 실시예에서는 설명의 편의를 위하여 2개의 서로 다른 기준 얼굴 영상이 등록된 경우를 일례로 하 여 설명한다. 상기 제2 얼굴 특징점 인식 설정부는 별도의 UI(User Interface)를 통한 사용자 옵션 조작에 따라 실행될 수 있다. 제2 얼굴 특징점 인식 설정부에 의한 사용자 옵션이 설정된 경우, 도 10에 도시된 바와 같이 제2 얼굴 특징점 관리부는, 적어도 두 개의 기준 얼굴 영상 중 어느 한 기준 얼굴 영상(이하 제1 기준 얼굴 영 상이라고 함)에 대하여 특정 얼굴 영역(이하 제1 얼굴 영역(ROI_1)이라고 함, ROI: Region Of Interest)에 대 한 얼굴 부분 특징점(이하 제1 기준 얼굴 특징점이라고 함)을 인식 및 추출하고, 나머지 다른 기준 얼굴 영상 (이하 제22 기준 얼굴 영상이라고 함)에 대하여 나머지 특정 얼굴 영역(이하 제2 얼굴 영역(ROI_2)라고 함)에 대한 얼굴 부분 특징점(이하 제2 기준 얼굴 특징점이라고 함)을 인식 및 추출하는 방식으로 동작하고, 도 11에 도시된 바와 얼굴 부분 특징점들을 취합하여 제2 얼굴 특징점으로서 얼굴 특징점 매칭부와 공유할 수 있다. 예를 들어, 도 10에 도시된 바와 같이 제1 기준 얼굴 영상에 대해서는 코부터 눈썹까지의 영역을 제1 얼굴 영역 (ROI_1)으로 설정하고, 제2 기준 얼굴 영상에 대해서는 코 아래부터 턱까지의 영역을 제2 얼굴 영역(ROI_2)으로 설정할 수 있다. 이때, 또한, 제1 얼굴 영역(ROI_1)과 제2 얼굴 영역(ROI_2)의 합은 하나의 얼굴 영역이 된다. 이와 같은 ROI는 얼굴 특징점의 분포도에 대하여 미리 정의되어 있어, 별도의 UI(User Interface)를 통해 어떠 한 얼굴 데이터에 대하여 어떠한 ROI를 적용할 것인지를 지정함으로써 서로 다른 제2 얼굴 데이터 별로 서로 다 른 얼굴 영역을 지정할 수 있다. 예를 들어, 얼굴 특징점은 1번부터 68번까지 각 얼굴 특정 부위 별로 고유번호 를 가지고 있어, 1번부터 45번까지를 제1 얼굴 영역(ROI_1)으로 지정하고, 46번부터 68번까지를 제2 얼굴 영역 (ROI_2)으로 지정할 수 있으며, 고유번호 지정 범위 또한 구성된 얼굴 영역의 수만큼 구분되어 미리 정의되어 있다. 상기 제2 얼굴 특징점 인식 설정부를 통해 제1 얼굴 영역(ROI_1)과 제2 얼굴 영역(ROI_2)이 설정된 정보를 얼굴 특징점 매칭부와 공유함으로써, 도 11에 도시된 바와 같이 제1 얼굴 영역(ROI_1)과 제2 얼굴 영역 (ROI_2)에 해당하는 각각의 얼굴 특징점들이 제1 얼굴 특징점과 1:1 매칭될 수 있으며, 이후 도 12에 도시된 바 와 같이 제1 얼굴 영역(ROI_1)과 제2 얼굴 영역(ROI_2)의 움직임 정보(XZ축 벡터값 또는 XYZ축 벡터값)를 제1 얼굴 특징점에 반영하여 얼굴 표정 영상를 생성하는 과정을 수행할 수 있다. 상기 얼굴 나이 변환부는, 사용자로부터 목표 연령대(ex. 10대, 20대, 30대, ..., 60대, 70대)를 선택 받 고, 얼굴 표정 영상 생성부를 통해 생성된 얼굴 표정 영상의 얼굴에 대하여 사용자에 의해 선택된 목표 연 령대의 나이로 변환(도 13의 예시 참조)하고, 변환된 얼굴 표정 영상을 얼굴 이모티콘 생성부로 제공할 수 있다. 좀 더 구체적으로 얼굴 나이 변환부는, 얼굴 표정 영상 생성부를 통해 생성된 얼굴 표정 영상의 얼굴 로부터 랜드마크를 추출하고, 랜드마크가 추출된 얼굴 표정 영상의 얼굴로부터 사용자에 의해 설정된 목표 연령 대에 대한 얼굴 텍스쳐를 생성하고, 랜드마크가 추출된 얼굴 표정 영상의 얼굴로부터 목표 연령대에 대한 얼굴 모양을 생성하고, 목표 연령대에 대한 얼굴 텍스쳐 및 얼굴 모양에 기초하여 얼굴 표정 영상 생성부를 통 해 생성된 얼굴 표정 영상의 얼굴을 목표 연령대의 얼굴로 변환할 수 있다. 이에 따라 실사 이미지를 입력했을 때 젊어 지거나 노인처럼 변화된 얼굴 이미지를 얻을 수 있다. 또한, 얼굴 나이 변환부는 성별 변환도 가능하다. 즉, 남성의 원본 얼굴을 여성의 기준 얼굴에 적용하거나, 여성의 원본 얼굴을 남성의 기준 얼굴에 적용하는 것도 가능하다. 상기 특수 효과 적용부는, 도 14에 도시된 바와 같이 사용자로부터 캐리커처 변환 및 애니메이션 효과(ex. 얼굴 색/채도, 머리 색/채도, 눈/코/입 색/채도, 배경 색/채도 변경, 전체 흑백)를 포함하는 특수 효과를 선택 받고, 얼굴 표정 영상 생성부를 통해 생성된 얼굴 표정 영상의 얼굴에 대하여 사용자에 의해 선택된 특수효과를 적용하고, 특수 효과가 적용된 얼굴 표정 영상을 얼굴 이모티콘 생성부로 제공할 수 있다. 상기 얼굴 이모티콘 생성부는 얼굴 표정 영상에 대한 그래픽 처리를 각각 수행하여 다수의 얼굴 이모티콘 을 생성할 수 있다. 예들 들어, 얼굴 표정 영상 즉 변환된 얼굴의 몸통을 애니메이션 그래픽을 적용하여 특정 포즈를 취하는 그래픽 처리, 배경에 반짝이 효과, 폭죽 효과, 점멸 효과 등의 애니메이션 그래픽을 적용하는 그 래픽 처리 등을 부가하여 실제 얼굴 그대로가 아닌 이모티콘으로서 갖춰야할 그래픽 요소가 부가될 수 있도록 하며, 이는 사용자의 설정(그래픽 카테고리 설정 방식)에 따라 진행되거나, 미리 준비된 그래픽 처리가 자동으 로 진행되도록 할 수 있다. 상기 얼굴 이모티콘 생성부를 통해 최종으로 출력되는 얼굴 이모티콘은 다양한 종류의 프레임을 갖는 서로 다른 이모티콘을 포함할 수 있으며, 다수의 얼굴 이모티콘은 1프레임 내지 수십 프레임으로 구성된 이미지 파일 일 수 있다. 이러한 얼굴 이모티콘은, 메신저 또는 문자 채팅 시 이모티콘으로 사용되거나, 이들의 배경이미지 를 추가 합성될 수 있다. 한편, 상술한 바와 같이 사용자가 입력한 얼굴에 대한 표정 변형 없이 이모티콘화를 위한 그래픽 처리만 적용될 수 있으며, 이러한 경우 원본 얼굴이 별도의 표정 변화 없이 그대로 사용 가능해도 되는 경우에 한하며, 이모티 콘화를 위한 그래픽 처리가 생략될 수도 있다. 이러한 경우 얼굴 표정이 변경된 영상을 별도의 효과 적용 없이 그대로 이모티콘으로 적용하여 사용할 수 있다. 이상에서 설명한 것은 본 발명에 의한 얼굴 기반의 이모티콘 생성 장치를 실시하기 위한 하나의 실시예에 불과 한 것으로서, 본 발명은 상기 실시예에 한정되지 않고, 이하의 특허청구범위에서 청구하는 바와 같이 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 분야에서 통상의 지식을 가진 자라면 누구든지 다양한 변경 실시가 가능한 범위까지 본 발명의 기술적 정신이 있다고 할 것이다."}
{"patent_id": "10-2023-0117644", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 얼굴 기반의 이모티콘 생성 장치의 개요도이다. 도 2는 본 발명의 실시예에 따른 얼굴 기반의 이모티콘 생성 장치의 구성을 나타낸 블록도이다. 도 3은 본 발명의 실시예에 따른 얼굴 표정 영상 생성부의 구성을 나타낸 블록도이다. 도 4는 본 발명의 실시예에 따른 제1 얼굴 특징점 인식부를 통한 제1 얼굴 특징점들의 인식 결과에 대한 일례를 나타낸 도면이다. 도 5는 본 발명의 실시예에 따른 기준 얼굴 영상 저장부에서 제공하는 기준 얼굴 영상, 제2 얼굴 특징점 관리부 를 통해 관리되는 기준 얼굴 영상의 제2 얼굴 특징점, 및 제2 얼굴 특징점 움직임 정보 관리부를 통해 관리되는 제2 얼굴 특징점 움직임 정보의 일례를 나타낸 도면이다. 도 6은 본 발명의 실시예에 따른 제2 얼굴 특징점 움직임 정보 관리부를 통한 2차원 및 3차원 얼굴 특징점 움직 임 정보를 생성 및 관리하는 기능을 설명하기 위해 나타낸 도면이다. 도 7은 본 발명의 실시예에 따른 제1 얼굴 특징점과 제2 얼굴 특징점 간의 1:1 매칭을 보여주기 위해 나타낸 도 면이다. 도 8은 본 발명의 실시예에 따른 제2 얼굴 특징점 움직임 정보를 제1 얼굴 특징점에 반영하여 표정 변화를 적용 한 과정을 설명하기 위해 나타낸 도면이다. 도 9는 본 발명의 실시예에 따른 입력 데이터(얼굴 영상)와 출력 데이터(얼굴 표정 영상 또는 얼굴 이모티콘)에 대한 이해를 돕기 위해 예시한 도면이다. 도 10은 본 발명의 실시예에 따른 제2 얼굴 특징점 인식 설정부의 기능 구성을 설명하기 위해 나타낸 도면이다. 도 11 및 도 12는 본 발명의 실시예에 따른 제2 얼굴 특징점 인식 설정부의 ROI 설정에 따른 얼굴 특징점 매칭 부 및 얼굴 표정 영상 파일 생성부의 기능 구성을 설명하기 위해 나타낸 도면이다. 도 13은 본 발명의 실시예에 따른 얼굴 나이 변환부를 통해 얼굴의 나이가 변환된 얼굴 표정 영상에 대한 이해 를 돕기 위해 예시한 도면이다. 도 14는 본 발명의 실시예에 따른 특수 효과 적용부를 통해 특수 효과가 적용된 얼굴 표정 영상에 대한 이해를 돕기 위해 예시한 도면이다."}
