{"patent_id": "10-2024-7008865", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0167424", "출원번호": "10-2024-7008865", "발명의 명칭": "게이밍 애플리케이션을 위한 품질 보증 게임 봇", "출원인": "모들.에이아이 에이피에스", "발명자": "페데르센 크리스토퍼 홀름가드"}}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "방법으로서,프로세서를 포함하는 시스템을 통해, 품질 보증(quality assurance: QA) 게임 봇을 생성하는 단계;상기 시스템을 통해, 게임에 대응하는 게이밍 애플리케이션을 수용하는 단계;상기 시스템을 통해, 상기 QA 게임 봇에 의한 게임 플레이에 기초하여 상기 게이밍 애플리케이션을 업데이트하여 제1 업데이트된 게임에 대응하는 제1 업데이트된 게이밍 애플리케이션을 생성하는 단계;상기 시스템을 통해, 상기 제1 업데이트된 게임의 실제 플레이어에 대응하는 상기 제1 업데이트된 게이밍 애플리케이션의 게임 텔레메트리 데이터를 수신하는 단계;상기 시스템을 통해, 실제 플레이어에 대응하는 상기 제1 업데이트된 게이밍 애플리케이션의 상기 게임 텔레메트리 데이터에 기초하여 상기 QA 게이밍 봇을 업데이트하여 업데이트된 QA 게이밍 봇을 생성하는 단계; 및상기 시스템을 통해, 상기 업데이트된 QA 게임 봇에 의한 상기 제1 업데이트된 게임의 플레이에 기초하여 상기제1 업데이트된 게이밍 애플리케이션을 업데이트하여 제2 업데이트된 게임에 대응하는 제2 업데이트된 게이밍애플리케이션을 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 QA 게임 봇은 인공 지능(artificial intelligence: AI) 모델을 통해 구현되는, 방법."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 QA 게임 봇은 복수의 QA 봇 제어 행동을 갖는, 방법."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 복수의 QA 봇 제어 행동은 상기 QA 게임 봇이 플레이어 입력 시스템에 통합되고 상기 게임을 탐색하여 상기 게임이 작동하는 방식에 대한 데이터를 수집하는 탐색 행동을 포함하는, 방법."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 탐색 행동은 가능한 액션을 새로운 게임 상태에 매핑하는 것을 포함하는, 방법."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서, 상기 QA 게임 봇에는 탐색할 상기 게임 또는 게임 콘텐츠의 특정한 영역이 할당되는, 방법."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서, 상기 탐색 행동은 상기 게임의 버그와 글리치를 검출하는 글리치 파인더(glitch finder)를 포함하는, 방법."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 글리치 파인더는 순차적인 이상치 검출을 활용하는, 방법."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제4항에 있어서, 상기 복수의 QA 봇 제어 행동은 상기 QA 게임 봇이 테스트 사례를 규정하는 시연 데이터에 기초하여 일련의 액션을 재생하고, 상기 QA 게임 봇이 재생이 실패할 때를 인식하는 복제 행동을 포함하는, 방법.공개특허 10-2024-0167424-3-청구항 10 제9항에 있어서, 상기 복수의 QA 봇 제어 행동은 상기 QA 게임 봇이 상기 실제 플레이어를 모방하도록 훈련되는모방 행동을 포함하는, 방법."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "시스템으로서,프로세서;상기 프로세서에 의해 실행될 때, 상기 프로세서가 작동을 수행하게 하는 작동 명령어를 저장하도록 구성된 메모리를 포함하되, 상기 작동은,품질 보증(QA) 게임 봇을 생성하는 것;게임에 대응하는 게이밍 애플리케이션을 수용하는 것;상기 QA 게임 봇에 의한 게임 플레이에 기초하여 상기 게이밍 애플리케이션을 업데이트하여 제1 업데이트된 게임에 대응하는 제1 업데이트된 게이밍 애플리케이션을 생성하는 것;상기 제1 업데이트된 게임의 실제 플레이어에 대응하는 상기 제1 업데이트된 게이밍 애플리케이션의 게임 텔레메트리 데이터를 수신하는 것;실제 플레이어에 대응하는 상기 제1 업데이트된 게이밍 애플리케이션의 상기 게임 텔레메트리 데이터에 기초하여 상기 QA 게이밍 봇을 업데이트하여 업데이트된 QA 게이밍 봇을 생성하는 것; 및상기 업데이트된 QA 게임 봇에 의한 상기 제1 업데이트된 게임의 플레이에 기초하여 상기 제1 업데이트된 게이밍 애플리케이션을 업데이트하여 제2 업데이트된 게임에 대응하는 제2 업데이트된 게이밍 애플리케이션을 생성하는 것을 포함하는, 시스템."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 QA 게임 봇은 인공 지능(AI) 모델을 통해 구현되는, 시스템."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 QA 게임 봇은 복수의 QA 봇 제어 행동을 갖는, 시스템."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 복수의 QA 봇 제어 행동은 상기 QA 게임 봇이 플레이어 입력 시스템에 통합되고 상기 게임을 탐색하여 상기 게임이 작동하는 방식에 대한 데이터를 수집하는 탐색 행동을 포함하는, 시스템."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 탐색 행동은 가능한 액션을 새로운 게임 상태에 매핑하는 것을 포함하는, 시스템."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서, 상기 QA 게임 봇에는 탐색할 상기 게임 또는 게임 콘텐츠의 특정한 영역이 할당되는, 시스템."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서, 상기 탐색 행동은 상기 게임의 버그와 글리치를 검출하는 글리치 파인더를 포함하는, 시스템."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 글리치 파인더는 순차적인 이상치 검출을 활용하는, 시스템."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "공개특허 10-2024-0167424-4-제14항에 있어서, 상기 복수의 QA 봇 제어 행동은 상기 QA 게임 봇이 테스트 사례를 규정하는 시연 데이터에 기초하여 일련의 액션을 재생하고, 상기 QA 게임 봇이 재생이 실패할 때를 인식하는 복제 행동을 포함하는, 시스템."}
{"patent_id": "10-2024-7008865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 복수의 QA 봇 제어 행동은 상기 QA 게임 봇이 상기 실제 플레이어를 모방하도록 훈련되는 모방 행동을 포함하는, 시스템."}
{"patent_id": "10-2024-7008865", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다양한 실시형태에서, 프로세서를 포함하는 시스템을 통해, 품질 보증(QA) 게임 봇을 생성하는 단계; 시스템을 통해, 게임에 대응하는 게이밍 애플리케이션을 수용하는 단계; 시스템을 통해, QA 게임 봇에 의한 게임 플레이에 기초하여 게이밍 애플리케이션을 업데이트하여 제1 업데이트된 게임에 대응하는 제1 업데이트된 게이밍 애플리케 (뒷면에 계속)"}
{"patent_id": "10-2024-7008865", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시내용은 게이밍 시스템 및 다른 게이밍 디바이스에 의해 사용되는 게이밍 애플리케이션의 개발에서 사용 되는 처리 시스템 및 애플리케이션에 관한 것이다."}
{"patent_id": "10-2024-7008865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 본 개시내용의 실시형태에 따른 게임 개발 시스템의 삽화/블록도를 나타낸다. 특히, 네트워크를 통 해 모바일 디바이스 및 게이밍 시스템와 같은 게이밍 디바이스와 네트워크를 통해 게임 데이터 및 플레이어 데이터를 통신하는 게임 개발 플랫폼이 제공된다. 네트워크는 인터넷 또는 다른 광역 통신망 또는 근거리 통신망일 수 있다. 게임 개발 시스템은 게이밍 애플리케이션의 생성, 개발,테스팅, 밸런싱 및 업데이팅에서 사용될 수 있다. 게임 데이터는, 예를 들어, 플레이를 위해 게이밍 디바이스에 제공되는 현재 버전의 게이밍 애플리케이션 을 포함할 수 있다. 게다가, 게이밍 디바이스로부터 게임 개발 플랫폼으로 전송되는 게임 데이터는 게임 텔레메트리 데이터를 포함할 수 있거나 게임 개발에서 사용되는 게임 텔레메트리 데이터 및/또는 다른 게 임 분석 정보를 생성하도록 처리될 수 있다. 플레이어 데이터는 하나 이상의 출력 모드, 예컨대, 게이밍 시스템(112 또는 113)과 연관된 마이크로폰에 의해 생성되는 플레이어 또는 시청자 구두 데이터, 플레이어 또는 시청자와 연관된 채팅 데이터 및/또는 플레이어 또는 시청자의 비-구두 데이터, 예컨대, 얼굴 표정, 머리 자세, 및/또는, 예를 들어, 플레이어 및/또는 시청자 참여, 반응 또는 감정을 나타내는 게이밍 시스템(112 또는 113) 과 연관된 카메라 또는 다른 영상 센서를 통해 캡처되는 다른 비-구두 데이터를 포함할 수 있다. 게임 개발 플랫폼의 작동이 여러 개의 임의의 기능 및 특징 및 이의 예를 포함하여, 도 2 내지 도 14와 함 께 더 상세히 설명될 것이다. 특히, 게임 애플리케이션 개발의 기술과 게이밍 애플리케이션의 기술 자체 둘 다 에 대한 개선이 본 명세서에 제공된다. 도 2는 본 개시내용의 실시형태에 따른 게임 개발 플랫폼의 블록도를 나타낸다. 특히, 게임 개발 플랫폼은 네트워크 인터페이스, 예컨대, 3G, 4G, 5G 또는 다른 셀룰러 무선 송수신기, 블루투스 송수신기, 와이파이 송수신기, 초광대역 송수신기, 위맥스 송수신기, 지그비 송수신기 또는 다른 무선 인터페이스, 범용 직렬 버스 (Universal Serial Bus: USB) 인터페이스, IEEE 1394 파이어와이어 인터페이스, 이더넷 인터페이스 또는 다른 유선 인터페이스 및/또는 네트워크를 통해 하나 이상의 게이밍 디바이스와 통신하기 위한 다른 네트워크 카드 또는 모뎀을 포함한다. 네트워크는 인터넷 또는 다른 공중 또는 사설 네트워크일 수 있다. 게임 개발 플랫폼은 또한 처리 모듈 및 운영 체제(O/S), 예컨대, 애플, 유닉스, 리눅스 또는 마 이크로소프트 운영 체제 또는 다른 운영 체제를 저장하는 메모리 모듈, 게임 개발 애플리케이션, 하 나 이상의 게이밍 애플리케이션, 하나 이상의 게이밍 봇, 하나 이상의 PCG(procedural content generation) 툴, 및 하나 이상의 BEA(behavioral experience analysis) 툴을 포함한다. 특히, O/S, 게임 개발 애플리케이션, 게이밍 애플리케이션, 게이밍 봇, PCG 툴 및 BEA 툴 은 처리 모듈에 의해 실행될 때, 처리 모듈을 본 명세서에 설명된 특정한 기능을 수행하는 특수 목적 디바이스로 구성하도록 협력하는 작동 명령어를 각각 포함한다. 게임 개발 플랫폼은 또한 사용자 인터페이스(user interface: I/F), 예컨대, 디스플레이 디바이스, 터치 스크린, 키 패드, 터치 패드, 조이 스틱, 지동륜, 마우스, 하나 이상의 버튼, 스피커, 마이크로폰, 가속도 계, 자이로스코프 또는 다른 움직임 또는 위치 센서, 비디오 카메라 또는 정보를 게임 개발 플랫폼의 사용 자에게 제공하고 게임 개발 플랫폼과의 사용자의 상호작용에 응답하여 데이터를 생성하는 다른 인터페이스 디바이스를 포함할 수 있다. 처리 모듈은 단일 처리 디바이스 또는 복수의 처리 디바이스를 통해 구현될 수 있다. 이러한 처리 디바이 스는 마이크로프로세서, 마이크로-컨트롤러, 디지털 신호 프로세서, 마이크로컴퓨터, 중앙 처리 장치, 필드 프 로그래밍 가능 게이트 어레이, 프로그래밍 가능 논리 디바이스, 상태 기계, 논리 회로망, 아날로그 회로망, 디 지털 회로망, 및/또는 메모리, 예컨대, 메모리에 저장되는 작동 명령어에 기초하여 신호(아날로그 및/또는 디지털)를 조작하는 임의의 디바이스를 포함할 수 있다. 메모리 모듈은 하드 디스크 드라이브 또는 다른 디스크 드라이브, 판독 전용 메모리, 임의 접근 메모리, 휘발성 메모리, 비휘발성 메모리, 정적 메모리, 동적 메모리, 플래시 메모리, 캐시 메모리, 및/또는 디지털 정보를 저장하는 임의의 디바이스를 포함할 수 있다. 처 리 디바이스가 상태 기계, 아날로그 회로망, 디지털 회로망 및/또는 논리 회로망을 통해 기능 중 하나 이상을 구현할 때, 대응하는 작동 명령어를 저장하는 메모리가 상태 기계, 아날로그 회로망, 디지털 회로망 및/또는 논 리 회로망을 포함하는 회로망 내에 내장되거나 그 외부에 있을 수 있다는 것에 유의한다. 단일 버스를 포 함하는 특정한 버스 아키텍처가 제공되지만, 하나 이상의 요소 간의 부가적인 데이터 버스 및/또는 직접 연결을 포함하는 다른 아키텍처가 가능하다. 게다가, 게임 개발 플랫폼은 구체적으로 도시되지 않은 하나 이상의 부가적인 요소를 포함할 수 있다. 게임 개발 애플리케이션은 게이밍 애플리케이션의 생성, 개발, 테스팅, 밸런싱, 개선, 수정, 적응 최 적화 및/또는 업데이팅을 돕고 촉진하기 위해 게임 개발자에 의해 사용될 수 있다. 게이밍 애플리케이션은, 예를 들어, 슈터를 포함하는 멀티플레이어 또는 단일 플레이어 게임 또는 다른 전투 게임, 판타지 게임 또는 다른 액션 또는 어드벤처 게임, 실세계 차량 디바이스 또는 시스템의 작동을 시뮬레이 션하는 시뮬레이션 게임, 실시간 전략 게임, 퍼즐, 스포츠 게임, 롤-플레잉 게임, 보드 게임 또는 다른 비디오또는 디지털 방식으로 애니메이션된 게임일 수 있다. 다양한 실시형태에서, 예를 들어, 게이밍 애플리케이션의 다수의 버전 또는 업데이트, 게임 매개변수의 하나 이상의 세트, 게임 프로파일 또는 게임 옵션, 하나 이상의 레벨 및 다른 콘텐츠 및/또는 다른 게이밍 데이터를 포함하는, 게이밍 애플리케이션의 하나 이상의 버전이 저장될 수 있다. 게이밍 봇이 게임 개발 애플리케이션과 합께 작동하여 게이밍 애플리케이션의 작동을 테스트하 고/하거나 게임에서 하나 이상의 논-플레이어 캐릭터(non-player character: NPC)로서 작동한다. 게이밍 봇 은 기계 학습 알고리즘을 통해 구성되고 구현되며, 예를 들어, 특정한 플레이-스타일 또는 기술 수준을 나 타내도록 설계되는 자동 테스터로서 작동하는 AI(artificial intelligence: 인공 지능) 페르소나를 포함하고/하 거나 이 페르소나로서 작동할 수 있다. 이 AI 페르소나는, 예를 들어, 실제 플레이어보다 훨씬 더 빠르게 게임 을 진행시켜서 게임 콘텐츠를 더 신속하게 평가하고; 수천 가지의 플레이스루(playthrough) 변형을 통해 무작위 로 레벨의 난이도를 평가하고; 핵심 성과 지표(key performance indicator: KPI)를 생성하여, 디자인 반복의 속 도를 증가시켜서, 설계자가 게임플레이 및 높은 수준의 개념에 집중하는 시간 확보하고; 예를 들어, 게이밍 애 플리케이션의 다양한 버전 및/또는 반복을 통해 동일한 기술 수준과 스타일을 계속해서 테스트하도록 사용 될 수 있다. 게다가, AI 페르소나 중 하나 이상은 기록된 인간 시연에 대한 기계 학습에 기초하여 게임을 플레이하고 콘텐츠 또는 코드 변경 후에도 게임이 여전히 플레이 가능한지 검증하는 회귀 플레이-테스터로 작동할 수 있다. 특히, 회귀 플레이-테스터는 게임에서 오류가 발견될 때 보고서를 생성하고, KPI를 생성하고, 전체 플레이 시간 및 게 임 난이도의 변화를 예측하고/하거나 BEA 툴과 함께 작동하여 지루함, 흥분, 완료 등을 포함하여 긍정적이 고 부정적인 플레이어 행동 동기의 양의 변화를 예측할 수 있다. 위에서 나타낸 바와 같이, AI 페르소나는 단일 및 멀티플레이어 게임을 위해 플레이어 대역, AI 상대 및/또는 NPC로 작동할 수 있다. 이것은 게임 개발자가 출시 전후에 실제 상대와 대결하고 모방하는 사람이 항상 있는지 검증하게 하고; 기술 수준과 스타일이 다양한 상대와 플레이어에게 도전하게 하고; 행동 패턴이 다양한 캐릭터 로 생생하고 명백한 세계를 생성하게 한다. PCG 툴은 새로운 게이밍 애플리케이션 및/또는 기존의 게이밍 애플리케이션에 대한 새로운 콘텐츠 또 는 레벨의 개발에서 게임 개발 애플리케이션을 사용할 때 게임 개발자의 창의적인 프로세스를 시작하고 가 속화하기 위해 절차적 콘텐츠 생성을 사용한다. PCG 툴은 구성 알고리즘, 생성-및-테스트 알고리즘, 검색- 기반 알고리즘 및/또는 기계 학습 알고리즘을 통해 구성되며, 예를 들어, 컨볼루션 신경망, 스태킹 신경망, 생 성적 대립쌍 네트워크, 또는 게임 텔레메트리 데이터, 행동 동기 데이터 및/또는 하나 이상의 AI 페르소나에 의 한 게임 플레이에 기초하여 반복적으로 훈련되고 새로운 게임 변형, 새로운 레벨 및 다른 콘텐츠와 같은 새로운 게임 콘텐츠를 생성하도록 작동하는 다른 심층 학습 알고리즘을 포함한다. 예를 들어, 게임을 플레이하는 AI 페르소나는 게임 콘텐츠에 걸쳐 AI 페르소나 플레이-추적 및 통계를 생성함으 로써 PCG를 통해 생성된 콘텐츠를 평가하고 비평할 수 있고 예측된 KPI 및/또는 다른 성능 메트릭의 면에서 절 차적으로 생성된 콘텐츠를 평가할 수 있다. 이것은 게임 개발 애플리케이션이 PCG 지원 게임의 플레이-공 간을 이해하고 평가하는 데 게임 개발자를 자동으로 그리고 신속하게 지원하여 플레이할 수 없거나 퇴보한 예로 부터 PCG 설계를 보호하게 할 수 있다. 게다가, PCG 툴은 게임 개발자가 게임 개발 플랫폼에 제공한 예를 학습하여 심층 학습 알고리즘을 시 드하고 평가를 위한 새로운 후보 콘텐츠를 생성함으로써 새로운 퍼즐, 레벨 또는 다른 콘텐츠를 생성할 수 있다. 이것은 게임 개발 플랫폼을 사용하는 게임 개발자가 미리 생성된 퍼즐, 레벨 및/또는 다른 콘텐츠로 생산성을 증가시키고; 평범한 레이아웃보다는 개념과 중요한 상세사항에 집중하고; 빈 캔버스 대신 생성된 예로 부터 생성을 시작하고/하거나 게임 개발자가 게임 개발 플랫폼에 제공한 시드 예제에 기초하여 이전 게임 개발자로부터 배운 스타일 및 선호도로 콘텐츠를 생성하게 한다. BEA 툴이 게임 개발 애플리케이션과 함께 작동하여 게임 텔레메트리 데이터 또는 플레이어/시청자의 다른 플레이 트레이스로부터 실시간으로 플레이어 동기 및 다른 플레이어/시청자 경험을 자동으로 예측하고, 예 를 들어, 복수의 동기 요인의 각각에 대한 양을 나타내는 점수 또는 다른 값 또는 플레이어/시청자 동기 또는 다른 플레이어/시청자 경험에 대한 예측을 나타내는 플레이어/시청자 동기의 다른 지표를 포함하는, 행동 동기 데이터(\"동기 데이터\", 예측된 \"플레이어/사용자 동기\" 또는 예측된 \"사용자 동기\"로서 또한 지칭됨)를 생성한 다. 게다가, 게이밍 봇 및/또는 PCG 툴과 결합된 BEA 툴의 사용은 게임 개발자가 시뮬레이션된 게임 플레이에 기초하여, 미래의 플레이어/시청자 동기 및 AI 페르소나의 플레이 트레이스로부터 다른 플레이어경험을 예측하게 한다. 게임 개발 플랫폼의 이러한 사용은 게임 개발자가 플레이어 또는 시청자가 특정한 게이밍 애플리케이션 을 좋아하는 이유를 이해하고 게이밍 애플리케이션을 조정하여 이탈을 감소시키고, 플레이어 경험 및 장기 적인 참여를 최적화하는 데 도움을 줄 수 있다. 특히, 잠재적인 게임 플레이어는 상이하고 상이한 이유로 플레 이한다. 플레이어 동기를 예측하면 게임 개발자가 잠재적인 플레이어 기반에 걸쳐 이러한 차이와 그룹화를 이해 하는 데 도움이 된다. BEA 툴은 실제 플레이어 동기를 학습하고 예측하기 위해 예를 들어, 플레이어 설문지, 게임 텔레메트리 데 이터 또는 다른 게임 데이터에 기초하여, 훈련되는 선호도 학습 또는 다른 기계 학습 기법을 통해 구성될 수 있 다. 훈련되면, BEA 툴은 다른 플레이어/시청자로부터 게임 텔레메트리 데이터를 사용하여 개별적인 플레이 어/시청자가 게임과 상호 작용하는 이유를 예측한다. 예를 들어, 플레이어/시청자가 복수의 동기 요인에 의해 어느 정도 또는 얼마나 동기를 부여받았는지 나타내는 동기 데이터 형태로 BEA 데이터를 생성하는 것은, 게임 개발자가 이에 따라 플레이어 경험을 최적화하고, 동기에 따라 플레이어를 매칭하여, 더 나은 플레이 세션을 생 성하고, 플레이어에 맞게 게임을 최적화하고 개별화하여, 플레이어/시청자를 유지하고 평생 가치를 개선하고, 문제가 발생하기 전에 열악한 플레이어 매치(즉, 플레이어 불일치) 및 잠재적인 부정적인 상호작용을 식별하고, 시간 경과에 따라 게임의 플레이어 기반을 추적하고 일반적인 플레이어 동기 또는 행동 프로필이 변하기 시작하 는지 매일 추적함으로써 게이밍 애플리케이션을 관리하게 한다. 다음의 사례를 고려하라. 사례#1 배경 게임 개발자는 멀티플레이어 모바일 게임인 게이밍 애플리케이션을 개발하기 위해 게임 개발 플랫폼 을 사용하고 있다. 이 게임은 2개의 상대 팀을 특징으로 하고, 각각의 팀은 최대 4명의 캐릭터로 구성되어, 환상적인 미식축구 형태를 플레이한다. 플레이어가 사용할 수 있는 캐릭터는 더 큰 풀에서 가져와서, 플레이어가 사용할 수 있고, 특정 매치를 위한 \"덱\"에 내장된다. 캐릭터의 각각은 플레이어 경험을 근본적으로 변경하는 상이한 능력을 갖는다. 상이한 덱에서 상이한 캐릭터 를 결합하는 것은 플레이어에게 상이한 팀을 제공할 것이다. 부가적으로 각각의 캐릭터는 건강 수치, 손상, 속도 등의 조합의 면에서 무한정으로 조정될 수 있다. 게임이 잘 균형을 이루고 플레이어가 게임을 플레이할 때 더 많은 캐릭터를 획득하도록 플레이어를 장려하는 것을 보장하기 위해, 이러한 상이한 덱이 서로 어떻게 플레이하는지를 이해하는 것이 중요하다. 게임 개발자는 새로운 캐릭터를 지속적으로 개발하고, 최초 출시 이후 주기적으로 새로운 캐릭터를 출시할 계획이다. 부가적으로, 게임 개발자는 게임플레이의 특성을 변경하여 특정한 덱의 플레이 가치에 다시 영향을 주는, 새 로운 플레잉 필드를 개발하고 출시할 계획이다. 요구 게임 개발자는 캐릭터의 각각의 플레이 특성을 단독으로 그리고 덱의 다른 캐릭터와 결합될 때 둘 다 이해해 야 한다. 이것은 게임 개발자가 게임플레이 동안 게임에서 상이한 캐릭터가 서로 동적으로 수행한다는 점을 이해해야 함을 의미한다. 이것은 상이한 캐릭터 덱 구성으로 많은 게임을 플레이하고 다양한 조합에 의해 다양한 플레이 스타일과 전 략의 영향을 관찰하고 분석하는 것을 의미한다. 게임은 18개의 캐릭터를 특징으로 하고 4개의 캐릭터를 선택하는 것 외에, 플레이어가 덱에 추가할 수 있는 4개의 주문 중에서 플레이어가 선택할 수 있다. 이것은 캐릭터의 특성 및 주문이 무한정 달라질 수 있는 293,760개의 상이한 덱 조합을 현재 버전의 게임이 지원한다는 것을 의미한다. 각각의 경기가 두 개의 덱(동일할 수 있음)으로 진행되므로, 임의의 게임 값을 조정하기 전에 설정되고 플레 이될 수 있는 86,294,937,600개의 상이한 경기가 있다. 이것 외에, 상이한 게임 맵은 복잡성을 더 증가시킨다. 이 조합 문제는 더 많은 캐릭터 및 맵이 게임에 추가됨에 따라 계속 확장된다. 게임 개발자는 가능한 한 많은 상이한 덱 솔루션과 경기 조합의 특성을 탐색하여 게임플레이를 최적화하고 수익이 잘 창출되는 유지율이 높은 제품을 보장하여, 고객 평생 가치(customer lifetime value: LTV)를 최대화 하길 원한다. 게임 개발 플랫폼의 사용 캐릭터와 덱의 특성을 조사하기 위해 단일 경기를 플레이하는 것은 현재 동시에 플레이할 수 있기 위해 두 사람이 조정해야 하는 데 약 5분 소요된다. 캐릭터와 덱의 특성을 조사하기 위해 단일 경기를 플레이하는 것은 현재 2개의 게이밍 봇에 대해 20 내 지 25초가 걸린다. 인간 플레이어를 사용하는 것보다 15배 더 빠르다는 점 외에도, 게이밍 봇은 많은 경기가 동시에 실행 되게 하고, 데이터가 집계되게 하고, 정성적 해석을 필요로 하기보다는, 통계를 사용하여 비교되게 한다. 캐릭터를 정성적으로 검사하려는 게임 개발자는 게이밍 봇과 대결하여 그렇게 할 수 있으므로, 수반되 는 인력을 50%만큼 감소시키고 직원이 다른 작업을 위한 시간을 확보하면서, 두 직원 간의 스케줄링의 필요성을 제거한다. 부가적으로, 게이밍 봇은 플레이어와 마주하는 NPC로서 완성된 게임에 포함될 수 있다. 이것은 게임 개 발자가 내부적으로 AI에 직면한 플레이어를 별도로 개발할 필요성을 제거하고, 게임 개발자가 플레이어 기반을 구축함에 따라, 새로운 플레이어에게 무제한의 상대를 제공함으로써 게임의 하드 출시를 개선시킨다. 사례#2 배경 게임 개발자는 퍼즐 게임을 구현하는 기존의 게이밍 애플리케이션을 갖는다. 플레이어에게 게임을 최신 상태로 유지하는 것은 새로운 콘텐츠의 지속적 생성을 필요로 한다. 새로운 콘텐츠는 고품질이어야 한다. 콘텐츠는 상호 교환할 수 없다: 게임 개발자는 레벨 품질의 차이가 고객 평생 가치에 큰 영향을 준다-우수한 레벨이 플레이어를 유지하는 핵심 구성요소라-는 정보를 분석으로부터 보고한다. 새로운 레벨을 생성하기 위한 현재 팀은 새로운 레벨을 생성하는 2 내지 3명의 레벨 설계자로 구성된다. 이전에는 설계자가 2주마다 게임에 출시되는 15개의 새로운 레벨을 생성할 수 있었다. 외부 플레이테스트 회 사와 함께 이러한 수준을 평가하는 것은 1주일이 걸렸다. 반복 시간을 감소시키는 것은 설계자가 게임 성능의 주요 예측 변수인 레벨의 품질을 증가시키는 새로운 특 징에 집중하게 한다. 요구 게임 개발자는 설계자가 레벨 디자인을 구성하는 일상적인 양상보다는 새로운 레벨 아이디어에 집중하게 하 기 위해, 설계자가 선택할 수 있는, 새로운 레벨 개념을 자동으로 생성하는 알고리즘을 선호할 것이다. 게임 개발자는 자동 콘텐츠 생성을 사용하여 설계자와 함께 새로운 아이디어를 촉발하기를 원한다-\"빈 캔버 스 문제\"를 해결하는 것-즉, 아이디어를 처음부터 시작하는 것. 게임 개발자는 설계자가 생성한 레벨의 평가를 개선시키기 위해, 인간처럼 더 플레이하는 봇을 선호할 것이다. 게임 개발 플랫폼의 사용 하나의 단일 게이밍 봇에 의한 자동화된 플레이테스팅을 통해, 이 비율은 1주일마다 30개의 완료 레벨 로 증가될 수 있다. 레벨 평가는 거의 즉각적이므로, 설계자는 아이디어가 새로 생기는 동안 반복되게 한다. 사례#3 배경 게임 개발자는 PC, Mac 및 PlayStation 4용 멀티플랫폼 서사적 게임을 구현하는 게이밍 애플리케이션 을 개발 중이다. 이 게임은 전체 플레이스루를 위해 약 8시간 분량의 게임플레이로 구성된 매우 복잡한 분기형 서사적이다. 요구 게임의 요소는 상호의존성이 높다. 스토리의 초반부를 변경하면 스토리의 후반부에 영향을 미쳐 게임을 완료할 수 없게 될 수 있다. 개발 후반에 식별되는 요구를 해결하거나 버그를 수정하기 위해 코드를 변경하면 게임 초기 부분의 기능이 중단될 수 있다. 팀 규모가 제한되어 있으며 팀에 정규 품질 보증 담당자가 없다. 프로그래머가 아닌 팀 멤버가 버그를 발견할 때, 게임을 테스트할 수 없거나 게임을 생성할 때 콘텐츠를 경 험할 수 없기 때문에, 결과적으로 작업이 종종 중단된다. 이로 인해 창의적인 흐름이 중단되고 스토리 아이디어를 반복하는 시간이 상당히 증가된다. 프로그래머에게 긴급 버그 수정을 요청하면 프로그래머의 작업 흐름이 중단되어 연쇄적인 비용 효과가 발생 하는 경향이 있다. 변경에 응답하여 전체 게임을 테스트하는 것은 로깅, 케이스 생성 및 파생 작업에 더하여, 적어도 8시간의 풀타임 작업을 필요로 한다. 게임 개발자는 게임의 스토리 콘텐츠를 검토할 때 실패 지점을 자동으로 식별하는 솔루션을 필요로 한다. 게임 개발 플랫폼의 사용 게이밍 봇은 게임 스토리를 자동으로 진행하여, 게임 개발자가 언제 게임이 중단되거나 플레이어가 갇 히는지를 식별하게 한다. 시스템은 두 가지 방식으로 작동한다: 1. 플레이어 모방을 통해, 게이밍 봇은 이전 플레이어 작동을 시뮬레이션하여 게임 코드 또는 콘텐츠의 변 경 후에도 이전 시연이 여전히 가능한지를 검증한다. 2. 게이밍 봇은 자동으로 게임을 검색하고, 스토리 라인을 따라 이동하며, 충돌 상황 및/또는 막다른 길을 찾는다. 게임 개발 플랫폼의 이러한 구현예는 3개의 이득을 갖는다: 1. 게임 개발 플랫폼은 변경 후 게임이 작동하는지를 연속적으로 확인할 수 있다. 2. 게임 개발 플랫폼은 게임이 완료 가능한지를 연속적으로 확인할 수 있다. 3. 게임 개발 플랫폼은 게임을 무한정 플레이할 수 있어서, 인간의 상호작용을 시뮬레이션하고 입력 없이 단순히 게임을 실행시키는 것보다 더 현실적인 사용 사례를 제공하는 스트레스 테스팅을 가능하게 한다. 게임 개발 플랫폼은 대략적으로 QA 직원 한 명의 노력을 대체한다. 대략 10명으로 구성된 팀의 경우, 이것은 초기 구현 후 예산의 면에서 약 7% 절감에 대응한다. 부가적으로, 게임 개발 플랫폼은 창의적 효율성의 개선을 제공하여, 최종 게임 성능에 긍정적인 영향을 줄 수 있는 고품질 콘텐츠를 발생시킨다. 사례#4 배경 게임 개발자가 무한 러너 게임을 구현했다. 요구 플레이어 기반이 매우 크면 플레이어를 알기가 어렵다. 플레이어 중 약 5%만이 게임을 완료한다. 게임 설계자의 목표는 대부분의 플레이어가 게임을 완료하도록 하는 것이다. 게임 개발 플랫폼의 사용 BEA 툴의 사용은 게임 완료 및 플레이어 유지를 개선하는 데 도움이 되도록 게임을 조정하는 데 사용되 는 플레이어 동기를 포함하여 실시간 플레이어 경험을 결정할 수 있다. 도 3a는 본 개시내용의 실시형태에 따른 게임 개발 파이프라인의 흐름/블록도를 나타낸다. 이 게임 개발 파이프라인은 도 1 및 도 2의 게임 개발 플랫폼과 함께 작동하고 이것과 함께 설명되는 기능 및 특징 중 하나 이상을 사용한다. 특히, 게임 개발이 단계의 게임 초기 생성부터 예를 들어, 알파 테스팅, 베타 테스팅 및/또는 소프트 런칭을 통해 일시적으로 진행되어 단계에서 하드 출시용으로 개선된 게임의 생성을 발생시키는, 게임 개발 파이프라인이 제공된다. 단계에서, 게이밍 애플리케이션의 초기 버전과 같은 게임이 생성된다. 다양한 실시형태에서, 게임의 초기 버전은 처음부터 또는, 예를 들어, 게임 개발자 또는 다른 사용자에 의해 개발되는 이전 게임 또는 이전 버전의 게임에 기초하여 PCG 툴에 의해 생성되는 초기 게임 콘텐츠로부터, 게임 개발 애플리케이션을 사용하여 게임 개발자에 의해 개발된다. 단계에서, 게임은 모방하지 않는, 예를 들어, 게임 개발자가 개발한 이전 게임 또는 이전 버전의 게임의 테스팅 및 평가로부터 개발되고 훈련되는 게이밍 봇을 사용하여 테스트된다. 다양한 실시형태에서, 게이밍 봇은, 예를 들어, 소스, 이전 사용, 플레이어 스타일, 기술 수준, 대응하는 플레이어 동기 및/또는 각각의 게이밍 봇의 다른 특성을 나타내는 기술적 메타데이터와 함께 비모방 게이밍 봇의 라이브러리를 포함한다. 게임 개발자는 이 테스팅을 위해 사용되는 하나 이상의 기존의 게이밍 봇을 선택하고 평가할 수 있다. 게이밍 봇 중 하나 이상이 선택되면, 게임은, 예를 들어, 막다른 길을 식별하고, 게임 균형을 시작하고, 플레이 가 능성을 증가시키는 등을 위해 테스트되고 개선될 수 있다. 단계에서, 하드 출시 전에 테스팅에 사용되는 내부 또는 외부 플레이어와 같은 실제 플레이어의 게임 텔레 메트리 데이터에 기초하여 모방 게이밍 봇이 생성된다. 다양한 실시형태에서, 게임 텔레메트리 데이터는, 예를 들어, 픽셀 데이터 및 오디오 데이터를 포함하는 게임 오디오 및 비디오 출력, 플레이어 입력, 게임 상태, 게임 이벤트, 게임 성과, 게임 목표를 향한 진행, 게임 매개변수, KPI, 게임 완료 데이터, 게임플레이 데이터, 게임 진행 데이터, 전술한 데이터 및 다른 게임 텔레메트리 데이터 및 게임 분석 정보 중 임의의 것에서 유래된 플레이어 스타일을 포함할 수 있는 플레이 트레이스로부터 수집된 데이터를 포함할 수 있다. 다양한 실시형태에서, 게이밍 봇은 게임 텔레메트리 데이터 및/또는 실제 플레이어/시청자로부터의 다른 데이터를 통해 훈련되는 기계 학습 알고리즘을 통해 작동한다. 이러한 기계 학습 알고리즘의 예는 인공 신경망 (또는 본 명세서에서 사용되는 바와 같이 더 간단히 \"신경망\"), 지원 벡터 기계(support vector machine: SVM), 베이지안(Bayesian) 네트워크, 유전 알고리즘 및/또는 비감독, 반감독, 감독 및/또는 보강 학습을 통해 훈련되는 다른 기계 학습 기법을 포함하고 특징 학습, 희소 사전 학습, 이상 검출, 의사결정 트리, 연관 규칙 및/또는 다른 프로세스를 더 포함할 수 있다. 단계에서, 게임은, 예를 들어, 게이밍 봇에 의한 게임 플레이에 의해 생성되는 KPI 및 다른 게임 분 석 정보를 포함하는 게임 텔레메트리 데이터와 같은 출력을 모니터링함으로써 더 테스트되고 개선된다. 이 방식 으로, 예를 들어, 막다른 길을 식별하고, 게임의 균형을 더 맞추고, 플레이 가능성을 더 증가시키고, 예측된 플 레이어 유지, 참여, 동기 및 다른 경험 등을 최적화하기 위해 다양한 버전의 게임이 테스트, 평가 및 개선될 수 있다. 단계에서, BEA 데이터는, 예를 들어, KPI, 게임 이벤트, 플레이어 행동, 게임 상태, 게임 성과, 게임 목표 를 향한 진행, 게임 매개변수, 및 다른 게임 분석 정보와 상호 연관될 수 있는 다양한 플레이어 동기 요인을 포 함하는 플레이어 설문지 또는 다른 경험 메트릭으로부터 수집된다. 플레이어 동기 요인은 능력, 자율성, 관련성, 및 존재감과 같은 광범위한 동기 요인일 수 있다. 부가적으로 또는 대안으로, 플레이어 동기 요인 및/ 또는 행동은 높은 점수 달성, 지속적으로 도전하기, 일부 다른 빈도로 도전하기, 게임 목표 및 성과 달성하기, 레벨 완료하기, 휴식하기, 탐색하기, 지루함 피하기, 다른 플레이어를 이기거나 다른 플레이어의 게임 망치기, 채팅, 채팅하는 다른 플레이어 피하기, 채팅하는 다른 플레이어 망치기, 및 다른 플레이 스타일 등과 같은 더 구체적인 동기를 포함하는, 경쟁, 완료, 환상, 파괴, 발견, 전략, 흥분, 힘을 포함하여 게임과 관련될 수 있다. 단계에서, BEA 데이터는 하나 이상의 BEA 툴을 훈련하는 데 사용된다. 이전에 논의된 바와 같이, BEA 툴 은 실제 플레이어 동기를 학습하고 예측하기 위해 BEA 데이터 및/또는 게임 텔레메트리 데이터에 기초하여 훈련되는 선호도 학습 또는 다른 일반적인 기계 학습 기법을 통해 구성될 수 있다. 단계에서, 플레이어 동기 또는 다른 경험과 같은 플레이어 경험은 실제 플레이어 및/또는 모방 또는 비모 방 게이밍 봇으로부터의 게임 텔레메트리 데이터에 기초하여 BEA 툴을 통해 자동으로 그리고 실시간으로 예측될 수 있다. 이 플레이어 경험 데이터는 단계의 게이밍 봇 테스팅과 함께 사용되어 예를 들어, 게임 성능 개선, 게임에 대한 예측 플레이어 만족도 개선, 예측 플레이어 유지 증가 및/또는 예측 수익 창출 증가에 의해 단계에서 하드 출시를 위한 게임을 더 개선할 수 있다. 게임 개발 파이프라인은 초기 버전의 게임을 하드 출시를 위한 개선된 게임으로의 적응, 테스팅, 분석 및 개선에 대응하는 것으로 설명되었지만, 게임 개발 파이프라인의 하나 이상의 단계는 또한 유사하게 게이밍 애플리케이션에 대한 새로운 버전, 업데이트 및/또는 새로운 콘텐츠 추가를 처리하도록 사용될 수 있다. 게다가, 게임 개발 파이프라인이 BEA 데이터를 수집하는 단계 및 BEA 데이터에 기초하여 BEA 툴(25 4)을 생성하는 단계를 포함하는 것으로 설명되었지만, 게임 개발 플랫폼이 게이밍 애플리케이션(24 8)에 대한 유사한 게임, 새로운 버전, 업데이트 및/또는 새로운 콘텐츠 추가를 처리하도록 사용되는 상황에서, 이전 버전의 게임 또는 유사한 게임으로부터 생성되는 하나 이상의 BEA 툴이 재사용을 위해 선택될 수 있 다. 예를 들어, BEA 툴은, 예를 들어, 각각의 BEA 툴의 소스, 이전 사용 및/또는 다른 특성을 나타내는 기 술적 메타데이터와 함께 BEA 툴의 라이브러리를 포함한다. 게임 개발자는 동기 및/또는 행동을 포함하는 플레이 어 경험과 외부 플레이어로부터의 게임 텔레메트리 데이터에 기초한 다른 경험을 예측하기 위해 단계에서 사용되는 하나 이상의 기존의 BEA 툴을 선택하고 평가할 수 있다. 또한, 생성적이고 일반적인 플레이어 경험의 계산 모델(예를 들어, \"일반 경험 페르소나\")을 획득하기 위한 다 음의 추가 예를 고려한다. 페르소나는 인간 경험 시연으로 제공되는 플레이어의 경험을 시뮬레이션할 수 있으므 로 생성적이다. 이 프로세스는 또한 인간 경험의 디지털화 및 시뮬레이션을 수반하는 특정한 영역의 다양한 인 스턴스화에 걸쳐 일반적이다.일반 경험 페르소나를 획득하기 위해, 게임 개발 플랫폼은 계산 모델의 3개의 양상, 즉, 모델 입력, 계산 및 모델 출력에 대한 혁신을 융합할 수 있다. 이 방식은 인간이 비교(상대) 방식으로 가치를 인코딩하는 것에 따른 심리학의 고정 방법을 기반으로 할 수 있다. 혁신적인 순서형 모델링 방식에 기초하여, 페르소나가 일반화 가능한 특징을 통해 인간(또는 인간의 시연)을 인식하고 페르소나가 점진적으로 기계 학습하여 인간처럼 환경을 경험한다. 게임 개발 플랫폼은 심리 측정학과 인간 심리학 전반의 근본적인 문제를 해결한다: 즉, 신뢰할 수 있고 유 효한 방식으로 경험을 계산적으로 측정한다. 이것은 또한 인간 컴퓨터 상호작용 및 플레이어 경험 연구의 핵심 질문을 처리한다: 즉, 인간이 느끼는 것과 동일한 방식으로 시뮬레이션된 세계에서 경험을 시뮬레이션하는 방식 을 처리한다. 마지막으로, 이것은 기계 학습과 감성 컴퓨팅의 교차점에서 종래의 문제를 해결한다: 즉, 적은 주 관적 성격의 데이터를 최대한 학습하여 AI 모델 생성 속도를 개선시키고, 복잡성을 감소시키고 또한 정확성을 개선시키는 방식을 해결한다. 도 3b는 본 개시내용의 실시형태에 따른 일반 경험 페르소나의 컴포넌트의 흐름/블록도를 나타낸다. 특히, 도 1, 도 2 및 도 3a와 함께 설명되는 임의의 기능 및 특징과 함께 사용하기 위한 방법이 제시된다. 이 프로세 스는 3개의 핵심 하위 프로세스, 즉, 입력(기술어 맵), 계산 자체(생성 모델) 및 출력(시연)에 걸쳐 혁신을 결 합시킴으로써 플레이어 경험(예를 들어, 동기 및/또는 행동을 포함함)의 생성 모델링에 대한 신뢰할 수 있고 효 과적인 솔루션을 제공한다. 단계 - 경험 시연: 페르소나의 출력을 처리하기 위해 제안된 방식은 종래의 심리 측정학의 모든 주석 유형 을 지원할 수 있으므로 일반적이다. 예를 들어, 경험 라벨을 수집하고 처리하는 방식에서 이전 접근 방식과 상 이할 수 있다. 특히, 인간의 경험 시연은 상호작용에서 추출되는 참여 메트릭을 통해 지속적인 방식으로 수집될 수 있다. 이것은 시청자가 비디오(예를 들어, 게임플레이 비디오)를 수동적으로 관찰하는 것부터 임의의 상호작 용(예를 들어, 게임)에 대한 능동적 주석까지 모든 스펙트럼을 포함한다. 경험 라벨은 순서적이고 무한 방식으 로 처리되므로 가치에 구애받지 않고 일반적인 경험 모델의 구성을 허용한다. 1차 및 2차 조합 기법을 따르면 유효하고 신뢰할 수 있는 인간 경험 시연을 생성하지만 또한 제한된 데이터에서 대규모 데이터세트를 생성한다. 임의의 유형의 설문지-인간 컴퓨터 상호작용 내에서 지배적인 실행 상태-는 더 이상 필요하지 않으며(설문지 데 이터가 여전히 처리될 수 있음에도 불구하고) 인간 참여는 현실적인 소규모 플레이어 그룹 규모로만 제한된다. 단계 - 경험 생성 모델: 경험 페르소나는 인간의 경험을 예측하는 방식을 학습하거나 심지어 인간이 하는 것처럼 경험을 표현할 수도 있다. 전자의 경우, 게임 개발 플랫폼은 라벨링된 경험의 전체 또는 부분 순서를 예 측하는 방식을 학습하는 심층(선호도) 학습 방법을 수반한다. 후자의 경우, 인간 시연의 순서(위에서와 같음)는 보강 학습 방식(예를 들어, 신경 진화)이 추론하는 방식을 학습하는 유용성을 규정한다. 그 결과는 인간 플레이 어처럼 시뮬레이션된 환경에서 \"느낄\" 수 있는 생성적 경험 모델이다. 단계 - 경험 기술어 맵: 경험은 상호 작용이 수행되고 경험 라벨링에 의해 경계를 이루는 방식으로 인지된 다. 인지 모델은 모델에 의미가 있는 라벨링된 경험 영역에 초점을 맞추고 경험과 관련하여 변화가 관찰되거나 보고되지 않는 영역을 제거한다. 경험의 표현은 상호작용의 일반적인 양상, 즉 일반적인 경험 기술어 맵을 관찰 함으로써 학습된다. 맵의 설계는 상호작용의 순차적 패턴에 대한 높은 수준의 행동 특성화부터 경험 라벨에 매 핑되는 상세한 잠재 변수에 이르기까지 다양할 수 있다. 후자는 가능한 경우 직접적으로 상호작용 시뮬레이션을 통해 구성되거나 상호작용을 생성하는 코드에 대한 액세스가 이용 불가능할 때 상호작용의 기계 학습된 순방향 모델을 통해 간접적으로 구성된다. 단순한 게임 개발에 더하여, 게임 개발 플랫폼의 BEA 툴은 최종 게임 자체에 통합될 수 있다. 이러한 방식으로, 개별적인 플레이어는 동기 및/또는 행동의 면에서 평가될 수 있다. 다양한 실시형태에서, 특정한 게 임 버전 또는 게임 매개변수 설정은, 예를 들어, 특정한 플레이어의 경험을 개선시키기 위해 개별적인 플레이어 에 대응하는 것으로 예측되는 특정한 동기 및/또는 행동을 보완하거나 다른 방식으로 일치시키기 위해 개별적인 플레이어에 대한 가능한 게임 버전/설정의 라이브러리로부터 선택될 수 있다. 이러한 방식으로, 도전을 좋아하 는 플레이어는 도전할 수 있고, 완료를 좋아하는 플레이어에게는 완료하기 더 쉬운 게임이 제공될 수 있는 등이 다. 게다가, 게임 개발 플랫폼의 BEA 툴은 플레이어 각각의 동기 및/또는 행동에 기초하여 멀티플레이어 게임에서 플레이어를 함께 짝짓기 위해 사용될 수 있다. 예를 들어, BEA 툴의 결정에 기초하여, 스포일러의 역 할하길 좋아하는 귀중한 플레이어는 경험이 부족한 플레이어와 일상적으로 짝을 이루어 실패하도록 함으로써 유 지될 수 있다. 또 다른 실시예에서, BEA 툴에 의해 채팅하기로 결정된 플레이어는 다른 이러한 플레이어 또는중립적으로 채팅하는 플레이어와 짝을 이루어, 채팅하는 상대 플레이어 등에 의해 사기가 저하된 것으로 결정된 다른 플레이어를 피할 수 있다. 게임용 BEA 데이터 생성과 함께 위에서 설명되지만, 위에서 설명된 기법은 다른 산업에도 적용될 수 있다. 사람 들의 경험을 모델링하고 생성할 수 있는 것은 인간 행동 및 경험을 수반하는 임의의 연구 영역 또는 산업 부문 에서 사용될 수 있다. 프로세스의 잠재적인 적용 목록은 방대하며 창조 산업, 마케팅, 소매, 웹 서비스, 아키텍 처 및 건축 환경, 사이버 물리 시스템, 자동차 산업, 및 디지털 예술과 같은 부문을 포함한다. 생성적이고 일반 적인 경험 페르소나는 서비스를 더 빠르고 더 효율적으로 테스트, 개발 및 제공하는 능력을 강화한다. 이들은 또한 아이디어 구상부터 프로토타입 제작, 생산, 및 서비스, 프로젝트 또는 인간이 상호작용할 객체 출시에 이 르기까지 더 나은(페르소나 주도) 결정을 내린다. 도 4는 본 개시내용의 실시형태에 따른 방법의 흐름도를 나타낸다. 특히, 도 1 및 도 2, 도 3a 및 도 3b와 함께 설명되는 임의의 기능 및 특징과 함께 사용하기 위한 방법이 제시된다. 단계에서, 게이밍 봇, 예컨대, 이 전에 설명된 게이밍 봇 중 임의의 게이밍 봇에 대응하는 게이밍 봇 모델이 생성된다. 단계는 게이밍 애플리케이션(app), 예컨대, 게이밍 애플리케이션으로부터 게임 출력을 수신하는 것을 포함한다. 단계는 게이밍 봇 모델을 통해 게이밍 앱에 대한 게임 입력을 생성하는 것을 포함하며, 게이밍 입력은 하나 이상의 시뮬레이션된 플레이어에 의한 게임 플레이에 대응한다. 단계는 시뮬레이션된 플레이 어에 의한 게임 플레이에 응답하여 게임 성능 데이터를 생성하는 것을 포함한다. 이 게임 성능 데이터는 게임 콘텐츠를 더 신속하게 평가하기 위해; 수천 가지의 플레이스루 변형을 통해 무작위로 레벨의 난이도를 평가하기 위해 사용될 수 있고; 핵심 성과 지표(key performance indicator: KPI) 또는 다른 게임 분석 정보를 포함할 수 있다. 도 5는 본 개시내용의 실시형태에 따른 게임 텔레메트리 데이터의 그래픽 도면(500 및 510)을 나타낸다. 다양한 실시형태에서, 게이밍 봇은 게임 텔레메트리 데이터에 기초하여, 마스터 플레이어 또는 다른 인간 플레이어와 같은 실제 플레이어를 모방하도록 훈련된 인공 신경망을 포함한다. 게임 텔레메트리 데이터는 실제 플레이어와 게이밍 봇에 대응하는 픽셀 데이터를 포함하는 비디오 데이터의 프레임을 포함할 수 있다. 도시된 특정한 실시 예에서, 실제 게임 출력 형태의 게임 텔레메트리 데이터는 시간(t1)에서 도면에 그리고 시간(t2)에서 도면 에 제시된다. 게임 텔레메트리 데이터는 게이밍 봇 모델, 예컨대, 게이밍 봇, 또 다른 AI 페르소나 또는 다른 AI에 의해 생성되는 캐릭터를 포함한다. 게임 텔레메트리 데이터는 또한 실제 플레이어, 예컨대, 마스터 플레이어, 일반 플레이어 또는 게이밍 봇 모델이 모방하거나 시뮬레이션하려는 다른 플레이어에 의해 생성되는 캐릭터를 포함한다. 게임 개발 애플리케이션은 캐릭터의 위치와 캐릭터의 위치 사이의 시간 경과에 따른 차이를 나 타내는 차이 데이터를 생성한다. 예를 들어, 시간 경과에 따른 차이는 복수의 시간 동안 실제 플레이어에 의해 생성되는 제1 캐릭터와 게이밍 봇에 의해 생성되는 제2 캐릭터 사이의 픽셀 거리를 나타낸다. 게임 텔레메트리 데이터에 표시된 예에서, 시간(t1)의 차이(d(t1))는 캐릭터(502 및 504)의 중심 사이의 유클리드 (Euclidean) 거리로 측정된다. 게임 텔레메트리 데이터에 표시된 예에서, 시간(t2)의 차이(d(t2))는 캐릭 터(502 및 504)의 중심 사이의 유클리드 거리로 측정된다. 예를 들어, 마스터 플레이어가 레벨을 완료하는 데 걸리는 시간 길이에 대응하는 시간 기간(t0 - tn), 마스터 플레이어 플레이 트레이스의 샘플의 시간 길이 또는 일부 다른 시간 간격을 고려하면, 차이 데이터가 i = 0, n에 대한 d(ti)의 값을 통합하거나 합산함으로써 차이 데이터를 생성될 수 있다. 이러한 방식으로 생성되는 차이 데이터는 게이밍 봇을 업데이트하여 마스터 플레이어를 더욱 밀접하게 모방하기 위한 적합성의 척도로 사용될 수 있다. 다양한 실시형태에서, 게이밍 봇은 게임 텔레메트리 데이터에 기초하여 실제 플레이어를 모방하도록 훈련된 인공 신경망을 포함한다. 예를 들어, 게이밍 봇은 보강 학습을 사용하 여 인간 마스터 플레이어를 \"섀도우(shadow)\"하는 방식을 학습하는 동시에, 보이지 않는 새로운 조건에 대처하 는 방식을 환경으로부터 학습할 수 있다. 게이밍 봇을 업데이트하는 것은 보강 학습을 통해 게이밍 봇을 조정된 게이밍 봇 구성으로 반복적으로 재훈련하는 것, 조정된 게이밍 봇 구성에 대응하는 업데이트된 차이 데 이터를 반복적으로 생성하는 것, 그리고 대응하는 업데이트된 차이 데이터가 예를 들어, 시뮬레이션된 플레이어 와 실제 플레이어 사이의 허용 가능한 일치를 나타내는 차이 문턱값에 유리하게 비교될 때 조정된 게이밍 봇 구 성 중 하나를 수용하는 것을 포함할 수 있다. 게이밍 봇을 업데이트하는 것은 또한 게이밍 봇의 매개변수 에 대한 검색 알고리즘을 통해 게이밍 봇을 조정된 게이밍 봇 구성으로 반복적으로 조정하는 것, 조정된 게이밍봇 구성에 대응하는 업데이트된 차이 데이터를 반복적으로 생성하는 것, 및 예를 들어, 대응하는 업데이트된 차 이 데이터가 허용 가능하거나 원하는 적합성을 나타내는 차이 문턱값과 유리하게 비교될 때 조정된 게이밍 봇 구성 중 하나를 수용하는 것을 포함할 수 있다. 마스터에서 섀도우까지의 거리 측정은 인간의 행동을 복제하는 데 얼마나 가까운지 이해하는 데 사용된다. 값 d(ti)이 선형 거리 측정값, 로그 거리 측정값 또는 일부 다른 비선형 함수로 변환된 거리 측정값일 수 있다는 점에 유의해야 한다. 게다가, 유클리드 거리로서 위에서 설명되었지만, 비-유클리드 거리, 비-매개변수 거리 순 위 및 다른 단조적 측정값을 포함하는 다른 거리가 마찬가지로 사용될 수 있습니다. 누적 거리 측정값의 면에서 위에서 설명되었지만, 차이 데이터는 해당 시간 기간(t0 - tn) 동안 게이밍 봇과 인 간 플레이어 사이의 누적 게임 점수의 차이, 시간 기간(t0 - tn) 동안 게이밍 봇과 인간 플레이어 간의 게임 성 과의 차이, 시간 기간(t0 - tn) 동안 게이밍 봇과 인간 플레이어 간의 게임 목표 도달의 시간 차이, 게이밍 봇과 인간 플레이어 및/또는 이들의 조합 간의 다른 게임 메트릭 또는 다른 게임 분석 정보의 차이와 같은, 거리에 추가로 또는 거리에 대한 대안으로 하나 이상의 다른 측정값을 포함할 수 있다. 도 6은 본 개시내용의 실시형태에 따른 방법의 흐름도를 나타낸다. 특히, 도 1 및 도 2, 도 3a, 도 3b, 도 4 및 도 5와 함께 설명되는 임의의 기능 및 특징과 함께 사용하기 위한 방법이 제시된다. 단계는 게이밍 봇을 생성하는 것을 포함한다. 단계는 실제 플레이어에 대응하는 게이밍 앱으로부터 게임 텔레메트리 데이터를 수신하는 것을 포함한다. 단계는 게이밍 봇에 대응하는 게이밍 앱으로부터 게임 텔레메트리 데이터를 생성 하는 것을 포함한다. 단계는 실제 플레이어에 대응하는 게임 텔레메트리 데이터와 실제 플레이어에 의해 생성되는 제1 캐릭터와 게이밍 봇에 의해 생성되는 제2 캐릭터 사이의 시간에 따른 거리를 나타내는 게이밍 봇에 대응하는 게임 데이터 에 기초하여 생성되는 차이 데이터에 기초하여 게이밍 봇을 업데이트하는 것을 포함한다. 다양한 실시형태에서, 시간 경과에 따른 차이는 복수의 시간 동안 실제 플레이어에 의해 생성되는 제1 캐릭터와 게이밍 봇에 의해 생성되는 제2 캐릭터 사이의 거리를 나타낸다. 거리는 유클리드 거리일 수 있다. 시간 경과에 따른 차이는 복수의 시간의 각각 동안 실제 플레이어에 의해 생성되는 제1 캐릭터와 게이밍 봇에 의해 생성되는 제2 캐릭터 사이의 거리의 누적을 나타낼 수 있다. 다양한 실시형태에서, 시간 경과에 따른 차이는, 시간 기간의 복수의 시간 동안 실제 플레이어에 의해 생성되는 제1 캐릭터와 게이밍 봇에 의해 생성되는 제2 캐릭터 사이의 거리, 시간 기간 동안 게이밍 봇과 인간 플레이어 간의 누적된 게임 점수의 차이, 시간 기간 동안 게이밍 봇과 인간 플레이어 간의 게임 성과의 차이, 또는 시간 기간 동안 게이밍 봇과 인간 플레이어 간의 게임 목표 달성의 시간 차이 중 하나 이상을 나타낸다. 다양한 실시형태에서, 게이밍 봇은 게임 텔레메트리 데이터에 기초하여 실제 플레이어를 모방하도록 훈련되는 인공 신경망을 포함한다. 게임 텔레메트리 데이터는 실제 플레이어와 게이밍 봇에 대응하는 픽셀 데이터를 포함 할 수 있고, 시간 경과에 따른 차이는 복수의 시간 동안 실제 플레이어에 의해 생성되는 제1 캐릭터와 게이밍 봇에 의해 생성되는 제2 캐릭터 사이의 픽셀 거리를 나타낸다. 단계는 게이밍 봇을 조정된 게이밍 봇 구성 으로 반복적으로 조정하는 것, 조정된 게이밍 봇 구성에 대응하는 업데이트된 차이 데이터를 반복적으로 생성하 는 것, 및 대응하는 업데이트된 차이 데이터가 차이 문턱값과 유리하게 비교될 때 조정된 게이밍 봇 구성 중 하 나를 수용하는 것을 포함할 수 있다. 도 7은 본 개시내용의 실시형태에 따른 방법의 흐름도를 나타낸다. 특히, 도 1 및 도 2, 도 3a, 도 3b, 및 도 4 내지 도 6와 함께 설명되는 임의의 기능 및 특징과 함께 사용하기 위한 방법이 제시된다. 단계는 선호도 학습 모델에 기초하여 행동 경험 분석(BEA) 툴을 생성하는 것을 포함한다. 단계는 사용자와 연관된 게이밍 앱으로부터 게임 텔레메트리 데이터를 수신하는 것을 포함한다. 단계는 BEA 툴을 게임 텔레메트리 데이터 에 적용함으로써 예측된 사용자 동기를 생성하는 것을 포함한다. 단계는 예측된 사용자 동기에 기초하여 게임을 조정하는 것을 포함한다. 다양한 실시형태에서, 선호도 학습 모델은 이전 게임 플레이와 연관된 복수의 플레이어 설문지에 기초하고 또한 이전 게임 플레이와 연관된 이전 게임 텔레메트리 데이터에 기초하여 훈련된다. 선호도 학습 모델은 복수의 플 레이어 설문지로부터 조합적으로 생성된 2차 데이터를 사용하여 훈련될 수 있다. 선호도 학습 모델은 지원 벡터 기계를 통해 구현될 수 있다. SVM는 방사형 기저 함수 커널이 있는 비선형 SVM을 포함할 수 있다. 다양한 실시형태에서, 게임 텔레메트리 데이터는 플레이 시간 데이터, 완료 데이터 또는 진행 데이터 중 적어도 하나를 포함한다. 게임 텔레메트리 데이터는 다른 게임 텔레메트리 데이터에 대한 클러스터링 분석을 통해 생성 된 복수의 플레이어 유형 중 하나의 표시를 포함할 수 있다. 게임 텔레메트리 데이터는 게이밍 봇에 기초하여 생성될 수 있다. 게임 텔레메트리 데이터는 게임 비디오와 연관된 픽셀 데이터를 포함할 수 있다. 다양한 실시형태에서, 시스템은 게이밍 개발 애플리케이션을 더 포함하는 게임 개발 플랫폼을 통해 구현될 수 있으며, 게이밍 애플리케이션의 적응을 촉진하는 것은 게이밍 개발 애플리케이션을 통해 게이밍 애플리케이션의 적응을 촉진하는 것을 포함한다. 게이밍 애플리케이션은 복수의 임의의 버전을 포함할 수 있고, 시스템은 게이 밍 애플리케이션을 실행하는 게이밍 시스템을 통해 구현되고, 게이밍 애플리케이션의 적응을 촉진하는 것은 예 측된 사용자 동기에 기초하여 복수의 임의의 버전 중 하나를 선택하는 것을 포함한다. 다양한 실시형태에서, 게이밍 애플리케이션의 적응을 촉진하는 것은 플레이어 불일치를 식별하는 것을 포함한다. 예측된 사용자 동기는 복수의 동기 요인의 각각에 대한 점수를 나타내는 동기 데이터를 포함할 수 있 다. 예측된 사용자 동기는 예측된 플레이어 동기의 변화를 나타내는 시간 경과에 따라 수집된 동기 데이터를 포 함할 수 있다. 본 명세서에 제시된 방법은 게임 텔레메트리 데이터에 기초하여, 플레이어 동기를 자동으로 정확하게 예측함으 로써 게임 개발 기술을 개선시킨다. 예를 들어, BEA 툴이 게이밍 애플리케이션의 각각의 반복/버전에 대해 예측된 사용자 동기를 나타낼 수 있으므로, 일부 미리 결정된 원하는 사용자 동기와 일치하는 예측된 사용자 동 기에 의해 업데이트된 버전의 게임을 달성하기 위해 게임 개발 플랫폼의 사용자에 의한 게임의 반복적 적 응을 촉진한다. 게다가, 게이밍 애플리케이션은, 예를 들어, 개별적인 플레이어의 예측된 사용자 동기에 적응하 여-게임에서 개별적인 플레이어의 경험을 향상시키는-다수의 버전으로 생성될 수 있다. 플레이어가 일치될 수 있고/있거나 플레이어 불일치가 예측된 사용자 동기에 기초하여 방지되어, 예를 들어, 동일한 동기를 일치시키 고, 호환 가능한 동기를 일치시키고/시키거나 호환되지 않는 동기를 방지하여 플레이어를 위한 매력적인 경험을 생성할 수 있다. 스스로 동기를 부여해 게임에 복귀하고 계속 플레이하는 플레이어는 게임의 성공을 향상시킬 수 있다. 게임 설계 및 게임이 이끌어내는 경험에 대한 동기의 중심 역할은 게임 내에서 동기의 심리학적 이론을 채택한 복수의 연구에 의해 강조되어 왔다. 그러나, 이러한 연구는 정성적 원칙에 기초하여 전형적인 플레이어 행동을 식별하고 설명하는 것을 목표로 하는 현상학적 동기 모델의 하향식 통합을 따른다. 대조적으로, 게임 사용자 연 구와 산업 기반 게임 테스팅은 플레이어 행동과 경험에 대한 이해를 더 많이 밝히기 위해 플레이어 분석 정보에 기초한 정량적 방식으로 초점을 옮겼다. 복수의 상이한 동기 요인을 정량화하는 대신, 이러한 방식은 플레이어 의 행동 패턴에 기초하여 플레이어를 클러스터링하거나 수익 창출 목적(예를 들어, 이탈 예측)을 위해 게임플레 이 행동의 객관적으로 규정된 양상을 예측하는 데 중점을 둔다. 이 점에서, 플레이어 분석 정보에 기초하여 플 레이어 경험의 양상(예컨대, 참여 또는 동기)을 캡처하는 것을 목표로 하는 방식은 게임에서 사용자 경험에 대 한 주관적인 개념을 측정하는 복잡성을 고려하면 여전히 정성적이다. 동기와 플레이 간의 관계에 대한 정량적 연구는 부족하다. 다음 예를 고려한다. BEA 툴은, 예를 들어, 플레이어가 -게임플레이 데이터를 통해 나타나는 바와 같이- 게임에서 행동적으로 수행하는 것과 동기 사이에 알려지지 않은 기본 기능이 있다고 가정하는 데이터-주도 플레 이어 모델링 방식을 사용할 수 있다. 특히, BEA 툴은 플레이어의 게임플레이로부터의 행동 데이터만이 게 임에서 동기의 정확한 예측 변수를 생성할 것이라고 가정할 수 있다. 동기는 자기 결정 이론-동기를 위한 긍정 적인 심리적 틀-에 기초할 수 있고 비디오게임 영역의 이론과 종종 연관되는 능력, 자율성, 관련성 및 존재감이 라는 4개의 핵심 동기 요인을 조사할 수 있다. BEA 툴은 플레이어 동기를 관찰하는 게임-특정 툴로 개발된 UPEQ(Ubisoft Perceived Experience Questionnaire)와 같은, 동기 측정 툴을 사용하여 훈련될 수 있다. 예를 들어, 플레이어 동기와 게임플레이 사 이의 관계를 추론하기 위해, Tom Clancy's The Division의 400명 초과의 플레이어로부터 데이터가 수집되었다. 이 데이터는 처리되고 집계되었으며 게임과 관련된 플레이어의 동기에 대한 설문조사가 독립적으로 수집되었다. UPEQ 설문지는 플레이어의 일반적인 능력 수준, 자율성, 관련성 및 게임에서의 존재감을 측정하는 데 사용되었 다. 보고된 개념의 주관적인 특성을 고려하면, BEA 툴은 2차 데이터 처리 방식을 사용하고 보고된 플레이 어의 UPEQ 리커트 척도 값을 점수가 아닌 순서 데이터로 처리할 수 있다. BEA 툴은 게임플레이와 보고된 동기 요인 간의 기능을 추론하기 위해 지원 벡터 기계(SVM)에 기초한 선호도 학습 모델에 간단한 통계적 순위 기반 방법을 적용할 수 있다. 결과는 몇몇의 높은 수준의 게임플레이 특징에 의존함으로써 보고된 동기 요인을 높은 정확도로 예측할 수 있음을 암시한다. 특히, BEA 툴의 비선형 기계 학습된 선호도 학습 모델은 보이지 않는 플레이어의 4개의 동기 요인을 적어도 93%의 정확도로 예측하려고 한다: 최상의 모델은 존재에 대해 97%의 정확도에 도달한다. 획득된 결과는 주관적으로 규정된 개념에 대한 순서형 데이터 처리의 이득에 대한 기 존의 증거에 추가되며 이들은 또한 플레잉의 높은 수준의 행동 데이터에 기초하여 검사된 게임에서 동기가 최고 의 정확도로 정성적으로 캡처될 수 있음을 검증한다. 본 명세서에 설명된 동기 모델은 여러 개의 기술적 개선을 보여준다. 첫째로, 플레이어 동기는 게임 내 게임플 레이 데이터를 통해서만 계산적으로 모델링된다. BEA 툴이 훈련되면, 사용자/플레이어 동기는 게임 텔레메 트리 데이터와 같은 게임플레이 데이터에만 기초하여 예측될 수 있다. 둘째로, 게임 테스팅 및 게임 사용자 조 사 전반에 자주 사용되는 Likert 척도 점수를 처리하기 위해 2차 방법론을 사용한다. 이 순서형 방식은 모든 플 레이어의 주관적 점수를 서로 비교하므로 소규모 참가자 세트만을 기반으로 매우 큰 데이터세트를 조합적으로 생성한다. 이 방식은 응답자의 보고 편견을 제거하는 데에도 효과적이므로, 보고된 동기의 실제 진실에 더 잘 접근하게 한다. 셋째로, 플레이어 동기의 양상은 소수의 주요 게임플레이 특징만을 기반으로 한 선호도 학습을 사용하여 모델링된다. 이러한 방법론의 예는 Tom Clancy's The Division(Ubisoft, 2016) 게임을 사용하여 400 명 초과의 플레이어를 대상으로 평가되었으며 이 게임에 대한 동기 모델의 예측 능력은 거의 확실성(즉, 93% 초 과의 정확도)에 도달했다. 다른 기술적 개선도 있을 수 있다. 자가-결정이론(self-determination theory: SDT)은 Deci와 Ryan의 연구에 기초하여 동기의 촉진에 대한 긍정 심리학 이론이다. 핵심 이론은 동기 뒤에 있는 내재적 인과 소재와 외재적 인과 소재의 이분법에 초점을 맞춤으 로써 단일 개념으로서의 초기 동기 프레임워크를 대조하기 위해 개발되었다. 후자는 외부 또는 내부 보상, 압력 및 기대에 의해 촉진되는 반면, 전자는 활동 자체의 본질적인 특성, 즉 능력, 자율성 및 관련성이라는 3개의 기 본 심리적 요구를 얼마나 잘 지원할 수 있는지에 기초한다. 비디오게임이 외적 동기를 촉진할 수 있는 상당한 양의 압력과 보상을 포함하지만, 이들은 일반적으로 내적 동기의 우수한 촉진제로서 간주된다. 게임플레이 동안 동기의 단기적인 변화가 관찰되더라도, 게임은 더 높은 수준에서 내재적 동기의 촉진을 위해 필요한 심리적 요 구를 지원한다. 비디오게임의 맥락에서, [R. M. Ryan, C. S. Rigby 및 A. Przybylski의 \"비디오 게임의 동기 끌어내기: 자기-결정 이론 방식\", Motivation and Emotion, vol. 30, no. 4, pp. 344 내지 360, 2006]은 내재 적 동기의 바탕이 되는 기본적인 심리적 요구를 다음과 같이 설명한다: 플레이어의 근위 및 원위 목표를 통해 나타나는 능력 또는 성취감과 행동 숙달에 대한 욕구. 이러한 요구는 일반적으로 자기 효능 및 의미 있는 발전에 대한 감각과 관련된다. 이것은 플레이어가 게임을 완료하기 위해 숙 달해야 하는 상호작용을 통해 지원되지만 완료 자체는 아니다. 플레이어가 취할 수 있는 의미 있는 선택, 전술 및 전략적 결정을 통해 나타나는 자율성 또는 통제력과 스스 로 결정하는 행동에 대한 욕구. 이것은 플레이 경험을 구성하면서도 높은 수준의 자유와 의미 있게 상이한 결과 를 허용하는 규칙 시스템과 상이한 게임 역학을 통해 지원된다. 다른 플레이어 및 믿을 수 있는 컴퓨터 에이전트와의 상호작용을 통해 나타나는 관련성 또는 소속감 및 다른 사람과 연결 및 상호작용하려는 욕구. 또한 다층적인 상호작용, 믿을 수 있고 풍부한 논-플레이어 캐릭터, 서사 적 설계, 및 심지어 게임 외부의 다른 플레이어와의 상호작용에 의해 지원된다. 중재된 경험의 존재감이나 느낌은 능력과 자율성 둘 다의 주요 촉진제이고, 신체적, 감정적, 서사적 구성요 소를 갖는 것으로 볼 수 있다. 실제로, 존재감 또는 몰입감 추구는 게임플레이 동기를 부여하는 원동력이 될 수 있다. STD와 존재감 사이의 강력한 관계에 기초하여, 욕구 만족 설문지의 플레이어 경험과 UPEQ 둘 다는 이를 사용하여 다른 긍정적인 심리적 욕구를 촉진할 수 있는 게임 참여 수준을 측정한다. 위의 요인이 내재적 동기의 공식화에 동등하게 기여하지 않는다는 점에 유의하는 것이 중요하고; 능력 또는 관 련성이 핵심 촉매제로 간주되는 반면, 자율성은 일반적으로 동기를 촉진하는 데 있어 지원 역할을 한다. 그럼에 도 불구하고, 자율성의 부재 시, 동기는 오직 내사적이거나 강박적인 것으로만 간주될 수 있다. 게임 내에서 내 재적 동기 부여의 주요 원동력은 활동이 구조화되는 방식으로 인해 일반적으로 능력이지만, 관련성은 경험을 향 상시키는 데 기여한다. BEA 툴은 SDT에 의존하여 위에서 언급한 동기의 4개의 양상을 정량화한다. 이를 위 해 UPEQ는 게임플레이 경험에 영향을 받는 SDT 요인을 측정하기 위해 설계된 게임 맞춤형 설문지로 사용된다. UPEQ는 특히 업계 설계자 및 이해관계자와 관련된 게임플레이 결과를 예측하기 위해 Massive Entertainment의 연구원이 개발했다. UPEQ는 측정된 SDT 요인에 기초하여 플레이 시간, 게임에 지출된 금액, 및 그룹 플레이 시 간을 예측할 수 있다. 유용성 외에도, UPEQ는 또한 게임 참여 설문지, BrainHex 및 플레이어의 욕구 만족 경험 과 같은 이전 영역별 SDT 설문지의 한계를 처리하면서, 기본 욕구 만족 척도(들)를 비디오게임 플레이에 특정한설문조사에 적응시키는 것에 초점을 둔다. 그 결과는 SDT의 강력한 이론적 기반을 갖춘 신뢰할 수 있고 일관된 평가 툴이다. 선호도 학습(Preference Learning: PL)은 알고리즘이 2개의 변수 간의 선호도 관계를 추론하는 방식을 학습하는 감독 기계 학습 기법이다. BEA 툴은 이러한 일반적인 기계 학습 패러다임과 플레이어 경험이 게임에서 작 동하는 방식 사이의 강력한 연결 때문에 선호도 학습(PL) 모델을 채택한다. 본질적으로, PL은 절대값 대신 발생 간의 차이에 초점을 맞춤으로써 특정한 심리적 프로세스를 모델링한다. 이 방식은 내부적으로 자신의 경험을 평 가하는 데 도움이 되는, 플레이어의 인식 프로세스-예를 들어, 고정 편향, 적응, 습관화 및 다른 최신 효과-에 더욱 밀접하게 부합한다는 이점이 있다. PL은 절대값 또는 부류 경계 대신 상대 연관성에 의존하고 대신 원본 데이터세트를 쿼리의 특징 벡터 간의 차이 표현으로 쌍으로 변환하는 것에 기초하는 강력한 방법이다. 데이터 세트의 이러한 변환은 이진 분류기가 문제를 해결할 수 있는 방식으로 원래 문제를 재구성한다. 새로운 데이터세트에서, 선호 관계의 방향은 2개의 부류 중 하나와 연관될 수 있다. 예로서, 선호 관계를 관찰한다:"}
{"patent_id": "10-2024-7008865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "연관된 출력에 기초하면:"}
{"patent_id": "10-2024-7008865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "쌍 변환을 통해, 2개의 새로운 특징이 생성된다: , 다음과 연관되고"}
{"patent_id": "10-2024-7008865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "다음과 연관됨"}
{"patent_id": "10-2024-7008865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "특징 벡터의 각각의 쌍 간의 이러한 비교가 다음을 제공한다"}
{"patent_id": "10-2024-7008865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "새로운 데이터 포인트. xI는 명확한 선호 관계가 항상 추론 가능한 것은 아니기 때문에 가능한 모든 고유 조합 의 하위세트이다. BEA 툴은 또한 이들이 LIBSVM 라이브러리에 기초하는 Preference Learning Toolbox1에 구현됨에 따라 지원 벡 터 기계(SVM)의 순위 지정을 사용할 수 있다. SVM은 제한된 양의 데이터 및 입력 특징으로도 강력한 모델을 생 성할 수 있다. SVM은 원래 더 높은 차원의 특징 공간에 투영된 데이터포인트를 분리하는 초평면의 마진을 최대 화하여 분류 작업을 해결하기 위해 사용되었지만 나중에 PL 작업도 해결하기 위해 채택되었다. BEA 툴은 방사형 기저 함수(RBF) 커널을 갖춘 선형 및 비선형 SVM을 모두 사용할 수 있다. 데이터 포인트 간의 선형 분리 를 목표로 하는 선형 SVM과 달리, RBF SVM은 데이터 포인트의 국부적 근접성을 강조하여, 변환된 특징 공간에 최대 마진 초평면을 맞춘다. 이들 알고리즘을 조정하기 위해, BEA 툴은 훈련 세트의 마진 최대화와 분류 오류 최소화 사이의 균형을 제어하는 C 정규화 항과-RBF 커널의 경우-포인트 간의 유사성 측정의 변화를 제한하 여 비선형 토폴로지에서 데이터포인트 간의 각각의 비교에 가중치를 부여하는 방식을 제어하는 γ 초매개변수에 의존적일 수 있다. 이 예에서 분석된 데이터는 Tom Clancy's The Division(Ubisoft, 2016)(이하 \"The Division\") 플레이어의 게임 내 행동 데이터(플레이어 메트릭) 및 설문조사 설문지 응답이다. The Division은 캐릭터 성장 시스템과 3인칭 커버 기반 전술 사격 전투 메커니즘을 결합한 온라인 멀티플레이어 액션 롤 플레잉 게임이다. 이 게임의 배경은 천연두가 창궐한 종말 이후의 뉴욕이다. 플레이어는 정부 요원으로서 협력하여 (그리고 서로 대항하여) 전염병 의 여파와 조직 범죄 활동의 증가로 혼란에 빠진 도시를 청소하고 조사해야 한다.게임의 핵심은 플레이어가 새로운 능력을 잠금 해제하는 스토리 중심의 임의의 미션을 포함하는 상이한 게임 내 활동에 참여함으로써 새로운 레벨을 획득하고, 무기와 방어구를 포함한 새로운 장비를 획득하는 진행 시스템이 다. 플레이어의 힘은 레벨(최대 30)로 측정할 수 있고 장비의 품질은 장비 점수 포인트로 표현된다. 게임의 PvE(플레이어 대 환경) 섹션에서, 플레이어는 그룹을 구성하고 함께 임무를 완료할 수 있다. 이 게임은 또한 자 체 진행 시스템을 갖춘 플레이어 대 플레이어 경쟁(PvP) 영역-다크존(Dark Zone)-을 특징으로 한다. 이 특별한 영역에서 플레이어가 더 나은 장비를 위한 임무를 완료하기 위해 여전히 그룹을 구성할 수 있지만; 이들은 또한 다른 플레이어를 죽이고 스스로 보상을 받음으로써 서로를 공격하고 불량배가 될 수 있다. 최대 레벨에 도달한 후, 플레이어는 그룹에게 특히 어려운 임무인 습격에 참여할 수 있다. Ubisoft는 또한 게임에 새로운 영역, 장 비, PvE 및 PvP 콘텐츠 둘 다를 추가하는, 다운로드 가능한 콘텐츠(downloadable content: DLC) 형태로 게임을 위한 복수의 확장팩을 출시했다. 이 게임은 호평을 받았을 뿐만 아니라(consoles2에서 메타크리틱 점수 80/100) release3 당시에 Ubisoft에서 가장 많이 팔린 게임이기도 했다. 이 게임이 대규모 멀티플레이어 온라인 롤플레 잉 게임과 멀티플레이어 슈터의 상이한 시스템을 통합하고 상이한 플레이 스타일과 상호작용 모드(즉, 플레이어 -환경 및 플레이어-플레이어)를 지원하므로, 동기 연구를 위한 풍부하고 복잡한 게임 테스트베드를 제공한다. 수집된 데이터는 장기간에 걸친 플레이어의 게임 내 활동에 대한 집계 정보와 대응하는 UPEQ 설문조사 점수로 구성된다. 이 두 가지 유형의 데이터는 독립적으로 수집되었고, 게임 플레이 특징은 웹 인터페이스를 통해 별도 로 수집된 설문조사 데이터를 기록했다. 이와 같이, 설문조사 데이터는 플레이어의 전반적인 성향을 측정한다. 데이터세트는 플레이어당 하나의 데이터포인트로 구성되고, 위에서 언급한 데이터 수집 프로세스에는 총 443명 의 플레이어가 참여했다. 피험자의 대략 51%는 18 내지 34세의 젊은 성인이었고, 반면에 9%는 미성년자(15 내지 17세), 34%는 35 내지 54세, 6%는 55세 초과였다. 국가별로는, 응답자의 23%가 영국, 호주 15%, 스웨덴 14%, 덴마크 9%, 핀란드 5%, 노르웨이 5%, 뉴질랜드 1%였으며 나머지 28%는 답변하지 않았다. 임의의 통계 분석 프로세스가 왜곡되는 것을 방지하기 위해 데이터세트에서 누락된 값, 손상된 항목 및 이상값 이 있는 데이터포인트를 정리했다. 일반적인 게임 메트릭의 분포를 왜곡하는 이상값으로 인해 그리고 플레이 시 간을 부풀리는 데이터 로깅 서비스에서 발생하는 잡음으로 인해 광범위한 가지치기가 필요했다. 정리 프로세스 후 데이터세트는 298명의 플레이어를 포함한다. 게임 내에서 플레이어의 행동을 계산적으로 표현하기 위해, 광범위한 게임 텔레메트리 데이터에서 추출할 수 있 는 30개의 높은 수준의 게임플레이 특징이 사용된다. 이들 중 대부분이 플레이어의 시간 할당 및 진행을 설명하 는 단순 집계 게임 메트릭이지만, 이러한 게임플레이 특징 중 4개는 클러스터 분석을 통해 수행되는 플레이어의 게임 내 활동의 시퀀스-기반 프로파일링에 기초한 고유한 플레이 스타일 또는 플레이어 유형의 전용 범주이다. 부가적으로, 데이터세트는 UPEQ 설문조사로 측정된 바와 같은 각각의 플레이어의 4개의 동기 요인을 나타내는 4 개의 Likert 점수를 포함한다. 고려되는 3가지 유형의 데이터는 다음과 같습니다: 게임 메트릭: 이러한 원(raw) 특징은 일반 플레이 시간(플레이한 일수, 그룹에 참여한 일수, 다크존에 있었 던 일수, 세션, 플레이 시간, 그룹 플레이 시간, 다크존 플레이 시간, 로그 플레이 시간); 완료(비일일 임무, 일일 임무, 보조 임무, 기습이 있는 날, 기습); 진행도(기어 점수, 다크존 순위, 레벨, 초기 레벨 30, 레벨 30 도달); 초기 게임플레이(레벨 < 30, 초기 플레이 시간, 초기 그룹 플레이 시간, 초기 다크존 플레이 시간, Rogue로서의 초기 플레이 시간); 및 DLC 게임 플레이(지하 플레이 시간, 서바이벌 플레이 시간, 시즌-패스)와 관련하여 분류될 수 있다. 플레이어 유형: 4가지 플레이어 유형은 모험가, 엘리트, PvE 올라운더, 및 소셜 다크존 플레이어로 지칭된다. 이러한 유형은 집계된 게임 데이터의 종래의 k-평균 클러스터링을 통해 유래될 수 있다. 동기 요인: UPEQ는 평균 리커트 척도 값의 형태로 동기의 4가지 요인에 점수를 매긴다. 순서형 데이터의 평 균을 계산하는 것이 개념적으로 문제가 될 수 있지만, 평균 설문조사 점수는 이들이 여전히 점수 내에서 특정 경향을 보여줄 수 있기 때문에 Likert 유사 데이터를 사용하는 광범위한 방법이다(예를 들어, 더 높은 점수는 전체 더 긍정적인 반응에 대응하는 것으로 가정된다). 이전에 언급된 바와 같이, 2차 모델링 방식은 모든 플레 이어에 대한 쌍별 비교를 통해 이러한 점수를 순서형 데이터로 처리하는 데 사용된다. 원본 데이터세트가 플레이어당 하나의 데이터포인트를 포함하므로, 선호도 학습 작업에 사용되는 개별적인 특징 벡터는 독립적이다. 이것은 PL 실험을 준비하는 동안, 데이터세트의 쌍 변환 중에 각각의 데이터포인트가 모든 다른 포인트와 비교된다는 것을 의미한다. 이 변환은 2개의 데이터포인트가 동일하다고 간주되는 유의 한계를제어하는 선호도 문턱값(preference threshold: Pt) 매개변수를 적용한다. 문턱값(Pt)의 목적은 모델링 결과를 왜곡할 수 있는 실측 데이터의 잡음에 대응하는 것이다. 부가적으로, 데이터포인트의 관계를 선호 관계로 변환 하기 위해, 이 단계는 또한 기계 학습 작업을 위한 새로운 데이터포인트를 생성한다. 데이터세트의 크기는 실측 및 최적의 Pt 매개변수에 따라 평균적으로 64, 705개의 훈련 포인트와 775개의 테스팅 포인트로, 원래 데이터세 트의 2차 비율에 가깝다. 게다가, 각각의 쌍별 비교가 2개의 새로운 데이터포인트-양방향의 선호 관계를 설명함 -를 생성하므로, 변환은 분류 작업의 기준을 50% 정확도로 균형을 맞춘다. 모든 PL 모델은 10-폴드 교차 검증을 통해 검증된다. 데이터 유출을 방지하기 위해, 데이터의 정규화 및 쌍별 변환 전에 훈련 폴드와 테스트 폴드가 분리된다. z-정규화 기법은 변환 전 훈련 세트와 테스트 세트 둘 다에 적 용될 수 있다. 테스트 세트의 독립성을 보존하기 위해, 훈련 세트와 동일한 분포에서 추출된다고 가정하고 대응 하는 테스트 세트에도 동일한 변환을 적용한다. RankSVM의 최적의 매개변수는 값 범위 내에서 철저한 검색을 통해 발견된다. 특히, 이 방법은 최고 10-폴 교차 검증 정확도를 산출하는 C, 감마 및 Pt 값의 삼중항을 철저하게 검색한다. C 정규화 용어는 다음에서 검색된다 , 감마 RBF 매개변수는 다음과 같다 , 최적의 선호도 문턱값은 다음과 같다"}
{"patent_id": "10-2024-7008865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "모든 실험에 걸쳐 최상의 감마 매개변수가 0.5인 것으로 밝혀졌지만, C와 Pt는 데이터의 토폴로지에 더 민감했 다; 도 3을 참조한다. 선택된 C 및 Pt 매개변수는 역량의 경우 C = 2, Pt = 1; 자율성의 경우 C = 1, Pt = 0; 관련성의 경우 C = 4, Pt = 1; 선형 SVM 존재의 경우 C = 3, Pt = 0.5 및 역량의 경우 C = 3, Pt = 0.5; 자율 성의 경우 C = 4, Pt = 0; 관련성의 경우 C = 4, Pt = 0; RBF SVM 존재의 경우 C = 2, Pt = 0.5였다. 제1 구현예에서, 4개의 플레이 스타일만이 SVM 모델의 입력으로 사용되어 동기 예측 능력을 테스트한다. 입력 특성 세트의 저차원에도 불구하고, 선형 모델과 비선형 모델 둘 다는 모든 모델에 걸쳐 평균적으로 3.7% 및 3.57% 정확도로 각각 50% 기준을 초과할 수 있다. 제2 구현예에서, PL 모델은 26개의 게임 메트릭만을 모델 입력으로 간주한다. 게임 메트릭만으로도 보고된 동기 요인을 예측하는 데 상당히 성공적이다. 특히, 선형 SVM 모델이 모든 모델에 걸쳐 평균 65.89%의 정확도로 성공 하는 반면, 개별적인 요인에 대한 최상의 모델은 특정한 폴드에서 거의 80%: 각각 능력, 자율성, 관련성 및 존 재감의 경우 79.66%, 75.62%, 71.69% 및 79.68%의 정확도로 성능을 발휘한다. 관련성은 선형 모델을 예측하는 가장 쉬운 요인인 것으로 보이며, 이는 통계 분석 동안 관련성이 가장 개별적인 게임 메트릭과 상관성이 있다는 점을 고려하면 놀라운 일이 아니다. 반면에, 선형 SVM은 자율성 문제로 어려움을 겪을 수 있고, 이는 자율성과 데이터의 기술적 통계 분석 동안 발견되는 다른 특징 간의 낮은 양의 상관성으로 설명될 수 있다. 비선형 커널은 모든 모델에 걸쳐 평균적으로 75.62%의 정확도로 모델 성능을 더욱 개선시킨다. 최상의 개별적인 모델은 거의 90%의 정확도(능력: 86.73%; 자율성: 89.31%; 관련성: 89.95%; 및 존재감: 87.60%)에 도달하는 대 응하는 선형 모델보다 훨씬 뛰어나다. 선형 모델과 비교하여, RBF SVM은 성능이 낮은 선형 모델(즉, 자율성)도 크게 개선시키기 때문에 임의의 동기 요인에 걸쳐 더 강력한 것으로 보인다. 플레이 스타일만을 기초한 모델에 서 획득한 저조한 성능과 달리, 게임 메트릭에 기초한 모델은 모든 4개의 요인에 걸쳐 매우 정확하고 강력하다. 플레이어 유형 또는 다른 높은 수준의 플레이 스타일 프로파일을 포함하면 영역별 정보를 추가함으로써 게임 메 트릭의 예측 능력을 향상시킬 수 있다. PL 작업에 다른 26개 게임 메트릭과 함께 플레이 스타일을 포함하면, 게 임 메트릭에만 기초한 모델의 능력을 뛰어넘어 비선형 모델의 정확도가 개선된다. 한편, 선형 모델은 모든 테스 트에 걸쳐 평균적으로 65.92%(능력, 자율성, 관련성 및 존재감에 대해 각각 79.66%, 70.94%, 71.79% 및 76.52%)에 도달하며 이는 게임 메트릭에 기초하여 모델에 의해 획득된 성능과 비슷하다. 한편, 비선형 RBF 커널 을 사용하는 모델은 평균적으로 82.36%의 정확도에 도달하고 최고 성능 폴드에서 93% 초과의 정확도 값을 달성 한다: 능력, 자율성, 관련성 및 존재감에 대해 각각 93.01%, 94.35%, 95.02% 및 96.83%. 개별적인 특징과 동기요인 사이에 분명한 선형 관계가 없는 경우에도, 비선형 PL 기법은 동기를 예측하기 위한 효율적인 방법을 제공 하고 게임 설계를 위한 위한 통찰력 있는 정성적 툴을 제공할 수 있다. 도 8은 본 개시내용의 실시형태에 따른 방법의 흐름도를 나타낸다. 특히, 도 1 및 도 2, 도 3a, 도 3b 및 도 4 내지 도 7과 함께 설명된 임의의 기능 및 특징과 함께 사용하기 위한 방법이 제시된다. 단계는 프로세서를 포함하는 시스템을 통해, 이전 게임 콘텐츠에 기초하여 절차적 콘텐츠를 수신하는 것을 포함한다. 단계는 게이밍 봇에 의한 시뮬레이션된 게임 플레이로부터의 기계 학습 및 플레이 트레이스 데이터 및/또는 행동 동기 데이터에 기초하여 시스템을 통해 절차적 콘텐츠를 반복적으로 개선하는 것을 포함한다. 단계는 개선된 절 차적 콘텐츠에 기초하여 시스템을 통해 후보 게임 콘텐츠를 생성하는 것을 포함한다. 도 9는 본 개시내용의 실시형태에 따른 방법의 흐름도를 나타낸다. 특히, 도 1 및 도 2, 도 3a, 도 3b 및 도 4 내지 도 8과 함께 설명된 임의의 기능 및 특징과 함께 사용하기 위한 방법이 제시된다. 단계는 프로세서를 포함하는 시스템을 통해 게임에 대응하는 게이밍 애플리케이션을 수용하는 것을 포함한다. 단계는 적어도 하나의 비모방 게이밍 봇에 의한 게임 플레이에 기초하여 시스템을 통해 게이밍 애플리케이션을 업데이트하여 제1 업데이트된 게임에 대응하는 제1 업데이트된 게이밍 애플리케이션을 생성하는 것을 포함한다. 단계는 시스템을 통해, 제1 복수의 실제 플레이어에 의한 제1 업데이트된 게임의 플레이에 응답하여 생성된 제1 게임 텔레메트리 데이터에 기초하여 적어도 하나의 모방 게이밍 봇을 생성하는 것을 포함한다. 단계는 시스템을 통해, 제1 복수의 실제 플레이어에 의한 제1 업데이트된 게임의 플레이에 기초하여 행동 경험 분석(BEA) 데이터 를 생성하는 것을 포함한다. 단계는 시스템을 통해, BEA 데이터에 기초하여 적어도 하나의 BEA 툴을 생성 하는 것을 포함한다. 단계는 적어도 하나의 모방 게이밍 봇에 의한 제1 업데이트된 게임의 플레이에 기초 하여 시스템을 통해 제1 게이밍 애플리케이션을 업데이트하여 제2 업데이트된 게임에 대응하는 제2 업데이트된 게이밍 애플리케이션을 생성하는 것을 포함한다. 단계는 제2 복수의 실제 플레이어에 의한 제2 업데이트된 게임의 플레이에 응답하여 생성된 제2 텔레메트리 데이터에 기초하여 시스템을 통해 예측된 플레이어 경험을 생 성하는 것을 포함한다. 단계는 시스템을 통해, 예측된 플레이어 경험에 기초하여 제2 게이밍 애플리케이션 을 업데이트하여 제3 업데이트된 게임에 대응하는 제3 업데이트된 게이밍 애플리케이션을 생성하는 것을 포함한 다. 도 10은 본 개시내용의 실시형태에 따른 방법의 흐름도를 나타낸다. 특히, 도 1 및 도 2, 도 3a, 도 3b 및 도 4 내지 도 9와 함께 설명된 임의의 기능 및 특징과 함께 사용하기 위한 방법이 제시된다. 전술한 내용이 예를 들 어, 게임 출력, 플레이어 입력, 게임 상태, 게임 이벤트, 게임 성과, 게임 목표를 향한 진행, 게임 매개변수, KPI 및 다른 게임 분석 정보 등을 포함할 수 있는 플레이 트레이스에서 수집된 데이터와 같은 게임 텔레메트리 데이터에 기초하여 훈련되는 인공 지능 모델에 주로 초점을 맞추었지만, 게이밍 애플리케이션의 픽셀 데이터는 또한 예를 들어, 사용자 동기 형태로 사용자 경험을 예측하고/하거나 본 명세서에서 논의되는 PCG 또는 BEA 툴 을 포함하지만 이들로 제한되지 않는 게임 개발 플랫폼과 함께 설명된 다른 기능 및 특징 중 임의의 하나 를 수행하도록 사용할 수 있는 인공 지능 모델을 생성하는 데 사용될 수 있다. 단계는 프로세서를 포함하는 시스템을 통해, 기계 학습에 기초하여 행동 경험 분석(BEA) 툴을 생성하는 것을 포함한다. 단계는 시스템을 통해, 게이밍 애플리케이션으로부터 픽셀 데이터를 수신하는 것을 포함 한다. 단계는 시스템을 통해, BEA 툴을 픽셀 데이터에 적용함으로써 예측된 사용자 경험을 생성하는 것을 포함한다. 단계는 시스템을 통해, 예측된 사용자 경험에 기초하여 게이밍 애플리케이션의 적응을 촉진하 는 것을 포함한다. 다양한 실시형태에서, 시스템은 게이밍 개발 애플리케이션을 더 포함하는 게임 개발 플랫폼을 통해 구현되며, 게임 애플리케이션의 적응을 촉진하는 것은 게이밍 개발 애플리케이션을 통해 게이밍 애플리케이션의 적응을 촉 진하는 것을 포함한다. 게이밍 애플리케이션은 복수의 임의의 버전을 포함할 수 있으며, 시스템은 게이밍 애플 리케이션을 실행하는 게임 시스템을 통해 구현되고, 게이밍 애플리케이션의 적응을 촉진하는 것은 예측된 사용 자 경험에 기초하여 복수의 임의의 버전 중 하나를 선택하는 것을 포함한다. 게이밍 애플리케이션의 적응을 촉 진하는 것은 플레이어 불일치를 식별하는 것을 포함할 수 있다. 예측된 사용자 경험은 복수의 동기 요인의 각각 에 대한 점수를 나타내는 동기 데이터 및/또는 예측된 플레이어 경험의 변화를 나타내는 시간 경과에 따라 수집 된 경험 데이터를 포함할 수 있다. 픽셀 데이터는 게이밍 봇에 기초하여 생성될 수 있다. 기계 학습은 이전 게 임 플레이와 연관된 복수의 플레이어 설문지에 기초하고 또한 이전 게임 플레이와 연관된 이전 게임 텔레메트리 데이터에 기초하여 훈련된 기계 학습 모델을 포함할 수 있다. 세가지 유형의 심층 컨볼루션 신경망(CNN) 아키텍처를 사용하여 비디오 프레임 또는 비디오 시퀀스의 픽셀 데이 터에 기초하여 주석이 달린 각성 흔적의 낮은 값과 높은 값을 분류하는 예를 고려한다. 예를 들어, CNN은 3D 서 바이벌 슈터 게임의 50개의 게임플레이 비디오의 데이터세트에서 테스트되었다. 모든 비디오에는 RankTrace 연 속 주석 툴을 사용하여 플레이어 자신에 의한 각성을 위해 주석이 달렸다(1인칭 주석). 경험한 콘텐츠의 픽셀로 부터 영향을 예측하는 작업이 가능할 뿐만 아니라 매우 정확하다. 특히, 획득된 각성 모델이 까다로운 리브-원- 비디오-아웃(leave-one-video-out) 교차 검증 방법을 사용하여 78% 초과의 평균 정확도를 달성할 수 있지만; 최 상의 모델은 98%보다 더 높은 수율 정확도를 획득했다. 결과는 또한 -적어도 조사된 게임에 대해- 플레이어 경 험이 매우 정확하고 일반적인 방식으로 화면 상 픽셀을 통해서만 캡처될 수 있다는 것을 나타낸다. 본 명세서에서 논의되는 방법론은 게임 애플리케이션 분석 및 설계의 기법에 대한 여러 개의 개선을 제공한다. 플레이어의 영향/경험은 상호작용의 맥락을 관찰함으로써만 모델링될 수 있고 사용자 입력의 감정 또는 양상의 임의의 다른 직접적인 표현을 통해서는 모델링될 수 없다; 이 점에서 제시된 방법은 일반적이며 사용자에 구애 받지 않는다. 게임플레이 스크린은 게임 경험에 매핑될 수 있고 둘 사이의 관계를 모델링하고 예측하는 데 사용 될 수 있다. 감성 컴퓨팅에서 이러한 매핑을 추론하는 능력에 대해 세 가지 CNN 변형을 비교한다: 획득된 높은 정확도 값은 작업에 대한 적합성을 입증한다. 플레이어 경험 모델링에 대한 이러한 기술적 개선은 더 빠르고, 더 쉽고 더 정확한 경험 모델링을 촉진하여 더 빠르고, 더 쉽고 더 효과적인 게임 분석 및 설계를 가능하게 한 다. 이 실시예에서 사용되는 게임플레이 비디오는 Unity 3D 게임 엔진으로 개발된 슈터 게임에서 캡처되었다. 특히, Unity 3D의 튜토리얼 패키지를 개조한 게임인 Survival Shooter가 사용되었다. 이 게임에서, 플레이어는 60초 동안 가능한 한 많은 적대적인 장난감을 쏘고 장난감이 플레이어의 아바타와 충돌하여 체력이 떨어지지 않도록 해야 한다. 적대적인 장난감은 레벨의 미리 결정된 영역에서 계속 생성되고 아바타를 향해 수렴된다. 플레이어 의 아바타에는 몇 발의 발사로 각각의 장난감을 파괴할 수 있는 밝은 레이저 빔을 발사하는 총이 있다. 파괴된 모든 장난감은 플레이어의 점수에 추가된다. 데이터는 각각 2개의 게임플레이 비디오를 생성하고 주석을 추가한 25명의 상이한 플레이어로부터 수집되었다. 각각의 플레이어는 게임 세션(60초)을 플레이한 후 각성의 면에서 녹화된 게임플레이 장면에 주석을 달았다. Griffin PowerMate 휠 인터페이스를 사용하여 영향에 대한 지속적이고 무제한적인 주석을 허용하는 RankTrace 주석 툴을 사용하여 주석을 수행했다. 게임플레이 비디오가 30㎐(즉, 초당 30프레임)로 캡처되는 동안 RankTrace 툴은 초당 4개의 주석 샘플을 제공했다. 게임플레이 비디오의 코퍼스(corpus)는 15초 미만의 게임플레이 장면을 생략하여 정리되었으며, 그 결과 45개의 게임플레이 비디오와 총 8,093개의 각성 주석의 정리 코퍼스가 생성되었다. 이 코퍼스의 플레이스루의 평균 지 속시간은 44초이지만, 플레이스루의 60%에서 플레이어는 전체 60초 동안 살아남아 게임 레벨을 완료했다. CNN이 원 비디오 데이터를 정서적 상태에 매핑할 수 있는 방식을 평가하기 위해, CNN 모델은 공간 정보만을 포 함하는 개별적인 프레임과 공간 및 시간 정보를 모두 포함하는 비디오 세그먼트를 입력으로 사용했다. RankTrace가 무제한 주석을 제공하므로, 각각의 비디오의 주석 값은 최소-최대 정규화를 통해 [0, 1] 값으로 변 환되었다. 주석이 없는 임의의 프레임의 각성 값을 마지막 주석 프레임의 각성 값으로 처리함으로써 주석(4㎐) 이 있는 비디오(30㎐)의 녹화 빈도와 값을 동기화했다. CNN을 훈련하고 평가하는 계산 복잡성을 감소시키기 위 해, RGB 비디오 프레임을 회색조로 변환했고 72×128 픽셀로 크기를 조정했다; 이것은 이미지의 색상이 아닌 밝 기만을 고려하는 더 간결한 표현을 발생시켰다. Survivor Shooter의 뚜렷한 그림자와 밝게 빛나는 아바타 및 발 사체로 인해, 밝기는 게임플레이 행동을 추출하는 핵심 특징으로 간주되었다. RGB 채널 또는 더 큰 프레임 크기 가 사용되어 게임플레이에 대한 더 많은 정보를 제공하고 차원에 영향을 미칠 수 있지만, 이것은 또한 훈련하는 CNN에 상당히 더 많은 데이터를 제공할 것이다. CNN의 입력과 관련하여, 소수의 후속 프레임이 장면의 내용을 캡처하는 데 적합한 것으로 간주되었다. 특히, 플레이어의 영향 상태를 특성화하기 위해 8개의 후속 프레임이 사용되었다. 특히, 게임플레이 비디오는 시간 인식 CNN 아키텍처에 대한 입력으로 사용되는 8개의 후속 프레임 의 겹치지 않는 세그먼트로 분할되었다. 입력이 단일 이미지인 경우, 각각의 비디오 세그먼트의 마지막 프레임 이 사용되었다. CNN의 출력은 8-프레임 비디오 세그먼트에 기초하여 계산하는 것이 간단하다. 주석은 4㎐에서 생성되므로, 대부 분의 경우에, 비디오 프레임 세그먼트는 하나의 주석을 포함할 것이다. 8개의 프레임 내에 2개의 주석이 제공되 는 경우에, 해당 평균값이 계산된다. RankTrace는 간격 데이터를 생성하므로 문제를 회귀 작업으로 기술하는 것 이 자연스럽게 보일 수 있다; 그러나, 사용자에 구애받지 않고 일반적인 방식을 제공하려는 목표를 고려할 때, 결과의 가치에 관해 어떤 가정도 할 필요가 없는데, 이로 인해 매우 편향되고 사용자별 모델이 생성될 수 있기때문이다. 기본 방법론은 분류 작업으로 간주될 수 있고 각각의 추적의 평균값을 클래스 분할 기준으로 사용하 여 간격 값을 이진 부류(낮은 각성 및 높은 각성)로 변환할 수 있다. 부류 분할은 임의의 문턱값 매개변수(E)를 사용하여 평균 주변의 각성 값이 '불확실'로 표시되고 분류 동안 무시되는 구역을 결정할 수 있다. 부류를 분할 하는 대안적인 방식(예컨대, 곡선 아래의 영역 또는 중앙값)도 가능하지만, 다음의 예는 평균에 기초하여 추적 을 분할한다. 이전에 논의된 바와 같이, 3개의 예시적인 CNN 아키텍처가 평가되었다. 제1의 2개는 입력(단일 프레임 또는 비 디오)에 2D 훈련 가능 필터를 적용하는 반면에, 제3의 것은 3D 훈련 가능 필터를 적용한다. 모든 CNN 아키텍처 는 동일한 수의 컨볼루션 계층과 완전 연결 계층, 대응하는 컨볼루션 계층에서의 동일한 수의 필터 및 완전 연 결 계층에서의 동일한 수의 은닉 뉴런을 갖는다. 이를 통해 비디오 데이터를 정서적 상태에 매핑하는 이 3개의 아키텍처의 능력을 공정하게 비교하는 동시에 시간 정보가 분류 작업에 미치는 영향에 대한 통찰력을 얻는다. 예를 들어, 비디오 및 이미지에 대한 다른 CNN은 사용된 것보다 훨씬 더 큰 아키텍처를 사용할 수 있다는 점에 유의해야 한다. 전술한 논의의 대부분이 픽셀 데이터에 대해 훈련되고 이를 활용하는 AI 모델의 사용에 초점을 맞추었지만, 게 임의 오디오는 또한 BEA 툴을 포함하지만 이로 제한되지 않는 게임 개발 플랫폼의 AI 모델의 입력으로 사 용될 수 있다. 특히, 오디오의 추가는 게임 유형에 따라 AI 모델의 성능을 5 내지 10%만큼 향상시킬 수 있다. 특히, 픽셀-오디오 AI 경험 모델은 90% 이상의 정확도에 도달할 수 있다. 도 11은 본 개시내용의 실시형태에 따른 CNN 아키텍처의 블록도 표현을 나타낸다. 컨볼루션 계층은 \"C\"로, 최대 풀링 계층은 \"P\"로, 완전 연결 계층은 \"F\"로 표시된다. 제1 CNN 예시적인 아키텍처인 2DFrameCNN은 2D 필터를 적용하는 단일 프레임을 입력으로 사용한다. 2DFrameCNN 아키텍처는 각각 크기가 5×5 픽셀인 8, 12 및 16개의 필터가 있는 3개의 컨볼루션 계층으로 구성된다. 각각의 컨볼루션 계층에는 2×2 크기의 2D 최대 풀링 계층이 후속된다. 컨볼루션의 출력은 960개 요소의 특징 벡터이며, 이는 출력에 연결되는 64개의 은닉 뉴런이 있는 완전 연결 계층에 공급된다. 이 아키텍처에는 대략 6.9×104개의 훈련 가능 매개변수를 갖고 비디오 데이터의 공간 정보만을 활용한다. 제2 CNN 아키텍처인 2DSeqCNN은 입력 비디오 세그먼트에 2D 필터를 적용한다. 2DSeqCNN 네트워크는 2DFrameCNN 아키텍처와 정확히 동일한 토폴로지를 갖지만 입력이 비디오 시퀀스이므로 훈련 가능 매개변수의 수가 약간 더 높다(대략 7×104). 이 아키텍처는 데이터의 공간적 정보와 시간적 정보를 모두 암시적으로 활용한다. 제3 CNN 아키텍처인 3DSeqCNN은 입력 비디오 세그먼트에 3D 필터를 적용한다. 다른 아키텍처와 마찬가지로, 3DSeqCNN은 각각 크기가 5×5×2 픽셀인 8, 12 및 16개의 필터가 있는 3개의 컨볼루션 계층을 갖는다. 컨볼루션 계층 중 각각의 계층에 2×2×1 크기의 3D 최대 풀링 계층이 후속된다. 3D 컨볼루션 계층은 1,920개의 요소의 특징 벡터를 생성하며, 이는 64개의 뉴런이 있는 완전 연결 계층에 공급된다. 3D 훈련 가능 필터로 인해, 3DSeqCNN은 대략 14.5×104개의 훈련 가능 매개변수를 갖는다. 이 아키텍처는 공간 차원 및 시간 차원에 따라 훈련 가능 필터를 적용함으로써 데이터의 공간 정보와 시간 정보를 모두 명시적으로 활용한다. 2DFrameCNN이 단일 프레임을 입력으로 수용하는 반면, 2DSeqCNN과 3DSeqCNN은 모두 8개의 프레임 시퀀스, 즉, 267밀리초 동안 지속되는 비디오의 시간 조각을 입력으로 수용한다. 3개의 네트워크 아키텍처 모두에서, 컨볼루 션 계층을 마지막 완전 연결 계층에 공급하기 전에 컨볼루션 계층에 의해 구성된 특징에 배치 정규화를 적용하 고, 이는 결국 이진 분류를 위해 2개의 출력 뉴런을 공급한다. CNN 아키텍처의 모든 하이퍼파라미터는 2개의 상 이한 기준, 즉, (a) 계산 복잡성(훈련 및 평가 시간)과 (b) 학습 복잡성(과소/과대 맞춤 방지 능력)의 균형을 맞추기 위해 수동으로 선택된다. 3개의 CNN은 모두 게임플레이 장면을 높은 각성 또는 낮은 각성으로 분류하는 데 사용되었다. 앞서 언급된 바와 같이, 이러한 이진 분류 방식은 무한하고 연속적인 추적(각각의 주석 추적의 평균이 상이하기 때문에)에 잘 적 합하며 심층 학습을 위한 충분히 풍부한 데이터세트를 생성할 수 있다. 보고된 모든 실험에서, 까다로운 리브- 원-비디오-아웃 방식이 사용되었다; 이것은 44개의 비디오에서 모델을 훈련하는 데 사용된 데이터 및 훈련에 사 용되지 않은 다른 데이터(즉, 테스트 세트)가 성능을 평가하는 데 사용되었음을 의미한다. 이 절차는 모든 비디 오로부터의 데이터에 대해 CNN의 성능을 테스트할 때까지 45회 반복되었다. 모델의 훈련 동안, 오버피팅을 방지 하기 위해 조기 중단 기준이 사용되었다. 조기 중단을 위해, 44개 비디오의 데이터가 섞였고 훈련 세트(데이터 의 90%)와 오버피팅을 테스트하기 위한 검증 세트(데이터의 10%)로 더 분할되었다. 검증 세트의 손실이 15회의훈련 에포크 동안 개선되지 않으면 조기 중단이 활성화될 수 있다. 보고된 정확도는 테스트 세트의 분류 정확도 로, 45회 실행의 평균이다. 유의성은 이 테스트 정확도의 95% 신뢰 구간에서 유래된다. 기준 정확도가 테스트 세트의 평균 분류 정확도인 반면에, 항상 훈련 세트의 44개 비디오에서 가장 일반적인 부류를 선택한다. 당연히, 기준은 또한 2개의 부류 간의 실측 분포를 나타낸다. 게임플레이 장면의 세그먼트를 분류하는 가장 간단한 방식은 주석 추적의 평균 각성 값에 기초하여, 평균 값 초 과의 모든 주석을 높은 각성 값으로 그리고 평균 값 미만의 모든 주석을 낮은 각성 값으로 처리한다. 이 간단한 분류는 모든 45개의 비디오에서 총 8,093개의 데이터 포인트(즉, 부류에 할당된 8-프레임 세그먼트)를 발생시킨 다. 표 I"}
{"patent_id": "10-2024-7008865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "표 I의 상단 행은 무경험 분류 방법(E = 0)을 사용하는 CNN 모델의 평균 분류 정확도를 보고한다. 모든 모델은 기본 분류기보다 20% 더 높은 정확도를 갖고, 이는 사용된 아키텍처에 관계없이 CNN이 원 게임플레이 비디오를 각성 이진 상태에 매핑하는 능력을 갖고 있다는 것을 암시한다. 가장 잘 수행되는 모델은 데이터의 시간 정보를 암시적으로 활용하는 2DSeqCNN이다. 공간 정보만을 활용하는 2DFrameCNN보다 정확도가 3% 이상 높지만, 3DSeqCNN보다는 약간 나은 수준이다. 시간 정보를 명시적으로 활용하는 3DSeqCNN의 능력은 성능에 상당히 영향 을 미치는 것으로 보이지 않는다. 2DFrameCNN의 성능을 다른 2개의 CNN 모델의 성능과 비교하는 것은 시간 정보 가 학습 프로세스에 기여하더라도, 입력의 지배적인 정보가 시간 구조가 아닌 공간 구조에서 나온다는 것을 나 타낸다. 이것은 입력 비디오 세그먼트의 매우 짧은 지속 시간(267밀리초)에 기인할 수 있거나 게임의 헤드업 디 스플레이에 존재하는 각성의 강력한 예측 변수에 기인할 수 있다. 각성 추적의 평균값을 초과하는 모든 데이터를 높은 값으로 분류하는 것이 큰 데이터 세트를 생성하지만, 데이 터 세트의 다소 임의적인 분할은 기본 실측을 잘못 나타낼 수 있으며 또한 분할 기준 편향을 도입할 수 있다. 특히, 평균 부근의 각성값을 갖는 프레임은 사소한 차이에 기초하여 높음 또는 낮음으로 분류된다. 모호한(즉, 평균 각성값( )에 가까운) 주석을 필터링하기 위해, 불확실성 범위 내에서 각성값(A)이 있는 모든 데이터 포인 트가 다음과 같이 결정된다:"}
{"patent_id": "10-2024-7008865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "표 I은 E의 상이한 문턱값에 대한 상이한 CNN 아키텍처의 성능을 나타낸다. 1개의 부류의 대표가 다른 부류보다 더 자주 발생하므로 데이터포인트를 제거하는 것이 기준값에 상당히 큰 영향을 미친다는 점에 유의해야 한다. 그럼에도 불구하고, 모호한 각성값이 있는 데이터가 제거될 때 모든 아키텍처의 정확도가 증가하며, 특히 E 값 이 더 높은 경우 더욱 그러하다. E = 0.20인 경우에, 모든 3개의 CNN 아키텍처의 정확도는 기준보다 26% 내지 28% 더 높다. 2DFrameCNN은 또한 E = 0.10 및 E = 0.20에 대해 2DSeqCNN에 이어 정확도가 두 번째로 깔끔한 데 이터세트로부터 이득을 얻는다. 3DSeqCNN의 부가적인 훈련 가능 매개변수는 희박한 데이터세트에서 사용할 수 있는 것보다 더 많은 데이터를 필요로 하는 것으로 보인다. 실제로, 총 데이터포인트 수는 E = 0.05의 경우 12%, E = 0.10의 경우 25%, E = 0.20의 경우 44%만큼 감소된다(총 4,534개의 데이터포인트에 대해). 더 명확하 지만 더 콤팩트한 데이터세트를 갖는 것이 덜 복잡한 아키텍처(2DFrameCNN, 2DSeqCNN)가 더 정확한 모델을 도출 하게 할 수 있지만 복잡한 아키텍처(3DSeqCNN)에 도전할 수 있다는 것은 분명하다. 이러한 트레이드-오프는 게 임플레이 주석과 유사한 작업을 진행할 때 흥미로운 문제를 제기한다. 실시예는, 스크린 상의 게임플레이 장면만으로부터-심지어 단일 프레임 스냅샷으로부터- 놀라울 정도로 정확한 플레이어의 각성 모델을 생성하는 것이 가능하다는 것을 나타낸다. 특히 모호한 각성 주석이 있는 데이터를 제 거할 때, 2DFrameCNN 모델은 평균적으로 테스트 정확도가 77%이지만, 98%(E = 0.20에서)의 테스트 정확도에 도달할 수 있다. 그러나, 스크린의 어떤 특징이 프레임이나 비디오를 낮은 각성 부류 또는 높은 각성 부류로 구별 하는지 관찰하는 것이 더 흥미롭다. 이것은 프레임의 어느 부분이 예를 들어, 구배-가중 부류 활성화 매핑을 통 해 모델 예측에 가장 큰 영향을 미치는지 보여줌으로써 달성될 수 있다. 이 방법은 특정한 입력이 주어지면, 컨 볼루션 계층의 노드에 대한 출력 노드의 구배를 계산한다. 입력에 구배를 곱하고, 계층의 모든 노드에 대한 평 균을 내고 결과값을 정규화함으로써, 입력의 각각의 영역이 출력 노드의 값 증가에 얼마나 기여했는지 보여주는 히트맵을 획득할 수 있다. 도 12a는 본 개시내용의 실시형태에 따른 비디오 프레임의 이미지 표현을 나타낸다. 도 12b 및 도 12c는 2DFrameCNN에 기초하여 계산된, 샘플 게임플레이 프레임에 대한 본 개시내용의 실시형태에 따른 낮은 각 성 활성화를 위한 활성화 맵과 높은 각성 활성화를 위한 활성화 맵을 나타낸다. 2DSeqCNN은 정확도 가 더 높지만, 정적 수치에서 시퀀스를 시각적으로 캡처하는 것이 훨씬 어려우므로, 2DFrameCNN의 프레임 전용 정보가 표시된다. 낮은 각성과 높은 각성 예측 변수는 모두 플레이어가 적대적인 장난감을 탐색하고 쏘고 충돌 하는 3D 세계에 오버레이되는 헤드업 디스플레이(heads-up display: HUD)의 양상에 초점을 맞추고 있다는 점에 유의해야 한다. 특히, 스크린의 중앙 상단에 위치한 점수는 높은 각성에 상당히 기여한다. 흥미롭게도, 플레이 어가 점점 더 적대적인 장난감을 죽임에 따라 게임이 진행되는 동안 점수가 계속 증가한다. 게임에서 경과된 시 간-점수 증가 정도에 의한- 각성에 미치는 영향은 주석 자체에 의해 확증될 수 있다: 대부분의 경우, 주석자는 시간 경과에 따라 각성 수준을 감소시키는 것이 아니라 계속 증가시켰다. 효과적으로, 전체 데이터세트의 모든 각성 값 변화 중 807개의 인스턴스가 증가했고 297개의 인스턴스가 감소했다. 따라서, 점수와 남은 시간은 모두 낮은 각성 또는 높은 각성의 단순한 지표가 될 것이다. 흥미롭게도, 플레이어 건강의 HUD 요소는 두 부류로 고 려되지 않았다. 3D 게임 세계의 다른 특징 중, 적대적인 장난감은 낮은 각성 출력으로 캡처되는 반면, 플레이어 옆의 장애물은 높은 각성 출력으로 캡처된다. 도 13a는 본 개시내용의 실시형태에 따른 방법의 흐름도를 나타낸다. 특히, 도 1 및 도 2, 도 3a, 도 3b 및 도 4 내지 도 12와 함께 설명된 임의의 기능 및 특징과 함께 사용하기 위한 방법이 제시된다. 전술한 내용이 주로 사용자 경험, 동기 및 행동을 모델링하고 예측하는 데 중점을 두었지만, 전술한 툴 및 방법론은 마찬가지로 예 를 들어, 시청자 경험을 예측하고/하거나 본 명세서에서 논의되는 PCG 또는 BEA 툴을 포함하지만 이들로 제한되 지 않는 게임 개발 플랫폼과 함께 설명되는 임의의 다른 기능 및 특징을 수행하도록 사용될 수 있다. 단계는 프로세서를 포함하는 시스템을 통해 기계 학습에 기초하여 행동 경험 분석(BEA) 툴을 생성하는 것 을 포함한다. 단계는 시스템을 통해, 게이밍 애플리케이션과 연관된 게임 데이터를 수신하는 것이 포함한 다. 단계는 시스템을 통해, BEA 툴을 게임 데이터에 적용함으로써 예측된 시청자 경험을 생성하는 것을 포함한다. 단계는 시스템을 통해, 예측된 시청자 경험에 기초하여 게이밍 애플리케이션의 적응을 촉진하 는 것을 포함한다. 다양한 실시형태에서, 기계 학습은 이전 게임 플레이와 연관된 복수의 플레이어 설문지에 기초하고 또한 이전 게임 플레이와 연관된 이전 게임 텔레메트리 데이터에 기초하여 훈련된 기계 학습 모델을 포함한다. 게임 데이 터는 복수의 시청자로부터의 채팅 데이터를 포함할 수 있다. 시스템은 게이밍 개발 애플리케이션을 더 포함하는 게임 개발 플랫폼을 통해 구현될 수 있고, 게이밍 애플리케이션의 적응을 촉진하는 것은 게이밍 개발 애플리케 이션을 통한 게이밍 애플리케이션의 적응을 촉진하는 것을 포함한다. 게이밍 애플리케이션은 복수의 임의의 버 전을 포함할 수 있고, 시스템은 게이밍 애플리케이션을 실행하는 게이밍 시스템을 통해 구현되고, 게이밍 애플 리케이션의 적응을 촉진하는 것은 예측된 시청자 경험에 기초하여 복수의 임의의 버전 중 하나를 선택하는 것을 포함한다. 게이밍 애플리케이션의 적응을 촉진하는 것은 플레이어 불일치를 식별하는 것을 포함할 수 있다. 예 측된 시청자 경험은 예측된 시청자 참여의 변화를 나타내는 시간 경과에 따라 수집된 참여 데이터를 포함할 수 있다. 순간 순간의 게임플레이 참여를 신뢰할 수 있게 추정하는 것은 게임 개발에 매우 중요하다. 정확한 참여 프록시 는 게임의 수익 창출 전략을 향상시킬 수 있을 뿐만 아니라 참여 중심 에이전트를 통해 게임을 신속하게 테스트 하는 데에도 사용될 수 있다. 이러한 에이전트는 결국 플레이어 경험을 개선시키고 게임 콘텐츠 생성을 통해 완 전히 새롭고 매력적인 게임플레이 경험의 설계를 이끌 수 있다. 플레이어의 행동을 참여 예측 변수로 보는 대신, 다음의 실시예는 모델링 문제를 재구성하고 시청자의 관점에서 게임플레이 참여를 살펴본다. 이를 위해, 참여는, 예를 들어, 게임을 플레이하는 동안 플레이어의 행동 상태-시청자에게 실시간 스트리밍됨-와 해당 게임 의 관객의 참여 간의 매핑이 있다고 가정하는 게임플레이의 시청자의 적극적인 참여로 규정될 수 있다. 다음의 실시예는 인기 있는 비디오 라이브 스트리밍 서비스(Twitch1)로부터의 데이터를 사용하고 PlayerUnknown's Battlegrounds-PUBG(PUBG Corporation, 2017) 게임으로부터 스트리밍 데이터를 획득한다. 이 예에서 순간 순간 게임플레이 참여 모델을 구성하기 위해, 게임의 중요한 이벤트와 대응하는 채팅 피드의 메시 지 빈도 간의 관계가 조사된다. 특히, 게임의 각각의 중요한 이벤트(예를 들어, 플레이어 사망, 헤드샷, 죽음 등)에서 게임플레이 참여(시청자의 채팅 빈도에 기여된 바와 같음)를 예측할 수 있는 인공 신경망(ANN)이 사용 된다. 파생된 ANN 모델은 게임플레이 이벤트가 시청자 참여의 정확한 예측 변수일 수 있고 게임플레이가 채팅 빈도를 통해 시청자 행동에 기여될 수 있다는 것을 암시하는, 평균적으로 80% 그리고 85%의 정확도에 도달한다. 이러한 ANN 모델은 방식의 확장성과 일반화 가능성을 보여주는 유사한 높은 정확도로 스트리머 내에서 그리고 스트리머에 걸친 참여를 예측할 수 있다. 이 작업의 결과는 스트리밍되는 임의의 주어진 라이브 PUBG 비디오에 대한 지속적인 예측 참여(참여 라인)이다(도 13b를 참조). 도 13b는 본 개시내용의 실시형태에 따른 비디오 프레임의 이미지 도면을 나타낸다. 특히, 스크린의 상단에서, 예측된 시청자 참여의 현재 수준을 나타내는 참여 점수 및 현재 게임 시간의 표시를 포함하는 PUBG 의 게임 플레이의 예시적인 화면 디스플레이가 제공된다. 게임 시간에 따른 예측된 시청자 참여의 추적 이 스크린의 하단의 근처에 제공된다. PUBG는 한 그룹의 플레이어(한 번에 최대 100명)가 넓은 개방형 맵에 떨어져 무기와 아이템을 찾아다니며, 결국 승자만 남을 때까지 서로 전투를 벌이는, 멀티플레이어 온라인 슈터 게임이다. 게임플레이의 역동성은 긴 횡단 시간 및 액션의 급속 버스트에 의한 준비 인터컷을 특징으로 한다. 게임이 진행됨에 따라, 플레이 가능한 영역 이 감소되어, 나머지 플레이어를 함께 더 가까워지게 하여, 전투 가능성을 증가시킨다. 플레이어가 플레이 가능 한 반경의 영역 밖에 있으면, 플레이어는 지속적인 손상을 입는다; 이 영역을 블루 존(Blue Zone)으로 지칭한다. 블루 존으로 둘러싸인 안전지대의 축소는 단계적으로 플레이된다. 각각의 단계에서, 대피 구역이 지 정되며, 그 구역 밖에서 플레이어는 해당 영역에서 대피하라는 경고를 받는다. 이어서 블루 존은 안전지대를 대 피지대의 크기로 점진적으로 축소한다. 게임의 진행 속도는 때때로 무작위 국부화된 영역의 폭격에 의해 중단되 고, 이는 레드 존으로 표시되며 플레이어가 건물 내부에서 대피하거나 해당 영역에서 대피하게 한다. PUBG Corporation은 개발자와 연구원이 게임플레이 텔레메트리의 밀도 있는 데이터세트를 생성할 수 있는, API 및 텔레메트리 서비스를 제공한다. 각각의 세션은 게임플레이 이벤트와 객체(예컨대, 플레이어, 픽업, 차량 및 무기)로 조직화된, 계층 구조에 상세히 기록된다. API를 통해 이용 가능한 40개의 게임플레이 이벤트와 10개의 객체가 있고, 이는 레벨의 모든 플레이어와 일반 게임 상태를 또한 포함한다. 이 실시예가 게임플레이를 방송하 는 스트리머의 콘텐츠에만 초점을 맞추기 때문에, 다른 플레이어와 관련된 데이터(예를 들어, 스트리머를 수반 하지 않은 위치, 액션 및 전투 기간)는 필터링될 수 있다. 이 실시예에서, 40개의 PUBG 게임플레이 특징이 추출되었다. 특징은 건강, 순회, 전투, 아이템 사용 및 일반 게 임 상태인 5개의 주요 범주로 나눠질 수 있다. 건강 범주는 스트리머의 건강 수준과 복수의 부울(boolean) 이벤 트를 포함한다: 치유, 소생, 부활 수용, 파괴된 갑옷이 그로기 상태로 됨, 피해를 입음, 사망. 횡단 범주는 마 지막 이벤트(델타 위치) 이후 이동한 거리와 블루 존 내, 레드 존 내, 수영 시작, 수영 종료, 도약 시작, 차량 탑승, 차량 떠나기 부울 게임 이벤트를 포함한다. 전투 범주는 사격 횟수, 피해 수행 스칼라 값 및 다음의 부울 특징을 포함한다: 공격 중, 무기 발사, 유발 피해, 파괴된 물체, 파괴된 갑옷, 파괴된 바퀴, 파괴된 차량, 적 그로기 생성. 아이템 사용 범주는 아이템 드롭, 아이템 장착, 아이템 장착 해제, 아이템 픽업, 관리 패키지에서 아이템 픽업, 전리품 상자에서 아이템 픽업, 아이템 사용, 아이템 부착, 아이템 분리 부울 이벤트의 추적을 유 지한다. 마지막으로, 일반 게임 상태 범주는 경과된 시간(초), 살아있는 팀 수 및 살아있는 플레이어 수 및 게 임 단계(즉, 블루 또는 레드 존)를 포함한다. 이 실시예에서, 라이브 PUBG 게임플레이 데이터가 Twitch 스트리밍 플랫폼에서 획득되었다. Twitch가 범용 라이 브 스트리밍 플랫폼이지만, 사이트 트래픽의 대부분은 캐주얼 및 경쟁 둘 다인 비디오게임 스트리밍에 의해 생 성된다. e스포츠와 게임 스트리밍이 점점 더 인기를 끌면서, 더 매력적인 스트림 또는 스팀의 일부를 선택하기 위한 필요성이 증가된다. 이것은 빠르게 상승하는 추세가 이전에 성공적인 장르를 뒤집을 수 있고 새로운 소비 자 선호가 회사를 성장시킬 수 있는 비디오게임 스트리밍의 경우 특히 그러하다. Twitch가 스트리머와 시청자를 연결하는 동안, 시청자가 서로 연결되는 플랫폼을 또한 제공한다. 스트리머를 보면서 채팅하는 것은 공유 경험 의 큰 부분을 차지한다. 실제로, Twitch 시청률의 동기에 대한 현대 연구에 따르면 가장 강력한 동기는 사회적 이며 그 다음으로는 정서적 욕구와 긴장 해소 욕구가 뒤따르는 것으로 나타난다. 시청자가 스트림을 시청하고 다른 시청자와 소통함으로써 어느 정도 만족을 얻지만, 플랫폼 사용자에게는 인지적(즉, 학습) 및 개인 통합(즉, 동료의 인정) 요구가 덜 두드러진다.순간 순간 참여는 게임의 2개의 연속적인 이벤트 사이에서 채팅 메시지의 역 빈도로 측정될 수 있다. 이 값은 0 과 1 사이의 범위에서 정규화된 연속 이벤트 간의 채팅 메시지의 수로 계산될 수 있다. 참여 예측은 이진 분류 작업으로 볼 수 있으며, 목표는 \"높음\" 또는 \"낮음\" 참여 라벨을 예측하는 것이다. 특히, 이 예는 선택된 문턱 값(α)보다 각각 더 높고 더 낮은 메시지 빈도를 가진 이벤트에 대한 낮은 참여와 높은 참여를 고려한다. 낮은 빈도를 시청자의 참여도가 높은 순간으로 연관시키는 것이 놀랍게 보일 수 있지만, 비디오를 정성적으로 검사함 으로써 스크린에서 빠른 속도의 작업이 발생할 때(즉, 시청자가 스크린에 좀 더 집중함) 채팅방이 더 조용해지 는 경향이 있고 차분하고 느린 속도의 순간이 있을 때(예를 들어, 지루함의 표현으로) 더 많은 채팅한다는 것이 관찰될 수 있다. 텔레메트리 이벤트를 통해 PUBG 참여를 어느 정도 예측할 수 있는지 테스트하기 위해, 기계 학습을 통해 탐색될 수 있을 만큼 충분히 큰 데이터세트의 인기와 가용성에 기초하여 5명의 스트리머-chocoTaco, Danucd, sprEEEzy, jeemzz 및 hambinooo-로부터 각각 PUBG API 및 Twitch API에서 게임 내 이벤트 및 대응하는 채팅 메시지를 수 집했다. 표 II는 스트리머의 순위 3, 수집된 비디오 및 경기 수, 평균 시청자 수 4, 평균 지속시간, 채팅 메시 지 수, 및 선택한 기간 내에 수집된 이벤트 수를 5명의 스트리머의 각각에 대해 나타낸다. 표준편차는 괄호 안 에 표시된다. 표 II"}
{"patent_id": "10-2024-7008865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "이 통계에 기초하여, 상위 순위의 2명의 스트리머인, chocoTaco와 Danucd가 이들 사이에 비슷한 수를 보유한 다 른 3명의 스트리머에 비해 상당히 더 많은 수의 시청자와 경기당 채팅 메시지를 갖는다는 것에 유의한다. 이 인 기 순위에 대한 흥미로운 예외는 다른 스트리머보다 약 2배 더 오래 플레이하는 것으로 보이는 sprEEEzy의 평균 경기 지속기간이다. 위에서 논의된 바와 같이 입력 특징을 추출 및 전처리하고 메시지 빈도를 이진 라벨로 변환한 후, 총 119,345개 의 라벨이 지정된 이벤트가 획득되었다. 선택한 부류 분할 문턱값(α)과 관계없이, 데이터세트는 2개의 부류 간 에 매우 불균형한 비율을 나타내고, 대부분의 라벨은 높은 참여도로 분류된다. 데이터세트의 균형을 맞추기 위 해, 소수 부류와 다수 부류에 각각 오버샘플링과 언더샘플링을 적용하여, 기준 정확도를 50%로 설정했다. 검증 세트로의 임의의 데이터 유출을 제거하기 위해 훈련 및 검증 세트에 대해 이 프로세스를 개별적으로 따랐다. 이 실시예에 포함된 모든 실험에 대해, 인공 신경망(ANN)이 예측 모델로 적용되었지만, 다른 기계 학습 기법도 마찬가지로 사용될 수 있다. 사용된 ANN은 128개의 노드로 구성된 단일 완전 연결 은닉 계층, 후속하여 드롭아 웃 계층을 특징으로 한다; 네트워크는 높은 참여도 또는 낮은 참여도를 예측하는 출력 노드를 갖는다. 모 든 노드가 ELU 활성화 함수를 사용하고, 학습률이 1e-5이며, ANN은 100개의 시기 동안 훈련된다. 제1 실험 세트 에서, 모델은 5명의 스트리머의 각각에 대해 개별적으로 훈련되고 테스트되었다. 제2 실험 세트에서, 이러한 참 여 모델의 확장성을 모든 스트리머에 걸쳐 테스트했다. 대안적인 방식에서, 모든 스트리머에 걸쳐 상이한 플레 이 스타일을 식별하고 모델링한다. 이 제1 실험 세트에서 데이터 포인트는 1명의 스트리머에서만 수집되었고, 모델은 5-폴드 교차-검증 체계를 사 용하여 검증되었다; 경기는 폴드에 무작위로 분배된다. 어떤 분할 기준이 최상의 성능을 발생시키는지 평가하기 위해, 4개의 상이한 문턱값(α)(0.0, 0.1, 0.2, 0.3)을 평가했다. 이 방식은 모델이 이벤트 빈도의 사소한 차이 에 기초하여 높은 참여도와 낮은 참여도를 분류하는 방법을 학습할 수 있으므로 분할 기준 편향으로 이어질 수 있다. 이 문제를 해결하기 위해, 선택한 문턱값에 가까운 임의의 모호하지 않은 데이터포인트를 필터링하기 위 해 데이터를 분할할 때 불확실성 한계( )가 사용되었다; 특히, α + 또는 - 범위 내에 속하는 생략된 모 든 이벤트. 4개의 α 값 외에도, 실시예는 = 0.02, 0.05, 0.08에 대한 3개의 상이한 값을 탐색한다 -- α 와 의 가능한 모든 가능한 조합을 철저하게 검사하고, 최고 5-폴드 교차 검증 정확도를 갖는 구성을 선택한 다. 표 III은 각각의 스트리머에 대해 선택된 설정을 나타낸다.표 III"}
{"patent_id": "10-2024-7008865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "모든 개별적인 스트리머 참여 모델은 평균적으로 76% 내지 79%에 도달하는 유사한 성과를 달성한다. 특히 Danucd(평균적으로 79.7%; 최상으로 84.3%), sprEEEzy(평균적으로 78.0%; 최상으로 82.4%), 및 hambinooo(평균 적으로 77.8%; 최상으로 80.43%) 스트리머에 대해 최상의 정확도가 관찰되었지만, jeemzz(평균적으로 76.8%; 최 상으로 80.8%)와 chocoTaco(평균적으로 76.0%; 최상으로 83.2%)에서는 약간 더 낮은 값이 획득된다. 이러한 결 과는 이미 이 방법론이 4개의 상이한 스트리머에 걸쳐 스트리머 텔레메트리와 시청자 참여 간의 관계를 매우 높 은 정확도로 캡처할 수 있음을 나타낸다. 이전 실험 세트의 결과는 개별적인 스트리머의 참여를 매우 높은 정확도로 캡처하는 것이 가능하다는 것을 보여 준다. 모델은 보이지 않는 스트리머의 참여값을 캡처하기 위해 더욱 일반화될 수 있다. 모델의 일반성을 테스트 하기 위해, 4명의 스트리머에서 수집된 데이터에 기초하여 모델을 훈련하고 나머지 스트리머에 대해 테스트하는, 리브-원-스트리머-아웃(leave-one-streamer-out) 교차-검증 체계가 사용된다. 이 프로세스는 각각 의 스트리머에 대해 한 번씩 5번 반복된 후, 결과의 평균이 계산된다. 보고된 모든 실험(표 IV)에 대해, 이전에 논의된 바와 같이 그리고 α 및 의 모든 조합에 대한 철저한 검색 에 기초하여 최상의 매개변수 설정이 선택된다. 발견된 최상의 모델(평균적으로 74.7%; 최상으로 78.7%)은 개별 적인 스트리머의 데이터에 대해 테스트한 모델의 정확도에 비해 정확도가 더 낮다. 스트리머 내 모델의 일반성 이 스트리머에 걸친 모델의 일반성보다 달성하기가 훨씬 쉽기 때문에 이는 놀라운 일이 아니다. 표 IV"}
{"patent_id": "10-2024-7008865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "제1의 2번의 실험에서 획득한 결과를 고려하면, 스트리머에 걸친 일반적인 참여 모델이 어느 정도 정확하게 수 행될 수 있다는 것이 분명해진다. 스트리머가 플레이하는 경기에 걸쳐 다양한(일관되지 않은) 행동을 스트리머 가 나타낼 가능성이 있고, 이는 고려하면 참여 모델의 정확성을 개선시킬 수 있다. 특히, 기계 학습이 캡처하여 참여와 연관시킬 수 있는 스트리머에 걸쳐 일반적인 플레이 패턴이 있다고 가정하면- 이러한 패턴은 모델 훈련 에 도움이 되도록 사용될 수 있다. 5명의 스트리머가 상이한 플레이 스타일을 보이는지 조사하기 위해, 수집된 데이터를 클러스터링했다. 먼저 원 데이터는 119,345개의 이벤트에서 324개의 일치 항목으로 집계되었다-부울 이벤트가 합산되었고(예를 들어, 치 유를 통해) 스칼라 값이 평균화되었다(예를 들어, 델타 위치를 통해)- 그리고 각각의 일치 항목에 대해 데이터 가 최소-최대 정규화를 통해 정규화되었다. 데이터에 존재하는 클러스터 수를 결정하기 위해, 2개의 상이한 클 러스터링 알고리즘-k-평균과 계층적 클러스터링-을 사용했고 결과가 일관성을 위해 테스트되었다. 먼저, 1부터 10까지 범위의 k에 대한 정규화된 데이터에 k-평균을 적용했고, 양자화 오류-모든 데이터 포인트에서 대응하는 클러스터 중심까지의 거리의 합-가 계산되었다. 결과는 k가 증가할 때 양자화 오류의 백분율 감소가 2개 및 3개 의 클러스터에서 특히 높으며 각각 53% 및 20% 감소를 보여준다. k 값이 높을수록(>= 4) 차이가 더 많이 억제된 다(1% 내지 10% 사이).적절한 수의 클러스터를 찾는 대안적인 방식은 모든 단일 일치 항목에서 시작하여 계층적 방식으로 데이터를 분 할한 다음 클러스터 수와 이 클러스터를 분리하는 대응하는 제곱 유클리드 거리 간의 관계를 관찰하는 것이다. 계층적 클러스터링의 이 적용에서, 클러스터 내 총 분산을 최소화하기 위해 Ward 거리 메트릭이 사용되었다. 이 방식은 k-평균과 비슷한 결과를 산출한다: 6.6보다 높은 제곱 유클리드 거리 문턱값을 생성하면 3개의 클러스터 가 생성되고, 10.3보다 높은 문턱값은 2개의 클러스터를 생성한다. 이 2개의 비감독 학습 알고리즘을 사용하여 수행된 분석은 가장 적절한 데이터 클러스터 수가 2 내지 3개라는 것을 종합적으로 나타낸다. 2개의 클러스터는 제1 클러스터의 경우 86개의 일치(74,947개의 이벤트), 제2 클러스터의 경우 238개의 일치(44,398개의 이벤트) 로, 데이터를 매우 불균형한 클러스터로 분할한다. 그러나, 3개의 클러스터는 제1, 제2 및 제3 클러스터에 대해 각각 105개(42,878개의 이벤트) 및 64개의 일치(61,609개의 이벤트)라는 더 균일하게 분포된 일치 데이터 분할 을 생성한다. 획득된 일치 분포의 균형의 측정값으로서 정보 엔트로피(E)를 사용하면, 2개의 클러스터 솔루션(E = 0.83)에 비해 3개의 클러스터에서 더 높은 엔트로피(E = 0.94)가 발생한다. 2개의 클러스터로 분할된 일치 항 목의 높은 불균형과 2개의 클러스터링 알고리즘에 의해 획득된 결과의 유사성을 고려하면 이 데이터세트에 3개 의 클러스터가 있음을 나타낸다. 클러스터링된 3개의 플레이어 스타일을 라벨링하기 위해, 게임플레이의 특징이 각각의 클러스터 내에서 어떻게 그룹화되어 있는지의 조사가 수행되었다. 3개의 클러스터에 걸쳐 4개의 대표적인 게임 특징을 고려할 수 있다. 이 4개의 특징은 Delta Location(경기에서 이동한 거리), Kill(경기에서 사망한 상대 수), Take Damage(경기에 서 플레이어가 받는 피해) 및 Time(경기 지속기간(초))이다. 대중적인 게임 문화 용어를 사용하여 제1 클러스터 는 해당 경기에서 스트리머가 특별히 잘 플레이하지 않고, 킬 수가 적고 자주 죽기 때문에 Noob 플레이 스타일 로 라벨링된다. 한편, 경기는 훨씬 더 짧아지며, 이는 스트리머가 경기 시작 몇 분 내에 사망하기 때문일 가능 성이 높다. 플레이 스타일의 제2 클러스터는 Explorer로 라벨링된다: 이 경기에서 스트리머는 -Delta Location 특징이 다른 2개의 클러스터에 비해 더 높기 때문에- 맵을 훨씬 더 많이 탐색하지만 플레이어의 성능은 여전히 Kill 및 Being Killed 특징에 의해 도시된 바와 같이, 평균 수준이다. 마지막으로, 제3 플레이 스타일은 스트리 머가 최선을 다한 경기를 특징으로 하기 때문에 Pro로 라벨링된다: 스트리머는 다른 2개의 클러스터에 비해 더 많은 플레이어를 죽이고, 덜 자주 죽는 경향이 있으며, 상당한 양의 손상를 입지만 스트리머는 더 오래 살아남 고(즉, 더 높은 시간 값) 경기에서 승리할 가능성이 높다. 3개의 플레이 스타일의 분포는 5명의 스트리머 및 상이한 스트리머가 보여주는 플레이 스타일의 변형에 걸쳐 발 견될 수 있다. 이 분포를 적용하면, chocoTaco는 Noob 일치 항목의 대부분을 나타내고 Pro 일치 항목의 백분율 은 더 낮다. 반면에 sprEEEzy는 Explorer 플레이어 유형에 더 가까운 것으로 보인다. Hambinooo, Danucd 및 Jeemzz는 게임플레이에서 3개의 플레이 스타일이 더 균일하게 분포되어 있음을 보여준다. 3개의 상이한 플레이 스타일을 고려하면, 스트리머 대신 별개의 플레이 스타일을 기반으로 순간 순간 참여 모델 을 구축할 수 있다. 각각의 플레이 스타일에 대해 별개의 참여 모델이 훈련된다. α와 의 미리 결정된 값에 대한 철저한 검색이 각각의 플레이 스타일 모델에 사용되었다. 획득한 결과를 비교하기 위해, 리브-원-스트리머 -아웃 교차-검증 체계를 사용하여 모델을 검증한다. 모든 모델이 높은 정확도(평균적으로 75% 초과)로 참여를 예측하지만 Noob 플레이 스타일을 위한 모델은 Explorer(평균적으로 77%, 최상으로 81.4) 및 Pro 플레이 스타일 (평균적으로 75.4%, 최상으로 80.7%)을 위한 모델보다 더 나은 성능(평균적으로 78.8%, 최상으로 84.8%)을 수행 한다. 이러한 예는 복수의 주요 게임플레이 이벤트에만 의존하고 표준 게임 텔레메트리에 기초한 지속적인 방식 으로 시청자 참여 수준을 예측하는 것이 가능할 뿐만 아니라 --높은 수준의 정확도로 예측을 수행할 수 있음을 암시한다. 이 예는 인기 있는 라이브 스트리밍 게임에서 특정한 애플리케이션을 사용하여 게임 참여에 대한 지속적인 순간 순간 예측을 도입함으로써 게임 분석 기술을 개선시킨다. 획득된 참여 모델은 시청자 참여와 플레이어 행동 간 의 특징을 정확하게 학습할 수 있음을 나타내는 스트리머 내에서 그리고 스트리머에 걸쳐서 매우 정확하고 일반 적이다. 도 14는 본 개시내용의 실시형태에 따른 방법의 흐름도를 나타낸다. 특히, 도 1 및 도 2, 도 3a, 도 3b 및 도 4 내지 도 13과 함께 설명된 임의의 기능 및 특징과 함께 사용하기 위한 방법이 제시된다. 전술한 내용이 주로 개 별적인 입력 양상에 기초하여 사용자 경험, 동기 및 행동을 모델링하고 예측하는 데 중점을 두었지만, 사용자 경험을 예측하고/하거나 본 명세서에서 논의된 PCG 또는 BEA 툴을 포함하지만 이들로 제한되지 않는 게임 개발 플랫폼과 함께 설명된 임의의 다른 기능 및 특징을 수행하기 위해 다수의 입력 양상을 사용할 수 있다. 특히, 게임플레이 특징, 게임플레이 스크린 픽셀 및/또는 게임 오디오와 같은 게임 텔레메트리 데이터를 포함하 는 게임 데이터의 조합은 마이크로폰을 통해 생성된 수신된 플레이어의 언어 정보 및/또는, 예를 들어, 비 디오 카메라 또는 다른 센서를 통해 생성된 플레이어의 비언어적 정보와 같은, 예를 들어, 멀티모드 플레이어 데이터를 포함하는, 언어적 또는 비언어적 시청자 정보와 같은 플레이어 데이터와 함께 사용될 수 있다. 멀티모드 플레이어 데이터와 게임 데이터 및/또는 시청자 정보와 행동의 이러한 조합은 플레이어의 경험에 대한 신뢰할 수 있는 범용 예측 변수를 생성하는 데 사용될 수 있다. 특히, 게임 데이터 및/또는 시청자 경험의 조합 에 기초한 예측 모델은 플레이어의 부가적인 언어적 및 비언어적 정보(예를 들어, 음성, 얼굴 표정, 머리 자세 등을 포함함)로 보완될 수 있다. 플레이어에 대한 이러한 부가적인 정보는 AI 모델의 예측 능력을 증가시킬 수 있다. 심층 선호 학습 및 다른 스트림 기반 기계 학습 알고리즘과 결합된 순서형 감성 컴퓨팅으로부터의 방법은 플레이어 동기 부여, 플레이어 참여 및 다른 경험 상태를 더 높은 정확도로 예측하는 방법을 학습할 수 있다. 플레이어의 멀티모드 데이터(예를 들어, 온라인 플랫폼을 통한 콘텐츠 스트리머)를 사용할 수 있게 되면, 이 정 보는 게임플레이 특징 및/또는 게임플레이의 픽셀 및 오디오와 융합되어 훨씬 더 정확한 플레이어 경험 모델을 도출할 수 있다. 단계는 프로세서를 포함하는 시스템을 통해, 기계 학습에 기초하여 행동 경험 분석(BEA) 툴을 생성하는 것을 포함한다. 단계는 시스템을 통해, 게이밍 애플리케이션의 플레이와 연관된 게임 데이터 및 멀티모드 플레이어 데이터를 수신하는 것을 포함한다. 단계는 시스템을 통해, BEA 툴을 게임 데이터 및 멀티모드 플레이어 데이터에 적용함으로써 예측된 사용자 경험을 생성하는 것을 포함한다. 단계는 시스템을 통해, 예측된 사용자 경험에 기초하여 게이밍 애플리케이션의 적응을 촉진하는 것을 포함한다. 다양한 실시형태에서, 기계 학습은 이전 게임 플레이와 연관된 복수의 플레이어 설문지에 기초하고 또한 이전 게임 플레이와 연관된 이전 게임 텔레메트리 데이터에 기초하여 훈련된 기계 학습 모델을 포함한다. 게임 데이 터는 플레이시간 데이터, 완료 데이터 또는 진행 데이터 중 적어도 하나를 포함할 수 있다. 게임 데이터는 다른 게임 데이터에 대한 클러스터링 분석을 통해 생성된 복수의 플레이어 유형 중 하나의 표시를 포함할 수 있다. 시스템은 게이밍 개발 애플리케이션을 더 포함하는 게임 개발 플랫폼을 통해 구현될 수 있고, 게이밍 애플리케 이션의 적응을 촉진하는 것은 게이밍 개발 애플리케이션을 통한 게이밍 애플리케이션의 적응을 촉진하는 것을 포함한다. 게이밍 애플리케이션은 복수의 임의의 버전을 포함할 수 있고, 시스템은 게이밍 애플리케이션을 실행 하는 게이밍 시스템을 통해 구현되고, 게이밍 애플리케이션의 적응을 촉진하는 것은 예측된 사용자 경험에 기초 하여 복수의 임의의 버전 중 하나를 선택하는 것을 포함한다. 게이밍 애플리케이션의 적응을 촉진하는 것은 플 레이어 불일치를 식별하는 것을 포함할 수 있다. 예측된 사용자 경험은 복수의 동기 요인의 각각에 대한 점수를 나타내는 동기 데이터 및/또는 예측된 플레이어 동기의 변화를 나타내는 시간 경과에 따라 수집된 동기 데이터 를 포함할 수 있다. 게임 데이터는 게이밍 봇에 기초하여 생성될 수 있다. 게임 데이터는 게임 비디오와 연관된 픽셀 데이터가 포함할 수 있다. 도 15a는 본 개시내용의 실시형태에 따른 방법의 흐름도를 나타낸다. 특히, 도 1 및 도 2, 도 3a, 도 3b 및 도 4 내지 도 14와 함께 설명된 임의의 기능 및 특징과 함께 사용하기 위한 방법이 제시되고 게다가 게임 플 랫폼 및 메타버스를 위한 자동 QA 봇의 설명이 이어진다. 특히, 방법은 게임 개발 플랫폼과 같은 시스템, 또는 게임 개발 시 품질 보증(QA)을 자동화하고 작동을 테스팅하기 위한, 게이밍 봇과 같은 하나 이상의 게이밍 봇을 구현하기 위한 처리 회로, 메모리 및 네트워크 인터페이스를 가진 다른 시스템과 함께 구현될 수 있다. 단계는 프로세서를 포함하는 시스템을 통해, 품질 보증(QA) 게임 봇을 생성하는 것을 포함한다. 단계 는 시스템을 통해, 게임에 대응하는 게이밍 애플리케이션을 수용하는 것을 포함한다. 단계는 시스 템을 통해, QA 게임 봇에 의한 게임 플레이에 기초하여 게이밍 애플리케이션을 업데이트하여 제1 업데이트된 게 임에 대응하는 제1 업데이트된 게이밍 애플리케이션을 생성하는 것을 포함한다. 단계는 시스템을 통해, 제1 업데이트된 게임의 실제 플레이어에 대응하는 제1 업데이트된 게이밍 애플리 케이션의 게임 텔레메트리 데이터를 수신하는 것을 포함한다. 단계는 시스템을 통해, 실제 플레이어에 대 응하는 제1 업데이트된 게이밍 애플리케이션의 게임 텔레메트리 데이터에 기초하여 QA 게이밍 봇을 업데이트하 여 업데이트된 QA 게이밍 봇을 생성하는 것을 포함한다. 단계는 시스템을 통해, 업데이트된 QA 게임 봇에 의한 제1 업데이트된 게임의 플레이에 기초하여 제1 업데이트된 게이밍 애플리케이션을 업데이트하여 제2 업데 이트된 게임에 대응하는 제2 업데이트된 게이밍 애플리케이션을 생성하는 것을 포함한다. 부가적으로 또는 대안으로, QA 게임 봇은 인공 지능(AI) 모델을 통해 구현된다. 부가적으로 또는 대안으로, QA 게임 봇은 복수의 QA 봇 제어 행동을 갖는다. 부가적으로 또는 대안으로, 복수의 QA 봇 제어 행동은 QA 게임 봇이 플레이어 입력 시스템에 통합되고 게임을 탐색하여 게임이 작동하는 방식에 대한 데이터를 수집하는 탐색 행동을 포함한다. 부가적으로 또는 대안으로, 탐색 행동은 가능한 액션을 새로운 게임 상태에 매핑하는 것을 포함한다. 부가적으로 또는 대안으로, QA 게임 봇에는 탐색할 게임 또는 게임 콘텐츠의 특정한 영역이 할당된다. 부가적으로 또는 대안으로, 탐색 행동은 게임의 버그와 글리치를 검출하는 글리치 파인더(glitch finder)를 포 함한다. 부가적으로 또는 대안으로, 글리치 파인더는 순차적인 이상치 검출을 활용한다. 부가적으로 또는 대안으로, 복수의 QA 봇 제어 행동은 QA 게임 봇이 테스트 사례를 규정하는 시연 데이터에 기 초하여 일련의 액션을 재생하고, QA 게임 봇이 재생이 실패할 때를 인식하는 복제 행동을 포함한다. 부가적으로 또는 대안으로, 복수의 QA 봇 제어 행동은 QA 게임 봇이 실제 플레이어를 모방하도록 훈련되는 모방 행동을 포함한다. 이 시스템과 프로세스는 QA 게임 봇 형태의 AI를 사용하여 테스팅 프로세스를 더욱 자동화함으로써 게임 플랫폼 의 성능을 개선시킨다. 이러한 AI 기법이 게임의 초기 버전에서 버그와 글리치를 찾아낼 수 있을 뿐만 아니라, AI 모델이 실제 게임플레이에 기초하여 훈련되어 플레이어를 모방하고 인간 QA 플레이어보다 더 체계적이고 포 괄적이며 훨씬 더 빠르게 수행할 수 있는 더 정교한 테스팅을 제공할 수 있으므로 게임 플랫폼을 통해 게임 업 데이트를 촉진하여 이러한 문제를 정정하는 데 도움이 될 수 있는 게임에 영향을 미치는 문제를 식별한다. 많은 임의의 기능과 특징을 포함하는 추가의 예는 다음의 추가의 설명과 함께 제시된다. 게임 플랫폼 및 메타버스를 위한 자동 QA 봇 소개 이 설명에서, 제작자의 게임을 플레이하는 인공 지능(AI) 봇을 사용하여 게임 엔진, 플랫폼, 메타버스 및 그에 부착된 저작 툴에 자동화된 품질 보증(QA) 기능을 추가하기 위한 기술 통합 방식의 예를 제공한다. 설명은 다음과 같은 방식으로 구성된다: 최종 구현된 솔루션의 비전을 소개한다. 게임/경험의 일반적인 문제에 대한 개요뿐만 아니라 AI가 이러한 문제를 식별하고 테스트하는 데 어떻게 도 움이 될 수 있는지에 대한 개요를 제공한다. 그런 다음, 게임 플랫폼/메타버스에서 기술이 이러한 문제를 어떻게 해결할 수 있는지를 간략하게 설명한다. 비전 게임 경험 제작자로서 온라인 게임 플랫폼을 위한 게임 및 게임 유사 경험을 생성하고, 게임 플레잉 품질 보증 (QA) 봇(QA 게임 봇, QA 테스팅 봇, 게이밍 봇, 게임 봇, 봇 등으로 또한 불릴 수 있음)을 당신의 게임에 직접 삽입하게 하는 특징에 접근하는 것을 상상한다. 봇은 세계 및 세계의 아이템과 상호 작용하는 방법을 자동으로 알고 있으며 2D 모드이든 세계에 내장되어 있든 상관없이 GUI를 작동하는 방법도 알고 있다. 이들은 하나의 테 스트 모드에서 다른 테스트 모드로 원활하게 원래대로 전이될 수 있다. QA 봇을 추가하는 것은 저작 소프트웨어의 패널을 사용하는 것만큼 간단하다. 짧은 튜토리얼 비디오를 시청한 후, 봇을 게임에 도입하고 테스팅을 시작하는 데는 몇 분 밖에 걸리지 않는다. 간단한 제1 설정에 힘입어, 저작 툴을 통해 게임에 대한 일부 더 많은 정보를 추가하는 데 일부 추가 시간을 투자한다. 하루도 채 지나지 않아, 봇이 대부분의 게임과 상호 작용하게 된다. 이들은 게임과 GUI를 통해 이동하여, 모든 버튼을 누르고, 모든 항 목을 사용하고, 모든 메뉴를 클릭하려고 한다. 스크립트와 레벨 설계 둘 다를 살펴봐야 할 게임 성능과 문제 영 역에 대해 알려주는 인터페이스가 있다: 저작 툴/게임 편집기의 내부에 모두 액세스할 수 있다. QA 봇은 일단 설치한 후에는 가장 똑똑하지는 않지만, 대부분의 게임 상호작용을 다룬다. 게임을 게시하고 플레 이어가 들어오기 시작하면, 봇의 행동이 변화하기 시작한다. 처음에 수행한 설정을 사용하여, 게임 내 플레이어 의 액션이 수집된다. 잠시 후 이러한 행동이 QA 봇의 행동에 반영되는 것을 보기 시작한다. 이것은 사용자의 개 입 없이 자동으로 발생하지만, 플레이어가 취하는 경향이 있는 일련의 액션이 봇에 표시된다는 것을 인식한다.이들은 점점 더 플레이어처럼 행동한다. QA 봇이 실제 플레이어처럼 행동하기 시작하면, 게임 내 일반적인 상호 작용에 대한 보고서를 받기 시작하고 이러한 상호작용이 갑자기 중단되면, 통지를 받게 된다. 이것은 여러분에게 제작자로서 편안함과 자신감을 준다. 여러분은 플레이어가 처음 로그인하는 순간부터 게임에 대해 훌륭한 경험을 하게 될 것이라는 것을 알고 있다. 여러분은 플레이어가 무엇을 하든 관계 없이 게임 엔진/ 플랫폼/메타버스가 지원하는 모든 디바이스에서 게임이 잘 실행될 것임을 알고 있다. 여러분은 기하학적 구조, 아이템, 상호작용 가능 항목, GUI, 상점 및 구매 가능한 항목이 작동한다는 것을 알고 있으며 -무언가 작동이 중지되면, QA 봇이 여러분에게 알려줄 것이다. 동일한 엔진 또는 플랫폼에서 많은 게임에 걸쳐 자동 QA 봇을 전달하는 방법 플랫폼에 걸쳐 자동 QA를 전달하는 데 있어 근본적인 과제는, 제작자가 경험을 상상할 수 있는 거의 무제한의 자유를 가지므로, 모든 설계를 미리 예측하는 것을 불가능하게 하는 것이다. 게다가, 플레이어는 게임이 출시된 후 경험이 무엇인지 재해석할 수 있을 것이고 커뮤니티는 제작자가 상상했던 것과 전적으로 상이한 어떤 것에 관한 것이라고 결정할 수 있다. 이것은 자동화된 QA 솔루션이 알려지지 않은 제작자 의도와 알려지지 않은 플레 이어 의도 둘 다를 처리해야 함을 의미한다. 도 15b는 일반적인 것부터 구체적인 것까지 QA 봇 테스팅 스펙트럼을 나타낸다. 이것에 대한 우리의 솔루션은 스펙트럼에 걸쳐 작동하는 자동 QA 봇을 제공하는 것이다: 일반적인 비게임별 테스팅부터 플레이어를 관찰함으 로써 테스트 행동을 학습하는 게임별 테스팅에 이르기까지. 아래에서, 이 스펙트럼의 상이한 주요 부분을 배치 하고 해당 부분이 지원할 수 있는 테스팅 종류를 설명한다. 자동화된 테스팅 방식 게임 플레잉 봇으로 어떤 종류의 자동화된 테스팅이 가능한가? QA 봇을 사용하여 다음 3개의 범주의 자동화된 테스팅을 수행한다. 테스트 방식은 상이한 사용 사례와 문제 유형을 다룰 수 있고, 이들은 서로 상이한 수준의 데이터를 필요로 하 고 결합되어 서로 지원하여, QA 테스팅 스펙트럼에 걸쳐 봇을 생성할 수 있다."}
{"patent_id": "10-2024-7008865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "제작자를 위한 핵심 가치 제안은 AI에 대한 기존의 지식, QA에 대한 깊은 지식 없이도 사용할 수 있고, 게임/경 험 저작 인터페이스/툴을 통해 로우 코드 또는 이상적으로 노 코드 방식으로 구현할 수 있는 솔루션을 전달하는 것이다. 이것에 대한 핵심이 아래에 설명되는, 확장형 자가-개선 게임 AI 방식을 사용하는 것이라고 믿는다. 게임 글리치 및 버그 제작자를 지원하는 데 중점을 두고, 제작자가 제어하고 해결할 수 있는 문제에 집중한다; 성능과 관련된 문제, 게임 세계의 구성과 관련되는 버그 및 글리치 또는 플레이어 경험에 영향을 주는 게임 논리. 이것은 예시와 함께 아래에 설명되는 광범위한 잠재적인 문제를 포함한다. 버그와 글리치는 일반적으로 다음 범주에 속한다: 예를 들어, 동결/걸림/충돌을 유발하는 성능 문제 특정한 장소 또는 특정한 액션을 수행할 때 게임이 지연되거나, 멈추거나, 충돌하거나 동결된다. 저장 및 로드 문제 플레이어는 접근할 수 있어야 하는 게임 내 새로운 영역을 로드할 수 없다. 진행 상황이 제대로 저장되지 않는다. 게임플레이/레벨 설계 글리치, 예를 들어, 게임 논리 또는 기하학적 구조 기하학적 구조가 부정확하게 구성되는 충돌 오류. 수행할 수 있어야 하는 액션을 수행할 수 없는 플레이어. 플레이어가 접근할 수 있어야 하는 공간, 물체, 게임 상태에 도달할 수 없는 플레이어. 플레이어는 플레이어가 접근할 수 없어야 하는 공간, 물체, 게임 상태에 도달할 수 있다. 게임 내 구매 아이템을 구매할 수 있어야 하는데 아이템을 구매할 수 없는 플레이어. 플레이어에게 필요한 것보다 더 많은 비용이 청구된다. 플레이어가 결제한 아이템을 받지 못하는 플레이어. 아이템 비용이 청구되지 않는 플레이어. 그래픽 문제 자산은 눈에 보이지 않는다. 서로를 통해 클리핑되거나 부자연스러운/불가능한 방식으로 렌더링되는 자산. 질감이 없거나 글리치가 있다. UI 문제 버튼 또는 다른 요소에 접근할 수 없다. 버튼 또는 다른 요소를 클릭할 수 없거나/상호작용에 응답하지 않는다. 텍스트/시각적 내용을 읽을 수 없거나 접근할 수 없다. 그래픽 사용자 인터페이스는 사용하거나 이해하기 어렵다. AI/NPC 행동 문제 AI는 제작자가 의도하지 않은 방식으로 또는 플레이어가 이해할 수 없거나/예상하지 못한 방식으로 이상하게 반응하고 있다. 오디오 문제 오디오가 어떤 면에서 이상하게 들린다. 오디오가 누락된다. 오디오가 재생되지 않거나 잘못된 오디오가 재생된다. 게임 상태 오류 검사 이전에 접속 가능한 게임은 접속할 수 없는 상태이다(물리적 위치와 다른 게임 상태 둘 다) 접속 불가를 검사 일부 게임에 대해 \"게임을 잘하는\" 플레이어(\"바람직한 상태\"를 가진 플레이어)를 생성 GUI 시스템 트리의 모든 상태를 검사. 그래픽 오류 또는 글리치를 검사. 글리치 및 버그 검출의 가치 및 비용 테스팅에 중점을 둘 문제를 결정하기 위해, 플레이어, 제작자 및 게임/메타버스 플랫폼 보유자의 가치와 비용을 살펴본다. 문제 검출 및 해결의 가치를 살펴볼 때, 심각도, 개별적인 경험 내 빈도, 및 게임/경험에 걸친 일반 성을 고려한다. 게임 플랫폼/메타버스 보유자 및 게임 플랫폼 커뮤니티로부터의 통찰력은 가치 평가에 필수적일 것이다. 버그 또는 글리치 유형의 심각도는 경험에 따라 달라질 수 있고, 예를 들어, 경쟁적인 멀티플레이어 경험의 지연은 게임에 지장을 줄 수 있지만 개인 탐색 또는 사교에 중점을 둔 경험에서는 방해가 덜할 수 있다. 테스팅 비용에 대해, 컴퓨팅 비용, 테스팅을 활용할 때 제작자 측의 인건비, 및 문제 검출의 용이성을 고려한다. 알고리즘 접근 방식 위에 나열된 문제 중 다수를 가능한 한 가장 효율적인 방법으로 검사하기 위해, 게임 플랫폼/메타버스의 기본 특성을 활용할 수 있다: 1) 모든 게임이 동일한 엔진과 내부 표현을 공유한다는 사실(가정); 및 2) 플랫폼의 모 든 게임에 대해 플레이어에 걸쳐 데이터가 수집 가능할 것이라는 사실. QA 테스팅이 출시 전에 게임을 처음 설 계할 때 처음에는 간단한 탐색 테스팅을 수행할 수 있을 것이지만, 게임이 출시되면 플레이트레이스에 대한 훈 련을 통해 능력을 크게 증가시킬 수 있을 것이다. QA 봇의 초기 버전은 호기심 기반 탐색과 비감독 학습을 사용하여 가능한 한 많은 상황을 다룬다. 플레이어 데 이터가 수집됨에 따라, 이 봇의 정책은 플레이어 데이터로부터 학습함으로써 더욱 관련성이 높아지고 인간과 유 사해질 것이고, 이는 테스팅 범위를 개선시킨다. 이 봇의 목적을 위해, 2개의 부분으로 구성된 게임의 게임 상태를 확인한다: 몇몇의 GUI 전용 게임을 제외 한 모든 게임에 공통되는 아바타의 위치와 방향; 게임 간에 크게 상이한, 보조 상태, 즉, 다른 모든 것, 예 컨대, 재고 및 상태 효과(예를 들어, 버프, 디버프(debuff), 임시 장식 등). 많은 게임에서 보조 상태는 극도로 고차원적이고, 이는 이 상태 공간을 탐색하는 능력을 엄격히 제한한다. 인코 더-디코더 네트워크(심층 학습 아키텍처의 일종)를 사용하여 상태 공간의 압축된 버전을 학습함으로써 이것을 완화할 것이다. 이 방식으로, 보조 상태를 나타내는 상대적으로 저차원의 벡터를 획득할 수 있다; 플레이어 데 이터가 충분하면, 변형이 가장 많은 상태 변수가 이 상태 표현에서 더 눈에 띄게 표현될 것이고, 이는 테스팅 목적으로 탐색할 관련 상태를 형성할 것임을 의미한다. 위치/방향과 압축된 보조 상태라는 2개의 상태 표현을 고려하면, 인간 플레이어로부터의 플레이트레이스에 대한 오프라인 보강 학습을 사용하여 더 나은 정책을 학습할 수 있다. 게임 플랫폼 경험이 매우 다양하다는 점을 고 려하면, 여기서 한 가지 과제는 에이전트가 학습하여 나아갈 수 있는 바람직한 상태를 식별하는 것이다. Tank Warfare와 같은 보다 더 많은 종래의 게임의 경우, 바람직한 상태는 승리 조건 또는 높은 점수를 가진 상 태로 쉽게 식별할 수 있다. 그러나, Pet Show Dress Up 또는 Adopt Me와 같은 경험의 경우, 종래의 단어 의미에서 승리 조건이 없다. 수집된 플레이 트레이스에 대한 자기주도학습과 클러스터링을 통해 바람직한 상태를 찾아내는 것을 제안한다. 이를 위해, 위치/방향과 압축된 보조 상태를 모두 사용할 것이다. 바람직한 상태는 많은 플레이어가 들어가고 시간을 보낼 것이지만 또한 나갈 수 있는 이러한 상태일 것이다. 바람직한 상태의 상이한 하위세트를 선택함으 로써(무작위로 또는 선택 원리의 변형을 사용하여) 오프라인 RL을 사용하여 다수의 상이한 정책을 훈련할 수 있 다. 그런 다음 이들은 탐색 봇에 통합될 것이다. 부가적으로, 간단한 주석 툴은 또한 게임 설계자가 특정한 관 련 게임 상태를 표시하게 하여, 관련 상태에 대한 봇의 테스팅 범위에 더욱 집중할 수 있다. 궁극적으로, 한 게임에서 훈련된 봇을 다른 관련 게임을 플레이해야 하는 봇의 시작점으로 사용할 수 있을 것이다(예를 들어, Tank Warfare을 플레이할 수 있는 봇은 또 다른 탱크 게임을 위한 우수한 시작이 되어야 한다). 여기서 아이디어는 게임 자체에 대한 자기주도학습 및 클러스터링을 사용하여, 유사한 봇을 필요로 하는 게임을 식별하려고 하는 것이다. 이어서 다른 게임으로 전송된 봇의 성능은 미래에 봇-게임 매칭을 더 개선시키기 위한 훈련 신호의 역할을 할 수 있다. 이렇게 하면, 각각의 게임마다 수집해야 하는 플레이 트레이스의 양을 감소시 킨다. 전체 개념적 파이프라인이 도 15c에 설명된다. 예상치 못한 행동 시퀀스의 식별 일부 버그는 순차적 이상치 검출의 형식을 통해 검출될 수 있을 것이다. 자기주도학습 및 오프라인 보강 학습을 사용하여 플레이어 데이터로부터 훈련된 모델을 사용하여, 에이전트의 그 다음의 단계를 예측할 수 있을 것이다. (특정 액션을 예측하기보다는 주어진 액션 시퀀스의 가능성만 판단해야 하는 경우에 적대 학습 알고리 즘을 사용하도록 선택할 수 있다.) 이러한 예측을 사용하면, 예상치 못한 액션 시퀀스를 쉽게 식별할 수 있다. 예상치 못한 시퀀스는 많은 것을 의미할 수 있고, 많은 경우에, 이것은 단지 개별적인 플레이어의 플레잉 스타 일의 변덕 또는 실수일 수 있다. 그러나 전체적으로 보면, 이들은 의미가 있다. 예를 들어, 모델이 플레이어가 재고를 완료한 후 점프 게이트를 나갈 것이고 많은 비율의 플레이어가 갑자기 이것을 중단한다고 예측하면, 이 것은 게임에서 점프 게이트를 나가는 것을 불가능하게 하는 문제가 발생했음을 의미할 가능성이 높다. 따라서, 예측된 사물의 흐름에서 갑작스러운 혼란을 사용하여 기계적 글리치를 식별할 것이다. 플레이어 데이터에서 기초 모델 학습 심층 학습의 개발 방향은 최근에 \"기초 모델\"이라고 불리는 방향을 향하여 점점 더 나아가고 있다. 이들은 특정 한 목적을 위해 미세 조정되거나 제로샷 학습을 위해 사용될 수 있고, 프롬프트 또는 다른 예에 의해 출력이 제 어되는 사전 훈련된 대규모 모델이다. 이러한 연구 방향은 ImageNet에서 사전 훈련된 넷의 매우 광범위한 사용 에서 볼 수 있지만, 아마도 GPT-2, BERT 및 GPT-3과 같은 대규모 언어 모델에서 무엇보다도 더 그러하다. 이들 은 거의 항상 사전 훈련된 상태로 사용되며, 특히 GPT-3의 경우에, 데이터, 전문 지식 및 수백만 달러를 모두 갖춘 극소수를 제외하고는 누구나 처음부터 훈련하는 것이 불가능하다. 이러한 기초 모델에 대한 제어는 미래에 점점 더 중요해질 것이며, 모델 보유자에게 상당한 경쟁 우위 또는 해자를 나타낼 가능성이 높다. 도 15c는 자동화된 QA 봇을 위한 전체 파이프라인을 나타낸다. 모방 기반 전략으로 탐색 봇을 강화하기 위해 구 상하는 모델 훈련은 기초 모델 생성까지 원활하게 확장될 수 있다. 복수의 게임/경험에 걸쳐 대량의 플레이어 데이터를 학습함으로써, 플레이어 행동에 대한 제1 실제 기초 모델을 생성할 수 있다. 이것은, 예를 들어, 플레 이어 분할, NPC 행동, 경험 예측 및 아마도 아직 예측할 수 없는 많은 다른 적용에 대한, 테스팅을 넘은 광범위 한 애플리케이션을 가질 수 있다. 비트 스트림, 스트림, 신호 시퀀스 등과 같은(또는 그 등가물) 본 명세서에서 사용될 수 있는 바와 같은 용어가 그 내용이 원하는 복수의 유형(예를 들어, 데이터, 비디오, 음성, 텍스트, 그래픽, 오디오 등, 이들 중 임의의 것은 일반적으로 '데이터'로 지칭될 수 있음) 중 임의의 것에 대응하는 디지털 정보를 설명하기 위해 상호교환 적으로 사용되었다는 점에 유의한다. 본 명세서에서 사용될 수 있는 바와 같이, 용어 \"실질적으로\" 및 \"대략\"은 대응하는 용어 및/또는 항목 간의 상 대성에 대한 업계에서 허용되는 허용오차를 제공한다. 일부 산업의 경우, 업계에서 허용되는 허용오차는 1% 미 만이고, 다른 산업의 경우, 업계에서 허용하는 허용오차는 10% 이상이다. 업계에서 허용되는 허용오차의 다른 예는 1% 미만 내지 50% 범위이다. 업계에서 허용되는 허용 오차는 컴포넌트 값, 집적 회로 프로세스 변화, 온도 변화, 상승 및 하강 시간, 열 잡음, 치수, 신호 오류, 드롭된 패킷, 온도, 압력, 재료 구성 및/또는 성능 메트 릭에 대응하지만 이들로 제한되지 않는다. 업계 내에서, 허용되는 허용오차의 허용오차 변동은 백분율 수준보다 크거나 작을 수 있다(예를 들어, +/- 1% 미만의 치수 허용오차). 항목 간의 일부 상대성은 퍼센트 수준 미만의차이에서 몇 퍼센트까지 다양할 수 있다. 항목 간의 다른 상대성은 몇 퍼센트의 차이에서 차이의 크기까지 다양 할 수 있다. 본 명세서에서 또한 사용될 수 있는 바와 같이, 용어(들) \"~로 구성된\", \"~에 작동 가능하게 결합된\", \"~에 결 합된\" 및/또는 \"결합\"은 항목들 사이의 직접적인 결합 및/또는 개재 항목을 통한 항목들 사이의 간접적인 결합 을 포함하고(예를 들어, 항목은 컴포넌트, 요소, 회로 및/또는 모듈을 포함하지만 이들로 제한되지 않음) 여기 서 간접 결합의 예에 대해, 개재 항목이 신호의 정보를 수정하지 않지만 전류 레벨, 전압 레벨 및/또는 전력 레 벨을 조정할 수 있다. 본 명세서에서 더 사용될 수 있는 바와 같이, 추론된 결합(즉, 하나의 요소가 추론에 의 해 또 다른 요소에 결합되는 경우)은 \"~에 결합된\"과 동일한 방식으로 2개의 항목들 사이의 직접 및 간접 결합 을 포함한다. 본 명세서에서 심지어 더 사용될 수 있는 바와 같이, 용어 \"~로 구성된\", \"~에 작동 가능한\", \"~에 결합된\" 또 는 \"~에 작동 가능하게 결합된\"은, 항목이 전력 연결, 입력(들), 출력(들) 등 중 하나 이상을 포함하여, 활성화 될 때, 하나 이상의 대응하는 기능을 수행하고 하나 이상의 다른 항목에 대한 추론된 결합을 더 포함할 수 있다 는 것을 나타낸다. 본 명세서에서 여전히 더 사용될 수 있는 바와 같이, 용어 \"~와 연관된\"은 별개의 항목의 직 접 및/또는 간접 결합 및/또는 하나의 항목이 또 다른 항목 내에 내장되어 있는 것을 포함한다. 본 명세서에서 사용될 수 있는 바와 같이, 용어 \"유리하게 비교하다\"는 2개 이상의 항목, 신호 등 간의 비교가 본 개시내용에 비추어 그리고 예를 들어, 비교되는 신호/항목의 특성에 기초하여 당업자에게 명백할 유리한 관 계를 나타내는 것을 나타낸다. 본 명세서에서 사용될 수 있는 바와 같이, 용어 \"불리하게 비교하다\"는 2개 이상 의 항목, 신호 등 간의 비교가 이러한 유리한 관계를 제공하지 못하고/못하거나 불리한 관계를 제공하는 것을 나타낸다. 이러한 항목/신호가 하나 이상의 숫치값, 하나 이상의 측정값, 하나 이상의 개수 및/또는 비율, 하나 이상의 데이터 유형 및/또는 문턱값과, 서로 그리고/또는 다른 정보의 속성과 비교할 수 있는 속성을 가진 다른 정보에 대응할 수 있으므로 유리한 비교 또는 불리한 비교가 존재하는지 여부를 결정할 수 있다. 이러한 유리한 관계의 예는 다음을 포함할 수 있다: 1개의 항목/신호가 문턱값보다 큼(또는 그 이상), 1개의 항목/신호가 문턱 값보다 작음(또는 그 이하), 1개의 항목/신호가 또 다른 항목/신호보다 큼(또는 그 이상), 1개의 항목/신호가 또 다른 항목/신호보다 작음(또는 그 이하), 1개의 항목/신호가 또 다른 항목/신호와 일치함, 1개의 항목/신호 가 1%, 5%, 10% 또는 일부 다른 마진 등과 같은 미리 규정된 또는 업계에서 허용되는 허용오차 내에서 또 다른 항목/신호와 실질적으로 일치함 등. 게다가, 당업자는 2개의 항목/신호 간의 이러한 비교가 상이한 방식으로 수 행될 수 있다는 것을 인지할 것이다. 예를 들어, 신호 1의 크기가 신호 2보다 큰 관계가 유리한 경우, 신호 1의 크기가 신호 2의 크기보다 클 때 또는 신호 2의 크기가 신호 1의 크기보다 작을 때 유리한 비교가 달성될 수 있 다. 마찬가지로, 당업자는 항목/신호의 역 또는 반대 비교 및/또는 다른 형태의 수학적 또는 논리적 동등성이 마찬가지로 동등한 방식으로 사용될 수 있음을 인식할 것이다. 예를 들어, 신호 X > 5인지 결정하는 비교는 -X < -5인지 결정하는 것과 동일하며, 신호 A가 신호 B와 일치하는지 결정하는 비교는 마찬가지로 -A가 -B와 일치 하는지 또는 (A)가 아닌 것이 (B)가 아닌 것과 일치하지 않는지를 결정함으로써 수행될 수 있다. 본 명세서에서 논의될 수 있는 바와 같이, 특정한 관계가 존재한다는 결정(유리하거나 불리함)은 특정 액션을 자동으로 트리거 링하는 데 활용될 수 있다. 달리 명시적으로 대조적인 것으로 언급되지 않는 한, 특정 조건의 부재는 특정 액션 이 자동으로 트리거링되지 않는다는 것을 의미하는 것으로 간주될 수 있다. 다른 예에서, 특정 관계가 존재한다 는 결정(유리하거나 불리함)은 하나 이상의 액션을 수행할지 여부를 결정하기 위한 기준 또는 고려사항으로 활 용될 수 있다. 이러한 기준 또는 고려사항이 단독으로 고려되거나 하나 이상의 다른 액션을 수행할지 여부를 결 정하기 위해 하나 이상의 다른 기준 또는 고려사항과 결합하여 고려될 수 있다는 것에 유의한다. 하나 이상의 액션을 수행할지 여부를 결정하기 위해 다수의 기준 또는 고려사항이 사용되는 일례에서, 각각의 기준 또는 고 려사항에는 이러한 결정에서 동일한 가중치가 부여된다. 하나 이상의 액션을 수행할지 여부를 결정하기 위해 다 수의 기준 또는 고려사항이 사용되는 또 다른 예에서, 이러한 결정에서 각각의 기준 또는 고려사항에 불평등한 가중치가 부여된다. 본 명세서에서 사용될 수 있는 바와 같이, 하나 이상의 청구범위는 이 일반적인 형태의 특정 형태로, 문구 \"a, b 및 c 중 적어도 하나\" 또는 \"a\", \"b\" 및 \"c\"보다 더 많거나 적은 요소를 가진, \"a, b 또는 c 중 적어도 하 나\"라는 이 일반적인 형태의 문구를 포함할 수 있다. 어느 표현에서든, 해당 문구는 동일하게 해석되어야 한다. 특히, \"a, b 및 c 중 적어도 하나\"는 \"a, b 또는 c 중 적어도 하나\"와 동일하며, a, b 및/또는 c를 의미할 것이다. 예로서, 이것은 \"a\"만, \"b\"만, \"c\"만, \"a\"와 \"b\", \"a\"와 \"c\", \"b\"와 \"c\" 및/또는 \"a\", \"b\" 및 \"c\"를 의미 한다. 본 명세서에서 또한 사용될 수 있는 바와 같이, 용어 \"처리 모듈\", \"처리 회로\", \"프로세서\", \"처리 회로망\" 및 /또는 \"처리 장치\"는 단일 처리 디바이스 또는 복수의 처리 디바이스일 수 있다. 이러한 처리 디바이스는 마이 크로프로세서, 마이크로-컨트롤러, 디지털 신호 프로세서, 마이크로컴퓨터, 중앙 처리 장치, 필드 프로그래밍 가능 게이트 어레이, 프로그래밍 가능 논리 디바이스, 상태 기계, 논리 회로망, 아날로그 회로망, 디지털 회로 망 및/또는 회로망의 하드 코딩 및/또는 작동 명령어에 기초하여 신호(아날로그 및/또는 디지털)를 조작하는 임 의의 디바이스일 수 있다. 처리 모듈, 모듈, 처리 회로, 처리 회로망 및/또는 처리 장치는 단일 메모리 디바이 스, 복수의 메모리 디바이스일 수 있는, 메모리 및/또는 통합 메모리 요소, 및/또는 또 다른 처리 모듈, 모듈, 처리 회로, 처리 회로망 및/또는 처리 장치의 내장된 회로망일 수 있거나 이를 더 포함할 수 있다. 이러한 메모 리 디바이스는 판독 전용 메모리, 랜덤 액세스 메모리, 휘발성 메모리, 비휘발성 메모리, 정적 메모리, 동적 메 모리, 플래시 메모리, 캐시 메모리, 및/또는 디지털 정보를 저장하는 임의의 디바이스일 수 있다. 처리 모듈, 모듈, 처리 회로, 처리 회로망 및/또는 처리 장치가 1개 초과의 처리 디바이스를 포함하는 경우에, 처리 디바이 스는 중앙에 위치될 수 있거나(예를 들어, 유선 및/또는 무선 버스 구조체를 통해 직접적으로 함께 결합됨) 분 산되어 위치될 수도 있다(예를 들어, 근거리 통신망 및/또는 광역 통신망을 통한 간접 결합을 통한 클라우드 컴 퓨팅)는 것에 유의한다. 또한, 처리 모듈, 모듈, 처리 회로, 처리 회로망 및/또는 처리 장치가 상태 기계, 아날 로그 회로망, 디지털 회로망 및/또는 논리 회로망을 통해 하나 이상의 기능을 구현하는 경우에, 대응하는 작동 명령어를 저장하는 메모리 및/또는 메모리 요소는 상태 기계, 아날로그 회로망, 디지털 회로망, 및/또는 논리 회로망을 포함하는 회로망 내부에 내장되거나 외부에 내장될 수 있다는 것에 유의한다. 또한, 메모리 요소가 저 장할 수 있고, 처리 모듈, 모듈, 처리 회로, 처리 회로망 및/또는 처리 장치가 도면 중 하나 이상의 도면에 예 시된 단계 및/또는 기능 중 적어도 일부에 대응하는 하드 코딩된 그리고/또는 작동 명령어를 실행시킨다는 것에 여전히 더 유의한다. 이러한 메모리 디바이스 또는 메모리 요소는 제조품에 포함될 수 있다. 하나 이상의 실시형태는 명시된 기능의 성능과 그 관계를 예시하는 방법 단계의 도움으로 위에서 설명되었다. 이러한 기능적 빌딩 블록과 방법 단계의 경계와 시퀀스는 설명의 편의를 위해 본 명세서에서 임의로 규정되었다. 명시된 기능과 관계가 적절하게 수행되는 한 교번 경계와 시퀀스가 규정될 수 있다. 따라서 임의의 이러한 교번 경계 또는 시퀀스는 청구범위의 범위 및 정신 내에 있다. 또한, 이들 기능적 빌딩 블록의 경계는 설명의 편의를 위해 임의로 규정되었다. 특정 중요한 기능이 적절하게 수행되는 한 교번 경계가 규정될 수 있다. 마찬가지로, 흐름도 블록은 또한 특정한 중요한 기능을 예시하기 위해 본 명세서에서 임의로 규정되었을 수 있다. 사용된 정도까지, 흐름도 블록 경계 및 시퀀스는 다르게 규정되었을 수 있고 여전히 특정 중요한 기능을 수행할 수 있다. 따라서 기능적 빌딩 블록과 흐름도 블록 및 시퀀스 둘 다에 대한 이러한 교번 정의는 청구범위의 범위 및 정신 내에 있다. 당업자는 또한 본 명세서의 기능적 빌딩 블록, 및 다른 예시적인 블록, 모듈 및 컴포넌트가 예시된 바와 같이 또는 개별 컴포넌트, 주문형 집적 회로, 적절한 소프트웨어를 실행하는 프로세서 등 또는 이 들의 임의의 조합에 의해 구현될 수 있다는 것을 인식할 것이다. 또한, 흐름도는 \"시작\" 및/또는 \"계속\" 표시를 포함할 수 있다. \"시작\" 및 \"계속\" 표시는 제시된 단계가 임의로 하나 이상의 다른 루틴에 통합되거나 다르게 함께 사용될 수 있음을 반영한다. 또한, 흐름도는 \"종료\" 및/또는 \"계속\" 표시를 포함할 수 있다. \"종료\" 및/또는 \"계속\" 표시는 제시된 단계가 설명 및 도시된 대로 종료될 수 있거나 임의로 하나 이상의 다른 루틴에 통합되거나 다르게 함께 사용될 수 있음을 반영한다. 이 맥락에서 \"시 작\"은 제시된 제1 단계의 시작을 나타내며 구체적으로 도시되지 않은 다른 활동이 선행될 수 있다. 또한, \"계속\" 표시는 제시된 단계가 여러 번 수행될 수 있고/있거나 구체적으로 도시되지 않은 다른 활동이 후속될 수 있음을 반영한다. 또한, 흐름도가 단계의 특정 순서를 나타내지만, 인과 관계의 원칙이 유지된다면 다른 순서도 마찬가지로 가능하다. 하나 이상의 실시형태는 하나 이상의 양상, 하나 이상의 특징, 하나 이상의 개념 및/또는 하나 이상의 예를 예 시하기 위해 본 명세서에서 사용된다. 장치, 제조 물품, 기계 및/또는 프로세스의 물리적 실시형태는 본 명세서 에 논의된 실시형태 중 하나 이상을 참조하여 설명된 양상, 특징, 개념, 예 등 중 하나 이상을 포함할 수 있다. 또한, 도면별로, 실시형태는 동일하거나 상이한 참조 부호를 사용할 수 있는 동일하거나 유사하게 명명된 기능, 단계, 모듈 등을 포함할 수 있고, 이와 같이, 기능, 단계, 모듈 등은 동일하거나 유사한 기능, 단계, 모듈 등 또는 상이한 것일 수 있다. 반대로 구체적으로 언급하지 않는 한, 본 명세서에 제시된 도면 중 임의의 도면에서 요소로의, 요소로부터의 그 리고/또는 요소 간의 신호는 아날로그 또는 디지털, 연속 시간 또는 이산 시간, 및 단일 종단 또는 차동일 수 있다. 예를 들어, 신호 경로가 단일 종단 경로로 도시되면, 신호 경로는 또한 차동 신호 경로를 나타낸다. 마찬 가지로, 신호 경로가 차동 경로로 도시되면, 신호 경로는 또한 단일 종단 신호 경로를 나타낸다. 하나 이상의특정한 아키텍처가 본 명세서에 설명되어 있지만, 당업자가 인식하는 바와 같이 명시적으로 도시되지 않은 하나 이상의 데이터 버스, 요소들 사이의 직접 연결, 및/또는 다른 요소들 사이의 간접적인 결합을 사용하는 다른 아 키텍처도 마찬가지로 구현될 수 있다. 용어 \"모듈\"은 하나 이상의 실시형태의 설명에서 사용된다. 모듈은 작동 명령어를 저장하는 메모리를 포함하거 나 이와 관련하여 작동할 수 있는 프로세서, 다른 처리 디바이스 또는 다른 하드웨어와 같은 디바이스를 통해 하나 이상의 기능을 구현한다. 모듈은 독립적으로 그리고/또는 소프트웨어 및/또는 펌웨어와 함께 작동할 수 있 다. 또한 본 명세서에 사용된 바와 같이, 모듈은 하나 이상의 서브모듈을 포함할 수 있고, 각각의 서브모듈은 하나 이상의 모듈일 수 있다. 본 명세서에서 더 사용될 수 있는 바와 같이, 컴퓨터 판독 가능 메모리는 하나 이상의 메모리 요소를 포함한다. 메모리 요소는 별개의 메모리 디바이스, 다수의 메모리 디바이스, 또는 메모리 디바이스 내의 메모리 위치의 세 트일 수 있다. 이러한 메모리 디바이스는 판독 전용 메모리, 랜덤 액세스 메모리, 휘발성 메모리, 비휘발성 메 모리, 정적 메모리, 동적 메모리, 플래시 메모리, 캐시 메모리, 양자 레지스터 또는 다른 양자 메모리 및/또는 비일시적 방식으로 데이터를 저장하는 임의의 다른 디바이스일 수 있다. 게다가, 메모리 디바이스는 솔리드 스 테이트 메모리, 하드 드라이브 메모리 또는 다른 디스크 저장소, 클라우드 메모리, 썸 드라이브, 서버 메모리, 컴퓨팅 디바이스 메모리, 및/또는 데이터를 저장하기 위한 다른 비일시적 매체의 형태일 수 있다. 데이터 저장 은 임시 저장(즉, 메모리 요소에서 전력이 제거될 때 데이터가 손실됨) 및/또는 영구 저장(즉, 메모리 요소에서 전력이 제거될 때 데이터가 유지됨)을 포함한다. 본 문서에 사용될 때, 일시적 매체는 다음 중 하나 이상을 의 미할 것이다: (a) 임시 저장 또는 영구 저장을 위해 하나의 컴퓨팅 디바이스에서 또 다른 컴퓨팅 디바이스로 신 호로서 데이터를 전송하기 위한 유선 또는 무선 매체; (b) 임시 저장 또는 영구 저장을 위해 컴퓨팅 디바이스의 하나의 요소에서 컴퓨팅 디바이스의 또 다른 요소로 컴퓨팅 디바이스 내 신호로서 데이터를 전송하기 위한 유선 또는 무선 매체; (c) 다른 컴퓨팅 디바이스에 의한 데이터를 처리하기 위해 하나의 컴퓨팅 디바이스에서 또 다 른 컴퓨팅 디바이스로 신호로서 데이터를 전송하기 위한 유선 또는 무선 매체; 및 (d) 컴퓨팅 디바이스의 다른 요소에 의해 데이터를 처리하기 위해 컴퓨팅 디바이스의 하나의 요소에서 컴퓨팅 디바이스의 또 다른 요소로 컴 퓨팅 디바이스 내 신호로서 데이터를 전송하기 위한 유선 또는 무선 매체. 본 명세서에서 사용될 수 있는 바와 같이, 비일시적 컴퓨터 판독 가능 메모리는 컴퓨터 판독 가능 메모리와 실질적으로 동등하다. 비일시적 컴퓨터 판독 가능 메모리는 또한 비일시적 컴퓨터 판독 가능 저장 매체로서 지칭될 수 있다. 본 명세서에 설명된 방법 및/또는 프로세스와 연관된 하나 이상의 기능은 기계의 비인간 \"인공\" 지능(AI)을 통 해 작동하는 처리 모듈을 통해 구현될 수 있다. 이러한 AI의 예는 이상 검출 기법, 의사결정 트리, 연관 규칙, 전문가 시스템 및 다른 지식 기반 시스템, 컴퓨터 비전 모델, 인공 신경망, 컨볼루션 신경망, 지원 벡터 기계 (SVM), 베이지안 네트워크, 유전 알고리즘, 특징 학습, 희소 사전 학습, 선호도 학습, 심층 학습, 및 비감독, 반감독, 감독 및/또는 보강 학습을 통해 훈련 데이터를 사용하여 훈련되는 다른 기계 학습 기법을 통해 작동하 는 기계 및/또는 다른 AI를 포함한다. 인간의 마음은 이러한 기법의 복잡성뿐만 아니라 인공 지능이 정의에 따 라 \"인공\" 지능 -즉, 기계/비인간 지능-을 필요로 한다는 사실로 인해 이러한 AI 기법을 수행할 준비가 되어 있 지 않다. 본 명세서에 설명된 방법 및/또는 프로세스와 연관된 하나 이상의 기능은 대규모로 데이터를 수신, 전송 및/또 는 처리하도록 작동 가능한 대규모 시스템으로 구현될 수 있다. 본 명세서에 사용된 바와 같이, 대규모는 수신, 전송 및/또는 처리되는 하나 이상의 킬로바이트, 메가바이트, 기가바이트, 테라바이트 또는 그 이상의 데이터와 같은 대량의 데이터를 나타낸다. 이러한 데이터의 수신, 전송 및/또는 처리는, 초, 밀리초, 마이크로초, 실시간 기반 또는 데이터를 생성하고, 데이터를 수신하고, 데이터를 전달하고, 데이터를 저장하고/하거나 데이터를 사 용하는 기계에 의해 요구되는 다른 고속과 같은, 합리적인 기간 내에 인간의 마음에 의해 대규모로 실제로 수행 될 수 없다. 본 명세서에 설명된 방법 및/또는 프로세스와 연관된 하나 이상의 기능은 데이터가 중첩되는 시간 범위 내에서 상이한 방식으로 조작되도록 요구할 수 있다. 인간의 마음은, 초, 밀리초, 마이크로초, 실시간 기반 또는 데이 터를 생성하고, 데이터를 수신하고, 데이터를 전달하고, 데이터를 저장하고/하거나 데이터를 사용하는 기계에 의해 요구되는 다른 고속과 같은, 합리적인 기간 내에 독립적으로, 동시에, 병렬로 그리고/또는 동격 기반으로 이러한 상이한 데이터 조작을 수행하도록 구비되지 않는다. 본 명세서에 설명된 방법 및/또는 프로세스와 연관된 하나 이상의 기능은 유선 또는 무선 통신 네트워크를 통해 디지털 데이터를 전자적으로 수신하고/하거나 유선 또는 무선 통신 네트워크를 통해 디지털 데이터를 전자적으로 전송하도록 작동 가능한 시스템에서 구현될 수 있다. 인간의 마음에는 디지털 데이터를 전자적으로 전송하거 나 수신할 수 있는 능력이 없고, 유선 또는 무선 통신 네트워크를 통해 디지털 데이터를 전송하고 수신할 수 있 는 능력도 갖춰져 있지 않기 때문에 이러한 수신과 전송은 실질적으로 인간의 마음으로는 수행될 수 없다. 본 명세서에 설명된 방법 및/또는 프로세스와 연관된 하나 이상의 기능은 메모리 디바이스에 디지털 데이터를 전자적으로 저장하도록 동작 가능한 시스템에서 구현될 수 있다. 인간의 마음에는 디지털 데이터를 전자적으로 저장할 수 있는 기능이 없기 때문에 이러한 저장은 실제로 인간의 마음에 의해 수행될 수 없다. 본 명세서에 설명된 방법 및/또는 프로세스와 연관된 하나 이상의 기능은 트리거링 이벤트와 액션 간에 인간 상 호작용의 임의의 개입 없이 트리거링 이벤트에 직접 응답하여 처리 모듈에 의해 액션을 유발하도록 작동할 수 있다. 이러한 모든 액션은 이러한 트리거링 이벤트에 \"자동으로\", \"기초하여 자동으로\" 그리고/또는 \"응답하여 자동으로\" 수행되는 것으로 식별될 수 있다. 게다가, 이러한 방식으로 식별된 임의의 이러한 액션은 -트리거링 이벤트 자체가 일종의 인간 활동과 인과적으로 연결될 수 있더라도- 이러한 액션에 대한 인간 활동의 작동을 구 체적으로 배제한다. 하나 이상의 실시형태의 다양한 기능 및 특징의 특정 조합이 본 명세서에 명시적으로 설명되어 있지만, 이러한 특징 및 기능의 다른 조합도 마찬가지로 가능하다. 본 개시내용은 본 명세서에 논의된 특정 실시예에 의해 제한 되지 않으며 이 다른 조합을 명시적으로 포함한다."}
{"patent_id": "10-2024-7008865", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시내용의 실시형태에 따른 게임 개발 시스템의 삽화/블록도. 도 2는 본 개시내용의 실시형태에 따른 게임 개발 플랫폼의 블록도. 도 3a는 본 개시내용의 실시형태에 따른 게임 개발 파이프라인의 흐름/블록도. 도 3b는 본 개시내용의 실시형태에 따른 일반 경험 페르소나(general experience persona)의 컴포넌트의 흐름/ 블록도. 도 4는 본 개시내용의 실시형태에 따른 방법의 흐름도. 도 5는 본 개시내용의 실시형태에 따른 게임 텔레메트리 데이터의 그래픽 도면. 도 6은 본 개시내용의 실시형태에 따른 방법의 흐름도. 도 7은 본 개시내용의 실시형태에 따른 방법의 흐름도. 도 8은 본 개시내용의 실시형태에 따른 방법의 흐름도. 도 9는 본 개시내용의 실시형태에 따른 방법의 흐름도. 도 10은 본 개시내용의 실시형태에 따른 방법의 흐름도. 도 11은 본 개시내용의 실시형태에 따른 CNN 아키텍처의 블록도. 도 12a는 본 개시내용의 실시형태에 따른 비디오 프레임의 이미지 도면. 도 12b 및 도 12c는 본 개시내용의 실시형태에 따른 활성화 맵을 나타내는 도면. 도 13a는 본 개시내용의 실시형태에 따른 방법의 흐름도. 도 13b는 본 개시내용의 실시형태에 따른 비디오 프레임의 이미지 도면. 도 14는 본 개시내용의 실시형태에 따른 방법의 흐름도. 도 15a는 본 개시내용의 실시형태에 따른 방법의 흐름도. 도 15b는 본 개시내용의 실시형태에 따른 QA 봇 테스팅 스펙트럼의 그래픽 도면. 도 15c는 본 개시내용의 실시형태에 따른 자동화된 QA 봇을 위한 전체 파이프라인의 그래픽 도면."}
