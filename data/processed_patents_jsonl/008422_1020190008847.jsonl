{"patent_id": "10-2019-0008847", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0091711", "출원번호": "10-2019-0008847", "발명의 명칭": "ＵＢＴ에 적용할 딥러닝을 사용한 이미지 Auto Tagging 시스템 및 방법", "출원인": "이언주", "발명자": "이언주"}}
{"patent_id": "10-2019-0008847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이미지를 분류하고 분류된 이미지에 태깅될 k개의 tag가 선정되며, 각 사진들에 대하여 이미지들을 분류하는 적어도 하나 이상의 분류기(classifier)를 갖는 멀티 라벨 분류기; 및상기 멀티 라벨 분류기에 의해 분류된 이미지에 대하여 k개의 태그로 태깅하는 이미지 Auto-Tagging 시스템을포함하는, UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 시스템."}
{"patent_id": "10-2019-0008847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 k개의 tag는 3개의 tag를 사용하며, 1번 tag는 '신체부위'로써 10개 클래스를 포함하며, 입, 눈, 귀, 심장, 폐, 근육, 피부, 위장, 혈액세포, 심혈관계로 구성되며, 2번 tag는 '의과대학 과목'으로써 7 클래스를 포함하며, 심장학, 피부과학, 감각기학, 소화기병학, 혈액학, 근골격학, 호흡기학으로 구성되며, 3번 tag는 '사진 종류'로써 3 클래스를 포함하며, CT, X-ray, 실제 사진으로 구성되는 UBT에 적용할 딥러닝을사용한 이미지 Auto-Tagging 시스템."}
{"patent_id": "10-2019-0008847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 멀티 라벨 분류기는 신체부위, 의과대학 과목, 사진 종류에 대하여 각각 태그1 분류기, 태그2 분류기, 태그3 분류기를 사용하여 각각 학습하여 분류하며, 상기 3개의 분류기(classifier)를 입력된 하나의 이미지에 대하여 모두 다 적용하는, UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 시스템."}
{"patent_id": "10-2019-0008847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 멀티 라벨 분류기는 상기 태그1 분류기를 통해 신체부위의 추론이 진행되며, 기계 학습 시에는 의료 이미지들을 입, 눈, 귀의 신체부위에 따라 나눈 뒤, 태그1 분류기(classfier)를 사용하여 학습하며, 이미지를 태그1 분류기가 분류하는 경우어느 신체부위 인지 최종적으로 출력되고, 상기 태그2 분류기를 통해 의과대학 과목의 추론이 진행되며, 기계 학습 시에는 의료이미지들을 피부과학, 감각기학의 의과대학 과목에 따라 나눈 뒤 태그2 분류기(classfier)를 사용하여 학습하며, 이미지를 태그2 분류기가분류하는 경우 어느 과목에 해당하는 이미지인지 최종적으로 출력되며,상기 태그3 분류기를 통해 이미지의 종류에 대한 추론이 진행되며, 기계 학습 시에는 의료이미지들을 CT, X-ray, 실제 사진의 영상종류에 따라 나눈 뒤 태그3 분류기(classfier)를 사용하여 학습하며, 이미지를 태그3 분류기가 분류하는 경우 어떤 종류의 영상인지 최종적으로 출력되며, 3개의 분류기(classifier)에서 추론한 결과들을 합해 이미지의 tag가 결정되며, 입력 이미지에 대해 태그 1 분류기로 분류하고, 태그 2 분류기로 분류하며, 태그 3 분류기로 분류하는 3 과정을 모두 거쳐 신체 부위, 영상종류, 의과대학 과목 3가지에 대한 태그가 출력되는, UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 시스템."}
{"patent_id": "10-2019-0008847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2020-0091711-3-제1항에 있어서, 상기 멀티 라벨 분류기는 각각의 분류기에서 모두 딥러닝의 이미지 분류 모델 인 inception resnet v2를 사용하는, UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 시스템."}
{"patent_id": "10-2019-0008847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 분류기(Classifier)의 정확도 향상을 위해 pretrained 모델의 특정 layer를 다시 학습하는 방법인imagenet dataset으로 학습된 Fine-tuning과 Gradient descent 알고리즘을 최적화하는 방법인 옵티마이저(Optimizer)를 사용하였으며, Fine-tuning 여부에 따른 결과는 크게 차이는 없었지만 학습 속도가 더 빠르다는장점이 있으며, 이미지 Auto-Tagging 시스템의 성능 테스트를 위해 사용한 옵티마이저(optimizer)는 RMSprop, Adadelta 그리고Adam을 사용하였으며, Adagrad optimizer를 개선한 RMSprop와 Adadelta를 사용하였을시 같은 성능을 나타냈고,RMSprop 발전시킨 Adam을 사용하였을 때 가장 좋은 성능을 제공하는, UBT에 적용할 딥러닝을 사용한 이미지Auto-Tagging 시스템."}
{"patent_id": "10-2019-0008847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 분류 및 태깅된 이미지는 유비쿼터스 기반 시험(Ubiquitous Based Test, UBT)에 의료 이미지가 포함된 출제 문항에 사용되는, UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 시스템."}
{"patent_id": "10-2019-0008847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "CT, X-ray, 실제 사진을 수집하여 각 사진들에 대하여 이미지들을 분류하는 적어도 하나 이상의 분류기(classifier)를 갖는 멀티 라벨 분류기로 입력하는 단계; 이미지를 분류하고 분류된 이미지에 태깅될 k개의 tag가 선정되며, 상기 적어도 하나 이상의 분류기(classifier)를 갖는 멀티 라벨 분류기에 의해 각 사진들에 대하여 이미지들을 분류하는 단계; 및상기 멀티 라벨 분류기에 의해 분류된 이미지에 대하여 이미지 Auto-Tagging 시스템에 의해 k개의 태그로 태깅하는 단계; 를 포함하는 UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 방법."}
{"patent_id": "10-2019-0008847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 k개의 tag는 3개의 tag를 사용하며, 1번 tag는 '신체부위'로써 10개 클래스를 포함하며, 입, 눈, 귀, 심장, 폐, 근육, 피부, 위장, 혈액세포, 심혈관계로 구성되며, 2번 tag는 '의과대학 과목'으로써 7 클래스를 포함하며, 심장학, 피부과학, 감각기학, 소화기병학, 혈액학, 근골격학, 호흡기학으로 구성되며, 3번 tag는 '사진 종류'로써 3 클래스를 포함하며, CT, X-ray, 실제 사진으로 구성되는 UBT에 적용할 딥러닝을사용한 이미지 Auto-Tagging 방법."}
{"patent_id": "10-2019-0008847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 상기 멀티 라벨 분류기는 신체부위, 의과대학 과목, 사진 종류에 대하여 각각 태그1 분류기, 태그2 분류기, 태그3 분류기를 각각 학습하여 분류하며, 상기 3개의 분류기(classifier)를 입력된 하나의 이미지에 대하여 모두공개특허 10-2020-0091711-4-다 적용하는, UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 방법."}
{"patent_id": "10-2019-0008847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 멀티 라벨 분류기는, 상기 태그1 분류기를 통해 신체부위의 추론이 진행되며, 기계 학습 시에는 의료 이미지들을 입, 눈, 귀의 신체부위에 따라 나눈 뒤, 태그1 분류기(classfier)를 사용하여 학습하며, 이미지를 태그1분류기가 분류하는 경우 어느 신체부위 인지 최종적으로 출력되는 단계;상기 태그2 분류기를 통해 의과대학 과목의 추론이 진행되며, 기계 학습 시에는 의료이미지들을 피부과학, 감각기학의 의과대학 과목에 따라 나눈 뒤 태그2 분류기(classfier)를 사용하여 학습하며, 이미지를 태그2 분류기가분류하는 경우 어느 과목에 해당하는 이미지인지 최종적으로 출력되는 단계; 상기 태그3 분류기를 통해 이미지의 종류에 대한 추론이 진행되며, 기계 학습 시에는 의료이미지들을 CT, X-ray, 실제 사진의 영상종류에 따라 나눈 뒤 태그3 분류기(classfier)를 사용하여 학습하며, 이미지를 태그3 분류기가 분류하는 경우 어떤 종류의 영상인지 최종적으로 출력되는 단계를 포함하며, 3개의 분류기(classifier)에서 추론한 결과들을 합해 이미지의 tag가 결정되며, 입력 이미지에 대해 태그 1 분류기로 분류하고, 태그 2 분류기로 분류하며, 태그 3 분류기로 분류하는 3 과정을 모두 거쳐 신체 부위, 영상종류, 의과대학 과목 3가지에 대한 태그가 출력되는, UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 방법."}
{"patent_id": "10-2019-0008847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 멀티 라벨 분류기는 각각의 분류기에서 모두 딥러닝의 이미지 분류 모델 인 inception resnet v2를 사용하는, UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 방법."}
{"patent_id": "10-2019-0008847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서, 상기 분류기(Classifier)의 정확도 향상을 위해 pretrained 모델의 특정 layer를 다시 학습하는 방법인imagenet dataset으로 학습된 Fine-tuning과 Gradient descent 알고리즘을 최적화하는 방법인 옵티마이저(Optimizer)를 사용하였으며, Fine-tuning 여부에 따른 결과는 크게 차이는 없었지만 학습 속도가 더 빠르다는장점이 있으며, 이미지 Auto-Tagging 시스템의 성능 테스트를 위해 사용한 옵티마이저(optimizer)는 RMSprop, Adadelta 그리고Adam을 사용하였으며, Adagrad optimizer를 개선한 RMSprop와 Adadelta를 사용하였을시 같은 성능을 나타냈고,RMSprop 발전시킨 Adam을 사용하였을 때 가장 좋은 성능을 제공하는, UBT에 적용할 딥러닝을 사용한 이미지Auto-Tagging 방법."}
{"patent_id": "10-2019-0008847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서, 분류 및 태깅된 이미지는 유비쿼터스 기반 시험(Ubiquitous Based Test, UBT)에 의료 이미지가 포함된 출제 문항에 사용되는, UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 방법."}
{"patent_id": "10-2019-0008847", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 시스템 및 방법이 개시된다. UBT 플랫폼에 업로드되는 멀티 미디어 영상, 이미지 소스를 갖는 입력정보를 기존 출제문항에 포함하여 출제자가 효율적으로 문제를 출제할 수 있도록 지원하기 위해, 연구 개발된 인공지능 모듈의 멀티 러벨 분류기와 Auto-Tagging 시스템이 서버에 설치 운 용되며, 머신 러닝의 지도 학습법(Supervised-Learning)을 사용하여 학습된 하나의 분류기(classifier)와 이미 지에 태깅될 3개의 Tagging field를 선정하고 의학 분야의 사진들에 대하여 이미지들을 분류, 태깅한다."}
{"patent_id": "10-2019-0008847", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 시스템 및 방법에 관한 것으로, 보다 상세하게는 UBT 플랫폼에 업로드되는 멀티미디어 영상, 이미지 소스를 갖는 입력정보를 기존 출제문항에 포함하여 출제자가 효율적으로 문제를 출제할 수 있도록 지원하기 위해, 연구 개발된 인공지능 모듈 인 하나의 멀티 라벨 분류기(multi-label classifier)와 Auto-Tagging 시스템이 서버에 설치 운용되며, 머신 러닝의 지도 학습법 (Supervised-Learning)을 사용하여 학습된 적어도 하나 이상의 분류기(classifier)와 이미지에 태깅될 3개의 Tagging field를 선정하고 의학 분야의 사진들에 대하여 이미지들을 분류, 태깅하는, UBT에 적용할 딥러닝을 사 용한 이미지 Auto-Tagging 시스템 및 방법에 관한 것이다. 본 연구는 과학기술정보통신부 및 정보통신기술진흥센터의 SW 중심대학사업의 연구결과로 수행되었습니다(2016- 0-00019)."}
{"patent_id": "10-2019-0008847", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "유비쿼터스 기반 시험(Ubiquitous Based Test, UBT)는 아이폰, 아이패드 및 기타 첨단 스마트폰 및 유비쿼터스 기기들을 이용하여 시험의 진행, 채점 및 성적관리, 통보 등을 할 수 있는 시험방식이다. 이 과제는 UBT 플랫폼 에 업로드되는 멀티미디어(영상, 이미지) 소스를 입력정보로 인공지능 모듈의 처리를 거쳐, 이를 교수자들이 문 항 개발 과정에서 소스의 선택, 활용의 효율성을 증대시킨다. 2011년부터 보건복지부 산하 대한보건의료인국가시험원은 의사면허 등 24종의 국가 면허 시험을 UBT/SBT 기반으 로 전환하기 위해 연구개발, 시범사업을 실시하였고, 2017년 12월 응급구조사 1급 면허 시험을 세계 최초로 시 행한 바 있다. 새로운 평가환경이 확산됨에 따라 문항을 연구, 개발, 분석하는 방법의 고도화가 요구되고 있고, 이를 위한 교육시장 및 교재산업의 변화가 시작되고 있다. 우리는 UBT 플랫폼에 업로드되는 멀티미디어(영상, 이미지) 소스를 입력정보로 인공지능 모듈의 처리를 거쳐 이를 교수자들이 문항 개발 과정에서 소스의 선택, 활 용의 효율성을 증대시키기 위함이다. 교수자가 직접 문항 개발 시 문항 소속 카테고리(ex 내과[대분류] - 혈액 학[중분류] -세부항목[소분류]) 선택 시 연관 멀티미디어 소스를 추천하는 방식으로 구현을 계획하였다. 이러한 방법으로 UBT를 사용하는 국내 보건의료대학 및 교육기관의 UBT 플랫폼에 저장되어 있는 방대한 데이터를 분석, 활용하여 인공지능 모듈을 연구, 개발, 적용한다면 교육 현장중심의 효과적이고, 유의미한 결과를 도출할 수 있 을 것이다. 최근, 구글사는 딥러닝을 위해 검색, 이미지 인식, 번역 등에 사용되는 기계 학습용 엔진으로 기계학습 라이브 러리를 갖는 TensorFlow을 출시하였으며, 2015년에 공개 소스 소프트웨어로 전환되었다. 멀티미디어(이미지, 영상) 정보 분석 모듈(기계학습 모듈, 분류 및 태깅, 카테고리와 태그 연관성 인식 모듈 포 함)에 의해 1) 소스 업로드 시 정보 분석 후 분류, 태깅하여 해당 문항의 DB 테이블에 저장, 2) 기존 등록된 문 항을 검색하여 멀티미디어 소스가 있는 경우 태깅 정보 생성 및 저장, 3) 태깅 정보는 [태그+정확도{확률}]형태 로 구성되고, 정확도{확률}은 플랫폼 상에서 교수자의 선택(맞음/틀림 또는 추천에서 선택)이 있는 경우 기계학 습 모듈에 학습정보가 제공되고, 이를 반영하여 메인 UBT 클라우드 플랫폼 상 문항정보 시스템을 갱신, 정확도 {확률}가 변경, 4) 새로운 소스 업로드 시 태깅 후 유사/중복 영상, 이미지 확인 기능이 백그라운드에서 동작하 고, 유사도가 90% 이상 인 경우 사용자에게 기존 영상 또는 이미지를 선택하도록 권유하고 사용자가 동의하는 경우 업로드한 신규 소스는 삭제한다. 이와 관련된 선행기술1로써, 특허등록번호 10-13118250000 에서는 \"사진 자동 분류 시스템 및 방법\"이 공개되어 있다. 사진 촬영이 가능한 촬영 단말에서 촬영된 이미지를 유, 무선 네트워크를 통해 사용자가 원하는 장치로 자동 분 류되어 저장할 수 있는 사진 자동 분류 방법은, 수신되는 다수의 촬영 이미지를 촬영 순서에 따라 순차적으로 스캔하여 분류기준용 이미지를 검출하는 1단계; 분류기준용 이미지가 검출되면, 검출된 분류기준용 이미지로부 터 분류기준정보를 추출하는 2단계; 추출된 분류기준정보를 폴더명으로 하는 사진 폴더를 생성하는 3단계; 및 생성된 사진 폴더에 다른 분류기준용 이미지가 검출되기 전까지의 촬영 이미지들을 저장하는 4단계;를 포함한다. 그러나, 기존의 멀티미디어 시스템은 인공지능의 기계학습된 분류기를 사용하여 인공 지능 모듈을 사용하여 의 학 분야의 이미지를 분류, 태깅하는 시스템이 존재하지 않았으며, 빅 데이터의 학습 데이터, 검증 데이터, 테스 트 데이터를 나눠 기계학습이 가능하여 충분한 데이터가 필요하다. 또한, 기계 학습법(machine learning, ML)의 지도 학습법(Supervised-Learning)을 사용하므로 의과대학의 이미지 데이터를 마련할 계획이었으나 여의치 않았 으며, 연구 개발된 인공지능 모듈은 별도의 서버에 설치, 운용하기 위해 머신 러닝의 지도 학습법(Supervised- Learning)을 사용하여 의학 분야의 사진을 사용하여 이미지들을 분류, 태깅하는 시스템이 필요하다. 선행기술문헌특허문헌 (특허문헌 0001) 특허 등록번호 10-13118250000 (등록일자 2015년 10월 07일), \"사진 자동 분류 시스템 및 방 법\", (주)엠팩토리 비특허문헌 (비특허문헌 0001) [1] Jonathan Long, Evan Shelhamer, et al. “Fully Convolutional Networks for Semantic Segmentation”The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015. (비특허문헌 0002) [2] Tianjun Xiao, Yichong Xu, et al. “The Application of Two-Level Attention Models in Deep Convolutional Neural Network for Fine-Grained Image Classification”The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015. (비특허문헌 0003) [3] Yang Zhang, Boqing Gong, et al. “Fast Zero-Shot Image Tagging” arXiv:1605.09759 [cs.CV], 2016. (비특허문헌 0004) [4] Christian Szegedy, Wei Liu, et al. “Going Deeper with Convolutions” arXiv:1409.4842 [cs.CV], 2014. (비특허문헌 0005) [5] Christian Szegedy, Vincent Vanhoucke, et al.“Rethinking the Inception Architecture for Computer Vision” arXiv:1512.00567 [cs.CV], 2015."}
{"patent_id": "10-2019-0008847", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기한 문제점을 해결하기 위한 본 발명의 목적은 UBT 플랫폼에 업로드되는 멀티미디어 영상, 이미지 소스를 갖 는 입력정보를 기존 출제문항에 포함하여 출제자가 효율적으로 문제를 출제하도록 지원하기 위해, 연구 개발된 인공지능 모듈 인 하나의 멀티 라벨 분류기(multi-label classifier)와 Auto-Tagging 시스템이 서버에 설치, 운용되며, 머신 러닝의 지도 학습법(Supervised-Learning)을 사용하여 학습된 적어도 하나 이상의 분류기 (classifier)와 이미지에 태깅될 3개의 Tagging field를 선정하고 의학 분야의 사진들에 대하여 이미지들을 분 류, 태깅하는, UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 시스템을 제공한다. 본 발명의 다른 목적은 UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 방법을 제공한다."}
{"patent_id": "10-2019-0008847", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 목적을 달성하기 위해, UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 시스템은, 이미지를 분류 하고 분류된 이미지에 태깅될 k개의 tag가 선정되며, 각 사진들에 대하여 이미지들을 분류하는 적어도 하나 이 상의 분류기(classifier)를 갖는 멀티 라벨 분류기; 및 상기 멀티 라벨 분류기에 의해 분류된 이미지에 대하여 k개의 태그로 태깅하는 이미지 Auto-Tagging 시스템을 포함한다. 본 발명의 다른 목적을 달성하기 위해, UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 방법은, CT, X-ray, 실제 사진을 수집하여 각 사진들에 대하여 이미지들을 분류하는 적어도 하나 이상의 분류기(classifier)를 갖는 멀티 라벨 분류기로 입력하는 단계; 이미지를 분류하고 분류된 이미지에 태깅될 k개의 tag가 선정되며, 상기 적 어도 하나 이상의 분류기(classifier)를 갖는 멀티 라벨 분류기에 의해 각 사진들에 대하여 이미지들을 분류하 는 단계; 및 상기 멀티 라벨 분류기에 의해 분류된 이미지에 대하여 이미지 Auto-Tagging 시스템에 의해 k개의 태그로 태깅하는 단계를 포함한다."}
{"patent_id": "10-2019-0008847", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 시스템 및 방법은 UBT 플랫폼에 업로드되는 멀티미디어 영상, 이미지 소스를 갖는 입력정보를 기존 출제문항에 포함하여 출제자가 효율적으로 문제를 출제 할 수 있도록 지원하기 위해, 연구 개발된 인공지능 모듈 인 하나의 멀티 라벨 분류기(multi-label classifier)와 Auto-Tagging 시스템이 서버에 설치 운용되며, 머신 러닝의 지도 학습법(Supervised-Learning)을 사용하 여 학습된 적어도 하나 이상의 분류기(classifier)와 이미지에 태깅될 3개의 Tagging field를 선정하고 의학 분 야의 사진들에 대하여 이미지들을 분류, 태깅하는 효과가 있다."}
{"patent_id": "10-2019-0008847", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 바람직한 실시예를 첨부된 도면을 참조하여 발명의 구성 및 동작을 상세하게 설명한다. 1. 필요성 UBT의 새로운 시험평가 환경이 확산되면서 이미지와 영상이 포함된 UBT 출제문항을 연구개발하고, 분석하는 방 법이 고도화된 현황에 대해 주목했다. 기존에는 출제자들이 수작업으로 문제를 분류하고 만들어내 시험 문제를 만드는 데에 많은 비용과 시간이 소모되었다. 이에 지필시험에서 제시할 수 없는 실무적인 문제들을 UBT 시험을 통해 출제가 필요하다고 판단된다. 본 연구는 이미지와 영상이 포함된 UBT에 적용할 이미지 멀티태깅 시스템을 구현하는 것을 목표로 하며, 이를 위해 멀티 라벨 분류기(multi-label classifier)와 Auto-Tagging 시스템이 서버에 설치 운영되며, 딥러닝의 이 미지 분류모델을 사용하여 분류기(classifier)에 의해 이미지를 인식 및 분류하여 자동적으로 태그(tag) 정보들 을 저장하게 한다. 이를 통해 출제자들이 문항 개발 과정에서 소스의 선택, 활용의 효율성을 증대시키는 위함이 다. 2. 이미지 Multi-Tagging 방법 본 연구에서 제안하는 이미지 Multi-Tagging 방법은 일반적으로, multi-label classification의 label 별로 여 러 개의 Single Class Classification 문제로 바꾸는 방법과 1개의 이미지를 여러 부분으로 나눠 각 부분별로 Label을 찾는 방법이 있다. 우리가 사용한 방법은 첫 번째와 유사한 방법이다. 먼저, Tag의 개수를 정해 여러 개의 multi Class Classification으로 나누는 방법을 사용했다. 각 Tagging Field별로 각각의 Classifier을 따 로 학습하고 학습된 Classifier들을 1개의 멀티 라벨 분류기(Multi Label Classifier)에 통합했다. 먼저, 이미지에 tagging될 3개의 Tag field를 선정하고 학습을 위한 이미지 데이터를 수집하였다. 본 발명의 UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 시스템은 지도 학습법(Supervised-Learning)을 사용하여 학습된 적어도 하나 이상의 분류기(classifier)를 구비하며, 이 미지를 분류하고 분류된 이미지에 태깅될 k개의 tag가 선정되며, 각 사진들에 대하여 이미지들을 분류하는 적어 도 하나 이상의 분류기(classifier)를 갖는 멀티 라벨 분류기; 및 상기 멀티 라벨 분류기에 의해 분류된 이미지에 대하여 k개의 태그로 태깅하는 이미지 Auto-Tagging 시스템을 포함한다. 본 발명의 UBT에 적용할 딥러닝을 사용한 이미지 Auto-Tagging 방법은, CT, X-ray, 실제 사진을 수집하여 각 사 진들에 대하여 이미지들을 분류하는 적어도 하나 이상의 분류기(classifier)를 갖는 멀티 라벨 분류기로 입력하 는 단계; 이미지를 분류하고 분류된 이미지에 태깅될 k개의 tag가 선정되며, 상기 적어도 하나 이상의 분류기 (classifier)를 갖는 멀티 라벨 분류기에 의해 각 사진들에 대하여 이미지들을 분류하는 단계; 및 상기 멀티 라벨 분류기에 의해 분류된 이미지에 대하여 이미지 Auto-Tagging 시스템에 의해 k개의 태그로 태깅하는 단계를 포함한다. 3. 시스템 구현 방법 이미지에 tagging될 3개의 tag를 선정하고, 이미지 분류 모델은 inception resnet v2를 사용하였다. Tag 1,2,3 - 1번 tag : 신체부위(10 클래스) 입, 눈, 귀, 심장, 폐, 근육, 피부, 위장, 혈액세포, 심혈관계 - 2번 tag : 의과대학 과목(7 클래스) 심장학, 피부과학, 감각기학, 소화기병학, 혈액학, 근골격학, 호흡기학 - 3번 tag : 사진 종류(3 클래스) CT, X-ray, 실제 사진 1번 태그 값을 중심으로 3번 태그 값의 이미지를 확보(1500여 개의 이미지)하였다. 이를 Train data와 Validation data를 3:1 비율로 나누어 TFRecord로 변환하였다. 사용한 이미지 분류 모델은 inception resnet v2라는 모델이다. Tensorflow Slim에서 제공하는 모델 중 성능이 높아 선택하게 되었다. 분류기(Classifier)의 정확도 향상을 위해 pretrained 모델의 특정 layer를 다시 학습하는 방법인 imagenet dataset으로 학습된 Fine-tuning과 Gradient descent 알고리즘을 최적화하는 방법인 옵티마이저(Optimizer)를 사용하였다. Fine- tuning 여부에 따른 결과는 크게 차이는 없었지만 학습 속도가 빠르다는 장점이 있었다. 본 연구에서는, 이미지 Auto-Tagging 시스템의 성능 테스트를 위해 사용한 옵티마이저(optimizer)는 RMSprop, Adadelta 그리고 Adam를 사용하였다. Adagrad optimizer를 개선한 RMSprop와 Adadelta를 사용하였을시 같은 성 능을 나타냈고 RMSprop 발전시킨 Adam을 사용하였을 때 가장 좋은 성능을 확인할 수 있었다. 도 1은 학습을 위한 이미디 데이터 예시를 보인 사진이다. 도 2는 Fine tuning과 Optimizer별 성능 표(표1)이다. 표 1"}
{"patent_id": "10-2019-0008847", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "RMSProp에서 진화한 것으로 learning rate 뿐만 아니라 loss function 기울기의 방향의 관성을 고려하여 학습하 는 Adam을 사용하였다. layer의 수의 조정에서는 data의 수가 적고 앞선 결과에서 underfitting 되었기 때문에, 모델 하단의 stem layer의 수를 줄이는 방법으로 조정하여 성능을 높였다. 도 5와 도 6은 이미지 분류와 태깅을 위해 태그1 분류기, 태그2 분류기, 태그3 분류기를 각각 학습하여 분류하 는 하나의 멀티 라벨 분류기와, 3개의 분류기를 입력된 하나의 이미지에 대해 각각 모두 다 적용하는 개념을 보 인 그림이다. 분류기(classifier) 사진이 입력되면, 분류기(classifier)는 정해진 태그에 대한 정해진 클래스로 분류한다. '신체부위', '의과대학 과목', '사진 종류'에 대하여 각각 태그1 분류기, 태그2 분류기, 태그3 분류기를 각각 학습하여 분류한다. 하나의 멀티 라벨 분류기(Mult label classifier)는 '신체부위', '의과대학 과목', '사진 종류'에 대하여 각각 태그1 분류기, 태그2 분류기, 태그3 분류기의 3개의 분류기를 입력된 하나의 이미지에 대해 모두 다적용하였다. 각각의 분류기는 모두 딥러닝의 이미지 분류 모델 inception resnet v2을 사용하였다. 태그1 분류기(classifier)를 통해 '신체부위'의 추론이 진행된다. 머신 러닝의 기계 학습 시에는 의료 이미지들 을 입, 눈 귀 등 신체부위에 따라 나눈 뒤, 분류기(classfier)가 학습한다. 이미지를 태그1 분류기(classifie r)가 분류하는 경우 어느 신체부위 인지 최종적으로 출력된다. 태그2 분류기(classifier)를 통해 '의과대학 과목'의 추론이 진행된다. 학습 시에는 의료이미지들을 피부과학, 감각기학 등 의과대학 과목에 따라 나눈 뒤 분류기(classfier)가 학습한다. 이미지를 태그2 분류기(classifie r)가 분류하는 경우 어느 과목에 해당하는 이미지인지 최종적으로 출력된다. 태그3 분류기(classifier)를 통해 사진 이미지의 종류에 대한 추론이 진행된다. 학습 시에는 의료이미지들을 CT, X-ray, 실제 사진 등 영상종류에 따라 나눈 뒤 분류기(classfier)를 사용하여 학습한다. 이미지를 태그3 분 류기(classifier)가 분류하는 경우 어떤 종류의 영상인지 최종적으로 출력된다. 3개의 분류기(classifier)에서 추론한 결과들을 합해 이미지의 tag가 결정된다. 입력 이미지에 대해 태그1 분류 기로 분류하고, 태그2 분류기로 분류하며, 태그3 분류기로 분류하는 3가지 과정을 모두 거쳐 신체 부위, 의대 과목, 영상 종류 3가지에 대한 태그가 출력된다. 사용된 옵티마이저 본 연구는 여러개의 옵티마이저(optimizer)에 대한 실험을 진행하였으나 실제로 사용되는 옵티마이저는 adam 옵 티마이저를 사용하였다. 옵티마이저는 딥러닝 모델 학습시 경사하강법을 통해 손실함수의 최저값을 찾아가는 과 정에 사용된다. * Rmsprop RMSProp은 딥러닝의 대가 제프리 힌톤이 제안한 방법으로서, Adagrad의 단점을 해결하기 위한 방법이다. Adagrad의 식에서 gradient의 제곱값을 더해나가면서 구한 Gt 부분을 합이 아니라 지수평균으로 바꾸어 대체한 방법이다. 이렇게 대체를 할 경우 Adagrad처럼 Gt가 무한정 커지지 않으면서 최근 변화량의 변수 간 상대적인 크기 차이는 유지할 수 있다. 식으로 나타내면 다음과 같다."}
{"patent_id": "10-2019-0008847", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, G는 다차원 벡터로 time step t까지 각 변수가 이동한 의 제곱의 합을 저장한 값이다. θ는 딥러닝 모델의 파라미터, γ는 momentum을 얼마나 줄 것이에 대한 momentum term이다. 는 딥러닝 결과값과 실제 결과값의 차이를 정의하는 손실함수이다. 는 손실 함수의 변화량(기울기)이다. ε은 0으로 나누는 것을 방지하기 위한 값으로 이다. 은 미리 정해진 걸음의 크기 step size이다. 0.01~0.001의 값이다. t는 time step으로 딥러닝 파라미터 업데이트가 일어날 때 마다 1씩 증가한다. - Adagrad 식"}
{"patent_id": "10-2019-0008847", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "* AdaDelta AdaDelta (Adaptive Delta)는 RMSProp과 유사하게 AdaGrad의 단점을 보완하기 위해 제안된 방법이다. AdaDelta 는 RMSProp과 동일하게 G를 구할 때 합을 구하는 대신에 지수평균을 구한다. 다만, 여기에서는 step size를 단 순하게 η으로 사용하는 대신에 step size의 변화값의 제곱을 가지고 지수평균 값을 사용한다."}
{"patent_id": "10-2019-0008847", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "s는 step size 변화값의 제곱이다. * Adam Adam (Adaptive Moment Estimation)은 지금까지 계산해온 기울기의 지수평균과 제곱 값의 지수평균을 저장한다. Adam에서는 m과 v가 처음에 0으로 초기화되어 있기 때문에 학습의 초반부에서는 , 가 0에 가깝게 bias 되 어있을 것이라고 판단하여 이를 unbiased 하게 만들어주는 작업을 거친다. 기울기의 지수평균 와 기울기의 제곱 평균 의 식을 ∑ 형태로 펼친 후 양변에 expectation을 씌워 정리해보면, 다음과 같은 보정을 통해 unbiased 된 expectation을 얻을 수 있다. 는 계산하는 기울기의 지수평균이다. 와 는 바이어스를 보정한 값이다."}
{"patent_id": "10-2019-0008847", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, 는 계산하는 기울기의 지수평균, 는 기울기의 제곱평균이다. 와 는 바이어스를 보정한 값이다. 이 보정된 expectation들을 가지고 다음 식과 같이 과 의 계산을 한다. 보통 β1 는 0.9, β2는 0.999, ε는 정도의 값을 사용한다."}
{"patent_id": "10-2019-0008847", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, β는 moment 추정을 위한 지수 감소율, β1는 를 위한 moment 추정을 위한 지수 감소율, β2는"}
{"patent_id": "10-2019-0008847", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "를 위한 moment 추정을 위한 지수 감소율이다. , 는 각각 타임 스텝에 따른 β1,β2값이다. ε은 0으로 나누는 것을 방지하기 위한 값으로 이다. 도 7은 사용된 딥러닝의 이미지 분류 모델은 inception resnet v2의 동작을 보인 그림이다. 사용된 딥러닝 모델 딥러닝 모델 : inception resnet v2[1] 가장 하단의 stem layer부터 시작해서 inception resnet A,B,C layer가 각각 10번, 20번씩 10번 반복이 된다. 그리고 stem layer와 inception resnet A,B,C layer사이에 reduction layer는 input의 사이즈를 줄이는 역할을 한다. inception resnet v2 사용시에, 빨간색, 주황색, 파란색 배경의 layer들은 각각 inception resnet A,B,C layer 이다. 이미지 가장 오른쪽의 layer부터 가장 왼쪽의 softmax까지 layer들을 통과하면서 학습된 결과에 따라 convolution 연산이 수행된다. convolution 연산의 결과가 각 classifier들이 분류하는 태그 값이 된다. 이미지가 가장 처음 통과하는 layer(stem layer)이며, Input Layer에서는 입력된 이미지를 299 x 299 크기로 변환한다. 입력 이미지는 R,G,B 칼라의 3가지 채널로 이루어져 있다. conv(convolution) 레이어에서는 깊이 32의 3x3 필터를 이용하여 분류를 위한 특징들을 찾는다. V는 valid padding을 의미한다. 레이어의 크기가 필터 크기에 따라 줄어든다. V가 없으면 이미지 크기가 그대로 유지되는 same padding를 의미한다. max pooling 레이어에서는 3x3 크기에 있는 픽셀들 중 최대값을 대표 값으 로 정해 이미지의 크기를 줄인다. 3. 실험 결과 제안된 이미지 Auto-Tagging 시스템의 성능을 분석하기 위해 3개 tag값 각각의 정확도를 평균내서 1개의 이미지 에 대한 정확도로 정의하였다. 예를 들면 tag값 3개중 1개만 맞은 경우 : 33% / 2개의 tag가 맞는 경우 : 66% 성능이 나왔다. Test data로는 1번째 tag값인 신체부위가 10개의 클래스로 수가 가장 많아서 신체부위별로 5장 씩 전체 50장의 이미지를 테스트 데이터로 사용하였다. 도 3은 이미지 인식 정확도 측정 결과(표2)이다. 표 2"}
{"patent_id": "10-2019-0008847", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "10종의 신체 부위에 따른 이미지 인식 정확도 측정 결과, 위와 같은 정확도 평균이 산출되었다. 명확한 이미지 들을 Test data로 선택한 것이 가장 큰 요인이라고 여겨진다. 태그1 분류기(Classifier)의 정확도가 74%로 가장 낮았는데 테스트 데이터에 대해 태그1 분류기(Classifier)가 정확도가 높게 나왔기 때문이라고 보인다. 하지만 CT 사진에서는 정확도가 다소 낮게 나왔다. 도 4는 위, 심장, 폐의 CT(Computed Tomography) 사진이다. 4종의 CT 사진을 서로 비교해보면 거의 차이가 없음을 알 수 있다. 학습 데이터를 살펴본 결과, 복부에 있는 부 위의 CT 사진은 차이를 구별하기 힘든 것들이 많았다. 따라서, CT 사진의 구별에 있어서는 한계가 있다고 판단 된다. 분류 및 태깅된 이미지는 의료 분야, 유비쿼터스 기반 시험(Ubiquitous Based Test, UBT)에 의료 이미지가 포함 된 출제 문항에 이미지 멀티 태깅 시스템이 사용될 수 있다. 4. 결론 본 연구는 딥러닝을 사용하여 UBT 시험 문항 개발에 도움을 줄 수 있는 의료 이미지에 대하여 멀티 라벨 분류기 (multi-label classifier)를 사용하여 이미지를 분류, 태깅하는 이미지 Auto-Tagging 시스템을 개발하였다. 이를 위해 신경망 모델을 사용하여 이미지를 학습하여 인식하고 분류하며. 자동적으로 태그 정보를 저장하게 하였 다. 그리고, 저장된 정보들을 쉽게 검색하여 유사시에 빠르게 활용할 수 있도록 하였다. 향후 UBT 플랫폼에 저 장되어 있는 시험 문항 분석을 통해 문제 추천 시 변별력이 높은 문제를 추천하는 방식으로 활용될 수 있을 것으로 예상한다. 이상에서 설명한 바와 같이, 본 발명의 방법은 프로그램으로 구현되어 컴퓨터의 소프트웨어를 이용하여 읽을 수 있는 형태로 기록매체(CD-ROM, RAM, ROM, 메모리 카드, 하드 디스크, 광자기 디스크, 스토리지 디바이스 등)에 저장될 수 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행 하도록 구성된 모든 형태의 하드웨어 장치가 포함될 수 있다. 프로그램 명령의 예에는 컴파일러에 의해 만들어 지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해 실행될 수 있는 고급 언어 코 드를 포함할 수 있다. 이러한 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로 서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야에서 통상의 지식을 가진자가 하기의 특허 청구범위에 기재된 본 발명의 기술적 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수 정 또는 변형하여 실시할 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2019-0008847", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 학습을 위한 이미디 데이터 예시를 보인 사진이다. 도 2는 Fine tuning과 Optimizer별 성능 표이다. 도 3은 이미지 인식 정확도 측정 결과이다. 도 4는 위, 심장, 폐의 CT(Computed Tomography) 사진이다. 도 5와 도 6은 이미지 분류와 태깅을 위해 태그1 분류기, 태그2 분류기, 태그3 분류기를 각각 학습하여 분류하 는 하나의 멀티 라벨 분류기와, 3개의 분류기를 입력된 하나의 이미지에 대해 각각 모두 다 적용하는 개념을 보 인 그림이다. 도 7은 사용된 딥러닝의 이미지 분류 모델은 inception resnet v2의 동작을 보인 그림이다."}
