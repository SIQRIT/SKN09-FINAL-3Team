{"patent_id": "10-2022-0180171", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0005079", "출원번호": "10-2022-0180171", "발명의 명칭": "데이터 인터랙션 방법과 장치, 전자 기기, 저장 매체 및 컴퓨터 프로그램", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "장, 얀롱"}}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "응답 데이터에 응답하여, 응답 데이터에 대응하는 음소 데이터를 결정하는 것;상기 음소 데이터에 일일이 대응하는 목표 입술 모양 이미지 프레임을 결정하는 것;상기 목표 입술 모양 이미지 프레임을 각각 기초 비디오 프레임과 융합하여 목표 비디오 프레임을 얻는 것; 및상기 목표 비디오 프레임을 렌더링하여 목표 표시 데이터를 얻는 것을 포함하는 데이터 인터랙션 방법."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항1에 있어서,상기 응답 데이터는 응답 음성 데이터를 포함하며, 상기 응답 데이터에 응답하여, 응답 데이터에 대응하는 음소데이터를 결정하는 것은,상기 응답 음성 데이터에 따라, 각각이 분할 주파수에 따라 상기 응답 음성 데이터를 분할하여 얻은 음성 프레임을 복수 포함하는 음성 프레임의 음성 특징 벡터를 결정하는 것;상기 음성 특징 벡터를 은닉 마코프 모델에 입력하여 각 상기 음성 프레임의 상태 데이터를 결정하는 것; 및상기 음성 프레임의 상태 데이터에 따라 음소 데이터를 결정하는 것을 포함하는 데이터 인터랙션 방법."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항1에 있어서,상기 음소 데이터에 일일이 대응하는 목표 입술 모양 이미지 프레임을 결정하는 것은,상기 음소 데이터에 대응하는 입술 모양 키 포인트 데이터를 결정하는 것; 및상기 입술 모양 키 포인트 데이터에 따라 입술 모양 이미지 프레임 집합에서 상기 입술 모양 키 포인트 데이터와 매칭되는 상기 목표 입술 모양 이미지 프레임을 결정하는 것을 포함하는 데이터 인터랙션 방법."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항1 내지 청구항3 중의 어느 하나에 있어서,상기 목표 입술 모양 이미지 프레임을 각각 기초 비디오 프레임과 융합하여 목표 비디오 프레임을 얻는 것은,상기 목표 입술 모양 이미지 프레임에 따라 입술 모양 마스크를 결정하는 것;상기 입술 모양 마스크와 상기 기초 비디오 프레임에 따라 융합 경로를 결정하는 것; 및상기 융합 경로에 따라 상기 입술 모양 마스크와 상기 기초 비디오 프레임을 융합하여 상기 목표 비디오 프레임을 얻는 것을 포함하는 데이터 인터랙션 방법."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항1 내지 청구항3 중의 어느 하나에 있어서,상기 목표 비디오 프레임을 렌더링하여 목표 표시 데이터를 얻는 것은,상기 목표 비디오 프레임의 정점 데이터에 따라 스크린 좌표계에 기반한 정점 좌표 데이터를 결정하는 것;상기 정점 좌표 데이터에 따라 프리미티브 데이터를 결정하는 것;상기 프리미티브 데이터를 유닛화 처리하여 목표 그래픽 데이터를 생성하는 것;공개특허 10-2023-0005079-3-상기 목표 그래픽 데이터를 픽셀 변환 처리하여 상기 목표 그래픽 데이터의 픽셀 데이터를 얻는 것; 및상기 픽셀 데이터에 따라 각 픽셀 포인트의 컬러 데이터를 결정하고 상기 목표 표시 데이터를 얻는 것을 포함하는 데이터 인터랙션 방법."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항2에 있어서,상기 응답 음성 데이터는 대응하는 응답 텍스트 데이터에서 얻고, 상기 응답 텍스트 데이터는 대응하는 입력 텍스트 데이터에서 얻고, 상기 입력 텍스트 데이터는 대응하는 입력 음성 데이터에서 얻는 데이터 인터랙션 방법."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항2에 있어서,상기 표시 데이터와 동기화하여 상기 응답 음성 데이터를 재생하는 것을 더 포함하는 데이터 인터랙션 방법."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "응답 데이터에 응답하여 상기 응답 데이터에 대응하는 음소 데이터를 결정하기 위한 음소 데이터 결정 모듈;상기 음소 데이터에 일일이 대응하는 목표 입술 모양 이미지 프레임을 결정하기 위한 목표 입술 모양 이미지 프레임 결정 모듈;상기 목표 입술 모양 이미지 프레임을 각각 기초 비디오 프레임과 융합하여 목표 비디오 프레임을 얻기 위한 융합 모듈; 및상기 목표 비디오 프레임을 렌더링하여 목표 표시 데이터를 얻기 위한 렌더링 모듈을 포함하는 데이터 인터랙션장치."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항8에 있어서,상기 응답 데이터는 응답 음성 데이터를 포함하며, 상기 음소 데이터 결정 모듈은,상기 응답 음성 데이터에 따라, 각각이 분할 주파수에 따라 응답 음성 데이터를 분할하여 얻은 음성 프레임을복수 포함하는 음성 프레임의 음성 특징 벡터를 결정하기 위한 음성 특징 벡터 결정 서브 모듈;상기 음성 특징 벡터를 은닉 마코프 모델에 입력하여 각 상기 음성 프레임의 상태 데이터를 결정하기 위한 상태데이터 결정 서브 모듈; 및상기 음성 프레임의 상태 데이터에 따라 음소 데이터를 결정하기 위한 음소 데이터 결정 서브 모듈을 포함하는데이터 인터랙션 장치."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항8에 있어서,목표 입술 모양 이미지 프레임 결정 모듈은,상기 음소 데이터에 대응하는 입술 모양 키 포인트 데이터를 결정하기 위한 입술 모양 키 포인트 결정 서브 모듈; 및상기 입술 모양 키 포인트 데이터에 따라 입술 모양 이미지 프레임 집합에서 상기 입술 모양 키 포인트 데이터와 매칭되는 상기 목표 입술 모양 이미지 프레임을 결정하기 위한 목표 입술 모양 이미지 프레임 결정 서브 모듈을 포함하는 데이터 인터랙션 장치."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항8 내지 청구항10 중의 어느 하나에 있어서,상기 융합 모듈은,공개특허 10-2023-0005079-4-상기 목표 입술 모양 이미지 프레임에 따라 입술 모양 마스크를 결정하기 위한 입술 모양 마스크 결정 서브 모듈;상기 입술 모양 마스크와 상기 기초 비디오 프레임에 따라 융합 경로를 결정하기 위한 융합 경로 결정 서브 모듈; 및상기 융합 경로에 따라 상기 입술 모양 마스크와 상기 기초 비디오 프레임을 융합하여 상기 목표 비디오 프레임을 얻기 위한 융합 서브 모듈을 포함하는 데이터 인터랙션 장치."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항8 내지 청구항10 중의 어느 하나에 있어서,상기 렌더링 모듈은,상기 목표 비디오 프레임의 정점 데이터에 따라 스크린 좌표계에 기반한 정점 좌표 데이터를 결정하기 위한 정점 좌표 데이터 결정 서브 모듈;상기 정점 좌표 데이터에 따라 프리미티브 데이터를 결정하기 위한 프리미티브 데이터 결정 서브 모듈;상기 프리미티브 데이터를 유닛화 처리하여 목표 그래픽 데이터를 생성하기 위한 목표 이미지 데이터 결정 서브모듈;상기 목표 그래픽 데이터를 픽셀 변환 처리하여 상기 목표 그래픽 데이터의 픽셀 데이터를 얻기 위한 픽셀 데이터 결정 서브 모듈; 및상기 픽셀 데이터에 따라 각 픽셀 포인트의 컬러 데이터를 결정하고 상기 목표 표시 데이터를 얻기 위한 목표표시 데이터 결정 서브 모듈을 포함하는 데이터 인터랙션 장치."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항9에 있어서,상기 응답 음성 데이터는 대응하는 응답 텍스트 데이터에서 얻고, 상기 응답 텍스트 데이터는 대응하는 입력 텍스트 데이터에서 얻고, 상기 입력 텍스트 데이터는 대응하는 입력 음성 데이터에서 얻는 데이터 인터랙션 장치."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항9에 있어서,상기 목표 표시 데이터와 동기화하여 상기 응답 음성 데이터를 재생하기 위한 응답 음성 데이터 재생 모듈을 더포함하는 데이터 인터랙션 장치."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서와 통신 연결된 메모리를 포함하며, 여기서,상기 메모리에는 적어도 하나의 프로세서에 의해 실행 가능한 명령어가 저장되어 있고, 상기 명령어는 적어도하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서로 하여금 청구항1 내지 청구항3 및 청구항6 내지 청구항7 중 어느 한 항의 상기 데이터 인터랙션 방법을 실행할 수 있게 하는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "컴퓨터로 하여금 청구항1 내지 청구항3 및 청구항6 내지 청구항7 중 어느 한 항의 데이터 인터랙션 방법을 실행하게 하기 위한 컴퓨터 명령어가 저장되어 있는 비휘발성 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2022-0180171", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "저장 매체에 저장되어 있으며, 프로세서에 의해 실행될 시에 청구항1 내지 청구항3 및 청구항6 내지 청구항7 중어느 한 항의 데이터 인터랙션 방법을 구현하는 컴퓨터 프로그램.공개특허 10-2023-0005079-5-"}
{"patent_id": "10-2022-0180171", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 데이터 인터랙션 방법과 장치, 전자 기기, 저장 매체 및 컴퓨터 프로그램을 제공하며, 인공 지능"}
{"patent_id": "10-2022-0180171", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": ", 특히 안면 인식 등 장면에 적용될 수 있는 딥러닝, 이미지 처리, 컴퓨터 비전 기술 분야에 관한 것이다. 구체적인 구현 방법은, 응답 데이터에 응답하여, 응답 데이터에 대응하는 음소 데이터를 결정하는 것; 음소 데이 터에 일일이 대응하는 목표 입술 모양 이미지 프레임을 결정하는 것; 목표 입술 모양 이미지 프레임을 각각 기초 비디오 프레임과 융합하여 목표 비디오 프레임을 얻는 것; 및 목표 비디오 프레임을 렌더링하여 목표 표시 데이 터를 얻는 것이다. 대 표 도 - 도2"}
{"patent_id": "10-2022-0180171", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2023-0005079 CPC특허분류 G06T 13/40 (2013.01) G10L 13/08 (2013.01) G10L 15/02 (2013.01) G10L 15/26 (2013.01) H04N 21/44 (2013.01)명 세 서 청구범위 청구항 1 응답 데이터에 응답하여, 응답 데이터에 대응하는 음소 데이터를 결정하는 것; 상기 음소 데이터에 일일이 대응하는 목표 입술 모양 이미지 프레임을 결정하는 것; 상기 목표 입술 모양 이미지 프레임을 각각 기초 비디오 프레임과 융합하여 목표 비디오 프레임을 얻는 것; 및 상기 목표 비디오 프레임을 렌더링하여 목표 표시 데이터를 얻는 것을 포함하는 데이터 인터랙션 방법. 청구항 2 청구항1에 있어서, 상기 응답 데이터는 응답 음성 데이터를 포함하며, 상기 응답 데이터에 응답하여, 응답 데이터에 대응하는 음소 데이터를 결정하는 것은, 상기 응답 음성 데이터에 따라, 각각이 분할 주파수에 따라 상기 응답 음성 데이터를 분할하여 얻은 음성 프레 임을 복수 포함하는 음성 프레임의 음성 특징 벡터를 결정하는 것; 상기 음성 특징 벡터를 은닉 마코프 모델에 입력하여 각 상기 음성 프레임의 상태 데이터를 결정하는 것; 및 상기 음성 프레임의 상태 데이터에 따라 음소 데이터를 결정하는 것을 포함하는 데이터 인터랙션 방법. 청구항 3 청구항1에 있어서, 상기 음소 데이터에 일일이 대응하는 목표 입술 모양 이미지 프레임을 결정하는 것은, 상기 음소 데이터에 대응하는 입술 모양 키 포인트 데이터를 결정하는 것; 및 상기 입술 모양 키 포인트 데이터에 따라 입술 모양 이미지 프레임 집합에서 상기 입술 모양 키 포인트 데이터 와 매칭되는 상기 목표 입술 모양 이미지 프레임을 결정하는 것을 포함하는 데이터 인터랙션 방법. 청구항 4 청구항1 내지 청구항3 중의 어느 하나에 있어서, 상기 목표 입술 모양 이미지 프레임을 각각 기초 비디오 프레임과 융합하여 목표 비디오 프레임을 얻는 것은, 상기 목표 입술 모양 이미지 프레임에 따라 입술 모양 마스크를 결정하는 것; 상기 입술 모양 마스크와 상기 기초 비디오 프레임에 따라 융합 경로를 결정하는 것; 및 상기 융합 경로에 따라 상기 입술 모양 마스크와 상기 기초 비디오 프레임을 융합하여 상기 목표 비디오 프레임 을 얻는 것을 포함하는 데이터 인터랙션 방법. 청구항 5 청구항1 내지 청구항3 중의 어느 하나에 있어서, 상기 목표 비디오 프레임을 렌더링하여 목표 표시 데이터를 얻는 것은, 상기 목표 비디오 프레임의 정점 데이터에 따라 스크린 좌표계에 기반한 정점 좌표 데이터를 결정하는 것; 상기 정점 좌표 데이터에 따라 프리미티브 데이터를 결정하는 것; 상기 프리미티브 데이터를 유닛화 처리하여 목표 그래픽 데이터를 생성하는 것;상기 목표 그래픽 데이터를 픽셀 변환 처리하여 상기 목표 그래픽 데이터의 픽셀 데이터를 얻는 것; 및 상기 픽셀 데이터에 따라 각 픽셀 포인트의 컬러 데이터를 결정하고 상기 목표 표시 데이터를 얻는 것을 포함하 는 데이터 인터랙션 방법. 청구항 6 청구항2에 있어서, 상기 응답 음성 데이터는 대응하는 응답 텍스트 데이터에서 얻고, 상기 응답 텍스트 데이터는 대응하는 입력 텍 스트 데이터에서 얻고, 상기 입력 텍스트 데이터는 대응하는 입력 음성 데이터에서 얻는 데이터 인터랙션 방법. 청구항 7 청구항2에 있어서, 상기 표시 데이터와 동기화하여 상기 응답 음성 데이터를 재생하는 것을 더 포함하는 데이터 인터랙션 방법. 청구항 8 응답 데이터에 응답하여 상기 응답 데이터에 대응하는 음소 데이터를 결정하기 위한 음소 데이터 결정 모듈; 상기 음소 데이터에 일일이 대응하는 목표 입술 모양 이미지 프레임을 결정하기 위한 목표 입술 모양 이미지 프 레임 결정 모듈; 상기 목표 입술 모양 이미지 프레임을 각각 기초 비디오 프레임과 융합하여 목표 비디오 프레임을 얻기 위한 융 합 모듈; 및 상기 목표 비디오 프레임을 렌더링하여 목표 표시 데이터를 얻기 위한 렌더링 모듈을 포함하는 데이터 인터랙션 장치. 청구항 9 청구항8에 있어서, 상기 응답 데이터는 응답 음성 데이터를 포함하며, 상기 음소 데이터 결정 모듈은, 상기 응답 음성 데이터에 따라, 각각이 분할 주파수에 따라 응답 음성 데이터를 분할하여 얻은 음성 프레임을 복수 포함하는 음성 프레임의 음성 특징 벡터를 결정하기 위한 음성 특징 벡터 결정 서브 모듈; 상기 음성 특징 벡터를 은닉 마코프 모델에 입력하여 각 상기 음성 프레임의 상태 데이터를 결정하기 위한 상태 데이터 결정 서브 모듈; 및 상기 음성 프레임의 상태 데이터에 따라 음소 데이터를 결정하기 위한 음소 데이터 결정 서브 모듈을 포함하는 데이터 인터랙션 장치. 청구항 10 청구항8에 있어서, 목표 입술 모양 이미지 프레임 결정 모듈은, 상기 음소 데이터에 대응하는 입술 모양 키 포인트 데이터를 결정하기 위한 입술 모양 키 포인트 결정 서브 모 듈; 및 상기 입술 모양 키 포인트 데이터에 따라 입술 모양 이미지 프레임 집합에서 상기 입술 모양 키 포인트 데이터 와 매칭되는 상기 목표 입술 모양 이미지 프레임을 결정하기 위한 목표 입술 모양 이미지 프레임 결정 서브 모 듈을 포함하는 데이터 인터랙션 장치. 청구항 11 청구항8 내지 청구항10 중의 어느 하나에 있어서, 상기 융합 모듈은,상기 목표 입술 모양 이미지 프레임에 따라 입술 모양 마스크를 결정하기 위한 입술 모양 마스크 결정 서브 모 듈; 상기 입술 모양 마스크와 상기 기초 비디오 프레임에 따라 융합 경로를 결정하기 위한 융합 경로 결정 서브 모 듈; 및 상기 융합 경로에 따라 상기 입술 모양 마스크와 상기 기초 비디오 프레임을 융합하여 상기 목표 비디오 프레임 을 얻기 위한 융합 서브 모듈을 포함하는 데이터 인터랙션 장치. 청구항 12 청구항8 내지 청구항10 중의 어느 하나에 있어서, 상기 렌더링 모듈은, 상기 목표 비디오 프레임의 정점 데이터에 따라 스크린 좌표계에 기반한 정점 좌표 데이터를 결정하기 위한 정 점 좌표 데이터 결정 서브 모듈; 상기 정점 좌표 데이터에 따라 프리미티브 데이터를 결정하기 위한 프리미티브 데이터 결정 서브 모듈; 상기 프리미티브 데이터를 유닛화 처리하여 목표 그래픽 데이터를 생성하기 위한 목표 이미지 데이터 결정 서브 모듈; 상기 목표 그래픽 데이터를 픽셀 변환 처리하여 상기 목표 그래픽 데이터의 픽셀 데이터를 얻기 위한 픽셀 데이 터 결정 서브 모듈; 및 상기 픽셀 데이터에 따라 각 픽셀 포인트의 컬러 데이터를 결정하고 상기 목표 표시 데이터를 얻기 위한 목표 표시 데이터 결정 서브 모듈을 포함하는 데이터 인터랙션 장치. 청구항 13 청구항9에 있어서, 상기 응답 음성 데이터는 대응하는 응답 텍스트 데이터에서 얻고, 상기 응답 텍스트 데이터는 대응하는 입력 텍 스트 데이터에서 얻고, 상기 입력 텍스트 데이터는 대응하는 입력 음성 데이터에서 얻는 데이터 인터랙션 장치. 청구항 14 청구항9에 있어서, 상기 목표 표시 데이터와 동기화하여 상기 응답 음성 데이터를 재생하기 위한 응답 음성 데이터 재생 모듈을 더 포함하는 데이터 인터랙션 장치. 청구항 15 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 연결된 메모리를 포함하며, 여기서, 상기 메모리에는 적어도 하나의 프로세서에 의해 실행 가능한 명령어가 저장되어 있고, 상기 명령어는 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서로 하여금 청구항1 내지 청구항3 및 청구항6 내 지 청구항7 중 어느 한 항의 상기 데이터 인터랙션 방법을 실행할 수 있게 하는 것을 특징으로 하는 전자 기기. 청구항 16 컴퓨터로 하여금 청구항1 내지 청구항3 및 청구항6 내지 청구항7 중 어느 한 항의 데이터 인터랙션 방법을 실행 하게 하기 위한 컴퓨터 명령어가 저장되어 있는 비휘발성 컴퓨터 판독 가능 저장 매체. 청구항 17 저장 매체에 저장되어 있으며, 프로세서에 의해 실행될 시에 청구항1 내지 청구항3 및 청구항6 내지 청구항7 중 어느 한 항의 데이터 인터랙션 방법을 구현하는 컴퓨터 프로그램.발명의 설명 기 술 분 야 본 개시는 인공 지능 기술 분야, 특히 안면 인식 등 장면에 적용될 수 있는 딥러닝, 이미지 처리, 컴퓨터 비전 기술 분야에 관한 것으로, 보다 구체적으로는, 데이터 인터랙션 방법과 장치, 전자 기기, 저장 매체 및 컴퓨터 프로그램에 관한 것이다."}
{"patent_id": "10-2022-0180171", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "컴퓨터 기술과 인터넷 기술의 발전에 따라 많은 지능형 제품에는 사용자의 사용 체험을 향상시키는 데이터 인터 랙션 기능이 있다. 본 개시는 데이터 인터랙션 방법과 장치, 전자 기기, 저장 매체 및 컴퓨터 프로그램을 제공한다. 본 개시의 일 측면에 따르면, 데이터 인터랙션 방법을 제공하며, 상기 데이터 인터랙션 방법은, 응답 데이터에 응답하여, 응답 데이터에 대응하는 음소 데이터를 결정하는 것; 음소 데이터에 일일이 대응하는 목표 입술 모양 이미지 프레임을 결정하는 것; 목표 입술 모양 이미지 프레임을 각각 기초 비디오 프레임과 융합하여 목표 비디 오 프레임을 얻는 것; 및 목표 비디오 프레임을 렌더링하여 목표 표시 데이터를 얻는 것을 포함한다. 본 개시의 다른 측면에 따르면, 데이터 인터랙션 장치를 제공하며, 상기 데이터 인터랙션 장치는, 응답 데이터 에 응답하여, 응답 데이터에 대응하는 음소 데이터를 결정하기 위한 음소 데이터 결정 모듈; 음소 데이터에 일 일이 대응하는 목표 입술 모양 이미지 프레임을 결정하기 위한 목표 입술 모양 이미지 프레임 결정 모듈; 목표 입술 모양 이미지 프레임을 각각 기초 비디오 프레임과 융합하여 목표 비디오 프레임을 얻기 위한 융합 모듈; 및 목표 비디오 프레임을 렌더링하여 목표 표시 데이터를 얻기 위한 랜더링 모듈을 포함한다. 본 개시의 다른 측면에 따르면, 적어도 하나의 프로세서 및 적어도 하나의 프로세서와 통신 연결된 메모리를 포 함하는 전자 기기를 제공한다. 메모리에는 적어도 하나의 프로세서에 의해 실행 가능한 명령어가 저장되어 있고, 명령어는 적어도 하나의 프로세서에 의해 실행되어, 적어도 하나의 프로세서로 하여금 본 개시의 실시예 의 방법을 실행할 수 있게 한다. 본 개시의 다른 측면에 따르면, 상기 컴퓨터로 하여금 본 개시의 실시예에서 설명한 방법을 실행하게 하기 위한 컴퓨터 명령어가 저장되어 있는 비휘발성 컴퓨터 판독 가능 저장 매체를 제공한다. 본 개시의 다른 측면에 따르면, 프로세서에 의해 실행시에 본 개시의 실시예의 방법을 구현하는 컴퓨터 프로그 램을 포함하는 컴퓨터 프로그램 제품을 제공한다. 이 부분에서 설명한 내용은 본 개시의 실시예의 핵심 또는 중요한 특징들을 표시하기 위한 것이 아니며, 본 개 시의 범위를 한정하는 데 사용하지 않는다는 것을 이해해야 한다. 본 개시의 기타 특징은 아래의 명세서를 통해 쉽게 이해할 수 있게 될 것이다."}
{"patent_id": "10-2022-0180171", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 예시적인 실시예를 상세히 설명하기로 한다. 이해를 돕기 위하여 그 중에는 본 출원의 실시예의 다양한 세부사항이 포함되어 있으며, 이들을 단지 예시적인 것으로 간주해야 한다."}
{"patent_id": "10-2022-0180171", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "따라서, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자는 본 출원의 범위 및 사상을 벗어나는 것이 없 이 여기서 설명된 실시예에 대해 다양한 변경 및 수정을 진행할 수 있음을 인식해야 한다. 마찬가지로, 명확하 고 간결하기 위하여, 아래 설명 중에는 공지 기능 또는 구성에 대한 설명은 생략하도록 한다. 여기에서 사용하는 용어는 단지 구체적인 실시예를 설명하기 위한 것으로, 본 개시를 제한하려는 것이 아니다. 여기서 사용하는 \"포괄\", \"포함\"등의 용어는 상기 특징, 스텝, 동작 및/또는 부품의 존재를 나타내지만, 하나 또는 하나이상의 다른 특징, 스텝, 동작 또는 부품의 존재 또는 추가를 제외하지 않는다. 여기에서 사용하는 모든 용어(기술 및 과학 용어를 포함)는 달리 정의되지 않는 한, 당업자가 일반적으로 이해 하는 의미를 갖는다. 여기서 사용하는 용어는 본 명세서의 문맥과 일치하는 의미를 갖는 것으로 해석되어야 하 며, 이상화되거나 지나치게 융통성 없는 방식으로 해석되어서는 안된다는 점에 유의해야 한다. \"A, B 및 C 등 중의 적어도 하나\"와 유사한 표현을 사용하는 경우, 일반적으로 말하면 당업자가 일반적으로 이 해하는 표현의 의미(예를 들면, \"A, B 및 C중의 적어도 하나를 구비한 시스템\"에는 단독으로 A를 구비, 단독으 로 B를 구비, 단독으로 C를 구비, A와 B를 구비, A와 C를 구비, B와 C를 구비 및/또는 A, B, C를 구비한 시스템 등을 포함하지만 이에 제한되지는 않는다. )로 해석해야 한다. 컴퓨터 기술과 인터넷 기술의 발전에 따라 많은 지능형 제품은 사용자의 사용 체험을 향상시키는 데이터 인터랙 션 기능을 구비한다. 예를 들면, 다양한 지능형 제품은 디지털 휴먼과 같은 가상 캐릭터를 통해 사용자와 데이터 인터랙션을 진행한 다. 디지털 휴먼은 인체의 형태와 기능을 가상 시뮬레이션할 수 가상 캐릭터이다. 일부 실시예에서, 단말 기기는 사용자의 입력 음성 데이터를 수집하고 입력 음성 데이터를 디지털 휴먼 서버의 백그라운드(background)로 전송할 수 있으며, 서버의 백그라운드는 입력 음성 데이터를 획득한 후 음성 해석을 진행하여 해석된 입력 음성 데이터를 얻고, 해석된 입력 음성 데이터에 따라 응답 내용을 생성할 수 있다. 그리 고, 응답 내용에 따라 가상 캐릭터를 생성하는 각 이미지 프레임을 구동하고, 각 이미지 프레임은 인코딩된 후 에 비디오 스트림을 형성하고, 비디오 스트림을 스트리밍 미디어 서버로 푸시한다. 단말 기기는 스트리밍 미디 어 서버 중의 비디오 스트림을 끌어와서 재생하고 데이터 인터래션 과정을 완성할 수 있다. 도 1은 본 개시의 실시예에 따른 데이터 인터랙션 방법과 장치의 시스템 아키텍처를 개략적으로 나타냈다. 도 1 에 도시된 것은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 개시의 기술적 내용을 이해할 수 있도록 본 개시의 실시예가 적용될 수 있는 시스템 아키텍처의 예시일 뿐, 본 개시의 실시예가 기타 장비, 시스 템, 환경 또는 장면에 사용할 수 없다는 것을 의미하지 않는다는 점을 유의해야 한다. 도 1에 도시된 바와 같이, 본 실시예에 따른 시스템 아키텍처는 클라이언트(101, 102, 103), 네트워크 및 서버를 포함할 수 있다. 네트워크는 클라이언트(101, 102, 103)와 서버 사이의 통신 링크의 매개를 제공하기 위한 것이다. 네트워크는 예를 들면 유선, 무선 통신 링크 또는 광섬유 케이블 등 과 같은 다양한 연결 유형을 포함할 수 있다. 사용자는 클라이언트(101, 102, 103)를 이용하여 네트워크를 통해 서버와 인터랙션하여 메시지 등을 수신 또는 송신할 수 있다. 클라이언트(101, 102, 103)에는 예를 들면 쇼핑 애플리케이션, 웹 브라우저 애플리 케이션, 검색 애플리케이션, 인스턴트 메시징 도구, 이메일 클라이언트, 소셜 플랫폼 소프트웨어 등(단지 예시)과 같은 다양한 통신 클라이언트 애플리케이션이 설치될 수 있다. 클라이언트(101, 102, 103)는 디스플레이 화면을 갖고 웹 브라우징을 지원하는 다양한 전자 기기일 수 있으며, 스마트 폰, 태블릿 컴퓨터, 랩톱 컴퓨터와 데스크톱 컴퓨터 등을 포함하나 이에 한정되지 않는다. 본 개시의 실 시예의 클라이언트(101, 102, 103)는 예를 들면 애플리케이션 프로그램을 실행시킬 수 있다. 서버는 다양한 서비스를 제공하는 서버일 수 있다. 예를 들면 사용자가 클라이언트(101, 102, 103)를 이용 하여 브라우징하는 웹사이트에 대하여 지원을 제공하는 백그라운드 관리 서버(단지 예시)일 수 있다. 백그라운 드 관리 서버는 수신된 사용자 요청 등 데이터에 대해 분석 등 처리를 진행하고, 처리 결과(예를 들면, 사용자 의 요청에 따라 획득 또는 생성된 웹 페이지, 정보, 또는 데이터 등)를 클라이언트에 피드백할 수 있다. 또한, 서버는 클라우드 서버일 수도 있으며, 즉 서버는 클라우드 컴퓨팅 기능을 갖는다. 설명이 필요한 것은, 본 개시의 실시예에 의해 제공되는 데이터 인터랙션 방법은 클라이언트(101, 102, 103)에 의해 실행될 수 있다. 이에 대응하여, 본 개시의 실시예에 의해 제공되는 데이터 인터랙션 장치는 클라이언트 (101, 102, 103)에 설치될 수 있다. 본 개시의 실시예에서 제공하는 데이터 인터랙션 방법은 클라이언트(101, 102, 103)와 다르면서 서버 및/또는 클라이언트(101, 102, 103)와 통신이 가능한 클라이언트 또는 클라이 언트 클러스터에 의해 실행될 수도 있다. 이에 대응하여, 본 개시의 실시예에서 제공하는 데이터 인터랙션 장치 는 클라이언트(101, 102, 103) 및 서버 및/또는 클라이언트(101, 102, 103)와 통신이 가능한 클라이언트 또는 클라이언트 클러스터에 설치될 수도 있다. 하나의 예시에서, 클라이언트(101, 102, 103)는 네트워크를 통해 서버로부터의 응답 데이터를 획득할 수 있다. 도 1 중의 클라이언트, 네트워크 및 서버의 수량은 단지 예시적인 것임을 이해해야 한다. 구현의 수요에 따라 임의의 수량의 클라이언트, 네크워크 및 서버를 가질 수 있다. 본 개시의 기술 방안에서 언급된 사용자 개인 정보의 수집, 저장, 사용, 가공, 전송, 제공과 공개 등 처리는 모 두 관련 법률과 법규의 규정에 부합되고 공서 양속을 위반하지 않는다는 점에 유의해야 한다. 본 개시의 기술방안에서, 사용자의 개인 정보를 획득하거나 수집하기 전에 모두 사용자의 권한 부여 또는 동의 를 받았다. 본 개시의 실시예는 데이터 인터랙션 방법을 제공하며, 아래 도1의 시스템 아키텍처과 결합하고, 도2 내지 도4 을 참조하여 본 개시의 예시적 실시방식에 따른 데이터 인터랙션 방법을 설명한다. 본 개시의 실시예의 데이터 인터랙션 방법은 예를 들면 도1에 도시된 클라이언트에 의해 실행될 수 있다. 도 2는 본 개시의 실시예에 따른 데이터 인터랙션 방법의 흐름도를 개략적으로 나타냈다. 도 2에 도시된 바와 같이, 본 개시의 실시예에 따른 데이터 인터랙션 방법은 예를 들면, 동작 S210 내지 동작 S240을 포함할 수 있다. 동작 S210에서, 응답 데이터에 응답하여, 응답 데이터에 대응하는 음소 데이터를 결정한다. 본 개시의 실시예의 데이터 인터랙션 방법은 디지털 휴먼을 예로 들어 설명한다. 응답 데이터는 입력 데이터에 응답하기 위한 데이터로 이해할 수 있다. 예를 들면, 사용자가 클라이언트를 통해 어떤 문제를 질문하면, 해당 문제는 입력 데이터이고, 해당 문제에 대한 답변 내용은 바로 응답 데이터이다. 응답 데이터는 클라이언트에 표 시된 디지털 휴먼에 의해 사용자에게 출력될 수 있다. 음소는 음성의 자연 속성에 따라 구분된 최소 음성 단위로 이해할 수 있으며, 음절 내의 각 발음 동작은 하나의 음소를 구성할 수 있다. 따라서, 음소는 음절을 구성하는 최소 단위 또는 가장 작은 음성 세그먼트이며, 음질의 측면에서 구분된 가장 작은 선형의 음성 단위이다. 응답 내용이 음성 포맷일 때, 응답 내용에 따라 대응하는 음소 데이터를 얻을 수 있다. 응답 내용이 텍스트 포 맷일 때, 텍스트 포맷의 응답 내용을 음성 포맷으로 변환하고. 대응하는 음소 데이터를 결정할 수 있다. 동작 S220에서, 음소 데이터에 일일이 대응하는 목표 입술 모양 이미지 프레임을 결정한다. 음소는 가장 작은 음성 단위임을 이해할 수 있다. 따라서, 응답 데이터의 경우, 음소 데이터에 따라 결정된 목 표 입술 모양 이미지 프레임은 응답 데이터를 음성으로 출력할 때의 입술 동작을 정확하게 반영할 수 있다. 동작 S230에서, 목표 입술 모양 이미지 프레임을 각각 기초 비디오 프레임과 융합하여 목표 비디오 프레임을 얻 을 수 있다. 기초 비디오 프레임은 디지털 휴먼의 템플릿 비디오 프레임으로 이해될 수 있으며, 기초 비디오 프레임은 예를 들면 디지털 휴먼의 전체 형상 및 배경을 포함할 수 있다. 디지털 휴먼은 실제 사람의 음성을 모의하여 응답 데 이터를 출력하는 것임을 이해할 수 있다. 이에 대응하여, 응답 데이터를 음성으로 출력할 때, 입술 모양은 서로 다른 발음 변화에 따라 변화하고, 디지털 휴먼의 다른 부분은 모두 변하지 않아도 된다. 목표 입술 모양 이미지 프레임과 기초 비디오 프레임을 융합하여 얻은 목표 비디오 프레임은 디지털 휴먼의 전체 상태를 정확하게 반영 할 수 있다. 동작 S240에서, 목표 비디오 프레임을 렌더링하여 목표 표시 데이터를 얻는다. 목표 표시 데이터는 예를 들면 인코딩을 통해 비디오 스트림을 형성하고, 클라이언트에서 비디오 스트림을 재생 할 수 있다. 본 개시의 실시예의 데이터 인터랙션 방법은, 가장 작은 음성 단위의 음소 데이터를 결정하는 것을 통해, 응답 데이터가 음성으로 출력될 때의 발음 과정을 정확하게 나타낼 수 있다. 음소 데이터에 대응하는 목표 입술 모양 이미지 프레임을 결정하는 것을 통해, 응답 데이터를 음성으로 출력할 때의 입술 모양을 정확하게 결정할 수 있 다. 목표 입술 모양 이미지 프레임을 기초 비디오 프레임과 융합하여 목표 비디오 프레임을 빠르고 효율적으로 결정할 수 있으며, 목표 비디오 프레임을 렌더링하여 얻은 목표 표시 데이터는 디지털 휴먼의 전체 상태를 정확 하게 표시하고 사용자의 사용 체험을 향상시킬 수 있다. 본 개시의 실시예의 데이터 인터랙션 방법은 네트워크가 없는 환경에서 데이터 인터랙션을 진행할 수 있다. 예 를 들면, 본 발명의 실시예에 따른 데이터 인터랙션 방법의 관련 동작은 네트워크를 통해 서버와 데이터 인터랙 션을 진행할 필요 없이 클라이언트에 의해 모두 수행될 수 있기 때문에, 네트워크에 대한 의존도를 낮출 수 있 으며, 네트워크 품질이 좋지 않으므로 인해 발생하는 데이터를 인터랙션할 때의 응답 속도가 낮아지고, 인터랙 션이 제때에 이루어지지 않는 상황 등을 피할 수 있다. 따라서, 본 개시의 실시예의 데이터 인터랙션 방법의 각 동작의 실행 과정은 더 빠르고 효율적이고, 더 높은 데이터 인터랙션 효율을 가지며, 사용자의 사용 체험을 향 상시킬 수 있다. 도 3은 다른 본 개시의 다른 실시예에 따른 데이터 인터랙션 방법의 설명도를 개략적으로 나타냈다. 도 3에 도시된 바와 같이, 본 개시의 다른 실시예에 따른 데이터 인터랙션 방법은 동작 S310 내지 동작 S340을 포함할 수 있다. 동작 S310에서, 응답 데이터에 응답하여, 응답 데이터에 대응하는 음소 데이터를 결정한다. 도 3은 n 개의 음소 데이터, 예를 들면 음소 데이터 Phone_1 내지 Phone_n을 개략적으로 나타냈다. 동작 S320에서, 음소 데이터에 일일이 대응하는 목표 입술 모양 이미지 프레임을 결정한다. 도 3은 n개의 목표 입술 모양 이미지 프레임, 예를 들면 목표 입술 모양 이미지 프레임 PL_1 내지 목표 입술 모양 이미지 프레임 PL_n을 개략적으로 나타냈다. 동작 S330에서, 목표 입술 모양 이미지 프레임을 각각 기초 비디오 프레임과 융합하여 목표 비디오 프레임을 얻 는다. 도 3은 n개의 목표 비디오 프레임, 예를 들면 목표 비디오 프레임 PT_1 내지 목표 비디오 프레임 PT_n을 개략적으로 나타냈다. 동작 S340에서, 목표 비디오 프레임을 렌더링하여 목표 표시 데이터를 얻는다. 도 3은 n개의 목표 표시 데이터, 예를 들면 목표 표시 데이터 V_1 내지 목표 표시 데이터 V_n을 개략적으로 나타냈다. 도 4는 본 개시의 또 다른 실시예에 따른 데이터 인터랙션 방법에서 음소 데이터의 결정의 설명도를 개략적으로 나타냈다. 본 개시의 다른 실시예에 따르면, 다음과 같은 실시예를 이용하여 데이터 인터랙션 방법에서 응답 데이터에 응 답하여 상기 응답 데이터에 대응하는 음소 데이터를 결정하는 구체적인 예시를 구현할 수 있다. 응답 데이터는 음답 음성 데이터를 포함할 수 있다. 도 4에 도시된 바와 같이, 동작 S411에서, 응답 음성 데이터에 따라 음성 프레임의 음성 특징 벡터를 결정한다. 음성 프레임은 복수를 포함할 수 있으며, 각 음성 프레임은 분할 주파수에 따라 응답 음성 데이터를 분할하여 얻은 것이다. 음성 특징 벡터는 음성 데이터에서 추출한 컴퓨터가 처리할 수 있는 특징 벡터로 이해할 수 있다. 음성 특징 벡터는 사람의 귀의 청각 감지 특성에 부합되거나 유사하며, 음성 정보를 어느 정도 증강하고 비음성 신호를 억제할 수 있다. 예시적으로, 선형 예측 분석 방법, 감지 선형 예측 계수 방법, 병목 특징 추출 방법, 선형 예측 캡스트럼 계수 방법 및 멜 주파수 캡스트럼 계수 방법과 같은 음성 특징 벡터 추출 방법 중 하나를 통해, 응답 음성 데이터에 대하여 언어 특징 벡터 추출을 진행할 수 있다. 아래 멜 주파수 캡스트럼 계수 방법(멜 주파수 캡스트럼 계수, 즉 Mel-scale Frequency Cepstral Coefficients, MFCC로 약칭)을 이용하여 응답 음성 데이터의 음성 특징 벡터를 추출하는 것을 예로 들어 설명한 다. 사람의 귀의 청각 메커니즘의 연구에 따라, 사람의 귀는 서로 다른 주파수의 음파에 대해 서로 다른 청각 민감 도를 가지고 있다는 것이 발견되었다. 200Hz에서 5000Hz까지의 음성 신호는 음성의 선명도에 큰 영향을 미친다. 두 개의 음량이 다른 음성이 사람의 귀에 작용할 때, 음량이 비교적 높은 주파수 성분의 존재는 음량이 낮은 주 파수 성분의 느낌에 영향을 주어, 인지하기 어렵게 할 수 있다. 이러한 현상을 마스킹 효과(masking effect)라 고 한다. 주파수가 비교적 낮은 음성은 안쪽 달팽이관의 기저막에서 전달하는 거리가 주파수가 비교적 높은 음 성보다 멀기 때문에, 일반적으로, 저음이 고음을 마스킹하기는 쉽지만 고음이 저음을 마스킹하는 것은 비교적 어렵다. 저주파에서의 음성 마스킹의 임계 대역폭은 고주파보다 작다. 따라서, 사람들은 입력 신호를 필터링하 기 위해, 저주파에서 고주파까지의 주파수대 안에서 임계 대역폭의 크기에 따라 빽빽한 것으로부터 성긴 것으로 대역 필터 군을 배치한다. 각 대역 필터에서 출력되는 신호 에너지를 신호의 기본 특징으로 하고, 이 특징에 대 해 추가 처리한 후 음성의 입력 특징으로 할 수 있다. 이러한 특징은 신호의 성질에 의존하지 않기 때문에, 입 력 신호에 대해 어떠한 가설과 제한도 하지 않으며, 또한 청각 모델의 연구 성과를 이용하였다. 따라서, 이러한 멜 주파수 캡스트럼 계수를 기반으로 결정한 파라미터는 더욱 좋은 로우버스트(Robust)성을 가지고, 사람의 귀 의 청각 특성에 더욱 부합되며, 신호 대 잡음비가 감소할 때 여전히 비교적 좋은 인식 성능을 가진다. 멜 주파수 캡스트럼 계수 방법에 기반한 음성 특징 벡터의 추출은, 예가중→프레임 분할→ 윈도우 추가 → 고속 푸리에 변환 → 삼각 대역 필터 → 멜 주파수 필터 군 → 각 필터 군이 출력한 로그 에너지를 계산 → 이산 코 사인 변환에 의해 MFCC 계수를 얻는 것과 같은 동작을 포함한다. 동작 S412에서, 음성 특징 벡터를 은닉 마코프 모델(HMM)에 입력하여 각 음성 프레임의 상태 데이터 를 결정한다. 은닉 마코프 모델（Hidden Markov Model，HMM로 약칭）은 은닉된 미지의 파라미터가 포함한 마코프 과정을 설명 하기 위한 통계 모델이다. 음성 인식 기술 분야에서, 은닉 마코프 모델은 입력된 음성 특징 벡터에 따라 각 음성 프레임의 상태 데이터를 결정할 수 있으며, 여기서, 하나의 음성 프레임에 따라 하나의 상태를 결정할 수 있고, 상태는 음소보다 더 작 은 음성 단위로 이해할 수 있다. 예를 들면, 하나의 음소를 세 가지 상태로 나눌 수 있다. 동작 S413에서, 음성 프레임의 상태 데이터에 따라 음소 데이터를 결정한다. 예를 들면, 연속적이고 같은 상태를 가진 3개 음성 프레임에 따라 하나의 음소를 결정할 수 있다. 따라서, 음성 프레임의 상태 데이터에 따라 음소 데이터를 결정할 수 있다. 본 개시의 실시예의 데이터 인터랙션 방법은, 응답 음성 데이터에 대해, 음성 데이터의 특성에 따라 음성 특징 벡터 추출을 진행하고, 은닉 마코프 모델이라는 구체적인 사운드트랙 모델을 이용하여 정확하고 효율적으로 음 소 데이터를 결정할 수 있다. 은닉 마코프 모델은 클라이언트에 위치할 수 있음을 이해할 수 있다. 따라서, 음성 특징 벡터를 로컬에 있는 은 닉 마코프 모델에 입력하여 각 음성 프레임의 상태 데이터를 결정하여, 음소 데이터를 결정할 수 있다. 도 5는 본 개시의 또 다른 실시예에 따른 데이터 인터랙션 방법에서 목표 입술 모양 이미지 프레임의 결정의 설 명도를 개략적으로 나타냈다. 본 개시의 또 다른 실시예에 따르면, 다음과 같은 실시예를 이용하여 데이터 인터랙션 방법에서 음소 데이터에 일일이 대응하는 목표 입술 모양 이미지 프레임을 결정하는 구체적인 예시를 구현할 수 있다. 동작 S521에서, 음소 데이터에 대응하는 입술 모양의 키 포인트 데이터를 결정한다. 입술 모양 키 포인트는 서로 다른 입술 모양을 구분할 수 있는 위치 포인트로 이해할 수 있다. 예시적으로, 예를 들면 목표 검출 모델에 의해 음소 데이터에 대응하는 입술 모양 키 포인트 데이터를 결정할 수 있다. 동작 S522에서, 입술 모양 키 포인트 데이터에 따라, 입술 모양 이미지 프레임 집합에서 입술 모양 키 포인트 데이터와 매칭되는 목표 입술 모양 이미지 프레임을 결정한다. 입술 모양 이미지 프레임 집합은 로컬에 있는 클라이언트에 저장될 수 있다. 본 개시의 실시예의 데이터 인터랙 션 방법은 입술 모양 키 포인트 데이터에 따라 로컬의 입술 이미지 프레임 집합에서 빠르고 효율적으로 검색하 고, 입술 모양 이미지 프레임 집합에서 입술 키 포인트 데이터와의 일치도가 비교적 높은 하나의 입술 모양 이 미지 프레임을 목표 입술 이미지 프레임으로 결정할 수 있어, 네트워크에 의존하지 않고 사용자의 사용 체험을 향상시킬 수 있다. 도 6은 본 개시의 다른 실시예에 따른 데이터 인터랙션 방법에서 목표 비디오 프레임을 얻는 설명도를 개략적으 로 나타냈다. 본 개시의 또 다른 실시예에 따르면, 다음과 같은 실시예를 이용하여 데이터 인터랙션 방법에서 목표 입술 모양 이미지 프레임을 각각 기초 비디오 프레임과 융합하여 목표 비디오 프레임을 얻는 구체적인 예시를 구현할 수 있다. 동작 S631에서, 목표 입술 모양 이미지 프레임에 따라 입술 모양 마스크를 결정한다. 마스크는 선정된 이미지, 그래픽으로 이해할 수 있으며, 마스크는 처리되는 이미지를 가려서 이미지 처리의 구 역이나 처리 과정을 제어하기 위한 것이다. 동작 S632에서, 입술 모양 마스크 및 기본 비디오 프레임에 따라 융합 경로를 결정한다. 예시적으로, 에너지 최소 검색 방책에 따라 입술 모양 마스크와 기초 비디오 프레임 사이의 융합 경로를 결정할 수 있다. 예를 들면, 입술 모양 마스크와 기초 비디오 프레임과의 융합 구역을 미리 결정할 수 있으며, \"에너지 ”는 융합 구역 양측의 이미지 픽셀의 차이값의 평방화로 이해할 수 있고, 에너지 최소 검색 방책에 따라 결정 된 융합 경로가 더욱 유창하고 평화하며, 더욱 좋은 융합 효과를 가진다. 동작 S633에서, 융합 경로에 따라 입술 모양 마스크와 기본 비디오 프레임을 융합하여 목표 비 디오 프레임을 얻는다. 본 개시의 실시예의 데이터 인터랙션 방법은, 목표 입술 모양 이미지 프레임에 따라 입술 모양 마스크를 결정하 고, 입술 모양 마스크와 기초 비디오 프레임 사이의 융합 경로에 따라 입술 모양 마스크와 기초 비디오 프레임 을 융합시켜, 융합 경로를 기반으로 하는 입술 모양 마스크와 기초 비디오 프레임의 양측의 픽셀 차이가 더욱 작고 더욱 좋은 융합 효과를 가지도록 하여, 더욱 자연스러운 목표 비디오 프레임을 얻을 수 있다. 도 7은 본 개시의 또 다른 실시예에 따른 데이터 인터랙션 방법에서 목표 표시 데이터를 얻는 설명도를 개략적 으로 나타냈다. 본 개시의 또 다른 실시예에 따르면, 다음과 같은 실시예를 이용하여 데이터 인터랙션 방법에서 목표 비디오 프 레임을 렌더링하여 목표 표시 데이터를 얻는 구체적인 예시를 구현할 수 있다. 동작 S741에서, 목표 비디오 프레임의 정점 데이터에 따라 스크린 좌표계에 기반한 정점 좌표 데이터(70 2)를 결정한다. 예시적으로, 정점 데이터는 배열의 형식을 이용하여 나타내는 각 정점의 좌표를 포함할 수 있다. 정점 셰이더를 이용하여 목표 비디오 프레임의 정점 데이터에 따라 스크린 좌표계에 기반한 정점 좌표 데이터를 결정할 수 있 다. 정점 셰이더는 정점 속성에 대하여 일부 기본적인 처리도 진행할 수 있다. 동작 S742에서, 정점 좌표 데이터에 따라 프리미티브 데이터를 결정한다. 프리미티브 데이터는 정점 데이터를 어떻게 렌더링할 것인지의 참조로 할 수 있다. 예를 들면, 프리미티브 데이 터는 점, 선, 삼각형을 포함할 수 있다.동작 S743에서, 프리미티브 데이터를 유닛화 처리하여 목표 그래픽 데이터를 생성할 수 있다. 예시적으로, 기하 셰이더를 이용하여 프리미티브 데이터를 유닛화 처리하여 목표 그래픽 데이터를 생성할 수 있 다. 유닛화 처리는 예를 들면 새로운 정점을 생성하고 각 정점을 연결하여 목표 그래픽 데이터를 생성하는 것을 포함할 수 있다. 동작 S744에서, 목표 그래픽 데이터를 픽셀 변환 처리하여 목표 그래픽 데이터의 픽셀 데이터를 얻는 다. 동작 S744는 격자화(rasterization) 처리로 이해할 수 있으며, 프리미티브 데이터를 최종 스크린 상의 대응하는 픽셀로 매핑하여 세그먼트를 생성한다. 세그먼트는 하나의 픽셀을 렌더링하는 데 필요한 모든 데이터이다. 동작 S745에서, 픽셀 데이터에 따라 각 픽셀 포인트의 컬러 데이터를 결정하고 목표 표시 데이터를 얻는다. 본 개시의 실시예의 데이터 인터랙션 방법에 따르면, 상술한 목표 비디오 프레임을 렌더링하는 구체적인 동작을 통해 목표 표시 데이터를 클라이언트의 스크린에 렌더링할 수 있다. 상술한 목표 비디오 프레임을 렌더링하는 동작은 그래픽 프로세서를 기반으로 한다. 그래픽 프로세서(Graphics Processing Unit, GPU로 약칭)는 개인용 컴퓨터, 워크스테이션, 게임기와 일부 모바일 기기에서 이미지와 그래픽의 관련 연산 동작을 하는 마이크로프로 세서이다. GPU는 강력한 연산 능력을 가지고 있어, 이미지 렌더링에 사용할 때 렌더링 효율을 향상시키고 CPU의 리소스 사용을 줄일 수 있다. 본 개시의 실시예의 데이터 인터랙션 방법은, GPU를 통해 이미지를 렌더링하여, 비교적 낮은 수준의 구성의 클라이언트에서도 양호한 표시 효과를 렌더링할 수 있다. 본 개시의 실시예의 데이터 인터랙션 방법에 따르면, 응답 음성 데이터는 대응하는 응답 텍스트 데이터에서 얻 을 수 있고, 응답 텍스트 데이터는 대응하는 입력 텍스트 데이터에서 얻을 수 있고, 입력 텍스트 데이터는 대응 하는 입력 음성 데이터에서 얻을 수 있다. 입력 음성 데이터는 사용자가 발성한 음성 형식의 입력 데이터로 이해할 수 있다. 예시적으로, 입력 음성 데이터에 대해 음성 인식을 진행하여 입력 텍스트 데이터를 얻을 수 있다. 예를 들면 음 성 인식 모듈의 인터페이스를 호출하여 입력 음성 데이터에 대해 음성 인식을 진행할 수 있다. 음성 인식 모듈 은 서버에 위치할 수 있다. 이때 클라이언트와 서버의 연결 및 데이터 인터랙션은 네트워크에 의존한다. 예시적으로, 로컬 데이터베이스 또는 서버에서 입력 텍스트 데이터에 대응하는 응답 텍스트를 검색할 수 있다. 예를 들면, 로컬 데이터베이스에 세팅된 응답 텍스트 데이터가 저장되어 있을 때, 입력 데이터에 응답하여 로컬 데이터베이스에 저장된 세팅된 응답 텍스트 데이터를 검색할 수 있다. 온 라인 적용 장면에서, 입력 데이터에 응답하여 서버에서 응답 텍스트 데이터를 검색할 수 있으며, 이때 클라이언트와 서버의 연결 및 데이터 인터랙 션은 네트워크에 의존한다. 예시적으로, 응답 텍스트 데이터를 텍스트 음성 변환(텍스트에서 음성으로, Text To Speech, TTS로 약칭) 처리 하여 응답 음성 데이터를 얻을 수 있다. 응답 음성 데이터는, 예를 들어 펄스 코드 변조 데이터(Pulse Code Modulation, PCM로 약칭)일 수 있다. 예를 들면, 텍스트 음성 변환 모듈의 인터페이스를 호출하여 응답 텍스트 를 텍스트 음성 변환 처리할 수 있다. 텍스트 음성 변환 모듈은 서버에 위치할 수 있다. 이때 클라이언트와 서 버의 연결 및 데이터 인터랙션은 네트워크에 의존한다. 도 8은 본 개시의 또 다른 실시예에 따른 데이터 인터랙션 방법의 흐름도를 개략적으로 나타냈다. 도 8에 도시된 바와 같이, 본 개시의 또 다른 실시예에 따른 데이터 인터랙션 방법은 동작 S850을 더 포함 할 수 있다. 동작 S850에서, 목표 표시 데이터와 동기화하여 응답 음성 데이터를 재생한다. 도 8에 도시된 바와 같이, 데이터 인터랙션 방법은 동작 S850 이전에 동작 S810 내지 동작 S840을 더 포함 할 수 있다. 동작 S810 내지 동작 S840은 각각 상술한 동작 S210 내지 동작 S240과 같기 때문에 여기서는 다시 설명하지 않는다. 본 개시의 실시예의 데이터 인터랙션 방법은 여전히 디지털 휴먼을 예로 든다. 응답 음성 데이터와 목표 표시 데이터의 동기화 재생은 사용자에게 동기화된 음성 출력과 시각 출력을 제공하여 사용자의 사용 체험을 향상시 킬 수 있다.예시적으로, 목표 표시 데이터에 대응하는 이미지 프레임의 표시 주파수와 응답 음성 데이터가 대응하는 음성 프레임의 재생 주파수가 동일하면, 목표 표시 데이터와 응답 음성 데이터는 동기화될 수 있다. 도 9는 본 개시의 일 실시예에 따른 데이터 인터랙션 장치의 블록도를 개략적으로 나타냈다. 도 9에 도시된 바와 같이, 본 개시의 실시예의 데이터 인터랙션 장치는, 예를 들면, 음소 데이터 결정 모 듈, 목표 입술 모양 이미지 프레임 결정 모듈, 융합 모듈 및 렌더링 모듈을 포함한다. 음소 데이터 결정 모듈은 응답 데이터에 응답하여 응답 데이터에 대응하는 음소 데이터를 결정하기 위한 것이다. 목표 입술 모양 이미지 프레임 결정 모듈은 음소 데이터에 일일이 대응하는 목표 입술 모양 이미지 프레임을 결 정하기 위한 것이다. 융합 모듈은 목표 입술 모양 이미지 프레임을 각각 기초 비디오 프레임과 융합하여 목표 비디오 프레임을 얻기 위한 것이다. 렌더링 모듈은 목표 비디오 프레임을 렌더링하여 목표 표시 데이터를 얻기 위한 것이다. 본 개시의 실시예의 데이터 인터랙션 장치에 따르면, 여기서, 응답 데이터는 응답 음성 데이터를 포함하고, 음 소 데이터 결정 모듈은 음성 특징 벡터 결정 서브 모듈, 상태 데이터 결정 서브 모듈 및 음소 데이터 결정 서브 모듈을 포함할 수 있다. 음성 특징 벡터 결정 서브 모듈은 응답 음성 데이터에 따라, 각각이 분할 주파수에 따라 응답 음성 데이터를 분 할하여 얻은 음성 프레임을 복수 포함하는 음성 프레임의 음성 특징 벡터를 결정하기 위한 것이다. 상태 데이터 결정 서브 모듈은 음성 특징 벡터를 은닉 마코프 모델에 입력하여 각 음성 프레임의 상태 데이터를 결정하기 위한 것이다. 음소 데이터 결정 서브 모듈은 음성 프레임의 상태 데이터에 따라 음소 데이터를 결정하기 위한 것이다. 본 개시의 실시예의 데이터 인터랙션 장치에 따르면, 여기서, 목표 입술 모양 이미지 프레임 결정 모듈은 입술 모양 키 포인트 결정 서브 모듈 및 목표 입술 모양 이미지 프레임 결정 서브 모듈을 포함할 수 있다. 입술 모양 키 포인트 결정 서브 모듈은 음소 데이터에 대응하는 입술 모양 키 포인트 데이터를 결정하기 위한 것이다. 목표 입술 모양 이미지 프레임 결정 서브 모듈은 입술 모양 키 포인트 데이터에 따라, 입술 모양 이미지 프레임 집합에서 입술 모양 키 포인트 데이터와 매칭되는 목표 입술 모양 이미지 프레임을 결정하기 위한 것이다. 본 개시의 실시예의 데이터 인터랙션 장치에 따르면, 여기서, 융합 모듈은 입술 모양 마스크 결정 서브 모듈, 융합 경로 결정 서브 모듈 및 융합 서브 모듈을 포함할 수 있다. 입술 모양 마스크 결정 서브 모듈은 목표 입술 모양 이미지 프레임에 따라 입술 모양 마스크를 결정하기 위한 것이다. 융합 경로 결정 서브 모듈은 입술 모양 마스크와 기초 비디오 프레임에 따라 융합 경로를 결정하기 위한 것이다. 융합 서브 모듈은 융합 경로에 따라 입술 모양 마스크와 기본 비디오 프레임을 융합하여 목표 비디오 프레임을 얻기 위한 것이다. 본 개시의 실시예의 데이터 인터랙션 장치에 따르면, 여기서, 렌더링 모듈은 정점 좌표 데이터 결정 서브 모듈, 프리미티브 데이터 결정 서브 모듈, 목표 이미지 데이터 결정 서브 모듈, 픽셀 데이터 결정 서브 모듈 및 목표 표시 데이터 결정 서브 모듈을 포함할 수 있다. 정점 좌표 데이터 결정 서브 모듈은 목표 비디오 프레임의 정점 데이터에 따라 스크린 좌표계에 기반한 정점 좌 표 데이터를 결정하기 위한 것이다. 프리미티브 데이터 결정 서브 모듈은 정점 좌표 데이터에 따라 프리미티브 데이터를 결정하기 위한 것이다. 목표 이미지 데이터 결정 서브 모듈은 프리미티브 데이터를 유닛화 처리하여 목표 그래픽 데이터를 생성하기 위 한 것이다.픽셀 데이터 결정 서브 모듈은 목표 그래픽 데이터를 픽셀 변환 처리하여 목표 그래픽 데이터의 픽셀 데이터를 얻기 위한 것이다. 목표 표시 데이터 결정 서브 모듈은 픽셀 데이터에 따라 각 픽셀 포인트의 컬러 데이터를 결정하고 목표 표시 데이터를 얻기 위한 것이다. 본 개시의 실시예의 데이터 인터랙션 장치에 따르면, 여기서, 응답 음성 데이터는 대응하는 응답 텍스트 데이터 에서 얻고, 응답 텍스트 데이터는 대응하는 입력 텍스트 데이터에서 얻고, 입력 텍스트 데이터는 대응하는 입력 음성 데이터에서 얻는다. 본 개시의 실시예의 데이터 인터랙션 장치에 따르면, 응답 음성 데이터 재생 모듈을 더 포함할 수 있다. 응답 음성 데이터 재생 모듈은 목표 표시 데이터와 동기화하여 응답 음성 데이터를 재생하기 위한 것이다. 본 개시의 장치 부분의 실시예는 본 개시의 방법 부분의 실시예와 대응하여 동일하거나 유사하며, 해결된 기술 문제와 달성한 기술 효과도 대응하여 동일하거나 유사하므로, 본 개시는 여기서 다시 설명하지 않는다는 것을 이해해야 한다. 본 개시의 실시예에 따르면, 본 개시는 또한 전자 기기와 판독 가능 저장 매체와 컴퓨터 프로그램 제품을 제공 한다. 도 10은 본 개시의 실시예를 실시하는데 사용될수 있는 예시적인 전자 기기 의 개략적인 블록도이다. 전 자 기기는 랩톱 컴퓨터, 데스크톱 컴퓨터, 웍스테이션, 개인 휴대 정보 단말기, 서버, 블레이드 서버, 메인 프 레임 컴퓨터 및 기타 적합한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 말한다. 전자 기기는 개인 휴대 정 보 단말기, 셀룰러 전화, 지능형 폰, 웨어러블 디바이스 및 기타 유사한 컴퓨팅 장치와 같은 다양한 형태의 모 바일 장치를 말할 수도 있다. 본 명세서에서 나타낸 부품, 이들의 연결 및 관계, 및 이들의 기능은 단지 예시일 뿐이며, 본 명세서에서의 설명 및/또는 요구하는 본 출원의 구현을 한정하려 하는 것이 아니다. 도 10에 도시된 바와 같이, 기기는 읽기 전용 기억 장치(ROM)에 저장된 컴퓨터 프로그램 또는 저장 유닛에서 랜덤 액세스 메모리(RAM)로 로드된 컴퓨터 프로그램에 따라 다양한 적절한 동작 및 처리 를 실행할 수 있는 컴퓨팅 유닛을 포함한다. RAM에는 저장 기기의 동작에 필요한 다양한 프 로그램 및 데이터가 저장될 수 있다. 컴퓨팅 유닛, ROM 및 RAM은 버스를 통해 서로 연결된다. 입력/출력(I/O)인터페이스도 버스에 연결된다. 기기 중의 복수의 부품은 I/O인터페이스와 연결되며, 예를 들면 키보드, 마우스 등과 같은 입력 유 닛; 예를 들면 다양한 유형의 디스플레이, 스피커 등과 같은 출력 유닛; 예를 들면 자기 디스크, 시디롬 등과 같은 저장 유닛 및 예를 들면 랜 카드, 모뎀, 무선 통신 송수신기 등과 같은 통신 유닛 을 포함한다. 통신 유닛은 기기가 인터넷과 같은 컴퓨터 네트워크 및/또는 다양한 통신 네트 워크와 기타 장치를 통하여 정보/데이터를 교환할 수 있도록 허용한다. 컴퓨팅 유닛은 처리 및 컴퓨팅 능력을 갖는 다양한 범용 및/또는 전용 처리 유닛일 수 있다. 컴퓨팅 유닛 의 일부 예는 중앙 처리 유닛(CPU), 그래픽 처리 유닛(GPU), 다양한 전용 인공 지능(AI) 컴퓨팅 칩, 머신 러닝 모델 알고리즘을 실행하는 다양한 컴퓨팅 유닛, 디지털 신호 처리 장치(DSP) 및 임의의 적절한 프로세서, 컨트롤러, 마이크로 컨트롤러 등를 포함하지만 이에 한정되지 않는다. 컴퓨팅 유닛은 예를 들면 데이터 인터랙션 방법과 같은 상술한 다양한 방법과 처리를 실행한다. 예를 들면, 일부 실시예에서는 데이터 인터랙션 방법은 컴퓨터 소프트웨어 프로그램으로 구현될 수 있으며, 이는 예를 들면 유형적으로 저장 유닛과 같은 기계 판독 가능 매체에 포함된다. 일부 실시예에서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및/또는 통 신 유닛을 통해 기기에 로드 및/또는 설치될수 있다. 컴퓨터 프로그램이 RAM에 로딩되고 컴 퓨팅 유닛에 의해 실행될 경우, 상술한 데이터 인터랙션 방법 중의 하나 또는 복수의 동작을 실행할 수 있다. 선택적으로, 다른 실시 예에서, 컴퓨팅 유닛은 기타 임의의 적절한 방식(예를 들면, 펌웨어에 의해)으로 데이터 인터랙션 방법을 실행하도록 배치될 수 있다. 본 명세서의 상술한 시스템 및 기술의 다양한 구현 방식은 디지털 전자 회로 시스템, 집적 회로 시스템, 필드 프로그램 가능 게이트 어레이(FPGA), 전용 집적 회로(ASIC), 특정 용도 표준 제품(ASSP), 시스템 온칩(SOC), 복 합 프로그램 가능 논리 장치(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및/또는 이들의 조합에서 구현될 수 있다. 이러한 다양한 실시방식은 아래와 같은 것을 포함할 수 있다. 하나 또는 복수의 컴퓨터 프로그램에서 실 시될 수 있으며, 해당 하나 또는 복수의 컴퓨터 프로그램은 적어도 하나의 프로그램 가능 프로세서를 포함하는프로그램 가능 시스템에서 실행 및/또는 해석될 수 있으며, 프로그램 가능 프로세서는 전용 또는 범용 프로그램 가능 프로세서일 수 있으며, 저장 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장치로부터 데이터 및 명령어를 수신하고, 데이터 및 명령어를 해당 저장 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장치에 전송할 수 있다. 본 개시의 방법을 실행하기 위한 프로그램 코드는 하나 또는 복수의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 전용 컴퓨터 또는 기타 프로그램 가능 데이터 처리 장치의 프로 세서 또는 컨트롤러에 제공하여, 프로그램 코드가 프로세서 또는 컨트롤러에 의해 실행될 때 흐름도 및/또는 블 록도에서 규정한 기능/동작이 실시되도록 할 수 있다. 프로그램 코드는 완전히 기계에서 실행되거나, 부분적으 로 기계에서 실행되거나, 독립적인 소프트웨어 패키지로서 부분적으로 기계에서 실행되면서 부분적으로 원격 기 계에서 실행되거나, 완전히 원격 기계 또는 서버에서 실행될 수 있다. 본 개시 내용의 맥락에서, 기계 판독 가능 매체는 명령어 실행 시스템, 장치 또는 설비에 의해 사용되거나, 명 령어 실행 시스템, 장치 또는 설비와 결합하여 사용되도록 제공하는 프로그램을 포함하거나 저장할 수 있는 매 체일 수있다. 기계 판독 가능 매체는 기계 판독 가능 신호 매체 또는 기계 판독 가능 저장 매체일 수 있다. 기 계 판독 가능 매체는 전자, 자기, 광학, 전자기, 적외선 또는 반도체 시스템, 장치 또는 기기, 또는 이들의 임 의의 적절한 조합을 포함할 수 있지만 이에 한정되지 않는다. 기계 판독 가능 저장 매체의 보다 구체적인 예에 는 하나 또는 복수의 전선에 기반한 전기 연결, 휴대용 컴퓨터 디스크, 하드 디스크, 임의기억장치 (RAM), 읽기 전용 기억 장치 (ROM), 소거 가능 프로그램 가능 읽기 전용 기억 장치 (EPROM 또는 플래시 메모리), 광섬유, 휴 대용 컴팩트 디스크 읽기 전용 기억 장치 (CD-ROM), 광학 저장 장치, 자기 저장 장치 또는 이들의 임의의 적절 한 조합을 포함할 수 있다. 사용자와의 인터랙션을 제공하기 위하여, 여기에 설명된 시스템 및 기술을 컴퓨터에서 실시할 수 있다. 이 컴퓨 터는 사용자에게 정보를 표시하는 디스플레이 장치(예: CRT(음극선관) 또는 LCD(액정 디스플레이) 모니터) 및 사용자가 컴퓨터에 입력을 제공할 수 있는 키보드 및 위치 결정 장치(예를 들면, 마우스 또는 트랙볼)를 구비한 다. 다른 유형의 장치도 사용자와의 인터랙션을 제공하기 위해 사용될 수 있다. 예를 들면, 사용자에게 제공되 는 피드백은 모든 형태의 감지 피드백(예를 들면, 시각 피드백, 청각 피드백 또는 촉각 피드백) 일 수 있고, 모 든 형태(소리 입력, 음성 입력 또는 촉각 입력을 포함)를 이용하여 사용자로부터의 입력을 접수할 수 있다. 여기에 설명된 시스템 및 기술을 백그라운드 부품을 포함하는 컴퓨팅 시스템(예를 들면, 데이터 서버로 함) 또 는 미들웨어 부품을 포함하는 컴퓨팅 시스템(예를 들면, 애플리케이션 서버) 또는 프론트 엔드 부품을 포함하는 컴퓨팅 시스템(예를 들면, 그래픽 유저 인터페이스 또는 웹 브라우저를 가지고 있는 사용자 컴퓨터이며, 사용자 가 상기 그래픽 유저 인터페이스 또는 웹 브라우저를 통하여 여기에 설명된 시스템 및 기술의 실시 형태과 인터 랙션할 수 있다) 또는 이러한 백그라운드 부품, 미들웨어 부품, 또는 프런트 엔드 부품의 모든 조합을 포함하는 컴퓨팅 시스템에서 실시할 수 있다. 임의의 형식 또는 매체의 디지털 데이터 통신(예를 들면, 통신 네트워크)을 통해 시스템의 부품을 서로 연결할 수 있다. 통신 네트워크의 예로는 근거리 통신망(LAN), 광역 통신망(WAN) 및 인터넷을 포함한다. 통신 네트워크의 예로는 근거리 통신망(LAN), 광역 통신망(WAN) 및 인터넷을 포함한다. 통 신 네트워크의 예로는 근거리 통신망(LAN), 광역 통신망(WAN) 및 인터넷을 포함한다. 컴퓨터 시스템은 클라이언트와 서버를 포함할 수 있다. 클라이언트와 서버는 일반적으로 서로 멀리 떨어져 있으 며, 일반적으로 통신 네트워크를 통해 인터랙션한다. 클라이언트와 서버간의 관계는 해당 컴퓨터에서 실행되고 서로 클라이언트-서버 관계를 갖는 컴퓨터 프로그램에 의해 생성된다. 위에 나타낸 다양한 형태의 흐름을 사용하여 동작을 다시 순서 배열, 추가 또는 삭제할 수 있음을 이해해야 한 다. 예를 들면, 본 출원에 기재된 각 동작은 본 개시에서 개시하는 기술 방안이 기대하는 결과를 구현할 수 있 는 한, 병행하여 실행하거나 순차적으로 실행하거나 다른 순서로 실행할 수도 있으며, 본 명세서에서는 여기에 대해서 제한을 하지 않는다. 상술한 구체적인 실시방식은 본 출원의 청구범위에 대한 제한을 구성하지 않는다. 해당 발명이 속하는 기술 분 야에서 통상의 지식을 가진 자라면 설계 요구 및 기타 요소에 따라 다양한 수정, 조합, 서브 조합 및 대체를 진 행할 수 있음을 이해해야 한다. 본 출원의 정신과 원칙내에서 이루어진 모든 수정, 동등한 교체 및 개선 등은 본 출원의 청구범위내에 포함되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2022-0180171", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면은 본 방안을 보다 잘 이해하는 데 사용되며, 본 개시에 대한 한정이 되지 않는다. 그중에, 도 1은 본 개시의 실시예에 따른 데이터 인터랙션 방법과 장치의 시스템 아키텍처를 개략적으로 나타내며, 도 2는 본 개시의 실시예에 따른 데이터 인터랙션 방법의 흐름도를 개략적으로 나타내며. 도 3은 본 개시의 다른 실시예에 따른 데이터 인터랙션 방법의 설명도를 개략적으로 나타내며, 도 4는 본 개시의 일 실시예에 따른 음소 데이터의 결정의 설명도를 개략적으로 나타내며,도 5는 본 개시의 일 실시예에 따른 목표 입술 모양 이미지 프레임의 결정의 설명도를 개략적으로 나타내며, 도 6은 본 개시의 일 실시예에 따른 목표 비디오 프레임의 얻음의 설명도를 개략적으로 나타내며, 도 7은 본 개시의 일 실시예에 따른 목표 표시 데이터의 얻음의 설명도를 개략적으로 나타내며, 도 8은 본 개시의 또 다른 실시예에 따른 데이터 인터랙션 방법의 흐름도를 개략적으로 나타내며. 도 9는 본 개시의 실시예에 따른 데이터 인터랙션 장치의 블록도를 개략적으로 나타내며, 도 10은 본 개시의 실시예의 데이터 인터랙션 방법을 구현할 수 있는 전자 기기의 블록도를 개략적으로 나타냈 다."}
