{"patent_id": "10-2022-0153756", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0072427", "출원번호": "10-2022-0153756", "발명의 명칭": "메타버스 환경에서 사용자 호응도에 반응하는 인터랙티브 콘텐츠 구현 방법", "출원인": "한국전자통신연구원", "발명자": "김기홍"}}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "메타버스 환경에서 콘텐츠 제공 방법에 있어서,콘텐츠 제공장치가 메타버스 사용자에게 콘텐츠를 제공하는 단계;상기 콘텐츠 제공장치가 상기 콘텐츠에 대응하는 상기 사용자 호응정보를 획득하는 단계;상기 콘텐츠 제공장치가 멀티모달 인공지능 모델을 이용하여 상기 사용자 호응정보에 기초한 사용자 호응도를획득하는 단계 및상기 콘텐츠 제공장치가 상기 사용자 호응도에 기초하여 수정된 콘텐츠를 상기 메타버스 환경에 제공하는 단계를 포함하는,콘텐츠 제공 방법."}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 상기 사용자 호응정보는 사용자의 표정정보, 시선정보 및 동작정보 중 적어도 하나를 포함하고,상기 콘텐츠 제공장치가 멀티모달 인공지능 모델을 이용하여 상기 사용자 호응정보에 기초한 사용자 호응도를획득하는 단계는, 상기 콘텐츠가 미리 정해진 이벤트 시점에 해당하는지 판단하는 단계 및상기 사용자의 표정정보, 시선정보 및 동작정보 중 적어도 하나를 상기 멀티모달 인공지능 모델에 입력하여 상기 사용자 호응도를 획득하는 단계를 포함하는,콘텐츠 제공 방법."}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 콘텐츠 제공장치가 상기 사용자 호응도에 기초하여 수정된 콘텐츠를 상기 메타버스 환경에 제공하는 단계는, 이펙트(Effect) 에셋, 프랍을 리소스 데이터베이스에서 로드함으로써 상기 메타버스 환경에 출력하는 단계를 포함하는,콘텐츠 제공 방법."}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서, 상기 사용자 호응정보는 사용자의 표정정보, 시선정보 및 동작정보 중 적어도 하나를 포함하고,상기 콘텐츠 제공장치가 멀티모달 인공지능 모델을 이용하여 상기 사용자 호응정보에 기초한 사용자 호응도를획득하는 단계는, 상기 콘텐츠가 미리 정해진 콘텐츠 시작시점에 해당하는지 판단하는 단계 및 상기 사용자의 표정정보, 시선정보및 동작정보 중 적어도 하나를 상기 멀티모달 인공지능 모델에 입력하여 상기 사용자 호응도를 획득하는 단계를포함하는, 콘텐츠 제공 방법."}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서,공개특허 10-2024-0072427-3-상기 콘텐츠 제공장치가 상기 사용자 호응도에 기초하여 수정된 콘텐츠를 상기 메타버스 환경에 제공하는 단계는,상기 콘텐츠 시나리오 중 획득된 호응도 수준에 상응하는 시나리오로 변경하여 출력하거나, 현재 진행중인 시나리오 이후에 출력하여 변경된 콘텐츠를 제공하는 단계를 포함하는, 콘텐츠 제공 방법."}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,상기 멀티모달 인공지능 모델은 복수개의 합성곱 신경망을 포함하고, 상기 복수개의 합성곱 신경망 각각은 사용자의 표정정보, 시선정보 및 동작정보 각각에 대응하는 특징을 출력하는,콘텐츠 제공 방법."}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서,상기 멀티모달 인공지능 모델은 순환 신경망을 포함하고, 상기 순환 신경망은 상기 복수개의 합성곱 신경망 각각으로부터 출력된 상기 사용자의 표정정보, 시선정보 및 동작정보에 기초한 사용자 호응도를 출력하는,콘텐츠 제공 방법."}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "메타버스 환경에서 콘텐츠를 제공하는 콘텐츠 제공장치에 있어서,메타버스 사용자에게 콘텐츠를 제공하는 재생부;상기 콘텐츠에 대응하는 상기 사용자 호응정보를 획득하는 촬영부;멀티모달 인공지능 모델을 이용하여 상기 사용자 호응정보에 기초한 사용자 호응도를 획득하고, 상기 사용자 호응도에 기초하여 수정된 콘텐츠를 상기 메타버스 환경에 제공하는 프로세서를 포함하는,콘텐츠 제공 장치."}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서, 상기 사용자 호응정보는 사용자의 표정정보, 시선정보 및 동작정보 중 적어도 하나를 포함하고,상기 프로세서는 상기 콘텐츠가 미리 정해진 이벤트 시점에 해당하는 경우, 상기 사용자의 표정정보, 시선정보및 동작정보 중 적어도 하나를 상기 멀티모달 인공지능 모델에 입력하여 상기 사용자 호응도를 획득하는 콘텐츠 제공 장치."}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,상기 프로세서는 상기 콘텐츠가 미리 정해진 이벤트 시점에 해당하는 경우, 이펙트(Effect) 에셋, 프랍을 리소스 데이터베이스에서 로드함으로써 상기 사용자 호응도에 기초하여 수정된 콘텐츠를 상기 메타버스 환경에 제공하는,콘텐츠 제공 장치."}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 8항에 있어서, 상기 사용자 호응정보는 사용자의 표정정보, 시선정보 및 동작정보 중 적어도 하나를 포함하고,상기 프로세서는, 상기 콘텐츠가 미리 정해진 콘텐츠 시작시점에 해당하는 경우, 상기 사용자의 표정정보, 시선공개특허 10-2024-0072427-4-정보 및 동작정보 중 적어도 하나를 상기 멀티모달 인공지능 모델에 입력하여 상기 사용자 호응도를 획득하는,콘텐츠 제공 장치."}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 프로세서는, 상기 콘텐츠 시나리오 중 획득된 호응도 수준에 상응하는 시나리오로 변경하여 출력하거나,현재 진행중인 시나리오 이후에 출력하여 변경된 콘텐츠를 제공하는,콘텐츠 제공 장치."}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 8항에 있어서,상기 멀티모달 인공지능 모델은 복수개의 합성곱 신경망을 포함하고, 상기 복수개의 합성곱 신경망 각각은 사용자의 표정정보, 시선정보 및 동작정보 각각에 대응하는 특징을 출력하는,콘텐츠 제공 장치."}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서,상기 멀티모달 인공지능 모델은 순환 신경망을 포함하고, 상기 순환 신경망은 상기 복수개의 합성곱 신경망 각각으로부터 출력된 상기 사용자의 표정정보, 시선정보 및 동작정보에 기초한 사용자 호응도를 출력하는,콘텐츠 제공 장치."}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "인공지능 모델을 이용하여 메타버스 환경에 콘텐츠를 제공하기 위한 학습장치에 있어서,사용자 호응도와 관련된 감정 유발을 위해 설계된 자극 동영상, 정지영상 또는 사운드 등을 저장하고 있는 자극저장부;상기 콘텐츠를 재생하는 재생부;적어도 하나의 카메라를 이용하여 사용자 표정 및 시선, 자세 및 동작 정보를 획득하는 촬영부;사용자가 설정한 특정구간들을 저장하는 사용자 입력처리부;상기 특정구간의 콘텐츠를 사용자에게 제공하고, 미리 정해진 기준에서 호응도 점수를 획득하여, 상기 특정구간의 영상 시퀀스 데이터들을 사용자가 결정한 호응도 점수로 레이블링 함으로써 학습 데이터를 생성하는 레이블링부를 포함하는,학습 장치."}
{"patent_id": "10-2022-0153756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15항에 있어서,상기 특정구간은 사용자의 마우스나 리모콘을 클릭을 통하여 마킹된 시점들 중 앞선 시점을 온셋포인트, 후행시점을 엔딩포인트로 설정하고, 상기 온셋포인트 및 엔딩포인트 사이를 포함하는 것인,학습 장치."}
{"patent_id": "10-2022-0153756", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시 예는 메타버스 환경에서 콘텐츠 제공 방법, 콘텐츠 제공장치 및 학습장치에 있어서, 콘텐츠 제공 장치가 메타버스 사용자에게 콘텐츠를 제공하는 단계, 상기 콘텐츠 제공장치가 상기 콘텐츠에 대응하는 상기 사 용자 호응정보를 획득하는 단계, 상기 콘텐츠 제공장치가 멀티모달 인공지능 모델을 이용하여 상기 사용자 호응 정보에 기초한 사용자 호응도를 획득하는 단계 및 상기 콘텐츠 제공장치가 상기 사용자 호응도에 기초하여 수정 된 콘텐츠를 상기 메타버스 환경에 제공하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0153756", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 메타버스 환경에 접속한 복수의 사용자 호응도에 기초하여 메타버스 환경에서 제공되는 콘텐츠를 변 경하는 방법에 관한 것이다."}
{"patent_id": "10-2022-0153756", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 다양한 회사들이 광고 혹은 기업의 이벤트 홍보를 위하여 일반인을 대상으로 다양한 미디어 또는 콘텐츠를 제작하여 웹사이트, 매스컴 등을 제공하고 있다. 또한 비대면 서비스가 급부상하면서 복수의 사용자가 온라인 상에서 상호작용가능한 메타버스형 콘텐츠들이 활성화되고 있다. 다만, 상기 메타버스 환경에서 제공되는 콘텐츠는 저작자의 경험과 창의성에 기반을 두고 제작되므로, 사용자가 상기 콘텐츠들에 얼마나 큰 만족감과 호감을 갖는지 정량적으로 확인할 수 있는 방법론이 미흡하였다. 최근에는 생체신호나 행위 등의 센싱을 통해서 사용자들의 감정상태를 파악하여 이를 서비스 효용성을 분석하는 토대로 활용되는 예시도 존재한다. 구체적으로, 콘텐츠를 시청하는 사용자의 얼굴을 촬영한 얼굴 이미지를 분석하여 사용자의 감정상태를 분석하는 기술, 생체신호 센서로 전두엽 부분에서 검출한 뇌전도(EEG)를 분석하여 사용자의 감정을 도출하는 기술 등이 예시이다. 다만, 종래의 방법들은 콘텐츠를 접하거나 경험하는 사람들의 감정상태를 파악하는데 중점을 두거나, 혹은 분석 된 감정상태를 토대로 콘텐츠의 효용성을 평가하는 용도로 사용되며, 실시간으로 메타버스 환경에서 제공되는 콘텐츠를 변화시켜주는 방법론은 부재하였다."}
{"patent_id": "10-2022-0153756", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 인공지능을 이용하여, 메타버스 환경에 접속한 복수의 사용자들이 제공받는 콘텐츠를 사용자 호응도 에 기초하여 변경하기 위함이다."}
{"patent_id": "10-2022-0153756", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시는 메타버스 환경에서 콘텐츠 제공 방법에 있어서, 콘텐츠 제공장치가 메타버스 사용자에게 콘텐츠를 제 공하는 단계, 상기 콘텐츠 제공장치가 상기 콘텐츠에 대응하는 상기 사용자 호응정보를 획득하는 단계, 상기 콘 텐츠 제공장치가 멀티모달 인공지능 모델을 이용하여 상기 사용자 호응정보에 기초한 사용자 호응도를 획득하는 단계 및 상기 콘텐츠 제공장치가 상기 사용자 호응도에 기초하여 수정된 콘텐츠를 상기 메타버스 환경에 제공하 는 단계를 포함하는, 콘텐츠 제공 방법을 개시한다. 또한, 상기 사용자 호응정보는 사용자의 표정정보, 시선정보 및 동작정보 중 적어도 하나를 포함하고, 상기 콘 텐츠 제공장치가 멀티모달 인공지능 모델을 이용하여 상기 사용자 호응정보에 기초한 사용자 호응도를 획득하는 단계는, 상기 콘텐츠가 미리 정해진 이벤트 시점에 해당하는지 판단하는 단계 및 상기 사용자의 표정정보, 시 선정보 및 동작정보 중 적어도 하나를 상기 멀티모달 인공지능 모델에 입력하여 상기 사용자 호응도를 획득하는 단계를 포함할 수 있다. 또한, 상기 콘텐츠 제공장치가 상기 사용자 호응도에 기초하여 수정된 콘텐츠를 상기 메타버스 환경에 제공하는 단계는, 이펙트(Effect) 에셋, 프랍을 리소스 데이터베이스에서 로드함으로써 상기 메타버스 환경에 출력하는 단계를 포함할 수 있다. 또한 상기 콘텐츠 제공장치가 멀티모달 인공지능 모델을 이용하여 상기 사용자 호응정보에 기초한 사용자 호응 도를 획득하는 단계는, 상기 콘텐츠가 미리 정해진 콘텐츠 시작시점에 해당하는지 판단하는 단계 및 상기 사용 자의 표정정보, 시선정보 및 동작정보 중 적어도 하나를 상기 멀티모달 인공지능 모델에 입력하여 상기 사용자 호응도를 획득하는 단계를 포함할 수 있다. 또한, 상기 콘텐츠 제공장치가 상기 사용자 호응도에 기초하여 수정된 콘텐츠를 상기 메타버스 환경에 제공하는 단계는, 상기 콘텐츠 시나리오 중 획득된 호응도 수준에 상응하는 시나리오로 변경하여 출력하거나, 현재 진행 중인 시나리오 이후에 출력하여 변경된 콘텐츠를 제공하는 단계를 포함할 수 있다. 또한, 상기 멀티모달 인공지능 모델은 복수개의 합성곱 신경망을 포함하고, 상기 복수개의 합성곱 신경망 각각 은 사용자의 표정정보, 시선정보 및 동작정보 각각에 대응하는 특징을 출력할 수 있다. 또한, 상기 멀티모달 인공지능 모델은 순환 신경망을 포함하고, 상기 순환 신경망은 상기 복수개의 합성곱 신경 망 각각으로부터 출력된 상기 사용자의 표정정보, 시선정보 및 동작정보에 기초한 사용자 호응도를 출력할 수 있다. 본 발명의 실시 예에 따른 메타버스 환경에서 콘텐츠를 제공하는 콘텐츠 제공장치는 메타버스 사용자에게 콘텐 츠를 제공하는 재생부, 상기 콘텐츠에 대응하는 상기 사용자 호응정보를 획득하는 촬영부, 멀티모달 인공지능 모델을 이용하여 상기 사용자 호응정보에 기초한 사용자 호응도를 획득하고, 상기 사용자 호응도에 기초하여 수 정된 콘텐츠를 상기 메타버스 환경에 제공하는 프로세서를 포함할 수 있다. 또한, 상기 프로세서는 상기 콘텐츠 가 미리 정해진 이벤트 시점에 해당하는 경우, 상기 사용자의 표정정보, 시선정보 및 동작정보 중 적어도 하나 를 상기 멀티모달 인공지능 모델에 입력하여 상기 사용자 호응도를 획득할 수 있다. 또한, 상기 프로세서는 상기 콘텐츠가 미리 정해진 이벤트 시점에 해당하는 경우, 이펙트(Effect) 에셋, 프랍을 리소스 데이터베이스에서 로드함으로써 상기 사용자 호응도에 기초하여 수정된 콘텐츠를 상기 메타버스 환경에 제공할 수 있다. 또한, 상기 프로세서는, 상기 콘텐츠가 미리 정해진 콘텐츠 시작시점에 해당하는 경우, 상기 사용자의 표정정보, 시선정보 및 동작정보 중 적어도 하나를 상기 멀티모달 인공지능 모델에 입력하여 상기 사용자 호응 도를 획득할 수 있다. 또한, 상기 프로세서는, 상기 콘텐츠 시나리오 중 획득된 호응도 수준에 상응하는 시나리오로 변경하여 출력하 거나, 현재 진행중인 시나리오 이후에 출력하여 변경된 콘텐츠를 제공할 수 있다. 본 개시의 실시 예에 따른 인공지능 모델을 이용하여 메타버스 환경에 콘텐츠를 제공하기 위한 학습장치는, 사 용자 호응도와 관련된 감정 유발을 위해 설계된 자극 동영상, 정지영상 또는 사운드 등을 저장하고 있는 자극저 장부, 상기 콘텐츠를 재생하는 재생부, 적어도 하나의 카메라를 이용하여 사용자 표정 및 시선, 자세 및 동작 정보를 획득하는 촬영부, 사용자가 설정한 특정구간들을 저장하는 사용자 입력처리부, 상기 특정구간의 콘텐츠 를 사용자에게 제공하고, 미리 정해진 기준에서 호응도 점수를 획득하여, 상기 특정구간의 영상 시퀀스 데이터 들을 사용자가 결정한 호응도 점수로 레이블링 함으로써 학습 데이터를 생성하는 레이블링부를 포함할 수 있다. 또한, 상기 특정구간은 사용자의 마우스나 리모콘을 클릭을 통하여 마킹된 시점들 중 앞선 시점을 온셋포인트, 후행 시점을 엔딩포인트로 설정하고, 상기 온셋포인트 및 엔딩포인트 사이를 포함할 수 있다."}
{"patent_id": "10-2022-0153756", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시는 인공지능을 이용하여, 메타버스 환경에 접속한 복수의 사용자들이 제공받는 콘텐츠에 대한 사용자 호 응도에 기초하여 콘텐츠 제공자가 제공하는 콘텐츠를 변경함으로써, 메타버스 환경 사용자들에게 보다 새로운 콘텐츠 경험과 높은 만족감을 줄 수 있다. 또한 서비스 제공자들에게도 사용자들의 호응도에 대한 객관적인 결과 데이터를 피드백해줌으로써 서비스의 품 질을 제고할 수 있다."}
{"patent_id": "10-2022-0153756", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 설명하는 기술은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면 에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 이하 설명하는 기술을 특정한 실시 형태에 대해 한정하려 는 것이 아니며, 이하 설명하는 기술의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2, A, B 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 해당 구성요소들은 상기 용어 들에 의해 한정되지는 않으며, 단지 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예 를 들어, 이하 설명하는 기술의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 본 명세서에서 사용되는 용어에서 단수의 표현은 문맥상 명백하게 다르게 해석되지 않는 한 복수의 표현을 포함 하는 것으로 이해되어야 하고, \"포함한다\" 등의 용어는 설명된 특징, 개수, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 의미하는 것이지, 하나 또는 그 이상의 다른 특징들이나 개수, 단계 동작 구성요 소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 배제하지 않는 것으로 이해되어야 한다. 도면에 대한 상세한 설명을 하기에 앞서, 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기 능 별로 구분한 것에 불과함을 명확히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이 하에서 설명할 구성부 각각은 자신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의 해 전담되어 수행될 수도 있음은 물론이다. 또, 방법 또는 동작 방법을 수행함에 있어서, 상기 방법을 이루는 각 과정들은 문맥상 명백하게 특정 순서를 기 재하지 않은 이상 명기된 순서와 다르게 일어날 수 있다. 즉, 각 과정들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 먼저, 이하 설명에서 사용되는 용어에 대한 정의는 아래와 같다. 본 개시의 실시 예에 따른 '메타버스'는 실제 생활과 법적으로 인정한 활동인 직업, 금융, 학습 등이 연결된 가상 세계를 의미할 수 있다. 구체적으로 가상현실, 증강현실의 상위 개념으로서 현실을 디지털 기반의 가상 세계로 확장해 가상 공간에서 모든 활동을 할 수 있게 만드는 시스템을 의미할 수 있다. 본 개시의 실시 예에 따른 '콘텐츠'는 동영상, 문서, 이미지, VR, AR 콘텐츠를 포함할 수 있으며 전자장치 또는 어플리케이션을 통해 디코딩 가능한 정보를 포함할 수 있다. 본 개시의 실시 예에 따른 '사용자 호응정보'는 이후 설명할 '사용자 호응도'를 도출하기 위한 다양한 정보를 포함할 수 있다. 예를 들어, 사용자 호응정보는 사용자의 표정정보, 시선정보, 사용자 동작정보(사용자 자세, 동작, 제스쳐 등) 등을 포함할 수 있다. '사용자 호응도'는 상기 사용자 호응정보에 따른 정도를 스코어로 나타낸 것일 수 있다. 예를 들어 사용자 호응 정보로부터 추출된 특징에 기초하여 사용자 반응의 정도가 기 설정된 정도를 초과하는 경우 사용자 호응도는 높 게 측정될 수 있으며, 사용자 반응의 정도가 기 설정된 정도보다 낮은 경우 사용자 호응도는 낮게 측정될 수 있 다. 본 개시의 실시 예에 따른 멀티모달 인공지능 모델은 상기 사용자 호응정보에 기초하여 사용자 호응도를 도출하 기 위하여 설계된 인공신경망 모델을 의미할 수 있다. 본 개시의 실시 예에 따른 '메타버스 서비스 제공자'는 상기 메타버스 환경을 제공할 수 있으며, 상기 메타버스 서비스는 특정단말기 또는 서버나 클라우드를 통해 구현 가능할 것이다. 또한 '콘텐츠 제공자'는 상기 메타버스 환경에서 실행되는 콘텐츠의 저작자 또는 제공자를 의미할 수 있다. 콘 텐츠 제공자가 사용하는 단말기 또는 서버는 콘텐츠 제공장치로 명명할 수 있다. 구현 예시에 따라 메타버스 서비스 제공자와 콘텐츠 제공자가 동일할 수 있다. 본 개시의 실시 예에 따른 사용자는 상기 메타버스 환경에 접속하는 유저(USER)에 해당할 수 있으며, 사용자 단 말기는 사용자가 사용하는 전자장치를 의미할 수 있다. 사용자 단말기의 예시로는 휴대폰, 노트북, HMD(Head Mounted Display), VR 장치, 등 메타버스에 접속할 수 있는 다양한 장치를 포함할 수 있다. 이하 사용자가 메타버스 환경에서 수행하는 동작은 사용자 단말기를 통해 서비스 제공자 또는 콘텐츠 제공장치 에 전송될 수 있으며, 사용자 단말기, 콘텐츠 제공자 단말기, 서비스 제공자 단말기는 입력된 데이터를 일정하게 처리하고 특정 모델이나 알고리즘에 따라 콘텐츠 제공에 필요한 연산을 수행하는 장치를 포함할 수 있다. 예 컨대, 콘텐츠 제공장치는 PC, 네트워크상의 서버, 스마트기기, 설계 프로그램이 임베딩된 칩셋 등과 같은 형태 로 구현될 수 있다. 이하 메타버스 환경에서 가상 콘텐츠 환경에 참여하는 복수의 사용자들이 표출하는 콘텐츠에 대한 호응도에 기 초하여 콘텐츠를 변경하는 구성에 대하여 설명한다. 도 1은 본 개시의 일 실시예에 사용자 콘텐츠 제공 환경을 나타낸 예시이다. 한편, 도 1은 콘텐츠에 대응하는 사용자 호응도를 획득하기 위한 콘텐츠 제공 환경을 나타낸 것이며, 상기 콘텐 츠 제공환경을 구현하기 위한 시스템은 인공지능 모델 학습환경과 유사하게 구현될 수 있다. 상기 시스템은 디스플레이 및 스피커를 포함하는 출력장치, 사용자 동작정보를 수신하기 위한 적어도 하나 이상 의 촬영부 및 메타버스 환경을 제공하는 사용자 단말기를 포함할 수 있다. 구현 예시에 따라 사용자 단말기 에 탑재된 출력부 및 카메라가 상기 출력장치 및 카메라의 역할을 수행하는 것 또한 가능하다. 콘텐츠 제공자 관점에서 상기 도 1의 콘텐츠 제공시스템은 인공지능 모델 학습을 위한 시스템일 수 있다. 구체적으로 콘텐츠 제공자가 제공하는 콘텐츠에 사용자들이 어떻게 반응 혹은 호응하는지 파악하기 위하여 인공 지능 모델의 학습에 필요한 학습데이터를 수집하는 시스템일 수 있다. 학습데이터 수집시, 사용자들이 특정 콘텐츠를 시청하는 상황에서 사용자 단말기 또는 상기 시스템에 구비된 촬 영부(카메라 등을 포함)를 통하여 사용자의 얼굴표정, 시선 및 신체 동작에 대한 데이터(정지영상 혹은 동영 상)을 획득할 수 있다. 한편, 인공지능 모델의 성능 향상을 위하여 다양한 학습데이터를 획득하는 것이 중요하다. 예를 들어 사용자가 보이는 반응에 대한 다양한 동작, 시선, 표정 영상을 획득하는 것이 매우 중요하다. 상기 인공지능 모델의 학습 데이터는 기쁨, 감동, 슬픔 등의 긍정 및 부정과 관련된 여러가지 감정상태 및 상기 감정상태를 유도할 수 있는 정지영상, 동영상, 사운드 등의 자극정보를 포함할 수 있다. 상기 자극정보는 디스플레이나 스피커 등을 통해 사용자에게 제공된 콘텐츠에 대하여 각 사용자들의 반응 양상 을 촬영부로 촬영함으로써 획득될 수 있다. 상기 획득된 데이터는 학습데이터로 데이터베이스화될 수 있다. 본 발명의 실시 예에 따른 학습데이터는 사용자의 선호도, 자극역치, 인종, 성별, 나이, 국적, 언어 등 다양한 요소(factor)에 기초하여 형성될 수 있다. 예를 들어, 동일한 콘텐츠 영상 혹은 사운드의 자극정보라 할지라도 복수의 사용자 각각의 호응도는 선호도, 인 종, 성별, 나이, 국적, 언어 등 다양한 요소에 기초하여 상이할 수 있으므로 학습데이터를 생성하기 위한 사용 자가 촬영 전 준비단계에서 사용자 각각으로 하여금 특정 감정상태와 관련해서 본인이 선호하는 것을 자유로이 선택하게 함으로써 학습데이터를 생성하는 것 또한 가능하다. 이하 본 발명의 인공지능 모델의 학습 과정에 대하여 설명한다. 도 2는 본 발명의 일 실시 예에 따른 인공지능모델을 학습하는 과정을 나타낸 것이다. 도 2를 참고하면, 적어도 하나 이상의 콘텐츠를 사용자에게 제공하여 이에 상응하는 사용자 호응도를 획득하고, 이를 데이터베이스화하여 저장함으로써 학습데이터를 생성하는 과정을 나타낸다. 도 2에 나타난 동작의 주체는 학습장치일 수 있으며, 상기 학습장치는 별도의 장비로 구비되어 학습 데이터베이 스를 저장할 수 있으며 저장된 데이터베이스는 콘텐츠 제공장치로 제공되거나 학습을 위한 서버로 전송될 수 있 다. 또한 학습장치는 콘텐츠 제공장치일 수 있다. 학습장치에 의해 인공지능 모델의 학습이 이루어지고 난 이후, 학습장치가 수행했던 동작과 동일하게 콘텐츠 제 공장치는 사용자 호응도를 획득할 수 있다. 따라서 콘텐츠 제공장치는 학습장치의 구성을 모두 포함하는 것으로 해석될 수 있다. 본 개시의 실시 예에 따르면, 학습장치는 콘텐츠를 저장하는 자극저장부, 콘텐츠를 선택하는 선택부, 콘텐츠를 재생시키는 자극재생부, 사용자를 촬영하는 촬영부, 촬영부와 자극재생부를 동기화시 키는 동기화부, 사용자 입력을 처리하는 사용자 입력처리부, 사용자 설문을 저장하는 사용자 설문부 , 데이터레이블링 및 저장을 수행하는 저장부(80,90)을 포함할 수 있다. 상기 구성요소들은 전기적 또는 구조적으로 연결되어 있으며 적어도 하나 이상의 프로세서에 의해 동작될 수 있을 것이다. 선택부는 호응도와 관련된 감정 유발을 위해 설계된 자극 동영상, 정지영상 또는 사운드 등을 저장하고 있 는 자극저장부로부터 콘텐츠를 선택하고, 재생부는 상기 선택된 콘텐츠를 재생할 수 있다. 이때 자극재생부는 촬영부와 동기화 되고, 상기 촬영부는 적어도 하나의 카메라를 이용하여 사용자 표정 및 시선, 자세 및 동작 정보를 획득할 수 있다. 사용자 입력처리부는 콘텐츠를 시청하는 사용자가 설정한 특정구간들을 저장할 수 있다. 이때, 상기 특정구 간은 사용자의 마우스나 리모콘을 클릭을 통하여 마킹될 수 있으며 상기 마킹한 시점들 중 앞선 시점을 Onset point, 후행 시점을 Ending point로 설정하고, 상기 온셋 포인트 및 엔딩포인트 사이를 특정 구간으로 설정될 수 있다. 이하 도 3에서 상세히 설명한다. 사용자 설문부는 상기 특정 구간의 콘텐츠를 사용자에게 다시금 제공하고, 설문을 통해 미리 정해진 기준에 서 적절한 호응도 점수를 획득할 수 있다. 레이블링부 및 데이터저장부는 특정구간의 영상 시퀀스 데이터들을 사용자가 결정한 호응도 점수로 레 이블링 함으로써 학습 데이터를 생성할 수 있다. 도 3은 본 발명의 실시 예에 따른 인공지능모델의 학습 과정 중 사용자가 호응도 높은 부분을 마킹하는 과정에 관한 것이다. 본 발명의 실시 예에 따르면, 학습데이터는 콘텐츠의 전체 구간 중 특정 구간에 획득된 사용자의 표정, 시선, 자세 및 동작정보에 따른 호응도 점수로 생성될 수 있다. 다시말해, 특정구간의 '사용자의 표정, 시선, 자세 및 동작 정보'와 '사용자 호응도'(점수)는 학습데이터 페어(pair)로 저장될 수 있다. 한편, 사용자의 표정, 시선, 자세 및 동작정보 중 적어도 하나 이상의 정보가 사용되는 것 또한 가능하다. 상기 특정 구간은 사용자에 의해 설정될 수 있다. 예를 들어, 학습장치는 사용자에게 동영상 콘텐츠를 시청하다 가 호감도가 높은 장면 구간이 나타날 무렵에 무선 마우스나 리모콘 등을 클릭(Onset point)하도록 요청하고, 호감도가 낮아졌다고 판단하는 시점에 한번 더 클릭(Ending point)을 하도록 요청함으로써 상기 콘텐츠의 특정 구간을 설정할 수 있다. 특정구간이 설정되면, 촬영부는 상기 특정구간동안 사용자의 표정, 시선, 자세 및 동작을 촬영하여 사용자 의 표정, 시선, 자세 및 동작 정보를 획득할 수 있다. 또한, 상기 특정 구간의 호응도 점수는 사용자가 추후에 입력함으로써 획득될 수 있다. 한편 상기 특정 구간은 콘텐츠 제공자가 미리 콘텐츠에 설정할 수 있으며, 실제 학습데이터 생성시 콘텐츠 제공 자가 설정한 구간과 사용자에 의해 설정된 특정구간이 상이한 경우, 사용자에 의해 설정된 특정구간에 획득된 사용자 표정, 시선, 자세 및 동작 데이터가 학습에 사용될 수 있을 것이다. 이를 통해 다소 긴 시간동안 사용자들을 카메라로 지속적으로 촬영하고 있기 때문에 어떤 부분에서 높은 호응도 를 보여주는지를 찾아서 해당 부분을 시청 중이었을 때의 사용자 표정과 동작 영상을 학습에 유효한 데이터만 획득할 수 있을 것이다. 도 4는 본 개시의 실시 예에 따른 인공지능 모델의 구성을 나타낸 도면이다. 도 4를 참고하면, 인공지능 모델은 합성공 신경망과 순환신경망으로 구성될 수 있다. 구체적으로 학 습용 입력데이터가 합성곱 신경망에 입력되고, 합성곱 신경망에서 출력된 결과값은 순환신 경망에 입력됨으로써 최종 결과가 도출될 수 있다. 앞서 언급한 바와 같이 인공지능 학습에 필요한 입력 데이터는 복수의 사용자에게 각각 획득한 다양한 표 정정보, 시선정보, 자세정보 및 동작정보이다. 이는 콘텐츠 몰입도, 만족도, 호응도 등 사용자의 감정상태와 연 관성이 높다. 다만, 각각의 사용자마다 외부로 표현 내지는 표출하는 반응 형태가 사람마다 상이할 수 있다. 예를 들어, 상기 반응형태는 인종, 나이, 성격, 문화, 반응 역치 등에 기초하여 상이할 수 있으며, 특정 사람 경우 호응 정도가 표정에 많이 드러나는가 하면 또다른 사람 경우 큰 동작 등으로 쉽게 파악이 가능하다. 따라서 사용자들이 취하게 되는 표정, 시선, 바디 포즈와 같은 몇가지의 특징적인 외형 반응 양상들을 한꺼번에 동시에 획득함으로써 콘텐츠 서비스를 접하거나 경험하는 사람들의 호응 정도를 객관적으로 파악하여야 한다.이는 도 2에서 설명하였다. 본 발명의 실시 예에 따른 인공지능 모델은 사용자의 표정정보, 시선정보, 동작정보(자세정보를 포함할 수 있다) 각각을 합성곱 신경망에 입력하여, 상기 표정정보, 시선정보 및 동작정보 각각에 대한 특징을 검출 할 수 있다. 예를 들어, 합성곱 신경망은 CNN(Convolutional Neural Network)을 포함할 수 있으며, 상기 CNN 모델은 표정정보, 시선정보 및 동작정보 각각에 대응하는 3개의 합성곱 신경망으로 구성될 수 있다. 구체적으로 합성곱 신경망은 표정정보에서 표정종류를 분류할 수 있으며, 시선정보에서 시선방향 검출 및 동작정보에서 동작특징을 검출할 수 있다. 예를 들어 합성곱 신경망은 상기 표정정보를 콘텐츠에 대한 반응으로 나타난 표정을 통해 복수의 감정 상 황을 분류할 수 있다. 상기 감정의 예시로는 Neutral, Happy, Sad, Surprised, Angry, Disgust, Fear 등 의 감정이 존재할 수 있다. 또한, 합성곱 신경망은 헤드 포즈에 따른 시선 방향을 통해 Roll, Pitch, Yaw 정보를 검출하여 재생 되고 있는 콘텐츠에 대한 집중도를 파악할 수 있다. 또한, 합성곱 신경망은 전신 자세 및 동작이나 행동 특징을 검출하여 사용자의 동작 특징을 판별할 수 있다. 상기와 같이 표정, 시선 및 동작특징을 검출함으로써 인공지능 모델은 복수개의 특징정보를 반영한 멀 티모달(multi-modal) 모델일 수 있다. 본 개시의 실시 예에 따르면, 상기와 같이 분류 및 파악된 개별 합성곱 신경망의 출력 결과는 순환 신경망 (RNN; Recurrent Neural Network)에 입력파라미터로 사용될 수 있다. 구체적으로 순환신경망은 입력과 출력을 시퀀스 단위로 처리하는 시퀀스(Sequence) 모델로서, 특정구간에 따라 변화하는 표정, 시선, 동작 및 자세정보를 함께 고려하는 멀티모달 모델일 수 있다. 본 개시의 실시 예에 따르면, 순환신경망은 특정구간에 따라 변화하는 표정, 시선, 동작 및 자세정보에 기초한 호응도 정도 최종 결과로 출력할 수 있다. 한편, 상기 실시예에 따른 합성곱 신경망 및 순환 신경망을 구현하기 위하여, 1단계 학습으로 콘텐츠에 대한 반 응으로 나타난 학습용 입력데이터를 결과 데이터에 라벨링함으로써 학습할 수 있으며 2단계 학습으로 표정, 시선, 동작 및 행동을 함께 고려하는 멀티모달 특징을 기반으로 한 융합(Fusion) 학습을 통해 호응도 정 도를 10점 척도를 기준으로 최종 평가함으로써 사전에 학습이 수행될 수 있다. 도 5는 본 발명의 실시 예에 따른 사용자 호응도에 기초한 콘텐츠 제공 과정을 나타낸 것이다. 먼저 본 발명의 실시 예에 따른 인공지능 모델은 알고리즘 형태로 콘텐츠 제공업체가 이용하는 메타버스 콘텐츠 플랫폼 등에 엔진 형태로 내재화하여 제공될 수 있다. 제공된 인공지능 알고리즘을 통하여 사용자는 콘텐츠 제 공업체가 제공하는 다양한 메타버스형 콘텐츠를 시청할 수 있으며, 콘텐츠 제공 업체는 해당 콘텐츠에 대한 사 용자 호응도를 파악하고 상기 사용자 호응도에 기초하여 제공하는 콘텐츠의 시나리오를 수정 또는 변화시킬 수 있을 것이다. 이를 위해, 메타버스 서비스 제공업체들은 호응 정도에 따른 다양한 시나리오의 콘텐츠 및 이펙트용 에셋 등 리 소스를 미리 제작해서 콘텐츠 제공업체에서 관리하는 서버 혹은 각 사용자들의 기기 등에 저장하도록 펌웨어를 다운로드 시킬 수 있다. 이하 콘텐츠 시나리오가 수정 또는 변경되는 실시예를 도 5 및 도 6을 통하여 구체적으 로 설명한다. 도 6은 본 개시의 실시 예에 따른 메타버스 콘텐츠 변경 시나리오를 나타낸 것이다. 도 6을 참조하면, 서비스 제공업체의 서버로부터 전송된 메타버스 콘텐츠가 시간의 흐름에 따라 전개되어 가는 상황에서 미리 정의해 둔 이벤트(e1, e2, e3)에 진입할 때 폭죽 터뜨리기, 하트 이모티콘 제시하기, 기타 감정 이모티콘, 이모지 등의 특수효과 이벤트를 연출될 수 있다. 또는 콘텐츠 시작시점(S1, S2)에서 메타버스 콘텐츠를 시청하는 복수의 사용자들로부터 획득된 호응도를 이용하 여 콘텐츠 시나리오를 수정 또는 변경하는 하는 예시를 나타낸다.본 발명의 실시 예에 따르면, 복수의 사용자들은 사용자 단말기를 이용하여 메타버스 서비스 제공자의 웹사이트 나 플랫폼에 접속해서 자유로이 메타버스 콘텐츠를 시청할 수 있다. 이때, 콘텐츠 제공장치는 서버 또는 콘텐츠 제공자 단말기를 이용하여 메타버스 콘텐츠를 웹사이트 또는 메타버스 플랫폼에 제공함으로써 사용자 단말기에 해당 콘텐츠를 출력할 수 있다. 각 사용자들의 디바이스에 부착되어 있는 웹캠 등의 카메라는 사용자의 표정, 시선, 동작정보들을 획득하 여 콘텐츠 제공장치로 전송할 수 있다. 상기 콘텐츠 장치에 내재화된 인공지능 알고리즘은 해당 사용자가 표출하는 호응도를 분석할 수 있다. 본 발명의 실시예에 따른 콘텐츠 제공장치는 이벤트 또는 콘텐츠 시작지점에 진입하는 경우 각각의 사용자에게 서 획득된 표정, 시선 및 동작정보를 인공지능 모델에 입력하여 복수의 사용자에게서 파악된 호응도를 각각 도 출하고, 상기 도출된 호응도를 이용하여 해당 시점 혹은 구간에서 제공되고 있는 콘텐츠에 대한 복수의 사용자 전체의 호응도를 측정할 수 있다. 이때, 복수의 사용자 전체의 호응도는 복수의 사용자 호응도 각각을 합산 또는 평균값일 수 있다. 한편, 사용자에게서 획득된 표정, 시선 및 동작정보 중 적어도 하나의 정보를 인공지능 모델에 입력함으로써 호 응도를 산출하는 것 또한 가능하다. 본 개시의 실시 예에 따른 콘텐츠 제공장치는 이벤트(e1,e2,e3) 시점에 산출된 호응도에 기초하여 다양한 이펙 트(Effect) 에셋, 프랍을 리소스 데이터베이스에서 로드함으로써 메타버스 콘텐츠의 환경에 반영함으로써 수정된 콘텐츠를 제공할 수 있다. 이를 통해, 사용자들로 하여금 서비스되고 있는 콘텐츠에 보다 큰 관심을 가지거나 지속적으로 몰입을 하도록 유도할 수 있을 것이다. 또는, 콘텐츠 제공장치는 콘텐츠 시작시점(S1,S2)에 산출된 호응도에 기초하여 사전에 설정되어 있는 여러 시나 리오 중 호응도 수준에 맞는 시나리오를 변경하여 로드하거나, 현재까지 진행되어온 시나리오 뒤에 자연스 럽게 연결해서 전개함으로써 수정 또는 변경된 콘텐츠를 제공할 수 있다. 이를 통해 복수의 사용자들이 콘텐츠의 변화 방향을 결정할 수 있는 인터랙티브 콘텐츠를 제공할 수 있다. 이를 통하여, 시나리오가 풍부한 메타버스 형태의 콘텐츠가 온라인 상에서 서비스되는 상황에서, 해당 서비스의 환경 내에 참여한 대규모의 사용자들이 표출하는 반응양상이나 전체적인 호응도를 콘텐츠 플랫폼 내의 엔진이 실시간으로 지속적으로 분석하여, 그에 맞게 콘텐츠의 흐름이나 메타버스 콘텐츠의 가상환경을 변화시켜 줌으로 써 사용자들에게 보다 새로운 콘텐츠 경험과 높은 만족감을 줄 수 있을 것이다. 나아가서는 서비스 제작자들에 게 대규모 사용자들의 호응도를 피드백해줌으로써 운영 중인 서비스의 품질을 개선하도록 하거나, 혹은 추후 새 로운 메타버스형 서비스를 위해 콘텐츠를 기획 혹은 제작할 때 활용될 수 있을 것이다. 본 개시에 기초한 콘텐츠 제공장치, 사용자 단말기, 단말기 등은 기술 분야에서 통상의 지식을 가진 자는 여기 에 개시된 실시예들과 관련하여 설명된 다양한 예시적인 논리 블록들, 모듈들, 프로세서들, 수단들, 회로들 및 알고리즘 단계들이 전자 하드웨어, (편의를 위해, 여기에서 소프트웨어로 지칭되는) 다양한 형태들의 프로그램 또는 설계 코드 또는 이들 모두의 결합에 의해 구현될 수 있다는 것을 이해할 것이다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6"}
{"patent_id": "10-2022-0153756", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 콘텐츠 제공 환경 예시를 나타낸다. 도 2는 본 발명의 일 실시 예에 따른 인공지능모델을 학습하는 과정을 나타낸 것이다. 도 3은 본 발명의 실시 예에 따른 인공지능모델의 학습 과정 중 사용자가 호응도 높은 부분을 마킹하는 과정에 관한 것이다. 도 4는 본 발명의 실시 예에 따른 인공지능모델의 구성을 나타낸 것이다. 도 5는 본 발명의 실시 예에 따른 사용자 호응도에 기초한 콘텐츠 제공 과정을 나타낸 것이다. 도 6은 본 발명의 실시 예에 따른 사용자 호응도에 기초한 콘텐츠 제공 과정을 예시를 나타낸 것이다."}
