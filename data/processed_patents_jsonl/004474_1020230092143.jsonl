{"patent_id": "10-2023-0092143", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0012209", "출원번호": "10-2023-0092143", "발명의 명칭": "인공지능 영상분석에 기반한 정밀좌표를 포함하는 객체정보를 도출하는 방법 및 시스템", "출원인": "주식회사 핀텔", "발명자": "김동기"}}
{"patent_id": "10-2023-0092143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "1 이상의 프로세서 및 1 이상의 메모리를 포함하는 컴퓨팅시스템에서 수행되는 객체정보를 생성하는방법으로서,상기 컴퓨팅시스템은 복수의 분석모듈, 이벤트정보생성모듈 및 트래킹모듈을 포함하고,제1분석모듈에 의하여, 제1카메라의 영상에서 제1객체를 검지하는 제1객체검지단계;이벤트정보생성모듈에 의하여, 상기 제1카메라의 영상을 변형하여, 정밀지도이미지에 정합시키고, 상기 정밀지도이미지에서의 좌표정보에 기초하여, 상기 제1객체의 실제좌표를 추출하는 제1실제좌표추출단계;제2분석모듈에 의하여, 제2카메라의 영상에서 제2객체를 검지하는 제2객체검지단계;이벤트정보생성모듈에 의하여, 상기 제2카메라의 영상을 변형하여, 정밀지도이미지에 정합시키고, 상기 정밀지도이미지에서의 좌표정보에 기초하여, 상기 제2객체의 실제좌표를 추출하는 제2실제좌표추출단계; 및트래킹모듈에 의하여, 상기 제1카메라에서 검지된 제1객체와 상기 제2카메라에서 검지된 제2객체를 통합적으로트래킹하는 트래킹단계;를 포함하고,상기 트래킹단계는,상기 제1분석모듈, 제2분석모듈 및 이벤트정보생성모듈로부터 객체속성정보 및 해당 객체의 실제좌표정보를 수신하여, 실제좌표계에서의 각각의 객체에 대한 트래킹정보를 생성하는 트래킹정보생성단계; 및동일 혹은 상응하는 시간구간에서 상기 제1객체의 실제좌표와 상기 제2객체의 실제좌표의 오차가 기설정된 오차범위 이내인 경우에는 상기 제1객체와 상기 제2객체에 대해 동일한 객체아이디를 부여하여 상기 트래킹정보를수정하는 제1트래킹정보수정단계;를 포함하는, 객체정보를 생성하는 방법."}
{"patent_id": "10-2023-0092143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 객체속성정보는 객체종류 혹은 객체이미지의 특징정보를 포함하고,상기 제1실제좌표추출단계 및 상기 제2실제좌표추출단계 각각은,이벤트정보생성모듈에 의하여, 카메라로부터 객체가 검지된 영상의 원본이미지, 상기 원본이미지에서 검지된 객체영역에 대한 바운딩박스 위치정보, 및 객체속성정보를 수신하는 검지정보수신단계;이벤트정보생성모듈에 의하여, 객체가 검지된 영상에 해당하는 영역의 일부 혹은 전체를 포함하고, 각각의 픽셀에 실제좌표가 직접적 혹은 간접적으로 매핑되어 있는 정밀지도이미지를 생성하는 관련정밀지도이미지생성단계;이벤트정보생성모듈에 의하여, 상기 바운딩박스 및 상기 원본이미지를 포함하는 바운딩박스이미지를 변형하여,상기 바운딩박스이미지에 포함되는 상기 원본이미지가 상기 정밀지도이미지에 정합되도록 하는 이미지정합단계;이벤트정보생성모듈에 의하여, 변형된 바운딩박스이미지에서의 바운딩박스의 위치정보를 상기 정밀지도이미지에서의 실제좌표의 매핑정보를 적용함으로써, 상기 바운딩박스의 실제좌표를 추출하는 실제좌표추출단계;를 포함하는, 객체정보를 생성하는 방법."}
{"patent_id": "10-2023-0092143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,공개특허 10-2025-0012209-3-상기 이미지정합단계에서는,상기 원본이미지에 2 이상의 제1마커객체가 설정되어 있고,상기 정밀지도이미지에 상기 원본이미지에서의 제1마커객체 각각에 상응하는 제2마커객체가 설정되어 있고,각각의 제1마커객체의 이미지와 해당 제2마커객체의 이미지 간의 차이가 최소화되도록 상기 바운딩박스이미지를변형하는, 객체정보를 생성하는 방법."}
{"patent_id": "10-2023-0092143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 이미지정합단계는,상기 바운딩박스이미지를 회전하거나,상기 바운딩박스이미지를 늘리거나,상기 바운딩박스이미지를 줄이고,상기 바운딩박스이미지를 늘리는 경우에, 상기 바운딩박스이미지를 구성하는 픽셀 각각의 위치마다 상기 바운딩박스이미지의 원근 왜곡에 기반하여 서로 다른 배수를 적용하여 상기 바운딩박스이미지를 늘리고,상기 바운딩박스이미지를 줄이는 경우에, 상기 바운딩박스이미지를 구성하는 픽셀 각각의 위치마다 상기 바운딩박스이미지의 원근 왜곡에 기반하여 서로 다른 배수를 적용하여 상기 바운딩박스이미지를 줄이는, 객체정보를생성하는 방법."}
{"patent_id": "10-2023-0092143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 2에 있어서,상기 바운딩박스의 위치정보는 상기 바운딩박스의 x축좌표, y축좌표, 높이 및 너비를 포함하고,상기 실제좌표의 매핑정보는 상기 정밀지도이미지를 구성하는, 픽셀 혹은 기설정된 영역마다 x축좌표 및 y축좌표를 포함하는 기설정된 실제좌표에 해당하고,상기 정밀지도이미지에 상기 변형된 바운딩박스이미지에서의 바운딩박스의 위치정보에 상응하는 실제좌표를 추출하는, 객체정보를 생성하는 방법."}
{"patent_id": "10-2023-0092143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서,상기 트래킹단계는 제2트래킹정보수정단계를 더 포함하고,상기 제2트래킹정보수정단계는,제1시간구간에서의 상기 제1객체의 실제좌표와 상기 제1시간구간 이후에 해당하는 제2시간구간에서의 상기 제2객체의 실제좌표의 차이가 기설정된 제1기준 이내에 해당하는 지 여부를 판단하는 객체판단단계;상기 객체판단단계의 판단결과 및 상기 제1객체의 객체속성정보와 상기 제2객체의 객체속성정보의 유사도로부터제1스코어를 산출하는 제1스코어산출단계;상기 제2시간구간에서 상기 제1객체의 예측되는 실제좌표의 예측정보와 상기 제2객체의 실제좌표와의 차이에 의하여 도출되는 제2스코어를 도출하는 제2스코어도출단계; 및상기 제1스코어와 상기 제2스코어의 합이 기설정된 제2기준을 초과하는 경우에는 상기 제1객체와 상기 제2객체에 대해 동일한 객체아이디를 부여하여 상기 트래킹정보를 수정하는 스코어합산단계;를 더 포함하는, 객체정보공개특허 10-2025-0012209-4-를 생성하는 방법."}
{"patent_id": "10-2023-0092143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,상기 예측정보는,상기 트래킹모듈이 상기 제1시간구간에서 상기 제1객체의 복수의 위치정보로부터 각각의 속도벡터를 도출하고,상기 제1객체의 제1시간구간의 마지막에서의 위치 및 기존의 속도벡터로부터 도출된 예상속도벡터를 적용하여,상기 제1객체의 제2시간구간에서의 예상위치로 산출되는, 객체정보를 생성하는 방법."}
{"patent_id": "10-2023-0092143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "1 이상의 프로세서 및 1 이상의 메모리를 포함하고, 객체정보를 생성하는 방법을 수행하는 컴퓨팅시스템으로서,상기 컴퓨팅시스템은 복수의 분석모듈, 이벤트정보생성모듈 및 트래킹모듈을 포함하고,제1분석모듈에 의하여, 제1카메라의 영상에서 제1객체를 검지하는 제1객체검지단계;이벤트정보생성모듈에 의하여, 상기 제1카메라의 영상을 변형하여, 정밀지도이미지에 정합시키고, 상기 정밀지도이미지에서의 좌표정보에 기초하여, 상기 제1객체의 실제좌표를 추출하는 제1실제좌표추출단계;제2분석모듈에 의하여, 제2카메라의 영상에서 제2객체를 검지하는 제2객체검지단계;이벤트정보생성모듈에 의하여, 상기 제2카메라의 영상을 변형하여, 정밀지도이미지에 정합시키고, 상기 정밀지도이미지에서의 좌표정보에 기초하여, 상기 제2객체의 실제좌표를 추출하는 제2실제좌표추출단계;트래킹모듈에 의하여, 상기 제1카메라에서 검지된 제1객체와 상기 제2카메라에서 검지된 제2객체를 통합적으로트래킹하는 트래킹단계;상기 트래킹단계는,상기 제1분석모듈 및 상기 제2분석모듈로부터 객체속성정보 및 해당 객체의 실제좌표정보를 수신하여, 실제좌표계에서의 각각의 객체에 대한 트래킹정보를 생성하는 트래킹정보생성단계; 및동일 혹은 상응하는 시간구간에서 상기 제1객체의 실제좌표와 상기 제2객체의 실제좌표의 오차가 기설정된 오차범위 이내인 경우에는 상기 제1객체와 상기 제2객체에 대해 동일한 객체아이디를 부여하여 상기 트래킹정보를수정하는 제1트래킹정보수정단계;를 수행하는, 컴퓨팅시스템."}
{"patent_id": "10-2023-0092143", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 영상분석에 기반한 정밀좌표를 포함하는 객체정보를 도출하는 방법 및 시스템으로서, 2 이상 의 카메라를 통해 검지되는 복수의 객체의 실제좌표를 추출하고, 상기 복수의 객체의 움직임에 대해 트래킹하여 트래킹정보를 생성하고, 각각의 카메라로부터 검지된 객체가 동일한 객체인지를 시간 및 실제좌표에 따라 판단하 고, 판단결과에 따라 객체에 객체아이디를 부여하여 트래킹정보를 수정하는, 인공지능 영상분석에 기반한 정밀좌 표를 포함하는 객체정보를 도출하는 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0092143", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 영상분석에 기반한 정밀좌표를 포함하는 객체정보를 도출하는 방법 및 시스템으로서, 2 이 상의 카메라를 통해 검지되는 복수의 객체의 실제좌표를 추출하고, 상기 복수의 객체의 움직임에 대해 트래킹하 여 트래킹정보를 생성하고, 각각의 카메라로부터 검지된 객체가 동일한 객체인지를 시간 및 실제좌표에 따라 판 단하고, 판단결과에 따라 객체에 객체아이디를 부여하여 트래킹정보를 수정하는, 인공지능 영상분석에 기반한 정밀좌표를 포함하는 객체정보를 도출하는 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0092143", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "바운딩박스(Bounding Box) 객체검지기술은 컴퓨터 비전과 딥러닝을 활용하여 카메라로부터 획득한 영상에서 객 체를 식별하고, 해당 객체 주위에 경계 상자인 바운딩박스를 그리는 기술이다. 해당 기술은 컴퓨터 비전 분야에 서 많은 응용 분야에서 활용되며, 자율 주행 자동차, 보안 시스템, 스마트 모니터링 등 다양한 분야에서 사용된다. 구체적으로, 카메라를 통해 획득된 영상에서 비전 알고리즘 및 딥러닝 기술이 활용되어 검지된 객체에 대해 주로 사각형 형태의 바운딩박스가 생성되고, 해당 객체가 어떤 클래스에 속하는지 분류할 수 있고, 해당 바운딩 박스를 원본 영상에 시각화하여 해당 바운딩박스를 통해 객체의 위치를 용이하게 추적할 수 있다. 또한, 이미지 와핑(Image Warping)이란, 기하하적 변형(Geometric Transformation)의 한 종류로서, 이미지에 묘사된 모양이 왜곡되도록 이미지를 디지털 방식으로 조작하는 기술이다. 즉, 이미지에서 (x, y)의 위치에 있는 픽셀을 다른 위치인 (x',y')로 대응시키되, 픽셀별로 이동 정도를 달리하여 대응시키는 기술로서, 쉽게 말해 영 상 이미지를 회전시키거나 찌그러트려서 변형하는 기술이다. 일반적으로 이미지 와핑은, 우주 망원경에서 촬영 한 우주 이미지를 보기 쉽도록 변형하거나, 영화 제작 중 특수효과로 쓰이며, 대중적으로는 스마트폰 앱 중에 문서를 카메라로 촬영한 후, 이를 PDF 파일로 변환할 때 사용된다. 이와 같이, 이미지 와핑은 다양한 분야에서 사용되며, 이미지 처리 및 분석에 필수적인 기술이다. 최근 자율주행차의 수요가 꾸준히 늘어남에 따라, 자율주행차를 이용하는 운전자들이 요구하는 기술수준 또한 증가하고 있다. 자율주행차는 서버로부터 받은 신호나 교통정보를 활용하여 주행 전략을 결정하고, 실시간으로 경로를 수정하거나 주행속도를 조절한다. 그러나 자율주행차로 실시간 송신되는 도로교통정보에 대하여, 독립적 으로 작동하는 카메라들이나 카메라의 시야가 일시적으로 가려지는 등 외부요인들로 인해 동일한 객체에 대하여 개별적인 식별자(ID)가 할당되거나, 개별적인 객체에 대하여 동일한 식별자가 할당되는 경우가 있다. 이와 같이 객체에 대해 식별자가 혼란스러워지는 경우로 인해 자율주행차에 입력되는 도로교통정보에 대한 신뢰도가 낮아 지고 있다. 그러므로 복수의 카메라에서 검지되는 객체들에 대하여 부여되는 식별자의 정확도를 높이는 기술의 개발이 필요 한 상황이다."}
{"patent_id": "10-2023-0092143", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 인공지능 영상분석에 기반한 정밀좌표를 포함하는 객체정보를 도출하는 방법 및 시스템으로서, 2 이 상의 카메라를 통해 검지되는 복수의 객체의 실제좌표를 추출하고, 상기 복수의 객체의 움직임에 대해 트래킹하 여 트래킹정보를 생성하고, 각각의 카메라로부터 검지된 객체가 동일한 객체인지를 시간 및 실제좌표에 따라 판 단하고, 판단결과에 따라 객체에 객체아이디를 부여하여 트래킹정보를 수정하는, 인공지능 영상분석에 기반한 정밀좌표를 포함하는 객체정보를 도출하는 방법 및 시스템을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2023-0092143", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 과제를 해결하기 위하여 본 발명의 일 실시예에서는, 1 이상의 프로세서 및 1 이상의 메모리를 포 함하는 컴퓨팅시스템에서 수행되는 객체정보를 생성하는 방법으로서, 상기 컴퓨팅시스템은 복수의 분석모듈, 이 벤트정보생성모듈 및 트래킹모듈을 포함하고, 제1분석모듈에 의하여, 제1카메라의 영상에서 제1객체를 검지하는 제1객체검지단계; 이벤트정보생성모듈에 의하여, 상기 제1카메라의 영상을 변형하여, 정밀지도이미지에 정합시 키고, 상기 정밀지도이미지에서의 좌표정보에 기초하여, 상기 제1객체의 실제좌표를 추출하는 제1실제좌표추출 단계; 제2분석모듈에 의하여, 제2카메라의 영상에서 제2객체를 검지하는 제2객체검지단계; 이벤트정보생성모듈 에 의하여, 상기 제2카메라의 영상을 변형하여, 정밀지도이미지에 정합시키고, 상기 정밀지도이미지에서의 좌표 정보에 기초하여, 상기 제2객체의 실제좌표를 추출하는 제2실제좌표추출단계; 및 트래킹모듈에 의하여, 상기 제 1카메라에서 검지된 제1객체와 상기 제2카메라에서 검지된 제2객체를 통합적으로 트래킹하는 트래킹단계;를 포 함하고, 상기 트래킹단계는, 상기 제1분석모듈, 제2분석모듈 및 이벤트정보생성모듈로부터 객체속성정보 및 해 당 객체의 실제좌표정보를 수신하여, 실제좌표계에서의 각각의 객체에 대한 트래킹정보를 생성하는 트래킹정보 생성단계; 및 동일 혹은 상응하는 시간구간에서 상기 제1객체의 실제좌표와 상기 제2객체의 실제좌표의 오차가 기설정된 오차범위 이내인 경우에는 상기 제1객체와 상기 제2객체에 대해 동일한 객체아이디를 부여하여 상기 트래킹정보를 수정하는 제1트래킹정보수정단계;를 포함하는, 객체정보를 생성하는 방법을 제공한다. 본 발명의 일 실시예에서는, 상기 객체속성정보는 객체종류 혹은 객체이미지의 특징정보를 포함하고, 상기 제1 실제좌표추출단계 및 상기 제2실제좌표추출단계 각각은, 이벤트정보생성모듈에 의하여, 카메라로부터 객체가 검지된 영상의 원본이미지, 상기 원본이미지에서 검지된 객체영역에 대한 바운딩박스 위치정보, 및 객체속성정보 를 수신하는 검지정보수신단계; 이벤트정보생성모듈에 의하여, 객체가 검지된 영상에 해당하는 영역의 일부 혹 은 전체를 포함하고, 각각의 픽셀에 실제좌표가 직접적 혹은 간접적으로 매핑되어 있는 정밀지도이미지를 생성 하는 관련정밀지도이미지생성단계; 이벤트정보생성모듈에 의하여, 상기 바운딩박스 및 상기 원본이미지를 포함 하는 바운딩박스이미지를 변형하여, 상기 바운딩박스이미지에 포함되는 상기 원본이미지가 상기 정밀지도이미지 에 정합되도록 하는 이미지정합단계; 이벤트정보생성모듈에 의하여, 변형된 바운딩박스이미지에서의 바운딩박스 의 위치정보를 상기 정밀지도이미지에서의 실제좌표의 매핑정보를 적용함으로써, 상기 바운딩박스의 실제좌표를 추출하는 실제좌표추출단계;를 포함할 수 있다. 본 발명의 일 실시예에서는, 상기 이미지정합단계에서는, 상기 원본이미지에 2 이상의 제1마커객체가 설정되어 있고, 상기 정밀지도이미지에 상기 원본이미지에서의 제1마커객체 각각에 상응하는 제2마커객체가 설정되어 있 고, 각각의 제1마커객체의 이미지와 해당 제2마커객체의 이미지 간의 차이가 최소화되도록 상기 바운딩박스이미 지를 변형할 수 있다. 본 발명의 일 실시예에서는, 상기 이미지정합단계는 학습된 인공신경망 기반의 이미지정합모델을 통해, 상기 바 운딩박스이미지를 회전하거나, 상기 바운딩박스이미지를 늘리거나, 상기 바운딩박스이미지를 줄이고, 상기 바운 딩박스이미지를 늘리는 경우에, 상기 바운딩박스이미지를 구성하는 픽셀 각각의 위치마다 상기 바운딩박스이미 지의 원근 왜곡에 기반하여 서로 다른 배수를 적용하여 상기 바운딩박스이미지를 늘리고, 상기 바운딩박스이미 지를 줄이는 경우에, 상기 바운딩박스이미지를 구성하는 픽셀 각각의 위치마다 상기 바운딩박스이미지의 원근 왜곡에 기반하여 서로 다른 배수를 적용하여 상기 바운딩박스이미지를 줄일 수 있다. 본 발명의 일 실시예에서는, 상기 바운딩박스의 위치정보는 상기 바운딩박스의 x축좌표, y축좌표, 높이 및 너비 를 포함하고, 상기 실제좌표의 매핑정보는 상기 정밀지도이미지를 구성하는, 픽셀 혹은 기설정된 영역마다 x축 좌표 및 y축좌표를 포함하는 기설정된 실제좌표에 해당하고, 상기 정밀지도이미지에 상기 변형된 바운딩박스이 미지에서의 바운딩박스의 위치정보에 상응하는 실제좌표를 추출할 수 있다. 본 발명의 일 실시예에서는, 상기 트래킹단계는 제2트래킹정보수정단계를 더 포함하고, 상기 제2트래킹정보수정 단계는, 제1시간구간에서의 상기 제1객체의 실제좌표와 상기 제1시간구간 이후에 해당하는 제2시간구간에서의 상기 제2객체의 실제좌표의 차이가 기설정된 제1기준 이내에 해당하는 지 여부를 판단하는 객체판단단계; 상기 제1객체 및 상기 제2객체의 객체속성정보의 유사도로부터 제1스코어를 산출하는 제1스코어산출단계; 상기 제2시 간구간에서 상기 제1객체의 예측되는 실제좌표의 예측정보와 상기 제2객체의 실제좌표와의 차이에 의하여 제2스 코어를 산출하는 제2스코어산출단계; 및 상기 제1스코어와 상기 제2스코어의 합이 기설정된 제2기준을 초과하는 경우에는 상기 제1객체와 상기 제2객체에 대해 동일한 객체아이디를 부여하여 상기 트래킹정보를 수정하는 스코 어합산단계;를 더 포함할 수 있다. 본 발명의 일 실시예에서는, 상기 예측정보는, 상기 트래킹모듈이 상기 제1시간구간에서 상기 제1객체의 복수의 위치정보로부터 각각의 속도벡터를 도출하고, 상기 제1객체의 제1시간구간의 마지막에서의 위치 및 기존의 속도 벡터로부터 도출된 예상속도벡터를 적용하여, 상기 제1객체의 제2시간구간에서의 예상위치로 산출될 수 있다. 상기와 같은 과제를 해결하기 위하여 본 발명의 일 실시예에서는, 1 이상의 프로세서 및 1 이상의 메모리를 포 함하고, 객체정보를 생성하는 방법을 수행하는 컴퓨팅시스템으로서, 상기 컴퓨팅시스템은 복수의 분석모듈, 이 벤트정보생성모듈 및 트래킹모듈을 포함하고, 제1분석모듈에 의하여, 제1카메라의 영상에서 제1객체를 검지하는 제1객체검지단계; 제1분석모듈에 의하여, 상기 제1카메라의 영상을 변형하여, 정밀지도이미지에 정합시키고, 상 기 정밀지도이미지에서의 좌표정보에 기초하여, 상기 제1객체의 실제좌표를 도출하는 제1실제좌표추출단계; 제2 분석모듈에 의하여, 제2카메라의 영상에서 제2객체를 검지하는 제2객체검지단계; 제2분석모듈에 의하여, 상기 제2카메라의 영상을 변형하여, 정밀지도이미지에 정합시키고, 상기 정밀지도이미지에서의 좌표정보에 기초하여, 상기 제2객체의 실제좌표를 도출하는 제2실제좌표추출단계; 트래킹모듈에 의하여, 상기 제1카메라에서 검지된 제1객체와 상기 제2카메라에서 검지된 제2객체를 통합적으로 트래킹하는 트래킹단계; 상기 트래킹단계는, 상기 제1분석모듈 및 상기 제2분석모듈로부터 객체속성정보 및 해당 객체의 실제좌표정보를 수신하여, 실제좌표계에 서의 각각의 객체에 대한 트래킹정보를 생성하는 트래킹정보생성단계; 및 동일 혹은 상응하는 시간구간에서 상 기 제1객체의 실제좌표와 상기 제2객체의 실제좌표의 오차가 기설정된 오차범위 이내인 경우에는 상기 제1객체 와 상기 제2객체에 대해 동일한 객체아이디를 부여하여 상기 트래킹정보를 수정하는 제1트래킹정보수정단계;를 수행하는, 컴퓨팅시스템을 제공한다."}
{"patent_id": "10-2023-0092143", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에서는, 실제좌표에 기반하여 객체의 트래킹정보를 생성 및 수정함으로써, 종래의 도로 위 에 설치된 카메라로부터 획득된 영상에서 검출된 객체의 움직임에만 기반하여 생성되는 트래킹정보보다 신뢰도 를 높이는 효과를 발휘할 수 있다. 본 발명의 일 실시예에서는, 복수의 카메라가 동일한 영역을 촬영하는 경우와 상이한 영역을 촬영하는 경우에서 의 객체정보를 생성하는 방법을 다르게 하여 신뢰도가 높은 트래킹정보를 생성하는 효과를 발휘할 수 있다. 본 발명의 일 실시예에서는, 복수의 카메라로 도로 위 객체의 움직임을 검지할 때, 실제좌표에 기반하여 해당 객체의 예상위치를 산출하여 서로 다른 카메라를 통해 상이하게 검지되는 객체의 동일여부를 파악하여 객체아이 디를 부여함으로써, 객체속성정보에 대한 신뢰도를 높이고, 컴퓨팅 리소스의 소모를 줄이는 효과를 발휘할 수 있다."}
{"patent_id": "10-2023-0092143", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는, 다양한 실시예들 및/또는 양상들이 이제 도면들을 참조하여 개시된다. 하기 설명에서는 설명을 목 적으로, 하나 이상의 양상들의 전반적 이해를 돕기 위해 다수의 구체적인 세부사항들이 개시된다. 그러나, 이러 한 양상(들)은 이러한 구체적인 세부사항들 없이도 실행될 수 있다는 점 또한 본 발명의 기술 분야에서 통상의 지식을 가진 자에게 인식될 수 있을 것이다. 이후의 기재 및 첨부된 도면들은 하나 이상의 양상들의 특정한 예 시적인 양상들을 상세하게 기술한다. 하지만, 이러한 양상들은 예시적인 것이고 다양한 양상들의 원리들에서의 다양한 방법들 중 일부가 이용될 수 있으며, 기술되는 설명들은 그러한 양상들 및 그들의 균등물들을 모두 포함하고자 하는 의도이다. 또한, 다양한 양상들 및 특징들이 다수의 디바이스들, 컴포넌트들 및/또는 모듈들 등을 포함할 수 있는 시스템 에 의하여 제시될 것이다. 다양한 시스템들이, 추가적인 장치들, 컴포넌트들 및/또는 모듈들 등을 포함할 수 있 다는 점 그리고/또는 도면들과 관련하여 논의된 장치들, 컴포넌트들, 모듈들 등 전부를 포함하지 않을 수도 있 다는 점 또한 이해되고 인식되어야 한다. 본 명세서에서 사용되는 \"실시예\", \"예\", \"양상\", \"예시\" 등은 기술되는 임의의 양상 또는 설계가 다른 양상 또 는 설계들보다 양호하다거나, 이점이 있는 것으로 해석되지 않을 수도 있다. 아래에서 사용되는 용어들 '~부', '컴포넌트', '모듈', '시스템', '인터페이스' 등은 일반적으로 컴퓨터 관련 엔티티(computer-related entity)를 의미하며, 예를 들어, 하드웨어, 하드웨어와 소프트웨어의 조합, 소프트웨어를 의미할 수 있다. 또한, \"포함한다\" 및/또는 \"포함하는\"이라는 용어는, 해당 특징 및/또는 구성요소가 존재함을 의미하지만, 하나 이상의 다른 특징, 구성요소 및/또는 이들의 그룹의 존재 또는 추가를 배제하지 않는 것으로 이해되어야 한다. 또한, 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구 성요소들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구 별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요 소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 또한, 본 발명의 실시예들에서, 별도로 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기 서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되 는 것과 동일한 의미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술 의 문맥 상 가지는 의미와 일치하는 의미를 가지는 것으로 해석되어야 하며, 본 발명의 실시예에서 명백하게 정 의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 1. 인공지능 영상분석에 기반한 정밀좌표를 포함하는 이벤트발생정보를 도출하는 방법 및 시스템 이하에서 후술되는 1. 인공지능 영상분석에 기반한 정밀좌표를 포함하는 이벤트발생정보를 도출하는 방법 및 시 스템은, 본 발명의 2. 인공지능 영상분석에 기반한 정밀좌표를 포함하는 객체정보를 도출하는 방법 및 시스템에 있어서, 영상에서 검지된 객체의 실제좌표를 추출하는 방법에 대해 상세히 기술한 발명에 해당한다. 도 1은 본 발명의 일 실시예에 따른 이벤트발생정보를 생성하는 방법을 수행하는 컴퓨팅시스템을 개략적 으로 도시한다. 도 1에 도시된 바와 같이, 컴퓨팅시스템은 분석모듈, 이벤트정보생성모듈, 및 ROI업데이트모 듈을 포함하고, 도로 위에 설치된 카메라는 해당 도로의 일부를 촬영하며 상기 분석모듈과 유선 혹 은 무선 형태로 연결된다. 구체적으로, 상기 분석모듈은 도로 위에 설치된 카메라로부터 해당 도로의 일부가 촬영된 영상을 실시간 으로 수신한다. 또한, 상기 분석모듈은 학습된 인공신경망 기반의 검지모델을 포함하여, 도로 위에서 교 통사고 혹은 적재물낙하사고 등과 같은 돌발상황에 해당하는 이벤트가 발생 시, 상기 검지모델을 통해 딥러닝 (Deep Learning) 기술을 기반으로 카메라로부터 수신한 영상에서 해당 이벤트를 검지한다. 상기 이벤트정보생성모듈은 이벤트가 검지된 영상의 원본이미지를 상기 분석모듈로부터 수신한다. 일반적으로, 도 1에 도시된 바와 같이, 카메라로 촬영된 이미지는 원근에 의해 왜곡되어 도로 위에 발생한 이벤 트에 대한 위치좌표가 정밀하게 도출되지 못할 수 있다. 그러므로 상기 이벤트정보생성모듈은 해당 원본이미지를 실제좌표가 매핑되어 있는 정밀지도이미지에 정합되도록 각각의 픽셀 혹은 일정 영역을 변형시킨다. 한편, 본 발명의 다른 실시예에서는, 상기 컴퓨팅시스템이 복수의 분석모듈을 포함하여 각각의 분 석모듈에 연결된 복수의 카메라를 통해 도로의 전체영역에 대한 이벤트를 검지할 수 있다. 도 2는 본 발명의 일 실시예에 따른 이벤트발생정보를 생성하는 방법의 수행단계를 개략적으로 도시한다. 도 2에 도시된 바와 같이, 1 이상의 프로세서 및 1 이상의 메모리를 포함하는 컴퓨팅시스템에서 수행되는 이벤트발생정보를 생성하는 방법으로서, 상기 컴퓨팅시스템은 분석모듈, 이벤트정보생성모듈(120 0)을 포함하고, 분석모듈에 의하여, 입력된 영상에 대하여 이벤트를 검지하는 이벤트검지단계(S100); 이 벤트정보생성모듈에 의하여, 상기 분석모듈로부터 이벤트가 검지된 영상의 원본이미지, 상기 원본 이미지에서 이벤트가 발생된 영역에 대한 바운딩박스의 위치정보, 및 이벤트의 속성정보를 수신하는 검지정보수 신단계(S200); 이벤트정보생성모듈에 의하여, 이벤트가 검지된 영상에 해당하는 영역의 일부 혹은 전체를 포함하고, 각각의 픽셀에 실제좌표가 직접적 혹은 간접적으로 매핑되어 있는 정밀지도이미지를 생성하는 관련정 밀지도이미지생성단계(S300); 이벤트정보생성모듈에 의하여, 상기 바운딩박스 및 상기 원본이미지를 포함 하는 바운딩박스이미지를 변형하여, 상기 바운딩박스이미지에 포함되는 상기 원본이미지가 상기 정밀지도이미지 에 정합되도록 하는 이미지정합단계(S400); 이벤트정보생성모듈에 의하여, 변형된 바운딩박스이미지에서 의 바운딩박스의 위치정보를 상기 정밀지도이미지에서의 실제좌표의 매핑정보를 적용함으로써, 상기 바운딩박스 의 실제좌표를 추출하는 실제좌표추출단계(S500); 이벤트정보생성모듈에 의하여, 상기 이벤트의 속성정보 및 상기 바운딩박스의 실제좌표를 포함하는 이벤트발생정보를 생성하는 이벤트발생정보생성단계(S600);를 포함 한다. 구체적으로, 상기 이벤트검지단계(S100)는, 분석모듈에 의해 수행되고, 도로 위에 설치된 카메라로부터 수신한 영상에 대하여 이벤트를 검지하고, 해당 이벤트가 발생된 영역에 대한 바운딩박스를 생성한다. 바람직하 게, 상기 바운딩박스에는 해당 바운딩박스의 위치정보 및 해당 이벤트의 속성정보가 기재될 수 있다. 이 때, 상 기 속성정보는 교통사고 혹은 적재물낙하사고 등과 같이 해당 이벤트에 대한 구체적인 정보를 포함한다. 상기 검지정보수신단계(S200)는, 이벤트정보생성모듈에 의해 수행되고, 상기 이벤트검지단계(S100)를 통 해 이벤트가 검지된 영상의 원본이미지, 상기 이벤트검지단계(S100)를 통해 생성된 바운딩박스의 위치정보 및 해당 이벤트의 속성정보를 상기 분석모듈로부터 수신한다. 그러나 상기 바운딩박스의 위치정보는 원근으 로 인해 왜곡된 원본이미지에서의 위치정보로서, 정밀한 위치좌표라 할 수 없다. 상기 컴퓨팅시스템은 해 당 이벤트에 대한 정확한 위치를 파악하여 운전자 혹은 자율주행차가 해당 이벤트에 대한 대비를 용이하게 할 수 있도록 하기 위해서, 실제좌표가 매핑되어 있는 정밀지도이미지를 통해 왜곡된 원본이미지에 실제좌표를 적 용할 필요가 있다. 상기 관련정밀지도이미지생성단계(S300)는, 이벤트정보생성모듈에 의해 수행되고, 상기 이벤트검지단계 (S100)를 통해 이벤트가 검지된 영상에 상기 이벤트가 발생한 영역을 포함하는 이미지의 일부 혹은 전체에 대해 서, 각각의 픽셀에 실제좌표가 직접적 혹은 간접적으로 매핑 되어 있는 정밀지도이미지를 생성한다. 즉, 상기 정밀지도이미지의 픽셀은 직접적으로 기설정된 실제좌표가 매핑 될 수 있고, 기설정된 실제좌표가 매핑 되지 않 은 픽셀은 인접픽셀 중 상기 기설정된 실제좌표가 매핑된 복수의 픽셀들에 대한 실제좌표의 평균값에 기반하여 간접적으로 실제좌표가 매핑 될 수 있다. 상기 이미지정합단계(S400)는, 이벤트정보생성모듈에 의해 수행되고, 상기 분석모듈로부터 생성된 바운딩박스 및 원본이미지를 포함하는 바운딩박스이미지를 변형하여 상기 정밀지도이미지에 정합되도록 한다. 바람직하게는, 상기 이벤트정보생성모듈은 바운딩박스이미지에서 이미지가 뚜렷한 제1마커객체(M1 내지 M3, 도 3의 (a) 참고)를 설정하고, 정밀지도이미지에서 상기 제1마커객체(M1 내지 M3)에 상응하는 제2마커객체 (N1 내지 N3, 도 3의 (b) 참고)를 설정하여, 상기 제1마커객체(M1 내지 M3)의 이미지가 해당 제2마커객체(N1 내지 N3)의 이미지에 정합되도록 상기 바운딩박스이미지를 변형한다. 이 때, 바운딩박스이미지를 회전하거나, 원근으 로 인해 왜곡된 정도에 따라 일부 픽셀 혹은 일부 영역을 늘리거나 줄여서 상기 정밀지도이미지에 정합되도록한다. 상기 실제좌표추출단계(S500)는, 이벤트정보생성모듈에 의해 수행되고, 상기 바운딩박스이미지가 상기 정 밀지도이미지에 정합되는 경우, 상기 정밀지도이미지에서의 실제좌표를 상기 바운딩박스이미지에 적용함으로써, 상기 바운딩박스이미지에서 이벤트 발생영역인 바운딩박스의 실제좌표를 추출할 수 있다. 상기 이벤트발생정보생성단계(S600)는, 이벤트정보생성모듈에 의해 수행되고, 검지된 상기 이벤트의 속성 정보 및 상기 바운딩박스의 실제좌표를 포함하는 이벤트발생정보를 생성한다. 상기 이벤트발생정보는 실시간 정 보를 필요로 하는 다양한 분야에 사용될 수 있으며, 특히 네비게이션이나 자율주행차에 적용되어, 도로 위에 발 생한 돌발상황을 해당 운전자 혹은 자율주행차가 직접 인지하기 전에 네비게이션 혹은 자율주행차에게 해당 돌 발상황에 대한 정보를 미리 제공함으로써, 운전자의 안전성을 높이고, 차량의 동선 낭비를 최소화하여 도로 정 체를 감소시키는 효과를 발휘할 수 있다. 도 3은 본 발명의 일 실시예에 따른 원본이미지 및 정밀지도이미지 각각에 설정된 복수의 마커객체를 개략적으 로 도시한다. 도 3에 도시된 바와 같이, 상기 이미지정합단계(S400)에서는, 상기 원본이미지에 2 이상의 제1마커객체가 설정 되어 있고, 상기 정밀지도이미지에 상기 원본이미지에서의 제1마커객체 각각에 상응하는 제2마커객체가 설정되 어 있고, 각각의 제1마커객체의 이미지와 해당 제2마커객체의 이미지 간의 차이가 최소화되도록 상기 바운딩박 스이미지를 변형한다. 개략적으로, 도 3의 (a)는 원본이미지에 설정된 복수의 제1마커객체(M1 내지 M3)를 도시하고, 도 3의 (b)는 정밀 지도이미지에 설정된 제2마커객체(N1 내지 N3)를 도시하고, 도 3의 (c) 내지 (d)는 이미지를 변형하는 과정을 도 시한다. 구체적으로, 도 3의 (a)에 도시된 바와 같이, 바운딩박스이미지에 포함되는 원본이미지는 도로 위에 설치된 카 메라가 도로를 바라보는 방향으로 촬영되고, 도 3의 (b)에 도시된 바와 같이, 실제좌표가 매핑되는 정밀지도이 미지는 일반적으로 도로 위에서 수직으로 내려보는 방향으로 생성된다. 이와 같이, 원본이미지와 정밀지도이미 지는 상이한 시점을 가지므로 상기 원본이미지에 실제좌표가 매핑되기 위해서는, 상기 이벤트정보생성모듈 은 상기 원본이미지를 포함하는 바운딩박스이미지를 회전하거나, 도 3의 (c) 내지 (d)에 도시된 바와 같 이, 원근에 의해 왜곡된 일부 픽셀을 늘리는 등의 변형, 즉, 이미지 와핑(Image Warping)을 통해 상기 원본이미 지가 정밀지도이미지에 정합되도록 한다. 바람직하게는, 바운딩박스이미지가 변형될 때 기준이 되는 마커객체는 도 3의 (a) 내지 (b)에 도시된 바와 같이, 이미지가 뚜렷하고 구체적인 객체로 설정되어 상기 이미지정합단계(S400)가 용이하게 수행되도록 한다. 더 바람직하게는, 학습된 인공신경망 기반의 추출모델(예를 들어, DNN)을 통해 제1마커객체(M1 내지 M3) 및 제2 마커객체(N2 내지 N3) 각각의 외곽선을 추출하고, 상기 제1마커객체(M1 내지 M3)의 외곽선과 해당 제1마커객체(M1 내지 M3)와 상응하는 제2마커객체(N1 내지 N3)의 외곽선의 차이가 최소화되도록 상기 바운딩박스이미지를 변형한 다. 한편, 본 발명의 다른 실시예에서의 마커객체는 도 3의 (a) 내지 (b)에 도시된 바와 같이 3개에 한정하지 아니 하고, 상기 이미지정합단계(S400)가 용이하게 수행될 정도의 개수로 설정되는 것이 바람직하다. 도 4는 본 발명의 일 실시예에 따른 이미지정합단계(S400)의 수행과정을 개략적으로 도시한다. 도 4에 도시된 바와 같이, 상기 이미지정합단계(S400)는, 상기 바운딩박스이미지를 회전하거나, 상기 바운딩박 스이미지를 늘리거나, 상기 바운딩박스이미지를 줄이거나, 상기 바운딩박스이미지를 늘리는 경우에, 상기 바운딩박스이미지를 구성하는 픽셀 각각의 위치마다 상기 바운딩박스이미지의 원근 왜곡에 기반하여 서로 다른 배수 를 적용하여 상기 바운딩박스이미지를 늘리고, 상기 바운딩박스이미지를 줄이는 경우에, 상기 바운딩박스이미지 를 구성하는 픽셀 각각의 위치마다 상기 바운딩박스이미지의 원근 왜곡에 기반하여 서로 다른 배수를 적용하여 상기 바운딩박스이미지를 줄인다. 구체적으로, 도 4는 도 3의 (c) 내지 (d)에 도시된 방법을 통해 바운딩박스이미지 중 원근으로 인해 왜곡된 영 역마다 서로 다른 배수가 적용되어 정밀지도이미지에 정합하도록 변형되는 과정을 개략적으로 도시한다. 상기 이벤트정보생성모듈은 학습된 인공신경망 기반의 이미지정합모델을 통해 바운딩박스이미지를 필요에 따라 회전하거나, 늘리거나, 줄이는 등 상기 바운딩박스이미지를 구성하는 복수의 픽셀 혹은 영역을 변형시킨다. 전술하였듯이, 상기 이벤트정보생성모듈은 상기 바운딩박스이미지에서 발생한 원근 왜곡에 기반하여 상기 바운딩박스이미지를 변형시키는데, 일반적으로 카메라로부터 먼 거리에 있는 객체 혹은 영역의 이미지는 가까운 거리에 있는 객체 혹은 영역의 이미지보다 축소된 형태로 촬영되므로 왜곡이 되어있지 않은 정 밀지도이미지에 바운딩박스이미지가 정합되기 위해서 원근에 의해 왜곡된 정도에 기초하여 상기 바운딩박스이미 지를 보정할 필요가 있다. 상기 이벤트정보생성모듈은 이미지 와핑(Image Warping)을 통해 도 4에 도시된 바와 같이 바운딩박스이미지를 일정 영역으로 나누며, 카메라로부터 먼 거리에 있는 영역은 큰 배수로 늘리고, 상기 카메라로부터 가까운 거리에 있는 영역은 작은 배수로 늘림으로써, 정밀지도이미지에 근접하게 변형된 바 운딩박스이미지를 생성한다. 한편 본 발명의 다른 실시예에서는 바운딩박스이미지를 구성하는 픽셀 단위로 상기 바운딩박스이미지를 변형시킬 수 있다. 도 5는 본 발명의 일 실시예에 따른 실제좌표추출단계(S500)의 수행과정 및 이벤트발생정보생성단계(S600)의 수 행결과를 개략적으로 도시한다. 도 5에 도시된 바와 같이, 상기 바운딩박스의 위치정보는 상기 바운딩박스의 x축좌표, y축좌표, 높이 및 너비를 포함하고, 상기 실제좌표의 매핑정보는 상기 정밀지도이미지를 구성하는, 픽셀 혹은 기설정된 영역마다 x축좌표 및 y축좌표를 포함하는 기설정된 실제좌표에 해당하고, 상기 정밀지도이미지에 상기 변형된 바운딩박스이미지에 서의 바운딩박스의 위치정보에 상응하는 실제좌표를 추출한다. 개략적으로 도 5의 (a)는 실제좌표추출단계(S500)의 수행과정을 도시하고, 도 5의 (b)는 이벤트발생정보생성단 계(S600)의 수행결과를 도시한다. 구체적으로, 도 5의 (a)는 변형된 바운딩박스이미지에 포함된 바운딩박스의 실제좌표를 추출하는 과정을 도시한 다. 이벤트가 검지된 바운딩박스의 실제좌표는 상기 변형된 바운딩박스이미지와 정합되는 정밀지도이미지에서의 (x1, y1)좌표에 해당하고, 상기 바운딩박스의 높이가 h1, 너비가 w1에 해당하는 경우 상기 바운딩박스의 위치정보 는 (x1, y1, h1, w1)이 된다. 도 5의 (b)에 도시된 바와 같이, 촬영된 영상 중 frame1에 해당하는 이미지에서 이벤트가 검지되었을 때, 이벤 트정보생성모듈은 이벤트발생정보생성단계(S600)를 통해, 해당 이벤트 혹은 해당 이벤트의 주체인 객체에 대하여 고유ID를 부여할 수 있으며, 해당 객체의 분류, 해당 객체에 대한 바운딩박스의 위치정보 및 해당 이벤 트의 속성정보를 포함하는 이벤트발생정보를 생성한다. 검지된 이벤트에 대하여 생성된 이벤트발생정보는 해당 이벤트발생정보가 실시간으로 필요한 다양한 분야의 서 비스 혹은 시스템으로 송신되어 사용될 수 있다. 특히, 운전자 혹은 자율주행차로부터 멀리 떨어진 곳에서 이벤 트가 발생하였을 경우, 운전자의 시각 혹은 자율주행차에 탑재된 라이다(Lidar) 센서 등으로 돌발상황을 감지하 지 못할 수 있다. 그러므로 운전자 혹은 자율주행차가 해당 서비스 혹은 시스템을 제공하는 서버로부터 돌발상 황에 대한 정보를 미리 수신하고 대처를 함으로써, 운전자에게 주행 중 높은 안전성과 편리함을 제공하는 효과 를 발휘할 수 있다.도 6은 본 발명의 일 실시예에 따른 ROI실좌표생성단계의 수행과정을 개략적으로 도시한다. 도 6에 도시된 바와 같이, 상기 컴퓨팅시스템은 ROI업데이트모듈을 더 포함하고, 상기 이벤트정보 를 생성하는 방법은, ROI실좌표생성단계 및 ROI재생성단계를 더 포함하고, 상기 ROI실좌표생성단계는, ROI업데 이트모듈에 의하여, ROI바운딩박스 및 원본이미지를 포함하는 ROI바운딩박스이미지를 변형하여, 상기 ROI 바운딩박스이미지에 포함되는 상기 원본이미지가 정밀지도이미지에 정합되도록 하는 ROI이미지정합단계; 및 ROI 업데이트모듈에 의하여, 변형된 ROI바운딩박스이미지에서의 ROI바운딩박스를 구성하는 꼭지점의 위치정보 를 상기 정밀지도이미지에서의 실제좌표의 매핑정보를 적용함으로써, 상기 ROI바운딩박스의 실제좌표를 추출하 는, ROI실좌표추출단계;를 포함한다. 개략적으로, 도 6의 (a)는 ROI실좌표생성단계의 수행과정을 도시하고, 도 6의 (b)는 외부요인으로 인해 시야가 변동된 이미지에서의 ROI를 도시한다. 구체적으로, ROI(Region Of Interest)는 관심영역으로, 특정 영역에 대하여 정보를 추출하거나 분석하기 위해 사용되며, 특히 본 발명의 일 실시예로서 도로에서 설정되는 ROI는 예기치 못한 교통사고 등을 주의 깊게 식별 하고 분석함으로써, 자율주행차량이 주행 결정을 용이하게 내릴 수 있도록 하는 기준이 된다. 그러므로 도 6의 (a)에 도시된 바와 같이, 이미지 위에 설정되는 ROI 또한 정보의 신뢰를 위해 정밀지도에서의 실제좌표에 기반 하여 설정될 필요가 있다. ROI이미지정합단계는 ROI업데이트모듈에 의해 수행되고, ROI바운딩박스 및 원본이미지를 포함하는 ROI바 운딩박스이미지를 변형하여 상기 정밀지도이미지에 정합되도록 한다. 이 때, 상기 ROI바운딩박스는 ROI의 영역 에 해당한다. 바람직하게는, 상기 ROI업데이트모듈은 ROI바운딩박스이미지에서 이미지가 뚜렷한 제1마커 객체를 설정하고, 이에 상응하는 정밀지도이미지에서의 제2마커객체를 설정하고, 해당 제2마커객체를 기준으로 상기 ROI바운딩박스이미지를 변형하여 상기 정밀지도이미지에 정합되도록 한다. 이 때, ROI바운딩박스이미지를 회전하거나, 원근으로 인해 왜곡된 정도에 따라 일부 픽셀을 늘리거나 줄여서 상기 정밀지도이미지에 정합되도 록 한다. 도 6의 (a)는 A1-A2 선을 B1-B2 선만큼 늘리고, A3-A4 선을 B3-B4 선만큼 줄이는 등의 과정을 통해 ROI 바운딩박스를 변형하는 과정을 예시적으로 도시한다. ROI실좌표추출단계는 ROI업데이트모듈에 의해 수행되고, 변형된 ROI바운딩박스이미지의 원본이미지가 상 기 정밀지도이미지에 정합되는 경우, 상기 정밀지도이미지에서의 실제좌표를 상기 ROI바운딩박스이미지에 적용 하여 상기 ROI바운딩박스의 실제좌표를 추출한다. 이 때, 상기 ROI바운딩박스의 실제좌표는 상기 ROI바운딩박스 를 구성하는 복수의 꼭지점의 실제좌표에 해당한다. 한편, 도 6의 (b)에 도시된 바와 같이, 일반적으로 도로에서의 ROI는 초기 촬영된 원본이미지의 좌표를 기준으 로 설정되고, 구체적으로, 4개의 꼭지점 각각의 좌표에 기반하여 ROI바운딩박스가 도로 위에 오버레이(Overlay) 형태로 설정된다. 그런데 외부요인으로 인해 카메라의 위치가 변동되어 해당 카메라가 기존에 촬영하던 원본이 미지에서 시야가 바뀐 변동원본이미지가 촬영되는 경우가 발생할 수 있는데, 이러한 경우 상기 변동원본이미지 에서의 ROI는 상기 원본이미지에 따라 기설정된 4개의 꼭지점 각각의 좌표에 기반하여 정상적인 ROI영역에서 살 짝 빗겨간 영역으로 오버레이되어 해당 ROI에서 추출되는 정보의 신뢰도가 크게 하락될 수 있다. 상기 ROI업데 이트모듈은 이러한 문제를 방지하기 위하여 기존에서 벗어난 ROI를 보정하고, 기존 목적에 맞는 위치좌표 에 재생성할 필요가 있다. 도 7은 본 발명의 일 실시예에 따른 ROI재생성단계의 수행과정을 개략적으로 도시한다. 도 7에 도시된 바와 같이, 상기 컴퓨팅시스템은 ROI업데이트모듈을 더 포함하고, 상기 이벤트정보 를 생성하는 방법은, ROI실좌표생성단계 및 ROI재생성단계를 더 포함하고, 상기 ROI재생성단계는, ROI업데이트 모듈에 의하여, 카메라의 위치변동으로 인해 시야가 변동된 변동원본이미지를 변형하여, 상기 변동원본이 미지가 상기 정밀지도이미지에 정합되도록 하는 변동원본이미지정합단계; ROI업데이트모듈에 의하여, 변 형된 변동원본이미지에 상기 ROI실좌표추출단계를 통해 추출한 상기 ROI바운딩박스의 실제좌표를 적용하여 상기 변형된 변동원본이미지에 실제위치에 해당하는 ROI바운딩박스를 생성하는 ROI바운딩박스생성단계; 및 ROI업데이 트모듈에 의하여, 상기 변동원본이미지정합단계를 통해 상기 변동원본이미지를 변형한 과정의 역순으로 상기 ROI바운딩박스 및 상기 변형된 변동원본이미지를 포함하는 변동원본바운딩박스이미지를 역변형하여 상기 변동원본이미지에 정상적으로 ROI가 형성되도록 하는 정상ROI형성단계;를 포함한다. 구체적으로, 변동원본이미지정합단계는 ROI업데이트모듈에 의해 수행되고, 도 6의 (b)에서 전술한 바와 같이, 카메라의 위치변동으로 인해 시야가 변동된 변동원본이미지를 원근으로 인한 왜곡에 기반하여 픽셀 혹은 일정 영역을 변형하여, 변동원본이미지가 상기 정밀지도이미지에 정합되도록 한다. ROI바운딩박스생성단계는 ROI업데이트모듈에 의해 수행되고, 상기 정밀지도이미지에서의 상기 ROI바운딩 박스의 실제좌표(B1 내지 B4)를 변형된 변동원본이미지에 적용하여 상기 변형된 변동원본이미지에 ROI바운딩박스 를 생성함으로써, 상기 변형된 변동원본이미지 및 ROI바운딩박스를 포함하는 변동원본바운딩박스이미지를 생성 한다. 정상ROI형성단계는 ROI업데이트모듈에 의해 수행되고, 실제좌표가 설정된 정밀지도이미지에 따라 변형된 상기 변동원본바운딩박스이미지를 변형과정의 역순으로 역변형함으로써, 기존 영역을 벗어났던 ROI를 보정하여 정상적인 위치좌표에 ROI를 형성한다. 예를 들어, 도 8의 (a)에 도시된 바와 같이, 함수 f(x, y)에 해당하는 이 미지영역이 특정연산을 통해 g(x', y')에 해당하는 이미지영역으로 변형됐다면, 도 8의 (b)에 도시된 바와 같이, 상기 특정연산의 역순에 해당하는 연산을 통해 g(x', y')에 해당하는 이미지영역을 f(x, y)에 해당하는 이미지영역으로 역변형할 수 있다. 2. 인공지능 영상분석에 기반한 정밀좌표를 포함하는 객체정보를 도출하는 방법 및 시스템 이하에서 설명하는 본 발명의 2. 인공지능 영상분석에 기반한 정밀좌표를 포함하는 객체정보를 도출하는 방법 및 시스템은, 상술한 1. 인공지능 영상분석에 기반한 정밀좌표를 포함하는 이벤트발생정보를 도출하는 방법 및 시스템에서 추출한 객체의 실제좌표에 기반하여 객체의 움직임을 트래킹하고, 실제좌표에 기반하여 트래킹된 객 체에 대해 정밀한 객체아이디를 부여하는 방법에 해당한다. 도 9는 본 발명의 일 실시예에 따른 객체정보를 생성하는 방법을 수행하는 컴퓨팅시스템을 개략적으로 도 시한다. 도 9에 도시된 바와 같이, 컴퓨팅시스템은 분석모듈(1100.1 내지 1100.2, 이하 1100), 이벤트정보생성모 듈 및 트래킹모듈을 포함하고, 도로 위에는 복수의 카메라가 설치되어 각각 할당된 영역을 촬영한 다. 상기 복수의 카메라 각각은 자신과 연결된 분석모듈과 무선 혹은 유선형태로 연결된다. 구체적으로, 상기 분석모듈은 자신과 연결된 카메라로부터 촬영된 영상을 실시간으로 수신한다. 또한, 상 기 분석모듈은 학습된 인공신경망 기반의 검지모델을 포함하여, 도로 위에서 객체가 존재하거나 움직이는 경우, 상기 분석모듈은 상기 검지모델을 통해 딥러닝(Deep Learning) 기술을 기반으로 카메라로부터 수신 한 영상에서 해당 객체를 검지한다. 상기 이벤트정보생성모듈은 객체가 검지된 영상의 원본이미지를 복수의 분석모듈로부터 수신한다. 일반적으로, 도 1에 도시된 바와 같이, 카메라로 촬영된 이미지는 원근에 의해 왜곡되어 도로 위의 객체에 대한위치좌표가 정밀하게 도출되지 못할 수 있다. 그러므로 상기 이벤트정보생성모듈은 해당 원본이미지를 실 제좌표가 매핑되어 있는 정밀지도이미지에 정합되도록 각각의 픽셀 혹은 일정 영역을 변형시킴으로써, 상기 정 밀지도이미지에서의 실제좌표에 기초하여 객체의 실제좌표를 추출한다. 상기 트래킹모듈은 각각의 영상에서 검지된 객체에 대하여, 해당 객체의 실제좌표를 트래킹하여 객체의 실제좌표, 이동방향 및 이동속도를 포함하는 트래킹정보를 생성하고, 복수의 객체 각각을 트래킹정보에 기반하 여 구별하고, 구별된 객체마다 고유의 객체아이디를 부여한다. 도 10은 본 발명의 일 실시예에 따른 객체정보를 생성하는 방법의 수행단계를 개략적으로 도시한다. 도 10에 도시된 바와 같이, 1 이상의 프로세서 및 1 이상의 메모리를 포함하는 컴퓨팅시스템에서 수행되 는 객체정보를 생성하는 방법으로서, 상기 컴퓨팅시스템은 복수의 분석모듈, 이벤트정보생성모듈 및 트래킹모듈을 포함하고, 제1분석모듈(1100.1)에 의하여, 제1카메라의 영상에서 제1객체를 검지 하는 제1객체검지단계(S700); 이벤트정보생성모듈에 의하여, 상기 제1카메라의 영상을 변형하여, 정밀지 도이미지에 정합시키고, 상기 정밀지도이미지에서의 좌표정보에 기초하여, 상기 제1객체의 실제좌표를 추출하는 제1실제좌표추출단계(S800); 제2분석모듈(1100.2)에 의하여, 제2카메라의 영상에서 제2객체를 검지하는 제2객체 검지단계(S900); 이벤트정보생성모듈에 의하여, 상기 제2카메라의 영상을 변형하여, 정밀지도이미지에 정 합시키고, 상기 정밀지도이미지에서의 좌표정보에 기초하여, 상기 제2객체의 실제좌표를 추출하는 제2실제좌표 추출단계(S1000); 트래킹모듈에 의하여, 상기 제1카메라에서 검지된 제1객체와 상기 제2카메라에서 검지 된 제2객체를 통합적으로 트래킹하는 트래킹단계(S1100);를 포함한다. 구체적으로, 상기 제1객체검지단계(S700)는 제1분석모듈(1100.1)에 의해 수행되고, 도로 위에 설치된 제1카메라 가 촬영한 영상에서 해당 도로 위에 있는 제1객체를 학습된 인공신경망 기반의 검지모델을 통해 검지한다. 상기 제1실제좌표추출단계(S800)는 이벤트정보생성모듈에 의해 수행되고, 1. 인공지능 영상분석에 기반한 정밀좌표를 포함하는 이벤트발생정보를 도출하는 방법 및 시스템에서 전술한 검지정보수신단계(S200), 관련정밀 지도이미지생성단계(S300), 이미지정합단계(S400) 및 실제좌표추출단계(S500)를 포함한다. 다시 말해, 상기 제1 카메라의 영상을 변형하여, 정밀지도이미지에 정합시키고, 상기 정밀지도이미지에 기설정된 실제좌표에 해당하 는 좌표정보에 기초하여, 상기 제1객체의 실제좌표를 도출한다. 상기 제2객체검지단계(S900)는 제2분석모듈(1100.2)에 의해 수행되고, 도로 위에 설치된 제2카메라가 촬영한 영 상에서 해당 도로 위에 있는 제2객체를 학습된 인공신경망 기반의 검지모델을 통해 검지한다. 상기 제2실제좌표추출단계(S1000)는 상기 이벤트정보생성모듈에 의해 수행되고, 1. 인공지능 영상분석에 기반한 정밀좌표를 포함하는 이벤트발생정보를 도출하는 방법 및 시스템에서 전술한 검지정보수신단계(S200), 관련정밀지도이미지생성단계(S300), 이미지정합단계(S400) 및 실제좌표추출단계(S500)를 포함한다. 다시 말해, 상기 제2카메라의 영상을 변형하여, 정밀지도이미지에 정합시키고, 상기 정밀지도이미지에 기설정된 실제좌표에 해당하는 좌표정보에 기초하여, 상기 제2객체의 실제좌표를 도출한다. 상기 트래킹단계(S1100)는 트래킹모듈에 의해 수행되고, 상기 제1카메라에서 검지된 제1객체와 상기 제2 카메라에서 검지된 제2객체를 각각 도출된 실제좌표에 기반하여 통합적으로 트래킹한다. 바람직하게, 기설정된 시간마다 객체 각각의 실제좌표를 트래킹하고, 해당 시간에 따른 객체의 위치변화를 정리하여 트래킹정보를 생 성한다. 상기 트래킹정보는 객체의 실제좌표에 기반하여 생성됨으로써, 종래의 움직이는 객체를 검지하는 기술 보다 더 정밀하게 객체를 트래킹하여 정보의 신뢰도를 높이는 효과를 발휘할 수 있다. 한편, 서로 다양한 방향을 바라보며 도로 위에 설치된 복수의 카메라 각각의 시야각 혹은 설치위치에 따라 촬영 되는 도로이미지 중 겹치는 영역 혹은 겹치지 않는 영역이 발생할 수 있다. 상기 트래킹단계(S1100)는 겹치는 영역 및 겹치지 않는 영역 각각의 경우에 따라 상이한 방법을 통해 객체를 분류하여 객체아이디를 부여함으로써 트래킹정보의 신뢰도를 높이는 효과를 발휘할 수 있다.도 11은 본 발명의 일 실시예에 따른 두 카메라가 같은 영역을 촬영하는 경우에서의 제1트래킹정보수정단계의 수행과정을 개략적으로 도시한다. 도 11에 도시된 바와 같이, 상기 트래킹단계(S1100)는, 상기 제1분석모듈(1100.1) 및 상기 제2분석모듈(1100. 2)로부터 객체속성정보 및 해당 객체의 실제좌표정보를 수신하여, 실제좌표계에서의 각각의 객체에 대한 트래킹 정보를 생성하는 트래킹정보생성단계; 및 동일 혹은 상응하는 시간구간에서 상기 제1객체의 실제좌표와 상기 제 2객체의 실제좌표의 오차가 기설정된 오차범위 이내인 경우에는 상기 제1객체와 상기 제2객체에 대해 동일한 객 체아이디를 부여하여 상기 트래킹정보를 수정하는 제1트래킹정보수정단계;를 포함한다. 상기 트래킹단계(S1100)는, 트래킹정보생성단계 및 제1트래킹정보수정단계를 포함한다. 구체적으로, 상기 트래킹정보생성단계는 트래킹모듈에 의해 수행되고, 상기 제1분석모듈(1100.1), 제2분 석모듈(1100.2) 및 이벤트정보생성모듈로부터 객체속성정보 및 해당 객체의 실제좌표정보를 수신하여, 실 제좌표계에서의 각각의 객체에 대한 트래킹정보를 생성한다. 상기 객체속성정보는 객체의 종류(예를 들어 트럭, 승용차 등) 혹은 객체의 외곽선을 포함하는 객체이미지의 특징정보를 포함한다. 도 11은 도로 위에서 제1카메라(CAM#1)와 제2카메라(CAM#2)가 서로 다른 위치에 설치되어 동일한 영역을 바라보 는 구성을 도시한다. 이 때, 상기 제1카메라(CAM#1)가 촬영하는 영상과 상기 제2카메라(CAM#2)가 촬영하는 영상 중 서로 겹치는 영역에 대하여 동일 혹은 상응하는 시간구간에서 객체가 검지되는 경우, 상기 제1트래킹정보수 정단계는 트래킹모듈에 의해 수행되고, 상기 겹치는 영역에 대하여 동일 혹은 상응하는 시간구간에서 검 지된 상기 제1객체의 실제좌표와 상기 제2객체의 실제좌표를 비교하여 실제좌표의 차이가 기설정된 오차범위 이 내라면, 즉, 동일한 시간에 제1객체의 위치와 제2객체의 위치가 유사하다면, 상기 제1객체와 상기 제2객체를 서 로 동일한 객체로 판단하여 상기 제1객체 및 제2객체에게 동일한 객체아이디를 부여한다. 기존의 트래킹정보는 서로 다른 카메라로부터 검지되어 객체마다 상이한 객체아이디가 부여된 상태이므로, 상기 제1트래킹정보수정단계는 상기 제1객체 및 제2객체에게 동일한 객체아이디 부여한 이후, 이에 따라 기존의 트래 킹정보를 수정함으로써, 트래킹정보에 대한 신뢰도를 높이는 효과를 발휘할 수 있다. 도 12는 본 발명의 일 실시예에 따른 제1스코어산출단계의 수행과정을 개략적으로 도시한다. 도 12에 도시된 바와 같이, 상기 트래킹단계(S1100)는 제2트래킹정보수정단계를 더 포함하고, 상기 제2트래킹정 보수정단계는, 제1시간구간에서의 상기 제1객체의 실제좌표와 상기 제1시간구간 이후에 해당하는 제2시간구간에 서의 상기 제2객체의 실제좌표의 차이가 기설정된 제1기준 이내에 해당하는 지 여부를 판단하는 객체판단단계; 상기 객체판단단계의 판단결과 및 상기 제1객체의 객체속성정보와 상기 제2객체의 객체속성정보의 유사도로부터 제1스코어를 산출하는 제1스코어산출단계;를 포함한다. 개략적으로 도 12의 (a)는 도로 위에서 설치된 복수의 카메라 각각이 서로 다른 영역을 촬영하는 구성을 도시하 고, 도 12의 (b)는 제1스코어의 산출과정을 개략적으로 도시한다. 구체적으로, 도 12의 (a)에 도시된 바와 같이, 도로 위에서 설치된 4개의 카메라가 서로 다른 영역을 촬영하는 경우, 차량과 같이 도로 위에서 움직이는 객체에 대해 카메라마다 서로 다른 객체아이디를 부여할 수 있다. 이 러한 경우, 상이한 객체아이디가 남발됨에 따라 객체의 트래킹정보에 대하여 신뢰도가 낮아지고, 컴퓨팅 리소스 의 소모가 낭비될 수 있다. 본 발명은 복수의 카메라가 서로 다른 영역을 촬영하는 경우에서의 전술한 문제의 발생을 방지하기 위해 제2트래킹정보수정단계를 통해 서로 다른 객체아이디로 부여되는 객체에 대하여 검토 및 수정을 한다. 도 12의 (b)는 객체의 동일여부를 판단하기 위해 제1스코어를 산출하는 과정을 도시한다. 도로 위에 (t1, x1, y1)좌표에 해당하는 제1객체는 제1시간구간인 t1시간구간 동안 제1카메라로 촬영된 객체로서, t1시간동안 (x1, y1)에 해당하는 실제좌표에 위치함을 의미하고, (t2, m2, n2)좌표에 해당하는 제2객체는 제1시간구간 이후인 제2 시간구간에 해당하는 t2시간구간 동안 제2카메라로 촬영된 객체로서, t2시간동안 (m2, n2)에 해당하는 실제좌표에 위치함을 의미한다. 객체판단단계는 트래킹모듈에 의해 수행되고, t1시간구간에서의 상기 제1객체의 실제좌표인 (x1, y1)과 t2 시간구간에서의 상기 제2객체의 실제좌표인 (m2, n2)를 비교하고, 실제좌표의 차이가 기설정된 제1기준 이내에 해당하는 지 여부를 판단한다. 제1스코어산출단계는 트래킹모듈에 의해 수행되고, 상기 제1객체의 객체속성정보와 상기 제2객체의 객체 속성정보의 유사도를 비교하고, 상기 객체판단단계의 판단결과 및 비교된 유사도로부터 제1스코어를 산출한다. 다시 말해, 상기 제1스코어는 일정 시간 동안 객체 실제좌표의 위치변화가 적을수록, 객체종류가 유사할수록, 혹은 객체이미지의 특징정보가 유사할수록 높게 산출되고, 상기 제1스코어가 높을수록 상기 제1객체와 상기 제2 객체는 동일한 객체일 확률이 높아진다. 도 13은 본 발명의 일 실시예에 따른 제2스코어산출단계의 수행과정을 개략적으로 도시한다. 도 13에 도시된 바와 같이, 상기 트래킹단계(S1100)는 제2트래킹정보수정단계를 더 포함하고, 상기 제2트래킹정 보수정단계는, 상기 제2시간구간에서 상기 제1객체의 예측되는 실제좌표의 예측정보와 상기 제2객체의 실제좌표 와의 차이에 의하여 제2스코어를 산출하는 제2스코어산출단계;를 포함한다. 예를 들어, 제1시간구간동안 제1카메라를 통해 제1객체가 검지되고, 제2시간구간동안 제2카메라를 통해 제2객체 가 검지된다고 할 때, 구체적으로, 제2스코어산출단계는 상기 트래킹모듈에 의해 수행되고, 제1시간구간 에서 제1카메라를 통해 제1객체가 검지되었을 때, 상기 제1시간구간 이후인 제2시간구간에서 상기 제1객체의 예 측되는 실제좌표(x1, y1)와 상기 제2시간구간에서 제2카메라를 통해 검지된 제2객체의 실제좌표(m1, n1)를 비교 한다. 바람직하게, 제1카메라를 통해 제1시간구간 마지막 프레임에 검지된 제1객체가 제2시간구간 첫번째 프레 임일 때 예측되는 위치;와 제2카메라를 통해 제2시간구간 첫번째 프레임에 검지된 제2객체의 위치;를 비교한다. 즉, 상기 트래킹모듈은 제1객체의 예측되는 실제좌표와 제2객체의 실제좌표의 유사도에 기반하여 제2스코 어를 산출한다. 제1시간구간동안 제1객체의 움직임을 통해 제2시간구간에서 예측되는 위치좌표와 제2시간구간에 검지된 제2객체의 위치좌표가 유사할수록 상기 제2스코어는 높아지고, 상기 제2스코어가 높아질수록 제1객체 및 제2객체는 동일한 객체일 확률이 높아진다. 한편, 실제좌표를 예측하는 방법에 대한 더 자세한 설명은 도 14에서 후술하도록 한다. 도 14는 본 발명의 일 실시예에 따른 예측정보가 산출되는 과정을 개략적으로 도시한다. 도 14에 도시된 바와 같이, 상기 예측정보는, 상기 트래킹모듈이 상기 제1시간구간에서 상기 제1객체의 복수의 위치정보로부터 각각의 속도벡터를 도출하고, 상기 제1객체의 제1시간구간의 마지막에서의 위치 및 기존 의 속도벡터로부터 도출된 예상속도벡터를 적용하여, 상기 제1객체의 제2시간구간에서의 예상위치로 산출된다. 개략적으로, 도 14의 (a)는 각각의 시간구간마다 포함하는 시간을 도시하고, 도 14의 (b)는 해당 시간마다 객체 실제좌표의 위치변화를 도시한다. 구체적으로, 도 13과 동일하게 제1시간구간동안 제1카메라를 통해 제1객체가 검지되고, 제2시간구간동안 제2카 메라를 통해 제2객체가 검지된다고 할 때, 도 14의 (a)에 도시된 바와 같이, 제1카메라로 제1객체를 검지한 제1시간구간은 t1 내지 t3에 해당하는 시간을 포함하고, 제2카메라로 제2객체를 검지한 제2시간구간은 t4 내지 t6에 해당하는 시간을 포함한다. 도 14의 (b)에 도시된 바와 같이, 제1객체는 제1카메라를 통해 t1시간구간에 촬영된 프레임에는 (x1, y1)에 해당 하는 실제좌표에 위치하고, t2시간구간에 촬영된 프레임에는 (x2, y2)에 해당하는 실제좌표에 위치한다. 상기 트 래킹모듈은 상기 제1시간구간에서 프레임 사이마다 상기 제1객체의 복수의 실제좌표의 위치변화(예를 들 어, (x2-x1, y2-y1))에 기반하여 속도벡터(예를 들어, (x2-x1/t1, y2-y1/t1))를 도출하고, 복수의 프레임 사이마다 도출되는 제1객체의 복수의 속도벡터에 기반하여 상기 제1시간구간 마지막에 촬영된 t3시간 이후인 제2시간구간 에 포함된 t4시간에 해당하는 프레임에서의 제1객체의 실제좌표(x4, y4)를 예측할 수 있다. 도 15는 본 발명의 일 실시예에 따른 스코어합산단계의 수행과정을 개략적으로 도시한다. 도 15에 도시된 바와 같이, 상기 트래킹단계(S1100)는 제2트래킹정보수정단계를 더 포함하고, 상기 제2트래킹정 보수정단계는, 상기 제1스코어와 상기 제2스코어의 합이 기설정된 제2기준을 초과하는 경우에는 상기 제1객체와 상기 제2객체에 대해 동일한 객체아이디를 부여하여 상기 트래킹정보를 수정하는 스코어합산단계;를 더 포함한 다. 구체적으로, 스코어합산단계는 상기 트래킹모듈에 의해 수행되고, 제1객체 및 제2객체에 대하여 제1스코 어산출단계를 통해 산출된 제1스코어 및 제2스코어산출단계를 통해 산출된 제2스코어를 합산하고, 상기 제1스코 어 및 제2스코어의 합이 기설정된 제2기준을 초과한다면 상기 제1객체 및 제2객체를 동일한 객체로 판단하고, 상기 제1객체 및 상기 제2객체에게 동일한 객체아이디를 부여한다. 상기 스코어합산단계는 이에 따라 상기 트래 킹정보생성단계를 통해 생성되었던 트래킹정보에 포함된 객체아이디를 수정함으로써, 복수의 카메라가 서로 다 른 영역을 촬영하는 경우에도 검지되는 객체마다 정밀한 객체아이디가 할당되어 트래킹정보의 정확도를 높이는 효과를 발휘할 수 있다. 도 16은 본 발명의 일 실시예에 따른 컴퓨팅장치의 내부 구성을 예시적으로 도시한다. 도 1 및 도 9에 대한 설명에서 언급된 컴퓨팅시스템은 후술하는 도 16에 도시된 컴퓨팅장치의 구 성요소를 포함할 수 있다. 도 16에 도시한 바와 같이, 컴퓨팅장치은 적어도 하나의 프로세서(processor), 메모리 (memory), 주변장치 인터페이스(peripheral interface), 입/출력 서브시스템(I/O subsystem), 전력 회로 및 통신 회로를 적어도 포함할 수 있다. 구체적으로, 상기 메모리는, 일례로 고속 랜덤 액세스 메모리(high-speed random access memory), 자기 디스크, 에스램(SRAM), 디램(DRAM), 롬(ROM), 플래시 메모리 또는 비휘발성 메모리를 포함할 수 있다. 상기 메 모리는 상기 컴퓨팅장치의 동작에 필요한 소프트웨어 모듈, 명령어 집합 또는 그 밖에 다양한 데 이터를 포함할 수 있다. 이때, 상기 프로세서나 상기 주변장치 인터페이스 등의 다른 컴포넌트에서 상기 메모리에 액세스하는 것은 상기 프로세서에 의해 제어될 수 있다. 상기 프로세서은 단일 혹은 복수로 구성 될 수 있고, 연산처리속도 향상을 위하여 GPU 및 TPU 형태의 프로세서를 포함할 수 있다. 상기 주변장치 인터페이스는 상기 컴퓨팅장치의 입력 및/또는 출력 주변장치를 상기 프로세서 및 상기 메모리 에 결합시킬 수 있다. 상기 프로세서는 상기 메모리에 저장된 소프트웨어 모듈 또는 명령어 집합을 실행하여 상기 컴퓨팅장치을 위한 다양한 기능을 수행하고 데이터를 처리할 수 있다. 상기 입/출력 서브시스템은 다양한 입/출력 주변장치들을 상기 주변장치 인터페이스에 결합시킬 수 있다. 예를 들어, 상기 입/출력 서브시스템은 모니터나 키보드, 마우스, 프린터 또는 필요에 따라 터 치스크린이나 센서 등의 주변장치를 상기 주변장치 인터페이스에 결합시키기 위한 컨트롤러를 포함할 수 있다. 다른 측면에 따르면, 상기 입/출력 주변장치들은 상기 입/출력 서브시스템을 거치지 않고 상기 주 변장치 인터페이스에 결합될 수도 있다. 상기 전력 회로는 단말기의 컴포넌트의 전부 또는 일부로 전력을 공급할 수 있다. 예를 들어 상기 전력 회로는 전력 관리 시스템, 배터리나 교류(AC) 등과 같은 하나 이상의 전원, 충전 시스템, 전력 실패 감 지 회로(power failure detection circuit), 전력 변환기나 인버터, 전력 상태 표시자 또는 전력 생성, 관리, 분배를 위한 임의의 다른 컴포넌트들을 포함할 수 있다. 상기 통신 회로는 적어도 하나의 외부 포트를 이용하여 다른 컴퓨팅장치와 통신을 가능하게 할 수 있다. 또는, 상술한 바와 같이 필요에 따라 상기 통신 회로는 RF 회로를 포함하여 전자기 신호 (electromagnetic signal)라고도 알려진 RF 신호를 송수신함으로써, 다른 컴퓨팅장치와 통신을 가능하게 할 수 도 있다. 이러한 도 16의 실시예는, 상기 컴퓨팅장치의 일례일 뿐이고, 상기 컴퓨팅장치는 도 16에 도시된 일부 컴포넌트가 생략되거나, 도 16에 도시되지 않은 추가의 컴포넌트를 더 구비하거나, 2 개 이상의 컴포넌트 를 결합시키는 구성 또는 배치를 가질 수 있다. 예를 들어, 모바일 환경의 통신 단말을 위한 컴퓨팅장치는 도 16에 도시된 컴포넌트들 외에도, 터치스크린이나 센서 등을 더 포함할 수도 있으며, 상기 통신 회로에 다 양한 통신방식(Wi-Fi, 3G, LTE, 5G, 6G, Bluetooth, NFC, Zigbee 등)의 RF 통신을 위한 회로가 포함될 수도 있 다. 상기 컴퓨팅장치에 포함 가능한 컴포넌트들은 하나 이상의 신호 처리 또는 어플리케이션에 특화된 집적 회로를 포함하는 하드웨어, 소프트웨어, 또는 하드웨어 및 소프트웨어 양자의 조합으로 구현될 수 있다. 본 발명의 실시예에 따른 방법들은 다양한 컴퓨팅장치를 통하여 수행될 수 있는 프로그램 명령(instruction) 형 태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 특히, 본 실시예에 따른 프로그램은 PC 기반의 프로그 램 또는 모바일 단말 전용의 어플리케이션으로 구성될 수 있다. 본 발명이 적용되는 어플리케이션은 파일 배포 시스템이 제공하는 파일을 통해 이용자 단말에 설치될 수 있다. 일 예로, 파일 배포 시스템은 이용자 단말이기 의 요청에 따라 상기 파일을 전송하는 파일 전송부(미도시)를 포함할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어구 성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세서, 컨트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크 로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명 령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목 적컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이 상의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2023-0092143", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상장 치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또 는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨팅장치 상에 표준편차되어서,표준편차된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기 록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD- ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다. 본 발명의 일 실시예에서는, 실제좌표에 기반하여 객체의 트래킹정보를 생성 및 수정함으로써, 종래의 도로 위 에 설치된 카메라로부터 획득된 영상에서 검출된 객체의 움직임에만 기반하여 생성되는 트래킹정보보다 신뢰도 를 높이는 효과를 발휘할 수 있다. 본 발명의 일 실시예에서는, 복수의 카메라가 동일한 영역을 촬영하는 경우와 상이한 영역을 촬영하는 경우에서 의 객체정보를 생성하는 방법을 다르게 하여 신뢰도가 높은 트래킹정보를 생성하는 효과를 발휘할 수 있다. 본 발명의 일 실시예에서는, 복수의 카메라로 도로 위 객체의 움직임을 검지할 때, 실제좌표에 기반하여 해당 객체의 예상위치를 산출하여 서로 다른 카메라를 통해 상이하게 검지되는 객체의 동일여부를 파악하여 객체아이 디를 부여함으로써, 객체속성정보에 대한 신뢰도를 높이고, 컴퓨팅 리소스의 소모를 줄이는 효과를 발휘할 수 있다."}
{"patent_id": "10-2023-0092143", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범 위에 속한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16"}
{"patent_id": "10-2023-0092143", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 이벤트발생정보를 생성하는 방법을 수행하는 컴퓨팅시스템을 개략적으로 도 시한다. 도 2는 본 발명의 일 실시예에 따른 이벤트발생정보를 생성하는 방법의 수행단계를 개략적으로 도시한다. 도 3은 본 발명의 일 실시예에 따른 원본이미지 및 정밀지도이미지 각각에 설정된 복수의 마커객체를 개략적으 로 도시한다. 도 4는 본 발명의 일 실시예에 따른 이미지정합단계의 수행과정을 개략적으로 도시한다. 도 5는 본 발명의 일 실시예에 따른 실제좌표추출단계의 수행과정 및 이벤트발생정보생성단계의 수행결과를 개 략적으로 도시한다. 도 6은 본 발명의 일 실시예에 따른 ROI실좌표생성단계의 수행과정을 개략적으로 도시한다. 도 7은 본 발명의 일 실시예에 따른 ROI재생성단계의 수행과정을 개략적으로 도시한다. 도 8은 본 발명의 일 실시예에 따른 정상ROI형성단계를 예시적으로 도시한다. 도 9는 본 발명의 일 실시예에 따른 객체정보를 생성하는 방법을 수행하는 컴퓨팅시스템을 개략적으로 도시한다. 도 10은 본 발명의 일 실시예에 따른 객체정보를 생성하는 방법의 수행단계를 개략적으로 도시한다. 도 11은 본 발명의 일 실시예에 따른 두 카메라가 같은 영역을 촬영하는 경우에서의 제1트래킹정보수정단계의 수행과정을 개략적으로 도시한다. 도 12는 본 발명의 일 실시예에 따른 제1스코어산출단계의 수행과정을 개략적으로 도시한다. 도 13은 본 발명의 일 실시예에 따른 제2스코어산출단계의 수행과정을 개략적으로 도시한다. 도 14는 본 발명의 일 실시예에 따른 예측정보가 산출되는 과정을 개략적으로 도시한다. 도 15는 본 발명의 일 실시예에 따른 스코어합산단계의 수행과정을 개략적으로 도시한다. 도 16은 본 발명의 일 실시예에 따른 컴퓨팅장치의 내부 구성을 예시적으로 도시한다."}
