{"patent_id": "10-2021-0156886", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0070868", "출원번호": "10-2021-0156886", "발명의 명칭": "시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정", "출원인": "건국대학교 산학협력단", "발명자": "조기춘"}}
{"patent_id": "10-2021-0156886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 방법으로서,소정의 이동체에 대한 주변 공간인 대상 공간에 대한 영상 입력을 수신하는 단계;입력되는 소정의 영상에 대하여 객체 기반의 의미론적 분할을 수행하도록 미리 학습된 제1인공지능 모델에 기초하여 상기 영상 입력에 대응하는 시맨틱 분할 이미지를 생성하는 단계; 및미리 구축된 시맨틱 포인트 클라우드 맵과 상기 시맨틱 분할 이미지를 매칭하여 상기 이동체의 위치 정보를 추정하는 단계,를 포함하는, 위치 추정 방법."}
{"patent_id": "10-2021-0156886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 시맨틱 포인트 클라우드 맵은,상기 대상 공간을 포함하는 맵 구축 공간 내에 위치하는 미리 설정된 유형의 객체의 위치 정보를 나타내는 복수의 3차원 점을 포함하고, 상기 복수의 3차원 점 각각에 대한 객체 분류 정보가 할당되도록 미리 구축된 것인,위치 추정 방법."}
{"patent_id": "10-2021-0156886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 위치 정보를 추정하는 단계는,상기 시맨틱 포인트 클라우드 맵으로부터 상기 이동체의 후보 위치를 나타내는 복수의 파티클 각각에 대응하는포인트 클러스터를 획득하는 단계;상기 포인트 클러스터를 상기 시맨틱 분할 이미지 상에 각각 투영하는 단계;상기 포인트 클러스터에 포함된 복수의 3차원 점 각각에 대하여 할당된 제1객체 분류 정보 및 상기 복수의 3차원 점 각각이 투영된 지점에 대하여 할당된 상기 시맨틱 분할 이미지의 제2객체 분류 정보 간의 유사도에 따른매칭 스코어를 상기 복수의 파티클마다 연산하는 단계; 및상기 매칭 스코어에 기초하여 상기 복수의 파티클 각각에 대한 가중치를 갱신하는 단계,를 포함하는 것인, 위치 추정 방법."}
{"patent_id": "10-2021-0156886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 이동체의 위치 정보는,상기 복수의 파티클 각각에 대응하는 상기 후보 위치 및 상기 갱신된 가중치에 기초하여 도출되는 것인, 위치추정 방법."}
{"patent_id": "10-2021-0156886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 복수의 파티클은,상기 이동체의 관성 센서 정보에 기초하여 예측되는 상태 정보의 변화에 따른 위치가 상기 이동체의 위성 항법공개특허 10-2023-0070868-3-정보에 기초하여 상기 이동체로부터 미리 설정된 거리 이내인 것으로 예측된 파티클인 것을 특징으로 하는, 위치 추정 방법."}
{"patent_id": "10-2021-0156886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 상태 정보는,상기 복수의 파티클 각각의 좌표 정보, 배향 정보 및 높이 정보를 포함하는 것인, 위치 추정 방법."}
{"patent_id": "10-2021-0156886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제3항에 있어서,상기 포인트 클러스터를 획득하는 단계는,상기 이동체가 상기 후보 위치 각각에 위치하는 것을 가정하여 설정되는 관심 영역에 포함되는 복수의 3차원 점을 상기 시맨틱 포인트 클라우드 맵으로부터 추출하는 단계,를 포함하는 것인, 위치 추정 방법."}
{"patent_id": "10-2021-0156886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 포인트 클러스터를 획득하는 단계는,상기 관심 영역에 포함된 복수의 3차원 점에 랜덤 샘플링(Random Sampling)을 적용하는 단계,를 더 포함하는 것인, 위치 추정 방법."}
{"patent_id": "10-2021-0156886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제2항에 있어서,상기 이동체는 차량이고,상기 미리 설정된 유형의 객체는,차선, 교통 표지판, 신호등, 펜스 구조물, 조명 구조물 및 건물 중 적어도 하나를 포함하는 것인, 위치 추정 방법."}
{"patent_id": "10-2021-0156886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제2항에 있어서,상기 영상 입력을 수신하는 단계 이전에,상기 시맨틱 포인트 클라우드 맵을 구축하는 단계,를 더 포함하고,상기 구축하는 단계는,상기 복수의 3차원 점을 포함하는 포인트 클라우드를 수집하는 단계; 및입력되는 소정의 포인트 클라우드에 대하여 객체 기반의 의미론적 분할을 수행하도록 미리 학습된 제2인공지능모델에 기초하여 상기 수집된 포인트 클라우드에 대응하는 시맨틱 포인트 클라우드를 생성하는 단계,를 포함하는 것인, 위치 추정 방법."}
{"patent_id": "10-2021-0156886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 장치로서,소정의 이동체에 대한 주변 공간인 대상 공간에 대한 영상 입력을 수신하는 이미지 획득부;공개특허 10-2023-0070868-4-입력되는 소정의 영상에 대하여 객체 기반의 의미론적 분할을 수행하도록 미리 학습된 제1인공지능 모델에 기초하여 상기 영상 입력에 대응하는 시맨틱 분할 이미지를 생성하는 이미지 처리부; 및미리 구축된 시맨틱 포인트 클라우드 맵과 상기 시맨틱 분할 이미지를 매칭하여 상기 이동체의 위치 정보를 추정하는 매칭부,를 포함하는, 위치 추정 장치."}
{"patent_id": "10-2021-0156886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 시맨틱 포인트 클라우드 맵은,상기 대상 공간을 포함하는 맵 구축 공간 내에 위치하는 미리 설정된 유형의 객체의 위치 정보를 나타내는 복수의 3차원 점을 포함하고, 상기 복수의 3차원 점 각각에 대한 객체 분류 정보가 할당되도록 미리 구축된 것인,위치 추정 장치."}
{"patent_id": "10-2021-0156886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 매칭부는,상기 시맨틱 포인트 클라우드 맵으로부터 상기 이동체의 후보 위치를 나타내는 복수의 파티클 각각에 대응하는포인트 클러스터를 획득하는 파티클 정보 획득부;상기 포인트 클러스터를 상기 시맨틱 분할 이미지 상에 각각 투영하는 투영부;상기 포인트 클러스터에 포함된 복수의 3차원 점 각각에 대하여 할당된 제1객체 분류 정보 및 상기 복수의 3차원 점 각각이 투영된 지점에 대하여 할당된 상기 시맨틱 분할 이미지의 제2객체 분류 정보 간의 유사도에 따른매칭 스코어를 상기 복수의 파티클마다 연산하는 매칭 스코어 연산부; 및상기 매칭 스코어에 기초하여 상기 복수의 파티클 각각에 대한 가중치를 갱신하는 가중치 갱신부,를 포함하는 것인, 위치 추정 장치."}
{"patent_id": "10-2021-0156886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 복수의 파티클은,상기 이동체의 관성 센서 정보에 기초하여 예측되는 상태 정보의 변화에 따른 위치가 상기 이동체의 위성 항법정보에 기초하여 상기 이동체로부터 미리 설정된 거리 이내인 것으로 예측된 파티클인 것을 특징으로 하는, 위치 추정 장치."}
{"patent_id": "10-2021-0156886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 복수의 3차원 점을 포함하는 포인트 클라우드를 수집하고, 입력되는 소정의 포인트 클라우드에 대하여 객체 기반의 의미론적 분할을 수행하도록 미리 학습된 제2인공지능 모델에 기초하여 상기 수집된 포인트 클라우드에 대응하는 시맨틱 포인트 클라우드를 생성하여 상기 시맨틱 포인트 클라우드 맵을 구축하는 맵 구축부,를 더 포함하는 것인, 위치 추정 장치."}
{"patent_id": "10-2021-0156886", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 장치 및 방법이 개시 되며, 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 방법은, 소정의 이동체에 대한 주변 공간인 대상 공간에 대한 영상 입력을 수신하는 단계, 입력되는 소정의 영상에 대하여 객체 기반의 의미론적 분할을 수행하도록 미리 학습된 제1인공지능 모델에 기초하여 상기 영상 입력에 대응하는 시맨틱 분할 이미지를 생성하는 단계 및 미리 구축된 시맨틱 포인트 클라우드 맵과 상기 시맨틱 분할 이미지를 매칭하여 상기 이동체의 위치 정보를 추정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0156886", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본원은 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 장치 및 방 법에 관한 것이다."}
{"patent_id": "10-2021-0156886", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "스마트 자동차(Smart Car)라는 용어는 기계 중심의 전통적인 자동차 기술에 전기, 전자, 정보통신 기술을 융복 합한 것으로, 완성차 업체, 부품업체, ICT업체 등 다양한 산업 주체들에 의해 운전자 편의 측면과 차량 안전 측 면에 초점을 두어 지속적으로 발전되어 왔으며, 이러한 스마트 자동차 관련 기술은 구체적으로 첨단 운전자 보 조체계(Advanced Driver Assistance System, ADAS), 자율 주행(Autonomous Vehicle), 협업 안전체계 (Cooperative Safety System) 등 안전과 관련된 분야와 커넥티드 카(Connected Car)와 같은 편의와 관련된 분 야로 분류될 수 있다. 특히, ADAS(Advanced Driver Assistance Systems) 또는 자율주행(Autonomous Vehicle)이 적용된 지능형 자동차 는 주행 중인 차량의 주변 환경을 인식하기 위해 구비되는 각종 센서(예를 들어, 카메라, GPS, 레이더, LiDAR 등)로부터 획득되는 센싱 데이터를 통해 차량 주변 상황을 높은 정확도로 실시간 모니터링 함으로써 탑승자, 보 행자 및 주변차량의 안전을 확보하고 주행 편의성을 향상시킬 수 있어야 한다. 특히, LiDAR는 레이저로 특정 대상과의 거리를 측정하여 대상 객체의 형태를 판별하여 자동차 주변의 도로 환경 을 3차원 형상으로 인지하는 센서로, 이러한 LiDAR는 주변 대상과의 거리 측정에서의 오차가 적은 정밀한 측정 성능을 제공함으로써 장애물 인지 및 동적 물체 추적 등 다양한 차량 연계 인지 시스템에 활용 가능한 이점이 있다. 다만, 종래의 3차원 라이다 센서를 이용한 맵 기반의 위치 추정 알고리즘의 경우, 센티미터 수준의 높은 정확도 를 보장하지만, 차량에 고가의 장비인 라이다 센서가 탑재되는 경우에만 적용 가능하여 양산용 차량에 적용되기 어려운 한계가 있다. 본원의 배경이 되는 기술은 한국등록특허공보 제10-2103941호에 개시되어 있다."}
{"patent_id": "10-2021-0156886", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 미리 구축된 3차원 포인트 클라우드 맵과 이동체 의 주행 과정에서 실시간으로 획득되는 이미지를 가공한 시맨틱 분할 이미지 간의 매칭을 통해 이동체의 위치를 추정하는 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 장치 및 방법을 제공하려는 것을 목적으로 한다. 다만, 본원의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2021-0156886", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨 틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 방법은, 소정의 이동체에 대한 주변 공간인 대 상 공간에 대한 영상 입력을 수신하는 단계, 입력되는 소정의 영상에 대하여 객체 기반의 의미론적 분할을 수행 하도록 미리 학습된 제1인공지능 모델에 기초하여 상기 영상 입력에 대응하는 시맨틱 분할 이미지를 생성하는 단계 및 미리 구축된 시맨틱 포인트 클라우드 맵과 상기 시맨틱 분할 이미지를 매칭하여 상기 이동체의 위치 정 보를 추정하는 단계를 포함할 수 있다. 또한, 상기 시맨틱 포인트 클라우드 맵은, 상기 대상 공간을 포함하는 맵 구축 공간 내에 위치하는 미리 설정된 유형의 객체의 위치 정보를 나타내는 복수의 3차원 점을 포함하고, 상기 복수의 3차원 점 각각에 대한 객체 분 류 정보가 할당되도록 미리 구축될 수 있다. 또한, 상기 위치 정보를 추정하는 단계는, 상기 시맨틱 포인트 클라우드 맵으로부터 상기 이동체의 후보 위치를 나타내는 복수의 파티클 각각에 대응하는 포인트 클러스터를 획득하는 단계, 상기 포인트 클러스터를 상기 시맨 틱 분할 이미지 상에 각각 투영하는 단계, 상기 포인트 클러스터에 포함된 복수의 3차원 점 각각에 대하여 할당 된 제1객체 분류 정보 및 상기 복수의 3차원 점 각각이 투영된 지점에 대하여 할당된 상기 시맨틱 분할 이미지 의 제2객체 분류 정보 간의 유사도에 따른 매칭 스코어를 상기 복수의 파티클마다 연산하는 단계 및 상기 매칭 스코어에 기초하여 상기 복수의 파티클 각각에 대한 가중치를 갱신하는 단계를 포함할 수 있다.또한, 상기 이동체의 위치 정보는, 상기 복수의 파티클 각각에 대응하는 상기 후보 위치 및 상기 갱신된 가중치 에 기초하여 도출될 수 있다. 또한, 상기 복수의 파티클은, 상기 이동체의 관성 센서 정보에 기초하여 예측되는 상태 정보의 변화에 따른 위 치가 상기 이동체의 위성 항법 정보에 기초하여 상기 이동체로부터 미리 설정된 거리 이내인 것으로 예측된 파 티클일 수 있다. 또한, 상기 상태 정보는, 상기 복수의 파티클 각각의 좌표 정보, 배향 정보 및 높이 정보를 포함할 수 있다. 또한, 상기 포인트 클러스터를 획득하는 단계는, 상기 이동체가 상기 후보 위치 각각에 위치하는 것을 가정하여 설정되는 관심 영역에 포함되는 복수의 3차원 점을 상기 시맨틱 포인트 클라우드 맵으로부터 추출하는 단계를 포함할 수 있다. 또한, 상기 포인트 클러스터를 획득하는 단계는, 상기 관심 영역에 포함된 복수의 3차원 점에 랜덤 샘플링 (Random Sampling)을 적용하는 단계를 포함할 수 있다. 또한, 상기 이동체는 차량일 수 있다. 또한, 상기 미리 설정된 유형의 객체는, 차선, 교통 표지판, 신호등, 펜스 구조물, 조명 구조물 및 건물 중 적 어도 하나를 포함할 수 있다. 또한, 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통 한 위치 추정 방법은, 상기 영상 입력을 수신하는 단계 이전에, 상기 시맨틱 포인트 클라우드 맵을 구축하는 단 계를 포함할 수 있다. 또한, 상기 구축하는 단계는, 상기 복수의 3차원 점을 포함하는 포인트 클라우드를 수집하는 단계 및 입력되는 소정의 포인트 클라우드에 대하여 객체 기반의 의미론적 분할을 수행하도록 미리 학습된 제2인공지능 모델에 기 초하여 상기 수집된 포인트 클라우드에 대응하는 시맨틱 포인트 클라우드를 생성하는 단계를 포함할 수 있다. 한편, 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통 한 위치 추정 장치는, 소정의 이동체에 대한 주변 공간인 대상 공간에 대한 영상 입력을 수신하는 이미지 획득 부, 입력되는 소정의 영상에 대하여 객체 기반의 의미론적 분할을 수행하도록 미리 학습된 제1인공지능 모델에 기초하여 상기 영상 입력에 대응하는 시맨틱 분할 이미지를 생성하는 이미지 처리부 및 미리 구축된 시맨틱 포 인트 클라우드 맵과 상기 시맨틱 분할 이미지를 매칭하여 상기 이동체의 위치 정보를 추정하는 매칭부를 포함할 수 있다. 또한, 상기 매칭부는, 상기 시맨틱 포인트 클라우드 맵으로부터 상기 이동체의 후보 위치를 나타내는 복수의 파 티클 각각에 대응하는 포인트 클러스터를 획득하는 파티클 정보 획득부, 상기 포인트 클러스터를 상기 시맨틱 분할 이미지 상에 각각 투영하는 투영부, 상기 포인트 클러스터에 포함된 복수의 3차원 점 각각에 대하여 할당 된 제1객체 분류 정보 및 상기 복수의 3차원 점 각각이 투영된 지점에 대하여 할당된 상기 시맨틱 분할 이미지 의 제2객체 분류 정보 간의 유사도에 따른 매칭 스코어를 상기 복수의 파티클마다 연산하는 매칭 스코어 연산부 및 상기 매칭 스코어에 기초하여 상기 복수의 파티클 각각에 대한 가중치를 갱신하는 가중치 갱신부를 포함할 수 있다. 또한, 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통 한 위치 추정 장치는, 상기 복수의 3차원 점을 포함하는 포인트 클라우드를 수집하고, 입력되는 소정의 포인트 클라우드에 대하여 객체 기반의 의미론적 분할을 수행하도록 미리 학습된 제2인공지능 모델에 기초하여 상기 수 집된 포인트 클라우드에 대응하는 시맨틱 포인트 클라우드를 생성하여 상기 시맨틱 포인트 클라우드 맵을 구축 하는 맵 구축부를 포함할 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본원을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예 시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2021-0156886", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본원의 과제 해결 수단에 의하면, 미리 구축된 3차원 포인트 클라우드 맵과 이동체의 주행 과정에서 실 시간으로 획득되는 이미지를 가공한 시맨틱 분할 이미지 간의 매칭을 통해 이동체의 위치를 추정하는 시맨틱 분 할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 장치 및 방법을 제공할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 고가의 장비인 라이다 센서가 차량에 구비되지 않는 경우에도 매칭 기 반의 위치 추정을 수행할 수 있어 보다 저렴하고, 현실적으로 적용 가능성이 높은 위치 추정 알고리즘을 제공할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 이동체의 주변 공간인 대상 공간의 영상에서 식별되는 랜드마크 정보 와 시맨틱 포인트 클라우드 맵에 반영된 시맨틱 정보를 실시간으로 융합할 수 있다. 다만, 본원에서 얻을 수 있는 효과는 상기된 바와 같은 효과들로 한정되지 않으며, 또 다른 효과들이 존재할 수 있다."}
{"patent_id": "10-2021-0156886", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본원이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본원의 실시예를 상세히 설명한다. 그러나 본원은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본원을 명확하게 설명하기 위해서 설명과 관계없는 부분 은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본원 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\" 또는 \"간접적으로 연결\"되어 있는 경우 도 포함한다. 본원 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\", \"상부에\", \"상단에\", \"하에\", \"하부에\", \"하단에\" 위치 하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존 재하는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 본원은 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 장치 및 방 법에 관한 것이다.도 1은 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통 한 위치 추정 장치를 포함하는 이동체 위치 추정 시스템의 개략적인 구성도이다. 도 1을 참조하면, 이동체 위치 추정 시스템은 은 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 장치(이하, '위치 추정 장치'라 한다.), 이동체의 카메라 모듈 및 맵 데이터베이스를 포함할 수 있다. 위치 추정 장치, 이동체의 카메라 모듈 및 맵 데이터베이스 상호간은 네트워크를 통해 통 신할 수 있다. 네트워크는 단말들 및 서버들과 같은 각각의 노드 상호간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 이러한 네트워크의 일 예에는, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, 5G 네트워크, WIMAX(World Interoperability for Microwave Access) 네 트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), wifi 네트워크, 블루투스(Bluetooth) 네트워크, 위성 방송 네트 워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지 는 않는다. 본원의 실시예에 관한 설명에서 맵 데이터베이스는 이동체에 대한 주변 공간인 대상 공간에 대하여 미 리 구축된 시맨틱 포인트 클라우드 맵을 저장하는 데이터베이스일 수 있다. 예시적으로, 위치 추정 장치 는 이동체의 대략적인 위치 정보를 GNSS 정보, GPS 정보 등의 위성 항법 정보를 활용하여 1차적으로 파 악한 후 해당 위치와 미리 설정된 범위 이내로 떨어진 대상 공간을 설정하고, 설정된 대상 공간에 대하여 미리 구축된 시맨틱 포인트 클라우드 맵을 맵 데이터베이스로부터 불러오는 것일 수 있으나, 이에만 한정 되는 것은 아니다. 또한, 본원의 실시예에 관한 설명에서 이동체는 도로 등을 주행하는 차량일 수 있으나, 이에만 한정되는 것 은 아니다. 본원의 일 실시예에 따르면, 이동체는 실내 공간 또는 실외 공간을 이동하는 로봇 디바이스(미도 시)일 수 있다. 다른 예로, 이동체는 사용자가 소지한 상태로 이동하여 위치 정보가 변동되는 사용자 단말 (미도시)을 지칭하는 것일 수 있다. 달리 말해, 본원에서 개시하는 이동체는 시맨틱 포인트 클라우드 맵 이 구축된 대상 공간 상에서 이동 가능한 다양한 유형의 오브젝트를 포함하는 것일 수 있다. 이하에서는 설명의 편의를 위하여 이동체가 도로 환경에서 주행하는 차량인 것을 가정하여 본원의 구현예를 설명하도록 한다. 도 2 및 도 3은 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 장치가 수행하는 이동체의 위치 추정 프로세스를 설명하기 위한 개념도이다. 도 2 및 도 3을 참조하면, 위치 추정 장치는 이동체에 대한 주변 공간인 대상 공간에 대한 영상 입력을 획득(수신)할 수 있다. 참고로, 도 2 및 도 3에 도시된 이동체가 주행하는 도로 영역을 포함하는 이미지는 전술한 영상 입력을 예시적으로 나타낸 것일 수 있다. 본원의 일 실시예에 따르면, 이동체는 이동체의 이동(주행)에 대응하여 이동체 주변 공간의 영상을 획 득하도록 카메라 모듈을 탑재하고, 위치 추정 장치는 카메라 모듈로부터 대상 공간의 영상 입력을 수신(획득)하는 것일 수 있으나, 이에만 한정되는 것은 아니다. 다른 예로, 위치 추정 장치는 이동체가 이동하는 대상 공간을 촬영하도록 대상 공간에 대하여 마련된 별도의 촬영 디바이스(예를 들면, CCTV 모듈 등) 로부터 이동체가 주행하는 대상 공간을 촬영한 영상 입력을 수신하는 것일 수 있다. 또한, 도 2 및 도 3을 참조하면 위치 추정 장치는 입력되는 소정의 영상에 대하여 객체 기반의 의미론적 분할을 수행하도록 미리 학습된 제1인공지능 모델에 기초하여 획득한 영상 입력에 대응하는 시맨틱 분할 이미지 를 생성할 수 있다(도 2의 'Landmark Perception'). 달리 말해, 위치 추정 장치의 제1인공지능 모델은 2 차원의 화상 형태로 입력되는 영상 입력에 대한 2차원 의미론적 분할(2D Semantic Segmentation)을 수행하도록 미리 학습된 인공지능 모델일 수 있다. 보다 구체적으로 제1인공지능 모델은 이동체의 주행에 영향을 미칠 수 있는 복수의 객체 유형에 대응되도록 선별된 복수의 클래스(Class) 각각을 영상 입력으로부터 구분하여 영상 입력의 각각의 픽셀에 대응하는 클래스 (Class)를 라벨링할 수 있다. 한편, 본원의 실시예에 관한 설명에서 각각의 객체 유형을 구분하기 위한 용어 클 래스(Class)는 랜드마크(Landmark) 등으로 달리 지칭될 수 있다. 이와 관련하여, 종래의 의미론적 분할 알고리즘인 RangeNet++ 등에서는 분류하고자 하는 객체 유형에 대응하는 클래스의 종류가 미리 정해져 있는 기존의 데이터 셋(예를 들면, SemanticKITTI 등)을 학습 데이터로 하여 학습 되는데, 이러한 기존에 존재하는 데이터 셋은 통상적으로 20개 내지 28개의 다수의 클래스를 포함한다. 이에 따라, 기존 데이터 셋을 단순히 활용하여 학습되는 의미론적 분할 모델의 경우 이동체의 주행에 큰 영 향을 주지 않는 객체들까지 별도의 클래스로 구분하게 될 수 있다(예를 들면, Vegetation, Terrain 등을 개별적 으로 구분하는 등). 이러한 문제를 해결하기 위하여, 본원에서 개시하는 위치 추정 장치는 이동체의 주행에 영향을 미칠 수 있을 것으로 예측되는 핵심 객체 분류(핵심 클래스)만을 선별하여 의미론적 분할(Semantic Segmentation)을 적 용할 수 있다. 예시적으로, 위치 추정 장치가 고려하는 핵심 객체 분류에는 신호등(Traffic Light), 차선 표시(Lane Marking), 펜스 구조물, 기둥 구조물, 교통 표지판(Traffic Sign), 인접 주행 차량(Car), 인도(Sidewalk), 건 물(Building) 등이 포함될 수 있으며, 예시적으로 높은 추론 속도를 확보하기 위해 전체 클래스(Class)의 수는 10개 이하로 유지될 수 있다. 또한, 위치 추정 장치는 전술한 제1인공지능 모델에 기초하여 영상 입력 각각의 픽셀에 대응하는 클래스를 결정하고, 결정된 클래스에 대하여 미리 설정된 색상(달리 말해, 클래스 각각에 대하여 사전에 설정된 색상)을 영상 입력에 각각 표시할 수 있다. 이에 따라, 도 2 및 도 7a에 도시된 바와 같이 시맨틱 분할 이미지는 픽셀별 로 분류된 클래스에 대응하는 색상이 표시되도록 변환되어 소정의 객체 유형에 대응되는 영역이 시각적으로 구 분되도록 색채화(Colorized)될 수 있다. 또한, 도 2 및 도 3을 참조하면, 위치 추정 장치는 미리 구축된 시맨틱 포인트 클라우드 맵(1000, 'SPC M')과 제1인공지능 모델을 이용하여 생성된 시맨틱 분할 이미지를 매칭하여 이동체의 위치 정보를 추정할 수 있다. 도 4는 시맨틱 포인트 클라우드 맵을 설명하기 위한 도면이다. 도 4를 참조하면, 본원의 실시예에 관한 설명에서 시맨틱 포인트 클라우드 맵은 대상 공간을 포함하는 맵 구축 공간 내에 위치하는 미리 설정된 유형의 객체의 위치 정보를 나타내는 복수의 3차원 점을 포함하되, 각 객 체의 위치 정보를 나타내는 복수의 3차원 점 각각에 대하여 해당 객체의 객체 분류 정보가 할당되도록 미리 구 축될 수 있다. 구체적으로, 위치 추정 장치는 복수의 3차원 점을 포함하는 포인트 클라우드를 수집하고(도 4의 (a) 참 조), 입력되는 소정의 포인트 클라우드에 대하여 객체 기반의 의미론적 분할을 수행하도록 미리 학습된 제2인공 지능 모델에 기초하여 수집된 포인트 클라우드에 대응하는 시맨틱 포인트 클라우드를 생성(도 4의 (b) 참조)하 여 시맨틱 포인트 클라우드 맵을 사전에 생성할 수 있다. 예시적으로, 복수의 3차원 점을 포함하는 포인트 클라 우드는 이동식 차량 측정 시스템(Mobile Mapping System)에 의해 수집되는 것일 수 있으나, 이에만 한정되는 것 은 아니다. 다른 예로, 위치 추정 장치는 시맨틱 포인트 클라우드 맵을 저장하도록 사전에 구축된 맵 데이터베 이스로부터 대상 공간에 대응하는 국부적인 맵 정보를 수신하는 것일 수 있다. 이하에서는 위치 추정 장치가 시맨틱 포인트 클라우드 맵과 시맨틱 분할 이미지를 파티클 필터 (Particle Filter)에 기반하여 매칭하여 이동체의 위치 정보를 추정하는 프로세스에 대하여 설명하도록 한다. 도 5는 파티클 필터를 설명하기 위한 개념도이다. 도 5를 참조하면, 위치 추정 장치는 시맨틱 포인트 클라우드 맵으로부터 이동체의 후보 위치를 나타내는 복수의 파티클 각각에 대응하는 포인트 클러스터를 획득할 수 있다. 이와 관련하여, 파티클 필터는 이동체의 자세나 위치에 대한 예측 값을 확률적으로 발생시킨 파티클을 기 구 축된 맵 상에 임의로 배치한 후 반복적인 정보 획득을 통해 이동체가 실제로 위치할 가능성이 높은 파티클로 이동체의 추정 위치가 수렴되도록 동작하는 위치 추정 알고리즘으로서 비선형식을 사용한 모델에도 적용이 가능하며 연산 속도가 빠르고 구현이 쉽다는 이점이 있다. 이러한 파티클 필터에 대한 사항은 통상의 기술자에 게 자명한 사항이므로 보다 상세한 설명은 생략하도록 한다. 구체적으로, 위치 추정 장치는 시맨틱 포인트 클라우드 맵으로부터 이동체의 후보 위치를 나타내 는 복수의 파티클 각각에 대응하는 포인트 클러스터를 획득할 수 있다. 보다 구체적으로, 위치 추정 장치 는 각각의 파티클에 대응하는 이동체의 후보 위치 각각에 실제로 이동체가 위치하는 것으로 가정하였을 때 해당 위치에서의 이동체의 관심 영역에 포함되는 시맨틱 포인트 클라우드 맵 내의 복수의 3차원 점 을 포함하는 포인트 클러스터를 시맨틱 포인트 클라우드 맵으로부터 추출할 수 있다. 한편, '관심 영역'과 관련하여, 본원의 일 실시예에 따르면, 위치 추정 장치는 이동체의 주변 공간에서 인지 중요도를 기초로 설정된 기준 거리를 결정하고, 이동체의 위치 또는 후보 위치로부터 기준 거리 내의 영역(예를 들면, 이동체 내부의 특정 기준점으로부터 설정된 기준 거리 이내로 떨어진 영역)을 관심 영역으 로 설정하는 것일 수 있다. 또한, 본원의 일 실시예에 따르면, 관심 영역은 이동체으로부터 기준 거리 내의 영역 중 이동체의 주행 방향 또는 이동체에 구비되는 카메라 모듈의 촬영 방향에 부합하는 영역으로 설정될 수 있다. 여기서, 카메라 모듈의 촬영 방향은 카메라 모듈의 시야, FoV(Field of View) 등으로 달리 지칭될 수 있다. 이해를 돕기 위해 예시하면, 관심 영역 설정을 위하여 설정된 기준 거리는 50m일 수 있으나, 이에만 한정되는 것은 아니며, 이동체의 유형, 이동체가 주행중인 도로의 규모, 이동체의 주행 위치 정보 등에 기초하 여 기준 거리는 상이하게 설정될 수 있으며, 이동체가 주행되는 도중에도 변동될 수 있다. 구체적으로, 이동 체가 전진 구동 중인 경우, 이동체의 전방 영역, 측방 영역 등은 관심 영역에 포함되고, 이동체의 후 방 영역은 관심 영역에 미포함되는 것일 수 있다. 이와 반대로, 이동체가 후진 구동 중인 경우에는, 이동체 의 후방 영역, 측방 영역 등은 관심 영역에 포함되고, 이동체의 전방 영역은 관심 영역으로 미포함되는 것일 수 있다. 또한, 본원의 일 실시예에 따르면, 관심 영역 설정을 위한 기준 거리 값은 이동체가 전진하는 경우의 기준 거리가 이동체가 후진하는 경우의 기준 거리보다 크게 설정될 수 있다. 이는, 이동체가 전진하는 경우 통 상적으로 주행 속도가 후진하는 경우에 비해 빠르므로 보다 넓은 범위에 대한 객체 식별이 요구되기 때문일 수 있다. 이와 관련하여, 본원의 일 실시예에 따르면, 관심 영역 설정을 위한 기준 거리 값은 이동체의 주행 속 도 정보에 기초하여 결정되는 것일 수 있다. 예를 들어, 이동체의 주행 속도가 빠른 경우가 주행 속도가 상 대적으로 느린 경우에 비하여 관심 영역 설정을 위한 기준 거리 값이 크게 설정되는 것일 수 있다. 또한, 도 5를 참조하면, 위치 추정 장치는 이동체의 관성 센서 정보에 기초하여 예측되는 파티클의 상 태 정보의 변화에 따른 변동 위치가 이동체의 위성 항법 정보(GPS 정보, GNSS 정보 등)에 기초하여 이동체 로부터 미리 설정된 거리(도 5의 δGPS) 이내인 것으로 예측된 파티클을 선정하여 각 파티클에 대응하는 포인 트 클러스터를 선택적으로 획득하는 것일 수 있다. 여기서, 파티클의 상태 정보란 복수의 파티클 각각의 좌표 정보, 배향 정보 및 높이 정보를 포함할 수 있다. 예시적으로, 각 파티클의 상태 정보의 변화를 예측(Prediction)하기 위한 관성 센서 정보는 이동체에 구비되 는 관성 측정 센서 유닛(Inertial Measurement Unit, 12) 등에 의해 획득되는 것일 수 있다. 한편, 위치 추정 장치는 맵 상의 임의의 위치에 각각 배치되는 복수의 파티클 중 이동체로부터 미리 설정된 거리보다 멀 리 위치하는 것으로 예측되는 파티클들에 대하여 부여된 가중치를 제거(달리 말해, 0으로 갱신)하도록 동작할 수 있다(도 5의 (b) 참조.). 참고로, 이러한 복수의 파티클 중 일부를 선택적으로 선정하는 프로세스는 도 2 및 도 5를 참조하면, 파티클 검증(Particle validation, Validation Check) 프로세스 등으로 지칭될 수 있다. 도 6은 랜덤 샘플링(Random Sampling)을 설명하기 위한 개념도이다. 도 6을 참조하면, 위치 추정 장치는 관심 영역에 포함된 복수의 3차원 점에 랜덤 샘플링(Random Samplin g)을 적용하여 시맨틱 분할 이미지에 대하여 후술하는 바와 같이 투영되는 복수의 3차원 점의 수를 감소시켜 연 산량을 줄이는 전처리를 수행할 수 있다. 보다 구체적으로, 도 6의 (a)는 관심 영역에 포함된 복수의 3차원 점 에 대하여 랜덤 샘플링이 적용되기 전 상태를 나타내고, 도 6의 (b)는 랜덤 샘플링이 적용된 후 랜덤 샘플링에 의해 제거되지 않은 복수의 3차원 점을 나타낸 것이다. 또한, 위치 추정 장치는 획득한 포인트 클러스터를 시맨틱 분할 이미지 상에 각각 투영할 수 있다. 본원의 일 실시예에 따르면, 위치 추정 장치는 미리 설정된 교정 파라미터(Calibration parameter)를 기초로 하여 3차원 공간 상에서 위치가 정의되는 포인트 클러스터 내의 각각의 3차원 점 각각이 2차원의 시맨틱 분할 이미지 상에서 대응되는 지점을 결정하는 방식으로 시맨틱 분할 이미지로의 투영(Projection)을 수행할 수 있다. 이와 관련하여, 도 7a는 제1인공지능 모델에 기초하여 생성되는 시맨틱 분할 이미지를 예시적으로 나타낸 도면 이고, 도 7b는 소정의 파티클에 대응하는 포인트 클러스터를 시맨틱 분할 이미지에 대하여 투영한 이미지를 예 시적으로 나타낸 도면이다. 또한, 위치 추정 장치는 각 파티클에 대응하는 포인트 클러스터에 포함된 복수의 3차원 점 각각에 대하여 할당된 제1객체 분류 정보 및 복수의 3차원 점 각각이 투영된 지점에 대하여 할당된 시맨틱 분할 이미지의 제2 객체 분류 정보 간의 유사도에 따른 매칭 스코어를 복수의 파티클마다 연산할 수 있다. 또한, 본원의 일 실시예에 따르면, 객체 분류 정보 간의 유사도는 전술한 복수의 클래스 각각에 대하여 개별 연 산될 수 있다. 예를 들어, 위치 추정 장치는 차선, 교통 표지판, 신호등, 펜스 구조물, 조명 구조물 및 건 물 중 적어도 하나를 포함하는 미리 설정된 유형(클래스)의 객체 각각에 대하여 객체 분류 정보를 할당하고, 시 맨틱 포인트 클라우드 맵과 시맨틱 분할 이미지의 매칭 결과, 소정의 3차원 점에 대하여 의미론적으로 부여된 클래스와 동일한 클래스가 시맨틱 분할 이미지 상에 할당된 지점에 해당 3차원 점이 투영될수록 매칭 스코어는 상대적으로 높게 연산될 수 있다. 예시적으로, 도 3에 도시된 SPCM Projection에 따른 첫 번째 파티클(Particle 1)의 경우, 두 번째 파티클 (Particle 2) 대비 시맨틱 분할 이미지 상에서 의미론적으로 분할된 객체 분류 정보(제2객체 분류 정보)와 투영 된 3차원 점 각각에 대하여 기 할당된 객체 분류 정보(제1객체 분류 정보)가 상대적으로 유사한 패턴을 보이는 것(동일한 객체 분류 정보가 할당된 투영된 점 및 픽셀 간의 이미지 상의 위치가 상대적으로 근접한 것)을 확인 할 수 있다. 이에 따라, 첫 번째 파티클에 대응하는 후보 위치가 두 번째 파티클에 대응하는 후보 위치 대비 이 동체의 실체 위치와 상대적으로 더 근접한 것으로 평가되어 첫 번째 파티클에 대응하여 연산되는 매칭 스코 어가 높은 값으로 도출될 수 있다. 이에 따라, 위치 추정 장치는 매칭 스코어가 상대적으로 높게 연산된 파티클에 따른 후보 위치가 이동체 의 실제 위치와 근접할 것으로 예측하는 방식으로 이동체의 실제 위치 정보를 추정할 수 있다. 보다 구체 적으로, 위치 추정 장치는 복수의 파티클 각각에 대하여 연산된 매칭 스코어에 기초하여 복수의 파티클 각 각에 대한 가중치를 갱신할 수 있다. 이해를 돕기 위해 예시하면, 도 5의 (b)에 도시된 바와 같이 초기 상태에 서는 모두 동등한 값으로 가중치가 할당(예시적으로, 도 5의 (b)를 참조하면, 0.083)된 복수의 파티클은 전술한 프로세스를 통해 매칭 스코어가 연산되고 나면, 매칭 스코어가 높게 연산된 파티클에 대한 가중치가 높은 값으 로 할당되도록 가중치가 갱신될 수 있다. 한편, 본원의 일 실시예에 따르면, 복수의 파티클 각각에 대한 매칭 스코어는 IoU(Intersection over Union) 메 트릭에 기반하여 연산될 수 있으나, 이에만 한정되는 것은 아니고, 본원의 구현예에 따라 정밀도(Precision), 재현율(Recall) 등의 성능 평가를 위한 메트릭에 기반하여 연산되는 것일 수 있다. 이와 관련하여, 본원의 일 실시예에 따르면, 위치 추정 장치는 각각의 객체 유형(클래스)마다 시맨틱 분할 이미지 상에 투영된 복수의 3차원 중 해당 클래스에 대응하는 제1객체 분류 정보가 할당된 3차원 점이 차지하는 영역인 제1영역과 해당 클래스에 대응하는 제2객체 분류 정보가 시맨틱 분할 이미지 상에 할당된 영역인 제2영 역이 중첩되는 면적(Area of Overlap)을 제1영역 및 제2영역을 통합한 영역의 면적(Area of Union)으로 나누는 방식으로 IoU(Intersection over Union) 메트릭에 기반하여 매칭 스코어를 연산할 수 있으나, 이에만 한정되는 것은 아니다. 도 7c는 소정의 파티클에 대응하여 연산된 매칭 스코어를 예시적으로 나타낸 도면이다. 도 7c를 참조하면, 위치 추정 장치는 관심 영역에서 식별되는 각각의 객체 유형(클래스)마다 매칭 스코어 를 개별 연산할 수 있다. 예시적으로, 도 7c은 교통 신호등(Traffic Light), 교통 표지(Traffic sign), 기둥 구조물(Pole), 펜스 구조물(Fence), 차선 표시(Lane Marking), 건물(Building) 등의 각 클래스마다의 매칭 스 코어를 개별 도출할 수 있다. 또한, 위치 추정 장치는 각 클래스마다 도출된 매칭 스코어를 종합(예를 들 면, 합 연산 등)하여 복수의 파티클 각각의 가중치를 갱신할 수 있다. 도 8은 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통 한 위치 추정 장치의 개략적인 구성도이다. 도 8을 참조하면, 위치 추정 장치는 맵 구축부, 이미지 획득부, 이미지 처리부 및 매칭부 를 포함할 수 있다. 맵 구축부는 복수의 3차원 점을 포함하는 포인트 클라우드를 수집할 수 있다. 또한, 맵 구축부는 입력되는 소정의 포인트 클라우드에 대하여 객체 기반의 의미론적 분할을 수행하도록 미리 학습된 제2인공지능 모델에 기초하여 수집된 포인트 클라우드에 대응하는 시맨틱 포인트 클라우드를 생성 하여 시맨틱 포인트 클라우드 맵을 구축할 수 있다. 이미지 획득부는 소정의 이동체에 대한 주변 공간인 대상 공간에 대한 영상 입력을 수신할 수 있다. 이미지 처리부는 입력되는 소정의 영상에 대하여 객체 기반의 의미론적 분할을 수행하도록 미리 학습된 제 1인공지능 모델에 기초하여 수신된 영상 입력에 대응하는 시맨틱 분할 이미지를 생성할 수 있다. 매칭부는 미리 구축된 시맨틱 포인트 클라우드 맵과 생성된 시맨틱 분할 이미지를 매칭하여 이동체 의 위치 정보를 추정할 수 있다. 도 9는 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통 한 위치 추정 장치의 매칭부의 세부 구성도이다. 도 9를 참조하면, 매칭부는 파티클 정보 획득부, 투영부, 매칭 스코어 연산부 및 가중치 갱신부를 포함할 수 있다. 파티클 정보 획득부는 시맨틱 포인트 클라우드 맵으로부터 이동체의 후보 위치를 나타내는 복수 의 파티클 각각에 대응하는 포인트 클러스터를 획득할 수 있다. 투영부는 획득한 포인트 클러스터를 이미지 처리부에 의해 생성된 시맨틱 분할 이미지 상에 각각 투 영할 수 있다. 매칭 스코어 연산부는 각각의 파티클에 대응하는 포인트 클러스터에 포함된 복수의 3차원 점 각각에 대하 여 할당된 제1객체 분류 정보 및 해당 포인트 클러스터의 복수의 3차원 점 각각이 시맨틱 분할 이미지 상에 투 영된 지점에 대하여 할당된 시맨틱 분할 이미지의 제2객체 분류 정보 간의 유사도에 따른 매칭 스코어를 복수의 파티클마다 연산할 수 있다. 가중치 갱신부는 연산된 매칭 스코어에 기초하여 복수의 파티클 각각에 대한 가중치를 갱신할 수 있다. 또한, 매칭부는 복수의 파티클 각각에 대응하는 후보 위치 및 가중치 갱신부에 의해 갱신된 가중치에 기초하여 이동체의 위치 정보를 도출(예를 들면, 확률적으로 결정)할 수 있다. 이하에서는 상기에 자세히 설명된 내용을 기반으로, 본원의 동작 흐름을 간단히 살펴보기로 한다. 도 10은 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 방법에 대한 동작 흐름도이다. 도 10에 도시된 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 방 법은 앞서 설명된 위치 추정 장치에 의하여 수행될 수 있다. 따라서, 이하 생략된 내용이라고 하더라도 위 치 추정 장치에 대하여 설명된 내용은 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 방법에 대한 설명에도 동일하게 적용될 수 있다. 도 10을 참조하면, 단계 S11에서 맵 구축부는 입력되는 소정의 포인트 클라우드에 대하여 객체 기반의 의 미론적 분할을 수행하도록 미리 학습된 제2인공지능 모델에 기초하여 수집된 포인트 클라우드에 대응하는 시맨 틱 포인트 클라우드를 생성하여 시맨틱 포인트 클라우드 맵을 구축할 수 있다. 다음으로, 단계 S12에서 이미지 획득부는 소정의 이동체에 대한 주변 공간인 대상 공간에 대한 영상 입 력을 수신할 수 있다. 다음으로, 단계 S13에서 이미지 처리부는 입력되는 소정의 영상에 대하여 객체 기반의 의미론적 분할을 수 행하도록 미리 학습된 제1인공지능 모델에 기초하여 단계 S12에서 수신된 영상 입력에 대응하는 시맨틱 분할 이 미지를 생성할 수 있다. 다음으로, 단계 S14에서 매칭부는 미리 구축된 시맨틱 포인트 클라우드 맵과 단계 S13을 통해 생성 된 시맨틱 분할 이미지를 매칭하여 이동체의 위치 정보를 추정할 수 있다. 구체적으로, 단계 S14에서 파티클 정보 획득부는 시맨틱 포인트 클라우드 맵으로부터 이동체의 후보 위치를 나타내는 복수의 파티클 각각에 대응하는 포인트 클러스터를 획득할 수 있다. 또한, 단계 S14에서 투영부는 획득한 포인트 클러스터를 이미지 처리부에 의해 생성된 시맨틱 분할 이미지 상에 각각 투영할 수 있다.또한, 단계 S14에서 매칭 스코어 연산부는 각각의 파티클에 대응하는 포인트 클러스터에 포함된 복수의 3 차원 점 각각에 대하여 할당된 제1객체 분류 정보 및 해당 포인트 클러스터의 복수의 3차원 점 각각이 시맨틱 분할 이미지 상에 투영된 지점에 대하여 할당된 시맨틱 분할 이미지의 제2객체 분류 정보 간의 유사도에 따른 매칭 스코어를 복수의 파티클마다 연산할 수 있다. 또한, 단계 S14에서 가중치 갱신부는 연산된 매칭 스코어에 기초하여 복수의 파티클 각각에 대한 가중치를 갱신할 수 있다. 또한, 단계 S14에서 매칭부는 복수의 파티클 각각에 대응하는 후보 위치 및 가중치 갱신부에 의해 갱 신된 가중치에 기초하여 이동체의 위치 정보를 도출할 수 있다. 상술한 설명에서, 단계 S11 내지 S14는 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단 계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매 체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매 체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같 은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아 니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역 도 마찬가지이다. 또한, 전술한 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 방법 은 기록 매체에 저장되는 컴퓨터에 의해 실행되는 컴퓨터 프로그램 또는 애플리케이션의 형태로도 구현될 수 있 다."}
{"patent_id": "10-2021-0156886", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본원의 설명은 예시를 위한 것이며, 본원이 속하는 기술분야의 통상의 지식을 가진 자는 본원의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해 석되어야 한다."}
{"patent_id": "10-2021-0156886", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통 한 위치 추정 장치를 포함하는 이동체 위치 추정 시스템의 개략적인 구성도이다. 도 2 및 도 3은 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 장치가 수행하는 이동체의 위치 추정 프로세스를 설명하기 위한 개념도이다. 도 4는 시맨틱 포인트 클라우드 맵을 설명하기 위한 도면이다. 도 5는 파티클 필터를 설명하기 위한 개념도이다. 도 6은 랜덤 샘플링(Random Sampling)을 설명하기 위한 개념도이다. 도 7a는 제1인공지능 모델에 기초하여 생성되는 시맨틱 분할 이미지를 예시적으로 나타낸 도면이다. 도 7b는 소정의 파티클에 대응하는 포인트 클러스터를 시맨틱 분할 이미지에 대하여 투영한 이미지를 예시적으 로 나타낸 도면이다. 도 7c는 소정의 파티클에 대응하여 연산된 매칭 스코어를 예시적으로 나타낸 도면이다. 도 8은 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통 한 위치 추정 장치의 개략적인 구성도이다. 도 9는 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통 한 위치 추정 장치의 매칭부의 세부 구성도이다. 도 10은 본원의 일 실시예에 따른 시맨틱 분할 이미지 및 시맨틱 포인트 클라우드 맵 기반의 전체론적 매칭을 통한 위치 추정 방법에 대한 동작 흐름도이다."}
