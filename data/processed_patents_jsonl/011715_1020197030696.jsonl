{"patent_id": "10-2019-7030696", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0023266", "출원번호": "10-2019-7030696", "발명의 명칭": "심층 신경망 및 신경망 애플리케이션을 위한 데이터 스트림에 태그 지정 및 라벨링하기 위한", "출원인": "뉴럴라 인코포레이티드", "발명자": "워브스 제레미"}}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "일련의 이미지에 태그 지정하는(tagging) 방법으로서,사용자에 의해, 일련의 이미지 내 제1 이미지 내의 오브젝트(object)의 표현(representation)의 제1 인스턴스에태그 지정하는 단계;적어도 하나의 프로세서에 의해, 상기 제1 이미지에서 상기 사용자에 의해 태그 지정된 상기 오브젝트의 상기표현을 학습하는 단계;상기 적어도 하나의 프로세서에 의해, 상기 일련의 이미지 내 상기 오브젝트의 상기 표현의 제2 인스턴스에 태그 지정하는 단계;상기 사용자에 의해, 상기 적어도 하나의 프로세서에 의해 생성된 상기 오브젝트의 상기 표현의 상기 제2 인스턴스의 태그 및/또는 위치의 조정을 수행하는 단계; 및상기 조정에 기초하여 상기 적어도 하나의 프로세서에 의해, 상기 일련의 이미지 내 상기 오브젝트의 상기 표현의 제3 인스턴스에 태그 지정하는 단계를 포함하는, 일련의 이미지에 태그 지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 오브젝트의 상기 표현의 상기 제2 인스턴스는 상기 일련의 이미지 내 상기 제1 이미지 내에 있는, 일련의 이미지에 태그 지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 오브젝트의 상기 표현의 상기 제2 인스턴스는 상기 일련의 이미지 내 다른 이미지 내에있는, 일련의 이미지에 태그 지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 사용자에 의해, 상기 적어도 하나의 프로세서에 의해 생성된 상기 오브젝트의 상기 표현의 상기 제3 인스턴스의 태그 및/또는 위치의 조정을 수행하는 단계; 및상기 오브젝트의 상기 표현의 상기 제3 인스턴스의 태그 및/또는 위치의 상기 조정에 기초하여 상기 적어도 하나의 프로세서에 의해, 상기 일련의 이미지 내 상기 오브젝트의 상기 표현의 제4 인스턴스에 태그 지정하는 단계를 더 포함하는, 일련의 이미지에 태그 지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 적어도 하나의 프로세서상에서 실행되는 고속 학습 분류기를 통해, 상기 제1 이미지에서 상기 사용자에 의해 태그 지정된 상기 오브젝트의 상기 표현을 분류하는 단계를 더 포함하는, 일련의 이미지에 태그 지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 오브젝트의 상기 표현의 상기 제3 인스턴스에 태그 지정하는 단계는,상기 고속 학습 분류기에 동작 가능하게 결합된 신경망을 사용하여, 상기 오브젝트의 상기 표현의 상기 제3 인스턴스의 피처(feature)를 나타내는 컨볼루션 출력(convolutional output)을 추출하는 단계; 및상기 고속 학습 분류기를 사용하여, 상기 컨볼루션 출력에 기초하여 상기 오브젝트의 상기 표현의 상기 제3 인공개특허 10-2020-0023266-3-스턴스를 분류하는 단계를 포함하는, 일련의 이미지에 태그 지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 오브젝트의 상기 표현의 상기 제2 인스턴스에 태그 지정하는 단계는,상기 적어도 하나의 프로세서상에서 실행되는 신경망을 사용하여, 상기 오브젝트의 상기 표현의 상기 제2 인스턴스의 피처를 나타내는 컨볼루션 출력을 추출하는 단계; 및상기 신경망에 동작 가능하게 결합된 분류기를 사용하여, 상기 컨볼루션 출력에 기초하여 상기 오브젝트의 상기표현의 상기 제2 인스턴스를 분류하는 단계를 포함하는, 일련의 이미지에 태그 지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "일련의 이미지에 태그 지정하기 위한 시스템으로서,사용자가 상기 일련의 이미지 내 제1 이미지 내의 오브젝트의 표현의 제1 인스턴스에 태그 지정하게 하는 사용자 인터페이스; 및상기 사용자 인터페이스에 동작 가능하게 커플링되어, 상기 제1 이미지에서 상기 사용자에 의해 태그 지정된 상기 오브젝트의 상기 표현을 학습하고 상기 일련의 이미지 내 상기 오브젝트의 상기 표현의 제2 인스턴스에 태그지정하는 적어도 하나의 프로세서를 포함하되,상기 사용자 인터페이스는 상기 사용자가 상기 적어도 하나의 프로세서에 의해 생성된 상기 오브젝트의 상기 표현의 상기 제2 인스턴스의 태그 및/또는 위치의 조정을 수행하게 하고, 상기 적어도 하나의 프로세서는 상기 조정에 기초하여 상기 일련의 이미지 내 상기 오브젝트의 상기 표현의 제3 인스턴스에 태그 지정하도록 구성되는,일련의 이미지에 태그 지정하기 위한 시스템."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 사용자 인터페이스는 상기 사용자가 상기 적어도 하나의 프로세서에 의해 생성된 상기 오브젝트의 상기 표현의 상기 제3 인스턴스의 태그 및/또는 위치의 조정을 상기 사용자에 의해 수행하게 하고, 상기적어도 하나의 프로세서는 상기 오브젝트의 상기 표현의 상기 제3 인스턴스의 상기 태그 및/또는 위치의 상기조정에 기초하여 상기 일련의 이미지 내 상기 오브젝트의 상기 표현의 제4 인스턴스에 태그 지정하도록 구성되는, 일련의 이미지에 태그 지정하기 위한 시스템."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 상기 오브젝트의 상기 표현의 상기 제2 인스턴스는 상기 일련의 이미지 내 상기 제1 이미지 내에 있는, 일련의 이미지에 태그 지정하기 위한 시스템."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 상기 오브젝트의 상기 표현의 상기 제2 인스턴스는 상기 일련의 이미지 내 제2 이미지 내에 있는, 일련의 이미지에 태그 지정하기 위한 시스템."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서, 상기 프로세서는 상기 제1 이미지에서 상기 사용자에 의해 태그 지정된 상기 오브젝트의 상기표현을 분류하기 위한 고속 학습 분류기를 구현하도록 구성되는, 일련의 이미지에 태그 지정하기 위한 시스템."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 프로세서는 상기 오브젝트의 상기 표현의 상기 제2 인스턴스 및 상기 오브젝트의 상기 표현의 상기 제3 인스턴스 중 적어도 하나에 대응하는 피처를 나타내는 적어도 하나의 컨볼루션 출력을 추출하기 위한 신경망을 구현하도록 더 구성되며; 그리고상기 분류기는 상기 적어도 하나의 컨볼루션 출력에 기초하여 상기 오브젝트의 상기 표현의 상기 제2 인스턴스및 상기 오브젝트의 상기 표현의 상기 제3 인스턴스 중 적어도 하나를 분류하도록 구성되는, 일련의 이미지에공개특허 10-2020-0023266-4-태그 지정하기 위한 시스템."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "데이터 스트림 내의 오브젝트에 태그 지정하는 방법으로서,적어도 하나의 프로세서상에서 실행되는 신경망을 사용하여, 데이터 스트림으로부터의 제1 컨볼루션 출력을 추출하는 단계로서, 상기 데이터 스트림은 제1 클래스의 오브젝트의 적어도 두 개의 표현을 포함하고, 상기 제1컨볼루션 출력은 상기 제1 카테고리의 오브젝트의 제1 표현의 피처를 나타내는, 상기 제1 컨볼루션 출력을 추출하는 단계;신경망에 동작 가능하게 결합된 분류기를 사용하여, 상기 제1 컨볼루션 출력에 기초하여 상기 제1 표현을 상기제1 카테고리의 오브젝트로 분류하는 단계;상기 분류기에 동작 가능하게 결합된 사용자 인터페이스를 통해, 상기 제1 카테고리에 기초하여 상기 제1 표현에 대한 태그 및/또는 위치를 디스플레이하는 단계;상기 사용자 인터페이스를 통해 사용자에 의해, 상기 제1 표현에 대한 상기 태그 및/또는 상기 위치의 조정을수행하는 단계; 및상기 분류기에 의해, 상기 조정에 기초하여 상기 오브젝트의 상기 적어도 하나의 표현의 상기 태그 및/또는 상기 위치를 학습하는 단계를 포함하는, 데이터 스트림 내의 오브젝트에 태그 지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 태그는 제1 태그이고 상기 위치는 제1 위치이며,상기 신경망을 사용하여, 상기 데이터 스트림으로부터의 제2 컨볼루션 출력을 추출하는 단계로서, 상기 제2 컨볼루션 출력은 상기 제1 카테고리의 오브젝트의 제2 표현의 피처를 나타내는, 상기 제2 컨볼루션 출력을 추출하는 단계;상기 분류기를 사용하여, 상기 제2 컨볼루션 출력 및 상기 제1 표현에 대한 상기 태그 및/또는 상기 위치의 상기 조정에 기초하여 상기 제2 표현을 상기 제1 카테고리로 분류하는 단계; 및상기 사용자 인터페이스를 통해, 상기 제1 카테고리에 기초하여 제2 태그 및/또는 제2 위치를 디스플레이하는단계를 더 포함하는, 데이터 스트림 내의 오브젝트에 태그 지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 분류기를 사용하여, 상기 제1 표현의 상기 태그 및/또는 위치가 정확하다는 신뢰도 값을 결정하는 단계;및상기 신뢰도 값을 상기 사용자에게 디스플레이하는 단계를 더 포함하는, 데이터 스트림 내의 오브젝트에 태그지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서, 상기 오브젝트는 제1 오브젝트이고 상기 태그는 제1 태그이며,상기 분류기에 의해, 제2 카테고리의 오브젝트에 대한 제2 태그를 학습하는 단계로서, 상기 데이터 스트림은 상기 제2 카테고리의 오브젝트의 적어도 하나의 표현을 포함하는, 상기 제2 태그를 학습하는 단계를 더 포함하는,데이터 스트림 내의 오브젝트에 태그 지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 신경망을 사용하여, 후속하는 데이터 스트림으로부터 후속하는 컨볼루션 출력을 추출하는 단계로서, 상기후속하는 데이터 스트림은 상기 제2 카테고리의 오브젝트의 적어도 하나의 다른 표현을 포함하고, 상기 후속하는 컨볼루션 출력은 상기 제2 카테고리의 오브젝트의 상기 적어도 하나의 다른 표현의 피처를 나타내는, 상기공개특허 10-2020-0023266-5-컨볼루션 출력을 추출하는 단계;상기 분류기를 사용하여, 상기 후속하는 컨볼루션 출력 및 상기 제2 태그에 기초하여 상기 제2 카테고리의 오브젝트의 상기 적어도 하나의 다른 표현을 상기 제2 카테고리로 분류하는 단계; 및상기 사용자 인터페이스를 통해, 상기 제2 태그를 디스플레이하는 단계를 더 포함하는, 데이터 스트림 내의 오브젝트에 태그 지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 제1 컨볼루션 출력을 추출하는 단계는,상기 데이터 스트림에서 제1 이미지의 복수의 세그먼트화된 서브 영역을 생성하는 단계; 및상기 신경망에 의해, 상기 복수의 세그먼트화된 서브 영역의 각각을 인코딩하는 단계를 포함하는, 데이터 스트림 내의 오브젝트에 태그 지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "시스템으로서,적어도 하나의 프로세서로서,데이터 스트림으로부터 제1 컨볼루션 출력을 추출하기 위한 신경망으로서, 상기 데이터 스트림은 제1 카테고리의 오브젝트의 적어도 두 개의 표현을 포함하고, 상기 제1 컨볼루션 출력은 상기 제1 카테고리의 오브젝트의 제1 표현의 피처를 나타내는, 상기 신경망; 및상기 제1 컨볼루션 출력에 기초하여 상기 제1 표현을 상기 제1 카테고리로 분류하고 사용자에 의한 조정에 기초하여 상기 오브젝트의 상기 제1 표현의 태그 및/또는 위치를 학습하기 위한 고속 학습 모듈을 구현하도록 구성된, 상기 적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서에 동작 가능하게 커플링되어, 상기 제1 표현에 대한 상기 태그 및/또는 상기 위치를 디스플레이하고 상기 사용자가 상기 제1 표현의 상기 태그 및/또는 상기 위치의 상기 조정을 수행하게 하는사용자 인터페이스를 포함하는, 시스템."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서,상기 태그는 제1 태그이고;상기 위치는 제1 위치이며;상기 신경망은 상기 데이터 스트림으로부터 제2 컨볼루션 출력을 추출하도록 구성되되, 상기 제2 컨볼루션 출력은 상기 제1 카테고리의 오브젝트의 제2 표현의 피처를 나타내고;상기 고속 학습 모듈은, 상기 제2 컨볼루션 출력 및 상기 오브젝트의 상기 적어도 하나의 표현의 상기 제1 인스턴스에 대한 상기 제1 태그 및/또는 상기 제1 위치의 상기 조정에 기초하여 상기 제2 표현을 상기 제1 카테고리로 분류하도록 구성되며; 그리고상기 사용자 인터페이스는 상기 제1 카테고리에 기초하여 제2 태그 및 제2 위치를 디스플레이하도록 더 구성되는, 시스템."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제20항에 있어서,상기 고속 학습 모듈은 상기 제1 태그 및/또는 상기 제1 위치가 정확하다는 신뢰도 값을 결정하도록 구성되고;그리고상기 사용자 인터페이스는 상기 신뢰도 값을 상기 사용자에게 디스플레이하도록 더 구성되는, 시스템."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "공개특허 10-2020-0023266-6-제20항에 있어서, 상기 태그는 제1 태그이고, 상기 고속 학습 모듈은 제2 카테고리의 오브젝트에 대한 제2 태그를 학습하도록 더 구성되되, 상기 데이터 스트림은 상기 제2 카테고리의 오브젝트의 적어도 하나의 표현을 포함하는, 시스템."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서,상기 신경망은 후속하는 데이터 스트림으로부터 후속하는 컨볼루션 출력을 추출하도록 더 구성되되, 상기 후속하는 데이터 스트림은 상기 제2 카테고리의 오브젝트의 적어도 하나의 다른 표현을 포함하고, 상기 후속하는 컨볼루션 출력은 상기 제2 카테고리의 오브젝트의 상기 적어도 하나의 다른 표현의 피처를 나타내고;상기 고속 학습 모듈은 상기 후속하는 컨볼루션 출력 및 상기 제2 태그에 기초하여 상기 제2 카테고리의 오브젝트의 상기 적어도 하나의 다른 표현을 상기 제2 카테고리로 분류하도록 더 구성되고; 그리고상기 사용자 인터페이스는 상기 제2 태그를 디스플레이하도록 더 구성되는, 시스템."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제20항에 있어서, 상기 신경망은,상기 데이터 스트림에서 제1 이미지의 복수의 세그먼트화된 서브 영역을 생성하도록; 그리고상기 복수의 세그먼트화된 서브 영역의 각각을 인코딩하도록 더 구성되는, 시스템."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "오브젝트의 복수의 인스턴스에 태그 지정하는 방법으로서,피처 추출 모듈을 사용하여, 상기 복수의 인스턴스에서 상기 오브젝트의 제1 인스턴스를 나타내는 제1 피처 벡터를 추출하는 단계;사용자 인터페이스를 통해, 제1 라벨을 사용하여 상기 오브젝트의 상기 제1 인스턴스에 태그 지정하는 단계;분류기 모듈에 의해, 상기 제1 피처 벡터를 상기 제1 라벨과 관련시키는 단계;상기 피처 추출 모듈을 사용하여, 상기 복수의 인스턴스에서 상기 오브젝트의 제2 인스턴스를 나타내는 제2 피처 벡터를 추출하는 단계;상기 분류기 모듈을 사용하여, 상기 제1 피처 벡터와 상기 제2 피처 벡터 사이의 거리를 계산하는 단계;상기 분류기 모듈을 사용하여, 미리 정의된 임계치와 차이의 비교를 수행하는 단계; 및상기 분류기 모듈을 사용하여, 상기 비교에 기초하여 상기 오브젝트의 상기 제2 인스턴스를 분류하는 단계를 포함하는, 오브젝트의 복수의 인스턴스에 태그 지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제26항에 있어서,상기 비교에 기초하여 상기 제1 라벨을 사용하여 상기 오브젝트의 상기 제2 인스턴스에 태그 지정하는 단계를더 포함하는, 오브젝트의 복수의 인스턴스에 태그 지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제26항에 있어서,상기 비교에 기초하여 상기 분류의 신뢰도를 결정하는 단계를 더 포함하는, 오브젝트의 복수의 인스턴스에 태그지정하는 방법."}
{"patent_id": "10-2019-7030696", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "오늘날, 인공 신경망은 수동으로 태그가 지정된 이미지의 큰 세트에 대해 트레이닝된다. 일반적으로, 더 나은 트 레이닝을 위해서, 트레이닝 데이터는 가능한 한 커야 한다. 불행히도, 이미지에 수동으로 태그 지정하는 것은 시 간 소모적이고 에러에 취약하며, 인공 신경망을 트레이닝시키기 위해 사용되는 태그 지정된 데이터의 큰 세트를 (뒷면에 계속)"}
{"patent_id": "10-2019-7030696", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 특허 출원(들)에 대한 교차 참조 본 출원은 2017년 3월 17일자로 출원되고, 참조에 의해 그 전체가 본 명세서에 통합되는 미국 출원 번호 제 62/472,925호의, 35 U.S.C. §119(e) 하에서의 우선권 이익을 주장한다."}
{"patent_id": "10-2019-7030696", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "입력 계층(layer)과 출력 계층 사이에 개재되는 많은 뉴런의 계층을 포함하는 컨볼루션 신경망(Convolutional Neural Network: CNN)을 포함하는 전통적인 심층 신경망(Deep Neural Network: DNN)은, 트레이닝할 특정한 데 이터세트에 걸친 수천 또는 수백만 번의 반복 사이클을 필요로 한다. 이 트레이닝이 발생하기 이전에, 데이터세 트 내의 모든 이미지는 인간 사용자에 의해 태그 지정되어야(tagged) 한다. 태그 지정(tagging)의 프로세스는, 분류를 위해 전체 이미지를 라벨링하는(labeling) 것 또는 개개의 오브젝트의 분류 및 검출/세그먼트화 (segmentation)를 위해 각각의 이미지의 개개의 영역을 특정한 오브젝트로서 라벨링하는 것을 수반할 수 있다. 종래의 이미지 태그 지정은 느리고 지루한 프로세스이다. 사람은, 컴퓨터, 태블릿 또는 스마트폰 상에서 사진을 보고; 사진에서 하나 이상의 오브젝트를 식별하고; 설명하는 태그(예를 들면, \"나무\", \"집\" 또는 \"자동차\")를 사용하여 그들 오브젝트에 태그 지정한다. 주목하는 오브젝트에 수동으로 태그 지정하는 것의 주된 어려움은, 주의 산만 및 피로에 의해 야기되는 인적 에러에 대한 취약성 및 느린 속도를 포함한다. 이들 이슈는 두 가지 타입의 문제를 생성한다: 트레이닝을 위한 데이터 준비는, 학업 환경 밖의 어느 곳에서도 허용 불가능하게 길어 질 수 있는 시간이 걸리고, 불량하게 태그 지정된 데이터가 태그는 DNN이 허용 가능한 성능 기준에 도달하는 것 을 허용하지 않을 것이기 때문에, 태깅의 품질은 후속하는 학습의 품질에 직접적으로 영향을 끼친다. 본 기술의 실시형태는 일련의(a sequence of) 이미지에 태그 지정하기 위한 방법 및 시스템을 포함한다. 예시적 인 방법은, 사용자 인터페이스를 통해 사용자에 의해, 일련의 이미지 내 제1 이미지 내의 오브젝트(object)의 표현(representation)의 제1 인스턴스에 태그 지정하는 단계를 포함한다. 적어도 하나의 프로세서는, 제1 이미 지에서 사용자에 의해 태그 지정된 오브젝트의 표현을 학습하고, 일련의 이미지 내 오브젝트의 표현의 제2 인스 턴스에 태그 지정한다. 사용자는, 프로세서(들)에 의해 생성되는 오브젝트의 표현의 제2 인스턴스의 태그 및/또 는 위치의 조정을 수행한다. 그리고 프로세서는, 조정에 기초하여, 일련의 이미지 내 오브젝트의 표현의 제3 인 스턴스에 태그 지정한다. 오브젝트 표현의 제2 인스턴스는, 일련의 이미지 내 제1 이미지에 있을 수 있거나 또는 일련의 이미지의 다른 이미지에 있을 수 있다. 몇몇 경우에, 사용자는 프로세서(들)에 의해 생성되는 오브젝트의 표현의 제3 인스턴스의 태그 및/또는 위치의 조정을 수행할 수도 있고, 프로세서는, 오브젝트의 표현의 제3 인스턴스의 태그 및/또는 위치의 조정에 기초하 여 일련의 이미지 내 오브젝트의 표현의 제4 인스턴스에 태그 지정한다. 이 방법의 예는 또한, 프로세서(들) 상에서 실행되는 고속 학습 분류기(fast learning classifier)를 통해, 제1 이미지에서 사용자에 의해 태그 지정된 오브젝트의 표현을 분류하는 단계를 포함할 수도 있다. 이 경우에, 오브 젝트의 표현의 제3 인스턴스에 태그 지정하는 단계는, 고속 학습 분류기에 동작 가능하게 결합된 신경망으로 오 브젝트의 표현의 제3 인스턴스의 피처(feature)를 나타내는 컨볼루션 출력을 추출하는 것을 포함할 수도 있다. 고속 학습 분류기는, 컨볼루션 출력에 기초하여 오브젝트 표현의 제3 인스턴스를 분류한다. 이 방법의 예는 또한, 프로세서(들) 상에서 실행되는 신경망을 사용하여, 오브젝트의 표현의 제2 인스턴스의 피 처를 나타내는 컨볼루션 출력을 추출하는 것 및 신경망에 동작 가능하게 결합된 분류기를 사용하여, 컨볼루션 출력에 기초하여 오브젝트의 표현의 제2 인스턴스를 분류하는 것에 의해 표현의 제2 인스턴스에 태그 지정하는 단계를 포함할 수도 있다. 일련의 이미지에 태그 지정하기 위한 시스템은, 사용자 인터페이스 및 사용자 인터페이스에 동작 가능하게 결합 된 적어도 하나의 프로세서를 포함할 수도 있다. 동작에서, 사용자 인터페이스는, 사용자가 일련의 이미지 내 제1 이미지 내의 오브젝트 표현의 제1 인스턴스에 태그 지정하게 한다. 그리고 프로세서는 제1 이미지에서 사용 자에 의해 태그 지정된 오브젝트의 표현을 학습하고 일련의 이미지 내 오브젝트의 표현의 제2 인스턴스에 태그 지정한다. 사용자 인터페이스는, 사용자가 적어도 하나의 프로세서에 의해 생성된 오브젝트의 표현의 제2 인스 턴스의 태그 및/또는 위치의 조정을 수행하게 하고 프로세서(들)는, 조정에 기초하여, 일련의 이미지 내 오브젝트의 표현의 제3 인스턴스에 태그 지정한다. 본 기술의 다른 실시형태는 데이터 스트림 내의 오브젝트에 태그 지정하기 위한 방법 및 시스템을 포함한다. 예 시적인 시스템은, 신경망 및 고속 학습 모듈을 구현하도록 구성되는 적어도 하나의 프로세서 및 프로세서(들)에 동작 가능하게 결합된 사용자 인터페이스를 포함한다. 동작에서, 신경망은, 제1 카테고리의 오브젝트의 적어도 두 개의 표현을 포함하는 데이터 스트림으로부터 제1 컨볼루션 출력을 추출한다. 이 제1 컨볼루션 출력은 제1 카테고리의 오브젝트의 제1 표현의 피처를 나타낸다. 고속 학습 모듈은, 제1 컨볼루션 출력에 기초하여 제1 표 현을 제1 카테고리로 분류하고, 사용자에 의한 조정에 기초하여 오브젝트의 제1 표현의 태그 및/또는 위치를 학 습한다. 그리고, 사용자 인터페이스는 제1 표현에 대한 태그 및/또는 위치를 디스플레이하고, 사용자가 제1 표 현의 태그 및/또는 위치를 조정하게 한다. 몇몇 경우에, 태그는 제1 태그이고 위치는 제1 위치이다. 이들 경우에, 신경망은 데이터 스트림으로부터 제2 컨 볼루션 출력을 추출할 수도 있다. 이 제2 컨볼루션 출력은, 제1 카테고리의 오브젝트의 제2 표현의 피처를 나타 낸다. 그리고 이들 경우에, 분류기는, 제2 컨볼루션 출력 및 제1 표현에 대한 태그 및/또는 위치의 조정에 기초 하여 제2 표현을 제1 카테고리로 분류한다. 사용자 인터페이스는, 제1 카테고리에 기초하여, 제2 태그 및/또는 제2 위치를 디스플레이할 수도 있다. 필요한 경우, 분류기는 제1 표현의 태그 및/또는 위치가 정확하다는 신뢰도 값을 결정할 수 있다. 사용자 인터 페이스는 신뢰도 값을 사용자에게 디스플레이할 수도 있다. 오브젝트가 제1 오브젝트이고 태그가 제1 태그인 경우, 분류기는 데이터 스트림에서 표현되는 제2 카테고리의 오브젝트에 대한 제2 태그를 학습할 수 있다. 이들 경우에, 신경망은, 제2 카테고리의 오브젝트의 적어도 하나 의 다른 표현을 포함하는 후속하는 데이터 스트림으로부터 후속하는 컨볼루션 출력을 추출할 수 있다. 이 후속 하는 컨볼루션 출력은, 제2 카테고리의 오브젝트에 대한 다른 표현의 피처를 나타낸다. 분류기는, 후속하는 컨 볼루션 출력 및 제2 태그에 기초하여 제2 카테고리의 오브젝트의 다른 표현을 제2 카테고리로 분류한다. 그리고 사용자 인터페이스는 제2 태그를 디스플레이한다. 이들 경우에, 신경망은, 데이터 스트림에서 제1 이미지의 복 수의 세그먼트화된 서브 영역을 생성하는 것 및 복수의 세그먼트화된 서브 영역의 각각을 인코딩하는 것에 의해, 제1 컨볼루션 출력을 추출할 수도 있다. 본 기술의 또 다른 실시형태는, 오브젝트의 복수의 인스턴스에 태그 지정하는 방법을 포함한다. 이 방법의 예는, 피처 추출 모듈을 사용하여 복수의 인스턴스에서 오브젝트의 제1 인스턴스를 나타내는 제1 피처 벡터를 추출하는 단계를 포함한다. 사용자는 사용자 인터페이스를 통해 오브젝트의 제1 인스턴스에 제1 라벨로 태그 지 정한다. 분류기 모듈은 제1 피처 벡터를 제1 라벨과 관련시킨다. 피처 추출 모듈은 복수의 인스턴스에서 오브젝 트의 제2 인스턴스를 나타내는 제2 피처 벡터를 추출한다. 분류기 모듈은, 제1 피처 벡터와 제2 피처 벡터 사이 의 거리를 계산하고, 미리 정의된 임계치와 차이의 비교를 수행하고, 비교에 기초하여 오브젝트의 제2 인스턴스 를 분류한다. 필요한 경우, 오브젝트의 제2 인스턴스는 비교에 기초하여 제1 라벨로 태그 지정될 수도 있다. 그 리고 분류기 모듈은 비교에 기초하여 분류의 신뢰도를 결정할 수도 있다. 전술한 개념 및 추가적인 개념 - (그러한 개념이 상호 일치하지 않는다면) 이하에서 더 상세히 논의됨 - 의 모 든 조합은 본 명세서에 개시된 본 발명의 주제의 일부인 것으로 고려된다는 것이 인식되어야 한다. 특히, 본 개 시내용의 끝에 나타나는 청구된 주제의 모든 조합은, 본 명세서에 개시된 본 발명의 주제의 일부인 것으로 고려 된다. 참조에 의해 통합되는 임의의 개시내용에서 또한 나타날 수도 있는 본 명세서에서 명시적으로 활용되는 전문 용어는 본 명세서에 개시된 특정한 개념과 가장 일치하는 의미를 부여받아야 한다는 것이 또한 인식되어야 한다."}
{"patent_id": "10-2019-7030696", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "심층 신경망 및 컨볼루션 신경망을 비롯한, 역전파 기반의 신경망(backpropagation-based Neural Network)의 파워는, 이들 아키텍처의 성능을 개발하고, 그 다음, 유효성을 확인하기 위한 많은 양의 트레이닝 및 테스팅 데 이터의 이용 가능성에 의존한다. 그러나, 많은 양의 라벨링된 또는 태그 지정된 데이터를 생성하는 것은 수동적 이고, 번거롭고, 비용이 많이 드는 프로세스이다. 본 출원은, 데이터 스트림에서 식별 및 위치 결정될 주목하는 오브젝트(예를 들면, 적녹청(RGB) 이미지, 포인트 클라우드 데이터, IR 이미지, 초분광 이미지(hyperspectral image), 또는 이들 또는 다른 데이터의 조합)에 자 동적으로 태그 지정하는 것, 주석을 다는 것, 또는 라벨링하는 것에 관한 것이다. 이들 태그 지정된 데이터 스 트림의 하나의 사용은, 적절한 트레이닝을 위해 수천 개의 이미지를 사용하는 역전파 기반의 심층 신경망을 비 롯한, 감독된 신경망(supervised Neural Network)의 트레이닝 및 테스팅에 활용될 트레이닝 및 지상 검증 (ground truth) 데이터를 생성하는 것이다. 용어 \"주석 달기\", \"라벨링\" 및 \"태그 지정\"은, 이 문서에서 상호 교환적으로 사용된다. 본 출원에서, 용어 \"고속 학습\"은, 역전파와는 달리, 이전에 제시된 데이터(또는 그 모두)에 대해 전체 시스템을 재트레이닝시킬 필요 없이, 예를 들면, 단일의 예로부터 점진적으로 업데이트될 수 있는 방법을 설명하기 위해 사용된다. 고속 학습은, 심지어 오브젝트의 단일의 새로운 인스턴스를 학습하기 위 해 데이터의 큰 집성본의 반복적인 제시를 수반하는 \"배취(batch)\" 트레이닝과는 대조적이다. 본 명세서에서 설명되는 기술은, 자동화된 실시간 고속 학습 단계를 도입하는 것에 의해 데이터를 수동으로 라 벨링하는 것을 가속시키고 그 정확도를 향상시킨다 이 고속 학습은, 태그 지정된 항목의 제1 인스턴스를 갖는 동일한 이미지, 후속하는 이미지, 또는 둘 모두 중 어느 하나에서, 태그 지정된 항목의 후속하는 외관에 대한 후보 태그를 제안한다. 반대로, 데이터에 태그 지정하는 현재의 기술은, 인간이 각각의 프레임(예를 들면, 비디 오 스트림 내의 프레임)에서 주목하는 각각의 오브젝트를 라벨링하는 것에 의존한다. 본 발명의 방법은 사용자에게 상호 작용식 지원(interactive assistance)을 도입한다. 이 상호 작용식 지원은, 인간이 데이터를 라벨링하는 프로세스 동안 새로운 태그를 빠르게 학습하는 능력을 갖는, 스마트 태그 지정 시 스템 또는 유틸리티로도 지칭되는 신경망 기반의 자동 어시스턴트의 형태로 나타난다. 자동 어시스턴트는, 새로 운 데이터에 라벨링하거나 또는 그에 대한 라벨을 제안하고, 그것의 제안된 라벨에 대한 수정을 사용자로부터 수신하고, 자동 어시스턴트에 의해 이루어지는 가능한 실수를 사용자가 계속 수정하면서 자동 라벨링의 품질을 반복적으로 개선한다. 이것은, 시스템이 학습함에 따라 점점 더 많은 작업을 그 스스로 떠맡고 사용자에게서 제 거하여, 주목하는 새로운 오브젝트 및 자동 태그의 검증에 사용자가 집중하는 것을 허용하는 이점을 갖는다. 결 과적으로, 태그 지정 프로세스는 더 많은 이미지가 처리됨에 따라 더 빨라지게 된다. 연구에 따르면, 경험이 없 는 인간 태거(tagger)에 대해 40%까지의 태그 지정 속도 향상을 나타내었다 - 다시 말하면, 본 발명의 스마트 태그 지정 유틸리티로 지원을 받은 태그 지정은, 이전에는 이미지 태그 지정을 전혀 하지 않았던 사람에 대한 수동의 태그 지정의 40%이다. 도 1a는 이 태그 지정 프로세스의 예를 도시한다: 1. 사용자는 (예를 들면, 도 1a의 에서) 프레임 1 내의 오브젝트의 제1 인스턴스에 태그 지정한다. 예를 들 면, 사용자는 경계 다각형(bounding polygon)을 묘화할 수 있고, 프레임 1 상의 오브젝트, 예를 들면, 나무에태그 지정할 수 있다. 2. 스마트 태그 지정 유틸리티의 하나 이상의 프로세서상에서 실행되는 분류기는, 태그 지정된 오브젝트를 나타 내는 피처를, 사용자에 의해 정의되는 태그와 관련시키는 것에 의해, (예를 들면, 도 1a의 에서) 오브젝트 의 제1 인스턴스를 학습한다. (나무에 태그 지정하는) 단계 1의 예에서, 분류기는 태그 지정 직후 나무를 학습 한다. 3. 프로세서(들)는 (예를 들면, 도 1a의 에서) 오브젝트의 후속하는 인스턴스에 태그 지정할 수 있다. 예를 들면, 프로세서(들)에 의해 실행되는 컨볼루션 신경망은, (예를 들면, 도 1a의 에서) 프레임으로부터 피처 를 추출할 수 있다. 분류기는 (예를 들면, 도 1a의 에서) 추출된 피처를, 사용자 정의 태그와 관련되는 추 출된 피처에 대한 그들의 유사성에 기초하여 분류한다. 예를 들면, 프로세서는 프레임 1에서 다른 나무에 태그 지정할 수 있다. 상이하게 말하면, 신경망은 프레임 1로부터 다른 나무의 피처를 추출하고 분류기는 그들을 적 절하게 분류한다. 각각의 나무는 경계 다각형과 관련되는 신뢰도 값을 가지며, 어떤 시각적 표시(예를 들면, 경 계 다각형의 컬러, 점선(dotted) 대 파선(dashed) 경계 다각형 윤곽 등)를 통해 다른 수동으로 라벨링된 오브젝 트와는 구별될 수도 있다. 신뢰도 값은 주목하는 오브젝트의 추적 또는 분류를 위한 여러 방법에 의해 할당될 수 있는데, 신뢰도는, 예를 들면, 0과 1 사이의 스칼라일 수 있으며, 여기서 1은 주목하는 오브젝트가 특정 클 래스에 속한다는 절대적 신뢰도를 나타낸다. 특정한 오브젝트는 클래스의 계층 구조와 관련되는 확률의 분포를 가질 수 있을 것이다. 예를 들면, 오브젝트는 나무와 식물로 동시에 분류될 수 있을 것이다. 4. 필요한 경우, 에서, 사용자는 라벨을 조정하거나 또는 프레임 1 내의 머신 생성 경계 다각형의 위치 또 는 형상을 조정하고, 분류기는 고속 학습을 활용하여 자신의 지식을 업데이트하고 사용자에 의해 아직 검증되지 않은 프레임 1 내의 오브젝트에 대한 제안을 업데이트한다. 이것은, 필요한 경우, 오브젝트가 프레임 1에서 만 족스럽게 태그 지정될 때까지, 프레임 1 내의 태그가 지정된 오브젝트를 자동적으로 업데이트할 수 있다. 5. 사용자는 프레임 2를 로딩한다. 6. 스마트 태그 지정 유틸리티는, 프레임 1에서 학습되는 오브젝트가 프레임 2에 나타나는 경우, 자동적으로 그 들에 태그 지정한다. 다른 방식으로 말하면, 스마트 태그 지정 유틸리티는, 프레임 2 내의 오브젝트에 태그 지 정하기 위해, 만약 있는 경우, 프레임 1 내의 태그에 대한 사용자 조정을 고려하는 것에 의해 오브젝트에 자동 적으로 태그 지정한다. 7. 필요한 경우, 사용자는 프레임 1에 존재하지 않았던 새로운 오브젝트를 추가하거나, 또는 다음 프레임으로 진행하고, 어느 경우든, 단계 1 내지 7에서 설명되는 프로세스는, 제공된 이미지 내의 소망되는 오브젝트가 태 그 지정되거나 또는 사용자가 프로세스를 종료할 때까지, 반복된다. 이 방법은 다음과 같은, 주목하는 임의의 영역에 적용될 수 있다: 직사각형, 다각형, 또는 픽셀 기반의 태그 지 정. 다각형 또는 픽셀 기반의 태그 지정에서, 이미지의 영역보다는, 오브젝트의 실루엣이 묘사되어, 태그 지정 되고 있는 오브젝트에서 배경의 영역이 포함될 수도 있는 직사각형 또는 다각형 태그와 관련한 '타겟 상의 픽셀' 카운트를 증가시킨다. 예를 들면, 다음을 포함하는, 그러나 이들로 제한되지는 않는 다양한 기술이 고속 학습 아키텍처를 도입하기 위 해 활용될 수 있다: 고속 분류기, 예컨대 다른 신경망, 지원 벡터 머신(Support Vector Machine), 또는 의사 결정 트리와의 DNN 의 조합, 이 경우 DNN은 고속 분류기에 대한 입력으로서 역할을 할 피처 세트를 제공함; 이미지의 타겟 서브세트(예를 들면, 키포인트 추적기) 상에서 신속하게 초기화될 수 있는 피처 검출 및 추적 프로세스; 및 상기 언급된 기술의 임의의 조합. 본 기술은, 역전파 기반의 신경망, 특히 DNN의 트레이닝을 위한 데이터세트의 효율적이고 비용 효과적인 준비를 가능하게 하고, 더 일반적으로, 자율 차량, 드론, 또는 다른 로봇을 실시간으로 제어하는 것과 같은 목적을 위 해 데이터 분석을 수행하는 수학식의 병렬 분산형 시스템에서 학습을 간소화한다. 더 상세하게는, 본 기술의 예는, 데이터 스트림(예를 들면, 프레임) 또는 일련의 프레임 내의 특정한 오브젝트 의 각각의 발생에 수동으로 태그 지정하는 그리고 데이터세트 준비와 관련되는 수동의 노동 및 비용을 감소시키는 것에 의해 오브젝트를 최적으로 선택하는 프로세스를 향상 또는 대체한다. 데이터 스트림에 태그 지정 및 라벨링하기 위한 점진적 실시간 학습을 위한 프로세스 도 1b는 본 발명의 스마트 태그 지정 시스템의 동작 프로세스의 플로우차트를 도시한다. 이 예에서, 시스템은 이미지에 대해 동작하지만, 그러나 그것은, 태그 지정되어야 하는 주목하는 영역 또는 별개의 오브젝트를 갖는 인간이 이해 가능한 2D 표현을 가질 수 있는 임의의 데이터에 대해 동일하게 잘 동작할 수 있다. 사용자는 시스 템을 시작하고 이미지의 세트 또는 비디오 파일을 시스템 안으로 로딩한다. 비디오 파일의 경우, 추가적인 처리 단계는 비디오를 일련의 키 프레임으로 분해하여 중복 이미지의 수를 감소시킨다. 이 분해는, 비디오 파일 에 인코딩되는 키 프레임 정보를 사용하여 자동적으로, 사용자에 의해 수동으로, 또는 둘 모두를 통해 행해질 수 있다. 일련의 이미지가 준비되면, 시스템은 임의의 태그 지정되지 않은 프레임이 있는지를 체크하고 남 은 것이 없으면 종료한다. 태그 지정되어야 하는 프레임이 있는 경우, 시스템은 제1 프레임을 로딩하 고 이 프레임에 대한 피처 추출을 수행한다. 상이하게 말하면, 시스템은 제1 프레임을 로딩하고 시스템의 하나 이상의 프로세서상의 신경망이 컨볼루션 출력을 추출하고 제1 프레임에 대한 피처를 나타내는 피처 벡터를 생성한다. 피처 추출 구현예의 세부 사항은 하기의 대응하는 섹션에서 개설된다(outlined). 동시에, 시스템은, 자신이 임의의 지식을 이미 가지고 있는지를 체크한다. 이 지식은, 추출된 피처 벡터와 대응하는 라벨 사이의 이전에 학습된 관련성의 세트를 포함할 수도 있다. 이전에 학습된 지식이 추출된 피처 벡 터와 대응하는 라벨 사이의 관련성을 포함하는 경우, 하나 이상의 프로세서상에서 실행되는 분류기는, 각각의 라벨을 갖는 추출된 피처 벡터를 분류한다. 추출된 피처 벡터를 분류하기 위해, 시스템은 피처 매칭을 수행한다. 예를 들면, 시스템은 추출된 피처 벡터를 시스템에게 이미 알려진 피처(예를 들면, 이전에 학습된 지 식)(및 피처 벡터)와 비교한다. 추출된 피처 벡터와 시스템에게 이미 알려진 피처 사이의 피처 공간에서 거리를 측정하는 거리 메트릭(예를 들면, 관련 피처 공간에서의 유클리드 놈(Euclidean norm))에 기초하여 비교가 수행 된다. 그 다음, 시스템은 차이에 기초하여 오브젝트를 분류한다. 시스템의 현존하는 지식에서 제1 오브젝트에 대한 피처와 추출된 피처 사이의 차이가 임계치보다 더 작은 경우, 시스템은 그 피처를 잠재적인 제1 오브젝트 로서 분류한다. 실제 거리 또는 거리와 임계치 사이의 차이는, 매치의 품질을 나타내는 신뢰도 값일 수 있거나 또는 그 신뢰도 값을 유도하기 위해 사용될 수 있다. 시스템은 태그 지정 세션 이후에 그러한 지식을 저장할 수 있고, 이 저장된 지식은 새로운 세션의 시작에서 사 용자에 의해 로딩될 수 있다. 이것은, 현재 태그 지정되는 이미지의 세트가, 사용자와 시스템이 이전에 태그 지 정한 동일한 도메인으로부터 유래하는 경우 특히 도움이 될 수 있다. 사전 로딩된 지식이 없으면, 시스템은 사 용자에게 프레임을 디스플레이하고 사용자 입력을 대기한다. 시스템에서 어떠한 사전 지식도 없는 제 1 프레임의 경우, 사용자는 사용자 인터페이스를 통해 제1 이미지 내의 오브젝트(들)의 하나 이상의 인스 턴스에 수동으로 태그 지정한다. 사용자가 이미지 내의 제1 오브젝트의 제1 인스턴스에 태그 지정하는 경우, 시 스템은 태그 지정된 오브젝트 피처 및 관련 라벨을 학습한다. 이 단계에서 수반되는 고속 학습 분류기의 세부 사항은, 하기의 대응하는 섹션에서 설명된다. 시스템이 프레임 내의 태그 지정된 오브젝트의 피처를 학습한 이후, 시스템은 프레임을 처리하여, 프레임 내의 동일한 오브젝트의 임의의 다른 인스턴스를 찾을 수 있는지의 여부를 체크한다. 시스템이 이전 세션으로부 터의 사전 로딩된 지식을 가지면, 시스템은, 동일한 프로세스를 통해 제1 프레임이 사용자에게 디스플레이되기 이전에, 알려진 오브젝트를 찾으려고 시도할 수 있다는 것을 유의한다. 시스템이 이미지에서 발견한 오브 젝트의 인스턴스에 대해, 시스템은 부착된 라벨을 갖는 경계 다각형을 생성하고, 이미지 상에 경계 다각형 을 중첩시키고, 중첩된 경계 다각형 및 태그를 갖는 이미지를 사용자에게 디스플레이한다. 몇몇 경우 에, 사용자가 시스템이 생성한 태그에 만족하지 않는 경우, 사용자는 사용자 인터페이스를 통해 태그를 조정할 수 있다. 분류기는 조정된 태그를 학습하고 자신의 지식을 업데이트한다. 그 다음, 내부 루프는, 사용자가 새로운 오브젝트를 추가하는 것 및 사용자가 이 프레임에 대한 태그 지정에 만족할 때가지 시스템 예측을 수정 하는 것을 계속한다. 사용자가 만족하면, 시스템은, 태그 지정할 더 이상의 프레임이 존재하는지를 체크하고 , 만약 존재한다면, 시스템은 다음 프레임을 로딩하고, 피처 추출을 실행하고, 내부 루프 에 재진입한다. 이 경우, 시스템은, 적어도, 하나의 이전 프레임으로부터의 사전 지식을 가지며, 따라서, 내부 루프는 워크플로의 하부 분기를 통해 진입되고 시스템은 프레임을 사용자에게 디스플레이하기 이전에 예측을 행한다(150, 155, 160)는 것을 유의한다. 전체 프로세스는, 이미지가 태그 지정될 때까지 또는 사용자가 워크플로를 종료할 때까지 계속된다. 종료하기 이전에, 시스템은 이 세션에서 사용자로부터 획득되는 지식을 저장할 수 있고, 따라서, 그것은 이어지는 세션동안 재사용될 수 있다. 사용자 관점에서의 동작 절차 도 2A 내지 도 2D는 사용자 관점에서 도 1b의 동작 워크플로를 도시한다. 시스템은, 도 2A에 도시된 바와 같이, 시스템 동작의 제어를 위해 그리고 이미지에 태그 지정하기 위해, 사용자에게 여러 가지 입력 양식, 예를 들면, 마우스 또는 터치스크린을 제공할 수 있다. 태그 지정할 일련의 프레임은, 시스템이 설치되는 로컬 컴퓨터 상의 이미지로 채워진 디렉토리, 이미지로 채워진 원격 디렉토리, 이미지에 대한 로컬 또는 원격 파일명 을 포함하는 평문 또는 마크업 문서, 또는 하나 이상의 비디오 파일 중 어느 하나로서 사용자에 의해 로딩된다. 후자의 경우, 비디오는 시스템에 의해 일련의 키 프레임으로 분할된다. 어느 경우든, 처리할 일련의 프레임 이 정의되고 제1 프레임이 시스템에 로딩되면 시스템은 동작 준비가 완료되고, 그 결과, 사용자가 화면 상 에서 이미지를 보게 된다. 사용자가 그렇게 소망하는 경우, 사용자는 태그 지정 프로세스를 더욱더 가속시키고 태스크의 수작업 부분을 감소시키기 위해, 본 명세서에서 설명되는 시스템의 트레이닝된 버전을 로딩할 수 있다. 도 2B에서, 사용자는, 예를 들면, 직사각형 경계 박스를 갖는 프레임 1에서 나무를 선택한다. 대안적으로, 후보 영역을 선택하는 다른 방법도 가능하다, 예를 들면, 사용자는 도 3 내지 도 5에 도시된 바와 같이 다각형 을 묘화할 수 있다. 시스템은, 경계 다각형 내에서 피처의 조합을 학습하고, 피처의 그 조합을 사용자에 의해 제공되는 라벨(예를 들면, \"나무\")과 관련시킨다. 학습 프로세스는, 예시적인 구현에서 100㎳ 이내에 완료되는 고속 학습 절차이다. 프로세스가 너무 빠르기 때문에, 시스템은, 프레임 내의 동일한 오브젝트의 아직 태그 지 정되지 않은 다른 인스턴스에 관한 제안을 사용자에게 제공할 수 있다. 이들 제안은 또한, 이 예시적인 구현예 에서 계산하는 데 100㎳ 미만이 걸리고, 따라서, 사용자에게 끊김 없이, 사용자가 하나의 오브젝트에 대한 태그 지정을 완료한 직후, 시스템은 이미지 내의 동일한 오브젝트의 다른 인스턴스에 대한 태그 지정을 제안한다 . 초기에, 특히 이전에 트레이닝된 시스템이 사전 로딩되지 않은 경우, 시스템에 의해 이루어지는 제안은 사 용자 관점에서 완벽과는 거리가 멀 수도 있다. 그 다음, 사용자는 완전히 부정확한 예측을 거부할 수 있고, 올 바른 경계 다각형에 대한 부정확한 라벨을 조정할 수 있고, 도 2C에 도시된 바와 같이 올바른 라벨에 대한 분류 기에 의해 제안되는 경계 다각형을 조정할 수 있고, 그리고/또는 올바른 제안을 수용할 수 있다. 프로세스를 단 순화하기 위해, 도 2C 및 도 2D에 도시된 바와 같이, 분류기(240, 260)에 의해 제안되는 경계 다각형은 점선으 로 디스플레이될 수 있고, 사용자의 원래 태그 지정(230, 270) 및 수용된 정정은 파선 또는 실선으로 디스 플레이될 수 있다. 수용된 정정은, 특정한 클래스의 오브젝트를 추가로 개선 및 재트레이닝하여 태그 지정을 위 한 추가 제안을 향상시키기 위해 시스템에 의해 사용될 수 있는 다른 입력을 구성한다. 그 다음, 프로세스는, 도 2D에 도시된 바와 같이, 후속 프레임에 대해 계속되는데, 여기서는, 새로운 오브젝트 가 사용자에 의해 태그 지정될 수 있고, 이전에 태그 지정된 오브젝트는, 그들의 관련된 클래스 및 시스템이 이미지 상에 마크하는 오브젝트에 대한 자신의 제안에 시스템이 얼마나 신뢰하는지를 나타내는 신뢰도 값과 함께 시각화될 수 있다. 시스템이 점점 더 많이 트레이닝 받음에 따라, 사용자 상호 작용은 주로 제안을 정정하는 것으로부터 시스템에 의해 이루어지는 제안을 수용하는 것으로 이동하는데, 이것은 이미지에 수동으로 태그 지정하는 것보다 상당히 덜 노동 집약적이고 훨씬 더 빠르다. 경험이 없는 태거의 경우 테스트 데이터세트 에 대한 전체 태그 지정 속도에서 최대 40% 증가를 그리고 전문 태거(professional tagger)의 경우 덜 극적이지 만 그러나 상당한 증가를 관찰하였다. 도 3 내지 도 5는, 예시적인 스마트 태그 지정 시스템의 그래픽 사용자 인터페이스로부터의 스크린샷을 제공한 다. 사용자는 수동 태그 지정 툴(manual tagging tool)을 활성화시키고, 현존하는 라벨의 목록으로부터 라 벨을 선택하거나 또는 새로운 라벨을 생성하고, 제1 자전거 주위에 다각형을 묘화한다. 이 예에서 다각형 컬러는 선택된 라벨을 나타낸다. 이 다각형이 수동으로 생성되었기 때문에, 그것은 자동적으로 승인 상태 가 된다. 이들 액션의 결과는 도 3에서 도시되어 있다. 그 다음, 스마트 태그 지정 시스템의 고속 분류기는 다 각형 내의 피처를 학습하고 그들을 제1 자전거 운전자에 대한 사용자 라벨과 관련시킨다. 그 다음, 시스템 은 프레임에 걸쳐 피처를 보고 이미지에서 다른 자전거 운전자를 찾고, 그 주위에 다각형을 생성하려고 시 도하고, 도 4에 도시된 바와 같이, 다른 자전거 운전자 상에 중첩된 다각형을 사용자에게 제시한다. 다각형이 시스템에 의해 생성되기 때문에, 그것은 제안의 신뢰도 값과 함께 '제안됨'으로 마킹된다는 것을 유의한다. 마지막으로, 도 5는, 사용자가 수동 정정 툴을 재활성화하였고, 이제 승인된 라벨을 얻은 제2 자전거 운전자에 대한 다각형을 업데이트한 것을 도시한다. 사용자는 이제, 필요한 경우, 프레임 내의다른 오브젝트에 태그 지정할 수 있거나, 화살표 버튼을 사용하여 다음 프레임으로 진행할 수 있거나, 또 는 '태그 지정 종료(Finished Tagging)' 버튼을 누르는 것에 의해 세션을 종료할 수 있다. 스마트 태그 지정 시스템 도 6은 스마트 태그 지정 시스템 - 본 명세서에서 설명되는 스마트 태그 지정 유틸리티를 구현하기 위한 하드웨 어 구성 - 을 묘사한다. 감각 정보(sensory information)(예를 들면, RGB, 적외선(infrared: IR) 및/또는 LIDAR 이미지)는, 로봇, 드론, 자율 주행 차량, 장난감 로봇, 산업용 로봇, 및/또는 다른 디바이스로부터 유도된다.<< 대안적인 실시형태는, 분리된 또는 네트워크화된 센서(예를 들면, 카메라, LIDAR)로부터 데이 터를 유도할 수도 있다. 또한, 데이터는 현존하는 데이터베이스에서 편제될(organized) 수도 있다. 데이터 는, 데이터(이미지)를 시각화하기 위해, 이미지에 태그 지정하기 위해, 태그 지정된 이미지를 시각화하기 위해, 필요한 경우 태그를 조정하기 위해 사용자가 사용할 수 있는 사용자 인터페이스가 장착된 컴퓨팅 디 바이스로 송신된다. 컴퓨팅 디바이스는, 하나 이상의 프로세서 또는 처리 유닛, 예컨대, 디지털 신호 처리 유닛, 필드 프로그래머블 게이트 어레이(field programmable gate array: FPGA), 중앙 처리 유닛(central processing unit: CPU), 그래픽 처리 유닛(graphic processing unit: GPU), 및/또는 도 1b의 워크플로를 구현 하기에 충분한 이들 프로세서의 조합을 구비한, 모바일 디바이스(예를 들면, 스마트폰, 태블릿, 랩탑), 데스크 탑, 또는 서버일 수 있다. 이들 처리 유닛은, 태그를 학습하고 자동적으로 적용하고 조정하는 피처 추출기 및 분류기를 구현하기 위해 사용될 수도 있다. 여러 가지 소프트웨어 모듈을 포함하는 아키텍처는 메모리 에 저장될 수 있고 실행을 위해 처리 유닛(들)으로 로딩될 수 있다. 태그 지정된 이미지는 사용자에 게 디스플레이하기 위해 UI에서 시각화될 수도 있고 별개의 데이터베이스에 저장될 수도 있다. 피처 추출 모듈 피처 추출 모듈(도 1의 , 도 6의 )은 본 명세서에서 설명되는 자동화된 스마트 태그 지정 시스템의 두 가지 핵심 컴포넌트 중 하나이다. 그것은 자신의 디스플레이된 형식으로 시스템에 대한 입력을 수신한다. 시 스템의 그래픽 사용자 인터페이스에서의 시각화 및 태그 지정의 편의의 목적을 위해, 원시(raw) 외부 입력의 2D 표현이 선호되지만, 그러나 그것은 입력 양식을 단지 시각적 이미지로만 제한하는 것은 아니다. 고속 푸리에 변 환 이후 사운드가 2D로 표현될 수 있고, 다른 입력 양식이 다른 수단에 의해 2D 표현으로 변환될 수 있다. 텍스 트 입력은 텍스트로서 디스플레이되고 시스템에 공급될 수 있다. 가상 및 증강 현실 시스템과 같은 3D 디스플레 이에서의 발전은, 시스템이 3D 데이터를 수용하고 태그 지정하는 것을 허용할 수도 있다. 피처 추출 모듈의 출력은 피처 벡터의 세트이다. 태그 지정의 본질에 따라, 피처 벡터의 세트는 이미지당 하나 의 피처 벡터(예를 들면, 장면 인식을 위해, 전체 이미지가 한 번에 태그 지정되는 간단한 경우) 또는 이들 피 처가 발견되는 이미지의 관련된 영역을 갖는 다수의 피처 벡터 중 어느 하나일 수 있다. 이들 영역은, 태그 지 정 프로세스의 최종 목표에 따라, 직사각형 경계 상자만큼 간단할 수 있거나, 더욱 복잡한 형상의 다각형일 수 있거나, 또는 심지어 픽셀 단위의 마스크일 수 있다. 본 명세서에서 설명되는 예시적인 구현예는 피처 추출을 위해 딥 컨볼루션 신경망(Deep Convolutional Neural Network)을 사용한다. 컨볼루션 신경망(CNN)은 컨볼루션 유닛을 사용하는데, 유닛의 필터(가중 벡터)의 수용 필 드(receptive field)는 입력의 높이 및 폭 치수에 걸쳐 단계적으로 시프트된다. 각각의 필터가 작기 때문에, 완 전히 연결되는 계층과 비교하여, 파라미터의 수가 크게 감소된다. 입력의 상이한 공간 위치에서의 각각의 필터 의 적용은, 다음과 같은 의미에서 병진 불변성의 매력적인 속성을 제공한다: 오브젝트가 하나의 공간 위치에 있 을 때 오브젝트에 대해 피처의 세트가 추출될 수 있는 경우, 동일한 오브젝트가 임의의 다른 공간 위치에서 나 타나는 경우 피처의 동일한 세트가 동일한 오브젝트에 대해 추출될 수 있는데, 그 이유는, 오브젝트를 포함하는 피처가 오브젝트의 공간 위치와 무관하기 때문이다. 이들 불변성은, 입력의 인코딩이 시각적 변동에 대해 향상 된 안정성을 갖는 피처 공간을 제공하는데, 입력이 변함에 따라(예를 들면, 오브젝트가 이미지 프레임에서 약간 병진하거나 또는 회전함), 출력 값은 입력 값보다 훨씬 더 적게 변한다는 것을 의미한다. 컨볼루션 신경망도 또한 일반화에 능숙하다. 일반화는, 네트워크가 트레이닝된 양식 내에서 트레이닝된 데이터 와 동일하지 않은 테스트 데이터에 대해 유사한 출력을 생성할 수 있다는 것을 의미한다. 피처의 클래스별 세트 (class-specific set)를 정의하는 주요 규칙을 학습하는 데에는 많은 양의 데이터를 필요로 한다. 네트워크가 많은 클래스에 대해 트레이닝되는 경우, 그 필터가 클래스 사이에서 공유되는 하위 계층은, 동일한 양식의 입력 에 대해 양호한 규칙 세트를 제공한다. 따라서, 하나의 태스크에 대해 트레이닝되는 CNN은, 다른 태스크의 초기 화로 사용되는 경우 또는 하위 계층이 새로운 상위 레벨 표현을 위한 사전프로세서(preprocessor)로서 사용되는 경우, 우수한 결과를 제공할 수 있다. 예를 들면, 자연적인 이미지는 통계 속성의 공통 세트를 공유한다. 하위계층에서의 학습된 피처는 완전히 클래스 독립적이며, 따라서, 사용자가 막 태그 지정하려고 하는 클래스가, CNN이 사전 트레이닝을 받은 클래스 사이에 있지 않더라도, 그들은 재사용될 수 있다. 이들 피처 벡터를 취하고 그들을 시스템의 고속 학습 분류기 부분(도 1b에서 150)에 대한 입력으로 공급하는 것으로 충분하다. 태그 지정 프로세스의 타겟 최종 결과에 따라, 상이한 CNN이 피처 추출기로서 역할을 할 수 있다. 전체 장면 인 식을 위해, 이용 가능한 하드웨어의 계산 능력에 따라 Alexnet, GoogLeNet, 또는 ResNet의 수정된 버전이 사용 될 수 있다. 이미지 내의 위치에 걸쳐 풀링하고 전체 장면 피처 벡터를 생성하기 위해서는, 이들 네트워크에서 의 최종 피처 계층(last feature layer) 이후에 평균 풀링 계층(average pooling layer)이 추가되어야 한다. 검출 네트워크를 트레이닝시키기 위한 데이터 세트를 생성하기 위해 시스템이 사용되면, 동일한 네트워크는 평 균 풀링 없이 사용될 수 있거나, 또는, 더 나은 공간 정밀도를 위해 fRCNN과 같은 영역 제안 네트워크가 대신 사용될 수 있다. 이미지 세그먼트화가 타겟인 경우, 마스크 RCNN, FCN, 또는 U-Net과 같은 세그먼트화 네트워크 가 피처 추출 및 마스크 생성을 위해 사용될 수 있다. 이들 마스크는, 디스플레이 및 정정을 위해 다각형으로 변환될 수 있다. 도 3 내지 도 5에 도시된 예시적인 구현예에서, FCN의 커스텀 버전이 사용되었다. 피처 추출 모듈의 대안적인 구현예는, 다음의 것을 포함하는, 그러나 그들로 제한되지는 않는, 피처 추출을 위 한 임의의 적절한 기술을 사용할 수 있다: 스케일 불변 피처 변환(scale invariant feature transform: SIFT), 가속된 강건한 피처(speeded up robust features: SURF), Haar-like(할라이크) 피처 검출기, 차원 축소, 성분 분석, 및 시스템이 태그 지정할 필요가 있는 상이한 오브젝트에 대해 충분히 별개인 피처 벡터를 생성하고 시스 템이 피처 세트를 계산하는 동안 사용자가 눈에 띄는 시간의 양 동안 기다리지 않을 만큼 충분히 빠르게 동작할 수 있는 다른 것. 고속 학습 분류기 모듈 고속 학습 분류기 모듈(도 1b의 , 도 6의 )은, 피처 추출 모듈(도 1b의 )에 의해 생성되는 피처 벡터를 취하고, 분류 또는 피처 매칭을 수행하고, 피처의 각각의 주어진 세트에 대한 클래스 라벨을 출력한다. 하나의 예시적인 구현예는 간단한 템플릿 매칭일 수 있다: 시스템은 모든 알려진 오브젝트에 대한 사용자 입력 에 기초하여 추출되는 템플릿 피처 벡터를 저장한다. 피처 벡터의 입력 세트가 제시되는 경우, 이들 벡터의 각 각은, 현재의 입력과 템플릿 사이의 차이를 측정하는 몇몇 거리 메트릭(예를 들면, 관련 피처 공간에서의 유클 리드 놈)에 기초하여 템플릿 벡터와 비교된다. 그 다음, 분류기는 설정된 임계치보다 더 작은 차이 메트릭을 갖 는 피처 벡터를 잠재적 오브젝트로서 마킹한다. 거리의 역수의 값은, 이 분류 스킴에서 신뢰도 척도로서 역할을 할 수 있다. 고속 학습에 적합한 다른 기술은, 회귀 방법(예를 들면, 선형 회귀, 로지스틱 회귀, 미니맥스(minimax) 분석), 커널 방법(예를 들면, 지원 벡터 머신), 베이지안 모델(Bayesian model), 앙상블 방법(ensemble method)(예를 들면, 전문가의 앙상블), 의사 결정 트리(예를 들면, 점진적 의사 결정 트리, 초고속 의사 결정 트리 및 그 파 생물), 적응식 공명 이론 기반의 모델(Adaptive Resonance Theory based model)(예를 들면, 퍼지(Fuzzy) ARTMAP), 및 선형 변별 온라인 알고리즘(linear discriminative online algorithm)(예를 들면, 온라인 패시브- 어그레시브 알고리즘(online passive-aggressive algorithm))을 비롯한, 이 템플릿 매칭 기술에 대한 분류기에 서 대체될 수도 있다. 예를 들면, 도 3 내지 도 5에 도시되는 구현예는, 고속 학습을 위해 수정된 ARTMAP를 사 용한다. 수정예는, ARTMAP의 순서 종속성을 감소시키고, 통계적 일관성을 향상시키며, 새로운 오브젝트를 학습 함에 따라 시스템 메모리 풋프린트의 증가를 감소시킨다. 결론 다양한 본 발명의 실시형태가 본 명세서에서 설명되고 예시되었지만, 기술 분야에서 통상의 지식을 가진 자는, 기능을 수행하기 위한 및/또는 본 명세서에서 설명되는 이점 중 하나 이상 및/또는 결과를 획득하기 위한 다양 한 다른 수단 및/또는 구조체를 쉽게 구상할 것이고, 그러한 변형예 및/또는 수정예의 각각은 본 명세서에서 설 명되는 본 발명의 실시형태의 범위 내에 있는 것으로 간주된다. 더욱 일반적으로, 기술 분야의 숙련된 자는 본 명세서에서 설명되는 모든 파라미터, 치수, 재료 및 구성이 예시적인 것으로 의도된다는 것 및 실제 파라미터, 치수, 재료, 및/또는 구성이 특정한 애플리케이션 또는 본 발명의 교시가 사용되는 애플리케이션에 의존할 것이다는 것을 쉽게 인식할 것이다. 기술 분야의 숙련된 자는, 단지 일상적인 실험을 사용하여, 본 명세서에서 설명 되는 특정한 본 발명의 실시형태에 대한 많은 등가적 형태(equivalent)를 인식할 것이거나 또는 확인할 수 있을 것이다. 따라서, 전술한 실시형태는 단지 예로서 제시된다는 것 및 첨부된 청구범위 및 그 등가적 범위 내에서, 본 발명의 실시형태는 구체적으로 설명되고 청구되는 것과는 다르게 실시될 수도 있다는 것이 이해되어야 한다. 본 개시내용의 독창적 실시형태는, 본 명세서에서 설명되는 각각 개개의 피처, 시스템, 물품, 재료, 키트, 및/또는 방법에 관한 것이다. 또한, 두 개 이상의 그러한 피처, 시스템, 물품, 재료, 키트, 및/또는 방법의 임의의 조합은, 그러한 피처, 시스템, 물품, 재료, 키트, 및/또는 방법이 상호 일치하지 않는 경우, 본 개시내용의 독 창적 범위 내에 포함된다. 상기에서 설명된 실시형태는 다양한 방식 중 임의의 방식으로 구현될 수 있다. 예를 들면, 본 명세서에 개시된 기술의 실시형태는, 하드웨어, 소프트웨어 또는 이들의 조합을 사용하여 구현될 수도 있다. 소프트웨어로 구현 되는 경우, 소프트웨어 코드는, 단일의 컴퓨터에서 제공되든 또는 다수의 컴퓨터 사이에서 분산되든 간에, 임의 의 적절한 프로세서 또는 프로세서의 콜렉션(collection)에서 실행될 수 있다. 또한, 컴퓨터는, 랙 마운트형 컴퓨터, 데스크탑 컴퓨터, 랩탑 컴퓨터, 또는 태블릿 컴퓨터와 같은 다수의 형태 중 임의의 형태로 구현될 수도 있다는 것이 인식되어야 한다. 추가적으로, 컴퓨터는, 개인 휴대형 정보 단말 (Personal Digital Assistant: PDA), 스마트폰 또는 임의의 다른 적절한 휴대용 또는 고정식 전자 디바이스를 포함하는, 일반적으로 컴퓨터로 간주되지 않지만 그러나 적절한 처리 성능을 갖는 디바이스에 내장될 수도 있다. 또한, 컴퓨터는 하나 이상의 입력 및 출력 디바이스를 구비할 수도 있다. 이들 디바이스는, 다른 것들 중에서도, 사용자 인터페이스를 제시하기 위해 사용될 수 있다. 사용자 인터페이스를 제공하기 위해 사용될 수 있는 출력 디바이스의 예는, 출력의 시각적 표현을 위한 프린터 또는 디스플레이 스크린 및 출력의 가청의 표현 을 위한 스피커 또는 다른 사운드 생성 디바이스를 포함한다. 사용자 인터페이스를 위해 사용될 수 있는 입력 디바이스의 예는, 키보드, 및 포인팅 디바이스, 예컨대 마우스, 터치 패드, 및 디지타이징 태블릿을 포함한다. 다른 예로서, 컴퓨터는 음성 인식을 통해 또는 다른 가청 포맷의 입력 정보를 수신할 수도 있다. 그러한 컴퓨터는, 근거리 통신망 또는 광역 네트워크, 예컨대 기업 네트워크, 및 지능형 네트워크(intelligent network: IN) 또는 인터넷을 비롯한, 임의의 적절한 형태의 하나 이상의 네트워크에 의해 인터커넥트될 수도 있 다. 그러한 네트워크는 임의의 적절한 기술에 기초할 수도 있고 임의의 적절한 프로토콜에 따라 동작할 수도 있 으며 무선 네트워크, 유선 네트워크 또는 광섬유 네트워크를 포함할 수도 있다. 본 명세서에서 개설되는 다양한 방법 또는 프로세스는, 다양한 오퍼레이팅 시스템 또는 플랫폼 중 임의의 하나 를 활용하는 하나 이상의 프로세서상에서 실행 가능한 소프트웨어로서 코딩될 수도 있다. 추가적으로, 그러한 소프트웨어는 다수의 적절한 프로그래밍 언어 및/또는 프로그래밍 또는 스크립팅 툴 중 임의의 것을 사용하여 작성될 수도 있고, 또한, 프레임워크 또는 가상 머신 상에서 실행되는 실행 가능한 기계어 코드 또는 중간 코드 로서 컴파일될 수도 있다. 이와 관련하여, 다양한 본 발명의 개념은, 하나 이상의 컴퓨터 또는 다른 프로세서상에서 실행될 때, 상기에서 논의되는 본 발명의 다양한 실시형태를 구현하는 방법을 수행하는 하나 이상의 프로그램으로 인코딩되는 컴퓨터 판독 가능 저장 매체(또는 다수의 컴퓨터 판독 가능 저장 매체)(예를 들면, 컴퓨터 메모리, 하나 이상의 플로피 디스크, 컴팩트 디스크, 광학 디스크, 자기 테이프, 플래시 메모리, 필드 프로그래머블 게이트 어레이 또는 다 른 반도체 디바이스에서의 회로 구성, 또는 다른 비일시적 매체 또는 유형의 컴퓨터 저장 매체)로서 구현될 수 도 있다. 컴퓨터 판독 가능 매체 또는 매체들은 운반 가능할 수 있고, 그 결과, 그 상에 저장되는 프로그램 또 는 프로그램들은 하나 이상의 상이한 컴퓨터 또는 다른 프로세서상으로 로딩되어 상기에서 논의되는 바와 같은 본 발명의 다양한 양태를 구현할 수 있다. 용어 \"프로그램\" 또는 \"소프트웨어\"는, 본 명세서에서, 상기에서 논의되는 바와 같은 실시형태의 다양한 양태를 구현하도록 컴퓨터 또는 다른 프로세서를 프로그래밍하기 위해 활용될 수 있는 임의의 타입의 컴퓨터 코드 또는 컴퓨터 실행 가능 명령어의 세트를 가리키는 일반적인 의미에서 사용된다. 추가적으로, 하나의 양태에 따르면, 실행 시 본 발명의 방법을 수행하는 하나 이상의 컴퓨터 프로그램은, 단일의 컴퓨터 또는 프로세서에 상주할 필 요가 있는 것이 아니라, 본 발명의 다양한 양태를 구현하기 위해 다수의 상이한 컴퓨터 또는 프로세서 사이에서 모듈 양식으로 분산될 수도 있다는 것이 인식되어야 한다. 컴퓨터 실행 가능 명령어는 하나 이상의 컴퓨터 또는 다른 디바이스에 의해 실행되는 프로그램 모듈과 같은 많 은 형태일 수도 있다. 일반적으로, 프로그램 모듈은 특정한 태스크를 수행하는 또는 특정한 추상 데이터 타입을 구현하는 루틴, 프로그램, 오브젝트, 컴포넌트, 데이터 구조 등을 포함한다. 통상적으로, 프로그램 모듈의 기능 성은, 다양한 실시형태에서 소망에 따라 조합될 수도 있거나 또는 분산될 수도 있다. 또한, 데이터 구조는 임의의 적절한 형태로 컴퓨터 판독 가능 매체에 저장될 수도 있다. 예시의 간략화를 위해, 데이터 구조는 데이터 구조에서의 위치를 통해 관련되는 필드를 갖는 것으로 도시될 수도 있다. 그러한 관계는,필드 사이의 관계를 전달하는 컴퓨터 판독 가능 매체 내의 위치를 갖는 필드에 대해 스토리지를 할당하는 것에 의해, 마찬가지로 달성될 수도 있다. 그러나, 데이터 구조의 필드 내의 정보 사이의 관계를 확립하기 위해, 포 인터, 태그 또는 데이터 요소 사이의 관계를 확립하는 다른 메커니즘의 사용을 통하는 것을 비롯하여, 임의의 적절한 메커니즘이 사용될 수도 있다. 또한, 다양한 본 발명의 개념은 하나 이상의 방법으로서 구현될 수도 있는데, 그 중 한 예가 제공되었다. 방법 의 일부로서 수행되는 액트(act)는, 임의의 적절한 방식으로 순서가 정해질 수도 있다. 따라서, 비록 예시적인 실시형태에서 순차적인 액트로서 도시되지만, 예시되는 것과는 상이한 순서로 액트가 수행되는 실시형태가 구성 될 수도 있는데, 그 상이한 순서는, 몇몇 액트를 동시에 수행하는 것을 포함할 수도 있다. 본 명세서에 정의되고 사용되는 바와 같이, 모든 정의는, 사전적 정의, 참조에 의해 통합되는 문서에서의 정의, 및/또는 정의된 용어의 일반적인 의미를 지배하는 것으로 이해되어야 한다. 단수 표현은, 본 명세서의 본 명세서 및 청구의 범위에서 사용될 때, 달리 명백하게 지시되지 않는 한, \"적어도 하나\"를 의미하는 것으로 이해되어야 한다. 어구 \"및/또는\"은, 본 명세서의 본 명세서 및 청구의 범위에서 사용될 때, 그렇게 결합되는 요소, 즉 몇몇 경우 에 접속적으로(conjunctively) 존재하고 다른 경우에 이접적으로(disjunctively) 존재하는 요소의 \"어느 하나 또는 둘 모두\"를 의미하는 것으로 이해되어야 한다. \"및/또는\"과 함께 열거되는 다수의 요소도 동일한 방식으로, 즉, 그렇게 결합되는 요소 중 \"하나 이상\"으로 해석되어야 한다. \"및/또는\" 절에 의해 구체적으로 식 별되는 요소 외에, 구체적으로 식별되는 그들 요소에 관련되든 또는 관련되지 않든 간에, 다른 요소가 옵션 사 항으로 존재할 수도 있다. 따라서, 비제한적인 예로서, \"A 및/또는 B\"에 대한 언급은, \"포함하는(comprising)\" 과 같은 확장 가능한(open-ended) 언어와 연계하여 사용될 때, 하나의 실시형태에서, A만(옵션 사항으로 B 이외 의 요소를 포함함)을; 다른 실시형태에서, B만(옵션 사항으로 A 이외의 요소를 포함함)을; 여전히 다른 실시형 태에서, A 및 B(옵션 사항으로 다른 요소를 포함함) 둘 모두를; 등등을 가리킬 수 있다. 본 명세서의 본 명세서 및 청구의 범위에서 사용될 때, \"또는\"은 상기에서 정의되는 \" 및/또는\"과 동일한 의미 를 갖는 것으로 이해되어야 한다. 예를 들면, 목록에서 항목을 분리할 때, \"또는\" 또는 \"및/또는\"은 포괄적인 것으로, 즉, 다수의 요소 또는 요소의 목록 중 적어도 하나뿐만 아니라, 또한 그들의 하나 이상, 및 옵션 사항 으로, 추가적인 열거되지 않은 항목의 포함으로서 해석되어야 한다. \"중 단지 하나(only one of)\" 또는 \"중 정 확히 하나(exactly one of)\", 또는, 청구범위에서 사용될 때, \"구성되는(consisting of)\"과 같은, 명확하게 반 대로 표시되는 용어만이, 다수의 요소 또는 요소의 목록 중 정확히 하나의 요소의 포함을 가리킬 것이다. 일반 적으로, 용어 \"또는\"은, 본 명세서에서 사용될 때, \"어느 하나\", \"중 하나\", \"중 단지 하나\", 또는 \"중 정확히 하나\"와 같은, 배타성의 용어를 앞세울 때, 배타적 양자택일(즉, \"하나 또는 다른 것 그러나 둘 모두는 아님\") 을 나타내는 것으로만 해석되어야 한다. \"로 본질적으로 구성되는(consisting essentially of)\"은, 청구범위에 서 사용될 때, 특허법의 분야에서 사용되는 바와 같은 자신의 일반적인 의미를 가져야 한다. 본 명세서에서 사용될 때, 용어 \"약\" 및 \"대략\"은 일반적으로 언급되는 값의 플러스 또는 마이너스 10%를 의미 한다. 본 명세서의 본 명세서 및 청구의 범위에서 사용될 때, 어구 \"적어도 하나\"는, 하나 이상의 요소의 목록과 관련 하여, 요소의 그 목록 내의 요소 중 임의의 하나 이상으로부터 선택되는 적어도 하나의 요소를 의미하는 것으로 이해되어야 하고, 요소의 그 목록 내에서 명시적으로 열거되는 각각의 및 모든 요소 중 적어도 하나를 반드시 포함하지는 않으며 요소의 목록 내의 요소의 임의의 조합을 배제하지도 않는다. 이 정의는 또한, 어구 \"적어도 하나\"가 참조하는 요소의 목록 내에서 명시적으로 식별되는 요소 이외의 요소가, 명시적으로 식별되는 그들 요 소에 관련되든 또는 관련되지 않든 간에, 옵션 사항으로 존재할 수도 있다는 것을 허용한다. 따라서, 비제한적 인 예로서, \"A 및 B 중 적어도 하나\"(또는, 등가적으로, \"A 또는 B 중 적어도 하나\", 또는, 등가적으로 \"A 및/ 또는 B 중 적어도 하나\")는, 하나의 실시형태에서, B는 없이(그리고 옵션 사항으로 B 이외의 요소를 포함함), 옵션 사항으로 하나보다 더 많은 것을 포함하는, 적어도 하나의 A를; 다른 실시형태에서, A는 없이(그리고 옵션 사항으로 A 이외의 요소를 포함함), 옵션 사항으로 하나보다 더 많은 것을 포함하는, 적어도 하나의 B를; 여전 히 다른 실시형태에서, 옵션 사항으로 하나보다 더 많은 것을 포함하는, 적어도 하나의 A, 및 옵션 사항으로 하 나보다 더 많은 것을 포함하는, 적어도 하나의 B(및 옵션 사항으로 다른 요소를 포함함)를; 등등을 가리킬 수 있다. 청구범위뿐만 아니라, 상기의 명세서에서, \"포함하는(comprising)\", \"포함하는(including)\", \"지니는 (carrying)\", \"갖는(having)\", \"함유하는(containing)\", \"수반하는(involving)\", \"유지하는(holding)\", \"로 구 성되는(composed of)\" 등과 같은 모든 이행 어구(transitional phrase)는, 확장 가능한 것으로, 즉, 포함하지 만 그러나 제한되지는 않는 것을 의미하는 것으로 이해되어야 한다. 오로지 이행 어구 \"구성되는(consisting of)\" 및 \"로 본질적으로 구성되는(consisting essentially of)\"만이, 미국 특허청 특허 심사 절차 매뉴얼 섹션 2111.03에 기술되는 바와 같이, 각각, 폐쇄형 또는 반폐쇄형 이행 어구일 수 있을 것이다."}
{"patent_id": "10-2019-7030696", "section": "도면", "subsection": "도면설명", "item": 1, "content": "숙련된 기술자는, 도면이 주로 예시적인 목적을 위한 것이며 본 명세서에서 설명되는 본 발명의 주제의 범위를 제한하도록 의도되지 않는다는 것을 이해할 것이다. 도면은 반드시 일정한 비율은 아니며; 몇몇 경우에, 본 명 세서에 개시된 본 발명의 주제의 다양한 양태는, 상이한 피처의 이해를 용이하게 하기 위해, 도면에서 과장되거 나 또는 확대되어 도시될 수도 있다. 도면에서, 유사한 참조 문자는 일반적으로 유사한 피처(예를 들면, 기능적 으로 유사한 및/또는 구조적으로 유사한 요소)를 가리킨다. 도 1a는, 프로세서 구현 컨볼루션 신경망(processor-implemented convolutional neural network) 및 고속 학습 분류기를 사용하여, 데이터 스트림에 태그 지정 및 라벨링하기 위한 온라인의 점진적 실시간 학습(online,incremental real-time learning)을 위한 프로세스를 도시한다. 도 1b는, 본 발명의 스마트 태그 지정 시스템을 사용하여 하나 이상의 이미지(예를 들면, 비디오 내의 프레임 또는 데이터베이스 내의 이미지) 내의 오브젝트에 태그 지정하기 위한 동작 워크플로를 도시한다. 도 2A 내지 도 2D는, 본 발명의 스마트 태그 지정 시스템의 동작 워크플로를 사용자 관점에서 예시한다. 도 3은, 사용자가 제1 오브젝트의 제1 인스턴스에 태그 지정한 이후의 예시적인 구현예의 스크린샷을 도시한다. 도 4는, 시스템이 이전 단계로부터 학습하고 제1 오브젝트의 제2 인스턴스에 태그 지정하기 위해 사용자에게 제 안을 한 이후의 예시적인 구현예의 스크린샷을 도시한다. 도 5는, 사용자가 시스템에 의해 이루어지는 제안을 수정한 이후의 예시적인 구현예의 스크린샷을 도시한다. 도 6은, 비디오 또는 다른 이미지 데이터의 동일한 프레임 또는 상이한 프레임 내에서 사용자가 선택한 오브젝 트와 유사한 오브젝트에 자동적으로 태그 지정할 수 있는 스마트 태그 지정 유틸리티(smart tagging utility)에 대한 구현예의 개략적인 개요이다."}
