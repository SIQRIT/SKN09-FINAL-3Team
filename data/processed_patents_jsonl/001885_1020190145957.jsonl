{"patent_id": "10-2019-0145957", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0058469", "출원번호": "10-2019-0145957", "발명의 명칭": "질의문 단순화를 통한 영상 검색 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "함경준"}}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 검색을 위한 단순화 문장 생성 장치에 있어서,학습 데이터가 저장된 학습 데이터 베이스;상기 학습 데이터로 학습을 수행하여 생성된 모델을 통해 사용자 입력 질의문으로부터 단순화 문장을 생성하는단순화 문장 생성부; 를 포함하되;상기 학습 데이터베이스는 제 1 메타데이터 및 제 2 메타데이터를 상기 학습 데이터로 구축하고,상기 제 1 메타데이터는 단순 질의문으로 구성되고 상기 제 2 메타데이터는 복합 질의문으로 구성되는 것을 특징으로 하는 단순화 문장 생성 장치."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 단순화 문장 생성부는 학습을 위해 상기 제 1 메타데이터와 상기 제 2 메타데이터를 벡터 형태로 표현하는임베딩을 수행하는 단순화 문장 생성 장치."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서, 상기 단순화 문장 생성부는상기 학습 데이터로 학습을 수행하여 생성된,상기 제 2 메타데이터로부터 단순화된 질의문을 생성하는, 단순화된 질의문 생성 모델; 을 포함하는 것을 특징으로 하는 단순화 문장 생성 장치."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서, 상기 단순화 문장 생성부는상기 학습 데이터로 학습을 수행하여 생성된,상기 생성된 단순화된 질의문과 상기 제 1 메타데이터를 비교하고 판별하는, 판별 모델; 을 포함하는 것을 특징으로 하는 단순화 문장 생성 장치."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서, 상기 단순화된 질의문 생성 모델과 상기 판별 모델은 GAN(Generative Adversarial Network)기반인 것을 포함하는 단순화 문장 생성 장치.공개특허 10-2021-0058469-3-청구항 6 제 5항에 있어서, 학습 효과를 높이기 위해 어텐션 메커니즘을 적용하여상기 단순화된 질의문 생성 모델과 상기 판별 모델이 attention GAN 기반인 것을 포함하는 단순화 문장 생성 장치."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 5항에 있어서, 상기 단순화된 질의문 생성 모델의 학습을 수행할 때,손실함수 값을 계산하되,상기 손실함수 값의 계산 시 문장 어휘력, 문장 복잡도 및 벡터 유사도 중 적어도 어느 하나를 고려하는 것을특징으로 하는 단순화 문장 생성 장치"}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서,상기 단순화된 질의문 생성 모델은 상기 손실함수 값과 상기 판별 모델의 판별 결과를 피드백 받고,상기 판별 모델은 판별의 정답 값을 피드백 받는 것을 특징으로 하는 단순화 문장 생성 장치."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "사용자 입력 질의문으로부터 단순화 문장을 생성하는 단순화 문장 생성 장치;단순화 문장 생성 장치로부터 생성된 단순화 문장과 영상들의 메타데이터를 비교하여 관련도를 계산하는 관련도계산 장치;상기 관련도가 높은 영상들을 검색 결과로 제공하는 검색결과 제공 부;를 포함하는 영상 검색 장치."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,각 영상의 구간별로 메타데이터를 생성하는 영상 캡셔닝 부; 를 더 포함하되,상기 영상 캡셔닝 부는,상기 메타데이터를 인공 지능 기술을 이용하여 자동으로 생성하는 것을 특징으로 하는 영상 검색 장치."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "영상 검색을 위한 단순화 문장 생성 단계;공개특허 10-2021-0058469-4-상기 단순화 문장 생성 단계를 통해 생성된 단순화 문장과 영상들의 메타데이터를 비교하여 관련도를 계산하는단계;상기 관련도가 높은 영상들을 검색 결과로 제공하는 단계;를 포함하는 영상 검색 방법."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 단순화 문장 생성 단계는,단순화 문장을 생성하기 위해 학습 데이터가 구축된 학습 데이터 베이스를 구성하는 단계;상기 학습 데이터를 이용하여 학습을 수행하여 사용자 입력 질의문으로부터 단순화 문장을 생성하는 단계;를 포함하는 영상 검색 방법."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 있어서,상기 학습 데이터 베이스를 구성하는 단계에서 제 1 메타데이터 및 제 2 메타데이터를 상기 학습 데이터로 구축하되,상기 제 1 메타데이터는 단순 질의문으로 구성되고 상기 제 2 메타데이터는 복합 질의문으로 구성되는 것을 특징으로 하는 영상 검색 방법."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서,상기 단순화 문장 생성 단계는 학습을 위해 상기 제 1 메타데이터와 상기 제 2 메타데이터를 벡터 형태로 표현하는 임베딩 과정을 포함하는 것을 특징으로 하는 영상 검색 방법."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14항에 있어서,상기 단순화 문장 생성 단계는,상기 학습데이터를 이용하여 학습을 수행하는, 상기 제 2 메타데이터로부터 단순화된 질의문을 생성하는 단계;및상기 학습데이터를 이용하여 학습을 수행하는, 상기 생성된 단순화된 질의문과 상기 제 1 메타데이터를 비교하여 판별하는 단계; 를 포함하는 영상 검색 방법."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15항에 있어서, 공개특허 10-2021-0058469-5-상기 단순화된 질의문을 생성하는 단계와 상기 판별하는 단계는 GAN 기반인 것을 포함하는 영상 검색 방법."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16항에 있어서, 학습 효과를 높이기 위해 어텐션 메커니즘을 더 적용하여상기 단순화된 질의문을 생성하는 단계 및 상기 판별하는 단계가 (self) attention GAN 기반인 것을 포함하는영상 검색 방법."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 16항에 있어서, 상기 단순화된 질의문을 생성하는 단계는 손실함수 값을 계산하며 학습을 수행하되,상기 손실함수 값의 계산 시 문장 어휘력, 문장 복잡도 및 벡터 유사도 중 적어도 어느 하나를 고려하는 영상검색 방법."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18 항에 있어서,상기 단순화된 질의문을 생성하는 단계는 상기 손실함수 값과 판별 모델의 판별 결과를 피드백 받고,상기 판별하는 단계는 판별의 정답 값을 피드백 받는 것을 특징으로 하는 영상 검색 방법."}
{"patent_id": "10-2019-0145957", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 11항에 있어서,각 영상의 구간 별로 메타데이터를 생성하는 영상 캡셔닝 단계; 를 더 포함하되,상기 영상 캡셔닝 단계는,상기 메타데이터를 인공 지능 기술을 이용하여 자동으로 생성하는 것을 포함하는 영상 검색 방법."}
{"patent_id": "10-2019-0145957", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공 지능 기반의 심층 학습을 수행하여 사용자가 입력한 자연어를 단순화하여 효율적인 영상검색에 사용하는 방법 및 장치에 관한 것이다. 본 발명의 영상 검색 장치는 영상 검색을 위해 사용자 입력 질의문을 단 순화 하는 단순화 문장 생성 장치, 생성된 단순화 문장과 영상들의 메타데이터를 비교하여 관련도를 계산하는 관 련도 계산 장치, 관련도가 높은 영상들을 검색 결과로 제공하는 영상 검색 결과 제공부를 포함하고 상기 단순화 문장 생성 장치는, 학습을 위한 데이터가 저장된 학습 데이터 베이스, 학습을 통해 생성된 단순화된 질의문 생성 모델 및 판별 모델을 포함한다. 본 발명의 실시예에 의해, 심층학습을 이용하여 확장성과 정확성을 높이고 유지 비용을 줄여 종래 기술의 문제점을 해결할 수 있다."}
{"patent_id": "10-2019-0145957", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 질의문 단순화를 통한 영상 검색 방법 및 장치에 관한 것이다. 보다 상세하게는 인공지능 기반의 심 층학습을 수행하여 사용자가 입력한 자연어를 단순화하여 효율적인 영상검색에 사용하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2019-0145957", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "OTT와 IPTV, 그리고 유튜브(Youtube)와 같은 스트리밍 플랫폼을 통하여 다양하고 방대한 영상 콘텐츠가 유통되 고 있다. 이에 따라 시청자가 원하는 영상을 찾기 위해 필요한 영상 검색 기능에 대한 수요가 늘어나고 있으며, 원하는 검색 결과를 제공하기 위해 영상에 대한 메타데이터를 인공지능 기술을 이용하여 자동으로 생성하는 영 상 캡셔닝 기술도 개발되고 있다. 영상 캡셔닝(Captioning)을 통해 방대한 영상 콘텐츠에 대한 메타데이터(Description) 생성이 가능 해졌지만, 인간이 작성한 만큼의 표현력이나 복잡도보다 상당히 낮은 수준의 문장 생성만 가능한 상황이다. 즉, 영상 캡셔 닝 기술을 활용하여 영상 메타데이터를 구축하고 이를 이용하여 영상 검색을 하려고 했을 때 사람이 직접 입력한 질의 문장과 캡셔닝 문장 간의 표현 수준의 갭(Gap)으로 인하여 원하는 검색 결과를 제공하기 어려워진다. 예를 들어 특정 영상에 대하여, 사람은 '카메라 렌즈 안에 보이는 부부가 포즈를 취하는 대로 셔터를 누른다'이 라고 표현하였을 때, 캡셔닝 문장은 '사진을 찍고 있는 부부'와 같이 단순하고 간결하게 표현을 하기 때문에 검 색에 어려움이 있다. 종래 기술은 검색대상과 질의문에 대한 표현의 차이를 극복하기 위해 기존의 대부분의 기술은 유의어 사전이나 도메인 온톨로지(Domain Ontology)를 활용하여 관련 단어를 추가하는 방법을 취하였다. 하지만 이러한 방법은 확장성이 떨어지고, 제3의 지식베이스를 구축해야 하는 비용도 상당히 소요된다."}
{"patent_id": "10-2019-0145957", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 전술한 종래기술의 문제점을 해결하기 위해, 심층학습을 이용하여 사용자 입력 질의문의 의미 는 보존하되 어휘력, 문장 복잡도 등을 낮추는 단순화 문장 생성 장치를 제공하는데 있다. 또한, 본 발명은 단순화 문장 생성 장치를 이용하여 생성된 단순화 문장과 영상의 메타데이터(description)를 비교하여 관련이 있는 영상을 검색 결과로 제공하는 영상 검색 장치 및 방법을 제공하는 데 목적이 있다. 본 발명의 다른 목적 및 장점들은 하기의 설명에 의해서 이해될 수 있으며, 본 발명의 실시예에 의해 보다 분명 하게 알게 될 것이다. 또한, 본 발명의 목적 및 장점들은 특허청구범위에 나타낸 수단 및 그 조합에 의해 실현 될 수 있음을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2019-0145957", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한, 본 발명의 영상 검색을 위한 단순화 문장 생성 장치는, 학습 데이터가 저장된 학습 데이터 베이스, 상기 학습 데이터로 학습을 수행하여 생성된 모델을 통해 사용자 입력 질의문으로부터 단순화 문장을 생성하는 단순화 문장 생성부를 포함하되, 상기 학습 데이터베이스는 제 1 메타데이터 및 제 2 메타데이 터를 상기 학습 데이터로 구축하고, 상기 제 1 메타데이터는 단순 질의문으로 구성되고 상기 제 2 메타데이터는 복합 질의문으로 구성되는 것을 특징으로 한다. 또한, 상기 단순화 문장 생성부는 학습을 위해 상기 제 1 메타데이터와 상기 제 2 메타데이터를 벡터 형태로 표 현하는 임베딩을 수행하는 것을 특징으로 한다. 또한, 상기 단순화 문장 생성부는 상기 학습 데이터로 학습을 수행하여 생성된, 상기 제 2 메타데이터로부터 단 순화된 질의문을 생성하는, 단순화된 질의문 생성 모델을 포함하는 것을 특징으로 한다. 또한, 상기 단순화 문장 생성부는 상기 학습 데이터로 학습을 수행하여 생성된, 상기 생성된 단순화된 질의문과 상기 제 1 메타데이터를 비교하고 판별하는, 판별 모델을 포함하는 것을 특징으로 한다. 또한, 상기 단순화된 질의문 생성 모델과 상기 판별 모델은 GAN(Generative Adversarial Network)기반으로 구 성되는 것을 특징으로 한다. 또한, 학습 효과를 높이기 위해 어텐션 메커니즘을 적용하면 상기 단순화된 질의문 생성 모델과 상기 판별 모델 이 attention GAN 기반으로 구성되는 것을 특징으로 한다. 또한 상기 단순화된 질의문 생성 모델의 학습을 수행할 때, 손실함수 값을 계산하되, 상기 손실함수 값의 계산 시 문장 어휘력, 문장 복잡도 및 벡터 유사도 중 적어도 어느 하나를 고려하는 것을 특징으로 한다. 또한, 상기 단순화된 질의문 생성 모델은 상기 손실함수 값과 상기 판별 모델의 판별 결과를 피드백 받고, 상기 판별 모델은 판별의 정답 값을 피드백 받는 것을 특징으로 한다. 상기 목적을 달성하기 위한, 본 발명의 실시예에 따른 영상 검색 장치는, 사용자 입력 질의문으로부터 단순화 문장을 생성하는 단순화 문장 생성 장치, 단순화 문장 생성 장치로부터 생성된 단순화 문장과 영상들의 메타데 이터를 비교하여 관련도를 계산하는 관련도 계산 장치, 상기 관련도가 높은 영상들을 검색 결과로 제공하는 검 색결과 제공 부를 포함한다. 또한, 상기 영상 검색 장치는, 각 영상의 구간별로 메타데이터를 생성하는 영상 캡셔닝 부를 더 포함할 수 있으 며 상기 영상 캡셔닝 부는 상기 메타데이터를 인공 지능 기술을 이용하여 자동으로 생성하는 것을 포함 한다.상기 목적을 달성하기 위한, 본 발명의 실시예에 따른 영상 검색 방법은 영상 검색을 위한 단순화 문장 생성 단 계, 상기 단순화 문장 생성 단계를 통해 생성된 단순화 문장과 영상들의 상기 메타데이터를 비교하여 관련도를 계산하는 단계, 상기 관련도가 높은 영상들을 검색 결과로 제공하는 단계를 포함한다. 또한, 상기 단순화 문장 생성 단계는 단순화 문장을 생성하기 위해 학습 데이터가 구축된 학습 데이터 베이스를 구성하는 단계 및 상기 학습 데이터를 이용하여 학습을 수행하여 사용자 입력 질의문으로부터 단순화 문장을 생 성하는 단계를 포함한다. 또한, 상기 학습 데이터 베이스를 구성하는 단계에서 제 1 메타데이터 및 제 2 메타데이터를 상기 학습 데이터 로 구축하되 상기 제 1 메타데이터는 단순 질의문으로 구성되고 상기 제 2 메타데이터는 복합 질의문으로 구성 되는 것을 특징으로 한다. 또한, 상기 단순화 문장 생성 단계는 학습을 위해 상기 제 1 메타데이터와 상기 제 2 메타데이터를 벡터 형태로 표현하는 임베딩 과정을 포함하는 것을 특징으로 한다. 또한, 상기 단순화 문장 생성 단계는 상기 학습데이터를 이용하여 학습을 수행하는, 상기 제 2 메타데이터로부 터 단순화된 질의문을 생성하는 단계 및 상기 학습데이터를 이용하여 학습을 수행하는 상기 생성된 단순화된 질 의문과 상기 제 1 메타데이터를 비교하여 판별하는 단계를 포함한다. 또한, 상기 단순화된 질의문을 생성하는 단계와 상기 판별하는 단계는 GAN 기반으로 구성되는 것을 특징으로 한 다. 또한, 학습 효과를 높이기 위해 어텐션 메커니즘을 더 적용하면 상기 단순화된 질의문을 생성하는 단계 및 상기 판별하는 단계가 (self) attention GAN 기반으로 구성되는 것을 특징으로 한다. 또한, 상기 단순화된 질의문을 생성하는 단계는 손실함수 값을 계산하며 학습을 수행하되, 상기 손실함수 값의 계산 시 문장 어휘력, 문장 복잡도 및 벡터 유사도 중 적어도 어느 하나를 고려하는 것을 특징으로 한다. 또한, 상기 단순화된 질의문을 생성하는 단계는 상기 손실함수 값과 판별 모델의 판별 결과를 피드백 받고, 상 기 판별하는 단계는 판별의 정답 값을 피드백 받는 것을 특징으로 한다. 또한, 상기 영상 검색 방법은 각 영상의 구간 별로 메타데이터를 생성하는 영상 캡셔닝 단계를 더 포함할 수 있 으며 상기 영상 캡셔닝 단계는 상기 메타데이터를 인공 지능 기술을 이용하여 자동으로 생성하는 것을 포함한다."}
{"patent_id": "10-2019-0145957", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 질의문 단순화를 통한 영상 검색 방법 및 장치에 대한 것으로, 종래 기술과 달리, 심층학습을 이용하 여 확장성과 정확성을 높이고 유지비용을 줄일 수 있다. 또한, 본 발명의 실시예에 따르면, 사용자가 입력한 질의문의 표현 수준과 검색 대상의 메타데이터 (description)의 표현 수준에 차이가 있는 환경에서도 영상 검색 결과를 적절하게 제공할 수 있는 바 검색 성능 을 개선할 수 있다."}
{"patent_id": "10-2019-0145957", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참고로 하여 본 발명의 실시 예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나, 본 발명은 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 발명의 실시 예를 설명함에 있어서 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그에 대한 상세한 설명은 생략한다. 그리고, 도면에서 본 발명에 대한 설명과 관계없 는 부분은 생략하였으며, 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 발명에 있어서, 서로 구별되는 구성요소들은 각각의 특징을 명확하게 설명하기 위함이며, 구성요소들이 반드 시 분리되는 것을 의미하지는 않는다. 즉, 복수의 구성요소가 통합되어 하나의 하드웨어 또는 소프트웨어 단위 로 이루어질 수도 있고, 하나의 구성요소가 분산되어 복수의 하드웨어 또는 소프트웨어 단위로 이루어질 수도 있다. 따라서, 별도로 언급하지 않더라도 이와 같이 통합된 또는 분산된 실시 예도 본 발명의 범위에 포함된다. 본 발명에 있어서, 다양한 실시 예에서 설명하는 구성요소들이 반드시 필수적인 구성요소들을 의미하는 것은 아 니며, 일부는 선택적인 구성요소일 수 있다. 따라서, 일 실시 예에서 설명하는 구성요소들의 부분집합으로 구성 되는 실시 예도 본 발명의 범위에 포함된다. 또한, 다양한 실시 예에서 설명하는 구성요소들에 추가적으로 다른 구성요소를 포함하는 실시 예도 본 발명의 범위에 포함된다. 이하, 첨부한 도면을 참조하여 본 발명의 실시 예들에 대해서 설명한다. 도 1은 본 발명의 일 실시예에 따른 단순화 문장 생성 장치의 구조를 도시한 것이다. 예를 들어, 본 발명 의 일 실시예에 따른 단순화 문장 생성 장치는, 학습 데이터가 저장된 학습 데이터 베이스 와 사용자 입력 질의문을 단순화 문장으로 생성하는 단순화 문장 생성부를 포함하여 구성할 수 있다. 구체적으로, 상기 학습 데이터베이스는 단순 질의문으로 구성된 제 1 메타데이터 및 복합 질의문으로 구성 된 제 2 메타데이터를 상기 학습 데이터로 구축할 수 있다. 상기 학습 데이터로 구축에 대해서는 도 2 이하에서 상세히 설명할 것이다. 또한, 상기 단순화 문장 생성부는, 상기 학습 데이터베이스내에 구측된 상기 학습 데이터로 학습을 수행하는 단순화 질의문 생성 모델(도2, 1101)을 통해 단순화 문장을 생성할 수 있다. 따라서, 본 발명의 일 실시예에 따르면, 상기 구축된 학습 데이터 베이스 및 상기 단순화 문장 생성부 를 이용하여, 입력된 사용자 질의문을 단순화 문장으로 변환하는 것이 가능하다. 도 2는 본 발명의 일 실시예에 따른 학습 데이터의 유형과 그 구축 과정을 도시한 것이다. 먼저, 원본 영상을 수 초 단위로 여러 구간으로 나눈다. 도 2에서는 일 예시로서 임의의 n구간과 n+k구간 의 메타데이터를 표현하였다. 해당 구간을 표현한 메타데이터(201, 203)를 작성하여, 학습 데이터 인스턴스 (205, 207)를 생성한다. 보다 상세하게는, 메타데이터는 두 종류로 나누어 구축을 하되, 장면에 대한 설명을 짧고 쉬운 문장으로 작성한 단순 질의문으로 구성된 제 1 메타데이터와, 실제 영화 각본처럼 복잡하고 다양한 어휘로 표현한 복합 질 의문의 형식으로 구성된 제 2 메타데이터로 나누어 구축한다. 메타데이터를 작성할 때에는 영화나 드라마 등의 각본을 참고하여 작성할 수도 있고 도 6에서 상세하게 설명할 영상 캡셔닝(Captioning) 기술을 이용할 수 도 있으며 본 발명은 이에 한정되지 않는다. 예를 들어, 해당 구간 (n구간 또는 n+k구간)에 매칭되는 제 1 메타데이터와 제 2 메타데이터 각각의 질의문은 학습 데이터 인스턴스 튜플(instance tuple)로 구성되며, 예시적으로, 장면 n을 표현한 두 단순 질의 문과 장면 n을 표현한 하나의 복합 질의문을 하나의 n번째 학습 데이터 인스턴스 튜플 로 구성한다. 마찬 가지로, 장면 n+k을 표현한 질의문들을 n+k번째 학습 데이터 인스턴스 튜플 로 구성할 수 있다. 제 1 메타 데이터 및 제 2 메타데이터 모두 서로 표현은 다르게 되어 있지만 의미는 동일한 문장으로 구성되어 있다고 가정하고 이를 학습에 이용한다. 다만 하나의 학습 데이터 인스턴스 튜플이 되기 위한 단순질의문의 수와 복합 질의문의 수에는 제한이 없다. 예를 들어, 3개의 단순 질의문과 하나의 복합 질의문이 학습 데이터 인 스턴스 튜플이 될 수도 있다. 예를 들어, 특정 학습 데이터 인스턴스는 특정 영화의 특정 구간에 대해 제 1 메타데이터: (남자와 여자가 해변가를 걷고 있다) (남자가 여자를 업고 걷는다) 제 2 메타데이터: (신혼 부부가 따사로운 햇살과 파도가 넘실대는 해변가를 함께 걸어가다 신부를 등에 업고 다 정하게 미소를 지으며 걷는다) 와 같이 구성되어 있게 되며, 이를 학습데이터로 사용한다. 도 3은 본 발명의 일 실시예에 따른 상기 단순화 문장 생성부의 구체적인 모델을 도시한 것이다. 예를 들어, 도 3은 본 발명의 일 실시예에 따른 GAN(Generative Adversarial Network) 형태로 구성된 단순화 문장 생성부의 학습 모델과 그 학습 과정을 함께 도시한 것이다. 단, 본 발명은 설명의 편의를 위해 GAN을 예로 하여 개시하나, 본 발명의 기술적 특징은 GAN에 한정되지 않는다. 예를 들어, RNN, CNN 방식을 적용할 수도 있다. 기 구축된 학습데이터를 이용하여, 자연어 형태의 질의문의 의미를 보존하면서 문장을 단순화하기 위해서 본 발 명에서는 예시적으로 GAN 기반의 학습 모델을 구성하였다. 본 발명의 일 실시예로서, 복합 질의문은 제 2 메타데이터가 될 수 있으며 실제 단순 질의문은 제 1 메타데이터로 표현될 수 있다. 먼저 제 2 메타데이터로 표현된 복합 질의문을 단순화된 질의문으로 생성하는 단순화된 질의문 생성 모델에 대한 학 습 과정과 이렇게 생성된 단순화된 질의문이 실제 단순 질의문과 비교했을 때 같은지, 다른지 판별하 는 판별 모델에 대한 학습 과정에 대하여 설명한다. 먼저, 본 발명에서는 모델 구축에 필요한 학습 파라미터의 값이나 GAN 목적함수의 정의는 기존 여러 논문을 통 해 공개되어 있는 수식을 사용한다고 가정한다. 또한 심층 학습을 위해 자연어 형태의 문장을 벡터형태로 표현 하는 임베딩 과정도 BERT나 Skip-thought와 같은 공개되어 있는 문장 임베딩 모델을 사용한다고 가정한다. 또한 학습 효과를 높이기 위해 어텐션 메커니즘을 적용할 수 있다고 가정한다. 예를 들어, 어텐션 메커니즘을 추가적 으로 적용하면 학습 모델은 성능이 향상된 (self) attention GAN 기반으로 구성될 수 있다. 본 발명의 일 실시예에 따라 GAN 형태로 학습 네트워크를 구성한다면, 단순화된 질의문 생성모델은 복합 질의문을 입력 값으로 받아, 단순화된 질의문을 생성한다. 상기 단순화된 질의문은 판별 모델 의 입력 값이 되고, 판별 모델은 상기 단순화된 질의문과 실제 단순 질의문이 어 휘 수 준과 복잡도가 유사 혹은 동일한 수준인지를 비교하고 판별한다. 이를 통해 판별 모델이 자신만의 판별 결과를 도출하면, 판별 결과와 판별 정답 값을 대비할 수 있다. 예를 들어, 단순화된 질의문 생성 모델은 도 4에서 상세하게 설명할 손실함수 값과 판별 모델의 판 별 결과를 피드백 받아, 질의문의 의미는 보존하면서 어휘 수준, 복잡도가 실제 단순 질의문과 유사 혹은 동일한 수준이 될 때까지 훈련된다. 단순화된 질의문 생성 모델의 목표는 판별 모델이, 자신 이 생성한 단순화된 질의문을 실제 단순 질의문이라고 판별하도록 하는 것이다. 즉, 실제 단순 질의 문과 견주어도 손색없을 정도로 문장의 본래 의미는 유지되면서도 자연스러운 단순화된 질의문을 생 성하는 것이다. 반면, 판별 모델의 경우 상기 실제 단순 질의문과 상기 단순화된 질의문을 입력 값으로 받아서, 둘 중 어떤 질의문이 실제 단순 질의문이고 어떤 것이 단순화된 질의문 생성 모델이 생성한 것인 지를 비교하여 판별한다. 판별 모델의 목표는 두 질의문 중 실제 단순 질의문을 가려내되, 생성된 단순화된 질의문에 혼동되지 않고 높은 정확성으로 구분하는 것이다. 판별 모델의 성능을 향상시키 기 위해 판별의 정답 값을 피드백 받는 것을 특징으로 할 수 있다. 여기서 판별의 정답 값이란, 판별 모델이 수행한 상기 판별의 실제 정답 값, 즉, 판별 결과가 참인지를 나타내는 값이 될 수 있다. 도 4는 본 발명의 일 실시예에 따른 단순화된 질의문 생성 모델의 학습 과정을 더욱 상세하게 도시한 것 이다. 예를 들어, 단순화된 질의문 생성 모델은, 자연어를 벡터(4011, 4013) 형태로 표현하는 임베딩 과 정을 포함하는, 단순화된 질의문을 생성하는 부분(1101a)과 학습이 얼마나 원하는 방향으로 이루어지고 있는지 를 나타내는 척도, 즉 출력값이 얼마나 기대값에 가까운지를 나타내는 지표인 손실함수를 계산(1101b)하는 부분을 포함할 수 있다. 먼저, 본 발명의 일 실시예에 따르면, 단순화 질의문을 생성하는 부분(1101a)은 복합 질의문 에 대하여, 심층 학습을 위해 자연어 형태의 문장을 벡터 형태로 표현하는 과정을 거쳐, 임베딩 벡터를 생성한다. 이 후 인코딩, 디코딩 과정을 거쳐 단순화된 질의문의 임베딩 벡터를 생성하고, 이를 통해 단순화된 질의문 을 생성한다. 단순화된 질의문을 생성하면 이를 손실함수를 계산하는 부분(1101b)에 전달한다. 손실함수를 계산하는 부 분(1101b)는 단순화된 질의문과 복합 질의문을 입력으로 받아 손실함수를 계산한다. 단순화된 질의문 생성 모델을 학습할 때 원하는 방향으로 학습이 이루어 지도록, 즉, 완성도가 높은 단순화된 질의문(40 3)을 생성하기 위하여 손실함수 값을 계산(1101b) 하는 것이다. 복합 질의문이 얼마나 잘 단순화되었는지를 판단하기 위해 손실함수를 줄이는 것이 상기 모델의 목 표이므로, 손실함수 값 계산(1101b)시 문장 어휘력, 문장 복잡도, 벡터 유사도 중 적어도 어느 하나를 고려하도 록 고안하였다. 일 예로, 손실함수 계산(1101b)은 아래의 수식과 같이 할 수 있다. [수식 1] L(x,y) = a(Fluency(x,y)) / (b(Complexity(x,y)) + c(similarity(x,y))) 여기서 x는 복합 질의문 학습 인스턴스를 의미하고 y는 x를 통해 생성된 질의문이다. a, b, c는 가중치로서 그 합은 1이다. Fluency(x,y)는 x와 y의 문장 어휘력의 차이를 수치화 한 것으로 본 발명에서는 문장의 어휘력 수 준을 측정하기 위해 초등학교 교과서 학년별 어휘 통계 자료를 하나의 예시로 사용하였다. 다음 도 5는 본 발명 의 일 실시예에 따른 실제 우리나라 초등학교 교과서의 어휘 통계 자료이다. 도 5에서, '폭행하다'와 '때 리다'는 같은 의미이지만, '폭행하다'는 고학년에 나타나고, '때리다'는 전 학년에 골고루 나타 난다. 또한 '증언하다'와 '말하다'는 영상에서 같은 의미로 표현될 수 있지만, '증언하다'는 고 학년에 나타나고 '말하다'는 전 학년에 걸쳐 두루 나타난다. 이를 통해 '폭행하다'가 '때리다' 보다 어휘 수준이 높음을 알 수 있고 '증언하다'가 '말하다'보다 어휘 수준이 높다고 유추할 수 있다. 본 발명의 일 실시예로서 이러한 통계 자료를 활용하여 문장의 어휘 수준을 수치화 하였다. 즉, x 라는 문장이 t1, t2, …tn의 단어로 구성되어 있다고 하였을 때 각 단어를 상단 표의 통계수치를 이용하여 1x6의 벡 터로 표현할 수 있다. x에 대한 어휘 수준을 나타내는 벡터는 다음과 같이 나타낼 수 있다. x 어휘수준 벡터 = tf - idf(t1)t1 + tf - idf(t2)t2 + …+ tf - idf(tn)tn 여기서 t1은 t1에 대한 임베딩 벡터이다. 예를 들어 위 표를 바탕으로 '때리다'의 임베딩 벡터는 [0, 8, 4, 5, 8, 6] 으로 구성될 수 있다. Fluency(x,y)는 다음과 같이 계산된다. [수식 2] Fluency(x,y) = 코사인 유사도(x 어휘수준 벡터, y 어휘수준 벡터) Fluency 값이 낮을수록 어휘 수준의 차이가 높도록 고안하였다. Complexity(x,y)는 다음과 같이 계산된다. [수식 3] Complexity(x,y) = (동사_출현빈도수_in_x) - (동사_출현빈도수_in_y) 즉 x에 나타나 있는 동사의 개수에서 y에 출현한 동사의 개수의 차이로 문장 복잡도를 계산하며 차이가 클수록 y 문장이 더 단순하게 표현되었음을 의미한다. Similarity(x,y)는 각 x,y에 대한 임베딩 벡터를 활용하여 코사인 유사도 값을 계산한다. 도 6은 본 발명의 일 실시예에 따른 영상 검색 장치를 표현한 것으로, 영상 검색이 수행되는 과정을 함께 도시 한 것이다. 학습을 통해 모델이 구축되고 나면 단순화 문장 생성 장치를 활용하여 영상검색을 수행하는 실 시예를 소개한다. 본 발명의 일 실시예에 따르면, 원본 영상을 수 초 단위의 구간으로 나누어 만든 원본 영상의 구간별 집합(60 1)이 존재한다고 가정한다. 이에 대하여 영상 캡셔닝 부를 통해, 각 영상의 구간 별로 해당 구간을 나타낸, 문장으로 구성된 메타데이터가 생성되어 있다고 가정한다. 예를 들어, 영상 캡셔닝 부는 인공 지능 기술을 이용하여 자동으로 영상에 등장하는 객체나 배경 등을 구 별하여 인식하고, 태깅(Tagging)하여 해당 장면을 표현하는 단순한 형태의 문장인 메타데이터를 생성할 수 있다. 사용자로부터 질의문이 입력되면, 단순화된 질의문 생성 모델을 포함하고 있는 단순화 문장 생성 장치를 통해 사용자 입력 질의문과 의미는 동일하나 어휘 수준 및 복잡도가 낮아진 단순화 문장을 생성한다. 생성 된 단순화 문장와 영상 캡셔닝 부에 의한 메타데이터의 각 영상 구간에 대한 관련도를 관련도 계산 장치에 의해 구한다. 이후 검색 결과 제공부에서는, 사용자에게 관련도가 높은 영상을 검색 결과(607, 609)로서 제공하게 된다. 이 때, 영상 검색 결과가 제공되는 방식은 제한하지 않으나 예시적으로, 바람직하게는 단순화 문장과 일치하는 해 당 구간의 영상을 제공할 수 있을 것이나 일치하는 해당 구간을 포함하는 영상 전체를 제공할 수도 있을 것이다. 도 7은 본 발명의 일 실시예에 따른 영상 검색 방법을 단계적으로 표현한 것이다. 예를 들어, 먼저 영상 검색을 위한 단순화 문장을 생성하는 단계(S701)는 사용자 입력 질의문으로부터 의미는 같으나 어휘 수준 및 복잡도가 낮아진 단순화 문장을 생성한다. 상기 영상 검색을 위한 단순화 문장을 생성하는 단계(S701)에 대해서는 도 8에 서 더욱 상세하게 설명할 것이다. 본 발명의 일 실시예에 따른 영상 검색 방법에서는 상기 단계(S701)에서 생성된 단순화 문장과 영상들의 메타데 이터를 비교하여 관련도를 계산하는 단계(S703)를 포함할 수 있다. 이 때 메타데이터란, 영상을 수 초 구간으로 나누어 해당 구간에 대하여 표현한 문장을 의미한다. 메타데이터를 작성할 때에는 영화나 드라마 등의 각본을 참고하여 작성할 수도 있으며, 도 6에서 개시된 바와 같이 영상 캡셔닝 기술을 이용할 수도 있다. 상기 영상 캡 셔닝 기술은 인공 지능에 의해 자동으로 장면의 객체, 배경을 구분하고 인식하여, 태깅된 후 생성된 문장일 수 도 있으며, 본 발명은 이에 한정되지 않는다. 상기 계산된 관련도가 높은 영상들을 검색 결과로 제공하는 단계(S705) 또한 포함될 수 있다. 이 때 영상 검색 결과가 제공되는 방식은 제한하지 않으나, 예시적으로, 바람직하게는 단순화 문장과 일치하는 해당 구간의 영상 을 제공할 수도 있으나 일치하는 해당 구간을 포함하는 영상 전체를 제공할 수도 있을 것이다. 도 8은 본 발명의 일 실시예에 따른, 도 7의 단순화 문장 생성 단계(S701)을 상세하게 도시한 것이다. 예를 들 어, 상기 단순화 문장 생성 단계(S701)는, 단순화 문장을 생성하기 위한 학습 데이터를 구축하는 단계(S7011)와 학습 데이터를 이용하여 기계학습을 수행하는 단계(S7012)를 포함할 수 있다. 예를 들어, 단순화 문장 생성을 위한 학습 데이터를 구축하는 단계(S7011)에서는 상기 학습 데이터로 제 1 메타 데이터 및 제 2 메타데이터를 상기 구축할 수 있다. 상기 제 1 메타데이터는 단순 질의문으로 구성되고 상기 제 2 메타데이터는 복합 질의문으로 구성할 수 있다. 도 2에서 상세하게 개시한 바와 같이, 원본 영상을 수 초 단 위의 여러 구간으로 나누고, 해당 구간을 표현한 메타데이터(도2, 201, 203)를 작성하여, 학습 데이터 인스턴스 를 생성한다. 보다 상세하게는, 메타데이터는 두 종류로 나누어 구축을 하되, 장면에 대한 설명을 짧고 쉬운 문장으로 작성한 단순 질의문으로 구성된 제 1 메타데이터(도2, 201)와, 실제 영화 각본처럼 복잡하고 다양한 어휘로 표현한 복 합 질의문의 형식으로 구성된 제 2 메타데이터(도2, 203)로 나누어 구축할 수 있다. 메타데이터를 작성할 때에 는 영화나 드라마 등의 각본을 참고하여 작성할 수도 있고 도 6에서 상세하게 설명한 영상 캡셔닝(Captioning) 기술을 이용할 수도 있다. 또한 영상 캡셔닝 기술은 상기 메타데이터를 인공 지능 기술을 이용하여 자동으로 장 면의 객체와 배경을 구분하여 인식하고, 태깅하여 문장을 생성하는 것을 포함한다. 또한, 본 발명은 이에 한정 되지 않는다. 예를 들어, 상기 학습 데이터를 이용하여 학습을 수행하는 단계(S7012)는 단계 (S7012a)를 통해 단순화된 질의 문 생성 모델을, 단계 (S7012b)를 통해 판별 모델을 생성한다. 상기 모델들은 GAN(Generative AdversarialNetwork) 형태로 구성할 수 있으나 설명의 편의를 위해 GAN을 예로 하여 개시한 것이고 본 발명의 기술적 특징 은 GAN에 한정되지 않는다. 예를 들어, RNN, CNN 방식을 적용할 수도 있다. 먼저, 본 발명에서는 모델 구축에 필요한 학습 파라미터의 값이나 GAN 목적함수의 정의는 기존 여러 논문을 통 해 공개되어 있는 수식을 사용한다고 가정한다. 또한 심층 학습을 위해 자연어 형태의 문장을 벡터형태로 표현 하는 임베딩 과정도 BERT나 Skip-thought와 같은 공개되어 있는 문장 임베딩 모델을 사용한다고 가정한다. 또한 학습 효과를 높이기 위해 어텐션 메커니즘을 적용할 수 있다고 가정한다. 예를 들어, 상기 단계(S7012)에 어텐 션 메커니즘을 추가적으로 적용하면 성능이 향상된 (self) attention GAN기반으로 구성될 수 있다. 본 발명의 일 실시예에 따르면 복합 질의문으로부터 단순화된 질의문을 생성하는 단계(S7012a) 및 생성된 단순 화된 질의문과 실제 단순 질의문을 비교하여 판별하는 단계(S7012b)를 학습 과정으로서 포함할 수 있다. 이 때, 복합 질의문은 상기 제 2 메타데이터가 될 수 있으며 실제 단순 질의문은 상기 제 1 메타데이터로 표현될 수 있 다. 또한 도 3 및 도 4에서 개시한 바와 같이, 단순화된 질의문을 생성하는 단계(S7012a)는, 복합 질의문 에 대하여 심층 학습을 위해 자연어 형태의 문장을 벡터 형태로 표현하는 과정을 거쳐 임베딩 벡터를 생성하 며, 이후 인코딩, 디코딩 과정을 거쳐 단순화된 질의문의 임베딩 벡터를 생성하고, 이를 통해 단순화된 질의문을 생성할 수 있다. 단순화된 질의문 생성 모델을 생성하기 위해 학습하는 단계, 즉 단순화된 질의문을 생성하는 단계(S7012a)는 의 도하는 방향으로 학습이 이루어 지도록 손실함수 값을 계산할 수 있다. 손실함수 값 계산시, 문장 어휘력, 문장 복잡도, 벡터 유사도 중 적어도 어느 하나를 고려하도록 고안하였다. 이러한 문장 어휘력, 문장 복잡도, 벡터 유사도를 계산하는 방법은 도 4에서 상세히 개시한 바와 같다. 또한 단순화된 질의문을 생성하는 단계(S7012a) 에서는 도 3에서 개시한 바와 유사하게, 손실함수 값과 판별하는 단계(S7012b)의 판별 결과를 피드백 받을 수 있으며, 본 발명은 이에 한정되지 않는다. 일 실시예로서 판별 모델을 생성하기 위해 학습하는 단계, 생성된 단순화된 질의문과 실제 단순 질의문을 비교 하여 판별하는 단계(S7012b)는, 도 3에서 상세히 개시한 바와 같이, 상기 실제 단순 질의문과 상기 단순화된 질 의문을 입력 값으로 받는다. 둘 중 어떤 질의문이 실제 단순 질의문이고, 어떤 것이 단순화된 질의문 생성하는 단계(S7012a)에서 생성한 것인지를 비교하여 판별한다. 상기 판별하는 단계(S7012b)의 목표는 두 질의문 중 실 제 단순 질의문을 가려내되, 생성된 단순화된 질의문에 혼동되지 않고, 높은 정확성으로 구분하는 것이다. 따라 서, 상기 판별하는 단계(S7012b)의 성능을 향상시키기 위해 판별의 정답 값을 피드백 받는 것을 특징으로 할 수 있다. 여기서 판별의 정답 값이란, 판별 모델이 수행한 상기 판별의 실제 정답 값, 즉, 판별 결과가 참인지를 나타내는 값이 될 수 있다. 도 9는 본 발명의 일 실시예에 따른 영상 검색 장치 및 방법이 구현되는 환경을 나타낸 것이다. 먼저 서버는 그 구현 방식에 있어서 제한이 없는 바 기존의 중앙집권식 서버뿐 아니라 클라우드 등과 같이 다양한 방법으로 구현될 수 있다. 사용자 단말은 통신이 가능한, 영상 검색이 가능한 전자 기기이면 되는 바, 휴대형 정보 단말기기, 스마트폰, 모바일 전자기기, 거치형 컴퓨터, 노트북 등 그 단말의 유형에 제한이 없다. 서버와의 연결 방식에 관련하여서 도 유선인지 무선인지에 대한 제한을 두지 않는다. 예를 들어, 사용자 단말은 무선으로 서버와 연결될 수 있으며, 사용자 단말(902, 903)은 유선으로 연결될 수도 있고 무선으로 연결될 수도 있다. 뿐만 아니라 본 발명의 일 실시예에 따른 영상 검색을 위한 장치가 서버에 모든 구성요소가 구비되어 있어 사용 자 단말에서는 단지 질의문 만을 입력 받아 서버로 전달하여 처리하게 할 수도 있으며, 반대로, 영상 검색을 위 한 장치가 사용자 단말에 전부 구성되어 있을 수도 있다. 또한, 편의상 일부 구성요소는 서버에, 일부 구성요소 는 사용자 단말로 나누어 구비될 수도 있는 바 그 구성 방식에 대하여 제한을 두지 않는다. 뿐만 아니라 영상 검색 방법에 있어서도 상술한 바와 같이 영상 검색을 위한 전부의 단계가 서버에서 처리되는 것일 수도 있으며 단말에서 처리되는 것도 가능하며, 일부 단계는 서버에서, 일부 단계는 사용자 단말에서 나누 어 처리될 수도 있다.본 개시의 다양한 실시 예는 모든 가능한 조합을 나열한 것이 아니고 본 개시의 대표적인 양상을 설명하기 위한 것이며, 다양한 실시 예에서 설명하는 사항들은 독립적으로 적용되거나 또는 둘 이상의 조합으로 적용될 수도 있다. 또한, 본 개시의 다양한 실시 예는 하드웨어, 펌웨어(firmware), 소프트웨어, 또는 그들의 결합 등에 의해 구현 될 수 있다. 하드웨어에 의한 구현의 경우, 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 범용 프로세서(general processor), 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 본 개시의 범위는 다양한 실시 예의 방법에 따른 동작이 장치 또는 컴퓨터 상에서 실행되도록 하는 소프트웨어 또는 머신-실행 가능한 명령들(예를 들어, 운영체제, 애플리케이션, 펌웨어(firmware), 프로그램 등), 및 이러 한 소프트웨어 또는 명령 등이 저장되어 장치 또는 컴퓨터 상에서 실행 가능한 비-일시적 컴퓨터-판독가능 매체 (non-transitory computer-readable medium)를 포함한다."}
{"patent_id": "10-2019-0145957", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상에서 설명한 본 발명은, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 있어 본 발명의 기술적 사상을 벗어나지 않는 범위 내에서 여러 가지 치환, 변형 및 변경이 가능하므로, 본 발명의 범위는 전술한 실시 예 및 첨부된 도면에 의해 한정되는 것이 아니다."}
{"patent_id": "10-2019-0145957", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 단순화 문장 생성 장치를 도시한 것이다. 도 2는 본 발명의 일 실시예에 따른 학습 데이터 구축 과정을 도시한 것이다. 도 3은 본 발명의 일 실시예에 따른 GAN 형태로 구성된 단순화 문장 생성부의 학습 모델을 도시한 것이다. 도 4는 본 발명의 일 실시예에 따른 단순화 문장 생성 모델의 상세한 학습 과정을 도시한 것이다. 도 5는 본 발명의 일 실시예에 따른 우리나라 초등학교 교과서의 어휘 통계 자료 예시이다. 도 6은 본 발명의 일 실시예에 따른 단순화 문장 생성 장치를 이용한 영상 검색 장치를 도시한 것이다. 도 7은 본 발명의 일 실시예에 따른 영상 검색 방법을 단계별로 표현한 것이다. 도 8은 본 발명의 일 실시예에 따른 상세한 단순화 문장 생성 단계를 도시한 것이다.도 9는 본 발명의 일 실시예에 따른 영상 검색 장치 및 방법이 구현되는 환경을 도시한 것이다."}
