{"patent_id": "10-2020-0115911", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0033713", "출원번호": "10-2020-0115911", "발명의 명칭": "데이터 처리 시스템 및 그 동작 방법", "출원인": "에스케이하이닉스 주식회사", "발명자": "남지훈"}}
{"patent_id": "10-2020-0115911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "신경망을 통한 예측값과 실제값 사이의 오차를 수치화한 손실함수의 기울기 데이터를 공유하며, 상기 기울기 데이터에 따라 가중치를 업데이트하는 에폭(epoch) 과정을 설정된 횟수 반복하는 복수의 가속기를 포함하는 데이터 처리 시스템으로서,상기 복수의 가속기 각각은, 이전 학습 이터레이션(Iteration)에서 산출된 입력 데이터별 상기 기울기 데이터의분산 및 상기 에폭 반복 횟수 중 적어도 하나에 기초하여, 상기 기울기 데이터의 정밀도를 조정하여, 정밀도가조정된 기울기 데이터를 다른 가속기로 전송하도록 구성되는 정밀도 조정부; 및적어도 상기 입력 데이터, 상기 가중치 및 상기 기울기 데이터에 기초하여 신경망 모델을 생성하도록 구성되는연산 회로;를 포함하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2020-0115911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 정밀도 조정부는, 상기 다른 가속기로부터 상기 정밀도가 조정된 기울기 데이터를 제공받아 상기 연산 회로에 초기값으로 설정된 정밀도로 변환하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2020-0115911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 각각의 가속기는, 전체 학습 데이터를 설정된 배치 크기로 분할한 미니 배치를 입력받으며, 상기 미니 배치 각각에 대한 학습 이터레이션을 상기 복수의 가속기에서 병렬로 수행하고 통합하는 상기 에폭 과정을 설정된횟수 반복하여 신경망 모델을 생성하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2020-0115911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 각각의 가속기는, 매 학습 이터레이션에서, 상기 입력 데이터에 가중치를 적용하여 예측값을 연산하고, 상기 예측값과 상기 입력 데이터 간의 오차에 따라 상기 손실함수의 기울기 데이터를 산출하며, 상기 기울기 데이터의 기울기가 낮은 방향으로 상기 가중치를 업데이트하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2020-0115911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 각각의 가속기는, 매 에폭마다 다른 가속기로부터 상기 정밀도가 조정된 기울기 데이터를 수신하여, 평균기울기 데이터를 산출하고 상기 가중치를 업데이트하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2020-0115911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 복수의 가속기는 상기 정밀도가 조정된 기울기 데이터를 수신하고 통합하는 적어도 하나의 마스터 가속기;및상기 마스터 가속기로부터 상기 통합된 기울기 데이터를 제공받아 상기 가중치를 업데이트하는 복수의 슬레이브가속기;를 포함하도록 구성되는 데이터 처리 시스템.공개특허 10-2022-0033713-3-청구항 7 제 1 항에 있어서,상기 복수의 가속기는 상기 정밀도가 조정된 기울기 데이터를 상호 공유하고 각각의 가속기에서 통합하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2020-0115911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 정밀도 조정부는, 상기 분산이 작을수록 상기 기울기 데이터가 높은 정밀도를 갖도록 조정하도록 구성되는데이터 처리 시스템."}
{"patent_id": "10-2020-0115911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 정밀도 조정부는, 상기 에폭 반복 횟수가 증가할수록 상기 기울기 데이터가 높은 정밀도를 갖도록 조정하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2020-0115911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "신경망을 통한 예측값과 실제값 사이의 오차를 수치화한 손실함수의 기울기 데이터를 공유하며, 상기 기울기 데이터에 따라 가중치를 업데이트하는 에폭(epoch) 과정을 설정된 횟수 반복하는 복수의 가속기를 포함하는 데이터 처리 시스템의 동작 방법으로서,상기 각각의 가속기가, 이전 학습 이터레이션(Iteration)에서 산출된 입력 데이터별 상기 기울기의 분산 및 상기 에폭 반복 횟수 중 적어도 하나에 기초하여, 상기 기울기 데이터의 정밀도를 조정하는 단계;상기 각각의 가속기가, 상기 정밀도가 조정된 기울기 데이터를 다른 가속기로 전송하는 단계; 및상기 각각의 가속기가, 적어도 상기 입력 데이터, 상기 가중치 및 상기 기울기 데이터에 기초하여 상기 에폭 과정을 상기 설정된 횟수 반복하여 신경망 모델을 생성하는 단계;를 포함하도록 구성되는 데이터 처리 시스템의 동작 방법."}
{"patent_id": "10-2020-0115911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 각각의 가속기가, 상기 다른 가속기로부터 상기 정밀도가 조정된 기울기 데이터를 제공받아 상기 연산 회로에 초기값으로 설정된 정밀도로 변환하는 단계를 더 포함하도록 구성되는 데이터 처리 시스템의 동작 방법."}
{"patent_id": "10-2020-0115911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 10 항에 있어서,상기 신경망 모델을 생성하는 단계는,전체 학습 데이터를 설정된 배치 크기로 분할한 미니 배치를 입력받는 단계;상기 미니 배치 각각에 대한 학습 이터레이션을 상기 복수의 가속기에서 병렬로 수행하고 통합하는 상기 에폭과정을 수행하는 단계; 및상기 에폭 과정을 설정된 횟수 반복하여 신경망 모델을 생성하는 단계;를 포함하도록 구성되는 데이터 처리 시스템의 동작 방법."}
{"patent_id": "10-2020-0115911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 10 항에 있어서,상기 신경망 모델을 생성하는 단계는,공개특허 10-2022-0033713-4-매 학습 이터레이션에서, 상기 입력 데이터에 가중치를 적용하여 예측값을 연산하는 단계;상기 예측값과 상기 입력 데이터 간의 오차에 따라 상기 손실함수의 기울기 데이터를 산출하는 단계; 및상기 기울기 데이터의 기울기가 낮은 방향으로 상기 가중치를 업데이트하는 단계;를 포함하도록 구성되는 데이터 처리 시스템의 동작 방법."}
{"patent_id": "10-2020-0115911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 가중치를 업데이트하는 단계는, 매 에폭마다 다른 가속기로부터 상기 정밀도가 조정된 기울기 데이터를 수신하여 평균 기울기 데이터를 산출하고 상기 가중치를 업데이트하는 단계를 포함하도록 구성되는 데이터 처리시스템의 동작 방법."}
{"patent_id": "10-2020-0115911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 10 항에 있어서,상기 정밀도를 조정부하는 단계는, 상기 분산이 작을수록 상기 기울기 데이터가 높은 정밀도를 갖도록 조정하도록 구성되는 데이터 처리 시스템의 동작 방법."}
{"patent_id": "10-2020-0115911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 10 항에 있어서,상기 정밀도를 조정하는 단계는, 상기 에폭 반복 횟수가 증가할수록 상기 기울기 데이터가 높은 정밀도를 갖도록 조정하도록 구성되는 데이터 처리 시스템의 동작 방법."}
{"patent_id": "10-2020-0115911", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에 의한 데이터 처리 시스템은 신경망을 통한 예측값과 실제값 사이의 오차를 수치화한 손실함수의 기 울기 데이터를 공유하며, 기울기 데이터에 따라 가중치를 업데이트하는 에폭(epoch) 과정을 설정된 횟수 반복하 는 복수의 가속기를 포함하는 데이터 처리 시스템으로서, 복수의 가속기 각각은, 이전 학습 이터레이션 (Iteration)에서 산출된 입력 데이터별 기울기 데이터의 분산 및 에폭 반복 횟수 중 적어도 하나에 기초하여, 기 울기 데이터의 정밀도를 조정하여, 정밀도가 조정된 기울기 데이터를 다른 가속기로 전송하도록 구성되는 정밀도 조정부 및, 적어도 입력 데이터, 가중치 및 기울기 데이터에 기초하여 신경망 모델을 생성하도록 구성되는 연산 회로를 포함하도록 구성될 수 있다."}
{"patent_id": "10-2020-0115911", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 기술은 데이터 처리 기술에 관한 것으로, 보다 구체적으로는 신경망 연산을 위한 데이터 처리 시스템 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2020-0115911", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술은 인간의 지적 능력을 모방하기 위한 방법을 연구하는 것으로 이미지 인식, 자연어 처리를 비롯 하여 자율 주행 자동차, 자동화 시스템, 의료, 보안, 금융 등 그 적용 분야가 날로 확대되고 있다. 인공 신경망은 인공지능을 구현하기 위한 하나의 방법이다. 인공 신경망의 목적은 학습을 통해 기계의 문제 해 결 능력, 즉 추론력을 키우는 데 있으나, 출력의 정확도가 높아질수록 연산량, 메모리 접근 횟수 및 데이터 이 동량이 증가하게 된다. 이는 속도 저하, 전력 소비 등을 유발하여 시스템 성능을 저하시키는 요인이 될 수 있다."}
{"patent_id": "10-2020-0115911", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 기술의 실시예는 데이터를 고속으로 이동시켜 연산 속도를 향상시킬 수 있는 데이터 처리 시스템 및 그 동작 방법을 제공할 수 있다."}
{"patent_id": "10-2020-0115911", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 기술의 일 실시예에 의한 데이터 처리 시스템은 신경망을 통한 예측값과 실제값 사이의 오차를 수치화한 손 실함수의 기울기 데이터를 공유하며, 상기 기울기 데이터에 따라 가중치를 업데이트하는 에폭(epoch) 과정을 설 정된 횟수 반복하는 복수의 가속기를 포함하는 데이터 처리 시스템으로서, 상기 복수의 가속기 각각은, 이전 학 습 이터레이션(Iteration)에서 산출된 입력 데이터별 상기 기울기 데이터의 분산 및 상기 에폭 반복 횟수 중 적어도 하나에 기초하여, 상기 기울기 데이터의 정밀도를 조정하여, 정밀도가 조정된 기울기 데이터를 다른 가속 기로 전송하도록 구성되는 정밀도 조정부; 및 적어도 상기 입력 데이터, 상기 가중치 및 상기 기울기 데이터에 기초하여 신경망 모델을 생성하도록 구성되는 연산 회로;를 포함하도록 구성될 수 있다. 본 기술의 일 실시예에 의한 데이터 처리 시스템의 동작 방법은 신경망을 통한 예측값과 실제값 사이의 오차를 수치화한 손실함수의 기울기 데이터를 공유하며, 상기 기울기 데이터에 따라 가중치를 업데이트하는 에폭 (epoch) 과정을 설정된 횟수 반복하는 복수의 가속기를 포함하는 데이터 처리 시스템의 동작 방법으로서, 상기 각각의 가속기가, 이전 학습 이터레이션(Iteration)에서 산출된 입력 데이터별 상기 기울기의 분산 및 상기 에 폭 반복 횟수 중 적어도 하나에 기초하여, 상기 기울기 데이터의 정밀도를 조정하는 단계; 상기 각각의 가속기 가, 상기 정밀도가 조정된 기울기 데이터를 다른 가속기로 전송하는 단계; 및 상기 각각의 가속기가, 적어도 상 기 입력 데이터, 상기 가중치 및 상기 기울기 데이터에 기초하여 상기 에폭 과정을 상기 설정된 횟수 반복하여 신경망 모델을 생성하는 단계;를 포함하도록 구성될 수 있다."}
{"patent_id": "10-2020-0115911", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 기술에 의하면, 학습 진행 상태에 따라 분산된 프로세서 간에 이동되는 데이터의 양이 조절되어, 데이터 전 송 오버헤드로 인한 속도 저하 및 병목 현상을 방지할 수 있다."}
{"patent_id": "10-2020-0115911", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 기술의 실시예를 보다 구체적으로 설명한다. 도 1a 및 도 1b는 일 실시예에 의한 인공 신경망의 데이터 처리 개념을 설명하기 위한 도면이다. 도 1a를 참조하면, 인공 신경망은 입력 레이어, 적어도 하나의 히든 레이어 및 출력 레이어로 이루어질 수 있고, 각 레이어는 적어도 하나의 노드를 포함할 수 있다. 입력 레이어는 예측값(출력값)을 도출하기 위해 사용되는 데이터(입력값)를 입력받는다. 만약 N개의 입력 값들이 있다면 입력 레이어는 N개의 노드를 포함할 수 있다. 인공 신경망의 학습 과정에서 입력값은 학습 데이터일 수 있고, 추론 과정에서는 인식 대상 데이터일 수 있다. 히든 레이어는 모든 입력 노드로부터 입력값을 받아 가중합을 계산하고 전이함수에 적용하여 출력 레이어 로 전달한다. 출력 레이어는 히든 레이어에서 파악한 특징을 사용하여 출력 패턴을 결정하고 예측값을 출력한다. 각 입력 노드, 히든 노드들 및 출력 노드는 모두 가중치를 갖는 네트워크로 연결되어 있다. 특히, 히든 레이어 는 가중치와 편향(bias)을 통해 입력값에 숨겨져 있는 특성을 학습 또는 도출할 수 있다. 가중치란 노드와 노드 간의 연결 강도, 다른 관점에서는 각 노드의 입력 신호가 출력 신호에 주는 영향도를 조 절하는 매개변수이다. 가중치의 초기값은 임의로 부여되고, 학습(훈련) 과정을 통해 예측값을 가장 잘 맞추는 값으로 조정될 수 있다. 전이함수, 즉 활성화 함수는 히든 레이어 내 각 노드의 출력 신호가 설정된 임계값 이상이면 활성화되어 다음 노드로 출력 신호를 전달하는 함수이다. 편향은 각 노드의 활성화 정도를 조정하는 매개변수이다. 인공 신경망 알고리즘은 입력 데이터(학습 데이터)와 유사한 출력 데이터가 생성되도록 가중치와 편향을 포함하 는 매개 변수를 결정하여 학습 모델을 생성하는 학습 과정 및, 학습 과정에서 생성한 학습 모델로 입력 데이터 (인식 대상 데이터)를 모델링하는 추론 과정을 포함할 수 있다. 학습 과정은 학습 데이터 집합을 구성하는 과정, 손실함수 값을 줄이기 위해 각 학습 데이터에 적용되는 가중치 및 편향에 대한 손실함수의 기울기를 구하는 과정, 손실함수를 최소화하는 기울기 방향으로 가중치를 갱신하는 과정 및, 기울기를 구하고 갱신하는 과정을 일정 횟수만큼 반복하는 과정으로 이루어질 수 있다. 손실함수는 출력 레이어에서 출력된 예측값과 실제값 사이의 차이를 수학적으로 구현한 함수이며, 평균제 곱오차(Mean Square Error; MSE), 교차 엔트로피(Cross Entropy Error; CEE) 등이 이용된다. 도 1b는 MSE 손실함수는 도 1b와 같은 2차 함수(볼록 함수(Convex function))로 나타내어진다. 도 1b의 손실함수 그래프에는 기울기가 0인 지점(최소값, Global Minimum)이 존재하며, 이 최소값에 손실함수가 수렴하게 된다. 따라서, 손실함수 그래프에 대한 접선의 기술기(Gradient)인 미분을 사용하여 최소값을 찾아낼 수 있다. 먼저, 가중치의 시작값(Initial Weight)을 선택하고, 선택한 시작값에서 그래프의 기울기를 계산한다. 손실함수 곡선의 다음 지점을 결정하기 위해 학습률(학습 계수)을 시작값에 반영하여 가중치를 업데이트하여, 다음 지점으로 이동한다. 이 때, 가능한 빨리 손실을 줄이기 위해 기울기의 반대 방향(음의 방향)으로 이동한 다. 이러한 과정을 반복하여 최소값에 점점 접근하고, 결과적으로 가중치를 최소값에 수렴시킬 수 있다. 이와 같이, 현재 가중치가 손실함수에 미치는 영향도를 파악하고, 그 영향도에 학습률을 반영하여 가중치를 갱 신하는 과정을 반복하여 점진적으로 손실이 최소가 되는 최적의 가중치를 찾는 과정을 경사 하강법(Gradient Descent; GD)이라 한다. 도 2는 일 실시예에 의한 학습 과정을 설명하기 위한 도면이다. 도 2를 참조하면, 먼저 순전파(Forward propagation) 과정(FP)에서 입력 레이어로부터 데이터를 입력받은 히든 레이어의 신경망 모델은 초기화된 가중치와 편향을 이용하여 예측값을 출력한다 출력 레이어에서는 손실 함수에 의해 예측값과 정답(실제값) 사이의 오차를 산출한다. 그리고, 출력 레이어로부터 입력 레이어로 거슬러 올라가는 역전파(Back propagation) 과정(BP)에서, 최적화 함수에 의해 손실함수의 기울기 값을 이용하여 손실함수의 오차를 최소화하는 방향으로 가중치와 편향을 업데이트한다. 상술하였듯이, 손실함수란 가중치의 학습을 위해 실제값과 예측값의 차이(오차)를 수치화 해 주는 함수이다. 오차가 클수록 손실함수의 값이 크며, 손실 함수의 값을 최소화는 가중치와 편향을 찾아 가는 것이 학습 과정이 라 할 수 있다. 최적의 가중치와 편향을 찾기 위한 최적화 기법의 하나인 경사 하강법은 가중치와 편향 등 매개변수에 대한 손 실함수의 기울기를 구한 후 기울기가 낮은 방향으로 매개변수를 계속 이동시키는 과정을 최소값에 이를 때까지 반복하는 방법이다. 경사 하강법은 입력 데이터 전체를 대상으로 수행되므로 긴 처리 시간이 요구된다. 확률적 경사 하강법(Stochastic Gradient Descent; SGD)은 매개변수 값을 조정할 때 전체 데이터가 아닌 랜덤으 로 선택한 하나의 데이터에 대해서만 계산하여 계산 속도를 향상시키는 방법이다. 경사 하강법과 같이 전체 데이터를 대상으로 하거나, 확률적 경사 하강법과 같이 하나의 데이터를 대상으로 하 지 않고, 정해진 일정 양의 데이터에 대해서 계산하여 매개 변수의 값을 조정하는 것을 미니 배치(Mini-Batch) 확률적 경사 하강법(mSGD)이라고 한다. 미니 배치 확률적 경사 하강법(mSGD)은 경사 하강법(GD)보다 계산 속도 가 빠르고, 확률적 경사 하강법(SGD)보다 안정적인 장점이 있다. 도 3은 일 실시예에 의한 신경망 모델의 학습 사이클을 설명하기 위한 도면이다. 신경망 모델이 순전파 과정(FP) 및 역전파 과정(BP)을 통해 학습 데이터 전체를 한 번 학습하는 사이클을 \"1-에 폭(epoch)'이라 한다. 따라서 1-에폭을 통해 가중치는 한 번 업데이트될 수 있다. 신경망 처리 장치의 속도 등의 한계로 한 번의 에폭에서 전체 학습 데이터(T)를 한번에 입력하게 되면 높은 성 능의 시스템이 요구되고, 시스템 부하가 가중되므로, 학습 데이터(T)를 복수의 이터레이션(iteration, I)으로 나누어 입력할 수 있다. 배치(batch) 또는 미니 배치란 한 번의 이터레이션(I)에 입력되는 데이터의 집합을 의 미하고, 하나의 배치에 포함된 데이터의 양을 배치 크기(B)라 한다. 따라서, 1-에폭은 배치 크기(B)에 따라 분할된 개수(T/B=I)의 미니 배치들을 복수의 이터레이션(I)을 통해 모두 학습하기까지의 과정이라 할 수 있다. 즉, 전체 학습 데이터(T)를 설정된 배치 크기(B)로 분할하여 복수개(I)의 미니 배치를 구성하고, 미니 배치 각 각에 대한 학습 이터레이션을 통해 손실함수의 기울기를 산출하고, 각 이터레이션에서 산출된 기울기를 통합하 는 에폭 과정을 설정될 횟수(학습률) 반복하여 신경망 모델을 생성할 수 있다. 시스템의 성능, 요구되는 정확도, 속도 등에 따라 배치 크기(B), 에폭 반복 횟수 등을 결정할 수 있음은 물론이 다. 도 4 및 도 ５는 일 실시예에 의한 분산 신경망 학습 시스템의 개념도이다. 학습 또는 추론할 데이터가 방대해짐에 따라 하나의 신경망 처리 장치(컴퓨터, 서버, 가속기 등)에서 학습이 곤 란할 수 있다. 따라서 전체 학습 데이터를 분할한 복수의 데이터 셋(미니 배치)을 복수의 신경망 처리 장치에 서 병렬로 학습하고 학습 결과를 통합할 수 있는 분산 신경망을 위한 데이터 처리 시스템이 도입되었다. 도 4를 참조하면, 일 실시예에 의한 데이터 처리 시스템(20-1)은 적어도 하나의 마스터 프로세서 및 복수 의 슬레이브 프로세서(2031~203N)를 포함할 수 있다. 복수의 슬레이브 프로세서(2031~203N) 각각은 미니 배치를 입력받아 미니 배치에 포함된 입력 데이터 각각에 대 한 학습 과정을 병렬로 수행할 수 있다. 즉, 전체 학습 데이터를 N개의 미니 배치로 분할함에 따라, 1-에폭을 구성하는 미니 배치별 학습 이터레이션이 별도의 프로세서(2031~203N)에서 병렬로 처리될 수 있다. 각 학습 이터레이션에서, 슬레이브 프로세서(2031~203N) 각각은 입력 데이터에 가중치와 편향을 적용하여 예측 값을 출력하고, 예측값과 실제값 간의 오차가 최소화되도록 손실함수의 기울기 방향으로 가중치와 편향을 수정 할 수 있다. 매 에폭마다 슬레이브 프로세서(2031~203N) 각각에서 계산된 학습 이터레이션별 가중치 및 편향은 통합되어, 매 에폭 완료 후 각 슬레이브 프로세서(2031~203N)는 동일한 가중치 및 편향을 갖게 된다. 그리고, 이러한 에폭을 정정된 횟수 반복하면서 가중치와 편향을 업데이트하여 결과적인 신경망 모델이 생성될 수 있다. 특히, 도 4에 도시한 데이터 처리 시스템(20-1)에서, 슬레이브 프로세서(2031~203N)의 각 훈련 이터레이션에서 계산된 손실함수의 기울기는 마스터 프로세서에서 공유 및 축소(Reduce)(예를 들어 평균화)된 후, 슬레이 브 프로세서(2031~203N)로 배포될 수 있다. 일 실시예에서, 도 4의 데이터 처리 시스템(20-1)은 마스터 프로세서 또한 미니 배치를 입력받아 슬레이브 프로세서(2031~203N)와 함께 학습 과정을 함께 수행할 수 있다. 도 5를 참조하면, 일 실시예에 의한 데이터 처리 시스템(20-2)은 마스터 또는 슬레이브로 구분되지 않는 복수의 프로세서(2051~205N)를 포함할 수 있다. 도 5의 각 프로세서(2051~205N) 각각은 미니 배치를 입력받아 미니 배치에 포함된 입력 데이터 각각에 대한 학 습 이터레이션을 병렬로 수행할 수 있다. 각 프로세서(2051~205N)의 학습 이터레이션의 결과로 도출되는 손실 함수의 기울기는 프로세서(2051~205N) 간에 공유될 수 있다. 손실함수의 기울기가 프로세서(2051~205N) 간에 공유되면 이를 각각 축소하여 결과적으로 모든 프로세서 (2051~205N)가 동일한 가중치 및 편향으로 다음 에폭을 수행하여 가중치 및 편향을 업데이트하면서 신경망 모델 을 생성하게 된다. 도 4 및 도 5에 도시한 복수의 프로세서들은 버스를 통해 상호 접속되거나, 이더넷(Ethernet), 파이버 채널 (Fiber channel) 또는 인피니밴드(InfiniBand)와 같은 패브릭 네트워크를 통해 접속될 수 있다. 이들 프로세서 는 신경망 연산을 위해 특화된 신경망 전용 하드웨어 가속기로 구현될 수 있다.도 6은 일 실시예에 의한 가속기의 구성도이다. 도 6을 참조하면, 일 실시예에 의한 가속기는 프로세서, 인터페이스 회로, ROM, RAM, 통합 버퍼, 정밀도 조정부 및 연산 회로를 포함할 수 있다. 프로세서는 연산 회로, 통합 버퍼, 정밀도 조정부제어하여 호스트 장치(미도시)로부터 처 리 요청된 신경망 어플리케이션의 프로그램 코드가 실행되도록 할 수 있다. 인터페이스 회로는 가속기가 다른 가속기 또는, 가속기가 마운트된 시스템 상의 입출력 회로, 시스템 메모리 등과 통신할 수 있는 환경을 제공한다. 인터페이스회로는 PCI(peripheral component interconnection), PCI-E(PCI Express)와 같은 시스템 버스 인터페이스 회로이거나, 패브릭 인터페이스 회로일 수 있으나, 이에 한정되지 않는다. ROM은 가속기의 동작에 필요한 프로그램 코드가 저장되고, 프로그램 코드들이 이용하는 코드 데이터 등이 저장될 수 있다. RAM은 가속기의 동작에 필요한 데이터 또는 가속기에 의해 생성된 데이터를 저장할 수 있다. 통합 버퍼에는 입출력 데이터, 매개변수의 초기값, 에폭 반복 횟수 등의 하이퍼 파라미터, 연산 회로(12 0)에서 출력된 연산의 중간 결과 등이 저장될 수 있다. 연산 회로는 메모리 근접 연산(Process Near Memory; PNM), 또는 메모리 내 연산(Process In Memory; PIM)을 수행하며, 복수의 처리요소(Process Element; PE)를 포함하도록 구성될 수 있다. 연산 회로는 인터페이스회로를 통해 입력된 데이터, 가중치, 파라미터에 기초하여 신경망 연산, 예를 들어 행렬 곱(matrix multiply), 누산(accumulator), 정규화(normalize), 풀링(pool) 등의 연산을 수행할 수 있다. 연산 회로의 중간 연산 결과는 통합 버퍼에 저장될 수 있고, 최종 연산 결과는 인터페이스 회 로를 통해 출력될 수 있다. 일 실시예에서, 연산 회로는 기 설정된 정밀도(precision)으로 연산을 수행할 수 있다. 연산의 정밀도는 신경망 모델 생성을 위해 계산되는 연산 결과를 표현하는 데이터 타입에 따라 결정될 수 있다. 도 7은 데이터 타입에 따른 연산 정밀도를 설명하기 위한 도면이다. 도 7을 참조하면, 데이터 타입은 [표 1]과 같이 정밀도가 높은 순서로 FP32, FP16, BF16, FP8 등으로 구분될 수 있다. 표 1 데이터 타입 부호(S) 비트 수 지수(EXP) 비트 수 가수(Fraction) 비트 수 FP32 1 8 23 FP16 1 5 10 BF16 1 8 7 FP8 1 4 3 FP32 데이터 타입은 부호(S) 표현에 1비트, 지수(EXP) 표현에 8비트, 가수(Fraction) 표현에 23비트를 사용하는 32비트 정밀도(단정밀도)의 데이터 타입을 나타낸다. F16 데이터 타입은 부호(S) 표현에 1비트, 지수(EXP) 표현에 5비트, 가수(Fraction) 표현에 10비트를 사용하는 16비트 정밀도(반정밀도)의 데이터 타입을 나타낸다. BF16 데이터 타입은 부호(S) 표현에 1비트, 지수(EXP) 표현에 8비트, 가수(Fraction) 표현에 7비트를 사용하는 16비트 정밀도의 데이터 타입을 나타낸다. F8 데이터 타입은 부호(S) 표현에 1비트, 지수(EXP) 표현에 4비트, 가수(Fraction) 표현에 3비트를 사용하는 8 비트 정밀도 데이터 타입을 나타낸다. 정밀도가 높을수록 연산 결과를 정확하게 표현할 수 있다. 복수의 가속기 간에 기울기를 공유하면서 분산 연산 을 수행할 때, 높은 정확도의 데이터가 송수신되는 경우 데이터 이동량이 많아 처리 속도가 저하될 수 있다. 연산 회로에서 계산하는 기울기의 정밀도는 초기값, 예를 들어 FP32로 결정되어 있으며, 본 기술에 의한 가속기는 학습 진행 상태에 따라 가속기 간에 이동되는 손실함수 기울기의 정밀도를 조정할 수 있는 정밀도 조정부를 포함할 수 있다. 일 실시예에서, 정밀도 조정부는 이전 단계의 학습 이터레이션에서 산출된 입력 데이터별 손실함수의 기울 기에 대한 분산을 산출하고, 분산값과 기 설정된 적어도 하나의 기준값에 기초하여 정밀도를 결정할 수 있다. [표 2]는 분산에 기초하여 정밀도를 결정하는 일 예를 나타낸다. [표 2]에서 각 기준값은 TH0>TH1>TH2의 관계를 갖는다. 표 2 정밀도 분산(VAR)과 기준값(TH)과의 관계 FP8 VAR>TH0 BF16 TH0>VAR>TH1 FP16 TH1>VAR>TH2 FP32 TH2>VAR 학습의 초기에 입력 데이터들에 대한 기울기의 분산은 상대적으로 큰 값을 가지며, 에폭이 반복될수록 입력 데 이터별 기울기의 분산은 세밀해진다. 따라서, 분산이 큰 학습 초기에는 복수의 가속기들이 낮은 정밀도로 기울기 값을 공유하여 데이터 이동량을 줄 임은 물론 데이터 이동 속도를 높인다. 그리고, 학습이 반복됨에 따라 높은 정밀도로 기울기 값을 공유하여 최적의 가중치와 편향을 찾아낼 수 있도록 한다. 일 실시예에서, 정밀도 조정부는 에폭 반복 횟수에 기초하여 정밀도를 조정하도록 구성될 수 있다. [표 3]은 총 에폭 반복 횟수(T_EPO)에 대한 에폭 수행 횟수(EPO_CNT)에 기초하여 정밀도를 선택하는 일 예를 나타낸 다. 표 3 정밀도 에폭 수행 횟수(EPO_CNT) FP8 EPO_CNT<[(1/4)*T_EPO] BF16 [(1/4)*T_EPO]<EPO_CNT<[(2/4)*T_EPO] FP16 [(2/4)*T_EPO]<EPO_CNT<[(3/4)*T_EPO] FP32 EPO_CNT>[(3/4)*T_EPO] 따라서, 각 가속기에서 계산한 손실함수의 기울기 간의 차이가 큰 학습 초기에는 낮은 정밀도로 데이터를 이동 시켜 연산 속도를 향상시키고, 학습 후반으로 갈수록 고 정밀도로 데이터를 이동시켜 연산의 정확도를 향상시킬 수 있다. 일 실시예에서, 정밀도 조정부는 손실함수의 기울기와 에폭 수행 횟수를 모두 고려하여 절밀도를 조정할 수 있다. 아울러, 매 에폭 과정에서 조정된 정밀도의 기울기가 수신되면, 정밀도 조정부는 연산 회로에 초기값 으로 설정된 정밀도로 데이터 타입을 변환하여 연산 회로로 제공할 수 있다. 도 7은 일 실시예에 의한 정밀도 조정부의 구성도이다. 도 7을 참조하면, 일 실시예에 의한 정밀도 조정부는 분산 산출부, 정밀도 선택부, 카운터 및 데이터 변환부를 포함할 수 있다. 매 에폭의 각 학습 이터레이션을 위해 미니 배치가 입력되어, 미니 배치에 포함된 입력 데이터 각각에 대한 손 실함수의 기울기(GRAD)가 산출된다. 분산 산출부는 각 입력 데이터의 기울기(GRAD)로부터 분산(VAR)을 산출하여 정밀도 선택부로 제공 할 수 있다.정해진 횟수의 에폭이 반복될 때마다, 카운터는 에폭 반복 신호(EPO)를 수신하여 에폭 수행 횟수 (EPO_CNT)를 카운트하여 정밀도 선택부로 제공할 수 있다. 정밀도 선택부는 분산(VAR) 및 에폭 수행 횟수(EPO_CNT)의 적어도 하나에 기초하여 정밀도 선택 신호 (PREC)를 출력할 수 있다. 데이터 변환부는 정밀도 선택 신호(PREC)에 응답하여, 다른 가속기로 전송할 기울기(GRAD)의 데이터 타입 을 변환하여 변환된 기울기 데이터(GRAD_PREC)를 출력할 수 있다. 아울러, 다른 가속기로부터 정밀도가 조정된 기울기(GRAD_PREC) 데이터를 전송받아 연산 회로에 초기값으로 설정된 데이터 타입을 갖는 기울기(GRAD) 데이터로 변환할 수 있다. 이와 같이, 학습 진행 상태에 따라 분산된 가속기 또는 프로세서 간에 이동되는 데이터의 양이 조절되어, 데이 터 전송 오버헤드로 인한 속도 저하 및 병목 현상을 방지할 수 있다. 도 8 내지 도 10은 실시예들에 의한 적층형 반도체 장치의 구성도이다. 도 8은 일 실시예에 의한 적층형 반도체 장치의 구성도이다. 일 실시예에 의한 적층형 반도체 장치는 복수의 다이가 적층된 적층 구조체를 포함할 수 있다. 적층 구조체는 복수의 다이를 적층하고, 관통 전극(TSV, Through Silicon Via)을 통해 전기적으로 연결시킴으로 써 입/출력 유닛의 수를 늘려 대역폭(Bandwidth)을 증가시킨 HBM(High Bandwidth Memory) 형태로 구성될 수 있 다. 적층 구조체는 베이스 다이(Base Die) 및 복수의 코어 다이(Core Die)를 포함할 수 있다. 복수의 코어 다이는 베이스 다이 상에 적층될 수 있으며, 관통 전극(TSV)을 통해 서로 연결될 수 있 다. 코어 다이 각각에는 데이터를 저장하기 위한 메모리 셀들 및 메모리 셀의 코어 동작을 위한 회로들이 배치될 수 있다. 코어 다이는 관통전극(TSV)을 통해 베이스 다이와 전기적으로 접속되어, 관통전극(TSV)을 통해 베이 스 다이로부터 신호 및 전원 등을 제공받을 수 있다. 베이스 다이는 예를 들어 도 6에 도시한 것과 같은 가속기를 포함할 수 있다. 베이스 다이는 적층형 반도체 장치 내의 다양한 기능, 예를 들어, 메모리 셀들의 부분적 활성화를 통한 전력 관리 기능 혹 은 코어 다이와 베이스 다이 간의 타이밍조절 기능들을 수행할 수 있다. 베이스 다이에 구비되는 물리 영역(PHY)은 어드레스, 명령어, 데이터, 제어신호 등의 입출력 영역일 수 있 다. 물리 영역(PHY)에는 적층형 반도체 장치에 요구되는 데이터 처리 속도를 만족시킬 수 있는 수만큼의 입출력 회로부가 구비될 수 있다. 그리고 베이스 다이의 배면 중 물리 영역(PHY) 부분에는 입출력 동작시 필요한 신호 및 전원을 공급받을 수 있도록 복수의 입출력 단자와 전원공급 단자가 구비될 수 있다. 도 9는 일 실시예에 의한 적층형 반도체 장치의 구성도이다. 도 9를 참조하면, 적층형 반도체 장치는 복수의 코어 다이와 베이스 다이의 적층 구조체, 메모리 호스트 및 인터페이스 기판을 포함할 수 있다. 호스트는 CPU, 또는 GPU, 또는 ASIC(Application Specific Integrated Circuit), 또는 FPGA(Field Programmable Gate Arrays) 등이 될 수 있 다. 베이스 다이는 코어 다이와 호스트 간의 인터페이스를 위한 회로가 실장될 수 있다. 적층 구조 체는 도 8을 참조하여 설명한 것과 유사한 구조를 가질 수 있다. 적층 구조체와 호스트는 인터페이스 기판을 통해 각각의 물리 영역(PHY)이 연결될 수 있다. 인 터페이스 기판은 인터포저(Interposer)가 지칭될 수 있다. 도 10은 일 실시예에 의한 적층형 반도체 장치의 구성도이다. 도 10에 도시한 적층형 반도체 장치는 도 9에 도시한 적층형 반도체 장치를 패키지 기판 상에 배치한 것으로 이해할 수 있다. 패키지 기판과 인터페이스 기판은 접속단자를 통해 전기적으로 접속될 수 있다. 인터페이스 기판 상에 도 8에 도시한 것과 같은 적층 구조체 및 호스트를 적층하고, 이를 패키 지 기판에 장착한 후 패키징함으로써 시스템 인 패키지(System In Package; SiP) 타입의 반도체 장치를 구 현할 수 있다. 도 11은 일 실시예에 의한 네트워크 시스템의 구성도이다. 도 11을 참조하면, 네트워크 시스템은 네트워크를 통해서 연결된 서버 시스템 및 복수의 클 라이언트 시스템들(5410~5430)을 포함할 수 있다. 서버 시스템은 복수의 클라이언트 시스템들(5410~5430)의 요청에 응답하여 데이터를 서비스할 수 있다. 예를 들면, 서버 시스템은 복수의 클라이언트 시스템들(5410~5430)로부터 제공된 데이터를 저장할 수 있 다. 다른 예로서, 서버 시스템은 복수의 클라이언트 시스템들(5410~5430)로 데이터를 제공할 수 있다. 서버 시스템은 호스트 장치 및 메모리 시스템을 포함할 수 있다. 메모리 시스템은 도 6에 도시한 가속기를 포함할 수 있다."}
{"patent_id": "10-2020-0115911", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이와 같이, 본 발명이 속하는 기술분야의 당업자는 본 발명이 그 기술적 사상이나 필수적 특징을 변경하지 않고 서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들 은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범위는 상기 상세 한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 등가개 념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2020-0115911", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a 및 도 1b는 일 실시예에 의한 인공 신경망의 데이터 처리 개념을 설명하기 위한 도면이다. 도 2는 일 실시예에 의한 학습 과정을 설명하기 위한 도면이다. 도 3은 일 실시예에 의한 신경망 모델의 학습 사이클을 설명하기 위한 도면이다. 도 4 및 도 ５는 일 실시예에 의한 분산 신경망 학습 시스템의 개념도이다. 도 6은 일 실시예에 의한 가속기의 구성도이다. 도 7은 일 실시예에 의한 정밀도 조정부의 구성도이다. 도 8 내지 도 10은 실시예들에 의한 적층형 반도체 장치의 구성도이다. 도 11은 일 실시예에 의한 네트워크 시스템의 구성도이다."}
