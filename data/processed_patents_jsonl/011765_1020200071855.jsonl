{"patent_id": "10-2020-0071855", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0086420", "출원번호": "10-2020-0071855", "발명의 명칭": "신경망 데이터 처리 장치, 방법 및 전자 장비", "출원인": "베이징 바이두 넷컴 사이언스 앤 테크놀로지 코.,", "발명자": "리 하오양"}}
{"patent_id": "10-2020-0071855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "DMA(직접 메모리 접속, Direct Memory Access) 태스크를 신경망 운반 데이터 중의 데이터 서브 블록과 하나씩대응하는 다수의 서브 태스크로 분할하고, 각각의 서브 태스크에 대응하는 데이터 서브 블록의 설정 정보를 획득하기 위한 명령 파싱 모듈;상기 설정 정보를 토대로, 상기 다수의 서브 태스크에 대응하는 데이터 서브 블록 중의 데이터 서브 블록인 제1데이터 서브 블록을 판독하기 위한 데이터 판독 모듈;상기 제1 데이터 서브 블록을 압축하기 위한 데이터 처리 모듈; 및상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 얻은 압축 데이터를 출력하기 위한 데이터 쓰기 모듈을포함하는 것을 특징으로 하는 신경망 데이터 처리 장치."}
{"patent_id": "10-2020-0071855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 데이터 처리 모듈은 또한 상기 제1 데이터 서브 블록에 대해 데이터 처리를 진행하기 위한 것임을 특징으로 하는 신경망 데이터 처리 장치."}
{"patent_id": "10-2020-0071855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 데이터 처리 모듈은,상기 제1 데이터 서브 블록을 캐싱하기 위한 원시 데이터 캐시;상기 제1 데이터 서브 블록을 압축하여, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 압축 데이터를얻기 위한 압축 알고리즘 모듈;상기 압축 데이터의 길이를 캐싱하기 위한 길이 필드 캐시;상기 제1 데이터 서브 블록의 길이와 상기 압축 데이터의 길이를 토대로 상기 제1 데이터 서브 블록에 압축 이득이 존재하는 것으로 판단하면 제1 스트로브 신호(strobe signal)를 발생시키고, 상기 제1 데이터 서브 블록의길이와 상기 압축 데이터의 길이를 토대로 상기 제1 데이터 서브 블록에 압축 이득이 존재하지 않는 것으로 판단하면 제2 스트로브 신호를 발생시키며, 상기 길이 캐시가 적중되지 않으면 제3 스트로브 신호를 발생시키기위한 압축 제어 상태 머신; 및상기 제1 스트로브 신호를 토대로 상기 압축 알고리즘 모듈로부터 상기 압축 신호를 판독하거나, 또는 상기 제2스트로브 신호를 토대로 상기 원시 데이터 캐시로부터 상기 제1 데이터 서브 블록을 판독하거나, 또는 상기 제3스트로브 신호를 토대로 상기 길이 필드 캐시로부터 상기 길이를 판독하기 위한 멀티 플렉서를 포함하는 것을특징으로 하는 신경망 데이터 처리 장치."}
{"patent_id": "10-2020-0071855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 설정 정보는 상기 제1 데이터 서브 블록의 어드레스 정보, 길이와 서브 블록 유형을 포함하고, 상기 데이터 판독 모듈은,상기 제1 데이터 서브 블록의 설정 정보를 토대로 상기 제1 데이터 서브 블록을 판독하고, 상기 판독한 제1 데이터 서브 블록에 대해 시프트 및 첨접(splice) 처리를 진행하여 상기 제1 데이터 서브 블록의 연속적이고 완전한 데이터 스트림을 얻기 위한 데이터 첨접 모듈을 포함하는 것을 특징으로 하는 신경망 데이터 처리 장치.공개특허 10-2021-0086420-3-청구항 5 제4항에 있어서,상기 데이터 판독 모듈은,상기 설정 정보를 판독하고, 상기 데이터 첨접 모듈에 판독 명령 요청을 송신하기 위한 데이터 출력 명령 캐시;상기 데이터 첨접 모듈이 출력한 상기 연속적이고 완전한 데이터 스트림을 캐싱하기 위한 데이터 캐시; 및상기 데이터 캐시 중의 상기 연속적이고 완전한 데이터 스트림을 패키징하고, 패키징된 데이터를 상기 데이터처리 모듈에 출력하기 위한 데이터 출력 상태 머신을 더 포함하는 것을 특징으로 하는 신경망 데이터 처리장치."}
{"patent_id": "10-2020-0071855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 데이터 판독 모듈은,상기 제1 데이터 서브 블록의 어드레스 정보를 판독하기 위한 판독 명령 캐시; 및상기 판독 명령 캐시로부터 명령을 획득하고, 상기 어드레스 정보를 토대로 내부 캐시의 판독에 필요한 인터페이스 신호를 생성하기 위한 데이터 판독 상태 머신을 더 포함하는 것을 특징으로 하는 신경망 데이터 처리장치."}
{"patent_id": "10-2020-0071855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 데이터 쓰기 모듈은,상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 얻은 압축 데이터를 캐싱하기 위한 데이터 출력 캐시;상기 제1 데이터 서브 블록의 설정 정보를 캐싱하기 위한 설정 정보 캐시;상기 제1 데이터 서브 블록의 목적 어드레스를 캐싱하기 위한 출력 어드레스 캐시; 및상기 설정 정보와 상기 목적 어드레스를 토대로, 상기 제1 데이터 서브 블록의 데이터 마스크 코드(mask code)를 생성하고, 상기 제1 데이터 서브 블록에 대응하는 인터페이스 시간 시퀀스를 발생시키기 위한 인터페이스 시간 시퀀스 생성 모듈을 포함하는 것을 특징으로 하는 신경망 데이터 처리 장치."}
{"patent_id": "10-2020-0071855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 신경망 데이터 처리 장치는,상기 제1 데이터 서브 블록의 목적 어드레스와 상기 압축 데이터의 길이를 토대로, 상기 제1 데이터 서브 블록의 버스 프로토콜이 지원하는 어드레스 채널 신호를 생성하고 상기 어드레스 채널 신호를 출력하기 위한 어드레스 생성 모듈을 더 포함하는 것을 특징으로 하는 신경망 데이터 처리 장치."}
{"patent_id": "10-2020-0071855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 따른 신경망 데이터 처리 장치를 포함하는 것을 특징으로 하는 전자 장비."}
{"patent_id": "10-2020-0071855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "DMA 태스크를 신경망 운반 데이터 중의 데이터 서브 블록과 하나씩 대응하는 다수의 서브 태스크로 분할하고,각각의 서브 태스크에 대응하는 데이터 서브 블록의 설정 정보를 획득하는 단계;상기 설정 정보를 토대로, 상기 다수의 서브 태스크에 대응하는 데이터 서브 블록 중의 데이터 서브 블록인 제1데이터 서브 블록을 판독하는 단계; 및상기 제1 데이터 서브 블록을 압축하고, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 얻은 압축 데이공개특허 10-2021-0086420-4-터를 출력하는 단계를 포함하는 것을 특징으로 하는 신경망 데이터 처리 방법."}
{"patent_id": "10-2020-0071855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상술한 상기 제1 데이터 서브 블록을 압축하고, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 얻은 압축 데이터를 출력하는 단계는,상기 제1 데이터 서브 블록과 상기 제1 데이터 서브 블록 데이터의 길이를 캐싱하는 단계;상기 제1 데이터 서브 블록을 압축하여, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 압축 데이터를얻고, 상기 압축 데이터의 길이를 기록하는 단계; 및상기 제1 데이터 서브 블록의 길이와 상기 압축 데이터의 길이를 토대로, 상기 제1 데이터 서브 블록에 압축 이득이 존재하는지를 판단하고, 압축 이득이 존재하면 상기 압축 데이터를 출력하고, 압축 이득이 존재하지 않으면 상기 제1 데이터 서브 블록 데이터를 출력하는 단계를 포함하는 것을 특징으로 하는 신경망 데이터 처리 방법."}
{"patent_id": "10-2020-0071855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 설정 정보는 상기 제1 데이터 서브 블록의 어드레스 정보를 포함하고, 상술한 상기 설정 정보를 토대로 제1 데이터 서브 블록을 판독하는 단계는,상기 제1 데이터 서브 블록의 어드레스 정보를 토대로, 상기 제1 데이터 서브 블록을 판독하고, 상기 판독한 제1 데이터 서브 블록에 대해 시프트 및 첨접 처리를 진행하여 상기 제1 데이터 서브 블록의 연속적이고 완전한데이터 스트림을 얻는 단계를 포함하는 것을 특징으로 하는 신경망 데이터 처리 방법."}
{"patent_id": "10-2020-0071855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서,상기 신경망 데이터 처리 방법은,상기 압축 데이터의 길이를 캐싱하는 단계; 및상기 제1 데이터 서브 블록의 목적 어드레스와 상기 압축 데이터의 길이를 토대로, 상기 제1 데이터 서브 블록의 버스 프로토콜이 지원하는 어드레스 채널 신호를 생성하고 상기 어드레스 채널 신호를 출력하는 단계를 더포함하는 것을 특징으로 하는 신경망 데이터 처리 방법."}
{"patent_id": "10-2020-0071855", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 신경망 데이터 처리 장치, 방법과 전자 장비를 개시하며, 인공 지능 칩"}
{"patent_id": "10-2020-0071855", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것이다. 구 체적인 구현 형태는, DMA 태스크를 신경망 운반 데이터 중의 데이터 서브 블록과 하나씩 대응하는 다수의 서브 태스크로 분할하고, 각각의 서브 태스크에 대응하는 데이터 서브 블록의 설정 정보를 획득하기 위한 명령 파싱 모듈; 다수의 서브 태스크에 대응하는 데이터 서브 블록들 중의 데이터 서브 블록인 제1 데이터 서브 블록을 설 정 정보를 토대로 판독하기 위한 데이터 판독 모듈; 제1 데이터 서브 블록을 압축하기 위한 데이터 처리 모듈; 및 제1 데이터 서브 블록에 대해 압축을 진행하여 얻은 압축 데이터를 출력하기 위한 데이터 쓰기 모듈을 포함한 다. 대 표 도 - 도1"}
{"patent_id": "10-2020-0071855", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2021-0086420 CPC특허분류 G06F 9/3004 (2013.01) G06F 9/4843 (2013.01)명 세 서 청구범위 청구항 1 DMA(직접 메모리 접속, Direct Memory Access) 태스크를 신경망 운반 데이터 중의 데이터 서브 블록과 하나씩 대응하는 다수의 서브 태스크로 분할하고, 각각의 서브 태스크에 대응하는 데이터 서브 블록의 설정 정보를 획 득하기 위한 명령 파싱 모듈; 상기 설정 정보를 토대로, 상기 다수의 서브 태스크에 대응하는 데이터 서브 블록 중의 데이터 서브 블록인 제1 데이터 서브 블록을 판독하기 위한 데이터 판독 모듈; 상기 제1 데이터 서브 블록을 압축하기 위한 데이터 처리 모듈; 및 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 얻은 압축 데이터를 출력하기 위한 데이터 쓰기 모듈을 포함하는 것을 특징으로 하는 신경망 데이터 처리 장치. 청구항 2 제1항에 있어서, 상기 데이터 처리 모듈은 또한 상기 제1 데이터 서브 블록에 대해 데이터 처리를 진행하기 위한 것임을 특징으 로 하는 신경망 데이터 처리 장치. 청구항 3 제1항에 있어서, 상기 데이터 처리 모듈은, 상기 제1 데이터 서브 블록을 캐싱하기 위한 원시 데이터 캐시; 상기 제1 데이터 서브 블록을 압축하여, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 압축 데이터를 얻기 위한 압축 알고리즘 모듈; 상기 압축 데이터의 길이를 캐싱하기 위한 길이 필드 캐시; 상기 제1 데이터 서브 블록의 길이와 상기 압축 데이터의 길이를 토대로 상기 제1 데이터 서브 블록에 압축 이 득이 존재하는 것으로 판단하면 제1 스트로브 신호(strobe signal)를 발생시키고, 상기 제1 데이터 서브 블록의 길이와 상기 압축 데이터의 길이를 토대로 상기 제1 데이터 서브 블록에 압축 이득이 존재하지 않는 것으로 판 단하면 제2 스트로브 신호를 발생시키며, 상기 길이 캐시가 적중되지 않으면 제3 스트로브 신호를 발생시키기 위한 압축 제어 상태 머신; 및 상기 제1 스트로브 신호를 토대로 상기 압축 알고리즘 모듈로부터 상기 압축 신호를 판독하거나, 또는 상기 제2 스트로브 신호를 토대로 상기 원시 데이터 캐시로부터 상기 제1 데이터 서브 블록을 판독하거나, 또는 상기 제3 스트로브 신호를 토대로 상기 길이 필드 캐시로부터 상기 길이를 판독하기 위한 멀티 플렉서를 포함하는 것을 특징으로 하는 신경망 데이터 처리 장치. 청구항 4 제1항에 있어서, 상기 설정 정보는 상기 제1 데이터 서브 블록의 어드레스 정보, 길이와 서브 블록 유형을 포함하고, 상기 데이 터 판독 모듈은, 상기 제1 데이터 서브 블록의 설정 정보를 토대로 상기 제1 데이터 서브 블록을 판독하고, 상기 판독한 제1 데 이터 서브 블록에 대해 시프트 및 첨접(splice) 처리를 진행하여 상기 제1 데이터 서브 블록의 연속적이고 완전 한 데이터 스트림을 얻기 위한 데이터 첨접 모듈을 포함하는 것을 특징으로 하는 신경망 데이터 처리 장치.청구항 5 제4항에 있어서, 상기 데이터 판독 모듈은, 상기 설정 정보를 판독하고, 상기 데이터 첨접 모듈에 판독 명령 요청을 송신하기 위한 데이터 출력 명령 캐시; 상기 데이터 첨접 모듈이 출력한 상기 연속적이고 완전한 데이터 스트림을 캐싱하기 위한 데이터 캐시; 및 상기 데이터 캐시 중의 상기 연속적이고 완전한 데이터 스트림을 패키징하고, 패키징된 데이터를 상기 데이터 처리 모듈에 출력하기 위한 데이터 출력 상태 머신을 더 포함하는 것을 특징으로 하는 신경망 데이터 처리 장치. 청구항 6 제5항에 있어서, 상기 데이터 판독 모듈은, 상기 제1 데이터 서브 블록의 어드레스 정보를 판독하기 위한 판독 명령 캐시; 및 상기 판독 명령 캐시로부터 명령을 획득하고, 상기 어드레스 정보를 토대로 내부 캐시의 판독에 필요한 인터페 이스 신호를 생성하기 위한 데이터 판독 상태 머신을 더 포함하는 것을 특징으로 하는 신경망 데이터 처리 장치. 청구항 7 제1항에 있어서, 상기 데이터 쓰기 모듈은, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 얻은 압축 데이터를 캐싱하기 위한 데이터 출력 캐시; 상기 제1 데이터 서브 블록의 설정 정보를 캐싱하기 위한 설정 정보 캐시; 상기 제1 데이터 서브 블록의 목적 어드레스를 캐싱하기 위한 출력 어드레스 캐시; 및 상기 설정 정보와 상기 목적 어드레스를 토대로, 상기 제1 데이터 서브 블록의 데이터 마스크 코드(mask code) 를 생성하고, 상기 제1 데이터 서브 블록에 대응하는 인터페이스 시간 시퀀스를 발생시키기 위한 인터페이스 시 간 시퀀스 생성 모듈을 포함하는 것을 특징으로 하는 신경망 데이터 처리 장치. 청구항 8 제1항에 있어서, 상기 신경망 데이터 처리 장치는, 상기 제1 데이터 서브 블록의 목적 어드레스와 상기 압축 데이터의 길이를 토대로, 상기 제1 데이터 서브 블록 의 버스 프로토콜이 지원하는 어드레스 채널 신호를 생성하고 상기 어드레스 채널 신호를 출력하기 위한 어드레 스 생성 모듈을 더 포함하는 것을 특징으로 하는 신경망 데이터 처리 장치. 청구항 9 제1항 내지 제8항 중 어느 한 항에 따른 신경망 데이터 처리 장치를 포함하는 것을 특징으로 하는 전자 장비. 청구항 10 DMA 태스크를 신경망 운반 데이터 중의 데이터 서브 블록과 하나씩 대응하는 다수의 서브 태스크로 분할하고, 각각의 서브 태스크에 대응하는 데이터 서브 블록의 설정 정보를 획득하는 단계; 상기 설정 정보를 토대로, 상기 다수의 서브 태스크에 대응하는 데이터 서브 블록 중의 데이터 서브 블록인 제1 데이터 서브 블록을 판독하는 단계; 및 상기 제1 데이터 서브 블록을 압축하고, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 얻은 압축 데이터를 출력하는 단계를 포함하는 것을 특징으로 하는 신경망 데이터 처리 방법. 청구항 11 제10항에 있어서, 상술한 상기 제1 데이터 서브 블록을 압축하고, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 얻은 압 축 데이터를 출력하는 단계는, 상기 제1 데이터 서브 블록과 상기 제1 데이터 서브 블록 데이터의 길이를 캐싱하는 단계; 상기 제1 데이터 서브 블록을 압축하여, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 압축 데이터를 얻고, 상기 압축 데이터의 길이를 기록하는 단계; 및 상기 제1 데이터 서브 블록의 길이와 상기 압축 데이터의 길이를 토대로, 상기 제1 데이터 서브 블록에 압축 이 득이 존재하는지를 판단하고, 압축 이득이 존재하면 상기 압축 데이터를 출력하고, 압축 이득이 존재하지 않으 면 상기 제1 데이터 서브 블록 데이터를 출력하는 단계를 포함하는 것을 특징으로 하는 신경망 데이터 처리 방 법. 청구항 12 제10항에 있어서, 상기 설정 정보는 상기 제1 데이터 서브 블록의 어드레스 정보를 포함하고, 상술한 상기 설정 정보를 토대로 제 1 데이터 서브 블록을 판독하는 단계는, 상기 제1 데이터 서브 블록의 어드레스 정보를 토대로, 상기 제1 데이터 서브 블록을 판독하고, 상기 판독한 제 1 데이터 서브 블록에 대해 시프트 및 첨접 처리를 진행하여 상기 제1 데이터 서브 블록의 연속적이고 완전한 데이터 스트림을 얻는 단계를 포함하는 것을 특징으로 하는 신경망 데이터 처리 방법. 청구항 13 제10항에 있어서, 상기 신경망 데이터 처리 방법은, 상기 압축 데이터의 길이를 캐싱하는 단계; 및 상기 제1 데이터 서브 블록의 목적 어드레스와 상기 압축 데이터의 길이를 토대로, 상기 제1 데이터 서브 블록 의 버스 프로토콜이 지원하는 어드레스 채널 신호를 생성하고 상기 어드레스 채널 신호를 출력하는 단계를 더 포함하는 것을 특징으로 하는 신경망 데이터 처리 방법. 발명의 설명 기 술 분 야 본 출원은 컴퓨터 기술 중 인공 지능 칩 기술 분야에 관한 것이며, 특히 신경망 데이터 처리 장치, 방법 및 전 자 장비에 관한 것이다."}
{"patent_id": "10-2020-0071855", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래의 신경망 예컨대 심층 콘볼루션 신경망(Convolutional Deep Nueral Networks, CDNN)은 음성 인식, 화상 인식, 자연 언어 처리 등과 같은 인터넷 어플리케이션에서 광범위하게 적용되고 있다. 그러나 신경망 연산은 흔 히 신경망 프로세서(Neural Processing Unit, NPU)에서 이루어지며, 신경망 연산을 수행한 후에는 연산 결과를 오프 칩 메모리에 운반한다. 오프 칩 메모리의 대역폭에 한계가 있으므로, 수많은 실제 서비스 장면에서는 온 칩 및 오프 칩 데이터의 운반 시간이 실제 연산 시간을 초과하여 신경망의 성능이 저하된다."}
{"patent_id": "10-2020-0071855", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2020-0071855", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 출원은 신경망의 성능 저하 문제를 해결하기 위한 신경망 데이터 처리 장치, 방법 및 전자 장비를 제공한다."}
{"patent_id": "10-2020-0071855", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "제1 측면에서 본 출원은 신경망 데이터 처리 장치를 제공한다. 상기 장치는, 직접 메모리 접근(Direct-Memory Access, DMA) 태스크를 신경망 운반 데이터 중의 데이터 서브 블록과 하나씩 대응하는 다수의 서브 태스크로 분할하고, 각각의 서브 태스크에 대응하는 데이터 서브 블록의 설정 정보를 획 득하기 위한 명령 파싱 모듈; 상기 다수의 서브 태스크에 대응하는 데이터 서브 블록들 중의 데이터 서브 블록인 제1 데이터 서브 블록을 상 기 설정 정보를 토대로 판독하기 위한 데이터 판독 모듈; 상기 제1 데이터 서브 블록을 압축하기 위한 데이터 처리 모듈; 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 얻은 압축 데이터를 출력하기 위한 데이터 쓰기 모듈을 포함한다. 데이터 서브 블록별로 압축하므로, 데이터 운반 효율을 향상하여 신경망의 성능을 향상할 수 있다. 선택적으로, 상기 데이터 처리 모듈은 또한 상기 제1 데이터 서브 블록에 대해 데이터 처리를 진행하기 위한 것 이다. 제1 데이터 서브 블록에 대해 데이터 처리를 진행하므로, 상기 장치의 데이터 처리 성능을 향상할 수 있다. 선택적으로, 상기 데이터 처리 모듈은, 상기 제1 데이터 서브 블록을 캐싱하기 위한 원시 데이터 캐시; 상기 제1 데이터 서브 블록을 압축하여, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 압축 데이터를 얻기 위한 압축 알고리즘 모듈; 상기 압축 데이터의 길이를 캐싱하기 위한 길이 필드 캐시; 상기 제1 데이터 서브 블록의 길이와 상기 압축 데이터의 길이를 토대로 상기 제1 데이터 서브 블록에 압축 이 득이 존재하는 것으로 판단하면 제1 스트로브 신호를 발생시키고, 상기 제1 데이터 서브 블록의 길이와 상기 압 축 데이터의 길이를 토대로 상기 제1 데이터 서브 블록에 압축 이득이 존재하지 않는 것으로 판단하면 제2 스트 로브 신호를 발생시키며, 상기 길이 캐시가 적중되지 않으면 제3 스트로브 신호를 발생시키기 위한 압축 제어 상태 머신; 상기 제1 스트로브 신호를 토대로 상기 압축 알고리즘 모듈로부터 상기 압축 신호를 판독하거나, 또는 상기 제2 스트로브 신호를 토대로 상기 원시 데이터 캐시로부터 상기 제1 데이터 서브 블록을 판독하거나, 또는 상기 제3 스트로브 신호를 토대로 상기 길이 필드 캐시로부터 상기 길이를 판독하기 위한 멀티 플렉서를 포함한다. 이 실시형태는, 상기 압축 제어 상태 머신을 통해 멀티 플렉서를 제어하여 적절한 데이터를 출력할 수 있으므로, 데이터 길이의 제어가 가능해지도록 하여, 과다한 저장 공간을 비축하는 것을 피하여 저장 공간을 절 약하는 효과를 이룰 수 있다. 선택적으로, 상기 설정 정보는 상기 제1 데이터 서브 블록의 어드레스 정보, 길이와 서브 블록 유형을 포함하고, 상기 데이터 판독 모듈은, 상기 제1 데이터 서브 블록의 설정 정보를 토대로 상기 제1 데이터 서브 블록을 판독하고, 상기 판독한 제1 데 이터 서브 블록에 대해 시프트 및 첨접 처리를 진행하여 상기 제1 데이터 서브 블록의 연속적이고 완전한 데이 터 스트림을 얻기 위한 데이터 첨접 모듈을 포함한다. 상기 판독한 제1 데이터 서브 블록에 대해 시프트 및 첨접 처리를 진행하여 상기 제1 데이터 서브 블록의 연속 적이고 완전한 데이터 스트림을 얻으므로, 비연속적인 데이터의 압축을 지원할 수 있고, 압축 처리된 데이터 서 브 블록의 크기를 향상하고, 압축 처리 효율을 향상할 수 있다. 선택적으로, 상기 데이터 판독 모듈은, 상기 설정 정보를 판독하고 상기 데이터 첨접 모듈에 판독 명령 요청을 송신하기 위한 데이터 출력 명령 캐시; 상기 데이터 첨접 모듈이 출력한 상기 연속적이고 완전한 데이터 스트림을 캐싱하기 위한 데이터 캐시; 상기 데이터 캐시 중의 상기 연속적이고 완전한 데이터 스트림을 패키징하고, 패키징된 데이터를 상기 데이터 처리 모듈에 출력하기 위한 데이터 출력 상태 머신을 더 포함한다. 상기 데이터 출력 상태 머신을 통해 데이터를 정확하고도 질서 있게 출력할 수 있다. 선택적으로, 상기 데이터 판독 모듈은, 상기 제1 데이터 서브 블록의 어드레스 정보를 판독하기 위한 판독 명령 캐시; 상기 판독 명령 캐시로부터 명령을 획득하고, 내부 캐시의 판독에 필요한 인터페이스 신호를 상기 어드레스 정 보를 토대로 생성하기 위한 데이터 판독 상태 머신을 더 포함한다. 상기 데이터 판독 상태 머신을 통해 데이터를 정확하고도 질서 있게 판독할 수 있다. 선택적으로, 상기 데이터 쓰기 모듈은, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 얻은 압축 데이터를 캐싱하기 위한 데이터 출력 캐시; 상기 제1 데이터 서브 블록의 설정 정보를 캐싱하기 위한 설정 정보 캐시; 상기 제1 데이터 서브 블록의 목적 어드레스를 캐싱하기 위한 출력 어드레스 캐시; 상기 설정 정보와 상기 목적 어드레스를 토대로, 상기 제1 데이터 서브 블록의 데이터 마스크 코드를 생성하고, 상기 제1 데이터 서브 블록에 대응하는 인터페이스 시간 시퀀스를 발생시키기 위한 인터페이스 시간 시퀀스 생 성 모듈을 포함한다. 상기 제1 데이터 서브 블록의 데이터 마스크 코드와 인터페이스 시간 시퀀스를 통해, 상기 제1 데이터 서브 블 록을 출력할 때 지정 위치로 정확하고도 질서 있게 출력되도록 할 수 있다. 선택적으로, 상기 장치는, 상기 제1 데이터 서브 블록의 목적 어드레스와 상기 압축 데이터의 길이를 토대로, 상기 제1 데이터 서브 블록 의 버스 프로토콜이 지원하는 어드레스 채널 신호를 생성하고 상기 어드레스 채널 신호를 출력하기 위한 어드레 스 생성 모듈을 더 포함한다. 상기 어드레스 채널 신호를 통해 압축 데이터의 랜덤 액세스를 지원하여 신경망의 성능을 더 향상할 수 있다. 제2 측면에서 본 출원은 본 출원에 따른 신경망 데이터 처리 장치를 포함하는 것을 특징으로 하는 전자 장비를 제공한다. 제3 측면에서 본 출원은 신경망 데이터 처리 방법을 제공한다. 상기 방법은, DMA 태스크를 신경망 운반 데이터 중의 데이터 서브 블록과 하나씩 대응하는 다수의 서브 태스크로 분할하고, 각각의 서브 태스크에 대응하는 데이터 서브 블록의 설정 정보를 획득하는 단계; 상기 다수의 서브 태스크에 대응하는 데이터 서브 블록들 중의 데이터 서브 블록인 제1 데이터 서브 블록을 상 기 설정 정보를 토대로 판독하는 단계; 상기 제1 데이터 서브 블록을 압축하고, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 얻은 압축 데이 터를 출력하는 단계를 포함한다. 데이터 서브 블록별로 압축하므로, 데이터 운반 효율을 향상하여 신경망의 성능을 향상할 수 있다. 선택적으로, 상술한 상기 제1 데이터 서브 블록을 압축하고, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로 부터 얻은 압축 데이터를 출력하는 단계는, 상기 제1 데이터 서브 블록과 상기 제1 데이터 서브 블록 데이터의 길이를 캐싱하는 단계; 상기 제1 데이터 서브 블록을 압축하여, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 압축 데이터를 얻고, 상기 압축 데이터의 길이를 기록하는 단계; 상기 제1 데이터 서브 블록의 길이와 상기 압축 데이터의 길이를 토대로, 상기 제1 데이터 서브 블록에 압축 이 득이 존재하는지를 판단하고, 압축 이득이 존재하면 상기 압축 데이터를 출력하고, 압축 이득이 존재하지 않으 면 상기 제1 데이터 서브 블록 데이터를 출력하는 단계를 포함한다. 상기 압축 데이터의 길이가 상기 제1 데이터 서브 블록 데이터의 길이보다 작은 경우에만 상기 압축 데이터를 출력하므로, 데이터 길이의 제어가 가능해지도록 하여, 과다한 저장 공간을 비축하는 것을 피하여 저장 공간을 절약하는 효과를 이룰 수 있다. 선택적으로, 상기 설정 정보는 상기 제1 데이터 서브 블록의 어드레스 정보를 포함하고, 상술한 상기 설정 정보 를 토대로 제1 데이터 서브 블록을 판독하는 단계는, 상기 제1 데이터 서브 블록의 어드레스 정보를 토대로 상기 제1 데이터 서브 블록을 판독하고, 상기 판독한 제1 데이터 서브 블록에 대해 시프트 및 첨접 처리를 진행하여 상기 제1 데이터 서브 블록의 연속적이고 완전한 데 이터 스트림을 얻는 단계를 포함한다. 상기 판독한 제1 데이터 서브 블록에 대해 시프트 및 첨접 처리를 진행하여 상기 제1 데이터 서브 블록의 연속 적이고 완전한 데이터 스트림을 얻으므로, 비연속적인 데이터의 압축을 지원할 수 있고, 압축 처리된 데이터 서 브 블록의 크기를 향상하여 압축 처리 효율을 향상할 수 있다. 선택적으로, 상기 방법은, 상기 압축 데이터의 길이를 캐싱하는 단계; 상기 제1 데이터 서브 블록의 목적 어드레스와 상기 압축 데이터의 길이를 토대로 상기 제1 데이터 서브 블록의 버스 프로토콜이 지원하는 어드레스 채널 신호를 생성하고 상기 어드레스 채널 신호를 출력하는 단계를 포함한 다. 상기 어드레스 채널 신호를 통해 압축 데이터의 랜덤 액세스를 지원하여 신경망의 성능을 더 향상할 수 있다."}
{"patent_id": "10-2020-0071855", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기 출원에 따른 일 실시예는 아래와 같은 장점 또는 유익한 효과를 가진다. 상기 출원에 따른 일 실시예는, 직접 메모리 접근 DMA 태스크를 신경망 운반 데이터 중의 데이터 서브 블록과 하나씩 대응하는 다수의 서브 태스크로 분할하고, 각각의 서브 태스크에 대응하는 데이터 서브 블록의 설정 정 보를 획득하기 위한 명령 파싱 모듈; 상기 다수의 서브 태스크에 대응하는 데이터 서브 블록들 중의 데이터 서 브 블록인 제1 데이터 서브 블록을 상기 설정 정보를 토대로 판독하기 위한 데이터 판독 모듈; 상기 제1 데이터 서브 블록을 압축하기 위한 데이터 처리 모듈; 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 얻은 압축 데이터를 출력하기 위한 데이터 쓰기 모듈을 포함한다. 따라서 신경망의 성능이 낮은 기술적 문제점을 해결하여 신경망의 성능을 향상하는 기술적 효과를 이룬다. 상기 선택적 방식이 가진 그밖의 다른 효과는 이하 구체적인 실시예를 결합하여 설명하도록 한다."}
{"patent_id": "10-2020-0071855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 결합하여 본 출원의 예시적인 실시예를 설명한다. 상기 예시적인 실시예는 이해를 돕기 위해 본 출원의 실시예의 다양한 세부 사항들을 포함하며, 이들은 예시적인 것으로만 간주해야 한다. 따라서, 본 분야의 통상의 기술자라면 본 출원의 범위 및 사상을 벗어나지 않고 여기서 설명된 실시예에 대해 다양한 변경 및 수정 이 이루어질 수 있음을 알 수 있을 것이다. 마찬가지로, 명료성과 간결성을 위해, 공지 기능과 구조에 대한 설 명은 이하 설명에서 생략한다. 도 1을 참고하면, 도 1은 본 출원에 따른 신경망 데이터 처리 장치의 구조도이다. 도 1에서와 같이, 신경망 데 이터 처리 장치는 아래 구성을 포함한다. 명령 파싱 모듈은 DMA 태스크를 신경망 운반 데이터 중의 데이터 서브 블록과 하나씩 대응하는 다수의 서 브 태스크로 분할하고, 각각의 서브 태스크에 대응하는 데이터 서브 블록의 설정 정보를 획득하기 위한 것이다. 그중, 상기 신경망 데이터 처리 장치는 신경망 연산을 위한 칩(또는 프로세서라고도 한다)이며, 예를 들어 신경망 프로세서(Neural Processing Unit, NPU) 또는 하드웨어 가속기이다. 그중, 명령 파싱 모듈은 처리 대상 명령을 수신하고 명령을 파싱하며, 수신한 DMA 태스크(예를 들어, 데이 터 운반과 처리 태스크)를 다수의 서브 태스크로 분할하기 위한 것일 수 있다. 상기 신경망 운반 데이터는 신경망 연산을 수행하여 얻은 데이터로서, 예를 들어 웨이트 매트릭스 또는 특징 맵 (feature map) 등의 데이터일 수 있다. 상기 데이터 서브 블록은 상기 운반 데이터를 분할하여 얻은 데이터 서 브 블록일 수 있다. 예를 들어 도 2에서와 같이 운반 데이터를 기본 블록, 정렬 블록과 리매핑(remaping)되지 않은 블록 이들 데이터 서브 블록으로 분할할 수 있으며, 그중, 각각의 기본 블록의 데이터 크기는 고정되며, 이 고정 크기는 미리 설정할 수 있으며 구체적으로 실제 수요에 따라 설정할 수 있다. 정렬 블록과 리매핑되지 않은 블록은 운반 데이터 블록을 다수의 기본 블록으로 분할한 후 남는, 기본 블록을 구성할 수 없는 서브 블록 이며, 구체적으로 도 2와 같을 수 있으며, 오른쪽에 남은 서브 블록을 정렬 블록이라고 하고, 아래쪽에 남은 서 브 블록을 리매핑되지 않은 블록이라고 한다. 또한, 상술한 각각의 서브 태스크에 대응하는 데이터 서브 블록의 설정 정보를 획득하는 것은, 데이터 서브 블 록의 설정 정보를 발생시키는 것일 수 있다. 또한 설정 정보는 데이터 서브 블록의 길이, 어드레스와 압축 정보 등을 포함할 수 있으며, 여기서 압축 정보는 데이터 서브 블록의 압축 여부를 표시하기 위한 것이다. 상기 서브 태스크와 신경망 운반 데이터 중의 데이터 서브 블록이 하나씩 대응한다는 것은, 각각의 서브 태스크 가 신경망 운반 데이터 중의 서브 블록에 대응하는 것일 수 있으며, 당해 데이터는 하나의 매트릭스일 수 있다. 그후, 다른 모듈을 위해 각각의 서브 블록에 대응하는 설정 정보를 생성할 수 있으며, 당해 설정 정보는 태스크 설정 정보라고 할 수 있다. 나아가, 상기 설정 정보는 다른 모듈이 하나의 서브 블록을 처리하는데 필요한 다양 한 정보, 예를 들어 데이터의 어드레스, 길이, 압축 여부 등 정보를 포함할 수 있다. 또한, 명령 파싱 모듈이 처리할 수 있는 명령은 DMA 설정 명령, DMA 수행 명령과 DMA 동기화 명령 등을 포 함할 수 있다. 그중, DMA 설정 명령은 후속 DMA 수행 명령의 파라미터를 설정하기 위한 것이고; DMA 수행 명령 은 하나의 데이터 운반 태스크의 시작을 선언하기 위한 것이며, 사용되는 파라미터는 그 직전의 DMA 설정 명령 이 설정한다. DMA 동기화 명령은 시스템의 동기화 마크이며, 당해 명령 전의 모든 명령이 수행된 후 장치가 하 나의 처리 완료 신호를 피드백함으로써 상위층 소프트웨어 및 하드웨어 시스템과의 동기화를 완료한다. 나아가, 명령 파싱 모듈은 명령을 수신한 후, 먼저 명령 유형을 판단하고, 만약 명령 유형이 DMA 설정 명 령이라면, 대응하는 내부 레지스터에 기입하고, 명령 파싱 모듈 내부에서 기록하며; 만약 명령 유형이 DMA 수행 명령이라면, 기존의 내부 레지스터의 설정에 따라 서브 블록의 태스크 설정 정보를 생성하기 시작할 수 있 다. 만약 명령 유형이 DMA 동기화 명령이라면, 하나의 중단 마크 신호를 응답 처리 모듈에 송신하며, 당해 마크 는 당해 마크의 송신 전의 전체 데이터 운반량을 기록한 것이다. 또한, 신경망 데이터 처리 장치의 캐시 기능이 활성화된 경우, 명령 파싱 모듈은 또한 서브 블록의 목표 어드레스를 토대로 캐시 적중(hit) 여부를 판단하고, 캐시 미스 시에는 캐시 리프레쉬된 설정 정보를 삽입 할 수 있다. 나아가, 명령 파싱 모듈이 명령을 처리한 후 발생한 태스크 설정 정보는 4가지 유형을 포함할 수 있으며, 이들은 각각 기본 블록 설정 정보, 정렬(alignment) 블록 설정 정보, 리매핑되지 않은 블록 설정 정보와 캐시 블록 설정 정보이다. 나아가, 명령 파싱 모듈은 또한 어드레스 재정렬 기능의 활성화 여부를 설정할 수 있으며, 어드레스 재정 렬 기능이 활성화되지 않은 경우, 명령 파싱 모듈은 데이터 전체를 리매핑되지 않은 블록으로서 처리하고, 리매핑되지 않은 블록으로서 처리할 경우, 이들 서브 블록은 압축하지 않아도 된다. 또한, 본 출원에 따른 신경망은 CDNN을 포함하나 이에 한정하지 않으며, 예를 들어 그밖의 다른 심층 신경망일 수 있다. 데이터 판독 모듈은 상기 다수의 서브 태스크에 대응하는 데이터 서브 블록들 중의 데이터 서브 블록인 제 1 데이터 서브 블록을 상기 설정 정보를 토대로 판독하기 위한 것이다. 그중, 상기 제1 데이터 서브 블록은 상기 운반 데이터 중 임의의 데이터 서브 블록일 수 있으며, 바람직하게는 제1 데이터 서브 블록은 임의의 기본 블록일 수 있다. 상술한 상기 설정 정보를 토대로 제1 데이터 서브 블록을 판독하는 것은, 내부 캐시에서 설정 정보가 표시하는 데이터 서브 블록에 대한 판독을 토대로 하는 것일 수 있다. 그중, 상기 데이터 판독 모듈은 명령 파싱 모듈로부터 설정 정보를 획득하고, 설정 정보를 토대로 제 1 데이터 서브 블록을 판독할 수 있다. 그중, 여기서 판독은 상기 장치의 내부 캐시로부터 판독하는 것일 수 있 다. 예를 들어, 데이터 판독 모듈은 명령 파싱 모듈로부터 설정 정보를 획득하고, 내부 캐시로부터의 데이터 판독 작업을 수행할 수 있다. 나아가, 판독한 데이터를 정리하고, 정리를 통해 특정의 내부 데이터 포맷 (예컨대 AXI 프로토콜, 데이터-데이터 유효 신호로 이루어진 단순 데이터 프로토콜)을 획득하여 데이터 처리 모 듈에 전송할 수 있다. 데이터 처리 모듈은 상기 제1 데이터 서브 블록을 압축하기 위한 것이다. 데이터 처리 모듈은 데이터 판독 모듈이 출력한 제1 데이터 서브 블록을 획득하고 이를 압축한다. 본 출원은 데이터 서브 블록을 압축함에 있어서 제로 압축, 런-랭스 인코딩, 허프만 인코딩, 콜럼버스 인코딩 등 압축 방식을 포함하여 이용할 수 있으나 이에 한정하지 않는다. 데이터 쓰기 모듈은 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 얻은 압축 데이터를 출력하기 위한 것이다. 데이터 쓰기 모듈은 상기 압축 데이터를 오프 칩 메모리에 기입할 수 있으며, 나아가, 데이터 처리 모듈이 처리한 데이터를 캐싱한 후 출력 인터페이스의 요구에 따라, 대응하는 데이터 출력 인터페이스 시간 시퀀스를 생성할 수 있다. 본 출원에서 상기 장치의 관련 도면에서 파선은 전송되는 것이 제어 스트림, 즉 모듈 간에 이용되는 제어임을 나타낼 수 있다. 그리고, 실선은 데이터 라인, 즉 모듈 간의 데이터 전송을 나타낼 수 있다. 본 실시예는 상기 장치를 통해 데이터 서브 블록별로 압축하는 것을 구현할 수 있으며, 이로써 데이터 운반 효 율을 향상하고 신경망의 성능을 향상할 수 있다. 선택적으로, 상기 데이터 처리 모듈은 또한 상기 제1 데이터 서브 블록에 대해 데이터 처리를 진행하기 위 한 것이다. 예를 들어, 데이터에 대한 시프트, 고정 소수점 구현, 최대치 찾기 등의 데이터 처리는 구체적으로 제1 데이터 서브 블록의 원시 데이터, 압축 데이터 또는 압축 길이에 대해, 데이터의 시프트, 고정 소수점 구현, 최대치 찾 기 등의 데이터 처리를 진행하는 것일 수 있으며, 이를 통해 데이터 처리 성능을 향상한다. 선택적으로, 도 3에서와 같이 상기 데이터 처리 모듈은 아래 구성을 포함한다. 원시 데이터 캐시은 상기 제1 데이터 서브 블록을 캐싱하기 위한 것이다. 압축 알고리즘 모듈은 상기 제1 데이터 서브 블록을 압축하여, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 압축 데이터를 얻기 위한 것이다. 길이 필드 캐시은 상기 압축 데이터의 길이를 캐싱하기 위한 것이다. 압축 제어 상태 머신은 상기 제1 데이터 서브 블록의 길이와 상기 압축 데이터의 길이를 토대로 상기 제1 데이터 서브 블록에 압축 이득이 존재하는 것으로 판단하면 제1 스트로브 신호를 발생시키고, 상기 제1 데이터 서브 블록의 길이와 상기 압축 데이터의 길이를 토대로 상기 제1 데이터 서브 블록에 압축 이득이 존재하지 않 는 것으로 판단하면 제2 스트로브 신호를 발생시키며, 상기 길이 캐시가 적중되지 않으면 제3 스트로브 신호를발생시키기 위한 것이다. 멀티 플렉서은 상기 제1 스트로브 신호를 토대로 상기 압축 알고리즘 모듈로부터 상기 압축 신호를 판독 하거나, 또는 상기 제2 스트로브 신호를 토대로 상기 원시 데이터 캐시로부터 상기 제1 데이터 서브 블록을 판 독하거나, 또는 상기 제3 스트로브 신호를 토대로 상기 길이 필드 캐시로부터 상기 길이를 판독하기 위한 것이다. 그중, 상술한 상기 길이 캐시가 적중되지 않으면 제3 스트로브 신호를 발생시키는 것은, 상기 압축 데이터의 길 이 필드가 메모리의 저장 어드레스 공간을 적중하지 않으면 제3 스트로브 신호를 발생시켜, 멀티 플렉서 로 하여금 상기 길이 필드 캐시에 캐싱된 상기 압축 데이터의 길이를 판독하여 출력하도록 하는 것일 수 있다. 구체적으로 길이 필드를 길이 블록으로서 처리하는 것일 수 있다. 나아가, 도 3에서와 같이 데이터 처리 모듈은, 상기 멀티 플렉서가 판독한 상기 압축 신호 또는 상기 제1 데이터 서브 블록을 출력하기 위한 데이터 시프트 모듈을 더 포함할 수 있다. 물론, 여기서 데이터 시프트 모듈은 하나의 예시에 불과하다. 예를 들어, 데이터 처리 모듈은 일부 데이터의 예비 처리 오퍼레이션을 위한 모듈, 예컨대 시프트, 고정 소수점 구현, 최대치 찾기 등의 데이터 처리 를 위한 모듈을 포함하는 것일 수도 있다. 상기 데이터 처리 모듈은 데이터 판독 모듈이 출력한 각각의 데이터 서브 블록에 대해 실시간 압축을 진행하는 것일 수 있으며, 압축 처리 입도는 하나의 서브 블록이다. 그중, 상기 원시 데이터 캐시, 길이 필드 캐시, 압축 알고리즘 모듈, 압축 제어 상태 머신 과 멀티 플렉서는 데이터 압축 모듈이라고 할 수 있다. 그중, 원시 데이터 캐시는 데이터 판독 모듈로부터 송신된 전체 데이터를 수신하여 캐시 내부에 저 장하고, 멀티 플렉서가 판독하기를 대기할 수 있다. 만약 서브 블록이 기본 블록이고 압축 길이 정보가 데이터 길이 정보보다 작으면, 원시 데이터 캐시는 내부에 캐싱된 대응하는 기본 블록 원시 정보를 무효로 설정 하여 저장 공간을 방출할 수도 있다. 만약 서브 블록이 정렬 블록, 리매핑되지 않은 블록, 및 압축 후 길이가 원시 길이보다 크거나 그와 같은 기본 블록이면, 멀티 플렉서가 당해 모듈로부터 데이터를 추출한다. 길이 필드 캐시는 길이 필드의 쓰기 횟수를 감소시키기 위해 설계한 캐시이다. 당해 캐시는 직접 매핑 또 는 다른 매핑 방법을 이용할 수 있으며, 캐시의 저장 공간을 길이 필드의 실제 저장 어드레스에 대응시키고, 캐 시 미스 또는 하나의 태스크의 수행이 완료된 후에야 캐시 중의 데이터를 일괄적으로 쓸(Write out) 수 있다. 길이 필드 캐시는 압축 알고리즘 모듈로부터 각각의 기본 블록에 대해 압축이 수행된 후 출력되는 길이 정보를 수신하고, 기본 블록의 목적 어드레스를 토대로 어드레스 매핑 규칙을 결합하여, 캐시 중 대응하는 길이 필드의 구체적인 저장 위치를 획득하고, 이 위치를 이미 업데이트된 것으로 마킹할 수 있다. 다음 번에 처 리하게 되는 서브 블록이 캐시 블록인 경우, 멀티 플렉서는 이미 업데이트된 것으로 마킹된 모든 길이 필 드의 데이터를 당해 모듈로부터 판독함과 함께, 이미 업데이트된 것을 나타내는 전체 마크를 제거한다. 압축 알고리즘 모듈은 압축 알고리즘을 이용하여 기본 블록에 대한 압축을 수행하기 위한 것이다. 그중, 여기서 압축 알고리즘은 제로 압축, 런-랭스 인코딩, 허프만 인코딩, 콜럼버스 인코딩 등 압축 방식을 포함하여 이용할 수 있으나 이에 한정하지 않는다. 서브 블록이 기본 블록인 경우, 압축 알고리즘 모듈은 데이터 판독 모듈로부터 송신된 데이터를 수신하고, 내부에 집적된 압축 알고리즘을 이용하여 데이터 압축을 수행한다. 만약 압축 후 데이터의 길이가 원시 데이터의 길이보다 크거나 그와 같으면, 원시 데이터 길이를 바로 출력하고, 이와 동시에 압축 후 데이터를 무효로 설정하고 내부 공간을 방출한다. 만약 압축 후 데이터의 길이 가 원시 데이터의 길이보다 작으면, 압축 후 데이터 길이를 출력하고, 압축 후 데이터 길이를 유효로 설정하며, 멀티 플렉서 모듈이 게이팅되어 압축 후 데이터를 출력하기를 대기한다. 압축 후 데이터의 출력이 완료된 후 저 장 위치를 무효로 설정하고 저장 공간을 방출한다. 압축 제어 상태 머신은 명령 파싱 모듈이 송신한 설정 정보를 수신하여 처리하고, 설정 정보에 포함 된 서브 블록 유형과 데이터 길이 정보를 토대로, 압축 알고리즘 모듈이 제공하는 압축 길이 정보를 결합 하여, 선택해야 하는 데이터 경로를 판단할 수 있다. 서브 블록이 기본 블록이고 압축 길이 정보가 데이터 길이 정보보다 작은 경우, 제1 스트로브 신호(channel selection signal)인 압축 알고리즘 모듈 경로 스트로브 신호 를 발생시키고; 서브 블록이 기본 블록이고 압축 길이 정보가 데이터 길이 정보보다 크거나 그와 같은 경우, 제 2 스트로브 신호인 원시 데이터 캐시 경로 스트로브 신호를 발생시킨다. 나아가, 서브 블록이 정렬 블록 또는 리매핑되지 않은 블록인 경우, 제2 스트로브 신호인 원시 데이터 캐시 경로 스트로브 신호를 발생시키고; 서브블록이 캐시 블록인 경우, 길이 필드 캐시 경로 스트로브 신호를 발생시킨다. 멀티 플렉서는 압축 제어 상태 머신이 발생시킨 경로 스트로브 신호를 토대로, 대응 경로로부터 데 이터를 획득하여 출력한다. 즉, 예를 들어 상기 제1 스트로브 신호를 토대로 상기 압축 알고리즘 모듈로부터 상 기 압축 신호를 판독하거나, 또는 상기 제2 스트로브 신호를 토대로 상기 원시 데이터 캐시로부터 상기 제1 데 이터 서브 블록을 판독한다. 데이터 시프트 모듈(data shifting module)은 데이터 압축 모듈이 출력한 데이터를 데이터 서브 블록의 목적 어드레스를 토대로 시프팅시켜, 대응되는 출력 인터페이스 비트 폭에 데이터를 매칭시키는 것일 수 있다. 이 실시형태는 상기 압축 모듈을 통해, 데이터 처리 모듈이 출력하는 데이터 길이에 대한 제어가 가능해지 도록 할 수 있고, 상기 DMA 채널에서 압축을 구현하여 캐시의 오버헤드를 저감시킬 수도 있다. 선택적으로, 상기 설정 정보는 상기 제1 데이터 서브 블록의 어드레스 정보, 길이와 서브 블록 유형 등을 포함 하며, 도 4와 같이 상기 데이터 판독 모듈은 아래 구성을 포함한다. 데이터 첨접 모듈은 상기 제1 데이터 서브 블록의 설정 정보를 토대로 상기 제1 데이터 서브 블록을 판독 하고, 상기 판독한 제1 데이터 서브 블록에 대해 시프트 및 첨접 처리를 진행하여 상기 제1 데이터 서브 블록의 연속적이고 완전한 데이터 스트림을 얻기 위한 것이다. 그중, 상기 제1 데이터 서브 블록의 어드레스 정보는 비연속적인 어드레스 정보일 수 있다. 구체적으로 본 출원 에서 각각의 데이터 서브 블록의 어드레스는 비연속적인 어드레스일 수 있으며, 예를 들어 도 2와 같다. 다시 말해, 상술한 상기 제1 데이터 서브 블록을 판독하는 것은 건너뛰면서 판독하는 것일 수 있으며, 제1 데이터 서 브 블록이 도 2의 기본 블록 a인 것을 예로 들면, 맨 처음 기본 블록 a의 제1 행의 데이터를 판독하고, 두 번째 로 기본 블록 a의 제2 행의 데이터를 판독한 후, 제1 행의 데이터와 제2 행의 데이터를 첨접하며, 그 다음 행의 데이터에 대해서도 동일한 처리를 진행한 후 이전 데이터에 첨접하여 상기 제1 데이터 서브 블록의 연속적이고 완전한 데이터 스트림을 획득한다. 상기 판독된 제1 데이터 서브 블록를 시프팅시키고 첨접 처리를 진행하여 상기 제1 데이터 서브 블록의 연속적 이고 완전한 데이터 스트림을 획득하므로, 비연속적 데이터의 압축을 지원할 수 있으며, 압축 처리된 데이터 서 브 블록의 크기를 향상하여 압축 처리 효율을 향상할 수 있다. 선택적으로, 상기 데이터 판독 모듈은 아래 구성을 더 포함한다. 데이터 출력 명령 캐시는 상기 설정 정보를 판독하고 상기 데이터 첨접 모듈에 판독 명령 요청을 송신하 기 위한 것이다. 데이터 캐시는 상기 데이터 첨접 모듈이 출력한 상기 연속적이고 완전한 데이터 스트림을 캐싱하기 위한 것이다. 데이터 출력 상태 머신은 상기 데이터 캐시 중의 상기 연속적이고 완전한 데이터 스트림을 패키징하고, 패키징된 데이터를 상기 데이터 처리 모듈에 출력하기 위한 것이다. 그중, 상기 설정 정보는 압축 여부를 표시하기 위한 압축 정보를 더 포함할 수 있다. 상기 데이터 출력 명령 캐시는 명령 파싱 모듈로부터 상기 길이와 압축 정보 중의 적어도 하나를 판 독하는 것일 수 있다. 예를 들어, 도 4와 같이 명령 파싱 모듈로부터 데이터 설정 정보를 수신하고 데이터 설정 정보를 일시 저장한다. 그중 당해 데이터 설정 정보는 명령 파싱 모듈에서 발생한 설정 정보일 수 있 으며, 적어도 데이터 서브 블록의 길이와 압축 정보 중의 적어도 하나를 포함한다. 수신한 설정 정보는 판독 명 령 요청의 송신과, 수신된 데이터에 대한 처리에 각각 이용된다. 상기 데이터 캐시는 후속의 데이터 출력 상태 머신의 처리가 지체되어 데이터를 잃는 것을 피하도록 데이 터를 일시 저장하는 것일 수 있다. 나아가, 데이터 캐시는 또한, 캐싱된 데이터량을 데이터 판독 상태 머 신에 제공하여, 판독 명령을 송신하는 데이터량을 제어함으로써, 과다한 데이터 수신에 따른 데이터 캐시의 오 버 플로우로 인해 데이터를 잃는 것을 피할 수 있다. 데이터 출력 상태 머신은 데이터 출력 명령 캐시로부터 명령을 수신하고, 설정 정보를 토대로 데이터 캐 시 중의 데이터를 약정 포맷으로 패키징한 후 내부 데이터 인터페이스를 거쳐 후위 데이터 처리 모듈에 송신하 는 것일 수 있다.선택적으로, 상기 데이터 판독 모듈은 또한 아래 구성을 더 포함한다. 판독 명령 캐시는 상기 제1 데이터 서브 블록의 어드레스 정보를 판독하기 위한 것이다. 데이터 판독 상태 머신는 상기 판독 명령 캐시로부터 명령을 획득하고, 상기 어드레스 정보를 토대로 내 부 캐시의 판독에 필요한 인터페이스 신호를 생성하기 위한 것이다. 그중, 상기 판독 명령 캐시는 명령 파싱 모듈로부터 제1 데이터 서브 블록의 어드레스 정보를 수신 하는 것일 수 있으며, 예를 들어 도 4에서와 같이 어드레스 설정 정보를 판독하는 것일 수 있다. 당해 어드레스 설정 정보는 명령 파싱 모듈에서 발생한 설정 정보이며, 적어도 제1 데이터 서브 블록의 어드레스 정보를 포함한다. 또한, 판독 명령 캐시가 수신한 설정 정보는 판독 명령 요청의 송신과, 수신된 데이터에 대한 처리에 각각 이용된다. 데이터 판독 상태 머신은 판독 명령 캐시로부터 명령을 획득하고, 설정 정보를 토대로 내부 캐시의 판독에 필요한 인터페이스 신호를 발생시키기 위한 것이다. 그중, 여기서 인터페이스 신호는 내부에서 데이터 판독을 진행하도록 트리거링하기 위한 신호일 수 있다. 상기 판독 명령 캐시와 데이터 판독 상태 머신을 통해 데이터 판독 모듈의 데이터 판독 정확 성을 향상할 수 있다. 선택적으로, 도 5에서와 같이 상기 데이터 쓰기 모듈은 아래 구성을 포함한다. 데이터 출력 캐시는 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 얻은 압축 데이터를 캐싱하기 위한 것이다. 설정 정보 캐시는 상기 제1 데이터 서브 블록의 설정 정보를 캐싱하기 위한 것이다. 출력 어드레스 캐시는 상기 제1 데이터 서브 블록의 목적 어드레스를 캐싱하기 위한 것이다. 인터페이스 시간 시퀀스 생성 모듈은 상기 설정 정보와 상기 목적 어드레스를 토대로, 상기 제1 데이터 서브 블록의 데이터 마스크 코드를 생성하고, 상기 제1 데이터 서브 블록에 대응하는 인터페이스 시간 시퀀스를 발생시키기 위한 것이다. 데이터 쓰기 모듈은 데이터 처리 모듈이 처리한 데이터를 캐싱한 후 출력 인터페이스의 요구에 따라 대응하는 데이터 출력 인터페이스 시간 시퀀스를 발생시키기는 것을 담당한다. 도 5에서와 같이, 당해 모듈은 데이터 출 력 캐시, 설정 정보 캐시, 인터페이스 시간 시퀀스 생성 모듈 및 출력 어드레스 캐시를 포함한다. 그중, 상기 데이터 출력 캐시는 데이터 처리 모듈이 처리한 출력 대상 데이터를 수신하여 일시 저장 하는 것일 수 있다. 상기 출력 대상 데이터는 구체적으로 압축 데이터 또는 데이터 서브 블록의 원시 데이터를 포함할 수 있다. 설정 정보 캐시는 명령 파싱 모듈로부터 설정 정보를 수신하는 것일 수 있다. 여기서 설정 정보는 주로 인터페이스의 데이터 마스크 신호를 생성하기 위한 것이다. 출력 어드레스 캐시는 어드레스 쓰기 인터페이스로부터 데이터 서브 블록의 목표 어드레스인 출력 어드레 스를 인터셉트하여 인터페이스 시간 시퀀스 생성 모듈이 사용하도록 하는 것일 수 있다. 인터페이스 시간 시퀀스 생성 모듈은 설정 정보 캐시로부터 설정 정보를 획득하고, 데이터 출력 캐 시로부터 데이터를 획득하며, 설정 정보를 토대로 데이터를 위해 대응하는 데이터 마스크를 생성할 수 있 으며, 그후 데이터 출력 인터페이스의 프로토콜 규칙에 따라, 대응하는 인터페이스 시간 시퀀스를 발생시킬 수 있다. 나아가, 인터페이스 시간 시퀀스 생성 모듈은 또한 일부 데이터 서브 블록에 대해 부분 쓰기를 최 적화할 수 있다. 그중, 부분 쓰기란, 데이터를 기입하는 비트 폭이 메모리의 비트 폭보다 작은 것을 가리킨다. 예를 들어, 현재 데이터 서브 블록의 초기 저장 어드레스의 정렬 여부를 판단하고, 정렬되지 않으면 직전 데이 터 서브 블록과 현재 데이터 서브 블록의 저장 어드레스의 연속 여부를 판단한다. 만약 연속된다면 직전 데이터 서브 블록의 압축 여부를 판단하고, 압축되었다면, 현재 데이터 서브 블록의 제1 비트(beat)에 대해 완전한 쓰 기를 진행한다. 그중, 여기서 완전한 쓰기란, 데이터를 기입하는 비트 폭이 메모리의 비트 폭과 같은 것을 가리 키며, 이로써 현재 데이터 서브 블록의 부분 쓰기의 횟수를 줄인다. 즉, 데이터 서브 블록에 대해 부분 쓰기를 최적화하여, 쓰기 횟수를 줄임으로써 신경망의 처리 성능을 한층 더 향상한다. 나아가, 부분 쓰기의 최적화가 완료되면, 데이터 마스크를 수정하여, 수정된 후의 마스크로 하여금 부분 쓰기가 완전 쓰기로 전환되었음을 나타내도록 할 수 있다. 나아가, 인터페이스 시간 시퀀스 생성 모듈은 또한 출력 어드레스 캐시로부터 어드레스 발생 상황 에 대한 정보를 획득할 수 있으며, 어드레스 채널과 데이터 채널이 분리된 버스 프로토콜에 대해, 두 채널의 데 이터의 선후 순서에 대한 제어를 구현할 수 있다. 이 실시형태는, 데이터 쓰기 모듈을 통해 신경망의 기입 성능을 최적화할 수 있다. 선택적으로, 도 6에서와 같이 상기 장치는 아래 구성을 더 포함한다. 어드레스 생성 모듈은 상기 제1 데이터 서브 블록의 목적 어드레스와 상기 압축 데이터의 길이를 토대로, 상기 제1 데이터 서브 블록의 버스 프로토콜이 지원하는 어드레스 채널 신호를 생성하고 상기 어드레스 채널 신 호를 출력하기 위한 것이다. 그중, 상기 제1 데이터 서브 블록의 목적 어드레스는, 오프 칩 메모리에서의 제1 데이터 서브 블록의 저장 어드 레스, 또는 출력 어드레스일 수 있다. 상술한 상기 제1 데이터 서브 블록의 목적 어드레스와 상기 압축 데이터의 길이를 토대로, 상기 제1 데이터 서 브 블록의 버스 프로토콜이 지원하는 어드레스 채널 신호를 생성하는 것은, 압축 데이터의 길이를 토대로 어드 레스 분할 논리를 이용하여 목적 어드레스를 분할하여, 제1 데이터 서브 블록의 버스 프로토콜이 지원하는 어드 레스 채널 신호를 얻는 것일 수 있다. 예를 들어, 압축 데이터의 길이가 버스 프로토콜이 최대 랜덤 액세스를 지원하는 어드레스보다 큰 경우, 제1 데이터 서브 블록의 목적 어드레스를 예컨대 128B 또는 64B의 어드레스 채 널 신호로 분할하며, 어드레스 채널 신호를 이용하여 데이터 랜덤 액세스를 지원한다. 또는, 압축 데이터의 길 이가 버스 프로토콜이 최대 랜덤 액세스를 지원하는 어드레스보다 작은 경우, 제1 데이터 서브 블록의 목적 어 드레스를 어드레스 채널 신호로 하며, 어드레스 채널 신호를 이용하여 데이터 랜덤 액세스를 지원한다. 나아가, 압축 기능이 활성화되고 처리되는 데이터 서브 블록이 기본 블록이면, 어드레스 생성 모듈은 또한 데이터 처리 모듈이 출력한 압축 길이 정보를 별도로 수신한 후, 수신한 설정 정보와 결합하여 대응 버스 프로토콜에 필요한 어드레스 채널 신호를 생성할 수 있다. 선택적으로, 도 6에서와 같이 상기 장치는 아래 구성을 더 포함한다. 응답 처리 모듈은 오프 칩 메모리, 버스 또는 네트워크 온 칩에서 피드백된 응답 신호를 처리하고, 명령 파싱 모듈로부터 송신된 중단 마크와 결합하여 처리 완료 중단을 발생시키고, 중단을 명령 파싱 모듈(10 1)에 송신하기 위한 것이다. 예를 들어, 명령 파싱 모듈은 명령을 수신한 후, 당해 명령이 DMA 동기화 명령인 것으로 판단하면, 하나의 중단 마크 신호를 응답 처리 모듈에 송신하며, 당해 마크는 당해 마크의 송신 전의 운반 데이터의 전체 양을 표 시한다. 나아가, 응답 처리 모듈은 명령 파싱 모듈의 설정 정보 출력 인터페이스를 인터셉트하고, 명령 카운 터를 이용하여 카운팅할 수 있다. 명령 파싱 모듈이 송신한 중단 마크를 수신한 경우, 응답 처리 모듈 은 현재 명령 카운터의 수치를 저장한다. 이와 동시에, 응답 처리 모듈은 또한 쓰기 응답 인터페이스 의 정보를 수신하고, 응답 카운터를 이용하여 카운팅할 수 있다. 응답 처리 모듈은 중단 마크의 도착 시 저장된 명령 카운터 수치와 현재 응답 카운터의 수치를 끊임없이 비교하며, 후자가 전자보다 크거나 그와 같은 경우, 당해 중단 마크 전의 모든 명령이 이미 수행되었음을 나타내고, 처리 완료 중단을 발생시켜 명령 파싱 모 듈에 송신함과 동시에, 저장된 명령 카운터의 수치를 무효로 설정한다. 나아가, 도 6에서와 같이 상기 장치는 쓰기 응답 인터페이스, 데이터 판독 인터페이스, 어드레스 판독 인터페이 스, 데이터 쓰기 인터페이스와 어드레스 쓰기 인터페이스를 더 포함할 수 있으며, 그중, 쓰기 응답 인터페이스, 데이터 쓰기 인터페이스와 어드레스 쓰기 인터페이스는 오프 칩 메모리의 쓰기 인터페이스거나, 또는 오프 칩 메모리의 쓰기 인터페이스에 연결된 버스, 네트워크 온 칩의 쓰기 인터페이스일 수 있다. 상기 데이터 판독 인 터페이스와 어드레스 판독 인터페이스는 캐시 온 칩의 판독 인터페이스거나, 또는 캐시 온 칩 인터페이스에 연 결된 버스, 네트워크 온 칩의 판독 인터페이스일 수 있다. 본 실시예는 상기 장치를 통해 데이터 서브 블록별로 압축하는 것을 구현할 수 있으며, 이로써 데이터 운반 효 율을 향상하고 신경망의 성능을 향상할 수 있다. 본 출원은 본 출원에 따른 신경망 데이터 처리 장치를 포함한 전자 장비를 더 제공한다. 당해 전자 장비는 휴대 폰, 컴퓨터, 서버 등의 신경망 연산을 진행할 수 있는 전자 장비를 포함하나 이에 한정되지 않는다. 도 7을 참고하면, 도 7은 본 출원에 따른 신경망 데이터 처리 방법의 흐름도이다. 도 7에서와 같이 상기 방법은 아래 단계를 포함한다. 단계 S701: DMA 태스크를 신경망 운반 데이터 중의 데이터 서브 블록과 하나씩 대응하는 다수의 서브 태스크로 분할하고, 각각의 서브 태스크에 대응하는 데이터 서브 블록의 설정 정보를 획득한다. 그중, 상기 DMA 태스크는 데이터 운반 태스크일 수 있다. 또는 DMA 태스크는 데이터 운반과 처리 태스크일 수 있다. 상기 신경망 운반 데이터는 신경망 연산을 수행하여 얻은 데이터일 수 있으며, 예컨대 웨이트 매트릭스 또는 특 징 맵(feature map) 등 데이터일 수 있다. 상기 데이터 서브 블록은 상기 운반 데이터를 분할하여 얻은 데이터 서브 블록일 수 있다. 예를 들어, 도 2에서와 같이 운반 데이터를 기본 블록, 정렬 블록과 재매핑되지 않은 블 록 이들 데이터 서브 블록으로 분할할 수 있다. 그중, 각각의 기본 블록의 데이터 크기는 고정되며, 이 고정 크 기는 미리 설정할 수 있으며, 구체적으로 실제 수요에 따라 설정할 수 있다. 정렬 블록과 재매핑되지 않은 블록 은 운반 데이터 블록을 다수의 기본 블록으로 분할한 후 남는, 기본 블록을 구성할 수 없는 서브 블록이며, 구 체적으로 도 2와 같을 수 있으며, 오른쪽에 남은 서브 블록을 정렬 블록이라고 하고, 아래쪽에 남은 서브 블록 을 리매핑되지 않은 블록이라고 한다. 또한, 상술한 각각의 서브 태스크에 대응하는 데이터 서브 블록의 설정 정보를 획득하는 것은, 데이터 서브 블 록의 설정 정보를 발생시키는 것일 수 있다. 설정 정보는 데이터 서브 블록의 길이, 어드레스와 압축 정보 등을 포함할 수 있으며, 여기서 압축 정보는 데이터 서브 블록의 압축 여부를 표시하기 위한 것이다. 상기 서브 태스크와 신경망 운반 데이터 중의 데이터 서브 블록이 하나씩 대응한다는 것은, 상기 DMA 태스크가 상기 신경망 운반 데이터에 대응하고, DMA 태스크를 서브 태스크로 분할한 후 이에 대응하여 신경망 운반 데이 터를 데이터 서브 블록으로 분할하는 것일 수 있다. 예를 들어, DMA 태스크가 데이터 운반 태스크인 것을 예로 들면, 서브 태스크는 하나의 데이터 서브 블록을 운반하는 태스크일 수 있으며, DMA 태스크가 데이터 운반과 처 리 태스크인 것을 예로 들면, 서브 태스크는 하나의 데이터 서브 블록을 운반하여 처리하는 태스크일 수 있다. 또한, 본 출원에 따른 신경망은 CDNN을 포함하나 이에 한정되지 않으며, 예를 들어 그밖의 다른 심층 신경망일 수 있다. 단계 S702: 상기 다수의 서브 태스크에 대응하는 데이터 서브 블록들 중의 데이터 서브 블록인 제1 데이터 서브 블록을 상기 설정 정보를 토대로 판독한다. 그중, 상기 제1 데이터 서브 블록은 상기 운반 데이터 중 임의의 데이터 서브 블록일 수 있으며, 바람직하게는 제1 데이터 서브 블록은 임의의 기본 블록일 수 있다. 상술한 상기 설정 정보를 토대로 제1 데이터 서브 블록을 판독하는 것은, 내부 캐시에서 설정 정보가 표시하는 데이터 서브 블록에 대한 판독을 토대로 하는 것일 수 있다. 본 출원에서 단계 S702와 단계 S703은 제1 데이터 서브 블록을 들어 설명했다. 상기 제1 데이터 서브 블록이 상 기 운반 데이터 중 임의의 데이터 서브 블록일 수 있으므로, 본 출원은 임의의 데이터 서브 블록에 대해 모두 단계 S702와 단계 S703을 수행할 수 있다. 단계 S703: 상기 제1 데이터 서브 블록을 압축하고, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 발생 한 압축 데이터를 출력한다. 본 출원은 데이터 서브 블록을 압축함에 있어서 제로 압축, 런-랭스 인코딩, 허프만 인코딩, 콜럼버스 인코딩 등 압축 방식을 포함하여 이용할 수 있으나 이에 한정하지 않는다. 상술한 상기 압축을 거쳐 제1 데이터 서브 블록으로부터 발생한 압축 데이터를 출력하는 것은, 압축 데이터를 오프 칩 메모리에 기입하는 것일 수 있다. 본 출원에 따른 신경망 데이터 처리 방법은 신경망 연산을 위한 칩(또는 프로세서라고도 한다) 예를 들어 NPU 또는 하드웨어 가속기에 적용될 수 있다. 본 실시예는 상기 단계를 통해 데이터 서브 블록별로 압축하는 것을 구현할 수 있으며, 이로써 데이터 운반 효 율을 향상하고 신경망의 성능을 향상하며, 신경망 프로세서의 등가적 대역폭을 상승시킬 수 있다.도 8을 참고하면, 도 8은 본 출원에 따른 또 다른 신경망 데이터 처리 방법의 흐름도이다. 도 8에서와 같이 상 기 방법은 아래 단계를 포함한다. 단계 S801: DMA 태스크를 신경망 운반 데이터 중의 데이터 서브 블록과 하나씩 대응하는 다수의 서브 태스크로 분할하고, 각각의 서브 태스크에 대응하는 데이터 서브 블록의 설정 정보를 획득한다. 단계 S802: 상기 다수의 서브 태스크에 대응하는 데이터 서브 블록들 중의 데이터 서브 블록인 제1 데이터 서브 블록을 상기 설정 정보를 토대로 판독한다. 선택적으로, 상기 설정 정보는 상기 제1 데이터 서브 블록의 어드레스 정보를 포함하고, 상술한 상기 설정 정보 를 토대로 제1 데이터 서브 블록을 판독하는 단계는, 상기 제1 데이터 서브 블록의 어드레스 정보를 토대로 상기 제1 데이터 서브 블록을 판독하고, 상기 판독한 제1 데이터 서브 블록에 대해 시프트 및 첨접 처리를 진행하여 상기 제1 데이터 서브 블록의 연속적이고 완전한 데 이터 스트림을 얻는 단계를 포함한다. 그중, 상기 제1 데이터 서브 블록의 어드레스 정보는 비연속적인 어드레스 정보일 수 있다. 구체적으로 본 출원 에서 각각의 데이터 서브 블록의 어드레스는 비연속적인 어드레스일 수 있으며, 예를 들어 도 2와 같다. 다시 말해, 상술한 상기 제1 데이터 서브 블록을 판독하는 것은 건너뛰면서 판독하는 것일 수 있다. 제1 데이터 서브 블록이 도 2의 기본 블록 a인 것을 예로 들면, 맨 처음 기본 블록 a의 제1 행의 데이터를 판독하고, 두 번째로 기본 블록 a의 제2 행의 데이터를 판독한 후, 제1 행의 데이터와 제2 행의 데이터를 첨접하며, 그 다음 행의 데 이터에 대해서도 동일한 처리를 진행한 후 이전 데이터에 첨접하여 상기 제1 데이터 서브 블록의 연속적이고 완 전한 데이터 스트림을 획득한다. 상기 판독된 제1 데이터 서브 블록에 대해 시프트 및 첨접 처리를 진행하여 상기 제1 데이터 서브 블록의 연속 적이고 완전한 데이터 스트림을 획득하므로, 비연속적인 데이터의 압축을 지원할 수 있으며, 압축 처리된 데이 터 서브 블록의 크기를 향상하여 압축 처리 효율을 향상할 수 있다. 단계 S803: 상기 제1 데이터 서브 블록을 압축하고, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 얻은 압축 데이터를 출력한다. 선택적으로, 상술한 상기 제1 데이터 서브 블록을 압축하고, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로 부터 얻은 압축 데이터를 출력하는 단계는, 상기 제1 데이터 서브 블록과 상기 제1 데이터 서브 블록 데이터의 길이를 캐싱하는 단계; 상기 제1 데이터 서브 블록을 압축하여, 상기 압축을 거쳐 상기 제1 데이터 서브 블록으로부터 압축 데이터를 얻고, 상기 압축 데이터의 길이를 기록하는 단계; 상기 제1 데이터 서브 블록의 길이와 상기 압축 데이터의 길이를 토대로, 상기 제1 데이터 서브 블록에 압축 이 득이 존재하는지를 판단하고, 압축 이득이 존재하면 상기 압축 데이터를 출력하고, 압축 이득이 존재하지 않으 면 상기 제1 데이터 서브 블록 데이터를 출력하는 단계를 포함한다. 상기 제1 데이터 서브 블록의 길이와 상기 압축 데이터의 길이를 토대로, 상기 제1 데이터 서브 블록에 압축 이 득이 존재하는지를 판단하는 단계는, 압축 데이터의 길이가 제1 데이터 서브 블록의 길이보다 작은지를 판단하 고, 만약 작다면 제1 데이터 서브 블록에 압축 이득이 존재하는 것으로 판단하며, 그렇지 않으면 압축 이득이 존재하지 않는 것으로 확정하는 단계일 수 있다. 또는, 상기 단계는 압축 데이터의 길이를 토대로 압축 데이터 의 전송에 필요한 비트(beat) 수를 확정하고 또한 제1 데이터 서브 블록의 길이를 토대로 제1 데이터 서브 블록 의 전송에 필요한 비트 수를 확정하며, 압축 데이터의 전송에 필요한 비트 수가 제1 데이터 서브 블록의 전송에 필요한 비트 수보다 작다면 제1 데이터 서브 블록에 압축 이득이 존재하는 것으로 확정하고, 그렇지 않으면 압 축 이득이 존재하지 않는 것으로 확정하는 단계일 수 있다. 상술한 상기 제1 데이터 서브 블록과 상기 제1 데이터 서브 블록 데이터의 길이를 캐싱하는 단계는, 제1 데이터 서브 블록의 원시 데이터와 원시 길이를 캐싱하는 단계로 이해할 수 있다. 상기 압축은 NPU의 DMA에서 압축을 수행하는 것일 수 있다. DMA에서 압축하므로, NPU에 별도의 큰 캐시를 설치 할 필요가 없으며, 이로써 NPU의 공간 오버헤드를 저감시킨다. 상기 압축 데이터의 길이가 상기 제1 데이터 서브 블록 데이터의 길이보다 작은 경우에만 상기 압축 데이터를 출력하므로, 데이터 길이의 제어가 가능해지도록 하여, 과다한 저장 공간을 비축하는 것을 피하여 저장 공간을 절약하는 효과를 이룰 수 있다. 선택적으로, 상기 방법은 아래 단계를 더 포함한다. 단계 S804: 상기 압축 데이터의 길이를 캐싱한다. 단계 S805: 상기 제1 데이터 서브 블록의 목적 어드레스와 상기 압축 데이터의 길이를 토대로, 상기 제1 데이터 서브 블록의 버스 프로토콜이 지원하는 어드레스 채널 신호를 생성하고 상기 어드레스 채널 신호를 출력한다. 그중, 상기 제1 데이터 서브 블록의 목적 어드레스는 오프 칩 메모리에서의 제1 데이터 서브 블록의 저장 어드 레스, 또는 출력 어드레스일 수 있다. 상술한 상기 제1 데이터 서브 블록의 목적 어드레스와 상기 압축 데이터의 길이를 토대로, 상기 제1 데이터 서 브 블록의 버스 프로토콜이 지원하는 어드레스 채널 신호를 생성하는 것은, 압축 데이터의 길이를 토대로 어드 레스 분할 논리를 이용하여 목적 어드레스를 분할하여, 제1 데이터 서브 블록의 버스 프로토콜이 지원하는 어드 레스 채널 신호를 얻는 것일 수 있다. 예를 들어, 압축 데이터의 길이가 버스 프로토콜이 최대 랜덤 액세스를 지원하는 어드레스보다 큰 경우, 제1 데이터 서브 블록의 목적 어드레스를 예컨대 128B 또는 64B의 어드레스 채 널 신호로 분할하며, 어드레스 채널 신호를 이용하여 데이터 랜덤 액세스를 지원한다. 또는, 압축 데이터의 길 이가 버스 프로토콜이 최대 랜덤 액세스를 지원하는 어드레스보다 작은 경우, 제1 데이터 서브 블록의 목적 어 드레스를 어드레스 채널 신호로 하며, 어드레스 채널 신호를 이용하여 데이터 랜덤 액세스를 지원한다. 이 실시형태는 상기 어드레스 채널 신호를 통해 압축 데이터의 랜덤 액세스를 지원하여 신경망의 성능을 한층 더 향상할 수 있다. 본 실시예는 도 1에 따른 실시예를 기초로 다양한 선택적인 실시형태를 추가하며 이들은 모두 신경망의 성능을 향상할 수 있다. 위에서 나타낸 다양한 형태의 흐름을 이용하여 단계를 다시 정렬하거나 추가, 삭제할 수 있음을 이해할 것이다. 예를 들어, 본 출원에 기재된 각 단계는 병행으로 수행될 수 있고, 순차적으로 수행될 수도 있으며, 서로 다른 순서로 수행될 수도 있다. 본 출원에 개시된 기술적 수단이 기대하고 있는 효과를 구현할 수만 있다면 본 명세 서에서는 각 단계의 순서를 한정하지 않는다. 상기 구체적인 실시형태는 본 출원의 보호 범위를 한정하지 않는다. 본 분야의 통상의 기술자라면 설계 요구와 그밖의 다른 요소에 따라 다양한 수정, 조합, 부분 조합과 대체 등 처리를 진행할 수 있음을 알 것이다. 본 출 원의 사상과 원칙 내에서 진행된 모든 수정, 균등 교체와 개량 등은 모두 본 출원의 보호 범위에 속한다. 이상의 설명은 본 발명의 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명의 실시예가 속하는 기술 분야에서 통상의 지식을 가진 자라면 본 발명의 실시예의 본질적인 특성에서 벗어나지 않는 범위에 서 다양한 수정 및 변형이 가능할 것이다. 따라서, 본 발명의 실시예들은 본 발명의 실시예의 기술 사상을 한정 하기 위한 것이 아니라 설명하기 위한 것이고, 이러한 실시예에 의하여 본 발명의 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등 한 범위 내에 있는 모든 기술 사상은 본 발명의 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2020-0071855", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면은 본 기술적 수단에 대한 이해를 돕기 위한 것이며, 본 출원을 한정하지 않는다. 도 1은 본 출원에 따른 신경망 데이터 처리 장치의 구조도이다. 도 2는 본 출원에 따른 데이터 서브 블록의 분할 개략도이다. 도 3은 본 출원에 따른 데이터 처리 모듈의 구조도이다. 도 4는 본 출원에 따른 데이터 판독 모듈의 구조도이다. 도 5는 본 출원에 따른 데이터 쓰기 모듈의 구조도이다. 도 6은 본 출원에 따른 또 다른 신경망 데이터 처리 장치의 구조도이다. 도 7은 본 출원에 따른 신경망 데이터 처리 방법의 흐름도이다. 도 8은 본 출원에 따른 또 다른 신경망 데이터 처리 방법의 흐름도이다."}
