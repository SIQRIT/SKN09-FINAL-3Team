{"patent_id": "10-2022-0148174", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0066867", "출원번호": "10-2022-0148174", "발명의 명칭": "음성 인식에 기반한 적어도 하나의 텍스트를 제공하기 위한 전자 장치, 및 그 동작 방법", "출원인": "(주)소리를보는통로", "발명자": "윤지현"}}
{"patent_id": "10-2022-0148174", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치의 동작 방법에 있어서,특정 언어의 복수의 음성 데이터들을 획득하는 동작;을 포함하고, 상기 복수의 음성 데이터들 중 일부는 상기특정 언어의 특정 단위의 동일한 음성에 대응하되, 서로 다른 음성학적 특성을 갖고,상기 복수의 음성 데이터들 중 적어도 하나의 제1 음성 데이터에 제1 소음 그룹의 소음 데이터를 반영하고, 상기 복수의 음성 데이터들 중 적어도 하나의 제2 음성 데이터에 상기 제1 소음 그룹과는 다른 제2 소음 그룹의소음 데이터를 반영하는 동작;상기 제1 소음 그룹의 소음 데이터가 반영된 상기 적어도 하나의 제1 음성 데이터에 기반하여 상기 특정 언어의음성을 획득하기 위한 제1 인공지능 모델을 생성하는 동작; 및상기 제2 소음 그룹의 소음 데이터가 반영된 상기 적어도 하나의 제2 음성 데이터에 기반하여 상기 특정 언어의음성을 획득하기 위한 제2 인공지능 모델을 생성하는 동작;을 포함하는,동작 방법."}
{"patent_id": "10-2022-0148174", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 제1 소음 및 상기 제2 소음을 반영하는 동작은,제1 소음 그룹에 대응하는 복수의 제1 하위 소음 데이터들을 획득하고, 상기 복수의 제1 소음 데이터들 중 적어도 하나의 소음 데이터를 상기 적어도 하나의 제1 음성 데이터에 반영하는 동작; 및제2 소음 그룹에 대응하는 복수의 제2 하위 소음 데이터들을 획득하고, 상기 복수의 제2 소음 데이터들 중 적어도 하나의 소음 데이터를 상기 적어도 하나의 제2 음성 데이터에 반영하는 동작;을 포함하는,동작 방법."}
{"patent_id": "10-2022-0148174", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서, 상기 제1 소음 그룹은 제1 환경 그리고 상기 제2 소음 그룹은 제2 환경에 대응하고,상기 복수의 제1 하위 노이즈 데이터들 각각은 상기 제1 환경 내에서 발생 가능한 서로 다른 종류의 소음에 대응하고,상기 복수의 제2 하위 노이즈 데이터들 각각은 상기 제2 환경 내에서 발생 가능한 서로 다른 종류의 소음에 대응하는,동작 방법."}
{"patent_id": "10-2022-0148174", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서, 상기 음성학적 특성은 주파수 별 세기를 나타내고,서로 다른 성별 또는 연령을 갖는 발화자들의 상기 특정 언어의 상기 특정 단위의 발화에 기반하여, 상기 특정언어의 복수의 음성 데이터들을 획득하는 동작;을 포함하는,공개특허 10-2024-0066867-3-동작 방법."}
{"patent_id": "10-2022-0148174", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서, 상기 제1 인공 지능 모델을 생성하는 동작은,제1 시간에 반영되는 상기 적어도 하나의 제1 음성 데이터, 상기 제1 시간의 이전인 제2 시간 및/또는 이후인제3 시간에 반영되는 빈-사운드 데이터, 및 상기 제1 시간에 반영되는 상기 제1 종류의 소음을 포함하는 입력데이터를 획득하는 동작;상기 제1 시간에 반영되는 상기 적어도 하나의 제1 음성 데이터를 포함하는 아웃풋 데이터를 획득하는 동작; 및상기 입력 데이터 및 상기 아웃풋 데이터에 기반하여 학습을 수행함으로써, 상기 제1 인공 지능 모델을 생성하는 동작;을 포함하는,동작 방법."}
{"patent_id": "10-2022-0148174", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "전자 장치의 동작 방법에 있어서,복수의 AI 모델들을 획득하는 동작;을 포함하고, 상기 복수의 AI 모델들 각각은 상기 서로 다른 소음 그룹에 대응하는 소음 데이터를 포함하는 사운드 데이터가 입력되는 경우, 상기 사운드 데이터에 포함된 음성을 제공하도록 구현되고,특정 하위의 소음이 반영된 특정 언어의 음성을 포함하는 사운드 데이터를 획득하는 동작;복수의 소음 그룹들 중 상기 특정 하위의 소음을 포함하는 특정 소음 그룹을 선택하는 동작; 및상기 복수의 AI 모델들 중 상기 선택된 특정 소음 그룹에 대응하는 특정 AI 모델에 기반하여, 상기 특정 하위의소음이 반영된 상기 사운드 데이터로부터 상기 특정 언어의 음성의 적어도 일부를 획득하는 동작;을 포함하는,동작 방법."}
{"patent_id": "10-2022-0148174", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서, 상기 복수의 소음 그룹들 각각은 상기 전자 장치가 위치되어 사운드를 수신 가능한 서로 다른 환경에 대응하고,상기 복수의 소음 그룹들 각각과 연관된 적어도 하나의 하위의 소음은 상기 서로 다른 환경에서 발생 가능한 종류의 소음을 포함하는,동작 방법."}
{"patent_id": "10-2022-0148174", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서, 상기 특정 소음 그룹을 선택하는 동작은, 상기 획득된 사운드 데이터에 대한 분석에 기반하여, 복수의 하위의 소음 데이터들을 식별하는 동작; 및복수의 소음 그룹들 중 식별된 상기 복수의 하위의 소음 데이터들 중 가장 많은 수의 소음 데이터를 포함하는상기 특정 그룹을 선택하는 동작;을 포함하는,동작 방법.공개특허 10-2024-0066867-4-청구항 9 제8 항에 있어서, 상기 특정 소음 그룹을 선택하는 동작은,상기 복수의 소음 그룹들에 대응하는 복수의 환경들을 나타내는 복수의 그래픽 오브젝트들을 포함하는 실행 화면을 표시하는 동작; 및상기 복수의 그래픽 오브젝트들 중 선택된 그래픽 오브젝트에 대응하는 상기 특정 소음 그룹을 식별하는 동작;을 포함하는,동작 방법."}
{"patent_id": "10-2022-0148174", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "전자 장치의 동작 방법에 있어서,특정 언어의 복수의 음성 데이터들을 획득하는 동작;을 포함하고, 상기 복수의 음성 데이터들 중 일부는 상기특정 언어의 특정 단위의 발화에 대응하되, 서로 다른 음성학적 특성을 갖고,상기 복수의 음성 데이터들 별로 서로 다른 그룹의 소음 데이터를 반영하는 동작;상기 서로 다른 그룹의 소음 데이터가 반영된 상기 복수의 음성 데이터들에 기반하여, 복수의 인공지능 모델들을 생성하는 동작;을 포함하고, 상기 복수의 인공지능 모델들 각각은 상기 서로 다른 그룹의 소음 데이터를 포함하는 사운드 데이터가 입력되는 경우, 상기 사운드 데이터에 포함된 음성을 제공하도록 구현되고,특정 소음 그룹이 선택되는 경우, 상기 복수의 인공지능 모델들 중 상기 선택된 특정 소음 그룹에 대응하는 특정 인공지능 모델이 이용되도록 설정되는,동작 방법."}
{"patent_id": "10-2022-0148174", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다양한 실시예들에 따르면, 전자 장치의 동작 방법에 있어서, 특정 언어의 복수의 음성 데이터들을 획득하는 동 작;을 포함하고, 상기 복수의 음성 데이터들 중 일부는 상기 특정 언어의 특정 단위의 동일한 음성에 대응하되, 서로 다른 음성학적 특성을 갖고, 상기 복수의 음성 데이터들 중 적어도 하나의 제1 음성 데이터에 제1 소음 그 (뒷면에 계속)"}
{"patent_id": "10-2022-0148174", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는, 음성 인식에 기반한 적어도 하나의 텍스트를 제공하기 위한 전자 장치, 및 그 동작 방법에 관한 것 이다."}
{"patent_id": "10-2022-0148174", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성 인식은 다양한 기반 기술에 의해 구현되지만, 인공지능의 세부 분야 중. 하나인 딥러닝 기술에 힘입어 비 약적으로 발전했다. 고도화된 음성 인식 기술은 실생활에서의 다양한 서비스뿐만 아니라 다양한 산업 분야까지 광범위하게 활용되고 있다. 특히 최근에는, 청각장애인 등과 같은 청각적 정보를 이용하기에 어려운 소비자들에게, 음성 인식 기술을 통해 인식된 청각적 정보를 다른 시각적 정보로 변환하여 제공하는 서비스에 대한 수요가 증대되고 있는 실정이다."}
{"patent_id": "10-2022-0148174", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "음성 인식을 위한 인공 지능 모델에 기반하여, 사운드가 전자 장치에 의해 획득되는 경우 상기 사운드에 포함되 는 상대 발화자의 음성에 대응하는 텍스트가 제공됨으로써, 사용자가 음성을 텍스트를 통해 시인할 수 있게 된 다. 다만 이때, 다양한 환경에서 발생되는 사운드에는 발화자의 음성 뿐만 아니라 다양한 환경 별로 존재하는 소음원으로부터 발생되는 소음까지 포함될 수 있다. 이에 따라, 사운드 내의 음성에 대한 인식률이 저하되는 문제가 발생될 수 있다. 다양한 실시예들에 따른, 전자 장치 및 그 동작 방법은, 음성 인식을 수행하기 이전에 다양한 환경 별로 발생되 는 소음을 저감하는 전-처리 동작을 수행함으로써, 음성에 대한 인식률을 향상시킬 수 있다. 본 출원이 해결하고자 하는 과제가 상술한 과제로 제한되는 것은 아니며, 언급되지 아니한 과제들은 본 명세서"}
{"patent_id": "10-2022-0148174", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "및 첨부된 도면으로부터 본 출원이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0148174", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "다양한 실시예들에 따르면, 전자 장치의 동작 방법에 있어서, 특정 언어의 복수의 음성 데이터들을 획득하는 동 작;을 포함하고, 상기 복수의 음성 데이터들 중 일부는 상기 특정 언어의 특정 단위의 동일한 음성에 대응하되, 서로 다른 음성학적 특성을 갖고, 상기 복수의 음성 데이터들 중 적어도 하나의 제1 음성 데이터에 제1 소음 그 룹의 소음 데이터를 반영하고, 상기 복수의 음성 데이터들 중 적어도 하나의 제2 음성 데이터에 상기 제1 소음 그룹과는 다른 제2 소음 그룹의 소음 데이터를 반영하는 동작; 상기 제1 소음 그룹의 소음 데이터가 반영된 상 기 적어도 하나의 제1 음성 데이터에 기반하여 상기 특정 언어의 음성을 획득하기 위한 제1 인공지능 모델을 생 성하는 동작; 및 상기 제2 소음 그룹의 소음 데이터가 반영된 상기 적어도 하나의 제2 음성 데이터에 기반하여 상기 특정 언어의 음성을 획득하기 위한 제2 인공지능 모델을 생성하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 전자 장치의 동작 방법에 있어서, 특정 언어의 복수의 음성 데이터들을 획득하는 동 작;을 포함하고, 상기 복수의 음성 데이터들 중 일부는 상기 특정 언어의 특정 단위의 발화에 대응하되, 서로 다른 음성학적 특성을 갖고, 상기 복수의 음성 데이터들 별로 서로 다른 그룹의 소음 데이터를 반영하는 동작; 상기 서로 다른 그룹의 소음 데이터가 반영된 상기 복수의 음성 데이터들에 기반하여, 복수의 인공지능 모델들 을 생성하는 동작;을 포함하고, 상기 복수의 인공지능 모델들 각각은 상기 서로 다른 그룹의 소음 데이터를 포 함하는 사운드 데이터가 입력되는 경우, 상기 사운드 데이터에 포함된 음성을 제공하도록 구현되고, 특정 소음 그룹이 선택되는 경우, 상기 복수의 인공지능 모델들 중 상기 선택된 특정 소음 그룹에 대응하는 특정 인공지능 모델이 이용되도록 설정되는, 동작 방법이 제공될 수 있다."}
{"patent_id": "10-2022-0148174", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "과제의 해결 수단이 상술한 해결 수단들로 제한되는 것은 아니며, 언급되지 아니한 해결 수단들은 본 명세서 및"}
{"patent_id": "10-2022-0148174", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "첨부된 도면으로부터 본 출원이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0148174", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "다양한 실시예들에 따른, 음성 인식을 수행하기 이전에 다양한 환경 별로 발생되는 소음을 저감하는 전-처리 동 작을 수행함으로써, 음성에 대한 인식률을 향상시키는, 전자 장치 및 그 동작 방법이 제공될 수 있다."}
{"patent_id": "10-2022-0148174", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다양한 실시예들에 대해서 특정한 구조적 내지 기능적 설명들은 단지 다양한 실시예들에 따른 설명을 위한 목적 으로 예시된 것으로, 다양한 실시예들은 다양한 형태로 실시될 수 있으며 본 명세서 또는 출원에 설명된 실시 예들에 한정되는 것으로 해석되어서는 아니 된다. 다양한 실시예들은 다양한 변경을 가할 수 있고 여러가지 형태를 가질 수 있으므로 다양한 실시예들을 도면에 예시하고 본 명세서 또는 출원에 상세하게 설명하고자 한다. 그러나, 도면으로부터 개시되는 사항은 다양한 실 시예들을 특정하거나 또는 한정하려는 것이 아니며, 다양한 실시예들의 사상 및 기술 범위에 포함되는 모든 변 경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1 및/또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로 만, 예컨대 본 개시의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 &quot;연결되어&quot; 있다거나 &quot;접속되어&quot; 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존 재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 &quot;직접 연결되어&quot; 있다거나 &quot;직접 접속되어&quot; 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이 해되어야 할 것이다. 구성요소들 간의 관계를 설명하는 다른 표현들, 즉 &quot;~사이에&quot;와 &quot;바로 ~사 이에&quot; 또는 &quot;~에 이웃하는&quot;과 &quot;~에 직접 이웃하는&quot; 등도 마찬가지로 해석되어야 한다. 본 명세서에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 다양한 실시예뜰을 한정하 려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세 서에서, &quot;포함하다&quot; 또는 &quot;가지다&quot; 등의 용어는 설시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 개시이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미이다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미인 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하, 첨부한 도면을 참조하여 본 개시의 바람직한 실시 예를 설명함으로써, 본 개시을 상세히 설명한다. 각 도 면에 제시된 동일한 참조부호는 동일한 부재를 나타낸다. 다양한 실시예들에 따르면, 전자 장치의 동작 방법에 있어서, 특정 언어의 복수의 음성 데이터들을 획득하는 동 작;을 포함하고, 상기 복수의 음성 데이터들 중 일부는 상기 특정 언어의 특정 단위의 동일한 음성에 대응하되, 서로 다른 음성학적 특성을 갖고, 상기 복수의 음성 데이터들 중 적어도 하나의 제1 음성 데이터에 제1 소음 그 룹의 소음 데이터를 반영하고, 상기 복수의 음성 데이터들 중 적어도 하나의 제2 음성 데이터에 상기 제1 소음 그룹과는 다른 제2 소음 그룹의 소음 데이터를 반영하는 동작; 상기 제1 소음 그룹의 소음 데이터가 반영된 상 기 적어도 하나의 제1 음성 데이터에 기반하여 상기 특정 언어의 음성을 획득하기 위한 제1 인공지능 모델을 생 성하는 동작; 및 상기 제2 소음 그룹의 소음 데이터가 반영된 상기 적어도 하나의 제2 음성 데이터에 기반하여 상기 특정 언어의 음성을 획득하기 위한 제2 인공지능 모델을 생성하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 상기 제1 소음 및 상기 제2 소음을 반영하는 동작은, 제1 소음 그룹에 대응하는 복 수의 제1 하위 소음 데이터들을 획득하고, 상기 복수의 제1 소음 데이터들 중 적어도 하나의 소음 데이터를 상 기 적어도 하나의 제1 음성 데이터에 반영하는 동작; 및 제2 소음 그룹에 대응하는 복수의 제2 하위 소음 데이 터들을 획득하고, 상기 복수의 제2 소음 데이터들 중 적어도 하나의 소음 데이터를 상기 적어도 하나의 제2 음 성 데이터에 반영하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 상기 제1 소음 그룹은 제1 환경 그리고 상기 제2 소음 그룹은 제2 환경에 대응하고, 상기 복수의 제1 하위 노이즈 데이터들 각각은 상기 제1 환경 내에서 발생 가능한 서로 다른 종류의 소음에 대 응하고, 상기 복수의 제2 하위 노이즈 데이터들 각각은 상기 제2 환경 내에서 발생 가능한 서로 다른 종류의 소 음에 대응하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 상기 음성학적 특성은 주파수 별 세기를 나타내고, 서로 다른 성별 또는 연령을 갖 는 발화자들의 상기 특정 언어의 상기 특정 단위의 발화에 기반하여, 상기 특정 언어의 복수의 음성 데이터들을 획득하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 상기 제1 인공 지능 모델을 생성하는 동작은, 제1 시간에 반영되는 상기 적어도 하 나의 제1 음성 데이터, 상기 제1 시간의 이전인 제2 시간 및/또는 이후인 제3 시간에 반영되는 빈-사운드 데이터, 및 상기 제1 시간에 반영되는 상기 제1 종류의 소음을 포함하는 입력 데이터를 획득하는 동작; 상기 제1 시 간에 반영되는 상기 적어도 하나의 제1 음성 데이터를 포함하는 아웃풋 데이터를 획득하는 동작; 및 상기 입력 데이터 및 상기 아웃풋 데이터에 기반하여 학습을 수행함으로써, 상기 제1 인공 지능 모델을 생성하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 전자 장치의 동작 방법에 있어서, 복수의 AI 모델들을 획득하는 동작;을 포함하고, 상기 복수의 AI 모델들 각각은 상기 서로 다른 소음 그룹에 대응하는 소음 데이터를 포함하는 사운드 데이터가 입력되는 경우, 상기 사운드 데이터에 포함된 음성을 제공하도록 구현되고, 특정 하위의 소음이 반영된 특정 언 어의 음성을 포함하는 사운드 데이터를 획득하는 동작; 복수의 소음 그룹들 중 상기 특정 하위의 소음을 포함하 는 특정 소음 그룹을 선택하는 동작; 및 상기 복수의 AI 모델들 중 상기 선택된 특정 소음 그룹에 대응하는 특 정 AI 모델에 기반하여, 상기 특정 하위의 소음이 반영된 상기 사운드 데이터로부터 상기 특정 언어의 음성의 적어도 일부를 획득하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 상기 복수의 소음 그룹들 각각은 상기 전자 장치가 위치되어 사운드를 수신 가능한 서로 다른 환경에 대응하고, 상기 복수의 소음 그룹들 각각과 연관된 적어도 하나의 하위의 소음은 상기 서로 다른 환경에서 발생 가능한 종류의 소음을 포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 상기 특정 소음 그룹을 선택하는 동작은, 상기 획득된 사운드 데이터에 대한 분석에 기반하여, 복수의 하위의 소음 데이터들을 식별하는 동작; 및 복수의 소음 그룹들 중 식별된 상기 복수의 하위 의 소음 데이터들 중 가장 많은 수의 소음 데이터를 포함하는 상기 특정 그룹을 선택하는 동작;을 포함하는, 동 작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 상기 특정 소음 그룹을 선택하는 동작은, 상기 복수의 소음 그룹들에 대응하는 복수 의 환경들을 나타내는 복수의 그래픽 오브젝트들을 포함하는 실행 화면을 표시하는 동작; 및 상기 복수의 그래 픽 오브젝트들 중 선택된 그래픽 오브젝트에 대응하는 상기 특정 소음 그룹을 식별하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 전자 장치의 동작 방법에 있어서, 특정 언어의 복수의 음성 데이터들을 획득하는 동 작;을 포함하고, 상기 복수의 음성 데이터들 중 일부는 상기 특정 언어의 특정 단위의 발화에 대응하되, 서로 다른 음성학적 특성을 갖고, 상기 복수의 음성 데이터들 별로 서로 다른 그룹의 소음 데이터를 반영하는 동작; 상기 서로 다른 그룹의 소음 데이터가 반영된 상기 복수의 음성 데이터들에 기반하여, 복수의 인공지능 모델들 을 생성하는 동작;을 포함하고, 상기 복수의 인공지능 모델들 각각은 상기 서로 다른 그룹의 소음 데이터를 포 함하는 사운드 데이터가 입력되는 경우, 상기 사운드 데이터에 포함된 음성을 제공하도록 구현되고, 특정 소음 그룹이 선택되는 경우, 상기 복수의 인공지능 모델들 중 상기 선택된 특정 소음 그룹에 대응하는 특정 인공지능 모델이 이용되도록 설정되는, 동작 방법이 제공될 수 있다. 1. 자막 제공 시스템에 대한 개요 다양한 실시예들에 따르면, 자막 제공 시스템은, 다양한 환경에서 수신되는 사운드로부터 음성을 획득하고, 획 득된 음성에 대한 적어도 하나의 텍스트를 제공하는 시스템으로 정의될 수 있다. 이에 따라 자막 제공 시스템은, 음성을 인식하기에 어려운 청각 장애인과 같은 사용자로 하여금, 텍스트를 통해 다양한 환경에서 수 신되는 음성에 대해 이해할 수 있도록 함으로써, 삶의 질을 향상시킬 수 있다. 이때, 자막 제공 시스템은, 제공 되는 텍스트의 정확도를 향상시키기 위해, 수신되는 사운드에 대해서 전-처리(pre-processing)하는 동작을 수행 할 수 있는데, 전-처리 동작에 대해서는 이하에서 더 구체적으로 기술한다. 2. 자막 제공 시스템의 구성 도 1은, 다양한 실시예들에 따른, 자막 제공 시스템의 구성의 예를 설명하기 위한 도면이다. 이하에서는, 도 2 를 참조하여, 도 1에 대해서 더 설명한다. 도 2는, 다양한 실시예들에 따른, 다양한 환경에서 사운드가 수신되는 예를 나타내는 도면이다. 다양한 실시예들에 따르면, 도 2를 참조하면, 자막 제공 시스템은, 전자 장치, 및 서버를 포함할 수 있다. 도 2에 도시된 및/또는 기재된 예에 제한되지 않고, 자막 제공 시스템은 더 많은 장치를 포함하거나, 또는 더 적은 장치를 포함하도록 구현될 수도 있다. 예를 들어, 특정 장치(예: 서버)가 구현되지 않고, 특정 장치(예: 서버)에서 수행되는 동작들이 모두 다른 장치(예: 전자 장치)에서 수행되도록 온-디바이스 (on-device) 형태로 구현되는 자막 제공 시스템이 제공될 수 있다. 일 예로 서버가 구현되지 않는 경우, 도 3b를 참조하여 후술되는, 프로그램의 기능(또는 일부 모델, 및/또는 모듈) 모두가 전자 장치에서 수행되도록 구현될 수 있다. 다양한 실시예들에 따르면, 전자 장치는, 외부 환경(C)에서 수신되는 사운드(S)에 포함된 음성에 대응하는 텍스트(T)를 제공할 수 있다. 예를 들어, 도 1 및 도 2를 참조하면, 상기 외부 환경(C)은 교실 및/또는 강의 환 경(C1), 지하철과 같은 교통 수단 환경(C2) 등의 다양한 환경을 포함하며, 도시된 및/또는 기재된 예에 제한되 지 않고, 음성이 발생될 수 있는 다양한 종류의 환경을 더 포함할 수 있다. 예를 들어, 전자 장치는 상기 다양한 환경(C1, C2) 별로 수신되는 사운드에 포함된 음성에 대응하는 텍스트(T)(또는 자막)를 표시하는 동작을 수행할 수 있는데, 구체적인 동작의 예에 대해서는 후술한다. 다양한 실시예들에 따르면, 서버는, 전자 장치로부터 수신되는 사운드(S)를 처리하기 위한 적어도 하 나의 동작을 수행할 수 있다. 예를 들어, 상기 적어도 하나의 동작은, 사운드(S)에 대한 전-처리를 수행하는 동 작, 사운드(S)로부터 음성을 획득(또는 노이즈를 제거)하는 동작, 및 음성에 대응하는 텍스트를 생성하는 동작 을 포함할 수 있다. 상기 적어도 하나의 동작 중 일부가 서버에서 수행되는 경우, 다른 일부의 동작은 전 자 장치에서 수행되도록 구현될 수 있다. 한편, 상기 적어도 하나의 동작 모두가 서버에서, 또는 전 자 장치에서 수행되도록 구현될 수도 있다. 2.1. 전자 장치의 구성 이하에서는, 다양한 실시예들에 따른, 전자 장치의 구성의 예들에 대해서 설명한다. 도 3a는, 다양한 실시예들에 따른, 전자 장치의 구성의 예를 나타내는 도면이다. 이하에서는, 도 3b를 참 조하여, 도 3a에 대해서 설명한다. 도 3b는, 다양한 실시예들에 따른, 프로그램의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 도 3a를 참조하면, 전자 장치는, 마이크, 디스플레이, 통신 회로 , 프로세서, 및 메모리를 포함할 수 있다. 다만, 기재된 및/또는 도시된 예에 제한되지 않고, 전자 장치는 더 많은 장치들을 포함하거나, 및/또는 더 적은 장치들을 포함하도록 구현될 수도 있다. 다양한 실시예들에 따르면, 마이크는, 사운드를 수신하도록 구현될 수 있다. 다양한 실시예들에 따르면, 디스플레이는, 예를 들면, 디스플레이, 홀로그램 장치, 또는 프로젝터 및 해당 장치를 제어하기 위한 제어 회로를 포함할 수 있다. 일 실시예에 따르면, 디스플레이는 터치를 감지하도록 설정된 터치 회로(touch circuitry), 또는 상기 터치에 의해 발생되는 힘의 세기를 측정하도록 설정된 센서 회 로(예: 압력 센서)를 포함할 수 있다. 상기 디스플레이는 그래픽 유저 인터페이스(graphic user interface, GUI)를 표시하도록 구현될 수 있다. 예를 들어, 디스플레이는 프로그램(또는 어플리케이 션)의 실행 화면을 표시할 수 있다. 상기 프로그램의 실행 화면은 음성에 대응하는 텍스트를 포함할 수 있 다. 다양한 실시예들에 따르면, 통신 회로는, 전자 장치와 외부 전자 장치(예: 서버)간의 무선 통신 채널의 수립 및 수립된 통신 채널을 통한 통신 수행을 지원할 수 있다. 상기 통신 회로는 프로세서와 독립적으로 운영되고, 무선 통신을 지원하는 하나 이상의 커뮤니케이션 프로세서를 포함하도록 구현될 수도 있 다. 다양한 실시예들에 따르면, 프로세서는 예를 들면, 소프트웨어를 실행하여 프로세서에 연결된 전자 장치의 적어도 하나의 다른 구성요소(예: 하드웨어 또는 소프트웨어 구성요소)를 제어할 수 있고, 다양한 데이터 처리 또는 연산을 수행할 수 있다. 상기 프로세서의 동작의 예에 대해서는 더 후술한다. 일 실시예 에 따르면, 데이터 처리 또는 연산의 적어도 일부로서, 프로세서는 다른 구성요소로부터 수신된 명령 또는 데이터를 휘발성 메모리에 로드하고, 휘발성 메모리에 저장된 명령 또는 데이터를 처리하고, 결과 데이터를 비 휘발성 메모리에 저장할 수 있다. 일 실시예에 따르면, 프로세서는 메인 프로세서(예: 중앙 처리 장치 또 는 어플리케이션 프로세서), 및 이와는 독립적으로 또는 함께 운영 가능한 보조 프로세서 (예: 그래픽 처리 장 치, 이미지 시그널 프로세서, 센서 허브 프로세서, 또는 커뮤니케이션 프로세서)를 포함할 수 있다. 추가적으로또는 대체적으로, 보조 프로세서는 메인 프로세서보다 저전력을 사용하거나, 또는 지정된 기능에 특화되도록 설 정될 수 있다. 보조 프로세서는 메인 프로세서와 별개로, 또는 그 일부로서 구현될 수 있다. 다양한 실시예들에 따르면, 프로세서는 메모리에 저장된 프로그램(또는 어플리케이션, 또는 컴 퓨터 코드(computer code), 또는 인스트럭션들(instructions))에 기반하여, 적어도 하나의 동작을 수행할 수 있 다. 예를 들어 도 3b를 참조하면, 상기 프로그램이 실행되는 경우, 상기 프로세서가 적어도 하나의 동작을 수행하도록 구현될 수 있다. 이하에서, 전자 장치의 동작은, 특별한 언급이 없다면, 프로그램(35 0)이 실행되는 경우 수행되는 프로세서의 동작으로 이해될 수 있으나, 기재된 예에 제한되지는 않는다. 다양한 실시예들에 따르면, 메모리는 전자 장치의 적어도 하나의 구성요소(예: 프로세서)에 의 해 사용되는 다양한 데이터를 저장할 수 있다. 예를 들어, 메모리는 프로그램을 저장할 수 있다. 다양한 실시예들에 따르면, 프로그램은 음성 획득 모델, 그룹 식별 모델, 및 자막 생성 모듈 을 포함할 수 있다. 다시 말해, 프로그램에 포함되는 각각의 모델들 및 모듈이 실행되는 경우, 프로 세서는 그에 대응하는 동작을 수행할 수 있다. 예를 들어, 상기 음성 획득 모델은, 마이크를 이용하여 수신된 사운드(S)에 기반하여 음성 데이터를 획득하도록 구현될 수 있다. 이때, 음성 획득 모델은 식별된 소은 그룹에 기반하여, 음성 데이터를 획득하 도록 구현될 수 있다. 예를 들어, 상기 음성 획득 모델은 디-노이즈 디먹스(de-noise demucs) 구조의 모델 일 수 있다. 예를 들어, 상기 그룹 식별 모델은, 수신된 사운드(S)에 기반하여 사운드(S)와 연관된 소음 그룹을 식별하 도록 구현될 수 있다. 상기 소음 그룹은 적어도 두 개 이상 존재하며, 복수의 소음 그룹들 각각은 적어도 하나 의 하위 소음을 포함하는 개념으로 이해될 수 있다. 예를 들어, 상기 소음 그룹은 사운드가 발생되는 환경(C)에 대응할 수 있다. 전술한 음성 획득 모델 및 그룹 식별 모델은 인공 지능 학습 알고리즘에 기반하여, 구현되는 인공 지 능 모델일 수 있으나, 기재된 예에 제한되지는 않고, 음성 데이터 획득 기능을 수행하도록 구현된 프로그램 및 소음 그룹 식별 기능을 수행하도록 구현되는 프로그램일 수도 있다. 예를 들어, 상기 자막 생성 모듈은, 상기 획득된 음성 데이터에 기반하여 텍스트를 생성하도록 구현될 수 있다. 상기 자막 생성 모듈 또한 인공 지능 학습 알고리즘에 기반하여, 구현되는 인공 지능 모델일 수 있으나, 기재된 예에 제한되지 않고, STT(speech to text) 기능을 수행하도록 구현되는 프로그램일 수도 있다. 2.2 서버의 구성 한편, 기재 및/또 도시되지 않았으나, 서버는 상기 전자 장치의 구성들(예: 디스플레이, 통신 회로, 프로세서, 및 메모리)을 포함하도록 구현될 수 있으며, 중복되는 설명은 생략한다. 다양한 실시예들에 따르면, 프로그램의 적어도 일부는 전자 장치에 구현되고, 다른 나머지 일부는 서 버에 구현됨에 따라, 전자 장치와 서버 서버 각각에서 해당하는 동작이 수행될 수 있으나, 기재 된 예에 제한되지 않고 프로그램의 모두가 특정 장치(예: 전자 장치, 또는 서버)에 구현될 수도 있음은, 당업자에게 자명하다. 3. 자막 제공 시스템의 동작 방법 이하에서는, 다양한 실시예들에 따른 자막 제공 시스템의 동작의 예에 대해서 설명한다. 특별한 언급이 없다면, 이하에서 기술되는, 전자 장치의 동작은 서버의 동작으로 구현되거나, 서버 의 동작은 전자 장치의 동작으로 구현될 수 있음은, 당업자에게 자명하다. 이하에서 기술되는 동작들 각각은 서로 조합되어 수행될 수 있다. 아울러, 이하에서 기술되는 &quot;데이터&quot;는 &quot;신호&quot;의 의미로 해석될 수 있으며, 아날로그 데이 터 및 디지털 데이터 모두를 포함하는 개념으로 이해될 수 있다.3.1. 음성 획득 모델 생성 동작 도 4는, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 음성 획득 모델 을 생성하는 동작의 예를 설명하기 위한 흐름도이다. 다양한 실시예들에 따르면, 도 4에 도시되는 동작들은 도 시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면 도 4에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 도 5a는, 다양한 실시예들에 따른, 서버의 특정 언어의 복수의 특성들 별 음성 데이터를 생성하는 동작의 예를 설명하기 위한 도면이다. 도 5b는, 다양한 실시예들에 따른, 서버의 복수의 환경들에 대응하는 복수 의 소음 그룹들 별 소음 데이터를 생성하는 동작의 예를 설명하기 위한 도면이다. 도 6a는, 다양한 실시예들에 따른, 서버의 음성 데이터 및 소음 데이터에 기반하여 사운드 데이터를 생성하는 동작의 예를 설명하기 위 한 도면이다. 도 6b는, 다양한 실시예들에 따른, 서버의 음성 데이터 및 사운드 데이터에 기반하여 음성 획득 모델을 생성하는 동작의 예를 설명하기 위한 도면이다. 도 6c는, 다양한 실시예들에 따른, 음성 획득 모델 의 예를 설명하기 위한 도면이다. 이하에서는, 도 5 내지 도 6을 참조하여, 도 4에 대해서 더 설명한다. 다양한 실시예들에 따르면, 서버는, 동작 401에서, 특정 단위(예: 단어, 문장, 단락 등)의 특정 언어의 복 수의 특성들 별 복수의 음성 데이터를 획득할 수 있다. 예를 들어, 도 5a를 참조하면, 서버는 복수의 언어 들 중 특정 언어(예: 한글)에 대해서, 복수의 특성 그룹들(예: 연령(또는 나이)(520a), 성별(520b)) 별로 선택되는 특정 특성의 특정 단위의 음성 데이터(예: 제1 음성 데이터(530a), 제2 음성 데이터(530b), 및 제3 음 성 데이터(530c))를 획득하는 동작을 수행할 수 있다. 예를 들어, 도 5a를 참조하면, 서버는 한글에 대해 서, 연령(520a) 중 제1 연령 그리고 성별(520b) 중 남성의 음성 데이터를 획득할 수 있으며, 기재된 예에 제한 되지 않고 다양한 특성 별 음성 데이터를 획득 수 있다. 다양한 실시예들에 따르면, 상기 복수의 특성 그룹들은, 음성학적인 특성을 의미하며, 예를 들면, 상기 복수의 특성들 그룹들 각각은 특정 단위의 음성에 대해서 주파수 별 세기를 결정하는 팩터(또는 요인, 또는 요소)를 의 미할 수 있다. 이는, 해당 특성 그룹들 별로 특성이 달라지는 경우(예: 연령(520a)의 서로 다른 연령 별로) 성 도의 위치가 상이함에 기인하여, 주파수 별 세기가 결정되기 때문일 수 있다. 한편 기재된 및/또는 도시된 예에 제한되지 않고, 상기 복수의 특성들은 연령(520a) 및 성별(520b) 이외에도, 음성의 주파수 별 세기에 영향을 주 는 다양한 팩터를 포함할 수 있다. 다양한 실시예들에 따르면, 서버는 음성 데이터를 획득하는 동작의 적어도 일부로, 전술한 특성 그룹들 별 특성에 대응하는 사람들로 하여금 특정 단위의 특정 언어의 음성을 발화함에 기반하여 마이크를 이용하여 수집 되는 음성 데이터를 획득하는 동작을 수행할 수 있다. 다양한 실시예들에 따르면, 서버는, 동작 403에서, 복수의 음성 데이터들에 복수의 종류들 별 소음 데이터 를 추가함으로써, 복수의 합성 사운드 데이터를 획득할 수 있다. 예를 들어, 서버는, 도 5b에 도시된 바와 같이, 복수의 소음 그룹들(예: 제1 소음 그룹(G1), 및 제2 소음 그룹(G2)) 별 소음 데이터(560a, 560b, 560c) 를 획득하는 동작을 수행하고, 도 6a에 도시된 바와 같이, 상기 복수의 소음 그룹들(예: 제1 소음 그룹(G1), 및 제2 소음 그룹(G2)) 별 소음 데이터(560a, 560b, 560c)를 획득된 복수의 음성 데이터들(예: 제1 음성 데이터 (530a)) 별로 추가함으로써, 복수의 합성 사운드 데이터(예: 제1 사운드 데이터(600a), 제2 사운드 데이터 (600b), 제3 사운드 데이터(600c))를 생성하는 동작을 수행할 수 있다. 상기 서버의 합성 사운드 데이터를 생성하는 동작의, 구체적인 예에 대해서는, 도 7 내지 도 8을 참조하여 후술한다. 다양한 실시예들에 따르면, 도 5b를 참조하면, 소음 그룹(G1, G2)은 복수의 환경들(예: 교실(550a), 지하 철(550b))에 대응할 수 있다. 예를 들어, 복수의 환경들(예: 교실(550a), 지하철(550b)) 별로 그에 대응하는 종 류의 소음이 발생될 수 있다. 일 예로, 교실(550a)의 경우 발생 가능한 소음은, 떠드는 소리, 책 넘기는 소리, 및 필기소리를 포함하고, 지하철(550b)의 경우 발생 가능한 소음은, 문 닫히는 소리, 문 열리는 소리, 및 덜컹 거리는 소리를 포함할 수 있으나, 기재된 예에 제한되지는 않는다. 이때, 상기 소음 그룹(G1, G2)은 상기 복수 의 환경들(예: 교실(550a), 지하철(550b)) 별로 발생 가능한 종류의 소음을 포함(또는 분류)하기 위한 개념일 수 있다. 이때, 소음 그룹(G1, G2)는 상위 소음으로 정의되고, 소음 그룹에 포함되는 소음 종류들은 하위 소음 으로 정의될 수도 있다. 서버는 상기 소음 그룹(G1, G2) 별 하위의 소음 데이터를 획득하는 동작의 적어도 일부로, 마이크를 이용하여 소음 그룹(G1, G2)에 대응하는 환경(예: 교실(550a), 지하철(550b)) 별로 수집되는 사운드 데이터를 획득하고, 획득된 사운드 데이터로부터 소음 데이터를 획득하는 동작을 수행할 수 있으나, 기재된 예에 제한되지 않는다. 다양한 실시예들에 따르면, 도 6b를 참조하면, 서버에 의해 생성된, 복수의 합성 사운드 데이터(예: 제1 사운드 데이터(600a), 제2 사운드 데이터(600b), 제3 사운드 데이터(600c))는, 소음 그룹(G1, G2)에 대응하는 그룹으로 분류될 수 있다. 예를 들어, 제1 소음 그룹(G1)에 포함된 제1 소음 데이터(560a) 및 제2 소음 데이터 (560b)에 기반하여 생성된 제1 사운드 데이터(600a) 및 제2 사운드 데이터(600b)는 제1 소음 그룹(G1)으로 분류 되고, 제2 소음 그룹(G2)에 포함된 제3 소음 데이터(560c)에 기반하여 생성된 제3 사운드 데이터(600c)는 제2 소음 그룹(G2)으로 분류될 수 있다. 다양한 실시예들에 따르면, 서버는, 동작 405에서, 복수의 합성 사운드 데이터(예: 제1 사운드 데이터 (600a), 제2 사운드 데이터(600b), 및 제3 사운드 데이터(600c)) 각각 및 복수의 합성 사운드 데이터(예: 제1 사운드 데이터(600a), 제2 사운드 데이터(600b), 및 제3 사운드 데이터(600c)) 각각에 대응하는 복수의 음성 데 이터(예: 제1 음성 데이터(530a)) 각각에 기반하여, 음성 획득 모델을 생성할 수 있다. 예를 들어, 서버 는 음성 획득 모델을 생성하기 위한 트레이닝 데이터(예: 입력 데이터 및 출력 데이터)로서, 합성 사 운드 데이터 및 그에 대응하는 음성 데이터를 획득할 수 있다. 즉, 도 6b에 도시된 바와 같이, 서버는 입 력 데이터로서 합성 사운드 데이터(예: 제1 사운드 데이터(600a), 제2 사운드 데이터(600b), 제3 사운드 데이터 (600c))를 획득하고, 출력 데이터로서 합성 사운드 데이터(예: 제1 사운드 데이터(600a), 제2 사운드 데이터 (600b), 제3 사운드 데이터(600c))를 생성하기 위해 이용한 음성 데이터(예: 제1 음성 데이터(530a))를 획득할 수 있다. 서버는 상기 획득된 트레이닝 데이터에 기반하여, 학습 알고리즘(L)에 기반하여 학습을 수행함으 로써, 사운드 데이터(S)가 입력되는 경우 음성 데이터(U)를 출력하도록 구현되는 음성 획득 모델을 생성할 수 있다. 또는, 기재된 예에 제한되지 않고, 서버는 상기 획득된 트레이닝 데이터에 기반하여, 학습 알고 리즘(L)에 기반하여 학습을 수행함으로써, 사운드 데이터(S)가 입력되는 경우, 소음이 저감되거나 및/또는 제거 된 사운드 데이터를 출력하도록 구현되는 음성 획득 모델을 생성할 수 있다. 상기 학습 알고리즘(L)은 ANN(artificial neural network), CNN(convolution neural network), DNN(deep neural network), RNN(recurrent neural network) 등과 같은 인공 신경망 학습 알고리즘, 및 지도 학습 알고리즘, 비지도학습 알 고리즘 등과 같은 머신러닝 알고리즘을 포함할 수 있으며, 이는 당업자에게 자명하므로, 더 구체적인 설명은 생 략한다. 다양한 실시예들에 따르면, 서버는 상기 트레이닝 데이터를 획득하는 동작의 일부로, 소음 그룹(G1, G2) 별로 트레이닝 데이터를 획득하고 학습을 수행하는 동작을 수행할 수 있다. 예를 들어, 도 6b에 도시된 바와 같 이, 서버는 제1 소음 그룹(G1)과 연관된 사운드 데이터(예: 제1 사운드 데이터(600a), 및 제2 사운드 데이 터(600b))와 이에 대응하는 제1 음성 데이터(530a)를 트레이닝 데이터로 하여 학습을 수행하고, 제2 소음 그룹 (G2)과 연관된 사운드 데이터(예: 제3 사운드 데이터(600c))와 이에 대응하는 제1 음성 데이터(530a)를 트레이 닝 데이터로 하여 학습을 수행할 수 있다. 상기 서버의 소음 그룹(G1, G2) 별 학습의 수행에 기반하여, 도 6c의 (a)에 도시된 바와 같이, 음성 획득 모델은 각각이 서로 다른 소음 그룹과 연관된 사운드 데이터를 수신하는 경우 음성 데이터를 출력하도록 구현되는 복수의 인공 지능 모델들(예: 제1 인공지능 모델(351a), 제2 인공지능 모델(351b))를 포함하도록 구현될 수 있다. 후술하겠으나, 복수의 인공 지능 모델들(예: 제1 인공지능 모델(351a), 제2 인공지능 모델(351b))의 이용 시, 소음 그룹(G1, G2)의 선택에 따라서 복수의 인공 지능 모델 들(예: 제1 인공지능 모델(351a), 제2 인공지능 모델(351b)) 중 선택된 소음 그룹에 대응하는 특정 인공 지능 모델이 선택되어 이용될 수 있는데, 이에 대해서는 후술한다. 또, 기재된 예에 제한되지 않고, 도 6c의 (b)에 도시된 바와 같이, 상기 음성 획득 모델은 앙상블(ensemble) 형태의 단일의 인공 지능 모델(351c)로서 구 현될 수도 있다. 상기 앙상블(ensemble) 형태의 단일의 인공 지능 모델(351c)은, 소음 그룹의 선택과는 무관하 게, 사운드 데이터를 수신하는 것에 기반하여, 음성 데이터를 출력하도록 구현될 수 있다. 상기 앙상블 (ensemble) 형태의 단일의 인공 지능 모델(351c)은 사운드 데이터와 함께, 소음 그룹(G1, G2) 별 가중치를 수신 함에 기반하여, 음성 데이터를 출력하도록 구현될 수 있는데, 이에 대해서는 후술한다. 3.1.1. 합성 사운드 데이터 생성 동작 도 7은, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 합성 사운드 데 이터를 생성하는 동작의 예를 설명하기 위한 흐름도이다. 다양한 실시예들에 따르면, 도 7에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면 도 7에 도시되 는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다.도 8은, 다양한 실시예들에 따른, 서버에 의해 획득되는 합성 사운드 데이터 및 음성 데이터의 예를 설명 하기 위한 도면이다. 이하에서는, 도 8을 참조하여, 도 7에 대해서 더 설명한다. 다양한 실시예들에 따르면, 서버는, 동작 701에서, 환경에 대응하는 하위의 소음 데이터들을 획득할 수 있 다. 예를 들어, 전술한 바와 같이, 서버는 환경 별로 소음 데이터를 수집할 수 있으며, 환경 별로 수 집된 소음 데이터는 소음 그룹 별로 분류될 수 있다. 중복되는 설명은 생략한다. 다양한 실시예들에 따르면, 서버는, 동작 703에서, 특정 언어의 음성 데이터 및 상기 획득된 서브 소음 데 이터를 합성함으로써, 특정 조건을 만족하는 합성 사운드 데이터를 생성할 수 있다. 예를 들어, 도 8을 참조하 면, 서버는 합성 사운드 데이터(800a)를 생성하는 동작의 적어도 일부로, 음성 데이터의 전후로 지정 된 시간(△t1, △t3) 만큼의 빈 사운드 데이터를 포함하고, 음성 데이터가 존재하는 시간(△t2)에 중첩되 도록 소음 데이터를 추가함으로써, 합성 사운드 데이터(800a)를 생성할 수 있다. 상기 빈 사운드 데이터 는 어떤 소리도 재생되지 않는 데이터를 의미하거나, 및/또는 데이터 자체가 없는 것을 의미할 수 있다. 이때, 상기 소음 데이터는 빈 사운드 데이터가 존재하는 시간(△t1, △t3)의 적어도 일부 시간에 추가될 수 있으나, 기재된 및/또는 도시된 예에 제한되지 않고, 빈 사운드 데이터가 존재하는 시간(△t1, △t3)에 소음 데이터가 추가되지 않을 수도 있다. 서버는 상기 합성 사운드 데이터(800a)에 대응하는 음성 데이터 (800b)로서, 빈 사운드 데이터와 소음 데이터를 추가하지 않고 합성 사운드 데이터(800a)의 음성 데 이터에 대응하는 시간(△t2)에 배치되는 음성 데이터를 획득할 수 있으나, 기재된 및/또는 도시된 예 에 제한되지 않는다. 3.2. 소음 전처리에 기반한 음성에 대응하는 텍스트 제공 동작 도 9는, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 합성 사운드 데 이터를 생성하는 동작의 예를 설명하기 위한 흐름도이다. 다양한 실시예들에 따르면, 도 9에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면 도 9에 도시되 는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 도 10은, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 텍스트를 생성 하는 동작의 예를 설명하기 위한 도면이다. 도 11은, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 다양한 환경에서 수신되는 사운드 데이터에 기반하여 텍스트를 제공하는 동작의 예 를 설명하기 위한 도면이다. 도 12는, 다양한 실시예들에 따른, 소음 그룹의 선택 동작의 예를 설명하기 위한 도면이다. 이하에서는, 도 10 내지 도 12를 참조하여, 도 9에 대해서 더 설명한다. 다양한 실시예들에 따르면, 전자 장치(또는 서버)는, 동작 901에서, 적어도 하나의 인공지능 모델을 획득할 수 있다. 예를 들어, 상기 적어도 하나의 인공 지능 모델은, 전술한 사운드 데이터를 수신한 것에 기반 하여 음성 데이터를 출력하도록 구현되는 음성 획득 모델을 포함할 수 있다. 다양한 실시예들에 따르면, 전자 장치(또는 서버)는, 동작 903에서, 적어도 하나의 특정 하위의 소음 이 반영된 특정 언어의 음성을 포함하는 사운드 데이터를 획득할 수 있다. 예를 들어, 전자 장치는, 마이 크를 이용하여 복수의 환경들(예: 도 11의 (a)의 교실(C1), 도 11의 (b)의 지하철(C2)) 중 특정 환경에서 발생되는 사운드를 수신함에 따라, 사운드 데이터를 획득할 수 있다. 도 10을 참조하면, 상기 특정 환경(C)은 소음원(N)과 발화자(P)를 포함하며, 이에 따라 상기 특정 환경(C) 내의 전자 장치는 마이크를 이용하 여 특정 환경(C)의 소음원(N)으로부터 발생된 소음 및 발화자(P)의 특정 언어(예: 한글)의 음성을 포함하는 사 운드를 수신할 수 있다. 상기 특정 환경(C) 별로 소음원(N)이 상이하며, 이에 따라 특정 환경(C) 별로 획득 가 능한 하위 소음의 종류는 서로 상이할 수 있다. 일 예로, 도 11의 (a)를 참조하면, 교실(C1) 내의 학생은, 전자 장치를 이용하여 교실(C1)에 존재하는 발화자인 선생님의 음성과 교실(C1) 내의 다양한 소음원들(예: 책) 로부터 발생되는 소음을 포함하는 사운드를 수신할 수 있다. 전자 장치는, 도 10에 도시된 바와 같이, 사 운드 처리 모듈를 이용하여 수신된 사운드를 처리함으로써, 사운드 데이터를 획득할 수 있으나, 기재된 및/또는 도시된 예에 제한되지 않는다. 상기 사운드 처리 모듈의 동작은 아날로그 신호를 데이터로 변환 하는 동작, 및/또는 수신된 신호 또는 획득된 신호의 특성(예: 세기 등)을 조절하는 동작을 포함할 수 있다. 다양한 실시예들에 따르면, 전자 장치(또는 서버)는, 동작 905에서, 상기 적어도 하나의 특정 하위의 소음을 포함하는 특정 그룹(예: 소음 그룹)을 선택할 수 있다. 예를 들어, 도 10에 도시된 바와 같이, 전자 장 치는, 그룹 관련 정보를 기반으로 음성 데이터를 획득하기 위해 음성 획득 모델을 이용할 수 있다.일 예로, 상기 그룹 관련 정보는 선택된 소음 그룹에 대한 정보를 포함할 수 있다. 일 실시예에서, 전자 장치 는 사용자의 선택에 기반하여, 특정 그룹을 선택할 수 있다. 예를 들어, 도 12의 (a)를 참조하면, 전자 장 치는, 복수의 환경들(예: 제1 환경(1201a), 및 제2 환경(1203a)) 중에서 특정 환경을 선택하기 위한 인터 페이스를 제공하고, 복수의 환경들(예: 제1 환경(1201a), 및 제2 환경(1203a)) 중 특정 환경이 선택되는 경우 선택된 특정 환경에 대응하는 소음 그룹(예: 제1 소음 그룹)을 선택할 수 있다. 또 일 실시예에서, 전자 장치 는, 획득된 사운드 데이터를 분석함에 기반하여, 소음 그룹을 선택할 수 있다. 예를 들어, 도 12의 (b)를 참조하면, 전자 장치는, 소음 그룹 식별 모델을 이용하여 사운드 데이터를 분석함에 기반하여, 사운 드 데이터에 포함된 하위 소음들(예: 제1 하위 소음, 제2 하위 소음, 제3 하위 소음)에 대한 정보(1200b)를 획 득할 수 있다. 전자 장치는 복수의 소음 그룹들 중에서 상기 하위 소음들을 포함하는 소음 그룹(예: 제1 소음 그룹)을 선택할 수 있다. 상기 하위 소음들(예: 제1 하위 소음, 제2 하위 소음, 제3 하위 소음)의 소음 그 룹이 서로 다른 경우, 전자 장치는, 가장 많은 수의 하위 소음을 식별하고, 식별된 하위 소음을 포함하는 소음 그룹을 선택할 수도 있다. 한편, 기재된 및/또는 도시된 예에 제한되지 않고, 그룹 관련 정보는 실시간으 로 선택되는 소음 그룹에 대한 정보, 및/또는 소음 그룹 별 가중치에 대한 정보를 포함할 수 있는데, 이에 대해 서는 후술한다. 다양한 실시예들에 따르면, 전자 장치(또는 서버)는, 동작 907에서, 상기 선택된 특정 그룹 및 상기 적어도 하나의 인공 지능 모델에 기반하여, 상기 특정 하위의 소음이 반영된 상기 사운드 데이터로부터 상기 특 정 언어의 음성의 적어도 일부를 획득할 수 있다. 예를 들어, 도 10에 도시된 바와 같이, 전자 장치는, 그 룹 관련 정보에 기반하여 음성 획득 모델에 사운드 데이터를 입력함으로써, 음성 획득 모델로부터 출 력되는 음성 데이터를 획득할 수 있다. 즉, 전자 장치는 상기 음성 획득 모델을 이용하여, 사운드 데 이터로부터 소음 데이터가 제거 및/또는 저감된 음성 데이터를 획득할 수 있다. 상기 음성 획득 모델은, &quot;3.1 목차&quot;에서 전술한 바와 같이, 구현될 수 있으므로 더 구체적인 설명은 생략한다. 다양한 실시예들에 따르면, 전자 장치는, 도 10을 참조하면, 자막 생성 모듈을 이용하여 획득된 특정 언어의 음성의 적어도 일부에 대응하는 적어도 하나의 텍스트틀 생성하고, 생성된 적어도 하나의 텍스트를 디스 플레이 상에 표시할 수 있다. 사용자는 상기 디스플레이 상에 표시되는 텍스트를 시인하고, 특정 환 경 내에서 발생되는 발화에 대해서 이해할 수 있게 된다. 3.2.1. 사운드 데이터 전-처리 동작 도 13은, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 합성 사운드 데 이터를 생성하는 동작의 예를 설명하기 위한 흐름도이다. 다양한 실시예들에 따르면, 도 13에 도시되는 동작들 은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면 도 13에 도 시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 도 14는, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 텍스트를 생성 하는 동작의 예를 설명하기 위한 도면이다. 이하에서는, 도 14를 참조하여, 도 13에 대해서 더 설명한다. 다양한 실시예들에 따르면, 전자 장치는, 동작 1301에서, 사용자와 발화자 사이의 거리에 대한 정보를 획 득할 수 있다. 예를 들어, 전자 장치는 특정 환경(C) 내에서의 사용자의 제1 위치에 대한 정보 및 발화자 (P)의 제2 위치에 대한 정보를 획득하고, 상기 제1 위치 및 상기 제2 위치에 기반하여 사용자와 발화자(P) 사이 의 거리에 대한 정보를 획득할 수 있다. 예를 들어, 도 14에 도시된 바와 같이, 전자 장치는 특정 사용자 의 위치에 대한 정보를 입력 받기 위한 인터페이스를 제공하고 상기 인터페이스 상에서 사용자의 위치(예: 좌석 위치)에 대한 정보를 획득하고, 발화자(P)의 위치에 대한 정보를 입력 받을 수 있다. 또, 기재된 예에 제한되지 않고, 전자 장치는 상기 발화자(P)의 위치에 대한 정보를 획득할 수 있다. 다양한 실시예들에 따르면, 전자 장치에 의해 제공되는 인터페이스는 상기 전자 장치가 위치되는 환 경에 대응하는 지도일 수 있다. 다양한 실시예들에 따르면, 전자 장치는, 동작 1303에서, 거리에 기반하여 수신된 사운드 데이터 중 일부 를 획득할 수 있다. 예를 들어, 전자 장치는 상기 사운드 데이터 중 상기 거리에 대응하는 일부 사운드 데 이터를 획득할 수 있다. 이에 따라, 특정 환경(C) 내에서 발화자와 사용자 사이의 거리에 대응하는 위치 이외의 다른 위치에서 발생되는 소음들이 1차적으로 제거되는 효과가 발생될 수 있다.3.2.2. 소음 그룹에 대응하는 음성 획득 모델 이용 동작 도 15는, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 합성 사운드 데 이터를 생성하는 동작의 예를 설명하기 위한 흐름도이다. 다양한 실시예들에 따르면, 도 15에 도시되는 동작들 은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면 도 15에 도 시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 도 16은, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 텍스트를 생성 하는 동작의 예를 설명하기 위한 도면이다. 이하에서는, 도 16을 참조하여, 도 15에 대해서 더 설명한다. 다양한 실시예들에 따르면, 전자 장치는, 동작 1501에서, 복수의 인공지능 모델들을 획득할 수 있다. 예를 들어, 도 16에 도시된 바와 같이, 전자 장치는 각각이 서로 다른 소음 그룹의 적어도 하나의 하위 소음을 포함하는 특정 언어의 사운드 데이터가 입력되는 경우 음성 데이터를 출력하도록 구현되는 복수의 인공 지능 모 델들(351a, 351b)를 획득할 수 있다. 다양한 실시예들에 따르면, 전자 장치는, 동작 1503에서, 적어도 하나의 하위의 소음이 반영된 특정 언어 의 음성을 포함하는 사운드 데이터를 획득하고, 동작 1505에서, 특정 하위의 소음을 포함하는 특정 그룹을 선택 할 수 있다. 전자 장치의 동작 1503 및 동작 1505는, 전술한 전자 장치의 동작 903 및 동작 905와 같 이 수행될 수 있으므로, 중복되는 설명은 생략한다. 다양한 실시예들에 따르면, 전자 장치는, 동작 1507에서, 복수의 인공 지능 모델들 중 선택된 특정 그룹에 대응하는 특정 인공 지능 모델을 선택할 수 있다. 예를 들어, 도 16에 도시된 바와 같이, 전자 장치는 특 정 그룹에 선택에 기반하여 선택된 그룹에 대응하는 인공 지능 모델을 선택하기 위한 정보를 획득하고, 복수의 인공 지능 모델들(351a, 351b) 중 특정 소음 그룹에 대응하는 특정 인공 지능 모델(예: 제1 인공 지능 모델 (351a))을 선택할 수 있다. 일 예로, 전자 장치는 현재 환경이 교실 환경인 경우, 교실 환경에 대응하는 하위의 소음 데이터들을 제거하거나 및/또는 하위의 소음 데이터들 대신에 음성 데이터를 획득하도록 구현되는 특정 인공 지능 모델을 선택할 수 있다. 다양한 실시예들에 따르면, 전자 장치는, 동작 1509에서, 특정 인공 지능 모델(예: 제1 인공 지능 모델 (351a))에 기반하여, 상기 특정 하위의 소음이 반영된 상기 사운드 데이터로부터 상기 특정 언어의 음성의 적어 도 일부를 획득할 수 있다. 3.2.3. 소음 그룹 별 가중치 기반 음성 획득 모델 이용 동작 도 17은, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 합성 사운드 데 이터를 생성하는 동작의 예를 설명하기 위한 흐름도이다. 다양한 실시예들에 따르면, 도 17에 도시되는 동작들 은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면 도 17에 도 시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 도 18은, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 텍스트를 생성 하는 동작의 예를 설명하기 위한 도면이다. 이하에서는, 도 18을 참조하여, 도 17에 대해서 더 설명한다. 다양한 실시예들에 따르면, 전자 장치는, 동작 1701에서, 인공지능 모델을 획득할 수 있다. 예를 들어, 도 18에 도시된 바와 같이, 전자 장치는 앙상블 형태의 인공 지능 모델(351c)을 포함하는 음성 획득 모델 을 획득할 수 있다. 다양한 실시예들에 따르면, 전자 장치는, 동작 1703에서, 복수의 하위의 소음들이 반영된 특정 언어의 음 성을 포함하는 사운드 데이터를 획득할 수 있다. 전자 장치의 동작 1703은 전술한 전자 장치의 동작 903과 같이 수행될 수 있으므로, 중복되는 설명은 생략한다. 다양한 실시예들에 따르면, 전자 장치는, 동작 1705에서, 사운드 데이터에 포함된 복수의 하위 소음 데이 터에 기반하여 복수의 소음 그룹들 별 가중치에 대한 정보를 획득할 수 있다. 예를 들어, 전자 장치는, 전 술한 그룹 식별 모델을 이용하여 사운드 데이터에 포함된 복수의 하위 소음 데이터에 기반하여, 복수의 소 음 그룹들 별 가중치에 대한 정보를 획득할 수 있다. 상기 소음 그룹 별 가중치는, 소음 그룹 별 사운드 데이터에 포함된 하위 소음 데이터의 정량에 비례할 수 있다. 다양한 실시예들에 따르면, 전자 장치는, 동작 1707에서, 상기 복수의 소음 그룹들 별 가중치 및 상기 인 공 지능 모델에 기반하여, 상기 특정 하위의 소음이 반영된 상기 사운드 데이터로부터 상기 특정 언어의 음성의 적어도 일부를 획득할 수 있다. 예를 들어, 전자 장치는, 상기 인공 지능 모델(351c)에 사운드 데이터를 입력한 것에 기반하여 출력되는 복수의 음성 데이터들을 획득할 수 있다. 상기 복수의 음성 데이터들 각각은 특 정 소음 그룹에 대응할 수 있다. 전자 장치(1100는 상기 복수의 음성 데이터들 각각에 전술한 대응하는 소음 그 룹의 가중치를 반영하고, 가중치가 반영된 상기 복수의 음성 데이터들 각각을 합하여 음성 데이터를 획득할 수 있다. 3.2.4. 실시간 음성 획득 모델 이용 동작 도 19는, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 합성 사운드 데 이터를 생성하는 동작의 예를 설명하기 위한 흐름도이다. 다양한 실시예들에 따르면, 도 19에 도시되는 동작들 은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면 도 19에 도 시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 도 20은, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 실시간으로 음 성 획득 모델을 이용하는 동작의 예를 설명하기 위한 도면이다. 이하에서는, 도 20을 참조하여, 도 19에 대해서 더 설명한다. 다양한 실시예들에 따르면, 전자 장치는, 동작 1901에서, 적어도 하나의 인공지능 모델을 획득하고, 동작 1903에서, 적어도 하나의 특정 하위의 소음이 반영된 특정 언어의 음성을 포함하는 사운드 데이터를 획득할 수 있다. 전자 장치의 동작 1901 및 동작 1903은 전술한 바와 같이 수행될 수 있으므로 중복되는 설명은 생략 한다. 다양한 실시예들에 따르면, 전자 장치는, 동작 1905에서, 실시간으로 상기 적어도 하나의 특정 하위의 소 음을 포함하는 특정 그룹을 선택할 수 있다. 일 실시예에서, 도 20의 (a)에 도시된 바와 같이, 전자 장치 는 시간 별로, 서로 다른 소음 그룹을 선택할 수 있다. 예를 들어, 전자 장치는 시간 별로 식별되는 하위 의 소음에 기반하여, 가장 많은 하위의 소음을 포함하는 소음 그룹(예: t1에서 제1 소음 그룹, t2에서 제2 소음 그룹)을 선택할 수 있다. 일 실시예에서, 도 20의 (b)에 도시된 바와 같이, 전자 장치는 시간 별로, 소음 그룹 별 가중치(예: 제1 가중치, 제2 가중치)를 계산할 수도 있다. 다양한 실시예들에 따르면, 전자 장치는, 동작 1907에서, 상기 실시간으로 선택된 특정 그룹 및 상기 적어 도 하나의 인공 지능 모델에 기반하여, 상기 특정 하위의 소음이 반영된 상기 사운드 데이터로부터 상기 특정 언어의 음성의 적어도 일부를 획득할 수 있다. 일 실시예에서, 전자 장치는, 시간 별로 선택되는 소음 그 룹에 대응하는 인공 지능 모델을 선택하여, 실시간으로 선택된 인공 지능 모델에 기반하여 사운드 데이터로부터 음성 데이터를 획득하는 동작을 수행할 수 있다. 또 일 실시예에서, 전자 장치는 단일의 인공 지능 모델로 부터 출력되는, 음성 데이터들 별로 대응하는 소음 그룹 별 가중치를 반영하여 획득하는 동작을 수행할 수 있다.도면 도면1 도면2 도면3a 도면3b 도면4 도면5a 도면5b 도면6a 도면6b 도면6c 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20"}
{"patent_id": "10-2022-0148174", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은, 다양한 실시예들에 따른, 자막 제공 시스템의 구성의 예를 설명하기 위한 도면이다. 도 2는, 다양한 실시예들에 따른, 다양한 환경에서 사운드가 수신되는 예를 나타내는 도면이다. 도 3a는, 다양한 실시예들에 따른, 전자 장치의 구성의 예를 나타내는 도면이다. 도 3b는, 다양한 실시예들에 따른, 프로그램의 예를 설명하기 위한 도면이다. 도 4는, 다양한 실시예들에 따른, 자막 제공 시스템의 음성 획득 모델을 생성하는 동작의 예를 설명하기 위한 흐름도이다. 도 5a는, 다양한 실시예들에 따른, 서버의 특정 언어의 복수의 특성들 별 음성 데이터를 생성하는 동작의 예를 설명하기 위한 도면이다.도 5b는, 다양한 실시예들에 따른, 서버의 복수의 환경들에 대응하는 복수의 소음 그룹들 별 소음 데이터를 생 성하는 동작의 예를 설명하기 위한 도면이다. 도 6a는, 다양한 실시예들에 따른, 서버)의 음성 데이터 및 소음 데이터에 기반하여 사운드 데이터를 생성하는 동작의 예를 설명하기 위한 도면이다. 도 6b는, 다양한 실시예들에 따른, 서버의 음성 데이터 및 사운드 데이터에 기반하여 음성 획득 모델을 생성하 는 동작의 예를 설명하기 위한 도면이다. 도 6c는, 다양한 실시예들에 따른, 음성 획득 모델의 예를 설명하기 위한 도면이다. 도 7은, 다양한 실시예들에 따른, 자막 제공 시스템의 합성 사운드 데이터를 생성하는 동작의 예를 설명하기 위 한 흐름도이다. 도 8은, 다양한 실시예들에 따른, 서버에 의해 획득되는 합성 사운드 데이터 및 음성 데이터의 예를 설명하기 위한 도면이다. 도 9는, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 합성 사운드 데이터를 생성 하는 동작의 예를 설명하기 위한 흐름도이다. 도 10은, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 텍스트를 생성하는 동작의 예를 설명하기 위한 도면이다. 도 11은, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 다양한 환경에서 수신되는 사운드 데이터에 기반하여 텍스트를 제공하는 동작의 예를 설명하기 위한 도면이다. 도 12는, 다양한 실시예들에 따른, 소음 그룹의 선택 동작의 예를 설명하기 위한 도면이다. 도 13은, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 합성 사운드 데이터를 생 성하는 동작의 예를 설명하기 위한 흐름도이다. 도 14는, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 텍스트를 생성하는 동작의 예를 설명하기 위한 도면이다. 도 15는, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 합성 사운드 데이터를 생 성하는 동작의 예를 설명하기 위한 흐름도이다. 도 16은, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 텍스트를 생성하는 동작의 예를 설명하기 위한 도면이다. 도 17은, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 합성 사운드 데이터를 생 성하는 동작의 예를 설명하기 위한 흐름도이다. 도 18은, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 텍스트를 생성하는 동작의 예를 설명하기 위한 도면이다. 도 19는, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 합성 사운드 데이터를 생 성하는 동작의 예를 설명하기 위한 흐름도이다. 도 20은, 다양한 실시예들에 따른, 자막 제공 시스템(예: 전자 장치 및/또는 서버)의 실시간으로 음성 획득 모 델을 이용하는 동작의 예를 설명하기 위한 도면이다."}
