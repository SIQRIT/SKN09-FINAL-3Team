{"patent_id": "10-2018-0055783", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0131206", "출원번호": "10-2018-0055783", "발명의 명칭": "영상의 전역 문맥 정보를 활용하는 딥러닝 기반 물체 검출 방법 및 시스템", "출원인": "한양대학교 산학협력단", "발명자": "최준원"}}
{"patent_id": "10-2018-0055783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "객체 검출 방법에 있어서,영상 정보를 제1 딥 뉴럴 네트워크에 통과시킴에 따라 특징맵을 획득하는 단계;상기 획득된 특징맵을 제2 딥 뉴럴 네트워크 및 제3 딥 뉴럴 네트워크에 각각 통과시키는 단계;상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계; 및상기 융합된 특징맵에 기반하여 상기 영상 정보로부터 객체를 검출하는 단계를 포함하는 객체 검출 방법."}
{"patent_id": "10-2018-0055783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 획득된 특징맵을 제2 딥 뉴럴 네트워크 및 제3 딥 뉴럴 네트워크에 통과시키는 단계는,상기 획득된 특징맵을 지역적 정보를 표현하기 위한 특징맵을 획득하기 위한 제2 딥 뉴럴 네트워크 및 전역적정보를 표현하는 특징맵을 획득하기 위한 제3 딥 뉴럴 네트워크 각각에 통과시키는 단계를 포함하는 객체 검출 방법."}
{"patent_id": "10-2018-0055783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 제2 딥 뉴럴 네트워크는, 지역적 정보를 표현하기 위한 특징값을 획득하기 위하여 6계층의 CNN 구조로 구성되고, 상기 CNN 구조에서 6계층의 특징맵을 추출하여 객체를 검출하고,상기 제 3 딥 뉴럴 네트워크는, 전역적 정보를 표현하기 위한 특징맵을 획득하기 위하여 5계층의 CNN구조로 구성되고, 상기 CNN구조에서 5계층 중 하나의 계층의 특징맵을 활용하여 객체를 검출하는, 객체 검출 방법."}
{"patent_id": "10-2018-0055783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵은, 지역적정보의 특징맵 및 전역적 정보의 특징맵이고,상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징값을 융합 네트워크를 통하여 융합하는 단계는,상기 지역적 정보의 특징맵을 위치에 따라 각각 컨볼루션 필터에 통과시킴에 따라 객체의 종류와 위치를 포함하는 객체 정보 값을 획득하고, 상기 전역적 정보의 특징맵의 특징값들을 펼친 후 임베딩 벡터와 연결하여 완전연결 층에 통과시킴에 따라 객체의 종류와 위치를 포함하는 객체 정보 값을 획득하고, 상기 지역적 정보에 대한객체 정보 값과 상기 전역적 정보에 대한 객체 정보 값을 결합하는 단계를 포함하는 객체 검출 방법."}
{"patent_id": "10-2018-0055783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵은, 지역적공개특허 10-2019-0131206-3-정보의 특징맵 및 전역적 정보의 특징맵이고,상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계는,상기 전역적 정보의 특징맵에서 상기 지역적 정보의 특징맵의 위치에 해당하는 특징값들을 0으로 만드는 행렬을곱하는 마스킹 기법을 이용하여 상기 지역적 정보의 특징맵으로 상기 객체에 대한 정보를 이용하고, 상기 전역적 정보의 특징맵으로 상기 객체 이외의 환경 정보를 이용하는 단계 를 포함하는 객체 검출 방법."}
{"patent_id": "10-2018-0055783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징값을 융합 네트워크를 통하여 융합하는 단계는,상기 지역적 정보의 특징맵을 위치에 따라 각각 컨볼루션 필터에 통과시킴에 따라 객체의 종류와 위치를 포함하는 객체 정보 값을 획득하고, 상기 마스킹 기법이 적용된 전역적 정보의 특징맵의 특징값들을 펼친 후 완전 연결 층에 통과시킴에 따라 획득된 값과 상기 지역적 정보에 대한 객체 정보 값을 결합하는 단계를 포함하는 객체 검출 방법."}
{"patent_id": "10-2018-0055783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵은, 지역적정보의 특징맵 및 전역적 정보의 특징맵이고,상기 융합된 특징맵에 기반하여 상기 영상 정보로부터 객체를 검출하는 단계는,상기 지역적 정보에 대한 객체 정보 값과 상기 전역적 정보에 대한 객체 정보 값을 결합하여 완전 연결 층에 통과시켜 상기 영상 정보로부터 상기 객체를 검출하는 단계 를 포함하는 객체 검출 방법."}
{"patent_id": "10-2018-0055783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "객체 검출 시스템에 있어서,영상 정보를 제1 딥 뉴럴 네트워크에 통과시킴에 따라 특징맵을 획득하는 특징맵 획득부;상기 획득된 특징맵을 제2 딥 뉴럴 네트워크 및 제3 딥 뉴럴 네트워크에 각각 통과시키는 입력부;상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 융합부; 및상기 융합된 특징맵에 기반하여 상기 영상 정보로부터 객체를 검출하는 검출부를 포함하는 객체 검출 시스템."}
{"patent_id": "10-2018-0055783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 입력부는,상기 획득된 특징맵을 지역적 정보를 표현하기 위한 특징맵을 획득하기 위한 제2 딥 뉴럴 네트워크 및 전역적정보를 표현하는 특징맵을 획득하기 위한 제3 딥 뉴럴 네트워크 각각에 통과시키는 것을 특징으로 하는 객체 검출 시스템."}
{"patent_id": "10-2018-0055783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2019-0131206-4-제8항에 있어서, 상기 제2 딥 뉴럴 네트워크는, 지역적 정보를 표현하기 위한 특징값을 획득하기 위하여 6계층의 CNN 구조로 구성되고, 상기 CNN 구조에서 6계층의 특징맵을 추출하여 객체를 검출하고,상기 제 3 딥 뉴럴 네트워크는, 전역적 정보를 표현하기 위한 특징맵을 획득하기 위하여 5계층의 CNN구조로 구성되고, 상기 CNN구조에서 5계층 중 하나의 계층의 특징맵을 활용하여 객체를 검출하는 것을 특징으로 하는 객체 검출 시스템."}
{"patent_id": "10-2018-0055783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵은, 지역적정보의 특징맵 및 전역적 정보의 특징맵이고,상기 융합부는, 상기 지역적 정보의 특징맵을 위치에 따라 각각 컨볼루션 필터에 통과시킴에 따라 객체의 종류와 위치를 포함하는 객체 정보 값을 획득하고, 상기 전역적 정보의 특징맵의 특징값들을 펼친 후 임베딩 벡터와 연결하여 완전연결 층에 통과시킴에 따라 객체의 종류와 위치를 포함하는 객체 정보 값을 획득하고, 상기 지역적 정보에 대한객체 정보 값과 상기 전역적 정보에 대한 객체 정보 값을 결합하는것을 특징으로 하는 객체 검출 시스템."}
{"patent_id": "10-2018-0055783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서, 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵은, 지역적정보의 특징맵 및 전역적 정보의 특징맵이고,상기 융합부는, 상기 전역적 정보의 특징맵에서 상기 지역적 정보의 특징맵의 위치에 해당하는 특징값들을 0으로 만드는 행렬을곱하는 마스킹 기법을 이용하여 상기 지역적 정보의 특징맵으로 상기 객체에 대한 정보를 이용하고, 상기 전역적 정보의 특징맵으로 상기 객체 이외의 환경 정보를 이용하는것을 특징으로 하는 객체 검출 시스템."}
{"patent_id": "10-2018-0055783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 융합부는, 상기 지역적 정보의 특징맵을 위치에 따라 각각 컨볼루션 필터에 통과시킴에 따라 객체의 종류와 위치를 포함하는 객체 정보 값을 획득하고, 상기 마스킹 기법이 적용된 전역적 정보의 특징맵의 특징값들을 펼친 후 완전 연결 층에 통과시킴에 따라 획득된 값과 상기 지역적 정보에 대한 객체 정보 값을 결합하는 것을 특징으로 하는 객체 검출 시스템."}
{"patent_id": "10-2018-0055783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서, 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵은, 지역적정보의 특징맵 및 전역적 정보의 특징맵이고,상기 검출부는, 상기 지역적 정보에 대한 객체 정보 값과 상기 전역적 정보에 대한 객체 정보 값을 결합하여 완전 연결 층에 통과시켜 상기 영상 정보로부터 상기 객체를 검출하는 공개특허 10-2019-0131206-5-것을 특징으로 하는 객체 검출 시스템."}
{"patent_id": "10-2018-0055783", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에 따른 객체 검출 방법은, 영상 정보를 제1 딥 뉴럴 네트워크에 통과시킴에 따라 특징맵을 획득하는 단계; 상기 획득된 특징맵을 제2 딥 뉴럴 네트워크 및 제3 딥 뉴럴 네트워크에 각각 통과시키는 단계; 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵을 융합 네트워크를 통 하여 융합하는 단계; 및 상기 융합된 특징맵에 기반하여 상기 영상 정보로부터 객체를 검출하는 단계를 포함할 수 있다."}
{"patent_id": "10-2018-0055783", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 영상의 전역 문맥 정보를 이용하여 객체를 검출하는 기술에 관한 것이다."}
{"patent_id": "10-2018-0055783", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "물체 검출기법이란 카메라 영상으로부터 검출하고자 하는 물체의 위치와 종을 구분하는 기술을 의미한다. 영상 정보를 통한 물체 검출 기술은 컴퓨터 비전 분야에서 오랫동안 연구되어 왔던 분야이다. 최근에 딥 뉴럴 네트 워크의 구조를 이용하는 딥러닝 기술이 발전함에 따라 대용량의 영상 데이터로부터 고차원의 특징값을 학습하여 매우 높은 수준의 정확도로 물체를 검출하는 방법이 제안되었다. 이러한 기술은 자율주행, 로봇 공학, 의료, 보안 등의 다양한 분야에 활발히 적용되고 있다. 최근 자동차의 보행자 안전 시스템 탑재가 의무화되는 추세로 안전을 위한 운전자 지원 시스템에 보행자의 위치와 상태를 인지하여 위험을 회피하는 기술에도 사용되고 있다. 공장에서도 사용되는 로봇의 경우 영상 기반 물체 인지 기술을 사용하여 스스로 공장 환경의 변화와 특징을 학 습하고 궁극적으로 로봇의 지능과 처리 성능을 극대화하는 기법에도 중요한 기술로 사용되고 있다. 의료 영상 분야에서도 의사의 단순노동을 줄이기 위해 딥러닝 기반 물체 인지 기법을 사용하여 전문가의 진단을 보조해주 는 수단으로 사용되고 있다. 이처럼 영상분야의 인지 기술의 발달과 함께 환경과 상황에 대한 이해를 통한 물 체 검출 기술의 필요성이 높아지고 있다. 일례로, 데이터의 주요 특징들을 추출할 수 있는 기법들을 정교하고 설계하여 영상의 특징값을 얻고 이를 통계 적인 분류기를 통해 물체를 인식 또는 검출하는 기술이 주로 사용되었다. 예를 들어, 영상의 선의 구조나 형태 등의 특징들을 알아내고 이를 이미 알고있는 템플릿과 비교하여 물체를 인지하거나 검출하는 기술이다. 대표적 인 특징 추출 기술로는 SIFT(Scale invariant feature transform)과 HOG(Historgram of oriented gradients) 표현자 등이 있다. SIFT는 영상에서 코너점 등 식별이 용이한 특징점들을 선택한 후에 각 특징점을 중심으로 한 로컬 패치에 대해 방향성을 갖는 특징 벡터를 추출하는 방법으로서, 이는 주변의 밝기 변화의 방향 및 밝기 변화의 급격한 정도를 표현하는 특징을 이용한다. HOG는 대상 영역을 일정 크기의 셀로 분할하고, 각 셀마다 경계 픽셀들의 방향에 대한 히스토그램을 구한 후 이들 히스토그램 bin 값들을 일렬로 연결한 벡터를 이용한 방 법으로서, 경계의 방향정보를 이용하기 때문에 경계기반 템플릿 매칭을 수행한다. 또한, HOG는 물체의 실루엣 정보를 이용하므로 사람, 자동차 등과 같이 내부 패턴이 복잡하지 않으면서도 고유의 독특한 윤곽선 정보를 갖 는 물체를 식별하는데 적합하다. 이러한 기술들은 미리 엣지나 형태에 대한 물체의 알려진 정보들만을 활용하 기 때문에 영상 데이터에 다양한 조도 변화나 형태 왜곡, 노이즈, 가림 등이 발생하는 경우에 특징값이 예측된 분포에서 벗어나게 되면 인식 성능이 크게 떨어지는 단점이 있다. 이러한 특징값 기반의 물체 검출 기법의 한계를 극복하기 위해서 딥러닝 기술은 보다 일반화된 학습 모델인 딥 뉴럴 네트워크의 구조를 사용하여 방대한 양의 데이터로부터 데이터의 표현 방법 즉, 특징값을 학습하게 된다. 이러한 경우 데이터의 표현 방법을 다양한 종류의 데이터를 통해 얻기 때문에 영상 정보의 다양한 변화와 악의 적인 요소에 대해 좋은 성능을 획득할 수 있다. 딥러닝 기법을 이용한 종래 물체검출 방법에는 R-CNN 기법이 있다. R-CNN 기법은 카메라 센서로부터 입력을 받아 먼저 이미지에서 물체의 후보가 될 수 있는 영역을 제안하 는 전처리 네트워크를 거친 후, 그 영역에 대한 정보를 각각 딥 뉴럴 네트워크의 입력으로 하는 물체 분류 네트 워크에 통과시키는 기법이다. 또한 R-CNN의 단점을 개선한 Fast R-CNN 기법은 기존 R-CNN 기법의 연산량을 줄 이기 위해 CNN 네트워크를 이용하여 특징값을 찾고 중간 노드의 특징맵(feature map)단에서 물체 후보 영역에 대한 정보를 추출하는 영역제안 네트워크와 물체의 종류를 판별하는 컨볼루션 네트워크를 모두 사용하여 물체 검출을 수행하게 된다. 최근에는 이러한 두 가지 네트워크를 하나로 통합하여 물체 영역의 위치를 찾는 단계와 물체의 종류를 구분하는 단계를 통합하여 처리하는 Single shot detector(SSD)와 You only look once(YOLO)라 는 딥러닝 기반 물체 검출 기법이 제안되었다. 그러나, Convolutional neural network(CNN)을 사용하여 영상으로부터 특징맵을 추출하고 특징맵으로부터 특정 물체에 해당하는 지역정보를 이용하여 물체의 위치를 위치를 표시하는 바운딩 상자와 물체의 클래스 정보를 찾는 딥러닝을 기반으로 하는 종래의 물체검출 기술은 CNN으로부터 획득된 특징값으로부터 물체에 해당하는 특징 값을 매칭하여 물체의 영역과 종류를 판별하기 때문에 특정 물체에 해당하는 지역적 정보만을 활용한다는 한계 가 있다. 예를 들면, 실제 사람의 경우에 물체를 검출하는 데 있어 주변 환경 또는 배경과 같은 전역적인 정보 는 물체를 검출하는 데 큰 도움을 준다. 주변 배경이 도로인 경우에 물체는 교통에 관련된 물체일 확률이 높으 며 주변이 실내의 환경인 경우에는 우리가 실내에서 보는 물체일 가능성이 높다. 종래의 딥러닝 기반의 물체검 출 기술은 이러한 전역적인 문맥 정보를 활용하지 않으므로 활용 가능한 주변 정보를 모두 적극적으로 이용하지 않는 문제점이 있다. 참고자료: KR 10-2016-0099289(2016.08.22), KR 10-1836742(2018.03.02), KR 10-2015-0050134(2015.05.08)"}
{"patent_id": "10-2018-0055783", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "객체가 존재하는 일부분에 대한 지역적 정보와 더불어 객체의 주변 환경에 대한 전역적 정보를 함께 이용하는 딥러닝 기반 물체 검출 방법 및 시스템을 제안하고자 한다."}
{"patent_id": "10-2018-0055783", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "객체 검출 시스템에 의해 수행되는 객체 검출 방법은, 영상 정보를 제1 딥 뉴럴 네트워크에 통과시킴에 따라 특 징맵을 획득하는 단계; 상기 획득된 특징맵을 제2 딥 뉴럴 네트워크 및 제3 딥 뉴럴 네트워크에 각각 통과시키 는 단계; 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계; 및 상기 융합된 특징맵에 기반하여 상기 영상 정보로부터 객체를 검출 하는 단계를 포함할 수 있다. 상기 획득된 특징맵을 제2 딥 뉴럴 네트워크 및 제3 딥 뉴럴 네트워크에 통과시키는 단계는, 상기 획득된 특징 맵을 지역적 정보를 표현하기 위한 특징맵을 획득하기 위한 제2 딥 뉴럴 네트워크 및 전역적 정보를 표현하는 특징맵을 획득하기 위한 제3 딥 뉴럴 네트워크 각각에 통과시키는 단계를 포함할 수 있다. 상기 제2 딥 뉴럴 네트워크는, 지역적 정보를 표현하기 위한 특징값을 획득하기 위하여 6계층의 CNN 구조로 구 성되고, 상기 CNN 구조에서 6계층의 특징맵을 추출하여 객체를 검출하고, 상기 제 3 딥 뉴럴 네트워크는, 전역 적 정보를 표현하기 위한 특징맵을 획득하기 위하여 5계층의 CNN구조로 구성되고, 상기 CNN구조에서 5계층 중 하나의 계층의 특징맵을 활용하여 객체를 검출할 수 있다. 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵은, 지역적 정보의 특징맵 및 전역적 정보의 특징맵이고, 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과 시킴에 따라 획득된 각각의 특징값을 융합 네트워크를 통하여 융합하는 단계는, 상기 지역적 정보의 특징맵을 위치에 따라 각각 컨볼루션 필터에 통과시킴에 따라 객체의 종류와 위치를 포함하는 객체 정보 값을 획득하고, 상기 전역적 정보의 특징맵의 특징값들을 펼친 후 임베딩 벡터와 연결하여 완전 연결 층에 통과시킴에 따라 객 체의 종류와 위치를 포함하는 객체 정보 값을 획득하고, 상기 지역적 정보에 대한 객체 정보 값과 상기 전역적 정보에 대한 객체 정보 값을 결합하는 단계를 포함할 수 있다. 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵은, 지역적 정보의 특징맵 및 전역적 정보의 특징맵이고, 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과 시킴에 따라 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하는 단계는, 상기 전역적 정보의 특징맵에서 상기 지역적 정보의 특징맵의 위치에 해당하는 특징값들을 0으로 만드는 행렬을 곱하는 마스킹 기법을 이용하여 상기 지역적 정보의 특징맵으로 상기 객체에 대한 정보를 이용하고, 상기 전역적 정보의 특징맵으로 상기 객체 이외의 환경 정보를 이용하는 단계를 포함할 수 있다. 상기 제2 딥 뉴럴 네트워크 및 상기 제2 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징값을 융합 네 트워크를 통하여 융합하는 단계는, 상기 지역적 정보의 특징맵을 위치에 따라 각각 컨볼루션 필터에 통과시킴에 따라 객체의 종류와 위치를 포함하는 객체 정보 값을 획득하고, 상기 마스킹 기법이 적용된 전역적 정보의 특징 맵의 특징값들을 펼친 후 완전 연결 층에 통과시킴에 따라 획득된 값과 상기 지역적 정보에 대한 객체 정보 값을 결합하는 단계를 포함할 수 있다. 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵은, 지역적 정보의 특징맵 및 전역적 정보의 특징맵이고, 상기 융합된 특징맵에 기반하여 상기 영상 정보로부터 객체를 검 출하는 단계는, 상기 지역적 정보에 대한 객체 정보 값과 상기 전역적 정보에 대한 객체 정보 값을 결합하여 완 전 연결 층에 통과시켜 상기 영상 정보로부터 상기 객체를 검출하는 단계를 포함할 수 있다. 객체 검출 시스템은, 영상 정보를 제1 딥 뉴럴 네트워크에 통과시킴에 따라 특징맵을 획득하는 특징맵 획득부; 상기 획득된 특징맵을 제2 딥 뉴럴 네트워크 및 제3 딥 뉴럴 네트워크에 각각 통과시키는 입력부; 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵을 융합 네트워크를 통하 여 융합하는 융합부; 및 상기 융합된 특징맵에 기반하여 상기 영상 정보로부터 객체를 검출하는 검출부를 포함 할 수 있다. 상기 입력부는, 상기 획득된 특징맵을 지역적 정보를 표현하기 위한 특징맵을 획득하기 위한 제2 딥 뉴럴 네트 워크 및 전역적 정보를 표현하는 특징맵을 획득하기 위한 제3 딥 뉴럴 네트워크 각각에 통과시킬 수 있다. 상기 제2 딥 뉴럴 네트워크는, 지역적 정보를 표현하기 위한 특징값을 획득하기 위하여 6계층의 CNN 구조로 구 성되고, 상기 CNN 구조에서 6계층의 특징맵을 추출하여 객체를 검출하고, 상기 제 3 딥 뉴럴 네트워크는, 전역 적 정보를 표현하기 위한 특징맵을 획득하기 위하여 5계층의 CNN구조로 구성되고, 상기 CNN구조에서 5계층 중 하나의 계층의 특징맵을 활용하여 객체를 검출할 수 있다. 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵은, 지역적 정보의 특징맵 및 전역적 정보의 특징맵이고, 상기 융합부는, 상기 지역적 정보의 특징맵을 위치에 따라 각각 컨볼루션 필터에 통과시킴에 따라 객체의 종류와 위치를 포함하는 객체 정보 값을 획득하고, 상기 전역적 정보 의 특징맵의 특징값들을 펼친 후 임베딩 벡터와 연결하여 완전 연결 층에 통과시킴에 따라 객체의 종류와 위치 를 포함하는 객체 정보 값을 획득하고, 상기 지역적 정보에 대한 객체 정보 값과 상기 전역적 정보에 대한 객체 정보 값을 결합할 수 있다. 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵은, 지역적 정보의 특징맵 및 전역적 정보의 특징맵이고, 상기 융합부는, 상기 전역적 정보의 특징맵에서 상기 지역적 정보 의 특징맵의 위치에 해당하는 특징값들을 0으로 만드는 행렬을 곱하는 마스킹 기법을 이용하여 상기 지역적 정 보의 특징맵으로 상기 객체에 대한 정보를 이용하고, 상기 전역적 정보의 특징맵으로 상기 객체 이외의 환경 정 보를 이용할 수 있다. 상기 융합부는, 상기 지역적 정보의 특징맵을 위치에 따라 각각 컨볼루션 필터에 통과시킴에 따라 객체의 종류 와 위치를 포함하는 객체 정보 값을 획득하고, 상기 마스킹 기법이 적용된 전역적 정보의 특징맵의 특징값들을 펼친 후 완전 연결 층에 통과시킴에 따라 획득된 값과 상기 지역적 정보에 대한 객체 정보 값을 결합할 수 있다. 상기 제2 딥 뉴럴 네트워크 및 상기 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵은, 지역적 정보의 특징맵 및 전역적 정보의 특징맵이고, 상기 검출부는, 상기 지역적 정보에 대한 객체 정보 값과 상기 전 역적 정보에 대한 객체 정보 값을 결합하여 완전 연결 층에 통과시켜 상기 영상 정보로부터 상기 객체를 검출할 수 있다."}
{"patent_id": "10-2018-0055783", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시예에 따른 객체 검출 시스템은 영상 정보에 대한 지역적 정보와 전역적 정보를 함께 이용함으로써 검출 성능을 향상시킬 수 있다. 일 실시예에 따른 객체 검출 시스템은 객체가 있는 지역적 정보를 획득하기 위한 네트워크와 객체가 속해있는 주변 환경에 대한 전역적 정보를 획득하기 위한 네트워크를 각각 구성하고, 구성된 네트워크를 통과함에 따라 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합하여 객체에 대한 주변 환경에 대한 이해를 기반으로 효율 적인 객체 인식을 수행할 수 있다."}
{"patent_id": "10-2018-0055783", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 실시예를 첨부한 도면을 참조하여 상세히 설명한다. 도 1은 일 실시예에 따른 객체 검출 시스템에서 객체 검출을 수행하는 딥 뉴럴 네트워크의 구조를 설명하기 위 한 도면이다. 객체 검출 시스템은 딥 뉴럴 네트워크를 이용하여 객체 검출을 수행함에 있어서, 객체에 대한 지역적 정보와 함 께 주변 환경을 포함하는 전역적 정보를 융합하여 영상 기반의 객체 검출 성능을 향상시킬 수 있다. 이에, 지 역적 정보와 전역적 정보를 추출하기 위하여 딥 뉴럴 네트워크(예를 들면, CNN)의 구조를 활용하고, 특징맵으로 부터 객체를 검출하기 위한 구조로 Single Shot Detector(SSD) 방법의 일부를 활용할 수 있다. 도 1을 참고하면, 전역적 정보와 지역적 정보를 융합하여 객체를 검출하기 위한 딥 뉴럴 네트워크의 구조를 나 타낸 것이다. 카메라의 영상 정보가 딥 뉴럴 네트워크(예를 들면, CNN)에 입력될 수 있다. 이하, 아래의 설명 에서는 편의상 영상 정보가 처음에 입력되는 딥 뉴럴 네트워크를 제1 딥 뉴럴 네트워크로 기재하기로 한다. 영 상 정보가 제1 딥 뉴럴 네트워크를 통과함에 따라 출력된 출력값을 제2 딥 뉴럴 네트워크 및 제3 딥 뉴럴 네트 워크로 나누어 통과시킬 수 있다. 예를 들면, 카메라의 RGB 이미지 정보를 VGG-16 CNN에 통과시킬 수 있다. 영상 정보가 VGG-16 CNN에 통과됨에 따른 특징값을 지역적 정보의 특징맵과 전역적 정보의 특징 맵을 획득하기 위한 지역적 CNN 및 전역적 CNN을 나누어 각각 통과시킬 있다. 지역적 CNN의 구조에 서는 (a), (b), (c), (d), (e), (f)의 총 6계층의 특징맵을 추출하여 객체를 검출하고, 전역적 CNN의 구조에서 는 총 5계층 중 4번 째 계층의 특징맵인 (g)를 활용하게 된다. 이러한 각각의 특징맵을 융합 네트워크를 통하여 융합함으로써 객체를 검출할 수 있다. 이와 같이 지역적 특징맵과 전역적 특징맵을 동시에 활용하 여 객체를 검출하기 위한 방법을 도 2 및 도 3에서 설명하기로 한다. 도 2는 일 실시예에 따른 객체 검출 시스템에서 임베딩 벡터를 이용하여 지역 정보와 전역 정보를 융합하는 융 합 네트워크(딥 뉴럴 네트워크)의 구조를 설명하기 위한 도면이다. 일례로, 도 2를 참고하면, 지역적 정보에 대한 위치 정보를 임베딩 벡터를 이용하여 서로 다른 두 종류의 특징맵을 융합하는 방법이다. 지역적 정보의 특징맵을 SSD 방법과 같이 위치에 따라 각각 컨볼루션 필터에 통과시켜 지역적 정보에 해당하는 물체의 종류와 위치를 포함하는 객체 정보 값을 획득할 수 있다. 또한, 전역적 정보의 특징맵은 전역적 정보의 특징맵의 값들을 펼친 후 임베딩 벡터와 연결하여 완전 연결 층(fully-connected layer)에 통과시켜 객체의 종 류와 위치를 포함하는 객체 정보 값을 획득할 수 있다. 이와 같이, 지역적 정보의 특징맵으로부터 획득된 객체 정보 값과 전역적 정보의 특징맵으로부터 획득된 객체 정보 값(예를 들면, 점수 값)을 결합(Concatenation)한 후, 다시 완전 연결 층에 통과시켜 객체의 종류와 좌표에 대한 값(예를 들면, 점수 값)을 획득하여 최종적인 검 출을 수행할 수 있다. 여기서, 임베딩 벡터란 위치 좌표에 대한 정보를 특정 차원의 벡터로 표현하는 기법으로 서, 실시예에서는 지역적 정보의 특징맵을 컨볼루션 필터의 위치에 대응하는 전역적 정보를 활성화시키기 위한 목적으로 이용할 수 있다. 이때, 임베딩 벡터 또한 네트워크의 훈련 과정에서 같이 학습될 수 있으며, 지역적 정보의 특징맵에서 컨볼루션 필터가 위치하고 있는 중심 좌표를 가져와서 상기 중심 좌표를 기준으로 임베딩 벡 터를 가져올 수 있다. 도 3은 일 실시예에 따른 객체 검출 시스템에서 마스킹 기법을 이용하여 지역 정보와 전역 정보를 융합하는 융 합 네트워크(딥 뉴럴 네트워크)의 구조를 설명하기 위한 도면이다. 도 3을 참고하면, 전역적 정보의 특징맵이 객체 정보 외에 환경에 대한 정보만을 이용하기 위하여 전역적 정보 의 특징맵에서 지역적 정보의 위치에 해당하는 특징값들을 0으로 생성하는 행렬을 곱하는 마스킹(masking) 기법 을 이용하여 지역적 정보와 전역적 정보를 융합할 수 있다. 이때, 마스킹 기법은 지역적 정보의 특징맵과 전역 적 정보의 특징맵을 함께 이용하여 객체를 검출할 때, 지역적 정보의 특징맵은 객체에 대한 정보만을 이용하고, 전역적 정보의 특징맵은 객체와 관련된 정보 이외의 환경 정보만을 이용하여 검출을 수행하기 때문에 전역적 정 보의 특징맵에서 객체와 관련된 정보를 제거하고 환경 정보만을 유지시키는 효과를 도출할 수 있는 기법이다. 지역적 정보의 특징맵을 SSD 방법과 같이 위치에 따라 각각 컨볼루션 필터에 통과시켜 지역적 정보에 해당하는 물체의 종류와 위치를 포함하는 객체 정보 값을 획득할 수 있다. 전역적 정보의 특징맵에서 지역적 정보의 위치에 해당하는 특징값을 0으로 생성하는 행렬을 곱하고, 전역적 정 보의 특징맵의 값들을 펼친 후 완전 연결 층에 통과시킴에 따라 획득된 값과 지역적 정보의 특징맵으로부터 획 득된 객체 정보 값(예를 들면, 점수 값)을 결합(Concatenation)한 후, 다시 완전 연결 층에 통과시킴에 따라 객 체에 대한 최종 검출을 수행하게 된다. 도 4는 일 실시예에 따른 객체 검출 시스템에서 객체를 검출하는 성능을 설명하기 위한 표이다. 실시예에서 제안된 객체 검출 기술과 종래의 객체 검출 알고리즘의 성능을 비교한 표이다. 표에서 검출기의 성 능을 mean average precision(mAP)로 나타내었고, 트레이닝을 위한 데이터는 PASCAL VOC 를 사용하였다. 표에 서 보는 바와 같이, 전역적 문맥 정보를 활용하는 제안하는 기술이 전역적 정보를 활용하지 않는 기존의 Single Shot Detector(SSD) 방법에 비해 평균 1프로 이상의 좋은 검출 성능을 나타냄을 확인할 수 있다. 종래의 딥러닝 기반 물체 인지 기술은 딥 뉴럴 네트워크의 특징맵에서 지역 정보만을 활용하여 물체 검출을 수 행하지만 실시예에서 제안하는 방법은 중간 단 이후의 네트워크 노드에서 지역 정보를 획득하기 위해 훈련된 네 트워크와 전역 정보를 획득하기 위해 훈련된 네트워크를 함께 이용하여 주변 배경에 대한 정보를 이용하여 객체 검출을 수행하게 된다. 또한, 종래의 딥러닝 기반 물체 검출 네트워크는 물체에 대한 레이블(label)이 있는 데이터를 이용하여 해당 레 이블에 맞는 검출을 수행하도록 지도 학습을 통해 트레이닝을 수행하는 반면, 실시예에서 제안된 기술에서 사용 하는 전역적 정보는 레이블 정보가 없는 데이터이지만 전역적 정보에 해당하는 데이터가 지역적 정보 데이터와 의 상호작용을 활용하게 된다. 이에 따라, 특징맵의 지역적 정보를 이용할 때 컴볼루션 필터의 위치에 대한 임 베딩 벡터를 함께 이용함으로써 지역적 정보와 전역적 정보간의 상호작용을 극대화시킬 수 있다. 이에 따라 지 역적 정보만을 이용하는 물체 검출 방법에 비하여 환경에 대한 부가적인 정보를 이용함으로써 객체의 인지 검출 성능을 향상시킬 수 있다. 일 실시예에 따른 객체 검출 시스템은 딥러닝 기법을 이용한 물체 검출 수행 시 지역적 정보와 전역적 정보를 함께 이용함으로써 검출 성능을 향상 시킬 수 있다. 이러한 제안하는 방법은 카메라 센서 데이터를 입력으로 하는 딥 뉴럴 네트워크에서 물체가 있는 지역적 정보를 획득하기 위한 네트워크와 물체가 속해 있는 주변 환경 에 대한 전역적 정보를 획득하기 위한 네트워크를 각각 구성하고, 두 정보를 효과적으로 융합하여 물체의 주변 환경에 대한 이해를 기반으로 효율적인 물체 인지를 수행할 수 있다. 일 실시예에 따른 객체 검출 시스템은 최근 스마트 홈 환경에나 자율 주행 환경에서는 카메라 센서 데이터를 이 용하여 물체 검출을 수행할 때 물체 검출과 동시에 물체가 속한 주변 환경에 대한 이해를 수행하는 데에 활용될 것으로 예상이 되며, 제안하는 방법은 이러한 물체와 그 주변 환경에 대한 이해를 효과적으로 수행할 수 있는 해결책을 제시할 수 있다. 또한 스마트 홈이나 자율주행뿐만 아니라 환경이나 물체를 인식하는 다양한 인공지 능 기술에 적용이 가능하다. 도 5는 일 실시예에 따른 객체 검출 시스템의 구조를 설명하기 위한 블록도이고, 도 6은 일 실시예에 따른 객체 검출 시스템에서 객체를 인식하는 방법을 설명하기 위한 흐름도이다. 객체 검출 시스템은 특징맵 획득부, 입력부, 융합부 및 검출부를 포함할 수 있다. 이러한 구성요소들은 객체 검출 시스템에 저장된 프로그램 코드가 제공하는 제어 명령에 따라 프로세서에 의해 수행되는 서로 다른 기능들(different functions)의 표현들일 수 있다. 구성요소들은 도 6의 객체 검출 방법이 포함하는 단계들(610 내지 640)을 수행하도록 객체 검출 시스템을 제어할 수 있다. 이때, 구성요소들은 메모리가 포함하는 운영체제의 코드와 적어도 하나의 프로그램의 코드에 따른 명령(instruction)을 실행 하도록 구현될 수 있다. 객체 검출 시스템의 프로세서는 객체 검출 방법을 위한 프로그램의 파일에 저장된 프로그램 코드를 메모리 에 로딩할 수 있다. 예를 들면, 객체 검출 시스템에서 프로그램이 실행되면, 프로세서는 운영체제의 제어 에 따라 프로그램의 파일로부터 프로그램 코드를 메모리에 로딩하도록 객체 검출 시스템을 제어할 수 있다. 이 때, 프로세서 및 프로세서가 포함하는 특징맵 획득부, 입력부, 융합부 및 검출부 각각은 메모리에 로딩된 프로그램 코드 중 대응하는 부분의 명령을 실행하여 이후 단계들(610 내지 640)을 실행하기 위 한 프로세서의 서로 다른 기능적 표현들일 수 있다. 단계에서 특징맵 획득부는 영상 정보를 제1 딥 뉴럴 네트워크에 통과시킴에 따라 특징맵을 획득할 수 있다. 단계에서 입력부는 획득된 특징맵을 제2 딥 뉴럴 네트워크 및 제3 딥 뉴럴 네트워크에 각각 통과시킬 수 있다. 입력부는 획득된 특징맵을 지역적 정보를 표현하기 위한 특징맵을 획득하기 위한 제2 딥 뉴럴 네트워크 및 전역적 정보를 표현하는 특징맵을 획득하기 위한 제3 딥 뉴럴 네트워크 각각에 통과시킬 수 있다. 이때, 제2 딥 뉴럴 네트워크는, 지역적 정보를 표현하기 위한 특징값을 획득하기 위하여 6계층의 CNN 구조로 구 성되고, CNN 구조에서 6계층의 특징맵을 추출하여 객체를 검출할 수 있고, 제 3 딥 뉴럴 네트워크는, 전역적 정 보를 표현하기 위한 특징맵을 획득하기 위하여 5계층의 CNN구조로 구성되고, CNN구조에서 5계층 중 하나의 계층 의 특징맵을 활용하여 객체를 검출할 수 있다. 단계에서 융합부는 제2 딥 뉴럴 네트워크 및 제3 딥 뉴럴 네트워크에 통과시킴에 따라 획득된 각각의 특징맵을 융합 네트워크를 통하여 융합시킬 수 있다. 융합부는 제2 딥 뉴럴 네트워크 및 제3 딥 뉴럴 네 트워크에 통과시킴에 따라 획득된 각각의 특징맵이 지역적 정보의 특징맵 및 전역적 정보의 특징맵이라면, 지역 적 정보의 특징맵을 위치에 따라 각각 컨볼루션 필터에 통과시킴에 따라 객체의 종류와 위치를 포함하는 객체 정보 값을 획득하고, 전역적 정보의 특징맵의 특징값들을 펼친 후 임베딩 벡터와 연결하여 완전 연결 층에 통과 시킴에 따라 객체의 종류와 위치를 포함하는 객체 정보 값을 획득하고, 지역적 정보에 대한 객체 정보 값과 전 역적 정보에 대한 객체 정보 값을 결합할 수 있다. 융합부는 전역적 정보의 특징맵에서 지역적 정보의 특 징맵의 위치에 해당하는 특징값들을 0으로 만드는 행렬을 곱하는 마스킹 기법을 이용하여 지역적 정보의 특징맵 으로 객체에 대한 정보를 이용하고, 전역적 정보의 특징맵으로 객체 이외의 환경 정보를 이용할 수 있다. 융합 부는 지역적 정보의 특징맵을 위치에 따라 각각 컨볼루션 필터에 통과시킴에 따라 객체의 종류와 위치를 포함하는 객체 정보 값을 획득하고, 마스킹 기법이 적용된 전역적 정보의 특징맵의 특징값들을 펼친 후 완전 연 결 층에 통과시킴에 따라 획득된 값과 지역적 정보에 대한 객체 정보 값을 결합할 수 있다. 단계에서 검출부는 융합된 특징맵에 기반하여 영상 정보로부터 객체를 검출할 수 있다. 검출부(54 0)는 지역적 정보에 대한 객체 정보 값과 전역적 정보에 대한 객체 정보 값을 결합하여 완전 연결 층에 통과시 킴에 따라 획득된 객체 정보 값에 기반하여 영상 정보로부터 객체를 검출할 수 있다. 일 실시예에 따른 전역 문맥 정보를 활용하는 물체 검출 기법은 다양한 분야에 적용이 가능하다. 대표적인 적 용 가능 분야로는 스마트홈 카메라, 자율주행 자동차, 로봇공학 시스템이 있다. 첫째로, 스마트홈 카메라에서 물체 검출은 가장 중요하게 수행되어야 하는 기술로, 스마트홈 시스템이 구현되어있는 실내 환경에 존재하는 물 체들의 종류와 위치에 대한 정보를 기반으로 목적에 맞는 제안이나 기능을 수행할 수 있도록 한다. 두 번째로 자율주행 자동차에서는 주변의 다른 차량, 물체 및 보행자가 어느 위치에 존재하는지, 위험요소의 존재유무를 판단하는 역할을 하며 이를 통해 안전한 주행을 할 수 있고 사고를 미연에 방지할 수 있다. 또한 물체 검출 기 술은 로봇 공학 분야에서 로봇에 장착된 카메라 센서를 이용하여 데이터를 취득하여 로봇이 이동하는데 있어 방 해가 되는 물체나 장애물에 대한 위치정보와 크기, 종류 등을 인지하여 목적에 맞는 임무를 수행하는데 필수적 인 정보를 제공한다. 이러한 기술을 적용하기 위해서는 카메라 센서를 이용하여 데이터를 실시간으로 취득하고 이를 그래픽 프로세서 유닛(GPU) 등을 장착한 임베디드 시스템에서 물체 인식 알고리즘을 수행하는 방법이 있다. 이를 위해서는 미리 다양한 환경에 대한 데이터들을 확보하고 이를 통해 딥 뉴럴 네트워크 구조를 학습 시키게 된다. 학습된 딥 뉴럴 네트워크는 최적화된 네트워크 계수로 저장되게 되고 이를 임베디드 시스템에 적 용하여 실시간으로 입력되는 테스트 데이터에 대해 물체인지 알고리즘을 수행하여 그 결과를 얻게 된다. 딥 러닝을 기반으로 한 전역 정보 이용 물체 검출 기술은 현재 스마트홈 카메라나 자율주행, 모바일 로봇 등에 응용될 수 있으며 이 기술을 바탕으로 향후에는 인지를 넘어 물체의 추적 및 물체간의 관계 파악, 환경에 대한 이해를 통한 미래 예측 등 좀 더 복잡한 기능을 수행할 것으로 예상된다. 예를 들면, 스마트 홈 환경에서 전역정보를 이용하여 환경에 대한 이해를 바탕으로 카메라 센서만을 이용해 위험 상황의 예측 및 예방, 물체간의 관 계 파악을 통해 움직이는 물체의 향후 위치에 대한 예측이 가능하다. 또한 자율주행 환경에서는 자동화된 감시, 교통 모니터링 등의 고도화된 작업에 이용될 수 있다. 이와 같이 전역 정보를 이용한 물체 검출 알고리 즘은 미래 기술에 기초가 되는 기술로 대표적인 인공지능 기술 중의 하나라고 할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2018-0055783", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2018-0055783", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5 도면6"}
{"patent_id": "10-2018-0055783", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 객체 검출 시스템에서 객체 검출을 수행하는 딥 뉴럴 네트워크의 구조를 설명하기 위 한 도면이다. 도 2는 일 실시예에 따른 객체 검출 시스템에서 임베딩 벡터를 이용하여 지역 정보와 전역 정보를 융합하는 딥 뉴럴 네트워크의 구조를 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 객체 검출 시스템에서 마스킹 기법을 이용하여 지역 정보와 전역 정보를 융합하는 딥 뉴럴 네트워크의 구조를 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 객체 검출 시스템에서 객체를 검출하는 성능을 설명하기 위한 표이다. 도 5는 일 실시예에 따른 객체 검출 시스템의 구조를 설명하기 위한 블록도이다. 도 6은 일 실시예에 따른 객체 검출 시스템에서 객체를 인식하는 방법을 설명하기 위한 흐름도이다."}
