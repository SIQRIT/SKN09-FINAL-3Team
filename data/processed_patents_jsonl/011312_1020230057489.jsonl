{"patent_id": "10-2023-0057489", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0160765", "출원번호": "10-2023-0057489", "발명의 명칭": "객체 재인식을 위한 신경망 모델의 적응적 업데이트", "출원인": "한화비전 주식회사", "발명자": "송창호"}}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상을 획득하는 영상 획득부;사전에 학습된 객체 재인식을 위한 신경망 모델을 저장하는 메모리;상기 영상 획득부를 통해 획득된 상기 영상으로부터 객체를 검출하고, 미리 정해진 기준에 따라 상기 검출된 객체 중 상기 신경망 모델을 업데이트하기 위한 학습 데이터를 획득하는 프로세서;를 포함하고,상기 프로세서는,상기 획득된 학습 데이터를 상기 신경망 모델에 피드 포워드(feedforward) 입력함으로써 상기 학습 데이터에 대응하는 영상 특성 파라미터를 획득하고, 상기 영상 특성 파라미터를 상기 신경망 모델에 반영하여 상기 신경망모델을 업데이트하는 것을 특징으로 하는 감시 카메라 장치."}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 프로세서는,상기 신경망 모델의 내부에 상기 영상 특성 파라미터를 정규화하기 위한 배치 정규화 레이어(batchnormalization layer)를 구성하고,상기 신경망 모델에 포함된 복수의 레이어에 대하여 상기 학습 데이터를 피드 포워드함으로써, 상기 영상 특성파라미터를 업데이트하는 것을 특징으로 하는 감시 카메라 장치."}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 프로세서는,상기 학습 데이터의 평균 및 분산, 상기 복수의 레이어들 사이의 평균과 분산을 업데이트하여 상기 영상 특성파라미터를 업데이트하는 것을 특징으로 하는 감시 카메라 장치."}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 미리 정해진 기준은,상기 객체의 검출박스의 크기, 상기 객체의 형태, 상기 객체의 이동 경로 중 적어도 하나를 포함하는 것을 특징으로 하는 감시 카메라 장치."}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 영상 특성 파라미터는, 엣지 변화량, 대칭도(skewness), 노이즈(noise), 조명(illumination) 성분, 반사(reflectance) 성분 중 적어도 하나를 포함하는 것을 특징으로 하는 감시 카메라 장치."}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 사전에 학습된 신경망 모델의 학습에 이용된 제1 영상과 상기 신경망 모델을 업데이트하기 위해 이용된 제2 영상은 서로 다른 위치에 설치된 각각의 감시 카메라를 통해 획득된 영상인 것을 특징으로 하는 감시 카메라공개특허 10-2024-0160765-3-장치."}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 제1 영상과 제2 영상의 상기 영상 특성 파라미터의 적어도 하나의 요소는 서로 다른 특성을 갖는 것을 특징으로 하는 감시 카메라 장치."}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "사전에 학습된 객체 재인식을 위한 신경망 모델을 저장하는 단계;상기 감시 카메라 장치로부터 영상을 획득하는 단계;상기 영상으로부터 객체를 검출하고, 미리 정해진 기준에 따라 상기 검출된 객체 중 상기 신경망 모델을 업데이트하기 위한 학습 데이터를 획득하는 단계; 및상기 획득된 학습 데이터를 상기 신경망 모델에 피드 포워드(feedforward) 입력함으로써 상기 학습 데이터에 대응하는 영상 특성 파라미터를 획득하고, 상기 영상 특성 파라미터를 상기 신경망 모델에 반영하여 상기 신경망모델을 업데이트 하는 단계;를 포함하는 객체 재인식을 위한 신경망 모델 업데이트 방법."}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 신경망 모델을 업데이트 하는 단계는,상기 신경망 모델의 내부에 상기 영상 특성 파라미터를 정규화하기 위한 배치 정규화 레이어(batchnormalization layer)를 구성하는 단계; 및상기 신경망 모델에 포함된 복수의 레이어에 대하여 상기 학습 데이터를 피드 포워드함으로써, 상기 영상 특성파라미터를 업데이트하는 단계;를 포함하는 것을 특징으로 하는 객체 재인식을 위한 신경망 모델 업데이트 방법."}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 영상 특정 파라미터를 업데이트 하는 단계는,상기 학습 데이터의 평균 및 분산, 상기 복수의 레이어들 사이의 평균과 분산을 업데이트하여 상기 영상 특성파라미터를 업데이트하는 것을 특징으로 하는 객체 재인식을 위한 신경망 모델 업데이트 방법."}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 8 항에 있어서,상기 업데이트된 신경망 모델을 무선 통신부를 통해 상기 감시 카메라로 전송하는 단계;를 더 포함하는 것을 특징으로 하는 객체 재인식을 위한 신경망 모델 업데이트 방법."}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 8 항에 있어서,상기 사전에 학습된 신경망 모델의 학습에 이용된 제1 영상과 상기 신경망 모델을 업데이트하기 위해 이용된 제2 영상은 서로 다른 위치에 설치된 각각의 감시 카메라를 통해 획득된 영상인 것을 특징으로 하는 객체 재인식을 위한 신경망 모델 업데이트 방법."}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "공개특허 10-2024-0160765-4-제1 위치에 설치된 제1 감시 카메라를 통해 획득된 제1 영상에 기초하여 객체 재인식을 위한 신경망 모델을 학습시키는 단계;상기 학습된 신경망 모델을 제2 위치에 설치될 제2 감시 카메라에 적용하여 제2 영상을 획득하는 단계;상기 제2 영상으로부터 검출된 객체에 기초하여 상기 신경망 모델을 업데이트하기 위한 학습 데이터를 획득하는단계; 및상기 획득된 학습 데이터를 상기 신경망 모델에 피드 포워드(feedforward) 입력함으로써 획득되는 상기 제2 영상의 영상 특성 파라미터에 기초하여 상기 신경망 모델을 업데이트하는 단계;를 포함하는 객체 재인식을 위한 신경망 모델 업데이트 방법."}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 12 항에 있어서,상기 제1 영상의 영상 특성 파라미터와 상기 제2 영상의 영상 특성 파라미터는 적어도 하나의 요소에 차이가 있으며,상기 영상 특성 파라미터는,엣지 변화량, 대칭도(skewness), 노이즈(noise), 조명(illumination) 성분, 반사(reflectance) 성분 중 적어도하나를 포함하는 것을 특징으로 하는 객체 재인식을 위한 신경망 모델 업데이트 방법."}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 12 항에 있어서,상기 제1 감시 카메라와 제2 감시 카메라는 동일 객체에 대하여 서로 다른 뷰 포인트(view point)를 갖는 위치에 각각 설치된 것을 특징으로 하는 객체 재인식을 위한 신경망 모델 업데이트 방법."}
{"patent_id": "10-2023-0057489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 12 항에 있어서,상기 제1 영상에서 인식된 제1 객체에 대하여 상기 제2 영상에서 객체 재인식을 수행하는 단계;를 더 포함하고,상기 객체 재인식의 결과, 동일 객체를 서로 다른 객체로 인식한 경우 또는 기 서로 다른 객체를 상기 동일 객체로 인식한 경우, 상기 신경망 모델을 업데이트하기 위한 학습 데이터를 획득하는 단계를 수행하는 것을 특징으로 하는 객체 재인식을 위한 신경망 모델을 업데이트하는 방법."}
{"patent_id": "10-2023-0057489", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "객체 재인식을 위한 신경망 모델을 업데이트하기 위한 방법이 개시된다. 본 명세서는, 사전에 학습된 객체 재인 식을 위한 신경망 모델을 저장하고, 신규로 설치되는 사이트에서 획득된 영상으로부터 객체를 검출하고, 미리 정 해진 기준에 따라 업데이트를 위한 학습 데이터를 획득한다. 본 명세서는, 획득된 학습 데이터를 신경망 모델에 피드 포워드(feedforward) 입력함으로써 영상 특성 파라미터를 획득하고, 신경망 모델을 업데이트한다. 이에 따 라 감시 카메라 장치별로 나타나는 영상 특성에 적응할 수 있도록 재인식 신경망을 업데이트할 수 있다. 본 명세 서는 감시용 카메라, 자율주행 차량, 사용자 단말기 및 서버 중 하나 이상이 인공 지능(Artificial Intelligence) 모듈, 로봇, 증강현실(Augmented Reality, AR) 장치, 가상 현실(Virtual reality, VT) 장치, 5G 서비스와 관련된 장치 등과 연계될 수 있다."}
{"patent_id": "10-2023-0057489", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서는 객체 재인식 신경망 모델 업데이트 방법에 관한 것이다."}
{"patent_id": "10-2023-0057489", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능 기술을 이용한 사람이나 차량에 대한 검출 알고리즘이 고도화 되면서, 검출 결과를 활용하는 사 람이나 차량을 재인식(Person/Vehicle Re-Identification, Re-ID) 신경망 알고리즘도 연구 되고 있다. 사람 또 는 차량 재인식 알고리즘은 검출 시스템에 의해 검출된 사람 또는 차량들이 같은 사람인지 구분해주는 알고리즘 이다. 주로 CCTV와 같은 감시 시스템(Surveillance systems)에서 사용되는데, 특히 마트나 병원, 호텔 등의 장 소에서 여러 카메라를 설치해두고, 찾고자 하는 사람을 검색하는 시스템에 활용 된다. 재인식 신경망을 학습하기 위해서는 먼저 여러 카메라에서 촬영한 동일한 사람 또는 차량에 대해 학습 데이터 셋 구성이 필요한데, 카메라를 설치하는 비용, 데이터를 추출하는 비용, 데이터를 정제하는 비용 등이 소요 된 다. 또한, 학습 데이터 셋이 완성이 되면 이를 이용한 신경망을 학습 및 검증에 소요 시간이 수일 많게는 수 개 월이 필요할 수 있다. 또한, 학습이 완료된 사람 또는 차량 재인식 신경망을 엣지 기기(Edge device)에서 동작가능하도록 임베딩(Embedding)하는 과정도 필요하다."}
{"patent_id": "10-2023-0057489", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "CCTV 카메라가 설치 되는 장소나 설치 위치에 따라 획득되는 영상 특성은 다를 수 있다. 즉, 감시 카메라의 설 치 장소나 위치에 따라 영상에서 인식되는 특성(밝기, 배경, 블러된 정도 등)이 다를 수 있다. 이렇게 설치 장 소 혹은 별로 다른 특성을 보이는데, 이에 대응하기 위해서는 해당 사이트 및 카메라에서 수집한 데이터를 정제 하여 재인식 모델을 학습하여야 한다. 특히, 학습 가능한 데이터를 만들기 위해서는 같은 사람 이미지 셋으로 구성하는 시간과 비용이 소요될 수 있다. 또한, 여러 대의 카메라를 설치하는 비용, 수집한 데이터를 가공하기 위한 필요한 시간과 인건비 등이 필요하게 된다. 만약 새로운 장소에 설치된 감시 카메라를 통해 획득되는 영상 이 종래의 특성과 다른 특성이 나타나게 되면, 해당 장소에서 새롭게 데이터를 수집하고 정제하는 비용, 학습하 는 시간 등이 비용이 소요되는 문제점이 있다. 전술한 문제를 해결하기 위해 본 명세서는 복수의 감시 카메라 장치별로 나타나는 영상 특성에 적응할 수 있도 록 재인식 신경망을 업데이트하는 방법을 제공하는 것을 목적으로 한다. 또한, 본 명세서는 학습데이터를 레이블링 작업하지 않으며, 나아가 손실함수를 계산할 필요 없이 기 학습된 재 인식 신경망 모델을 효율적으로 업데이트 하는 방법을 제공하는 것을 목적으로 한다. 또한, 본 명세서는 엣지 디바이스 환경(감시 카메라 장치)에서도 효율적으로 재인식 신경망 모델의 업데이트가 가능한 방법을 제공하는 것을 목적으로 한다. 본 발명이 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은"}
{"patent_id": "10-2023-0057489", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 이하의 발명의 상세한 설명으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가 진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0057489", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 명세서의 일 실시예에 따른 감시 카메라 장치는, 영상을 획득하는 영상 획득부; 사전에 학습된 객체 재인식 을 위한 신경망 모델을 저장하는 메모리; 상기 영상 획득부를 통해 획득된 상기 영상으로부터 객체를 검출하고, 미리 정해진 기준에 따라 상기 검출된 객체 중 상기 신경망 모델을 업데이트하기 위한 학습 데이터를 획득하는 프로세서;를 포함하고, 상기 프로세서는, 상기 획득된 학습 데이터를 상기 신경망 모델에 피드 포워드 (feedforward) 입력함으로써 상기 학습 데이터에 대응하는 영상 특성 파라미터를 획득하고, 상기 영상 특성 파 라미터를 상기 신경망 모델에 반영하여 상기 신경망 모델을 업데이트할 수 있다. 상기 프로세서는, 상기 신경망 모델의 내부에 상기 영상 특성 파라미터를 정규화하기 위한 배치 정규화 레이어 (batch normalization layer)를 구성하고, 상기 신경망 모델에 포함된 복수의 레이어에 대하여 상기 학습 데이 터를 피드 포워드함으로써, 상기 영상 특성 파라미터를 업데이트할 수 있다. 상기 프로세서는, 상기 학습 데이터의 평균 및 분산, 상기 복수의 레이어들 사이의 평균과 분산을 업데이트하여 상기 영상 특성 파라미터를 업데이트할 수 있다. 상기 미리 정해진 기준은, 상기 객체의 검출박스의 크기, 상기 객체의 형태, 상기 객체의 이동 경로 중 적어도 하나를 포함할 수 있다. 상기 영상 특성 파라미터는, 엣지 변화량, 대칭도(skewness), 노이즈(noise), 조명(illumination) 성분, 반사 (reflectance) 성분 중 적어도 하나를 포함할 수 있다. 상기 사전에 학습된 신경망 모델의 학습에 이용된 제1 영상과 상기 신경망 모델을 업데이트하기 위해 이용된 제 2 영상은 서로 다른 위치에 설치된 각각의 감시 카메라를 통해 획득된 영상일 수 있다. 상기 제1 영상과 제2 영상의 상기 영상 특성 파라미터의 적어도 하나의 요소는 서로 다른 특성을 가질 수 있다. 본 명세서의 다른 실시예에 따른 객체 재인식을 위한 신경망 모델 업데이트 방법은, 사전에 학습된 객체 재인식 을 위한 신경망 모델을 저장하는 단계; 상기 감시 카메라 장치로부터 영상을 획득하는 단계; 상기 영상으로부터 객체를 검출하고, 미리 정해진 기준에 따라 상기 검출된 객체 중 상기 신경망 모델을 업데이트하기 위한 학습 데이터를 획득하는 단계; 및 상기 획득된 학습 데이터를 상기 신경망 모델에 피드 포워드(feedforward) 입력함으로써 상기 학습 데이터에 대응하는 영상 특성 파라미터를 획득하고, 상기 영상 특성 파라미터를 상기 신경망 모델에 반영하여 상기 신경망 모델을 업데이트 하는 단계;를 포함한다. 상기 신경망 모델을 업데이트 하는 단계는, 상기 신경망 모델의 내부에 상기 영상 특성 파라미터를 정규화하기 위한 배치 정규화 레이어(batch normalization layer)를 구성하는 단계; 및 상기 신경망 모델에 포함된 복수의 레이어에 대하여 상기 학습 데이터를 피드 포워드함으로써, 상기 영상 특성 파라미터를 업데이트하는 단계;를 포함할 수 있다. 상기 영상 특정 파라미터를 업데이트 하는 단계는, 상기 학습 데이터의 평균 및 분산, 상기 복수의 레이어들 사 이의 평균과 분산을 업데이트하여 상기 영상 특성 파라미터를 업데이트할 수 있다. 상기 신경망 모델 업데이트 방법은, 상기 업데이트된 신경망 모델을 무선 통신부를 통해 상기 감시 카메라로 전 송하는 단계;를 더 포함할 수 있다. 상기 사전에 학습된 신경망 모델의 학습에 이용된 제1 영상과 상기 신경망 모델을 업데이트하기 위해 이용된 제 2 영상은 서로 다른 위치에 설치된 각각의 감시 카메라를 통해 획득된 영상일 수 있다. 본 명세서의 일 실시에에 따른 다른 객체 재인식을 위한 신경망 모델 업데이트 방법은, 제1 위치에 설치된 제1 감시 카메라를 통해 획득된 제1 영상에 기초하여 객체 재인식을 위한 신경망 모델을 학습시키는 단계; 상기 학 습된 신경망 모델을 제2 위치에 설치될 제2 감시 카메라에 적용하여 제2 영상을 획득하는 단계; 상기 제2 영상 으로부터 검출된 객체에 기초하여 상기 신경망 모델을 업데이트하기 위한 학습 데이터를 획득하는 단계; 및 상 기 획득된 학습 데이터를 상기 신경망 모델에 피드 포워드(feedforward) 입력함으로써 획득되는 상기 제2 영상 의 영상 특성 파라미터에 기초하여 상기 신경망 모델을 업데이트하는 단계;를 포함한다. 상기 제1 영상의 영상 특성 파라미터와 상기 제2 영상의 영상 특성 파라미터는 적어도 하나의 요소에 차이가 있 으며, 상기 영상 특성 파라미터는, 엣지 변화량, 대칭도(skewness), 노이즈(noise), 조명(illumination) 성분, 반사(reflectance) 성분 중 적어도 하나를 포함할 수 있다. 상기 제1 감시 카메라와 제2 감시 카메라는 동일 객체에 대하여 서로 다른 뷰 포인트(view point)를 갖는 위치 에 각각 설치된 카메라일 수 있다. 상기 신경망 모델 업데이트 방법은, 상기 제1 영상에서 인식된 제1 객체에 대하여 상기 제2 영상에서 객체 재인 식을 수행하는 단계;를 더 포함하고, 상기 객체 재인식의 결과, 동일 객체를 서로 다른 객체로 인식한 경우 또 는 기 서로 다른 객체를 상기 동일 객체로 인식한 경우, 상기 신경망 모델을 업데이트하기 위한 학습 데이터를 획득하는 단계를 수행할 수 있다."}
{"patent_id": "10-2023-0057489", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 명세서의 일 실시예에 따르면, 복수의 감시 카메라 장치별로 나타나는 영상 특성에 적응할 수 있도록 재인식 신경망을 업데이트할 수 있다. 또한, 본 명세서의 일 실시예에 따르면, 데이터를 레이블링 작업하지 않으며, 나아가 손실함수를 계산할 필요 없이 기 학습된 재인식 신경망 모델을 효율적으로 업데이트할 수 있다. 또한, 본 명세서의 일 실시예에 따르면, 엣지 디바이스 환경(감시 카메라 장치)에서도 효율적으로 재인식 신경 망 모델의 업데이트할 수 있다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2023-0057489", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0057489", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 도 1은 본 명세서의 일 실시예에 따른 감시 카메라의 영상 처리 방법을 구현하기 위한 감시 카메라 시스템을 설 명하기 위한 도면이다. 도 1을 참조하면, 본 명세서의 일 실시예에 따른 영상 관리 시스템은 촬영 장치(100a, 100b, 100c, 이하, 설명의 편의를 위해 100으로 호칭) 및 영상 관리 서버을 포함할 수 있다. 촬영 장치는 특정 장소의 고정된 위치에 배치되는 촬영용 전자 장치일 수도 있고, 일정한 경로를 따라 자동 또는 수동으로 움직일 수 있 는 촬영용 전자 장치일 수도 있고, 사람 또는 로봇 등에 의하여 이동될 수 있는 촬영용 전자 장치일 수도 있다. 촬영 장치는 유무선 인터넷에 연결하여 사용하는 IP 카메라일 수 있다. 촬영 장치는 팬(pan), 틸트 (tilt), 및 줌(zoom) 기능을 갖는 PTZ 카메라일 수 있다. 촬영 장치는 감시 하는 영역을 녹화하거나 사진 을 촬영하는 기능을 가질 수 있다. 촬영 장치는 감시하는 영역에서 발생하는 소리를 녹음하는 기능을 가질 수 있다. 촬영 장치는 감시하는 영역에서 움직임 또는 소리 등 변화가 발생 할 경우, 이에 대한 알림을 발 생시키거나 녹화 또는 사진 촬영을 수행하는 기능을 가질 수 있다. 상기 촬영 장치는 서로 다른 공간에 설치된 복수의 촬영 장치(100a, 100b, 100c)를 포함할 수 있다. 예를 들어, 제1 촬영 장치(100a)와 제2 촬영 장치(100b)는 제1 간격으로 이격되며, 제2 촬영 장치(100b)와 제3 촬영 장치(100c)는 제2 간격으로 이격되어 있을 수 있다. 즉, 각각의 촬영장치(100a, 100b, 100c)는 동일한 인물에 대하여 소정의 시간 간격을 두고 촬영 가능한 위치에 각각 배치되어 있는 CCTV 형태로 구현되는 시스템일 수 있다. 상기 복수의 촬영 장치(100a, 100b, 100c)는 하나의 영상 관리 서버에서 영상 관리를 위해 영상 데이터를 각각 수집하는 장치일 수 있다. 이에 따라 복수의 촬영 장치(100a, 100b, 100c)에서 획득한 각각의 영상에 동일 한 객체가 포함되어 있다고 하더라도 복수의 촬영 장치(100a, 100b, 100c)가 설치된 위치의 조명, 배경, 각 촬 영 장치의 뷰 포인트 등에 따라 서로 다른 객체로 인식될 수도 있다. 즉, 제1 객체가 제1 촬영 장치(100a)에서 검출된 후, 객체 이동을 통해 순차적으로 제2 촬영 장치(100b), 제3 촬영 장치(100c)에서도 각각 검출될 수 있 다. 영상 관리 서버는 제1 객체를 제2 촬영 장치(100b) 및 제3 촬영 장치(100c)에서도 동일한 제1 객체로 인식하는지 여부를 확인하기 위해 객체 재인식 동작을 수행할 수 있다. 객체 재인식 동작을 수행한 결과, 상기 제1 객체에 대하여 상기 제1 촬영 장치(100a), 제2 촬영 장치(100b) 및 제3 촬영 장치(100c)에서 모두 서로 다 른 객체로 인식하는 경우, 영상 관리 서버 및/또는 각 촬영 장치(100a, 100b, 100c)가 포함하고 있는 객체 재인식을 위한 신경망 모델을 업데이트할 필요가 있다. 영상 관리 서버는 촬영 장치를 통하여 촬영된 영상 자체 및/또는 해당 영상을 편집하여 얻어지는 영 상을 수신하여 저장 및/또는 검색기능을 갖는 장치일 수 있다. 영상 관리 서버는 수신한 용도에 대응되도 록 분석할 수 있다. 예를 들어, 영상 관리 서버는 영상에서 객체를 검출하기 위해 객체 검출 알고리즘을 이용하여 객체를 검출할 수 있다. 상기 객체 검출 알고리즘은 AI 기반 알고리즘이 적용될 수 있으며, 미리 학습 된 인공신경망 모델을 적용하여 객체를 검출할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 영상 관리 서버는 영상 검색 장치로서의 기능을 수행할 수 있다. 상기 영상 검색 장치는, 복수의 감시 카메라 채널로부터 획득하는 영상들에 대하여 특정 영상, 특정 영상에 포 함된 객체 또는 특정 채널을 검색 조건으로 입력하면 빠르고 용이하게 검색할 수 있다. 영상 검색 장치는 사용 자가 영상을 용이하게 검색할 수 있도록 데이터 베이스를 구축하는 과정이 선행되어야 하며, 본 명세서의 일 실 시예는 특정 검색 조건에 따라 영상 검색을 수행함에 검색 대상의 크기를 제한하여 연산량을 제한하는 방법을 제안한다. 한편, 상기 영상 관리 서버는 네트워크를 통해 획득된 영상을 저장하는 기능을 수행하는 NVR(Network Video Recoder) 또는 DVR(Digital Video Recoder)일 수 있다. 또는 영상을 통합적으로 관리 및 제어하여, 원격 으로 영상을 모니터링할 수 있는 CMS(Central Management System)일 수도 있다. 한편, 이에 한정되지 않고 영상 관리 서버는 퍼스널 컴퓨터 또는 휴대용 단말기일 수도 있다. 다만, 이는 예시적인 것으로 본 명세서의 기 술적 사상은 이에 제한되는 것은 아니며, 네트워크를 통해 하나 이상의 감시 카메라로부터 멀티 미디어 개체를 전송 받아 디스플레이 및/또는 저장할 수 있는 장치이면 제한없이 사용될 수 있음은 물론이다. 한편, 영상 관리 서버는 영상 분석 목적에 맞는 다양한 학습 모델을 저장하고 있을 수 있다. 전술한 객체 검출을 위한 학습 모델 외에, 검출된 객체의 이동 속도를 획득할 수 있는 모델을 저장하고 있을 수도 있다. 여 기서 상기 학습된 모델들은 상기 복수의 촬영 장치(100a, 100b, 100c)를 통해 촬영된 영상 즉, 영상 촬영 시간 과 영상 촬영 위치가 서로 다른 영상을 입력데이터로 하여, 상기 촬영된 영상에 포함된 인물의 성별과 영상의 특징벡터 값을 출력하는 학습 모델을 포함할 수도 있다. 또한, 영상 관리 서버는 수신한 영상을 분석하여 메타 데이터와 해당 메타 데이터에 대한 인덱스 정보를 생성할 수 있다. 영상 관리 서버는 수신한 영상에 포함된 영상 정보 및 /또는 음향 정보를 함께 또는 별도 로 분석하여 메타 데이터와 해당 메타 데이터에 대한 인덱스 정보를 생성할 수 있다. 상기 메타 데이터는 영상 이 촬영된 시간정보, 촬영 위치 정보 등을 더 포함할 수도 있다. 영상 관리 시스템은 촬영 장치 및/또는 영상 관리 서버와 유무선 통신을 수행할 수 있는 외부 장 치를 더 포함할 수 있다. 외부 장치는 영상 관리 서버로 영상 전체 또는 일부의 제공을 요청하는 정보 제공 요청 신호를 송신 할 수 있다. 외부 장치는 영상 관리 서버로 영상 분석 결과 객체의 존재 여부, 객체의 이동 속도, 객 체의 이동 속도에 따른 셔터 속도 조절값, 객체의 이동 속도에 따른 노이즈 제거값, 센서 이득값 등을 요청하는 정보 제공 요청 신호를 송신할 수 있다. 또한 외부 장치는 영상 관리 서버로 영상을 분석하여 얻어진 메타 데이터 및/또는 메타 데이터에 대한 인덱스 정보를 요청하는 정보 제공 요청 신호를 송신할 수 있다. 영상 관리 시스템은 촬영 장치, 영상 관리 서버, 및/또는 외부 장치 간의 유무선 통신 경로 인 통신망을 더 포함할 수 있다. 통신망은 예컨대 LANs(Local Area Networks), WANs(Wide Area Networks), MANs(Metropolitan Area Networks), ISDNs(Integrated Service Digital Networks) 등의 유선 네트워크나, 무선 LANs, CDMA, 블루투스, 위성 통신 등의 무선 네트워크를 망라할 수 있으나, 본 명세서의 범위가 이에 한정되는 것은 아니다. 도 2는 본 명세서의 일 실시예에 따른 감시 카메라의 개략적인 블록도이다. 도 2는 도 1에 도시된 카메라의 구성을 나타내는 블록도이다. 도 2를 참조하면,카메라는 지능형 영상분석 기능을 수행하여 상기 영상분석 신호를 생성하는 네트워크 카메라임을 그 예로 설명하나, 본 발명의 실시예에 의한 네트워크 감시 카메라 시스템의 동작이 반드시 이에 한정되는 것은 아니다. 카메라는 이미지 센서, 인코더, 메모리, 이벤트 센서, 프로세서, 및 통신부 를 포함한다. 이미지 센서는 감시 영역을 촬영하여 영상을 획득하는 기능을 수행하는 것으로서, 예컨대, CCD(Charge- Coupled Device) 센서, CMOS(Complementary Metal-Oxide-Semiconductor) 센서 등으로 구현될 수 있다. 인코더는 이미지 센서를 통해 획득한 영상을 디지털 신호로 부호화하는 동작을 수행하며, 이는 예컨 대, H.264, H.265, MPEG(Moving Picture Experts Group), M-JPEG(Motion Joint Photographic Experts Group) 표준 등을 따를 수 있다. 메모리는 영상 데이터, 음성 데이터, 스틸 이미지, 메타데이터 등을 저장할 수 있다. 앞서 언급한 바와 같 이, 상기 메타데이터는 상기 감시영역에 촬영된 객체 검출 정보(움직임, 소리, 지정지역 침입 등), 객체 식별 정보(사람, 차, 얼굴, 모자, 의상 등), 및 검출된 위치 정보(좌표, 크기 등)을 포함하는 데이터일 수 있다. 또한, 상기 스틸 이미지는 상기 메타데이터와 함께 생성되어 메모리에 저장되는 것으로서, 상기 영상분석 정보들 중 특정 분석 영역에 대한 이미지 정보를 캡쳐하여 생성될 수 있다. 일 예로, 상기 스틸 이미지는 JPEG 이미지 파일로 구현될 수 있다. 일 예로, 상기 스틸 이미지는 특정 영역 및 특정 기간 동안 검출된 상기 감시영역의 영상 데이터들 중 식별 가 능한 객체로 판단된 영상 데이터의 특정영역을 크롭핑(cropping)하여 생성될 수 있으며, 이는 상기 메타데이터 와 함께 실시간으로 전송될 수 있다. 메모리는 객체 인식을 위해 학습된 신경망 모델을 저장할 수 있다. 신경망 모델은 영상 특성 파라미터인 밝기와 분산을 고려하여 구성되고 학습될 수 있다. 각 신경망 층에서 특징(feature)이 추출되면, 특징 값에 대 해서 밝기와 분산을 고려하여 학습될 수 있다. 신경망 학습이 완료되면 학습 데이터에 따라 정해진 영상 특성 파라미터는 고정되며 변경되지 않을 수 있다. 상기 신경망 모델은 도 1의 영상 관리 서버로부터 수신하여 프로세서에 의해 메모리에 저장될 수 있다. 또한, 상기 신경망 모델은 영상 촬영 장치에서 독립 적으로 학습되어 메모리에 저장될 수도 있다. 본 명세서의 일 실시예들은 객체 탐지에 있어서 YOLO(You Only Lock Once) 알고리즘을 적용할 수 있다. YOLO은 객체 검출 속도가 빠르기 때문에 실시간 동영상을 처리하는 감시 카메라에 적당한 AI 알고리즘이다. YOLO 알고 리즘은 다른 객체 기반 알고리즘들(Faster R-CNN, R_FCN, FPN-FRCN 등)과 달리 한 장의 입력 영상을 리사이즈 (Resize)후 단일 신경망을 단 한 번 통과킨 결과로 각 객체의 위치를 인디케이팅하는 바운딩 박스(Bounding Box)와 객체가 무엇인지 분류 확률을 출력한다. 최종적으로 Non-max suppression을 통해 하나의 객체를 한번 인 식(detection)한다. 한편, 본 명세서에 개시되는 객체 인식 알고리즘은 전술한 YOLO에 한정되지 않고 다양한 딥러닝 알고리즘으로 구현될 수 있음을 밝혀둔다. 통신부는 상기 영상 데이터, 음성 데이터, 스틸 이미지, 및/또는 메타데이터를 영상수신/검색장치(도 1의 300)에 전송한다. 일 실시예에 따른 통신부는 영상 데이터, 음성 데이터, 스틸 이미지, 및/또는 메타데이 터를 영상수신장치(도 1의 300)에 실시간으로 전송할 수 있다. 통신부는 유무선 LAN(Local Area Network), 와이파이(Wi-Fi), 지그비(ZigBee), 블루투스(Bluetooth), 근거리 통신(Near Field Communication) 중 적어도 하나의 통신 기능을 수행할 수 있다. 한편, 본 명세서의 일 실시예에 따라 감시 카메라를 통해 획득된 영상에 대한 객체 인식, 객체 인식을 위한 신 경망 모델의 학습은 도 2에 도시된 프로세서의 제어에 따라 수행될 수 있으나, 인공 지능 영상 분석을 위 해 독립적으로 마련되는 AI 장치(모듈)에 의해 수행될 수도 있다. 설명의 편의상 도 3에서 AI 장치(모듈)에 대 해 설명하지만, 도 3의 모듈이 수행하는 기능은 도 2의 프로세서에서도 함께 수행될 수 있음은 물론이다.도 3은 본 명세서의 일 실시예에 따른 영상 검색 장치에 적용되는 AI 장치(모듈)을 설명하기 위한 도면이다. 도 3을 살펴보면, AI 장치는 AI 프로세싱을 수행할 수 있는 AI 모듈을 포함하는 전자 기기 또는 AI 모듈을 포함하는 서버 등을 포함할 수 있다. 또한, AI 장치는 감시 카메라 또는 영상 관리 서버의 적어도 일부의 구성으로 포함되어 AI 프로세싱 중 적어도 일부를 함께 수행하도록 구비될 수도 있다. AI 프로세싱은 감시카메라 또는 영상 관리 서버의 제어부(프로세서)와 관련된 모든 동작들을 포함할 수 있다. 예를 들어, 감시 카메라 또는 영상 관리 서버는 획득된 영상 신호를 AI 프로세싱 하여 처리/판단, 제어 신호 생 성 동작을 수행할 수 있다. AI 장치는 AI 프로세싱 결과를 직접 이용하는 클라이언트 디바이스이거나, AI 프로세싱 결과를 다른 기기 에 제공하는 클라우드 환경의 디바이스일 수도 있다. AI 장치는 신경망을 학습할 수 있는 컴퓨팅 장치로서, 서버, 데스크탑 PC, 노트북 PC, 태블릿 PC 등과 같은 다양한 전자 장치로 구현될 수 있다. AI 장치는 AI 프로세서, 메모리 및/또는 통신부를 포함할 수 있다. AI 프로세서는 메모리에 저장된 프로그램을 이용하여 신경망을 학습할 수 있다. 특히, AI 프로세서(2 1)는 감시 카메라의 관련 데이터를 인식하기 위한 신경망을 학습할 수 있다. 여기서, 감시 카메라의 관련 데이 터를 인식하기 위한 신경망은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며, 인간의 신경망의 뉴런(neuron)을 모의하는, 가중치를 갖는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 모드들은 뉴런이 시냅스(synapse)를 통해 신호를 주고 받는 뉴런의 시냅틱 활동을 모의하도록 각각 연결 관계에 따라 데 이터를 주고 받을 수 있다. 여기서 신경망은 신경망 모델에서 발전한 딥러닝 모델을 포함할 수 있다. 딥러닝 모 델에서 복수의 네트워크 노드들은 서로 다른 레이어에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데 이터를 주고 받을 수 있다. 신경망 모델의 예는 심층 신경망(DNN, deep neural networks), 합성곱 신경망(CNN, convolutional deep neural networks), 순환 신경망(RNN, Recurrent Boltzmann Machine), 제한 볼츠만 머신 (RBM, Restricted Boltzmann Machine), 심층 신뢰 신경망(DBN, deep belief networks), 심층 Q-네트워크(Deep Q-Network)와 같은 다양한 딥 러닝 기법들을 포함하며, 컴퓨터비젼, 음성인식, 자연어처리, 음성/신호처리 등의 분야에 적용될 수 있다. 한편, 전술한 바와 같은 기능을 수행하는 프로세서는 범용 프로세서(예를 들어, CPU)일 수 있으나, 인공지능 학 습을 위한 AI 전용 프로세서(예를 들어, GPU)일 수 있다. 메모리는 AI 장치의 동작에 필요한 각종 프로그램 및 데이터를 저장할 수 있다. 메모리는 비 휘발 성 메모리, 휘발성 메모리, 플래시 메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드 라이브(SDD) 등으로 구현할 수 있다. 메모리는 AI 프로세서에 의해 액세스되며, AI 프로세서에 의 한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 또한, 메모리는 본 발명의 일 실시예에 따른 데이터 분류/인식을 위한 학습 알고리즘을 통해 생성된 신경망 모델(예를 들어, 딥 러닝 모델)을 저장할 수 있다. 한편, AI 프로세서는 데이터 분류/인식을 위한 신경망을 학습하는 데이터 학습부를 포함할 수 있다. 데 이터 학습부는 데이터 분류/인식을 판단하기 위하여 어떤 학습 데이터를 이용할지, 학습 데이터를 이용하여 데이터를 어떻게 분류하고 인식할지에 관한 기준을 학습할 수 있다. 데이터 학습부는 학습에 이용될 학습 데이터를 획득하고, 획득된 학습데이터를 딥러닝 모델에 적용함으로써, 딥러닝 모델을 학습할 수 있다. 데이터 학습부는 적어도 하나의 하드웨어 칩 형태로 제작되어 AI 장치에 탑재될 수 있다. 예를 들어, 데이터 학습부는 인공지능(AI)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 범용 프로세서(CPU) 또 는 그래픽 전용 프로세서(GPU)의 일부로 제작되어 AI 장치에 탑재될 수도 있다. 또한, 데이터 학습부 는 소프트웨어 모듈로 구현될 수 있다. 소프트웨어 모듈(또는 인스트럭션(instruction)을 포함하는 프로그램 모 듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록 매체 (non-transitory computer readable media)에 저장될 수 있다. 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 애플리케이션에 의해 제공될 수 있다. 데이터 학습부는 학습 데이터 획득부 및 모델 학습부를 포함할 수 있다. 학습 데이터 획득부는 데이터를 분류하고 인식하기 위한 신경망 모델에 필요한 학습 데이터를 획득할 수 있 다. 모델 학습부는 획득된 학습 데이터를 이용하여, 신경망 모델이 소정의 데이터를 어떻게 분류할지에 관한 판 단 기준을 가지도록 학습할 수 있다. 이 때 모델 학습부는 학습 데이터 중 적어도 일부를 판단 기준으로 이 용하는 지도 학습(supervised learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 또는 모델 학습부는 지도 없이 학습 데이터를 이용하여 스스로 학습함으로써, 판단 기준을 발견하는 비지도 학습(unsupervised learning)을 통해 신경망 모델을 학습시킬 수 있다. 또한, 모델 학습부는 학습에 따른 상황 판단의 결과가 올바른지에 대한 피드백을 이용하여 강화 학습(reinforcement learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 또한, 모델 학습부는 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient decent)을 포함하는 학습 알고리즘을 이용하여 신경망 모델을 학습시킬 수 있다. 신경망 모델이 학습되면, 모델 학습부는 학습된 신경망 모델을 메모리에 저장할 수 있다. 모델 학습부 는 학습된 신경망 모델을 AI 장치와 유선 또는 무선 네트워크로 연결된 서버의 메모리에 저장할 수도 있다. 데이터 학습부는 인식 모델의 분석 결과를 향상시키거나, 인식 모델의 생성에 필요한 리소스 또는 시간을 절약하기 위해 학습 데이터 전처리부(미도시) 및 학습 데이터 선택부(미도시)를 더 포함할 수도 있다. 학습 데이터 전처리부는 획득된 데이터가 상황 판단을 위한 학습에 이용될 수 있도록, 획득된 데이터를 전처리 할 수 있다. 예를 들어, 학습 데이터 전처리부는, 모델 학습부가 이미지 인식을 위한 학습을 위하여 획득된 학습 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다. 또한, 학습 데이터 선택부는, 학습 데이터 획득부에서 획득된 학습 데이터 또는 전처리부에서 전처리된 학 습 데이터 중 학습에 필요한 데이터를 선택할 수 있다.선택된 학습 데이터는 모델 학습부에 제공될 수 있다. 또한, 데이터 학습부는 신경망 모델의 분석 결과를 향상시키기 위하여 모델 평가부(미도시)를 더 포함할 수 도 있다. 모델 평가부는, 신경망 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 분석 결과가 소정 기준을 만족하지 못하는 경우, 모델 학습부로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가 데이터는 인식 모델을 평가하기 위한 기 정의된 데이터일 수 있다. 일 예로, 모델 평가부는 평가 데이터에 대한 학습된 인식 모델의 분석 결과 중, 분석 결과가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정되 임계치를 초과 하는 경우, 소정 기준을 만족하지 못한 것으로 평가할 수 있다. 통신부는 AI 프로세서에 의한 AI 프로세싱 결과를 외부 전자 기기로 전송할 수 있다. 예를 들어, 외부 전자 기기는 감시카메라, 블루투스 장치, 자율주행 차량, 로봇, 드론, AR 기기, 모바일 기기, 가전 기기 등을 포함할 수 있다. 한편, 도 3에 도시된 AI 장치는 AI 프로세서와 메모리, 통신부 등으로 기능적으로 구분하여 설 명하였지만, 전술한 구성요소들이 하나의 모듈로 통합되어 AI 모듈로 호칭될 수도 있음을 밝혀둔다. 본 명세서는 감시용 카메라, 자율주행 차량, 사용자 단말기 및 서버 중 하나 이상이 인공 지능(Artificial Intelligence) 모듈, 로봇, 증강현실(Augmented Reality, AR) 장치, 가상 현실(Virtual reality, VT) 장치, 5G, 6G 서비스와 관련된 장치 등과 연계될 수 있다. 도 1은 본 명세서의 일 실시예에 따른 감시 카메라의 영상 처리 방법을 구현하기 위한 감시 카메라 시스템을 설 명하기 위한 도면이다. 도 1을 참조하면, 본 명세서의 일 실시예에 따른 영상 관리 시스템은 촬영 장치 및 영상 관리 서버 을 포함할 수 있다. 촬영 장치는 특정 장소의 고정된 위치에 배치되는 촬영용 전자 장치일 수도 있고, 일정한 경로를 따라 자 동 또는 수동으로 움직일 수 있는 촬영용 전자 장치일 수도 있고, 사람 또는 로봇 등에 의하여 이동될 수 있는 촬영용 전자 장치일 수도 있다. 촬영 장치는 유무선 인터넷에 연결하여 사용 하는 IP 카메라일 수 있다. 촬영 장치는 팬(pan), 틸트(tilt), 및 줌(zoom) 기능을 갖는 PTZ 카메라일 수 있다. 촬영 장치는 감시 하는 영역을 녹화하거나 사진을 촬영하는 기능을 가질 수 있다. 촬영 장치는 감시하는 영역에서 발생하는 소리를 녹음하는 기능을 가질 수 있다. 촬영 장치는 감시하는 영역에서 움직 임 또는 소리 등 변화가 발생 할 경우, 이에 대한 알림을 발생시키거나 녹화 또는 사진 촬영을 수행하는 기능을가질 수 있다. 영상 관리 서버는 촬영 장치를 통하여 촬영된 영상 자체 및/또는 해당 영상을 편집하여 얻어지는 영 상을 수신하여 저장하는 장치일 수 있다. 영상 관리 서버는 수신한 용도에 대응되도록 분석할 수 있다. 예 를 들어, 영상 관리 서버는 영상에서 객체를 검출하기 위해 객체 검출 알고리즘을 이용하여 객체를 검출할 수 있다. 상기 객체 검출 알고리즘은 AI 기반 알고리즘이 적용될 수 있으며, 미리 학습된 인공신경망 모델을 적 용하여 객체를 검출할 수 있다. 한편, 영상 관리 서버는 영상 분석 목적에 맞는 다양한 학습 모델을 저장하고 있을 수 있다. 전술한 객체 검출을 위한 학습 모델 외에, 검출된 객체의 이동 속도를 획득할 수 있는 모델을 저장하고 있을 수도 있다. 여 기서 상기 학습된 모델들은 객체의 이동 속도에 대응되는 셔터 속도, 또는 셔터 속도가 제어됨에 따라 밝기를 보상하기 위한 센서의 이득값을 출력하는 학습 모델을 포함할 수도 있다. 또한, 상기 학습된 모델들은 AI 객체 인식 알고리즘을 통해 분석된 객체의 이동속도에 따라 모션 블러 강도를 검출하고, 검출된 모션 블러 강도를 유 발하는 촬영 환경에 최적의 셔터속도 및/또는 센서 이득값이 출력되도록 학습된 모델을 통해 구현될 수도 있다. 또한, 영상 관리 서버는 수신한 영상을 분석하여 메타 데이터와 해당 메타 데이터에 대한 인덱스 정보를 생성할 수 있다. 영상 관리 서버는 수신한 영상에 포함된 영상 정보 및 /또는 음향 정보를 함께 또는 별도 로 분석하여 메타 데이터와 해당 메타 데이터에 대한 인덱스 정보를 생성할 수 있다. 영상 관리 시스템은 촬영 장치 및/또는 영상 관리 서버와 유무선 통신을 수행할 수 있는 외부 장 치를 더 포함할 수 있다. 외부 장치는 영상 관리 서버로 영상 전체 또는 일부의 제공을 요청하는 정보 제공 요청 신호를 송신 할 수 있다. 외부 장치는 영상 관리 서버로 영상 분석 결과 객체의 존재 여부, 객체의 이동 속도, 객 체의 이동 속도에 따른 셔터 속도 조절값, 객체의 이동 속도에 따른 노이즈 제거값, 센서 이득값 등을 요청하는 정보 제공 요청 신호를 송신할 수 있다. 또한 외부 장치는 영상 관리 서버로 영상을 분석하여 얻어진 메타 데이터 및/또는 메타 데이터에 대한 인덱스 정보를 요청하는 정보 제공 요청 신호를 송신할 수 있다. 영상 관리 시스템은 촬영 장치, 영상 관리 서버, 및/또는 외부 장치 간의 유무선 통신 경로 인 통신망을 더 포함할 수 있다. 통신망은 예컨대 LANs(Local Area Networks), WANs(Wide Area Networks), MANs(Metropolitan Area Networks), ISDNs(Integrated Service Digital Networks) 등의 유선 네트 워크나, 무선 LANs, CDMA, 블루투스, 위성 통신 등의 무선 네트워크를 망라할 수 있으나, 본 명세서의 범위가 이 에 한정되는 것은 아니다. 도 2는 본 명세서의 일 실시예에 따른 감시 카메라의 개략적인 블록도이다. 도 2는 도 1에 도시된 카메라의 구성을 나타내는 블록도이다. 도 2를 참조하면,카메라는 지능형 영상분석 기능을 수행하여 상기 영상분석 신호를 생성하는 네트워크 카메라임을 그 예로 설명하나, 본 발명의 실시예에 의한 네트워크 감시 카메라 시스템의 동작이 반드시 이에 한정되는 것은 아니다. 카메라는 이미지 센서, 인코더, 메모리, 이벤트 센서, 프로세서, 및 통신부 를 포함한다. 이미지 센서는 감시 영역을 촬영하여 영상을 획득하는 기능을 수행하는 것으로서, 예컨대, CCD(Charge- Coupled Device) 센서, CMOS(Complementary Metal-Oxide-Semiconductor) 센서 등으로 구현될 수 있다. 인코더는 이미지 센서를 통해 획득한 영상을 디지털 신호로 부호화하는 동작을 수행하며, 이는 예컨 대, H.264, H.265, MPEG(Moving Picture Experts Group), M-JPEG(Motion Joint Photographic Experts Group) 표준 등을 따를 수 있다. 메모리는 영상 데이터, 음성 데이터, 스틸 이미지, 메타데이터 등을 저장할 수 있다. 앞서 언급한 바와 같 이, 상기 메타데이터는 상기 감시영역에 촬영된 객체 검출 정보(움직임, 소리, 지정지역 침입 등), 객체 식별 정보(사람, 차, 얼굴, 모자, 의상 등), 및 검출된 위치 정보(좌표, 크기 등)을 포함하는 데이터일 수 있다. 또한, 상기 스틸 이미지는 상기 메타데이터와 함께 생성되어 메모리에 저장되는 것으로서, 상기 영상분석 정보들 중 특정 분석 영역에 대한 이미지 정보를 캡쳐하여 생성될 수 있다. 일 예로, 상기 스틸 이미지는 JPEG 이미지 파일로 구현될 수 있다. 일 예로, 상기 스틸 이미지는 특정 영역 및 특정 기간 동안 검출된 상기 감시영역의 영상 데이터들 중 식별 가 능한 객체로 판단된 영상 데이터의 특정영역을 크롭핑(cropping)하여 생성될 수 있으며, 이는 상기 메타데이터 와 함께 실시간으로 전송될 수 있다. 메모리는 객체 인식을 위해 학습된 신경망 모델을 저장할 수 있다. 신경망 모델은 영상 특성 파라미터인 밝기와 분산을 고려하여 구성되고 학습될 수 있다. 각 신경망 층에서 특징(feature)이 추출되면, 특징 값에 대 해서 밝기와 분산을 고려하여 학습될 수 있다. 신경망 학습이 완료되면 학습 데이터에 따라 정해진 영상 특성 파라미터는 고정되며 변경되지 않을 수 있다. 상기 신경망 모델은 도 1의 영상 관리 서버로부터 수신하여 프로세서에 의해 메모리에 저장될 수 있다. 또한, 상기 신경망 모델은 영상 촬영 장치에서 독립 적으로 학습되어 메모리에 저장될 수도 있다. 본 명세서의 일 실시예들은 객체 탐지에 있어서 YOLO(You Only Lock Once) 알고리즘을 적용할 수 있다. YOLO은 객체 검출 속도가 빠르기 때문에 실시간 동영상을 처리하는 감시 카메라에 적당한 AI 알고리즘이다. YOLO 알고 리즘은 다른 객체 기반 알고리즘들(Faster R-CNN, R_FCN, FPN-FRCN 등)과 달리 한 장의 입력 영상을 리사이즈 (Resize)후 단일 신경망을 단 한 번 통과킨 결과로 각 객체의 위치를 인디케이팅하는 바운딩 박스(Bounding Box)와 객체가 무엇인지 분류 확률을 출력한다. 최종적으로 Non-max suppression을 통해 하나의 객체를 한번 인 식(detection)한다. 한편, 본 명세서에 개시되는 객체 인식 알고리즘은 전술한 YOLO에 한정되지 않고 다양한 딥러닝 알고리즘으로 구현될 수 있음을 밝혀둔다. 통신부는 상기 영상 데이터, 음성 데이터, 스틸 이미지, 및/또는 메타데이터를 영상수신/검색장치(도 1의 300)에 전송한다. 일 실시예에 따른 통신부는 영상 데이터, 음성 데이터, 스틸 이미지, 및/또는 메타데이 터를 영상수신장치(도 1의 300)에 실시간으로 전송할 수 있다. 통신부는 유무선 LAN(Local Area Network), 와이파이(Wi-Fi), 지그비(ZigBee), 블루투스(Bluetooth), 근거리 통신(Near Field Communication) 중 적어도 하나의 통신 기능을 수행할 수 있다. 한편, 본 명세서의 일 실시예에 따라 감시 카미라를 통해 획득된 영상에 대한 객체 인식, 객체 인식을 위한 신 경망 모델의 학습은 도 2에 도시된 프로세서의 제어에 따라 수행될 수 있으나, 인공 지능 영상 분석을 위 해 독립적으로 마련되는 AI 장치(모듈)에 의해 수행될 수도 있다. 설명의 편의상 도 3에서 AI 장치(모듈)에 대 해 설명하지만, 도 3의 모듈이 수행하는 기능은 도 2의 프로세서에서도 함께 수행될 수 있음은 물론이다. 도 3은 본 명세서의 일 실시예에 따른 감시 카메라 영상의 분석에 적용되는 AI 장치(모듈)을 설명하기 위한 도 면이다. 도 3을 살펴보면, AI 장치는 AI 프로세싱을 수행할 수 있는 AI 모듈을 포함하는 전자 기기 또는 AI 모듈을 포함하는 서버 등을 포함할 수 있다. 또한, AI 장치는 감시 카메라 또는 영상 관리 서버의 적어도 일부의 구성으로 포함되어 AI 프로세싱 중 적어도 일부를 함께 수행하도록 구비될 수도 있다. AI 프로세싱은 감시카메라 또는 영상 관리 서버의 제어부와 관련된 모든 동작들을 포함할 수 있다. 예를 들어, 감시 카메라 또는 영상 관리 서버는 획득된 영상 신호를 AI 프로세싱 하여 처리/판단, 제어 신호 생성 동작을 수행할 수 있다. AI 장치는 AI 프로세싱 결과를 직접 이용하는 클라이언트 디바이스이거나, AI 프로세싱 결과를 다른 기기 에 제공하는 클라우드 환경의 디바이스일 수도 있다. AI 장치는 신경망을 학습할 수 있는 컴퓨팅 장치로서, 서버, 데스크탑 PC, 노트북 PC, 태블릿 PC 등과 같은 다양한 전자 장치로 구현될 수 있다. AI 장치는 AI 프로세서, 메모리 및/또는 통신부를 포함할 수 있다. AI 프로세서는 메모리에 저장된 프로그램을 이용하여 신경망을 학습할 수 있다. 특히, AI 프로세서(2 1)는 감시 카메라의 관련 데이터를 인식하기 위한 신경망을 학습할 수 있다. 여기서, 감시 카메라의 관련 데이 터를 인식하기 위한 신경망은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며, 인간의 신경망의 뉴런(neuron)을 모의하는, 가중치를 갖는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 모드들은 뉴런이 시냅스(synapse)를 통해 신호를 주고 받는 뉴런의 시냅틱 활동을 모의하도록 각각 연결 관계에 따라 데 이터를 주고 받을 수 있다. 여기서 신경망은 신경망 모델에서 발전한 딥러닝 모델을 포함할 수 있다. 딥러닝 모 델에서 복수의 네트워크 노드들은 서로 다른 레이어에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데 이터를 주고 받을 수 있다. 신경망 모델의 예는 심층 신경망(DNN, deep neural networks), 합성곱 신경망(CNN, convolutional deep neural networks), 순환 신경망(RNN, Recurrent Boltzmann Machine), 제한 볼츠만 머신(RBM, Restricted Boltzmann Machine), 심층 신뢰 신경망(DBN, deep belief networks), 심층 Q-네트워크(Deep Q-Network)와 같은 다양한 딥 러닝 기법들을 포함하며, 컴퓨터비젼, 음성인식, 자연어처리, 음성/신호처리 등의 분야에 적용될 수 있다. 한편, 전술한 바와 같은 기능을 수행하는 프로세서는 범용 프로세서(예를 들어, CPU)일 수 있으나, 인공지능 학 습을 위한 AI 전용 프로세서(예를 들어, GPU)일 수 있다. 메모리는 AI 장치의 동작에 필요한 각종 프로그램 및 데이터를 저장할 수 있다. 메모리는 비 휘발 성 메모리, 휘발성 메모리, 플래시 메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드 라이브(SDD) 등으로 구현할 수 있다. 메모리는 AI 프로세서에 의해 액세스되며, AI 프로세서에 의 한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 또한, 메모리는 본 발명의 일 실시예에 따른 데이터 분류/인식을 위한 학습 알고리즘을 통해 생성된 신경망 모델(예를 들어, 딥 러닝 모델)을 저장할 수 있다. 한편, AI 프로세서는 데이터 분류/인식을 위한 신경망을 학습하는 데이터 학습부를 포함할 수 있다. 데 이터 학습부는 데이터 분류/인식을 판단하기 위하여 어떤 학습 데이터를 이용할지, 학습 데이터를 이용하여 데이터를 어떻게 분류하고 인식할지에 관한 기준을 학습할 수 있다. 데이터 학습부는 학습에 이용될 학습 데이터를 획득하고, 획득된 학습데이터를 딥러닝 모델에 적용함으로써, 딥러닝 모델을 학습할 수 있다. 데이터 학습부는 적어도 하나의 하드웨어 칩 형태로 제작되어 AI 장치에 탑재될 수 있다. 예를 들어, 데이터 학습부는 인공지능(AI)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 범용 프로세서(CPU) 또 는 그래픽 전용 프로세서(GPU)의 일부로 제작되어 AI 장치에 탑재될 수도 있다. 또한, 데이터 학습부 는 소프트웨어 모듈로 구현될 수 있다. 소프트웨어 모듈(또는 인스트럭션(instruction)을 포함하는 프로그램 모 듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록 매체 (non-transitory computer readable media)에 저장될 수 있다. 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 애플리케이션에 의해 제공될 수 있다. 데이터 학습부는 학습 데이터 획득부 및 모델 학습부를 포함할 수 있다. 학습 데이터 획득부는 데이터를 분류하고 인식하기 위한 신경망 모델에 필요한 학습 데이터를 획득할 수 있 다. 모델 학습부는 획득된 학습 데이터를 이용하여, 신경망 모델이 소정의 데이터를 어떻게 분류할지에 관한 판 단 기준을 가지도록 학습할 수 있다. 이 때 모델 학습부는 학습 데이터 중 적어도 일부를 판단 기준으로 이 용하는 지도 학습(supervised learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 또는 모델 학습부는 지도 없이 학습 데이터를 이용하여 스스로 학습함으로써, 판단 기준을 발견하는 비지도 학습(unsupervised learning)을 통해 신경망 모델을 학습시킬 수 있다. 또한, 모델 학습부는 학습에 따른 상황 판단의 결과가 올바른지에 대한 피드백을 이용하여 강화 학습(reinforcement learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 또한, 모델 학습부는 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient decent)을 포함하는 학습 알고리즘을 이용하여 신경망 모델을 학습시킬 수 있다. 신경망 모델이 학습되면, 모델 학습부는 학습된 신경망 모델을 메모리에 저장할 수 있다. 모델 학습부 는 학습된 신경망 모델을 AI 장치와 유선 또는 무선 네트워크로 연결된 서버의 메모리에 저장할 수도 있다. 데이터 학습부는 인식 모델의 분석 결과를 향상시키거나, 인식 모델의 생성에 필요한 리소스 또는 시간을 절약하기 위해 학습 데이터 전처리부(미도시) 및 학습 데이터 선택부(미도시)를 더 포함할 수도 있다. 학습 데이터 전처리부는 획득된 데이터가 상황 판단을 위한 학습에 이용될 수 있도록, 획득된 데이터를 전처리 할 수 있다. 예를 들어, 학습 데이터 전처리부는, 모델 학습부가 이미지 인식을 위한 학습을 위하여 획득된 학습 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다. 또한, 학습 데이터 선택부는, 학습 데이터 획득부에서 획득된 학습 데이터 또는 전처리부에서 전처리된 학 습 데이터 중 학습에 필요한 데이터를 선택할 수 있다.선택된 학습 데이터는 모델 학습부에 제공될 수 있다. 또한, 데이터 학습부는 신경망 모델의 분석 결과를 향상시키기 위하여 모델 평가부(미도시)를 더 포함할 수 도 있다.모델 평가부는, 신경망 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 분석 결과가 소정 기준을 만족하지 못하는 경우, 모델 학습부로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가 데이터는 인식 모델을 평가하기 위한 기 정의된 데이터일 수 있다. 일 예로, 모델 평가부는 평가 데이터에 대한 학습된 인식 모델의 분석 결과 중, 분석 결과가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정되 임계치를 초과 하는 경우, 소정 기준을 만족하지 못한 것으로 평가할 수 있다. 통신부는 AI 프로세서에 의한 AI 프로세싱 결과를 외부 전자 기기로 전송할 수 있다. 예를 들어, 외부 전자 기기는 감시카메라, 블루투스 장치, 자율주행 차량, 로봇, 드론, AR 기기, 모바일 기기, 가전 기기 등을 포함할 수 있다. 한편, 도 3에 도시된 AI 장치는 AI 프로세서와 메모리, 통신부 등으로 기능적으로 구분하여 설 명하였지만, 전술한 구성요소들이 하나의 모듈로 통합되어 AI 모듈로 호칭될 수도 있음을 밝혀둔다. 본 명세서는 감시용 카메라, 자율주행 차량, 사용자 단말기 및 서버 중 하나 이상이 인공 지능(Artificial Intelligence) 모듈, 로봇, 증강현실(Augmented Reality, AR) 장치, 가상 현실(Virtual reality, VT) 장치, 5G 서비스와 관련된 장치 등과 연계될 수 있다. 도 4는 본 명세서의 일 실시예에 객체 재인식을 위한 신경망 모델 업데이트 방법의 흐름도이다. 도 4에 신경망 모델 업데이트 방법은, 도 1 내지 도 3을 통해 설명한 감시 카메라 시스템, 감시 카메라 장치, 감시 카메라 장 치에 포함된 프로세서 또는 제어부를 통해 구현될 수 있다. 본 명세서의 객체 재인식을 위한 신경망 모델 업데 이트를 위한 동작들은, 감시 카메라 장치에서 단독으로 이루어지거나, 감시 카메라와 영상 관리 서버의 조합에 의해 구현될 수 있다. 도 4는 설명의 편의를 위해 감시 카메라 장치(도 1의 100a, 100b, 100c, 도 2의 100)에서 구현되며, 감시 카메라 장치의 프로세서에 의해 구현되는 경우를 가정하여 설명한다. 도 4를 참조하면, 감시 카메라는 사전에 학습된 객체 재인식 신경망 모델을 메모리에 저장할 수 있다 (S400). 여기서 상기 감시 카메라는 뷰 포인트(view point)가 서로 다른 위치에 설치된 감시 카메라에 저장된 객체 인식 모델 및/또는 객체 재인식 모델과 동일할 수 있다. 상기 뷰 포인트가 서로 다른 경우, 동일 객체에 대하여 각각 카메라에서 획득된 영상에서 인식하는 객체를 동일 객체로 인식하지 못하는 경우를 의미할 수 있다. 예를 들어, 사람의 앞면을 인식하는 카메라와, 사람의 뒷면을 인식하는 카메라를 의미할 수 있다. 또한, 두 카메라는 획득된 영상의 영상 특성 파라미터가 다르기 때문에 동일 객체를 다른 객체로 인식할 확률이 높다. 한편, 본 명세서의 일 실시예에 따라 객체 재인식 신경망 모델의 업데이트가 필요한 감시 카메라는 특정 장소 또는 사이트에 새롭게 설치될 감시 카메라일 수 있다. 이에 따라, 종래에 기 학습된 재인식 신경망은 새롭게 설 치될 장소에서 설치된 카메라에 그대로 적용될 경우, 새로운 장소에서 획득되는 영상 특성을 반영하지 못하게 되는 문제점이 있으며, 이와 같은 문제점을 극복하고 객체 재인식 결과의 신뢰성을 확보하기 위해서는 기 학습 되어 설치된 객체 재인식 신경망 모델을 카메라가 설치될 장소적 특성에 맞게 업데이트할 필요가 있다. 이를 위 해서는 새로운 사이트에서 획득되는 영상을 학습 데이터로 구성할 필요가 있다. 이에 따라, 프로세서는 영상 획득부를 통해 영상을 획득하고(S410), 객체를 검출할 수 있다(S420). 일 실 시예에 따라 프로세서는 상기 영상에서 사람, 차량 등의 객체를 검출할 수 있다. 프로세서는 복수의 프레임에 대해 객체를 검출하며, 객체의 이동 경로, 객체의 형태 등을 분석할 수 있다. 프로세서는 미리 정해진 기준에 따라 신경망 모델을 업데이트하기 위한 학습 데이터를 선택할 수 있다 (S430). 일 실시예에 따라 프로세서는 검출된 객체의 검출 박스의 크기가 크고, 객체의 형태가 명확한 객 체를 신경망 모델 업데이트에 이용할 학습 데이터로 선택할 수 있다. 본 명세서의 일 실시예에 따른 재인식 신 경망 모델을 업데이트 시키기 위해서는 사전에 학습된 신경망 모델 학습에 이용된 학습 데이터가 필요없이 감시 카메라가 새롭게 설치된 사이트에서 수집된 데이터로만 적응적 학습을 통해 신경망 모델을 업데이트할 수 있다. 프로세서는 상기 선택된 학습 데이터를 기 학습된 신경망 모델에 피드 포워드(feedforward) 입력함으로써 (S440), 상기 신규 사이트에서 수집한 영상의 영상 특성 파라미터를 획득할 수 있다. 본 명세서는 손실함수를 계산할 필요 없이 기 구성된 신경망 모델에 대하여 피드 포워드 입력만으로 모델 수정이 가능하기 때문에 연산 성능이 상대적으로 낮을 수 있는 엣지 디바이스(edge device) 환경에서도 효율적으로 적용 가능하다. 프로세서는 상기 획득된 영상 특성 파라미터에 기초하여 신경망 모델을 업데이트할 수 있다. 이하, 도 5를 참조하여, 신규 사이트에서 새롭게 획득된 영상 데이터의 일부만으로 기 학습된 신경망 모델을 효 율적으로 업데이트 하는 과정을 보다 구체적으로 설명한다. 도 5는 본 명세서의 일 실시예에 따라 신경망 모델 업데이트 방법을 설명하기 위한 도면이다. 도 5를 참조하면, 프로세서는 기 학습된 신경망 모델의 내부에 상기 영상 특성 파라미터를 정규화하기 위 한 배치 정규화 레이어(batch normalization layer, 53)구성하고, 신경망 모델에 포함된 복수의 레이어 (51,52,54)에 대하여 상기 학습 데이터를 피드 포워드 함으로써, 영상 특성 파라미터를 업데이트할 수 있다. 여기서 영상 특성 파라미터는 엣지 변화량, 대칭도(skewness), 노이즈(noise), 조명(illumination) 성분, 반사 (reflectance) 성분 중 적어도 하나를 포함할 수 있다. 신규 사이트에 설치된 감시 카메라에서 획득된 영상의 영상 특성 파라미터를 반영하는 방법은 일반적인 배치 정 규화(batch normalization)과정과 유사하다. 배치 정규화는 하나 이상의 배치 정규화 계층이 신경망에 추가되어 훈련 데이터에 기초한 입력의 통계적 특성에 기초하여 계층에 대한 입력을 정규화하는 기술을 의미한다. 배치 정규화는 입력데이터가 다양한 분포를 갖더라 도 동일한 분포를 갖도록 배치 단위로 정규화하는 과정을 의미할 수 있다. 신경망의 일부는 입력 계층, 히든 계층. 배치 정규화 계층, 출력 계층을 포함할 수 있다. 학습 중에 학습 데이터는 일반적으로 효율성 향상을 위해 다수의 \"배치\"로 나뉜다. (예를 들어, 전체 학습 데이 터 세트가 컴퓨터의 메모리에 맞지 않을 수 있으며, 디스크 또는 기타 대용량 저장 장치에서 읽기를 방지하여 성능을 향상시킬 수 있기 때문이다). 각 배치로부터의 샘플은 신경망의 입력 계층에 제공되고 주어진 입력에 대 해 각 계층에 의해 계산된 활성 값은 다음 계층에 공급된다. 예를 들어, 입력 계층에 의해 계산된 활성 값 은 그 활성 값을 배치 정규화 층에 공급하는 히든 계층 에 입력으로서 공급된다. 배치 정규화 계층(5 3)은 현재 학습 데이터의 배치에 대해 이전 계층(예를 들어, 도 5에 도시된 바와 같은 계층) 으로부터 수신 된 입력을 정규화 한다. 예를 들어, 프로세서는 학습 데이터 배치에 대한 입력의 평균과 분산을 계산하고 해당 입력이 동일한 평균과 분산을 갖도록 정규화 함으로써 입력의 정규화 된 버전은 네트워크의 다음 계층(예 를 들어, 도 5에 도시된 바와 같은 계층)에 공급된다. 학습이 완료되면, 전체 학습 데이터 세트에서 계산된 평균과 분산이 배치 정규화 계층에 저장되므로, 추론 동안, 배치 정규화 층에 대한 입력은 학습 데이터 세트의 평균 및 분산에 기초하여 조정된다. 따라서 사전에 학습된 신경망 모델의 각 배치 정규화 계층은 (신경망의 이전 계층을 통해 처리되는 바와 같이) 학습 데이터에 대한 응답으로 이전 계층 출력의 통계적 분포를 반영하는 통계적 특성 정보를 저장한다. 한편, 본 명세서의 일 실시예에 따른 객체 재인식 신경망 모델 방법은, 실제로는 모든 학습데이터의 평균과 분 산을 미리 구하는 것이 아니라 학습을 진행하면서 이동 평균, 지수 평균 등의 방법을 이용하여 평균과 분산 파 라미터를 업데이트될 수 있다. 입력 데이터 자체의 평균과 분산만 고려하는 것이 아닌, 신경망의 레이어 들 사 이 사이에서도 구하며, 학습 진행중에 해당 값들이 업데이트 된다. 학습이 완료되고 추론 단계에서는 이동 평균, 이동 분산 파라미터를 더 이상 업데이트하지 않고 고정하여 사용하게 된다. 이에 따라, 본 명세서는 배치 정규화 레이어의 평균, 분산 파라미터를 업데이트 하는 방법과 유사하게 평균, 분 산을 포함하여 영상의 특성 정규화 할 수 있는 나타내는 값들을 반영할 수 있는 레이어(layer)를 추가 구성할 수 있다. 전술한 설명에서는 재인식 신경망 모델은 배치 정규화 레이어가 추가되는 것으로 설명하였으나, 본 명 세서는 이에 한정되지 않고, 추가되는 레이어가 배치 정규화 기능을 수행할 수 있는 어떠한 레이어도 포함될 수 있음은 물론이다. 여기서 언급하는 영상의 특성은 엣지 변화량, 대칭도(skewness), 노이즈, 조명 성분(illumination), 반사 (reflectance) 성분 등이 해당 될 수 있다. 해당 특성들을 정규화 할 수 있는 layer들을 구성하고, 학습 시에 이동 평균 혹은 지수 평균 등의 방법으로 각 layer 별 영상 특성 파라미터들을 학습한다. 학습이 완료되면 추론 시에는 모든 파라미터를 고정(freeze)하고 사용한다. 일 실시예예 따라 본 명세서는, 새로운 사이트 카메라에 설치 후, 해당 카메라 적응을 위한 파라미터 업데이트 하는 방법은 도 4의 흐름도로 신경망을 업데이트할 수 있다. 일 실시예에 다라 먼저, 프로세서는 영상 특 성 파라미터를 학습 가능하도록 변경할 수 있다. 단, 영상 특성 파라미터 이외의 파라미터들은 변경되지 않도록 한다. 그 이후 프로세서는 학습 데이터를 재인식 신경망에 입력시킨다. 신경망 내부에서 데이터를 피드 포워드(feedforward) 하면서 영상 특성 파라미터를 획득하고 업데이트한다. 이에 따라, 본 명세서는, 종래에 신경망 모델 학습 과정에서 이용된 학습 데이터가 필요 없이 신규 사이트에서 수집한 데이터만으로도 신경망 모델의 업데이트가 가능하다. 또한, 본 명세서는, 학습 데이터에 대해 일일이 레이블링(labeling)할 필요가 없으므로 신경망 모델 업데이트에 필요한 리소스(인건비 및 작업 투입 시간)를 절감시킬 수 있다. 이로 인해, 수백장의 적은 데이터만으로도 학습이 가능하며, 손실함수를 계산하지 않고, 반복적 업데이트가 필 요 없기 때문에 엣지 디바이스 환경(감시 카메라 장치)에서도 학습이 가능할 수 있다. 한편, 본 명세서에 개시되는 재인식 신경망 모델 업데이트 과정은 엣지 디바이스 환경과 클라우드 환경의 조합 을 통해서도 효율적으로 이루어질 수 있다. 도 6은 본 명세서의 일 실시예에 따라 객체 재인식을 위한 신경망 모델 업데이트 방법의 다른 예를 설명하기 위 한 흐름도이다. 도 6을 참조하면, 최초 재인식 신경망 모델의 학습은 제1 감시 카메라(100a)에서 획득된 제1 영상에 기초하여 서버가 재인식 신경망 모델을 학습할 수 있다. 제1 감시 카메라(100a)는 일정 시간 이상 특정 장소에 설치 된 감시 카메라일 수 있다. 한편, 제2 감시 카메라가 상기 특정 장소에서 상기 제1 감시 카메라의 뷰 포인트와 다른 뷰 포인트를 갖는 지점에 새롭게 설치될 수 있다. 상기 서버에서 학습된 재인식 신경망 모델은 제1 감시 카메라(100a)와 제2 감시 카메라(100b)에 모두 제공 된다. 이에 따라 신규 설치될 제2 감시 카메라(100b)는 처음에는 기 학습된 재인식 신경망 모델을 이용하여 객 체 재인식을 수행할 수 있다. 그러나, 제1 감시 카메라(100a)와 제2 감시 카메라(100b)는 각각 획득되는 영상의 영상 특성 파라미터가 다를 수 있는 바, 제2 감시 카메라(100b)는 제2 영상에 기초하여 기 학습된 신경망 모델 을 추가적으로 업데이트할 필요성이 있다. 제2 감시 카메라(100b)는 제2 영상을 획득하고(S610), 제2 영상에서 검출된 객체 중 특정 데이터를 학습 데이터 로 선정할 수 있다(S620). 선정되는 학습 데이터는 전술한 바와 같이, 미리 정해진 기준에 따라 선택될 수 있다. 제2 감시 카메라(100b)는 기 학습된 신경망 모델에 학습 데이터를 피드 포워드 함으로써, 제2 영상의 영상 특성 파라미터를 획득하고, 신경망 모델을 효율적으로 업데이트할 수 있다. 한편, 일 실시예에 따라, 제2 감시 카메라(100b)는 신규로 설치되기는 하지만, 기 학습된 재인식 신경망 모델을 그대로 적용하더라도 객체 재인식의 신뢰성에 문제가 없는 경우, 신경망 모델을 업데이트하지 않고 그대로 사용 할 수 있다. 이에 따라 제2 감세 카미라(100b)는 신규 사이트에 설치된 후, 객체 재인식 결과를 확인한 후, 제1 감시 카메라(100a)가 인식한 객체에 대하여 동일 객체를 올바르게 인식하지 못한 것으로 판단한 경우에만, 제2 영상에 기초하여 신경망 모델을 업데이트할 수도 있다. 한편, 도 6에 도시되지는 않았으나, 서버는 개별 감시 카메라에 대하여 신경망 모델을 업데이트한 후, 엣 지 디바이스 환경에 맞게 최적화를 수행하여 각 감시 카메라로 제공할 수도 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있으며, 또한 캐리어 웨이브(예를 들어, 인터넷을 통한 전송)의 형태로 구현되는 것도 포함한다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항 의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함 된다.부호의 설명"}
{"patent_id": "10-2023-0057489", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 관한 이해를 돕기 위해 상세한 설명의 일부로 포함되는, 첨부 도면은 본 명세서에 대한 실시예를 제공하고, 상세한 설명과 함께 본 명세서의 기술적 특징을도 설명한다. 도 1은 본 명세서의 일 실시예에 따른 감시 카메라의 영상 처리 방법을 구현하기 위한 감시 카메라 시스템을 설 명하기 위한 도면이다. 도 2는 본 명세서의 일 실시예에 따른 감시 카메라의 개략적인 블록도이다.도 3은 본 명세서의 일 실시예에 따른 감시 카메라 영상의 분석에 적용되는 AI 장치(모듈)을 설명하기 위한 도 면이다. 도 4는 본 명세서의 일 실시예에 객체 재인식을 위한 신경망 모델 업데이트 방법의 흐름도이다. 도 5는 본 명세서의 일 실시예에 따라 신경망 모델 업데이트 방법을 설명하기 위한 도면이다. 도 6은 본 명세서의 일 실시예예 따라 객체 재인식을 위한 신경망 모델 업데이트 방법의 다른 예를 설명하기 위 한 흐름도이다. 본 발명에 관한 이해를 돕기 위해 상세한 설명의 일부로 포함되는, 첨부 도면은 본 발명에 대한 실시예를 제공 하고, 상세한 설명과 함께 본 발명의 기술적 특징을 설명한다."}
