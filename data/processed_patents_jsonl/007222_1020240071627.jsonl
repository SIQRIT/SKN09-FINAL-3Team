{"patent_id": "10-2024-0071627", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0053690", "출원번호": "10-2024-0071627", "발명의 명칭": "사전 학습 모델을 이용한 영상 데이터 분석 방법 및 이를 위한 장치", "출원인": "주식회사 서르", "발명자": "이해진"}}
{"patent_id": "10-2024-0071627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 기반 사전 학습모델을 이용한 영상데이터 분석 장치로서,외부 장치와 통신을 수행하는 통신부;인공지능 기반 사전 학습모델을 이용하여 영상데이터를 분석하기 위한 적어도 하나의 프로세스를 저장하는 저장부; 및상기 적어도 하나의 프로세스를 기반으로 상기 인공지능 기반 사전 학습모델을 이용하여 영상데이터를 분석하기위한 동작을 수행하는 프로세서을 포함하며,상기 프로세서는,제1 촬영 장치를 이용하여 검사 대상자의 장기를 촬영한 제1 영상데이터를 획득하고, 상기 획득된 제1 영상데이터를 상기 사전 학습모델에 입력하여 전체 영역을 기 설정된 복수의 영역으로 구분하고, 제2 촬영 장치를 이용하여 획득된 제2 영상데이터에서 상기 기 설정된 복수의 영역의 각 대응 영역으로부터추출된 영상 특성을 적용하여 변환된 제1 영상데이터를 출력한 후, 상기 변환된 제1 영상데이터를 분석하여 분석정보를 생성하며,상기 사전 학습모델은,기 설정된 기간 동안 적어도 하나의 제1 영상데이터 및 적어도 하나의 제2 영상데이터를 수집하여 학습데이터셋을 구축하고, 상기 구축된 학습데이터 셋을 이용하여 원본 모델을 학습함으로써, 사전 학습모델을 생성하는것을 특징으로 하는, 인공지능 기반 사전 학습모델을 이용한 영상데이터 분석 장치."}
{"patent_id": "10-2024-0071627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 촬영 장치 및 상기 제2 촬영 장치는, 서로 상이한 이종 디바이스이며, 상기 제1 촬영 장치는 상기 제2 촬영 장치보다 신규한 촬영장치이며, 상기 제1 촬영 장치에 의해 촬영되어 데이터베이스에 저장된 영상데이터의 개수는 상기 제2 촬영 장치에 의해촬영되어 데이터베이스에 저장된 영상데이터의 개수보다 적은, 인공지능 기반 사전 학습모델을 이용한 영상데이터 분석 장치."}
{"patent_id": "10-2024-0071627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제1 영상데이터는, 상기 제1 촬영 장치에 의해 촬영된 제1 도메인의 영상데이터이고,상기 제2 영상데이터는, 상기 제2 촬영 장치에 의해 촬영된 제2 도메인의 영상데이터인, 인공지능 기반 사전 학습모델을 이용한 영상데이터 분석 장치."}
{"patent_id": "10-2024-0071627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프로세서는,상기 제2 영상데이터를 이용한 분석 방식이 그대로 상기 획득된 제1 영상데이터에 적용되어 상기 사전 학습모델을 이용하도록, 상기 제2 영상데이터의 영상 특성에 기반하여 상기 획득된 제1 영상데이터를 상기 변환된 제1영상데이터로 출력하도록 구성되는, 인공지능 기반 사전 학습모델을 이용한 영상데이터 분석 장치.공개특허 10-2025-0053690-3-청구항 5 제4항에 있어서,상기 프로세서는,상기 제1 영상데이터를 상기 사전 학습모델에 입력하여 상기 전체 영역을 기 설정된 기준에 따라 복수의 영역으로 구분하고,상기 프로세서는,상기 제1 영상데이터의 각 영역에 대한 형상 특성(shape feature)을 추출하고 상기 제2 영상데이터에서 상기 각대응 영역에 대한 색상 특성(color feature)을 추출한 후 상기 각 영역에 대한 형상 특성 및 상기 각 대응 영역에 대한 색상 특성을 결합하여 상기 변환된 제1 영상데이터를 출력하거나,상기 제1 영상데이터의 각 영역에 대한 제1 형상 특성(shape feature) 및 제1 색상 특성(color feature)을 추출하고, 상기 제2 영상데이터의 상기 각 대응 영역으로부터 제2 형상 특성 및 제2 색상 특성을 추출한 후, 상기제1 형상 특성을 기반으로 하되, 상기 제1 색상 특성을 상기 제2 색상 특성으로 교체하여 상기 변환된 제1 영상데이터를 출력하는 것을 특징으로 하는,인공지능 기반 사전 학습모델을 이용한 영상데이터 분석 장치."}
{"patent_id": "10-2024-0071627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 복수의 영역은 제1 영역 내지 제3 영역을 포함하며,상기 제1 영역은, 상기 전체 영역에서 버블을 포함하는 영역을 나타내고,상기 제2 영역은, 상기 전체 영역에서 상기 제1 영역을 제외한 영역에서 픽셀값의 밝기값이 기 설정된 임계치이하인 영역을 나타내고,상기 제3 영역은, 상기 전체 영역에서 상기 제1 영역 및 상기 제2 영역을 제외한 영역에서 픽셀값의 밝기값이상기 기 설정된 임계치를 초과하는 영역을 나타내는 것을 특징으로 하는, 인공지능 기반 사전 학습모델을 이용한 영상데이터 분석 장치."}
{"patent_id": "10-2024-0071627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 프로세서는,상기 분석정보를 기 설정된 적어도 하나의 사용자 단말로 송신하고,상기 분석정보는,상기 변환된 제1 영상데이터를 분석하여 발견된 병변에 대한 진단, 위치, 진행정도 및 진행범위 중 적어도 하나를 포함하는 것을 특징으로 하는,인공지능 기반 사전 학습모델을 이용한 영상데이터 분석 장치."}
{"patent_id": "10-2024-0071627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "프로세서에 의해 수행되는, 인공지능 기반 사전 학습모델을 이용한 영상데이터 분석 방법에 있어서,제1 촬영 장치를 이용하여 검사 대상자의 장기를 촬영한 제1 영상데이터를 획득하는 단계;상기 획득된 제1 영상데이터를 상기 사전 학습모델에 입력하여 전체 영역을 기 설정된 복수의 영역으로 구분하는 단계;제2 촬영 장치를 이용하여 획득된 제2 영상데이터에서 상기 기 설정된 복수의 영역의 각 대응 영역으로부터 추출된 영상 특성을 적용하여 변환된 제1 영상데이터를 출력하는 단계; 및공개특허 10-2025-0053690-4-상기 변환된 제1 영상데이터를 분석하여 분석정보를 생성하는 단계를 포함하며,상기 사전 학습모델은,기 설정된 기간 동안 적어도 하나의 제1 영상데이터 및 적어도 하나의 제2 영상데이터를 수집하여 학습데이터셋을 구축하고, 상기 구축된 학습데이터 셋을 이용하여 원본 모델을 학습함으로써, 사전 학습모델을 생성하는것을 특징으로 하는, 인공지능 기반 사전 학습모델을 이용한 영상데이터 분석 방법."}
{"patent_id": "10-2024-0071627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 제1 촬영 장치 및 상기 제2 촬영 장치는, 서로 상이한 이종 디바이스이며, 상기 제1 촬영 장치는 상기 제2 촬영 장치보다 신규한 촬영장치이며, 상기 제1 촬영 장치에 의해 촬영되어 데이터베이스에 저장된 영상데이터의 개수는 상기 제2 촬영 장치에 의해촬영되어 데이터베이스에 저장된 영상데이터의 개수보다 적은, 인공지능 기반 사전 학습모델을 이용한 영상데이터 분석 방법."}
{"patent_id": "10-2024-0071627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 제1 영상데이터는, 상기 제1 촬영 장치에 의해 촬영된 제1 도메인의 영상데이터이고,상기 제2 영상데이터는, 상기 제2 촬영 장치에 의해 촬영된 제2 도메인의 영상데이터인, 인공지능 기반 사전 학습모델을 이용한 영상데이터 분석 방법."}
{"patent_id": "10-2024-0071627", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 인공지능 기반 사전 학습모델을 이용한 영상데이터 분석 장치 및 방법에 관한 것으로, 외부 장치와 통 신을 수행하는 통신부; 인공지능 기반 사전 학습모델을 이용하여 영상데이터를 분석하기 위한 적어도 하나의 프 로세스를 저장하는 저장부; 및 상기 적어도 하나의 프로세스를 기반으로 상기 인공지능 기반 사전 학습모델을 이 용하여 영상데이터를 분석하기 위한 동작을 수행하는 프로세서을 포함하며, 상기 프로세서는, 검사 대상자의 장 기를 촬영한 제1 영상데이터를 획득하고, 상기 획득된 영상데이터를 상기 사전 학습모델에 입력하여 기 설정된 복수의 영역으로 구분하고, 제2 영상데이터에서 상기 기 설정된 복수의 영역의 각 대응 영역으로부터 추출된 영 상 특성을 적용하여 변환된 제1 영상데이터를 출력한 후, 상기 변환된 제1 영상데이터를 분석하여 분석정보를 생 성할 수 있다."}
{"patent_id": "10-2024-0071627", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 영상데이터 분석 장치 및 방법에 대한 것으로, 보다 상세하게는, 인공지능 기반 사전 학습모델을 이 용한 영상데이터 분석 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2024-0071627", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "소장의 병변은 소장에서 발생하는 비정상적인 성장 또는 조직 변화로서, 이러한 병변은 출혈, 폐쇄 및 암을 포 함하여 심각한 건강상의 결과를 초래할 수 있다. 일반적으로, 이러한 소장 병변은 내시경 검사를 통해 검출한다. 이 내시경 검사는 신체의 내강을 관찰하는 것으 로, 소장은 삽입 부위에서 멀고 굴곡과 움직임이 많아 내시경을 이용한 관찰이 어려웠으나, 소형 카메라가 장착 된 캡슐내시경이 개발되어 보다 수월하게 소장 검사가 가능해졌다. 이 캡슐내시경은 작은 크기의 캡슐 내부에 카메라, 전송장치, 플래시가 내장된 것으로, 검사 대상자가 이를 삼 키면 소화관을 지나면서 카메라가 내부를 촬영하여 컴퓨터로 전송해줌에 따라 검사 대상자가 일상적인 생활을 하면서 검사 진행이 가능하여 그 수요가 증가하고 있는 추세이다. 때문에 다양한 기업에서 캡슐내시경에 대한 개발을 활발하게 진행하고 있으며, 그 결과로 다양한 캡슐내시경이 출시되고 있다. 그 캡슐내시경을 통해 획득한 영상데이터를 기반으로 병변을 진단하기 위해서는 의료진이 직접 영상을 확인해야 하는 불편함이 있을 뿐만 아니라, 정확한 진단을 위해서는 다양한 종류의 캡슐내시경의 영상 특성을 파악해야 하는 문제점이 있다. 따라서, 인공지능을 기반의 사전 학습모델을 이용하여 영상데이터의 데이터 도메인을 용이하게 변환 처리하여 분석함으로써 병변을 정확하고 신속하게 진단할 수 있도록 하는 기술이 개발될 필요가 있다. 선행기술문헌특허문헌 (특허문헌 0001) 한국공개특허공보 제10-2022-0137215호 (등록일: 2022년 10월 12일)"}
{"patent_id": "10-2024-0071627", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 인공지능을 기반의 사전 학습모델을 이용하여 영상데이터의 데이터 도메인을 용이하게 변환 처리하여 분석함으로써 병변을 정확하고 신속하게 진단할 수 있도록 하는 인공지능 기반 사전 학습모델을 이용한 영상데 이터 분석 장치 및 방법을 제공함에 있다. 본 개시가 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0071627", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 본 개시의 일 측면에 따른 인공지능 기반 사전 학습모델을 이용한 영상데 이터 분석 장치는, 외부 장치와 통신을 수행하는 통신부; 인공지능 기반 사전 학습모델을 이용하여 영상데이터 를 분석하기 위한 적어도 하나의 프로세스를 저장하는 저장부; 및 상기 적어도 하나의 프로세스를 기반으로 상 기 인공지능 기반 사전 학습모델을 이용하여 영상데이터를 분석하기 위한 동작을 수행하는 프로세서을 포함하며, 상기 프로세서는, 검사 대상자의 장기를 촬영한 제1 영상데이터를 획득하고, 상기 획득된 영상데이터 를 상기 사전 학습모델에 입력하여 전체 영역을 기 설정된 복수의 영역으로 구분하고, 제2 영상데이터에서 상기 기 설정된 복수의 영역의 각 대응 영역으로부터 추출된 영상 특성을 적용하여 변환된 제1 영상데이터를 출력한 후, 상기 변환된 제1 영상데이터를 분석하여 분석정보를 생성할 수 있다. 한편, 본 개시의 일 측면에 따른 인공지능 기반 사전 학습모델을 이용한 영상데이터 분석 방법은, 검사 대상자 의 장기를 촬영한 제1 영상데이터를 획득하는 단계; 상기 획득된 영상데이터를 상기 사전 학습모델에 입력하여 전체 영역을 기 설정된 복수의 영역으로 구분하는 단계; 제2 영상데이터에서 상기 기 설정된 복수의 영역의 각 대응 영역으로부터 추출된 영상 특성을 적용하여 변환된 제1 영상데이터를 출력하는 단계; 및 상기 변환된 제1 영상데이터를 분석하여 분석정보를 생성하는 단계를 포함할 수 있다. 이 외에도, 본 개시를 구현하기 위한 방법을 실행하기 위한 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프 로그램이 더 제공될 수 있다. 이 외에도, 본 개시를 구현하기 위한 방법을 실행하기 위한 컴퓨터 프로그램을 기록하는 컴퓨터 판독 가능한 기 록 매체가 더 제공될 수 있다."}
{"patent_id": "10-2024-0071627", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 전술한 과제 해결 수단에 의하면, 인공지능을 기반의 사전 학습모델을 이용하여 영상데이터의 데이터 도메인을 용이하게 변환 처리하여 분석함으로써 병변을 정확하고 신속하게 진단할 수 있도록 한다. 본 개시의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0071627", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 개시는 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 개시가 완전하도록 하고, 본 개시가 속하는 기술 분야의 통상의 기술자에게 본 개시의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 개시는 청구항 의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 개시를 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단 지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 개시의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 개시가 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 본 개시 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 개시가 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2024-0071627", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 본 개시가 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한 다. 명세서에서 사용되는 \"부\" 또는 “모듈”이라는 용어는 소프트웨어, FPGA 또는 ASIC과 같은 하드웨어 구성 요소를 의미하며, \"부\" 또는 “모듈”은 어떤 역할들을 수행한다. 그렇지만 \"부\" 또는 “모듈”은 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. \"부\" 또는 “모듈”은 어드레싱할 수 있는 저장 매체에 있도록 구성 될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 \"부\" 또는 “모듈”은 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들 과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드 라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들 을 포함한다. 구성요소들과 \"부\" 또는 “모듈”들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 \"부\" 또 는 “모듈”들로 결합되거나 추가적인 구성요소들과 \"부\" 또는 “모듈”들로 더 분리될 수 있다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐 아니라, 간접적으로 연결되어 있는 경우를 포함하고, 간접적인 연결은 무선 통신망을 통해 연결되는 것을 포함 한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\" 위치하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존재하는 경우도 포함한다. 제1, 제2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전 술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 설명에서 사용되는 용어에 대하여 정의하면 하기와 같다. 본 명세서에서 인공지능 기반 사전 학습모델은 딥러닝 기반의 예측 모델이며, 이들 각각을 통해 수술 전 또는 수술 중에 해당 환자의 수술 부위에 대한 재파열 확률을 예측하여 분석정보를 생성할 수 있다. 이때, 딥러닝 방 식은 한정하지 않으며, 상황(필요)에 따라 적어도 하나의 방식이 적용될 수 있다. 이때, 인공지능 알고리즘의 일 예로서 RNN(Recurrent Neural Network) 또는 트랜스포머(transformer) 등이 적용될 수 있으나, 이것으로 한 정하는 것은 아니며, 다른 인공지능 알고리즘이 적용될 수도 있다. 본 명세서에서 '분석 장치'로 한정하여 설명하였으나, 이는 인공지능 기반 사전 학습모델을 제공하기 위한 장치로서, 연산처리를 수행할 수 있는 다양한 장치들을 모두 포함할 수 있다. 즉, 제공 장치는 서버, 컴퓨 터, 서버 및/또는 휴대용 단말기를 더 포함하거나, 또는 그 중 어느 하나의 형태가 될 수 있으며, 이를 한정하 지 않는다. 여기에서, 상기 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱 (laptop), 태블릿 PC, 슬레이트 PC 등을 포함할 수 있다. 상기 서버는 외부 장치와 통신을 수행하여 정보를 처리하는 서버로써, 애플리케이션 서버, 컴퓨팅 서버, 데이터 베이스 서버, 파일 서버, 게임 서버, 메일 서버, 프록시 서버 및 웹 서버 등을 포함할 수 있다. 상기 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), WiBro(Wireless Broadband Internet) 단말, 스마트 폰(Smart Phone) 등과 같은 모든 종류의 핸드헬드 (Handheld) 기반의 무선 통신 장치와 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD) 등과 같은 웨어러블 장치를 포함할 수 있다. 이하 첨부된 도면들을 참고하여 본 개시의 작용 원리 및 실시예들에 대해 설명한다. 도 1은 서로 다른 장치를 통해 각각 촬영된 영상데이터의 일 예시를 나타내는 도면으로서, (a)는 제1 촬영장치 를 통해 촬영된 제1 영상데이터로서 제1 도메인의 영상데이터이고, (b)는 제2 촬영장치를 통해 촬영된 제2 영상 데이터로서 제2 도메인의 영상데이터이다. 여기서, 제1 촬영장치는 신규 장치이고, 제2 촬영장치는 기존 장치이 다. 즉, 제1 촬영 장치 및 제2 촬영 장치는 서로 상이한 이종 디바이스이다. 제1 촬영장치가 신규 장치이기 때문에, 이를 통해 촬영된 영상데이터가 데이터베이스 상에 없거나 소량 존재할 수 있다. 이 경우, 사용자가 제1 영상데이터의 영상 특성을 고려하여 제1 영상데이터을 직접 육안으로 확인해가 며 병변을 진단하지 않고는 자동으로 병변을 진단하기는 어렵다. 따라서, 제2 촬영장치에 의해 촬영되어 데이터베이스 상에 저장된 다수의 제2 영상데이터의 영상 특성을 제1 영 상데이터에 적용함으로써 변환된 제1 영상데이터를 생성할 수 있다. 다시 말해, 변환된 제1 영상데이터는 제1 영상데이터에 제2 영상데이터의 영상 특성이 적용되어 생성된 영상데이터로서, 제3 영상데이터라 칭할 수도 있 다. 즉, 본 개시는 신규 장치에 의해 촬영된 소량의 제1 영상데이터를 제2 영상데이터의 형태로 변환하여 기존 제2 영상데이터를 이용한 분석 방식을 그대로 사용하여 자동으로 병변 진단을 수행하도록 할 수 있다. 따라서, 본 개시는 제1 영상데이터가 색상 감각을 익힐 수 있는 정도로 수집된 상황에서도 제2 영상데이터의 영 상 특성을 적용하여 이를 변환함으로써 사전 학습모델을 통해 그 병변 진단이 가능하도록 한다. 도 2는 본 개시의 일 실시예에 따른 인공지능 기반의 영상데이터 분석 시스템의 네트워크 구조를 나타내는 도면 이다.도 2를 참조하면, 인공지능 기반의 영상데이터 분석 시스템(이하, '분석 시스템'이라 칭함)은 분석 장치 , 촬영 장치 및 적어도 하나의 사용자 단말 중 적어도 하나를 포함하여 구성될 수 있다. 분석 장치는 촬영 장치와 네트워크로 연결되며, 그 촬영 장치로부터 촬영된 영상데이터를 수신 한 후, 그 영상데이터를 기반으로 생성된 분석정보를 적어도 하나의 사용자 단말로 송신할 수 있다. 이를 위해, 분석 장치는 인공지능 기반 사전 학습모델을 생성하여 구비할 수 있으며, 촬영 장치로부 터 수신된 적어도 하나의 영상데이터를 그 사전 학습모델에 입력데이터로 입력함으로써 촬영 장치와는 상 이한 촬영 장치(미도시)의 영상 특성을 적용하여 변환된 적어도 하나의 영상데이터를 출력데이터로서 출력한다. 한편, 촬영 장치는 카메라를 구비하여 검사 대상자의 신체 내강을 이동하며 촬영을 수행하는 장치로서, 이 를 통해 촬영된 적어도 하나의 영상데이터를 분석 장치 및/또는 적어도 하나의 사용자 단말로 송신한 다. 즉, 이 촬영 장치는 내시경 장치일 수 있으며, 예를 들어 캡슐내시경일 수 있다. 적어도 하나의 사용자 단말은 검사 대상자와 관련한 사용자(의료진, 의료기관, 검사 대상자, 보호자 등)가 소지하는 단말로서, 분석 장치 및/또는 촬영 장치에 사전 등록됨으로써 분석정보를 제공받거나 적어 도 하나의 영상데이터를 제공받을 수 있다. 즉, 적어도 하나의 사용자 단말은 촬영 장치로부터 촬영 된 적어도 하나의 영상데이터를 기반으로 생성된 분석정보를 제공받거나, 촬영 장치로부터 촬영된 적어도 하나의 영상데이터를 그대로 제공받을 수도 있다. 여기서, 분석정보는 적어도 하나의 영상데이터를 분석하여 발견된 병변에 대한 진단, 위치, 진행정도 및 진행범 위 중 적어도 하나를 포함할 수 있으며, 적어도 하나의 영상데이터 중 그 병변이 발견된 관련 영상(이하, '병변 영상'이라 칭함)을 더 포함할 수도 있다. 이로써, 사용자가 시계열 순으로 제공되는 적어도 하나의 영상데이터를 직접 육안으로 확인하여 병변을 발견 및 진단하거나, 적어도 하나의 영상데이터 중 병변영상을 확인하여 병변을 최종 진단할 수 있다. 한편, 적어도 하나의 사용자 단말은 사용자가 원하는 다수의 응용 프로그램(즉, 애플리케이션)을 설치하여 실행할 수 있는 컴퓨터, UMPC(Ultra Mobile PC), 워크스테이션, 넷북(net-book), PDA(Personal Digital Assistants), 포터블(portable) 컴퓨터, 웹 테블릿(web tablet), 무선 전화기(wireless phone), 모바일 폰 (mobile phone), 스마트 폰(smart phone), 패드(Pad), 스마트 워치(Smart watch), 웨어러블(wearable) 단말, e-북(e-book), PMP(portable multimedia player), 휴대용 게임기, 네비게이션(navigation) 장치, 블랙 박스 (black box) 또는 디지털 카메라(digital camera), 기타 이동통신 단말 등일 수 있다. 즉, 적어도 하나의 사용 자 단말은 다양한 형태로 구비될 수 있으며, 이를 한정하지 않는다. 상술한 바와 같이, 본 개시에 따른 분석 시스템은 분석 장치, 촬영 장치 및 적어도 하나의 사용자 단 말 간 데이터 송수신을 통해 구현될 수 있다. 도 3은 본 개시의 일 실시예에 따른 인공지능 기반의 영상데이터 분석 시스템의 동작을 나타내는 흐름도이다. 도 3을 참조하면, 분석 장치는 기 설정된 기간 동안 적어도 하나의 제1 영상데이터 및 적어도 하나의 제2 영상데이터(여기서, 적어도 하나의 제2 영상데이터는 데이터베이스에 기 저장된 적어도 하나의 제2 영상데이터 를 포함함)를 수집하여 생성된 학습데이터 셋을 이용하여 원본 모델을 학습함으로써, 사전 학습모델을 생성한다 (S101). 이로써, 분석 장치는 사전 학습모델을 이용하여 영상데이터 분석 서비스를 개시할 수 있다. 그 다음으로, 촬영 장치가 동작하여 검사 대상자의 신체 내강을 이동하며 촬영을 수행하고(S103), 이를 통 해 수집된 영상데이터(제1 영상데이터)를 분석 장치로 송신한다(S105). 그 다음으로, 분석 장치는 S105 단계에 의해 수신된 영상데이터를 S101 단계에 의해 구축된 사전 학습모델 에 입력하여 이를 변환하고(S107), 그 변환된 영상데이터에 대한 분석을 수행한다(S109). 그 다음으로, 분석 장치는 S109 단계에 의한 분석 결과에 따라 병변에 대한 적어도 하나의 정보를 포함하 는 분석정보를 생성한 후(S111), 그 생성된 분석정보를 기 설정된 사용자 단말로 송신한다(S113). 이로써, 사용자 단말은 S113 단계에 의해 수신된 분석정보를 시각화하여 디스플레이 상에 표시함으로써 사 용자가 검사 대상자의 병변에 대한 정보를 확인하도록 한다(S115).한편, 도 3에는 도시하지 않았으나, 그 영상데이터 분석 서비스를 제공받고자 하는 적어도 하나의 사용자 단말 을 등록하는 절차를 수행할 수 있다. 구체적으로, 적어도 하나의 사용자 단말로부터 등록요청정보가 수신되면, 이를 기반으로 그 사용자에 대한 등록을 수행할 수 있다. 다만, 도 3에는 사용자 단말을 하나만 도시하였으나, 이는 설명의 편의를 위한 것일 뿐 적어도 하나 이상 으로 구성될 수 있으며, 이를 한정하지 않는다. 도 4는 본 개시의 일 실시예에 따른 인공지능 기반의 영상데이터 분석 장치의 구성을 나타내는 도면이다. 도 4를 참조하면, 본 개시의 일 실시예에 따른 인공지능 기반의 영상데이터 분석 장치(이하, '분석 장치'라 칭 함)는 통신부, 저장부 및 프로세서 중 적어도 하나를 포함하여 구성될 수 있다. 통신부는 단말기, 외부 저장소(예를 들어, 데이터베이스(database, 140)), 외부 서버 및 클라우드 서버 중 적어도 하나와 통신을 수행할 수 있다. 한편, 외부 서버 또는 클라우드 서버에서는, 프로세서의 적어도 일부의 역할을 수행하도록 구성될 수 있다. 즉, 데이터 처리 또는 데이터 연산 등의 수행은 외부 서버 또는 클라우드 서버에서 이루어지는 것이 가능 하며, 본 개시에서는 이러한 방식에 대한 특별한 제한을 두지 않는다. 한편, 통신부는 통신하는 대상(예를 들어, 전자기기, 외부 서버, 디바이스 등)의 통신 규격에 따라 다양한 통신 방식을 지원할 수 있다. 예를 들어, 통신부는, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), Wi-Fi(Wireless Fidelity) Direct, DLNA(Digital Living Network Alliance), WiBro(Wireless Broadband), WiMAX(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced), 5G(5th Generation Mobile Telecommunication ), 블루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra-Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여, 통신 대상과 통신하도록 이루 어질 수 있다. 다음으로 저장부는, 본 개시와 관련된 다양한 정보를 저장하도록 이루어질 수 있다. 본 개시에서 저장부 는 본 개시에 따른 장치 자체에 구비될 수 있다. 이와 다르게, 저장부의 적어도 일부는, 데이터베이 스(database: DB, 140) 클라우드 저장소(또는 클라우드 서버) 중 적어도 하나를 의미할 수 있다. 즉, 저장부 는 본 개시에 따른 장치 및 방법을 위하여 필요한 정보가 저장되는 공간이면 충분하며, 물리적인 공간에 대한 제약은 없는 것으로 이해될 수 있다. 이에, 이하에서는, 저장부, 데이터베이스, 외부 저장소, 클라우드 저장소(또는 클라우드 서버)를 별도로 구분하지 않고, 모두 저장부라고 표현하도록 한다. 이 저장부는 분석 장치에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션 (application), 분석 장치의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 한편, 응용 프로그램은, 저장부 에 구비된 적어도 하나의 메모리에 저장되고, 분석 장치 상에 설치되어, 제어부를 통해 저장부 에 저장된 적어도 하나의 프로세서에 의하여 동작(또는 기능)을 수행하도록 구동될 수 있다. 한편, 적어도 하나의 메모리는 플래시 메모리 타입(flash memory type), 하드 디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모 리 등), 램(Random Access Memory, RAM), SRAM(Static Random Access Memory), 롬(Read-Only Memory, ROM), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory) 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 아울러, 메모리는 일시적, 영구적 또는 반영구적으로 정보를 저장할 수 있으며, 내장형 또는 탈착형으로 제공될 수 있다. 다음으로, 프로세서는 본 개시와 관련된 장치의 전반적인 동작을 제어하도록 이루어질 수 있다. 프로세서 는 위에서 살펴본 구성요소들을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리하거나 사용자에게 적절한 정보 또는 기능을 제공 또는 처리할 수 있다. 프로세서는 적어도 하나의 CPU(Central Processing Unit, 중앙처리장치)를 포함하여, 본 개시에 따른 기능 을 수행할 수 있다. 구체적으로, 프로세서는 검사 대상자의 장기를 촬영한 제1 영상데이터를 획득하고, 그 획득된 영상데이터 를 인공지능 기반의 사전 학습모델에 입력하여 전체 영역을 기 설정된 복수의 영역으로 구분하고, 제2 영상데이 터에서 앞서 구분된 기 설정된 복수의 영역의 각 대응 영역으로부터 추출된 영상 특성을 적용하여 변환된 제1 영상데이터를 출력한 후, 그 변환된 제1 영상데이터를 분석하여 분석정보를 생성한다. 또한, 프로세서는 그 분석정보를 기 설정된 적어도 하나의 사용자 단말로 송신함으로써, 사용자가 검 사 대상자의 병변에 대한 정보를 시각적으로 확인하도록 할 수 있다. 여기서, 제1 영상데이터는 제1 촬영 장치에 의해 촬영된 제1 도메인의 영상데이터이고, 제2 영상데이터는 제2 촬영 장치에 의해 촬영된 제2 도메인의 영상데이터이다. 즉, 제1 촬영 장치 및 제2 촬영 장치는 서로 상이한 이 종 디바이스이다. 그 외, 프로세서의 구체적인 동작에 대해서는 이하에서 각각의 도면을 기반으로 설명하도록 한다. 그 중 변환된 제1 영상데이터를 출력하는 동작은 이하에서 도 7 및 도 8을 이용하여 구체적으로 설명하도록 하고, 사 전 학습모델을 생성하는 동작은 이하에서 도 9 및 도 10을 이용하여 구체적으로 설명하도록 한다. 도 4에 도시된 구성 요소들의 성능에 대응하여 적어도 하나의 구성요소가 추가되거나 삭제될 수 있다. 또한, 구 성 요소들의 상호 위치는 장치의 성능 또는 구조에 대응하여 변경될 수 있다는 것은 당해 기술 분야에서 통상의 지식을 가진 자에게 용이하게 이해될 것이다. 도 5는 본 개시의 일 실시예에 따른 인공지능 기반의 영상데이터 분석 장치를 통해 영상데이터를 변환하는 매커 니즘을 나타내는 도면이다. 먼저, 제1 영상데이터는 촬영 장치로부터 수집된 데이터이고, 제2 영상데이터는 데이터베이스에 기 저장된 데이터이다. 이때, 제1 영상데이터 및 제2 영상데이터는 모두 적어도 하나 이상일 수 있다. 도 5를 참조하면, 분석 장치는 제1 영상데이터가 촬영 장치로부터 획득되면, 이를 사전 학습모델에 입력하여 제1 영상데이터의 전체 영역을 기 설정된 조건에 따라 제1 영역, 제2 영역 및 제3 영역으로 구분하고, 각 영역에 대한 형상 특성(shape feature)(S1', S2', S3') 및 색상 특성(color feature)(C1', C2', C3')를 추 출한다. 한편, 분석 장치는 데이터베이스에 기 저장된 제2 영상데이터의 전체 영역을 기 설정된 조건에 따라 제1 영역, 제2 영역 및 제3 영역으로 구분하고, 각 영역에 대한 형상 특성(S1, S2, S3) 및 색상 특성(C1, C2, C3)를 추출한다. 여기서, 제1 영상데이터 및 제2 영상데이터의 영역을 구분하기 위한 기 설정된 조건은 동일하며, 제2 영상데이 터의 각 영역은 제1 영상데이터의 각 영역에 대응하는 대응 영역이다. 즉, 제2 영상데이터의 제1 영역, 제2 영 역 및 제3 영역 각각은 제1 영상데이터의 제1 영역, 제2 영역 및 제3 영역에 대응한다. 이후, 분석 장치는 제2 영상데이터의 각 영역으로부터 추출된 색상 특성(C1, C2, C3)를 각각 제1 영상데이 터의 각 대응 영역으로부터 추출된 형상 특성(S1', S2', S3')와 결합함으로써, 결과적으로 제3 영상데이터(변환 된 제1 영상데이터)를 출력한다. 한편, 제1 영역은 해당 영상데이터의 전체 영역에서 버블(거품, 부유물 등)을 포함하는 영역을 나타내고, 제2 영역은 해당 영상데이터의 전체 영역에서 제1 영역을 제외한 영역에서 픽셀의 밝기값이 기 설정된 임계치 이하 인 영역을 나타내며, 제3 영역은 해당 영상데이터의 전체 영역에서 제1 영역 및 제2 영역을 제외한 영역에서 픽 셀의 밝기값이 기 설정된 임계치를 초과하는 영역을 나타낼 수 있다. 그러나, 이는 하나의 실시예에 해당하는 것으로, 영상데이터의 전체 영역이 앞서 설명한 바와 같이 반드시 세 개의 영역으로 구분될 필요는 없으며, 그 구분되는 영역의 개수 및 조건은 분석 장치의 관리자(사용자)에 의해 설정 및/또는 변경될 수 있다. 일 예로서, 영상데이터의 전체 영역을 두 개의 영역으로 구분하도록 설정할 시에는 비가시영역(거품, 부유물이 존재하거나 어두운 영역)에 해당하는 부분을 제1 영역으로 하고, 가시 영역 에 해당하는 부분을 제2 영역으로 결정할 수 있다. 또한, 다른 예로서, 영상데이터의 전체 영역을 네 개의 영역 으로 구분하도록 설정할 시에는 버블(거품)을 포함하는 영역에 해당하는 부분을 제1 영역으로, 부유물을 포함하 는 영역에 해당하는 부분을 제2 영역으로, 어두운 영역에 해당하는 부분을 제3 영역으로, 그 외 나머지 영역 또 는 가시 영역에 해당하는 부분을 제4 영역으로 결정할 수 있다. 한편, 구분되는 영역의 개수와 각 영역에서 추출하는 특성의 개수가 동일하거나 동일하지 않을 수 있다. 예를 들어, 영상데이터의 전체 영역이 3개의 영역으로 구분된 경우, 각각의 영역으로부터 각각 특성을 추출함에 따라, 형상 특성이 3개, 색상 특성이 3개 추출될 수 있으나, 이 또한 하나의 실시예에 해당하는 바, 영역의 개 수와 추출되는 특성의 개수는 상이할 수 있다. 도 6은 본 개시의 일 실시예에 따른 인공지능 기반의 영상데이터 분석 방법을 나타내는 도면이다. 도 6을 참조하면, 분석 장치는 검사 대상자의 장기를 촬영한 제1 영상데이터를 획득하고(S210), 그 획득된 제1 영상데이터를 인공지능 기반의 사전 학습모델에 입력하여 전체 영역을 기 설정된 복수의 영역으로 구분한다 (S220). 그 다음으로, 분석 장치는 데이터베이스에 기 저장된 제2 영상데이터에서 기 설정된 복수의 영역에 대응하는 각 대응 영역으로부터 추출된 영상 특성을 S210 단계에 의해 획득된 제1 영상데이터 상에 적용함으로 써 변환된 제1 영상데이터를 출력하고(S230), 그 변환된 제1 영상데이터를 분석하여 분석정보를 생성한다 (S240). 도 7은 본 개시의 제1 실시예에 따른 인공지능 기반의 영상데이터 분석 방법에서 영상데이터를 변환하는 동작을 구체적으로 설명하기 위한 도면으로서, 도 6의 S230 단계를 구체적으로 나타낸 것이다. 도 7을 참조하면, 분석 장치는 S220 단계에서 제1 영상데이터를 사전 학습모델에 입력하여 전체 영역이 기 설정된 기준에 따라 세 개의 영역으로 구분되면, 제1 영상데이터의 각 영역에 대한 형상 특성을 추출하고 (S2311), 제2 영상데이터에서 제1 영상데이터의 각 영역에 대응하는 영역, 즉, 각 대응 영역에 대한 색상 특성 을 추출한다(S2312). 그 다음으로, 분석 장치는 S2311 단계에 의해 추출된 각 영역에 대한 형상 특성 및 S2312 단계에 의해 추 출된 각 대응 영역에 대한 색상 특성을 결합하여 변환된 제1 영상데이터를 출력한다(S2313). 도 8은 본 개시의 제2 실시예에 따른 인공지능 기반의 영상데이터 분석 방법에서 영상데이터를 변환하는 동작을 구체적으로 설명하기 위한 도면으로서, 도 6의 S230 단계를 구체적으로 나타낸 것이다. 도 8을 참조하면, 분석 장치는 S220 단계에서 제1 영상데이터를 사전 학습모델에 입력하여 전체 영역이 기 설정된 기준에 따라 세 개의 영역으로 구분되면, 제1 영상데이터의 각 영역에 대한 제1 형상 특성 및 제1 색상 특성을 추출하고(S2321), 제2 영상데이터에서 제1 영상데이터의 각 영역에 대응하는 영역, 즉, 각 대응 영역에 대한 제2 형상 특성 및 제2 색상 특성을 추출한다(S2322). 그 다음으로, 분석 장치는 S2321 단계에 의해 추출된 제1 형상 특성을 기반으로 하되, 제1 색상 특성을 S2322 단계에 의해 추출된 제2 색상 특성으로 교체하여 변환된 제1 영상데이터를 출력한다(S2323). 상기에서 살펴본 바와 같이, 도 7은 제1 영상데이터의 각 영역에서 형상 특성만을 추출하고, 제2 영상데이터의 각 대응 영역에서 색상 특성만을 추출하여 이들을 결합함으로써 변환된 제1 영상데이터를 출력하는 실시예에 관 한 것이고, 도 8은 제1 영상데이터의 각 영역 및 제2 영상데이터의 각 대응 영역으로부터 색상 특성 및 형상 특 성을 추출한 후, 제1 영상데이터의 각 영역으로부터 추출된 색상 특성을 제2 영상데이터의 각 대응 영역으로부 터 추출된 색상 특성으로 교체함으로써 변환된 제1 영상데이터를 출력하는 실시예에 관한 것이다. 도 9는 본 개시의 일 실시예에 따른 인공지능 기반의 사전 학습모델을 생성하는 방법을 나타내는 도면이다. 도 9를 참조하면, 분석 장치는 기 설정된 기간 동안 적어도 하나의 제1 영상데이터 및 적어도 하나의 제2 영상데이터를 수집하고(S201), 그 수집된 적어도 하나의 제1 영상데이터 및 적어도 하나의 제2 영상데이터를 이 용하여 학습데이터 셋을 구축한다(S202). 그 다음으로, 분석 장치는 S202 단계에 의해 구축된 학습데이터 셋을 이용하여 원본 모델을 학습함으로써 사전 학습모델을 생성한다(S203). 도 10은 본 개시의 일 실시예에 따른 인공지능 기반의 사전 학습모델을 학습하기 위한 데이터 셋을 구축하는 동 작을 구체적으로 설명하기 위한 도면으로서, 도 9의 S202 단계를 구체적으로 나타낸 것이다. 도 10을 참조하면, 분석 장치는 S201 단계에 의해 수집된 적어도 하나의 제1 영상데이터 각각의 전체 영역 을 기 설정된 기준에 따라 세 개의 영역으로 구분하고(S2021), 데이터베이스에 기 저장된 제2 영상데이터의 각 대응 영역으로부터 추출된 영상 특성을 적용하여 적어도 하나의 제1 영상데이터 각각에 대한 변환을 수행한다 (S2022).그 다음으로, 분석 장치는 S2022 단계에 의해 변환된 적어도 하나의 제1 영상데이터 및 S2021 단계에 의해 수집된 적어도 하나의 제2 영상데이터를 취합하여 학습데이터 셋을 구축한다. 즉, S201 단계에 의해 수집된 데이터들 중 적어도 하나의 제1 영상데이터는 제2 영상데이터의 영상 특성을 적용 하여 제2 도메인의 영상데이터의 형태로 변환함으로써 이용한다. 앞서 본 발명을 설명함에 있어서, 영상 특성으로서 형상 특성 및 색상 특성만을 이용하였으나, 이는 설명의 편 의를 위하여 일 실시예에 한정하여 설명한 것일 뿐, 텍스처 특성(texture feature)을 더 이용할 수 있다, 즉, 영상 특성으로서 형상 특성, 색상 특성 및 텍스처 특성 중 2개 이상을 추출하여 이용할 수 있다. 뿐만 아니라, 영상 특성으로 추출될 수 있는 다른 특성을 이용할 수 있으며, 그 영상 특성의 종류 및 개수는 한정하지 않는다. 한편, 본 개시는 인공 신경망 방식으로 구현된 모델을 이용해서 소정의 목적 하에 예측(inference)을 수행하는 바, 이하에서는 인공 신경망에 대해 살펴보기로 한다. 본 명세서에서의 모델은 네트워크 함수, 인공신경망 및/또는 뉴럴 네트워크에 기반하여 동작하는 임의의 형태의 컴퓨터 프로그램을 의미할 수 있다. 본 명세서에 걸쳐, 모델, 신경망, 네트워크 함수, 뉴럴 네트워크(neural network)는 상호 교환 가능한 의미로 사용될 수 있다. 신경망은 하나 이상의 노드들이 하나 이상의 링크를 통해 상호 연결되어 신경망 내에서 입력 노드 및 출력 노드 관계를 형성한다. 신경망 내에서 노드들과 링크들의 개수 및 노드들과 링크들 사이의 연관관계, 링크들 각각에 부여된 가중치의 값에 따라, 신경망의 특성이 결정될 수 있다. 신경망은 하나 이상의 노드들의 집합으로 구성될 수 있다. 신경망을 구성하는 노드들의 부분 집합은 레이 어(layer)를 구성할 수 있다. 딥 뉴럴 네트워크(DNN: deep neural network, 심층신경망)는 입력 레이어와 출력 레이어 외에 복수개의 히든 레 이어를 포함하는 신경망을 의미할 수 있으며, 중간에 있는 히든 계층이 딥 뉴럴 네트워크에서는 1개 이상, 바람 직하게는 2개 이상으로 구성된다. 이러한 딥 뉴럴 네트워크는 합성곱 신경망(CNN: convolutional neural network), 비젼 트랜스포머(vision transformer), 리커런트 뉴럴 네트워크(RNN: recurrent neural network), LSTM(Long Short Term Memory) 네트 워크, GPT(Generative Pre-trained Transformer), 오토 인코더(auto encoder), GAN(Generative Adversarial Networks), 제한 볼츠만 머신(RBM: restricted boltzmann machine), 심층 신뢰 네트워크(DBN: deep belief network), Q 네트워크, U 네트워크, 샴 네트워크, 적대적 생성 네트워크(GAN: Generative Adversarial Network), 트랜스포머(transformer) 등을 포함할 수 있다. 또는, 실시예에 따라 딥 뉴럴 네트워크는 전이학습(transfer learning) 방식으로 학습된 모델일 수 있다. 여기 서, 전이학습은 대용량의 라벨링되어 있지 않은 학습용 데이터를 준지도학습 또는 자가학습 방식으로 사전 학습 (pre-training)하여 제1 태스크를 갖는 사전 학습된(pre-trained) 모델(또는 베이스부)을 특정 기법(MLM 및 NSP) 등을 통해 얻고, 사전 학습된 모델을 제2 태스크에 적합하도록 fine-tuning하기 위해, 라벨링된 학습용 데 이터를 지도학습 방식으로 학습시켜서 타겟으로 하는 모델을 구현하는 학습 방식을 나타낸다. 이러한 전이학습 방식으로 학습된 모델 중 하나로서, BERT(Bidirectional Encoder Representations from Transformers) 등이 있 는데, 다만 이에 한정되는 것은 아니다. 전술한 딥 뉴럴 네트워크의 기재는 예시일 뿐이며 본 개시는 이에 제한되지 않는다. 여기서 전술한 합성곱 신경 망의 경우, 이미지로부터 특징을 추출하는 특징 추출부(feature learning), 그리고 이렇게 추출된 특징을 이용 해서 분류를 수행하는 분류부(classification)로 구성된다. 특징 추출부에는 이미지로부터 커널을 이용해서 특 징이 추출되는 합성곱 계층, 활성화 함수 중 하나인 ReLU 계층 그리고 데이터의 차원을 줄이기 위한 풀링 (Pooling) 계층이 포함될 수 있으며, 다만 이에 한정되는 것은 아니다. 아울러, 분류부에는 특징 추출부에서 추 출된 특징을 일렬로 늘어뜨리는 flatten 계층, 그리고 실질적으로 분류가 수행되는 전결합층(fully connected layer) 및 softmax 함수가 포함될 수 있으며, 다만 이에 한정되는 것은 아니다. 뉴럴 네트워크는 지도학습(supervised learning), 비지도학습(unsupervised learning), 준지도학습(semi supervised learning), 자가학습(self-supervised learning) 또는 강화학습(reinforcement learning) 중 적어 도 하나의 방식으로 학습될 수 있다. 뉴럴 네트워크의 학습은 뉴럴 네트워크가 특정한 동작을 수행하기 위한 지 식을 뉴럴 네트워크에 적용하는 과정일 수 있다. 뉴럴 네트워크는 출력의 오류를 최소화하는 방향으로 학습될 수 있다. 뉴럴 네트워크의 학습에서 반복적으로 학 습 데이터를 뉴럴 네트워크에 입력시키고 학습 데이터에 대한 뉴럴 네트워크의 출력과 타겟의 에러를 계산하고, 에러를 줄이기 위한 방향으로 뉴럴 네트워크의 에러를 뉴럴 네트워크의 출력 레이어에서부터 입력 레이어 방향 으로 역전파(backpropagation)하여 뉴럴 네트워크의 각 노드의 가중치를 업데이트 하는 과정이다. 지도학습의 경우 각각의 학습 데이터에 정답이 라벨링 되어있는 데이터(labelled data)를 사용하며, 비지도학습의 경우는 각각의 학습 데이터에 정답이 라벨링되어 있지 않은 데이터(unlabeled data)를 사용할 수 있다. 업데이트 되는 각 노드의 연결 가중치는 학습률(learning rate)에 따라 변화량이 결정될 수 있다. 입력 데이터에 대한 뉴럴 네 트워크의 계산과 에러의 역전파는 학습 사이클(epoch)을 구성할 수 있다. 학습률은 뉴럴 네트워크의 학습 사이 클의 반복 횟수에 따라 상이하게 적용될 수 있다. 또한, 과적합(overfitting)을 막기 위해서 학습 데이터의 증 가, 레귤러화(regularization), 노드 일부를 비활성화하는 드롭아웃(dropout), 배치 정규화 레이어(batch normalization layer) 등의 방법이 적용될 수 있다. 한편, 일 실시예에서 개시되는 모델은 트랜스포머의 적어도 일부분을 차용할 수 있다. 트랜스포머는 임베딩된 데이터들을 인코딩하는 인코더 및 인코딩된 데이터들을 디코딩하는 디코더로 구성될 수 있다. 트랜스포머는 일 련의 데이터들을 수신하여, 인코딩 및 디코딩 단계를 거처 상이한 타입의 일련의 데이터들을 출력하는 구조를 지닐 수 있다. 일 실시예에서, 일련의 데이터들은 트랜스포머가 연산가능한 형태로 가공될 수 있다. 일련의 데 이터들을 트랜스포머가 연산가능한 형태로 가공하는 과정은 임베딩 과정을 포함할 수 있다. 데이터 토큰, 임베 딩 벡터, 임베딩 토큰 등과 같은 표현들은, 트랜스포머가 처리할 수 있는 형태로 임베딩된 데이터들을 지칭하는 것일 수 있다. 트랜스포머가 일련의 데이터들을 인코딩 및 디코딩하기 위하여, 트랜스포머 내의 인코더 및 디코더들을 어텐션 (attention) 알고리즘을 활용하여 처리할 수 있다. 어텐션 알고리즘이란 주어진 쿼리(Query)에 대해, 하나 이상 의 키(Key)에 대한 유사도를 구하고, 이렇게 주어진 유사도를, 각각의 키(Key)와 대응하는 값(Value)에 반영한 후, 유사도가 반영된 값(Value)들을 가중합하여 어텐션 값을 계산하는 알고리즘을 의미할 수 있다. 쿼리, 키 및 값을 어떻게 설정하느냐에 따라, 다양한 종류의 어텐션 알고리즘이 분류될 수 있다. 예를 들어, 쿼 리, 키 및 값을 모두 동일하게 설정하여 어텐션을 구하는 경우, 이는 셀프-어텐션 알고리즘을 의미할 수 있다. 입력된 일련의 데이터들을 병렬로 처리하기 위해, 임베딩 벡터를 차원을 축소하여, 각 분할된 임베딩 벡터에 대 해 개별적인 어텐션 헤드를 구하여 어텐션을 구하는 경우, 이는 멀티-헤드(multi-head) 어텐션 알고리즘을 의미 할 수 있다. 일 실시예에서, 트랜스포머는 복수개의 멀티-헤드 셀프 어텐션 알고리즘 또는 멀티-헤드 인코더-디코더 알고리 즘을 수행하는 모듈들로 구성될 수 있다. 일 실시예에서, 트랜스포머는 임베딩, 정규화, 소프트맥스(softmax) 등 어텐션 알고리즘이 아닌 부가적인 구성요소들 또한 포함할 수 있다. 어텐션 알고리즘을 이용하여 트랜스포머 를 구성하는 방법은 Vaswani et al., Attention Is All You Need, 2017 NIPS에 개시된 방법을 포함할 수 있으 며, 이는 본 명세서에 참조로 통합된다. 트랜스포머는 임베딩된 자연어, 분할된 이미지 데이터, 오디오 파형 등 다양한 데이터 도메인에 적용하여, 일련 의 입력 데이터를 일련의 출력 데이터로 변환할 수 있다. 다양한 데이터 도메인을 가진 데이터들을 트랜스포머 에 입력가능한 일련의 데이터들로 변환하기 위해, 트랜스포머는 데이터들을 임베딩할 수 있다. 트랜스포머는 일 련의 입력 데이터 사이의 상대적 위치관계 또는 위상관계를 표현하는 추가적인 데이터를 처리할 수 있다. 또는 일련의 입력 데이터에 입력 데이터들 사이의 상대적인 위치관계 또는 위상관계를 표현하는 벡터들이 추가적으로 반영되어 일련의 입력 데이터가 임베딩될 수 있다. 일 예에서, 일련의 입력 데이터 사이의 상대적 위치관계는, 자연어 문장 내에서의 어순, 각각의 분할된 이미지의 상대적 위치 관계, 분할된 오디오 파형의 시간 순서 등을 포함할 수 있으나, 이에 제한되지 않는다. 일련의 입력 데이터들 사이의 상대적인 위치관계 또는 위상관계를 표 현하는 정보를 추가하는 과정은 위치 인코딩(positional encoding)으로 지칭될 수 있다. 상기 전술한 프로그램은, 상기 컴퓨터가 프로그램을 읽어 들여 프로그램으로 구현된 상기 방법들을 실행시키기 위하여, 상기 컴퓨터의 프로세서(CPU)가 상기 컴퓨터의 장치 인터페이스를 통해 읽힐 수 있는 C, C++, JAVA, 기 계어 등의 컴퓨터 언어로 코드화된 코드(Code)를 포함할 수 있다. 이러한 코드는 상기 방법들을 실행하는 필요 한 기능들을 정의한 함수 등과 관련된 기능적인 코드(Functional Code)를 포함할 수 있고, 상기 기능들을 상기 컴퓨터의 프로세서가 소정의 절차대로 실행시키는데 필요한 실행 절차 관련 제어 코드를 포함할 수 있다. 또한, 이러한 코드는 상기 기능들을 상기 컴퓨터의 프로세서가 실행시키는데 필요한 추가 정보나 미디어가 상기 컴퓨 터의 내부 또는 외부 메모리의 어느 위치(주소 번지)에서 참조되어야 하는지에 대한 메모리 참조관련 코드를 더 포함할 수 있다. 또한, 상기 컴퓨터의 프로세서가 상기 기능들을 실행시키기 위하여 원격(Remote)에 있는 어떠한 다른 컴퓨터나 서버 등과 통신이 필요한 경우, 코드는 상기 컴퓨터의 통신 모듈을 이용하여 원격에 있는 어 떠한 다른 컴퓨터나 서버 등과 어떻게 통신해야 하는지, 통신 시 어떠한 정보나 미디어를 송수신해야 하는지 등 에 대한 통신 관련 코드를 더 포함할 수 있다. 상기 저장되는 매체는, 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반 영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상기 저 장되는 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등이 있지만, 이에 제한되지 않는다. 즉, 상기 프로그램은 상기 컴퓨터가 접속할 수 있는 다양한 서버 상의 다양한 기록매체 또는 사용자의 상기 컴퓨터상의 다양한 기록매체에 저장될 수 있다. 또한, 상기 매체는 네트워크로 연결된 컴퓨터 시 스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장될 수 있다. 본 개시의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 개시가 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다."}
{"patent_id": "10-2024-0071627", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상, 첨부된 도면을 참조로 하여 본 개시의 실시예를 설명하였지만, 본 개시가 속하는 기술분야의 통상의 기술 자는 본 개시가 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2024-0071627", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 서로 다른 장치를 통해 각각 촬영된 영상데이터의 일 예시를 나타내는 도면 도 2는 본 개시의 일 실시예에 따른 인공지능 기반의 영상데이터 분석 시스템의 네트워크 구조를 나타내는 도면 도 3은 본 개시의 일 실시예에 따른 인공지능 기반의 영상데이터 분석 시스템의 동작을 나타내는 흐름도 도 4는 본 개시의 일 실시예에 따른 인공지능 기반의 영상데이터 분석 장치의 구성을 나타내는 도면 도 5는 본 개시의 일 실시예에 따른 인공지능 기반의 영상데이터 분석 장치를 통해 영상데이터를 변환하는 매커 니즘을 나타내는 도면도 6은 본 개시의 일 실시예에 따른 인공지능 기반의 영상데이터 분석 방법을 나타내는 도면 도 7은 본 개시의 제1 실시예에 따른 인공지능 기반의 영상데이터 분석 방법에서 영상데이터를 변환하는 동작을 구체적으로 설명하기 위한 도면 도 8은 본 개시의 제2 실시예에 따른 인공지능 기반의 영상데이터 분석 방법에서 영상데이터를 변환하는 동작을 구체적으로 설명하기 위한 도면 도 9는 본 개시의 일 실시예에 따른 인공지능 기반의 사전 학습모델을 생성하는 방법을 나타내는 도면 도 10은 본 개시의 일 실시예에 따른 인공지능 기반의 사전 학습모델을 학습하기 위한 데이터 셋을 구축하는 동 작을 구체적으로 설명하기 위한 도면"}
