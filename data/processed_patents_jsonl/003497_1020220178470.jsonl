{"patent_id": "10-2022-0178470", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0094171", "출원번호": "10-2022-0178470", "발명의 명칭": "압축된 기울기 및 모델 파라미터의 전송을 이용하는 분산형 인공지능 시스템, 그 학습 장치", "출원인": "한국전자통신연구원", "발명자": "이안석"}}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "로컬 디바이스에 의한 분산형 인공지능의 학습 방법에 있어서, 상기 로컬 디바이스가 로컬 데이터셋에 기반하여 로컬 모델을 학습함으로써 상기 로컬 모델의 파라미터를 업데이트하는 단계; 상기 로컬 디바이스가 상기 로컬 모델의 파라미터의 기울기(gradient)를 압축하여 압축된 기울기 정보를 생성하는 단계;상기 로컬 디바이스가 상기 압축된 기울기 정보를 파라미터 서버로 전송하는 단계; 상기 파라미터 서버가 상기 로컬 디바이스로부터 수신되는 상기 압축된 기울기 정보에 기반하여 상기 로컬 모델의 파라미터의 기울기를 복원하는 단계; 및 상기 파라미터 서버가 상기 복원된 로컬 모델의 파라미터의 기울기에 기반하여 글로벌 모델의 파라미터를 업데이트하는 단계; 를 포함하는,분산형 인공지능의 학습 방법."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 압축된 기울기 정보를 생성하는 단계는, 상기 로컬 모델의 파라미터의 기울기를 형성하는 고차원 로컬 원시 벡터를 복수개의 저차원 S-희소 서브 벡터들로 변환하는 블록 희소화 단계; 및 상기 복수개의 저차원 S-희소 서브 벡터들을 디지털 비트 시퀀스 형태로 변환하는 디지털 인코딩 단계;를 포함하는, 분산형 인공지능의 학습 방법."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 블록 희소화 단계는, 상기 고차원 로컬 원시 벡터를 L개의 서브 벡터들로 구분하는 단계; 및 상기 L개의 서브 벡터들 각각에 대해 가장 큰 S개의 원소를 선택하고 나머지 원소들을 제거하여 상기 저차원 S-희소 서브 벡터들을 생성하는 단계;를 포함하는, 분산형 인공지능의 학습 방법."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 블록 희소화 단계는, 상기 디지털 인코딩 단계를 거친 압축된 기울기 정보를 복원하는 단계;공개특허 10-2023-0094171-3-상기 고차원 로컬 원시 벡터에서 상기 복원된 기울기 정보를 뺀 나머지 정보를 저장하는 단계; 및상기 저장된 나머지 원소들을 다음 차수의 상기 고차원 로컬 원시 벡터에 부가하는 단계;를 포함하는, 분산형 인공지능의 학습 방법."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 저차원 S-희소 서브 벡터들을 생성하는 단계는, 상기 L개의 서브 벡터들 각각에 대해 병렬적으로 수행되는, 분산형 인공지능의 학습 방법."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 저차원 S-희소 서브 벡터들을 생성하는 단계는, 원시 벡터 복원 성능이 고려된 최적화 목적 함수를 최대화하는 양자화 레벨 Q과 관련되는 최적 희소화 레벨 S에기반하여 수행되는, 분산형 인공지능의 학습 방법."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서,상기 디지털 인코딩 단계는, 상기 복수개의 저차원 S-희소 서브 벡터들을 복수개의 S 차원 선형 변환된 벡터로 변환하는 단계; 및 상기 복수개의 S 차원 선형 변환된 벡터의 각 원소를 디지털 형태로 변환하는 스칼라 양자화 단계;를 포함하는, 분산형 인공지능의 학습 방법."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 복수개의 저차원 S-희소 서브 벡터들을 복수개의 S 차원 선형 변환된 벡터로 변환하는 단계는상기 복수개의 저차원 S-희소 서브 벡터들 각각에서 0이 아닌 원소를 선택하여 S 차원 벡터를 생성하는 단계;상기 S 차원 벡터의 경험적 평균 및 분산 값을 도출하는 단계;상기 도출된 경험적 평균 및 분산 값을 이용하여 S 차원 벡터를 정규화된 벡터로 변환하는 단계; 및 상기 정규화된 벡터를 S 차원 직교 행렬 또는 이에 준하는 행렬을 이용하여 선형 변환된 벡터로 변환하는 단계;를 포함하는, 분산형 인공지능의 학습 방법."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 S 차원 직교 행렬은 하다마드 행렬 또는 랜덤 기우시안 행렬인, 분산형 인공지능의 학습 방법.공개특허 10-2023-0094171-4-청구항 10 제7항에 있어서,상기 스칼라 양자화 단계는, 원시 벡터 복원 성능이 고려된 최적화 목적 함수를 최대화하는 양자화 레벨 Q에 기반하여 수행되는, 분산형 인공지능의 학습 방법."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 양자화 레벨 Q는, 허용된 통신 오버헤드를 고려하여 결정되는,분산형 인공지능의 학습 방법."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서,상기 디지털 인코딩 단계는, 상기 복수개의 저차원 S-희소 서브 벡터들 내에서 0이 아닌 S개의 값들이 존재하는 위치를 디지털 비트 시퀀스로 나타내는 위치 인코딩 단계;를 더 포함하는, 분산형 인공지능의 학습 방법."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 파라미터 서버가 상기 로컬 모델의 파라미터의 기울기를 복원하는 단계는, 양자화된 값 벡터에 선형 최소평균제곱오류 추정 기법을 적용하여 정규화된 벡터의 추정치를 얻는 단계;를 포함하는, 분산형 인공지능의 학습 방법."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 파라미터 서버가 상기 로컬 모델의 파라미터의 기울기를 복원하는 단계는, 상기 정규화된 벡터의 추정치에 대하여 정규화 과정에서 얻은 경험적인 평균 및 분산값을 이용하여 역정규화를수행하는 단계;를 더 포함하는, 분산형 인공지능의 학습 방법."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "파라미터 서버 및 로컬 디바이스에 의한 분산형 인공지능의 학습 방법에 있어서,상기 파라미터 서버가 글로벌 모델의 파라미터를 압축하여 압축된 글로벌 모델 파라미터 정보를 생성하는 단계;상기 파라미터 서버가 상기 압축된 글로벌 모델 파라미터 정보를 상기 로컬 디바이스로 전송하는 단계;상기 로컬 디바이스가 상기 파라미터 서버로부터 수신되는 상기 압축된 글로벌 모델 파라미터 정보에 기반하여상기 글로벌 모델의 파라미터를 복원하는 단계; 및 공개특허 10-2023-0094171-5-상기 로컬 디바이스가 상기 복원된 상기 글로벌 모델의 파라미터를 로컬 모델로서 저장하는 단계;를 포함하는, 분산형 인공지능의 학습 방법."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 압축된 글로벌 모델 파라미터 정보를 생성하는 단계는, 상기 글로벌 모델의 파라미터를 형성하는 고차원 글로벌 원시 벡터를 복수개의 저차원 S-희소 서브 벡터들로 변환하는 블록 희소화 단계; 및 상기 복수개의 저차원 S-희소 서브 벡터들을 디지털 비트 시퀀스 형태로 변환하는 디지털 인코딩 단계;를 포함하는, 분산형 인공지능의 학습 방법."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "적어도 하나 이상의 명령을 저장하는 메모리(memory); 및 상기 적어도 하나 이상의 명령을 수행하는 프로세서(processor);를 포함하고, 상기 프로세서는 상기 적어도 하나 이상의 명령을 수행함으로써, 로컬 데이터셋에 기반하여 로컬 모델을 학습함으로써 상기 로컬 모델의 파라미터를 업데이트하고,상기 로컬 모델의 파라미터의 기울기(gradient)를 압축하여 압축된 기울기 정보를 생성하고, 상기 로컬 디바이스가 상기 압축된 기울기 정보를 파라미터 서버로 전송하고,상기 파라미터 서버로부터 글로벌 모델의 파라미터를 수신하는, 분산형 인공지능의 학습 장치."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 파라미터 서버로부터 수신되는 상기 글로벌 모델의 파라미터는, 상기 글로벌 모델의 파라미터가 압축된 정보인, 분산형 인공지능의 학습 장치."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서, 상기 프로세서는, 상기 글로벌 모델의 파라미터에 기반하여 상기 로컬 모델의 파라미터를 업데이트하고, 새로운 로컬 데이터셋에 기반하여 상기 로컬 모델을 학습함으로써 상기 로컬 모델의 파라미터를 다시 업데이트하는, 분산형 인공지능의 학습 장치."}
{"patent_id": "10-2022-0178470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17항에 있어서,공개특허 10-2023-0094171-6-상기 프로세서는 상기 압축된 기울기 정보를 생성함에 있어서, 블록 희소화 과정에 의하여 상기 로컬 모델의 파라미터의 기울기를 형성하는 고차원 로컬 원시 벡터를 복수개의저차원 S-희소 서브 벡터들로 변환하고,디지털 인코딩 과정에 의하여 상기 복수개의 저차원 S-희소 서브 벡터들을 디지털 비트 시퀀스 형태로변환하는, 분산형 인공지능의 학습 장치."}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 분산형 인공지능의 학습 방법은 로컬 디바이스가 로컬 데이터셋에 기반하여 로컬 모 델을 학습함으로써 로컬 모델의 파라미터를 업데이트하는 단계; 로컬 디바이스가 로컬 모델의 파라미터의 기울기 (gradient)를 압축하여 압축된 기울기 정보를 생성하는 단계; 로컬 디바이스가 압축된 기울기 정보를 파라미터 서버로 전송하는 단계; 파라미터 서버가 로컬 디바이스로부터 수신되는 압축된 기울기 정보에 기반하여 로컬 모 델의 파라미터의 기울기를 복원하는 단계; 및 파라미터 서버가 복원된 로컬 모델의 파라미터의 기울기에 기반하 여 글로벌 모델의 파라미터를 업데이트하는 단계를 포함한다."}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 다수개의 분산된 장치에서 학습이 이루어지는 분산형 인공지능, 및/또는 다수개의 분산된 장치들 간 의 연합학습(federated learning)에 관한 것이다."}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 본 실시예에 대한 배경 정보를 제공할 뿐 종래 기술을 구성하는 것은 아니다. 다양한 인공지능 기술들이 통신의 전송 용량 및 속도를 증대시키기 위해 적용된다. 분산형 인공지능 기술은 인 공지능 모델에 대한 훈련을 무선 기기들과의 협력에 기반하여 수행할 때 활용할 수 있는 핵심 기반 기술이다. 특별히 무선 기기의 프라이버시(privacy) 정보가 담겨있는 로컬 데이터를 활용하는 경우, 기기의 프라이버시를 보존하기 위해 분산형 인공지능이 활용될 수 있다. 또한, 무선 기기만 접속할 수 있는 다량의 로컬 데이터를 활 용하는 경우 로컬 데이터 전송을 위해 필요한 오버헤드를 피하기 위해 분산형 인공지능이 활용될 수 있다. 이렇 듯 분산형 인공지능은 인공지능 모델을 학습하는데 있어 기기의 프라이버시 그리고 통신 오버헤드 관점에서 상 당한 이점을 제공한다. 분산형 인공지능 기술의 하나로서, 연합학습(federated learning)은 로우 데이터(raw data)를 서버와 공유하지 않고 모바일 장치에 배치된 분산된 이기종 학습 데이터셋을 사용하여 서버에서 기계 학습 모델을 학습시키는 분 산된 접근 방식이다. 연합학습은 로컬 데이터 셋을 사용한 모델 최적화, 모델 집계 즉, 모델 평균화의 두 가지 작업을 통해 분산 모델 학습을 반복적으로 수행한다. 예를 들면, 모든 라운드에서 서버는 사용 가능한 모바일 장치에 글로벌 모델을 전송하며, 각 모바일 장치는 로컬에서 사용 가능한 데이터로 글로벌 모델을 최적화한 다 음 업데이트된 모델 매개변수(또는 업데이트된 로컬 기울기(gradient))를 통신 링크를 통해 서버로 보낸다. 이 에, 서버는 모바일 장치에서 수신한 로컬 모델 또는 기울기를 평균하여 글로벌 모델을 업데이트하고 반복하여 공유한다. 이와 같이, 수많은 모바일 장치에 배치된 로컬 데이터 셋을 사용하여 글로벌 모델을 최적화하는 것은 어려운 작 업이다. 그 중에서 가장 큰 문제는 모바일 장치 및 서버에서 로컬 계산을 업데이트할 때 발생되는 높은 통신 비 용이다. 통신 비용은 글로벌 모델 매개변수의 크기와 서버에 연결된 모바일 장치 수에 비례한다. 따라서 다수의 모바일 장치에 분산된 인공지능을 학습하는 과정에서 파라미터를 송수신하는 비용을 절감하는 기 법이 요구되는 실정이다. 선행기술문헌 비특허문헌 (비특허문헌 0001) \"FEDERATED LEARNING: STRATEGIES FOR IMPROVING COMMUNICATION EFFICIENCY\", Jakub Konecny et al., arXiv:1610.05492, (공개일 2017년 10월 30일)"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 종래 기술의 문제점을 해결하기 위해 도출된 것으로, 분산형 인공지능의 학습을 위한 정보 전송 시 통신 비용을 절감하기 위한 것을 목적으로 한다. 본 발명은 분산형 인공지능 학습의 효율 및 성능을 증대시키고 비용을 절감하기 위하여 인공지능 모델 파라미터 및 파라미터의 기울기 정보를 가능하면 더 작은 정보량으로 압축 후 전송하여 원격의 장치에서 작은 오차로 기 울기 정보를 복원할 수 있는 분산형 인공지능 시스템, 그 시스템을 구성하는 원격 디바이스, 학습 방법, 및 기 울기 정보의 압축 및 복원 방법을 제안하는 것을 목적으로 한다."}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른 분산형 인공지능의 학습 방법은, 적어도 하나 이상의 명령을 저장하는 메모리(memory)와 전자적으로 통신하며 적어도 하나 이상의 명령을 수행하는 프로세서 (processor)에 의하여 실행될 수 있다. 본 발명의 일 실시예에 따른 방법은 로컬 디바이스에 의한 분산형 인공 지능의 학습 방법으로서 실행될 수 있다. 프로세서는 적어도 하나 이상의 명령을 수행함으로써, 로컬 디바이스 가 로컬 데이터셋에 기반하여 로컬 모델을 학습함으로써 로컬 모델의 파라미터를 업데이트하는 단계; 로컬 디바 이스가 로컬 모델의 파라미터의 기울기(gradient)를 압축하여 압축된 기울기 정보를 생성하는 단계; 로컬 디바 이스가 압축된 기울기 정보를 파라미터 서버로 전송하는 단계; 파라미터 서버가 로컬 디바이스로부터 수신되는 압축된 기울기 정보에 기반하여 로컬 모델의 파라미터의 기울기를 복원하는 단계; 및 파라미터 서버가 복원된 로컬 모델의 파라미터의 기울기에 기반하여 글로벌 모델의 파라미터를 업데이트하는 단계를 포함한다. 압축된 기울기 정보를 생성하는 단계는, 로컬 모델의 파라미터의 기울기를 형성하는 고차원 로컬 원시 벡터를 복수개의 저차원 S-희소 서브 벡터들로 변환하는 블록 희소화 단계; 및 복수개의 저차원 S-희소 서브 벡터들을 디지털 비트 시퀀스 형태로 변환하는 디지털 인코딩 단계를 포함할 수 있다. 블록 희소화 단계는, 고차원 로컬 원시 벡터를 L개의 서브 벡터들로 구분하는 단계; 및 L개의 서브 벡터들 각각 에 대해 가장 큰 S개의 원소를 선택하고 나머지 원소들을 제거하여 저차원 S-희소 서브 벡터들을 생성하는 단계 를 포함할 수 있다. 블록 희소화 단계는, 디지털 인코딩 단계를 거친 압축된 기울기 정보를 복원하는 단계; 고차원 로컬 원시 벡터 에서 복원된 기울기 정보를 뺀 나머지 정보를 저장하는 단계; 및 저장된 나머지 원소들을 다음 차수의 고차원 로컬 원시 벡터에 부가하는 단계를 포함할 수 있다. 저차원 S-희소 서브 벡터들을 생성하는 단계는, L개의 서브 벡터들 각각에 대해 병렬적으로 수행될 수 있다. 저차원 S-희소 서브 벡터들을 생성하는 단계는, 원시 벡터 복원 성능이 고려된 최적화 목적 함수를 최대화하는 양자화 레벨 Q과 관련되는 최적 희소화 레벨 S에 기반하여 수행될 수 있다. 디지털 인코딩 단계는, 복수개의 저차원 S-희소 서브 벡터들을 복수개의 S차원 선형 변환된 벡터로 변환하는 단 계; 및 복수개의 S차원 선형 변환된 벡터의 각 원소를 디지털 형태로 변환하는 스칼라 양자화 단계를 포함할 수 있다. 복수개의 저차원 S-희소 서브 벡터들을 복수개의 S 차원 선형 변환된 벡터로 변환하는 단계는, 복수개의 저차원 S-희소 서브 벡터들 각각에서 0이 아닌 원소를 선택하여 S 차원 벡터를 생성하는 단계; S 차원 벡터의 경험적 평균 및 분산 값을 도출하는 단계; 도출된 경험적 평균 및 분산 값을 이용하여 S 차원 벡터를 정규화된 벡터로 변환하는 단계; 및 정규화된 벡터를 S 차원 직교 행렬 또는 이에 준하는 행렬을 이용하여 선형 변환된 벡터로 변환하는 단계를 포함할 수 있다. S 차원 직교 행렬은 하다마드 행렬 또는 랜덤 기우시안 행렬일 수 있다. 스칼라 양자화 단계는, 원시 벡터 복원 성능이 고려된 최적화 목적 함수를 최대화하는 양자화 레벨 Q에 기반하 여 수행될 수 있다. 양자화 레벨 Q는 허용된 통신 오버헤드를 고려하여 결정될 수 있다. 디지털 인코딩 단계는, 복수개의 저차원 S-희소 서브 벡터들 내에서 0이 아닌 S개의 값들이 존재하는 위치를 디 지털 비트 시퀀스로 나타내는 위치 인코딩 단계를 더 포함할 수 있다. 파라미터 서버가 로컬 모델의 파라미터의 기울기를 복원하는 단계는, 양자화된 값 벡터에 선형 최소평균제곱오 류 추정 기법을 적용하여 정규화된 벡터의 추정치를 얻는 단계를 포함할 수 있다. 이때 변환된 선형 형태의 벡 터를 이용하여 기울기 복원 과정이 수행될 수 있다. 파라미터 서버가 로컬 모델의 파라미터의 기울기를 복원하는 단계는, 정규화된 벡터의 추정치에 대하여 정규화 과정에서 얻은 경험적인 평균 및 분산값을 이용하여 역정규화를 수행하는 단계를 더 포함할 수 있다. 본 발명의 일 실시예에 따른 분산형 인공지능의 학습 방법은 파라미터 서버 및 로컬 디바이스에 의한 분산형 인 공지능의 학습 방법이고, 파라미터 서버가 글로벌 모델의 파라미터를 압축하여 압축된 글로벌 모델 파라미터 정 보를 생성하는 단계; 파라미터 서버가 압축된 글로벌 모델 파라미터 정보를 로컬 디바이스로 전송하는 단계; 로 컬 디바이스가 파라미터 서버로부터 수신되는 압축된 글로벌 모델 파라미터 정보에 기반하여 글로벌 모델의 파 라미터를 복원하는 단계; 및 로컬 디바이스가 복원된 글로벌 모델의 파라미터를 로컬 모델로서 저장하는 단계를 포함한다. 압축된 글로벌 모델 파라미터 정보를 생성하는 단계는, 글로벌 모델의 파라미터를 형성하는 고차원 글로벌 원시 벡터를 복수개의 저차원 S-희소 서브 벡터들로 변환하는 블록 희소화 단계; 및 복수개의 저차원 S-희소 서브 벡 터들을 디지털 비트 시퀀스 형태로 변환하는 디지털 인코딩 단계를 포함할 수 있다. 본 발명의 일 실시예에 따른 분산형 인공지능 학습 장치는, 적어도 하나 이상의 명령을 저장하는 메모리 (memory); 및 적어도 하나 이상의 명령을 수행하는 프로세서(processor)를 포함한다. 프로세서는 적어도 하나 이상의 명령을 수행함으로써, 로컬 데이터셋에 기반하여 로컬 모델을 학습함으로써 로컬 모델의 파라미터를 업 데이트하고, 로컬 모델의 파라미터의 기울기(gradient)를 압축하여 압축된 기울기 정보를 생성하고, 로컬 디바 이스가 압축된 기울기 정보를 파라미터 서버로 전송하고, 파라미터 서버로부터 글로벌 모델의 파라미터를 수신 한다. 파라미터 서버로부터 수신되는 글로벌 모델의 파라미터는, 글로벌 모델의 파라미터가 압축된 정보일 수 있다. 프로세서는, 글로벌 모델의 파라미터에 기반하여 로컬 모델의 파라미터를 업데이트할 수 있고, 새로운 로컬 데 이터셋에 기반하여 로컬 모델을 학습함으로써 로컬 모델의 파라미터를 다시 업데이트할 수 있다. 프로세서는 압축된 기울기 정보를 생성함에 있어서, 블록 희소화 과정에 의하여 로컬 모델의 파라미터의 기울기 를 형성하는 고차원 로컬 원시 벡터를 복수개의 저차원 S-희소 서브 벡터들로 변환할 수 있고, 디지털 인코딩 과정에 의하여 복수개의 저차원 S-희소 서브 벡터들을 디지털 비트 시퀀스 형태로 변환할 수 있다."}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면 기존의 지능형 무선통신 기술들이 공통적으로 요구하는 학습 데이터 확보 및 학 습 데이터의 프라이버시 문제를 효과적으로 해결할 수 있어, 지능형 통신 기술들의 도입 가능성 및 적용 범위를 향상시킬 수 있다. 본 발명의 일 실시예에 따르면 분산형 인공지능 모델 학습 과정에서 발생하는 통신 부하를 줄일 수 있다. 본 발명의 일 실시예에 따르면 통신 오버헤드가 제한된 상황에서 다양한 지능형 무선통신 기술들의 전송용량 증 대 성능을 향상시킬 수 있다."}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명 의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의 해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된 다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유 사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. '및/또는' 이라는 용어는 복수의 관련된 기재된 항목들 의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 본 출원의 실시예들에서, \"A 및 B 중에서 적어도 하나\"는 \"A 또는 B 중에서 적어도 하나\" 또는 \"A 및 B 중 하나 이상의 조합들 중에서 적어도 하나\"를 의미할 수 있다. 또한, 본 출원의 실시예들에서, \"A 및 B 중에서 하나 이 상\"은 \"A 또는 B 중에서 하나 이상\" 또는 \"A 및 B 중 하나 이상의 조합들 중에서 하나 이상\"을 의미할 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 한편 본 출원일 전에 공지된 기술이라 하더라도 필요 시 본 출원 발명의 구성의 일부로서 포함될 수 있으며, 이 에 대해서는 본 발명의 취지를 흐리지 않는 범위 내에서 본 명세서에서 설명한다. 다만 본 출원 발명의 구성을 설명함에 있어, 본 출원일 전에 공지된 기술로서 당업자가 자명하게 이해할 수 있는 사항에 대한 자세한 설명은 본 발명의 취지를 흐릴 수 있으므로, 공지 기술에 대한 지나치게 자세한 사항의 설명은 생략한다. 예를 들어, 분산형 인공지능을 연합학습에 의하여 구현하는 기술, 스칼라 기반 양자화/역 양자화, 벡터 기반 양 자화/역 양자화, 인코딩된 결과를 인코딩 기법에 기반한 디코딩 기법에 의하여 디코딩하는 기술 등은 본 발명의 출원 전 공지 기술을 이용할 수 있으며, 이들 공지 기술들 중 적어도 일부는 본 발명을 실시하는 데에 필요한 요소 기술로서 적용될 수 있다. 그러나 본 발명의 취지는 이들 공지 기술에 대한 권리를 주장하고자 하는 것이 아니며 공지 기술의 내용은 본 발명의 취지에 벗어나지 않는 범위 내에서 본 발명의 일부로서 포함될 수 있다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 본 발명을 설 명함에 있어 전체적인 이해를 용이하게 하기 위하여 도면상의 동일한 구성요소에 대해서는 동일한 참조부호를사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 도 1은 본 발명의 일 실시예에 따른 무선 통신 기반 분산형 인공지능 시스템 및 그 동작을 도시하는 개념도이다. 도 2는 본 발명의 일 실시예에 따른 무선 통신 기반 분산형 인공지능 시스템의 학습 방법을 도시하는 동작 흐름 도이다. 본 발명의 일 실시예에 따른 모델의 학습 방법은, 메모리(memory)에 저장되는 적어도 하나 이상의 명령을 수행 하는 프로세서(processor)가 적어도 하나 이상의 명령을 수행함으로써 구현될 수 있다. 본 발명의 일 실시예에 따른 방법은 로컬 디바이스에 의한 분산형 인공지능을 대상으로 실행될 수 있다. 프로세서는 적어도 하나 이상의 명령을 수행함으로써, 로컬 디바이스가 로컬 데이터셋(D1, D2, D3)에 기반 하여 로컬 모델을 학습함으로써 로컬 모델의 파라미터를 업데이트하는 단계(S320); 로컬 디바이스 가 로컬 모델의 파라미터의 기울기(gradient)를 압축하여 압축된 기울기 정보를 생성하는 단계 (S320); 로컬 디바이스가 압축된 기울기 정보를 파라미터 서버로 전송하는 단계(S330); 파라미터 서 버가 로컬 디바이스로부터 수신되는 압축된 기울기 정보에 기반하여 로컬 모델의 파라미터의 기 울기를 복원하는 단계(S340); 및 파라미터 서버가 복원된 로컬 모델의 파라미터의 기울기에 기반하여 글로벌 모델의 파라미터를 업데이트하는 단계(S340)를 포함한다. 또한 프로세서는 적어도 하나 이상의 명령을 수행함으로써, 파라미터 서버가 글로벌 모델의 파라미터 를 압축하여 압축된 글로벌 모델 파라미터 정보를 생성하는 단계(S340); 파라미터 서버 가 압축된 글로벌 모델 파라미터 정보를 로컬 디바이스로 전송하는 단계(S350); 로컬 디바이스가 파라미터 서버로 부터 수신되는 압축된 글로벌 모델 파라미터 정보에 기반하여 글로벌 모델의 파라미터를 복원하여 로컬 모델 로 저장하는 단계(S320)를 포함할 수 있다. 압축된 파라미터를 생성하는 단계(S340) 또는 기울기 정보를 생성하는 단계(S320)는, 글로벌 모델의 파라 미터 또는 로컬 모델의 파라미터의 기울기를 형성하는 고차원 원시 (Source) 벡터를 복수개의 저차원 S-희 소 서브 벡터들로 변환하는 블록 희소화 단계; 및 복수개의 저차원 S-희소 서브 벡터들을 디지털 비트 시퀀스 형태로 변환하는 디지털 인코딩 단계를 포함할 수 있다. 이때 글로벌 모델의 파라미터를 형성하는 글로벌 원시 벡터 또는 로컬 모델의 파라미터의 기울기를 형성하는 로컬 기울기 원시 벡터가 저차원 S-희소 서브 벡터들로 변환될 수 있다. 블록 희소화 단계는, 고차원 원시 벡터를 L개의 서브 벡터들로 구분하는 단계(도 7의 S410); 및 L개의 서브 벡 터들 각각에 대해 가장 큰 S개의 원소를 선택하고 나머지 원소들을 제거하여 저차원 S-희소 서브 벡터들을 생성 하는 단계(도 7의 S420)를 포함할 수 있다. 블록 희소화 단계는, 디지털 인코딩되어 압축된 정보를 복원 (도 7의 S440)하여, 고차원 로컬 원시 벡터에 서 복원된 정보를 제외한(도 7의 S450) 나머지를 저장하는 단계; 및 저장된 나머지 원소들을 다음 차수의 고차 원 로컬 원시 벡터에 부가하는 단계(도 7의 S460)를 포함할 수 있다. 저차원 S-희소 서브 벡터들을 생성하는 단계(S420)는, L개의 서브 벡터들 각각에 대해 병렬적으로 수행될 수 있 다. 저차원 S-희소 서브 벡터들을 생성하는 단계(S420)는, 원시 벡터 복원 성능이 고려된 최적화 목적 함수를 최대 화하는 양자화 레벨 Q과 관련되는 최적 희소화 레벨 S에 기반하여 수행될 수 있다. 디지털 인코딩 단계는, 복수개의 저차원 S-희소 서브 벡터들을 복수개의 S차원 선형 변환된 벡터로 변환하는 단 계(도 8의 S510, S520); 및 복수개의 S차원 선형 변환된 벡터의 각 원소를 디지털 형태로 변환하는 스칼라 양자 화 단계(도 8의 S530)를 포함할 수 있다. 디지털 인코딩 단계의 복수개의 저차원 S-희소 서브 벡터들을 복수개의 S 차원 선형 변환된 벡터로 변환하는 단 계는, 복수개의 저차원 S-희소 서브 벡터에서 0이 아닌 원소를 선택하여 S 차원 벡터를 생성하는 단계; S 차원 벡터의 경험적 평균 및 분산 값을 도출하는 단계; 도출된 경험적 평균 및 분산 값을 이용하여 S 차원 벡터를 정 규화된 벡터로 변환하는 단계; 정규화된 벡터를 S 차원 직교 행렬 또는 이에 준하는 행렬을 이용하여 선형 변환 된 벡터로 변환하는 단계를 포함할 수 있다. S 차원 직교 행렬은 하다마드 행렬 또는 랜덤 기우시안 행렬일 수 있다. 스칼라 양자화 단계(S530)는, 원시 벡터 복원 성능이 고려된 최적화 목적 함수를 최대화하는 양자화 레벨 Q에 기반하여 수행될 수 있다. 양자화 레벨 Q는 허용된 통신 오버헤드를 고려하여 결정될 수 있다. 디지털 인코딩 단계는, 복수개의 저차원 S-희소 서브 벡터들 내에서 0이 아닌 S개의 값들이 존재하는 위치를 디 지털 비트 시퀀스로 나타내는 위치 인코딩 단계를 더 포함할 수 있다. 파라미터 서버가 로컬 모델의 기울기를 복원하는 단계(S340) 또는 로컬 디바이스가 글로벌 모델 의 파라미터를 복원하는 단계(S320)는, 양자화된 기울기 및/또는 파라미터 값 벡터를 선형 최소평균제곱오 류 추정 기법을 적용하여 정규화된 벡터의 추정치를 얻는 단계; 정규화된 벡터의 추정치를 정규화 과정에서 얻 은 경험적인 평균 및 분산값을 이용하여 역정규화를 수행하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 따른 분산형 인공지능 학습 장치는, 적어도 하나 이상의 명령을 저장하는 메모리 (memory); 및 적어도 하나 이상의 명령을 수행하는 프로세서(processor)를 포함한다. 프로세서는 적어도 하나 이상의 명령을 수행함으로써, 로컬 데이터셋(D1, D2, D3)에 기반하여 로컬 모델을 학습함으로써 로컬 모델 의 파라미터를 업데이트하고, 로컬 모델의 파라미터의 기울기(gradient)를 압축하여 압축된 기울기 정보를 생성하고, 로컬 디바이스가 압축된 기울기 정보를 파라미터 서버로 전송하고, 파라미터 서버 로부터 글로벌 모델의 파라미터를 수신한다. 본 발명의 일 실시예에 따른 분산형 인공지능 학습 장치 는 로컬 디바이스일 수 있다. 파라미터 서버로부터 수신되는 글로벌 모델의 파라미터는, 글로벌 모델의 파라미터가 압축된 정 보일 수 있다. 프로세서는, 글로벌 모델의 파라미터에 기반하여 로컬 모델의 파라미터를 업데이트할 수 있고, 새로 운 로컬 데이터셋(D1, D2, D3)에 기반하여 로컬 모델을 학습함으로써 로컬 모델의 파라미터를 다시 업데이트할 수 있다(S320을 다시 수행). 프로세서는 압축된 기울기 정보를 생성함에 있어서, 블록 희소화 과정에 의하여 로컬 모델의 파라미터의 기울기를 형성하는 고차원 로컬 원시 벡터를 복수개의 저차원 S-희소 서브 벡터들로 변환할 수 있고, 디지털 인 코딩 과정에 의하여 복수개의 저차원 S-희소 서브 벡터들을 디지털 비트 시퀀스 형태로 변환할 수 있다. 프로세서는 블록 희소화 과정을 실행함에 있어서, 고차원 로컬 원시 벡터를 L개의 서브 벡터들로 구분할 수 있 고(S410), L개의 서브 벡터들 각각에 대해 가장 큰 S개의 원소를 선택하고 나머지 원소들을 제거하여 저차원 S- 희소 서브 벡터들을 생성할 수 있다(S420). 프로세서는, 블록 희소화 과정을 실행함에 있어서, 디지털 인코딩 단계를 거친 압축된 기울기 정보를 복원하고, 고차원 로컬 원시 벡터에서 복원된 기울기 정보를 뺀 나머지 정보를 저장하고, 저장된 나머지 원소들을 다음 차 수의 상기 고차원 로컬 원시 벡터에 부가할 수 있다. 프로세서는, 원시 벡터 복원 성능이 고려된 최적화 목적 함수를 최대화하는 양자화 레벨 Q과 관련되는 최적 희 소화 레벨 S에 기반하여 저차원 S-희소 서브 벡터들을 생성할 수 있다. 프로세서는 디지털 인코딩 과정을 실행함에 있어서, 복수개의 저차원 S-희소 서브 벡터들을 복수개의 S차원 선 형 변환 벡터로 변환할 수 있고, 스칼라 양자화 과정에 의하여 복수개의 S차원 선형 변환 벡터의 각 원소를 디 지털 형태로 변환할 수 있다. 본 발명의 일 실시예에 따른 분산형 인공지능 시스템은 로컬 데이터셋(D1, D2, D3)과 로컬 모델을 저장하 는 복수개의 로컬 디바이스; 및 글로벌 모델을 저장하는 파라미터 서버를 포함한다. 본 발명의 일 실시예에 따른 분산형 인공지능 시스템에서는 로컬 디바이스가 로컬 데이터셋(D1, D2, D3)에 기반하여 로컬 모델을 학습함으로써 로컬 모델의 파라미터를 업데이트하고, 로컬 디바이스가 로 컬 모델의 파라미터의 기울기(gradient)를 압축하여 압축된 기울기 정보를 생성하고, 로컬 디바이스 가 압축된 기울기 정보를 파라미터 서버로 전송하고, 파라미터 서버가 로컬 디바이스로부터 수 신되는 압축된 기울기 정보에 기반하여 로컬 모델의 파라미터의 기울기를 복원하고, 파라미터 서버가 복원된 로컬 모델의 파라미터의 기울기에 기반하여 글로벌 모델의 파라미터를 업데이트한다. 로컬 디바이스는 파라미터 서버로부터 글로벌 모델의 파라미터를 수신할 수 있고, 글로벌 모델 의 파라미터에 기반하여 로컬 모델의 파라미터를 업데이트할 수 있고, 새로운 로컬 데이터셋(D1, D2,D3)에 기반하여 로컬 모델을 학습함으로써 로컬 모델의 파라미터를 다시 업데이트할 수 있다. 로컬 디바이스는 압축된 기울기 정보를 생성함에 있어서, 블록 희소화 과정에 의하여 로컬 모델의 파 라미터의 기울기를 형성하는 고차원 로컬 원시 벡터를 복수개의 저차원 S-희소 서브 벡터들로 변환할 수 있고, 디지털 인코딩 과정에 의하여 복수개의 저차원 S-희소 서브 벡터들을 디지털 비트 시퀀스 형태로 변환할 수 있 다. 파라미터 서버는 로컬 모델의 파라미터의 기울기를 복원함에 있어서, 양자화된 값 벡터를 선형 형태 로 변환할 수 있다. 이때 변환된 선형 형태의 벡터를 이용하여 기울기 복원 과정이 수행될 수 있다. 본 발명의 일 실시예에 따른 분산형 인공지능의 학습 장치 및 방법은, 각 로컬 디바이스에서 로컬 데이터 셋을 활용한 학습 이후 원격의 서버로 기울기 정보를 효율적으로 전달할 수 있는 수단을 제안한다. 본 발명에서 제안하는 파라미터 및 기울기 압축, 전송 및 복원 방법은 전체 네트워크 크기 대비 매우 적은 용량 을 통해서도 파라미터 및 기울기 정보의 오차가 매우 작은 수준으로 원격의 네트워크 장치로 전달할 수 있다. 도 1 및 도 2의 실시예에서는 파라미터 서버가 도시되었으나, 파라미터 서버는 하나의 개체에 의해서 만 구현되는 데에 국한되지 않고, 클라우드 형태의 서버 등을 통하여 구현될 수도 있다. 본 발명의 실시예를 구현하는 데에 참조할 수 있는 관련 기술로서 연합학습(federated learning)을 들 수 있다. 다양한 인공지능 기술들이 통신의 전송 용량 및 속도를 증대시키기 위해 적용되고 있다. 분산형 인공지능 기술 은 인공지능 모델에 대한 훈련을 무선 기기들과의 협력에 기반하여 수행할 때 활용할 수 있는 핵심 기반 기술을 의미할 수 있다. 로컬 디바이스가 무선 통신 기기이고, 프라이버시(privacy) 정보가 담겨있는 로컬 데이터를 활용하는 경우, 기기의 프라이버시를 보존하기 위해 분산형 인공지능이 활용될 수 있다. 로컬 디바이스인 무선 통신 기기만 접속할 수 있는 다량의 로컬 데이터를 활용하는 경우 로컬 데이터 전송 을 위해 필요한 오버헤드를 피하기 위해 분산형 인공지능이 활용될 수 있다. 분산형 인공지능은 인공지능 모델 을 학습하는데 있어 로컬 디바이스의 프라이버시 그리고 통신 오버헤드 관점에서 상당한 이점을 제공할 수 있다. 도 1 및 도 2에 도시된 본 발명의 일 실시예에 따른 분산형 인공지능은 서버에 존재하는 글로벌 모델 (global model)을 로컬 디바이스들이 가지고 있는 로컬 데이터셋(local dataset)에 대한 직접적인 전송 없이 훈련할 수 있다. 서버는 로컬 데이터셋을 직접 이용하는 대신 각 로컬 디바이스인 무선 기기가 로컬 데이터셋으로 훈 련한 로컬 모델을 대신 전송받을 수 있다(S330). 로컬 디바이스는 로컬 데이터셋을 이용하여(S310) 로컬 모델을 학습/훈련할 수 있다(S320). 이때의 학습/훈련 과정(S320)에 의하여 로컬 모델의 파라미 터가 업데이트될 수 있다. 서버는 다수의 무선 기기들로부터 전송받은 로컬 모델들에 기반하여 글로벌 모델을 업데이트할 수 있다(S340). 서버는 업데이트된 글로벌 모델을 다시 로컬 디바이스인 무선 기기들에게 전송할 수 있다 (S350). 각 무선 기기는 업데이트된 모델을 자신의 로컬 데이터셋으로 훈련한 뒤(S320을 다시 수행), 이에 기반하여 얻 어진 로컬 모델을 다시 서버에게 전송할 수 있다(S330을 다시 수행). 서버의 글로벌 모델이 충분히 훈련될 때까지 위 과정이 반복될 수 있다. 이러한 훈련 과정을 통해 얻 을 수 있는 가장 큰 장점으로는 훈련 과정 동안 무선 기기가 가지고 있는 로컬 데이터를 서버가 직접적으 로 받을 필요가 없으므로 훈련에 참여하는 로컬 디바이스들의 프라이버시를 지킬 수 있다는 점을 들 수 있 다. 또 다른 장점으로는 로컬 디바이스인 무선 기기만 접속이 가능한 다양한 정보에 대해 서버에 직 접적인 업로드 과정 없이도 간접적으로 해당 정보에 기반한 글로벌 모델의 최적화를 수행할 수 있다는 점 을 들 수 있다. 분산형 인공지능에서 활용되는 대표적인 전략은 무선기기와 서버가 모델의 기울기(gradient) 벡터 정보를 주고받는 것이다. 많은 인공지능 어플리케이션에서 모델의 업데이트 시 발생하는 기울기 정보에 기반하여 최적화를 수행하는 기울기 기반 최적화 알고리즘이 사용되며, 이 과정에서 필요한 핵심 정보가 바로 모델의 기울기 정보이기 때문이다. 분산형 인공지능에서 서버가 가지고 있는 모델을 파라미터 벡터 로 표현할 때, 서버는 이 파 라미터 벡터를 하기 수학식 1의 손실 함수를 최소화하는 방향으로 훈련시킬 수 있다. [수학식 1]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "위 식에서 K는 무선 기기들의 수를, 는 k번째 기기의 로컬 데이터셋을, 는 k번째 기기의 로컬 손실 함수로써 하기 수학식 2와 같이 정의될 수 있다. [수학식 2]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이때 f(w; u)는 개별 데이터 u를 이용하여 계산한 파라미터 w에 대한 손실함수를 나타낸다. 만약 서버가 기울기 기반 최적화 알고리즘을 사용할 경우, t번째 반복에서 필요한 정보는 현재 파라미터 벡터에 대한 기울기 벡터로서 하기 수학식 3과 같이 정의될 수 있다. [수학식 3]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "위 식에서 는 t번째 반복까지 얻어진 파라미터 벡터를 나타낸다. 위와 같은 정의들에 따라, 기울기 전송을 기반으로 한 분산형 인공지능은 다음의 과정을 포함할 수 있다. t번째 반복에서 각 무선 기기는 자신의 로컬 데이터셋에 기반하여 하기 수학식 4의 기울기 벡터를 계산할 수 있다. [수학식 4]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "위 식에서 는 t번째 반복에서 k번째 기기가 기울기 계산에 활용한 로컬 데이터셋을 나타내며, 이 데이터셋 은 에 대한 부분 집합이다. 각 무선기기는 기울기 벡터를 계산한 뒤, 이 벡터에 대한 정보를 서버로 전 송할 수 있다. 다음으로, t번째 반복에서 서버는 무선 기기들이 전송한 로컬 기울기 벡터들에 대한 정보를 취합한 뒤 하기 수학식 5를 이용하여 글로벌 기울기 벡터를 결정할 수 있다. [수학식 5]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "서버는 글로벌 기울기 벡터를 계산한 뒤, 글로벌 기울기 벡터에 기반하여 글로벌 모델을 업데이트하 여 t+1번째 파라미터 벡터를 결정한다. 기울기 정보를 주고받는 대신 로컬 모델의 업데이트 정보를 주고받 는 전략도 활용할 수 있으며, 이 전략 또한 기본적으로 기울기 정보 전송 전략과 동등한 과정으로 나타낼 수 있다. 무선 통신 기반 분산형 인공지능 기술의 실현에 있어 가장 핵심적인 과제는 각 무선 기기에서 로컬 기울기 벡터 를 전송할 때 필요한 통신 오버헤드를 줄이는 것이다. 기울기 벡터 전송을 위해 필요한 통신 오버헤드의 경우 파라미터 개수에 따라 결정된다. 무선 통신 시스템에서 고려될 수 있는 인공지능 어플리케이션들에서 글로벌 모 델의 크기는 수천개 혹은 수만개 이상의 파라미터로 이루어질 수 있으며, 이 경우, 기울기 벡터 전송을 위 해 상당한 통신 오버헤드가 야기된다. 스칼라 양자화 기반 기울기 벡터 압축 도 3은 본 발명의 일 실시예에서 사용되는 스칼라 양자화의 예시로서 SignSGD(Sign Stochastic Gradient Descent) 기법의 pseudo-code를 도시하는 개념도이다. 도 3의 기법에서는 기울기 벡터에서 각 원소가 차지하고 있는 32-비트를 이보다 작은 n비트로 압축하는 n-비트 스칼라 양자화기를 사용한다. 스칼라 양자화는 32-비트의 실수 값의 원소들의 분포를 분석하여 가짓수의 n-비 트 심볼로 압축시킨다. 이 경우 양자화 비트인 n이 작아질수록 통신 오버헤드가 선형적으로 줄어들게 된다. 서 버는 각 기기의 양자화된 기울기 벡터를 받은 후 공유하고 있는 양자화기를 통해 다시 실수 값으로 변환하 여 글로벌 모델을 학습시킨다. 스칼라 양자화 기법은 기울기 벡터의 길이에 따라 선형적으로 증가하는 복 잡성을 가지며 기기와 서버가 양자화기만을 공유하고 있으면 된다는 장점을 가지고 있다. 그러나 32-bit의 실수 값을 n-비트로 압축시키는 만큼의 양자화 오류가 발생한다는 단점이 있다. 스칼라 양자화 기법을 사용한 예시로 SignSGD를 들 수 있다. 도 3은 SignSGD의 알고리즘을 나타낸다. 알고리즘을 통해 확인할 수 있듯이, SignSGD는 각 기기에서 기울기 벡터를 받은 후 각 원소의 부호가 +이면 1, -이면 -1로 인코딩을 진행한다. 즉 1-비트 양자화기라고 생각할 수 있다. 서버는 각 기기에서 받은 기울기 벡터를 모두 합친 후 다시 부호가 +이면 1, -이면 -1로 변환시킨다. 벡터 양자화 기반 기울기 벡터 압축 도 4는 본 발명의 일 실시예에서 사용되는 벡터 양자화 기반 기울기 벡터 압축 기법의 동작을 도시하는 개념도 이다. 도 4의 기법에서는 고차원의 기울기 벡터를 벡터의 크기와 저차원 벡터들로 분할하고, 각각을 스칼라 양자화기 와 벡터 양자화기를 이용해 압축한다. 벡터 양자화기를 이용해 인코딩된 저차원 벡터들의 인덱스(index) 값들은 기기에서 서버로 전송되고, 서버에서는 수신한 인덱스 값을 복호화하여 양자화된 저차원 벡터를 생성 한다. 그리고 생성된 저차원 벡터들은 크기 조정 및 연결되는 과정을 거쳐 양자화된 고차원 기울기 벡터가 된다. 이후 서버는 각 기기의 양자화된 고차원 기울기 벡터를 평균하고, 이를 이용하여 신경망/글로벌 모 델을 학습시킨다. 벡터 양자화는 스칼라 양자화와 비교해 양자화 오류가 적다는 장점이 있다. 그러나 이러 한 이득은 벡터 길이에 따라 기하급수적으로 증가하는 복잡성이 수반된다. 또한 벡터 양자화를 활용할 때는 기 기와 서버가 미리 코드북(codebook)을 공유하고 있어야 하는 제약이 있을 수 있다. 희소화 기반 기울기 벡터 압축 도 5는 본 발명의 일 실시예에서 사용되는 희소화 기법의 pseudo-code를 도시하는 개념도이다. 도 5의 기법에서는 기울기 벡터의 원소들 중에서 절댓값이 큰 S개의 원소들만을 전송하는 기법이다. 기울기 벡 터 원소들 중 절댓값이 큰 원소들은 인공지능 모델 학습에 있어서 중요한 값으로 해석되므로 이러한 원소만을 보내더라도 학습 성능의 큰 손실을 방지할 수 있다. 이때 절댓값이 작은 원소들을 버리지 않고 다음번 통신 라 운드에 송신하지 않았던 원소들을 더한 후에 다시 희소화를 시행한다. 도 5의 희소화 기법은 디지털 인코딩과 압축 센싱 기법으로 나뉜다. 디지털 인코딩을 기반으로 희소화하는 기법은 먼저 기울기 벡터를 희소화하여 희소 벡터를 만든 후 0이 아닌 원 소값들의 위치 정보를 송신하는 기법이다. 즉 희소화를 진행하게 되면 매 통신 라운드마다 절댓값이 큰 S개의 원소들만 남게 되며 나머지 원소들은 0의 값으로 설정된다. 이때 0이 아닌 원소들의 위치를 송신하여 통신 오버헤드를 줄인다. 특히 디지털 인코딩 기반 희소화 기법을 사용한 기법의 예시로 D-DSGD 기법을 들 수 있다. 도 6은 본 발명의 일 실시예에서 사용되는 디지털 인코딩 기법의 예시로서 D-DSGD 기법의 동작을 도시하는 개념 도이다. 도 6을 참조하면, 기울기 벡터의 길이가 N일 때 기기의 통신 라운드마다 양수 값 중 크기가 큰 기울기 벡터의 S 개의 원소들만으로 희소 벡터를 생성하며 동시에 같은 방식으로 음수 값 중 절댓값의 크기가 큰 원소들을 뽑은 희소 벡터를 생성한다. 이때 두 벡터는 각각 절댓값의 크기가 0이 아닌 S개의 원소들이 남으며 양수 희소 벡터 원소들의 평균값과 음수 희소 벡터 원소들의 평균값의 절댓값을 비교한다. 이때 양수 희소 벡터의 원소들의 평 균값이 더 큰 경우 32 비트의 실수 값과 함께 부호 정보 1 비트를 담은 33 비트의 정보와 함께 양수 희소 벡터 의 0이 아닌 원소들의 위치를 송신한다. 음수 희소 벡터 원소들의 평균값이 큰 경우에는 반대로 음수 희소 벡터 의 평균값 정보 33 비트와 원소들의 위치를 송신한다. 그 후 기기에서는 송신하지 않은 음수 희소 벡터 혹은 양 수 희소 벡터를 다음 통신 라운드에 더한 후 다시 희소화하는 작업을 반복한다. 본 발명을 통해 제안된 희소화/양자화 기반 기울기 압축을 이용한 송/수신 기술은 분산형 인공지능의 통신 오버 헤드 문제를 효과적으로 해결할 수 있다. 종래에 제안되었던 다양한 기울기 벡터 압축 기술들은 통신 오버헤드 경감에 한계가 있거나 서버에서 정확한 기울기 복원을 보장할 수 없다는 문제점을 가지고 있다. 종래 기술들의 한계를 뛰어넘기 위해, 본 발명에서 제안하는 희소화/양자화 기반 기울기 압축을 이용한 송신 기 술은 통신 오버헤드 요구조건에 유연하게 대처하며 기울기 복원의 정확도에 따라 최적의 파라미터 결정이 가능 한 압축 기법을 포함한다. 제안된 수신 기술은 서버가 무선 기기로부터 전달받은 압축 정보에서부터 원래 의 로컬 기울기 벡터를 정확하게 복원할 수 있는 압축 복원 기술을 포함한다. 본 발명에서 제안하는 기울기 압축 기술 로컬 기울기의 손실 압축은 통신 라운드 당 메시지 크기를 줄이는 실용적인 솔루션이며, 압축은 희소화 또는 정 량화를 통해 수행할 수 있다. 압축을 통한 통신 효율성 향상의 상당한 진전에도 불구하고, 종래 연구에서는 이 기종 로컬 데이터 분포, 장치별 다양한 통신 링크 신뢰성 및 정량화 효과를 공동으로 수용하여 로컬 기울기의 집계를 고려하지 않았다. 대부분의 종래 연구는 주로 별도의 통신 및 학습 시스템의 설계 접근 방식에 초점을 맞추고 있으므로, 로컬 기울기를 디코딩하고 이를 독립적으로 집계하였다. 무선 통합(Over the air aggregation)은 무선 매체의 중첩 특성을 활용하여 통신 및 학습 시스템을 공동으로 설 계하는 새로운 패러다임이다. 이 접근 방식은 무선 및 학습 시스템을 공동으로 설계하는 데 새로운 기회를 열어 주지만, 업 링크 전송을 위해 모바일 장치에서 채널 상태 정보를 사용할 수 있는 시분할 이중 무선 시스템으로 제한된다. 도 7은 본 발명의 일 실시예에서 사용되는 기울기 압축 기술을 도시하는 개념도이다. 도 7을 참조하면, 제안된 기울기 압축 기술은 블록 희소화(S410, S420)와 디지털 인코딩의 두 가지 과정으 로 이루어진다. 두 가지 과정 중 블록 희소화 과정(S410, S420)에 대한 설명은 다음과 같다. 블록 희소화 과정 (S410, S420)의 목적은 고차원의 로컬 기울기 벡터를 L개의 저차원 S-희소 서브-벡터(sub-vector)들로 변환하는 것이다. 이를 위해 각 무선 기기는 로컬 기울기 벡터를 L개의 서브-벡터로 구분하고(S410), 각각의 서브-벡터에 대해 가장 큰 S개의 원소만을 선택하고 나머지 원소들을 제거하여 S-희소 서브-벡터를 생성한다(S420). 본 발명의 일 실시예에 따른 블록 희소화 과정에는, 희소화 과정에서 발생할 수 있는 정보 손실을 방지하기 위 해 디지털 인코딩되어 압축된 정보를 복원 (S440)하여, 로컬 기울기 벡터에서 이를 제외한(S450) 나머지를 사전에 버퍼에 저장하고, 다음번 기울기 벡터에 부가하는 과정(S460)이 포함될 수 있다. 위와 유사한 희소 벡터 생성 과정이 종래 연구를 통해서도 제안된 바 있으나, 본 발명에서 제안하는 블록 희소화 과정은 종래 기술 대 비 두 가지의 차별점을 가지고 있다. 첫째, 본 발명에서는 L개의 차원 분할을 적용하여 전체 과정을 병렬 형태 로 수행하게 할 뿐만 아니라, 이어지는 디지털 인코딩 과정에서 발생할 수 있는 오류에 따른 손실을 상당히 방 지할 수 있다. 둘째, 본 발명에서는 기울기 복원 성능을 고려한 최적화 과정을 통해 복원 성능을 최대로 할 수 있는 최적의 S값을 결정한다. 최적의 S값을 결정하는 과정은 후술할 기울기 압축 최적화 기술에 의하여 구현될 수 있다. 도 8은 본 발명의 일 실시예에서 사용되는 디지털 인코딩 과정을 도시하는 개념도이다. 도 8을 참조하면, 디지털 인코딩 과정에서는 앞선 도 7의 블록 희소화 과정(S420)을 통해 얻어진 L개의 S- 희소 서브-벡터들을 디지털 비트 시퀀스 형태로 나타내기 위한 변환이 이루어질 수 있다. 제안된 디지털 인코딩 과정은 S개 원소들의 위치를 나타내는 위치 인코딩과 S개 원소값들을 표현하는 값 인코딩을 별도로 수행한 다. 도 8에서 는 번째 S-희소 서브-벡터인 에서 0이 아닌 S개의 값들만을 모아 새롭게 정의한 S 차원 의 벡터이다. 도 8을 통해 확인할 수 있듯이, 제안된 값 인코딩 과정은 총 3단계로 이루어진다. 1단계(S510): 본 발명의 일 실시예에 따른 디지털 인코딩 과정에서는, 각 벡터 에 대하여 경험적인 평균과 분산을 하기 수학식 6을 이용하여 계산할 수 있다. [수학식 6]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "본 발명의 일 실시예에 따른 디지털 인코딩 과정에서는, 평균이 0이고 분산이 1인 정규화된 벡터 를 하기 수학식 7을 이용하여 생성할 수 있다. [수학식 7]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "2단계(S520): 본 발명의 일 실시예에 따른 디지털 인코딩 과정에서는, S 차원 직교 행렬 에 대한 선형 곱을 통해 정규화된 벡터 를 하기 수학식 8과 같이 변환함으로써 선형 변환 벡터 를 생성할 수 있다. [수학식 8]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "상기 수학식 8에서 S 차원 직교 행렬 를 결정하기 위해 하다마드(Hadamard) 행렬, 랜덤 가우시안(Gaussian) 행렬 등 다양한 직교 행렬 혹은 이에 준하는 행렬들을 활용할 수 있다. 3단계(S530): 본 발명의 일 실시예에 따른 디지털 인코딩 과정에서는, 스칼라 양자화기를 사용하여 선형 변환 벡터 의 각 원소를 디지털 형태로 변환할 수 있다. 이때 양자화된 벡터는 하기 수학식 9와 같이 표현 할 수 있다. [수학식 9]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "값 인코딩 과정에서 사용된 스칼라 양자화기가 Q개의 양자화 레벨을 가지고 있을 경우, 의 각 원소는"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "의 비트로 표현할 수 있다. 이에 따라 본 발명에서 제안된 값 인코딩 과정을 적용하면, 각 S-희소 서브-벡터 를 개의 비트로 변환할 수 있다. 위치 인코딩은 각 서브-벡터의 전체 원소 개수인 N 중에서 0이 아닌 S개의 값들이 존재하는 위치를 디지털 비트 시퀀스로 나타냄으로써 수행될 수 있다. 위치 인코 딩으로는, 이때 다음에 소개된 3가지 인코딩 기법들이 고려될 수 있다.조합 기반 인코딩: 전체 N개 원소 중 S개의 원소를 고르는 모든 가능한 조합을 고려한 뒤, 현재 서브-벡터가 매 칭되는 조합을 선택하여 해당 인덱스를 보내는 방법이며, 이때 필요한 비트 오버헤드는 다음의 수학식 10과 같 다. [수학식 10]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "Golomb 인코딩: 도 9는 본 발명의 일 실시예에서 사용되는 Golomb 인코딩 알고리즘의 pseudo-code를 도시하는 개념도이다. 도 9를 참조하여 수행되는 Golomb 인코딩에서 요구되는 비트 오버헤드는 다음의 수학식 11과 같다. [수학식 11]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "Huffman 인코딩: 도 10은 본 발명의 일 실시예에서 사용되는 Huffman 인코딩 알고리즘의 pseudo-code를 도시하 는 개념도이다. 본 발명의 일 실시예에 따른 분산형 인공지능 시스템에서 기울기 압축을 위하여 조합 기반 위치 인코딩을 사용 할 경우, 로컬 기울기 벡터 전송을 위해 필요한 비트 오버헤드는 다음의 수학식 12와 같이 얻어질 수 있다. [수학식 12]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "본 발명에서 제안하는 기울기 복원 기술 본 발명에서 제안하는 서버에서 수행되는 기울기 복원 기술은 다음과 같다. 무선 기기들이 앞서 설명한 기 울기 압축 과정을 사용할 경우, 각 S-희소 서브-벡터에 대해 S개의 기울기 원소들의 위치 정보는 손실 없는 인 코딩 과정을 거쳤으므로, 서버가 완벽하게 위치 정보를 복원할 수 있다고 가정할 수 있다. 따라서, 서버 에서 정확한 기울기 복원이 요구되는 부분은 각 희소 서브-벡터에서 S개의 기울기 원소들의 값에 대한 정 보라고 할 수 있다. 이러한 기울기 원소들의 값은 양자화된 벡터 의 형태로 서버에서 관찰되므로, 양자 화된 벡터로부터 S개의 기울기 값 벡터인 를 복원해야 한다. 이를 위해 본 발명에서 제안하는 기울기 복원 기술에서는 잘 알려진 Bussgang 이론을 활용한다. Bussgang 이론에 따르면 비선형적인 양자화 과정을 선형형태 로 변환할 수 있다. Bussgang 이론에 따르면 양자화기의 입력 벡터인 이 서로 독립적인 원소들을 가지고 각 원소의 평균이 0이며 분산이 1인 가우시안 벡터인 경우, 양자화된 벡터가 다음의 수학식 13과 같이 표현됨이 증 명될 수 있다. [수학식 13]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "위 식에서 과 의 상관관계는 0이며, 상수 는 다음의 수학식 14와 같이 계산된다. [수학식 14]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "위 식에서 와 는 무선 기기에서 사용한 양자화기의 i번째 양자화 값과 한계점(threshold)을 각각 나타낸 다. 또한, 의 공분산 행렬은 다음의 수학식 15와 같이 계산된다. [수학식 15]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "상기 수학식 15에서 는 정규확률변수의 누적분포함수를 나타낸다. 는 의 공분산 행렬이고, Is는 S차원의 단위행렬 (S개의 주 대각선 성분은 1이며, 나머지 성분은 0인 대각행렬) 이다. 실제로 본 발명에서 제안된 기울기 압축 기법에서 랜덤 가우시안 행렬을 통해 원래 기울기 벡터를 선형 변환할 경우, 는 서로 독립적인 원소들을 가지고 각 원소의 평균이 0이며 분산이 1인 가우시안 벡터로 모델링될 수 있다. 따라서, 앞서 설명한 Bussgang 이론을 통해 양자화된 벡터를 선형 형태로 변환하는 것이 가능하다. 제안된 기울기 복원 기술에서는 양자화된 벡터가 선형 형태로 표현이 가능하다는 점에 착안하여, 선형최소평균 제곱오류 추정 기법을 적용한다. 이 추정 기법을 구체화하기 위해 선형 수신 신호가 다음의 수학식 16과 같이 얻어졌다고 가정하자. [수학식 16]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "상기 수학식 16에서 q는 임의의 양자화된 수신 신호 벡터이고, U는 임의의 직교 행렬이고, v는 임의의 정규화된 벡터이며, d는 임의의 벡터이다. 상기 수학식 16의 선형 수신 신호로부터 벡터 v를 선형최소평균제곱오류 기법으로 추정할 경우, 벡터 v의 추정 치 는 다음의 수학식 17과 같이 얻어질 수 있다. [수학식 17]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 19, "content": "Rvq는 v및 q 벡터의 교차 공분산 행렬, Rq-1은 q벡터의 공분산 행렬의 역행렬이다. 이때 추정 오류는 다음의 수학식 18과 같이 계산된다. [수학식 18] Tr 연산자는 대각합 (대각 성분의 합) 이고, Rv는 v벡터의 공분산 행렬이고, Rq는 q 벡터의 공분산 행렬이고 Rvq는 v및 q 벡터의 교차 공분산 행렬이고, Rqv는 q 및 v 벡터의 교차 공분산 행렬이다. 위 추정치 결정 및 오류 계산을 위해 필요한 공분산 행렬들은 와 의 상관도가 0인 경우, 다음의 수학식 19와 같이 계산된다. [수학식 19]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 20, "content": "만약 와 를 만족하는 경우, 선형최소평균제곱오류 기법의 추정치와 추정 오류는 다음의 수학식 20과 같이 간단한 형태로 표현이 가능하다. [수학식 20]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 21, "content": "위 결과에 기반하여, 제안하는 기울기 복원 기술에서는 양자화된 벡터 에 대해서 Bussgang 이론을 적용하여 선형 형태의 표현식을 얻은 뒤 선형최소평균제곱오류 추정 기법을 적용하여 정규화된 벡터 에 대한 추정치를 다음의 수학식 21과 같이 결정할 수 있다. [수학식 21]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 22, "content": "최종적으로, 기울기 압축의 정규화 단계에서 사용된 경험적인 평균과 분산값을 별도로 전달받는다는 가정하에서, 평균과 분산값을 이용해 기울기 값 벡터인 을 다음의 수학식 22와 같이 추정한다. [수학식 22]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 23, "content": "는 별도로 전달받은 기울기 값 벡터의 경험적인 표준편차이고, 는 별도로 전달받은 기울기 값 벡터의 경험적인 평균이다. 이때 발생하는 추정 오류는 다음의 수학식 23과 같이 계산될 수 있다. [수학식 23]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 24, "content": "본 발명에서 제안하는 기울기 압축 최적화 기술 본 발명에서 제안하는 기울기 압축 기술에서 활용하는 양자화 레벨 Q와 희소화 레벨 S에 대한 최적화를 통해 기 울기 복원 기술의 성능을 최대화할 수 있다. 만약 k번째 무선 기기에 대하여 의 통신 오버헤드만 허용된 경우, 서버의 기울기 복원 오류를 최소화하는 파라미터 Q와 S에 대한 최적화 문제는 다음의 수학식 24와같이 정의될 수 있다. [수학식 24]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 25, "content": "이때 는 local gradient vector, 는 의 추정치이고, 상기 수학식 24는 양자화 레벨 Q, 및 희소 화 레벨 S에 대하여 local gradient vector의 추정 오류를 최소화하는 최적화 문제로 귀결될 수 있다. 위 수식에서 만약 조합 기반 위치 인코딩을 사용할 경우, 고정된 양자화 레벨 Q에 대해 전송할 수 있는 희소화 레벨 S의 최대 희소화 레벨 는 상기 수학식 12를 참고하여 다음의 수학식 25와 같이 결정될 수 있다. [수학식 25]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 26, "content": "위 결과를 원래의 최적화 문제(수학식 24)에 대입하면 최적화 문제를 다음의 수학식 26과 같이 다시 표현할 수 있다. [수학식 26]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 27, "content": "제안된 기울기 압축 기술에서 사용하는 블록 희소화 과정을 고려하여, 위 최적화 문제의 목적 함수를 다음의 수 학식 27과 같이 계산할 수 있다. [수학식 27]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 28, "content": "위 결과에 기반하여, 고정된 양자화 레벨 Q에 대한 최적의 희소화 레벨 S는 다음의 수학식 28의 최적화 문제로 귀결된다. [수학식 28]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 29, "content": "상기 수학식 28의 문제의 닫힌 형태의 해법을 구하는 것은 매우 어려운 문제이다. 이 문제를 해결하기 위해, 기 울기 벡터 중 가장 큰 S개의 원소들이 독립적인 랜덤 변수처럼 동작한다고 가정하여, 이들의 평균 값을 0으로가정한다. 이 가정 하에서, 희소화 레벨 S를 찾기 위한 최적화 문제는 다음의 수학식 29와 같이 보다 간단한 형 태로 해결될 수 있다. [수학식 29]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 30, "content": "위 결과를 활용하면, 최적의 양자화 레벨은 다음의 수학식 30을 이용하여 쉽게 계산될 수 있다. [수학식 30]"}
{"patent_id": "10-2022-0178470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 31, "content": "위 최적화 문제에서 최대값을 가지는 양자화 레벨과 그때의 최대 희소화 레벨이 제안된 기울기 압축 기술의 최 적의 파라미터로 결정될 수 있다. 본 발명에서 제안하는 상기 기울기의 압축, 전송 및 복원 방법은 파라미터 서버의 글로벌 모델 파라미터를 로컬 디바이스로 전송하기 위한 절차에도 그대로 적용될 수 있다. 도 11은 도 1 내지 도 10의 과정의 적어도 일부를 수행할 수 있는 일반화된 분산형 인공지능 시스템, 분산형 인 공지능의 학습을 위한 장치(로컬 디바이스/파라미터 서버), 또는 컴퓨팅 시스템의 예시를 도시하는 개념도이다. 본 발명의 일 실시예에 따른 분산형 인공지능 학습 방법의 적어도 일부의 과정은 도 11의 컴퓨팅 시스템 에 의하여 실행될 수 있다. 도 11을 참조하면, 본 발명의 일 실시예에 따른 컴퓨팅 시스템은, 프로세서, 메모리, 통신 인터페이스, 저장 장치, 입력 인터페이스, 출력 인터페이스 및 버스(bus)를 포 함하여 구성될 수 있다. 본 발명의 일 실시예에 따른 컴퓨팅 시스템은, 적어도 하나의 프로세서(processor) 및 상기 적어도 하나의 프로세서가 적어도 하나의 단계를 수행하도록 지시하는 명령어들(instructions)을 저장하는 메모 리(memory)를 포함할 수 있다. 본 발명의 일 실시예에 따른 방법의 적어도 일부의 단계는 상기 적어도 하 나의 프로세서가 상기 메모리로부터 명령어들을 로드하여 실행함으로써 수행될 수 있다. 프로세서는 중앙 처리 장치(central processing unit, CPU), 그래픽 처리 장치(graphics processing unit, GPU), 또는 본 발명의 실시예들에 따른 방법들이 수행되는 전용의 프로세서를 의미할 수 있다. 메모리 및 저장 장치 각각은 휘발성 저장 매체 및 비휘발성 저장 매체 중에서 적어도 하나로 구성 될 수 있다. 예를 들어, 메모리는 읽기 전용 메모리(read only memory, ROM) 및 랜덤 액세스 메모리 (random access memory, RAM) 중에서 적어도 하나로 구성될 수 있다. 또한, 컴퓨팅 시스템은, 무선 네트워크를 통해 통신을 수행하는 통신 인터페이스를 포함할 수 있다. 또한, 컴퓨팅 시스템은, 저장 장치, 입력 인터페이스, 출력 인터페이스 등을 더 포함 할 수 있다. 또한, 컴퓨팅 시스템에 포함된 각각의 구성 요소들은 버스(bus)에 의해 연결되어 서로 통신을 수행 할 수 있다. 본 발명의 컴퓨팅 시스템의 예를 들면, 통신 가능한 데스크탑 컴퓨터(desktop computer), 랩탑 컴퓨터 (laptop computer), 노트북(notebook), 스마트폰(smart phone), 태블릿 PC(tablet PC), 모바일폰(mobilephone), 스마트 워치(smart watch), 스마트 글래스(smart glass), e-book 리더기, PMP(portable multimedia player), 휴대용 게임기, 네비게이션(navigation) 장치, 디지털 카메라(digital camera), DMB(digital multimedia broadcasting) 재생기, 디지털 음성 녹음기(digital audio recorder), 디지털 음성 재생기(digital audio player), 디지털 동영상 녹화기(digital video recorder), 디지털 동영상 재생기(digital video player), PDA(Personal Digital Assistant) 등일 수 있다. 본 발명의 일 실시예에 따른 분산형 인공지능 시스템, 시스템을 구성하는 파라미터 서버, 로컬 디바이스 는, 적어도 하나 이상의 명령을 저장하는 메모리(memory); 및 적어도 하나 이상의 명령을 수행하는 프로세서(processor)를 포함한다. 프로세서는 적어도 하나 이상의 명령을 수행함으로써, 분산형 인 공지능 시스템/장치가 로컬 데이터셋에 기반하여 로컬 모델의 파라미터를 업데이트하고, 글로벌 모델(11 0)의 파라미터를 서버로부터 전송받아 로컬 모델의 파라미터를 업데이트하는 과정을 제어할 수 있다. 로컬 데이터셋은 저장 장치, 및/또는 메모리에 저장될 수 있다. 로컬 모델 또한 저장 장치, 및/또는 메모리에 저장될 수 있다. 구체적으로는, 로컬 데이터셋 또는 로컬 모델은 저장 장치에 저장된 상태에서 저장 장치 및/또는 메모리와 전자적으 로 통신할 수 있는 프로세서의 요구에 따라 메모리 또는 프로세서 내의 캐쉬에 로드될 수 있 다. 프로세서는 로컬 모델이 로컬 데이터셋을 학습하도록 로컬 모델을 제어할 수 있고(S310), 로컬 모델 내부의 파라미터가 학습에 의하여 업데이트되도록 제어할 수 있다(S320). 프로세서는 통신 인터페이스를 경유하여 서버로부터 전달받은(S350) 글로벌 모델의 파라 미터를 이용하여 로컬 모델 내부의 파라미터를 업데이트할 수 있다. 프로세서는 업데이트된 로컬 모델을 새롭게 발생되는 로컬 데이터셋에 기반하여 다시 학습하도록 제 어하고(S310), 로컬 모델의 내부의 파라미터가 재학습에 의하여 다시 업데이트되도록 제어할 수 있다 (S320). 본 발명의 실시예에 따른 신경망 모델들은, 프로세서와 전자적으로 통신할 수 있는 메모리 및/또는 스토리지에 저장되는 파라미터 셋에 의하여 정의되며, 프로세서와 협력하여 각 모델에 주어진 태스 크(task)를 수행할 수 있다. 본 발명의 실시예에 따른 방법의 동작은 컴퓨터로 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 프로그램 또 는 코드로서 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의해 읽힐 수 있는 정보가 저장되는 모든 종류의 기록장치를 포함한다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어 분산 방식으로 컴퓨터로 읽을 수 있는 프로그램 또는 코드가 저장되고 실행될 수 있 다. 또한, 컴퓨터가 읽을 수 있는 기록매체는 롬(rom), 램(ram), 플래시 메모리(flash memory) 등과 같이 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 프로그램 명령은 컴파일러 (compiler)에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터(interpreter) 등을 사용해서 컴퓨 터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 본 발명의 일부 측면들은 장치의 문맥에서 설명되었으나, 그것은 상응하는 방법에 따른 설명 또한 나타낼 수 있 고, 여기서 블록 또는 장치는 방법 단계 또는 방법 단계의 특징에 상응한다. 유사하게, 방법의 문맥에서 설명된 측면들은 또한 상응하는 블록 또는 아이템 또는 상응하는 장치의 특징으로 나타낼 수 있다. 방법 단계들의 몇몇 또는 전부는 예를 들어, 마이크로프로세서, 프로그램 가능한 컴퓨터 또는 전자 회로와 같은 하드웨어 장치에 의 해(또는 이용하여) 수행될 수 있다. 몇몇의 실시 예에서, 가장 중요한 방법 단계들의 적어도 하나 이상은 이와 같은 장치에 의해 수행될 수 있다. 실시예들에서, 프로그램 가능한 로직 장치(예를 들어, 필드 프로그래머블 게이트 어레이)가 여기서 설명된 방법 들의 기능의 일부 또는 전부를 수행하기 위해 사용될 수 있다. 실시예들에서, 필드 프로그래머블 게이트 어레이 (field-programmable gate array)는 여기서 설명된 방법들 중 하나를 수행하기 위한 마이크로프로세서 (microprocessor)와 함께 작동할 수 있다. 일반적으로, 방법들은 어떤 하드웨어 장치에 의해 수행되는 것이 바 람직하다. 이상 본 발명의 바람직한 실시 예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청 구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2022-0178470", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 무선 통신 기반 분산형 인공지능 시스템 및 그 동작을 도시하는 개념도이다. 도 2는 본 발명의 일 실시예에 따른 무선 통신 기반 분산형 인공지능 시스템의 학습 방법을 도시하는 동작 흐름 도이다. 도 3은 본 발명의 일 실시예에서 사용되는 스칼라 양자화의 예시로서 SignSGD 기법의 pseudo-code를 도시하는 개념도이다. 도 4는 본 발명의 일 실시예에서 사용되는 벡터 양자화 기반 기울기 벡터 압축 기법의 동작을 도시하는 개념도 이다. 도 5는 본 발명의 일 실시예에서 사용되는 희소화 기법의 pseudo-code를 도시하는 개념도이다. 도 6은 본 발명의 일 실시예에서 사용되는 디지털 인코딩 기법의 예시로서 D-DSGD 기법의 동작을 도시하는 개념 도이다.도 7은 본 발명의 일 실시예에서 사용되는 기울기 압축 기술을 도시하는 개념도이다. 도 8은 본 발명의 일 실시예에서 사용되는 디지털 인코딩 과정을 도시하는 개념도이다. 도 9는 본 발명의 일 실시예에서 사용되는 Golomb 인코딩 알고리즘의 pseudo-code를 도시하는 개념도이다. 도 10은 본 발명의 일 실시예에서 사용되는 Huffman 인코딩 알고리즘의 pseudo-code를 도시하는 개념도이다. 도 11은 도 1 내지 도 10의 과정의 적어도 일부를 수행할 수 있는 일반화된 분산형 인공지능 시스템, 분산형 인 공지능의 학습을 위한 장치 또는 컴퓨팅 시스템의 예시를 도시하는 개념도이다."}
