{"patent_id": "10-2019-0122061", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0043902", "출원번호": "10-2019-0122061", "발명의 명칭": "전자 장치 및 전자 장치의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "신민규"}}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,디스플레이;마이크;적어도 하나의 인스트럭션(instruction)을 저장하는 메모리; 및상기 적어도 하나의 인스트럭션을 실행하는 프로세서; 를 포함하고,상기 프로세서는, 적어도 하나의 오브젝트를 포함하는 이미지가 획득되면, 상기 이미지를 분석하여 상기 이미지에 포함된 적어도하나의 오브젝트를 식별하고,상기 마이크를 통해 사용자 음성이 수신되면, 상기 사용자 음성에 대한 음성 인식을 수행하여 상기 사용자 음성에 대응되는 텍스트 정보를 획득하며,상기 이미지에 포함된 적어도 하나의 오브젝트 중 상기 사용자 음성에 대응되는 오브젝트를 식별하고,상기 디스플레이 상의 영역 중 상기 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 상기 텍스트 정보를 포함하는 메모 UI (User Interface)를 표시하도록 상기 디스플레이를 제어하는 전자 장치."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 프로세서는, 상기 획득된 텍스트 정보에 상기 이미지에 포함된 적어도 하나의 오브젝트에 대한 정보가 포함되면, 상기 이미지에 포함된 적어도 하나의 오브젝트 중 상기 적어도 하나의 오브젝트에 대한 정보에 대응되는 오브젝트를 상기사용자 음성에 대응되는 오브젝트로 식별하는 전자 장치."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 프로세서는,상기 사용자 음성이 수신되는 동안 상기 디스플레이 상에 터치 인터렉션이 수신되면, 상기 디스플레이 상의 영역 중 상기 터치 인터렉션이 수신된 영역에 대응되는 오브젝트를 상기 사용자 음성에 대응되는 오브젝트로 식별하는 전자 장치."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 프로세서는,상기 디스플레이 상에 상기 이미지를 표시하도록 상기 디스플레이를 제어하고,상기 디스플레이 상의 영역 중 상기 터치 인터렉션이 수신된 영역 상에 표시된 오브젝트를 상기 사용자 음성에공개특허 10-2020-0043902-3-대응되는 오브젝트로 식별하는 전자 장치."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3 항에 있어서,상기 프로세서는,상기 마이크를 통해 수신된 사용자 음성 중 상기 터치 인터렉션이 상기 디스플레이 상에 유지되는 동안 수신된사용자 음성에 대한 음성 인식을 수행하여 상기 사용자 음성에 대응되는 텍스트 정보를 획득하는 전자 장치."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3 항에 있어서,상기 프로세서는,상기 디스플레이 상에 수신된 상기 사용자의 터치 인터렉션의 좌표 값을 바탕으로 상기 메모 UI의 크기 및 형태중 적어도 하나를 결정하고,상기 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 상기 결정된 크기 및 형태 중 적어도 하나를 바탕으로 상기 메모 UI를 표시하도록 상기 디스플레이를 제어하는 전자 장치."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역은 상기 사용자 음성에 대응되는 것으로식별된 오브젝트가 상기 디스플레이 상에 표시되는 영역 및 상기 사용자 음성에 대응되는 것으로 식별된 오브젝트가 상기 디스플레이 상에 표시되는 영역으로부터 기 설정된 거리 내의 영역을 포함하는 전자 장치."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서,상기 프로세서는,상기 사용자 음성에 대응되는 것으로 식별된 오브젝트가 2 개 이상이면, 상기 디스플레이 상에 상기 2 개 이상의 오브젝트에 대한 정보를 포함하는 선택 UI를 표시하도록 상기 디스플레이를 제어하고,상기 선택 UI를 통해 상기 2 개 이상의 오브젝트 중 하나의 오브젝트를 선택하는 사용자 입력이 수신되면, 상기선택된 하나의 오브젝트를 상기 사용자 음성에 대응되는 오브젝트로 식별하는 전자 장치."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항에 있어서,상기 프로세서는 상기 획득된 텍스트 정보에 대명사가 포함되면, 상기 대명사가 상기 사용자 음성에 대응되는 것으로 식별된 오브젝트의 명칭으로 변경된 텍스트 정보를 획득하고, 상기 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 상기 변경된 텍스트 정보를 포함하는 메모 UI를 표시하도록 상기 디스플레이를 제어하는 전자 장치.공개특허 10-2020-0043902-4-청구항 10 제1 항에 있어서,회로를 포함하는 통신부; 를 더 포함하고,상기 프로세서는,상기 획득된 텍스트 정보에 기 저장된 사용자의 명칭이 포함되면, 상기 사용자 명칭에 대응되는 사용자 단말에상기 획득된 텍스트 정보를 전송하도록 상기 통신부를 제어하는 전자 장치."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "디스플레이를 포함하는 전자 장치의 제어 방법에 있어서,적어도 하나의 오브젝트를 포함하는 이미지가 획득되면, 상기 이미지를 분석하여 상기 이미지에 포함된 적어도하나의 오브젝트를 식별하는 단계;사용자 음성이 수신되면, 상기 사용자 음성에 대한 음성 인식을 수행하여 상기 사용자 음성에 대응되는 텍스트정보를 획득하는 단계;상기 이미지에 포함된 적어도 하나의 오브젝트 중 상기 사용자 음성에 대응되는 오브젝트를 식별하는 단계; 및 상기 디스플레이 상의 영역 중 상기 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 상기 텍스트 정보를 포함하는 메모 UI (User Interface)를 표시하는 단계; 를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 사용자 음성에 대응되는 오브젝트를 식별하는 단계는, 상기 획득된 텍스트 정보에 상기 이미지에 포함된 적어도 하나의 오브젝트에 대한 정보가 포함되면, 상기 이미지에 포함된 적어도 하나의 오브젝트 중 상기 적어도 하나의 오브젝트에 대한 정보에 대응되는 오브젝트를 상기사용자 음성에 대응되는 오브젝트로 식별하는 단계를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11 항에 있어서,상기 사용자 음성에 대응되는 오브젝트를 식별하는 단계는, 상기 사용자 음성이 수신되는 동안 상기 디스플레이 상에 터치 인터렉션이 수신되면, 상기 디스플레이 상의 영역 중 상기 터치 인터렉션이 수신된 영역에 대응되는 오브젝트를 상기 사용자 음성에 대응되는 오브젝트로 식별하는 단계를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서,상기 사용자 음성에 대응되는 오브젝트를 식별하는 단계는, 상기 디스플레이 상에 상기 이미지를 표시하는 단계; 및상기 디스플레이 상의 영역 중 상기 터치 인터렉션이 수신된 영역 상에 표시된 오브젝트를 상기 사용자 음성에공개특허 10-2020-0043902-5-대응되는 오브젝트로 식별하는 단계; 를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13 항에 있어서,상기 사용자 음성에 대응되는 텍스트 정보를 획득하는 단계는,상기 수신된 사용자 음성 중 상기 터치 인터렉션이 상기 디스플레이 상에 유지되는 동안 수신된 사용자 음성에대한 음성 인식을 수행하여 상기 사용자 음성에 대응되는 텍스트 정보를 획득하는 단계; 를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13 항에 있어서,상기 메모 UI를 표시하는 단계는,상기 디스플레이 상에 수신된 상기 사용자의 터치 인터렉션의 좌표 값을 바탕으로 상기 메모 UI의 크기 및 형태중 적어도 하나를 결정하는 단계; 및상기 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 상기 결정된 크기 및 형태 중 적어도 하나를 바탕으로 상기 메모 UI를 표시하는 단계; 를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11 항에 있어서,상기 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역은 상기 사용자 음성에 대응되는 것으로식별된 오브젝트가 상기 디스플레이 상에 표시되는 영역 및 상기 사용자 음성에 대응되는 것으로 식별된 오브젝트가 상기 디스플레이 상에 표시되는 영역으로부터 기 설정된 거리 내의 영역을 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11 항에 있어서,상기 사용자 음성에 대응되는 오브젝트를 식별하는 단계는,상기 사용자 음성에 대응되는 것으로 식별된 오브젝트가 2 개 이상이면, 상기 디스플레이 상에 상기 2 개 이상의 오브젝트에 대한 정보를 포함하는 선택 UI를 표시하는 단계; 및 상기 선택 UI를 통해 상기 2 개 이상의 오브젝트 중 하나의 오브젝트를 선택하는 사용자 입력이 수신되면, 상기선택된 하나의 오브젝트를 상기 사용자 음성에 대응되는 오브젝트로 식별하는 단계; 를 포함하는 전자 장치의제어 방법."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11 항에 있어서,상기 메모 UI를 표시하는 단계는,상기 획득된 텍스트 정보에 대명사가 포함되면, 상기 대명사가 상기 사용자 음성에 대응되는 것으로 식별된 오브젝트의 명칭으로 변경된 텍스트 정보를 획득하는 단계; 및 공개특허 10-2020-0043902-6-상기 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 상기 변경된 텍스트 정보를 포함하는 메모 UI를 표시하는 단계; 를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0122061", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11 항에 있어서,상기 획득된 텍스트 정보에 기 저장된 사용자의 명칭이 포함되면, 상기 사용자 명칭에 대응되는 사용자 단말에상기 획득된 텍스트 정보를 전송하는 단계; 를 더 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0122061", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사용자 인터페이스를 통해 사용자 음성에 대응되는 텍스트 정보를 제공할 수 있는 전자 장치 및 이의 제어 방법 이 제공된다. 구체적으로, 본 개시에 따른 전자 장치는 적어도 하나의 오브젝트를 포함하는 이미지가 획득되면 이미지를 분석하여 이미지에 포함된 적어도 하나의 오브젝트를 식별하고, 사용자 음성이 수신되면 사용자 음성에 대한 음성 인식을 수행하여 사용자 음성에 대응되는 텍스트 정보를 획득하며, 이미지에 포함된 적어도 하나의 오 브젝트 중 사용자 음성에 대응되는 오브젝트를 식별하고, 디스플레이 상의 영역 중 사용자 음성에 대응되는 것으 로 식별된 오브젝트에 대응되는 영역 상에 텍스트 정보를 포함하는 메모 UI (User Interface)를 표시한다."}
{"patent_id": "10-2019-0122061", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 전자 장치의 제어 방법에 관한 것으로서, 구체적으로는 사용자 인터페이스를 통해 사용 자 음성에 대응되는 텍스트 정보를 제공할 수 있는 전자 장치 및 이의 제어 방법에 관한 것이다."}
{"patent_id": "10-2019-0122061", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "근래에 음성 인식을 이용한 기술이 다양한 종류의 전자 장치에 적용됨에 따라, 사용자는 텍스트 정보를 직접 입 력하지 않고, 사용자 음성을 발화함으로써 텍스트 정보를 생성하고 디스플레이 상에 생성된 텍스트 정보를 표시 할 수 있다. 그런데, 종래 기술에 따르면, 전자 장치의 사용자는 음성 인식을 이용하여 전자 장치에 텍스트 정보를 생성하고 사용자가 원하는 디스플레이 상의 영역에 표시하기 위해, 텍스트 정보를 생성하기 위한 어플리케이션을 실행하 는 단계, 음성 인식을 위한 트리거 입력을 입력하는 단계, 텍스트 정보에 대응되는 사용자 음성을 발화하는 단 계, 텍스트 정보가 표시될 위치를 지정하는 단계, 그리고 텍스트 정보가 표시될 크기 및 형태를 지정하는 단계 등과 같이, 여러 단계를 수행하는 불편함을 감수하여야 하는 문제가 있다. 따라서, 사용자 음성에 대응되는 텍스트 정보를 획득하고 획득된 텍스트 정보를 사용자가 원하는 디스플레이 상 의 영역에 표시하는 일련의 과정을 수행할 수 있는 직관적이고도 간편한 기술에 대한 필요성이 대두되고 있다."}
{"patent_id": "10-2019-0122061", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 바와 같은 필요성에 따라 안출된 것으로서, 본 개시의 목적은 직관적이고도 간편한 방법으로 사용자 인터페이스를 통해 사용자 음성에 대응되는 텍스트 정보를 제공할 수 있는 전자 장치 및 이의 제어 방법 에 관한 것이다."}
{"patent_id": "10-2019-0122061", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 바와 같은 본 개시의 목적을 달성하기 위한 일 실시 예에 따르면, 전자 장치는 디스플레이, 마이크, 적 어도 하나의 인스트럭션(instruction)을 저장하는 메모리 및 상기 적어도 하나의 인스트럭션을 실행하는 프로세 서를 포함하고, 상기 프로세서는 적어도 하나의 오브젝트를 포함하는 이미지가 획득되면, 상기 이미지를 분석하 여 상기 이미지에 포함된 적어도 하나의 오브젝트를 식별하고, 상기 마이크를 통해 사용자 음성이 수신되면, 상 기 사용자 음성에 대한 음성 인식을 수행하여 상기 사용자 음성에 대응되는 텍스트 정보를 획득하며, 상기 이미 지에 포함된 적어도 하나의 오브젝트 중 상기 사용자 음성에 대응되는 오브젝트를 식별하고, 상기 디스플레이 상의 영역 중 상기 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 상기 텍스트 정보를 포함하는 메모 UI (User Interface)를 표시하도록 상기 디스플레이를 제어한다. 상술한 바와 같은 본 개시의 목적을 달성하기 위한 일 실시 예에 따르면, 디스플레이를 포함하는 전자 장치의 제어 방법은 적어도 하나의 오브젝트를 포함하는 이미지가 획득되면, 상기 이미지를 분석하여 상기 이미지에 포 함된 적어도 하나의 오브젝트를 식별하는 단계, 사용자 음성이 수신되면, 상기 사용자 음성에 대한 음성 인식을 수행하여 상기 사용자 음성에 대응되는 텍스트 정보를 획득하는 단계, 상기 이미지에 포함된 적어도 하나의 오 브젝트 중 상기 사용자 음성에 대응되는 오브젝트를 식별하는 단계 및 상기 디스플레이 상의 영역 중 상기 사용 자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 상기 텍스트 정보를 포함하는 메모 UI (User Interface)를 표시하는 단계를 포함한다."}
{"patent_id": "10-2019-0122061", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참고하여 본 개시에 따른 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 도 1은 본 개시에 따른 전자 장치의 제어 과정을 간략하게 설명하기 위한 개념도이다. 도 1에 도시된 바와 같이, 전자 장치는 사용자 음성을 수신하고, 수신된 사용자 음성을 바탕으로 메모 UI(User Interface)를 표시할 수 있다. 여기서, 메모 UI란 획득된 텍스트 정보를 포함하는 사용자 인터페이스를 말한다. 메모 UI에 포함되는 다양한 정보에 대한 구체적인 설명은 후술한다. 한편, 본 개시의 다양한 실시 예에 따르면, 전자 장치의 디스플레이 상에 메모 UI가 표시되는 영역은 사용자 음성 및 사용자의 터치 인터렉션 중 적어도 하나를 바탕으로 결정될 수 있다. 이하에서는 전자 장치 의 디스플레이 상에 메모 UI가 표시되는 영역을 결정하는 과정에 대해 구체적으로 설명한다. 전자 장치는 적어도 하나의 오브젝트를 포함하는 이미지를 획득할 수 있다. 그리고, 적어도 하나의 오브 젝트를 포함하는 이미지가 획득되면, 전자 장치는 획득된 이미지를 분석하여 이미지에 포함된 적어도 하나 의 오브젝트를 식별할 수 있다. 예를 들어, 도 1에 도시된 바와 같이 전자 장치가 냉장고인 경우, 전자 장 치는 냉장고의 내부를 촬영하여 냉장고의 내부 이미지를 획득하고, 획득된 이미지에 포함된 적어도 하나의 오브젝트로서 \"양배추\", \"브로콜리\", \"포도\", \"주스\" 및 \"샌드위치\"와 같은 오브젝트를 식별할 수 있다. 다만, 예시로 든 바와 같이 본 개시에 따른 전자 장치가 냉장고에 국한되는 것이 아님은 물론이다. 한편, 전자 장치는 사용자 음성을 수신할 수 있다. 그리고, 사용자 음성이 수신되면, 전자 장치는 수 신된 사용자 음성에 대한 음성 인식을 수행하여 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다. 예를 들어, 도 1에 도시된 바와 같이, 사용자 음성이 수신되면, 전자 장치는 수신된 사용자 음성에 대한 음성 인식을 수행하여, 사용자 음성에 대응되는 텍스트 정보로서 \"오이 샌드위치 먹고 토미 간식도 챙겨줘\"라는 텍스 트 정보를 획득할 수 있다. 한편, 전자 장치는 이미지에 포함된 것으로 식별된 적어도 하나의 오브젝트 중 수신된 사용자 음성에 대응 되는 오브젝트를 식별할 수 있다. 구체적으로, 사용자 음성에 대응되는 오브젝트는 사용자 음성에 대응되는 텍 스트 정보 및 수신된 사용자의 터치 인터렉션 중 적어도 하나를 바탕으로 식별될 수 있다. 구체적으로, 획득된 텍스트 정보에 이미지에 포함된 적어도 하나의 오브젝트에 대한 정보가 포함되면, 전자 장 치는 획득된 텍스트 정보에 포함된 적어도 하나의 오브젝트에 대한 정보에 대응되는 오브젝트를 사용자 음 성에 대응되는 오브젝트로 식별할 수 있다. 예를 들어, 도 1에 도시된 바와 같이, 획득된 텍스트 정보에 \"오이 샌드위치\"라는 오브젝트에 대한 정보가 포함되면, 전자 장치는 \"오이 샌드위치\"를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 한편, 디스플레이 상에 사용자의 터치 인터렉션이 수신되면, 전자 장치는 디스플레이 상의 영역 중 사용자의 터치 인터렉션이 수신된 영역에 대응되는 오브젝트를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 예를 들어, 도 1에 도시된 바와 같이, 디스플레이 상의 영역 중 하나의 영역에 대한 사용자의 터 치 인터렉션이 수신되면, 전자 장치는 터치 인터렉션이 수신된 영역에 대응되는 오브젝트인 \"오이 샌 드위치\"를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 한편, 사용자의 터치 인터렉션은 사용자 음성이 수신되는 동안 수신될 수도 있으나, 본 개시가 이에 국한되는 것은 아니다. 즉, 본 개시에 따른 사용자의 터치 인터렉션은 사용자 음성이 수신되기 전 또는 사용자 음성이 수 신된 후에 수신될 수도 있다. 사용자의 터치 인터렉션이 수신되는 시점 및 그에 따른 다양한 실시 예에 대해서 는 특히 도 10b를 참조하여 후술한다. 상술한 바와 같이 사용자 음성에 대응되는 오브젝트가 식별되면, 전자 장치는 디스플레이 상의 영역 중 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 텍스트 정보를 포함하는 메모 UI를 표시할 수 있다. 상술한 바와 같은 실시 예에 따르면, 전자 장치는 사용자 음성에 대응되는 텍스트 정보를 포함하는 메모 UI를 표시함에 있어서, 디스플레이 상의 영역 중 사용자 음성을 발화하는 사용자의 직관적인 인식에 부합 하는 영역 상에 메모 UI를 표시할 수 있게 된다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 나타내는 흐름도이다. 도 2에 도시된 바와 같이, 전자 장치는 적어도 하나의 오브젝트를 포함하는 이미지를 획득할 수 있다 (S210). 구체적으로, 전자 장치는 전자 장치에 포함된 카메라를 통해 적어도 하나의 오브젝트를 포함 하는 이미지를 획득할 수 있으며, 외부 장치로부터 적어도 하나의 오브젝트를 포함하는 이미지를 수신하여 획득 할 수도 있다. 적어도 하나의 오브젝트를 포함하는 이미지가 획득되면, 전자 장치는 획득된이미지에 포함된 적어도 하나 의 오브젝트를 식별할 수 있다(S220). 구체적으로, 전자 장치는 획득된 이미지를 분석하여 획득된 이미지 에 포함된 적어도 하나의 오브젝트를 식별할 수 있다. 획득된 이미지를 분석하는 과정은 소위 객체 인식 모듈을 통해 수행될 수 있는바, 객체 인식 모듈을 통한 이미지 분석 내지는 객체 인식 과정에 대해서는 도 4를 참조하 여 상술한다. 한편, 이미지에 대한 객체 인식 결과 식별의 대상이 되는 오브젝트의 범위는 전자 장치의 종류 또는 사용자의 설정 등에 따라 상이하게 기 설정될 수 있다. 예를 들어, 전자 장치가 냉장고인 경우, 냉장고의 내부 이미 지에 대한 객체 인식 결과 식별의 대상이 되는 오브젝트의 범위는 냉장고 내부의 선반 또는 저장함과 같은 내부 구조물을 제외하고, 냉장고의 내부에 배치된 식품만을 포함하는 범위로 기 설정될 수 있다. 이 때, 오브젝트를 식별하기 위해 이용되는 인공 지능 모델은 식품류에 한정된 오브젝트를 식별하도록 학습된 인공 지능 모델로 구 현될 수 있다. 전자 장치는 사용자 음성을 수신할 수 있다(S230). 구체적으로, 전자 장치는 전자 장치에 포함 된 마이크를 통해 사용자 음성을 수신할 수 있으며, 외부 장치로부터 사용자 음성을 수신할 수도 있다. 여기서, 외부 장치는 스마트 폰과 같은 사용자 단말 또는 전자 장치를 제어하기 위한 원격 제어 장치를 포함할 수 있다. 즉, 사용자 단말 또는 원격 제어 장치는 사용자 단말 또는 원격 제어 장치에 포함된 마이크를 통해 사용 자 음성을 수신하고, 수신된 사용자 음성을 전자 장치로 전송할 수 있다. 그리고, 이에 따라 전자 장치 는 사용자 단말 또는 원격 제어 장치로부터 사용자 음성을 수신할 수 있다. 사용자 음성이 수신되면, 전자 장치는 수신된 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다 (S240). 구체적으로, 전자 장치는 수신된 사용자 음성에 대한 음성 인식을 수행하여 사용자 음성에 대응되 는 텍스트 정보를 획득할 수 있다. 특히, 수신된 사용자 음성에 대한 음성 인식은 소위 ASR(automatic speech recognition) 모듈을 통해 수행될 수 있는바, ASR 모듈을 통한 음성 인식 과정에 대해서는 도 5를 참조하여 상 술한다. 한편, 수신된 사용자 음성은 그 전체가 음성 인식의 대상이 될 수도 있지만, 수신된 사용자 음성 중 일부만이 음성 인식의 대상이 될 수도 있다. 여기서, 음성 인식의 대상이 되는 사용자 음성은 기 설정된 시작점과 종료점 을 바탕으로 특정될 수 있다. 구체적으로, 음성 인식의 대상이 되는 사용자 음성을 특정하기 위한 시작점은 음성 인식을 수행하기 위한 트리 거(trigger) 입력이 수신된 시점일 수 있다. 즉, 트리거 입력이 수신되면, 전자 장치는 트리거 입력이 수 신된 후에 수신된 사용자 음성에 대한 음성 인식을 수행하여, 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다. 특히, 본 개시의 일 실시 예에 따르면, 트리거 입력은 디스플레이 상에 수신된 사용자의 터치 인터렉션을 통해 수신될 수 있다. 다시 말해, 구체적으로, 디스플레이 상에 트리거 입력에 대응되는 것으로 기 설정된 사용자의 터치 인터렉션이 수신되면, 전자 장치는 사용자의 터치 인터렉션이 수신된 후에 수신된 사용자 음성에 대 한 음성 인식을 수행하여, 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다. 예를 들어, 디스플레이 상의 두 개 이상의 지점을 동시에 터치하는 멀티 터치 인터렉션이 음성 인식을 수행하기 위한 트리거 입력에 대응되 는 것으로 기 설정된 경우, 전자 장치는 멀티 터치 인터렉션이 수신된 후에 수신된 사용자 음성에 대한 음 성 인식을 수행하여, 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다. 또 다른 예로서, 디스플레이 상에수신된 터치 인터렉션이 3 초간 유지되는 것이 트리거 입력에 대응되는 터치 인터렉션으로 기 설정될 수도 있다. 한편, 트리거 입력은 기 설정된 트리거 워드(trigger word)를 포함하는 사용자 음성을 통해 수신될 수도 있다. 예를 들어, \"하이 ABC\"가 기 설정된 트리거 워드(trigger word)인 경우 \"하이 ABC, 맥주 사왔어, 퇴근하면 마셔\"\"라는 사용자 음성이 수신되면, \"하이 ABC\"가 수신된 후에 수신된 사용자 음성인 \"맥주 사왔어, 퇴근하면 마셔\"에 대한 음성 인식을 수행하여, 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다. 한편, 음성 인식의 대상이 되는 사용자 음성을 특정하기 위한 종료점은 다양한 종류의 종료점 검출 (End Point Detection: EPD) 기술을 통해 특정된 시점일 수 있다. 예를 들어, 음성 인식의 대상이 되는 사용자 음성은 사용 자 음성에 대한 엣지(edge) 정보 또는 주파수 특성 정보 등을 바탕으로 수신된 사용자 음성에서 음성 구간 및 비음성 구간을 구분함으로써 특정될 수 있다. 특히, 본 개시의 일 실시 예에 따르면, 음성 인식의 대상이 되는 사용자 음성을 특정하기 위한 종료점은 디스플 레이 상에 수신된 사용자의 터치 인터렉션이 종료되는 시점일 수 있다. 구체적으로, 디스플레이 상에 전술한 바 와 같은 사용자의 터치 인터렉션이 수신되고 수신된 터치 인터렉션이 디스플레이 상에 유지될 수 있다. 그리고, 전자 장치는 사용자의 터치 인터렉션이 디스플레이 상에 유지되는 동안 사용자 음성을 수신할 수 있다. 그 후, 디스플레이 상에 유지되고 있던 사용자의 터치 인터렉션이 종료되면, 전자 장치는 사용자의 터치 인터 렉션이 종료되는 시점까지 수신된 사용자 음성에 대한 음성 인식을 수행하여, 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다. 종래 기술과 같이 사용자 음성이 기 설정된 기간 동안 전자 장치에 수신되지 않는 것을 조건으로 음성 인 식의 종료점을 특정하면, 사용자가 발화 도중에 발화를 머뭇거림에 따라 사용자 음성이 기 설정된 기간 동안 전 자 장치에 수신되지 않게 되는 경우에도, 그 기 설정된 기간이 경과한 시점이 음성 인식의 종료점으로 특 정되어 사용자의 의도에 반하는 문제가 발생될 수 있다. 뿐만 아니라, 종래 기술에 따르면, 사용자가 음성 인식 을 원하는 사용자 음성을 발화한 후 기 설정된 기간이 경과하기 전에 음성 인식을 원하지 않는 사용자 음성을 추가로 발화한 경우, 사용자가 음성 인식을 원하는 음성뿐만 아니라 음성 인식을 원하지 않는 음성에 대해서까 지 음성 인식이 수행되어 사용자의 의도에 반하는 문제가 발생될 수 있다. 반면, 상술한 바와 같은 본 개시의 일 실시 예와 같이 사용자의 터치 인터렉션을 바탕으로 음성 인식의 종료점 을 특정하면, 사용자의 의도에 부합하는 시점을 음성 인식의 종료점으로 특정할 수 있게 되며, 그에 따라 음성 인식의 종료점 검출(End Point Detection, EPD)의 정확도가 향상될 수 있다. 이상에서 상술한 바와 같이, 본 개시의 일 실시 예에 따르면, 전자 장치는 수신된 사용자 음성 중 디스플 레이 상에 사용자의 터치 인터렉션이 유지되는 동안 수신된 사용자 음성에 대해 음성 인식을 수행하고, 그에 따 라 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다. 한편, 이상에서는 마이크가 활성화된 상태인 것을 전제로, 마이크를 통해 수신된 사용자 음성 전체 중에서 사용 자의 터치 인터렉션을 바탕으로 음성 인식의 대상을 특정하는 실시 예에 대해 설명한 바 있으나, 본 개시의 또 다른 실시 예에 따르면, 마이크가 활성화되지 않은 상태인 것을 전제로, 사용자의 터치 인터렉션을 바탕으로 마 이크가 활성화되는 시간을 제어하고, 활성화된 마이크를 통해 수신된 사용자 음성 전체에 대해 음성 인식을 수 행함으로써 음성 인식의 대상을 특정할 수도 있다. 이상에서 수신된 사용자 음성 중 음성 인식의 대상이 되는 사용자 음성을 특정하는 방법에 대해 상술하였는바, 이하에서는 편의상, 수신된 사용자 음성 중 음성 인식의 대상이 되는 사용자 음성을 단순히 '사용자 음성'이라 고 지칭한다. 전자 장치는 이미지에 포함된 적어도 하나의 오브젝트 중 수신된 사용자 음성에 대응되는 오브젝트를 식별 할 수 있다(S250). 여기서, 사용자 음성에 대응되는 오브젝트는 사용자 음성에 대응되는 텍스트 정보 및 수신된 사용자의 터치 인터렉션 중 적어도 하나를 바탕으로 식별될 수 있다. 구체적으로, 획득된 텍스트 정보에 이미지에 포함된 적어도 하나의 오브젝트에 대한 정보가 포함되면, 전자 장 치는 획득된 텍스트 정보에 포함된 적어도 하나의 오브젝트에 대한 정보에 대응되는 오브젝트를 사용자 음 성에 대응되는 오브젝트로 식별할 수 있다. 즉, 전술한 예와 같이, 사용자 음성에 대응되는 텍스트 정보에 \"맥 주\"라는 오브젝트에 대한 정보가 포함되면, 전자 장치는 \"맥주\"를 사용자 음성에 대응되는 오브젝트로 식 별할 수 있다.한편, 디스플레이 상에 사용자의 터치 인터렉션이 수신되면, 전자 장치는 디스플레이 상의 영역 중 사용자 의 터치 인터렉션이 수신된 영역에 대응되는 오브젝트를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 특히, 사용자의 터치 인터렉션은 사용자 음성이 수신되는 동안 수신될 수 있으며, 다만, 본 개시가 이에 국한되 는 것이 아니라는 점은 전술한 바와 같다. 구체적으로, 전자 장치는 디스플레이 상에 이미지를 표시하고, 디스플레이 상에 사용자의 터치 인터렉션을 수신할 수 있다. 그리고, 전자 장치는 디스플레이 상의 영역 중 사용자의 터치 인터렉션이 수신된 영역 상 에 표시된 오브젝트를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 전술한 바와 같은 예에서, 전자 장 치는 디스플레이 상에 \"맥주\", \"콜라\" 및 \"주스\"와 같은 오브젝트를 포함하는 이미지를 표시할 수 있다. 그리고, 전자 장치는 디스플레이 상의 영역 중 \"맥주\"가 표시된 영역 상에 사용자의 터치 인터렉션을 수신 할 수 있다. 이 경우, 전자 장치는 \"맥주\"를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 사용자 음성에 대응되는 오브젝트가 식별되면, 전자 장치는 디스플레이 상의 영역 중 사용자 음성에 대응 되는 것으로 식별된 오브젝트에 대응되는 영역 상에 텍스트 정보를 포함하는 메모 UI를 표시할 수 있다(S260). 즉, 전술한 바와 같은 예에서, 전자 장치는 디스플레이 상의 영역 중 \"맥주\"라는 오브젝트가 표시된 영역 상에 \"맥주 사왔어, 퇴근하면 마셔\"라는 텍스트 정보를 포함하는 메모 UI를 표시할 수 있다. 한편, 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역은 사용자 음성에 대응되는 것으로 식별 된 오브젝트가 디스플레이 상에 표시되는 영역 및 사용자 음성에 대응되는 것으로 식별된 오브젝트가 디스플레 이 상에 표시되는 영역으로부터 기 설정된 거리 내의 영역을 포함할 수 있다. 즉, 전술한 바와 같은 예에서, 전 자 장치는 \"맥주\"라는 오브젝트가 디스플레이 상에 표시되는 영역 및 \"맥주\"라는 오브젝트가 디스플레이 상에 표시되는 영역으로부터 기 설정된 거리 내의 영역을 포함할 수 있다. 한편, 사용자 음성에 대응되는 것으로 식별된 오브젝트가 2 개 이상이면, 전자 장치는 디스플레이 상에 2 개 이상의 오브젝트에 대한 정보를 포함하는 선택 UI를 표시할 수 있다. 여기서, 선택 UI는 2 개 이상의 오브젝 트 중 하나를 선택하는 사용자 입력을 수신하기 위한 사용자 인터페이스를 말한다. 그리고, 선택 UI를 통해 2 개 이상의 오브젝트 중 하나의 오브젝트를 선택하는 사용자 입력이 수신되면, 전자 장치는 선택된 하나의 오브젝트를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 선택 UI를 제공하는 것에 관련된 실시 예에 대 해서는 도 11a 및 도 11b를 참조하여 보다 구체적으로 설명한다. 한편, 이상에서는 사용자 음성에 대응된 텍스트 정보에 포함되는 적어도 하나의 오브젝트에 대한 정보가 이미지 에 포함된 적어도 하나의 오브젝트의 명칭에 대한 정보인 것을 전제로 설명하였으나, 본 개시의 일 실시 예에 따르면, 적어도 하나의 오브젝트에 대한 정보는 이미지에 포함된 적어도 하나의 오브젝트의 기한에 대한 정보 등과 같은 다양한 정보를 포함할 수도 있다. 또한, 사용자 음성에 대응되는 텍스트 정보는 이미지에 포함된 적 어도 하나의 오브젝트에 대한 정보뿐만 아니라, 대명사를 포함할 수 있으며, 사용자 명칭을 포함할 수도 있다. 사용자 음성에 대응되는 텍스트 정보에 포함된 다양한 정보에 관련된 실시 예에 대해서는 도 12, 도 13a 및 도 13b를 참조하여 구체적으로 설명한다. 상술한 바와 같은 본 개시의 다양한 실시 예에 따르면, 전자 장치는 디스플레이 상에 텍스트 정보를 포함 하는 메모 UI가 표시되는 영역을 지정하는 별도의 사용자 조작 없이, 사용자 음성에 대응되는 텍스트 정보만을 바탕으로 사용자가 원하는 영역 상에 메모 UI를 표시할 수 있게 된다. 또한, 전자 장치는 사용자의 터치 인터렉션을 바탕으로 음성 인식의 대상이 되는 사용자 음성을 특정함과 동시에 편의적이고도 직관적인 방식으로 메모 UI가 표시되는 영역을 결정하여 메모 UI를 표시할 수 있게 된다. 이에 따라, 전자 장치의 사용자는 직관적이고도 간편한 방법으로 사용자 인터페이스를 통해 사용자 음성에 대응되는 텍스트 정보를 생성하고, 사용자의 의도에 부합하는 디스플레이 상의 영역에 생성된 텍스트 정보를 표 시할 수 있게 된다. 도 3a는 본 개시에 따른 전자 장치의 구성을 간략하게 나타내는 블록도이고, 도 3b는 도 3a에 도시된 바와 같은 전자 장치의 하드웨어 구성과 본 개시에 따른 소프트웨어 모듈 사이의 결합 관계를 전제로 본 개시에 따른 실시 예를 설명하기 위한 도면이다. 도 3a 및 도 3b에 도시된 바와 같이, 본 개시에 따른 전자 장치는 디스플레이, 마이크, 메모리 및 프로세서를 포함한다. 디스플레이는 프로세서의 제어에 의하여 영상 데이터를 출력할 수 있다. 구체적으로, 디스플레이 는 프로세서의 제어에 의하여 메모리에 기 저장된 영상을 출력할 수 있다. 메모리에 저장 된 디스플레이는 LCD(Liquid Crystal Display Panel), OLED(Organic Light Emitting Diodes) 등으로 구현 될 수 있으며, 또한 디스플레이는 경우에 따라 플렉서블 디스플레이, 투명 디스플레이 등으로 구현되는 것 도 가능하다. 다만, 본 개시에 따른 디스플레이가 특정한 종류에 한정되는 것은 아니다. 특히, 본 개시에 따른 디스플레이는 프로세서의 제어에 의해 적어도 하나의 오브젝트를 포함하는 이 미지를 표시할 수 있으며, 메모 UI, 선택 UI 및 삭제 UI 등과 같은 사용자 인터페이스(User Interface)를 표시 할 수도 있다. 마이크는 전자 장치의 외부에서 발생된 사운드(sound) 또는 음성(voice) 수신할 수 있다. 구체적으로, 마이크는 전자 장치의 외부에서 발생된 사운드 또는 음성에 따른 음향 신호를 수신하고, 수신된 음향 신호를 전기적인 신호로 변환할 수 있다. 특히, 본 개시에 따른 마이크는 사용자의 발화에 의 해 발생된 사용자 음성을 수신할 수 있다. 메모리에는 전자 장치에 관한 적어도 하나의 명령이 저장될 수 있다. 그리고, 메모리에는 전자 장치를 구동시키기 위한 O/S(Operating System)가 저장될 수 있다. 또한, 메모리에는 본 개시의 다양 한 실시 예들에 따라 전자 장치가 동작하기 위한 각종 소프트웨어 프로그램이나 애플리케이션이 저장될 수 도 있다. 구체적으로, 메모리에는 전자 장치가 동작하기 위한 각종 소프트웨어 모듈이 저장될 수 있으며, 프로 세서는 메모리에 저장된 각종 소프트웨어 모듈을 실행하여 전자 장치의 동작을 제어할 수 있다. 즉, 메모리는 프로세서에 의해 액세스되며, 프로세서에 의한 데이터의 독취/기록/수정/삭제/갱 신 등이 수행될 수 있다. 한편, 본 개시에서 메모리라는 용어는 메모리, 프로세서 내 롬(미도시), 램(미도시) 또는 전자 장치에 장착되는 메모리 카드(미도시)(예를 들어, micro SD 카드, 메모리 스틱)를 포함하는 의미로 사용될 수 있으며, 플래시 메모리 (Flash Memory) 및 PROM(Programmable Read-Only Memory) 등과 같은 비휘발성 메모 리와 DRAM(Dynamic Random-Access Memory) 및 SRAM(Static RAM) 등과 같은 휘발성 메모리를 포함하는 의미로 사용될 수 있다. 특히, 도 3b에 도시된 바와 같이, 본 개시에 따른 메모리에는 Wake-up 모듈, ASR 모듈, NLU 모 듈, 객체 인식 모듈 및 메모 UI 처리 모듈 등과 같은 복수의 모듈이 저장될 수 있다. 여기서, 메모리에 복수의 모듈이 저장된다는 것은, 복수의 모듈을 실행하고 복수의 모듈의 기능을 수행하기 위해 필요한 모든 데이터가 메모리에 저장된다는 것을 의미한다. 한편, 메모리에는 메모 UI 관련 데이터 가 저장될 수도 있다. 한편, 프로세서는 메모리에 저장된 복수의 모듈에 엑세스하여 복수의 모듈을 통해 본 개시에 따른 다 양한 동작을 수행할 수 있는바, 이하에서는 복수의 모듈 각각의 기능에 대해 설명한다. Wake-up 모듈은 사용자 음성에 대한 음성 인식의 수행 여부를 결정하는 모듈을 말하며, WoV(Wake-on- Voice) 모듈로 지칭될 수도 있다. 구체적으로, 트리거 입력이 수신되면, Wake-up 모듈은 트리거 입력이 수 신된 후 마이크를 통해 수신되는 사용자 음성에 대해 음성 인식을 수행하는 것으로 결정할 수 있다. ASR(Automatic Speech Recognition) 모듈은 사용자 음성에 대한 음성 인식을 수행하여 수신된 사용자 음성에 대 응되는 텍스트 정보를 획득하는 모듈을 말한다. ASR 모듈은 AM(Acoustic Model), PM(Pronunciation Model) 및 LM(Language Model) 등을 포함할 수 있으며, AM, PM 및 LM 등과 같은 인공지능 모델을 통해 사용자 음성에 대응되는 텍스트를 획득할 수 있다. NLU 모듈(Natural Language Understanding)은 수신된 사용자 음성에 대한 자연어 이해를 수행하는 모듈로 서, Domain Classifier 및 NLU 엔진 등을 포함할 수 있다. Domain Classifier는 사용자 음성에 관련된 도메인 을 식별하는 모듈을 말하며, NLU 엔진은 자연어 이해를 수행하기 위한 데이터베이스를 이용하여 사용자 음성에 대응되는 텍스트 정보에 대한 자연어 이해를 수행하는 모듈을 말한다. 즉, NLU 모듈은 Domain Classifier 및 NLU 엔진 등을 통해 사용자 음성에 대응되는 텍스트 정보에 대한 문법적 분석(syntactic analyze) 및 의미적 분석(semantic analyze)을 수행하여, 사용자의 의도에 대한 정보를 획득할 수 있다. 객체 인식 모듈은 이미지 내의 경계를 추출하여 오브젝트의 존재 여부 및 오브젝트의 위치를 식별할 수 있 다. 그리고, 객체 인식 모듈은 2D 이미지 매칭, OCR(Optical Character Recognition) 그리고, 객체 인식 을 위한 인공지능 모델 등을 통해 이미지에 포함된 적어도 하나의 오브젝트를 식별할 수 있다. 메모 UI 처리 모듈은 본 개시에 따른 메모 UI에 관련된 전반적인 처리 과정을 수행하는 모듈을 말한다. 구 체적으로, 메모 UI 처리 모듈은 메모 UI를 생성하여 획득하고, 메모 UI를 메모리에 저장하며, 메모 UI에 대한 이미지 처리를 수행하고, 메모 UI를 표시하도록 디스플레이를 제어하는 동작 등을 비롯하여, 본 개시에 따른 메모 UI에 대한 처리를 관장할 수 있다. 특히, 메모 UI 처리 모듈은 메모리에 저장된 메 모 UI 관련 데이터를 바탕으로 본 개시에 따른 메모 UI에 관련된 전반적인 처리 과정을 수행할 수 있다. 메모 UI 관련 데이터는 본 개시에 따른 메모 UI에 관련된 각종의 데이터를 말한다. 즉, 본 개시를 설명함 에 있어서, 메모 UI란 메모 UI에 포함되는 텍스트 정보, 메모 UI에 표시되는 텍스트 정보의 크기, 폰트 및 색상 등에 대한 정보, 메모 UI에 표시되는 오브젝트에 대한 정보, 메모 UI에 표시되는 UI 아이템에 대한 정보 등 본 개시에 따른 메모 UI에 관련된 데이터를 총칭하는 의미로 사용된다. 한편, 이상에서는 프로세서가 메모리에 저장된 복수의 모듈을 로딩하고, 복수의 모듈을 통해 본 개시 에 따른 동작을 수행하는 과정에 대해 설명하였으나, 이는 본 개시에 따른 동작을 구현하기 위한 하드웨어와 소 프트웨어의 유기적인 결합에 대해 상세하게 설명하기 위한 것일 뿐, 본 개시가 도 2에 도시된 바와 같은 소프트 웨어 구조(software architecture)을 포함하는 경우에 국한되는 것은 아니다. 즉, 본 개시의 목적을 달성하기 위한 범위 내에서, 복수의 모듈의 종류와 그 명칭은 도 3b에 도시된 바와 상이하게 구현될 수도 있다. 그리고, 본 개시의 다양한 실시 예를 구현함에 있어서, 도 3b를 통해 설명한 바와 같은 복수의 모듈 중 적어도 일부는 사용되지 않을 수 있음은 물론이다. 한편, 도 3b에는 복수의 모듈들이 메모리에 저장되고, 프로세서가 메모리에 저장된 복수의 모듈 을 로딩하고, 복수의 모듈에 엑세스하여 복수의 모듈을 통해 본 개시에 따른 다양한 동작을 수행하는 것을 전제 로 복수의 모듈들이 메모리 내에 도시되어 있으나, 복수의 모듈 중 적어도 일부는 그 모듈의 기능을 수행 할 수 있는 전용 칩으로 구현되어 프로세서에 포함될 수도 있다. 프로세서는 전자 장치의 전반적인 동작을 제어한다. 구체적으로, 프로세서는 상술한 바와 같은 마이크, 디스플레이 및 메모리를 포함하는 전자 장치의 구성과 연결되며, 상술한 바와 같 은 메모리에 저장된 적어도 하나의 명령을 실행하여 전자 장치의 동작을 전반적으로 제어할 수 있다. 프로세서는 다양한 방식으로 구현될 수 있다. 예를 들어, 프로세서는 주문형 집적 회로(Application Specific Integrated Circuit, ASIC), 임베디드 프로세서, 마이크로 프로세서, 하드웨어 컨트롤 로직, 하드웨 어 유한 상태 기계(hardware Finite State Machine, FSM), 디지털 신호 프로세서(Digital Signal Processor, DSP) 중 적어도 하나로 구현될 수 있다. 한편, 본 개시에서 프로세서라는 용어는 CPU(Central Processing Unit), GPU(Graphic Processing Unit) 및 MPU(Main Processing Unit)등을 포함하는 의미로 사용될 수 있다. 특히, 본 개시에 따른 프로세서는 상술한 바와 같은 복수의 모듈, 즉 메모리에 저장된 복수의 모듈에 엑세스하여 복수의 모듈을 통해 본 개시에 따른 다양한 동작을 수행할 수 있다. 이하, 도 3b를 참조하여 본 개 시에 따른 프로세서의 제어 과정에 대해 구체적으로 설명한다. 프로세서는 적어도 하나의 오브젝트를 포함하는 이미지를 획득할 수 있다. 이미지가 획득되면, 프로세서 는 획득된 이미지를 객체 인식 모듈에 입력하여, 이미지에 포함된 적어도 하나의 오브젝트를 식별할 수 있다. 그리고, 프로세서는 획득된 이미지와 이미지에 포함된 적어도 하나의 오브젝트를 식별함으로써 획득된 적어도 하나의 오브젝트에 대한 정보를 메모리에 저장할 수 있으며, 저장된 이미지 및 오브젝트에 대한 정보를 바탕으로 후술하는 바와 같은 사용자 음성에 대응되는 오브젝트를 식별할 수도 있다. 여기서, 적어 도 하나의 오브젝트에 대한 정보는, 예를 들어 오브젝트의 명칭에 대한 정보 및 이미지 내의 오브젝트의 위치에 대응되는 좌표 값 등을 포함할 수 있다. 객체 인식 모듈을 통한 이미지 분석 내지는 객체 인식 과정에 대 해서는 도 4를 참조하여 구체적으로 설명한다. 프로세서는 음성 인식을 수행하기 위한 트리거(trigger) 입력을 수신할 수 있다. 여기서, 트리거 입력은 기 설정된 트리거 워드(trigger word)를 포함하는 사용자 음성의 형태로 마이크를 통해 수신될 수 있을 뿐 만 아니라, 전자 장치에 배치된 입력 버튼을 통해 수신하거나, 또는 전자 장치를 제어하기 위한 원격 제어 장치로부터 수신된 제어 신호를 통해 수신될 수도 있다. 트리거 입력이 수신되면, 프로세서는 Wake-up 모듈을 통해 음성 인식의 수행 여부를 결정할 수 있다. 구체적으로, 트리거 입력이 수신되면, 프로세서는 Wake-up 모듈에 트리거 입력을 입력하여, 음성 인식의 수행 여부를 결정할 수 있다. 그리고, 음성 인식을 수행하는 것으로 결정되면, 프로세서는 트리거 입 력이 수신된 후 마이크를 통해 수신되는 사용자 음성에 대해 음성 인식을 수행하는 것으로 결정할 수 있다. 다시 말해, 트리거 입력이 수신된 시점은 음성 인식의 대상이 되는 사용자 음성을 특정하기 위한 시작점 일 수 있다. 음성 인식의 대상이 되는 사용자 음성을 특정하기 위한 시작점과 종료점에 대해서는 도 2를 참조하 여 상술한 바, 중복 설명은 생략한다. 프로세서는 마이크를 통해 사용자 음성을 수신할 수 있다. 사용자 음성이 수신되면, 프로세서는 수신된 사용자 음성을 ASR 모듈에 입력하여, 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다. ASR 모듈을 통한 음성 인식 과정에 대해서는 도 5를 참조하여 구체적으로 설명한다. 프로세서는 디스플레이를 통해 사용자의 터치 인터렉션을 수신할 수 있다. 구체적으로, 본 개시에 따 른 디스플레이는 사용자의 터치 인터렉션을 감지하기 위한 터치 센서를 포함할 수 있으며, 프로세서 는 디스플레이에 포함된 터치 센서를 통해 디스플레이 상의 영역 중 일 영역에 대한 사용자의 터치 인터렉션을 수신할 수 있다. 터치 센서는 정전식, 감압식 및 압전식 등과 같은 다양한 유형의 센서로 구현될 수 있다. 또한, 디스플레이 는 사용자의 손가락 이외에도 스타일러스 펜과 같은 입력 수단을 이용한 터치 인터렉션도 감지할 수 있다. 그리고, 터치 인터렉션의 입력 수단이 내부에 코일을 포함하는 스타일러스 펜일 경우, 디스플레이는 스타 일러스 펜 내부의 코일에 의해 변화되는 자기장을 감지할 수 있는 자기장 감지 센서를 포함할 수도 있다. 이에 따라, 프로세서는 디스플레이를 통해 터치 인터렉션뿐만 아니라 근접 제스처, 즉, 호버링(hovering) 도 감지할 수 있게 된다. 한편, 이상에서는 디스플레이의 표시 기능과 사용자 터치 인터렉션의 감지 기능 이 동일한 구성에서 수행되는 것으로 설명하였지만, 서로 다른 구성에서 수행될 수도 있다. 프로세서는 이미지에 포함된 적어도 하나의 오브젝트 중 수신된 사용자 음성에 대응되는 오브젝트를 식별 할 수 있다. 여기서, 사용자 음성에 대응되는 오브젝트는 ASR 모듈을 통해 획득된 사용자 음성에 대응되는 텍스트 정보 및 디스플레이를 통해 수신된 사용자의 터치 인터렉션 중 적어도 하나를 바탕으로 식별될 수 있다. 구체적으로, 획득된 텍스트 정보에 이미지에 포함된 적어도 하나의 오브젝트에 대한 정보가 포함되면, 프로세서 는 획득된 텍스트 정보에 포함된 적어도 하나의 오브젝트에 대한 정보에 대응되는 오브젝트를 사용자 음성 에 대응되는 오브젝트로 식별할 수 있다. 한편, 디스플레이 상에 사용자의 터치 인터렉션이 수신되면, 프로세서는 디스플레이 상의 영역 중 사용자의 터치 인터렉션이 수신된 영역에 대응되는 오브젝트를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 특히, 사용자의 터치 인터렉션은 사용자 음성이 수신되는 동안 수신될 수 있으며, 다만, 본 개시가 이 에 국한되는 것이 아니라는 점은 전술한 바와 같다. 구체적으로, 프로세서는 디스플레이 상에 이미지를 표시하고, 디스플레이 상에 사용자의 터치 인터렉션을 수신할 수 있다. 그리고, 프로세서는 디스플레이 상의 영역 중 사용자의 터치 인터렉션이 수신된 영역 상에 표시된 오브젝트를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 프로세서는 텍스트 정보를 포함하는 메모 UI를 표시하도록 디스플레이를 제어할 수 있다. 구체적으로, 사용자 음성에 대응되는 오브젝트가 식별되면, 프로세서는 디스플레이 상의 영역 중 사 용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 텍스트 정보를 포함하는 메모 UI를 표시하 도록 디스플레이를 제어할 수 있다. 여기서, 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역은 사용자 음성에 대응되는 것으로 식별된 오브젝트가 디스플레이 상에 표시되는 영역 및 사용자 음성 에 대응되는 것으로 식별된 오브젝트가 디스플레이 상에 표시되는 영역으로부터 기 설정된 거리 내의 영역 을 포함할 수 있다. 한편, 사용자 음성에 대응되는 것으로 식별된 오브젝트가 2 개 이상이면, 프로세서는 디스플레이 상 에 2 개 이상의 오브젝트에 대한 정보를 포함하는 선택 UI를 표시할 수 있다. 여기서, 선택 UI는 2 개 이상의 오브젝트 중 하나를 선택하는 사용자 입력을 수신하기 위한 사용자 인터페이스를 말한다. 그리고, 선택 UI를 통 해 2 개 이상의 오브젝트 중 하나의 오브젝트를 선택하는 사용자 입력이 수신되면, 프로세서는 선택된 하 나의 오브젝트를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 선택 UI를 제공하는 것에 관련된 실시 예 에 대해서는 도 11a 및 도 11b를 참조하여 보다 구체적으로 설명한다. 한편, 이상에서는 사용자 음성에 대응되는 텍스트 정보에 포함되는 적어도 하나의 오브젝트에 대한 정보가 이미 지에 포함된 적어도 하나의 오브젝트의 명칭에 대한 정보인 것을 전제로 설명하였으나, 본 개시의 일 실시 예에 따르면, 적어도 하나의 오브젝트에 대한 정보는 이미지에 포함된 적어도 하나의 오브젝트의 기한에 대한 정보 등과 같은 다양한 정보를 포함할 수도 있다. 또한, 사용자 음성에 대응되는 텍스트 정보는 이미지에 포함된 적 어도 하나의 오브젝트에 대한 정보뿐만 아니라, 대명사, 사용자 명칭 및 사용자의 의도에 대한 정보 중 적어도 하나를 포함할 수도 있다. 사용자 음성에 대응되는 텍스트 정보에 포함된 다양한 정보에 관련된 실시 예에 대해 서는 도 12, 도 13a 및 도 13c를 참조하여 구체적으로 설명한다. 도 4는 본 개시에 따른 객체 인식 과정을 보다 상세하게 설명하기 위한 도면이다. 전술한 바와 같이, 전자 장치는 적어도 하나의 오브젝트를 포함하는 이미지를 획득할 수 있다. 그리고, 이 미지가 획득되면, 전자 장치는 획득된 이미지를 분석하여 이미지에 포함된 적어도 하나의 오브젝트를 식별 할 수 있다. 구체적으로, 전자 장치는 객체 인식 모듈을 통해 이미지에 포함된 적어도 하나의 오브젝트를 식별할 수 있다. 이하에서는 전자 장치가 객체 인식 모듈을 통해 이미지 분석 내지는 객체 인식을 수행하 는 다양한 방법에 대해 구체적으로 설명한다. 전자 장치는 획득된 이미지 내의 경계를 추출하여 오브젝트의 존재 여부 및 오브젝트의 위치를 식별할 수 있다. 그리고, 객체 인식 모듈은 2D 이미지 매칭, OCR(Optical Character Recognition) 그리고, 객체 인식을 위한 인공지능 모델 등을 통해 이미지에 포함된 적어도 하나의 오브젝트를 식별할 수 있다. 구체적으로, 전자 장치는 엣지 검출(Edge Detection), 코너 검출(Corner Detection), 히스토그램 특징 검 출, 영상 고주파 분석, 영상 분산(variance) 분석 등과 같은 다양한 방법을 이용하여, 획득된 이미지에 포함된 오브젝트의 특징을 추출할 수 있다. 그리고, 전자 장치는 추출된 특징을 바탕으로 획득된 이미지에 포함된 오브젝트가 오브젝트를 분류하기 위한 복수의 카테고리 각각에 대응될 확률을 획득하고, 그에 따라 이미지에 포 함된 적어도 하나의 오브젝트를 식별할 수 있다. 일 실시 예로, 2D 이미지 매칭을 통해 오브젝트를 분류하는 경우, 전자 장치는 획득된 이미지에서 각각의 오브젝트가 포함된 영역의 이미지를 획득하고, 이를 복수의 오브젝트의 종류 별로 기 저장된 이미지와 비교하여, 양 자의 유사도를 바탕으로 이미지에 포함된 적어도 하나의 오브젝트를 식별할 수 있다. 다른 실시 예로, 전자 장치가 냉장고이고 획득된 이미지가 냉장고 내부의 이미지인 경우, 전자 장치 는 OCR 기술을 이용하여 이미지에 포함된 식품의 라벨 등을 인식하여 이미지에 포함된 적어도 하나의 오브젝트 를 식별할 수 있다. 또 다른 실시 예로, 전자 장치는 학습된 인공지능 모델을 통해 객체 인식을 수행할 수 있다. 구체적으로, 전자 장치는 획득된 이미지를 학습된 인공지능 모델에 입력하여 이미지에 포함된 적어도 하나의 오브젝트 를 식별할 수 있다. 여기서, 인공지능 모델은 기계학습, 신경망, 유전자, 딥러닝 및 분류 알고리즘과 같은 인공 지능 알고리즘 중 적어도 하나를 이용하여 학습된 인공지능 모델일 수 있으며, 특히 CNN(Convolutional Neural Network) 및 RNN(Recurrent Neural Network) 중 적어도 하나의 인공 신경망을 포함할 수 있다. 다만, 본 개시 에 따른 인공 지능 모델의 종류 및 그에 포함되는 인공 신경망의 종류에 특별한 제한이 있는 것은 아니다. 예를 들어, 도 4에 도시된 바와 같이 전자 장치가 냉장고인 경우, 전자 장치는 냉장고의 내부를 촬영 하여 냉장고의 내부 이미지를 획득할 수 있다. 그리고, 전자 장치는 상술한 바와 같은 다양한 방법을 이용 하여 획득된 이미지에 대한 이미지 분석 내지는 객체 인식을 수행할 수 있다. 그리고, 객체 인식의 결과, 전자 장치는 이미지에 포함된 적어도 하나의 오브젝트로서, \"양배추\", \"포도\" 및 \"주스\" 등과 같은 오브젝트를 식별할 수 있다. 한편, 이미지에 대한 객체 인식 결과 식별의 대상이 되는 오브젝트의 범위는 전자 장치의 종류 또는 사용자의 설정 등에 따라 상이하게 기 설정될 수 있다. 예를 들어, 전자 장치가 냉장고인 경우, 냉장고의 내부 이미 지에 대한 객체 인식 결과 식별의 대상이 되는 오브젝트의 범위는 냉장고 내부의 선반 또는 저장함과 같은 내부 구조물을 제외하고, 냉장고의 내부에 배치된 식품만을 포함하는 범위로 기 설정될 수 있다. 이 때, 오브젝트를 식별하기 위해 이용되는 인공 지능 모델은 식품류에 한정된 오브젝트를 식별하도록 학습된 인공 지능 모델로 구 현될 수 있다. 한편, 이상에서 상술한 바와 같은 객체 인식 모듈은 전자 장치에 온-디바이스(on-device)로 포함될 수 있 을 뿐만 아니라 서버와 같은 외부 장치에 포함될 수 있으며, 전자 장치는 획득된 이미지를 서버로 전송하고, 서버에 포함된 객체 인식 모듈에 의해 이미지에 대한 객체 인식이 수행되면 서버로부터 객체 인식의 결과를 수신함으로써 이미지에 포함된 적어도 하나의 오브젝트를 식별할 수도 있다. 도 5는 본 개시에 따른 음성 인식 과정을 보다 상세하게 설명하기 위한 도면이다. 전술한 바와 같이, 전자 장치는 사용자 음성을 수신할 수 있다. 그리고, 사용자 음성이 수신되면, 전자 장 치는 수신된 사용자 음성에 대한 음성 인식을 수행하여 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다. 구체적으로, 전자 장치는 ASR(Automatic Speech Recognition) 모듈을 바탕으로 음성 인식을 수행하여 수 신된 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다. ASR 모듈은 특징 추출부와 디코더를 포함할 수 있 다. 특징 추출부는 오디오 신호로부터 특징 정보(특징 벡터)를 추출할 수 있다. 그리고 디코더는 AM(Acoustic Model), PM(Pronunciation Model) 및 LM(Language Model) 등을 바탕으로 추출된 특징 정보에 대응되는 음성 인 식 정보를 획득할 수 있다. 음성 인식 정보는 음향 모델을 기초로 획득된 특징 정보들에 대응하는 발음 정보, 음소 정보, 문자열 정보와, 언어 모델을 기초로 획득된 발음 정보들에 대응되는 텍스트 데이터를 포함할 수 있 다. 구체적으로, AM은 수신된 사용자 음성의 음향 특징을 추출하고 음소 시퀀스를 획득할 수 있다. PM은 발음 사전 (pronunciation dictionary, pronunciation lexicon)을 포함하며, 획득된 음소 시퀀스를 단어에 매핑하여 단어 시퀀스를 획득할 수 있다. 그리고, LM은 획득된 단어 시퀀스에 확률을 지정할 수 있다. 한편, ASR 모듈은 AM, PM 및 LM의 구성요소가 단일 신경망으로 결합된 종단간(end-to-end) 음성 인식 모델을 포함할 수도 있다. 예를 들어, 도 5에 도시된 바와 같이, 전자 장치는 사용자의 발화에 의해 발생된 사용자 음성을 수신 하고, 상술한 바와 같은 ASR 모듈을 이용하여 사용자 음성에 대응되는 텍스트 정보로서, \"딸기 씻어 놨으니 챙 겨 먹어\"라는 텍스트 정보를 획득할 수 있다. 한편, 이상에서 상술한 바와 같은 ASR 모듈은 전자 장치에 온-디바이스(on-device)로 포함될 수 있을 뿐만 아니라 서버와 같은 외부 장치에 포함될 수 있다. 그리고, 전자 장치는 수신된 사용자 음성을 서버로 전송 하고, 서버에 포함된 ASR 모듈에 의해 사용자 음성에 대한 음성 인식이 수행되면 서버로부터 음성 인식의 결과 를 수신함으로써 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다. 도 6은 전자 장치가 사용자 음성에 대응되는 텍스트 정보를 바탕으로 사용자 음성에 대응되는 오브젝트를 식별하는 실시 예를 설명하기 위한 도면이다. 전술한 바와 같이, 전자 장치는 이미지를 획득하고, 획득된 이미지에 포함된 적어도 하나의 오브젝트를 식 별할 수 있다. 그리고, 전자 장치는 사용자 음성을 수신하고, 수신된 사용자 음성에 대응되는 텍스트 정보 를 획득할 수 있다. 또한, 전자 장치는 이미지에 포함된 적어도 하나의 오브젝트 중 사용자 음성에 대응되는 오브젝트를 식별 할 수 있다. 구체적으로, 사용자 음성에 대응되는 오브젝트는 사용자 음성에 대응되는 텍스트 정보 및 수신된 사용자의 터치 인터렉션 중 적어도 하나를 바탕으로 식별될 수 있다. 이하에서는 도 6을 참조하여, 사용자 음성 에 대응되는 텍스트 정보를 바탕으로 사용자 음성에 대응되는 오브젝트를 식별하는 과정에 대해 설명한다. 사용자 음성에 대응되는 텍스트 정보에 적어도 하나의 오브젝트에 대한 정보가 포함되면, 전자 장치는 텍 스트 정보에 포함된 적어도 하나의 오브젝트에 대한 정보를 바탕으로 이미지에 포함된 적어도 하나의 오브젝트 중 사용자 음성에 대응되는 오브젝트를 식별할 수 있다. 구체적으로, 사용자 음성에 대응되는 텍스트 정보에 적 어도 하나의 오브젝트에 대한 정보가 포함되면, 전자 장치는 이미지에 포함된 적어도 하나의 오브젝트 중 적어도 하나의 오브젝트에 대한 정보에 대응되는 오브젝트를 사용자 음성에 대응되는 오브젝트로 식별할 수 있 다. 예를 들어, 도 6에 도시된 바와 같이, 전자 장치는 이미지를 획득하고, 획득된 이미지를 분석하여 이미지 에 포함된 적어도 하나의 오브젝트를 식별할 수 있다. 구체적으로 전자 장치가 냉장고인 경우, 전자 장치 는 도 6에 도시된 바와 같은 전자 장치의 내부 이미지를 획득하고, 획득된 이미지에 포함된 적어도 하나의 오브젝트로서 \"오이 샌드위치\"를 식별할 수 있다. 그리고, 전자 장치는 사용자 음성을 수신하고, 수신된 사용자 음성에 대한 음성 인식을 수행하여 사용자 음성에 대응되는 텍스트 정보로서 \"오이 샌드위치 먹고 토미 간식도 챙겨줘\"라는 텍스트 정보를 획득할 수 있다. 사용자 음성에 대응되는 텍스트 정보에 이미지에 포함된 적어도 하나의 오브젝트인 \"오이 샌드위치\" 에 대한 정보가 포함되면, 전자 장치는 \"오이 샌드위치\"를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 한편, 상술한 바와 같은 예에서는 획득된 이미지에 대한 객체 인식의 결과 이미지에 포함된 적어도 하나의 오브 젝트로서 \"오이 샌드위치\"가 식별되는 경우를 전제로 설명하였으나, 객체 인식의 결과 이미지에 포함된 적 어도 하나의 오브젝트로서, \"오이 샌드위치\"가 아닌 \"샌드위치\"를 식별될 수도 있다. 그런데, 이 경우에도 전자 장치는 이미지에 포함된 적어도 하나의 오브젝트 중 \"샌드위치\"를 사용자 음성에 대응되는 오브젝트로 식 별할 수도 있다. 다시 말해, 본 개시가 텍스트 정보에 포함된 적어도 하나의 오브젝트에 대한 정보를 바탕으로 식별된 오브젝트의 명칭과 이미지에 포함되는 것으로 식별된 적어도 하나의 오브젝트 명칭이 동일한 경우에 국 한되는 것은 아니며, 양 자의 명칭 중 어느 하나가 다른 하나에 포함되는 경우 등에도 적용될 수 있다. 상술한 바와 같이 사용자 음성에 대응되는 텍스트 정보를 바탕으로 사용자 음성에 대응되는 오브젝트가 식별되 면, 전자 장치는 디스플레이 상의 영역 중 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영 역 상에 텍스트 정보를 포함하는 메모 UI를 표시할 수 있다. 메모 UI에 관련된 다양한 실시 예에 대해서는 도 8a 내지 도 9b를 참조하여 후술한다. 도 7a 내지 도 7c는 전자 장치가 사용자의 터치 인터렉션을 바탕으로 사용자 음성에 대응되는 오브젝트를 식별하는 실시 예를 설명하기 위한 도면이다. 전술한 바와 같이, 전자 장치는 이미지를 획득하고, 획득된 이미지에 포함된 적어도 하나의 오브젝트를 식 별할 수 있다. 그리고, 전자 장치는 사용자 음성을 수신하고, 수신된 사용자 음성에 대응되는 텍스트 정보 를 획득할 수 있다. 또한, 전자 장치는 이미지에 포함된 적어도 하나의 오브젝트 중 사용자 음성에 대응되는 오브젝트를 식별 할 수 있다. 구체적으로, 사용자 음성에 대응되는 오브젝트는 사용자 음성에 대응되는 텍스트 정보 및 수신된 사용자의 터치 인터렉션 중 적어도 하나를 바탕으로 식별될 수 있다. 이하에서는 도 7a 내지 도 7c를 참조하여, 사용자 터치 인터렉션을 바탕으로 사용자 음성에 대응되는 오브젝트를 식별하는 과정에 대해 설명한다. 구체적으로, 사용자의 터치 인터렉션은 도 7a에 도시된 바와 같이 디스플레이 상의 하나의 지점(71-1)을 터치하는 싱글 터치 인터렉션일 수 있다. 그리고, 싱글 터치 인터렉션이 수신되면, 전자 장치는 싱글 터치 인터렉션에 따라 터치된 지점(71-1)의 위치를 바탕으로 디스플레이 상의 영역 중 터치 인터렉션이 수신된 영역(72-1)을 식별할 수 있다. 구체적으로, 전자 장치는 디스플레이 상의 영역 중 싱글 터치 인터렉 션에 따라 터치된 지점(71-1)의 위치로부터 기 설정된 범위 내의 영역을 식별하고, 식별된 영역을 터치 인터렉 션이 수신된 영역(72-1)으로 식별할 수 있다. 그리고, 전자 장치는 디스플레이 상의 영역 중 터치 인 터렉션이 수신된 영역(72-1)에 대응되는 오브젝트(73-1)를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 또한, 사용자의 터치 인터렉션은 도 7b에 도시된 바와 같이 디스플레이 상의 두 개 이상의 지점(71-2)을 동시에 터치하는 멀티 터치 인터렉션일 수 있다. 그리고, 멀티 터치 인터렉션이 수신되면, 전자 장치는 멀 티 터치 인터렉션에 따라 터치된 두 개 이상의 지점의 위치(71-2)를 바탕으로 디스플레이 상의 영역 중 터 치 인터렉션이 수신된 영역(72-2)을 식별할 수 있다. 구체적으로, 전자 장치는 디스플레이 상의 영역 중 멀티 터치 인터렉션에 따라 터치된 두 개 이상의 지점(71-2)이 포함되는 영역을 식별하고, 식별된 영역을 터 치 인터렉션이 수신된 영역(72-2)으로 식별할 수 있다. 그리고, 전자 장치는 디스플레이 상의 영역 중 터치 인터렉션이 수신된 영역(72-2)에 대응되는 오브젝트(73-2)를 사용자 음성에 대응되는 오브젝트로 식별 할 수 있다. 그리고, 사용자의 터치 인터렉션은 도 7c에 도시된 바와 같이 디스플레이 상의 복수의 지점(71-3)이 연결 된 폐곡선을 따라 이루어지는 드래그 인터렉션일 수도 있다. 그리고, 드래그 인터렉션이 수신되면, 전자 장치 는 드래그 인터렉션에 따른 폐곡선을 바탕으로 디스플레이 상의 영역 중 터치 인터렉션이 수신된 영 역(72-3)을 식별할 수 있다. 구체적으로, 전자 장치는 디스플레이 상의 영역 중 드래그 인터렉션에 따른 폐곡선에 포함되는 영역을 식별하고, 식별된 영역을 터치 인터렉션이 수신된 영역(72-3)으로 식별할 수 있 다. 그리고, 전자 장치는 디스플레이 상의 영역 중 터치 인터렉션이 수신된 영역(72-3)에 대응되는오브젝트를 사용자 음성에 대응되는 오브젝트(73-3)로 식별할 수 있다. 한편, 이상에서 터치 인터렉션이 수신된 영역에 대응되는 오브젝트란 디스플레이 상의 영역 중 터치 인터 렉션이 수신된 영역 상에 표시되는 오브젝트일 수 있다. 구체적으로, 전자 장치는 디스플레이 상에 상기 이미지를 표시하고, 디스플레이 상의 영역 중 터치 인터렉션이 수신된 영역 상에 표시되는 오브젝트 를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 상술한 바와 같이 사용자 인터렉션을 바탕으로 사용자 음성에 대응되는 오브젝트가 식별되면, 전자 장치는 디스플레이 상의 영역 중 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 텍스트 정보(74-1, 74-2, 74-3)를 포함하는 메모 UI(75-1, 75-2, 75-3)를 표시할 수 있다. 메모 UI에 관련된 다양한 실시 예에 대해서는 도 8a 내지 도 9b를 참조하여 후술한다. 상술한 바와 같은 본 개시의 다양한 실시 예에 따르면, 전자 장치는 사용자의 터치 인터렉션을 바탕으로 음성 인식의 대상이 되는 사용자 음성을 특정함과 동시에 편의적이고도 직관적인 방식으로 메모 UI가 표시되는 영역을 결정하여 메모 UI를 표시할 수 있게 된다. 도 8a 및 도 8b는 사용자의 터치 인테렉션을 바탕으로 메모 UI의 크기 및 형태를 상이하게 표시하는 것에 관련 된 실시 예를 설명하기 위한 도면이다. 이상에서는 도 7a 내지 도 7c를 참조하여, 다양한 유형의 터치 인터렉션을 바탕으로 이미지에 포함된 적어도 하 나의 오브젝트 중 사용자 음성에 대응되는 오브젝트를 식별하고, 디스플레이 상의 영역 중 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 텍스트 정보를 포함하는 메모 UI를 표시하는 실시 예에 대해 설명하였다. 즉, 이상에서는 사용자의 터치 인터렉션을 바탕으로 메모 UI가 표시되는 영역이 결정되는 실시 예에 대해 설명 하였으나, 본 개시에 따르면 메모 UI의 크기 및 형태 또한 다양한 유형의 사용자의 터치 인터렉션에 따라 결정 될 수 있다. 구체적으로, 도 8a에 도시된 바와 같이, 사용자의 터치 인터렉션은 디스플레이 상의 두 개 이상의 지점 (81-1)을 동시에 터치하는 멀티 터치 인터렉션일 수 있다. 그리고, 멀티 터치 인터렉션이 수신되면, 전자 장치 는 멀티 터치 인터렉션에 따라 터치된 두 개 이상의 지점(81-1)의 위치를 바탕으로 디스플레이 상의 영역 중 터치 인터렉션이 수신된 영역(82-1)을 식별할 수 있다. 구체적으로, 전자 장치는 디스플레이 상의 영역 중 멀티 터치 인터렉션에 따라 터치된 두 개 이상의 좌표 값이 포함되는 영역(82-1)의 크기 및 형태 를 식별할 수 있다. 그리고, 전자 장치는 멀티 터치 인터렉션에 따라 식별된 영역(82-1)의 크기 및 형태에 대응되는 크기 및 형태로 디스플레이 상에 메모 UI(83-1)를 표시할 수 있다. 한편, 도 8b에 도시된 바와 같이, 사용자의 터치 인터렉션은 디스플레이 상의 복수의 지점이 연결된 폐곡 선(81-2)을 따라 이루어지는 드래그 인터렉션일 수도 있다. 그리고, 드래그 인터렉션이 수신되면, 전자 장치 는 드래그 인터렉션에 따른 폐곡선을 바탕으로 디스플레이 상의 영역 중 터치 인터렉션이 수신된 영 역(82-2)을 식별할 수 있다. 구체적으로, 전자 장치는 디스플레이 상의 영역 중 드래그 인터렉션에 따라 터치된 복수의 좌표 값이 포함되는 영역(82-2)의 크기 및 형태를 식별할 수 있다. 그리고, 전자 장치(10 0)는 드래그 인터렉션에 따라 식별된 영역(82-2)의 크기 및 형태에 대응되는 크기 및 형태로 디스플레이 상에 메모 UI(83-2)를 표시할 수 있다. 한편, 도 8a 및 도 8b에서는 오브젝트가 표시되지 않은 영역 상에 사용자의 터치 인터렉션이 수신되는 경우를 도시하였으나, 도 7a 내지 도 7c에 도시된 바와 같이 오브젝트가 표시된 영역 상에 사용자의 터치 인터렉션이 수신되는 경우에도, 사용자의 터치 인터렉션을 바탕으로 메모 UI의 크기 및 형태가 결정될 수 있음은 물론이다. 상술한 바와 같은 본 개시의 다양한 실시 예에 따르면, 전자 장치는 한 번의 사용자의 터치 인터렉션을 바 탕으로 메모 UI가 표시되는 영역뿐만 아니라, 메모 UI의 크기 및 형태까지 결정하여 메모 UI를 표시할 수 있게 된다. 도 9a 및 도 9b는 본 개시에 따른 메모 UI에 관련된 다양한 유형을 설명하기 위한 도면이다. 도 9a에 도시된 바와 같이, 본 개시에 따른 메모 UI는 \"결혼기념일 선물!\" (이하, 제1 텍스트 정보라고 지칭한다), \"아침 꼭 챙겨 먹어라\" (이하, 제2 텍스트 정보라고 지칭한다), \"냄비에 500ml 물을 넣고, 물이 끓으면 면을 넣고 스프를 넣고 2분 정도 더 끓인 다음...\" (이하, 제3 텍스트 정보라고 지칭한 다)과 같은 텍스트 정보를 포함할 수 있다. 그리고, 제1 텍스트 정보, 제2 텍스트 정보 및 제3 텍스트 정보는 다양한 유형의 크기, 폰트 및 색상 등으로 표시될 수 있다. 구체적으로, 본 개시에 따른 메모 UI를 통해 표시되는 텍스트 정보의 크기는 메모 UI가 표시되는 크기를 바탕으 로 결정될 수 있다. 예를 들어, 도 9a에 도시된 바와 같이, 제1 텍스트 정보가 표시되는 메모 UI의 크기가 제2 텍스트 정보가 표시되는 메모 UI에 비하여 크게 결정된 경우, 제2 텍스트 정보에 비하여 제1 텍스 트 정보가 더 크게 표시될 수 있다. 한편, 본 개시에 따른 텍스트 정보가 메모 UI를 통해 표시되는 크기는 텍스트 정보의 양을 바탕으로 결정될 수 도 있다. 예를 들어, 동일한 크기의 메모 UI에 제2 텍스트 정보와 제3 텍스트 정보를 표시하는 경우, 상대적으로 적은 문자 개수를 포함하는 제2 텍스트 정보의 크기가 제3 텍스트 정보의 크기보다 크게 결 정될 수 있다. 한편, 본 개시에 따른 텍스트 정보가 메모 UI를 통해 표시되는 크기는 수신된 사용자 음성의 크기 바탕으로 결 정될 수 있다. 예를 들어, 텍스트 정보에 대응되는 사용자 음성의 크기가 더 클수록 메모 UI를 통해 텍스트 정 보를 더 크게 표시할 수 있다. 여기서, 사용자 음성의 크기에 대한 정보는 상술한 바와 같은 ASR 모듈을 통해 획득된 사용자 음성의 음향 특징을 바탕으로 획득될 수 있다. 한편, 본 개시에 따른 메모 UI를 통해 표시되는 텍스트 정보의 크기, 폰트 및 색상은 텍스트 정보에 대응되는 사용자 음성을 발화한 사용자에 따라 상이하게 결정될 수 있다. 여기서, 사용자 음성을 발화한 사용자는 사용자 음성의 성문 분석 또는 카메라를 통해 획득된 사용자 이미지에 대한 객체 인식 등을 바탕으로 식별될 수 있다. 구체적으로, 사용자 음성이 수신되면, 전자 장치는 수신된 사용자 음성의 성문(voice print)에 대한 정보 를 바탕으로 수신된 사용자 음성을 발화한 사용자를 식별할 수 있다. 여기서, 성문이란 사용자 음성의 주파수를 분석하여 획득할 수 있는 식별 정보로서, 사용자마다 그 음성의 주파수 형태가 고유하다는 점에서 사용자 인식 에 이용될 수 있다. 구체적으로, 전자 장치는 수신된 사용자 음성의 성문에 대한 정보를 획득하고, 사용자 음성의 성문에 대한 정보를 기 저장된 성문에 대한 정보와 비교함으로써 사용자 음성을 발화한 사용자를 식별할 수 있다. 한편, 전자 장치는 사용자 음성이 수신되는 동안 카메라를 통해 사용자 이미지를 획득하고, 획득된 사용자 이미지에 대한 객체 인식을 수행하여 사용자 음성을 발화한 사용자를 식별할 수 있다. 구체적으로, 전자 장치 는 카메라를 통하여 획득된 사용자의 이미지가 기 등록된 사용자의 이미지와 비교함으로써 사용자 음성을 발화한 사용자를 식별할 수 있다. 상술한 바와 같이 사용자 음성을 발화한 사용자가 식별되면, 전자 장치는 식별된 사용자에 따라 메모 UI를 통해 표시되는 텍스트 정보의 크기, 폰트 및 색상 등을 상이하게 결정할 수 있다. 구체적으로, 전자 장치 는 사용자에 따라 선호하는 텍스트 정보의 크기, 폰트 및 색상 등에 대한 설정 정보를 저장하고, 식별된 사용자 에 대응되는 설정 정보를 바탕으로 메모 UI를 통해 표시되는 텍스트 정보의 크기, 폰트 및 색상 등을 결정할 수 있다. 메모 UI를 통해 표시되는 텍스트 정보의 크기, 폰트 및 색상 등이 결정되면, 결정된 크기, 폰트 및 색상 등으로 메모 UI를 통해 텍스트 정보를 표시할 수 있다. 예를 들어, 식별된 사용자가 전자 장치를 사용하는 사용자 가족 중 '할머니'이면, 전자 장치는 식별 된 사용자인 '할머니'에 대응되는 설정 정보를 바탕으로 메모 UI를 통해 텍스트 정보를 크게, 가독성 좋은 폰트, 그리고 검정색으로 표시할 수 있다. 또한, 식별된 사용자가 전자 장치를 사용하는 사용자 가족 중 '딸'이면, 전자 장치는 식별된 사용자인 '딸'에 대응되는 설정 정보를 바탕으로 메모 UI를 통해 텍스트 정보를 크게, 심미감이 좋은 폰트, 그리고 하늘색으로 표시할 수 있다. 한편, 디스플레이 상에 이미지가 표시된 상태에서 메모 UI를 표시하는 경우, 메모 UI는 표시된 이미지의 일 영역을 가리면서 그 일 영역 상에 표시될 수도 있고, 표시된 이미지의 일 영역 상에 투명한 형태로 표시될 수도 있다. 예를 들어, 도 9b에 도시된 바와 같이, 메모 UI(94, 95)는 표시된 이미지의 일 영역 상에 투명한 형 태로 표시되면서, 메모 UI(94, 95)가 표시되는 영역에 대응되는 오브젝트가 함께 표시될 수 있다. 한편, 메모 UI(94, 95)가 투명한 형태로 표시되는 경우, 그 투명도는 사용자 설정에 의해 변경될 수도 있음은 물론이다. 한편, 디스플레이 상에 표시되는 이미지는 카메라를 통해 획득된 이미지를 처리하여 디스플레이 상에 표시되는 이미지일 수 있을 뿐만 아니라, 디스플레이의 후면에 배치된 사물이 투명 디스플레이를 투과하여 투명 디스플레이 상에 표시되는 것일 수도 있다. 그리고, 이미지가 투명 디스플레이를 투과하 여 표시되는 경우에도 그 이미지 상에 본 개시에 따른 메모 UI가 상술한 바와 같은 다양한 유형으로 표시될 수 있다. 한편, 이상에서는 메모 UI를 통해 표시되는 텍스트 정보에 대해 설명하였으나, 메모 UI는 사용자 음성에 대응되 는 것으로 식별된 오브젝트에 관련된 다양한 정보를 더 포함할 수 있다. 예를 들어, 전자 장치는 메모 UI 를 통해, 이미지에서 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역이 캡쳐된 이미지를 표시 할 수 있으며, 뿐만 아니라 기 저장되거나 외부 장치로부터 사용자 음성에 대응되는 오브젝트에 관련된 정보를 수신하여 표시할 수도 있다. 상술한 바와 같은 본 개시의 다양한 실시 예에 따르면, 전자 장치는 사용자 음성 및 사용자 음성을 발화한 사용자가 누구인지에 따라 다양한 유형의 크기, 폰트 및 색상으로 텍스트 정보를 표시할 수 있으며, 이에 따라 직관적인 방식으로 사용자 맞춤형의 메모 UI를 제공할 수 있게 된다. 도 10a는 본 개시에 따라 사용자 음성에 대응되는 오브젝트를 식별하는 과정 및 사용자 음성에 대응되는 오브젝 트가 2 개 이상인 경우에 관련된 실시 예를 통합적으로 설명하기 위한 도면이다. 이상에서, 도 2를 참조하여 사용자 음성에 대응되는 오브젝트를 식별하는 과정에 대해 간략히 설명하였다 (S250). 그리고, 도 6을 참조하여 사용자 음성에 대응되는 텍스트 정보를 바탕으로 사용자 음성에 대응되는 오 브젝트를 식별하는 과정에 대해 상세하게 설명하였으며, 도 7a 내지 도 7c를 참조하여 사용자의 터치 인터렉션 을 바탕으로 사용자 음성에 대응되는 오브젝트를 식별하는 과정에 대해 상세하게 설명하였다. 이하에서는 도 10a를 참조하여, 사용자 음성에 대응되는 텍스트 정보에 이미지에 포함된 적어도 하나의 오브젝트에 대한 정보 가 포함되는지 여부(S1020)와 사용자 음성이 수신되는 동안 디스플레이 상에 터치 인터렉션이 수신되었는지 여 부(S1030)를 함께 고려하여 사용자 음성에 대응되는 오브젝트를 식별하는 실시 예에 대해 설명한다. 도 10a에 도시된 바와 같이, 전자 장치는 이미지에 포함된 적어도 하나의 오브젝트를 식별할 수 있다 (S1010). 구체적으로, 전자 장치는 이미지를 획득하고, 획득된 이미지를 분석하여 이미지에 포함된 적어도 하나의 오브젝트를 식별할 수 있다. 전자 장치는 수신된 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다(S1015). 구체적으로, 전자 장 치는 사용자 음성을 수신하고, 수신된 사용자 음성에 대한 음성 인식을 수행하여 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다. 한편, 전자 장치는 도 10a에 도시된 바와 같이, 사용자 음성에 대응되는 텍스트 정보에 이미지에 포함된 적어도 하나의 오브젝트에 대한 정보가 포함되는지 여부 및 사용자 음성이 수신되는 동안 디스플레이 상에 터치 인터렉션이 수신되었는지 여부를 바탕으로 사용자 음성에 대응되는 오브젝트를 식별할 수 있다. 먼저, 전자 장치는 사용자 음성에 대응되는 텍스트 정보에 이미지에 포함된 적어도 하나의 오브젝트에 대 한 정보가 포함되는지를 식별할 수 있다(S1020). 사용자 음성에 대응되는 텍스트 정보에 적어도 하나의 오브젝 트에 대한 정보가 포함되면(S1020-Y), 전자 장치는 텍스트 정보에 대응되는 오브젝트의 개수를 식별할 수 있다(S1025). 구체적으로, 전자 장치는 텍스트 정보에 포함된 적어도 하나의 오브젝트에 대한 정보를 바탕 으로 텍스트 정보에 대응되는 오브젝트의 개수를 식별할 수 있다. 예를 들어, 이미지에 포함된 오브젝트로서, \"맥주\", \"치킨\" 및 \"딸기\"가 식별되고, 사용자 음성에 대응되는 텍스트 정보에 \"맥주\" 및 \"치킨\"이라는 오브젝 트에 대한 정보가 포함되면, 전자 장치는 이미지에 포함된 오브젝트 중 텍스트 정보에 대응되는 오브젝트 의 개수가 2 개라는 것을 식별할 수 있다. 한편, 사용자 음성에 대응되는 텍스트 정보에 적어도 하나의 오브젝트에 대한 정보가 포함되지 않으면(S1020- N), 전자 장치는 사용자 음성이 수신되는 동안 디스플레이 상에 사용자의 터치 인터렉션이 수신되었는지를 식별할 수 있다(S1030). 그리고, 사용자 음성이 수신되는 동안 디스플레이 상에 사용자의 터치 인터렉션이 수신되지 않았다면(S1030-N), 전자 장치는 디스플레이 상의 영역 중 기 설정된 영역 상에 메모 UI를 표시할 수 있다(S1035). 구체적으로, 전자 장치는 디스플레이 상의 영역 중 텍스트 정보에 이미지에 포함된 적어도 하나의 오브젝 트에 대한 정보가 포함되지 않고, 사용자 음성이 수신되는 동안 디스플레이 상에 사용자의 터치 인터렉션이 수 신되지 않는 경우에 메모 UI를 표시하도록 기 설정된 영역 상에 메모 UI를 표시할 수 있다. 여기서 기 설정된영역은 예를 들어 디스플레이 상의 중앙 영역일 수 있다. 사용자 음성이 수신되는 동안 디스플레이 상에 사용자의 터치 인터렉션이 수신되었다면(S1030-Y), 사용자의 터 치 인터렉션이 수신된 영역에 대응되는 오브젝트의 개수를 식별할 수 있다(S1040). 예를 들어, 사용자의 터치 인터렉션이 수신된 지점으로부터 기 설정된 거리 내의 영역에 \"맥주 및 \"치킨\"이라는 오브젝트가 디스플레이 상 에 표시된 경우, 전자 장치는 사용자의 터치 인터렉션이 수신된 영역에 대응되는 오브젝트의 개수가 2 개 라는 것을 식별할 수 있다. 상술한 바와 같이, 텍스트 정보에 대응되는 오브젝트의 개수 또는 사용자의 터치 인터렉션이 수신된 영역에 대 응되는 오브젝트의 개수가 식별되면, 전자 장치는 텍스트 정보 또는 사용자의 터치 인터렉션이 수신된 영 역에 대응되는 것으로 식별된 오브젝트가 2 개 이상인지를 식별할 수 있다(S1045). 텍스트 정보 또는 사용자의 터치 인터렉션이 수신된 영역에 대응되는 것으로 식별된 오브젝트가 2 개 이상이 아 니면(S1045-N), 전자 장치는 디스플레이 상의 영역 중 텍스트 정보 또는 사용자의 터치 인터렉션이 수신된 영역에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 메모 UI를 표시할 수 있다(S1050). 텍스트 정보 또는 사용자의 터치 인터렉션이 수신된 영역에 대응되는 것으로 식별된 오브젝트가 2 개 이상이면 (S1045-Y), 전자 장치는 텍스트 정보 또는 사용자의 터치 인터렉션이 수신된 영역에 대응되는 것으로 식별 된 2 개 이상의 오브젝트에 대한 정보를 포함하는 선택 UI를 디스플레이 상에 표시할 수 있다(S1055). 그리고, 전자 장치는 디스플레이 상의 영역 중 선택 UI를 통해 선택된 오브젝트에 대응되는 영역 상에 메모 UI를 표시할 수 있다(S1060). 여기서, 선택 UI를 제공하는 것에 관련된 실시 예에 대해서는 도 11a 및 도 11b를 참조 하여 구체적으로 설명한다. 한편, 이상에서는 도 10a를 참조하여 사용자 음성에 대응되는 텍스트 정보에 이미지에 포함된 적어도 하나의 오 브젝트에 대한 정보가 포함되는지를 식별하고(S1020), 그 후 사용자 음성이 수신되는 동안 디스플레이 상에 사 용자의 터치 인터렉션이 수신되었는지를 식별(S1030)함에 따라 사용자 음성에 대응되는 오브젝트 및 그 개수를 식별하는 실시 예에 대해 설명하였으나, 본 개시의 또 다른 실시 예에 따르면 S1020 단계와 S1030 단계의 순서 는 서로 바뀔 수 있으며, 도 6 및 도 7a 내지 도 7c를 참조하여 설명한 바와 같이, 사용자 음성에 대응되는 텍 스트 정보와 디스플레이 상에 수신된 사용자의 터치 인터렉션은 사용자 음성에 대응되는 오브젝트를 식별하기 위한 독립적인 기준이 될 수 있다. 한편, 전술한 바와 같이, 이미지에 대한 객체 인식 결과 식별의 대상이 되는 오브젝트의 범위는 전자 장치의 종 류 또는 사용자의 설정 등에 따라 상이하게 기 설정될 수도 있다. 예를 들어, 전자 장치가 냉장고인 경우, 냉장고의 내부 이미지에 대한 객체 인식 결과 식별의 대상이 되는 오브젝트의 범위는 냉장고 내부의 선반 또는 저장함과 같은 내부 구조물을 제외하고, 냉장고의 내부에 배치된 식품만을 포함하는 범위로 기 설정될 수도 있 다. 이미지에 대한 객체 인식 결과, 기 설정된 오브젝트의 범위에 포함되는 오브젝트가 식별되지 않으면, 전자 장치 는 사용자의 터치 인터렉션을 바탕으로 메모 UI가 표시되는 영역을 결정할 수 있다. 또한, 전자 장치(10 0)는 이미지를 획득하는 과정, 획득된 이미지에 포함된 적어도 하나의 오브젝트를 식별하는 과정 등을 수행하지 않고, 사용자의 터치 인터렉션을 바탕으로 메모 UI가 표시되는 영역을 결정할 수 있다. 이처럼 이미지에 포함된 오브젝트에 의존하지 않고 사용자의 터치 인터렉션을 바탕으로 메모 UI가 표시되는 영역을 결정하는 실시 예에 대해서는 이하에서 도 10b를 참조하여 설명한다. 도 10b는 디스플레이 상에 사용자의 터치 인터렉션이 수신된 영역 상에 메모 UI를 표시하는 실시 예를 설명하기 위한 도면이다. 도 10b에 도시된 바와 같이, 전자 장치는 디스플레이 상에 사용자의 터치 인터렉션을 수신할 수 있다 (S1070). 구체적으로 전자 장치는 디스플레이 상의 영역 중 하나의 영역에 대한 사용자의 터치 인터렉션을 수신할 수 있다. 여기서, 사용자의 터치 인터렉션은 도 7a 내지 도 7c를 참조하여 상술한 바와 같은 다양한 유 형의 터치 인터렉션일 수 있다. 전자 장치는 사용자 음성을 수신할 수 있다(S1075). 그리고, 사용자 음성이 수신되면, 전자 장치는 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다(S1080). 여기서, 음성 인식의 대상이 되는 사용자 음성 은 사용자의 터치 인터렉션을 바탕으로 특정될 수 있다. 구체적으로, 사용자의 터치 인터렉션이 수신된 시점은 음성 인식의 대상이 되는 사용자 음성을 특정하기 위한 시작점일 수 있다. 즉, 디스플레이 상에 트리거 입력에 대응되는 것으로 기 설정된 사용자의 터치 인터렉션이 수신되면, 전자 장치는 사용자의 터치 인터렉션이 수신된 후에 수신된 사용자 음성에 대한 음성 인식을 수 행하여, 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다. 여기서, 사용자 음성이 수신되기 시작하는 시점까지 사용자의 터치 인터렉션이 유지되는지 여부는 문제되지 않 는다. 다만, 사용자 음성이 수신되기 시작하는 시점 이후까지 사용자의 터치 인터렉션이 유지된다면, 도 2를 참 조하여 상술한 바와 같이, 사용자의 터치 인터렉션이 수신된 시점은 음성 인식의 대상이 되는 사용자 음성을 특 정하기 위한 시작점이 되고, 사용자의 터치 인터렉션이 종료된 시점은 음성 인식의 대상이 되는 사용자 음성을 특정하기 위한 종료점이 될 수도 있다. 전자 장치는 사용자의 터치 인터렉션이 수신된 영역 상에 텍스트 정보를 포함하는 메모 UI를 표시할 수 있 다(S1085). 즉, 이상에서는 도 10b를 참조하여 상술한 바와 같은 본 개시의 일 실시 예에 따르면, 전자 장치 는 적어도 하나의 오브젝트를 포함하는 이미지를 획득하는 과정, 획득된 이미지에 포함된 적어도 하나의 오브젝트를 식별하는 과정, 사용자 음성에 대응되는 텍스트 정보를 바탕으로 사용자 음성에 대응되는 오브젝트 를 식별하는 과정 및 획득된 이미지를 디스플레이 상에 표시하는 과정 중 적어도 일부를 수행하지 않고, 사용자 의 터치 인터렉션이 수신된 영역 상에 메모 UI를 표시할 수 있다. 도 10b를 참조하여 상술한 바와 같은 실시 예에 따르면, 전자 장치의 사용자는 적어도 하나의 오브젝트를 포함하는 이미지와의 관계를 고려하지 않고, 사용자의 터치 인터렉션을 바탕으로 사용자가 메모 UI를 표시하기 를 원하는 영역 상에 메모 UI를 표시할 수 있게 된다. 특히, 한 번의 사용자의 터치 인터렉션을 바탕으로 메모 UI가 표시되는 영역을 결정함과 동시에 음성 인식의 대상이 되는 사용자 음성을 특정할 수 있다. 도 11a 및 도 11b는 사용자 음성에 대응되는 것으로 식별된 오브젝트가 2 개 이상인 경우 선택 UI를 제공하는 것에 관련된 실시 예를 상세하게 설명하기 위한 도면이다. 전술한 바와 같이, 도 11a 및 도 11b에 도시된 바와 같이 전자 장치가 냉장고인 경우, 전자 장치는 냉장고의 내부를 촬영하여 냉장고의 내부 이미지를 획득하고, 획득된 이미지에 포함된 적어도 하나의 오브젝트 로서 \"주스\" 및 \"샌드위치\" 등을 식별할 수 있다. 한편, 전술한 바와 같이, 전자 장치는 이미지에 포함된 적어도 하나의 오브젝트 중 수신된 사용자 음성에 대응되는 오브젝트를 식별할 수 있다. 그리고, 사용자 음성에 대응되는 것으로 식별된 오브젝트가 2 개 이상이 면, 전자 장치는 디스플레이 상에 2 개 이상의 오브젝트에 대한 정보를 포함하는 선택 UI를 표시할 수 있 다. 여기서, 선택 UI는 2 개 이상의 오브젝트 중 하나를 선택하는 사용자 입력을 수신하기 위한 사용자 인터페 이스를 말한다. 선택 UI를 통해 2 개 이상의 오브젝트 중 하나의 오브젝트를 선택하는 사용자 입력이 수신되면, 전자 장치(10 0)는 선택된 하나의 오브젝트를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 이하, 도 11a 및 도 11b를 참조하여, 본 개시에 따라 선택 UI를 제공하는 것에 관련된 다양한 실시 예를 구체적으로 설명한다. 도 11a는 사용자 음성에 대응되는 텍스트 정보를 바탕으로 이미지에 포함된 적어도 하나의 오브젝트 중 수신된 사용자 음성에 대응되는 오브젝트를 식별한 결과, 사용자 음성에 대응되는 것으로 식별된 오브젝트가 2 개 이상 인 경우 선택 UI를 제공하는 것에 관련된 실시 예를 설명하기 위한 도면이다. 도 11a를 참조하면, 전자 장치는 사용자 음성을 수신하고, 수신된 사용자 음성에 대응되는 텍스트 정보로 서 \"주스랑 샌드위치 먹고 출근해\"라는 텍스트 정보를 획득할 수 있다. 사용자 음성에 대응되는 텍스트 정보가 획득되면, 전자 장치는 이미지에 포함된 적어도 하나의 오브젝트 중 사용자 음성에 대응되는 오브 젝트로서 \"주스\" 및 \"샌드위치\"라는 오브젝트를 식별할 수 있다. 이 경우, 식별된 오브젝트가 2 개 이상이므로, 전자 장치는 디스플레이 상에 \"주스\" 및 \"샌드위치\"라는 2 개 이상의 오브젝트에 대한 정보를 포함하는 선 택 UI를 제공할 수 있다. 선택 UI를 통해 \"주스\" 및 \"샌드위치\" 중 \"샌드위치\"라는 오브젝트를 선택하는 사용자 입력이 수신되면, 전자 장치는 \"샌드위치\" 라는 오브젝트를 수신된 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 그 리고, 전자 장치는 디스플레이 상의 영역 중 \"샌드위치\"에 대응되는 영역 상에 \"주스랑 샌드위치 먹고 출 근해\"라는 텍스트 정보를 포함하는 메모 UI를 표시할 수 있다.도 11b는 사용자의 터치 인터렉션을 바탕으로 이미지에 포함된 적어도 하나의 오브젝트 중 수신된 사용자 음성 에 대응되는 오브젝트를 식별한 결과, 사용자 음성에 대응되는 것으로 식별된 오브젝트가 2 개 이상인 경우 선 택 UI를 제공하는 것에 관련된 실시 예를 설명하기 위한 도면이다. 도 11b를 참조하면, 전자 장치는 사용자 음성을 수신하고, 수신된 사용자 음성에 대응되는 텍스트 정보로 서 \"아침 먹고 출근해\"라는 텍스트 정보를 획득할 수 있다. 그리고, 도 11b에 도시된 바와 같이, 전자 장 치는 디스플레이 상에 사용자의 터치 인터렉션을 수신할 수 있다. 사용자의 터치 인터렉션이 수신되면, 디 스플레이 상의 영역 중 사용자의 터치 인터렉션이 수신된 영역에 대응되는 오브젝트를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 구체적으로, 사용자의 터치 인터렉션이 수신된 지점으로부터 기 설정된 거리 내의 영역에 \"주스\" 및 \"샌드위치\"라는 오브젝트가 디스플레이 상에 표시된 경우, 전자 장치는 \"주스\" 및 \"샌드 위치\"를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 이 경우, 식별된 오브젝트가 2 개 이상이므로, 전자 장치는 도 11a를 참조하여 설명한 것과 마찬가지로, 디스플레이 상에 \"주스\" 및 \"샌드위치\"라는 2 개 이상의 오브젝트에 대한 정보를 포함하는 선택 UI를 제 공할 수 있으며, 선택 UI를 통해 \"샌드위치\"라는 오브젝트를 선택하는 사용자 입력이 수신되면, 전자 장 치는 디스플레이 상의 영역 중 \"샌드위치\"에 대응되는 영역 상에 \"이거 먹고 출근해\"라는 텍스트 정보를 포함하는 메모 UI를 표시할 수 있다. 상술한 바와 같은 본 개시의 다양한 실시 예에 따르면, 전자 장치는 사용자 음성에 대응되는 것으로 식별 된 오브젝트가 2 개 이상인 경우 선택 UI를 통해 사용자가 오브젝트를 선택할 수 있도록 함으로써, 사용자 의도 에 부합하는 디스플레이의 영역 상에 메모 UI를 표시할 수 있게 된다. 한편, 이상에서는 터치 인터렉션이 수신되지 않는 전제 하에 텍스트 정보를 바탕으로 2 개 이상의 오브젝트가 식별된 경우와, 텍스트 정보에 오브젝트에 대한 정보가 포함되지 않는 전제 하에 터치 인터렉션을 바탕으로 2 개 이상의 오브젝트가 식별된 경우에 선택 UI를 제공하는 실시 예에 대해 각각 도 11a 및 11b로 구분하여 설명 하였다. 다만, 본 개시의 일 실시 예에 따르면, 텍스트 정보를 바탕으로 사용자 음성에 대응되는 오브젝트가 식별되고, 터치 인터렉션을 바탕으로도 사용자 음성에 대응되는 오브젝트가 식별될 수 있다. 그리고 이 경우, 전자 장치 는 선택 UI를 제공하지 않고 메모 UI가 표시되는 영역을 결정할 수 있다. 예를 들어, 텍스트 정보를 바탕으로 \"주스\" 및 \"샌드위치\"라는 2 개의 오브젝트가 식별된 경우, 터치 인터렉션 을 바탕으로도 \"주스\"라는 하나의 오브젝트가 식별되면, 전자 장치는 선택 UI를 제공하지 않고 터치 인터 렉션을 바탕으로 식별된 하나의 오브젝트인 \"주스\"에 대응되는 영역 상에 메모 UI를 표시할 수 있다. 또한, 터 치 인터렉션을 바탕으로 \"주스\" 및 \"샌드위치\"라는 2 개의 오브젝트가 식별된 경우, 텍스트 정보를 바탕으로도 \"샌드위치\"라는 오브젝트가 식별되면, 전자 장치는 선택 UI를 제공하지 않고 텍스트 정보를 바탕으로 식별 된 하나의 오브젝트인 \"샌드위치\"에 대응되는 영역 상에 메모 UI를 표시할 수 있다. 도 12은 사용자 음성에 대응되는 텍스트 정보에 대명사가 포함되는 경우에 관련된 실시 예를 설명하기 위한 도 면이다. 이상에서는 사용자 음성에 대응되는 텍스트 정보에 이미지에 포함된 적어도 하나의 오브젝트에 대한 정보가 포 함되는 경우에 대해 상술한 바 있으나, 획득된 텍스트 정보에는 대명사가 포함될 수도 있다. 예를 들어, 도 12 에 도시된 바와 같이, 전자 장치는 수신된 사용자 음성에 대응되는 텍스트 정보로서 \"이거 먹어\"라 는 텍스트 정보를 획득할 수 있다. 이 경우, 획득된 텍스트 정보는 \"이거\"라는 대명사를 포함할 수 있다. 한편, 대명사는 사람이나 사물의 명칭을 대신 나타내는 말이기 때문에, 텍스트 정보에 대명사가 포함되는 경우 그 대명사를 사용자의 발화 의도에 맞는 사람이나 사물의 명칭으로 변경하여 메모 UI를 통해 표시하면, 사용자 의 발화 의도가 상대방에게 더욱 잘 전달될 수 있게 된다. 따라서, 본 개시의 일 실시 예에 따르면, 사용자 음성에 대응되는 텍스트 정보에 대명사가 포함되면, 전자 장치 는 대명사가 사용자 음성에 대응되는 것으로 식별된 오브젝트의 명칭으로 변경된 텍스트 정보를 획득할 수 있다. 여기서, 사용자 음성에 대응되는 오브젝트는 전술한 바와 같이 디스플레이 상에 수신된 사용자의 터 치 인터렉션을 바탕으로 식별될 수 있다. 그리고, 변경된 텍스트 정보가 획득되면, 전자 장치는 사용자 음 성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 변경된 텍스트 정보를 포함하는 메모 UI를 표시할수 있다. 예를 들어, 도 12에 도시된 바와 같이, 전자 장치는 디스플레이 상의 영역 중 터치 인터렉션이 수신된 영역에 대응되는 오브젝트인 \"샌드위치\"를 사용자 음성에 대응되는 오브젝트로 식별할 수 있다. 그리고, 획득된 텍스트 정보에 \"이거\"와 같은 대명사가 포함되면, 전자 장치는 \"이거\"를 사용자 음성에 대 응되는 것으로 식별된 오브젝트의 명칭인 \"샌드위치\"로 변경함으로써 \"샌드위치 먹어\"라는 변경된 텍스트 정보 를 획득할 수 있다. 그리고, 변경된 텍스트 정보가 획득되면, 전자 장치는 식별된 오브젝트에 대응되는 영 역 상에 변경된 텍스트 정보인 \"샌드위치 먹어\"라는 텍스트 정보를 포함하는 메모 UI를 표시할 수 있다. 상술한 바와 같은 본 개시의 다양한 실시 예에 따르면, 전자 장치는 사용자 음성에 대응되는 텍스트 정보 에 대명사가 포함된 경우, 사용자의 터치 인터렉션에 따른 사용자의 의도를 반영하여 메모 UI를 제공함으로써, 음성 인식을 통해 텍스트 정보를 생성하고 표시하고자 하는 사용자의 편의성이 더욱 향상시킬 수 있다. 도 13a는 사용자 음성에 대응되는 텍스트 정보에 사용자 명칭에 대한 정보가 포함되는 경우에 관련된 실시 예를 설명하기 위한 도면이다. 이상에서는 사용자 음성에 대응되는 텍스트 정보에 이미지에 포함된 적어도 하나의 오브젝트에 대한 정보가 포 함되는 경우를 중심으로 본 개시에 따른 다양한 실시 예를 설명하였으나, 사용자 음성에 대응되는 텍스트 정보 에는 기 저장된 사용자 명칭에 대한 정보가 포함될 수도 있다. 예를 들어, 도 13a에 도시된 바와 같이, 전자 장 치는 수신된 사용자 음성에 대응되는 텍스트 정보로서 기 저장된 사용자 명칭인 \"하나\"라는 사용자 명칭을 포함하는 텍스트 정보를 획득할 수 있다. 사용자 음성에 대응되는 텍스트 정보에 기 저장된 사용자의 명칭이 포함되면, 전자 장치는 사용자 명칭에 대응되는 사용자 단말에 텍스트 정보를 전송할 수 있다. 구체적으로 전자 장치는 사용자 명칭 및 그 사용자 명칭에 대응되는 사용자 단말에 대한 정보를 저장할 수 있다. 그리고, 사용자 음성에 대응되는 텍 스트 정보에 기 저장된 사용자의 명칭이 포함되면, 전자 장치는 사용자 명칭에 대응되는 사용자 단말(40 0)에 사용자 음성에 대응되는 텍스트 정보를 전송할 수 있다. 도 13a에 도시된 바와 같이, 사용자 음성에 대응 되는 텍스트 정보는 사용자 단말에 직접 전송될 수도 있으며, 외부 서버를 통해 전송할 수도 있다. 예를 들어, 도 13a에 도시된 바와 같이, 전자 장치는 사용자 음성에 대응되는 텍스트 정보를 포함하는 메 모 UI를 전자 장치의 디스플레이 상에 표시할 수 있을 뿐만 아니라, 사용자 음성에 대응되는 텍스트 정보 를 \"하나\"라는 사용자 명칭에 대응되는 사용자 단말에 직접 또는 외부 서버를 통해 전송할 수 있다. 한편, 전자 장치는 텍스트 정보에 포함된 사용자 명칭에 대응되는 사용자 단말에 사용자 음성에 대응 되는 텍스트 정보를 전송할 수 있을 뿐만 아니라, 그 사용자 음성을 발화한 사용자에 대한 정보를 함께 전송할 수도 있다. 여기서, 사용자 음성을 발화한 사용자는 도 9a 및 도 9b에 대한 설명에서 상술한 바와 같이 사용자 음성의 성문 분석 또는 카메라를 통해 획득된 사용자 이미지에 대한 객체 인식을 바탕으로 식별될 수 있다. 그 리고, 식별된 사용자에 대한 정보는 전자 장치에 기 저장될 수 있으며, 사용자의 명칭에 대한 정보를 포함 할 수 있다. 상술한 바와 같은 예에서, 사용자 음성을 발화한 사용자가 \"토미\"라는 것이 식별되면, 전자 장치 는 사용자 음성에 대응되는 텍스트 정보와 함께 그 사용자 음성을 발화한 사용자가 \"토미\"라는 정보를 \"하 나\"라는 사용자 명칭에 대응되는 사용자 단말에 전송할 수 있다. 한편, 이상에서는 전자 장치가 사용자 단말에 사용자 음성에 대응되는 텍스트 정보를 전송함으로써 사용자에게 알림을 제공하는 실시 예에 대해 설명하였으나, 상술한 바와 같은 알림은 전자 장치를 통해 사 용자에게 제공될 수도 있다. 특히, 텍스트 정보에 포함된 사용자 명칭에 대응되는 사용자가 전자 장치로부 터 기 설정된 거리 내에 위치한다는 것이 식별되면, 전자 장치는 전자 장치를 통해 사용자에게 알림 을 제공할 수 있다. 구체적으로, 전자 장치는 도 9a 및 도 9b에 대한 설명에서 상술한 바와 같이 사용자 음성의 성문 분석 또 는 카메라를 통해 획득된 사용자 이미지에 대한 객체 인식을 바탕으로 텍스트 정보에 포함된 사용자 명칭에 대 응되는 사용자가 전자 장치로부터 기 설정된 거리 내에 위치한다는 것을 식별할 수 있다. 그리고, 그 사용 자가 전자 장치로부터 기 설정된 거리 내에 위치한다는 것이 식별되면, 전자 장치는 디스플레이 상에 표시된 메모 UI의 색상 또는 형태 등을 변경하거나 인디케이터를 점등함으로써 사용자가 메모 UI를 확인하는 것 을 유도할 수 있으며, 스피커를 통해 사용자에게 메모 UI를 확인할 것을 요청하는 음성을 출력할 수도 있다.상술한 바와 같은 본 개시의 다양한 실시 예에 따르면, 전자 장치는 사용자 음성에 대응되는 텍스트 정보 에 사용자 명칭에 대한 정보가 포함된 경우, 사용자 명칭에 대응되는 사용자 단말에 알림을 전송함으로써 사용 자의 편의성을 더욱 향상시킬 수 있게 된다. 도 13b는 사용자 음성에 대응되는 텍스트 정보에 오브젝트의 기한에 대한 정보가 포함되는 경우에 관련된 실시 예를 설명하기 위한 도면이다. 사용자 음성에 대응되는 텍스트 정보에는 오브젝트의 기한에 대한 정보가 포함될 수도 있다. 그리고, 사용자 음 성에 대응되는 텍스트 정보에 오브젝트의 기한에 대한 정보가 포함되면, 전자 장치는 오브젝트의 기한에 관련된 알림을 제공할 수 있다. 여기서 오브젝트의 기한에 관련된 알림은 전자 장치의 디스플레이 및 스피커 등을 통해 제공될 수 있을 뿐만 아니라. 전자 장치와 연결된 사용자 단말의 디스플레이 및 스피커 등을 통해 제공될 수도 있다. 예를 들어, 사용자 음성에 대응되는 텍스트 정보가 \"냉장고에 있는 우유 오늘까지 먹어\"인 경우와 같이 사용자 음성에 대응되는 텍스트 정보에 \"오늘까지\"와 같은 오브젝트의 기한에 대한 정보가 포함되면, 전자 장치는 디스플레이 상에 오브젝트의 기한에 관련된 알림을 표시할 수 있다. 구체적으로, 도 13b에 도시된 바와 같 이, 전자 장치는 디스플레이 상에 \"우유의 유통기한이 하루 남았습니다\"와 같은 오브젝트의 기 한에 관련된 알림을 표시할 수 있으며, 이와 함께 \"우유\"와 관련된 이미지 등을 표시할 수도 있다. 한편, 사용자 음성에 대응되는 텍스트 정보에 오브젝트의 기한에 대한 정보가 포함되면, 전자 장치는 오브 젝트의 기한에 대한 정보에 대응되는 시점까지 기 설정된 시간 간격으로 오브젝트의 기한에 관련된 알림을 제공 할 수 있다. 예를 들어, 사용자 음성에 텍스트 정보가 \"냉장고에 있는 우유 오늘까지 먹어\"이면, 전자 장치 는 사용자 음성에 대응되는 텍스트 정보가 획득된 날의 자정까지 1 시간 간격으로 \"우유의 유통기한이 n 시간 남았습니다\"와 같은 오브젝트의 기한에 관련된 알림을 제공할 수 있다. 즉, 전자 장치가 냉장고이고 사용자 음성에 대응되는 텍스트 정보에 포함된 오브젝트가 냉장고 내부의 식품인 경우, 전자 장치는 그 식 품의 신선도에 관련된 알림을 제공할 수 있다. 한편, 전자 장치는 알림을 제공하는 시점과 오브젝트의 기한에 대한 정보에 대응되는 시점 사이의 간격에 따라 상이한 방법으로 오브젝트의 기한에 관련된 알림을 제공할 수도 있다. 예를 들어, 사용자 음성에 대응되는 텍스트 정보가 \"냉장고에 있는 우유 내일까지 먹어\"이면, 전자 장치는 사용자 음성에 대응되는 텍스트 정 보가 획득된 시점에는 전자 장치의 디스플레이를 통해 메모 UI를 표시함으로써 오브젝트의 기한에 관 련된 알림을 제공하고, 그로부터 3 시간 후에는 3 시간에 전과 상이한 색상으로 메모 UI를 표시함으로써 오브젝 트의 기한에 관련된 알림을 제공하며, 다시 3 시간 후에는 사용자 단말의 디스플레이를 통해 오브젝트의 기한에 관련된 알림을 제공하고, 다시 3 시간 후에는 사용자 단말의 디스플레이를 통해 오브젝트의 기한에 관련된 알림 을 제공함과 동시에, 스피커를 통해 오브젝트의 기한에 관련된 음성을 출력할 수도 있다. 여기서, 사용자 단말을 통해 오브젝트의 기한에 관련된 알림을 제공하는 것은 전자 장치가 오브젝트의 기 한에 관련된 알림에 대한 정보를 사용자 단말로 전송하고, 사용자 단말이 전자 장치로부터 수신된 오브젝 트의 기한에 관련된 알림에 대한 정보를 바탕으로 사용자 단말에서 오브젝트의 기한에 관련된 알림을 제공하는 것을 의미한다. 한편, 제1 이미지에 포함된 적어도 하나의 오브젝트 중 제1 오브젝트가 사용자 음성에 대응되는 오브젝트로 식 별된 경우, 사용자 음성에 대응되는 텍스트 정보에 제1 오브젝트의 기한에 대한 정보가 포함되면, 전자 장치 는 제2 이미지를 획득하고, 획득된 제2 이미지에서 제1 오브젝트가 식별되는 경우에 한하여, 오브젝트의 기한에 관련된 알림을 제공할 수 있다. 여기서, 제2 이미지란 제1 이미지가 획득된 이후에 제1 이미지와 동일한 장소를 촬영하여 획득된 이미지일 수 있다. 제2 이미지가 획득된 시점은 제1 이미지가 획득된 시점으로부터 기 설정된 시간 이후의 시점일 수 있다. 제1 이미지 및 제2 이미지는 기 설정된 시간 간격에 따라 동일한 장소를 촬영하여 획득될 수 있으며, 뿐만 아니 라 기 설정된 이벤트가 발생되는 것을 바탕으로 동일한 장소를 촬영하여 획득될 수도 있다. 예를 들어, 전자 장치가 냉장고인 경우 제1 이미지는 냉장고 내부의 특정 장소를 촬영하여 획득된 이미지 일 수 있다. 이 경우, 제1 이미지에 포함된 \"우유\"가 사용자 음성에 대응되는 오브젝트로 식별되고, 사용자 음 성에 대응되는 텍스트 정보에 \"우유\"의 기한에 대한 정보가 포함되면, 전자 장치는 제1 이미지의 획득 시촬영된 장소를 촬영하여 제2 이미지를 획득할 수 있다. 그리고, 전자 장치는 획득된 제2 이미지에서 \"우유\"가 식별되는 경우에 한하여, 오브젝트의 기한에 관련된 알림을 제공할 수 있다. 한편, 오브젝트의 기한에 대한 정보에 대응되는 시점이 지난 후에도 사용자 음성에 대응되는 오브젝트가 존재하 면, 전자 장치는 오브젝트의 기한에 관련된 알림으로서, 오브젝트의 기한에 대한 정보에 대응되는 시점이 지나기 전과는 상이한 알림을 제공할 수 있다. 예를 들어, 사용자 음성에 대응되는 텍스트 정보가 \"냉장고에 있 는 우유 오늘까지 먹어\"이고, 사용자 음성에 대응되는 텍스트 정보가 획득된 날의 자정 이후에도 \"우유\"가 존재 하면, 전자 장치는 \"냉장고에 있는 우유 버려야 해\"와 같은 알림을 제공할 수도 있다. 한편, 이상에서는 사용자 음성에 대응되는 텍스트 정보에 오브젝트의 기한에 대한 정보가 포함되는 경우를 전제 로 설명하였으나, 오브젝트의 기한에 대한 정보는 사용자 음성에 대응되는 텍스트 정보에 명시적으로 포함될 수 있을 뿐만 아니라, 텍스트 정보에 포함된 적어도 하나의 오브젝트에 대한 정보를 바탕으로 획득될 수도 있다. 예를 들어, 사용자 음성에 대응되는 정보에 \"우유\"라는 오브젝트에 대한 정보가 포함되면, 전자 장치는 기 저장된 오브젝트 별 소비 기한에 대한 정보를 바탕으로 \"우유\"의 소비 기한이 5 일이라는 오브젝트의 기한에 대 한 정보를 획득하고, 오브젝트의 기한에 관련된 알림을 제공할 수도 있다. 상술한 바와 같은 본 개시의 다양한 실시 예에 따르면, 전자 장치는 사용자 음성에 대응되는 텍스트 정보 에 오브젝트의 기한에 대한 정보가 포함된 경우, 다양한 방식으로 오브젝트의 기한에 관련된 알림을 제공함으로 써 사용자의 편의성을 더욱 향상시킬 수 있게 된다. 도 13c는 사용자 음성에 대응되는 텍스트 정보에 사용자의 의도에 대한 정보가 포함되는 경우에 관련된 실시 예 를 설명하기 위한 도면이다. 이상에서는 사용자 음성에 대응되는 텍스트 정보에 이미지에 포함된 적어도 하나의 오브젝트에 대한 정보가 포 함되는 경우를 중심으로 본 개시에 따른 다양한 실시 예를 설명하였으나, 사용자 음성에 대응되는 텍스트 정보 에는 사용자의 의도에 대한 정보가 포함될 수도 있다. 그리고, 사용자의 의도에 대한 정보는 도 3b를 참조하여 상술한 바와 같이 NLU 모듈을 통해 획득될 수 있다. 전술한 바와 같이, NLU 모듈은 사용자 음성에 대응되는 텍스트 정보에 대한 문법적 분석(syntactic analyze) 및 의미적 분석(semantic analyze)을 수행하여, 사용자의 의도에 대한 정보를 획득할 수 있다. 구체적으로, NLU 모듈은 획득된 텍스트 정보의 문법적 단위(예: 단어, 구, 형태소 등)를 구분하고, 구분된 문법 적 단위가 어떠한 문법적 요소를 갖는지를 식별할 수 있다. 그리고, NLU 모듈은 식별된 문법적 요소를 바탕으로 텍스트 정보의 의미를 판단할 수 있다. 또한, NLU 모듈은 판단된 텍스트 정보의 의미를 식별된 도메인, 식별된 도메인에 포함되는 복수의 의도(intent) 및 복수의 파라미터(parameter) 내지는 슬롯(slot)에 매칭시킴으로써 사용자의 의도에 대한 정보를 획득할 수 있다. 예를 들어, NLU 모듈은 판단된 텍스트의 의미를 식별된 도메인인 \"알람\" 및 식별된 도메인에 포함되는 복수의 의도인 \"알람 설정\" 및 \"알람 해제\", 그리고 사용자의 의도를 표현 하는데 필요한 파라미터인 \"시간\", \"반복 횟수\" 및 \"알람음\" 등에 매칭시킴으로써 사용자의 의도에 대한 정보를 획득할 수 있다. 상술한 바와 같이 NLU 모듈을 통해 사용자의 의도에 대한 정보가 획득되면, 전자 장치는 사용자의 의도에 관련된 동작을 수행할 수 있다. 구체적으로, 사용자 음성에 대응되는 텍스트 정보에 사용자의 의도에 대한 정보 가 포함되면, 전자 장치는 사용자의 의도에 관련된 동작을 수행할 수 있는 어플리케이션을 식별하고, 식별 된 어플리케이션을 통해 사용자의 의도에 관련된 동작을 수행할 수 있다. 본 실시 예에 대해서는, 이하에서 도 13c에 도시된 바와 같은 예를 참조하여 설명한다. 먼저 전술한 바와 같이, 전자 장치가 냉장고인 경우 전자 장치는 전자 장치의 내부 이미지를 획 득하고, 획득된 이미지에 포함된 적어도 하나의 오브젝트로서 \"오이 샌드위치\"를 식별할 수 있다. 또한, 전자 장치는 사용자 음성을 수신하고, 수신된 사용자 음성에 대한 음성 인식을 수행하여, 사용자 음성에 대응되는 텍스트 정보로서 \"오이 샌드위치 먹고 딸기 3kg만 주문해 줘\"라는 텍스트 정보를 획득할 수 있 다. 그리고, 전자 장치는 이미지에 포함된 적어도 하나의 오브젝트 중 사용자 음성에 대응되는 오브젝트로서, \"오이 샌드위치\"를 식별하고, 디스플레이 상의 영역 중 \"오이 샌드위치\"에 대응되는 영역 상에 \"오 이 샌드위치 먹고 딸기 3kg만 주문해 줘\"라는 텍스트 정보를 포함하는 메모 UI를 표시할 수 있다.한편, 전자 장치는 획득된 텍스트 정보에 대한 자연어 이해를 수행하여, \"딸기 3kg 주문\"이라는 사용자의 의도에 대한 정보를 획득할 수 있다. 이 경우, 전자 장치는 전자 장치에 저장된 어플리케이션들 중 \"딸기 3kg 주문\"이라는 사용자의 의도에 관련된 어플리케이션으로서 쇼핑 어플리케이션을 식별하고, \"딸기 3kg\"을 쇼 핑 어플리케이션을 통해 제공되는 쇼핑 리스트에 추가할 수 있다. 한편, 사용자 음성에 대응되는 텍스트 정보에 사용자의 의도에 대한 정보가 포함되는 경우, 그 사용자의 의도에 대응되는 오브젝트는 도 13c에 도시된 바와 같이 사용자 음성에 대응되는 텍스트 정보를 바탕으로 식별될 수 있 을 뿐만 아니라, 사용자의 터치 인터렉션을 바탕으로 식별될 수도 있다. 예를 들어, 사용자 음성에 대응되는 텍 스트 정보에 \"사야겠다\" 및 \"추가해줘\"와 같은 사용자의 의도에 대한 정보가 포함되고, 디스플레이 상의 영역 중 \"딸기\"에 대응되는 영역 상에 사용자의 터치 인터렉션이 수신되면, 전자 장치는 \"딸기 주문\"이라는 사 용자의 의도에 대한 정보를 획득할 수 있다. 그리고, 전자 장치는 \"딸기 주문\"이라는 사용자의 의도에 관 련된 어플리케이션으로서 쇼핑 어플리케이션을 식별하고, \"딸기\"을 쇼핑 어플리케이션을 통해 제공되는 쇼핑 리 스트에 추가할 수 있다.상술한 바와 같은 실시 예에 따르면, 전자 장치는 사용자 음성에 대응되는 텍스트 정보에 사용자의 의도에 대한 정보가 포함된 경우, 메모 UI의 제공과 함께 사용자의 의도에 관련된 기능을 추가 적으로 제공함으로써 사용자의 편의성을 더욱 향상시킬 수 있게 된다. 도 14는 메모 UI를 전자 장치를 통해 제공되는 홈 화면에 표시하는 것에 관련된 실시 예를 설명하기 위한 도면이다. 이상에서는 디스플레이 상의 영역 중 사용자 음성에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 메 모 UI를 표시하는 실시 예에 대해 상술하였으나, 본 개시에 따라 메모 UI가 표시되는 영역이 이에 국한되는 것 은 아니며, 전자 장치의 OS(operating system)에 의해 제공되는 다양한 UI 영역 상에 표시될 수도 있다. 예를 들어, 전자 장치가 스마트 폰인 경우, 본 개시에 따른 메모 UI는 도 14에 도시된 바와 같이 스마트 폰의 홈 화면 상에 위젯 형태의 메모 UI로 표시될 수 있다. 뿐만 아니라, 메모 UI는 스마트 폰의 알림 바 또는 잠금 화면 등에 표시될 수도 있다. 한편, 메모 UI가 상술한 바와 같은 다양한 UI 영역 상에 표시되는 경우, 메모 UI가 표시되는 영역에 따라 UI의 크기 및 형태는 상이해 질 수 있음은 물론이다. 도 15a 및 도 15b는 사용자 음성에 대응되는 오브젝트의 위치가 이동되거나 사라진 경우에 관련된 실시 예를 설 명하기 위한 도면이다. 이상에서 상술한 바와 같이, 본 개시에 따른 전자 장치는 디스플레이 상의 영역 중 사용자 음성에 대응되 는 것으로 식별된 오브젝트에 대응되는 영역 상에 사용자 음성에 대응되는 텍스트 정보를 포함하는 메모 UI를 표시할 수 있다. 그런데, 본 개시에 따른 메모 UI가 표시된 후 사용자 음성에 대응되는 것으로 식별된 오브젝트의 위치는 이동될 수 있다. 여기서, 사용자 음성에 대응되는 것으로 식별된 오브젝트의 이동은, 본 개시에 따른 메모 UI가 표시되 기 전에 획득된 제1 이미지 내에서의 사용자 음성에 대응되는 것으로 식별된 오브젝트의 위치와 메모 UI가 표시 된 후에 획득된 제2 이미지 내에서의 사용자 음성에 대응되는 것으로 식별된 오브젝트의 위치를 비교함으로써 식별될 수 있다. 여기서, 제2 이미지란 제1 이미지가 획득된 후 제1 이미지와 동일한 장소를 촬영하여 획득된 이미지일 수 있다. 그리고, 제1 이미지 및 제2 이미지는 기 설정된 시간 간격에 따라 동일한 장소를 촬영하여 획득될 수 있으며, 뿐만 아니라 기 설정된 이벤트가 발생되는 것을 바탕으로 동일한 장소를 촬영하여 획득될 수도 있다. 예를 들어, 전자 장치가 냉장고인 경우, 전자 장치는 냉장고의 도어가 열렸다 닫히는 동작과 같은 기 설정 된 이벤트가 발생되면 냉장고 내부의 특정 장소를 촬영하여 제1 이미지를 획득하고, 제1 이미지가 획득된 후 냉 장고의 도어가 열렸다 닫히는 동작과 같은 기 설정된 이벤트가 다시 발생되면 제1 이미지의 획득 시 촬영된 장 소를 촬영하여 제2 이미지를 획득할 수 있다. 한편, 제1 이미지 및 제2 이미지 내에서 사용자 음성에 대응되는 것으로 식별된 오브젝트의 위치는 이미지 내에 서의 오브젝트의 중심점의 좌표 값, 특징 점의 좌표 값 및 텍스트 정보의 좌표 값 중 적어도 하나를 바탕으로식별될 수 있다. 사용자 음성에 대응되는 오브젝트의 이동이 식별되면, 전자 장치는 디스플레이 상의 영역 중 이동된 오브 젝트의 위치에 대응되는 영역 상에 메모 UI를 표시할 수 있다. 구체적으로, 전자 장치는 디스플레이 상의 영역 중 사용자 음성에 대응되는 오브젝트가 이동되기 전의 위치에 대응되는 영역 상에 표시된 메모 UI를 삭제 하고, 디스플레이 상의 영역 중 사용자 음성에 대응되는 오브젝트가 이동된 위치에 대응되는 영역 상에 메모 UI 를 표시할 수 있다. 예를 들어, 도 15a에 도시된 바와 같이, 전자 장치는 디스플레이 상의 영역 중 사용자 음성에 대응되는 오 브젝트인 \"샌드위치\"가 이동되기 전의 위치에 대응되는 영역 상에 표시된 메모 UI를 삭제하고, 디 스플레이 상의 영역 중 이동된 \"샌드위치\"의 위치에 대응되는 영역 상에 메모 UI를 표시할 수 있다. 한편, 본 개시에 따른 메모 UI가 표시된 후 사용자 음성에 대응되는 오브젝트는 삭제될 수 있다. 여기서, 사용 자 음성에 대응되는 오브젝트의 삭제 또한, 상술한 바와 같은 오브젝트의 이동과 마찬가지 방법으로 식별될 수 있다. 사용자 음성에 대응되는 오브젝트의 삭제가 식별되면, 전자 장치는 삭제 UI를 표시할 수 있다. 여기 서, 삭제 UI란 사용자가 디스플레이 상에 표시된 메모 UI의 삭제 여부를 선택할 수 있도록 하는 사용자 인터페이스를 말한다. 그리고, 삭제 UI를 통해 표시된 메모 UI를 삭제하는 것으로 선택하는 사용자 입력 이 수신되면, 전자 장치는 디스플레이 상에 표시된 메모 UI를 삭제할 수 있다. 이상에서, 메모 UI의 삭제 란 디스플레이 상에 표시된 메모 UI를 디스플레이 상에 표시되지 않도록 하는 것을 말한다. 예를 들어, 도 15b에 도시된 바와 같이, 사용자 음성에 대응되는 오브젝트의 삭제가 식별되면, 전자 장치 는 표시된 메모 UI에 대한 이미지와 함께 \"삭제할까요?\", \"YES\" 및 \"NO\"와 같은 구성요소를 포함하는 삭제 UI를 디스플레이 상에 표시할 수 있다. 그리고, 삭제 UI를 통해 표시된 메모 UI를 삭제하는 것으로 선택하는 사용자 입력이 수신되면, 전자 장치는 디스플레이 상에 표시된 메모 UI를 삭제할 수 있다. 상술한 바와 같은 본 개시의 다양한 실시 예에 따르면, 전자 장치는 사용자 음성에 대응되는 오브젝트의 이동과 삭제를 반영하여 사용자 인터페이스를 제공함으로써 사용자 음성을 발화한 이후에까지 사용자 경험을 향 상시킬 수 있게 된다. 도 16은 본 개시에 따른 전자 장치가 냉장고인 경우, 본 개시에 관련된 냉장고의 구조에 대해 간략하게 설 명하기 위한 도면이다. 전술한 바와 같이, 본 개시에 따른 전자 장치가 특정한 유형의 전자 장치에 국한되는 것은 아니지만, 특히 본 개시에 따른 전자 장치는 냉장고일 수 있다. 그리고, 도 16에 도시된 바와 같이, 냉장고는 디스플 레이, 전면 카메라 및 내부 카메라(1620, 1630) 등을 포함할 수 있다. 그 밖에도 냉장고는 냉기 공 급부를 포함하는 본체, 저장실, 복수의 도어, 복수의 도어를 본체와 연결하는 힌지 등을 포함할 수 있으나, 이 하에서는 본 개시에 따른 실시 예에 관련된 구성을 중심으로 설명한다. 디스플레이는 영상 데이터를 출력할 수 있다. 구체적으로, 디스플레이는 프로세서의 제어에 의하여 메모리에 기 저장된 영상을 출력할 수 있다. 특히, 본 개시에 따른 디스플레이는 프로세서의 제어에 의해 적어도 하나의 오브젝트를 포함하는 이미지를 표시할 수 있으며, 메모 UI, 선택 UI 및 삭제 UI 등과 같은 사용 자 인터페이스(User Interface)를 표시할 수도 있다. 한편, 본 개시에 따른 디스플레이는 투명 디스플레이로 구현될 수 있다. 투명 디스플레이는 투명한 산화물 반도체막을 포함하도록 구현되어 투명한 성질을 가질 수 있으며, 그에 따라 디스플레이 후면에 배치된 사 물 또는 이미지를 표시할 수 있다. 특히, 본 개시에 따른 전자 장치가 냉장고인 경우, 디스플레이는 투명 디스플레이로 구현될 수 있다. 그리고, 디스플레이가 투명 디스플레이로 구현되는 경우, 전자 장치 는 냉장고 내부에 배치된 적어도 하나의 오브젝트를 투명 디스플레이 상에 투사하거나, 투명 디스플레이를 투과하도록 함으로써, 투명 디스플레이 상에 적어도 하나의 오브젝트를 포함하는 이미지를 표시할 수 있다. 한편, 디스플레이는 복수의 도어 중 적어도 하나의 도어 외부에 배치될 수 있다. 그리고, 디스플레이(11 0)는 투명 디스플레이와 일반적인 디스플레이를 모두 포함할 수 있다. 또한 디스플레이는 스피 커(미도시)와 인접하는 위치에 배치되어, 사용자에게 디스플레이를 통한 시각적 경험과 함께 스피커를 통한 청각적 경험을 일체로 제공할 수 있다. 내부 카메라(1620, 1630)는 냉장고의 내부를 촬영할 수 있다. 구체적으로, 내부 카메라(1620, 1630)는 통상적인 카메라 및 분광 이미지를 획득할 수 있는 분광 카메라를 포함할 수 있다. 내부 카메라(1620, 163 0)는 도 16에 도시된 바와 같이, 복수의 도어 내부에 배치되어 냉장고의 내부를 촬영할 수 있으며, 그에 따라 전자 장치는 냉장고의 내부 이미지를 획득할 수 있다. 그리고, 내부 카메라(1620, 1630)를 통해 획득된 냉 장고의 내부 이미지는 디스플레이 상에 표시될 수 있다. 한편, 내부 카메라(1620, 1630)에 인접한 위치에는 근접 센서가 배치될 수 있다. 그리고, 근접 센서를 통해 복 수의 도어 중 적어도 하나가 열렸다 닫히는 동작이 감지되면, 전자 장치는 내부 카메라(1620, 1630)를 통 해 냉장고 내부의 특정 장소를 촬영하여 냉장고의 내부 이미지를 획득할 수 있다. 전면 카메라는 냉장고의 외부를 촬영할 수 있다. 구체적으로, 전면 카메라는 디스플레이의 상 부와 같이 냉장고의 외부를 촬영하기에 적합한 위치에 배치되어 냉장고의 외부를 촬영할 수 있으며, 그에 따라 냉장고의 외부 이미지가 획득될 수 있다. 특히, 전면 카메라는 냉장고 외부의 사용자를 촬영할 수 있다. 그리고, 전면 카메라를 통해 사용자 이미지가 획득되면, 전자 장치는 전술한 바와 같이 획득된 사용 자 이미지에 대한 객체 인식을 수행하여 사용자 음성을 발화한 사용자를 식별할 수 있다. 그리고, 사용자 음성 을 발화한 사용자가 식별되면, 전자 장치는 식별된 사용자에 따라 메모 UI를 통해 표시되는 텍스트 정보의 크기, 폰트 및 색상 등을 상이하게 결정할 수 있으며, 또한 식별된 사용자의 사용자 단말로 사용자 음성에 대응 되는 텍스트 정보를 전송할 수도 있다. 도 17은 본 개시에 따른 전자 장치의 구성을 상세하게 나타내는 블록도이다. 도 17에 도시된 바와 같이, 전자 장치는 디스플레이, 마이크, 메모리 및 프로세서를 포함할 뿐만 아니라, 통신부, 카메라, 스피커 및 입력 버튼 등을 포함할 수 있다. 그러나, 이와 같은 구성은 예시적인 것으로서, 본 개시를 실시함에 있어 이와 같은 구성에 더하여 새로운 구성이 추가되 거나 일부 구성이 생략될 수 있음을 물론이다. 마이크, 디스플레이, 메모리 및 프로세서에 대해서는 도 3a 및 도 3b를 참조하여 전술하였으므로, 이하에서는 통신부, 카메라, 스피커 및 입력 버튼에 대해 상술한다. 통신부는 회로를 포함하며, 외부 장치와의 통신을 수행할 수 있다. 구체적으로, 프로세서는 통신부 를 통해 연결된 외부 장치로부터 각종 데이터 또는 정보를 수신할 수 있으며, 외부 장치로 각종 데이터 또 는 정보를 전송할 수도 있다. 통신부는 WiFi 모듈, Bluetooth 모듈, 무선 통신 모듈, 및 NFC 모듈 중 적어도 하나를 포함할 수 있다. 구 체적으로, WiFi 모듈과 Bluetooth 모듈 각각은 WiFi 방식, Bluetooth 방식으로 통신을 수행할 수 있다. WiFi 모듈이나 Bluetooth 모듈을 이용하는 경우에는 SSID 등과 같은 각종 연결 정보를 먼저 송수신하여, 이를 이용하 여 통신 연결한 후 각종 정보들을 송수신할 수 있다. 또한, 무선 통신 모듈은 IEEE, Zigbee, 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), 5G(5th Generation) 등과 같은 다양한 통신 규격에 따라 통신을 수행할 수 있다. 그리고, NFC 모듈은 135kHz, 13.56MHz, 433MHz, 860~960MHz, 2.45GHz 등과 같은 다양한 RF-ID 주파수 대역들 중에서 13.56MHz 대역을 사용하는 NFC(Near Field Communication) 방식으로 통신을 수행할 수 있다. 특히, 본 개시에 따르면, 프로세서는 획득된 이미지 및 수신된 사용자 음성 중 적어도 하나를 외부 장치로 전송하도록 통신부를 제어하고, 통신부를 통해 외부 장치로부터 이미지에 포함된 오브젝트에 대한 정 보 및 사용자 음성에 대응되는 텍스트 정보 중 적어도 하나를 수신할 수 있다. 또한, 사용자 음성에 대응되는 텍스트 정보에 기 저장된 사용자의 명칭이 포함되면, 프로세서는 사용자 명칭에 대응되는 사용자 단말에 텍스트 정보를 전송하도록 통신부를 제어할 수 있다. 카메라는 전자 장치의 내부 또는 외부에 배치되어, 전자 장치의 내부 또는 외부에 대한 이미지 를 촬영할 수 있다. 그리고, 프로세서는 카메라를 통해 전자 장치의 내부 또는 외부에 대한 이 미지를 획득할 수 있다. 특히, 본 개시에 따른 전자 장치가 냉장고인 경우, 프로세서는 냉장고의 도 어가 열렸다 닫히는 동작과 같은 기 설정된 이벤트가 발생되면 냉장고의 내부를 촬영하여 냉장고 내부의 이미지 를 획득할 수 있으며, 뿐만 아니라 기 설정된 시간 간격으로 냉장고의 내부를 촬영하여 냉장고 내부의 이미지를획득할 수도 있다. 스피커는 사운드를 출력할 수 있다. 구체적으로, 스피커는 프로세서의 제어에 의해 본 개시에 따른 오디오 데이터를 바탕으로 사운드를 출력할 수 있다. 특히, 본 개시에 따른 사용자 음성에 대응되는 텍스 트 정보에 기한에 대한 정보가 포함되면, 프로세서는 스피커를 통해 기한에 대한 정보에 관련된 사운 드를 출력할 수 있다. 그리고, 프로세서는 본 개시에 따른 사용자 음성에 대한 응답 음성을 획득하고, 획 득된 응답 음성을 스피커를 통해 출력할 수도 있다. 입력 버튼은 다양한 종류의 사용자 입력을 수신할 수 있다. 특히, 본 개시에 따른 입력 버튼은 음성 인식을 수행하기 위한 트리거 입력을 수신할 수 있다. 트리거 입력은 기 설정된 트리거 워드를 포함하는 사용자 음성의 형태로 마이크를 통해 수신될 수 있을 뿐만 아니라. 트리거 입력을 수신하도록 전자 장치에 배치된 입력 버튼을 통해 수신될 수도 있다. 여기서, 입력 버튼은 물리적으로 전자 장치의 외부에 배치된 물리 버튼뿐만 아니라 터치 디스플레이 상에 표시된 UI의 형태로 구현된 소프트 버튼일 수 도 있다. 도 18a 및 도 18b는 본 개시에 따라 제공되는 인디케이터에 관련된 실시 예를 설명하기 위한 도면이다. 도 2를 통해 상술한 바와 같이, 수신된 사용자 음성은 그 전체가 음성 인식의 대상이 될 수도 있지만, 수신된 사용자 음성 중 일부만이 음성 인식의 대상이 될 수도 있다. 여기서, 음성 인식의 대상이 되는 사용자 음성은 기 설정된 시작점과 종료점을 바탕으로 특정될 수 있다. 특히, 본 개시의 일 실시 예에 따르면, 음성 인식의 대상이 되는 사용자 음성을 특정하기 위한 시작점과 종료점 은 디스플레이 상에 수신된 사용자의 터치 인터렉션을 바탕으로 특정될 수 있다. 구체적으로, 전자 장치는 디스플레이 상에 사용자의 트리거 입력에 대응되는 것으로 기 설정된 터치 인터렉션이 수신된 시점부터 사용자 의 터치 인터렉션이 종료된 시점까지 수신된 사용자 음성에 대해 음성 인식을 수행하여 사용자 음성에 대응되는 텍스트 정보를 획득할 수 있다. 한편, 디스플레이 상에 사용자의 터치 인터렉션이 유지되는 동안, 전자 장치는 인디케이터가 표시되는 동 안 수신되는 사용자 음성이 음성 인식의 대상이 된다는 점을 나타내는 인디케이터를 디스플레이 상에 표시할 수 있다. 구체적으로, 디스플레이 상에 사용자의 터치 인터렉션이 수신되면, 전자 장치는 인디케이터가 표시 되는 동안 수신되는 사용자 음성이 음성 인식의 대상이 된다는 점을 나타내는 인디케이터를 표시할 수 있으며, 디스플레이 상에 수신된 사용자의 터치 인터렉션이 종료되면, 표시된 인디케이터를 삭제할 수 있다. 예를 들어, 본 개시에 따른 인디케이터는 도 18a에 도시된 바와 같이 마이크 모양의 UI를 통해 제공될 수 있으며, 도 18b에 도시된 바와 같이 \"음성 인식 중입니다\"와 같은 메시지를 포함하는 UI를 통해 제공될 수도 있다. 상술한 바와 같이 본 개시에 따른 인디케이터가 제공되면, 전자 장치의 사용자는 인디케이터가 표시되는 동안 수신되는 사용자 음성이 음성 인식의 대상이 된다는 점을 파악하면서, 메모 UI를 통해 표시하기를 원하는 텍스트 정보에 대응되도록 발화를 수행할 수 있게 된다. 그리고, 이에 따라 전자 장치는 사용자의 의도에 부합하는 메모 UI를 표시할 수 있게 된다. 도 19는 본 개시에 따른 객체 인식 및 음성 인식 과정이 전자 장치와 연결된 서버를 통해 수행되는 실시 예를 설명하기 위한 도면이다. 이상에서는 전자 장치에 의해 본 개시에 따른 과정이 모두 전자 장치에 수행되는 것을 전제로 본 개 시에 따른 다양한 실시 예에 대해 설명하였으나, 본 개시가 이에 국한되는 것은 아니다. 즉, 본 개시에 따른 과 정 중 적어도 일부의 과정은 외부 장치 내지는 서버를 통해 수행될 수 있다. 특히, 본 개시에 따른 객체 인식 및 음성 인식 과정 중 적어도 하나의 과정은 객체 인식 모듈 및/또는 ASR 모듈을 포함하는 서버를 통해 수행될 수도 있다. 이하에서는 도 19를 참조하여 본 개시에 따른 객체 인식 및 음성 인식 과정이 모두 서버를 통해 수행되는 경우 에 대해 설명하되, 이상에서 상술한 바와 같은 내용에 대한 중복 설명은 생략한다. 전자 장치는 적어도 하나의 오브젝트를 포함하는 이미지를 획득할 수 있다(S1910). 적어도 하나의 오브젝 트를 포함하는 이미지가 획득되면, 전자 장치는 획득된 이미지를 서버로 전송할 수 있다(S1915). 그리고, 서버는 수신된 이미지를 바탕으로 이미지에 포함된 적어도 하나의 오브젝트를 식별할 수 있다(S1920). 이미지에 포함된 적어도 하나의 오브젝트가 식별되면, 서버는 적어도 하나의 오브젝트에 대한 정보를 전자 장치에 전송할 수 있다(S1925). 한편, 전자 장치는 사용자 음성을 수신할 수 있다(S1930). 사용자 음성이 수신되면, 전자 장치는 수 신된 사용자 음성을 서버로 전송할 수 있다(S1935). 서버는 수신된 사용자 음성을 바탕으로 사용자 음성에 대응 되는 텍스트 정보를 획득할 수 있다(S1940). 그리고, 사용자 음성에 대응되는 텍스트 정보가 획득되면, 서버는 사용자 음성에 대응되는 텍스트 정보를 전자 장치로 전송할 수 있다(S1945). 한편, 전자 장치는 이미지에 포함된 적어도 하나의 오브젝트 중 수신된 사용자 음성에 대응되는 오브젝트 를 식별할 수 있다(S1950). 사용자 음성에 대응되는 오브젝트는 사용자 음성에 대응되는 텍스트 정보 및 수신된 사용자의 터치 인터렉션 중 적어도 하나를 바탕으로 식별될 수 있다. 그리고, 사용자 음성에 대응되는 오브젝트가 식별되면, 전자 장치는 디스플레이 상의 영역 중 사용자 음성 에 대응되는 것으로 식별된 오브젝트에 대응되는 영역 상에 텍스트 정보를 포함하는 메모 UI를 표시할 수 있다 (S1955). 한편, 이상에서는 객체 인식 및 음성 인식 과정이 모두 하나의 서버를 통해 수행되는 것으로 전제하였으나, 본 개시에 따른 객체 인식 및 음성 인식 과정은 각각의 과정을 수행할 수 있는 복수의 서버를 통해 수행될 수도 있 음은 물론이다. 도 1 내지 도 19를 참조하여 상술한 바와 같은 본 개시의 다양한 실시 예에 따르면, 상술한 바와 같은 본 개시 의 다양한 실시 예에 따르면, 전자 장치는 디스플레이 상에 텍스트 정보를 포함하는 메모 UI가 표시되는 영역을 지정하는 별도의 사용자 조작 없이, 사용자 음성에 대응되는 텍스트 정보만을 바탕으로 사용자가 원하는 영역 상에 메모 UI를 표시할 수 있게 된다. 또한, 전자 장치는 사용자의 터치 인터렉션을 바탕으로 음성 인식의 대상이 되는 사용자 음성을 특정함과 동시에 메모 UI가 표시되는 영역을 결정하여 메모 UI를 표시할 수 있게 된다. 이에 따라, 전자 장치의 사용자는 직관적이고도 간편한 방법으로 사용자 인터페이스를 통해 사용자 음성에 대응되는 텍스트 정보를 생성하고, 사용자의 의도에 부합하는 디스플레이 상의 영역에 생성된 텍스트 정보를 표 시할 수 있게 된다. 한편, 이상에서 상술한 바와 같은 전자 장치의 제어 방법, 프로세서의 제어 과정 및 그에 따른 다양한 실 시 예는 프로그램으로 구현되어 전자 장치에 제공될 수 있다. 특히, 전자 장치의 제어 방법을 포함하 는 프로그램은 비일시적 판독 가능 매체(non-transitory computer readable medium)에 저장되어 제공될 수 있 다. 여기서, 비일시적 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로 는, 상술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있다. 한편, 이상에서 상술한 바와 같은 복수의 모듈 중 적어도 하나는 인공 지능 모델을 통해 구현될 수 있다. 그리 고, 본 개시에 따른 인공 지능과 관련된 기능은 메모리 및 프로세서를 통해 수행된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP 등과 같 은 범용 프로세서, GPU. VPU 등과 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공 지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 비휘발성 메모리 및 휘발성 메모리에 저장된 기 정의된 동작 규칙 또는 인공 지 능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 기 정의된 동작 규칙 또는 인공 지능 모델은 학습을 통해만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만들어진다는 것은, 다수의 학습 데이터들에 학습 알고리즘을 적용함으로써, 원하는 특성 의 기 정의된 동작 규칙 또는 인공 지능 모델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공 지능 이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버/시스템을 통해 이루어 질 수도 있다. 인공 지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 각 레이어는 복수의 가중치(weight values)을 갖 고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치의 연산을 통해 레이어의 연산을 수행한다. 신 경망의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network), GAN(Generative Adversarial Networks) 및 심층 Q-네트워크 (Deep Q-Networks)이 있으 며, 본 개시에서의 신경망은 명시한 경우를 제외하고 전술한 예에 한정되지 않는다. 학습 알고리즘은, 다수의 학습 데이터들을 이용하여 소정의 대상 기기(예컨대, 로봇)을 훈련시켜 소정의 대상 기기 스스로 결정을 내리거나 예측을 할 수 있도록 하는 방법이다. 학습 알고리즘의 예로는, 지도형 학습 (supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또 는 강화 학습(reinforcement learning)이 있으며, 본 개시에서의 학습 알고리즘은 명시한 경우를 제외하고 전술 한 예에 한정되지 않는다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2019-0122061", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시가 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어서는 안 될 것이다."}
{"patent_id": "10-2019-0122061", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시에 따른 전자 장치의 제어 과정을 간략하게 설명하기 위한 개념도, 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 나타내는 흐름도, 도 3a는 본 개시에 따른 전자 장치의 구성을 간략하게 나타내는 블록도, 도 3b는 도 3a에 도시된 바와 같은 전자 장치의 하드웨어 구성과 본 개시에 따른 소프트웨어 모듈 사이의 결합 관계를 전제로 본 개시에 따른 실시 예를 설명하기 위한 도면, 도 4는 본 개시에 따른 객체 인식 과정을 보다 상세하게 설명하기 위한 도면, 도 5는 본 개시에 따른 음성 인식 과정을 보다 상세하게 설명하기 위한 도면, 도 6은 전자 장치가 사용자 음성에 대응되는 텍스트 정보를 바탕으로 사용자 음성에 대응되는 오브젝트를 식별 하는 실시 예를 설명하기 위한 도면, 도 7a 내지 도 7c는 전자 장치가 사용자의 터치 인터렉션을 바탕으로 사용자 음성에 대응되는 오브젝트를 식별 하는 실시 예를 설명하기 위한 도면, 도 8a 및 도 8b는 사용자의 터치 인테렉션을 바탕으로 메모 UI의 크기 및 형태를 상이하게 표시하는 것에 관련 된 실시 예를 설명하기 위한 도면, 도 9a 및 도 9b는 본 개시에 따른 메모 UI에 관련된 다양한 유형을 설명하기 위한 도면, 도 10a는 본 개시에 따라 사용자 음성에 대응되는 오브젝트를 식별하는 과정 및 사용자 음성에 대응되는 오브젝 트가 2 개 이상인 경우에 관련된 실시 예를 통합적으로 설명하기 위한 도면, 도 10b는 디스플레이 상에 사용자의 터치 인터렉션이 수신된 영역 상에 메모 UI를 표시하는 실시 예를 설명하기 위한 도면, 도 11a 및 도 11b는 사용자 음성에 대응되는 것으로 식별된 오브젝트가 2 개 이상인 경우 선택 UI를 제공하는 것에 관련된 실시 예를 상세하게 설명하기 위한 도면, 도 12은 사용자 음성에 대응되는 텍스트 정보에 대명사가 포함되는 경우에 관련된 실시 예를 설명하기 위한 도 면, 도 13a는 사용자 음성에 대응되는 텍스트 정보에 사용자 명칭에 대한 정보가 포함되는 경우에 관련된 실시 예를 설명하기 위한 도면, 도 13b는 사용자 음성에 대응되는 텍스트 정보에 오브젝트의 기한에 대한 정보가 포함되는 경우에 관련된 실시 예를 설명하기 위한 도면, 도 13c는 사용자 음성에 대응되는 텍스트 정보에 사용자의 의도에 대한 정보가 포함되는 경우에 관련된 실시 예 를 설명하기 위한 도면, 도 14는 메모 UI를 전자 장치를 통해 제공되는 홈 화면에 표시하는 것에 관련된 실시 예를 설명하기 위한 도면, 도 15a 및 도 15b는 사용자 음성에 대응되는 오브젝트의 위치가 이동되거나 사라진 경우에 관련된 실시 예를 설 명하기 위한 도면, 도 16은 본 개시에 따른 전자 장치가 냉장고인 경우, 본 개시에 관련된 냉장고의 구조에 대해 간략하게 설명하 기 위한 도면, 도 17은 본 개시에 따른 전자 장치의 구성을 상세하게 나타내는 블록도, 도 18a 및 도 18b는 본 개시에 따라 제공되는 인디케이터에 관련된 실시 예를 설명하기 위한 도면, 그리고, 도 19는 본 개시에 따른 객체 인식 및 음성 인식 과정이 전자 장치와 연결된 서버를 통해 수행되는 실시 예를 설명하기 위한 도면이다."}
