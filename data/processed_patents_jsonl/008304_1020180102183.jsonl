{"patent_id": "10-2018-0102183", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0025200", "출원번호": "10-2018-0102183", "발명의 명칭": "전자 장치 및 전자 장치의 동작 방법", "출원인": "삼성전자주식회사", "발명자": "김철민"}}
{"patent_id": "10-2018-0102183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "학습 데이터와 가중치들을 이용하여 객체 인식 모델을 학습시켜 학습된 객체 인식 모델을 제공하는 인공 신경망엔진을 구비하는 그래픽 프로세서; 및상기 학습 데이터와 상기 가중치들을 저장하고, 상기 학습 데이터와 상기 가중치들을 상기 그래픽 프로세서에제공하고, 입력 데이터로부터 추출된 특징 벡터를 제1 서브 특징 벡터와 제2 서브 특징 벡터로 분할하고, 상기제1 서브 특징 벡터를 상기 그래픽 프로세서에 제공하고, 상기 학습된 객체 인식 모델을 상기 그래픽 프로세서로부터 수신하고, 상기 제2 서브 특징 벡터와 상기 가중치들을 상기 제2 학습된 객체 인식 모델에 적용하여 제2객체 인식 결과를 제공하는 제1 연산을 수행하는 적층형 메모리 장치를 포함하고,상기 인공 신경망 엔진은 상기 제1 연산과 병렬적으로 상기 제1 서브 특징 벡터와 상기 가중치들을 상기 학습된객체 인식 모델에 적용하여 제1 객체 인식 결과를 생성하는 제2 연산을 수행하고, 상기 제1 객체 인식 결과를상기 적층형 메모리 장치에 제공하는 전자 장치."}
{"patent_id": "10-2018-0102183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 적층형 메모리 장치는 상기 제1 객체 인식 결과를 저장하고, 상기 제1 객체 인식 결과와 상기 제2 객체 인식 결과를 병합하여 병합된 객체 인식 결과를 사용자에게 제공하고,상기 적층형 메모리 장치는상기 그래픽 프로세서 및 외부 장치와 통신하는 버퍼 다이;상기 상기 버퍼 다이 상에 적층되는 복수의 메모리 다이들; 및상기 메모리 다이들을 관통하는 복수의 관통 실리콘 비아(through silicon via)들을 포함하고,상기 메모리 다이들 각각은 복수의 워드라인들과 복수의 비트라인들에 연결되며, 상기 학습 데이터, 상기 가중치들 및 상기 특징 벡터를 저장하는 복수의 동적 메모리 셀들을 구비하는 메모리 셀 어레이를 포함하고,상기 버퍼 다이는 상기 관통 실리콘 비아들을 통하여 상기 메모리 다이들과 연결되고 상기 특징 벡터를 상기 제1 서브 특징 벡터와 상기 제2 서브 특징 벡터로 분할하고, 상기 제1 연산을 수행하는 프로세서-인-메모리(processor-in-memory) 회로를 포함하는 전자 장치."}
{"patent_id": "10-2018-0102183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 프로세서-인-메모리 회로는상기 메모리 다이들 중 적어도 일부로부터 상기 특징 벡터를 수신하고, 상기 특징 벡터를 상기 제1 서브 특징벡터와 상기 제2 서브 특징 벡터로 분할하고, 상기 제1 서브 특징 벡터를 상기 그래픽 프로세서에 제공하는 데이터 분배기; 상기 데이터 분배기로부터 상기 제2 서브 특징 벡터를 수신하고, 상기 제2 서브 특징 벡터에 상기 웨이트들을적용하여 상기 제1 연산을 수행하여 상기 제2 객체 인식 결과를 출력하는 곱셈 및 누적 회로; 및상기 곱셈 및 누적 회로를 제어하는 컨트롤러를 포함하고,상기 곱셈 및 누적 회로는 상기 제2 서브 특징 벡터와 상기 웨이트들에 대하여 행렬-벡터 곱셈 연산을 수행하는전자 장치."}
{"patent_id": "10-2018-0102183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 공개특허 10-2020-0025200-3-버스를 통하여 상기 그래픽 프로세서 및 상기 적층형 메모리 장치와 통신하는 중앙 처리 장치를 포함하고,상기 중앙 처리 장치는 상기 데이터 분배기와 상기 컨트롤러를 제어하는 시스템 소프트웨어를 포함하고,상기 시스템 소트프웨어는 상기 제1 서브 특징 벡터와 상기 제2 서브 특징 벡터의 분할 비율을 결정하는 전자장치."}
{"patent_id": "10-2018-0102183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 버퍼 다이는 상기 제1 연산과 상기 제2 연산이 종료된 경우, 상기 제1 서브 인식 결과와 상기 제2 서브 결과를 수신하고, 상기 제1 서브 인식 결과와 상기 제2 서브 인식 결과를 병합하여 병합된 객체 인식 결과를 출력하는 병합기; 및상기 버퍼 다이 상에 형성되며, 상기 학습된 객체 인식 모델을 저장하는 비휘발성 메모리를 더 포함하는 전자장치."}
{"patent_id": "10-2018-0102183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제1 서브 특징 벡터와 상기 제2 서브 특징 벡터는 적어도 일부의 중복 데이터를 포함하고, 상기 그래픽 프로세서는 상기 중복 데이터에 대한 중간 연산 결과를 상기 적층형 메모리 장치에 제공하고, 상기 적층형 메모리 장치는 상기 중복 데이터에 대한 상기 중간 연산 결과를 이용하여 상기 제1 연산을 수행하는 전자 장치."}
{"patent_id": "10-2018-0102183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 인공 신경망 엔진은 상기 학습 데이터와 상기 가중치들을 상기 객체 인식 모델에 적용한 결과와 상기 학습데이터에 대한 기대값의 유사도가 제1 기준값 이상인 경우에 상기 학습된 객체 인식 모델을 상기 적층형 메모리장치에 제공하고, 상기 객체 인식 모델은 복수의 네트워크 노드들 간의 연결관계 및 상기 복수의 네트워크 노드들의 상기 가중치들에 기초하여 연산을 수행하는 신경망 모델 또는 딥러닝 모델인 전자 장치."}
{"patent_id": "10-2018-0102183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 객체 인식 모델은상기 학습 데이터 또는 상기 제1 서브 특징 벡터를 수신하며, 입력 노드들을 포함하는 입력 레이어;상기 학습 데이터 또는 상기 제1 서브 특징 벡터에 대한 출력을 제공하며 출력 노드들을 포함하는 출력 레이어;상기 입력 레이어를 상기 출력 레이어에 연결시키며, 히든 노드들을 포함하는 히든 레이어상기 입력 노드들 각각과 상기 히든 노드들 각각을 제1 가중치들을 가지고 연결하는 제1 연결선들; 및상기 히든 노드들 각각과 상기 출력 노드들 각각을 제2 가중치들을 가지고 연결하는 제2 연결선들을 포함하는전자 장치."}
{"patent_id": "10-2018-0102183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "학습 데이터와 웨이트들을 제공하고, 객체를 구성하는 객체 데이터로부터 추출된 특징 벡터를 제공하는 어플리케이션 프로세서; 상기 학습 데이터와 가중치들을 이용하여 객체 인식 모델을 학습시켜 학습된 객체 인식 모델을 제공하는 인공신경망 엔진을 구비하는 그래픽 프로세서; 및상기 프로세서로부터 수신된 상기 학습 데이터, 상기 웨이트들 및 상기 특징 벡터들을 저장하고, 상기 학습 데공개특허 10-2020-0025200-4-이터와 상기 가중치들을 상기 그래픽 프로세서에 제공하고, 상기 특징 벡터를 제1 서브 특징 벡터와 제2 서브특징 벡터로 분할하고, 상기 제1 서브 특징 벡터를 상기 그래픽 프로세서에 제공하고, 상기 그래픽 프로세서로부터 수신된 상기 학습된 객체 인식 모델을 저장하고, 상기 제2 서브 특징 벡터와 상기 가중치들을 상기 제2 학습된 객체 인식 모델에 적용하여 제2 객체 인식 결과를 제공하는 제1 연산을 수행하는 적층형 메모리 장치를 포함하고, 상기 인공 신경망 엔진은 상기 제1 연산과 병렬적으로 상기 제1 서브 특징 벡터와 상기 가중치들을 상기 학습된객체 인식 모델에 적용하여 제1 객체 인식 결과를 생성하는 제2 연산을 수행하고, 상기 제1 객체 인식 결과를상기 적층형 메모리 장치에 제공하는 전자 장치."}
{"patent_id": "10-2018-0102183", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "인공 신경망 엔진을 구비하는 그래픽 프로세서 및 상기 그래픽 프로세서와 통신하는 적층형 메모리 장치를 구비하는 전자 장치의 동작 방법으로서, 상기 인공 신경망 엔진에서 학습 데이터와 가중치들을 객체 인식 모델에 적용하여 상기 객체 인식 모델을 학습시키는 단계;상기 적층형 메모리 장치의 데이터 분배기에서 입력 데이터와 관련된 특징 벡터를 제1 서브 특징 벡터와 제2 서브 특징 벡터로 분할하고, 상기 제2 서브 특징 벡터를 상기 그래픽 프로세서에 제공하는 단계;상기 적층형 메모리 장치의 곱셈 및 누적 회로에서 상기 제2 서브 특징 벡터와 상기 가중치들을 상기 학습된 객체 인식 모델에 적용하여 제2 객체 인식 결과를 출력하는 제1 연산을 수행하는 단계;상기 그래픽 프로세서의 상기 인공 신경망 엔진에서 상기 제1 서브 특징 벡터와 상기 가중치들을 상기 학습된객체 인식 모델에 적용하여 제1 객체 인식 결과를 출력하는 제2 연산을 수행하는 단계; 및상기 적층형 메모리 장치의 합성기에서 상기 제1 객체 인식 결과와 상기 제2 객체 인식 결과를 병합하여 병합된객체 인식 결과를 사용자에게 제공하는 단계를 포함하고,상기 제1 연산과 상기 제2 연산은 병렬적으로 수행되는 전자 장치의 동작 방법."}
{"patent_id": "10-2018-0102183", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치는 그래픽 프로세서 및 적층형 메모리 장치를 포함한다. 상기 그래픽 프로세서는 학습 데이터와 가중치 들을 이용하여 객체 인식 모델을 학습시켜 학습된 객체 인식 모델을 제공하는 인공 신경망 엔진을 구비한다. 상 기 적층형 메모리 장치는 상기 학습 데이터와 상기 가중치들을 저장하고, 상기 학습 데이터와 상기 가중치들을 (뒷면에 계속)"}
{"patent_id": "10-2018-0102183", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공 지능 분야에 관한 것으로, 보다 상세하게는 성능을 높일 수 있는 전자 장치 및 전자 장치의 동 작 방법에 관한 것이다."}
{"patent_id": "10-2018-0102183", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "컴퓨터, 스마트폰 등의 정보 기기의 보급으로 인하여 디지털 컴퓨터의 응용 및 디지털 신호처리 기술이 발전하 게 되었다. 특히, 근래에는 인공 지능, 영상인식(Video/Motion Recognition), 딥러닝(Deep learning), 기계학습(Machine Learning) 등의 기술이 발전함으로써, 음성, 이미지, 동영상 또는 텍스트와 같은 데이터를 자동(Automation)으 로 인식하여 데이터와 연관된 정보를 제공하거나 데이터와 관련된 서비스를 제공하는 지능형 서비스 (Intelligent Service)가 다양한 분야에서 사용되고 있다. 또한 최근에는 지능형 서비스가 에지 디바이스(edge device)에 채택되고 있다."}
{"patent_id": "10-2018-0102183", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 목적은 인공 지능 연산을 병렬적으로 수행할 수 있는 구조를 가지는 전자 장치를 제공하는 것이다. 본 발명의 일 목적은 인공 지능 연산을 병렬적으로 수행할 수 있는 전자 장치의 동작 방법을 제공하는 것이다."}
{"patent_id": "10-2018-0102183", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예들에 따른 전자 장치는 그래픽 프로세서 및 적층형 메모리 장치를 포함한다. 상기 그래픽 프로 세서는 학습 데이터와 가중치들을 이용하여 객체 인식 모델을 학습시켜 학습된 객체 인식 모델을 제공하는 인공 신경망 엔진을 구비한다. 상기 적층형 메모리 장치는 상기 학습 데이터와 상기 가중치들을 저장하고, 상기 학습 데이터와 상기 가중치들을 상기 그래픽 프로세서에 제공하고, 입력 데이터로부터 추출된 특징 벡터를 제1 서브 특징 벡터와 제2 서브 특징 벡터로 분할하고, 상기 제1 서브 특징 벡터를 상기 그래픽 프로세서에 제공하고, 상 기 학습된 객체 인식 모델을 상기 그래픽 프로세서로부터 수신하고, 상기 제2 서브 특징 벡터와 상기 가중치들 을 상기 제2 학습된 객체 인식 모델에 적용하여 제2 객체 인식 결과를 제공하는 제1 연산을 수행한다. 상기 인 공 신경망 엔진은 상기 제1 연산과 병렬적으로 상기 제1 서브 특징 벡터와 상기 가중치들을 상기 학습된 객체 인식 모델에 적용하여 제1 객체 인식 결과를 생성하는 제2 연산을 수행하고, 상기 제1 객체 인식 결과를 상기 적층형 메모리 장치에 제공한다. 본 발명의 실시예들에 따른 전자 장치는 어플리케이션 프로세서, 그래픽 프로세서 및 적층형 메모리 장치를 포 함한다. 상기 어플리케이션 프로세서는 학습 데이터와 웨이트들을 제공하고, 객체를 구성하는 객체 데이터로부 터 추출된 특징 벡터를 제공한다. 상기 그래픽 프로세서는 상기 학습 데이터와 가중치들을 이용하여 객체 인식 모델을 학습시켜 학습된 객체 인식 모델을 제공하는 인공 신경망 엔진을 구비한다. 상기 적층형 메모리 장치는 상기 프로세서로부터 수신된 상기 학습 데이터, 상기 웨이트들 및 상기 특징 벡터들을 저장하고, 상기 학습 데 이터와 상기 가중치들을 상기 그래픽 프로세서에 제공하고, 상기 특징 벡터를 제1 서브 특징 벡터와 제2 서브 특징 벡터로 분할하고, 상기 제1 서브 특징 벡터를 상기 그래픽 프로세서에 제공하고, 상기 그래픽 프로세서로 부터 수신된 상기 학습된 객체 인식 모델을 저장하고, 상기 제2 서브 특징 벡터와 상기 가중치들을 상기 제2 학 습된 객체 인식 모델에 적용하여 제2 객체 인식 결과를 제공하는 제1 연산을 수행한다. 상기 인공 신경망 엔진 은 상기 제1 연산과 병렬적으로 상기 제1 서브 특징 벡터와 상기 가중치들을 상기 학습된 객체 인식 모델에 적 용하여 제1 객체 인식 결과를 생성하는 제2 연산을 수행하고, 상기 제1 객체 인식 결과를 상기 적층형 메모리 장치에 제공한다. 본 발명의 실시예들에 따른 인공 신경망 엔진을 구비하는 그래픽 프로세서 및 상기 그래픽 프로세서와 통신하는 적층형 메모리 장치를 구비하는 전자 장치의 동작 방법에서는 상기 인공 신경망 엔진에서 학습 데이터와 가중치 들을 객체 인식 모델에 적용하여 상기 객체 인식 모델을 학습시키고, 상기 적층형 메모리 장치의 데이터 분배기 에서 입력 데이터와 관련된 특징 벡터를 제1 서브 특징 벡터와 제2 서브 특징 벡터로 분할하고, 상기 제2 서브 특징 벡터를 상기 그래픽 프로세서에 제공하고, 상기 적층형 메모리 장치의 곱셈 및 누적 회로에서 상기 제2 서 브 특징 벡터와 상기 가중치들을 상기 학습된 객체 인식 모델에 적용하여 제2 객체 인식 결과를 출력하는 제1 연산을 수행하고, 상기 그래픽 프로세서의 상기 인공 신경망 엔진에서 상기 제1 서브 특징 벡터와 상기 가중치 들을 상기 학습된 객체 인식 모델에 적용하여 제1 객체 인식 결과를 출력하는 제2 연산을 수행하고, 상기 적층 형 메모리 장치의 합성기에서 상기 제1 객체 인식 결과와 상기 제2 객체 인식 결과를 병합하여 병합된 객체 인 식 결과를 사용자에게 제공한다. 상기 제1 연산과 상기 제2 연산은 병렬적으로 수행된다."}
{"patent_id": "10-2018-0102183", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 실시예들에 따르면, 입력 데이터에 상응하는 또는 입력 데이터로부터 추출된 특징 벡터를 적층형 메 모리 장치에 구비되는 프로세서-인-메모리 회로에서 제1 서브 특징 벡터와 제2 서브 특징 벡터로 분할하고, 상 기 제1 특징 벡터를 그래픽 프로세서에 제공하고, 상기 그래픽 프로세서가 제1 특징 벡터에 대하여 인공 지능 연산을 수행하는 것과 병렬적으로 적층형 메모리 장치의 프로세서-인-메모리 회로에서 제2 특징 벡터에 대하여 인공 지능 연산을 수행하여 특징 벡터에 대한 로드 밸런싱을 수행할 수 있다. 따라서, 본 발명의 실시예들에 따 르면 그래픽 프로세서나 중앙 처리 장치의 변경없이 인공 지능 연산의 성능을 향상시킬 수 있다."}
{"patent_id": "10-2018-0102183", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 도면상의 동일 한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 인공 지능 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 룰(rule) 기반 스마트 시스템과 달 리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공 지능 시스템은 사용할수록 인식률이 향상되 고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 룰 기반 스마트 시스템은 점차 딥러닝 기반 인공지 능 시스템으로 대체되고 있다. 인공 지능 기술은 기계학습(예로, 딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 도 1은 본 발명의 실시예들에 따른 인공 지능 연산을 병렬적으로 수행할 수 있는 전자 장치를 나타내는 블록도 이다. 도 1을 참조하면, 본 발명의 실시예들에 따른 전자 장치는 중앙 처리 장치(central processing unit, CPU), 그래픽 프로세서(GPU, 50) 및 적층형 메모리 장치를 포함할 수 있다. 중앙 처리 장치, 그래픽 프로세서 및 적층형 메모리 장치는 버스를 통하여 서로 통신할 수 있 다. 적층형 메모리 장치는 버퍼 다이 및 버퍼 다이 상에 적층되며 데이터를 저장하는 복수의 메모리 다이 들을 포함할 수 있다. 메모리 다이들은 관통 실리콘 비아를 통하여 버퍼 다이에 연결될 수있다. 적층형 메모리 장치는 학습 데이터(LDT), 가중치들(WDT)을 저장하고, 학습 데이터(LDT) 및 가중치들 (WDT)을 그래픽 프로세서에 제공할 수 있다. 그래픽 프로세서는 인공 신경망 엔진을 포함할 수 있다. 인공 신경망 엔진은 적층형 메모리 장치 로부터 학습 데이터(LDT)와 가중치들(WDT)을 수신하고, 학습 데이터(LDT)와 가중치들(WDT)을 이용하여 객체 인식 모델(object recognition model, ORM)을 학습시키고, 학습된 객체 인식 모델(LORM)을 적층형 메모리 장치에 제공할 수 있다. 인공 신경망 엔진과 적층형 메모리 장치의 일부는 객체 인식 장치를 구성할 수 있다. 객체 인식 장치의 적어도 일부는 소프트웨어 모듈로 구현되거나 하드웨어 칩 형태로 제작되어 전술한 각종 전자 장치에 탑재될 수 있다. 예를 들어, 객체 인식 장치는 인공 지능(AI; artificial intelligence)을 위한 전용 하 드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그 래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 이 때, 인공 지능 을 위한 전용 하드웨어 칩은 확률 연산에 특화된 전용 프로세서로서, 기존의 범용 프로세서보다 병렬처리 성능 이 높아 기계 학습과 같은 인공 지능 분야의 연산 작업을 빠르게 처리할 수 있다. 객체 인식 장치가 소프트웨어 모듈(또는, 인스트럭션(instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 이 경우, 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소 정의 애플리케이션에 의해 제공될 수 있다. 또는, 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제 공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 실시예에 따라서, 객체 인식 모델은 복수의 네트워크 노드들 간의 연결관계 및 상기 복수의 네트워크 노드 들 중 일부의 상기 선택된 가중치에 기초하여 연산을 수행하는 신경망 모델 또는 딥러닝 모델일 수 있다. 객체 인식 모델은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있다. 데이터 인식 모델은 인간 의 신경망의 뉴런(neuron)을 모의하는, 가중치를 가지는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네 트워크 노드들은 뉴런이 시냅스(synapse)를 통하여 신호를 주고 받는 시냅틱(synaptic) 활동을 모의하도록 각각 연결 관계를 형성할 수 있다. 데이터 인식 모델은, 일 예로, 신경망 모델, 또는 신경망 모델에서 발전한 딥 러닝모델을 포함할 수 있다. 딥 러닝 모델에서 복수의 네트워크 노드들은 서로 다른 깊이(또는, 레이어)에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데이터를 주고 받을 수 있다. 데이터 인식 모델에는, 예컨대, DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network), CNN(Convolutional Neural Network)과 같은 모델들이 포함될 수 있으며, 전술한 예에 특별히 한정되지는 않는다. 인공 신경망 엔진은 적층형 메모리 장치로부터 입력 데이터에 관련된 제1 서브 특징 벡터(SFV1)를 수 신하고, 제1 서브 특징 벡터(SFV1)와 가중치들(WDT)을 학습된 객체 인식 모델에 적용하여 제1 객체 인식 결과 (ORR1)를 적층형 메모리 장치에 제공하는 제2 연산을 수행할 수 있다. 적층형 메모리 장치는 입력 데이터에 관련된 제2 서브 특징 벡터와 가중치들(WDT)을 학습된 객체 인식 모델 에 적용하여 제2 객체 인식 결과를 제공하는 제1 연산을 상기 제1 연산과 병렬적으로 수행할 수 있다. 버퍼 다이는 입력 데이터 또는 입력 데이터로부터 추출된 특징 벡터를 제1 서브 특징 벡터(SFV1)와 제2 서 브 특징 벡터로 분할하고, 상기 제1 서브 특징 벡터(SFV1)를 인공 신경망 엔진에 제공하고, 상기 제1 연산 을 수행하는 프로세서-인-메모리 회로(processor-in-memory circuit, 230)를 포함할 수 있다. 중앙 처리 장치는 상기 프로세서-인-메모리 회로를 제어하는 시스템 소프트웨어를 포함할 수 있다. 도 2는 본 발명의 실시예들에 따른 도 1의 객체 인식 모델을 나타낸다. 도 2를 참조하면, 객체 인식 모델은 입력 레이어, 히든 레이어, 출력 레이어, 제1 연결선 들 및 제2 연결 선들을 포함할 수 있다. 입력 레이어는 입력 노드들(111, 112, 113)을 포함하고, 히든 레이어는 히든 노드들(131, 132)를 포 함하고, 출력 레이터(151, 152, 153)을 포함할 수 있다.입력 레이어의 입력 노드들(111, 112, 113)은 학습 데이터(LDT) 또는 제1 서브 특징 벡터(SFV1)를 수신하 고, 제1 가중치들(WT11~WT16)을 갖는 제1 연결선들을 통하여 학습 데이터(LDT) 또는 제1 서브 특징 벡터 (SFV1)를 히든 레이어에 전달한다. 히든 레이어의 히든 노드들(131, 132)은 입력 레이어로부터 수신된 학습 데이터(LDT) 또는 제1 서브 특징 벡터(SFV1)에 대하여 연산을 수행하여 제2 가중치들(WT21~WT26)을 갖는 제2 연결선들을 통하여 출력 레이어에 전달한다. 출력 레이어의 출력 노드들(151, 152, 153)은 히든 레이어로부터 전달받은 값들에 대하여 연산을 수 행하여 학습 데이터(LDT)에 상응하는 객체 인식 결과(ORR) 또는 제1 서브 특징 벡터(SFV1)에 상응하는 제1 객체 인식 결과(ORR1)을 출력할 수 있다. 도 2에서 제1 가중치들(WT11~WT16) 및 제2 가중치들(WT21~WT26)은 연결 가중치들 또는 연결 강도라 호칭될 수 있다. 도시하지는 않았지만, 객체 인식 모델은 복수 개의 히든 레이어들을 포함할 수 있다. 복수 개의 히든 레이 어들을 포함하는 뉴럴 네트워크는 깊은 뉴럴 네트워크(deep neural network)라고 지칭될 수 있다. 깊은 뉴럴 네 트워크를 학습시키는 것은 깊은 학습(deep learning)이라고 지칭될 수 있다. 히든 레이어에 제1 히든 레이어, 제2 히든 레이어, 및 제3 히든 레이어가 포함되는 경우를 가정하면, 제1 히든 레이어에 속한 히든 노드의 출력은 제2 히든 레이어에 속한 히든 노드들에 연결될 수 있다. 제2 히든 레이 어에 속한 히든 노드의 출력은 제3 히든 레이어에 속한 히든 노드들에 연결될 수 있다. 예를 들어, 객체 인식 모델은 각 히든 레이어에 이전 히든 레이어에 포함된 이전 히든 노드들의 출력들을 연결 가중치를 가지는 연결선들을 통해 입력할 수 있고, 이전 히든 노드들의 출력들에 연결가중치가 적용된 값 들 및 활성화 함수에 기초하여 히든 레이어에 포함된 히든 노드들의 출력을 생성할 수 있다. 일 실시예에 따르 면, 다음 히든 노드로 출력를 발화하기 위하여, 활성화 함수의 결과는 현재 히든 노드의 임계 값을 초과해야 한 다. 이 경우, 노드는 입력 벡터들을 통하여 특정 임계 활성화 강도에 도달하기 전에는 다음 노드로 신호를 발화 하지 않고, 비활성화 상태를 유지할 수 있다. 도 3은 본 발명의 실시예들에 따른 도 1의 인공 신경망 엔진을 나타내는 블록도이다. 도 3을 참조하면, 인공 신경망 엔진은 학습 모듈, 및 인식 모듈을 포함할 수 있다. 실시예에 있 어서, 인공 신경망 엔진은 모델 업데이트 모듈을 더 포함할 수 있다. 학습 모듈은 학습 데이터(LDT) 및 가중치들(WDT)을 이용하여 객체 인식 모델(ORM)을 학습시킨다. 인식 모 듈은 제1 서브 특징 벡터(SFV1) 및 가중치들(SWDT)을 학습된 객체 인식 모델(LORM)에 적용하여 제1 객체의 인식 결과(ORR1)를 제공한다. 모델 갱신 모듈은 학습된 객체 인식 모델(LORM) 및 제1 객체 인식 결과(1ORR)에 기초하여 제1 객체 인식 결과(1ORR)의 유사도가 제1 기준값 이하인 경우에 객체 인식 모델(ORM)을 갱신할 수 있다. 도 4는 본 발명의 실시예들에 따른 도 3의 학습 모듈을 나타내는 블록도이다. 도 4를 참조하면, 학습 모듈은 모델 학습부, 모델 저장부 및 모델 평가부를 포함할 수 있 다. 모델 학습부는 학습 데이터(LDT) 및 가중치들(SWDT)을 이용하여 객체 인식 모델(ORM)을 학습시킨다. 모델 저장부는 학습된 객체 인식 모델(LORM)을 저장한다. 모델 평가부는 학습된 객체 인식 모델(LORM)에 평가 데이터(LVDT)를 입력하고, 평가 데이터로부터 출력되는 유사도 신호(SS)가 일정한 기준을 만족하지 못하는 경우에 모델 학습부가 객체 인식 모델(ORM)을 다시 학습하도록 할 수 있다. 모델 학습부는 미리 구축된 데이터 인식 모델이 복수 개가 존재하는 경우, 입력된 학습 데이터와 기본 학 습 데이터의 관련성이 큰 객체 인식 모델을 학습할 객체 인식 모델(ORM)로 결정할 수 있다. 이 경우, 기본 학습 데이터는 데이터의 타입 별로 기 분류되어 있을 수 있으며, 객체 인식 모델은 데이터의 타입 별로 미리 구축되 어 있을 수 있다. 실시예들에 따르면, 모델 학습부는, 예로, 오류 역전파법(error back-propagation) 또는 경사 하강법 (gradient descent)을 포함하는 학습 알고리즘 등을 이용하여 객체 인식 모델(ORM)을 학습시킬 수 있다.도 5는 본 발명의 실시예들에 따른 도 3의 인식 모듈을 나타내는 블록도이다. 도 5를 참조하면, 인식 모듈은 입력부 및 인식 결과 제공기를 포함할 수 있다. 입력부는 제1 서브 특징 벡터(SFV1)와 가중치들(WDT)를 수신하여 인식 결과 제공기에 제공한다. 인식 결과 제공기는 제1 서브 특징 벡터(SFV1)와 가중치들(WDT)을 학습된 객체 인식 모델(LORM)에 적용하여 제1 객체 인식 결과(ORR1)를 제공할 수 있다. 도 6은 본 발명의 실시예들에 따른 도 1의 전자 장치에서 적층형 메모리 장치를 나타내는 블록도이다. 도 6을 참조하면, 적층형 메모리 장치는 버퍼 다이 및 복수의 메모리 다이들(300a~300k, k는 2 이상의 자연수)을 포함할 수 있다. 적층형 메모리 장치는 버퍼 다이 및 복수의 메모리 다이들(200a~200k)이 각각 적층되어 패키징된 것 일 수 있다. 버퍼 다이 상에 적층되는 메모리 다이들(300a~300k)은 버퍼 다이 와 전기적으로 연결되며, 이를 위하여 적층형 메모리 장치는 버퍼 다이와 메모리 다이들 (300a~300k)을 전기적으로 연결하는 도전 수단을 포함할 수 있다. 실시예에 있어서, 상기 도전 수단으로 관통 실리콘 비아(Through silicon via, TSV)가 적용될 수 있다. 실시예에 있어서, 적층형 메모리 장치는 버퍼 다이 상에 적층되는 비휘발성 메모리를 더 포함할 수 있다. 버퍼 다이는 중앙 처리 장치 및 그래픽 프로세서와 통신할 수 있고, 메모리 다이들(300a~300k) 각 각은 복수의 동적 메모리 셀들을 구비하는 DDR SDRAM (Double Data Rate Synchronous Dynamic Ramdom Access Memory), LPDDR(Low Power Double Data Rate) SDRAM, GDDR (Graphics Double Data Rate) SDRAM, RDRAM (Rambus Dynamic Ramdom Access Memory) 등과 같은 동적 랜덤 억세스 메모리(Dynamic Ramdom Access Memory, DRAM)일 수 있다. 도 7은 본 발명의 실시예들에 따른 도 6의 적층형 메모리 장치를 나타내는 블록도이다. 도 7에서는 서로 독립된 인터페이스를 가지는 복수의 채널들을 포함함으로써 증가된 대역폭(Bandwidth)을 갖는 HBM(High Bandwidth Memory) 형태의 메모리 장치가 예시된다. 도 7을 참조하면, 적층형 메모리 장치(90a)는 다수 개의 레이어들을 포함할 수 있다. 일 예로서, 적층형 메모리 장치는 버퍼 다이와 버퍼 다이 상에 적층된 하나 이상의 메모리 다이들을 포함할 수 있다. 도 7의 예에서는, 제1 내지 제 4 메모리 다이들(300a~300d)이 구비되는 예가 도시되었으나, 상기 메모리 다이들 의 개수는 다양하게 변경될 수 있다. 또한, 메모리 다이들 각각은 하나 이상의 채널을 포함할 수 있으며, 도 7의 예에서는 메모리 다이들 각각이 두 개의 채널을 포함함에 따라 적층형 메모리 장치(90a)가 8 개의 채널들(CH1~CH8)을 갖는 예가 도시된 다. 예를 들어, 제1 메모리 다이(300a)가 제1 채널 및 제3 채널(CH1, CH3)을 포함하고, 제2 메모리 다이(300b)가 제 2 채널 및 제4 채널(CH2, CH4)을 포함하며, 제3 메모리 다이(300c)가 제5 채널 및 제7 채널(CH5, CH7)을 포함 하며, 제4 메모리 다이(300d)가 제6 채널 및 제8 채널(CH6, CH8)을 포함할 수 있다. 버퍼 다이는 메모리 컨트롤러(외부 장치)와 통신하고, 메모리 컨트롤러로부터 커맨드, 어드레스 및 데이터 를 수신할 수 있으며, 수신된 커맨드, 어드레스 및 데이터를 메모리 다이들로 제공할 수 있다. 버퍼 다이 는 그 외면에 형성된 범프 등의 도전 수단(미도시)을 통해 메모리 컨트롤러와 통신할 수 있다. 버퍼 다이 는 커맨드, 어드레스 및 데이터를 버퍼링하며, 이에 따라 메모리 컨트롤러는 버퍼 다이의 로드(loa d)만을 구동함으로써 메모리 다이들과 인터페이스할 수 있다. 또한, 적층형 메모리 장치(90a)는 레이어들을 관통하는 복수의 관통 실리콘 비아(TSV, 220)들을 포함할 수 있다. TSV들은 다수의 채널들(CH1 ~ CH8)에 대응하여 배치될 수 있으며, 각각의 채널이 128 비트의 대역폭 (Bandwidth)을 갖는 경우, TSV들은 1024 비트의 데이터 입출력을 위한 구성들을 포함할 수 있다. TSV들은 제1 내지 제4 메모리 다이들(300a~300d)을 관통하도록 배치되고, 제1 내지 제4 메모리 다이들 (300a~300d) 각각은 TSV에 연결된 송신부/수신부를 포함할 수 있다. 각 채널 별로 데이터 입출력이 독립하 게 수행되는 노멀 동작시에는, 각각의 TSV에 대해 어느 하나의 메모리 다이의 송신부/수신부만이 인에이블됨으로써, 각각의 TSV는 어느 하나의 메모리 다이(또는, 어느 하나의 채널)의 데이터만을 독립하게 전달할 수 있다. 버퍼 다이는 프로세서-인-메모리 회로, TSV 영역, 물리(PHY) 영역 및 직접 액세스 영역 (DA, 214)을 포함할 수 있다. TSV 영역은 메모리 다이들과의 통신을 위한 TSV가 형성되는 영역이다. 또한, 물리(PHY) 영역 은 외부의 메모리 컨트롤러와의 통신을 위해 다수의 입출력 회로를 포함하는 영역으로서, 메모리 컨트롤러 로부터의 각종 신호들은 물리(PHY) 영역을 통해 TSV 영역으로 제공되고, 또한 TSV를 통해 메모 리 다이들로 제공될 수 있다. 또한, 물리(PHY) 영역은 그래픽 프로세서와의 통신을 위한 다수의 입출력 회로들을 포함할 수 있다. 한편, 직접 액세스 영역은 적층형 메모리 장치(90a)에 대한 테스트 모드에서 적층형 메모리 장치(90a)의 외면에 배치되는 도전 수단을 통해 외부의 테스트 장치와 직접 통신할 수 있다. 테스트 장치로부터 제공되는 각 종 신호들은 직접 액세스 영역 및 TSV 영역을 통해 메모리 다이들로 제공될 수 있다. 다른 실시 예에 있어서, 테스트 장치로부터 제공되는 각종 신호들은 직접 액세스 영역, 물리(PHY) 영역 및 TSV 영역을 통해 메모리 다이들로 제공될 수도 있다. 프로세서-인-메모리 회로는 벡터-곱(vector multiplication) 연산을 수행할 수 있는 곱셈 및 누적 (multiply and accumulate, MAC) 회로를 포함하여 그래픽 프로세서와 병렬적으로 인공 지능 연산을 수행하 여 특징 벡터와 관련된 신경망 연산에 대하여 로드 밸런싱을 수행할 수 있다. 도 8은 도 7의 적층형 메모리 장치에서 인공 지능 연산의 분배가 수행되는 것을 나타낸다. 도 7 및 도 8을 참조하면, 버퍼 다이는 내부 커맨드 생성기 및 프로세서-인-메모리 회로를 포함 하고, 내부 커맨드 생성기에서 생성하는 내부 커맨드들은 채널 별로 서로 독립하게 형성되는 커맨드 TSV(TSV_C)를 통하여 메모리 다이들로 제공될 수 있다. 프로세서-인-메모리 회로는 메모리 다이들에 저장된 가중치들(WDT) 및 입력 데이터에 해당하는 또는 입력 데이터로부터 추출된 특징 벡터(FV)를 수신하고, 특징 벡터(FV)를 제1 서브 특징 벡터(SFV1)와 제2 서브 특징 벡터로 분할하고, 제1 서브 특징 벡터(SFV1)를 물리 영역를 통하여 그래픽 프로세서에 제공하고, 학습된 객체 인식 모델에 가중치들(WDT)과 제2 서브 특징 벡터를 적용하여 제2 객체 인식 결과를 제공하는 제1 연산을 수행할 수 있다. 프로세서-인-메모리 회로는 또한 물리 영역를 통하여 제1 서브 특징 벡터(SFV1)와 가중치들(WDT)에 기반하여 도출된 제1 객체 인식 결과를 수신하고, 제1 객체 인식 결과와 제2 객체 인식 결과를 병합하여 병합된 객체 인식 결과를 사용자에게 제공할 수 있다. 메모리 다이들 각각은 내부 커맨드를 디코딩하여 내부 제어신호를 출력하는 커맨드 디코더들(211a~211d)과 독출된 데이터 및/또는 기입될 데이터에 대한 처리 동작을 수행하는 데이터 처리기부(313a~313d)를 포함할 수 있다. 어느 하나의 메모리 다이(예컨대, 제1 메모리 다이(300a))를 참조하면, 제1 메모리 다이(300a)는 커맨드 디코더 (311a)의 디코딩 결과에 따라 메모리 동작을 수행하고, 일 예로서 제1 메모리 다이(300a) 내부의 셀 영역에 저 장된 다수 비트들의 데이터가 독출되어 데이터 처리부(313a)로 제공될 수 있다. 데이터 처리부(313a)는 다수 비 트들의 데이터를 병렬하게 처리할 수 있으며, 병렬하게 처리된 데이터를 다수의 데이터 TSV들(TSV_D)로 병렬하 게 출력할 수 있다. 메모리 동작의 종류에 따라, 데이터 처리부(313a)는 독출된 데이터를 일시 저장할 수 있으며, 저장된 데이터를 데이터 TSV(TSV_D)로 출력할 수 있다. 또한, 커맨드 디코더(311a)의 제어에 따라, 데이터 처리부(313a)로부터의 데이터는 데이터 TSV(TSV_data)를 통해 다른 메모리 다이들 중 적어도 하나로 제공될 수 있다. 만약, 제1 메모 리 다이(300a)의 데이터를 제2 메모리 다이(300b)에 카피하는 내부 프로세스가 수행되는 경우, 데이터 처리부 (313a)로부터의 데이터는 데이터 TSV(TSV_D)를 통해 제2 메모리 다이(300b)로 제공될 수 있다. 적층형 메모리 장치(90a)는 버퍼 다이상에 형성되는 비휘발성 메모리 장치를 포함할 수 있고, 버퍼 다이는 상기 비휘발성 메모리 장치를 제어하는 비휘발성 인터페이스를 포함할 수 있다. 비휘발 성 메모리 장치는 학습된 객체 인식 모델을 저장할 수 있다. 도 9는 본 발명의 실시예들에 따른 도 1의 프로세서-인-메모리 회로를 나타내는 블록도이다. 도 9를 참조하면, 프로세서-인-메모리 회로는 컨트롤러, 데이터 분배기 및 곱셈 및 누적 회로 를 포함할 수 있다. 실시예에 있어서, 프로세서-인-메모리 회로는 특징 추출기 및 병합기 (pooler)를 더 포함할 수 있다. 특징 추출기는 입력 데이터(INDT)의 특징을 추출하여 특징 벡터(FV)를 제공할 수 있다. 데이터 분배기 는 특징 벡터(FV)를 수신하고, 시스템 소프트웨어로부터의 제1 제어 메시지(CTM1)에 따라 특징 벡터 (FV)를 제1 서브 특징 벡터(SFV1) 및 제2 서브 특징 벡터(SFV2)로 분할하고, 제1 서브 특징 벡터(SFV1)를 그래 픽 프로세서에 제공하고, 제2 서브 특징 벡터(SFV2)는 곱셈 및 누적 회로에 제공할 수 있다. 실시예 에 따라, 데이터 분배기는 특징 벡터(FV)를 분할하지 않고, 그대로 그래픽 프로세서에 제공할 수 있다. 곱셈 및 누적 회로는 컨트롤러의 제어에 따라 제2 서브 특징 벡터(SFV2) 및 가중치들(WDT)에 대하여 학습된 객체 인식 모델(LORM)에 상응하는 행렬 벡터-곱(vector-multiplication) 연산을 수행하여 제2 객체 인식 결과(ORR2)를 제공할 수 있다. 곱셈 및 누적 회로는 제2 서브 특징 벡터(SFV2) 및 가중치들(WDT)을 학습된 객체 인식 모델(LORM)에 적용하여 제2 객체 인식 결과(ORR2)를 제공할 수 있다. 즉, 곱셈 및 누적 회로는 제2 서브 특징 벡터(SFV2) 및 가중치들(WDT)을 기초로 제1 연산을 수행하여 제2 객체 인식 결과(ORR2)를 제공할 수 있다. 컨트롤러는 시스템 소프트웨어로부터의 제2 제어 메시지(CTM1)에 응답하여 곱셈 및 누적 회 로가 상기 연산을 수행하도록 제어 신호(CTL)를 곱셈 및 누적 회로에 제공할 수 있다. 곱셈 및 누적 회로는 복수의 연산 유닛들을 포함할 수 있다. 곱셈 및 누적 회로는 그래픽 프로세서로부터 제공 되는 중간 연산 결과(IOR)를 이용하여 제1 연산을 수행할 수 있다. 그래픽 프로세서는 제1 서브 특징 벡터 (SFV1)와 제2 서브 특징 벡터(SFV2)가 실시예에 따라, 곱셈 및 누적 회로는 그래픽 프로세서로부터 제공되는 중간 연산 결과(IOR)를 이용하 여 제1 연산을 수행할 수 있다. 그래픽 프로세서는 제1 서브 특징 벡터(SFV1)와 제2 서브 특징 벡터(SFV2) 가 적어도 일부의 중복 데이터를 포함하는 경우, 중복 데이터에 대한 중간 연산 결과(IOR)를 곱셈 및 누적 회로 에 제공할 수 있다. 병합기는 그래픽 프로세서로부터 제1 객체 인식 결과(ORR1)를 수신하고, 곱셈 및 누적 회로로부 터 제2 객체 인식 결과(ORR2)를 수신하고, 제1 객체 인식 결과(ORR1)과 제2 객체 인식 결과(ORR2)를 병합하여 병합된 객체 인식 결과(MORR)를 사용자에게 제공할 수 있다. 특징 추출기 및 병합기는 프로세서-인- 메모리 회로 외부에 포함될 수 있다. 도 10은 본 발명의 실시예들에 따른 도 9의 곱셈 및 누적 회로를 나타내는 블록도이다. 도 10을 참조하면, 곱셈 및 누적 회로는 곱셈 회로 및 누적 회로를 포함할 수 있다. 곱셈 회로 는 가중치들(WDT) 및 제2 서브 특징 벡터(SFV1)를 수신하고, 제2 서브 특징 벡터(SFV1)와 가중치들(WDT)을 곱하여 출력한다. 누적 회로는 곱셈 회로의 출력을 누적하여 제2 객체 인식 결과(ORR2)를 제공한다. 곱셈 회로는 제1 버퍼, 제2 버퍼 및 곱셈기를 포함한다. 제1 버퍼는 가중치들(WDT) 을 수신하고, 가중치들(WDT)을 제1 연산 단위인 커널 단위로 출력한다. 제2 버퍼는 제2 서브 특징 벡터 (SFV2)를 수신하고, 제2 서브 특징 벡터(SFV2)를 제2 연산 단위로 출력한다. 곱셈기는 제1 버퍼의 출 력과 제2 버퍼의 출력을 곱하여 중간 연산 결과로서 제공한다. 누적 회로는 가산기 및 버퍼를 포함한다. 가산기는 제1 입력과 제2 입력을 구비하고 제1 입력에서 곱셈기의 출력을 수신한다. 가산기는 곱셈기의 출력과 제2 입력에서 수신되는 버퍼 의 출력을 합산하여 가산기의 제2 입력으로 피드백시킨다. 버퍼는 출력 인에이블 신호(OEN)에 응답하여 가산기의 출력을 제2 객체 인식 결과(ORR2)로서 제공하고, 리셋 신호(RST)에 응답하여 리셋된다. 출력 인에이블 신호(OEN) 및 리셋 신호(RST)는 제어 신호(CTL)에 포함될 수 있다. 도 11은 본 발명의 실시예들에 따른 도 6의 적층형 메모리 장치에 포함되는 메모리 다이들 중 하나를 나타내는 블록도이다. 도 11에서는 메모리 다이(300a)의 구성을 나타내었으나, 메모리 다이들(300b~300k) 각각의 구성은 메모리 다이 (300a)와 실질적으로 동일할 수 있다. 메모리 다이(300a)는 제어 로직 회로, 어드레스 레지스터, 뱅크 제어 로직, 리프레시 카운터 , 로우 어드레스 멀티플렉서, 칼럼 어드레스 래치, 로우 디코더, 칼럼 디코더, 메모 리 셀 어레이, 센스 앰프부, 입출력 게이팅 회로 및 데이터 처리부(313a)를 포함할 수 있다. 상기 메모리 셀 어레이는 제1 내지 제8 뱅크 어레이들(410~480)을 포함할 수 있다. 또한, 상기 로우 디코 더는 제1 내지 제8 뱅크 어레이들(410~480)에 각각 연결된 제1 내지 제8 뱅크 로우 디코더들(360a~360h)을 포함하고, 상기 칼럼 디코더는 제1 내지 제8 뱅크 어레이들(410~480)에 각각 연결된 제1 내지 제8 뱅크 칼 럼 디코더들(370a~370h)을 포함하며, 상기 센스 앰프부는 제1 내지 제8 뱅크 어레이들(410~480)에 각각 연 결된 제1 내지 제8 뱅크 센스 앰프들(385a~385h)을 포함할 수 있다. 제1 내지 제8 뱅크 어레이들(410~480), 제1 내지 제8 뱅크 센스 앰프들(385a~385h), 제1 내지 제8 뱅크 칼럼 디 코더들(370a~370h) 및 제1 내지 제8 뱅크 로우 디코더들(360a~360h)은 제1 내지 제8 뱅크들을 각각 구성할 수 있다. 제1 내지 제8 뱅크 어레이들(410~480) 각각은 복수의 워드라인(WL)들과 복수의 비트라인(BTL)들 및 워드 라인(WL)들과 비트라인(BTL)들이 교차하는 지점에 형성되는 복수의 메모리 셀(MC)들을 포함할 수 있다. 어드레스 레지스터는 외부로부터 뱅크 어드레스(BANK_ADDR), 로우 어드레스(ROW_ADDR) 및 칼럼 어드레스 (COL_ADDR)를 포함하는 어드레스(ADDR)를 수신할 수 있다. 어드레스 레지스터는 수신된 뱅크 어드레스 (BANK_ADDR)를 뱅크 제어 로직에 제공하고, 수신된 로우 어드레스(ROW_ADDR)를 로우 어드레스 멀티플렉서 에 제공하며, 수신된 칼럼 어드레스(COL_ADDR)를 칼럼 어드레스 래치에 제공할 수 있다. 뱅크 제어 로직은 뱅크 어드레스(BANK_ADDR)에 응답하여 뱅크 제어 신호들을 생성할 수 있다. 상기 뱅크 제어 신호들에 응답하여, 제1 내지 제8 뱅크 로우 디코더들(360a~360h) 중 뱅크 어드레스(BANK_ADDR)에 상응하 는 뱅크 로우 디코더가 활성화되고, 제1 내지 제8 뱅크 칼럼 디코더들(370a~370h) 중 뱅크 어드레스(BANK_ADD R)에 상응하는 뱅크 칼럼 디코더가 활성화될 수 있다. 로우 어드레스 멀티플렉서는 어드레스 레지스터로부터 로우 어드레스(ROW_ADDR)를 수신하고, 리프레 쉬 카운터로부터 리프레시 로우 어드레스(REF_ADDR)를 수신할 수 있다. 로우 어드레스 멀티플렉서는 로우 어드레스(ROW_ADDR) 또는 리프레쉬 로우 어드레스(REF_ADDR)를 로우 어드레스(RA)로서 선택적으로 출력할 수 있다. 로우 어드레스 멀티플렉서로부터 출력된 로우 어드레스(RA)는 제1 내지 제8 뱅크 로우 디코더들 (360a~360h)에 각각 인가될 수 있다. 리프레쉬 카운터는 제어 로직 회로의 제어에 따라 리프레쉬 로우 어드레스(REF_ADDR)를 순차적으로 출력할 수 있다. 제1 내지 제8 뱅크 로우 디코더들(360a~360h) 중 뱅크 제어 로직에 의해 활성화된 뱅크 로우 디코더는 로 우 어드레스 멀티플렉서로부터 출력된 로우 어드레스(RA)를 디코딩하여 상기 로우 어드레스에 상응하는 워 드라인을 활성화할 수 있다. 예를 들어, 상기 활성화된 뱅크 로우 디코더는 로우 어드레스에 상응하는 워드라인 에 워드라인 구동 전압을 인가할 수 있다. 칼럼 어드레스 래치는 어드레스 레지스터로부터 칼럼 어드레스(COL_ADDR)를 수신하고, 수신된 칼럼 어드레스(COL_ADDR)를 일시적으로 저장할 수 있다. 또한, 칼럼 어드레스 래치는, 버스트 모드에서, 수신된 칼럼 어드레스(COL_ADDR)를 점진적으로 증가시킬 수 있다. 칼럼 어드레스 래치는 일시적으로 저장된 또는 점진적으로 증가된 칼럼 어드레스(COL_ADDR)를 제1 내지 제8 뱅크 칼럼 디코더들(370a~370h)에 각각 인가할 수 있다. 제1 내지 제8 뱅크 칼럼 디코더들(370a~370h) 중 뱅크 제어 로직에 의해 활성화된 뱅크 칼럼 디코더는 상 응하는 입출력 게이팅 회로를 통하여 뱅크 어드레스(BANK_ADDR) 및 칼럼 어드레스(COL_ADDR)에 상응하는 센스 앰프를 활성화시킬 수 있다. 입출력 게이팅 회로는 입출력 데이터를 게이팅하는 회로들과 함께, 입력 데이터 마스크 로직, 제1 내지 제 8 뱅크 어레이들(410~480)로부터 출력된 데이터를 저장하기 위한 독출 데이터 래치들, 및 제1 내지 제8 뱅크 어 레이들(410~480)에 데이터를 기입하기 위한 기입 드라이버들을 포함할 수 있다. 제1 내지 제8 뱅크 어레이들(410~380) 중 하나의 뱅크 어레이에서 독출될 데이터(가중치들 및 특징 벡터를 포함) 상기 하나의 뱅크 어레이에 상응하는 센스 앰프에 의해 감지되고, 상기 독출 데이터 래치들에 저장될 수 있다. 상기 독출 데이터 래치들에 저장된 데이터는 데이터 처리부(313a)를 통하여 외부로 제공되거나 다른 메모 리 다이로 제공될 수 있다. 제1 내지 제8 뱅크 어레이들(410~480) 중 하나의 뱅크 어레이에 기입될 데이터는 입출력 게이팅 회로에 제 공하고, 입출력 게이팅 회로는 상기 기입 드라이버들을 통하여 상기 데이터를 상기 하나의 뱅크 어레이에 기입할 수 있다. 데이터 처리부(313a)는 기입 동작에서는 가중치들(WDT) 및 특징 벡터(FV)를 입출력 게이팅 회로를 통하여 메모리 셀 어레이에 저장하고, 기입 동작에서는 가중치들(WDT) 및 특징 벡터(FV)를 데이터 TSV(TSV_D)를 통하여 버퍼 다이의 프로세서-인-메모리 회로에 제공할 수 있다. 제어 로직 회로는 메모리 다이(300a)의 동작을 제어할 수 있다. 예를 들어, 제어 로직 회로는 메모리 다이(300a)가 기입 동작 또는 독출 동작을 수행하도록 제어 신호들을 생성할 수 있다. 제어 로직 회로는 내부 커맨드 생성기로부터 수신되는 커맨드(CMD)를 디코딩하는 커맨드 디코더(311a) 및 메모리 다이(300 a)의 동작 모드를 설정하기 위한 모드 레지스터를 포함할 수 있다. 도 12는 본 발명의 실시예들에 따른 도 11의 메모리 다이에서 제1 뱅크 어레이를 나타낸다. 도 12를 참조하면, 제1 뱅크 어레이는 복수개의 워드라인들(WL1~WLm, m은 2이상의 정수), 복수개의 비트라 인들(BL1~BLn, n은 2이상의 정수), 그리고 워드라인들(WL1~WLm)과 비트라인들(BL1~BLn) 사이의 교차점에 배치되 는 복수개의 동적 메모리 셀들(MCs)을 포함한다. 동적 메모리 셀들(MCs) 각각은 워드라인들(WL1~WLm) 각각과 비 트라인들(BL1~BLn) 각각에 연결되는 셀 트랜지스터 및 상기 셀 트랜지스터에 연결되는 셀 커패시터를 포함할 수 있다. 도 11 및 도 12에서는 메모리 다이(200a)가 동적 메모리 셀들을 포함하는 DRAM으로 구현되는 경우를 설명하였다. 하지만, 메모리 다이들(200a~200k) 각각은 저항성 메모리 셀들을 구비하는 저항성 메모리 장치나 다른 종류의 메모리 장치로 구현될 수 있다. 도 13은 도 9의 프로세서-인-메모리 회로의 특징 벡터와 가중치와 관련된 커널을 나타낸다. 도 13을 참조하면, 특징 벡터(FV)가 K*K(K는 여기서 7) 행렬로 구성되고, 가중치들(WDT)과 관련된 커널(KRN1)이 I*I(I는 여기서 3)으로 구성되는 경우, 데이터 분배기는 특징 벡터(FV)를 제1 서브 특징 벡터(SFV1)과 제2 서브 특징 벡터(SFV2)로 분할하고, 제1 서브 특징 벡터(SFV1)를 그래픽 프로세서에 제공하고, 제2 서브 특 징 벡터(SFV2)를 곱셈 및 누적 회로에 제공한다. 그래픽 프로세서는 제1 서브 특징 벡터(SFV1)에 해당하는 K*((I+(K-1))/2 이상인 정수)의 행렬에 대하여만 커널(KRN1)을 적용하여 행렬-곱 연산을 수행하면 된다. 따라서, 특징 벡터(FV) 전체가 그래픽 프로세서로 전달되어 그래픽 프로세서에서 특징 벡터(FV) 전체에 대하여 행렬-곱 연산을 수행하는 경우보다 그래픽 프 로세서에서의 연산량이 감소한다. 또한 그래픽 프로세서에서 제1 서브 특징 벡터(SFV1)에 대하여 행렬- 곱 연산을 수행할 때, 곱셈 및 누적 회로는 제2 서브 특징 벡터(SFV2)에 동일한 커널(KRN1)을 적용하여 제 2 서브 특징 벡터(SFV2)에 행렬-곱 연산을 수행할 수 있다. 도 14는 도 1의 그래픽 프로세서에서의 제2 연산을 나타내고, 도 15는 프로세서-인-메모리 회로에서의 제1 연산 을 나타내고, 도 16은 도 9의 병합기의 동작을 나타낸다. 도 14를 참조하면, 그래픽 프로세서는 제1 서브 특징 벡터(SFV1)에 커널(KRN1)을 적용하여 제1 서브 특징 벡터(SFV1)와 커널(KRN1)에 대한 행렬-곱 연산을 수행하여 제1 객체 인식 결과(ORR1)를 제공할 수 있다. 제1 객 체 인식 결과(ORR1)는 5*3의 행렬로 구성될 수 있다. 도 15를 참조하면, 곱셈 및 누적 회로는 제2 서브 특징 벡터(SFV2)에 커널(KRN1)을 적용하여 제2 서브 특 징 벡터(SFV2)와 커널(KRN1)에 대한 행렬-곱 연산을 수행하여 제2 객체 인식 결과(ORR1)를 제공할 수 있다. 제2 객체 인식 결과(ORR1)는 5*2의 행렬로 구성될 수 있다. 도 16을 참조하면, 병합기는 제1 객체 인식 결과(ORR1)와 제2 객체 인식 결과(ORR2)를 병합하여 병합된 객 체 인식 결과(MORR)를 제공할 수 있다. 병합된 객체 인식 결과(MORR)는 5*5의 행렬로 구성될 수 있다. 도 17 및 도 18은 도 9의 데이터 분배기가 입력 데이터 또는 특징 벡터를 제1 서브 특징 벡터 및 제2 서브 특징 벡터로 분할하는 것을 나타낸다. 도 17은 도 9의 데이터 분배기가 컨트롤러의 제어에 따라입력 데이터 또는 특징 벡터를 단순히 절반 으로 분할하여 제1 특징 벡터(SFV1) 및 제2 특징 벡터(SFV2)로 분할하는 것을 나타낸다. 도 17을 참조하면, 제1 입력 데이터(INDT1)는 객체들(OB11, OB12)를 포함하고, 제2 입력 데이터(INDT2)는 객체 들(OB21, OB22)를 포함하는 경우, 데이터 분배기는 제1 입력 데이터(INDT1)를 제1 부분(SFV11)과 제2 부 분(SFV21)으로 2-분할하고, 제2 입력 데이터(INDT2)를 제1 부분(SFV12)과 제2 부분(SFV22)로 2-분할하고, 제1 부분들(SFV11, SFV12)을 제1 서브 특징 벡터(SFV1)로 구성하고, 제2 부분들(SFV21, SFV22)을 제2 서브 특징 벡 터(SFV2)로 구성할 수 있다. 도 18을 참조하면, 제1 입력 데이터(INDT1)는 객체들(OB11, OB12)를 포함하고, 제2 입력 데이터(INDT2)는 객체 들(OB21, OB22)를 포함하는 경우, 데이터 분배기는 객체들에 기초하여 제1 입력 데이터(INDT1)를 제1 서브 특징 벡터(SFV1)로 구성하고, 제2 입력 데이터(INDT2)를 제2 서브 특징 벡터(SFV2)로 구성할 수 있다. 도 19는 본 발명의 실시예들에 따른 적층형 메모리 장치에서 데이터카피 동작이 수행되는 예를 나타내는 블록도 이다. 이하에서는, 설명의 편의상 하나의 버퍼 다이와 두 개의 메모리 다이들의 동작이 예시된다. 또한, 이하의 실시 예들에 도시된 테스트 회로는 내부 프로세스에 따라 채널 선택 또는 칩 선택을 위한 칩 선택신호(chip_select) 를 제공하는 기능을 수행할 수 있다. 다른 실시예에 따라, 이하의 도면들에 도시된 칩 선택신호(CS)는 각각의 메모리 다이의 커맨드 디코더를 통해 생성될 수 있다. 도 19를 참조하면, 적층형 메모리 장치는 버퍼 다이, 제1 메모리 다이 및 제2 메모리 다이(63 0)를 포함할 수 있다. 버퍼 다이는 외부 장치와 통신하고, 외부 장치로부터의 커맨드에 응답하여 내부 커맨드를 생성하는 내부 커맨드 생성기를 포함할 수 있다. 내부 커맨드 생성기는 메모리 다이를 선택하기 위한 칩 선택신호 (CS)를 변경해가면서 내부 커맨드를 제1 메모리 다이 및 제2 메모리 다이로 제공할 수 있다. 또한, 버퍼 다이와 제1 및 제2 메모리 다이들(620, 630) 사이에서 데이터가 송수신될 수 있으며, 데이터 송수신 을 위한 데이터 TSV들은 버퍼 다이와 제1 및 제2 메모리 다이들(620, 630)에 대해 공통하게 배치될 수 있 다. 버퍼 다이는 제1 및 제2 메모리 다이들(620, 630)과 채널 별로 독립한 인터페이스를 수행하기 위해 다수 개의 입출력 회로들을 포함할 수 있다. 예컨대, 버퍼 다이는 제1 메모리 다이와 인터페이스하는 제A 채널(CH_A)용 입출력 회로와 제2 메모리 다이와 인터페이스하는 제B 채널(CH_B)용 입출력 회로를 포함할 수 있다. 각각의 입출력 회로에 구비되는 다양한 구성 요소들은 버퍼 다이에 적어도 하나의 영역에 배치될 수있으며, 일 예로서 입출력 회로의 구성 요소들은 물리(PHY) 영역에 배치될 수 있다. 또한, 각각의 채널에 대응하는 입출력 회로는, 외부 장치와 인터페이스하는 인터페이스부, 경로 제어부 , 독출 데이터 경로 및 기입 데이터 경로를 포함할 수 있다. 제1 및 제2 메모리 다이들(620, 630) 각각은 데이터를 TSV를 통해 데이터를 입출력하는 송수신부(625, 635)를 포함할 수 있으며, 각각의 메모리 다이의 송수신부는 칩 선택 신호(CS)에 의해 활성화가 제어될 수 있다. 제1 메모리 다이는 메모리 셀 어레이를 포함하는 셀 코어, 내부 커맨드를 디코딩하는 커맨드 디코더 , 기입 데이터 경로, 독출 데이터 경로 및 송수신부를 포함할 수 있다. 제2 메모리 다이 는 제1 메모리 다이와 동일 또는 유사하게 구현될 수 있으며, 이에 따라 제2 메모리 다이는 셀 코어, 내부 커맨드를 디코딩하는 커맨드 디코더, 기입 데이터 경로, 독출 데이터 경로 및 송수신부를 포함할 수 있다. 외부 장치의 커맨드에 따라 제2 메모리 다이의 데이터를 제1 메모리 다이에 카피하기 위한 내부 동작 이 수행되는 경우, 상기 내부 동작은 외부 장치의 개입 없이 적층형 메모리 장치 내부에서 수행될 수 있다. 내부 커맨드 생성기는 내부 커맨드를 제2 메모리 다이로 제공하고, 제2 메모리 다이의 셀 코어에 저장된 독출 데이터 경로를 통하여 송수신부로 제공되고, 송수신부의 독출 버퍼 (RD_BUF)와 데이터 TSV를 통하여 제1 메모리 다이의 송수신부로 제공되고, 송수신부의 기입 버 퍼(WR_BUF)와 기입 경로를 통하여 제1 메모리 다이의 셀 코어에 카피될 수 있다. 도 20은 본 발명의 실시예들에 따른 전자 장치의 동작 방법을 나타내는 흐름도이다. 도 1 내지 도 18 및 도 20을 참조하면, 인공 신경망 엔진을 구비하는 그래픽 프로세서 및 상기 그래픽 프로세서와 통신하는 적층형 메모리 장치를 구비하는 전자 장치의 동작 방법에서는 인공 신경망 엔진 에서 학습 데이터(LDT)와 가중치들(WDT)을 객체 인식 모델에 적용하여 상기 객체 인식 모델을 학습시킨다(S710). 적층형 메모리 장치의 데이터 분배기에서 입력 데이터와 관련된 특징 벡터(FV)를제1 서브 특징 벡터(SFV1)와 제2 서브 특징 벡터(SFV2)로 분할하고, 상기 제2 서브 특징 벡터(SFV1)를 상기 그 래픽 프로세서에 제공한다(S720). 적층형 메모리 장치의 곱셈 및 누적 회로에서 상기 제2 서브 특징 벡터(SFV2)와 상기 가중치들(WDT)을 상기 학습된 객체 인식 모델에 적용하여 제2 객체 인식 결과(ORR2)를 출력하는 제1 연산을 수행한다(S730). 상 기 그래픽 프로세서의 상기 인공 신경망 엔진에서 상기 제1 서브 특징 벡터(SFV1)와 상기 가중치들 (WDT)을 상기 학습된 객체 인식 모델에 적용하여 제1 객체 인식 결과(ORR2)를 출력하는 제2 연산을 수행한다 (S740). 적층형 메모리 장치의 합성기에서 상기 제1 객체 인식 결과(ORR1)와 상기 제2 객체 인식 결과(ORR2)를 병합하여 병합된 객체 인식 결(MORR)과를 사용자에게 제공한다(S750). 상기 제1 연산과 상기 제2 연산은 병렬적 으로 수행될 수 있다. 따라서 본 발명의 실시예들에 따르면, 입력 데이터에 상응하는 또는 입력 데이터로부터 추출된 특징 벡터를 적 층형 메모리 장치에 구비되는 프로세서-인-메모리 회로에서 제1 서브 특징 벡터와 제2 서브 특징 벡터로 분할하 고, 상기 제1 특징 벡터를 그래픽 프로세서에 제공하고, 상기 그래픽 프로세서가 제1 특징 벡터에 대하여 인공 지능 연산을 수행하는 것과 병렬적으로 적층형 메모리 장치의 프로세서-인-메모리 회로에서 제2 특징 벡터에 대 하여 인공 지능 연산을 수행하여 특징 벡터에 대한 로드 밸런싱을 수행할 수 있다. 따라서, 본 발명의 실시예들 에 따르면 그래픽 프로세서나 중앙 처리 장치의 변경없이 인공 지능 연산의 성능을 향상시킬 수 있다. 도 21은 본 발명의 실시예들에 따른 하이브리드 적층형 메모리 장치를 포함하는 인공 지능 가속기(전자 장치)를 나타내는 블록도이다. 도 21을 참조하면, 인공 지능 가속기는 어플리케이션 프로세서, 그래픽 프로세서 및 하이브리드 적층형 메모리 장치을 포함할 수 있다. 하이브리드 적층형 메모리 장치은 버퍼 다이, 비휘발성 메모리 장치 및 복수의 메모리 다이들 를 포함할 수 있다. 어플리케이션 프로세서는 휘발성 메모리 장치와 플래시 서브 시스템을 제어할 수 있다. 휘발성 메모리 장치는 언어 모델을 저장할 수 있다. 버퍼 다이는 프로세서-인-메모리 회로를 포함할 수 있다. 프로세서-인-메모리 회로는 도 9의 프 로세서-인-메모리 회로를 포함할 수 있다. 하이브리드 적층형 메모리 장치는 가중치들(WDT)을 저장하여 그래픽 프로세서에 제공하고, 입력 데이 터와 관련된 특징 벡터를 분할하여 제1 서브 특징 벡터(SFV1)를 그래픽 프로세서에 제공할 수 있다. 그래 픽 프로세서는 가중치들(WDT)과 제1 서브 특징 벡터(SFV1)를 학습된 객체 인식 모델에 적용시켜 제1 객체 인식 결과(ORR1)를 어플리케이션 프로세서에 제공할 수 있다. 비휘발성 메모리 장치는 그래픽 프로세서로부터 제공된 학습된 객체 인식 모델(LORM)을 저장하고, 학 습된 객체 인식 모델(LORM)을 프로세서-인-메모리 회로에 제공할 수 있다. 프로세서-인-메모리 회로 는 메모리 다이들로부터 제공받은 특징 벡터(FV)를 제1 서브 특징 벡터(SFV1)와 제2 서브 특징 벡터(SFV 2)로 분할하고, 제2 서브 특징 벡터(SFV2)와 가중치들(WDT)을 학습된 객체 인식 모델(LORM)에 적용하여 제2 객 체 인식 결과(ORR2)를 어플리케이션 프로세서에 제공할 수 있다. 어플리케이션 프로세서는 제1 객체 인식 결과(ORR1)과 제2 객체 인식 결과(ORR2)를 병합하여 병합된 객체 인식 결과를 사용자에게 제공할 수 있다. 도 22는 본 발명의 실시예들에 따른 적층형 메모리 장치를 포함하는 반도체 패키지의 예를 나타내는 구조도이다. 도 22를 참조하면, 반도체 패키지는 하나 이상의 적층형 메모리 장치, 중앙 처리 장치 및 그래 픽 프로세서를 포함할 수 있다. 상기 적층형 메모리 장치, 중앙 처리 장치 및 그래픽 프로세서 는 인터포저(Interposer, 930) 상에 장착되고, 적층형 메모리 장치, 중앙 처리 장치 및 그래픽 프로세서가 장착된 인터포저는 패키지 기판 상에 장착될 수 있다. 중앙 처리 장치 및 그래 픽 프로세서는 도 1의 중앙 처리 장치 및 그래픽 프로세서와 실질적으로 동일한 기능을 수행할 수 있다. 적층형 메모리 장치는 다양한 형태로 구현이 가능하며, 일 실시예에 따라 적층형 메모리 장치는 다수 개의 레이어들이 적층된 HBM(High Bandwidth Memory) 형태의 메모리 장치일 수 있다. 이에 따라, 적층형 메모리 장치는 버퍼 다이 및 복수의 메모리 다이들을 포함하고 상기 버퍼 다이는 인공 지능 연산을 수행할 수 있 는 프로세서-인-메모리 회로를 포함하여 그래픽 프로세서와 병렬적으로 인공 지능 연산을 수행할 수 있다. 인터포저 상에는 다수 개의 적층형 메모리 장치들이 장착될 수 있으며, 중앙 처리 장치 및 그래 픽 프로세서는 다수개의 적층형 메모리 장치들과 통신할 수 있다. 일 예로서, 적층형 메모리 장치 들 각각과 중앙 처리 장치 및 그래픽 프로세서는 물리 영역을 포함할 수 있으며, 물리(PHY) 영 역을 통해 적층형 메모리 장치들과 메모리 컨트롤러 사이에서 통신이 수행될 수 있다. 한편, 적층형 메모리 장치가 직접 액세스 영역을 포함하는 경우, 패키지 기판의 하부에 장착되는 도전 수단(예컨대, 솔더볼) 및 직접 액세스 영역을 통해 테스트 신호가 스택형 메모리 장치 내부로 제공될 수 있다. 여기서, 인터포저는 실리콘(TSV) 형태, PCB 형태의 오가닉(Organic) 또는 Non-TSV 방식인 EMIB(embedded multi-die interconnect bridge)를 포함할 수 있다. 산업상 이용가능성 본 발명은 인공 지능을 사용하는 다양한 장치에 적용되어 데이터 처리 효율을 증가시킬 수 있다. 상술한 바와 같이, 본 발명의 바람직한 실시예를 참조하여 설명하였지만 해당 기술 분야에서 통상의 지식을 가 진 자라면 하기의 특허청구범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명 을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2018-0102183", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예들에 따른 인공 지능 연산을 병렬적으로 수행할 수 있는 전자 장치를 나타내는 블록도 이다. 도 2는 본 발명의 실시예들에 따른 도 1의 객체 인식 모델을 나타낸다. 도 3은 본 발명의 실시예들에 따른 도 1의 인공 신경망 엔진을 나타내는 블록도이다.도 4는 본 발명의 실시예들에 따른 도 3의 학습 모듈을 나타내는 블록도이다. 도 5는 본 발명의 실시예들에 따른 도 3의 인식 모듈을 나타내는 블록도이다. 도 6은 본 발명의 실시예들에 따른 도 1의 전자 장치에서 적층형 메모리 장치를 나타내는 블록도이다. 도 7은 본 발명의 실시예들에 따른 도 6의 적층형 메모리 장치를 나타내는 블록도이다. 도 8은 도 7의 적층형 메모리 장치에서 인공 지능 연산의 분배가 수행되는 것을 나타낸다. 도 9는 본 발명의 실시예들에 따른 도 1의 프로세서-인-메모리 회로를 나타내는 블록도이다. 도 10은 본 발명의 실시예들에 따른 도 9의 곱셈 및 누적 회로를 나타내는 블록도이다. 도 11은 본 발명의 실시예들에 따른 도 6의 적층형 메모리 장치에 포함되는 메모리 다이들 중 하나를 나타내는 블록도이다. 도 12는 본 발명의 실시예들에 따른 도 11의 메모리 다이에서 제1 뱅크 어레이를 나타낸다. 도 13은 도 9의 프로세서-인-메모리 회로의 특징 벡터와 가중치와 관련된 커널을 나타낸다. 도 14는 도 1의 그래픽 프로세서에서의 제2 연산을 나타내고, 도 15는 프로세서-인-메모리 회로에서의 제1 연산 을 나타내고, 도 16은 도 9의 병합기의 동작을 나타낸다. 도 17 및 도 18은 도 9의 데이터 분배기가 입력 데이터 또는 특징 벡터를 제1 서브 특징 벡터 및 제2 서브 특징 벡터로 분할하는 것을 나타낸다. 도 19는 본 발명의 실시예들에 따른 적층형 메모리 장치에서 데이터카피 동작이 수행되는 예를 나타내는 블록도 이다. 도 20은 본 발명의 실시예들에 따른 전자 장치의 동작 방법을 나타내는 흐름도이다. 도 21은 본 발명의 실시예들에 따른 객체 인식 장치를 포함하는 인공 지능 가속기를 나타내는 블록도이다. 도 22는 본 발명의 실시예들에 따른 적층형 메모리 장치를 포함하는 반도체 패키지의 예를 나타내는 구조도이다."}
