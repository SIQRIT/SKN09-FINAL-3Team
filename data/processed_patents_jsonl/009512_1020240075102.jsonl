{"patent_id": "10-2024-0075102", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0013094", "출원번호": "10-2024-0075102", "발명의 명칭": "인공신경망 및 텍스트 쌍 임베딩을 이용한 특허 분석 모델의 생성 방법, 특허 분석 방법 및", "출원인": "이진수", "발명자": "이진수"}}
{"patent_id": "10-2024-0075102", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "독립변수인 텍스트 쌍 및 이에 지정된 종속변수인 레이블을 포함하는 학습 데이터를 생성하는 컴퓨팅 장치에 의해 수행되는 방법으로서,복수의 특허문서의 제1 항목으로부터 각 특허문서에 대한 제1 텍스트 시퀀스를 추출하고, 상기 복수의 특허문서의 제2 항목으로부터 각 특허문서에 대한 제2 텍스트 시퀀스를 추출하는 단계;상기 제1 텍스트 시퀀스와 상기 제2 텍스트 시퀀스를 결합하여 텍스트 쌍(text pair)을 생성하는 단계; 및상기 텍스트 쌍에 대해 발명의 유사 여부에 관한 레이블을 지정하는 단계를 포함하되,상기 학습 데이터는, 동일한 특허문서에서 추출된 제1 텍스트 시퀀스 및 제2 텍스트 시퀀스의 텍스트 쌍으로 이루어진 제1 그룹; 및 서로 다른 특허문서에서 추출된 제1 텍스트 시퀀스 및 제2 텍스트 시퀀스의 텍스트 쌍으로이루어진 제2 그룹을 포함하고,상기 제1 그룹에 속하는 텍스트 쌍에는 제1 레이블이 지정되고, 상기 제2 그룹에 속하는 텍스트 쌍에는 제2 레이블이 지정되는 것을 특징으로 하는, 특허 분석 모델용 학습 데이터의 생성 방법."}
{"patent_id": "10-2024-0075102", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제1 항목은 각 특허문서의 청구범위이고, 상기 제2 항목은 각 특허문서의"}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공신경망 및 텍스트 쌍 임베딩을 이용한 특허 분석 모델의 생성 방법, 특허 분석 방법 및 컴퓨팅 장치가 제공 된다. 여기서 특허 분석 모델용 학습 데이터의 생성 방법은, 독립변수인 텍스트 쌍 및 이에 지정된 종속변수인 레이블을 포함하는 학습 데이터를 생성하는 컴퓨팅 장치에 의해 수행되는 방법으로서, 복수의 특허문서의 제1 항 목으로부터 복수의 제1 텍스트 시퀀스를 추출하고, 복수의 특허문서의 제2 항목으로부터 복수의 제2 텍스트 시퀀 스를 추출하는 단계; 복수의 제1 텍스트 시퀀스 중 어느 하나와, 복수의 제2 텍스트 시퀀스 중 어느 하나를 결합 하여 텍스트 쌍(text pair)을 생성하는 단계; 및 각 텍스트 쌍에 대해 발명의 유사 여부에 관한 레이블을 지정하 는 단계를 포함한다."}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 특허 분석 모델의 생성 방법, 특허 분석 방법 및 컴퓨팅 장치에 관한 것으로서, 더욱 상세하게는 인 공신경망 및 텍스트 쌍 임베딩을 이용하여 발명의 유사성을 추론하는 특허 분석 모델의 생성 방법, 특허 분석 방법 및 컴퓨팅 장치에 관한 것이다."}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "특허는 청구범위에 명시된 발명을 배타적으로 보호하는 권리로서, 특허권을 보유한 기업은 경쟁자가 특허 발명 을 무단으로 사용하는 것을 방지하기 위해 해당 특허를 이용한 제품이나 서비스의 생산 및 판매 등을 금지함으 로써 독점 지배력을 유지할 수 있다. 따라서 정부는 출원된 발명을 심사할 때 기존 기술보다 더 새롭고 진보한 발명만을 등록하도록 엄격하게 심사하고 있다. 그래서 기업이 새로운 제품 개발하거나 연구기관이 연구과제를 선택할 때, 맨 처음으로 하는 중요한 작업은 이 미 존재하는 선행특허가 있는지 조사하고 이를 피할 수 있는 방법을 찾는 것이다. 또한, 특허 침해를 피할 수 없는 경우 해당 특허를 무효화하기 위해 선행 기술을 찾아 내려고 한다. 이러한 특허 분석 작업(Patent Analysis Task)은 기술과 특허법에 대한 전문 지식을 요구하는 노동 집약적인 작 업이다. 특허 문서는 초록, 상세한 설명, 특허청구범위와 같이 자연어로 작성된 텍스트로 구성되기 때문에 딥러 닝 기반의 자연어 처리 분야에서는 특허 문서의 텍스트를 임베딩하고 이를 기반으로 다양한 딥러닝 알고리즘을 이용하여 특허 분석 작업을 자동화하려는 다양한 시도가 있어 왔다. 초기 연구에서는 특허문서의 텍스트 데이터 에서 특징을 추출하기 위해 전처리 작업에 많은 시간을 투자하였다. 그러나 딥러닝 기술이 자연어 처리처리 (NLP) 분야에 폭넓게 적용되면서, 특허 텍스트를 기계 학습 모델에서 사용할 수 있는 적절한 벡터 표현으로 변 환하는 임베딩 기법들이 등장하였고, 이러한 벡터표현을 이용하여 특정 특허 분석 작업에 적용하기 시작했다. 나아가 셀프 어텐션 인코딩/디코딩 구조를 가진 트랜스포머(transformer) 계열의 언어 모델과 같은 문맥의존 단 어 임베딩(context-dependent word embeddings) 기법이 개발되면서 컴퓨팅 장치는 좀더 사람의 자연어의 문맥적 의미를 반영할 수 있게 되었으며, 사전 학습 언어모델의 개발로 특허문서를 자연어 측면에서 언어적으로 이해하 는 데에 상당한 성과를 보였다. 하지만 특허 문서는 보통 주술 간 또는 수식어와 피수식어 간의 거리가 멀어 그 의미의 호응이 잘 이루어지지 않고, 모호한 기술 용어와 신조어로 가득 차 있다는 언어적 특징이 있다. 이러한 언어적 특징은 컴퓨팅을 통한 특허 텍스트의 분석을 어렵게 하고 정확성에 상당한 영향을 미칠 수 있다. 따라서 특허문서에 기재된 문장과 용어의 특성을 제대로 컴퓨팅에 반영하려면 일반 문서가 아닌 특허문서를 학 습하여야 한다. 나아가 어떤 종류의 특허 분석 작업이든, 특허 청구범위의 해석이 전제되어야 하는데, 그 해석에는 청구범위에 기재된 텍스트는 언어적 이해를 바탕으로 다른 특허나 문헌이 아닌 바로 그 해당 특허의 상세한 설명을 직접 참 고하여 법률적으로 해석을 하여야 한다는 법률적 특이성이 존재한다. 따라서 인공신경망을 통한 특허 분석 작업 은 다른 특허 문서가 아닌 해당 발명에 관한 특허문서를 학습하여야 하는 제한이 뒤 따른다. 따라서 다른 문헌이나 특허를 통해 사전 학습한 언어 모델들은 특허문서의 언어적 이해에 의존할 수 있는 특허 분류나 클러스터링(clustering) 등과 같은 작업에서는 상당한 성과를 보았지만, 특허문서의 임베딩 과정에 언어 적 이해에만 의존하고 특허문서의 법률적인 특이성이 충분히 반영되지 않아 여전히 특허청구범위 해석을 전제로 하는 특허 침해분석과 같은 작업에서는 그 성능이 제한되고 있다. 특허 분석 작업은 중요한 전문 분야로, 특허 문서의 청구범위와 발명 설명을 이해하는 것은 특허 침해 여부와 신규성 등의 특허성을 판단하는 데 필수적이다. 그러나 수많은 다른 특허를 학습하거나 일반 문서를 학습하는 기존의 접근 방식은 청구범위와 발명의 설명 간의 상호 작용을 충분히 반영하지 못하여 정확한 특허 침해 판단 에 제약이 있었다. 이에 본 발명자는 오랜 연구와 노력을 기울인 끝에, 특허청구범위와 발명의 설명을 결합한 텍스트 쌍을 벡터로 임베딩하고 그 임베딩 벡터의 유사성을 기준으로 특허성 및 특허침해를 판단하는 모델을 개발하게 되었다. 이하 에서 발명의 유사성이란 컴퓨팅 장치에서는 발명을 표현한 텍스트 임베딩 벡터에 대한 유사성을 의미하는 용어로 사용한다."}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는, 특허법상 청구범위 해석을 위한 법리를 적용한 특허 분석 모델의 생성 방법 을 제공하고자 하는 것이다. 본 발명이 해결하고자 하는 다른 과제는, 이러한 특허 분석 모델에 입력할 학습 데이터의 생성 방법과 학습방법 을 제공하고자 하는 것이다. 본 발명이 해결하고자 하는 다른 과제는, 이러한 특허 분석 모델을 이용하여 발명의 유사성을 기반으로 특허성 및/또는 특허침해 여부를 예측하는 특허 분석 방법을 제공하고자 하는 것이다. 본 발명이 해결하고자 하는 또 다른 과제는, 이러한 특허 분석 모델을 구현한 컴퓨팅 장치를 제공하고자 하는 것이다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제 들은 아래의 기재로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 달성하기 위한 본 발명의 일 실시예에 따른 특허 분석 모델용 학습 데이터의 생성 방법은, 독립변 수인 텍스트 쌍 및 이에 지정된 종속변수인 레이블을 포함하는 학습 데이터를 생성하는 컴퓨팅 장치에 의해 수 행되는 방법으로서, 복수의 특허문서의 제1 항목으로부터 각 특허문서에 대한 제1 텍스트 시퀀스를 추출하고, 상기 복수의 특허문서의 제2 항목으로부터 각 특허문서에 대한 제2 텍스트 시퀀스를 추출하는 단계; 상기 제1 텍스트 시퀀스와 상기 제2 텍스트 시퀀스를 결합하여 텍스트 쌍(text pair)을 생성하는 단계; 및 상기 텍스트 쌍에 대해 발명의 유사 여부에 관한 레이블을 지정하는 단계를 포함한다. 상기 학습 데이터는, 동일한 특허문서 에서 추출된 제1 텍스트 시퀀스 및 제2 텍스트 시퀀스의 텍스트 쌍으로 이루어진 제1 그룹; 및 서로 다른 특허 문서에서 추출된 제1 텍스트 시퀀스 및 제2 텍스트 시퀀스의 텍스트 쌍으로 이루어진 제2 그룹을 포함한다. 상 기 제1 그룹에 속하는 텍스트 쌍에는 제1 레이블이 지정되고, 상기 제2 그룹에 속하는 텍스트 쌍에는 제2 레이 블이 지정된다. 상기 제1 항목은 각 특허문서의 청구범위일 수 있고, 상기 제2 항목은 각 특허문서의 발명의 설명일 수 있다. 소정의 특허문서의 제2 항목을 복수의 임시 텍스트 시퀀스로 분할하고, 각 임시 텍스트 시퀀스의 임베딩 벡터와, 상기 소정의 특허문서의 제1 항목에서 추출된 제1 텍스트 시퀀스의 임베딩 벡터 간의 유사도를 기준으 로 상기 복수의 임시 텍스트 시퀀스로부터 제2 텍스트 시퀀스를 추출할 수 있다. 소정의 특허문서의 제1 항목이 복수의 청구항으로 이루어진 청구범위인 경우, 상기 복수의 청구항 중 독립항으 로부터 상기 제1 텍스트 시퀀스를 추출할 수 있다. 상기 과제를 달성하기 위한 본 발명의 다른 실시예에 따른 특허 분석 모델의 생성 방법은, 텍스트 쌍 임베딩을 기반으로 발명의 유사 여부를 추론하는 특허 분석 모델을 생성하는 컴퓨팅 장치에 의해 수행되는 방법으로서, 독립변수인 복수의 텍스트 쌍, 및 각 텍스트 쌍마다 지정된 발명의 유사 여부에 관한 종속변수인 레이블을 포함 하는 학습 데이터를 준비하는 단계 -상기 각 텍스트 쌍은 복수의 특허문서의 제1 항목으로부터 추출된 각 특허 문서에 대한 제1 텍스트 시퀀스와, 상기 복수의 특허문서의 제2 항목으로부터 추출된 각 특허문서에 대한 제2 텍스트 시퀀스가 결합되어 구성됨-; 상기 복수의 텍스트 쌍을 사전 학습된 언어모델에 입력하여 문장 벡터를 출 력하는 단계; 및 상기 문장 벡터를 분류 작업 모델에 입력하여 얻은 출력과 상기 레이블을 이용하여 상기 사전 학습 언어모델 또는 상기 분류 작업 모델을 최적화하는 단계를 포함한다. 상기 제1 텍스트 시퀀스와 상기 제2 텍스트 시퀀스는 식별 태그에 의해 상기 제1 항목 및 상기 제2 항목으로부 터 각각 자동으로 구별되어 추출되고, 상기 제1 항목은 각 특허문서의 청구범위이고 상기 제2 항목은 각 특허문 서의 발명의 설명일 수 있다. 상기 학습 데이터는, 동일한 특허문서에서 추출된 제1 텍스트 시퀀스 및 제2 텍스트 시퀀스의 텍스트 쌍으로 이 루어진 제1 그룹; 및 서로 다른 특허문서에서 추출된 제1 텍스트 시퀀스 및 제2 텍스트 시퀀스의 텍스트 쌍으로 이루어진 제2 그룹을 포함할 수 있다. 상기 제1 그룹에 속하는 텍스트 쌍에는 제1 레이블이 지정되고, 상기 제2 그룹에 속하는 텍스트 쌍에는 제2 레이블이 지정될 수 있다. 상기 학습 데이터는, 동일한 특허문서에서 추출된 제1 텍스트 시퀀스 및 제2 텍스트 시퀀스의 텍스트 쌍으로 이 루어진 제1 그룹; 및 서로 다른 특허문서에서 추출된 제1 텍스트 시퀀스 및 제2 텍스트 시퀀스의 텍스트 쌍으로 이루어진 제2 그룹을 포함할 수 있다. 상기 사전 학습된 언어모델 및 상기 분류 작업 모델을 학습하는 동안, 각 에포크마다 상기 제1 그룹과 상기 제2 그룹을 교대로 입력하여 각 그룹의 손실값의 평균이 최소화되도록 상기 사전 학습된 언어모델 또는 상기 분류 작업 모델을 최적화할 수 있다. 상기 과제를 달성하기 위한 본 발명의 또 다른 실시예에 따른 특허 분석 방법은, 앞서 생성된 특허 분석 모델을 이용하여 텍스트 쌍 임베딩을 기반으로 발명의 유사 여부를 추론하는 컴퓨팅 장치에 의해 수행되는 방법으로서, 관심 특허문서로부터 제1 텍스트 시퀀스를 추출하는 단계; 대상 발명문서로부터 제2 텍스트 시퀀스를 추출하는 단계; 및 상기 제1 텍스트 시퀀스와 상기 제2 텍스트 시퀀스로 이루어진 텍스트 쌍을 상기 특허 분석 모델에 입 력하여, 상기 대상 발명문서에 기재된 대상 발명과 상기 관심 특허문서에 기재된 관심 발명 간의 유사성을 추론 하는 단계를 포함한다. 상기 제1 텍스트 시퀀스는 상기 관심 특허문서 중 청구범위로부터 추출되고, 상기 대상 발명문서는 상기 대상 발명에 관한 특허문서이고, 상기 제2 텍스트 시퀀스는 상기 대상 발명문서 중 발명의 설명으로부터 추출되고, 상기 유사성에 이용하여 상기 대상 발명문서의 특허성을 판단할 수 있다. 상기 제1 텍스트 시퀀스는 상기 관심 특허문서 중 청구범위로부터 추출되고, 상기 대상 발명문서는 상기 대상 발명이 적용된 제품의 기술 설명 문서이고, 상기 유사성에 이용하여 상기 대상 발명이 상기 관심 특허문서에 대 해 특허침해여부를 판단할 수 있다. 상기 과제를 달성하기 위한 본 발명의 일 실시예에 따른 인공신경망 기반 컴퓨팅 장치는, 독립변수인 텍스트 쌍 및 이에 지정된 종속변수인 레이블을 포함하는 학습 데이터를 생성하는 하나 이상의 프로세서들; 및 상기 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비하되, 복수의 특허문서의 제1 항목으로부터 각 특허문서에 대한 제1 텍스트 시퀀스를 추출하고, 상기 복수의 특허문서의 제2 항목으로부 터 각 특허문서에 대한 제2 텍스트 시퀀스를 추출하고; 상기 제1 텍스트 시퀀스와 상기 제2 텍스트 시퀀스를 결 합하여 텍스트 쌍(text pair)을 생성하고; 상기 텍스트 쌍에 대해 발명의 유사 여부에 관한 레이블을 지정한다. 상기 학습 데이터는, 동일한 특허문서에서 추출된 제1 텍스트 시퀀스 및 제2 텍스트 시퀀스의 텍스트 쌍으로 이 루어진 제1 그룹; 및 서로 다른 특허문서에서 추출된 제1 텍스트 시퀀스 및 제2 텍스트 시퀀스의 텍스트 쌍으로 이루어진 제2 그룹을 포함한다. 상기 제1 그룹에 속하는 텍스트 쌍에는 제1 레이블이 지정되고, 상기 제2 그룹 에 속하는 텍스트 쌍에는 제2 레이블이 지정된다. 상기 과제를 달성하기 위한 본 발명의 다른 실시예에 따른 인공신경망 기반 컴퓨팅 장치는, 텍스트 쌍 임베딩을 기반으로 발명의 유사 여부를 추론하는 특허 분석 모델을 생성하는 하나 이상의 프로세서들; 및 상기 하나 이상 의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비하되, 독립변수인 복수의 텍 스트 쌍, 및 각 텍스트 쌍마다 지정된 발명의 유사 여부에 관한 종속변수인 레이블을 포함하는 학습 데이터를 준비하고 -상기 각 텍스트 쌍은 복수의 특허문서의 제1 항목으로부터 추출된 각 특허문서에 대한 제1 텍스트 시 퀀스와, 상기 복수의 특허문서의 제2 항목으로부터 추출된 각 특허문서에 대한 제2 텍스트 시퀀스가 결합되어 구성됨-; 상기 복수의 텍스트 쌍을 사전 학습된 언어모델에 입력하여 문장 벡터를 출력하고; 상기 문장 벡터에 대한 분류 작업 모델에 입력하여 얻은 출력과 상기 레이블을 이용하여 상기 사전 학습 언어모델 또는 상기 분류 작업 모델을 최적화한다. 상기 과제를 달성하기 위한 본 발명의 또 다른 실시예에 따른 인공지능 기반 컴퓨팅 장치는, 앞서 생성된 특허 분석 모델을 이용하여 텍스트 쌍 임베딩을 기반으로 발명의 유사 여부를 추론하는 하나 이상의 프로세서들; 및 상기 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비하되, 관심 특 허문서로부터 제1 텍스트 시퀀스를 추출하고; 대상 발명문서로부터 제2 텍스트 시퀀스를 추출하고; 상기 제1 텍 스트 시퀀스와 상기 제2 텍스트 시퀀스로 이루어진 텍스트 쌍을 상기 특허 분석 모델에 입력하여, 상기 대상 발 명문서에 기재된 대상 발명과 상기 관심 특허문서에 기재된 관심 발명의 유사성을 추론한다. 기타 실시예들의 구체적인 사항들은 구체적인 내용 및 도면들에 포함되어 있다."}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이 본 발명에 따른 특허 분석 모델의 생성 방법, 특허 분석 방법 및 컴퓨팅 장치에 의하면, 제1 텍스트 시퀀스와 제2 텍스트 시퀀스로 이루어진 텍스트 쌍에 대해 별도의 발명 유사성 분석이나 특허 침해 분석 없이 자동으로 레이블을 지정하여 학습 데이터를 구성할 수 있다. 구체적으로, 제1 텍스트 시퀀스와 제2 텍스트 시퀀스가 동일한 특허문서에서 추출된 경우 유사 또는 침해의 레이블이 자동으로 지정되고, 제1 텍스트 시퀀스 와 제2 텍스트 시퀀스가 서로 다른 특허문서에서 추출된 경우 비유사 또는 비침해로 레이블이 자동으로 지정된 다. 또한 모델이 처리할 수 있는 입력 데이터 또는 토큰의 크기에 제한이 있는 경우, 데이터 전처리 과정을 통해 청 구범위 및/또는 발명의 설명을 구성하는 텍스트를 분할하고 임베딩 벡터 유사도를 이용하여 이들 중 선정된 텍 스트로부터 텍스트 시퀀스를 추출할 수 있다. 또한 학습 데이터를 발명 유사성에 따라 제1 그룹과 제2 그룹으로 구분하고, 서로 다른 데이터셋을 번갈아 가면 서 학습함으로써 모델의 예측 성능을 향상시킬 수 있다."}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 본 발명은 특허 분석 작업을 위한 인공 신경망을 기반으로 한 방법 및 시스템에 관한 것이다. 본 발명에서 제공 하는 특허 분석 작업은 두 발명 간의 유사 판단에 기초한 신규성과 같은 특허성을 판단하는 작업과 특허 침해 여부를 판단하는 작업을 포함하는 개념으로 이해될 수 있다. 따라서 '발명의 유사성'은 특허성 판단 또는 특허 침해 판단의 기준이 된다. 예컨대, '두 발명이 유사하다'는 한 발명이 다른 발명으로 인해 신규성 또는 진보성 이 없어 특허성이 없다는 의미로 판단될 수 있고, 한 발명의 권리범위에 다른 발명이 속하게 되어 특허 침해가 된다는 의미를 판단될 수도 있다. 반대로, '두 발명이 비유사하다'는 한 발명이 다른 발명과 유사하지 않아서 특허성이 있다는 의미로 판단될 수 있고, 한 발명의 권리범위에 다른 발명이 속하지 않아서 특허 비침해가 된다 는 의미로 판단될 수도 있다. 이와 같이 본 명세서에는 '발명의 유사 여부'는 '특허성 유무' 및/또는 '특허침해 여부'를 포함하는 개념으로 사용되며, 이들과 혼용되어 사용될 수 있다. 본 발명의 일 실시예에 따른 컴퓨팅 장치 또는 시스템은 특허 문서의 청구범위와 발명의 설명에서 각각 추출된 텍스트 시퀀스를 결합한 '텍스트 쌍'을 입력 데이터로 활용한다. 본 발명의 일 실시예에 따른 컴퓨팅 장치 또는 시스템은 연속된 텍스트 시퀀스를 처리할 수 있는 자연어 처리 모델을 이용한다. 여기서 '텍스트 시퀀스(text sequence)'는 하나의 문서 내에서 추출한 일련의 시퀀스를 가지는 텍스트 집합을 의미하며, 예를 들어 단어 시퀀스, 문장 시퀀스 등을 포함하는 개념으로 이해될 수 있다. 또한 '문장 시퀀스'에 서 '문장'은 전통적인 언어학적 구조를 반드시 요구하지 않는, 일련의 단어 집합 또는 텍스트 집합을 이해될 수 있다. 본 발명에서 사용되는 컴퓨팅 장치 또는 시스템은 단일 컴퓨팅 장치 혹은 네트워크로 연결된 다수의 컴퓨팅 장 치로 구성될 수 있으며, 폰 노이만, 하버드, CIM(Computing In Memory), 또는 멤리스터를 이용한 뉴로모픽 아키 텍처와 같은 다양한 컴퓨팅 아키텍처를 채택할 수 있다.본 발명의 인공신경망 컴퓨팅 장치 또는 시스템이 수행하는 작업(task)은 발명의 유사성 및 침해 여부를 기준으 로 학습 데이터를 두 클래스(유사/비유사 또는 침해/비침해)로 자동 분류하는 것이다. 컴퓨팅 장치 또는 시스템 은 '텍스트 쌍' 입력 데이터에 대해 자동으로 레이블을 부여하고, 이를 바탕으로 지도학습을 수행한다. 본 발명은 특허 공보와 같은 특허 문서의 유사성 및 침해 여부를 자동으로 분류할 수 있다. 이 시스템은 특허 문서 내의 청구범위와 발명의 설명에서 추출된 텍스트 시퀀스를 결합한 '텍스트 쌍'을 사용한다. 예를 들어, 같은 문서에서 추출된 텍스트 쌍은 '유사 또는 침해'로 분류하기 위해 제1 레이블(예를 들어, 1)로 레이블링되며, 서로 다른 문서에서 추출된 텍스트 쌍은 '비유사 또는 비침해'로 분류하기 위해 제2 레이블(예를 들어, 0)로 레이블링된다. 이러한 레이블링 규칙은 컴퓨팅 장치는 물론 별도의 레이블링 시스템에서 수행될 수도 있지만 텍스트 쌍을 생성 한 후 토큰화 과정 또는 임베딩 과정에서 수행할 수도 있다. 본 발명의 레이블링 규칙은 특허법의 규정에 따라 청구범위가 해당 발명의 설명에 의해 지지되어야 한다는 원칙을 반영한다. 결과적으로, 본 시스템은 전문가의 개입 없이도 학습 데이터를 자동으로 생성할 수 있으며, 이 데이터는 자동 레이블링과 함께 텍스트 쌍으로 구성 된다. 앞에서 특허 문서 내의 청구범위와 발명의 설명에서 각각 텍스트 시퀀스를 추출하여 텍스트 쌍을 생성하는 것으 로 설명하였지만, 본 발명은 이에 한정되지 않으며 특허 문서의 청구범위에서 추출된 텍스트 시퀀스와, 발명이 적용된 제품의 기술적 특징을 설명하는 기술 설명 문서에서 추출한 텍스트 시퀀스를 결합한 텍스트 쌍을 생성하 여 본 발명의 인공신경망에서 비교 분류하는 것도 가능하다. 텍스트 쌍 생성 원리와 이에 대한 레이블링 규칙은 특정 기술 분야뿐만 아니라 범용의 기술 분야에서도 충분한 학습 데이터 셋을 자동으로 생성할 수 있게 해준다. 이러한 학습 데이터는 토큰화 과정을 거쳐 각 텍스트를 분석적으로 처리 가능한 토큰 시퀀스로 변환된다. 이 토 큰들은 다양한 기법을 사용하여 고차원이나 저차원의 벡터로 임베딩된다. 이러한 벡터들은 다양한 신경망 구조 에 적용될 수 있다. 일 실시예에서는 뉴로모픽 컴퓨팅 환경인 스파이킹 신경망(Spiking Neural Networks, SNN)에서도 활용될 수 있 다. 스파이킹 신경망은 임베딩된 벡터들을 시간에 따라 변화하는 스파이크 트레인으로 변환하여 처리한다. 이는 각 차원의 벡터를 다양한 시간 창에서 스파이크로 인코딩하여 신경망이 시간적 동적을 반영하게 함으로써, 더욱 정교한 데이터 처리가 가능하도록 한다. 이러한 입력 임베딩을 동시에 인공신경망 모델에 입력하여 학습을 진행 할 수 있다. 본 발명의 일 실시예에서는 전통적인 컴퓨팅 장치에서 소프트웨어적으로 구현된 심층신경망 모델을 사용하여 학 습을 수행할 수 있다. 자연어 처리 모델의 학습방법은 텍스트 쌍을 처음부터 두 개의 클래스(유사/비유사 또는 침해/비침해)로 분류하 는 작업(task)을 학습하는 방식으로 수행할 수 있으며, 또한 트랜스퍼 러닝(transfer learning) 방식을 통해 사 전에 학습된 모델을 활용하여 효율적으로 학습과정을 진행할 수도 있다. 트랜스퍼 러닝이란 특정 업스트림 작업(upstream task)를 학습한 모델을 다른 다운스트림 작업(downstream task) 수행에 재사용하는 기법으로, 본 발명의 일 실시예에서는 대규모의 텍스트 코퍼스에서 사전에 학습된 (pre-trained) 언어 모델을 활용한다. 예를 들어, 버트(Bidirectional Encoder Representations from Transformers, BERT)와 같은 트랜스포머 인코딩 모델을 사용하여 본 발명의 다운스트림 작업(task)를 위한 학습 을 수행할 수 있다. 버트는 마스크 언어 모델을 통해 대규모 텍스트 코퍼스에서 사전 학습되어 있으며, 이러한 사전 학습된 모델에 원하는 작업 모듈을 덧붙여 다운스트림 작업을 수행할 수 있다. 본 발명의 일 실시예는 사전 학습된 트랜스포머 계열의 언어 모델을 사용하면서, 특허 공보와 같은 특허 문서의 유사성 또는 침해 여부를 자동으로 분류하기 위해 간단한 완전 연결 신경망 층(Full connected layer) 모듈을 추가한 분류 작업 모델을 사용한다. 이 분류 작업 모델은은 사전 학습된 언어 모델의 마지막 블록(레이어)에서 출력된 모든 벡터들의 시퀀스를 입력 데이터로 활용하여, 이를 통해 미세 조정(fine-tuning) 방식으로 모델을 빠르고 정확하게 다운스트림 작업에 맞게 업데이트 한다. 본 발명의 다른 실시예에서는 하드웨어적으로 설계된 인공 신경망을 사용하는 것이 가능하다. 이러한 신경망은 멤리스터를 활용한 크로스바 구조를 포함한다. 크로스바 구조는 두 방향으로 연결된 멤리스터로 구성된 샌드위 치 형태의 행렬로, 메모리 내에서 데이터 계산을 수행하는 신경망 연산을 가능하게 한다. 이 구조 내에서, 멤리스터는 두 개의 멤리스터를 직렬로 연결한 인공 시냅스 구조를 형성한다. 상단 멤리스터는 은(Ag) 필라멘트의 형성 및 파괴를 작동 원리로 하는 '은 멤리스터'(Ag Memristor)로, 구조는 Pt-SiOx,Ag-Pt 이다. 하단 멤리스터 는 '탄탈럼 산화물 멤리스터'(TaxOy Memristor)로, 구조는 TaOx-Ta2O5-Pt 가 될 수 있다. 이러한 하드웨어 기반 모델은 가중치를 하드웨어적으로 학습하며, 이는 신경망의 연산을 물리적 상태 변화를 통 해 직접적으로 구현한다. 결과적으로, 학습을 완료한 모델의 가중치는 특허 기술 분야에서의 침해 여부나 발명 의 유사성을 효과적으로 분류할 수 있도록 최적화된다. 본 발명에 따른 컴퓨팅 장치 또는 시스템은 학습이 완료된 특허 분석 모델을 사용하여 두 발명의 유사 여부 또 는 특허 침해 여부를 판단할 수 있다. 이를 위해, 관심 있는 특허의 특허문서(이를 '관심 특허문서'라 함) 중 청구범위에서 추출한 텍스트 시퀀스와, 비교 대상이 되는 발명을 기술적으로 설명하는 문서(이를 '대상 발명문 서'라 함)에서 추출한 텍스트 시퀀스를 결합하여 '텍스트 쌍'을 형성한다. 여기서 '대상 발명문서'는 대상 발명 에 관한 특허문서의 발명의 설명일 수도 있고, 대상 발명이 적용된 제품의 기술적 특징을 설명하는 기술 설명 문서일 수도 있다. 이 텍스트 쌍은 토큰화 및 임베딩 과정을 거쳐, 입력 임베딩으로 변환된다. 이 입력 임베딩에는 텍스트 쌍의 시 퀀스가 반영되어 있으며, 이는 학습이 완료된 인공 신경망 모델에 입력된다. 모델은 이 입력 데이터를 바탕으로 이진 분류 작업을 수행하여 각 텍스트 쌍이 유사하거나 침해를 나타내는지 여부를 추론할 수 있다. 본 발명의 실시예들은 주로 전통적인 컴퓨터 아키텍처를 기반으로 한 컴퓨팅 장치에서 소프트웨어적으로 구현되 는 예들을 설명한다. 그러나 본 발명의 기술적 사상은 메모리 내 컴퓨팅(CIM) 및 뉴로모픽 컴퓨팅과 같은 새로 운 아키텍처를 사용하는 컴퓨팅 장치에서도 하드웨어적으로 구현될 수 있다. 이는 통상의 기술자가 본 발명을 다양한 기술 환경에 적용할 수 있으며 본 발명은 범용적으로 확장하여 구현될 수 있다. 도 1은 본 발명의 일 실시예에 따른 컴퓨팅 장치를 예시적으로 나타낸 구성도이다. 도시된 실시예에서, 각 컴포 넌트들은 이하에 기술된 것 이외에 상이한 기능 및 능력을 가질 수 있고, 이하에 기술되는 것 이외에도 추가적 인 컴포넌트를 포함할 수 있다. 본 발명의 일 실시예에 따른 컴퓨팅 장치는 텍스트 쌍 임베딩을 기반으로 발명의 유사 여부를 판단하는 인 공신경망 컴퓨팅 장치이다. 여기서 텍스트 쌍 임베딩이란 특허문서 중 청구범위에서 추출한 텍스트 시퀀스와 발 명의 설명에서 추출한 텍스트 시퀀스가 하나의 입력 쌍을 이룬 텍스트 시퀀스 쌍을 의미한다. 또는 '발명의 유 사 여부'는 '특허성 유무' 및/또는 '특허침해 여부'를 포함하는 개념이다. 컴퓨팅 장치는 적어도 하나의 프로세서, 메모리, 버스, 입출력 유닛 및 통신 유닛을 포함한 다. 인공신경망 컴퓨팅 장치는 소프트웨어적으로 본 발명을 프로그래밍된 컴퓨팅 장치일 수도 있고 하 드웨어적으로 구현한 컴퓨팅 장치일 수도 있다. 따라서 멤리스터와 같은 소자를 사용하여 프로세서와 메 모리와 버스의 구성이 하나의 물리적 구조로 프로그래밍될 수도 있다. 이하에서는 전통적인 컴퓨팅 장치 에서 소프트웨어적으로 구현된 예를 중심으로 설명한다. 프로세서는 독립변수인 텍스트 쌍 및 이에 지정된 종속변수인 레이블을 포함하는 학습 데이터를 생성하며, 메모리에 저장된 하나 이상의 프로그램을 실행할 수 있다. 또는 프로세서는 텍스트 쌍 임베딩을 기반 으로 발명의 유사 여부를 추론하는 특허 분석 모델을 생성하며, 메모리에 저장된 하나 이상의 프로그램을 실행할 수 있다. 또는 프로세서는 특허 분석 모델을 이용하여 텍스트 쌍 임베딩을 기반으로 발명의 유사 여 부를 추론하며, 메모리에 저장된 하나 이상의 프로그램을 실행할 수 있다. 상기 하나 이상의 프로그램 은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터 실행 가능 명령어는 프로세서 에 의해 실행되는 경우 컴퓨팅 장치가 본 발명의 일 실시예에 따른 동작들을 수행하도록 구성될 수 있다. 메모리는 컴퓨터 실행 가능 명령어, 데이터 및/또는 다른 적합한 형태의 정보를 저장한다. 메모리에 저장 된 프로그램은 프로세서에 의해 실행 가능한 명령어의 집합을 포함한다. 예를 들어, 메모리는 랜덤 액 세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 하나 이상의 자기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 장치에 의해 액세스되고 원하는 정보를 저장 할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합일 수 있다.버스는 프로세서, 메모리를 포함하여 컴퓨팅 장치의 다양한 컴포넌트들을 상호 연결한다. 다양한 컴포넌트들의 예시로서 입출력 유닛 및 통신 유닛이 있으며 이들은 버스에 연결된다. 예를 들 어, 입출력 유닛으로는 포인팅 장치(마우스 또는 트랙패드 등), 키보드, 터치 입력 장치(터치패드 또는 터치 스크린 등), 음성 또는 소리 입력 장치, 다양한 종류의 센서 장치, 촬영 장치, 디스플레이 장치, 프린터, 스피 커, 네트워크 카드 등을 포함할 수 있다. 통신 유닛은 유무선 네트워크를 통해 컴퓨팅 장치를 외부 장치 와 연결한다. 입출력 유닛 및/또는 통신 유닛은 본 실시예와 같이 컴퓨팅 장치를 구성하는 일 컴포넌 트로서 컴퓨팅 장치의 내부에 포함될 수도 있고, 컴퓨팅 장치와는 구별되는 별개의 장치로 컴퓨팅 장치 와 연결될 수도 있다. 본 발명의 일 실시예에 따른 컴퓨팅 장치는 특허 분석 모델의 생성 단계 및 특허 분석 모델을 이용한 추론 단계를 수행한다. 여기서 특허 분석 모델의 생성 단계 및 특허 분석 모델을 이용한 추론 단계는 반드시 동일한 컴퓨팅 장치에 의해 수행될 필요는 없으며, 각 단계는 독립적인 컴퓨팅 장치에 의해 수행될 수 있다. 상기 특허 분석 모델의 생성 단계는, 학습 데이터를 생성하는 단계 및 모델 학습 단계를 포함한다. 여기서 학습 데이터를 생성하는 단계 및 모델 학습 단계는 반드시 동일한 컴퓨팅 장치에 의해 수행될 필요는 없으며, 각 단 계는 독립적인 컴퓨팅 장치에 의해 수행될 수도 있다. 이하 도 2를 참조하여 본 발명의 일 실시예에 따른 특허 분석 모델용 학습 데이터의 생성 방법에 대해 자세히 설명한다. 도 2는 본 발명의 일 실시예에 따른 학습 데이터의 생성 방법을 나타낸 순서도이다. 특허문서를 기반으로 학습할 경우 청구범위에 기재된 발명과 발명의 설명에 기재된 발명이 유사 관계에 있는지, 비유사 관계에 있는지를 분류하는 작업을 하기 위하여, 일 실시예서는 버트(BERT)와 같은 트랜스포머 계열의 모 델을 이용하여 트랜스퍼 러닝을 수행한다. 즉 텍스트쌍 분류 파인튜닝 모델(Text pair fine-tuning model)을 사 용하여 미세조정한다. 먼저, 텍스트 쌍(text pair)을 생성할 때 아무런 전략 없이 무작위로 텍스트를 추출하여 쌍을 이루도록 하는 것 이 아니라 특허법 상 청구범위 해석의 원칙에 따라 청구범위와 발명의 설명에서 각각 텍스트를 추출하여 텍스트 쌍을 이루도록 한다. 그리고 학습할 데이터 클래스를 두 텍스트가 관련성이 높은 경우, 즉 발명의 설명이 청구 범위에 기재된 발명을 뒷받침하고 있을 경우를 제1 레이블(예를 들어, 유사관계 또는 label 1)로 정의하고, 두 텍스트가 관련성이 적은 경우, 즉 발명의 설명이 청구범위에 기재된 발명을 뒷받침하지 않는 경우를 제2 레이블 (예를 들어, 비유사관계 또는 label 0)로 정의하여 텍스트쌍 분류 파인튜닝 모델(Text pair fine-tuning model)로 학습한다. 본 발명의 일 실시예에 따른 특허 분석 모델용 학습 데이터는 독립변수로서 텍스트 쌍, 그리고 종속변수로서 각 텍스트 쌍에 지정된 레이블을 포함한다. 컴퓨팅 장치는 복수의 특허문서로부터 복수의 제1 텍스트 시퀀스를 추출하고, 복수의 특허문서로부터 복수의 제2 텍스트 시퀀스를 추출한다(S12). 컴퓨팅 장치는 복수의 특허 문서의 제1 항목으로부터 복수의 제1 텍스트 시퀀스를 추출하고, 복수의 특허문서의 제2 항목으로부터 복수의 제2 텍스트 시퀀스를 추출할 수 있다. 구체적으로 컴퓨팅 장치는 복수의 특허문서의 제1 항목으로부터 각 특허문서에 대한 제1 텍스트 시퀀스를 추출하고, 복수의 특허문서의 제2 항목으로부터 각 특허문서에 대한 제2 텍스트 시퀀스를 추출한다. 즉, 제1 텍스트 시퀀스 및 제2 텍스트 시퀀스는 각 특허문서의 서로 다른 항목에서 추출된다. 제1 항목은 각 특허문서의 <청구범위>이고, 제2 항목은 각 특허문서의 <발명의 설명>이다. 국제적으로 합의된 서식을 따르는 특허문서는 <청구범위>와 <발명의 설명>과 같은 항목별로 식별 태그가 사전에 정의되어 있다. 따라서 컴퓨팅 장치는 이러한 식별 태그를 이용하여 각 특허문서로부터 제1 텍스트 시퀀스 및 제2 텍스트 시퀀스를 자동으로 구별하여 추출할 수 있다. 제1 텍스트 시퀀스를 추출하는 단계와 제2 텍스트 시퀀스를 추출하는 단계는 동시에 또는 순차적으로 진행될 수 있다. 컴퓨팅 장치는 제1 텍스트 시퀀스와 상기 제2 텍스트 시퀀스를 결합하여 텍스트 쌍(text pair)을 생성한다 (S14). 텍스트 시퀀스를 추출하는 단계 또는 텍스트 쌍을 생성하는 단계에서 토큰화 작업이 진행될 수 있다. 토 큰화 작업은 단어 토큰화, 문장 토큰화 등이 될 수 있다. 각 텍스트 시퀀스는 시퀀스를 가진 텍스트 집합이다. 가능하다면 하나의 특허 문서 또는 두 개의 특허 문서에서 텍스트를 모두 추출하여 하나의 텍스트 쌍을 구성하는 것이 바람직하다. 그러나 본 발명은 이에 제한되지 않으며, 사전 학습된 언어모델이 가진 입력 토큰 수의 제약이 있는 경우 전처 리를 통해 텍스트를 분할하여 복수의 텍스트 쌍으로 구성할 수 있다. 예를 들어 버트(Bert)의 경우 최대 입력 토큰 크기는 512 개이다. 보통 특허문서의 <청구범위> 텍스트를 토큰화하면 5백개에서 8백개의 토큰이 되고 <발 명의 설명> 텍스트를 토큰화하면 2천개에서 5천개의 토큰이 된다. 이 경우 가급적 가장 적은 수의 그룹의 토큰 시퀀스가 되도록 분할하여 복수의 텍스트 쌍을 생성하여 학습 데이터로 사용하는 것이 바람직하다. 컴퓨팅 장치는 하나의 특허 문서에 포함된 제1 항목 또는 <청구범위>에 해당하는 모든 텍스트로부터 제1 텍 스트 시퀀스를 추출할 수 있다. 만일 사전 학습된 언어모델이 처리할 수 있는 입력 데이터 또는 토큰의 크기에 제한이 있는 경우, 컴퓨팅 장치는 데이터 전처리 과정을 실행하여 제1 항목 또는 <청구범위>의 일부로부터 제1 텍스트 시퀀스를 추출할 수 있다. 예컨대 만일 소정의 특허문서의 제1 항목이 복수의 청구항으로 이루어진 청구범위인 경우, 컴퓨팅 장치는 데이터 전처리 과정을 실행하여 <청구범위>를 구성하는 복수의 청구항 중 하나의 청구항에 해당하는 텍스트로부터 제1 텍스트 시퀀스를 추출할 수 있다. 예를 들어, 제1 텍스트 시퀀스는 청구범위 중 독립항으로부터 추출될 수 있다. 컴퓨팅 장치는 하나의 특허 문서에 포함된 제2 항목 또는 <발명의 설명>에 해당하는 모든 텍스트로부터 제2 텍스트 시퀀스를 추출할 수 있다. 만일 사전 학습된 언어모델이 처리할 수 있는 입력 데이터 또는 토큰의 크기 에 제한이 있는 경우, 컴퓨팅 장치는 데이터 전처리 과정을 실행하여 제2 항목 또는 <발명의 설명>의 일부 로부터 제2 텍스트 시퀀스를 추출할 수 있다."}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이러한 데이터 전처리 방법으로는 사전 학습된 텍스트 요약 모델(예를 들어, ChatGPT 등)이 사용될 수 있다. 또 한 데이터 전처리 방법으로 하나의 특허문서에 포함된 <발명의 설명>을 복수의 임시 텍스트 시퀀스로 분할하고, 각 임시 텍스트 시퀀스와 동일 특허문서의 제1 항목에서 추출된 제1 텍스트 시퀀스와의 임베딩 벡터 간의 유사 도를 산출한 후 유사도를 기준으로 복수의 임시 텍스트 시퀀스로부터 유사도가 높은 제2 텍스트 시퀀스를 추출 할 수도 있다. 예를 들어 제1 텍스트 시퀀스의 임베딩 벡터와 각 임시 텍스트 시퀀스의 임베딩 벡터를 도트 프 로덕트 연산하여 나온 값(즉, 유사도)이 소정의 값 이상인 경우 해당 임시 텍스트 시퀀스로부터 제2 텍스트 시 퀀스를 추출할 수 있다. 이와 같이 하나의 특허문서의 제1 항목 및 제2 항목으로부터 각각 하나의 제1 텍스트 시퀀스 및 하나의 제2 텍 스트 시퀀스가 추출되는 것이 바람직하다. 다만, 본 발명은 이에 한정되지 않으며 하나의 특허문서에 대해 하나 이상의 제1 텍스트 시퀀스 및 하나 이상의 제2 텍스트 시퀀스가 추출될 수도 있다. 컴퓨팅 장치는 데이터 전처리 과정을 실행하여 하나의 특허문서의 <청구범위>에 대해 복수의 제1 텍스트 시퀀스를 추출하고 하나의 특 허문서의 <발명의 설명>에 대해 복수의 제2 텍스트 시퀀스를 추출할 경우, 하나의 특허문서에 대해 복수의 텍스 트 쌍이 생성될 수 있다. 이 경우 학습단계에서 배치 기법을 사용하면 효율적으로 학습할 수 있다. 또한 컴퓨팅 장치는 데이터 전처리 방법을 통해 하나의 특허문서의 <청구범위>로부터 하나의 제1 텍스트 시퀀스를 추출 하고 하나의 특허문서의 <발명의 설명>으로부터 복수의 제2 텍스트 시퀀스를 추출할 경우, 제1 텍스트 시퀀스와 각 제2 텍스트 시퀀스를 결합하여 하나의 특허문서에 대해 복수의 텍스트 쌍이 생성될 수 있다. 상술되니 모든 텍스트 시퀀스의 추출 과정은 상기 텍스트 쌍의 생성 이전이라면 각 텍스트 토큰의 임베딩 이전 에 처리하는 것도 가능하고, 텍스트 토큰의 임베딩 이후에 임베딩된 벡터 행렬 상태로 처리하는 것도 가능하다. 이어서 컴퓨팅 장치는 각 텍스트 쌍에 대해 발명의 유사 여부에 관한 레이블을 지정한다(S16). 본 발명의 일 실시예에서 학습 데이터는, 제1 그룹과 제2 그룹을 포함한다. 제1 그룹에 속하는 텍스트 쌍은 동일한 특허문 서에서 추출된 제1 텍스트 시퀀스 및 제2 텍스트 시퀀스로 이루어지며, 이 텍스트 쌍에는 자동으로 제1 레이블 (예를 들어, 유사 레이블 또는 1)이 지정된다. 이는 텍스트 쌍이 같은 특허문서 내에서 추출되었기 때문에 특허 문서 내 내용이 일관성을 갖는 것으로 가정되며, <청구범위>의 기재 내용은 <발명의 설명>에 의해 지지되어야 한다는 특허법 원칙이 반영된 것이다. 반면, 제2 그룹에 속하는 텍스트 쌍은 서로 다른 특허문서에서 추출된 제1 텍스트 시퀀스 및 제2 텍스트 시퀀스 로 이루어지며, 이 텍스트 쌍에는 자동으로 제2 레이블(예를 들어, 비유사 레이블 또는 0)이 지정된다. 이는 두 텍스트 시퀀스가 서로 다른 특허문서로부터 추출되었기 때문에 각 특허문서의 내용이 독립적이라고 가정되며 <발명의 설명>이 <청구범위>의 기재 내용을 지지하지 않는다는 것을 의미한다. 제1 레이블 또는 유사 레이블은 해당 텍스트 쌍이 특허의 신규성 또는 진보성에 문제가 있을 가능성이 높거나 특허 침해 가능성이 높다는 것을 의미할 수 있다. 반면, 제2 레이블 또는 비유사 레이블은 특허의 신규성 또는 진보성에 문제가 없음을 나타내거나 특허 침해 가능성이 낮다는 것을 의미할 수 있다. 아래 식 1은 <청구범위>와 <발명의 설명>이 결합되어 만들어진 텍스트 쌍이 어떻게 토큰 구조로 변환될 수 있는 지를 나타낸다. 이 구조는 각 텍스트 쌍의 내용을 분석적으로 처리할 수 있도록 토큰화하여 다양한 수준의 벡터 로 임베딩하는 과정을 통해 학습 모델에 입력될 준비를 한다. 본 발명에서 입력 토큰 시퀀스는 [CLS] 토큰으로 시작하여, [SEP] 토큰을 사용해 두 개의 문장 시퀀스를 구분한 다. 여기서 [CLS]는 문장 시퀀스의 시작을 의미하는 특수 토큰이고, [SEP]은 <청구범위>와 <발명의 설명> 사이 의 구분자로 기능한다. 입력 토큰 Input_tokens는 다음과 같이 구성된다: [식 1]"}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서 Claim(i)는 <청구범위>에서 추출된 텍스트 토큰의 시퀀스이며, descript(j)는 <발명의 설명>에서 추출된 텍스트 토큰의 시퀀스이다. 인덱스 i와 j는 각각 <청구범위>와 <발명의 설명>을 식별하는 인덱스이며, n은 <발 명의 설명>을 분할하여 <청구범위>에 대응하여 복수의 텍스트 쌍을 구성할 경우 <발명의 설명>에서 분할된 텍스 트 시퀀스의 총 수를 나타낸다. 만약 i와 j가 동일한 경우, 해당 텍스트 쌍은 동일한 특허 문서에서 추출된 것으로 간주되어 자동으로 유사 레 이블이 지정된다. 반면, i와 j가 서로 다를 경우, 이는 서로 다른 특허 문서에서 추출된 텍스트 쌍을 나타내 며, 이 경우 자동으로 비유사 레이블이 지정된다. 이 레이블링 규칙은 컴퓨팅 장치에 의해 토큰화 과정에서 자동으로 적용되거나, 임베딩 단계에서 실행될 수 있다. 이러한 자동화된 레이블링 절차는 학습 데이터의 준비 과정을 효율화하고, 인공 신경망 학습의 정확성을 보장하는 데 기여한다. 이하 도 3 및 도 4를 참조하여 본 발명의 일 실시예에 따른 특허 분석 모델의 생성 방법에 대해 자세히 설명한 다. 도 3은 본 발명의 일 실시예에 따른 특허 분석 모델의 생성 방법을 나타낸 순서도이다. 도 4는 본 발명의 일 실시예에 따른 특허 분석 모델의 네트워크 구조를 예시적으로 나타낸 도면이다. 본 발명에서 학습에 사용될 인공신경망 모델은 심층 신경망 모델을 소프트웨어적으로 구현한 것일 수도 있고, 하드웨어적으로 구현한 것을 수도 있다. 자연어 처리 모델의 학습방법은 텍스트 쌍을 처음부터 두 개의 클래스 (유사/비유사 또는 침해/비침해)로 분류하는 작업(task)을 학습하는 방식으로 수행할 수도 있으며, 또한 트랜스 퍼 러닝(transfer learning) 방식을 통해 사전에 학습된 모델을 활용하여 효율적으로 학습과정을 진행할 수도 있다. 트랜스퍼 러닝이란 특정 업스트림 작업(upstream task)를 학습한 모델을 다른 다운스트림 작업(dowenstream task) 수행에 재사용하는 기법으로, 본 발명의 일 실시예에서는 대규모의 텍스트 코퍼스에서 사전에 학습된 (pre-trained) 언어 모델을 활용한다. 사전 학습된 언어 모델은 다음 단어 맞추기, 빈칸 채우기 등과 같은 업스트림 작업을 통해 자연어의 풍부한 문 맥을 이해할 수 있도록 학습되어 있다. 예를 들어, 버트(BERT)와 같은 트랜스포머 인코딩 모델은 컴퓨팅 장치 로 하여금 마스크 언어 모델을 통해 대규모 텍스트 코퍼스에서 사전 학습되어 자연어로 작성된 텍스트의 문 맥적 의미를 반영하게 한다. 이어서 발명의 유사성 또는 침해 여부를 자동으로 분류 작업과 같이 본 발명의 다운스트림 작업(task)를 위한 학습을 수행하기 위해 간단한 완전 연결 신경망 층(Full connected layer) 모듈을 추가할 수 있다. 이를 본 발 명의 <분류 작업(task) 모델>이라 한다. 이 분류 작업 모델은 언어 모델의 마지막 블록(레이어)에서 출력된 모든 벡터들의 시퀀스를 입력 데이터로 활용 하여, 이를 통해 미세 조정(fine-tuning) 방식으로 모델을 빠르고 정확하게 다운스트림 작업에 맞게 업데이트 한다. 본 발명의 다른 실시예에서는 하드웨어적으로 설계된 인공 신경망을 사용하는 것이 가능하다. 이러한 신경망은 멤리스터를 활용한 크로스바 구조를 포함한다. 크로스바 구조는 두 방향으로 연결된 멤리스터로 구성된 샌드위 치 형태의 행렬로, 메모리 내에서 데이터 계산을 수행하는 신경망 연산을 가능하게 한다. 이 구조 내에서, 멤리스터는 두 개의 멤리스터를 직렬로 연결한 인공 시냅스 구조를 형성한다. 상단 멤리스터는 은(Ag) 필라멘트의 형성 및 파괴를 작동 원리로 하는 '은 멤리스터'(Ag Memristor)로, 구조는 Pt-SiOx,Ag-Pt 이 다. 하단 멤리스터는 '탄탈럼 산화물 멤리스터'(TaxOy Memristor)로, 구조는 TaOx-Ta2O5-Pt 가 될 수 있다. 이러한 하드웨어 기반 모델은 가중치를 하드웨어적으로 학습하며, 이는 신경망의 연산을 물리적 상태 변화를 통 해 직접적으로 구현한다. 결과적으로, 학습을 완료한 모델의 가중치는 특허 기술 분야에서의 침해 여부나 발명 의 유사성을 효과적으로 분류할 수 있도록 최적화된다. 본 발명에 따른 시스템은 학습이 완료된 모델을 사용하여 두 발명의 유사 여부 또는 특허 침해 여부를 판단할 수 있다. 본 발명의 일 실시예에 따른 <특허 분석 모델>은 트랜스퍼 러닝 방식으로 학습을 진행하여 생성된다. 텍스트 쌍 임베딩을 기반으로 사전 학습된 트랜스포머 계열의 언어모델을 분류 작업(task)로 파인 튜닝하여 생성된 모델이 다. 컴퓨팅 장치는 다음 과정을 거쳐 텍스트 쌍 임베딩을 기반으로 발명의 유사여부를 추론하는 특허 분석 모델을 생성한다. 컴퓨팅 장치는 독립변수인 복수의 텍스트 쌍, 및 각 텍스트 쌍마다 지정된 발명의 유사 여부에 관한 종속변 수인 레이블을 포함하는 학습 데이터를 준비한다(S22). 여기서 각 텍스트 쌍은 복수의 특허문서의 제1 항목으로 부터 추출된 각 특허문서에 대한 제1 텍스트 시퀀스와, 상기 복수의 특허문서의 제2 항목으로부터 추출된 각 특 허문서에 대한 제2 텍스트 시퀀스가 결합되어 구성된다. 컴퓨팅 장치는 복수의 텍스트 쌍을 사전 학습된 언어모델에 입력하고 텍스트 쌍 임베딩을 통해 문장 벡터를 출력한다(S24). 여기서 텍스트 쌍 임베딩은 버트(BERT)의 트랜스포머 인코딩 모델이 채용될 수 있다. 이를 통해 텍스트 쌍은 밀집 벡터(dense vector) 형태의 문장 벡터로 표현될 수 있다. 본 발명을 새로운 아키텍처의 컴퓨 팅 장치에 구현할 때에는 그 아키텍처에 알맞은 입력으로 변환하여야 한다. 예를 들어 뉴로모픽 아키텍처의 스 파이크 신경망을 이용할 경우 상기 문장벡터는 스파이크 트레인으로 변환한다. 이어서 컴퓨팅 장치는 다음 과정을 거쳐 문장 벡터를 분류 작업 모델에 입력하여 얻은 출력과 종속변수인 레이블을 이용하여 사전 학습된 언어모델 또는 상기 분류 작업 모델을 최적화한다(S26). 첫째, 컴퓨팅 장치는 텍스트 쌍의 문장 벡터를 <분류 작업(task) 모델>에 입력한다. 여기서 분류 작업 (task) 모델은 사전 학습된 언어모델의 출력 벡터를 이진 클래스{0, 1}로 라벨링하는 이진 분류기일 수 있다. 예를 들어, 분류 작업(task) 모델은 소프트맥스 함수를 포함하는 이진 분류기로 이루어질 수 있다. 분류 작업 (task) 모델은 완전 연결층(Fully connected Layer)과 같은 다양한 딥러닝 모델로 이루어질 수 있다. 한편 도 3의 예시에서, 사전 학습된 모델(BERT)의 출력인 [CLS] 토큰은 입력된 텍스트 쌍에 대한 총체적 표현이 므로, 해당 [CLS] 토큰의 출력 벡터는 분류 작업(task) 모델의 입력으로 사용되었다. 다만 본 발명은 상기 [CLS] 토근에 한정되는 것은 아니며, 사전 학습된 모델(BERT)의 모든 출력 벡터를 평균 내어, 즉 평균 풀링 (mean pooling)하는 등의 문장 임베딩(sentence BERT) 방식을 사용할 수도 있다. 사전 학습된 언어모델의 출력 벡터는 문장 벡터 또는 텍스트 쌍을 이루는 제1 텍스트 시퀀스(청구범위) 및 제2 텍스트 시퀀스(발명의 설명) 각각의 의미가 응축되어 내포되어 있기 때문에, 분류 작업(task) 모델은 청구범위 와 발명의 설명 간의 관련성이 높을 경우 <유사>로 예측할 것이고, 이들 간의 관련성이 낮은 경우 <비유사>로 예측할 것이다. 둘째, 컴퓨팅 장치는 분류 작업(task) 모델의 예측값(즉, 출력) 및 학습 데이터의 레이블을 기반으로 손실 함수를 이용하여 사전 학습된 언어모델 또는 분류 작업(task) 모델을 최적화한다. 예를 들어, 손실 함수로는 교 차 엔트로피(cross entropy) 함수가 사용될 수 있다. 입력 데이터를 구성하는 각 텍스트 쌍에 대한 특허 분석 모델의 최종 출력이 정답 레이블에 최대한 같아지도록 사전 학습된 언어모델과 분류 작업(task) 모델의 파라미 터를 업데이트한다. 본 발명의 일 실시예에서는 모델의 예측 성능을 향상시키기 위해 학습 데이터의 배치 방식은 두 개의 서로 다른 데이터셋(즉, 제1 그룹 및 제2 그룹)을 번갈아 가면서 학습하는 방식을 사용한다. 구체적으로, 컴퓨팅 장치(1 0)는 사전 학습된 언어모델 및 분류 작업 모델을 학습하는 동안, 각 에포크(epoch)마다 제1 그룹과 제2 그룹을 교대로 입력하여 각 그룹의 손실값의 평균이 최소화도로록 사전 학습된 언어모델 및/또는 분류 작업 모델을 최 적화한다. 하나의 모델이 두 개의 서로 다른 데이터셋을 번갈아 가며 학습하는 기법을 채택하는 배깅(bagging) 과 유사하다. 제1 레이블(유사 레이블 또는 1)이 지정된 제1 그룹과 제2 레이블(비유사 레이블 또는 0)이 지정 된 제2 그룹에 속하는 텍스트 쌍으로 구성된 두 데이터 셋을 각 에포크(epoch)에서 번갈아 가며 모델 학습에 사용한다. 각 데이터 셋은 독립적으로 모델에 입력되어 학습되고, 모델들의 손실을 평균하여 전체 손실을 계산한 다. 이러한 방식으로 각 데이터셋의 특성을 모델에 반영하고, 모델들의 예측을 결합하여 앙상블 효과를 얻을 수 있다. 예컨대, 학습 데이터 중 제1 그룹 및 제2 그룹을 특허 분석 모델에 교대로 학습시키고, 각 그룹의 손실값의 평 균이 최소화되도록 특허 분석 모델의 파라미터를 최적화할 수 있다. 아래 식 2는 손실 함수를 나타낸 것이다. [식 2]"}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서 Loss(1 group)은 제1 그룹에 대한 손실이고, Loss(2 group)은 제2 그룹에 대한 손실이고, Loss(i)는 i 번째 배치이다. 이와 같이 컴퓨팅 장치에서 학습을 반복하여 본 발명의 <분류 작업(task) 모델>이 파인튜닝되면 최적화된 모델의 파라미터를 비롯하여 학습이 완료된 모델을 얻을 수 있다. 이하 도 5를 참조하여 본 발명의 일 실시예에 따른 특허 분석 방법에 대해 자세히 설명한다. 도 5는 본 발명의 일 실시예에 따른 특허 분석 방법을 나타낸 순서도이다. 특허 분석 모델을 이용하여 텍스트 쌍 임베딩을 기반으로 발명의 유사 여부를 추론하는 컴퓨팅 장치는 다음 과정을 거쳐 <대상 발명문서>에 기재된 발명과 <관심 특허문서>에 기재된 발명의 유사 여부를 추론한다. 먼저 컴퓨팅 장치는 관심 특허문서로부터 제1 텍스트 시퀀스를 추출한다(S32). 여기서 제1 텍스트 시퀀스는 관심 특허문서 중 <청구범위>로부터 추출된다. 컴퓨팅 장치는 청구범위에 대응하는 모든 텍스트로부터 제1 텍스트 시퀀스를 추출할 수 있다. 만일 특허 분석 모델이 처리할 수 있는 입력 데이터 또는 토큰의 크기에 제한"}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이 있는 경우, 컴퓨팅 장치는 데이터 전처리 과정을 실행하여 청구범위로부터 주요 특징부를 요약하고 이로 부터 제1 텍스트 시퀀스를 추출할 수도 있다. 예를 들어, 제1 텍스트 시퀀스는 청구범위 중 독립항으로부터 추 출될 수 있다. 이어서 컴퓨팅 장치는 대상 발명문서로부터 제2 텍스트 시퀀스를 추출한다(S34). 만일 대상 발명문서가 대 상 발명에 관한 특허문서인 경우, 제2 텍스트 시퀀스는 대상 발명문서 중 <발명의 설명>으로부터 추출될 수 있 다. 컴퓨팅 장치는 발명의 설명에 대응하는 모든 텍스트로부터 제2 텍스트 시퀀스를 추출할 수 있다. 만일 특허 분석 모델이 처리할 수 있는 입력 데이터 또는 토큰의 크기에 제한이 있는 경우, 컴퓨팅 장치는 데이 터 전처리 과정을 실행하여 특허문서에 포함된 <발명의 설명>을 복수의 임시 텍스트 시퀀스로 분할하고, 각 임 시 텍스트 시퀀스와 동일 특허문서의 제1 항목에서 추출된 제1 텍스트 시퀀스와의 임베딩 벡터 간의 유사도를 산출한 후 유사도를 기준으로 복수의 임시 텍스트 시퀀스로부터 유사도가 높은 제2 텍스트 시퀀스를 추출할 수 도 있다. 만일 대상 발명문서가 대상 발명이 적용된 제품의 기술적 특징을 설명하는 기술 설명 문서일 경우, 컴퓨팅 장치"}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "는 대상 발명문서를 구성하는 모든 텍스트 또는 그 요약으로부터 제2 텍스트 시퀀스를 추출할 수 있다. 컴퓨팅 장치는 제1 텍스트 시퀀스와 제2 텍스트 시퀀스로 이루어진 텍스트 쌍을 앞서 생성된 특허 분석 모 델에 입력한다(S36). 구체적으로, 컴퓨팅 장치는 텍스트 쌍을 사전 학습된 언어모델을 입력하여 텍스트 쌍 임베팅을 통해 문장 벡터를 출력하고, 문장 벡터를 분류 작업 모델에 입력하여 대상 발명문서에 기재된 대상 발 명과 관심 특허문서에 기재된 관심 발명 간의 유사성을 추론한다. 만일 대상 발명문서가 대상 발명에 관한 특허문서인 경우, 컴퓨팅 장치는 추론된 발명의 유사성을 이용하여 대상 발명문서의 특허성(즉, 신규성 또는 진보성)을 판단할 수 있다. 만일 대상 발명문서가 대상 발명이 적용된제품의 기술 설명 문서인 경우, 컴퓨팅 장치는 추론된 발명의 유사성을 이용하여 대상 발명이 관심 특허문 서에 대해 특허침해여부를 판단할 수 있다. [실험예] 본 실험에서는 Hugging Face의 Transformers 라이브러리(BERT 파인튜닝 모델모델)를 사용하였다(T. Wolf et al, \"Huggingface's transformers: State-of-the-art natural language processing,\" arXiv Preprint arXiv:1910.03771, 2019.). <1. 데이터셋> 먼저 미국등록특허 A를 관심특허(이하 \"<특허 1>\"이라 한다)로 선정한다. 이 <특허 1>은 약 4,700단어로 이루어 진 발명의 설명과 약 340단어로 이루어진 청구범위(제1항)으로 구성되어 있다. 비교특허(또는 대상특허)는 관련분야의 특허 중 <특허 1>의 청구범위 범위에 속하지 않는 미국등록 특허 B(이하 \"<특허 2>\"라 한다)로 선택되었으며, 이 텍스트에는 약 1200단어로 이루어진 발명의 설명이 포함되어 있다. 테스트용 특허 \"<특허 3>\"은 <특허 1>의 권리범위에 명백하게 속하는 미국등록 특허 C로 선택되었으며, 약 2500 단어로 이루어진 발명의 설명이 포함되어 있다. 모든 특허는 UTF-8로 인코딩되었다. 청구범위과 발명의 설명을 텍스트 쌍(text pair)으로 결합하였을 때 BERT가 처리할 수 있는 토큰 최대 크기 512개를 넘지 않아야 한다. 이 때 청구항은 분할하지 않고 청구항 전체의 텍스트가 인코딩되도록 한다. 이는 특허 청구범위의 해석은 청구범위 전체로서 해석되어야 한다는 원칙을 따르기 위한 것으로 단순히 문장마다 결합하는 방식이 아니다. 따라서 전체 토큰 수 512에서 청구항 문장 세그먼트가 차지하는 전체 토큰 수를 제외한 공간이 발명의 설명이 차지할 토큰 공간이 된다. 가급적 청구항이 차지하는 토큰 수를 적절하게 줄여 상세한 설명이 결합될 공간을 최 대한 확보하는 것이 바람직하다. 이를 위해 특허 1의 청구항의 핵심특징을 추출하여 약 190 토큰의 한 문장이"}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "되도록 요약하였다. 나머지 여유 토큰은 청구항과 결합할 발명의 설명이 분할된 토큰 크기가 된다. 이와 같은 데이터 전처리는 모두 자동으로 처리 가능하다. 본 실험에서는 발명의 설명은 모두 310 토큰 크기로 분할하였다. 가급적 분할된 <발명의 설명>의 텍스트 개수가"}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "많아지지 않도록 대상 발명의 설명 중 그 발명의 내용과 관련이 없는 노이즈를 제거하기 위해 해당 대상 발명의 <청구범위>의 벡터와 분할된 <발명의 설명>의 벡터 간의 벡터 유사도를 통해 자동으로 전처리를 수행하였다. 그 렇게 분할된 문장은 <특허 2>와 <특허 3> 모두 각각 17개가 되었다. 이렇게 <특허 1>의 청구항과 발명의 설명을 1:1로 결합하여 만들어진 텍스트 쌍(text pair)이 17개씩 생성되었 다. 각 텍스트 쌍의 구조는 앞서 설명한 식 1과 같다. 따라서 <특허 1>의 청구범위와 <특허 1>의 발명의 설명으로 결합된 텍스트 쌍(text pair)은 17개로, 이 텍스트 쌍(text pair)은 모두 라벨 1로 분류된다(텍스트 쌍 1 그룹). 발명의 설명이 특허 청구범위를 그대로 나타내고 있기 때문이다. 나아가 <특허 1>의 청구항과 <특허 2>의 발명의 설명이 결합된 텍스트 쌍을 17개 생성하여 모두 라벨 0으로 분 류한다(텍스트 쌍 2 그룹). <특허 1>의 청구항과 <특허 3>의 발명의 설명이 결합된 텍스트 쌍 17개는 모두 라벨 1로 분류한다 (텍스트 쌍 3 그룹). <2. 실험환경> 앞에서 라벨링된 텍스트 쌍(text pair)으로 구성된 학습 데이터가 생성되면, Hugging Face의 Transformers 라 이브러리 중에서 BertForSequence Classification 모델을 사용하여 학습을 진행한다. 이 모델은 BERT의 양방향 Transformer 아키텍처에 분류를 위한 추가적인 레이어를 추가하여 문장 쌍을 분류할 수 있는 능력을 갖추고 있 다. 모델은 입력으로 주어진 텍스트 쌍에서 각 텍스트의 표현을 추출하고 이를 결합하여 텍스트 쌍의 분류를 수 행한다.추가된 분류 레이어는 보통 하나 이상의 완전히 연결된(fully connected) 레이어와 출력 레이어로 구성되며, 이 레이어는 각 분류 작업에 대한 예측을 생성하는 데 사용된다. 학습 데이터의 배치 방식은 두 개의 서로 다른 데이터셋을 번갈아 가면서 학습하는 방식을 채택한다. 좀 더 상 세하게 설명하면, Dataloader1 (label 1 그룹)과 Dataloader2 (label 0 그룹)는 각각 다른 데이터셋을 나타낸 다. Zip (dataloader1, dataloader2)를 사용하여 두 데이터셋의 배치를 번갈아 가져와서 각 에포크에서 dataloader1의 배치와 dataloader2의 배치가 번갈아 학습에 사용된다. 각 데이터셋은 독립적으로 모델에 입력되 어 학습되고, 모델들의 손실을 평균하여 전체 손실을 계산한다. 이러한 방식으로 각 데이터셋의 특성을 모델에 반영하고, 모델들의 예측을 결합하여 앙상블 효과를 얻을 수 있다. <3. 실험결과 및 학습성능> BERT의 Sequence Classification 모델은 레이블이 있는 텍스트 쌍(text pair) 데이터 임베딩을 입력으로 학습 되며, 일반적으로 softmax 활성화 함수와 교차 엔트로피 손실(cross-entropy loss) 함수를 사용하여 최적화된다. softmax 활성화 함수에서 노드가 2개인 경우로 한정하면 시그모이드 함수와 같아지기 때문에 전형 적인 이진 분류 문제를 처리할 수 있다. 이러한 아키텍처는 기본적으로 Hugging Face에서 제공하는 라이브러리 중 하나인 \"BertForSequenceClassification\" 텍스트 분류 모델을 사용한다. 앞에서 언급한 바와 같이 학습 데이터를 label 1 그룹과 label 0 그룹을 번갈아 학습시키면서 각각 그룹의 손실 값을 평균하여 최적화하고 그 데이터 전체 손실의 평균값을 학습성능 측정을 위한 손실값으로 정의한다(식 2 참 조). 표 1은 본 발명의 일 실시예에 따른 특허 분석 모델의 성능을 측정한 결과이다. 이 텍스트쌍(text pair) 그룹 1 과 그룹 2를 텍스트 쌍(text pair) 분류 모델에 넣어 학습한 결과 학습 성능은 15 에포크만에 약 80%의 정확도 를 달성하였다. [표 1] <5. 예측성능 평가> 예측성능 평가를 위해, <특허 1>과 동일한 발명을 다른 표현과 다른 용어로 설명한 다른 <특허 3>과, <특허 1> 과 동일한 기술 분야의 발명이나 전혀 다른 기술을 특징으로 하는 <특허 4>를 확보하였다. <특허 3> 의 발명의 설명과 <특허 1>의 청구범위를 추출하여 텍스트 쌍으로 미세 조정된 학습 모델에 입력할 때 유사 여부를 예측하 고 있는지를 확인하였다. <특허 3>은 사실상 기술적 사상은 같으나 사용한 표현이나 용어가 다른 방식으로 설명 된 특허 문서이었기에 그 침해판단의 성능은 의미가 크다고 할 수 있다. 먼저 이미 <특허 1>의 청구범위에 기재된 특허발명을 침해한 것으로 알고 있는 <특허 3>의 상세한 설명을 <특허 1>의 청구범위와 텍스트 쌍으로 결합하여 본 발명의 특허 분석 모델에 넣어 예측해보았다. <특허 1 >의 청구범위와 <특허 3>의 발명의 설명을 분할하여 결합한 텍스트 쌍은 총17개가 생성되었다. 이 텍스 트 쌍은 침해로 분류되기에 모두 라벨이1을 갖는다(텍스트 쌍 3 그룹). 관심특허와 침해 관계에 있는지를 검증하려는 발명에 대한 텍스트 쌍 토큰이 완성되면, 이 토큰을 학습된 Bert 모델에 넣어 분류결과를 출력한다. 분류결과는 label이 0이면 침해 가능성이 낮은 것을 의미하고, 1이면 침해 가능성이 높다는 것을 의미한다. 아래 표 2에 나타난 바와 같이, 텍스트 쌍 3 그룹으로 테스트한 결과, 모두 라벨1으로 예측되었다. 이것을 실제 검증 데이터의 라벨과 같은 결과이다. [표 2]"}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "또는 <특허 4>의 경우에 대한 성능 역시 큰 차이가 없었다. 위에서 설명한 방식으로 하나의 관심 특허문서에서 추출한 청구항과 해당 발명을 설명한 텍스트 쌍(text pair) 을 라벨1로 지정하고, 청구범위와 다른 발명을 기술한 다른 특허문서의 발명의 설명을 텍스트 쌍(text pair)으 로 생성하여 라벨0으로 지정하여 학습 데이터로 사용하는 것은 이진 분류 튜닝 학습을 통해 청구범위를 발명의설명과 비교해 해석하는 효과가 있다는 점이 실증되었다. 앞서 언급된 시스템, 기능부, 모듈 등은 컴퓨터 프로그램으로서, 예를 들어 컴퓨터 판독가능 저장매체(computer readable storage medium)에 저장(store)되거나 적재(load)된 하나 이상의 프로세서(processor)에 의해 구현되 는 복수의 프로그램 모듈(program module)로 구성될 수 있다. 또한 순서도(flowchart)에 언급된 각 단계는 컴퓨 터 프로그램, 프로그램 모듈, 또는 컴퓨터 실행 가능 명령(computer-executable instruction) 등으로 이루어질 수 있다."}
{"patent_id": "10-2024-0075102", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "이상 첨부된 도면을 참조하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있 다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적 이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2024-0075102", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 컴퓨팅 장치를 예시적으로 나타낸 구성도이다. 도 2는 본 발명의 일 실시예에 따른 학습 데이터의 생성 방법을 나타낸 순서도이다. 도 3은 본 발명의 일 실시예에 따른 특허 분석 모델의 생성 방법을 나타낸 순서도이다. 도 4는 본 발명의 일 실시예에 따른 특허 분석 모델의 네트워크 구조를 예시적으로 나타낸 도면이다. 도 5는 본 발명의 일 실시예에 따른 특허 분석 방법을 나타낸 순서도이다."}
