{"patent_id": "10-2022-0184923", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0102660", "출원번호": "10-2022-0184923", "발명의 명칭": "이미지에 포함된 객체를 인식하는 시스템 및 방법", "출원인": "경북대학교 산학협력단", "발명자": "박대진"}}
{"patent_id": "10-2022-0184923", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이미지에 포함되는 객체를 인식하는 시스템으로서,촬영 장치로부터 제1 이미지를 수신하는 이미지 수신부;상기 제1 이미지에 포함된 사람을 확인하고, 상기 제1 이미지에 상기 확인된 사람이 표시된 제2 이미지를 생성하는 객체 표시부;상기 제2 이미지에 이진화(binarize) 동작을 수행하여 제3 이미지를 생성하는 이진화 이미지 생성부;상기 제3 이미지와 상기 제1 이미지를 합성하여 마스킹된 제4 이미지를 생성하는 마스킹 이미지 생성부;상기 제4 이미지에 대하여 임계 신뢰(threshold of confidence)값을 설정하고, 상기 설정된 임계 신뢰 값에 기초하여 제5 이미지를 생성하는 임계 신뢰 이미지 생성부; 및상기 제5 이미지와 상기 제1 이미지를 합성하여 제6 이미지를 생성하는 이미지 합성부를 포함하는 것을 특징으로 하는, 이미지에 포함되는 객체를 인식하는 시스템."}
{"patent_id": "10-2022-0184923", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 이미지 수신부는,상기 촬영장치로부터 수신한 제1 이미지의 크기를 변환하는 이미지 전 처리(Preprocessing) 과정을 더 수행하는것을 특징으로 하는, 이미지에 포함되는 객체를 인식하는 시스템."}
{"patent_id": "10-2022-0184923", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 객체 표시부는,상기 확인된 사람을 특정 색으로 표시하고, 상기 특정 색으로 표시된 사람이 포함된 제2 이미지를 생성하는 것을 특징으로 하는, 이미지에 포함되는 객체를 인식하는 시스템."}
{"patent_id": "10-2022-0184923", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 이진화 동작은, 상기 제2 이미지에 포함된 특정 색으로 표시된 사람을 제외한 영역을 제거하는 동작인 것을 특징으로 하는, 이미지에 포함되는 객체를 인식하는 시스템."}
{"patent_id": "10-2022-0184923", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,상기 제3 이미지와 상기 제1 이미지를 합성하는 과정은,OpenCV(Open Source Computer Vision) 이미지 처리 라이브러리의 비트 연산(bitwise operation)에 기초하여 수행되는 것을 특징으로 하는, 이미지에 포함되는 객체를 인식하는 시스템."}
{"patent_id": "10-2022-0184923", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서,공개특허 10-2024-0102660-4-상기 임계 신뢰 이미지 생성부는,상기 임계 신뢰 값에 기초하여, 상기 제4 이미지에 포함된 사람을 둘러싸는 사각형 이미지 및 상기 제4 이미지에 포함된 사람이 실제 사람일 확률 값이 표시된 제5 이미지를 생성하는 것을 특징으로 하는, 이미지에 포함되는 객체를 인식하는 시스템."}
{"patent_id": "10-2022-0184923", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,상기 제5 이미지는,상기 제4 이미지에 포함된 사람의 총 인원 수 정보가 표시되는 것을 특징으로 하는, 이미지에 포함되는 객체를인식하는 시스템."}
{"patent_id": "10-2022-0184923", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "이미지에 포함되는 객체를 인식하는 방법으로서,촬영 장치로부터 제1 이미지를 수신하는 단계;상기 제1 이미지에 포함된 사람을 확인하고, 상기 제1 이미지에 상기 확인된 사람이 표시된 제2 이미지를 생성하는 단계;상기 제2 이미지에 이진화(binarize) 동작을 수행하여 제3 이미지를 생성하는 단계;상기 제3 이미지와 상기 제1 이미지를 합성하여 마스킹된 제4 이미지를 생성하는 단계;상기 제4 이미지에 대하여 임계 신뢰(threshold of confidence)값을 설정하고, 상기 설정된 임계 신뢰 값에 기초하여 제5 이미지를 생성하는 단계; 및상기 제5 이미지와 상기 제1 이미지를 합성하여 제6 이미지를 생성하는 단계를 포함하는 것을 특징으로 하는,이미지에 포함되는 객체를 인식하는 방법."}
{"patent_id": "10-2022-0184923", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 이미지에 포함되는 객체를 인식하는 시스템으로서 촬영 장치로부터 제1 이미지를 수신하는 이미지 수 신부, 상기 제1 이미지에 포함된 사람을 확인하고, 상기 제1 이미지에 상기 확인된 사람이 표시된 제2 이미지를 생성하는 객체 표시부, 상기 제2 이미지에 이진화(binarize) 동작을 수행하여 제3 이미지를 생성하는 이진화 이 미지 생성부, 상기 제3 이미지와 상기 제1 이미지를 합성하여 마스킹된 제4 이미지를 생성하는 마스킹 이미지 생 성부, 상기 제4 이미지에 대하여 임계 신뢰(threshold of confidence)값을 설정하고, 상기 설정된 임계 신뢰 값 에 기초하여 제5 이미지를 생성하는 임계 신뢰 이미지 생성부 및 상기 제5 이미지와 상기 제1 이미지를 합성하여 제6 이미지를 생성하는 이미지 합성부를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0184923", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이미지에 포함된 객체를 인식하는 시스템 및 방법에 관한 것으로, 보다 상세하게는, 인공지능 모델을 활용하여 이미지에 포함된 객체를 인식하는 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0184923", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술의 발전으로 자동차부터 사물인터넷까지 다양한 분야의 산업이 발전하고 있다. 인공지능 기술은 여러 데이터의 입력을 계산하여 사용자에게 필요한 데이터를 제공할 수 있다. 사용자 또는 사용자 장비로부터 데이터를 수신할 때 여러 종류의 센서가 사용될 수 있지만, 이러한 센서들 중에서 카메라 센서와 센서로부터 입 력된 시각정보를 처리하는 방법이 현재 활발히 연구되고 있다. 연구되는 방법들 중 머신러닝(Machine Learning)과 딥러닝(Deep learning)을 통하여 학습된 데이터로 시각 데이 터를 이용한 물체 인식 방법이 주목받고 있다. 하지만 이러한 방법들은 카메라 데이터의 큰 용량과 이미지 처리 의 연산량이 많아 실시간으로 처리되기 어려운 문제점이 있다. 또한 효율적으로 인공지능이 구현되기 위해서는 경량화된 임베디드 보드가 사용되어야 하는데 방대한 연산량이 적용되기에는 적합하지 않다는 문제가 있다. 이와 같이, 카메라 센서를 활용한 물체 인식 방법에 있어 알고리즘의 경량화는 해결해야 할 과제였으며 현재 다 양한 방법으로 연구가 진행되고 있지만, 통상적으로 활용되는 카메라 센서 이미지 기반 물체 인식 딥러닝 모델 은 실행시간, 연산량이 크다는 문제점이 존재하였다. 즉, 기존 딥러닝 타깃 물체 인식 방법은 GPU등 성능이 높 은 시스템을 기반으로 개발되고 있어, 경량화 임베디드 보드에서 정확한 타깃 인식이 실시간으로 어렵다는 문제 점이 있다."}
{"patent_id": "10-2022-0184923", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2022-0184923", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기와 같은 문제점을 해결하기 위한 본 발명의 목적은 경량화된 딥러닝 모델과 무거운 딥러닝 모델 2가지를 사 용하여 실시간으로 이미지에 포함된 사람을 효율적으로 인식할 수 있는 시스템 및 방법을 제공하는 것이다."}
{"patent_id": "10-2022-0184923", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른 이미지에 포함된 객체를 인식하는 시스템은 촬영 장치 로부터 제1 이미지를 수신하는 이미지 수신부, 상기 제1 이미지에 포함된 사람을 확인하고, 상기 제1 이미지에 상기 확인된 사람이 표시된 제2 이미지를 생성하는 객체 표시부, 상기 제2 이미지에 이진화(binarize) 동작을 수행하여 제3 이미지를 생성하는 이진화 이미지 생성부, 상기 제3 이미지와 상기 제1 이미지를 합성하여 마스킹 된 제4 이미지를 생성하는 마스킹 이미지 생성부, 상기 제4 이미지에 대하여 임계 신뢰(threshold of confidence)값을 설정하고, 상기 설정된 임계 신뢰 값에 기초하여 제5 이미지를 생성하는 임계 신뢰 이미지 생 성부 및 상기 제5 이미지와 상기 제1 이미지를 합성하여 제6 이미지를 생성하는 이미지 합성부를 포함하는 것을 특징으로 한다. 또한, 상기 이미지 수신부는, 상기 촬영장치로부터 수신한 제1 이미지의 크기를 변환하는 이미지 전 처리 (Preprocessing) 과정을 더 수행하는 것을 특징으로 한다. 또한, 상기 객체 표시부는, 상기 확인된 사람을 특정 색으로 표시하고, 상기 특정 색으로 표시된 사람이 포함된 제2 이미지를 생성하는 것을 특징으로 한다. 또한, 상기 이진화 동작은, 상기 제2 이미지에 포함된 특정 색으로 표시된 사람을 제외한 영역을 제거하는 동작 인 것을 특징으로 한다. 또한, 상기 제3 이미지와 상기 제1 이미지를 합성하는 과정은, OpenCV(Open Source Computer Vision) 이미지 처리 라이브러리의 비트 연산(bitwise operation)에 기초하여 수행되는 것을 특징으로 한다. 또한, 상기 임계 신뢰 이미지 생성부는, 상기 임계 신뢰 값에 기초하여, 상기 제4 이미지에 포함된 사람을 둘러 싸는 사각형 이미지 및 상기 제4 이미지에 포함된 사람이 실제 사람일 확률 값이 표시된 제5 이미지를 생성하는 것을 특징으로 한다. 또한, 상기 제5 이미지는, 상기 제4 이미지에 포함된 사람의 총 인원 수 정보가 표시되는 것을 특징으로 한다. 또한, 본 발명의 일 실시예에 따른 이미지에 포함된 객체를 인식하는 방법은 촬영 장치로부터 제1 이미지를 수 신하는 단계, 상기 제1 이미지에 포함된 사람을 확인하고, 상기 제1 이미지에 상기 확인된 사람이 표시된 제2 이미지를 생성하는 단계, 상기 제2 이미지에 이진화(binarize) 동작을 수행하여 제3 이미지를 생성하는 단계, 상기 제3 이미지와 상기 제1 이미지를 합성하여 마스킹된 제4 이미지를 생성하는 단계, 상기 제4 이미지에 대하 여 임계 신뢰(threshold of confidence)값을 설정하고, 상기 설정된 임계 신뢰 값에 기초하여 제5 이미지를 생 성하는 단계 및 상기 제5 이미지와 상기 제1 이미지를 합성하여 제6 이미지를 생성하는 단계를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0184923", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 이미지에 포함된 객체를 인식하는 시스템 및 방법을 통하여 실시간으로 빠르고 정확하게 사람을 인식할 수 있다. 또한 적은 전력 소모를 통하여 안정적으로 사람을 인식할 수 있다. 또한 경량화 임베디드 보드 상에서 용이하게 구현이 가능하여 저가격 경량화된 응용 분야에 활용될 수 있다. 또한 복수의 사람들을 동시에 인식할 수 있어 사용될 수 있는 분야가 매우 넓다. 또한 이미지 처리 방식을 복수 의 단계로 나누어 수행함으로써 높은 정확도로 신속한 처리가 가능하다. 또한 다양한 환경에서 정확도가 크게 변하지 않는 안정적인 시스템을 제공할 수 있다. 다만, 본 발명의 실시 예들에 따른 이미지에 포함된 객체를 인식하는 시스템 및 방법이 달성할 수 있는 효과는 이상에서 언급한 것들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 발명이 속하"}
{"patent_id": "10-2022-0184923", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0184923", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명 의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의 해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된 다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유 사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다.다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 본 발명을 설 명함에 있어 전체적인 이해를 용이하게 하기 위하여 도면상의 동일한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 도 1은 본 발명에 따른 이미지에 포함된 객체를 인식하는 시스템의 개념도이다. 도 1을 참조하면, 본 발명에 따른 이미지에 포함된 객체를 인식하는 시스템은 촬영 장치와 네트워크를 통 해 상호 연결될 수 있다. 이미지에 포함된 객체를 인식하는 시스템과 촬영 장치는 네트워크를 통하여 데 이터 송수신 동작을 수행할 수 있다. 네트워크(network)는 WiFi(wireless fidelity)와 같은 무선인터넷, WiBro(wireless broadband internet) 또는 WiMax(world interoperability for microwave access)와 같은 휴대인터넷, GSM(global system for mobile communication) 또는 CDMA(code division multiple access)와 같은 2G 이동통신망, WCDMA(wideband code division multiple access) 또는 CDMA2000과 같은 3G 이동통신망, HSDPA(high speed downlink packet access) 또는 HSUPA(high speed uplink packet access)와 같은 3.5G 이동통신망, LTE(long term evolution)망 또는 LTE-Advanced망과 같은 4G 이동통신망, 및 5G 이동통신망 등을 포함할 수 있다. 또한 촬영 장치는 통신이 가능한 데스크탑 컴퓨터(desktop computer), 랩탑 컴퓨터(laptop computer), 태블릿 (tablet) PC, 무선전화기(wireless phone), 모바일폰(mobile phone), 스마트 폰(smart phone), 스마트 워치 (smart watch), 웹캠(webcam)과 같은 다양한 형태의 장치일 수 있다. 도 2는 본 발명에 따른 이미지에 포함된 객체를 인식하는 시스템의 블록도이다. 도 2를 참조하면, 본 발명에 따른 이미지에 포함된 객체를 인식하는 시스템은 유무선 통신망을 통해 연결 되는 촬영 장치와 연계하여 서비스 제공에 필요한 동작을 수행할 수 있다. 이미지에 포함된 객체를 인식하는 시 스템에 의해 제공되는 서비스는 웹 기반 어플리케이션 서비스일 수 있다. 본 발명에 따른 이미지에 포함 된 객체를 인식하는 시스템은 서버의 역할을 수행할 수 있다. 또한 본 발명에 따른 이미지에 포함된 객체를 인식하는 시스템은 경량화된 임베디드 보드에서 객체 인식 방법이 실시간으로 실행되도록 분업화된 알고리즘 방식(Semantic segmentation, YOLO)으로 수행될 수 있다. 구 체적으로 연산량을 줄이고 정확도를 높이기 위하여 2개의 딥러닝 기반 시스템에 기반하여 동작을 수행할 수 있 다. 한편, 본 발명에 따른 이미지에 포함된 객체를 인식하는 시스템은 이미지 수신부, 객체 표시부 , 이진화 이미지 생성부, 마스킹 이미지 생성부, 임계 신뢰 이미지 생성부 및 이미지 합성 부를 포함할 수 있다. 본 발명에 따른 이미지 수신부는 촬영 장치로부터 원본 이미지인 제1 이미지를 수신할 수 있다. 이미지 수 신부는 촬영장치로부터 수신한 제1 이미지의 크기를 변환하는 이미지 전 처리(Preprocessing) 과정을 수행 할 수 있다. 도 3은 본 발명에 따른 Semantic segmentation을 수행하여 이미지의 크기를 변환하는 과정을 도시 한 개념도이다. 도 3을 참조하면, 이미지 수신부는 수신한 제1 이미지의 크기가 640*480인 경우, 이를 ENet에서 사용할 수 있는 256*256의 크기로 변환할 수 있다. 이를 통하여 연산의 효율성을 높일 수 있다. 보다 구체적으로, 이미지 수신부는 촬영 장비로부터 수신한 제1 이미지를 OpenCV의 함수를 사용하여 프레 임 단위로 나누어 처리함으로써 효율성을 향상시킬 수 있다. 즉, 이미지 수신부는 추후 설명되는 ENet에서 사용할 수 있도록 이미지를 256*256의 크기로 전환할 수 있다.다시 도 2를 참조하면, 본 발명에 따른 객체 표시부는 제1 이미지에 포함된 사람을 확인하고, 제1 이미지 에 확인된 사람이 표시된 제2 이미지를 생성할 수 있다. 구체적으로, 객체 표시부는 제1 이미지에 포함된 사람을 특정 색으로 표시하고, 특정 색으로 표시된 사람이 표시된 제2 이미지를 생성할 수 있다. 여기서, 제1 이미지에 포함된 사람을 확인하는 동작은 시멘틱 분할(Semantic segmentation) 방법의 일 구성요소 일 수 있고, 객체 표시부는 관심 객체(예를 들어, 사람)를 Semantic segmentation에 기초하여 특정 색으로 표현할 수 있다. 여기서 Semantic segmentation은 이미지 내의 모든 픽셀을 지정된 클래스(class)로 분류하여 객체를 인식하는 방법일 수 있다. 일 실시예로서, Semantic segmentation 동작은 ENet(Efficient neural network)로 수행될 수 있다. ENet은 ResNet 알고리즘 모델을 사용한 딥러닝 기반 Semantic segmentation 구조일 수 있다. 기존에 수행되는 방법은 픽셀 단위로 객체 클래스를 분류하기 위해서 많은 연산량과 전력소모가 크고 처리속도가 느리지만, ENet은 deep neural network 구조를 가져 임베디드 보드에서 실행 가능할 수 있다. ENet은 인코더(encoder)와 디코더 (decoder)로 구성될 수 있고, 13개의 컨볼루션(convolution) 필터를 가질 수 있다. 도 4는 본 발명에 따른 Semantic segmentation을 수행하여 객체를 특정한 결과를 도시한 것이고, 도 5는 본 발 명에 따른 Semantic segmentation을 수행함에 있어 객체에 따라 지정되는 색을 도시한 것이다. 도 4 및 도 5를 참조하면, 각 클래스에 지정된 색이 사용되어 이미지 내의 객체가 분류되는 것을 확인할 수 있다. 다시 도 2를 참조하면, 본 발명에 따른 이진화 이미지 생성부는 제2 이미지에 이진화(binarize) 동작을 수 행하여 제3 이미지를 생성할 수 있다. 여기서, 이진화 동작은 제2 이미지에 포함된 특정 색으로 표시된 사람을 제외한 영역을 제거하는 동작일 수 있다. 또한 본 발명에 따른 마스킹 이미지 생성부는 제3 이미지와 제1 이미지를 합성하여 마스킹된 제4 이미지를 생성할 수 있다. 여기서 제3 이미지와 상기 제1 이미지를 합성하는 과정은 OpenCV(Open Source Computer Vision) 이미지 처리 라이브러리의 비트 연산(bitwise operation)에 기초 하여 수행될 수 있다. 도 6은 본 발명에 따른 Semantic segmentation을 수행하는 과정에서 이진화 동작 및 마스킹 이미지를 생성하는 과정이 구현되는 시스템 코드를 도시한 것이다. 도 6을 참조하면, 본 발명에 따른 이진화 이미지 생성부는 ENet에서 사람만 인식하도록 훈련된 모델을 불러온 뒤 추가 동작을 수행할 수 있다. Semantic Segmentation이 된 결과 값은 인식된 사람에 색이 입혀져서 출력되므로 마스킹을 하기 위해서는 색이 입혀진 부분만 추출되어야 할 수 있다. 먼저 이진화 이미지 생성부는 결과값에서 라벨이 된 부분을 배열로 바꿔준 뒤 이미지 배열과 병합할 수 있다. 이진화 이미지 생성부는 마스킹하기 전 마스크 배열을 초기화하고 배경의 복잡도에 따른 연산량을 계산하기 위하여 변수들을 초기화할 수 있다. 이진화 이미지 생성부는 마스킹을 위해 segmentation 된 결과 이미지의 배열이 0이 아니면 마스크 배열에 1을 입력하여 이진화 동작을 수행할 수 있다. 도 7은 본 발명에 따른 Semantic segmentation을 수행하는 과정에 서 원본 이미지와 이진화된 이미지를 도시한 것이다. 이진화 이미지 생성부는 배경에 대해 인식된 물체가 어느 정도의 비율을 차지하는지 확인하기 위해 area 변수에 1씩 추가할 수 있다. 만약 segmentation 된 결과 이 미지의 배열이 0이 아니라면 배경의 분산을 구해주기 위하여 원본 이미지의 값을 더해주고 area_bac의 변수에도 1씩 추가할 수 있다. 또한 이진화 이미지 생성부는 배경의 RGB 값의 분산을 구하기 위해 배경의 평균값을 계산한 후, 편차의 합 을 계산할 수 있고, 이후 편차의 합을 전체 배경의 원소 수로 나누어 분산 값을 계산할 수 있다. 이후, 마스킹 이미지 생성부는 마스킹 된 이미지를 만들어주기 위하여 원본 이미지를 배열로 변환 후 OpenCV(Open Source Computer Vision) 이미지 처리 라이브러리의 비트 연산(bitwise operation)을 이용하여 마 스크와 원본 이미지를 합성할 수 있다. 도 8은 본 발명에 따른 Semantic segmentation을 수행하는 과정에서 원 본 이미지와 이진화된 이미지가 합성된 마스킹 이미지를 도시한 것이다. 추가로 마스킹 이미지 생성부는 해당 처리 과정의 연산량을 계산하기 위하여 앞서 생성한 메모리 사용량 함수를 호출할 수 있다. 이와 같이, 이미지 수신부, 객체 표시부, 이진화 이미지 생성부 및 마스킹 이미지 생성부 에 의하여 수행되는 과정은 Semantic segmentation 과정으로 정의될 수 있다.다시 도 2를 참조하면, 본 발명에 따른 임계 신뢰 이미지 생성부는 제4 이미지에 대하여 임계 신뢰 (threshold of confidence)값을 설정하고, 설정된 임계 신뢰 값에 기초하여 제5 이미지를 생성할 수 있다. 여기 서, 제5 이미지는 제4 이미지에 포함된 사람을 둘러싸는 사각형 이미지 및 제4 이미지에 포함된 사람이 실제 사 람일 확률 값이 표시될 수 있다. 또한 제5 이미지는 제4 이미지에 포함된 사람의 총 인원 수 정보가 추가적으로 표시될 수 있다. 한편, 본 발명에 따른 이미지 합성부는 제5 이미지와 제1 이미지를 합성하여 제6 이미지 를 생성할 수 있다. 임계 신뢰 이미지 생성부 및 이미지 합성부에 의하여 수행되는 과정은 YOLO를 활용하여 수행될 수 있 다. 여기서 YOLO(You Look Only Once)는 딥러닝 기반 실시간 이미지 검출 프로그램일 수 있다. 본 발명에 따른 이미지에 포함된 객체를 인식하는 시스템은 앞서 Semantic segmentation으로 ROI 마스킹한 이미지를 YOLO(You Only Look Once)를 활용하여 객체 인식 동작을 수행할 수 있다. 즉, 본 발명에 따른 이미지에 포함된 객체를 인식하는 시스템은 마스킹 된 이미지를 YOLO의 모델로 객체를 인식하여 인식된 객체를 둘러싸는 사각형 이미지와 확률을 출력할 수 있다. 도 9는 본 발명에 따른 YOLO 객체 인식 방법을 활용하여 객체를 인식하는 과정이 구현되는 시스템 코드를 도시 한 것이다. 도 9를 참조하면, 임계 신뢰 이미지 생성부는 Semantic segmentation으로 ROI가 마스킹 된 이 미지를 수신하여 tfnet을 사용하여 이전에 빌드한 모델로 이미지를 분석할 수 있다. 이때 임계 신뢰 이미지 생 성부는 처리한 시간과 fps를 계산해주기 위하여 start_time 변수에 현재 시각을 기록할 수 있다. 또한 임계 신뢰 이미지 생성부는 정확도를 계산하기 위하여 사람 수를 카운트하는 변수인 obj_count를 초 기화할 수 있다. 임계 신뢰 이미지 생성부는 분석한 이미지의 결과를 출력하기 위하여 tl 변수에 인식된 객체의 윗부분 좌표를, br 변수에 객체의 아랫부분 좌표를 저장할 수 있다. 또한 임계 신뢰 이미지 생성부(50 0)는 인식된 객체의 종류와 확률을 text 변수에 저장하여 이미지에 쉽게 입력할 수 있도록 할 수 있다. 임계 신뢰 이미지 생성부는 Tl과 bl 변수에 저장된 값을 사용하여 인식된 객체에 사각형 이미지를 객체를 둘러싸도록 형성하고, 사각형 윗부분에 객체의 종류와 확률이 표시되도록 할 수 있다. 사각형이 표시될 때마다 인식된 객체의 수를 세어주기 위해 obj_count에 1씩 더할 수 있다. 이 때, 결과를 실시간으로 다시 표시하기 위 하여 OpenCV의 함수가 사용되어 output이 출력될 수 있다. 이후, 이미지 합성부는 이미지들을 합성하여 최 종 이미지를 생성할 수 있다. 도 10은 본 발명에 따른 YOLO를 사용하여 사람만 인식된 결과를 도시한 것이다. 인식된 사람의 수와 fps를 계산 하여 출력된 것을 확인할 수 있다. 이후, 이미지 합성부는 앞서 Segmantic segmentation방법에서 작성된 메모리 사용량 계산 함수를 사용하여 YOLO를 사용하여 이미지를 처리할 때의 연산량을 계산할 수 있다. ENet는 매우 작은 FPGA(Field Programmable Gate Array) 보드에서 작동할 수 있고 YOLO는 보다 나은 성능의 FPGA에서 실행될 수 있다. Segmentation 및 탐지를 하나의 거대한 모델로 결합하려면 각각 개별적으로 실행되는 것과 비교하여 보다 더 나은 성능을 발휘하는 임베디드 보드가 필요할 수 있다. 상대적으로 성능이 열화된 두 개의 보드가 고성능 보드보다 비용적인 측면에서 효율적일 수 있다. 구체적으로 두 FPGA 기판 간의 통신시간이 매우 짧고, 에너지 사용량이 적어 통신비용이 미미해 더욱 효과적일 수 있다. 도 11은 본 발명에 따른 이미지에 포함된 객체를 인식하는 방법을 도시한 흐름도이다. 도 11을 참조하면, 본 발명에 따른 이미지에 포함된 객체를 인식하는 방법은 촬영 장치로부터 제1 이미지를 수 신하는 단계(S100), 상기 제1 이미지에 포함된 사람을 확인하고, 상기 제1 이미지에 상기 확인된 사람이 표시된 제2 이미지를 생성하는 단계(S200), 상기 제2 이미지에 이진화(binarize) 동작을 수행하여 제3 이미지를 생성하 는 단계(S300), 상기 제3 이미지와 상기 제1 이미지를 합성하여 마스킹된 제4 이미지를 생성하는 단계(S400), 상기 제4 이미지에 대하여 임계 신뢰(threshold of confidence)값을 설정하고, 상기 설정된 임계 신뢰 값에 기 초하여 제5 이미지를 생성하는 단계(S500) 및 상기 제5 이미지와 상기 제1 이미지를 합성하여 제6 이미지를 생 성하는 단계(S600)를 포함할 수 있다. 도 12a 및 도 12b는 YOLO 단독 실행 시와 YOLO와 ENet 실행 시 시간, fps, 사람 수를 측정한 결과를 도시한 것 이다. 도 12a 및 도 12b를 참조하면, 사람의 수의 변화가 많은 곳을 실시간으로 측정하기에는 한계가 있어 웹캠에 사 람의 수가 다른 사진들을 연속으로 보여주어 실험하였다. 서로 다른 인원의 사진 17장을 실시간 웹캠으로 슬라 이드 쇼 형태로 제작하였다. YOLO를 단독으로 사용했을 때 사람 수의 변화에 따른 FPS와 처리시간이 불안정함을 확인할 수 있다. 평균 FPS는 3.64이고 FPS의 분산은 0.166이다. 하지만 ENet과 YOLO를 통합하여 사용한 프로그 램은 변화하는 사람의 수에 상관없이 FPS와 처리시간이 안정됨을 알 수 있다. 평균 FPS는 3.93이고FPS의 분산은 0.0051이다. 표 1의 (a) 내지 (c)는 Window 10 기반의 PC에서 실행하였을 때, YOLO 단독 사용할 때와 ENet과 YOLO를 함께 사용할 때의 평균 시간, FPS와 정확도, 에러를 측정한 결과이다. (표 1)"}
{"patent_id": "10-2022-0184923", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "표 1의 (a)를 참조하면, YOLO보다 훨씬 적은 컨볼루션 레이어와 빠르고 컴팩트한 인코더 디코더 구조로, 가장 낮은 평균 처리 시간은 프레임당 0.156초였으며, 평균 FPS는 6.41로 가장 높았다. YOLO만 사용했을 때 프레임당 평균 처리시간은 0.281초, 평균 FPS는 3.645초였다. ENet 결과를 YOLO로 처리했을 때, YOLO에서의 평균 소요 시 간은 0.269초, 평균 FPS는 3.701이었다. ENet을 사용하여 ROI를 설정하고 YOLO의 입력으로 처리하는 방법이 YOLO의 실행 부담을 줄일 수 있음을 확인할 수 있다. 이 결과는 YOLO의 임곗값을 낮추어 생긴 이점이다. 딥러닝 에서 모델의 정확도를 측정하는데 confusion matrix를 사용하여 측정하였다. 모델이 정답을 맞힐 때 TP, 모델이 정답을 잘못 예측했을 때 TN, 모델이 정답을 오답으로 잘못 예측했을 때 FN, 모델이 정답을 오답으로 잘못 예측 했을 때 FP으로 4가지 상태로 나눌 수 있다. 정확도는 하기 (수학식1)로 계산될 수 있다. (수학식 1)"}
{"patent_id": "10-2022-0184923", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "또한 다양한 성능평가를 위해 precision, recall, F1-Score를 계산했다. TP는 YOLO에 의해 검출된 사람 수로, FP는 검출된 사람이 아닌 물체의 수로 계산했다. FN은 감지되지 않는 사람들의 수이다. Precision은 (수학식 2), recall은 (수학식 3), F1-score는 (수학식4로 계산할 수 있다. (수학식 2) (수학식 3)"}
{"patent_id": "10-2022-0184923", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "(수학식 4)"}
{"patent_id": "10-2022-0184923", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "객체 인식 프로그램의 정확도를 측정하기 위해 총 인식된 프레임 수를 사진 속 사람 수와 올바르게 인식된 프레 임 수로 나누었다. YOLO와 ENet을 함께 사용하면 정확도가 확연히 향상되는 것을 확인할 수 있다. TP와 TN이 정 확하게 일치한 부분을 계산했기 때문에 오차는 인정된 인원과 실제 인원을 비교하여 더욱 적절한 정확도를 얻기 위해 산출됐다. 표 1의 (a)를 보면 알 수 있듯이 실시간으로 실행했을 때 YOLO와 ENet을 사용할 때 더 빠른 것을 알 수 있다. 표 1의 (b)를 보면 알 수 있듯이 정확도를 계산해보면 YOLO와 ENet을 함께 사용하는 방법이 크게 개선되지 않았 음을 알 수 있다. 다만 YOLO만 사용했을 때는 평균 인식 오차가 7.097로 나타났고, ENet과 YOLO를 함께 사용했 을 때는 평균 인식 오차가 2.913으로 나타났다. 사진 속 사람이 많을수록 YOLO만 사용할 경우 오류가 더 많이 나타난다. 그러나 ENet과 YOLO를 함께 사용하면 오류를 줄이고 정확한 인식을 할 수 있음을 확인할 수 있다. 또한 표 1의 (c)에서 볼 수 있듯이 ENet과 YOLO를 사용했을 때 precision은 0.937, recall은 0.806, F1-score는 0.866이 나타났다. 한편, YOLO 단독 사용시 precision은 0.992, recall은 0.72, F1-score는 0.834가 나타났다. F1-score를 보았을 때도 ENet과 YOLO를 함 께 사용했을 때 더 높게 나왔음을 알 수 있다. 도 13은 YOLO 단독 실행 시와 YOLO와 ENet 실행 시, 전력 소비를 측정한 결과를 도시한 것이다. 도 13을 참조하면, 호스트 PC에서 실행되며 임곗값은 0.4로 고정하였다. 전력 소비는 AMD Ryzen 73800XT 8코어 프로세서 3.90GHz, RAM 32.0GB, Windows 10 Pro에서 실행되었다. 이 결과는 CPU만 사용될 때 이 구조가 사용한 총CPU 전력의 평균 값이다. 이 구조가 동일한 데이터를 처리하기 위해 사용하는 전력량은 동일한 시간 동안 동 일한 그림을 입력으로 넣어 측정하였다. 전력 사용의 경향을 비교하기 위한 실험이었으므로 보드에서 측정되지 않았다. ENet과 YOLO를 사용 시 전력은 22.54W, YOLO 단독 사용전력은 32.831W로, ENet과 Tiny-YOLO로 실행시 전력은 14.14W, Tiny-YOLO의 소비전력은 26.716W였다. YOLO와 함께 ENet을 사용하면 약 10W를 줄일 수 있어 경 량 임베디드 보드에 유용하다. 또한 Tiny-YOLO는 YOLO보다 전력을 적게 사용함을 볼 수 있다. 도 14a 및 도 14b는 YOLO 단독 실행 시와 YOLO와 ENet 실행 시, 메모리양을 측정한 결과를 도시한 것이다. 도 14a 및 도 14b를 참조하면, 특정 임곗값에서 메모리가 최소로 사용되는 것을 알 수 있다. 임곗값이 너무 낮 으면 많은 개체가 감지되고 메모리가 많이 소모되기 때문임을 알 수 있다. 그러나 임곗값이 너무 높으면 감지된 개체가 없으므로 메모리 사용량이 적다. 임곗값이 0.4일 때 평균 메모리 사용량은 2.067GB이다. ENet과 YOLO를 함께 사용할 경우 두 프로그램의 모델을 별도로 불러와야 하므로 메모리 사용량이 YOLO만 사용하는 것보다 높을 수밖에 없다. 그러나 메모리 바이트 수가 증가하더라도 정확도는 크게 향상된다. 또한 이 방법은 임베디드 보드 에서 충분히 사용할 수 있기 때문에 유효하다 도 15a 및 도 15b는 YOLO 단독 실행 시와 YOLO와 ENet 실행 시, 배경의 복잡도를 측정한 결과를 도시한 것이다. 도 15a 및 도 15b를 참조하면, Window10 기반의 PC에서 실행했을 때 사진 속 배경의 복잡도가 연산에 어떠한 영 향을 미치는지에 대한 결과를 확인할 수 있다. 인식된 사람을 제외한 배경에서 RGB 값의 평균과 그에 따른 분산 값이 크면 배경이 복잡하다고 추정하였다. 도 15의 (a)는 배경 RGB 분산 값이 0.047, 도 15의 (b)는 0.132로 차 이가 있음을 알 수 있다. 먼저 사람의 눈으로 배경이 복잡한 사진과 흰 배경에 사람만 있는 사진들을 골라 웹캠에 실시간으로 입력하였다. 배경이 단순할 경우 평균 FPS는 3.46, 평균 메모리는 2096.937MB이고 RGB 값의 평균 분산은 0.0655이다. 배경이 복잡할 때 평균 FPS는 3.17, 평균 메모리는 2133.625MB이고 RGB의 평균 분산은 0.177이다. 배경이 단순하여 ENet을 사용해 배경을 제외해주지 않아도 되는 사진들이 더 적은 시간과 적은 메모 리가 소요되었고 배경이 복잡할수록 인식되는 사람 수가 불안정하고 정확도가 떨어짐을 볼 수 있다. 본 발명의 실시예에 따른 방법의 동작은 컴퓨터로 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 프로그램 또 는 코드로서 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의해 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결 된 컴퓨터 시스템에 분산되어 분산 방식으로 컴퓨터로 읽을 수 있는 프로그램 또는 코드가 저장되고 실행될 수 있다. 또한, 컴퓨터가 읽을 수 있는 기록매체는 롬(rom), 램(ram), 플래시 메모리(flash memory) 등과 같이 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 프로그램 명령은 컴파일러 (compiler)에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터(interpreter) 등을 사용해서 컴퓨 터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 본 발명의 일부 측면들은 장치의 문맥에서 설명되었으나, 그것은 상응하는 방법에 따른 설명 또한 나타낼 수 있 고, 여기서 블록 또는 장치는 방법 단계 또는 방법 단계의 특징에 상응한다. 유사하게, 방법의 문맥에서 설명된 측면들은 또한 상응하는 블록 또는 아이템 또는 상응하는 장치의 특징으로 나타낼 수 있다. 방법 단계들의 몇몇 또는 전부는 예를 들어, 마이크로프로세서, 프로그램 가능한 컴퓨터 또는 전자 회로와 같은 하드웨어 장치에 의 해(또는 이용하여) 수행될 수 있다. 몇몇의 실시예에서, 가장 중요한 방법 단계들의 하나 이상은 이와 같은 장 치에 의해 수행될 수 있다. 실시예들에서, 프로그램 가능한 로직 장치(예를 들어, 필드 프로그머블 게이트 어레이)가 여기서 설명된 방법들 의 기능의 일부 또는 전부를 수행하기 위해 사용될 수 있다. 실시예들에서, 필드 프로그머블 게이트 어레이는 여기서 설명된 방법들 중 하나를 수행하기 위한 마이크로프로세서와 함께 작동할 수 있다. 일반적으로, 방법들 은 어떤 하드웨어 장치에 의해 수행되는 것이 바람직하다. 이상 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청 구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2022-0184923", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명에 관한 이해를 돕기 위해 상세한 설명의 일부로 포함되는, 첨부도면은 본 발명에 대한 실시예를 제공하 고, 상세한 설명과 함께 본 발명의 기술적 사상을 설명한다. 도 1은 본 발명에 따른 이미지에 포함된 객체를 인식하는 시스템의 개념도이다. 도 2는 본 발명에 따른 이미지에 포함된 객체를 인식하는 시스템의 블록도이다. 도 3은 본 발명에 따른 Semantic segmentation을 수행하여 이미지의 크기를 변환하는 과정을 도시한 개념도이다. 도 4는 본 발명에 따른 Semantic segmentation을 수행하여 객체를 특정한 결과를 도시한 것이다. 도 5는 본 발명에 따른 Semantic segmentation을 수행함에 있어 객체에 따라 지정되는 색을 도시한 것이다. 도 6은 본 발명에 따른 Semantic segmentation을 수행하는 과정에서 이진화 동작 및 마스킹 이미지를 생성하는 과정이 구현되는 시스템 코드를 도시한 것이다. 도 7은 본 발명에 따른 Semantic segmentation을 수행하는 과정에서 원본 이미지와 이진화된 이미지를 도시한 것이다. 도 8은 본 발명에 따른 Semantic segmentation을 수행하는 과정에서 원본 이미지와 이진화된 이미지가 합성된 마스킹 이미지를 도시한 것이다. 도 9는 본 발명에 따른 YOLO 객체 인식 방법을 활용하여 객체를 인식하는 과정이 구현되는 시스템 코드를 도시 한 것이다. 도 10은 본 발명에 따른 YOLO를 사용하여 사람만 인식된 결과를 도시한 것이다. 도 11은 본 발명에 따른 이미지에 포함된 객체를 인식하는 방법을 도시한 흐름도이다. 도 12a 및 도 12b는 YOLO 단독 실행 시와 YOLO와 ENet 실행 시, 시간, fps, 사람 수를 측정한 결과를 도시한 것 이다. 도 13은 YOLO 단독 실행 시와 YOLO와 ENet 실행 시, 전력 소비를 측정한 결과를 도시한 것이다. 도 14a 및 도 14b는 YOLO 단독 실행 시와 YOLO와 ENet 실행 시, 메모리양을 측정한 결과를 도시한 것이다. 도 15a 및 도 15b는 YOLO 단독 실행 시와 YOLO와 ENet 실행 시, 배경의 복잡도를 측정한 결과를 도시한 것이다."}
