{"patent_id": "10-2023-0098256", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0017470", "출원번호": "10-2023-0098256", "발명의 명칭": "3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템", "출원인": "(주)엔에스데블", "발명자": "이언주"}}
{"patent_id": "10-2023-0098256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "3D 메타버스 강의실에서 교수자와 학습자들의 아바타들이 3D 렌더링으로 표시되며, 온라인 학습 또는 유비쿼터스 기반 학습(UBL) 시에, 학습자의 출석을 관리하고 학습 콘텐츠를 제공하며, 사용자 단말의 정면 카메라로 촬영된 학습자의 얼굴의 윤곽선과 눈2/코/귀2를 포함하는 학습자의 얼굴 자세를 모니터링한 학습자의 얼굴 학습패턴을 등급/점수를 저장하며, 정면 자세 이탈시에 해당 학습자 단말로 알람을 발생하여 주의 집중 학습되도록경고 메시지를 발생하는 블렌디드 러닝 시스템; 및상기 블렌디드 러닝 시스템과 유무선 통신망을 통해 연결되고, 3D 메타버스 강의실에 출석 정보를 서버로 저장하고, 상기 학습 콘텐츠를 제공받고 카메라와 안면인식 모듈과 음성인식 모듈을 구비하며 학습자의 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들 인식하고, 학습자의 말소리를 인식하며, 3D 학습 패턴을 3D View로 제공받는학습자 단말들;을 포함하는 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템."}
{"patent_id": "10-2023-0098256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 블렌디드 러닝 시스템에 유무선 통신망을 통해 접속되며, 강의실 별로 해당 과목의 교수자와 강의실 ID가구비되며, 수강신청 학습자 명단 정보를 제공받으며, 한글 또는 워드로 작성된 자료, PPT 자료, 또는 강의 동영상/음성이 포함되는 강의 데이터를 업로딩하는 교수자 단말을 더 포함하는 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템."}
{"patent_id": "10-2023-0098256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 학습자 단말들과 교수자 단말은 PC, 노트북, 스마트폰 또는 태블릿 PC를 사용하는 3D 메타버스 강의실에서학습집중도를 향상시키는 블렌디드 러닝 시스템."}
{"patent_id": "10-2023-0098256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 학습자 단말들과 교수자 단말은 한글과 워드로 작성된 자료, PPT 자료 또는 강의 동영상/음성이 포함되는강의 데이터를 표시하는 강의 자료 표시부와 강의 동영상/음성 데이터를 출력하는 멀티미디어 뷰어와, 안면 인식 모듈과, 음성 인식 모듈과 3D 학습 얼굴과 학습 패턴 데이터를 시각화하여 표시하는 3D 렌더러를 구비하는3D 뷰어가 구비되는, 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템."}
{"patent_id": "10-2023-0098256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 학습자 단말은 얼굴의 윤곽선과 눈2/코/귀2를 인식하는 상기 안면인식 모듈이 구비되며, 상기 안면 인식 모듈은 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점을 인식하기 위해 posenet 알고리즘을 사용하는, 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템."}
{"patent_id": "10-2023-0098256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서, 상기 학습자 단말은 음성 상기 인식 모듈이 구비되고, 상기 음성 인식 모듈은 주변 잡음을 필터링하고 학습자의말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음성을 인식하기 위해 SileroVAD 및 SpeechBrain 알고리즘을공개특허 10-2025-0017470-3-사용하는, 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템."}
{"patent_id": "10-2023-0098256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 블렌디드 러닝 시스템은 학습자 단말과 교수자 단말과 유무선 통신을 통해 연결되는 WWW 서버; 유무선 통신망을 통해 강의실별로 학습자 단말들과 교수자 단말로 온라인 학습/시험 또는 유비쿼터스 기반 학습(UBL)과 유비쿼터스 기반 시험(UBT)의 응용 서비스를 제공하도록 제어하는 제어부; 상기 제어부에 연결되며, 학습자의 회원 정보를 등록받아 ID/Passwd를 저장하여 관리하는 회원 등록부; 상기 제어부에 연결되며, 학번/Passwd, 또는 QR 코드/Passwd 또는 ID/Passwd 또는 온라인 인증서를 사용하여 사용자를 인증하는 사용자 인증부; 상기 제어부에 연결되며, 온라인 학습과 시험 또는 유비쿼터스 기반 온라인 학습(UBL)과 시험(UBT)의 출석을 관리하는 출석관리부; 상기 제어부에 연결되며, 3D 강의실 콘텐츠와 교수자와 학습자들의 아바타를 제공하며 온라인 학습 또는 유비쿼터스 기반 학습(UBL) 콘텐츠를 제공하는 3D 메타버스 강의실 학습 콘텐츠 제공부; 상기 제어부에 연결되며, 학습자별로 학급자의 안면인식 데이터를 수신받아 얼굴의 윤곽선과 눈2/코/귀2 얼굴의특징점들을 추출하여 UBL 주의집중 학습되도록 학습자의 얼굴의 학습 패턴을 분석하는 안면인식 분석부; 상기 제어부에 연결되며, 학습자별로 학급자의 음성인식 데이터를 수신받아 학습자의 소리 패턴을 분석하는 음성인식 분석부; 상기 제어부에 연결되며, 실시간으로 수신되는 학습자의 안면 인식 데이터 및또는 학습자의 말소리 데이터를 수신받아 학습자별 학습 패턴의 빅 데이터를 분석하여 학습 패턴을 등급/접수화하여 점수화된 학습집중도를 제공하며 학습집중도 제공부; 및강의실 정보와 교수자와 학습자DB, 학습 콘텐츠DB, 및 얼굴 사진 DB를 포함하는 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템."}
{"patent_id": "10-2023-0098256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제2항에 있어서, 상기 제어부에 연결되며, 3D 메타버스 강의실에서 교수자의 발언권 제어 방식에 따라 학습자의 질문 요청 Queue에 저장하고 FIFO 방식으로 상기 교수자 단말과 상기 학습자들의 질의 응답 채팅 데이터를 송수신하는 채팅 서버 또는 아바타 채팅 서버를 더 포함하는 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템."}
{"patent_id": "10-2023-0098256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 블렌디드 러닝 시스템은 유무선 통신망을 통해 학습자 단말들과 교수자 단말과 연결되고 교수자의 강의 동영상과 음성 데이터를 제공하며, 추가적으로 학습자의 얼굴 영상과 음성 데이터를 저장하고 스트리밍 서비스를제공하는 NVR 서버를 더 포함하는 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템."}
{"patent_id": "10-2023-0098256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 블렌디드 러닝 시스템은 3D 메타버스 강의실 콘텐츠와 교수자와 학습자들으 아바타들이 표시되는 3D 학습콘텐츠를 제공하며, 학습자의 3D 학습 얼굴을 모델링하여 사용자 단말의 카메라를 주시하는 얼굴 모습이 표현되는 얼굴의 윤곽선과 머리와 이마/눈2/코/귀2/입을 포함하여 3D 모델링하여 렌더링하는 3D 렌더러를 더 포함하는3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템.공개특허 10-2025-0017470-4-청구항 11 제2항에 있어서, 온라인 학습 또는 UBT 학습/또는 시험 시에, 상기 교수자 단말은 상기 LRS 서버를 통해 다수의 학습자 단말의학습자의 출석을 확인하고, 안면인식과 음성인식 기술을 활용한 AI 감독관으로써, 학습자별 학습 패턴을 모니터링하며, 학습자의 두 눈의 아이트랙킹, 눈/코/귀의 안면 인식 데이터 및 주변 화이트 노이즈를 필터링한 학습자의 말소리의 음성 인식 데이터를 모니터링하다가, 정면 자세를 기준으로 일정 기준치 이하로 학습자의 학습 자세가 비딱하면(학습자의 비딱한 자세, 고개 돌림의 눈2/코/귀2의 거리가 일정 기준치 미만이면, 말소리) 학습자세가 삐탁하거나 고개를 상하 방향/좌우 방향으로 돌리거나, 말소리가 들리면, 해당 학습자 단말로 UBL 주의집중 학습되도록 경고 메시지 또는 알람을 전송하는, 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템."}
{"patent_id": "10-2023-0098256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서, 상기 블렌디드 러닝 시스템에 연동된 상기 학습자 단말은, 학습 시간 동안, 녹음/녹화 데이터(소리 파일과 이미지 파일/영상 파일)을 상기 블렌디드 러닝 시스템으로 전송하여 저장되는 상기 학습자 단말에 구비된 녹음 및녹화 프로그램을 구비하는, 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템."}
{"patent_id": "10-2023-0098256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서, 상기 블렌디드 러닝 시스템은 상기 제어부에 연결되며, 학습자 단말들로 온라인 시험 프로그램을 제공하며 온라인 시험 프로그램에 온라인 시험 또는 UBT 시험 문제가 출제되고, 학습자별 시험 답안을 취합하여, 채점 정보를 제공하는 온라인 시험 또는UBT 시험부를 더 포함하는 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템."}
{"patent_id": "10-2023-0098256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 블렌디드 러닝 시스템은 온라인 시험 또는 UBT 시험 시에, 응시자의 얼굴의 윤곽선과 눈2/코/귀2의 시각적인 부정행위를 감지하는 안면인식 분석부와, 말소리를 분석하는 음성인식 분석부를 기본적으로 구비하며, 상기 온라인 시험 또는 UBT 시험부는 상기 제어부에 연결되며, 상기 응시자 단말과 상기 교수자 단말(감독관 단말)로 시험 프로그램(App)과 시험지를제공하며, 응시자 정보들과 응시자의 현장 얼굴 사진, 감독관 정보를 관리하며, 온라인 시험 또는 UBT 시험 시에 일정 시험 시간 이내에 각각의 응시자 단말에 시험지 작성 답안을 저장 후 시험 종료시 시험 서버로 전송받고, 응시자들의 시험지 작성 답안, 채점 결과, 감독관 정보와 응시자 현황 정보를 저장하여 관리하는 시험 관리부; 및 시험 정보와 감독관 정보와 응시자들의 시험지와 작성 답안, 채점 결과를 저장하는 시험 정보DB; 응시자 정보와표준 크기의 정면 얼굴 사진 및/또는 얼굴 동영상/음성을 저장하는 응시자DB와 얼굴/말소리 DB, 시험 DB를 더포함하는 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템."}
{"patent_id": "10-2023-0098256", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템이 개시된다. 상기 블렌디드 러닝 시스템 은 3D 메타버스 강의실에서 교수자와 학습자들의 아바타들이 3D 렌더링으로 표시되며, 온라인 학습 또는 유비쿼 터스 기반 학습(UBL) 시에, 학습자의 출석을 관리하고 학습 콘텐츠를 제공하며, 사용자 단말의 정면 카메라로 촬 (뒷면에 계속)"}
{"patent_id": "10-2023-0098256", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 온라인 블렌디드 러닝(blended learning) 시스템에 관한 것으로, 보다 상세하게는 3D 메타버스 강의 실에서 교수자와 학습자들의 아바타들이 3D 렌더링으로 표시되며, 출석 관리와 학습 콘텐츠를 제공하며, 채팅 서버에 의해 선생님의 발언권 제어에 따라 FIFO 방식으로 선생님과 학생들의 질의응답 채팅을 제공하며, 학습자 의 얼굴 영상과 음성 인식을 통해 모니터링되는 주의 집중 학습 패턴을 3D View로 제공하는 온라인 학습과 유비쿼터스 기반 학습(UBL, Ubiquitous based learning) 콘텐츠를 제공하는, 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템에 관한 것이다."}
{"patent_id": "10-2023-0098256", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "얼굴 인식(Face Recognition) 기술은 형상 기반 매칭 방법(appearance based matching method), 및 특징 (feature) 기반의 얼굴 인식이 주로 사용된다. 얼굴 인식은 카메라의 촬영 각도, 조명의 방향, 자세(pose), 표 정의 변화 및 시간에 따른 얼굴의 변화에 따라 다르게 인식된다. 특징(feature) 기반의 얼굴 인식은 디지털 카메라, IoT 디바이스의 카메라 또는 스마트폰의 카메라로 촬영된 영 상 데이터를 Haar-like feature를 이용한 검출 방법과 MCT(Modified Census Transform) 영상을 이용한 검출 방 법이 사용된다. 스마트폰의 카메라의 입력 영상에서 Haar-like feature로 학습된 얼굴 및 눈 검출기를 사용하여 얼굴의 윤곽선과 이마/눈/코/입을 검출하고, 원형의 눈동자를 검출하기 위해 관심 영역(ROI, Region of Interest)으로 설정된 눈 영역을 grayscale로 변환하며, 눈 영역에서 눈동자와 눈의 외곽선 영역이 추출되는 실 험에 의한 통계적인 임계값(threshold)을 사용하여 눈 이미지의 histogram[x축 각 픽셀의 화소값, y축 해당 화 소 값의 갯수]을 구하고 눈의 이미지를 이진화(binarization)한 후, 히스토그램 평활화(histogram equalization)를 통해 눈 영역의 사진의 전처리를 수행하며, 얼굴 영역에서 윤곽선과 눈썹과 눈, 코, 입의 얼굴 특징 얼굴데이터를 검출하고, 텍스처 특징(texture faetures)과 형상 특징(shape features)을 추출하여 얼굴 인 식 DB에 저장된 얼굴 사진의 특징점들과 유사도(similarity)를 비교하여 얼굴이 인식된다. 얼굴 영역의 눈썹과 눈, 코, 입, 턱의 특징 값은 Haar-like feature의 흰 영역에서 포함되는 픽셀들의 합에서 검은 영역에서 포함되는 픽셀의 합의 차로 표현된다. 예를들면, 가로와 세로 표준 크기의 얼굴 영역 사진에서 검출된 눈 영역에서 오른쪽과 왼쪽 눈의 양쪽 끝점 까지의 거리, 허프 원 변환(hough circle transform) 알고리 즘을 사용하여 추출된 눈동자(iris)의 크기 값이 특징 값으로 사용된다. 도 1은 기존 얼굴 인식 장치의 구성도이다. 얼굴 인식 장치는 영상 표시 장치, 영상 촬영 장치, 얼굴 인식 서버, 태블릿 PC, 랩톱(Laptop), 개인용 PC, 스마트폰, 개인 휴대용 정보단말기(Personal Digital Assistant, PDA), 이동통신 단말기 및 지능형 로봇 (Intelligence Robot) 등 중 어느 하나일 수 있다. 얼굴 인식 장치는 카메라로부터 입력 영상을 획득하는 입력 영상 획득부; 상기 입력 영상에서 얼굴 영역을 검출하여 얼굴 포즈(Pose)를 정규화함으로써 정면포즈 영상을 생성하고, 상기 카메라와 피사체 간의 거 리에 따른 원근왜곡(Perspective Distortion)을 제거하기 위하여 상기 정면포즈 영상의 원근감(Perspective)을 정규화하여 정규화 영상을 생성하는 정규화부; 상기 정규화 영상으로부터 상기 피사체의 얼굴을 표현하는 특징 벡터(Feature Vector)를 추출하는 특징 벡터 추출부; 및 기 학습된 분류 모델에 상기 특징 벡터를 적 용하여 상기 입력 영상에 포함된 상기 피사체의 얼굴을 인식하는 얼굴인식부를 포함한다. 입력 영상 획득부는 카메라로부터 입력 영상을 획득한다. 카메라는 깊이인식 카메라, 스테레오 카메라, 및 컬러 카메라일 수 있다(예를 들면, 키넥트(Kinect) 카메라 등). 또한, 입력 영상은 인식대상이 되는 피사체의 얼굴이 포함된 영상으로서 2차원 정지영상 및 동영상을 포함한다. 입력 영상은 컬러영상, 깊이영상, 및 컬러-깊 이(RGB-D) 영상을 포함할 수 있다. 정규화부는 입력 영상으로부터 얼굴 영역을 검출하고, 얼굴 포즈(Pose) 및 원근감(Perspective)을 정규화 하여 정규화 영상을 생성한다. 얼굴 포즈에 변화가 있는 경우, 그레이스케일, 형상, 얼굴의 특징점들의 위치 등 이 달라지기 때문에 얼굴 인식률이 저하된다. 또한, 카메라와 피사체 간의 거리가 달라지면 동일한 피사체라 하 더라도 촬영된 위치마다 원근 왜곡(Perspective Distortion, 뒤틀림)이 다르게 발생하므로, 다른 피사체를 촬영 한 것처럼 보이기도 한다. 따라서, 얼굴인식률을 향상시키기 위해 입력 영상의 얼굴포즈 및 원근감을 정규화할 필요가 있다. 정규화부는, 다양한 포즈의 학습용 얼굴영상을 제1 인공신경망의 입력층에 입력하고, 정면포즈의 학습용 얼굴영상이 상기 제1 인공신경망의 출력층에서 출력되도록 상기 제1 인공신경망을 학습시키는 얼굴포즈 정규화 학습부; 및 상기 제1 인공신경망의 출력층에서 출력된 데이터를 제 2 인공신경망의 입력층에 입력하고, 원근왜 곡이 없는 학습용 얼굴영상이 상기 제 2 인공신경망의 출력층에서 출력되도록 상기 제2 인공신경망을 학습시키 는 원근감 정규화 학습부를 포함한다. 상기 정규화부는, 학습이 완료된 상기 제1 인공신경망과 상기 제2 인공신경망을 통합한 통합 인공신경망의 입력 층에 다양한 원근 왜곡이 있는 다양한 포즈의 학습용 얼굴영상을 입력하고, 정면 포즈의 원근 왜곡이 없는 학습 용 얼굴영상이 상기통합 인공신경망의 출력층에서 출력되도록 상기 통합 인공신경망을 학습시킨다. 특징 벡터 추출부는 기계 학습(Machine Learning)에 의해 결정되며, 정규화 영상으로부터 피사체의 얼굴을 표현하는 특징 벡터(Feature Vector)를 추출한다. 특징 벡터는 얼굴인식에 사용되는 특징값들을 원소로 가지는 벡터이다. 특징벡터를 추출하는데 사용되는 필터로 써 Gabor 필터, Haar 필터, LBP(Local Binary Pattern) - DLBP(Discriminative LBP), ULBP(Uniform LBP), NLBP(Number LBP) 등을 포함 - 등이 있으나, 반드시 이에 한정되지 않으며 그 밖의 다른 필터가 사용될 수 있다. 얼굴 인식부는 기 학습된 분류 모델에 의해 특징 벡터 추출부에서 추출된 특징 벡터를 적용하여 입력 영상에 포함된 피사체의 얼굴을 인식한다. 기 학습된 분류 모델은 서포트 벡터 머신(Support Vector Machine, SVM), 선형 판별 분석(Linear Discriminant Analysis, LDA), 및 Softmax 등을 포함할 수 있다. 가상 얼굴영상 생성부는 정규화부, 특징 벡터 추출부, 및 얼굴 인식부가 학습하는데 사용 되는 복수의 가상 얼굴영상을 생성할 수 있다. 복수의 가상 얼굴 영상은 가상 얼굴 영상 생성부가 카메라로부터 획득된 하나 이상의 2차원 기준 영상을 이용하여 합성한 3차원 얼굴 모델을 변형시킴으로써 생성되는 얼굴 영상을 의미한다. 이와 관련된 선행기술1로써, 특허등록번호 10-1770817에서는 \"온라인 학습자를 위한 주의집중 판단 시스템 및 그 방법\"이 등록되어 있다. 도 2는 종래의 온라인 학습자를 위한 주의집중 판단 시스템 구성도이다. 사용자가 학습한 콘텐츠에 대해서 주의집중 여부를 판단하는 주의집중 판단 시스템은 입력부, 데이터 베이스, 디스플레이부, 단어 생성부, 및 주의집중 판단부를 포함하여 구성된다. 상기 온라인 학습자를 위한 주의집중 판단 시스템은 콘텐츠를 입력받아 등록하는 입력부; 상기 등록된 콘텐츠에서 콘텐츠 정보를 생성하여 카테고리별로 저장하는 데이터베이스; 상기 등록된 콘텐츠 중 사용자가 선택한 콘텐츠를 디스플레이하는 디스플레이부; 상기 사용자가 선택한 콘텐츠에서 단어를 추출하고 상기 추출된 단어와 상기 카테고리별로 저장된 콘텐츠 정보 를 이용하여 콘텐츠 단어 및 노이즈 단어를 생성하는 단어 생성부; 및 상기 콘텐츠 단어 및 상기 노이즈 단어로 구성된 질의응답을 이용하여 상기 사용자의 주의집중 여부를 판단하는 주의집중 판단부;를 포함하며, 상기 단어 생성부는 기 콘텐츠가 등록되면 자동적으로 상기 콘텐츠로부터 자막 및 명사를 추출하여 단어를 생성하고, 상기 저장된 콘텐츠 정보와 상기 생성된 단어에 대해서 각각 가중치를 계산하며, 상기 계산된 가중치 에 따라 상기 콘텐츠 단어를 생성함으로써, 상기 가중치에 따라 상기 콘텐츠 단어를 포함하는 상기 질의응답을 사용자에게 제공하고, 상기 단어 생성부는 상기 콘텐츠 단어 및 노이즈 단어를 학습자가 이전에 시청했던 콘텐츠를 기반으로 생 성함으로써, 동일한 콘텐츠에 대해서도 학습자마다 서로 다른 콘텐츠 단어 및 노이즈 단어를 생성한다. 이와 관련된 선행기술2로써, 특허 등록번호 10-2103521에서는 “인공지능 심층학습 기반의 영상물 인식 시스템 및 방법“이 등록되어 있다. 인공지능 심층학습 기반의 영상물 인식 시스템은 인공지능의 심층학습(Deep Learning)으로 다양한 이미지를 사 전 학습하고, 상기 사전 학습 결과를 반영하여 유통되는 영상물에 대해 프레임 단위로 이미지를 분석하고, 경우 에 따라 영상물의 음성 정보도 함께 분석하여 시간순으로 키워드를 도출해 낸 후 사전에 축적되어 있던 영상물 대본의 시계열적 키워드와 비교하는 방식의 인공지능 심층학습 기반의 영상물 인식 시스템을 제공한다. 인공지능 심층학습 기반의 영상물 인식 시스템은 다수의 오브젝트 이미지를 키워드로 심층 학습(Deep Learnin g)하는 데이터셋 학습부; 영상물 대본에서 키워드를 추출하여 시계열적으로 나열, 저장하는 DB부; 영상물을 프 레임 단위 이미지 분석을 통해, 이미지 상의 오브젝트들과 오브젝트 간의 관계를 키워드로 추출하여 시계열적으로 나열하는 영상물 분석부; 및 상기 DB부와 영상물 분석부의 키워드를 비교하여 유사성을 판단하는 비교판단부 를 포함한다. 이와 관련된 선행기술3로써, 특허 등록번호 10-1690546에서는 단말기의 음성인식을 통한 어학학습 방법 및 시스 템이 등록되어 있다. 단말기는 어학 어플리케이션 실행에 따른 화면을 제공하는 표시부; 개인의 발음 차이를 고려하여 설정되는 다수 의 패턴데이터를 저장하는 단말저장부; 및 상기 어학 어플리케이션을 실행하여 적어도 하나의 어학 문제를 제시 하고, 상기 어학문제에 대응하는 음성데이터를 사용자로부터 수집하고, 상기 수집된 음성데이터와 상기 다수의 패턴데이터를 비교하고, 매칭도가 기 설정값 보다 높은 패턴데이터를 선택하여 음성 인식을 위한 범위를 설정하 고, 상기 선택된 패턴 데이터와 상기 수집된 음성데이터를 비교하여 음성 인식을 수행한 후 어학문제에 대한 평 가 결과를 생성하는 단말제어부 포함한다. 이와 관련된 선행기술4로써, 특허등록번호 10-2041618 (등록일자 2019년 10월 31일), \"인공지능 음성인식을 위 한 기계학습 기반 자연어 말뭉치 구축 서비스 제공 시스템 및 방법\"이 등록되어 있다. 또한, 음성 인식(Speech Recognition)은 man-machine 인터페이스 기술로써, 마이크로 입력된 음향 신호 (Acoustic speech signal)에 대하여 잡음을 제거하고 음성 신호의 특징을 추출하여 단어의 집합 또는 문장의 텍 스트로 변환하는(mapping) 과정이며, 마이크-> AMP -> LPF -> ADC -> 음성 데이터베이스에 저장된다. 음성 인식 은 크게 전처리부와 인식부로 구성되며, 전처리부는 사용자가 발성한 음성 신호로부터 잡음을 제거하고 인식 과 정을 위한 특징을 추출하며, 인식부는 입력된 음성을 음성 데이터베이스와의 비교를 통해 가장 가능성 있는 단 어를 인식결과로 출력하거나 비교 단어를 제한하여 문장을 인식한다. 음성 인식 기술은 미리 저장된 음성 패턴과 사용자의 음성 패턴을 비교하여, 매칭되는 패턴의 음성을 인식한다. 음성 인식 시스템은 벡터 양자화(Vector Quantization)를 이용하는 방법, 동적 시간 정합(Dynamic Time Warping, DTW)을 이용하는 방법, 신경회로망(Neural Network)을 이용하는 방법, HMM(Hidden Markov Model, 은 닉 마코프 모델)을 이용하는 방법이 사용되고 있다. MSVQ(Multi-Section Vector Quantization)는 음성의 대 음성의 대표 패턴을 생성할 때 음성의 시간적인 관계를 고려하여 벡터양자화(Vector Quantization)를 적용한 방법이다. 음성 신호는 동일한 발음에 대해서도 시간 길이 가 다르므로 음성을 일정한 몇 개의 구간으로 분할하고, 분할된 음성 구간에서 특징 벡터를 구함으로써 음성 구 간의 수를 일정하게 정규화하며, 이를 위하여 발성 시간이 짧은 음성은 구간 길이를 짧게 하고, 발성 시간이 긴 음성은 각 구간의 길이를 길게 하여 시간 길이가 다른 음성이라도 동일한 구간 수를 갖도록 한다. MVSQ는 음성 을 몇 개의 구간(section)으로 나누고 구간 별로 독립된 벡터양자화(VQ, Vector Quantization)를 수행하여 각 구간 별로 대표 벡터를 생성하고, 음성의 구간 수를 정규화 한다. 길이가 다른 음성을 MSVQ을 이용하여 음성 구 간 수를 정규화하며, 각 구간에서의 대표 벡터 생성은 LBG(Linde-Buzo-Gray) 알고리즘을 사용한다. 은닉 마르코프 모델(HMM, Hidden Markov Models)을 사용한 음성 인식 알고리즘은 통계적 언어 모델이 사용될 경 우 음성 처리 및 언어 처리를 계층적인 단일구조로 처리할 수 있다. 음성 인식 기술은 미리 저장된 음성 패턴과 사용자의 음성 패턴을 비교하여, 매칭되는 패턴의 음성을 인식한다. 그러나, 기존의 이러닝 또는 유러닝 시스템은 단지 온라인 학습 콘텐츠를 제공하였으며, 교수자와 학습자들의 아바타가 표현되는 3D 메타버스 강의실을 제공하지 않았으며, 선생님의 발언권 제어에 따라 선생님과 학생들의 질의응답 채팅을 제공하지 않았으며, 학습자의 얼굴 영상과 음성 인식을 통해 모니터링되는 주의 집중 학습 패 턴을 3D View로 제공하지 않았으며, 얼굴 인식 기술과 소리와 메시징 기술을 사용하여 학습자의 부주의하게 얼 굴 시선이 이탈하면 실시간으로 AI 안면 인식/음성 인식에 의해 이를 감지하고 해당 사용자 단말로 알람을 발생 하고 주의집중 학습이 되도록 하는 블렌디드 러닝 시스템을 제공하지 않았다. 선행기술문헌 특허문헌 (특허문헌 0001) 특허등록번호 10-1770817 (등록일자 2017년 08월 17일), \"온라인 학습자를 위한 주의집중 판단 시스템 및 그 방법\", 고려대학교 산학협력단 (특허문헌 0002) 특허등록번호 10-2103521 (등록일자 2020년 04월 16일), \"인공지능 심층 학습 기반의 영상물인식 시스템 및 방법\", 상명대학교 산학협력단 (특허문헌 0003) 특허등록번호 10-1690546 (등록일자 2016년 12월 22일), \"단말기의 음성인식을 통한 어학학습 방법 및 시스템\", 에스케이텔레콤 주식회사 (특허문헌 0004) 특허등록번호 10-2041618 (등록일자 2019년 10월 31일), \"인공지능 음성인식을 위한 기계학습 기반 자연어 말뭉치 구축 서비스 제공 시스템 및 방법\", (주)미디어코퍼스"}
{"patent_id": "10-2023-0098256", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기 문제점을 해결하기 위한 본 발명의 목적은 3D 메타버스 강의실에서 교수자와 학습자들의 아바타들이 3D 렌 더링으로 표시되며, 출석 관리와 학습 콘텐츠를 제공하며, 채팅 서버에 의해 선생님의 발언권 제어에 따라 FIFO 방식으로 선생님과 학생들의 질의응답 채팅을 제공하며, 학습자의 얼굴 영상과 음성 인식을 통해 모니터링되는 주의 집중 학습 패턴을 3D View로 제공하는 온라인 학습과 유비쿼터스 기반 학습(UBL, Ubiquitous based learning) 콘텐츠를 제공하는 블렌디드 러닝 서버(LRS 서버)과 연동되며, 사용자 단말은 3D 렌더러와 미디어 재 생부와 안면인식 모듈과 음성인식 모듈을 구비하고, 학습자 단말기로 학습 콘텐츠를 제공하고, 주의 집중 학습 패턴을 모니터링하는 블렌디드 러닝 시스템(LRS 서버)에 연동된 사용자 단말의 정면 카메라에 포커싱된 학생의 시선을 바로보고 주의집중 학습되도록 학습자의 얼굴의 윤곽선과 눈2/코/귀2/입의 얼굴의 특징점들을 안면 인식 을 하며, 학습자의 학습 패턴을 모니터링하고 일정 각도로 시선이 빗나갈 경우 또는 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어깨와 어깨의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우, 말소리가 들리는 경우 소리와 메시징 기술을 사용하여 주의 집중 학습하도록 해당 사용자 단말로 알람/경고 메시지를 발생하며 이를 점수화하여 학습 집중도를 제공하는, 3D 메타버스 강의실에서 학습집 중도를 향상시키는 블렌디드 러닝 시스템을 제공한다."}
{"patent_id": "10-2023-0098256", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 목적을 달성하기 위해, 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템은 3D 메타버스 강의실에서 교수자와 학습자들의 아바타들이 3D 렌더링으로 표시되며, 온라인 학습 또는 유비쿼터스 기반 학습(UBL) 시에, 학습자의 출석을 관리하고 학습 콘텐츠를 제공하며, 사용자 단말의 정면 카메라로 촬영된 학습자의 얼굴의 윤곽선과 눈2/코/귀2를 포함하는 학습자의 자세를 모니터링한 학습자의 얼굴 학습 패턴을 등급 /점수를 기록하며, 정면 자세 이탈시에 해당 학습자 단말로 알람을 발생하여 주의 집중 학습되도록 경고 메시지 를 발생하는 블렌디드 러닝 시스템; 및 상기 블렌디드 러닝 시스템과 유무선 통신망을 통해 연결되고, 3D 메타 버스 강의실에 출석 정보를 서버로 저장하고, 상기 학습 콘텐츠를 제공받고 카메라와 안면인식 모듈과 음성인식 모듈을 구비하며 학습자의 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들 인식하고, 학습자의 말소리를 인식하며, 3D 학습 패턴을 3D View로 제공받는 학습자 단말들을 포함한다."}
{"patent_id": "10-2023-0098256", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템은 3D 메타버스 강의실에서 교수자와 학습자들의 아바타들이 3D 렌더링으로 표시되며, 출석 관리와 학습 콘텐츠를 제공하며, 채팅 서버에 의해 선생님의 발언권 제어에 따라 FIFO 방식으로 선생님과 학생들의 질의응답 채팅을 제공하며, 학습자의 얼굴 영상과 음성 인식을 통해 모니터링되는 주의 집중 학습 패턴을 3D View로 제공하는 온라인 학습과 유비쿼터스 기반 학습(UBL, Ubiquitous based learning) 콘텐츠를 제공하는 블렌디드 러닝 시스템(LRS 서버)과 연동되며, 사용자 단말은 3D 렌더러와 미디어 재생부와 안면인식 모듈과 음성인식 모듈을 구비하고, 학습자 단말기로 학습 콘텐츠를 제공하고, 주의 집중 학습 패턴을 모니터링하는 블렌디드 러닝 서버(LRS 서버)에 연동된 사용자 단말 의 정면 카메라에 포커싱된 학생의 시선을 바로보고 주의집중 학습되도록 학습자의 얼굴의 윤곽선과 눈2/코/귀 2/입의 얼굴의 특징점들을 안면 인식을 하며, 학습자의 학습 패턴을 모니터링하고 일정 각도로 시선이 빗나갈 경우 또는 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어깨와 어 깨의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우, 말소리가 들리는 경우 소리와 메시징 기술을 사용하 여 주의 집중 학습하도록 해당 사용자 단말로 알람/경고 메시지를 발생하며 이를 점수화하여 학습 집중도를 제 공하여 학습자가 주의 집중 학습되도록 하는 효과가 있다."}
{"patent_id": "10-2023-0098256", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 바람직한 실시예를 첨부된 도면을 참조하여 발명의 구성 및 동작을 상세하게 설명한다."}
{"patent_id": "10-2023-0098256", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 발명은 개시되는 실시예들에 한정되는 것이 아니라 해당 기술분야에서 통상의 지식을 가진 자가 서로 다른 다양한 형태로 구현될 수 있다. 본 발명의 설명에 있어서 관련된 공지의 기술 또는 공지의 구성에 대한 구체적 인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 자세한 설명을 생략한다. 또한, 첨부 된 도면 번호는 동일한 구성을 표기할 때에 다른 도면에서 동일한 도면번호를 부여한다. 본 연구개발을 통한 특정한 실시 형태에 대해 한정하지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 발명의 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템은 3D 메타버스 강의실을 제 공하여 교수자와 학습자들의 아바타들이 3D 렌더링으로 표시되며, 출석 관리와 학습 콘텐츠를 제공하며, 채팅 서버에 의해 선생님의 발언권 제어에 따라 FIFO 방식으로 선생님과 학생들의 질의응답 채팅을 제공하며, 학습자 의 얼굴 영상과 음성 인식을 통해 모니터링되는 주의 집중 학습 패턴을 3D View로 제공하는 온라인 학습과 유비쿼터스 기반 학습(UBL, Ubiquitous based learning) 콘텐츠를 제공하는 블렌디드 러닝 시스템(LRS 서버)과 연 동되며, 사용자 단말은 3D 렌더러와 미디어 재생부와 안면인식 모듈과 음성인식 모듈을 구비하고, 학습자 단말 기로 학습 콘텐츠를 제공하고, 주의 집중 학습 패턴을 모니터링하는 블렌디드 러닝 시스템(LRS 서버)에 연동된 사용자 단말의 정면 카메라에 포커싱된 학생의 시선을 바로보고 주의집중 학습되도록 학습자의 얼굴의 윤곽선과 눈2/코/귀2/입의 얼굴의 특징점들을 안면 인식을 하며, 학습자의 학습 패턴을 모니터링하고 일정 각도로 시선이 빗나갈 경우 또는 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어 깨와 어깨의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우, 말소리가 들리는 경우 소리와 메시징 기술을 사용하여 주의 집중 학습하도록 해당 사용자 단말로 알람/경고 메시지를 발생하며 이를 점수화하여 학습 집중도 를 제공하여 학습자가 주의 집중 학습되도록 한다. 비대면 온라인 학습/유비쿼터스 학습에서, 블렌디드 러닝 시스템에서 #D 메타버스 강의실을 학습자의 아바타들 이 렌더링되며 출석관리와 학습 콘텐츠를 제공하며, 메타버스 기술과 안면인식과 음성 기술 및 온라인 학습 /UBL(Ubiquitous-Based Learning) 기술을 적용하여 블렌디드 러닝 시스템에 유무선 통신망을 통해 접속된 스마 트 기기(PC, 태블릿 PC)를 사용하여 온라인 블렌디드 러닝 학습 시에 얼굴 인식과 음성 인식 기술이 적용되며, 채팅 서버에 의해 선생님의 발언권 제어에 따라 FIFO 방식으로 선생님과 학생(학습자)와의 질의 응답 채팅 데이 터를 송수신하며, 학습과 UBT(Ubiquitous-Based Test) 시험 기술을 활용한 문제중심학습(PBL; Problem Based Learning), 사용자 단말의 카메라로 모니터링되는 학습자의 행동 데이터를 인식하여 학습자의 얼굴이 포함된 학 습 패턴을 3D View로 제공하고, 학습 집중도를 접수화하여 주의집중 학습을 제공하는 블렌디드 러닝 시스템을 제공한다. * 블렌디드 러닝(Blended Learning) 시스템 - 3D 메타버스 강의실: 강의실 ID, 과목과 교수자 정보, 수강신청 학생 정보 3D Metaverse contents: VR/AR 콘텐츠, 확장현실(XR) 콘텐츠 제공 - 교수자와 학습자들의 질의 응답: 채팅 서버/아바타 채팅 서버 - 온라인 학습/유비쿼터스-기반 학습(UBL) : 주의 집중 학습 정면 자세의 얼굴 학습 패턴(얼굴의 정면 자세 이탈 횟수/시간) -> 등급/점수화, 학습 집중도 값 제공 온라인 학습 또는 UBL 학습 시에, 학습자의 얼굴의 학습 패턴이 지속적으로 불량한 학습자가 감지된 경우(학 습자의 얼굴의 정면 자세를 기준으로 비딱한 자세, 고개 돌림 시에 눈2/코/귀2의 거리가 일정 기준치 미만이면, 말소리 등), 블렌디드 러닝 시스템(LRS 서버)에 연동된 교수자 단말(감독관 단말)은 해당 학습자가 주의력 결핍증(attention deficit disorder)을 가진 학습자로 판단하여 해당 학습자를 주의집중 학습 모니터링 관리 대 상자로 선정하여 카메라 안면 인식/음성 인식을 하여 주의집중 바른 정면 학습 태도가 되도록 항시 모니터링한 다. - 온라인 시험/유비쿼터스-기반 시험(UBT) 도 3은 3D 메타버스 강의실에서 태블릿 PC/스마트폰/PC 기반 학습 콘텐츠를 제공하고 Blended Learning을 위한 학습자의 학습 패턴을 기록하는 메타버스 콘텐츠 제공부와 학습 콘텐츠 제공부와 LRS 서버와 채팅 서버를 구비 하는 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템 구성도이다. 도 4는 본 발명의 실시예에 따른 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 서비스 화면 이다. 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템은 3D 메타버스 강의실에서 교수자와 학습자들의 아바타들이 3D 렌더링으로 표시되며, 온라인 학습 또는 유비쿼터 스 기반 학습(UBL) 시에, 학습자의 출석을 관리하고 학습 콘텐츠를 제공하며, 사용자 단말의 정면 카메라로 촬 영된 학습자의 얼굴의 윤곽선과 눈/코/귀2를 포함하는 학습자의 정면 얼굴 자세를 모니터링한 학습자의 얼굴의 학습 패턴을 등급/점수를 기록/저장하며, 학습자의 얼굴의 정면 자세 이탈시에 해당 학습자 단말로 알람을 발생 하여 주의 집중 학습되도록 경고 메시지를 발생하는 블렌디드 러닝 시스템; 및 상기 블렌디드 러닝 시스템과 유무선 통신망을 통해 연결되고, 3D 메타버스 강의실에 출석 정보를 서버로 저장하고, 상기 학습 콘텐츠를 제공받고 카메라와 안면인식 모듈과 음성인식 모듈을 구비하며 학습자의 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들 인식하고, 학습자의 말소리를 인식하며, 3D 학습 패턴을 3D View로 제공받는 학습자 단말들(300,310,311)을 포함한다. 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템은 상기 블렌디드 러닝 시스템에 유무선 통신망을 통해 접속되며, 강의실 별로 해당 과목의 교수자와 강의실 ID가 구비되며, 수강신청 학습자 명단 정보를 제공받으며, 한글과 워드와 PPT 자료와 강의 동영상/음성이 포함되는 강의 데이터를 업로딩하며, 학습자 단말의 학습자의 자세가 비딱하면 해당 학습자 단말로 주의집중 학습되도록 알람 또는 경고 메시지를 전송하는 교수자 단말을 더 포함한다. 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템은 UBL 클라우드 서버로써 온라인 학습 과 UBL 학습 콘텐츠를 제공하는 블렌디드 러닝 시스템, 학습자 단말 및 교수자 단말(300,310,311)을 포함 한다. 사용자 단말(300,310,311)은 학습 콘텐츠를 제공받고, 학습자의 안면인식/음성 인식을 통해 정면 자세를 기준으 로 학습 패턴을 기록하고 학습 패턴을 등급/접수화하여 출력하는 LRS 서버로부터 유무선 통신망을 통해 온 라인 학습 콘텐츠를 제공받는 스마트폰, 태블릿 PC 뿐만 아니라, 유무선 통신망(이더넷, Wi-Fi, LTE 4G/5G)을 통해 인터넷 접속이 가능한 노트북을 포함한다. 학습자들과 교수자 단말(300,310,311)은 한글과 워드와 PPT 자료 또는 강의 동영상/음성이 포함되는 강의 데이 터를 표시하는 강의 자료 표시부와 강의 동영상/음성 데이터를 출력하는 멀티미디어 뷰어와, 안면 인식 모듈과, 음성 인식 모듈과 3D 학습 얼굴과 학습 패턴 데이터를 시각화하여 표시하는 3D 렌더러를 구비하는 3D 뷰어가 구 비된다. 학습자 단말들과 교수자 단말들을 포함하는 사용자 단말(300,310,311)은 온라인 학습 플랫폼에서 강의실별로 3D 메타버스 강의실에서 온라인 학습과 유비쿼터스-기반 학습(UBL) 시에 주의집중 합습이 되도록 학습 콘텐츠를 제 공받고, 학습자들의 정면 자세의 학습 패턴을 기록하는 블렌디드 러닝 시스템(LRS 서버)와 연동되는 교육 콘텐 츠 viewer가 설치되며, 3D 메타버스 콘텐츠와 AI 안면인식/동작인식/음성인식과 메시징 기술을 사용하여 학습자 단말의 정면 카메라로 촬영되는 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점 5점 척도 특징점들을 인식하고 학 급자의 얼굴의 행동 패턴 데이터를 인식하는 안면인식 모듈과, 주변 잡음을 필터링하고 학습자의 말소리를 샘플 링(8k, 16k, 또는 48k 샘플링)하여 음성을 인식하는 음성 인식 모듈을 구비한다. 학습자 단말(300, 310,311)의 안면 인식 모듈은 얼굴의 윤곽선과 눈2/코/귀2 얼굴이 특징점들을 인식하기 위해 posenet 알고리즘을 사용한다. 학습자 단말(310,311)의 음성 인식 모듈은 주변 잡음을 필터링하고 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음성을 인식하기 위해 SileroVAD 및 SpeechBrain 알고리즘을 사용하였다. 교수자 단말과 사용자 단말은 블렌디드 러닝 시스템(LRS 서버)에 접속되며 각각 \"교사 모드\" 및 \"학습자 모드\", 채팅 서버에 의해 교수자와 학습자들의 질의 응답 데이터를 송수신하는 \"질의 응답 모드\"로 동작된다."}
{"patent_id": "10-2023-0098256", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "교수자와 학습자의 질의 응답 시간 동안에, \"질의 응답 모드\"는 교수자와 학습자의 질의 응답 채팅 데이터를 송 수신하므로, 그 시간 동안에는 학습자의 얼굴의 학습 패턴 모니터링 데이터를 제외한다. 3D 메타버스 강의실에서, 학습 시간 동안, 사용자 단말은 학습자의 영상과 말소리가 레코딩되는 녹음 및 녹화 프로그램, 학습자의 학습 얼굴이 3D 모델링되고 렌더링되는 학습 패턴 3D viewer가 설치되며, 안면 인식 모듈과 음성 인식 모듈이 설치된다. 블렌디드 러닝 시스템의 온라인 학습 또는 UBT 학습 시에, 얼굴의 윤곽선과 눈2/코/귀2를 감지하는 안면인식 모 듈은 응시자 단말의 카메라로 실시간으로 촬영된 정면 얼굴 영상의 ROI를 검출하여 코의 정점을 기준으로 center alignment를 통해 표준 크기로 크기 보정/회전/각도 보정된 표준 크기의 정면 얼굴 사진에 대하여 AI 안 면 인식 알고리즘을 사용하여 얼굴 객체를 추출하고, 얼굴 행동 패턴을 인식하며, 학습자의 얼굴의 윤곽선과 눈 2/코/귀2의 얼굴 특징점들을 추출하며, 얼굴 특징 추출과 분류를 통해 눈2/코/귀2의 얼굴의 특징점들의 각각 좌 측/우측 귀와 좌측/우측 눈의 중심점(동공)과의 유클리디안 거리(d)와 유사도(similarity)를 계산하고, 온라인 학습 또는 UBL 학습을 제공하는 블렌디드 러닝 시스템(LRS 서버)의 얼굴사진 DB의 사진과 데이터와 비교하여 출 석을 확인하며, 온라인 학습/시험 또는 UBL 학습/UBT 시험시에 눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따 라 오른쪽/왼쪽으로 머리 이동을 감지하고 부정행위와 관련된 얼굴의 이상행동 패턴을 검출하고, 얼굴 인식 시 에 안면윤곽선 인식이 안되는 경우, 화면으로부터 일정 각도 이상으로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어깨와 어깨의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우) 학습자 단말의 카메라로 촬영되는 얼굴 행동 패턴을 인식하여 전면 얼굴이 좌우로 돌아간 각도에 따라 우측 눈과 우측 귀의 거리와 좌측 눈과 좌 측 귀의 거리가 달라지므로, 또는 학습자의 말소리가 들리는 경우 주의집중 학습되도록 관련 이미지 또는 영상 데이터를 LRS 서버로 전송하고, LRS 서버에 연동된 감독관 단말이 확인 후, 감독관 단말로부터 LRS 서버를 통해 해당 학습자 단말로 주의집중 학습되도록 경고 메시지를 전송하거나 또는 알람을 발생한다. 사용자 단말(310,311)에서 정면 자세로 학습자가 온라인 학습 또는 UBL 학습이 되도록, 학습자의 안면인식 시에 정면 자세가 아닌 일정 기준치 이하의 비딱한 자세가 검출되거나 또는 \"학습자 모드\"에서 음성 인식시에 학습자 의 말소리 들리는 경우 해당 사용자 단말로 알람 또는 경고 메시지를 출력하여 주의집중 학습되도록 한다. 온라인 학습 또는 UBT 학습/또는 시험 시에, 교수자 단말은 블렌디드 러닝 시스템(LRS 서버)를 통해 다수 의 학습자 단말의 학습자의 출석을 확인하고, 안면인식과 음성인식 기술을 활용한 AI 감독관으로써, 학습자별 정면 자세 학습 패턴 또는 시험 패턴을 모니터링하며, 학습자의 두 눈의 시선 방향 아이트랙킹, 눈2/코/귀2의 안면 인식 데이터 및 주변 화이트 노이즈를 필터링한 학습자의 말소리의 음성 인식 데이터를 모니터링하다가, 학습자의 학습 자세가 일정 기준치 이하로 학습 자세 데이터가 기준치를 초과하는 경우 학습자의 학습 자세가 비딱하면(학습자의 비딱한 자세, 고개 돌림, 말소리) 학습 자세가 삐탁하거나 고개를 상하 방향/좌우 방향으로 돌리거나, 말소리가 들리면, 해당 사용자 단말로 온라인 학습/UBL 주의집중 학습되도록 경고 메시지 또는 알람 을 해당 사용자 단말로 전송한다. 이때, 학습자 단말은 주의집중 학습되도록 경고 메시지 또는 알람이 출력된다. 블렌디드 러닝 시스템(LRS 서버)는 WWW 서버, 제어부, 회원 등록부, 사용자 인증부, 출석 관리부, 3D 메타버스 강의실 학습 콘텐츠 제공부, 안면인식 분석부, 음성인식 분석부 , 학습집중도 제공부, 채팅 서버, 3D 렌더러, 강의실 정보와 교수자와 학습자DB, 학 습 콘텐츠DB, 및 얼굴사진 DB를 포함한다. 상기 블렌디드 러닝 시스템(LRS 서버)은 상기 제어부에 연결되며, 3D 메타버스 강의실에서 교수자의 발언권 제어 방식에 따라 학습자의 질문 요청 Queue에 저장하고 FIFO 방식으로 순차적으로 상기 교수자 단말과 상기 학습자들의 질의 응답 채팅 데이터를 송수신하는 채팅 서버 또는 아바타 채팅 서버를 더 포함한다. 상기 블렌디드 러닝 시스템(LRS 서버)은 학습자 단말들과 교수자 단말과 유무선 통신을 통해 연결되는 WWW 서버; 유무선 통신망을 통해 태블릿 PC, 스마트폰, PC의 학습자 단말들과 교수자 단말로 온라인 학습 또는 유비쿼터스 기반 학습(UBL)과 유비쿼터스 기반 시험(UBT)의 응용 서비스를 제공하도록 제어하는 제어부; 상기 제어부에 연결되며, 학습자들의 회원 정보를 등록받아 ID/Passwd를 저장하여 관리하는 회원 등록부 ; 상기 제어부에 연결되며, 학번/Passwd, 또는 QR 코드/Passwd 또는 ID/Passwd 또는 온라인 인증서를 사용하 여 사용자를 인증하는 사용자 인증부; 상기 제어부에 연결되며, 태블릿 PC, 스마트폰, PC 기반 온라인 학습(Learning)과 시험(Test) 또는 유비쿼 터스 기반 학습(UBL)과 시험(UBT)의 출석을 관리하는 출석관리부; 상기 제어부에 연결되며, 3D 강의실 콘텐츠와 교수자와 학습자들의 아바타를 제공하며 온라인 학습 또는 유비쿼터스 기반 학습(UBL, Ubiquitous based Learning) 콘텐츠를 제공하는 3D 메타버스 강의실 학습 콘텐츠 제 공부; 상기 제어부에 연결되며, 학습자별로 학급자의 안면인식 데이터를 수신받아 얼굴의 윤곽선과 눈2/코/귀2/ 입 얼굴의 특징점들을 추출하여 온라인 학습/UBL 주의집중 학습되도록 학습자의 얼굴의 학습 패턴을 분석하는 안면인식 분석부; 상기 제어부에 연결되며, 학습자별로 학급자의 음성인식 데이터를 수신받아 학습자의 소리 패턴을 분석하 는 음성인식 분석부; 상기 제어부에 연결되며, 실시간으로 수신되는 학습자의 안면 인식 데이터 및또는 학습자의 말소리 데이터 를 수신받아 학습자별 학습 패턴의 빅 데이터를 분석하여 학습 패턴을 등급/점수화하여 점수화된 학습집중도를 제공하며 학습집중도 제공부; 및 강의실 정보와 교수자와 학습자DB, 학습 콘텐츠DB, 및 얼굴사진 DB를 포함한다. 또한, 상기 블렌디드 러닝 시스템은 LMS 서버와 학사관리 시스템과 연동될 수 있다. 3D 메타버스 강의실은 메타버스 가상 공간에서, 교수자와 학습자들의 아바타들이 표시되며 확장 현실(XR) 콘텐 츠로 제작되며 3D 모델링된 3D 캐릭터가 3D 렌더러에 의해 렌더링되며, 강의 제목과 교수자, 한글 또는 워드로 작성된 자료 또는 PPT 자료와 강의 동영상과 음성이 포함된 강의 자료를 제공하며, 메타버스 게더 타운에서 교 수자와 학습자들와의 인터렉티브하게 질의 응답을 위해 선생님의 발언권 제어에 따라 FIFO 방식으로 선생님과 학생들의 질의응답 채팅 데이터를 송수신하는 채팅 서버 또는 아바타 채팅 서버가 구비된다. 상기 블렌디드 러닝 시스템은 상기 제어부에 연결되며, 학습자 단말들로 온라인 시험 프로그램을 제 공하며 온라인 시험 프로그램에 온라인 시험 또는 UBT 시험 문제가 출제되고, 시험 시간 동안 작성된 온라인으 로 학습자별 시험 답안을 취합하여, 시험 후 해당 학습자 단말기들로 채점 정보를 제공하는 온라인 시험 또는 UBT 시험부(시험 서버)를 더 포함한다. 온라인 시험 또는 UBT 시험 시에, 정해진 일정과 시간과 장소에서 학습자의 응시표에 부착되는 인식 코드로써 학번/Passwd 또는 응시표에 부착된 사진과 바코드 또는 QR 코드를 사용할 수 있다. 상기 시험 프로그램의 시험지 문항은 주관식 및/또는 객관식 시험 문항을 포함하며, 각 문항마다 텍스트 및 이 미지 뿐만 아니라 텍스트, 이미지, VR/AR 콘텐츠, 음성과 동영상 중 적어도 하나 이상이 포함된 멀티미디어 시 험 문항이 출제되어 응시자 단말(300,310,311)로 디스플레이된다. 상기 블렌디드 러닝 시스템은 유무선 통신망(이더넷, Wi-Fi, LTE 4G/5G)을 통해 학습자 단말들과 교수자 단말과 연결되고 실시간으로 교수자의 강의 동영상과 음성 데이터를 제공하며, 추가적으로 학습자의 얼굴 영상 과 음성 데이터를 저장하고, 스트리밍 서비스를 제공하는 NVR 서버를 더 포함한다. 상기 블렌디드 러닝 시스템은 3D 메타버스 강의실에서, 학습자 단말들과 교수자 단말로 제공되는 한글과 워드로 작성된 자료, PPT 자료 또는 강의 동영상/음성이 포함되는 강의 데이터를 표시하는 강의 자료 표시부와 강의 동영상/음성 데이터를 출력하는 멀티미디어 뷰어와, 안면 인식 모듈과, 음성 인식 모듈과 학습자의 얼굴의 학습 패턴 데이터를 시각화하여 3D View로 표시하는 3D 렌더러를 구비하는 3D 뷰어가 구비되며, 3D 학습 콘텐츠를 제공하며, 실시간으로 학습자의 3D 학습 패턴을 모델링/형성하여 얼굴의 윤곽선과 머리와 이 마/눈2/코/귀2/입을 3D 모델링하여 렌더링하는 3D 렌더러를 더 포함한다. 상기 블렌디드 러닝 시스템에 연동된 상기 학습자 단말은 학습 시간 동안, 녹음/녹화 데이터(소리 파일과 이미지 파일이 통합된 영상 파일)을 블렌디드 러닝 시스템(LRS 서버)으로 전송하여 저장되는 상기 학습자 단말에 구비된 녹음 및 녹화 프로그램을 구비한다. 블렌디드 러닝 시스템은 학습자 단말에서 안면인식 모듈과 얼굴의 특징점들을 인식하는 안면 인식 모듈에 의해 정면 카메라의 영상에 대하여 안면인식 기술(posenet 알고리즘)을 사용하여 눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 오른쪽/왼쪽으로 머리 이동을 감지하고 온라인 학습과 UBL 학습시 얼굴의 학습 패턴을 검 출하며, 안면윤곽선 인식이 안되는 경우, 학습 화면 또는 시험 화면으로부터 얼굴이 일정 각도 이상으로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어깨와 어깨의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우) 교수 자 단말(감독관 단말)에 표시되고, 교수자 단말(감독관 단말)로부터 블렌디드 러닝 시스템(LRS 서버)을 통 해 해당 학습자 단말로 학습 시 주의 집중 학습 알람/시험 시 부정행위 관련 경고 메시지 또는 알람을 해당 학 습자 단말로 전송한다. 학습자의 얼굴의 학습 패턴은 얼굴 인식과 음성 인식을 통해 개별 학습자의 얼굴의 학습 패턴을 빅 데이터 분석 을 통해 학습자의 얼굴의 학습 패턴 3D View를 표시하고, 학습 패턴 통계 데이터를 제공할 수 있다. 모집단(population)의 n개의 표본(sample)을 추출하고, 모집단의 평균/표준편차/분산을 계산하여 학습자의 얼굴 의 학습 패턴 빅 데이터 분석을 통해 통계 분석(개인별 학습자 얼굴의 학습 패턴 평균, 표준편차)을 실시하여 막대 그래프, 시간 경과에 따른 학습 패턴(학습 자세, 고개의 좌우 방향, 상하 방향)이 표시된 산점도(scatter diagram)로 데이터 시각화하여 표시된다. n명의 학습자들의 학습 패턴[n개의 표본(sample)]의 모평균 E(x) E(x)= m = (X1+X2+X3+...+Xn)/n 모평균(mean) m, 표준편차(standard deviation)가 σ 일때, 모집단(population)에서 샘플링된 크기가 n개의 표 본(sample)을 추출하여 생성된 표본 평균 m과 표본 분산 을 갖는 모평균과 모분산을 갖는 정규 분포 N(m, )를 이루며, 이에 따라 표본 평균 m을 갖는 표준 정규 분포를 이룬다. 표준 정규 분포는 학습 패턴 n개의 표본 평균 m 및 표준편차를 계산하며, 표본 오차는 ±2P (신뢰도 95% 신뢰구 간)을 갖는다. 도 5a 내지 도 6은 블렌디드 러닝 시스템(UBL 클라우드 서버:LRS 서버, Learning Record Server)에 접속된 사 용자 단말의 온라인 학습/주의집중 UBL 학습 테스트 화면이다. 도 7은 학습자의 얼굴의 코의 센터 얼라이먼트(centre alignment)를 기준으로 학습자의 자세 인식 얼굴의 윤곽 선과 눈2/코/귀2 안면인식 초기화 화면이다. 1) 안면인식과 음성 인식를 실행하는 AI 감독관 프로그램이 사용자 단말의 카메라를 주시하는 학습자의 얼굴의 코의 센터 얼라인먼트(centre alignment)를 기준으로 성공적으로 학습자의 얼굴의 안면 인식을 했다면 눈2/코/ 귀2에 빨간 점이 찍힌 캡춰가 출력된다[Close 버튼을 클릭한다]. 2) 학습자가 머리를 오른쪽으로 움직이면, 우측 상단에 경고 메시지가 팝업된다. [메시지, Please docus on screen]. 메시지를 확인한 뒤 고개를 왼쪽으로 돌려서 메시지를 한번 더 확인한다. 3) 사용자 단말의 카메라를 가리거나 얼굴을 숨긴 뒤 메시지 팝업을 확인한다. [메시지, Face not available] 온라인 학습 또는 UBL 학습/또는 UBT 시험 시에, 수업 진행중 집중하지 않았을때 학습자 단말의 화면 메시지 우 측 상단에 화면에 경고 메시지를 출력하고, 동시에 소리로 경고음을 출력한다. 실시예에서는, 서울대-NSD 공동보고서에서, 서울대학교 사범대학 AI 기반 교육연구센터에서 교육에서의 AI 활용 사례 및 온라인 학습/유비쿼터스-기반 학습(UBL) 시스템에 대하여, 블렌디드 러닝 시스템(UBL 클라우드 서 버:LRS 서버) 상에서 태블릿 PC 기반의 온라인 학습/유비쿼터스 기반 학습(UBL) 및 유비쿼터스 기반 시험(UBT) 에 얼굴의 윤곽선과 눈2/코/귀2 안면 인식과 음성 인식이 사용된 AI 감독관 기술을 실시하였으며, 영어를 외국 어로 학습하는 상황에서 영어 독해 및 쓰기 과업에서 학습자의 인지적 처리 과정을 통해 특정 회사의 뇌파(EEG) 검출과 함께 고려하여 \"학습집중도\"를 평가한 결과 긍정적인 결과가 있었다. 블렌디드 러닝 시스템은 3D 메타버스 강의실에서 메타버스 콘텐츠를 제공하며, 학습 콘텐츠를 제공하는 LMS 서 버와 연동될 수 있으며, AI 감독관 기술은 학습자의 얼굴의 행동 데이터(영상과 음성)를 기록하고 제공하기 때 문에, AI 감독관은 일반적인 LMS 서버가 제공하던 서버 접속 시간, 접속 횟수, 학습 시간, 과제 등의 로그 데이 터를 넘어, 수업 참여에 대한 직접적인 데이터를 제공할 수 있다. AI 감독관을 사용한 학습자의 동공의 시선 추적(Eye-Tracking) 또는 안구 이동(Eye-Movement)에 관련된 로그 데 이터를 저장하여 실험을 실시하였다. 도 8은 Posenet 알고리즘을 사용한 학습자의 학습 얼굴 눈2/코/귀2 얼굴 영상과, 3D 학습 얼굴 렌더링(3D view), 및 학습 패턴과 관련된 통계 데이터를 시각화하여 학습 분석 차트로 표시된 막대 그래프와 산점도(좌우 방향, 상하 방향)를 나타낸다. 학습이나 시험 시에, 사용자 단말에서 안면인식 시에, 지속적으로 학습자의 정면 얼굴의 학습 자세가 비정상적 으로 불량한 경우(학습자의 얼굴의 정면 자세를 기준으로 비딱한 자세, 고개 돌림 시에 눈2/코/귀2의 거리가 일 정 기준치 미만이면, 말소리 등)를 검출하며, 양쪽 귀2/눈2/코 5점 사이 거리 비율을 계산한 각도/비율 정보, 얼굴의 좌우 방향, 얼굴의 상하 방향을 테스트하여, 학습집중도를 계산하였다. 학습 집중도는 얼굴의 움직임 횟수, 시선의 위치 좌표(x,y), 말소리 발생 여부/발생 시간을 포함하는 집중도 지 표(Attention Metric)에 따라 등급[집중 학습(3점)/보통(2점)/학습 자세 불량(1점)]에 따라 학습자의 얼굴의 움 직임과 두 눈의 움직임을 트래킹하여 시선의 위치 좌표(x,y)와 이동 방향 뿐만 아니라 시선응시값(Fixation)과 시선이동값(Saccade)을 도출하며, Time Stamp와 함께 저장하며, 학습자의 말소리 발생 여부/말소리 발생 시간을기록하여 점수화한다. 표 1 집중도 지표 (Attention Metric)학습자의 얼굴의 정면 자세 기준 특징점들(눈2/코/귀2)의 거리 눈과 귀의 거리, 코와 귀의 거리 학습자의 얼굴 부분의 학습 집중도 정량 분석/정성 분석(점수화) 얼굴의 움직임 (40점) 학습자의 눈과 귀의 거리, 코와 귀의 거리의 일정 기준치 초과시 알람/집 중도 점수 감점 등급:집중 학습/보통/자세 불량 시선의 위치 좌표(x,y) (30점)- 시선의 x,y축 움직임이나 이동방향 트래킹하며, 정면 화면 직사각형의 이외의 영역에 시선의 위치 좌표에 이동시 알람등급:집중 학습/보통/자세 불량 말소리 발생 여부/시간 (30점)학습 시에 말소리 발생 여부/시간 기 록->알람/집중도 점수 감점 등급: 집중 학습/보통/자세 불 량 학습 집중도는 학습 시간 동안 해당 학습자의 얼굴의 정면 자세 학습 패턴을 기준으로 얼굴의 눈2/코/귀2의 거 리(코와 귀의 거리, 눈과 귀의 거리 등)를 측정하여 일정 기준치의 표준 편차 이내의 경미한 미동을 제외하고, 일정 기준치를 미만의 단위 시간당 그 학습자의 비정상적으로 불량한 횟수와 시간을 검출하여 학습 집중도를 감 점하는 방식으로, 학습 집중도 값을 산출한다. 단, 학습 시간이 완료된 후에 교수자의 질의 응답 시간을 별도로 두고, 교수자와 학생들과의 질의 응답 채팅 데이터 송수신 시에는 학습자들의 학습 집중도 값 산출을 제외한다. 온라인 학습과 시험 또는 유비쿼터스-기반 합습과 시험 시에, 개인별 학습자마다 학습 집중도가 학습자별로 등 급/점수화하며, 출석 점수와 시험 점수(리포트 점수/중간 고사와 기말 고사의 시험 점수)와 같이 관리된다. 도 9는 출석, 온라인 학습/UBL 학습 콘텐츠를 제공하고 AI 모듈을 구동하여 학습자의 얼굴 안면 인식에 의해 학 습자별 얼굴의 학습 패턴(등급, 점수), 학습과 과제수행(assignment), 학습자별 얼굴의 학습 패턴을 제공하며 통과/탈락 예측을 제공하는 UBL 클라우드 서버(LRS 서버)의 지식 트랙킹 모듈(activities), activities의 그룹 핑, 학습 패턴 일반화, 학습자 얼굴의 학습 패턴 통계 데이터 시각화 및 통과/탈락 예측(prediction)을 제공하 는 UBL 클라우드 서버(LRS 서버)의 구성도이다. 도 10a 내지 도 10d는 출석, 학습 콘텐츠를 제공하고 AI 모듈을 구동하여 학습자의 얼굴 안면 인식에 의해 학습 자 얼굴의 학습 패턴(등급, 접수), 학습과 과제수행(assignment), 학습자별 학습 패턴을 제공하며 통과/탈락 예 측을 제공하는 블렌디드 러닝 시스템(UBL 클라우드 서버:LRS 서버)의 지식 트랙킹 액티비티들(activities)과 애 트리뷰션, 학습 진단을 나타낸 도면이다. 학습 액티비티들(activities)은 Log in time, Log out time, Stay time in UBL, Number of dairy visit, Study time in viewer, Video watching time, Video call stay time, Video cal stay time, 출석(attentanc e)들이 특정 애트리뷰트(사이트 방문, 뷰어, 퀴즈, 토론, 과제 수행, 팀 프로젝트, MSG)에 그룹핑되어 연결되며, 각각의 애트리뷰트는 진단 목록의 학습 역량, 학습 패턴, 콘텐츠 이용, 관심, 집중도, initiative, 관계(Relationship)과 연결된다. 온라인 학습 또는 UBL 학습 시에, 학습자의 얼굴의 학습 패턴이 지속적으로 불량한 학습자가 감지된 경우, 블렌 디드 러닝 시스템(LRS 서버)에 연동된 교수자 단말(감독관 단말)은 해당 학습자가 주의력 결핍증 (attention deficit disorder)을 가진 학습자로 판단하여 해당 학습자를 주의집중 학습 모니터링 관리 대상자로 선정하여 카메라 안면 인식/음성 인식을 하여 주의집중 바른 정면 학습 태도가 되도록 항시 모니터링한다. 도 11은 온라인 학습/UBL 학습 시에, UI/UX 화면의 음성 검출 화면이다. 도 12는 음성 인식 시에, 주변 잡음을 필터링하고 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음 성 인식된 SileroVAD 및 SpeechBrain 알고리즘 실행 결과이다. 사용자 단말의 음성 인식 모듈은 SileroVAD 및 SpeechBrain 알고리즘을 사용하였으며, 음성 인식 시에, 마이크 로 입력 된 음성 신호에 대하여 미리 저장된 생활상의 특정 소리(TV 소리, 전화 소리, 탁자 소리, 집 문여는 소 리)를 필터링하고 주변 잡음(가우시안 노이즈)을 필터링하며, 순수한 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 학습자의 말소리를 음성 인식한다. 도 13은 온라인 학습/UBL 학습 또는 시험 시에, 블렌디드 러닝 시스템(LRS 서버)와 연동된 사용자 단말의 녹음/ 녹화 프로그램을 보인 화면이다. 사용자 단말은 앱 실행 및 시험데이터 요청, QR 코드 인식(또는 바코드 인식), 안면 인식 -> 데이터 확인 -> 레 코딩 대기 -> 레코딩 시작(시험 데이터 기반 자동 오프라인 레코딩) -> 레코딩 중 앱 강제종료 등 예외 처리 (재시작, 계속 레코딩 기능) -> 레코딩 종료 대기 -> 레코딩 종료 -> 레코딩 종료 후 처리(이미지 취합 및 영상 파일, 녹음파일) -> 응시자 단말로부터 블렌디드 러닝 시스템(LRS 서버)로 전송(학습 또는 시험 부정행위 관련 이미지, 영상 파일, 녹음 파일) -> 전송실패 예외 처리(자동 재시도, 수동 업로드) -> 처리 종료 메시지를 블렌 디드 러닝 시스템(LRS 서버)로부터 수신받고 종료된다. 또한, 온라인 학습 및 유비쿼터스-기반 학습(UBL) 학습 과정 후에, 온라인 시험 및 UBT 시험이 실시될 수 있다. 실시예에서는, 응시자 단말은 유무선 통신망을 통해 시험 서버를 구비하는 블렌디드 러닝 시스템에 접속하여 온 라인 시럼 또는 UBT 시험응시를 신청하게 되면, 응시자의 시험신청정보를 시험 서버에 응시자의 시험접수를 수 행하는 시험신청접수 과정; 시험 일정과 시간과 장소가 결정되면 해당 시험의 응시자들에게 시험 일정과 시간과 장소 정보를 포함하는 시험정보를 공지하는 시험정보 공지 과정; 시험 장소 및 시간이 설정되면, 설정된 시험의 일시와 장소의 시험실별 감독관을 설정하고 감독관에게 선임 사실을 알리는 감독관선임정보를 제공하고 해당 감 독관으로부터 시험 서버로 선임확인정보를 수신하여 감독관설정과정을 완료하는 감독관 설정 과정; 시험 당일 해당 시험 장소의 감독관으로부터 시험장소 셋팅 정보의 입력을 대기하고, 감독관으로부터의 시험장소 셋팅 정 보가 입력되면 시험 프로그램(어플, App)을 제공하여 응시자들의 스마트 폰에 설치하도록 하고, 응시자들의 스 마트 폰에 설치된 시험 프로그램을 통해 접속된 응시자들에게 시험접속확인을 요청하는 시험장 셋팅 과정; 시험 장소 셋팅이 완료되면 설정되어 있는 문제의 유형과 문제선택설정정보(난이도)를 참조하여 등록저장 되어있는 시행될 문제리스트 중 어느 하나를 선택하고, 설치된 응시자들의 시험프로그램과 통신하여 시험문제를 제공하며, 응시자 단말은 시험 프로그램을 통해 시험지의 답안정보를 시험 서버로 수신하여 응시자별로 저장하 는 시험진행 과정; 모든 시험문제가 출제되고, 시험이 종료되면 감독관의 종료확인정보 입력을 대기하고, 감독 관의 종료확인정보가 입력되면 응시자들의 태블릿PC에 설치된 응용프로그램을 자동 삭제시키는 시험마무리 과정; 및 시험 서버로 수신 저장된 각 응시생들의 작성 답안을 채점답안정보와 비교하여 채점하며, 그 채점 결 과 정보를 공지하는 시험 발표 과정으로 구성된다. 감독관 선임은 미리 등록된 감독관 중에서 선택하게 되며, 감독관은 미리 계약된 감독관들이며, 시험 서버의 시 험정보 데이터베이스에 등록관리 한다. 감독관이 선임되면, 시험 서버를 통해 감독관 선임 정보를 제공하고 감독관으로부터 선임 확인 정보를 수신하여 감독관 설정 과정을 완료하게 된다. 감독관 선임 정보는 시험 장소, 시험 시간, 응시 인원 정보를 포함한다. 응시인원 정보는 각 응시자들의 사진과 이름, 성별, 주소를 포함하는 인적 정보와, 연락 정보를 포함한다. 시험 셋팅 과정은 시험당일 미리 설정되어 있는 준비시간 전 시험에 필요한 부분들을 점검하고 시험을 진행하는 장치를 셋팅하는 과정이다. 시험장이 응시자들을 감독관이 응시자 정보와 정면 얼굴 사진을 확인하고 이에 대한 확인정보인 시험장소 셋팅 정보를 입력하면, 시험 서버로부터 응시자 단말로 시험에 필요한 시험 프로그램(App)을 제공하게 되며, 응시자 들이 시험 프로그램을 태블릿 PC에 설치하며, 시험 프로그램을 통해 데이터를 송수신하여 응시자들이 신청정보 입력 시 입력한 식별정보를 입력하여 응시자들의 시험접속확인을 완료하는 과정이다. 감독관의 시험 셋팅 정보는 시험에 참가한 응시자수 정보를 포함하고, 응시자들의 식별정보는 응시자들이 신청 정보 입력 시 입력한 이름, 주민등록번호와 같은 인적정보 중 어느 하나 또는 회원 아이디로 이루어진다. 시험 프로그램(App)은 시험 서버를 구비하는 블렌디드 러닝 시스템에 접속하여 응시자 식별 정보를 입력하 여 시험 프로그램을 응시자 단말에서 다운로드받아 시험 프로그램이 설치되며, 시험 서버를 구비하는 블렌디드 러닝 시스템에서 감독관 단말을 통해 감독관이 시험셋팅정보를 입력하면, 감독관이 시험 프로그램의 경로를 제 공하고, 그 경로에 따라 응시자들이 시험 프로그램을 설치하도록 하는 과정을 포함한다. 추가적으로, 블렌디드 러닝 시스템은 대학의 학사관리 시스템과 학습 관리 콘텐츠를 제공하는 LMS 서버와 연동될 수 있으며, UBL/UBT 클라우드 서버로 사용되는 블렌디드 러닝 시스템(LRS 서버)은 온라인 시험 또 는 UBT 시험을 위해, 응시자의 얼굴의 윤곽선과 눈2/코/귀2의 시각적인 부정행위를 감지하는 안면인식 분석부와말소리를 분석하는 음성인식 분석부를 기본적으로 구비하며, 상기 온라인 시험 또는 UBT 시험부는 상기 제어부에 연결되며, 상기 응시자 단말과 상기 감독관 단말로 시험 프로그램(App)과 시험지를 제공하 며, 응시자 정보들과 응시자의 현장 얼굴 사진, 감독관 정보를 관리하며, 온라인 시험 또는 UBT 시험 시에 일정 시험 시간 이내에 각각의 응시자 단말에 시험지 작성 답안을 저장 후 시험 종료시 시험 서버로 전송되며, 응시 자들의 시험지 작성 답안, 채점 결과, 감독관 정보와 응시자 현황 정보를 저장하여 관리하는 시험 관리부; 시험 정보와 감독관 정보와 응시자들의 시험지와 작성 답안, 채점 결과를 저장하는 시험 정보DB; 응시자 정보와 표준 크기의 정면 얼굴 사진 및/또는 얼굴 동영상/음성을 저장하는 응시자DB와 얼굴/말소리 DB, 시험 DB를 더 포함한다. 블렌디드 러닝 시스템에 구비된 제어부에 연결된 온라인 시험 또는 UBT 시험 관리부는 초중고 시험, 대학 시험, TOEIC/TOEFL 시험, 어학 시험, 공무원 시험, 자격증 시험, 어학 교육, 보건의료교육 등의 학습과 온라인 시험지 를 제공하는 문제 은행의 각종 공인 인증 시험 또는 비공인 시험을 시험 일정과 장소를 공지하고, 시험 서버의 데이터베이스의 시험 프로그램을 사용하여 유무선 통신망을 통해 응시자 단말들에게 온라인 시험 문제를 활용하 여 시험을 치를 수 있는 모든 형태의 PC/스마트 기기를 활용하는 UBT 시험을 제공한다. 블렌디드 러닝 시스템(LRS 서버)의 제어부는 시험일정과 장소가 확정되면, 감독관을 선임하여 감독관에게 감독관선임정보를 제공하고, 응시자들에게 문자 메시지/웹페이지를 통해 시험 일정과 장소를 공지하며, 시험 당 일 시험장소의 감독관 단말로 시험 정보와 시험지 정보를 송수신하여 시험을 진행 관리하고, 자동채점결과부 및 검수관리부의 결과로부터 채점 결과를 해당 응시자 단말들로 제공한다. 시험정보 데이터베이스에 저장되는 시험 정보는 시험 제목, 시험 일정과 장소, 시험 시간, 시험 장소의 위치 정 보, 할당된 시험실별 감독관 정보와 응시자들 명단, 시험실별 좌석수, A/B 문제 유형별 시험지의 문제 정보, 답 안 정보, 채점 정보를 포함한다. 그리고, 응시자 데이터베이스는 이름, 주민등록번호, 집주소, 이동전화번호, 이메일 등을 포함하는 응시자 정보, 응시자 사진(표준 크기의 얼굴 정면 사진) 및 학번/Passwd, QR 코드/passwd, ID/passwd 식별 정보와 시험 관련 정보, 응시자 신청 현황이 저장된다. 또한, 상기 LRS 서버는 온라인 학습/UBL 학습 후에, 정해진 일정과 시간과 장소에서 UBT 시험을 실시하는 시험관리부와 채점부를 추가적으로 더 구비하며, 온라인 시험 또는 UBT 시험 시에, 정해진 일정과 시간과 장소 에서 학습자의 응시표에 부착되는 인식 코드로써 학번/Passwd 또는 응시표에 부착된 바코드 또는 QR 코드를 사 용할 수 있다. 상기 시험 프로그램의 시험지 문항은 주관식 및/또는 객관식 시험 문항을 포함하며, 각 문항마다 텍스트 및 이 미지 뿐만 아니라 텍스트, 이미지, VR/AR 콘텐츠, 음성과 동영상 중 적어도 하나 이상이 포함된 멀티미디어 시 험 문항이 출제되어 응시자 단말(300,310,311)로 디스플레이된다. 상기 응시자 단말(300,310,311)은 획일적으로 정면 카메라(C)를 구비하는 태블릿 PC, 스마트폰, PC, 노트북 중 어느 하나 단말을 사용하며, 온라인 시험 또는 UBT 시험 서버로부터 다운로드된 시험 프로그램(App)이 설 치되고, 온라인 시험 또는 UBT 시험 서버와 연동되는 영상과 소리가 레코딩되는 녹음 및 녹화 프로그램이 설치 된다. 시험시에는 , 상기 응시자 단말(300,310,311)은 응시자 단말의 정면 카메라 영상의 얼굴의 특징점들을 인식하는 인공지능 안면인식 모듈; 온라인 시험 또는 UBT 시험 중에, 시각적인 부정행위를 방지하도록 응시자 단말의 정면 카메라 영상의 얼굴의 행동 패턴을 인식하여 얼굴의 특징점들을 구성하는 얼굴의 윤곽선과 눈2, 코, 귀2의 얼굴의 특징점 5점 척도 부 정행위 방지 모듈; 및 온라인 시험 또는 UBT 시험 중에, 청각적인 부정행위를 방지하도록 응시자의 말소리를 인식하는 음성 인식 모듈 을 포함한다. 추가적으로, 응시자 단말은 주관식 시험 문항을 위해 스타일러스 펜의 필기체를 인식하여 문자로 변환하여 필기 체 문자를 인식하는 터치 센서와 디스플레이를 구비하는 응시자 단말의 필기체 인식부를 더 포함한다. 추가적으로, 온라인 시험 또는 UBT 시험은 2지/3지/4지/5지선다 객관식 시험 뿐만아니라 주관식 시험을 제공하 며. 주관식 시험 문항은 터치 센서와 디스플레이를 구비하는 응시자 단말의 필기체 인식부를 사용하여 스타일러 스 펜의 필기체를 인식하여 문자로 변환하여 필기체 문자를 인식하는 주관식 시험을 포함한다. 마찬가지로, 상기 안면인식 모듈에 사용된 상기 안면윤곽선 인식 기술은 posenet 알고리즘을 사용한다. 안면인식과 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점 5점 척도 부정행위를 방지하는 안면인식 모듈은 얼굴의 특징점 눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 오른쪽/왼쪽으로 머리 이동을 감지하고 추적하여 얼 굴의 행동 패턴을 검출하며, FACE RECOGNITION/FACE MOTION RECOGNITION/RESULT ANLAYSIS를 통해 얼굴 인식시 에 안면윤곽선 인식이 안되는 경우, 태블릿 PC의 카메라 영상이 촬영되는 시험 화면으로부터 일정 각도 이상으 로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어깨와 어깨의 거리의 해당 방향의 거리가 일정 수치를 넘는 경 우), 말소리가 들리는 경우 해당 응시자 단말로 경고 메시지 또는 알람을 출력하거나 또는 해당 응시자 단말에 저장한 후 이를 시험 종료시 서버로 전송하며, 서버는 응시자들에게 채점 결과를 제공한다. 마찬가지로, 응시자 단말은 온라인 또는 UBT 시험 서버와 연동되는 녹음/녹화 프로그램이 설치되며, AI 안면인 식/동작인식/소리인식 기술을 사용하여 인공지능 안면인식 모듈과 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점 5 점 척도 부정행위 방지 모듈, 및 음성인식 모듈을 구비하며, 온라인 시험 또는 UBT 시험 서버와 연동하여 온라 인 시험 또는 UBT 시험의 대리시험 방지 및 시청각적인 부정행위를 방지하게 된다. 본 발명에 따른 실시예들은 다양한 컴퓨터 수단을 통해 수행될 수 있는 프로그램 명령 형태로 구현되고, 컴퓨터 판독 가능 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 기록 매체는 프로그램 명령, 데이터 파일, 데이 터 구조를 단독으로 또는 조합하여 포함할 수 있다. 컴퓨터 판독 가능 기록 매체는 스토리지, 하드 디스크, 플 로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램 (RAM), 플래시 메모리, 스토리지 등과 같은 저장 매체에 프로그램 명령을 저장하고 수행하도록 구성된 하드웨어 장치가 포함될 수 있다. 프로그램 명령의 예는 컴파일러에 의해 만들어지는 것과, 기계어 코드 뿐만 아니라 인 터프리터를 사용하여 컴퓨터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 상기 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로써 작동하도록 구성될 수 있다. 이상에서 설명한 바와 같이, 본 발명의 방법은 프로그램으로 구현되어 컴퓨터의 소프트웨어를 이용하여 읽을 수 있는 형태로 기록매체(CD-ROM, RAM, ROM, 메모리 카드, 하드 디스크, 광자기 디스크, 스토리지 디바이스 등)에 저장될 수 있다. 본 발명의 구체적인 실시예를 참조하여 설명하였지만, 본 발명은 상기와 같이 기술적 사상을 예시하기 위해 구 체적인 실시 예와 동일한 구성 및 작용에만 한정되지 않고, 본 발명의 기술적 사상과 범위를 벗어나지 않는 한 도 내에서 다양하게 변형하여 실시될 수 있으며, 본 발명의 범위는 후술하는 특허청구범위에 의해 결정되어야 한다."}
{"patent_id": "10-2023-0098256", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 기존 얼굴 인식 장치의 구성도이다. 도 1b는 종래의 인공지능 심층학습 기반의 영상물 인식 시스템의 구성도이다. 도 2는 종래의 온라인 학습자를 위한 주의집중 판단 시스템 구성도이다. 도 3은 3D 메타버스 강의실에서 태블릿 PC/스마트폰/PC 기반 학습 콘텐츠를 제공하고 Blended Learning을 위한 학습자의 학습 패턴을 기록하는 메타버스 콘텐츠 제공부와 학습 콘텐츠 제공부와 LRS 서버와 채팅 서버를 구비 하는 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 시스템 구성도이다. 도 4는 본 발명의 실시예에 따른 3D 메타버스 강의실에서 학습집중도를 향상시키는 블렌디드 러닝 서비스 화면 이다. 도 5a 내지 도 6은 UBL 클라우드 서버(LRS 서버, Learning Record Server)에 접속된 사용자 단말의 주의집중 UBL 학습 테스트 화면이다. 도 7은 학습자의 얼굴의 코의 센터 얼라이먼트(centre alignment)를 기준으로 학습자의 자세 인식 얼굴의 윤곽 선과 눈2/코/귀2 안면인식 초기화 화면이다. 도 8은 Posenet 알고리즘을 사용한 학습자의 학습 얼굴 눈2/코/귀2 얼굴 영상과, 3D 학습 얼굴 렌더링(3D view), 및 학습 패턴과 관련된 통계 데이터를 시각화하여 학습 분석 차트로 표시된 막대 그래프와 산점도를 나 타낸다. 도 9는 출석, 온라인 학습/UBL 학습 콘텐츠를 제공하고 AI 모듈을 구동하여 학습자의 얼굴 안면 인식에 의해 학 습자별 얼굴의 학습 패턴(등급, 점수), 학습과 과제수행(assignment), 학습자별 얼굴의 학습 패턴을 제공하며 통과/탈락 예측을 제공하는 UBL 클라우드 서버(LRS 서버)의 지식 트랙킹 모듈(activities), activities의 그룹 핑, 학습 패턴 일반화, 학습 패턴 통계 데이터 시각화 및 통과/탈락 예측(prediction)을 제공하는 블렌디드 러 닝 시스템(UBL 클라우드 서버: LRS 서버)의 구성도이다. 도 10a 내지 도 10d는 출석, 온라인 학습/UBL 학습 콘텐츠를 제공하고 AI 모듈을 구동하여 학습자의 얼굴 안면 인식에 의해 학습자 얼굴의 학습 패턴(등급, 점수), 학습과 과제수행(assignment), 학습자별 학습 패턴을 제공 하며 통과/탈락 예측을 제공하는 블렌디드 러닝 시스템(UBL 클라우드 서버:LRS 서버)의 지식 트랙킹 액티비티들 과 애트리뷰션, 학습 진단을 나타낸 도면이다. 도 11은 온라인 학습/UBL 학습 시에, UI/UX 화면의 음성 검출 화면이다. 도 12는 음성 인식 시에, 주변 잡음을 필터링하고 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음 성 인식된 SileroVAD 및 SpeechBrain 알고리즘 실행 결과이다. 도 13은 온라인 학습/UBL 학습 또는 시험 시에, LRS 서버와 연동된 사용자 단말의 녹음/녹화 프로그램을 보인 화면이다."}
