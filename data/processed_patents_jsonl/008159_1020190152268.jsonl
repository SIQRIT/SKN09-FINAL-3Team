{"patent_id": "10-2019-0152268", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0063762", "출원번호": "10-2019-0152268", "발명의 명칭": "이기종 뉴로모픽 아키텍처를 지원하기 위한 추상화 구조 설계 방법, 이를 수행하기 위한 기록", "출원인": "숭실대학교산학협력단", "발명자": "홍지만"}}
{"patent_id": "10-2019-0152268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "FPGA 기반 뉴로모픽 아키텍처 보드와 이기종 IoT 환경에서 동작하기 위한 실행환경 설정파일(NAAL_config)을 분석하는 파일 분석기;상기 FPGA 기반 뉴로모픽 아키텍처 보드에 학습 모델 프로그램의 실행 및 종료 명령어를 전달하고, 초기 설정파일을 전송하는 명령어, 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 대한 자원을 확인하는 명령어 및 경로 설정파일(NAAL_script)에 설정된 학습 모델 프로그램을 실행하는 명령어를 송신하는 명령어 처리기; 및상기 학습 모델 프로그램의 실행을 위해 필요한 데이터를 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 전달하고,상기 FPGA 기반 뉴로모픽 아키텍처 보드로부터 매 스텝마다 학습된 결과를 수신하는 제1 스텝 처리기;를 포함하는, 이기종 뉴로모픽 아키텍처를 지원하기 위한 호스트 장치."}
{"patent_id": "10-2019-0152268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 파일 분석기는 상기 설정파일(NAAL_config) 파일을 분석하여 학습을 수행할 FPGA 기반 뉴로모픽 아키텍처보드의 정보와 학습 모델 구동 제어를 위해 호스트에 대한 정보를 추출하고,상기 명령어 처리기는 모델 학습 구동에 필요한 데이터를 압축하고, 상기 설정파일(NAAL_config)의 학습 전처리과정을 위한 임시 파일 경로(remote_tmp)에 설정된 경로로 SSH 통신을 이용하여 압축된 데이터 파일을전송하고,상기 명령어 처리기와 상기 제1 스텝 처리기를 동시에 사용하기 위해서 상기 FPGA 기반 뉴로모픽 아키텍처 보드로 TCP 및 UDP 통신의 연결을 요청하는 전처리 과정을 수행하는, 이기종 뉴로모픽 아키텍처를 지원하기 위한 호스트 장치."}
{"patent_id": "10-2019-0152268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 제1 스텝 처리기는 UDP 통신을 이용하여 상기 학습 모델 프로그램의 실행을 위해 필요한 데이터를 송수신하는, 이기종 뉴로모픽 아키텍처를 지원하기 위한 호스트 장치."}
{"patent_id": "10-2019-0152268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 명령어 처리기는 SSH 통신의 SFTP(Secure File Transfer Protocol)를 통해 초기 설정 파일을 전송하는 명령어, 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 대한 자원을 확인하는 명령어 및 경로 설정파일(NAAL_script)에 설정된 학습 모델 프로그램을 실행하는 명령어를 송신하는, 이기종 뉴로모픽 아키텍처를 지원하기 위한 호스트 장치."}
{"patent_id": "10-2019-0152268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 공개특허 10-2021-0063762-3-상기 명령어 처리기는 상기 SSH 통신을 이용하여 전달되는 데이터 값들을 *.npz파일로 압축하여 한 번에 전달하는, 이기종 뉴로모픽 아키텍처를 지원하기 위한 호스트 장치."}
{"patent_id": "10-2019-0152268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 명령어 처리기는 TCP 통신을 이용하여 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 학습 모델 프로그램의 실행 및 종료 명령어를 전달하는, 이기종 뉴로모픽 아키텍처를 지원하기 위한 호스트 장치."}
{"patent_id": "10-2019-0152268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 설정파일(NAAL_config)은,호스트의 IP(ip), 상기 FPGA 기반 뉴로모픽 아키텍처 보드에서 수행한 weight, bias, encoder 값을 전달 받을경로(weight_path), 상기 FPGA 기반 뉴로모픽 아키텍처 보드의 IP(ip), 상기 FPGA 기반 뉴로모픽 아키텍처 보드의 SSH 포트(ssh_port), 상기 FPGA 기반 뉴로모픽 아키텍처 보드의 SSH 아이디(ssh_user), 상기 FPGA 기반 뉴로모픽 아키텍처 보드의 SSH 비밀번호(ssh_pwd), 상기 FPGA 기반 뉴로모픽 아키텍처 보드에서 모델 학습을 수행하는 파일(pes_network.py)의 경로 설정파일(NAAL_script), 학습 전처리 과정을 위한 임시 파일 경로(remote_tmp) 중 적어도 하나의 정보를 포함하는, 이기종 뉴로모픽 아키텍처를 지원하기 위한 호스트 장치."}
{"patent_id": "10-2019-0152268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 FPGA 기반 뉴로모픽 아키텍처 보드는 하나 이상의 보드를 포함하는, 이기종 뉴로모픽 아키텍처를 지원하기위한 호스트 장치."}
{"patent_id": "10-2019-0152268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 각 FPGA 기반 뉴로모픽 아키텍처 보드는,모델 학습에 필요한 데이터를 압축한 *.npz 파일과 뉴로모픽 아키텍처 보드에서 수행해야 할 스크립트의 경로를수신하여 레지스터 값을 설정하는 자원 관리기; 및매 스텝마다 모델 학습의 결과 데이터를 상기 제1 스텝 처리기로 송신하는 제2 스텝 처리기를 포함하는, 이기종뉴로모픽 아키텍처를 지원하기 위한 호스트 장치."}
{"patent_id": "10-2019-0152268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "FPGA 기반 뉴로모픽 아키텍처 보드와 이기종 IoT 환경에서 동작하기 위한 실행환경 설정파일(NAAL_config)을 분석하는 단계;상기 FPGA 기반 뉴로모픽 아키텍처 보드에 학습 모델 프로그램의 실행 및 종료 명령어를 전달하는 단계;상기 FPGA 기반 뉴로모픽 아키텍처 보드에 초기 설정 파일을 전송하는 명령어, 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 대한 자원을 확인하는 명령어 및 경로 설정파일(NAAL_script)에 설정된 학습 모델 프로그램을 실행하는 명령어를 송신하는 단계;상기 학습 모델 프로그램의 실행을 위해 필요한 데이터를 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 전달하는단계; 및상기 FPGA 기반 뉴로모픽 아키텍처 보드로부터 매 스텝마다 학습된 결과를 수신하는 단계;를 포함하는, 이기종공개특허 10-2021-0063762-4-뉴로모픽 아키텍처를 지원하기 위한 추상화 구조 설계 방법."}
{"patent_id": "10-2019-0152268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 학습 모델 실행을 위한 데이터 전처리 단계를 더 포함하는, 이기종 뉴로모픽 아키텍처를 지원하기 위한 추상화구조 설계 방법."}
{"patent_id": "10-2019-0152268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 학습 모델 실행을 위한 데이터 전처리 단계는,상기 설정파일(NAAL_config) 파일을 분석하여 학습을 수행할 FPGA 기반 뉴로모픽 아키텍처 보드의 정보와 학습모델 구동 제어를 위해 호스트에 대한 정보를 추출하는 단계;상기 학습 모델 구동에 필요한 데이터를 압축하는 단계;상기 설정파일(NAAL_config)의 학습 전처리 과정을 위한 임시 파일 경로(remote_tmp)에 설정된 경로로 SSH 통신을 이용하여 압축된 데이터 파일을 전송하는 단계; 및상기 FPGA 기반 뉴로모픽 아키텍처 보드로 TCP 및 UDP 통신의 연결을 요청하는 단계;를 포함하는, 이기종 뉴로모픽 아키텍처를 지원하기 위한 추상화 구조 설계 방법."}
{"patent_id": "10-2019-0152268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서, 상기 학습 모델 프로그램의 실행을 위해 필요한 데이터를 상기 FPGA 기반 뉴로모픽 아키텍처보드에 전달하는 단계 및 상기 FPGA 기반 뉴로모픽 아키텍처 보드로부터 매 스텝마다 학습된 결과를 수신하는단계는,UDP 통신을 이용하여 상기 학습 모델 프로그램의 실행을 위해 필요한 데이터를 송수신하는, 이기종 뉴로모픽 아키텍처를 지원하기 위한 추상화 구조 설계 방법."}
{"patent_id": "10-2019-0152268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서, 상기 학습 모델 프로그램을 실행하는 명령어를 송신하는 단계는, SSH 통신의 SFTP(Secure File TransferProtocol)를 통해 송신하는 데이터 값들을 *.npz 파일로 압축하여 한 번에 송신하고,상기 FPGA 기반 뉴로모픽 아키텍처 보드에 학습 모델 프로그램의 실행 및 종료 명령어를 전달하는 단계는, TCP통신을 이용하여 전달하는, 이기종 뉴로모픽 아키텍처를 지원하기 위한 추상화 구조 설계 방법."}
{"patent_id": "10-2019-0152268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,상기 이기종 뉴로모픽 아키텍처를 지원하기 위한 추상화 구조 설계 방법을 수행하기 위한 컴퓨터 프로그램이 기록된 컴퓨터로 판독 가능한 저장 매체."}
{"patent_id": "10-2019-0152268", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이기종 뉴로모픽 아키텍처를 지원하기 위한 호스트 장치는, FPGA 기반 뉴로모픽 아키텍처 보드와 이기종 IoT 환 경에서 동작하기 위한 실행환경 설정파일(NAAL_config)을 분석하는 파일 분석기; 상기 FPGA 기반 뉴로모픽 아키 텍처 보드에 학습 모델 프로그램의 실행 및 종료 명령어를 전달하고, 초기 설정 파일을 전송하는 명령어, 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 대한 자원을 확인하는 명령어 및 경로 설정파일(NAAL_script)에 설정된 학 습 모델 프로그램을 실행하는 명령어를 송신하는 명령어 처리기; 및 상기 학습 모델 프로그램의 실행을 위해 필 요한 데이터를 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 전달하고, 상기 FPGA 기반 뉴로모픽 아키텍처 보드로부 터 매 스텝마다 학습된 결과를 수신하는 제1 스텝 처리기를 포함한다. 이에 따라, 뉴로모픽 아키텍처 기반의 통 합개발환경을 위한 표준화를 이룰 수 있다."}
{"patent_id": "10-2019-0152268", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이기종 뉴로모픽 아키텍처를 지원하기 위한 추상화 구조 설계 방법, 이를 수행하기 위한 기록 매체 및 호스트 장치에 관한 것으로서, 더욱 상세하게는 다양한 이기종 뉴로모픽 아키텍처를 추상화하여 다양한 IoT 환경의 응용 서비스에 필요한 인공지능 모델을 효율적으로 학습시키고 활용할 수 있도록 지원하는 기술에 관한 것이다."}
{"patent_id": "10-2019-0152268", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 주목을 받고 있는 인공지능, 특히 딥러닝 기술은 이미지 분류 및 해석, 스타크래프트 등의 게임 분야에서 인간의 능력에 필적하는 성능을 보여주고 있다. 하지만, 이는 많은 계산량을 필요로 하기 때문에 고가의 GPU(또 는 이와 유사한 처리 장치, 예를 들어 구글의 TPU)를 여러 개 연결하여 사용하는 고사양 컴퓨팅 시스템을 요구 한다. 따라서, 인공지능 기술을 IoT 디바이스나 웨어러블 기기 등의 소형 디바이스에서도 사용하기 위해서는 기존의 인공 신경망 기반의 기술로는 한계가 있다. 뉴로모픽 아키텍처는 차세대 인공지능 반도체로서 연산이나 전력 면에서 매우 우수한 반도체로 여겨지고 있다. IBM은 2008년 DARPA의 SyNAPSE 프로젝트를 기반으로 2014년 TrueNorth라는 뉴로모픽 칩 개발하였다. 사람의 뇌 신경세포 구조와 기능을 모방한 TrueNorth는 256개의 뉴런을 갖는 코어를 4096개 연결한 형태로 기존 마이크로프로세서보다 10,000분의 1 수준의 초저전력 성능을 보여준다. 하지만, 2014년 발표 이후 개발 도구나 후속 연구 개발은 없다. 인텔은 가장 최근에 발표된 LIF(Leaky Integrate-and-Fire) 뉴런을 지원하는 유일한 하드웨어인 Loihi를 발표하 였다. 코어당 13만개의 뉴런을 구현하였으며, 칩 하나에 128개의 코어를 장착하여 총 1천6백만 개 정도의 뉴런 과 130만개의 시냅스로 이루어져 있다. 기존 하드웨어들은 LIF가 아니라 선형 모델 기반의 뉴런을 지원하는데, LIF가 훨씬 생물학적 뉴런에 가까운 모 델이다. USB형태의 소형 프로토타입을 발표할 예정이며, 일부 한정된 연구팀에게만 하드웨어 공개되고 있다. 뉴로모픽 아키텍처 기반의 소프트웨어 개발 패키지인 워털루대학의 Nengo와 AppliedBrainResearch은 파이썬 언 어를 사용한다. Nengo는 복잡한 스파이킹 및 비스파이킹 신경망의 시뮬레이션이 가능하다. 또한, 확장 가능하고 유연하게 설계되어 있기 때문에 다양한 뉴런 타입 및 학습 규칙을 추가할 수 있으며 하드 웨어로부터 바로 입력을 연결할 수 있어 다양한 응용에 활용될 수 있다. 신경망 기술을 위해 NEF를 사용하고 있으며, 백앤드로 인텔의 Loihi, SpiNNaker, AppliedBrainResarch의 FPGA 보드 등을 지원한다. IBM의 TrueNorth와 마찬가지로 선형 모델 기반의 뉴런을 지원한다. 인공지능을 적용하기 위한 다량의 데이터를 학습할 수 있는 고성능 대용량 서버와 그 데이터를 처리할 수 있는 슈퍼컴퓨터가 필요하다. 하지만, 뉴로모픽 아키텍처 보드라는 인공지능 반도체를 활용하면 저전력 IoT 환경에서 도 고성능 하드웨어의 지원 없이 학습을 수행할 수 있다. 소형 디바이스에 인공지능을 적용하기 위한 다량의 데이터를 학습할 수 있는 기술로 뉴로모픽 아키텍처가 매우 적절한 기술로 평가되고 있다. 뉴로모픽 아키텍처를 활용한 소프트웨어 플랫폼 및 개발 환경 구축이 필수적인데, 아직까지 뉴로모픽 아키텍처 기반의 통합개발환경을 위한 표준화는 전무한 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 2017-0068360 A (특허문헌 0002) KR 2016-0095856 A (특허문헌 0003) US 2018/0174045 A1"}
{"patent_id": "10-2019-0152268", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에, 본 발명의 기술적 과제는 이러한 점에서 착안된 것으로 본 발명의 목적은 소프트웨어의 개발 과정에서 이 기종 뉴로모픽 아키텍처를 지원하기 위한 호스트 장치를 제공하는 것이다. 본 발명의 다른 목적은 이기종 뉴로모픽 아키텍처를 지원하기 위한 추상화 구조 설계 방법을 제공하는 것이다. 본 발명의 또 다른 목적은 상기 이기종 뉴로모픽 아키텍처를 지원하기 위한 추상화 구조 설계 방법을 수행하기 위한 컴퓨터 프로그램이 기록된 기록 매체를 제공하는 것이다."}
{"patent_id": "10-2019-0152268", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 본 발명의 목적을 실현하기 위한 일 실시예에 따른 이기종 뉴로모픽 아키텍처를 지원하기 위한 호스트 장치는, FPGA 기반 뉴로모픽 아키텍처 보드와 이기종 IoT 환경에서 동작하기 위한 실행환경 설정파일 (NAAL_config)을 분석하는 파일 분석기; 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 학습 모델 프로그램의 실행 및 종료 명령어를 전달하고, 초기 설정 파일을 전송하는 명령어, 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 대 한 자원을 확인하는 명령어 및 경로 설정파일(NAAL_script)에 설정된 학습 모델 프로그램을 실행하는 명령어를 송신하는 명령어 처리기; 및 상기 학습 모델 프로그램의 실행을 위해 필요한 데이터를 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 전달하고, 상기 FPGA 기반 뉴로모픽 아키텍처 보드로부터 매 스텝마다 학습된 결과를 수신하는 제1 스텝 처리기를 포함한다. 본 발명의 실시예에서, 상기 파일 분석기는 상기 설정파일(NAAL_config) 파일을 분석하여 학습을 수행할 FPGA 기반 뉴로모픽 아키텍처 보드의 정보와 학습 모델 구동 제어를 위해 호스트에 대한 정보를 추출하고, 상기 명령 어 처리기는 모델 학습 구동에 필요한 데이터를 압축하고, 상기 설정파일(NAAL_config)의 학습 전처리 과정을 위한 임시 파일 경로(remote_tmp)에 설정된 경로로 SSH 통신을 이용하여 압축된 데이터 파일을 전송하고, 상기 명령어 처리기와 상기 제1 스텝 처리기를 동시에 사용하기 위해서 상기 FPGA 기반 뉴로모픽 아키텍처 보드로 TCP 및 UDP 통신의 연결을 요청하는 전처리 과정을 수행할 수 있다. 본 발명의 실시예에서, 상기 제1 스텝 처리기는 UDP 통신을 이용하여 상기 학습 모델 프로그램의 실행을 위해 필요한 데이터를 송수신할 수 있다. 본 발명의 실시예에서, 상기 명령어 처리기는 SSH 통신의 SFTP(Secure File Transfer Protocol)를 통해 초기 설정 파일을 전송하는 명령어, 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 대한 자원을 확인하는 명령어 및 경로 설정파일(NAAL_script)에 설정된 학습 모델 프로그램을 실행하는 명령어를 송신할 수 있다. 본 발명의 실시예에서, 상기 명령어 처리기는 상기 SSH 통신을 이용하여 전달되는 데이터 값들을 *.npz 파일로 압축하여 한 번에 전달할 수 있다. 본 발명의 실시예에서, 상기 명령어 처리기는 TCP 통신을 이용하여 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 학습 모델 프로그램의 실행 및 종료 명령어를 전달할 수 있다. 본 발명의 실시예에서, 상기 설정파일(NAAL_config)은, 호스트의 IP(ip), 상기 FPGA 기반 뉴로모픽 아키텍처 보 드에서 수행한 weight, bias, encoder 값을 전달 받을 경로(weight_path), 상기 FPGA 기반 뉴로모픽 아키텍처 보드의 IP(ip), 상기 FPGA 기반 뉴로모픽 아키텍처 보드의 SSH 포트(ssh_port), 상기 FPGA 기반 뉴로모픽 아키 텍처 보드의 SSH 아이디(ssh_user), 상기 FPGA 기반 뉴로모픽 아키텍처 보드의 SSH 비밀번호(ssh_pwd), 상기 FPGA 기반 뉴로모픽 아키텍처 보드에서 모델 학습을 수행하는 파일(pes_network.py)의 경로 설정파일 (NAAL_script), 학습 전처리 과정을 위한 임시 파일 경로(remote_tmp) 중 적어도 하나의 정보를 포함할 수 있다. 본 발명의 실시예에서, 상기 FPGA 기반 뉴로모픽 아키텍처 보드는 하나 이상의 보드를 포함할 수 있다. 본 발명의 실시예에서, 상기 각 FPGA 기반 뉴로모픽 아키텍처 보드는, 모델 학습에 필요한 데이터를 압축한 *.npz 파일과 뉴로모픽 아키텍처 보드에서 수행해야 할 스크립트의 경로를 수신하여 레지스터 값을 설정하는 자 원 관리기; 및 매 스텝마다 모델 학습의 결과 데이터를 상기 제1 스텝 처리기로 송신하는 제2 스텝 처리기를 포 함할 수 있다. 상기한 본 발명의 다른 목적을 실현하기 위한 일 실시예에 따른 이기종 뉴로모픽 아키텍처를 지원하기 위한 추 상화 구조 설계 방법은, FPGA 기반 뉴로모픽 아키텍처 보드와 이기종 IoT 환경에서 동작하기 위한 실행환경 설 정파일(NAAL_config)을 분석하는 단계; 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 학습 모델 프로그램의 실행 및 종료 명령어를 전달하는 단계; 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 초기 설정 파일을 전송하는 명령어, 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 대한 자원을 확인하는 명령어 및 경로 설정파일 (NAAL_script)에 설정된 학습 모델 프로그램을 실행하는 명령어를 송신하는 단계; 상기 학습 모델 프로그램의 실행을 위해 필요한 데이터를 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 전달하는 단계; 및 상기 FPGA 기반 뉴 로모픽 아키텍처 보드로부터 매 스텝마다 학습된 결과를 수신하는 단계;를 포함한다. 본 발명의 실시예에서, 상기 이기종 뉴로모픽 아키텍처를 지원하기 위한 추상화 구조 설계 방법은, 학습 모델 실행을 위한 데이터 전처리 단계를 더 포함할 수 있다. 본 발명의 실시예에서, 상기 학습 모델 실행을 위한 데이터 전처리 단계는, 상기 설정파일(NAAL_config) 파일을 분석하여 학습을 수행할 FPGA 기반 뉴로모픽 아키텍처 보드의 정보와 학습 모델 구동 제어를 위해 호스트에 대 한 정보를 추출하는 단계; 상기 학습 모델 구동에 필요한 데이터를 압축하는 단계; 상기 설정파일(NAAL_confi g)의 학습 전처리 과정을 위한 임시 파일 경로(remote_tmp)에 설정된 경로로 SSH 통신을 이용하여 압축된 데이 터 파일을 전송하는 단계; 및 상기 FPGA 기반 뉴로모픽 아키텍처 보드로 TCP 및 UDP 통신의 연결을 요청하는 단 계;를 포함할 수 있다. 본 발명의 실시예에서, 상기 학습 모델 프로그램의 실행을 위해 필요한 데이터를 상기 FPGA 기반 뉴로모픽 아키 텍처 보드에 전달하는 단계 및 상기 FPGA 기반 뉴로모픽 아키텍처 보드로부터 매 스텝마다 학습된 결과를 수신 하는 단계는, UDP 통신을 이용하여 상기 학습 모델 프로그램의 실행을 위해 필요한 데이터를 송수신할 수 있다. 본 발명의 실시예에서, 상기 학습 모델 프로그램을 실행하는 명령어를 송신하는 단계는, SSH 통신의 SFTP(Secure File Transfer Protocol)를 통해 송신하는 데이터 값들을 *.npz파일로 압축하여 한 번에 송수신할 수 있다. 본 발명의 실시예에서, 상기 FPGA 기반 뉴로모픽 아키텍처 보드에 학습 모델 프로그램의 실행 및 종료 명령어를 전달하는 단계는, TCP 통신을 이용하여 전달할 수 있다. 상기한 본 발명의 또 다른 목적을 실현하기 위한 일 실시예에 따른 컴퓨터로 판독 가능한 저장 매체에는, 이기 종 뉴로모픽 아키텍처를 지원하기 위한 추상화 구조 설계 방법을 수행하기 위한 컴퓨터 프로그램이 기록되어 있 다."}
{"patent_id": "10-2019-0152268", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이와 같은 이기종 뉴로모픽 아키텍처를 지원하기 위한 방법 및 호스트 장치에 따르면, 고성능 하드웨어의 지원 없이 크기가 작고 전력소비가 적은 뉴로모픽 칩셋을 사용하여 효율적인 학습이 가능하게 한다. 이는 사용자가 IoT 디바이스에서 학습하기 위해 기존의 서버를 통한 원격 실행을 하거나, 고성능 하드웨어를 연결해서 쓰지 않 고도 크기가 작고 저전력인 IoT 환경을 만들 수 있어 자원 제약적인 환경에서도 학습이 가능하게 한다."}
{"patent_id": "10-2019-0152268", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "후술하는 본 발명에 대한 상세한 설명은, 본 발명이 실시될 수 있는 특정 실시예를 예시로서 도시하는 첨부 도 면을 참조한다. 이들 실시예는 당업자가 본 발명을 실시할 수 있기에 충분하도록 상세히 설명된다. 본 발명의 다양한 실시예는 서로 다르지만 상호 배타적일 필요는 없음이 이해되어야 한다. 예를 들어, 여기에 기재되어 있 는 특정 형상, 구조 및 특성은 일 실시예에 관련하여 본 발명의 정신 및 범위를 벗어나지 않으면서 다른 실시예 로 구현될 수 있다. 또한, 각각의 개시된 실시예 내의 개별 구성요소의 위치 또는 배치는 본 발명의 정신 및 범 위를 벗어나지 않으면서 변경될 수 있음이 이해되어야 한다. 따라서, 후술하는 상세한 설명은 한정적인 의미로 서 취하려는 것이 아니며, 본 발명의 범위는, 적절하게 설명된다면, 그 청구항들이 주장하는 것과 균등한 모든 범위와 더불어 첨부된 청구항에 의해서만 한정된다. 도면에서 유사한 참조부호는 여러 측면에 걸쳐서 동일하거 나 유사한 기능을 지칭한다. 이하, 도면들을 참조하여 본 발명의 바람직한 실시예들을 보다 상세하게 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 이기종 뉴로모픽 아키텍처를 지원하기 위한 호스트 장치를 포함하는 전체 이기종 IoT 환경 시스템의 블록도이다. 도 2는 본 발명에서 사용하는 실행환경 설정파일(NAAL_config)의 구성요 소의 예를 보여주는 도표이다. 본 발명에 따른 이기종 뉴로모픽 아키텍처를 지원하기 위한 추상화 구조는 다양한 이기종 뉴로모픽 아키텍 처를 추상화하여 다양한 IoT 환경의 응용 서비스에 필요한 인공지능 모델을 효율적으로 학습시키고 활용할 수 있도록 지원한다. 본 발명에서는 이기종 뉴로모픽 아키텍처를 지원하는 추상화 구조를 Neuromorphic Architecture Abstract Layer(NAAL)로 정의한다. NAAL은 뉴로모픽 아키텍처 실행환경으로 하드웨어적으로 NAAL_HOST(라즈베리파이, 로 컬 PC 등)와 FPGA 기반 뉴로모픽 아키텍처 보드(PYNQ-Z1, DE1-SoC 등)로 구분된다. 따라서, NAAL를 호스트에 해당되는 NAAL_HOST와 FPGA 기반 뉴로모픽 아키텍처 보드에 해당되는 NAAL_FPGA로 모 듈을 나눠 설계하고 구현하였다. NAAL_HOST는 학습 모델 구동을 위해 필요한 데이터를 전송하고 학습 및 인식 결과를 전달 받는 것을 목표로 한다. NAAL_FPGA는 학습 모델을 구동하고 갱신된 학습 및 인식 결과를 전달하는 것을 목표로 한다. 도 1을 참조하면, 전체 이기종 IoT 환경 시스템에서 이기종 뉴로모픽 아키텍처를 지원하기 위한 추상화 구조 는 호스트 장치(100, NAAL_HOST 이하 호스트)와 한 개 이상의 FPGA 기반 뉴로모픽 아키텍처 보드(300, NAAL_FPGA 이하 보드)를 포함한다. 본 발명에 따른 호스트는 파일 분석기, 명령어 처리기 및 제1 스텝 처리기를 포함한다. 보 드는 각 모듈마다 자원 관리기(310, 350) 및 제2 스텝 처리기(330, 370)를 포함한다. 본 발명의 상기 호스트는 이기종 뉴로모픽 아키텍처를 지원하기 위한 소프트웨어(애플리케이션)가 설치되어 실행될 수 있으며, 상기 파일 분석기, 상기 명령어 처리기 및 상기 제1 스텝 처리기의 구성은 상기 호스트에서 실행되는 상기 이기종 뉴로모픽 아키텍처를 지원을 수행하기 위한 소프트웨어에 의해 제어 될 수 있다. 상기 호스트는 별도의 단말이거나 또는 단말의 일부 모듈일 수 있다. 또한, 상기 파일 분석기, 상기 명령어 처리기 및 상기 제1 스텝 처리기의 구성은 통합 모듈로 형성되거나, 하나 이상의 모듈로 이루 어 질 수 있다. 그러나, 이와 반대로 각 구성은 별도의 모듈로 이루어질 수도 있다. 상기 호스트는 이동성을 갖거나 고정될 수 있다. 상기 장치는, 디바이스(device), 기구(apparatus), 단 말(terminal), UE(user equipment), MS(mobile station), 무선기기(wireless device), 휴대기기(handheld device) 등 다른 용어로 불릴 수 있다. 예를 들어, 상기 호스트는 로컬 PC일 수 있다. 또한, 상기 보드 는 서버 또는 엔진 등 다른 용어로 불릴 수 있다. 상기 호스트 및 상기 보드는 운영체제(Operation System; OS), 즉 시스템을 기반으로 다양한 소프트웨 어를 실행하거나 제작할 수 있다. 상기 운영체제는 소프트웨어가 장치의 하드웨어를 사용할 수 있도록 하기 위한 시스템 프로그램으로서, 안드로이드 OS, iOS, 윈도우 모바일 OS, 바다 OS, 심비안 OS, 블랙베리 OS 등 모바 일 컴퓨터 운영체제 및 윈도우 계열, 리눅스 계열, 유닉스 계열, MAC, AIX, HP-UX 등 컴퓨터 운영체제를 모두 포함할 수 있다. 상기 호스트는 호스트 디바이스에 해당하는 모듈이다. 상기 호스트는 상기 보드에서 학습 모델 구 동을 위해 필요한 데이터들을 송수신하는 API를 설계하고 구현한다. 상기 호스트는 상기 보드와의 데이터 송수신을 위해 총 3개의 통신을 사용한다. 먼저, TCP 통신을 사 용하여 상기 보드에 학습 모델 구동의 시작 및 종료 명령어를 전달한다. 학습 모델의 구동 여부를 전달하 는 역할을 수행하기 때문에 상기 보드가 서버 역할을 담당한다. 두 번째로, 학습 모델 구동을 위해 필요한 데이터 값들을 SSH의 SFTP Secure File Transfer Protocol(SFTP)을 통해 전달한다. 여러 데이터 값들은 *.npz파일로 압축이 되어 한 번에 전달된다. 마지막으로, 학습 모델 구동을 시킨 후 인식 혹은 학습의 결과를 수신하기 위해 UDP 통신을 사용한다. 상기 보 드에서 학습의 매 스텝(step)마다 업데이트 된 결과를 전송한다. 상기 호스트는 업데이트된 학습 및 인식의 결과를 전달받아 사용자에게 전달한다. 상기 파일 분석기는 상기 보드와 이기종 IoT 환경에서 동작하기 위한 실행환경 설정파일 (NAAL_config)을 분석한다. NAAL 실행환경 설정을 위한 실행환경 설정파일(NAAL_config)의 구성요소에 대해 도 2에 도시하였다. 도 2를 참조하면, 호스트의 키 값으로, [host]의 IP(ip), 상기 보드에서 수행한 weight, bias, encoder 값을 전달 받을 경로(weight_path)를 포함한다. 또한, [pynq] or [de1]의 키 값으로, 상기 보드의 IP(ip), 상기 보드의 SSH 포트(ssh_port), 상기 보드의 SSH 아이디(ssh_user), 상기 보드의 SSH 비밀번호(ssh_pwd), 상기 보드에서 모델 학습 을 수행하는 파일(pes_network.py)의 경로 설정파일(NAAL_script), 학습 전처리 과정을 위한 임시 파일 경로 (remote_tmp)를 포함한다. 상기 명령어 처리기는 UDP 통신을 이용하여 모델 학습을 위해 필요한 데이터를 송수신한다. 여기서, 스텝 (step)이란 모델 학습을 수행할 데이터가 상기 보드에 전달되면 상기 보드에 설정된 Rectified Linear Unit(LeRu) 모델의 스파이킹 버전인 Spiking LeRU 모델을 통해 학습이 진행된 데이터를 상기 호스트(1 0)에 전달하는 과정을 의미한다. 입력 데이터는 사용자가 지정한 일정 시간동안 반복적으로 스텝을 수행하여 학습이 진행된다. 도 3은 상기 호스 트의 제1 스텝 처리기와 상기 보드의 제2 스텝 처리기의 동작 과정을 나타낸다. 도 3을 참조하면, 상기 호스트의 제1 스텝 처리기에서 학습 모델 실행을 위한 데이터를 전달하면 (S11), 상기 보드의 제2 스텝 처리기는 학습을 진행하고, 학습이 완료되면 Spiking LeRU의 학습 결과 데이터를 상기 호스트에 반환한다(S12). 상기 S11와 S12이 한 스텝이고, 지정된 시간동안 스텝을 반복적으로 수행하여 학습한다. 상기 보드는 PGA 기반 뉴로모픽 아키텍처 보드에 해당하는 모듈이다. 예를 들어, PYNQ-Z1와 DE1-SoC 보드 가 FPGA 기반 뉴로모픽 아키텍처 보드에 해당된다. 상기 보드는 자원 관리기 및 제2 스텝 처리기 를 포함한다. 상기 보드는 다수개로 형성될 수 있다. 상기 보드는 상기 호스트로부터 모델 학습에 필요한 데이터를 압축한 *.npz 파일과 상기 보드에 서 수행해야 할 스크립트의 경로를 수신 받아 뉴로모픽 아키텍처 보드의 레지스터 값을 설정한다. 상기 자원 관리기는 상기 호스트로부터 전송 받은 *.npz 파일의 데이터 값을 활용하여 모델 학습을 실 행 전의 레지스터 값과 학습 모델 관련 데이터를 초기화 한다. 또한, 상기 보드의 모델 학습이 종료되면 모델 학습에 사용되었던 자원을 반환하며, 다음 학습에 사용에 필요 없는 레지스터 값과 *.npz 파일과 같은 자 원을 삭제한다. 상기 제2 스텝 처리기는 매 스텝마다 모델 학습의 결과 데이터를 상기 호스트의 제1 스텝 처리기(15 0)로 송신한다. 도 4는 본 발명에서 수행되는 학습 모델 실행을 위한 데이터 전처리 과정을 보여주는 도면이다. 도 4를 참조하면, 상기 호스트의 파일 분석기는 외부 프로그램에서 NAAL_config 파일의 구성요소를 설 정하고 초기 모델 학습을 위한 데이터를 전송하면(S21), NAAL_config 파일을 분석하여 학습을 수행할 상기 보드 의 정보와 학습 모델을 구동 제어를 위해 호스트에 대한 정보를 추출한다. 또한, 상기 호스트는 모델 학습 구동에 필요한 데이터를 *.npz 파일로 압축하고, NAAL_config 파일의 remote_tmp에 설정된 경로에 SSH 통신으로 NAAL_FPGA에 *.npz 파일을 전송한다(S22). 이후, 상기 보드는 NAAL_config 파일의 NAAL_script에 설정된 파일을 실행한다. 상기 호스트는 상기 명령어 처리기 및 상기 제1 스텝 처리기를 동시에 사용하기 위해서 상기 보 드로 TCP 및 UDP 통신의 연결을 요청한다. 상기 보드는 수신한 *.npz 파일을 기반으로 모델 학습을 위해 사용될 정보들을 저장하고 상기 호스트와 통신하게 된다. 도 5는 본 발명에서 수행되는 전체적인 학습 구동 시나리오를 보여주는 도면이다. 도 5를 참조하면, 전처리 과정 이후, TCP 및 UDP 통신이 연결되면, 외부 프로그램이 NAAL_FPGA에서의 학습 모델 실행 명령어를 전송한다(S31). 상기 호스트의 명령어 처리기가 학습 모델 프로그램의 실행 명령어를 상기 보드에 전달하고(S32), 상기 호스트의 제1 스텝 처리기가 외부 프로그램으로부터 받은 학습 데이터를 상기 보드에 전송한다(S33). 상기 보드의 자원 관리기는 상기 호스트로부터 전송 받은 *.npz 파일의 데이터 값을 활용하여 모 델 학습을 실행 전의 레지스터 값과 학습 모델 관련 데이터를 초기화 한다. 상기 제2 스텝 처리기는 전달받은 데이터를 LeRu모델의 스파이킹 버전인 Spiking LeRU 모델에 적용하여 인 식 및 학습을 수행한다. 상기 제2 스텝 처리기에서 학습의 결과 데이터를 상기 호스트의 제1 스텝 처 리기에 전송하면 한 스텝이 처리된다. 이 과정을 반복하면서 PES 학습이 진행된다. 본 발명에 따른, NAAL은 고성능 하드웨어의 지원 없이 크기가 작고 전력소비가 적은 뉴로모픽 칩셋을 사용하여 효율적인 학습이 가능하게 한다. 이는 사용자가 IoT 디바이스에서 학습하기 위해 기존의 서버를 통한 원격 실행 을 하거나, 고성능 하드웨어를 연결해서 쓰지 않고도 크기가 작고 저전력인 IoT 환경을 만들 수 있어 자원 제약 적인 환경에서도 학습이 가능하게 한다. 이와 같은, 이기종 뉴로모픽 아키텍처를 지원하기 위한 추상화 구조 설계 방법은 애플리케이션으로 구현되거나 다양한 컴퓨터 구성요소를 통하여 수행될 수 있는 프로그램 명령어의 형태로 구현되어 컴퓨터 판독 가능한 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체는 프로그램 명령어, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판독 가능한 기록 매체에 기록되는 프로그램 명령어는 본 발명을 위하여 특별히 설계되고 구성된 것들이거니와 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD- ROM, DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 ROM, RAM, 플래시 메모리 등과 같은 프로그램 명령어를 저장하고 수행하도록 특별히 구성된 하드웨 어 장치가 포함된다. 프로그램 명령어의 예에는, 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사 용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함된다. 상기 하드웨어 장치는 본 발명에 따른 처 리를 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 이상에서는 실시예들을 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다. 산업상 이용가능성 본 발명은 다양한 이기종 뉴로모픽 아키텍처를 추상화하여 다양한 IoT 환경의 응용 서비스에 필요한 인공지능 모델을 효율적으로 학습시키고 활용할 수 있도록 지원할 수 있다.부호의 설명 1: 이기종 IoT 환경 시스템 10: 이기종 뉴로모픽 아키텍처를 지원하는 추상화 구조 100: 호스트 장치 110: 파일 분석기 130: 명령어 처리기 150: 제1 스텝 처리기 300: FPGA 기반 뉴로모픽 아키텍처 보드 310, 350: 자원 관리기 330, 370: 제2 스텝 처리기"}
{"patent_id": "10-2019-0152268", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 이기종 뉴로모픽 아키텍처를 지원하기 위한 호스트 장치를 포함하는 전체 이기종 IoT 환경 시스템의 블록도이다. 도 2는 본 발명에서 사용하는 실행환경 설정파일(NAAL_config)의 구성요소의 예를 보여주는 도표이다. 도 3은 본 발명에서 수행되는 모델 학습의 한 스텝(step)의 과정을 보여주는 도면이다.도 4는 본 발명에서 수행되는 학습 모델 실행을 위한 데이터 전처리 과정을 보여주는 도면이다. 도 5는 본 발명에서 수행되는 전체적인 학습 구동 시나리오를 보여주는 도면이다."}
