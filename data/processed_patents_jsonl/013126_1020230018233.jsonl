{"patent_id": "10-2023-0018233", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0121016", "출원번호": "10-2023-0018233", "발명의 명칭": "신경망 모델에 대한 정보를 제공하는 방법 및 이를 수행하는 전자 장치", "출원인": "주식회사 노타", "발명자": "김유찬"}}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "신경망 모델에 대한 정보를 제공하는 방법에 있어서,사용자 장치로부터 신경망 모델이 실행될 타겟 디바이스와 관련된 정보 및 상기 타겟 디바이스와 관련된 상기신경망 모델의 타겟 성능을 수신하는 단계; 및상기 타겟 디바이스에 대한 정보 및 상기 타겟 성능에 기초하여 획득된 복수의 후보 신경망 모델에 대한 정보를각각 포함하는 복수의 UI 엘리먼트를 표시하도록 상기 사용자 장치로 명령을 전송하는 단계;를 포함하고,상기 복수의 UI 엘리먼트는,사용자에 의해 설정된 입력 데이터의 크기를 기초로 획득된 복수의 제1 후보 신경망 모델에 각각 대응되는 제1UI 엘리먼트들, 및 상기 사용자에 의해 설정된 타겟 성능을 기초로 획득된 복수의 제2 후보 신경망 모델에 각각대응되는 제2 UI 엘리먼트들을 포함하고, 상기 제1 UI 엘리먼트들 및 상기 제2 UI 엘리먼트들은 서로 다른 영역에 표시되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 복수의 UI 엘리먼트는,상기 복수의 UI 엘리먼트 각각에 대응되는 후보 신경망 모델의 성능 및 상기 수신한 타겟 성능의 차이가 작은순서대로 표시되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 복수의 제1 후보 신경망 모델은,상기 복수의 후보 신경망 모델 중 입력 데이터의 크기가 상기 사용자에 의해 설정된 입력 데이터의 크기와 동일하고,상기 복수의 제2 후보 신경망 모델은,상기 복수의 후보 신경망 모델 중 상기 타겟 성능과의 성능 차이에 기초한 순위가 기설정된 순위 이상인 것을특징으로 하는, 방법."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 타겟 디바이스와 관련된 정보를 입력 받기 위한 제1 화면을 표시하도록 상기 사용자 장치로 명령을 전송하는 단계;를 더 포함하고,상기 제1 화면은,상기 타겟 디바이스를 선택하기 위한 제1 영역, 상기 타겟 디바이스에서 실행될 신경망 모델의 프레임 워크를 선택하기 위한 제2 영역, 및상기 타겟 디바이스가 지원하는 데이터 타입을 선택하기 위한 제3 영역을 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2023-0121016-3-제4 항에 있어서,상기 제2 영역에서 선택 가능한 프레임 워크, 또는 상기 제3 영역에서 선택 가능한 데이터 타입 중 적어도 하나는, 상기 제1 영역에서 상기 사용자가 선택한 타겟 디바이스를 기초로 결정되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4 항에 있어서,상기 제1 화면의 상기 제3 영역은,서로 다른 데이터 타입을 표시하는 제3 UI 엘리먼트들을 포함하고,상기 제3 UI 엘리먼트들은, 상기 사용자가 선택한 타겟 디바이스에 따라 개별적으로 활성화되거나 비활성화되어시각적으로 구별되도록 표시되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 획득하는 단계는,룩-업 테이블에 기초하여 상기 복수의 후보 신경망 모델에 대한 정보를 획득하되,상기 룩-업 테이블은,복수의 신경망 모델의 식별 정보, 상기 복수의 신경망 모델이 실행되는 복수의 디바이스에 대한 정보 및 상기복수의 디바이스에 대한 상기 복수의 신경망 모델의 성능 정보를 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "신경망 모델에 대한 정보를 제공하는 전자 장치에 있어서,적어도 하나의 회로를 포함하는 통신 인터페이스;적어도 하나의 인스트럭션을 저장하는 메모리; 및프로세서;를 포함하고,상기 프로세서는, 상기 적어도 하나의 인스트럭션을 실행함으로써,사용자 장치로부터 신경망 모델이 실행될 타겟 디바이스와 관련된 정보 및 상기 타겟 디바이스와 관련된 상기신경망 모델의 타겟 성능을 수신하고,상기 타겟 디바이스에 대한 정보 및 상기 타겟 성능에 기초하여 획득된 복수의 후보 신경망 모델에 대한 정보를각각 포함하는 복수의 UI 엘리먼트를 표시하도록 상기 사용자 장치로 명령을 전송하고,상기 복수의 UI 엘리먼트는,사용자에 의해 설정된 입력 데이터의 크기를 기초로 획득된 복수의 제1 후보 신경망 모델에 각각 대응되는 제1UI 엘리먼트들, 및 상기 사용자에 의해 설정된 타겟 성능을 기초로 획득된 복수의 제2 후보 신경망 모델에 각각대응되는 제2 UI 엘리먼트들을 포함하고, 상기 제1 UI 엘리먼트들 및 상기 제2 UI 엘리먼트들은 서로 다른 영역에 표시되는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 복수의 UI 엘리먼트는,상기 복수의 UI 엘리먼트 각각에 대응되는 후보 신경망 모델의 성능 및 상기 수신한 타겟 성능의 차이가 작은공개특허 10-2023-0121016-4-순서대로 표시되는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8 항에 있어서,상기 복수의 제1 후보 신경망 모델은,상기 복수의 후보 신경망 모델 중 입력 데이터의 크기가 상기 사용자에 의해 설정된 입력 데이터의 크기와 동일하고,상기 복수의 제2 후보 신경망 모델은,상기 복수의 후보 신경망 모델 중 상기 타겟 성능과의 성능 차이에 기초한 순위가 기설정된 순위 이상인 것을특징으로 하는, 전자 장치."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8 항에 있어서,상기 프로세서는,상기 타겟 디바이스와 관련된 정보를 입력 받기 위한 제1 화면을 표시하도록 상기 사용자 장치로 명령을 전송하고,상기 제1 화면은,상기 타겟 디바이스를 선택하기 위한 제1 영역, 상기 타겟 디바이스에서 실행될 신경망 모델의 프레임 워크를 선택하기 위한 제2 영역, 및상기 타겟 디바이스가 지원하는 데이터 타입을 선택하기 위한 제3 영역을 포함하는 것을 특징으로 하는, 전자장치."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 제2 영역에서 선택 가능한 프레임 워크, 또는 상기 제3 영역에서 선택 가능한 데이터 타입 중 적어도 하나는, 상기 제1 영역에서 상기 사용자가 선택한 타겟 디바이스를 기초로 결정되는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11 항에 있어서,상기 제1 화면의 상기 제3 영역은,서로 다른 데이터 타입을 표시하는 제3 UI 엘리먼트들을 포함하고,상기 제3 UI 엘리먼트들은, 상기 사용자가 선택한 타겟 디바이스에 따라 개별적으로 활성화되거나 비활성화되어시각적으로 구별되도록 표시되는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8 항에 있어서,상기 프로세서는,룩-업 테이블에 기초하여 상기 복수의 후보 신경망 모델에 대한 정보를 획득하되,상기 룩-업 테이블은,복수의 신경망 모델의 식별 정보, 상기 복수의 신경망 모델이 실행되는 복수의 디바이스에 대한 정보 및 상기복수의 디바이스에 대한 상기 복수의 신경망 모델의 성능 정보를 포함하는 것을 특징으로 하는, 전자 장치.공개특허 10-2023-0121016-5-청구항 15 사용자 장치에서 신경망 모델의 정보를 표시하는 방법에 있어서,신경망 모델이 실행될 타겟 디바이스와 관련된 정보를 입력받는 적어도 하나의 제1 UI 엘리먼트 및 상기 타겟디바이스와 관련된 상기 신경망 모델의 타겟 성능을 입력받는 제2 UI 엘리먼트를 디스플레이에 표시하는 단계;및상기 적어도 하나의 제1 UI 엘리먼트 및 상기 제2 UI 엘리먼트를 통해 사용자가 입력한 정보를 기초로 획득된복수의 후보 신경망 모델의 정보를 포함하는 복수의 UI 엘리먼트를 상기 디스플레이에 표시하는 단계;를 포함하고, 상기 복수의 UI 엘리머트는,사용자에 의해 설정된 입력 데이터의 크기를 기초로 획득된 복수의 제1 후보 신경망 모델에 각각 대응되는 제3UI 엘리먼트들, 및 상기 사용자에 의해 설정된 타겟 성능을 기초로 획득된 복수의 제2 후보 신경망 모델에 각각대응되는 제4 UI 엘리먼트들을 포함하고, 상기 제3 UI 엘리먼트들 및 상기 제4 UI 엘리먼트들은 상기 디스플레이의 서로 다른 영역에 표시되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서,상기 복수의 UI 엘리먼트는,상기 복수의 UI 엘리먼트 각각에 대응되는 후보 신경망 모델의 성능 및 상기 수신한 타겟 성능의 차이가 작은순서대로 표시되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15 항에 있어서,상기 복수의 제1 후보 신경망 모델은,상기 복수의 후보 신경망 모델 중 입력 데이터의 크기가 상기 사용자에 의해 설정된 입력 데이터의 크기와 동일하고,상기 복수의 제2 후보 신경망 모델은,상기 복수의 후보 신경망 모델 중 상기 타겟 성능과의 성능 차이에 기초한 순위가 기설정된 순위 이상인 것을특징으로 하는, 방법."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15 항에 있어서,상기 적어도 하나의 제1 UI 엘리먼트는,상기 타겟 디바이스를 선택하기 위한 제5 UI 엘리먼트, 상기 타겟 디바이스에서 실행될 신경망 모델의 프레임 워크를 선택하기 위한 제6 UI 엘리먼트, 및상기 타겟 디바이스가 지원하는 데이터 타입을 선택하기 위한 제7 UI 엘리먼트들을 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18 항에 있어서,상기 제6 UI 엘리먼트에서 선택 가능한 프레임 워크, 또는 상기 제7 UI 엘리먼트들에서 선택 가능한 데이터 타입 중 적어도 하나는, 공개특허 10-2023-0121016-6-상기 제5 UI 엘리먼트에서 상기 사용자가 선택한 타겟 디바이스를 기초로 결정되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0018233", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18 항에 있어서,상기 제7 UI 엘리먼트들은,서로 다른 데이터 타입을 표시하고,상기 사용자가 선택한 타겟 디바이스에 따라 개별적으로 활성화되거나 비활성화되어 시각적으로 구별되도록 표시되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0018233", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "신경망 모델에 대한 정보를 제공하는 방법이 개시된다. 방법은, 외부 장치로부터 신경망 모델이 실행될 타겟 디 바이스에 대한 정보 및 타겟 디바이스에 대한 신경망 모델의 타겟 성능을 수신하는 단계, 타겟 디바이스에 대한 정보 및 수신한 타겟 성능에 기초하여 복수의 후보 신경망 모델에 대한 정보를 획득하는 단계, 및 수신한 타겟 성능에 기초하여 복수의 후보 신경망 모델에 대한 정보를 표시하도록 외부 장치로 명령을 전송하는 단계를 포함 한다."}
{"patent_id": "10-2023-0018233", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 신경망 모델에 대한 정보를 제공하는 방법 및 이를 수행하는 전자 장치에 관한 것이다."}
{"patent_id": "10-2023-0018233", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술의 확산에 따라 인공지능 모델을 필요로 하는 사용자가 타겟 디바이스에서 인공지능 모델을 구동 시키려는 니즈가 증가하고 있다. 전 세계적으로 다양한 인공지능 모델이 공개되고 있지만, 사용자가 자신이 원 하는 성능을 갖는 인공지능 모델을 직접 찾는 것은 쉽지 않은 일이다. 또한, 사용자가 SOTA(State-of-the-art) 모델과 같은 성능이 우수한 모델을 찾았다 하더라도, 해당 모델이 타겟 디바이스에서 반드시 구동가능한 것은 아니다. 때문에, 사용자 입장에서는 해당 모델이 타겟 디바이스에서 구동가능한 지 알아봐야 하는 번거로움이 있다. 따라서, 사용자가 편리하게 타겟 디바이스에 최적화된 신경망 모델을 얻을 수 있도록 하는 기술에 대한 필요성 이 대두된다."}
{"patent_id": "10-2023-0018233", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 일 기술적 과제는, 타겟 디바이스에 최적화된 신경망 모델을 제공하는 전자 장치를 제공하는 것이다. 본 발명이 해결하고자 하는 일 기술적 과제는, 사용자가 입력한 데이터셋에 기초하여 학습된 신경망 모델을 제 공하는 전자 장치를 제공하는 것이다. 본 발명이 해결하고자 하는 일 기술적 과제는, 사용자가 설정한 타겟 성능과 유사한 성능을 갖는 신경망 모델을 제공하는 전자 장치를 제공하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적"}
{"patent_id": "10-2023-0018233", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "과제들은 아래의 기재로부터 본 발명의 기술분야에서의 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0018233", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 해결하기 위한 본 개시의 예시적인 일 실시 예에 따르면, 신경망 모델에 대한 정보를 제 공하는 방법에 있어서, 외부 장치로부터 신경망 모델이 실행될 타겟 디바이스에 대한 정보 및 상기 타겟 디바이 스에 대한 상기 신경망 모델의 타겟 성능을 수신하는 단계; 상기 타겟 디바이스에 대한 정보 및 상기 수신한 타 겟 성능에 기초하여 복수의 후보 신경망 모델에 대한 정보를 획득하는 단계; 및 상기 수신한 타겟 성능에 기초 하여 상기 복수의 후보 신경망 모델에 대한 정보-상기 복수의 후보 신경망 모델에 대한 정보는, 상기 복수의 후 보 신경망 모델의 명칭, 상기 복수의 후보 신경망 모델의 성능 또는 상기 복수의 후보 신경망 모델의 입력 데이 터의 크기 중 적어도 하나를 포함함-를 표시하도록 상기 외부 장치로 명령을 전송하는 단계;를 포함하는 방법이 제공될 수 있다.상술한 기술적 과제를 해결하기 위한 본 개시의 예시적인 일 실시 예에 따르면, 신경망 모델에 대한 정보를 제 공하는 전자 장치에 있어서, 적어도 하나의 회로를 포함하는 통신 인터페이스; 적어도 하나의 인스트럭션을 저 장하는 메모리; 및 프로세서;를 포함하고, 상기 프로세서는, 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 통신 인터페이스를 통해 외부 장치로부터 신경망 모델이 실행될 타겟 디바이스에 대한 정보 및 상기 타겟 디바이스에 대한 상기 신경망 모델의 타겟 성능을 수신하고, 상기 타겟 디바이스에 대한 정보 및 상기 수신한 타겟 성능에 기초하여 복수의 후보 신경망 모델에 대한 정보를 획득하고, 상기 수신한 타겟 성능에 기초하여 상 기 복수의 후보 신경망 모델에 대한 정보-상기 복수의 후보 신경망 모델에 대한 정보는, 상기 복수의 후보 신경 망 모델의 명칭, 상기 복수의 후보 신경망 모델의 성능 또는 상기 복수의 후보 신경망 모델의 입력 데이터의 크 기 중 적어도 하나를 포함함-를 표시하도록 상기 외부 장치로 명령을 전송하도록 상기 통신 인터페이스를 제어 하는 전자 장치가 제공될 수 있다."}
{"patent_id": "10-2023-0018233", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 개시의 과제의 해결 수단이 상술한 해결 수단들로 제한되는 것은 아니며, 언급되지 아니한 해결 수단들은 본"}
{"patent_id": "10-2023-0018233", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "명세서 및 첨부된 도면으로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0018233", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상과 같은 본 개시의 다양한 실시 예에 따르면, 타겟 디바이스 최적화된 신경망 모델을 제공할 수 있다. 이상과 같은 본 개시의 다양한 실시 예에 따르면, 사용자가 입력한 데이터셋에 기초하여 학습되며 사용자가 설 정한 타겟 성능과 유사한 성능을 갖는 신경망 모델을 제공할 수 있다. 이에 따라, 사용자 편의성 및 만족감이 향상될 수 있다. 그 외에 본 개시의 실시 예로 인하여 얻을 수 있거나 예측되는 효과에 대해서는 본 개시의 실시 예에 대한 상세 한 설명에서 직접적 또는 암시적으로 개시하도록 한다. 예컨대, 본 개시의 실시 예에 따라 예측되는 다양한 효 과에 대해서는 후술될 상세한 설명 내에서 개시될 것이다. 본 개시의 다른 양상, 이점 및 두드러진 특징들은 첨부된 도면과 관련하여 본 발명의 다양한 실시 예들을 개시 하는 다음의 상세한 설명으로부터 당업자에게 명백해질 것이다."}
{"patent_id": "10-2023-0018233", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 개시의 실시 예들은 다양한 변환을 가할 수 있고 여러 가지 실시 예를 가질 수 있는바, 특정 실시 예들을 도 면에 예시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나 이는 특정한 실시 형태에 대해 범위를 한정하 려는 것이 아니며, 개시된 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이 해되어야 한다. 실시 예들을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들은 용어들에 의해 한정되 어서는 안 된다. 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또 는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해 서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를붙였다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 도면이다. *도 1을 참조하면, 전자 장치는 데이터셋, 타겟 디바이스에 대한 정보 및 학습 모드를 기초로 프로젝트를 정의할 수 있다. 프로젝트는 타겟 디바이스에 최적화된 신경망 모델을 획득하기 위한 업무 유닛을 의미할 수 있다. 전자 장치는 프로젝트를 수행하여 최적화된 신경망 모델을 획득할 수 있다. 전자 장치는 최적화된 신경망 모델을 사용자에게 제공할 수 있다. 데이터셋은 신경망 모델의 학습에 이용된 각종 데이터를 포함할 수 있다. 예를 들어, 데이터셋은 신경망 모델의 학습에 이용되는 트레이닝 데이터, 신경망 모델의 학습이 진행되는 동안 신경망 모델 의 성능을 평가하는 데 이용되는 밸리데이션 데이터, 및 신경망 모델의 학습이 완료된 후 신경망 모델 의 성능을 평가하는 데 이용되는 테스트 데이터를 포함할 수 있다. 타겟 디바이스에 대한 정보는 타겟 디바이스와 관련된 각종 정보를 포함할 수 있다. 타겟 디바이스에 대한 정보는 타겟 디바이스의 모델 정보 및 타겟 디바이스의 소프트웨어를 포함할 수 있다. 학습 모드는 제1 학습 모드, 제2 학습 모드 및 제3 학습 모드를 포함할 수 있다. 제1 학습 모드는, 미리 저 장된 복수의 베이스 모델 중 사용자에 의해 선택된 모델을 학습시키는 모드이다. 제2 학습 모드는, 기정의된 알 고리즘을 기초로 획득된 모델을 학습시키는 모드이다. 제3 학습 모드는, 제1 학습 모드 또는 제2 학습 모드에서 학습된 모델을 재학습시키는 모드이다. 전자 장치는 데이터셋, 타겟 디바이스에 대한 정보, 학습 모드 및 신경망 모델에 대한 정 보를 기초로 프로젝트를 정의할 수 있다. 신경망 모델에 대한 정보는, 신경망 모델의 프레임 워크, 출력 데이터 타입(예로, 32비트 부동소수점) 및 추론 배치 사이즈(inference batch size)를 포함할 수 있다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 도시한 블록도이다. 도 2를 참조하면, 전자 장치는 통신 인터페이스, 메모리 및 프로세서를 포함할 수 있다. 예로, 전자 장치는 물리적 서버 또는 클라우드 서버로 구현될 수 있다. 통신 인터페이스는 적어도 하나의 통신 회로를 포함하며, 다양한 유형의 외부 장치와 통신을 수행할 수 있 다. 예를 들어, 통신 인터페이스는 외부 장치로부터 데이터셋 및 타겟 디바이스에 대한 정보를 수신할 수 있다. 외부 장치는 사용자 장치일 수 있다. 사용자 장치는, 개인용 컴퓨터 및 모바일 장치를 포함할 수 있다. 통신 인터페이스는 타겟 디바이스에 대한 정보에 기초하여 서치된 복수의 베이스 모델에 대한 정보를 외부 장치로 전송할 수 있다. 이에 따라, 외부 장치는 복수의 베이스 모델에 대한 정보를 출력할 수 있다. 통신 인터 페이스는 외부 장치로부터 복수의 베이스 모델 중 적어도 하나의 베이스 모델을 선택하는 사용자 명령을 수신할 수 있다. 통신 인터페이스는 선택된 적어도 하나의 베이스 모델 및 데이터셋을 외부 서버로 전송할 수 있다. 외부 서버는 데이터셋을 이용하여 선택된 적어도 하나의 베이스 모델을 학습시켜 학습된 신경망 모델(또는 학습된 모 델)을 획득할 수 있다. 통신 인터페이스는 외부 서버로부터 학습된 모델을 수신할 수 있다. 통신 인터페이스는 학습된 모델을 외부 장치로 전송할 수 있다. 통신 인터페이스는 학습된 모델에 대 한 정보를 외부 장치로 전송할 수 있다. 학습된 모델에 대한 정보는, 학습된 모델의 이름, 학습된 모델이 수행 하는 태스크, 학습된 모델에 대응되는 타겟 디바이스에 대한 정보 및 학습된 모델의 성능(예로, 정확도, 레이턴 시)을 포함할 수 있다. 한편, 본 개시에서 신경망 모델을 획득/저장/전송/수신/한다는 것은, 모델과 관련된 데 이터(예로, 아키텍처, 가중치)를 획득/저장/전송/수신한다는 것을 의미한다. 통신 인터페이스는 와이파이 통신 모듈, 셀룰러 통신모듈, 3G(3세대) 이동통신 모듈, 4G(4세대) 이동통신 모듈, 4세대 LTE(Long Term Evolution) 통신 모듈, 5G(5세대) 이동통신 모듈 및 유선 이더넷(Ethernet) 중 적 어도 하나를 포함할 수 있다. 메모리는 전자 장치의 구성요소들의 전반적인 동작을 제어하기 위한 운영체제(OS: Operating System) 및 전자 장치의 구성요소와 관련된 명령 또는 데이터를 저장할 수 있다. 메모리는 비휘발성 메모리(ex: 하드 디스크, SSD(Solid state drive), 플래시 메모리) 또는 휘발성 메모리 등으로 구현될 수 있다. 메모리는 데이터베이스를 포함할 수 있다. 예를 들어, 메모리는 데이터셋을 저장하는 데이터셋 DB를 포함할 수 있다. 메모리는 프로젝트를 저장하는 프로젝트 DB를 포함할 수 있다. 메모리는 학습된 모 델을 저장하는 모델 DB를 포함할 수 있다. 데이터베이스에 저장된 정보는 사용자에게 제공될 수 있다. 예를 들 어, 데이터셋 리스트, 프로젝트 리스트 및/또는 모델 리스트는 외부 장치에 표시될 수 있다. 메모리는 복수의 신경망 모델에 대한 정보를 저장할 수 있다. 예를 들어, 메모리는 복수의 신경망 모 델의 식별 정보, 타겟 디바이스에 대한 정보 및 복수의 신경망 모델의 성능 정보가 매칭된 룩-업 테이블을 저장 할 수 있다. 복수의 신경망 모델의 성능 정보는, 타겟 디바이스에서 실행될 때 복수의 신경망 모델 각각의 성능 (예로, 레이턴시)을 반영할 수 있다. 타겟 디바이스에 대한 신경망 모델의 성능이란, 타겟 디바이스에서 실행될 때 신경망 모델의 성능을 의미할 수 있다. 신경망 모델의 레이턴시는 디바이스 팜(farm)으로부터 획득될 수 있 다. 신경망 모델의 정확도는 테스트 데이터를 이용하여 획득될 수 있다. 메모리는 베이스 모델을 서치하기 위한 기정의된 알고리즘을 저장할 수 있다. 기정의된 알고리즘은, 하이 퍼파라미터 최적화(Hyperparameter Optimization) 알고리즘 또는 신경망 아키텍처 탐색(Neural Architecture Search) 알고리즘 중 적어도 하나를 포함할 수 있다. 하이퍼파라미터 최적화 알고리즘은, TPE(tree-structured parzen estimator) 알고리즘을 포함할 수 있다. TPE 알고리즘은 베이지안 최적화(Bayesian optimization)에 기 초할 수 있다. 신경망 아키텍처 탐색 알고리즘은, 진화 알고리즘에 기초할 수 있다. 프로세서는 메모리와 전기적으로 연결되어 전자 장치의 전반적인 기능 및 동작을 제어할 수 있 다. 프로세서는 메모리에 저장된 인스트럭션을 실행함으로써 전자 장치를 제어할 수 있다. 예를 들어, 프로세서는 데이터셋, 타겟 디바이스에 대한 정보 및 학습 모드를 획득할 수 있다. 프로세서 는 통신 인터페이스를 통해 외부 장치로부터 데이터셋, 타겟 디바이스에 대한 정보 및 학습 모드를 수신할 수 있다. 데이터셋, 타겟 디바이스에 대한 정보 및 학습 모드는 외부 장치에 사용자에 의해 입력될 수 있다. 프로세서는 데이터셋의 포맷이 기설정된 포맷인 지 식별할 수 있다. 데이터셋의 포맷이 기설정된 포맷이 아니면, 프로세서는 데이터셋의 포맷을 기설정된 포맷으로 변환할 수 있다. 프로세서는 포맷이 변환 된 데이터셋을 메모리에 저장할 수 있다. 기설정된 포맷은, YOLO(You only look once)를 포함할 수 있다. 프로세서는 데이터셋, 타겟 디바이스에 대한 정보 및 학습 모드에 기초하여 프로젝트를 설정할 수 있다. 프로젝트는, 타겟 디바이스에 최적화된 학습된 신경망 모델을 획득하기 위한 업무 유닛을 의미할 수 있다. 예를 들어, 프로세서는 제1 데이터셋, 제1 타겟 디바이스에 대한 정보 및 제1 학습 모드에 기초하여 제1 프로젝 트를 설정할 수 있다. 프로세서는 제2 데이터셋, 제2 타겟 디바이스에 대한 정보 및 제2 학습 모드에 기초 하여 제2 프로젝트를 설정할 수 있다. 프로세서는 제3 데이터셋, 제3 타겟 디바이스에 대한 정보 및 제3 학습 모드에 기초하여 제3 프로젝트를 설정할 수 있다. 프로세서는 프로젝트를 수행하여 신경망 모델을 획득할 수 있다. 예를 들어, 프로세서는 제1 프로젝 트를 수행할 수 있다. 이 때, 프로세서는 타겟 디바이스에 대한 정보 및 사용자가 설정한 타겟 성능에 기 초하여 복수의 베이스 모델을 식별할 수 있다. 예를 들어, 프로세서는 메모리에 저장된 룩-업 테이블 에 기초하여 복수의 베이스 모델을 식별할 수 있다. 룩-업 테이블에서 복수의 신경망 모델의 식별 정보, 타겟 디바이스에 대한 정보 및 복수의 신경망 모델의 성능 정보가 매칭되어 있을 수 있다. 복수의 신경망 모델의 성 능 정보는, 타겟 디바이스에서 실행될 때 복수의 신경망 모델 각각의 성능(예로, 레이턴시)을 반영할 수 있다. 프로세서는 디바이스 팜(farm)으로부터 복수의 신경망 모델 각각의 성능을 획득할 수 있다. 또는, 프로세 서는 디바이스 팜을 이용하여 복수의 신경망 모델 중 일부의 성능을 획득하고, 레이턴시를 예측하도록 학 습된 신경망 모델을 이용하여 복수의 신경망 모델 중 나머지 일부의 성능을 획득할 수 있다. 제1 프로젝트를 수행할 때 프로세서는, 룩-업 테이블에 기초하여 타겟 디바이스에 대응되며 타겟 성능과의 성능 차이가 기설정된 범위 이내인 신경망 모델을 베이스 모델로 식별할 수 있다. 예를 들어, 프로세서는 타겟 레이턴시와의 차이가 0.1초 이내인 복수의 베이스 모델을 식별할 수 있다. 프로세서는 복수의 베이스 모델에 대한 정보를 외부 장치로 전송하도록 통신 인터페이스를 제어할 수 있다. 외부 장치는 복수의 베이스 모델에 대한 정보를 사용자에게 제공할 수 있다. 예를 들어, 복수의 베이스 모델에 대한 정보는, 복수의 베이스 모델 각각의 식별 정보(예로, 모델 명칭), 레이턴시, 입력 데이터의 크기를 포함할 수 있다. 외부 장치는 복수의 베이스 모델 중 제1 베이스 모델을 선택하는 사용자 명령을 획득할 수 있다. 프로세서는 통신 인터페이스를 통해 외부 장치로부터 사용자 명령을 수신할 수 있다. 프로세서는 제1 베이스 모델 및 제1 데이터셋을 외부 서버로 전송하도록 통신 인터페이스를 제어할 수 있다. 또한, 프로세서는 제1 베이스 모델에 대한 학습 설정 정보를 외부 서버로 전송하도록 통신 인터 페이스를 제어할 수 있다. 학습 설정 정보는, 학습된 모델의 입력 데이터의 크기(예로, 입력 이미지의 해 상도), 트레이닝 에포크(training epoch), 데이터 어그멘테이션(data augmentation)을 포함할 수 있다. 외부 서버는 학습 설정 정보에 기초하여 제1 데이터셋을 이용하여 제1 베이스 모델을 학습시켜 제1 학습된 모델을 획 득할 수 있다. 프로세서는 외부 서버로부터 제1 학습된 모델을 수신할 수 있다. 프로세서는 제2 프로젝트를 수행할 수 있다. 이 때, 프로세서는 기정의된 알고리즘에 기초하여 복수 의 베이스 모델을 획득할 수 있다. 프로세서는 복수의 베이스 모델에 대한 정보를 외부 장치로 전송하도록 통신 인터페이스를 제어할 수 있다. 외부 장치는 복수의 베이스 모델에 대한 정보를 사용자에게 제공할 수 있다. 외부 장치는 복수의 베이스 모델 중 복수의 제2 베이스 모델을 선택하는 사용자 명령을 획득할 수 있다. 또는, 프로세서는 사용자가 설정한 타겟 성능에 기초하여 복수의 베이스 모델 중 복수의 제2 베이스 모델 을 선택할 수 있다. 예컨대, 프로세서는 사용자가 설정한 타겟 정확도 범위 및 타겟 레이턴시 범위 이내의 성능을 갖는 복수의 제2 베이스 모델을 선택할 수 있다. 프로세서는 복수의 제2 베이스 모델, 제2 데이터셋 및 학습 설정 정보를 외부 서버로 전송하도록 통신 인 터페이스를 제어할 수 있다. 외부 서버는 학습 설정 정보에 기초하여 제2 데이터셋을 이용하여 복수의 제2 베이스 모델 각각을 학습시켜 복수의 제2 학습된 모델을 획득할 수 있다. 프로세서는 외부 서버로부터 복 수의 제2 학습된 모델을 수신할 수 있다. 프로세서는 제3 프로젝트를 수행할 수 있다. 프로세서는 제1 프로젝트 또는 제2 프로젝트를 수행한 이후에 제3 프로젝트를 수행할 수 있다. 예를 들어, 프로세서는 제1 프로젝트를 수행한 이후에 제3 프로젝 트를 수행할 수 있다. 프로세서는 제1 학습된 모델의 재학습을 위한 제3 데이터셋 및 재학습 설정 정보를 외부 서버로 전송하도록 통신 인터페이스를 제어할 수 있다. 외부 서버는 재학습 설정 정보에 기초하여 제 3 데이터셋을 이용하여 제1 베이스 모델을 학습시켜 제3 학습된 모델을 획득할 수 있다. 프로세서는 외부 서버로부터 제3 학습된 모델을 수신할 수 있다. 한편, 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서(13 0)는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프 로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하 드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은 학습을 통해 만들어질 수 있다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수 의 가중치들은 인공지능 모델의 학습 결과에 의해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델 에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN: Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), GAN (Generative Adversarial Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network),BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 도 3은 본 개시의 일 실시 예에 따른 제1 프로젝트를 수행하는 방법을 설명하기 위한 도면이다. 도 3을 참조하면, 전자 장치는 데이터셋, 타겟 디바이스에 대한 정보 및 사용자에 의해 설정된 타 겟 레이턴시를 획득할 수 있다. 예를 들어, 타겟 디바이스에 대한 정보는 제1 디바이스(T1)를 지시할 수 있다. 타겟 레이턴시는 500ms일 수 있다. 전자 장치는 타겟 디바이스에 대한 정보 및 타겟 레이턴시를 룩-업 테이블과 비교할 수 있다. 룩-업 테이블은 모델 명칭, 타겟 디바이스의 명칭, 모델에 입력되는 이미지의 해상도, 모델이 타겟 디바이 스에서 실행될 때의 레이턴시를 포함할 수 있다. 전자 장치는 룩-업 테이블을 참조하여 타겟 디바이스 에 대한 정보에 대응되며 타겟 레이턴시와의 차이가 기설정된 범위(예로, 100ms) 이내인 모델을 식별할 수 있다. 예를 들어, 전자 장치는 제1 디바이스(T1)에 대응되는 제1 모델(M1) 및 제2 모델(M2)을 식별할 수 있다. 전자 장치는 제1 모델(M1) 및 제2 모델(M2)에 대한 정보를 포함하는 베이스 모델 리스트를 사용자에게 제공할 수 있다. 예를 들어, 베이스 모델 리스트은 사용자 장치에 표시될 수 있다. 사용자는 베이스 모델 리스트에 포함된 복수의 베이스 모델 중 제1 베이스 모델을 선택할 수 있다. 전자 장치는 데이터 셋 및 제1 베이스 모델에 기초하여 제1 학습된 모델을 획득할 수 있다. 한편, 도 3에서는 룩-업 테이블에 3 개의 정보(즉, 모델 명칭, 타겟 디바이스의 명칭, 모델에 입력되는 이 미지의 해상도)의 조합별로 레이턴시가 기록되어 있는 것으로 도시하였다. 다만 이는 일 실시 예에 불과하며, 룩-업 테이블에는 추가적인 정보의 조합에 대한 레이턴시가 기록될 수 있다. 예를 들어, 상기 3 개의 정보 에 더하여, 배치 사이즈(batch size), 프레임 워크, 모델의 데이터 타입의 조합별로 레이턴시가 기록될 수 있다. 도 3에서는 타겟 레이턴시에 기초하여 베이스 모델 리스트를 획득하는 방법을 설명하였다. 다만 이에 한정되는 것은 아니며 전자 장치는 다양한 유형의 성능 지표에 기초하여 베이스 모델 리스트를 획득할 수 있다. 예를 들어, 전자 장치는 정확도, 전력 소비량 및/또는 메모리 사용량에 기초하여 베이스 모델 리 스트를 획득할 수 있다. 도 4는 본 개시의 일 실시 예에 따른 제2 프로젝트를 수행하는 방법을 설명하기 위한 도면이다. 도 4를 참조하면, 전자 장치는 데이터셋, 타겟 디바이스에 대한 정보 및 기정의된 알고리즘을 획득할 수 있다. 전자 장치는 타겟 디바이스에 대한 정보 및 기정의된 알고리즘에 기초하여 복수 의 베이스 모델에 대한 정보를 포함하는 베이스 모델 리스트를 획득할 수 있다. 기정의된 알고리즘은 하이퍼파라미터 최적화 알고리즘 및 신경망 아키텍처 탐색 알고리즘을 포함할 수 있다. 전자 장치는 베이스 모델 리스트를 사용자에게 제공할 수 있다. 예를 들어, 베이스 모델 리스트은 사용자 장치에 표시될 수 있다. 사용자는 베이스 모델 리스트에서 복수의 제2 베이스 모델를 선택할 수 있다. 전자 장치는 데이터셋 및 복수의 제2 베이스 모델에 기초하여 복수의 제2 학습된 모델 을 획득할 수 있다. 한편, 전자 장치는 복수의 제2 베이스 모델을 선택하는 사용자의 입력 없이 복수의 제2 학습된 모델 을 획득할 수 있다. 예컨대, 전자 장치는 미리 정해진 개수만큼의 베이스 모델을 획득하고, 획득된 베 이스 모델에 대응되는 학습된 모델을 획득할 수 있다. 또는, 전자 장치는 복수의 베이스 모델 리스트 에서 미리 정해진 성능 범위 이내인 복수의 제2 베이스 모델을 식별할 수 있다. 예컨대, 전자 장치는 복수의 베이스 모델 리스트에서 미리 정해진 정확도 범위 및 미리 정해진 레이턴시 범위 이내인 복수의 제2 베이스 모델을 식별할 수 있다. 여기서, 미리 정해진 개수, 미리 정해진 성능 범위는 사용자에 의해 설정될 수 있다. 예컨대, 사용자는 미리 정해진 성능 범위를 타겟 성능으로서 사용자 장치에 입력할 수 있다. 도 5는 본 개시의 일 실시 예에 따른 제3 프로젝트를 수행하는 방법을 설명하기 위한 도면이다. 도 5를 참조하면, 전자 장치는 데이터셋을 획득할 수 있다. 데이터셋은 제1 프로젝트에서 이용된 데이터셋 또는 제2 프로젝트에서 이용된 데이터셋일 수 있다. 또는, 데이터셋은 제1 프로젝트 또는 제2 프로젝트에서 이용되지 않은 새로운 데이터셋일 수 있다. 데이터셋은 데이터셋 DB에 저장되어 있을 수있다. 데이터셋 DB는 전자 장치의 메모리에 포함될 수 있다. 전자 장치는 베이스 모델 리스트를 획득할 수 있다. 베이스 모델 리스트는 이전 프로젝트에서 획 득된 신경망 모델을 포함할 수 있다. 즉, 제3 프로젝트에서 베이스 모델은 이전 프로젝트에서 획득된 학습된 모 델 중 하나일 수 있다. 예를 들어, 베이스 모델 리스트는 제1 프로젝트에서 획득된 제1 학습된 모델 및 제2 프로젝트에서 획득된 복수의 제2 학습된 모델을 포함할 수 있다. 전자 장치는 베이스 모델 리스트 를 제공할 수 있다. 사용자는 베이스 모델 리스트 중 제3 베이스 모델을 선택할 수 있다. 전자 장 치는 데이터셋 및 제3 베이스 모델에 기초하여 제3 학습된 모델을 획득할 수 있다. 한편, 전자 장치는 사용자 선택 없이 데이터셋 DB에서 데이터셋을 획득할 수 있다. 이 때, 전자 장치 는 획득된 데이터셋이 사용자에게 추천되도록 외부 장치로 명령을 전송할 수 있다. 이에 따라, 외부 장치는 사용자에게 전자 장치가 획득한 데이터셋을 추천할 수 있다. 또는 전자 장치는 데이터셋 에 기초하여 제3 학습된 모델을 획득할 수 있다. 전자 장치는 압축된 모델을 기초로 제3 학습된 모델을 획득할 수 있다. 여기서, 압축된 모델이란, 컴 프레서가 제1 프로젝트, 제2 프로젝트 또는 제3 프로젝트를 통해 획득된 학습된 모델을 압축하여 생성한 경량화 된 모델을 의미할 수 있다. 컴프레서의 동작에 대해서는 후술하도록 한다. 전자 장치는 제3 베이스 모델이 압축된 모델인 지 여부에 기초하여 데이터셋 DB에서 데이터셋을 획득할 수 있다. 제3 베이스 모델이 압축된 모델이면, 전자 장치는 제3 베이스 모델을 학습시키는 데 이용된 데이터셋을 데이터셋으로 획득할 수 있다. 예를 들어, 제3 베이스 모델이 제1 학습된 모델 인 경우, 전자 장치는 데이터셋을 획득할 수 있다. 제3 베이스 모델이 압축된 모델이면, 압축 이 진행되는 동안 모델의 정확도가 감소할 수 있다. 전자 장치는 제3 프로젝트를 수행함으로써 제3 베이스 모델에 비해 정확도가 향상된 제3 학습된 모델을 획득할 수 있다. 제3 베이스 모델이 압축된 모델이 아니면, 전자 장치는 제3 베이스 모델을 학습시키는데 이용되지 않은 데이터셋을 데이터셋으로 획득할 수 있다. 예를 들어, 제3 베이스 모델이 제1 학습된 모델인 경우, 전자 장치는 데이터셋이 아닌 다른 데이터셋을 획득할 수 있다. 따라서, 제3 학습된 모델은 데이터셋 뿐만 아니라 새로운 데이터셋에 대해서도 정확히 추론할 수 있다. 도 6 내지 도 9는 사용자에게 제공되는 각종 화면들이다. 각 화면은 사용자 장치에 표시될 수 있다. 도 6은 본 개시의 일 실시 예에 따른 데이터셋 입력 화면이다. 도 6을 참조하면, 데이터셋 입력 화면은 사용자로부터 데이터셋을 입력 받는 화면이다. 데이터셋 입력 화면 은 데이터셋의 명칭 및 사용자 메모를 입력 받는 제1 영역을 포함할 수 있다. 데이터셋 입력 화면 은 데이터셋을 통해 학습된 모델이 수행할 태스크를 입력 받는 제2 영역을 포함할 수 있다. 태스크는, 이미 지 분류, 오브젝트 검출 및 시맨틱 세그멘테이션을 포함할 수 있다. 제2 영역은 데이터셋의 포맷을 입력 받 을 수 있다. 데이터셋의 포맷은, YOLO(You only look once), VOC 및 COCO를 포함할 수 있다. 제2 영역에는 사용자가 태스크, 데이터셋의 포맷을 입력하기 위한 UI 엘리먼트가 표시될 수 있다. 데이터셋 입력 화면은 데이터셋의 업로드 경로 및 데이터셋의 파일을 입력 받는 제3 영역을 포함할 수 있다. 데이터셋의 업로드 경로는 로컬 스토리지 및 클라우드 스토리지를 포함할 수 있다. 제3 영역에는 사 용자가 데이터셋의 업로드 경로를 선택하기 위한 UI 엘리먼트가 표시될 수 있다. 제3 영역에는 사용자 가 데이터셋의 파일을 선택하기 위한 UI 엘리먼트가 표시될 수 있다. UI 엘리먼트에서 로컬 스토리지가 선택된 경우, UI 엘리먼트는 파일을 입력받을 수 있다. UI 엘리먼트에서 클라우드 스토리지가 선택된 경우, UI 엘리먼트는 링크를 입력받을 수 있다. 도 7은 본 개시의 일 실시 예에 따른 데이터셋 확인 화면이다. 도 7을 참조하면, 데이터셋 확인 화면은 사용자가 입력한 데이터셋에 대한 상세 정보를 표시하는 화면이다. 데이터셋 확인 화면에는 데이터셋 입력 화면에서 사용자에 의해 입력된 정보들이 표시될 수 있다. 예를 들어, 데이터셋 확인 화면에는 데이터셋의 명칭, 사용자 메모, 데이터셋을 통해 학습될 모델이 수 행할 태스크, 데이터셋의 포맷, 전체 데이터셋의 개수 및 데이터셋의 유형 별 개수가 표시될 수 있다. 데이터셋 확인 화면에는 데이터셋을 수정하기 위한 버튼, 데이터셋을 나타내는 테이블 및 데이터셋 을 이용해 프로젝트 생성하기 위한 버튼이 표시될 수 있다. 사용자가 버튼을 누르면, 사용자 장치는 프로젝트 생성 명령을 전자 장치로 전송할 수 있다. 프로젝트 생성 명령이 수신되면, 전자 장치는 데이 터셋에 기초하여 프로젝트를 설정할 수 있다. 도시되지 않았으나, 데이터셋 확인 화면에는 데이터셋과 관련된 프로젝트에 대한 정보가 표시될 수 있다. 예를 들어, 데이터셋과 관련된 프로젝트는, 데이터셋을 이용해 획득된 프로젝트를 포함할 수 있다. 프로젝트에 대한 정보는, 프로젝트를 통해 획득된 학습된 모델의 태스크, 프로젝트에 이용된 데이터셋에 대한 정보, 프로젝 트에 대응되는 타겟 디바이스에 대한 정보 및 프로젝트의 목적을 포함할 수 있다. 사용자에 의해 데이터셋의 입력이 완료되면, 데이터셋은 전자 장치에 업로드 될 수 있다. 사용자 장치는 입력된 데이터셋, 데이터셋과 관련된 정보(예로, 데이터셋의 명칭 등)를 전자 장치로 전송할 수 있다. 전 자 장치는 데이터셋 및 데이터셋과 관련된 정보를 메모리에 포함된 데이터셋 DB에 저장할 수 있다. 도 8은 본 개시의 일 실시 예에 따른 데이터셋 리스트 화면이다. 도 8을 참조하면, 데이터셋 리스트 화면은 데이터셋 리스트를 표시하는 화면이다. 사용자는 데이터셋 리스 트 화면에서 업로드 된 데이터셋을 확인하고, 데이터셋을 기초로 프로젝트를 생성하고, 데이터셋을 삭제할 수 있다. 데이터셋 리스트는 메모리에 포함된 데이터셋 DB에 저장되어 있을 수 있다. 데이터셋 리스트 화면에는 데이터셋 DB에 저장된 복수의 데이터셋과 각각과 관련된 정보가 표시될 수 있다. 예를 들어, 데이터셋 리스트 화면에는 제1 데이터셋과 관련된 정보가 표시될 수 있다. 제1 데이터셋과 관련된 정보는 제1 데이터셋을 이용해 학습될 모델의 태스크 및 제1 데이터셋의 업로드 상태가 표 시될 수 있다. 업로드 상태는, 업로드 완료 상태, 업로드 중 상태, 에러 발생 상태를 표시할 수 있다. 데이터셋 리스트 화면에는 제1 데이터셋의 명칭, 데이터셋의 개수가 표시될 수 있다. 데이터셋 리 스트 화면에는 제1 데이터셋에 대한 상세 정보를 표시하기 위한 버튼이 표시될 수 있다. 예를 들어, 버 튼이 입력되면, 데이터셋 리스트 화면에는 제1 데이터셋에 대응되는 데이터셋 확인 화면이 표시될 수 있다. 데이터셋 리스트 화면에는 데이터셋을 이용해 프로젝트를 설정하기 위한 버튼이 표시될 수 있 다. 데이터셋 리스트 화면에는 업로드 된 데이터셋을 삭제하기 위한 버튼이 표시될 수 있다. 도 9는 본 개시의 일 실시 예에 따른 타겟 디바이스 입력 화면이다. 도 9를 참조하면, 타겟 디바이스 입력 화면은 사용자로부터 타겟 디바이스와 관련된 정보를 입력 받는 화면 이다. 타겟 디바이스 입력 화면은 타겟 디바이스의 명칭 및 버전을 입력 받는 제1 영역을 포함할 수 있 다. 제1 영역에는 사용자가 타겟 디바이스의 명칭 및 버전을 선택하기 위한 UI 엘리먼트가 표시될 수 있다. 타겟 디바이스 입력 화면은 타겟 디바이스에 대응되게 신경망 모델을 획득하기 위한 출력 포맷을 입력 받는 제2 영역을 포함할 수 있다. 출력 포맷은, 프레임 워크는 및 소프트웨어 버전을 포함할 수 있다. 제2 영역 에는 사용자가 프레임 워크 및 소프트웨어 버전을 각각 선택하기 위한 UI 엘리먼트들이 표시될 수 있다. 타겟 디바이스 입력 화면은 타겟 디바이스에 대응되게 신경망 모델을 획득하기 위한 출력 데이터의 타입을 입력 받는 제3 영역을 포함할 수 있다. 제3 영역에는 사용자가 출력 데이터의 타입을 선택하기 위한 UI 엘리먼트들이 표시될 수 있다. 제1 영역에서 선택된 사항에 따라 제2 영역 및/또는 제3 영역에 표 시된 UI 엘리먼트들 중 일부가 비활성화될 수 있다. 타겟 디바이스 입력 화면은 타겟 디바이스에 대응되게 신경망 모델을 획득하기 위한 추론 배치(interference batch)의 크기를 입력 받는 제4 영역을 포함할 수 있 다. 도시하지 않았지만, 사용자 장치에는 학습 모드를 입력 받기 위한 학습 모드 선택 화면이 표시될 수 있다. 학습 모드 선택 화면은 복수의 학습 모드 각각에 대응되는 UI 엘리먼트들(예로, 버튼)을 포함할 수 있다. 사용 자가 학습 모드를 선택하면, 사용자 장치는 전자 장치로 선택된 학습 모드와 관련된 커맨드를 전송할 수 있다. 전자 장치는 선택된 학습 모드에 기초하여 프로젝트를 설정할 수 있다. 또한, 사용자 장치에는 사용자로부터 학습 자원을 선택받기 위한 학습 자원 선택 화면이 표시될 수 있다. 학습 자원은 베이스 모델을 학습시켜 학습된 모델을 생성할 수 있다. 예를 들어, 학습 자원은 외부 서버를 포함할 수 있다. 학습 자원 선택 화면에는 적어도 하나의 학습 자원에 대응되는 UI 엘리먼트가 표시될 수 있다. 사용자가 UI 엘리먼트를 선택하면, 사용자 장치는 선택된 UI 엘리먼트에 대응되는 학습 자원과 관련된 커맨드를 전송할 수 있다. 전자 장치는 베이스 모델을 학습 자원으로 전송할 수 있다. 전자 장치는 학습 자원에 의해 생성된 학습된 모델을 학습 자원으로부터 수신할 수 있다.도 10은 본 개시의 일 실시 예에 따른 프로젝트 정보 화면이다. 도 10을 참조하면, 프로젝트 정보 화면은 사용자가 입력한 정보에 기초하여 설정된 프로젝트에 대한 정보 를 표시할 수 있다. 예를 들어, 프로젝트 정보 화면에는 사용자가 선택한 학습 모드 및 사용자가 입 력한 데이터셋에 대한 정보가 표시될 수 있다. 데이터셋에 대한 정보는 프로젝트를 통해 획득될 학습 된 모델이 수행할 태스크 및 데이터셋의 식별 정보를 포함할 수 있다. 도시되지 않았으나, 프로젝트 정보 화면은 학습 설정 정보를 입력 받기 위한 학습 설정 영역을 포함할 수 있다. 학습 설정 정보는, 학습된 모델의 타겟 성능, 학습된 모델의 입력 데이터의 크기(예로, 입력 이미지의 해 상도), 트레이닝 에포크(training epoch) 및 데이터 어그멘테이션(data augmentation)를 포함할 수 있다. 도 11은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 도면이다. 도 11을 참조하면, 전자 장치는 신경망 모델의 학습을 위한 데이터셋, 신경망 모델을 실행할 타겟 디바이 스에 대한 정보 및 신경망 모델에 대한 학습 모드를 획득할 수 있다(S1110). 전자 장치는 사용자 장치로부 터 신경망 모델의 학습을 위한 데이터셋, 신경망 모델을 실행할 타겟 디바이스에 대한 정보 및 신경망 모델에 대한 학습 모드를 수신할 수 있다. 전자 장치는 데이터셋, 타겟 디바이스에 대한 정보 및 학습 모드를 기초로 프로젝트를 설정할 수 있다 (S1120). 전자 장치는 데이터셋, 타겟 디바이스에 대한 정보 및 학습 모드로 특정되는 프로젝트를 생성할 수 있다. 프로젝트는 학습 모드에 따라 분류될 수 있다. 예를 들어, 제1 학습 모드에 의해 설정된 프로젝트는 제1 프로젝트로, 제2 학습 모드에 의해 설정된 프로젝트는 제2 프로젝트로, 제3 학습 모드에 의해 설정된 프로 젝트는 제3 프로젝트로 각각 분류될 수 있다. 전자 장치는 프로젝트를 수행하여 적어도 하나의 학습된 신경망 모델을 획득할 수 있다(S1130). 획득된 모 델은 타겟 디바이스에 최적화된 모델일 수 있다. 이하에서는 프로젝트를 수행하는 방법에 대해 보다 상세히 설 명하도록 한다. 도 12는 본 개시의 일 실시 예에 따른 제1 프로젝트를 수행하는 방법을 나타내는 시퀀스도이다. 도 12를 참조하면, 신경망 모델 제공 시스템은 전자 장치, 외부 장치 및 외부 서버를 포 함할 수 있다. 외부 장치는 사용자와 인터랙션을 수행하는 사용자 장치일 수 있다. 외부 서버는 데이 터셋에 기초하여 학습된 모델을 생성하는 학습 서버일 수 있다. 외부 장치는 제1 데이터셋, 제1 타겟 디바이스에 대한 정보 및 제1 학습 모드를 획득할 수 있다(S1210). 외부 장치는 제1 데이터셋, 제1 타겟 디바이스에 대한 정보 및 제1 학습 모드를 전자 장치로 전송할 수 있다(S1215). 본 개시에서 학습 모드를 전송하는 동작은, 학습 모드를 지시하는 정보를 전송하는 동작을 의 미한다. 전자 장치는 제1 데이터셋, 제1 타겟 디바이스에 대한 정보 및 제1 학습 모드를 기초로 제1 프로젝트를 설 정할 수 있다(S1220). 전자 장치는 설정된 제1 프로젝트를 수행할 수 있다(S1230). 이하에서는 제1 프로젝 트 수행 단계(S1230)에 대해 보다 상세히 설명하도록 한다. 전자 장치는 제1 타겟 디바이스에 대한 정보 및 사용자에 의해 입력된 타겟 성능에 기초하여 복수의 베이 스 모델을 획득할 수 있다(S1231). 예를 들어, 전자 장치는 복수의 신경망 모델 및 복수의 신경망 모델 각 각에 대한 정보를 포함하는 룩-업 테이블을 저장하고 있을 수 있다. 전자 장치는 룩-업 테이블을 이용하여 복수의 신경망 모델 중 타겟 디바이스에 대응되며 상기 타겟 성능과의 성능 차이가 기설정된 범위 이내인 신경 망 모델을 베이스 모델로 식별할 수 있다. 전자 장치는 복수의 베이스 모델에 대한 정보를 외부 장치로 전송할 수 있다(S1232). 이 때, 전자 장 치는 복수의 베이스 모델에 대한 정보를 표시하기 위한 커맨드를 외부 장치로 전송할 수 있다. 외부 장치는 복수의 베이스 모델에 대한 정보를 출력할 수 있다(S1233). 예를 들어, 외부 장치는 복 수의 베이스 모델 각각에 대한 정보를 표시할 수 있다. 이를 위해, 외부 장치는 디스플레이, 스피커를 비 롯한 각종 출력 유닛을 포함할 수 있다. 외부 장치는 복수의 베이스 모델 중 제1 베이스 모델을 선택하는 사용자 명령을 획득할 수 있다. 외 부 장치는 제1 베이스 모델에 대한 정보를 전자 장치로 전송할 수 있다(S1235).전자 장치는 제1 데이터셋 및 제1 베이스 모델을 외부 서버로 전송할 수 있다(S1236). 외부 서버 는 사용자에 의해 선택될 수 있다. 예를 들어, 외부 장치는 복수의 외부 서버를 표시하고, 복수의 외 부 서버 중 하나를 선택하는 사용자 입력을 획득 수 있다. 사용자에 의해 외부 서버가 선택되는 동작은 제 1 프로젝트 수행 단계(S1230) 이전 또는 제1 프로젝트 수행 단계(S1230) 내에 수행될 수 있다. 외부 서버는 제1 데이터셋에 기초하여 제1 베이스 모델을 학습시켜 제1 학습된 모델을 획득할 수 있다 (S1237). 외부 서버는 제1 학습된 모델을 전자 장치로 전송할 수 있다(S1238). 한편, 다른 실시 예에 서, 제1 학습된 모델은 전자 장치에 의해 생성할 수 있다. 즉, 전자 장치가 외부 서버의 기능을 수행할 수도 있다. 이 때, 단계 S1237 및 단계 S1238은 생략될 수 있다. 전자 장치는 제1 학습된 모델에 대한 정보를 외부 장치로 전송할 수 있다(S1239). 외부 장치는 제1 학습된 모델에 대한 정보를 사용자에게 제공할 수 있다. 예를 들어, 제1 학습된 모델에 대한 정보는, 제1 학습된 모델의 성능 정보, 제1 학습된 모델의 다운로드 파일 및 다운로드 링크를 포함할 수 있다. 도 13은 본 개시의 일 실시 예에 따른 제2 프로젝트를 수행하는 방법을 나타내는 시퀀스도이다. 도 13을 참조하면, 외부 장치는 제2 데이터셋, 제2 타겟 디바이스에 대한 정보 및 제2 학습 모드를 획득하 여(S1310), 전자 장치로 전송할 수 있다(S1315). 전자 장치는 제2 데이터셋, 제2 타겟 디바이스에 대 한 정보 및 제2 학습 모드를 기초로 제2 프로젝트를 설정할 수 있다(S1320). 전자 장치는 제2 프로젝트를 수행할 수 있다(S1330). 이하에서는 제2 프로젝트 수행 단계(S1330)에 대해 보다 상세히 설명하도록 한다. 전자 장치는 제2 타겟 디바이스에 대한 정보 및 기정의된 알고리즘에 기초하여 복수의 베이스 모델을 생성 할 수 있다(S1331). 기정의된 알고리즘은, 하이퍼파라미터 최적화 알고리즘 또는 신경망 아키텍처 탐색 알고리 즘 중 적어도 하나를 포함할 수 있다. 하이퍼파라미터 최적화 알고리즘은 HPO(Hyper-Parameter Optimization)를 포함할 수 있다. HPO는 주어진 하이퍼파리미터 탐색 공간(Hyperparameter search space)에서 최적의 하이퍼파리 미터를 찾는 알고리즘일 수 있다. 예를 들어, HPO는 신경망 모델의 일부 레이어를 변경해가면서 여러 베이스 모 델을 생성하고, 각 베이스 모델의 성능을 평가하면서 성능이 좋은 베이스 모델을 탐색할 수 있다. HPO는 하이퍼 밴드(Hyperband), 베이지안 최적화(Bayesian Optimization)와 같은 알고리즘을 활용할 수 있다. 전자 장치는 복수의 베이스 모델에 대한 정보를 외부 장치로 전송할 수 있다(S1332). 외부 장치(20 0)는 복수의 베이스 모델에 대한 정보를 출력할 수 있다(S1333). 외부 장치는 복수의 베이스 모델 중 적어 도 하나의 베이스 모델을 선택하는 사용자 명령을 획득할 수 있다(S1334). 예를 들어, 외부 장치는 복수의 베이스 모델을 선택하는 사용자 명령을 획득할 수 있다. 외부 장치는 적어도 하나의 베이스 모델에 대한 정보를 전자 장치로 전송할 수 있다(S1335). 전자 장치는 제2 데이터셋 및 적어도 하나의 베이스 모 델을 외부 서버로 전송할 수 있다(S1336). 외부 서버는 제2 데이터셋에 기초하여 적어도 하나의 베이스 모델을 학습시켜 적어도 하나의 제2 학습된 모델을 획득할 수 있다(S1337). 외부 서버는 적어도 하나의 제2 학습된 모델을 전자 장치롤 전송할 수 있다. 전자 장치는 적어도 하나의 제2 학습된 모델에 대한 정보를 외부 장치로 전송할 수 있다. 한편, 다른 실시 예에서, 전자 장치는 베이스 모델을 선택하는 사용자 명령 없이 적어도 하나의 제2 학습 된 모델을 획득할 수 있다. 예를 들어, 전자 장치는 복수의 베이스 모델을 생성하고, 복수의 베이스 모델 각각이 학습된 복수의 제2 학습된 모델을 획득할 수 있다. 즉, 전자 장치는 제2 데이터셋 및 복수의 베이 스 모델을 외부 서버로 전송하고, 외부 서버로부터 복수의 제2 학습된 모델을 수신할 수 있다. 이 때, 단계 S1332, 단계 S1333, 단계 S1334, 단계 S1335는 생략될 수 있다. 도 14는 본 개시의 일 실시 예에 따른 제3 프로젝트를 수행하는 방법을 나타내는 시퀀스도이다. 도 14를 참조하면, 외부 장치는 제3 데이터셋, 제3 타겟 디바이스에 대한 정보 및 제3 학습 모드를 획득하 고(S1410), 전자 장치로 전송할 수 있다(S1415). 전자 장치는 제3 데이터셋, 제3 타겟 디바이스에 대 한 정보 및 제3 학습 모드를 기초로 제3 프로젝트를 설정할 수 있다(S1420). 다른 실시 예에서, 제3 타겟 디바 이스에 대한 정보가 획득되어 전자 장치로 전송되는 동작은 생략될 수 있다. 예를 들어, 사용자에 의해 제 3 학습 모드가 선택되면, 전자 장치는 제3 프로젝트 이전에 수행된 프로젝트에 대응되는 타겟 디바이스에 대한 정보를 프로젝트 DB에서 획득할 수 있다. 가령, 전자 장치가 제1 프로젝트를 수행한 이후 제3 프로젝 트를 수행하는 경우, 전자 장치는 제1 프로젝트에서 이용된 제1 타겟 디바이스에 대한 정보를 획득할 수있다. 전자 장치는 제3 데이터셋, 제3 타겟 디바이스에 대한 정보 및 제3 학습 모드를 기초로 제3 프로젝트를 설 정할 수 있다(S1420). 전자 장치는 제3 프로젝트를 수행할 수 있다(S1430). 이하에서는 제3 프로젝트 수행 단계(S1430)에 대해 보다 상세히 설명하도록 한다. 전자 장치는 학습된 모델 리스트를 획득할 수 있다(S1431). 예를 들어, 전자 장치는 모델 DB에서 학 습된 모델 리스트를 획득할 수 있다. 학습된 모델 리스트는 모델 DB에 저장된 복수의 학습된 모델에 대한 정보 를 포함할 수 있다. 전자 장치는 학습된 모델 리스트를 외부 장치로 전송할 수 있다(S1432). 외부 장치는 학습된 모 델 리스트를 출력할 수 있다. 다른 실시 예에서, 단계 S1431 및 단계 S1432는 생략될 수 있다. 예컨대, 학습된 모델 리스트는 외부 장치에 저장되어 있을 수 있다. 외부 장치는 학습된 모델 리스트 중 하나의 학습된 모델을 선택하는 사용자 명령을 획득할 수 있다 (S1434). 외부 장치는 선택된 학습된 모델에 대한 정보를 전자 장치로 전송할 수 있다(S1435). 전자 장치는 제3 데이터셋 및 선택된 학습된 모델을 외부 서버로 전송할 수 있다(S1436). 외부 서버 는 제3 데이터셋에 기초하여 선택된 학습된 모델을 학습시켜 제3 학습된 모델을 획득할 수 있다(S1437). 즉, 제 3 프로젝트에서 베이스 모델은 제1 프로젝트 또는 제2 프로젝트를 통해 생성된 학습된 모델일 수 있다. 또한, 제3 프로젝트의 베이스 모델은 제1 프로젝트 또는 제2 프로젝트를 통해 생성된 학습된 모델을 기초로 재학습된 모델(즉, 다른 제3 프로젝트를 통해 획득된 모델)을 포함할 수 있다. 외부 서버는 제3 학습된 모델을 전송할 수 있다(S1438). 전자 장치는 제3 학습된 모델에 대한 정보를 외부 장치로 전송할 수 있다(S1439). 도 15는 본 개시의 일 실시 예에 따른 신경망 모델 제공 시스템의 구성을 도시한 블록도이다. 도 15를 참조하면, 신경망 모델 제공 시스템은은 전자 장치, 외부 장치 및 외부 서버를 포함할 수 있다. 전자 장치는 외부 장치를 통해 획득된 사용자 입력에 기초하여 신경망 모델에 대한 정보를 획득할 수 있다. 전자 장치는 신경망 모델에 대한 정보를 외부 장치로 전송할 수 있다. 외부 장치는 전자 장치로부터 수신한 신경망 모델에 대한 정보를 사용자에게 제공할 수 있다. 메모리는 복수의 신경망 모델에 대한 정보를 저장할 수 있다. 복수의 신경망 모델에 대한 정보는, 복수의 신경망 모델의 식별 정보, 복수의 신경망 모델이 실행되는 복수의 디바이스에 대한 정보, 복수의 디바이스에서 실행될 때 복수의 신경망 모델의 성능 정보 및 복수의 신경망 모델의 입력 데이터의 크기를 포함할 수 있다. 각 정보는 서로 매칭되어 룩-업 테이블 형태로 저장되어 있을 수 있다. 프로세서는 신경망 모델이 실행될 타겟 디바이스에 대한 정보 및 타겟 디바이스에서 실행될 때 신경망 모 델의 타겟 성능을 획득할 수 있다. 타겟 성능은, 타겟 정확도, 타겟 지연 시간 또는 타겟 연산량 중 적어도 하 나를 포함할 수 있다. 프로세서는 통신 인터페이스를 통해 외부 장치로부터 타겟 디바이스에 대 한 정보 및 신경망 모델의 타겟 성능을 수신할 수 있다. 외부 장치는 입력부를 통해 타겟 디바이스에 대한 정보 및 신경망 모델의 타겟 성능을 입력하는 사용자 명령을 획득할 수 있다. 프로세서는 타겟 디바이스에 대한 정보 및 타겟 성능에 기초하여 복수의 후보 신경망 모델에 대한 정보를 획득할 수 있다. 복수의 후보 신경망 모델에 대한 정보는, 복수의 후보 신경망 모델의 명칭, 복수의 후보 신경 망 모델의 성능 또는 복수의 후보 신경망 모델의 입력 데이터의 크기 중 적어도 하나를 포함할 수 있다. 프로세서는 복수의 후보 신경망 모델에 대한 정보를 메모리에서 획득할 수 있다. 프로세서는 타 겟 디바이스에 대한 정보 및 타겟 성능과 메모리에 저장된 복수의 신경망 모델에 대한 정보를 비교하여 복 수의 신경망 모델 중 복수의 후보 신경망 모델을 식별할 수 있다. 프로세서는 식별된 후보 신경망 모델에 대한 정보를 메모리에서 획득할 수 있다. 프로세서는 메모리에 저장된 복수의 신경망 모델 중 타겟 성능과의 성능 차이에 기초한 순위가 기설 정된 순위 이상인 신경망 모델들을 복수의 후보 신경망 모델로 식별할 수 있다. 기설정된 순위는 5순위일 수 있 다. 타겟 성능과의 성능 차이가 작은 신경망 모델일수록 높은 순위를 가질 수 있다. 예를 들어, 복수의 신경망 모델은 제1 내지 제10 신경망 모델을 포함할 수 있다. 이 중 제1 내지 제5 신경망 모델은 각각은 제1 순위 내지 제5 순위를 가질 수 있다. 이 때, 프로세서는 제1 내지 제5 신경망 모델은 복수의 후보 신경망 모델로 식별할 수 있다. 프로세서는 복수의 신경망 모델 중 타겟 성능과의 차이가 기설정된 범위 이내인 신경망 모델들을 복수의 후보 신경망 모델로 식별할 수 있다. 예를 들어, 타겟 성능은 타겟 레이턴시이며 기설정된 범위는 100(ms)일 수 있다. 프로세서는 타겟 성능에 기초하여 복수의 후보 신경망 모델에 대한 정보를 표시하도록 외부 장치로 명령을 전송하도록 통신 인터페이스를 제어할 수 있다. 외부 장치는 전송된 명령에 기초하여 복수의 후보 신경망 모델에 대한 정보를 표시할 수 있다. 본 개시에서 특별한 언급이 없으면 프로세서가 외부 장 치로 명령은 전송한다는 것은, 프로세서가 통신 인터페이스를 제어함으로써 통신 인터페이스 가 외부 장치로 명령을 전송하는 것을 의미한다. 한편, 전자 장치가 외부 장치로 표시 명 령을 전송한 경우, 특별한 언급이 없어도 외부 장치가 표시 명령에 대응되는 정보를 표시하는 것은 자명하 다. 프로세서는 복수의 후보 신경망 모델에 대한 정보를 각각 나타내는 복수의 UI 엘리먼트를 대응되는 후보 신경망 모델의 성능 및 타겟 성능의 차이가 작은 순서대로 표시하도록 외부 장치로 명령을 전송할 수 있다. 복수의 UI 엘리먼트 각각은, 복수의 UI 엘리먼트 각각에 커서가 놓여지면 복수의 후보 신경망 모델에 대 한 정보를 표시할 수 있다. 복수의 후보 신경망 모델은, 제1 유형의 복수의 제1 후보 신경망 모델 및 제2 유형의 복수의 제2 후보 신경망 모델을 포함할 수 있다. 제1 후보 신경망 모델은, 사용자에 의해 설정된 프로젝트 정보를 기초로 획득된 모델일 수 있다. 프로젝트 정보는, 프로젝트를 정의하는 각종 정보(예로, 프로젝트를 통해 생성되는 신경망 모델의 입 력 데이터의 크기)를 포함할 수 있다. 예컨대, 제1 후보 신경망 모델은, 사용자에 의해 설정된 입력 데이터의 크기와 동일한 입력 데이터의 크기를 갖는 모델일 수 있다. 제2 후보 신경망 모델은, 사용자에 의해 설정된 프 로젝트 정보로부터 일부 수정된 프로젝트 정보를 기초로 획득된 모델일 수 있다. 예컨대, 제2 후보 신경망 모델 은, 사용자에 의해 설정된 입력 데이터의 크기와 다른 입력 데이터의 크기를 가지고, 사용자에 의해 설정된 타 겟 성능으로부터 기설정된 범위 이내의 성능을 가질 수 있다. 복수의 UI 엘리먼트는, 복수의 제1 후보 신경망 모델에 각각 대응되는 복수의 제1 UI 엘리먼트, 및 복수의 제2 후보 신경망 모델에 각각 대응되는 복수의 제2 UI 엘리먼트를 포함할 수 있다. 프로세서는 복수의 제1 UI 엘리먼트 및 복수의 제2 UI 엘리먼트를 서로 다른 영역에 동시에 표시하도록 외부 장치로 명령을 전송할 수 있다. 이에 따라, 외부 장치는 복수의 제1 UI 엘리먼트 및 복수의 제2 UI 엘리먼트를 서로 다른 영역에 동시에 표시할 수 있다. 프로세서는 복수의 후보 신경망 모델에 대한 정보를 각각 나타내는 복수의 UI 엘리먼트를 2차원 그래프에 표시하도록 외부 장치로 명령을 전송할 수 있다. 2차원 그래프는, 제1 성능 파라미터에 대응되는 제1 축 및 제2 성능 파라미터에 대응되는 제2 축에 의해 정의될 수 있다. 예를 들어, 제1 성능 파라미터는 지연 시간 (latency) 관련 파라미터이며, 제2 성능 파라미터는 정확도 관련 파라미터일 수 있다. 복수의 UI 엘리먼트는, 상기 복수의 UI 엘리먼트 각각에 대응되는 후보 신경망 모델의 성능이 타겟 성능에 대응 되는 제3 UI 엘리먼트들, 및 대응되는 후보 신경망 모델의 성능이 타겟 성능에 대응되지 않는 제4 UI 엘리먼트 들을 포함할 수 있다. 프로세서는 제3 UI 엘리먼트들은 활성화하고 제4 UI 엘리먼트들은 비활성화하도록 외부 장치로 명령을 전송할 수 있다. 외부 장치는 PC(Personal Computer)로 구현될 수 있다. 외부 장치는 통신 인터페이스, 메모리 , 프로세서, 입력부 및 디스플레이를 포함할 수 있다. 프로세서는 입력부를 통해 획득한 사용자 명령을 전자 장치로 전송하도록 통신 인터페이스(21 0)를 제어할 수 있다. 예를 들어, 프로세서는 복수의 후보 신경망 모델 중 하나를 선택하는 사용자 명령을 전자 장치로 전송하도록 통신 인터페이스를 제어할 수 있다. 입력부는 외부 장치의 동작과 관련하여 다양한 사용자 명령을 입력받기 위한 구성이다. 입력부 는 외부 장치에 연결된 키보드, 마우스 등과 같은 외부 입력 수단으로부터 각종 입력 신호를 입력받는 (Input/Output Interface)로 구현될 수 있다. 또는, 입력부는 디스플레이상의 터치 화면으로 구현될 수 있다. 디스플레이는 프로세서의 제어에 의해 다양한 정보를 표시할 수 있다. 예를 들어, 디스플레이는 복수의 후보 신경망 모델에 대한 정보를 표시할 수 있다. 도 16은 본 개시의 일 실시 예에 따른 학습 설정 화면이다. 도 16을 참조하면, 학습 설정 화면은 사용자로부터 학습 설정 정보를 입력받기 위한 화면으로, 외부 장치 에 표시될 수 있다. 학습 설정 정보는, 학습된 모델의 입력 데이터의 크기(예로, 입력 이미지의 해상도), 트레이닝 에포크(training epoch), 데이터 어그멘테이션(data augmentation)을 포함할 수 있다. 학습 설정 화면은 타겟 성능(예로, 레이턴시)을 입력 받는 제1 영역을 포함할 수 있다. 제1 영역 은 단일 값을 입력받거나 범위 값(예로, 400~500)을 입력받을 수 있다. 학습 설정 화면은 신경망 모델의 입력 데이터의 크기를 입력 받는 제2 영역, 및 데이터 어그멘테이션 수행 여부와 트레이닝 에포크 를 입력 받는 제3 영역을 포함할 수 있다. 각 영역(1610, 1620, 1630)에 대한 사용자 입력이 획득되면, 외부 장치는 사용자 입력과 관련된 정보를 전 자 장치로 전송할 수 있다. 전자 장치는 사용자에 의해 입력된 타겟 성능 및 입력 데이터의 크기를 기초로 복수의 후보 신경망 모델을 획득하여 외부 장치로 전송할 수 있다. 한편, 사용자가 입력하는 데이터셋의 크기는 설정된 입력 데이터의 크기와 상이할 수 있다. 예컨대, 사용자가 입력한 데이터셋은 제1 해상도의 이미지셋이고, 설정된 입력 데이터의 크기는 제1 해상도와 상이한 제2 해상도 일 수 있다. 이 때, 전자 장치는 사용자가 입력한 데이터셋의 크기를 설정된 입력 데이터의 크기로 변환할 수 있다. 예를 들어, 전자 장치는 제1 해상도의 이미지셋으로부터 제2 해상도의 이미지셋을 획득할 수 있 다. 도 17은 본 개시의 일 실시 예에 따른 베이스 모델 추천 화면이다. 도 17을 참조하면, 베이스 모델 추천 화면은 사용자에게 복수의 후보 신경망 모델을 추천하는 화면으로 외부 장치에 표시될 수 있다. 사용자는 복수의 후보 신경망 모델 중 베이스 모델을 선택할 수 있다. 신경 망 모델 제공 시스템은 사용자가 선택한 베이스 모델을 기초로 학습된 모델을 생성하여 사용자에게 제공 할 수 있다. 베이스 모델 추천 화면에는 복수의 후보 신경망 모델에 대한 정보를 각각 나타내는 복수의 UI 엘리먼트 (1711, 1712, 1713, 1714, 1715, 1721, 1722, 1723, 1724, 1725)가 표시될 수 있다. 각각의 UI 엘리먼트는 대 응되는 후보 신경망 모델에 대한 정보를 나타낼 수 있다. 예를 들어, 후보 신경망 모델에 대한 정보는, 후보 신 경망 모델의 명칭, 크기, 레이턴시, 입력 데이터의 크기를 포함할 수 있다. 복수의 UI 엘리먼트(1711, 1712, 1713, 1714, 1715, 1721, 1722, 1723, 1724, 1725)는 사용자에 의해 입력된 타겟 성능 및 신경망 모델의 입력 데이터의 크기에 기초하여 표시될 수 있다. 예를 들어, 타겟 레이턴시는 100(ms)이며, 입력 데이터의 크기는 480 x 480(px)일 수 있다. 복수의 UI 엘리먼트(1711, 1712, 1713, 1714, 1715, 1721, 1722, 1723, 1724, 1725)는 대응되는 레이턴시와 타 겟 레이턴시의 차이가 작은 순서대로 표시될 수 있다. 예를 들어, 제1 UI 엘리먼트들(1711, 1712, 1713, 1714, 1715)에 각각 대응되는 레이턴시는 98(ms), 102(ms), 116(ms), 120(ms), 143(ms)일 수 있다. 제1 UI 엘리먼트 들(1711, 1712, 1713, 1714, 1715)은 제1 방향(d1)을 따라 순서대로 표시될 수 있다. 마찬가지로 제2 UI 엘리 먼트들(1721, 1722, 1723, 1724, 1725)은 제1 방향(d1)을 따라 순서대로 표시될 수 있다. 한편, 복수의 UI 엘리먼트(1711, 1712, 1713, 1714, 1715, 1721, 1722, 1723, 1724, 1725)는 대응되는 레이턴 시가 사용자가 설정한 입력 데이터의 크기와 동일한 제1 UI 엘리먼트들(1711, 1712, 1713, 1714, 1715)과 대응 되는 레이턴시가 사용자가 설정한 입력 데이터의 크기와 상이한 제2 UI 엘리먼트들(1721, 1722, 1723, 1724, 1725)로 구분될 수 있다. 제1 UI 엘리먼트들(1711, 1712, 1713, 1714, 1715) 및 제2 UI 엘리먼트들(1721, 1722, 1723, 1724, 1725)은 서로 다른 영역에 표시될 수 있다. 예를 들어, 제1 UI 엘리먼트들(1711, 1712, 1713, 1714, 1715)은 제1 영역에 표시되며, 제2 UI 엘리먼트들(1721, 1722, 1723, 1724, 1725)은 제2 영 역에 표시될 수 있다. 제1 UI 엘리먼트들(1711, 1712, 1713, 1714, 1715)과 제2 UI 엘리먼트들(1721, 1722, 1723, 1724, 1725)은 동시에 표시될 수 있다. 제1 영역 및 제2 영역은 제1 방향(d1)과 수직 하는 방향을 따라 위치할 수 있다. 도 18은 본 개시의 일 실시 예에 따른 신경망 모델에 대한 정보를 표시하는 방법을 설명하기 위한 도면이다. 도 18을 참조하면, 외부 장치는 복수의 신경망 모델 각각에 대응되는 복수의 UI 엘리먼트(1810, 1820, 1830, 1840, 1850, 1860)를 표시할 수 있다. 외부 장치는 복수의 UI 엘리먼트(1810, 1820, 1830, 1840, 1850, 1860)를 2차원 그래프에 표시할 수 있다. 2차원 그래프는 레이턴시에 대응되는 제1 축 및 정확도에 대응 되는 제2 축에 의해 정의될 수 있다. 제2 축은, mAP(mean Average Precision)에 대응될 수 있다. 외부 장치는 UI 엘리먼트가 사용자에 의해 선택되면 선택된 UI 엘리먼트에 대응되는 신경망 모델에 대한 정보를 표시할 수 있다. 사용자의 선택은 커서(C)를 UI 엘리먼트에 놓거나 UI 엘리먼트를 선택하는 액션(예로, 클릭)등에 의해 이루어질 수 있다. 예를 들어, 제1 UI 엘리먼트에 커서(C)가 놓이면, 외부 장치는 제1 UI 엘리먼트에 대응되는 제1 신경망 모델에 대한 정보를 표시할 수 있다. 복수의 신경망 모델은 베이스 모델들일 수 있다. 예를 들어, 복수의 신경망 모델은 전자 장치가 제2 프로 젝트를 수행하여 생성한 베이스 모델들일 수 있다. 또는, 복수의 신경망 모델은 전자 장치가 제1 프로젝트 를 수행하여 획득한 베이스 모델들일 수 있다. 복수의 신경망 모델은 학습된 신경망 모델들일 수 있다. 예를 들어, 또는, 복수의 신경망 모델은 전자 장치가 제3 프로젝트를 수행하여 획득한 베이스 모델들일 수 있다. 도 19는 본 개시의 일 실시 예에 따른 신경망 모델에 대한 정보를 표시하는 방법을 설명하기 위한 도면이다. 도 19를 참조하면, 외부 장치는 관심 영역(ROI)을 기초로 복수의 신경망 모델 각각에 대응되는 UI 엘리먼 트들(1910, 1920, 1930, 1940, 1950, 1960)을 표시할 수 있다. 외부 장치는 사용자가 설정한 타겟 성능에 기초하여 관심 영역(ROI)을 정의할 수 있다. 외부 장치는 사용자가 설정한 타겟 레이턴시 및 타겟 정확도 에 기초하여 관심 영역(ROI)을 결정할 수 있다. 외부 장치는 사용자가 설정한 타겟 레이턴시로부터 기설정된 시간 범위 및 사용자가 설정한 타겟 정확도로 부터 기설정된 정확도 범위에 의해 정의되는 영역을 관심 영역(ROI)으로 결정할 수 있다. 예를 들어, 사용자가 설정한 타겟 레이턴시는 0.2(s)이고, 기설정된 시간 범위는 -0.05(s)로부터 +0.05(s)일 수 있다. 또한, 사용자 가 설정한 타겟 정확도가 0.03이고, 기설정된 정확도 범위는 -0.025로부터 0.035일 수 있다. 이 때, 외부 장치 는 도 19의 관심 영역(ROI)을 정의할 수 있다. 한편, 사용자가 설정한 타겟 성능이 범위값일 수 있다. 이 때, 외부 장치는 사용자가 설정한 타겟 성능을 확장 없이 관심 영역(ROI)을 정의할 수 있다. 예를 들어, 사용자가 타겟 레이턴시를 0.15(s)로부터 0.25(s)까지, 타겟 정확도를 0.025로부터 0.035까지로 설정할 수 있다. 이 때, 외부 장치는 사용자가 설정 한 타겟 성능을 그대로 반영하여 도 19의 관심 영역(ROI)을 정의할 수 있다. 도 19에서는 관심 영역(ROI)이 2축에 의해 정의되는 것으로 도시하였으나, 이는 일 실시 예에 불과하며, 관심 영역(ROI)은 단일 축을 기초로 정의될 수 있다. 예컨대, 관심 영역(ROI)은 타겟 레이턴시를 기초로 정의될 수 있다. 외부 장치는 타겟 레이턴시로부터 기설정된 시간 범위를 관심 영역(ROI)으로 정의할 수 있다. 외부 장치는 UI 엘리먼트들(1910, 1920, 1930, 1940, 1950, 1960) 중 관심 영역(ROI)에 포함되는 UI 엘리 먼트들(1910, 1920)과 관심 영역(ROI)에 포함되지 않는 UI 엘리먼트들(1930, 1940, 1950, 1960)이 구별되도록 표시할 수 있다. 예를 들어, 외부 장치는 UI 엘리먼트들(1910, 1920)의 시각적 특징(예로, 형상, 색상 등)을 UI 엘리먼트들(1930, 1940, 1950, 1960)의 시각적 특징과 다르게 하여 표시할 수 있다. 여기서, UI 엘리 먼트들(1910, 1920)은 신경망 모델의 타겟 성능으로부터 기설정된 범위 이내의 성능을 갖는 후보 신경망 모델들 에 대응될 수 있다. UI 엘리먼트들(1930, 1940, 1950, 1960)은 신경망 모델의 타겟 성능으로부터 기설정된 범위 밖의 성능을 갖는 후보 신경망 모델들에 대응될 수 있다. 외부 장치는 관심 영역(ROI)에 포함된 UI 엘리먼트들(1910, 1920)을 활성화시킬 수 있다. 이에 따라, UI 엘리먼트들(1910, 1920) 중 적어도 하나가 선택되면, 외부 장치는 선택된 적어도 하나의 UI 엘리먼트에 대 응되는 신경망 모델에 대한 정보를 표시할 수 있다. 예를 들어, 제1 UI 엘리먼트가 선택되면, 외부 장치 는 제1 UI 엘리먼트에 대응되는 제1 신경망 모델에 대한 정보를 표시할 수 있다. 외부 장치는 관심 영역(ROI)에 포함되지 않는 UI 엘리먼트들(1930, 1940, 1950, 1960)을 비활성화시킬 수 있다. 이에 따라, UI 엘리먼트들(1930, 1940, 1950, 1960)은 선택 불가능해질 수 있다. 도 20은 본 개시의 일 실시 예에 따른 신경망 모델의 성능을 획득하는 방법을 설명하기 위한 도면이다. 도 20을 참조하면, 전자 장치는 디바이스 팜을 이용하여 신경망 모델의 성능을 획득할 수 있 다. 신경망 모델은 베이스 모델 또는 학습된 모델일 수 있다. 디바이스 팜은 다양한 디바이스들에관련된 정보를 포함할 수 있다. 전자 장치는 사용자가 입력한 타겟 디바이스에 대한 정보에 기초하여 디바 이스 팜에서 타겟 디바이스를 식별할 수 있다. 전자 장치는 신경망 모델을 타겟 디바이 스에서 실행시켜 신경망 모델의 성능을 측정할 수 있다. 디바이스 팜은 전자 장치에 포 함된 데이터베이스로 구현될 수 있다. 전자 장치는 디바이스 팜을 이용하여 획득한 신경망 모델의 성능에 기초하여 룩-업 테이블을 생성할 수 있다. 전술한 바와 같이, 룩-업 테이블은 복수의 신경망 모델의 성능을 비롯한 복수의 신경망 모델에 대한 정보를 포함할 수 있다. 전자 장치는 신경망 모델의 성능에 기초하여 신경망 모델을 압축할 수 있다. 예를 들어, 전자 장치는 신경망 모델의 레이턴시에 기초하여 신경망 모델의 압축을 위한 설정값을 획득할 수 있다. 도 21은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 도면이다. 도 21을 참조하면, 전자 장치는 외부 장치로부터 신경망 모델이 실행될 타겟 디바이스에 대한 정보 및 타 겟 디바이스에서 실행될 때 신경망 모델의 타겟 성능을 수신할 수 있다(S2110). 타겟 성능은, 타겟 레이턴시 및 타겟 정확도를 포함할 수 있다. 전자 장치는 타겟 디바이스에 대한 정보 및 타겟 성능에 기초하여 복수의 후보 신경망 모델에 대한 정보를 획득할 수 있다(S2120). 후보 신경망 모델은, 베이스 모델 또는 학습된 모델일 수 있다. 예를 들어, 전자 장치 는 프로젝트를 수행하여 후보 신경망 모델을 획득할 수 있다. 전자 장치는 타겟 성능에 기초하여 복수의 후보 신경망 모델에 대한 정보를 표시하도록 외부 장치로 명령 을 전송할 수 있다(S2130). 전자 장치가 전송한 명령에 기초하여 복수의 후보 신경망 모델에 대한 정보가 표시되는 방법은 도 17 내지 도 19를 통해 명확히 이해될 수 있을 것이다. 도 22는 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 도면이다. 도 22를 참조하면, 전자 장치는 모델 획득 유닛, 압축 유닛 및 런처 유닛을 포함할 수 있다. 모델 획득 유닛, 압축 유닛 및 런처 유닛은 소프트웨어로 모듈로 구현될 수 있다. 프 로세서는 각 유닛과 관련된 인스트럭션을 메모리에 로딩하여 실행할 수 있다. 모델 획득 유닛은 데이터셋 및 타겟 디바이스 정보(또는 타겟 디바이스에 대한 정보)에 기초 하여 학습된 학습 모델을 획득할 수 있다. 예를 들어, 모델 획득 유닛은 제1 프로젝트를 수행하여 제1 학습된 모델을 획득할 수 있다. 모델 획득 유닛은 압축 유닛로부터 압축 모델을 수신할 수 있다. 모델 획득 유닛은 압축 모델에 기초하여 설정된 제3 프로젝트를 수행하여 재학습 모델을 획득할 수 있다. 모델 획득 유닛은 학습 모델을 압축 유닛 또는 런처 유닛로 전송할 수 있다. 예를 들 어, 모델 획득 유닛은 제1 학습된 모델을 압축 유닛로 전송할 수 있다. 모델 획득 유닛은 재 학습 모델을 런처 유닛로 전송할 수 있다. 모델 획득 유닛과 관련된 전자 장치의 기타 다른 동작들(예로, 프로젝트를 수행하는 동작)은 상술한 바 그 상세한 설명은 생략하도록 한다. 압축 유닛은 입력된 모델에 대해 압축을 수행하여 경량화된 모델을 출력할 수 있다. 압축 유닛은 학습 모델 또는 신경망 모델을 압축하여 압축 모델을 생성할 수 있다. 신경망 모델은 모델 획득 유닛에 의해 획득되지 않은 소정의 모델일 수 있다. 압축 유닛은 압축 모델을 런 처 유닛 또는 모델 획득 유닛로 전송할 수 있다. 압축 유닛은 사용자가 설정한 압축 설정 정보에 기초하여 입력된 모델을 압축할 수 있다. 압축 설정 정보 는, 압축 모드, 압축 방법, 압축 압축을 위한 설정값, 또는 입력된 모델에 포함된 복수의 채널 중 압축 타겟을 결정하기 위한 기준 정보 중 적어도 하나를 포함할 수 있다. 압축 모드는, 입력된 모델의 압축을 위해 사용자가 설정한 모델 압축을 위한 설정값을 기초로 입력된 모델을 압축하는 제1 압축 모드를 포함할 수 있다. 압축 모드 는, 입력된 모델에 포함된 블록에 대한 정보를 사용자에게 제공하고 블록의 압축을 위해 사용자가 설정한 블록 압축을 위한 설정값을 기초로 학습 모델을 압축하는 제2 압축 모드를 포함할 수 있다. 런처 유닛은 타겟 디바이스에 디플로이(deploy)될 수 있도록 입력된 모델에 대응되는 다운로드 데이터 를 출력할 수 있다. 런처 유닛로 입력되는 모델은 압축 모델, 신경망 모델 및 재학습모델을 포함할 수 있다. 런처 유닛은 타겟 디바이스 정보를 기초로 입력된 모델에 대해 양자화를 수행할 수 있다. 타겟 디 바이스 정보는 타겟 디바이스가 지원하는 데이터 타입(예로, 8비트 정수형)을 포함할 수 있다. 런처 유닛 은 입력된 모델의 데이터 타입을 타겟 디바이스가 지원하는 데이터 타입으로 변환할 수 있다. 런처 유닛은 입력된 모델에 대해 캘리브레이션을 수행할 수 있다. 런처 유닛은 사용자가 입력한 코 드 또는 미리 저장된 코드에 기초하여 캘리브레이션을 수행할 수 있다. 예를 들어, 런처 유닛은 양자화 간격을 조절할 수 있다. 런처 유닛은 조절된 양자화 간격을 기초로 양자화를 수행할 수 있다. 이에 따라, 입력된 모델 또는 양자화된 모델의 파라미터 값(예로, 가중치)이 변경될 수 있다. 런처 유닛은 사용자에게 다운로드 데이터를 제공할 수 있다. 다운로드 데이터는, 다운로드 파일 또는 다운로드 패키지를 의미할 수 있다. 사용자가 다운로드 데이터를 요청하면, 런처 유닛은 다운로드 데이터를 사용자 장치에 전송할 수 있다. 이에 따라 사용자 장치에는 타겟 디바이스에 최적화된 신경망 모델이 설치될 수 있다. 도 23은 본 개시의 일 실시 예에 따른 제1 압축 모드를 설명하기 위한 도면이다. 각 단계는 프로세서에 의 해 수행될 수 있다. 도 23을 참조하면, 전자 장치는 베이스 모델의 압축을 위해 사용자가 설정한 모델 압축을 위한 설정값을 획득할 수 있다(S2310). 예를 들어, 모델 압축을 위한 설정값은, 프루닝 정도를 나타내는 프루닝 비율(pruning ratio) 및 랭크(rank)의 수를 결정하기 위한 값을 포함할 수 있다. 베이스 모델은 모델 획득 유닛에 의해 획득된 학습 모델 및 신경망 모델을 포함할 수 있다. 전자 장치는 베이스 모델에 포함된 복수의 블록 중 압축 가능한 복수의 타겟 블록을 식별할 수 있다 (S2320). 블록(block)은 적어도 하나의 레이어를 포함하는 레이어 셋일 수 있다. 블록은 다양한 유형의 레이어 를 포함할 수 있다. 예를 들어, 블록은 컨볼루션 레이어, 활성화 함수, 정규화 함수 및 사칙 연산자(예로, 덧셈 연산자 또는 곱셈 연산자)를 포함할 수 있다. 전자 장치는 압축 불가능하다고 미리 정의된 블록을 제외한 나머지 블록을 타겟 블록으로 식별할 수 있다. 압축 불가능하다고 미리 정의된 블록은, 활성화 함수 또는 정규화 함수를 포함하는 블록을 포함할 수 있다. 또 한, 압축 불가능하다고 미리 정의된 블록은 출력 채널이 사칙 연산자와 직접 연결된 블록을 포함할 수 있다. 여 기서, 출력 채널이 사칙 연산자와 직접 연결된다는 것은, 출력 채널과 사칙 연산자 사이에 가중치를 갖는 블록 이 존재하지 않는 것을 의미할 수 있다. 가령, 사칙 연산자와 바로 이전에 위치하는 블록은 압축 불가능한 블록 일 수 있다. 전자 장치는 모델 압축을 위한 설정값 및 기정의된 알고리즘에 기초하여 복수의 타겟 블록에 각각 대응되 는 복수의 제1 블록 압축을 위한 설정값을 획득할 수 있다(S2330). 기정의된 알고리즘은, 이른바 LAMP(Layer- Adaptive Sparsity for the Magnitude-based Pruning) 및 VBMF(Variational Bayesian matrix factorization) 를 포함할 수 있다. 블록 압축을 위한 설정값은, 개별 블록의 프루닝 정도를 나타내는 프루닝 비율(pruning ratio) 및 랭크(rank)의 수를 포함할 수 있다. 본 개시에서, 모델 압축을 위한 설정값은 모델 전체에 대응되는 값을 의미하며, 블록 압축을 위한 설정값은 모델에 포함된 개별 블록에 대응되는 값을 의미할 수 있다. 전자 장치는 디바이스 팜으로부터 획득된 레이턴시에 기초하여 블록 압축을 위한 설정값을 획득할 수 있다. 예를 들어, 전자 장치는 블록에 대응되는 레이턴시가 클수록 블록에 적용할 압축률을 크게 획득할 수 있다. 또한, 전자 장치는 디바이스 팜으로부터 획득된 레이턴시를 이용하여 기정의된 알고리즘에 기초 하여 획득한 블록 압축을 위한 설정값을 조절할 수 있다. 전자 장치는 복수의 제1 블록 압축을 위한 설정값을 기초로 복수의 타겟 블록을 압축할 수 있다(S2340). 이에 따라, 전자 장치는 압축 모델을 획득할 수 있다. 예를 들어, 전자 장치는 복수의 타겟 블록에 대해 프루닝을 수행할 수 있다. 또는, 전자 장치는 복수의 타겟 블록에 대해 필터 분해(또는 텐서 분해)를 수행할 수 있다. 전자 장치는 복수의 제1 블록 압축을 위한 설정값을 사용자에게 제공할 수 있다. 예를 들어, 전자 장치 는 복수의 블록 압축을 위한 설정값이 사용자 장치에 표시될 수 있도록 복수의 제1 블록 압축을 위한 설 정값 및 복수의 제1 블록 압축을 위한 설정값의 표시와 관련된 명령을 사용자 장치로 전송할 수 있다. 이에 따 라, 사용자 장치는 복수의 제1 블록 압축을 위한 설정값을 표시할 수 있다.사용자는 복수의 제1 블록 압축을 위한 설정값 중 적어도 하나의 제1 블록 압축을 위한 설정값을 수정할 수 있다. 전자 장치는 사용자 장치로부터 적어도 하나의 제1 블록 압축을 위한 설정값을 수정하는 사용자 명 령을 수신할 수 있다. 전자 장치는 사용자 명령에 기초하여 복수의 타겟 블록을 압축할 수 있다. 제1 압축 모드에서, 사용자는 단일의 모델 압축을 위한 설정값만 입력하면 경량화된 모델을 획득할 수 있다. 따 라서, 사용자 편의성이 향상될 수 있다. 다른 실시 예에서, 사용자는 복수의 압축 방법 각각에 대응되는 복수의 모델 압축을 위한 설정값을 입력할 수 있다. 예컨대, 사용자는 프루닝에 대응되는 제1 모델 압축을 위한 설정값 및 필터 분해에 대응되는 제2 모델 압축을 위한 설정값을 입력할 수 있다. 도 24는 본 개시의 일 실시 예에 따른 제1 압축 모드의 압축설정화면이다. 도 24를 참조하면, 압축설정화면은 압축 모델의 명칭을 입력받는 제1 영역, 압축에 대한 사용자 메 모를 입력받는 제2 영역, 압축 대상이 되는 베이스 모델을 입력받는 제3 영역 및 모델 압축을 위한 설정값을 입력받는 제4 영역을 포함할 수 있다. 압축설정화면은 사용자 장치에 표시될 수 있다. 사용자 장치는 압축설정화면에 입력되는 정보를 전자 장치로 전송할 수 있다. 전자 장치는 압 축설정화면에 입력되는 정보를 기초로 베이스 모델에 포함된 복수의 타겟 블록에 대응되는 복수의 블록 압축을 위한 설정값을 획득할 수 있다. 전자 장치는 제3 영역에서 선택된 모델을 베이스 모델로 식 별할 수 있다. 제3 영역에는 모델 획득 유닛에 의해 획득된 학습 모델 및 신경망 모델(223 5)을 포함한 모델 리스트가 제공될 수 있다. 전자 장치는 제4 영역에서 사용자가 설정한 압축율을 기초로 복수의 타겟 블록에 대응되는 복수의 압축율을 획득할 수 있다. 전자 장치는 사용자가 설정한 모델 압축을 위한 설정값을 기초로 미리 정해진 압축 방법에 대응되는 모델 압축을 위한 설정값을 획득할 수 있다. 미리 정해진 압축 방법은 프루닝 및/또는 필터 분해를 포함할 수 있다. 예를 들어, 전자 장치는 사용자가 설정한 압축율을 기초로 타겟 블록에 대응되는 프루닝 비율을 획득할 수 있다. 또는, 전자 장치는 사용자가 설정한 압축율을 기초로 타겟 블록에 대응되는 랭크의 수를 획득할 수 있다. 미리 정해진 압축 방법은 사용자에 의해 설정될 수 있다. 미리 정해진 압축 방법은 복수 개일 수 있다. 예컨대, 전자 장치는 사용자가 설정한 압축율을 기초로 타겟 블록에 대응되는 프루닝 비율 및 랭크의 수를 획득할 수 있다. 전자 장치는 베이스 모델에 대해 프루닝 및 필터 분해를 수행할 수 있다. 한편, 사용자는 압축 방법 및 모델 압축을 위한 설정값을 함께 설정할 수 있다. 예를 들어, 사용자는 압축 방법 으로 프루닝을 선택하고, 베이스 모델에 대응되는 프루닝 비율을 입력할 수 있다. 이 때, 전자 장치는 베 이스 모델에 대응되는 프루닝 비율에 기초하여 베이스 모델에 포함된 타겟 블록에 대응되는 프루닝 비율을 획득 할 수 있다. 도 24에 도시되지 않았으나, 압축설정화면은 압축 방법을 선택하는 사용자 명령을 획득하기 위한 압축방 법선택영역을 포함할 수 있다. 또는, 압축방법선택영역은 별도의 화면에서 제공될 수 있다. 도 25는 본 개시의 일 실시 예에 따른 제2 압축 모드를 설명하기 위한 도면이다. 각 단계는 프로세서에 의 해 수행될 수 있다. 도 25를 참조하면, 전자 장치는 베이스 모델을 분석하여 베이스 모델의 프로파일 정보를 획득할 수 있다 (S2510). 베이스 모델의 프로파일 정보는, 베이스 모델에 포함된 각 블록에 대한 정보를 포함할 수 있다. 각 블 록에 대한 정보는, 블록의 식별 정보, 블록에 대응되는 레이턴시, 블록에 포함된 채널의 수 및 블록에 포함된 커널(kernel)의 크기를 포함할 수 있다. 전자 장치는 베이스 모델의 프로파일 정보를 사용자에게 제공할 수 있다(S2520). 전자 장치는 베이스 모델의 프로파일 정보를 사용자 장치로 전송할 수 있다. 사용자 장치는 베이스 모델의 프로파일 정보를 표시할 수 있다. 전자 장치는 베이스 모델에 포함된 복수의 타겟 블록의 압축을 위해 사용자가 설정한 복수의 제2 블록 압 축을 위한 설정값을 획득할 수 있다(S2530). 복수의 제2 블록 압축을 위한 설정값은 각각 복수의 타겟 블록에 대응될 수 있다. 전자 장치는 복수의 제2 블록 압축을 위한 설정값을 기초로 복수의 타겟 블록을 압축할 수 있다(S2540). 예를 들어, 전자 장치는 복수의 타겟 블록에 대해 프루닝 또는 필터 분해를 수행할 수 있다. 이에 따라,전자 장치는 경량화 된 모델을 획득할 수 있다. 도 26은 본 개시의 일 실시 예에 따른 제2 압축 모드의 압축설정화면이다. 도 26을 참조하면, 압축설정화면은 압축 모델의 명칭 및 메모를 입력받는 제1 영역, 압축 대상이 되는 베이스 모델을 입력받는 제2 영역 및 압축 방법을 입력받는 제3 영역을 포함할 수 있다. 제3 영역에는 선택된 압축 방법에 관한 디스크립션이 표시될 수 있다. 압축 방법은, 프루닝 및 필터 분해를 포함할 수 있다. 프루닝은, 크리테리아를 기초로한 제1 유형의 프루닝과 사용자가 설정하는 인덱스를 기초로하는 제2 유형의 프루닝을 포함할 수 있다. 필터 분해는 터커 분해(tucker decomposition) 및 CP 분해를 포함할 수 있다. 압축설정화면은 사용자 장치에 표시될 수 있다. 사용자 장 치는 압축설정화면에 입력되는 사용자 입력과 관련된 정보를 전자 장치로 전송할 수 있다. 전자 장 치는 사용자가 선택한 베이스 모델 및 압축 방법을 기초로 베이스 모델에 대한 압축을 수행할 수 있다. 도 27은 본 개시의 일 실시 예에 따른 블록 압축을 위한 설정값을 설정하기 위한 화면이다. 도 27을 참조하면, 블록 압축을 위한 설정값을 설정하기 위한 화면은 베이스 모델에 대한 정보가 표시되 는 제1 화면 및 블록 압축을 위한 설정값을 입력받는 제2 화면을 포함할 수 있다. 제1 화면(271 0)에는 베이스 모델의 아키텍처가 표시될 수 있다. 또한, 제1 화면에는 각 블록에 대응되는 레이턴시, 모 델에 포함된 채널의 수가 표시될 수 있다. 사용자 장치는 제2 화면에서 블록 압축을 위한 설정값을 설정하는 사용자 입력을 획득할 수 있다. 예를 들어, 사용자 장치는 제1 블록(block 1)에 대응되는 제1 블록 압축을 위한 설정값(예로, 0.5)을 획득할 수 있 다. 사용자 장치는 제1 블록 압축을 위한 설정값을 전자 장치로 전송할 수 있다. 전자 장치는 제1 블 록 압축을 위한 설정값을 기초로 제1 블록을 압축할 수 있다. 이와 같이, 제2 압축 모드에서, 사용자는 각 블록에 대해 자신이 원하는 블록 압축을 위한 설정값을 설정하고, 각 블록이 자신이 원하는 만큼 압축된 압축 모델을 획득할 수 있다. 이에 따라, 사용자의 만족감이 향상될 수 있다. 도시되지 않았으나, 압축설정화면 또는 화면에는 압축 정책을 선택받는 UI 엘리먼트가 표시될 수 있다. 압축 정책이란, 압축을 어떻게 수행할 것인지에 관한 규칙을 의미할 수 있다. 예컨대, 압축 방법이 프루 닝인 경우, 압축을 위한 설정값이 동일하더라도 압축 정책에 따라 프루닝되는 채널이 달라질 수 있다. 도 28은 본 개시의 일 실시 예에 따른 압축 정책을 설명하기 위한 도면이다. 구체적으로, 도 28은 3가지 압축 정책별로 프루닝되는 노드를 나타낸다. 도 28을 참조하면, 블록은 제1 레이어 및 제2 레이어를 포함할 수 있다. 제1 레이어는 복수 의 노드(N11, N12, N13, N14, N15)를 포함할 수 있다. 제2 레이어는 복수의 노드(N21, N22, N23, N24, N25)를 포함할 수 있다. 노드(N11) 및 노드(N21)는 동일한 인덱스를 갖는다. 노드(N12) 및 노드(N22)는 동일한 인덱스를 갖는다. 노드(N13) 및 노드(N23)는 동일한 인덱스를 갖는다. 노드(N14) 및 노드(N24)는 동일한 인덱스 를 갖는다. 노드(N15) 및 노드(N25)는 동일한 인덱스를 갖는다. 각 노드(또는 뉴런)에 표시된 숫자는 각 노드의 중요도를 나타낸다. 예를 들어, 노드(N11)의 중요도는 0.08이고, 노드(N12)의 중요도는 0.14이다. 표시된 중요도는 정규화된 값일 수 있다. 전자 장치는 사용자 가 선택한 압축 방법에 기초하여 각 노드의 중요도를 산출할 수 있다. 예를 들어, 제3 영역에서 'L2 Norm Pruning'이 선택되면, 전자 장치는 L2 Norm에 기초하여 각 노드의 중요도를 산출할 수 있다. 전자 장치는 압축 정책 및 각 노드의 중요도를 기초로 프루닝 할 노드를 결정할 수 있다. 이하에서는 여러 가지 압축 정책에 따른 프루닝 방법에 대해 설명한다. 압축 정책이 제1 정책(average)인 경우, 전자 장치는 각 채널에서 중요도가 낮은 순서대로 두 노드를 식별 할 수 있다. 예를 들어, 전자 장치는 제1 채널에서 노드(N11) 및 노드(N12)를 식별할 수 있다. 전자 장치는 제2 채널에서 노드(N22) 및 노드(N24)를 식별할 수 있다. 전자 장치는 식별된 노드 및 식별된 노드와 동일한 인덱스를 갖는 노드의 평균값을 산출할 수 있다. 예를 들어, 전자 장치는 노드(N1 1)의 중요도와 노드(N21)의 중요도의 평균값을 산출할 수 있다. 또한, 전자 장치는 노드(N12)의 중요도와 노드(N22)의 중요도의 평균값을 산출할 수 있다. 전자 장치는 평균값이 가장 작은 노드 셋에 포함된 노드 들을 프루닝할 수 있다. 예를 들어, 전자 장치는 노드(N11)와 노드(N21)를 프루닝할 수 있다. 또한, 전자장치는 노드(N12)와 노드(N22)를 프루닝할 수 있다. 압축 정책이 제2 정책(intersection)인 경우, 전자 장치는 각 채널에서 중요도가 낮은 순서대로 두 노드를 식별할 수 있다. 예를 들어, 전자 장치는 제1 채널에서 노드(N11) 및 노드(N12)를 식별할 수 있다. 전자 장치는 제2 채널에서 노드(N22) 및 노드(N24)를 식별할 수 있다. 전자 장치는 식별된 노 드들 중에서 동일한 인덱스를 갖는 노드들을 프루닝할 수 있다. 예를 들어, 전자 장치는 노드(N12) 및 노 드(N22)를 프루닝할 수 있다. 압축 정책이 제3 정책(union)인 경우, 전자 장치는 각 채널에서 중요도가 낮은 순서대로 두 노드를 식별할 수 있다. 예를 들어, 전자 장치는 제1 채널에서 노드(N11) 및 노드(N12)를 식별할 수 있다. 전자 장 치는 제2 채널에서 노드(N22) 및 노드(N24)를 식별할 수 있다. 전자 장치는 식별된 노드들 각 각과 동일한 인덱스를 갖는 노드들을 프루닝할 수 있다. 예를 들어, 전자 장치는 노드(N11) 및 노드(N11) 와 인덱스가 동일한 노드(N21)를 프루닝할 수 있다. 전자 장치는 노드(N12) 및 노드(N22)를 프루닝할 수 있다. 전자 장치는 노드(N24) 및 노드(N24)와 인덱스가 동일한 노드(N14)를 프루닝할 수 있다. 한편, 도 28에서는 각 채널에서 식별되는 노드의 개수가 두 개인 것을 예로 들었으나, 이에 한정되는 것은 아니 다. 예컨대, 전자 장치는 각 채널에서 중요도가 낮은 순서대로 세 개 또는 그 이상의 노드를 식별할 수 있 다. 도 29는 본 개시의 일 실시 예에 따른 신경망 모델의 압축 방법을 나타내는 순서도이다. 도 29를 참조하면, 전자 장치는 학습된 모델 및 학습된 모델을 압축하기 위한 압축 방법을 획득할 수 있다 (S2910). 예를 들어, 전자 장치는 모델 획득 유닛에 기초하여 학습 모델을 획득할 수 있다. 또는, 전자 장치는 신경망 모델을 획득할 수 있다. 전자 장치는 압축 방법에 기초하여 학습된 모델에 포함된 복수의 블록 중 압축가능 블록 및 압축불가능 블 록을 식별할 수 있다(S2920). 본 개시에서 압축불가능 블록이란, 압축을 수행할 수 없는 블록뿐만 아니라 압축 을 수행할 수는 있으나 압축을 수행할 경우 압축된 모델의 성능이 임계값보다 작아지는 블록을 포함할 수 있다. 압축 방법에 따라 학습된 모델의 압축 가능 여부를 판단하는 기준이 다를 수 있다. 압축 방법은 프루닝 및 필터 분해를 포함할 수 있다. 압축 방법이 프루닝일 때, 전자 장치는 활성화 함수, 정규화 함수 및 출력 채널이 사칙 연산자와 직접 연 결된 블록을 압축불가능 블록으로 식별할 수 있다. 여기서, 출력 채널이 사칙 연산자와 직접 연결된다는 것은, 해당 블록과 사칙 연산자 사이에 가중치를 갖는 다른 블록이 존재하지 않는 것을 의미할 수 있다. 예를 들어, 제3 블록, 제4 블록 및 제5 블록이 순서대로 직렬적으로 연결될 수 있다. 제4 블록은 활성화 함수 또는 정규화 함수이고, 제5 블록은 사칙 연산자일 수 있다. 이 때, 제3 블록은 '출력 채널이 사칙 연산자와 직접 연결된 블 록'일 수 있다. 따라서, 전자 장치는 제3 블록을 압축 불가능한 블록이라 판단할 수 있다. 압축 방법이 필터 분해일 때, 전자 장치는 컨볼루션 레이어를 포함하는 블록을 압축가능 블록이라 식별할 수 있다. 전자 장치는 복수의 블록의 연결 관계를 나타내는 학습된 모델의 구조를 제1 화면에 표시하되 압축가능 블 록과 압축불가능 블록이 시각적으로 구별되도록 표시하고, 압축가능 블록의 압축을 위한 설정값을 입력받는 인 풋 필드를 제2 화면에 표시하도록 사용자 장치로 명령을 전송할 수 있다(S2930). 사용자 장치는 전자 장치(10 0)로부터 수신한 명령을 기초로 학습된 모델의 구조를 제1 화면에 표시할 수 있다. 또한, 사용자 장치는 압축가 능 블록의 압축을 위한 설정값을 입력받는 인풋 필드를 제2 화면에 표시할 수 있다. 사용자 장치는 제1 화면 및 제2 화면을 동시에 출력할 수 있다. 학습된 모델의 구조는, 학습된 모델에 포함된 복수의 블록 각각에 대응되는 복수의 UI 엘리먼트 간의 연결 관계 를 나타낼 수 있다. 복수의 UI 엘리먼트는 복수의 블록 각각에 대한 정보를 나타낼 수 있다. 복수의 블록 각각 에 대한 정보는, 복수의 블록 각각의 식별 정보 및 복수의 블록 각각에 대응되는 복수의 레이턴시를 포함할 수 있다. 예를 들어, 학습된 모델의 구조는, 복수의 UI 엘리먼트가 노드로 표현되는 그래프 형태로 표현될 수 있다. 한편, 전자 장치는 학습된 모델이 실행될 타겟 디바이스를 포함하는 디바이스 팜을 이용하여 복수의 블록 각각에 대응되는 복수의 레이턴시를 획득할 수 있다. 예를 들어, 타겟 디바이스가 제1 디바이스로 선택되면, 사 용자 장치는 제1 디바이스에 관한 정보를 전자 장치로 전송할 수 있다. 전자 장치는 제1 디바이스에관한 정보에 기초하여 디바이스 팜에서 제1 디바이스를 식별할 수 있다. 전자 장치는 제1 디바이스에서 학 습된 모델을 실행시켜 복수의 블록 각각에 대응되는 복수의 레이턴시를 산출할 수 있다. 전자 장치는 인풋 필드에 사용자가 입력한 블록 압축을 위한 설정값을 기초로 학습된 모델을 압축할 수 있 다(S2940). 예를 들어, 전자 장치는 사용자가 입력한 프루닝 비율에 기초하여 학습된 모델에 대한 프루닝 을 수행할 수 있다. 한편, 제1 화면에 표시된 압축가능 블록에 대응되는 제1 UI 엘리먼트가 선택되면, 전자 장치는 제2 화면에 표시된 압축가능 블록에 대응되는 인풋 필드를 활성화하도록 사용자 장치로 명령을 전송할 수 있다. 이에 따라, 사용자는 활성화된 인풋 필드에 압축을 위한 설정값을 입력할 수 있다. 또한, 제1 UI 엘리먼트가 선택되면, 전 자 장치는 제1 화면에 선택된 제1 UI 엘리먼트에 대응되는 압축가능 블록에 관한 상세 정보를 표시하도록 사용자 장치로 명령을 전송할 수 있다. 제1 화면에 표시된 압축불가능 블록에 대응되는 제2 UI 엘리먼트가 선택되면, 전자 장치는 제1 화면에 압 축불가능 블록에 관한 상세 정보를 표시하도록 사용자 장치로 명령을 전송할 수 있다. 압축불가능 블록에 관한 상세 정보는, 압축불가능 블록에 포함된 채널의 개수 또는 커널의 크기 중 적어도 하나를 포함할 수 있다. 도 29에서는 사용자 장치가 전자 장치로부터 수신된 명령에 기초하여 제1 화면 및 제2 화면을 표시하는 것으로 설명하였다. 다른 실시 예에서, 사용자 장치는 전자 장치로부터 수신되는 명령 없이 사용자 입력에 기초하여 제1 화면 및 제2 화면을 표시할 수도 있다. 예로, 제1 화면에 표시된 압축 가능한 제1 블록에 대응되 는 UI 엘리먼트를 선택하는 사용자 입력이 획득되면, 사용자 장치는 제2 화면에 표시된 제1 블록에 대응되는 제 1 인풋 필드를 활성화할 수 있다. 이하에서는 제1 화면 및 제2 화면에 대해 상세히 설명하도록 한다. 도 30은 본 개시의 일 실시 예에 따른 블록 압축을 위한 설정값을 설정하기 위한 화면이다. 화면은 압축 모드가 제2 압축 모드일 때 사용자 장치에 표시될 수 있다. 사용자는 화면에 기초하여 압축할 학습 모델 에 포함된 블록에 대응되는 블록 압축을 위한 설정값을 입력할 수 있다. 도 30을 참조하면, 화면은 제1 화면 및 제2 화면을 포함할 수 있다. 사용자 장치는 학습된 모델의 구조를 제1 화면에 표시할 수 있다. 예를 들어, 학습된 모델의 구조는 학습된 모델에 포함된 복수 의 블록(add, conv1, conv2, relu, hardsigmoid, mul, conv3)에 각각 대응되는 복수의 UI 엘리먼트(3011, 3012, 3013, 3014, 3015, 3016, 3017)가 노드로 표현되는 계층 구조일 수 있다. 학습된 모델의 구조는 복수의 UI 엘리먼트(3011, 3012, 3013, 3014, 3015, 3016, 3017) 간의 연결 관계를 나타낼 수 있다. 사용자 장치는 복수의 UI 엘리먼트(3011, 3012, 3013, 3014, 3015, 3016, 3017)를 제1 화면에 표시할 수 있다. 복수의 UI 엘리먼트(3011, 3012, 3013, 3014, 3015, 3016, 3017) 각각은 대응되는 블록에 대한 정보를 나타낼 수 있다. 예를 들어, 제1 블록(add)에 대응되는 제1 UI 엘리먼트는 제1 블록(add)에 대응되는 레 이턴시를 나타내는 인디케이터(LI1)를 포함할 수 있다. 이와 같이, 블록에 대응되는 레이턴시가 화면에 표시되면, 사용자는 블록 압축을 위한 설정값을 결정할 때 표시된 레이턴시를 참고할 수 있다. 즉, 각 블록의 압축을 위한 설정값은 각 블록에 대응되는 레이턴시 기초하여 결정될 수 있다. 또한, 사용자의 편의성이 향상될 수 있다. 사용자 장치는 압축가능 블록 및 압축불가능 블록을 구분하여 표시할 수 있다. 도 30에서, 전자 장치는 제 1 블록(add), 제6 블록(mul) 및 제7 블록(conv3)을 압축가능 블록으로 판단할 수 있다. 전자 장치는 제2 블록(conv1), 제3 블록(conv2), 제4 블록(relu) 및 제5 블록(hardsigmoid)을 압축불가능 블록으로 판단할 수 있다. 구체적으로, 제2 블록(conv1), 제3 블록(conv2)의 출력 채널은 곱셈 연산자인 제6 블록(mul)과 직접 연결 되므로 압축불가능 블록으로 판단될 수 있다. 제4 블록(relu) 및 제5 블록(hardsigmoid)은 활성화 함수이므로 압축불가능 블록으로 판단될 수 있다. 예를 들어, 압축가능 블록들(add, mul, conv3)에 대응되는 UI 엘리먼트들(3011, 3016, 3017)은 체크박스들 (CB1, CB6, CB7)을 포함할 수 있다. 압축불가능 블록들(conv1, conv2, relu, hardsigmoid)에 대응되는 UI 엘리 먼트들(3012, 3013, 3014, 3015)는 체크박스를 포함하지 않을 수 있다. UI 엘리먼트들(3011, 3016, 3017)은 UI 엘리먼트들(3012, 3013, 3014, 3015)보다 시인성이 좋게 표시될 수 있다. 예를 들어, UI 엘리먼트들(3011, 3016, 3017)은 UI 엘리먼트들(3012, 3013, 3014, 3015)보다 밝게 표시될 수 있다. 또는, UI 엘리먼트들(3011, 3016, 3017)은 실선으로 표시되고 UI 엘리먼트들(3012, 3013, 3014, 3015)은 점선으로 표시될 수 있다.사용자 장치는 압축가능 블록에 대한 정보를 제2 화면에 표시할 수 있다. 예를 들어, 사용자 장치는 압축 가능 블록들(add, mul, conv3) 각각의 명칭 및 출력 채널 개수를 표시할 수 있다. 사용자 장치는 압축가능 블록 의 압축을 위한 설정값을 입력받는 인풋 필드를 표시할 수 있다. 여기서, 압축을 위한 설정값은 상술한 블록 압축을 위한 설정값을 의미한다. 예를 들어, 사용자 장치는 압축가능 블록들(add, mul, conv3) 각각에 대응되는 인풋 필드들(IF1, IF2, IF3)을 표시할 수 있다. 인풋 필드들(IF1, IF2, IF3)은 프루닝 비율을 입력받을 수 있다. 또한, 사용자 장치는 압축가능 블록들(add, mul, conv3) 각각을 선택하기 위한 체크박스들(CB11, CB12, CB13)을 표시할 수 있다. 도 31은 본 개시의 일 실시 예에 따른 블록 압축을 위한 설정값을 설정하기 위한 화면이다. 도 31을 참조하면, 사용자 장치는 제1 화면을 통해 획득된 사용자 입력에 기초하여 제2 화면을 표 시할 수 있다. 예를 들어, 제1 UI 엘리먼트 또는 제1 블록(add)이 사용자에 의해 선택될 수 있다. 예를 들어, 사용자는 체크박스(CB1)를 클릭할 수 있다. 사용자 장치는 선택된 제1 블록(add)에 대응되는 체크박스 (CB11)에 체크마크를 표시하고, 제1 인풋 필드(IF1)를 활성화할 수 있다. 제1 UI 엘리먼트의 선택은 해제 될 수 있다. 이 때, 사용자 장치는 제1 인풋 필드(IF1)를 비활성화할 수 있다. 사용자 장치는 제2 화면을 통해 획득된 사용자 입력에 기초하여 제1 화면을 표시할 수 있다. 예를 들어, 제1 블록(add)에 대응되는 체크박스(CB11)가 선택되면, 사용자 장치는 제1 블록(add)에 대응되는 체크박 스(CB1)에 체크마크를 표시할 수 있다. 체크박스(CB11)의 선택이 해제되면, 사용자 장치는 체크박스(CB1)에 표 시된 체크마크를 제거할 수 있다. 도 32는 본 개시의 일 실시 예에 따른 블록 압축을 위한 설정값을 설정하기 위한 화면이다. 도 32를 참조하면, 사용자 장치는 사용자에 의해 선택된 블록과 관련된 상세 정보를 제공할 수 있다. 블록과 관 련된 상세 정보는, 블록에 포함된 채널의 개수, 커널의 크기, 스트라이드 또는 레이턴시 중 적어도 하나를 포함 할 수 있다. 예를 들어, 제7 블록(conv3)이 선택될 수 있다. 이 때, 사용자 장치는 제7 블록(conv3)과 관련된 상세 정보를 제1 화면에 표시할 수 있다. 한편, 사용자는 압축불가능 블록을 선택할 수 있다. 예를 들어, 사용자는 제2 블록(conv1)을 선택할 수 있다. 이 때, 사용자 장치는 제2 블록(conv1)에 관한 상세 정보를 제1 화면에 표시할 수 있다. 한편, 도 30 내지 도 32에서는 인풋 필드가 블록 압축을 위한 설정값으로 0보다 크고 1이하인 비율값을 입력 받는 것으로 도시하였다. 다만 이에 한정되는 것은 아니며 블록 압축을 위한 설정값의 범위는 압축 방법에 따 라 다양하게 변경될 수 있다. 일 예로, 압축 방법이 인덱스를 기초로 하는 제2 유형의 프루닝인 경우, 인풋 필 드는 프루닝 대상이 되는 채널의 인덱스를 입력받을 수 있다. 다른 일 예로, 압축 방법이 터커 분해인 경우, 인 풋 필드는 코어 텐서의 입력 채널의 개수 및 코어 텐서의 출력 채널의 개수를 입력받을 수 있다. 한편, 블록 압축을 위한 설정값은, 사용자에 의해 입력되거나, 전자 장치에 의해 결정될 수 있다. 예를 들 어, 전자 장치는 각 블록에 대응되는 레이턴시에 기초하여 각 블록의 압축률을 설정할 수 있다. 전자 장치 는 블록에 대응되는 레이턴시가 클수록 해당 블록의 압축률을 높게 설정할 수 있다. 도 30을 참조하면, 제 1 블록(add)에 대응되는 압축률은 제6 블록(mul)에 대응되는 압축률보다 작을 수 있다. 본 개시의 예시적인 일 실시 예에 따르면, 신경망 모델에 대한 정보를 제공하는 방법에 있어서, 외부 장치로부 터 신경망 모델이 실행될 타겟 디바이스에 대한 정보 및 상기 타겟 디바이스에 대한 상기 신경망 모델의 타겟 성능을 수신하는 단계; 상기 타겟 디바이스에 대한 정보 및 상기 수신한 타겟 성능에 기초하여 복수의 후보 신 경망 모델에 대한 정보를 획득하는 단계; 및 상기 수신한 타겟 성능에 기초하여 상기 복수의 후보 신경망 모델 에 대한 정보-상기 복수의 후보 신경망 모델에 대한 정보는, 상기 복수의 후보 신경망 모델의 명칭, 상기 복수 의 후보 신경망 모델의 성능 또는 상기 복수의 후보 신경망 모델의 입력 데이터의 크기 중 적어도 하나를 포함 함-를 표시하도록 상기 외부 장치로 명령을 전송하는 단계;를 포함하는 방법이 제공될 수 있다. 상기 전송하는 단계는, 상기 복수의 후보 신경망 모델에 대한 정보를 각각 나타내는 복수의 UI 엘리먼트를 상기 복수의 UI 엘리먼트 각각에 대응되는 후보 신경망 모델의 성능 및 상기 수신한 타겟 성능의 차이가 작은 순서대 로 표시하도록 상기 외부 장치로 명령을 전송할 수 있다. 상기 복수의 UI 엘리먼트는, 사용자에 의해 설정된 입력 데이터의 크기와 입력 데이터의 크기가 동일한 복수의 제1 후보 신경망 모델에 각각 대응되는 제1 UI 엘리먼트들, 및 사용자에 의해 설정된 입력 데이터의 크기와 입력 데이터의 크기가 상이한 복수의 제2 후보 신경망 모델에 각각 대응되는 제2 UI 엘리먼트들을 포함하고, 상기 전송하는 단계는, 상기 제1 UI 엘리먼트들 및 상기 제2 UI 엘리먼트들을 서로 다른 영역에 동시에 표시하도록 상기 외부 장치로 명령을 전송할 수 있다. 상기 전송하는 단계는, 상기 복수의 후보 신경망 모델에 대한 정보를 각각 나타내는 복수의 UI 엘리먼트를 2차 원 그래프-상기 2차원 그래프는, 제1 성능 파라미터에 대응되는 제1 축 및 제2 성능 파라미터에 대응되는 제2 축에 의해 정의됨-에 표시하도록 상기 외부 장치로 명령을 전송할 수 있다. 상기 복수의 UI 엘리먼트는, 상기 수신한 타겟 성능으로부터 기설정된 범위 이내의 성능을 갖는 복수의 제3 후 보 신경망 모델에 각각 대응되는 제3 UI 엘리먼트들, 및 상기 수신한 타겟 성능으로부터 상기 기설정된 범위 밖 의 성능을 갖는 복수의 제4 후보 신경망 모델에 대응되는 제4 UI 엘리먼트들을 포함하고, 상기 전송하는 단계는, 상기 제3 UI 엘리먼트들은 활성화하고 상기 제4 UI 엘리먼트들은 비활성화하도록 상기 외부 장치로 명 령을 전송할 수 있다. 상기 복수의 UI 엘리먼트 각각은, 사용자에 의해 선택되면 상기 복수의 후보 신경망 모델에 대한 정보를 표시할 수 있다. 상기 획득하는 단계는, 룩-업 테이블에 기초하여 상기 복수의 후보 신경망 모델에 대한 정보를 획득하되, 상기 룩-업 테이블은, 복수의 신경망 모델의 식별 정보, 상기 복수의 신경망 모델이 실행되는 복수의 디바이스에 대 한 정보 및 상기 복수의 디바이스에 대한 상기 복수의 신경망 모델의 성능 정보를 포함할 수 있다. 상기 획득하는 단계는, 상기 복수의 신경망 모델 중 상기 타겟 성능과의 성능 차이에 기초한 순위가 기설정된 순위 이상인 신경망 모델들에 대한 정보를 획득할 수 있다. 상기 획득하는 단계는, 상기 복수의 신경망 모델 중 상기 타겟 성능과의 차이가 기설정된 범위 이내인 신경망 모델들에 대한 정보를 획득할 수 있다. 본 개시의 예시적인 일 실시 예에 따르면, 신경망 모델에 대한 정보를 제공하는 전자 장치에 있어서, 적어도 하 나의 회로를 포함하는 통신 인터페이스; 적어도 하나의 인스트럭션을 저장하는 메모리; 및 프로세서;를 포함하 고, 상기 프로세서는, 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 통신 인터페이스를 통해 외부 장치 로부터 신경망 모델이 실행될 타겟 디바이스에 대한 정보 및 상기 타겟 디바이스에 대한 상기 신경망 모델의 타 겟 성능을 수신하고, 상기 타겟 디바이스에 대한 정보 및 상기 수신한 타겟 성능에 기초하여 복수의 후보 신경 망 모델에 대한 정보를 획득하고, 상기 수신한 타겟 성능에 기초하여 상기 복수의 후보 신경망 모델에 대한 정 보-상기 복수의 후보 신경망 모델에 대한 정보는, 상기 복수의 후보 신경망 모델의 명칭, 상기 복수의 후보 신 경망 모델의 성능 또는 상기 복수의 후보 신경망 모델의 입력 데이터의 크기 중 적어도 하나를 포함함-를 표시 하도록 상기 외부 장치로 명령을 전송하도록 상기 통신 인터페이스를 제어하는 전자 장치가 제공될 수 있다. 상기 프로세서는, 상기 복수의 후보 신경망 모델에 대한 정보를 각각 나타내는 복수의 UI 엘리먼트를 상기 복수 의 UI 엘리먼트 각각에 대응되는 후보 신경망 모델의 성능 및 상기 수신한 타겟 성능의 차이가 작은 순서대로 표시하도록 상기 외부 장치로 명령을 전송하도록 상기 통신 인터페이스를 제어할 수 있다. 상기 복수의 UI 엘리먼트는, 사용자에 의해 설정된 입력 데이터의 크기와 입력 데이터의 크기가 동일한 복수의 제1 후보 신경망 모델에 각각 대응되는 제1 UI 엘리먼트들, 및 사용자에 의해 설정된 입력 데이터의 크기와 입 력 데이터의 크기가 상이한 복수의 제2 후보 신경망 모델에 각각 대응되는 제2 UI 엘리먼트들을 포함하고, 상기 프로세서는, 상기 제1 UI 엘리먼트들 및 상기 제2 UI 엘리먼트들을 서로 다른 영역에 동시에 표시하도록 상기 외부 장치로 명령을 전송하도록 상기 통신 인터페이스를 제어할 수 있다. 상기 프로세서는, 상기 복수의 후보 신경망 모델에 대한 정보를 각각 나타내는 복수의 UI 엘리먼트를 2차원 그 래프-상기 2차원 그래프는, 제1 성능 파라미터에 대응되는 제1 축 및 제2 성능 파라미터에 대응되는 제2 축에 의해 정의됨-에 표시하도록 상기 외부 장치로 명령을 전송하도록 상기 통신 인터페이스를 제어할 수 있다. 상기 복수의 UI 엘리먼트는, 상기 수신한 타겟 성능으로부터 기설정된 범위 이내의 성능을 갖는 복수의 제3 후 보 신경망 모델에 각각 대응되는 제3 UI 엘리먼트들, 및 상기 수신한 타겟 성능으로부터 상기 기설정된 범위 밖 의 성능을 갖는 복수의 제4 후보 신경망 모델에 각각 대응되는 제4 UI 엘리먼트들을 포함하고, 상기 프로세서는, 상기 제3 UI 엘리먼트들은 활성화하고 상기 제4 UI 엘리먼트들은 비활성화하도록 상기 외부 장치로 명령을 전송하도록 상기 통신 인터페이스를 제어할 수 있다. 상기 프로세서는, 룩-업 테이블에 기초하여 상기 복수의 후보 신경망 모델에 대한 정보를 획득하되, 상기 룩-업 테이블은, 복수의 신경망 모델의 식별 정보, 상기 복수의 신경망 모델이 실행되는 복수의 디바이스에 대한 정보 및 상기 복수의 디바이스에 대한 상기 복수의 신경망 모델의 성능 정보를 포함할 수 있다. 상기 프로세서는, 상기 복수의 신경망 모델 중 상기 타겟 성능과의 성능 차이에 기초한 순위가 기설정된 순위 이상인 신경망 모델들에 대한 정보를 획득할 수 있다. 상기 프로세서는, 상기 복수의 신경망 모델 중 상기 타겟 성능과의 차이가 기설정된 범위 이내인 신경망 모델들 에 대한 정보를 획득할 수 있다. 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합을 이용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 일부 경우에 있어 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어로 구현되는 경우, 본 명세서 에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 소프트웨어 모듈 들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 작동을 수행할 수 있다. 상술한 본 개시의 다양한 실시 예들에 따른 처리 동작을 수행하기 위한 컴퓨터 명령어(computer instructions) 는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium)에 저장될 수 있다. 이러한 비 일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 프로세서에 의해 실행되었을 때 상술한 다양한 실시 예에 따른 처리 동작을 특정 기기가 수행하도록 할 수 있다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등 이 있을 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비 일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미 할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하 지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또 는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2023-0018233", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어져서는 안 될 것이다."}
{"patent_id": "10-2023-0018233", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 특정 실시 예의 양상, 특징 및 이점은 첨부된 도면들을 참조하여 후술되는 설명을 통해 보다 명확해 질 것이다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 도시한 블록도이다. 도 3은 본 개시의 일 실시 예에 따른 제1 프로젝트를 수행하는 방법을 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시 예에 따른 제2 프로젝트를 수행하는 방법을 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따른 제3 프로젝트를 수행하는 방법을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시 예에 따른 데이터셋 입력 화면이다. 도 7은 본 개시의 일 실시 예에 따른 데이터셋 확인 화면이다. 도 8은 본 개시의 일 실시 예에 따른 데이터셋 리스트 화면이다. 도 9는 본 개시의 일 실시 예에 따른 타겟 디바이스 입력 화면이다. 도 10은 본 개시의 일 실시 예에 따른 프로젝트 정보 화면이다. 도 11은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 도면이다. 도 12는 본 개시의 일 실시 예에 따른 제1 프로젝트를 수행하는 방법을 나타내는 시퀀스도이다. 도 13은 본 개시의 일 실시 예에 따른 제2 프로젝트를 수행하는 방법을 나타내는 시퀀스도이다. 도 14는 본 개시의 일 실시 예에 따른 제3 프로젝트를 수행하는 방법을 나타내는 시퀀스도이다.도 15는 본 개시의 일 실시 예에 따른 신경망 모델 제공 시스템의 구성을 도시한 블록도이다. 도 16은 본 개시의 일 실시 예에 따른 학습 설정 화면이다. 도 17은 본 개시의 일 실시 예에 따른 베이스 모델 추천 화면이다. 도 18은 본 개시의 일 실시 예에 따른 신경망 모델에 대한 정보를 표시하는 방법을 설명하기 위한 도면이다. 도 19는 본 개시의 일 실시 예에 따른 신경망 모델에 대한 정보를 표시하는 방법을 설명하기 위한 도면이다. 도 20은 본 개시의 일 실시 예에 따른 신경망 모델의 성능을 획득하는 방법을 설명하기 위한 도면이다. 도 21은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 도면이다. 도 22는 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 도면이다. 도 23은 본 개시의 일 실시 예에 따른 제1 압축 모드를 설명하기 위한 도면이다. 도 24는 본 개시의 일 실시 예에 따른 제1 압축 모드의 압축설정화면이다. 도 25는 본 개시의 일 실시 예에 따른 제2 압축 모드를 설명하기 위한 도면이다. 도 26은 본 개시의 일 실시 예에 따른 제2 압축 모드의 압축설정화면이다. 도 27은 본 개시의 일 실시 예에 따른 블록 압축을 위한 설정값을 설정하기 위한 화면이다. 도 28은 본 개시의 일 실시 예에 따른 압축 정책을 설명하기 위한 도면이다. 도 29는 본 개시의 일 실시 예에 따른 신경망 모델의 압축 방법을 나타내는 순서도이다. 도 30은 본 개시의 일 실시 예에 따른 블록 압축을 위한 설정값을 설정하기 위한 화면이다. 도 31은 본 개시의 일 실시 예에 따른 블록 압축을 위한 설정값을 설정하기 위한 화면이다. 도 32는 본 개시의 일 실시 예에 따른 블록 압축을 위한 설정값을 설정하기 위한 화면이다."}
