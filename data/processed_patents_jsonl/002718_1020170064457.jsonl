{"patent_id": "10-2017-0064457", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0129044", "출원번호": "10-2017-0064457", "발명의 명칭": "차량 운전 보조 장치 및 이의 안전 운전 유도 방법", "출원인": "(주)에이다스원", "발명자": "강경수"}}
{"patent_id": "10-2017-0064457", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "차량 운전 보조 장치에 있어서,운전자의 얼굴 및 주행 차량의 주변 영상을 촬영하는 촬영부,상기 촬영된 영상으로부터 주행 상태의 안전 여부를 판단하기 위한 프로그램이 저장된 메모리 및상기 메모리에 저장된 프로그램을 실행시키는 프로세서를 포함하되,상기 프로세서는 상기 프로그램을 실행시킴에 따라, 상기 촬영된 운전자의 얼굴로부터 운전자의 시선 정보를 분석하고, 상기 촬영된 주변 영상으로부터 차량의 주행 정보를 분석하며, 상기 시선 정보와 상기 분석된 주행 정보와의 대응 여부에 기초하여 상기 차량의 주행 상태의 안전 여부를 판단하여 상기 운전자에게 경고 알림 메시지를 출력하되,상기 운전자의 시선 정보는 상기 얼굴 및 시선의 방향 정보를 포함하고,상기 주행 정보는 주행 속도 정보, 주행 방향 정보, 주행 차선의 정보 및 상기 주행 차선을 기준으로 전방, 후방, 좌측 및 우측에 위치하는 객체의 정보 중 하나 이상을 포함하는 것인 차량 운전 보조 장치."}
{"patent_id": "10-2017-0064457", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 프로세서는 상기 운전자가 차량 내에서 주시 가능한 방향을 복수 개의 영역으로 구획하여 구별하고, 상기복수 개의 영역 중 상기 운전자의 얼굴 및 시선의 방향 정보와 매칭되는 영역을 상기 운전자의 시선 정보로 획득하는 것인 차량 운전 보조 장치."}
{"patent_id": "10-2017-0064457", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 프로세서는 상기 운전자의 얼굴 및 시선의 방향 정보와 매칭되는 영역이 상기 주행 정보 중 상기 주행 차선의 정보와 대응되지 않는 경우 상기 운전자에게 경고 알림 메시지를 출력하는 것인 차량 운전 보조 장치."}
{"patent_id": "10-2017-0064457", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서,상기 프로세서는 상기 주행 정보 중 객체의 정보, 주행 방향 정보 및 주행 속도 정보에 기초하여 기 설정된 시간 이내에 상기 객체와 차량과의 충돌 가능성이 있을 것으로 분석된 경우, 상기 운전자의 얼굴 및 시선의 방향정보와 매칭되는 영역이 상기 객체의 정보와 대응되지 않으면 상기 운전자에게 경고 알림 메시지를 출력하는 것인 차량 운전 보조 장치."}
{"patent_id": "10-2017-0064457", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 프로세서는 상기 객체의 정보 중 객체의 이동 방향 및 속도를 산출하고, 산출 결과 상기 기 설정된 시간이내 상기 객체와 차량과의 충돌 가능성이 있을 것으로 분석된 경우 상기 경고 알림 메시지를 출력하는 것인 차량 운전 보조 장치."}
{"patent_id": "10-2017-0064457", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 3 항 내지 제 5 항 중 어느 한 항에 있어서,상기 프로세서는 상기 매칭되는 영역에 대한 운전자의 주시 시간을 측정하여 상기 시선 정보로 획득하고, 상기공개특허 10-2018-0129044-3-매칭되는 영역이 상기 주행 정보와 대응되지 않는 경우에 상기 주시 시간이 일정 초과하는 경우 상기 운전자에게 경고 알림 메시지를 출력하는 것인 차량 운전 보조 장치."}
{"patent_id": "10-2017-0064457", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 프로세서는 상기 시선 정보를 실시간으로 또는 기 설정된 주기마다 상기 메모리에 누적하여 저장하고, 미리 학습된 알고리즘을 통해 상기 누적된 시선 정보로부터 운전자의 예측 시선 정보를 생성하는 것인 차량 운전보조 장치."}
{"patent_id": "10-2017-0064457", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 프로세서는 상기 예측 시선 정보를 운전자 별로 구분하여 생성하되, 상기 매칭되는 영역이 상기 주행 정보와 대응되지 않으나 상기 주행 상태가 안전한 경우로 판단된 횟수가 기 설정된 횟수 이상을 만족하는 경우 생성하는 것인 차량 운전 보조 장치."}
{"patent_id": "10-2017-0064457", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 2 항에 있어서,상기 프로세서는 상기 복수 개의 영역 별로 각각 상이한 가중치를 적용하고, 상기 적용된 가중치에 따라 상기경고 알림 메시지를 출력하기 위한 경고 수준을 상이하게 적용시키는 것인 차량 운전 보조 장치."}
{"patent_id": "10-2017-0064457", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 2 항에 있어서,상기 프로세서는 상기 주행 상태의 안전 여부의 판단 결과에 기초하여 상기 운전자의 안전 운전 지수를 산출하는 것인 차량 운전 보조 장치."}
{"patent_id": "10-2017-0064457", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "차량 운전 보조 장치에서의 안전운전 유도 방법에 있어서,운전자의 얼굴을 촬영하여 상기 운전자의 얼굴 및 시선의 방향 정보를 포함하는 시선 정보를 분석하는 단계;차량의 주변을 촬영한 주변 영상으로부터 차량의 주행 속도 정보, 주행 방향 정보, 주행 차선의 정보 및 상기주행 차선을 기준으로 전방, 후방, 좌측 및 우측에 위치하는 객체의 정보 중 하나 이상을 포함하는 주행 정보를분석하는 단계;상기 시선 정보와 상기 주행 정보와의 대응 여부에 기초하여 상기 차량의 주행 상태의 안전 여부를 판단하는 단계 및상기 차량의 주행 상태가 안전하지 않은 것으로 판단된 경우 상기 운전자에게 경고 알림 메시지를 출력하는 단계를 포함하는 안전운전 유도 방법."}
{"patent_id": "10-2017-0064457", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따른 차량 운전 보조 장치는 운전자의 얼굴 및 주행 차량의 주변 영상을 촬영하는 촬영부, 상기 촬영 된 영상으로부터 주행 상태의 안전 여부를 판단하기 위한 프로그램이 저장된 메모리 및 상기 메모리에 저장된 프 로그램을 실행시키는 프로세서를 포함한다. 이때, 상기 프로세서는 상기 프로그램을 실행시킴에 따라, 상기 촬영 된 운전자의 얼굴로부터 운전자의 시선 정보를 분석하고, 상기 촬영된 주변 영상으로부터 차량의 주행 정보를 분 석하며, 상기 시선 정보와 상기 분석된 주행 정보와의 대응 여부에 기초하여 상기 차량의 주행 상태의 안전 여부 를 판단하여 상기 운전자에게 경고 알림 메시지를 출력하되, 상기 운전자의 시선 정보는 상기 얼굴 및 시선의 방 향 정보를 포함하고, 상기 주행 정보는 주행 속도 정보, 주행 방향 정보, 주행 차선의 정보 및 상기 주행 차선을 기준으로 전방, 후방, 좌측 및 우측에 위치하는 객체의 정보 중 하나 이상을 포함한다."}
{"patent_id": "10-2017-0064457", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 차량 운전 보조 장치 및 이의 안전 운전 유도 방법에 관한 것이다."}
{"patent_id": "10-2017-0064457", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 차량에는 지능형 안전 기능을 구현하기 위해 LDWS(Lane Departure Warning), LKAS(Lane Keeping Assistance)의 카메라, SCC(Smart Cruise Control)와 BSD(Blind Spot Detection)의 레이더 등 다양한 센서 또 는 카메라가 적용되어 운전자의 안전 운전을 보조하는 ADAS(Advanced Driver Assistance System)가 상용화되어 적용되고 있다.또한, 운전자의 주의가 분산되는 것을 감지하기 위하여 얼굴을 인식하는 카메라를 통해 운전자의 상태를 분석하 는 기술도 제공되어, 졸음 운전 등을 방지하게끔 하는 기술도 제공되고 있는 실정이다. 그러나 ADAS나 운전자의 얼굴을 인식하는 기술은 상호 연동되지 않고 각각 별개로 제공됨에 따라 그 활용도가 매우 제한적이다는 문제가 있다. 즉, ADAS의 경우 단순히 전방 차량 등과의 충돌 상태, 차선 이탈 상태 등을 개별적으로 안내해줄 뿐이고, 얼굴 인식 기술 역시 단순히 졸음 운전과 같은 상황에 대하여 경고하는 수준에 그치고 있다. 이와 같이 운전자에게 제공되고 있는 정보들은 각각의 개별 정보들에 불과한 실정인바, 운전자의 상태 정보를 ADAS에서 제공하는 정보와 융합하여 운전자에게 보다 직접적인 경보를 제공하는 기술이 필요한 실정이다. 이와 관련하여, 한국공개특허공보 제10-2017-0017616호(발명의 명칭: 운전 보조 장치 및 방법)는 운전자가 졸음 상태이거나 전방을 주시하지 않는 상태일 때 경고를 알리는 기술을 개시하고 있다."}
{"patent_id": "10-2017-0064457", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예는 운전자의 얼굴을 촬영하여 운전자의 시선 정보를 획득하고, 주변 영상으로부터 차량의 주행 정보를 분석하여, 시선 정보와 주행 정보와의 대응 여부에 기초하여 차량의 주행 상태의 안전 여부 판별 및 경 고 알림 메시지를 제공할 수 있는 차량 운전 보조 장치 및 이의 안전운전 유도 방법을 제공하고자 한다. 다만, 본 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제로 한정되지 않으며, 또 다른 기 술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2017-0064457", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 발명의 제 1 측면에 따른 차량 운전 보조 장치는 운전자의 얼굴 및 주행 차량의 주변 영상을 촬영하는 촬영부, 상기 촬영된 영상으로부터 주행 상태의 안전 여부 를 판단하기 위한 프로그램이 저장된 메모리 및 상기 메모리에 저장된 프로그램을 실행시키는 프로세서를 포함 한다. 이때, 상기 프로세서는 상기 프로그램을 실행시킴에 따라, 상기 촬영된 운전자의 얼굴로부터 운전자의 시 선 정보를 분석하고, 상기 촬영된 주변 영상으로부터 차량의 주행 정보를 분석하며, 상기 시선 정보와 상기 분 석된 주행 정보와의 대응 여부에 기초하여 상기 차량의 주행 상태의 안전 여부를 판단하여 상기 운전자에게 경 고 알림 메시지를 출력하되, 상기 운전자의 시선 정보는 상기 얼굴 및 시선의 방향 정보를 포함하고, 상기 주행 정보는 주행 속도 정보, 주행 방향 정보, 주행 차선의 정보 및 상기 주행 차선을 기준으로 전방, 후방, 좌측 및 우측에 위치하는 객체의 정보 중 하나 이상을 포함한다. 상기 프로세서는 상기 운전자가 차량 내에서 주시 가능한 방향을 복수 개의 영역으로 구획하여 구별하고, 상기 복수 개의 영역 중 상기 운전자의 얼굴 및 시선의 방향 정보와 매칭되는 영역을 상기 운전자의 시선 정보로 획 득할 수 있다. 상기 프로세서는 상기 운전자의 얼굴 및 시선의 방향 정보와 매칭되는 영역이 상기 주행 정보 중 상기 주행 차 선의 정보와 대응되지 않는 경우 상기 운전자에게 경고 알림 메시지를 출력할 수 있다. 상기 프로세서는 상기 주행 정보 중 객체의 정보, 주행 방향 정보 및 주행 속도 정보에 기초하여 기 설정된 시 간 이내에 상기 객체와 차량과의 충돌 가능성이 있을 것으로 분석된 경우, 상기 운전자의 얼굴 및 시선의 방향 정보와 매칭되는 영역이 상기 객체의 정보와 대응되지 않으면 상기 운전자에게 경고 알림 메시지를 출력할 수 있다. 상기 프로세서는 상기 객체의 정보 중 객체의 이동 방향 및 속도를 산출하고, 산출 결과 상기 기 설정된 시간 이내 상기 객체와 차량과의 충돌 가능성이 있을 것으로 분석된 경우 상기 경고 알림 메시지를 출력할 수 있다. 상기 프로세서는 상기 매칭되는 영역에 대한 운전자의 주시 시간을 측정하여 상기 시선 정보로 획득하고, 상기 매칭되는 영역이 상기 주행 정보와 대응되지 않는 경우에 상기 주시 시간이 일정 초과하는 경우 상기 운전자에 게 경고 알림 메시지를 출력할 수 있다. 상기 프로세서는 상기 시선 정보를 실시간으로 또는 기 설정된 주기마다 상기 메모리에 누적하여 저장하고, 미 리 학습된 알고리즘을 통해 상기 누적된 시선 정보로부터 운전자의 예측 시선 정보를 생성할 수 있다.상기 프로세서는 상기 예측 시선 정보를 운전자 별로 구분하여 생성하되, 상기 매칭되는 영역이 상기 주행 정보 와 대응되지 않으나 상기 주행 상태가 안전한 경우로 판단된 횟수가 기 설정된 횟수 이상을 만족하는 경우 생성 할 수 있다. 상기 프로세서는 상기 복수 개의 영역 별로 각각 상이한 가중치를 적용하고, 상기 적용된 가중치에 따라 상기 경고 알림 메시지를 출력하기 위한 경고 수준을 상이하게 적용시킬 수 있다. 상기 프로세서는 상기 주행 상태의 안전 여부의 판단 결과에 기초하여 상기 운전자의 안전 운전 지수를 산출할 수 있다. 또한, 본 발명의 제 2 측면에 따른 차량 운전 보조 장치에서의 안전운전 유도 방법은 운전자의 얼굴을 촬영하여 상기 운전자의 얼굴 및 시선의 방향 정보를 포함하는 시선 정보를 분석하는 단계; 차량의 주변을 촬영한 주변 영상으로부터 차량의 주행 속도 정보, 주행 방향 정보, 주행 차선의 정보 및 상기 주행 차선을 기준으로 전방, 후방, 좌측 및 우측에 위치하는 객체의 정보 중 하나 이상을 포함하는 주행 정보를 분석하는 단계; 상기 시선 정보와 상기 주행 정보와의 대응 여부에 기초하여 상기 차량의 주행 상태의 안전 여부를 판단하는 단계 및 상기 차량의 주행 상태가 안전하지 않은 것으로 판단된 경우 상기 운전자에게 경고 알림 메시지를 출력하는 단계를 포함한다."}
{"patent_id": "10-2017-0064457", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 운전자의 상태 정보와 차량의 주행 정보를 종합하여 차량의 주행 상태를 판단함으로써 운전자에게 보다 직접적인 주행 상태 및 이에 대한 경고 제공이 가능하다."}
{"patent_id": "10-2017-0064457", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 이하에서는 첨부된 도면을 참조하여 본 발명의 일 실시예에 따른 차량 운전 보조 장치에 대하여 설명하도 록 한다. 도 1은 본 발명의 일 실시예에 따른 차량 운전 보조 장치의 블록도이다. 도 2는 차량 내 주시 가능한 복수 개의 영역을 설명하기 위한 도면이다. 도 3은 주변 영상의 예시도이다. 본 발명의 일 실시예에 따른 차량 운전 보조 장치는 촬영부, 메모리 및 프로세서를 포함한 다. 촬영부는 운전자의 얼굴을 촬영하는 운전자 촬영부 및 주행 차량의 주변 영상을 촬영하는 주변 영상 촬영 부를 포함한다. 이때, 운전자 촬영부는 일반 카메라, 스테레오 카메라, 깊이 카메라 등 특별한 종류의 카메라로 한정되는 것은 아니며, 본 발명에서는 운전자의 얼굴 및 운전자의 눈동자를 통한 시선을 획득할 수 있는 카메라를 의미한다. 또한, 실내가 어두운 경우에도 운전자의 얼굴 및 시선을 촬영한 영상을 획득하기 위하여 적외선 카메라로 구현 되거나 상술한 카메라와 함께 적외선 카메라가 구비될 수도 있다. 또한, 운전자 촬영부는 운전자의 얼굴뿐만 아니라 운전자의 자세 정보도 함께 촬영할 수 있다. 이에 따라, 본 발명의 일 실시예는 예를 들어 좌석 시트의 포지션의 변경에 따라 운전자의 얼굴이 위치하는 높낮이 또는 카메 라로부터의 거리 등이 변경되더라도 카메라의 줌을 재조절하거나 영상을 보정하여 운전자의 얼굴을 촬영하거나 정확한 영상을 획득할 수 있다. 주변 영상 촬영부는 차량의 전방, 양 측면 또는 후방을 촬영한다. 이때, 본 발명의 일 실시예에 따른 차량 운전 보조 장치는 차량의 전방, 양 측면 및 후방을 각각 촬영하기 위하여, 전방 카메라, 사이드 미러 등에 설치 된 측면 카메라 및 후방 카메라를 각각 구비할 수도 있으며, 이 중 어느 하나의 카메라만을 구비할 수도 있음은 물론이다. 한편, 주변 영상 촬영부는 반드시 카메라에 의해 구현된 것은 아니며, 차량의 외부에 구비되는 LDWS(Lane Departure Warning)와 LKAS(Lane Keeping Assistance)의 카메라, SCC(Smart Cruise Control)와 BSD(Blind Spot Detection)의 레이더 등을 포함하도록 구현될 수도 있다. 메모리에는 촬영된 영상으로부터 주행 상태의 안전 여부를 판단하기 위한 프로그램이 저장된다. 여기에서, 메모리는 전원이 공급되지 않아도 저장된 정보를 계속 유지하는 비휘발성 저장장치 및 휘발성 저장장치를 통칭하는 것이다. 예를 들어, 메모리는 콤팩트 플래시(compact flash; CF) 카드, SD(secure digital) 카드, 메모리 스틱 (memory stick), 솔리드 스테이트 드라이브(solid-state drive; SSD) 및 마이크로(micro) SD 카드 등과 같은 낸드 플래시 메모리(NAND flash memory), 하드 디스크 드라이브(hard disk drive; HDD) 등과 같은 마그네틱 컴 퓨터 기억 장치 및 CD-ROM, DVD-ROM 등과 같은 광학 디스크 드라이브(optical disc drive) 등을 포함할 수 있 다. 한편, 본 발명의 일 실시예에 따른 차량 운전 보조 장치는 통신모듈을 더 포함할 수 있으며, 통신모 듈은 촬영부에 의해 촬영된 각 영상들을 수신한다. 이와 같은 통신모듈은 유선 통신모듈 및 무 선 통신모듈을 모두 포함할 수 있다. 유선 통신모듈은 전력선 통신 장치, 전화선 통신 장치, 케이블 홈(MoCA), 이더넷(Ethernet), IEEE1294, 통합 유선 홈 네트워크 및 RS-485 제어 장치로 구현될 수 있다. 또한, 무선 통신 모듈은 WLAN(wireless LAN), Bluetooth, HDR WPAN, UWB, ZigBee, Impulse Radio, 60GHz WPAN, Binary-CDMA, 무선 USB 기술 및 무선 HDMI 기술 등으로 구현될 수 있다. 보다 바람직하게 통신모듈은 촬영부 및 메모리와 CAN(Controller Area Network) 통신을 통하여 데이터를 송수신할 수 있다. 프로세서는 메모리에 저장된 프로그램을 실행시킨다. 프로세서는 프로그램을 실행시킴에 따라, 운전자 촬영부를 통해 촬영된 운전자의 얼굴로부터 운전자의 시선 정보를 분석한다. 이때, 운전자의 시선 정보 는 운전자의 얼굴의 방향 및 운전자의 얼굴의 방향에 따른 또는 눈동자에 따른 시선의 방향 정보를 포함한다. 이와 같이 운전자의 시선 정보를 획득하고 나면, 프로세서는 도 2와 같이 운전자가 차량 내에서 주시 가능 한 방향을 복수 개의 영역으로 구획하여 구별한다. 그리고 복수 개의 영역 중 운전자의 얼굴 및 시선의 방향 정 보와 매칭되는 영역을 운전자의 시선 정보로 획득할 수 있다. 예를 들어, 차량이 직진 차로를 주행 중인 경우 운전자는 주로 얼굴 및 시선의 방향을 제 1 영역 또는 제 3 영 역을 바라보게 되는바, 이와 같이 현재 주행 중인 차량에서 바라보는 제 1 영역 또는 제 3 영역을 운전자의 얼 굴 및 시선의 방향 정보와 매칭되는 영역으로 확인하여 시선 정보로 획득한다. 정상 주행뿐만 아니라, 예를 들어 차량이 직진 차로를 주행 중에 운전자가 졸음 운전을 하고 있는 경우, 운전자 의 얼굴의 방향이 제 8 영역을 바라보게 되는바, 제 8 영역을 운전자의 얼굴 및 시선의 방향 정보와 매칭되는 영역으로 확인하여 시선 정보로 획득한다. 한편, 도 2의 경우 전방 및 측면에 대하여 한정된 개수의 영역이 설정된 것으로 도시되어 있으나 이는 일 예시 에 불과하며, 복수 개의 영역은 보다 세밀하게 구획되어 구분될 수도 있고, 전방 및 측방뿐만 아니라 후방에도 영역이 구획되어 구분될 수 있음은 물론이다. 보다 세밀하고 넓은 범위에 걸쳐 영역이 구분됨에 따라 운전자의 시선 정보가 더욱 구체화될 수 있으며, 후술하 는 운전자의 습관을 보다 구체적으로 학습할 수도 있게 된다. 다음으로 프로세서는 주변 영상 촬영부에 의해 촬영된 주변 영상으로부터 차량의 주행 정보를 분석한다. 이때, 차량의 주행 정보는 차량의 주행 속도 정보, 주행 방향 정보, 주행 차선 정보 및 주행 차선을 기준으로전방, 후방, 좌측 및 우측에 위치하는 객체의 정보 중 하나 이상을 포함한다. 이때, 차량의 주행 정보는 주변 영상으로부터 분석하여 획득할 수도 있으며, 이와 함께 또는 별개로 차량에 포 함된 각 센서에 의해 센싱된 정보를 분석하여 획득하거나, ECU가 센싱된 정보를 이용하여 차량을 자가 진단한 정보를 분석하여 획득할 수도 있다. 이와 같이 운전자의 시선 정보와 주행 정보를 획득하고 나면, 프로세서는 시선 정보와 주행 정보와의 대응 여부에 기초하여 차량의 주행 상태의 안전 여부를 판단하고, 이에 기초하여 운전자에게 경고 알림 메시지를 출 력할 수 있다. 구체적으로, 프로세서는 운전자의 얼굴 및 시선의 방향 정보와 매칭되는 영역이 주행 정보 중 주행 차선의 정보와 대응되지 않는 경우 운전자에게 경고 알림 메시지를 출력할 수 있다. 이때, 시선 정보에 매칭되는 영역 과 주행 정보에 대응되는 영역은 미리 메모리 상에 저장되어 있을 수 있다. 그리고 주행 정보에 해당하는 영역의 경우, 객체나 차선에 대하여 운전자가 바라보는 시선 방향을 연장시켰을 때 이와 교차하는 영역일 수 있으며 하나의 객체가 복수 개의 영역에 나뉘어 포함되는 경우 포함되는 복수 개의 영역이 주행 정보에 해당하는 영역일 수 있다. 예를 들어, 차량이 직진 차선을 주행하고 있는 경우에는 운전자의 시선 방향이 제 1 영역 또는 제 3 영역을 바 라보고 있는 것이 정상적이며, 주변을 살피고자 할 경우 제 2 영역 또는 제 4 영역도 바라보는 것이 정상적이다. 따라서, 현재 차량의 주행 정보가 직진 차선을 똑바로 주행하고 있는 경우, 이에 대응되는 영역은 제 1 내지 제 4 영역에 해당한다. 그러나 차량이 직진 차선을 주행하고 있는 경우, 운전자의 얼굴 및 시선의 방향 정보와 매칭되는 영역이 제 1 내지 제 4 영역이 아닌 제 5 내지 제 8 영역인 경우, 상기 영역과 주행 정보는 대응되지 않는 경우에 해당하는 바, 이 경우 프로세서는 운전자에게 경고 알림 메시지를 출력할 수 있다. 또 다른 예로, 차량이 왼쪽 차선으로 차선 변경을 하고 있는 중인 경우 운전자의 시선 방향은 제 1 영역 및 제 3 영역의 전방 영역과, 왼쪽 사이드 미러 영역인 제 7 영역 그리고 뒷차를 확인하기 위한 제 5 영역을 바라보는 것이 정상적이다. 따라서, 현재 차량의 주행 정보가 왼쪽으로 차선 변경을 하는 중인 경우, 이에 대응되는 영역 은 제 1, 3, 5, 7 영역에 해당한다. 그러나 차량이 왼쪽 차선으로 차선 변경을 하고 있는 중 이에 대응되는 영역을 바라보고 있는 시선 정보를 획득 하지 못하고, 그 외 다른 영역인 예를 들어 제 8 영역을 바라보고 있는 시선 정보를 획득한 경우, 상기 영역과 주행 정보는 대응되지 않는 경우에 해당하는바, 이 경우 프로세서는 운전자에게 경고 알림 메시지를 출력 할 수 있다. 또한, 프로세서는 주행 정보 중 객체의 정보, 주행 방향 정보 및 주행 속도 정보에 기초하여 기 설정된 시 간 이내에 객체와 차량과의 충돌 가능성이 있는 것으로 분석한 경우, 운전자의 얼굴 및 시선의 방향 정보와 매 칭되는 영역이 객체의 정보와 대응되지 않으면 운전자에게 경고 알림 메시지를 출력할 수 있다. 이때, 프로세서는 객체의 정보 중 객체의 이동 방향 및 속도를 산출하고, 산출 결과 기 설정된 시간 이내 객체와 차량과의 충돌 가능성이 있을 것으로 분석된 경우 경고 알림 메시지를 출력할 수 있다. 여기에서, 객체는 차량 주변 차선에 위치하는 타차량, 보행자뿐만 아니라 기타 장애물을 포함하는 개념이다. 또 한, 객체의 이동 방향은 예를 들어 보행자의 무단 횡단과 같은 차량과의 수직 방향, 대각 방향 등을 포함하는 교차 방향일 수 있으나 반드시 이에 한정되는 것은 아니며, 차량의 진행방향과 정방향 및 역방향도 충돌 가능성 이 있으므로 이들 방향을 모두 포함한다. 예를 들어, 차량이 직진 차선을 정방향으로 시속 60으로 주행 중인 경우, 해당 차선의 왼쪽에 정차된 타차량이 존재하면, 이와 대응되는 영역은 제 1 영역, 제 2 영역 및 제 5 영역이 될 수 있다. 프로세서가 초음파 센서, 라이다 센서 등의 거리 측정 센서를 통해 객체들과 5초 이내에 충돌할 가능성이 있는 것으로 분석한 경우, 운전자의 얼굴 및 시선의 방향 정보와 매칭되는 영역이 제 1 영역, 제 2 영역 및 제 5 영역이 아닌 예를 들어 제 7 영역이면, 프로세서는 해당 영역이 주행 정보와 대응되지 않는 것으로 판단 하여 운전자에게 경고 알림 메시지를 출력할 수 있다. 또한, 프로세서는 예를 들어 보행자가 왼쪽에서 오른쪽으로 무단횡단을 하는 경우로, 보행자의 이동 방향 (왼쪽에서 오른쪽으로 이동 중)과 이동 속도를 산출하고, 자차의 주행 방향 정보 및 주행 속도 정보에 기초하여5초 후에 보행자와의 충돌 가능성이 있을 것으로 판단한 경우 운전자에게 경고 알림 메시지를 출력할 수 있다. 이와 같이 본 발명의 일 실시예는 객체가 단순히 정지 상태인 경우뿐만 아니라, 이동 중인 객체의 방향 및 속도 를 산출하고 이를 주행 방향 및 속도에 기초하여 충돌 가능성을 산출하여 운전자에게 경고할 수 있는바, 운전자 의 시선이 객체의 방향에 대응되지 않는 경우에도 사고 위험을 최소화시킬 수 있다는 장점이 있다. 또한, 본 발명의 일 실시예에 따른 차량 운전 보조 장치는 도 3과 같이 촬영부를 통해 촬영한 이미지 로부터 프로세서는 주변에 위치하는 차량들에 직접 대응하는 영역만을 관심 영역(Region of Interest)으로 설정하고, 설정된 관심 영역을 기초로 하여 객체의 정보, 즉 객체의 이동 방향 및 속도를 산출할 수 있다. 그리고 운전자의 시선 정보에 매칭되는 영역이 관심 영역과 대응되지 않으면 운전자에 경고 알림 메시지를 출력 할 수 있다. 예를 들어, 도 3에서 차량이 직진으로 주행 중인 경우, 프로세서는 촬영된 영상으로부터 관심 영역(P1~P 3)을 설정한다. 이때, 관심 영역(P2)인 차량이 차선 변경을 통해 자차의 전방 쪽으로 접근하는 경우, 운전자는 시선 정보와 매칭되는 영역으로 도 2에서 제 1 영역 또는 제 3영역을 보는 것이 정상적이며, 관심 영역(P2)도 제 1 영역 또는 제 3 영역에 대응되게 된다. 그러나 이때 제 8 영역이나 제 6 영역과 같이 관심 영역(P2)에 대 응되는 영역과 상이한 경우, 프로세서는 운전자에게 경고 알림 메시지를 출력할 수 있다. 이에 따라, 본 발명의 일 실시예는 촬영된 영상 전체를 분석하지 않고, 관심 영역만으로 객체를 빠르고 정확하 게 검출 및 분석할 수 있어, 사고의 위험에 대하여 실시간으로 대처하게끔 할 수 있다. 한편, 관심 영역은 도 3에 도시된 예시와 같이, 주변 영상 촬영부가 거리별로 구분되는 복수 개의 거리별 관심 영역(P4)을 설정하고, 해당 객체에 대한 관심 영역(P1~P3)를 설정한 다음, 관심 영역(P1~P3)에 대하여 복수 개 의 거리 별 관심 영역을 매핑시킴으로써, 본 발명의 일 실시예는 관심 영역(P1~P3)에 대한 자차와의 거리, 상대 적인 위치 정보를 보다 정확하고 빠르게 획득할 수 있다. 예를 들어, 관심 영역(P1)의 경우 상대적으로 촘촘한 복수 개의 거리별 관심 영역(P4)의 중심 부분에 위치하고, 관심 영역(P2)의 경우 상대적으로 넓은 간격을 가지는 복수 개의 거리별 관심 영역(P4)의 측면 부분에 위치하는 것을 확인하여, 프로세서는 관심 영역(P1), 관심영역(P2)에 대응하는 차량과 자차와의 거리 및 상대적인 위치를 정확하고 빠르게 획득할 수 있다. 또한, 운전자의 시선 정보에 매칭되는 영역을 주행 정보에 해당하는 영역과 대응되는지 여부를 판단함에 있어, 관심 영역은 거리별 관심 영역(P4)의 정보(위치 및 거리 정보)를 포함하고 있는바, 복수의 객체에 해당하는 관 심 영역들이 도 3의 동일 영역에 포함되더라도, 사용자의 시선 정보에 기초하여 복수의 객체 중 사용자가 현재 관심을 가지고 있는 하나 또는 그 이상의 객체의 정보를 정확하게 추출할 수 있다. 예를 들어, 도 3에서 관심 영역 (P2)와 관심 영역(P3)이 모두 도 2의 동일한 제 3 영역에 해당하고, 이 중에서 사용자가 관심 영역(P3)인 객체를 중심으로 바라보고 있는 경우, 본 발명의 일 실시예는 제 3 영역에 포함되는 모든 관심 영역(P2, P3)에 대한 정보를 획득하지 않고, 사용자의 시선 정보 즉, 얼굴과 시선이 향하고 있는 객 체에 대응하는 관심 영역(P3)에 대한 정보만을 획득할 수 있다. 한편, 본 발명의 일 실시예에 따른 차량 운전 보조 장치는 프로세서가 운전자의 얼굴 및 시선의 방향 정보와 매칭되는 영역에 대한 운전자의 주시 시간을 측정하여 시선 정보로 획득할 수 있다. 즉, 시선 정보는 얼 굴 방향 정보, 시선 방향 정보 및 주시 시간 정보를 포함할 수 있다. 이에 따라, 프로세서는 매칭되는 영역이 주행 정보와 대응되지 않는 경우에 주시 시간이 일정 시간을 초과 하는 경우 운전자에게 경고 알림 메시지를 출력할 수 있다. 즉, 운전자가 주행 차선 정보와 대응되는 영역 또는 객체의 정보와 대응되는 영역을 바라보지 않고, 대응되지 않는 영역을 일정 시간을 초과하여 바라보고 있는 경우 사고 위험성이 높은 것으로 판단하여 경고 알림 메시지 를 출력하게 된다. 예를 들어, 차량이 직진 차선을 주행하고 있는 상태에서 운전자의 시선 방향이 제 1 영역 내지 제 4 영역을 바 라보고 있는 경우 각 영역에 대한 주시 시간을 측정한다. 차량이 직진 차선을 주행하고 있는 상태에서, 운전자의 얼굴 및 시선의 방향 정보와 매칭되는 영역이 제 1 내지 제 4 영역이 아닌 제 5 내지 제 8 영역인 경우, 해당 영역에 대한 주시 시간을 측정하게 되며, 이때 제 5 내지 제 8 영역에 대한 주시 시간이 예를 들어 5초를 초과하는 경우 프로세서는 사고 위험성이 높은 것으로 판단하여 운전자에게 경고 알림 메시지를 출력할 수 있다. 또한, 프로세서는 운전자의 시선 정보를 실시간으로 또는 기 설정된 주기마다 메모리에 누적하여 저 장할 수 있다. 그리고 미리 학습된 알고리즘을 통해 누적된 시선 정보로부터 운전자의 예측 시선 정보를 생성할 수 있다. 이때, 프로세서는 예측 시선 정보를 운전자 별로 구분하여 생성하되, 운전자의 얼굴 및 시선의 방향 정보 와 매칭되는 영역이 주행 정보와 대응되지 않으나, 주행 상태가 안전한 경우로 판단된 횟수가 기 설정된 횟수 이상을 만족하는 경우 생성할 수 있다. 프로세서는 운전자의 시선 정보 즉, 얼굴의 방향 정보, 시선의 방향 정보 및 주시 시간 정보를 각 영역별 로 구분하여 메모리에 누적하여 저장한다. 이와 같이 누적된 시선 정보를 입력값으로 설정하여 미리 학습된 알고리즘을 통해 운전자의 예측 시선 정보를 생성할 수 있다. 이때, 미리 학습된 알고리즘은 인공지능 신경망(Artificial Neural Network), 은닉 마르코프 모델(Hidden-Markov-Model, HMM) 기반의 알고리즘뿐만 아니라, CNN(Convolutional Neural Networks), RNN(Recurrent neural network) 등의 딥러닝 기반의 알고리즘이 적용될 수 있다. 예를 들어, 운전자가 차량을 후진하고자 하는 경우 일반적으로 백미러 영역인 제 5 영역 또는 사이드 미러 영역 인 제 7 영역과 제 8 영역을 바라보게 되나, 후방카메라가 설치되어 있는 경우 제 9 영역만을 보고도 후진이 가 능할 수 있다. 이 경우 프로세서는 제 9 영역만을 보고 후진하는 경우가 일정 횟수 이상 발생하되, 충돌 등의 사고가 없 는 경우, 매칭되는 영역(제 9 영역)이 주행 정보와 대응되지 않으나 안전한 것으로 판단하여 예측 시선 정보로 생성하고 이 경우 경고 알림 메시지를 출력하지 않는다. 또 다른 예로, 직진 차선을 주행 중에 왼쪽 차선으로 차선 변경을 하고자 하는 경우, 차량이 많은 복잡한 도로 에서는 왼쪽 사이드 미러 영역인 제 7 영역을 바라보고 차선 변경을 하는 것이 일반적이나, 차량이 거의 드문 한적한 도로에서는 뒷차량의 유무만을 보고도 차선 변경을 하는 경우가 있으며, 이 경우 백미러 영역인 제 5 영 역만을 보고도 차선 변경이 가능하다. 이러한 케이스에서 프로세서는 제 5 영역만을 보고 차선 변경을 하는 경우가 일정 횟수 이상 발생하되, 충 돌 등의 사고가 없는 경우, 매칭되는 영역(제 5 영역)이 주행 정보와 대응되지 않으나 안전한 것으로 판단하여 예측 시선 정보로 생성하고 이 경우 경고 알림 메시지를 출력하지 않게 된다. 이와 같이, 본 발명의 일 실시예에 따른 차량 운전 보조 장치는 운전자의 운전 습관 등의 패턴을 분석하고, 분석한 결과에 따른 예측 시선 정보를 생성하여 경고 알림 메시지가 출력되도록 함으로써, 일률적으 로 경고 알림 메시지를 출력하여 정상적인 운전 상태에서도 경고 알림 메시지로 인해 운전에 방해되는 것을 방 지할 수 있다. 한편, 경고 알림 메시지는 차량의 계기판, HUD(Head Up Display) 또는 AVN(Audio Video Navigation) 시스템을 통해 음성, 화면에 디스플레이되는 형식으로 출력될 수 있음은 물론이고, 안전벨트나 시트의 진동을 통해 경고 알림 메시지는 출력될 수 있다. 또는 차량과 페어링된 스마트 폰, 태블릿 PC, 스마트워치 등과 같은 스마트 단 말을 통해 경고 알림 메시지는 출력될 수도 있다. 프로세서는 운전자가 차량 내에서 주시 가능한 복수 개의 영역에 대하여 각각 상이한 가중치를 적용하고, 적용된 가중치에 따라 경고 알림 메시지를 출력하기 위한 경고 수준을 상이하게 적용시킬 수 있다. 예를 들어, 운전자가 주로 바라보는 전방 영역인 제 1 내지 제 4 영역은 가중치를 상대적으로 낮게 설정하고, 차선 변경시 사용하는 제5 내지 제 7 영역은 중간 단계로 설정하며, 졸음 운전시와 같은 상황에서 바라보게 되 는 영역인 제 8 내지 제 9 영역은 가중치를 높게 설정할 수 있다. 이에 따라, 상술한 경고 알림 메시지가 가중 치가 낮은 단계에서는 화면 상의 팝업, 깜빡임 등으로만 출력되고, 중간 단계에서는 1회의 낮은 음량으로 출력 되며, 높은 단계에서는 높은 음량과 복수회, 또는 위험 요소가 해소되었을 때까지 출력될 수 있다. 또한, 프로세서는 복수 개의 영역별 가중치를 적용함에 있어, 차량의 주행 정보를 반영하여 가중치를 실시 간으로 다르게 설정할 수 있다. 즉, 본 발명의 일 실시예는 차량의 주행 상태가 직진 중인지, 차선을 변경 중인 지, 유턴 중인지, 후진 중인지 등을 고려하고, 차량의 속도, 객체의 정보 등도 가중치를 설정함에 있어 파라미 터로 함께 적용시킬 수 있다.예를 들어, 차량이 직진 중인 경우 제 1 내지 제 4 영역은 가중치가 가장 낮은 영역일 것이나, 후진 중인 경우 제 1 내지 제 4 영역은 잘 바라보지 않게 되지 않는 영역이므로 돌발 상황 위험성이 높은바, 가중치를 조금 더 높게 설정할 수 있다. 또 다른 예로, 왼쪽 차선으로 차선 변경을 하는 경우 왼쪽 사이드 미러 영역인 제 7 영역이 아닌 오른쪽 사이드 미러인 제 6 영역에 대하여 가중치를 더 높게 설정하여 차선 변경 시도 중에 오른편에서 접근하는 차량, 보행자 등의 충돌 위험에 대하여 보다 적극적으로 경고 알림 메시지를 출력하게끔 할 수 있다. 또한, 본 발명의 일 실시예는 경고 알림 메시지를 출력하는 것뿐만 아니라, 경고 알림 메시지를 출력함과 동시 에 또는 일정 시간이 경과함에도 불구하고 운전자의 조치가 없는 경우, 차량의 일부 제어 또는 전체 제어를 통 해 사고 위험성을 방지할 수 있다. 즉, 보행자와의 충돌 위험이 있는 경우 경고 알림 메시지를 출력함과 동시에 또는 일정 시간 후에도 차량의 속 도가 감속되지 않는 경우 프로세서는 직접 차량의 속도를 감속시키거나, 주변 차량 등의 객체 유무를 판단 하여 차량의 핸들의 조향각을 변경시켜 충돌 발생을 직접 방지하게끔 할 수도 있다. 한편, 본 발명의 일 실시예에 따른 차량 운전 보조 장치는 주행 상태의 안전 여부의 판단 결과에 기초하여 운전자의 안전 운전 지수를 산출할 수 있다. 즉, 프로세서는 시선 정보와 주행 차선 정보, 객체의 정보와 같은 주행 정보가 매칭되지 않음에 따라 경고 알림 메시지를 출력한 횟수, 경고 수준에 따른 경고 알림 메시지의 출력 단계 등을 종합적으로 고려하여 운전자 의 안전 운전 지수를 산출할 수 있다. 이 경우 프로세서는 예측 시선 정보로 생성됨에 따라 주행 정보와 영역이 대응되지 않는 경우에는 경고 알 림 메시지를 출력하지 않아도 되는바, 주행 정보와 영역이 대응되는 것으로 취급하여 안전 운전 지수를 산출할 수 있다. 이러한 안전 운전 지수는 1일마다 또는 1달과 같이 일정 주기 별로 산출될 수 있고, 산출된 안전 운전 지수는 운전자 마일리지 등과 같은 인센티브나 운전자 벌점 등과 같은 디센티브 제공시 반영될 수 있다. 이러한 안전 운전 지수를 통해 인센티브나 디센티브를 제공함으로써, 차량 운전시 졸음 운전, 운전 미숙 행위 등에 대해 보다 적극적인 방지가 가능한바, 최종적으로 교통 사고 감소에 큰 영향을 미칠 수 있다는 효과를 기 대할 수 있다. 참고로, 본 발명의 실시예에 따른 도 1에 도시된 구성 요소들은 소프트웨어 또는 FPGA(Field Programmable Gate Array) 또는 ASIC(Application Specific Integrated Circuit)와 같은 하드웨어 형태로 구현될 수 있으며, 소정 의 역할들을 수행할 수 있다. 그렇지만 '구성 요소들'은 소프트웨어 또는 하드웨어에 한정되는 의미는 아니며, 각 구성 요소는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 구성 요소는 소프트웨어 구성 요소들, 객체지향 소프트웨어 구성 요소들, 클래스 구성 요소 들 및 태스크 구성 요소들과 같은 구성 요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로 그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 메모리, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성 요소들과 해당 구성 요소들 안에서 제공되는 기능은 더 작은 수의 구성 요소들로 결합되거나 추가적인 구 성 요소들로 더 분리될 수 있다. 이하에서는 도 4를 참조하여, 본 발명의 일 실시예에 따른 차량 운전 보조 장치에서의 안전운전 유도 방법 을 설명하도록 한다. 도 4는 본 발명의 일 실시예에 따른 안전운전 유도 방법의 순서도이다. 본 발명의 일 실시예에 따른 안전 운전 유도 방법은 먼저, 운전자의 얼굴을 촬영하여 운전자의 얼굴 및 시선의 방향 정보를 포함하는 시선 정보를 분석한다(S110). 다음으로, 차량의 전방을 촬영한 주변 영상으로부터 차량의 주행 속도 정보, 주행 방향 정보, 주행 차선의 정보 및 상기 주행 차선을 기준으로 전방, 후방, 좌측 및 우측에 위치하는 객체의 정보 중 하나 이상을 포함하는 주 행 정보를 분석한다(S120).다음으로, 시선 정보와 주행 정보와의 대응 여부에 기초하여 차량의 주행 상태의 안전 여부를 판단하고(S130), 차량의 주행 상태가 안전하지 않은 것으로 판단된 경우 운전자에게 경고 알림 메시지를 출력한다(S140). 한편 상술한 설명에서, 단계 S110 내지 S140은 본 발명의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 아울러, 기타 생략된 내용이라 하더라도 도 1 내지 도 3에서의 차량 운전 보조 장치에 관하여 이미 기술된 내용은 도 4의 안전 운전 유도 방법에도 적용된다. 본 발명의 일 실시예는 컴퓨터에 의해 실행되는 매체에 저장된 컴퓨터 프로그램 또는 컴퓨터에 의해 실행가능한 명령어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체 및 통신 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판 독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기 술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈, 또는 반송파와 같은 변조된 데이터 신호의 기타 데이터, 또는 기타 전송 메커니즘을 포함하며, 임의의 정보 전달 매체를 포함한다. 본 발명의 방법 및 시스템은 특정 실시예와 관련하여 설명되었지만, 그것들의 구성 요소 또는 동작의 일부 또는 전부는 범용 하드웨어 아키텍쳐를 갖는 컴퓨터 시스템을 사용하여 구현될 수 있다."}
{"patent_id": "10-2017-0064457", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2017-0064457", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 차량 운전 보조 장치의 블록도이다. 도 2는 차량 내 주시 가능한 복수 개의 영역을 설명하기 위한 도면이다. 도 3은 주변 영상의 예시도이다. 도 4는 본 발명의 일 실시예에 따른 안전운전 유도 방법의 순서도이다."}
