{"patent_id": "10-2020-0040549", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0123152", "출원번호": "10-2020-0040549", "발명의 명칭": "인공지능 프로세서를 위한 명령어 자동 생성 장치 및 그의 최적화 방법", "출원인": "한국전자통신연구원", "발명자": "김현미"}}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 프로세서를 최적화하는 방법으로서,상기 인공지능 프로세서가 적용되는 뉴럴 네트워크 모델을 최적화한 모델 최적화 정보와 상기 인공지능 프로세서의 구성 정보를 기반으로, 상기 인공지능 프로세서가 수행하는 동작에 대한 최적화 조건 정보를 고려하여 상기 동작을 수행하기 위한 조건 조합을 획득하는 단계;상기 조건 조합을 토대로 하는 하드웨어 모델링을 생성하고, 상기 하드웨어 모델링을 통해 성능치를 예측하는단계; 및상기 예측된 성능치와 미리 설정된 최적의 성능값의 비교를 통해 최적의 조건 조합을 결정하는 단계를 포함하는 최적화 방법."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 최적의 조건 조합을 결정하는 단계는 상기 예측된 성능치와 미리 설정된 최적의 성능값의 비교 결과, 더 작은 값으로 상기 최적의 성능값을 업데이트하는 단계를 포함하는, 최적화 방법."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 동작을 수행하기 위하여 조합이 가능한 조건 조합에 대하여, 상기 성능치를 예측하는 단계와 상기 업데이트하는 단계가 반복적으로 수행되고, 상기 최적의 조건 조합을 결정하는 단계는 상기 조건 조합에 포함되는 모든 조건에 대하여 상기 성능치를 예측하는 단계와 상기 업데이트하는 단계가 수행된 경우, 최적의 조건 조합을 결정하는 단계를 포함하는, 최적화 방법."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 최적화 조건 정보는 상기 인공지능 프로세서의 내부 메모리로의 입력 데이터, 가중치 데이터, 그리고 출력 데이터의 할당 비율, 전체 데이터를 분할하는 타일링 정보, 데이터 분할 정보, 상기 뉴럴 네트워크의 인접한 레이어간 데이터 재사용여부, 동작별로 동작간 의존성을 고려하여 병렬 동작이 가능하도록 하는 더블 버퍼링 기법 적용 여부, 동작들의스케줄링을 포함하는, 최적화 방법."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 동작은 상기 인공지능 프로세서의 외부 메모리에서 내부 메모리로 입력 데이터를 로딩하는 제1 동작, 상기 외부 메모리에서 가중치 데이터를 로딩하는 제2 동작, 상기 인공지능 프로세서의 연산기가 연산을 수행하는 제3 동작, 상기공개특허 10-2021-0123152-3-연산 결과 데이터를 상기 외부 메모리로 저장하는 제4 동작을 포함하는, 최적화 방법."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 조건 조합을 획득하는 단계는 상기 할당 비율, 상기 더블 버퍼링 기법 적용 여부, 및 상기 동작들의 스케줄링을 기반으로, 더블 버퍼링 조건과, 상기 제3 동작을 위한 입력 데이터와 출력 데이터를 위한 상기 내부 메모리 동시 접근 가능 여부 조건, 그리고 전체 가중치 할당 여부를 조합하여 스케줄링 관련 탐색 공간들인 제1 조건 조합을 획득하는 단계를 포함하는, 최적화 방법."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제1 조건 조합은 가중치 우선 모드에 따른 스케줄링 관련 탐색 공간과, 입력 데이터 우선 모드에 따른 스케줄링 관련 탐색 공간을 포함하는, 최적화 방법."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 조건 조합을 획득하는 단계는 상기 제1 조건 조합에 상기 타일링 정보를 결합하여 제2 조건 조합을 획득하는 단계; 상기 제2 조건 조합에 상기 데이터 분할 정보를 결합하여 제3 조건 조합을 획득하는 단계; 및상기 제3 조건 조합에 상기 데이터 재사용률 여부를 기반으로 스케줄링 조건을 재조합하여 제4 조건 조합을 획득하는 단계를 더 포함하는, 최적화 방법."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 성능치를 예측하는 단계는상기 제4 조건 조합을 토대로 하는 하드웨어 모델링을 생성하고, 상기 하드웨어 모델링을 통해 성능치를 예측하는, 최적화 방법."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 성능치를 예측하는 단계는 상기 하드웨어 모델링을 통해 상기 인공지능 프로세서가 수행하는 동작별로 성능치를 예측하고,상기 성능치를 예측하는 단계 이후에,상기 동작별로 예측된 성능치에 가중치를 부여하고, 상기 동작별 테스트에 따라 획득되는 실제 성능과 상기 동작별 예측된 성능치의 비율에 따라 상기 동작별로 부여된 가중치를 보정하는 단계를 더 포함하는, 최적화 방법."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 인공지능 프로세서는 시스톨릭 어레이 구조의 가속기인, 최적화 방법.공개특허 10-2021-0123152-4-청구항 12 인공지능 프로세서의 동작을 위한 명령을 생성하는 장치로서,인터페이스 장치; 및상기 인터페이스 장치와 연결되어 있으며, 상기 인공지능 프로세서가 적용되는 뉴럴 네트워크 모델을 최적화한모델 최적화 정보와 상기 인공지능 프로세서의 구성 정보를 기반으로, 상기 인공지능 프로세서가 수행하는 동작을 수행하기 위한 최적의 조건 조합을 획득하고 상기 최적의 조건 조합에 따른 명령을 생성하도록 구성된 프로세서를 포함하며,상기 프로세서는 상기 인공지능 프로세서가 수행하는 동작에 대한 최적화 조건 정보를 고려하여 상기 동작을 수행하기 위한 조건조합을 획득하는 단계;상기 조건 조합을 토대로 하는 하드웨어 모델링을 생성하고, 상기 하드웨어 모델링을 통해 성능치를 예측하는단계; 및상기 예측된 성능치와 미리 설정된 최적의 성능값의 비교를 통해 최적의 조건 조합을 결정하는 단계를 수행하도록 구성되는, 명령어 생성 장치."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 프로세서는 상기 예측된 성능치와 미리 설정된 최적의 성능값의 비교 결과, 더 작은 값으로 상기 최적의 성능값을 업데이트하는 단계를 수행하도록 구성되고, 상기 동작을 수행하기 위하여 조합이 가능한 조건 조합에 대하여, 상기 성능치를 예측하는 단계와 상기 업데이트하는 단계가 반복적으로 수행되는, 명령어 생성 장치."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 프로세서는, 상기 조건 조합에 포함되는 모든 조건에 대하여 상기 성능치를 예측하는 단계와 상기 업데이트하는 단계가 수행된 경우, 상기 동작별 최적의 조건 조합을 결정하고, 상기 최적의 조건 조합을 토대로 해당 동작을 수행하기 위한 명령을 생성하는 단계를 수행하도록 구성되는, 명령어 생성 장치."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 최적화 조건 정보는 상기 인공지능 프로세서의 내부 메모리로의 입력 데이터, 가중치 데이터, 그리고 출력 데이터의 할당 비율, 전체 데이터를 분할하는 타일링 정보, 데이터 분할 정보, 상기 뉴럴 네트워크의 인접한 레이어간 데이터 재사용여부, 동작별로 동작간 의존성을 고려하여 병렬 동작이 가능하도록 하는 더블 버퍼링 기법 적용 여부, 동작들의스케줄링을 포함하는, 명령어 생성 장치."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 인공지능 프로세서가 수행하는 동작은, 상기 인공지능 프로세서의 외부 메모리에서 내부 메모리로 입력 데이터를 로딩하는 제1 동작, 상기 외부 메모리에서 가중치 데이터를 로딩하는 제2 동작, 상기 인공지능 프로세서공개특허 10-2021-0123152-5-의 연산기가 연산을 수행하는 제3 동작, 상기 연산 결과 데이터를 상기 외부 메모리로 저장하는 제4 동작을 포함하는, 명령어 생성 장치."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 프로세서는, 상기 할당 비율, 상기 더블 버퍼링 기법 적용 여부, 및 상기 동작들의 스케줄링을 기반으로, 더블 버퍼링 조건과, 상기 제3 동작을 위한 입력 데이터와 출력 데이터를 위한 상기 내부 메모리 동시 접근 가능 여부 조건, 그리고 전체 가중치 할당 여부를 조합하여 스케줄링 관련 탐색 공간들인 제1 조건 조합을 획득하는 단계를 수행하도록 구성되는, 명령어 생성 장치."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 프로세서는, 상기 제1 조건 조합에 상기 타일링 정보를 결합하여 제2 조건 조합을 획득하는 단계; 상기 제2 조건 조합에 상기 데이터 분할 정보를 결합하여 제3 조건 조합을 획득하는 단계; 및상기 제3 조건 조합에 상기 데이터 재사용률 여부를 기반으로 스케줄링 조건을 재조합하여 제4 조건 조합을 획득하는 단계를 추가적으로 수행하도록 구성되며,상기 성능치를 예측하는 단계 수행시, 상기 프로세서는 상기 제4 조건 조합을 토대로 하는 하드웨어 모델링을 생성하고, 상기 하드웨어 모델링을 통해성능치를 예측하도록 구성되는, 명령어 생성 장치."}
{"patent_id": "10-2020-0040549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서,상기 프로세서는 상기 성능치를 예측하는 단계에서 상기 하드웨어 모델링을 통해 상기 인공지능 프로세서가 수행하는 동작별로성능치를 예측하도록 구성되고,상기 성능치를 예측하는 단계 이후에,상기 동작별로 예측된 성능치에 가중치를 부여하고, 상기 동작별 테스트에 따라 획득되는 실제 성능과 상기 동작별 예측된 성능치의 비율에 따라 상기 동작별로 부여된 가중치를 보정하는 단계를 추가적으로 수행하도록 구성되는, 명령어 생성 장치."}
{"patent_id": "10-2020-0040549", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 프로세서를 위한 명령어 자동 생성 장치 및 그의 최적화 방법이 제공된다. 상기 방법은, 상기 인공지능 프로세서가 적용되는 뉴럴 네트워크 모델을 최적화한 모델 최적화 정보와 상기 인공지능 프로세서의 구성 정보를 기반으로, 상기 인공지능 프로세서가 수행하는 동작에 대한 최적화 조건 정보를 고려하여 상기 동작을 수행하기 위한 조건 조합을 획득하는 단계; 상기 조건 조합을 토대로 하는 하드웨어 모델링을 생성하고, 상기 하드웨어 모 델링을 통해 성능치를 예측하는 단계; 및 상기 예측된 성능치와 미리 설정된 최적의 성능값의 비교를 통해 최적 의 조건 조합을 결정하는 단계를 포함한다."}
{"patent_id": "10-2020-0040549", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 프로세서를 위한 명령어 자동 생성 장치 및 그의 최적화 방법에 관한 것이다."}
{"patent_id": "10-2020-0040549", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능 분야의 발전으로 인해 전용 가속 기능을 가진 인공지능 프로세서의 필요성이 대두된다. 일반적으로 인공지능 프로세서는 입출력 데이터와 가중치 데이터를 저장하는 외부 메모리와 딥러닝 알고리즘의 대부분의 연 산을 차지하는 벡터 또는 행렬 계산을 가속하기 위한 연산기, 그리고 연산기에 빠른 데이터를 공급하고 출력되는 데이터를 저장하기 위한 내부 메모리로 구성된다. 이렇게 구성된 인공지능 전용 프로세서는 다양한 뉴럴(neural) 네트워크 모델에 대응하기 위해 프로그래밍 가능 하도록 전용 명령어를 정의하여 사용한다. 비록 인공지능 프로세서가 일반적인 목적의 프로세서와 다르게 특정 기능을 가지고 뉴럴 네트워크를 가속한다고 할지라도, 다양하고 빠르게 변화하는 뉴럴 네트워크 알고리즘에 대 응하기 위해서는 프로그래밍이 가능해야 하고 기존 일반 프로세서나 그래픽 프로세서보다 좋은 성능이 요구되고 있다. 또한 요구된 기능과 성능을 가진 인공지능 프로세서를 다양한 뉴럴 네트워크 모델에 따라 최고의 성능으로 운용 하기 위한 명령어를 자동 생성하는 시스템인 컴파일러가 필수적이다. 하지만 기존 컴파일러들은 딥러닝 알고리 즘을 처리하기 위한 CPU(Central Processing Unit)와 GPU(Graphics Processing Unit) 하드웨어를 대상으로 최 적화하는데 초점이 맞춰져 있어 인공지능 전용 프로세서를 위한 전용 컴파일러가 요구된다. 특히, 기존 딥러닝 시스템의 자동 코드 생성기의 경우 성능 최적화 기능의 구체적인 제시가 없이 코드 자동 생성 장치에 초점이 맞 춰져 있거나, CPU 코드나 이미지 처리 하드웨어 플랫폼 등 다른 하드웨어를 위한 최적화를 다루고 있어 딥러닝 시스템에 활용하기 어렵다."}
{"patent_id": "10-2020-0040549", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 인공지능 전용 프로세서(또는 뉴럴 네트워크의 딥러닝 가속기)가 다양한 뉴 럴 네트워크 모델을 가장 최적의 성능으로 처리할 수 있도록 하는 명령어 자동 생성 장치 및 그 최적화 방법을 제공하는 것이다."}
{"patent_id": "10-2020-0040549", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시 예에 따르면, 인공지능 프로세서를 최적화하는 방법이 제공된다. 상기 방법은, 상기 인공지 능 프로세서가 적용되는 뉴럴 네트워크 모델을 최적화한 모델 최적화 정보와 상기 인공지능 프로세서의 구성 정 보를 기반으로, 상기 인공지능 프로세서가 수행하는 동작에 대한 최적화 조건 정보를 고려하여 상기 동작을 수 행하기 위한 조건 조합을 획득하는 단계; 상기 조건 조합을 토대로 하는 하드웨어 모델링을 생성하고, 상기 하 드웨어 모델링을 통해 성능치를 예측하는 단계; 및 상기 예측된 성능치와 미리 설정된 최적의 성능값의 비교를 통해 최적의 조건 조합을 결정하는 단계를 포함한다. 일 구현 예에서, 상기 최적의 조건 조합을 결정하는 단계는, 상기 예측된 성능치와 미리 설정된 최적의 성능값 의 비교 결과, 더 작은 값으로 상기 최적의 성능값을 업데이트하는 단계를 포함할 수 있다. 일 구현 예에서, 상기 동작을 수행하기 위하여 조합이 가능한 조건 조합에 대하여, 상기 성능치를 예측하는 단 계와 상기 업데이트하는 단계가 반복적으로 수행될 수 있다. 이 경우, 상기 최적의 조건 조합을 결정하는 단계 는, 상기 조건 조합에 포함되는 모든 조건에 대하여 상기 성능치를 예측하는 단계와 상기 업데이트하는 단계가 수행된 경우, 최적의 조건 조합을 결정하는 단계를 포함할 수 있다. 일 구현 예에서, 상기 최적화 조건 정보는 상기 인공지능 프로세서의 내부 메모리로의 입력 데이터, 가중치 데 이터, 그리고 출력 데이터의 할당 비율, 전체 데이터를 분할하는 타일링 정보, 데이터 분할 정보, 상기 뉴럴 네 트워크의 인접한 레이어간 데이터 재사용 여부, 동작별로 동작간 의존성을 고려하여 병렬 동작이 가능하도록 하 는 더블 버퍼링 기법 적용 여부, 동작들의 스케줄링을 포함할 수 있다. 일 구현 예에서, 상기 동작은 상기 인공지능 프로세서의 외부 메모리에서 내부 메모리로 입력 데이터를 로딩하 는 제1 동작, 상기 외부 메모리에서 가중치 데이터를 로딩하는 제2 동작, 상기 인공지능 프로세서의 연산기가 연산을 수행하는 제3 동작, 상기 연산 결과 데이터를 상기 외부 메모리로 저장하는 제4 동작을 포함할 수 있다. 일 구현 예에서, 상기 조건 조합을 획득하는 단계는, 상기 할당 비율, 상기 더블 버퍼링 기법 적용 여부, 및 상 기 동작들의 스케줄링을 기반으로, 더블 버퍼링 조건과, 상기 제3 동작을 위한 입력 데이터와 출력 데이터를 위 한 상기 내부 메모리 동시 접근 가능 여부 조건, 그리고 전체 가중치 할당 여부를 조합하여 스케줄링 관련 탐색 공간들인 제1 조건 조합을 획득하는 단계를 포함할 수 있다. 일 구현 예에서, 상기 제1 조건 조합은 가중치 우선 모드에 따른 스케줄링 관련 탐색 공간과, 입력 데이터 우선 모드에 따른 스케줄링 관련 탐색 공간을 포함할 수 있다. 일 구현 예에서, 상기 조건 조합을 획득하는 단계는, 상기 제1 조건 조합에 상기 타일링 정보를 결합하여 제2 조건 조합을 획득하는 단계; 상기 제2 조건 조합에 상기 데이터 분할 정보를 결합하여 제3 조건 조합을 획득하 는 단계; 및 상기 제3 조건 조합에 상기 데이터 재사용률 여부를 기반으로 스케줄링 조건을 재조합하여 제4 조 건 조합을 획득하는 단계를 더 포함할 수 있다. 일 구현 예에서, 상기 성능치를 예측하는 단계는, 상기 제4 조건 조합을 토대로 하는 하드웨어 모델링을 생성하 고, 상기 하드웨어 모델링을 통해 성능치를 예측할 수 있다. 일 구현 예에서, 상기 성능치를 예측하는 단계는 상기 하드웨어 모델링을 통해 상기 인공지능 프로세서가 수행 하는 동작별로 성능치를 예측할 수 있다. 이 경우, 상기 성능치를 예측하는 단계 이후에, 상기 방법은, 상기 동 작별로 예측된 성능치에 가중치를 부여하고, 상기 동작별 테스트에 따라 획득되는 실제 성능과 상기 동작별 예 측된 성능치의 비율에 따라 상기 동작별로 부여된 가중치를 보정하는 단계를 더 포함할 수 있다. 일 구현 예에서, 상기 인공지능 프로세서는 시스톨릭 어레이 구조의 가속기일 수 있다. 본 발명의 다른 실시 예에 따르면, 인공지능 프로세서의 동작을 위한 명령을 생성하는 장치가 제공된다. 상기 장치는, 인터페이스 장치; 및 상기 인터페이스 장치와 연결되어 있으며, 상기 인공지능 프로세서가 적용되는 뉴 럴 네트워크 모델을 최적화한 모델 최적화 정보와 상기 인공지능 프로세서의 구성 정보를 기반으로, 상기 인공 지능 프로세서가 수행하는 동작을 수행하기 위한 최적의 조건 조합을 획득하고 상기 최적의 조건 조합에 따른 명령을 생성하도록 구성된 프로세서를 포함하며, 상기 프로세서는 상기 인공지능 프로세서가 수행하는 동작에 대한 최적화 조건 정보를 고려하여 상기 동작을 수행하기 위한 조건 조합을 획득하는 단계; 상기 조건 조합을 토대로 하는 하드웨어 모델링을 생성하고, 상기 하드웨어 모델링을 통해 성능치를 예측하는 단계; 및 상기 예측 된 성능치와 미리 설정된 최적의 성능값의 비교를 통해 최적의 조건 조합을 결정하는 단계를 수행하도록 구성된 다. 일 구현 예에서, 상기 프로세서는, 상기 예측된 성능치와 미리 설정된 최적의 성능값의 비교 결과, 더 작은 값 으로 상기 최적의 성능값을 업데이트하는 단계를 수행하도록 구성되고, 상기 동작을 수행하기 위하여 조합이 가 능한 조건 조합에 대하여, 상기 성능치를 예측하는 단계와 상기 업데이트하는 단계가 반복적으로 수행될 수 있 다. 일 구현 예에서, 상기 프로세서는, 상기 조건 조합에 포함되는 모든 조건에 대하여 상기 성능치를 예측하는 단 계와 상기 업데이트하는 단계가 수행된 경우, 상기 동작별 최적의 조건 조합을 결정하고, 상기 최적의 조건 조 합을 토대로 해당 동작을 수행하기 위한 명령을 생성하는 단계를 수행하도록 구성될 수 있다. 일 구현 예에서, 상기 최적화 조건 정보는, 상기 인공지능 프로세서의 내부 메모리로의 입력 데이터, 가중치 데 이터, 그리고 출력 데이터의 할당 비율, 전체 데이터를 분할하는 타일링 정보, 데이터 분할 정보, 상기 뉴럴 네 트워크의 인접한 레이어간 데이터 재사용 여부, 동작별로 동작간 의존성을 고려하여 병렬 동작이 가능하도록 하 는 더블 버퍼링 기법 적용 여부, 동작들의 스케줄링을 포함할 수 있다. 일 구현 예에서, 상기 인공지능 프로세서가 수행하는 동작은, 상기 인공지능 프로세서의 외부 메모리에서 내부 메모리로 입력 데이터를 로딩하는 제1 동작, 상기 외부 메모리에서 가중치 데이터를 로딩하는 제2 동작, 상기 인공지능 프로세서의 연산기가 연산을 수행하는 제3 동작, 상기 연산 결과 데이터를 상기 외부 메모리로 저장하 는 제4 동작을 포함할 수 있다. 일 구현 예에서, 상기 프로세서는, 상기 할당 비율, 상기 더블 버퍼링 기법 적용 여부, 및 상기 동작들의 스케 줄링을 기반으로, 더블 버퍼링 조건과, 상기 제3 동작을 위한 입력 데이터와 출력 데이터를 위한 상기 내부 메 모리 동시 접근 가능 여부 조건, 그리고 전체 가중치 할당 여부를 조합하여 스케줄링 관련 탐색 공간들인 제1 조건 조합을 획득하는 단계를 수행하도록 구성될 수 있다. 일 구현 예에서, 상기 프로세서는, 상기 제1 조건 조합에 상기 타일링 정보를 결합하여 제2 조건 조합을 획득하 는 단계; 상기 제2 조건 조합에 상기 데이터 분할 정보를 결합하여 제3 조건 조합을 획득하는 단계; 및 상기 제 3 조건 조합에 상기 데이터 재사용률 여부를 기반으로 스케줄링 조건을 재조합하여 제4 조건 조합을 획득하는 단계를 추가적으로 수행하도록 구성될 수 있다. 이 경우, 상기 성능치를 예측하는 단계 수행시, 상기 프로세서 는 상기 제4 조건 조합을 토대로 하는 하드웨어 모델링을 생성하고, 상기 하드웨어 모델링을 통해 성능치를 예 측하도록 구성될 수 있다. 일 구현 예에서, 상기 프로세서는, 상기 성능치를 예측하는 단계에서 상기 하드웨어 모델링을 통해 상기 인공지 능 프로세서가 수행하는 동작별로 성능치를 예측하도록 구성될 수 있다. 이 경우, 상기 성능치를 예측하는 단계 이후에, 상기 프로세서는 상기 동작별로 예측된 성능치에 가중치를 부여하고, 상기 동작별 테스트에 따라 획득 되는 실제 성능과 상기 동작별 예측된 성능치의 비율에 따라 상기 동작별로 부여된 가중치를 보정하는 단계를 추가적으로 수행하도록 구성될 수 있다."}
{"patent_id": "10-2020-0040549", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 따르면, 최적화 알고리즘을 갖춘 전용 명령어 자동 생성 장치를 통해, 인공지능 전용 프로 세서(또는 뉴럴 네트워크의 딥러닝 가속기)가 다양한 뉴럴 네트워크 모델을 가장 최적의 성능으로 처리할 수 있 으므로, 인공지능 전용 프로세서 또는 뉴럴 네트워크의 딥러닝 가속기의 효율성을 극대화하고 자동화할 수 있다. 또한, 현재 개발된 인공지능 프로세서들을 분석하여 하드웨어 성능 최적화를 위한 동작을 구분과 문제 사항을 정의하고 이를 해결하기 위한 알고리즘을 제시함으로써, 딥러닝 시스템의 명령어 자동 생성 장치를 기반으로 해 당 시스템의 성능을 극대화할 수 있다."}
{"patent_id": "10-2020-0040549", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시 예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위 해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성 요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 단수로 기재된 표현은 \"하나\" 또는 \"단일\" 등의 명시적인 표현을 사용하지 않은 이상, 단수 또는 복수로 해석될 수 있다. 또한, 본 발명의 실시 예에서 사용되는 제1, 제2 등과 같이 서수를 포함하는 용어는 구성 요소들을 설명하는데 사용될 수 있지만, 구성 요소들은 용어들에 의해 한정되어서는 안 된다. 용어들은 하나의 구성 요소를 다른 구 성 요소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성 요소는 제2 구성 요소로 명명될 수 있고, 유사하게 제2 구성 요소도 제1 구성 요소로 명명될 수 있다. 본 발명은 인공지능 프로세서의 여러 아키텍처 중 TPU(Tensor Processing Unit)와 같이, 시스톨릭 어레이 (systolic array) 기반의 연산기를 차용하여 높은 병렬처리 능력을 갖는 장치 즉, 인공지능 프로세싱 장치를 예 로 하여 설명하며, 인공지능 프로세싱 장치가 다양한 뉴럴 네트워크 모델을 가장 최적의 성능으로 처리할 수 있 도록 하는 명령어 자동 생성 장치 및 그 최적화 방법을 제공한다. 여기서 인공지능 프로세싱 장치는 뉴럴 네트 워크의 딥러닝 가속기를 포함할 수 있으며, 반드시 위의 예에 한정되는 것은 아니다. 이하, 도면을 참조하여 본 발명의 실시 예에 따른 인공지능 프로세서를 위한 명령어 자동 생성 장치 및 그의 최 적화 방법에 대하여 설명한다. 도 1은 본 발명의 실시 예에 따른 인공지능 프로세싱 장치의 구조를 나타낸 도이다. 본 발명의 실시 예에 따른 인공지능 프로세서 즉, 인공지능 프로세싱 장치는 도 1에서와 같이, 입출력 데이 터와 가중치 데이터를 저장하는 외부 메모리, 연산기 그리고 연산기에 데이터를 공급하고 연산기로부터 출력되는 데이터를 저장하는 내부 메모리를 포함하며, 명령어 제어기, 그리고 외부 메모리와 내부 메모리 사이에 위치된 DMA(direct memory access)를 더 포함한다. 연산기는 도 1에서와 같이, 행(row)과 열(column)에 대응하는 위치에 연산 유닛이 배치되는 시스톨릭 어레 이 구조 기반의 연산기일 수 있으며, 이에 따라 내부 메모리도 연산기의 각 어레이별에 대응하는 개별 적 레지스터를 포함하는 구조로 이루어질 수 있다. 이러한 구조로 이루어지는 인공지능 프로세싱 장치에서, 연산기의 동작을 위한 데이터 접근은 내부 메모 리를 통해서만 이루어지며, 본 발명의 실시 예에 따른 인공지능 프로세싱 장치는 다음과 같은 동작을 수 행할 수 있다. (a) 외부 메모리에서 내부 메모리로 입력 데이터 로딩(Input data LOADing, ILOAD)(제1 동작이라고도 명명함). (b) 외부 메모리에서 가중치 데이터 로딩(Weight data LOADing, WLOAD)(제2 동작이라고도 명명함). (c) 연산기 동작(Multiplier accumulator Operation, MMOP)(제3 동작이라고도 명명함). (d) 연산 결과(출력) 데이터를 외부 메모리로 저장(Output data storing, OSTR) (제4 동작이라고도 명명함). 이러한 동작들을 수행할 때, 뉴럴 네트워크는 많은 데이터를 다루고 내부 메모리는 소요되는 비용으로 인해 작 은 크기로 구성되며, 이를 위해 해결하기 위해 인공지능 프로세서의 성능을 최적화하기 위해서는 본 발명의 실 시 예에서는 다음과 같은 사항들을 고려한다. 사항 1: 내부 메모리로의 입력 데이터, 가중치 데이터, 그리고 출력 데이터의 할당 비율 사항 2: 각 성분별로 할당된 메모리에 데이터를 저장하기 위해 전체 데이터를 분할하는 타일링(Tiling) 정보 (여기서 성분은 데이터의 성분을 나타내는 것으로, 예를 들어, 해당 데이터가 입력 데이터, 가중치, 출력 데이 터 중 하나임을 나타낸다) 사항 3: 타일링 정보와 처리하여야 하는 배치(batch) 크기를 고려하여, 시스톨릭 어레이 구조에서 각 행(row) 또는 열(column)에 배치되어야 하는 데이터 분할(Slicing) 정보 사항 4: 뉴럴 네트워크의 인접한 레이어간 데이터 재사용률을 높여 데이터 로딩과 저장에 필요한 동작을 생략한 성능의 최적화 사항 5: 인공지능 프로세싱 장치의 위의 4가지 동작(a~d)을 순차적으로 처리하는 경우 성능이 저하되는 것을 방 지하기 위해, 동작간의 의존성(Dependency)을 고려하여 병렬 동작이 가능하도록 하는 더블 버퍼링(Double Buffering) 기법 여부 사항 6: 순차 또는 병렬 동작들의 의존성을 고려한 동작들의 스케줄링 사항 7: 내부 메모리를 통해 레이어간 재사용되지 않는 데이터의 외부 메모리 할당시 단편화(fragmentation)를 최소화 이러한 사항들(설명의 편의상, 최적화 조건 정보라고 명명함)을 고려하여, 본 발명의 실시 예에서는 인공지능 프로세싱 장치의 동작을 위한 명령어를 자동 생성한다. 도 2는 본 발명의 실시 예에 따른 명령어 생성 장치의 구조를 나타낸 도이다. 본 발명의 실시 예에 따른 명령어 생성 장치(컴파일러라고도 명명됨)는 첨부한 도 2에서와 같이, 입력 정 보 분석기, 뉴럴 네트워크 모델 최적화기, 가속기 구성 기반 최적화기 및 명령어 생성기를 포함한다. 입력 정보 분석기는 대상이 되는 뉴럴 네트워크 모델에 관련된 정보를 입력 받아 분석하도록 구성되며, 입 력 정보를 분석하여 일정한 데이터 구조로 저장하는 IR(intermediate representation) 변환기를 포함할 수 있다. 뉴럴 네트워크 모델 최적화기는 입력 정보 분석기에 의해 분석된 결과이며 일정한 데이터 구조를 가 지는 분석 결과 데이터를 토대로 해당 뉴럴 네트워크 모델을 최적화시킨, 모델 최적화 정보를 생성하도록 구성 된다. 가속기 구성 기반 최적화기는 입력되는 가속기(인공지능 프로세싱 장치) 구성 정보와 뉴럴 네트워크 모델 최적화기로부터 제공되는 모델 최적화 정보를 토대로 가속기의 동작을 최적화하는 최적 동작 정보를 생성 하도록 구성된다. 여기서 가속기 구성 정보는 가속기 즉, 인공지능 프로세싱 장치의 하드웨어 정보를 포함할 수 있다. 명령어 생성기는 가속기 구성 기반 최적화기로부터 제공되는 최적 동작 정보를 토대로 명령어를 생성 하도록 구성된다. 이러한 구조로 이루어지는 명령어 생성 장치는 인공지능 프로세싱 장치가 위에 기술된 바와 같은 동작 (a~d)을 수행하는데 있어서 위에 기술된 바와 같은 최적화 조건 정보(사항 1 내지 사항 7)를 고려하여, 다음과 같이 임의 뉴럴 네트워크 모델을 처리하는 인공지능 프로세싱 장치의 성능치를 예측하고 비교하여 성능을 최적 화한다. 도 3a 및 도 3b는 본 발명의 실시 예에 따른 최적화 방법의 흐름도이다. 본 발명의 실시 예에 따른 명령어 생성 장치에서, 뉴럴 네트워크 모델에 관련된 정보를 입력 받아 분석한 분 석 결과 데이터를 토대로 해당 뉴럴 네트워크 모델에 최적화된 모델 최적화 정보가 생성되며, 생성된 모델 최적 화 정보와 가속기 구성 정보를 토대로 가속기의 동작을 최적화한다. 여기서는 인공지능 프로세싱 장치가 딥러닝 가속기인 것을 예로 들어서 설명하며, 위와 같이, 모델 최적화 정보와 가속기 구성 정보가 이미 획득된 것을 기 반으로 설명한다. 먼저, 첨부한 도 3a에서와 같이, 최적의 성능값을 최대값(MAX)로 설정하고(S100), 해당 뉴럴 네트워크 모델에서 사용되는 전체 가중치가 가속기의 내부 메모리에 할당되어 있는지를 확인한다(S110). 최적의 성능값은 각 동작 (정의된 4가지의 가속기 동작(a~d))별로 설정될 수 있다. 그리고 가속기 동작(a~d)간의 의존성을 고려하여 병렬 동작이 가능하도록 하는 더블 버퍼링의 사용 여부를 결정 하고, 더블 버퍼링 사용에 따라 가속기 동작(a~d)들의 스케줄링을 위한 조합을 구성한다(S120). 예를 들어, 위 에서 정의된 4가지의 가속기 동작(a~d)을 기반으로, ILOAD, WLOAD, OSTR 동작들의 더블 버퍼링 조건과, MMOP를 위한 입/출력 데이터를 위한 내부 메모리 동시 접근 가능 여부 조건(입출력 데이터를 위한 메모리내 공간이 분 리 조건 또는 통합 조건인지의 여부), 그리고 단계(S110)에서 확인된 전체 가중치 할당 가능 여부를 조합하여, 가속기 동작(a~d)을 수행하기 위한 스케줄링 관련 탐색 공간들을 정의하며, 가중치 우선 모드인지 또는 입력 데 이터 우선 모드를 고려하여 스케줄링 관련 탐색 공간(또는 스케줄링 탐색 공간이라고도 명명됨)들을 정의한다. 이와 같이 더블 버퍼링 사용에 따라 가속기 동작(a~d)들의 스케줄링을 위한 조합(정의되는 스케줄링 관련 탐색 공간들)을 설명의 편의를 위해 제1 조건 조합이라고 명명한다. 스케줄링 탐색 공간은 예를 들어, 다음과 같이 이루어질 수 있다. 1. 전체 가중치가 내부 메모리에 할당 가능할 때 스케줄링 탐색공간 = (입력 데이터의 더블 버퍼링 여부) × (출력 데이터의 더블 버퍼링 여부) × (입출력 데이 터를 위한 메모리내 공간 통합/분리) × (가중치 우선 모드/입력 데이터 우선 모드) = 24 = 16개의 탐색 공간 2. 전체 가중치가 내부 메모리에 할당 가능하지 않을 때 스케줄링 탐색공간 = (입력 데이터의 더블 버퍼링 여부) × (출력 데이터의 더블 버퍼링 여부) × (가중치 데이 터의 더블 버퍼링 여부)× (입출력 데이터를 위한 메모리내 공간 통합/분리) × (가중치 우선 모드/입력 데이터 우선 모드) = 25 = 32개의 탐색 공간 단계(S110)에서 확인된 전체 가중치 할당 가능 여부에 따라 전체 가중치 할당이 불가능한 경우, 제1 조건 조합 에 대응하는 스케줄링 탐색 공간은 총 32개의 탐색 공간으로 설정된다. 반면, 단계(S110)에서 확인된 전체 가중치 할당 가능 여부에 따라 전체 가중치 할당이 가능한 경우, 제1 조건 조합에 대응하는 스케줄링 탐색 공간은 총 16 + 32 = 48개의 탐색 공간으로 설정된다. 도 4 및 도 5는 본 발명의 실시 예에 따른 스케줄링 탐색 공간의 예를 나타낸 도이다. 구체적으로, 도 4에 도시된 스케줄링 탐색 공간은 가중치 우선 모드일 때 48개의 스케줄링 탐색 공간 중 하나를 나타낸 예이다. 성분별로 할당된 메모리에 데이터를 저장하기 위해 가중치는 도 4에서와 같이, 2개의 타일로 구 성되며, 입력 데이터의 더블 버퍼링을 사용하고, 출력 데이터는 싱글 버퍼를 사용하며, 가중치는 더블 버퍼링을 사용하고, 입출력 데이터를 위한 메모리내 공간은 분리 조건일 때, 가속기 동작(ILOAD, WLOAD, MMOP, OSTR)이 수행되는 스케줄링 탐색 공간이 도 4와 같이 구성될 수 있다. 도 5에 도시된 스케줄링 탐색 공간은 입력 데이터 우선 모드일 때 48개의 스케줄링 탐색 공간 중 하나를 나타낸 예이다. 성분별로 할당된 메모리에 데이터를 저장하기 위해 입력 데이터는 도 5에서와 같이, 2개의 타일로 구성 되며, 입력 데이터의 더블 버퍼링을 사용하고, 출력 데이터는 싱글 버퍼를 사용하며, 가중치는 더블 버퍼링을 사용하고, 입출력 데이터를 위한 메모리내 공간은 분리 조건일 때, 가속기 동작(ILOAD, WLOAD, MMOP, OSTR)이 수행되는 스케줄링 탐색 공간이 도 5와 같이 구성될 수 있다. 다음, 도 3a에서와 같이, 제1 조건 조합에 대해 타일링 조건을 결합한다(S130). 더블 버퍼링을 사용하면서 가 속기 동작(a~d)을 수행하기 위한 스케줄링 조건들을 조합한 제1 조건 조합에 대해 타일링 정보를 결합한다. 즉, 정의된 스케줄링 관련 탐색 공간 중 하나의 공간별로 타일링 정보를 결합하여, 스케줄링 관련 탐색 공간에 대해 각 동작을 수행하는데 필요한 전체 데이터를 메모리(내부 메모리)의 데이터 성분별 할당 영역에 분할한 것에 대 응하는, 제2 조건 조합이 획득된다. 그리고, 단계(S130)에서 획득된 제2 조건 조합에 대해 슬라이싱 조건(데이터 분할 정보)을 결합한다(S140). 제2 조건 조합에 포함되어 있는 타일링 정보와 처리하여야 하는 배치 크기를 고려하여, 딥러닝 가속기의 연산기의 각 행 또는 각 열에 대해 데이터를 분할하여 배치한, 제3 조건 조합이 획득된다. 제3 조건 조합에 기반하여, 뉴럴 네트워크의 레이어간 데이터 재사용 여부를 확인한다(S150). 레이어간 데이터 재사용이 가능하면, 데이터 재사용을 고려하여 가속기 동작(a~d)을 수행하기 위한 스케줄링 조건을 재조합한다 (S160). 이에 따라 제3 조건 조합에 대해 데이터 재사용을 기반한 스케줄링 조건이 반영된 제4 조건 조합이 획 득된다. 도 6 및 도 7은 본 발명의 실시 예에 따른 데이터 재사용을 고려하여 스케줄링 조건을 재조합한 예를 나타낸 도 이다. 예를 들어, 현재 레이어의 출력 데이터를 외부 메모리로의 데이터의 이동 없이 내부 메모리 내에서 다음 레이어 의 입력 데이터로 재사용이 가능한 경우, 현재 레이어를 위한 OSTR과 다음 레이어를 위한 ILOAD가 제거되고 이 를 위한 의존성 확인도 제거되어 스케줄링 조건이 재설정되어 제4 조건 조합이 획득된다. 이 경우, 입력과 출력 을 위한 더블 버퍼링 조건도 제거될 수 있다. 도 4에 도시된 가중치 우선 모드일 때 정의된 스케줄링 탐색 공간을 예로 설명하면, 위에 기술된 바와 같이 데 이터의 재사용이 가능한 경우, 도 6에서와 같이 현재 레이어에 대한 스케줄링 탐색 공간에서 OSTR이 제거되면서, 현재 레이어에 대한 스케줄링 조건이 재설정된다. 또한, 도 7에서와 같이 다음 레이어에 대한 스케 줄링 탐색 공간에서 ILOAD이 제거되면서, 다음 레이어에 대한 스케줄링 조건이 재설정된다. 다음에, 도 3a에서와 같이, 제4 조건 조합에 기반하여 하드웨어 모델링을 통한 성능치를 예측한다(S170). 가속 기의 구성 정보와 모델 최적화 정보를 이용하여, 제4 조건 조합 즉, 더블 버퍼링과 가속기 동작의 스케줄링을 위한 관련 조건들의 조합에, 타일링 조건, 슬라이싱 조건, 데이터 재사용 여부에 따른 스케줄링 조건이 반영된 제4 조건 조합을 수행하기 위한 최적화한 하드웨어 모델링을 생성하고, 생성된 하드웨어 모델링을 통한 성능치 를 예측한다. 하드웨어 모델링은 제4 조건 조합을 기반으로 각 동작을 수행하기 위한 명령어를 포함할 수 있으 며, 이러한 명령어에 기반하여 가속기가 해당 동작을 수행하였을 때의 성능치를 예측한다. 여기서, 하드웨어 모 델링은, 위의 조건 조합에 의해서 실제 하드웨어가 동작하는 그대로 흉내낼 수 있도록 소프트웨어로 모델을 만 들어 해당 조건 조합일 때의 성능치(예를 들어, 처리 시간 또는 하드웨어 동작 시간)를 계산하도록 만든 것을 나타낼 수 있다. 예측된 성능치와 최적의 성능값(단계 S100에서 설정된 성능값)을 비교하고, 예측된 성능치와 최적의 성능값 중 에서 더 작은 값을 토대로 최적의 성능값을 업데이트한다(S180). 예를 들어, 성능치가 하드웨어 동작 시간을 나 타내는 경우, 가장 작은 동작시간을 가지는 경우가 최적의 성능으로 해석되어, 예측된 하드웨어 동작 시간이 설 정된 최적의 성능값보다 작으면, 예측된 하드웨어 동작 시간에 따라 최적의 성능값을 업데이트한다. 이러한 성능치를 예측하고 최적의 성능값과의 비교를 통해 최적의 성능값을 업데이트하는 과정을 위의 단계 (S120, S130, S140)에서 획득된 조건 조합들 모두에 대해 반복적으로 수행하여, 최적의 성능을 달성할 수 있는 최적의 조건 조합을 결정한다. 예를 들어, 가장 작은 하드웨어 동작시간을 차지하는 조건 조합이 최적화 완료 조건 조합으로 결정된다. 이를 위해, 도 3b에서와 같이, 단계(S140)에서 제2 조건 조합에 슬라이싱 조건을 결합하여 획득한 제3 조건 조 합에 대한 시도가 완료되었는지를 판단하고(S190), 제3 조건 조합에 대한 시도가 완료되지 않은 경우에는 단계 (S140)으로 복귀하여 다시 단계(S140) 내지 단계(S190)를 수행한다. 제3 조건 조합에 대한 시도가 완료된 경우에는 제2 조건 조합에 대한 시도가 완료되었는지를 판단하고(S200), 제2 조건 조합에 대한 시도가 완료되지 않은 경우에는 단계(S130)으로 복귀하여 다시 단계(S130) 내지 단계 (S200)를 수행한다. 제2 조건 조합에 대한 시도가 완료된 경우에는 제1 조건 조합에 대한 시도가 완료되었는지를 판단하고(S210), 제1 조건 조합에 대한 시도가 완료되지 않은 경우에는 단계(S120)으로 복귀하여 다시 단계(S120) 내지 단계 (S210)를 수행한다. 본 발명의 실시 예에서는 각 조건 조합별로 최적화 완료 조합을 찾기 위한 시도를 수행하는 최적화 실행 시간이 감소되도록, 슬라이싱 조건을 결합하여 획득한 제3 조건 조합, 타일링 조건을 결합하여 획득한 제2 조건 조합, 그리고 제1 조건 조합의 순서로 시도가 완료되었는지를 판단한다. 이를 위해, 슬라이싱 조건이나 타일링 조건을 위한 루프(loop)에는 빠른 종료(early termination) 조건들을 삽 입하기 쉽도록 아래 레벨로 배치하고, 메모리 내에 데이터를 배치하기 위한 데이터 모양 결정과 관련하여 그래 뉼래리티(granularity)가 큰 것부터 작은 것으로 배치하여, 제3 조건 조합, 타일링 조건을 결합하여 획득한 제2 조건 조합, 그리고 제1 조건 조합의 순서로 시도가 완료되었는지를 판단한다. 예를 들어, 슬라이싱 조건이나 타일링 조건에 대해서, 아래 레벨부터 예를 들어, 적은 타일 개수를 가지는 데이 터부터 시도하여 해당 타일의 데이터를 내부 메모리에 수용 가능한 경우 초기 종료가 가능하도록 조건을 설정하 고, 더블 버퍼링의 조건에 대해서는 입력을 위한 메모리 공간 2개를 확보하도록 조건을 설정할 수 있다. 그러나, 본 발명은 반드시, 슬라이싱 조건을 결합하여 획득한 제3 조건 조합, 타일링 조건을 결합하여 획득한 제2 조건 조합, 그리고 제1 조건 조합의 순서로 시도가 완료되었는지를 판단하는 것에 한정되는 것은 아니다. 한편, 제1 조건 조합에 대한 시도가 완료된 경우에는, 즉, 단계(S120)에서 정의된 모든 스케줄링 관련 탐색 공 간에 관련하여 타일링 정보 결합, 슬라이싱 조건 결합, 데이터 재사용에 따른 스케줄링 조건 재조합이 완료된 경우에, 현재까지 수행된 조건 조합들을 토대로 가속기 구성 기반 최적화 완료 조합으로 저장한다(S220). 그리 고 최적화 완료 조합에 따라 메모리 할당 최적화를 수행한다(S230). 즉, 위에서 정의된 4가지의 동작을 수행하 기 위한 최적의 스케줄링에 따른 명령어가 생성되며, 각 명령어에 따라 데이터가 로딩되어 연산기로 제공되고, 그리고 연산기의 출력 데이터가 저장되는 메모리 할당 최적화가 이루어진다. 이와 같이, 위에서 정의된 4가지의 동작 구분을 기반으로 하여 ILOAD, WLOAD, OSTR 동작들의 더블 버퍼링 조건, MMOP를 위한 입/출력 데이터를 위한 내부 메모리 동시 접근 가능 여부 조건, 그리고 전체 가중치 할당 여부를 조합하여 스케줄링 관련 탐색 공간을 정의하고, 정의된 탐색 공간들 각각에서 하드웨어 모델링을 통해 성능 예 측치 즉, 예측된 성능치를 추출하여 최적의 성능을 갖는 스케줄링을 수행할 수 있다. 한편, 예측된 성능치를 추출할 때, 내부 메모리와 연산기 사이의 동작인 MMOP 성능 모델링은 할당된 데이터의 크기에 따라 정확히 예측 가능하다. 하지만 외부 메모리와 내부 메모리 사이의 데이터 전달을 하는 ILOAD, WLOAD, OSTR 동작의 경우 두 메모리 사이의 버스 구성에 따라 다르게 동작하므로 정확한 예측이 힘들 수 있다. 본 발명의 실시 예에서는 이런 불확실성을 보정하기 위해 4가지 동작 구성에 대한 하드웨어 예측된 성능치에 4 가지 동작별로 각각 가중치를 곱하고, 실제 제작된 프로세서로부터 테스트를 거쳐 가중치 값을 업데이트하여 보 정할 수 있도록 한다. 도 8은 본 발명의 실시 예에 따른 최적화 방법에서, 가중치 보정 과정을 나타낸 흐름도이다. 위에 기술된 바와 같은 최적화 방법에서, 생성된 하드웨어 모델링을 통해 성능치를 예측한 경우, 수행된 4가지 동작별로 즉, ILOAD, WLOAD, MMOP, OSTR 각각의 예측된 성능치에 가중치를 부여하고, ILOAD, WLOAD, MMOP, OSTR에 대한 테스트벤치(testbench)를 구성한다(S300). 그리고 테스트를 실시하여(예를 들어, SoC(System on chip) 상에서 테스트 실시) 각 동작별 실제 성능값을 획득하고, 획득된 실제 성능값과 예측치의 비율을 계산한다(S310). 그리고 계산된 비율에 따라 각 동작에 대해 부여된 가중치의 값을 업데이트한다(S320). 즉, 단계(S310)의 결과 에 따라 각 동작의 예측된 성능치에 부여된 가중치의 값을 보정함으로써, 각 동작별 예측의 불확실성을 보정할 수 있다. 이와 같이, 각 동작별로 예측된 성능치가 보정된 다음에, 위의 최적화 방법에서 단계(S180)에서 최적의 성능값 과 비교될 수 있다. 도 9는 본 발명의 실시 예에 따른 명령어 생성 장치의 구조를 나타낸 도이다. 본 발명의 실시 예에 따른 명령어 생성 장치는 첨부한 도 9에 도시되어 있듯이, 컴퓨터 시스템으로 구현될 수 있다. 명령어 생성 장치는 프로세서, 메모리, 입력 인터페이스 장치, 출력 인터페이스 장치 , 및 저장 장치를 포함한다. 각각의 구성 요소들은 버스(bus)에 의해 연결되어 서로 통신을 수 행할 수 있다. 또한, 각각의 구성요소들은 공통 버스가 아니라, 프로세서를 중심으로 개별 인터페이 스 또는 개별 버스를 통하여 연결될 수도 있다. 프로세서는 메모리 및 저장 장치 중에서 적어도 하나에 저장된 프로그램 명령(program comman d)을 실행할 수 있다. 프로세서는 중앙 처리 장치(central processing unit, CPU) 또는 본 발명의 실시 예들에 따른 방법들이 수행되는 전용의 프로세서를 의미할 수 있다. 이러한 프로세서는 위의 도 1 내지 도 8을 토대로 설명한 방법에서 대응하는 기능을 구현하도록 구성될 수 있다. 메모리는 프로세서와 연결되고 프로세서의 동작과 관련한 다양한 정보를 저장한다. 메모리(22 0)는 프로세서에서 수행하기 위한 명령어를 저장하고 있거나 저장 장치로부터 명령어를 로드하여 일 시 저장할 수 있다. 프로세서는 메모리에 저장되어 있거나 로드된 명령어를 실행할 수 있다. 메모리 는 ROM 및 RAM를 포함할 수 있다. 본 발명의 실시 예에서 메모리/저장 장치는 프로세서의 내부 또는 외부에 위치할 수 있고, 이미 알려진 다양한 수단을 통해 프로세서와 연결될 수 있다. 본 발명의 실시 예는 이상에서 설명한 장치 및/또는 방법을 통해서만 구현이 되는 것은 아니며, 본 발명의 실시 예의 구성에 대응하는 기능을 실현하기 위한 프로그램, 그 프로그램이 기록된 기록 매체 등을 통해 구현될 수도"}
{"patent_id": "10-2020-0040549", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "있으며, 이러한 구현은 앞서 설명한 실시예의 기재로부터 본 발명이 속하는 기술분야의 전문가라면 쉽게 구현할 수 있는 것이다. 이상에서 본 발명의 실시 예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다.도면 도면1 도면2 도면3a 도면3b 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2020-0040549", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 인공지능 프로세싱 장치의 구조를 나타낸 도이다. 도 2는 본 발명의 실시 예에 따른 명령어 생성 장치의 구조를 나타낸 도이다. 도 3a 및 도 3b는 본 발명의 실시 예에 따른 최적화 방법의 흐름도이다. 도 4 및 도 5는 본 발명의 실시 예에 따른 스케줄링 탐색 공간의 예를 나타낸 도이다. 도 6 및 도 7은 본 발명의 실시 예에 따른 데이터 재사용을 고려하여 스케줄링 조건을 재조합한 예를 나타낸 도 이다. 도 8은 본 발명의 실시 예에 따른 최적화 방법에서, 가중치 보정 과정을 나타낸 흐름도이다. 도 9는 본 발명의 실시 예에 따른 명령어 생성 장치의 구조를 나타낸 도이다."}
