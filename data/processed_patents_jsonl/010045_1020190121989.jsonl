{"patent_id": "10-2019-0121989", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0039583", "출원번호": "10-2019-0121989", "발명의 명칭": "멀티모달 기반 사용자 구별 방법 및 장치", "출원인": "에스케이텔레콤 주식회사", "발명자": "사수다카르"}}
{"patent_id": "10-2019-0121989", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 사용자와 관련한 음성 신호 및 영상 프레임을 수집하는 수집부;상기 영상 프레임 내 상기 각 사용자의 얼굴 영역을 추출하는 사용자 인식부;상기 음성 신호를 분석하여 상기 음성 신호 내 사용자 발화 구간을 검출하는 발화 검출부; 및상기 각 사용자의 얼굴 영역 내 입술 영역을 구분하고, 상기 사용자별 입술 영역의 특징값 및 상기 사용자 발화구간에 대한 특징값을 활용하여 상기 사용자 중 현재 처리해야하는 음성 명령의 대상인 발화 사용자를 구별하는사용자 구별부를 포함하는 것을 특징으로 하는 멀티모달 사용자 구별장치."}
{"patent_id": "10-2019-0121989", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 발화 검출부는,상기 음성 신호 내 상기 음성 명령에 상응하는 문장의 발화 시작 시각부터 발화 종료 시각까지의 구간을 상기사용자 발화 구간으로서 검출하는 것을 특징으로 하는 멀티모달 사용자 구별장치."}
{"patent_id": "10-2019-0121989", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 사용자 구별부는,상기 각 사용자별 상기 얼굴 영역에 상응하는 얼굴 랜드마크 포인트를 추출하고, 상기 얼굴 랜드마크 포인트 중상기 입술 영역에 상응하는 입술 랜드마크 포인트를 기반으로 입술 사이의 거리정보를 산출하여 상기 입술 영역에 대한 특징값으로서 활용하는 것을 특징으로 하는 멀티모달 사용자 구별장치."}
{"patent_id": "10-2019-0121989", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 사용자 구별부는,상기 입술 랜드마크 포인트를 위치에 따라 복수의 내측(Inner) 랜드마크 포인트 쌍(Pair) 및 복수의 외측(Outer) 랜드마크 포인트 쌍으로 분류하여 정의하고, 상기 내측 랜드마크 포인트 쌍 및 상기 외측 랜드마크 포인트 쌍을 기반으로 상기 입술 사이의 거리정보를 산출하는 것을 특징으로 하는 멀티모달 사용자 구별장치."}
{"patent_id": "10-2019-0121989", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서,상기 사용자 구별부는,상기 내측 랜드마크 포인트 쌍별 랜드마크 포인트 사이의 거리정보 및 상기 외측 랜드마크 포인트 쌍별 랜드마크 포인트 사이의 거리정보를 기반으로 상기 입술 사이의 거리정보를 산출하는 것을 특징으로 하는 멀티모달 사용자 구별장치."}
{"patent_id": "10-2019-0121989", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,상기 사용자 구별부는,공개특허 10-2021-0039583-3-상기 사용자 발화 구간에 상응하는 매칭 영상 프레임 및 상기 매칭 영상 프레임에 대해 산출된 상기 사용자별입술 영역에 대한 특징값을 기반으로 상기 매칭 영상 프레임별 상기 각 사용자의 입술 사이의 거리정보에 대한상관도를 계산하고, 상기 상관도에 기반하여 상기 발화 사용자를 구별하는 것을 특징으로 하는 멀티모달 사용자구별장치."}
{"patent_id": "10-2019-0121989", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서,상기 사용자 구별부는,상기 사용자별로 상기 매칭 영상 프레임에 대하여 상기 입술 사이의 거리정보에 대한 표준편차가 기 설정된 임계치 이상인 경우에 해당하는 발화 프레임을 선별하고, 상기 발화 프레임의 갯수가 가장 많은 사용자를 상기 발화 사용자로서 판단하는 것을 특징으로 하는 멀티모달 사용자 구별장치."}
{"patent_id": "10-2019-0121989", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 6항에 있어서,상기 사용자 구별부는,상기 사용자별로 상기 매칭 영상 프레임에 대하여 상기 입술 사이의 거리정보에 대한 표준편차를 산출하고, 상기 표준편차가 최대인 사용자를 상기 발화 사용자로서 판단하는 것을 특징으로 하는 멀티모달 사용자 구별장치."}
{"patent_id": "10-2019-0121989", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1항에 있어서,상기 사용자 구별부는,상기 각 사용자별 상기 얼굴 영역에 상응하는 얼굴 랜드마크 포인트를 추출하고, 상기 얼굴 랜드마크 포인트 중눈 영역에 상응하는 랜드마크 포인트를 기반으로 산출된 상기 각 사용자의 홍채(Iris) 영역과 공막(Sclera) 영역 사이의 거리정보에 대한 상관도를 활용하여 상기 사용자 중 응시 사용자를 구별하는 것을 특징으로 하는 멀티모달 사용자 구별장치."}
{"patent_id": "10-2019-0121989", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,상기 사용자 구별부는,상기 응시 사용자에 대한 구별결과에 근거하여 기기 동작 모드가 비활성화 상태에서 활성화 상태로 전환되도록제어하는 것을 특징으로 하는 멀티모달 사용자 구별장치."}
{"patent_id": "10-2019-0121989", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 9항에 있어서,상기 사용자 구별부는,상기 발화 사용자와 상기 응시 사용자가 동일한 경우 상기 발화 사용자에 대한 정보를 선택적으로 출력하는 것을 특징으로 하는 특징으로 하는 멀티모달 사용자 구별장치."}
{"patent_id": "10-2019-0121989", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "적어도 하나의 사용자와 관련한 음성 신호 및 영상 프레임을 수집하는 과정;상기 영상 프레임 내 상기 각 사용자의 얼굴 영역을 추출하는 과정;상기 음성 신호를 분석하여 상기 음성 신호 내 사용자 발화 구간을 검출하는 과정; 및상기 각 사용자의 얼굴 영역 내 입술 영역을 구분하고, 상기 사용자별 입술 영역의 특징값 및 상기 사용자 발화구간에 대한 특징값을 활용하여 상기 사용자 중 현재 처리해야하는 음성 명령의 대상인 발화 사용자를 구별하는공개특허 10-2021-0039583-4-과정을 포함하는 것을 특징으로 하는 멀티모달 사용자 구별방법."}
{"patent_id": "10-2019-0121989", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 의한 멀티모달 사용자 구별방법의 각 단계를 실행시키기 위하여 컴퓨터로 읽을 수 있는 기록매체에저장된 컴퓨터프로그램."}
{"patent_id": "10-2019-0121989", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 실시예는 다수의 사용자가 공존하는 환경에서 멀티모달 입력을 활용하여 현재 발화 중인 사용자를 감지하고, 이를 기반으로 맥락에 맞는 정보가 제공될 수 있도록 함으로써 사용자로 하여금 보다 유연하고 매끄러운 인공지 능 서비스를 제공받을 수 있도록 하는 멀티모달 기반 사용자 구별 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2019-0121989", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 실시예는 멀티모달 기반 사용자 구별 방법 및 장치에 관한 것이다. 더욱 상세하게는, 다수의 사용자가 공존 하는 환경에서 멀티모달 입력을 활용하여 발화 중인 사용자를 구별할 수 있도록 하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2019-0121989", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 본 실시예에 대한 배경 정보를 제공할 뿐 종래기술을 구성하는 것은 아니다. 최근 디스플레이 및 카메라를 탑재한 인공지능 기기들이 다양한 회사(SKT NUGU Nemo, Amazon Echo Show/Look, Google Home Hub, Facebook Portal 등)에서 출시되고 있다. 음성 입출력을 기반으로 하는 기존의 인공지능 기기 로부터 다양한 입출력이 가능한 멀티모달(Multimodal) 기기로 진화함에 따라 향상된 사용자 경험 및 새로운 사 용자 경험을 제공하는 서비스의 출현이 예고되고 있다. 기존의 음성 기반 인공지능 스피커(SKT NUGU, Amazon Echo, Google Home 등)은 음성으로만 사용자로부터 정보를 받기에 음성 인식의 한계에 따라 제한된 사용자 경험을 제공하였다. 예를 들면 다수의 사용자가 있는 환경에서 현재 인공지능 스피커와 소통 중인 사용자를 실시간으로 구분하여 그 맥락에 맞는 정보를 제공하거나, 웨이크 업 워드(Wake up word) 없이 사용자의 시선만으로 휴면 상태에서 깨어나는 등의 동작은 음성 인식의 기술적, 본질적 한계에 따라 제한된다. 카메라 및 다양한 센서를 통한 멀티모달 인터페이스는 이러한 한계를 극복하여 보다 유연하고 능동적인 서비스 를 제공할 것으로 기대되고 있다. 하지만 카메라로부터 입력되는 영상은 음성에 비해 정보의 양이 매우 방대하 기 때문에 제공하고자하는 서비스에 따라 영상 정보를 효과적으로 처리하고 음성 정보와 유기적으로 결합하여 시너지를 낼 수 있는 기술의 개발이 필요하다."}
{"patent_id": "10-2019-0121989", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 실시예는 다수의 사용자가 공존하는 환경에서 멀티모달 입력을 활용하여 현재 발화 중인 사용자를 감지하고, 이를 기반으로 맥락에 맞는 정보가 제공될 수 있도록 함으로써 사용자로 하여금 보다 유연하고 매끄러운 인공지 능 서비스를 제공받을 수 있도록 하는 데 그 목적이 있다."}
{"patent_id": "10-2019-0121989", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 실시예는, 적어도 하나의 사용자와 관련한 음성 신호 및 영상 프레임을 수집하는 수집부; 상기 영상 프레임 내 상기 각 사용자의 얼굴 영역을 추출하는 사용자 인식부; 상기 음성 신호를 분석하여 상기 음성 신호 내 사용 자 발화 구간을 검출하는 발화 검출부; 및 상기 각 사용자의 얼굴 영역 내 입술 영역을 구분하고, 상기 사용자 별 입술 영역의 특징값 및 상기 사용자 발화 구간에 대한 특징값을 활용하여 상기 사용자 중 현재 처리해야하는 음성 명령의 대상인 발화 사용자를 구별하는 사용자 구별부를 포함하는 것을 특징으로 하는 멀티모달 사용자 구 별장치를 제공한다. 또한, 본 실시예의 다른 측면에 의하면, 적어도 하나의 사용자와 관련한 음성 신호 및 영상 프레임을 수집하는 과정; 상기 영상 프레임 내 상기 각 사용자의 얼굴 영역을 추출하는 과정; 상기 음성 신호를 분석하여 상기 음 성 신호 내 사용자 발화 구간을 검출하는 과정; 및 상기 각 사용자의 얼굴 영역 내 입술 영역을 구분하고, 상기 사용자별 입술 영역의 특징값 및 상기 사용자 발화 구간에 대한 특징값을 활용하여 상기 사용자 중 현재 처리해야하는 음성 명령의 대상인 발화 사용자를 구별하는 과정을 포함하는 것을 특징으로 하는 멀티모달 사용자 구별 방법을 제공한다. 또한, 본 실시예의 다른 측면에 의하면, 멀티모달 사용자 구별방법의 각 단계를 실행시키기 위하여 컴퓨터로 읽 을 수 있는 기록매체에 저장된 컴퓨터프로그램을 제공한다."}
{"patent_id": "10-2019-0121989", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 실시예에 따르면, 다수의 사용자가 공존하는 환경에서 멀티모달 입력을 활용하여 현재 발화 중인 사용자를 감지하고, 이를 기반으로 맥락에 맞는 정보가 제공될 수 있도록 함으로써 사용자로 하여금 보다 유연하고 매끄 러운 인공지능 서비스를 제공받을 수 있도록 하는 효과가 있다. 또한, 본 실시예에 따르면, 웨이크 업 워드없이 사용자의 시선만으로 휴면 상태에서 깨어나는 등의 종래의 음성 인식의 기술적, 본질적 한계를 극복 가능한 보다 새로운 인공지능 서비스를 사용자로 하여금 경험할 수 있도록 하는 효과가 있다."}
{"patent_id": "10-2019-0121989", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 최근 디스플레이 및 카메라를 탑재한 인공지능 기기들이 다양한 회사에서 출시되고 있다. 음성 입출력을 기반으 로 하는 기존의 인공지능 기기로부터 다양한 입출력이 가능한 멀티모달(Multimodal) 기기로 진화함에 따라 향상 된 사용자 경험 및 새로운 사용자 경험을 제공하는 서비스의 출현이 예고되고 있다. 본 실시예의 경우 이러한, 멀티모달 입력을 활용하여, 음성 인식의 한계에 따라 제한된 사용자 경험만을 제공하 는 기존의 음성 기반 인공지능 서비스의 문제점을 극복 가능한 Multi-Modal, Multi-Domain, Multi-Party Speaker Recognition 시스템을 구축하고, 이를 통해 보다 유연하고 매끄러운 인공지능 서비스 사용자 경험을 제 공하고자 한다. 보다 자세하게는, 다수의 사용자가 공존하는 환경에서 단일 인공지능 기기가 발화 중인 사용자를 구분하여 맥락 에 맞는 서비스를 제공할 수 있도록 하는 데 그 목적이 있다. 도 1은 본 실시예에 따른 멀티모달 사용자 구별 방법에 따른 서비스 시나리오를 설명하기 위한 예시도이다. 도 1은 두 사용자(사용자 A와 사용자 B)가 인공지능 기기에게 각자에 대한 질문을 하고 인공지능 기기는 멀티모 달 입력 정보를 활용하여 각 사용자에게 알맞게 응답하는 예시 시나리오를 나타낸다 각 사용자의 발화시 인공지능 기기는 발화 사용자를 구분하고 해당 사용자의 발화 대상이 스스로인지를 판단한 다. 사용자 A의 경우 최초 “안녕”이라는 말을 할 때 그 대상이 인공지능 기기라고 판단하여 기기가 응답하였으며, 사용자 B의 경우에는 응시(Gaze)에 반응하여 응답 대기 모드로 전환한다. 이러한 시나리오 수행에는 다음의 두 가지 기능이 요구된다. 1) 발화 사용자 인식(Speaker Recognition) 2) 응시 사용자 인식(Gaze Detection) 본 실시예에 따른 멀티모달 사용자 구별 방법에 의하는 경우 멀티모달 입력 정보를 활용하여 상기의 두 가지 동 작을 동시에 수행할 수 있다. 도 2는 본 실시예에 따른 멀티모달 사용자 구별장치를 개략적으로 나타낸 블록 구성도이다. 본 실시예에 따른 멀티모달 사용자 구별장치는 영상 프레임 및 음성 신호와 같은 멀티모달 입력 정보의 분 석을 통해 사용자의 발화 상태를 인식하고, 복수의 사용자를 구분하여 입력된 명령을 병렬로 처리하는 장치를 의미한다. 이러한, 멀티모달 사용자 구별장치는 바람직하게는 인공지능(AI) 서비스 분야에 적용될 수 있으며, 이 경 우 멀티모달 사용자 구별장치는 인공지능 기기 자체이거나, 인공지능 기기 자체와 연동되는 외부 기기의 형태로 구현될 수 있다. 이하에서는 본 실시예에 따른 멀티모달 사용자 구별장치가 인공지능 서비스 분야에서 적용된 것으로 예시 하여 설명하나 반드시 이에 한정되는 것은 아니다. 본 실시예에 따른 멀티모달 사용자 구별장치는 수집부, 사용자 인식부, 발화 검출부, 사용 자 구별부, 모드 전환부 및 수행부를 구비한다. 한편, 도 2의 경우, 본 실시예에 따른 멀티모달 사용자 구별방법에 따른 인공지능 서비스를 제공함에 있어서, 기본이 되는 구성요소를 예시적으로 도시한 것으 로서, 이러한, 멀티모달 사용자 구별장치는 도시한 것보다 많거나 적은 구성요소 또는 상이한 구성요소의 구성(Configuration)을 가질 수 있음을 인식하여야 한다. 수집부는 영상 촬영장치 및 마이크와 통신을 수행하며, 이를 통해, 영상 촬영장치 및 마이크 각각으로부터 취득된 영상 프레임 및 음성 신호를 수집하는 장치를 의미한다. 본 실시예에 있어서, 수집부는 다수의 사용자가 공존하는 환경에서 현재 음성 명령의 대상이 되는 발화 사 용자를 포함한 적어도 하나의 사용자와 관련한 음성 신호 및 영상 프레임을 수집한다. 즉, 수집부는 발화 사용자로부터의 음성 명령에 대응되는 음성 신호 및 발화 사용자 및 주변의 다른 사용자를 포함한 영상 프레임 을 수집할 수 있다. 여기서, 영상 프레임 내에는 영상 프레임, 해당 영상 프레임에 대한 타임 스탬프 등의 정보 가 포함될 수 있다. 한편, 본 실시예에서는 영상 프레임 내에 포함되는 정보들에 대해서 특정 데이터로 한정하 지는 않는다. 수집부는 영상 촬영장치 및 마이크로부터 영상 프레임 및 음성 신호를 실시간으로 수신할 수 있다. 예컨대, 입력부는 일정 크기의 영상을 초당 기 설정된 프레임 단위로 수신할 수 있다. 다른 실시예에서, 입력부는 영상 촬영장치에서 기 촬영되어 저장된 영상에 대한 영상 프레임을 획득할 수도 있다. 또한, 본 실시예에서는 수집부가 영상 촬영장치 및 마이크로부터 영상 프레임 및 음성 신호를 획득한다고 명시하였지만 반드시 이에 한정되지 않고, 수집부 자체에 영상을 촬영하기 위한 모듈 및 음성 신호를 수집 하기 위한 모듈이 구비될 수도 있다. 사용자 인식부는 영상 프레임 내 각 사용자를 인식하고, 각 사용자의 얼굴 영역을 추출하는 기능을 수행한 다. 본 실시예에 있어서, 사용자 인식부는 영상 촬영장치를 통해 입력된 영상 프레임에서 다수의 사용자를 새 로 감지하거나, 이전 프레임에서의 정보를 바탕으로 추적하여 각 사용자를 인식할 수 있다. 사용자 인식부는 인식된 각 사용자의 얼굴 영역을 잘라(Crop)내어 출력한다. 여기서, 사용자 인식부 가 영상 프레임 내 각 사용자를 인식하는 방법 및 인식된 각 사용자의 얼굴 영역을 추출하는 방법은 종래의 영 상 인식 분야에서 일반적인 바 자세한 설명은 생략하도록 한다. 본 실시예에서는 이에 대해 특정 방식으로 한정 하지 않는다. 발화 검출부는 음성 신호를 분석하여 음성 신호 내 사용자 발화 구간을 검출하는 기능을 수행한다. 본 실시예에 있어서, 발화 검출부는 음성 신호 내 음성과 비음성 구간을 검출하고, 이를 기반으로 자연어 발화 여부를 확인하는 음성 검출모듈(VAD: Voice Activity Detector)로 구현되는 것이 바람직하나 반드시 이에 한정되는 것은 아니다. 도 4를 참조하면, 본 실시예에 따른 발화 검출부가 음성 신호 내 음성 명령에 상응하는 문장의 발화 시작 시각부터 발화종료 시각까지의 구간을 사용자 발화 구간으로서 검출하는 것을 확인할 수 있다. 사용자 구별부는 멀티 모달 입력을 활용하여 사용자 인식 기능을 수행하는 장치를 의미한다. 즉, 사용자 구별부는 다수의 사용자가 공존하는 환경에서 음성 및 영상 정보를 동시 활용하여 발화 중인 사용자를 실 시간으로 감지하거나, 사용자의 시선을 감지하여 휴면 상태에서 깨어나는 등의 사용자 인식 기능을 수행한다. 이하, 본 실시예에 따른 사용자 구별부가 멀티 모달 입력을 활용하여 발화 사용자를 구별하는 방법에 대해 설명하도록 한다. 사용자 구별부는 사용자 인식부를 통해 추출된 각 사용자의 얼굴 영역 내 입술 영역을 구분하고, 사 용자별 입술 영역의 특징값 및 발화 검출부에서 검출된 사용자 발화 구간에 대한 특징값을 활용하여 복수 의 사용자 중 현재 처리해야하는 음성 명령의 대상인 발화 사용자를 구별한다. 본 실시예에 있어서, 사용자 구별부는 각 사용자별 얼굴 영역에 상응하는 얼굴 랜드마크 포인트를 추출하 고, 얼굴 랜드마크 포인트 중 입술 영역에 상응하는 입술 랜드마크 포인트를 기반으로 입술 사이의 거리정보를 산출하여 입술 영역에 대한 특징값으로서 활용할 수 있다. 이를 위해, 사용자 구별부는 사용자별 얼굴 랜드마크를 추출하는 복수의 얼굴 랜드마크 추출 모듈을 포함 하여 구현될 수 있다. 또한, 사용자 구별부는 발화 검출부의 결과가 병렬 전달되도록 구현되며, 발화 검출부의 결과 및 얼굴 랜트마크 포인트를 전달받아 사용자 인식을 수행하는 수행 모듈이 포함될 수 있다. 사용자 구별부는 입술 랜드마크 포인트를 위치에 따라 복수의 내측(Inner) 랜드마크 포인트 쌍(Pair) 및 복수의 외측(Outer) 랜드마크 포인트 쌍으로 분류하여 정의한다. 여기서, 내측은 입술 사이 영역으로서, 윗 입 술의 아랫쪽과 아랫 입술의 위쪽 사이의 영역을 의미한다. 외측은 윗 입술의 위쪽과 아랫 윕술의 아랫쪽 사이의 영역을 의미한다. 예컨대, 도 3을 참조하면, 사용자 구별부는 사용자별로 매 영상 프레임마다 얼굴 랜드마크 포인트로부터 안쪽 입 영역(49 ~ 68 Point)을 구분한다. 이를 바탕으로 입술 사이의 거리를 구하기 위한 내측 랜드마크 포인 트 쌍 (62, 68), (63, 67), (64, 66), (61, 65)과 외측 랜드마크 포인트 쌍 (51, 59), (52, 58), (53, 57), (49, 55)을 정의한다. 이때, 매 영상 프레임은 카메라로부터 캡쳐된 타임 스템프 정보를 갖는다. 사용자 구별부는 내측 랜드마크 포인트 쌍 및 외측 랜드마크 포인트 쌍을 기반으로 입술 사이의 거리정보 를 산출한다. 즉, 사용자 구별부는 내측 랜드마크 포인트 쌍별 두 랜드마크 포인트 사이의 거리정보 및 외 측 랜드마크 포인트 쌍별 랜드마크 포인트 사이의 거리정보를 기반으로 입술 사이의 거리정보를 산출할 수 있다. 예컨대, 사용자 u의 k번째 랜드마크 포인트의 위치를 , 두 랜드마크 포인트 사이의 거리를 라 할때 수학식 1과 같이 사용자 u의 입술 사이의 거리를 구한다. 수학식 1"}
{"patent_id": "10-2019-0121989", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서 α와 β는 내측 랜드마크 포인트 쌍간의 거리와 외측 랜드마크 포인트 쌍간의 거리에 따른 가중치 를 적용하기 위한 파라미터로 0과 1사이의 값을 가진다. 이때, M이 전체 쌍의 개수일 때 α와 β에 대하여 각각 수학식 2와 3과 같이 설정하여 내측 랜드마크 포인트 쌍 에 더 높은 가중치를 줄 수 있다.수학식 2"}
{"patent_id": "10-2019-0121989", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 3"}
{"patent_id": "10-2019-0121989", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "사용자 구별부는 발화 검출부에서 검출된 사용자 발화 구간에 상응하는 타임 스템프 정보를 가진 매 칭 영상 프레임을 추출한다. 사용자 구별부는 매칭 영상 프레임에 대해 산출된 사용자별 입술 영역에 대한 특징값을 기반으로 매칭 영 상 프레임별 각 사용자의 입술 사이의 거리정보에 대한 상관도를 계산하고, 상관도에 기반하여 발화 사용자를 구별한다. 예컨대, 본 실시예에 있어서, 사용자 구별부는 매 매칭 영상 프레임별로 매칭 영상 프레임 내 복수의 사용 자 중 어떤 사용자가 발화하고 있는지를 판단하고, 이를 기반으로 발화 사용자를 구별할 수 있다. 즉, 사용자 구별부는 사용자별로 매칭 영상 프레임에 대하여 입술 사이의 거리정보에 대한 표준편차가 기 설정된 임계치 이상인 경우에 해당하는 발화 프레임을 선별하고, 발화 프레임의 갯수가 가장 많은 사용자를 발 화 사용자로서 판단할 수 있다. 보다 자세하게는, 사용자 구별부는 사용자별로 n번째 영상 프레임(=매칭 영상 프레임)으로부터 최근 W(ex: 10)개의 영상 프레임의 입술 거리의 표준편차가 기 설정된 제1 임계치 이상일 때 해당 사용자의 n번째 영상 프 레임을 발화 프레임으로 판단하고, 사용자 발화 구간 내에서 가장 많은 발화 프레임을 가진 사용자를 해당 사용 자 발화 구간의 발화자로 판단한다. 이때, 가장 많은 발화 프레임을 가진 사용자의 발화 프레임 수가 기 설정된 제2 임계치 이하일때에는 아무도 발화하지 않는다고 판단한다. i번째 프레임에서 사용자 u의 입술 거리를 du,i라 할 때 이를 수식으로 표현하면 수학식 4와 같다. 수학식 4"}
{"patent_id": "10-2019-0121989", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "사용자 u의 n번째 프레임에서의 발화 여부는 수학식 5와 같이 나타낼 수 있다. 수학식 5"}
{"patent_id": "10-2019-0121989", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 5에서는 사용자 u의 n번째 프레임이 발화 프레임으로서 판단될 시 나머지 사용자들에 대해서는 발화 사 용자로서 판단하지 않는 것으로 도시하였으나, 이는 일 실시예에 불과하며, 입술 거리의 표준편차가 제1 임계치이상인 다른 사용자 또한 발화 사용자로서 추가 판단될 수 있다. n번째 프레임의 발화 사용자는 수학식 6과 같이 나타낼 수 있다. 수학식 6"}
{"patent_id": "10-2019-0121989", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "다른 실시예에 있어서, 사용자 구별부는 사용자 발화 구간 내에서 가장 큰 입술 거리의 표준편차를 가지는 사용자를 발화 사용자로 판단할 수 있다. 이때, 사용자 구별부는 가장 큰 표준편차가 기 설정된 제3 임계 치 이하이면 아무도 발화하지 않는다고 판단한다. 발화구간 stdu 및 n번째 프레임의 발화 사용자를 각각 수학식으로 나타내면 수학식 7,8과 같다. 수학식 7"}
{"patent_id": "10-2019-0121989", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "수학식 8"}
{"patent_id": "10-2019-0121989", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "이하, 본 실시예에 따른 사용자 구별부가 응시 사용자를 구별하는 방법에 대해 설명하도록 한다. 사용자 구별부는 각 사용자별 얼굴 랜드마크 포인트 중 눈 영역에 상응하는 랜드마크 포인트를 산출하고, 이를 기반으로 산출되는 각 사용자의 홍채(Iris) 영역과 공막(Sclera) 영역 사이의 거리정보에 대한 상관도를 활용하여 복수의 사용자 중 응시 사용자를 구별한다. 보다 자세하게는, 사용자 구별부는 사용자별로 매 영상 프레임마다 얼굴 랜드마크 포인트로부터 왼쪽 눈 영역(ex: 도 3의 37 ~ 42번 포인트)와 오른쪽 눈 영역(ex: 도 3의 43 ~ 48번 포인트)을 구분한다. 사용자 구별부는 각 눈 영역의 랜드마크 포인트를 연결한 윤곽선 내부를 공막 영역으로 잘라내어 정의하고, 공막영역 내 픽셀을 그레이 스케일로 변환한다. 사용자 구별부는 각 눈별로 공막영역 내의 홍채 영역을 구분하기 위해 그레이 스케일 픽셀을 이진화한다. 이때, 이진화의 기준이 되는 이진화 임계치가 필요하며, 이 임계치는 최초 사용자 얼굴 등록 시 얻은 공막 대 홍채 비율(ISR: Iris-to-Sclera Ratio)을 바탕으로 가장 비슷한 ISR을 가지는 값으로 설정한다. 이진화 임계치 를 결정하는 알고리즘에 대한 소스 코드는 도 5와 같다. 이 알고리즘은 왼쪽 눈과 오른쪽 눈에 대하여 별도로 수행된다. 사용자 구별부는 양쪽 눈 모두 홍채영역의 무게 중심과 공막영역의 무게 중심의 거리가 기 설정된 제4 임 계치 이하이면 해당 사용자를 응시 사용자로서 판단한다. 본 실시예에 있어서, 사용자 구별부는 응시 사용자에 대한 구별결과에 근거하여 기기의 동작 모드가 전환 되도록 제어한다. 예컨대, 사용자 구별부는 응시 사용자의 존재가 확인되는 경우, 기기의 동작모드가 비활 성화 상태에서 활성화 상태로의 전환되도록 하는 모드 동작명령을 모드 전환부로 제공할 수 있다. 또한, 사용자 구별부는 인식된 발화 사용자가 인공지능 기기를 응시할 때에만 발화 문장에 대한 처리가 이 루어질 수 있도록 제어한다. 예컨대, 사용자 구별부는 발화 사용자가 응시 사용자가 동일한 경우에 한해 발화 사용자에 대한 정보를 수행부로 제공함으로써 수행부로 하여금 발화 문장에 대한 선택적 처리가 이루어질 수 있도록 한다. 모드 전환부는 기기의 동작모드를 기 설정된 조건에 따라 비활성화 상태에서 활성화 상태로 혹은 활성화 상태에서 비활성화 상태로 전환하는 기능을 수행한다. 본 실시예에 있어서, 모드 전환부는 사용자의 응시 여부가 확인되는 경우 기기의 상태를 비활성화 상태에 서 활성화 상태로 전환할 수 있다. 수행부는 다수의 사용자가 있는 환경에서 사용자 구별부를 통해 발화 사용자가 특정되면 음성 신호 내 해당 발화 사용자의 발화의도를 구분하고, 이를 기반으로 맥락에 맞는 정보를 제공하는 기능을 수행한다. 이 러한, 수행부는 바람직하게는 자연어 처리/이해 및 응답을 담당하는 Dialog Manager일 수 있다. 수행부는 복수의 다이얼로그 인스턴스(Dialog Instance)를 관리하며 각 대화는 발화자의 ID로 구분된다. 따라서, 상기의 발화 사용자 인식 방법을 통해 발화 사용자가 특정되면 다이얼로그 인스턴스를 특정할 수 있으 며, 만일 해당 사용자의 ID에 매칭되는 다이얼로그 인스턴스가 없는 경우 새로운 다이얼로그 인스턴스를 생성한 다. 이러한, 기본 동작에서 확장하여, 인식된 발화 사용자가 인공지능 기기를 응시할 때에만 발화된 문장을 전달받 어 사용자의 발화 의도를 구분할 수 있고, 다수의 사용자가 같은 도메인에서 대화를 진행하는 다이얼로그 인스 턴스도 생성/관리하여 해당 대화 참여자가 발화할때 그 인스턴스에 발화 문장을 전달할 수 있다. 도 6은 본 실시예에 따른 멀티모달 사용자 구별 방법에 대한 개요도이다. 종래의 기술과 차별되는 본 발명의 특징을 멀티모달 입력을 활용하여 발화 사용자 인식 기능 및 응시 사용자 인 식 기능을 동시에 수행하는 동작에 있다. 도 6을 참조하면, 본 실시예에 따른 멀티모달 사용자 구별 방법에 의하는 경우 먼저 카메라를 통해 입력된 영상 프레임에서 다수의 사용자의 얼굴을 새로 감지하거나 이전 프레임에서의 정보를 바탕으로 추적하여 각 사용자를 인식한다. 이후, 각 사용자 얼굴 영역을 잘라내어 얼굴 랜드마크 포인트를 추출하는 모듈로 전달한다. 동시에 마이크를 통해 입력된 음성 신호는 Speech-to-Text(STT)를 거쳐 자연어 처리/이해 및 응답을 담당하는 Dialog Manager로 전달되는 과정 외에 자연어 발화 여부를 확인하는 Voice Activity Detector(VAD)로 병렬 전 달된다. 이렇게 추출된 VAD 결과 및 얼굴 랜드마크 포인트는 통합되어 발화 사용자 인식과 응시 사용자 인식을 동시 수 행하는 모듈로 전달되고, 해당 인식 정보는 Dialog Manager로 전달되어 대화의 도메인을 구분하여 알맞은 응답 을 도출한다. 도 7은 본 실시예에 따른 멀티모달 사용자 구별 방법을 설명하기 위한 순서도이다. 멀티모달 사용자 구별장치는 영상 촬영장치 및 마이크 각각으로부터 취득된 영상 프레임 및 음성 신호를 수집한다(S702). 멀티모달 사용자 구별장치는 단계 S702의 영상 프레임 내 각 사용자를 인식하고, 각 사용자의 얼굴 영역을 추출한다(S704). 멀티모달 사용자 구별장치는 단계 S702의 음성 신호를 분석하여 음성 신호 내 사용자 발화 구간을 검출한 다(S706). 단계 S706에서 멀티모달 사용자 구별장치는 음성 신호 내 음성 명령에 상응하는 문장의 발화 시 작 시각부터 발화종료 시각까지의 구간을 사용자 발화 구간으로서 검출한다. 멀티모달 사용자 구별장치는 단계 S704에서 추출된 각 사용자의 얼굴 영역 내 입술 영역을 구분한다 (S708). 단계 S708에서 멀티모달 사용자 구별장치는 각 사용자별 얼굴 영역에 상응하는 얼굴 랜드마크 포인트를 추출하고, 얼굴 랜드마크 포인트 중 입술 영역에 상응하는 입술 랜드마크 포인트를 추출한다. 멀티모달 사용자 구별장치는 단계 S708의 사용자별 입술 영역의 특징값 및 단계 S706의 사용자 발화 구간 에 대한 특징값을 활용하여 발화 사용자를 구별한다(S710). 단계 S710에서 멀티모달 사용자 구별장치는 사 용자 발화 구간에 상응하는 타임 스템프 정보를 가진 매칭 영상 프레임에 대해 산출된 사용자별 입술 영역에 대 한 특징값을 기반으로 매칭 영상 프레임별 각 사용자의 입술 사이의 거리정보에 대한 상관도를 계산하고, 상관 도에 기반하여 발화 사용자를 구별한다. 단계 S710에서 멀티모달 사용자 구별장치는 각 사용자별 얼굴 랜드마크 포인트 중 눈 영역에 상응하는 랜 드마크 포인트를 산출하고, 이를 기반으로 산출되는 각 사용자의 홍채(Iris) 영역과 공막(Sclera) 영역 사이의 거리정보에 대한 상관도를 활용하여 복수의 사용자 중 응시 사용자를 구별한다. 멀티모달 사용자 구별장치는 응시 사용자에 대한 구별결과에 근거하여 기기의 동작 모드가 전환되도록 제 어할 수 있다. 또한, 멀티모달 사용자 구별장치는 인식된 발화 사용자가 인공지능 기기를 응시하고 있는 것으로 판단된 경우에 한해 발화 문장에 대한 처리가 이루어질 수 있도록 제어할 수 있다. 여기서, 단계 S702 내지 S710은 앞서 설명된 멀티모달 사용자 구별장치의 각 구성요소의 동작에 대응되므 로 더 이상의 상세한 설명은 생략한다. 도 7에서는 각각의 과정을 순차적으로 실행하는 것으로 기재하고 있으나, 반드시 이에 한정되는 것은 아니다. 다시 말해, 도 7에 기재된 과정을 변경하여 실행하거나 하나 이상의 과정을 병렬적으로 실행하는 것으로 적용 가능할 것이므로, 도 7은 시계열적인 순서로 한정되는 것은 아니다. 전술한 바와 같이 도 7에 기재된 멀티모달 사용자 구별 방법은 프로그램으로 구현되고 컴퓨터의 소프트웨어를 이용하여 읽을 수 있는 기록매체(CD-ROM, RAM, ROM, 메모리 카드, 하드 디스크, 광자기 디스크, 스토리지 디바 이스 등)에 기록될 수 있다. 이상의 설명은 본 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술 분 야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변 형이 가능할 것이다. 따라서, 본 실시예들은 본 실시예의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위 한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2019-0121989", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 실시예에 따른 멀티모달 사용자 구별 방법에 따른 서비스 시나리오를 설명하기 위한 예시도이다. 도 2는 본 실시예에 따른 멀티모달 사용자 구별장치를 개략적으로 나타낸 블록 구성도이다. 도 3은 본 실시예에 따른 얼굴 랜드마크 포인트를 예시한 예시도이다. 도 4는 본 실시예에 따른 사용자 발화 구간을 설명하기 위한 예시도이다. 도 5는 본 실시예에 따른 응시 사용자 구별방법을 설명하기 위한 도면이다. 도 6은 본 실시예에 따른 멀티모달 사용자 구별 방법에 대한 개요도이다. 도 7은 본 실시예에 따른 멀티모달 사용자 구별 방법을 설명하기 위한 순서도이다."}
