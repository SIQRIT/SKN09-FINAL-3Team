{"patent_id": "10-2023-0118101", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0035741", "출원번호": "10-2023-0118101", "발명의 명칭": "머신러닝을 지원하는 메모리 장치, 그것을 갖는 메모리 시스템, 및 그것의 동작 방법", "출원인": "삼성전자주식회사", "발명자": "김호연"}}
{"patent_id": "10-2023-0118101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "머신러닝을 지원하는 메모리 장치에 있어서,제 1 정밀도 혹은 제 2 정밀도를 갖는 가중치 데이터를 저장하는 제 1 셀 어레이;상기 제 1 정밀도를 갖는 손실 데이터를 저장하는 제 2 셀 어레이;상기 제 1 정밀도를 갖는 기울기 데이터를 저장하는 제 3 셀 어레이;혼합 정밀도 트레이닝(mixed-precision training)을 수행할 때, 스케일링 팩터에 대응하는 곱셈 동작, 나눗셈동작, 혹은 라운딩 동작 중에서 적어도 하나를 수행하는 연산 회로; 및상기 스케일링 팩터를 출력하는 스케일링 회로를 포함하는 메모리 장치."}
{"patent_id": "10-2023-0118101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 제 1 정밀도는 16-비트 정밀도이고,상기 제 2 정밀도는 32-비트 정밀도인 것을 특징으로 하는 메모리 장치."}
{"patent_id": "10-2023-0118101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 제 1 정밀도와 상기 제 2 정밀도는 서로 다르고,상기 제 2 정밀도는 32-비트 정밀도, 64-비트 정밀도, 및 128-비트 정밀도 중에서 어느 하나인 것을 특징으로하는 메모리 장치."}
{"patent_id": "10-2023-0118101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 연산 회로는 상기 스케일링 팩터에 따라 상기 제 2 정밀도의 데이터를 상기 제 1 정밀도의 데이터로 변경하는 것을 특징으로 하는 메모리 장치."}
{"patent_id": "10-2023-0118101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 제 1 정밀도 데이터는 1-비트의 부호 비트, 5-비트의 지수(exponent) 비트, 및 10-비트의 가수(mantissa)비트를 포함하고,상기 제 2 정밀도 데이터는 1-비트의 부호 비트, 8-비트의 지수 비트, 및 23-비트의 가수 비트를 포함하는 것을특징으로 하는 메모리 장치."}
{"patent_id": "10-2023-0118101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 연산 회로는 상기 스케일링 팩터에 따라 상기 8-비트의 지수 비트를 상기 5-비트의 지수 비트로 변경하고,상기 23-비트의 가수 비트를 상기 10-비트의 가수 비트로 변경하는 것을 특징으로 하는 메모리 장치."}
{"patent_id": "10-2023-0118101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,공개특허 10-2025-0035741-3-상기 손실 데이터는 상기 스케일링 팩터 만큼 곱셈 동작이 수행된 후에 메모리-인(memory-in) 혹은 메모리-아웃(memory-out) 되는 것을 특징으로 하는 메모리 장치."}
{"patent_id": "10-2023-0118101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 기울기 데이터는 상기 스케일링 팩터 만큼 나눗셈 동작이 수행된 후에 메모리-인 혹은 메모리 아웃 되는것을 특징으로 하는 메모리 장치."}
{"patent_id": "10-2023-0118101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "머신러닝을 지원하는 메모리 장치; 및상기 메모리 장치를 제어하는 적어도 하나의 프로세서를 포함하고,상기 메모리 장치는,제 1 정밀도 혹은 제 2 정밀도를 갖는 가중치 데이터를 저장하는 제 1 셀 어레이;상기 제 1 정밀도를 갖는 손실 데이터를 저장하는 제 2 셀 어레이;상기 제 1 정밀도를 갖는 기울기 데이터를 저장하는 제 3 셀 어레이;혼합 정밀도 트레이닝(mixed-precision training)을 수행할 때, 스케일링 팩터에 대응하는 곱셈 동작, 나눗셈동작, 혹은 라운딩 동작 중에서 적어도 하나를 수행하는 연산 회로; 및상기 스케일링 팩터를 출력하는 스케일링 회로를 포함하는 메모리 시스템."}
{"patent_id": "10-2023-0118101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "메모리 장치와 프로세서를 포함하는 메모리 시스템의 동작 방법에 있어서,혼합 정밀도 트레이닝을 수행할 때 상기 메모리 장치 내에서 가중치 데이터와 기울기 데이터 사이에 스케일링을갖는 덧셈을 수행하는 단계;상기 가중치 데이터를 업데이트 하는 단계; 및라운딩 로직을 이용하여 상기 업데이트된 가중치 데이터의 정밀도를 변경하는 단계를 포함하는 방법."}
{"patent_id": "10-2023-0118101", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따른 머신러닝을 지원하는 메모리 장치는, 제 1 정밀도 혹은 제 2 정밀도를 갖는 가중치 데이터를 저 장하는 제 1 셀 어레이, 상기 제 1 정밀도를 갖는 손실 데이터를 저장하는 제 2 셀 어레이, 상기 제 1 정밀도를 갖는 기울기 데이터를 저장하는 제 3 셀 어레이, 혼합 정밀도 트레이닝(mixed-precision training)을 수행할 때, 스케일링 팩터에 대응하는 곱셈 동작, 나눗셈 동작, 혹은 라운딩 동작 중에서 적어도 하나를 수행하는 연산 회로, 및 상기 스케일링 팩터를 출력하는 스케일링 회로를 포함할 수 있다."}
{"patent_id": "10-2023-0118101", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 머신러닝을 지원하는 메모리 장치, 그것을 갖는 메모리 시스템, 및 그것의 동작 방법에 관한 것이다."}
{"patent_id": "10-2023-0118101", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 혼합 정밀도 트레이닝(mixed precision training)은 딥러닝 트레이닝에서 사용되는 최적화 기법 중 하나이다. 이 기법은 하드웨어 가속기에서 트레이닝 성능을 향상시킨다. 혼합 정밀도 트레이닝은, 일반적으로 32-비트 부동소수점(float32) 연산과 16-비트 부동소수점(float16) 연산을 함께 사용한다. 혼합 정밀도 트레이 닝의 목표는 학습 속도를 높이고, 메모리 사용량을 줄이면서, 학습 모델의 성능을 유지시키는데 있다."}
{"patent_id": "10-2023-0118101", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 메모리 사용량을 줄이면서 성능을 향상시키는 머신러닝을 지원하는 메모리 장치, 그것을 갖는 메모리 시스템, 및 그것의 동작 방법을 제공하는 데 있다."}
{"patent_id": "10-2023-0118101", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 머신러닝을 지원하는 메모리 장치는, 제 1 정밀도 혹은 제 2 정밀도를 갖는 가중치 데이터를 저장하는 제 1 셀 어레이; 상기 제 1 정밀도를 갖는 손실 데이터를 저장하는 제 2 셀 어레이; 상기 제 1 정밀도를 갖는 기울기 데이터를 저장하는 제 3 셀 어레이; 혼합 정밀도 트레이닝(mixed-precision training) 을 수행할 때, 스케일링 팩터에 대응하는 곱셈 동작, 나눗셈 동작, 혹은 라운딩 동작 중에서 적어도 하나를 수 행하는 연산 회로; 및 상기 스케일링 팩터를 출력하는 스케일링 회로를 포함할 수 있다. 본 발명의 실시 예에 따른 메모리 시스템은, 머신러닝을 지원하는 메모리 장치; 및 상기 메모리 장치를 제어하 는 적어도 하나의 프로세서를 포함하고, 상기 메모리 장치는, 제 1 정밀도 혹은 제 2 정밀도를 갖는 가중치 데 이터를 저장하는 제 1 셀 어레이; 상기 제 1 정밀도를 갖는 손실 데이터를 저장하는 제 2 셀 어레이; 상기 제 1 정밀도를 갖는 기울기 데이터를 저장하는 제 3 셀 어레이; 혼합 정밀도 트레이닝(mixed-precision training)을 수행할 때, 스케일링 팩터에 대응하는 곱셈 동작, 나눗셈 동작, 혹은 라운딩 동작 중에서 적어도 하나를 수행하 는 연산 회로; 및 상기 스케일링 팩터를 출력하는 스케일링 회로를 포함할 수 있다. 본 발명의 실시 예에 따른 메모리 장치와 프로세서를 포함하는 메모리 시스템의 동작 방법은, 혼합 정밀도 트레 이닝을 수행할 때 상기 메모리 장치 내에서 가중치 데이터와 기울기 데이터 사이에 스케일링을 갖는 덧셈을 수 행하는 단계; 상기 가중치 데이터를 업데이트 하는 단계; 및 라운딩 로직을 이용하여 상기 업데이트된 가중치 데이터의 정밀도를 변경하는 단계를 포함할 수 있다. 본 발명의 다른 실시 예에 따른 메모리 시스템은, 머신러닝을 지원하는 적어도 하나의 메모리 장치; 혼합 정밀 도 트레이닝을 수행할 때, 스케일링 팩터에 대응하는 곱셈 동작, 나눗셈 동작, 혹은 라운딩 동작 중에서 적어도 하나를 수행하는 보조 메모리 모듈; 및 상기 적어도 하나의 메모리 장치 및 상기 보조 메모리 모듈을 제어하는 프로세서를 포함하고, 상기 적어도 하나의 메모리 장치는, 제 1 정밀도 혹은 제 2 정밀도를 갖는 가중치 데이터 를 저장하는 제 1 셀 어레이; 상기 제 1 정밀도를 갖는 손실 데이터를 저장하는 제 2 셀 어레이; 및 상기 제 1 정밀도를 갖는 기울기 데이터를 저장하는 제 3 셀 어레이를 포함할 수 있다."}
{"patent_id": "10-2023-0118101", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 따른 머신러닝을 지원하는 메모리 장치, 그것을 갖는 메모리 시스템, 및 그것의 동작 방법 은, 혼합 정밀도 트레이닝을 수행하면서 메모리 장치 내부에서 인-데이터/아웃-데이터의 정밀도를 변환함으로써, 효율적으로 메모리를 사용할 수 있다."}
{"patent_id": "10-2023-0118101", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 도면들을 이용하여 본 발명의 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시 할 수 있을 정"}
{"patent_id": "10-2023-0118101", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "도로 본 발명의 내용을 명확하고 상세하게 기재할 것이다. 본 발명의 실시 예에 따른 머신러닝을 지원하는 메모리 장치, 그것을 갖는 메모리 시스템, 및 그것의 동작 방법 은, 메모리 장치 내에서 머신러닝 데이터 처리할 수 있다. 본 발명은 multiply/divide/round 로직을 이용하는 PIM(Processing In Memory)/PNM(Processing Near Memory)이 구현된 메모리 모듈(데이터 연산 기능이 구현된 memory expander 형태의 모듈도 포함함)) 등으로 구현될 수 있다. 본 발명의 메모리 장치, 그것을 갖는 메모리 시스템, 및 그것의 동작 방법은, 리던던트 데이터 트랜잭션(redundant data transaction) 감소로 인한 대역폭/ 지연/전력(bandwidth/delay/power) 이득을 꾀할 수 있다. 본 발명은 메모리 장치에서 혼합 정밀도 트레이닝 (mixed precision training)을 위한 정밀도 변경(precision change) 동작을 수행할 수 있다. 도 1은 일반적인 혼합 정밀도 트레이닝을 보여주는 도면이다. 프로세서는 메모리에 쓰여진 모든 데이터의 정밀 도를 일일이 변경할 필요는 없다. 해당 작업/과정은 메모리 내에서 수행이 가능한 종류이다. 따라서, 메모리 장 치에서 정밀도 변경을 수행함으로써 시스템 부하-균형(load-balancing)에 도움이 될 수 있다. 일반적으로 혼합 정밀도 트레이닝은 주요 개념과 장점은 다음과 같다. float16 연산은 float32 연산에 비해 더 적은 메모리를 사용한다. 따라서 같은 GPU(Graphic Processing Unit) 메모리 내에서 더 큰 모델이나 더 큰 미니 배치 크기로 학습을 진행할 수 있다. GPU 아키텍처는 float16 연산을 float32 연산보다 빠르게 처리할 수 있다. 이로 인해 학습 속도가 빨라질 수 있다. float16 연산은 제한된 수치 범위를 갖는다. 이로 인해 일부 연산에서 오버플로우나 언더플로우 문제가 발생할 수 있다. Tensor Core와 같은 하드웨어는 이러한 문제를 완화시키고 있 다. 오버플로우나 언더플로우 문제를 방지하기 위해, 기울기 값들이 너무 작아져서 float16에서 0으로 인식되지 않도록 한다. 이를 위하여 손실(loss) 값을 일정 비율로 확대(scale up)시키고 있다. 이렇게 스케일링 된 손실 을 사용하여 역전파를 수행한 후, 기울기는 업데이트하기 전에 다시 원래의 비율로 축소(scale down)된다. 가중 치의 float32 복사본을 유지함으로써, 기울기 업데이트가 더 정밀하게 수행될 수 있다. 이러한 방법은 float16 의 정밀도 한계로 인한 문제를 완화시킬 수 있다. 도 2는 일반적인 혼합 정밀도 트레이닝의 동작을 개념적으로 설명하는 도면이다. 도 2를 참조하면, 혼합 정밀도 트레이닝은 학습 사이클마다 마스터 가중치(master weight)를 복제하는 과정을 포함하고 있다. 이러한 복제 과 정을 위한 메모리 낭비가 발생될 수 있다. 본 발명의 메모리 장치는 이러한 메모리 낭비를 메모리 내 정밀도 혼 합(precision mixing) 구현으로 제거할 수 있다. 본 발명의 실시 예에 따른 메모리 장치는 머신러닝 시스템이 학습 과정을 수행할 때, 메모리 내부에서 혼합 정 밀도 트레이닝을 지원할 수 있다. 특히, 메모리 내부에서 인/아웃(in/out)-데이터의 정밀도를 변경해 줌으로써, 불필요한 신경망(neural network) 데이터 복제 과정을 삭제할 수 있다. 일반적으로 신경망의 트레이닝, 특히 플로팅 포인트 정밀도(floating point precision)에 따라 계산/전력 소모/ 메모리 사용이 영향을 받는다. 혼합 정밀도 트레이닝은, 32-비트 정밀도(single precision)에서 16-비트 정밀도 (half precision) 변경될 때 데이터 업데이트는 32-비트로 하지만, 트레이닝 반복(training iteration)에 사용 되고 손실되는 정보들은 낮은 정밀도로 수행할 수 있다. 일반적으로, 32-비트 정밀도(FP32)에서 16-비트 정밀도(FP16)로 변경할 때, 32-비트 정밀도(FP32)에서는 표현 가능하지만 16-비트 정밀도(FP16)에서 표현 불가능하다. 32-비트 정밀도의 데이터에서 변경된(예를 들어, 0으로 강제 변환) 값들에 대해 손실 스케일링(loss scaling; data range shift/exponent change)함으로써 트레이닝에 이용될 수 있다. 메모리에 마스터 가중치(master weight) 업데이트할 때, 디-스케일링(de-scaling)함으로써, 정 보 왜곡이 최소화 되고, 가중치가 업데이트 될 수 있다. 수 있다. 혼합 정밀도 트레이닝은 마스터 가중치를 FP32에서 FP16으로 변환 후(float2half), 전파/역전파(Forward/Back- propagation)을 FP16으로 연산할 수 있다.이때 계산된 기울기(gradient(FP16))로부터 가중치를 업데이트할 때, FP32로 변환됨으로써 마스터 가중치가 업데이트될 수 있다. 한편, FP16을 그대로 사용하면 상술된 트레이닝 손실(training loss)이 커지는 현상이 발생함으로써 학습이 제 대로 이루어지지 않을 수 있다. 손실 스케일링(loss scaling) 기법이 사용되고 있다. 도 3은 일반적인 혼합 정밀도 트레이닝의 손실 스케일링을 개념적으로 보여주는 도면이다. 도 3을 참조하면, 활 성화 기울기 값 히스토그램이 도시되고 있다.트레이닝이 발산하고 있기 때문에, 손실 스케일링이 요구된다. 손 실 스케일링은 도 3에 도시된 바와 같이, FP16으로 기울기(gradient)를 연산할 때 기울기가 매우 작을 때 FP16은 이를 표현하지 못한다. 손실 스케일링은 '0'이 되는 부분 때문에 발생하는 오차를 방지하기 위해 FP16이 표 현할 수 있는 범위로 기울기를 이동(shift) 시키는 것이다. 예를 들어, 기울기를 FP16이 표현할 수 있는 범위로 이동하기 위해서, 간단하게 기울기에 스케일링 팩터(scaling factor; S)가 곱해질 수 있다. 도 4는 본 발명의 실시 예에 따른 메모리 시스템을 예시적으로 보여주는 도면이다. 도 4를 참조하면, 메모 리 시스템은 머신러닝을 지원하는 메모리 장치 및 메모리 장치를 제어하는 프로세서를 포함 할 수 있다. 예를 들어, 프로세서는 NPU(Neural Processing Unit), CPU(Central Processing Unit), GPU(Graphic Processing Unit), 혹은 DPU(Data Processing Unit)로 구현될 수 있다. 메모리 장치는 머신러닝을 수행하기 위한 적어도 하나의 휘발성 메모리 장치 혹은 적어도 하나의 비휘발성 메모리 장치를 포함할 수 있다. 실시 예에 있어서, 휘발성 메모리 장치는 DRAM(dynamic random access memory), SRAM(static random access memory), T-RAM(thyristor RAM), Z-RAM(zero capacitor RAM), 혹은 TTRAM(Twin Transistor RAM)으로 구현될 수 있다. 실시 예에 있어서, 비휘발성 메모리 장치는 EEPROM(Electrically Erasable Programmable Read-Only Memory), 플래시(flash) 메모리, MRAM(Magnetic RAM), 스핀전달토크 MRAM(Spin-Transfer Torque(STT)-MRAM), Conductive Bridging RAM(CBRAM), FeRAM(Ferroelectric RAM), PRAM(Phase change RAM), 저항 메모리(Resistive RAM(RRAM)), 나노 튜브 RRAM(Nanotube RRAM), 폴리머 RAM(Polymer RAM(PoRAM)), 나노 부유 게이트 메모리(Nano Floating Gate Memory(NFGM)), 홀로그래픽 메모리 (holographic memory), 분자 전자 메모리 소자(Molecular Eelectronic Memory Device), 혹은 절연 저항 변화 메모리(Insulator Resistance Change Memory)로 구현될 수 있다. 메모리 장치는 혼합 정밀도를 지원하도록 구현될 수 있다. 여기서 혼합 정밀도는 16-비트 정밀도(다른 말 로, '제 1 정밀도') 및 32-비트 정밀도(다른 말로, '제 2 정밀도')를 포함할 수 있다. 한편, 본 발명의 혼합 정 밀도가 여기에 제한되지 않는다고 이해되어야 할 것이다. 트레이닝 정밀도에 따라 32/64/128 비트 정밀도도 가 능하다. 아래에서는 설명의 편의를 위하여, 메모리 장치에서 프로세서로 전송되는 데이터는 16-비트 정밀도를 갖고, 프로세서에서 메모리 장치로 전송되는 데이터는 16-비트/32-비트 정밀도를 갖는다고 하겠다. 메모리 장치는 제 1 셀 어레이, 제 2 셀 어레이, 제 3 셀 어레이, 연산 회로, 및 스 케일링 회로를 포함할 수 있다. 제 1 셀 어레이, 제 2 셀 어레이, 제 3 셀 어레이는 논리적 혹은 물리적으로 구분될 수 있다. 실시 예에 있어서, 제 1 셀 어레이, 제 2 셀 어레이, 제 3 셀 어레이의 각각은 머신러닝에 사용 되는 데이터의 속성에 따라 구분될 수 있다. 실시 예에 있어서, 제 1 셀 어레이는 가중치 데이터를 저장하는 영역을 포함할 수 있다. 일반적으로 가중 치 데이터는 인-메모리(in-memory data) 정밀도 데이터 및 아웃-메모리(out-memory) 정밀도로써, 서로 다른 정 밀도를 가질 수 있다.즉, 가중치 데이터는 혼합 정밀도를 갖는다. 제 2 셀 어레이는 손실 데이터를 저장하는 영역을 포함할 수 있다. 제 2 셀 어레이의 손실 데이터는 스케일링 팩터 만큼 곱셈(multiply)을 수행한 후 메모리-인/메모리-아웃 될 수 있다. 메모리-인/메모리-아웃 중 에서 하나만 수행됨으로써, 연산 시간 이득이 크다. 여기서 곱셈 연산은 메모리-인/메모리-아웃 과정에서 수행 될 수 있다. 제 3 셀 어레이는 활성화/기울기 데이터를 저장하는 영역을 포함할 수 있다. 제 3 셀 어레이의 활성 화/기울기 데이터는 스케일링 팩터만큼 나눗셈(divide)을 수행한 후 메모리-인/메모리-아웃 될 수 있다. 메모리 -인/메모리-아웃 중 한번만 수행됨으로써, 연산 시간 이득이 크다. 여기서 나눗셈 연산은 메모리-인/메모리-아 웃 중에 수행될 수 있다. 스케일링 회로는 정밀도를 지시하는 스케일링 팩터(scaling factor)를 출력하도록 구현될 수 있다. 스케일 링 팩터는 초기 값 (e.g., 23)에서 시작하여, 연산 회로의 프로세서 연산 중에서 데이터 오버플로우 발생 시 감소시켜 사용할 수 잇다. 이는 프로세서 드라이븐 튜닝(Processor driven tuning) 가능하다는 의미이다. 프 로세서는 메모리 장치의 alert/exception signaling 통해서 연산 회로의 통제 가능하다. 메모리 장치는 스케일링 회로에서 출력된 스케일링 팩터와 연산 회로의 PIM(Processing In Memory) 연산(예를 들어, multiply, divide, round 등) 이용하여 혼합 정밀도 트레이닝을 지원할 수 있다. 본 발명의 실시 예에 따른 메모리 장치의 혼합 정밀도 트레이닝은 하프-정밀도 트레이닝 수준의 연산을 수 행하고, 메모리를 사용함으로써, 트레이닝 속도 및 자원 효율성을 증가시킬 수 있다. 또한, 본 발명의 실시 예 에 따른 메모리 장치의 혼합 정밀도 트레이닝은 추론(inference) 결과 (=신경망 성능)로써, 싱글-정밀도 트레이닝 수준 결과를 갖는다. 일반적인 메모리 시스템은 시스템의 프로세서가 주도하여 정밀도를 변환시켜 혼합 정밀도 트레이닝을 수행함으 로써, 메모리 장치 내에서 불필요한 신경망 데이터 복제 과정을 야기시킬 수 있다. 반면에, 본 발명의 실시 예 에 따른 메모리 시스템은 메모리 내부에서 인-데이터/아웃-데이터의 정밀도를 변환시킴으로써, 불필요한 신 경망(Neural Network) 데이터 복제 과정을 삭제할 수 있다. 본 발명의 실시 에에 따른 메모리 시스템은 인공지능(Artificial Intelligence; AI) 혼합 정밀도 트레이닝 을 수해함으로써, 메모리 내에서 정밀도 변환을 지원할 수 있다. 이로써, 메모리 시스템은 메모리의 효율적 인 대역폭(Effective Bandwidth)을 향상시킬 수 있다. 즉, 프로세서-메모리 사이의 교환되는 데이터의 정밀도 감소로 인하여 메모리의 효율적인 대역폭이 증가될 수 있다. 본 발명은 머신러닝을 지원하는 메모리 장치/메모리 모듈을 포함할 수 있다. 메모리 장치/메모리 모듈 내에서 데이터 정밀도의 혼합이 수행될 수 있다. 본 발명의 메모리 장치/메모리 모듈은 메모리 셀 어레이의 구분 결과 를 시스템(프로세서)에 알릴 수 있다. 실시 예에 있어서, 입력 데이터(memory-in data)는 데이터 클래스(data class)에 구분되어 메모리 장치에 저장될 수 있다. 실시 예에 있어서, 출력 데이터(memory-out data)는 데이터 클래스에 따라 구분되어 PIM(rounding logic)/ PNM(Processing Near Memory)이 구현된 메모리 모듈 등을 통해 시스템에 전송될 수 있다. 실시 예에 있어서, 트레이닝 중에서 가중치 데이터가 업데이트 될 수 있다. 실시 예 에 있어서, 메모리 내, 가중치 데이터 및 기울기 데이터 사이의 스케일링을 갖는 덧셈(addition with scaling) 이 수행될 수 있다. 실시 예에 있어서, PIM/ PNM(Processing Near Memory)이 구현된 메모리 모듈 등의 라운딩 로직을 이용하여 업데이트된 가중치 데이터의 정밀도를 변환시킨 후에, 가중치 데이터가 시스템에 전송될 수 있 다. 도 5는 본 발명의 실시 예에 따른 인-메모리 플로팅 포인트 정밀도 변환을 예시적으로 보여주는 도면이다. 도 5 를 참조하면, 연산 회로는 메모리 내부 PIM의 형태로 구성될 수 있다. 플로팅 포인트 정밀도 변환 (floating point precision) 변환은 도 5에 도시된 바와 같이 수행될 수 있다. 플로팅 포인트(FP) 포맷 변환 시(FP32 FP16), 지수(exponent)는 줄이고 가수(mantissa)는 반올림(rounding to nearest)함으로써, 데이터의 길이가 줄어 들 수 있다. PIM 이용해서 이러한 변환 동작을 수행하는 라운딩 로직이 구현될 수 있다. 이러한 인-메모리 정밀도 혼합은, 혼합 정밀도 트레이닝 중에서 불필요한 데이터 복제 과정을 삭제 시켜 메모리 사용량/점유율 감소시킬 수 있다. Memory-to-Processor 데이터의 정밀도를 PIM을 통해 감소시킴으로써, 효율적 인 메모리 대역폭이 증가될 수 있다. 한편, 본 발명에서 플로팅 포인트 변환은 FP32 FP16만 되는 것은 아니고, 다양한 플로팅 포인트 포맷 변환을 지원할 수 있다고 이해되어야 할 것이다. 도 6은 본 발명의 실시 예에 따른 메모리 장치에서 가중치 업데이트를 예시적으로 보여주는 도면이다. 일반적으 로 트레이닝 사이클 마무리 시, 가중치 업데이트가 필요하다. 도 6을 참조하면, PIM(multiplication/add) 이용 하여 가중치 업데이트 과정에서 메모리 장치(100a)에서 오프-로딩(off-loading)이 가능하다. 메모리 셀 어레이는 가중치 데이터를 저장하는 제 1 셀 어레이와 기울기 데이터를 저장하는 제 3 셀 어레 이로 구분되어 있다. 따라서, 정밀도 매칭 후에, 메모리 장치(100a)의 내부에 덧셈 로직(PIM; 122)을 이용 하여 시스템/프로세서에 업데이트 가중치 데이터가 전달될 수 있다. 본 발명은 가중치 업데이트 과정에서 프로세서 오프-로딩 효과 확보할 수 있다. 한편, 본 발명은 메모리 모듈(memory module)에 적용 가능하다. 도 7은 본 발명의 다른 실시 예에 따른 메모리 시스템을 예시적으로 보여주는 도면이다. 도 7을 참조하면, 메모리 시스템은 적어도 하나의 메모리 장치(100b), 프로세서(200b) 및 보조 메모리 모듈(300; AXDIMM)을 포함할 수 있다. 여기서, 적어도 하나의 메모리 장치(100b) 및 보조 메모리 모듈은 하나의 메모리 모듈로 구현될 수 있다. 적어도 하나의 메모리 장치(100b)는 머신러닝을 지원하도록 구현될 수 있다. 메모리 장치(100b)는 가중치 데이 터를 저장하는 제 1 셀 어레이, 손실 데이터를 저장하는 제 2 셀 어레이, 및 활성화/기울기 데이터를저장하는 제 3 셀 어레이를 포함할 수 있다. 여기서, 가중치 데이터는 제 1 정밀도 혹은 제 2 정밀도를 갖 고, 손실 데이터 및 활성화/기울기 데이터는 제 1 정밀도를 갖는다. 보조 메모리 모듈(300; AXDIMM)은 혼합 정밀도 트레이닝을 수행할 때, 스케일링 팩터에 대응하는 곱셈 동작, 나 눗셈 동작, 혹은 라운딩 동작 중에서 적어도 하나를 수행하도록 구현될 수 있다. 보조 메모리 모듈은 도 4 내지 도 7에설 설명된 혼합 정밀도 트레이닝을 수행하는 process-in-module(예시: AXDIMM 등)로 구현될 수 있다. 즉, 보조 메모리 모듈는 도 4 내지 도 7에서 설명된 메모리 내에서 혼합 정밀도 트레이닝 동작을 동 일하게 혹은 유사하게 수행할 수 있다. 실시 예에 있어서, 보조 메모리 모듈은 스케일링 팩터를 출력하는 스케일링 회로를 포함할 수 있다. 실시 예에 있어서, 보조 메모리 모듈은 프로세서(200b)로부터 제 2 정밀도의 가중치 데이터를 수신하고, 제 2 정밀도의 가중치 데이터를 메모리 장치(100b)의 제 1 셀 어레이으로 저장시킬 수 있다. 실시 예에 있 어서, 보조 메모리 모듈은 메모리 장치(100b)의 제 1 셀 어레이으로부터 제 2 정밀도의 가중치 데이 터를 수신하고, 제 2 정밀도의 가중치 데이터를 제 1 정밀도의 가중치 데이터로 변환하고, 제 1 정밀도의 가중 치 데이터를 프로세서(100b)로 출력시킬 수 있다. 프로세서(200b)는 적어도 하나의 메모리 장치(100b) 및 보조 메모리 모듈을 제어하도록 구현될 수 있다. 도 8은 본 발명의 실시 예에 따른 메모리/모듈의 혼합 정밀도 트레이닝 동작을 예시적으로 보여주는 흐름도이다. 도 1 내지 도 8을 참조하면, 혼합 정밀도 트레이닝 동작은 다음과 같이 진행될 수 있다. 가중치 데이터와 기울기 데이터 사이에서 스케일링을 갖는 인-메모리 덧셈(in-memory addition)이 수행될 수 있 다(S110). 라운딩 PIM/ PNM(Processing Near Memory)이 구현된 메모리 모듈을 이용하여 가중치 데이터가 업데 이트 될 수 있다(S120). 업데이트된 가중치 데이터의 정밀도가 변경될 수 있다(S130). 실시 예에 있어서, 변경 된 정밀도를 갖는 가중치 데이터는 프로세서로 출력될 수 있다. 실시 예에 있어서, 혼합 정밀도 트레이닝에서 오버플로우가 발생할 때, 프로세서는 스케일링 팩터를 변경하도록 메모리 장치를 제어할 수 있다. 실시 예에 있어서, 메모리 장치는 메모리 셀 어레이의 구분 결과를 프로세서로 알릴 수 있다. 실시 예에 있어서, 프로세서 의 입력 데이터는 데이터 클래스에 따라 메모리 장치의 대응하는 셀 어레이로 저장되고, 메모리 장치의 출력 데 이터는 데이터 클래스에 따라 프로세서로 전송될 수 있다. 본 발명의 실시 예에 따른 인-메모리 혼합 정밀도 트레이닝은 머신러닝 전용의 메모리 및 PIM(Processing-In- Memory) 및 PNM(Processing Near Memory)이 구현된 메모리 모듈 기술과 결합 가능하다. 특히, 본 발명의 인-메 모리 혼합 정밀도 트레이닝은 머신러닝 어플리케이션을 지원하는 AI향 메모리 특징으로 이용될 수 있다. 한편, 본 발명은 신경망 학습 장치에 적용 가능하다. 도 9는 본 발명의 실시 예에 따른 신경망 학습 장치를 예시적으로 보여주는 도면이다. 도 9를 참조하면, 신경망 학습 장치는 신경망(혹은, 신경망 모델)를 학습시킬 수 있다. 또한, 신경망 학습 장치는 학 습된 신경망을 이용하여 추론을 수행할 수 있다. 신경망 학습 장치는 낮은 연산 복잡도로 신경망을 학습 시킬 수 있다. 신경망 학습 장치는 양자화(quantization)를 이용하여 신경망을 학습시킴으로써 신경망 연 산의 복잡도를 낮출 수 있다. 실시 예에 있어서, 신경망은 심층 신경망(Deep Neural Network)를 포함할 수 있다. 신경망은 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), 퍼셉트론(perceptron), 다층 퍼셉트론 (multilayer perceptron), FF(Feed Forward), RBF(Radial Basis Network), DFF(Deep Feed Forward), LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit), AE(Auto Encoder), VAE(Variational Auto Encoder), DAE(Denoising Auto Encoder), SAE(Sparse Auto Encoder), MC(Markov Chain), HN(Hopfield Network), BM(Boltzmann Machine), RBM(Restricted Boltzmann Machine), DBN(Depp Belief Network), DCN(Deep Convolutional Network), DN(Deconvolutional Network), DCIGN(Deep Convolutional Inverse Graphics Network), GAN(Generative Adversarial Network), LSM(Liquid State Machine), ELM(Extreme Learning Machine), ESN(Echo State Network), DRN(Deep Residual Network), DNC(Differentiable Neural Computer), NTM(Neural Turning Machine), CN(Capsule Network), KN(Kohonen Network) 및 AN(Attention Network)를 포함 할 수 있다. 실시 예에 있어서, 신경망 학습 장치는 경량 신경망 모델을 이용함으로써 제한된 하드웨어 자원을 이용하 는 임베디드 시스템 상에서 구현될 수 있다. 신경망 학습 장치는 온-디바이스(on-device)로 학습 및 추론 을 모두 진행할 수 있다. 신경망 학습 장치는 마더보드(motherboard)와 같은 인쇄 회로 기판(PrintedCircuit Board; PCB), 집적 회로(Integrated Circuit; IC), 혹은 SoC(System on Chip)로 구현될 수 있다. 예를 들어, 신경망 학습 장치는 애플리케이션 프로세서(application processor)로 구현될 수 있다. 또한, 신경망 학습 장치는 PC(personal computer), 데이터 서버, 혹은 휴대용 장치 내에 구현될 수 있다. 휴대용 장치는 랩탑(laptop) 컴퓨터, 이동 전화기, 스마트 폰(smart phone), 태블릿(tablet) PC, 모바일 인터 넷 디바이스(mobile internet device(MID)), PDA(personal digital assistant), EDA(enterprise digital assistant), 디지털 스틸 카메라(digital still camera), 디지털 비디오 카메라(digital video camera), PMP(portable multimedia player), PND(personal navigation device 혹은 portable navigation device), 휴대 용 게임 콘솔(handheld game console), e-북(e-book), 혹은 스마트 디바이스(smart device)로 구현될 수 있다. 스마트 디바이스는 스마트 와치(smart watch), 스마트 밴드(smart band), 혹은 스마트 링(smart ring)으로 구 현될 수 있다. 실시 예에 있어서, 신경망 학습 장치는 신경망 모델의 가중치를 처리함으로써 신경망을 학습시킬 수 있다. 신경망 학습 장치는 최대 정밀도(full-precision)로 학습된 신경망 모델의 가중치를 처리하여 경량 신경망 모델을 생성할 수 있다. 신경망 학습 장치는 신경망 모델의 학습 중에 변화하는 가중치를 처리함 으로써 새로운 가중치를 획득하고, 새로운 가중치에 기초하여 신경망 모델을 재학습(retrain)시킬 수 있다. 도 9를 다시 참조하면, 신경망 학습 장치는 수신기, 프로세서, 및 메모리 장치를 포함 할 수 있다. 여기서 메모리 장치는 도 1 내지 도 8에서 설명된 바와 같이 머신러닝을 지원하도록 구현될 수 있다. 수신기는 수신 인터페이스를 포함할 수 있다. 수신기는 신경망 모델 혹은 신경망 모델에 대응되는 파라미터를 수신할 수 있다. 예를 들어, 수신기는 신경망 모델의 가중치를 수신할 수 있다. 수신기(110 0)는 무작위로 초기화된 신경망 모델 혹은 임의의 가중치에 기초하여 학습된 신경망 모델을 수신할 수 있다. 예 를 들어, 수신기는 제 1 가중치에 기초하여 제 1 학습된 신경망 모델을 수신할 수 있다. 이 때, 제 1 가 중치는 양자화된 가중치를 포함할 수 있다. 수신기는 수신한 신경망 모델 혹은 신경망 모델에 대응되는 파라미터를 프로세서로 출력할 수 있다. 프로세서는 메모리 장치에 저장된 데이터를 처리하도록 구현될 수 잇다. 프로세서는 메모리 장치에 저장된 컴퓨터로 읽을 수 있는 코드(예를 들어, 소프트웨어) 및 프로세서에 의해 유발된 인 스트럭션(instruction)들을 실행할 수 있다. 프로세서는 목적하는 동작들(desired operations)을 실행시키기 위한 물리적인 구조를 갖는 회로를 가지 는 하드웨어로 구현된 데이터 처리 장치일 수 있다. 예를 들어, 목적하는 동작들은 프로그램에 포함된 코드 (code) 혹은 인스트럭션들(instructions)을 포함할 수 있다. 예를 들어, 하드웨어로 구현된 데이터 처리 장치는 마이크로프로세서(microprocessor), 중앙 처리 장치(central processing unit), 프로세서 코어(processor core), 멀티-코어 프로세서(multi-core processor), 멀티프로세서(multiprocessor), ASIC(Application- Specific Integrated Circuit), FPGA(Field Programmable Gate Array)를 포함할 수 있다. 실시 예에 있어서, 프로세서는 제 1 학습된 신경망 모델을 복수의 학습률(learning rate)에 기초하여 제 2 학습시킴으로써 제 2 학습된 신경망 모델로부터 복수의 제 2 가중치를 획득할 수 있다. 프로세서는 제 1 학습된 신경망 모델을 복수의 학습률에 기초하여 제 2 학습시킬 수 있다. 프로세서는 주기 학습률 (cyclical learning rate)에 기초하여 제 1 학습된 신경망 모델을 제 2 학습시킬 수 있다. 이 때, 주기 학습률 은 미리 결정된 에포크(epoch)의 주기에 따라 변화하는 학습률을 의미할 수 있다. 주기 학습률은 한 주기 내에 서 선형 혹은 비선형 적으로 변화할 수 있다. 또한, 프로세서는 복수의 학습률에 기초하여 제 2 학습된 신경망 모델로부터 복수의 제 2 가중치를 획득 할 수 있다. 프로세서는 복수의 학습률 중에서 가장 낮은 학습률에 기초하여 제 2 학습된 신경망 모델로 부터 복수의 제 2 가중치를 획득할 수 있다. 예를 들어, 프로세서는 주기 학습률의 한 주기 내에서 가장 낮은 학습률에 기초하여 제 2 학습된 신경망 모델로부터 복수의 제 2 가중치를 획득할 수 있다. 프로세서는 복수의 제 2 가중치에 기초하여 제 2 학습된 신경망 모델을 제 3 학습시킬 수 있다. 다시 말 해, 제 2 학습 및 제 3 학습은 신경망의 재학습을 의미할 수 있다. 프로세서는 복수의 제 2 가중치의 평 균값을 획득할 수 있다. 프로세서는 복수의 제 2 가중치의 이동 평균값을 획득할 수 있다. 프로세서 는 평균값을 양자화 함으로써 양자화된 평균값을 획득할 수 있다. 프로세서는 양자화된 평균값에 기초하여 제 2 학습된 신경망 모델을 제 3 학습시킬 수 있다.프로세서는 복수의 학습률의 최대값 보다 작은 학습률에 기초하여 미리 결정된 에포크(epoch) 이하의 에 포크로 제 2 학습된 신경망 모델을 제 3 학습시킬 수 있다. 메모리 장치는 신경망 모델 혹은 신경망 모델의 파라미터를 저장할 수 있다. 메모리 장치는 프로세 서에 의해 실행가능한 인스트럭션들(혹은 프로그램)을 저장할 수 있다. 예를 들어, 인스트럭션들은 프로세서의 동작 및/혹은 프로세서의 각 구성의 동작을 실행하기 위한 인스트럭션들을 포함할 수 있다. 실시 예에 있어서, 메모리 장치는 휘발성 메모리 장치 혹은 비휘발성 메모리 장치로 구현될 수 있다. 한편, 본 발명은 텐서(tensor) 연산을 수행하는 연산 장치에 적용 가능하다. 일반적으로 텐서는 다차원 배열로 써, 텐서 연산은 텐서들 사이의 연산을 의미한다. 딥러닝에서는 요소별 연산(element-wise operations), 행렬 곱(matrix multiplication), 텐서 모양 변경(reshaping), 축 기준 연산(reduction along an axis), 텐서 합치 기 및 분리하기(concatenation & splitting) 등 같은 텐서 연산들이 수행되고 있다. 이러한 텐서 연산들 중에서 혼합 정밀도 트레이닝 동작이 수행될 수 있다. 도 10은 본 발명의 실시 예에 따른 연산 장치를 예시적으로 보여주는 도면이다. 도 10을 참조하면, 연산 장치는 텐서 코어, 벡터 코어, 로컬 버퍼, 온-칩 메모리 장치 및 제어 장치 를 포함할 수 있다. 텐서 코어는 텐서 연산을 수행하는 가산기 트리 기반의 인공 신경망 가속기일 수 있다. 벡터 코어 는 벡터 연산을 수행하는 MAC 기반의 코프로세서일 수 있다. 연산 장치는 가산기 트리 기반의 인공신경망 가속기에 MAC 기반의 코프로세서(co-processor)로 구성되어, 가산기 트리 기반의 인공신경망 가속기에서 텐서 연산을 수행하고 MAC 기반의 코프로세서에서 벡터 연산을 효율적으로 수행할 수 있다. 연산 장치는 텐서 연산의 출력을 입력으로 사용하는 벡터 연산이 있을 때, 텐서 연산의 출력을 온-칩 메모리 장치에 라이트 -백(write-back) 한 뒤 벡터 연산을 수행하는 것이 아니라, 텐서 연산의 출력을 벡터 연산의 입력으로 사용하여 온-칩 메모리 장치에서 라이트-백 하지 않고 벡터 연산을 수행할 수 있다. 이를 통해, 연산 장치는 벡터 연산의 메모리 대역폭 요구 사항(memory bandwidth requirement)를 줄이고 계산 자원 이용 효율 (computation resource utilization)을 향상시킬 수 있다. 또한, 온-칩 메모리 장치는 텐서 연산 동작 중에 도 1 내지 도 8에서 설명된 바와 같이 혼합 정밀도 트레 이닝을 수행하도록 구현될 수 있다. 이때 텐서 연산에서 대부분의 연산은 제 2 정밀도(예를 들어, float32)로 수행하지만, 일부 연산은 제 1 정밀도(float16)로 수행할 수 있다. 실시 예에 있어서, 중요한 연산(예를 들어, 가중치 연산)은 32-비트 정밀도로 수행되지만, 나머지 연산들은 16-비트 정밀도로 수행될 수 있다. 연산 장치는 데이터 재사용을 위해 로컬 버퍼를 포함할 수 있다. 데이터 재사용의 의미는 로딩된 데이터(예를 들어, 가중치 혹은 입력 특징맵)을 반복적으로 사용하여 연산을 수행하는 것을 의미하고, 데이터 재사용을 통해 데이터 로드 횟수와 연산 횟수를 줄일 수 있다. 한편, 본 발명은 전자 장치에 적용 가능하다. 도 11은 본 발명의 실시 예에 따른 전자 장치를 예시적으로 보여주는 도면이다. 도 11를 참조하면, 전자 장치는 프로세서, 메모리 장치, 카메라 장치, 저장 장치, 입력 장치, 출 력 장치 및 통신 인터페이스 장치를 포함할 수 있다. 프로세서, 메모리 장치, 카메라 장치, 저장 장치, 입력 장치, 출력 장치 및 통신 인터페이스 장치은 시스템 버 스를 통해 서로 통신할 수 있다. 예를 들어, 전자 장치는 이동 전화, 스마트 폰, PDA, 넷북, 태블 릿 컴퓨터, 랩톱 컴퓨터 등과 같은 모바일 장치, 스마트 워치, 스마트 밴드, 스마트 안경 등과 같은 웨어러블 디바이스, 데스크탑, 서버 등과 같은 컴퓨팅 장치, 텔레비전, 스마트 텔레비전, 냉장고 등과 같은 가전 제품, 도어 락 등과 같은 보안 장치, 자율주행 차량, 스마트 차량 등과 같은 차량의 적어도 일부로 구현될 수 있다. 프로세서는 전자 장치 내에서 실행하기 위한 기능 및 명령어들을 실행한다. 예를 들어, 프로세서 는 메모리 장치 혹은 저장 장치에 저장된 명령어들을 처리할 수 있다. 메모리 장치는 영상 처리를 위한 데이터를 저장한다. 메모리 장치는 컴퓨터 판독가능한 저장 매체 혹은 컴퓨터 판독가능한 저장 장치를 포함할 수 있다. 메모리 장치는 프로세서에 의해 실행하기 위 한 명령어들을 저장할 수 있고, 전자 장치에 의해 소프트웨어 및/혹은 애플리케이션이 실행되는 동안 관 련 정보를 저장할 수 있다. 또한, 메모리 장치는 도 1 내지 도 8에서 설명된 바와 같이 메모리 내에서 혼 합 정밀도 트레이닝을 수행하도록 구현될 수 있다.카메라 장치는 사진 및/혹은 비디오를 촬영할 수 있다. 예를 들어, 카메라 장치는 사용자의 얼굴을 포함하는 얼굴 영상을 촬영할 수 있다. 카메라 장치는 객체들에 관한 깊이 정보를 포함하는 3D 카메라일 수 있다. 저장 장치는 컴퓨터 판독가능한 저장 매체 혹은 컴퓨터 판독가능한 저장 장치를 포함한다. 저장 장치는 메모리 장치보다 더 많은 양의 정보를 저장하고, 정보를 장기간 저장할 수 있다. 예를 들어, 저장 장치는 자기 하드 디스크, 광 디스크, 플래쉬 메모리, 플로피 디스크 혹은 이 기술 분야에서 알려진 다른 형태의 비휘발성 메모리를 포함할 수 있다. 입력 장치는 키보드 및 마우스를 통한 전통적인 입력 방식, 및 터치 입력, 음성 입력, 및 이미지 입력과 같은 새로운 입력 방식을 통해 사용자로부터 입력을 수신할 수 있다. 예를 들어, 입력 장치는 키보드, 마 우스, 터치 스크린, 마이크로폰, 혹은 사용자로부터 입력을 검출하고, 검출된 입력을 전자 장치에 전달할 수 있는 임의의 다른 장치를 포함할 수 있다. 출력 장치는 시각적, 청각적 혹은 촉각적인 채널을 통해 사 용자에게 전자 장치의 출력을 제공할 수 있다. 출력 장치는 예를 들어, 디스플레이, 터치 스크린, 스피커, 진동 발생 장치 혹은 사용자에게 출력을 제공할 수 있는 임의의 다른 장치를 포함할 수 있다. 통신 인 터페이스 장치는 유선 혹은 무선 네트워크를 통해 외부 장치와 통신할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/혹은 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시 예에서 설명된 장치 및 구성요소는, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 혹은 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 혹은 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접 근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명"}
{"patent_id": "10-2023-0118101", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 혹은 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로 세서 혹은 하나의 프로세서 및 하나의 제어기를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 혹은 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 혹은 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/혹은 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 혹은 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상장 치(virtual equipment), 컴퓨터 저장 매체 혹은 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연 결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 본 발명은 시스템이 AI 향 Mixed-precision Training을 수행할 때, 메모리 내에서 Precision 변환을 지원함. 이로써, 메모리의 Effective Bandwidth가 향상될 수 있다. 종래 기술은 시스템이 주도하여 Precision 변환하여 Mixed-precision Training 수행한다. 본 발명은 메모리 내부에서 In/Out-data의 Precision을 변환해 줌으로써, 불필요한 Neural Network 데이터 복제 과정을 삭제할 수 있다. 또한, 본 발명은 Processor-Memory 간 교환되는 데이터의 Precision 감소로 인해 메모리의 Effective BW 증가시킬 수 있다. 본 발명의 메모리/모듈 내에서 Data Precision Mi이 수행될 수 있다. 본 발명의 메모리 장치는 메모리 cell array 영역의 구분 결과를 시스템에 알 릴 수 있다. 본 발명의 메모리 장치는 Input data를 data class에 따라 구분하여 메모리에 저장할 수 있다. 본 발명의 메모리 장치는 Output data를 data class에 따라 구분하여 PIM(rounding logic)/ PNM(Processing Near Memory)이 구현된 메모리 모듈 등을 통해 시스템에 전송할 수 있다. 본 발명의 메모리 장치는 Training 중 메모 리 내에서 weight update 할 수 있다. 본 발명의 메모리 장치는 메모리 내, weight 및 gradient data 간 addition with scaling 수행할 수 있다. 본 발명은 PIM/ PNM(Processing Near Memory)이 구현된 메모리 모듈 등의 rounding을 활용해 updated weight를 precision 변환 후 시스템에 전송할 수 있다."}
{"patent_id": "10-2023-0118101", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "한편, 상술된 본 발명의 내용은 발명을 실시하기 위한 구체적인 실시 예들에 불과하다. 본 발명은 구체적이고 실제로 이용할 수 있는 수단 자체뿐 아니라, 장차 기술로 활용할 수 있는 추상적이고 개념적인 아이디어인 기술 적 사상을 포함 할 것이다. 부호의 설명10: 메모리 시스템 100: 메모리 장치 200: 프로세서 111: 제 1 셀 어레이 112: 제 2 셀 어레이 113: 제 3 셀 어레이 120: 연산 회로 130: 스케일링 회로"}
{"patent_id": "10-2023-0118101", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이하에 첨부되는 도면들은 본 실시 예에 관한 이해를 돕기 위한 것으로, 상세한 설명과 함께 실시 예들을 제공 한다. 도 1은 일반적인 혼합 정밀도 트레이닝을 보여주는 도면이다. 도 2는 일반적인 혼합 정밀도 트레이닝의 동작을 개념적으로 설명하는 도면이다. 도 3은 일반적인 혼합 정밀도 트레이닝의 손실 스케일링을 개념적으로 보여주는 도면이다. 도 4는 본 발명의 실시 예에 따른 메모리 시스템을 예시적으로 보여주는 도면이다. 도 5는 본 발명의 실시 예에 따른 인-메모리 플로팅 포인트 정밀도 변환을 예시적으로 보여주는 도면이다 도 6은 본 발명의 실시 예에 따른 메모리 장치에서 가중치 업데이트를 예시적으로 보여주는 도면이다. 도 7은 본 발명의 다른 실시 예에 따른 메모리 시스템을 예시적으로 보여주는 도면이다. 도 8은 본 발명의 실시 예에 따른 메모리/모듈의 혼합 정밀도 트레이닝 동작을 예시적으로 보여주는 흐름도이다. 도 9는 본 발명의 실시 예에 따른 신경망 학습 장치를 예시적으로 보여주는 도면이다. 도 10은 본 발명의 실시 예에 따른 연산 장치를 예시적으로 보여주는 도면이다. 도 11은 본 발명의 실시 예에 따른 전자 장치를 예시적으로 보여주는 도면이다."}
