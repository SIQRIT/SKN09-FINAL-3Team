{"patent_id": "10-2021-0162548", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0075898", "출원번호": "10-2021-0162548", "발명의 명칭": "다중플랫폼 및 다중센서 융합에 의한 데이터 수집 방법", "출원인": "주식회사 카카오모빌리티", "발명자": "홍승환"}}
{"patent_id": "10-2021-0162548", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "다중 플랫폼 및 다중센서 융합에 의한 데이터 수집 방법에 있어서, 다중 플랫폼 별로 탑재된 다중 센서의 센서 데이터 및 시공간 동기화 정보를 수신하는 단계; 상기 센서 데이터를 시간 동기화하는 단계;상기 시간 동기화된 센서 데이터를 공간 동기화하는 단계; 상기 공간 동기화된 데이터를 지도 좌표계로 동기화하는 단계; 및상기 동기화된 데이터들 간의 연계 관계 정보를 정의하는 단계를 포함하는, 데이터 수집 방법."}
{"patent_id": "10-2021-0162548", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 다중 플랫폼은 이동형 플랫폼 및 고정형 플랫폼을 포함하는, 데이터 수집 방법."}
{"patent_id": "10-2021-0162548", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 상기 이동형 플랫폼의 센서 데이터는 관측 센서 데이터 및 항법 센서 데이터를 포함하고, 상기 고정형 플랫폼의센서 데이터는 관측 센서 데이터를 포함하는, 데이터 수집 방법."}
{"patent_id": "10-2021-0162548", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 센서 데이터를 시간 동기화하는 단계는, 기준 시스템에 기초하여, 상기 다중 센서의 시계 모듈의 시간을 동기화하는 단계; 상기 다중 센서들의 시간의 프레임 동기화를 수행하고, 동일 시간에 수집된 센서 데이터들의 연관 관계를 결정하는 단계; 및다중센서 시스템 기하 모델을 기준으로 시간 정보 기반 동기화 데이터를 공간 동기화를 수행하는 단계를 포함하는, 데이터 수집 방법."}
{"patent_id": "10-2021-0162548", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 상기 다중 센서의 시계 모듈의 시간을 동기화하는 단계 후에, 상기 센서 데이터의 시간계가 통일된지 여부를 확인하는 단계; 및 확인 결과 통일되지 않는 경우, 상기 통일되지 않는 센서 데이터를 동일 시간계로 변환하는 단계를 더포함하는, 데이터 수집 방법.공개특허 10-2023-0075898-3-"}
{"patent_id": "10-2021-0162548", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4 항에 있어서,상기 공간 동기화를 수행하는 단계 후에, 상기 공간 동기화된 데이터에 대해 오차 여부를 확인하는 단계; 및 확인 결과 오차가 발생한 경우, 시간 및 공간 동기화의 편위 값(offset)을 상기 공간 동기화된 데이터에 적용하는 단계를 더 포함하는, 데이터 수집 방법."}
{"patent_id": "10-2021-0162548", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서, 상기 시간 동기화된 센서 데이터를 공간 동기화하는 단계는, 상기 센서 데이터와 관련된 내부 정보 및 외부 정보를 변환하는 단계;상기 항법 정보에 대한 상기 센서 데이터를 변환하는 단계; 및 상기 변환된 내부 정보, 외부 정보 및 상기 항법 정보에 의해 변환된 센서 데이터에 기초하여, 다중 센서의 데이터를 동기화하는 단계를 포함하는, 데이터 수집 방법."}
{"patent_id": "10-2021-0162548", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서, 상기 내부 정보 및 외부 정보를 변환하는 단계, 상기 항법 정보에 대한 상기 센서 데이터를 변환하는 단계, 및상기 다중 센서의 데이터를 동기화하는 단계 중 적어도 하나의 단계 후에, 상기 변환된 정보 또는 상기 동기화된 다중 센서의 데이터와 관련된 센서 데이터의 동기화 오차가 있는지를 확인하는 단계; 및 상기 동기화 오차가 있는 경우, 동기화 오차의 원인을 분석하여, 분석 결과에 따라 상기 내부 정보, 상기 외부정보 및 상기 항법 정보 중 적어도 하나를 보정하는 단계를 더 포함하는, 데이터 수집 방법."}
{"patent_id": "10-2021-0162548", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다중 플랫폼 및 다중센서 융합에 의한 데이터 수집 방법이 개시된다. 상기 방법은, 다중 플랫폼 별로 탑재된 다중 센서의 센서 데이터 및 시공간 동기화 정보를 수신하는 단계; 상기 센서 데이터를 시간 동기화하는 단계; 상기 시간 동기화된 센서 데이터를 공간 동기화하는 단계; 상기 공간 동기 화된 데이터를 지도 좌표계로 동기화하는 단계; 및 상기 동기화된 데이터들 간의 연계 관계 정보를 정의하는 단 계를 포함한다."}
{"patent_id": "10-2021-0162548", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 다중플랫폼 및 다중센서 융합에 의한 데이터 수집 방법에 관한 것이며, 보다 구체적으로 센서들 및 플랫폼 간의 센서 및 추출 정보들을 하나의 연결된 시스템으로 연결하여 운영가능한 다중플랫폼 및 다중센서 융 합에 의한 데이터 수집 방법에 대한 것이다."}
{"patent_id": "10-2021-0162548", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자율주행 차량, 로봇, 드론 등에 라이다, 레이더, 카메라, 항법센서들이 다양하게 적용되고 있으며, 특히 단일 센서가 아닌 다중센서의 센서 융합 (sensor fusion) 형태로 시스템 플랫폼들이 운영되고 있다. 또한, 종래의 기 술들은 단독 주행, 단독 운영 시스템의 형태로 운영되어 그 인지범위에 한계가 있었으나, 최근에는 다중 플랫폼 들이 서로 연결되어 연계 작동하는 방식으로 운영하는 것을 목표로 하여, 시스템들이 설계되고 있다. 이러한 다중 플랫폼, 다중 센서들이 연계 운영됨에 따라 이를 작동시키고 관제하기 위한 데이터의 수집 관리가 중요해지고 있는 상황이다. 종래의 단독 센서, 단독 운영의 방식에서는 각 시스템들이 독립적으로 데이터를 수 집하고 처리하여 센서 데이터 간의 융합 활용이 프로세스 상에 중요한 역할을 발휘하지 않았다. 융합센서, 융합플랫폼 데이터 처리에 있어서는 각 센서들의 시간, 공간 동기화 정보들이 정밀하게 정의되어 있어야 하며 각 정보 사의 연결 정보들이 상세히 정의되어 연결될 필요가 있다. 그러나, 종래의 기술들과 데이터셋들은 연결관 계를 정의하지 못하고 있으며, 이에 따라 스마트시티, 고도의 자율주행, 배송로봇 시스템 구현에 따른 실제 운 영이 곤란한 상황이다."}
{"patent_id": "10-2021-0162548", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 기술적 과제는 센서들 및 플랫폼 간의 센서 및 추출 정보들을 하나의 연결된 시스템으로 연결하여 운 영가능한 다중플랫폼 및 다중센서 융합에 의한 데이터 수집 방법을 제공하는데 그 목적이 있다. 본 개시의 기술적 과제는 더 나아가, 인공지능 및 시뮬레이션 모델 개발에 수반되는 기술 한계를 극복하는 다중 플랫폼 및 다중센서 융합에 의한 데이터 수집 방법을 제공하는데 목적이 을 제공하는데 그 목적이 있다. 본 개시에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2021-0162548", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0162548", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 양상에 따르면, 다중플랫폼 및 다중센서 융합에 의한 데이터 수집 방법은, 다중 플랫폼 별로 탑재 된 다중 센서의 센서 데이터 및 시공간 동기화 정보를 수신하는 단계; 상기 센서 데이터를 시간 동기화하는 단 계; 상기 시간 동기화된 센서 데이터를 공간 동기화하는 단계; 상기 공간 동기화된 데이터를 지도 좌표계로 동 기화하는 단계; 및 상기 동기화된 데이터들 간의 연계 관계 정보를 정의하는 단계를 포함한다."}
{"patent_id": "10-2021-0162548", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 개시에 대하여 위에서 간략하게 요약된 특징들은 후술하는 본 개시의 상세한 설명의 예시적인 양상일 뿐이 며, 본 개시의 범위를 제한하는 것은 아니다."}
{"patent_id": "10-2021-0162548", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 센서들 및 플랫폼 간의 센서 및 추출 정보들을 하나의 연결된 시스템으로 연결하여 운영가능 한 다중플랫폼 및 다중센서 융합에 의한 데이터 수집 방법을 제공할 수 있다. 본 개시에 따르면, 다중센서, 다중플랫폼에서 수집데이터들을 시간, 공간, 속성 등의 관점에서 동기화시켜 통합 데이터로 활용함으로써, 단독 플랫폼에서의 시스템 인지 및 판단 모델의 한계를 극복할 수 있다. 본 개시에 따르면, 센서, 플랫폼들은 각각의 하드웨어, 소프트웨어, 데이터 시스템으로 작동하며, 데이터들을 하나의 시스템으로 활용하기 위해, 각 요소들 간에 연결 정보들이 수식, 데이터 구조, 프로세스, 모델 등의 형 태로 연결될 수 있다. 본 개시에 따르면, 다중플랫폼의 연계에 있어서, 각 데이터들이 하나의 공통된 좌표계로 변환 및 매핑 과정을 통해 통합되어 연계될 수 있으며, 공통된 좌표계 내지 지도 좌표계 내의 데이터는 시공간 정보 분석을 통해 데 이터 간의 연계 관계가 정의되어 분석될 수 있다. 본 개시에 따르면, 다중 센서, 다중 플랫폼의 데이터들이 연계되어 운용될 수 있는 비행장치, 로봇 등의 이동형 플랫폼 또는 고정형 관제 플랫폼 상에 탑재되는 플랫폼 엣지 간의 연계된 시스템으로 3-tier (차량-클라우드-인 프라) 자율주행 서비스, 라스트마일(last mile) 로봇 서비스, 드론(drone) 서비스 등을 지원하며, 다중 센서, 다중 플랫폼이 운영되는 지상/항공/우주 센싱 시스템으로 확장 적용될 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0162548", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참고로 하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나, 본 개시는 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시의 실시 예를 설명함에 있어서 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그에 대한 상세한 설명은 생략한다. 그리고, 도면에서 본 개시에 대한 설명과 관계없 는 부분은 생략하였으며, 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시에 있어서, 어떤 구성요소가 다른 구성요소와 \"연결\", \"결합\" 또는 \"접속\"되어 있다고 할 때, 이는 직접 적인 연결 관계 뿐만 아니라, 그 중간에 또 다른 구성요소가 존재하는 간접적인 연결관계도 포함할 수 있다. 또 한 어떤 구성요소가 다른 구성요소를 \"포함한다\" 또는 \"가진다\"고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 배제하는 것이 아니라 또 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 개시에 있어서, 제 1, 제 2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용 되며, 특별히 언급되지 않는 한 구성요소들 간의 순서 또는 중요도 등을 한정하지 않는다. 따라서, 본 개시의 범위 내에서 일 실시 예에서의 제 1 구성요소는 다른 실시 예에서 제 2 구성요소라고 칭할 수도 있고, 마찬가지 로 일 실시 예에서의 제 2 구성요소를 다른 실시 예에서 제 1 구성요소라고 칭할 수도 있다. 본 개시에 있어서, 서로 구별되는 구성요소들은 각각의 특징을 명확하게 설명하기 위함이며, 구성요소들이 반드 시 분리되는 것을 의미하지는 않는다. 즉, 복수의 구성요소가 통합되어 하나의 하드웨어 또는 소프트웨어 단위 로 이루어질 수도 있고, 하나의 구성요소가 분산되어 복수의 하드웨어 또는 소프트웨어 단위로 이루어질 수도 있다. 따라서, 별도로 언급하지 않더라도 이와 같이 통합된 또는 분산된 실시 예도 본 개시의 범위에 포함된다. 본 개시에 있어서, 다양한 실시 예에서 설명하는 구성요소들이 반드시 필수적인 구성요소들은 의미하는 것은 아 니며, 일부는 선택적인 구성요소일 수 있다. 따라서, 일 실시 예에서 설명하는 구성요소들의 부분집합으로 구성 되는 실시 예도 본 개시의 범위에 포함된다. 또한, 다양한 실시예에서 설명하는 구성요소들에 추가적으로 다른 구성요소를 포함하는 실시 예도 본 개시의 범위에 포함된다. 이하, 첨부한 도면을 참조하여 본 개시의 실시 예들에 대해서 설명한다. 도 1은 이동체가 네트워크를 통해 다른 장치와 통신을 수행하는 것을 나타낸 도면이다. 도 1을 참조하면, 이동체는 다른 이동체 또는 다른 디바이스와 통신을 수행할 수 있다. 이때, 일 예로, 이동체 는 셀룰라 통신, WAVE 통신, DSRC(Dedicated Short Range Communication) 또는 그 밖에 다른 통신 방식에 기초 하여 다른 이동체 또는 다른 디바이스와 통신을 수행할 수 있다. 즉, 셀룰러 통신망으로서 LTE, 5G와 같은 통신 망, WiFi 통신망, WAVE 통신망 등이 이용될 수 있다. 또한, DSRC와 같이 이동체에서 사용되는 근거리 통신망 등 이 사용될 수 있으며, 상술한 실시예로 한정되지 않는다. 또한, 일 예로, 이동체의 통신과 관련하여, 이동체 보안을 위해 이동체 내부에 위치하는 디바이스만 통신을 수 행할 수 있는 모듈과 이동체 외부 디바이스와 통신을 수행할 수 있는 모듈이 분리되어 존재할 수 있다. 일 예로, 이동체 내부에서는 와이파이 통신처럼 이동체 내의 일정 범위 내의 디바이스에 대해서만 보안에 기초하여 통신을 수행할 수 있다. 일 예로, 이동체와 이동체 운전자의 개인 소유 디바이스는 상호 간의 통신만을 수행하 기 위한 통신 모듈을 포함할 수 있다. 즉, 이동체와 이동체 운전자의 개인 디바이스는 외부 통신망과 차단된 통 신망을 이용할 수 있다. 또한, 일 예로, 이동체는 외부 디바이스와 통신을 수행하는 통신 모듈을 포함할 수 있 다. 또한, 일 예로, 상술한 모듈은 하나의 모듈로 구현될 수 있다. 즉, 하나의 모듈에 기초하여 이동체는 다른 디바이스와 통신을 수행할 수 있으며, 상술한 실시예로 한정되지 않는다. 즉, 이동체에서 통신 방법은 다양한 방법에 기초하여 구현될 수 있으며, 상술한 실시예로 한정되지 않는다. 이때, 이동체는 예를 들어, 이동할 수 있는 디바이스를 지칭할 수 있다. 일 예로, 이동체는 차량 (Autonomous Vehicle, Automated Vehicle 포함), 드론, 개인 모빌리티, 이동 오피스, 이동 호텔 또는 PAV(Personal Air Vehicle) 일 수 있다. 개인 모빌리티는 예컨대 안정적인 독립주행을 위해 적어도 3개의 휠을 포함하는 이동체, 또는 1개 또는 2개의 휠을 구비하더라도 균형을 유지하여 독립적으로 주행될 수 있는 이동체(예, 싱글 휠 세그 웨이, 투 휠 세그웨이, 전동 킥보드 등)를 포함할 수 있다. 개인 모빌리티는 동력원으로 배터리를 이용한 전기 를 사용할 수 있으나, 이에 제한되지 않고 모빌리티를 이동시킬 수 있는 어떠한 형태의 동력원을 활용할 수 있 다. 일 예로, 개인 모빌리티는 한 명의 사용자만이 탑승 또는 이용할 수 있는 이동 수단을 의미할 수 있다. 또 한, 개인 모빌리티는 소형 이동 수단으로 소수의 사용자가 이용할 수 있는 이동 수단을 의미할 수 있다. 일 예 로, 싱글 휠, 투 휠, 세그웨이류 및 전동 킥보드뿐만 아니라 전동 휠체어, 전기 자전거 및 전기 이륜차도 개인 모빌리티가 될 수 있다. 또한, 이동체는 그 밖에 다른 이동하는 장치일 수 있으며, 상술한 실시예로 한정되지 않는다. 또한, 이동체와 데이터 교환 및 통신하는 개체는 외부 디바이스로서, 서버, 사용자 디바이스, 지능형 교통 정보 를 제공하는 다양한 ITS 디바이스 및 다른 이동체 중 적어도 하나일 수 있다. 서버는 지도 정보, 공간 정보 및 기준 데이터를 저장하여 관리하고, 이동체 등의 요청에 따라 이들을 제공하는 기준 시스템의 서버일 수 있다. 사용자 디바이스는 스마트폰, 스마트패드, 스마트 워치 등일 수 있다. 또 다른 일 예로, 디바이스는 기타 통신 이 가능하여 신호를 교환할 수 있는 장치를 의미할 수 있으며, 상술한 실시예로 한정되지 않는다. ITS 디바이스 는 예를 들어 RSU(Road Side Unit)일 수 있다. RSU는 도로 주변 장치로서 통신이 가능한 장치일 수 있다. 또한, 일 예로, RSU는 건물이나 기타 지역에 신호를 송수신할 수 있도록 설치된 구조물을 지칭할 수 있으며, 상술한 실시예로 한정되지 않는다. 다만, 하기에서는 설명의 편의를 위해 RSU로 통칭하며, 이에 대해서는 다양한 구조 물이나 장치일 수 있으며, 상술한 실시예로 한정되지 않는다. 도 2는 상호 통신하는 이동체 및 서버의 개략적인 모듈을 나타내는 구성도이다. 이동체는 주변 환경을 감지하는 다중 센서, 통신부, 입력부, 디스플레이부, 메모리, 이동체의 운행 제어를 실행하는 구동부및 프로세서를 포함할 수 있다. 다중 센서는 관측 센서, 항법 센서, 주행 센서를 구비할 수 있다. 관측 센서는 카메라, 라 이다, 레이더 센서 등을 포함하여 주변 환경을 관측하는 센서들로 구성될 수 있다. 항법 센서는 이동체 의 위치, 방향 정보를 수집할 수 있는 GNSS, IMU 센서, 항법 센서 등을 포함할 수 있다. 주행 센서는 운행 중에 작동되는 이동체의 구동, 조향, 제동 등의 발생 및 동작 정도를 검출하는 다양한 센서를 포함할 수 있다. 주행 센서는 이동체의 동작 과정에서의 주행 상태와 주행 제어 상태를 감지하고, 프로세서 는 감지된 상태 정보에 기반하여, 운행 제어 데이터를 구성하는 다양한 정보를 생성할 수 있다. 카메라 센서는 이동 중인 지상 또는 공중 플랫폼에 탑재되어 그 주위의 주변 대상물, 예컨대 지형, 지물을 이미 지로 촬영하여 영상용 관측 데이터를 취득하는 센서이며, 측량용 또는 비측량용 카메라, 스테레오 카메라일 있 으며, 이에 제한되지 않는다. 라이다 센서(Light Detection and Ranging; LiDAR)는 플랫폼에 탑재되어 그 주위의 대상물과 관련된 3차원 지 리 데이터, 예컨대 지형, 지물 관련 데이터를 획득하여 3차원 측량용 관측 데이터를 취득하는 센서로서, 능동형 원격 탐사용 센서이다. 예를 들어, 라이다 센서는 레이저 또는 초음파 센서 등일 수 있다. 이러한 라이다 센서 는 데이터를 취득하고자 하는 대상물에 레이저를 주사하며 대상물로부터 반사되어 복귀하는 전자파의 시차와 에 너지 변화를 감지하여 대상물에 대한 거리와 반사 강도를 산출한다. 항법 센서는 측위 정보, 플랫폼의 위치, 자세 및 속도 등의 항법 정보를 검출하여 항법용 관측 데이터를 취득하는 센서로서, 위성 항법 장치(GPS)를 통해 플랫폼의 이동 위치를 취득하는 위치 취득 장치와 관성 측정 장치(Inertial Measurement Unit; IMU), 관성 항법 장치(Inertial Navigation System; INS)를 통해 차량의 자 세를 취득하는 자세 취득 장치 등으로 구성될 수 있다. 대 지형, 지물을 이미지로 촬영하여 영상용 관측 데이터 를 취득하는 센서이며, 측량용 또는 비측량용 카메라, 스테레오 카메라일 있으며, 이에 제한되지 않는다. 동일 플랫폼인 이동체의 센서들 간의 기하 정보는 이동체의 주행 중에 취득된 센서 데이터 및 센서에 내재된 고유 정보에 기반하여 도출되는 내부 기하 정보 및 외부 기하 정보를 포함할 수 있다. 각 센서들은 상술 한 정보뿐만 아니라 다른 정보들을 포함할 수 있으며, 각 센서마다 구체적 정보를 예를 들어 설명하면 이하와 같이 열거될 수 있다. 예컨대, 카메라 센서의 경우, 카메라 센서 관련 정보는 IOP (내부기하). EOP (외부기하), 촬영날짜, 촬영시간, 조도, ISO, 셔터스피드, 영상 이름, 폴더 이름, 시간 동기화 정보, 센서 시리얼번호, 렌즈 모델, 센서 모델 등 을 포함할 수 있다. 라이다 센서 관련 정보는 내부 기하정보, 외부 기하정보, 시간 동기화 정보, 레이저 파장, 레이저 강도, 레이저 송수신 시간, 레이저 관측 각/거리, 레이저 펄스, 전자적 지연 시간, 대기 지연 시간, 센서 온도 등을 포함할 수 있다. 항법 센서 관련 정보는 GNSS 센서 모델 정보, IMU 센서 모델 정보, GNSS 수신 정보, GNSS 수신 위성 개수, GNSS 위성 신호 강도, GNSS 네비게이션 정보, 전리층/대류층 신호지연 정보, DOP 정보, 지구자전 관련 정보, 이중/다 중 GNSS 장비 정보, Base station 정보, SBAS 정보, 좌표계 정보, 타원체 정보, 지오이드 정보 등을 포함할 수 있다. 이에 더하여, 항법 센서 관련 정보는 Wheel센서 회전/이동 정보, 자이로 센서 Scale/Bias 정보, 가속도계 Scale/Bias 정보, 위치/자세 정보 및 예상 오차량, 속도/가속도 정보 및 예상 오차량, 각속도/각가속도 정보 및 예상 오차량, 필터링 모델 및 소거 오차 정보, 플랫폼과의 기하 관계 정보, 센서 간 기하 관계 정보, 시간 동기 화 정보 등을 포함할 수 있다. 운행 제어 데이터는 상술한 관측 및 측위 센서 데이터 뿐만 아니라, 이하의 다양한 정보를 추가로 포함할 수 있 다. 주변 정보는 이동체의 카메라, 이동체 주변의 외부 디바이스 또는 서버로부터 수신된 이동체 주변의 객체와 관련된 위치, 종류, 모션, 형상 등에 관한 데이터로 구성될 수 있다. 객체는 정적 객체 혹은 동적 객체 일 수 있다. 정적 객체는 고정 시설물과 같이 이동성을 수반하지 않는 객체일 수 있다. 동적 객체는 사람, 다 른 이동체, 동물과 같이 이동성이 있는 객체일 수 있다. 이벤트 정보는 이동체의 주변 혹은 예상 경로에서 발생된 다양한 상황 정보일 수 있다. 이벤트 정보는 예 컨대, 교통 상황, 사고 상황, 공사 상황, 국지적 기상 상황과 관련된 정보일 수 있다. 지도 정보는 기준 시스템의 데이터베이스에 기록될 수 있으며, 도로, 도로 주변의 시설물, 차선 정보 등의 다양한 데이터를 2차원 또는 3차원적으로 표현될 수 있다. 공간 정보는 기준 시스템의 데이터베이스에 기 록될 수 있으며, 지도 정보와 연관된 3차원 공간 상에 시점 별로 구조화될 수 있다. 구체적으로, 공간 정보는 지도 상의 객체의 이력 정보를 시점 별로 구조화하여 저장할 수 있으며, 차선 단위 또는 cm 단위의 고정밀도로 객체 정보를 기록할 수 있다. 주행 패턴 정보는 사용자의 이동체 운전 및 사용 패턴, 알고리즘에서 제시한 이동체 경로 및 운행 제어와 관련 된 옵션의 선택 패턴, 특정 동승자의 탑승한 경우의 이동체 사용 패턴 등과 관련된 정보일 수 있다. 주행 패턴 정보는 프로세서가 사용자가 이동체의 입력부 또는 터치 수신가능한 디스플레이부를 통해 선택한 옵션 유형을 분석하여 추정될 수 있다. 또한, 주행 패턴 정보는 사용자 디바이스 또는 이동체로부 터 입력받은 특정 동승자가 탑승한 경우, 사용자가 이용하는 경로, 운전 패턴을 포함하는 주행 패턴을 포함할 수 있다. 또한, 주행 패턴 정보는 이벤트 정보, 기상 정보와 연관되어 사용자가 이용하는 운전 패턴, 경로를 포함할 수 있다. 통신부는 기준 시스템(200; 이하, 기준 시스템 및 서버는 혼용하여 기재), ITS 디바이스, 다른 이동체와 통신하여, 이동체의 다중 센서로부터 획득되지 않는 운행 제어 데이터를 수신할 수 있다. 서버 또는 외부 디바이스로부터 획득되는 운행 제어 데이터는 이벤트 정보, 경로 속성 정보, 지도 정보, 공간 정보, 기상 정보 등일 수 있다. 입력부 및 디스플레이부는 사용자의 경로 안내 요구를 수신하는 인터페이스를 제공하며, 경로 및 운 행 제어와 관련된 상태 및 경로를 디스플레이할 수 있다. 본 도면에서는 입력부 및 디스플레이부를 별개 모듈로 도시하고 있으나, 터치 입력이 가능한 디스플레이부는 입력부를 포함할 수 있다. 메모리는 운행 제어 데이터를 저장하거나, 외부 호출에 의해 상기 데이터를 제공할 수 있다. 구동부는 프로세서의 제어에 의해, 이동체의 기계적 동작을 실행할 수 있다. 구동부는 전 륜 및 후륜에 동력을 전달하는 동력 계통, 제동 계통, 스티어링에 따른 이동체의 방향을 전달하는 조향 계 통 등일 수 있다. 서버는 이동체를 포함하는 복수의 이동형 플랫폼 및 RSU, 소정 위치에 설치된 에지 디바이스를 포함 하는 고정형 플랫폼과 통신하면서, 다중 플랫폼 및 다중 센서의 데이터를 융합하기 위한 소트웨어 내지 애플리 케이션을 구동하고, 융합에 필요한 지도 및 공간 정보를 저장하여 활용할 수 있다. 서버를 포함하는 기준 시스템 관련 시간 정보, 기하 정보, 공간 정보, 기준 시간계 정보, 기준 좌표계 정 보, 시계 오차 정보, 기하 오차 정보. 캘리브레이션 정보 등을 포함할 수 있다. 본 실시예에서, 이동체과 같은 이동형 플랫폼을 위주로 설명하였으나, 고정형 플랫폼은 구동부을 제 외한 다른 모듈을 포함할 수 있으며, 지도 및 공간 정보에서 고정형 플랫폼의 측위 정보를 보유하는 경우, 항법 센서가 생략될 수도 있다. 도 3은 본 개시에 따른 다중플랫폼 및 다중센서 융합에 의한 데이터 수집 방법에 관한 순서도이다. 이하에서는 이동형 및 고정형 플랫폼에 탑재된 다중 센서의 데이터에 대한 융합을 설명하면서, 센서 데이터가 이동형 및 고 정형 플랫폼의 데이터임을 명시적으로 기재하지 않더라도, 각 플랫폼의 센서 데이터임을 의미할 수 있다. 본 개 시에 따른 방법은 데이터 활용에 있어 필요시 시공간 오차를 확인하고 시스템 캘리브레이션을 통해 시간, 공간 동기화 정보가 갱신될 수 있다. 먼저, 서버는 이동형 및 고정형 플랫폼으로부터 센서 데이터, 시간 및 공간 동기화 정보를 수신할 수 있다 (S105). 이외에도, 각 플랫폼은 서버에 등록할 각 개체의 식별 및 인증 정보 및 도 2를 통해 상술한 정보들을 서버 로 전송할 수 있다. 다음으로, 서버는 수신한 플랫폼 및 센서 데이터들에 대해 전처리 과정을 수행할 수 있다(S110). 전처리 과정은 예컨대, 플랫폼 데이터 및 센서 데이터의 사이즈 변환, 회전, 변이, 경계 강화, 특정 객체 추정, 배경 분류, 사물 분류 등의 알고리즘을 적용할 수 있다. 이하에서, 플랫폼 데이터 및 센서 데이터는 데이터로 약칭하여 설명될 수 있다. 다음으로, 서버는 전처리된 데이터들에 대해 기준 시간계로 동기화할 수 있다(S115). 시간 동기화 프로세서는 도 4에서와 같이 처리될 수 있다. 도 4는 시간 동기화 프로세스에 관한 순서도이다. 우선, 서버는 각 플랫폼의 다중센서 시스템에 탑재된 항법 센서 및 관측 센서로부터 데이터들을 수집할 수 있다(S205). 이어서, 기준 시스템은 다중센서 시스템 또는 각 센서 시스템의 시계 모듈 시간을 동기화할 수 있다 (S210). 이 때, 관측 센서의 촬영 주기 정보는 엣지 또는 기준 시스템의 모듈에 기록될 수 있다. 경우에 따라, 관측 센서의 촬영 주기 정보를 기록하기 위한 별도의 모듈이 설치될 수 있다. 별도의 모듈은 타임 프로토콜 서버(time protocol)일 수 있으며, 항법 신호 수신기 정보에 기초하여 시간 동기화함으로써, 관측 센 서의 촬영 정보의 촬영 주기 정보와 동기화하는데 사용할 수 있다.시간 모듈의 시간 동기화와 관련하여 예를 들어 구체적으로 설명하면, 각 플랫폼의 시스템은 카메라, 라이다, 레이더, 레이저 중 적어도 하나를 포함한 관측 센서를 탑재할 수 있으며, 관측 센서의 시계는 시간을 기록 할 수 있다. 기록된 시간들은 각 시계마다의 시간계를 가지고 있으며, 다중 플랫폼, 다중 센서 간의 시간계가 통일 내지 일관되지 않을 수 있다. 이에 따라 센서 시간계를 하나로 통일할 필요성이 있으며, 센서 시간계의 통 일화는 다중 플랫폼마다의 다중 센서에 대한 트리깅 시간을 기록하여 분석하는 방법과, 다중 플랫폼에서의 다중 센서의 시간계를 동기화하여 통일하는 방법 등이 있을 수 있다. 트리깅 시간을 기록하는 방법은 라이다 또는 레이더 센서가 신호를 송수신하는 주기와 영상 촬영 주기를 동기화 하며 각 플랫폼에서 트리깅하여 해당 시간을 기록하는 것일 수 있다. 동일 트리깅을 통해 수집된 데이터들은 동 일 시간에 수집된 데이터로 해당 시간을 기록하여 관리할 수 있다. 또한 다중 플랫폼에서의 다중 센서의 시간을 동기화하는 방식은 기준 시스템으로부터 수신된 동기화 신호를 통해, 각 센서 내 탑재된 시계를 동기화시 키는 방식일 수 있다. 센서 모듈의 시계는 기준 시스템으로부터 교환되는 메시지, 혹은, 기준 시스템(20 0)으로부터 수신하는 일정 주기 신호를 통해서 보정될 수 있다. 기준 시스템은 지상에 설치된 별도의 기준 기지국 데이터 뿐만 아니라, 위성으로부터 보정 신호를 수신하여, 동기화 신호를 보정할 수도 있다. 이어서, 서버는 다중 플랫폼에 탑재된 각 센서의 센서 데이터 시간계가 통일된지 여부를 확인할 수 있다 (S215). 센서 데이터 시간계가 통일되지 않으면, 서버는 각 센서의 센서 데이터 시간계를 동일 시간계로 변환할 수 있다(S220). S220 단계는 시간 동기화에 대한 검수 과정이며, S215 단계에서 통일화되지 않는 경우에만 선택적으로 수행될 수 있다. 검수 과정은 센서 트리깅 횟수, 촬영 횟수, 신호 송신 횟수, 신호 수신 횟수, 신호 기록 횟수, 센서 데이터 기록 횟수 중 적어도 하나의 값을 확인하여, 상기 값과 동기화된 시계 모듈에 기록된 데이터를 비교할 수 있다. 비교 결과, 동일 시간계에 있지 않는 시계 모듈의 시간이 동일 시간계로 적용되도록 변환될 수 있다. 시간 정보 기준의 동기화시 센서 데이터와 항법 정보 간 시간이 정확하게 일치하지 않음에 따라, 시간에 대한 내삽/외삽 과정이 수행될 수 있다. 예를 들어, 도 5에서와 같이, 동일 시간계에서 수집된 데이터도 각 데이터의 수집 샘플링(Sampling) 시간이 서로 상이하여, 샘플링 시간들이 동기화될 필요성이 있다. 이를 위한 시간 동기 화는 내삽(interpolation)/외삽(exterpolation) 과정으로 진행될 수 있으며, 이 때, 플랫폼의 항법 (Navigation) 정보들도 함께 활용될 수 있다. 이를 통해, 기준 시간축을 참조하여 정의된 시간 정보들이 하나의 시간 값을 갖도록 동기화될 수 있으며, 이는 비록 다른 시점에서 데이터가 수집되었을지라도 한 시점에서 수집 된 데이터로 해석되어 처리될 수 있다. 센서 데이터 시간계가 통일되면, 서버는 기록된 각 관측, 항법 센서들(102, 104)의 시간의 프레임 동기화 수행 및 동일 시간에 수집된 센서 데이터들의 연관 관계를 결정할 수 있다(S225). 다음으로, 서버는 다중센서 시스템 기하 모델을 기준으로 시간 정보 기반 동기화 데이터의 공간 동기화를 수행할 수 있다(S230). 여기서, 공간 동기화는 다중 플랫폼의 다중 센서 각각이 보유하는 시공간 정보에 기반하 여 진행될 수 있다. 정의된 시간동기화 결과와 사전에 정의된 공간 동기화 정보를 통해서 센서들 간의 동기화 과정을 우선 수행할 수 있다. 결과를 확인하고, 다음으로, 서버는 공간 동기화된 데이터에 대해 오차 여부를 확인할 수 있다(S235). 오차가 발생한 경우, 시간 및 공간 동기화에 대한 편위 값(offset)이 공간 동기화된 데이터에 적용될 수 있다 (S240). 오차 검수는 예를 들어, 아래 두가지 방법이 적용될 수 있다. 오차 검수는 도 6에서와 같이, 3차원 기 준 데이터와 지오레퍼런싱(Georeferencing)된 관측 센서 데이터 간 비교 방법이 있을 수 있다. 서버에 저 장된 지도 및 공간 정보의 기준 객체의 정보와 센서 데이터에서 취득되어 3차원적으로 지오레퍼런싱된 객체 정 보를 비교하여 오차를 검수할 수 있다. 다른 예로, 오차 검수는 도 7에서와 같이, 다중센서 시스템 내 데이터들 을 상호 비교하는 방법이 있을 수 있다. 예컨대 동일 공간으로 추정되는 다중 플랫폼의 카메라, 라이다 센서로 부터 취득된 센서 데이터를 비교가능하도록 변환하여 특징 객체를 기준으로 비교함으로써, 오차를 검수할 수 있 다. 오차 검수에 의해 공간 동기화 오차가 제거되거나, S235 단계에서 공간 동기화 오차가 없는 것으로 확인된 경우, 시간 동기화 프로세스가 완료될 수 있다. 도 3을 다시 참조하면, 시간 동기화 프로세스 완료 후, 서버는 시간 동기화된 데이터를 기준 공간계로 동 기화할 수 있다(S120). 이는 다중 플랫폼의 다중 센서의 각 데이터에 대한 기하학적 해석에 기반하여 수행될 수 있다. 이와 관련하여, 도 8 및 도 9를 참조하여 설명하기로 한다. 도 8은 공간 동기화 프로세스에 관한 순서도 이다. 도 9는 공간 동기화를 위해 이용되는 다중 센서 간에 적용되는 기하 모델, 센서 데이터들의 변환을 예시 한 도면이다. 도 8의 단계별 설명에 앞서, 공간 동기화 프로세스를 개념적으로 이해하기 위해, 도 9를 참조하여 기하 모델과 파라미터를 이용한 공간 동기화 프로세스를 서술하기로 한다. 공간 동기화는 다중 센서 내 또는 다중 센서 간 정의되는 기하모델을 기반으로 수행되며, 경우에 따라, 지상 기 준좌표계과의 기하관계식을 정의하여 적용할 수 있다. 다중 플랫폼에 적용된 다중 센서 시스템에서, 동작 중인 관측 센서 간의 기하는 특정 기하모델을 통해 정의될 필요가 있다. 여기서 3차원의 좌표계에 존재하는 사 물이 센서의 좌표계에 투영될 때, 우선적으로 기하는 기본적으로 각 축에 대한 거리 값으로 정의되는 직교 좌표 계 또는 수평/수직각과 거리 값으로 정의되는 구면 좌표계의 기하로 표현될 수 있다. 데이터 기록 형태는 좌표 계 변환의 최종 단계 또는 중간 단계에서 저장될 수 있으며, 데이터 용량 압축을 위해 내삽 프로세스를 전제한 데이터 형태로 저장될 수 있다. 영상 형태로 저장될 경우에는 공선조건식과 같이 일정 면에 투영되는 기하 모델을 기준으로 정의될 수 있다. 이 때, 센서 데이터의 왜곡이 발생을 감소시키기 위해 보정 파라미터를 포함한 기하식을 추가 적용할 수 있다. 다중 센서들의 공간 동기화는 센서들 간의 위치 및 자세 값에 대한 변환을 기반으로 하거나 별도의 기하식을 통 해 수행될 수 있다. 또한, 공간 동기화에서, 항법 센서에 기록된 플랫폼 이동 정보를 통해 관측 정보들은 절대 좌표계로 등록될 수 있다. 일반적으로, 공간 동기화를 위한 파라미터들은 센서 시스템의 설계 사양로부터 획득 될 수 있으나, 더욱 정밀한 공간 동기화를 위해 캘리브레이션 과정을 수행할 수도 있다. 또한, 기하 파라매터 의해 센서 간 동기화 오차가 캘리브레이션 작업만으로 수행되지 않을 경우, 오차는 시간에 특정 오프셋(offset) 값을 포함하여 보정할 수 있다. 이상의 공간 동기화 프로세스에 대해 도 8을 통해 보다 상세히 설명하기로 한다. 동기화 오차는 다중 플랫폼의 다중 센서의 데이터 상에 오차가 예상될 때만 수행될 수 있다. 도 8은 데이터 변환의 일예로, 모든 변환 프로세 스는 단일 식으로도 표현 및 수행이 가능하다. 단일 프로세스 적용 시에는 오차 확인 및 정보 보정은 단일 프로 세스로 가능하다. RSU와 같이 고정형 플랫폼일 경우 항법 정보가 포함되지 않을 수 있다. 우선, 서버는 다중 플랫폼들의 센서들 간의 동기화를 과정 수행을 위해, S115 단계에서 시간 동기화된 데 이터를 입력받아(S305), 각 데이터와 관련된 센서 내부 정보에 대한 데이터를 변환할 수 있다(S310). 내부 정보에 대한 데이터 변환은 예컨대, 어안, 광각렌즈 등에서 주로 나타나는 방사왜곡 등에 대한 보정일 수 있다. 라이다 센서의 경우 예를 들면, 라이다 센서의 수직각, 수평각에 대한 변환을 통한 3차원 좌표 산출일 수 있다. 레이더 센서의 경우 예를 들면, 레이저에 의해 반사된 신호 처리를 통해 물체가 인지되고, 해당 물체에 대한 위치 및 속도 데이터로 변환하기 위한 정보들일 수 있다. 다음으로, 서버는 센서들의 각 데이터와 관련된 센서 외부 정보에 대한 데이터를 변환할 수 있다(S315). 센서 외부 변수는 예컨대, 각 센서의 위치, 자세, 스케일(scale) 정보를 포함할 수 있다. 센서 데이터는 센서 외부 정보를 통해, 2차원 내지는 3차원 변환이 수행될 수 있다. 각 센서들의 외부 정보에 의한 변환을 통해, 센 서 데이터는 통일 좌표계로 투영 또는 변환되어 동기화될 수 있다. 이어서, 서버는 센서들의 외부 정보에 대한 데이터의 변환에 의해, 기하 변환된 센서 데이들의 동기화에 오차가 있는지를 확인할 수 있다(S320). 동기화 오차 확인은 통일 좌표계로 투영 또는 변환된 결과를 확인하여, 센서 데이터들 및 기준 객체의 데이터와 의 이격량을 확인할 수 있다. 이격량 확인 시 영상 내에 투영 또는 3차원 공간 상에 투영시켜 확인할 수 있다. 확인된 이격량이 소정의 제 1 오차 임계치를 초과할 경우(S320의 Y), 센서 외부 정보에 오차가 있는 것으로 예 측한 경우(S325의 Y), 서버는 센서 외부 정보에 대한 보정을 수행할 수 있다. 센서 외부 정보의 보정으로 도 오차가 제 2 오차 임계치를 초과할 경우, 서버는 외부 정보와 함께, 센서 내부 정보를 보정할 수 있다 (S335). 센서 내부/외부 정보들을 보정할 때, 서버는 확인된 이격량을 최소 또는 최적화하여 내부 정보 및 외부 정보들을 보정할 수 있다. 다음으로, 동기화 오차가 없거나 보정되면, 서버는 다중 플랫폼의 항법 센서에 대한 센서 데이터를 변환 할 수 있다(S340). 항법 정보는 GNSS/INS, 비콘, RFID, UWB 와 같은 측위 정보를 활용하거나, 센서 데이터를 기준데이터와 정합하 여 산출한 정보를 통해 수집한다. 항법 정보는 지도 등 기준좌표계 상의 플랫폼의 위치, 자세 정보를 포함할 수 있다. 서버는 항법 정보를 통해, 센서 데이터들을 실제 환경에서의 기준 좌표계로 투영 또는 변환되어 동 기화될 수 있다. 변환 데이터들은 지도 등 기준 데이터 상에 투영되어 활용될 수 있다. 이어서, 서버는 항법 센서를 기준으로 변환된 센서 데이터에 오차가 있는지를 확인할 수 있다(S345). 동기화 오차 확인은 기준 좌표계 상에 투영 또는 변환 결과를 확인하여 그 이격량을 확인할 수 있다. 이격량 확 인시 지상기준점 등 플랫폼 외부에서 수집된 기준 데이터를 활용할 수 있다. 다음으로, 서버는 항법 정보로 인한 센서 데이터에 오차가 있는 경우(S350의 Y), 우선적으로 항법 정보를 보정할 수 있다(S355). S350 단계는 센서 데이터의 오차 원인을 분석하는 과정을 포함할 수 있다. 오차 원인 분 석은 확인된 오차 내지 이격량이 제 3 오차 임계치를 초과할 경우, 오차 원인의 분석 결과에 따라, 항법 정보의 보정(S355), 센서 데이터으 내부 및 외부 정보에 대한 보정(S330, S335)을 수행할 수 있다. 항법 정보 보정은 예를 들어, 다른 시간에 수집된 데이터와의 비교 등 독립적으로 구축된 기준 데이터와의 이격량을 비교하며 수 행할 수 있다. 다른 예로 내부, 외부, 항법 정보들을 보정할 경우, 서버는 확인된 이격량을 최소 또는 최 적화하여 해당 정보들을 보정할 수 있다. 다음으로, 서버는 다중 플랫폼에서 변환된 다중 센서의 데이터를 동기화할 수 있다(S360). 다중센서 데이터 동기화는 데이터 간의 융합 활용에 있어 센서 내부/외부 정보와 항법 정보를 활용하여 수행할 수 있다. 일례로, 3차원 점군 데이터를 2차원 영상 데이터의 동기화함에 있어서, 투영 관계는 공선조건식 (Collinearity Equation)을 통해 정의하여 수행할 수 있다. 이 때 항법 정보, 센서 외부/내부 정보, 시간 동기 화 정보들이 활용될 수 있다. 이어서, 서버는 동기화된 다중 센서의 데이터 간에 오차가 있는지를 확인할 수 있다(S365). 오차가 있는 경우(S365의 Y), 서버는 데이터 동기화 오차 요인을 분석하여(S370), 센서 외부 정보 및 센서 내부 정보에 대한 데이터 변환, 항법 정보에 대한 데이터 변환 중 오차가 발생된 변환을 탐색할 수 있다. 탐색 결과에 따라, 서버는 해당 변환 별 보정 작업을 수행할 수 있다. 오차가 보정되거나 동기화된 다중센서 데이터 간에 오차가 없는 경우, 공간 동기화 프로세스는 완료될 수 있다. 다시 도 3을 참조하면, 시간 및 공간 동기화 프로세스가 완료된 다중 플랫폼의 다중 센서의 데이터를 지도 정보 의 지도 좌표계로 동기화할 수 있다(S125). 이어서, 서버는 지도 좌표계로 동기화된 데이터 간의 연계 관계를 정의할 수 있다(S130). 연계 관계는 서 버에 저장되는 지도 및 공간 정보에 구조화되어 저장될 수 있다. 연계 관계는 다중 플랫폼마다의 카메라 센서, 라이다 센서, 항법 센서, 시스템 정보를 구성하는 상술의 데이터들 중 적어도 하나를 해당 위치 및 시점 별로 지도 및 공간 정보에 기록하도록 구성될 수 있다. 연계 관계는 도 11에 예시되어 있다. 다음으로, 서버는 연계된 센서 데이터 간에 시공간 오차가 있는지를 확인하여(S135), 있는 경우 연계된 센 서 데이터와 관련된 내부 및 외부 정보, 항법 정보에 대하여 보정을 수행하여, 시스템 캘리브레이션을 수행할 수 있다(S140). 다음으로, 보정에 따라 시스템이 캘리브레이션되면, 서버는 센서 데이터의 시간, 공간 동기화 정보를 갱신 할 수 있다(S145). 도 11은 다중 플랫폼 및 다중 센서의 데이터가 동기화되어 연계된 데이터 스키마(schema)를 예시한 도면이다. 연계된 센서 데이터는 이동체, 엣지-인프라의 다중 플랫폼과 각 플랫폼에 탑재된 다중센서들의 시공간 동기 정 보, 각 센서의 내부/외부 파라매터들을 정의하는 프로파일정보, 플랫폼의 위치 및 자세 정보를 하나 이상을 포 함하는 데이터셋을 통해 동기화될 수 있다. 동기화된 정보들은 기준 좌표계에 등록됨으로써 지도(HDmap) 정보들 과 연계 활용될 수 있다. 동일 좌표계 상에 데이터가 등록됨으로써, 동기화된 정보들은 기준 좌표계에 등록될 수 있다. 동기화된 데이터는 시간 정보를 포함하므로, 날씨, 교통 정보, 사고 정보 등의 인프라 정보들과 연계 될 수 있으며, 교통 체계 정보, 공사 정보 등 도로상태를 표현하는 추가 정보들과도 동기화될 수 있다. 도 12는 인공 지능 및 시뮬레이션 개발에 활용되기 위해 다중 플랫폼 및 다중 센서의 데이터의 연계 구조 및 검 색을 도식화한 도면이다. 인공지능 및 시뮬레이션 개발과 데이터 생성을 목적으로 하는 사용자들은 다중플랫폼 다중센서 데이터들이 도 11에 예시된 형태로 등록된 데이터베이스로부터, 목적에 부합하는 데이터를 검색하고 사용할 수 있다. 사용되는 데이터의 목적이 상이하고, 목적을 충족시키는 데이터의 형태가 상이함에 따라, 사용자 요청은 비정형적 정보를 포함할 수 있으며, 각 데이터의 연결관계는 비정형의 정보로부터 검색을 위한 정보들을 정의하여 연관 데이터들 을 검색할 수 있게 된다. 각 센서, 다중플랫폼 간의 시간, 기하정보, 공간정보, 속성정보 중 하나 이상을 포함한 정보들의 조합을 통해 검색이 진행될 수 있으며, 연결관계 정의에 있어서는 기하모델, 기계학습 모델, 네트워크 모델 등이 사용될 수 있다. 검색된 데이터들 시공간 동기화, 변환/매핑(mapping) 과 같은 프로세스를 통해 하나의 데이터셋을 구성하고 이 러한 데이터는 인공지능/시뮬레이션 학습에 반복 사용될 수 있다. 도 13은 다중 플랫폼 및 다중 센서로부터 융합된 데이터가 인공 지능 및 시뮬레이션 모델에 적용되는 것을 예시 한 도면이다. 다중센서 데이터 간의 융합은 카메라, 라이다, 레이다의 인지 범위를 상호 보완할 수 있다. 카메라 센서는 2차 원 영상 정보를 수집하며, 2차원 영상 정보에서 3차원 정보를 수집할 경우에는 그 정확도와 성능에 대한 보증과 관리가 어려우므로, 라이다와 레이더 센서는 상술의 점을 보완할 수 있다. 라이다, 레이더의 경우에는 3차원 정 보를 수집하나, 색상 등 대상물의 속성정보을 추정하기 어렵다는 단점이 있으며, 카메라 영상은 상기 단점을 보 완할 수 있다. 이러한 융합 정보를 활용하면, 3차원 객체 인지/추적 알고리즘 적용 시 그 성능을 극대화시킬 수 있다. 또한, 항법 정보와의 융합을 통해 정밀지도 또는 이동궤적 정보와 융합 분석할 수 있다는 장점이 있다. 또한, 정밀지도 내에 포함된 데이터를 융합센서 데이터와 복합 분석하다는 장점이 있다. 도 14는 다중 플랫폼 및 다중 센서로부터 융합된 데이터가 융합하여 멀티에이전트 지능 학습을 수행하는 것을 예시한 도면이다. 다중 플랫폼 간의 데이터 융합은 이동체 또는 RSU 등의 엣지-인프라 단독 관측을 통한 데이터 수집의 단점을 보 완할 수 있다. 각 플랫폼 상에 탑재된 센서 데이터 및 융합 정보로부터 3차원 객체 정보들을 분석할 수 있으며, 분석된 객체 정보들은 기준 좌표계로의 변환을 통해 지도정보들과 연동되어 표현될 수 있다. 표현된 정보들은 시공간 동기화 정보를 통해 상호 연결관계를 가질 수 있으며, 그 연결 관계를 통해 멀티에이전 트 (multi-agent)에 대한 분석을 가능하게 한다. 멀티에이전트는 각 플랫폼 객체들을 에이전트로 가상 환경 상 에 표현하여 연결된 것을 의미할 수 있다. 연결된 멀티에이전트 정보는 다양한 자율주행 시나리오 상에서 행동 패턴들이 모델화 되어 분석될 수 있다. 해당 분석 시나리오는 자율주행 서비스에 있어 주행, 교통에 대한 안전 성, 안정성, 원활함을 평가하는데 활용될 수 있다. 도 15는 다중 플랫폼 및 다중 센서로부터 융합된 데이터를 이용하여 정밀 지도 및 공간 정보를 자동 구축하고 갱신하는 것을 예시한 도면이다. 우선, AI기반 학습된 모델을 이용하여 객체 인식을 수행하고, 카메라 센서로 촬영한 당시의 영상과 연계되어 있 는 3차원 정보에서 객체 절대좌표를 추출하고, 서버의 데이터베이스 상에 공간 정보를 등록할 수 있다. 공 간 정보는 예컨대, 도로 시설물 위치 정보, 속성 정보 등일 수 있다. 본 개시의 예시적인 방법들은 설명의 명확성을 위해서 동작의 시리즈로 표현되어 있지만, 이는 단계가 수행되는 순서를 제한하기 위한 것은 아니며, 필요한 경우에는 각각의 단계가 동시에 또는 상이한 순서로 수행될 수도 있 다. 본 개시에 따른 방법을 구현하기 위해서, 예시하는 단계에 추가적으로 다른 단계를 포함하거나, 일부의 단 계를 제외하고 나머지 단계를 포함하거나, 또는 일부의 단계를 제외하고 추가적인 다른 단계를 포함할 수도 있 다. 본 개시의 다양한 실시 예는 모든 가능한 조합을 나열한 것이 아니고 본 개시의 대표적인 양상을 설명하기 위한 것이며, 다양한 실시 예에서 설명하는 사항들은 독립적으로 적용되거나 또는 둘 이상의 조합으로 적용될 수도 있다. 또한, 본 개시의 다양한 실시 예는 하드웨어, 펌웨어(firmware), 소프트웨어, 또는 그들의 결합 등에 의해 구현 될 수 있다. 하드웨어에 의한 구현의 경우, 하나 또는 그 이상의 ASICs(Application Specific IntegratedCircuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 범용 프로세서(general processor), 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 본 개시의 범위는 다양한 실시 예의 방법에 따른 동작이 장치 또는 컴퓨터 상에서 실행되도록 하는 소프트웨어 또는 머신-실행가능한 명령들(예를 들어, 운영체제, 애플리케이션, 펌웨어(firmware), 프로그램 등), 및 이러한 소프트웨어 또는 명령 등이 저장되어 장치 또는 컴퓨터 상에서 실행 가능한 비-일시적 컴퓨터-판독가능 매체 (non-transitory computer-readable medium)를 포함한다."}
{"patent_id": "10-2021-0162548", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 이동체가 네트워크를 통해 다른 디바이스와 통신을 수행하는 것을 나타낸 도면이다. 도 2는 상호 통신하는 이동체 및 기준 시스템의 개략적인 모듈을 나타내는 구성도이다. 도 3은 본 개시에 따른 다중플랫폼 및 다중센서 융합에 의한 데이터 수집 방법에 관한 순서도이다. 도 4는 시간 동기화 프로세스에 관한 순서도이다. 도 5는 동일 시간계에 획득된 센서 데이터들의 상이한 수집 샘플링을 예시한 도면이다. 도 6은 기준 데이터와 지오레포런싱(georeferencing)된 관측 센서 데이터 간의 비교를 예시한 도면이다. 도 7은 융합된 다중 센서 시스템에서의 센서 데이터들 간의 비교를 예시한 도면이다. 도 8은 공간 동기화 프로세스에 관한 순서도이다. 도 9는 공간 동기화를 위해 이용되는 다중 센서 간에 적용되는 기하 모델, 센서 데이터들의 변환을 예시한 도면 이다. 도 10은 카메라 센서 내부 정보에 대한 변환을 예시한 도면이다. 도 11은 다중 플랫폼 및 다중 센서의 데이터가 동기화되어 연계된 데이터 스키마(schema)를 예시한 도면이다. 도 12는 인공 지능 및 시뮬레이션 개발에 활용되기 위해 다중 플랫폼 및 다중 센서의 데이터의 연계 구조 및 검 색을 도식화한 도면이다. 도 13은 다중 플랫폼 및 다중 센서로부터 융합된 데이터가 인공 지능 및 시뮬레이션 모델에 적용되는 것을 예시 한 도면이다. 도 14는 다중 플랫폼 및 다중 센서로부터 융합된 데이터가 융합하여 멀티에이전트 지능 학습을 수행하는 것을 예시한 도면이다. 도 15는 다중 플랫폼 및 다중 센서로부터 융합된 데이터를 이용하여 정밀 지도 및 공간 정보를 자동 구축하고 갱신하는 것을 예시한 도면이다."}
