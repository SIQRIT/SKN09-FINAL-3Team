{"patent_id": "10-2022-0039162", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0140251", "출원번호": "10-2022-0039162", "발명의 명칭": "클라우드를 이용하는 인공지능 기반 추론 서비스의 해석 자동화 방법, 장치 및 시스템", "출원인": "한국전자통신연구원", "발명자": "나태흠"}}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "클라우드를 이용한 인공지능 기반 추론 서비스의 해석 자동화 방법에 있어서,클라이언트로부터 수신된 추론 요청 메시지에 기초하여, 추론 서비스에 따른 추론 컨테이너에 추론 응답 메시지를 요청하는 단계;미러링 설정에 의해, 상기 추론 컨테이너와 연동된 모사 학습 컨테이너에 상기 추론 요청 메시지 및 상기 추론응답 메시지를 전달하는 단계; 및상기 추론 요청 메시지 및 상기 추론 응답 메시지에 기반하여 상기 추론 컨테이너의 해석 정보를 생성하고, 상기 클라이언트로 제공하는 단계를 포함하는 추론 서비스의 해석 자동화 방법."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 추론 컨테이너 및 상기 모사 학습 컨테이너는 서로 독립적 학습 모델을 가지며, 상기 모사 학습 컨테이너는 상가 추론 컨테이너의 추론을 모사하도록 학습되는, 추론 서비스의 해석 자동화 방법."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 모사 학습 컨테이너는 상기 추론 서비스를 생성하기 위해 사용되는 추론 서비스 디스크립터(descriptor)에기초하여 생성되되, 상기 추론 서비스 디스크립터는 상기 추론 컨테이너의 제 1 액세스 정보와 입출력 규격을포함하는 상태 정보를 포함하는, 추론 서비스의 해석 자동화 방법."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서, 상기 미러링 설정은 상기 제 1 액세스 정보에 기반하여 전송되는 상기 추론 요청 메시지과 함께 상기 추론 응답메시지를 상기 모사 학습 컨테이너로 미러링하기 위한 인그레스 설정에 의해 수행되는, 추론 서비스의 해석 자동화 방법."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3 항에 있어서, 상기 추론 서비스 디스크립터는 상기 해석 정보의 제공을 지시하는 해석 필드 및 상기 모사 학습 컨테이너의 제2 액세스 정보를 더 포함하되,상기 해석 필드는 활성화 여부를 나타내는 값을 포함하고, 상기 제 2 액세스 정보는 상기 인그레스 설정에 의해생성되며, API 설정을 위해, 상기 모사 학습 컨테이너의 IP 주소 또는 도메인 네임을 가지는, 추론 서비스의 해석 자동화 방법.공개특허 10-2023-0140251-3-청구항 6 제 1 항에 있어서, 상기 해석 정보는 상기 모사 학습 컨테이너의 모사 추론 결과에 작용한 입력 피쳐(input feature) 및 상기 입력피쳐의 중요도 중 적어도 하나를 포함하는, 추론 서비스의 해석 자동화 방법."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서, 상기 해석 정보를 생성하고 상기 클라이언트로 제공하는 단계는, 임계 조건을 충족하는 경우, 상기 해석 정보와함께, 상기 모사 학습 컨테이너의 모사 추론 결과 및 상기 추론 응답 메시지를 상기 클라이언트에 제공하는 것을 포함하되,상기 임계 조건은 상기 모사 학습 컨테이너의 모사 추론 결과가 상기 추론 응답 메시지에 따른 추론 결과에 대하여, 기준값 이상의 유사도를 갖는 조건으로 설정되는, 추론 서비스의 해석 자동화 방법."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서, 상기 해석 정보를 생성하고 상기 클라이언트로 제공하는 단계는, 상기 임계 조건을 충족할 때까지 상기 모사 학습 컨테이너를 계속적으로 학습시켜 상기 모사 추론 결과를 출력하며, 상기 임계 조건을 충족한 상기 모사 추론결과의 해석 정보를 생성하고, 상기 임계 조건이 충족되지 않은 상기 모사 추론 결과는 폐기하는 단계를 더 포함하는, 추론 서비스의 해석 자동화 방법."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서, 상기 추론 응답 메시지를 요청하는 단계 전에, 상기 클리이언트로부터 요청에 따라 상기 추론 서비스를 생성하는 단계; 상기 추론 서비스의 상태 정보에 기초하여 상기 추론 컨테이너 및 상기 모사 학습 컨테이너를 순차적으로 생성하는 단계; 및 상기 상태 정보에 기초하여, 상기 추론 요청 메시지 및 상기 추론 응답 메시지를 상기 모사 학습 컨테이너로 전송하는 미러링 설정을 수행하는 단계를 더 포함하고, 상기 상태 정보는 상기 추론 컨테이너의 제 1 액세스 정보와 입출력 규격을 구비하는, 추론 서비스의 해석 자동화 방법."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 추론 컨테이너를 생성하는 단계는, 상기 추론 서비스에 기초하여 인그레스 레이어, 서비스 레이어 및 추론컨테이너를 포함하는 하위 리소스를 생성하는 것을 포함하는, 추론 서비스의 해석 자동화 방법."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "클라우드를 이용한 인공지능 기반 추론 서비스의 해석 자동화 플랫폼 장치에 있어서,공개특허 10-2023-0140251-4-신호를 송수신하는 송수신부; 및 상기 신호를 처리하는 프로세서를 포함하되, 상기 프로세서는, 클라이언트로부터 수신된 추론 요청 메시지에 기초하여, 추론 서비스에 따른 추론 컨테이너에 추론 응답 메시지를 요청하고, 미러링 설정에 의해, 상기 추론 컨테이너와 연동된 모사 학습 컨테이너에 상기 추론 요청 메시지 및 상기 추론응답 메시지를 전달하고, 상기 추론 요청 메시지 및 상기 추론 응답 메시지에 기반하여 상기 모사 학습 컨테이너를 학습하여 제공 조건을충족하는 경우, 상기 추론 컨테이너의 해석 정보를 생성하고, 상기 클라이언트로 제공하도록 구성되는 추론 서비스의 해석 자동화 플랫폼 장치."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 추론 컨테이너 및 상기 모사 학습 컨테이너는 서로 독립적 학습 모델을 가지며, 상기 모사 학습 컨테이너는 상가 추론 컨테이너의 추론을 모사하도록 학습되는, 추론 서비스의 해석 자동화 플랫폼 장치."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11 항에 있어서,상기 모사 학습 컨테이너는 상기 추론 서비스를 생성하기 위해 사용되는 추론 서비스 디스크립터에 기초하여 생성되되, 상기 추론 서비스 디스크립터는 상기 추론 컨테이너의 제 1 액세스 정보와 입출력 규격을 포함하는 상태 정보를 포함하는, 추론 서비스의 해석 자동화 플랫폼 장치."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 미러링 설정은 상기 제 1 액세스 정보에 기반하여 전송되는 상기 추론 요청 메시지과 함께 상기 추론 응답메시지를 상기 모사 학습 컨테이너로 미러링하기 위한 인그레스 설정에 의해 수행되는, 추론 서비스의 해석 자동화 플랫폼 장치."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 13 항에 있어서,상기 추론 서비스 디스크립터는 상기 해석 정보의 제공을 지시하는 해석 필드 및 상기 모사 학습 컨테이너의 제2 액세스 정보를 더 포함하되, 상기 해석 필드는 활성화 여부를 나타내는 값을 포함하고, 상기 제 2 액세스 정보는 상기 인그레스 설정에 의해생성되며, API 설정을 위해, 상기 모사 학습 컨테이너의 IP 주소 또는 도메인 네임을 가지는, 추론 서비스의 해석 자동화 플랫폼 장치."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 11 항에 있어서,공개특허 10-2023-0140251-5-상기 해석 정보는 상기 모사 학습 컨테이너의 모사 추론 결과에 작용한 입력 피쳐 및 상기 입력 피쳐의 중요도중 적어도 하나를 포함하는, 추론 서비스의 해석 자동화 플랫폼 장치."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 11 항에 있어서,상기 해석 정보를 생성하고 상기 클라이언트로 제공하는 것은, 상기 프로세서에 의해, 임계 조건을 충족하는 경우, 상기 해석 정보와 함께, 상기 모사 학습 컨테이너의 모사 추론 결과 및 상기 추론 응답 메시지를 상기 클라이언트에 제공하는 것을 포함하되, 상기 임계 조건은 상기 모사 학습 컨테이너의 모사 추론 결과가 상기 추론 응답 메시지에 따른 추론 결과에 대하여, 기준값 이상의 유사도를 갖는 조건으로 설정되는, 추론 서비스의 해석 자동화 플랫폼 장치."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 프로세서는, 상기 임계 조건을 충족할 때까지 상기 모사 학습 컨테이너를 계속적으로 학습시켜 상기 모사 추론 결과를 출력하며, 상기 임계 조건을 충족한 상기 모사 추론 결과의 해석 정보를 생성하고, 상기 임계 조건이 충족되지 않은상기 모사 추론 결과는 폐기하도록 구성하는 것을 더 포함하는, 추론 서비스의 해석 자동화 플랫폼 장치."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 11 항에 있어서,상기 프로세서는, 상기 클리이언트로부터 요청에 따라 상기 추론 서비스를 생성하고, 상기 추론 서비스의 상태 정보에 기초하여 상기 추론 컨테이너 및 상기 모사 학습 컨테이너를 순차적으로 생성하고, 상기 상태 정보에 기초하여, 상기 추론 요청 메시지 및 상기 추론 응답 메시지를 상기 모사 학습 컨테이너로 전송하는 미러링 설정을 수행하도록 구성되고, 상기 상태 정보는 상기 추론 컨테이너의 제 1 액세스 정보와 입출력 규격을 구비하는, 추론 서비스의 해석 자동화 플랫폼 장치."}
{"patent_id": "10-2022-0039162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "클라우드를 이용한 인공지능 기반 추론 서비스의 해석 자동화 시스템에 있어서,추론 서비스를 생성 또는 이용을 요청하는 클라이언트; 및 상기 추론 서비스의 요청을 처리하는 프로세서를 포함하는 추론 서비스 해석 자동화 플랫폼 장치를 포함하되, 상기 프로세서는, 상기 클라이언트로부터 수신된 추론 요청 메시지에 기초하여, 추론 서비스에 따른 추론 컨테이너에 추론 응답메시지를 요청하고, 미러링 설정에 의해, 상기 추론 컨테이너와 연동된 모사 학습 컨테이너에 상기 추론 요청 메시지 및 상기 추론응답 메시지를 전달하고, 공개특허 10-2023-0140251-6-상기 추론 요청 메시지 및 상기 추론 응답 메시지에 기반하여 상기 모사 학습 컨테이너를 학습하여 제공 조건을충족하는 경우, 상기 추론 컨테이너의 해석 정보를 생성하고, 상기 클라이언트로 제공하도록 구성되는 추론 서비스의 해석 자동화 시스템."}
{"patent_id": "10-2022-0039162", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "클라우드를 이용하는 인공지능 기반 추론 서비스의 해석 자동화 방법, 장치 및 시스템이 개시된다. 상기 방법은, 클라이언트로부터 수신된 추론 요청 메시지에 기초하여, 추론 서비스에 따른 추론 컨테이너에 추론 응답 메시지를 요청하는 단계; 미러링 설정에 의해, 상기 추론 컨테이너와 연동된 모사 학습 컨테이너에 상기 추 론 요청 메시지 및 상기 추론 응답 메시지를 전달하는 단계; 및 상기 추론 요청 메시지 및 상기 추론 응답 메시 지에 기반하여 상기 추론 컨테이너의 해석 정보를 생성하고, 상기 클라이언트로 제공하는 단계를 포함한다."}
{"patent_id": "10-2022-0039162", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 클라우드를 이용하는 인공지능 기반 추론 서비스의 해석 자동화 방법, 장치 및 시스템에 관한 것이며, 보다 구체적으로 추론 컨테이너와 독립적으로 운용되는 모사 학습 컨테이너를 통해 추론의 인과에 대한 해석 정보를 제공하는 인공지능 기반 추론 서비스의 해석 자동화 방법, 장치 및 시스템에 대한 것이다."}
{"patent_id": "10-2022-0039162", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 AI에 대한 폭발적 관심의 증가로 심층신경망(DNN)에 대한 설계와 더불어, 내부 처리 절차 및 추론 결과에 대한 설명가능성(eXplainable AI; XAI)또는 해석가능성(interpretability)을 높이는 연구도 활발히 진행되고 있다. 예를 들어 분류(classification) 모델의 경우 추론 결과에 가장 큰 영향을 미친 뉴런을 구분하는 기법 및 여러 입력 피쳐(feature) 중 해당 추론에 가장 큰 영향을 준 입력을 도출하는 기법 등이 있다. 이러한 기법들은 운용자가 모델의 결정에 대한 원인을 개략적으로 이해할 수 있는 수준이다. 따라서, 운용자가 모델의 결과에 대 한 인과 관계를 이해하고 모델의 결과를 상세히 이해할 수 있도록 연구되고 있다. 이와 동시에, DNN을 모사 학 습하여 새로운 자료구조의 알고리즘 형태로 변환하는 경우도 모두 설명가능성을 높이는 기술에 해당한다. 따라 서 인공지능 모델의 해석가능성이 높을수록, 모델에서 도출된 결정 또는 예측의 과정 및 이유가 쉽게 이해될 수 있다. 해석가능성을 높임으로써 네트워크 시스템과 결합된 형태의 인공지능 모델의 동작이 이해될 수 있고, 인공지능 과 인간이 협업할 수 있는 형태(human in the loop)의 구조가 구현될 수 있다. 이를 활용하면, 네트워크 운용자 는 모델이 도출한 운용 결과(operation result)과 관련한 이유를 이해할 수 있고, 해당 운용을 승인하는 방식으 로 불확실성이 제거될 수 있다. 또한, AI모델이 학습하지 못한 피쳐 외에 외부 요인들을 운용자가 보완함으로써 운용 효율도 극대화할 수 있다. 그러나, 종래의 학습 모델의 해석 방식은 추론 서비스 이용자가 추론 서비스의 생성 과정 및 추론 서비스의 이 용 과정에서 추론 요청에 따른 결과를 제공받을 수 있으나, 해당 결과가 도출된 구체적인 인관 관계를 여전히 파악할 수 없다. 즉, 이용자는 추론 결과를 도출시킨 상세한 추론 절차와 관련된 해석 정보를 획득할 수 없다. 예를 들어, 이용자는 추론 결과에 주요하게 작용한 다수의 입력 피쳐 및 피쳐 별 중요도 등 관련된 해석 정보를 취득할 수 없어, 이용자는 추론 서비스 결과와 모델의 해석 결과를 스스로 확인하고 해당 원인을 직접 규명하여 야 한다. 이에 따라, 이용자가 추론 절차를 직접 추정하여 설명하여야 하는 번거로움이 있다."}
{"patent_id": "10-2022-0039162", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 기술적 과제는 추론 컨테이너와 독립적으로 운용되는 학습 모사 컨테이너를 통해 추론의 인과에 대한 설명을 제공하는 인공지능 기반 추론 서비스의 해석 자동화 방법, 장치 및 시스템을 제공하는데 그 목적이 있다. 본 개시에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2022-0039162", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0039162", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 양상에 따르면, 클라우드를 이용하는 인공지능 기반 추론 서비스의 해석 자동화 방법은, 클라이언 트로부터 수신된 추론 요청 메시지에 기초하여, 추론 서비스에 따른 추론 컨테이너에 추론 응답 메시지를 요청 하는 단계; 미러링 설정에 의해, 상기 추론 컨테이너와 연동된 모사 학습 컨테이너에 상기 추론 요청 메시지 및 상기 추론 응답 메시지를 전달하는 단계; 및 상기 추론 요청 메시지 및 상기 추론 응답 메시지에 기반하여 상기 추론 컨테이너의 해석 정보를 생성하고, 상기 클라이언트로 제공하는 단계를 포함한다. 본 개시의 다른 실시예에 따르면, 상기 추론 컨테이너 및 상기 모사 학습 컨테이너는 서로 독립적 학습 모델을 가지며, 상기 모사 학습 컨테이너는 상가 추론 컨테이너의 추론을 모사하도록 학습될 수 있다. 본 개시의 또 다른 실시예에 따르면, 상기 모사 학습 컨테이너는 상기 추론 서비스를 생성하기 위해 사용되는 추론 서비스 디스크립터(descriptor)에 기초하여 생성되되, 상기 추론 서비스 디스크립터는 상기 추론 컨테이너 의 제 1 액세스 정보와 입출력 규격을 포함하는 상태 정보를 포함할 수 있다. 본 개시의 또 다른 실시예에 따르면, 상기 미러링 설정은 상기 제 1 액세스 정보에 기반하여 전송되는 상기 추 론 요청 메시지과 함께 상기 추론 응답 메시지를 상기 모사 학습 컨테이너로 미러링하기 위한 인그레스 설정에 의해 수행될 수 있다. 본 개시의 또 다른 실시예에 따르면, 상기 추론 서비스 디스크립터는 상기 해석 정보의 제공을 지시하는 해석 필드 및 상기 모사 학습 컨테이너의 제 2 액세스 정보를 더 포함할 수 있다. 상기 해석 필드는 활성화 여부를 나타내는 값을 포함하고, 상기 제 2 액세스 정보는 상기 인그레스 설정에 의해 생성되며, API 설정을 위해, 상 기 모사 학습 컨테이너의 IP 주소 또는 도메인 네임을 가질 수 있다. 본 개시의 또 다른 실시예에 따르면, 상기 해석 정보는 상기 모사 학습 컨테이너의 모사 추론 결과에 작용한 입 력 피쳐(input feature) 및 상기 입력 피쳐의 중요도 중 적어도 하나를 포함할 수 있다. 본 개시의 또 다른 실시예에 따르면, 상기 해석 정보를 생성하고 상기 클라이언트로 제공하는 단계는, 임계 조 건을 충족하는 경우, 상기 해석 정보와 함께, 상기 모사 학습 컨테이너의 모사 추론 결과 및 상기 추론 응답 메 시지를 상기 클라이언트에 제공하는 것을 포함할 수 있다. 상기 임계 조건은 상기 모사 학습 컨테이너의 모사 추론 결과가 상기 추론 응답 메시지에 따른 추론 결과에 대하여, 기준값 이상의 유사도를 갖는 조건으로 설정될 수 있다. 본 개시의 또 다른 실시예에 따르면, 상기 해석 정보를 생성하고 상기 클라이언트로 제공하는 단계는, 상기 임 계 조건을 충족할 때까지 상기 모사 학습 컨테이너를 계속적으로 학습시켜 상기 모사 추론 결과를 출력하며, 상 기 임계 조건을 충족한 상기 모사 추론 결과의 해석 정보를 생성하고, 상기 임계 조건이 충족되지 않은 상기 모 사 추론 결과는 폐기하는 단계를 더 포함할 수 있다. 본 개시의 또 다른 실시예에 따르면, 상기 추론 응답 메시지를 요청하는 단계 전에, 상기 클리이언트로부터 요 청에 따라 상기 추론 서비스를 생성하는 단계; 상기 추론 서비스의 상태 정보에 기초하여 상기 추론 컨테이너 및 상기 모사 학습 컨테이너를 순차적으로 생성하는 단계; 및 상기 상태 정보에 기초하여, 상기 추론 요청 메시 지 및 상기 추론 응답 메시지를 상기 모사 학습 컨테이너로 전송하는 미러링 설정을 수행하는 단계를 더 포함할 수 있다. 상기 상태 정보는 상기 추론 컨테이너의 제 1 액세스 정보와 입출력 규격을 구비할 수 있다. 본 개시의 또 다른 실시예에 따르면, 상기 추론 컨테이너를 생성하는 단계는, 상기 추론 서비스에 기초하여 인 그레스 레이어, 서비스 레이어 및 추론 컨테이너를 포함하는 하위 리소스를 생성하는 것을 포함할 수 있다. 본 개시의 다른 양상에 따르면, 클라우드를 이용하는 인공지능 기반 추론 서비스의 해석 자동화 플랫폼 장치는, 신호를 송수신하는 송수신부; 및 상기 신호를 처리하는 프로세서를 포함한다. 상기 프로세서는, 클라이언트로부 터 수신된 추론 요청 메시지에 기초하여, 추론 서비스에 따른 추론 컨테이너에 추론 응답 메시지를 요청하고, 미러링 설정에 의해, 상기 추론 컨테이너와 연동된 모사 학습 컨테이너에 상기 추론 요청 메시지 및 상기 추론 응답 메시지를 전달하고, 상기 추론 요청 메시지 및 상기 추론 응답 메시지에 기반하여 상기 모사 학습 컨테이 너를 학습하여 제공 조건을 충족하는 경우, 상기 추론 컨테이너의 해석 정보를 생성하고, 상기 클라이언트로 제 공하도록 구성된다. 본 개시의 또 다른 양상에 따르면, 클라우드를 이용하는 인공지능 기반 추론 서비스의 해석 자동화 시스템은, 추론 서비스를 생성 또는 이용을 요청하는 클라이언트; 및 상기 추론 서비스의 요청을 처리하는 프로세서를 포 함하는 추론 서비스 해석 자동화 플랫폼 장치를 포함한다. 상기 프로세서는, 상기 클라이언트로부터 수신된 추 론 요청 메시지에 기초하여, 추론 서비스에 따른 추론 컨테이너에 추론 응답 메시지를 요청하고, 미러링 설정에 의해, 상기 추론 컨테이너와 연동된 모사 학습 컨테이너에 상기 추론 요청 메시지 및 상기 추론 응답 메시지를 전달하고, 상기 추론 요청 메시지 및 상기 추론 응답 메시지에 기반하여 상기 모사 학습 컨테이너를 학습하여 제공 조건을 충족하는 경우, 상기 추론 컨테이너의 해석 정보를 생성하고, 상기 클라이언트로 제공하도록 구성 된다."}
{"patent_id": "10-2022-0039162", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 개시에 대하여 위에서 간략하게 요약된 특징들은 후술하는 본 개시의 상세한 설명의 예시적인 양상일 뿐이며, 본 개시의 범위를 제한하는 것은 아니다."}
{"patent_id": "10-2022-0039162", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 추론 컨테이너와 독립적으로 운용되는 모사 학습 컨테이너를 통해 추론의 인과에 대한 해석 정보를 제공하는 인공지능 기반 추론 서비스의 해석 자동화 방법, 장치 및 시스템을 제공할 수 있다. 본 개시에 따르면, 추론 서비스 제공자 및 추론 서비스 이용자는 별도의 해석 과정을 위한 절차를 수행하지 않 고도 추론에 대한 해석 정보를 획득할 수 있다. 상세하게는, 추론 서비스 제공자는 별도의 부가적인 요청이나 동작 없이도 추론 서비스에 대한 해석을 제공받을 수 있으며, 추론 서비스 이용자도 추론 결과의 이유를 보다 상세히 이해할 수 있다. 또한, 본 개시에 따르면, 미러링 설정에 관한 정책이 인그레스(ingress) 제어를 통해 추가됨으로써, HTTP기반 및 REST API기반 추론 요청 메시지 및 추론 응답 메시지를 해석 제공을 위한 모사 학습 서비스의 엔드포인트로 전달할 수 있다. 본 개시에 따르면, 추론 서비스 디스크립터에 주석(annotation) 필드의 값을 추가함으로써 사용자 관점에서의 수정 없이 선택적으로 용이하게 해석 기능을 활용할 수 있다. 이에 더하여, 추론 서비스 제공자 및 이용자가 디커플링(decoupling) 가능하도록, 해석 기능이 모델링될 수 있 다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0039162", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참고로 하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나, 본 개시는 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시의 실시 예를 설명함에 있어서 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그에 대한 상세한 설명은 생략한다. 그리고, 도면에서 본 개시에 대한 설명과 관계없 는 부분은 생략하였으며, 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시에 있어서, 어떤 구성요소가 다른 구성요소와 \"연결\", \"결합\" 또는 \"접속\"되어 있다고 할 때, 이는 직접 적인 연결 관계 뿐만 아니라, 그 중간에 또 다른 구성요소가 존재하는 간접적인 연결관계도 포함할 수 있다. 또 한 어떤 구성요소가 다른 구성요소를 \"포함한다\" 또는 \"가진다\"고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 배제하는 것이 아니라 또 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 개시에 있어서, 제 1, 제 2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용 되며, 특별히 언급되지 않는 한 구성요소들 간의 순서 또는 중요도 등을 한정하지 않는다. 따라서, 본 개시의 범위 내에서 일 실시 예에서의 제 1 구성요소는 다른 실시 예에서 제 2 구성요소라고 칭할 수도 있고, 마찬가지 로 일 실시 예에서의 제 2 구성요소를 다른 실시 예에서 제 1 구성요소라고 칭할 수도 있다. 본 개시에 있어서, 서로 구별되는 구성요소들은 각각의 특징을 명확하게 설명하기 위함이며, 구성요소들이 반드 시 분리되는 것을 의미하지는 않는다. 즉, 복수의 구성요소가 통합되어 하나의 하드웨어 또는 소프트웨어 단위 로 이루어질 수도 있고, 하나의 구성요소가 분산되어 복수의 하드웨어 또는 소프트웨어 단위로 이루어질 수도 있다. 따라서, 별도로 언급하지 않더라도 이와 같이 통합된 또는 분산된 실시 예도 본 개시의 범위에 포함된다. 본 개시에 있어서, 다양한 실시 예에서 설명하는 구성요소들이 반드시 필수적인 구성요소들은 의미하는 것은 아 니며, 일부는 선택적인 구성요소일 수 있다. 따라서, 일 실시 예에서 설명하는 구성요소들의 부분집합으로 구성 되는 실시 예도 본 개시의 범위에 포함된다. 또한, 다양한 실시예에서 설명하는 구성요소들에 추가적으로 다른 구성요소를 포함하는 실시 예도 본 개시의 범위에 포함된다. 이하, 첨부한 도면을 참조하여 본 개시의 실시 예들에 대해서 설명한다. 도 1은 본 개시를 설명하기 위한 클라우드를 이용하는 인공지능 기반 추론 서비스에 적용되는 해석 자동화 시스 템의 예시도이다. 클라우드 기반의 추론 서비스에서 해석 자동화 시스템은 추론 서비스 해석 자동화 플랫폼 장치, 추론 서비 스 제공자 클라이언트 및 추론 서비스 이용자 클라이언트를 포함할 수 있다. 기재의 편의를 위해, 추 론 서비스 해석 자동화 플랫폼 장치는 클라우드 인프라스트럭쳐와 혼용되어 서술될 수 있다. 추론 서비스 제공자 클라이언트 및 추론 서비스 이용자 클라이언트는 각각 제공자 클라이언트 및 이용자 클라이언 트로 약칭될 수 있다. 해석 자동화 시스템은 일례로 자원 효율성을 높이기 위해, 이용자 클라이언트로부터 추론 서비스가 요청될 때, 클라우드 인프라스트럭쳐에 사전 정의된(predefined) 추론 컨테이너를 생성하여 추론 서비스를 제공할 수 있다. 또한, 해석 자동화 시스템은 추론 컨테이너와 독립적으로 운영되는 모사 학습 컨테이너에 의해, 모사 추론 결과 및 추론 서비스의 추론 결과를 설명하는 해석 정보를 제공할 수 있다. 사전 정의된 추론 컨테이너는 제공자 클라이언트로부터의 추론 서비스(또는 추론 서비스 모듈)의 생성 요 청에 의해, 클라우드 인프라스트럭쳐의 소정 위치에 할당될 수 있다. 사전 정의된 추론 컨테이너는 예컨대 추론 컨테이너 이름(또는 식별자), 추론 컨테이너의 저장 위치 정보, 추론 컨테이너에 적용할 학습 모델, 학습 모델의 런타임 정보, 추론 컨테이너의 입출력 규격 등을 포함하는 상태 정보를 가질 수 있다. 저장 위치 정보는 예를 들어, URL일 수 있다. 사전 정의된 추론 컨테이너는 이용자 클라이언트로부터 추론 요청에 의해 실제 로 활성화되지 않은 프로토타입의 추론 컨테이너일 수 있다. 상기 추론 컨테이너는 예컨대, DNN과 같은 심층 신 경망 학습 모델일 수 있으나, 이에 제한되지 않고 추론 서비스를 지원하는 다양한 학습 모델로 구성될 수 있다. 클라우드 인프라스트럭쳐는 다양한 종류의 추론 컨테이너를 관리하는 엔드포인트를 복수로 가지면서, 엔드 포인트 별로 IP 주소 또는 도메인 네임을 갖도록 구성될 수 있다. 사전 정의된 추론 컨테이너의 생성 요청이 있 는 경우, 클라우드 인프라스트럭쳐는 예컨대 인그레스의 제어기에 의해, 추론 컨테이너와 연동되는 레이어 들, 예컨대 인그레스 레이어 및 서비스 레이어를 구성하도록 제어될 수 있다. 이에 따라, 클라우드 인프라스트 럭쳐는 적어도 하나의 서버를 구비하며, 예컨대 복수의 서버인 경우, 상기 레이어들을 제어하는 서버 및 엔드포인트를 관리하는 서버가 별도로 마련될 수 있다. 사전 정의된 추론 컨테이너의 생성과 추론 서비스의 이용에 대해 구체적으로 설명하면, 제공자 클라이언트(20 0)가 클라우드 인프라스트럭쳐에 추론 서비스의 생성을 요청할 수 있다. 클라우드 인프라스트럭쳐는 내부에서 추론 서비스를 생성할 수 있다. 클라우드 인프라스트럭쳐는 API 서버 역할을 담당하는 추론 서비 스 엔터티(inference service entity)를 생성하고, 엔드포인트 정보를 반환할 수 있다. 사전 정의된 추론 컨테 이너는 추론 서비스 엔터티와 연계되어 관리될 수 있다. 클라우드 인프라스트럭쳐의 내부에 생성된 추론 서비스는 API 호출을 대기할 수 있다. 이용자 클라이언트에 의해, 추론 서비스 요청과 관련된 API가 호출 되면, 추론 서비스 엔터티는 학습된 모델을 포함하는 실제 운영할 추론 컨테이너를 생성할 수 있다. 즉, 추론서비스 엔터티는 사전 정의된 추론 컨테이너를 기반으로 실제 운영할 추론 컨테이너를 생성할 수 있다. 실제의 추론 컨테이너의 생성이 완료되면, 클라우드 인프라스트럭쳐는 추론 요청 API를 리다이렉팅하여 (redirecting) 추론을 요청하고, 추론 결과를 획득하여 이용자 클라이언트로 반환할 수 있다. 추론 결과가 반환될 때, 모사 학습 컨테이너는 추론 서비스의 요청 및 응답 메시지에 기반하여 모사 추론 결과 및 추론 컨테이너의 추론 결과를 설명하는 해석 정보를 이용자 클라이언트로 전달할 수 있다. 모사 학습 컨테이너 및 해석 정보에 대한 상세한 설명은 후술하기로 한다. 다른 예로, 실제의 추론 컨테이너는 제공자 클라이언트로부터의 추론 서비스의 요청에 의해 생성되어 엔드 포인트에 할당되면서, 이용자 클라이언트로부터의 API 호출을 대기할 수도 있다. 이 경우, 사전 정의된 추 론 컨테이너가 생성되지 않을 수도 있다. 도 2는 본 개시의 실시예에 따른 인공지능 기반 추론 서비스의 해석 자동화 플랫폼 장치의 개략 구성도이다. 추론 서비스의 해석 자동화 플랫폼 장치는 추론 서비스의 생성, 이용과 관련된 처리를 실행하는 서버 등을 구비하는 클라우드 인프라스트럭쳐일 수 있다. 클라우드 인프라스트럭쳐는 레이어들의 제어 모듈, 추론 컨 테이너 및 모사 학습 컨테이너가 할당된 파드(pod)의 저장소 등을 포함하는 서버일 수 있다. 레이어들의 제어 모듈 및 컨테이너는 단일 서버에서 운영될 수 있거나, 서로 다른 서버에서 관리될 수 있다. 일 예로, 장치 는 적어도 하나의 서버를 포함하며, 서버는 상술한 동작을 위해 프로세서, 메모리 및 송수신부 중 적어도 어느 하나 이상을 포함할 수 있다. 즉, 장치는 다른 장치와 통신을 하기 위해 필요한 구성을 포함할 수 있다. 또한, 일 예로, 장치는 상술한 구성 이외에도 다른 구성들을 포함할 수 있다. 즉, 장치는 다른 디바이스 와 통신을 수행하기 위해 상술한 장치를 포함하는 구성일 뿐, 이에 한정되는 것이며, 상술한 바에 기초하여 동 작하는 장치일 수 있다. 도 3은 본 개시의 실시예에 따른 인공지능 기반 추론 서비스의 해석 자동화 플랫폼 장치에서, 인그레스 (ingress) 레이어, 서비스 레이어 및 엔드포인트(endpoint) 간의 리소스 연계를 예시한 도면이다. 도 3을 참고 하여, 도 1에 나타나는 추론 컨테이너의 이용과 관련된 인그레스 제어에 대해 상세하게 설명한다. 해석 자동화 플랫폼 장치, 즉 클라우드 인프라스트럭쳐는 이용자 클라이언트의 추론 서비스의 이용 요청을 수신하여, 상기 이용 요청을 수행하는 추론 컨테이너로 상기 요청을 전달하도록 제어될 수 있다. 이를 위해, 클라우드 인프라스트럭쳐는 상기 요청을 최초 수신하는 인그레스 레이어, 서비스 레이어 , 엔드포인트를 포함하는 하위 리소스(sub-resource)를 갖도록 구성될 수 있다. 하위 리소스는 클라 우드 인프라스트럭쳐의 프로세서 및 메모리에 의해 관리될 수 있다. 인그레스 레이어는 이용자 클라이언트의 추론 요청 API를 수신하여 추론 컨테이너로 전송하도록 제어할 수 있다. 인그레스 레이어는 클라우드 네이티브 환경에서 제공되며, API 게이트웨이로 활용될 수 있다. 인그레스 레이어는 클라우드 인프라스트럭쳐 내부에서 단일 퍼블릭(public) IP를 활용하며, URL 기반으로 추론 서비스를 구분할 수 있다. 인그레스 레이어는 추론 요청의 추론 서비스에 부합하는 URL 를 조회하여, 조회된 URL과 연계되어 설정된 추론 서비스의 엔드포인트, 즉 해당 추론 컨테이너로, 추론 요청에 따른 웹 요청 패킷을 전달할 수 있다. URL은 추론 컨테이너로 접근하는데 필요한 제 1 액세스 정보 의 일종일 수 있다. 제 1 액세스 정보는 인그레스 레이어가 추론 요청을 포워딩하는데 이용되는 URL 뿐만 아니라, URL과 연계된 엔드포인트의 위치 정보를 포함할 수 있다. 위치 정보는 예컨대, IP 주소 또는 도메 인 네임일 수 있다. 제 1 액세스 정보로 활용될 수 있는 URL 형태는 일례로, 독립적인 도메인 네임을 가질 수 있다. 도 3에 예시된 바와 같이, 독립적인 도메인 네임은 foo.example.com, bar.example.com 일 수 있다. 다른 예로, URL 형태는 동일한 도메인 네임에 '/'로 구분되는 도메인 내에서 하위 디렉토리를 표기함으로써, 별도의 서비스 엔드포인트와 연동하는 형태로 활용 가능하다. 도 3에 예시된 바와 같이, kubia. example.com/kubia, kubia.example.com/example 일 수 있다. 서비스 레이어는 인그레스 레이어로부터 인지된 URL에 매핑되는 추론 컨테이너의 위치 정보를 탐색할 수 있다. 추론 컨테이너의 위치 정보는 엔드포인트를 통해 확인되며, 제 1 액세스 정보에 포 함된 엔드포인트의 위치 정보와 실질적으로 동일할 수 있다. 추론 컨테이너에 대한 제 1 액세스 정보 가 동적 IP 주소인 경우, 클라우드 인프라스트럭쳐의 설정에 따라 동적으로 변동될 수 있다. 이 경우, 추 론 요청이 인그레스 레이어가 인지한 URL에 의해 해당 추론 컨테이너로 전달될 수 있다. 이에 따라, 서비스 레이어는 추론 컨테이너의 URL과 같은 도메인 네임으로 추론 컨테이너의 동적 IP 주소를 확인하기 위해, 추론 컨테이너는 동적 IP 주소와 함께, 컨테이너의 정적 이름(또는 식별자)을 포함하는 컨테이너 정보를 가질 수 있다. 서비스 레이어는 인그레스 레이어로부터 전달된 도메인 네임과 추론 컨 테이너의 정적 네임을 매핑하여, 매핑된 정적 네임에 상응하는 IP 주소로 추론 요청을 전송할 수 있다. 엔드포인트는 이용자 클라이언트의 추론 요청을 실행하는 추론 컨테이너를 지정된 파드에 저장 하여 관리할 수 있다. 예를 들어, 추론 요청은 이용자가 전송한 이미지, 오디오에 포함된 객체를 인식하여 객체 정보(예컨대, 꽃 이미지에서의 꽃 이름, 음악의 곡명 등)를 도출할 것을 요구할 수 있다. 상술한 예에 의하면, 추론 컨테이너는 객체 정보를 포함하는 추론 결과를 이용자 클라이언트로 반환하는 학습 모델일 수 있다. 추론 컨테이너는 예를 들어, 심층적인 분석에 따른 추정 또는 예측 결과를 제공가능한 DNN 등일 수 있으며, 심층 학습 모델이라면, DNN 이외의 다양한 학습 모델일 수도 있다. 실질적으로 동일한 추론 요청이 다 수로 수신되어 추론 결과가 신속히 출력하기 위해, 추론 요청이 많은 추론 컨테이너는 엔드포인트에 복수 개로 할당되도록 생성될 수 있다, 도 3에 예시된 바와 같이, 실질적으로 동일한 추론 컨테이너로 지 정된 복수의 파드가 엔드포인트에 제공될 수 있다. 추론 컨테이너는 상술한 바와 같이, 엔드포인트에서 마련될 수 있으며, 엔드포인트는 이용자 클 라이언트의 추론 요청이 추론 컨테이너에 접근하기 위한 제 1 액세스 정보로 지정될 수 있다. 제 1 액세스 정보는 예컨대, 추론 컨테이너의 IP 주소 또는 도메인 네임일 수 있다. IP 주소의 경우, 제 1 액세 스 정보는 클라우드 인프라스트럭쳐의 설정에 따라 동적으로 변동될 수 있다. 도메인 네임은 동적 IP 주소 에 대응하는 텍스트 이름으로 정의된 주소이며, IP 주소가 가변되더라도 유지될 수 있다. 도 4는 인그레스 레이어의 동작을 예시한 도면이다. 도 4는 클라우드 인프라스트럭쳐의 레이어들(110~130)에서 수행되는 절차로서, 인그레스 레이어를 통 해 설정된 URL-서비스 엔드포인트의 동작 절차를 보여준다. 도 4는 사전에 설정된 URL(kubia.example.com)로 HTTP요청이 전달되는 예를 들어 도시되어 있다. 이용자 클라이언트가 생성한 추론 요청은 DNS(140; Domain Name System)로 전송되어, DNS는 추론 요 청에 상응하는 URL의 IP를 조회할 수 있다. DNS는 클라우드 인프라스트럭쳐에 포함되어 운영될 수 있 다. 이용자 클라이언트는 DNS로 조회된 IP를 이용하여 HTTP 취득(GET) 요청 메시지를 전송할 수 있다. 이 때, HTTP의 헤더에는 URL이 명시될 수 있다. 인그레스 레이어를 제어하는 인그레스 제어기 는 해당 요청 메시지를 수신하여 헤더의 URL을 조회할 수 있다. 인그레스 제어기는 미리 설정된 서비스 엔 드포인트를 지시하는 인그레스 레이어로 포워딩할 수 있다. 도 3에서 설명된 바와 같이, 추론 요청은 인그레스 제어에 의해, 인그레스 레이어, 서비스 레이어 및 엔드포인트를 경유하여 해당 추론 컨테이너(132; 또는 파드)로 전달될 수 있다. 도 5 및 도 6을 참조하여, 본 개시의 실시예에 따른 인공지능 기반 추론 서비스의 해석 자동화 방법에서 수행되 는 모사 학습 컨테이너의 생성 및 미러링 설정에 대하여 설명하기로 한다. 도 5는 본 개시의 실시예에 따른 인공지능 기반 추론 서비스의 해석 자동화 방법에서 수행되는 모사 학습 컨테 이너의 생성 및 미러링 설정에 관한 순서도이다. 도 6은 모사 학습 컨테이너의 생성 및 미러링 설정이 본 개시 의 실시예에 따른 해석 자동화 플랫폼 장치에서 구현되는 과정을 예시한 도면이다. 도 5를 참조하면, 클라우드 인프라스트럭쳐는 제공자 클라이언트의 요청에 따라, API 서버를 통 해 추론 서비스를 생성할 수 있다(S105). 클라우드 인프라스트럭쳐의 프로세서는 상기 요청에 따른 추론 서비스 디스크립터(descriptor)를 구성 할 수 있다. API 서버는 클라우드 인프라스트럭쳐를 구성하는 장치일 수 있다. 상기 요청은 추론 서 비스의 추론 결과와 함께, 모사 학습 컨테이너(134; imitation training container)에 의한 모사 추론 결과 및 해석 정보를 제공하는 것을 포함할 수 있다. 이에 따라, 추론 서비스는 추론 서비스 디스크립터에 기초하여 생 성될 수 있다. 추론 서비스 디스크립터는 도 6의 좌측 상단에 예시된 바와 같이, 추론 컨테이너 이름(또는 식별 자), 추론 컨테이너의 저장 위치 정보, 추론 컨테이너에 적용할 학습 모델, 학습 모델의 런타임 정보, 추론 컨테이너의 입출력(input/output) 규격 등을 포함하는 상태 정보를 가질 수 있다. 추론 컨테이 너의 저장 위치 정보는 추론 컨테이너의 제 1 액세스 정보에 해당될 수 있다. 저장 위치 정보는 예컨 대, URL과 같은 도메인 네임 또는 IP 주소일 수 있다. 상술한 바와 같이, 모사 학습 컨테이너가 생성되어 해석 정보를 제공하도록, 추론 서비스 디스크립터는 제 공자 클라이언트의 요청에 의해, 해석 정보의 제공을 지시하는 해석 필드를 활성화하도록 생성될 수 있다. 예를 들어, 제공자 클라이언트는 도 6의 좌측 상단의 추론 서비스 디스크립터에 예시된 바와 같이, YAML형식의 metadata/annotation/interpretation 필드(언더라인된 부분), 즉 해석 필드를 활성화 값인 true값으로 설 정할 수 있다. 다음으로, 프로세서는 추론 서비스의 상태 정보에 기초하여 추론 컨테이너 및 모사 학습 컨테이너 를 순차적으로 생성할 수 있다(S110). 도 6에서는, 추론 컨테이너는 추론 서비스 제어기에 의해 생성되며, 모사 학습 컨테이너는 해석 제어기에 의해 생성되는 것이 예시된다. 추론 서비스 제어기 및 해석 제어기는 프로세서에 서 통합적으로 구현될 수 있다. 이에 따라, 추론 서비스 제어기 및 해석 제어기는 클라우드 인프라스 트럭쳐를 구성하는 모듈 내지 장치일 수 있다. 추론 서비스 제어기는 구체적으로, 상태 정보와 관련된 추론 서비스 디스크립터에 기초하여 인그레스 레이 어, 서비스 레이어 및 추론 컨테이너를 포함하는 하위 리소스를 생성할 수 있다. 또한, 해석 제어기는 해석 필드의 활성화 값을 인지하고, 상태 정보를 기초로 모사 학습 컨테이너를 생성할 수 있다. 모사 학습 컨테이너는 상태 정보 중 적어도 추론 컨테이너 이름(또는 식별자)와 추론 컨 테이너의 학습 모델을 포함하는 컨테이너 정보, 추론 컨테이너의 제 1 액세스 정보, 입출력 규격 등 에 기초하여 생성될 수 있다. 제 1 액세스 정보는 예컨대, 추론 컨테이너의 API URL일 수 있다. 이에 따라, 도 9에 예시된 바와 같이, 모사 학습 컨테이너는 추론 컨테이너와 유사한 인그레스 설정에 의 해, 서비스 레이어와 연계된 엔드포인트의 파드로 지정되어 관리될 수 있다. 모사 학습 컨테이너는 추론 컨테이너와 서로 독립적 학습 모델을 가질 수 있다. 예컨대, 추론 컨테이 너는 DNN과 같은 심층 학습 모델을 채용하면, 모사 학습 컨테이너는 추론 컨테이너의 입출력 규 격에 부합하도록 입출력을 설정하고, 모사 학습 컨테이너는 심층 학습 모델보다 경량의 학습 모델로 구현 될 수 있다. 모사 학습 컨테이너의 학습 모델은 설정된 입출력을 이용하여 추론 컨테이너의 추론을 모사하 도록 구성될 수 있다. 이에 의해, 모사 학습 컨테이너는 추론 컨테이너의 추론 결과와 유사한 모사 추론 결과에 작용한 입력 피쳐(input feature) 및 입력 피쳐의 중요도 중 적어도 하나를 포함하는 해석 정보를 제공할 수 있다. 해석 정보가 모사 추론 결과에 기반할지라도, 추론 결과의 원인을 설명하는 정보로 채용될 수 있다. 모사 학습 컨테이너는 예컨대, DNN과 같은 심층 신경망 모델의 입출력 행동을 모사하면서 이용자가 이해가 능한 구조를 갖는 의사 결정 트리 또는 선형회귀 등과 같은 학습 모델일 수 있다. 의사 결정 트리의 경우, 의사 결정 트리에 의한 학습 과정 및 결과에 기초하여, 추론 결과에 작용한 입력 피쳐 및 그 중요도가 해석 정보로 제공될 수 있다. 다음으로, 프로세서, 예컨대 해석 제어기는 추론 서비스 디스크립터의 상태 정보에 기초하여, 추론 서 비스의 이용을 요구하는 추론 요청 메시지 및 요청에 대한 추론 응답 메시지를 모사 학습 컨테이너로 전송 하는 미러링 설정을 수행할 수 있다(S115). 해석 제어기는 추론 서비스의 디스크립터에 정의된 추론 컨테이너의 제 1 액세스 정보에 기반하여 미 러링 설정을 수행할 수 있다. 구체적으로, 해석 제어기는 상기 디스크립터에 사전 정의된 추론 서비스의 URL을 토대로, 해당 URL로 전송되는 추론 요청 메시지 등을 모사 학습 컨테이너로 미러링하는 인그레스 설 정을 진행할 수 있다. 이에 따라, 추론 서비스 디스크립터는 추론 요청 메시지 등이 포워딩되기 위한 제 2 액세 스 정보를 포함하는 미러링 설정 정보를 더 포함하도록 구성될 수 있다. 제 2 액세스 정보는 API 설정을 위해, 상기 모사 학습 컨테이너의 IP 주소 또는 도메인 네임을 갖도록 생성될 수 있다. 도 7는 인그레스 설정에 의해 미러링이 설정된 추론 서비스 디스크립터(descriptor)를 예시한 도면이다. Spec-rule 하단에 표기된 HTTP 프로토콜 및 URL Path가 /testpath 로 지정된 요청이라면, 추론 요청 메시지 및 추론 응답 메시지는 추론 컨테이너의 엔드포인트로 연결된 테스트 서비스의 80번 포트로 전달하도록 설정될 수 있다. 해석 제어기는 미러링 위한 인그레스 설정에 있어서, 인그레스의 추론 서비스 디스크립터의 메타데이터에 'nginx.ingress.kubernetes.io/mirror-target: https://test.env.com/$request_uri' 필드를 추가함으로써, API 미러링이 설정될 수 있다. 모사 학습 컨테이너의 IP주소 또는 도메인 네임이 Mirror-target 필드의 값 으로 입력될 수 있다. 도 5의 실시예는 실제 운영할 추론 컨테이너가 생성된 후에 모사 학습 컨테이너가 생성되는 것을 상 정하고 있다. 다른 예에서, 추론 서비스에 기초한 모사 학습 컨테이너가 생성되고 미러링이 설정된 후, 이용자 클라이언트로부터 추론 서비스에 기반한 추론 요청 메시지가 전송될 때, 실제의 추론 컨테이너가 생성될 수도 있다. 구체적으로, 프로세서, 예컨대 해석 제어기는 S105 단계에서 생성된 추론 서비스에 따른 추론 서비스 디스크립터에 정의된 상태 정보에 기초하여 모사 학습 컨테이너를 구성할 수 있다. 이어서, 해석 제어기는 상태 정보에 기초하여, 추론 요청 메시지 및 추론 응답 메시지를 모사 학습 컨테이너로 전송하는 미러링 설정을 수행할 수 있다. 상태 정보 및 미러링 설정은 도 5에서 설명한 것과 실질적으로 동일하다. 다음 으로, 프로세서, 예컨대 추론 서비스 제어기는 이용자 클라이언트로부터 수신된 추론 요청 메시 지에 응답하여, 추론 서비스의 디스크립터에 따른 하위 리소스를 생성할 수 있다. 하위 리소소는 인그레스 레이 어, 서비스 레이어 및 추론 컨테이너를 포함할 수 있다. 도 8 및 도 9를 참조하여, 본 개시의 실시예에 따른 인공지능 기반 추론 서비스의 해석 자동화 방법에 대하여 설명하기로 한다. 도 8은 본 개시의 실시예에 따른 인공지능 기반 추론 서비스의 해석 자동화 방법에 관한 순서도이다. 도 9는 본 개시의 실시예에 따른 해석 자동화 플랫폼 장치에 있어서, 추론 컨테이너 및 모사 학습 컨테이너의 동작 과정을 모듈 별로 설명하는 도면이다. 도 8을 참조하면, 클라우드 인프라스트럭쳐의 프로세서는 이용자 클라이언트로부터 추론 요청 메 시지를 수신하여 해당 추론 컨테이너로 전달할 수 있다(S205). 도 4에 예시된 바와 같이, 추론 요청 메시지는 DNS로 전송되어, DNS는 추론 요청에 상응하는 추론 컨 테이너의 URL의 IP를 조회할 수 있다. HTTP 취득(GET) 요청 메시지는 DNS로 조회된 IP를 포함하여 프 로세서, 예컨대 인그레스 레이어를 제어하는 인그레스 제어기로 전송할 수 있다. 이 때, HTTP의 헤더에는 도 9에 예시된 바와 같이, 'http:''inference-flower.com과 같은 URL이 명시될 수 있다. 인그레스 제 어기는 추론 요청 메시지를 수신하여 헤더의 URL을 조회할 수 있다. 인그레스 제어기는 미리 설정된 서비스 엔드포인트를 지시하는 인그레스 레이어로 포워딩할 수 있다. 이어서, 추론 요청은 인그레스 제어에 의해, 인그레스 레이어, 서비스 레이어 및 엔드포인트를 경유하여 해당 추론 컨테이너 로 전달될 수 있다. 이어서, 추론 컨테이너는 추론 요청 메시지에 기초하여, 추론 서비스에 따른 추론 컨테이너에 추론 응답 메시지를 출력할 수 있다(S210). 추론 응답 메시지는 예컨대, 추론 컨테이너에 포함된 심층 학습 모델에 의해 생성된 추론 결과일 수 있다. 다음으로, 인그레스 제어기는 미러링 설정에 의해, 추론 컨테이너와 연동된 모사 학습 컨테이너(13 4)에 추론 요청 메시지 및 추론 응답 메시지를 전달할 수 있다(S215). 인그레스 제어기는 인그레스와 관련된 추론 서비스 디스크립터에 표기된 제 2 액세스 정보를 참조하여, 상 기 메시지들을 모사 학습 컨테이너로 전송할 수 있다. 계속해서, 모사 학습 컨테이너는 자신의 학습 모델을 이용하여, 추론 요청 메시지에 따른 모사 추론 결과 를 출력하고, 모사 추론 결과와 추론 응답 메시지에 의한 추론 결과를 서로 비교하는 과정으로 모사 추론 결과 를 확인할 수 있다(S220). 다음으로, 모사 학습 컨테이너가 임계 조건을 충족하는지를 판정할 수 있다(S225). 임계 조건은 모사 학습 컨테이너의 모사 추론 결과가 추론 응답 메시지에 따른 추론 결과에 대하여, 기준 값 이상의 유사도를 갖는 조건으로 설정될 수 있다. 예시로 설명하면, 추론 요청이 이용자에 의해 전송된 이미 지에 포함된 객체 정보인 꽃 이름을 도출하는 경우, 추론 컨테이너가 추론 결과로 국화를 출력한 경우, 모 사 학습 컨테이너가 모사 학습 결과로 국화 또는 적어도 국화와 매우 유사한 꽃을 제시한다면, 모사 학습 컨테이너는 모사 추론 결과가 추론 결과에 대하여 기준값 이상의 유사도를 갖는다고 판정할 수 있다. 반면에, 모사 학습 컨테이너가 모사 학습 결과 국화와 현저히 유사하지 꽃 이름을 제시하면, 모사 학습 컨 테이너는 모사 추론 결과가 추론 결과에 대하여 기준값 미만의 유사도를 갖는다고 판정할 수 있다. 이어서, 모사 추론 결과의 추론 응답 메시지에 대한 유사도가 기준값 이상 인 경우(S225의 Y인 경우), 인그레스 제어기는 추론 응답 메시지와 함께, 모사 추론 결과 및 이의 해석 정보를 이용자 클라이언트로 제공 하도록 제어할 수 있다(S230).해석 정보는 모사 추론 결과가 기준값 이상의 유사도로 임계 조건을 충족하면 생성될 수 있다. 해석 정보는 모 사 학습 컨테이너의 모사 추론 결과에 작용한 정보이며, 상기 정보는 추론 결과의 원인을 설명할 수 있다. 해석 정보는 예컨대, 입력 피쳐(input feature) 및 상기 입력 피쳐의 중요도 중 적어도 하나를 포함할 수 있다. 모사 학습 컨테이너가 의사 결정 트리로 구성된 학습 모델을 구비하고, 추론 결과가 상술한 꽃 이름인 경우로 예시하 면, 입력 피쳐는 이미지에 포함된 꽃, 잎, 줄기 등과 같은 세부 객체의 형태에서 추론 결과를 도출하는데 작용 된 세부 객체의 형태이고, 입력 피쳐의 중요도는 세부 객체의 가중치 또는 트리 구조에서 위치하는 노드 레벨 등일 수 있다. 이와는 달리, 모사 추론 결과의 추론 응답 메시지에 대한 유사도가 기준값 미만인 경우(S225의 N인 경우), 모사 학습 컨테이너는 S210 단계에서 출력된 모사 추론 결과를 폐기하고, 자신의 모델을 계속적으로 학습시켜 모사 추론 결과를 출력하도록 제어할 수 있다(S235). S235 단계 이후, S225 단계에서 요구되는 임계 조건을 만족할 때까지, 모사 학습 컨테이너는 S220 및 S225 단계를 반복할 수 있다. 구체적으로, S225 단계에서 요구되는 임계 조건을 만족할 때까지, 모사 학습 컨테이너 는 추론 요청 메시지에 기반하여 재차 학습하고, 학습에 의해 출력된 후속 모사 출력 결과와 추론 결과를 비교하여, 후속 모사 출력 결과가 임계 조건을 충족한지를 판정할 수 있다. 만약 충족한다면, 모사 학습 컨테이 너는 임계 조건을 만족한 모사 출력 결과에 따른 해석 정보를 생성하며, 모사 추론 결과와 해석 정보를 인 그레스 제어기로 전송할 수 있다. 인그레스 제어기는 별도로 모사 추론 결과와 해석 정보를 이용자 클라이언트로 제공할 수 있다. 다른 예로, 인그레스 제어기는 추론 응답 메시지와 함께, 모사 추론 결과 및 해석 정보를 제공할 수도 있다. 상술의 과정에서는 모사 학습 컨테이너가 모사 출력 결과와 추론 결과를 비교하는 것으로 기재하였으나, 다른 예로, 인그레스 제어기가 모사 출력 결과와 추론 결과를 비교하며, 임계 조건을 충족한 모사 추론 결 과 및 해석 정보를 이용자 클라이언트로 제공하도록 제어할 수 있다. 다른 예에서, 인그레스 제어기 는 모사 추론 결과가 임계 조건을 충족하지 못한다고 판정한 경우, 모사 학습 컨테이너에서 모사 추론 결 과를 폐기함과 아울러서, 해석 정보를 생성하지 않도록 제어할 수도 있다. 본 개시의 예시적인 방법들은 설명의 명확성을 위해서 동작의 시리즈로 표현되어 있지만, 이는 단계가 수행되는 순서를 제한하기 위한 것은 아니며, 필요한 경우에는 각각의 단계가 동시에 또는 상이한 순서로 수행될 수도 있 다. 본 개시에 따른 방법을 구현하기 위해서, 예시하는 단계에 추가적으로 다른 단계를 포함하거나, 일부의 단 계를 제외하고 나머지 단계를 포함하거나, 또는 일부의 단계를 제외하고 추가적인 다른 단계를 포함할 수도 있 다. 본 개시의 다양한 실시 예는 모든 가능한 조합을 나열한 것이 아니고 본 개시의 대표적인 양상을 설명하기 위한 것이며, 다양한 실시 예에서 설명하는 사항들은 독립적으로 적용되거나 또는 둘 이상의 조합으로 적용될 수도 있다. 또한, 본 개시의 다양한 실시 예는 하드웨어, 펌웨어(firmware), 소프트웨어, 또는 그들의 결합 등에 의해 구현 될 수 있다. 하드웨어에 의한 구현의 경우, 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 범용 프로세서(general processor), 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 본 개시의 범위는 다양한 실시 예의 방법에 따른 동작이 장치 또는 컴퓨터 상에서 실행되도록 하는 소프트웨어 또는 머신-실행가능한 명령들(예를 들어, 운영체제, 애플리케이션, 펌웨어(firmware), 프로그램 등), 및 이러한 소프트웨어 또는 명령 등이 저장되어 장치 또는 컴퓨터 상에서 실행 가능한 비-일시적 컴퓨터-판독가능 매체 (non-transitory computer-readable medium)를 포함한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2022-0039162", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시를 설명하기 위한 클라우드를 이용하는 인공지능 기반 추론 서비스에 적용되는 해석 자동화 시스 템의 예시도이다. 도 2는 본 개시의 실시예에 따른 인공지능 기반 추론 서비스의 해석 자동화 플랫폼 장치의 개략 구성도이다. 도 3은 본 개시의 실시예에 따른 인공지능 기반 추론 서비스의 해석 자동화 플랫폼 장치에서, 인그레스 (ingress) 레이어, 서비스 레이어 및 엔드포인트(endpoint) 간의 리소스 연계를 예시한 도면이다. 도 4는 인그레스 레이어의 동작을 예시한 도면이다. 도 5는 본 개시의 실시예에 따른 인공지능 기반 추론 서비스의 해석 자동화 방법에서 수행되는 모사 학습 컨테 이너의 생성 및 미러링 설정에 관한 순서도이다. 도 6은 모사 학습 컨테이너의 생성 및 미러링 설정이 본 개시의 실시예에 따른 해석 자동화 플랫폼 장치에서 구 현되는 과정을 예시한 도면이다. 도 7는 인그레스 설정에 의해 미러링이 설정된 추론 서비스 디스크립터(descriptor)를 예시한 도면이다. 도 8은 본 개시의 실시예에 따른 인공지능 기반 추론 서비스의 해석 자동화 방법에 관한 순서도이다. 도 9는 본 개시의 실시예에 따른 해석 자동화 플랫폼 장치에 있어서, 추론 컨테이너 및 모사 학습 컨테이너의 동작 과정을 모듈 별로 설명하는 도면이다."}
