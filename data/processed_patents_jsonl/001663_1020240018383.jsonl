{"patent_id": "10-2024-0018383", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0176760", "출원번호": "10-2024-0018383", "발명의 명칭": "거대 생성 인공지능 하드웨어의 스트리밍 연산을 위한 가중치 메모리 매핑 방법 및 시스템", "출원인": "주식회사 하이퍼엑셀", "발명자": "김준수"}}
{"patent_id": "10-2024-0018383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "가중치 메모리 매핑 시스템에 있어서,사전 학습된 인공지능 모델을 위한 가중치 행렬을 저장하는 가중치 메모리;복수의 인풋 데이터를 저장하는 인풋 레지스터;상기 복수의 인풋 데이터와 상기 가중치 행렬간의 행렬 곱 연산을 처리하되, 상기 행렬 곱 연산의 부분합을 재사용하여 상기 행렬 곱 연산의 진행 중에 최종합을 계산하는 제1 하드웨어 연산기; 및 상기 최종합을 이용하여 상기 행렬 곱 연산의 진행 중에 다음 행렬 곱 연산을 미리 처리하는 제2 하드웨어 연산기를 포함하는 가중치 메모리 매핑 시스템."}
{"patent_id": "10-2024-0018383", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "거대 생성 인공지능 하드웨어의 스트리밍 연산을 위한 가중치 메모리 매핑 방법 및 시스템이 제공된다. 일실시 예에 따른 가중치 메모리 매핑 시스템은 사전 학습된 인공지능 모델을 위한 가중치 행렬을 저장하는 가중치 메모 리, 복수의 인풋 데이터를 저장하는 인풋 레지스터, 상기 복수의 인풋 데이터와 상기 가중치 행렬간의 행렬 곱 연산을 처리하되, 상기 행렬 곱 연산의 부분합을 재사용하여 상기 행렬 곱 연산의 진행 중에 레인(lane) 단위의 최종합을 계산하는 제1 하드웨어 연산기 및 상기 최종합을 이용하여 상기 행렬 곱 연산의 진행 중에 다음 행렬 곱 연산을 미리 처리하는 제2 하드웨어 연산기를 포함할 수 있다."}
{"patent_id": "10-2024-0018383", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예들은 거대 생성 인공지능 하드웨어의 스트리밍 연산을 위한 가중치 메모리 매핑 방법 및 시스 템에 관한 것이다."}
{"patent_id": "10-2024-0018383", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "생성형 인공지능 모델의 경우 대부분 트랜스포머의 구조를 채택하여 높은 성능을 보이고 있다. 하지만 트랜스 포머의 경우 연산의 병렬성이 적기 때문에 레이턴시가 중요하다. 하드웨어의 레이턴시를 줄이기 위해서는 효율 적인 가중치 매핑 방법이 요구된다. [선행문헌번호] 한국공개특허 제10-2022-0164573호"}
{"patent_id": "10-2024-0018383", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "거대 생성 인공지능 하드웨어의 스트리밍 연산을 위한 가중치 메모리 매핑 방법 및 시스템을 제공할 수 있다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과 제들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0018383", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "가중치 메모리 매핑 시스템에 있어서, 사전 학습된 인공지능 모델을 위한 가중치 행렬을 저장하는 가중치 메모 리; 복수의 인풋 데이터를 저장하는 인풋 레지스터; 상기 복수의 인풋 데이터와 상기 가중치 행렬간의 행렬 곱 연산을 처리하되, 상기 행렬 곱 연산의 부분합을 재사용하여 상기 행렬 곱 연산의 진행 중에 레인(lane) 단위의 최종합을 계산하는 제1 하드웨어 연산기; 및 상기 최종합을 이용하여 상기 행렬 곱 연산의 진행 중에 다음 행렬 곱 연산을 미리 처리하는 제2 하드웨어 연산기를 포함하는 가중치 메모리 매핑 시스템을 제공한다. 일측에 따르면, 상기 부분합은 상기 가중치 행렬의 하나의 열과 상기 복수의 인풋 데이터간의 행렬 곱셈의 결과 를 포함하고, 상기 레인 단위의 최종합은 상기 가중치 행렬의 레인 단위의 열들 각각과 상기 복수의 인풋 데이 터간의 행렬 곱셈의 결과로서의 부분합들이 축적된 값을 포함하는 것을 특징으로 할 수 있다. 다른 측면에 따르면, 상기 제1 하드웨어 연산기는, 상기 레인 단위로 상기 행렬 곱 연산을 처리하는 복수의 MAC(multiply-and-accumulation) 트리; 상기 행렬 곱 연산의 부분합을 저장하는 부분합 레지스터; 및 상기 부분 합 레지스터의 부분합들을 축적하여 상기 레인 단위의 최종합을 계산하는 복수의 부분합 어큐물레이터를 포함하 는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 복수의 MAC 트리의 수와 상기 복수의 부분합 어큐물레이터의 수는 각각 레인의 수 에 대응하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 제2 하드웨어 연산기는 상기 복수의 부분합 어큐물레이터 중 적어도 하나의 부분 합 어큐물레이터가 계산한 상기 레인 단위의 최종합을 이용하여 상기 다음 연산을 미리 처리하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 인공지능 모델은 트랜스포머 모델을 포함하고, 상기 가중치 메모리는 상기 트랜스 포머 모델을 위한 토큰 임베딩 연산과 LM(Language Modeling) 헤드 연산을 위한 공유된 가중치 데이터를 상기 가중치 행렬로서 저장하고, 상기 제1 하드웨어 연산기는 상기 토큰 임베딩 연산 시, 상기 가중치 메모리의 특정 열의 가중치를 읽어와 상기 토큰 임베딩 연산을 처리하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 가중치 메모리 매핑 시스템은 상기 가중치 메모리에 저장된 상기 가중치 행렬의 값들의 위치를 상기 행렬 곱 연산의 다음 연산에 요구되는 값들이 서로 이웃하도록 상기 행렬 곱 연산 이전에 조정하는 전처리 라우팅부를 더 포함할 수 있다. 또 다른 측면에 따르면, 상기 인공지능 모델은 트랜스포머 모델을 포함하고, 상기 다음 연산은 상기 트랜스포머 모델을 위한 로터리 임베딩 연산을 포함하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 인공지능 모델은 트랜스포머 모델을 포함하고, 상기 가중치 메모리 매핑 시스템은 상기 트랜스포머 모델의 로터리 임베딩 연산을 위한 로터리 임베딩 파라미터의 하나의 포지션의 사인 값 및 코 사인 값 각각을 고정소수점 8비트로 양자화한 후 양자화된 사인 값 및 코사인 값을 16비트로 패킹한 세트를 상 기 가중치 메모리에 저장하는 로터리 임베딩 파라미터 처리부를 더 포함할 수 있다. 또 다른 측면에 따르면, 상기 로터리 임베딩 파라미터 처리부는 상기 세트의 포지션을 채널 수로 나눈 값과 헤 드번호로 결정되는 채널 및 상기 세트의 포지션을 채널 수로 나눈 나머지 값으로 결정되는 주소에 따라 상기 세 트를 상기 가중치 메모리에 저장하거나 상기 세트를 상기 가중치 메모리에서 읽어오는 것을 특징으로 할 수 있 다. 가중치 메모리 매핑 방법에 있어서, 사전 학습된 인공지능 모델을 위한 가중치 행렬을 가중치 메모리에 저장하 는 단계; 복수의 인풋 데이터를 인풋 레지스터에 저장하는 단계; 제1 하드웨어 연산기를 통해 상기 복수의 인풋 데이터와 상기 가중치 행렬간의 행렬 곱 연산을 처리하되, 상기 행렬 곱 연산의 부분합을 재사용하여 상기 행렬 곱 연산의 진행 중에 레인(lane) 단위의 최종합을 계산하는 단계; 및 제2 하드웨어 연산기를 통해 상기 최종합 을 이용하여 상기 행렬 곱 연산의 진행 중에 다음 행렬 곱 연산을 미리 처리하는 단계를 포함하는 가중치 메모 리 매핑 방법을 제공한다. 기타 실시예들의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2024-0018383", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "거대 생성 인공지능 하드웨어의 스트리밍 연산을 위한 가중치 메모리 매핑 방법 및 시스템을 제공할 수 있다."}
{"patent_id": "10-2024-0018383", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 청구범위의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0018383", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2024-0018383", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 하나의 구성 요소가 다른 구성 요소와 \"연결된(connected to)\" 또는 \"커플링된(coupled to)\" 이라고 지칭되는 것은, 다른 구성 요소와 직접 연결 또는 커플링된 경우 또는 중간에 다른 구성 요소를 개재한 경우를 모두 포함 한다. 반면, 하나의 구성 요소가 다른 구성 요소와 \"직접 연결된(directly connected to)\" 또는 \"직접 커플링된 (directly coupled to)\"으로 지칭되는 것은 중간에 다른 구성 요소를 개재하지 않은 것을 나타낸다. \"및/또는\" 은 언급된 아이템들의 각각 및 하나 이상의 모든 조합을 포함한다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성 요소, 단계, 동작 및/또는 소자는 하나 이상의 다 른 구성 요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 비록 제1, 제2 등이 다양한 구성 요소들을 서술하기 위해서 사용되나, 이들 구성 요소들은 이들 용어에 의해 제 한되지 않음은 물론이다. 이들 용어들은 단지 하나의 구성 요소를 다른 구성 요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성 요소 일 수도 있 음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해 석되지 않는다. 도 1은 본 발명의 실시예에 따른 레이턴시 프로세싱 유닛의 구조의 예를 도시한 도면이다. 도 1을 참조하면, 본 발명의 실시예에 따른 LPU(레이턴시 프로세싱 유닛(Latency Processing Unit), 100)은 SMA(간소화 메모리 액세스(Streamlined Memory Access), 110), OIU(피연산자 발행 유닛(Operand Issue Unit), 120), SXE(간소화 실행 엔진(Streamlined eXecution Engine), 130), VXE(벡터 실행 엔진(Vector eXecution Engine), 140), LMU(로컬 메모리 유닛(Local Memory Unit)), 150), ISU(명령어 스케줄링 유닛(Instruction Scheduling Unit)), 160), PCIe 인터페이스(PCIe(Peripheral Component Interconnect express) Interface,170), P2P 인터페이스(P2P(Peer to Peer) Interface, 180)를 포함할 수 있다. SMA는 특수 DMA(Direct Memory Access)일 수 있다. 일례로, SMA는 HBM의 모든 채널(일례로, 32개)을 실행 엔진(일례로, SEE)에 연결하여 최대 대역폭에서 FP16(half precision floating point) 데이 터를 전송할 수 있다. SMA는 사전 로드된 메모리(MEM) 명령어를 기반으로 연속 메모리 요청을 전송하기 위해 심층 FIFO(First In First Out)로 설계될 수 있다. 하드웨어를 고려한 메모리 매핑은 행렬의 변경 혹은 전치 작업을 제거함으로써 지연시간을 단축시킬 수 있다. 따라서 SMA는 최대 버스트 크기로 수신된 데이 터를 최소한의 지연으로 실행 엔진으로 스트리밍할 수 있다. SMA는 또한 스트로브(strobe) 신호를 사용하 여 행렬의 전치(transpose)를 효율적으로 실행할 수 있다. 스트리밍 데이터는 벡터 매트릭스 실행(예: 가중치, 편향) 및 기타 벡터 관련 실행(예: 감마/베타, 임베딩)을 위한 매개변수를 포함할 수 있다. OIU는 실행 엔진에 발행하기 전에 SMA에서 스트리밍된 데이터(일례로, 제1 피연산자)와 온칩 메모리 에서의 입력(일례로, 제2 피연산자)을 조정할 수 있다. 실행(EXE) 명령을 기반으로 OIU는 실행 엔진을 구 성하고 피연산자의 대상 엔진을 결정하는 마이크로코드를 생성할 수 있다. 또한 OIU에는 정적 피연산자 (예: 입력 벡터)의 읽기 대기 시간을 제거하기 위해 재사용 버퍼가 배치되고 스칼라(예: 바이어스)로 사용되는 벡터화된 데이터를 유지하기 위해 비대칭 버퍼가 배치될 수 있다. 따라서 적절한 피연산자는 거의 항상 프리페 치되어 실행 엔진에 즉시 발행될 준비가 된다. SXE는 LPU의 주요 컴퓨팅 하드웨어로서, 어텐션, 1D 컨볼루션, 피드포워드 네트워크와 같은 벡터-매 트릭스 곱셈(vector-matrix multiplication, V·M)을 실행하기 위해 들어오는 대역폭을 최대한 활용하도록 설계 될 수 있다. SXE는 HBM의 수신 대역폭과 연산 대역폭을 일치시킬 수 있는 수의 MAC(multiply-and- accumulation) 트리(MAC Tree, 131)를 포함할 수 있다. 예를 들어, HBM으로부터 매 사이클마다 1024개의 요소를 수신한다면 64개의 입력 벡터를 가진 MAC 트리 16개를 통해 수신 대역폭과 연산 대역폭을 일치시킬 수 있다. 그리고 64개의 입력 벡터를 가진 MAC 트리는 64개의 곱셈기와 63개의 덧셈기로 구성될 수 있다. 복수의 MAC 트리는 행렬 곱 연산을 수행할 수 있으며, 외부 메모리이자 고대역 메모리인 HBM과 SMA를 통해 채널별로 연결될 수 있다. 구체적으로, 복수의 MAC 트리 중 하나는 하나의 채널을 통해 HBM과 연결됨으로써 LPU와 HBM 사이의 전송 대역폭을 극대화하며 초거대 인공지능 모델에 필요 한 행렬 곱 연산을 병목현상 없이 수행할 수 있다. 따라서 복수의 MAC 트리의 개수와 HBM의 메모리 채널의 개수는 동일하게 구성될 수 있다. 복수의 MAC 트리의 행렬 곱 연산 결과는 VXE으로 제공될 수 있다. VXE는 사용자 지정 저지연 ALU(Arithmetic Logic Unit)를 사용하여 구현될 수 있으며, 토큰 임베딩, 소프트맥스, 정규화 및 잔차 연산과 같은 벡터 작업을 실행할 수 있다. 이러한 벡터 작업은 상대적으로 덜 자주 발생하므로 OIU에서 이 경로 로의 팬인(fan-in)을 조정하여 무시할 수 있는 성능 손실로 하드웨어 리소스를 줄일 수 있다. VXE는 복수 의 MAC 트리의 연산 결과를 제공받는 한편 LMU로부터 활성화 값을 전달받아 후속 연산을 수행할 수 있다. VXE는 복수의 다기능 연산 데이터패스를 포함함으로써 다양한 연산기 조합을 포함하도록 구성될 수 있다. LMU는 복수의 MAC 트리와 VXE으로 활성화 값을 전달할 수 있다. 이때 LMU는 복수의 MAC 트리에 대하여 동일한 활성화 값을 전달하기 위하여 활성화 값을 복사하여 전송할 수 있다. 또한, LMU는 복수의 MAC 트리와 VXE이 연산한 결과값을 저장할 수 있다. 다시 말해, LMU는 HBM에 대응하는 내부 버퍼로서 LPU 내에서 기능할 수 있다. 이때 LPU는 행렬 곱셈 연산에 있어 서 재사용율이 높은 활성화 값 또는 모델의 매개변수를 LMU에 저장하고 재사용율이 낮은 가중치를 HBM에 저장할 수 있다. LMU는 입력, 출력 및 중간 데이터의 빠른 고대역폭 액세스를 위해 스칼라 벡 터 분리가 있는 4MB 다중 뱅크 레지스터 파일로 구현될 수 있다. 또한 LMU는 OIU와 실행 엔진의 쓰 기 저장 단계에서 동시 읽기 및 쓰기를 지원하는 다중 포트일 수 있다. ISU는 LPU의 전체 실행 흐름을 제어할 수 있다. ISU는 PIC(Parallel Instruction Chaining) 방식을 이용할 수 있으며, 명령어 체이닝을 사용하면 종속 명령어를 연속적으로 실행할 수 있다. PIC는 독립적 인 하드웨어가 필요한 명령을 종속 명령의 그룹(예: 메모리(MEM) 명령, 실행(EXE) 명령, 네트워크(NET) 명령)으 로 분리하므로 모든 명령이 각 그룹의 명령 체인과 병렬로 실행되어 낮은 제어 오버헤드 및 대기 시간 절약을 달성할 수 있다. ISU는 또한 엔진 실행을 위해 제어 레지스터(예: 토큰 및 계층 번호)를 업데이트할 수 있다. 내부 스케줄러는 하드웨어 활용도를 최대화하기 위해 SXE 및 VXE의 비순차적 실행을 지원하며 강력한 스코어보드는 데이터 위험을 처리하도록 설계될 수 있다. 예를 들어, ISU는 복수의 MAC 트리와 VXE가 동시에 연산을 수행할 수 있도록 스케쥴링할 수 있다. 또한 ISU는 병렬 연산을 최대화하 기 위해 종속성이 없는 명령어를 미리 실행함으로써, 각각의 연산 장치와 메모리 접근 장치의 쉬는 시간(idle time)을 최소화함으로써 연산 처리량 및 지연 시간을 향상시킬 수 있다. LPU는 PCIe 인터페이스를 통해 호스트 컴퓨터와 연결될 수 있으며, 호스트 컴퓨터로부터 LPU의 동작에 필요한 명령어, 초거대 인공지능 모델의 입력값 및 가중치를 전달받아 연산을 수행한 후 그 결과를 호스 트 컴퓨터로 전달할 수 있다. LPU는 P2P 인터페이스를 통해 연결된 복수의 LPU들의 클러스터로 스케일 아웃(scale-out)될 수 있다. 확장된 클러스터 구조는 초거대 인공지능 모델의 연산의 가속을 더욱 향상시킬 수 있다. 도 2 내지 도 5는 본 발명의 실시예들에 따른 LPU들의 구현 모델의 예를 도시한 도면들이다. 앞서 도 1의 실시 예에서는 HBM의 외부 메모리를 사용하는 구현 모델의 예를 설명하였다. 외부 메모리로는 HBM 대신 DDR(Double Data Rate)이 이용될 수도 있다. 이때, 거대 모델은 하나의 디바이스에 저장되기 어렵기 때문에 복 수의 파티션으로 분리될 수 있으며, 복수의 디바이스들(복수의 LPU들)을 위한 외부 메모리들에 파티션별로 저장 될 수 있다. 이 경우, 거대 모델의 추론을 위해 복수의 디바이스들간의 동기화가 요구될 수 있다. 도 2의 실시예에서는 앞서 도 1의 실시예에서 설명한 것과 유사하게, 거대 모델의 복수의 파티션들을 저장 하는 복수의 외부 메모리들, 그리고 복수의 외부 메모리들과 병렬적으로 연결되는 복수의 LPU들(33 0)을 나타내고 있다. 하나의 LPU는 하나의 FPGA(Field Programmable Gate Array)에 구현될 수 있으며, 하나의 파티션이 하나의 FPGA에 병렬적으로 연결될 수 있다. 트랜스포머 구조가 디코더 레이어 안에 멀티헤드 어텐션, 레이어 노멀라이제이션, 피드 포워드 등을 포함하고 있는데, 멀티헤드 어텐션과 피드 포워드를 모델 병렬화시킬 수 있다. 이 경우 멀티헤드 어텐션이 종료되면, 임베딩 벡터 하나가 결과로 출력될 수 있다. 하나의 디바이스 에서는 임베딩 벡터의 포션만을 갖고 있기 때문에 다음 연산으로 넘어가기 위해서는 복수의 디바이스들이 각 임 베딩 벡터를 공유할 필요가 있기 때문에 동기화가 요구될 수 있다. 이때, 확장성을 고려하면, 하나의 LPU가 복 수의 외부 메모리(일례로, 2개나 4개 등)를 갖는 형태로 구현될 수도 있다. 일례로, 도 1의 실시예에서는 각각 하나의 파티션이 저장된 두 개의 HBM이 사용된 예를 나타내고 있다. 도 3의 실시예에서는 PIM(Processing-in-Memory) 모델의 예로서, 하나의 LPU가 PIM 칩으로 구현되어 파티션과 LPU 연산부가 모두 하나의 칩에 집적되는 형태로 구현된 예를 나타내고 있다. 도 3의 실시예에서는 각각 PIM 칩으로 구현될 수 있는 복수의 LPU, 복수의 파티션들, 그리고 복수의 LPU 연산부들을 나타내고 있다. 이때, 복수의 LPU 각각이 하나의 파티션과 하나의 LPU 연산부를 포함할 수 있다. 도 4의 실시예에서는 PNM(Processing-near-Memory) 모델의 예를 나타내고 있다. 하나의 PIM 칩 안에 모든 LPU 연산의 처리를 위한 구성이 포함되기 어려울 수 있다. 도 4의 실시예에서는 복수의 메모리 칩에는 복수의 파티션들을 저장하고, PNM 칩과 같은 버퍼 칩에서 LPU의 연산을 위한 LPU 연산부를 포함하는 형 태의 모델을 나타내고 있다. 도 5의 실시예에서는 PIM과 PNM이 결합된 모델의 예를 나타내고 있다. 일례로, 복수의 메모리 칩에는 복 수의 파티션들이 저장될 수 있다. 또한, 복수의 메모리 칩 각각에는 MAC 트리와 같은 축적부로서의 PIM 방식 LPU 연산부들이 구현될 수 있다. 이때, 버퍼 칩에 LPU의 나머지 하이-레벨 오퍼레이션을 위한 LPU 연산부가 PNM 방식으로 구현될 수 있다. 도 6은 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛의 행렬 곱 연산을 위한 고대역 메모리의 가중치 행 렬 데이터 매핑을 설명하기 위한 도면이다. 도 6을 참조하면, 본 실시예에 따른 LPU는 복수의 MAC 트리를 구성하는 MAC 트리의 개수와 SMA 의 메모리 채널의 개수가 동일한 점으로부터 각각의 MAC 트리의 행렬 곱 연산 시 다른 메모리 채널에 접근하지 않고도 가중치 데이터를 불러올 수 있도록 HBM과 같은 고대역 메모리에 매핑된 가중치 행렬 데이터를 저장할 수 있다. 구체적으로, 가중치 행렬의 열 방향(D1)으로 복수의 MAC 트리의 개수만큼 각 채널(620-n)에 매핑되도록 고 대역 메모리에 가중치 행렬 데이터가 저장될 수 있다. 가중치 행렬에서 열 방향은 행렬 곱 연산이 병렬적 으로 수행될 수 있기 때문에 복수의 MAC 트리는 각각의 할당된 메모리 채널(620-n)에서 열 방향 데이터를 읽어와 행렬 곱 연산을 진행할 수 있다. 그 다음 복수의 MAC 트리가 가중치 행렬의 행 방향(D2)으로 축적하여 최종 연산 결과를 완성할 수 있도록 가중치 행렬 데이터를 매핑할 수 있다. 고대역 메모리의 대역폭에 의해 한번에 매핑되는 행 데이터의 개수 가 결정될 수 있으며, 이는 복수의 MAC 트리가 한번에 처리할 수 있는 타일의 크기로 결정될 수 있다. 도 7은 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛에 포함된 고대역 메모리 인터페이스를 설명하기 위 한 도면이다. 도 7을 참조하면, SMA는 LMU, 복수의 MAC 트리 및 고대역 메모리를 연결할 수 있다. SMA는 LPU의 다른 연산 유닛들과는 연결되지 않으며, 따라서 고대역 메모리 인터페이스를 하드웨어 리소스 측면에서 최소화할 수 있다. 복수의 MAC 트리와 메모리 채널(620-n)은 각각 일대일 대응으로 연결될 수 있다. 즉, 복수의 MAC 트리 는 직접적으로 할당된 채널 이외의 다른 채널에 접근할 필요가 없어 리소스를 많이 사용하여 지연 시간이 큰 복잡한 예를 들어 크로스바(cross-bar)와 같은 인터페이스를 사용하지 않고 행렬 곱 연산을 수행할 수 있다. SMA는 복수의 MAC 트리가 고대역 메모리에 저장된 가중치 행렬 데이터를 불러오는 읽기 인터페 이스 만을 구성할 수 있다. 다시 말해, 뒤에서 설명하는 것과 같이 연산의 결과는 LMU를 통해 고대역 메 모리에 저장되므로, 복수의 MAC 트리의 고대역 메모리에 대한 쓰기 인터페이스는 구성되지 않고 하드웨어 리소스가 그만큼 감소될 수 있다. 이와는 반대로 SMA는 LMU와 고대역 메모리 사이에 쓰기 인터페이스만을 구성할 수 있다. SMA를 통해 내부 버퍼로써의 LMU에 저장된 연산 결과가 고대역 메모리에 기록되기 위해 전송될 수 있으며, 디멀티플렉서를 이용하여 기록 대상의 메모리 채널을 선택할 수 있다. 도 8은 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛에 포함된 재구성 가능한 다기능 연산 유닛을 설명하 기 위한 도면이다. 도 8을 참조하면, VXE는 복수의 다기능 연산 데이터패스(810, 820)를 포함할 수 있으며, 복수의 다기능 연 산 데이터패스(810, 820)는 연산자/결과값 체인 네트워크와 연결되어 다양한 연산기 조합을 구성할 수 있 다. 도 8에 도시된 것과 같이 복수의 다기능 연산 데이터패스(810, 820)는 예를 들어 룩업 테이블 기반 비선형 활성 화 함수, 마스킹 연산 등에 필요한 다양한 연산 유닛을 포함할 수 있으며, 다만 도 8에 도시된 재구성 가능한 다기능 연산 데이터패스(810, 820)의 연산 유닛의 구성은 예시적인 것으로 거대 모델 연산에 필요한 추가적인 연산 유닛도 얼마든지 다기능 연산 데이터패스(810, 820)에 포함될 수 있음은 물론이다. VXE에 의해 연산 된 결과는 LMU로 전달될 수 있다. 도 9는 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛에 포함된 주소 기반 비순차적 다중유닛 스케쥴러의 구성을 설명하기 위한 도면이다. 도 9를 참조하면, 본 실시예에 따른 LPU에 포함된 주소 기반 비순차적 다중유닛 스케쥴러로서의 ISU 는 주소 기반 명령어 종속성 판단 및 스케쥴링 컨트롤러, 복수의 명령어 이슈 컨트롤러들(921, 922, 923, 924), 다중 뱅크 버퍼 주소 상태 테이블, 명령어 버퍼 및 결과 주소 상태 업데이트 로직, 다중 유닛 명렁어 디스패처를 포함할 수 있다. ISU는 주소 기반 명령어 종속성 판단 및 스케쥴링 컨트롤러와 복수의 명령어 이슈 컨트롤러들(921, 922, 923, 924)을 통해 각 연산 장치들과 데이터 이동 유닛들을 동시에 동작시킬 수 있다. 이때, ISU는 각 연산 장치에서 수행되는 명령어에 대한 다중 뱅크 버퍼 주소 상태 테이블의 연산자 주소 및 결과 주소 의 상태를 1로 바꿀 수 있다. 다중 뱅크 버퍼 주소 상태 테이블은 결과 주소 상태 업데이트 로직을 통해 수행이 끝난 명령어의 결 과 주소의 상태를 0으로 바꿀 수 있다. 주소 기반 명령어 종속성 판단 및 스케쥴링 컨트롤러는 다중 뱅크 버퍼 주소 상태 테이블을 통해 주 소의 상태들을 참조하여 수행해야 할 명령어와 수행 중인 명령어 사이의 종속성과, 수행해야 할 명령어들 사이 의 종속성을 판단할 수 있다. 이를 통해 종속성이 없는 명령어를 미리 처리할 수 있게 함으로써 각 연산 장치 및 데이터 이동 유닛의 쉬는 시간을 최소화할 수 있다. ISU에 포함된 주소 기반 명령어 종속성 판단 및 스케쥴링 컨트롤러는 명령어 버퍼로부터 명령어 를 로딩하여 처리할 수 있다. 이때, 주소 기반 명령어 종속성 판단 및 스케쥴링 컨트롤러는 루프(loop)명령어를 수행하며, 이 외의 명령어들은 디코딩하여 명령어들을 구분해 다중유닛 명령어 디스패처를 통해 디바이스 투 디바이스 명령어 이슈 컨트롤러, 직접 메모리 접근 명령어 이슈 컨트롤러, MAC 트리 명 령어 이슈 컨트롤러 및 재구성 가능한 다기능 연산 유닛 명령어 이슈 컨트롤러로 전달할 수 있다. ISU는 PCIe 인터페이스를 통해 호스트 컴퓨터로부터 LPU의 명령어들을 입력 받아 저장하며, 현 재 LPU의 상태를 상태 레지스터(register)에 저장할 수 있다. 호스트 컴퓨터는 PCIe 인터페이스를 통해 해당 상태 레지스터를 확인할 수 있다. 한편, 인공지능의 가중치는 사전에 학습되어 인공지능 모델의 추론시에는 외부 메모리에서 불러와 연산을 처리 한다. 따라서 가중치에 대해 런타임에서 처리할 필요가 없는 경우, 미리 최대한 최적화를 한 후 인공지능 모델 의 추론을 처리하는 하드웨어에 넘겨줄 수 있다. 본 발명의 실시예들에서는 거대 생성 인공지능 하드웨어를 위 한 메모리 매핑 방법 및 시스템을 제공할 수 있다. 인공지능 하드웨어에서는 인풋(input), 가중치(weight) 및 아웃풋(output) 중 어떤 것을 재사용하면서 연산할 것인지 결정해야 한다. 일례로, 트랜스포머 기반의 모델의 경우, 추론시 가중치를 재사용할 수 없기 때문에, 인풋과 아웃풋 중 어느 것을 재사용해서 하드웨어의 레이턴시를 줄이고 효율적으로 연산할 수 있는지 결정해야 한다. 또한 런타임에서 수행하는 경우에 비효율적인 연산이 있는지 판단하고, 이러한 연산을 매핑시에 처리할 수 있는 지 확인해야 한다. 파라미터의 분포나 최대 값 및/또는 최소 값을 활용하여 양자화를 진행할 수도 있어야 한다. 본 발명의 실시예들에 따른 메모리 매핑 방법 및 시스템은 하드웨어의 레이턴시를 줄이는 것에 초점을 두어서 구현되어 있다. 현재 연산의 아웃풋이 다음 연산의 인풋으로 연결되어 있는 트랜스포머의 구조는 아웃-오브-오 더(out-of-order) 등의 연산기 활용률을 높이는 방법들을 사용할 수 없다. 따라서 최종 결과값이 빠르게 나와 서 다음 연산을 더 빨리 처리할 수 있는 방법을 채택하여야 한다. 본 발명의 실시예들에서는 아웃풋 재사용 메 모리 매핑 방법을 기반으로 하여 최종합이 빠르게 나오는 방법을 사용하여서, 다음 연산을 진행하여 연산기 효 율을 늘릴 수 있도록 하였다. 또한 토큰 임베딩과 LM(Language Modeling) 헤드 연산과 같이 같은 가중치를 서로 다른 방식으로 이용할 때의 매핑 방법론도 제안하였다. LM 헤드 연산의 경우 행렬 곱이고, 토큰 임베딩의 경우 특정 주소의 벡터를 읽는 것 이기 때문에 매핑 방법이 달라야 한다. 하지만 서로 가중치 데이터 자체는 같기 때문에 외부 메모리에 매핑을 각각 다르게 하면 중복된 데이터들이 써져서 외부 메모리를 효율적으로 사용할 수 없다. 이를 해결하기 위해서 행렬 곱 매핑 방법에서 토큰 임베딩을 하는 방법을 제안하였다. 또한, 본 발명의 일실시예에서는 로터리(rotary) 임베딩시 발생할 수 있는 하드웨어 라우팅 복잡도를 줄이기 위 해 전용 매핑 방법을 제공할 수 있다. 본 실시예에 따른 가중치 메모리 매핑 방법 및 시스템에서는 가중치 메 모리 매핑시에 미리 라우팅을 없애서 런타임 하드웨어에서는 이와 관련된 레이턴시를 줄여서 진행할 수 있다. 도 10 및 도 11은 본 발명의 일실시예에 있어서, 인풋 재사용과 부분합(아웃풋) 재사용의 개념을 설명하기 위한 도면들이다. 가중치를 배치할 때는 인풋 한번 불러와서 재사용할지, 아니면 아웃풋을 한번 저장하고 재사용할 지 결정할 수 있다. 도 10에서와 같이 인풋을 재사용하는 경우 부분합의 개수가 행 개수만큼 늘어나서 행 개수 만큼의 FIFO(First In First Out) 자원을 사용하여야 한다. 반대로 도 11에서와 같이 부분합을 재사용하는 경 우 열 개수만큼의 인풋 데이터를 레지스터에 저장해 두기 위한 자원을 사용하여야 한다. 다시 말해, 둘 중 어 느 방법을 사용하건, 트랜스포머에서는 행과 열의 크기가 대체로 동일하기 때문에 하드웨어 자원 사용량은 동일 하다. 하지만 최종 결과가 어느 시점에 나오는지 차이가 있다. 인풋을 재사용하는 경우에는 최종합들이 마지 막에 연속적으로 계산되는 반면, 부분합을 재사용하면 빠르게 최종합이 계산될 수 있다. 본 발명의 실시예들에 서는 레이턴시를 줄이는 것이 목표이기 때문에, 최종합이 조금이라도 빠르게 계산되는 것이 좋다. 일례로, 연 산에 참여하지 않는 연산기가 있다면 먼저 계산된 최종합을 이용하여 미리 다음 연산을 수행할 수 있기 때문이 다. 도 12는 본 발명의 일실시예에 따른 부분합 재사용에 기반한 가중치 메모리 매핑 시스템의 개괄적인 모습의 예 를 도시한 도면이다. 본 실시예에 따른 가중치 메모리 매핑 시스템은 가중치 메모리, 인풋 레지스 터 및 하드웨어 연산기를 포함할 수 있다. 여기서, 하드웨어 연산기는 앞서 설명한 LPU에 대응할 수 있다. 또한, 가중치 메모리는 사전 학습된 인공지능 모델의 가중치 행렬을 저장하 는 메모리로서 HBM에 대응할 수 있다. 앞서 부분합 재사용을 위해 열 개수(가중치 행렬의 열 개수)만큼의인풋 데이터를 저장하기 위해 레지스터가 요구됨을 설명한 바 있으며, 인풋 레지스터는 이러한 인풋 데이 터를 저장하기 위한 레지스터에 대응할 수 있다. 도 12의 실시예에서는 레인(lane)이 4인 경우의 예를 나타내고 있다. 이를 위해, 하드웨어 연산기는 4개 의 MAC 트리와 4개의 부분합 어큐뮬레이터를 포함할 수 있으며, 부분합을 저장하기 위한 부분합 레 지스터를 더 포함할 수 있다. 하드웨어 연산기는 스트림라인(streamline)으로 가중치 메모리 의 데이터를 읽어올 수 있고, MAC 트리를 통해 바로 부분합들을 계산하여 부분합 레지스터에 저장할 수 있으며, 부분합 어큐뮬레이터를 통해 부분합들을 축적하여 최종합들이 행렬 곱 연산의 중간에 빠르게 계산될 수 있다. 이처럼, 도 11에 나타난 바와 같이 최종합들이 연산의 마지막이 아니라 중간에 빠르게 계산되기 때문에, 연산에 참여하지 않는 제2 하드웨어 연산기가 있다면, 제2 하드웨어 연산기가 먼 저 계산된 최종합을 부분합 어큐물레이터로부터 제공받고, 제공받은 최종합을 이용하여 미리 다음 연산을 수행할 수 있어 하드웨어의 레이턴시를 줄일 수 있다. 일례로, 제2 하드웨어 연산기는 다른 LPU에 대응 할 수 있다. 도 13은 본 발명의 일실시예에 있어서, 데이터 중복 제거의 예를 도시한 도면이다. 트랜스포머에서는 토큰 임 베딩 연산과 LM 헤드 연산이 있다. 도 13의 실시예에서는 트랜스포머 자체에 대해서는 이미 잘 알 려져 있기 때문에 토큰 임베딩 연산과 LM 헤드 연산만을 표시하고 있다. 이러한 토큰 임베딩 연산과 LM 헤드 연산은 가중치 데이터를 공유한다. 다시 말해, HBM에 어느 한곳에만 저장해 두고 토큰 임베딩 연산 시에는 해당 주소에 벡터를 읽고, LM 헤드 연산 시에는 가중치를 가지고 행 렬 곱 연산을 진행하는 것이 가능하다. 하지만 이렇게 같은 데이터를 가지고 다른 연산을 하는 경우, GPU에서 는 아예 다른 데이터라고 보고 HBM에 가중치 데이터를 중복으로 저장해 놓는 경우가 발생하며, 이는 HBM의 낭비로 이어진다. 본 실시예에서는 행렬 곱을 위한 메모리 매핑에서 토큰 임베딩도 처리할 수 있다. 도 13에 나타난 바와 같이 부분합 재사용 방법으로 메모리 매핑을 처리하면 데이터가 한 줄(하나의 열)에 다 모여있는 것을 알 수 있 다. 따라서 토큰 임베딩 시에는 어떤 레인의 몇 번째 열에서 가중치 데이터를 읽어 올 것 인지만 정하면 필요한 가중치 데이터를 쉽게 읽어올 수 있다. 이 경우, HBM의 대역폭을 완전하게 활용하는 것은 아니지 만 데이터를 중복에서 저장하지 않아도 되기 때문에 메모리 낭비를 줄일 수 있다. 도 14는 본 발명의 일실시예에 있어서, 행렬 곱 연산의 처리 예를 도시한 도면이다. 본 실시예에서는 로터리 (rotary) 임베딩 연산의 예를 설명하고 있으나, 이에 한정되는 것은 아니다. 로터리 임베딩의 경우 행렬 곱 연 산을 한 후에 가중치 행렬에서 0번 값과 64번 값간의 연산을 하고, 1번 값과 65번 값간의 연산을 하는 등 가중 치 행렬에서 서로 멀리 떨어진 값들간의 연산을 처리하게 된다. 이를 하드웨어로 구현할 시에 하드웨어 라우팅 을 혼잡하게 만드는 것은 물론, 서로 연산하고자 하는 값들이 너무 멀리 떨어져 있으면 스트리밍한 처리가 어려 울 수 있다. 따라서 컴파일러 단에서 가중치 행렬의 값들의 위치를 바꾸면, 복잡한 하드웨어 라우팅 없이 바로 옆에 있는 데 이터간의 연산을 처리할 수 있다. 전처리 과정에서 전처리 라우팅이 생기지만, 런타임에서는 하드웨어 라우팅 을 없앨 수 있기 때문에 하드웨어적으로 이득을 얻을 수 있다. 또한 이렇게 임의로 가중치 행렬의 값들간의 순서를 바꾸어도, 다음 연산이 순서에 상관없는 내적 연산이기 때 문에, 런타임에서는 라우팅에 관한 오버헤드가 전혀 없다. 도 15 및 도 16은 본 발명의 일실시예에 있어서, 로터리 임베딩 연산을 처리하는 과정의 예를 도시한 도면들이 다. 로터리 임베딩 연산은 사인(sin) 연산과 코사인(cos) 연산을 진행한다. 하지만 사인 연산과 코사인 연산 의 결과는 -1에서 1의 범위를 가지고 있기 때문에, 일반적인 부동소수점 16비트(float16)를 사용하면 효율적이 지 않다. 소스 코드 레벨 시뮬레이터를 활용하여 고정소수점 8비트로 양자화를 진행하여도 연산 정확도에는 전 혀 문제가 없는 것을 확인하였으며, 이에 본 실시예에서는 8비트 두 개를 패킹하여 16비트로 사인 값 및 코사인 값을 하나의 세트로 묶어 사용함으로써 메모리 사용량을 줄일 수 있다. 또한 사인 값, 코사인 값은 헤드 개수 만큼, 포지션 개수만큼 존재한다. 이를 HBM과 같은 메모리에 저장해두고 읽어올 때는 메모리 채널과 주소 를 결정하면 읽어올 수 있다. 도 17은 본 발명의 일실시예에 따른 가중치 메모리 매핑 시스템의 내부 구성의 예를 도시한 블록도이고, 도 18 은 본 발명의 일실시예에 따른 가중치 메모리 매핑 방법의 예를 도시한 흐름도이다. 본 실시예에 따른 가중치 메모리 매핑 시스템은 가중치 메모리, 인풋 레지스터, 전처리 라우 팅부, 로터리 임베딩 파라미터 처리부 및 복수의 하드웨어 연산기를 포함할 수 있다. 실시 예에 따라 가중치 메모리는 복수의 하드웨어 연산기 각각을 위한 가중치 메모리들의 집합일 수도 있다. 예를 들어, 가중치 메모리들 각각은 앞서 설명한 HBM에 대응할 수 있다. 또한 실시예에 따라, 가 중치 메모리 매핑 시스템이 포함하는 구성요소들 중 적어도 일부는 물리적으로 상이한 하드웨어 장치로 구현될 수도 있다. 일례로, 복수의 하드웨어 연산기 각각이 개별 하드웨어 장치로 구현되고, 가중치 메 모리, 인풋 레지스터, 전처리 라우팅부 및 로터리 임베딩 파라미터 처리부가 또 다른 하드웨어 장치로 구현될 수도 있다. 각 하드웨어 장치들은 네트워크로 연결되어 서로 통신할 수 있다. 또한, 적어도 일부의 구성요소가 가중치 메모리 매핑 시스템에서 제외되거나 추가적인 구성요소가 더 포함될 수 도 있다. 예를 들어, 트랜스포머 모델을 위한 로터리 임베딩 연산을 처리하지 않는 실시예를 위해, 로터리 임 베딩 파라미터 처리부가 가중치 메모리 매핑 시스템에서 제외될 수 있다. 다른 예로, 가중치 메모 리 매핑 시스템은 입출력 장치와의 연결을 위한 입출력 인터페이스를 더 포함하거나 통신 인터페이스를 더 포함할 수도 있다. 단계에서 가중치 메모리 매핑 시스템은 사전 학습된 인공지능 모델을 위한 가중치 행렬을 가중치 메모리에 저장할 수 있다. 여기서 가중치 메모리에 저장되는 가중치 행렬은 인공지능 모델의 전체 가중치 행렬 중 일부일 수도 있다. 예를 들어, 거대 인공지능 모델을 복수의 파티션으로 분리하여 복수의 LPU 들을 통해 처리하는 경우, 복수의 LPU들 각각을 위한 가중치 메모리들이 존재할 수 있으며, 각 LPU에서 처리할 가중치 행렬이 해당 LPU에 대응하는 가중치 메모리에 저장될 수 있다. 본 실시예에서 가중치 메모리는 복수의 하드웨어 연산기 중 하나인 제1 하드웨어 연산기를 위한 가중치 행렬을 저장할 수 있다. 단계에서 가중치 메모리 매핑 시스템은 전처리 라우팅부를 통해 가중치 메모리에 저장 된 가중치 행렬의 값들의 위치를 행렬 곱 연산의 다음 연산에 요구되는 값들이 서로 이웃하도록 조정할 수 있다. 일례로, 인공지능 모델은 트랜스포머 모델인 경우, 다음 연산은 트랜스포머 모델을 위한 로터리 임베딩 연산을 포함할 수 있으나, 이에 한정되는 것은 아니다. 만약, 행렬 곱 연산 이후의 연산에서 흩어진 값들간의 연산을 요구하는 경우, 가중치 메모리 매핑 시스템은 해당 연산을 위해 미리 가중치 행렬의 값들의 위치 를 조정할 수 있다. 실시예에 따라 단계는 생략될 수도 있다. 단계에서 가중치 메모리 매핑 시스템은 로터리 임베딩 파라미터 처리부를 통해 트랜스포머 모델의 로터리 임베딩 연산을 위한 로터리 임베딩 파라미터의 하나의 포지션의 사인 값 및 코사인 값 각각을 고 정소수점 8비트로 양자화한 후 양자화된 사인 값 및 코사인 값을 16비트로 패킹한 세트를 가중치 메모리 에 저장할 수 있다. 이 경우, 로터리 임베딩 파라미터 처리부는 세트의 포지션을 채널 수로 나눈 값과 헤드번호로 결정되는 채널 및 세트의 포지션을 채널 수로 나눈 나머지 값으로 결정되는 주소에 따라 세트를 가 중치 메모리에 저장하거나 세트를 가중치 메모리에서 읽어올 수 있다. 이러한 단계는 트랜 스포머 모델의 로터리 임베딩 연산을 위한 것으로 실시예에 따라 생략될 수도 있다. 또한, 단계과 단계 는 그 순서가 변경될 수도 있다. 단계에서 가중치 메모리 매핑 시스템은 복수의 인풋 데이터를 인풋 레지스터에 저장할 수 있 다. 부분합 재사용을 위해서는 복수의 인풋 데이터와 가중치 행렬의 열 각각간의 행렬 곱 연산이 연속적으로 발생할 수 있다. 따라서, 복수의 인풋 데이터가 가중치 행렬의 열 개수만큼 반복적으로 이용되기 때문에 가중 치 메모리 매핑 시스템은 이러한 복수의 인풋 데이터를 인풋 레지스터에 저장해놓을 수 있다. 단계에서 가중치 메모리 매핑 시스템은 제1 하드웨어 연산기를 통해 복수의 인풋 데이터와 가중치 행렬간의 행렬 곱 연산을 처리하되, 행렬 곱 연산의 부분합을 재사용하여 행렬 곱 연산의 진행 중에 레 인(lane) 단위의 최종합을 계산할 수 있다. 여기서, 제1 하드웨어 연산기는 도 12를 통해 설명한 제1 하 드웨어 연산기에 대응할 수 있다. 다시 말해, 제1 하드웨어 연산기는 레인 단위로 행렬 곱 연산을 처리하는 복수의 MAC 트리, 행렬 곱 연산의 부분합을 저장하는 부분합 레지스터 및 부분합 레지스 터의 부분합들을 축적하여 레인 단위의 최종합을 계산하는 복수의 부분합 어큐물레이터를 포함할 수 있다. 이때, 복수의 MAC 트리의 수와 복수의 부분합 어큐물레이터의 수는 각각 레인의 수에 대 응할 수 있다. 예를 들어, 레인의 수가 4라면, 복수의 MAC 트리의 수와 복수의 부분합 어큐물레이터 의 수도 각각 4가 될 수 있다. 한편, 부분합은 가중치 행렬의 하나의 열과 복수의 인풋 데이터간의 행렬 곱셈의 결과를 포함할 수 있다. 또한, 레인 단위의 최종합은 가중치 행렬의 레인 단위의 열들 각각과 복수의 인풋 데이터간의 행렬 곱셈의 결과로서의 부분합들이 축적된 값을 포함할 수 있다. 단계에서 가중치 메모리 매핑 시스템은 제2 하드웨어 연산기를 통해 최종합을 이용하여 행렬 곱 연산의 진행 중에 다음 행렬 곱 연산을 미리 처리할 수 있다. 제2 하드웨어 연산기는 복수의 하드웨 어 연산기 중 현재 연산에 참여하지 않고 있는 연산기일 수 있다. 다시 말해, 가중치 메모리 매핑 시스 템은 빠르게 계산된 최종합을 현재 연산에 참여하지 않고 있는 연산기로서의 제2 하드웨어 연산기 로 전달하여 다음 연산을 미리 처리할 수 있다. 이때, 제2 하드웨어 연산기는 복수의 부분합 어큐물레이 터 중 적어도 하나의 부분합 어큐물레이터가 계산한 레인 단위의 최종합을 이용하여 다음 연산을 미리 처 리할 수 있다. 또한 실시예에 따라 인공지능 모델이 트랜스포머 모델인 경우, 트랜스포머 모델을 위한 토큰 임베딩 연산과 LM 헤드 연산은 가중치 데이터를 공유할 수 있다. 이를 위해, 단계에서 가중치 메모리 매핑 시스템은 공유된 가중치 데이터를 가중치 행렬로서 가중치 메모리에 저장할 수 있다. 또한, 단계에서 가중 치 메모리 매핑 시스템은 제1 하드웨어 연산기를 통해 토큰 임베딩 연산 시, 가중치 메모리의 특정 열의 가중치를 읽어와 토큰 임베딩 연산을 처리할 수 있다. 일례로, 앞서 LPU가 포함하는 VXE에서 토큰 임베딩, 소프트맥스, 정규화 및 잔차 연산과 같은 벡터 작업을 실행할 수 있음에 대해 설명한 바 있다. 이처럼, 본 발명의 실시예들에 따르면, 거대 생성 인공지능 하드웨어의 스트리밍 연산을 위한 가중치 메모리 매 핑 방법 및 시스템을 제공할 수 있다."}
{"patent_id": "10-2024-0018383", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상 첨부된 도면을 참조하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있 다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적 이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2024-0018383", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 레이턴시 프로세싱 유닛의 구조의 예를 도시한 도면이다. 도 2 내지 도 5는 본 발명의 실시예들에 따른 LPU들의 구현 모델의 예를 도시한 도면들이다. 도 6은 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛의 행렬 곱 연산을 위한 고대역 메모리의 가중치 행 렬 데이터 매핑을 설명하기 위한 도면이다. 도 7은 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛에 포함된 고대역 메모리 인터페이스를 설명하기 위 한 도면이다.도 8은 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛에 포함된 재구성 가능한 다기능 연산 유닛을 설명하 기 위한 도면이다. 도 9는 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛에 포함된 주소 기반 비순차적 다중유닛 스케쥴러의 구성을 설명하기 위한 도면이다. 도 10 및 도 11은 본 발명의 일실시예에 있어서, 인풋 재사용과 부분합(아웃풋) 재사용의 개념을 설명하기 위한 도면들이다. 도 12는 본 발명의 일실시예에 따른 부분합 재사용에 기반한 가중치 메모리 매핑 시스템의 개괄적인 모습의 예 를 도시한 도면이다. 도 13은 본 발명의 일실시예에 있어서, 데이터 중복 제거의 예를 도시한 도면이다. 도 14는 본 발명의 일실시예에 있어서, 행렬 곱 연산의 처리 예를 도시한 도면이다. 도 15 및 도 16은 본 발명의 일실시예에 있어서, 로터리 임베딩 연산을 처리하는 과정의 예를 도시한 도면들이 다. 도 17은 본 발명의 일실시예에 따른 가중치 메모리 매핑 시스템의 내부 구성의 예를 도시한 블록도이다. 도 18은 본 발명의 일실시예에 따른 가중치 메모리 매핑 방법의 예를 도시한 흐름도이다."}
