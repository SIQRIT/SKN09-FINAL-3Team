{"patent_id": "10-2021-0094253", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0013468", "출원번호": "10-2021-0094253", "발명의 명칭": "딥러닝 기반의 입천장심장얼굴 증후군", "출원인": "서울대학교병원", "발명자": "조안나"}}
{"patent_id": "10-2021-0094253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "대상자의 얼굴 이미지를 입력 받는 입력부; 및딥러닝 기반의 미리 학습된 예측 모델로서, 입력된 얼굴 이미지에 기초하여 대상자의 입천장심장얼굴 증후군(VCFS) 발현 가능성을 예측하는 예측 모델을 포함하되, 상기 예측 모델은 상기 대상자의 입천장심장얼굴 증후군(VCFS) 발현 가능성과 연관된 정보를 시각화한 정보를더 제공하는, 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 시스템."}
{"patent_id": "10-2021-0094253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 예측 모델은, 입력된 얼굴 이미지에서 얼굴 영역을 검출하고 정렬하여 표준화된 얼굴 이미지를 생성하는 전처리부;상기 표준화된 얼굴 이미지에서 피처 맵(feature map)을 추출하는 합성곱 계층; 상기 추출된 피처 맵(feature map)을 기초로 입천장심장얼굴 증후군(VCFS)에 의한 안면 표현형일 확률 값을 출력하도록 구성된 전-연결 계층; 및상기 시각화한 정보를 생성하는 데이터 시각화부를 포함하는, 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단지원 시스템."}
{"patent_id": "10-2021-0094253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 시각화한 정보는 상기 전-연결 계층이 결과를 얻기 위해 특정 레이어의 어떤 위치에 있는 특징들을 이용했는지 시각화하여 나타낸 히트맵을 상기 입력된 얼굴 이미지와 함께 표시한 클래스 활성화 맵이며, 상기 클래스 활성화 맵은 상기 대상자의 얼굴 이미지에 입천장심장얼굴 증후군(VCFS) 발현 가능성에 대한 판단시 기여도가 타 얼굴 영역보다 높은 얼굴 영역을 표시하도록 구성되는 것을 특징으로 하는, 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 시스템."}
{"patent_id": "10-2021-0094253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서, 상기 히트맵은 Grad-CAM(gradient-weighted class activation mapping)을 통해 생성되며, 상기 Grad-CAM은 하기 수학식 1과 같이 구현되는 것을 특징으로 하는, 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 시스템.[수학식 1], 공개특허 10-2023-0013468-3-(: 합성곱 계층 구조의 마지막 단의 출력이자 전-연결 계층의 입력 값, : 합성곱 계층의 k번째에 있는 특징맵, Z: 특징 맵의 크기, ReLU는 음의 값을 0으로 만드는 활성 함수이다)"}
{"patent_id": "10-2021-0094253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2 항에 있어서,상기 합성곱 계층은 ResNet(residual networks)으로 구성되고, 상기 전처리부는 MTCNN(Multi-task cascadedconvolutional networks)으로 구성되는 것을 특징으로 하는, 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단지원 시스템."}
{"patent_id": "10-2021-0094253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서, 상기 얼굴 이미지는 정면 얼굴 이미지인 것을 특징으로 하는, 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단지원 시스템."}
{"patent_id": "10-2021-0094253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "대상자의 얼굴 이미지를 입력 받는 단계; 상기 입력된 얼굴 이미지에 따른 대상자의 입천장심장얼굴 증후군(VCFS) 발현 가능성을 딥러닝 기반의 미리 학습된 예측 모델을 통해 예측하는 단계; 및상기 예측 모델을 통해 상기 입천장심장얼굴 증후군(VCFS) 발현 가능성과 연관된 정보를 시각화한 정보를 제공하는 단계를 포함하는, 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 방법."}
{"patent_id": "10-2021-0094253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서, 상기 입력된 얼굴 이미지에 따른 대상자의 입천장심장얼굴 증후군(VCFS) 발현 가능성을 딥러닝 기반의 미리 학습된 예측 모델을 통해 예측하는 단계는, 상기 예측 모델의 전처리부가, 입력된 얼굴 이미지에서 얼굴 영역을 검출하고 정렬하여 표준화된 얼굴 이미지를생성하는 단계; 상기 예측 모델의 합성곱 계층이, 상기 표준화된 얼굴 이미지에서 피처 맵(feature map)을 추출하는 단계; 및상기 예측 모델의 전-연결 계층이, 상기 추출된 피처 맵(feature map)을 기초로 입천장심장얼굴 증후군(VCFS)에의한 안면 표현형일 확률 값을 출력하는 단계를 포함하는, 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 방법."}
{"patent_id": "10-2021-0094253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서, 상기 시각화한 정보는 상기 전-연결 계층이 결과를 얻기 위해 특정 레이어의 어떤 위치에 있는 특징들을 이용했는지 시각화하여 나타낸 히트맵을 상기 입력된 얼굴 이미지와 함께 표시한 클래스 활성화 맵이며, 상기 클래스 활성화 맵은 상기 대상자의 얼굴 이미지에 입천장심장얼굴 증후군(VCFS) 발현 가능성에 대한 판단시 기여도가 타 얼굴 영역보다 높은 얼굴 영역을 표시하도록 구성되는 것을 특징으로 하는, 딥러닝 기반의 입천공개특허 10-2023-0013468-4-장심장얼굴 증후군(VCFS) 진단 지원 방법."}
{"patent_id": "10-2021-0094253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서, 상기 히트맵은 Grad-CAM(gradient-weighted class activation mapping)을 통해 생성되며, 상기 Grad-CAM은 하기 수학식 1과 같이 구현되는 것을 특징으로 하는, 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 방법.[수학식 1], (: 합성곱 계층 구조의 마지막 단의 출력이자 전-연결 계층의 입력 값, : 합성곱 계층의 k번째에 있는 특징맵, Z: 특징 맵의 크기, ReLU는 음의 값을 0으로 만드는 활성 함수이다)"}
{"patent_id": "10-2021-0094253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8 항에 있어서, 상기 입력된 얼굴 이미지에서 얼굴 영역을 검출하고 정렬하여 표준화된 얼굴 이미지를 생성하는 단계는MTCNN(Multi-task cascaded convolutional networks)으로 구성되는 전처리부에서 수행되고, 상기 표준화된 얼굴 이미지에서 피처 맵(feature map)을 추출하는 단계는 ResNet(residual networks)으로 구성되는 합성곱 계층에서 수행되는 것을 특징으로 하는, 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 방법."}
{"patent_id": "10-2021-0094253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7 항에 있어서,상기 얼굴 이미지는 정면 얼굴 이미지인 것을 특징으로 하는, 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단지원 방법."}
{"patent_id": "10-2021-0094253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제7 항 내지 제12 항 중 어느 한 항에 따른 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 방법을 구현하기 위한, 컴퓨터로 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2021-0094253", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 시스템 및 방법이 제공된다. 상기 시스템은 대상자의 얼 굴 이미지를 입력 받는 입력부; 및 딥러닝 기반의 미리 학습된 예측 모델로서, 입력된 얼굴 이미지에 기초하여 대상자의 VCFS 발현 가능성을 예측하는 예측 모델을 포함하되, 상기 예측 모델은 상기 대상자의 VCFS 발현 가능 성과 연관된 정보를 시각화한 정보를 더 제공한다."}
{"patent_id": "10-2021-0094253", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 입천장심장얼굴 증후군(VCFS) 진단 지원 시스템 및 방법에 관한 것으로, 더욱 상세하게는 딥러닝 기 반의 예측 모델을 이용하여 환자의 얼굴 이미지로부터 VCFS에 의한 얼굴 표현 여부를 예측하고, 연관된 얼굴 영 역의 클래스 활성화 맵을 제공함으로써 의료인의 VCFS 진단을 지원할 수 있는 시스템 및 방법에 관한 것입니다."}
{"patent_id": "10-2021-0094253", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "입천장심장얼굴 증후군(Velocardiofacial syndrome; VCFS)은 22번 염색체 장완 11.2 부위의 미세결실로 발생하 는 복합 질환에 해당한다. VCFS는 심장기형, 저칼슘혈증, 갑상선호르몬 이상, 면역저하 등의 합병증이 발생하는 질환으로, 합병증의 치료와 예방을 위해서 VCFS의 정확한 조기 진단이 요구된다. 그러나, VCFS는 발생 빈도가 매우 드문 질환이어서 환자의 안면에 표현된 다양한 특징을 전문의가 파악한 후 유 전자 검사를 시행하여 최종 확진이 가능하며, VCFS를 주로 진료하는 전문가가 아닌 의료진이 조기에 의심하고 진단하는데 어려움이 있다. 최근 빠른 속도로 발전하고 있는 기계학습(machine learning) 기반 인공지능 기술로 인해, 환자들의 데이터를 활용하여 특정 질병의 발생을 예측하거나 관리하는 것이 가능해졌다. 특히, 기계학습 모델은 기존의 회귀 모델 (regression models)과 비교하여 많은 기능을 통합할 수 있으므로 비선형 알고리즘을 사용할 수 있게 하고, 그 결과 다양한 질병 발생 예측 분야에서 신경망(neural network) 모델과 같은 기계학습 방법을 채택한 다양한 연 구가 보고되고 있다. 이에, 본 출원의 발명자들은 VCFS의 조기 진단에 도움을 주고자 딥러닝 기반의 VCFS의 안면 특징을 구분할 수 있는 기술을 제안하고자 한다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-2241483"}
{"patent_id": "10-2021-0094253", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에 본 발명은, 본 발명은 딥러닝을 이용하여 환자의 얼굴 이미지로부터 VCFS에 의한 얼굴 표현 여부를 예측하 고, 연관된 얼굴 영역의 클래스 활성화 맵을 제공함으로써 의료인의 VCFS 진단을 지원할 수 있는 시스템 및 방 법을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2021-0094253", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 시스템은 대상자의 얼굴 이미지를 입 력 받는 입력부; 및 딥러닝 기반의 미리 학습된 예측 모델로서, 입력된 얼굴 이미지에 기초하여 대상자의 VCFS 발현 가능성을 예측하는 예측 모델을 포함하되, 상기 예측 모델은 상기 대상자의 VCFS 발현 가능성과 연관된 정 보를 시각화한 정보를 더 제공한다. 실시예에서, 상기 예측 모델은 입력된 얼굴 이미지에서 얼굴 영역을 검출하고 정렬하여 표준화된 얼굴 이미지를 생성하는 전처리부; 상기 표준화된 얼굴 이미지에서 피처 맵(feature map)을 추출하는 합성곱 계층; 상기 추출 된 피처 맵(feature map)을 기초로 VCFS에 의한 안면 표현형일 확률 값을 출력하도록 구성된 전-연결 계층; 및 상기 시각화한 정보를 생성하는 데이터 시각화부를 포함할 수 있다. 실시예에서, 상기 시각화한 정보는 상기 전-연결 계층이 결과를 얻기 위해 특정 레이어의 어떤 위치에 있는 특 징들을 이용했는지 시각화하여 나타낸 히트맵을 상기 입력된 얼굴 이미지와 함께 표시한 클래스 활성화 맵이며, 상기 클래스 활성화 맵은 상기 대상자의 얼굴 이미지에 VCFS 발현 가능성에 대한 판단 시 기여도가 타 얼굴 영 역보다 높은 얼굴 영역을 표시하도록 구성될 수 있다. 실시예에서, 상기 히트맵은 Grad-CAM(gradient-weighted class activation mapping)을 통해 생성될 수 있다. 실시예에서, 상기 합성곱 계층은 ResNet(residual networks)으로 구성되고, 상기 전처리부는 MTCNN(Multi-task cascaded convolutional networks)으로 구성될 수 있다. 실시예에서, 상기 얼굴 이미지는 정면 얼굴 이미지일 수 있다. 다른 실시예에 따른 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 방법은 대상자의 얼굴 이미지를 입 력 받는 단계; 상기 입력된 얼굴 이미지에 따른 대상자의 VCFS 발현 가능성을 딥러닝 기반의 미리 학습된 예측 모델을 통해 예측하는 단계; 및 상기 예측 모델을 통해 상기 VCFS 발현 가능성과 연관된 정보를 시각화한 정보를 제공하는 단계를 포함한다. 실시예에서, 상기 입력된 얼굴 이미지에 따른 대상자의 VCFS 발현 가능성을 딥러닝 기반의 미리 학습된 예측 모 델을 통해 예측하는 단계는 입력된 얼굴 이미지에서 얼굴 영역을 검출하고 정렬하여 표준화된 얼굴 이미지를 생 성하는 단계; 상기 표준화된 얼굴 이미지에서 피처 맵(feature map)을 추출하는 단계; 및 상기 추출된 피처 맵 (feature map)을 기초로 VCFS에 의한 안면 표현형일 확률 값을 출력하는 단계를 포함할 수 있다. 실시예에서, 상기 시각화한 정보는 상기 전-연결 계층이 결과를 얻기 위해 특정 레이어의 어떤 위치에 있는 특 징들을 이용했는지 시각화하여 나타낸 히트맵을 상기 입력된 얼굴 이미지와 함께 표시한 클래스 활성화 맵이며, 상기 클래스 활성화 맵은 상기 대상자의 얼굴 이미지에 VCFS 발현 가능성에 대한 판단 시 기여도가 타 얼굴 영 역보다 높은 얼굴 영역을 표시하도록 구성될 수 있다. 실시예에서, 상기 히트맵은 Grad-CAM(gradient-weighted class activation mapping)을 통해 생성될 수 있다. 실시예에서, 상기 입력된 얼굴 이미지에서 얼굴 영역을 검출하고 정렬하여 표준화된 얼굴 이미지를 생성하는 단 계는 MTCNN(Multi-task cascaded convolutional networks)으로 구성되는 전처리부에서 수행되고, 상기 표준화 된 얼굴 이미지에서 피처 맵(feature map)을 추출하는 단계는 ResNet(residual networks)으로 구성되는 합성곱 계층에서 수행될 수 있다. 실시예에서, 상기 얼굴 이미지는 정면 얼굴 이미지일 수 있다. 또 다른 실시예에 따른 컴퓨터 프로그램은 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 방법을 구현 하기 위한, 컴퓨터로 판독 가능한 기록 매체에 저장된다."}
{"patent_id": "10-2021-0094253", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예에 따른 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 시스템 및 방법은 딥러닝 기반의 예측 모 델을 이용하여 환자의 얼굴 이미지로부터 VCFS에 의한 얼굴 표현 여부를 예측할 수 있고, 예측 모델의 결과에 영향을 미치는 특징 변수들과 결과 간의 관계를 시각적으로 나타내는 얼굴 영역의 클래스 활성화 맵을 제공하여 임상의에게 변수들이 예측 결과에 어떻게 영향을 미치는지에 대한 통찰력을 제공할 수 있다."}
{"patent_id": "10-2021-0094253", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부 도면들 및 첨부 도면들에 기재된 내용들을 참조하여 실시예를 상세하게 설명하지만, 청구하고자 하는 범위는 실시예들에 의해 제한되거나 한정되는 것은 아니다. 본 명세서에서 사용되는 용어는 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어를 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 관례 또는 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 명세서의 설명 부분에서 그 의미를 기 재할 것이다. 따라서 본 명세서에서 사용되는 용어는, 단순한 용어의 명칭이 아닌 그 용어가 가지는 실질적인 의미와 본 명세서의 전반에 걸친 내용을 토대로 해석되어야 함을 밝혀두고자 한다. 또한, 본 명세서에 기술된 실시예는 전적으로 하드웨어이거나, 부분적으로 하드웨어이고 부분적으로 소프트웨어 이거나, 또는 전적으로 소프트웨어인 측면을 가질 수 있다. 본 명세서에서 \"부(unit)\", “모듈(module)\", \"장치 (device)\" 또는 \"시스템(system)\" 등의 용어는 하드웨어, 하드웨어와 소프트웨어의 조합, 또는 소프트웨어 등 컴퓨터 관련 엔티티(entity)를 지칭한다. 예를 들어, 부, 모듈, 장치 또는 시스템은 플랫폼(platform)의 일부 또는 전부를 구성하는 하드웨어 및/또는 상기 하드웨어를 구동하기 위한 애플리케이션(application) 등의 소프 트웨어를 지칭하는 것일 수 있다. 이하에서는 도면들을 참조하여 본 발명의 바람직한 실시예들에 대하여 상세히 살펴본다. 도 1은 일 실시예에 따른 딥러닝 기반의 VCFS 진단 지원 시스템의 구성을 나타낸 블록도이다. 도 2는 예측 모델 의 네트워크 구조를 도시한다. 도 3은 전-연결 계층의 구조를 예시적으로 도시한다. 도 4는 일 실시예에 따른 딥러닝 기반의 VCFS 진단 지원 시스템에 따른 예측 결과를 예시적으로 도시한다. 입천장심장얼굴 증후군(VCFS)는 신체적, 대사적, 내분비적, 행동적 특징에서 광범위한 특징이 나타날 수 있으며, 심장병, 특징적인 얼굴, 면역결핍, 인지적 저하 등이 주요 특성에 해당한다. VCFS에 의해 나타나는 특 징적인 얼굴 표현형은 구개열, 길쭉한 배 모양의 코, 작은 귀 또는 좁은 눈 등이 있다. 실시예에 따른 VCFS 진 단 지원 시스템은 대상자의 얼굴 이미지를 입력 받고, 입력된 대상자의 얼굴 이미지를 기초로 대상자의 VCFS 발현 가능성을 예측할 수 있다. 도 1 내지 도 4를 참조하면, 실시예에 따른 VCFS 진단 지원 시스템은 데이터 입력부, 예측 모델 을 포함한다. 데이터 입력부는 대상자의 얼굴 이미지를 입력 받는다. 대상자의 얼굴 이미지는 대상자의 얼굴이 포함한 이미지를 의미한다. 대상자의 얼굴 이미지는 카메라가 대상자의 얼굴을 정면에서 촬영한 정면 얼굴 이미지일 수 있다. 여기서, 정면 얼굴 이미지는 대상자의 얼굴 특징이 가장 잘 나타나도록 촬영된 이미지로서, 본 실시예에 따른 VCFS 진단 지원 시스템에 더욱 적합한 이미지일 수 있다. 예측 모델은 딥러닝 기반의 미리 학습된 예측 모델로서, 입력된 얼굴 이미지에 기초하여 대상자의 VCFS 발 현 가능성을 예측한다. 예측 모델은 입력된 얼굴 이미지에서 인식되는 얼굴 영역이 VCFS에 의한 얼굴 표현 형일 확률 값을 계산할 수 있다. 또한, 예측 모델은 대상자의 VCFS 발현 가능성과 연관된 정보를 시각화한 정보를 더 제공할 수 있다. 예측 모델은 심층 신경망(deep neural network) 구조를 갖는 기계 학습 모델로, 도 2와 같은 구조를 가질 수 있다. 예측 모델은 입력된 얼굴 이미지에서 얼굴 영역을 전처리하여 딥러닝 모델에 예측 가능한 입력으 로 변환하도록 구성되며, 대규모 공개 얼굴 데이터 세트를 통해 학습된 얼굴 인식 모델을 VCFS 특화 얼굴 인식 모델로 미세 조정(Fine-tuning)한 모델로 구성되어, 입력된 얼굴 영역이 VCFS에 의한 얼굴 표현형일 확률 값을 추론할 수 있다. 구체적으로, 예측 모델은 전처리부, 합성곱 계층, 전-연결 계층 및 데이터 시각화부 를 포함한다. 전처리부는 입력된 얼굴 이미지에서 얼굴 영역을 검출할 수 있다. 전처리부는 MTCNN(Multi-task Cascaded Convolutional Neural Networks)를 사용하여 구현될 수 있다. 전처리부는 검출된 얼굴 영역이 얼굴 이미지의 일정 영역에 위치하도록 얼굴 영역을 정렬하거나, 동일한 크기로 조정된 얼굴 영역을 얼굴 이미 지에서 추출하여 표준화된 얼굴 이미지를 생성할 수 있다. 합성곱 계층(112, convolutional layer)은 표준화된 얼굴 이미지에서 얼굴을 인식하고 인식된 얼굴의 특징 맵 (feature map)을 추출할 수 있다. 합성곱 계층은 합성곱 필터(Convolutional filter)를 이동시키면서 표 준화된 얼굴 이미지와 필터의 내적(inner product)을 이용해 특징 맵의 특징을 추출할 수 있다. 일 실시예에서, 합성곱 계층은 영상 데이터 학습에 효율적이라고 알려진 ResNet(Residual networks)을 통해 구성될 수 있 으며, 입력을 바로 출력으로 연결시키는 스킵 커넥션(skip connection)을 통해 더욱 심층적인 학습을 제공할 수 있다. 전-연결 계층(113, fully-connected layer)은 합성곱 계층에서 추출된 피처 맵(feature map)이 VCFS에 의 한 안면 표현형일 확률 값을 출력하도록 구성될 수 있다. 전-연결 계층은 VCFS에 의한 안면 표현형과 정상 구분을 위한 이진 분류(binary classification)형태로 구성될 수 있다. 전-연결 계층은 합성곱 계층(11 2)에서 추출된 특징 맵의 차원을 감소시키도록 적어도 하나의 합성곱 계층(FC)과 차원이 감소된 특징 맵을 분류 하는 분류기(Classifier)를 포함한다. 도 3에 도시된 바와 같이, 합성곱 계층은 제1 전-연결 계층(FC1), 제2 전-연결 계층(FC2) 및 분류기(Classifier)를 포함하도록 구성될 수 있다. 제1, 제2 전-연결 계층(FC1, FC2)에서, 특징 맵들은 활성 함수(activation function)를 통과하고, 풀링(Pooling) 과정을 통해 크기가 줄어 들게 된다. 크기가 줄어든 특징 맵에 분류기의 소프트맥스(softmax) 함수가 적용되어 0과 1 사이의 결과 값 (class score, 결과 총합이 1인)이 출력될 수 있다. 전-연결 계층은 VCFS에 의한 안면 표현형일 확률 값과 정상 표현형일 확률 값을 각각 계산할 수 있으며, 계산된 VCFS에 의한 안면 표현형일 확률 값과 계산된 정상 표 현형일 확률 값 중 큰 값을 결과 값으로 출력할 수 있다. 다른 실시예에서, 크기가 줄어든 특징 맵에 분류기의 시그모이드(sigmoid) 함수가 적용되어 0과 1 사이의 결과 값(class score)이 출력될 수 있다. 전-연결 계층 은 하나의 결과 값을 출력할 수 있으며, 출력된 결과 값이 미리 지정된 임계 값 이상인 경우 VCFS에 의한 안면 표현형으로 분류하고, 결과 값이 미리 지정된 임계 값 미만인 경우 정상으로 분류할 수도 있다. 전-연결 계층은 역전파(back-propagation)를 통해, 예측하고자 하는 클래스(class)의 이미지를 추정하도록 파라미 터가 최적화된 상태일 수 있다. 예시적으로, 모델의 학습을 위해 교차 엔트로피 손실(Cross Entropy Loss) 함수 와 Adam 최적화 프로그램이 사용될 수 있다. 인공지능 기술의 발전으로 인해 질환 예측 시스템들의 성능은 향상되고 있지만 신경망 모델의 블랙박스 특성으 로 인해 현장 의료진의 임상의사 결정에 직접적인 도움을 주는 것에 한계가 존재한다. 이는 기계학습 기반 모델 이 복잡한 다중 은닉 계층과 가중치 매개 변수를 통해 한 번에 많은 양의 입력 데이터를 처리하기 때문에 사용 자가 어떠한 기준과 방식으로 결과가 도출되었는지 해석하기 어렵기 때문이다. 이는 사용자가 예측 모델의 결과 를 전적으로 신뢰할 수 없게 하고, 단순한 수치의 나열만으로는 의료진이 어떠한 조치를 취해야 하는지 결정하 기 어렵게 만들기 때문이다. 따라서 실제 의료 현장에서 예측 결과를 적용하려면 임상의가 예측 모델의 위험 평가가 어떻게 도출되는지에 대 한 자료, 특히, 시각화된 자료가 필요하다. 이에, 본 발명의 실시예에 따른 딥러닝 기반의 입천장심장얼굴 증후 군(VCFS) 진단 지원 시스템은 예측 모델의 결과를 해석할 수 있도록 하고 직관적인 분석을 제공하여 임상의 사 결정을 지원할 수 있는 시각화된 자료를 더 제공할 수 있다. 데이터 시각화부는 대상자의 VCFS 발현 가능성과 연관된 정보를 시각화한 정보로 더 제공할 수 있다. 데이 터 시각화부는 합성곱 계층 및 전-연결 계층이 결과를 얻기 위해 특정 레이어의 어떤 위치에 있 는 특징들을 이용했는지 확인한 정보를 시각화하여 제공할 수 있다. 데이터 시각화부는 결과 값(class score)과 합성곱 계층의 최종 피처 맵 사이의 변화량을 추적하여, 입력된 얼굴 이미지와 동일한 크기를 갖 는 히트맵(heatmap)을 생성할 수 있으며, 생성된 히트맵을 원본 얼굴 이미지와 함께 표시한 클래스 활성화 맵 (CAM, Class Activation Map)을 시각화한 정보로서 제공할 수 있다. 일 실시예에서, 데이터 시각화부는 Grad-CAM(Gradient-weighted class activation mapping)을 통해 히트 맵을 생성할 수 있다. Grad-CAM은 신경망이 결과를 얻기 위해 특정 레이어의 어떤 위치에 있는 특징들을 이용했 는지 확인할 수 있는 시각화 방법으로서, 그래디언트(gradients)를 사용하여 컨볼루션 레이어들에서 활성화된 공간 영역(spatial region)을 나타낼 수 있다. 일반적으로, 합성곱 계층은 전-연결 계층에서 상실되 는 공간 정보를 보유할 수 있으며, 합성곱 계층의 후단으로 가는 것에 따라 더욱 추상화된 정보를 보유할 수 있다. Grad-CAM에서는 합성곱 계층들 중 최종층의 정보를 이용하여 히트맵의 작성이 진행될 수 있다. 구체적으로, Grad-CAM은 하기 수학식 1과 같이 구현될 수 있다. [수학식 1] ,"}
{"patent_id": "10-2021-0094253", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "( : 합성곱 계층 구조의 마지막 단의 출력이자 전-연결 계층의 입력 값, : 합성곱 계층의 k번째에 있는 특 징맵, Z: 특징 맵의 크기, ReLU는 음의 값을 0으로 만드는 활성 함수이다) 는 신경망 중요도 가중치(neuron importance weight)로서, 가 에 대해 가지는 그래디언트 값인"}
{"patent_id": "10-2021-0094253", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "을 모두 더한 다음 평균을 구한 값에 해당한다. 최종적으로 획득되는 Grad-cam 값( )은 에 를 곱해서 모두 더한 다음, 음의 값을 0으로 만드는 활성 함수(ReLU)를 통과하여 계산될 수 있다. 상술한 과정을 통해 생성된 히트맵에서 강조되는 영역은 컨볼루션 레이어들에서 활성화된 공간 영역에 해당한다. 예시적으로, 히트맵은 활성화된 공간 영역을 적색으로 표시할 수 있으며, 비활성화된 공간 영역을 청 색으로 나타낼 수 있으며, 이의 사이 영역은 적색과 청색 사이의 색상 그라데이션을 나타낼 수 있다. 생성된 히 트맵을 원본 얼굴 이미지와 함께 표시한 클래스 활성화 맵(CAM, Class Activation Map)을 통해 원본 얼굴 이미 지에서 신경망이 중요하게 고려하는 영역의 확인이 가능하다. 즉, 예측 모델이 입력된 얼굴 이미지가 VCFS 에 의한 얼굴 표현형으로 판단한 경우, 입력된 얼굴 이미지 중 VCFS에 의한 얼굴 표현형으로 판단하는 데에 있 어 다른 얼굴 영역보다 기여도가 높은 얼굴 영역을 클래스 활성화 맵을 통해 확인할 수 있다. 도 4를 참조하면, 입력된 대상자의 얼굴 이미지, 얼굴 이미지에 각각 대응되어 예측된 VCFS에 의한 얼굴 표현형 일 확률 값 및 시각화 자료로서 생성된 클래스 활성화 맵을 확인할 수 있다. 클래스 활성화 맵에서, 적색으로 나타낸 영역이 VCFS에 의한 얼굴 표현형일 확률 값의 계산에 다른 영역 대비 크게 기여한 영역에 해당한다. 클 래스 활성화 맵에서 적색으로 표시되는 얼굴 영역은 VCFS에 의한 특징적인 얼굴 표현이 나타나는 부위일 수 있 다. 본 실시예에 따른 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 시스템을 통해 생성되는 클래스 활성화 맵은 의료진의 VCFS 진단을 위한 보조 자료로 충분히 활용되어 의료진의 VCFS 진단을 지원할 수 있으며, 대상자의 VCFS 조기 진단에 도움을 주어 적절한 시기에 치료가 이루어질 수 있도록 지원할 수 있다. 도 5는 일 실시예에 따른 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 방법의 각 단계를 나타내는 순 서도이다. 도 6은 입력된 얼굴 이미지에 따른 대상자의 VCFS 발현 가능성을 예측 모델을 통해 예측하는 단계의 세부 단계를 나타내는 순서도이다. 각 단계의 일부 또는 전부는 컴퓨터 프로그램으로 구현될 수 있으며, 컴퓨터 프로세서에 의해 실행될 수 있다. 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 방법은 VCFS 진단 지 원 시스템에서 수행될 수 있으며, 본 실시예의 설명을 위해 도 1 내지 도 4, 관련된 설명 내용이 참조될 수 있다. 도 5를 참조하면, 일 실시예에 따른 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 방법은 대상자의 얼 굴 이미지를 입력 받는 단계(S100); 상기 입력된 얼굴 이미지에 따른 대상자의 VCFS 발현 가능성을 딥러닝 기반 의 미리 학습된 예측 모델을 통해 예측하는 단계(S110); 및 상기 예측 모델을 통해 상기 VCFS 발현 가능성과 연 관된 정보를 시각화한 정보를 제공하는 단계(S120)를 포함한다. 먼저, 대상자의 얼굴 이미지를 입력 받는다(S100). 대상자의 얼굴 이미지는 대상자의 얼굴이 포함한 이미지를 의미한다. 대상자의 얼굴 이미지는 카메라가 대상자 의 얼굴을 정면에서 촬영한 정면 얼굴 이미지일 수 있다. 여기서, 정면 얼굴 이미지는 대상자의 얼굴 특징이 가 장 잘 나타나도록 촬영된 이미지로서, 본 실시예에 따른 VCFS 진단 지원 시스템에 더욱 적합한 이미지일 수 있 다. 다음으로, 상기 입력된 얼굴 이미지에 따른 대상자의 VCFS 발현 가능성을 딥러닝 기반의 미리 학습된 예측 모델 을 통해 예측한다(S110). 본 단계(S110)에서, 예측 모델은 딥러닝 기반의 미리 학습된 예측 모델로서, 입력된 얼굴 이미지에 기초하 여 대상자의 VCFS 발현 가능성을 예측한다. 예측 모델은 입력된 얼굴 이미지에서 얼굴 영역을 전처리하여 딥러닝 모델에 예측 가능한 입력으로 변환하도록 구성되며, 대규모 공개 얼굴 데이터 세트를 통해 학습된 얼굴 인식 모델을 VCFS 특화 얼굴 인식 모델로 미세 조정(Fine-tuning)한 모델로 구성되어, 입력된 얼굴 영역이 VCFS 에 의한 얼굴 표현형일 확률 값을 추론할 수 있다. 구체적으로, 도 6을 참조하면, 본 단계(S110)는 입력된 얼굴 이미지에서 얼굴 영역을 검출하고 정렬하여 표준화 된 얼굴 이미지를 생성하는 단계(S112); 상기 표준화된 얼굴 이미지에서 피처 맵(feature map)을 추출하는 단계 (S114); 및 상기 추출된 피처 맵(feature map)을 기초로 VCFS에 의한 안면 표현형일 확률 값을 출력하는 단계 (S116)를 포함한다. 여기서, 상기 입력된 얼굴 이미지에서 얼굴 영역을 검출하고 정렬하여 표준화된 얼굴 이미지를 생성하는 단계 (S112)는 MTCNN(Multi-task cascaded convolutional networks)으로 구성되는 전처리부에서 수행되고, 상기 표 준화된 얼굴 이미지에서 피처 맵(feature map)을 추출하는 단계(S114)는 ResNet(residual networks)으로 구성 되는 합성곱 계층에서 수행될 수 있다. 다음으로, 예측 모델을 통해 상기 VCFS 발현 가능성과 연관된 정보를 시각화한 정보를 제공한다(S120). 상기 시각화한 정보는 상기 전-연결 계층이 결과를 얻기 위해 특정 레이어의 어떤 위치에 있는 특징들을 이용했 는지 시각화하여 나타낸 히트맵을 상기 입력된 얼굴 이미지와 함께 표시한 클래스 활성화 맵이며, 상기 클래스 활성화 맵은 상기 대상자의 얼굴 이미지에 VCFS 발현 가능성에 대한 판단 시 기여도가 타 얼굴 영역보다 높은 얼굴 영역을 표시하도록 구성될 수 있다. 상기 히트맵은 Grad-CAM(gradient-weighted class activation mapping)을 통해 생성되며, 상기 Grad-CAM은 하 기 수학식 1과 같이 구현된다. [수학식 1] ,"}
{"patent_id": "10-2021-0094253", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "( : 합성곱 계층 구조의 마지막 단의 출력이자 전-연결 계층의 입력 값, : 합성곱 계층의 k번째에 있는 특 징맵, Z: 특징 맵의 크기, ReLU는 음의 값을 0으로 만드는 활성 함수이다) 는 신경망 중요도 가중치(neuron importance weight)로서, 가 에 대해 가지는 그래디언트 값인"}
{"patent_id": "10-2021-0094253", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "을 모두 더한 다음 평균을 구한 값에 해당한다. 최종적으로 획득되는 Grad-cam 값( )은 에 를 곱해서 모두 더한 다음, 음의 값을 0으로 만드는 활성 함수(ReLU)를 통과하여 계산될 수 있다. 생성된 히트맵을 원본 얼굴 이미지와 함께 표시한 클래스 활성화 맵(CAM, Class Activation Map)을 통해 원본 얼굴 이미지에서 신경망이 중요하게 고려하는 영역의 확인이 가능하다. 즉, 예측 모델이 입력된 얼굴 이미 지가 VCFS에 의한 얼굴 표현형으로 판단한 경우, 입력된 얼굴 이미지 중 VCFS에 의한 얼굴 표현형으로 판단하는 데에 있어 다른 얼굴 영역보다 기여도가 높은 얼굴 영역을 클래스 활성화 맵을 통해 확인할 수 있다. 이러한 실시예들에 따른 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 방법 은, 애플리케이션으로 구 현되거나 다양한 컴퓨터 구성요소를 통하여 수행될 수 있는 프로그램 명령어의 형태로 구현되어 컴퓨터 판독 가 능한 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체는 프로그램 명령어, 데이터 파일, 데이 터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD- ROM, DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 ROM, RAM, 플래시 메모리 등과 같은 프로그램 명령어를 저장하고 수행하도록 특별히 구성된 하드웨 어 장치가 포함된다. 프로그램 명령어의 예에는, 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사 용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함된다. 상기 하드웨어 장치는 본 발명에 따른 처 리를 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 실험예 상술한 실시예에 따른 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 시스템 및 방법의 예측 모델을 여 러 학습 데이터를 통해 구축하고, 구축된 예측 모델을 검증하는 실험을 수행하였다. 예측 모델은 대규모 공개 얼굴 데이터 세트를 통해 학습된 얼굴 인식 모델의 전-연결 계층을 VCFS에 의한 얼굴 표현형과 정상 얼굴을 구별하도록 미세 조정(Fine-tuning)한 모델에 해당한다. 얼굴 인식 모델과 미세 조정 과정 각각에 대한 학습이 수행되어 예측 모델이 구축될 수 있다. 얼굴 인식 모델은 공개된 안면이미지 데이터 세트와 검증된 알고리즘을 이용하여 구축되었다. 영상 데이터 학습 에 효율적이라고 알려진 residual networks (ResNet), 구체적으로 ResNet100, 또는 ResNet101을 사용하였으며, 입력되기 위한 데이터 전처리 과정을 MTCNN을 통해 수행되도록 하였다. 학습용 데이터 세트와 검증용 데이터 세 트는 하기 표 1과 같이 준비되었다. 표 1 구분 데이터 세트명 학습용 데이터 세트 CASIA MS-Celeb-1M K-Face Asian-Celeb, CASIA(Asian), K-Face 검증용 데이터 세트 LFW(Labelled Faces in the Wild) CFP-FP AGEDB-30 Microsoft Celeb (MS-Celeb-1M), Institute of Automation Chinese Academy of Sciences (CASIA) 데이터 셋 등 다양한 공용 데이터 세트를 사용하여 각각 얼굴 인식 모델을 구축하였다. 구체적으로, 얼굴 인식 모델 1은 CASIA 데이터 셋을 통해 ResNet100을 활용하여 구축하였으며, 얼굴 인식 모델 2는 MS-Celeb-1M 데이터 셋을 통 해 ResNet100을 활용하여 구축하였으며, 얼굴 인식 모델 3은 K-Face 데이터 셋을 통해 ResNet100을 활용하여 구 축하였으며, 얼굴 인식 모델 4는 Asian-Celeb, CASIA(Asian), K-Face 데이터 셋과 ResNet101을 활용하여 구축 하였다. 구축된 인식 모델 각각의 성능을 LFW(Labelled Faces in the Wild), CFP-FP, AGEDB-30와 같은 검증용 데이터 세트를 사용하여 검증하였으며, 이에 따른 결과 데이터는 하기 표 2와 같이 도출되었다. 표 2 모델 1 2 3 4 구조 ResNet100 ResNet100 ResNet100 ResNet101 학습 데이터 CASIA MS-Celeb-1M K-Face Asian-Celeb, CASIA(Asian), K-Face Face Verification 성능(%)검증 데 이터LFW 99.52 99.78 70.78 98.23 AgeDB-30 94.57 97.93 51.10 88.22 CFP-FP 95.89 94.03 64.20 89.13 표 2를 참조하면, CASIA에 포함된 이미지 수가 약 0.5백만장, MS-Celeb-1M에 포함된 이미지 수가 3.9백만장, K- Face에 포함된 이미지 수가 1.1백만장, Asian-Celeb + CASIA(Asian) + K-Face에 포함된 이미지 수가 2.8백만장 인 점을 감안할 때, ResNet의 초기 버전인 ResNet101보다 개선 버전인 ResNet100이 더 적은 학습 데이터 량에도 더 개선된 식별 성능을 나타내는 것을 알 수 있으며, 학습 데이터 량이 가장 많은 모델 2가 가장 우수한 얼굴 식별 성능을 나타내는 것을 알 수 있다. 전-연결 계층을 VCFS에 의한 얼굴 표현형과 정상 얼굴을 구별하도록 미세 조정(Fine-tuning)하고, 조정된 전-연 결 계층의 테스트를 위한 Train 데이터와 Test 데이터가 표 3과 같은 데이터가 활용되었다. 표 3 구분 전체 Train Test MTCNN 검출 탈락 ID (명)ImagesID (명)ImagesID (명)ImagesImages % VCFS98 1105 88 868 10 52 185 16.74 정상91 521 81 442 10 21 58 11.13 표 3에서, VCFS는 유전자 검사로 22q11.2 결실이 확인된 VCFS 환자, 정상은 안면 표현형 이상이 없는 질환, 예 를 들어 피부양성 종양 환자에 해당한다. 표 3의 Train 데이터를 통해 얼굴 인식 모델 1 내지 4의 전-연결 계층을 미세 조정하는 학습을 수행하여, 최종 적인 예측 모델을 구축하였으며, 표 3의 Test 데이터를 통해 각각의 분류 성능을 확인하였다. 분류 성능은 실제 클래스(Actual Class)에 대한 예측된 클래스(Predicted class)의 적합 여부를 기초로 판단하게 된다. 도 7은 분 류 성능을 계산하기 위한 계산식을 예시적으로 나타낸다. 도 7에 도시된 바와 같이, 각 모델에 대한 True Positives(TP), True Negatives (TN), False Negatives(FN), False Positives(FP)가 결정될 수 있으며, 결정된 TP, TN, FN, FP를 기초로 정확도(accuracy)의 계산이 가능할 수 있다. 이의 결과는 하기 표 4와 같이 나타났다. 표 4 예측 모델 1 2 3 4 구조 ResNet100ResNet100ResNet100ResNet101 학습 데이터 CASIAMS-Celeb-1MK-FaceAsian-Celeb, CASIA(Asian), K-Face Classification 성능(%)TEST (전체각 도)F1- Score88.02 81.43 67.50 90.34 Accurac y87.67 80.82 71.23 90.41 표 4를 참조하면, 예측 모델 1, 예측 모델 2 및 예측 모델 4는 모두 높은 F1-score와 정확도(Accuracy)를 나타 내는 것을 알 수 있으며, 충분한 분류 기능을 제공하는 것을 확인할 수 있다. 여기서, Train 데이터 또는 얼굴 인식 모델을 구축하기 위한 훈련 데이터는 다양한 얼굴 각도를 가진 이미지일 수 있으며, 얼굴 각도에 따라 분류 정확도가 달라질 수 있기에, 이에 대한 추가적인 검증을 수행하였다. 도 8은 Test 이미지의 얼굴 각도(정면, Upward 정면, 측면1(45도), 측면2(90도))를 예시적으로 나타낸다. 도 8에 도시된 바와 같이, 얼굴 각도를 달리한 Test 이미지의 분류 정확도를 하기 표 5와 같이 확인하였다. 표 5 예측 모델 1 2 3 4 구조 ResNet100ResNet100ResNet100ResNet101 학습 데이터 CASIAMS-Celeb-1MK-FaceAsian-Celeb, CASIA(Asian), K-Face Classifi cation 성능(%)TEST F1-score (VCFS/정상)정면 94.99 94.99 60.11 84.65 Upward 정면89.57 100.00 68.06 100.00 측면1 96.01 88.70 84.19 100.00 측면2 71.98 52.38 56.27 80.00 측면 이미지 대비, 얼굴의 특징이 잘 나타나는 정면 이미지에 대한 분류 정확도가 더 높은 것을 확인할 수 있다. 상술한 바와 같이, 구축된 예측 모델 1, 예측 모델 2, 예측 모델 3 및 예측 모델 4의 결과 값(class score)과 합성곱 계층의 최종 피처 맵 사이의 변화량을 추적하여, 입력된 얼굴 이미지와 동일한 크기를 갖는 히트맵 (heatmap)을 각각 생성하고, 생성된 히트맵을 원본 얼굴 이미지와 함께 표시한 클래스 활성화 맵(CAM, Class Activation Map)을 시각화한 정보로 생성할 수 있다. 이상에서 설명한 VCFS 진단 지원 시스템 및 방법의 실시예들에 의하면, 딥러닝 기반의 예측 모델을 이용하여 환 자의 얼굴 이미지로부터 VCFS에 의한 얼굴 표현 여부를 예측할 수 있고, 예측 모델의 결과에 영향을 미치는 특 징 변수들과 결과 간의 관계를 시각적으로 나타내는 얼굴 영역의 클래스 활성화 맵을 제공하여 임상의에게 변수 들이 예측 결과에 어떻게 영향을 미치는지에 대한 통찰력을 제공할 수 있다. 이상에서는 실시예들을 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2021-0094253", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명 또는 종래 기술의 실시예의 기술적 해결책을 보다 명확하게 설명하기 위해, 실시예에 대한 설명에서 필 요한 도면이 아래에서 간단히 소개된다. 아래의 도면들은 본 명세서의 실시예를 설명하기 목적일 뿐 한정의 목 적이 아니라는 것으로 이해되어야 한다. 또한, 설명의 명료성을 위해 아래의 도면들에서 과장, 생략 등 다양한 변형이 적용된 일부 요소들이 도시될 수 있다. 도 1은 일 실시예에 따른 딥러닝 기반의 VCFS 진단 지원 시스템의 구성을 나타낸 블록도이다. 도 2는 예측 모델의 네트워크 구조를 도시한다. 도 3은 전-연결 계층의 구조를 예시적으로 도시한다. 도 4는 일 실시예에 따른 딥러닝 기반의 VCFS 진단 지원 시스템에 따른 예측 결과를 예시적으로 도시한다. 도 5는 일 실시예에 따른 딥러닝 기반의 입천장심장얼굴 증후군(VCFS) 진단 지원 방법의 각 단계를 나타내는 순 서도이다. 도 6은 입력된 얼굴 이미지에 따른 대상자의 VCFS 발현 가능성을 예측 모델을 통해 예측하는 단계의 세부 단계 를 나타내는 순서도이다. 도 7은 분류 성능을 계산하기 위한 계산식을 예시적으로 나타낸다. 도 8은 Test 이미지의 얼굴 각도(정면, Upward 정면, 측면1, 측면2)를 예시적으로 나타낸다."}
