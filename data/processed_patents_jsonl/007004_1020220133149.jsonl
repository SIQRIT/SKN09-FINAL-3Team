{"patent_id": "10-2022-0133149", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0053261", "출원번호": "10-2022-0133149", "발명의 명칭": "반려 동물 고유 식별 정보 생성 방법 및 그 시스템", "출원인": "울산과학기술원", "발명자": "백승렬"}}
{"patent_id": "10-2022-0133149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 반려 동물의 고유 식별 정보를 생성하는 방법에 있어서,입력 이미지로부터 반려 동물의 얼굴 영역을 추출하는 단계;상기 추출한 얼굴 영역의 이미지를 푸리에 변환기를 통해 처리하여 푸리에 변환값을 출력하는 단계;상기 추출한 얼굴 영역의 이미지를 제1 기계 학습 모델을 이용한 특징 추출기를 통해 처리하여 이미지 특징값을출력하는 단계; 및상기 푸리에 변환값과 상기 이미지 특징값을 제2 기계 학습 모델을 이용한 고유값 생성기를 통해 학습 처리하여상기 반려 동물을 식별할 수 있는 하나 이상의 정보를 포함하는 고유값을 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0133149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 고유값은,상기 반려 동물에 고유하게 부여되는 식별 정보, 상기 반려 동물의 종(species) 정보, 및 상기 반려 동물의 거주 지역 정보 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2022-0133149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 고유값은 일련의 숫자 정보로 표현되는 것인, 방법."}
{"patent_id": "10-2022-0133149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 제1 기계 학습 모델로서 합성 곱 기반의 딥 러닝 모델을 사용하는, 방법."}
{"patent_id": "10-2022-0133149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서, 상기 입력 이미지는 RGB 이미지 데이터, IR 이미지 데이터 및 깊이 데이터 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2022-0133149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서, 상기 제2 기계 학습 모델은 동일 반려 동물에 대한 서로 다른 복수의 입력 이미지 각각에 따른 푸리에 변환값및 이미지 특징값을 입력받아 기계 학습 처리를 통해 하나의 고유값을 생성하여 출력하는, 방법."}
{"patent_id": "10-2022-0133149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "적어도 하나의 클라이언트 장치와 통신하는 서버가 반려 동물 고유 식별 정보를 생성하는 방법에 있어서, 상기 적어도 하나의 클라이언트 장치로부터 이미지 데이터를 수신하는 단계; 상기 이미지 데이터에 대응하여 추출된 반려 동물의 얼굴 영역 이미지를 푸리에 변환 처리하여 푸리에 변환값을획득하는 단계;제1 기계 학습 모델을 통해 상기 추출된 반려 동물의 얼굴 영역 이미지로부터 이미지 특징값을 추출하는 단계;공개특허 10-2024-0053261-3-및상기 푸리에 변환값과 상기 이미지 특징값을 제2 기계 학습 모델에 입력하여 상기 반려 동물을 식별할 수 있는하나 이상의 정보를 포함하는 고유값을 출력하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0133149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서, 상기 생성된 반려 동물의 고유값을 상기 클라이언트 장치로 전송하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-0133149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7항에 있어서, 상기 적어도 하나의 클라이언트 장치로부터 이미지 데이터를 수신하는 단계 이후에,상기 이미지 데이터로부터 반려 동물의 얼굴 영역을 추출하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-0133149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 7 항에 있어서, 상기 적어도 하나의 클라이언트 장치로부터 이미지 데이터를 수신하는 단계는, 상기 클라이언트 장치에 의해 이미지 데이터에서 반려 동물의 얼굴 영역이 검출된 얼굴 영역 이미지를 수신하는것인, 방법."}
{"patent_id": "10-2022-0133149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 7 항에 있어서, 상기 고유값은,상기 반려 동물에 고유하게 부여되는 식별 정보, 상기 반려 동물의 종(species) 정보, 및 상기 반려 동물의 거주 지역 정보 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2022-0133149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 7 항에 있어서,상기 제1 기계 학습 모델로서 합성 곱 기반의 딥 러닝 모델을 사용하는, 방법."}
{"patent_id": "10-2022-0133149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 7 항에 있어서, 상기 입력 이미지는 RGB 이미지 데이터, IR 이미지 데이터 및 깊이 데이터 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2022-0133149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 7 항에 있어서, 상기 제2 기계 학습 모델은 동일 반려 동물에 대한 서로 다른 복수의 입력 이미지 각각에 따른 푸리에 변환값및 이미지 특징값을 입력받아 기계 학습 처리를 통해 하나의 고유값을 생성하여 출력하는, 방법."}
{"patent_id": "10-2022-0133149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 제1 항의 방법을 수행하는, 전자 장치.공개특허 10-2024-0053261-4-청구항 16 하드웨어인 컴퓨터와 결합되어, 제1 항의 방법을 수행할 수 있도록 컴퓨터에서 독출 가능한 기록매체에 저장된컴퓨터프로그램."}
{"patent_id": "10-2022-0133149", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "반려 동물의 고유 식별 정보를 생성하는 방법 및 그 시스템을 개시한다. 본 방법은 입력 이미지로부터 반려 동물 의 얼굴 영역을 추출하고, 추출한 얼굴 영역의 이미지를 푸리에 변환기를 통해 처리하여 푸리에 변환값을 출력하 고, 추출한 얼굴 영역의 이미지를 제1 기계 학습 모델을 이용한 특징 추출기를 통해 처리하여 이미지 특징값을 출력하며, 푸리에 변환값과 이미지 특징값을 제2 기계 학습 모델을 이용한 고유값 생성기를 통해 학습 처리하여 반려 동물을 식별할 수 있는 하나 이상의 정보를 포함하는 고유값을 생성한다."}
{"patent_id": "10-2022-0133149", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이미지로부터 반려 동물의 얼굴을 인식한 정보에 기반하여 반려 동물 별 고유 식별 정보를 생성하는 방법 및 이를 구현하기 위한 시스템에 관한 것이다."}
{"patent_id": "10-2022-0133149", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현대 사회에서는 반려 동물이 가족 구성원으로써 인식되고 있으며, 이에 따라 반려 동물의 실종 발생 시 신속하 고 정확하게 반려 동물을 찾고 신원을 확인할 수 있는 방법에 대한 요구가 크다. 최근 들어, 반려 동물의 신체에 반려동물의 등록 정보를 식별할 수 있도록 하는 마이크로 칩을 시술하는 반려동 물등록제가 실시되고 있으나, 이는 유기된 반려 동물 포획 시 마이크로 칩을 리더기로 확인하는 방식으로써, 반 려 동물의 포획이 선행되어야 하며 마이크로 칩을 인식할 수 있는 리더기를 개인적으로 구비하기 어렵다는 점에 서 효율성이 떨어진다. 즉, 유기된 반려 동물이 발견되더라도 직접 포획하기 위한 전문가가 필요할 수 있고, 또한 반려 동물의 실시간 발견 및 포획 자체가 불가능하거나 어려운 상황이 대부분이라는 점에서 실질적으로 편리성 및 접근성이 부족한 반려 동물 보호 방식이라고 볼 수 있다. 따라서, 발견된 반려 동물을 포획하지 않더라도 원격에서 확인할 수 있고, 반려 동물을 실시간으로 발견하지 못 하더라도 이동 경로 등을 추적할 수 있고, 외모가 비슷한 반려 동물들의 특성을 효과적으로 구분할 수 있으며, 사회 관리 시설 및 단체 뿐만 아니라 개별 가정 또는 개인도 간편하게 자기 반려 동물만의 고유한 식별 정보를 생성 및 관리할 수 있도록 하는 방법 및 그 시스템의 개발이 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허 제10-2018-0070057호 (발명의 명칭: 실종 반려동물과 유기 반려동물의 매칭 을 위한 방법, 시스템 및 컴퓨터 판독가능 기록 매체) (특허문헌 0002) 대한민국 공개특허 제 10-2021-0084110호 (발명의 명칭: 인지능력 향상 판정방법)"}
{"patent_id": "10-2022-0133149", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 해결하기 위한 것으로, 본 발명의 일 실시시예가 이루고자 하는 기술적 과제는 반려 동물의 얼굴 인식을 이용한 반려 동물 고유 식별 정보 생성 방법 및 그 시스템을 제공하는 것이다. 또한, 본 발명의 다른 실시예가 이루고자 하는 기술적 과제는 인공지능 기반의 학습에 따른 반려 동물 고유 식 별 정보 생성 및 이를 이용한 반려 동물 식별 방법과 그 시스템을 제공하는 것이다. 다만, 본 발명의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 더 존재할 수 있다."}
{"patent_id": "10-2022-0133149", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 목적을 달성하기 위한 본 발명의 일 실시 예에 따른 아바타를 생성하는 전자 장치의 동작 방법은 비디오 데이터로부터 이미지 데이터 및 음성 데이터를 추출하는 단계; 상기 이미지 데이터로부터 검출된 제1 랜드마크 (landmark)로부터 이미지 인코딩 값을 추출하는 단계; 상기 음성 데이터로부터 콘텐트 인코딩 값을 추출하는 단계; 상기 이미지 인코딩 값과 상기 콘텐트 인코딩 값에 기반하여 제2 랜드마크를 추출하는 단계; 상기 제1 랜드 마크 및 상기 제2 랜드마크를 이용하여 3차원의 포즈 정보, 기하 정보 및 표현 정보를 생성하는 단계; 및 상기 3차원의 포즈 정보, 기하 정보 및 표현 정보를 기초로 2차원 평면으로 정사영된 아바타 이미지를 생성하는 단계 를 개시한다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2022-0133149", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 반려 동물이 촬영된 이미지로부터 반려 동물의 얼굴을 인식하되, 이미지로부터 추출된 반려 동물의 얼굴 인식 결과에 따른 특징 정보뿐만 아니라 고차원의 푸리에 변환을 통해 획득된 특성 값 을 함께 기계 학습하여 신뢰성이 높은 반려 동물의 고유한 식별 정보를 생성할 수 있다. 이에 따라, 학습되지 않은 새로운 이미지가 입력되더라도 기존에 학습된 반려 동물 고유 식별 정보 중 해당하는 정보로의 구분이 가능하다. 즉, 임의의 반려 동물이 객체로써 포함된 이미지를 입력 받는 것만으로도 해당 반 려 동물에 대한 정확하고 신속한 식별이 가능한 효과가 있다."}
{"patent_id": "10-2022-0133149", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0133149", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야의 통상의 기술자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단 지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 본 명세서에서, 전자 장치는 적어도 하나의 프로세서를 포함하는 무선 통신 기능을 포함하는 하드웨어 장치를 의미하는 것이고, 실시 예에 따라 해당 하드웨어 장치에서 동작하는 소프트웨어적 구성도 포괄하는 의미로서 이 해될 수 있다. 예를 들어, 전자 장치는 스마트폰, 휴대폰, 핸드 헬드 장치(hand-held device), 태블릿 PC, 데스 크톱, 노트북 및 각 장치에서 구동되는 사용자 클라이언트 및 애플리케이션을 모두 포함하는 의미로서 이해될 수 있으며, 또한 이에 제한되는 것은 아니다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 본 명세서에서 설명되는 각 단계들은 단말에 의하여 수행되는 것으로 설명되나, 각 단계의 주체는 이에 제한되 는 것은 아니며, 실시 예에 따라 각 단계들의 적어도 일부가 서로 다른 장치에서 각각 수행되어 유기적으로 연 동될 수도 있다. 도 1은 본 발명의 일 실시예에 따른 반려 동물 고유 식별 정보 생성 시스템을 도시한 도면이다. 도 2는 본 발명의 일 실시예에 따른 반려 동물 고유 식별 정보 생성 시스템의 동작 방법을 도시한 순서도이 고, 도 3은 본 발명의 일 실시예에 따른 반려 동물 고유 식별 정보 생성 프로세스를 나타낸 도식도이다. 본 발명의 일 실시예에 따른 반려 동물 고유 식별 정보 생성 시스템은 서버, 복수의 전자 장치를 포 함한다. 서버와 적어도 하나의 전자 장치, 및 각각의 전자 장치들은 서로 네트워크를 통해 통신할 수 있으며, 이때 각각의 전자 장치는 클라이언트 장치(client device)로 동작할 수 있다. 서버는 적어도 하나의 전자 장치로부터 복수의 이미지 데이터 또는 복수의 프레임(frame)으로 구성된 비디오 데이터를 수신할 수 있다(S21). 이때, 서버는 비디오 데이터를 수신할 경우 비디오 데이터로부터 2 차원 이미지 데이터를 추출할 수 있다. 예를 들어, 도 3의 제1 단계(S31)에 도시된 바와 같이, 수신된 이미지 데이터는 반려 동물 개체가 촬영된 이미 지로써, 하나의 반려 동물 개체에 대한 하나 이상의 이미지이거나 또는 사회 기반 설비(예들 들어, CCTV) 등을 통해 무작위로 촬영된 이미지들일 수 있다. 서버는 입력된 적어도 하나의 이미지 데이터에서 반려 동물의 얼굴 영역을 검출한다(S22). 구체적으로, 도 3의 제2 단계(S32)에 도시된 바와 같이, 서버는 이미지 데이터를 반려 동물 얼굴 인식기로 입력하여 기설정된 안면 인식 기법을 통해 반려 동물의 얼굴을 인식하고 얼굴 부분에 대응하는 얼굴 영역 이미 지만 출력할 수 있다. 참고로, 서버는 전자 장치로부터 반려 동물의 얼굴 영역만을 포함하는 이미지 데이터 또는 비디오 데이 터를 수신할 수도 있으며, 이는 전자 장치가 자체적으로 안면 인식 처리를 수행한 결과로서의 반려 동물 얼 굴 영역 이미지를 서버로 송신한 결과이다. 서버는 반려 동물의 얼굴 영역 이미지에 대해 기설정된 기계 학습 모델을 통해 복수의 특징점을 추출하는 제1 특징 추출을 수행하고(S23-1), 이와 병렬적으로 동일 얼굴 영역 이미지에 대해 기설정된 푸리에 변환을 통 해 주파수 영역의 특징값을 추출하는 제2 특징 추출을 수행한다(S23-2). 구체적으로, 서버가 제1 특징 추출을 수행하는(S23-1) 단계와 관련하여, 도 3의 제3 -1 단계(S33-1)에 도시 한 바와 같이, 서버는 특징 추출기를 통해 반려 동물의 얼굴 영역 이미지로부터 기설정된 종류의 특징 값 (features)을 추출한다. 이때, 서버는 하나 이상의 반려 동물의 얼굴 영역 이미지를 학습하는 기계 학습 모델을 사용하여 반려 동물 의 얼굴 영역 이미지로부터 특징 벡터를 추출할 수 있다. 기계 학습은 데이터를 분류하는 방식에 따라 대표적으로 의사결정나무 (Decision Tree)나 베이지안 망(Bayesian network), 서포트벡터머신(SVM: support vector machine), 및 인공 신경망(ANN: Artificial Neural Network) 등의 알고리즘으로 구분될 수 있다. 그 중 인공 신경망은 복수의 레이어(layer)를 포함하되, 레이어들 각각은 복수의 뉴런(neuron)을 포함하며. 또 한 인공 신경망은 뉴런과 뉴런을 연결하는 시냅스를 포함할 수 있다. 일반적으로 인공 신경망은 세가지 인자, 즉 다른 레이어의 뉴런들 사이의 연결 패턴, 연결의 가 중치를 갱신하는 학습 과정, 이전 레이어로 부터 수신되는 입력에 대한 가중합으로부터 출력값을 생성하는 활성화 함수에 의해 정의될 수 있다. 이러한 인공 신경망은 DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network), MLP(Multilayer Perceptron), CNN(Convolutional Neural Network)와 같은방식의 네트 워크 모델들을 포함할 수 있으나, 이에 한정되지 않는다. 예를 들어, 서버는 인공 신경망 중 MLP를 사용하여 반려 동물의 얼굴 영역 이미지로부터 특징 벡터를 추출 할 수 있으며, 도 4를 참조하여 MLP가 속하는 다층 신경망에 대해서 설명하도록 한다. 도 4는 본 발명의 일 실시예에 따른 반려 동물 특징 추출 단계에 적용되는 인공 신경망의 일 예의 개념을 도시 한 도면이다. 도 4에 도시한 바와 같이, 다층 신경망은 입력층(Input Layer)과 하나 이상의 은닉층(Hidden Layer), 출력층 (Output Layer)으로 구성된다. 입력층은 외부의 자료들을 받아들이는 층으로서, 입력층의 뉴런 수는 입력되는 변수의 수와 동일하며, 은닉층은 입력층과 출력층 사이에 위치하며 입력층으로부터 신호를 받아 특성을 추출하 여 출력층으로 전달한다. 출력층은 은닉층으로부터 신호를 받고, 수신한 신호에 기반한 출력 값을 출력한다. 뉴 런 간의 입력신호는 각각의 연결강도 (가중치)와 곱해진 후 합산되며 이 합이 뉴런의 임계치보다 크면 뉴런이 활성화되어 활성화 함수를 통하여 획득한 출력 값을 출력한다. 한편 입력층과 출력층 사이에 복수의 은닉층을 포함하는 심층 신경망은, 기계 학습 기술의 한 종류인 딥 러닝을 구현하는 대표적인 인공 신경망일 수 있다. 인공 신경망은 훈련 데이터(training data)를 이용하여 학습(training)될 수 있다. 여기서 학습이란, 입력 데이 터를 분류(classification)하거나 회귀분석(regression)하거나 군집화(clustering)하는 등의 목적을 달성하기 위하여, 학습 데이터를 이용하여 인공 신경망의 파라미터(parameter)를 결정하는 과정을 의미할 수 있다. 인공 신경망의 파라미터의 대표적인 예시로써, 시냅스에 부여되는 가중치(weight)나 뉴런에 적용되는 편향 (bias)을 들 수 있다. 훈련 데이터에 의하여 학습된 인공 신경망은, 입력 데이터를 입력 데이터가 가지는 패턴 에 따라 분류하거나 군집화 할 수 있다. 이러한 훈련 데이터를 이용하여 학습된 인공 신경망을 학습 모델(a trained model)이라 명칭할 수 있다. 한편, 인공 신경망 학습 모델에서 코사인 유사도로 두 이미지를 비교하기 위해서는 이미지를 벡터로 표현하는 것이 필요하며, 이미지를 벡터로 표현하는 방법으로써 앞서 살펴본 MLP 더불어 합성 곱 기반 딥 러닝 모델(CN N)이 사용될 수 있다. MLP는 대체로 많은 연산이 필요한 반면, CNN은 이미지에서 인접한 영역의 특징을 참조하여 연산을 수행한다는 장점이 있고, MLP에 비해 연산량이 많이 필요하지는 않다는 장점이 있다. 이에 따라, 본 발명의 일 실시예에 따른 서버는 기계 학습 모델로서 합성 곱 기반의 딥 러닝 모델을 사용할 수도 있다. 예를 들어, 합성 곱 기반의 딥 러닝 모델로서 16개의 딥 러닝 연산층으로 구성된 ‘VGG16’ 모델을 사용할 수 있다. 이러한 ‘VGG16’ 모델은 3x3 크기의 합성 곱 필터를 이용한 연산을 반복적으로 수행하고, 모델의 초반 부에는 합성 곱 연산으로 영상의 특징점을 찾아내고, 이를 특징 벡터로 변환하여 표현한다. 이와 같은 ‘VGG16’ 모델을 사용할 경우 작은 크기(즉, 3x3 크기)의 필터로 합성 곱 연산을 더 많은 횟수로 반 복함으로써 합성 곱 연산의 필터 크기가 큰 것 보다 더 효율적인 연산이 가능하다. ‘VGG16’ 모델의 구조는 합성 곱 연산, 최대값 풀링, 다층 퍼셉트론, 드롭아웃 연산으로 구성되어 있으며, 합 성곱 연산 중간에 최대값 풀링을 이용하여 영상의 해상도를 낮춰 연산량을 줄이고, 해상도가 충분히 낮아지면 다층 퍼셉트론을 이용해 특징을 추출한다. ‘VGG16’ 모델은 학습과정에서 발생하는 오버피팅을 최소화 하기위 해 드롭아웃을 다층 퍼셉트론 사이에 추가하며, 이는 학습에만 사용이 되고 테스트시에는 사용하지 않는 특징이 있다. 다시 도 3의 제3 -1 단계(S33-1)으로 돌아가서, 반려 동물의 얼굴 영역 이미지는 적어도 RGB 이미지 데이터일 수 있으며, 서버는 RGB 이미지 특징 추출기를 통해 반려 동물의 얼굴 영역 이미지로부터 기설정된 종류의 특징 값(features)을 추출할 수 있다. 본 발명의 일 실시예에서는 RGB 이미지로부터 반려 동물의 특징 값을 추출하는 것을 예로써 설명하되, 이미지 데이터의 종류는 이에 한정되지 않는다. 예를 들어, 이미지 데이터는 RGB 이미지 뿐만 아니라 적외선(IR) 이미 지 데이터 및 깊이(depth) 이미지 데이터 중 적어도 하나를 더 포함할 수도 있으며, 이와 같이 복수의 종류의 이미지 데이터를 함께 이용하여 좀 더 정확한 객체의 특징값을 추출할 수 있다. RGB 이미지 특징 추출기를 통 해 추출된 특징 값은 대상 객체(즉, 반려 동물)의 종류, 크기, 색상, 위치 또는 이미지 데이터 내에서의 영역 중 적어도 하나를 포함할 수 있다. 다음으로, 서버가 제2 특징 추출을 수행하는(S23-2) 단계와 관련하여, 도 3의 제3-2 단계(S33-2)에 도시한 바와 같이, 서버는 푸리에 변환기를 통해 반려 동물의 얼굴 영역 이미지에 대한 푸리에 변환 값을 추출한다. 푸리에 변환(Fourier transform)을 직관적으로 설명하면 임의의 입력 신호를 다양한 주파수를 갖는 주기함수들 의 합으로 분해하여 표현하는 것이다. 푸리에 변환에서 사용하는 주기함수는 sin, cos 삼각함수이며 푸리에 변 환은 고주파부터 저주파까지 다양한 주파수 대역의 sin, cos 함수들로 원본 신호를 분해한다. 이와 같이 푸리 에 변환 처리 시 입력 신호가 어떤 신호이든지 관계없이 입력 신호를 sin, cos 주기함수들의 합으로 항상 분해 할 수 있다. 사람의 안면 인식 및 식별 방식과 달리, 반려 동물은 같은 종의 반려 동물들 간의 형상을 구분하기에 앞서 설명 한 특징 추출기를 사용한 RGB 도메인에서의 특징 추출만으로는 부족할 수 있다. 이에 본 발명의 일 실시예에 따른 서버는 푸리에 변환 처리를 통해 고차원으로 매핑 시켜서 더 많은 정보를 고려하게 함으로써 적은 데 이터의 반려 동물 이미지에 대해서도 적합한 고유값을 생성할 수 있다. 다음으로, 서버는 제1 특징 추출 단계(S23-1) 및 제2 특징 추출 단계(S23-2)를 통해 각각 획득한 복수의 특 징점과 주파수 영역의 특징값을 기설정된 기계 학습 모델에 입력하여 학습 처리하여 반려 동물을 식별할 수 있 는 하나 이상의 정보를 포함하는 고유값(즉, 반려 동물 고유 식별 정보)를 생성한다(S24). 서버는 기계 학습 모델에 동일 반려 동물에 대한 서로 다른 복수의 입력 이미지 각각에 따른 푸리에 변환값 및 이미지 특징값을 입력하여 기계 학습 처리를 통해 하나의 고유값을 생성할 수 있다. 구체적으로, 도 3의 제4 단계(S34)에 도시된 바와 같이, 서버는 특징 추출기를 통해 추출된 이미지 특징값 과 푸리에 변환기를 통해 추출된 푸리에 변환값을 기설정된 기계 학습 모델을 이용한 고유값 생성기를 통해 학 습 처리하여, 반려 동물을 식별할 수 있는 하나 이상의 정보를 포함하는 고유값을 생성 및 출력한다. 이때, 고유값은 반려 동물에 고유하게 부여되는 식별 정보, 상기 반려 동물의 종(species) 정보, 및 상기 반려 동물의 거주 지역 정보 중 적어도 하나를 포함할 수 있다. 예를 들어, 반려 동물에 대한 고유값은 주민등록번 호와 같이 일련의 숫자 정보로 표현될 수 있으며, 숫자 정보의 위치 및 단위 별로 특정한 정보를 의미할 수 있 다. 즉, 도 3의 제4 단계(S34)에 도시된 바와 같이, 반려 동물 고유 식별 정보가 “0000231”과 같은 숫자 정보 로 표현될 경우, 1번째 숫자는 해당 동물에 고유하게 부여된 번호일 수 있고, 2번째 숫자는 해당 반려 동물의 종을 구분할 수 있는 종 번호 일 수 있으며, 3번째 숫자는 해당 반려 동물이 거주하는 지역에 대한 번호일 수 있다. 이와 같은 방식으로 복수의 자리로 형성된 숫자 정보의 위치 및 단위 별로 다양한 정보를 추가로 저장할 수 있으며, 다수의 반려 동물들에 대해 반려 동물 고유 식별 정보에 포함된 숫자 위치 및 단위 별로 공통적인 의미를 적용함으로써 반려 동물 고유 식별 정보만으로 해당 반려 동물에 대한 정보를 해석할 수 있다. 또한, 서버는 생성된 반려 동물의 고유값을 적어도 하나의 전자 장치로 전송하여(S25), 전자 장치 에서 고유값 및 고유값에 대응하는 반려 동물의 정보와 함께 출력되도록 할 수 있다. 도 5는 본 발명의 일 실시예에 따라 도 2 내지 도 4의 동작을 서버가 아닌 전자 장치가 수행하는 반려 동물 식별 정보 생성 시스템을 도시한 일 예이다. 즉, 도 2 내지 도 4에서는 서버가 도 2 내지 도 4의 방법을 수행하는 것으로 기술하였으나, 본 발명의 구현예에 따라, 도 5에 도시된 바와 같이 하나의 전자 장치 가 상기 도 2내지 도 4의 방법을 수행할 수 있다. 예를 들어, 하나의 전자 장치는 촬상되거나 또는 저 장된 이미지 데이터로부터 반려 동물의 얼굴 영역 이미지를 추출하고, 추출된 얼굴 영역 이미지에 대한 제1 및 제2 특징 추출 단계를 수행하여 RGB 이미지에 대한 특징값 및 푸리에 변환값을 모두 적용한 반려 동물 고유 식 별 정보를 생성할 수 있다. 또한, 하나의 전자 장치는 생성된 반려 동물 고유 식별 정보 및 그에 대응하는 반려 동물의 정보를 네트워크로 연결된 다른 전자 장치들로 전송될 수 있다. 또한, 구현예에 따라, 도 2내지 도 4의 방법을 복수의 전자 장치들이 분산 수행하는 것도 가능하다는 것은 본 발명의 당업자에게 용이하게 이해될 수 있으므로 자세한 설명은 생략한다. 도 6은 본 발명의 일 실시 예에 따른 서버의 구성도이다. 프로세서는 하나 이상의 코어(core, 미도시) 및 그래픽 처리부(미도시) 및/또는 다른 구성 요소와 신호를 송수신하는 연결 통로(예를 들어, 버스(bus) 등)를 포함할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 도 1 내지 도 5과 관련하여 설명된 방법을 수행한다. 한편, 프로세서는 프로세서 내부에서 처리되는 신호(또는, 데이터)를 일시적 및/또는 영구적으로 저 장하는 램(RAM: Random Access Memory, 미도시) 및 롬(ROM: Read-Only Memory, 미도시)을 더 포함할 수 있다. 또한, 프로세서는 그래픽 처리부, 램 및 롬 중 적어도 하나를 포함하는 시스템 온 칩(SoC: system on chip) 형태로 구현될 수 있다. 메모리에는 프로세서의 처리 및 제어를 위한 프로그램들(하나 이상의 인스트럭션들)을 저장할 수 있 다. 메모리에 저장된 프로그램들은 기능에 따라 복수 개의 모듈들로 구분될 수 있다. 또한, 서버는 상기의 구성들 이외에, 각 기능에서 처리되는 데이터 등을 표시하고 사용자 입력(예컨대, 터 치 등)을 수신하는 디스플레이부(미도시), 다른 전자 장치 등과 통신하기 위한 적어도 하나의 구성요소를 포함 하는 통신부(미도시), 사용자의 음성을 입력받는 마이크(미도시) 등을 더 포함할 수 있다. 그러나, 본 발명의"}
{"patent_id": "10-2022-0133149", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "서버가 더 많은 구성요소들을 포함하여 구현될 수 있음은 본 발명의 기술분야의 당업자가 용이하게 이해할 수 있을 것이다. 한편, 도 6의 구성요소들은 전자 장치의 구성들에 대응될 수도 있다. 즉, 전자 장치는 하나 이상의 코 어 및 그래픽 처리부를 포함하는 프로세서 및 메모리를 포함하며, 프로세서는 메모리에 저장된 하나 이상의 인 스트럭션을 실행함으로써 도1 내지 도 5와 관련하여 설명된 방법을 수행할 수 있다. 한편, 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드 웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모 듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다. 본 발명의 구성 요소들은 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 애플리케이션)으로 구현 되어 매체에 저장될 수 있다. 예를 들어, 본 발명의 일 실시예는 컴퓨터에서 독출가능한 기록매체에 저장된 컴 퓨터프로그램으로서, 입력 이미지로부터 반려 동물의 얼굴 영역을 추출하는 기능, 추출한 얼굴 영역의 이미지 를 푸리에 변환기를 통해 처리하여 푸리에 변환값을 출력하는 기능, 추출한 얼굴 영역의 이미지를 제1 기계 학 습 모델을 이용한 특징 추출기를 통해 처리하여 이미지 특징값을 출력하는 기능, 및 푸리에 변환값과 이미지 특 징값을 제2 기계 학습 모델을 이용한 고유값 생성기를 통해 학습 처리하여 반려 동물을 식별할 수 있는 하나 이 상의 정보를 포함하는 고유값을 생성하는 기능을 수행할 수 있다. 또한, 본 발명의 구성 요소들은 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행될 수 있으며, 이와 유사 하게, 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조합으로 구현되는 다양한 알고리즘을 포함하여, C, C++, 자바(Java), 어셈블러(assembler), 파이선(Python) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현 될 수 있다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 또한, 본 발명에 개시된 실시 예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하기 한 것이고, 이러한 실시 예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 따라서, 본 발명의 호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명 의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0133149", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 반려 동물 고유 식별 정보 생성 시스템을 도시한 도면이다. 도 2는 본 발명의 일 실시예에 따른 반려 동물 고유 식별 정보 생성 시스템의 동작 방법을 도시한 순서도이다. 도 3은 본 발명의 일 실시예에 따른 반려 동물 고유 식별 정보 생성 프로세스를 나타낸 도식도이다. 도 4는 본 발명의 일 실시예에 따른 반려 동물 특징 추출 단계에 적용되는 인공 신경망의 일 예의 개념을 도시 한 도면이다. 도 5는 본 발명의 일 실시예에 따라 도 2 내지 도 4의 동작을 서버가 아닌 전자 장치가 수행하는 반려 동물 고 유 식별 정보 생성 시스템을 도시한 일 예이다. 도 6은 본 발명의 일 실시 예에 따른 서버의 구성도이다."}
