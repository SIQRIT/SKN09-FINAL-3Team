{"patent_id": "10-2021-0049327", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0142823", "출원번호": "10-2021-0049327", "발명의 명칭": "인공지능 기반의 병해충 진단 시스템 및 방법", "출원인": "(주)농협정보시스템", "발명자": "나훈"}}
{"patent_id": "10-2021-0049327", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "미리 수집된 원시 작물 이미지를 저장하고 있는 이미지 저장 모듈;상기 이미지 저장 모듈에 저장된 원시 작물 이미지에 비지도 학습(Unsupervised Learning)에 따른 AutoML(Auto Machine Learning)을 적용하는 방식으로 상기 원시 작물 이미지를 그 클래스별로 분류하여 분류 작물이미지를 생성하는 Auto ML 모듈;상기 Auto ML 모듈에 의해 생성된 분류 작물 이미지에 미리 정의된 Auto Labeling 알고리즘을 적용하여 상기 분류 작물 이미지의 Annotation 파일을 생성하는 Auto Labeling 모듈;상기 Auto ML 모듈에 의해 생성된 분류 작물 이미지와 상기 Auto Labeling 모듈에 의해 생성된 Annotation 파일을 매핑하여 학습 데이터 셋(Training Data Set)을 생성하는 학습 데이터 생성 모듈;상기 학습 데이터 생성 모듈에 의해 생성된 학습 데이터 셋을 기반으로, 입력된 작물 이미지 상의 병해충을 신경망을 통해 진단하도록 구성된 딥 러닝(Deep Learning) 모델을 학습시키는 학습 모듈; 및제1 사용자가 소지한 제1 사용자 단말로부터 대상 작물 이미지를 입력받으며, 상기 학습 모듈에 의해 학습된 딥러닝 모델에 상기 대상 작물 이미지가 적용되어 도출된, 상기 대상 작물 이미지에 반영된 병해충 진단 결과를상기 제1 사용자 단말로 제공하는 인터페이스 모듈;을 포함하는 것을 특징으로 하는 인공지능 기반의 병해충 진단 시스템."}
{"patent_id": "10-2021-0049327", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 Auto ML 모듈에 의해 생성된 분류 작물 이미지에 대하여 디노이징(Denoising), 리사이징(Resizing), 업스케일링(Upscaling) 및 증강(Augmentation) 중 하나 이상을 적용하여 상기 분류 작물 이미지에 대한 정제 작업을수행하는 정제 모듈;을 더 포함하고,상기 Auto Labeling 모듈은, 상기 정제 모듈에 의해 정제된 분류 작물 이미지로부터 그 Annotation 파일을 생성하는 것을 특징으로 하는 인공지능 기반의 병해충 진단 시스템."}
{"patent_id": "10-2021-0049327", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 Auto Labeling 모듈은, Auto Labeling 알고리즘에 따라, Instance Segmentation을 통해 상기 분류 작물이미지의 픽셀 단위로 오브젝트를 식별하고 Auto Labeling을 수행하여 Annotation 파일을 생성하는 것을 특징으로 하는 인공지능 기반의 병해충 진단 시스템."}
{"patent_id": "10-2021-0049327", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 학습 데이터 생성 모듈은, 상기 학습 데이터 셋을, 상기 딥 러닝 모델의 학습을 위한 훈련용 데이터 셋 및검증용 데이터 셋과, 학습된 딥 러닝 모델의 평가를 위한 평가용 데이터 셋으로 구분하여 생성하는 것을 특징으로 하는 인공지능 기반의 병해충 진단 시스템.공개특허 10-2022-0142823-3-청구항 5 제4항에 있어서,상기 학습 모듈은, 상기 훈련용 데이터 셋 및 상기 검증용 데이터 셋을 기반으로 상기 딥 러닝 모델을 학습시킬때 도출되는 손실함수의 값(Loss)이 미리 설정된 제1 기준치 이하가 되도록 상기 딥 러닝 모델을 반복 학습시키되, 반복 학습되는 에포크(Epoch)의 수는 미리 설정된 상한치를 갖는 것을 특징으로 하는 인공지능 기반의 병해충 진단 시스템."}
{"patent_id": "10-2021-0049327", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 학습 모듈에 의해 학습이 완료된 딥 러닝 모델에 상기 평가용 데이터 셋을 적용하고, 그 적용 결과 도출되는 mAP(mean Average Precision) 값이 미리 설정된 제2 기준치 이상인지 여부를 판단하는 방식으로 상기 학습이완료된 딥 러닝 모델을 평가하는 평가 모듈;을 더 포함하는 것을 특징으로 하는 인공지능 기반의 병해충 진단시스템."}
{"patent_id": "10-2021-0049327", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 딥 러닝 모델은 Mask-RCNN 모델인 것을 특징으로 하는 인공지능 기반의 병해충 진단 시스템."}
{"patent_id": "10-2021-0049327", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 병해충 진단 결과는 병해충의 종류 및 인식 정확도를 포함하고,상기 인터페이스 모듈은 상기 딥 러닝 모델에 의해 도출된 병해충에 대한 정보를 외부 시스템으로 전달받아 상기 제1 사용자 단말로 제공하는 것을 특징으로 하는 인공지능 기반의 병해충 진단 시스템."}
{"patent_id": "10-2021-0049327", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 인터페이스 모듈은, 상기 딥 러닝 모듈에 의해 도출된 병해충의 인식 정확도가 미리 설정된 제3 기준치 미만인 경우, 제2 사용자가 소지한 제2 사용자 단말로 상기 진단 결과를 전달하여, 상기 제2 사용자가 상기 진단결과를 분석하도록 하고,상기 제2 사용자의 분석은 상기 제1 사용자 단말로 피드백되도록 구성되는 것을 특징으로 하는 인공지능 기반의병해충 진단 시스템."}
{"patent_id": "10-2021-0049327", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 분류 작물 이미지에는 해당 이미지의 지역 정보 및 시간 정보를 포함하는 메타 데이터가 반영되어 있고,상기 분류 작물 이미지의 메타 데이터를 토대로 병해충의 발생 현황 및 발생 지역이 반영된 병해충 지도 데이터를 생성하는 병해충 지도 데이터 생성 모듈;을 더 포함하며,공개특허 10-2022-0142823-4-상기 인터페이스 모듈은, 상기 지도 데이터 생성 모듈에 의해 생성된 병해충 지도 데이터를 상기 제1 사용자 단말로 제공하는 것을 특징으로 하는 인공지능 기반의 병해충 진단 시스템."}
{"patent_id": "10-2021-0049327", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "서버에 의해 수행되는 인공지능 기반의 병해충 진단 방법으로서,입력된 작물 이미지 상의 병해충을 신경망을 통해 진단하도록 구성된 딥 러닝(Deep Learning) 모델을 학습시키는 단계로서,미리 수집된 원시 작물 이미지에 비지도 학습(Unsupervised Learning)에 따른 Auto ML(Auto Machine Learning)을 적용하는 방식으로 상기 원시 작물 이미지를 그 클래스별로 분류하여 분류 작물 이미지를 생성하는 단계;상기 생성된 분류 작물 이미지에 미리 정의된 Auto Labeling 알고리즘을 적용하여 상기 분류 작물 이미지의Annotation 파일을 생성하는 단계;상기 생성된 분류 작물 이미지 및 Annotation 파일을 매핑하여 학습 데이터 셋(Training Data Set)을 생성하는단계; 및상기 생성된 학습 데이터 셋을 기반으로, 상기 딥 러닝 모델을 학습시키는 단계;를 포함하는, 단계;제1 사용자가 소지한 제1 사용자 단말로부터 대상 작물 이미지를 입력받는 단계;상기 학습된 딥 러닝 모델에 상기 대상 작물 이미지를 적용하여 상기 대상 작물 이미지에 반영된 병해충을 진단하는 단계; 및상기 병해충의 진단 결과를 상기 제1 사용자 단말로 제공하는 단계;를 포함하는 것을 특징으로 하는 인공지능 기반의 병해충 진단 방법."}
{"patent_id": "10-2021-0049327", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 기반의 병해충 진단 시스템 및 방법에 관한 것으로서, 미리 수집된 원시 작물 이미지를 저장 하고 있는 이미지 저장 모듈; 이미지 저장 모듈에 저장된 원시 작물 이미지에 비지도 학습(Unsupervised Learning)에 따른 Auto ML(Auto Machine Learning)을 적용하는 방식으로 원시 작물 이미지를 그 클래스별로 분 (뒷면에 계속)"}
{"patent_id": "10-2021-0049327", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반의 병해충 진단 시스템 및 방법에 관한 것으로서, 보다 상세하게는 입력된 작물 이미지 상의 병해충을 딥 러닝 모델을 통해 진단하는, 인공지능 기반의 병해충 진단 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0049327", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 농업 기술에 IT 기술의 접목시키는 작물 재배 관리 시스템들이 개발되어 농업 현장에 적용되고 있으며, 이러한 작물 재배 관리 시스템들은 시설 작물 재배(온실 재배) 분야에서 광범위하게 활용되고 있다. 이러한 작 물 재배 관리 시스템은 여러 가지 제어장치, 예컨대 조명, 창문 개폐, 수분 공급기, 차광 커튼, 환풍기 등과 같 은 제어 장치를 구비하여 작물의 생장환경을 적절하게 조절해 줌으로써, 시설 작물에서의 단위 면적당 생산량을 획기적으로 증대시키고 있다. 여기에서, 시설 작물은, 예컨대 채소, 화훼, 과일 등이 될 수 있다. 또한, 작물 재배 관리 시스템은 다양한 작물들에 대한 병해충 정보 및 각 작물별 병해충들에 대한 방제역 정보 를 병해충 데이터베이스로 구축하고, 필요할 때마다 사용자 인터페이스를 통해 병해충 데이터베이스를 검색하여 원하는 병해충 관련 정보를 얻을 수 있도록 함으로써, 시설 작물의 생장시에 발생할 수 있는 병해충에 대해 적 절하게 대응하도록 하는 서비스를 제공하고 있다. 관련하여, 대한민국 등록특허공보 제10-1986418호(이하, 선행문헌)는 병해충 검색을 위한 통합 시스템을 개시하 고 있으며, 구체적으로 질의 이미지로부터 유사도 이미지 및 병해충 정보를 획득하고, 질의 이미지에 대한 병해 충 정보를 포함하는 병해충 결과를 출력하며, 질의 이미지로부터 획득된 유사도 이미지 또는 병해충 정보와 관 련된 병해충 이미지를 제공하는 구성을 개시하고 있다. 선행문헌에 개시된 구성은, 질의 이미지로부터 획득된 유사도 이미지를 제공하는 딥 러닝 기반의 단순 분류 (Classification)에 불과하기 때문에 어떤 병해충인지만 예측이 가능하며, 이미지 내에 1개 이상의 병해충이 존재할 경우 이를 구분해내지 못할 뿐만 아니라 각 객체들의 인스턴스(Instance)도 구분할 수 없어 그 정확도가 떨어지는 한계를 갖는다. 나아가, 종래 병해충을 식별하기 위한 딥 러닝을 학습시키는 과정은, 학습 데이터의 수집, 분류, 라벨링 및 튜 닝 등의 과정으로 이루어지며, 상기 작업은 현재 작업자의 수작업에 의존하여 이루어지고 있어, 딥 러닝 학습 과정에서 상당한 시간 및 비용적 소모가 야기되고 있다."}
{"patent_id": "10-2021-0049327", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 측면에 따른 목적은 종래 딥 러닝 기반의 단순 분류를 이용한 병해충 식별 방법에 있어서 그 식별 정확도가 감소되는 문제점을 해결하여 그 식별 및 진단 정확도를 향상시킴과 동시에, 데이터를 수집하는 과정에 서부터 딥 러닝 모델을 학습시키는 일련의 과정을 자동화하여 작업자의 수작업에 의해 야기되는 시간 및 비용적 소모를 제거하기 위한, 인공지능 기반의 병해충 진단 시스템 및 방법을 제공하는 것이다."}
{"patent_id": "10-2021-0049327", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따른 인공지능 기반의 병해충 진단 시스템은 미리 수집된 원시 작물 이미지를 저장하고 있 는 이미지 저장 모듈; 상기 이미지 저장 모듈에 저장된 원시 작물 이미지에 비지도 학습(Unsupervised Learning)에 따른 Auto ML(Auto Machine Learning)을 적용하는 방식으로 상기 원시 작물 이미지를 그 클래스별 로 분류하여 분류 작물 이미지를 생성하는 Auto ML 모듈; 상기 Auto ML 모듈에 의해 생성된 분류 작물 이미지에 미리 정의된 Auto Labeling 알고리즘을 적용하여 상기 분류 작물 이미지의 Annotation 파일을 생성하는 Auto Labeling 모듈; 상기 Auto ML 모듈에 의해 생성된 분류 작물 이미지와 상기 Auto Labeling 모듈에 의해 생성된 Annotation 파일을 매핑하여 학습 데이터 셋(Training Data Set)을 생성하는 학습 데이터 생성 모듈; 상기 학습 데이터 생성 모듈에 의해 생성된 학습 데이터 셋을 기반으로, 입력된 작물 이미지 상의 병해충을 신경망을 통해 진단하도록 구성된 딥 러닝(Deep Learning) 모델을 학습시키는 학습 모듈; 및 제1 사용자가 소지한 제1 사용자 단말로부터 대상 작물 이미지를 입력받으며, 상기 학습 모듈에 의해 학습된 딥 러닝 모델에 상기 대상 작물 이 미지가 적용되어 도출된, 상기 대상 작물 이미지에 반영된 병해충 진단 결과를 상기 제1 사용자 단말로 제공하 는 인터페이스 모듈;을 포함하는 것을 특징으로 한다. 본 발명은 상기 Auto ML 모듈에 의해 생성된 분류 작물 이미지에 대하여 디노이징(Denoising), 리사이징 (Resizing), 업스케일링(Upscaling) 및 증강(Augmentation) 중 하나 이상을 적용하여 상기 분류 작물 이미지에 대한 정제 작업을 수행하는 정제 모듈;을 더 포함하고, 상기 Auto Labeling 모듈은, 상기 정제 모듈에 의해 정 제된 분류 작물 이미지로부터 그 Annotation 파일을 생성하는 것을 특징으로 한다. 본 발명에 있어 상기 Auto Labeling 모듈은, Auto Labeling 알고리즘에 따라, Instance Segmentation을 통해 상기 분류 작물 이미지의 픽셀 단위로 오브젝트를 식별하고 Auto Labeling을 수행하여 Annotation 파일을 생성 하는 것을 특징으로 한다. 본 발명에 있어 상기 학습 데이터 생성 모듈은, 상기 학습 데이터 셋을, 상기 딥 러닝 모델의 학습을 위한 훈련 용 데이터 셋 및 검증용 데이터 셋과, 학습된 딥 러닝 모델의 평가를 위한 평가용 데이터 셋으로 구분하여 생성 하는 것을 특징으로 한다. 본 발명에 있어 상기 학습 모듈은, 상기 훈련용 데이터 셋 및 상기 검증용 데이터 셋을 기반으로 상기 딥 러닝 모델을 학습시킬 때 도출되는 손실함수의 값(Loss)이 미리 설정된 제1 기준치 이하가 되도록 상기 딥 러닝 모델 을 반복 학습시키되, 반복 학습되는 에포크(Epoch)의 수는 미리 설정된 상한치를 갖는 것을 특징으로 한다. 본 발명은 상기 학습 모듈에 의해 학습이 완료된 딥 러닝 모델에 상기 평가용 데이터 셋을 적용하고, 그 적용 결과 도출되는 mAP(mean Average Precision) 값이 미리 설정된 제2 기준치 이상인지 여부를 판단하는 방식으로 상기 학습이 완료된 딥 러닝 모델을 평가하는 평가 모듈;을 더 포함하는 것을 특징으로 한다. 본 발명에 있어 상기 딥 러닝 모델은 Mask-RCNN 모델인 것을 특징으로 한다. 본 발명에 있어 상기 병해충 진단 결과는 병해충의 종류 및 인식 정확도를 포함하고, 상기 인터페이스 모듈은 상기 딥 러닝 모델에 의해 도출된 병해충에 대한 정보를 외부 시스템으로 전달받아 상기 제1 사용자 단말로 제 공하는 것을 특징으로 한다. 본 발명에 있어 상기 인터페이스 모듈은, 상기 딥 러닝 모듈에 의해 도출된 병해충의 인식 정확도가 미리 설정 된 제3 기준치 미만인 경우, 제2 사용자가 소지한 제2 사용자 단말로 상기 진단 결과를 전달하여, 상기 제2 사 용자가 상기 진단 결과를 분석하도록 하고, 상기 제2 사용자의 분석은 상기 제1 사용자 단말로 피드백되도록 구 성되는 것을 특징으로 한다. 본 발명에 있어 상기 분류 작물 이미지에는 해당 이미지의 지역 정보 및 시간 정보를 포함하는 메타 데이터가 반영되어 있고, 상기 분류 작물 이미지의 메타 데이터를 토대로 병해충의 발생 현황 및 발생 지역이 반영된 병 해충 지도 데이터를 생성하는 병해충 지도 데이터 생성 모듈;을 더 포함하며, 상기 인터페이스 모듈은, 상기 지 도 데이터 생성 모듈에 의해 생성된 병해충 지도 데이터를 상기 제1 사용자 단말로 제공하는 것을 특징으로 한 다. 본 발명의 일 측면에 따른 인공지능 기반의 병해충 진단 방법은 입력된 작물 이미지 상의 병해충을 신경망을 통 해 진단하도록 구성된 딥 러닝(Deep Learning) 모델을 학습시키는 단계로서, 미리 수집된 원시 작물 이미지에 비지도 학습(Unsupervised Learning)에 따른 Auto ML(Auto Machine Learning)을 적용하는 방식으로 상기 원시 작물 이미지를 그 클래스별로 분류하여 분류 작물 이미지를 생성하는 단계; 상기 생성된 분류 작물 이미지에 미 리 정의된 Auto Labeling 알고리즘을 적용하여 상기 분류 작물 이미지의 Annotation 파일을 생성하는 단계; 상 기 생성된 분류 작물 이미지 및 Annotation 파일을 매핑하여 학습 데이터 셋(Training Data Set)을 생성하는 단 계; 및 상기 생성된 학습 데이터 셋을 기반으로, 상기 딥 러닝 모델을 학습시키는 단계;를 포함하는, 단계; 제1 사용자가 소지한 제1 사용자 단말로부터 대상 작물 이미지를 입력받는 단계; 상기 학습된 딥 러닝 모델에 상기 대상 작물 이미지를 적용하여 상기 대상 작물 이미지에 반영된 병해충을 진단하는 단계; 및 상기 병해충의 진단 결과를 상기 제1 사용자 단말로 제공하는 단계;를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2021-0049327", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, 본 발명은 비지도 학습(Unsupervised Learning)에 따른 Auto ML(Auto Machine Learning)과, 이미지 내의 오브젝트를 식별하고 Instance Segmentation을 통해 픽셀 단위로 Auto Labeling을 수행하여 Annotation 파일을 생성하는 Auto Labeling을 결합시킨 구조를 기반으로 딥 러닝 모델을 학습시키고 그에 따라 병해충을 진단하는 구성을 채용함으로써, 종래 딥 러닝 기반의 단순 분류를 이용한 병해충 식별 방법 에 있어서 식별 정확도가 감소되는 문제점을 해결하여 식별 및 진단 정확도를 향상시킴과 동시에 작업자의 수작 업에 의해 야기되는 시간 및 비용적 소모를 제거할 수 있다. 또한, 이미지의 메타 데이터를 토대로 병해충 지도 데이터를 사용자에게 제공하여 사용자로 하여금 병해충의 발 생 현황 및 발생 지역을 파악 및 예측하도록 하는 서비스를 제공할 수 있어, 그 활용 확장성 측면에서도 이점을 갖는다."}
{"patent_id": "10-2021-0049327", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면들을 참조하여 본 발명에 따른 인공지능 기반의 병해충 진단 시스템 및 방법의 실시예를 설명 한다. 이 과정에서 도면에 도시된 선들의 두께나 구성요소의 크기 등은 설명의 명료성과 편의상 과장되게 도시 되어 있을 수 있다. 또한, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자,운용자의 의도 또는 관례에 따라 달라질 수 있다. 그러므로 이러한 용어들에 대한 정의는 본 명세서 전반에 걸 친 내용을 토대로 내려져야 할 것이다. 도 1 및 도 2는 본 발명의 일 실시예에 따른 인공지능 기반의 병해충 진단 시스템을 설명하기 위한 블록구성도 이고, 도 3 및 도 4는 본 발명의 일 실시예에 따른 인공지능 기반의 병해충 진단 시스템에서 제1 사용자 단말을 통해 제공되는 UI를 보인 예시도이다. 도 1을 참조하면, 본 실시예에 따른 인공지능 기반의 병해충 진단 시스템(이하, 병해충 진단 시스템)은 제1 내 지 제3 사용자가 각각 소지한 제1 내지 제3 사용자 단말(DEV1, DEV2, DEV3) 및 진단 서버(SERVER)를 포함할 수 있으며, 진단 서버(SERVER)는 제1 내지 제3 사용자 단말(DEV1, DEV2, DEV3)과 외부 시스템(EXT)(예: 영농 정보 시스템, 후술)과 유무선 통신을 통해 연결되도록 구성될 수 있다. 제1 사용자는 작물을 재배하는 영농인에 해당 할 수 있고, 제2 사용자는 작물에 발생할 수 있는 병해충에 대한 전문가에 해당할 수 있으며, 제3 사용자는 본 실시예에서 제공하는 병해충 진단 서비스를 제공하기 위해 원시 작물 이미지를 수집하는 수집인에 해당할 수 있 다. 제1 내지 제3 사용자 단말(DEV1, DEV2, DEV3)은 각 사용자가 소지한 스마트폰, 태블릿 또는 PC 등 컴퓨팅 디바이스로 구현될 수 있으며, 진단 서버(SERVER)와의 통신을 기반으로 본 실시예의 병해충 진단 서비스를 제공 하기 위한 전용 어플리케이션이 제1 내지 제3 사용자 단말(DEV1, DEV2, DEV3)에 설치되어 있을 수 있다. 이에 따라, 제1 사용자가 제1 사용자 단말(DEV1)을 통해 자신이 재배하는 작물에 대한 이미지(대상 작물 이미지 로 정의한다)를 촬영하여 진단 서버(SERVER)로 전송하면, 진단 서버(SERVER)는 입력된 대상 작물 이미지를 미리 학습된 딥 러닝 모델에 적용하여 대상 작물 이미지 상의 병해충을 진단하고 그 진단 결과를 제1 사용자 단말 (DEV1)로 전송하여 제1 사용자가 확인하도록 할 수 있다. 이때, 딥 러닝 모델에 의해 도출된 병해충의 인식 정 확도가 소정치 미만인 경우, 진단 서버(SERVER)는 병해충 진단 결과를 제2 사용자 단말(DEV2)로 전달하여 제2 사용자가 병해충 진단 결과를 분석하도록 할 수 있으며, 제2 사용자의 분석은 제1 사용자 단말(DEV1)로 피드백 됨으로써 제1 사용자는 보다 정확한 병해충에 대한 정보를 제공받을 수 있다. 대상 작물 이미지를 진단하기 위 해 이용되는 딥 러닝 모델은 제3 사용자에 의해 기 획득된 작물 이미지(원시 작물 이미지로 정의한다)를 기반으 로 학습될 수 있으며, 또한 제1 사용자 단말(DEV1)로부터 전송된 대상 작물 이미지도 딥 러닝 모델의 학습에 활 용되도록 구성될 수도 있다. 위 내용을 바탕으로, 본 실시예의 병해충 진단 시스템의 동작을 진단 서버(SERVER)의 구성을 중심으로 구체적으 로 설명한다. 도 2에 도시된 것과 같이 진단 서버(SERVER)는 인터페이스 모듈, 이미지 저장 모듈, Auto ML 모듈, 정제 모듈, Auto Labeling 모듈, 학습 데이터 생성 모듈, 학습 모듈, 평가 모듈, 모델 버 전 관리 모듈, 진단 모듈, 빅데이터 저장 모듈 및 지도 데이터 생성 모듈을 포함할 수 있다. 인터페이스 모듈은 제1 내지 제3 사용자 단말(DEV1, DEV2, DEV3)로부터 전송되는 데이터를 입력받고, 진단 서버(SERVER)로부터 데이터를 제1 내지 제3 사용자 단말(DEV1, DEV2, DEV3)로 출력하는, 제1 내지 제3 사용자 단말(DEV1, DEV2, DEV3)과 진단 서버(SERVER) 간의 입출력 인터페이스 기능을 수행할 수 있으며, 데이터 송수신 을 위한 유무선 통신 모듈로 구현될 수 있다. 이미지 저장 모듈은 제3 사용자 단말(DEV3)에 의해 미리 수집된 원시 작물 이미지를 저장하고 있을 수 있다. 원시 작물 이미지는 후술하는 Auto ML 및 Auto Labeling을 거쳐 딥 러닝 모델을 학습시키기 위한 데이터 로 활용될 수 있다. 또한, 제1 사용자 단말(DEV1)로부터 전달되는 대상 작물 이미지 또한 이미지 저장 모듈(2 0)에 저장되어 딥 러닝 모델을 학습시키기 위한 데이터로 활용될 수 있다. Auto ML(Auto Machine Learning) 모듈은 이미지 저장 모듈에 저장된 원시 작물 이미지에 비지도 학습 (Unsupervised Learning)에 따른 Auto ML(Auto Machine Learning)을 적용하는 방식으로 원시 작물 이미지를 그 클래스별로 분류할 수 있다(용어의 명확한 구분을 위해 Auto ML 모듈에 의해 클래스별로 분류된 원시 작물 이미지를 분류 작물 이미지로 정의한다). 즉, Auto ML 모듈은 라벨링이 수행되기 전인 원시 작물 이미지에 대하여 Auto ML 알고리즘을 적용하여, 이미지의 특징(클래스)의 유사성을 토대로 원시 작물 이미지를 군집화하 는 방식으로 분류 작물 이미지를 생성할 수 있으며, Auto ML 알고리즘은 비지도 학습이 적용되어 Auto ML 모듈 에 미리 정의되어 있을 수 있다. 정제 모듈은 Auto ML 모듈에 의해 생성된 분류 작물 이미지에 대하여 디노이징(Denoising), 리사이징 (Resizing), 업스케일링(Upscaling) 및 증강(Augmentation) 중 하나 이상을 적용하여 분류 작물 이미지에 대한정제 작업을 수행할 수 있으며, 정제 작업은 분류 작물 이미지를 딥 러닝 모델의 학습용으로 활용하기 위한 전 처리 과정에 해당한다. 구체적으로, 정제 모듈은 분류 작물 이미지에 대한 이미지 디노이징을 통해 노이즈 를 제거하는 과정, 후술하는 딥 러닝 모델로서 Mask-RCNN에서 사용되는 Backbone의 구조에 따라 이미지의 긴축 사이즈를 리사이징하는 과정(예: Mask-RCNN의 Backbone으로 ResNet-101이 사용된 경우, ResNet 네트워크에서 가장 효율이 좋은 1024px의 이미지로 리사이징), 이미지의 사이즈 및 해상도가 기준값 미만인 저품질의 데이터 에 대한 이미지 업스케일링 과정, 또는 분류 작물 이미지의 양이 기준치 미만이어서 딥 러닝 모델의 학습을 위 한 데이터량이 불충분한 경우, 충분한 데이터를 확보하기 위한 데이터 증강 과정을 수행할 수 있다. Auto Labeling 모듈은 Auto ML 모듈에 의해 생성된 분류 작물 이미지(또는 정제 모듈에 의해 정제 된 분류 작물 이미지)에 미리 정의된 Auto Labeling 알고리즘을 적용하여 분류 작물 이미지의 Annotation 파일 을 생성할 수 있다. Auto Labeling 알고리즘은 Instance Segmentation을 통해 분류 작물 이미지의 픽셀 단위로 오브젝트를 식별하고 Auto Labeling을 수행하여 Annotation 파일을 생성하는 알고리즘으로서 Auto Labeling 모 듈에 미리 정의되어 있을 수 있다. Auto Labeling 알고리즘에 따라 분류 작물 이미지의 픽셀 단위로 오브젝 트를 식별하고 Auto Labeling을 수행하여 Annotation 파일을 생성하는 Instance Segmentation을 수행함으로써, 후술하는 딥 러닝 모델인 Mask-RCNN에 의한 진단 정확도를 보장할 수 있게 된다. 학습 데이터 생성 모듈은 Auto ML 모듈에 의해 생성된 분류 작물 이미지와 Auto Labeling 모듈에 의해 생성된 Annotation 파일을 매핑하여 딥 러닝 모델의 학습을 위한 학습 데이터 셋(Training Data Set)을 생 성할 수 있다. 이 경우, 학습 데이터 생성 모듈은 딥 러닝 모델의 학습 및 평가를 위해, 학습 데이터 셋을, 딥 러닝 모델의 학습을 위한 훈련용 데이터 셋(Training Data Set) 및 검증용 데이터 셋(Validation Data Se t)과, 학습된 딥 러닝 모델의 평가를 위한 평가용 데이터 셋(Test Data Set)으로 구분하여 생성할 수 있으며, 그 비율은 설계자의 의도에 따라 특정값으로 설정되어 있을 수 있다(예: 훈련용 데이터 셋 70%, 검증용 데이터 셋 30%, 평가용 데이터 셋 10%). 학습 모듈은 학습 데이터 생성 모듈에 의해 생성된 학습 데이터 셋을 기반으로, 입력된 작물 이미지 상 의 병해충을 신경망을 통해 진단하도록 구성된 딥 러닝(Deep Learning) 모델을 학습시킬 수 있다. 딥 러닝 모델 은 모델 버전 관리 모듈에 의해 저장 관리되며, Mask-RCNN으로 구현되어 작물 이미지를 입력받아 그 진단 결과로서 병해충의 종류 및 인식 정확도를 출력하도록 구성될 수 있다. 딥 러닝 모델의 학습 방법으로서, 훈련용 데이터 셋 및 검증용 데이터 셋을 기반으로 딥 러닝 모델을 학습시킬 때 도출되는 손실함수의 값(Loss)이 미리 설정된 제1 기준치(예: 0.01) 이하가 되도록 딥 러닝 모델을 반복 학 습시키는 방식이 채용될 수 있으며, 손실함수의 값이 제1 기준치 이하가 될 때까지 딥 러닝 모델의 학습은 반복 수행될 수 있다. 다만, 딥 러닝 모델의 반복 학습의 수를 제한하기 위해, 반복 학습되는 에포크(Epoch)의 수는 미리 설정된 상한치(예: 5000)를 가질 수 있다. 딥 러닝 모델의 학습 과정에서 도출되는 손실함수의 값이 제1 기준치 이하에 도달한 경우, 학습 모듈은 현재 작업중인 에포크 수와 무관하게 딥 러닝 모델의 학습을 중지 하고, 학습을 통해 최종 생성된 가중치를 적용하여 딥 러닝 모델을 최종 구축할 수 있다. 이 경우, 최종 생성된 가중치 이외에, 학습 과정에서 생성된 이전 에포크의 가중치는 백업되거나 삭제될 수 있다. 전술한 과정을 통해 딥 러닝 모델의 학습이 완료되면, 평가 모듈은 학습이 완료된 딥 러닝 모델에 평가용 데이터 셋을 적용하는 방식으로 학습이 완료된 딥 러닝 모델을 평가할 수 있다. 이 경우, 학습 완료된 딥 러닝 모델을 통해 도출되는 객체 인식 정확도(즉, 병해충 인식 정확도)가, 이전에 학습이 완료된 딥 러닝 모델(즉, 모델 버전 관리 모듈에 저장되어 있던 이전 버전의 딥 러닝 모델)을 통해 도출되었던 객체 인식 정확도보다 일정치 이상 낮을 경우 오버피팅(Overfitting)에 해당하는 것으로 볼 수 있으므로, 평가 모듈은 학습 모듈 로 하여금 전술한 에포크 수의 상한치 및 제1 기준치를 조절하여 딥 러닝 모델에 대한 재학습을 수행하도록 할 수 있다. 학습 완료된 딥 러닝 모델을 통해 도출되는 객체 인식 정확도가, 이전에 학습이 완료된 딥 러닝 모델을 통해 도 출되었던 객체 인식 정확도보다 일정치 이상 낮지 않을 경우, 평가 모듈은 학습이 완료된 딥 러닝 모델에 평가용 데이터 셋을 적용하고, 그 적용 결과 도출되는 mAP(mean Average Precision) 값이 미리 설정된 제2 기준 치(예: 70) 이상인지 여부를 판단하는 방식으로 학습이 완료된 딥 러닝 모델을 평가할 수 있다. 평가용 데이터 셋 적용 결과 도출되는 mAP 값이 제2 기준치 미만인 것으로 판단된 경우, 평가 모듈은 하이 퍼 파라미터 최적화(HPO:Hyper Parameter Optimization) 방식을 통해 딥 러닝 모델의 하이퍼 파라미터 매개변수 (딥 러닝 모델의 은닉층의 수 및 크기, 은닉층의 뉴런 수, 학습률, 배치 크기(batch size) 등)들을 조절하고 손 실함수의 값이 최소화되는 가중치를 재탐색하는 방식으로 딥 러닝 모델의 하이퍼 파라미터를 최적화시킬 수 있다. 즉, 평가 모듈은 미리 설정된 하이퍼 파라미터의 설정 범위 내에서 특정 값을 샘플링하여 딥 러닝 모델 에 대한 재학습을 수행하고, 평가용 데이터 셋 적용 결과 도출되는 mAP 값이 제2 기준치 이상인지 여부를 판단 하는 과정을 반복 수행하여 하이퍼 파라미터의 범위를 좁혀 나가는 방식으로 딥 러닝 모델의 하이퍼 파라미터를 최적화시킬 수 있다. 평가 모듈에 의해 평가용 데이터 셋 적용 결과 도출되는 mAP 값이 제2 기준치 이상인 것으로 판단된 경우, 모델 버전 관리 모듈은 평가가 완료된 딥 러닝 모델을 저장하여 관리하며, 딥 러닝 모델의 반영 일자, 실행 정보, 학습 과정에서 도출된 성능 지표, 학습에 소요된 시간, 학습 데이터 셋, 및 하이퍼 파라미터 등의 정보와 함께 딥 러닝 모델의 버전을 관리할 수 있다. 이에 따라, 이전 버전의 딥 러닝 모델은 새로운 버전의 딥 러닝 모델로 갱신된다. 전술한 과정을 통해 딥 러닝 모델에 대한 학습 및 평가가 완료된 후, 인터페이스 모듈을 통해 제1 사용자 단말(DEV1)로부터 대상 작물 이미지가 입력되면, 진단 모듈은 학습 완료된 딥 러닝 모델에 대상 작물 이미 지를 적용하여, 대상 작물 이미지에 반영된 병해충을 진단할 수 있으며, 이에 따라 병해충의 종류 및 인식 정확 도(즉, 해당 작물의 실제 병해충이, 딥 러닝 모델에 의해 식별된 병해충에 해당할 확률)가 그 진단 결과로서 도 출될 수 있다. 진단 모듈에 의해 도출된 진단 결과는 인터페이스 모듈을 통해 제1 사용자 단말(DEV1) 로 제공될 수 있다. 도 3은 제1 사용자 단말(DEV1)에 설치된 전용 어플리케이션이 제공하는 UI의 예시를 보이고 있다. 또한, 인터페이스 모듈은 딥 러닝 모델에 의해 도출된 병해충에 대한 정보(즉, 대상 작물 이미지를 딥 러닝 모델에 적용하여 식별된 병해충에 대한 정보)를 외부 시스템(EXT)으로 전달받아 제1 사용자 단말(DEV1)로 제공 하도록 동작할 수도 있다. 외부 시스템(EXT)은, 예를 들어 공인 기관이 관리하는 영농 정보 시스템에 해당할 수 있으며, 인터페이스 모듈은 Open API를 통해 외부 시스템(EXT)으로부터 병해충 정보(예: 병원체 정보, 작목 기술 정보, 방제 정보)를 제1 사용자 단말(DEV1)로 제공하여 제1 사용자가 해당 병해충에 대한 정보를 종합적으 로 확인하도록 할 수 있다. 도 4는 병해충 정보가 제1 사용자 단말(DEV1)을 통해 디스플레이되는 UI의 예시를 보이고 있다. 인터페이스 모듈은 딥 러닝 모듈에 의해 도출된 병해충의 인식 정확도가 미리 설정된 제3 기준치 미만인 경 우, 제2 사용자가 소지한 제2 사용자 단말(DEV2)로 진단 결과를 전달하여, 제2 사용자가 상기 진단 결과를 분석 하도록 할 수 있으며, 제2 사용자의 분석은 제1 사용자 단말(DEV1)로 피드백되도록 구성될 수 있다. 즉, 대상 작물 이미지가 딥 러닝 모델에 적용되어 도출된 병해충의 인식 정확도가 제3 기준치 미만인 경우(즉, 해당 작물 의 실제 병해충이, 딥 러닝 모델에 의해 식별된 병해충에 해당할 확률이 제3 기준치(예: 70%) 미만인 경우), 보 다 전문적인 분석을 위해 해당 진단 결과는 제2 사용자(전문가)가 소지한 제2 사용자 단말(DEV2)로 전달될 수 있으며, 제2 사용자의 분석은 제1 사용자 단말(DEV1)로 피드백됨으로써, 제1 사용자가 해당 병해충에 대한 전문 적인 분석 결과를 확인하도록 구성될 수 있다. 한편, 원시 작물 이미지 및 분류 작물 이미지에는 해당 이미지의 지역 정보, 시간 정보(이미지가 촬영된 시간 정보) 및 기상 정보(기온, 강수량, 습도, 풍속 등. 외부 기상 서버로부터 획득되어 해당 이미지에 반영될 수 있 다)를 포함하는 메타 데이터가 반영되어 있을 수 있으며, 이러한 분류 작물 이미지는 빅데이터화되어 빅데이터 저장 모듈에 별도로 저장 관리될 수 있다. 이를 토대로, 병해충 지도 데이터 생성 모듈은 분류 작물 이미지의 메타 데이터를 토대로 병해충의 발생 현황 및 발생 지역이 반영된 병해충 지도 데이터를 생성할 수 있 으며, 인터페이스 모듈은 지도 데이터 생성 모듈에 의해 생성된 병해충 지도 데이터를 제1 사용자 단 말(DEV1)로 제공할 수 있다. 이에 따라, 제1 사용자는 자신이 소지한 단말 상에 디스플레이되는 병해충 지도 데 이터를 토대로 병해충의 발생 현황 및 발생 지역을 파악하고 향후 병해충이 발생할 지역을 예측하도록 할 수 있 다. 추가적으로, 제1 사용자 단말(DEV1)의 전용 어플리케이션은 GPS 모듈을 통해 제1 사용자의 현재 위치를 측 위하여 해당 위치의 병해충 정보를 실시간으로 안내하는 기능과, 제1 사용자가 관심 지역으로 등록한 지역의 병 해충 발생 현황에 대한 알람 서비스를 제공하는 기능과, 해당 지역의 실시간 기상 정보, 기상 상황에 따른 농약 살포 가능 여부 및 최적 일자를 안내하는 기능을 지원할 수도 있다. 도 5는 본 발명의 일 실시예에 따른 인공지능 기반의 병해충 진단 방법을 설명하기 위한 흐름도이다. 도 5를 참 조하여 본 실시예에 따른 인공지능 기반의 병해충 진단 방법을 설명하며, 전술한 내용과 중복되는 부분에 대한 구체적인 설명은 배제하고 그 시계열적 구성을 중심으로 설명한다. 우선적으로, 서버는 입력된 작물 이미지 상의 병해충을 신경망을 통해 진단하도록 구성된 딥 러닝 모델을 학습 시킨다(S100).S100 단계는, 미리 수집된 원시 작물 이미지에 비지도 학습(Unsupervised Learning)에 따른 Auto ML(Auto Machine Learning)을 적용하는 방식으로 원시 작물 이미지를 그 클래스별로 분류하여 분류 작물 이미지를 생성 하는 S110 단계와, S110 단계에서 생성된 분류 작물 이미지에 대하여 디노이징(Denoising), 리사이징 (Resizing), 업스케일링(Upscaling) 및 증강(Augmentation) 중 하나 이상을 적용하여 분류 작물 이미지에 대한 정제 작업을 수행하는 S120 단계와, S120 단계를 통해 정제된 분류 작물 이미지에 미리 정의된 Auto Labeling 알고리즘을 적용하여 분류 작물 이미지의 Annotation 파일을 생성하는 S130 단계와, S130 단계에서 생성된 분류 작물 이미지 및 Annotation 파일을 매핑하여 학습 데이터 셋(Training Data Set)을 생성하는 S140 단계와, S140 단계에서 생성된 학습 데이터 셋을 기반으로, 딥 러닝 모델을 학습시키는 S150 단계와, S150 단계를 통해 학습이 완료된 딥 러닝 모델을 평가하는 S160 단계와, S160 단계를 통해 평가가 완료된 딥 러닝 모델의 버전을 관리하는 S170 단계를 포함할 수 있다. S100 단계를 통해 딥 러닝 모델의 학습 및 평가가 완료되면, 서버는 제1 사용자가 소지한 제1 사용자 단말 (DEV1)로부터 대상 작물 이미지를 입력받는다(S200). 이어서, 서버는 S100 단계를 통해 학습된 딥 러닝 모델에 S200 단계에서 입력된 대상 작물 이미지를 적용하여 대상 작물 이미지에 반영된 병해충을 진단한다(S300). 이어서, 서버는 S300 단계의 진단 결과를 제1 사용자 단말(DEV1)로 제공한다(S400). 이와 같이 본 실시예는 비지도 학습(Unsupervised Learning)에 따른 Auto ML(Auto Machine Learning)과, 이미 지 내의 오브젝트를 식별하고 Instance Segmentation을 통해 픽셀 단위로 Auto Labeling을 수행하여 Annotation 파일을 생성하는 Auto Labeling을 결합시킨 구조를 기반으로 딥 러닝 모델을 학습시키고 그에 따라 병해충을 진단하는 구성을 채용함으로써, 종래 딥 러닝 기반의 단순 분류를 이용한 병해충 식별 방법에 있어서 그 식별 정확도가 감소되는 문제점을 해결하여 그 식별 및 진단 정확도를 향상시킴과 동시에 작업자의 수작업에 의해 야기되는 시간 및 비용적 소모를 제거할 수 있다. 또한, 이미지의 메타 데이터를 토대로 병해충 지도 데이 터를 사용자에게 제공하여 사용자로 하여금 병해충의 발생 현황 및 발생 지역을 파악 및 예측하도록 하는 서비 스를 제공할 수 있어, 그 활용 확장성 측면에서도 이점을 갖는다. 본 명세서에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함할 수 있으며, 예 를 들면, 로직, 논리 블록, 부품, 또는 회로 등의 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구 성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부가 될 수 있다. 예 를 들면, 일 실시 예에 따르면, 모듈은 ASIC(Application-Specific Integrated Circuit)의 형태로 구현될 수 있다. 또한, 본 명세서에서 설명된 구현은, 예컨대, 방법 또는 프로세스, 장치, 소프트웨어 프로그램, 데이터 스트림 또는 신호로 구현될 수 있다. 단일 형태의 구현의 맥락에서만 논의(예컨대, 방법으로서만 논의)되었더라 도, 논의된 특징의 구현은 또한 다른 형태(예컨대, 장치 또는 프로그램)로도 구현될 수 있다. 장치는 적절한 하 드웨어, 소프트웨어 및 펌웨어 등으로 구현될 수 있다. 방법은, 예컨대, 컴퓨터, 마이크로프로세서, 집적 회로 또는 프로그래밍가능한 로직 디바이스 등을 포함하는 프로세싱 디바이스를 일반적으로 지칭하는 프로세서 등과 같은 장치에서 구현될 수 있다. 프로세서는 또한 최종-사용자 사이에 정보의 통신을 용이하게 하는 컴퓨터, 셀 폰, 휴대용/개인용 정보 단말기(personal digital assistant: \"PDA\") 및 다른 디바이스 등과 같은 통신 디바이 스를 포함한다. 본 발명은 도면에 도시된 실시예를 참고로 하여 설명되었으나, 이는 예시적인 것에 불과하며 당해 기술이 속하"}
{"patent_id": "10-2021-0049327", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이 해할 것이다. 따라서, 본 발명의 진정한 기술적 보호범위는 아래의 특허청구범위에 의하여 정해져야 할 것이다."}
{"patent_id": "10-2021-0049327", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 및 도 2는 본 발명의 일 실시예에 따른 인공지능 기반의 병해충 진단 시스템을 설명하기 위한 블록구성도 이다. 도 3 및 도 4는 본 발명의 일 실시예에 따른 인공지능 기반의 병해충 진단 시스템에서 제1 사용자 단말을 통해 제공되는 UI를 보인 예시도이다. 도 5는 본 발명의 일 실시예에 따른 인공지능 기반의 병해충 진단 방법을 설명하기 위한 흐름도이다."}
