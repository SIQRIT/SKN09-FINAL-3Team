{"patent_id": "10-2021-0144687", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0060214", "출원번호": "10-2021-0144687", "발명의 명칭": "인공지능 기반 영상 객체 추적 장치 및 방법", "출원인": "인천대학교 산학협력단", "발명자": "전광길"}}
{"patent_id": "10-2021-0144687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "학습 데이터셋, 검증 데이터셋, 테스트 데이터셋을 저장한 학습 데이터셋에서 영상 프레임의 제1 특징맵을 추출하고, 추출한 제1 특징맵을 기초로 영상에서 사람 객체의 존재가 추정되는 적어도 하나의 영역을 추출하여 제1바운딩 박스로 표시하는 제1 객체 탐지부;탑뷰에 설치된 카메라부를 이용하여 탑뷰 영상 프레임을 수신하여 상기 탑뷰 영상 프레임의 제2 특징맵을 추출하고, 추출한 제2 특징맵을 기초로 영상에서 사람 객체의 존재가 추정되는 적어도 하나의 영역을 추출하여 제2바운딩 박스로 표시하는 제2 객체 탐지부; 및상기 제1 객체 탐지부로부터 사전 학습 완료된 학습 모델로부터 학습된 결과에 대한 제1 가중치를 생성하고, 상기 제2 객체 탐지부로부터 탑뷰 영상 프레임을 이용한 학습 모델로부터 학습된 결과에 대한 제2 가중치를 생성하는 전이 학습 모델부를 포함하는 인공지능 기반 영상 객체 추적 장치."}
{"patent_id": "10-2021-0144687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,탑뷰 영상인 훈련 영상 프레임을 입력받고, 상기 전이 학습 모델부에서 생성된 제1 가중치와 제2 가중치를 이용하여 상기 입력된 훈련 영상 프레임의 제3 특징맵을 추출하고, 추출한 제3 특징맵을 기초로 영상에서 사람 객체의 존재가 추정되는 적어도 하나의 영역을 추출하여 제3 바운딩 박스로 표시하는 객체 탐지 모델부를 더 포함하는 인공지능 기반 영상 객체 추적 장치."}
{"patent_id": "10-2021-0144687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 객체 탐지 모델부로부터 사람 객체를 바운딩 박스로 표시한 영상 프레임을 수신하고, 바운딩 박스 정보를추적하기 위해 칼만 필터를 사용하여 시간적으로 수신되는 복수의 영상 프레임에 포함된 바운딩 박스 정보를 추적하는 바운딩 박스 추적부; 및컨볼루션 신경망(Convolutional Proposal Network, CNN)과 복수개의 필터들로 이루어져 상기 바운딩 박스 추적부로부터 바운딩 박스의 공간 정보 및 추적 정보를 수신하여 바운딩 박스의 모양(외형, Appearance) 정보를 포함한 특징 벡터를 추출하는 CNN 모델부로 이루어진 객체 추적부를 더 포함하는 인공지능 기반 영상 객체 추적장치."}
{"patent_id": "10-2021-0144687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 제1 객체 탐지부와 상기 제2 객체 탐지부는 검출된 바운딩 박스의 정도를 사람으로 나타내는 신뢰도 값(Conf(person))을 하기의 수학식 1과 수학식 2로 정의하는 인공지능 기반 영상 객체 추적 장치.[수학식 1]여기서, Pr(person)은 예측된 바운딩 박스에 사람이 있는지(예: 1, 아니오: 0)를 나타내고, IOU(Pred, Truth)는 예측된 바운딩 박스와 실제 바운딩 박스의 겹치는 넓이를 두 영역을 합친 넓이로 나눈 IoU 중첩 비율임.공개특허 10-2023-0060214-3-[수학식 2]여기서, BoxT는 훈련 세트에서 그라운드 트루(Ground Truth)를 나타내고(Truth), BoxP는 예측된 바운딩 박스를나타냄(Pred)."}
{"patent_id": "10-2021-0144687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,상기 제1 객체 탐지부와 상기 제2 객체 탐지부는 하기의 수학식 3, 수학식 4, 수학식 5의 손실 함수의 총합이최소가 되도록 영상 프레임의 특징을 학습하는 인공지능 기반 영상 객체 추적 장치.[수학식 3]여기서, 는 예측된 바운딩 박스의 좌표 손실을 나타내고, 는 실제 바운딩 박스의 좌표 손실을 계산하는데 사용됨.[수학식 4]여기서, 는 바운딩 박스의 좌표 예측에 사용하는 스케일 매개변수이고( ),는 i번째 셀에서 감지된 바운딩 박스의 예측 위치이고, 는 i번째 셀에서바운딩 박스의 실제 위치임.[수학식 5]여기서, 는 분류 오류를 나타내고, 와 는 예측된 바운딩 박스의 i번째 그리드 셀의 신뢰도값과 원본 슬라이딩 윈도우의 i번째 그리드 셀의 신뢰도 값이고, 는 그리드 셀 i의 j번째 바운딩 박스공개특허 10-2023-0060214-4-에서 사람이 감지되는지 여부를 나타내고, 는 그리드 셀 i의 j번째 바운딩 박스에서 사람이 감지되지 않는지 여부를 나타내고, 는 (j = 0 내지 B)를 각 그리드 셀(i = 0 내지 S2)에 대한 예측 변수로 사용하여 각 바운딩 박스에 대한 합계를 계산함."}
{"patent_id": "10-2021-0144687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 객체 탐지부는 학습 데이터셋, 검증 데이터셋, 테스트 데이터셋을 저장한 학습 데이터셋에서 영상 프레임의제1 특징맵을 추출하고, 추출한 제1 특징맵을 기초로 영상에서 사람 객체의 존재가 추정되는 적어도 하나의 영역을 추출하여 제1 바운딩 박스로 표시하는 단계;제2 객체 탐지부는 탑뷰에 설치된 카메라부를 이용하여 탑뷰 영상 프레임을 수신하여 상기 탑뷰 영상 프레임의제2 특징맵을 추출하고, 추출한 제2 특징맵을 기초로 영상에서 사람 객체의 존재가 추정되는 적어도 하나의 영역을 추출하여 제2 바운딩 박스로 표시하는 단계; 및전이 학습 모델부는 상기 제1 객체 탐지부로부터 사전 학습 완료된 학습 모델로부터 학습된 결과에 대한 제1 가중치를 생성하고, 상기 제2 객체 탐지부로부터 탑뷰 영상 프레임을 이용한 학습 모델로부터 학습된 결과에 대한제2 가중치를 생성하는 단계를 포함하는 인공지능 기반 영상 객체 추적 방법."}
{"patent_id": "10-2021-0144687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,객체 탐지 모델부는 탑뷰 영상인 훈련 영상 프레임을 입력받고, 상기 전이 학습 모델부에서 생성된 제1 가중치와 제2 가중치를 이용하여 상기 입력된 훈련 영상 프레임의 제3 특징맵을 추출하고, 추출한 제3 특징맵을 기초로 영상에서 사람 객체의 존재가 추정되는 적어도 하나의 영역을 추출하여 제3 바운딩 박스로 표시하는 단계를더 포함하는 인공지능 기반 영상 객체 추적 방법."}
{"patent_id": "10-2021-0144687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서,바운딩 박스 추적부는 상기 객체 탐지 모델부로부터 사람 객체를 바운딩 박스로 표시한 영상 프레임을수신하고, 바운딩 박스 정보를 추적하기 위해 칼만 필터를 사용하여 시간적으로 수신되는 복수의 영상 프레임에포함된 바운딩 박스 정보를 추적하는 단계; 및CNN 모델부는 컨볼루션 신경망(Convolutional Proposal Network, CNN)과 복수개의 필터들로 이루어져 상기 바운딩 박스 추적부로부터 바운딩 박스의 공간 정보 및 추적 정보를 수신하여 바운딩 박스의 모양(외형,Appearance) 정보를 포함한 특징 벡터를 추출하는 단계를 더 포함하는 인공지능 기반 영상 객체 추적 방법."}
{"patent_id": "10-2021-0144687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 6에 있어서,상기 제1 객체 탐지부와 상기 제2 객체 탐지부는 검출된 바운딩 박스의 정도를 사람으로 나타내는 신뢰도 값(Conf(person))을 하기의 수학식 1과 수학식 2로 정의하는 단계를 포함하는 인공지능 기반 영상 객체 추적방법.[수학식 1]여기서, Pr(person)은 예측된 바운딩 박스에 사람이 있는지(예: 1, 아니오: 0)를 나타내고, IOU(Pred, Truth)는 예측된 바운딩 박스와 실제 바운딩 박스의 겹치는 넓이를 두 영역을 합친 넓이로 나눈 IoU 중첩 비율임.공개특허 10-2023-0060214-5-[수학식 2]여기서, BoxT는 훈련 세트에서 그라운드 트루(Ground Truth)를 나타내고(Truth), BoxP는 예측된 바운딩 박스를나타냄(Pred)."}
{"patent_id": "10-2021-0144687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 6에 있어서,상기 제1 객체 탐지부와 상기 제2 객체 탐지부는 하기의 수학식 3, 수학식 4, 수학식 5의 손실 함수의 총합이최소가 되도록 영상 프레임의 특징을 학습하는 단계를 포함하는 인공지능 기반 영상 객체 추적 방법.[수학식 3]여기서, 는 예측된 바운딩 박스의 좌표 손실을 나타내고, 는 실제 바운딩 박스의 좌표 손실을 계산하는데 사용됨.[수학식 4]여기서, 는 바운딩 박스의 좌표 예측에 사용하는 스케일 매개변수이고( ),는 i번째 셀에서 감지된 바운딩 박스의 예측 위치이고, 는 i번째 셀에서바운딩 박스의 실제 위치임.[수학식 5]여기서, 는 분류 오류를 나타내고, 와 는 예측된 바운딩 박스의 i번째 그리드 셀의 신뢰도값과 원본 슬라이딩 윈도우의 i번째 그리드 셀의 신뢰도 값이고, 는 그리드 셀 i의 j번째 바운딩 박스공개특허 10-2023-0060214-6-에서 사람이 감지되는지 여부를 나타내고, 는 그리드 셀 i의 j번째 바운딩 박스에서 사람이 감지되지 않는지 여부를 나타내고, 는 (j = 0 내지 B)를 각 그리드 셀(i = 0 내지 S2)에 대한 예측 변수로 사용하여 각 바운딩 박스에 대한 합계를 계산함."}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 기반 영상 객체 추적 장치 및 방법은 미리 사전 학습하여 사람 객체를 추정한 가중치와 탑뷰 영상 프레 임을 학습하여 사람 객체를 추정한 가중치를 전이 학습하고, 입력된 영상 프레임의 특징의 추출 시 2개의 가중치 를 이용하여 사람 객체의 존재를 추정한다. 본 발명은 미리 사전 학습하여 사람 객체를 추정한 가중치와 탑뷰 영상 프레임을 학습하여 사람 객체를 추정한 가중치를 이용하여 객체를 탐지 및 추적함으로써 객체 추적 기술의 추적 정확도(96%)와 탐지 정확도(95%)가 매우 우수한 효과를 달성할 수 있다."}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상 객체 추적 장치 및 방법에 관한 것으로서, 더욱 상세하게는 미리 사전 학습하여 사람 객체를 추 정한 가중치와 탑뷰 영상 프레임을 학습하여 사람 객체를 추정한 가중치를 전이 학습하고, 입력된 영상 프레임 의 특징의 추출 시 2개의 가중치를 이용하여 사람 객체의 존재를 추정하는 인공지능 기반 영상 객체 추적 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "오늘날 5G는 고신뢰성, 고대역폭 및 안전한 네트워크 연결로 비디오 스트림을 고속으로 처리하여 비디오 감시 및 모니터링 서비스에 지대한 영향을 미치고 있다. 이러한 5G 인프라를 이용하여 다중 인물 추적, 탐지 프레임워크에 의한 딥러닝 기반 추적 기술이 많이 연구되고 있는 실정이다. 영상 감시에서 사람 추적은 인체의 변형 가능한 특성, 폐색, 조명 및 배경 조건과 같은 다양한 환경 구성 요소, 특히 사람의 시각적 모양이 다른 사람과 구별해내는 것이 중요하다. 현재의 객체 추적 기술은 객체의 탐지 정확도와 추적 정확도가 다소 떨어지는 단점이 있거나 비용이 많이 드는 솔루션, 더 긴 분석 시간 및 막대한 대역폭 요구사항이 발생하는 문제점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 공개특허번호 제10-2021-0067498호"}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이와 같은 문제점을 해결하기 위하여, 본 발명은 미리 사전 학습하여 사람 객체를 추정한 가중치와 탑뷰 영상 프레임을 학습하여 사람 객체를 추정한 가중치를 전이 학습하고, 입력된 영상 프레임의 특징의 추출 시 2개의 가중치를 이용하여 사람 객체의 존재를 추정하는 인공지능 기반 영상 객체 추적 장치 및 방법을 제공하는데 그 목적이 있다."}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 특징에 따른 인공지능 기반 영상 객체 추적 장치는, 학습 데이터셋, 검증 데이터셋, 테스트 데이터셋을 저장한 학습 데이터셋에서 영상 프레임의 제1 특징맵을 추출 하고, 추출한 제1 특징맵을 기초로 영상에서 사람 객체의 존재가 추정되는 적어도 하나의 영역을 추출하여 제1 바운딩 박스로 표시하는 제1 객체 탐지부; 탑뷰에 설치된 카메라부를 이용하여 탑뷰 영상 프레임을 수신하여 상기 탑뷰 영상 프레임의 제2 특징맵을 추출 하고, 추출한 제2 특징맵을 기초로 영상에서 사람 객체의 존재가 추정되는 적어도 하나의 영역을 추출하여 제2 바운딩 박스로 표시하는 제2 객체 탐지부; 및 상기 제1 객체 탐지부로부터 사전 학습 완료된 학습 모델로부터 학습된 결과에 대한 제1 가중치를 생성하고, 상 기 제2 객체 탐지부로부터 탑뷰 영상 프레임을 이용한 학습 모델로부터 학습된 결과에 대한 제2 가중치를 생성 하는 전이 학습 모델부를 포함한다. 본 발명의 특징에 따른 인공지능 기반 영상 객체 추적 방법은, 제1 객체 탐지부는 학습 데이터셋, 검증 데이터셋, 테스트 데이터셋을 저장한 학습 데이터셋에서 영상 프레임의 제1 특징맵을 추출하고, 추출한 제1 특징맵을 기초로 영상에서 사람 객체의 존재가 추정되는 적어도 하나의 영 역을 추출하여 제1 바운딩 박스로 표시하는 단계; 제2 객체 탐지부는 탑뷰에 설치된 카메라부를 이용하여 탑뷰 영상 프레임을 수신하여 상기 탑뷰 영상 프레임의 제2 특징맵을 추출하고, 추출한 제2 특징맵을 기초로 영상에서 사람 객체의 존재가 추정되는 적어도 하나의 영 역을 추출하여 제2 바운딩 박스로 표시하는 단계; 및 전이 학습 모델부는 상기 제1 객체 탐지부로부터 사전 학습 완료된 학습 모델로부터 학습된 결과에 대한 제1 가 중치를 생성하고, 상기 제2 객체 탐지부로부터 탑뷰 영상 프레임을 이용한 학습 모델로부터 학습된 결과에 대한 제2 가중치를 생성하는 단계를 포함한다."}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 구성에 의하여, 본 발명은 미리 사전 학습하여 사람 객체를 추정한 가중치와 탑뷰 영상 프레임을 학습하 여 사람 객체를 추정한 가중치를 이용하여 객체를 탐지 및 추적함으로써 객체 추적 기술의 추적 정확도(96%)와 탐지 정확도(95%)가 매우 우수한 효과를 달성할 수 있다."}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 도 1 및 도 2는 본 발명의 실시예에 따른 전이 학습 기반의 탑뷰 영상 객체 추적 장치의 구성을 나타낸 도면이 고, 도 3 및 도 4는 본 발명의 실시예에 따른 바운딩 박스 탐지부의 구성을 간략하게 나타낸 도면이다. 본 발명은 탑뷰에서 탑뷰 영상 시퀀스(Top View Sequence)를 생성하여 탑뷰 영상 시퀀스에서 객체 탐지와 객체 추적을 수행하는 일련의 과정을 간략하게 나타낸다. 본 발명의 실시예에 따른 전이 학습 기반의 탑뷰 영상 객체 추적 장치는 바운딩 박스 탐지부 및 객체 추적부를 포함한다. 본 발명의 실시예에 따른 바운딩 박스 탐지부는 COCO 데이터셋 데이터베이스부, 제1 객체 탐지부 , 입력부, 제2 객체 탐지부, 전이 학습 모델부, 객체 탐지 모델부, 훈련 영상 입력부 , 출력부를 포함한다. 탑뷰 영상 생성부(미도시)는 탑뷰에 설치된 카메라부를 이용하여 탑뷰 영상 시퀀스를 생성한다. 여기서, 탑뷰 (Top View)는 상부에서 내려다 보는 시야이다. 탑뷰 영상 생성부는 생성한 탑뷰 영상 시퀀스를 영상 프레임으로 변환한다. COCO 데이터셋 데이터베이스부는 객체 탐지, 세그먼테이션, 키포인트 탐지 등의 컴퓨터 비전 분야의 Task 를 목적으로 만들어진 데이터셋이며, 학습 데이터셋, 검증 데이터셋, 테스트 데이터셋을 저장하고 있다.입력부는 탑뷰 영상 생성부로부터 영상 프레임을 수신한다. 제1 객체 탐지부는 COCO 데이터셋 데이터베이스부로부터 학습 데이터셋, 검증 데이터셋, 테스트 데이 터셋을 수집하고, 사전 훈련된 YOLOv3를 이용하여 영상 프레임의 특징맵을 추출하고, 추출한 특징맵을 기초로 영상에서 사람 객체의 존재가 추정되는 적어도 하나의 영역을 추출한다. 제2 객체 탐지부는 입력부로부터 탑뷰 영상 생성부에서 획득한 영상 프레임을 수집하고, YOLOv3를 이 용하여 탑뷰 영상 프레임의 특징맵을 추출하고, 추출한 특징맵을 기초로 영상에서 사람 객체의 존재가 추정되는 적어도 하나의 영역을 추출한다. 제1 객체 탐지부와 제2 객체 탐지부는 심층 신경망(Deep Neural Networks, DNN), 컨볼루션 신경망 (Convolutional deep Neural Networks, CNN), 순환 신경망(Reccurent Neural Network, RNN) 및 심층 신뢰 신경 망(Deep Belief Networks, DBN) 중 어느 하나의 신경망을 이용하여 입력 영상으로부터 특징맵을 추출한다. 제1 객체 탐지부와 제2 객체 탐지부는 딥러닝(Deep learning)을 기반으로 학습부에 의하여 이미 학습 이 완료된 모델을 이용하여서 특징맵을 생성할 수 있다. 딥러닝은 여러 비선형 변환기법의 조합을 통해 높은 수"}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "준의 추상화(Abstractions, 다량의 데이터나 복잡한 자료들 속에서 핵심적인 내용 또는 기능을 요약하는 작업) 를 시도하는 기계학습(Machine Learning) 알고리즘의 집합으로 정의된다. 제1 객체 탐지부와 제2 객체 탐지부는 영상 프레임에서 객체가 존재할 것으로 추정되는 영역을 추출 하고, 추출된 영역으로부터 특징을 나타내는 특징맵을 추출한다. 제1 객체 탐지부와 제2 객체 탐지부는 추출한 특징맵을 기초로 영상에서 사람 객체의 존재가 추정되 는 적어도 하나의 영역을 추출한다. 영역을 추출하는 방법은 예를 들어 faster RCNN, SSD(Single Shot MultiBox Detector), YOLO(You Only Look Once) 등이 있을 수 있으며, 본 발명은 YOLO 객체 인식모듈(YOLOv3) 을 일례로 하고 있다. 제1 객체 탐지부와 제2 객체 탐지부는 특징맵 중에서 영상의 영역별 클래스의 좌표를 포함하는 특징 맵을 선정하고, 선정된 특징맵으로부터 영역을 구별하는 좌표를 식별한 뒤, 식별된 좌표를 개체의 존재가 추정 되는 영역으로 추출할 수 있다. 제1 객체 탐지부와 제2 객체 탐지부는 사람 객체를 하나 또는 2개 이상으로 설정할 수 있다. 제1 객체 탐지부와 제2 객체 탐지부는 추출된 적어도 하나의 영역 각각에 대해서, 해당 객체의 최외 곽을 둘러싸는 바운딩 박스(Bounding Box)로서 표시할 수 있다. 각각의 바운딩 박스는 영상에서 해당 바운딩 박스의 위치에 개체의 존재 가능성이 있음을 나타낸다. YOLOv3 모델은 단일 네트워크 아키텍처를 사용하여 전체 입력 영상에 대한 클래스 확률과 해당 바운딩 박스를 예측한다. YOLOv3 모델은 24개의 컨볼루션 레이어와 2개의 완전히 연결된 레이어가 포함되어 있다. 컨볼루션 레이어는 영 상 추출에 사용되는 반면 완전 연결 레이어는 클래스 예측과 확률을 계산한다. 제1 객체 탐지부와 제2 객체 탐지부는 사람을 감지하는 동안 모델은 도 5와 같이 입력 영상 프레임을 그리드 셀이라고도 하는 S × S 영역으로 나눈다. 이러한 그리드 셀은 바운딩 박자 예측 및 클래스 확률과 연결 된다. 각 셀은 사람의 중심이 격자 셀에 있는지 여부의 확률을 예측한다. 예측이 양성이면 경계 상자와 각 양성 검출에 대한 신뢰도 값이 예측된다. 제1 객체 탐지부와 제2 객체 탐지부는 검출된 바운딩 박스의 정도를 사람으로 나타내는 신뢰도 값 (Conf(person))을 수학식 1로 정의한다. 수학식 1"}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, Pr(person)은 예측된 바운딩 박스에 사람이 있는지(예: 1, 아니오: 0)를 나타내고, IOU(Pred, Truth) 는 예측된 바운딩 박스와 실제 바운딩 박스의 겹치는 넓이를 두 영역을 합친 넓이로 나눈 IoU 중첩 비율이다.수학식 2"}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, BoxT는 훈련 세트에서 그라운드 트루(Ground Truth)를 나타내고(Truth), BoxP는 예측된 바운딩 박스를 나타낸다(Pred). 그라운드 트루(Ground Truth)는 신경망 모델이 예측한 값이 아닌 실제 정답 레벨(Label)을 의미한다. 즉, 어떤 객체의 실제 위치를 나타낸다. IoU은 객체 탐지에서 바운딩 박스로 객체의 위치를 나타내고, 이때 예측한 바운딩 박스와 실제 그라운드 트루 바운딩 박스의 영역을 비교하고, 두 영역을 비교했을 때, 겹치는 넓이를 두 영역을 합친 넓이로 나눈 IoU 중첩 비율이 기설정된 임계값(0.5 이상)일 때 매치되었다고 한다. IoU 값이 0.5 이상이면, 해당 Region을 객체로 바라보고, 그라운드 트루와 같은 클래스로 레이블링한다. 제1 객체 탐지부와 제2 객체 탐지부는 탑뷰 영상 프레임에서 사람 감지를 위해 적합한 영역이 선택되 고 예측되고, 예측 후 신뢰도 값을 사용하여 원하는 바운딩 박스를 획득한다. 제1 객체 탐지부와 제2 객체 탐지부는 h, w, x, y 및 신뢰도 값을 포함하여 모든 바운딩 박스에 대해 5개의 값이 예측된다. 여기서, 너비와 높이는 w, h로 표시되고, 바운딩 박스 중심 좌표는 x, y로 표시된다. 제1 객체 탐지부와 제2 객체 탐지부는 임계값을 정의하여 낮은 점수의 신뢰도 값을 버리고 나머지 여 러 개의 높은 신뢰도 바운딩 박스를 처리하고 최대가 아닌 억제를 사용하여 최종 위치 매개변수를 파생한다. 제1 객체 탐지부와 제2 객체 탐지부는 감지된 바운딩 박스에 대해 손실 함수를 계산한다. 제1 객체 탐지부와 제2 객체 탐지부는 계산한 손실 함수의 총합이 최소가 되도록 영상 프레임의 특징 을 학습한다. 손실 함수는 회귀 손실과 분류 손실의 합이다. 제1 객체 탐지부와 제2 객체 탐지부는 하나의 대상, 즉 사람만을 고려하고, 이러한 작업에 대한 손실함수는 다음의 수학식 3과 같이 주어진다. 수학식 3"}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, 는 예측된 바운딩 박스의 좌표 손실을 나타내고, 는 실제 바운딩 박스의 좌표 손실을 계산하 는데 사용된다. 탑뷰 영상 프레임에서 사람의 크기가 다르며 YOLOv3 손실 특징은 모든 바운딩 박스에 대해 동일 한 손실을 계산한다. 그러나 손실 함수에 대한 크고 작은 객체의 영향은 전체 이미지에 대해 다릅니다. 따라서, 좌표의 손실 함수를 개선하기 위해서 대조(Contrast) 정규화가 사용된다. 좌표 의 손실함수는 하기의 수학식 4로 주어진다.수학식 4"}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, 는 바운딩 박스의 좌표 예측에 사용하는 스케일 매개변수이고( ), 는 i번째 셀에서 감지된 바운딩 박스의 예측 위치이고, 는 i번째 셀에서 바운딩 박스의 실제 위치이다. 수학식 4는 좌표값 x, y를 갖는 예측된 바운딩 박스와 관련된 손실 함수를 계산한다. 는 j번째 바운딩 박스에서 감지된 사람의 가능성을 보여준다. 는 일정한 상수이다. 는 (j = 0 내지 B)를 각 그리드 셀(i = 0 내지 S2)에 대한 예측 변수로 사용하여 각 바운딩 박스에 대한 합계를 계산한다. 의 는 하기의 수학식 5로 계산된다. 수학식 5"}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, 는 분류 오류를 나타내고, 와 는 예측된 바운딩 박스의 i번째 그리드 셀의 신뢰도 값과 원본 슬라이딩 윈도우의 i번째 그리드 셀의 신뢰도 값이고, 는 그리드 셀 i의 j번째 바운딩 박스 에서 사람이 감지되는지 여부를 나타낸다. 대상 사람이 j번째 경계 상자와 i번째 격자 셀에 있는 경우 수학식 5 의 함수는 1과 같고, 그렇지 않으면 0이 된다. 는 그리드 셀 i의 j번째 바운딩 박스에서 사람이 감지되지 않는지 여부를 나타낸다. 전이 학습 모델부는 제1 객체 탐지부로부터 사전 학습 완료된 학습 모델로부터 학습된 결과에 대한 제1 가중치를 생성하고, 제2 객체 탐지부로부터 탑뷰 영상 프레임을 이용한 학습 모델로부터 학습된 결과에 대한 제2 가중치를 생성한다. 훈련 영상 입력부는 탑뷰 영상인 훈련 영상 프레임을 생성한다. 객체 탐지 모델부는 탑뷰 영상인 훈련 영상 프레임을 입력받고, 전이 학습 모델부에서 생성된 제1 가 중치와 제2 가중치를 이용하여 입력된 훈련 영상 프레임의 특징맵을 추출하고, 추출한 특징맵을 기초로 영상에 서 사람 객체의 존재가 추정되는 적어도 하나의 영역을 추출하여 바운딩 박스로 표시하여 출력부로 출력한 다. 도 6은 본 발명의 실시예에 따른 객체 추적부의 내부 구성을 간략하게 나타낸 블록도이다. 객체 추적부는 탑뷰 영상 프레임에서 사람 객체를 추적하기 위해 딥러닝 기반으로 추적 알고리즘인 deep SORT를 적용한다. 객체 추적부는 입력 모듈, 바운딩 박스 추적부, 제어부, CNN 모델부, 거리 계산부 및 추적 결과부를 포함한다. 입력 모듈은 바운딩 박스 탐지부의 객체 탐지 모델부로부터 사람 객체를 바운딩 박스로 표시한 영상 프레임을 수신한다. 바운딩 박스 추적부는 바운딩 박스 정보를 추적하기 위해 칼만 필터를 사용한다. 바운딩 박스 추적부는 칼만 필터를 사용하여 시간적으로 수신되는 복수의 영상 프레임에 포함된 바운딩 박 스 정보를 추적한다. 칼만 필터는 오차(잡음)가 포함되어 있는 측정치(관측값)을 바탕으로 선형 상태를 추정하는 재귀필터이다 칼만 필터는 기존에 누적된 과거 추적 데이터를 사용하여 현재의 위치를 예측을 하고, 새로 들어온 검출 데이터 중에서 매칭되는 관측데이터가 있다면 예측데이터와 관측데이터 사이의 분산(variance)값의 비율을 가지고 둘 중의 분산의 비율로써 최종적인 상태가 정해진다. 칼만 필터는 이전에 누적된 추적 데이터로부터 칼만필터를 통해 물체의 상태(위치와 크기)를 예측한다. 칼만 필 터는 공지된 추적 알고리즘으로 상세한 설명을 생략한다. 칼만 필터링은 현재 영상 프레임의 객체 추적에 공간 좌표 정보를 사용한다. 공간 좌표 정보는 아래와 같다. 는 감지된 바운딩 박스의 각 좌표의 추적 속도이고, 는 바운딩 박스의 위치이다. u, v는 바운딩 박스 중심 위치이고, 종횡비 , 높이 h이다. 바운딩 박스 추적부는 바운딩 박스의 공간 좌표 정보를 이용하여 추적 예측이 수행된다. 제어부는 바운딩 박스 추적부로부터 바운딩 박스의 공간 정보 및 추적 정보를 수신하여 CNN 모델부 로 전송한다. CNN 모델부는 컨볼루션 신경망(Convolutional Proposal Network, CNN)과 복수개의 필터들을 포함하고, CNN은 컨볼루션 연산을 수행하도록 설계된 컨볼루션 레이어들을 포함할 수 있다. CNN을 구성하는 컨볼루션 레이어는 커널을 이용하여 입력과 연관된 컨볼루션 연산을 수행할 수 있다. CNN 모델부는 CNN을 사용하여 바운딩 박스의 모양(외형, Appearance) 정보를 포함한 특징 벡터를 추출한다. 거리 계산부는 기존의 감지된 객체 추적과 다음의 감지된 객체 추적 사이의 거리를 계산하기 위해 마할라 노비스 거리(Mahalanobis Distance)를 사용한다. 비용 행렬은 Deep SORT 알고리즘에서 모양을 나타내는데 사용된다. 거리 계산부는 수학식 6에 의해 계산된 두 개의 거리값을 사용하여 새로운 탐지와 추적 간의 공간적 유사 성을 나타낸다. 수학식 6"}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서, 는 투영 추적이 측정 공간이고, 를 위한 새로운 탐지 가 사용됨을 나타낸다. T는 전 치행렬을 나타낸다. 는 각 바운딩 박스 탐지를 나타낸다. 거리 계산부는 새로운 탐지 와 측정된 위치의 추적(Track) 간의 차이를 계산하여 마할라노비스 거리(Mahalanobis Distance)를 획득한다. 거리 계산부는 수학식 6의 거리값과, i번째( ) 추적(Track)과 j번째( ) 탐지 사이의 마할라노비스 거리 임계값을 이용하여 다음의 수학식 7에 의해 결정 지표를 계산한다. 수학식 7"}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서, t는 기설정된 마할라노비스 거리 임계값이다. 거리 계산부는 i번째 추적 사이의 연관성이 있는 경우, 1로 평가되고, j번째 검출이 허용된다. 거리 계산부는 다음의 수학식 8에 의해 모양 정보를 나타내는 2번째 거리값을 계산한다. 두 번째 거리값(d(i,j))은 수학식 8과 같이, 추적(Track)과 탐지(Detection) 사이의 최소 코사인 거리를 계산한다. 수학식 8"}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "여기서, 과 은 모양 디스크립터(Apperance Descript)를 나타내고, 는 i번째 추적에 있는 100개 이상 의 객체(사람)의 모양을 나타내는데 사용된다. 연관 추적 사이의 임계값을 설정하기 위해서는 다음의 수학식 9 를 사용한다. 거리 계산부는 각 추적 k를 위한 모양 디스크립터(Descriptor)에 연관된 마지막 의 갤러리 (Gallery)( ) 상태를 유지한다. 거리 계산부는 연관 추적 사이에 임계값을 설정하기 위해 하기의 수학식 9를 이용한다. 수학식 9"}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "거리값이 작으면 1이 되고, 거리값이 크면 0이 된다. 거리 계산부는 수학식 9의 비용함수(비용행렬, Ci,j) 를 하기의 수학식 10에 의해 결합한다. 다시 말해, 연관 문제를 만들기 위해서는 가중합(수학식 10)을 사용하여 두 메트릭(Metric)을 결합한다. 수학식 10"}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "결합된 연관 비용에 대한 각 메트릭의 영향은 하이퍼파라미터 를 통해 제어할 수 있다. 거리 계산부는 공간 정보와 모양 정보를 매칭하기 위해서 다음의 수학식 11의 게이트 함수(게이트 행렬, bi,j)를 정의한다. 수학식 11의 두 메트릭의 게이팅 영역 내에 있는 경우, 연관성을 허용 가능하다고 말한다. 수학식 11"}
{"patent_id": "10-2021-0144687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "수학식 11의 값이 모양과 공간 게이트 함수가 동일하지 않으면 0, 동일하면 1과 같다. 또한, (i, j)가 모양과 공간 정보 사이의 진정한 일치임을 나타낸다. 따라서 모든 새로운 영상 프레임에서 탐지 및 추적은 위의 비용 및 게이트 기능을 활용하는 것과 관련된다. 추적 결과부는 영상 시퀀스에서 추적하고 새로운 감지가 현재 추적과 효과적으로 연관되는 경우 다음 새로 운 영상 프레임에서의 추적이 계속된다. 추적 결과부는 새로운 탐지와 추적이 연결되거나 일치하지 않으면 0으로 설정된다. 따라서, 이러한 경우 추적 결과부는 새로운 탐지가 실패한다. 이러한 경우 새로운 탐지는 프레임 f에서 기 존 탐지와 연결되지 않는다. 그런 다음 새로운 탐지가 임시 추적으로 초기화된다. 따라서, 추적 결과부는 연관 추적 사이의 임계값이 설정되면(수학식 9), Deep SORT 알고리즘이 계속해서 검증하고, 다음의 (f + 1), (f + 2),…(f + t) 임시 프레임에서 새로운 탐지와 연결하고, 성공적으로 연결되면 해당 추적이 추적 확인되고 업데이트된다. 그렇지 않으면 즉시 삭제된다. 추적 결과부는 연관 추적 사이의 임계값이 설정되지 않으면, 즉시 삭제된다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다. 부호의 설명100: 탑뷰 영상 객체 추적 장치 200: 바운딩 박스 탐지부 300: 객체 추적부"}
{"patent_id": "10-2021-0144687", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 및 도 2는 본 발명의 실시예에 따른 전이 학습 기반의 탑뷰 영상 객체 추적 장치의 구성을 나타낸 도면이 다. 도 3 및 도 4는 본 발명의 실시예에 따른 바운딩 박스 탐지부의 구성을 간략하게 나타낸 도면이다. 도 5는 YOLO를 사용한 탑뷰 영상에서의 사람 객체 탐지된 예를 나타낸 도면이다. 도 6은 본 발명의 실시예에 따른 객체 추적부의 내부 구성을 간략하게 나타낸 블록도이다."}
