{"patent_id": "10-2023-0118599", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0052642", "출원번호": "10-2023-0118599", "발명의 명칭": "쌍선형 보간법을 연산할 수 있는 신경 프로세싱 유닛", "출원인": "주식회사 딥엑스", "발명자": "김형석"}}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 제1 픽셀 데이터를 포함하는 제1 데이터의 해상도를 확장시켜 복수의 제2 픽셀 데이터를 포함하는 제2데이터를 생성하기 위하여, 쌍선형 보간법을 수행하도록 구성된 복수의 PE(Processing Element)를 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 복수의 PE 중 적어도 하나는,상기 복수의 제1 픽셀 데이터 및 상기 쌍선형 보간법을 수행하는 가중치를 입력 받아 상기 복수의 제2 픽셀 데이터를 산출하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 복수의 PE 중 적어도 하나는,2x2 크기의 상기 쌍선형 보간법 연산용 가중치를 입력 받도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 복수의 PE에 입력되는 가중치 각각의 원소는 상기 쌍선형 보간법을 수행하기 위해 상기 제1 데이터의 제1픽셀 데이터에 곱해지는 계수인, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 제2 데이터의 복수의 제2 픽셀 데이터 중 적어도 하나는,상기 제1 데이터의 인접한 복수의 픽셀들 사이에 배치된 상기 제2 데이터의 픽셀의 데이터인, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제2 데이터의 최외측 영역에 대응되는 제2 픽셀 데이터를 생성하기 위하여,상기 제1 데이터의 최외측 영역에 대응되는 제1 픽셀 데이터를 상기 제1 데이터의 외부 영역으로 복제하는, 신경 프로세싱 유닛.공개특허 10-2024-0052642-3-청구항 7 제1항에 있어서,상기 복수의 PE의 출력단에 연결되고, 소수점 연산을 수행하는 소수점 곱셈기(Floating point multiplier)을 더포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 복수의 PE는,뎁스와이즈 합성곱 연산(depth-wise convolution)을 수행하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 복수의 PE는,행과 열로 배열된 PE Array로 구성되고,상기 PE Array는 상기 쌍선형 보간법을 수행하는 가중치를 특정 클럭만큼 딜레이하여 인접한 PE에 전달하는 딜레이 버퍼를 더 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 복수의 PE는,행과 열로 배열되고, 딜레이 버퍼를 포함하는 PE Array로 구성되고,상기 PE Array는 상기 쌍선형 보간법을 수행하는 가중치가 상기 PE Array 중 특정 행의 PE들 및 대응되는 상기딜레이 버퍼에 브로드캐스트 되도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 복수의 PE는,복수의 행과 복수의 열로 배열된 PE Array로 구성되고,인접한 행들 사이의 PE들에 대응되는 딜레이 버퍼를 더 포함하고, 상기 딜레이 버퍼는 제1 행의 PE에 입력된 가중치를 다음 클럭에 제2 행의 PE에 전달하여 상기 가중치를 재사용하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 복수의 PE는,공개특허 10-2024-0052642-4-포인트와이즈 합성곱 연산(point-wise convolution)을 수행하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 복수의 PE는,행과 열로 배열된 PE Array로 구성되고,상기 쌍선형 보간법을 수행하는 가중치 각각은 상기 PE Array 중 서로 다른 행에 배치된 PE들에 브로드캐스트되도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항에 있어서,상기 복수의 PE는,행과 열로 배열된 PE Array로 구성되고,상기 제1 픽셀 데이터를 특정 클럭만큼 딜레이하여 출력하는 직렬 연결된 복수의 딜레이 버퍼를 더 포함하는,신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항에 있어서,상기 복수의 PE는,복수의 딜레이 버퍼를 포함하는 행과 열로 배열된 PE Array로 구성되고,상기 제1 픽셀 데이터는 상기 PE Array 중 첫번째 행에 배치된 PE들 및 상기 복수의 딜레이 버퍼에 브로드캐스트 되도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1항에 있어서,상기 복수의 PE는,딜레이 버퍼를 포함하는 PE Array로 구성되고,하나의 PE에 입력되고, 상기 딜레이 버퍼에 의해 딜레이된 상기 제1 픽셀 데이터는 다음행의 PE에서 재사용되도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제1 항에 있어서,상기 제1 데이터는 인공신경망모델의 특정 레이어의 입력 데이터이고,상기 제2 데이터는 상기 특정 레이어의 출력 데이터이고,상기 제2 데이터는 특정 PE에서 상기 쌍선형 보간법을 수행하는 가중치를 적용하여 상기 제1 데이터에 상기 쌍선형 보간법이 적용된 결과인, 신경 프로세싱 유닛.공개특허 10-2024-0052642-5-청구항 18 제1 항에 있어서,상기 제1 데이터는 이미지, 특징맵 또는 활성화맵 중 하나이고,상기 제1 데이터는 특정 인공신경망모델의 특정 레이어의 입력 데이터이고,상기 제2 데이터는 쌍선형 보간법이 적용된 상기 특정 인공신경망모델의 상기 특정 레이어의 출력 데이터인, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제1 항에 있어서,상기 복수의 PE는 곱셈기, 덧셈기, 및 누산기를 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1 항에 있어서,상기 쌍선형 보간법은 상기 복수의 PE를 통해서 특정 인공신경망모델의 업스케일링(up-scaling) 연산 또는 세그먼테이션(segmentation) 연산을 수행하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2023-0118599", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "신경 프로세싱 유닛이 제공된다. 신경 프로세싱 유닛은 복수의 제1 픽셀 데이터를 포함하는 제1 데이터의 해상도 를 확장시켜 복수의 제2 픽셀 데이터를 포함하는 제2 데이터를 생성하기 위하여, 쌍선형 보간법을 수행하도록 구 성된 복수의 PE(Processing Element)를 포함할 수 있다."}
{"patent_id": "10-2023-0118599", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인간은 인식(Recognition), 분류(Classification), 추론(Inference), 예측(Predict), 조작/의사결정 (Control/Decision making) 등을 할 수 있는 지능을 갖추고 있다. 인공지능(artificial intelligence: AI)은 인간의 지능을 인공적으로 모방하는 것을 의미한다. 인간의 뇌는 뉴런(Neuron)이라는 수많은 신경세포로 이루어져 있다. 각각의 뉴런은 시냅스(Synapse)라고 불리는 연결부위를 통해 수백에서 수천 개의 다른 뉴런들과 연결되어 있다. 인간의 지능을 모방하기 위하여, 생물학적 뉴런의 동작원리와 뉴런 간의 연결 관계를 모델링한 것을, 인공신경망(Artificial Neural Network, ANN) 모델이 라고 한다. 즉, 인공신경망은 뉴런들을 모방한 노드들을 레이어(Layer: 계층) 구조로 연결시킨 시스템이다."}
{"patent_id": "10-2023-0118599", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "인공신경망모델(Artificial Neural Network (ANN) 모델)은 레이어 수에 따라 '단층 신경망'과 '다층 신경망'으 로 구분한다. 일반적인 다층신경망은 입력 레이어와 은닉 레이어, 출력 레이어로 구성된다. 입력 레이어 (input layer)는 외부의 자료들을 받아들이는 레이어로서, 입력 레이어의 뉴런 수는 입력되는 변수의 수와 동일 하다. 은닉 레이어(hidden layer)는 입력 레이어와 출력 레이어 사이에 위치하며 입력 레이어로부터 신 호 를 받아 특징을 추출하여 출력층으로 전달한다. 출력 레이어(output layer)는 은닉 레이어로부터 신호를 받 아 외부로 출력한다. 뉴런 간의 입력신호는 0에서 1 사이의 값을 갖는 각각의 가중치와 곱해진 후 합산된다. 이 합이 뉴런의 임계치보다 크면 뉴런이 활성화되어 활성화 함수를 통하여 출력 값으로 구현된다. 한편, 보다 높은 인공 지능을 구현하기 위하여, 인공신경망의 은닉 레이어의 개수를 늘린 것을 심층 신경망 (Deep Neural Network, DNN)이라고 한다. DNN에는 여러 종류가 있으나, 합성곱 신경망(Convolutional Neural Network, CNN)은 입력 데이터의 특징들을 추출하고, 특징들의 패턴을 파악하기에 용이한 것으로 알려져 있다. 합성곱 신경망(CNN)은 각각의 레이어의 뉴런 간의 연산을 매트릭스 형태의 입력 신호와 매트릭스 형태의 가중치 커널의 합성곱으로 구현한 네트워크 구조를 의미한다. 합성곱 신경망은 인간 뇌의 시각 피질에서 영상을 처리하는 것과 유사한 기능을 하는 신경망이다. 합성곱 신경 망은 이미지 분류 및 객체 인식(image classification and object detection)에 적합한 것으로 알려져 있다. 합성곱 신경망은 이미지 세그먼테이션(segmentation)에도 적합한 것으로 알려져 있다. 이미지 세그먼테이션 연 산에는 보간법 연산이 요구된다. 한편, 세그먼테이션 처리에 필요한 계산량은 이미지 분류 및 객체 인식보다 더 큰 경향이 있다. 합성곱 신경망은 합성곱 연산과 활성화 함수(activation function) 연산과 풀링(pooling) 연산들이 특정 순서로 처리되는 형태로 구성된다(예를 들어, 도 3). 합성곱 신경망에서 대부분의 연산 시간은 합성곱 연산이 차지한다. 합성곱 신경망은 행렬(Matrix) 형태의 커널(kernel)에 의해 각 채널의 영상의 특징을 추출하고, 풀링(Pooling) 에 의해 이동이나 왜곡 등에 대해서 항상성을 제공하는 방식으로 사물을 추론한다. 각 채널에서는 입력 데이터 와 커널의 합성곱으로 특징맵(Feature Map)을 구한 후 활성화 함수를 적용하여 해당 채널의 활성화 맵을 생성한 다. 이후 풀링이 적용될 수 있다. 패턴을 최종적으로 분류하는 레이어는 합성곱 신경망의 후단에 위치하며, 완전 연결 레이어(Fully Connected Layer)가 예시적으로 사용될 수 있다. 합성곱 신경망의 연산 처리에서 대부분의 연산은 합성곱 또는 행렬곱을 통해 수행된다. 한편, 입력 데이터의 해상도를 향상시키기 위하여, 쌍선형 보간법을 수행할 수 있다. 그리고, 이러한 쌍선형 보 간법에 따른 연산은 입력 데이터의 픽셀 데이터와 기 정해진 커널의 합성곱 연산으로 표현할 수 있다. 이에, 쌍선형 보간법을 이용한 입력 데이터의 해상도 향상을 위하여, 입력 데이터의 픽셀 데이터와 기 정해진 복수개의 커널들의 합성곱 연산을 반복할 수 있다. 이때 필요한 커널들을 메인 메모리로부터 읽어 오는 빈도가 상당히 빈번하다. 이러한 합성곱 신경망 동작의 상 당 부분은 각각의 채널에 대응되는 커널들을 메인 메모리로부터 신경 프로세싱 유닛으로 읽어오는 시간이 차지 한다. 메모리는 메인 메모리, 내부 메모리, 온 칩(On-Chip) 메모리 등으로 나뉘어진다. 각각의 메모리는 복수의 메모 리 셀로 이루어지며, 각각의 메모리 셀은 고유한 메모리 주소를 가진다. 신경 프로세싱 유닛이 메인 메모리에 저장된 특징맵 또는 가중치를 불러오거나 다른 파라미터(parameter)를 불러올 때마다, 메인 메모리의 주소에 대 응되는 메인 메모리 셀에 접근하기까지 여러 클럭(clock)의 지연시간(latency)이 발생될 수 있다. 이러한 지연 시간은 Column Address Strobe(CAS) Latency 및 Row Address Strobe (RAS) Latency를 포함할 수 있다. 인공신경망 연산은 방대한 데이터를 요구한다. 따라서 메인 메모리에서 신경 프로세싱 유닛으로 필요한 데이터, 즉, 파라미터, 예를 들면, 가중치, 특징맵 또는 커널을 읽어오는데 소모되는 시간과 전력 소모가 상당하다는 문 제가 있다. 인공신경망모델의 추론 시, 신경 프로세싱 유닛(NPU)이 빈번하게 인공신경망모델의 특정 레이어의 데이터, 예를 들면, 가중치, 특징맵 또는 커널 등의 파라미터를 메인 메모리에서 읽어온다는 사실을 본 개시의 발명자는 인식 하였다. 신경 프로세싱 유닛(NPU)이 인공신경망모델의 데이터, 예를 들면, 가중치, 특징맵 또는 커널 등의 파라미터를 메인 메모리에서 읽어오는 동작의 처리 속도가 느리고 에너지를 많이 소비한다는 사실을 본 개시의 발명자는 인 식하였다. 메인 메모리에 대한 액세스가 아닌 온칩 메모리나 NPU 내부 메모리에 대한 엑세스가 빈도가 늘어날 수록 NPU의 처리 속도가 빨라지고 에너지 소비도 감소한다는 사실을 본 개시의 발명자는 인식하였다. 또한, NPU는 많은 수의 프로세싱 엘리먼트를 포함하도록 설계될 수 있다. 다수의 프로세싱 엘리먼트를 활용하여 쌍선형 보간법을 처리할 수 있다면 병렬 처리도 쌍선형 보간법을 빠르게 처리할 수 있다는 사실도 본 개시의 발 명자들은 인식하였다. 이에, 본 개시가 해결하고자 하는 과제는 NPU에서 쌍선형 보간법(Bilinear Interpolation)을 적용하기 위한 합 성곱 연산 시 가중치를 재사용하여, 메인 메모리 읽기 동작의 횟수를 저감하고, 소비 전력을 저감할 수 있는 신 경 프로세싱 유닛 및 그 동작 방법을 제공하는 것이다. 이에, 본 개시가 해결하고자 하는 과제는 NPU의 복수의 프로세싱 엘리먼트 들에서 쌍선형 보간법을 수행하도록 구성된 신경 프로세싱 유닛 및 그 동작 방법을 제공하는 것이다. 단 본 개시는 이에 제한되지 않으며, 또 다른 과제들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0118599", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 바와 같은 과제를 해결하기 위하여 본 개시의 일 예시에 따른 신경 프로세싱 유닛이 제공된다. 신경 프로세싱 유닛은 복수의 제1 픽셀 데이터를 포함하는 제1 데이터의 해상도를 확장시켜 복수의 제2 픽셀 데 이터를 포함하는 제2 데이터를 생성하기 위하여, 쌍선형 보간법을 수행하도록 구성된 복수의 PE(Processing Element)를 포함할 수 있다. 상기 복수의 PE 중 적어도 하나는, 상기 복수의 제1 픽셀 데이터 및 상기 쌍선형 보간법을 수행하는 가중치를 입력 받아 상기 복수의 제2 픽셀 데이터를 산출하도록 구성할 수 있다. 상기 복수의 PE 중 적어도 하나는, 2x2 크기의 상기 쌍선형 보간법 연산용 가중치를 입력 받도록 구성될 수 있 다. 상기 복수의 PE에 입력되는 가중치 각각의 원소는 상기 쌍선형 보간법을 수행하기 위해 상기 제1 데이터의 제1 픽셀 데이터에 곱해지는 계수일 수 있다. 상기 제2 데이터의 최외측 영역에 대응되는 제2 픽셀 데이터를 생성하기 위하여, 상기 제1 데이터의 최외측 영 역에 대응되는 제1 픽셀 데이터를 상기 제1 데이터의 외부 영역으로 복제할 수 있다. 상기 복수의 PE는,과 열로 배열되고, 딜레이 버퍼를 포함하는 PE Array로 구성되고, 상기 PE Array는 상기 쌍선 형 보간법을 수행하는 가중치가 상기 PE Array 중 특정 행의 PE들 및 대응되는 상기 딜레이 버퍼에 브로드캐스 트 되도록 구성될 수 있다. 상기 복수의 PE는, 복수의 행과 복수의 열로 배열된 PE Array로 구성되고, 인접한 행들 사이의 PE들에 대응되는 딜레이 버퍼를 더 포함하고, 딜레이 버퍼는 제1 행의 PE에 입력된 가중치를 다음 클럭에 제2 행의 PE에 전달하 여 상기 가중치를 재사용 하도록 구성될 수 있다. 상기 복수의 PE는, 포인트와이즈 합성곱 연산(point-wise convolution)을 수행하도록 구성될 수 있다. 상기 복수의 PE는, 행과 열로 배열된 PE Array로 구성되고, 상기 쌍선형 보간법을 수행하는 가중치 각각은 상기 PE Array 중 서로 다른 행에 배치된 PE들에 브로드캐스트 되도록 구성될 수 있다. 상기 복수의 PE는, 행과 열로 배열된 PE Array로 구성되고, 상기 제1 픽셀 데이터를 특정 클럭만큼 딜레이하여 출력하는 직렬 연결된 복수의 딜레이 버퍼를 더 포함할 수 있다. 상기 복수의 PE는, 복수의 딜레이 버퍼를 포함하는 행과 열로 배열된 PE Array로 구성되고, 상기 제1 픽셀 데이 터는 상기 PE Array 중 첫번째 행에 배치된 PE들 및 상기 복수의 딜레이 버퍼에 브로드캐스트 되도록 구성될 수 있다. 상기 복수의 PE는, 딜레이 버퍼를 포함하는 PE Array로 구성되고, 하나의 PE에 입력되고, 상기 딜레이 버퍼에 의해 딜레이된 상기 제1 픽셀 데이터는 다음행의 PE에서 재사용되도록 구성될 수 있다. 상기 제1 데이터는 인공신경망모델의 특정 레이어의 입력 데이터이고, 상기 제2 데이터는 상기 특정 레이어의 출력 데이터이고, 상기 제2 데이터는 특정 PE에서 상기 쌍선형 보간법을 수행하는 가중치를 적용하여 상기 제1 데이터에 상기 쌍선형 보간법이 적용된 결과일 수 있다. 상기 제1 데이터는 이미지, 특징맵 또는 활성화맵 중 하나이고, 상기 제1 데이터는 특정 인공신경망모델의 특정 레이어의 입력 데이터이고, 상기 제2 데이터는 쌍선형 보간법이 적용된 상기 특정 인공신경망모델의 상기 특정 레이어의 출력 데이터일 수 있다. 상기 복수의 PE는 곱셈기, 덧셈기, 및 누산기를 포함할 수 있다. 상기 쌍선형 보간법은 상기 복수의 PE를 통해서 특정 인공신경망모델의 업스케일링(up-scaling) 연산 또는 세그 먼테이션(segmentation) 연산을 수행하도록 구성될 수 있다."}
{"patent_id": "10-2023-0118599", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, NPU에서 쌍선형 보간법(Bilinear Interpolation)을 위한 합성곱 연산 시 가중치 및 픽셀 데 이터를 재사용함으로써, 메인 메모리 읽기 동작의 횟수를 저감하고, 소비 전력을 저감할 수 있다. 또한, 본 개시에 따르면, 쌍선형 보간법(Bilinear Interpolation) 적용을 위한 합성곱 연산 시 가중치 및 픽셀 데이터를 딜레이하여 재사용함으로써, NPU에서 사용되는 에너지를 절약하고, 프로세싱 엘리먼트 어레이의 효율 성 및 처리율이 향상된 신경 프로세싱 유닛을 제공할 수 있다. 또한, 본 개시에 따르면, 복수의 프로세싱 엘리먼트들이 쌍선형 보간법 연산에 활용되어 쌍선형 보간법 연산을 병렬로 고속으로 처리할 수 있는 신경 프로세싱 유닛을 제공할 수 있다."}
{"patent_id": "10-2023-0118599", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서 또는 출원에 개시되어 있는 본 개시의 개념에 따른 실시 예들에 대해서 특정한 구조적 내지 단계적 설명들은 단지 본 개시의 개념에 따른 실시 예를 설명하기 위한 목적으로 예시된 것이다. 본 개시의 개념에 따 른 실시 예들은 다양한 형태로 실시될 수 있으며 본 명세서 또는 출원에 설명된 실시 예들에 한정되는 것으로 해석되어서는 아니 된다. 본 개시의 개념에 따른 실시 예는 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있다. 따라서 특정 실 시 예들을 도면에 예시하고 본 명세서 또는 출원에 상세하게 설명하고자 한다. 그러나, 이는 본 개시의 개념에 따른 실시 예를 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 개시의 사상 및 기술 범위에 포함되는 모 든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1 및/또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만, 예컨대 본 개시의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1 구성요소는 제2 구성요소로 명명 될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관 계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 인접하는\"과 \"~에 직접 인접하는\" 등도 마찬가지로 해석되어야 한다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\" 등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\" 등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 예를 들면, 제1 사용자 기기와 제2 사용자 기기는, 순서 또는 중요도와 무관하게, 서로 다른 사용자 기기를 나타낼 수 있다. 예를 들면, 본 문서에 기재된 권리범위를 벗어나지 않으면서 제1 구성요소는 제 2 구성요소로 명명될 수 있고, 유사하게 제 2 구성요소도 제1 구성요소로 바꾸어 명명될 수 있다. 본 개시에서 사용된 용어들은 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 다른 예시의 범위를 한정하 려는 의도가 아닐 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수"}
{"patent_id": "10-2023-0118599", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 문서에 기재된 기술분야에서 통상 의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시에 사용된 용어들 중 일반적인 사전에 정의된 용어들은, 관련 기술의 문맥상 가지는 의미와 동일 또는 유사한 의미로 해석될 수 있으며, 본 문서에서 명백하게 정의되지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 경우에 따라서, 본 문서에서 정의된 용어일지라도 본 문서의 실시 예들을 배제하도록 해 석될 수 없다. 본 개시에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 개시를 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 개시에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 서술된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이다. 따라서, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미 를 가지는 것으로 해석되어야 하며, 본 개시에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 본 개시의 여러 예시들의 각각 특징들이 부분적으로 또는 전체적으로 서로 결합 또는 조합 가능하다. 따라서 여 러 예시들은 당업자가 충분히 이해할 수 있듯이 기술적으로 다양한 연동 및 구동이 가능하며, 각 예시들이 서로 에 대하여 독립적으로 실시 가능할 수도 있고 연관 관계로 함께 실시 가능할 수도 있다. 실시 예를 설명함에 있어서 본 개시가 속하는 기술 분야에 익히 알려져 있고 본 개시와 직접적으로 관련이 없는 기술 내용에 대해서는 설명을 생략할 수 있다. 이는 불필요한 설명을 생략함으로써 본 개시의 요지를 흐리지 않 고 더욱 명확히 전달하기 위함이다. <용어의 정의> 이하, 본 명세서에서 제시되는 개시들의 이해를 돕고자, 본 명세서에서 사용되는 용어들에 대하여 간략하게 정 리하기로 한다. NPU: 신경 프로세싱 유닛(Neural Processing Unit)의 약어로서, CPU(Central processing unit)과 별개로 인공 신경망모델의 연산을 위해 특화된 프로세서를 의미할 수 있다. ANN: 인공신경망(artificial neural network)의 약어로서, 인간의 지능을 모방하기 위하여, 인간 뇌 속의 뉴런 들(Neurons)이 시냅스(Synapse)를 통하여 연결되는 것을 모방하여, 노드들을 레이어(Layer: 계층) 구조로 연결 시킨, 네트워크를 의미할 수 있다. 인공신경망의 정보: 네트워크의 구조 정보, 레이어의 개수에 대한 정보, 각 레이어의 연결 관계 정보, 각 레이 어의 가중치 정보, 연산 처리 방법에 대한 정보, 활성화 함수 정보 등을 포함하는 정보이다. DNN: 심층 신경망(Deep Neural Network)의 약어로서, 보다 높은 인공 지능을 구현하기 위하여, 인공신경망의 은 닉 레이어의 개수를 늘린 것을 의미할 수 있다. CNN: 합성곱 신경망(Convolutional Neural Network)의 약어로서, 인간 뇌의 시각 피질에서 영상을 처리하는 것 과 유사한 기능을 하는 신경망이다. 합성곱 신경망은 영상처리에 적합한 것으로 알려져 있으며, 입력 데이터의 특징들을 추출하고, 특징들의 패턴을 파악하기에 용이한 것으로 알려져 있다. KERNEL: 합성곱의 N x M 행렬의 가중치를 의미한다. 인공신경망모델의 각각의 레이어는 복수개의 KERNEL을 가지 며, KERNEL의 개수는 채널의 개수 또는 필터의 개수 등으로 지칭될 수 있다. TRANSFORMER: 트랜스포머(transformer)는 어텐션(attention) 기술에 기반한 DNN이다. 트랜스포머는 행렬 곱셈 (matrix multiplication) 연산을 다수 활용한다. 트랜스포머는 입력 값과 쿼리(query; Q), 키(key; K), 및 값 (value; V) 등의 파라미터를 사용하여 출력 값인 어텐션(Q,K,V)를 획득할 수 있다. 트랜스포머는 출력 값 (즉, 어텐션(Q,K,V))에 기초하여 다양한 추론 연산을 처리할 수 있다. 트랜스포머는 CNN 보다 더 우수한 추론 성능을 보여주는 경향이 있다. 이하, 첨부한 도면을 참조하여 본 개시의 일 예시를 설명한다. 도 1은 본 개시의 일 예시에 따른 신경 프로세싱 유닛이 포함된 장치를 설명하는 개략적인 개념도이다. 도 1을 참조하면 신경 프로세싱 유닛이 포함된 장치(B)는 온칩 영역(A)을 포함한다. 온칩 영역 외부에는 메인 메모리가 포함될 수 있다. 예를 들면, 메인 메모리는 ROM, SRAM, DRAM, Resistive RAM, Magneto-resistive RAM, Phase-change RAM, Ferroelectric RAM, Flash Memory, HBM 등과 같은 메모리 중 하나의 메모리를 포함할 수 있다. 메인 메모리 는 적어도 하나의 메모리 유닛으로 구성될 수 있다. 메인 메모리는 단일(homogeneous) 메모리 유닛 또는 이종(heterogeneous) 메모리 유닛으로 구성될 수 있다. 메모리는 복수의 로직 게이트 회로로 구성될 수 있 다. 따라서, 메모리 회로는 육안으로는 식별되어 구분되기 어려울 수 있고, 동작에 의해서 식별될 수 있다. 신경 프로세싱 유닛(neural processing unit, NPU)은 인공신경망을 위한 동작을 수행하도록 특화된 프로 세서이다.온칩 영역(A)에는 신경 프로세싱 유닛이 배치된다. 신경 프로세싱 유닛은 내부 메모리를 포함 할 수 있다. 내부 메모리는 휘발성 메모리 및/또는 비휘발성 메모리를 포함할 수 있다. 예를 들면, 내부 메모리는 ROM, SRAM, DRAM, Resistive RAM, Magneto-resistive RAM, Phase-change RAM, Ferroelectric RAM, Flash Memory, HBM 등과 같은 메모리 중 하나의 메모리를 포함할 수 있다. 내부 메모리 는 적어도 하나의 메모리 유닛으로 구성될 수 있다. 내부 메모리는 단일(homogeneous) 메모리 유닛 또는 이종(heterogeneous) 메모리 유닛으로 구성될 수 있다. 온칩 영역(A)에는 온칩 메모리가 배치될 수 있다. 온칩 메모리는 반도체 다이에 실장된 메모리로 온칩 영역(A)에서 처리되는 데이터를 캐싱하거나 또는 저장하기 위한 메모리일 수 있다. 온칩 메모리는 ROM, SRAM, DRAM, Resistive RAM, Magneto-resistive RAM, Phase-change RAM, Ferroelectric RAM, Flash Memory, HBM 등과 같은 메모리 중 하나의 메모리를 포함할 수 있다. 온칩 메모리는 적어도 하나의 메모리 유닛으로 구성될 수 있다. 온칩 메모리는 단일(homogeneous) 메모리 유닛 또는 이종(heterogeneous) 메 모리 유닛으로 구성될 수 있다. 온칩 영역(A)에는 중앙 프로세싱 유닛(CPU)와 같은 범용 프로세싱 유닛이 배치될 수 있다. CPU는 신경 프로세싱 유닛과 온칩 메모리 그리고 메인 메모리와 동작 가능하게 연결될 수 있다. 신경 프로세싱 유닛이 포함된 장치(B)는 전술한 신경 프로세싱 유닛의 내부 메모리, 온칩 메 모리, 메인 메모리 중 적어도 하나를 포함할 수 있다. 단, 이에 제한되지 않는다. 이하에서 적어도 하나의 메모리는 내부 메모리, 온칩 메모리, 메인 메모리 중 적어도 하나를 포함하도록 의도된다. 또한, 온칩 메모리의 기재는 신경 프로세싱 유닛의 내부 메모리 또는 신경 프로세싱 유닛의 외부에 있으나 온칩 영역(A)에 있는 메모리를 포함하도록 의도된다. 신경 프로세싱 유닛은 전기/전자 회로로 구현된 반도체일 수 있다. 상기 전기/전자 회로라 함은 수많은 전자 소자, (예컨대, 트렌지스터, 커패시터)를 포함하는 것을 의미할 수 있다. 신경 프로세싱 유닛은 프 로세싱 엘리먼트 어레이(processing element array), 내부 메모리, 컨트롤러, 및 인터페이스를 포함할 수 있다. 프로세싱 엘리먼트 어레이, 내부 메모리, 컨트롤러, 특수 함수 유닛 및 인터페이스 각각은 수많은 트렌지스터들이 연결된 반도체 회로일 수 있다. 반도체 회로는 복수의 논리 게이트로 이루어진 회로 일 수 있다. 따라서, 이들 중 일부는 육안으로는 식별되어 구분되기 어려울 수 있고, 동작에 의해서만 식별될 수 있다. 예를 들어, 임의 회로는 프로세싱 엘리먼트 어레이로 동작하기도 하고, 혹은 컨트롤러로 동작될 수도 있 다. 신경 프로세싱 유닛은 프로세싱 엘리먼트 어레이, 프로세싱 엘리먼트 어레이에서 추론될 수 있는 인공신 경망모델의 적어도 일부를 저장하도록 구성된 내부 메모리, 및 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 프로세싱 엘리먼트 어레이 및 내부 메모리를 제어하도록 구성된 스케줄러를 포함할 수 있다. 여기서, 인공신경망모델은 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보를 포 함할 수 있다. 단, 본 개시는 이에 제한되지 않는다. 인공신경망모델은 특정 추론 기능을 수행하도록 학습된 AI 인식모델을 의미할 수 있다. Transformer 및/또는 CNN 기반의 인공신경망모델인 경우, 신경 프로세싱 유닛은 행렬 곱셈 연산, 합성곱 연산, 등을 인공신경망모델의 구조(architecture)에 따라 선별하여, 처리할 수 있다. 예를 들어, 합성곱 신경망(CNN)의 레이어 각각에서, 입력 데이터에 해당하는 입력 특징맵(Input feature map)과 가중치(Weight)에 해당하는 커널(kernel)은 복수의 채널로 구성된 행렬일 수 있다. 입력 특징맵과 커널의 합성 곱 연산이 수행되며, 각 채널에서 합성곱 연산과 풀링 출력 특징맵(output feature map)이 생성된다. 출력 특징 맵에 활성화 함수를 적용하여 해당 채널의 활성화맵(activation map)이 생성된다. 이후, 활성화맵에 대한 풀링 이 적용될 수 있다. 여기서 포괄적으로 활성화맵은 출력 특징맵으로 지칭될 수 있다. 가중치, 활성화 함수, 입 력 특징맵, 활성화맵, 출력 특징맵은 인공신경망모델의 파라미터로 지칭되는 것도 가능하다. 예를 들면, 인공신경망모델은 Object Detection, Object Segmentation, Image/Video Reconstruction, Image/Video Enhancement, Object Tracking, Event Recognition, Event Prediction, Anomaly Detection, Density Estimation, Event Search, Measurement 등의 추론을 수행하도록 학습될 모델일 수 있다. 예를 들면, 인공신경망모델은 ViT, DaViT, MobileViT, Swin-Transformer, Transformer, RCNN, SegNet, DeconvNet, DeepLAB, U-net, PIDNet, Segment Anything, Segment Anything Model (SAM), MobileSAM, Bisenet,Shelfnet, Alexnet, Densenet, Efficientnet, EfficientDet, Googlenet, Mnasnet, Mobilenet, Resnet, Shufflenet, Squeezenet, VGG, Yolo, RNN, CNN, DBN, RBM, LSTM 등의 모델일 수 있다. 단, 본 개시는 이에 제 한되지 않으며, NPU에서 동작할 새로운 인공신경망모델이 꾸준히 발표되고 있다. 상술한 인공신경망모델은 다층구조의 레이어를 포함하도록 구성될 수 있다. 예를 들면 MobileNet V1.0 모델의 레이어는 28개일 수 있다. 인공신경망은 입력 신호가 들어오면, 입력 신호에 가중치를 적용하고, 선택적으로 활성화 함수를 적용하는 인공 뉴런들로 구성된 네트워크를 의미한다. 이러한 인공신경망은 입력 데이터로부터 추론(inference) 결과를 출력하 는데 사용될 수 있다. 프로세싱 엘리먼트 어레이는 인공신경망모델의 연산을 위한 동작을 수행할 수 있다. 예를 들어, 입력 데이터가 입력되었을 때, 프로세싱 엘리먼트 어레이는 인공신경망모델의 학습을 수행하도록 할 수 있다. 또한 입력 데이 터가 입력되었을 때, 프로세싱 엘리먼트 어레이는 학습 완료된 인공신경망모델을 통해 추론 결과를 도출하는 연 산을 수행할 수 있다. 예를 들면, 신경 프로세싱 유닛은 인터페이스를 통해서 메인 메모리에 저장된 인공신경망모델의 데 이터의 적어도 일부를 내부 메모리으로 불러올 수 있다. 컨트롤러는 신경 프로세싱 유닛은 추론 연산을 위한 프로세싱 엘리먼트 어레이의 연산 및 내부 메모리 의 읽기 및 쓰기 순서를 제어하도록 구성된다. 또한 컨트롤러는 입력 데이터에 해당하는 배치 채널의 적어 도 일부의 크기를 조정하도록 구성된다. 컨트롤러는 복수의 로직 게이트 회로로 구성될 수 있다. 따라서, 컨트 롤러는 육안으로는 식별되어 구분되기 어려울 수 있고, 동작에 의해서 식별될 수 있다. 인공신경망모델의 구조에 의하면, 각 레이어 별 연산은 순차적으로 수행된다. 즉, 인공신경망모델의 구조가 확 정될 경우, 레이어 별 연산순서가 정해질 수 있다. 각 레이어 별 연산은 신경 프로세싱 유닛의 내부 메모 리 또는 온 칩 메모리의 크기에 따라서 한번에 처리가 불가한 경우가 발생할 수 있다. 이러한 경우, 신경 프로세싱 유닛은 적절한 크기로 해당 레이어를 타일링(tiling)하여 하나의 연산처리를 복수의 연산 처리로 나누어 처리할 수 있다. 이러한 인공신경망모델의 구조 및 신경 프로세싱 유닛의 하드웨어 제약에 따른 연산의 순서 또는 데이터 흐름의 순서를 신경 프로세싱 유닛에서 추론되는 인공신경망모델의 데이터 지역성으로 정의할 수 있다. 즉, 인공신경망모델이 신경 프로세싱 유닛에서 실행되도록 컴파일러가 인공신경망모델을 컴파일 할 경우, 신경 프로세싱 유닛-메모리 레벨에서의 인공신경망모델의 인공신경망 데이터 지역성이 재구성될 수 있다. 예를 들어, 컴파일러는 CPU에 의해 실행될 수 있다. 또는 컴파일러는 별도의 시스템에서 실행될 수 있다. 컴파 일러는 소프트웨어 또는 펌웨어로 구현될 수 있다. 즉, 컴파일러, 인공신경망모델에 적용된 알고리즘들, 및 신경 프로세싱 유닛의 동작 특성, 가중치의 크기, 및 특징맵 또는 채널의 개수에 따라서 내부 메모리에 로딩되는 인공신경망모델 처리에 필요한 데이 터의 크기 및 순서가 결정될 수 있다. 예를 들면, 동일한 인공신경망모델의 경우에도 신경 프로세싱 유닛이 해당 인공신경망모델을 연산하는 방 식, 예를 들면, 특징맵 타일링(feature map tiling), 프로세싱 엘리먼트의 스테이셔너리(Stationary) 기법 등, 신경 프로세싱 유닛의 프로세싱 엘리먼트 개수, 신경 프로세싱 유닛 내 특징맵 및 가중치의 크기, 내부 메모리 용량, 신경 프로세싱 유닛내의 메모리 계층 구조, 및 해당 인공신경망모델을 연산 처리하기 위한 신경 프로세싱 유닛의 연산 동작의 순서를 결정해 주는 이와 같이 생성된 출력 특징맵에 활성화 함 수가 적용되어 활성화 맵이 최종적으로 출력될 데이터의 알고리즘 특성 등에 따라서 처리하고자 하는 인공신경 망모델의 계산 방법이 구성될 수 있다. 왜냐하면, 상술한 요인들에 의해서 동일한 인공신경망모델을 연산 처리 하더라도 신경 프로세싱 유닛이 클럭 단위로 매 순간 필요한 데이터의 순서를 상이하게 결정할 수 있기 때문이다. 이하에서는 도 2를 참조하여 컴파일러에 대해서 구체적으로 설명한다. 도 2는 본 개시에 관련된 컴파일러를 설명하는 개략적인 개념도이다. 도 2를 참조하면, 컴파일러는 프론트엔드(frontend) 및 백엔드(backend)를 가지고, 프로그램 최적화를 위 해 사용되는 IR(Intermediate representation)이 프론트엔드와 백엔드 사이에 존재한다. 예를 들면, 컴파일러 특정 딥러닝 프레임워크로 생성된 인공신경망모델을 입력 받도록 구성될 수 있다. 예를 들면, 딥러닝 프레임워크는 TensorFlow, PyTorch, Keras, XGBoost, mxnet, DARKNET, ONNX 등이 있다. 프론트엔드는 입력되는 인공신경망모델에 대한 하드웨어에 독립적인 변환 및 최적화 작업을 수행하고, IR은 소 스 코드를 나타내기 위해 사용되며, 백엔드는 소스 코드로부터 바이너리 형태의 머신 코드(즉, 신경 프로세싱 유닛에서 사용될 수 있는 코드)를 생성한다. 컴파일러는 인공신경망모델의 데이터 지역성에 기초하여 프로세싱 순서를 스케줄링 하기 때문에, 일반적 인 CPU의 스케줄링 개념과 다르게 동작할 수 있다. 일반적인 CPU의 스케줄링은 공평성, 효율성, 안정성, 반응 시간 등을 고려하여, 최상의 효율을 낼 수 있도록 동작한다. 즉, 우선 순위, 연산 시간 등을 고려해서 동일 시 간내에 가장 많은 프로세싱을 수행하도록 스케줄링 한다. 즉, 종래의 CPU는 각 프로세싱의 우선 순서, 연산 처 리 시간 등의 데이터를 고려하여 작업을 스케줄링 하는 알고리즘을 사용하였다. 이와 다르게 컴파일러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 결정된 신경 프로세싱 유닛의 프로세싱 순서대로 신경 프로세싱 유닛을 제어할 수 있다. 즉, 신경 프로세싱 유닛은 컴파일러로부터 컴파일 된 머신 코드에 기초하여 동작하도록 구성될 수 있으나, 다른 예에서는 신경 프로세싱 유닛는 임베디드 컴파일러를 내장하도록 구성되는 것도 가능하다. 상술한 구성에 따르면, 신경 프로세싱 유닛은 다양한 AI 소프트웨어의 프레임워크의 형식의 파일을 입력 받아 머신 코드를 생성하도록 구성될 수 있다. 또 다른 예에서는 신경 프로세싱 유닛을 포함하는 장치 (B)는 임베디드 컴파일러를 내장하도록 구성되는 것도 가능하다. 이하에서는 인공신경망 중에서 심층 신경망(DNN)의 한 종류인 합성곱 신경망(CNN)에 대해서 도 3을 참조하여 상 세하게 설명하기로 한다. 도 3은 본 개시에 관련된 합성곱 신경망을 설명하는 개략적인 개념도이다. 컨볼루션 신경망은 하나 또는 여러 개의 컨볼루션 레이어(convolutional layer)와 통합 레이어(pooling layer), 완전하게 연결된 레이어(fully connected layer)들의 조합일 수 있다. 컨볼루션 신경망은 2차원 데이터 의 학습 및 추론에 적합한 구조를 가지고 있으며, 역전달(Backpropagation algorithm)을 통해 학습될 수 있다. 본 개시의 예시에서, 컨볼루션 신경망은 채널마다 채널의 입력 영상의 특징을 추출하는 커널이 존재한다. 커널 은 2차원 행렬로 구성될 수 있으며, 입력 데이터를 순회하면서 합성곱 연산 수행한다. 커널의 크기는 임의로 결 정될 수 있으며, 커널이 입력 데이터를 순회하는 간격(stride) 또한 임의로 결정될 수 있다. 커널 하나당 입력 데이터 전체에 대한 합성곱 결과는 특징맵(feature map) 또는 활성화 맵으로 지칭될 수 있다. 이하에서 커널은 일 세트의 가중치 또는 복수의 세트의 가중치를 포함할 수 있다. 각 레이어 별 커널의 개수는 채널의 개수로 지칭될 수 있다. 이처럼 합성곱 연산은 입력 데이터와 커널의 조합으로 이루어진 연산이므로, 이후 비선형성을 추가하기 위한 활 성화 함수가 적용될 수 있다. 합성곱 연산의 결과인 특징맵에 활성화 함수가 적용되면 활성화 맵으로 지칭될 수 있다. 구체적으로 도 3을 참조하면, 컨볼루션 신경망은 적어도 하나의 컨볼루션 레이어, 적어도 하나의 풀링 레이어, 및 적어도 하나의 완전 연결 레이어를 포함한다. 예를 들면, 합성곱(컨볼루션)은, 입력 데이터의 크기(통상적으로 1×1, 3×3 또는 5×5 행렬)와 출력 피처 맵 (Feature Map)의 깊이(커널의 수)와 같은 두 개의 주요 파라미터에 의해 정의될 수 있다. 이러한 주요 파라미터 는 합성곱에 의해 연산될 수 있다. 이들 합성곱은, 깊이 32에서 시작하여, 깊이 64로 계속되며, 깊이 128 또는 256에서 종료될 수 있다. 합성곱 연산은, 입력 데이터인 입력 이미지 행렬 위로 3×3 또는 5×5 크기의 커널 (kernel)을 슬라이딩하여 커널의 각 가중치와 겹쳐지는 입력 이미지 행렬의 각 원소를 곱한 후 이들을 모두 더 하는 연산을 의미할 수 있다. 이와 같이 생성된 출력 특징맵에 활성화 함수가 적용되어 활성화 맵이 최종적으로 출력될 수 있다. 풀링 레이어 는 출력 데이터(즉, 활성화 맵)을 다운 샘플링하여 특징맵의 크기를 줄이는 풀링 연산을 수행할 수 있다. 예를 들어, 풀링 연산은 최대 풀링(max pooling) 및/또는 평균 풀링(average pooling)을 포함할 수 있으나, 이에 한 정되지 않는다. 최대 풀링 연산은 커널을 이용하며, 특징맵과 커널이 슬라이딩되어 커널과 겹쳐지는 특징맵의 영역에서 최대 값 을 출력한다. 평균 풀링 연산은 특징맵과 커널이 슬라이딩되어 커널과 겹쳐지는 특징맵의 영역 내에서 평균값을출력한다. 이처럼 풀링 연산에 의해 특징맵의 크기가 줄어들기 때문에 특징맵의 파라미터 개수 또한 줄어든다. 완전 연결 레이어는 풀링 레이어를 통해서 출력된 데이터를 복수의 클래스(즉, 추정값)로 분류하고, 분류된 클 래스 및 이에 대한 점수(score)를 출력할 수 있다. 풀링 레이어를 통해서 출력된 데이터는 3차원 특징맵 형태를 이루며, 이러한 3차원 특징맵이 1차원 벡터로 변환되어 완전 연결 레이어로 입력될 수 있다. 이하에서는 도 4를 참조하여 신경망 프로세스 유닛에 대해서 구체적으로 설명하도록 한다. 도 4는 본 개시의 일 예시에 따른 신경 프로세싱 유닛을 설명하는 개략적인 개념도이다. 도 4를 참조하면, 신경 프로세싱 유닛은 프로세싱 엘리먼트 어레이, 내부 메모리, 컨트롤러 특수 함수 유닛(Special function unit; SFU)을 포함한다. 프로세싱 엘리먼트 어레이는 인공신경망의 노드 데이터와 연결망의 가중치를 연산하도록 구성된 적어도 하 나의 프로세싱 엘리먼트를 포함하도록 구성된다. 각각의 프로세싱 엘리먼트는 MAC (multiply and accumulate) 연산기 및/또는 ALU (Arithmetic Logic Unit) 연산기를 포함할 수 있다. 단, 본 개시에 따른 예시 들은 이에 제한되지 않는다. 프로세싱 엘리먼트는 복수의 로직 게이트 회로로 구성될 수 있다. 따라서, 프 로세싱 엘리먼트는 육안으로는 식별되어 구분되기 어려울 수 있고, 동작에 의해서 식별될 수 있다. 또한, 제시된 일 예시에서 적어도 하나의 프로세싱 엘리먼트는 단지 설명의 편의를 위한 예시이며, 적어도 하나의 프로세싱 엘리먼트의 개수는 제한되지 않는다. 적어도 하나의 프로세싱 엘리먼트의 개수에 의 해서 프로세싱 엘리먼트 어레이의 크기 또는 개수가 결정될 수 있다. 프로세싱 엘리먼트 어레이의 크기는 N x M 행렬 형태로 구현될 수 있다. 여기서 N 과 M은 0보다 큰 정수이다. 이에, 프로세싱 엘리먼트 어레이(10 0)는 N x M 개의 프로세싱 엘리먼트를 포함할 수 있다. 프로세싱 엘리먼트 어레이의 크기는 신경 프로세싱 유닛이 작동하는 인공신경망모델의 특성을 고려 하여 설계할 수 있다. 부연 설명하면, 프로세싱 엘리먼트의 개수는 작동할 인공신경망모델의 데이터 크기, 요구 되는 연산량, 요구되는 소비 전력 등을 고려하여 결정될 수 있다. 인공신경망모델의 데이터 크기는 인공신경망 모델의 레이어 수와 각각의 레이어의 가중치 크기에 대응되어 크기가 결정될 수 있다. 따라서, 본 개시의 일 예시에 따른 프로세싱 엘리먼트 어레이의 크기는 제한되지 않는다. 프로세싱 엘리먼 트 어레이의 적어도 하나의 프로세싱 엘리먼트의 개수가 증가할수록 작동하는 인공신경망모델의 병렬 연산 능력이 증가되나, 신경 프로세싱 유닛의 제조 비용 및 물리적인 칩 크기가 증가될 수 있다. 프로세싱 엘리먼트 어레이는 적어도 하나일 수 있다. 즉, 프로세싱 엘리먼트 어레이는 복수개로 구성 될 수 있다. 프로세싱 엘리먼트 어레이가 복수일 경우, 각각의 어레이는 NPU 쓰레드, NPU 코어, 또는 NPU 엔진으로 지칭되는 것도 가능하다. 예를 들면, 신경 프로세싱 유닛에서 작동되는 인공신경망모델은 30개의 특정 키워드를 감지하도록 학습된 인공신경망, 즉 AI 키워드 인식모델일 수 있다. 이러한 경우, 프로세싱 엘리먼트 어레이의 크기는 인공신 경망모델의 연산량 특성을 고려하여 4 x 3로 설계될 수 있다. 다르게 설명하면, 프로세싱 엘리먼트 어레이(10 0)는 12개의 프로세싱 엘리먼트들을 포함할 수 있다. 단, 이에 제한되지 않으며, 적어도 하나의 프로세싱 엘리 먼트의 개수는 예를 들면, 8개 내지 16,384 범위 내에서 선택되는 것도 가능하다. 즉, 본 개시의 예시들에 서 프로세싱 엘리먼트의 개수는 제한되지 않는다. 프로세싱 엘리먼트 어레이는 인공신경망 연산에 필요한 덧셈, 곱셈, 누산 등의 기능을 수행하도록 구성된 다. 다르게 설명하면, 프로세싱 엘리먼트 어레이는 MAC(multiplication and accumulation) 연산을 수행하 도록 구성될 수 있다. 한편, 프로세싱 엘리먼트 어레이는 인공신경망모델의 연산을 수행할 뿐만 아니라, 입력 데이터의 해상도를 증가시키기 위한 쌍선형 보간법(Bilinear Interpolation)을 연산할 수 있다. 입력 데이터는 이미지, 특징맵 또는 활성화맵일 수 있다. 입력 데이터는 인공신경망모델의 특정 레이어의 입력 파라미터 일 수 있다. 즉, 프로세싱 엘리먼트 어레이에 포함되는 적어도 하나의 프로세싱 엘리먼트에 제1 데이터의 픽셀 데 이터와 쌍선형 보간법을 연산을 위한 커널인 가중치를 제공한다. 그리고, 적어도 하나의 프로세싱 엘리먼트 는 제1 데이터와 쌍선형 보간법을 연산을 위한 가중치의 합성곱 연산을 수행하여, 업스케일된 제2 데이터 의 픽셀 데이터를 출력할 수 있다.이하에서는 도 5 내지 도 10을 참조하여, 제1 데이터의 해상도를 확장시켜 제2 데이터를 생성하기 위하여, 쌍선 형 보간법(Bilinear Interpolation) 연산에 사용되는 가중치를 설정하는 방법에 대해서 설명한다. 도 5는 본 개시에 적용될 수 있는 쌍선형 보간법(Bilinear Interpolation)을 설명하는 개략적인 개념도이다. 쌍선형 보간법(Bilinear Interpolation)은 제1 데이터의 4개의 픽셀 데이터를 통해, 제1 데이터의 4개의 픽셀 데이터 사이에 배치되는 제2 데이터의 픽셀 데이터를 연산하는 방법을 의미한다. 여기서 픽셀은 이미지 파일의 픽셀, 텐서(tensor)의 픽셀, 행렬의 픽셀, 커널의 픽셀, 특징맵의 픽셀, 활성화맵 의 픽셀 등을 지칭할 수 있다. 이 때, 쌍선형 보간법(Bilinear Interpolation)을 수행하여 생성되는 상기 제2 데이터의 픽셀은 상기 제1 데이 터의 복수의 픽셀 사이에 배치될 수 있다. 구체적으로, 쌍선형 보간법(Bilinear Interpolation)은 제1 데이터의 4개의 픽셀 데이터에 대하여 제1 방향(수 평 방향) 기준으로 선형 보간법(Linear Interpolation)을 수행한 뒤, 제2 방향(수직 방향) 기준으로 선형 보간 법(Linear Interpolation)을 수행하여 연산될 수 있다. 보다 상세하게는, 제1 데이터의 4개의 픽셀 데이터 중 수평 방향으로 배치된 2개의 픽셀 데이터에 대하여 선형 보간법(Linear Interpolation)을 수행한다. 예를 들어, 도 5에 도시된 바와 같이, E픽셀 데이터는 w2/(w1+w2) * A + w1/(w1+w2) * C로 표현될 수 있다. 그 리고, F픽셀 데이터는 w2/(w1+w2) * B + w1/(w1+w2) * D로 표현될 수 있다. 여기서, w1은 A픽셀과 E픽셀 사이의 수평 거리 혹은 B픽셀과 F픽셀 사이의 수평 거리를 의미한다. 그리고, w2는 C픽셀과 E픽셀 사이의 수평 거리 혹은 D픽셀과 F픽셀 사이의 수평 거리를 의미한다. 그리고, A는 A 픽셀 데이터 를 의미하고, B는 B 픽셀 데이터를 의미하고, C는 C 픽셀 데이터를 의미하고, D는 D픽셀 데이터를 의미한다. 이후, 수평 방향으로 선형 보간법을 통해 계산된 픽셀 데이터를 다시 수직 방향으로 선형 보간법을 수행하여, 제2 데이터의 픽셀 데이터를 연산할 수 있다. 즉, E픽셀 데이터와 F 픽셀 데이터를 수직 방향으로 선형 보간법을 수행하여, 제2 데이터의 픽셀 데이터인 T 픽 셀 데이터를 연산할 수 있다. 예를 들어, T 픽셀 데이터는 h2/(h1+h2) * E + h1/(h1+h2) * F로 표현될 수 있다. 여기서, h1은 E픽셀과 T픽셀 사이의 수평 거리를 의미한다. 그리고, h2는 T픽셀과 F픽셀 사이의 수평 거리를 의 미한다. 그리고, E는 E 픽셀 데이터를 의미하고, F는 F 픽셀 데이터를 의미한다. T 픽셀 데이터를 A 픽셀 데이터, B 픽셀 데이터, C 픽셀 데이터 및 D 픽셀 데이터로 표현하면, w2/(w1+w2) * h2/(h1+h2) * A + w2/(w1+w2) * h1/(h1+h2) * B + w1/(w1+w2) * h2/(h1+h2) * C + w1/(w1+w2) * h1/(h1+h2) * D로 표현할 수 있다. 이를 정리하면, T 픽셀 데이터는 입력데이터( )에 커널( )를 합성곱한 값인 W0*A + W1*B + W2*C + W3*D 로 표현할 수 있다. 그리고, W0=w2/(w1+w2) * h2/(h1+h2) 일 수 있고, W1=w2/(w1+w2) * h1/(h1+h2) 일 수 있고, W2=w1/(w1+w2) * h2/(h1+h2) 일 수 있고, W3=w1/(w1+w2) * h1/(h1+h2)일 수 있다. 즉, 커널 즉, 가중치 각각의 원소는 쌍선형 보간법(Bilinear Interpolation)을 수행하기 위해 상기 제1 데이터 의 복수의 픽셀 데이터에 곱해지는 계수라고 표현할 수 있다. 도 6은 본 개시에 적용될 수 있는 제2 데이터의 정렬 방식을 설명하는 개략적인 개념도이다. 소스 이미지인 제1 데이터로부터 해상도를 증가시켜 타겟 이미지인 제2 데이터를 생성할 때, 제1 데이터의 코너 기준으로 제2 데이터를 정렬하는 방식이 2가지 존재한다. 첫번째로, align_corners True 방식은 제1 데이터의 코너 픽셀의 위치를 제2 데이터의 코너 픽셀의 위치와 중첩 되도록 정렬하는 방식을 의미한다. 다음으로, align_corners False 방식은 제1 데이터의 코너 픽셀의 위치를 제2 데이터의 코너 픽셀의 위치와 중 첩되도록 정렬하지 않는 방식을 의미한다. 구체적으로, align_corners False 방식에서, 제1 데이터의 모든 픽셀 사이에 규칙적으로 제2 데이터의 픽셀이 배치될 수 있다. 따라서, align_corners False 방식을 진행할 경우에만, 제1 데이터의 복수의 픽셀 데이터에 쌍 선형 보간법(Bilinear Interpolation)을 적용하여 제2 데이터의 픽셀 데이터를 생성할 수 있다. 단, align_corners False 방식은 본 개시의 예시를 용이하게 설명하기 위한 것일 뿐이며, 본 개시는 이에 제한되지 않는다. 도 7은 본 개시에서 쌍선형 보간법(Bilinear Interpolation)을 적용하여 제2 데이터의 제1 픽셀 데이터를 생성 하는 방법을 설명하기 위한 개념도이다. 도 8은 본 개시에서 쌍선형 보간법(Bilinear Interpolation)을 적용하여 제2 데이터의 제2 픽셀 데이터를 생성 하는 방법을 설명하기 위한 개념도이다. 도 9는 본 개시에서 쌍선형 보간법(Bilinear Interpolation)을 적용하여 제2 데이터의 제3 픽셀 데이터를 생성 하는 방법을 설명하기 위한 개념도이다. 도 10은 본 개시에서 쌍선형 보간법(Bilinear Interpolation)을 적용하여 제2 데이터의 제4 픽셀 데이터를 생성 하는 방법을 설명하기 위한 개념도이다. 제1 데이터에서 2x2로 배치된 4개의 픽셀을 기준으로, 쌍선형 보간법(Bilinear Interpolation)을 적용하여 제1 데이터의 4개의 픽셀 내부에 제2 데이터의 4개의 픽셀 데이터를 생성할 수 있다. 다만, 도 7 내지 도 10에서는 제1 데이터에서 2x2로 배치된 4개의 픽셀을 기준으로, 쌍선형 보간법(Bilinear Interpolation)을 적용하여 제1 데이터의 4개의 픽셀 내부에 2x2 형태로 제2 데이터의 4개의 픽셀 데이터를 생 성하는 것을 도시하였으나, 이에 한정되지 않고, 제1 데이터의 4개의 픽셀 내부에 n x m 형태로 배치된 복수의 제2 데이터의 픽셀 데이터를 생성할 수도 있다. 상술한 n 및 m 각각은 2 이상의 자연수 일 수 있다. 구체적으로 도 7에서는, 제1 데이터의 4개의 픽셀 내부에 제2 데이터의 제1 픽셀 데이터를 생성하는 것을 도시 하였다. 상술한 제2 데이터의 제1 픽셀 데이터는 제1 데이터의 4개의 픽셀 내부의 좌상단 영역에 배치된 제2 데 이터의 픽셀(1, 2, 3, 4)을 의미한다. 그리고, 도 8에서는, 제1 데이터의 4개의 픽셀 내부에 제2 데이터의 제2 픽셀 데이터를 생성하는 것을 도시하였 다. 상술한 제2 데이터의 제2 픽셀 데이터는 제1 데이터의 4개의 픽셀 내부의 우상단 영역에 배치된 제2 데이터 (5, 6, 7, 8)의 픽셀을 의미한다. 그리고, 도 9에서는, 제1 데이터의 4개의 픽셀 내부에 제2 데이터의 제3 픽셀 데이터를 생성하는 것을 도시하였 다. 상술한 제2 데이터의 제1 픽셀 데이터는 제1 데이터의 4개의 픽셀 내부의 좌하단 영역에 배치된 제2 데이터 의 픽셀(9, 10, 11, 12)을 의미한다. 그리고, 도 10에서는, 제1 데이터의 4개의 픽셀 내부에 제2 데이터의 제4 픽셀 데이터를 생성하는 것을 도시하 였다. 상술한 제2 데이터의 제2 픽셀 데이터는 제1 데이터의 4개의 픽셀 내부의 우하단 영역에 배치된 제2 데이 터의 픽셀(13, 14, 15, 16)을 의미한다. 먼저, 도 5에서 설명한 쌍선형 보간법을 이용하여 도 7에 도시된 제2 데이터의 제1 픽셀 데이터를 표현하면 다 음과 같다. 제1 데이터의 a픽셀, d픽셀, b픽셀, 및 e픽셀 기준으로 제2 데이터의 제1 픽셀 데이터는 입력데이터 ( )에 제1 가중치( )를 합성곱한 값인 W0_1*a + W1_1*b + W2_1*d + W3_1*e 로 표현할 수 있 다. 상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 그리고, 제1 데이터의 d픽셀, g픽셀, e픽셀, 및 h픽셀 기준으로 제2 데이터의 제1 픽셀 데이터는 입력데이터 ( )에 제1 가중치( )를 합성곱한 값인 W0_1*d + W1_1*e + W2_1*g + W3_1*h 로 표현할 수 있 다.상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 그리고, 제1 데이터의 b픽셀, e픽셀, c픽셀, 및 f픽셀 기준으로 제2 데이터의 제1 픽셀 데이터는 입력데이터 ( )에 제1 가중치( 를 합성곱한 값인 W0_1*b + W1_1*c + W2_1*e + W3_1*f 로 표현할 수 있다. 상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 그리고, 제1 데이터의 e픽셀, h픽셀, f픽셀, 및 i픽셀 기준으로 제2 데이터의 제1 픽셀 데이터는 입력데이터 ( )에 제1 가중치( 합성곱한 값인 W0_1*e + W1_1*f + W2_1*h + W3_1*i 로 표현할 수 있다. 상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 여기서, W0_1=w2/(w1+w2) * h2/(h1+h2) 일 수 있고, W1_1= w1/(w1+w2) * h2/(h1+h2) 일 수 있고, W2_1= w2/(w1+w2) * h1/(h1+h2) 일 수 있고, W3_1=w1/(w1+w2) * h1/(h1+h2)일 수 있다. 예를 들어, w1=1, w2=3, h1=1, h2=3일 경우, W0_1=9/16, W1_1=3/16, W2_2=3/16, W3_2=1/16 일 수 있다. 상술한 바와 같이, 제1 데이터에서 2x2로 배치된 4개의 픽셀 내부에 제2 데이터의 제1 픽셀 데이터를 생성하기 위해서는, 여러 커널이 필요한 것이 아닌 하나의 커널인 제1 가중치만이 필요하다. 따라서, 제1 가중치만 알고 있다면, 제1 데이터에서 2x2로 배치된 4개의 픽셀에 쌍선형 보간법을 적용하면 제2 데이터의 제1 픽셀 데이터(1, 2, 3, 4)를 산출할 수 있다. 즉, 제1 가중치를 재사용 할 수 있다. 상술한 바와 같이, 가중치는 9/16, 3/16, 1/16과 같은 0과 1사이의 소수일 수 있다. 다만, 제1 프로세싱 엘리먼 트(PE1)는 곱셈기(Multiplier)만을 포함하므로, 정수의 곱셈 연산만을 수행할 뿐 소수점의 곱셈 연산을 수 행할 수 없다. 이에, 소수점의 곱셈 연산을 위한 소수점 곱셈기(Floating point multiplier)를 더 구비할 수 있다. 따라서, 제1 프로세싱 엘리먼트(PE1)에서 정수의 곱셈 연산을 수행하여 출력 특징맵 데이터를 출력 한 뒤, 소수 점 곱셈기(Floating point multiplier)에서 출력 특징맵 데이터에 1/16에 해당하는 소수인 0.00625을 곱셈 연 산하여, 최종 출력 특징맵 데이터를 생성할 수 있다. 도 5에서 설명한 쌍선형 보간법을 이용하여 도 8에 도시된 제2 데이터의 제2 픽셀 데이터를 표현하면 다음과 같 다. 제1 데이터의 a픽셀, d픽셀, b픽셀, 및 e픽셀 기준으로 제2 데이터의 제2 픽셀 데이터는 입력데이터 ( )에 제2 가중치( )를 합성곱한 값인 W0_2*a + W1_2*b + W2_2*d + W3_2*e 로 표현할 수 있 다. 상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 그리고, 제1 데이터의 d픽셀, g픽셀, e픽셀, 및 h픽셀 기준으로 제2 데이터의 제2 픽셀 데이터는 입력데이터 ( )에 제2 가중치( )를 합성곱한 값인 W0_2*d + W1_2*e + W2_2*g + W3_2*h 로 표현할 수 있 다. 상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 그리고, 제1 데이터의 b픽셀, e픽셀, c픽셀, 및 f픽셀 기준으로 제2 데이터의 제2 픽셀 데이터는 입력데이터 ( )에 제2 가중치( )를 합성곱한 값인 W0_2*b + W1_2*c + W2_2*e + W3_2*f 로 표현할 수 있 다.상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 그리고, 제1 데이터의 e픽셀, h픽셀, f픽셀, 및 i픽셀 기준으로 제2 데이터의 제2 픽셀 데이터는 입력데이터 ( )에 제2 가중치( )를 합성곱한 값인 W0_2*e + W1_2*f + W2_2*g + W3_2*i 로 표현할 수 있 다. 상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 여기서, W0_2=w1/(w1+w2) * h2/(h1+h2) 일 수 있고, W1_2= w2/(w1+w2) * h2/(h1+h2) 일 수 있고, W2_2= w1/(w1+w2) * h1/(h1+h2) 일 수 있고, W3_2=w2/(w1+w2) * h1/(h1+h2)일 수 있다. 예를 들어, w1=1, w2=3, h1=1, h2=3일 경우, W0_2=3/16, W1_2=1/16, W2_2=9/16, W2_2=3/16 일 수 있다. 상술한 바와 같이, 제1 데이터에서 2x2로 배치된 4개의 픽셀 내부에 제2 데이터의 제2 픽셀 데이터를 생성하기 위해서는, 여러 커널이 필요한 것이 아닌 하나의 커널인 제2 가중치만이 필요하다. 따라서, 제2 가중치만 알고 있다면, 제1 데이터에서 2x2로 배치된 4개의 픽셀에 쌍선형 보간법을 적용하면 제2 데이터의 제2 픽셀 데이터(5,6 ,7, 8)를 산출할 수 있다. 즉, 제2 가중치를 재사용 할 수 있다. 도 5에서 설명한 쌍선형 보간법을 이용하여 도 9에 도시된 제2 데이터의 제3 픽셀 데이터를 표현하면 다음과 같 다. 제1 데이터의 a픽셀, d픽셀, b픽셀, 및 e픽셀 기준으로 제2 데이터의 제3 픽셀 데이터는 입력데이터 ( )에 제3 가중치( )를 합성곱한 값인 W0_3*a + W1_3*b+ W2_3*d + W3_3*e 로 표현할 수 있다. 상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 그리고, 제1 데이터의 d픽셀, g픽셀, e픽셀, 및 h픽셀 기준으로 제2 데이터의 제3 픽셀 데이터는 입력데이 터( )에 제3 가중치( )를 합성곱한 값인 W0_3*d + W1_3*e + W2_3*g + W3_3*h 로 표현할 수 있다. 상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 그리고, 제1 데이터의 b픽셀, e픽셀, c픽셀, 및 f픽셀 기준으로 제2 데이터의 제3 픽셀 데이터는 입력데이 터( )에 제3 가중치( )를 합성곱한 값인 W0_3*b + W1_3*c + W2_3*e + W3_3*f 로 표현할 수 있다. 상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 그리고, 제1 데이터의 e픽셀, h픽셀, f픽셀, 및 i픽셀 기준으로 제2 데이터의 제3 픽셀 데이터는 입력데이 터( )에 제3 가중치( )를 합성곱한 값인 W0_3*e + W1_3*f + W2_3*h + W3_3*i 로 표현할 수 있다. 상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 여기서, W0_3=w2/(w1+w2) * h1/(h1+h2) 일 수 있고, W1_3= w1/(w1+w2) * h1/(h1+h2) 일 수 있고, W2_3= w2/(w1+w2) * h2/(h1+h2) 일 수 있고, W3_3=w1/(w1+w2) * h2/(h1+h2)일 수 있다. 예를 들어, w1=1, w2=3, h1=1, h2=3일 경우, W0_3=3/16, W1_3=1/16, W2_4=9/16, W3_4=3/16 일 수 있다. 상술한 바와 같이, 제1 데이터에서 2x2로 배치된 4개의 픽셀 내부에 제2 데이터의 제3 픽셀 데이터를 생성하기 위해서는, 여러 커널이 필요한 것이 아닌 하나의 커널인 제3 가중치만이 필요하다. 따라서, 제3 가중치만 알고 있다면, 제1 데이터에서 2x2로 배치된 4개의 픽셀에 쌍선형 보간법을 적용하면 제2 데이터의 제3 픽셀 데이터(9, 10, 11, 12)를 산출할 수 있다. 즉, 제3 가중치를 재사용 할 수 있다. 도 5에서 설명한 쌍선형 보간법을 이용하여 도 10에 도시된 제2 데이터의 제4 픽셀 데이터(13, 14, 15, 16)를 표현하면 다음과 같다. 제1 데이터의 a픽셀, d픽셀, b픽셀, 및 e픽셀 기준으로 제2 데이터의 제4 픽셀 데이터는 입력데이터 ( )에 제4 가중치( )를 합성곱한 값인 W0_4*a + W1_4*b + W2_4*d + W3_4*e 로 표현할 수 있 다. 상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 그리고, 제1 데이터의 d픽셀, g픽셀, e픽셀, 및 h픽셀 기준으로 제2 데이터의 제4 픽셀 데이터는 입력데이 터( )에 제4 가중치( )를 합성곱한 값인 W0_4*d + W1_4*e + W2_4*g + W3_4*h 로 표현할 수 있다. 상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 그리고, 제1 데이터의 b픽셀, e픽셀, c픽셀, 및 f픽셀 기준으로 제2 데이터의 제4 픽셀 데이터는 입력데이 터( )에 제4 가중치( )를 합성곱한 값인 W0_4*b + W1_4*c + W2_4*e + W3_4*f 로 표현할 수 있다. 상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 그리고, 제1 데이터의 e픽셀, h픽셀, f픽셀, 및 i픽셀 기준으로 제2 데이터의 제4 픽셀 데이터는 입력데이 터( )에 제4 가중치( )를 합성곱한 값인 W0_4*e + W1_4*f + W2_4*h + W3_4*i 로 표현할 수 있다. 상기 합성곱 연산은 신경 프로세싱 유닛의 하나의 프로세싱 엘리먼트에서 처리될 수 있다. 여기서, W0_4=w1/(w1+w2) * h1/(h1+h2) 일 수 있고, W1_4= w2/(w1+w2) * h1/(h1+h2) 일 수 있고, W2_4= w1/(w1+w2) * h2/(h1+h2) 일 수 있고, W3_4=w2/(w1+w2) * h2/(h1+h2)일 수 있다. 예를 들어, w1=1, w2=3, h1=1, h2=3일 경우, W0_4=1/16, W1_4=3/16, W2_4=3/16, W3_4=9/16 일 수 있다. 상술한 바와 같이, 제1 데이터에서 2x2로 배치된 4개의 픽셀 내부에 제2 데이터의 제4 픽셀 데이터를 생성하기 위해서는, 여러 커널이 필요한 것이 아닌 하나의 커널인 제4 가중치만이 필요하다. 따라서, 제4 가중치만 알고 있다면, 제1 데이터에서 2x2로 배치된 4개의 픽셀에 쌍선형 보간법을 적용하면 제2 데이터의 제4 픽셀 데이터(13, 14, 15, 16)를 산출할 수 있다. 즉, 제4 가중치를 재사용 할 수 있다. 상술한 바와 같이, 제1 데이터에서 2x2로 배치된 픽셀을 기준으로, 쌍선형 보간법(Bilinear Interpolation)에 대응되는 제1 가중치 내지 제4 가중치의 합성곱을 수행하여, 제1 데이터의 4개의 픽셀 내부에 배치되는 제2 데 이터의 4개의 픽셀 데이터를 생성할 수 있다. 일 예로, 도 7 내지 도 10의 보간법 연산은 하나의 프로세싱 엘리먼트에서 순차적으로 처리될 수 있다. 다른 예로, 도 7 내지 도 10의 보간법 연산은 2개의 프로세싱 엘리먼트에서 병렬로 처리될 수 있다. 다른 예로, 도 7 내지 도 10의 보간법 연산은 3개의 프로세싱 엘리먼트에서 병렬로 처리될 수 있다. 다른 예로, 도 7 내지 도 10의 보간법 연산은 4개의 프로세싱 엘리먼트에서 병렬로 처리될 수 있다. 즉, 신경 프로세싱 유닛의 컨트롤러는 쌍선형 보간법을 처리하기 위해서 특정 프로세싱 엘리먼트의 행과 열의 위치 및 할당되는 프로세싱 엘리먼트의 개수를 결정할 수 있다.이하에서는 도 11를 참조하여 제1 데이터의 외부에 배치되는 제2 데이터를 쌍선형 보간법(Bilinear Interpolation)을 통해 생성하기 위하여, 제1 데이터를 복제하는 방법에 대하여 구체적으로 설명하도록 한다. 상술한 제2 데이터는 출력(output)을 의미한다. 도 11은 본 개시에 적용될 수 있는 제1 데이터를 외부에 복제하는 방법을 설명하는 개략적인 개념도이다. 도 7 내지 도 10에서 상술한 바와 같이, 쌍선형 보간법(Bilinear Interpolation)을 수행하여 생성되는 상기 제2 데이터의 복수의 픽셀은 상기 제1 데이터의 복수의 픽셀 사이에 배치될 수 있다. 즉, 도 11에서, 원형의 실선으로 표기된 제1 데이터의 복수의 픽셀(a, b, c, d, e, f, g, h, i) 내부에 배치되 는 제2 데이터의 복수의 픽셀(8, 9, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 26, 27, 28, 29)는 도 7 내지 도 10에서 상술한 바와 같이, 원형의 실선으로 표기된 제1 데이터의 복수의 픽셀(a, b, c, d, e, f, g, h, i)을 기준으로 쌍선형 보간법(Bilinear Interpolation)을 수행하여 픽셀 데이터를 산출할 수 있다. 다만, 도 11에서, 원형의 실선으로 표기된 제1 데이터의 복수의 픽셀(a, b, c, d, e, f, g, h, i) 외부에 배치 되는 제2 데이터의 복수의 픽셀(1, 2, 3, 4, 5, 6, 7, 12, 13, 18, 19, 24, 25, 31, 32, 33, 34, 35, 36)은 원 형의 실선으로 표기된 제1 데이터의 복수의 픽셀(a, b, c, d, e, f, g, h, i)만으로는 쌍선형 보간법(Bilinear Interpolation)을 적용할 수 없다. 따라서, 제1 데이터의 외부에 배치되는 상기 제2 데이터의 복수의 픽셀 데이터(1, 2, 3, 4, 5, 6, 7, 12, 13, 18, 19, 24, 25, 31, 32, 33, 34, 35, 36)를 연산하기 위하여, 상기 제1 데이터의 최외측의 복수의 픽셀 데이 터(a, b, c, d, f, g, h, i)를 상기 제2 데이터(output)의 외부로 복제할 수 있다. 즉, a 픽셀의 상측에 a 픽셀을 복제하고, a 픽셀의 좌측에 a 픽셀을 복제하고, a 픽셀의 좌상측에 a 픽셀을 복 제하여, 제2 데이터의 1 픽셀을 쌍선형 보간법(Bilinear Interpolation)을 통해 연산할 수 있다. 그리고, a 픽셀의 상측에 a 픽셀을 복제하고, d 픽셀의 상측에 d 픽셀을 복제하여, 제2 데이터의 2 픽셀 및 3픽 셀을 쌍선형 보간법(Bilinear Interpolation)을 통해 연산할 수 있다. 그리고, d 픽셀의 상측에 d 픽셀을 복제하고, g 픽셀의 상측에 g 픽셀을 복제하여, 제2 데이터의 4 픽셀 및 5픽 셀을 쌍선형 보간법(Bilinear Interpolation)을 통해 연산할 수 있다. 그리고, g 픽셀의 상측에 g 픽셀을 복제하고, g 픽셀의 우측에 g 픽셀을 복제하고, g 픽셀의 우상측에 g 픽셀을 복제하여, 제2 데이터의 6픽셀을 쌍선형 보간법(Bilinear Interpolation)을 통해 연산할 수 있다. 그리고, a 픽셀의 좌측에 a 픽셀을 복제하고, b 픽셀의 좌측에 b 픽셀을 복제하여, 제2 데이터의 7 픽셀 및 13 픽셀을 쌍선형 보간법(Bilinear Interpolation)을 통해 연산할 수 있다. 그리고, g 픽셀의 우측에 g 픽셀을 복제하고, h 픽셀의 우측에 h 픽셀을 복제하여, 제2 데이터의 12 픽셀 및 18 픽셀을 쌍선형 보간법(Bilinear Interpolation)을 통해 연산할 수 있다. 그리고, b 픽셀의 좌측에 b 픽셀을 복제하고, c 픽셀의 좌측에 c 픽셀을 복제하여, 제2 데이터의 19 픽셀 및 25 픽셀을 쌍선형 보간법(Bilinear Interpolation)을 통해 연산할 수 있다. 그리고, h 픽셀의 우측에 h 픽셀을 복제하고, i 픽셀의 우측에 i 픽셀을 복제하여, 제2 데이터의 24 픽셀 및 30 픽셀을 쌍선형 보간법(Bilinear Interpolation)을 통해 연산할 수 있다. 그리고, c 픽셀의 하측에 c 픽셀을 복제하고, c 픽셀의 좌측에 c 픽셀을 복제하고, c 픽셀의 좌하측에 c 픽셀을 복제하여, 제2 데이터의 31 픽셀을 쌍선형 보간법(Bilinear Interpolation)을 통해 연산할 수 있다. 그리고, c 픽셀의 하측에 c 픽셀을 복제하고, f 픽셀의 하측에 f 픽셀을 복제하여, 제2 데이터의 32 픽셀 및 33 픽셀을 쌍선형 보간법(Bilinear Interpolation)을 통해 연산할 수 있다. 그리고, f 픽셀의 하측에 f 픽셀을 복제하고, i 픽셀의 하측에 i 픽셀을 복제하여, 제2 데이터의 34 픽셀 및 35 픽셀을 쌍선형 보간법(Bilinecr Interpolction)을 통해 연산할 수 있다. 그리고, i 픽셀의 하측에 i 픽셀을 복제하고, i 픽셀의 우측에 i 픽셀을 복제하고, i 픽셀의 우하측에 i 픽셀을 복제하여, 제2 데이터의 36픽셀을 쌍선형 보간법(Bilinear Interpolation)을 통해 연산할 수 있다. 일 예로, 도 11의 보간법 연산은 하나의 프로세싱 엘리먼트에서 순차적으로 처리될 수 있다. 다른 예로, 도 11의 보간법 연산은 2개의 프로세싱 엘리먼트에서 병렬로 처리될 수 있다. 다른 예로, 도 11의 보간법 연산은 3개의 프로세싱 엘리먼트에서 병렬로 처리될 수 있다. 다른 예로, 도 11의 보간법 연산은 4개의 프로세싱 엘리먼트에서 병렬로 처리될 수 있다. 즉, 신경 프로세싱 유닛의 컨트롤러는 쌍선형 보간법을 처리하기 위해서 특정 프로세싱 엘리먼트의 행과 열의 위치 및 할당되는 프로세싱 엘리먼트의 개수를 결정할 수 있다. 이하에서는 도 11를 참조하여 제1 데이터와 쌍선형 보간법(Bilinear Interpolation)에 대응되는 커널의 합성곱 을 수행하는 하나의 프로세싱 엘리먼트를 구체적으로 설명하도록 한다. 도 12는 본 개시에 적용될 수 있는 프로세싱 엘리먼트 어레이 중 하나의 프로세싱 엘리먼트를 설명하는 개략적 인 개념도이다. 도 12를 참조하면, 제1 프로세싱 엘리먼트(PE1)는 곱셈기(Multiplier), 가산기(Adder), 누산기 (Accumulator)를 포함할 수 있다. 제1 프로세싱 엘리먼트(PE1)는 비트 양자화 유닛(Bit quantization unit)을 선택적으로 포함할 수 있다. 단, 본 개시에 따른 예시들은 이에 제한되지 않으며, 프로세싱 엘리먼트 어레이는 인공신경망의 연산 특성 을 고려하여 다양하게 변형 실시될 수도 있다. 곱셈기는 입력 받은 (N)bit 데이터와 (M)bit 데이터를 곱한다. 곱셈기의 연산 값은 (N+M)bit 데이터 로 출력될 수 있다. 여기서 N과 M은 0보다 큰 정수이다. (N)bit 데이터를 입력 받는 제1 입력부는 제1 도메인의 파라미터를 입력 받도록 구성될 수 있고, (M)bit 데이터를 입력 받는 제2 입력부는 제2 도메인의 파라미터를 입 력 받도록 구성될 수 있다. 예를 들면, 제1 입력부는 특징맵 데이터를 입력 받을 수 있다. 즉, 특징맵 데이터는 입력 영상, 음성 등의 특징 을 추출한 데이터 일 수 있기 때문에, 실시간으로 센서 등 외부에서 입력되는 데이터 일 수 있다. 프로세싱 엘 리먼트로 입력되는 특징맵 데이터는 입력 특징맵 데이터로 지칭될 수 있다. MAC 연산이 완료되어 프로세싱 엘리 먼트에서 출력되는 특징맵 데이터는 출력 특징맵 데이터로 지칭될 수 있다. 신경 프로세싱 유닛은 출력 특징맵 데이터에 배치 정규화, 풀링, 활성화 함수 등의 추가 연산을 선택적으로 더 적용할 수 있다. 본 개시에서, 입력 특징맵 데이터는 제1 데이터의 픽셀 데이터일 수 있고, 출력 특징맵 데이터는 제2 데이터의 픽셀 데이터일 수 있다. 예를 들면, 제2 입력부는 가중치, 즉, 가중치 커널을 입력 받을 수 있다. 본 개시에서, 가중치는 쌍선형 보간 법(Bilinear Interpolation) 연산에 대응되는 일 수 있다. 즉, 복수의 가중치 각각의 원소는 쌍선형 보간법 (Bilinear Interpolation)을 수행하기 위해 적어도 하나의 프로세싱 엘리먼트에 입력되어 상기 제1 데이터의 복 수의 픽셀 데이터에 곱해지는 계수일 수 있다. 곱셈기의 제1 입력부에 입력되는 파라미터는 인공신경망모델의 특징맵 데이터 혹은 제1 데이터의 픽셀 데 이터일 수 있다. 제2 입력부에 입력되는 파라미터는 인공신경망모델의 가중치 혹은 쌍선형 보간법(Bilinear Interpolation) 연산에 대응되는 가중치일 수 있다. 이처럼 컨트롤러가 프로세싱 엘리먼트의 입력 데이터의 종류를 구분하여 내부 메모리를 제어할 경우, 컨트롤러는 데이터 재사용율을 증가시킬 수 있다. 이를 바탕으로, 컨트롤러는 쌍선형 보간법을 위한 커널의 특성을 고려하여 프로세싱 엘리먼트에서 커널을 재사용 하도록 상기 프로세싱 엘리먼트를 제어하도록 구성될 수 있다. 다른 한편으로, 신경 프로세싱 유닛은 쌍선형 보간법 뿐만 아니라 인공신경망모델의 연산에 최적화된 내 부 메모리 제어를 수행하는 것도 가능하다. 예를 들면, 컨트롤러는 인공신경망모델의 각각의 레이어의 가중치 크기(Kernel size), 입력 특징맵 크기 (IFMAP size), 출력 특징맵 크기(OFMAP size)가 서로 상이한 것을 확인할 수 있다. 예를 들면, 내부 메모리의 크기가 결정될 경우, 인공신경망모델의 특정 레이어 또는 특정 레이어의 타일 (tile)의 입력 특징맵의 크기와 출력 특징맵의 크기가 내부 메모리보다 작을 경우, 컨트롤러는 특징 맵 데이터를 재사용을 하도록 신경 프로세싱 유닛을 제어할 수 있다.예를 들면, 내부 메모리의 크기가 결정될 경우, 특정 레이어 또는 특정 레이어의 타일의 가중치의 크기가 상당히 작을 경우, 컨트롤러는 특징맵 데이터를 재사용을 하도록 신경 프로세싱 유닛을 제어할 수 있다. 또는, 내부 메모리의 크기가 결정될 경우, 쌍선형 보간법(Bilinear Interpolation) 연산에 대응되는 가중 치의 크기가 작으므로, 컨트롤러는 쌍선형 보간법(Bilinear Interpolation) 연산에 대응되는 가중치를 재 사용을 하도록 신경 프로세싱 유닛을 제어할 수 있다. 또는, 쌍선형 보간법(Bilinear Interpolation)을 수행하기 위한 가중치의 용량이 작기 때문에, 내부 메모리 에 상주하거나 또는 신경 프로세싱 유닛에 포함된 별도의 비 휘발성 메모리에 저장되는 것도 가능하 다. 즉, 컨트롤러는 인공신경망모델의 상기 데이터 재사용 정보를 포함하는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 재사용될 수 있는 파라미터를 각각 인식하고, 선택적으로 파라미터를 재사용 하도록 내부 메모리 및/또는 프로세싱 엘리먼트 어레이를 제어할 수 있다. 상기 동작을 위해 서 컴파일러 또는 컨트롤러는 인공신경망모델의 임계 크기 이하의 파라미터를 분류할 수 있다. 한편, 제1 프로세싱 엘리먼트(PE1)는 곱셈기의 제1 입력부 및 제2 입력부 중 하나의 입력부에 0이 입력될 때, 연산을 하지 않더라도 연산 결과가 0인 것을 인지하고 있기 때문에, 곱셈기가 연산을 하지 않도록 동 작을 제한할 수 있다. 예를 들면, 곱셈기의 제1 입력부 및 제2 입력부 중 하나의 입력부에 0이 입력될 때, 곱셈기는 제로 스키핑(zero skipping) 방식으로 동작하도록 구성될 수 있다. 곱셈기의 제1 입력부 및 제2 입력부에 입력되는 데이터는 인공신경망모델의 각각의 특징맵 및 가중치의 양 자화에 따라서 비트 폭(bit width)이 결정될 수 있다. 예를 들면, 제1 레이어의 특징맵이 5bit로 양자화 되고 제1 레이어의 가중치가 7bit로 양자화되는 경우 제1 입력부는 5bit-width의 데이터를 입력 받도록 구성되고, 제 2 입력부는 7bit-width의 데이터를 입력 받도록 구성될 수 있다. 신경 프로세싱 유닛은 내부 메모리에 저장된 양자화된 데이터가 제1 프로세싱 엘리먼트의 입력 부들에 입력될 때 양자화된 비트 폭이 실시간으로 변환되도록 제1 프로세싱 엘리먼트를 제어할 수 있다. 즉, 레이어 마다 양자화 된 비트 폭이 다를 수 있다. 따라서 제1 프로세싱 엘리먼트는 입력되는 데이터의 비트 폭이 변환될 때마다 비트 폭 정보를 신경 프로세싱 유닛에서 제공받고, 제공된 비트 폭 정보에 기반 하여 비트 폭을 변환시켜서 입력 데이터를 생성하도록 구성될 수 있다. 가산기는 곱셈기의 연산 값과 누산기의 연산 값을 가산한다. (L)loops가 0일 경우, 누산된 데이 터가 없으므로, 가산기의 연산 값은 곱셈기의 연산 값과 동일할 수 있다. (L)loops가 1일 경우, 곱셈 기의 연산 값과 누산기의 연산 값이 가산된 값이 가산기의 연산 값일 수 있다. 누산기는 가산기의 연산 값과 곱셈기의 연산 값이 (L)loops 횟수만큼 누산되도록 가산기의 출력부에서 출력된 데이터를 임시 저장한다. 구체적으로, 가산기의 출력부에서 출력된 가산기의 연산 값은 누산기의 입력부에 입력되고, 입력된 연산 값은 누산기에 임시 저장되었다가 누산기의 출 력부에서 출력된다. 출력된 연산 값은 루프에 의해 가산기의 입력부에 입력된다. 이때, 가산기의 입 력부에는 곱셈기의 출력부에서 새롭게 출력된 연산 값이 함께 입력된다. 즉, 누산기의 연산 값과 곱 셈기의 새로운 연산 값이 가산기의 입력부에 입력되고, 이 값들이 가산기에서 가산되어 가산기 의 출력부를 통해 출력된다. 가산기의 출력부에서 출력된 데이터, 즉 가산기의 새로운 연산 값 은 누산기의 입력부에 입력되며, 이후 동작들은 상술한 동작들과 실질적으로 동일하게 루프 횟수만큼 수행 된다. 이처럼, 누산기는 곱셈기의 연산 값과 가산기의 연산 값을 루프 횟수만큼 누산하기 위해 가산기 의 출력부에서 출력된 데이터를 임시 저장하므로, 누산기의 입력부에 입력되는 데이터 및 출력부에서 출력되는 데이터는 가산기의 출력부에서 출력된 데이터와 같은 (N+M+log2(L))bit의 비트 폭을 가질 수 있 다. 여기서 L은 0보다 큰 정수이다. 누산기는 임시 메모리로 레지스터를 포함하도록 구성될 수 있다. 누산기는 누산이 종료되면, 초기화 신호(initialization reset)를 인가받아서 누산기 내부에 저장된 데이터를 0으로 초기화 할 수 있다. 단, 본 개시에 따른 예시들은 이에 제한되지 않는다. 비트 양자화 유닛은 누산기에서 출력되는 데이터의 비트 폭을 저감하도록 구성될 수 있다. 비트 양자 화 유닛은 컨트롤러에 의해서 제어될 수 있다. 양자화된 데이터의 비트 폭은 (X)bit로 출력될 수 있 다. 여기서 X는 0보다 큰 정수이다. 상술한 구성에 따르면, 제1 프로세싱 엘리먼트 어레이는 MAC 연산을 수행하도록 구성되고 MAC 연산 결과를 양자화해서 출력할 수 있다. 특히 이러한 양자화는 (L)loops가 증가할수 록 소비 전력을 더 절감할 수 있는 효과가 있다. 또한 소비 전력이 저감되면 발열도 저감할 수 있다. 특히 발열 을 저감하면 신경 프로세싱 유닛의 고온에 의한 오동작 발생 가능성을 저감할 수 있다. 비트 양자화 유닛의 출력 데이터(X)bit는 다음 레이어의 노드 데이터 또는 합성곱의 입력 데이터가 될 수 있다. 만약 인공신경망모델이 양자화되었다면, 비트 양자화 유닛은 양자화된 정보를 인공신경망모델에서 제공받도록 구성될 수 있다. 단, 이에 제한되지 않으며, 컨트롤러는 인공신경망모델을 분석하여 양자화된 정보를 추출하도록 구성될 수 있다. 따라서 비트 양자화 유닛은 양자화된 데이터 크기에 대응되도록, 출력 데이터(X)bit를 양자화 된 비트 폭으로 변환하여 출력할 수 있다. 비트 양자화 유닛의 출력 데이터(X)bit 는 양자화된 비트 폭으로 내부 메모리에 저장될 수 있다. 본 개시의 일 예시에 따른 신경 프로세싱 유닛의 제1 프로세싱 엘리먼트는 비트 양자화 유닛에 의해서 누산기에서 출력되는 (N+M+log2(L))bit의 비트 폭의 데이터를 (X)bit의 비트 폭으로 저감할 수 있 다. 이를 위해 컨트롤러는 비트 양자화 유닛을 제어하여 출력 데이터의 비트 폭을 LSB(least significant bit)에서 MSB(most significant bit)까지 소정 비트만큼 저감할 수 있다. 출력 데이터의 비트 폭이 저감되면 신경 프로세싱 유닛의 소비 전력, 연산량, 메모리 사용량이 저감될 수 있다. 하지만 비트 폭이 특정 길이 이하로 저감될 경우, 인공신경망모델의 추론 정확도가 급격히 저하될 수 있 는 문제가 발생될 수 있다. 따라서, 출력 데이터의 비트 폭 저감, 즉, 양자화 수준은 인공신경망모델의 추론 정 확도 저감 수준 대비 소비 전력, 연산량, 메모리 사용량 저감 정도를 비교하여 결정될 수 있다. 양자화 수준은 인공신경망모델의 목표 추론 정확도를 결정하고, 비트 폭을 점진적으로 저감하면서 열화를 테스트하는 방법으로 결정될 수 있다. 양자화 수준은 각각의 레이어의 연산 값마다 각각 결정될 수 있다. 상술한 제1 프로세싱 엘리먼트(PE1)에 따라 곱셈기의 (N)bit 데이터와 (M)bit 데이터의 비트 폭을 조 절하고, 비트 양자화 유닛에 의해서 연산 값(X)bit의 비트 폭을 저감함으로써, 프로세싱 엘리먼트 어레이 의 MAC 연산 속도를 향상시키면서 소비 전력을 저감할 수 있고, 인공신경망의 합성곱(convolution) 연산을 보다 더 효율적으로 할 수 있다. 이를 바탕으로 하는 신경 프로세싱 유닛의 내부 메모리는 프로세싱 엘리먼트 어레이의 MAC 연 산 특성 및 소비 전력 특성을 고려하여 구성된 메모리 시스템일 수 있다. 예를 들면, 신경 프로세싱 유닛은, 프로세싱 엘리먼트 어레이의 MAC 연산 특성 및 소비 전력 특성을 고려하여 프로세싱 엘리먼트 어레이의 연산 값의 비트 폭을 저감하도록 구성될 수 있다. 예를 들면, 신경 프로세싱 유닛은 내부 메모리의 특징맵 또는 가중치 재사용을 위해 프로세싱 엘리 먼트 어레이의 연산 값의 비트 폭을 저감하도록 구성될 수 있다. 신경 프로세싱 유닛의 내부 메모리는 신경 프로세싱 유닛의 소비 전력을 최소화하도록 구성될 수 있다. 신경 프로세싱 유닛의 내부 메모리는 작동되는 인공신경망모델의 파라미터들의 크기 및 연산 단계를 고려하여 저전력으로 메모리를 제어하도록 구성된 메모리 시스템일 수 있다. 신경 프로세싱 유닛의 내부 메모리는 인공신경망모델의 데이터 크기 및 연산 단계를 고려하여 가중 치가 저장된 특정 메모리 어드레스를 재사용하도록 구성된 저전력 메모리 시스템일 수 있다. 다시 도 4를 참조하면, 신경 프로세싱 유닛은 비선형성을 부여하기 위한 여러 가지 활성화 함수를 처리하 도록 구성된 특수 함수 유닛(Special function unit; SFU)을 포함하도록 구성될 수 있다. 특수 함수 유닛 은 복수의 로직 게이트 회로로 구성될 수 있다. 따라서, 특수 함수 유닛은 육안으로는 식별되어 구분 되기 어려울 수 있고, 동작에 의해서 식별될 수 있다. 예를 들면, 활성화 함수는 입력값에 대한 비선형의 출력값을 도출하는 시그모이드 함수, 하이퍼볼릭 탄젠트 (tanh) 함수, ReLU함수, Leaky ReLU 함수, Maxout 함수 또는 ELU 함수 등을 포함할 수 있으나, 이에 한정되지 않는다. 모든 활성화 함수를 신경 프로세싱 유닛에서 지원하는 것은 기술적으로 어려울 수 있다. 따라서 신경 프로세싱 유닛은 조각별 선형 함수 근사화(piecewise linear function approximation) 알고리즘 및 조각별 선형 함수 처리 회로를 통해서 다양한 활성화 함수를 근사화 하는 것도 가능하다. 이러한 활성화 함수는MAC 연산 이후에 선택적으로 적용될 수 있다. 활성화 함수가 적용된 연산 값은, 활성화 맵으로 지칭될 수 있다. 한편, 특수 함수 유닛(Special function unit; SFU)은 소수점 연산을 수행하는 소수점 곱셈기(Floating point multiplier) 회로를 포함하도록 구성될 수 있다. 상술한 바와 같이, 제1 가중치 내지 제4 가중치는 9/16, 3/16, 1/16과 같은 0과 1사이의 소수일 수 있다. 다만, 제1 프로세싱 엘리먼트(PE1)는 곱셈기(Multiplier)만을 포함하므로, 정수의 곱셈 연산만을 수행할 뿐 소수 점의 곱셈 연산을 수행할 수 없다. 이에, 제1 프로세싱 엘리먼트(PE1)에서 정수의 곱셈 연산을 수행하여 출력 특징맵 데이터를 출력 한 뒤, 소수점 곱셈기(Floating point multiplier)에서 출력 특징맵 데이터에 1/16에 해당하는 소수인 0.00625을 곱셈 연산하 여, 최종 출력 특징맵 데이터를 생성할 수 있다. 부연 설명하면, 신경 프로세싱 유닛의 설계 관점에서 소수점 곱셈기 회로는 나눗셈 회로보다 상대적으로 로직 게이트 개수가 적을 수 있다. 따라서 소수점 곱셉기를 프로세싱 엘리먼트와 별도로 구비할 경우 신경 프로 세싱 유닛의 총 로직 게이트 개수를 상당히 저감할 수 있다. 또한 프로세싱 엘리먼트는 효율적으로 쌍선 형 보간법의 정수 연산 부분만 처리하고 별도의 소수점 곱셈기는 쌍선형 보간법의 소수점 곱셈을 처리할 수 있 다. 따라서, 신경 프로세싱 유닛의 프로세싱 엘리먼트의 개수가 증가할수록 쌍선형 보간법을 위한 소수점 곱 셈기를 별도로 구비하는 것이 보다 더 효과적일 수 있다. 상술한 구성에 따르면, 신경 프로세싱 유닛의 크기를 저감할 수 있고 소비 전력도 저감할 수 있다. 한편 도 4를 참조하면, 내부 메모리는 휘발성 메모리로 구성될 수 있다. 휘발성 메모리는 전원이 공급된 경우에만 데이터를 저장하고, 전원 공급이 차단되면 저장된 데이터가 소멸되는 메모리다. 휘발성 메모리는 정적 랜덤 액세스 메모리 (Static Random Access Memory; SRAM), 동적 랜덤 액세스 메모리 (Dynamic Random Access Memory; DRAM) 등을 포함할 수 있다. 내부 메모리는 바람직하게는 SRAM일 수 있으나, 이에 한정되지 않는 다. 내부 메모리의 적어도 일부는 비휘발성 메모리로 구성될 수 있다. 비휘발성 메모리는 전원이 공급되지 않 는 경우에도 데이터를 저장하는 메모리다. 비휘발성 메모리는 롬(Read Only Memory; ROM) 등을 포함할 수 있다. 학습이 완료된 가중치는 비휘발성 메모리에 저장되는 것도 가능하다. 즉, 가중치 저장부 및/또는 휘발성 메모리 또는 비휘발성 메모리를 포함할 수 있다. 내부 메모리는 가중치 저장부 및 특징맵 저장부를 포함한다. 가중치 저장부는 인공신경망 모델의 가중치의 적어도 일부 혹은 쌍선형 보간법(Bilinear Interpolation) 연산에 대응되는 가중치를 저장하고, 특징맵 저장부는 인공신경망모델의 노드 데이터 또는 특징맵의 적어도 일부를 저장한다. 내부 메모리는 복수의 로직 게이트 회로로 구성될 수 있다. 따라서, 내부 메모리는 육안으로는 식별 되어 구분되기 어려울 수 있고, 동작에 의해서 식별될 수 있다. 가중치 저장부는 복수의 로직 게이트 회로 로 구성될 수 있다. 따라서, 가중치 저장부는 육안으로는 식별되어 구분되기 어려울 수 있고, 동작에 의해 서 식별될 수 있다. 특징맵 저장부는 복수의 로직 게이트 회로로 구성될 수 있다. 따라서, 특징맵 저장부 는 육안으로는 식별되어 구분되기 어려울 수 있고, 동작에 의해서 식별될 수 있다. 인공신경망모델이 포함할 수 있는 인공신경망의 데이터는 각각의 레이어의 노드 데이터 또는 특징맵, 및 각각의 레이어의 노드를 연결하는 연결망 각각의 가중치를 포함할 수 있다. 인공신경망의 데이터 또는 파라미터들 중 적어도 일부는 컨트롤러 내부에 제공되는 메모리 또는 내부 메모리에 저장될 수 있다. 인공신경망의 파라미터들 중 특징맵은 배치 채널로 구성될 수 있다. 여기서 복수의 배치 채널들은 예를 들어 실 질적으로 동일한 기간(예를 들어 10 또는 100 ms 이내)에 복수의 이미지 센서들 또는 카메라들을 통해 촬영된 제1 데이터일 수 있다. 한편, 컨트롤러는 인공신경망모델의 가중치의 크기, 특징맵의 크기, 및 가중치와 특징맵의 계산 순서 등을 고려하여 프로세싱 엘리먼트 어레이 및 내부 메모리를 제어하도록 구성될 수 있다. 컨트롤러는 프로세싱 엘리먼트 어레이 및 내부 메모리를 제어할 수 있다. 예를 들어, 컨트롤러는 제1 입력 데이터에 해당하는 인공신경망모델의 가중치 혹은 쌍선형 보간법 (Bilinear Interpolation) 연산에 대응되는 가중치를 내부 메모리의 가중치 저장부에 로드(load)하고, 제2 입력 데이터에 해당하는 인공신경망모델의 특징맵 데이터 혹은 제1 데이터의 픽셀 데이터를 내부 메모 리의 특징맵 저장부에 로드할 수 있다. 컨트롤러는 프로세싱 엘리먼트 어레이를 구성하는 복수의 PE 각각에서 제1 합성곱 연산을 통해 가중치 및 특징맵 데이터를 계산하도록 프로세싱 엘리먼트 어레이 를 제어할 수 있다. 내부 메모리가 가중치 저장부 및 특징맵 저장부를 구분하여 포함하는 것으로 도시되었으나, 이 는 예시적일 뿐이고, 메모리 주소 등을 통해 논리적으로 구분되거나 또는 가변적으로 구분되거나 또는 구분되지 않을 수도 있다. 부연 설명하면, 가중치 저장부의 크기와 특징맵 저장부의 크기는 각 레이어별, 각 타일별 상이할 수 있다. 위에 설명된 예시에서는 인공신경망의 파라미터들이 신경 프로세싱 유닛의 내부 메모리에 저장되는 것으로 설명되었지만, 이에 제한되지 않고 온칩 메모리 또는 메인 메모리에 저장될 수도 있다. 이하에서는 신경 프로세싱 유닛이 뎁스와이즈 합성곱을 통해 쌍선형 보간법(Bilinear Interpolation) 연 산하는 프로세싱 엘리먼트 어레이를 구체적으로 설명한다. 도 13은 본 개시의 일 예시에 따른 프로세싱 엘리먼트 어레이 중 하나의 프로세싱 엘리먼트를 설명하는 구성도 이다. 제시된 일 예시에서 프로세싱 엘리먼트의 동작을 구체적으로 설명하기 위해 도 4를 통해서 설명된 구성 요소(즉, 가중치 저장부 및 특징맵 저장부)를 이용하도록 한다. 도 13를 참조하면, 복수의 프로세싱 엘리먼트 중 하나인 제1 프로세싱 엘리먼트(PE_00)는 제1 프로세싱 엘리먼 트(PE_00)에 대응하여 레지스터가 구비된다. 레지스터는 레지스터 파일로 지칭될 수 있다. 레지스터 는 도 12에 도시된 누산기의 누산 값을 저장하는 임시 메모리에 대응될 수 있다. 레지스터는 복 수의 로직 게이트 회로로 구성될 수 있다. 따라서, 레지스터은 육안으로는 식별되어 구분되기 어려울 수 있고, 동작에 의해서 식별될 수 있다. 제1 프로세싱 엘리먼트(PE_00)는 가중치 저장부와 연결되어 가중치가 전달되는 신호 라인(W_in_0)과 연결 되고, 특징맵 저장부와 연결되어 특징맵 데이터가 전달되는 신호 라인(F_in_0)과 연결될 수 있다. 상술한 가중치는 인공신경망모델의 가중치 혹은 쌍선형 보간법(Bilinear Interpolation) 연산에 대응되는 가중 치일 수 있다. 그리고, 상술한 특징맵 데이터는 인공신경망모델의 특징맵 데이터 혹은 제1 데이터의 픽셀 데이 터일 수 있다. 제1 프로세싱 엘리먼트(PE_00)는 가중치 저장부로부터 전달된 가중치 및 특징맵 저장부로부터 전달된 특징맵 데이터에 대한 연산(예: MAC 연산)을 수행하고, 연산값을 레지스터에 저장할 수 있다. 여기서, 연 산값은 특징맵 데이터에 가중치가 MAC 연산된 결과를 나타내는 특징맵 데이터일 수 있다. 예를 들면, 제1 프로 세싱 엘리먼트(PE_00)가 2 x 2 행렬의 가중치 커널로 합성곱 연산을 하려면 4 클럭이 소요될 수 있다. 4 클럭 동안 누산된 값은 레지스터에 저장될 수 있다. 제1 프로세싱 엘리먼트(PE_00)에서 연산이 완료되면 연산값 을 초기화하는 리셋 신호(Reset_00)가 수신되고, 이로 인해 제1 프로세싱 엘리먼트(PE_00)의 연산값이 초기화될 수 있다. 제1 프로세싱 엘리먼트(PE_00)는 가동 여부에 따라서 인에이블 신호(Enable, En0)가 인가되어 신경 프로세싱 유 닛의 소비 전력을 저감하도록 구성될 수 있다. 또한 각각의 프로세싱 엘리먼트의 가동 여부에 따라서 신 경 프로세싱 유닛의 프로세싱 엘리먼트 어레이의 가동율이 결정될 수 있다. 각각의 프로세싱 엘리먼트의 가동여부는 컨트롤러에 의해서 제어될 수 있다. 컨트롤러는 각각의 프로 세싱 엘리먼트에 대응되는 인에이블 신호를 생성하도록 구성될 수 있다. 레지스터는 도 4를 참조하여 앞서 설명한 레지스터 파일을 의미할 수 있다. 연산값을 특징맵 저장부 로 출력하기 위한 출력 명령 신호가 수신되면 레지스터는 특징맵 저장부와 연결된 출력 신호 라 인(F_out_00)을 통해 연산값을 출력하고, 출력된 연산값은 특징맵 저장부에 저장될 수 있다. 이러한 레지 스터는 선택적으로 구비될 수 있다. 레지스터가 구비되지 않은 경우, 제1 프로세싱 엘리먼트(PE_00)의 연산값은 특징맵 저장부로 바로 전 달되어 저장되도록 구성될 수 있다. 제1 프로세싱 엘리먼트(PE_00)는 MAC 연산이 완료되면 출력 데이터가 전달되는 신호 라인(F_out_00)과 연결될 수 있다. 상기 신호 라인(F_out_00)은 내부 메모리와 연결되거나 또는 소수점 곱셈기(미도시) 또는 별도의 벡터 프로세싱 유닛(미도시) 또는 활성화 함수 연산 유닛(미도시)와 연결되도록 구성될 수 있다. 부연 설명하면, 본 개시의 일 예시들에 따른 프로세싱 엘리먼트는 입력 받은 가중치를 다른 프로세싱 엘리먼트 에 전달하도록 구성될 수 있다. 따라서 전달되는 가중치는 프로세싱 엘리먼트 어레이 내부에서 재사용될 수 있 기 때문에, 상기 가중치를 내부 메모리, 온칩 메모리 및/또는 메인 메모리에서 다시 로드 하 는 횟수를 저감할 수 있다. 제1 프로세싱 엘리먼트(PE_00)에는 레지스터 이외에 제1 프로세싱 엘리먼트(PE_00)에 대응하여 딜레이 버 퍼가 더 구비될 수 있다. 딜레이 버퍼는 복수의 로직 게이트 회로로 구성될 수 있다. 따라서, 딜레이 버퍼 는 육안으로는 식별 되어 구분되기 어려울 수 있고, 동작에 의해서 식별될 수 있다. 딜레이 버퍼는 특정 클럭 기간동안 입력 신호를 딜레이 할 수 있다. 예를 들면 딜레이 버퍼가 1클럭 딜레이 된다면 Z-1로 표기될 수 있다. 예를 들면 딜레이 버퍼가 2클럭 딜레이 된다면 Z-2로 표기될 수 있다. 예를 들면 딜레이 버퍼가 4클럭 딜레이 된다면 Z-4로 표기될 수 있다. 예를 들면 딜레이 버퍼가 6클럭 딜레이 된다면 Z-6로 표기될 수 있다. 다만, 도 13에서는 특정 클럭 기간동안 입력 신호를 딜레이하는 딜레이 버퍼를 표현하기 위하여, Z-k로 표 기하였다. 딜레이 버퍼는 가중치 저장부로부터 전달된 가중치(W_in_0)를 기 설정된 클럭만큼 임시로 저장한 후 출력한다. 딜레이 버퍼에서 출력된 가중치(W_in_0)는 다음행의 프로세싱 엘리먼트에 입력된다. 딜레이 버 퍼에서 출력된 가중치(W_in_0)는 기 설정된 클럭만큼 딜레이된 가중치일 수 있다. 도 13에서는 딜레이 버퍼가 한 개로 구성되는 것으로 도시하였으나, 이에 제한되지 않고, 딜레이 버퍼 는 직렬 연결된 복수개의 딜레이 버퍼로 구성될 수 있다. 예를 들면 2개의 직렬 연결된 딜레이 버퍼는 2클 럭을 딜레이 시킬 수 있다. 예를 들면 3개의 직렬 연결된 딜레이 버퍼는 3클럭을 딜레이 시킬 수 있다. 예를 들어, 딜레이 버퍼가 직렬 연결된 제1 딜레이 버퍼 및 제2 딜레이 버퍼로 구성될 경우, 딜레이 버퍼 는 데이터는 제1 딜레이 버퍼에 의해 딜레이된 클럭 수 및 제2 딜레이 버퍼에 의해 딜레이된 클럽 수를 합 한 클럭 수 만큼 딜레이 될 수 있다. 본 개시의 일 예시들에 따른 프로세싱 엘리먼트 어레이의 딜레이 버퍼에 따르면, 프로세싱 엘리먼트 어레이 중 적어도 일부 열에 해당하는 프로세싱 엘리먼트가 딜레이 버퍼를 활용하여 뎁스와이즈 합성곱 연산을 수행 하도록 구성될 수 있다. 즉, 딜레이 버퍼에 의해서, 행렬 형태의 가중치가 행렬 형태의 특징맵 데이터를 기 설정된 간격만큼 슬라 이딩하는 방식으로 특정 프로세싱 엘리먼트에서 합성곱 연산되면, 가중치의 일부가 인접한 다른 프로세싱 엘리 먼트의 합성곱 연산을 위해 재사용될 수 있다. 이처럼 재사용되는 가중치의 일부를 가중치 저장부에서 프로세싱 엘리먼트 어레이로 반복하여 로드하 지 않고, 딜레이 버퍼를 이용하여 재사용함으로써, 뎁스와이즈 합성곱 연산 성능을 향상시킬 수 있다. 한편, 프로세싱 엘리먼트 어레이에서 제2 모드에서 동작되는 프로세싱 엘리먼트들은 인에이블 신호(En0)에 의해 활성화되고, 동작되지 않은 나머지 프로세싱 엘리먼트는 비활성화됨으로써, 신경 프로세싱 유닛의 전력 소모를 저감시킬 수 있다. 이하에서는 이러한 프로세싱 엘리먼트가 행렬 형태로 구성된 프로세싱 엘리먼트 어레이 및 이의 동작 방식을 도 14 내지 도 27를 참조하여 설명하도록 한다. 도 14는 본 개시의 일 예시에 따른 프로세싱 엘리먼트 어레이에 입력되는 입력 데이터 및 출력 데이터를 나타내 는 도면이다.도 14를 참조하면, 제1 입력 데이터인 쌍선형 보간법(Bilinear Interpolation) 연산에 사용되는 가중치는 2x2의 크기를 가질 수 있다. 즉, 쌍선형 보간법(Bilinear Interpolation) 연산은 2차원 평면에 대해서 선형 보간법 (Linear Interpolation)이 두번 진행되는 연산이므로, 쌍선형 보간법(Bilinear Interpolation) 연산에 사용되 는 가중치는 2x2의 크기로 고정될 수 있다. 예를 들어, 쌍선형 보간법(Bilinear Interpolation) 연산에 사용되 는 가중치의 각각의 값은 w0, w1, w2, w3로 표현될 수 있다. 제2 입력 데이터인 제1 데이터의 픽셀 데이터는 4x4의 크기를 가질 수 있다. 예를 들어, 제1 데이터의 픽셀 데 이터는 i00, i01, i02, i03, i10, i11, i12, i13, i20, i21, i22, i23, i30, i32, i33으로 표현할 수 있다. 그 러나, 제2 입력 데이터인 제1 데이터의 픽셀 데이터의 크기는 이에 한정되지 않고 다양한 크기로 변경될 수 있 다. 그리고, 출력 데이터인 해상도가 확장된 제2 데이터의 픽셀 데이터는 8x8의 크기를 가질 수 있다. 예를 들어 제 2 데이터의 픽셀 데이터는 o00, o01, o02, o03, o04, o05, o06, o07, …, o70, o71, o72, o73, o74, o75, o76, o77으로 표현할 수 있다. 그러나, 출력 데이터인 해상도가 확장된 제2 데이터의 픽셀 데이터는 이에 한정되지 않고 다양한 크기로 변경될 수 있다. 도 15는 일 예시에 따른 프로세싱 엘리먼트 어레이에 입력되는 입력 데이터와 출력 데이터의 배치 관계를 나타 내는 도면이다. 도 15를 참조하면, 2x2형태로 배치된 4개의 제1 데이터의 픽셀 데이터의 사이에는 2x2형태로 배치된 4개의 제2 데이터의 픽셀 데이터가 배치될 수 있다. 예를 들어, i00, i01, i10, i11 사이에는 o11, o12, o21, o22가 배치될 수 있고, i01, i02, i11, i12 사이에는 o13, o14, o23, o24가 배치될 수 있고, i02, i03, i13, i13 사이에는 o15, o16, o25, o26이 배치될 수 있다. 그리고, i10, i11, i20, i21 사이에는 o31, o32, o41, o42가 배치될 수 있고, i11, i12, i21, i22 사이에는 o33, o34, o43, o44가 배치될 수 있고, i12, i13, i23, i23 사이에는 o35, o36, o45, o46이 배치될 수 있다. 그리고, i20, i21, i30, i31 사이에는 o51, o52, o61, o62가 배치될 수 있고, i21, i22, i31, i32 사이에는 o53, o54, o63, o64가 배치될 수 있고, i22, i23, i33, i33 사이에는 o55, o56, o65, o66이 배치될 수 있다. 도 16은 본 개시의 일 예시에 따른 프로세싱 엘리먼트 어레이의 구조를 나타내는 개략적인 구성도이다. 도 16을 참조하면, 프로세싱 엘리먼트 어레이는 복수의 PE 행 및 복수의 PE 열로 구성된 복수의 PE를 포함 할 수 있다. 복수의 프로세싱 엘리먼트는 하나의 프로세싱 엘리먼트보다 보다 빠르게 쌍선형 보간법 연산을 처리할 수 있다. 따라서 복수의 프로세싱 엘리먼트를 쌍선형 보간법 연산에 활용하도록 구성된 신경 프로세싱 유닛은 쌍선 형 보간법 연산을 빠르게 처리할 수 있다. 부연 설명하면, 제1 PE 행은 첫번째 행에 배치된 복수의 프로세싱 엘리먼트들(PE_00, PE_01, PE_02, …, PE_0n- 1)을 지칭할 수 있다. 제2 PE 행은 두번째 행에 배치된 복수의 프로세싱 엘리먼트들(PE_10, PE_11, PE_12, …, PE_1n-1)을 지칭할 수 있다. 부연 설명하면 제1 PE 열은 첫번째 열에 배치된 복수의 프로세싱 엘리먼트들(PE_00, PE_10, … )을 지칭할 수 있다. 제2 PE 열은 두번째 복수의 프로세싱 엘리먼트들(PE_01, PE_11, …)을 지칭할 수 있다. 제3 PE 열은 세번 째 열에 배치된 복수의 프로세싱 엘리먼트들(PE_02, PE_12, … )을 지칭할 수 있다. 제n-1 PE 열은 n번째 복수 의 프로세싱 엘리먼트들(PE_0n-1, PE_1n-1, …)을 지칭할 수 있다. 도 13 및 도 16을 참조하면, 제1 PE 열(PE_00, PE_01, PE_02, …, PE_0n-1)은 가중치가 전달되는 신호 라인 (W_in)을 통해 가중치 저장부와 연결될 수 있다. 가중치 저장부로부터 출력된 가중치는 각 가중치가 전달되는 신호 라인(W_in)의 브랜치를 통해 제1 PE 열(PE_00, PE_01, PE_02, …, PE_0n-1)으로 입력된다. 보다 구체적으로, 제1 PE 열(PE_00, PE_01, PE_02, …, PE_0n-1) 각각에 쌍선형 보간법(Bilinear Interpolation) 연 산에 사용되는 가중치는 브로드캐스팅(broadcasting) 될 수 있다. 즉, 제1 PE 열(PE_00, PE_01, PE_02, …, PE_0n-1) 각각에는 동일한 타이밍에 동일한 가중치가 입력될 수 있다. 한편, 복수의 딜레이 버퍼(141, 142) 또한 가중치가 전달되는 신호 라인(W_in)을 통해 가중치 저장부와 연 결될 수 있다. 가중치 저장부로부터 출력된 가중치는 각 가중치가 전달되는 신호 라인(W_in)의 브랜치를 통해 복수의 딜레이 버퍼(141, 142)으로 입력된다. 즉, 복수의 딜레이 버퍼(141, 142)에 쌍선형 보간법(Bilinear Interpolation) 연산에 사용되는 가중치는 브로드캐스팅(broadcasting) 될 수 있다. 보다 구체적으로, 복수의 딜레이 버퍼(141, 142)가 직렬 연결된 제1 딜레이 버퍼 및 제2 딜레이 버퍼(14 2)로 구성될 수 있다. 제1 딜레이 버퍼는 한 클럭의 딜레이 특성(Z-1)을 가질 수 있다. 즉, 하나의 클럭을 딜레이 하는 제1 딜레이 버퍼의 k 값은 -1일 수 있다. 제2 딜레이 버퍼는 한 클럭의 딜레이 특성(Z- 1)을 가질 수 있다. 즉, 하나의 클럭을 딜레이 하는 제2 딜레이 버퍼의 k 값은 -1일 수 있다. 이러한 경우, 제1 딜레이 버퍼는 가중치가 전달되는 신호 라인(W_in_0)을 통해 가중치 저장부와 연결 될 수 있다. 그리고, 제2 딜레이 버퍼는 제2 PE 열에 연결될 수 있다. 따라서, 쌍선형 보간법(Bilinear Interpolation) 연산에 사용되는 가중치는 제1 딜레이 버퍼에 입력된다. 그리고, 제1 딜레이 버퍼는 입력된 쌍선형 보간법(Bilinear Interpolation) 연산에 사용되는 가중치를 1클 럭만큼 지연시켜, 제2 딜레이 버퍼로 출력할 수 있다. 그리고, 제2 딜레이 버퍼는 입력된 쌍선형 보 간법(Bilinear Interpolation) 연산에 사용되는 가중치를 1클럭만큼 추가로 지연시켜, 제2 PE 열에 출력할 수 있다. 결과적으로, 제2 PE 열에는 제1 딜레이 버퍼 및 제2 딜레이 버퍼에 의해 2클럭 만큼 딜레이된 가중치가 입력될 수 있다. 다른 예로, 복수의 딜레이 버퍼(141, 142)는 2클럭을 딜레이 하는 하나의 딜레이 버 퍼일 수 있다. 이러한 경우 딜레이 버퍼의 k 값은 -2일 수 있다. 즉, 딜레이 버퍼(Z-k)를 통해 딜레이되며 전달된 가중치는 각 PE 열 방향으로 딜레이 브로드캐스팅(delayed broadcasting)될 수 있다. 따라서, 가중치 저장부에서 전달된 가중치는 딜레이 브로드캐스팅(delayed broadcasting)에 의해 딜레이된 가중치가 제공되는 각 PE에서 재사용될 수 있다. 이를 통해 가중치가 프로세싱 엘리먼트 어레이 내에서 재사용되어 연산을 위해 사용되는 리소스 소모 및 메모리 사용량을 최소화시킬 수 있다. 여기서 가중치는 인공신경망모델의 추론연산을 위한 가중치 또는 쌍선형 보간법용 가중치일 수 있다. 한편, 복수의 PE 행 각각은 특징맵 데이터가 전달되는 신호 라인(F_in)을 통해 특징맵 저장부와 연결될 수 있다. 특징맵 저장부로부터 출력된 특징맵 데이터는 각 F_in 신호 라인을 통해 복수의 PE 행 각각으로 입 력된다. 예를 들어, n채널의 특징맵 데이터는 제1 PE 행 및 제2 PE행 각각으로 유니캐스팅(unicasting) 또는 브 로드캐스팅(broadcasting) 될 수 있다. F_in 신호 라인은 n개의 채널로 구성된 버스일 수 있다. F_in 신호 라인은 1개의 PE 행에 대응되는 개별 신호 라인들을 포함하는 버스 라인일 수 있다. 예를 들어, 제1 PE 행(PE_00, PE_01, …)이 64개의 프로세싱 엘리먼트 를 가지도록 구성되면, F_in 신호 라인은 64개의 라인으로 구성된 버스 라인일 수 있다. 그리고, F_in 신호 라 인은 PE 행의 각각의 프로세싱 엘리먼트에 개별 특징맵 데이터를 유니캐스트하거나 또는 동일한 특징맵 데이터 를 브로드캐스트 하도록 구성될 수 있다. 이처럼 각 PE에 특징맵 데이터 및 가중치가 입력되면 각 PE에서 입력된 특징맵 데이터 및 가중치에 대한 MAC 연 산이 매 클럭마다 수행된다. MAC 연산을 통해 산출된 연산 결과 데이터(즉, 특징맵 데이터)가 각 PE로부터 출력 되어 특징맵 저장부에 저장될 수 있다. 부연 설명하면, 도 16에서는 생략되었으나, 도 13를 다시 참조하면, 각각의 PE는 MAC 연산 값이 저장된 레지스 터에서 MAC 연산 값을 출력하는 F_out 신호 라인을 각각 포함하도록 구성될 수 있다. 단, 이에 제한되지 않으며, F_out 신호 라인은 소수점 곱셈기 회로, 내부 메모리 또는 추가적인 다른 연산 유닛과 연결되도록 구성될 수 있다. 이하에서는 도 17 내지 도 27을 참조하여 프로세싱 엘리먼트 어레이가 뎁스와이즈 합성곱 연산을 수행하는 방식 을 설명한다. 도 17 내지 도 27은 본 개시의 일 예시에 따른 프로세싱 엘리먼트 어레이가 복수의 클럭 동안 동작하는 방식을 설명하기 위만 도면이다. 도 17 내지 도 27에서 복수의 클럭 동안 제1 PE열이 n개 채널의 입력 데이터 중 하나의 채널의 입력 데이터에 대하여 합성곱을 수행하는 과정을 도시하였다. 도 17을 참조하면, 제1 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w0와 제1 데이터의 픽셀 데이 터 i00을 입력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w0와 제1 데이터의 픽셀 데이터 i00의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트(PE_00)에 연결된 레지스터에는 w0*i00의 값이 저장된다. 한편, 도 17을 참조하면, 제1 클럭 타임 동안, 제1 딜레이 버퍼에도 가중치 w0이 입력된다. 그리고, 제1 딜레이 버퍼는 제1 클럭 타임동안 가중치 w0을 저장하여 이를 1클럭만큼 딜레이시킨다. 그리고, 도 18을 참조하면, 제2 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w1와 제1 데이터의 픽 셀 데이터 i10을 입력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w1와 제1 데이터의 픽셀 데이터 i10의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트(PE_00)에 연결된 레 지스터에는 w0*i00+w1*i10의 값이 저장된다. 즉, w0*i00의 값에 w1*i10의 값을 누산한다. 한편, 도 18을 참조하면, 제2 클럭 타임 동안, 제1 딜레이 버퍼에도 가중치 w1이 입력된다. 그리고, 제1 딜레이 버퍼는 제2 클럭 타임동안 가중치 w1을 저장하여 이를 1클럭만큼 딜레이시킨다. 여기서 제1 딜레이 버퍼의 k값은 -1이다. 그리고, 제2 딜레이 버퍼에는 제1 딜레이 버퍼로부터 1클럭만큼 딜레이된 가중치 w0이 입력된다. 그 리고, 제2 딜레이 버퍼는 제2 클럭 타임동안 가중치 w0을 추가로 1클럭만큼 딜레이시킨다. 즉, 가중치 w0 은 제1 딜레이 버퍼 및 제2 딜레이 버퍼를 통하여 2클럭만큼 딜레이 될 수 있다. 여기서 제2 딜레이 버퍼의 k값은 -1이다. 그리고, 도 19를 참조하면, 제3 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w2와 제1 데이터의 픽 셀 데이터 i01을 입력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w2와 제1 데이터의 픽셀 데이터 i01의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트(PE_00)에 연결된 레 지스터에는 w0*i00+w1*i10+w2*i01의 값이 저장된다. 즉, 연산값이 프로세싱 엘리먼트에서 누산 될 수 있다. 한편, 도 19를 참조하면, 제3 클럭 타임 동안, 제1 딜레이 버퍼에도 가중치 w2이 입력된다. 그리고, 제1 딜레이 버퍼는 제3 클럭 타임동안 가중치 w2을 저장하여 이를 1클럭만큼 딜레이시킨다. 그리고, 제2 딜레이 버퍼에는 제1 딜레이 버퍼로부터 1클럭만큼 딜레이된 가중치 w1이 입력된다. 그 리고, 제2 딜레이 버퍼는 제3 클럭 타임동안 가중치 w1을 추가로 1클럭만큼 딜레이시킨다. 즉, 가중치 w1 은 제1 딜레이 버퍼 및 제2 딜레이 버퍼를 통하여 2클럭만큼 딜레이 될 수 있다. 한편, 도 19를 참조하면, 제3 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)는 제2 딜레이 버퍼로부터 가 중치 w0를 입력 받고, 제1 데이터의 픽셀 데이터 i01을 입력 받는다. 그리고, 제2 프로세싱 엘리먼트(PE_10)는 가중치 w0와 제1 데이터의 픽셀 데이터 i01의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제2 프로세싱 엘리먼트(PE_10)에 연결된 레지스터에는 w0*i01의 값이 저장된다. 그리고, 도 20를 참조하면, 제4 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w3와 제1 데이터의 픽 셀 데이터 i11을 입력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w3와 제1 데이터의 픽셀 데이터 i11의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트(PE_00)에 연결된 레 지스터에는 w0*i00+w1*i10+w2*i01+w3*i11의 값이 저장된다. 즉, 연산값이 프로세싱 엘리먼트에서 누산 될 수 있 다. 한편, 도 20을 참조하면, 제4 클럭 타임 동안, 제1 딜레이 버퍼에도 가중치 w3이 입력된다. 그리고, 제1 딜레이 버퍼는 제4 클럭 타임동안 가중치 w3을 저장하여 이를 1클럭만큼 딜레이시킨다. 그리고, 제2 딜레이 버퍼에는 제1 딜레이 버퍼로부터 1클럭만큼 딜레이된 가중치 w2이 입력된다. 그 리고, 제2 딜레이 버퍼는 제4 클럭 타임동안 가중치 w2을 추가로 1클럭만큼 딜레이시킨다. 즉, 가중치 w2 은 제1 딜레이 버퍼 및 제2 딜레이 버퍼를 통하여 2클럭만큼 딜레이 될 수 있다. 한편, 도 20을 참조하면, 제4 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)는 제2 딜레이 버퍼로부터 가 중치 w1를 입력 받고, 제1 데이터의 픽셀 데이터 i11을 입력 받는다. 그리고, 제2 프로세싱 엘리먼트(PE_10)는 가중치 w1와 제1 데이터의 픽셀 데이터 i11의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제2 프로세싱 엘리먼트(PE_10)에 연결된 레지스터에는 w0*i01+w1*i11의 값이 저장된다. 즉, 연산값이 프로세싱 엘리 먼트에서 누산 될 수 있다. 그리고, 도 21를 참조하면, 제5 클럭 타임 동안 제1 프로세싱 엘리먼트(PE_00)에 연결된 레지스터에 저장된 w0*i00+w1*i10+w2*i01+w3*i11의 값은 제2 데이터의 픽셀 데이터 o11로 출력된다. 그리고, 제5 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w0과 제1 데이터의 픽셀 데이터 i02을 입 력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w0와 제1 데이터의 픽셀 데이터 i02의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트(PE_00)에 연결된 레지스터에는 w0*i02의 값이 저장된다. 한편, 도 21을 참조하면, 제5 클럭 타임 동안, 제1 딜레이 버퍼에도 가중치 w0 입력된다. 그리고, 제1 딜 레이 버퍼는 제5 클럭 타임동안 가중치 w0을 저장하여 이를 1클럭만큼 딜레이시킨다. 그리고, 제2 딜레이 버퍼에는 제1 딜레이 버퍼로부터 1클럭만큼 딜레이된 가중치 w3이 입력된다. 그 리고, 제2 딜레이 버퍼는 제5 클럭 타임동안 가중치 w3을 추가로 1클럭만큼 딜레이시킨다. 즉, 가중치 w3 은 제1 딜레이 버퍼 및 제2 딜레이 버퍼를 통하여 2클럭만큼 딜레이 될 수 있다. 한편, 도 21을 참조하면, 제5 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)는 제2 딜레이 버퍼로부터 가 중치 w2를 입력 받고, 제1 데이터의 픽셀 데이터 i02을 입력 받는다. 그리고, 제2 프로세싱 엘리먼트(PE_10)는 가중치 w2와 제1 데이터의 픽셀 데이터 i02의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제2 프로세싱 엘리먼트(PE_10)에 연결된 레지스터에는 w0*i01+w1*i11+w2*i02의 값이 저장된다. 즉, 연산값이 프로세 싱 엘리먼트에서 누산 될 수 있다. 그리고, 도 22를 참조하면, 제6 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w1과 제1 데이터의 픽 셀 데이터 i12을 입력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w1와 제1 데이터의 픽셀 데이터 i12의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트(PE_00)에 연결된 레 지스터에는 w0*i02+w1*i12의 값이 저장된다. 즉, 연산값이 프로세싱 엘리먼트에서 누산 될 수 있다. 한편, 도 22를 참조하면, 제6 클럭 타임 동안, 제1 딜레이 버퍼에도 가중치 w1 입력된다. 그리고, 제1 딜 레이 버퍼는 제6 클럭 타임동안 가중치 w1을 저장하여 이를 1클럭만큼 딜레이시킨다. 그리고, 제2 딜레이 버퍼에는 제1 딜레이 버퍼로부터 1클럭만큼 딜레이된 가중치 w0이 입력된다. 그 리고, 제2 딜레이 버퍼는 제6 클럭 타임동안 가중치 w0을 추가로 1클럭만큼 딜레이시킨다. 즉, 가중치 w0 은 제1 딜레이 버퍼 및 제2 딜레이 버퍼를 통하여 2클럭만큼 딜레이 될 수 있다. 한편, 도 22를 참조하면, 제6 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)는 제2 딜레이 버퍼로부터 가 중치 w3를 입력 받고, 제1 데이터의 픽셀 데이터 i12을 입력 받는다. 그리고, 제2 프로세싱 엘리먼트(PE_10)는 가중치 w3와 제1 데이터의 픽셀 데이터 i12의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제2 프로세싱 엘리먼트(PE_10)에 연결된 레지스터에는 w0*i01+w1*i11+w2*i02+w3*i12의 값이 저장된다. 즉, 연산값이 프로세싱 엘리먼트에서 누산 될 수 있다. 그리고, 도 23을 참조하면, 제7 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w2과 제1 데이터의 픽 셀 데이터 i03을 입력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w2와 제1 데이터의 픽셀 데이터 i03의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트(PE_00)에 연결된 레 지스터에는 w0*i02+w1*i12+w2*i03의 값이 저장된다. 즉, 연산값이 프로세싱 엘리먼트에서 누산 될 수 있다. 한편, 도 23을 참조하면, 제7 클럭 타임 동안, 제1 딜레이 버퍼에도 가중치 w2 입력된다. 그리고, 제1 딜 레이 버퍼는 제7 클럭 타임동안 가중치 w2을 저장하여 이를 1클럭만큼 딜레이시킨다. 그리고, 제2 딜레이 버퍼에는 제1 딜레이 버퍼로부터 1클럭만큼 딜레이된 가중치 w1이 입력된다. 그 리고, 제2 딜레이 버퍼는 제7 클럭 타임동안 가중치 w1을 추가로 1클럭만큼 딜레이시킨다. 즉, 가중치 w1 은 제1 딜레이 버퍼 및 제2 딜레이 버퍼를 통하여 2클럭만큼 딜레이 될 수 있다. 한편, 도 23을 참조하면, 제7 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)에 연결된 레지스터에 저장된 w0*i01+w1*i11+w2*i02+w3*i12의 값은 제2 데이터의 픽셀 데이터 o13로 출력된다. 그리고 제7 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)는 제2 딜레이 버퍼로부터 가중치 w0를 입력 받 고, 제1 데이터의 픽셀 데이터 i03을 입력 받는다. 그리고, 제2 프로세싱 엘리먼트(PE_10)는 가중치 w0와 제1 데이터의 픽셀 데이터 i03의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제2 프로세싱 엘리먼 트(PE_10)에 연결된 레지스터에는 w0*i03의 값이 저장된다. 그리고, 도 24를 참조하면, 제8 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w3과 제1 데이터의 픽 셀 데이터 i13을 입력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 가중치 w3와 제1 데이터의 픽셀 데이터 i13의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트(PE_00)에 연결된 레지스터에는 w0*i02+w1*i12+w2*i03+w3*i13의 값이 저장된다. 즉, 연산값이 프로세싱 엘리먼트에서 누산 될 수 있 다. 한편, 도 24를 참조하면, 제8 클럭 타임 동안, 제1 딜레이 버퍼에도 가중치 w3 입력된다. 그리고, 제1 딜 레이 버퍼는 제8 클럭 타임동안 가중치 w3을 저장하여 이를 1클럭만큼 딜레이시킨다. 그리고, 제2 딜레이 버퍼에는 제1 딜레이 버퍼로부터 1클럭만큼 딜레이된 가중치 w2이 입력된다. 그 리고, 제2 딜레이 버퍼는 제8 클럭 타임동안 가중치 w2을 추가로 1클럭만큼 딜레이시킨다. 즉, 가중치 w2 은 제1 딜레이 버퍼 및 제2 딜레이 버퍼를 통하여 2클럭만큼 딜레이 될 수 있다. 한편, 도 24를 참조하면, 제8 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)는 제2 딜레이 버퍼로부터 가 중치 w1를 입력 받고, 제1 데이터의 픽셀 데이터 i13을 입력 받는다. 그리고, 제2 프로세싱 엘리먼트(PE_10)는 가중치 w1와 제1 데이터의 픽셀 데이터 i13의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제2 프로세싱 엘리먼트(PE_10)에 연결된 레지스터에는 w0*i03+w1*i13의 값이 저장된다. 즉, 연산값이 프로세싱 엘리 먼트에서 누산 될 수 있다. 그리고, 도 25를 참조하면, 제9 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)에 연결된 레지스터에 저장된 w0*i02+w1*i12+w2*i03+w3*i13의 값은 제2 데이터의 픽셀 데이터 o15로 출력된다. 그리고, 제2 딜레이 버퍼에는 제1 딜레이 버퍼로부터 1클럭만큼 딜레이된 가중치 w3이 입력된다. 그 리고, 제2 딜레이 버퍼는 제9 클럭 타임동안 가중치 w3을 추가로 1클럭만큼 딜레이시킨다. 즉, 가중치 w3 은 제1 딜레이 버퍼 및 제2 딜레이 버퍼를 통하여 2클럭만큼 딜레이 될 수 있다. 한편, 도 25를 참조하면, 제9 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)는 제2 딜레이 버퍼로부터 가 중치 w2를 입력 받고, 제1 데이터의 픽셀 데이터 i03을 입력 받는다. 그리고, 제2 프로세싱 엘리먼트(PE_10)는 가중치 w2와 제1 데이터의 픽셀 데이터 i03의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제2 프로세싱 엘리먼트(PE_10)에 연결된 레지스터에는 w0*i03+w1*i13+w2*i03의 값이 저장된다. 즉, 연산값이 프로세 싱 엘리먼트에서 누산 될 수 있다. 그리고, 도 26을 참조하면, 제10 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)는 제2 딜레이 버퍼로부터 가중치 w3를 입력 받고, 제1 데이터의 픽셀 데이터 i13을 입력 받는다. 그리고, 제2 프로세싱 엘리먼트(PE_10) 는 가중치 w3와 제1 데이터의 픽셀 데이터 i13의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제2 프로세싱 엘리먼트(PE_10)에 연결된 레지스터에는 w0*i03+w1*i13+w2*i03+w3*i03의 값이 저장된다. 즉, 연 산값이 프로세싱 엘리먼트에서 누산 될 수 있다. 그리고, 도 27을 참조하면, 제11 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)에 연결된 레지스터에 저장된 w0*i03+w1*i13+w2*i03+w3*i03의 값은 제2 데이터의 픽셀 데이터 o17로 출력된다. 이처럼 매 클럭마다 프로세싱 엘리먼트의 누산기에는 가중치와 픽셀 데이터가 곱셈 된 값이 누산 될 수 있다. 이처럼 딜레이 버퍼를 통해서 가중치가 다른 프로세싱 엘리먼트로 전달되는 방식으로 가중치를 재사용할 수 있 다. 따라서, 가중치 재사용에 의해서 신경 프로세싱 유닛의 소비 전력이 저감될 수 있다. 이처럼 각 PE에 특징맵 데이터(즉, 입력 특징맵 데이터) 및 가중치가 입력되면 각 PE에 입력된 특징맵 데이터 및 가중치에 대한 MAC 연산이 매 클럭 별 수행된다. 연산을 통해 산출된 연산 결과 데이터(즉, 출력 특징맵 데 이터)는 각 PE로부터 출력되어 소수점 곱셈기에 입력되거나, 내부 메모리 또는 특징맵 저장부에 저장 될 수 있다. 즉, 각 PE는 가중치 및 특징맵 데이터를 입력 받아 가중치 및 특징맵 데이터에 대한 MAC 연산을 수행한다. 즉, 프로세싱 엘리먼트 어레이는 가중치를 입력받는 제1 프로세싱 엘리먼트(PE_00), 가중치를 입력 받고 특정 클럭으로 딜레이하여 제2 프로세싱 엘리먼트(PE_10)으로 전달하도록 구성된 딜레이 버퍼(Z-k)을 포함하도록 구성 될 수 있다. 여기서 딜레이 버퍼의 딜레이 기간은 k 값으로 결정할 수 있다. 따라서, 딜레이 버퍼는 가중치를 재사용하면서 뎁스와이즈 합성곱을 처리하도록 구성될 수 있다. 즉, 가중치를 전달하는 하나의 딜레이 버퍼, 딜레이 버퍼의 입력과 출력에 대응되는 2개의 프로세싱 엘리먼트를 제공함에 따라 데이터 재사용이 가능한 뎁스와이즈 합성곱을 구현할 수 있다. 즉, 상술한 구성에 따르면, 신경 프로세싱 유닛은 일반적인 인공신경망모델의 합성곱 연산과 쌍선형 보간 법 연산을 선택적으로 수행할 수 있다. 따라서, 신경 프로세싱 유닛은 별도의 쌍선형 보간법 연산을 위한 회로를 구비하지 않더라도, 프로세싱 엘리먼트를 활용하여 쌍선형 보간법을 효과적으로 수행할 수 있다. 특히, 다수의 프로세싱 엘리먼트를 활용하는 쌍선형 보간법은 인공신경망 연산 중 세그먼테이션 연산 및 업스케일링 연산을 효율적으로 처리할 수 있는 효과가 있다. 이하에서는 도 28 내지 도 36을 참조하여 프로세싱 엘리먼트 어레이가 포인트와이즈 합성곱 연산을 수행하는 방 식을 설명한다. 도 28은 본 개시의 다른 예시에 따른 프로세싱 엘리먼트 어레이의 구조를 나타내는 개략적인 구성도이다. 도 28을 참조하면, 프로세싱 엘리먼트 어레이는 복수의 PE 행 및 복수의 PE 열로 구성된 복수의 PE를 포함할 수 있다. 부연 설명하면, 제1 PE 행은 첫번째 행에 배치된 복수의 프로세싱 엘리먼트들(PE_00, PE_01, PE_02, …, PE_0n- 1)을 지칭할 수 있다. 제2 PE 행은 두번째 행에 배치된 복수의 프로세싱 엘리먼트들(PE_10, PE_11, PE_12, …, PE_1n-1)을 지칭할 수 있다. 제3 PE 행은 세번째 행에 배치된 복수의 프로세싱 엘리먼트들(PE_20, PE_21, PE_22, …, PE_2n-1)을 지칭할 수 있다. 제4 PE 행은 네번째 행에 배치된 복수의 프로세싱 엘리먼트들(PE_30, PE_31, PE_32, …, PE_3n-1)을 지칭할 수 있다. 부연 설명하면, 제1 PE 열은 첫번째 열에 배치된 복수의 프로세싱 엘리먼트들(PE_00, PE_10, PE_20, PE_30, …)을 지칭할 수 있다. 제2 PE 열은 두번째 복수의 프로세싱 엘리먼트들(PE_01, PE_11, PE_21, PE_31, …)을 지칭할 수 있다. 제3 PE 열은 세번째 열에 배치된 복수의 프로세싱 엘리먼트들(PE_02, PE_12, PE_22, PE_32, …)을 지칭할 수 있다. 제n-1 PE 열은 n번째 복수의 프로세싱 엘리먼트들(PE_0n-1, PE_1n-1, PE_2n-1, PE_3n- 1, …)을 지칭할 수 있다. 도 28을 참조하면, 제1 PE 열(PE_00, PE_01, PE_02, …, PE_0n-1)은 제1 가중치(w0_1, w1_1, w2_1, w3_1)가 전 달되는 신호 라인(W_in_1)을 통해 가중치 저장부와 연결될 수 있다. 가중치 저장부로부터 제1 가중치 (w0_1, w1_1, w2_1, w3_1)가 출력된다. 신호 라인(W_in)의 브랜치를 통해 제1 PE 열(PE_00, PE_01, PE_02, …, PE_0n-1)으로 제1 가중치(w1_1, w2_1, w3_1, w0_1)가 입력된다. 보다 구체적으로, 제1 PE 열(PE_00, PE_01, PE_02, …, PE_0n-1) 각각에 쌍선형 보간법(Bilinear Interpolation) 연산에 사용되는 제1 가중치(w0_1, w1_1, w2_1, w3_1)는 브로드캐스팅(broadcasting) 될 수 있다. 즉, 제1 PE 열(PE_00, PE_01, PE_02, …, PE_0n-1) 각 각에는 동일한 타이밍에 동일한 가중치가 입력될 수 있다. 그리고, 제2PE 열(PE_10, PE_11, PE_12, …, PE_1n-1)은 제2 가중치(w0_2, w1_2, w2_2, w3_2)가 전달되는 신호 라인(W_in_2)을 통해 가중치 저장부와 연결될 수 있다. 가중치 저장부로부터 제2 가중치(w0_2, w1_2, w2_2, w3_2)가 출력된다. 신호 라인(W_in)의 브랜치를 통해 제2PE 열(PE_10, PE_11, PE_12, …, PE_1n-1)으로 제2 가중치(w0_2, w1_2, w2_2, w3_2)가 입력된다. 보다 구체적으로, 제2PE 열(PE_10, PE_11, PE_12, …, PE_1n-1) 각각에 쌍선형 보간법(Bilinear Interpolation) 연산에 사용되는 제2 가중치(w0_2, w1_2, w2_2, w3_2)는 브로드캐스팅(broadcasting) 될 수 있다. 즉, 제2PE 열(PE_10, PE_11, PE_12, …, PE_1n-1) 각각에는 동일한 타이밍에 동일한 가중치가 입력될 수 있다. 그리고, 제3 PE 열(PE_20, PE_21, PE_22, …, PE_2n-1)은 제3 가중치(w0_3, w1_3, w2_3, w3_3)가 전달되는 신 호 라인(W_in_3)을 통해 가중치 저장부와 연결될 수 있다. 가중치 저장부로부터 제3 가중치(w0_3, w1_3, w2_3, w3_3)가 출력된다. 신호 라인(W_in)의 브랜치를 통해 제3 PE 열(PE_20, PE_21, PE_22, …, PE_2n- 1)으로 제3 가중치(w0_3, w1_3, w2_3, w3_3)가 입력된다. 보다 구체적으로, 제3 PE 열(PE_20, PE_21, PE_22, …, PE_2n-1) 각각에 쌍선형 보간법(Bilinear Interpolation) 연산에 사용되는 제3 가중치(w0_3, w1_3, w2_3, w3_3)는 브로드캐스팅(broadcasting) 될 수 있다. 즉, 제3 PE 열(PE_20, PE_21, PE_22, …, PE_2n-1) 각각에는 동일한 타이밍에 동일한 가중치가 입력될 수 있다. 그리고, 제4PE 열(PE_30, PE_31, PE_32, …, PE_3n-1)은 제4 가중치(w0_4, w1_4, w2_4, w3_4)가 전달되는 신호 라인(W_in_4)을 통해 가중치 저장부와 연결될 수 있다. 가중치 저장부로부터 제4 가중치(w0_4, w1_4, w2_4, w3_4)가 출력된다. 신호 라인(W_in)의 브랜치를 통해 제4PE 열(PE_30, PE_31, PE_32, …, PE_3n-1)으로 제4 가중치(w0_4, w1_4, w2_4, w3_4)가 입력된다. 보다 구체적으로, 제4PE 열(PE_30, PE_31, PE_32, …, PE_3n-1) 각각에 쌍선형 보간법(Bilinear Interpolation) 연산에 사용되는 제4 가중치(w0_4, w1_4, w2_4, w3_4)는 브로드캐스팅(broadcasting) 될 수 있다. 즉, 제4PE 열(PE_30, PE_31, PE_32, …, PE_3n-1) 각각에는 동일한 타이밍에 동일한 가중치가 입력될 수 있다.즉, 복수의 가중치 각각은 상기 PE Array 중 서로 다른 행에 배치된 PE들에 브로드캐스트 되도록 구성될 수 있 다. 한편, 복수의 PE 열 각각은 특징맵 데이터가 전달되는 신호 라인(F_in)을 통해 특징맵 저장부와 연결될 수 있다. 특징맵 저장부로부터 출력된 특징맵 데이터는 각 F_in 신호 라인을 통해 복수의 PE 열 각각으로 입 력된다. 예를 들어, n채널의 특징맵 데이터는 제1 PE 열 내지 제n PE열 각각으로 유니캐스팅(unicasting) 또는 브로드캐스팅(broadcasting) 될 수 있다. 상술한 특징맵 데이터는 제1 데이터의 픽셀 데이터 일 수 있다. F_in 신호 라인은 n개의 채널로 구성된 버스일 수 있다. F_in 신호 라인은 1개의 PE 열에 대응되는 개별 신호 라인들을 포함하는 버스 라인일 수 있다. 예를 들어, 제1 PE 행(PE_00, PE_01, …)이 64개의 프로세싱 엘리먼트 를 가지도록 구성되면, F_in 신호 라인은 64개의 라인으로 구성된 버스 라인일 수 있다. 그리고, F_in 신호 라 인은 PE 열의 각각의 프로세싱 엘리먼트에 개별 특징맵 데이터를 유니캐스트하거나 또는 동일한 특징맵 데이터 를 브로드캐스트 하도록 구성될 수 있다. 이처럼 각 PE에 특징맵 데이터 및 가중치가 입력되면 각 PE에서 입력된 특징맵 데이터 및 가중치에 대한 MAC 연 산이 매 클럭마다 수열되고, 연산을 통해 산출된 연산 결과 데이터(즉, 특징맵 데이터)가 각 PE로부터 출력되어 특징맵 저장부에 저장될 수 있다. 부연 설명하면, 도 28에서는 생략되었으나, 도 13을 다시 참조하면, 각각의 PE는 MAC 연산 값이 저장된 레지스 터에서 MAC 연산 값을 출력하는 F_out 신호 라인을 각각 포함하도록 구성될 수 있다. 단, 이에 제한되지 않으며, F_out 신호 라인은 내부 메모리 또는 추가적인 다른 연산 유닛과 연결되도록 구성될 수 있다. 한편, 복수의 딜레이 버퍼(241, 242, 243, 244) 또한 특징맵 데이터가 전달되는 신호 라인(F_in)을 통해 특징맵 저장부와 연결될 수 있다. 특징맵 저장부로부터 출력된 특징맵 데이터는 각 특징맵 데이터가 전달되 는 신호 라인(F_in)의 브랜치를 통해 복수의 딜레이 버퍼(241, 242, 243, 244)으로 입력된다. 보다 구체적으로, 복수의 딜레이 버퍼(241, 242, 243, 244)가 직렬 연결된 제1 딜레이 버퍼, 제2 딜레이 버퍼, 제3 딜레이 버퍼, 제4 딜레이 버퍼 로 구성될 수 있다. 이러한 경우, 제1 딜레이 버퍼 는 특징맵 데이터가 전달되는 신호 라인(F_in)을 통해 특징맵 저장부와 연결될 수 있다. 여기서 제1 내지 제4 딜레이 버퍼의 k는 1일 수 있다. 따라서 각각의 딜레이 버퍼는 한 클럭씩 데이터를 딜레이 시킬 수 있 다. 따라서, 특징맵 데이터는 제1 딜레이 버퍼에 입력된다. 그리고, 제1 딜레이 버퍼는 입력된 특징맵 데 이터를 1클럭만큼 지연시켜, 제2 딜레이 버퍼 및 제2 PE열로 출력한다. 이에, 제2 PE 열에는 제1 딜레이 버퍼에 의해 1클럭 만큼 딜레이된 특징맵 데이터가 입력될 수 있다. 그리고, 제2 딜레이 버퍼는 입력된 특징맵 데이터를 1클럭만큼 추가로 지연시켜, 제3 딜레이 버퍼 및 제3 PE 열에 출력한다. 결과적으로, 제3 PE 열에는 제1 딜레이 버퍼 및 제2 딜레이 버퍼에 의해 2클 럭 만큼 딜레이된 특징맵 데이터가 입력될 수 있다. 그리고, 제3 딜레이 버퍼는 입력된 특징맵 데이터를 1클럭만큼 추가로 지연시켜, 제4 딜레이 버퍼 및 제4 PE 열에 출력한다. 결과적으로, 제4 PE 열에는 제1 딜레이 버퍼, 제2 딜레이 버퍼 및 제3 딜레이 버퍼에 의해 3클럭 만큼 딜레이된 특징맵 데이터가 입력될 수 있다. 즉, 딜레이 버퍼(Z-k)를 통해 딜레이되며 전달된 특징맵 데이터는 각 PE 열 방향으로 딜레이 브로드캐스팅 (delayed broadcasting)될 수 있다. 따라서, 특징맵 저장부에서 전달된 특징맵 데이터는 딜레이 브로드캐 스팅(delayed broadcasting)에 의해 딜레이된 특징맵 데이터가 제공되는 각 PE에서 재사용될 수 있다. 이를 통 해 특징맵 데이터가 프로세싱 엘리먼트 어레이 내에서 재사용되어 연산을 위해 사용되는 리소스 소모 및 메모리 사용량을 최소화시킬 수 있다. 또한 상술한 구성에 따르면, 다수의 프로세싱 엘리먼트를 쌍선형 보간법 연산에 활용할 수 있다. 따라서, 쌍선 형 보간법 연산 속도를 향상시킬 수 있는 효과가 있다. 이하에서는 도 29 내지 도 36을 참조하여 프로세싱 엘리먼트 어레이가 포인트와이즈 합성곱 연산을 수행하는 방 식을 설명한다. 도 29 내지 도 36은 본 개시의 일 예시에 따른 프로세싱 엘리먼트 어레이가 복수의 클럭 동안 동작하는 방식을 설명하기 위만 도면이다.도 29 내지 도 36에서 복수의 클럭 동안 제1 PE열이 n개 채널의 입력 데이터 중 하나의 채널의 입력 데이터에 대하여 합성곱을 수행하는 과정을 도시하였다. 도 29를 참조하면, 제1 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w0_1와 제1 데이터의 픽셀 데이터 i00을 입력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w0_1와 제1 데이터의 픽셀 데 이터 i00의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트(PE_00)에 연결 된 레지스터에는 w0_1*i00의 값이 저장된다. 한편, 도 29를 참조하면, 제1 클럭 타임 동안, 제1 딜레이 버퍼에도 제1 데이터의 픽셀 데이터 i00이 입력 된다. 그리고, 제1 딜레이 버퍼는 제1 클럭 타임동안 제1 데이터의 픽셀 데이터 i00을 저장하여 이를 1클 럭만큼 딜레이시킨다. 그리고, 도 30을 참조하면, 제2 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w1_1와 제1 데이 터의 픽셀 데이터 i10을 입력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w1_1와 제1 데이터 의 픽셀 데이터 i10의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트 (PE_00)에 연결된 레지스터에는 w0_1*i00+w1_1*i10의 값이 저장된다. 즉, 연산값이 프로세싱 엘리먼트에서 누산 될 수 있다. 한편, 도 30을 참조하면, 제2 클럭 타임 동안, 제1 딜레이 버퍼에도 제1 데이터의 픽셀 데이터 i10이 입력 된다. 그리고, 제1 딜레이 버퍼는 제2 클럭 타임동안 제1 데이터의 픽셀 데이터 i10을 저장하여 이를 1클 럭만큼 딜레이시킨다. 그리고, 제2 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)는 제1 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i00를 입력 받고, 제2 가중치 w0_2을 입력 받는다. 그리고, 제2 프로세싱 엘리먼트(PE_10)는 제2 가중치 w0_2와 제1 데이터의 픽셀 데이터 i00의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제2 프로 세싱 엘리먼트(PE_10)에 연결된 레지스터에는 w0_2*i00의 값이 저장된다. 그리고, 제2 딜레이 버퍼에는 제1 딜레이 버퍼로부터 1클럭만큼 딜레이된 제1 데이터의 픽셀 데이터 i00이 입력된다. 그리고, 제2 딜레이 버퍼는 제2 클럭 타임동안 제1 데이터의 픽셀 데이터 i00을 추가로 1 클럭만큼 딜레이시킨다. 즉, 제1 데이터의 픽셀 데이터 i00은 제1 딜레이 버퍼 및 제2 딜레이 버퍼를 통하여 2클럭만큼 딜레이 될 수 있다. 그리고, 도 31을 참조하면, 제3 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w2_1와 제1 데이 터의 픽셀 데이터 i01을 입력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w2_1와 제1 데이터 의 픽셀 데이터 i01의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트 (PE_00)에 연결된 레지스터에는 w0_1*i00+w1_1*i10+w2_1*i01의 값이 저장된다. 즉, 연산값이 프로세싱 엘리먼트 에서 누산 될 수 있다. 한편, 도 31을 참조하면, 제3 클럭 타임 동안, 제1 딜레이 버퍼에도 제1 데이터의 픽셀 데이터 i01이 입력 된다. 그리고, 제1 딜레이 버퍼는 제3 클럭 타임동안 제1 데이터의 픽셀 데이터 i01을 저장하여 이를 1클 럭만큼 딜레이시킨다. 그리고, 제3 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)는 제1 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i10를 입력 받고, 제2 가중치 w1_2을 입력 받는다. 그리고, 제2 프로세싱 엘리먼트(PE_10)는 제2 가중치 w1_2와 제1 데이터의 픽셀 데이터 i10의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제2 프로 세싱 엘리먼트(PE_10)에 연결된 레지스터에는 w0_2*i00+w1_2*i10의 값이 저장된다. 즉, 연산값이 프로세싱 엘리 먼트에서 누산 될 수 있다. 그리고, 제2 딜레이 버퍼에는 제1 딜레이 버퍼로부터 1클럭만큼 딜레이된 제1 데이터의 픽셀 데이터 i10이 입력된다. 그리고, 제2 딜레이 버퍼는 제3 클럭 타임동안 제1 데이터의 픽셀 데이터 i10을 추가로 1 클럭만큼 딜레이시킨다. 즉, 제1 데이터의 픽셀 데이터 i10은 제1 딜레이 버퍼 및 제2 딜레이 버퍼를 통하여 2클럭만큼 딜레이 될 수 있다. 그리고, 제3 클럭 타임 동안, 제3 프로세싱 엘리먼트(PE_20)는 제2 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i00를 입력 받고, 제3 가중치 w0_3을 입력 받는다. 그리고, 제3 프로세싱 엘리먼트(PE_20)는 제3 가중치 w0_3와 제1 데이터의 픽셀 데이터 i00의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제3 프로 세싱 엘리먼트(PE_20)에 연결된 레지스터에는 w0_3*i00의 값이 저장된다.그리고, 제3 딜레이 버퍼에는 제2 딜레이 버퍼로부터 2클럭만큼 딜레이된 제1 데이터의 픽셀 데이터 i00이 입력된다. 그리고, 제3 딜레이 버퍼는 제3 클럭 타임동안 제1 데이터의 픽셀 데이터 i00을 추가로 1 클럭만큼 딜레이시킨다. 즉, 제1 데이터의 픽셀 데이터 i00은 제1 딜레이 버퍼, 제2 딜레이 버퍼 및 제3 딜레이 버퍼를 통하여 3클럭만큼 딜레이 될 수 있다. 그리고, 도 32를 참조하면, 제4 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w3_1와 제1 데이 터의 픽셀 데이터 i11을 입력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w3_1와 제1 데이터 의 픽셀 데이터 i11의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트 (PE_00)에 연결된 레지스터에는 w0_1*i00+w1_1*i10+w2_1*i01+ w3_1*i11의 값이 저장된다. 즉, 연산값이 프로세 싱 엘리먼트에서 누산 될 수 있다. 한편, 도 32를 참조하면, 제4 클럭 타임 동안, 제1 딜레이 버퍼에도 제1 데이터의 픽셀 데이터 i11이 입력 된다. 그리고, 제1 딜레이 버퍼는 제4 클럭 타임동안 제1 데이터의 픽셀 데이터 i11을 저장하여 이를 1클 럭만큼 딜레이시킨다. 그리고, 제4 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)는 제1 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i01를 입력 받고, 제2 가중치 w2_2을 입력 받는다. 그리고, 제2 프로세싱 엘리먼트(PE_10)는 제2 가중치 w2_2와 제1 데이터의 픽셀 데이터 i01의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제2 프로 세싱 엘리먼트(PE_10)에 연결된 레지스터에는 w0_2*i00+w1_2*i10+w2_2*i01의 값이 저장된다. 즉, 연산값이 프로 세싱 엘리먼트에서 누산 될 수 있다. 그리고, 제2 딜레이 버퍼에는 제1 딜레이 버퍼로부터 1클럭만큼 딜레이된 제1 데이터의 픽셀 데이터 i01이 입력된다. 그리고, 제2 딜레이 버퍼는 제4 클럭 타임동안 제1 데이터의 픽셀 데이터 i01을 추가로 1 클럭만큼 딜레이시킨다. 즉, 제1 데이터의 픽셀 데이터 i01은 제1 딜레이 버퍼 및 제2 딜레이 버퍼를 통하여 2클럭만큼 딜레이 될 수 있다. 그리고, 제4 클럭 타임 동안, 제3 프로세싱 엘리먼트(PE_20)는 제2 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i10를 입력 받고, 제3 가중치 w1_3을 입력 받는다. 그리고, 제3 프로세싱 엘리먼트(PE_20)는 제3 가중치 w1_3와 제1 데이터의 픽셀 데이터 i10의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제3 프로 세싱 엘리먼트(PE_20)에 연결된 레지스터에는 w0_3*i00+ w1_3*i10의 값이 저장된다. 즉, 연산값이 프로세싱 엘 리먼트에서 누산 될 수 있다. 그리고, 제3 딜레이 버퍼에는 제2 딜레이 버퍼로부터 2클럭만큼 딜레이된 제1 데이터의 픽셀 데이터 i10이 입력된다. 그리고, 제3 딜레이 버퍼는 제4 클럭 타임동안 제1 데이터의 픽셀 데이터 i10을 추가로 1 클럭만큼 딜레이시킨다. 즉, 제1 데이터의 픽셀 데이터 i10은 제1 딜레이 버퍼, 제2 딜레이 버퍼 및 제3 딜레이 버퍼를 통하여 3클럭만큼 딜레이 될 수 있다. 그리고, 제4 클럭 타임 동안, 제4 프로세싱 엘리먼트(PE_30)는 제3 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i00를 입력 받고, 제4 가중치 w0_4을 입력 받는다. 그리고, 제4 프로세싱 엘리먼트(PE_.30)는 제4 가중 치 w0_4와 제1 데이터의 픽셀 데이터 i00의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제4 프 로세싱 엘리먼트(PE_30)에 연결된 레지스터에는 w0_4*i00의 값이 저장된다. 그리고, 도 33을 참조하면, 제5 클럭 타임 동안 제1 프로세싱 엘리먼트(PE_00)에 연결된 레지스터에 저장된 w0_1*i00+w1_1*i10+w2_1*i01+ w3_1*i11의 값은 제2 데이터의 픽셀 데이터 o11로 출력된다. 그리고, 도 33를 참조하면, 제5 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w0_1와 제1 데이 터의 픽셀 데이터 i01을 입력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w0_1와 제1 데이터 의 픽셀 데이터 i01의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트 (PE_00)에 연결된 레지스터에는 w0_1*i01의 값이 저장된다. 한편, 도 33를 참조하면, 제5 클럭 타임 동안, 제1 딜레이 버퍼에도 제1 데이터의 픽셀 데이터 i01이 입력 된다. 그리고, 제1 딜레이 버퍼는 제5 클럭 타임동안 제1 데이터의 픽셀 데이터 i01을 저장하여 이를 1클 럭만큼 딜레이시킨다. 그리고, 제5 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)는 제1 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i11를 입력 받고, 제2 가중치 w3_2을 입력 받는다. 그리고, 제2 프로세싱 엘리먼트(PE_10)는 제2 가중치 w3_2와 제1 데이터의 픽셀 데이터 i11의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제2 프로세싱 엘리먼트(PE_10)에 연결된 레지스터에는 w0_2*i00+w1_2*i10+w2_2*i01+ w3_2*i11의 값이 저장된다. 즉, 연 산값이 프로세싱 엘리먼트에서 누산 될 수 있다. 그리고, 제2 딜레이 버퍼에는 제1 딜레이 버퍼로부터 1클럭만큼 딜레이된 제1 데이터의 픽셀 데이터 i11이 입력된다. 그리고, 제2 딜레이 버퍼는 제5 클럭 타임동안 제1 데이터의 픽셀 데이터 i11을 추가로 1 클럭만큼 딜레이시킨다. 즉, 제1 데이터의 픽셀 데이터 i11은 제1 딜레이 버퍼 및 제2 딜레이 버퍼를 통하여 2클럭만큼 딜레이 될 수 있다. 그리고, 제5 클럭 타임 동안, 제3 프로세싱 엘리먼트(PE_20)는 제2 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i01를 입력 받고, 제3 가중치 w2_3을 입력 받는다. 그리고, 제3 프로세싱 엘리먼트(PE_20)는 제3 가중치 w2_3와 제1 데이터의 픽셀 데이터 i01의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제3 프로 세싱 엘리먼트(PE_20)에 연결된 레지스터에는 w0_3*i00+ w1_3*i10+ w2_3*i01의 값이 저장된다. 즉, 연산값이 프로세싱 엘리먼트에서 누산 될 수 있다. 그리고, 제3 딜레이 버퍼에는 제2 딜레이 버퍼로부터 2클럭만큼 딜레이된 제1 데이터의 픽셀 데이터 i01이 입력된다. 그리고, 제3 딜레이 버퍼는 제5 클럭 타임동안 제1 데이터의 픽셀 데이터 i01을 추가로 1 클럭만큼 딜레이시킨다. 즉, 제1 데이터의 픽셀 데이터 i01은 제1 딜레이 버퍼, 제2 딜레이 버퍼 및 제3 딜레이 버퍼를 통하여 3클럭만큼 딜레이 될 수 있다. 그리고, 제5 클럭 타임 동안, 제4 프로세싱 엘리먼트(PE_30)는 제3 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i10를 입력 받고, 제4 가중치 w1_4을 입력 받는다. 그리고, 제4 프로세싱 엘리먼트(PE_.30)는 제4 가중 치 w1_4와 제1 데이터의 픽셀 데이터 i10의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제4 프 로세싱 엘리먼트(PE_30)에 연결된 레지스터에는 w0_4*i00+ w1_4*i10값이 저장된다. 즉, 연산값이 프로세싱 엘리 먼트에서 누산 될 수 있다. 그리고, 도 34를 참조하면, 제6 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w1_1와 제1 데이 터의 픽셀 데이터 i11을 입력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w1_1와 제1 데이터 의 픽셀 데이터 i11의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트 (PE_00)에 연결된 레지스터에는 w0_1*i01+ w1_1*i11의 값이 저장된다. 즉, 연산값이 프로세싱 엘리먼트에서 누 산 될 수 있다. 한편, 도 34를 참조하면, 제6 클럭 타임 동안, 제1 딜레이 버퍼에도 제1 데이터의 픽셀 데이터 i11이 입력 된다. 그리고, 제1 딜레이 버퍼는 제6 클럭 타임동안 제1 데이터의 픽셀 데이터 i11을 저장하여 이를 1클 럭만큼 딜레이시킨다. 그리고, 도 34을 참조하면, 제6 클럭 타임 동안 제2 프로세싱 엘리먼트(PE_10)에 연결된 레지스터에 저장된 w0_2*i00+w1_2*i10+w2_2*i01+ w3_2*i11의 값은 제2 데이터의 픽셀 데이터 o21로 출력된다. 그리고, 제6 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)는 제1 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i01를 입력 받고, 제2 가중치 w0_2을 입력 받는다. 그리고, 제2 프로세싱 엘리먼트(PE_10)는 제2 가중치 w0_2와 제1 데이터의 픽셀 데이터 i01의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제2 프로 세싱 엘리먼트(PE_10)에 연결된 레지스터에는 w0_2*i01의 값이 저장된다. 그리고, 제2 딜레이 버퍼에는 제1 딜레이 버퍼로부터 1클럭만큼 딜레이된 제1 데이터의 픽셀 데이터 i01이 입력된다. 그리고, 제2 딜레이 버퍼는 제6 클럭 타임동안 제1 데이터의 픽셀 데이터 i01을 추가로 1 클럭만큼 딜레이시킨다. 즉, 제1 데이터의 픽셀 데이터 i01은 제1 딜레이 버퍼 및 제2 딜레이 버퍼를 통하여 2클럭만큼 딜레이 될 수 있다. 그리고, 제6 클럭 타임 동안, 제3 프로세싱 엘리먼트(PE_20)는 제2 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i11를 입력 받고, 제3 가중치 w3_3을 입력 받는다. 그리고, 제3 프로세싱 엘리먼트(PE_20)는 제3 가중치 w3_3와 제1 데이터의 픽셀 데이터 i11의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제3 프로 세싱 엘리먼트(PE_20)에 연결된 레지스터에는 w0_3*i00+ w1_3*i10+ w2_3*i01+ w3_3*i11의 값이 저장된다. 즉, 연산값이 프로세싱 엘리먼트에서 누산 될 수 있다. 그리고, 제3 딜레이 버퍼에는 제2 딜레이 버퍼로부터 2클럭만큼 딜레이된 제1 데이터의 픽셀 데이터 i11이 입력된다. 그리고, 제3 딜레이 버퍼는 제6 클럭 타임동안 제1 데이터의 픽셀 데이터 i11을 추가로 1 클럭만큼 딜레이시킨다. 즉, 제1 데이터의 픽셀 데이터 i11은 제1 딜레이 버퍼, 제2 딜레이 버퍼 및제3 딜레이 버퍼를 통하여 3클럭만큼 딜레이 될 수 있다. 그리고, 제6 클럭 타임 동안, 제4 프로세싱 엘리먼트(PE_30)는 제3 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i01를 입력 받고, 제4 가중치 w2_4을 입력 받는다. 그리고, 제4 프로세싱 엘리먼트(PE_.30)는 제4 가중 치 w2_4와 제1 데이터의 픽셀 데이터 i01의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제4 프 로세싱 엘리먼트(PE_30)에 연결된 레지스터에는 w0_4*i00+ w1_4*i10+ w2_4*i01값이 저장된다. 즉, 연산값이 프 로세싱 엘리먼트에서 누산 될 수 있다. 그리고, 도 35를 참조하면, 제7 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w2_1와 제1 데이 터의 픽셀 데이터 i02을 입력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w2_1와 제1 데이터 의 픽셀 데이터 i02의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트 (PE_00)에 연결된 레지스터에는 w0_1*i01+ w1_1*i11+ w2_1*i02의 값이 저장된다. 즉, 연산값이 프로세싱 엘리 먼트에서 누산 될 수 있다. 한편, 도 35를 참조하면, 제7 클럭 타임 동안, 제1 딜레이 버퍼에도 제1 데이터의 픽셀 데이터 i02이 입력 된다. 그리고, 제1 딜레이 버퍼는 제7 클럭 타임동안 제1 데이터의 픽셀 데이터 i02을 저장하여 이를 1클 럭만큼 딜레이시킨다. 그리고, 제7 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)는 제1 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i11를 입력 받고, 제2 가중치 w1_2을 입력 받는다. 그리고, 제2 프로세싱 엘리먼트(PE_10)는 제2 가중치 w1_2와 제1 데이터의 픽셀 데이터 i11의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제2 프로 세싱 엘리먼트(PE_10)에 연결된 레지스터에는 w0_2*i01+ w1_2*i11의 값이 저장된다. 즉, 연산값이 프로세싱 엘 리먼트에서 누산 될 수 있다. 그리고, 제2 딜레이 버퍼에는 제1 딜레이 버퍼로부터 1클럭만큼 딜레이된 제1 데이터의 픽셀 데이터 i11이 입력된다. 그리고, 제2 딜레이 버퍼는 제7 클럭 타임동안 제1 데이터의 픽셀 데이터 i11을 추가로 1 클럭만큼 딜레이시킨다. 즉, 제1 데이터의 픽셀 데이터 i11은 제1 딜레이 버퍼 및 제2 딜레이 버퍼를 통하여 2클럭만큼 딜레이 될 수 있다. 그리고, 도 35을 참조하면, 제7 클럭 타임 동안 제3 프로세싱 엘리먼트(PE_20)에 연결된 레지스터에 저장된 w0_3*i00+ w1_3*i10+ w2_3*i01+ w3_3*i11의 값은 제2 데이터의 픽셀 데이터 o12로 출력된다. 그리고, 제7 클럭 타임 동안, 제3 프로세싱 엘리먼트(PE_20)는 제2 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i01를 입력 받고, 제3 가중치 w0_3을 입력 받는다. 그리고, 제3 프로세싱 엘리먼트(PE_20)는 제3 가중치 w0_3와 제1 데이터의 픽셀 데이터 i01의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제3 프로 세싱 엘리먼트(PE_20)에 연결된 레지스터에는 w0_3*i01의 값이 저장된다. 그리고, 제3 딜레이 버퍼에는 제2 딜레이 버퍼로부터 2클럭만큼 딜레이된 제1 데이터의 픽셀 데이터 i01이 입력된다. 그리고, 제3 딜레이 버퍼는 제7 클럭 타임동안 제1 데이터의 픽셀 데이터 i01을 추가로 1 클럭만큼 딜레이시킨다. 즉, 제1 데이터의 픽셀 데이터 i01은 제1 딜레이 버퍼, 제2 딜레이 버퍼 및 제3 딜레이 버퍼를 통하여 3클럭만큼 딜레이 될 수 있다. 그리고, 제7 클럭 타임 동안, 제4 프로세싱 엘리먼트(PE_30)는 제3 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i11를 입력 받고, 제4 가중치 w3_4을 입력 받는다. 그리고, 제4 프로세싱 엘리먼트(PE_.30)는 제4 가중 치 w3_4와 제1 데이터의 픽셀 데이터 i11의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제4 프 로세싱 엘리먼트(PE_30)에 연결된 레지스터에는 w0_4*i00+ w1_4*i10+ w2_4*i01+w3_4*i11값이 저장된다. 즉, 연 산값이 프로세싱 엘리먼트에서 누산 될 수 있다. 그리고, 도 36를 참조하면, 제8 클럭 타임 동안, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w3_1와 제1 데이 터의 픽셀 데이터 i12을 입력 받는다. 그리고, 제1 프로세싱 엘리먼트(PE_00)는 제1 가중치 w3_1와 제1 데이터 의 픽셀 데이터 i12의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제1 프로세싱 엘리먼트 (PE_00)에 연결된 레지스터에는 w0_1*i01+ w1_1*i11+ w2_1*i02+ w3_1*i12의 값이 저장된다. 즉, 연산값이 프로 세싱 엘리먼트에서 누산 될 수 있다. 한편, 도 36를 참조하면, 제8 클럭 타임 동안, 제1 딜레이 버퍼에도 제1 데이터의 픽셀 데이터 i12이 입력 된다. 그리고, 제1 딜레이 버퍼는 제8 클럭 타임동안 제1 데이터의 픽셀 데이터 i12을 저장하여 이를 1클 럭만큼 딜레이시킨다. 그리고, 제8 클럭 타임 동안, 제2 프로세싱 엘리먼트(PE_10)는 제1 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i02를 입력 받고, 제2 가중치 w2_2을 입력 받는다. 그리고, 제2 프로세싱 엘리먼트(PE_10)는 제2 가중치 w2_2와 제1 데이터의 픽셀 데이터 i02의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제2 프로 세싱 엘리먼트(PE_10)에 연결된 레지스터에는 w0_2*i01+ w1_2*i11+ w2_2*i02의 값이 저장된다. 즉, 연산값이 프로세싱 엘리먼트에서 누산 될 수 있다. 그리고, 제2 딜레이 버퍼에는 제1 딜레이 버퍼로부터 1클럭만큼 딜레이된 제1 데이터의 픽셀 데이터 i02이 입력된다. 그리고, 제2 딜레이 버퍼는 제8 클럭 타임동안 제1 데이터의 픽셀 데이터 i02을 추가로 1 클럭만큼 딜레이시킨다. 즉, 제1 데이터의 픽셀 데이터 i02은 제1 딜레이 버퍼 및 제2 딜레이 버퍼를 통하여 2클럭만큼 딜레이 될 수 있다. 그리고, 제8 클럭 타임 동안, 제3 프로세싱 엘리먼트(PE_20)는 제2 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i11를 입력 받고, 제3 가중치 w1_3을 입력 받는다. 그리고, 제3 프로세싱 엘리먼트(PE_20)는 제3 가중치 w1_3와 제1 데이터의 픽셀 데이터 i11의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제3 프로 세싱 엘리먼트(PE_20)에 연결된 레지스터에는 w0_3*i01+ w1_3*i11의 값이 저장된다. 즉, 연산값이 프로세싱 엘 리먼트에서 누산 될 수 있다. 그리고, 제3 딜레이 버퍼에는 제2 딜레이 버퍼로부터 2클럭만큼 딜레이된 제1 데이터의 픽셀 데이터 i11이 입력된다. 그리고, 제3 딜레이 버퍼는 제8 클럭 타임동안 제1 데이터의 픽셀 데이터 i11을 추가로 1 클럭만큼 딜레이시킨다. 즉, 제1 데이터의 픽셀 데이터 i11은 제1 딜레이 버퍼, 제2 딜레이 버퍼 및 제3 딜레이 버퍼를 통하여 3클럭만큼 딜레이 될 수 있다. 그리고, 도 36을 참조하면, 제8 클럭 타임 동안 제4 프로세싱 엘리먼트(PE_30)에 연결된 레지스터에 저장된 w0_4*i00+ w1_4*i10+ w2_4*i01+w3_4*i11값의 값은 제2 데이터의 픽셀 데이터 o22로 출력된다. 그리고, 제8 클럭 타임 동안, 제4 프로세싱 엘리먼트(PE_30)는 제3 딜레이 버퍼로부터 제1 데이터의 픽셀 데이터 i01를 입력 받고, 제4 가중치 w0_4을 입력 받는다. 그리고, 제4 프로세싱 엘리먼트(PE_.30)는 제4 가중 치 w0_4와 제1 데이터의 픽셀 데이터 i01의 곱셈 연산을 수행하고, 연산 값을 레지스터에 저장한다. 즉, 제4 프 로세싱 엘리먼트(PE_30)에 연결된 레지스터에는 w0_4*i01이 저장된다. 이처럼 매 클럭마다 프로세싱 엘리먼트의 누산기에는 가중치와 픽셀 데이터가 곱셈 된 값이 누산 될 수 있다. 이처럼 딜레이 버퍼를 통해서 가중치가 다른 프로세싱 엘리먼트로 전달되는 방식으로 가중치를 재사용할 수 있 다. 따라서, 가중치 재사용에 의해서 신경 프로세싱 유닛의 소비 전력이 저감될 수 있다. 이처럼 각 PE에 특징맵 데이터(즉, 입력 특징맵 데이터) 및 가중치가 입력되면 각 PE에 입력된 특징맵 데이터 및 가중치에 대한 MAC 연산이 매 클럭 별 수행된다. 연산을 통해 산출된 연산 결과 데이터(즉, 출력 특징맵 데 이터)는 각 PE로부터 출력되어 내부 메모리 또는 특징맵 저장부에 저장될 수 있다. 즉, 각 PE는 가중치 및 특징맵 데이터를 입력 받아 가중치 및 특징맵 데이터에 대한 MAC 연산을 수행한다. 즉, 프로세싱 엘리먼트 어레이는 특징맵 데이터를 입력받는 제1 프로세싱 엘리먼트(PE_00), 특징맵 데이터를 입 력 받고 특정 클럭으로 딜레이하여 제2 프로세싱 엘리먼트(PE_10)으로 전달하도록 구성된 딜레이 버퍼(Z-k)을 포 함하도록 구성될 수 있다. 여기서 딜레이 버퍼의 딜레이 기간은 k 값으로 결정할 수 있다. 따라서, 딜레이 버퍼 는 특징맵 데이터를 재사용하면서 포인트와이즈 합성곱을 처리하도록 구성될 수 있다. 즉, 특징맵 데이터를 전달하는 하나의 딜레이 버퍼, 딜레이 버퍼의 입력과 출력에 대응되는 2개의 프로세싱 엘 리먼트를 제공함에 따라 데이터 재사용이 가능한 포인트 와이즈 합성곱을 구현할 수 있다. 한편, 도 17 내지 도 27에서 도시한 바와 같이, 해상도를 증가시키기 위하여 뎁스와이즈 합성곱 연산을 수행할 시 NPU는 복수의 PE 행렬로 구성된 프로세싱 엘리먼트 어레이 중 2개의 PE 행만을 이용하여 연산을 수행하므로, 연산을 위해 사용되지 않은 PE들이 존재하게 된다. 이에, 뎁스와이즈 합성곱 연산을 수행하는 프로세싱 엘리먼 트 어레이의 가동률이 저하될 수 있다. 하지만, 프로세싱 엘리먼트 어레이의 가동률이 저하될 경우, 신경 프로 세싱 유닛의 소비 전력을 저감 시킬 수 있다. 따라서, 신경 프로세싱 유닛은 소비 전력을 우선시할 때는 뎁스와이즈 합성곱으로 쌍선형 보간법을 수행하도록 동작할 수 있다. 이와 달리, 도 17 내지 도 27에서 도시한 바와 같이, 해상도를 증가시키기 위하여 포인트와이즈 합성곱 연산을 수행할 시 NPU는 보다 많은 개수의 PE행인 4개의 PE 행을 이용하여 연산을 수행하므로, 프로세싱 엘리먼트 어레이의 가동률이 상대적으로 향상될 수 있다. 따라서, 신경 프로세싱 유닛은 처리 속도를 우선시할 때는 포 인트와이즈 합성곱으로 쌍선형 보간법을 수행하도록 동작할 수 있다. 이에, 본 개시의 다른 일 예시에 따른 신경 프로세싱 유닛은 연산 속도가 향상될 수 있다. 전술한 바와 같은 과제를 해결하기 위하여 본 개시의 일 예시에 따른 신경 프로세싱 유닛이 제공된다. 신경 프로세싱 유닛은 제1 데이터의 해상도를 확장시켜 제2 데이터를 생성하기 위하여, 쌍선형 보간법(Bilinear Interpolation)을 수행하는 복수의 PE(Processing Element)를 포함하는 프로세싱 엘리먼트 어레이(PE Array)를 포함할 수 있다. 제1 데이터의 복수의 픽셀 데이터에 대하여 쌍선형 보간법(Bilinear Interpolation)에 해당하는 복수의 가중치 를 합성곱 연산하여 상기 제2 데이터의 복수의 픽셀 데이터를 가질 수 있다. 상기 복수의 가중치 각각의 원소는 쌍선형 보간법(Bilinear Interpolation)을 수행하기 위해 적어도 하나의 프 로세싱 엘리먼트에 입력되어 상기 제1 데이터의 복수의 픽셀 데이터에 곱해지는 계수일 수 있다. 쌍선형 보간법(Bilinear Interpolation)을 수행하여 생성되는 상기 제2 데이터의 복수의 픽셀은 상기 제1 데이 터의 복수의 픽셀 사이에 배치될 수 있다. 상기 제1 데이터의 외부에 배치되는 상기 제2 데이터의 복수의 픽셀 데이터를 연산하기 위하여, 상기 제1 데이 터의 최외측의 복수의 픽셀 데이터를 상기 제2 데이터의 외부로 복제할 수 있다. 신경망 프로세싱 유닛은 상기 PE Array의 출력단에 연결되고, 소수점 연산을 수행하는 소수점 곱셈기(Floating point multiplier)을 더 포함할 수 있다. 상기 PE Array는, 뎁스와이즈 합성곱 연산(depth-wise convolution)을 수행하도록 구성될 수 있다. 신경망 프로세싱 유닛은 상기 복수의 가중치를 특정 클럭만큼 딜레이하여 출력하는 직렬 연결된 복수의 딜레이 버퍼를 더 포함할 수 있다. 상기 복수의 가중치는 상기 PE Array 중 첫번째 행에 배치된 PE들 및 상기 복수의 딜레이 버퍼에 브로드캐스트 되도록 구성될 수 있다. 상기 복수의 딜레이 버퍼에 의해 딜레이된 가중치는 상기 PE Array 중 두번째 행에 배치된 PE들에 출력되어, 상 기 가중치는 재사용되도록 구성될 수 있다. 상기 PE Array는, 포인트와이즈 합성곱 연산(point-wise convolution)을 수행하도록 구성될 수 있다. 상기 복수의 가중치 각각은 상기 PE Array 중 서로 다른 행에 배치된 PE들에 브로드캐스트 되도록 구성될 수 있 다. 신경망 프로세싱 유닛은 상기 제1 데이터의 픽셀 데이터를 특정 클럭만큼 딜레이하여 출력하는 직렬 연결된 복 수의 딜레이 버퍼를 더 포함할 수 있다. 상기 제1 데이터의 복수의 픽셀 데이터는 상기 PE Array 중 첫번째 행에 배치된 PE들 및 상기 복수의 딜레이 버 퍼에 캐스트 되도록 구성될 수 있다. 상기 복수의 딜레이 버퍼에 의해 딜레이된 제1 데이터의 복수의 픽셀 데이터는 상기 PE Array 중 다음행에 배치 된 PE들에 출력되어, 상기 제1 데이터의 복수의 픽셀 데이터는 재사용되도록 구성될 수 있다. 본 명세서와 도면에 게시된 본 개시의 예시들은 본 개시의 기술내용을 쉽게 설명하고 본 개시의 이해를 돕기 위 해 특정 예를 제시한 것뿐이며, 본 명의 범위를 한정하고자 하는 것은 아니다. 여기에 게시된 예시들 이외에도 발명의 기술적 사상에 바탕을 둔 다른 변형 예들이 실시 가능하다는 것은 본 개시가 속하는 기술 분야에서 통상 의 지식을 가진 자에게 자명한 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21 도면22 도면23 도면24 도면25 도면26 도면27 도면28 도면29 도면30 도면31 도면32 도면33 도면34 도면35 도면36"}
{"patent_id": "10-2023-0118599", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 예시에 따른 신경 프로세싱 유닛이 포함된 장치를 설명하는 개략적인 개념도이다. 도 2는 본 개시에 관련된 컴파일러를 설명하는 개략적인 개념도이다. 도 3은 본 개시에 관련된 합성곱 신경망을 설명하는 개략적인 개념도이다. 도 4는 본 개시의 일 예시에 따른 신경 프로세싱 유닛을 설명하는 개략적인 개념도이다. 도 5는 본 개시에 적용될 수 있는 쌍선형 보간법(Bilinear Interpolation)을 설명하는 개략적인 개념도이다. 도 6은 본 개시에 적용될 수 있는 제2 데이터의 정렬 방식을 설명하는 개략적인 개념도이다. 도 7은 본 개시에서 쌍선형 보간법(Bilinear Interpolation)을 적용하여 제2 데이터의 제1 픽셀 데이터를 생성 하는 방법을 설명하기 위한 개념도이다. 도 8은 본 개시에서 쌍선형 보간법(Bilinear Interpolation)을 적용하여 제2 데이터의 제2 픽셀 데이터를 생성 하는 방법을 설명하기 위한 개념도이다. 도 9는 본 개시에서 쌍선형 보간법(Bilinear Interpolation)을 적용하여 제2 데이터의 제3 픽셀 데이터를 생성 하는 방법을 설명하기 위한 개념도이다. 도 10은 본 개시에서 쌍선형 보간법(Bilinear Interpolation)을 적용하여 제2 데이터의 제4 픽셀 데이터를 생성 하는 방법을 설명하기 위한 개념도이다. 도 11은 본 개시에 적용될 수 있는 제1 데이터를 외부에 복제하는 방법을 설명하는 개략적인 개념도이다. 도 12는 본 개시에 적용될 수 있는 프로세싱 엘리먼트 어레이 중 하나의 프로세싱 엘리먼트를 설명하는 개략적 인 개념도이다. 도 13은 본 개시의 일 예시에 따른 프로세싱 엘리먼트 어레이 중 하나의 프로세싱 엘리먼트를 설명하는 구성도 이다. 도 14는 본 개시의 일 예시에 따른 프로세싱 엘리먼트 어레이에 입력되는 입력 데이터 및 출력 데이터를 나타내 는 도면이다. 도 15는 일 예시에 따른 프로세싱 엘리먼트 어레이에 입력되는 입력 데이터와 출력 데이터의 배치 관계를 나타 내는 도면이다. 도 16은 본 개시의 일 예시에 따른 프로세싱 엘리먼트 어레이의 구조를 나타내는 개략적인 구성도이다. 도 17 내지 도 27은 본 개시의 일 예시에 따른 프로세싱 엘리먼트 어레이가 복수의 클럭 동안 동작하는 방식을 설명하기 위만 도면이다.도 28은 본 개시의 다른 예시에 따른 프로세싱 엘리먼트 어레이의 구조를 나타내는 개략적인 구성도이다. 도 29 내지 도 36은 본 개시의 일 예시에 따른 프로세싱 엘리먼트 어레이가 복수의 클럭 동안 동작하는 방식을 설명하기 위만 도면이다."}
