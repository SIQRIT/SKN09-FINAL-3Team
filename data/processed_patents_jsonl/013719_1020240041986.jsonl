{"patent_id": "10-2024-0041986", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0149325", "출원번호": "10-2024-0041986", "발명의 명칭": "동영상 처리 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "송영찬"}}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "동영상 처리 방법에 있어서,제1 프레임으로부터 제1 특징 데이터를 추출하는 단계;하나 이상의 제2 프레임으로부터 하나 이상의 제2 특징 데이터를 추출하는 단계;하나 이상의 프레임 페어(frame pair) 각각에 대응하는 하나 이상의 양방향 모션(bi-directional motion) 정보를 획득하는 단계로서, 상기 하나 이상의 프레임 페어 각각은 상기 제1 프레임, 및 상기 하나 이상의 제2 프레임 중 대응하는 제2 프레임을 포함하고;상기 하나 이상의 양방향 모션 정보에 기초하여 하나 이상의 특징 페어(feature pair) 각각에 제1 특징 처리를수행하여 하나 이상의 제3 특징 데이터를 획득하는 단계로서, 상기 하나 이상의 특징 페어 각각은 상기 제1 특징 데이터, 및 상기 하나 이상의 제2 특징 데이터 중 대응하는 제2 특징 데이터를 포함하고;상기 하나 이상의 양방향 모션 정보에 기초하여 상기 하나 이상의 제3 특징 데이터에 제2 특징 처리를 수행하여하나 이상의 제4 특징 데이터를 획득하는 단계;상기 제1 특징 데이터 및 상기 하나 이상의 제4 특징 데이터에 기초하여 제5 특징 데이터를 획득하는 단계; 및상기 제5 특징 데이터에 기초하여 제3 프레임을 생성하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 하나 이상의 양방향 모션 정보에 기초하여 하나 이상의 특징 페어(feature pair) 각각에 제1 특징 처리를수행하여 하나 이상의 제3 특징 데이터를 획득하는 단계는,상기 하나 이상의 양방향 모션 정보에 기초하여 상기 하나 이상의 제2 특징 데이터를 와핑하는 단계,상기 제1 특징 데이터 및 상기 와핑된 하나 이상의 제2 특징 데이터를 패치 임베딩으로 변환하는 단계로서, 상기 패치 임베딩은 상기 제1 특징 데이터로부터 변환된 제1 패치 임베딩, 및 상기 와핑된 하나 이상의 제2 특징데이터로부터 변환된 제2 패치 임베딩을 포함하고, 상기 제1 및 제2 패치 임베딩은 각각 소정의 크기의 복수의패치를 포함하고,상기 패치 임베딩에 대하여 어텐션(attention)을 수행하는 단계, 및상기 어텐션 결과에 기초하여 상기 하나 이상의 제3 특징 데이터를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서,상기 패치 임베딩에 대하여 어텐션(attention)을 수행하는 단계는,상기 제1 패치 임베딩에 기초하여 쿼리(query)를 획득하는 단계,상기 제2 패치 임베딩에 기초하여 키(key) 및 밸류(value)를 획득하는 단계,상기 쿼리 및 상기 키에 기초하여 가중치를 계산하는 단계, 및상기 밸류에 상기 가중치를 적용하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "공개특허 10-2024-0149325-3-제1항 내지 제3항 중 어느 한 항에 있어서,상기 패치 임베딩에 대하여 어텐션(attention)을 수행하는 단계는,상기 패치 임베딩에 포함된 복수의 패치에 대하여 패치 단위로 제1 어텐션을 수행하는 단계, 및상기 패치 임베딩에 포함된 복수의 패치에 대하여 픽셀 단위로 제2 어텐션을 수행하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서,상기 하나 이상의 양방향 모션 정보에 기초하여 상기 하나 이상의 제3 특징 데이터에 제2 특징 처리를 수행하여하나 이상의 제4 특징 데이터를 획득하는 단계는,상기 하나 이상의 양방향 모션 정보에 기초하여 하나 이상의 변환 파라미터를 획득하는 단계, 및상기 하나 이상의 변환 파라미터에 기초하여 상기 하나 이상의 제3 특징 데이터에 소정의 변환 동작을 통해 상기 하나 이상의 제4 특징 데이터를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항 중 어느 한 항에 있어서,상기 하나 이상의 변환 파라미터는 스케일 인자(scale factor) 및 바이어스(bias)를 포함하고,상기 소정의 변환 동작은 상기 하나 이상의 제3 특징 데이터에 상기 스케일 인자를 곱하고, 곱셈 결과에 상기바이어스를 합산하는 것을 포함하는, 방법."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서,상기 제1 특징 데이터 및 상기 하나 이상의 제4 특징 데이터에 기초하여 제5 특징 데이터를 획득하는 단계는,상기 하나 이상의 제4 특징 데이터를 연결하는 단계,상기 연결된 하나 이상의 제4 특징 데이터에 컨볼루션 연산을 수행하는 단계, 및상기 컨볼루션 연산 결과에 상기 제1 특징 데이터를 합산하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,상기 제1 특징 데이터에 제3 특징 처리를 수행하여 제6 특징 데이터를 획득하는 단계; 및상기 하나 이상의 제4 특징 데이터 및 상기 제6 특징 데이터에 기초하여 상기 제5 특징 데이터를 획득하는단계;를 더 포함하는, 방법."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서,상기 양방향 모션 정보는 상기 제1 프레임에서 상기 대응하는 제2 프레임으로의 제1 모션 정보, 및 상기 대응하는 제2 프레임에서 상기 제1 프레임으로의 제2 모션 정보를 포함하는, 방법."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터에 의해 실행될 때, 상기 컴퓨터가 제1항 내지 제9항 중 어느 한 항의 방법을 수행하게 하는, 하나 이상의 인스트럭션을 저장하는 컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2024-0149325-4-전자 장치(1200)에 있어서,적어도 하나의 프로세서(1210); 및하나 이상의 인스트럭션을 저장하는 메모리(1220);를 포함하고,상기 적어도 하나의 프로세서(1210)는 상기 하나 이상의 인스트럭션을 실행함으로써 상기 전자 장치(1200)가,제1 프레임으로부터 제1 특징 데이터를 추출하고,하나 이상의 제2 프레임으로부터 하나 이상의 제2 특징 데이터를 추출하고,하나 이상의 프레임 페어(frame pair) 각각에 대응하는 하나 이상의 양방향 모션(bi-directional motion) 정보를 획득하고, 상기 하나 이상의 프레임 페어 각각은 상기 제1 프레임, 및 상기 하나 이상의 제2 프레임 중 대응하는 제2 프레임을 포함하고,상기 하나 이상의 양방향 모션 정보에 기초하여 하나 이상의 특징 페어(feature pair) 각각에 제1 특징 처리를수행하여 하나 이상의 제3 특징 데이터를 획득하고, 상기 하나 이상의 특징 페어 각각은 상기 제1 특징 데이터,및 상기 하나 이상의 제2 특징 데이터 중 대응하는 제2 특징 데이터를 포함하고,상기 하나 이상의 양방향 모션 정보에 기초하여 상기 하나 이상의 제3 특징 데이터에 제2 특징 처리를 수행하여하나 이상의 제4 특징 데이터를 획득하고,상기 제1 특징 데이터 및 상기 하나 이상의 제4 특징 데이터에 기초하여 제5 특징 데이터를 획득하고, 및상기 제5 특징 데이터에 기초하여 제3 프레임을 생성하는 것을 포함하는 동작을 수행하게 하는, 전자 장치."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 하나 이상의 양방향 모션 정보에 기초하여 하나 이상의 특징 페어(feature pair) 각각에 제1 특징 처리를수행하여 하나 이상의 제3 특징 데이터를 획득하는 것은,상기 하나 이상의 양방향 모션 정보에 기초하여 상기 하나 이상의 제2 특징 데이터를 와핑하고,상기 제1 특징 데이터 및 상기 와핑된 하나 이상의 제2 특징 데이터를 패치 임베딩으로 변환하고, 상기 패치 임베딩은 상기 제1 특징 데이터로부터 변환된 제1 패치 임베딩, 및 상기 와핑된 하나 이상의 제2 특징 데이터로부터 변환된 제2 패치 임베딩을 포함하고, 상기 제1 및 제2 패치 임베딩은 각각 소정의 크기의 복수의 패치를 포함하고,상기 패치 임베딩에 대하여 어텐션(attention)을 수행하고, 및상기 어텐션 결과에 기초하여 상기 하나 이상의 제3 특징 데이터를 획득하는 것을 포함하는, 전자 장치."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항 또는 제12항에 있어서,상기 패치 임베딩에 대하여 어텐션(attention)을 수행하는 것은,상기 제1 패치 임베딩에 기초하여 쿼리(query)를 획득하고,상기 제2 패치 임베딩에 기초하여 키(key) 및 밸류(value)를 획득하고,상기 쿼리 및 상기 키에 기초하여 가중치를 계산하고, 및상기 밸류에 상기 가중치를 적용하는 것을 포함하는, 전자 장치."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항 내지 제13항 중 어느 한 항에 있어서,공개특허 10-2024-0149325-5-상기 패치 임베딩에 대하여 어텐션(attention)을 수행하는 것은,상기 패치 임베딩에 포함된 복수의 패치에 대하여 패치 단위로 제1 어텐션을 수행하고, 및상기 패치 임베딩에 포함된 복수의 패치에 대하여 픽셀 단위로 제2 어텐션을 수행하는 것을 포함하는, 전자 장치."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항 내지 제14항 중 어느 한 항에 있어서,상기 하나 이상의 양방향 모션 정보에 기초하여 상기 하나 이상의 제3 특징 데이터에 제2 특징 처리를 수행하여하나 이상의 제4 특징 데이터를 획득하는 것은,상기 하나 이상의 양방향 모션 정보에 기초하여 하나 이상의 변환 파라미터를 획득하고, 및상기 하나 이상의 변환 파라미터에 기초하여 상기 하나 이상의 제3 특징 데이터에 소정의 변환 동작을 통해 상기 하나 이상의 제4 특징 데이터를 획득하는 것을 포함하는, 전자 장치."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항 내지 제15항 중 어느 한 항에 있어서,상기 하나 이상의 변환 파라미터는 스케일 인자(scale factor) 및 바이어스(bias)를 포함하고,상기 소정의 변환 동작은 상기 하나 이상의 제3 특징 데이터에 상기 스케일 인자를 곱하고, 곱셈 결과에 상기바이어스를 합산하는 것을 포함하는, 전자 장치."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항 내지 제16항 중 어느 한 항에 있어서,상기 제1 특징 데이터 및 상기 하나 이상의 제4 특징 데이터에 기초하여 제5 특징 데이터를 획득하는 것은,상기 하나 이상의 제4 특징 데이터를 연결하고,상기 연결된 하나 이상의 제4 특징 데이터에 컨볼루션 연산을 수행하고, 및상기 컨볼루션 연산 결과에 상기 제1 특징 데이터를 합산하는 것을 포함하는, 전자 장치."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항 내지 제17항 중 어느 한 항에 있어서,상기 동작은,상기 제1 특징 데이터에 제3 특징 처리를 수행하여 제6 특징 데이터를 획득하고, 및상기 하나 이상의 제4 특징 데이터 및 상기 제6 특징 데이터에 기초하여 상기 제5 특징 데이터를 획득하는 것을더 포함하는, 전자 장치."}
{"patent_id": "10-2024-0041986", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항 내지 제18항 중 어느 한 항에 있어서,상기 양방향 모션 정보는 상기 제1 프레임에서 상기 대응하는 제2 프레임으로의 제1 모션 정보, 및 상기 대응하는 제2 프레임에서 상기 제1 프레임으로의 제2 모션 정보를 포함하는, 전자 장치."}
{"patent_id": "10-2024-0041986", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "제1 프레임으로부터 제1 특징 데이터를 추출하는 단계, 하나 이상의 제2 프레임으로부터 하나 이상의 제2 특징 데이터를 추출하는 단계, 하나 이상의 프레임 페어(frame pair) 각각에 대응하는 하나 이상의 양방향 모션(bi- directional motion) 정보를 획득하는 단계로서, 상기 하나 이상의 프레임 페어 각각은 상기 제1 프레임, 및 상 (뒷면에 계속)"}
{"patent_id": "10-2024-0041986", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공 신경망을 이용한 동영상 처리 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2024-0041986", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "컴퓨터 기술의 발달과 함께 데이터 트래픽이 지수함수 형태로 증가하면서 인공지능 기술은 미래 혁신을 주도하 는 중요한 트렌드로 자리잡았다. 인공지능 기술은 사람의 사고방식을 모방하기 때문에 사실상 모든 산업에서 무 한한 응용이 가능하다. 인공지능 기술의 대표적인 예시로는 패턴 인식, 기계 학습, 전문가 시스템, 인공 신경망, 자연어 처리 등이 있다. 인공 신경망은 사람의 신경 세포의 특성을 수학적 표현에 의해 모델링한 것으로, 사람의 학습 능력을 모방한 알 고리즘을 이용한다. 이러한 알고리즘을 통해, 인공 신경망은 입력 데이터와 출력 데이터 사이의 사상(mapping) 을 생성할 수 있고, 사상을 생성하는 능력은 신경망의 학습 능력이라고 표현될 수 있다. 또한 신경망은 학습된 결과에 기초하여 학습에 이용되지 않았던 입력 데이터에 대하여 올바른 출력 데이터를 생성할 수 있는 일반화 능력을 갖는다. 인공 신경망은 동영상 처리에 이용될 수 있다. 특히, 인공 신경망은 동영상의 노이즈(noise) 또는 아티팩트 (artifact)를 제거하거나, 동영상의 해상도를 증가시키기 위해 이용될 수 있다. 동영상을 구성하는 각 프레임은 반복적으로 나타나는 정보(예: 크기, 모양 및/또는 구조가 동일 또는 유사한 객체(object), 선(line) 또는 가장 자리(edge) 등)를 포함할 수 있으며, 이러한 반복 정보는 동영상 처리 시 유용하게 활용될 수 있다. 또한 동영 상에 포함된 인접한 프레임들은 시간의 변화에 대한 정보를 포함하고 있으므로, 인접한 프레임들에서 공통된 반 복 정보가 나타날 수 있다. 따라서 동영상 처리 시 인접한 프레임들에서 공통적으로 나타나는 반복 정보를 효과 적이고 효율적으로 활용할 수 있는 방안이 필요하다."}
{"patent_id": "10-2024-0041986", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 따르면, 동영상 처리 방법은 제1 프레임으로부터 제1 특징 데이터를 추출하는 단계, 하나 이상의 제2 프레임으로부터 하나 이상의 제2 특징 데이터를 추출하는 단계, 하나 이상의 프레임 페어(frame pair) 각각에 대응하는 하나 이상의 양방향 모션(bi-directional motion) 정보를 획득하는 단계로서, 상기 하나 이상의 프레임 페어 각각은 상기 제1 프레임, 및 상기 하나 이상의 제2 프레임 중 대응하는 제2 프레임을 포함 하고, 상기 하나 이상의 양방향 모션 정보에 기초하여 하나 이상의 특징 페어(feature pair) 각각에 제1 특징 처리를 수행하여 하나 이상의 제3 특징 데이터를 획득하는 단계로서, 상기 하나 이상의 특징 페어 각각은 상기 제1 특징 데이터, 및 상기 하나 이상의 제2 특징 데이터 중 대응하는 제2 특징 데이터를 포함하고, 상기 하나 이상의 양방향 모션 정보에 기초하여 상기 하나 이상의 제3 특징 데이터에 제2 특징 처리를 수행하여 하나 이상 의 제4 특징 데이터를 획득하는 단계, 상기 제1 특징 데이터 및 상기 하나 이상의 제4 특징 데이터에 기초하여 제5 특징 데이터를 획득하는 단계, 및 상기 제5 특징 데이터에 기초하여 제3 프레임을 생성하는 단계를 포함할 수 있다. 본 개시의 일 측면에 따르면, 컴퓨터 판독 가능한 기록매체는 컴퓨터에 의해 실행될 때, 상기 컴퓨터가, 제1 프 레임으로부터 제1 특징 데이터를 추출하는 단계, 하나 이상의 제2 프레임으로부터 하나 이상의 제2 특징 데이터 를 추출하는 단계, 하나 이상의 프레임 페어(frame pair) 각각에 대응하는 하나 이상의 양방향 모션(bi- directional motion) 정보를 획득하는 단계로서, 상기 하나 이상의 프레임 페어 각각은 상기 제1 프레임, 및 상 기 하나 이상의 제2 프레임 중 대응하는 제2 프레임을 포함하고, 상기 하나 이상의 양방향 모션 정보에 기초하 여 하나 이상의 특징 페어(feature pair) 각각에 제1 특징 처리를 수행하여 하나 이상의 제3 특징 데이터를 획 득하는 단계로서, 상기 하나 이상의 특징 페어 각각은 상기 제1 특징 데이터, 및 상기 하나 이상의 제2 특징 데 이터 중 대응하는 제2 특징 데이터를 포함하고, 상기 하나 이상의 양방향 모션 정보에 기초하여 상기 하나 이상 의 제3 특징 데이터에 제2 특징 처리를 수행하여 하나 이상의 제4 특징 데이터를 획득하는 단계, 상기 제1 특징 데이터 및 상기 하나 이상의 제4 특징 데이터에 기초하여 제5 특징 데이터를 획득하는 단계, 및 상기 제5 특징 데이터에 기초하여 제3 프레임을 생성하는 단계를 포함할 수 있는 방법을 수행하게 하는, 하나 이상의 인스트럭 션을 저장한다. 본 개시의 일 측면에 따르면, 전자 장치는 적어도 하나의 프로세서, 및 하나 이상의 인스트럭션을 저장하는 메 모리를 포함하고, 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써 상기 전자 장치 가, 제1 프레임으로부터 제1 특징 데이터를 추출하고, 하나 이상의 제2 프레임으로부터 하나 이상의 제2 특징 데이터를 추출하고, 하나 이상의 프레임 페어(frame pair) 각각에 대응하는 하나 이상의 양방향 모션(bi- directional motion) 정보를 획득하고, 상기 하나 이상의 프레임 페어 각각은 상기 제1 프레임, 및 상기 하나 이상의 제2 프레임 중 대응하는 제2 프레임을 포함하고, 상기 하나 이상의 양방향 모션 정보에 기초하여 하나이상의 특징 페어(feature pair) 각각에 제1 특징 처리를 수행하여 하나 이상의 제3 특징 데이터를 획득하고, 상기 하나 이상의 특징 페어 각각은 상기 제1 특징 데이터, 및 상기 하나 이상의 제2 특징 데이터 중 대응하는 제2 특징 데이터를 포함하고, 상기 하나 이상의 양방향 모션 정보에 기초하여 상기 하나 이상의 제3 특징 데이 터에 제2 특징 처리를 수행하여 하나 이상의 제4 특징 데이터를 획득하고, 상기 제1 특징 데이터 및 상기 하나 이상의 제4 특징 데이터에 기초하여 제5 특징 데이터를 획득하고, 및 상기 제5 특징 데이터에 기초하여 제3 프 레임을 생성하는 것을 포함할 수 있는 동작을 수행하게 할 수 있다."}
{"patent_id": "10-2024-0041986", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에서, “a, b 및 c 중 적어도 하나”의 표현은 “a”, “b”, “c”, “a 및 b”, “a 및 c”, “b 및 c ”, “a, b 및 c 모두”, 또는 그 변형들을 지칭할 수 있다. 본 개시에서 사용되는 용어는 실시예에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 개시의 전반에 걸친 내용을 토대로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는 데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용 된다. 예를 들어, 실시예의 권리범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유 사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 문맥상 명백하게 다르게 지시하지 않는 한, 단수의 형태 \"a,\" \"an,\" 및 \"the\"는 복수의 대상을 포함한다고 이해 될 수 있다. 따라서, 예를 들어, \"구성 표면(a component surface)\"이라는 기재는 그러한 표면들 중 하나 이상 을 가리키는 경우도 포함할 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인"}
{"patent_id": "10-2024-0041986", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 본 개시에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 본 개시에서 ‘~부(유닛)’, ‘모듈’ 등으로 표현되는 구성요소는 2개 이상의 구성요소가 하나의 구성요소로 합쳐지거나 또는 하나의 구성요소가 보다 세분화된 기능별로 2개 이상으로 분화될 수도 있다. 또한 이하에서 설 명할 구성요소 각각은 자신이 담당하는 주기능 이외에도 다른 구성요소가 담당하는 기능 중 일부 또는 전부의 기능을 추가적으로 수행할 수도 있으며, 구성요소 각각이 담당하는 주기능 중 일부 기능이 다른 구성요소에 의 해 전담되어 수행될 수도 있음은 물론이다. 본 개시에 설명된 모든 기능이나 동작은 하나의 프로세서 또는 프로세서들의 조합에 의해 처리될 수 있다. 하나 의 프로세서 또는 프로세서들의 조합은 처리를 수행하는 회로 장치(circuitry)로서, AP(Application Processor), CP(Communication Processor), GPU(Graphic Processing Unit), NPU(Neural Processing Unit), MPU(Microprocessor Unit), SoC(System on Chip), IC(Integrated Chip) 등과 같은 회로 장치를 포함할 수 있다. 본 개시에서, 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작될 수 있다. 프로세서는 하나 또는 복수 의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리할 수 있다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로 세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특정(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 할 수 있다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서 버 및/또는 시스템을 통해 이루어질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습 (reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들에 포함된 복수의 가중치들은 인공지능 모델의 학습 결과에 의해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값 이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공신경망은 심층신경망(DNN: Deep Neural Network)을 포함할 수 있으며, 예를 들어, CNN(Convolutional Neural Network), DNN(Deep Neural Network), RNN(Recurrent Neural Network), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 DQN(Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 개시에서, 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다 는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경 우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 본 개시에서, 각각의 순서도에서의 블록들 및 순서도들의 조합들은 컴퓨터 실행 가능 명령어들을 포함하는 하나 이상의 컴퓨터 프로그램들에 의해 수행될 수 있다고 이해되어야 한다. 하나 이상의 컴퓨터 프로그램들은 단일 메모리에 모두 저장되거나, 또는 서로 다른 다수의 메모리들에 분할되어 저장될 수 있다. 일 실시예에 따르면, 본 개시에 설명된 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제 공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또 는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더블 앱 (downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2024-0041986", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이하에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 도 1은 본 개시의 일 실시예에 따른, 동영상 처리 네트워크를 도시한다. 도 1을 참조하면, 동영상 처리 네트워크는 동영상을 처리하기 위해 제1 프레임 및 하나 이상의 제2 프 레임을 입력 받고, 제3 프레임을 출력할 수 있다. 동영상의 처리는, 예를 들어, 새로운 프레임을 생성 하고 생성된 프레임을 기존의 프레임 사이에 삽입하는 프레임 보간(frame interpolation), 블러(blur) 등의 잡 음을 제거하는 디노이징(denoising), 또는 저해상도(예: 1920x1080)의 동영상을 고해상도(예: 3840x2160)의 동 영상으로 변환하는 초해상도(super resolution) 등을 포함할 수 있으나, 이에 제한되는 것은 아니다. 일 실시예에서, 제1 프레임은 처리의 대상인 타겟 프레임이다. 예를 들어, 제1 프레임은 노이즈 또는 아티팩트를 포함하는 이미지, 저해상도 이미지, 또는 저화질 이미지일 수 있다. 일 실시예에서, 하나 이상의 제2 프레임은 제1 프레임을 처리하기 위하여 사용되는 참조 프레임일 수 있다. 예를 들어, 참조 프레임은 인접 프레임, 주변 프레임, 근처 프레임, 이웃 프레임, 또는 가까운 프레임 등 으로 지칭될 수 있다. 하나 이상의 제2 프레임은 제1 프레임과 연속된 하나 이상의 프레임을 포함할 수 있으나, 반드시 제1 프레임과 연속된 프레임만을 지칭하는 것은 아니다. 예를 들어 하나 이상의 제2 프레임 은 제1 프레임과 동일한 장면(scene)에 포함된 하나 이상의 프레임일 수 있다. 이 경우, 제1 프레임 과 하나 이상의 제2 프레임이 동일한 장면에 포함되었는지 여부는 동영상의 메타 정보에 기초하여 식별 될 수 있다. 본 개시에서는 설명의 편의를 위해, 도 1에 도시된 바와 같이, 제1 프레임이 t번째 프레임()이고, 하나 이상의 제2 프레임이 t-2번째 프레임(), t-1번째 프레임(), t+1번째 프레임(), 및 t+2번째 프 레임()인 예시가 설명되지만, 제2 프레임의 개수, 및 제1 프레임과 하나 이상의 제2 프레임의 순서는 이에 제한되지 않는다. 예를 들어, 동영상 처리 네트워크는 t-1번째 프레임 및 t+2번째 프레임을 제2 프레임으로 활용할 수도 있다. 일 실시예에서, 제3 프레임은 제1 프레임이 동영상 처리 네트워크에 의해 처리된 결과로서 생성되 는 프레임이다. 예를 들어, 제3 프레임은 제1 프레임에서 노이즈 또는 아티팩트가 제거된 이미지, 제1 프레임보다 고해상도 이미지, 또는 제1 프레임보다 고화질 이미지일 수 있다. 일 실시예에서, 동영상 처리 네트워크는 특징 추출 네트워크, 모션 추정 모듈, 특징 처리 네트 워크 및 동영상 복원 네트워크를 포함할 수 있다. 다만, 동영상 처리 네트워크의 구성요소는 이 에 제한되지 않으며, 동영상 처리 네트워크는 도 1에 도시된 구성요소 중 일부를 포함하지 않을 수도 있고, 도 1에 도시된 것 이외에 다른 구성요소를 더 포함할 수도 있다. 일 실시예에서, 특징 추출 네트워크는 입력되는 프레임으로부터 특징 데이터를 추출할 수 있다. 예를 들어, 특징 추출 네트워크는 제1 프레임으로부터 제1 특징 데이터()를 추출할 수 있고, 하나 이상 의 제2 프레임으로부터 하나 이상의 제2 특징 데이터(, , , )를 추출할 수 있다. 특징 추출 네트워크는 하나 이상의 컨볼루션 신경망을 포함할 수 있다. 일 실시예에서, 특징 추출 네트워크는 제1 프레임 및 하나 이상의 제2 프레임으로부터 제1 특징 데이터 및 하나 이상의 제2 특징 데이터를 추출하는 하나의 네트워크일 수 있다. 일 실시예에서, 특징 추출 네트워크는 제1 프레임 및 하나 이상의 제2 프레임에 대응하는 복수의 특징 추출 서브네트워크(미도시)를 포함할 수 있다. 예를 들어, 도 1의 예시에서, 특징 추출 네트워크는제1 프레임()으로부터 제1 특징 데이터()를 추출하는 제1 특징 추출 서브네트워크, 제2 프레임()으로 부터 제2 특징 데이터()를 추출하는 제2 특징 추출 서브네트워크, 제2 프레임()으로부터 제2 특징 데이 터()를 추출하는 제3 특징 추출 서브네트워크, 제2 프레임()으로부터 제2 특징 데이터()를 추출하 는 제4 특징 추출 서브네트워크, 제2 프레임()으로부터 제2 특징 데이터()를 추출하는 제5 특징 추출 서브네트워크를 포함할 수 있다. 이 경우, 복수의 특징 추출 서브네트워크 각각은 하나 이상의 컨볼루션 신경망 을 포함할 수 있다. 일 실시예에서, 모션 추정 모듈은 입력되는 프레임 페어(frame pair)에 대하여 양방향 모션 추정을 수행할 수 있다. 여기서, 프레임 페어는 제1 프레임, 및 하나 이상의 제2 프레임 중 대응하는 제2 프레임 을 포함할 수 있다. 예를 들어, 도 1의 예시에서, 모션 추정 모듈은 t번째 프레임 및 t-2번째 프레임을 포 함하는 제1 프레임 페어, t번째 프레임 및 t-1번째 프레임을 포함하는 제2 프레임 페어, t번째 프레임 및 t+1번 째 프레임을 포함하는 제3 프레임 페어, 및 t번째 프레임 및 t+2번째 프레임을 포함하는 제4 프레임 페어에 대 하여 각각 양방향 모션 추정을 수행할 수 있다. 본 개시에서, 양방향 모션 추정 결과는 양방향 모션 정보로 지 칭될 수 있다. 일 실시예에서, 양방향 모션 정보는 제1 프레임에서 제2 프레임으로의 제1 모션 정보( ), 및 제 2 프레임에서 제1 프레임으로의 제2 모션 정보( )를 포함할 수 있다. 도 1의 예시에서, i는 -2, -1, +1 및 +2이다. 예를 들어, 제1 모션 정보 및 제2 모션 정보는 제1 프레임 및 제2 프레임 사이에서 객체의 위치 변화를 나타내는 벡터, 좌표, 또는 변환 행렬 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 모션 추정 모듈은 인공 신경망 모델(예: 컨볼루션 신경망을 이용하여 광 흐름(optical flow)을 예측하는 모델 또는 트랜스포머에 기반한 모델 등)로 구현될 수도 있고, 인공 신경망을 사용하지 않는 알고리즘(예: Lucas-Kanade 방법, Horn-Schunck 알고리즘, 다항식 피팅(polynomial fitting), 칼만 필터 (Karman filter) 등)으로 구현될 수도 있다. 일 실시예에서, 특징 처리 네트워크는 양방향 모션 정보에 기초하여 입력되는 특징 데이터를 처리할 수 있 다. 특징 처리 네트워크에 입력되는 특징 데이터는 제1 특징 데이터 및 하나 이상의 제2 특징 데이터를 포 함할 수 있다. 일 실시예에서, 특징 처리 네트워크는, 양방향 모션 정보에 기초하여, 특징 페어(feature pair)에 대하여 어텐션(attention)을 포함하는 특징 처리를 수행하여 제3 특징 데이터를 획득할 수 있다. 여기서, 특징 페어는 제1 특징 데이터, 및 하나 이상의 제2 특징 데이터 중 대응하는 제2 특징 데이터를 포함할 수 있다. 예를 들어, 도 1의 예시에서, 특징 처리 네트워크는 제1 특징 데이터() 및 제2 특징 데이터()를 포함하는 제1 특징 페어, 제1 특징 데이터() 및 제2 특징 데이터()를 포함하는 제2 특징 페어, 제1 특징 데이터() 및 제2 특징 데이터()를 포함하는 제3 특징 페어, 및 제1 특징 데이터() 및 제2 특징 데이터()를 포함하는 제4 특징 페어에 대하여 어텐션을 포함하는 특징 처리를 수행할 수 있다. 일 실시예에서, 어텐션은 입력되는 특징 데이터에 기초하여 쿼리(query), 키(key), 밸류(value)라고 지칭되는 투영된 특징 데이터를 획득하고, 쿼리와 키 사이의 상관관계(correlation)에 대응하는 가중치를 계산하고, 밸류 에 가중치를 적용하는 연산을 포함할 수 있다. 일 실시예에서, 특징 처리 네트워크는, 양방향 모션 정보에 기초하여, 제3 특징 데이터에 대하여 특징 변 환(feature transformation)을 포함하는 특징 처리를 수행하여 제4 특징 데이터를 획득할 수 있다. 여기서, 특 징 변환은 2개의 프레임 간의 양방향 모션 정보의 일관성(consistency)에 기초하여 대응하는 제3 특징 데이터를 변조하는 과정으로 이해될 수 있다. 예를 들어, 특징 변환은 양방향 모션 정보에 기초하여 스케일 인자 및 바이 어스를 획득하고, 획득된 스케일 인자 및 바이어스에 기초하여 제3 특징 데이터를 변환하는 것을 포함할 수 있 다. 특징 처리 네트워크의 구조 및 동작의 예시는 도 2 내지 도 10을 참조하여 후술된다. 일 실시예에서, 동영상 복원 네트워크는 입력되는 특징 데이터에 기초하여 제3 프레임을 생성할 수 있 다. 예를 들어, 동영상 복원 네트워크는 특징 도메인의 특징 데이터를 이미지 도메인의 이미지로 변환할 수 있다. 동영상 복원 네트워크에 입력되는 특징 데이터는 특징 처리 네트워크에 의해 획득된 제5 특 징 데이터()일 수 있다. 동영상 복원 네트워크는 애플리케이션에 따라 다양한 방식으로 구현될 수 있다. 예를 들어, 초해상도의 경 우, 동영상 복원 네트워크는 하나 이상의 업-컨볼루션 레이어 및 하나 이상의 픽셀 셔플(pixel shuffle) 레이어를 포함할 수 있다. 예를 들어, 디노이징의 경우, 동영상 복원 네트워크는 다층 퍼셉트론(Multi- Layer Perceptron, MLP) 기반의 네트워크를 포함할 수 있다. 도 2는 본 개시의 일 실시예에 따른, 특징 처리 네트워크를 도시한다. 도 2를 참조하면, 일 실시예에서, 특징 처리 네트워크는 하나 이상의 멀티-프레임 매칭 모듈(multi-frame matching module)(211, 212, 213, 214 및 220), 하나 이상의 특징 변환 모듈(feature transformation module)(231, 232, 233 및 234), 연결 레이어(concatenation layer), 컨볼루션 레이어, 및 합산 레 이어를 포함할 수 있다. 도 2에서, 특징 처리 네트워크가 5개의 멀티-프레임 매칭 모듈(211, 212, 213, 214 및 220) 및 4개의 특징 변환 모듈(231, 232, 233 및 234)을 포함하는 것으로 도시되어 있으나, 이는 예시적인 것일 뿐, 멀티-프레임 매칭 모듈의 개수 및 특징 변환 모듈의 개수는 이에 제한되지 않는다. 일 실시예에서, 하나 이상의 멀티-프레임 매칭 모듈(211, 212, 213, 214 및 220)은 제1 멀티-프레임 매칭 모듈 (211, 212, 213 및 214) 및 제2 멀티-프레임 매칭 모듈을 포함할 수 있다. 도 2에 도시된 바와 같이, 제1 멀티-프레임 매칭 모듈(211, 212, 213 및 214)은 전술한 특징 페어에 대하여 특징 처리를 수행할 수 있고, 제2 멀티-프레임 매칭 모듈은 제1 특징 데이터에 대하여 특징 처리를 수행할 수 있다. 따라서, 일 실시예에서, 제2 멀티-프레임 매칭 모듈의 특징 처리 동작은 제1 멀티-프레임 매칭 모듈(211, 212, 213 및 214)의 특징 처리 동작 중 특징 페어에 관련된 동작(예: 특징 와핑 모듈(도 3의 310)의 동작 등)을 제외한 나머지 동작과 동 일할 수 있다. 다만 본 개시는 이에 제한되지 않으며, 예를 들어, 제2 멀티-프레임 매칭 모듈은 제1 멀티- 프레임 매칭 모듈(211, 212, 213 및 214)과 동일하게 구현되어 2개의 제1 특징 데이터를 포함하는 특징 페어에 대하여 특징 처리를 수행할 수도 있다. 따라서 이하의 설명에서는 제1 멀티-프레임 매칭 모듈(211, 212, 213 및 214) 및 제2 멀티-프레임 매칭 모듈을 구별하지 않고 설명하기로 한다. 일 실시예에서, 멀티-프레임 매칭 모듈(211, 212, 213, 214 및 220)은 양방향 모션 정보에 기초하여, 특징 페어 에 대하여 어텐션을 포함하는 특징 처리를 수행하여 제3 특징 데이터를 획득할 수 있다. 여기서, 특징 페어는 제1 특징 데이터, 및 하나 이상의 제2 특징 데이터 중 대응하는 제2 특징 데이터를 포함할 수 있다. 예를 들어, 특징 페어는 제1 특징 데이터 및 제2 특징 데이터가 연결된(concatenated) 행렬일 수 있다. 예를 들어, 멀티-프레임 매칭 모듈은 t번째 프레임 및 t-2번째 프레임 사이의 양방향 모션 정보( 및 )에 기초하여, 제1 특징 데이터() 및 제2 특징 데이터()를 포함하는 제1 특징 페어에 대하여 특징 처리를 수행하여 제3 특징 데이터( )를 획득할 수 있다. 예를 들어, 멀티-프레임 매칭 모듈은 t번째 프레임 및 t-1번째 프레임 사이의 양방향 모션 정보( 및 )에 기초하여, 제1 특징 데이터() 및 제2 특징 데이터()를 포함하는 제2 특징 페어에 대하여 특징 처리를 수행하여 제3 특징 데이터( )를 획득할 수 있다. 예를 들어, 멀티-프레임 매칭 모듈은 t번째 프레임 및 t+1번째 프레임 사이의 양방향 모션 정보( 및 )에 기초하여, 제1 특징 데이터() 및 제2 특징 데이터()를 포함하는 제3 특징 페어에 대하여 특징 처리를 수행하여 제3 특징 데이터( )를 획득할 수 있다. 예를 들어, 멀티-프레임 매칭 모듈은 t번째 프레임 및 t+2번째 프레임 사이의 양방향 모션 정보( 및 )에 기초하여, 제1 특징 데이터() 및 제2 특징 데이터()를 포함하는 제4 특징 페어에 대하여 특징 처리를 수행하여 제3 특징 데이터( )를 획득할 수 있다. 한편, 전술한 바와 같이, 멀티-프레임 매칭 모듈은 제1 특징 데이터()에 대하여 특징 처리를 수행하여 제3 특징 데이터()를 획득할 수도 있고, 2개의 제1 특징 데이터()를 포함하는 특징 페어에 대하여 특 징 처리를 수행하여 제3 특징 데이터()를 획득할 수도 있다. 멀티-프레임 매칭 모듈(211, 212, 213, 214 및 220)의 상세한 구조 및 동작의 예시는 도 3 내지 도 8b를 참조하 여 후술된다. 일 실시예에서, 특징 변환 모듈(231, 232, 233 및 234)은 양방향 모션 정보에 기초하여, 제3 특징 데이터에 대 하여 특징 변환을 적용하여 제4 특징 데이터를 획득할 수 있다. 특징 변환 모듈(231, 232, 233 및 234)의 구조 및 동작의 예시는 도 10 및 도 11를 참조하여 후술된다. 일 실시예에서, 연결 레이어는 입력되는 복수의 특징 데이터를 채널 방향으로 연결할 수 있다. 예를 들어, 연결 레이어에 입력되는 특징 데이터는 제2 멀티-프레임 매칭 모듈에서 출력된 특징 데이터(예: ) 및 특징 변환 모듈(231, 232, 233 및 234)에서 출력된 특징 데이터를 포함할 수 있다. 일 실시예에서, 컨볼루션 레이어는 입력되는 특징 데이터와 컨볼루션 레이어에 포함된 커널 간의 컨 볼루션 연산을 수행할 수 있다. 예를 들어, 컨볼루션 레이어에 입력되는 특징 데이터는 연결 레이어 에서 출력된 특징 데이터일 수 있다. 도 2에서, 특징 처리 네트워크가 하나의 컨볼루션 레이어를 포 함하는 것으로 도시되어 있지만, 컨볼루션 레이어의 개수는 이에 제한되지 않으며, 특징 처리 네트워크 는 2개 이상의 컨볼루션 레이어를 포함할 수 있다. 일 실시예에서, 합산 레이어는 컨볼루션 레이어의 출력 데이터와 제1 특징 데이터 간의 요소별 합산 연산을 수행하여 제5 특징 데이터()를 획득할 수 있다. 제5 특징 데이터는 동영상 복원 네트워크(도 1의 140)에 입력될 수 있다. 도 3은 본 개시의 일 실시예에 따른, 멀티 프레임 매칭 모듈을 도시한다. 도 3에 도시된 멀티-프레임 매칭 모듈은 도 2에 도시된 멀티-프레임 매칭 모듈(211, 212, 213, 214 및 220) 중 어느 하나일 수 있다. 도 3을 참조하면, 일 실시예에서, 멀티-프레임 매칭 모듈은 t번째 프레임 및 t+i번째 프레임 사이의 양방 향 모션 정보( 및 )에 기초하여, 제1 특징 데이터() 및 제2 특징 데이터()를 포함하는 특징 페어에 대하여 특징 처리를 수행하여 제3 특징 데이터( )를 획득할 수 있다. 도 1 내지 도 3의 예 시에서, i는 -2, -1, +1 및 +2이다. 일 실시예에서, 멀티-프레임 매칭 모듈은 특징 와핑 모듈(feature warping module), 패치 임베딩 모 듈(patch embedding module), 하나 이상의 특징 매칭 모듈(feature matching module), 정규화 레이 어(normalization layer) 및 패치 언임베딩 모듈(patch un-embedding module)을 포함할 수 있다. 일 실시예에서, 특징 와핑 모듈은 양방향 모션 정보에 기초하여, 입력되는 제2 특징 데이터를 와핑할 수 있다. 여기서, 와핑은 닮음 변환(similarity transformation), 유클리드 변환(Euclidean transformation), 아 핀 변환(affine transformation), 투영 변환(projective transformation) 등을 포함할 수 있으나, 이에 제한되 는 것은 아니다. 예를 들어, 특징 와핑 모듈은 양방향 모션 정보에 포함된 제1 프레임 및 제2 프레임 사이에서의 객체의 위치 변화를 나타내는 좌표에 기초하여, 제2 특징 데이터에 포함된 요소(element)의 위 치를 제1 특징 데이터와 대응되도록, 제2 특징 데이터를 와핑할 수 있다. 제1 특징 데이터 및 제2 특징 데이터는 각각 서로 다른 프레임으로부터 추출된 것이므로, 객체의 이동 또는 카 메라의 움직임 등에 의해 제1 특징 데이터 및 제2 특징 데이터에서 동일한 객체의 위치가 달라질 수 있다. 특징와핑 모듈은 이러한 객체의 위치 변형을 보정할 수 있다. 특징 와핑 모듈에 의해 제2 특징 데이터를 와핑함으로써 이후의 동작들(예: 어텐션 등)이 객체의 이동과 같은 프레임의 변형에 강인하게 수행될 수 있다. 일 실시예에서, 특징 와핑 모듈의 동작은 멀티-프레임 매칭 모듈이 아니라 어텐션 모듈(도 5의 530) 에서 수행될 수도 있다. 특징 와핑은 어텐션 연산이 프레임의 변형에 강인하게 수행되도록 하기 위한 것이므로, 예를 들어 제2 특징 데이터로부터 키 및 밸류를 추출하기 전이라면 어느 단계에서도 특징 와핑이 수행될 수 있 다. 한편, 전술한 바와 같이, 제2 멀티-프레임 매칭 모듈(도 2의 220)은 특징 와핑 모듈을 포함하지 않도록 구 성될 수도 있다. 일 실시예에서, 패치 임베딩 모듈은 입력되는 특징 데이터를 패치 임베딩으로 변환할 수 있다. 예를 들어, 패치 임베딩 모듈은 입력되는 특징 데이터를 소정의 크기의 복수의 패치로 분할하고, 분할된 패치에 선형 변환을 적용하여 패치 임베딩을 획득할 수 있다. 패치 임베딩 모듈에 입력되는 특징 데이터는 제1 특징 데 이터 및 와핑된 제2 특징 데이터를 포함할 수 있다. 일 실시예에서, 패치 임베딩은 제1 특징 데이터로부터 획득 된 제1 패치 임베딩 및 제2 특징 데이터로부터 획득된 제2 패치 임베딩을 포함할 수 있다. 일 실시예에서, 하나 이상의 특징 매칭 모듈은 입력되는 특징 데이터에 특징 처리를 수행할 수 있다. 예를 들어, 하나 이상의 특징 매칭 모듈에 입력되는 데이터는 패치 임베딩 모듈에 의해 획득된 패치 임베 딩일 수 있다. 특징 매칭 모듈의 구조 및 동작의 예시는 도 4를 참조하여 후술된다. 일 실시예에서, 정규화 레이어는 입력되는 데이터를 정규화할 수 있다. 예를 들어, 정규화 레이어에 입력되는 데이터의 합이 1이 되도록 정규화할 수 있다. 다만, 정규화 레이어에 수행하는 정규화 방법은 이 에 제한되지 않는다. 정규화 레이어에 입력되는 데이터는 하나 이상의 특징 매칭 모듈의 특징 처리 결과 획득된 데이터일 수 있다. 일 실시예에서, 패치 언임베딩 모듈은 입력되는 데이터를 언임베딩 하여 제3 특징 데이터( )를 획 득할 수 있다. 패치 언임베딩 모듈의 동작은 패치 임베딩 모듈의 동작의 역(inverse) 동작으로 이해 될 수 있다. 패치 언임베딩 모듈에 입력되는 데이터는 정규화 레이어의 정규화 동작의 결과로서 획득 된 데이터일 수 있다. 도 4는 본 개시의 일 실시예에 따른, 특징 매칭 모듈을 도시한다. 도 4에 도시된 특징 매칭 모듈은 도 3에 도시된 하나 이상의 특징 매칭 모듈 중 어느 하나일 수 있다. 도 4를 참조하면, 일 실시예에서, 특징 매칭 모듈은 하나 이상의 변환기 레이어, 컨볼루션 레이어 및 합산 레이어를 포함할 수 있다. 일 실시예에서, 하나 이상의 변환기 레이어는 제1 입력 데이터() 및 제2 입력 데이터()에 대하 여 특징 처리를 수행할 수 있다. 하나 이상의 변환기 레이어에 입력되는 제1 입력 데이터()는 제1 특징 데이터()가 특징 와핑 모듈 및 패치 임베딩 모듈에 의해 처리된 결과로서 획득된 데이터일 수 있다. 하나 이상의 변환기 레이어에 입력되는 제2 입력 데이터()는 제2 특징 데이터()가 특 징 와핑 모듈 및 패치 임베딩 모듈에 의해 처리된 결과로서 획득된 데이터일 수 있다. 하나 이상의 변환기 레이어의 구조 및 동작의 예시는 도 5를 참조하여 후술된다. 일 실시예에서, 컨볼루션 레이어는 입력되는 특징 데이터와 컨볼루션 레이어에 포함된 커널 간의 컨 볼루션 연산을 수행할 수 있다. 예를 들어, 컨볼루션 레이어에 입력되는 특징 데이터는 하나 이상의 변환 기 레이어에서 출력된 특징 데이터일 수 있다. 도 4에서, 특징 매칭 모듈이 하나의 컨볼루션 레이어 를 포함하는 것으로 도시되어 있지만, 컨볼루션 레이어의 개수는 이에 제한되지 않으며, 특징 매칭 모듈은 2개 이상의 컨볼루션 레이어를 포함할 수 있다. 일 실시예에서, 합산 레이어는 컨볼루션 레이어의 출력 데이터와 제1 입력 데이터() 간의 요소 별 합산 연산을 수행하여 제1 출력 데이터()를 획득할 수 있다. 제1 출력 데이터()는 다음 특징 매칭 모듈의 제1 입력 데이터()로서 입력될 수 있다. 일 실시예에서, 특징 매칭 모듈은 제1 출력 데이터() 및 제2 출력 데이터()를 출력할 수 있 다. 제1 출력 데이터()는 합산 레이어에 의해 획득된 데이터일 수 있고, 제2 출력 데이터() 는 제2 입력 데이터()와 동일할 수 있다. 도 5는 본 개시의 일 실시예에 따른, 변환기 레이어를 도시한다. 도 5에 도시된 변환기 레이어는 도 4에 도시된 하나 이상의 변환기 레이어 중 어느 하나일 수 있다. 도 5를 참조하면, 일 실시예에서, 변환기 레이어는 제1 정규화 레이어, 패치 분할 모듈, 어텐션 모듈, 패치 병합 모듈, 제1 합산 레이어, 제2 정규화 레이어, 다층 퍼셉트론(Multi-Layer Perceptron, MLP) 및 제2 합산 레이어를 포함할 수 있다. 일 실시예에서, 제1 정규화 레이어는 변환기 레이어에 입력되는 제1 입력 데이터() 및 제2 입 력 데이터()를 정규화할 수 있다. 변환기 레이어에 입력되는 제1 입력 데이터()는 하나 이상의 변환기 레이어에 입력되는 제1 입력 데이터()일 수 있다. 변환기 레이어에 입력되는 제2 입력 데이터()는 하나 이상의 변환기 레이어에 입력되는 제2 입력 데이터()일 수 있다. 정규화 된 제1 입력 데이터 및 제2 입력 데이터는 패치 분할 모듈에 입력될 수 있다. 예를 들어, 제1 정규화 레이어는 변환기 레이어에 입력되는 제1 입력 데이터의 합이 1이 되도록 제1 입력 데이터를 정규화할 수 있다. 제1 정규화 레이어는 변환기 레이어에 입력되는 제2 입력 데이터의 합이 1이 되도록 제2 입력 데이터를 정규화할 수 있다. 다만, 제1 정규화 레이어가 수행하는 정규화 방법 은 이에 제한되지 않는다. 일 실시예에서, 패치 분할 모듈은 입력되는 제1 입력 데이터 및 제2 입력 데이터를 소정의 크기의 복수의 패치로 분할할 수 있다. 패치 분할 모듈에 입력되는 제1 입력 데이터는 제1 정규화 레이어에 의해 정 규화 된 제1 입력 데이터()일 수 있다. 패치 분할 모듈에 입력되는 제2 입력 데이터는 제1 정규화 레이어에 의해 정규화 된 제2 입력 데이터()일 수 있다. 일 실시예에서, 패치의 크기는 하드웨어 성 능, 메모리 사이즈 등을 고려하여 결정될 수 있다. 예를 들어, 패치의 크기가 커질수록 연산 코스트가 커질 수 있다. 일 실시예에서, 패치의 모양은 정사각형 형태(즉, M × M)일 수 있으나, 이에 제한되지 않으며, 직사각형 형태(즉, M × N)일 수도 있다. 일 실시예에서, 어텐션 모듈은 입력되는 제1 입력 데이터 및 제2 입력 데이터에 어텐션을 수행할 수 있다. 어텐션 모듈에 입력되는 제1 입력 데이터는 변환기 레이어에 입력된 제1 입력 데이터()가 정규 화 및 분할된 패치일 수 있다. 어텐션 모듈에 입력되는 제2 입력 데이터는 변환기 레이어에 입력된 제2 입력 데이터()가 정규화 및 분할된 패치일 수 있다. 일 실시예에서, 어텐션 모듈은 제1 어텐션 모듈(도 6의 600) 또는 제2 어텐션 모듈(도 7의 700) 중 어느 하나일 수 있다. 제1 어텐션 모듈은 패치 분할 모듈에 의해 분할된 패치 단위로 어텐션을 수행할 수 있다. 제2 어텐션 모듈은 각각의 패치에 포함된 픽셀 단위로 어텐션을 수행할 수 있다. 제1 어텐션 모듈 및 제2 어텐션 모듈의 구조 및 동작의 예시는 각각 도 6 및 도 7을 참조하여 후술된다. 일 실시예에서, 패치 병합 모듈은 패치 병합 모듈에 입력되는 제1 입력 데이터를 병합하고, 제2 입력 데이터를 병합할 수 있다. 패치 병합 모듈의 동작은 패치 분할 모듈의 동작의 역 동작으로 이해될 수 있다. 패치 병합 모듈에 입력되는 제1 입력 데이터는 어텐션 모듈에서 수행된 어텐션 결과일 수있다. 패치 병합 모듈에 입력되는 제2 입력 데이터는 어텐션 모듈에 입력되는 제2 입력 데이터일 수 있다. 일 실시예에서, 제1 합산 레이어는 패치 병합 모듈의 제1 출력 데이터와 변환기 레이어의 제1 입력 데이터 간의 요소별 합산 연산을 수행할 수 있다. 제1 합산 레이어의 출력 데이터는 제2 정규화 레이 어에 입력될 수 있다. 일 실시예에서, 제2 정규화 레이어는 제1 합산 레이어의 출력 데이터를 정규화할 수 있다. 예를 들어, 제2 정규화 레이어는 제1 합산 레이어의 출력 데이터의 합이 1이 되도록 제1 합산 레이어(55 0)의 출력 데이터를 정규화할 수 있다. 다만, 제2 정규화 레이어가 수행하는 정규화 방법은 이에 제한되지 않는다. 일 실시예에서, 다층 퍼셉트론은 제2 정규화 레이어에 의해 정규화 된 데이터에 대하여 특징 처리를 수행할 수 있다. 다층 퍼셉트론은 하나 이상의 완전 연결 레이어 및 하나 이상의 활성화 함수를 포함할 수 있다. 예를 들어, 다층 퍼셉트론은 제1 리니어 레이어, GELU(Gaussian Error Linear Unit) 함수 및 제2 리니어 레이어를 포함할 수 있으며, 이때 제1 리니어 레이어 및 제2 리니어 레이너는 각각 입력되는 데이터와 가중치 행렬 간의 곱셈 연산을 수행할 수 있다. 다층 퍼셉트론에 포함되는 활성화 함수의 종류는 전술한 것에 제한되지 않으며, 예를 들어, 시그모이드(sigmoid), ReLU(Rectified Linear Unit), Tanh, Leaky ReLu, PReLU(Parametric ReLU), ELU(Exponential Linear Unit) 등의 다양한 활성화 함수가 사용될 수 있다. 일 실시예에서, 제2 합산 레이어는 제1 합산 레이어의 출력 데이터와 다층 퍼셉트론의 출력 데 이터 간의 요소 별 합산 연산을 수행할 수 있다. 제2 합산 레이어의 출력 데이터는 변환기 레이어의 제1 출력 데이터()일 수 있다. 일 실시예에서, 변환기 레이어는 제2 출력 데이터()를 출력할 수 있다. 변환기 레이어의 제2 출력 데이터는 패치 병합 모듈의 제2 출력 데이터일 수 있다. 변환기 레이어의 제2 입력 데이터는 제 1 정규화 레이어에 의해 정규화되고, 패치 분할 모듈 및 패치 병합 모듈에 의해 처리되므로, 변 환기 레이어의 제2 출력 데이터는 변환기 레이어의 정규화된 제1 입력 데이터와 동일할 수 있다. 도 6은 본 개시의 일 실시예에 따른, 제1 어텐션 모듈을 도시한다. 도 6을 참조하면, 제1 어텐션 모듈은 정규화 된 특징 데이터가 패치 분할 모듈에 의해 분할된 복수의 패치에 대하여 패치 단위로 어텐션을 수행할 수 있다. 예를 들어, 제1 어텐션 모듈에 입력되 는 제1 입력 데이터()는 제1 특징 데이터()가 분할된 패치일 수 있고, 제1 어텐션 모듈에 입력되 는 제2 입력 데이터()는 제2 특징 데이터()가 분할된 패치일 수 있다. 본 개시에서, 제1 어텐션 모듈 은 인터-패치(inter-patch) 어텐션 모듈로 지칭될 수 있다. 패치는 복수의 픽셀을 포함하므로, 패치는 개별 픽셀에서는 식별되기 어려운 선(line), 코너 (corner), 패턴(pattern) 등과 같은 구조적인 정보를 포함할 수 있다. 패치 단위로 어텐션을 수행하면 유사한 구조를 포함하는 패치들 간의 상관관계(correlation)가 큰 값으로 계산될 수 있고, 따라서 각 픽셀의 색상 정보 (예: 픽셀 강도(intensity) 등)뿐만 아니라 구조적인 정보를 함께 활용할 수 있다. 일 실시예에서, 제1 어텐션 모듈은 특징 와핑 모듈, 제1 리니어 레이어, 제2 리니어 레이어 , 제3 리니어 레이어, 전치 함수, 제1 곱셈 레이어, 소프트맥스 함수, 제2 곱셈 레 이어 및 제4 리니어 레이어를 포함할 수 있다. 일 실시예에서, 특징 와핑 모듈은 양방향 모션 정보에 기초하여, 제1 어텐션 모듈에 입력되는 제2 입 력 데이터()를 와핑할 수 있다. 여기서, 와핑은 닮음 변환(similarity transformation), 유클리드 변환 (Euclidean transformation), 아핀 변환(affine transformation), 투영 변환(projective transformation) 등 을 포함할 수 있으나, 이에 제한되는 것은 아니다. 특징 와핑 모듈은 특징 와핑 모듈(도 3의 310)과 유사 한 동작을 수행할 수 있다. 전술한 바와 같이, 특징 와핑은 제2 특징 데이터로부터 키 및 밸류를 추출하기 전이라면 어느 단계에서도 수행 될 수 있으므로, 멀티-프레임 매칭 모듈이 특징 와핑 모듈을 포함하는 경우, 제1 어텐션 모듈은특징 와핑 모듈을 포함하지 않을 수도 있다. 일 실시예에서, 제1 리니어 레이어는 제1 어텐션 모듈에 입력되는 제1 입력 데이터와 제1 리니어 레 이어에 포함된 가중치 행렬 간의 곱 연산을 통해 제1 입력 데이터에 대응하는 쿼리(Q)를 획득할 수 있다. 일 실시예에서, 제1 리니어 레이어는 1 × 1 컨볼루션 레이어를 포함할 수 있다. 일 실시예에서, 제2 리니어 레이어는 제1 어텐션 모듈에 입력되는 제2 입력 데이터(또는 특징 와핑 모듈에 의해 와핑된 제2 입력 데이터)와 제2 리니어 레이어에 포함된 가중치 행렬 간의 곱 연산을 통 해 제2 입력 데이터에 대응하는 키(K)를 획득할 수 있다. 일 실시예에서, 제2 리니어 레이어는 1 × 1 컨 볼루션 레이어를 포함할 수 있다. 일 실시예에서, 제3 리니어 레이어는 제1 어텐션 모듈에 입력되는 제2 입력 데이터(또는 특징 와핑 모듈에 의해 와핑된 제2 입력 데이터)와 제3 리니어 레이어에 포함된 가중치 행렬 간의 곱 연산을 통 해 제2 입력 데이터에 대응하는 밸류(V)를 획득할 수 있다. 일 실시예에서, 제3 리니어 레이어는 1 × 1 컨볼루션 레이어를 포함할 수 있다. 일 실시예에서, 전치 함수는 키를 전치시켜 전치된 키(KT)를 생성할 수 있다. 일 실시예에서, 제1 곱셈 레이어는 쿼리와 전치된 키의 요소 별 곱셈 연산을 수행할 수 있다. 일 실시예에서, 제2 곱셈 레이어는 소프트맥스 함수가 적용된 제1 곱셈 레이어의 출력과 밸류의 요소 별 곱셈 연산을 수행할 수 있다. 소프트맥스 함수가 적용된 제1 곱셈 레이어의 출력은 쿼리와 키 사이의 상관관계(correlation)을 나타내는 가중치로 이해될 수 있으며, 제2 곱셈 레이어의 동작은 가중 치와 밸류의 가중 합 연산으로 이해될 수 있다. 일 실시예에서, 제4 리니어 레이어는 제2 곱셈 레이어의 출력과 제4 리니어 레이어에 포함된 가 중치 행렬 간의 곱 연산을 수행할 수 있다. 일 실시예에서, 제4 리니어 레이어는 1 × 1 컨볼루션 레이어 를 포함할 수 있다. 도 7은 본 개시의 일 실시예에 따른, 제2 어텐션 모듈을 도시한다. 도 7을 참조하면, 제2 어텐션 모듈은 정규화 된 특징 데이터가 패치 분할 모듈에 의해 분할된 복수의 패치에 대하여 픽셀 단위로 어텐션을 수행할 수 있다. 예를 들어, 제2 어텐션 모듈에 입력되 는 제1 입력 데이터()는 제1 특징 데이터()가 분할된 패치에 포함된 픽셀일 수 있고, 제2 어텐션 모듈 에 입력되는 제2 입력 데이터()는 제2 특징 데이터()가 분할된 패치에 포함된 픽셀일 수 있다. 본 개시에서, 제2 어텐션 모듈은 인트라-패치(intra-patch) 어텐션 모듈로 지칭될 수 있다. 일 실시예에서, 제2 어텐션 모듈은 특징 와핑 모듈, 제1 리니어 레이어, 제2 리니어 레이어 , 제3 리니어 레이어, 전치 함수, 제1 곱셈 레이어, 소프트맥스 함수, 제2 곱셈 레 이어 및 제4 리니어 레이어를 포함할 수 있다. 일 실시예에서, 특징 와핑 모듈은 양방향 모션 정보에 기초하여, 제2 어텐션 모듈에 입력되는 제2 입 력 데이터()를 와핑할 수 있다. 여기서, 와핑은 닮음 변환(similarity transformation), 유클리드 변환 (Euclidean transformation), 아핀 변환(affine transformation), 투영 변환(projective transformation) 등 을 포함할 수 있으나, 이에 제한되는 것은 아니다. 특징 와핑 모듈은 특징 와핑 모듈(도 3의 310)과 유사 한 동작을 수행할 수 있다. 전술한 바와 같이, 특징 와핑은 제2 특징 데이터로부터 키 및 밸류를 추출하기 전이라면 어느 단계에서도 수행 될 수 있으므로, 멀티-프레임 매칭 모듈이 특징 와핑 모듈을 포함하는 경우, 제2 어텐션 모듈은 특징 와핑 모듈을 포함하지 않을 수도 있다. 일 실시예에서, 제1 리니어 레이어는 제1 어텐션 모듈에 입력되는 제1 입력 데이터와 제1 리니어 레 이어에 포함된 가중치 행렬 간의 곱 연산을 통해 제1 입력 데이터에 대응하는 쿼리(Q)를 획득할 수 있다. 일 실시예에서, 제1 리니어 레이어는 1 × 1 컨볼루션 레이어를 포함할 수 있다. 일 실시예에서, 제2 리니어 레이어는 제2 어텐션 모듈에 입력되는 제2 입력 데이터(또는 특징 와핑 모듈에 의해 와핑된 제2 입력 데이터)와 제2 리니어 레이어에 포함된 가중치 행렬 간의 곱 연산을 통 해 제2 입력 데이터에 대응하는 키(K)를 획득할 수 있다. 일 실시예에서, 제2 리니어 레이어는 1 × 1 컨 볼루션 레이어를 포함할 수 있다. 일 실시예에서, 제3 리니어 레이어는 제1 어텐션 모듈에 입력되는 제2 입력 데이터(또는 특징 와핑 모듈에 의해 와핑된 제2 입력 데이터)와 제3 리니어 레이어에 포함된 가중치 행렬 간의 곱 연산을 통 해 제2 입력 데이터에 대응하는 밸류(V)를 획득할 수 있다. 일 실시예에서, 제3 리니어 레이어는 1 × 1 컨볼루션 레이어를 포함할 수 있다. 일 실시예에서, 전치 함수는 키를 전치시켜 전치된 키(KT)를 생성할 수 있다. 일 실시예에서, 제1 곱셈 레이어는 쿼리와 전치된 키의 요소 별 곱셈 연산을 수행할 수 있다. 일 실시예에서, 제2 곱셈 레이어는 소프트맥스 함수가 적용된 제1 곱셈 레이어의 출력과 밸류의 요소 별 곱셈 연산을 수행할 수 있다. 소프트맥스 함수가 적용된 제1 곱셈 레이어의 출력은 쿼리와 키 사이의 상관관계(correlation)을 나타내는 가중치로 이해될 수 있으며, 제2 곱셈 레이어의 동작은 가중 치와 밸류의 가중 합 연산으로 이해될 수 있다. 일 실시예에서, 제4 리니어 레이어는 제2 곱셈 레이어의 출력과 제4 리니어 레이어에 포함된 가 중치 행렬 간의 곱 연산을 수행할 수 있다. 일 실시예에서, 제4 리니어 레이어는 1 × 1 컨볼루션 레이어 를 포함할 수 있다. 도 8a 및 도 8b는 본 개시의 일 실시예에 따른, 제1 어텐션 모듈 및 제2 어텐션 모듈의 배치 예시를 도시한다. 도 8a 및 도 8b에는 제1 어텐션 모듈을 포함하는 제1 변환기 레이어 및 제2 어텐션 모듈을 포함 하는 제2 변환기 레이어가 간소화되어 도시되어 있다. 제1 변환기 레이어 및 제2 변환기 레이어(82 0)는 도 4에 도시된 하나 이상의 변환기 레이어에 대응될 수 있다. 도 8a 및 도 8b에서, 설명의 편의를 위 해 4개의 변환기 레이어(810, 820)가 도시되어 있으나, 변환기 레이어의 개수는 이에 제한되지 않는다. 일 실시예에서, 제1 변환기 레이어 및 제2 변환기 레이어의 개수 및 순서는 다양하게 구현될 수 있다. 예를 들어, 도 8a에 도시된 바와 같이, 변환기 레이어들은 2개의 제1 변환기 레이어 및 2개의 제2 변환기 레이어 순으로 배치될 수 있다. 또는, 도 8b에 도시된 바와 같이, 변환기 레이어들은 제1 변환기 레이어 및 제2 변환기 레이어가 교차로 배치될 수 있다. 패치 단위의 어텐션을 수행하는 제1 변환기 레이어는 제2 변환기 레이어보다 더 넓은 범위의 정보를 활용하여 제1 특징 데이터()를 업데이트 할 수 있다. 반면, 픽셀 단위의 어텐션을 수행하는 제2 변환기 레이 어는 제1 변환기 레이어보다 더 세부적인 정보를 활용하여 제1 특징 데이터()를 업데이트 할 수 있다. 따라서, 제1 특징 데이터()를 업데이트하기 위해 활용하고자 하는 정보의 범위에 따라 제1 변환기 레 이어 또는 제2 변환기 레이어 중 하나가 선택될 수 있다. 예를 들어, 제1 변환기 레이어 또는 제2 변환기 레이어는 동영상 처리를 수행하는 하드웨어(예: GPU, 메모리 등)의 성능, 설계자의 경험 등에 기초하여 선택될 수 있다. 도 9는 본 개시의 일 실시예에 따른, 특징 변환 모듈을 도시한다. 도 9에 도시된 특징 변환 모듈은 도 2에 도시된 특징 변환 모듈(231, 232, 233 및 234) 중 어느 하나일 수 있다. 도 9를 참조하면, 일 실시예에서, 특징 변환 모듈은 양방향 모션 정보( 및 )에 기초하여, 제3 특징 데이터( )에 대하여 특징 변환을 적용하여 제4 특징 데이터()를 획득할 수 있다. 일 실시예에서, 특징 변환 모듈은 파라미터 추출 네트워크 및 변환 모듈을 포함할 수 있다. 일 실시예에서, 파라미터 추출 네트워크는 양방향 모션 정보( 및 )에 기초하여 변환 파라 미터를 획득할 수 있다. 변환 파라미터는 변환 모듈의 변환 동작에 연관된 파라미터로서, 하나 이상의 파 라미터를 포함할 수 있다. 파라미터 추출 네트워크는 하나 이상의 인공 신경망을 포함할 수 있다. 일 실시예에서, 변환 모듈은 변환 파라미터에 기초하여 소정의 변환 동작을 통해 제3 특징 데이터를 변환 할 수 있다. 예를 들어, 소정의 변환 동작은 닮음 변환(similarity transformation), 유클리드 변환(Euclidean transformation), 아핀 변환(affine transformation), 투영 변환(projective transformation) 등을 포함할 수 있으나, 이에 제한되는 것은 아니다. 예를 들어, 소정의 변환 동작은 제3 특징 데이터에 변환 파라미터를 곱하 는 연산, 또는 제3 특징 데이터에 변환 파라미터를 더하는 연산을 포함할 수 있다. 전술한 특징 변환 모듈의 동작은 양방향 모션 정보를 활용하여 참조 프레임(예: 제2 프레임)에서 추출된 정보의 활용도를 결정하는 과정으로 이해될 수 있다. 양방향 모션 정보는 각 픽셀 마다 주변 영역을 고려하여 2 개의 프레임(예: 제1 프레임 및 제2 프레임)을 매칭한 결과로 해석될 수 있다. 예를 들어, 제1 프레임에 존재하 는 객체가 제2 프레임에는 존재하지 않는 경우와 같이, 2개의 프레임 간에 정보의 차이가 있으면 양방향 모션 정보가 일관적이지 않게 계산될 수 있다. 일관적이지 않은 양방향 모션 정보는 2개의 프레임 간에 차이가 나는 정보가 동영상 처리 시 매우 중요한 정보 또는 매우 중요하지 않은 정보임을 암시할 수 있다. 특징 변환 모듈 은 학습을 통해 참조 프레임에서 추출된 특징 데이터(예: 제2 특징 데이터)에 적용될 가중치(예: 변환 파 라미터)를 생성할 수 있고, 생성된 가중치에 따라 참조 프레임에서 추출된 정보의 활용도가 결정될 수 있다. 이하에서는 도 10을 참조하여 특징 변환 모듈의 구현 예시가 설명된다. 도 10은 본 개시의 일 실시예에 따른, 특징 변환 모듈을 도시한다. 도 10에 도시된 특징 변환 모듈은 도 9에 도시된 특징 변환 모듈의 구현 예시이다. 도 10에 도시된 파라미터 추출 네트워크 및 변환 모듈은 각각 도 9에 도시된 파라미터 추출 네트워크 및 변환 모듈에 대응될 수 있다. 도 10을 참조하면, 파라미터 추출 네트워크는 컨디션 네트워크, 제1 및 제2 컨볼루션 레이어(1012, 1013), 제3 및 제4 컨볼루션 레이어(1014, 1015)를 포함할 수 있다. 일 실시예에서, 컨디션 네트워크는 양방향 모션 정보에 대하여 특징 처리를 수행하여 중간 특징을 획득할 수 있다. 컨디션 네트워크는 하나 이상의 컨볼루션 레이어 및 하나 이상의 활성화 함수를 포함할 수 있다. 예를 들어, 컨디션 네트워크는 2차원(2D) 컨볼루션 레이어 및 LeakyReLU 활성화 함수가 교차되도록 구성될 수 있다. 다만, 컨디션 네트워크의 구성은 이에 제한되지 않는다. 본 개시에서, 중간 특징은 컨피 던스 마스크(confidence mark)로 지칭될 수 있다. 일 실시예에서, 제1 및 제2 컨볼루션 레이어(1012, 1013)는 컨피던스 마스크에 대하여 컨볼루션 연산을 수행하 여 스케일 인자(scale factor)를 획득할 수 있다. 일 실시예에서, 제3 및 제4 컨볼루션 레이어(1014, 1015)는 컨피던스 마스크에 대하여 컨볼루션 연산을 수행하 여 바이어스(bias)를 획득할 수 있다. 도 10에서, 스케일 인자 및 바이어스를 획득하기 위해 각각 2개의 컨볼루션 레이어가 사용되는 것이 설명되어 있으나, 신경망의 종류 및 개수는 이에 제한되지 않는다. 일 실시예에서, 변환 모듈은 제3 특징 데이터와 스케일 인자를 곱하고, 곱셈 결과에 바이어스를 합산하여 제4 특징 데이터()를 획득할 수 있다. 본 개시에서, 도 10에 도시된 특징 변환 모듈의 동작은 공간적 특징 변환(spatial feature transformation)으로 지칭될 수 있다. 도 11은 본 개시의 일 실시예에 따른, 동영상 처리 방법의 순서도이다. 동영상 처리 방법은 도 12 에 도시된 전자 장치에 의해 수행될 수 있다. 동작 1110에서, 전자 장치는 제1 프레임으로부터 제1 특징 데이터를 추출할 수 있다. 동작 1120에서, 전자 장치는 하나 이상의 제2 프레임으로부터 하나 이상의 제2 특징 데이터를 추출할 수 있다. 동작 1110 및 1120은 특징 추출 네트워크의 동작에 대응될 수 있다. 동작 1130에서, 전자 장치는 하나 이상의 프레임 페어 각각에 대응하는 하나 이상의 양방향 모션 정보를 획득할 수 있다. 여기서, 하나 이상의 프레임 페어 각각은 제1 프레임, 및 하나 이상의 제2 프레임 중 대응하는 제2 프레임을 포함할 수 있다. 동작 1130은 모션 추정 모듈의 동작에 대응될 수 있다. 양방향 모션 정보는 제1 프레임에서 제2 프레임으로의 제1 모션 정보, 및 제2 프레임에서 제1 프레임으로의 제2 모션 정보를 포함할 수 있다. 동작 1140에서, 전자 장치는 하나 이상의 양방향 모션 정보에 기초하여 하나 이상의 특징 페어 각각에 제 1 특징 처리를 수행하여 하나 이상의 제3 특징 데이터를 획득할 수 있다. 여기서, 하나 이상의 특징 페어 각각 은 제1 특징 데이터, 및 하나 이상의 제2 특징 데이터 중 대응하는 제2 특징 데이터를 포함할 수 있다. 제1 특 징 처리는 어텐션을 포함할 수 있다. 동작 1150에서, 전자 장치는 하나 이상의 양방향 모션 정보에 기초하여 하나 이상의 제3 특징 데이터에 제2 특징 처리를 수행하여 하나 이상의 제4 특징 데이터를 획득할 수 있다. 제2 특징 처리는 특징 변환을 포함 할 수 있다. 동작 1160에서, 전자 장치는 제1 특징 데이터 및 하나 이상의 제4 특징 데이터에 기초하여 제5 특징 데이 터를 획득할 수 있다. 동작 1140 내지 1160은 특징 처리 네트워크의 동작에 대응될 수 있다. 동작 1170에서, 전자 장치는 제5 특징 데이터에 기초하여 제3 프레임을 생성할 수 있다. 동작 1170은 동 영상 복원 네트워크의 동작에 대응될 수 있다. 도 12는 본 개시의 일 실시예에 따른, 동영상을 처리하는 전자 장치를 도시한다. 도 12에 도시된 전자 장치는 전술한 동영상 처리 네트워크의 동작을 수행하여 동영상을 처리할 수 있다. 처리 대상인 동영상은 전자 장치에 저장된 동영상일 수도 있고, 전자 장치가 외부 장치(예: 인터넷을 통해 동영상을 제공하는 OTT(over the top) 서비스 제공자의 서버 등)로부터 수신한 동영상일 수도 있 다. 도 12를 참조하면, 일 실시예에서, 전자 장치는 프로세서 및 메모리를 포함할 수 있다. 다만, 전자 장치의 구성요소는 도 12에 도시된 것에 제한되지 않으며, 전자 장치는 도 12에 도시된 구성요소보다 더 많은 구성요소를 포함할 수 있다. 예를 들어, 전자 장치는 외부 장치와 데이터를 송수신 하기 위한 통신 인터페이스, 및/또는 동영상을 표시하는 디스플레이를 더 포함할 수 있다. 일 실시예에서, 프로세서는 본 개시에서 설명된 바에 따라 전자 장치가 동작하도록 일련의 과정을 제어하는 구성으로서, 하나 또는 복수의 프로세서로 구성될 수 있다. 프로세서에 포함되는 하나 또는 복 수의 프로세서는 System on Chip(SoC), Integrated Circuit(IC) 등과 같은 회로 장치(circuitry)일 수 있다. 프로세서에 포함되는 하나 또는 복수의 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), AP(Application Processor), DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU(Graphic Processing Unit), VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서, NPU(Neural Processing Unit) 와 같은 인공지능 전용 프로세서 또는 CP(Communication Processor)와 같은 통신 전용 프로세서일 수 있다. 프 로세서에 포함되는 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 해당 인공지능 전용 프 로세서는 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 일 실시예에서, 프로세서는 메모리에 데이터를 기록하거나, 메모리에 저장된 데이터를 읽을 수 있으며, 특히 메모리에 저장된 프로그램 또는 적어도 하나의 인스트럭션을 실행함으로써 미리 정의된 동작 규칙 또는 인공지능 모델에 따라 데이터를 처리할 수 있다. 따라서, 프로세서는 본 개시에서 설명된 동작들을 수행할 수 있으며, 본 개시에서 전자 장치가 수행한다고 설명된 동작들은 특별한 설명이 없는 한 프로세서가 수행하는 것으로 볼 수 있다. 일 실시예에서, 메모리는 다양한 프로그램이나 데이터를 저장하기 위한 구성으로서, 롬(ROM), 램(RAM), 하드디스크, CD-ROM 및 DVD 등과 같은 저장 매체 또는 저장 매체들의 조합으로 구성될 수 있다. 메모리는 별도로 존재하지 않고 프로세서에 포함되도록 구성될 수도 있다. 메모리는 휘발성 메모리, 비휘발 성 메모리 또는 휘발성 메모리와 비휘발성 메모리의 조합으로 구성될 수도 있다. 메모리에는 본 개시에서 설명된 실시예들에 따른 동작들을 수행하기 위한 프로그램 또는 적어도 하나의 인스트럭션이 저장될 수 있다. 메모리는 프로세서의 요청에 따라 저장된 데이터를 프로세서에 제공할 수도 있다.본 개시의 일 측면에 따르면, 동영상 처리 방법은 제1 프레임으로부터 제1 특징 데이터를 추출하는 단계, 하나 이상의 제2 프레임으로부터 하나 이상의 제2 특징 데이터를 추출하는 단계, 하나 이상의 프레임 페어(frame pair) 각각에 대응하는 하나 이상의 양방향 모션(bi-directional motion) 정보를 획득하는 단계로서, 상기 하나 이상의 프레임 페어 각각은 상기 제1 프레임, 및 상기 하나 이상의 제2 프레임 중 대응하는 제2 프레임을 포함 하고, 상기 하나 이상의 양방향 모션 정보에 기초하여 하나 이상의 특징 페어(feature pair) 각각에 제1 특징 처리를 수행하여 하나 이상의 제3 특징 데이터를 획득하는 단계로서, 상기 하나 이상의 특징 페어 각각은 상기 제1 특징 데이터, 및 상기 하나 이상의 제2 특징 데이터 중 대응하는 제2 특징 데이터를 포함하고, 상기 하나 이상의 양방향 모션 정보에 기초하여 상기 하나 이상의 제3 특징 데이터에 제2 특징 처리를 수행하여 하나 이상 의 제4 특징 데이터를 획득하는 단계, 상기 제1 특징 데이터 및 상기 하나 이상의 제4 특징 데이터에 기초하여 제5 특징 데이터를 획득하는 단계, 및 상기 제5 특징 데이터에 기초하여 제3 프레임을 생성하는 단계를 포함할 수 있다. 일 실시예에서, 상기 하나 이상의 양방향 모션 정보에 기초하여 하나 이상의 특징 페어(feature pair) 각각에 제1 특징 처리를 수행하여 하나 이상의 제3 특징 데이터를 획득하는 단계는, 상기 하나 이상의 양방향 모션 정 보에 기초하여 상기 하나 이상의 제2 특징 데이터를 와핑하는 단계, 상기 제1 특징 데이터 및 상기 와핑된 하나 이상의 제2 특징 데이터를 패치 임베딩으로 변환하는 단계로서, 상기 패치 임베딩은 상기 제1 특징 데이터로부 터 변환된 제1 패치 임베딩, 및 상기 와핑된 하나 이상의 제2 특징 데이터로부터 변환된 제2 패치 임베딩을 포 함하고, 상기 제1 및 제2 패치 임베딩은 각각 소정의 크기의 복수의 패치를 포함하고, 상기 패치 임베딩에 대하 여 어텐션(attention)을 수행하는 단계, 및 상기 어텐션 결과에 기초하여 상기 하나 이상의 제3 특징 데이터를 획득하는 단계를 포함할 수 있다. 일 실시예에서, 상기 패치 임베딩에 대하여 어텐션(attention)을 수행하는 단계는, 상기 제1 패치 임베딩에 기 초하여 쿼리(query)를 획득하는 단계, 상기 제2 패치 임베딩에 기초하여 키(key) 및 밸류(value)를 획득하는 단 계, 상기 쿼리 및 상기 키에 기초하여 가중치를 계산하는 단계, 및 상기 밸류에 상기 가중치를 적용하는 단계를 포함할 수 있다. 일 실시예에서, 상기 패치 임베딩에 대하여 어텐션(attention)을 수행하는 단계는, 상기 패치 임베딩에 포함된 복수의 패치에 대하여 패치 단위로 제1 어텐션을 수행하는 단계, 및 상기 패치 임베딩에 포함된 복수의 패치에 대하여 픽셀 단위로 제2 어텐션을 수행하는 단계를 포함할 수 있다. 일 실시예에서, 상기 하나 이상의 양방향 모션 정보에 기초하여 상기 하나 이상의 제3 특징 데이터에 제2 특징 처리를 수행하여 하나 이상의 제4 특징 데이터를 획득하는 단계는, 상기 하나 이상의 양방향 모션 정보에 기초 하여 하나 이상의 변환 파라미터를 획득하는 단계, 및 상기 하나 이상의 변환 파라미터에 기초하여 상기 하나 이상의 제3 특징 데이터에 소정의 변환 동작을 통해 상기 하나 이상의 제4 특징 데이터를 획득하는 단계를 포함 할 수 있다. 일 실시예에서, 상기 하나 이상의 변환 파라미터는 스케일 인자(scale factor) 및 바이어스(bias)를 포함할 수 있다. 일 실시예에서, 상기 소정의 변환 동작은 상기 하나 이상의 제3 특징 데이터에 상기 스케일 인자를 곱하고, 곱 셈 결과에 상기 바이어스를 합산하는 것을 포함할 수 있다. 일 실시예에서, 상기 제1 특징 데이터 및 상기 하나 이상의 제4 특징 데이터에 기초하여 제5 특징 데이터를 획 득하는 단계는, 상기 하나 이상의 제4 특징 데이터를 연결하는 단계, 상기 연결된 하나 이상의 제4 특징 데이터 에 컨볼루션 연산을 수행하는 단계, 및 상기 컨볼루션 연산 결과에 상기 제1 특징 데이터를 합산하는 단계를 포 함할 수 있다. 일 실시예에서, 상기 방법은 상기 제1 특징 데이터에 제3 특징 처리를 수행하여 제6 특징 데이터를 획득하는 단 계, 및 상기 하나 이상의 제4 특징 데이터 및 상기 제6 특징 데이터에 기초하여 상기 제5 특징 데이터를 획득하 는 단계를 더 포함할 수 있다. 일 실시예에서, 상기 양방향 모션 정보는 상기 제1 프레임에서 상기 대응하는 제2 프레임으로의 제1 모션 정보, 및 상기 대응하는 제2 프레임에서 상기 제1 프레임으로의 제2 모션 정보를 포함할 수 있다. 본 개시의 일 측면에 따르면, 컴퓨터 판독 가능한 기록매체는 컴퓨터에 의해 실행될 때, 상기 컴퓨터가, 제1 프 레임으로부터 제1 특징 데이터를 추출하는 단계, 하나 이상의 제2 프레임으로부터 하나 이상의 제2 특징 데이터를 추출하는 단계, 하나 이상의 프레임 페어(frame pair) 각각에 대응하는 하나 이상의 양방향 모션(bi- directional motion) 정보를 획득하는 단계로서, 상기 하나 이상의 프레임 페어 각각은 상기 제1 프레임, 및 상 기 하나 이상의 제2 프레임 중 대응하는 제2 프레임을 포함하고, 상기 하나 이상의 양방향 모션 정보에 기초하 여 하나 이상의 특징 페어(feature pair) 각각에 제1 특징 처리를 수행하여 하나 이상의 제3 특징 데이터를 획 득하는 단계로서, 상기 하나 이상의 특징 페어 각각은 상기 제1 특징 데이터, 및 상기 하나 이상의 제2 특징 데 이터 중 대응하는 제2 특징 데이터를 포함하고, 상기 하나 이상의 양방향 모션 정보에 기초하여 상기 하나 이상 의 제3 특징 데이터에 제2 특징 처리를 수행하여 하나 이상의 제4 특징 데이터를 획득하는 단계, 상기 제1 특징 데이터 및 상기 하나 이상의 제4 특징 데이터에 기초하여 제5 특징 데이터를 획득하는 단계, 및 상기 제5 특징 데이터에 기초하여 제3 프레임을 생성하는 단계를 포함할 수 있는 방법을 수행하게 하는, 하나 이상의 인스트럭 션을 저장한다. 본 개시의 일 측면에 따르면, 전자 장치는 적어도 하나의 프로세서, 및 하나 이상의 인스트럭션을 저장하는 메모리를 포함하고, 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행 함으로써 상기 전자 장치가, 제1 프레임으로부터 제1 특징 데이터를 추출하고, 하나 이상의 제2 프레임으 로부터 하나 이상의 제2 특징 데이터를 추출하고, 하나 이상의 프레임 페어(frame pair) 각각에 대응하는 하나 이상의 양방향 모션(bi-directional motion) 정보를 획득하고, 상기 하나 이상의 프레임 페어 각각은 상기 제1 프레임, 및 상기 하나 이상의 제2 프레임 중 대응하는 제2 프레임을 포함하고, 상기 하나 이상의 양방향 모션 정보에 기초하여 하나 이상의 특징 페어(feature pair) 각각에 제1 특징 처리를 수행하여 하나 이상의 제3 특징 데이터를 획득하고, 상기 하나 이상의 특징 페어 각각은 상기 제1 특징 데이터, 및 상기 하나 이상의 제2 특징 데이터 중 대응하는 제2 특징 데이터를 포함하고, 상기 하나 이상의 양방향 모션 정보에 기초하여 상기 하나 이 상의 제3 특징 데이터에 제2 특징 처리를 수행하여 하나 이상의 제4 특징 데이터를 획득하고, 상기 제1 특징 데 이터 및 상기 하나 이상의 제4 특징 데이터에 기초하여 제5 특징 데이터를 획득하고, 및 상기 제5 특징 데이터 에 기초하여 제3 프레임을 생성하는 것을 포함할 수 있는 동작을 수행하게 할 수 있다. 일 실시예에서, 상기 하나 이상의 양방향 모션 정보에 기초하여 하나 이상의 특징 페어(feature pair) 각각에 제1 특징 처리를 수행하여 하나 이상의 제3 특징 데이터를 획득하는 것은, 상기 하나 이상의 양방향 모션 정보 에 기초하여 상기 하나 이상의 제2 특징 데이터를 와핑하고, 상기 제1 특징 데이터 및 상기 와핑된 하나 이상의 제2 특징 데이터를 패치 임베딩으로 변환하고, 상기 패치 임베딩은 상기 제1 특징 데이터로부터 변환된 제1 패 치 임베딩, 및 상기 와핑된 하나 이상의 제2 특징 데이터로부터 변환된 제2 패치 임베딩을 포함하고, 상기 제1 및 제2 패치 임베딩은 각각 소정의 크기의 복수의 패치를 포함하고, 상기 패치 임베딩에 대하여 어텐션 (attention)을 수행하고, 및 상기 어텐션 결과에 기초하여 상기 하나 이상의 제3 특징 데이터를 획득하는 것을 포함할 수 있다. 일 실시예에서, 상기 패치 임베딩에 대하여 어텐션(attention)을 수행하는 것은, 상기 제1 패치 임베딩에 기초 하여 쿼리(query)를 획득하고, 상기 제2 패치 임베딩에 기초하여 키(key) 및 밸류(value)를 획득하고, 상기 쿼 리 및 상기 키에 기초하여 가중치를 계산하고, 및 상기 밸류에 상기 가중치를 적용하는 것을 포함할 수 있다. 일 실시예에서, 상기 패치 임베딩에 대하여 어텐션(attention)을 수행하는 것은, 상기 패치 임베딩에 포함된 복 수의 패치에 대하여 패치 단위로 제1 어텐션을 수행하고, 및 상기 패치 임베딩에 포함된 복수의 패치에 대하여 픽셀 단위로 제2 어텐션을 수행하는 것을 포함할 수 있다. 일 실시예에서, 상기 하나 이상의 양방향 모션 정보에 기초하여 상기 하나 이상의 제3 특징 데이터에 제2 특징 처리를 수행하여 하나 이상의 제4 특징 데이터를 획득하는 것은, 상기 하나 이상의 양방향 모션 정보에 기초하 여 하나 이상의 변환 파라미터를 획득하고, 및 상기 하나 이상의 변환 파라미터에 기초하여 상기 하나 이상의 제3 특징 데이터에 소정의 변환 동작을 통해 상기 하나 이상의 제4 특징 데이터를 획득하는 것을 포함할 수 있 다. 일 실시예에서, 상기 하나 이상의 변환 파라미터는 스케일 인자(scale factor) 및 바이어스(bias)를 포함할 수 있다. 일 실시예에서, 상기 소정의 변환 동작은 상기 하나 이상의 제3 특징 데이터에 상기 스케일 인자를 곱하고, 곱 셈 결과에 상기 바이어스를 합산하는 것을 포함할 수 있다. 일 실시예에서, 상기 제1 특징 데이터 및 상기 하나 이상의 제4 특징 데이터에 기초하여 제5 특징 데이터를 획 득하는 것은, 상기 하나 이상의 제4 특징 데이터를 연결하고, 상기 연결된 하나 이상의 제4 특징 데이터에 컨볼루션 연산을 수행하고, 및 상기 컨볼루션 연산 결과에 상기 제1 특징 데이터를 합산하는 것을 포함할 수 있다. 일 실시예에서, 상기 동작은, 상기 제1 특징 데이터에 제3 특징 처리를 수행하여 제6 특징 데이터를 획득하고, 및 상기 하나 이상의 제4 특징 데이터 및 상기 제6 특징 데이터에 기초하여 상기 제5 특징 데이터를 획득하는 것을 더 포함할 수 있다. 일 실시예에서, 상기 양방향 모션 정보는 상기 제1 프레임에서 상기 대응하는 제2 프레임으로의 제1 모션 정보, 및 상기 대응하는 제2 프레임에서 상기 제1 프레임으로의 제2 모션 정보를 포함할 수 있다."}
{"patent_id": "10-2024-0041986", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른, 동영상 처리 네트워크를 도시한다. 도 2는 본 개시의 일 실시예에 따른, 특징 처리 네트워크를 도시한다. 도 3은 본 개시의 일 실시예에 따른, 멀티 프레임 매칭 모듈을 도시한다. 도 4는 본 개시의 일 실시예에 따른, 특징 매칭 모듈을 도시한다. 도 5는 본 개시의 일 실시예에 따른, 변환기 레이어를 도시한다. 도 6은 본 개시의 일 실시예에 따른, 제1 어텐션 모듈을 도시한다. 도 7은 본 개시의 일 실시예에 따른, 제2 어텐션 모듈을 도시한다. 도 8a는 본 개시의 일 실시예에 따른, 제1 어텐션 모듈 및 제2 어텐션 모듈의 배치 예시를 도시한다. 도 8b는 본 개시의 일 실시예에 따른, 제1 어텐션 모듈 및 제2 어텐션 모듈의 배치 예시를 도시한다. 도 9는 본 개시의 일 실시예에 따른, 특징 변환 모듈을 도시한다. 도 10은 본 개시의 일 실시예에 따른, 특징 변환 모듈을 도시한다. 도 11은 본 개시의 일 실시예에 따른, 동영상 처리 방법의 순서도이다. 도 12는 본 개시의 일 실시예에 따른, 동영상을 처리하는 전자 장치를 도시한다."}
