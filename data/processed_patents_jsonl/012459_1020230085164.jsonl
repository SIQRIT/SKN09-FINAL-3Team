{"patent_id": "10-2023-0085164", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0004486", "출원번호": "10-2023-0085164", "발명의 명칭": "입체 영상의 표시 방법 및 이를 수행하는 디스플레이 시스템", "출원인": "삼성디스플레이 주식회사", "발명자": "원병희"}}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 데이터를 모델링하여 3차원 모델을 생성하는 단계;상기 3차원 모델의 각각의 시점들을 서브 픽셀들에 매핑하는 단계;상기 3차원 모델을 렌더링하여 각각의 상기 시점들에 대한 렌더링 영상 데이터를 생성하는 단계; 및각각의 상기 시점들에 대한 상기 렌더링 영상 데이터를 기초로 입체 영상 데이터를 생성하는 단계를 포함하는입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 3차원 모델은 상기 시점들 중 동일한 시점으로 매핑된 상기 서브 픽셀들에 대하여 렌더링되는 것을 특징으로 하는 입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 3차원 모델은 상기 시점들 중 적어도 두 개의 인접한 시점들로 매핑된 상기 서브 픽셀들에 대하여 렌더링되는 것을 특징으로 하는 입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 입체 영상 데이터는 각각의 상기 시점들에 대한 상기 렌더링 영상 데이터를 합하여 생성되는 것을 특징으로 하는 입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서, 상기 3차원 모델은 상기 영상 데이터를 제1 해상도로 모델링하여 생성되고,상기 렌더링 영상 데이터를 상기 제1 해상도에서 상기 제1 해상도보다 높은 제2 해상도로 업스케일링(up-scaling)하는 단계를 더 포함하는 것을 특징으로 하는 입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서, 상기 제2 해상도는 표시 패널의 해상도인 것을 특징으로 하는 입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 5 항에 있어서, 상기 업스케일링은 딥러닝(deep learning)을 활용한 초고해상도(super resolution) 알고리즘을 통하여 수행되는 것을 특징으로 하는 입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 5 항에 있어서, 동영상에 대한 상기 렌더링 영상 데이터는 초고속 업스케일링 알고리즘을 통하여 업스케일링되고,정지 영상에 대한 상기 렌더링 영상 데이터는 고화질 업스케일링 알고리즘을 통하여 업스케일링되는 것을 특징으로 하는 입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서, 상기 초고속 업스케일링 알고리즘은 쌍삼차 보간법(bicubic interpolation)을 활용하는 것을특징으로 하는 입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2025-0004486-3-제 8 항에 있어서, 상기 고화질 업스케일링 알고리즘은 초고해상도 합성곱 신경망(fast super resolutionconvolutional neural network)을 활용하는 것을 특징으로 하는 입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "영상 데이터를 제1 해상도로 모델링하여 3차원 모델을 생성하는 단계;상기 3차원 모델을 렌더링하여 각각의 시점들에 대한 렌더링 영상 데이터를 생성하는 단계;상기 렌더링 영상 데이터를 상기 제1 해상도에서 상기 제1 해상도보다 높은 제2 해상도로 업스케일링(up-scaling)하는 단계; 및상기 렌더링 영상 데이터의 각각의 상기 시점들을 서브 픽셀들에 매핑하여 입체 영상 데이터를 생성하는 단계를포함하는 입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서, 상기 제2 해상도는 표시 패널의 해상도인 것을 특징으로 하는 입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11 항에 있어서, 상기 업스케일링은 딥러닝(deep learning)을 활용한 초고해상도(super resolution) 알고리즘을 통하여 수행되는 것을 특징으로 하는 입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 11 항에 있어서, 동영상에 대한 상기 렌더링 영상 데이터는 초고속 업스케일링 알고리즘을 통하여 업스케일링되고,정지 영상에 대한 상기 렌더링 영상 데이터는 고화질 업스케일링 알고리즘을 통하여 업스케일링되는 것을 특징으로 하는 입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서, 상기 초고속 업스케일링 알고리즘은 쌍삼차 보간법(bicubic interpolation)을 활용하는 것을 특징으로 하는 입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 14 항에 있어서, 상기 고화질 업스케일링 알고리즘은 초고해상도 합성곱 신경망(fast super resolutionconvolutional neural network)을 활용하는 것을 특징으로 하는 입체 영상의 표시 방법."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "영상 데이터를 기초로 입체 영상 데이터를 생성하는 메인 프로세서; 및상기 입체 영상 데이터를 기초로 입체 영상을 표시하는 표시 장치를 포함하고,상기 표시 장치는제1 방향 및 상기 제1 방향과 교차하는 제2 방향으로 배열되는 서브 픽셀들을 포함하는 표시 패널;상기 서브 픽셀들과 상기 제1 방향 및 상기 제2 방향과 교차하는 제3 방향에서 중첩되는 렌즈들; 및상기 표시 패널을 구동하는 표시 패널 구동부를 포함하고,상기 메인 프로세서는 상기 영상 데이터를 모델링하여 3차원 모델을 생성하고, 상기 3차원 모델의 각각의 시점들을 서브 픽셀들에 매핑하며, 상기 3차원 모델을 렌더링하여 각각의 상기 시점들에 대한 렌더링 영상 데이터를생성하고, 각각의 상기 시점들에 대한 상기 렌더링 영상 데이터를 기초로 상기 입체 영상 데이터를 생성하는 것을 특징으로 하는 디스플레이 시스템."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "공개특허 10-2025-0004486-4-제 17 항에 있어서, 상기 3차원 모델은 상기 시점들 중 동일한 시점으로 매핑된 상기 서브 픽셀들에 대하여 렌더링되는 것을 특징으로 하는 디스플레이 시스템."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 17 항에 있어서, 상기 3차원 모델은 상기 시점들 중 상기 시점들 중 적어도 두 개의 인접한 시점들로 매핑된상기 서브 픽셀들에 대하여 렌더링되는 것을 특징으로 하는 디스플레이 시스템."}
{"patent_id": "10-2023-0085164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 17 항에 있어서, 상기 3차원 모델은 상기 영상 데이터를 제1 해상도로 모델링하여 생성되고,상기 표시 패널 구동부는 상기 렌더링 영상 데이터를 상기 제1 해상도에서 상기 제1 해상도보다 높은 제2 해상도로 업스케일링(up-scaling)하는 것을 특징으로 하는 디스플레이 시스템."}
{"patent_id": "10-2023-0085164", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "입체 영상의 표시 방법은 영상 데이터를 모델링하여 3차원 모델을 생성하고, 3차원 모델의 각각의 시점들을 서브 픽셀들에 매핑하며, 3차원 모델을 렌더링하여 각각의 시점들에 대한 렌더링 영상 데이터를 생성하고, 각각의 시 점들에 대한 렌더링 영상 데이터를 기초로 입체 영상 데이터를 생성한다."}
{"patent_id": "10-2023-0085164", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 입체 영상의 표시 방법 및 이를 수행하는 디스플레이 시스템에 관한 것이다. 보다 상세하게는, 입체 영상 데이터를 생성하는 입체 영상의 표시 방법 및 이를 수행하는 디스플레이 시스템에 관한 것이다."}
{"patent_id": "10-2023-0085164", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보화 기술이 발달함에 따라 사용자와 정보간의 연결매체인 표시 장치의 중요성이 부각되고 있다. 이에 부응하 여 액정 표시 장치(Liquid Crystal Display Device), 유기 발광 표시 장치(Organic Light Emitting Display Device) 등과 같은 표시 장치의 사용이 증가하고 있다. 입체 영상 표시 장치는 시청자의 시각적 감각을 실제 사물과 동일하게 자극하여 입체로 인지하도록 물리적 요인 을 제공하는 표시 장치이다. 예를 들어, 입체 영상 표시 장치는 시청자의 좌안과 우안에 서로 다른 영상을 제공 함으로써 시청자가 좌안과 우안의 양안 시차(Binocular Parallax)에 의해 입체 영상을 시청할 수 있도록 할 수 있다. 최근에는, 입체 안경을 착용하지 않는 무안경 방식에 대한 연구가 활발히 진행되고 있다. 무안경 방식으로는, 원통형의 렌즈 어레이를 이용해 좌안과 우안 영상을 분리하는 렌티큘러(Lenticular) 방식과 배리어(Barrier)를 이용하여 좌안과 우안 영상을 분리하는 배리어 방식 등이 있다."}
{"patent_id": "10-2023-0085164", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 목적은 입체 영상 데이터를 생성하는 속도를 향상시키는 입체 영상의 표시 방법을 제공하는 것이다. 본 발명의 다른 목적은 입체 영상의 표시 방법을 수행하는 디스플레이 시스템을 제공하는 것이다."}
{"patent_id": "10-2023-0085164", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 목적을 달성하기 위하여, 본 발명의 실시예들에 따른 입체 영상의 표시 방법은 영상 데이터를 모 델링하여 3차원 모델을 생성하는 단계, 상기 3차원 모델의 각각의 시점들을 서브 픽셀들에 매핑하는 단계, 상기 3차원 모델을 렌더링하여 각각의 상기 시점들에 대한 렌더링 영상 데이터를 생성하는 단계, 및 각각의 상기 시 점들에 대한 상기 렌더링 영상 데이터를 기초로 입체 영상 데이터를 생성하는 단계를 포함할 수 있다. 일 실시예에 있어서, 상기 3차원 모델은 상기 시점들 중 동일한 시점으로 매핑된 상기 서브 픽셀들에 대하여 렌 더링될 수 있다. 일 실시예에 있어서, 상기 3차원 모델은 상기 시점들 중 적어도 두 개의 인접한 시점들로 매핑된 상기 서브 픽 셀들에 대하여 렌더링될 수 있다. 일 실시예에 있어서, 상기 입체 영상 데이터는 각각의 상기 시점들에 대한 상기 렌더링 영상 데이터를 합하여 생성될 수 있다. 일 실시예에 있어서, 상기 3차원 모델은 상기 영상 데이터를 제1 해상도로 모델링하여 생성되고, 상기 렌더링 영상 데이터를 상기 제1 해상도에서 상기 제1 해상도보다 높은 제2 해상도로 업스케일링(up-scaling)하는 단계 를 더 포함할 수 있다. 일 실시예에 있어서, 상기 제2 해상도는 표시 패널의 해상도일 수 있다. 일 실시예에 있어서, 상기 업스케일링은 딥러닝(deep learning)을 활용한 초고해상도(super resolution) 알고리 즘을 통하여 수행될 수 있다. 일 실시예에 있어서, 동영상에 대한 상기 렌더링 영상 데이터는 초고속 업스케일링 알고리즘을 통하여 업스케일 링되고, 정지 영상에 대한 상기 렌더링 영상 데이터는 고화질 업스케일링 알고리즘을 통하여 업스케일링될 수 있다. 일 실시예에 있어서, 상기 초고속 업스케일링 알고리즘은 쌍삼차 보간법(bicubic interpolation)을 활용할 수 있다. 일 실시예에 있어서, 상기 고화질 업스케일링 알고리즘은 초고해상도 합성곱 신경망(fast super resolution convolutional neural network)을 활용할 수 있다. 본 발명의 일 목적을 달성하기 위하여, 본 발명의 실시예들에 따른 입체 영상의 표시 방법은 영상 데이터를 제1 해상도로 모델링하여 3차원 모델을 생성하는 단계, 상기 3차원 모델을 렌더링하여 각각의 시점들에 대한 렌더링 영상 데이터를 생성하는 단계, 상기 렌더링 영상 데이터를 상기 제1 해상도에서 상기 제1 해상도보다 높은 제2 해상도로 업스케일링(up-scaling)하는 단계, 및 상기 렌더링 영상 데이터의 각각의 상기 시점들을 서브 픽셀들 에 매핑하여 입체 영상 데이터를 생성하는 단계를 포함할 수 있다. 일 실시예에 있어서, 상기 제2 해상도는 표시 패널의 해상도일 수 있다. 일 실시예에 있어서, 상기 업스케일링은 딥러닝(deep learning)을 활용한 초고해상도(super resolution) 알고리 즘을 통하여 수행될 수 있다. 일 실시예에 있어서, 동영상에 대한 상기 렌더링 영상 데이터는 초고속 업스케일링 알고리즘을 통하여 업스케일 링되고, 정지 영상에 대한 상기 렌더링 영상 데이터는 고화질 업스케일링 알고리즘을 통하여 업스케일링될 수 있다. 일 실시예에 있어서, 상기 초고속 업스케일링 알고리즘은 쌍삼차 보간법(bicubic interpolation)을 활용할 수 있다. 일 실시예에 있어서, 상기 고화질 업스케일링 알고리즘은 초고해상도 합성곱 신경망(fast super resolution convolutional neural network)을 활용할 수 있다. 본 발명의 다른 목적을 달성하기 위하여, 본 발명의 실시예들에 따른 디스플레이 시스템은 영상 데이터를 기초 로 입체 영상 데이터를 생성하는 메인 프로세서, 및 상기 입체 영상 데이터를 기초로 입체 영상을 표시하는 표 시 장치를 포함하고, 상기 표시 장치는 제1 방향 및 상기 제1 방향과 교차하는 제2 방향으로 배열되는 서브 픽 셀들을 포함하는 표시 패널, 상기 서브 픽셀들과 상기 제1 방향 및 상기 제2 방향과 교차하는 제3 방향에서 중 첩되는 렌즈들, 및 상기 표시 패널을 구동하는 표시 패널 구동부를 포함하고, 상기 메인 프로세서는 상기 영상 데이터를 모델링하여 3차원 모델을 생성하고, 상기 3차원 모델의 각각의 시점들을 서브 픽셀들에 매핑하며, 상 기 3차원 모델을 렌더링하여 각각의 상기 시점들에 대한 렌더링 영상 데이터를 생성하고, 각각의 상기 시점들에 대한 상기 렌더링 영상 데이터를 기초로 상기 입체 영상 데이터를 생성할 수 있다. 일 실시예에 있어서, 상기 3차원 모델은 상기 시점들 중 동일한 시점으로 매핑된 상기 서브 픽셀들에 대하여 렌 더링될 수 있다. 일 실시예에 있어서, 상기 3차원 모델은 상기 시점들 중 상기 시점들 중 적어도 두 개의 인접한 시점들로 매핑 된 상기 서브 픽셀들에 대하여 렌더링될 수 있다. 일 실시예에 있어서, 상기 3차원 모델은 상기 영상 데이터를 제1 해상도로 모델링하여 생성되고, 상기 표시 패 널 구동부는 상기 렌더링 영상 데이터를 상기 제1 해상도에서 상기 제1 해상도보다 높은 제2 해상도로 업스케일 링(up-scaling)할 수 있다."}
{"patent_id": "10-2023-0085164", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들에 따른 입체 영상의 표시 방법은 각 시점에 대한 서브 픽셀들에 대하여 3차원 모델을 렌더 링함으로써, 렌더링 속도를 향상시킬 수 있다. 본 발명의 실시예들에 따른 입체 영상의 표시 방법은 영상 데이터를 낮은 해상도로 모델링하여 생성된 3차원 모 델을 렌더링함으로써, 렌더링 속도를 향상시킬 수 있다."}
{"patent_id": "10-2023-0085164", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "다만, 본 발명의 효과는 상술한 효과에 한정되는 것이 아니며, 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위에서 다양하게 확장될 수 있을 것이다."}
{"patent_id": "10-2023-0085164", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명에 따른 바람직한 실시예를 첨부한 도면을 참조하여 상세히 설명한다. 하기의 설명에서는 본 발명 에 따른 동작을 이해하는데 필요한 부분만이 설명되며 그 이외 부분의 설명은 본 발명의 요지를 모호하지 않도 록 하기 위해 생략될 것이라는 것을 유의하여야 한다. 또한 본 발명은 여기에서 설명되는 실시예에 한정되지 않"}
{"patent_id": "10-2023-0085164", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "고 다른 형태로 구체화될 수도 있다. 단지, 여기에서 설명되는 실시예는 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 본 발명의 기술적 사상을 용이하게 실시할 수 있을 정도로 상세히 설명하기 위하여 제공되 는 것이다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"간접적으로 연결\"되어 있는 경우도 포함한다. 여기에서 사용된 용 어는 특정한 실시예들을 설명하기 위한 것이며 본 발명을 한정하기 위한 것이 아니다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. \"X, Y, 및 Z 중 적어도 어느 하나\", 그리고 \"X, Y, 및 Z로 구성된 그룹으로부터 선택된 적어도 어느 하나\"는 X 하나, Y 하나, Z 하나, 또는 X, Y, 및 Z 중 둘 또는 그 이상의 어떤 조합 (예를 들면, XYZ, XYY, YZ, ZZ) 으로 해석될 수 있다. 여기에서, \"및/또는\"은 해 당 구성들 중 하나 또는 그 이상의 모든 조합을 포함한다. 여기에서, 제1, 제2 등과 같은 용어가 다양한 구성 요소들을 설명하기 위해 사용될 수 있지만, 이러한 구성 요 소들은 이러한 용어들에 한정되지 않는다. 이러한 용어들은 하나의 구성 요소를 다른 구성 요소와 구별하기 위 해 사용된다. 따라서, 제1 구성 요소는 여기에 개시된 바를 벗어나지 않는 범위 내에서 제2 구성 요소를 칭할 수 있다.\"아래\", \"위\" 등과 같이 공간적으로 상대적인 용어가 설명의 목적으로 사용될 수 있으며, 그렇게 함으로써 도면 에서 도시된 대로 하나의 소자 또는 특징과 다른 소자(들) 또는 특징(들)과의 관계를 설명한다. 공간적으로 상 대적인 용어는 도면에 묘사된 방향에 더하여, 사용 시, 동작 시, 및/또는 제조 시의 상이한 방향들도 포함하도 록 의도된 것이다. 예를 들면, 도면에 도시된 장치가 뒤집히면, 다른 소자들 또는 특징들의 \"아래\"에 위치하는 것으로 묘사된 소자들은 다른 소자들 또는 특징들의 \"위\"의 방향에 위치한다. 따라서, 일 실시예에서 \"아래\"라 는 용어는 위와 아래의 양 방향을 포함할 수 있다. 뿐만 아니라, 장치는 그 외 다른 방향을 향할 수 있고(예를 들어, 90도 회전된 혹은 다른 방향에서), 이에 따라, 여기에서 사용되는 공간적으로 상대적인 용어들은 그에 따 라 해석된다. 다양한 실시예들이 이상적인 실시예들을 도식화한 도면들을 참조하여 설명된다. 이에 따라, 예를 들면 허용 오 차들 및/또는 제조 기술들에 따라 그 형상들이 변화할 수 있음이 예상될 것이다. 따라서, 여기에 개시된 실시예 들은 도시된 특정 형상들에 한정되는 것으로 해석될 수 없으며, 예를 들면 제조의 결과로 발생하는 형상들의 변 화들을 포함하는 것으로 해석되어야 한다. 이와 같이, 도면들에 도시된 형상들은 장치의 영역들의 실제 형상들 을 도시하지 않을 수 있으며, 본 실시예들은 여기에 한정되지 않는다. 도 1은 본 발명의 실시예들에 따른 입체 영상의 표시 방법을 나타내는 순서도이다. 도 1을 참조하면, 입체 영상의 표시 방법은 영상 데이터를 모델링하여 3차원 모델을 생성(S110)하고, 3차원 모 델의 각각의 시점들을 서브 픽셀들에 매핑(S120)하며, 3차원 모델을 렌더링하여 각각의 시점들에 대한 렌더링 영상 데이터를 생성(S130)하고, 각각의 시점들에 대한 렌더링 영상 데이터를 기초로 입체 영상 데이터를 생성 (S140)할 수 있다. 이하 도 2 내지 도 8을 참조하여 구체적으로 설명한다. 도 2는 도 1의 입체 영상의 표시 방법에 따른 디스플레이 시스템을 나타내는 블록도이다. 도 2를 참조하면, 디스플레이 시스템은 메인 프로세서 및 표시 장치를 포함할 수 있다. 예를 들어, 메인 프로세서는 중앙처리장치(central processing unit; CPU) 또는 어플리케이션 프로세서(application processor; AP) 중 하나 이상을 포함할 수 있다. 메인 프로세서는 그래픽처리장치(graphic processing unit; GPU), 커뮤니케이션 프로세서(communication processor; CP), 및 이미지 신호 프로세서(image signal processor; ISP) 중 어느 하나 이상을 더 포함할 수도 있다. 메인 프로세서는 신경망 처리 장치(neural processing unit; NPU)를 더 포함할 수도 있다. 신경망 처리 장치는 인공지능 모델의 처리에 특화된 프로세서로, 인공지능 모델은 기계 학습을 통해 생성될 수 있다. 인공지능 모델은, 복수의 인공 신경망 레이어 들을 포함할 수 있다. 인공 신경망은 심층 신경망(deep neural network; DNN), CNN(convolutional neural network), RNN(recurrent neural network), RBM(restricted boltzmann machine), DBN(deep belief network), BRDNN(bidirectional recurrent deep neural network), 심층 Q-네트워크(deep Q-networks) 또는 상기 중 둘 이 상의 조합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은 하드웨어 구조 이외에, 추가적 으로 또는 대체적으로, 소프트웨어 구조를 포함할 수 있다. 상술한 처리 장치(processing unit) 및 프로세서 중 적어도 두 개가 하나의 통합된 구성(예컨대, 단일 칩)으로 구현되거나, 각각이 독립된 구성(예컨대, 복수 개의 칩)으로 구현될 수 있다. 메인 프로세서는 영상 데이터를 기초로 입체 영상 데이터(SIMG)를 생성할 수 있다. 예를 들어, 영상 데이 터는 복수의 카메라들로부터 촬영된 이미지들일 수 있다. 예를 들어, 입체 영상 데이터(SIMG)가 12개의 시점을 포함하는 경우, 영상 데이터는 12개의 카메라들로부터 촬영된 이미지들일 수 있다. 일 실시예에서, 영상 데이터 는 복수의 가상의 카메라들로부터 촬영된 이미지들일 수 있다. 표시 장치는 표시 패널 및 표시 패널 구동부를 포함할 수 있다. 표시 패널 구동부는 구동 제어부 , 게이트 드라이버, 및 데이터 드라이버를 포함할 수 있다. 일 실시예에서, 구동 제어부 및 데이터 드라이버는 하나의 칩에 집적될 수 있다. 표시 패널은 영상을 표시하는 표시 영역(DA) 및 표시 영역(DA)에 이웃하여 배치되는 비표시 영역(NDA)을 포함할 수 있다. 일 실시예에서, 게이트 드라이버는 비표시 영역(NDA)에 실장될 수 있다. 표시 패널은 복수의 게이트 라인들(GL), 복수의 데이터 라인들(DL) 및 게이트 라인들(GL)과 데이터 라인들 (DL)에 전기적으로 연결된 복수의 서브 픽셀들(SP)을 포함할 수 있다. 게이트 라인들(GL)은 제1 방향(D1)으로 연장되고, 데이터 라인들(DL)은 제1 방향(D1)과 교차하는 제2 방향(D2)으로 연장될 수 있다.구동 제어부는 메인 프로세서로부터 입체 영상 데이터(SIMG) 및 입력 제어 신호(CONT)를 수신할 수 있다. 예를 들어, 입체 영상 데이터(SIMG)는 적색 영상 데이터, 녹색 영상 데이터 및 청색 영상 데이터를 포함 할 수 있다. 일 실시예에서, 입체 영상 데이터(SIMG)는 백색 영상 데이터를 더 포함할 수 있다. 다른 예를 들어, 입체 영상 데이터(SIMG)는 마젠타색(magenta) 영상 데이터, 황색(yellow) 영상 데이터 및 시안색(cyan) 영상 데이터를 포함할 수 있다. 입력 제어 신호(CONT)는 마스터 클럭 신호 및 데이터 인에이블 신호를 포함할 수 있다. 입력 제어 신호(CONT)는 수직 동기 신호 및 수평 동기 신호를 더 포함할 수 있다. 구동 제어부는 입체 영상 데이터(SIMG) 및 입력 제어 신호(CONT)에 기초하여 제1 제어 신호(CONT1), 제2 제어 신호(CONT2), 및 데이터 신호(DATA)를 생성할 수 있다. 구동 제어부는 입력 제어 신호(CONT)에 기초하여 게이트 드라이버의 동작을 제어하기 위한 제1 제어 신호(CONT1)를 생성하여 게이트 드라이버로 출력할 수 있다. 제1 제어 신호(CONT1)는 수직 개시 신호 및 게이트 클럭 신호를 포함할 수 있다. 구동 제어부는 입력 제어 신호(CONT)에 기초하여 데이터 드라이버의 동작을 제어하기 위한 제2 제어 신호(CONT2)를 생성하여 데이터 드라이버로 출력할 수 있다. 제2 제어 신호(CONT2)는 수평 개시 신호 및 로드 신호를 포함할 수 있다. 구동 제어부는 입체 영상 데이터(SIMG) 및 입력 제어 신호(CONT)를 수신하여 데이터 신호(DATA)를 생성할 수 있다. 구동 제어부는 데이터 신호(DATA)를 데이터 드라이버로 출력할 수 있다. 게이트 드라이버는 구동 제어부로부터 입력 받은 제1 제어 신호(CONT1)에 응답하여 게이트 라인들 (GL)을 구동하기 위한 게이트 신호들을 생성할 수 있다. 게이트 드라이버는 게이트 신호들을 게이트 라인 들(GL)로 출력할 수 있다. 예를 들어, 게이트 드라이버는 게이트 신호들을 게이트 라인들(GL)에 순차적으 로 출력할 수 있다. 데이터 드라이버는 구동 제어부로부터 제2 제어 신호(CONT2) 및 데이터 신호(DATA)를 입력 받을 수 있다. 데이터 드라이버는 데이터 신호(DATA)를 아날로그 형태의 전압으로 변환한 데이터 전압들을 생성할 수 있다. 데이터 드라이버는 데이터 전압들을 데이터 라인(DL)으로 출력할 수 있다. 도 3 및 도 4는 렌즈 어레이 방식의 입체 영상을 표시하는 표시 장치를 설명하기 위한 도면이다. 도 2 내지 도 4를 참조하면, 표시 장치는 복수의 시점들(P)에 대한 영상을 표시할 수 있다. 예를 들어, 표시 패널을 바라보는 방향에 따라 다른 영상이 인식될 수 있다. 표시 장치는 표시 패널 및 렌즈(LS)들을 포함할 수 있다. 서브 픽셀들(SP)은 제1 방향(D1) 및 제1 방향(D1)과 교차되는 제2 방향(D2)으로 배열될 수 있다. 렌즈들(LS)은 제1 방향(D1) 및 제2 방향(D2)과 교차하 는 제3 방향(D3)에서 서브 픽셀들(SP)과 교차될 수 있다. 표시 패널은 광을 방출하여 영상을 표시하는 서브 픽셀들(SP)을 포함할 수 있다. 일 실시예에서, 서브 픽 셀들(SP) 각각은 제1 색(예를 들어, 적색)의 광, 제2 색(예를 들어, 녹색)의 광, 및 제3 색(예를 들어, 청색)의 광 중 하나를 출력할 수 있다. 다만, 이는 예시적인 것으로서, 서브 픽셀들(SP)에서 방출되는 광의 색이 이에 한정되는 것은 아니며, 풀-컬러 구현을 위한 다양한 색의 광이 출력될 수 있다. 표시 패널은 유기 발광 표시 패널(Organic Light Emitting Display Panel), 액정 표시 패널(Liquid Crystal Display Panel), 퀀텀 닷 표시 패널(Quantum Dot Display Panel) 등을 포함할 수 있다. 렌즈들(LS)은 서브 픽셀들(SP)로부터 입사되는 광을 굴절시킬 수 있다. 예를 들어, 렌즈 어레이(LSA)는 렌티큘 러 렌즈 어레이(lenticular lens array), 마이크로 렌즈 어레이(micro lens array) 등으로 구현될 수 있다. 라이트 필드 디스플레이(light field display)는 평면 디스플레이와 광학 소자(예를 들어, 렌즈들(LS))를 이용 하여 공간 상의 광의 벡터 분포(세기, 방향)로 표현되는 라이트 필드(light field)를 형성하여 입체 영상을 구 현하는 3D 표시 장치이다. 라이트 필드 디스플레이는 사물의 깊이와 옆면 등을 볼 수 있어 보다 자연스러운 입 체 영상 구현이 가능하여 AR(증강현실) 기술 등과의 융합으로 다양한 활용이 기대되는 디스플레이 기술이다. 라이트 필드는 다양한 방식으로 구현될 수 있다. 예를 들어, 라이트 필드는, 여러 대의 프로젝터를 사용해 여러 방향의 라이트 필드를 만드는 방법, 회절 격자(Grating)를 이용해 광의 방향을 제어하는 방법, 2개 이상의 패널 을 사용해 각 화소의 조합에 따른 광의 방향과 세기(휘도)를 조절하는 방법, 핀홀(Pinhole) 또는 배리어 (Barrier)를 사용해 광의 방향을 제어하는 방법, 렌즈 어레이(lens array)를 통해 광의 굴절 방향을 제어하는방법 등으로 형성될 수 있다. 일 실시예에서, 렌즈 어레이 방식의 입체 영상을 표시하는 표시 장치는 라이트 필드를 형성하여 입체 영상(3D 영상)을 표시할 수 있다. 각각의 렌즈들(LS)에는 일련의 서브 픽셀들(SP)이 할당되고, 서브 픽셀들(SP) 각각으로부터 나온 광은 렌즈(L S)에 의해 굴절되어 특정 방향으로만 진행되어 광의 세기와 방향으로 표현되는 라이트 필드를 형성할 수 있다. 이렇게 형성된 라이트 필드 내에서 시청자가 표시 장치를 바라보게 되면 시청자는 해당 영상의 입체감을 느낄 수 있다. 도 3 및 도 4는 표시 장치가 3개의 시점들(P)을 표시하는 것을 예시하였으나, 본 발명은 시점들(P)의 개 수에 한정되지 않는다. 도 5는 도 2의 메인 프로세서의 일 예를 나타내는 블록도이고, 도 6은 도 2의 서브 픽셀들의 구조의 일 예를 나 타내는 도면이며, 도 7은 도 1의 입체 영상의 표시 방법에 따른 매핑 테이블의 일 예를 나타내는 도면이고, 도 8은 도 1의 입체 영상의 표시 방법에 따른 렌더링의 일 예를 나타내는 도면이다. 도 5를 참조하면, 메인 프로세서는 3차원 모델링부, 3차원 매핑부, 2차원 렌더링부, 및 영상 합산부를 포함할 수 있다. 3차원 모델링부는 영상 데이터(IMG)를 모델링하여 3차원 모델(TDM)을 생성할 수 있다. 예를 들어, 3차원 모델(TDM)은 객체의 좌표 정보 및 깊이 정보를 포함할 수 있다. 도 5 내지 도 7을 참조하면, 3차원 매핑부는 3차원 모델(TDM)의 각각의 시점들(P1 내지 P12)을 서브 픽셀 들(SP)에 매핑할 수 있다. 하나의 픽셀 단위(PU)는 제1 색을 표시하는 제1 색 서브 픽셀(R), 제2 색을 표시하는 제2 색 서브 픽셀(G), 및 제3 색을 표시하는 제3 색 서브 픽셀(B)을 포함할 수 있다. 도 7은 도 6의 서브 픽셀들(SP)의 구조에 따라 각각 의 서브 픽셀들(SP)에 매핑된 시점들(P1 내지 P12)을 나타낸다. 다만, 본 발명은 서브 픽셀들(SP)의 구조에 한 정되지 않는다. 3차원 매핑부는 3차원 모델(TDM)의 각각의 시점들(P1 내지 P12)이 표시되는 서브 픽셀들(SP)을 결정할 수 있다. 예를 들어, 제1 픽셀 단위(PU1)의 제1 색 서브 픽셀(R)은 3차원 모델(TDM)의 제3 시점(P3)을 표시할 수 있다. 예를 들어, 제1 픽셀 단위(PU1)의 제2 색 서브 픽셀(G)은 3차원 모델(TDM)의 제3 시점(P3)을 표시할 수 있다. 예를 들어, 제1 픽셀 단위(PU1)의 제3 색 서브 픽셀(B)은 3차원 모델(TDM)의 제3 시점(P3)을 표시할 수 있다. 도 4에 나타난 바와 같이, 각각의 서브 픽셀들(SP)에서 나온 광은 특정 방향(즉, 특정 시점)으로 굴절될 수 있 다. 따라서, 3차원 매핑부는 각각의 시점들(P1 내지 P12)을 서브 픽셀들(SP)에 매핑하여 매핑 테이블(M T)을 생성할 수 있다. 도 5 및 도 8을 참조하면, 2차원 렌더링부는 3차원 모델(TDM)을 렌더링하여 각각의 시점들(P1 내지 P12) 에 대한 렌더링 영상 데이터(RIMG)를 생성할 수 있다. 렌더링 영상 데이터(RIMG)는 3차원 모델(TDM)의 각각의 시점들(P1 내지 P12)에 대한 2차원 영상 데이터일 수 있다. 예를 들어, 표시 장치는 제1 시점(P1)으로 굴절되는 광을 출사하는 서브 픽셀들(SP)에 제1 시점(P1)에 대한 렌더링 영상 데이터(RIMG)를 표시하고, 제2 시점(P2)으 로 굴절되는 광을 출사하는 서브 픽셀들(SP)에 제2 시점(P2)에 대한 렌더링 영상 데이터(RIMG)를 표시할 수 있 다. 3차원 모델(TDM)은 시점들(P1 내지 P12) 중 동일한 시점으로 매핑된 서브 픽셀들(SP)에 대하여 렌더링될 수 있 다. 예를 들어, 제1 시점(P1)에 대한 렌더링 영상 데이터(RIMG)는 제1 시점(P1)으로 매핑된 서브 픽셀들(SP)에 표시되는 영상에 대한 데이터(예를 들어, 픽셀 데이터)를 포함할 수 있다. 즉, 제1 시점(P1)에 대한 렌더링 영 상 데이터(RIMG)를 생성함에 있어서, 2차원 렌더링부는 모든 서브 픽셀들(SP)이 아닌 제1 시점(P1)으로 매핑된 서브 픽셀들(SP)만을 고려할 수 있다. 이에 따라, 3차원 모델(TDM)의 렌더링은 모든 서브 픽셀들(SP)에 대하여 각각의 시점들(P1 내지 P12)에 대한 렌더링 영상 데이터(RIMG)를 생성할 때보다 렌더링 시간을 감소시킬 수 있다. 영상 합산부는 각각의 시점들(P1 내지 P12)에 대한 렌더링 영상 데이터(RIMG)를 기초로 입체 영상 데이터 (SIMG)를 생성할 수 있다. 일 실시예에서, 입체 영상 데이터(SIMG)는 각각의 시점들(P1 내지 P12)에 대한 렌더링 영상 데이터(RIMG)를 합하여 생성될 수 있다. 예를 들어, 제1 시점(P1)에 대한 렌더링 영상 데이터(RIMG)는 제1 시점(P1)으로 매핑된 서브 픽셀들(SP)에 표시 되는 영상에 대한 데이터를 포함하고, 제2 시점(P2)에 대한 렌더링 영상 데이터(RIMG)는 제2 시점(P2)으로 매핑 된 서브 픽셀들(SP)에 표시되는 영상에 대한 데이터를 포함할 수 있다. 제1 내지 제12 시점들(P1 내지 P12)에 대한 렌더링 영상 데이터(RIMG)를 합하여 생성된 입체 영상 데이터(SIMG)는 모든 서브 픽셀들(SP)에 표시되는 영상에 대한 데이터를 포함할 수 있다. 도 9는 본 발명의 실시예들에 따른 입체 영상의 표시 방법에 따른 렌더링의 일 예를 나타내는 도면이다. 본 실시예들에 따른 입체 영상의 표시 방법은 렌더링을 제외하고, 도 1의 입체 영상의 표시 방법의 구성과 실질 적으로 동일하므로, 동일 또는 유사한 구성 요소에 대해서는 동일한 참조 번호 및 참조 기호를 사용하고, 중복 되는 설명은 생략한다. 도 4 내지 도 7 및 도 9를 참조하면, 2차원 렌더링부는 3차원 모델(TDM)을 렌더링하여 각각의 시점들(P1 내지 P12)에 대한 렌더링 영상 데이터(RIMG)를 생성할 수 있다. 렌더링 영상 데이터(RIMG)는 3차원 모델(TDM)의 각각의 시점들(P1 내지 P12)에 대한 2차원 영상 데이터일 수 있다. 예를 들어, 표시 장치는 제1 시점(P1)으로 굴절되는 광을 출사하는 서브 픽셀들(SP)에 제1 시점(P1)에 대한 렌더링 영상 데이터(RIMG)를 표시하고, 제2 시 점(P2)으로 굴절되는 광을 출사하는 서브 픽셀들(SP)에 제2 시점(P2)에 대한 렌더링 영상 데이터(RIMG)를 표시 할 수 있다. 3차원 모델(TDM)은 시점들(P1 내지 P12) 중 적어도 두 개의 인접한 시점들(예를 들어, 제1 시점(P1) 및 제2 시 점(P2))로 매핑된 서브 픽셀들(SP)에 대하여 렌더링될 수 있다. 렌즈들(LS)은 제조 공정 과정에서 표시 패널과 부분적으로 어긋날 수 있다. 이 경우, 매핑 테이블(MT)이 보정될 수 있다. 예를 들어, 도 7은 보정 전 매핑 테이블(MT)이고, 도 9는 보정 후 매핑 테이블(MT)일 수 있다. 예를 들어, 렌즈들(LS)이 부분적으로 어긋나, 제1 픽셀 단위(PU1)의 제3 색 서브 픽셀(B)에서 나온 광이 제2 시 점(P2)에 대응하는 방향 및 제3 시점(P3)에 대응하는 방향 모두로 굴절될 수 있다. 이 경우, 제1 픽셀 단위 (PU1)의 제3 색 서브 픽셀(B)에 대한 매핑 테이블(MT)은 제3 시점(P3)에서 제2.5 시점(P2.5)으로 보정될 수 있 다. 그리고, 제3 시점(P3)에 대한 렌더링 영상 데이터(RIMG)는 제1 픽셀 단위(PU1)의 제3 색 서브 픽셀(B)에 보 정 전의 픽셀 데이터와 제2 픽셀 단위(PU2)의 제3 색 서브 픽셀(B)의 보정 전의 픽셀 데이터를 기초로 결정된 제1 픽셀 단위(PU1)의 제3 색 서브 픽셀(B)에 대한 픽셀 데이터를 포함할 수 있다. 여기서, 제2 픽셀 단위(PU 2)는 제1 픽셀 단위(PU1)에 인접하고, 보정 전 제2 픽셀 단위(PU2)의 제3 색 서브 픽셀(B)은 보정 전 제1 픽셀 단위(PU1)의 제3 색 서브 픽셀(B)에 매핑된 제3 시점(P3)과 인접한 제2 시점(P2)으로 매핑될 수 있다. 그리고, 픽셀 데이터는 계조 값일 수 있다. 즉, 제3 시점(P3)에 대한 렌더링 영상 데이터(RIMG)를 생성함에 있어서, 2차원 렌더링부는 모든 서브 픽 셀들(SP)이 아닌 제3 시점(P3) 및 제2 시점(P2)으로 매핑된 서브 픽셀들(SP)만을 고려할 수 있다. 이에 따라, 3 차원 모델(TDM)의 렌더링은 모든 서브 픽셀들(SP)에 대하여 각각의 시점들(P1 내지 P12)에 대한 렌더링 영상 데 이터(RIMG)를 생성할 때보다 렌더링 시간을 감소시킬 수 있다. 도 10은 본 발명의 실시예들에 따른 입체 영상의 표시 방법을 나타내는 순서도이다. 도 10을 참조하면, 입체 영상의 표시 방법은 영상 데이터를 제1 해상도로 모델링하여 3차원 모델을 생성(S210) 하고, 3차원 모델을 렌더링하여 각각의 시점들에 대한 렌더링 영상 데이터를 생성(S220)하며, 렌더링 영상 데이 터를 제1 해상도에서 제1 해상도보다 높은 제2 해상도로 업스케일링(S230)하고, 렌더링 영상 데이터의 각각의 시점들을 서브 픽셀들에 매핑하여 입체 영상 데이터를 생성(S240)할 수 있다. 이하, 도 11 및 도 12를 참조하여 구체적으로 설명한다. 도 11은 도 10의 입체 영상의 표시 방법에 따른 메인 프로세서의 일 예를 나타내는 블록도이고, 도 12는 도 10 의 입체 영상의 표시 방법에 따른 업스케일링의 일 예를 나타내는 도면이다. 도 11을 참조하면, 메인 프로세서는 3차원 모델링부, 2차원 렌더링부, 업스케일링부, 및 3차원 매핑부를 포함할 수 있다. 3차원 모델링부는 영상 데이터(IMG)를 모델링하여 3차원 모델(TDM)을 생성할 수 있다. 예를 들어, 3차원 모델(TDM)은 객체의 좌표 정보 및 깊이 정보를 포함할 수 있다.일 실시예에서, 3차원 모델링부는 영상 데이터(IMG)를 제1 해상도(R1)로 모델링하여 3차원 모델(TDM)을 생성할 수 있다. 제1 해상도(R1)는 표시 패널의 제2 해상도(R2)보다 낮을 수 있다. 즉, 3차원 모델(TDM)을 표시 패널에 표시하기 위해서 제1 해상도(R1)를 제2 해상도(R2)로 업스케일링하는 과정이 요구된다. 2차원 렌더링부는 3차원 모델(TDM)을 렌더링하여 각각의 시점들(P1 내지 P12)에 대한 렌더링 영상 데이터 (RIMG)를 생성할 수 있다. 렌더링 영상 데이터(RIMG)는 3차원 모델(TDM)의 각각의 시점들(P1 내지 P12)에 대한 2차원 영상 데이터일 수 있다. 렌더링 영상 데이터(RIMG)는 각각의 시점들(P1 내지 P12)에 표시되는 영상에 대 한 데이터일 수 있다. 2차원 렌더링부는 제1 해상도(R1)의 3차원 모델(TDM)을 렌더링하여 제1 해상도(R1)의 렌더링 영상 데이터 (RIMG)를 생성할 수 있다. 이에 따라, 2차원 렌더링부는 제2 해상도(R2)(즉, 표시 패널의 해상도)의 3차 원 모델(TDM)을 렌더링하여 제2 해상도(R2)의 렌더링 영상 데이터(RIMG)를 생성할 때보다 렌더링 시간을 감소시 킬 수 있다. 업스케일링부는 렌더링 영상 데이터(RIMG)를 제1 해상도(R1)에서 제1 해상도(R1)보다 높은 제2 해상도 (R2)로 업스케일링할 수 있다. 제2 해상도(R2)는 표시 패널의 해상도일 수 있다. 예를 들어, 업스케일링은 딥러 닝(deep learning)을 활용한 초고해상도(super resolution) 알고리즘을 통하여 수행될 수 있다. 다만, 본 발명 은 업스케일링하는 방법에 한정되지 않는다. 일 실시예에서, 도 11 및 도 12를 참조하면, 동영상에 대한 렌더링 영상 데이터(RIMG_MI)는 초고속 업스케일링 알고리즘을 통하여 업스케일링되고, 정지 영상에 대한 렌더링 영상 데이터(RIMG_SI)는 고화질 업스케일링 알고 리즘을 통하여 업스케일링될 수 있다. 예를 들어, 제2 해상도는 제1 해상도의 2배일 수 있다. 예를 들어, 제2 해상도는 제1 해상도의 3배일 수 있다. 예를 들어, 제2 해상도는 제1 해상도의 4배일 수 있다. 제2 해상도와 제1 해상도의 차이가 클수록 레더링 속도 가 더 향상될 수 있다. 업스케일링부는 영상 구분부, 제1 업스케일링부, 및 제2 업스케일링부를 포함할 수 있 다. 영상 구분부는 렌더링 영상 데이터(RIMG)가 동영상에 대한 영상 데이터인지 정지 영상에 대한 영상 데이 터인지 구분할 수 있다. 일 실시예에서, 영상 구분부는 이전 프레임의 렌더링 영상 데이터(RIMG)와 현재 프레임의 렌더링 영상 데이터(RIMG)를 비교하여 동영상과 정지 영상을 구분할 수 있다. 일 실시예에서, 영상 구 분부는 영상 데이터(IMG) 혹은 3차원 모델(TDM)을 비교하여 동영상과 정지 영상을 구분할 수 있다. 제1 업스케일링부는 동영상에 대한 렌더링 영상 데이터(RIMG_MI)를 초고속 업스케일링 알고리즘을 통하여 업스케일링 할 수 있다. 초고속 업스케일링 알고리즘은 고화질 업스케일링 알고리즘과 비교하여 상대적으로 높 은 속도로 업스케일링할 수 있다. 예를 들어, 초고속 업스케일링 알고리즘은 쌍삼차 보간법(bicubic interpolation)을 활용할 수 있다. 제2 업스케일링부는 정지 영상에 대한 렌더링 영상 데이터(RIMG_SI)를 고화질 업스케일링 알고리즘을 통 하여 업스케일링 할 수 있다. 고화질 업스케일링 알고리즘은 초고속 업스케일링 알고리즘과 비교하여 상대적으 로 높은 화질로 업스케일링할 수 있다. 예를 들어, 고화질 업스케일링 알고리즘은 초고해상도 합성곱 신경망 (fast super resolution convolutional neural network)을 활용할 수 있다. 도 11을 참조하면, 3차원 매핑부는 렌더링 영상 데이터(RIMG)의 각각의 시점들을 서브 픽셀들에 매핑하여 입체 영상 데이터(SIMG)를 생성할 수 있다. 3차원 매핑부는 렌더링 영상 데이터(RIMG)의 각각의 시점들이 표시되는 서브 픽셀들을 결정할 수 있다. 그리고, 3차원 매핑부는 각각의 시점들에 대한 렌더링 영상 데이터(RIMG)를 합하여 입체 영상 데이터 (SIMG)를 생성할 수 있다. 도 13은 본 발명의 실시예들에 따른 입체 영상의 표시 방법을 나타내는 순서도이다. 본 실시예들에 따른 입체 영상의 표시 방법은 모델링 및 업스케일링을 제외하고, 도 1의 입체 영상의 표시 방법 의 구성과 실질적으로 동일하므로, 동일 또는 유사한 구성 요소에 대해서는 동일한 참조 번호 및 참조 기호를 사용하고, 중복되는 설명은 생략한다. 도 13을 참조하면, 입체 영상의 표시 방법은 영상 데이터를 제1 해상도로 모델링하여 3차원 모델을 생성(S210) 하고, 3차원 모델의 각각의 시점들을 서브 픽셀들에 매핑(S120)하며, 3차원 모델을 렌더링하여 각각의 시점들에 대한 렌더링 영상 데이터를 생성(S130)하고, 렌더링 영상 데이터를 제1 해상도에서 제1 해상도보다 높은 제2 해 상도로 업스케일링(S230)하며, 각각의 시점들에 대한 렌더링 영상 데이터를 기초로 입체 영상 데이터를 생성 (S140)할 수 있다. 이하, 도 14를 참조하여 구체적으로 설명한다. 도 14는 도 13의 입체 영상의 표시 방법에 따른 메인 프로세서의 일 예를 나타내는 블록도이다. 도 14를 참조하면, 메인 프로세서는 3차원 모델링부, 3차원 매핑부, 2차원 렌더링부, 업스케일링부, 및 영상 합산부를 포함할 수 있다. 3차원 모델링부는 영상 데이터(IMG)를 모델링하여 3차원 모델(TDM)을 생성할 수 있다. 예를 들어, 3차원 모델(TDM)은 객체의 좌표 정보 및 깊이 정보를 포함할 수 있다. 일 실시예에서, 3차원 모델링부는 영상 데이터(IMG)를 제1 해상도(R1)로 모델링하여 3차원 모델(TDM)을 생성할 수 있다. 제1 해상도(R1)는 표시 패널의 제2 해상도(R2)보다 낮을 수 있다. 즉, 3차원 모델(TDM)을 표시 패널에 표시하기 위해서 제1 해상도(R1)를 제2 해상도(R2)로 업스케일링하는 과정이 요구된다. 업스케일링부는 렌더링 영상 데이터(RIMG)를 제1 해상도(R1)에서 제1 해상도(R1)보다 높은 제2 해상도 (R2)로 업스케일링할 수 있다. 제2 해상도(R2)는 표시 패널의 해상도일 수 있다. 다만, 본 발명은 업스케일링하 는 방법에 한정되지 않는다. 산업상 이용가능성 본 발명은 표시 장치 및 이를 포함하는 전자 기기에 적용될 수 있다. 예를 들어, 본 발명은 디지털 TV, 3D TV, 휴대폰, 스마트 폰, 태블릿 컴퓨터, VR 기기, PC, 가정용 전자기기, 노트북 컴퓨터, PDA, PMP, 디지털 카메라, 음악 재생기, 휴대용 게임 콘솔, 내비게이션 등에 적용될 수 있다. 이상 실시예들을 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2023-0085164", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예들에 따른 입체 영상의 표시 방법을 나타내는 순서도이다. 도 2는 도 1의 입체 영상의 표시 방법에 따른 디스플레이 시스템을 나타내는 블록도이다. 도 3 및 도 4는 렌즈 어레이 방식의 입체 영상을 표시하는 표시 장치를 설명하기 위한 도면이다. 도 5는 도 2의 메인 프로세서의 일 예를 나타내는 블록도이다. 도 6은 도 2의 서브 픽셀들의 구조의 일 예를 나타내는 도면이다. 도 7은 도 1의 입체 영상의 표시 방법에 따른 매핑 테이블의 일 예를 나타내는 도면이다. 도 8은 도 1의 입체 영상의 표시 방법에 따른 렌더링의 일 예를 나타내는 도면이다. 도 9는 본 발명의 실시예들에 따른 입체 영상의 표시 방법에 따른 렌더링의 일 예를 나타내는 도면이다. 도 10은 본 발명의 실시예들에 따른 입체 영상의 표시 방법을 나타내는 순서도이다. 도 11은 도 10의 입체 영상의 표시 방법에 따른 메인 프로세서의 일 예를 나타내는 블록도이다. 도 12는 도 10의 입체 영상의 표시 방법에 따른 업스케일링의 일 예를 나타내는 도면이다. 도 13은 본 발명의 실시예들에 따른 입체 영상의 표시 방법을 나타내는 순서도이다. 도 14는 도 13의 입체 영상의 표시 방법에 따른 메인 프로세서의 일 예를 나타내는 블록도이다."}
