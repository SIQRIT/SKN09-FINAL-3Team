{"patent_id": "10-2018-0124634", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0046186", "출원번호": "10-2018-0124634", "발명의 명칭": "로봇 및 그의 제어 방법", "출원인": "엘지전자 주식회사", "발명자": "박용진"}}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자를 감지하는 적어도 하나의 센서를 포함하는 사용자 감지부; 상기 사용자 감지부에 의해 감지된 사용자의 얼굴을 포함하는 이미지를 획득하는 얼굴 검출부;상기 획득된 이미지로부터 상기 사용자의 인터랙션 의도를 검출하는 제어부; 및상기 인터랙션 의도가 검출된 경우, 상기 사용자의 인터랙션 유도를 위한 음성과 화면 중 적어도 하나를 출력하기 위한 스피커와 디스플레이 중 적어도 하나를 포함하는 출력부를 포함하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 사용자 감지부는,상기 로봇으로부터 기설정된 거리 이내의 감지 영역에 존재하는 오브젝트를 감지하는 오브젝트 감지 센서; 및상기 감지된 오브젝트가 상기 사용자인지 여부를 감지하는 사용자 감지 센서를 포함하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제어부는,상기 사용자 감지부를 통해 상기 감지 영역에 존재하는 복수의 사용자들을 감지하고,상기 감지된 복수의 사용자들 중, 상기 감지 영역 내의 인터랙션 의도 검출 영역으로 선 진입한 제1 사용자의얼굴을 포함하는 제1 이미지를 획득하도록 상기 얼굴 검출부를 제어하고, 상기 획득된 제1 이미지에 기초하여 상기 제1 사용자의 인터랙션 의도를 검출하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제어부는,상기 제1 사용자의 인터랙션 의도가 검출된 경우, 상기 제1 사용자의 인터랙션 유도를 위한 음성과 화면 중 적어도 하나를 출력하도록 상기 출력부를 제어하고,상기 제1 사용자의 인터랙션 의도가 검출되지 않은 경우, 상기 복수의 사용자들 중 상기 제1 사용자 다음으로상기 인터랙션 의도 검출 영역으로 진입한 제2 사용자의 얼굴을 포함하는 제2 이미지를 획득하도록 상기 얼굴검출부를 제어하고, 상기 획득된 제2 이미지에 기초하여 상기 제2 사용자의 인터랙션 의도를 검출하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 오브젝트 감지 센서는 라이다 센서(LiDar sensor)를 포함하고, 상기 사용자 감지 센서는 3D 스테레오 카메라를 포함하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,공개특허 10-2020-0046186-3-상기 제어부는,상기 얼굴 검출부에 의해 획득된 상기 이미지로부터 상기 사용자의 시선을 감지하고,감지된 시선이 상기 로봇을 향하는 경우 상기 인터랙션 의도가 존재함을 검출하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제어부는,상기 얼굴 검출부에 의해 획득된 상기 이미지로부터 상기 사용자의 특성을 검출하고,상기 인터랙션 의도가 검출된 경우, 상기 사용자의 특성에 기초하여 상기 음성과 상기 화면 중 적어도 하나를출력하도록 상기 출력부를 제어하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,사용자로부터 입력을 수신하는 입력부를 더 포함하고,상기 제어부는,상기 출력된 음성과 화면 중 적어도 하나에 기초한 입력을 상기 입력부를 통해 수신하고,수신된 입력에 기초하여 서비스를 제공함으로써 상기 사용자와의 인터랙션을 수행하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 입력부는 마이크로폰을 포함하고,상기 제어부는,상기 출력된 음성과 화면 중 적어도 하나에 기초하여 상기 사용자로부터 발화된 음성을 상기 마이크로폰을 통해수신하고,수신된 음성에 포함된 키워드를 인식하고, 인식된 키워드에 기초하여 상기 서비스를 제공하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,이동을 위한 주행부를 더 포함하고,상기 제어부는,상기 로봇의 주행 중 상기 사용자 감지부를 통해 상기 사용자의 접근을 감지하고,타 사용자에게 서비스 제공 중인 경우, 상기 사용자와의 인터랙션이 불가함을 나타내는 음성 또는 화면을 출력하도록 상기 출력부를 제어하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 제어부는,타 사용자에게 서비스 제공 중이 아닌 경우, 상기 주행부를 제어하여 주행을 정지하고,상기 얼굴 검출부를 통해 획득된 이미지로부터 상기 사용자의 인터랙션 의도를 검출하고,상기 인터랙션 의도가 검출된 경우, 상기 사용자의 인터랙션 유도를 위한 음성과 화면 중 적어도 하나를 출력하도록 상기 출력부를 제어하는 로봇.공개특허 10-2020-0046186-4-청구항 12 이동을 위한 주행부와, 오브젝트 감지 센서가 구비된 하부모듈; 상기 하부모듈의 상부에 연결되고, 사용자 감지 센서가 일 측에 구비된 바디부, 및 상기 바디부의 상부에 연결되고, 얼굴 검출부를 포함하는 헤드부를 포함하는 상부모듈;상기 오브젝트 감지 센서와 상기 사용자 감지 센서를 통해, 기설정된 거리 이내의 감지 영역에 존재하는 사용자를 감지하고, 상기 얼굴 검출부를 통해 상기 사용자의 얼굴을 포함하는 이미지를 획득하고, 획득된 이미지로부터 상기 사용자의 인터랙션 의도를 검출하는 제어부; 및상기 인터랙션 의도가 검출된 경우, 상기 사용자의 인터랙션 유도를 위한 음성과 화면 중 적어도 하나를 출력하기 위한 스피커와 디스플레이 중 적어도 하나를 포함하는 출력부를 포함하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 상부모듈에 구비되어, 상기 헤드부를 회전시키는 헤드 모터를 더 포함하고,상기 제어부는,상기 오브젝트 감지 센서와 상기 사용자 감지 센서를 통해 상기 사용자의 위치를 감지하고,상기 얼굴 검출부가 상기 사용자의 얼굴을 포함하는 이미지를 획득하기 위해, 상기 감지된 위치에 기초하여 상기 헤드부가 회전되도록 상기 헤드 모터를 제어하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 제어부는,상기 얼굴 검출부에 의해 획득된 상기 이미지로부터 상기 사용자의 시선을 감지하고,감지된 시선이 상기 헤드부를 향하는 경우, 상기 인터랙션 의도가 존재함을 검출하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 제어부는,상기 인터랙션 의도가 검출된 경우, 상기 로봇이 상기 사용자를 향하도록 상기 주행부를 제어하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 제어부는,상기 인터랙션 의도가 검출된 경우, 상기 사용자가 위치한 방향으로 주행하도록 상기 주행부를 제어하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서,상기 오브젝트 감지 센서는,상기 로봇의 전방위에 대해, 상기 감지 영역 이내의 오브젝트를 감지하는 제1 라이다 센서와 제2 라이다 센서를포함하고,상기 하부모듈의 저면으로부터 상기 제1 라이다 센서의 높이와, 상기 저면으로부터 상기 제2 라이다 센서의 높이는 서로 다른 로봇.공개특허 10-2020-0046186-5-청구항 18 제17항에 있어서,상기 사용자 감지 센서는,상기 오브젝트 감지 센서에 의해 감지된 오브젝트가 사용자인지 여부를 검출하는 3D 스테레오 카메라를 포함하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서,상기 얼굴 검출부는,상기 헤드부의 일 측에 구비된 카메라 및 RGBD 센서 중 적어도 하나를 포함하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제12항에 있어서,상기 헤드부에 구비되는 마이크로폰을 더 포함하고,상기 제어부는,상기 출력부를 통해 출력된 음성과 화면 중 적어도 하나에 기초하여 상기 사용자로부터 발화된 음성을 상기 마이크로폰을 통해 수신하고,수신된 음성에 포함된 키워드를 인식하고, 인식된 키워드에 기초하여 상기 사용자에게 서비스를 제공하는 로봇."}
{"patent_id": "10-2018-0124634", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시 예에 따른 로봇은, 사용자를 감지하는 적어도 하나의 센서를 포함하는 사용자 감지부, 상기 사용 자 감지부에 의해 감지된 사용자의 얼굴을 포함하는 이미지를 획득하는 얼굴 검출부, 상기 획득된 이미지로부터 상기 사용자의 인터랙션 의도를 검출하는 제어부, 및 상기 인터랙션 의도가 검출된 경우, 상기 사용자의 인터랙 션 유도를 위한 음성과 화면 중 적어도 하나를 출력하기 위한 스피커와 디스플레이 중 적어도 하나를 포함한다."}
{"patent_id": "10-2018-0124634", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 로봇에 관한 것으로서, 특히 상기 로봇과의 인터랙션 의도를 갖는 사용자를 스스로 인식하여, 인식된 사용자와의 인터랙션을 수행할 수 있는 로봇 및 그의 제어 방법에 관한 것이다."}
{"patent_id": "10-2018-0124634", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇의 응용분야는 대체로 산업용, 의료용, 우주용, 해저용으로 분류된다. 예를 들면, 자동차 생산과 같은 기계 가공 공업에서는 로봇이 반복작업을 수행할 수 있다. 즉, 사람의 팔이 하는 작업을 한 번만 가르쳐 주면 몇 시 간이든 같은 동작을 반복하는 산업로봇이 이미 많이 가동되고 있다. 또한, 로봇에 카메라가 장착되는 기술은 이미 종래에 많이 구현되어 있다. 로봇은 카메라를 이용하여 위치를 확인하거나 장애물을 인식할 수 있다. 또한, 촬영 영상을 디스플레이부에 표시하는 것도 충분히 구현되고 있다. 일반적으로 로봇이 제공하는 서비스는 장소, 이용자, 목적 등에 따라 다양한 반면에, 로봇이 상기 제공하는 서 비스를 위해 수행하는 동작 자체는 정해진 하중을 견디어 주어진 사양의 속도와 주행시간, 거리에 맞춰 이동 동 작을 하는 것이 보편적이다. 한편, 최근 공항 이용객의 폭발적인 증가 추세 및 스마트 공항으로의 도약을 위한 노력으로, 공항 내에서 로봇 을 통해 서비스를 제공하는 방안이 개발되고 있다. 공항에 인공지능 로봇을 도입하는 경우, 기존의 컴퓨터 시스 템이 대체할 수 없었던 사람의 고유 역할을 로봇이 대신 수행할 수 있어, 제공되는 서비스의 양적 및 질적 향상 에 기여할 수 있을 것으로 기대된다. 이용자에게 편의를 제공하거나 사람의 역할을 대체할 수 있는 로봇은 상기 공항뿐만 아니라 호텔, 병원, 학교, 대형 쇼핑시설, 문화시설, 공공시설 등의 사회시설 전반에 걸쳐 그 수요가 급증하고 있다. 종래의 로봇은 사용자로부터 인터랙션(interaction)을 위한 요청으로서 버튼이나 터치 스크린 등의 조작부를 통 한 입력, 또는 시동어를 포함하는 음성을 획득하고, 획득된 입력이나 음성에 기초하여 사용자와의 인터랙션을 수행할 수 있었다. 그러나, 사용자가 로봇에 구비된 조작부를 조작하기 위해서는 로봇으로 근접하여야 하나, 로봇이 이동 중인 경 우 로봇으로의 근접이 용이하지 않으며 번거로울 수 있다. 또한, 로봇이 이용자가 많고 소음이 심한 공공장소에 구비된 경우, 로봇은 상기 사용자가 발화한 시동어를 정확 히 인식하기 어려울 수 있다. 뿐만 아니라, 로봇은 상기 공공장소의 다수의 이용자들 중 상기 시동어를 발화한 사용자를 정확히 식별하지 못할 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 미국 공개특허 US 2017/0148434호 (2017.05.25. 자 공개)"}
{"patent_id": "10-2018-0124634", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는, 사용자로부터 로봇과의 인터랙션을 위한 조작이나 시동어 발화 등의 행위 없이도, 인터랙션 의도를 갖는 사용자를 스스로 검출할 수 있는 로봇을 제공하는 것이다. 본 발명이 해결하고자 하는 다른 과제는, 로봇 주변의 사용자 중 인터랙션 의도를 갖는 사용자를 효과적으로 검 출할 수 있는 로봇을 제공하는 것이다. 본 발명이 해결하고자 하는 다른 과제는, 로봇 주변에 복수의 사용자들이 존재하는 경우, 복수의 사용자들에 대 한 인터랙션 의도를 효율적으로 검출할 수 있는 로봇을 제공하는 것이다. 본 발명이 해결하고자 하는 또 다른 과제는, 로봇이 인터랙션 의도를 갖는 사용자를 감지하였음을 사용자에게 나타낼 수 있는 로봇을 제공하는 것이다. 본 발명이 해결하고자 하는 또 다른 과제는, 인터랙션 의도를 갖는 사용자의 특성에 대응하여 음성 또는 화면을 출력하는 로봇을 제공하는 것이다. 본 발명이 해결하고자 하는 또 다른 과제는, 다양한 키를 갖는 사용자를 용이하게 감지할 수 있는 로봇을 제공 하는 것이다."}
{"patent_id": "10-2018-0124634", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 로봇은, 상기 로봇으로 접근하는 사용자를 감지하는 사용자 감지부와, 상기 사용자의 얼굴로부터 상기 로봇과의 인터랙션 의도를 검출하기 위한 얼굴 검출부를 구비함으로써, 상기 사용자의 시동어 발화나 조작 등의 행위 없이도 사용자의 인터랙션 의도를 자동으로 검출할 수 있다. 상기 사용자 감지부는 상기 로봇으로부터 소정 거리 이내의 감지 영역에 존재하는 오브젝트를 감지하는 오브젝 트 감지 센서와, 상기 오브젝트가 사용자인지 여부를 감지하는 사용자 감지 센서를 포함할 수 있다. 실시 예에 따라, 상기 오브젝트 감지 센서는 상기 로봇의 하부모듈에 구비되어, 낮은 높이의 오브젝트를 효과적 으로 감지할 수 있다. 실시 예에 따라, 상기 로봇은 복수의 사용자들이 감지된 경우, 소정 영역에 진입한 순서 등과 같은 우선 순위를 설정하여 순차적으로 인터랙션 의도를 검출함으로써, 효율적인 인터랙션 의도 검출 동작을 수행할 수 있다. 상기 로봇은 상기 얼굴 검출부에 의해 획득된 사용자의 얼굴을 포함하는 이미지로부터 사용자의 특성을 검출하 고, 인터랙션 유도를 위한 음성이나 화면을 사용자의 특성에 기초하여 제공할 수 있다. 실시 예에 따라, 상기 얼굴 검출부는 상기 로봇의 헤드부에 구비되고, 상기 로봇은 상기 사용자의 위치에 기초 하여 상기 헤드부를 회전시키고, 상기 얼굴 검출부는 상기 헤드부의 회전에 따라 상기 사용자의 얼굴을 포함하 는 이미지를 획득할 수 있다. 상기 로봇은, 상기 얼굴 검출부에 의해 획득된 이미지로부터 사용자의 시선을 감지하고, 감지된 시선이 헤드부 를 향하는 경우 상기 인터랙션 의도가 존재함을 검출할 수 있다. 실시 예에 따라, 상기 로봇은 상기 인터랙션 의도가 검출된 경우 사용자를 향하도록 주행부를 제어하거나, 사용 자가 위치한 방향으로 주행하도록 주행부를 제어할 수 있다."}
{"patent_id": "10-2018-0124634", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 따르면, 로봇은 사용자로부터 별도의 조작이나 시동어를 수신하지 않고도, 사용자의 인터 랙션 의도를 자동으로 검출하여 사용자와의 인터랙션을 효과적으로 수행할 수 있다. 특히, 상기 로봇은 라이다 센서, 3D 스테레오 카메라, 2D 카메라, 및 RGBD 센서 등 다양한 센서들을 이용함으로 써, 사용자의 존재 및 사용자의 인터랙션 의도를 보다 정확히 검출할 수 있다. 또한, 상기 로봇은 복수의 사용자들의 접근이 감지된 경우, 소정 영역 내로 진입한 순서 등을 통해 우선 순위를 설정함으로써, 복수의 사용자들에 대한 인터랙션 의도를 효율적으로 검출할 수 있다. 뿐만 아니라, 상기 로봇은 인터랙션 의도를 갖는 사용자가 검출된 경우, 사용자를 향하거나 사용자가 위치한 방 향으로 주행하도록 주행부를 제어함으로써, 상기 사용자는 로봇이 상기 사용자를 검출하였음을 용이하게 인지할 수 있다. 또한, 상기 로봇은 인터랙션 의도를 갖는 사용자의 특성에 기초한 화면 또는 음성을 제공함으로써, 사용자와 보 다 효과적인 인터랙션을 수행할 수 있다. 뿐만 아니라, 사용자로 하여금 로봇에 대한 흥미를 유발함으로써, 로 봇 및 제조사에 대한 긍정적 이미지가 제고될 수 있다. 또한, 오브젝트를 감지하기 위한 라이다 센서는 로봇의 하부모듈에 배치되어, 어린이 등 키가 작은 사용자를 용 이하게 감지할 수 있다."}
{"patent_id": "10-2018-0124634", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명한다. 첨부된 도면은 본 명세서에 개 시된 실시 예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사 상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 발명의 실시 예에 따른 로봇은 공항, 백화점 등 로봇을 이용하는 사용자에게 길 안내, 상품 안내, 공항 정보 등의 다양한 정보를 제공하는 안내 로봇으로 구현될 수 있으나, 반드시 그러한 것은 아니고, 사용자와의 인터랙 션을 수행할 수 있는 다양한 형태의 로봇으로 구현될 수 있다. 도 1은 본 발명의 일 실시 예에 따른 로봇의 외관을 보여주는 사시도이고, 도 2는 도 1의 상부모듈과 하부모듈 이 분리된 모습을 보여주는 도면이다. 도 1 및 도 2를 참조하면, 본 발명의 실시예에 따른 로봇은 상부모듈 및 하부모듈을 포함할 수 있다. 그리고 상부모듈과 하부모듈은 상호간에 탈착 가능하도록 구비될 수 있다. 본 발명의 실시 예에 따른 로봇에서, 상기 상부모듈은 서비스 환경에 따라 변경 가능한 유아이(User Interface, 사용자 인터페이스)를 제공할 수 있다. 그리고 상기 하부모듈은 이동을 위한 주행기능을 제공할 수 있다. 상기 상부모듈은 몸체를 형성하는 바디부, 헤드부 및 디스플레이부를 포함할 수 있다. 상기 바디부는 외관을 형성하는 상부케이스, 상기 상부케이스의 일 측에 설치되는 제1 카메라 및 제2 카메라를 포함할 수 있다. 상기 상부케이스는 하방을 향할수록 직경이 커지는 원통 형상을 가질 수 있다. 상기 제1 카메라는 상기 상부케이스의 전면에 구비되어 전방을 향하도록 설치할 수 있다. 상기 제2 카메라는 상기 상부케이스 의 측면에 복수 개로 구비될 수 있다. 상기 제1 카메라는 3D 스테레오 카메라를 포함할 수 있다. 상기 3D 스테레오 카메라는 장애물 감지, 사용자 얼굴인식, 입체영상 획득 등의 기능을 수행할 수 있다. 이를 이용하면, 로봇은 자신의 이동방향에 따른 장애 물을 감지하여 회피할 수 있으며, 현 위치를 파악할 수 있고, 사용자를 인식하여 각종 제어동작을 수행할 수 있 다. 상기 제2 카메라는 슬램(Simultaneous Localization And Mapping)카메라를 포함할 수 있다. 상기 슬램카메 라는 특징점 매칭을 통하여 카메라의 현 위치를 추적하고 이를 기초로 3차원 지도를 작성하는 기능을 수행한다. 이를 이용하면 로봇은 자신의 현재 위치를 파악할 수 있다. 한편, 상기 바디부는 상부케이스의 일 측에 설치되는 RGBD 센서(미도시) 및 스피커(미도시)를 더 포함 할 수 있다. 상기 RGBD 센서는 상기 로봇이 주행 중 장애물 사이의 충돌을 감지하는 기능을 수행할 수 있다. 이를 위하여, 상기 RGBD 센서는 상기 로봇이 주행하는 전방을 향하도록, 즉 상기 제1 카메라와 함께 위 치할 수 있다. 상기 스피커는 사용자에게 공항 관련 정보를 음성으로 알려주는 기능을 수행할 수 있다. 상기 스피커는 상기 상 부케이스의 외주면에 형성될 수 있다. 상기 디스플레이부는 상기 바디부의 일 방향에 위치할 수 있다. 일례로, 상기 디스플레이부는 상기 로봇의 후방에 설치할 수 있다. 그리고, 상기 디스플레이부는 상하 방향으로 연장되는 곡면의 디 스플레이를 포함할 수 있다. 상기 디스플레이는 시각적인 정보를 제공하기 위한 화면을 표시할 수 있다. 도 1을 참조하여 방향을 정의하면, 로봇의 중심축을 기준으로 제1 카메라가 설치된 방향을 전방, 디스플 레이부가 설치된 방향을 후방이라 정의한다. 상기 디스플레이부는 후술할 바디부의 이동가이드부와 결합할 수 있다. 그리고 상기 이동가이드 부의 가이드에 의해 상기 디스플레이부는 상기 바디부의 내부를 개방 또는 차폐시킬 수 있다. 물론, 상기 디스플레이부는 고정부재를 이용하여 상기 바디부에 결속됨으로써 고정될 수도 있을 것이다. 상기 디스플레이부는 상기 로봇이 사용자에게 안내 기능 등을 수행하기 위해 구비될 수 있다. 따라서, 상기 디스플레이부는 상기 로봇의 이동방향과는 반대되는 방향에 위치하여 상기 디스플레이부를 통해 뒤따라오는 사용자에게 안내정보를 시각적으로 제공할 수 있다. 즉, 디스플레이부는 현재 제공 중인 서비스와 관련된 시각 정보(예: 공항 게이트 질의 정보, 길 안내 서비 스 정보 등)를 표시하는 기능을 수행할 수 있다. 예를 들면, 상기 로봇은 사용자에게 길을 안내하기 위하여 설정된 경로를 따라 먼저 이동할 수 있다. 그리고 사용자는 상기 로봇을 따라 이동하면서 상기 로봇의 후 방에 설치된 디스플레이부를 볼 수 있다. 즉, 상기 로봇이 길 안내를 위하여 주행 중이더라도, 상기 로봇을 따라다니면서 상기 디스플레이부에 표시된 서비스 정보를 용이하게 볼 수 있다. 상기 헤드부는 상기 바디부의 상방에 위치할 수 있다. 상세히, 상기 헤드부는 상기 바디부(10 0)의 상단에 연결되어 로봇의 상부를 형성할 수 있다. 상기 헤드부는 사용자로부터 명령을 입력받는 조작부의 내부 구성을 보호하는 헤드케이스를 포 함할 수 있다. 상기 조작부는 사용자로부터 터치 입력을 수신하거나, 각종 정보를 표시할 수 있는 터치 스크린을 포함할 수 있다. 상기 터치 스크린은 터치 입력을 수신하는 터치 패널과, 각종 정보를 표시하는 디스플레이를 포함할 수 있다. 그리고 상기 조작부는 사물 인식 센서를 더 포함할 수 있다. 상기 사물 인식 센서는 2D 카메라 및 RGBD 센서를 포함할 수 있다. 상기 2D 카메라는 2차원 영상을 기반으로 사 람 또는 사물을 인식하기 위한 센서일 수 있다. 또한, 상기 2D 카메라 및 상기 RGBD 센서(Red, Green, Blue, Distance)는 사람의 위치 또는 얼굴 이미지를 획득하기 위한 구성일 수 있다. 상기 헤드케이스는 상기 상부케이스와 연결될 수 있다. 또한, 상기 헤드케이스는 상기 상부케이 스가 상방으로 연장되어 돔 형상을 가지도록 일체로 형성할 수 있다. 또한, 상기 헤드케이스는 360도 회전 가능하도록 구성될 수 있다. 또한, 상기 헤드부는 마이크(미도시)를 더 포함할 수 있다. 상기 마이크는 사용자로부터 오디오 신호의 명 령을 입력받기 위한 기능을 수행한다. 한편, 상기 하부모듈은 외관을 형성하는 하부케이스 및 조명부를 포함할 수 있다. 상기 하부케이스는 하방을 향할수록 직경이 커지는 원통 형상을 가질 수 있다. 그리고 상기 조명부는 상기 하부케이스의 하부에 설치되어 상기 하부케이스와 일체를 이루도록 구비될 수 있다. 이 경우, 상 기 하부모듈은 항아리 형상의 외관을 가질 수 있다. 상기 상부케이스와 하부케이스는 상하방향으로 연속적인 형상을 이루도록 형성할 수 있다. 일례로, 상 기 상부케이스는 하방으로 직경이 커지는 원기둥 형상을 가질 수 있으며, 상기 하부케이스는 상기 상부 케이스의 직경 증가율과 동일한 증가율로 하방으로 직경이 커지는 원기둥 형상을 가질 수 있다. 따라서, 상 기 하부케이스의 상단부 직경은 상기 상부케이스의 하단부 직경보다 크거나 동일하게 형성할 수 있다. 이에 의하면, 상부모듈과 하부모듈이 결합된 경우, 상기 하부케이스와 상부케이스는 상하방향 으로 연속적인 외관을 형성할 수 있다. 상기 조명부는 로봇의 기능에 따라 제공되는 다양한 조명을 제공할 수 있다. 이에 대한 설명은 후술한 다. 상기 하부모듈은 하부케이스의 일 측에 서로 이격되어 다수 개가 설치되는 초음파 센서(미도시)를 더 포함할 수 있다. 일례로, 상기 다수 개의 초음파 센서는 상기 하부 케이스의 하단 둘레를 따라 서로 일정거 리 이격되도록 구비될 수 있다. 상기 초음파 센서는, 초음파 신호를 이용하여 장애물과 상기 로봇 사이의 거리를 판단하는 기능을 수행할 수 있다. 또한, 상기 초음파 센서는 상기 로봇과 근접한 장애물을 감지하기 위한 기능을 수행할 수 있다. 상기 상부모듈과 하부모듈은 서로 구조적으로 독립되도록 형성되므로 상호 분리 또는 결합이 가능하다. 따라서, 상기 상부모듈의 하단과 하부모듈의 상단은 서로의 하드웨어적 및 소프트웨어적 연결을 위한 구성이 구비될 수 있다. 일례로, 메인 전원스위치, 입력어셈블리, 연결가이드 등은 상기 상부모듈의 하단과 하부모듈의 상단에 위치할 수 있다. 도 3은 도 1에 도시된 로봇의 외관을 보여주는 측면도이다. 도 3을 참조하면, 상기 상부모듈은 상부케이스에 회동 가능하게 연결되는 서브케이스를 포함할 수 있다. 그리고 메인 전원스위치 및 전원플러그(미도시)는 상기 서브케이스의 회동에 따라 외부로 노출 될 수 있다. 상기 상부케이스는, 하부모듈에 구비되는 메인 전원스위치와 배터리 충전을 위한 전원플러그로의 접근성을 향상시키기 위해, 하단의 일부가 개구되는 개구부를 형성할 수 있다. 상기 개구부에는 내측으로 메인 전원스위치와 전원플러그가 위치할 수 있다. 그리고, 상기 개구부는 상기 상부케이스의 후방에 형성될 수 있으며, 상기 디스플레이부의 연결 여부 에 따라 개폐되는 연결개구의 하방에 위치할 수 있다. 또한, 상기 개구부는 상기 연결개구를 하방으로 연장하여 형성할 수도 있을 것이다. 상기 서브케이스는 상기 상부케이스의 개구부를 개폐할 수 있도록 상기 상부케이스와 회동 가능하 게 연결될 수 있다. 일례로, 상기 서브케이스는 상기 상부케이스와 회전 힌지로 연결될 수 있다. 상기 회전 힌지는 상기 서브케이스의 양측 모서리의 중심에 각각 구비되어 상기 상부케이스와 결합을 이룰 수 있다. 즉, 상기 서브케이스의 하단부가 외측으로 이동함으로써, 상기 메인 전원스위치 또는 전원플러그가 외 부로 노출될 수 있다. 이때, 작업자는 상기 메인 전원스위치를 온/오프 시키거나 전원플러그의 연결을 수 행할 수 있다. 작업자의 가압이 끝나면, 상기 서브케이스는 탄성력에 의해 원 위치로 복귀되어 상기 개구부 를 다시 차폐시킬 수 있다. 한편, 상기 하부케이스는 제1 절개부 및 제2 절개부를 포함할 수 있다. 상기 제1 절개부는 상기 하부케이스의 전면에 형성될 수 있다. 구체적으로, 상기 제1 절개부는 상 기 하부케이스의 상단부와 상기 상부케이스의 하단부가 서로 이격되도록 형성할 수 있다. 즉, 상기 제1 절개부는 전방 라이다가 동작 가능하도록 상기 상부케이스 및 하부케이스 사이의 절개되는 부 분으로 이해할 수 있다. 또한, 상기 제1 절개부는 상기 상부모듈과 하부모듈의 결합 또는 분리 시에 상부모듈을 하단에 서 지지할 수 있는 손잡이로서의 기능을 수행할 수 있다. 상기 전방 라이다는 상기 하부케이스의 내부에 위치된다. 그리고 상기 제1 절개부는 상기 전방 라 이다의 위치에 대응되는 지점에서 상기 하부케이스의 둘레를 따라 형성될 수 있다. 따라서, 상기 전방 라이다는 상기 제1 절개부에 의해 외부로 노출될 수 있다. 상기 제2 절개부는 상기 하부케이스의 후면에 형성될 수 있다. 상기 제2 절개부는 후술될 후방 라 이다가 동작 가능하도록 상기 하부케이스에서 절개되는 부분이다. 구체적으로, 상기 제2 절개부는 상기 하부케이스의 후면에서 반경 방향으로 일정 길이만큼 절개될 수 있다. 여기서, 상기 후방 라이다(23 4)는 상기 후방케이스의 내부에 위치된다. 그리고 상기 제2 절개부는 상기 후방 라이다의 위치에 대응되는 지점에서 상기 하부케이스의 둘레 를 따라 절개되어 형성될 수 있다. 따라서, 상기 후방 라이다는 상기 제2 절개부에 의해 외부로 노출 될 수 있다. 그리고, 상기 제1 절개부는 상기 제2 절개부와 연결되지 않도록 상하 방향으로 이격되어 형성할수 있다. 일례로, 상기 제1 절개부는 상기 제 2 절개부 보다 상측에 위치할 수 있다. 한편, 상기 전방 라이다 및 후방 라이다는 레이저 레이더로서, 레이저 빔을 조사하고 에어로졸에 의 해 흡수 혹은 산란된 빛 중 후방 산란된 빛을 수집, 분석하여 위치 인식을 수행하는 센서이다. 또한, 상기 전방 라이다 및 후방 라이다는 조사된 레이저 빔이 오브젝트로부터 반사되면, 반사된 레 이저 빔을 수신할 수 있다. 로봇은 수신된 레이저 빔에 기초하여, 로봇 주변의 상기 오브젝트의 존재 및 위치를 감지할 수 있다. 상기 전방 라이다 및 후방 라이다는 하부모듈에 배치되어, 낮은 높이의 오브젝트를 효과적으로 감지할 수 있다. 특히, 전방 라이다 및 후방 라이다는 하부모듈에 배치되 어, 키가 작은 사용자(예컨대, 어린이)도 용이하게 감지할 수 있다. 도 4는 도 1의 상부모듈 내부의 일례를 보여주는 도면이다. 도 4를 참조하면, 상기 바디부는 상부모듈의 저면을 제공하는 베이스플레이트, 상기 베이스플레 이트의 상방에 위치하는 미들플레이트 및 상기 미들플레이트의 상방에 위치하는 탑플레이트 를 포함할 수 있다. 상기 베이스플레이트는 상부모듈의 베이스 면을 제공할 수 있다. 상기 베이스플레이트는 원반 형 상으로 형성할 수 있다. 또한, 상기 베이스플레이트는 상기 미들플레이트보다 큰 외둘레를 가지도록 형성할 수 있다. 그리고 상기 미들플레이트는 상기 탑플레이트보다 큰 외둘레를 가지도록 형성할 수 있다. 따라서, 상기 상부케이스가 상기 베이스플레이트, 미들플레이트 및 탑플레이트와 결합하는 경우 하방을 향할수록 직경이 커지도록 구비될 수 있다. 상기 베이스플레이트는 상기 하부모듈에 안착되어 결합 또는 분리될 수 있다. 따라서, 상기 베이스플 레이트는 상기 하부모듈과 결합 또는 분리를 위한 구성이 구비될 수 있다. 일례로, 상기 바디부 는 상기 베이스플레이트와 상기 하부모듈의 체결을 위한 체결부재(106a)를 더 포함할 수 있다. 상기 바디부는 후술할 하부모듈과 연동되어 로봇의 주행기능을 보완해줄 수 있는 절벽감지센서 를 더 포함할 수 있다. 상기 절벽감지센서는 로봇이 이동하는 주행 면의 단차를 감지하는 기능을 수행할 수 있다. 이와 연동되 어, 상기 로봇은 주행 중 절벽을 감지하거나 장애물을 감지하는 경우에 정지 또는 회피 구동을 수행할 수 있 다. 상기 바디부는 다양한 서비스 환경에 맞추어 유아이(User Interface, 사용자 인터페이스)를 제공할 수 있 는 메인피씨(PC)를 더 포함할 수 있다. 상기 메인피씨는 상기 미들플레이트의 상측에 위치할 수 있다. 그리고 상기 피씨서포터에 결합 되어 고정 지지될 수 있다. 즉, 상기 메인피씨는 상기 피씨서포터의 전면에 위치할 수 있다. 상기 메인피씨는 로봇이 제공되는 다양한 서비스 환경에 맞춰 유아이(UI, 사용자 인터페이스)를 설정 (setting)할 수 있다. 즉, 상기 메인피씨는, 서비스 환경에 따라 유아이 설정을 달리하여 개별적인 서비스 환경에 적합한 로봇 서비스를 제공할 수 있다. 상기 메인피씨는 다양한 서비스 환경에서 로봇이 활동하는 작동 서비스 환경에 맞춰 유아이 설정을 변 경하면, 상기 디스플레이부 및/또는 조작부 등 시각적인 화면을 제공하는 구성은 상기 변경된 유아이 설정을 따라 사용자에게 시각적인 화면을 제공할 수 있다. 여기서, 상기 디스플레이부 및 조작부 등 시각적인 화면을 제공하는 구성을 로봇의 디스플레이(672; 도 6 참조)라 이름할 수 있다. 또한, 상기 메인피씨는 지속적인 프로그램 업그레이드를 수행할 수 있으며, 이에 따라 로봇의 동작 서 비스 환경에 맞춰진 서비스를 지속적으로 발전시켜서 제공할 수 있다. 본 발명의 실시예에 따른 로봇은, 로봇이 활용되는 서비스 환경에 따라 설정된 유아이(UI)를 변경할 수 있다. 하지만, 로봇은 활용되는 서비스 환경에 따라 구조적인 변경이 필요할 수도 있다. 일례로, 공항과 백 화점에서 사용자에게 길 안내 서비스를 제공하는 경우에는 공항 또는 백화점 환경에 알맞은 유아이(UI) 변경이 필요하다. 특히, 사용자의 명령이 입력되며, 부수적인 소통이 수행되는 로봇의 상부에서 구조적 변경이 빈번하 게 일어날 수 있다. 또한, 상기한 구조적 변경이 필요할 경우 종래 로봇은 두 서비스 환경에서 공통적으로 사용 가능한 주행관련 구성들도 함께 재설계가 필요한 문제가 있다. 본 발명의 실시예에 따른 로봇은, 상부모듈 및 하부모듈로 각 구성을 독립적으로 분리하여 제공할 수 있다. 즉, 본 발명의 실시예에 따른 로봇은 공용으로 사용이 가능한 주행기능을 하부모듈에 구비하고, 구조적 변경이 빈번한 상부모듈을 상기 하부모듈에 결합 또는 분리 가능하도록 구비할 수 있 다. 한편, 상기 메인피씨에 의해 생성된 열기는 상기 베이스플레이트에 구비되는 제 1 쿨러(103a) 및 제 2 쿨러(103b)에 의해 외부로 빠져나갈 수 있다. 즉, 상기 제 1 쿨러(103a) 및 제 2 쿨러(103b)는 상부모듈 의 방열 기능을 수행할 수 있다. 상기 바디부는 상기 로봇의 작동을 제어하기 위한 각종 보드를 포함할 수 있다. 상기 바디부는 메인보드, 유저 인터페이스 보드 및 스테레오 보드를 더 포함할 수 있다 상기 메인보드는 상기 미들플레이트의 상측에 위치할 수 있다. 상기 메인보드는 상기 메인피씨 와 연결되어 상기 메인피씨의 안정적인 구동과 각종 제어장치들 간의 데이터 입출력 교환의 기능을 수행할 수 있다. 상기 유저 인터페이스 보드는 상기 메인피씨와 연결되어 사용자의 입출력을 담당하는 구성의 동작을 제어 할 수 있다. 상기 스테레오 보드는 각종 센서 및 카메라로부터 수집되는 센싱 데이터를 처리 및 가공하여 상기 로봇의 위 치 인식과 장애물 인식을 위한 데이터 관리를 담당할 수 있다.상기 바디부는 상부모듈과 외부기기 또는 상부모듈과 하부모듈의 통신 등을 수행할 수 있는 통신기기를 더 포함할 수 있다. 상기 통신기기는 상기 미들플레이트의 상측에 위치할 수 있다. 그리고 상기 통신기기는 IP공유기를 포함할 수 있다. 한편, 상기 헤드부는 리더기를 더 포함할 수 있다. 상기 리더기는 상기 탑플레이트의 상 측에 위치할 수 있다. 상기 리더기는 사용자의 여권, 항공권, 모바일 바코드 등을 스캔 또는 인식할 수 있다. 따라서, 상기 리더 기를 통하여 획득한 정보를 기초로 사용자에게 필요한 정보를 상기 디스플레이부를 통하여 표시할 수 있다. 일례로, 사용자가 리더기에 모바일 기기를 삽입하여, 모바일 탑승권의 바코드를 인식하는 경우, 상 기 디스플레이부는 상기 모바일 탑승권을 통해 얻은 정보를 기초로 사용자가 이동해야 할 탑승구를 표시하 고 안내할 수 있다. 상기 헤드부는 회전 부재 및 헤드 모터를 더 포함할 수 있다. 상기 헤드 모터는 상기 탑플레이트 의 중심부에 위치할 수 있다. 그리고 상기 회전부재는 상기 헤드 모터와 상방으로 연결되어 위치할 수 있다. 상기 회전 부재의 가장자리에는 상기 헤드케이스가 결합될 수 있다. 따라서, 상기 회전 부재의 회전에 의해 상기 헤드케이스가 함께 회전될 수 있다. 상기 헤드 모터는 상기 회전 부재를 회전시키 는 동력을 제공할 수 있다. 한편, 상기 베이스플레이트는 상기 상부모듈의 구성을 최하단에서 고정 지지해주며, 상기 하부모듈 에 안착되어 상부모듈과 하부모듈의 안정적인 결합 또는 분리가 이루어지도록 할 수 있다. 도 5는 도 1의 하부모듈 내부를 보여주는 도면이다. 상술한 바와 같이, 상기 상부모듈은 로봇의 다양한 서비스 환경에 따라 변경될 수 있는 유아이(UI)기능 을 수행하며, 상기 하부모듈은 다양한 서비스 환경에서도 변경 가능성이 적은 주행기능을 수행한다. 상기 로봇의 공용 기능인 주행기능을 위하여, 상기 하부모듈은 바퀴, 휠, 모터 등을 구비하는 주행부 , 상기 주행부에 동력을 제공할 수 있는 배터리 등을 구비하는 구동부, 및 상기 상부모듈과 의 결합을 위한 연결부를 포함할 수 있다. 상기 구동부는, 하부모듈의 베이스 면을 형성하는 로우플레이트, 상기 로우플레이트에 안착 되는 배터리, 상기 배터리의 상방에 위치하는 어퍼플레이트 및 상기 로우플레이트와 어퍼 플레이트를 연결해주는 하부프레임을 포함할 수 있다. 상기 로우플레이트는 하부모듈의 저면을 형성할 수 있다. 그리고 상기 로우플레이트는 주행부 와 연결될 수 있다. 상기 로우플레이트의 형상은 다양할 수 있다. 일례로, 상기 로우플레이트는 사각 형상의 판으로 형성할 수 있다. 상기 하부프레임은 상기 로우플레이트의 끝 단부에 상방으로 길게 연장되도록 구비될 수 있다. 일례 로, 상기 하부프레임은 상기 로우플레이트의 꼭지점과 대응되는 위치에 복수 개로 구비될 수 있다. 상기 하부프레임은, 상기 로우플레이트 및 어퍼플레이트와 수직하게 연결될 수 있다. 상세히, 상기 하부프레임은 상기 로우플레이트의 상면과 상기 어퍼플레이트의 하면에 결합할 수 있다. 그리고 상기 하부프레임은 일 방향으로 길게 연장되는 육면체 기둥 형상을 가질 수 있다. 상기 어퍼플레이트의 중심부는 홀을 형성할 수 있다. 상기 어퍼플레이트의 홀에는 후술할 전장플레이 트가 구비되어 복수의 전자 장비가 설치될 수 있다. 상기 어퍼플레이트는 다양한 형상을 가질 수 있다. 일례로, 상기 어퍼플레이트는 사각 형상의 판으로 형성될 수 있다. 이때, 상기 어퍼플레이트의 크기는 로우플레이트의 크기와 동일하게 형성될 수도 있 다. 따라서, 상기 하부프레임의 로우플레이트와 결합되는 위치는 상기 하부프레임의 어퍼플레이 트와 결합되는 위치와 대응될 수 있다. 다만, 상기 어퍼플레이트의 크기는 상기 로우플레이트의 크기에 제한되지 않는다. 상기 어퍼플레이트의 하면은 상기 하부프레임와 연결되며 상면은 후술할 상부프레임과 연결될 수 있다.상기 로우플레이트, 하부프레임 및 어퍼플레이트는 내부가 비어있는 직육면체 형상을 형성할 수 있다. 그리고 상기 로우플레이트와 어퍼플레이트 사이의 내부 공간은 설치공간이라 이름한다. 상기 설치공간은 무게가 상대적으로 무거운 배터리가 위치하는 공간으로 이해할 수 있다. 상기 배터리는 리튬-이온 배터리(Li-Ion Battery)를 포함할 수 있다. 그러나 이에 한정되지는 않으며, 상 기 배터리는 리튬-이온 배터리 이외의 다른 종류의 배터리를 포함할 수 있다. 상기 배터리는 상기 로봇의 구동을 위한 전원을 공급할 수 있다. 그리고 상기 배터리는 상기 설치 공간에 위치할 수 있다. 상기 배터리는 상기 로봇의 전체 무게 중 가장 큰 비중을 차지하고 있으 므로, 상기 로우플레이트의 상면에 안착되는 것이 무게중심 측면에서 바람직할 것이다. 상기 구동부는, 상기 연결부를 지지하는 상부프레임, 상기 어퍼플레이트의 중심부에 위치 하는 전장플레이트를 더 포함할 수 있다. 상기 전장플레이트는, 상기 어퍼플레이트의 중심부에 위치할 수 있다. 상기 전장플레이트는 상 하방향으로 다단의 층을 이루도록 복수개로 구비될 수 있다. 상기 복수 개의 전장플레이트는 상하방향으로 배치되어 다수의 층을 형성하며, 상기 다수의 층을 전장공간이라 이름한다. 상기 전장공간에는 다수의 전자장비들이 위치할 수 있다. 상기 다수의 전자장비들은 상기 전장플레이트 에 결합될 수 있다. 일례로, 상기 전장공간에는 다수의 보드가 구비될 수 있다. 상기 상부프레임은 상기 어퍼플레이트에 연결할 수 있다. 상기 상부프레임은 상기 어퍼플레이트 의 외둘레와 중심 홀이 이루는 내둘레 사이에 위치할 수 있다. 보다 상세히, 상기 상부프레임은 상기 어퍼플레이트의 상면에서 상기 전장플레이트의 외측으로 가상의 삼각형이 그려지도록 위치할 수 있다. 그리고 상기 가상의 삼각형 꼭지점에 각각 상부프레임이 위치할 수 있다. 즉, 상기 상부프레임은 복수 개로 구비되어 상기 연결부를 3점 지지할 수 있다. 일례로, 상기 상부프 레임은 상기 전장플레이트의 전방에 위치하는 제 1 상부프레임, 상기 전장플레이트의 양 측방에 위치하는 제 2 상부프레임 및 제 3 상부프레임을 포함할 수 있다. 상기 제 1 내지 제 3 상부프레임의 상측 에는 상기 연결부의 연결플레이트가 결합될 수 있다. 상기 상부프레임은, 상기 어퍼플레이트의 상면에 수직하게 결합할 수 있다. 그리고 상기 상부프레임 은 일 방향으로 길게 연장된 육면체 기둥 형상을 가질 수 있다. 또한, 상부프레임의 상하방향 길이는, 상부모듈과의 결합 또는 분리를 위한 연결부를 고정 지지하므로 상기 상부모듈과 하부모 듈의 결합 시 안정적인 균형을 이루기 위하여, 상기 하부프레임의 상하방향 길이보다 작게 형성할 수 있다. 상기 구동부는 상기 어퍼플레이트의 상측에 위치하는 블록, 상기 블록의 상측에 위치하는 하중센서 및 상기 하중센서의 상측에 위치하는 접촉링을 더 포함할 수 있다. 상기 블록은 상기 어퍼플레이트의 꼭지점과 대응되는 위치에 상방으로 연장되어 구비될 수 있다. 즉, 상기 블록은 상기 상부프레임의 외측에 위치할 수 있다. 상기 블록의 상측에는 하중센서가 구비될 수 있다. 즉, 상기 블록은 상기 하중센서 및 접 촉링을 고정 지지하는 역할을 수행할 수 있다. 상기 하중센서는 접촉링과 연결되어 상기 접촉링으로부터 전달되는 힘에 의한 하중을 감지하는 센서로 복수 개로 구비될 수 있다. 그리고 상기 블록은 상기 하중센서의 개수에 대응되도록 구비될 수 있다. 상기 하중센서는 상기 어퍼플레이트의 꼭지점과 대응되도록 제 1 하중센서, 제 2 하중센서, 제 3 하 중센서, 및 제 4 하중센서를 포함할 수 있다. 상기 제 1 내지 제 4 하중센서는 상기 어퍼플레이트보다 외측에 위치할 수 있다. 그리고 상기 제 1 내지 제 4 하중센서의 외측 끝단을 따라 접촉링이 연결될 수 있다. 상기 접촉링은 상기 제 1 내지 제 4 하중센서의 상단부를 따라 외측 방향으로 안착되어 위치할 수 있 다. 상기 접촉링은 상기 블록의 상방에 외측방향으로 이격되어 위치할 수 있다. 상기 접촉링은 내부가 비어 있는 링 형상으로 형성할 수 있다. 그리고 상기 접촉링의 외경은 상기 접 촉링의 내부에 상기 어퍼플레이트가 위치할 수 있도록 상대적으로 크게 형성할 수 있다. 그리고 상기 접촉링은 상기 하부케이스와 연결될 수 있다. 따라서, 상기 하부모듈의 충돌이 발생하는 경우 용 이하게 충격이 전달될 수 있다. 상기 하중센서 및 접촉링은 상기 하부모듈의 충돌을 감지하여 주행동작을 제어할 수 있는 역할을 수행한다. 상세히, 하부모듈의 충돌 시 상기 접촉링은 상기 하부케이스에 의해 전달받은 충격으로 뒤틀림이 발생할 수 있다. 즉, 상기 접촉링은 모멘텀이 발생되며, 상기 하중센서는 상기 모멘텀을 감 지하여 신호를 전달할 수 있다. 이때, 제어부는 상기 하중센서의 신호를 전달받아 주행부의 구름 운 동이 정지되도록 제어할 수 있다. 이에 의하면, 상기 로봇의 주행에 의한 안전성을 향상시킬 수 있는 효과가 있다. 한편, 상기 로우플레이트는 로봇의 이동 기능을 수행하는 주행부와 연결될 수 있다. 상기 주행부 는, 하부모듈이 용이하게 움직일 수 있도록, 메인바퀴, 보조바퀴 및 서스펜션(미도시)을 포 함할 수 있다. 즉, 상기 주행부는 로봇에 이동 능력을 제공할 수 있다. 상기 서스펜션(미도시)은 상기 로우플레이트의 양 측방에 위치할 수 있다. 상세히, 상기 서스펜션은 상기 로우플레이트의 양 측단부에 각각 결합할 수 있다. 그리고 상기 서스펜션은 외측으로 메인바퀴를 연 결할 수 있다. 상기 메인바퀴는 로우플레이트의 양 측방으로 연결될 수 있다. 상세히, 상기 메인바퀴는 상기 로우플레이트의 하면에 위치하는 모터어셈블리(미도시)와 연결할 수 있다. 그리고, 상기 모터는 상기 배터 리로부터 전원을 제공받아 회전함으로써 상기 메인바퀴에 회전력을 제공할 수 있다. 상기 메인바퀴 는 상기 모터의 회전력을 제공받아 구름운동을 수행할 수 있으며, 이에 의하여 하부모듈의 주행이 이 루어질 수 있다. 또한, 상술한 바와 같이 상기 메인바퀴는 상기 서스펜션과 연결되어 상기 서스펜션의 외 측으로 각각 위치할 수 있다. 한편, 로우플레이트의 양 측방 각각에 구비된 메인바퀴는, 대응하는 모터에 의해 서로 독립적으로 회 전할 수 있다. 각 모터가 동일한 회전력을 메인바퀴 각각으로 제공하는 경우, 로봇은 전방 또는 후방으 로 직진 주행할 수 있다. 반면, 각 모터가 서로 다른 회전력을 메인바퀴 각각으로 제공하는 경우, 로봇 은 곡선 주행 또는 회전할 수 있다. 상기 보조바퀴는 상기 로우플레이트의 하측에 위치할 수 있다. 상세히, 상기 보조바퀴는, 상기 로우플레이트의 전단과 후단에 각각 하방으로 연결되는 보조바퀴플레이트와 결합될 수 있다. 상기 보조바 퀴는 복수 개로 구비될 수 있다. 상기 복수의 보조바퀴는 상기 로우플레이트의 하면의 전후 방 향에서 안정적으로 하부모듈을 지지할 수 있다. 즉, 상기 보조바퀴는 상기 하부모듈의 주행이 안 정적으로 이루어지도록 상기 하부모듈의 중심을 잡아주는 역할을 수행할 수 있다. 상기 보조바퀴는 주행 시 상기 모터에 의해 회전하는 상기 메인바퀴에 종속되어 구름운동을 수행할 수 있다. 즉, 상기 보조바퀴는 독립적으로 회전하지 않으며, 외력이나 메인바퀴의 회전에 종속되어 구름운동을 할 수 있다. 상기 보조바퀴는 캐스터를 포함할 수 있다. 도 6은 본 발명의 실시 예에 따른 로봇의 제어 구성을 개략적으로 나타낸 블록도이다. 도 6에는 로봇이 통신부, 입력부, 사용자 감지부, 얼굴 검출부, 주행부, 헤드 모 터, 출력부, 메모리, 및 제어부를 포함하는 것으로 도시되어 있다. 그러나, 도 6에 도시된 구성들은 설명의 편의를 위한 것으로서 로봇을 구현하는 데 있어 필수적인 것은 아닌 바, 로봇은 도 6에 도시된 구성들 중 일부를 포함하지 않을 수도 있다. 또한, 실시 예에 따라 로봇은 도 6에 도시된 구성들 및 추가적인 제어 구성들을 더 포함할 수도 있다. 통신부는, 로봇을 네트워크를 통해 서버, 단말기, 및 다른 로봇 등과 연결하기 위한 적어도 하나의 통 신 모듈을 포함할 수 있다. 예컨대, 통신부는 블루투스, NFC(near field communication)와 같은 근거리 통신 모듈, Wi-Fi 등의 무선 인터넷 모듈이나 이동 통신 모듈을 포함할 수 있다. 제어부는 로봇의 상태 정보나 동작 정보, 입력부를 통해 사용자로부터 수신된 입력, 사용자 감지부나 얼굴 검출부에 의해 획득된 다양한 감지 데이터를, 통신부를 통해 상기 서버, 단말기, 및/또는 다른 로봇으로 전송할 수 있다. 또한, 제어부는 통신부를 통해 상기 서버나 단말기로부터 로봇의 제어 정보를 수신할 수 있 다. 입력부는 사용자의 조작이나 기타 행위에 의해 소정 신호 또는 데이터를 로봇으로 입력하는 적어도 하 나의 입력 수단을 포함할 수 있다. 예컨대, 상기 적어도 하나의 입력 수단은 버튼, 다이얼, 터치패드, 마이크로 폰(microphone) 등을 포함할 수 있다. 사용자는 상기 버튼, 다이얼, 및/또는 터치패드를 조작함으로써 요청이나 명령을 로봇으로 입력할 수 있다. 또한, 사용자는 상기 마이크로폰을 통해 음성 형태의 요청이나 명령을 로 봇으로 입력할 수 있다. 사용자 감지부는 로봇으로부터 소정 거리 이내에 존재하는 오브젝트를 감지하기 위한 적어도 하나의 센 서를 포함할 수 있다. 특히, 사용자 감지부는 감지된 오브젝트 중 사용자를 다른 오브젝트와 구분함으로써, 로봇으로 사용자가 접근하는지 여부를 감지할 수 있다. 이하 명세서에서, 사용자는 사람을 의미할 수 있다. 상기 사용자는 로봇과의 인터랙션 의도를 갖는 사용자, 및 로봇과의 인터랙션 의도를 갖지 않는 사용자를 모두 포함하는 의미로 이해될 수 있다. 사용자 감지부는 로봇으로부터 소정 거리 이내에 존재하는 오브젝트를 감지하는 오브젝트 감지 센서 를 포함할 수 있다. 예컨대, 오브젝트 감지 센서는 라이다 센서(LiDar Sensor)를 포함할 수 있으나, 이에 한정되는 것은 아니고 초음파 센서 등의 다른 센서를 포함할 수도 있다. 예컨대, 오브젝트 감지 센서는 로봇의 전방위에 대한 오브젝트 감지를 위해 적어도 하나의 라이다 센서 를 포함할 수 있다. 예컨대, 도 1 내지 도 5에 도시된 로봇의 경우, 상기 오브젝트 감지 센서는 전방 라이다 및 후방 라이다를 의미할 수 있다. 라이다 센서는 레이저 빔을 조사하고, 조사된 레이저 빔이 오브젝트에 의해 반사되면, 반사된 레이저 빔을 수신 할 수 있다. 라이다 센서는 수신된 레이저 빔에 기초하여, 상기 오브젝트의 존재 및 위치를 감지할 수 있다. 한편, 사용자 감지부는, 감지된 오브젝트가 사용자인지 여부를 감지하기 위한 사용자 감지 센서를 포 함할 수 있다. 예컨대, 상기 사용자 감지 센서는 3D 스테레오 카메라로 구현될 수 있으나, 실시 예에 따라 사용 자 감지 센서는 다양한 오브젝트들 중 사용자를 다른 오브젝트와 구별할 수 있는 적어도 하나의 센서로 구현될 수 있다. 상기 3D 스테레오 카메라에 의해 획득된 이미지는 각 픽셀에 대한 깊이(depth) 정보를 포함할 수 있다. 제어부 는 획득된 이미지의 각 픽셀값 및 상기 깊이 정보를 이용하여, 상기 오브젝트가 사용자인지 여부를 감지할 수 있다. 사용자 감지 센서는 로봇의 전방위에 대한 이미지를 획득하여 사용자를 감지하기 위해, 적어도 하나의 3D 스 테레오 카메라를 구비할 수 있다. 이 경우, 제어부는 라이다 센서에 의해 오브젝트가 감지되면, 적어 도 하나의 3D 스테레오 카메라 중 상기 감지된 오브젝트를 향하는 3D 스테레오 카메라를 제어하여 상기 오브젝 트를 포함하는 이미지를 획득할 수 있다. 한편, 도 1 내지 도 5에 도시된 로봇의 경우, 상기 3D 스테레오 카메라는 바디부에 구비된 제1 카메라 를 의미할 수 있다. 도 1 내지 도 5의 실시 예와 같이 로봇이 하나의 3D 스테레오 카메라를 구비하는 경 우, 로봇의 전방위에 대한 이미지를 획득하지 못할 수 있다. 이 경우, 제어부는 오브젝트 감지 센서 에 의해 오브젝트가 감지되면, 3D 스테레오 카메라가 상기 오브젝트를 향하도록 바디부를 회전시킬 수 있다. 예컨대, 제어부는 주행부를 제어하여 주행 방향을 변경할 수 있고, 상기 주행 방향이 변경 됨에 따라 상기 바디부가 회전될 수 있다. 실시 예에 따라, 로봇에 상기 바디부의 수평 방향 회전 을 위한 별도의 모터가 구비된 경우, 제어부는 상기 모터를 제어하여 상기 바디부를 회전시킬 수도 있다. 얼굴 검출부는, 사용자 감지부에 의해 사용자가 감지되면, 감지된 사용자의 얼굴을 검출할 수 있다. 이러한 얼굴 검출부는 상기 사용자의 얼굴을 포함하는 이미지를 획득하는 적어도 하나의 카메라를 포함할 수 있다. 제어부는 상기 획득된 이미지에 포함된 사용자의 얼굴에 기초하여 인터랙션 의도를 검출할 수 있다. 사용 자가 로봇과의 인터랙션을 수행하고자 하는 경우, 사용자의 시선은 로봇을 향하는 것이 일반적이다. 즉, 제어부는 상기 획득된 이미지로부터 사용자의 시선 방향을 감지하고, 감지된 시선 방향이 로봇을 향하 는 경우 사용자의 인터랙션 의도가 존재하는 것으로 검출할 수 있다. 예컨대 도 1 내지 도 5에 도시된 로봇의 경우, 상기 얼굴 검출부는 헤드부에 구비된 2D 카메라와 RGBD 센서 중 적어도 하나를 포함할 수 있다. 제어부는 헤드 모터를 제어하여, 얼굴 검출부가사용자 방향을 향하도록 헤드부를 회전시킬 수 있다. 한편, 헤드부에는 터치 스크린 등의 조작부가 구비되고, 제어부는 조작부를 통해 시각적 화면을 표시할 수 있다. 이에 따라, 로봇과의 인터랙션 의도를 갖는 사용자의 시선은 상기 헤드부를 향 할 수 있다. 즉, 상기 얼굴 검출부는 헤드부에 구비됨으로써, 사용자의 시선이 헤드부를 향하는 지 여부를 효과적으로 감지할 수 있다. 이에 따라, 로봇은 사용자의 인터랙션 의도를 보다 정확히 검출할 수 있다. 주행부는 로봇의 이동을 위한 구성이다. 예컨대, 주행부는 하부 모듈에 구비되는 주행 바퀴 , 및 주행 바퀴에 회전력을 제공하는 모터를 포함할 수 있다. 예컨대, 도 1 내지 도 5에 도시된 로봇 의 경우, 주행 바퀴는 하부 모듈의 양 측방에 배치된 제1 주행 바퀴와 제2 주행 바퀴를 포함할 수 있고, 모터는 상기 제1 주행 바퀴에 회전력을 제공하는 제1 모터와, 상기 제2 주행 바퀴에 회전력을 제공하는 제2 모터를 포함할 수 있다. 제어부가 상기 제1 모터와 상기 제2 모터를 동일하게 제어하는 경우, 로봇 은 직진 주행 또는 후진 주행할 수 있다. 반면, 제어부가 상기 제1 모터와 상기 제2 모터를 다르게 제 어하는 경우, 로봇은 곡선 주행 또는 회전할 수 있다. 로봇이 회전함에 따라, 바디부 또한 회전할 수 있다. 출력부는 로봇의 동작이나 상태, 로봇이 제공하는 서비스와 관련된 각종 정보를 출력할 수 있다. 또 한, 출력부는 사용자와의 인터랙션을 수행하기 위한 각종 메시지나 정보 등을 출력할 수 있다. 예컨대, 출력부는 디스플레이, 스피커, 및 광 출력부 중 적어도 하나를 포함할 수 있다. 디스플레이는 상술한 각종 정보나 메시지를 그래픽 형태로 출력할 수 있고, 스피커는 상기 각종 정보 나 메시지를 음성 형태로 출력할 수 있다. 도 1 내지 도 5에 도시된 로봇의 실시 예에서, 디스플레이는 디스플레이부 및 조작부의 터치 스크린을 포함하는 것으로 이해될 수 있다. 스피커는 바디부 또는 헤드부에 구비될 수 있다. 광 출력부는, 상술한 각종 정보나 메시지에 대응하여 특정 색상이나 패턴의 광을 출력할 수 있다. 광 출력 부는 디스플레이 또는 스피커의 출력 시 보조적인 출력 수단으로서 활용될 수 있으나, 반드시 그러한 것은 아니다. 메모리에는, 로봇에 포함된 구성 요소들의 동작을 제어하기 위한 제어 데이터, 입력부를 통해 획 득된 입력에 대응하는 동작을 수행하기 위한 데이터 등의 각종 데이터가 저장될 수 있다. 메모리에는 사용자 감지부의 오브젝트 감지 센서 및 사용자 감지 센서를 통해 획득되는 감 지 데이터가 저장될 수 있고, 상기 감지 데이터에 기초하여 사용자를 감지하기 위한 알고리즘 및 관련 데이터가 저장될 수 있다. 또한, 메모리에는 얼굴 검출부를 통해 획득된 이미지가 저장될 수 있고, 상기 이미지로부터 사용자의 인터랙션 의도를 검출하기 위한 알고리즘 및 관련 데이터가 저장될 수 있다. 제어부는 로봇의 전반적인 동작을 제어할 수 있다. 특히, 제어부는 사용자 감지부에 포함된 적어도 하나의 센서(632, 634)를 제어하여, 로봇 주변의 사용자를 감지할 수 있다. 또한, 제어부는 얼 굴 검출부를 제어하여 상기 감지된 사용자의 얼굴을 포함하는 이미지를 획득하고, 획득된 이미지에 기초하 여 사용자의 인터랙션 의도를 검출할 수 있다. 인터랙션 의도가 검출된 경우, 제어부는 사용자와의 인터랙 션을 수행하기 위한 안내 음성이나 안내 화면 등을 출력할 수 있다. 상술한 로봇은 사용자와의 인터랙션을 통해, 사용자에게 각종 정보 제공 및 안내 동작 등을 수행할 수 있다. 종래의 경우, 사용자는 로봇과의 인터랙션을 위해서는 로봇의 조작부 등을 조작하거나, 시동어를 발 화하는 등의 행위를 수행해야 하였다. 그러나, 사용자가 조작부를 직접 조작하는 것은 번거로울 뿐만 아니 라, 조작부에 메뉴 화면이 아닌 광고 화면 등이 표시 중인 경우 로봇과의 인터랙션이 지연되거나 수행 되지 못할 수 있다. 또한, 로봇이 공항이나 백화점 등 이용자가 많은 공간에 배치된 경우, 로봇은 소음 등으로 인해 사용자가 발화한 시동어를 용이하게 인식하지 못할 우려가 있다. 본 발명의 실시 예에 따르면, 로봇은 사용자로부터 별도의 조작이나 시동어를 수신하지 않고도, 사용자의 인 터랙션 의도를 자동으로 검출하여 사용자와의 인터랙션을 효과적으로 수행할 수 있다. 이와 관련된 다양한 실시 예들에 대해 이하 도 7 내지 도 19를 참조하여 설명한다.도 7은 본 발명의 실시 예에 따른 로봇의 제어 동작을 개략적으로 나타낸 플로우차트이다. 이하 명세서에서는 설명의 편의를 위해, 본 발명의 실시 에에 따른 다양한 제어 동작을 수행하는 로봇은 도 1 내지 도 5에 도시된 로봇인 것으로 가정한다. 또한 상술한 바와 같이, 본 명세서에서 사용자는 인터랙션 의도가 존재하거나 존재하지 않는 사람을 모두 포함 하는 의미로 이해될 수 있다. 도 7을 참조하면, 로봇은 사용자의 접근을 감지할 수 있다(S700). 로봇의 제어부는, 사용자 감지부에 포함된 센서들(632, 634)을 이용하여 로봇으로부터 소정 거 리 이내에 존재하는 사용자를 감지할 수 있다. 또한, 제어부는 감지된 사용자의 위치 변화에 기초하여 사 용자의 접근을 감지할 수 있다. 이에 대해서는 추후 도 8 내지 도 9를 참조하여 보다 상세히 설명하기로 한다. 사용자의 접근이 감지된 경우, 로봇은 감지된 사용자가 위치한 방향으로 헤드부를 회전할 수 있다 (S710). 제어부는 헤드부에 구비된 얼굴 검출부가 상기 사용자를 향하도록, 헤드 모터를 제어하여 헤드부를 회전시킬 수 있다. 로봇은 사용자의 얼굴 및 인터랙션 의도를 검출할 수 있다(S720). 제어부는 얼굴 검출부를 제어하여 사용자의 얼굴을 포함하는 이미지를 획득하고, 획득된 이미지로부 터 사용자의 로봇에 대한 인터랙션 의도를 검출할 수 있다. 이와 관련된 실시 예들에 대해서는 추후 도 10 내지 도 14를 참조하여 설명하기로 한다. 인터랙션 의도가 검출된 경우, 로봇은 사용자가 위치한 방향으로 로봇 바디를 회전하고(S730), 사용자와의 인터랙션을 수행할 수 있다(S740). 제어부는 사용자의 인터랙션 의도가 검출되면, 사용자가 위치한 방향으로 바디부의 전방이 향하도록 주행부를 제어할 수 있다. 실시 예에 따라, 제어부는 바디부의 전방이 사용자를 향한 후, 로봇이 사용자 측으로 주행하도록 주행부를 제어할 수도 있다. 즉, 제어부는 인터랙션 의도가 검출된 사용자를 향하여 스스로 주행함으 로써, 사용자의 편의성을 보다 향상시킬 수 있다. 제어부는 사용자와의 인터랙션을 위한 안내 음성 또는 안내 화면 등의 가이드를 출력하도록 출력부를 제어할 수 있다. 사용자는 출력된 가이드에 기초하여 특정 서비스를 요청하고, 제어부는 수신된 요청에 응 답하여 사용자에게 서비스를 제공함으로써, 사용자와의 인터랙션을 수행할 수 있다. 즉, 본 발명의 실시 예에 따르면, 로봇은 사용자로부터 별도의 조작 입력이나 음성 입력을 수신하지 않고도 사용자의 인터랙션 의도를 스스로 검출함으로써, 사용자와의 인터랙션을 보다 효과적으로 수행할 수 있다. 도 7에서 상술한 로봇의 각 제어 동작과 관련된 보다 구체적인 실시 예들에 대해 이하 도 8 내지 도 18을 참 조하여 설명한다. 도 8과 도 9는 본 발명의 로봇이 사용자의 접근을 감지하는 동작의 일례를 설명하기 위한 도면들이다. 도 8과 도 9를 참조하면, 로봇은 오브젝트 감지 센서를 통해, 기설정된 거리(D1) 이내에 존재하는 오브 젝트를 감지할 수 있다(S800). 상기 오브젝트 감지 센서는 로봇의 전방 라이다와 후방 라이다를 포함하는 것으로 가정한다. 제어부는, 상기 전방 라이다와 후방 라이다를 이용하여, 로봇으로부터 기설정된 거리(D1) 이 내에 오브젝트가 존재하는지 여부를 감지할 수 있다. 상술한 바와 같이, 제어부는 전방 라이다와 후방 라이다 각각을 제어하여 레이저 빔을 조사하고, 오브젝트에 의해 반사된 레이저 빔을 수신하고, 수신된 레이저 빔에 기초하여 상기 오브젝트의 존재 를 감지할 수 있다. 한편, 상기 기설정된 거리(D1)는, 오브젝트 감지 센서의 최대 감지거리 이하일 수 있다. 도 9의 예시도를 참조하면, 로봇으로부터 기설정된 거리(D1) 이내의 감지 영역(Zone 1)에 오브젝트들(901, 902)이 존재할 수 있다. 이 경우, 전방 라이다 또는 후방 라이다로부터 조사된 제1 레이저 빔(L1)은 제1 오브젝트에 의해 반사되고, 전방 라이다 또는 후방 라이다는 반사된 제1 레이저 빔(L1')을 수신할 수 있다. 또한, 전방 라이다 또는 후방 라이다로부터 조사된 제2 레이저 빔(L2)은 제2 오브젝 트에 의해 반사되고, 전방 라이다 또는 후방 라이다는 반사된 제2 레이저 빔(L2')을 수신할 수 있다. 제어부는 상기 반사된 제1 레이저 빔(L1') 및 제2 레이저 빔(L2')에 기초하여 제1 오브젝트와 제2 오 브젝트를 감지할 수 있다. 또한, 제어부는 반사된 제1 레이저 빔(L1')의 수신 방향 및 수신 시점에 기초하여 제1 오브젝트의 위치를 인식할 수 있고, 반사된 제2 레이저 빔(L2')의 수신 방향 및 수신 시점에 기초하여 제2 오브젝트의 위치를 인식할 수 있다. 예컨대, 제어부는 인식된 위치를 2차원 좌표 형태 로 각각 정의할 수 있다. 한편, 전방 라이다와 후방 라이다는 하부모듈에 배치됨으로써, 낮은 높이의 장애물을 효과적으로 감지할 수 있다. 즉, 전방 라이다와 후방 라이다는 키가 작은 사용자(예컨대, 어린이 등) 또한 효과 적으로 감지할 수 있다. 오브젝트가 감지된 경우, 로봇은 사용자 감지 센서를 이용하여 상기 오브젝트가 사용자인지 여부를 감 지할 수 있다(S810). 제어부는 오브젝트 감지 센서에 의해 오브젝트가 감지된 경우, 사용자 감지 센서를 이용하여 상 기 오브젝트가 사용자인지 여부를 감지할 수 있다. 예컨대, 상기 사용자 감지 센서는 로봇의 바디부에 구비된 제1 카메라를 포함하는 것으로 가 정한다. 이 경우, 제어부는 상기 제1 카메라에 의해 획득되는 이미지에 상기 오브젝트가 포함되도록, 주행부 를 제어하여 바디부를 회전시킬 수 있다. 제어부는 바디부가 회전되면, 상기 제1 카메라 를 통해 상기 오브젝트를 포함하는 이미지를 획득할 수 있다. 예컨대, 제어부는 제1 카메라에 의해 획득되는 이미지에 제1 오브젝트가 포함되도록 바디부(10 0)를 회전시키고, 제1 카메라를 제어하여 제1 오브젝트가 포함된 이미지를 획득할 수 있다. 또한, 제어부는 제1 카메라에 의해 획득되는 이미지에 제2 오브젝트가 포함되도록 바디부를 회전시키고, 제1 카메라를 제어하여 제2 오브젝트가 포함된 이미지를 획득할 수 있다. 실시 예에 따라, 사용자 감지 센서가 서로 다른 방향을 향하도록 배치된 복수의 3D 스테레오 카메라들을 포함하는 경우, 제어부는 상기 복수의 3D 스테레오 카메라들 중, 상기 오브젝트를 포함하는 이미지를 획득 가능한 3D 스테레오 카메라를 제어하여 이미지를 획득할 수 있다. 제어부는 획득된 이미지에 기초하여 오브젝트가 사용자인지 여부를 감지할 수 있다. 상기 3D 스테레오 카 메라에 의해 획득되는 이미지는 오브젝트의 색상이나 형태를 나타내는 픽셀값(예컨대, RGB 데이터)뿐만 아니라, 각 픽셀(또는 일부 픽셀)에서 오브젝트와 3D 스테레오 카메라 사이의 거리를 나타내는 깊이 정보를 포함할 수 있다. 제어부는 상기 픽셀값 및 상기 깊이 정보를 이용하여 상기 오브젝트가 사용자인지 여부를 감지할 수 있다. 이를 위해, 메모리에는 사용자(사람)에 대한 픽셀값 패턴 및 깊이 정보 패턴에 대한 데이터가 저장되어 있 거나, 상기 오브젝트가 사용자인지 여부를 판단하기 위한 알고리즘이 저장되어 있을 수 있다. 예컨대, 제어부는 제1 오브젝트가 포함된 이미지로부터, 제1 오브젝트가 사용자임을 감지할 수 있다. 또한, 제어부는 제2 오브젝트가 포함된 이미지로부터, 제2 오브젝트가 사용자가 아님을 감지할 수 있다. 실시 예에 따라, 제어부는 전방 라이다와 후방 라이다 각각을 제어하여 레이저 빔을 주기적으로 조사함으로써, 상기 오브젝트의 위치 변화를 감지할 수 있다. 제어부는 상기 오브젝트가 로봇으로 접근 중임이 감지되는 경우, 상기 사용자 감지 센서를 이용하여 상기 접근 중인 오브젝트가 사용자인지 여부를 감지할 수도 있다. 또는, 제어부는 S610 단계와 병렬적으로, 오브젝트 감지 센서 및/또는 사용자 감지 센서를 이용 하여 상기 오브젝트가 로봇으로 접근 중인지 여부를 감지할 수도 있다. 오브젝트가 로봇으로 접근 중임은, 오브젝트 및/또는 로봇의 이동에 의해 오브젝트와 로봇 사이의 거 리가 감소하는 경우를 의미할 수 있다. 즉, 제어부는 오브젝트가 사용자인 경우 상기 S720 단계 및 이하 단계들을 수행할 수 있다. 또는, 제어부는 상기 사용자가 로봇으로 접근 중임이 감지되는 경우에 상기 S720 단계 및 이하 단계들 을 수행할 수도 있다. 즉, 제어부는 기설정된 거리(D1) 이내에 사용자가 존재하더라도, 사용자가 로봇 으로 접근 중인 경우에만 상기 S720 단계 및 이하 단계들을 수행하므로, 로봇의 부하 낭비를 최소화할 수 있 다. 도 10과 도 11은 본 발명의 로봇이, 접근이 감지된 사용자에 대한 인터랙션 의도를 검출하는 동작의 일례를 설 명하기 위한 도면들이다. 도 10 내지 도 11을 참조하면, 로봇은 사용자의 접근이 감지된 경우, 사용자 방향으로 헤드부를 회전하 도록 헤드 모터를 제어할 수 있다(S1000). 제어부는 사용자 감지부에 의해 사용자의 접근이 감지되면, 감지된 사용자가 위치한 방 향으로 조작부 및 얼굴 검출부가 향하도록 헤드부를 회전시킬 수 있다. 제어부는 헤드 모 터를 제어하여 상기 헤드부를 회전시킬 수 있다. 제어부는 감지된 사용자의 위치를 2차원 좌표 형태로 나타낼 수 있다. 제어부는 상기 사용자 의 위치에 대응하는 좌표를 이용하여 헤드부의 회전 각도를 산출하고, 산출된 회전 각도에 기초하여 헤드 모터를 제어할 수 있다. 실시 예에 따라, 제어부가 헤드 모터를 제어하는 동안 사용자는 기존 위치에서 다른 위치로 이 동할 수도 있다. 제어부는 상기 산출된 회전 각도로 헤드부를 회전시킨 후, 사용자 감지부를 이 용하여 사용자의 위치를 재 감지할 수 있다. 제어부는 재 감지된 사용자의 위치에 기초하여 헤드부의 회전 각도를 보정함으로써, 얼굴 검출부가 사용자를 정확히 향하게 할 수 있다. 로봇은 얼굴 검출부를 이용하여 사용자의 얼굴을 검출할 수 있다(S1010). 제어부는 얼굴 검출부가 사용자를 향하도록 헤드부를 회전시킨 후, 얼굴 검출부를 제어하여 사용자의 얼굴을 포함하는 이미지(I1)를 획득할 수 있다. 로봇은 검출된 얼굴로부터 감지되는 사용자의 시선에 기초하여, 사용자의 로봇에 대한 인터랙션 의도를 검출할 수 있다(S1020). 도 11을 참조하면, 제어부는 얼굴 검출부를 통해 획득된 이미지(I1)로부터, 기 공지된 영상 인식 알 고리즘을 이용하여 사용자의 눈을 검출할 수 있다. 제어부는 검출된 사용자의 눈으로부터 사 용자의 시선(S1)이 향하는 방향을 감지할 수 있다. 일례로, 제어부는 기공지된 아이트래킹(eye tracking) 알고리즘을 이용하여 동공이 향하는 방향을 감지함으로써 사용자의 시선(S1) 방향을 감지할 수 있다. 제어부는 감지된 시선(S1)이 로봇을 향하는 것으로 감지되는 경우, 사용자가 로봇과의 인터랙 션 의도가 존재함을 검출할 수 있다. 구체적으로, 제어부는 시선(S1)이 조작부를 향하는 것으로 감지 된 경우 상기 인터랙션 의도가 존재함을 검출할 수 있다. 이는, 로봇과의 인터랙션 의도가 존재하는 사용자 는 로봇의 조작부를 바라보는 것이 일반적이기 때문이다. 한편, 인터랙션 의도가 존재하는 사용자의 시선은 로봇 또는 조작부로 유지될 수 있다. 반면, 인 터랙션 의도가 존재하지 않는 사용자의 시선은 로봇 또는 조작부를 미소한 시간 동안 향한 후 다 른 방향으로 변화할 수 있다. 이에 따라, 제어부는 상기 시선(S1)이 소정 시간 이상 로봇 또는 조작부 를 향하는 것으로 감지되는 경우에 상기 인터랙션 의도가 존재하는 것으로 검출함으로써, 검출 정확도를 보다 향상시킬 수 있다. 도 12 내지 도 14는 본 발명의 로봇이, 복수의 사용자들의 접근이 감지되는 경우 인터랙션 의도를 갖는 사용자 를 검출하는 동작의 일례를 설명하기 위한 도면들이다. 공항이나 백화점 등의 공공 장소에는 많은 이용객들이 존재하고, 이 경우, 복수의 사용자들이 로봇 근방을 통과할 수 있다. 본 발명의 실시 예에 따른 로봇은 복수의 사용자들의 접근이 감지된 경우에도, 인터랙션 의도를 갖는 사용자를 원활히 검출할 수 있다. 이와 관련하여 도 12 내지 도 14를 참조하면, 로봇은 복수의 사용자가 접근함을 감지할 수 있다(S1200). 이하 도 12 내지 도 14에서는, 설명의 편의를 위해 복수의 사용자가 제1 사용자 및 제2 사용자를 포함하는 것으로 가정한다. 도 8 내지 도 9에서 상술한 바와 유사하게, 제어부는 사용자 감지부에 포함된 센서들(632, 634)을 이 용하여, 로봇으로부터 소정 거리 이내의 감지 영역(Zone 2)에 존재하는 제1 사용자 및 제2 사용자 의 접근을 감지할 수 있다. 상기 감지 영역(Zone 2)은 오브젝트 감지 센서의 최대 감지거리 이하의 영역을 의미할 수 있다. 로봇은 감지된 복수의 사용자들 중, 기설정된 거리 이내로 선 진입한 제1 사용자의 인터랙션 의도를 검출할 수 있다(S1210). 제어부는 감지된 복수의 사용자들(1301, 1302) 중, 상기 감지 영역(Zone 2) 내의 인터랙션 의도 검출 영역 (Zone 1)으로 먼저 진입한 제1 사용자의 인터랙션 의도를 검출할 수 있다. 상기 인터랙션 의도 검출 영역 (Zone 1)은 상기 감지 영역(Zone 2)과 같거나, 상기 감지 영역(Zone 2) 내의 일부 영역에 해당할 수 있다. 도 10 내지 도 11에서 상술한 바와 유사하게, 제어부는 얼굴 검출부가 제1 사용자를 향하도록 헤드부를 회전시킬 수 있다. 제어부는 얼굴 검출부를 제어하여 제1 사용자의 얼굴을 포함 하는 이미지를 획득하고, 획득된 이미지로부터 제1 사용자의 시선 방향을 감지하여 인터랙션 의도를 검출 할 수 있다. 즉, 로봇은 복수의 사용자들의 접근이 감지된 경우, 상기 인터랙션 의도 검출 영역(Zone 1)으로 진입한 순서 에 따라 복수의 사용자들에 대한 우선순위를 설정함으로써, 복수의 사용자들에 대한 인터랙션 의도를 효율적으 로 검출할 수 있다. 실시 예에 따라, 상기 우선순위는 다양한 방식으로 설정될 수 있다. 예컨대, 상기 우선순위는 로봇과 사용자 간의 거리 순으로 설정될 수 있다. 또는, 상기 우선순위는 사용자의 이동 속도에 기초하여 산출되는 로봇으 로의 도달 순서에 따라 설정될 수도 있다. 인터랙션 의도가 검출된 경우(S1220의 YES), 로봇은 제1 사용자 와의 인터랙션을 수행할 수 있다 (S1230). 이 경우, 상기 인터랙션 의도 검출 영역(Zone 1) 내로 다른 사용자가 진입하더라도, 제어부는 제1 사용자 와의 인터랙션을 지속 수행할 수 있다. 제어부는 제1 사용자와의 인터랙션이 수행된 후 제1 사용자가 인터랙션 의도 검출 영역(Zone 1)을 벗어난 경우, 상기 다른 사용자의 인터랙션 의도를 검출하 여 인터랙션을 수행할 수 있다. 반면, 인터랙션 의도가 검출되지 않은 경우(S1220의 NO), 로봇은 복수의 사용자들 중 기설정된 거리 이내로 후 진입한 제2 사용자의 방향으로 헤드부를 회전하고(S1240), 제2 사용자의 인터랙션 의도를 검출할 수 있 다(S1250). 제어부는 얼굴 검출부를 통해 획득한 이미지(I1)로부터 제1 사용자의 인터랙션 의도가 검출되 지 않은 경우, 제1 사용자 다음으로 상기 인터랙션 의도 검출 영역(Zone 1)에 진입한 제2 사용자에 대한 인터랙션 의도를 검출할 수 있다. 이를 위해, 제어부는 얼굴 검출부가 제2 사용자를 향하도록 헤드부를 회전시키고, 얼굴 검출부를 제어하여 제2 사용자의 얼굴을 포함하는 이미지(I2)를 획득할 수 있다. 제어부는 획 득된 이미지(I2)로부터 제2 사용자의 시선 방향을 감지하고, 감지된 시선 방향에 기초하여 제2 사용자 의 인터랙션 의도를 검출할 수 있다. 제2 사용자의 인터랙션 의도가 검출된 경우(S1260의 YES), 로봇은 제2 사용자와의 인터랙션을 수행할 수 있 다(S1270). 반면, 제2 사용자의 인터랙션 의도가 검출되지 않는 경우, 제어부는 인터랙션 의도 검출 영역(Zone 1)으로 진입한 다른 사용자에 대한 인터랙션 의도를 검출할 수 있다. 실시 예에 따라, 제어부는 제1 사용자의 인터랙션 의도가 검출되지 않더라도, 제1 사용자가 인터랙션 의도 검출 영역(Zone 1)을 벗어날 때까지는 다른 사용자에 대한 인터랙션 의도 검출 동작을 수행하지 않을 수 있다. 이러한 실시 예에 따르면, 제어부가 제1 사용자의 인터랙션 의도가 없는 것으로 잘못 검출하더라도, 제1 사용자는 로봇으로 이동하여 인터랙션을 위한 조작이나 음성 발화를 수행함으로써, 로봇으로부터 원하는 서비스를 제공받을 수 있다. 도 15는 본 발명의 로봇이, 인터랙션 의도를 갖는 사용자와의 인터랙션을 수행하는 동작의 구체적 일례를 나타 낸 플로우차트이다. 도 15를 참조하면, S720 단계에 의해 사용자의 인터랙션 의도가 검출된 경우, 로봇은 사용자가 위치한 방향 으로 로봇 바디를 회전하도록 주행부를 제어할 수 있다(S1500). 사용자가 위치한 방향으로 로봇 바디를 회전함은, 로봇의 전방이 상기 사용자가 위치한 방향에 대응하도록 주행 방향을 변경함을 의미할 수 있다. 예컨대, 제어부는 로봇의 전방이 상기 사용자가 위치한 방향에 대응하도록 주행부에 포함된 모터(제1 모터와 제2 모터)를 제어할 수 있다. 한편, 헤드부의 조작부는 사용자의 인터랙션 의도 검출 동작 시 사용자가 위치한 방향을 향할 수 있 다. 이 경우, 제어부는 로봇이 회전할 때, 조작부가 사용자가 위치한 방향을 향하는 상태를 유지 시키기 위해, 주행부의 제어에 대응하여 헤드 모터를 제어하여 헤드부를 바디부에 대해 상 대적으로 회전시킬 수 있다. 로봇은 사용자의 발화를 유도하기 위한 안내 음성 또는 안내 화면을 출력할 수 있다(S1510). 제어부는 사용자로부터 제공받고자 하는 서비스와 관련된 발화를 수신하기 위한 안내 음성을 스피커 를 통해 출력하거나, 디스플레이 중 조작부의 터치 스크린을 통해 안내 화면을 출력할 수 있다. 실시 예에 따라, 제어부는 사용자로부터 제공받고자 하는 서비스에 대한 선택 입력을 수신하기 위해, 조작 부의 터치 스크린을 통해 메뉴 화면을 출력할 수도 있다. 로봇은 입력부의 마이크로폰을 통해 사용자의 발화에 따른 음성을 획득하고(S1520), 획득된 음성에 기 초한 서비스를 제공함으로써 사용자와의 인터랙션을 수행할 수 있다(S1530). 사용자는 출력된 안내 음성 또는 안내 화면에 기초하여, 로봇으로부터 제공받고자 하는 서비스와 관련된 음 성을 발화할 수 있다. 예컨대, 상기 음성은 사용자가 제공받고자 하는 서비스에 대한 키워드를 포함할 수 있다. 제어부는 입력부의 마이크로폰을 통해 상기 사용자가 발화한 음성을 수신할 수 있다. 제어부는 기 공지된 음성 인식 기법을 이용하여, 수신된 음성에 포함된 상기 키워드를 인식할 수 있다. 제어부는 인 식된 키워드에 기초하여 사용자가 원하는 서비스를 제공함으로써 사용자와의 인터랙션을 수행할 수 있다. 실시 예에 따라, 사용자는 조작부에 출력된 메뉴 화면에 기초하여, 로봇으로부터 제공받고자 하는 서비 스와 관련된 메뉴를 선택할 수 있다. 제어부는 조작부의 터치 스크린을 통해 사용자의 선택 입력을 수신하고, 선택된 메뉴에 기초하여 사용자가 원하는 서비스를 제공함으로써 사용자와의 인터랙션을 수행할 수도 있다. 한편, 제어부는 기 설정된 시간 동안 사용자로부터 음성 등 입력이 수신되지 않는 경우, 상기 안내 음성 또는 안내 화면을 다시 출력할 수 있다. 또는, 제어부는 기 설정된 시간 동안 사용자로부터 음성 등 입력 이 수신되지 않는 경우, 안내 음성 또는 안내 화면의 출력을 종료하고, 인터랙션 의도를 갖는 다른 사용자를 검 출할 수도 있다. 도 16 내지 도 18은 본 발명의 로봇이, 사용자의 특성에 기초하여 인터랙션을 수행하는 동작의 일례를 나타내는 도면들이다. 도 16을 참조하면, S710 단계에 따라 로봇은 얼굴 검출부가 사용자 방향을 향하도록 헤드부를 회 전시킬 수 있다. 로봇은 얼굴 검출부를 이용하여 사용자의 얼굴을 검출할 수 있다(S1600). S1600 단계는 도 10의 S1010 단계와 실질적으로 동일한 바, 이에 대한 구체적인 설명은 생략한다. 로봇은 검출된 얼굴로부터 사용자의 특성을 검출할 수 있다(S1610). 제어부는 얼굴 검출부를 통해 획득된 이미지 내의 사용자 얼굴로부터, 사용자의 특성과 관련된 특징 들을 추출할 수 있다. 제어부는 추출된 특징들에 기초하여 사용자의 특성을 검출할 수 있다. 상기 특징은 얼굴이나 얼굴 각 부위(눈, 코, 입 등)의 크기, 피부색, 주름 정도, 헤어스타일 등 사용자의 특성 과 관련된 각종 정보를 포함할 수 있다. 상기 사용자의 특성은, 사용자의 연령대, 성별, 및 인종 등과 같이 사용자의 얼굴로부터 인식 또는 추정가능한 특성들을 포함할 수 있다. 로봇은 사용자의 인터랙션 의도를 검출할 수 있다(S1620). 인터랙션 의도가 검출된 경우, 로봇은 검출된 사용자의 특성에 기초한 안내 음성 또는 안내 화면을 출력할 수 있다(S1630). 도 17의 예시를 참조하면, 인터랙션 의도를 갖는 사용자의 특성이 '어린이'인 경우, 제어부는 조작부(18 3)의 터치 스크린을 통해 '동물 캐릭터'를 포함하는 안내 화면을 표시할 수 있다. 또한, 제어부는 '동물 캐릭터'의 음성으로 상기 안내 음성을 출력할 수 있다. 한편, 도 18의 예시를 참조하면, 인터랙션 의도를 갖는 사용자의 특성이 '청소년 여성'인 경우, 제어부는 조작부의 터치 스크린을 통해 '남자 연예인'을 포함하는 안내 화면을 표시할 수 있다. 또한, 제어부 는 상기 '남자 연예인'의 음성으로 안내 음성을 출력할 수 있다. 비록 도시되지는 않았으나, 예를 들어 사용자의 특성이 '서양인'인 경우, 제어부는 영어, 프랑스어, 또는 스페인어 등으로 안내 음성을 출력할 수도 있다. 반면, 사용자의 특성이 '동양인'인 경우, 제어부는 한국 어, 중국어, 또는 일본어로 안내 음성을 출력할 수도 있다. 즉, 로봇은 인터랙션 의도를 갖는 사용자의 특성에 기초한 안내 화면 또는 안내 음성을 제공함으로써, 사용 자와 보다 효과적인 인터랙션을 수행할 수 있다. 또한, 사용자로 하여금 로봇에 대한 흥미를 유발함으로써, 로봇 및 제조사에 대한 긍정적 이미지가 제고될 수 있다. 도 19는 본 발명의 로봇이 수행하는 제어 동작의 다른 예를 설명하기 위한 플로우차트이다. 도 19를 참조하면, 로봇은 주행 중 사용자의 접근을 감지할 수 있다(S1900). S1900 단계는 도 8 내지 도 9를 통해 상술한 내용과 유사한 바, 이에 대한 구체적인 설명은 생략하기로 한다. 로봇은 다른 사용자에게 서비스를 제공하고 있는 경우, 제공되는 서비스에 기초하여 특정 위치로 주행할 수 있다. 또는, 로봇이 현재 서비스를 제공하고 있지 않은 상태이더라도, 로봇은 공간 내를 자율 주행하면서 기설정된 동작(광고화면 표시 등)을 수행할 수 있다. 로봇이 현재 다른 사용자에게 서비스를 제공하고 있거나, 기설정된 서비스를 다수의 사용자에게 제공중인 경 우(S1905의 YES), 로봇은 현재 서비스 제공 중임을 상기 접근 감지된 사용자에게 알린 후, 서비스를 지속 제 공할 수 있다(S1910). 제어부는 주행 중 장애물 감지나 위치 인식 등을 위해, 다른 사용자에게 서비스를 제공하는 동안에도 사용 자 감지부나 얼굴 검출부 등에 포함된 센서들을 지속 구동시킬 수 있다. 이 경우, 제어부는 사용자 감지부를 통해 로봇으로 접근 중인 사용자를 감지할 수 있다. 그러나, 로봇은 현재 다른 사용자와의 인터랙션이 수행 중(서비스 제공 중)이므로, 상기 접근 중인 사용자와는 인터 랙션이 불가능할 수 있다. 이에 따라, 제어부는 로봇이 상기 접근 중인 사용자와의 인터랙션이 불가함을 나타내는 화면 또는 음성 을 출력부를 통해 출력하고, 상기 다른 사용자에 대한 서비스를 지속 제공할 수 있다. 반면, 로봇이 현재 서비스를 제공하고 있지 않은 경우(S1905의 NO), 로봇은 주행을 정지할 수 있다 (S1915). 제어부는 서비스를 제공하고 있지 않은 상태에서 접근 중인 사용자가 감지된 경우, 사용자의 인터랙션 의 도를 정확히 검출하기 위해 주행을 정지하도록 주행부를 제어할 수 있다. 실시 예에 따라, 제어부는 헤드부의 조작부가 상기 접근 중인 사용자를 향하도록 헤드 모터 를 제어할 수도 있다. 로봇은 사용자로부터 인터랙션의 시도를 위한 입력이 수신되는지 여부를 확인할 수 있다(S1920). 인터랙션 시도를 위한 입력이 수신되지 않는 경우(S1920의 NO), 로봇은 사용자의 인터랙션 의도를 검출할 수 있다(S1925). 제어부는 조작부 또는 입력부를 통해, 사용자로부터 인터랙션의 시도를 위한 입력이 수신되는지 여부를 확인할 수 있다. 기 설정된 시간 동안 상기 입력이 수신되지 않는 경우, 제어부는 도 10의 S1000 단계 내지 S1020 단계에 따라 사용자의 인터랙션 의도를 검출할 수 있다. 다만, 실시 예에 따라 S1920 단계와 S1925 단계는 병렬적으로 수행될 수도 있다. 즉, 제어부는 상기 인터 랙션의 시도를 위한 입력의 수신을 대기하면서, 동시에 사용자의 인터랙션 의도를 검출할 수도 있다. 인터랙션 의도가 검출된 경우, 로봇은 사용자 방향으로 로봇 바디를 회전하고(S1930), 사용자의 발화를 유도 하기 위한 안내 음성 또는 안내 화면을 출력할 수 있다(S1935). S1930 단계 및 S1935 단계는 도 15의 S1500 단계 및 S1510 단계와 실질적으로 동일할 수 있다. 사용자의 발화에 따른 음성이 획득되지 않는 경우(S1940의 NO), 로봇은 사용자의 인터랙션 의도가 없는 것으 로 확인하고 주행을 재개할 수 있다(S1945). 제어부는 기 설정된 시간 동안 사용자로부터 상기 음성 등의 입력이 획득되지 않는 경우, 사용자의 인터랙 션 의도가 없는 것으로 확인할 수 있다. 이 경우, 제어부는 주행부를 제어하여 주행을 재개할 수 있다. 실시 예에 따라, 제어부는 기 설정된 시간 동안 사용자로부터 상기 음성 등의 입력이 획득되지 않는 경우, 상기 안내 음성 또는 안내 화면을 소정 회 재출력할 수도 있다. 반면, 사용자의 발화에 따른 음성이 획득된 경우(S1940의 YES), 로봇은 획득된 음성에 기초하여 사용자와의 인터랙션을 수행할 수 있다(S1950). 한편, S1920 단계에서 사용자로부터 인터랙션 시도를 위한 입력이 수신된 경우(S920의 YES), 로봇은 수신된 입력에 기초하여 사용자와의 인터랙션을 수행할 수 있다(S1950). 즉, 도 19에 도시된 실시 예에 따르면, 로봇은 주행 중 사용자가 접근함이 감지되면, 서비스의 제공 중인지 여부에 기초하여 보다 지능적인 동작 수행이 가능하다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시 예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이 고, 이러한 실시 예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사 상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19"}
{"patent_id": "10-2018-0124634", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 로봇의 외관을 보여주는 사시도이다. 도 2는 도 1의 상부모듈과 하부모듈이 분리된 모습을 보여주는 도면이다. 도 3은 도 1에 도시된 로봇의 외관을 보여주는 측면도이다. 도 4는 도 1의 상부모듈 내부를 보여주는 도면이다. 도 5는 도 1의 하부모듈 내부를 보여주는 도면이다. 도 6은 본 발명의 실시 예에 따른 로봇의 제어 구성을 개략적으로 나타낸 블록도이다. 도 7은 본 발명의 실시 예에 따른 로봇의 제어 동작을 개략적으로 나타낸 플로우차트이다. 도 8과 도 9는 본 발명의 로봇이 사용자의 접근을 감지하는 동작의 일례를 설명하기 위한 도면들이다. 도 10과 도 11은 본 발명의 로봇이, 접근이 감지된 사용자에 대한 인터랙션 의도를 검출하는 동작의 일례를 설 명하기 위한 도면들이다. 도 12 내지 도 14는 본 발명의 로봇이, 복수의 사용자들의 접근이 감지되는 경우 인터랙션 의도를 갖는 사용자 를 검출하는 동작의 일례를 설명하기 위한 도면들이다. 도 15는 본 발명의 로봇이, 인터랙션 의도를 갖는 사용자와의 인터랙션을 수행하는 동작의 구체적 일례를 나타 낸 플로우차트이다. 도 16 내지 도 18은 본 발명의 로봇이, 사용자의 특성에 기초하여 인터랙션을 수행하는 동작의 일례를 나타내는 도면들이다. 도 19는 본 발명의 로봇이 수행하는 제어 동작의 다른 예를 설명하기 위한 플로우차트이다."}
