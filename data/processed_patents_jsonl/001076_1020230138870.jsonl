{"patent_id": "10-2023-0138870", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0055267", "출원번호": "10-2023-0138870", "발명의 명칭": "레이더 센서 및 라이더 센서를 이용하는 차량 추적 장치 및 방법", "출원인": "주식회사 아이디씨티", "발명자": "류지훈"}}
{"patent_id": "10-2023-0138870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 레이더(RADAR, radio detection and ranging) 검출 구간에서, 레이더 센서의 검출 신호를 이용하여, 도로의 적어도 하나의 차량을 인식하고, 상기 적어도 하나의 차량의 궤적을 추적하여 상기 적어도 하나의차량의 서브 궤적 정보를 생성하는 단계;적어도 하나의 라이다(LiDAR, light detection and ranging) 검출 구간에서, 라이다 센서의 검출 신호를 이용하여, 상기 도로의 상기 적어도 하나의 차량을 인식하고, 상기 적어도 하나의 차량의 궤적을 추적하여 상기 적어도 하나의 차량의 서브 궤적 정보를 생성하는 단계; 및상기 적어도 하나의 레이더 검출 구간의 상기 적어도 하나의 차량의 서브 궤적 정보와 상기 적어도 하나의 라이다 검출 구간의 상기 적어도 하나의 차량의 서브 궤적 정보의 조합에 의해 상기 도로 상에서 상기 적어도 하나의 차량의 전체 궤적 정보를 생성하는 단계를 포함하고,상기 도로 상에 상기 적어도 하나의 레이더 검출 구간과 상기 적어도 하나의 라이다 검출 구간이 배치되고, 상기 적어도 하나의 레이더 검출 구간 각각의 길이는 상기 적어도 하나의 라이다 검출 구간 각각의 길이보다 길게설정되는, 차량 추적 방법."}
{"patent_id": "10-2023-0138870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 적어도 하나의 레이더 검출 구간 각각에 배치된 상기 레이더 센서는 상기 도로의 차량 주행 방향을 향해배치되어 상기 적어도 하나의 차량의 후면을 센싱하도록 배치되고,상기 적어도 하나의 라이다 검출 구간 각각에 배치된 상기 라이다 센서는 상기 도로의 차량 주행 방향을 향해배치되어 상기 적어도 하나의 차량의 후면을 센싱하도록 배치되는, 차량 추적 방법."}
{"patent_id": "10-2023-0138870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 적어도 하나의 레이더 검출 구간은 상기 도로의 직선 구간에 배치되고, 상기 적어도 하나의 라이다 검출구간은 상기 도로의 커브 구간에 배치되는, 차량 추적 방법."}
{"patent_id": "10-2023-0138870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 도로를 주행 중인 차량을 촬영하는 제1 카메라로부터 촬영 영상을 획득하는 단계;상기 촬영 영상에 기초하여 주행 중인 차량의 번호판을 인식하는 단계; 및상기 인식된 번호판과 상기 적어도 하나의 차량을 매칭시키는 단계를 더 포함하는, 차량 추적 방법."}
{"patent_id": "10-2023-0138870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 촬영 영상으로부터 인식된 차량의 차선 정보를 획득하는 단계를 더 포함하고,상기 인식된 번호판과 상기 적어도 하나의 차량을 매칭시키는 단계는, 상기 촬영 영상의 촬영 시간 및 상기 인식된 차량의 차선 정보에 기초하여 상기 인식된 번호판과 상기 적어도 하나의 차량을 매칭시키는, 차량 추적 방법."}
{"patent_id": "10-2023-0138870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2025-0055267-3-제4항에 있어서,상기 도로 상에 적어도 하나의 제1 카메라가 배치되고, 상기 적어도 하나의 카메라는 상기 적어도 하나의 레이더 센서와 대응되는 위치에 배치되고, 상기 인식된 번호판과 상기 적어도 하나의 차량을 매칭시키는 단계는, 상기 촬영 영상의 촬영 시간, 상기 인식된 차량의 차선 정보, 및 상기 적어도 하나의 레이더 검출 구간의 상기 적어도 하나의 차량의 서브 궤적 정보에기초하여 상기 인식된 번호판과 상기 적어도 하나의 차량을 매칭시키는, 차량 추적 방법."}
{"patent_id": "10-2023-0138870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,두개의 상기 레이더 검출 구간이 연속해서 배치되는 경우, 상기 두개의 레이더 검출 구간 사이에 제2 카메라에의해 상기 적어도 하나의 차량의 서브 궤적 정보를 생성하는 카메라 검출 구간이 배치되고, 상기 차량 추적 방법은, 상기 카메라 검출 구간에서 상기 제2 카메라에 의해 촬영된 촬영 영상에 기초하여 상기적어도 하나의 차량의 서브 궤적 정보를 생성하는 단계를 더 포함하고,상기 적어도 하나의 차량의 전체 궤적 정보를 생성하는 단계는, 상기 적어도 하나의 레이더 검출 구간의 상기적어도 하나의 차량의 서브 궤적 정보, 상기 적어도 하나의 라이다 검출 구간의 상기 적어도 하나의 차량의 서브 궤적 정보, 및 상기 카메라 검출 구간의 서브 궤적 정보의 조합에 의해 상기 도로 상에서 상기 적어도 하나의 차량의 전체 궤적 정보를 생성하는, 차량 추적 방법."}
{"patent_id": "10-2023-0138870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 도로를 촬영하는 제3 카메라의 촬영 영상에 기초하여 상기 도로를 주행 중인 적어도 하나의 차량을 인식하는 단계;상기 촬영 영상으로부터 인식된 적어도 하나의 차량을 상기 전체 궤적 정보가 정의된 적어도 하나의 차량과 매칭시키는 단계; 및상기 촬영 영상과 상기 전체 궤적 정보를 이용하여 합성 영상을 생성하는 단계를 더 포함하는 차량 추적 방법."}
{"patent_id": "10-2023-0138870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 합성 영상에 기초하여, 상기 도로 상에서의 교통 이벤트를 검출하는 단계를 더 포함하는 차량 추적 방법."}
{"patent_id": "10-2023-0138870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 도로를 주행 중인 차량을 촬영하는 제1 카메라로부터 촬영 영상을 획득하는 단계;상기 촬영 영상에 기초하여 주행 중인 차량의 번호판을 인식하는 단계; 및상기 인식된 번호판과 상기 적어도 하나의 차량을 매칭시키는 단계를 더 포함하고,상기 합성 영상은 상기 제3 카메라의 촬영 영상으로부터 인식된 적어도 하나의 차량 각각의 번호판 정보를 포함하는, 차량 추적 방법."}
{"patent_id": "10-2023-0138870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 적어도 하나의 레이더 검출 구간 각각의 길이는 2km이고, 상기 적어도 하나의 라이다 검출 구간 각각의 길이는 200m인, 차량 추적 방법."}
{"patent_id": "10-2023-0138870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2025-0055267-4-적어도 하나의 레이더(RADAR, radio detection and ranging) 센서 및 적어도 하나의 라이다(LiDAR, lightdetection and ranging) 센서로부터 검출 신호를 수신하는 통신 모듈;적어도 하나의 인스트럭션을 저장하는 메모리; 및적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는 상기 적어도 하나의 인스트럭션을 실행함에 의해,적어도 하나의 레이더 검출 구간에서, 레이더 센서의 검출 신호를 이용하여 도로의 적어도 하나의 차량을 인식하고, 상기 적어도 하나의 차량의 궤적을 추적하여 상기 적어도 하나의 차량의 서브 궤적 정보를 생성하고,적어도 하나의 라이다 검출 구간에서, 라이다 센서의 검출 신호를 이용하여, 상기 도로의 상기 적어도 하나의차량을 인식하고, 상기 적어도 하나의 차량의 궤적을 추적하여 상기 적어도 하나의 차량의 서브 궤적 정보를 생성하고,상기 적어도 하나의 레이더 검출 구간의 상기 적어도 하나의 차량의 서브 궤적 정보와 상기 적어도 하나의 라이다 검출 구간의 상기 적어도 하나의 차량의 서브 궤적 정보의 조합에 의해 상기 도로 상에서 상기 적어도 하나의 차량의 전체 궤적 정보를 생성하고,상기 도로 상에 상기 적어도 하나의 레이더 검출 구간과 상기 적어도 하나의 라이다 검출 구간이 배치되고, 상기 적어도 하나의 레이더 검출 구간 각각의 길이는 상기 적어도 하나의 라이다 검출 구간 각각의 길이보다 길게설정되는, 차량 추적 장치."}
{"patent_id": "10-2023-0138870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항 내지 제11항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2023-0138870", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 일 실시예의 일 측면에 따르면, 적어도 하나의 레이더(RADAR, radio detection and ranging) 검출 구 간에서, 레이더 센서의 검출 신호를 이용하여, 도로의 적어도 하나의 차량을 인식하고, 상기 적어도 하나의 차량 의 궤적을 추적하여 상기 적어도 하나의 차량의 서브 궤적 정보를 생성하는 단계, 적어도 하나의 라이다(LiDAR, (뒷면에 계속)"}
{"patent_id": "10-2023-0138870", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, 레이더 센서 및 라이더 센서를 이용하는 차량 추적 장치, 차량 추적 방법, 및 차량 추적 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체가 제공된다."}
{"patent_id": "10-2023-0138870", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "도로에서 차량을 인식하고 추적하여 교통 정보를 제공하는 기술이 널리 이용되고 있다. 차량을 인식하고 추적함 에 의해, 교통 정보 서버 등에서 교통 상황을 모니터링하고, 교통 정보를 수집하는 것이 가능하다. 이와 관련하 여, 차량의 인식 및 추적을 위해 다양한 센서들이 도로 상에 배치되고, 도로에서 수집된 데이터를 이용하여 서 버 등에서 교통 정보를 수집할 수 있다. 그런데 도로 상의 센서를 이용하여 빠른 속도로 이동하는 차량을 높은 정확도로 인식하고 추적하는데 적절한 비용으로, 요구되는 성능을 얻는데 어려움이 있다."}
{"patent_id": "10-2023-0138870", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예의 일 측면에 따르면, 적어도 하나의 레이더(RADAR, radio detection and ranging) 검출 구간에서, 레이더 센서의 검출 신호를 이용하여, 도로의 적어도 하나의 차량을 인식하고, 상기 적어도 하나의 차량의 궤적을 추적하여 상기 적어도 하나의 차량의 서브 궤적 정보를 생성하는 단계, 적어도 하나의 라이다 (LiDAR, light detection and ranging) 검출 구간에서, 라이다 센서의 검출 신호를 이용하여, 상기 도로의 상 기 적어도 하나의 차량을 인식하고, 상기 적어도 하나의 차량의 궤적을 추적하여 상기 적어도 하나의 차량의 서 브 궤적 정보를 생성하는 단계, 및 상기 적어도 하나의 레이더 검출 구간의 상기 적어도 하나의 차량의 서브 궤 적 정보와 상기 적어도 하나의 라이다 검출 구간의 상기 적어도 하나의 차량의 서브 궤적 정보의 조합에 의해 상기 도로 상에서 상기 적어도 하나의 차량의 전체 궤적 정보를 생성하는 단계를 포함하고, 상기 도로 상에 상 기 적어도 하나의 레이더 검출 구간과 상기 적어도 하나의 라이다 검출 구간이 배치되고, 상기 적어도 하나의 레이더 검출 구간 각각의 길이는 상기 적어도 하나의 라이다 검출 구간 각각의 길이보다 길게 설정되는, 차량 추적 방법이 제공된다.또한, 본 개시의 일 실시예에 따르면, 상기 적어도 하나의 레이더 검출 구간 각각에 배치된 상기 레이더 센서는 상기 도로의 차량 주행 방향을 향해 배치되어 상기 적어도 하나의 차량의 후면을 센싱하도록 배치되고, 상기 적 어도 하나의 라이다 검출 구간 각각에 배치된 상기 라이다 센서는 상기 도로의 차량 주행 방향을 향해 배치되어 상기 적어도 하나의 차량의 후면을 센싱하도록 배치될 수 있다. 또한, 본 개시의 일 실시예에 따르면, 상기 적어도 하나의 레이더 검출 구간은 상기 도로의 직선 구간에 배치되 고, 상기 적어도 하나의 라이다 검출 구간은 상기 도로의 커브 구간에 배치될 수 있다. 또한, 본 개시의 일 실시예에 따르면, 상기 도로를 주행 중인 차량을 촬영하는 제1 카메라로부터 촬영 영상을 획득하는 단계, 상기 촬영 영상에 기초하여 주행 중인 차량의 번호판을 인식하는 단계, 및 상기 인식된 번호판 과 상기 적어도 하나의 차량을 매칭시키는 단계를 더 포함할 수 있다. 또한, 본 개시의 일 실시예에 따르면, 상기 촬영 영상으로부터 인식된 차량의 차선 정보를 획득하는 단계를 더 포함하고, 상기 인식된 번호판과 상기 적어도 하나의 차량을 매칭시키는 단계는, 상기 촬영 영상의 촬영 시간 및 상기 인식된 차량의 차선 정보에 기초하여 상기 인식된 번호판과 상기 적어도 하나의 차량을 매칭시킬 수 있 다. 또한, 본 개시의 일 실시예에 따르면, 상기 도로 상에 적어도 하나의 제1 카메라가 배치되고, 상기 적어도 하나 의 카메라는 상기 적어도 하나의 레이더 센서와 대응되는 위치에 배치되고, 상기 인식된 번호판과 상기 적어도 하나의 차량을 매칭시키는 단계는, 상기 촬영 영상의 촬영 시간, 상기 인식된 차량의 차선 정보, 및 상기 적어 도 하나의 레이더 검출 구간의 상기 적어도 하나의 차량의 서브 궤적 정보에 기초하여 상기 인식된 번호판과 상 기 적어도 하나의 차량을 매칭시킬 수 있다. 또한, 본 개시의 일 실시예에 따르면, 두개의 상기 레이더 검출 구간이 연속해서 배치되는 경우, 상기 두개의 레이더 검출 구간 사이에 제2 카메라에 의해 상기 적어도 하나의 차량의 서브 궤적 정보를 생성하는 카메라 검 출 구간이 배치되고, 상기 차량 추적 방법은, 상기 카메라 검출 구간에서 상기 제2 카메라에 의해 촬영된 촬영 영상에 기초하여 상기 적어도 하나의 차량의 서브 궤적 정보를 생성하는 단계를 더 포함하고, 상기 적어도 하나 의 차량의 전체 궤적 정보를 생성하는 단계는, 상기 적어도 하나의 레이더 검출 구간의 상기 적어도 하나의 차 량의 서브 궤적 정보, 상기 적어도 하나의 라이다 검출 구간의 상기 적어도 하나의 차량의 서브 궤적 정보, 및 상기 카메라 검출 구간의 서브 궤적 정보의 조합에 의해 상기 도로 상에서 상기 적어도 하나의 차량의 전체 궤 적 정보를 생성할 수 있다. 또한, 본 개시의 일 실시예에 따르면, 상기 도로를 촬영하는 제3 카메라의 촬영 영상에 기초하여 상기 도로를 주행 중인 적어도 하나의 차량을 인식하는 단계, 상기 촬영 영상으로부터 인식된 적어도 하나의 차량을 상기 전 체 궤적 정보가 정의된 적어도 하나의 차량과 매칭시키는 단계, 및 상기 촬영 영상과 상기 전체 궤적 정보를 이 용하여 합성 영상을 생성하는 단계를 더 포함할 수 있다. 또한, 본 개시의 일 실시예에 따르면, 상기 합성 영상에 기초하여, 상기 도로 상에서의 교통 이벤트를 검출하는 단계를 더 포함할 수 있다. 또한, 본 개시의 일 실시예에 따르면, 상기 도로를 주행 중인 차량을 촬영하는 제1 카메라로부터 촬영 영상을 획득하는 단계, 상기 촬영 영상에 기초하여 주행 중인 차량의 번호판을 인식하는 단계, 및 상기 인식된 번호판 과 상기 적어도 하나의 차량을 매칭시키는 단계를 더 포함하고, 상기 합성 영상은 상기 제3 카메라의 촬영 영상 으로부터 인식된 적어도 하나의 차량 각각의 번호판 정보를 포함할 수 있다. 또한, 본 개시의 일 실시예에 따르면, 상기 적어도 하나의 레이더 검출 구간 각각의 길이는 2km이고, 상기 적어 도 하나의 라이다 검출 구간 각각의 길이는 200m일 수 있다. 또한, 본 개시의 일 실시예의 일 측면에 따르면, 적어도 하나의 레이더(RADAR, radio detection and ranging) 센서 및 적어도 하나의 라이다(LiDAR, light detection and ranging) 센서로부터 검출 신호를 수신하는 통신 모듈, 적어도 하나의 인스트럭션을 저장하는 메모리, 및 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나 의 프로세서는 상기 적어도 하나의 인스트럭션을 실행함에 의해, 적어도 하나의 레이더 검출 구간에서, 레이더 센서의 검출 신호를 이용하여 도로의 적어도 하나의 차량을 인식하고, 상기 적어도 하나의 차량의 궤적을 추적 하여 상기 적어도 하나의 차량의 서브 궤적 정보를 생성하고, 적어도 하나의 라이다 검출 구간에서, 라이다 센 서의 검출 신호를 이용하여, 상기 도로의 상기 적어도 하나의 차량을 인식하고, 상기 적어도 하나의 차량의 궤 적을 추적하여 상기 적어도 하나의 차량의 서브 궤적 정보를 생성하고, 상기 적어도 하나의 레이더 검출 구간의상기 적어도 하나의 차량의 서브 궤적 정보와 상기 적어도 하나의 라이다 검출 구간의 상기 적어도 하나의 차량 의 서브 궤적 정보의 조합에 의해 상기 도로 상에서 상기 적어도 하나의 차량의 전체 궤적 정보를 생성하고, 상 기 도로 상에 상기 적어도 하나의 레이더 검출 구간과 상기 적어도 하나의 라이다 검출 구간이 배치되고, 상기 적어도 하나의 레이더 검출 구간 각각의 길이는 상기 적어도 하나의 라이다 검출 구간 각각의 길이보다 길게 설 정되는, 차량 추적 장치가 제공된다. 또한, 본 개시의 일 실시예의 일 측면에 따르면, 차량 추적 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록 된 컴퓨터로 읽을 수 있는 기록매체가 제공된다."}
{"patent_id": "10-2023-0138870", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서는 본 개시의 청구항의 권리범위를 명확히 하고, 본 개시의 실시 예들이 속하는 기술분야에서 통상의 지식을 가진 자가 본 개시의 실시 예들을 실시할 수 있도록, 본 개시의 실시 예들의 원리를 설명하고, 실시 예 들을 개시한다. 개시된 실시 예들은 다양한 형태로 구현될 수 있다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 명세서가 실시 예들의 모든 요소들을 설"}
{"patent_id": "10-2023-0138870", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명하는 것은 아니며, 본 개시의 실시 예들이 속하는 기술분야에서 일반적인 내용 또는 실시 예들 간에 중복되는 내용은 생략한다. 명세서에서 사용되는 '부'(part, portion)라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실시 예들에 따라 복수의 '부'가 하나의 요소(unit, element)로 구현되거나, 하나의 '부'가 복수의 요 소들을 포함하는 것도 가능하다. 이하 첨부된 도면들을 참고하여 본 개시의 실시 예들, 및 실시 예들의 작용 원리에 대해 설명한다. 도 1은 본 개시의 일 실시예에 따른 차량 추적 시스템을 나타낸 도면이다. 차량 추적 시스템은 도로 상의 차량을 인식하고 추적하는 시스템이다. 차량 추적 시스템은 차량 추적 장치, 적어도 하나의 센서, 제1 카메라, 및 제2 카메라를 포함한다. 본 개시의 일 실 시예에 따르면, 차량 추적 시스템은 터널에 해당하는 도로 상에 배치될 수 있다. 또한, 본 개시의 일 실시예에 따르면, 차량 추적 시스템은 고가도로에 배치될 수 있다. 차량 추적 장치는 센서, 제1 카메라, 및 제2 카메라로부터 데이터 또는 신호를 수신하여, 차량을 인식하고 추적한다. 차량 추적 장치는 예를 들면, 서버, 컴퓨터, 모바일 장치, 또는 통신 단 말 등에 대응될 수 있다. 차량 추적 장치는 다른 외부 장치와 통신할 수 있다. 예를 들면, 차량 추적 장치는 모바일 장치, 통신 단말, 또는 컴퓨터 등의 외부 장치와 통신할 수 있다. 차량 추적 장치는 외부 장치로부터 사용자 입력을 수신하거나, 외부 장치를 통해 차량 추적의 결과 데이터를 출력할 수 있다. 센서는 레이더(RADAR, radio detection and ranging) 센서 또는 라이다(LiDAR, light detection and ranging) 센서를 포함한다. 본 개시의 일 실시예에 따르면, 도로 상에 레이더 센서에 의해 차량을 검출하는 레 이더 검출 구간과 라이다 센서에 의해 차량을 검출하는 라이더 검출 구간이 소정의 기준에 따라 배치된다. 센서 가 배치된 구간이 레이더 검출 구간인 경우, 센서는 레이더 센서를 포함하고, 센서가 배치된 구 간이 라이다 검출 구간인 경우, 센서는 라이다 센서를 포함한다. 레이더 센서는 전자기파를 발생시켜, 객체를 향해 출력하고, 다시 돌아오는 전자기파를 통해 객체까지의 거리 및 객체의 방향을 검출할 수 있다. 레이더 센서는 ToF(Time of Flight) 센서의 일종이다. 레이더 센서는 장거리 (약: 2km)까지 검출 가능하지만, 광각이 좁은 특징이 있다. 라이다 센서는 펄스 레이저를 이용하여 객체를 검출한다. 라이다 센서는 객체까지의 거리 및 객체의 방향을 검 출할 수 있다. 라이다 센서는 ToF 센서의 일종이다. 라이다 센서는 단거리(약: 200m)까지 검출 가능하지만, 광 각이 넓은 특징이 있다. 다만, 라이다 센서는 레이더 센서에 비해 고가의 장비로, 비용 부담이 큰 단점이 있다. 본 개시의 일 실시예에 따르면, 도로에 걸쳐서 적어도 하나의 레이더 검출 구간과 적어도 하나의 라이다 검출 구간이 배치될 수 있다. 소정의 도로에 레이더 검출 구간과 라이다 검출 구간은 다양한 순서 및 조합으로 배치 될 수 있다. 레이더 검출 구간과 라이다 검출 구간이 다양한 조합으로 순차적으로 배치되어, 차량 추적 시스템 은 레이더 검출 구간과 라이다 검출 구간의 조합에 의해 도로의 전 구간을 커버할 수 있다. 예를 들면, 제1 레이더 검출 구간, 제2 레이더 검출 구간, 제1 라이다 검출 구간, 제2 라이다 검출 구간, 및 제3 레이더 검출 구간이 순차적으로 터널 상에 배치될 수 있다. 본 개시의 일 실시예에 따르면, 레이더 검출 구간에서 주행 방향의 출발 지점에 레이더 센서가 배치될 수 있다. 또한, 본 개시의 일 실시예에 따르면, 라이다 검출 구간에서 주행 방향의 출발 지점에 라이다 센서가 배치될 수 있다. 본 개시의 일 실시예에 따르면, 레이더 검출 구간과 라이다 검출 구간에서, 주행 방향의 출발 지점에 레 이더 센서 또는 라이다 센서를 배치하여, 차량을 후방에서 촬영한다. 이러한 레이더 센서 또는 라이다 센 서의 배치에 의해, 차량을 근거리에서 처음으로 검출하고 점자 차량이 원거리로 이동하게 된다. 따라 서 차량 추적 장치는 차량을 근거리에서 처음 인식하고, 이후에 검출 신호를 이용하여 차량을 트래킹하여, 각 구간에서 처음 차량을 인식할 때, 높은 정확도로 차량을 인식할 수 있는 장점이 있다. 본 개시의 일 실시예에 따르면, 차량 추적 장치는 도로의 레이더 검출 구간과 라이다 검출 구간에서 레이 더 센서 또는 라이더 센서의 검출 신호를 이용하여, 서브 궤적 정보를 생성할 수 있다. 서브 궤적 정보는 레이 더 검출 구간과 라이다 검출 구간 각각에서 검출된 각 차량의 궤적 정보를 나타낸다. 또한, 차량 추적 장치 는 레이더 검출 구간과 라이다 검출 구간 각각의 서브 궤적 정보를 이용하여, 전체 궤적 정보를 생성한다. 차량 추적 장치는 레이더 검출 구간과 라이다 검출 구간의 배치 순서를 미리 저장할 수 있다. 차량 추적 장치는 미리 저장된 레이더 검출 구간과 라이다 검출 구간의 배치 순서에 따라, 서브 궤적 정보를 나열하 고 병합하여, 각 차량에 대한 전체 궤적 정보를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 차량 추적 시스템은 적어도 하나의 제1 카메라를 포함할 수 있다. 제1 카메라는 차량의 번호판을 촬영한다. 차량 추적 장치는 제1 카메라에 의해 촬영된 번 호판 영상을 이용하여, 각 차량의 번호판의 번호를 인식한다. 본 개시의 일 실시예에 따르면, 제1 카메라는 터널의 입구에 배치될 수 있다. 차량 추적 장치는 터널의 입구에서 제1 카메라의 촬영 영상을 이용하여 번호판을 인식하고, 인식된 번호판을 센서의 검출 신호에 의해 인식된 차량과 매칭시킬 수 있다. 본 개시의 일 실시예에 따르면, 제1 카메라는 각각의 레이더 검출 구간 및 라이다 검출 구간에 배치될 수 있다. 차량 추적 장치는 각각의 레이더 검출 구간 및 라이다 검출 구간의 제1 카메라의 촬영 영상을 이용하여, 번호판을 인식하고, 인식된 번호판을 센서의 검출 신호에 의해 인식된 차량과 매칭시킬 수 있다. 본 개시의 일 실시예에 따르면, 차량 추적 시스템은 적어도 하나의 제2 카메라를 포함할 수 있다. 제2 카메라는 카메라 검출 구간에서 주행 중인 차량을 촬영한다. 차량 추적 장치는 카메라 검출 구 간에서 제2 카메라의 촬영 영상을 이용하여 차량을 인식하고, 서브 궤적 정보를 생성한다. 카메라 검 출 구간은 레이더 검출 구간 두 개 사이에 배치될 수 있다. 레이더 검출 구간이 연속으로 배치 경우, 레이더 센서의 레이저 신호 사이에 간섭이 발생할 수 있다. 본 개시의 일 실시예에 따르면, 레이더 검출 구간 사이에 카 메라 검출 구간을 배치하여, 레이더 검출 구간 사이의 레이저 신호 간섭을 방지할 수 있다. 또한, 본 개시의 일 실시예에 따르면, 두 개의 레이더 검출 구간이 연속으로 배치되는 경우, 레이더 검출 구간 사이에 추측 구간이 배치될 수 있다. 레이더 검출 구간이 연속으로 배치되는 경우, 레이더 신호 사이에 간섭이 발생할 수 있다. 본 개시의 일 실시예에 다르면, 레이더 검출 구간 사이에 추측 구간을 배치하여 레이더 신호 사이의 간섭을 방지할 수 있다. 추측 구간은 예를 들면, 500m의 구간으로 배치될 수 있다. 추측 구간에 대해 차 량 추적 장치는 이전 레이더 검출 구간의 서브 궤적 정보와 다음 레이더 검출 구간의 서브 궤적 정보를 이 용하여 추측 구간에서의 서브 궤적 정보를 추측하여 생성한다. 도 2는 본 개시의 일 실시예에 따라 차량을 인식하는 과정을 나타낸 도면이다. 본 개시의 일 실시예에 따르면, 차량 추적 장치는 도로를 주행 중인 차량을 센서를 이용하 여 인식할 수 있다. 차량 추적 장치는 센서의 검출 신호를 이용하여 차량의 서브 궤적 정보를 생성한다. 차량 추적 장치는 검출 신호로부터 차량을 인식하고, 차량을 트래킹한다. 차량 추적 장치는 차량의 차선 정보를 검출 신호 또는 서브 궤적 정보로부터 획득할 수 있다. 또한, 차량 추적 장치는 카메라 검출 구간에서 제2 카메라의 촬영 영상을 이용하여, 차량의 서 브 궤적 정보를 생성한다. 차량 추적 장치는 제2 카메라의 촬영 영상을 이용하여 차량을 인식한 다. 또한, 차량 추적 장치는 제2 카메라의 촬영 영상을 이용하여 인식된 차량을 트래킹한다. 차량 추적 장치는 레이더 검출 구간, 라이다 검출 구간, 및 카메라 검출 구간의 각각의 서브 궤적 정보를 매칭시킨다. 본 개시의 일 실시예에 따르면, 차량 추적 장치는 서브 궤적 정보의 시간 정보 및 차선 정보 를 이용하여 각 서브 궤적 정보를 매칭시킬 수 있다. 차량 추적 장치는 서로 매칭되는 서브 궤적 정보를 연결하여 전체 궤적 정보를 생성할 수 있다. 도 3은 본 개시의 일 실시예에 따른 차량 추적 장치의 구조를 나타낸 도면이다. 본 개시의 일 실시예에 따르면, 차량 추적 장치는 예를 들면, 서버, 컴퓨터, 모바일 장치, 또는 통신 단말 등에 대응될 수 있다. 차량 추적 장치는 프로세서, 통신 모듈, 및 메모리를 포함할 수 있 다. 프로세서는 차량 추적 장치 전반의 동작을 제어한다. 프로세서는 하나 또는 그 이상의 프로세서 로 구현될 수 있다. 프로세서는 메모리에 저장된 인스트럭션 또는 커맨드를 실행하여 소정의 동작을 수행할 수 있다. 또한, 프로세서는 차량 추적 장치에 구비된 구성요소들의 동작을 제어한다. 프로세 서는 CPU(Central Processing Unit), 마이크로 프로세서(microprocessor) 등을 포함할 수 있다. 통신 모듈은 유선 또는 무선으로 적어도 하나의 외부 장치와 통신할 수 있다. 본 개시의 일 실시예에 따르 면, 통신 모듈은 센서, 제1 카메라, 또는 제2 카메라와 통신할 수 있다. 통신 모듈은 센서에 대응하는 레이더 센서 또는 라이다 센서로부터 검출 신호를 수신할 수 있다. 또한, 통신 모듈(31 2)은 제1 카메라로부터 번호판 영상을 수신할 수 있다. 또한, 통신 모듈은 제2 카메라로부터 도 로의 차량을 촬영한 촬영 영상을 수신할 수 있다. 통신 모듈는 무선 통신 모듈(예: 셀룰러 통신 모듈, 근거리 무선 통신 모듈, 또는 GNSS(global navigation satellite system) 통신 모듈) 또는 유선 통신 모듈(예: LAN(local area network) 통신 모듈, 또는 전력선 통 신 모듈)을 포함할 수 있다. 또한, 통신 모듈은 근거리 통신을 수행할 수 있으며, 예를 들면, 블루투스, BLE(Bluetooth Low Energy), 근거리 무선 통신 (Near Field Communication), WLAN(와이파이), 지그비(Zigbee), 적외선(IrDA, infrared Data Association) 통신, WFD(Wi-Fi Direct), UWB(ultrawideband), Ant+ 통신 등을 이 용할 수 있다. 또한, 예를 들면, 통신 모듈은 원거리 통신을 수행할 수 있으며, 예를 들면, 레거시 셀룰러 네트워크, 5G 네트워크, 차세대 통신 네트워크, 인터넷, 또는 컴퓨터 네트워크(예: LAN 또는 WAN) 등을 통해 외 부 장치와 통신할 수 있다. 또한 예를 들면, 통신 모듈은 이동 통신을 이용할 수 있으며, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신할 수 있다. 본 개시의 일 실시예에 따르면, 통신 모듈은 와이파이 통신을 통해 접속 중계기(AP; Access Point)에 연결 된다. 통신 모듈은 접속 중계기를 통해 외부 장치와 통신할 수 있다.메모리는 차량 추적 장치의 동작에 필요한 다양한 정보, 데이터, 명령어, 프로그램 등을 저장한다. 메모리는 휘발성 메모리 또는 비휘발성 메모리 중 적어도 하나 또는 이들의 조합을 포함할 수 있다. 메모 리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이 크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory), SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 또한, 메모리는 인 터넷(internet) 상에서 저장 기능을 수행하는 웹 스토리지(web storage) 또는 클라우드 서버에 대응될 수 있다. 메모리는 레이더 검출 구간, 라이다 검출 구간, 및 카메라 검출 구간의 배치 정보를 저장할 수 있다. 각 레이더 검출 구간, 라이다 검출 구간, 및 카메라 검출 구간은 식별자에 의해 식별될 수 있다. 또한, 메모리 는 각 레이더 검출 구간, 라이다 검출 구간, 및 카메라 검출 구간의 위치 정보를 저장할 수 있다. 예를 들 면, 제1 레이더 검출 구간에 대응하는 영역이 위도와 경도에 의해 정의될 수 있다. 프로세서는 통신 모듈을 통해 각각의 레이더 검출 구간의 레이더 센서의 검출 신호, 각각의 라이다 검출 구간의 라이다 센서의 검출 신호, 및 각각의 카메라 검출 구간의 촬영 영상을 획득한다. 프로세서는 각각의 레이더 검출 구간의 레이더 센서의 검출 신호, 각각의 라이다 검출 구간의 라이다 센서의 검출 신호, 및 각각의 카메라 검출 구간의 촬영 영상으로부터 각각의 구간에 대한 서브 궤적 정보를 생성한다. 프로세서 는 새로운 차량이 검출 신호 또는 촬영 영상으로부터 인식되면, 인식된 차량을 추적하여 서브 궤적 정보를 생성한다. 프로세서는 각각의 서브 궤적 정보를 이어서 전체 궤적 정보를 생성한다. 프로세서는 각각의 레이더 검출 구간, 각각의 라이다 검출 구간, 및 각각의 카메라 검출 구간의 배치 정보 및 위치 정보에 기초하여 서브 궤적 정보를 연결한다. 또한, 각각의 서브 궤적 정보의 시간 정보에 기초하여, 서브 궤적 정보를 연결한다. 본 개시의 일 실시예에 따르면, 프로세서는 전체 궤적 정보를 생성하면, 통신 모듈을 통해 전체 궤적 정보를 외부 장치로 전송할 수 있다. 또한, 본 개시의 일 실시예에 따르면, 프로세서는 전체 궤적 정보를 생성하면, 소정의 출력 인터페이스를 통해 전체 궤적 정보를 출력할 수 있다. 도 4는 본 개시의 일 실시예에 따른 차량 추적 방법을 나타낸 흐름도이다. 본 개시의 일 실시예에 따르면, 차량 추적 방법은 본 개시의 일 실시예에 따른 차량 추적 장치에 의해 수 행될 수 있다. 또한, 차량 추적 방법은 프로세서, 통신 모듈, 및 메모리를 포함하는 다양한 종류의 전자 장치에 의해 수행될 수 있다. 본 개시에서는 본 개시의 일 실시예에 따른 차량 추적 장치에 의해 차량 추적 방법 이 수행되는 실시예를 중심으로 설명하지만, 본 개시의 실시예가 이에 한정되는 것은 아니다. 도 4를 참조하면, 차량 추적 장치는 단계 S402에서 레이더 검출 구간의 서브 궤적 정보를 생성한다. 또한, 차량 추적 장치는 단계 S404에서 라이다 검출 구간의 서브 궤적 정보를 생성한다. 단계 S402에서 레이더 검출 구간의 서브 궤적 정보를 생성하는 처리와, 단계 S404에서 라이다 검출 구간의 서브 궤적 정보를 생성하는 처리는 병렬적으로 수행될 수 있다. 본 개시의 일 실시예에 따르면, 차량 추적 장치는 레이더 센서의 검출 신호를 처리하는 제1 프로세서와, 라이다 센서의 검출 신호를 처리하는 제2 프로세서를 포함할 수 있다. 제1 프 로세서와 제2 프로세서는 물리적으로 분리된 프로세서에 대응될 수 있다. 다음으로 단계 S406에서 차량 추적 장치는 서브 궤적 정보를 연결하여 전체 궤적 정보를 생성한다. 차량 추적 장치는 각 서브 궤적 정보를 레이더 검출 구간 및 라이다 검출 구간의 배치 정보 또는 위치 정보에 기초하여 연결하여, 전체 궤적 정보를 생성할 수 있다. 도 5는 본 개시의 일 실시예에 따라 레이더 검출 구간 및 라이다 검출 구간의 서브 궤적 정보를 이용하여 전체 궤적 정보를 생성하는 과정을 나타낸 도면이다. 본 개시의 일 실시예에 따르면, 도로에 적어도 하나의 레이더 검출 구간(R1, R2, 및 R3) 및 라이다 검출 구간(L1, L2, L3, 및 L4)이 배치될 수 있다. 본 개시의 일 실시예에 따르면, 도로의 직선 구간에는 레이더 검출 구간(R1, R2, 및 R3)이 배치되고, 도로의 곡선 구간에는 라이다 검출 구간(L1, L2, L3, 및 L4)이 배 치될 수 있다. 예를 들면, 도로의 커브의 곡률이 기준 값 이상인 구간에 라이다 검출 구간(L1, L2, L3, 및 L4)이 배치되고, 나머지 구간에 레이더 검출 구간(R1, R2, 및 R3)이 배치될 수 있다. 라이다 센서는 레이더 센 서에 비해 고가의 장비이기 때문에, 차량 검출 시스템은 라이다 센서가 필수적으로 필요한 구간에만 라이다검출 구간(L1, L2, L3, 및 L4)을 배치하고, 나머지 구간에는 레이더 검출 구간(R1, R2, 및 R3)을 배치할 수 있 다. 본 개시의 일 실시예에 따르면, 레이더 검출 구간(R1, R2, 및 R3)이 연속해서 배치되는 경우, 레이더 검출 구간 (R1, R2, 및 R3) 사이에 카메라 검출 구간이 배치될 수 있다. 레이더 검출 구간(R1, R2, 및 R3)은 제1 구간 길이를 갖고, 라이다 검출 구간(L1, L2, L3, 및 L4)은 제2 구간 길이를 가질 수 있다. 제1 구간 길이는 제2 구간 길이보다 길 수 있다. 예를 들면, 제1 구간 길이는 2km이고, 제2 구간 길이는 200m일 수 있다. 본 개시의 일 실시예에 따르면, 도 5에 도시된 바와 같이 각각의 레이더 검출 구간(R1, R2, 및 R3) 및 각각의 라이다 검출 구간(L1, L2, L3, 및 L4)에 대해 서브 궤적 정보가 생성된다. 차량 추적 장치는 도 5에 도시 된 바와 같이 각 서브 궤적 정보를 각각의 레이더 검출 구간(R1, R2, 및 R3) 및 각각의 라이다 검출 구간(L1, L2, L3, 및 L4)의 순서에 따라 연결하여, 전체 궤적 정보를 생성한다. 도 6은 본 개시의 일 실시예에 따른 차량 추적 장치, 센서 모듈, 및 제1 카메라 모듈의 구조를 나타낸 도면이다. 본 개시의 일 실시예에 따른 차량 추적 시스템은 차량 추적 장치, 센서 모듈, 및 제1 카메라 모 듈을 포함할 수 있다. 차량 추적 장치는 센서 모듈 및 제1 카메라 모듈과 통신한다. 차량 추적 장치는 센서 모듈로부터 센서(레이더 센서 또는 라이다 센서)의 검출 신호를 수신할 수 있 다. 또한, 차량 추적 장치는 제1 카메라 모듈로부터 제1 카메라에 의해 촬영된 번호판 영상을 수신할 수 있다. 또한, 차량 추적 장치는 센서 모듈 및 제1 카메라 모듈을 모니터링하고, 제어 할 수 있다. 또한, 센서 모듈 및 제1 카메라 모듈은 하나 이상으로 배치되고, 차량 추적 장치는 각각의 센서 모듈 및 제1 카메라 모듈과 통신할 수 있다. 센서 모듈은 레이다 검출 구간 또는 라이다 검출 구간에 배치된다. 센서 모듈은 각각의 레이다 검출 구간 또는 라이다 검출 구간에 하나씩 배치된다. 센서 모듈은 레이다 검출 구간 또는 라이다 검출 구간에 서, 주행 방향의 시작 지점 주변에 배치될 수 있다. 센서 모듈은 센서가 도로를 주행 중인 차량 의 후방을 촬영하도록 주행 방향을 향해서 배치될 수 있다. 센서 모듈은 센서, 입력 인터페이스, 및 통신 모듈을 포함할 수 있다. 레이다 검출 구간의 센서 모듈의 센서는 레이다 센서를 포함하고, 라이다 검출 구간의 센서 모듈 의 센서는 라이다 센서를 포함한다. 입력 인터페이스는 센서에 의해 생성된 검출 신호를 입력 받아, 통신 모듈로 전달한다. 입력 인터페이스는 센서의 검출 신호에 대해, 아날로그-디지 털 변환, 노이즈 저감 처리 등을 수행할 수 있다. 입력 인터페이스는 영상 포인트 클라우드 형태의 입력 데이터를 통신 모듈로 전달할 수 있다. 통신 모듈은 입력 인터페이스로부터 전달된 검출 신호를 차량 추적 장치로 전송할 수 있다. 제1 카메라 모듈은 도로의 소정의 지점에 배치된다. 본 개시의 일 실시예에 따르면, 제1 카메라 모듈(63 0)은 터널의 입구에 배치된다. 또한, 본 개시의 일 실시예에 따르면, 제1 카메라 모듈은 도로의 차량 진입로 주변에 배치될 수 있다. 또한, 본 개시의 일 실시예에 따르면, 제1 카메라 모듈은 레이다 검출 구 간 또는 라이다 검출 구간 중 하나 또는 복수의 구간에 배치된다. 제1 카메라 모듈이 레이다 검출 구간 또 는 라이다 검출 구간 중 하나 또는 복수의 구간에 배치되는 경우, 제1 카메라 모듈은 해당 구간의 주행 방 향의 시작 지점 주변에 배치될 수 있다. 제1 카메라 모듈은 제1 카메라가 주행 방향을 향해 배치되어 차량의 후방을 촬영하도록 배치될 수 있다. 제1 카메라 모듈은 제1 카메라, 입력 인터페이스, 및 통신 모듈을 포함한다. 제1 카메라는 차량의 번호판을 촬영하여, 번호판 영상을 생성한다. 본 개시의 일 실시예에 따르 면, 제1 카메라는 고해상도의 망원 카메라에 대응될 수 있다. 제1 카메라는 하나 이상의 차량의 후방을 촬영할 수 있다. 본 개시의 일 실시예에 따르면, 제1 카메라는 복수의 제1 카메라를 포함할 수 있다. 복수의 제1 카메라는 각 차선별로 차량을 촬영하도록 배치되거나, 2~3개 차선 당 하나의 제 1 카메라가 배치될 수 있다. 입력 인터페이스는 제1 카메라에 의해 생성된 번호판 영상을 제1 카메라로부터 입력 받아, 통신 모듈로 전달한다. 입력 인터페이스는 동영상 형태의 번호판 영상을 제1 카메라로부터 입력 받아통신 모듈로 전달할 수 있다. 제1 카메라는 실시간 번호판 영상의 영상 스트림을 생성하고, 영상 스 트림을 입력 인터페이스로 전달할 수 있다. 입력 인터페이스는 실시간 번호판 영상의 동영상을 통신 모듈로 전달할 수 있다. 입력 인터페이스는 번호판 영상에 대해, 아날로그-디지털 변환, 노이즈 저감 처리 등을 수행할 수 있다. 통신 모듈은 번호판 영상을 차량 추적 장치로 전송할 수 있다. 차량 추적 장치는 프로세서, 통신 모듈, 메모리, 및 출력 인터페이스를 포함할 수 있 다. 프로세서는 제1 프로세서 및 제2 프로세서를 포함할 수 있다. 통신 모듈은 각각의 센서 모듈로부터 센서의 검출 신호를 수신할 수 있다. 또한, 통신 모듈 은 각각의 제1 카메라 모듈로부터 번호판 영상을 수신할 수 있다. 통신 모듈은 검출 신호 및 번호판 영상을 프로세서 또는 메모리로 전달한다. 프로세서는 통신 모듈 또는 메모리로부터 검출 신호 및 번호판 영상을 획득한다. 프로세서(31 0)는 제1 프로세서에서 차량의 인식 및 처리를 수행하고, 제2 프로세서에서 번호판 인식 처리를 수행 할 수 있다. 제1 프로세서 및 제2 프로세서는 물리적으로 분리된 서로 다른 프로세서에 대응할 수 있 다. 제1 프로세서 및 제2 프로세서는GPU(Graphic Processing Unit) 또는 NPU(Neural Processing Unit)에 대응할 수 있다. 제1 프로세서와 제2 프로세서는 서로 병렬적으로 처리를 수행할 수 있다. 제1 프로세서는 센서 모듈의 검출 신호를 이용하여 차량의 인식 및 추적 처리를 수행한다. 제1 프로 세서는 검출 신호로부터 차량에 대응하는 형상을 인식한다. 또한, 제1 프로세서는 인식된 차량을 추 적한다. 제1 프로세서는 객체 인식 알고리즘, 인공지능 모델 등을 이용하여 차량의 인식과 추적 처리를 수 행할 수 있다. 제1 프로세서는 레이더 검출 신호에 대한 차량 인식 및 추적 처리를 수행할 수 있다. 또한, 제1 프로세서는 라이다 검출 신호에 대한 차량 인식 및 추적 처리를 수행할 수 있다. 제1 프로세서는 각각의 센서 모듈의 검출 신호로부터 서브 궤적 정보를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 차량 추적 시스템은 제2 카메라 모듈(미도시)을 더 포함할 수 있다. 제2 카 메라 모듈은 제2 카메라를 포함하고, 제2 카메라의 촬영 영상을 생성하여 차량 추적 장치로 전 송할 수 있다. 제1 프로세서는 제2 카메라에 의해 생성된 촬영 영상으로부터 차량을 인식하고 추적할 수 있다. 제1 프로세서는 각각의 제2 카메라 모듈의 촬영 영상으로부터 서브 궤적 정보를 생성할 수 있다. 제1 프로세서는 서브 궤적 정보를 연결하여 전체 궤적 정보를 생성한다. 제1 프로세서는 메모리(31 4)에 저장된 센서 모듈의 배치 정보 및 서브 궤적 정보의 시간 정보에 기초하여, 서브 궤적 정보를 서로 매칭시켜 연결할 수 있다. 서브 궤적 정보는 차량의 시간에 따른 위치를 나타내는 포인트의 세트일 수 있다. 서 브 궤적 정보의 시간 정보는 서브 궤적 정보에서 궤적을 나타내는 각 포인트에 대응하는 시간을 나타낼 수 있다. 전체 궤적 정보는 차량의 시간에 따른 위치를 나타내는 포인트의 세트일 수 있다. 제2 프로세서는 번호판 영상으로부터 번호판 정보를 인식한다. 제2 프로세서는 객체 인식 알고리즘, 텍스트 인식 알고리즘, 또는 인공지능 모델을 이용하여 번호판 영상으로부터 번호판 정보를 인식할 수 있다. 제 2 프로세서는 인식된 번호판의 번호 정보, 위치, 시간, 또는 차선 정보 등을 생성할 수 있다. 프로세서는 제1 프로세서에 의해 생성된 전체 궤적 정보와 제2 프로세서에 의해 생성된 번호판 정보를 매칭한다. 프로세서는 차량 각각에 대해 전체 궤적 정보를 생성할 수 있다. 프로세서는 각각 의 차량에 대한 전체 궤적 정보와 번호판 정보를 매칭시킬 수 있다. 프로세서는 전체 궤적 정보와 대응하는 번호판 정보를 출력 인터페이스로 전달한다. 프로세서는 전체 궤적 정보와 대응하는 번호판 정보를 영상 데이터, 데이터 세트 등의 형태로 출력할 수 있다. 출력 인터페이스는 전체 궤적 정보와 번호판 정보를 출력한다. 출력 인터페이스는 영상 데이터 형태 의 전체 궤적 정보 및 번호판 정보를 디스플레이하거나 외부 장치로 전송할 수 있다. 또한, 출력 인터페이스 는 전체 궤적 정보 및 번호판 정보를 포함하는 데이터 세트를 디스플레이하거나 외부 장치로 전송할 수 있 다. 출력 인터페이스는 디스플레이, 스피커, 또는 통신 모듈 등에 대응할 수 있다. 도 7은 본 개시의 일 실시예에 따른 차량 추적 시스템을 나타낸 도면이다. 본 개시의 일 실시예에 따르면, 차량 추적 시스템은 차량 추적 장치, 적어도 하나의 센서 모듈, 적어도 하나의 제1 카메라 모듈, 및 적어도 하나의 제3 카메라 모듈을 포함할 수 있다. 센서 모듈은 레이더 센서 또는 라이다 센서에 대응하는 센서를 포함한다. 또한, 센서 모듈은 프 로세서를 포함할 수 있다. 프로세서는 코덱(codec)을 포함하고, 센서의 검출 신호를 소정의 규 격으로 인코딩한다. 센서 모듈은 인코딩된 검출 신호를 차량 추적 장치로 전송한다. 제1 카메라 모듈은 제1 카메라 및 프로세서를 포함할 수 있다. 프로세서는 코덱을 포함하 고, 제1 카메라의 번호판 영상을 소정의 규격으로 인코딩한다. 제1 카메라 모듈은 인코딩된 번호판 영상을 차량 추적 장치로 전송한다. 제3 카메라 모듈은 제3 카메라 및 프로세서를 포함한다. 제3 카메라는 도로 상의 차량을 촬영하도록 배치된다. 제3 카메라는 도로 상의 차량을 사선 뷰, 또는 탑(top) 뷰로 촬영할 수 있다. 본 개 시의 일 실시예에 따르면, 교통 정보 수집용 CCTV에 대응될 수 있다. 프로세서는 코덱을 포함하고, 제3 카메라의 촬영 영상을 소정의 규격으로 인코딩한다. 제3 카메라 모 듈은 인코딩된 촬영 영상을 차량 추적 장치로 전송한다. 차량 추적 장치는 센서 모듈로부터 수신한 검출 신호를 이용하여, 제1 객체 인식 및 추적부에서 차량을 인식하고 추적한다. 제1 객체 인식 및 추적부는 인코딩된 검출 신호를 디코딩한다. 또한, 제1 객체 인식 및 추적부는 디코딩된 검출 신호로부터 차량을 인식하고 추적하여, 서브 궤적 정보를 생성한다. 제1 객체 인식 및 추적부는 복수의 센서 모듈로부터 수신된 검출 신호를 이용하여 복수의 서브 궤적 정보 를 생성한다. 제1 객체 인식 및 추적부는 복수의 서브 궤적 정보를 연결하여 각각의 차량에 대한 전체 궤 적 정보를 생성한다. 차량 추적 장치는 제1 객체 인식 및 추적부, 번호판 인식 및 차선 검출부, 제2 객체 인식 및 추 적부, 및 제3 객체 인식 및 추적부를 포함할 수 있다. 제1 객체 인식 및 추적부, 번호판 인식 및 차선 검출부, 제2 객체 인식 및 추적부, 및 제3 객체 인식 및 추적부는 인스트럭션에 의해 동작하는 소프트웨어 모듈에 대응할 수 있다. 본 개시의 일 실시예에 따르면, 제1 객체 인식 및 추적부, 번호판 인식 및 차선 검출부, 제2 객체 인식 및 추적부, 및 제3 객체 인식 및 추적부 중 일부 또는 전부는 별개의 하드웨어 블록으로 구현될 수 있다. 본 개시의 일 실시예에 따르면, 제1 객체 인식 및 추적부는 각각의 차량에 대해, 속도를 인식한다. 제1 객 체 인식 및 추적부는 각각의 차량에 대해 시간에 따른 위치 정보를 획득한다. 제1 객체 인식 및 추적부 는 각각의 차량에 대해, 시간에 따른 위치 정보를 이용하여 속도 정보를 산출할 수 있다. 제1 객체 인식 및 추적부는 전체 궤적 정보 및 속도 정보를 제2 객체 인식 및 추적부로 출력한다. 번호판 인식 및 차선 검출부는 제1 카메라 모듈로부터 수신한 번호판 영상을 디코딩한다. 또한, 번호 판 인식 및 차선 검출부는 디코딩된 번호판 영상을 이용하여 번호판을 인식하고 차선을 검출한다. 번호판 인식 및 차선 검출부는 번호판 영상으로부터 번호판에 기재된 번호인 번호판 정보를 생성한다. 번호판 인 식 및 차선 검출부는 객체 인식 알고리즘, 텍스트 인식 알고리즘, 또는 인공지능 모델 등을 이용하여 번호 판 영상으로부터 번호판 정보를 인식할 수 있다. 번호판 인식 및 차선 검출부는 번호판이 인식된 시간 정보와 위치 정보를 함께 획득할 수 있다. 또한, 번 호판 인식 및 차선 검출부는 번호판이 인식된 차선 정보를 획득할 수 있다. 번호판 인식 및 차선 검출부 는 각각의 차선 영역에 대한 위치 정보를 미리 저장하고, 번호판이 인식된 위치 정보에 기초하여 번호판의 차선 정보를 획득할 수 있다. 본 개시의 일 실시예에 따르면, 번호판 인식 및 차선 검출부는 각각의 차선의 기준 선 또는 기준 위치에서 검출 시간 정보 및 번호판 정보를 획득할 수 있다. 번호판 인식 및 차선 검출부는 예를 들면, 제1 카메라 로부터 3미터 전방의 기준 선을 통과하는 차량의 번호판을 인식하여, 검출 시간 정보 및 번호판 정보를 획 득할 수 있다. 번호판 인식 및 차선 검출부는 인식된 번호판 정보, 시간 정보, 및 위치 정보(또는 차선 정보)를 메타데이 터로서 제2 객체 인식 및 추적부로 출력한다. 제2 객체 인식 및 추적부는 제1 객체 인식 및 추적부로부터 입력된 전체 궤적 정보와 속도 정보, 및 번호판 인식 및 차선 검출부로부터 입력된 메타 데이터를 이용하여, 각각의 차량에 매칭된 전체 궤적 정보, 속도 정보, 및 번호판 정보를 포함하는 교통 데이터 세트를 생성한다. 제2 객체 인식 및 추적부는 전체 궤적 정보의 각각의 지점의 시간 정보와, 번호판 정보에 대응하는 시간 정보를 이용하여 전체 궤적 정보와 번호판 정보를 매칭시킨다. 예를 들면, 제2 객체 인식 및 추적부는 소정의 번호판 정보의 기준선 통과 시간 및 차선 정보를 이용하여, 해당 시간에 해당 차선을 통과한 차량을 전체 궤적 정보를 참조하여 검출한다. 제2 객체 인식 및 추적부는 각각의 차량에 대한 교통 데이터 세트를 제3 객체 인식 및 추적부로 출력 한다. 제3 객체 인식 및 추적부는 제3 카메라 모듈로부터 수신한 촬영 영상을 디코딩한다. 제3 객체 인식 및 추적부는 촬영 영상으로부터 차량을 인식한다. 제3 객체 인식 및 추적부는 인식된 차량의 검출 시 간 및 위치를 인식한다. 제3 객체 인식 및 추적부는 인식된 차량의 검출 시간 및 위치에 대응하는 전체 궤 적 정보를 갖는 교통 데이터 세트를 촬영 영상에서 인식된 차량에 매칭시킨다. 제3 객체 인식 및 추적부는 촬영 영상에서 인식된 각각의 차량에 교통 데이터 세트의 정보를 합성한 합성 영상을 생성한다. 예를 들면, 제3 객체 인식 및 추적부는 촬영 영상에서 인식된 각각의 차량 영역의 주변에, 번호판 정보 및 속도 정보를 오 버레이하여 합성 영상을 생성한다. 번호판 정보 및 속도 정보는 해당 차량이 이동함에 따라, 합성 영상에서 해 당 차량을 트래킹하면서 이동한다. 제3 객체 인식 및 추적부는 합성 영상을 생성하여 외부 장치로 출력한다. 제3 객체 인식 및 추적부는 통신 모듈 또는 출력 인터페이스를 통해 합성 영상을 외부 장치로 출력할 수 있다. 예를 들면, 제3 객체 인식 및 추적부는 교통 정보를 모니터링하는 관제실의 소정의 장치 또는 서버로 합성 영상을 출 력할 수 있다. 도 8은 본 개시의 일 실시예에 따라 센서, 제1 카메라, 및 제3 카메라의 데이터로부터 교통 정보를 생성하는 과 정을 나타낸 도면이다. 본 개시의 일 실시예에 따르면, 차량 추적 장치는 단계 802에서 센서의 검출 신호로부터 차량의 식별 정보 및 속도 정보를 획득할 수 있다. 식별 정보는 인식된 차량에 대한 식별 정보를 의미한다. 식별 정보는 제1 객체 인식 및 추적부에 의해 임의로 정의될 수 있다. 전체 궤적 정보 및 속도 정보는 차량의 식별 정보에 매칭될 수 있다. 또한, 본 개시의 일 실시예에 따르면, 차량 추적 장치는 단계 804에서 제1 카메라의 번호판 영상으로 부터 차량의 번호판 정보 및 차선 정보를 획득할 수 있다. 차량 추적 장치는 번호판 영상으로부터 번호판 정보에 대응하는 검출 시간 정보 및 차선 정보를 획득할 수 있다. 또한, 본 개시의 일 실시예에 따르면, 차량 추적 장치는 단계 806에서 제3 카메라의 촬영 영상에 차 량 별 속도 정보 및 번호판 정보를 합성하여 시현한다. 차량 추적 장치는 촬영 영상에서 차량을 인식한다. 또한, 차량 추적 장치는 촬영 영상에서 인식된 차량에 센서 모듈의 데이터로부터 획득된 전체 궤적 정보, 속도 정보를 매칭시킨다. 또한, 차량 추적 장치는 촬영 영상에서 인식된 차량에 제1 카메라의 데이터로부터 획득된 차량의 번호판 정보 및 차선 정보를 매칭시킨다. 차량 추적 장치는 촬영 영상에 전체 궤적 정보, 속도 정보, 및 번호판 정보를 합성한 합성 영상을 생성한다. 또한, 본 개시의 일 실시예에 따르면, 제3 카메라는 탑 뷰 영상을 촬영한다. 탑 뷰 영상은 도로의 상공에 서 도로를 촬영한 영상이다. 차량 추적 장치는 제3 카메라의 탑 뷰 영상으로부터 차량을 인식한다. 또한, 차량 추적 장치는 탑 뷰 영상에서 인식된 차량에 센서 모듈의 데이터로부터 획득된 전체 궤적 정보, 속도 정보를 매칭시킨다. 또한, 차량 추적 장치는 탑 뷰 영상에서 인식된 차량에 제1 카메라의 데이터로부터 획득된 차량의 번호판 정보 및 차선 정보를 매칭시킨다. 차량 추적 장치는 탑 뷰 영상에 전 체 궤적 정보, 속도 정보, 및 번호판 정보를 합성한 합성 영상을 생성한다. 차량 추적 장치는 촬영 영상 또는 탑 뷰 영상으로부터 생성된 합성 영상을 이용하여, 단계 810에서 이벤트 를 검출한다. 이벤트는 예를 들면, 과속 이벤트, 교통 사고 이벤트, 또는 금지 차량 검출 이벤트 등을 포함할 수 있다. 차량 추적 장치는 속도가 제한 속도를 초과한 차량을 검출하여 과속 이벤트를 검출할 수 있다. 또한, 차량 추적 장치는 전체 궤적 정보가 서로 접촉 또는 교차하는 이벤트를 검출하여, 교통 사고 이벤트 를 검출할 수 있다. 본 개시의 일 실시예에 따르면, 차량 추적 장치는 촬영 영상 또는 탑 뷰 영상으로부터 진입 금지 차량을 검출할 수 있다. 본 개시의 일 실시예에 따르면, 차량 추적 장치는 차량의 번호판 정보를 이용하여, 해당 번호판 정보에 대응하는 차량이 진입 금지 차량인지 여부를 검색할 수 있다. 차량 추적 장치는 소정의 교통 데이터베이스를 이용하여, 검출되 차량이 진입 금지 차량인지 여부를 검색할 수 있다. 차량 추적 장치는 해당 차량이 진입 금지 차량인 경우, 해당 도로에서 나가도록 유도할 수 있다. 예를 들면, 차량 추적 장치는 스피커 등을 이용하여 진입 금지 차량이 터널을 나가도록 음성 가이드를 출력할 수 있다. 차량 추적 장치는 이벤트를 검출한 경우, 단계 812에서 이벤트 정보 및 이벤트 정보에 관련된 관심 차량 정보를 생성한다. 이벤트 정보는 이벤트의 종류, 발생 시간, 부가 정보 등을 포함할 수 있다. 부가 정보는 속도 정보, 차량 궤적 정보 등을 포함할 수 있다. 관심 차량 정보는 번호판 정보를 포함할 수 있다. 또한, 차량 추적 장치는 이벤트 정보 및 관심 차량 정보를 외부 장치 또는 기관으로 보고한다. 예를 들면, 차량 추적 장치 는 이벤트 정보 및 관심 차량 정보를 경찰청 서버, 교통 관제 센터 서버 등으로 보고할 수 있다. 도 9는 본 개시의 일 실시예에 따라 번호판 정보 및 차선 정보를 인식한 예시를 나타낸 도면이다. 본 개시의 일 실시예에 따르면, 제1 카메라의 번호판 영상으로부터 도 9에 도시된 바와 같이 번호판 정보와 차선 정보가 획득될 수 있다. 차량 추적 장치는 번호판 영상으로부터 메타 데이터(920a, 920b)를 생성한다. 메타 데이터(920a, 920b)는 번호판 정보 및 차선 정보를 포함한다. 메타 데이터 920a는 차선 정보에 대응하는 값으로 '1번 레인'을 포함하고, 번호판 정보에 대응하는 값으로 '12호9876'을 포함할 수 있다. 메타 데이터 920b는 차선 정보에 대응하는 값으로 '2번 레인'을 포함하고, 번호판 정보에 대응하는 값으로 '10호 1234'을 포함할 수 있다. 차량 추적 장치는 번호판 영상으로부터 차량의 번호판 영역(910a, 910b)을 인식한다. 차량 추적 장치는 번호판 영역(910a, 910b)으로부터 번호판 정보를 인식할 수 있다. 또한, 차량 추적 장치는 번 호판 영역(910a, 910b)의 위치로부터 차선 정보를 인식할 수 있다. 도 10은 본 개시의 일 실시예에 따른 차량 및 속도 인식의 나타낸 도면이다. 본 개시의 일 실시예에 따르면, 차량 추적 장치는 센서로부터 생성된 검출 신호로부터 차량을 인식하고 속도 정보를 획득할 수 있다. 차량 추적 장치는 센서의 검출 신호로부터 차량을 인식하고 식별 정보를 생성할 수 있다. 또한, 차량 추적 장치는 센서의 검출 신호로부터 궤적 정보를 생성하고, 궤적 정보에 기초하여 속도 정보를 획득할 수 있다. 차량 추적 장치는 검출 신호로부터 각 차량에 대한 데이터 세트(1010a, 1010b, 1010c, 1010d, 1010e)를 생성할 수 있다. 데이터 세트(1010a, 1010b, 1010c, 1010d, 1010e)는 식별 정보 및 속도 정보를 포함할 수 있 다. 데이터 세트 1010a는 식별 정보의 값으로 ID 101을 갖고, 속도 정보의 값으로 40km/h를 가질 수 있다. 데이 터 세트 1010b는 식별 정보의 값으로 ID 102를 갖고, 속도 정보의 값으로 50km/h를 가질 수 있다. 데이터 세트 1010c, 1010d, 1010e도 유사하게 식별 정보와 속도 정보의 값을 포함할 수 있다. 본 개시의 일 실시예에 따르면, 차량 추적 장치는 데이터 세트(1010a, 1010b, 1010c, 1010d, 1010e)와 번 호판 정보를 매칭시켜 교통 데이터 세트를 생성할 수 있다. 차량 추적 장치는 각각의 차량의 데이터 세트(1010a, 1010b, 1010c, 1010d, 1010e)와 번호판 정보를 매칭시켜, 교통 데이터 세트를 생성 할 수 있다. 예를 들면, 교통 데이터 세트는 번호판 정보의 값으로 12호9876을 갖고, 속도 정보의 값으로 49km/h를 가질 수 있다. 본 개시의 일 실시예에 따르면, 센서 모듈, 제1 카메라 모듈, 및 제3 카메라 모듈이 도 10에 도 시된 바와 같이 터널의 입구에 배치될 수 있다. 센서 모듈은 소정의 간격으로 터널에 배치될 수 있다. 센서 모듈이 레이더 센서를 포함하는 경우 제1 간격(예: 2km)으로 배치되고, 센서 모듈이 라이 다 센서를 포함하는 경우 제2 간격(예: 200m)으로 배치될 수 있다. 제3 카메라 모듈은 터널 내에 소 정의 간격으로 배치될 수 있다. 도 11은 본 개시의 일 실시예에 따라, 탑 뷰 영상을 이용하여 생성된 합성 영상을 나타낸 도면이다. 본 개시의 일 실시예에 따르면, 차량 추적 장치는 도로를 상공에서 촬영한 탑 뷰 영상을 이용한 합성 영상을 생성할 수 있다. 합성 영상은 인식된 차량에 대응하는 교통 데이터 세트(1110a, 1110b, 1110c)를 포함할 수 있다. 교통 데이터 세트(1110a, 1110b, 1110c)는 대응하는 차량 주변에 배치될 수 있다. 교통 데이터 세트(1110a, 1110b, 1110c)는 식별 정보, 번호판 정보, 및 속도 정보를 포함할 수 있다. 예 를 들면, 교통 데이터 세트 1110a은 식별 정보의 값으로 ID 103을 갖고, 번호판 정보의 값으로 10나2020을 갖고, 속도 정보의 값으로 55km/h를 가질 수 있다. 또한, 예를 들면, 교통 데이터 세트 1110b는 식별 정보의 값 으로 ID 104를 갖고, 번호판 정보의 값으로 10호1234를 갖고, 속도 정보의 값으로 52km/h를 가질 수 있다. 합성 영상은 각 차량의 차선 정보를 나타낼 수 있다. 합성 영상은 차선을 도시하여, 차량 이 어느 차선에 배치되어 있는지 식별 가능하도록 할 수 있다. 차량 추적 장치는 합성 영상에 이벤트 정보를 표시할 수 있다. 예를 들면, 차량 추적 장치는 합성 영 상에 과속 이벤트가 발생한 차량 주변에 과속 이벤트를 나타내는 과속 인디케이터를 배치하여 이벤트 정 보를 표시할 수 있다. 한편, 개시된 실시 예들은 컴퓨터에 의해 실행 가능한 명령어 및 데이터를 저장하는 컴퓨터로 읽을 수 있는 기 록매체의 형태로 구현될 수 있다. 상기 명령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 소정의 프로그램 모듈을 생성하여 소정의 동작을 수행할 수 있다. 또한, 상기 명령어는 프로세 서에 의해 실행되었을 때, 개시된 실시예들의 소정의 동작들을 수행할 수 있다."}
{"patent_id": "10-2023-0138870", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시 예들을 설명하였다. 본 발명이 속하는 기술분야에서 통상 의 지식을 가진 자는 본 발명의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시 예들과 다른 형태로 본 발명이 실시될 수 있음을 이해할 것이다. 개시된 실시 예들은 예시적인 것이며, 한정적으로 해석되어 서는 안 된다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2023-0138870", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 일 실시예는, 다음의 자세한 설명과 그에 수반되는 도면들의 결합으로 쉽게 이해될 수 있으며, 참조 번호(reference numerals)들은 구조적 구성요소 (structural elements)를 의미한다. 도 1은 본 개시의 일 실시예에 따른 차량 추적 시스템을 나타낸 도면이다. 도 2는 본 개시의 일 실시예에 따라 차량을 인식하는 과정을 나타낸 도면이다. 도 3은 본 개시의 일 실시예에 따른 차량 추적 장치의 구조를 나타낸 도면이다. 도 4는 본 개시의 일 실시예에 따른 차량 추적 방법을 나타낸 흐름도이다. 도 5는 본 개시의 일 실시예에 따라 레이더 검출 구간 및 라이다 검출 구간의 서브 궤적 정보를 이용하여 전체 궤적 정보를 생성하는 과정을 나타낸 도면이다. 도 6은 본 개시의 일 실시예에 따른 차량 추적 장치, 센서 모듈, 및 제1 카메라 모듈의 구조를 나타낸 도면이다. 도 7은 본 개시의 일 실시예에 따른 차량 추적 시스템을 나타낸 도면이다. 도 8은 본 개시의 일 실시예에 따라 센서, 제1 카메라, 및 제3 카메라의 데이터로부터 교통 정보를 생성하는 과 정을 나타낸 도면이다. 도 9는 본 개시의 일 실시예에 따라 번호판 정보 및 차선 정보를 인식한 예시를 나타낸 도면이다. 도 10은 본 개시의 일 실시예에 따른 차량 및 속도 인식의 나타낸 도면이다. 도 11은 본 개시의 일 실시예에 따라, 탑 뷰 영상을 이용하여 생성된 합성 영상을 나타낸 도면이다."}
