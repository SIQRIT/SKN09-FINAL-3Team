{"patent_id": "10-2025-7002758", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0043417", "출원번호": "10-2025-7002758", "발명의 명칭": "인공지능 기반 인루프 필터들을 위한 콘텐츠 기반 스케일링을 위한 방법 및 시스템", "출원인": "삼성전자주식회사", "발명자": "아그라왈 아비랄"}}
{"patent_id": "10-2025-7002758", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "미디어의 인공지능(Artificial Intelligence, AI) 기반 인코딩을 위해 전자 기기에 의해 수행되는 방법(1400)에있어서,입력 비디오와 연관된 입력 이미지 프레임을 압축하는 단계(1410);AI 기반 인루프 필터(302e)를 사용하여 상기 입력 이미지 프레임에 대응하는 재구성된 이미지 프레임을 생성하는 단계(1420);상기 입력 이미지 프레임 및 상기 재구성된 이미지 프레임에 기반하여 오프셋 값을 결정하는 단계(1430); 및상기 결정된 오프셋 값에 기반하여 상기 재구성된 이미지 프레임을 인코딩하는 단계(1440)를 포함하는, 방법(1400)."}
{"patent_id": "10-2025-7002758", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 입력 이미지 프레임 및 상기 재구성된 이미지 프레임에 기반하여 상기 오프셋 값을 결정하는 단계(1430)는,상기 재구성된 이미지 프레임에 대한 모델 출력 데이터 분포를 생성하는 단계;상기 입력 이미지 프레임에 대한 정답값 데이터 분포를 생성하는 단계; 및상기 모델 출력 데이터 분포와 상기 정답값 데이터 분포를 비교함으로써 상기 오프셋 값을 결정하는 단계를 포함하는, 방법(1400)."}
{"patent_id": "10-2025-7002758", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 재구성된 이미지 프레임에 대한 상기 모델 출력 데이터 분포를 생성하는 단계는,사용자 입력에 기초하여 상기 재구성된 이미지 프레임에 대한 단편 수를 식별하는 단계;상기 재구성된 이미지 프레임 내의 콘텐츠 변화를, 하나 이상의 분포 메커니즘을 사용하여, 분석하는 단계;최적의 단편화된 이미지 프레임을 생성하기 위해 상기 결정된 단편 수 및 상기 분석된 콘텐츠 변화에 기반하여상기 재구성된 이미지 프레임을 단편화하는 단계;상기 최적의 단편화된 이미지 프레임 ― 상기 최적의 단편화된 이미지 프레임은 고유 특성을 갖는 화소들의 그룹을 포함함 ― 의 하나 이상의 단편에 대해, 하나 이상의 통계적 메커니즘을 사용하여, 화소 비닝 동작을 수행하는 단계; 및상기 화소 비닝 동작에 기초하여 상기 최적의 단편화된 이미지 프레임에 대한 제1 대표 데이터 포인트 세트를생성하는 단계를 포함하는, 방법(1400)."}
{"patent_id": "10-2025-7002758", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항 또는 제3항에 있어서, 상기 입력 이미지 프레임에 대한 상기 정답값 데이터 분포를 생성하는 단계는,사용자 입력에 기반하여 상기 입력 이미지 프레임에 대한 단편 수를 식별하는 단계;상기 입력 이미지 프레임 내의 콘텐츠 변화를, 하나 이상의 분포 메커니즘을 사용하여, 분석하는 단계;공개특허 10-2025-0043417-3-최적의 단편화된 입력 이미지 프레임을 생성하기 위해 상기 결정된 단편 수 및 상기 분석된 콘텐츠 변화에 기반하여 상기 입력 이미지 프레임을 단편화하는 단계;상기 최적의 단편화된 입력 이미지 프레임 ― 상기 최적의 단편화된 입력 이미지 프레임은 고유 특성을 갖는 화소들의 그룹을 포함함 ― 의 하나 이상의 단편에 대해, 하나 이상의 통계적 메커니즘을 사용하여, 화소 비닝 동작을 수행하는 단계; 및상기 화소 비닝 동작에 기반하여 상기 최적의 단편화된 입력 이미지 프레임에 대한 제2 대표 데이터 포인트 세트를 생성하는 단계를 포함하는, 방법(1400)."}
{"patent_id": "10-2025-7002758", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항 내지 제4항 중 어느 한 항에 있어서, 상기 모델 출력 데이터 분포와 상기 정답값 데이터 분포를 비교함으로써 상기 오프셋 값을 결정하는 단계는,상기 재구성된 이미지 프레임으로부터의 단편화된 이미지 프레임에 대한 제1 대표 데이터 포인트 세트와 상기입력 이미지 프레임으로부터의 단편화된 입력 이미지 프레임에 대한 제2 대표 데이터 포인트 세트 사이의 데이터 분포 비유사성 메트릭을 결정하는 단계; 및상기 데이터 분포 비유사성 메트릭에 기반하여 상기 오프셋 값을 결정하는 단계를 포함하는, 방법(1400)."}
{"patent_id": "10-2025-7002758", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항 내지 제5항 중 어느 한 항에 있어서, 상기 모델 출력 데이터 분포와 상기 정답값 데이터 분포를 비교함으로써 상기 오프셋 값을 결정하는 단계는,상기 모델 출력 데이터 분포, 상기 정답값 데이터 분포, 및 매핑 범위를 사용하여 단편별 오프셋의 형태로 화소매핑을 결정하는 단계를 포함하는, 방법(1400)."}
{"patent_id": "10-2025-7002758", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 매핑 범위는 RD 비용을 기반으로 특정 단편에 대해 상기 오프셋 스케일링을 적용할 지의결정이고, 상기 매핑 범위는 단편 수 및 코덱 RD 비용에 기반하여 결정되는, 방법(1400)."}
{"patent_id": "10-2025-7002758", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서, 상기 재구성된 이미지 프레임의 상기 인코딩(1440)은,스케일링된 이미지 프레임을 생성하기 위해 상기 결정된 오프셋 값에 기반하여 상기 재구성된 이미지 프레임에대한 스케일링 동작 ― 상기 스케일링 동작은 덧셈 연산, 곱셈 연산, 나눗셈 연산, 또는 지수 연산 중 적어도하나를 포함함 ― 을 수행하는 단계; 및상기 스케일링된 이미지 프레임을 인코딩하는 단계를 포함하는, 방법(1400)."}
{"patent_id": "10-2025-7002758", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서, 상기 재구성된 이미지 프레임은 상기 AI 기반 인루프 필터의 하나이상의 신경망(Neural Network, NN) 모델을 이용함으로써 생성되는, 방법(1400)."}
{"patent_id": "10-2025-7002758", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2025-0043417-4-제1항 내지 제9항 중 어느 한 항에 있어서,상기 재구성된 이미지 프레임과 연관된 비트스트림 정보 ― 상기 비트스트림 정보는 상기 결정된 오프셋 값을포함함 ― 를 디코더에 전송하는 단계를 포함하는, 방법(1400)."}
{"patent_id": "10-2025-7002758", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제10항 중 어느 한 항에 있어서, 상기 오프셋 값은 단편별 세분도로 계산되고 사용되는, 방법(1400)."}
{"patent_id": "10-2025-7002758", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "미디어의 인공지능(Artificial Intelligence, AI) 기반 디코딩을 위해 전자 기기에 의해 수행되는 방법(1600)에있어서,인코더로부터 오프셋 정보를 포함하는 비트스트림 정보를 수신하는 단계(1610);AI 기반 인루프 필터를 사용하여 상기 비트스트림 정보에 기반하여 재구성된 이미지 프레임을 생성하는 단계(1620);스케일링된 이미지 프레임을 생성하기 위해 상기 오프셋 정보에 기반하여 상기 재구성된 이미지 프레임에 대한스케일링 동작을 수행하는 단계(1630); 및상기 스케일링된 이미지 프레임에 기반하여 출력 비디오를 생성하는 단계(1640)를 포함하는, 방법(1600)."}
{"patent_id": "10-2025-7002758", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 재구성된 이미지 프레임에 대해 상기 스케일링 동작을 수행하는 단계(1630)는,상기 재구성된 이미지 프레임에 대한 모델 출력 데이터 분포를 생성하는 단계;상기 오프셋 정보 및 상기 모델 출력 데이터 분포에 기반하여 상기 스케일링 동작을 위한 화소 매핑을 수행하는단계; 및상기 스케일링된 이미지 프레임을 생성하기 위해 상기 화소 매핑에 기반하여 상기 재구성된 이미지 프레임에 대한 상기 스케일링 동작을 수행하는 단계를 포함하는, 방법(1600)."}
{"patent_id": "10-2025-7002758", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항 또는 제13항에 있어서, 상기 스케일링 동작은 덧셈 연산, 곱셈 연산, 나눗셈 연산, 또는 지수 연산 중적어도 하나를 포함하는, 방법(1600)."}
{"patent_id": "10-2025-7002758", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "미디어의 인공지능(Artificial Intelligence, AI) 기반 인코딩을 위한 시스템(101)에 있어서,메모리(110) 및 통신부(130)에 동작적으로 연결되는 프로세서(120)를 포함하며,상기 프로세서(120)는,입력 비디오와 연관된 입력 이미지 프레임을 압축하며;AI 기반 인루프 필터를 사용하여 상기 입력 이미지 프레임에 대응하는 재구성된 이미지 프레임을 생성하며;상기 입력 이미지 프레임 및 상기 재구성된 이미지 프레임에 기반하여 오프셋 값을 결정하며; 및공개특허 10-2025-0043417-5-상기 결정된 오프셋 값에 기반하여 상기 재구성된 이미지 프레임을 인코딩하도록구성되는, 시스템(101)."}
{"patent_id": "10-2025-7002758", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "미디어의 인공지능(AI) 기반 인코딩을 위한 방법이, 입력 비디오와 연관된 입력 이미지 프레임을 압축하는 단계, AI 기반 인루프 필터를 사용하여 입력 이미지 프레임에 대응하는 재구성된 이미지 프레임을 생성하는 단계, 입력 이미지 프레임 및 재구성된 이미지 프레임에 기반하여 오프셋 값을 결정하는 단계, 및 결정된 오프셋 값에 기반 하여 재구성된 이미지 프레임을 인코딩하는 단계를 포함한다."}
{"patent_id": "10-2025-7002758", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 대체로 이미지 프로세싱에 관한 것이고, 더 구체적으로는 인공지능(Artificial intelligence, AI) 기 반 인루프 필터들을 위한 콘텐츠 기반 스케일링을 위한 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2025-7002758", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "비디오 압축 기법은 소비를 위한 비디오 콘텐츠의 기초이다. 비디오 압축 기법의 기본 목표는 전송 시간 및 대 역폭 요건들을 줄이는 것이다. 인공지능(AI) 기술의 도래로, 비디오 코덱 표준 기관들은 비디오 압축 기법에서 AI 기술의 잠재적 이점을 얻을 수 있기를 기대하고 있다. 그러나, AI 기반 모델(예컨대, 심층 신경망들(deep neural networks), 선형 회귀 등)을 구현하는 데에는 다른 장애물들이 있다. 비디오 압축 기법은 매우 다양한 콘텐츠의 압축을 위한 비디오 코덱 파이프라인을 포함하며, 더 높은 해상도들 을 갖는 콘텐츠, 상이한 스크린 콘텐츠들 등과 같이 더 새로운 콘텐츠가 항상 개발되고 있다. AI 기반 코딩 도 구들이 비디오 코덱 파이프라인에 도입되는 경우, AI 기반 모델은 먼저 훈련된 다음 비디오 코덱 파이프라인에 서 전개되어야 한다. 그러나, AI 기반 모델은 특정한 시점에 수집된 제한된 훈련 데이터 세트에 대해서만 훈련 되어, 내재적인 바이어스 및 분산을 AI 기반 모델들에 도입할 수 있고 잠재적으로는 예상치 못한 성능과 신뢰할 수 없는 답변들로 이어질 수 있다."}
{"patent_id": "10-2025-7002758", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이 개요는 본 발명의 상세한 설명에서 추가로 설명되는 단순화된 포맷으로 개념들의 선택을 도입하기 위해 제공 된다. 이 개요는 본 발명의 핵심 또는 필수적인 발명적 개념들을 식별하도록 의도되지 않았고 본 발명의 범위를 결정하기 위해 의도되지도 않았다. 본 개시의 일 실시예에 따르면, 미디어의 인공지능(AI) 기반 인코딩을 위한 방법이 개시된다. 본 개시의 일 실 시예에서, 이 방법은 입력 비디오와 연관된 입력 이미지 프레임을 압축하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 이 방법은 AI 기반 인루프 필터를 사용하여 입력 이미지 프레임에 대응하는 재구성된 이미지 프 레임을 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 이 방법은 입력 이미지 프레임 및 재구성된 이미지 프레임에 기반하여 오프셋 값을 결정하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 이 방법은 결정된 오프셋 값에 기반하여 재구성된 이미지 프레임을 인코딩하는 단계를 포함할 수 있다. 본 개시의 실시예에 따르면, 미디어의 AI 기반 디코딩을 사용하는 방법이 개시된다. 본 개시의 일 실시예에서, 이 방법은 인코더로부터 오프셋 정보를 포함하는 비트스트림 정보를 수신하는 단계를 포함할 수 있다. 본 개시 의 일 실시예에서, 이 방법은 AI 기반 인루프 필터를 사용하여 비트스트림 정보에 기반하여 재구성된 이미지 프 레임을 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 이 방법은 스케일링된 이미지 프레임을 생 성하기 위해 오프셋 정보에 기반하여 재구성된 이미지 프레임에 대한 스케일링 동작을 수행하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 이 방법은 스케일링된 이미지 프레임에 기반하여 출력 비디오를 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따르면, 미디어의 AI 기반 인코딩을 위한 전자 기기가 개시된다. 전자 기기는 시스템을 포함하며, 이 시스템은 메모리 및 통신부가 결합된 프로세서를 포함한다. 본 개시의 일 실시예에서, 프로세서는 입력 비디오와 연관된 입력 이미지 프레임을 압축하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 AI 기반 인루프 필터를 사용하여 입력 이미지 프레임에 대응하는 재구성된 이미지 프레임을 생성하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 입력 이미지 프레임 및 재구성된 이미지 프레임에 기반하여 오 프셋 값을 결정하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 결정된 오프셋 값에 기반하여 재 구성된 이미지 프레임을 인코딩하도록 구성될 수 있다. 본 개시의 일 실시예에 따르면, 미디어의 AI 기반 디코딩을 위한 전자 기기가 개시된다. 전자 기기는 시스템을 포함하며, 이 시스템은 메모리 및 통신부가 결합된 프로세서를 포함한다. 본 개시의 일 실시예에서, 프로세서는 인코더로부터 오프셋 정보를 포함하는 비트스트림 정보를 수신하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 AI 기반 인루프 필터를 사용하여 비트스트림 정보에 기반하여 재구성된 이미지 프레임 을 생성하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 스케일링된 이미지 프레임을 생성하기 위 해 오프셋 정보에 기반하여 재구성된 이미지 프레임에 대한 스케일링 동작을 수행하도록 구성될 수 있다. 본 개 시의 일 실시예에서, 프로세서는 스케일링된 이미지 프레임에 기반하여 출력 비디오를 생성하도록 구성될 수 있 다. 본 발명의 장점들 및 특징들을 더 명확하게 하기 위해, 본 발명의 더 구체적인 설명이 첨부된 도면들에서 예시 되는 특정 실시예들을 참조하여 제공될 것이다. 이들 도면들은 본 발명의 전형적인 실시예들만을 묘사하고 그러 므로 본 발명의 범위의 제한으로서 간주되지 않아야 한다는 것이 이해된다. 본 발명은 첨부 도면들과 함께 추가 적인 구체성(specificity) 및 세부사항으로 기술되고 설명될 것이다."}
{"patent_id": "10-2025-7002758", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 원리들의 이해를 촉진할 목적으로, 도면들에서 예시된 실시예가 이제 언급될 것이고, 특정 언어표현 이 그 실시예를 설명하는 데 사용될 것이다. 그럼에도 불구하고 본 발명의 범위의 제한은 이에 의해 의도되지 않으며, 예시된 기기에서의 이러한 개조들 및 추가의 수정들과 본원에서 예시된 바와 같은 본 발명의 원리들의 이러한 추가의 적용들은 본 발명이 관련되는 통상의 기술자에게 일반적으로 일어날 바와 같이 생각 (contemplation)될 수 있는 것임이 이해될 것이다. 전술한 일반적인 설명과 다음의 상세한 설명은 본 발명을 설명하는 것이고 그것의 제한으로서 의도되지 않는다"}
{"patent_id": "10-2025-7002758", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 것이 본 기술분야의 통상의 기술자들에 의해 이해될 것이다. \"일 양태\", \"다른 양태\" 또는 유사한 언어표현에 대한 이 명세서의 전체에 걸친 언급은 실시예에 관련하여 설명 되는 특정 특징, 구조, 또는 특성이 본 발명의 적어도 하나의 실시예에 포함된다는 것을 의미한다. 따라서, 이 명세서의 전체에 걸친 문구인 \"일 실시예에서\", \"다른 실시예에서\" 및 유사한 언어표현의 출현들은 동일한 실시 예를 언급할 수 있지만, 반드시 그러한 것은 아니다. \"포함한다\", \"포함하는\", 또는 그것의 임의의 다른 변형들의 용어들은 비배타적인 포함을 커버하도록 의도되어 서, 단계들의 리스트를 포함하는 프로세스 또는 방법은 그들 단계들만을 포함하는 것이 아니라, 명시적으로 나 열되거나 또는 이러한 프로세스 또는 방법에 내재하는 다른 단계들을 포함할 수 있다. 마찬가지로,\"...을 포함 한다\"로 진행되는 하나 이상의 기기 또는 서브시스템 또는 요소 또는 구조 또는 구성요소는, 더 이상의 제약조 건들 없이, 다른 기기들 또는 다른 서브시스템들 또는 다른 요소들 또는 다른 구조들 또는 다른 구성요소들 또 는 추가적인 기기들 또는 추가적인 서브시스템들 또는 추가적인 요소들 또는 추가적인 구조들 또는 추가적인 구 성요소들의 존재를 배제하지 않는다. 본 개시의 전체에 걸쳐, \"a, b 또는 c 중 적어도 하나\"라는 표현은 a만, b만, c만, a 및 b 둘 다, a 및 c 둘 다, b 및 c 둘 다, a, b, 및 c의 모두, 또는 그 변형들을 나타낸다. 본 개시에서의 실시예들과 그것들의 다양한 특징들 및 유리한 세부사항들은 첨부 도면들에서 예시되고 다음의 설명에서 상세하게 되는 비제한적인 실시예들을 참조하여 더 충분히 설명된다. 널리 공지된 구성요소들 및 프로 세싱 기법들의 설명들은 본 개시의 실시예들을 불필요하게 모호하게 하지 않기 위해서 생략된다. 또한, 본 개시 에서 설명되는 다양한 실시예들은 반드시 상호 배타적인 것은 아닌데, 일부 실시예들이 새로운 실시예들을 형성 하기 위해 하나 이상의 다른 실시예와 조합될 수 있기 때문이다. 본 개시에서 사용되는 바와 같은 \"또는\"이란 용어는, 달리 지시되지 않는 한, 비배타적인 것을 의미한다. 본 개시에서 사용되는 예들은 단지 본 개시의 실시"}
{"patent_id": "10-2025-7002758", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "예들이 실시될 수 있는 방법들의 이해를 용이하게 하기 위해서 그리고 본 기술분야의 통상의 기술자들이 본 개 시의 실시예들을 실시하는 것을 추가로 가능하게 하기 위해서일 뿐이다. 따라서, 그 예들은 본 개시의 실시예들 의 범위를 제한하는 것으로 해석되지 않아야 한다. 해당 분야에서 통상적인 바와 같이, 실시예들은 설명된 기능 또는 기능들을 수행하는 블록들의 측면에서 설명되 고 예시될 수 있다. 유닛들 또는 모듈들 등으로서 본 개시에서 지칭될 수 있는 이들 블록들은 로직 게이트들, 집적 회로들, 마이크로프로세서들, 마이크로컨트롤러들, 메모리 회로들, 수동 전자 부품들, 능동 전자 부품들, 광학적 부품들, 하드와이어드 회로들 등과 같은 아날로그 또는 디지털 회로들에 의해 물리적으로 구현되고, 펌 웨어 및 소프트웨어에 의해 옵션적으로 구동될 수 있다. 그 회로들은, 예를 들어, 하나 이상의 반도체 칩 내에, 또는 인쇄 회로 보드들 등과 같은 기판 지지물들 상에 실시될 수 있다. 블록을 구성하는 회로들은 전용 하드웨 어에 의해, 또는 프로세서(예컨대, 하나 이상의 프로그래밍된 마이크로프로세서 및 연관된 회로)에 의해, 또는 그 블록의 일부 기능들을 수행하는 전용 하드웨어와 그 블록의 다른 기능들을 수행하는 프로세서의 조합에 의해 구현될 수 있다. 실시예들의 각각의 블록은 본 발명의 범위로부터 벗어남 없이 둘 이상의 상호작용 및 개별 블 록들로 물리적으로 분리될 수 있다. 비슷하게, 실시예들의 블록들은 본 발명의 범위로부터 벗어남 없이 더 복잡한 블록들로 물리적으로 결합될 수 있다. 첨부 도면들은 다양한 기술적 특징들을 쉽게 이해하는 것을 돕는데 사용되고 본 개시에서 제시된 실시예들은 첨 부 도면들에 의해 제한되지 않는다는 것이 이해되어야 한다. 이와 같이, 본 개시는 특히 첨부 도면들에서 제시 된 것들 외에도 임의의 변경들, 동등물들 및 치환물들로 확장되는 것으로 해석되어야 한다. 비록 제1, 제2 등의 용어들이 다양한 엘리먼트들을 설명하기 위해 본 개시에서 사용될 수 있지만, 이들 엘리먼트들은 이들 용어들에 의해 제한되지 않아야 한다. 이들 용어들은 하나의 요소를 다른 요소로부터 구별하는 데에만 일반적으로 사용된 다. 본 개시의 전체에 걸쳐, \"원하는 압축 레벨\" 및 \"압축의 원하는 레벨\"은 교환적으로 사용되고 동일한 것을 의미 한다. 본 개시의 전체에 걸쳐, \"입력 비디오\", \"입력 비디오 데이터\" 및 \"입력 미디어\"라는 용어들은 교환적으 로 사용되고 동일한 것을 의미한다. \"재구성된 비디오\", \"출력 비디오\" 및 \"최적화된 압축된 미디어\"라는 용어 들은 교환적으로 사용되고 동일한 것을 의미한다. 바이어스 및 분산은 모델(예컨대, AI 기반 모델, 머신 러닝(ML) 모델 등)의 두 가지 핵심 특성들이다. 모델의 바이어스는 모델이 모든 잠재적인 결과들을 얼마나 잘 표현할 수 있는지를 말한다. 한편, 분산은 모델의 예측들 이 입력 데이터에서의 작은 변경들에 얼마나 많이 영향을 받는지를 말한다. 바이어스와 분산 사이의 절충은 모 델에서의 기본적인 문제이고, 절충은 훈련 데이터에 가장 적합한 균형을 찾기 위하여 여러 모델 유형들을 실험 하는 데 통상적으로 필요하다. 도 1a는 관련 기술에 따른 AI 기반 모델에서 바이어스와 분산 사이의 절충을 시 각화하기 위한 예시적인 시나리오를 예시한다. 사람은 타깃 값을 나타내는 포인트에 도달하기를 바라며 하나 이 상의 돌을 던진다. 그러나 하나 이상의 돌은 타깃 값으로부터 멀 수 있는 다양한 위치들에서 지면을 때린다. 바 이어스는 여기서는 타깃 값(즉, 실제 값)과 하나 이상의 돌이 떨어진 지점들의 평균 사이의 간극으로서 묘사된 다. 동일한 모집단으로부터 뽑아낸 상이한 훈련 데이터 세트들을 사용하여 훈련된 하나 이상의 AI 기반 모델에 의해 제공되는 예측들의 평균을 파선은 하나 이상의 돌이 땅을 때리는 상이한 위치들에 반영한다. 여기서, 파선 은 하나 이상의 AI 기반 모델의 계산에 기반하여 하나 이상의 돌이 땅을 때릴 수 있는 예측된 위치를 반영할 수 있다. 그러나, 각각의 AI 기반 모델이 상이한 훈련 데이터로 훈련되므로, 하나 이상의 돌은 타깃 값 주위의 다 양한 위치들에 떨어질 수 있다. 파선은 하나 이상의 돌이 땅을 때리는 위치들에서의 변화들을 고려하여 하나 이 상의 AI 기반 모델에 기반하여 예상된 결과의 근사치로서 역할을 할 수 있다. 거리가 짧을수록, 평균(즉, 파 선)과 타깃 값 사이의 바이어스는 더 작아져, 더 나은 모델로 이어진다. 분산은 평균(즉, 파선) 주의의 개별 포 인트들의 확산으로서 표현될 수 있다. 더 낮은 확산과 분산은 하나 이상의 AI 기반 모델 중에서 더 우수한 모델 을 나타낸다. 이는 더 낮은 확산이 모델의 예측들에서 더 높은 레벨의 정확도 및 정밀도를 의미한다는 사실 때 문이다. 분산을 최소화함으로써, 모델은 출력들을 예측하고 더 신뢰성 있는 결과들을 정확하게 제공할 수 있다. 도 1b는 관련 기술에 따른 훈련 데이터로부터의 학습된 바이어스 및 분산에 기반한 AI 기반 모델의 한계를 예시 한다. AI 기반 모델에 대해 원하는 성능 및 신뢰할 수 있는 답변들을 획득하기 위해, 소스 데이터(즉, 훈련 데 이터)와 타깃 데이터(즉, 테스트 데이터)는 동일한 샘플 공간으로부터 나와야 한다. 그러나, 실시간 환경에서, 소스 데이터와 타깃 데이터는 상이한 샘플 공간들에 속할 수 있다. 그 경우, AI 기반 모델은 예상되는 성능과 신뢰할 수 있는 응답들을 제공하지 못할 수 있다. 예를 들어, 얼굴 분류 및 검출을 위해 AI 기반 모델이 인디언 얼굴들(제한된 훈련 데이터)에 대해서만 훈련되는 시나리오를 고려한다. 이 상황에서, 훈련된 AI 기반 모델이 미국인 얼굴들(즉, 새롭고, 보이지 않은 데이터)에 대해 실행되면, 훈련된 AI 기반 모델은 예상되는 바와 같이 수행되지 못할 수 있다. 이는 인디언 얼굴과 미국인 얼굴 사이의 특정한 차이들(예컨대, 앵커 포인트 변경)로 인한 것이다. 그래서, 훈련된 AI 기반 모델은 인디언 얼굴들에 치우친 학습된 바이어스 및 분산을 가진다. 따라 서, 훈련된 AI 기반 모델은 예상된 성능 및 신뢰할 수 있는 응답들을 제공하지 못할 수 있다. 이 문제를 해결하 기 위해, AI 기반 모델은 새로운 샘플 공간이 발견될 때마다 다시 훈련되어야 하며, 이는 광범위하고 지속적인 수동 작업들로 이어질 수 있다. 게다가, AI 기반 모델은 더 새로운 형태들의 데이터의 생성이 진행중이라서 시간이 지날수록 쓸모없어지는 경향 이 있고 다시 훈련되어야 한다. 그러나, AI 기반 모델을 정기적으로 재훈련하는 것은 불편하다. 비디오 압축 기 법은, 예를 들어, 전역적으로 전개되고, AI 기반 모델의 가중값들에서의 빈번한 조정들은 바람직하지 않다. 더 욱이, AI 기반 모델에 연결된 기존의 인루프 필터들(in-loop filters, ILF들)은 이미지 및 신호 프로세싱 원리 들을 이용하여 특정한 종류의 아티팩트를 식별한다. 제한된 옵션들로, 기존의 ILF들은 도 2a 및 도 2b에 도시된 바와 같은 그리고 설명에서 나중에 논의되는 바와 같은 주어진 콘텐츠에 가장 적합한 수많은 모드들/필터들을 채용한다. 단일 입력에 대해 다양한 모드들/필터들을 이용하여 실험하면 인코딩 시간이 증가된다. 일부 기존 ILF들은 품질의 척도(measure)로서 측정결과들을 사용하지 않고, 대신에 가시적 아티팩트들에만 초점을 맞추며;기존의 ILF들의 이러한 본질적인 성질은 기존의 ILF들이 경직되게 한다. 도 2a는 관련 기술에 따른 기존의 다용도 비디오 코딩(VVC) 디코더의 블록도를 예시한다. VVC 디코더는 비디오 데이터의 효율적인 압축 및 압축해제를 가능하게 하는 비디오 코딩 시스템들의 필수적인 일부이다. VVC 디코더 는 전송 및 저장에 요구된 데이터의 양을 최소화하면서도 고품질 비디오 플레이백을 제공하도록 구성된다. VVC 디코더의 근본적인 모듈들 중 하나는 콘텍스트 적응 이진 산술 코딩(context-adaptive binary arithmetic coding, CABAC)이며, 이는 입력 데이터의 통계적 특성들에 적응하는 정교한 엔트로피 코딩 기법이다. CABAC는 VVC 디코더가 비디오 품질을 희생하지 않으면서 높은 압축 비율들을 달성하는 것을 허용한다. CABAC 외에도, VVC 디코더는 역 양자화 모듈, 역변환 모듈, 루마 매핑 크로마 스케일링(luma mapping chroma scaling, LMCS) 모듈, 인루프 필터 모듈, 인트라 예측 모듈, 인터 예측 모듈, LMCS(forward luma mapping) 모듈, 결합식 인터 인트라 예측(combined inter intra prediction, CIIP) 모듈, 디코딩된 픽처 버퍼(decoded picture buffer, DPB) 모듈, 및 재구성된 이미지를 포함한 다른 중요한 몇몇 모듈들을 포함한다. 역 양자화 모듈 및 역변환 모듈 은 양자화되고 변환된 비디오 데이터를 원래의 형태로 변환하는 역할을 한다. LMCS 모듈은 비디오 데이터의 크 로마 및 루마 성분들을 조정하여 전체 이미지 품질을 개선하는 데 사용된다. 추가로, 인루프 필터는 비디오 압축 프로세스 동안 발생할 수 있는 아티팩트들 및 노이즈를 제거하도록 구성된 다. 인루프 필터는 일반적으로 역 루마 매핑 크로마 스케일링(LMCS), 블록화제거 필터(deblocking filter, DBF), 샘플 적응 오프셋(sample adaptive offset, SAO) 필터, 적응 루프 필터(adaptive loop filter, ALF), 및 교차 성분 적응 루프 필터링(cross-component adaptive loop filtering, CC-ALF)을 포함한다. 역 LMCS 모듈은 크로마 스케일링을 조정하여 루마 매핑을 일치시키고 비디오 압축 프로세스에서 적절한 컬러 표현을 보장하도록 구성된다. DBF는 블록화 아티팩트들을 제거하기 위해 블록 경계들에서 사용된다. SAO 필터는 후속하여 블록화제 거된 샘플들에 적용된다. SAO는 링잉(ringing) 아티팩트들을 제거하고 국부 평균 세기 변화를 정정함에 있어서 매우 효과적이다. ALF 및 CC-ALF는 원래의 데이터(예컨대, 원래의 이미지)와 재생성된 데이터(예컨대, 재구성된 이미지) 사이의 평균 제곱 오차(mean squared error, MSE)를 최소화하기 위해 블록 기반 선형 필터링 및 적응적 필터링을 수행한다. 마지막으로, DPB 모듈과 재구성된 이미지 모듈은 함께 작동하여 디코딩된 비디오 데이터를 저장하고 디스플레이 한다. DPB 모듈은 이전에 디코딩된 프레임들을 저장하여 효율적인 프레임간 예측을 가능하게 하는 한편, 재구성 된 이미지 모듈은 디코딩된 비디오 데이터로부터 고품질 디스플레이 이미지를 생성한다. 인트라 예측 모듈과 인터 예측 모듈은 공간적 상관 및 시간적 상관에 기반하여 비디오 데이터의 값들을 예측하 도록 구성된다. 이는 예측된 값과 실제 값 사이의 차이들만을 인코딩함으로써 송신 또는 저장될 필요가 있는 데 이터의 양을 줄이는 데 도움이 된다. CIIP 모듈은 인트라 예측 기법 및 인터 예측 기법 둘 다를 결합하여 압축 효율을 추가로 개선한다. 기존의 VVC 디코더에서, 각각의 인루프 필터는 고유한 아티팩트 또는 미리 정의된 아티팩트를 타깃으로 한다. 예를 들어, 앞서 언급된 바와 같이, DBF는 블로킹 아티팩트들만을 제거한다. 그 결과, 기존의 필터링 처리는 기 존의 필터링 프로세스에 존재하는 '지능형' 요소가 없으므로 입력 콘텐츠의 유형에 기반하여 성능을 조정할 수 없다. 최상의 성능을 얻기 위해, 기존의 필터링 처리는 휴리스틱을 사용하여 상이한 다수의 필터 버전들(예컨대, LMCS, DBF, SAO 등) 중에서 선택하는데, 이는 사용자 경험을 저하시킨다. 도 2b는 관련 기술에 따른 AI 기반 인루프 필터가 있는 기존의 VVC 디코더 파이프라인을 예시한다. 도 2A의 블 록도와 비교하여, AI 기반 인루프 필터는 기존의 VVC 디코더 파이프라인에서의 추가적인 블록이다. AI 기반 인 루프 필터는 인루프 필터들의 문제를 제거한다(즉, 각각의 필터는 고유한 아티팩트 또는 미리 정의된 아티팩트 를 타깃으로 한다). 그러나, 도 1B에 도시된 바와 같이, AI 기반 인루프 필터는 AI 기반 모델에 의해 사용되는 제한된 양의 훈련 데이터로 인해 본질적인 바이어스 및 변형을 더할 수 있다. 그 결과, AI 기반 인루프 필터는 AI 기반 모델이 훈련되지 않은 시나리오들에서 예상치 못한 결과들을 생성할 수 있고 솔루션들을 신뢰할 수 없 게 만들 수 있다. 게다가, AI 기반 모델은 더 새로운 형태들의 데이터의 생성이 진행중이라서 시간이 지날수록 쓸모없어지는 경향이 있고 다시 훈련되어야 할 수 있다. 그러나, AI 기반 모델을 정기적으로 재훈련하는 것은 불편하다. 본 개시의 일 실시예에 따른 방법은, 도 3 내지 도 16과 연계하여 설명되는 바와 같이, 콘텐츠 기반 스케일링을 수행하여 데이터 도메인 간극들을 줄임으로써, 더 새롭고 보이지 않는 데이터에 맞추어 조정하는 추가적인 실시 간 모듈로 AI 기반 모델을 증강시키는 고유한 전략을 제공할 수 있다. 본 개시의 일 실시예에 따른 방법은 화소 매핑을 사용하여 AI 기반 인루프 필터들에서 더 새로운/보이지 않는 데이터와 훈련 데이터 사이의 데이터 도메인 간극들을 메운다. 그 결과, 본 개시의 일 실시예에 따른 방법은, 특정 아티팩트들을 타깃으로 하고 제한된 데이터를 사용하여 자주 훈련되어 AI 기반 훈련 모델들에 내재적인 바이어스 및 변동성(volatility)을 초래하는 기존의 방법들을 능가한다. 본 개시의 일 실시예에 따른 방법은 콘텐츠 기반 스케일링이 오프셋을 스케일링하기 위한 화소 매핑을 식별하는 것을 가능하게 하며, 즉석에서 동작하며, 사전 훈련을 요구하지 않고, 상이한 유형 들의 데이터에 대해 더 많은 일반화를 제공할 수 있다. 더욱이, 본 개시의 일 실시예에 따른 방법은 기존의 방 법들과 비교할 때 복잡도가 매우 낮은데, 기존의 방법들이 더 높은 이득을 달성하기 위해 매우 복잡한 심층 신 경망(DNN) 모델들을 알맞게 사용하고, 또한 콘텐츠별로 적응적이지 않기 때문이다. 본 개시의 일 실시예에 따른 방법은 인코딩 프로세스 동안 비디오 데이터 기반 통계적 회귀를 도입하고 디코딩 프로세스 동안 동일한 것을 사용함으로써 이 문제를 해결할 수 있다. 이제 도면들을 더 상세하게는 유사한 참조 부호들이 도면들의 전체에 걸쳐 일관되게 대응하는 특징부들을 표시 하는 도 3 내지 도 16을 참조하면, 이것들에는 본 개시의 하나 이상의 실시예들이 도시되어 있다. 도 3은 본 개시의 일 실시예에 따른 미디어(예컨대, 입력 비디오)의 AI 기반 인코딩을 위한 다용도 비디오 코딩 (VVC) 인코더 파이프라인의 블록도를 예시한다. VVC 인코더 파이프라인은 복수의 모듈들을 포함한다. 복수의 모듈들은 압축 모듈, 인루프 필터들 , CABAC 모듈, 및 RD 비용 모듈을 포함할 수 있다. 압축 모듈은 전통적인 모듈이며, 이는 입력 비디오(예컨대, 하나 이상의 입력 이미지 프레임)을 수신(또는 식별)할 수 있다. 입력 비디오를 수신할 시, 압축 모듈은 변환, 양자화, 역양자화, 및 역변환과 같은, 수신된 입력 비디오에 대한 하나 이상의 미 리 정의된 동작을 수행할 수 있다. a.변환: 변환 동작은 데이터(예컨대, 입력 비디오)를 그것의 원래의 도메인 표현으로부터 상이한 도메인으로 변 환하는 것을 포함하며, 데이터는 더 효율적으로 압축될 수 있고, 데이터는 변환된 계수들을 포함한다. 변환 동 작은 전형적으로는 수학적 기법들, 이를테면 이산 코사인 변환(discrete cosine transform, DCT), 또는 이산 웨 이브릿 변환(discrete wavelet transform, DWT)을 사용하여 달성된다. b.양자화: 일단 데이터가 변환되면, 양자화 동작이 수행된다. 양자화 동작은 변환된 계수들의 정밀도 또는 동적 범위를 줄이는 것을 수반한다. 변환된 계수들은 본질적으로는 연속 범위의 값들을 유한 세트의 이산 레벨들로 매핑한다. 계수들을 양자화함으로써, 정보는 손실되며, 이는 압축에 기여한다. c.역양자화: 역양자화 동작은 양자화 동작의 역 동작이다. 역양자화는 양자화된 계수들을 다시 그것들의 대략 원래의 값들로 복원하는 것을 수반하며, 이는 각각의 양자화된 계수에 역양자화 계수를 곱함으로써 달성된다. 역양자화 동작은 압축해제 동안에 수행되어 원래의 변환된 계수들의 근사치를 복원한다. d.역 변환: 역 변환 동작은 변환되고 역양자화된 계수들을 다시 원래의 도메인으로 변환하는 것을 포함한다. 역 변환 동작은 초기 변환의 역 동작을 수행하여, 압축된 데이터를 원래의 입력(예컨대, 입력 비디오)과 거의 흡사 하게 재구성한다. 역 변환 동작, 이를테면 역 DCT 또는 역 DWT는, 초기 변환 스테이지 동안 수행된 에너지의 비 상관성(decorrelation) 및 농도를 효과적으로 역전시킨다. 인루프 필터들은 압축 모듈로부터 압축된 데이터(예컨대, 양자화된 데이터, 재구성된 데이터)를 수신 (식별)할 수 있다. 인루프 필터들은 압축 동작들 동안 발생할 수 있는 아티팩트들 및 노이즈를 제거하도록 구성된다. 인루프 필터들은 LMCS(302a), DBF(302b), SAO 필터(302c), ALF, 및 CC-ALF(302d)를 포함할 수 있다. 다양한 블록들(즉, 302a, 302b, 302c, 및 302d)의 기능은 도 2a에 설명된 것과 동일하고 이들 다양한 블 록들은 전통적인 모듈들이다. 본 개시의 하나 이상의 실시예에서, 인루프 필터들은 AI 기반 인루프 필터(302e), 데이터 분포 모델 (302f), 정답값 데이터 분포 모델(302g), 레이트 왜곡 최적화(RDO) 제어 매핑 범위 모듈(302h), 오프셋 스케일 링을 위한 화소 매핑 모듈(302i), 및 최종 AI 기반 인루프 필터 출력 모듈(302j)을 포함할 수 있다. 본 개시의 하나 이상의 실시예에서, AI 기반 인루프 필터(302e)는, 도 5와 연계하여 설명되는 바와 같이, 비디 오 코딩의 루프 필터링 처리에 AI 기법들을 적용하도록 구성될 수 있다. 인루프 필터 모듈들(302a, 302b, 302c, 및 302d)은 블로킹 및 링잉 아티팩트들과 같은 압축 아티팩트들을 감소하기 위해 고정된 수법을 사용하여 전형 적으로 설계될 수 있다. 그러나, AI 및 머신 러닝에서의 진보들로, 연구자들은 인루프 필터 모듈들(302a, 302b, 302c, 및 302d)의 성능을 향상시키기 위해 AI 기반 접근법들의 사용을 모색하였다. AI 기반 인루프 필터(302e) 는 머신 러닝 모델들을 활용하여 비디오 콘텐츠(예컨대, VVC로부터의 이미지 입력, 입력 비디오 등)의 특성들을 학습하고 적응적 필터링 기법들을 적용할 수 있다. 미리 정의된 규칙들 또는 휴리스틱에 의존하는 대신, AI 기반 인루프 필터(302e)는 신경망들 또는 다른 AI 수법들을 사용하여 비디오 콘텐츠를 분석하고 프로세싱할 수 있 다. AI 기반 인루프 필터(302e)는 AI 모델들을 사용할 수 있고 많은 양의 훈련 데이터로부터 학습하여 필터링 동작들에 관한 지능형 결정들을 내릴 수 있다. AI 기반 인루프 필터(302e)를 사용함으로써, 특히 전통적인 인루 프 필터 모듈들(302a, 302b, 302c, 및 302d)이 어려움을 겪을 수 있는 도전 시나리오들에서 아티팩트 감소의 효 과를 개선할 수 있다. AI 모델들은 상이한 콘텐츠 유형들에 적응할 수 있으며, 복잡한 텍스처들과 모션을 처리 할 수 있고, 아티팩트들을 감소하면서도 더 나은 방식으로 세부사항들을 보존할 수 있다. 전반적으로, AI 기반 인루프 필터(302e)는 압축 아티팩트들을 더 적응적이고 지능적으로 줄임으로써 AI의 능력들을 활용하여 인코딩 된 비디오 콘텐츠의 품질을 향상시키는 것을 목표로 할 수 있다. 인코딩된 비디오 콘텐츠는, 도 5와 연계하여 설명되는 바와 같이, 재구성된 비디오 및/또는 하나 이상의 재구성된 이미지 프레임을 포함할 수 있다. 본 개시의 하나 이상의 실시예에서, 데이터 분포 모델(302f)은, 도 6과 연계하여 설명되는 바와 같이, 제1 대표 데이터 포인트 세트를 생성할 수 있다. 데이터 분포 모델(302f)은 아래에서 주어지는 여러 동작들을 실행하여 제1 대표 데이터 포인트 세트를 생성할 수 있다. 데이터 분포 모델(302f)은 AI 기반 인루프 필터(302e)로부터 하나 이상의 재구성된 이미지 프레임(예컨대, 하나 이상의 향상된 이미지 프레임, 모델 출력 데이터)을 수신(식별)할 수 있으며, 여기서 하나 이상의 재구성된 이 미지 프레임은 재구성된 비디오와 연관된다. 데이터 분포 모델(302f)은 그런 다음 하나 이상의 재구성된 이미지 프레임 각각에 대한 원하는 압축 레벨을 지시하는 사용자 입력을 수신(또는 식별)할 수 있다. 데이터 분포 모델 (302f)은 그런 다음 수신된 사용자 입력(또는 원하는 압축 레벨)에 기반하여 하나 이상의 재구성된 이미지 프레 임 각각에 대한 단편 수(예컨대, 5)를 결정할 수 있다. 데이터 분포 모델(302f)은 그런 다음 결정된 단편 수에 기반하여 하나 이상의 재구성된 이미지 프레임 각각을 단편화할 수 있다. 그런 다음 데이터 분포 모델(302f)은, 하나 이상의 분포 메커니즘(예컨대, 정규 분포 등)을 사용하여, 하나 이상의 재구성된 이미지 프레임 각각 내의 콘텐츠 변화를 분석하여 하나 이상의 재구성된 이미지 프레임 각각에 대한 최적의 단편들을 계산한다(즉, 하나 이상의 최적의 단편화된 이미지 프레임을 생성한다). 데이터 분포 모델(302f)은 그 다음에 하나 이상의 최적의 단편화된 이미지 프레임에 대해 하나 이상의 통계적 메커니즘(예컨대, 가우스 혼합 모델들(GMM들))을 사용하여 화소 비닝 동작을 수행할 수 있으며, 하나 이상의 최적의 단편화된 이미지 프레임 각각은 고유 특성을 갖는 화 소들의 그룹(이를테면 유사한 텍스처를 갖는 영역, 평균으로부터의 유사한 편차를 갖는 영역 등)을 포함한다. 데이터 분포 모델(302f)은 하나 이상의 최적의 단편화된 이미지 프레임 각각의 하나 이상의 단편(또는 영역)에 대한 화소 비닝 동작을 수행하여 하나 이상의 최적의 단편화된 이미지 프레임 각각에 대한 제1 대표 데이터 포 인트 세트를 생성할 수 있으며, 여기서 제1 대표 데이터 포인트 세트는 하나 이상의 단편(또는 최적의 단편화된 이미지 프레임) 각각에 대한 스칼라 값을 나타낼 수 있다. 본 개시의 하나 이상의 실시예에서, 정답값 데이터 분포 모델(302g)은, 도 7과 연계하여 설명되는 바와 같이, 제2 대표 데이터 포인트 세트를 생성할 수 있다. 정답값 데이터 분포 모델(302g)은 아래에서 주어지는 여러 동 작들을 실행하여 제2 대표 데이터 포인트 세트를 생성할 수 있다. 정답값 데이터 분포 모델(302g)은 입력 비디오(예컨대, 원래의 비디오, 압축되지 않은 비디오)와 연관된 하나 이상의 입력 이미지 프레임을 수신(또는 식별)할 수 있다. 정답값 데이터 분포 모델(302g)은 그런 다음 하나 이 상의 입력 이미지 프레임 각각에 대한 원하는 압축 레벨을 지시하는 사용자 입력을 수신(또는 식별)할 수 있다. 정답값 데이터 분포 모델(302g)은 그런 다음 수신된 사용자 입력(또는 원하는 압축 레벨)에 기반하여 하나 이상 의 입력 이미지 프레임 각각에 대한 단편 수를 결정할 수 있다. 정답값 데이터 분포 모델(302g)은 그런 다음 결 정된 단편 수에 기반하여 하나 이상의 입력 이미지 프레임 각각을 단편화할 수 있다. 정답값 데이터 분포 모델 (302g)은 그런 다음 하나 이상의 입력 이미지 프레임 각각 내의 콘텐츠 변화를, 하나 이상의 분포 메커니즘을 사용하여, 분석하여 하나 이상의 입력 이미지 프레임 각각에 대한 최적의 단편들을 계산(즉, 하나 이상의 최적 의 단편화된 입력 이미지 프레임을 생성)할 수 있다. 정답값 데이터 분포 모델(302g)은 그런 다음 하나 이상의 최적의 단편화된 입력 이미지 프레임에 대해, 하나 이상의 통계적 메커니즘을 사용하여, 화소 비닝 동작을 수행 할 수 있으며, 여기서 하나 이상의 최적의 단편화된 입력 이미지 프레임 각각은 고유 특성을 갖는 화소들의 그 룹(또는 영역)을 포함한다. 정답값 데이터 분포 모델(302g)은 하나 이상의 최적의 단편화된 입력 이미지 프레임 각각의 하나 이상의 단편(또는 영역들)에 대해 화소 비닝 동작을 수행하여 하나 이상의 최적의 단편화된 입력 이미지 프레임 각각에 대한 제2 대표 데이터 포인트 세트를 생성할 수 있으며, 여기서 제2 대표 데이터 포인트 세트는 하나 이상의 단편(또는 최적의 단편화된 이미지 프레임) 각각에 대한 스칼라 값을 나타낼 수 있다. 본 개시의 하나 이상의 실시예에서, RDO 제어 매핑 범위 모듈(302h)은, 도 4와 연관하여 설명된 바와 같이, RD 비용 모듈의 출력 및 단편 수에 관한 사용자 입력에 기반하여 전체 RD 비용을 결정할 수 있다. RDO 제어매핑 범위 모듈(302h)은 수학식으로서 표현되는 목적 함수를 구축할 수 있다. 목적 함수는 이전의 RDO 비용과 함께, 업데이트된 레이트 및 왜곡과 같은 입력을 받을 수 있다. 업데이트된 RDO 비용에 기반하여, RD 비용 모듈 은 레이트 또는 왜곡 중 어느 하나, 또는 둘 다를 최소화함으로써 전체 RD 비용을 최적화하는 결정들을 내 릴 수 있다. 본 개시의 하나 이상의 실시예에서, 오프셋 스케일링을 위한 화소 매핑 모듈(302i)은, 도 8과 연계하여 설명된 바와 같이, 재구성된 비디오와 연관된 각각의 단편화된 이미지 프레임에 대한 제1 대표 데이터 포인트 세트와 입력 비디오와 연관된 각각의 단편화된 입력 이미지 프레임에 대한 제2 대표 데이터 포인트 세트 사이의 데이터 분포 비유사성 메트릭을 결정할 수 있다. 오프셋 스케일링을 위한 화소 매핑 모듈(302i)은, 도 8과 연계하여 설 명되는 바와 같이, 데이터 분포 비유사성 메트릭을 이용함으로써 각각의 단편화된 이미지 프레임에 대한 오프셋 값을 추가로 결정할 수 있다. 오프셋 값은 단편별 세분도로 계산되고 사용되며, 여기서 단편 수는 사용자로부터 의 입력으로서 수신되고, 각각의 단편은 데이터 분포 모델링 동작(예컨대, 데이터 분포 비유사성 메트릭) 중에 계산된다. 본 개시의 하나 이상의 실시예에서, 오프셋 스케일링 모듈(302i)을 위한 화소 매핑은 모델 출력 데이터 분포, 정답값 데이터 분포, 및 매핑 범위(예컨대, RDO 제어 매핑 범위)를 사용하여 단편별 오프셋의 형태로 (전향적) 화소 매핑을 결정(또는 계산)할 수 있다. 화소 매핑은 모델링된 분포들에서의 차이들에 기반한 화소 레벨 도메 인 매핑일 수 있다. 매핑 범위는 RD 비용을 기반으로 특정 단편에 대한 오프셋 스케일링을 적용할 지의 결정일 수 있고, 매핑 범위는 사용자 정의된 단편 수 및 RD 비용 모듈의 출력(예컨대, 코덱 RD 비용)을 사용하여 결정된다. 본 개시의 하나 이상의 실시예에서, 최종 AI 기반 인루프 필터 출력 모듈(302j)은, 도 9와 연계하여 설명되는 바와 같이, 결정된 오프셋 값을 이용함으로써 각각의 단편화된 이미지 프레임과 연관된 각각의 화소 값에 대한 스케일링 동작을 수행할 수 있다. 스케일링 동작의 예들은 덧셈 연산, 곱셈 동작, 나눗셈 연산, 또는 지수 연산 을 포함할 수 있지만, 그것으로 제한되지 않는다. 최종 AI 기반 인루프 필터 출력 모듈(302j)은 수행된 스케일 링 동작에 기반하여 재구성된 비디오를 더 향상시킬 수 있다. 본 개시의 하나 이상의 실시예에서, 인코더는 재구성된 비디오와 연관된 비트스트림 정보를 디코더(도 12 참 조)에 송신할 수 있으며, 여기서 비트스트림 정보는 결정된 오프셋 값(예컨대, 오프셋 시그널링)을 포함할 수 있다. 추가로, CABAC 모듈과 RD 비용 모듈은 VVC 인코더에서 사용되는 두 가지 전통적인 모듈들이고, 이는 최신 비디오 코딩 표준이다. CABAC 모듈은 변환 및 양자화된 계수를 효율적으로 압축하기 위해 VVC 인코더 에서 채용되는 엔트로피 코딩 기법이다. VVC 인코더에서, CABAC 모듈은 입력 비디오 데이터를 압축하고 다 음 기능들을 수행하도록 구성된다: a.콘텍스트 모델링: CABAC 모듈은 입력 비디오 데이터(예컨대, 입력 비디오, 이미지 프레임 등)를 분석할 수 있고 입력 비디오 데이터에서의 심볼들 사이의 관계들 및 의존도들을 캡처하는 통계적 모델들을 생성할 수 있다. CABAC 모듈은 입력 비디오 데이터와 연관된 콘텍스트에 기반하여 발생하는 상이한 심볼들의 확률들 을 추정할 수 있다. b.이진 산술 코딩: CABAC 모듈은 확률들을 누적 분포 함수들(cumulative distribution functions, CDF 들)로 변환할 수 있다. CDF들은 이진 코드워드들을 입력 비디오 데이터의 심볼들에 배정하는 데 사용된다. 이진 산술 코딩 기법은 확률들에 기반하여 심볼들을 효율적으로 인코딩한다. c.비트스트림 생성: CABAC 모듈은 입력 비디오 데이터를 재구성하기 위해 디코더에 대한 필요한 정보와 함 께, 인코딩된 심볼들을 포함하는 압축된 비트스트림을 생성할 수 있다. 그 다음에 압축된 비트스트림은, 이하에 서 자세히 설명되는 바와 같이, 추가 프로세싱 또는 전송을 위해 송신 또는 저장된다. RD 비용 모듈은 레이트(즉, 비트레이트)와 왜곡(즉, 시각적 품질) 사이에 최적의 절충을 결정하도록 구성 되며, 이는 VVC 인코더가 상이한 인코딩 옵션들의 레이트 및 왜곡을 평가함으로써 각각의 코딩 단위에 대한 최 상의 코딩 파라미터들을 찾는데 도움이 된다. RD 비용 모듈은 입력 비디오 데이터를 인코딩하기 위한 다양 한 동작들을 수행할 수 있으며, 이러한 동작들은 아래에서 나열된다. a.RD 비용 모듈은 특정 코딩 옵션을 위한 인코딩된 데이터를 나타내는 데 필요한 비트 수를 추정할 수 있 다. 이는 구문 요소들, 모션 정보, 및 잔차 데이터를 코딩하는 데 사용되는 비트들을 포함한다.b.시각적 품질을 평가하기 위해, RD 비용 모듈은 재구성된 비디오를 원래의 입력과 비교함으로써 왜곡을 계산할 수 있다. 평균 제곱 오차(MSE) 또는 구조적 유사도 지수(structural similarity index, SSIM)와 같은 공통 메트릭들이 왜곡 측정에 사용될 수 있다. c.RD 비용 모듈은 각각의 코딩 단위에 대한 다양한 코딩 옵션들을 평가함으로써 레이트 왜곡 최적화를 수 행할 수 있다. 이는 상이한 모드들, 모션 벡터들, 변환 옵션들, 및 양자화 파라미터들을 탐색하여 레이트와 왜 곡 사이의 최상의 절충을 달성하는 조합을 찾는다. d.레이트 및 왜곡 계산들에 기반하여, RD 비용 모듈은 전체 RD 비용을 최소화하는 코딩 옵션들을 선택할 수 있다. 이들 최적의 선택들은 입력 비디오 데이터의 최종 인코딩에 사용된다. RD 비용 모듈을 통합함으로써, VVC 인코더는 콘텐츠 특성들 및 지각적 중요도에 기반하여 비트들을 효율적 으로 할당할 수 있어, 만족스러운 시각적 품질을 유지하면서도 비디오 압축 성능을 개선한다. 도 4는 관련 기술에 따른 미디어의 AI 기반 인코딩을 위한 각각의 압축된 이미지 프레임에 대한 RD 비용 값을 결정하기 위한 레이트 왜곡 선도를 예시한다. RD 비용 모듈은 미디어의 압축의 양 및 압축된 미디어의 품질에 대한 사용자 선호도(preference)를 획득할 수 있다. RD 비용 모듈은, 수학식 1에 도시된 바와 같이, 압축의 양(또는 범위)(compressio-extent)에 기 반하여 각각의 압축된 이미지 프레임에 대한 레이트(R) 값(즉, 비트 레이트)을 결정할 수 있다. RD 비용 모듈 은 수학식 2에 도시된 바와 같이, 압축된 콘텐츠의 품질(compressed-content-quality)에 기반하여 각각의 압축된 이미지 프레임에 대한 왜곡(D) 값을 결정할 수 있다."}
{"patent_id": "10-2025-7002758", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "RD 비용 모듈은 튜닝 파라미터(λ)를 결정할 수 있으며, 튜닝 파라미터는 현재 요건(즉, 미디어의 압축의 양에 대한 사용자 선호도)에 기반하여 설정되며, 튜닝 파라미터는 레이트 또는 왜곡의 차분 가중치(weightage) 를 허용할 수 있다. RD 비용 모듈은, 수학식 3에 도시된 바와 같이, R 값, D 값, 및 튜닝 파라미터(λ)에 기반하여 각각의 압축된 이미지 프레임에 대한 RD 비용 값(RD cost value)을 결정할 수 있다."}
{"patent_id": "10-2025-7002758", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "레이트 왜곡 선도는 y축상의 복수의 레이트(R) 값들과 x-축상의 복수의 왜곡(D) 값들을 예시한다. 게다가, 레이트 왜곡 선도는 제1 튜닝 파라미터(λ1)에 대한 제1 곡선와 제2 튜닝 파라미터(λ2)에 대한 제2 곡선 을 예시한다. 사용자의 현재 요건에 기반하여, 사용자는 레이트 왜곡 선도에 도시된 바와 같이, R 값 또는 D 값 중 어느 하나를 낮출 수 있다. 다르게 말하면, R 값과 D 값 사이에 절충이 존재한다. 예를 들어, 요소에 묘사된 바 와 같이, 사용자가 비디오 코덱 파이프라인의 출력이 왜곡이 거의 없는 이례적으로 높은 품질이기를 원한다면, D 값은 40.5로 선택될 수 있다. 그러면 R 값은 왜곡을 줄이기 위해 증가될 수 있다. R 값은 제2 곡선(예컨 대, R 값 = 1.25) 또는 제1 곡선(예컨대, R 값 = 1.75) 중 어느 하나와 연결된다. 사용자가 전자 기기의 메모리를 최적화하기 원하면, RD 비용 모듈은 최저 R 값을 갖는 제2 곡선을 선택할 수 있다. 도 5는 관련 기술에 따른 미디어의 AI 기반 인코딩을 위한 각각의 압축된 이미지 프레임(예컨대, 재구성된 이미 지 프레임)의 품질을 향상시키기 위한 AI 기반 인루프 필터(302e)와 연관된 심층 콘볼루션 신경망들(Deep Convolutional Neural Network, DCNN)의 전형적인 아키텍처를 예시한다. AI 기반 인루프 필터(302e)는 압축 모듈, LMCS(302a), DBF(302b), SAO 필터(302c), ALF, 및 CC-ALF(302d) 중 적어도 하나로부터 하나 이상의 입력 이미지 프레임을 수신한다. 하나 이상의 입력 이미지 프레임은 입력 이 미지 화소들에 관한 특정 높이와 폭 그리고 하나 이상의 제1 채널을 갖는 제1 차원 세트(예컨대, HXWXC1)에 의 해 나타낼 수 있으며, 여기서 H는 텐서의 높이를 나타내며, W는 텐서의 폭을 나타내고, C는 텐서에서의 채널 수 를 나타낸다. 차원은 하나 이상의 입력 이미지 프레임의 특정 높이, 폭 및 텐서에 존재하는 채널 수에 해당할 수 있다. 텐서는 다차원 어레이로 하나 이상의 이미지 프레임의 화소 값들을 구성하는 방식으로 구조화될 수 있다. 그런 다음 하나 이상의 입력 이미지 프레임은 하나 이상의 입력 이미지 프레임의 품질을 향상시키기 위해 하나 이상의 DCNN을 통해 통과될 수 있다. 하나 이상의 향상된 이미지 프레임은 입력 이미지 신호들의 이미지 화소들에 관한 특정 높이와 가중값 그리고 하나 이상의 제2 채널을 갖는 제2 차원 세트(예컨대, HXWXC2)에 의해 표현될 수 있다. 본 개시의 일 실시예에서, 비디오 코덱 파이프라인에서의 품질 향상을 위한 AI 기반 인루프 필 터(302e)의 사용은 더 넓은 범위의 데이터 변형들이 관리되는 것을 허용할 수 있는데, AI 기반 모듈들이 여러 유형들의 아티팩트들(예컨대, 블록화 아티팩트들, 링잉 아티팩트들 등)을 제거하도록 훈련될 수 있기 때문이다. 본 개시의 일 실시예에서, AI 기반 인루프 필터(302e)는 다양한 종류들의 압축 아티팩트들을 방지하도록 설계될 수 있다. 이러한 필터들로부터의 결정들은 루프 내에서 이루어지며, 이는 향후 이미지 프레임들에 대한 결정들 에도 영향을 미친다. AI 기반 인루프 필터(302e)는, 도 6과 연계하여 설명되는 바와 같이, 하나 이상의 향상된 이미지 프레임을 데이터 분포 모델(302f)에 추가 프로세싱을 위해 전달할 수 있다. 도 6은 본 개시의 일 실시예에 따른 제1 대표 데이터 포인트 세트를 생성하기 위한 예시적인 시나리오를 예시한다. 향상된 이미지 프레임은 AI 기반 인루프 필터(302e)로부터 수신된다. 단계 601에서, AI 기반 인루프 필터(302e)는 압축 모듈, LMCS(302a), DBF(302b), SAO 필터(302c), ALF, 또는 CC-ALF(302d) 중 적어도 하나로부터 입력 비디오와 연관된 하나 이상의 입력 이미지 프레임(예컨대, 재구 성된 이미지 프레임들, 압축된 이미지 프레임들)을 수신할 수 있다. 단계 602에서, 하나 이상의 입력 이미지 프 레임을 수신할 시, AI 기반 인루프 필터(302e)는 하나 이상의 입력 이미지 프레임의 품질을 향상시킬 수 있다. 그런 다음 AI 기반 인루프 필터(302e)는, 이후에 설명되는 바와 같이, 하나 이상의 향상된 이미지 프레임을 데 이터 분포 모델(302f)에 추가 프로세싱을 위해 전달할 수 있다. 단계들(603~604)에서, 데이터 분포 모델(302f)은 AI 기반 인루프 필터(302e)로부터 하나 이상의 향상된 이미지 프레임을 수신(또는 식별)할 수 있고 각각의 향상된 이미지 프레임에 대한 단편 수를 결정하기 위해 사용자 입 력을 수신(또는 식별)할 수 있다. 예를 들어, 사용자는 커맨드 라인 인수들의 형태로 선호 압축 거래를 특정할 수 있다. 단계들(605~606)에서, 데이터 분포 모델(302f)은 하나 이상의 분포 메커니즘을 이용하여 하나 이상의 최적의 단 편화된 이미지 프레임을 결정함으로써 각각의 향상된 이미지 프레임 내의 콘텐츠 변화를 분석할 수 있으며, 여 기서 각각의 최적의 단편화된 이미지 프레임은 고유 특성을 갖는 화소들의 그룹을 포함할 수 있다. 본 개시의 일 실시예에서, 데이터 분포 모델(302f)은 각각의 향상된 이미지 프레임 내의 콘텐츠 변화를 분석하여 각각의 향상된 이미지 프레임에 대한 하나 이상의 최적의 단편들을 생성할 수 있다. 데이터 분포 모델(302f)은 그런 다 음 하나 이상의 통계적 메커니즘을 이용함으로써 각각의 향상된 이미지 프레임에 대한 화소 비닝을 수행할 수 있다. 데이터 분포 모델(302f)은 그런 다음 수신된 사용자 입력, 분석된 콘텐츠 변화, 또는 화소 비닝 중 적어 도 하나에 기반하여 각각의 향상된 이미지 프레임을 단편화할 수 있다. 예를 들어, 각각의 향상된 이미지 프레 임은 네 개의 단편들 또는 네 개의 섹션들(예컨대, fragment-1, fragment-2, fragment-3 등)을 포함할 수 있고, 각각의 섹션은 특정 대역(예컨대, 대역-1)에 의해 나타내어진다. 단계 607에서, 데이터 분포 모델(302f)은 하나 이상의 최적의 단편화된 이미지 프레임 각각에 대한 제1 대표 데 이터 포인트 세트를 생성할 수 있으며, 여기서 제1 대표 데이터 포인트 세트는 하나 이상의 최적의 단편화된 이 미지 프레임 각각에 대한 스칼라 값의 벡터를 표현할 수 있다. 본 개시의 일 실시예에서, 데이터 분포 모델 (302f)은 각각의 최적의 단편화된 이미지 프레임 내의 하나 이상의 단편 각각에 대한 화소 비닝을 수행하여 각 각의 최적의 단편화된 이미지 프레임에 대한 제1 대표 데이터 포인트 세트를 생성할 수 있다. 각각의 최적의 단 편화된 이미지 프레임에 대한 제1 대표 데이터 포인트 세트는 각각의 최적의 단편화된 이미지 프레임 내의 하나 이상의 단편 각각에 대한 스칼라 값을 나타낼 수 있다. 일 실시예에서, 데이터 분포 모델(302f)은 예를 들어, 가우시안 혼합(Gaussian Mixture, GM) 모델을 사용하여 각각의 향상된 이미지 프레임을 단편화하지만, 가우시안 혼합(GM) 모델로 제한되지 않는다. 일 실시예에서, 각각의 단편화된 이미지 프레임은 각각의 향상된 이미지 프레임 내의 상이한 종류들의 콘텐츠를 캡처할 수 있다. 그런고로, 본 개시의 일 실시예에 따른 방법은 다양한 데이터 변형들에 대한 처리를 맞춤화할 수 있는데, 상이한 종류들의 데이터 변형들이 상이한 종류들의 단편들로 이어지는 상이한 종류들의 내부 데이터 분포를 생성할 수 있기 때문이다. 더욱이, 개시된 방법이 즉석에서 작동하므로 요구된 사전 훈련이 없고 모든 종류들의 입력 데이터(예컨대, 이미지 프레임, 입력 비디오 등)에 대한 일반화될 수 있다. 도 7은 본 개시의 일 실시예에 따른 제2 대표 데이터 포인트 세트를 생성하기 위한 예시적인 시나리오를 예시한다. 단계들(701~702)에서, 정답값 데이터 분포 모델(302g)은 입력 비디오(예컨대, 원래의 비디오)와 연관된 하나 이 상의 입력 이미지 프레임을 수신(또는 식별)할 수 있다. 단계들(702~703)에서, 각각의 입력 이미지 프레임에 대한 단편 수를 결정하기 위해 정답값 데이터 분포 모델 (302g)은 사용자 입력을 수신(또는 식별)할 수 있다. 예를 들어, 사용자는 커맨드 라인 인수들의 형태로 단편 선호도를 특정할 수 있다. 단계들(704~705)에서, 정답값 데이터 분포 모델(302g)은 하나 이상의 분포 메커니즘을 이용하여 하나 이상의 최 적의 단편화된 입력 이미지 프레임을 결정함으로써 각각의 입력 이미지 프레임 내의 콘텐츠 변화를 분석할 수 있으며, 여기서 각각의 최적의 단편화된 입력 이미지 프레임은 고유 특성을 갖는 화소들의 그룹을 포함할 수 있 다. 본 개시의 일 실시예에서, 정답값 데이터 분포 모델(302g)은 각각의 입력 이미지 프레임 내의 콘텐츠 변화 를 분석하여 각각의 입력 이미지 프레임에 대한 하나 이상의 최적의 단편을 생성할 수 있다. 정답값 데이터 분 포 모델(302g)은 그런 다음 하나 이상의 통계적 메커니즘을 이용함으로써 각각의 입력 이미지 프레임에 대한 화 소 비닝을 수행할 수 있다. 정답값 데이터 분포 모델(302g)은 그런 다음 수신된 사용자 입력, 분석된 콘텐츠 변 화, 및 화소 비닝에 기반하여 각각의 입력 이미지 프레임을 단편화할 수 있다. 예를 들어, 각각의 입력 이미지 프레임은 네 개의 단편들 또는 네 개의 섹션들(예컨대, fragment-1, fragment-2, fragment-3 등)을 포함할 수 있고, 각각의 섹션은 특정 대역(예컨대, 대역-1)에 의해 나타내어진다. 단계 706에서, 정답값 데이터 분포 모델(302g)은 하나 이상의 최적의 단편화된 입력 이미지 프레임 각각에 대한 제2 대표 데이터 포인트 세트를 생성할 수 있으며, 여기서 제2 대표 데이터 포인트 세트는 하나 이상의 최적의 단편화된 입력 이미지 프레임 각각에 대한 스칼라 값의 벡터를 나타낼 수 있다. 본 개시의 일 실시예에서, 정답 값 데이터 분포 모델(302g)은 각각의 최적의 단편화된 입력 이미지 프레임 내의 하나 이상의 단편 각각에 대한 화소 비닝을 수행하여 각각의 최적의 단편화된 입력 이미지 프레임에 대한 제2 대표 데이터 포인트 세트를 생성 할 수 있다. 각각의 최적의 단편화된 입력 이미지 프레임에 대한 제2 대표 데이터 포인트 세트는 각각의 최적의 단편화된 입력 이미지 프레임 내의 하나 이상의 단편 각각에 대한 스칼라 값을 나타낼 수 있다. 일 실시예에서, 정답값 데이터 분포 모델(302g)은, 예를 들어 GM 모델을 사용하여 각각의 입력 이미지 프레임을 단편화할 수 있지만, GM 모델로 제한되지 않는다. 일 실시예에서, 데이터 분포 모델(302f)에 의해 이용되는 하나 이상의 통계적 메커니즘은 정답값 데이터 분포 모델(302g)에 의해 이용되는 하나 이상의 통계적 메커니즘과 동일하다. 도 8은 본 개시의 일 실시예에 따른 미디어의 AI 기반 인코딩을 위한 오프셋 스케일링을 위한 화소 매핑을 생성 하기 위한 예시적인 시나리오를 예시한다. 본 개시의 일 실시예에서, 오프셋 스케일링을 위한 화소 매핑 모듈(302i)은 데이터 분포 모델(302f) 및 정답값 데이터 분포 모델(302g)로부터 모델링된 데이터 분포 정보를 수신(또는 식별)한다. 양 모델들(302f, 302g)에 의 해 이용되는 하나 이상의 분포 메커니즘은 동일하고, 후속하여, 오프셋 스케일링을 위한 화소 매핑 모듈(302i) 은 양 모델들(302f, 302g)의 출력을 비교할 수 있고 양 모델들(즉, 데이터 분포 모델(302f) 및 정답값 데이터 분포 모델(302g))의 출력 사이의 차이를 결정한다. 도메인의 대표값(예: 도 6 및 도 7에 예시된 바와 같은 화소 비닝 곡선의 진폭)과 함께 단편 정보(예컨대, fragment-1)는 모델링된 데이터 분포들에 이미 존재할 수 있다. 오프셋 스케일링을 위한 화소 매핑 모듈(302i)은 특정 시간 인스턴스에서 하나의 단편을 고려할 수 있고 정답값 데이터(예컨대, 입력 이미지 프레임, 단편화된 입력 이미지 프레임) 및 모델 출력 데이터(예컨대, 재구성된 이 미지 프레임, 향상된 이미지 프레임, 단편화된 이미지 프레임)에서 대응하는 세그먼트들의 단편 도메인 대표 값 사이의 변환을 계산할 수 있다. 본 개시의 일 실시예에서, 오프셋 스케일링을 위한 화소 매핑 모듈(302i)은 RDO 제어 매핑 범위 모듈(302h)로부 터 매핑 범위 정보(특정 단편(예컨대, fragment-1)에 대한 오프셋 스케일링을 적용할 지의 결정)를 수신(또는 식별)할 수 있다. 본 개시의 일 실시예에서, 오프셋 스케일링을 위한 화소 매핑 모듈(302i)은 RDO 제어 매핑 범 위 모듈(302h)로부터의 목적 함수에 기반하여 매핑 범위를 계산할 수 있다. 매핑 범위 정보는 수학식 4에 도시 된 바와 같은 두 가지 함수들에 의해 결정된다."}
{"patent_id": "10-2025-7002758", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 4에서, f는 RDO 제어 매핑 범위(RDO controlled mapping extent) 모듈(302h)에 의해 구축된 전체 RD 비 용을 최소화하는 목적 함수일 수 있다. 예를 들어, 그래프는 데이터 분포 모델(302f)과 연관된 분포 모델링을 나타내는 반면, 그래프는 정답 값 데이터 분포 모델(302g)과 연관된 분포 모델링을 나타낸다. 그래프와 그래프는 fragment-1에 대한 도메인 정보를 묘사한다. 오프셋 스케일링을 위한 화소 매핑 모듈(302i)은 오프셋 스케일링을 위한 수학적 연산 (예컨대, 평균 연산)을 사용하여 오프셋 값들을 결정할 수 있다. 그래프의 x-y 축상에 나타낸 데이터의 평 균 값은 \"2\"인 반면, 그래프의 x-y 축상에 나타낸 데이터의 평균 값은 \"2.5\"이다. 그 결과, 도메인 차이 평균 값 \"0.5\"가 획득된다. 도메인 차이 평균 값을 극복하기 위해, 하나 이상의 최적화 연산들(예컨대, 덧셈, 곱셈 등)이 실행될 수 있고 fragment-1과 연관된 화소 값들은 왜곡을 줄이도록 스케일링될 수 있다. 위에서 언 급된 프로세스는 이미지 프레임에서의 각각의 단편에 대해 수행된다. 그 결과, 오프셋 스케일링을 위한 화소 매 핑 모듈(302i)은 오프셋 맵을 생성할 수 있다. 생성된 오프셋 맵은, 도 9와 연계하여 설명되는 바와 같이, 추가 프로세싱을 위해 최종 AI 기반 인루프 필터 출력 모듈(302j)에 전송될 수 있다. 도 9는 본 개시의 일 실시예에 따른 오프셋 스케일링을 생성하기 위한 예시적인 시나리오를 예시한다. 최종 AI 기반 인루프 필터 출력 모듈(302j)은 오프셋 스케일링을 위한 화소 매핑 모듈(302i)로부터의 생성된 오 프셋 맵과 AI 기반 인루프 필터(302e)로부터의 향상된 이미지 프레임을 수신(또는 식별)한다. 이 정 보를 수신할 시, 최종 AI 기반 인루프 필터 출력 모듈(302j)은 생성된 오프셋 맵에 기반하여 향상된 이미 지 프레임에 대해 오프셋 스케일링을 수행할 수 있다. 그 결과, 최종 AI 기반 인루프 필터 출력 모듈 (302j)은 콘텐츠 기반 스케일링된 출력을 생성할 수 있다. 본 개시의 일 실시예에 따른 방법은 단지 세그먼트별(또는 단편별) 오프셋이 비트스트림 정보에 인코딩되는 것 을 요구한다. 본 개시의 일 실시예에 따른 방법은 데이터 분포 모델(302f) 및 정답값 데이터 분포 모델(302g)과 연관된 정보를 인코딩하지 않을 수 있다. 다르게 말하면, 즉석 모델링에 관한 정보는 비트스트림에 제공될 필요 가 없고, 그런 고로, 개시된 방법은 인코딩 프로세스와 연관된 레이트를 크게 증가시키지 않는다. 도 10 및 도 11은 본 개시의 일 실시예에 따른 도메인을 모델링하는 여러 방법들을 예시한다. 도 10을 참조하면, 도 10에 도시된 바와 같은 예시적인 시나리오에는, 상단의 세 개의 주 성분들을 나타내는 선 도가 존재한다. 선도는 3차원 공간에서 화소 포인트들을 시각화한다. 예를 들면, 양자화 파라미터 (QP) 값(즉, 42)을 갖는 100개의 포인트들, QP 값을 갖는 500개의 포인트들, 및 QP 값을 갖는 모 든 포인트들이 있다. 주성분 분석(principal component analysis, PCA) 수법을 사용하여 대표 포인트들 (즉, 제1 대표 데이터 포인트 세트 및 제2 대표 데이터 포인트 세트)을 계산하기 위해, 오프셋 스케일링을 위한 화소 매핑 모듈(302i)은 PCA 수법을 사용하여 화소 값들을 변환할 수 있다. 이 변환은 변환된 값들을 클러스터 들로서 시각화하는 것을 허용한다. 이들 클러스터들(즉, 1001, 1002, 및 1003)로부터, 오프셋 스케일링을 위한 화소 매핑 모듈(302i)은 해당 특정 클러스터(즉, 1001, 1002, 및 1003)에 대한 대표 포인트로서 역할을 하는 클 러스터 센트로이드(centroid)를 추출할 수 있다. 대표 포인트는 클러스터(즉, 1001, 1002, 및 1003)의 필수적인 특성들을 캡처하고 추가 분석 또는 의사 결정 프로세스들을 위해 사용될 수 있다. 도 11을 참조하면, 하나 이상의 그래프는, 예를 들어, 도 8에 관련되는, 정답값 데이터 분포 모델(302g) 과 데이터 분포 모델(302f) 사이의 화소 차이('diff'라고 지칭됨)의 평균 및 표준 편차 모델링을 나타낸다. QP 값이 22일 때, 그래프들(1101 및 1102)은 원래의 데이터 포인트들(즉, 제2 대표 데이터 포인트 세트)과 코덱 재 생성된 데이터 포인트들(즉, 제1 대표 데이터 포인트 세트) 사이의 화소 차이의 평균 및 표준 편차 모델링을 디 스플레이한다. QP 값이 32일 때, 그래프들(1103 및 1104)은 원래의 데이터 포인트들과 코덱 재생성된 데이터 포 인트들 사이의 화소 차이의 평균 및 표준 편차 모델링을 디스플레이한다. QP 값이 42일 때, 그래프들(1104 및 1105)은 원래의 데이터 포인트들과 코덱 재생성된 데이터 포인트들 사이의 화소 차이의 평균 및 표준 편차 모델 링을 디스플레이한다. 도 12는 본 개시의 일 실시예에 따른 미디어의 AI 기반 인코딩을 위한 VVC 디코더 파이프라인의 블록도를 예시한다. VVC 디코더 파이프라인은 복수의 모듈들을 포함한다. 복수의 모듈들은 CABAC 모듈, 역 양자화 모듈 , 역변환 모듈, LMCS, 인루프 필터들, 인트라 예측 모듈, 인터 예측 모듈 , CIIP 모듈, LMCS, DPB, 및 재구성된 이미지 모듈을 포함할 수 있다. CABAC 모듈, 역 양자화 모듈, 역변환 모듈, LMCS, 인루프 필터들, 인트라 예측 모듈 , 인터 예측 모듈, CIIP 모듈, LMCS, DPB, 및 재구성된 이미지 모듈은전통적인 모듈들이다. CABAC 모듈은 압축된 비트스트림(즉, VVC 인코더 파이프라인으로부터 수신된 비트스트림 정보)을 압 축해제할 수 있고 원래의 프레임들(즉, 입력 비디오 데이터)을 재구성할 수 있다: a.비트스트림 파싱: CABAC 모듈은 압축된 비트스트림을 수신할 수 있고 이를 파싱하여 인코딩된 심볼들 및 연관된 정보를 추출할 수 있다. b.이진 산술 디코딩: CABAC 모듈은 이진 산술 디코딩을 사용하여 압축된 비트스트림으로부터 심볼들을 디 코딩할 수 있다. CABAC 모듈은 디코딩된 심볼들에 확률들을 배정할 수 있고 이 확률들을 사용하여 인코딩 된 심볼들과 연관된 원래의 심볼들을 재구성할 수 있다. c.콘텍스트 모델링 동기화: CABAC 모듈은 콘텍스트 모델링을 사용하여 VVC 인코더 파이프라인과 VVC 디코더 파이프라인 사이에 적절한 동기화를 제공할 수 있다. 추가로, 역 양자화 모듈과 역변환 모듈은 양자화되고 변환된 비디오 데이터를 다시 원래의 형태로 변환하도록 구성된다. LMCS 모듈은 비디오 데이터의 크로마 및 루마 성분들을 조정하여 전체 이미지 품질 을 개선하는 데 사용된다. 추가로, 인루프 필터들은 LMCS 모듈로부터 데이터를 수신할 수 있다. 인루프 필터들은 압축 동작들 동안 발생할 수 있는 아티팩트들 및 노이즈를 제거하도록 구성된다. 인루프 필터들의 예는 LMCS(1205a), DBF(1205b), SAO 필터(1205c), ALF, 및 CC-ALF(1205d)를 포함할 수 있다. 다양한 블록들(1205a, 1205b, 1205c, 및 1205d)의 기능은 도 2a에 설명된 것과 동일하고 이들 다양한 블록들은 전통적인 모듈들이다. 추가로, 인트라 예측 모듈과 인터 예측 모듈은 공간적 및 시간적 상관들에 기반하여 데이터의 값들 을 예측하도록 구성된다. CIIP 모듈은 인트라 예측 기법 및 인터 예측 기법 둘 다를 결합하여 압축 효율 을 추가로 개선할 수 있다. 마지막으로, DPB와 재구성된 이미지 모듈들은 디코딩된 비디오 데이터를 저장 하고 디스플레이하기 위해 함께 작업할 수 있다. DPB는 효율적인 프레임간 예측을 가능하게 하기 위해 이 전에 디코딩된 프레임들을 저장할 수 있는 한편, 재구성된 이미지 모듈은 디코딩된 데이터(예컨대, 인루 프 필터로부터의 이미지 프레임)로부터 고품질 디스플레이 이미지를 생성한다. 본 개시의 하나 이상의 실시예에서, 인루프 필터들은 AI 기반 인루프 필터(1205e), 데이터 분포 모델 (1205f), 오프셋 스케일링을 위한 화소 매핑 모듈(1205g), 및 최종 AI 기반 인루프 필터 출력 모듈(1205h)을 포 함할 수 있다. 본 개시의 하나 이상의 실시예에서, AI 기반 인루프 필터(1205e)는 VVC 인코더 파이프라인(도 3 참조)으로 부터 재구성된 비디오와 연관된 비트스트림 정보를 수신할 수 있으며, 여기서 비트스트림 정보는 오프셋 값을 포함한다. AI 기반 인루프 필터(1205e)는, 수신된 비트스트림 정보에 기반하여, AI 기반 인루프 필터(302e)에 관련되는 다양한 기능을 수행할 수 있다. 본 개시의 하나 이상의 실시예에서, AI 기반 인루프 필터(1205e)는 LMCS, LMCS(1205a), 블록화제거 필터 (1205b), SAO(1205c) 또는 ALF, CC-ALF(1205d) 중 적어도 하나로부터 재구성된 비디오와 연관된 재구성된 이미 지 프레임을 수신(또는 식별)할 수 있다. AI 기반 인루프 필터(1205e)는 재구성된 이미지 프레임으로부터 아티 팩트들을 제거함으로써 재구성된 이미지 프레임의 품질을 향상시킬 수 있다. 본 개시의 하나 이상의 실시예에서, 데이터 분포 모델(1205f)은 재구성된 비디오에 대한 모델 출력 데이터 분포 를 생성할 수 있다. 데이터 분포 모델(1205f)은 AI 기반 인루프 필터(1205e)로부터의 향상된 이미지 프레임에 대한 모델 출력 데이터 분포를 생성할 수 있다. 본 개시의 하나 이상의 실시예에서, 오프셋 스케일링을 위한 화소 매핑 모듈(1205g)은 오프셋 값 및 생성된 모 델 출력 데이터 분포를 이용함으로써 재구성된 비디오의 각각의 단편화된 이미지 프레임과 연관된 각각의 화소 값에 대한 스케일링 동작을 수행할 수 있다. 본 개시의 일 실시예에서, 오프셋 스케일링을 위한 화소 매핑 모듈 (1205g)은 비트스트림으로부터 오프셋 시그널링을 식별할 수 있고 오프셋 시그널링에 기반하여 오프셋 맵을 생 성할 수 있다. 본 개시의 하나 이상의 실시예에서, 최종 AI 기반 인루프 필터 출력 모듈(1205h)은 수행된 스케일링 동작에 기 반하여 출력 비디오를 생성할 수 있다. 본 개시의 일 실시예에서, 최종 AI 기반 인루프 필터 출력 모듈(1205h) 은 생성된 오프셋 맵(또는 오프셋 값들, 오프셋 시그널링)에 기반하여 AI 기반 인루프 필터링(1205e)으로부터의향상된 이미지 프레임에 대해 오프셋 스케일링 동작을 수행할 수 있다. 도 13a는 본 개시의 일 실시예에 따른 미디어의 AI 기반 인코딩을 위한 전자 기기의 블록도를 예시한다. 본 개 시의 하나 이상의 실시예에서, 전자 기기는 도 3에 묘사된 하나 이상의 모듈을 포함할 수 있다. 전자 기기 의 예들은 스마트폰, 태블릿 컴퓨터, 개인 정보 단말기(Personal Digital Assistance, PDA), 사물 인터넷 (Internet of Things, IoT) 기기, 착용 가능 기기들을 포함할 수 있지만, 그것들로 제한되지 않는다. 본 개시의 일 실시예에서, 전자 기기는 시스템을 포함한다. 시스템은 메모리, 프로세서 , 및 통신부를 포함할 수 있다. 본 개시의 일 실시예에서, 메모리는, 본 개시의 전체에 걸쳐 논의되는 바와 같이, 미디어의 AI 기반 인코 딩을 위해 프로세서에 의해 실행될 명령어들을 저장한다. 메모리는 비휘발성 저장 요소들을 포함할 수 있다. 이러한 비휘발성 저장 요소들의 예들은 자기적 하드 디스크들, 광학적 디스크들, 플로피 디스크들, 플 래시 메모리들, 또는 EPROM(electrically programmable memories) 또는 EEPROM(electrically erasable and programmable memories)의 형태들을 포함할 수 있다. 추가적으로, 메모리는, 일부 실시예들에서, 비일시적 저장 매체로 간주될 수 있다. \"비일시적\"이란 용어는 저장 매체가 반송파 또는 전파되는 신호로 구현되지 않음 을 나타낼 수 있다. 그러나, \"비일시적\"이란 용어는 메모리가 비이동식인 것으로 해석되지 않아야 한다. 일부 예들에서, 메모리는 메모리보다 더 많은 양의 정보를 저장하도록 구성될 수 있다. 특정한 예들에서, 비-일시적 저장 매체가(예컨대, RAM(Random Access Memory) 또는 캐시에) 시간 경과에 따라 변할 수 있는 데이 터를 저장할 수 있다. 메모리는 내부 저장소 유닛일 수 있거나 또는 이는 전자 기기의 외부 저장소 유닛, 클라우드 저장소, 또는 임의의 다른 유형의 외부 저장소일 수 있다. 프로세서는 메모리 및 통신부와 통신한다. 프로세서는 메모리에 저장된 명령어들을 실행하도록 그리고, 본 개시의 전체에 걸쳐 논의되는 바와 같이, 미디어의 AI 기반 인코딩을 위한 다양한 프로 세스들을 수행하도록 구성된다. 프로세서는 하나 또는 복수의 프로세서들을 포함할 수 있으며, 범용 프로 세서, 이를테면 중앙 프로세싱 유닛(central processing unit, CPU), 애플리케이션 프로세서(application processor, AP) 등, 그래픽 전용 프로세싱 유닛 이를테면 그래픽 프로세싱 유닛(graphics processing unit, GPU), 시각적 프로세싱 유닛(visual processing unit, VPU), 및/또는 인공지능(Artificial intelligence, AI) 전용 프로세서 이를테면 신경 프로세싱 유닛(neural processing unit, NPU)일 수 있다. 통신부는 내부 하드웨어 구성요소들 사이에서 내부적으로 그리고 하나 이상의 네트워크(예컨대, 라디오 기 술)를 통해 외부 기기들(예컨대, 서버)과 통신하도록 구성된다. 통신부는 유선 또는 무선 통신을 가능하게 하는 표준에 특화된 전자 회로를 포함한다. 프로세서는 로직 게이트들, 집적 회로들, 마이크로프로세서들, 마이크로컨트롤러들, 메모리 회로들, 수동 전자 구성요소들, 능동 전자 구성요소들, 광학적 구성요소들, 하드와이어드 회로들 등과 같은 프로세싱 회로에 의해 구현되고, 펌웨어에 의해 옵션적으로 구동될 수 있다. 그 회로들은, 예를 들어, 하나 이상의 반도체 칩 내 에, 또는 인쇄 회로 보드들 등과 같은 기판 지지물들 상에 실시될 수 있다. 본 개시의 일 실시예에서, 프로세서는 이미지 압축부, AI 기반 인루프 필터, 데이터 분포 모델 , 정답값 데이터 분포 모델, RDO 제어 매핑 범위 모듈, 오프셋 스케일링을 위한 화소 매핑 모듈 , 및 최적화된 미디어 생성부를 포함한다. 본 개시의 일 실시예에서, 이미지 압축부는 압축 모듈에 관련되며, AI 기반 인루프 필터는 AI 기반 인루프 필터(302e)에 관련되며, 데이터 분포 모델은 데이터 분포 모델(302f)에 관련되며, 정답값 데 이터 분포 모델은 정답값 데이터 분포 모델(302g)에 관련되며, RDO 제어 매핑 범위 모듈은 RDO 제어 매핑 컨텍스트 모듈(302h)에 관련되며, 오프셋 스케일링을 위한 화소 매핑 모듈은 오프셋 스케일링을 위한 화소 매핑 모듈(302i)에 관련되고, 최적화된 미디어 생성부는 최종 AI 기반 인루프 필터 출력 모듈(302j) 에 관련된다. 이미지 압축부는 전통적인 모듈이며, 이는 입력 비디오를 수신할 수 있다. 입력 비디오를 수신할 시, 이미 지 압축부는 변환, 양자화, 역양자화, 및 역변환과 같은 하나 이상의 미리 정의된 압축 동작들을 수신된 입력 비디오에 대해 수행할 수 있다. AI 기반 인루프 필터는 비디오 코딩의 루프 필터링 프로세스에서 AI 기법들을 적용하도록 구성될 수 있다. AI 기반 인루프 필터는 인루프 필터들(302a, 302b, 302c, 및 302d) 의 성능을 향상시킬 수 있다. AI 기반 인루프 필터는 머신 러닝 모델들을 활용하여 비디오 콘텐츠(예컨대, 입력 비디오 등)의 특성들을 학습하고 적응적 필터링 기법들을 적용할 수 있다. 미리 정의된 규칙들 또는 휴리스틱에 의존하는 대신, AI 기반 인루프 필터는 신경망들 또는 다른 AI 수법들을 사용하여 비디오 콘텐츠를 분석하고 프로세싱할 수 있다. AI 기반 인루프 필터는 AI 모델들을 사용할 수 있으며, AI 모델들은 다량의 훈련 데이터로부터 학습할 수 있고 필터링 동작들에 관한 지능형 결정들을 내릴 수 있다. AI 기반 인루프 필터 는 하나 이상의 재구성된 이미지 프레임을 생성할 수 있고 하나 이상의 재구성된 이미지 프레임을 데이터 분포 모델에 추가 프로세싱을 위해 전송하며, 이는 이하에서 자세히 설명된다. 데이터 분포 모델은, 도 6과 연계하여 설명되는 바와 같이, 제1 대표 데이터 포인트 세트를 생성할 수 있 다. 데이터 분포 모델은 아래에서 주어지는 여러 단계들을 실행하여 제1 대표 데이터 포인트 세트를 생성 할 수 있다. 데이터 분포 모델은 AI 기반 인루프 필터로부터 하나 이상의 재구성된 이미지 프레임(예컨대, 하나 이상의 향상된 이미지 프레임)을 수신할 수 있으며, 여기서 하나 이상의 재구성된 이미지 프레임은 재구성된 비 디오와 연관된다. 데이터 분포 모델은 그런 다음 하나 이상의 재구성된 이미지 프레임 각각에 대한 원하는 압축 레벨을 지시하는 사용자 입력을 수신할 수 있다. 데이터 분포 모델은 그런 다음 수신된 사용자 입력 에 기반하여 하나 이상의 재구성된 이미지 프레임 각각에 대한 단편 수를 결정할 수 있다. 데이터 분포 모델 은 그런 다음 결정된 단편 수에 기반하여 하나 이상의 재구성된 이미지 프레임 각각을 단편화할 수 있다. 데이터 분포 모델은 그런 다음, 각각의 단편화된 이미지 프레임 내의 콘텐츠 변화를, 하나 이상의 분포 메 커니즘을 사용하여, 분석할 수 있다. 데이터 분포 모델은 그런 다음 분석된 콘텐츠 변화에 대해, 하나 이 상의 통계적 메커니즘을 사용하여, 화소 비닝 동작을 수행하여 하나 이상의 최적의 단편화된 이미지 프레임을 결정할 수 있으며, 여기서 하나 이상의 최적의 단편화된 이미지 프레임 각각은 고유 특성을 갖는 화소들의 그룹 을 포함한다. 데이터 분포 모델은 그런 다음 하나 이상의 최적의 단편화된 이미지 프레임 각각에 대한 제1 대표 데이터 포인트 세트를 생성할 수 있다. 정답값 데이터 분포 모델은, 도 7과 연계하여 설명되는 바와 같이, 제2 대표 데이터 포인트 세트를 생성할 수 있다. 정답값 데이터 분포 모델은 아래에서 주어지는 여러 단계들을 실행하여 제2 대표 데이터 포인트 세트를 생성할 수 있다. 정답값 데이터 분포 모델은 입력 비디오와 연관된 하나 이상의 입력 이미지 프레임을 수신할 수 있다. 정 답값 데이터 분포 모델은 그런 다음 하나 이상의 입력 이미지 프레임 각각에 대한 원하는 압축 레벨을 지 시하는 사용자 입력을 수신할 수 있다. 정답값 데이터 분포 모델은 그런 다음 수신된 사용자 입력에 기반 하여 하나 이상의 입력 이미지 프레임 각각에 대한 단편 수를 결정할 수 있다. 정답값 데이터 분포 모델은 그런 다음 결정된 단편 수에 기반하여 하나 이상의 입력 이미지 프레임 각각을 단편화할 수 있다. 정답값 데이 터 분포 모델은 그런 다음 각각의 단편화된 입력 이미지 프레임 내의 콘텐츠 변화를, 하나 이상의 분포 메 커니즘을 사용하여, 분석할 수 있다. 정답값 데이터 분포 모델은 그런 다음 분석된 콘텐츠 변화에 대해, 하나 이상의 통계적 메커니즘을 사용하여, 화소 비닝 동작을 수행하여 하나 이상의 최적의 단편화된 이미지 프 레임을 결정할 수 있으며, 여기서 하나 이상의 최적의 단편화된 이미지 프레임 각각은 고유 특성을 갖는 화소들 의 그룹을 포함한다. 정답값 데이터 분포 모델은 그런 다음 하나 이상의 최적의 단편화된 이미지 프레임 각각에 대한 제2 대표 데이터 포인트 세트를 생성할 수 있다. RDO 제어 매핑 범위 모듈은, 도 4와 연계하여 설명된 바와 같이, RD 비용 모듈의 출력 및 단편 수에 관한 사용자 입력에 기반하여 전체 RD 비용을 결정할 수 있다. RDO 제어 매핑 범위 모듈은 전체 RD 비용을 최소화하는 목적 함수를 추가로 구축할 수 있다. 오프셋 스케일링을 위한 화소 매핑 모듈은, 도 8과 연계하여 설명되는 바와 같이, 재구성된 비디오와 연관 된 각각의 단편화된 이미지 프레임에 대한 제1 대표 데이터 포인트 세트와 입력 비디오와 연관된 각각의 단편화 된 이미지 프레임에 대한 제2 대표 데이터 포인트 세트 사이의 데이터 분포 비유사성 메트릭을 결정할 수 있다. 오프셋 스케일링을 위한 화소 매핑 모듈은 그런 다음, 도 8과 연계하여 설명되는 바와 같이, 데이터 분포 비유사성 메트릭을 이용함으로써 각각의 단편화된 이미지 프레임에 대한 오프셋 값을 추가로 결정할 수 있다. 최적화된 미디어 생성부는, 도 9와 연계하여 설명되는 바와 같이, 결정된 오프셋 값을 이용함으로써 각각 의 단편화된 이미지 프레임과 연관된 각각의 화소 값에 대한 스케일링 동작을 수행할 수 있다. 최적화된 미디어 생성부는 수행된 스케일링 동작에 기반하여 재구성된 비디오를 추가로 인코딩할 수 있다. 전자 기기의 다양한 구성요소들과 연관된 기능은 비휘발성 메모리, 휘발성 메모리, 및 프로세서를 통 해 수행될 수 있다. 하나의 또는 복수의 프로세서들은 비휘발성 메모리 및 휘발성 메모리에 저장된 미리 정의된운영 규칙 또는 AI 모델에 따라 입력 데이터의 프로세싱을 제어한다. 미리 정의된 동작 규칙 또는 AI 모델은 훈 련 또는 학습을 통해 제공된다. 학습을 통해 제공된다는 것은 학습 알고리즘을 복수의 학습 데이터에 적용함으 로써, 원하는 특성의 미리 정의된 동작 규칙 또는 AI 모델이 만들어진다는 것을 의미한다. 학습은 실시예에 따 른 AI가 수행되는 기기 자체에서 수행될 수 있고, 및/또는 별도의 서버/시스템을 통해 구현될 수 있다. 학습 알 고리즘은 타깃 기기가 결정 또는 예측하는 것을 초래, 허용, 또는 제어하기 위해 복수의 학습 데이터를 사용하 여 미리 결정된 타깃 기기(예를 들어, 로봇)를 훈련하는 방법이다. 학습 수법의 예들은 지도 학습, 비지도 학습, 반지도 학습, 또는 강화 학습을 포함하지만, 그것으로 제한되지 않는다. AI 모델은 복수의 신경망 레이어들로 구성될 수 있다. 각각의 레이어는 복수의 가중값 값들을 가지고, 이전의 레이어의 계산 및 복수의 가중값들의 연산을 통해 레이어 연산을 수행한다. 신경망들의 예들은 콘볼루션 신경망 (CNN), 심층 신경망(DNN), 순환 신경망(recurrent neural network, RNN), RBM(restricted Boltzmann Machine), DBN(deep belief network), 양방향성 순환 심층 신경망(bidirectional recurrent deep neural network, BRDNN), GAN(generative adversarial networks), 및 심층 Q 네트워크들을 포함하지만 그것들로 제한 되지 않는다. 도 13a가 전자 기기의 다양한 하드웨어 구성요소들을 도시하지만, 본 개시의 하나 이상의 실시예는 그것으 로 제한되지 않는다는 것이 이해되어야 한다. 본 개시의 하나 이상의 실시예에서, 전자 기기는 더 적거나 또는 더 많은 수의 구성요소들을 포함할 수 있다. 게다가, 구성요소들의 라벨들 또는 이름들은 예시 목적으로만 사용되고 발명의 범위를 제한하지 않는다. 하나 이상의 구성요소는 미디어의 AI 기반 인코딩을 위해 동일한 또 는 실질적으로 유사한 기능들을 수행하도록 결합될 수 있다. 도 13b는 본 개시의 일 실시예에 따른 미디어의 AI 기반 디코딩을 위한 전자 기기의 블록도를 예시한다. 본 개 시의 하나 이상의 실시예에서, 전자 기기는 도 12에 묘사된 하나 이상의 모듈을 포함한다. 전자 기기 의 예들은 스마트폰, 태블릿 컴퓨터, PDA, IoT 기기, 착용가능 기기 등을 포함할 수 있지만, 그것으로 제 한되지 않는다. 일 실시예에서, 전자 기기는 시스템을 포함한다. 시스템은 메모리, 프로세서, 및 통신부를 포함할 수 있다. 일 실시예에서, 메모리는, 본 개시의 전체에 걸쳐 논의되는 바와 같이, 미디어의 AI 기반 디코딩에 대한 프로세서에 의해 실행될 명령어들을 저장한다. 메모리는 비휘발성 저장 요소들을 포함할 수 있다. 이러한 비휘발성 스토리지 요소들의 예들은 자기 하드 디스크들, 광학적 디스크들, 플로피 디스크들, 플래시 메 모리들, 또는 EPROM 또는 EEPROM 메모리들의 행태들을 포함할 수 있다. 추가적으로, 메모리는, 일부 실시 예들에서, 비일시적 저장 매체로 간주될 수 있다. \"비일시적\"이란 용어는 저장 매체가 반송파 또는 전파되는 신 호로 구현되지 않음을 나타낼 수 있다. 그러나, \"비-일시적\"이란 용어는 메모리가 비이동식인 것으로 해 석되지 않아야 한다. 일부 예들에서, 메모리는 메모리보다 더 많은 양의 정보를 저장하도록 구성될 수 있 다. 특정한 예들에서, 비일시적 저장 매체는 (예컨대, RAM 또는 캐시에) 시간 경과에 따라 변화할 수 있는 데이 터를 저장할 수 있다. 메모리는 내부 저장소 유닛일 수 있거나 또는 이는 전자 기기의 외부 저장소 유닛, 클라우드 저장소, 또는 임의의 다른 유형의 외부 저장소일 수 있다. 프로세서는 메모리 및 통신부와 통신한다. 프로세서는 메모리에 저장된 명령어 들을 실행하도록 그리고, 본 개시의 전체에 걸쳐 논의되는 바와 같이, 미디어의 AI 기반 인코딩-디코딩을 위한 다양한 프로세스들을 수행하도록 구성된다. 프로세서는 하나 또는 복수의 프로세서들을 포함할 수 있으며, 범용 프로세서, 이를테면 중앙 프로세싱 유닛(CPU), 애플리케이션 프로세서(AP) 등, 그래픽 전용 프로 세싱 유닛 이를테면 그래픽 프로세싱 유닛(GPU), 시각적 프로세싱 유닛(VPU), 및/또는 인공지능(AI) 전용 프로 세서 이를테면 신경 프로세싱 유닛( NPU)일 수 있다. 통신부는 내부 하드웨어 구성요소들 사이에서 내부적으로 그리고 하나 이상의 네트워크(예컨대, 라디오 기술)를 통해 외부 기기들(예컨대, 서버)과 통신하도록 구성된다. 통신부는 유선 또는 무선 통신을 가능 하게 하는 표준에 특화된 전자 회로를 포함한다. 프로세서는 로직 게이트들, 집적 회로들, 마이크로프로세서들, 마이크로컨트롤러들, 메모리 회로들, 수동 전자 구성요소들, 능동 전자 구성요소들, 광학적 구성요소들, 하드와이어드 회로들 등과 같은 프로세싱 회로에 의해 구현되고, 펌웨어에 의해 옵션적으로 구동될 수 있다. 그 회로들은, 예를 들어, 하나 이상의 반도체 칩 내 에, 또는 인쇄 회로 보드들 등과 같은 기판 지지물들 상에 실시될 수 있다.본 개시의 일 실시예에서, 프로세서는 AI 기반 인루프 필터, 데이터 분포 모델, 오프셋 스케 일링을 위한 화소 매핑 모듈, 및 최적화된 미디어 생성부를 포함한다. 본 개시의 일 실시예에서, AI 기반 인루프 필터는 AI 기반 인루프 필터(1205e)에 관련되며, 데이터 분포 모델은 데이터 분포 모델(1205f)에 관련되며, 오프셋 스케일링을 위한 화소 매핑 모듈은 오프셋 스 케일링을 위한 화소 매핑 모듈(1205g)에 관련되고, 최적화된 미디어 생성부는 최종 AI 기반 인루프 필터 출력 모듈(1205h)에 관련된다. AI 기반 인루프 필터는 비디오 디코딩의 루프 필터링 프로세스에서 AI 기법들을 적용하도록 구성될 수 있 다. AI 기반 인루프 필터는 인루프 필터들(302a, 302b, 302c, 및 302d)의 성능을 향상시킬 수 있다. AI 기반 인루프 필터는 머신 러닝 모델들을 활용하여 비디오 콘텐츠(예컨대, 입력 비디오 등)의 특성들을 학 습하고 적응적 필터링 기법들을 적용할 수 있다. 미리 정의된 규칙들 또는 휴리스틱에 의존하는 대신, AI 기반 인루프 필터는 신경망들 또는 다른 AI 수법들을 사용하여 비디오 콘텐츠를 분석하고 프로세싱할 수 있다. AI 기반 인루프 필터는 AI 모델들을 사용할 수 있으며, AI 모델들은 다량의 훈련 데이터로부터 학습할 수 있고 필터링 동작들에 관한 지능형 결정들을 내릴 수 있다. AI 기반 인루프 필터는 하나 이상의 재구성된 이미지 프레임을 생성할 수 있고 하나 이상의 재구성된 이미지 프레임을 데이터 분포 모델에 추가 프로세 싱을 위해 전송하며, 이는 이하에서 자세히 설명된다. 데이터 분포 모델은, 도 6과 연계하여 설명되는 바와 같이, 제1 대표 데이터 포인트 세트를 생성할 수 있 다. 데이터 분포 모델은 아래에서 주어지는 여러 단계들을 실행하여 제1 대표 데이터 포인트 세트를 생성 할 수 있다. 데이터 분포 모델은 AI 기반 인루프 필터로부터 하나 이상의 재구성된 이미지 프레임(예컨대, 하나 이상의 향상된 이미지 프레임)을 수신할 수 있으며, 여기서 하나 이상의 재구성된 이미지 프레임은 재구성된 비 디오와 연관된다. 데이터 분포 모델은 그런 다음 하나 이상의 재구성된 이미지 프레임 각각에 대한 원하 는 압축 레벨을 지시하는 사용자 입력을 수신할 수 있다. 데이터 분포 모델은 그런 다음 수신된 사용자 입력에 기반하여 하나 이상의 재구성된 이미지 프레임 각각에 대한 단편 수를 결정할 수 있다. 데이터 분포 모 델은 그런 다음 결정된 단편 수에 기반하여 하나 이상의 재구성된 이미지 프레임 각각을 단편화할 수 있 다. 데이터 분포 모델은 그런 다음, 각각의 단편화된 이미지 프레임 내의 콘텐츠 변화를, 하나 이상의 분 포 메커니즘을 사용하여, 분석할 수 있다. 데이터 분포 모델은 그런 다음 분석된 콘텐츠 변화에 대해, 하 나 이상의 통계적 메커니즘을 사용하여, 화소 비닝 동작을 수행하여 하나 이상의 최적의 단편화된 이미지 프레 임을 결정할 수 있으며, 여기서 하나 이상의 최적의 단편화된 이미지 프레임 각각은 고유 특성을 갖는 화소들의 그룹을 포함한다. 데이터 분포 모델은 그런 다음 하나 이상의 최적의 단편화된 이미지 프레임 각각에 대 한 제1 대표 데이터 포인트 세트를 생성할 수 있다. 오프셋 스케일링을 위한 화소 매핑 모듈은, 도 8과 연계하여 설명되는 바와 같이, 인코더로부터의 비트스 트림 정보에 포함된 오프셋 정보에 기반하여 스케일링 동작을 위한 화소 매핑을 수행할 수 있다. 최적화된 미디어 생성부는 화소 매핑에 기반하여 재구성된 이미지 프레임에 대해 스케일링 동작을 수행하 여 스케일링된 이미지 프레임을 생성할 수 있다. 최적화된 미디어 생성부는, 도 9와 연계하여 설명되는 바와 같이, 오프셋 정보(예컨대, 값)를 이용함으로써 각각의 단편화된 이미지 프레임과 연관된 각각의 화소 값 에 대한 스케일링 동작을 수행할 수 있다. 최적화된 미디어 생성부는 스케일링된 이미지 프레임에 기반하 여 출력 비디오를 생성할 수 있다. 추가로, 최적화된 미디어 생성부는 인코더(즉, VVC 인코더 파이프라인)로부터 재구성된 비디오와 연 관된 비트스트림 정보를 수신할 수 있으며, 여기서 비트스트림 정보는 오프셋 값을 포함한다. 최적화된 미디어 생성부는 데이터 분포 모델(1205f)을 사용하여 오프셋 값을 이용함으로써 재구성된 비디오에 대한 모델 출력 데이터 분포를 생성할 수 있다. 최적화된 미디어 생성부는 그런 다음 오프셋 스케일링을 위한 화소 매핑 모듈(1205g)을 사용하여 오프셋 값 및 생성된 모델 출력 데이터 분포를 이용함으로써 재구성된 비디오의 각각의 단편화된 이미지 프레임과 연관된 각각의 화소 값에 대한 스케일링 동작을 수행할 수 있다. 최적화된 미 디어 생성부는 그런 다음 최종 AI 기반 인루프 필터링 출력 모듈(1205h)을 사용함으로써 수행된 스케일링 동작에 기반하여 출력 비디오를 생성할 수 있다. 전자 기기의 다양한 구성요소들과 연관된 기능은 비휘발성 메모리, 휘발성 메모리, 및 프로세서를 통 해 수행될 수 있다. 하나의 또는 복수의 프로세서들은 비휘발성 메모리 및 휘발성 메모리에 저장된 미리 정의된운영 규칙 또는 AI 모델에 따라 입력 데이터의 프로세싱을 제어한다. 미리 정의된 동작 규칙 또는 AI 모델은 훈 련 또는 학습을 통해 제공된다. 학습을 통해 제공된다는 것은 학습 알고리즘을 복수의 학습 데이터에 적용함으 로써, 원하는 특성의 미리 정의된 동작 규칙 또는 AI 모델이 만들어진다는 것을 의미한다. 학습은 실시예에 따 른 AI가 수행되는 기기 자체에서 수행될 수 있고, 및/또는 별도의 서버/시스템을 통해 구현될 수 있다. 학습 알 고리즘은 타깃 기기가 결정 또는 예측하는 것을 초래, 허용, 또는 제어하기 위해 복수의 학습 데이터를 사용하 여 미리 결정된 타깃 기기(예를 들어, 로봇)를 훈련하는 방법이다. 학습 수법의 예들은 지도 학습, 비지도 학습, 반지도 학습, 또는 강화 학습을 포함하지만, 그것으로 제한되지 않는다. AI 모델은 복수의 신경망 레이어들로 구성될 수 있다. 각각의 레이어는 복수의 가중값 값들을 가지고, 이전의 레이어의 계산 및 복수의 가중값들의 연산을 통해 레이어 연산을 수행한다. 신경망들의 예들은 CNN, DNN, RNN, RBM, DBN, BRDNN, GAN, 및 깊은 Q-네트워크들을 포함하지만, 그것들로 제한되지 않는다. 도 13b가 전자 기기의 다양한 하드웨어 구성요소들을 도시하지만, 본 개시의 하나 이상의 실시예는 그것으로 제한되지 않는다는 것이 이해되어야 한다. 본 개시의 하나 이상의 실시예에서, 전자 기기는 더 적거 나 또는 더 많은 수의 구성요소들을 포함할 수 있다. 게다가, 구성요소들의 라벨들 또는 이름들은 예시 목적으 로만 사용되고 발명의 범위를 제한하지 않는다. 하나 이상의 구성요소는 미디어의 AI 기반 인코딩-디코딩을 위 해 동일한 또는 실질적으로 유사한 기능들을 수행하도록 결합될 수 있다. 도 14는 본 개시의 일 실시예에 따른 미디어의 AI 기반 인코딩을 위해 전자 기기에 의해 수행되는 방법을 예시하는 흐름도이다. 단계 1410에서, 방법은 입력 비디오와 연관된 입력 이미지를 압축하는 단계를 포함한다. 본 개시의 일 실 시예에서, 방법은 AI 기반 인루프 필터에 피드하기 위한 입력 비디오를 압축하는 단계를 포함할 수 있으 며, 이는 도 3의 압축 모듈, 인루프 필터(예컨대, LMCS(302a), 블록화제거 필터(302b), SAO(302c), ALF, CC-ALF(302d)), CABAC 모듈 또는 RD 비용 모듈 중 적어도 하나에 관련될 수 있다. 단계 1420에서, 방법은 AI 기반 인루프 필터(302e)를 사용하여 입력 이미지 프레임에 대응하는 재구성된 이미지 프레임을 생성하는 단계를 포함하며, 이는 도 3의 AI 기반 인루프 필터(302e)의 출력에 관련될 수 있다. 단계 1430에서, 방법은 입력 이미지 프레임 및 재구성된 이미지 프레임에 기반하여 오프셋 값을 생성하는 단계를 포함한다. 본 개시의 일 실시예에서, 방법은 재구성된 비디오에 대한 모델 출력 데이터 분포를 생 성하는 단계를 포함할 수 있으며, 이는 도 3의 데이터 분포 모델(302f)에 관련될 수 있다. 방법은 재구성 된 비디오에 대한 모델 출력 데이터 분포를 생성하기 위한 여러 프로세스들을 포함하며, 이는 이후에 나열된다. 방법은 AI 기반 인루프 필터로부터 하나 이상의 재구성된 이미지 프레임을 수신하는 단계를 포함하며, 여 기서 하나 이상의 재구성된 이미지 프레임은 재구성된 비디오와 연관된다. 하나 이상의 재구성된 이미지 프레임 은 하나 이상의 NN 모델을 이용함으로써 생성된다. 방법은 하나 이상의 재구성된 이미지 프레임 각각에 대한 원하는 압축 레벨을 지시하는 사용자 입력을 수신하는 단계를 더 포함한다. 방법은 수신된 사용자 입력에 기반하여 하나 이상의 재구성된 이미지 프레임 각각에 대한 단편 수를 결정하는 단계를 더 포함한다. 방 법은 결정된 단편 수에 기반하여 하나 이상의 재구성된 이미지 프레임 각각을 단편화하는 단계를 더 포함 한다. 방법은 각각의 단편화된 이미지 프레임 내의 콘텐츠 변화를, 하나 이상의 분포 메커니즘을 사용하 여, 분석하는 단계를 더 포함한다. 방법은 하나 이상의 최적의 단편화된 이미지 프레임을 결정하기 위해 분석된 콘텐츠 변화에 대해, 하나 이상의 통계적 메커니즘을 사용하여, 화소 비닝 동작을 수행하는 단계를 더 포함하며, 여기서 하나 이상의 최적의 단편화된 이미지 프레임 각각은 고유 특성을 갖는 화소들의 그룹을 포함 한다. 방법은 하나 이상의 최적의 단편화된 이미지 프레임 각각에 대한 제1 대표 데이터 포인트 세트를 생성하는 단계를 더 포함한다. 본 개시의 일 실시예에서, 방법은 입력 비디오에 대한 정답값 데이터 분포를 생성하는 단계를 포함하며, 이는 도 3의 정답값 데이터 분포 모델(302g)에 관련될 수 있다. 방법은 입력 비디오에 대한 정답값 데이 터 분포를 생성하는 여러 프로세스들을 포함하며, 이는 이후에 나열된다. 방법은 입력 비디오와 연관된 하나 이상의 입력 이미지 프레임을 수신하는 단계를 포함한다. 방법은 하나 이상의 입력 이미지 프레임 각각에 대한 원하는 압축 레벨을 지시하는 사용자 입력을 수신하는 단계를 더 포함한다. 방법은 수신된 사용자 입력에 기반하여 하나 이상의 입력 이미지 프레임 각각에 대한 단편 수를 결정하는 단계를 더 포함한다. 방법은 결정된 단편 수에 기반하여 하나 이상의 입력 이미지 프레임 각각을 단편화하는 단계를 더 포함한 다. 방법은 각각의 단편화된 입력 이미지 프레임 내의 콘텐츠 변화를, 하나 이상의 분포 메커니즘을 사용 하여, 분석하는 단계를 더 포함한다. 방법은 하나 이상의 최적의 단편화된 이미지 프레임을 결정하기 위해 분석된 콘텐츠 변화에 대해, 하나 이상의 통계적 메커니즘을 사용하여, 화소 비닝 동작을 수행하는 단계를 더 포함하며, 하나 이상의 최적의 단편화된 이미지 프레임 각각은 고유 특성을 갖는 화소들의 그룹을 포함한다. 방법은 하나 이상의 최적의 단편화된 이미지 프레임 각각에 대한 제2 대표 데이터 포인트 세트를 생성하 는 단계를 더 포함한다. 본 개시의 일 실시예에서, 방법은 모델 출력 데이터 분포와 정답값 데이터 분포를 비교함으로써 오프셋 값을 결정하는 단계를 포함하며, 이는 도 3의 오프셋 스케일링을 위한 화소 매핑 모듈(302i)에 관련될 수 있다. 방법은 오프셋 값을 결정하기 위한 여러 프로세스들을 포함하며, 이는 이후에 나열된다. 방법은 재 구성된 비디오와 연관된 각각의 단편화된 이미지 프레임에 대한 제1 대표 데이터 포인트 세트와 입력 비디오와 연관된 각각의 단편화된 이미지 프레임에 대한 제2 대표 데이터 포인트 세트 사이의 데이터 분포 비유사성 메트 릭을 결정하는 단계를 포함한다. 방법은 데이터 분포 비유사성 메트릭을 이용함으로써 각각의 단편화된 이미지 프레임에 대한 오프셋 값을 결정하는 단계를 더 포함한다. 단계 1440에서, 방법은 결정된 오프셋 값에 기반하여 재구성된 이미지 프레임을 인코딩하는 단계를 포함 한다. 본 개시의 일 실시예에서, 방법은 결정된 오프셋 값을 이용함으로써 재구성된 비디오를 인코딩하는 단계를 포함할 수 있으며, 이는 도 3의 최종 AI 기반 인루프 필터 출력 모듈(302j), In-loop 필터들(e.g. LMCS(302a), 블록화제거 필터(302b), SAO(302c), ALF, CC-ALF(302d)), CABAC 모듈 또는 RD 비용 모듈 중 적어도 하나에 관련될 수 있다. 방법은 재구성된 비디오를 인코딩하기 위한 여러 프로세스들을 포함하며, 이는 이후에 나열된다. 방법은 결정된 오프셋 값을 이용함으로써 각각의 단편화된 이미지 프레 임과 연관된 각각의 화소 값에 대한 스케일링 동작을 수행하는 단계를 포함하며, 여기서 스케일링 동작은 덧셈 연산, 곱셈 연산, 나눗셈 연산, 또는 지수 연산 중 적어도 하나를 포함한다. 방법은 수행된 스케일링 동 작에 기반하여 재구성된 비디오를 인코딩하는 단계를 더 포함한다. 본 개시의 일 실시예에서, 방법은 재구성된 비디오와 연관된 비트스트림 정보를 디코더에 전송하는 단계 를 포함하며, 여기서 비트스트림 정보는 결정된 오프셋 값을 포함한다. 도 15는 본 개시의 일 실시예에 따른 미디어의 AI 기반 압축을 위한 방법을 예시하는 흐름도이다. 방법 은 방법에 관련될 수 있다. 단계 1510에서, 방법은 입력 미디어에 대한 원하는 압축 레벨을 결정하는 단계를 포함하며, 여기서 원하 는 압축 레벨은 사용자에 의해 지시된다. 단계 1520에서, 방법은 원하는 압축 레벨에 기반하여 입력 미디어를 압축하는 단계를 포함하며, 이는 도 14의 단계 1410 및 단계 1420에 관련될 수 있다. 단계 1530에서, 방법은 압축된 미디어를 입력 미디어와 입력 미디어에 대한 원하는 압축 레벨과 비교함으 로써 입력 미디어에 관해 압축된 미디어에서의 오프셋 값을 결정하는 단계를 포함하며, 이는 도 14의 단계 1430 에 관련될 수 있다. 오프셋 값은 단편별 세분도로 계산되고 사용되며, 여기서 단편 수는 사용자로부터 입력으로 서 수신되고 각각의 단편은 데이터 분포 모델링 동작 동안 계산된다. 방법은 오프셋 값을 결정하기 위한 여러 프로세스들을 포함하며, 이는 이후에 나열된다. 방법은 모델 출력 데이터 분포를 모델링하는 단계를 포함한다. 방법은 정답값 데이터 분포를 모델링하는 단계를 더 포함한다. 방법은 모델링된 모델 출 력 데이터 분포, 모델링된 정답값 데이터 분포, 및 매핑 범위를 사용하여 화소 매핑을 결정하는 단계를 더 포함 한다. 매핑 범위는 RD 비용을 기반으로 특정 단편에 대한 오프셋 스케일링을 적용할 지의 결정이고, 매핑 범위 는 사용자 정의된 단편 수 및 코덱 RD 비용을 사용하여 결정된다. 단계 1540에서, 방법은 결정된 오프셋 값을 압축된 미디어에 더함으로써 최적화된 압축된 미디어를 획득 하는 단계를 포함하며, 이는 도 14의 단계 1440에 관련될 수 있다. 도 16은 본 개시의 일 실시예에 따른 미디어의 AI 기반 디코딩을 위한 방법을 예시하는 흐름도이다. 단계 1610에서, 방법은 인코더로부터 오프셋 정보를 포함하는 비트스트림 정보를 수신하는 단계를 포함한 다. 본 개시의 일 실시예에서, 방법은 인코더로부터 재구성된 비디오와 연관된 비트스트림 정보를 수신하 는 단계를 포함할 수 있으며, 여기서 비트스트림 정보는 오프셋 값을 포함한다. 단계 1620에서, 방법은 AI 기반 인루프 필터를 사용하여 비트스트림 정보에 기반하여 재구성된 이미지 프 레임을 생성하는 단계를 포함하며, 이는 도 12의 CABAC, 역 양자화 모듈, 역변환 모듈, LMCS 모듈, 또는 인루프 필터 중 적어도 하나에 관련될 수 있다. 본 개시의 일 실시예에서, 방법은 오프셋 값을 이용함으로써 재구성된 비디오에 대한 모델 출력 데이터 분포를 포함할 수 있으며, 이는 도 14의 단계 1420에 관련될 수 있다. 단계 1630에서, 방법은 스케일링된 이미지 프레임을 생성하기 위해 오프셋 정보에 기반하여 재구성된 이 미지 프레임에 대한 스케일링 동작을 수행하는 단계를 포함한다. 본 개시의 일 실시예에서, 방법은 오프 셋 값 및 생성된 모델 출력 데이터 분포를 이용함으로써 재구성된 비디오의 각각의 단편화된 이미지 프레임과 연관된 각각의 화소 값에 대한 스케일링 동작을 수행하는 단계를 포함할 수 있으며, 이는 도 14의 단계 1420 또 는 단계 1430 중 적어도 하나에 관련될 수 있다. 스케일링 동작은 덧셈 연산, 곱셈 연산, 나눗셈 연산, 또는 지 수 연산 중 적어도 하나를 포함한다. 단계 1640에서, 방법은 스케일링된 이미지 프레임에 기반하여 출력 비디오를 생성하는 단계를 포함하며, 이는 도 12의 인루프 필터(예컨대, LMCS(1205a), 블록화제거 필터(1205b), SAO(1205c), ALF, CC-ALF(1205d)) 또는 재구성된 이미지 모듈 중 적어도 하나에 관련될 수 있다. 본 개시의 일 실시예에서, 방법은 수행된 스케일링동작에 기반하여 출력 비디오를 생성하는 단계를 포함할 수 있다. 본 개시의 하나 이상의 실시예에서, 비트스트림 정보는 여러 튜닝 가능한 파라미터들을 포함할 수 있다. 파라미 터들은 튜닝 가능한(tunable) 향상 플래그, 튜닝 가능한 클래스 수, 및 오프셋 스케일링을 위한 튜닝 가능한 클 래스 오프셋을 포함할 수 있다. 예를 들어, 튜닝 가능한 향상 플래그는 이진 값이다. 튜닝 가능한 향상 플래그 가 0으로 설정될 때, 이는 비트스트림 정보가 튜닝 가능한 오프셋에 관련된 구문 요소들을 포함하지 않음을 나 타낸다. 결과적으로, 이들 구문 요소들은 재구성 프로세스(도 12 참조)에서 사용될 수 없다. 튜닝 가능한 클래 스 수는 프로세싱(예컨대, 디코딩) 동안 고려될 클래스 수를 결정하기 위해 사용자의 요건들에 기반하여 조정될 수 있는 다른 파라미터이다. 추가로, 튜닝 가능한 클래스 오프셋 파라미터는 각각의 화소 클래스에 적용될 특정 오프셋들을 특정한다. 이들 오프셋들은 각각의 클래스 내 화소들의 특성들을 수정할 수 있다. 비트스트림 정보 내의 이들 파라미터들을 튜닝함으로써, 개시된 방법은 상이한 시나리오들 및 사용자 선호사항들에 적용하여, 데 이터의 사용자 정의 가능하고 유연한 프로세싱을 허용할 수 있다. 본 개시의 하나 이상의 실시예에서, 개시된 방법은, 도 3 내지 도 16과 연계하여 설명되는 바와 같이, 데이터 도메인 간극들을 줄이기 위해 더 새롭고 보이지 않는 데이터에 맞추어 조정하는 추가적인 실시간 모듈을 이용한 AI 기반 모델을 위한 고유 전략을 제공한다. 개시된 방법은 화소 매핑과 콘텐츠 기반 스케일링을 사용하여 AI 기반 인루프 필터들에서 더 새로운/보이지 않는 데이터와 훈련 데이터 사이의 데이터 도메인 간극을 메운다. 그 결과, 개시된 방법은, 특정 아티팩트들을 타깃으로 하고 제한된 데이터를 사용하여 자주 훈련되어 AI 기반 훈련 모델들에 내재적인 바이어스 및 변동성을 초래하는 기존의 방법들을 능가한다. 개시된 방법은 오프셋 값을 스케 일링하기 위한 화소 매핑을 식별하기 위한 콘텐츠 기반 스케일링을 가능하게 할 수 있으며, 즉석에서 동작하며, 사전 훈련을 요구하지 않고, 상이한 유형들의 데이터에 대한 더 많은 일반화를 제공할 수 있다. 더욱이, 개시된 방법은 기존 방법들과 비교할 때 복잡도가 매우 낮은데, 기존의 방법들이 매우 복잡한 DNN 모델들을 전개하여 더 높은 이득을 달성하지만 그 방법들은 콘텐츠 기반으로 적응적이지 않기 때문이다. 개시된 방법은 인코딩 프 로세스 동안 비디오 데이터 기반 통계적 회귀를 도입하고 디코딩 프로세스 동안 동일한 회귀를 사용함으로써 이 문제를 해결한다. 특정 아티팩트들을 타깃으로 하고 제한된 데이터에 의존하는 기존의 방법들과 달리, 개시된 방법은 콘텐츠 기반 스케일링을 사용하여 데이터 도메인 간극들을 메우고 상이한 유형들의 데이터에 대한 더 많은 일반화를 제공한 다. 개시된 방법의 핵심 장점들 중 하나는 사전 훈련을 요구하지 않고 오프셋을 스케일링하기 위한 화소 매핑 을 식별하는 능력이다. 이는 데이터가 계속해서 변경되는 동적 환경들에서 매우 중요한 즉석 조정들을 허용한다. 추가로, 개시된 방법은 더 높은 이득을 달성하기 위해 복잡한 DNN 모델에 의존하는 기존의 방법들과 비교하여 복잡도가 훨씬 가볍다. 개시된 방법은 또한 인코딩 프로세스 및 디코딩 프로세스 동안 비디오 데이터 기반 통계적 회귀를 도입함으로써 AI 기반 훈련된 모델들에서 바이어스 및 변동성의 문제를 해결한다. 이는 개 시된 방법이 콘텐츠 기반으로 적응적이고 더 정확한 예측들을 제공하는 것을 보장한다. 전반적으로, 개시된 방 법은 AI 기반 모델들을 개선하고 더 새롭고 보이지 않는 데이터에 의해 부과된 도전과제들을 해결하는 강력한 도구를 제공한다. 콘텐츠 기반 스케일링을 수행하며, 데이터 도메인 간극들을 메우고, 더 많은 일반화를 제공하 는 능력을 갖는 전자 기기가 많은 동작들(예컨대, 인코딩, 디코딩 등)에서 AI 기술을 활용하려는 조직에 필수적인 도구가 되게 한다. 본 개시의 하나 이상의 실시예에서, 개시된 방법은 전자 기기에서 인코더 및 디코더의 효율을 개선하는 잠 재력을 가짐으로써, 전자 기기에서 비디오 기록 및 메모리 요건들을 감소시킨다. 추가로, 개시된 방법은대역폭 제한된 시나리오들에서도 우수한 비디오 품질을 가능하게 한다. 개시된 방법은 전체 사용자 경험 및 만 족도를 크게 향상시킬 수 있다. 이러하 이점은 비디오 콘텐츠 소비가 일반화되고 대역폭 제한이 만연한 요즘 세 상에서 특히 관련이 있다. 본 개시의 하나 이상의 실시예에서, 개시된 방법은 BD 레이트(Bjontegaard-delta rate)를 향상시킬 수 있다. BD 레이트는 전체 파이프라인의 전체 압축 효율을 측정한다. 추가로, 개시된 방법은 대역폭 요건들을 일정하게 유 지하면서도 왜곡을 줄임으로써 시각적 품질을 향상시킨다. 더욱이, 개시된 방법은 또한 동일한 시각적 품질을 유지하면서 비트스트림 또는 대역폭 요건들을 감소시킬 수 있다. 더욱이, 개시된 방법은 시각적 품질을 개선할 수 있고 또한 대역폭 요건들을 줄일 수 있다. 이들 특징들은 비디오 스트리밍 서비스들을 개선함에 있어서 개시 된 방법을 가치 있는 자산으로 만든다. 본 개시의 일 실시예에서, 미디어의 AI 기반 인코딩을 위한 방법이 입력 비디오와 연관된 입력 이미지 프레임을 압축하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 이 방법은 AI 기반 인루프 필터를 사용하여 입력 이미지 프레임에 대응하는 재구성된 이미지 프레임을 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 서, 이 방법은 입력 이미지 프레임 및 재구성된 이미지 프레임에 기반하여 오프셋 값을 결정하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 이 방법은 결정된 오프셋 값에 기반하여 재구성된 이미지 프레임을 인코딩 하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 입력 이미지 프레임 및 재구성된 이미지 프레임에 기반하여 오프셋 값을 결정하는 단 계는 재구성된 이미지 프레임에 대한 모델 출력 데이터 분포를 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 입력 이미지 프레임 및 재구성된 이미지 프레임에 기반하여 오프셋 값을 결정하는 단계는 입력 이 미지 프레임에 대한 정답값 데이터 분포를 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 입력 이 미지 프레임 및 재구성된 이미지 프레임에 기반하여 오프셋 값을 결정하는 단계는 모델 출력 데이터 분포와 정 답값 데이터 분포를 비교함으로써 오프셋 값을 결정하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 재구성된 이미지 프레임에 대한 모델 출력 데이터 분포를 생성하는 단계는 사용자 입 력에 기반하여 재구성된 이미지 프레임에 대한 단편 수를 식별하는 단계를 포함할 수 있다. 본 개시의 일 실시 예에서, 재구성된 이미지 프레임에 대한 모델 출력 데이터 분포를 생성하는 단계는 재구성된 이미지 프레임 내 의 콘텐츠 변화를, 하나 이상의 분포 메커니즘을 사용하여, 분석하는 단계를 포함할 수 있다. 본 개시의 일 실 시예에서, 재구성된 이미지 프레임에 대한 모델 출력 데이터 분포를 생성하는 단계는 최적의 단편화된 이미지 프레임을 생성하기 위해 결정된 단편 수 및 분석된 콘텐츠 변화에 기반하여 재구성된 이미지 프레임을 단편화하 는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 재구성된 이미지 프레임에 대한 모델 출력 데이터 분포를 생성하는 단계는 최적의 단편화된 이미지 프레임의 하나 이상의 단편에 대해, 하나 이상의 통계적 메커니즘을 사용하여, 화소 비닝 동작을 수행하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 최적의 단편화된 이미 지 프레임은 고유 특성을 갖는 화소들의 그룹을 포함할 수 있다. 본 개시의 일 실시예에서, 재구성된 이미지 프 레임에 대한 모델 출력 데이터 분포를 생성하는 단계는 화소 비닝 동작에 기반하여 최적의 단편화된 이미지 프 레임에 대한 제1 대표 데이터 포인트 세트를 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 입력 이미지 프레임에 대한 정답값 데이터 분포를 생성하는 단계는 사용자 입력에 기 반하여 입력 이미지 프레임에 대한 단편 수를 식별하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 입력 이미지 프레임에 대한 정답값 데이터 분포를 생성하는 단계는 입력 이미지 프레임 내의 콘텐츠 변화를, 하나 이 상의 분포 메커니즘을 사용하여, 분석하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 입력 이미지 프레 임에 대한 정답값 데이터 분포를 생성하는 단계는 최적의 단편화된 입력 이미지 프레임을 생성하기 위해 결정된 단편 수 및 분석된 콘텐츠 변화에 기반하여 입력 이미지 프레임을 단편화하는 단계를 포함할 수 있다. 본 개시 의 일 실시예에서, 입력 이미지 프레임에 대한 정답값 데이터 분포를 생성하는 단계는 최적의 단편화된 입력 이 미지 프레임의 하나 이상의 단편에 대해, 하나 이상의 통계적 메커니즘을 사용하여, 화소 비닝 동작을 수행하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 최적의 단편화된 입력 이미지 프레임은 고유 특성을 갖는 화 소들의 그룹을 포함할 수 있다. 본 개시의 일 실시예에서, 입력 이미지 프레임에 대한 정답값 데이터 분포를 생 성하는 단계는 화소 비닝 동작에 기반하여 최적의 단편화된 입력 이미지 프레임에 대한 제2 대표 데이터 포인트 세트를 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 모델 출력 데이터 분포와 정답값 데이터 분포를 비교함으로써 오프셋 값을 결정하는 단계는 재구성된 이미지 프레임으로부터의 단편화된 이미지 프레임에 대한 제1 대표 데이터 포인트 세트와 입력 이미지 프레임으로부터의 단편화된 입력 이미지 프레임에 대한 제2 대표 데이터 포인트 세트 사이의 데이터 분포 비유사성 메트릭을 결정하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 모델 출력 데이터 분포와 정 답값 데이터 분포를 비교함으로써 오프셋 값을 결정하는 단계는 데이터 분포 비유사성 메트릭에 기반하여 오프 셋 값을 결정하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 모델 출력 데이터 분포와 정답값 데이터 분포를 비교함으로써 오프셋 값을 결정하는 단계는 모델 출력 데이터 분포, 정답값 데이터 분포, 및 매핑 범위를 사용하여 단편별 오프셋의 형태로 화소 매 핑을 결정하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 매핑 범위는 RD 비용을 기반으로 특정 단편에 대한 오프셋 스케일링을 적용할 지의 결정일 수 있다. 본 개시의 일 실시예에서, 매핑 범위는 단편 수 및 코덱 RD 비용에 기반하여 결정될 수 있다. 본 개시의 일 실시예에서, 재구성된 이미지 프레임의 인코딩하는 단계는 스케일링된 이미지 프레임을 생성하기 위해 결정된 오프셋 값에 기반하여 재구성된 이미지 프레임에 대한 스케일링 동작을 수행하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 스케일링 동작은 덧셈 연산, 곱셈 연산, 나눗셈 연산, 또는 지수 연산 중 적어 도 하나를 포함할 수 있다. 본 개시의 일 실시예에서, 재구성된 이미지 프레임의 인코딩은 스케일링된 이미지 프레임을 인코딩하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 재구성된 이미지 프레임은 AI 기반 인루프 필터의 하나 이상의 신경망(NN) 모델을 이 용함으로써 생성될 수 있다. 본 개시의 일 실시예에서, 이 방법은 재구성된 이미지 프레임과 연관된 비트스트림 정보를 디코더에 전송하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 비트스트림 정보는 결정된 오프셋 값을 포함할 수 있다. 본 개시의 일 실시예에서, 오프셋 값은 단편별 세분도로 계산되고 사용될 수 있다. 본 개시의 일 실시예에서, 미디어의 AI 기반 디코딩을 위한 방법이 인코더로부터 오프셋 정보를 포함하는 비트 스트림 정보를 수신하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 이 방법은 AI 기반 인루프 필터를 사용하여 비트스트림 정보에 기반하여 재구성된 이미지 프레임을 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 이 방법은 스케일링된 이미지 프레임을 생성하기 위해 오프셋 정보에 기반하여 재구성된 이미지 프레임에 대한 스케일링 동작을 수행하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 이 방법은 스케일 링된 이미지 프레임에 기반하여 출력 비디오를 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 재구성된 이미지 프레임에 대해 스케일링 동작을 수행하는 단계는 재구성된 이미지 프레임에 대한 모델 출력 데이터 분포를 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 재구성된 이미지 프레임에 대해 스케일링 동작을 수행하는 단계는 오프셋 정보 및 모델 출력 데이터 분포에 기반하여 스 케일링 동작을 위한 화소 매핑을 수행하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 재구성된 이미지 프레임에 대해 스케일링 동작을 수행하는 단계는 스케일링된 이미지 프레임을 생성하기 위해 화소 매핑에 기반 하여 재구성된 이미지 프레임에 대해 스케일링 동작을 수행하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 스케일링 동작은 덧셈 연산, 곱셈 연산, 나눗셈 연산, 또는 지수 연산 중 적어도 하 나를 포함할 수 있다. 미디어의 AI 기반 인코딩을 위한 시스템은 메모리 및 통신부에 동작적으로 연결되는 프로세서를 포함할 수 있다. 본 개시의 일 실시예에서, 프로세서는 입력 비디오와 연관된 입력 이미지 프레임을 압축하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 AI 기반 인루프 필터를 사용하여 입력 이미지 프레임에 대응하는 재구성된 이미지 프레임을 생성하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 입력 이미지 프레 임 및 재구성된 이미지 프레임에 기반하여 오프셋 값을 결정하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 결정된 오프셋 값에 기반하여 재구성된 이미지 프레임을 인코딩하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 재구성된 이미지 프레임에 대한 모델 출력 데이터 분포를 생성하도록 구 성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 입력 이미지 프레임에 대한 정답값 데이터 분포를 생성하 도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 모델 출력 데이터 분포와 정답값 데이터 분포를 비 교함으로써 오프셋 값을 결정하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 사용자 입력에 기반하여 재구성된 이미지 프레임에 대한 단편 수를 식별 하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 재구성된 이미지 프레임 내의 콘텐츠 변화를, 하 나 이상의 분포 메커니즘을 사용하여, 분석하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 최적 의 단편화된 이미지 프레임을 생성하기 위해 결정된 단편 수 및 분석된 콘텐츠 변화에 기반하여 재구성된 이미지 프레임을 단편화하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 최적의 단편화된 이미지 프레 임의 하나 이상의 단편에 대해, 하나 이상의 통계적 메커니즘을 사용하여, 화소 비닝 동작을 수행하도록 구성될 수 있다. 본 개시의 일 실시예에서, 최적의 단편화된 이미지 프레임은 고유 특성을 갖는 화소들의 그룹을 포함 할 수 있다. 본 개시의 일 실시예에서, 프로세서는 화소 비닝 동작에 기반하여 최적의 단편화된 이미지 프레임 에 대한 제1 대표 데이터 포인트 세트를 생성하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 사용자 입력에 기반하여 입력 이미지 프레임에 대한 단편 수를 식별하도 록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 입력 이미지 프레임 내의 콘텐츠 변화를, 하나 이상 의 분포 메커니즘을 사용하여, 분석하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 최적의 단편 화된 이미지 프레임을 생성하기 위해 결정된 단편 수 및 분석된 콘텐츠 변화에 기반하여 입력 이미지 프레임을 단편화하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 최적의 단편화된 입력 이미지 프레임의 하 나 이상의 단편에 대해, 하나 이상의 통계적 메커니즘을 사용하여, 화소 비닝 동작을 수행하도록 구성될 수 있 다. 본 개시의 일 실시예에서, 최적의 단편화된 입력 이미지 프레임은 고유 특성을 갖는 화소들의 그룹을 포함 할 수 있다. 본 개시의 일 실시예에서, 프로세서는 화소 비닝 동작에 기반하여 최적의 단편화된 입력 이미지 프 레임에 대한 제2 대표 데이터 포인트 세트를 생성하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 재구성된 이미지 프레임으로부터의 단편화된 이미지 프레임에 대한 제1 대표 데이터 포인트 세트와 입력 이미지 프레임으로부터의 단편화된 입력 이미지 프레임에 대한 제2 대표 데이 터 포인트 세트 사이의 데이터 분포 비유사성 메트릭을 결정하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 데이터 분포 비유사성 메트릭에 기반하여 오프셋 값을 결정하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 모델 출력 데이터 분포, 정답값 데이터 분포, 및 매핑 범위를 사용하여 단편별 오프셋의 형태로 화소 매핑을 결정하도록 구성될 수 있다. 본 개시의 일 실시예에서, 매핑 범위는 RD 비용을 기반으로 특정 단편에 대한 오프셋 스케일링을 적용할 지의 결정일 수 있다. 본 개시의 일 실시예에서, 매핑 범위는 단편 수 및 코덱 RD 비용에 기반하여 결정될 수 있다. 본 개시의 일 실시예에서, 프로세서는 스케일링된 이미지 프레임을 생성하기 위해 결정된 오프셋 값에 기반하여 재구성된 이미지 프레임에 대한 스케일링 동작을 수행하도록 구성될 수 있다. 본 개시의 일 실시예에서, 스케일 링 동작은 덧셈 연산, 곱셈 연산, 나눗셈 연산, 또는 지수 연산 중 적어도 하나를 포함할 수 있다. 본 개시의 일 실시예에서, 프로세서는 스케일링된 이미지 프레임을 인코딩하도록 구성될 수 있다. 본 개시의 일 실시예에서, 재구성된 이미지 프레임은 AI 기반 인루프 필터의 하나 이상의 신경망(NN) 모델을 이 용함으로써 생성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 재구성된 이미지 프레임과 연관된 비트스트림 정보를 디코더에 전송하도 록 구성될 수 있으며, 본 개시의 일 실시예에서, 비트스트림 정보는 결정된 오프셋 값을 포함할 수 있다. 본 개시의 일 실시예에서, 오프셋 값은 단편별 세분도로 계산되고 사용될 수 있다. 미디어의 AI 기반 디코딩을 위한 시스템은 메모리 및 통신부에 동작적으로 연결되는 프로세서를 포함할 수 있다. 본 개시의 일 실시예에서, 프로세서는 인코더로부터 오프셋 정보를 포함하는 비트스트림 정보를 수신하도 록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 AI 기반 인루프 필터를 사용하여 비트스트림 정보에 기반하여 재구성된 이미지 프레임을 생성하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 스케일 링된 이미지 프레임을 생성하기 위해 오프셋 정보에 기반하여 재구성된 이미지 프레임에 대한 스케일링 동작을 수행하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 스케일링된 이미지 프레임에 기반하여 출력 비디오를 생성하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 재구성된 이미지 프레임에 대한 모델 출력 데이터 분포를 생성하도록 구 성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 오프셋 정보 및 모델 출력 데이터 분포에 기반하여 스케일 링 동작을 위한 화소 매핑을 수행하도록 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 스케일링된 이 미지 프레임을 생성하기 위해 화소 매핑에 기반하여 재구성된 이미지 프레임에 대해 스케일링 동작을 수행하도 록 구성될 수 있다. 본 개시의 일 실시예에서, 스케일링 동작은 덧셈 연산, 곱셈 연산, 나눗셈 연산, 또는 지수 연산 중 적어도 하 나를 포함할 수 있다. 본 개시의 일 실시예에 따르면, 이미지 프레임에 대해 수행되고 있는 것으로서 설명되는 하나 이상의 동작은 이 미지 프레임을 포함하는 비디오에 대해 수행될 수 있고, 마찬가지로, 비디오에 대해 수행되고 있는 것으로서 설 명되는 하나 이상의 동작은 비디오에 포함되는 이미지 프레임에 대해 수행될 수 있다. 이 방법에서의 다양한 액션들, 액트들, 블록들, 단계들 등은 제시된 순서로, 상이한 순서로 또는 동시에 수행될 수 있다. 게다가, 일부 실시예들에서, 액션들, 액트들, 블록들, 단계들 등의 일부는 본 발명의 범위로부 터 벗어남 없이 생략, 추가, 수정, 스킵 등이 될 수 있다."}
{"patent_id": "10-2025-7002758", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "달리 정의되지 않으면, 본 개시에서 사용되는 모든 기술적 및 과학적 용어들은 본 발명이 속한 기술분야의 통상 의 기술자가 통상적으로 이해하는 것과 동일한 의미를 가진다. 본 개시에서 제공되는 시스템, 방법들, 및 예들 은 예시적일 뿐이고 제한하는 것으로 의도되지 않는다. 특정 언어표현이 본원의 주제를 설명하는 데 사용되었지만, 그것 때문에 발생하는 임의의 제한들은 의도되지 않 는다. 본 기술의 통상의 기술자에게 명백할 바와 같이, 본 개시에서 교시되는 바와 같은 발명적 개념을 구현하 기 위해 본 방법에 대해 다양한 작업 수정들이 이루어질 수 있다. 도면들과 앞서의 설명은 실시의 예들을 제공"}
{"patent_id": "10-2025-7002758", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "한다. 본 기술분야의 통상의 기술자들은 설명된 요소들의 하나 이상이 단일 기능 요소로 잘 결합될 수 있다는 것을 이해할 것이다. 대안적으로, 특정한 요소들이 다수의 기능성 요소들로 분할될 수 있다. 일 실시예로부터의 요소들이 다른 실시예에 추가될 수 있다. 본원에서 개시되는 실시예들은 적어도 하나의 하드웨어 기기를 사용하여 구현되고 네트워크 관리 기능들을 수행 하여 요소들을 제어할 수 있다. 특정 실시예들의 앞서의 설명은, 다른 사람들이, 현재의 지식을 적용함으로써, 일반적인 개념으로부터 벗어남 없이 이러한 특정 실시예들을 다양한 응용들을 위해 쉽사리 수정 및/또는 적응시킬 수 있는 본 개시에서의 실시 예들의 일반적인 성질을 충분히 드러낼 것이고, 그러므로, 이러한 개조들 및 수정들은 개시된 실시예들의 동등 물들의 의미 및 범위 내에서 이해되어야 하고 이해되도록 의도된다. 본 개시에서 채용되는 어법 또는 용어는 설 명의 목적을 위한 것이고 제한하는 것이 아님이 이해되어야 한다. 그러므로, 본 명세서에서의 실시예들이 바람"}
{"patent_id": "10-2025-7002758", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "직한 실시예들의 측면에서 설명되었지만, 관련 기술분야의 통상의 기술자들은 본 명세서에서의 실시예들이 본원 에서 설명되는 바와 같은 실시예들의 범위 내에서 수정하여 실시될 수 있다는 것이 인식될 것이다."}
{"patent_id": "10-2025-7002758", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 이들 및 다른 특징들, 양태들, 및 장점들은 유사한 문자들이 도면들 전체에 걸쳐 유사한 부분들을 나 타내는 첨부 도면들을 참조하여 다음의 상세한 설명이 읽힐 때 더 잘 이해될 것이며, 도면들 중: 도 1a는 관련 기술에 따른 인공지능(AI) 기반 모델에서 바이어스와 분산 사이의 절충을 시각화하기 위한 예시적 인 시나리오를 예시하며; 도 1b는 관련 기술에 따른 훈련 데이터로부터의 학습된 바이어스 및 분산에 기반한 AI 기반 모델의 한계를 예시 하며; 도 2a는 관련 기술에 따른 기존의 다용도 비디오 코딩(versatile video coding, VVC) 디코더의 블록도를 예시하 며; 도 2b는 관련 기술에 따른 AI 기반 인루프 필터가 있는 기존의 VVC 디코더 파이프라인을 예시하며; 도 3은 본 개시의 일 실시예에 따른 미디어의 AI 기반 인코딩을 위한 VVC 인코더 파이프라인의 블록도를 예시하 며; 도 4는 관련 기술에 따른 미디어의 AI 기반 인코딩을 위한 각각의 압축된 이미지 프레임에 대한 레이트 왜곡 (rate-distortion, RD) 비용 값을 결정하기 위한 레이트 왜곡 선도를 예시하며; 도 5는 관련 기술에 따른 미디어의 AI 기반 인코딩을 위한 각각의 압축된 이미지 프레임의 품질을 향상시키기 위한 AI 기반 인루프 필터와 연관된 심층 콘볼루션 신경망들(deep convolutional neural networks, DCNN들)의 전형적인 아키텍처를 예시하며; 도 6은 본 개시의 일 실시예에 따른 제1 대표 데이터 포인트 세트를 생성하기 위한 예시적인 시나리오를 예시하 며; 도 7은 본 개시의 일 실시예에 따른 제2 대표 데이터 포인트 세트를 생성하기 위한 예시적인 시나리오를 예시하 며; 도 8은 본 개시의 일 실시예에 따른 미디어의 AI 기반 인코딩을 위한 오프셋 스케일링을 위한 화소 매핑을 생성 하기 위한 예시적인 시나리오를 예시하며; 도 9는 본 개시의 일 실시예에 따른 오프셋 스케일링을 생성하기 위한 예시적인 시나리오를 예시하며; 도 10 및 도 11은 본 개시의 일 실시예에 따른 도메인을 모델링하는 여러 방법들을 예시하며; 도 12는 본 개시의 일 실시예에 따른 미디어의 AI 기반 인코딩을 위한 VVC 디코더 파이프라인의 블록도를 예시 하며; 도 13a는 본 개시의 일 실시예에 따른 미디어의 AI 기반 인코딩을 위한 전자 기기의 블록도를 예시하며; 도 13b는 본 개시의 일 실시예에 따른 미디어의 AI 기반 디코딩을 위한 전자 기기의 블록도를 예시하며; 도 14는 본 개시의 일 실시예에 따른 미디어의 AI 기반 인코딩을 위한 방법을 예시하는 흐름도이며; 도 15는 본 개시의 일 실시예에 따른 미디어의 AI 기반 압축을 위한 방법을 예시하는 흐름도이며; 그리고도 16은 본 개시의 일 실시예에 따른 미디어의 AI 기반 디코딩을 위한 방법을 예시하는 흐름도이다. 게다가, 통상의 기술자들은 도면들에서의 그들 요소들이 단순화를 위해 예시되고 반드시 축척대로 그려지지 않 을 수 있다는 것을 이해할 것이다. 예를 들어, 흐름도들은 본 발명의 양태들의 이해를 개선하는 것을 돕는 것에 수반하는 가정 두드러진 단계들의 측면에서의 방법을 예시한다. 더욱이, 기기의 구성의 측면에서, 기기의 하나 이상의 구성요소는 기존의 심볼들에 의해 도면들에서 나타내어질 수 있고, 그 도면들은 본 개시의 설명의 혜택"}
{"patent_id": "10-2025-7002758", "section": "도면", "subsection": "도면설명", "item": 2, "content": "을 누리는 당해 기술분야의 통상의 기술자에게 쉽사리 명확하게 될 세부사항들로 도면들을 모호하게 하지 않기 위하여 본 발명의 실시예들을 이해하는 것에 적절한 그들 특정 세부사항들만을 도시할 수 있다."}
