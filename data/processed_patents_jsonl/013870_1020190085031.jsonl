{"patent_id": "10-2019-0085031", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0008647", "출원번호": "10-2019-0085031", "발명의 명칭": "레이더 장치와 영상 처리를 이용하여 차종, 속도, 통행량을 검지하는 장치 및 방법", "출원인": "인하대학교 산학협력단", "발명자": "권장우"}}
{"patent_id": "10-2019-0085031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "무인교통단속 시스템에 있어서, 제1 전자 기기에 설정된 검지 영역에 기초하여 획득된 제1 정보 및 제2 전자 기기를 이용하여 상기 검지 영역에존재하는 차량을 촬영함에 따라 획득된 상기 제2 정보를 결합한 결합 정보를 교통단속을 위하여 구성된 학습 모델을 통하여 학습시키는 학습부; 및 상기 학습된 학습 결과로부터 상기 검지 영역에서의 차량에 대한 단속 정보를 포함하는 차량 정보를 제공하는도출부를 포함하는 무인교통단속 시스템."}
{"patent_id": "10-2019-0085031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 학습부는,상기 제1 정보 및 상기 제2 정보를 결합한 결합 정보를 이용하여 상기 검지 영역의 측정 시작 지점으로부터 상기 측정 종료 지점까지의 시간 차이 정보에 기초하여 상기 차량의 속도 정보를 판단하는것을 특징으로 하는 무인교통단속 시스템."}
{"patent_id": "10-2019-0085031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 학습부는,상기 제1 정보 및 상기 제2 정보를 결합한 결합 정보를 이용하여 교통단속을 위한 딥러닝 기반의 학습 모델을구성하고, 상기 구성된 학습 모델에 상기 제1 정보 및 상기 제2 정보를 결합한 결합 정보를 입력함에 따라 상기검지 영역에서의 상기 차량이 위치하는 차선 정보, 상기 차량의 차종 및 차량의 번호를 판단하는 것을 특징으로 하는 무인교통단속 시스템."}
{"patent_id": "10-2019-0085031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 도출부는,상기 제1 정보 및 상기 제2 정보를 결합한 결합 정보에 기초하여 획득된 학습 결과로부터 상기 검지 영역에서의차량의 정상 주행 여부, 차량의 차선 위반 여부를 포함하는 차량의 단속 정보를 도출하고, 상기 도출된 차량의단속 정보, 및 상기 차량과 관련된 차량이 위치하는 차선 정보, 상기 차량의 차종 및 차량의 번호를 포함하는차량 정보를 제공하는 것을 특징으로 하는 무인교통단속 시스템."}
{"patent_id": "10-2019-0085031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 도출부는,상기 검지 영역에서의 상기 단속 정보가 포함된 차량에 대한 차량 정보를 상기 단속 정보가 미포함된 차량에 대한 차량 정보와 구분하여 표시하는 공개특허 10-2021-0008647-3-것을 특징으로 하는 무인교통단속 시스템."}
{"patent_id": "10-2019-0085031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제1 전자 기기는, 레이더(RADAR), 레이저(RASER), 라이다(LIDAR) 중 적어도 하나 이상을 포함하고, 상기제2 전자 기기는, 카메라를 포함하고, 상기 레이더(RADAR), 상기 레이저(RASER) 또는 상기 라이다(LIDAR) 중 적어도 하나 이상의 기기에 설정된 검지영역에 기초하여 레이더 정보, 레이저 정보 또는 라이다 정보 중 적어도 하나 이상의 정보를 획득하는 제1 정보획득부; 및 상기 카메라를 이용하여 상기 검지 영역에 존재하는 차량의 영상 정보를 획득하는 제2 정보 획득부를 포함하는 무인교통단속 시스템."}
{"patent_id": "10-2019-0085031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "무인교통단속 시스템에 의해 수행되는 교통 단속 방법에 있어서, 제1 전자 기기에 설정된 검지 영역에 기초하여 획득된 제1 정보 및 제2 전자 기기를 이용하여 상기 검지 영역에존재하는 차량을 촬영함에 따라 획득된 제2 정보를 결합한 결합 정보를 교통단속을 위하여 구성된 학습 모델을통하여 학습시키는 단계; 및 상기 학습된 학습 결과로부터 상기 검지 영역에서의 차량에 대한 단속 정보를 포함하는 차량 정보를 제공하는단계를 포함하는 교통 단속 방법."}
{"patent_id": "10-2019-0085031", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "비접촉식 방식의 무인교통단속시스템이 개시된다. 일 실시예에 따른 무인교통단속 시스템은, 제1 전자 기기에 설정된 검지 영역에 기초하여 제1 정보를 획득하는 데이터 획득부; 제2 전자 기기를 이용하여 상기 검지 영역에 존재하는 차량을 촬영함에 따라 제2 정보를 획득하는 영상 획득부; 상기 제1 정보 및 상기 제2 정보를 결합한 결 합 정보를 교통단속을 위하여 구성된 학습 모델을 통하여 학습시키는 학습부; 및 상기 학습된 학습 결과로부터 상기 검지 영역에서의 차량에 대한 단속 정보를 포함하는 차량 정보를 제공하는 도출부를 포함할 수 있다."}
{"patent_id": "10-2019-0085031", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 레이더 장치와 영상 처리를 이용하여 차종, 속도, 통행량을 검지하는 비접촉 방식의 무인교통단 속장비에 관한 것이다."}
{"patent_id": "10-2019-0085031", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현대 사회에 진입하면서 차량의 양은 급속하게 증가되어 왔고 동시에 교통 혼잡 역시 꾸준히 증가해왔다. 그에 따른 운영 및 제어 방법 역시 다양하게 제시되어 왔다. 최근에는 다양한 검지수단을 이용해 차량을 검지한 후 검지 데이터를 활용해 관리하고 모니터링 하는데 이를 지능형 교통정보 시스템(ITS: Intelligent Transportation System)이라고 한다. 차량을 검지하는 방법에는 크게 레이더를 활용한 방법과 카메라를 활용한 방법 또는 루프검지기를 활용한 방법 등이 있다. 레이더를 활용한 방법은 레이더의 검지영역 안에서 레이더에서 송출된 신호가 물체에 부딪칠 때 반 사되는 신호를 분석하여 물체를 파악하는 방법이다. 레이더를 활용한 방법은 차량의 상대 위치나 속도 등을 파 악하는데 용이하고 외부환경에 영향을 적게 받는다. 하지만 레이더의 종류에 따라 성능차가 크고 신호의 회전 에 따른 고스트 생성의 문제가 있다. 카메라를 활용한 방법은 영상 정보를 이용해 영상 정보 내에 있는 물체 정보를 배경과 구분하여 분석하고 판단하는 방법이다. 카메라를 활용한 방법은 레이더에 비해 상대적으로 가격 이 저렴하고 설치가 간편하지만 외부환경에 영향을 많이 받는다. 차량을 검지하는 지능형 교통정보 시스템을 설치하고 유지 보수를 하기 위하여 도로를 훼손하거나 차량을 통제 해야 한다. 또한, 주기적으로 2~ 3년에 한번씩 유지 보수가 필요하다. 더욱이, 대형 교량과 같은 곳에서의 설"}
{"patent_id": "10-2019-0085031", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "치가 어렵고, 한 개의 차선당 루프검지기가 필요하기 때문에 비효율적이다. 발명의 내용"}
{"patent_id": "10-2019-0085031", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "레이더 장치와 영상 처리를 이용하여 차종, 속도, 통행량을 검지하는 비접촉 방식의 무인교통단속시스템 및 방 법을 제공할 수 있다. 레이더, 레이저 및 라이더 중 적어도 하나 이상의 장치로부터 획득된 영상 정보와 카메라를 이용한 영상 정보를 결합하여 인공 지능에 기반한 차량에 대한 단속 정보를 포함하는 차량 정보를 검지하는 시스템 및 방법을 제공 할 수 있다."}
{"patent_id": "10-2019-0085031", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "무인교통단속 시스템은, 제1 전자 기기에 설정된 검지 영역에 기초하여 획득된 제1 정보 및 제2 전자 기기를 이 용하여 상기 검지 영역에 존재하는 차량을 촬영함에 따라 획득된 상기 제2 정보를 결합한 결합 정보를 교통단속 을 위하여 구성된 학습 모델을 통하여 학습시키는 학습부; 및 상기 학습된 학습 결과로부터 상기 검지 영역에서 의 차량에 대한 단속 정보를 포함하는 차량 정보를 제공하는 도출부를 포함할 수 있다. 상기 학습부는, 상기 제1 정보 및 상기 제2 정보를 결합한 결합 정보를 이용하여 상기 검지 영역의 측정 시작 지점으로부터 상기 측정 종료 지점까지의 시간 차이 정보에 기초하여 상기 차량의 속도 정보를 판단할 수 있다. 상기 학습부는, 상기 제1 정보 및 상기 제2 정보를 결합한 결합 정보를 이용하여 교통단속을 위한 딥러닝 기반 의 학습 모델을 구성하고, 상기 구성된 학습 모델에 상기 제1 정보 및 상기 제2 정보를 결합한 결합 정보를 입 력함에 따라 상기 검지 영역에서의 상기 차량이 위치하는 차선 정보, 상기 차량의 차종 및 차량의 번호를 판단 할 수 있다. 상기 도출부는, 상기 제1 정보 및 상기 제2 정보를 결합한 결합 정보에 기초하여 획득된 학습 결과로부터 상기 검지 영역에서의 차량의 정상 주행 여부, 차량의 차선 위반 여부를 포함하는 차량의 단속 정보를 도출하고, 상 기 도출된 차량의 단속 정보, 및 상기 차량과 관련된 차량이 위치하는 차선 정보, 상기 차량의 차종 및 차량의 번호를 포함하는 차량 정보를 제공할 수 있다. 상기 도출부는, 상기 검지 영역에서의 상기 단속 정보가 포함된 차량에 대한 차량 정보를 상기 단속 정보가 미 포함된 차량에 대한 차량 정보와 구분하여 표시할 수 있다. 상기 제1 전자 기기는, 레이더(RADAR), 레이저(RASER), 라이다(LIDAR) 중 적어도 하나 이상을 포함하고, 상기 제2 전자 기기는, 카메라를 포함하고, 상기 레이더(RADAR), 상기 레이저(RASER) 또는 상기 라이다(LIDAR) 중 적 어도 하나 이상의 기기에 설정된 검지 영역에 기초하여 레이더 정보, 레이저 정보 또는 라이다 정보 중 적어도 하나 이상의 정보를 획득하는 제1 정보 획득부; 및 상기 카메라를 이용하여 상기 검지 영역에 존재하는 차량의 영상 정보를 획득하는 제2 정보 획득부를 더 포함할 수 있다. 무인교통단속 시스템에 의해 수행되는 교통 단속 방법은, 제1 전자 기기에 설정된 검지 영역에 기초하여 획득된 제1 정보 및 제2 전자 기기를 이용하여 상기 검지 영역에 존재하는 차량을 촬영함에 따라 획득된 제2 정보를 결 합한 결합 정보를 교통단속을 위하여 구성된 학습 모델을 통하여 학습시키는 단계; 및 상기 학습된 학습 결과로 부터 상기 검지 영역에서의 차량에 대한 단속 정보를 포함하는 차량 정보를 제공하는 단계를 포함할 수 있다."}
{"patent_id": "10-2019-0085031", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "레이더, 레이저 및 라이더 중 적어도 하나 이상의 장치로부터 획득된 영상 정보와 카메라를 이용한 영상 정보를 결합하여 인공 지능에 기반한 학습 모델을 통하여 학습시킴에 따라 보다 정확하게 차량 정보를 도출할 수 있다. 이에, 한 대의 무인교통단속시스템을 통하여 다차로를 검지할 수 있고, 차종, 속도까지도 판별할 수 있다."}
{"patent_id": "10-2019-0085031", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 실시예를 첨부한 도면을 참조하여 상세히 설명한다. 도 1은 일 실시예에 따른 무인교통단속시스템의 구조를 설명하기 위한 도면이다. 무인교통단속 시스템은 레이더, 레이저, 라이다 중 어느 하나 이상의 기능과 카메라의 기능이 복합되어 물 체(object)를 탐지하는 장치로서, 특정 장소에 설치될 수 있으며, 검지 영역을 검지할 수 있다. 무인교통 단속 시스템은 레이더, 레이저, 라이다 중 어느 하나 이상의 기능과 카메라의 기능을 결합하여 탐지된 물 체(object)의 영상 정보에 대하여 인공지능(딥러닝)을 이용하여 검지 영역에 존재하는 차량을 검지할 수 있다. 무인교통단속 시스템은 기계학습 기반의 DNN, CNN, RNN 등 다양한 네트워크 구조의 학습 모델을 구 성할 수 있다. 무인교통단속 시스템은 레이더, 레이저, 라이다를 이용하여 획득된 정보 및 카메라를 이용 하여 획득된 영상 정보를 결합한 결합 정보를 구성된 학습 모델에 학습시켜 보다 정확한 차량에 대한 단속 정보 를 포함하는 차량 정보를 도출할 수 있다. 일례로, 무인교통단속 시스템은 무인교통단속 시스템은 카메라 기능이 포함된 제1 전자 기기(예를 들 면, 주 카메라) 및 레이더, 레이저, 라이다 중 적어도 하나 이상이 포함된 제2 전자 기기(예를 들면, 보조 카메라)를 통하여 검지 영역에 존재하는 차량을 검지 및 분석할 수 있다. 무인교통단속 시스템(10 0)은 차선에 존재하는 차량을 검지할 수 있다. 이때, 검지 영역은 무인교통단속 시스템에 의하여 사 전에 설정될 수 있으며, 검지 영역에 대한 범위 및 각도의 변경이 가능하다. 예를 들면, 레이더, 레이저, 라이 다를 이용하여 차량의 위치 정보를 획득할 수 있고, 카메라를 이용하여 영상 정보를 획득할 수 있다. 또는, 레 이저, 라이다를 이용하여 차량의 위치 정보를 포함하는 영상 정보를 획득할 수 있고, 카메라를 이용하여 영상 정보를 획득할 수 있다. 도 2는 일 실시예에 따른 무인교통단속 시스템의 동작을 설명하기 위한 도면이다. 무인교통단속 시스템은 차량과 접촉하지 않는 비접촉식 방식에 기반하여 차량에 대한 교통단속을 수행할 수 있 다. 무인교통단속 시스템은 양방향 차선에 존재하는 차량에 대한 교통단속을 수행할 수 있다. 예를 들면, 교 통단속을 위한 무인교통단속 시스템이 도로를 촬영할 수 있는 특정 높이에 설치될 수 있다. 이와 같이 설치된 무인교통단속 시스템에 제1 전자 기기 및 제2 전자 기기가 포함될 수 있으며, 상기 각각의 전자 기기의 각도 및 높이를 포함하는 위치 정보가 실시간으로 변경되거나 외부의 입력에 의하여 변경될 수 있다. 만약, 각각의 전 자 기기의 위치 정보가 변경될 경우, 검지 영역의 범위도 마찬가지로 변경될 수 있다. 무인교통단속 시스템에서 카메라는 검지 영역에 존재하는 차량 정보를 획득할 수 있다. 카메라는 물체를 촬영하는 기기로서, 적외선 카메라를 이용하여 늦은 시간(깜깜한 밤)에도 물체의 촬영이 가능할 수 있다. 카메 라는 무인교통단속 시스템에 내장되어 검지 영역에 존재하는 물체를 촬영할 수 있으며, 무인교통단속 시스 템에 내장되어 있지 않고 무인교통단속 시스템와 통신이 가능한 거리 이내에 설치되어 검지 영역에 존재하는 물체를 촬영하여 통신을 통하여 촬영된 영상 정보를 전달할 수 있다. 이때, 카메라는 WiFi, 블루투스, 비콘 등과 같은 무선 통신을 통하여 카메라 촬영된 영상에 대한 영상 정보를 전달할 수 있다. 무인교통단속 시스템에서 레이더, 레이저, 라이다는 검지 영역에 존재하는 차량 정보를 획득할 수 있 다. 이때, 레이더(Radar) 는 무선 탐지와 거리 측정(Radio Detecting And Ranging)의 약어로 전자기파 발사 후 물체에서 반사되는 전자기파를 수신해 거리, 방향 등을 확인할 수 있다. 일례로, 레이더는 검지 영역에 존 재하는 차량에 신호를 전파하고, 전파되는 신호가 반사되는 시간을 계산하여 차량까지의 거리 및 각도를 계산함 으로써 차량 정보를 획득할 수 있다. 다른 예로서, 레이저(Laser)는 물체를 향해 레이저를 발사한 뒤 반사되어 되돌아오는 레이저를 검출하여 정확한 거리를 측정할 수 있다. 이때, 실시예에서는 양방향 레이저가 사용되어차량 정보를 획득할 수 있다. 또 다른 예로서, 라이다(Lidar)는 레이더와 이름이 비슷할 뿐만 아니라, 기본적 인 원리도 비슷하다. 다만, 라이더는 레이더와 파장이 다른 레이저를 발사해 반사되는 레이저의 시간과 강 도, 주파수의 변화 등을 활용해 주변을 인지할 수 있고, 더 구체적인 정보를 획득할 수 있다. 라이다는 센서 서가 360도 회전하면서 모든 곳을 인지할 수 있다. 예를 들면, 제1 전자 기기(카메라) 및 제2 전자 기기(레이더, 레이저, 라이다)는 계속적으로 검지 영역을 촬영 할 수 있다. 이때, 각각의 전자 기기에서 동일한 차량을 촬영할지라도 촬영된 영상 정보(영상 정보에 포함된 차량의 위치, 영상 정보의 촬영 시간 등)가 다를 수 있다. 예를 들면, 무인교통단속 시스템은 제1 전자 기기로 부터 영상 정보를 획득할 수 있고, 제2 전자 기기로부터 위치 정보를 획득할 수 있다. 이에, 제1 전자 기기 및 제2 전자 기기에서 획득된 각각의 정보의 동기화가 수행될 수 있다. 다시 말해서, 무인교통단속 시스템은 제1 전자 기기에서 검지 영역을 검지한 제1 정보와 제2 전자 기기에서 검지 영역을 검지한 제2 정보 의 동기화를 수행할 수 있다. 일례로, 한국등록특허 제10-1758576호를 참고하면, 제1 정보 및 제2 정보에 대하 여 시간을 기준으로 동기화를 수행한 후, 제2 정보에 포함된 좌표를 호모그래피(Homography)로 변환하고, 제1 전자 기기의 검지 영역을 좌표로 변환된 제2 정보에 포함된 검지 영역에 투사시켜 제2 정보에 대한 검지 영역 내의 좌표와 제1 정보에 포함된 좌표의 위치를 매칭시킬 수 있다. 도 5를 참고하면, 무인교통단속 시스템은 제1 전자 기기에서 검지 영역을 검지한 제1 정보와 제2 전자 기 기에서 검지 영역을 제2 정보를 결합한 후, 결합 정보를 학습 모델에 학습시킴에 따라 획득한 학습 결과로 부터 차량에 대한 단속 정보를 포함하는 차량 정보를 제공할 수 있다. 이때, 단속 정보란, 각 도로마다 정해진 규칙을 지키는지 여부를 판단하기 위한 것을 의미할 수 있다. 무인교통단속 시스템은 검지 영역에서의 차 량의 정상 주행 여부, 차량의 차선 위반 여부를 포함하는 차량의 단속 정보를 도출하고, 도출된 차량의 단속 정 보, 및 차량과 관련된 차량이 위치하는 차선 정보, 차량의 차종 및 차량의 번호를 포함하는 차량 정보를 제공할 수 있다. 예를 들면, 무인교통단속 시스템은 영상 정보를 통하여 차량의 위치, 차량의 외형 또는 차량의 번호 등을 판단할 수 있고, 레이더, 레이저 및 라이더 정보를 통하여 차량의 속도, 차량의 위치 또는 차선별 차 량의 진입수 등을 판단할 수 있다. 또한, 무인교통단속 시스템은 차량의 번호판을 인식할 수 있고, 더 나 아가 차 모델을 추정할 수도 있다. 무인교통단속 시스템은 차량의 속도 검출, 통행량을 추정할 수 있다. 무인 교통단속 시스템은 버스전용차로 에서의 규정위반을 판단할 수도 있다. 무인교통단속 시스템은 결합 정보를 통 하여 보다 정확하게 차량 정보를 획득할 수 있다. 이때, 무인교통단속 시스템은 검지 영역에서의 단속 정보가 포함된 차량에 대한 차량 정보를 단속 정보가 미포함된 차량에 대한 차량 정보와 구분하여 표시할 수 있다. 예 를 들면, 무인교통단속 시스템은 검지 영역에서 판단된 차량 정보를 모니터링할 수 있다. 무인교통단속 시스템 은 검지 영역에서 판단된 차량 정보가 단속 정보에 미포함될 경우, 210과 같이 정상 차량으로 표시할 수 있다. 무인교통단속 시스템은 검지 영역에서 판단된 차량 정보에 단속 정보가 포함될 경우, 220과 같이 위반 차량으로 표시할 수 있다. 구체적으로, 무인교통단속 시스템에서 레이더, 레이저, 라이다 중 어느 하나 이상으로부터 검지 영역의 측 정 시작 지점에 검지된 차량의 정보와 검지 영역의 측정 종료 시점까지의 차량 정보를 획득할 수 있다. 예를 들면, 무인교통단속 시스템은 제1 정보 및 제2 정보를 결합한 결합 정보를 이용하여 검지 영역의 측 정 시작 지점으로부터 측정 종료 지점까지의 시간 차이 정보에 기초하여 차량의 속도 정보를 판단할 수 있 다. 검지 영역의 측정 시작 지점에서 측정 종료 시점을 통과한 차량의 차량 속도 정보가 획득될 수 있다. 검지 영역에서 획득된 차량 속도 정보에 기반하여 차량의 위반 정보(여기서, 속도 위반 정보)가 도 출될 수 있다. 검지 영역에서 획득된 차량 속도 정보와 검지 영역 또는 차량의 위치된 위치 정보에서의 기준치를 비교하여 차량의 위반 정보가 도출될 수 있다. 또한, 무인교통단속 시스템은 검지 영역에서의 차량이 존재하는 밀도에 기초하여 차량의 통행량을 검출할 수 있다. 무인교통단속 시스템은 검지 영역에 서의 차량이 측정 시작 지점과 측정 종료 지점까지의 시간 차이 정보에 기초하여 차량의 통행량을 검출할 수도 있다. 무인교통단속 시스템은 검지 영역에 포함된 차선 정보가 저장하고 있을 수 있다. 이때, 무인교통단속 시 스템은 검지 영역에 포함된 각각의 차선에 대한 위치 정보를 함께 저장해놓을 수 있다. 무인교통단속 시 스템은 검지 영역에 검지된 차량의 위치 정보에 기초하여 차량이 위치하고 있는 차선을 식별할 수 있다. 또한, 예를 들면, 무인교통단속 시스템은 사전에 차량의 차종을 저장하고 있을 수 있다. 무인교통단속 시스템 은 검지 영역에 검지된 차량의 특징을 검출하여 차량의 차종을 식별할 수 있다. 또는, 무인교통단속 시스 템은 레이더, 레이저 및 라이더 검지기로부터 감지된 차량의 형체의 크기에 기초하여 차량의 차종(예를 들면, 버스, 승용차, 화물차 등)을 판단할 수 있다. 이와 같이, 무인교통단속 시스템은 검지 영역에서의 차량의차종, 차량의 속도, 차량 번호, 차량의 차선 정보 등이 차량 정보로 획득될 수 있다. 무인교통단속 시스템은 다중 차선을 동시에 검지할 수 있게 된다. 무인교통단속 시스템은 특정 시간대별로 검지 영역을 검지하도록 설정할 수 있다. 예를 들면, 무인교통단속 시 스템은 출퇴근 시간(예를 들면, 8~10시, 17~21시) 사이에는 교통단속을 수행하지 않고, 출퇴근 시간 이외의 시 간에는 교통단속을 수행하도록 교통단속 기준을 설정할 수도 있다. 무인교통단속 시스템은 시간에 따라 설정된 교통단속 기준에 기초하여 검지 영역에서의 차량 정보를 분석할 수 있다. 도 3은 일 실시예에 따른 무인교통단속 시스템의 구성을 설명하기 위한 블록도이고, 도 4는 일 실시예에 따른 무인교통단속 시스템에서 교통단속을 수행하는 방법을 설명하기 위한 흐름도이다. 무인교통단속 시스템에 포함된 프로세서는 학습부 및 도출부를 포함할 수 있다. 이러한 프로세 서 및 프로세서의 구성요소들은 도 4의 교통단속을 수행하는 방법이 포함하는 단계들(410 내지 420)을 수행하도 록 무인교통단속 시스템을 제어할 수 있다. 이때, 프로세서 및 프로세서의 구성요소들은 메모리가 포함하는 운 영체제의 코드와 적어도 하나의 프로그램의 코드에 따른 명령(instruction)을 실행하도록 구현될 수 있다. 여 기서, 프로세서의 구성요소들은 무인교통단속 시스템에 저장된 프로그램 코드가 제공하는 제어 명령에 따 라 프로세서에 의해 수행되는 서로 다른 기능들(different functions)의 표현들일 수 있다. 프로세서는 교통단속을 수행하는 방법을 위한 프로그램의 파일에 저장된 프로그램 코드를 메모리에 로딩할 수 있다. 예를 들면, 무인교통단속 시스템 에서 프로그램이 실행되면, 프로세서는 운영체제의 제어에 따라 프로그램의 파일로부터 프로그램 코드를 메모리에 로딩하도록 무인교통단속 시스템을 제어할 수 있다. 단계에서 학습부는 제1 전자 기기에 설정된 검지 영역에 기초하여 획득된 제1 정보 및 제2 전자 기기 를 이용하여 검지 영역에 존재하는 차량을 촬영함에 따라 획득된 제2 정보를 결합한 결합 정보를 교통단속을 위 하여 구성된 학습 모델을 통하여 학습할 수 있다. 이때, 제1 전자 기기는, 레이더(RADAR), 레이저(RASER), 라 이다(LIDAR) 중 적어도 하나 이상을 포함하고, 제2 전자 기기는, 카메라일 수 있다. 제1 정보 획득부(미도시됨)는 레이더(RADAR), 상기 레이저(RASER) 또는 상기 라이다(LIDAR) 중 적어도 하나 이상의 기기 에 설정된 검지 영역에 기초하여 레이더 정보, 레이저 정보 또는 라이다 정보 중 적어도 하나 이상의 정보를 획 득할 수 있다. 제2 정보 획득부(미도시됨)는 카메라를 이용하여 검지 영역에 존재하는 차량의 영상 정보를 획 득할 수 있다. 구체적으로, 학습부는 제1 정보 및 상기 제2 정보를 결합한 결합 정보를 이용하여 교통단 속을 위한 딥러닝 기반의 학습 모델을 구성할 수 있다. 학습부는 제1 정보 및 제2 정보를 결합한 결합 정 보를 이용하여 검지 영역의 측정 시작 지점으로부터 측정 종료 지점까지의 시간 차이 정보에 기초하여 차량의 속도 정보를 판단할 수 있다. 학습부는 구성된 학습 모델에 제1 정보 및 제2 정보를 결합한 결합 정보를 입력함에 따라 검지 영역에서의 차량이 위치하는 차선 정보, 차량의 차종 및 차량의 번호를 판단할 수 있다. 단계에서 도출부는 학습된 학습 결과로부터 검지 영역에서의 차량에 대한 단속 정보를 포함하는 차량 정보를 제공할 수 있다. 도출부는 제1 정보 및 제2 정보를 결합한 결합 정보에 기초하여 획득된 학습 결 과로부터 검지 영역에서의 차량의 정상 주행 여부, 차량의 차선 위반 여부를 포함하는 차량의 단속 정보를 도출 하고, 도출된 차량의 단속 정보, 및 차량과 관련된 차량이 위치하는 차선 정보, 차량의 차종 및 차량의 번호를 포함하는 차량 정보를 제공할 수 있다. 도출부는 검지 영역에서의 상기 단속 정보가 포함된 차량에 대한 차량 정보를 단속 정보가 미포함된 차량에 대한 차량 정보와 구분하여 표시할 수 있다. 실시예에 따른 무인교통단속장비는 오류 및 고장이 발생하였을 경우, 빠른 대처가 가능하다. 또한, 무인교통단 속장비는 설치공간의 제약을 받지 않으며, 시간/물적 자원 낭비를 개선할 수 있어 비용을 절감시킬 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2019-0085031", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2019-0085031", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2019-0085031", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 무인교통단속 시스템의 구조를 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 무인교통단속 시스템의 동작을 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 무인교통단속 시스템의 구성을 설명하기 위한 블록도이다. 도 4는 일 실시예에 따른 무인교통단속 시스템에서 교통단속을 수행하는 방법을 설명하기 위한 흐름도이다. 도 5는 일 실시예에 따른 무인교통단속 시스템의 개괄적인 동작을 설명하기 위한 도면이다."}
