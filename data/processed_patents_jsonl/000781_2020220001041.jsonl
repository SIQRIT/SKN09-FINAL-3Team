{"patent_id": "20-2022-0001041", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "20-2022-0003050", "출원번호": "20-2022-0001041", "출원인": "주식회사 쓰리디팩토리"}}
{"patent_id": "20-2022-0001041", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 대화 제공을 위한 전자 장치에 있어서,하나 이상의 프로세서; 및상기 하나 이상의 프로세서에 의한 실행 시, 상기 하나 이상의 프로세서가 연산을 수행하도록 하는 명령들이 저장된 하나 이상의 메모리를 포함하며,상기 하나 이상의 프로세서는,사용자의 음성 신호를 수신하고,상기 음성 신호를 텍스트 신호로 변환하며,상기 텍스트 신호의 자연 언어 처리를 수행하여 키워드를 추출하고,추출된 키워드를 이용하여 데이터베이스와 매칭을 수행하여 지식 베이스 응답 신호를 형성하며,상기 지식 베이스 응답 신호를 이용하여 상기 사용자의 나이, 성격 및 친밀도를 고려하여 감성 베이스 응답 신호를 형성하고,상기 감성 베이스 응답 신호를 음성 출력 신호로 변환하며,상기 하나 이상의 프로세서는,상기 음성 출력 신호에 대한 상기 사용자의 피드백을 이용하여 상기 사용자의 반응 정도에 따른 상기 음성 출력신호에 대한 가중치를 부여하되,상기 사용자가 특정 음성 출력 신호에 대해서는 긍정적인 반응을 보이고, 다른 음성 출력 신호에 대해서는 무반응 또는 부정적인 반응을 보인 경우,상기 사용자가 긍정적인 반응을 보인 특정 음성 출력 신호에 상대적으로 높은 가중치를 부여하고,상기 상대적으로 높은 가중치가 부여된 특정 음성 출력 신호가 상기 감성 베이스 응답 신호 형성에 고려될 수있도록, 상기 상대적으로 높은 가중치가 부여된 특정 음성 출력 신호를 이용하여 상기 데이터베이스의 업데이트를 수행하며,상기 하나 이상의 프로세서는, 음성 대화 내역 데이터를 통해 적합한 답변을 유도하고, 키워드 트레이닝을 수행하되,성별, 지역, 연령 및 다자발화에 따른 다수의 음성 데이터를 수신하고, 상기 다수의 음성 데이터를 이용하여 상기 데이터베이스의 업데이트를 수행하며, 상기 추출된 키워드를 이용하여 상기 데이터베이스와 매칭을 수행하여상기 지식 베이스 응답 신호를 형성하는 검색기반 모델과, 상기 추출된 키워드와 상기 데이터베이스와의 매칭이불가능한 경우 상기 지식 베이스 응답 신호 형성이 불가능한 것으로 판단하고, 기계 학습 알고리즘을 이용하여상기 추출된 키워드로부터 상기 지식 베이스 응답 신호를 형성하는 생성 모델을 사용하며,상기 하나 이상의 프로세서는, 5G 클라우드 실감 콘텐츠 아키텍처를 도출하고, 기존 아키텍처를 기반으로 클라우드 사업자가 제공하고 있는 네이티브(native) 서비스를 추가 반영하며,상기 하나 이상의 프로세서는, 실제 사람의 음성과 매칭되는 목소리 TTS(text to speech)를 제공하는, 인공지능대화 제공을 위한 전자 장치."}
{"patent_id": "20-2022-0001041", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,공개실용신안 20-2022-0003050-3-상기 하나 이상의 프로세서는,상기 음성 신호에 대하여 문장 분리, 띄어쓰기 교정, 철자 교정, 약어 확장 및 기호 제거 절차를 통하여 수신된음성 신호의 자연 언어 처리를 수행하는, 인공지능 대화 제공을 위한 전자 장치.고안의 설명기 술 분 야본 고안은 인공지능 대화 제공을 위한 전자 장치에 관련된 것으로, 보다 구체적으로는 인공지능(AI: Artificial [0001]Intelligence) 학습 기반으로 감성 베이스의 대화를 제공할 수 있는 인공지능 대화 제공을 위한 전자 장치에 관련된 것이다.배 경 기 술인공지능 대화 기술의 보급이 확대되고, 인공지능 대화 기술과 연계된 다양한 서비스들이 등장하면서 인공지능 [0003]대화 기술의 활용도가 계속해서 높아지고 있다. 사용자들은 다양한 분야의 서비스를 인공지능 대화를 통해서이용할 수 있다.그러나, 인공지능 대화 기술을 이용할 경우 사용자의 문의에 대한 인공지능 시스템의 대답은 미리 설정된 톤 [0004](tone), 억양, 말투 등을 이용하여 구현되므로, 사용자가 인공지능 시스템에 대한 친근감을 느끼지 못하는 문제점이 있다. 특히, 어린 아이들의 경우 인공지능 시스템의 대답에 대해서 공포감을 느낄 수 있는 문제점이있다.고안의 내용해결하려는 과제본 고안이 해결하고자 하는 일 기술적 과제는, 사용자로부터 수신된 음성에 대하여 감성 베이스의 응답을 제공 [0006]하는 인공지능 대화 제공을 위한 전자 장치를 제공하는데 있다.본 고안이 해결하고자 하는 다른 기술적 과제는, 사용자로부터 수신된 음성에 대하여 사용자의 나이, 성격 및 [0007]친밀도를 고려한 감성 베이스의 응답을 제공하는 인공지능 대화 제공을 위한 전자 장치를 제공하는데 있다.본 고안이 해결하고자 하는 다른 기술적 과제는, 음성 출력에 대한 사용자의 반응 정도에 따른 가중치를 부여하 [0008]여 데이터베이스의 업데이트를 수행하는 인공지능 대화 제공을 위한 전자 장치를 제공하는데 있다.본 고안이 해결하고자 하는 기술적 과제는 상술된 것에 제한되지 않는다. [0009]과제의 해결 수단본 고안의 일 실시 예에 따른 인공지능 대화 제공을 위한 전자 장치는, 하나 이상의 프로세서; 및 상기 하나 이 [0010]상의 프로세서에 의한 실행 시, 상기 하나 이상의 프로세서가 연산을 수행하도록 하는 명령들이 저장된 하나 이상의 메모리를 포함하며, 상기 하나 이상의 프로세서는, 사용자의 음성 신호를 수신하고, 상기 음성 신호를 텍스트 신호로 변환하며, 상기 텍스트 신호의 자연 언어 처리를 수행하여 키워드를 추출하고, 추출된 키워드를 이용하여 데이터베이스와 매칭을 수행하여 지식 베이스 응답 신호를 형성하며, 상기 지식 베이스 응답 신호를 이용하여 상기 사용자의 나이, 성격 및 친밀도를 고려하여 감성 베이스 응답 신호를 형성하고, 상기 감성 베이스응답 신호를 음성 출력 신호로 변환할 수 있다.일 실시예로서, 상기 하나 이상의 프로세서는, 상기 음성 신호에 대하여 문장 분리, 띄어쓰기 교정, 철자 교정, [0011]약어 확장 및 기호 제거 절차를 통하여 수신된 음성 신호의 자연 언어 처리를 수행할 수 있다.일 실시예로서, 상기 하나 이상의 프로세서는, 성별, 지역, 연령 및 다자발화에 따른 다수의 음성 데이터를 수 [0012]신하고, 상기 다수의 음성 데이터를 이용하여 상기 데이터베이스의 업데이트를 수행하며, 상기 추출된 키워드를공개실용신안 20-2022-0003050-4-이용하여 상기 데이터베이스와 매칭을 수행하여 상기 지식 베이스 응답 신호를 형성할 수 있다.일 실시예로서, 상기 하나 이상의 프로세서는, 상기 음성 출력 신호에 대한 상기 사용자의 반응 정도에 따른 가 [0013]중치를 부여하여 상기 데이터베이스의 업데이트를 수행할 수 있다.일 실시예로서, 상기 하나 이상의 프로세서는, 상기 추출된 키워드와 상기 데이터베이스와의 매칭이 불가능한 [0014]경우 상기 지식 베이스 응답 신호 형성이 불가능한 것으로 판단하고, 기계 학습 알고리즘을 이용하여 상기 추출된 키워드로부터 상기 지식 베이스 응답 신호를 형성할 수 있다.본 고안의 일 실시 예에 따른 하나 이상의 프로세서; 및 상기 하나 이상의 프로세서에 의한 실행 시, 상기 하나 [0015]이상의 프로세서가 연산을 수행하도록 하는 명령들이 저장된 하나 이상의 메모리를 포함하는 인공지능 대화 제공을 위한 전자 장치를 이용한 인공지능 대화 제공 방법은, 상기 하나 이상의 프로세서에 의해서, 사용자의 음성 신호를 수신하는 단계; 상기 하나 이상의 프로세서에 의해서, 상기 음성 신호를 텍스트 신호로 변환하는 단계; 상기 하나 이상의 프로세서에 의해서, 상기 텍스트 신호의 자연 언어 처리를 수행하여 키워드를 추출하는단계; 상기 하나 이상의 프로세서에 의해서, 추출된 키워드를 이용하여 데이터베이스와 매칭을 수행하여 지식베이스 응답 신호를 형성하는 단계; 상기 하나 이상의 프로세서에 의해서, 상기 지식 베이스 응답 신호를 이용하여 상기 사용자의 나이, 성격 및 친밀도를 고려하여 감성 베이스 응답 신호를 형성하는 단계; 및 상기 하나이상의 프로세서에 의해서, 상기 감성 베이스 응답 신호를 음성 출력 신호로 변환하는 단계를 포함할 수 있다.본 고안의 실시예에 따른 하나 이상의 프로세서; 및 상기 하나 이상의 프로세서에 의한 실행 시, 상기 하나 이 [0016]상의 프로세서가 연산을 수행하도록 하는 명령들이 저장된 하나 이상의 메모리를 포함하는 컴퓨터에서 수행 가능하도록 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램은, 상기 하나 이상의 프로세서에 의해서, 사용자의 음성 신호를 수신하는 단계; 상기 하나 이상의 프로세서에 의해서, 상기 음성 신호를 텍스트 신호로 변환하는 단계; 상기 하나 이상의 프로세서에 의해서, 상기 텍스트 신호의 자연 언어 처리를 수행하여 키워드를추출하는 단계; 상기 하나 이상의 프로세서에 의해서, 추출된 키워드를 이용하여 데이터베이스와 매칭을 수행하여 지식 베이스 응답 신호를 형성하는 단계;상기 하나 이상의 프로세서에 의해서, 상기 지식 베이스 응답 신호를 이용하여 상기 사용자의 나이, 성격 및 친 [0017]밀도를 고려하여 감성 베이스 응답 신호를 형성하는 단계; 및 상기 하나 이상의 프로세서에 의해서, 상기 감성베이스 응답 신호를 음성 출력 신호로 변환하는 단계를 수행 가능하도록 컴퓨터 판독 가능한 기록매체에 저장될수 있다.고안의 효과본 고안의 일 실시 예에 따른 인공지능 대화 제공을 위한 전자 장치 및 방법과, 그를 수행하도록 컴퓨터 판독 [0019]가능한 기록매체에 저장된 프로그램은, 사용자로부터 수신된 음성에 대하여 감성 베이스의 응답을 제공하여 사용자 친화적인 대화가 가능하도록 할 수 있다.또한, 본 고안의 일 실시 예에 따른 인공지능 대화 제공을 위한 전자 장치 및 방법과, 그를 수행하도록 컴퓨터 [0020]판독 가능한 기록매체에 저장된 프로그램은, 사용자로부터 수신된 음성에 대하여 사용자의 나이, 성격, 친밀도등을 고려한 사용자 맞춤형 대화가 가능하여 사용자가 다시 찾을 수 있는 인공지능 대화를 제공할 수 있다.또한, 본 고안의 일 실시 예에 따른 인공지능 대화 제공을 위한 전자 장치 및 방법과, 그를 수행하도록 컴퓨터 [0021]판독 가능한 기록매체에 저장된 프로그램은, 음성 출력에 대한 사용자의 반응 정도에 따른 가중치를 부여하여데이터베이스의 업데이트를 수행하므로 보다 정교하면서도 인공지능 대화 제공을 위한 연산량을 감소시킬 수 있다.도면의 간단한 설명도 1은 본 고안의 실시 예에 따른 인공지능 대화 제공을 위한 전자 장치의 구성을 보이는 예시도이다. [0023]도 2는 본 고안의 실시예에 따른 인공지능 대화 제공 시스템의 구성을 보이는 예시도이다.도 3은 본 고안의 실시예에 따른 뉴럴 네트워크의 학습을 설명하기 위한 도면이다.공개실용신안 20-2022-0003050-5-도 4 및 도 5는 본 고안의 실시 예에 따른 인공지능 대화 제공 방법의 절차를 보이는 흐름도이다.고안을 실시하기 위한 구체적인 내용이하, 첨부된 도면들을 참조하여 본 고안의 바람직한 실시 예를 상세히 설명할 것이다. 그러나 본 고안의 기술 [0024]적 사상은 여기서 설명되는 실시 예에 한정되지 않고 다른 형태로 구체화될 수도 있다. 오히려, 여기서 소개되는 실시 예는 개시된 내용이 철저하고 완전해질 수 있도록 그리고 당업자에게 본 고안의 사상이 충분히 전달될수 있도록 하기 위해 제공되는 것이다.본 명세서에서, 어떤 구성요소가 다른 구성요소 상에 있다고 언급되는 경우에 그것은 다른 구성요소 상에 직접 [0025]형성될 수 있거나 또는 그들 사이에 제 3의 구성요소가 개재될 수도 있다는 것을 의미한다.또한, 본 명세서의 다양한 실시 예 들에서 제1, 제2, 제3 등의 용어가 다양한 구성요소들을 기술하기 위해서 사 [0026]용되었지만, 이들 구성요소들이 이 같은 용어들에 의해서 한정되어서는 안 된다. 이들 용어들은 단지 어느 구성요소를 다른 구성요소와 구별시키기 위해서 사용되었을 뿐이다. 따라서, 어느 한 실시 예에 제 1 구성요소로 언급된 것이다른 실시 예에서는 제 2 구성요소로 언급될 수도 있다. 여기에 설명되고 예시되는 각 실시 예는 그것의 상보적인 실시 예도 포함한다. 또한, 본 명세서에서 '및/또는'은 전후에 나열한 구성요소들 중 적어도 하나를 포함하는 의미로 사용되었다.명세서에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함한다. 또한, \"포함하다\" [0027]또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 구성요소 또는 이들을 조합한 것이 존재함을지정하려는 것이지, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 구성요소 또는 이들을 조합한 것들의 존재또는 부가 가능성을 배제하는 것으로 이해되어서는 안 된다. 또한, 본 명세서에서 \"연결\"은 복수의 구성 요소를 간접적으로 연결하는 것, 및 직접적으로 연결하는 것을 모두 [0028]포함하는 의미로 사용된다. 또한, \"연결\"이라 함은 물리적인 연결은 물론 전기적인 연결을 포함하는 개념이다.또한, 하기에서 본 고안을 설명함에 있어 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 고안의 요지 [0029]를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략할 것이다.도 1은 본 고안의 실시 예에 따른 인공지능 대화 제공을 위한 전자 장치의 구성을 보이는 예시도이다. [0030]도 1에 도시한 바와 같이, 인공지능 대화 제공을 위한 전자 장치(100)는, 하나 이상의 프로세서(110), 하나 이 [0031]상의 메모리(120), 송수신기(130), 마이크(140) 및 스피커(150)를 포함할 수 있다. 일 실시예로서, 인공지능대화 제공을 위한 전자 장치(100)의 이 구성요소들 중 적어도 하나가 생략되거나, 다른 구성요소가 인공지능 대화 제공을 위한 전자 장치(100)에 추가될 수 있다. 추가적으로(additionally) 또는 대체적으로(alternatively), 일부의 구성요소들이 통합되어 구현되거나, 단수 또는 복수의 개체로 구현될 수 있다. 인공지능 대화 제공을 위한 전자 장치(100) 내, 외부의 구성요소들 중 적어도 일부의 구성요소들은 시스템 버스(system bus), GPIO(general purpose input/output), SPI(serial peripheral interface) 또는 MIPI(mobileindustry processor interface) 등을 통해 서로 연결되어, 데이터 및/또는 시그널을 주고받을 수 있다. 일 실시예로서, 인공지능 대화 제공을 위한 전자 장치(100)는 기계학습(machine learning) 특히, 딥러닝(deeplearning)과 같은 심층 강화 학습 알고리즘을 이용하여 감성 베이스 응답 신호를 형성할 수 있다.하나 이상의 프로세서(110)는, 소프트웨어(예: 명령, 프로그램 등)를 구동하여 프로세서(110)에 연결된 인공지 [0032]능 대화 제공을 위한 전자 장치(100)의 적어도 하나의 구성요소를 제어할 수 있다. 또한, 프로세서(110)는 본고안과 관련된 다양한 연산, 처리, 데이터 생성, 가공 등의 동작을 수행할 수 있다. 또한, 프로세서(110)는 데이터 등을 하나 이상의 메모리(120)로부터 로드하거나, 하나 이상의 메모리(120)에 저장할 수 있다.하나 이상의 프로세서(110)는, 사용자의 음성 신호를 수신할 수 있다. 일 실시 예에 따르면, 하나 이상의 프로 [0033]세서(110)는, 마이크(140)를 통하여 사용자의 음성 신호를 컴퓨터에서 처리 가능한 데이터 패킷 형태로 획득할수 있다. 예를 들어, 프로세서(110)는, 연속 음성 인식(Continuous Speech Recognition) 알고리즘을 사용하여사용자가 연속적으로 발음한 음성 신호를 여러 단어로 인식할 수 있다. 일 실시 예에 따르면, 사용자의 음성신호는 자연 음성(Spontaneous Speech)으로 대화하듯이 자연스럽게 발성한 음성, 머뭇거림, 감탄사, 숨소리 등을 포함할 수 있다. 다른 실시 예에 따르면, 프로세서(110)는, 불특정 다수의 사용자가 사용할 수 있도록 임의의 화자의 음성을 인식하는 화자 독립(Speaker Independent)으로 편의성을 향상시킬 수 있다. 예를 들어, 프로세서(110)는, 음성 트레이닝 기능을 통하여 사용자의 음성 인식률을 개선시킬 수 있다. 다른 실시 예에따르면, 프로세서(110)는, 구글 클라우드 스피치(Google Cloud Speech)를 응용한 스피치 적응(Speech공개실용신안 20-2022-0003050-6-Adaptation) 기술 구현으로 오디오 데이터에서 자주 나타나는 단어와 구문의 정확도를 향상시킬 수 있다.하나 이상의 프로세서(110)는, 수신된 음성 신호를 텍스트 신호로 변환할 수 있다. 일 실시 예에 따르면, 하나 [0034]이상의 프로세서(110)는, 수신된 음성 신호를 A/D(Analog Digital) 변환기(Converter)에 의하여 샘플링하여 디지털 신호로 변환한 후 잡음 신호를 제거하여 텍스트 신호로 변환할 수 있다. 예를 들어, 프로세서(110)는,STT(Speech to Text)의 인식 엔진으로 다양한 언어를 선택하여 사용할 수 있고, 요청 구성의 언어 코드(language code) 필드에서 BCP-47 식별자를 사용하여 오디오 언어(그리고 국가 또는 지역 방언)를 지정하여 사용할 수 있도록 개발할 수 있다. 프로세서(110)는, 설정된 버튼이나 키를 이용하여 기능을 활성화하여 사용할수 있다. 스트리밍 음성 인식을 사용하여 오디오를 STT로 스트리밍하고 오디오가 처리됨에 따라 실시간으로 스트리밍 음성 인식 결과를 텍스트로 처리하고 번역 시스템 파일로 저장할 수 있다. 스트리밍 STTAPI(application programming interface) 인식 호출은, 양방향 스트림 내에서 오디오의 실시간 캡처 및 인식을위해 설계, 애플리케이션은 요청 스트림에서 오디오를 보내고 응답 스트림에서 중간 및 최종 인식 결과를 실시간으로 텍스트로 저장하고, 중간 결과는 특정 오디오 섹션의 현재 인식 결과를 나타내며, 최종 인식 결과는 해당 오디오 섹션의 가장 높은 최종 추측 결과를 도출할 수 있다. 프로세서(110)는, CDN(Content DeliveryNetwork) 서비스를 적용하여 네트워크 속도를 1/10로 감소시킬 수 있다. 프로세서(110)는, 서비스 운영을 고려한 클라우드 아키텍처 설계 및 구성할 수 있다. 확장성, 안정성을 고려하여 이중화하는 구성이며, 제공되고 있는 Clova, VOD Trans에 대한 서비스 확장을 고려하여 반영할 수 있다. 네이버 클라우드 플랫폼의 ObjectStorage에 관련 설정 파일을 업로드하고, CDN+(CDN+는 컨텐츠를 많은 사용자에게 손실없이 빠르고 안전하게 전달하는 서비스) 연계를 통해 HTTP/HTTPS 프로토콜을 연결할 수 있다. 프로세서(110)는 통화 음성 파일을 활용하여 인식 및 서비스 연결을 수행할 수 있다. API를 통한 서비스 호출 후 확인 시 결과 값을 도출할 수 있다.하나 이상의 프로세서(110)는, 수신된 텍스트 신호의 자연 언어 처리를 수행하여 키워드를 추출할 수 있다. 일 [0035]실시 예에 따르면, 하나 이상의 프로세서(110)는, 텍스트 신호에 대하여 문장 분리, 띄어쓰기 교정, 철자 교정,약어 확장 및 기호 제거 절차를 통하여 수신된 음성 신호의 자연 언어 처리를 수행할 수 있다. 예를 들어, 프로세서(122)는, 수신된 텍스트 신호가 포함하는 모든 어절을 추출하고, 추출된 어절에 대하여 문장 종결 기호를제거하며, 추출된 어절 중 연속하는 두 어절이 서로 다른 문장으로 분리될 수 있는 문장 분리 확률을 계산하고,문장 분리 확률과 미리 결정된 기준 확률을 비교하며, 문장 분리 확률이 미리 결정된 기준 확률 이상인 경우,연속하는 두 어절을 서로 다른 문장으로 분리할 수 있다. 또한, 하나 이상의 프로세서(110)는, 수신된 텍스트 신호가 포함하는 각 문장에서 모든 문장 부호를 제거하고, [0036]추출된 어절의 각각이 미리 결정된 말뭉치에 포함되어 있는지 확인하며, 추출된 어절의 각각이 미리 결정된 말뭉치에 포함되어 있는 경우 어절의 철자를 교정하지 않고, 추출된 어절의 각각이 말뭉치에 포함되어 있지 않은경우 말뭉치에 포함되어 있지 않은 교정 대상 어절을 교정 후보 어절로 교정할 수 있다.하나 이상의 프로세서(110)는, 추출된 어절의 각각이 미리 결정된 시소러스(Thesaurus) - 서로 다른 어절 간의 [0037]유의어 또는 반의어 관계를 나타내는 사전 -에 포함되어 있는지 확인하고, 추출된 어절의 각각이 시소러스에 포함되어 있지 않은 경우 어절의 변경을 수행하지 않고, 추출된 어절의 각각이 시소러스에 포함되어 있는 경우 어절을 시소러스에 포함된 약어 확장 어절로 변경할 수 있다.또한, 하나 이상의 프로세서(110)는, 추출된 어절의 각각이 의존소 및 지배소로 분류될 확률을 각각 산출하고, [0038]의존소로 분류될 확률과 지배소로 분류될 확률을 서로 비교하여, 의존소로 분류될 확률이 지배소로 분류될 확률보다 높을 경우 추출된 어절을 의존소로 분류하고, 지배소로 분류될 확률이 의존소로 분류될 확률보다 높을 경우 추출된 어절을 지배소로 각각 분류할 수 있다.예를 들어, 하나 이상의 프로세서(110)는, 사용자로부터 \"내일 설악산의 날씨가 어때?\"라는 음성 신호를 수신한 [0039]경우 자연 언어 처리를 수행하여 \"내일\", \"설악산\", \"날씨\"를 텍스트 신호의 키워드로 추출할 수 있다.다른 실시 예에 따르면, 하나 이상의 프로세서(110)는, 텍스트 신호로부터 음성 인식에 유용한 특징을 추출하여 [0040]특징 벡터를 생성하고, 생성된 특징 벡터를 미리 학습과정에서 준비된 인식 대상 어휘로 구성된 사전을 참조하여 가장 유사한 단어를 키워드로 추출할 수 있다. 예를 들어, 어휘의 크기는 일반적인 채팅에 사용되는 100단어 이하의 소규모 어휘를 사용하나 필요에 의해서 10,000단어 이상의 대어휘도 적용 가능할 수 있다.하나 이상의 프로세서(110)는, 추출된 키워드를 이용하여 데이터베이스와 매칭을 수행하여 지식 베이스 응답 신 [0041]호를 형성할 수 있다. 일 실시 예에 따르면, 하나 이상의 프로세서(110)는, 성별, 지역, 연령 및 다자발화에따른 다수의 음성 데이터를 수신하고, 다수의 음성 데이터를 이용하여 데이터베이스의 업데이트를 수행하며, 텍공개실용신안 20-2022-0003050-7-스트 신호를 이용하여 데이터베이스와 매칭을 수행하여 지식 베이스 응답 신호를 형성할 수 있다. 예를 들어,프로세서(110)는, 음성 출력 신호에 대한 사용자의 반응 정도에 따른 가중치를 부여하여 데이터베이스의 업데이트를 수행할 수 있다. 또한, 프로세서(110)는, 지식 베이스 응답 신호 형성을 위하여 룰베이스 대화 시스템을구축할 수 있다. 즉, 일상 대화를 인식하고 음성 신호를 텍스트 신호로 실시간 변환하는 인공지능 기술 개발을위한 대화 음성 데이터 세트를 구축할 수 있고, 성별, 지역, 연령, 원거리, 다자발화 등 분야별 원본 음성데이터(4,000 시간), 텍스트 데이터 400만 문장을 확보할 수 있으며, 확보된 음성 데이터 기반 대화 데이터 세트를구축할 수 있다. 또한, 프로세서(110)는 유연한 답변이 가능한 클라우드 기반 대규모 데이터 세트를 구축할 수있고, 예상하지 못했던 질문에 대한 적합한 답변이 가능하도록 고도화할 수 있다.예를 들어, 프로세서(110)는, 추출된 키워드인 \"내일\", \"설악산\", \"날씨\"라는 키워드를 이용하여 데이터베이스 [0042]와의 매칭을 수행하고, \"설악산의 기온은 14~23℃, 구름 많고 흐림, 미세먼지/초미세먼지 좋음\"이라는 지식 베이스 응답 신호를 형성할 수 있다.하나 이상의 프로세서(110)는, 지식 베이스 응답 신호를 이용하여 사용자의 나이, 성격 및 친밀도를 고려하여 [0043]감성 베이스 응답 신호를 형성할 수 있다. 일 실시 예에 따르면, 하나 이상의 프로세서(110)는, 사용자의 나이를 고려하여 지식 베이스 응답 신호에 감정이 나타나도록 감성 베이스 응답 신호를 형성할 수 있다. 예를들어, 프로세서(110)는, 사용자의 음성 신호로부터 사용자의 나이 정보를 추출하고, 추출된 나이 정보를 이용하여 지식 베이스 응답 신호의 어투를 조절하여 감성 베이스 응답 신호를 형성할 수 있다. 즉, 프로세서(110)는,사용자의 나이가 10대로 추출된 경우, \"설악산의 기온은 14~23℃, 구름 많고 흐림, 미세먼지/초미세먼지 좋음\"이라는 지식 베이스 응답 신호의 어투를 조절하여, \"설악산의 기온은 14~23℃이고, 구름 많고 흐릴거야, 미세먼지/초미세먼지 좋을것 같아\"라는 감성 베이스 응답 신호를 형성할 수 있다. 또한, 프로세서(110)는, 사용자의음성 신호로부터 사용자의 성격 정보를 추출하고, 추출된 성격 정보를 이용하여 지식 베이스 응답 신호의 어투를 조절하여 감성 베이스 응답 신호를 형성할 수 있다. 즉, 프로세서(110)는, 사용자가 급한 성격으로 파악한경우, \"설악산의 기온은 14~23℃, 구름 많고 흐림, 미세먼지/초미세먼지 좋음\"이라는 지식 베이스 응답 신호의어투를 조절하여, \"설악산의 기온은 14~23℃, 구름 많고 흐림, 미세먼지/초미세먼지 좋음\"이라는 최대한 간략한형태로 감성 베이스 응답 신호를 형성할 수 있다. 또한, 프로세서(110)는, 사용자의 음성 신호로부터 사용자의친밀도 정보를 추출하고, 추출된 친밀도 정보를 이용하여 지식 베이스 응답 신호의 어투를 조절하여 감성 베이스 응답 신호를 형성할 수 있다. 즉, 프로세서(110)는, 사용자와의 친밀도가 낮은 것으로 파악한 경우, \"설악산의 기온은 14~23℃, 구름 많고 흐림, 미세먼지/초미세먼지 좋음\"이라는 지식 베이스 응답 신호의 어투를 조절하여, \"설악산의 기온은 14~23℃입니다, 구름 많고 흐릴 것으로 예상됩니다, 미세먼지/초미세먼지 좋을 것으로예상됩니다\"라는 격식을 갖춘 문장 형태로 감성 베이스 응답 신호를 형성할 수 있다. 또한, 하나 이상의 프로세서(110)는, 감성 베이스 응답 신호에 대한 사용자의 피드백을 이용하여 감성 베이스 응답 신호에 가중치를 부여하여 감성 베이스 응답 신호 형성에 대한 기계 학습을 수행할 수 있다. 예를 들어, 프로세서(110)는 감성 베이스 응답 신호에 대하여 사용자가 웃는 경우 감성 베이스 응답 신호에 보다 높은 가중치를 부여하고, 감성 베이스 응답 신호에 대하여 사용자의 표정 변화가 없는 경우 감성 베이스 응답 신호에 보다 낮은 가중치를 부여할수 있다.하나 이상의 프로세서(110)는, 추출된 키워드와 데이터베이스와의 매칭이 불가능한 경우 지식 베이스 응답 신호 [0044]형성이 불가능한 것으로 판단하고, 기계 학습 알고리즘을 이용하여 추출된 키워드로부터 지식 베이스 응답 신호를 형성할 수 있다. 일 실시 예에 따르면, 프로세서(110)는 사용자로부터 \"아프리카 스키장은 어디가 좋아?\"라는 음성 신호를 수신한 경우 데이터베이스에서 음성 신호의 키워드인 \"아프리카\", \"스키장\"과 매칭되는 응답이존재하지 않음을 확인하고, \"아프리카 스키장은 사하라사막이 최고지.\"라는 지식 베이스 응답 신호를 형성할 수있다. 또한, 하나 이상의 프로세서(110)는, 지식 베이스 응답 신호를 이용하여 사용자의 나이, 성격 및 친밀도를 고려하여 감성 베이스 응답 신호를 형성할 수 있다.하나 이상의 프로세서(110)는, 음성 대화 내역 데이터를 통해 적합한 답변을 유도하고, 키워드 트레이닝을 수행 [0045]할 수 있다. 검색기반 모델(데이터베이스와의 매칭을 이용한 지식 베이스 응답 신호의 형성)과 생성 모델(기계학습을 이용한 지식 베이스 응답 신호의 형성)의 2가지의 유연한 사용으로 각 모델의 단점을 상호 보완할 수 있고, 자연스러운 응답 신호를 형성하기 위해서 언어적 문맥(linguistic context)과 물리적 문맥(physicalcontext)를 병합할 수 있다. 답변의 일관성 유지를 위해 고정된 지식과 모델에 대한 인격 단일화를 추구하고,인공지능 활용을 위해 단일 환경에서 텍스트 분석, 머신러닝, 딥러닝 알고리즘을 지원하는 통합 분석 플랫폼을제작할 수 있다. 유연한 답변이 가능한 클라우드 기반 대규모 데이터 세트 구축이 가능할 수 있다.하나 이상의 프로세서(110)는, 5G 클라우드 실감 콘텐츠 아키텍처를 도출하고, 기존 아키텍처를 기반으로 클라 [0046]공개실용신안 20-2022-0003050-8-우드 사업자가 제공하고 있는 Native 서비스를 추가 반영할 수 있다. 아키텍처 고도화를 실시하여 실제 서비스운영을 고려한 클라우드 아키텍처 설계 및 구성을 수행할 수 있다. 확장성, 안정성을 고려하고 이중화하여 구성, 서비스 확장을 고려하여 서버에 대한 이중화 구성을 수행하고, 5G 연동이 가능한 아키텍처로 구성하여AR(Augmented Reality), VR(Virtual Reality) 등 메타버스 서비스로의 확장성을 고려한 스케일링(Scaling)이가능하도록 구성할 수 있다. 로드밸런서(서버의 성능과 부하량을 고려해 네트워크 트래픽을 다수의 서버로 분산시켜 주는 서비스)를 활용하여 서비스에 대한 운영의 안정화 및 이중화 구성을 실시하고, 오토 스케일링을 이용하여 미리 등록한 설정에 따라 서버 수를 자동으로 증가 또는 감소시켜 안정적인 서비스를 유지할 수 있다.하나 이상의 프로세서(110)는, AI 캐릭터에 어울리는 목소리 TTS(Text to Speech)를 개발하고, 실제 사람의 음 [0047]성과 같은 자연스러운 목소리 TTS를 구현할 수 있다. 특정인의 목소리를 재연하고 비슷한 수준의 Naver ClovaTTS 목소리를 활용, 스펙트럼 비교 분석하여 튜닝된 목소리를 구현할 수 있다. WaveNet 기술과 Clova TTS 기술을 활용하여 개인화 음성 합성 기술을 구현하고, 오디오 신호의 원시 파형을 한번에 한 샘플씩 직접 모델링하는기술을 구현할 수 있다.게임 엔진은 게임 개발이라는 본연의 목적외에도 모바일 앱, AR, VR 등 다양한 개발에 사용되고 있다. 본 고안 [0048]의 인공지능 대화 제공을 위한 전자 장치(100)는 Unity, Unreal 등의 게임 엔진에 응용, 연동할 수 있는 범용플랫폼으로 제작하고, 음성 인식, STT, 번역 시스템을 연결하여 글로벌 메타버스 사용자의 커뮤니케이션을 활성화시킬 수 있다.하나 이상의 프로세서(110)는, 감성 베이스 응답 신호를 음성 출력 신호로 변환할 수 있다. 일 실시 예에 따르 [0049]면, 프로세서(110)는, 감성 베이스 응답 신호를 음성 출력 신호로 변환할 수 있고, 변환된 음성 출력 신호는 스피커(150)를 통하여 사용자에게 출력할 수 있다.하나 이상의 메모리(120)는, 다양한 데이터를 저장할 수 있다. 메모리(120)에 저장되는 데이터는, 인공지능 대 [0050]화 제공을 위한 전자 장치(100)의 적어도 하나의 구성요소에 의해 획득되거나, 처리되거나, 사용되는 데이터로서, 소프트웨어(예: 명령, 프로그램 등)를 포함할 수 있다. 메모리(120)는 휘발성 및/또는 비휘발성 메모리를포함할 수 있다. 본 고안에서, 명령 내지 프로그램은 메모리(120)에 저장되는 소프트웨어로서, 인공지능 대화제공을 위한 전자 장치(100)의 리소스를 제어하기 위한 운영체제, 어플리케이션 및/또는 어플리케이션이 전자장치의 리소스들을 활용할 수 있도록 다양한 기능을 어플리케이션에 제공하는 미들 웨어 등을 포함할 수 있다.하나 이상의 메모리(120)는, 상술한 사용자의 음성 신호, 텍스트 신호, 키워드, 지식 베이스 응답 신호, 감성 [0051]베이스 응답 신호, 음성 출력 신호 등을 저장할 수 있다. 또한 하나 이상의 메모리(120)는, 하나 이상의 프로세서(110)에 의한 실행 시, 하나 이상의 프로세서(110)가 연산을 수행하도록 하는 명령들을 저장할 수 있다.일 실시 예에 따르면, 인공지능 대화 제공을 위한 전자 장치(100)는 송수신기(130)를 더 포함할 수 있다. 송수 [0052]신기(130)는, 인공지능 대화 제공을 위한 전자 장치(100)와 서버, 데이터베이스, 클라이언트 장치들 및/또는 기타 다른 장치 간의 무선 또는 유선 통신을 수행할 수 있다. 예를 들어, 송수신기(130)는 eMBB(enhanced MobileBroadband), URLLC(Ultra Reliable Low-Latency Communications), MMTC(Massive Machine TypeCommunications), LTE(long-term evolution), LTE-A(LTE Advance), UMTS(Universal MobileTelecommunications System), GSM(Global System for Mobile communications), CDMA(code division multipleaccess), WCDMA(wideband CDMA), WiBro(Wireless Broadband), WiFi(wireless fidelity), 블루투스(Bluetooth), NFC(near field communication), GPS(Global Positioning System) 또는 GNSS(global navigationsatellite system) 등의 방식에 따른 무선 통신을 수행할 수 있다. 예를 들어, 송수신기(130)는USB(universal serial bus), HDMI(high definition multimedia interface), RS-232(recommended standard232)또는 POTS(plain old telephone service) 등의 방식에 따른 유선 통신을 수행할 수 있다.일 실시 예에 따르면, 하나 이상의 프로세서(110)는, 송수신기(130)를 제어하여 서버 및 데이터베이스로부터 정 [0053]보를 획득할 수 있다. 서버 및 데이터베이스로부터 획득된 정보는 하나 이상의 메모리(120)에 저장될 수 있다.일 실시예로서, 서버 및 데이터베이스로부터 획득되는 정보는 지식 베이스 응답 신호의 형성을 위한 키워드 매칭에 필요한 정보를 포함할 수 있다.일 실시 예에 따르면, 인공지능 대화 제공을 위한 전자 장치(100)는, 다양한 형태의 장치가 될 수 있다. 예를 [0054]들어, 인공지능 대화 제공을 위한 전자 장치(100)는 휴대용 통신 장치, 컴퓨터 장치, 또는 상술한 장치들 중 하나 또는 그 이상의 조합에 따른 장치일 수 있다. 본 고안의 인공지능 대화 제공을 위한 전자 장치(100)는 전술한 장치들에 한정되지 않는다.공개실용신안 20-2022-0003050-9-본 고안에 따른 인공지능 대화 제공을 위한 전자 장치(100)의 다양한 실시예들은 서로 조합될 수 있다. 각 실 [0055]시예들은 경우의 수에 따라 조합될 수 있으며, 조합되어 만들어진 인공지능 대화 제공을 위한 전자 장치(100)의실시예 역시 본 고안의 범위에 속한다. 또한 전술한 본 고안에 따른 전자 장치(100)의 내/외부 구성 요소들은실시예에 따라 추가, 변경, 대체 또는 삭제될 수 있다. 또한 전술한 인공지능 대화 제공을 위한 전자 장치(100)의 내/외부 구성 요소들은 하드웨어 컴포넌트로 구현될 수 있다.본 고안에서, 인공지능(Artificial Intelligence, AI)은 인간의 학습능력, 추론능력, 지각능력 등을 모방하고, [0056]이를 컴퓨터로 구현하는 기술을 의미하고, 기계 학습, 심볼릭 로직(Symbolic Logic) 등의 개념을 포함할 수 있다. 기계 학습(Machine Learning, ML)은 입력 데이터들의 특징을 스스로 분류 또는 학습하는 알고리즘 기술이다. 인공지능의 기술은 기계 학습의 알고리즘으로써 입력 데이터를 분석하고, 그 분석의 결과를 학습하며, 그학습의 결과에 기초하여 판단이나 예측을 할 수 있다. 또한, 기계 학습의 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술들 역시 인공지능의 범주로 이해될 수 있다. 예를 들어, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야가 포함될 수 있다.기계 학습은 데이터를 처리한 경험을 이용해 신경망 모델을 훈련시키는 처리를 의미할 수 있다. 기계 학습을 [0057]통해 컴퓨터 소프트웨어는 스스로 데이터 처리 능력을 향상시키는 것을 의미할 수 있다. 신경망 모델은 데이터사이의 상관 관계를 모델링하여 구축된 것으로서, 그 상관 관계는 복수의 파라미터에 의해 표현될 수 있다. 신경망 모델은 주어진 데이터로부터 특징들을 추출하고 분석하여 데이터 간의 상관 관계를 도출하는데, 이러한 과정을 반복하여 신경망 모델의 파라미터를 최적화해 나가는 것이 기계 학습이라고 할 수 있다. 예를 들어, 신경망 모델은 입출력 쌍으로 주어지는 데이터에 대하여, 입력과 출력 사이의 매핑(상관 관계)을 학습할 수 있다.또는, 신경망 모델은 입력 데이터만 주어지는 경우에도 주어진 데이터 사이의 규칙성을 도출하여 그 관계를 학습할 수도 있다.인공지능 학습모델 또는 신경망 모델은 인간의 뇌 구조를 컴퓨터 상에서 구현하도록 설계될 수 있으며, 인간의 [0058]신경망의 뉴런(neuron)을 모의하며 가중치를 가지는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 노드들은 뉴런이 시냅스(synapse)를 통하여 신호를 주고받는 뉴런의 시냅틱(synaptic) 활동을 모의하여, 서로 간의 연결 관계를 가질 수 있다. 인공지능 학습모델에서 복수의 네트워크 노드들은 서로 다른 깊이의 레이어에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데이터를 주고받을 수 있다. 인공지능 학습모델은,예를 들어, 인공 신경망 모델(Artificial Neural Network), 컨볼루션 신경망 모델(Convolution NeuralNetwork: CNN) 등일 수 있다. 일 실시예로서, 인공지능 학습모델은, 지도학습(Supervised Learning), 비지도학습(Unsupervised Learning), 강화 학습(Reinforcement Learning) 등의 방식에 따라 기계 학습될 수 있다.기계 학습을 수행하기 위한 기계 학습 알고리즘에는, 의사결정트리(Decision Tree), 베이지안 망(BayesianNetwork), 서포트 벡터 머신(Support Vector Machine), 인공 신경망(Artificial Neural Network), 에이다부스트(Ada-boost), 퍼셉트론(Perceptron), 유전자 프로그래밍(Genetic Programming), 군집화(Clustering) 등이 사용될 수 있다.이중, CNN은 최소한의 전처리(preprocess)를 사용하도록 설계된 다계층 퍼셉트론(multilayer perceptrons)의 [0059]한 종류이다. CNN은 하나 또는 여러 개의 합성곱 계층과 그 위에 올려진 일반적인 인공 신경망 계층들로 이루어져 있으며, 가중치와 통합 계층(pooling layer)들을 추가로 활용한다. 이러한 구조 덕분에 CNN은 2차원 구조의 입력 데이터를 충분히 활용할 수 있다. 다른 딥러닝 구조들과 비교해서, CNN은 영상, 음성 분야 모두에서좋은 성능을 보여준다. CNN은 또한 표준 역전달을 통해 훈련될 수 있다. CNN은 다른 피드포워드 인공신경망기법들보다 쉽게 훈련되는 편이고 적은 수의 매개변수를 사용한다는 이점이 있다.컨볼루션 네트워크는 묶인 파라미터들을 가지는 노드들의 집합들을 포함하는 신경 네트워크들이다. 사용 가능 [0060]한 트레이닝 데이터의 크기 증가와 연산 능력의 가용성이, 구분적 선형 단위 및 드롭아웃 트레이닝과 같은 알고리즘 발전과 결합되어, 많은 컴퓨터 비전 작업들이 크게 개선되었다. 오늘날 많은 작업에 사용할 수 있는 데이터 세트들과 같은 엄청난 양의 데이터 세트에서는 초과 맞춤(outfitting)이 중요하지 않으며, 네트워크의 크기를 늘리면 테스트 정확도가 향상된다. 컴퓨팅 리소스들의 최적 사용은 제한 요소가 된다. 이를 위해, 심층 신경 네트워크들의 분산된, 확장 가능한 구현예가 사용될 수 있다.도 2는 본 고안의 실시예에 따른 인공지능 대화 제공 시스템의 구성을 보이는 예시도이다. [0061]도 2에 도시한 바와 같이, 인공지능 대화 제공 시스템(200)은, 게임 엔진(210), A/D 컨버터(220), 잡음 제거부 [0062](230), 특징 추출부(240), 어휘 사전(250), 텍스트 변환부(260), 룰베이스 대화 시스템(270) 및 AI 대화 시스템공개실용신안 20-2022-0003050-10-(280)을 포함할 수 있다.게임 엔진(210)은, 게임 개발이라는 본연의 목적 외에도 모바일 앱, AR, VR 등 다양한 개발에 사용되고 있다. [0063]일 실시 예에 따르면, 본 고안의 인공지능 대화 제공을 위한 전자 장치(100)는 Unity, Unreal 등의 게임 엔진에응용, 연동할 수 있는 범용 플랫폼으로 제작하고, 음성 인식, STT, 번역 시스템을 연결하여 글로벌 메타버스 사용자의 커뮤니케이션을 활성화시킬 수 있다.A/D 컨버터(220)는, 사용자(UE)로부터 수신된 음성 신호를 샘플링하여 디지털 신호로 변환할 수 있다. 일 실시 [0064]예에 따르면, A/D 컨버터(220)는 아날로그 신호인 음성 신호를 전자 장치에서 인식 가능한 디지털 신호로 변환할 수 있다.잡음 제거부(230)는, A/D 컨버터(220)에서 변환된 디지털 신호에서 잡음 신호를 제거할 수 있다. 일 실시 예에 [0065]따르면, 잡음 제거부(230)는 대역 필터링을 수행하여 디지털 신호에서 잡음 신호를 제거할 수 있다.특징 추출부(240)는, 디지털 신호에서 잡음 신호를 제거한 후 조사, 문장 부호, 띄어쓰기 등을 제거하여 키워드 [0066](특징)를 추출할 수 있고, 추출된 키워드는 어휘 사전(250)에 저장된 단어로 변환될 수 있다. 텍스트 변환부(260)는, 어휘 사전(250)에 저장된 단어로 구성된 텍스트 신호를 형성할 수 있다. [0067]룰베이스 대화 시스템(270)은, 텍스트 신호에서 추출된 키워드를 이용하여 데이터베이스와 매칭을 수행하여 지 [0068]식 베이스 응답 신호를 형성할 수 있다.AI 대화 시스템(280)은, 지식 베이스 응답 신호를 이용하여 사용자의 나이, 성격, 친밀도 등을 고려하여 감성 [0069]베이스 응답 신호를 형성할 수 있다. 감성 베이스 응답 신호는 음성 출력 신호로 변환되어 스피커(150)를 통하여 사용자(UE)에게 출력될 수 있다.도 3은 본 고안의 실시예에 따른 뉴럴 네트워크의 학습을 설명하기 위한 도면이다. [0070]도 3에 도시한 바와 같이, 학습 장치는 대상체의 이미지가 포함하는 특징점들의 인식을 위하여 뉴럴 네트워크 [0071](114)를 학습시킬 수 있다. 일 실시예에 따르면, 학습 장치는 인공지능 대화 제공을 위한 전자 장치(100)와 다른 별개의 주체일 수 있지만, 이에 제한되는 것은 아니다.뉴럴 네트워크(114)는 트레이닝 샘플들이 입력되는 입력 레이어(112)와 트레이닝 출력들을 출력하는 출력 레이 [0072]어(116)를 포함하고, 트레이닝 출력들과 레이블들 사이의 차이에 기초하여 학습될 수 있다. 여기서, 레이블들은 음성 출력 신호에 대응하는 사용자의 반응 정도에 기초하여 정의될 수 있다. 뉴럴 네트워크(114)는 복수의노드들의 그룹으로 연결되어 있고, 연결된 노드들 사이의 가중치들과 노드들을 활성화시키는 활성화 함수에 의해 정의된다.학습 장치는 GD(Gradient Decent) 기법 또는 SGD(Stochastic Gradient Descent) 기법을 이용하여 뉴럴 네트워 [0073]크(114)를 학습시킬 수 있다. 학습 장치는 뉴럴 네트워크의 출력들 및 레이블들 의해 설계된 손실 함수(LossFunction)를 이용할 수 있다.학습 장치는 미리 정의된 손실 함수를 이용하여 트레이닝 에러를 계산할 수 있다. 손실 함수는 레이블, 출력 [0074]및 파라미터를 입력 변수로 미리 정의될 수 있고, 여기서 파라미터는 뉴럴 네트워크(114) 내 가중치들에 의해설정될 수 있다. 예를 들어, 손실 함수는 MSE(Mean Square Error) 형태, 엔트로피(entropy) 형태 등으로 설계될 수 있는데, 손실 함수가 설계되는 실시예에는 다양한 기법 또는 방식이 채용될 수 있다.학습 장치는 역전파(Backpropagation) 기법을 이용하여 트레이닝 에러에 영향을 주는 가중치들을 찾아낼 수 있 [0075]다. 여기서, 가중치들은 뉴럴 네트워크(114) 내 노드들 사이의 관계들이다. 학습 장치는 역전파 기법을 통해찾아낸 가중치들을 최적화시키기 위해 레이블들 및 출력들을 이용한 SGD 기법을 이용할 수 있다. 예를 들어,학습 장치는 레이블들, 출력들 및 가중치들에 기초하여 정의된 손실 함수의 가중치들을 SGD 기법을 이용하여 갱신할 수 있다.일 실시예에 따르면, 학습 장치는 트레이닝 대상체의 음성 신호를 획득하고, 트레이닝 대상체의 음성 신호로부 [0076]터 트레이닝 음성 출력 신호를 추출할 수 있다. 학습 장치는 트레이닝 음성 출력 신호들에 대해서 각각 미리레이블링 된 정보(제1 레이블들)를 획득할 수 있는데, 트레이닝 음성 출력 신호들에 미리 정의된 음성 출력 신호에 대응한 사용자의 반응 정도(예를 들어, 반응도 상, 중, 하 등)를 나타내는 제1 레이블들을 획득할 수있다.공개실용신안 20-2022-0003050-11-일 실시예에 따르면, 학습 장치는 트레이닝 음성 출력 신호들의 외관 특징들, 패턴 특징들 및 어투 특징들에 기 [0077]초하여 제1 트레이닝 특징 벡터들을 생성할 수 있다. 트레이닝 음성 출력 신호들의 특징을 추출하는 데는 다양한 방식이 채용될 수 있다.일 실시예에 따르면, 학습 장치는 제1 트레이닝 특징 벡터들을 뉴럴 네트워크(114)에 적용하여 트레이닝 출력들 [0078]을 획득할 수 있다. 학습 장치는 트레이닝 출력들과 제1 레이블들에 기초하여 뉴럴 네트워크(114)를 학습시킬수 있다. 학습 장치는 트레이닝 출력들에 대응하는 트레이닝 에러들을 계산하고, 그 트레이닝 에러들을 최소화하기 위해 뉴럴 네트워크(114) 내 노드들의 연결 관계를 최적화하여 뉴럴 네트워크(114)를 학습시킬 수 있다.전자 장치(110)는 학습이 완료된 뉴럴 네트워크(114)를 이용하여 음성 신호로부터 음성 출력 신호를 형성할 수있다.도 4 및 도 5는 본 고안의 실시 예에 따른 인공지능 대화 제공 방법의 절차를 보이는 흐름도이다. 도 4 및 [0079]도 5의 흐름도에서 프로세스 단계들, 방법 단계들, 알고리즘들 등이 순차적인 순서로 설명되었지만, 그러한 프로세스들, 방법들 및 알고리즘들은 임의의 적합한 순서로 작동하도록 구성될 수 있다. 다시 말하면, 본 고안의다양한 실시예들에서 설명되는 프로세스들, 방법들 및 알고리즘들의 단계들이 본 고안에서 기술된 순서로 수행될 필요는 없다. 또한, 일부 단계들이 비동시적으로 수행되는 것으로서 설명되더라도, 다른 실시예에서는 이러한 일부 단계들이 동시에 수행될 수 있다. 또한, 도면에서의 묘사에 의한 프로세스의 예시는 예시된 프로세스가 그에 대한 다른 변화들 및 수정들을 제외하는 것을 의미하지 않으며, 예시된 프로세스 또는 그의 단계들 중임의의 것이 본 고안의 다양한 실시예들 중 하나 이상에 필수적임을 의미하지 않으며, 예시된 프로세스가 바람직하다는 것을 의미하지 않는다.도 4에 도시한 바와 같이, 단계(S410)에서, 사용자의 음성 신호가 수신된다. 예를 들어, 도 1 내지 [0080]도 2를 참조하면, 인공지능 대화 제공을 위한 전자 장치(100)의 프로세서(110)는, 사용자의 음성 신호를 수신할 수 있다. 일 실시 예에 따르면, 프로세서(110)는, 인공지능 대화 제공을 위한 전자 장치(100)의 마이크(140)를 통하여 사용자의 음성 신호를 수신할 수 있다.단계(S420)에서, 음성 신호가 텍스트 신호로 변환된다. 예를 들어, 도 1 내지 도 2를 참조하면, 인공 [0081]지능 대화 제공을 위한 전자 장치(100)의 프로세서(110)는, 단계 S410에서 수신한 사용자의 음성 신호를 텍스트 신호로 변환할 수 있다. 일 실시 예에 따르면, 프로세서(110)는, 수신된 음성 신호를 A/D(AnalogDigital) 변환기(Converter)에 의하여 샘플링하여 디지털 신호로 변환한 후 잡음 신호를 제거하여 텍스트 신호로 변환할 수 있다.단계(S430)에서, 텍스트 신호의 자연 언어 처리를 수행하여 키워드가 추출된다. 예를 들어, 도 1 내지 도 [0082] 3을 참조하면, 인공지능 대화 제공을 위한 전자 장치(100)의 프로세서(110)는, 단계 S420에서 변환된 텍스트 신호로부터 음성 인식에 유용한 특징을 추출하여 특징 벡터를 생성하고, 생성된 특징 벡터를 미리 학습과정에서 준비된 인식 대상 어휘로 구성된 사전을 참조하여 가장 유사한 단어를 키워드로 추출할 수 있다.단계(S440)에서, 추출된 키워드를 이용하여 데이터베이스와 매칭을 수행하여 지식 베이스 응답 신호가 형성된 [0083]다. 예를 들어, 도 1 내지 도 3을 참조하면, 인공지능 대화 제공을 위한 전자 장치(100)의 프로세서(110)는, 성별, 지역, 연령 및 다자발화에 따른 다수의 음성 데이터를 수신하고, 다수의 음성 데이터를 이용하여 데이터베이스의 업데이트를 수행하며, 텍스트 신호를 이용하여 데이터베이스와 매칭을 수행하여 지식베이스 응답 신호를 형성할 수 있다. 단계(S450)에서, 지식 베이스 응답 신호를 이용하여 사용자의 나이, 성격 및 친밀도를 고려하여 감성 베이스 응 [0084]답 신호가 형성된다. 예를 들어, 도 1 내지 도 3을 참조하면, 인공지능 대화 제공을 위한 전자 장치(100)의 프로세서(110)는, 기계학습(machine learning) 특히, 딥러닝(deep learning)과 같은 심층 강화 학습 알고리즘을 이용하여 감성 베이스 응답 신호를 형성할 수 있다.단계(S460)에서, 감성 베이스 응답 신호가 음성 출력 신호로 변환된다. 예를 들어, 도 1 내지 도 3을 참조 [0085]하면, 인공지능 대화 제공을 위한 전자 장치(100)의 프로세서(110)는, 감성 베이스 응답 신호를 TTS(Text toSpeech) 인식 엔진을 이용하여 음성 출력 신호로 변환할 수 있고, 음성 출력 신호는 스피커(150)를 통하여 사용자(UE)에게 출력할 수 있다.도 5에 도시한 바와 같이, 단계(S510)에서, 다수의 음성 데이터가 수신된다. 예를 들어, 도 1 내지 도 [0086] 4를 참조하면, 인공지능 대화 제공을 위한 전자 장치(100)의 프로세서(110)는, 성별, 지역, 연령 및 다자발화에 따른 다수의 음성 데이터를 수신할 수 있다. 일 실시 예에 따르면, 프로세서(110)는, 인터넷, SNS(Social공개실용신안 20-2022-0003050-12-Network Service) 등 다양한 경로를 통하여 다수의 음성 데이터를 수신할 수 있다.단계(S520)에서, 데이터베이스의 업데이트가 수행된다. 예를 들어, 도 1 내지 도 4를 참조하면, 인공지능 대 [0087]화 제공을 위한 전자 장치(100)의 프로세서(110)는, 단계 S510에서 수신한 다수의 음성 데이터를 이용하여 데이터베이스의 업데이트를 수행할 수 있다. 일 실시 예에 따르면, 프로세서(110)는, 수신된 다수의 음성 데이터를 성별, 지역, 연령, 다자발화 등에 따라 분류하여 이를 데이터베이스에 지속적으로 업데이트할 수 있다.단계(S530)에서, 지식 베이스 응답 신호가 형성된다. 예를 들어, 도 1 내지 도 4를 참조하면, 인공지능 [0088]대화 제공을 위한 전자 장치(100)의 프로세서(110)는, 단계 S430에서 추출된 키워드를 이용하여 단계 S520에서업데이트 된 데이터베이스와 매칭을 수행하여 지식 베이스 응답 신호를 형성할 수 있다.상기 방법은 특정 실시예들을 통하여 설명되었지만, 상기 방법은 또한 컴퓨터로 읽을 수 있는 기록매체에 컴퓨 [0089]터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의해 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 기록매체의예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광데이터 저장 장치 등이 있다. 또한, 컴퓨터가 읽을수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가저장되고 실행될 수 있다. 그리고, 상기 실시예들을 구현하기 위한 기능적인(functional) 프로그램, 코드 및코드 세그먼트들은 본 고안이 속하는 기술분야의 프로그래머들에 의해 용이하게 추론될 수 있다.이상, 본 고안을 바람직한 실시 예를 사용하여 상세히 설명하였으나, 본 고안의 범위는 특정 실시 예에 한정되 [0090]는 것은 아니며, 첨부된 특허청구범위에 의하여 해석되어야 할 것이다. 또한, 이 기술분야에서 통상의 지식을습득한 자라면, 본 고안의 범위에서 벗어나지 않으면서도 많은 수정과 변형이 가능함을 이해하여야 할 것이다.부호의 설명100: 전자 장치 110: 프로세서 [0091]120: 메모리 130: 송수신기140: 마이크 150: 스피커200: 인공지능 대화 제공 시스템 210: 게임 엔진220: A/D 컨버터 230: 잡음 제거부240: 특징 추출부 250: 어휘 사전260: 텍스트 변환부 270: 룰베이스 대화 시스템280: AI 대화 시스템 112: 입력 레이어114: 뉴럴 네트워크 116: 출력 레이어공개실용신안 20-2022-0003050-13-도면도면1공개실용신안 20-2022-0003050-14-도면2공개실용신안 20-2022-0003050-15-도면3공개실용신안 20-2022-0003050-16-도면4도면5공개실용신안 20-2022-0003050-17-"}
{"patent_id": "20-2022-0001041", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 대화 제공을 위한 전자 장치가 제공된다. 인공지능 대화 제공을 위한 전자 장치는, 사용자의 음성 신 호를 수신하고, 음성 신호를 텍스트 신호로 변환하며, 텍스트 신호의 자연 언어 처리를 수행하여 키워드를 추출 하고, 추출된 키워드를 이용하여 데이터베이스와 매칭을 수행하여 지식 베이스 응답 신호를 형성하며, 지식 베이 스 응답 신호를 이용하여 사용자의 나이, 성격 및 친밀도를 고려하여 감성 베이스 응답 신호를 형성하며, 감성 베이스 응답 신호를 음성 출력 신호로 변환한다."}
{"patent_id": "20-2022-0001041", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 고안은 인공지능 대화 제공을 위한 전자 장치에 관련된 것으로, 보다 구체적으로는 인공지능(AI: Artificial Intelligence) 학습 기반으로 감성 베이스의 대화를 제공할 수 있는 인공지능 대화 제공을 위한 전자 장치에 관 련된 것이다."}
{"patent_id": "20-2022-0001041", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 대화 기술의 보급이 확대되고, 인공지능 대화 기술과 연계된 다양한 서비스들이 등장하면서 인공지능 대화 기술의 활용도가 계속해서 높아지고 있다. 사용자들은 다양한 분야의 서비스를 인공지능 대화를 통해서 이용할 수 있다. 그러나, 인공지능 대화 기술을 이용할 경우 사용자의 문의에 대한 인공지능 시스템의 대답은 미리 설정된 톤 (tone), 억양, 말투 등을 이용하여 구현되므로, 사용자가 인공지능 시스템에 대한 친근감을 느끼지 못하는 문제 점이 있다. 특히, 어린 아이들의 경우 인공지능 시스템의 대답에 대해서 공포감을 느낄 수 있는 문제점이 있다. 고안의 내용"}
{"patent_id": "20-2022-0001041", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 고안이 해결하고자 하는 일 기술적 과제는, 사용자로부터 수신된 음성에 대하여 감성 베이스의 응답을 제공 하는 인공지능 대화 제공을 위한 전자 장치를 제공하는데 있다. 본 고안이 해결하고자 하는 다른 기술적 과제는, 사용자로부터 수신된 음성에 대하여 사용자의 나이, 성격 및 친밀도를 고려한 감성 베이스의 응답을 제공하는 인공지능 대화 제공을 위한 전자 장치를 제공하는데 있다. 본 고안이 해결하고자 하는 다른 기술적 과제는, 음성 출력에 대한 사용자의 반응 정도에 따른 가중치를 부여하 여 데이터베이스의 업데이트를 수행하는 인공지능 대화 제공을 위한 전자 장치를 제공하는데 있다. 본 고안이 해결하고자 하는 기술적 과제는 상술된 것에 제한되지 않는다."}
{"patent_id": "20-2022-0001041", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 고안의 일 실시 예에 따른 인공지능 대화 제공을 위한 전자 장치는, 하나 이상의 프로세서; 및 상기 하나 이 상의 프로세서에 의한 실행 시, 상기 하나 이상의 프로세서가 연산을 수행하도록 하는 명령들이 저장된 하나 이 상의 메모리를 포함하며, 상기 하나 이상의 프로세서는, 사용자의 음성 신호를 수신하고, 상기 음성 신호를 텍 스트 신호로 변환하며, 상기 텍스트 신호의 자연 언어 처리를 수행하여 키워드를 추출하고, 추출된 키워드를 이 용하여 데이터베이스와 매칭을 수행하여 지식 베이스 응답 신호를 형성하며, 상기 지식 베이스 응답 신호를 이 용하여 상기 사용자의 나이, 성격 및 친밀도를 고려하여 감성 베이스 응답 신호를 형성하고, 상기 감성 베이스 응답 신호를 음성 출력 신호로 변환할 수 있다. 일 실시예로서, 상기 하나 이상의 프로세서는, 상기 음성 신호에 대하여 문장 분리, 띄어쓰기 교정, 철자 교정, 약어 확장 및 기호 제거 절차를 통하여 수신된 음성 신호의 자연 언어 처리를 수행할 수 있다. 일 실시예로서, 상기 하나 이상의 프로세서는, 성별, 지역, 연령 및 다자발화에 따른 다수의 음성 데이터를 수 신하고, 상기 다수의 음성 데이터를 이용하여 상기 데이터베이스의 업데이트를 수행하며, 상기 추출된 키워드를공개실용신안 20-2022-0003050 -4-이용하여 상기 데이터베이스와 매칭을 수행하여 상기 지식 베이스 응답 신호를 형성할 수 있다. 일 실시예로서, 상기 하나 이상의 프로세서는, 상기 음성 출력 신호에 대한 상기 사용자의 반응 정도에 따른 가 중치를 부여하여 상기 데이터베이스의 업데이트를 수행할 수 있다. 일 실시예로서, 상기 하나 이상의 프로세서는, 상기 추출된 키워드와 상기 데이터베이스와의 매칭이 불가능한 경우 상기 지식 베이스 응답 신호 형성이 불가능한 것으로 판단하고, 기계 학습 알고리즘을 이용하여 상기 추출 된 키워드로부터 상기 지식 베이스 응답 신호를 형성할 수 있다. 본 고안의 일 실시 예에 따른 하나 이상의 프로세서; 및 상기 하나 이상의 프로세서에 의한 실행 시, 상기 하나 이상의 프로세서가 연산을 수행하도록 하는 명령들이 저장된 하나 이상의 메모리를 포함하는 인공지능 대화 제 공을 위한 전자 장치를 이용한 인공지능 대화 제공 방법은, 상기 하나 이상의 프로세서에 의해서, 사용자의 음 성 신호를 수신하는 단계; 상기 하나 이상의 프로세서에 의해서, 상기 음성 신호를 텍스트 신호로 변환하는 단 계; 상기 하나 이상의 프로세서에 의해서, 상기 텍스트 신호의 자연 언어 처리를 수행하여 키워드를 추출하는 단계; 상기 하나 이상의 프로세서에 의해서, 추출된 키워드를 이용하여 데이터베이스와 매칭을 수행하여 지식 베이스 응답 신호를 형성하는 단계; 상기 하나 이상의 프로세서에 의해서, 상기 지식 베이스 응답 신호를 이용 하여 상기 사용자의 나이, 성격 및 친밀도를 고려하여 감성 베이스 응답 신호를 형성하는 단계; 및 상기 하나 이상의 프로세서에 의해서, 상기 감성 베이스 응답 신호를 음성 출력 신호로 변환하는 단계를 포함할 수 있다. 본 고안의 실시예에 따른 하나 이상의 프로세서; 및 상기 하나 이상의 프로세서에 의한 실행 시, 상기 하나 이 상의 프로세서가 연산을 수행하도록 하는 명령들이 저장된 하나 이상의 메모리를 포함하는 컴퓨터에서 수행 가 능하도록 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램은, 상기 하나 이상의 프로세서에 의해서, 사 용자의 음성 신호를 수신하는 단계; 상기 하나 이상의 프로세서에 의해서, 상기 음성 신호를 텍스트 신호로 변 환하는 단계; 상기 하나 이상의 프로세서에 의해서, 상기 텍스트 신호의 자연 언어 처리를 수행하여 키워드를 추출하는 단계; 상기 하나 이상의 프로세서에 의해서, 추출된 키워드를 이용하여 데이터베이스와 매칭을 수행하 여 지식 베이스 응답 신호를 형성하는 단계; 상기 하나 이상의 프로세서에 의해서, 상기 지식 베이스 응답 신호를 이용하여 상기 사용자의 나이, 성격 및 친 밀도를 고려하여 감성 베이스 응답 신호를 형성하는 단계; 및 상기 하나 이상의 프로세서에 의해서, 상기 감성 베이스 응답 신호를 음성 출력 신호로 변환하는 단계를 수행 가능하도록 컴퓨터 판독 가능한 기록매체에 저장될 수 있다. 고안의 효과 본 고안의 일 실시 예에 따른 인공지능 대화 제공을 위한 전자 장치 및 방법과, 그를 수행하도록 컴퓨터 판독 가능한 기록매체에 저장된 프로그램은, 사용자로부터 수신된 음성에 대하여 감성 베이스의 응답을 제공하여 사 용자 친화적인 대화가 가능하도록 할 수 있다. 또한, 본 고안의 일 실시 예에 따른 인공지능 대화 제공을 위한 전자 장치 및 방법과, 그를 수행하도록 컴퓨터 판독 가능한 기록매체에 저장된 프로그램은, 사용자로부터 수신된 음성에 대하여 사용자의 나이, 성격, 친밀도 등을 고려한 사용자 맞춤형 대화가 가능하여 사용자가 다시 찾을 수 있는 인공지능 대화를 제공할 수 있다. 또한, 본 고안의 일 실시 예에 따른 인공지능 대화 제공을 위한 전자 장치 및 방법과, 그를 수행하도록 컴퓨터 판독 가능한 기록매체에 저장된 프로그램은, 음성 출력에 대한 사용자의 반응 정도에 따른 가중치를 부여하여 데이터베이스의 업데이트를 수행하므로 보다 정교하면서도 인공지능 대화 제공을 위한 연산량을 감소시킬 수 있 다."}
