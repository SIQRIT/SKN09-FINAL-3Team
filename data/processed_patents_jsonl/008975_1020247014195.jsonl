{"patent_id": "10-2024-7014195", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0089151", "출원번호": "10-2024-7014195", "발명의 명칭": "비디오 스트림 생성을 위한 시스템 및 방법", "출원인": "라이브아레나 테크놀로지스 에이비", "발명자": "다니엘손, 망누스"}}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "공유된 디지털 비디오 스트림을 제공하는 방법에 있어서, 상기 방법은:수집 단계에서, 적어도 2개의 디지털 비디오 소스(120)로부터 각각의 기본 디지털 비디오 스트림(210)을 수집하는 단계;이벤트 감지 단계에서, 제1 이벤트 세트로부터 선택된 적어도 하나의 이벤트(211)를 감지하기 위해 상기 기본디지털 비디오 스트림(210)을 개별적으로 분석하는 단계;동기화 단계에서, 공통 시간 기준(260)에 대해 상기 기본 디지털 비디오 스트림(210)을 시간 동기화하는 단계;패턴 감지 단계에서, 제1 패턴 세트로부터 선택된 적어도 하나의 패턴(212)을 감지하기 위해 상기 시간 동기화된 기본 디지털 비디오 스트림(210)을 분석하는 단계 - 상기 패턴 감지는 상기 감지된 적어도 하나의 이벤트(211)에 기초함 - ;생성 단계에서, 상기 시간 동기화된 기본 디지털 비디오 스트림(210)의 연속적으로 고려된 프레임(213) 및 상기감지된 패턴(212)에 기초하여 상기 공유 디지털 비디오 스트림을 출력 디지털 비디오 스트림(230)으로서 생성하는 단계; 및게시 단계에서, 상기 출력 디지털 비디오 스트림(230)을 상기 공유 디지털 비디오 스트림의 소비자에게 지속적으로 제공하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 기본 디지털 비디오 스트림(210) 중 적어도 2개는 문제의 상기 기본 디지털 비디오 스트림(210)을 제공하는 각각의 원격 연결 참여 클라이언트(121)를 포함하는 공유 디지털 비디오 통신 서비스(110)의 일부로 제공되는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 수집 단계는 상기 공유 디지털 비디오 통신 서비스(110)로부터 상기 기본 디지털 비디오스트림(210) 중 적어도 하나를 수집하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항 또는 제3항에 있어서, 상기 수집 단계는 상기 공유 디지털 비디오 통신 서비스(110) 외부에 있는 정보 소스(300)로부터 수집된 외부 디지털 비디오 스트림(301)으로서 상기 기본 디지털 비디오 스트림(210) 중 적어도하나를 수집하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "선행 항들 중 어느 한 항에 있어서, 상기 기본 디지털 비디오 스트림(210) 중 적어도 하나는 이탈하는 비디오인코딩, 프레임 속도, 종횡비 및/또는 해상도를 갖는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "선행 항들 중 어느 한 항에 있어서, 상기 수집 단계는 상기 기본 디지털 비디오 스트림(210) 중 적어도 2개를공통 프로토콜(240)로 변환하는 단계를 포함하고, 상기 공통 프로토콜(240)은 디지털 비디오 디코딩이나 디지털비디오 인코딩을 수행하지 않고 원시 이진 형식으로의 디지털 비디오 데이터의 저장을 규정하고, 상기 공통 프로토콜(240)은 또한 상기 저장된 디지털 비디오 데이터와 관련하여 특정 시점과 연관된 메타데이터(242)의 저장을 규정하는, 방법.공개특허 10-2024-0089151-3-청구항 7 제6항에 있어서, 상기 메타데이터(242)는 사용된 디지털 비디오 인코딩, 해상도, 프레임 속도 또는 종횡비와 관련하여, 문제의 상기 기본 디지털 비디오 스트림(210)의 상기 형식에 대한 정보를 포함하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항 또는 제7항에 있어서, 상기 수집 단계는 서로 다른 인코딩 형식을 사용하여 인코딩되는 기본 디지털 비디오 스트림(210)에 대해 서로 다른 형식별 수집 기능을 사용하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항 내지 제8항 중 어느 한 항에 있어서, 상기 변환 단계는 상기 기본 디지털 비디오 스트림(210) 각각의 원시 이진 데이터를 더 작은 데이터 세트(241)로 분할하는 단계, 및 상기 더 작은 세트(241) 각각을 상기 공통 시간 기준(260)의 각각의 시간과 연관시키는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항 내지 제9항 중 어느 한 항에 있어서, 상기 변환 단계는 상기 기본 디지털 비디오 스트림(210)의 상기 원시 이진 디지털 비디오 데이터를 필요에 따라 공통 프레임 속도 및 공통 해상도로 다운 샘플링하거나 업 샘플링하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 기본 디지털 비디오 스트림(210) 각각은 개별 버퍼(250)에, 개별 프레임 또는 프레임(213)의 시퀀스로서 저장되며, 각각은 상기 공통 시간 기준(260)과 연관된 대응 타임 스탬프와 연관되는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항 또는 제11항에 있어서, 오버레이 또는 효과와 같은 적어도 하나의 추가적인 디지털 비디오 정보(220)는또한 상기 공통 시간 기준(260)과 연관된 해당 타임 스탬프와 각각 연관된 개별 프레임 또는 프레임의 시퀀스로서 각각의 개별 버퍼(250)에 저장되는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제6항 내지 제12항 중 어느 한 항에 있어서, 상기 이벤트 감지 단계는 상기 공통 프로토콜(240)을 사용하여, 문제의 상기 이벤트(211)가 감지된 상기 기본 디지털 비디오 스트림(210)과 연관된, 상기 감지된 이벤트(211)를설명하는 메타데이터(242)를 저장하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "선행 항들 중 어느 한 항에 있어서, 상기 이벤트 감지 단계는 상기 이벤트(211)를 자동으로 감지하기 위해 상기기본 디지털 비디오 스트림(210) 각각을 분석하는 제1 훈련된 신경망 또는 다른 기계 학습 구성요소(132a)를 포함하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 이벤트(211)는 프리젠테이션 슬라이드의 변경이고,상기 이벤트 감지 단계는, 먼저, 제1 슬라이드 이미지와 후속 제2 슬라이드 이미지의 차이에 대한 이미지 분석을 기반으로 상기 이벤트를감지하는 단계(211); 및둘째, 상기 제2 이미지의 정보 복잡성에 대한 이미지 분석에 기초하여 상기 이벤트를 감지하는 단계(211)중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서, 상기 이벤트(211)는 디지털 비디오 통신 서비스(110)에 대한 참여 클라이언트(121)의 통신 연공개특허 10-2024-0089151-4-결이 끊긴 것이며, 상기 감지 단계는 문제의 상기 참여 클라이언트(121)에 대응하는 기본 디지털 비디오 스트림(210)의 일련의 후속 프레임(213)의 이미지 분석에 기초하여 상기 참여 클라이언트(121)가 통신 연결이 끊긴 것을 감지하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "선행 항들 중 어느 한 항에 있어서, 상기 공통 시간 기준(260)은 공통 오디오 신호(111)를 포함하고, 상기 공통오디오 신호(111)는 각각이 상기 기본 디지털 비디오 스트림(210) 중 각각의 것을 제공하는 적어도 두 개의 원격으로 연결된 참여 클라이언트(121)를 포함하는 공유 디지털 비디오 통신 서비스(110)에 대해 공통인, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제1항 내지 제16항 중 어느 한 항에 있어서, 상기 기본 디지털 비디오 스트림(210) 중 적어도 2개는 각각의 참여 클라이언트(121)에 의해 공유 디지털 비디오 통신 서비스(110)에 제공되고, 각각의 참여 클라이언트(121)는문제의 상기 참여 클라이언트(121)에 제공되는 상기 출력 디지털 비디오 스트림(230)의 일부로서 제공되는 시간동기화 요소(231)의 도착 시간을 감지하도록 배열된 각각의 로컬 동기화 소프트웨어(125)를 갖고, 상기 공통 시간 기준(260)은 상기 감지된 도착 시간에 적어도 부분적으로 기반하여 결정되는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "선행 항들 중 어느 한 항에 있어서, 상기 공통 시간 기준(260)은 상기 기본 디지털 비디오 스트림(210) 중 제1스트림의 오디오 부분(214)과 상기 제1 기본 디지털 비디오 스트림(210)의 이미지 부분(215) 사이의 불일치의감지에 적어도 부분적으로 기반하여 결정되고, 상기 불일치는 상기 제1 기본 디지털 비디오 스트림(210)에서 보여지는 발언 참가자(122)의 디지털 립싱크 비디오 분석에 기초하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "선행 항들 중 어느 한 항에 있어서, 상기 동기화 단계는 최대 30초, 예를 들어 최대 5초, 예를 들어 최대 1초,예를 들어 최대 0.5초의 대기 시간을 의도적으로 도입하여 상기 출력 디지털 비디오 스트림(230)에 적어도 상기레이턴시가 제공되도록 하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서, 상기 패턴 감지 단계는 상기 기본 디지털 비디오 스트림(210)의 정보를 고려하는 단계를 포함하고, 상기 정보는 상기 출력 디지털 비디오 스트림(230)의 상기 생성에 사용될 시간 동기화된 기본 디지털 비디오 스트림(210)의 프레임보다 나중 프레임(213)에 존재하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "선행 항들 중 어느 한 항에 있어서, 상기 패턴 감지 단계는 상기 패턴(212)을 자동으로 감지하기 위해 상기 기본 디지털 비디오 스트림(120)을 동시에 분석하는 제2 훈련된 신경망 또는 다른 기계 학습 구성요소(134a)를 포함하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "선행 항들 중 어느 한 항에 있어서, 상기 감지된 패턴(212)은 적어도 두 명의 서로 다른 발언 참가자(122)를 포함하는 발언 패턴을 포함하고, 각각은 공유 비디오 통신 서비스(110)에 대한, 각각의 참여 클라이언트(121)와연관되고, 상기 발언 참가자(122) 각각은 상기 기본 디지털 비디오 스트림(210) 각각에서 보여지는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "선행 항들 중 어느 한 항에 있어서, 상기 생성 단계는 상기 출력 디지털 비디오 스트림(230) 내의 상기 기본 디지털 비디오 스트림(210) 중 개별 스트림의 가시성에 관한 미리 결정된 및/또는 동적으로 가변적인 매개변수 세트; 시각적 및/또는 청각적 비디오 콘텐츠 배열; 시각 또는 청각 효과 사용; 및/또는 상기 출력 디지털 비디오스트림(230)의 출력 모드에 기초하여 상기 출력 디지털 비디오 스트림(230)을 생성하는 단계를 더 포함하는, 방법.공개특허 10-2024-0089151-5-청구항 25 선행 항들 중 어느 한 항에 있어서, 상기 기본 디지털 비디오 스트림(210) 중 적어도 하나는 디지털 비디오 통신 서비스(110)에 제공되며, 상기 게시 단계는 상기 출력 디지털 비디오 스트림(230)을 상기 통신 서비스(110)의 참여 클라이언트(121)와 같은 상기 통신 서비스(110), 또는 외부 소비자(150)에 제공하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "선행 항들 중 어느 한 항에 있어서, 상기 생성 단계는 중앙 서버(130)에 의해 수행되어, API(137)를 통해 라이브 비디오 스트림으로서 하나 또는 수 개의 동시 소비자에게 상기 출력 디지털 비디오 스트림(230)을 제공하는,방법."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "공유 디지털 비디오 스트림을 제공하기 위한 컴퓨터 소프트웨어 제품에 있어서, 상기 컴퓨터 소프트웨어 기능은실행시, 각각의 기본 디지털 비디오 스트림(210)이 적어도 두 개의 디지털 비디오 소스(120)로부터 수집되는 수집 단계;상기 기본 디지털 비디오 스트림(210)이 제1 이벤트 세트로부터 선택된 적어도 하나의 이벤트(211)를 감지하도록 개별적으로 분석되는 이벤트 감지 단계;상기 기본 디지털 비디오 스트림(210)이 공통 시간 기준(260)에 대해 시간 동기화되는 동기화 단계;상기 시간 동기화된 기본 디지털 비디오 스트림(210)이 제1 패턴 세트로부터 선택된 적어도 하나의 패턴(212)을감지하도록 분석되는 패턴 감지 단계 - 상기 패턴 감지는 상기 감지된 적어도 하나의 이벤트(211)에 기초함 - ;상기 공유 디지털 비디오 스트림이 상기 시간 동기화된 기본 디지털 비디오 스트림(210)의 연속적으로 고려되는프레임(213)과 상기 감지된 패턴(212)에 기초하여 출력 디지털 비디오 스트림(230)으로서 생성되는 생성 단계;및상기 출력 디지털 비디오 스트림(230)이 상기 공유 디지털 비디오 스트림의 소비자에게 지속적으로 제공되는 게시 단계를 수행하도록 구성되는, 컴퓨터 소프트웨어 제품."}
{"patent_id": "10-2024-7014195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "공유 디지털 비디오 스트림을 제공하기 위한 시스템(100)에 있어서, 중앙 서버(130)를 포함하는 상기 시스템(100)은:적어도 2개의 디지털 비디오 소스(120)로부터 각각의 기본 디지털 비디오 스트림(210)을 수집하도록 구성된 수집 기능(131);제1 이벤트 세트로부터 선택된 적어도 하나의 이벤트(211)를 감지하기 위해 상기 기본 디지털 비디오 스트림(210)을 개별적으로 분석하도록 구성된 이벤트 감지 기능(132);공통 시간 기준(260)에 대해 상기 기본 디지털 비디오 스트림(210)을 시간 동기화하도록 구성된 동기화 기능(133);제1 패턴 세트로부터 선택된 적어도 하나의 패턴(212)을 감지하기 위해 상기 시간 동기화된 기본 디지털 비디오스트림(210)을 분석하도록 구성된 패턴 감지 기능(134) - 상기 패턴 감지는 상기 감지된 적어도 하나의 이벤트(211)에 기초함 - ;상기 시간 동기화된 기본 디지털 비디오 스트림(210)의 연속적으로 고려되는 프레임(213) 및 상기 감지된 패턴(212)에 기초하여 상기 공유 디지털 비디오 스트림을 출력 디지털 비디오 스트림(230)으로서 생성하도록 구성된생성 기능(135); 및상기 출력 디지털 비디오 스트림(230)을 상기 공유 디지털 비디오 스트림의 소비자에게 지속적으로 제공하도록공개특허 10-2024-0089151-6-구성된 게시 기능(136)을 포함하는, 시스템(100)."}
{"patent_id": "10-2024-7014195", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "공유된 디지털 비디오 스트림을 제공하는 방법을 제공하고, 상기 방법은 적어도 2개의 디지털 비디오 소스 로부터 각각의 기본 디지털 비디오 스트림을 수집하는 수집 단계; 적어도 하나의 이벤트를 감지하기 위해 상기 기본 디지털 비디오 스트림을 개별적으로 분석하는 이벤트 감지 단계; 공통 시간 기준에 대해 상 (뒷면에 계속)"}
{"patent_id": "10-2024-7014195", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 디지털 비디오 스트림을 생성하기 위한 시스템, 컴퓨터 소프트웨어 제품 및 방법에 관한 것으로, 특 히 둘 이상의 서로 다른 디지털 입력 비디오 스트림을 기반으로 디지털 비디오 스트림을 생성하기 위한 방법에 관한 것이다. 바람직한 실시 예에서, 디지털 비디오 스트림은 특히 복수의 서로 다른 동시 사용자를 포함하는 디지털 비디오 회의 또는 디지털 비디오 회의 또는 미팅 시스템의 컨텍스트에서 생성된다. 생성된 디지털 비디 오 스트림은 외부로 게시되거나 디지털 비디오 회의 또는 디지털 비디오 회의 시스템 내에서 게시될 수 있다."}
{"patent_id": "10-2024-7014195", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "다른 실시 예에서, 본 발명은 디지털 비디오 회의가 아니고 여러 디지털 비디오 입력 스트림이 동시에 처리되어 생성된 디지털 비디오 스트림으로 결합되는 컨텍스트에서 적용된다. 예를 들어, 그러한 컨텍스트는 교육적이거 나 지시적일 수 있다. 두 명 이상의 참가자에게 로컬로 녹음된 디지털 비디오 및 오디오를 사용하여 가상으로 만나고 모든 참가자에게 실제 회의를 에뮬레이션하도록 방송하도록 제공하는, Microsoft® Teams®, Zoom®, Google® Meet® 등과 같이 알려진 디지털 화상 회의 시스템이 많이 있다. 디지털 화상회의 솔루션을, 특히 누구에게 언제 어떤 배포 채널을 통해 무엇이 표시되는지와 같이, 보여지는 콘 텐츠의 생성과 관련하여 전반적으로 개선할 필요성이 대두되고 있다. 예를 들어, 일부 시스템은 현재 발언 참가자를 자동으로 감지하고, 말하고 있는 참가자의 해당 비디오 피드를 다른 참가자에게 보여준다. 많은 시스템에서 현재 표시된 화면, 보기 창 또는 디지털 프리젠테이션과 같은 그래 픽을 공유하는 것이 가능하다. 그러나 가상 회의가 더욱 복잡해지면서, 현재 사용 가능한 모든 정보 중 각 시점 에 각 참가자에게 표시할 정보가 무엇인지 파악하는 서브시가 점점 더 어려워지고 있다. 다른 예에서는 발표 참가자가 디지털 프레젠테이션의 슬라이드에 관해 이야기하면서 무대 위를 돌아다닌다. 그 런 다음 시스템은 프레젠테이션 화면, 발표자 또는 둘 다를 표시할지, 아니면 둘 사이를 전환할지를 결정해야 한다. 자동 생성 프로세스에 의해 다수의 입력 디지털 비디오 스트림에 기초하여 하나 또는 여러 개의 출력 디지털 비 디오 스트림을 생성하고, 이렇게 생성된 디지털 비디오 스트림 또는 스트림을 한 명 또는 여러 소비자에게 제공 하는 것이 바람직할 수 있다. 그러나 많은 경우, 이러한 디지털 화상 회의 시스템이 직면한 많은 기술적 어려움으로 인해, 동적 회의 화면 레 이아웃 관리자 또는 기타 자동화된 생성 기능이 표시할 정보를 선택하는 것이 어렵다. 첫째, 디지털 화상회의는 실시간이라는 측면을 갖고 있기 때문에, 지연 시간이 짧은 것이 중요하다. 이는 서로 다른 하드웨어를 사용하여 참여하는 서로 다른 참가자로부터 수신되는 서로 다른 인입하는 디지털 비디오 스트 림이 서로 다른 대기 시간, 프레임 속도, 종횡비 또는 해상도와 연관될 때 문제를 야기한다. 많은 경우, 이러한 수신 디지털 비디오 스트림은 잘 구성된 사용자 경험을 위한 처리를 필요로 한다. 둘째, 시간 동기화에 문제가 있다. 참가자가 제공하는 외부 디지털 비디오 스트림이나 디지털 비디오 스트림과 같은 다양한 입력 디지털 비디오 스트림이 일반적으로 중앙 서버 또는 유사한 서버로 공급되므로, 이러한 각 디 지털 비디오 피드를 동기화할 절대적인 시간은 없다. 대기 시간이 너무 길면, 동기화되지 않은 디지털 비디오 피드로 인해 사용자 경험의 저하로 이어지게 된다. 셋째, 다자간 디지털 화상 회의에는 인코딩 또는 형식이 다른 다양한 디지털 비디오 스트림이 포함될 수 있으며, 이로 인해 디코딩 및 재인코딩이 필요하고 결과적으로 대기 시간 및 동기화 측면에서 문제가 발생할 수 있다. 이러한 인코딩은 또한 계산적으로 부담스럽기 때문에 하드웨어 요구 사항 측면에서도 비용이 많이 든다. 넷째, 서로 다른 디지털 비디오 소스가 서로 다른 프레임 속도, 종횡비 및 해상도와 연관될 수 있다는 사실은 메모리 할당 요구 사항이 예측할 수 없을 정도로 달라져 지속적인 균형 조정을 필요로 하는 결과를 가져올 수있다. 이로 인해 추가 대기 시간 및 동기화 문제가 발생할 가능성이 있다. 결과적으로 버퍼 요구 사항이 커진다. 다섯째, 참가자는 다양한 연결, 이탈/재연결 등의 측면에서 다양한 문제를 경험할 수 있으며, 이는 잘 구성된 사용자 경험을 자동으로 생성하는 데 더 많은 문제를 야기한다. 이러한 문제는, 예를 들어 많은 참가자가 참여하는 보다 복잡한 회의 상황; 서로 다른 하드웨어 및/또는 소프트 웨어를 사용하여 연결하는 참가자; 외부에서 제공되는 디지털 비디오 스트림; 화면 공유; 또는 여러 호스트에서 증폭된다. 대응하는 문제는 출력 디지털 비디오 스트림이 교육 및 지시를 위한 디지털 비디오 생성 시스템 등에서, 여러 입력 디지털 비디오 스트림을 기반으로 생성되는 다른 상황에서 발생한다."}
{"patent_id": "10-2024-7014195", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기 전술한 문제 중 하나 또는 여러 가지를 해결한다."}
{"patent_id": "10-2024-7014195", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "따라서, 공유된 디지털 비디오 스트림을 제공하는 방법에 있어서, 상기 방법은, 수집 단계에서, 적어도 2개의 디지털 비디오 소스로부터 각각의 기본 디지털 비디오 스트림을 수집하는 단계; 이벤트 감지 단계에서, 제1 이 벤트 세트로부터 선택된 적어도 하나의 이벤트를 감지하기 위해 상기 기본 디지털 비디오 스트림을 개별적으로 분석하는 단계; 동기화 단계에서, 공통 시간 기준에 대해 상기 기본 디지털 비디오 스트림을 시간 동기화하는 단계; 패턴 감지 단계에서, 제1 패턴 세트로부터 선택된 적어도 하나의 패턴을 감지하기 위해 시간 동기화된 기 본 디지털 비디오 스트림을 분석하는 단계 - 상기 패턴 감지는 상기 감지된 적어도 하나의 이벤트에 기초함 - ; 생성 단계에서, 상기 시간 동기화된 기본 디지털 비디오 스트림의 연속적으로 고려된 프레임 및 상기 감지된 패 턴에 기초하여 상기 공유 디지털 비디오 스트림을 출력 디지털 비디오 스트림으로서 생성하는 단계; 및 게시 단 계에서, 상기 출력 디지털 비디오 스트림을 상기 공유 디지털 비디오 스트림의 소비자에게 지속적으로 제공하는 단계를 포함한다. 본 발명은 또한 공유 디지털 비디오 스트림을 제공하기 위한 컴퓨터 소프트웨어 제품에 관한 것으로, 상기 컴퓨 터 소프트웨어 기능은 실행시, 각각의 기본 디지털 비디오 스트림이 적어도 두 개의 디지털 비디오 소스로부터 수집되는 수집 단계; 상기 기본 디지털 비디오 스트림이 제1 이벤트 세트로부터 선택된 적어도 하나의 이벤트를 감지하도록 개별적으로 분석되는 이벤트 감지 단계; 상기 기본 디지털 비디오 스트림이 공통 시간 기준에 대해 시간 동기화되는 동기화 단계; 상기 시간 동기화된 기본 디지털 비디오 스트림이 제1 패턴 세트로부터 선택된 적어도 하나의 패턴을 감지하도록 분석되는 패턴 감지 단계 - 상기 패턴 감지는 상기 감지된 적어도 하나의 이 벤트에 기초함 - ; 상기 공유 디지털 비디오 스트림이 상기 시간 동기화된 기본 디지털 비디오 스트림의 연속적 으로 고려되는 프레임과 상기 감지된 패턴에 기초하여 출력 디지털 비디오 스트림으로서 생성되는 생성 단계; 및 상기 출력 디지털 비디오 스트림이 상기 공유 디지털 비디오 스트림의 소비자에게 지속적으로 제공되는 게시 단계를 수행하도록 구성된다. 또한, 본 발명은 공유 디지털 비디오 스트림을 제공하기 위한 시스템에 관한 것으로, 중앙 서버를 포함하는 상 기 시스템은, 적어도 2개의 디지털 비디오 소스로부터 각각의 기본 디지털 비디오 스트림을 수집하도록 구성된 수집 기능; 제1 이벤트 세트로부터 선택된 적어도 하나의 이벤트를 감지하기 위해 상기 기본 디지털 비디오 스 트림을 개별적으로 분석하도록 구성된 이벤트 감지 기능; 공통 시간 기준에 대해 상기 기본 디지털 비디오 스트 림을 시간 동기화하도록 구성된 동기화 기능; 제1 패턴 세트로부터 선택된 적어도 하나의 패턴을 감지하기 위해 상기 시간 동기화된 기본 디지털 비디오 스트림을 분석하도록 구성된 패턴 감지 기능 - 상기 패턴 감지는 상기 감지된 적어도 하나의 이벤트에 기초함 - ; 상기 시간 동기화된 기본 디지털 비디오 스트림의 연속적으로 고려 되는 프레임 및 상기 감지된 패턴에 기초하여 상기 공유 디지털 비디오 스트림을 출력 디지털 비디오 스트림으 로서 생성하도록 구성된 생성 기능; 및 상기 출력 디지털 비디오 스트림을 상기 공유 디지털 비디오 스트림의 소비자에게 지속적으로 제공하도록 구성된 게시 기능을 포함한다."}
{"patent_id": "10-2024-7014195", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "모든 도면은 동일하거나 해당하는 부분에 대해서는 참조번호를 공유한다. 도 1은 공유 디지털 비디오 스트림을 제공하기 위해 본 발명에 따른 방법을 수행하도록 배열된 본 발명에 따른 시스템을 도시한다. 시스템은 비디오 통신 서비스를 포함할 수 있지만, 비디오 통신 서비스는 일부 실시 예에서는 시스템 외부에 있을 수도 있다. 시스템은 하나 또는 여러 개의 참여 클라이언트를 포함할 수 있지만, 일부 실시 예에서는 하나, 일부 또는 모든 참여 클라이언트가 시스템 외부에 있을 수도 있다. 시스템은 중앙 서버를 포함한다. 본 명세서에 사용된 바와 같이, \"중앙 서버\"라는 용어는 잘 정의된 API(응용 프로그래밍 인터페이스)를 통해 논 리적으로 중앙화된 방식으로 액세스되도록 배열된 컴퓨터로 구현 기능이다. 이러한 중앙 서버의 기능은 순수하 게 컴퓨터 소프트웨어로 구현되거나, 소프트웨어와 가상 및/또는 물리적 하드웨어와의 조합으로 구현될 수 있다. 이는 독립형 물리적 또는 가상 서버 컴퓨터에서 구현되거나 상호 연결된 여러 물리적 및/또는 가상 서버 컴퓨터에 분산될 수 있다. 중앙 서버가 실행되는 물리적 또는 가상 하드웨어, 즉 중앙 서버의 기능을 정의하는 컴퓨터 소프트웨 어는 본래 일반적인 CPU, 본래 일반적인 GPU, 본래 기존의 RAM/ROM 메모리, 본래 일반적인 컴퓨터 버스, 인터넷 연결과 같은 본래 일반적인 외부 통신 기능을 포함할 수 있다. 비디오 통신 서비스는 사용되는 정도에 있어서는 중앙 서버이고, 이는 중앙서버와는 다른 중앙 서버 이거나 중앙 서버의 일부일 수 있다. 이에 따라, 상기 참여 클라이언트 각각은 해당 해석으로 상기 의미에서 중앙 서버일 수 있고, 각 참여 클 라이언트가 실행되는 물리적 또는 가상 하드웨어, 즉 참여 클라이언트의 기능을 정의하는 컴퓨터 소 프트웨어는 또한 본래 일반적인 CPU/GPU, 본래 일반적인 RAM/ROM 메모리, 본래 일반적인 컴퓨터 버스, 인터넷 연결과 같은 본래 일반적인 외부 통신 기능을 포함할 수도 있다. 각 참여 클라이언트는 또한 일반적으로 진행 중인 비디오 통신의 일부로서 참여 클라이언트에 제공되 는 비디오 콘텐츠를 표시하도록 구성된 컴퓨터 화면; 상기 비디오 통신의 일부로서 참여 클라이언트에 제 공되는 사운드 콘텐츠를 방출하도록 구성된 확성기; 비디오 카메라; 및 상기 비디오 통신에 참여하는 인간 참가 자에게 로컬로 사운드를 녹음하도록 배열된 마이크로폰을 포함하거나 이와 통신하며, 참가자는 해당 참여 클라이언트를 사용하여 상기 비디오 통신에 참여한다. 다시 말해서, 각각의 참여 클라이언트의 각각의 인간-기계 인터페이스는 각각의 참가자가 비디오 통 신에서 해당 클라이언트와, 다른 참가자 및/또는 다양한 소스에 의해 제공되는 오디오/비디오 스트림과 상 호작용할 수 있도록 한다. 일반적으로, 참여 클라이언트 각각은 상기 비디오 카메라를 포함할 수 있는 각각의 입력 수단; 마이 크로폰; 키보드; 컴퓨터 마우스 또는 트랙패드; 및/또는 디지털 비디오 스트림, 디지털 오디오 스트림 및/또는 기타 디지털 데이터를 수신하기 위한 API을 포함한다. 입력 수단은 특히 비디오 통신 서비스 및/또는중앙 서버와 같은 중앙 서버로부터 비디오 스트림 및/또는 오디오 스트림을 수신하도록 구성되고, 이러한 비디오 스트림 및/또는 오디오 스트림은 비디오 통신의 일부로 제공되고 바람직하게는 예를 들어 이러한 디지털 데이터 입력 스트림의 적어도 두 소스, 예를 들어, 참여 클라이언트 및/또는 외부 소스(아래 참조)로부터 상기 중앙 서버에 제공되는 해당 디지털 데이터 입력 스트림을 기반으로 생성된다. 더 일반적으로, 참여 클라이언트 각각은 상기 컴퓨터 스크린을 포함할 수 있는 각각의 출력 수단; 상 기 확성기; 디지털 비디오 및/또는 오디오 스트림을 내보내는 API를 포함하고, 이러한 스트림은 해당 참여 클라 이언트를 사용하여 참가자에게 로컬로 캡처된 비디오 및/또는 오디오를 나타낸다. 실제로, 각 참여 클라이언트는 스크린, 확성기, 마이크로폰 및 인터넷 연결을 갖춘 휴대폰과 같은 모바일 장치일 수 있고, 이 때 모바일 장치는 로컬로 컴퓨터 소프트웨어를 실행하거나 원격으로 실행되는 컴퓨터 소프 트웨어에 액세스하여 해당 참여 클라이언트의 기능을 수행한다. 이에 따라, 참여 클라이언트는 경우 에 따라 웹 브라우저를 통해 원격으로 액세스되는 기능 등을 사용하여, 로컬로 설치된 애플리케이션을 실행하는 두껍거나 얇은 랩톱 또는 고정식 컴퓨터일 수도 있다. 현재 유형의 하나의 동일한 비디오 통신에 사용되는 적어도 세 개와 같이 하나 이상의 참여 클라이언트가 있을 수 있다. 본 명세서에 기술되고 예시되는 바와 같이, 비디오 통신은 적어도 부분적으로 비디오 통신 서비스에 의해 그리고 적어도 부분적으로 중앙 서버에 의해 제공될 수 있다. 본 명세서에서 용어가 사용되는 바와 같이, \"비디오 통신\"은 적어도 2개, 바람직하게는 적어도 3개의 비디오 스 트림을 포함하고, 바람직하게는 하나 또는 여러 소비자에 의해 소비되는 하나 또는 여러 개의 혼합 또는 공동 디지털 비디오/오디오 스트림을 생성하는 데 사용되는 오디오 스트림을 일치시킨 대화형 디지털 통신 세션이며, 이것은 비디오 및/또는 오디오를 통한 비디오 커뮤니케이션에 기여할 수도 있고 그렇지 않을 수도 있다. 이러한 비디오 통신은 특정 대기 시간이나 지연이 있거나 없이 실시간으로 이루어진다. 그러한 비디오 통신에 대한 적 어도 한 명, 바람직하게는 적어도 두 명의 참가자는 비디오/오디오 정보를 제공하고 소비하는, 대화형 방 식으로 비디오 통신에 참여한다. 참여 클라이언트 중 적어도 하나 또는 모든 참여 클라이언트는 이하서 더 자세히 설명되는 로컬 동기 화 소프트웨어 기능을 포함한다. 비디오 통신 서비스는 이하 더 자세히 설명되는 바와 같이, 공통 시간 기준을 포함하거나 그에 대한 액세 스를 가질 수 있다. 중앙 서버는 중앙 서버 외부의 개체와 디지털 방식으로 통신하기 위한 API를 포함할 수 있다. 그러한 통신은 입력과 출력을 모두 포함할 수 있다. 중앙 서버와 같은 시스템은 디지털 방식으로 통신하도록 구성될 수 있으며, 특히 오디오 및/또는 비 디오 스트림 데이터와 같은 디지털 정보를 외부에서 제공되는 비디오 스트림과 같은 외부 정보 소스로부터 수신하도록 구성될 수 있다. 정보 소스가 \"외부\"라는 것은 중앙 서버로부터 또는 중앙 서버의 일부로서 제공되지 않는다는 것을 의미한다. 바람직하게는, 외부 정보 소스가 제공하는 디지털 데이터는 중앙 서버와 독립적이며, 중앙 서버는 그 정보 내용에 영향을 미칠 수 없다. 예를 들어, 외부 정보 소스는 공개 스포츠 이벤트, 진행 중인 뉴스 이벤트 또는 보고 등의 실시간 캡처된 비디오 및/또는 오디오 일 수 있다. 외부 정보 소스는 웹 카메라 등을 통해 캡쳐될 수도 있지만, 참여 클라이언트 중 어느 하나에 의해서는 캡쳐될 수 없다. 따라서 이러한 캡처된 비디오는 참여 클라이언트 중 어느 하나와 동일한 위치를 묘사할 수 있지만, 참여 클라이언트 자체의 활동의 일부로서 캡처되지는 않는다. 외부에서 제공되 는 정보 소스와 내부적으로 제공되는 정보 소스 사이의 한 가지 가능한 차이점은 내부에서 제공되는 정보 소스는 상기 정의된 유형의 비디오 통신에 참가자로서 및 이들의 역량내에서 참가자로서 제공될 수 있는 반면, 외부에서 제공되는 정보 소스는 그렇지 않고 대신에 상기 화상 회의 외부에 있는 컨텍스트의 일부로 제공된다는 것이다. 오디오 및/또는 비디오 스트림과 같은 상기 유형의 디지털 정보를 중앙 서버에 병렬로 제공하는 여러 외부 정보 소스가 또한 있을 수 있다. 도 1에 도시된 바와 같이, 각각의 참여 클라이언트는 설명된 바와 같이 해당 참여 클라이언트에 의해 비디오 통신 서비스에 제공되는 정보(비디오 및/또는 오디오) 스트림의 소스를 구성한다.중앙 서버와 같은 시스템은 외부 소비자와 디지털 방식으로 통신하고, 특히 외부 소비자에 게 디지털 정보를 방출하도록 더욱 구성될 수 있다. 예를 들어, 중앙 서버에 의해 생성된 디지털 비디오 및/또는 오디오 스트림은 상기 API를 통해 하나 또는 여러 외부 소비자에게 실시간 또는 거의 실시간 으로 지속적으로 제공될 수 있다. 또한, 소비자가 \"외부\"라는 것은 소비자가 중앙 서버의 일부 로 제공되지 않거나, 상기 영상 통신의 당사자가 아니라는 것을 의미한다. 달리 명시하지 않는 한, 본 명세서에서의 모든 기능과 통신은 디지털 및 전자적으로 제공되며, 적절한 컴퓨터 하드웨어에서 실행되는 컴퓨터 소프트웨어에 의해 실행되고 인터넷과 같은 디지털 통신 네트워크 또는 채널을 통해 통신된다. 따라서, 도 1에 도시된 시스템 구성에서, 다수의 참여 클라이언트는 비디오 통신 서비스에 의해 제공되는 디지털 비디오 통신에 참여한다. 따라서 각 참여 클라이언트는 진행 중인 로그인, 세션 또는 비 디오 통신 서비스와 유사한 것을 가질 수 있으며, 비디오 통신 서비스에 의해 제공되는 동일한 진행 중인 비디오 통신에 참여할 수 있다. 즉, 비디오 통신은 참여 클라이언트 사이에서 및 이에 따라 또한 대 응하는 인간 참가자에 의해서 \"공유\"된다. 도 1에서, 중앙 서버는 참여 클라이언트에 대응하지만 인간 참가자와 연관되지 않는 자동화된 클라이언트인 자동 참여 클라이언트를 포함한다. 대신에, 자동 참여 클라이언트는 비디오 통신 서비 스에 참여 클라이언트로 추가되어 참여 클라이언트와 동일한 공유 영상통신에 참여하게 된다. 이러한 참여 클라이언트로서, 자동 참여 클라이언트는 비디오 통신 서비스에 의해 진행 중인 영상 통신의 일 부로서 제공되는 지속적으로 생성된 디지털 비디오 및/또는 오디오 스트림(들)에 대한 액세스가 승인되고, 자동 참여 클라이언트를 통해 중앙 서버에 의해 소비될 수 있다. 바람직하게, 자동 참여 클라이언트 는 비디오 통신 서비스로부터, 각 참여 클라이언트에 배포되거나 배포될 수 있는 공통 비디오 및/또 는 오디오 스트림; 하나 또는 여러 참여 클라이언트 각각으로부터 비디오 통신 서비스에 제공되고 원 시 또는 수정된 형태로 비디오 통신 서비스에 의해 모든 또는 요청하는 참여 클라이언트에게 중계되 는 개별 비디오 및/또는 오디오 스트림; 및/또는 공통 시간 참조를 수신한다. 중앙 서버는 자동 참여 클라이언트로부터 및 또한 가능하게 아래 설명된 처리를 위해 상기 외부 정보 소스(들)로부터 상기 유형의 비디오 및/또는 오디오 스트림을 수신하고, 그런 다음 API를 통해 공유 비디오 스트림을 제공하도록 구성된 수집 기능을 포함한다. 예를 들어, 이 공유 비디오 스트림은 외부 소 비자 및/또는 비디오 통신 서비스에 의해 소비되어 비디오 통신 서비스에 의해 참여 클라이언트 중 모든 또는 어느 요청자에게나 배포될 수 있다. 도 2는 도 1과 유사하지만, 자동 클라이언트 참가자를 사용하는 대신에 중앙 서버가 비디오 통신 서 비스의 API를 통해 진행 중인 비디오 통신으로부터 비디오 및/또는 오디오 스트림 데이터를 수신한다. 도 3도 또한 도 1과 유사하지만, 비디오 통신 서비스가 도시되지 않는다. 이 경우, 참여 클라이언트 는 중앙 서버의 API와 직접 통신하여, 예를 들어 중앙 서버에 비디오 및/또는 오디오 스트림 데 이터를 제공하고/하거나 중앙 서버로부터 비디오 및/또는 오디오 스트림 데이터를 수신한다. 이후, 생성된 공유 스트림은 외부 소비자 및/또는 클라이언트 참여자 중 하나 또는 여러 명에게 제공될 수 있다. 도 4는 중앙 서버를 더 자세히 도시한다. 도시된 바와 같이, 상기 수집 기능은 하나 또는 바람직하게 는 여러 개의 형식별 수집 기능(131a)을 포함할 수 있다. 상기 형식별 수집 기능(131a) 각각은 미리 결정된 이 진 인코딩 형식 및/또는 미리 결정된 스트림 데이터 컨테이너와 같은 미리 결정된 형식을 갖는 비디오 및/또는 오디오 스트림을 수신하도록 구성되며, 특히 상기 형식의 이진 비디오 및/또는 오디오 데이터를 개별 비디오 프 레임, 비디오 프레임 시퀀스 및/또는 시간 슬롯으로 구문 분석하도록 구성된다. 중앙 서버는 수집 기능으로부터 이진 스트림 데이터와 같은 비디오 및/또는 오디오 스트림 데이터를 수신하고 수신된 데이터 스트림 각각에 대해 각각의 이벤트 감지를 수행하도록 구성된 이벤트 감지 기능을 더 포함한다. 이벤트 감지 기능은 상기 이벤트 감지를 수행하기 위한 AI(인공지능) 구성요소트(132a)를 포 함할 수 있다. 이벤트 감지는 수집된 개별 스트림을 처음으로 시간 동기화하지 않고 발생할 수 있다. 중앙 서버는 수집 기능에 의해 제공되고 이벤트 감지 기능에 의해 처리되는 데이터 스트림을 시 간 동기화하도록 배열된 동기화 기능을 더 포함한다. 동기화 기능은 상기 시간 동기화를 수행하기 위 한 AI 구성요소(133a)를 포함할 수 있다.중앙 서버는 수신된 데이터 스트림 중 적어도 하나이지만, 많은 경우에는 적어도 2개, 예를 들어 적어도 3 개, 예를 들어 모두의 조합에 기초하여 패턴 감지를 수행하도록 구성된 패턴 감지 기능을 더 포함한다. 패 턴 감지는 또한 이벤트 감지 기능에 의해 상기 데이터 스트림 중 각각의 개별적인 것에 대해 감지된 하나, 또는 일부 경우에는 적어도 둘 이상의 이벤트에 기초할 수 있다. 상기 패턴 감지 기능에 의해 고려된 이러 한 감지된 이벤트는 각각의 개별적인 수집된 스트림에 대해 시간에 걸쳐 분포될 수 있다. 패턴 감지 기능 은 상기 패턴 감지를 수행하기 위한 AI 구성요소(134a)를 포함할 수 있다. 중앙 서버는 수집 기능으로부터 제공된 데이터 스트림에 기초하고 또한 임의의 감지된 이벤트 및/또 는 패턴에 기초하여 공유 디지털 비디오 스트림을 생성하도록 구성된 생성 기능을 더 포함한다. 공유 비디 오 스트림은 적어도 수집 기능에 의해 제공되고 원시 재형식화 또는 변환된 비디오 스트림 중 하나 또는 여러 개를 포함하도록 생성된 비디오 스트림을 포함하고, 또한 해당 오디오 스트림 데이터를 포함할 수도 있다. 중앙 서버는 상술된 바와 같이 예를 들어 API를 통해 생성된 공유 디지털 비디오 스트림을 게시하도 록 구성된 게시 기능을 더 포함한다. 도 1, 2 및 3은 본 명세서에 설명된 원리를 구현하고 특히 본 발명에 따른 방법을 제공하기 위해 중앙 서버 가 어떻게 사용될 수 있는지에 대한 세 가지 다른 예를 도시하지만, 하나 또는 여러 개의 비디오 통신 서 비스를 사용하거나 사용하지 않는 다른 구성이 또한 가능하다는 것에 주의한다. 따라서, 도 5는 상기 공유 디지털 비디오 스트림을 제공하기 위한 본 발명에 따른 방법을 도시한다. 도 6a-6f는 도 5에 도시된 방법의 단계로부터 결과된 다양한 디지털 비디오/오디오 데이터 스트림 상태를 도시한다. 상기 방법은 제1 단계에서, 시작한다. 후속 수집 단계에서, 각각의 기본 디지털 비디오 스트림(210, 301)은 예를 들어 상기 수집 기능에 의해 상 기 디지털 비디오 소스(120, 300) 중 적어도 2개로부터 수집된다. 이러한 기본 데이터 스트림(210, 301) 각각은 오디오 부분 및/또는 비디오 부분을 포함할 수 있다. 이러한 컨텍스트에서, \"비디오\"는 그러한 데이 터 스트림의 이동 및/또는 정지 이미지 콘텐츠를 의미하는 것으로 이해된다. 각각의 기본 데이터 스트림(210, 301)은 (해당 기본 스트림(210, 301)을 제공하는 개체가 사용하는 해당 코덱을 사용하여) 임의의 비디오/오디오 인코딩 사양에 따라 인코딩될 수 있으며, 인코딩 형식은 하나의 동일한 비디오 통신에서 동시에 사용되는 상기 기본 스트림(210, 301) 중 서로 다른 스트림에 걸쳐 다를 수 있다. 기본 데이터 스트림(210, 301) 중 적어도 하 나, 예를 들어 모두는 가능하게 본래 일반적인 데이터 컨테이너 데이터 구조로 제공되는, 이진 데이터 스트림으 로 제공되는 것이 바람직하다. 기본 데이터 스트림(210, 301) 중 적어도 하나, 예를 들어 적어도 2개 또는 심지 어 모두는 각각의 라이브 비디오 녹화로서 제공되는 것이 바람직하다. 기본 스트림(210, 301)은 수집 기능에 의해 수신될 때 시간 측면에서 비동기화될 수 있다는 것에 유의한다. 이는 이들이 서로에 대해 다른 대기 시간 또는 지연과 연관되어 있다는 것을 의미할 수 있다. 예를 들어, 두 개의 기본 비디오 스트림(210, 301)이 라이브 녹화인 경우에, 이것은 이들이 수집 기능에 의해 수신될 때, 녹화 시간과 관련하여 서로 다른 대기 시간과 연관되어 있는 것을 의미할 수 있다. 또한 기본 스트림(210, 301) 자체는 웹 카메라로부터의 각각의 라이브 카메라 피드; 현재 공유된 화면 또는 프 리젠테이션; 보기 필름 클립 또는 이와 유사한 것; 또는 하나의 동일한 화면에 다양한 방식으로 배열된 이들의 조합인 것에 유의한다. 수집 단계는 도 6a 및 6b에 나와 있다. 도 6b에는, 수집 기능이 각각의 기본 비디오 스트림(210, 301)을 번들 오디오/비디오 정보로서 또는 관련 비디오 스트림 데이터로부터 분리된 오디오 스트림 데이터로서 저장할 수 있는 방법이 도시되어 있다. 도 6b는 기본 비디오 스트림(210, 301) 데이터가 개별 프레임 또는 프레임 의 집합/클러스터로 저장되는 방법을 도시하고, 여기서 \"프레임\"은 이미지 데이터 및/또는 관련 오디오 데이터 의 시간이 제한된 부분을 의미하고, 예를 들어 각 프레임은 동영상 비디오 콘텐츠를 함께 형성하는 개별 정지 이미지 또는 연속적인 일련의 이미지(예를 들어, 최대 1초의 동영상을 구성하는 일련의 이미지)이다. 이벤트 감지 기능에 의해 수행되는 후속 이벤트 감지 단계에서, 상기 기본 디지털 비디오 스트림(210, 301)은 제1 이벤트 세트로부터 선택된 적어도 하나의 이벤트를 감지하기 위해, 예를 들어 상기 이벤트 감 지 기능 및 특히 상기 AI 구성요소(132a)에 의해 분석된다. 이것이 도 6c에 도시된다. 이 이벤트 감지 단계는 적어도 하나, 예를 들어, 적어도 두 개, 에를 들어, 모든 기본 비디오 스트림(210, 30 1)에 대해 수행되고, 각각의 기본 비디오 스트림(210, 301)에 대해 개별적으로 수행되는 것이 바람직하다. 다시말해서, 이벤트 감지 단계는 바람직하게 문제의 특정 기본 비디오 스트림(210, 301)의 일부로 포함된 정보만을 고려하고, 특히 다른 기본 비디오 스트림의 일부로 포함된 정보를 고려하지 않고, 상기 개별 기본 비디오 스트 림(210, 301)에 대해 발생한다. 뿐만 아니라, 이벤트 감지는 바람직하게는 여러 기본 비디오 스트림(210, 301) 과 관련된 공통 시간 기준을 고려하지 않고 발생한다. 반면에, 이벤트 감지는 0초, 예를 들어 적어도 0.1초, 예를 들어 적어도 1초보다 긴 기본 비디오 스트림의 과거 시간 간격과 같은, 특정 시간 간격에 걸쳐 문제의 개별적으로 분석된 기본 비디오 스트림의 일부로서 포함된 정 보를 고려하는 것이 바람직하다. 이벤트 감지는 상기 기본 비디오 스트림(210, 301)의 일부로서 포함된 오디오 및/또는 비디오 데이터에 포함된 정보를 고려할 수 있다. 상기 제1 이벤트 세트는 문제의 기본 데이터 스트림(210, 301)을 구성하거나 그 일부인 슬라이드 프리젠테이션 의 슬라이드 변경과 같은 임의의 수의 이벤트 유형; 이미지 품질 변화, 이미지 데이터 손실 또는 이미지 데이터 복구를 초래하는, 문제의 기본 비디오 스트림(210, 301)을 제공하는 소스(120, 300)의 연결 품질의 변화; 및 문 제의 기본 비디오 스트림(210, 301)에서 감지된 움직임 물리적 이벤트, 예를 들어, 비디오 속 사람이나 사물의 움직임, 비디오 속 조명의 변화, 오디오의 갑작스러운 날카로운 소음, 오디오 품질의 변화를 포함할 수 있다. 이는 완전한 목록이 되도록 의도된 것이 아니고, 이들 에는 현재 설명된 원리의 적용 가능성을 이해하기 위해 제공된다는 것이 인식된다. 동기화 기능에 의해 수행되는 후속 동기화 단계에서, 기본 디지털 비디오 스트림은 공통 시간 기준 에 대해 시간 동기화된다. 도 6d에 도시된 바와 같이, 이러한 시간 동기화는 공통 시간 기준을 사용 하여 기본 비디오 스트림(210, 301)을 서로에 관련하여 정렬하는 단계를 포함하므로, 이들은 시간 동기화된 컨 텍스트를 형성하도록 결합될 수 있다. 공통 시간 기준은 데이터 스트림, 하트비트 신호 또는 기타 펄스형 데이터, 또는 개별 기본 비디오 스트림(210, 301) 각각에 적용 가능한 시간 앵커일 수 있다. 중요한 것은 공통 시간 기준이 문제의 기본 비디오 스트림(210, 301)의 정보 콘텐츠가 공통 시간 축에 대한 공통 시간 기준과 명 확하게 관련될 수 있도록 하는 방식으로 개별 기본 비디오 스트림(210, 301) 각각에 적용될 수 있다는 것이다. 즉, 공통 시간 기준은 기본 비디오 스트림(210, 301)이 시간 이동을 통해 정렬되도록 허용하여, 현재 의미에서 시간 동기화된다. 도 6d에 도시된 바와 같이, 시간 동기화는 각각의 기본 비디오 스트림(210, 301)에 대해 공통 시간 기준과 관련하여 하나 또는 여러 개의 타임스탬프를 결정하는 단계를 포함할 수 있다. 패턴 감지 기능에 의해 수행되는 후속 패턴 감지 단계에서, 시간 동기화된 기본 디지털 비디오 스트림 (210, 301)은 제1 패턴 세트로부터 선택된 적어도 하나의 패턴을 감지하기 위해 분석된다. 이것이 도 6e에 도시된다. 이벤트 감지 단계와 달리, 패턴 감지 단계는 바람직하게는 함께 고려되는 시간 동기화된 기본 비디오 스트림 (210, 301) 중 적어도 2개의 일부로 포함된 비디오 및/또는 오디오 정보에 기초하여 수행될 수 있다. 상기 제1 패턴 세트는 다수의 유형의 패턴, 예를 들어, 여러 참가자가 상호 교환적으로 또는 동시에 말하거나; 여러 참가자가 말하는 것과 같이 여러 이벤트로서 동시에 발생하는 프레젠테이션 슬라이드 변경을 포함할 수 있 다. 이 목록은 완전한 것은 아니지만 설명을 위한 것이다. 대안적인 실시 예에서, 감지된 패턴은 상기 기본 비디오 스트림(210, 301) 중 여러 개에 포함된 정보에 관 한 것이 아니고, 상기 기본 비디오 스트림(210, 301) 중 하나에 포함된 정보에 관한 것일 수 있다. 그런 경우는, 이러한 패턴은 적어도 2개의 감지된 이벤트에 걸쳐 있는 단일 기본 비디오 스트림(210, 30 1)에 포함된 비디오 및/또는 오디오 정보, 예를 들어 2개 이상의 연속적으로 감지된 프리젠테이션 슬라이드 변 경 또는 연결 품질 변경에 기초하여 감지되는 것이 바람직하다. 일 예로, 시간이 지나면서 서로 빠르게 이어지 는 여러 개의 연속적인 슬라이드 변경이 감지된 각 슬라이드 변경 이벤트에 대해 하나의 개별 슬라이드 변경 패 턴과 반대로, 하나의 단일 슬라이드 변경 패턴으로 감지될 수 있다. 제1 이벤트 세트 및 상기 제1 패턴 세트는 각각의 매개변수 세트 및 매개변수 간격을 사용하여 정의된, 미리 결 정된 유형으로 된 이벤트/패턴을 포함할 수 있다는 것이 실현된다. 이하 설명되는 바와 같이, 상기 세트의 이벤 트/패턴은 또한 또는 추가로 다양한 AI 도구를 사용하여 정의되고 감지될 수 있다. 생성 기능에 의해 수행되는 후속 생성 단계에서, 공유 디지털 비디오 스트림은 시간 동기화된 기본 디지털 비디오 스트림(210, 301)의 연속적으로 고려되는 프레임 및 상기 감지된 패턴에 기초하여 출력 디지 털 비디오 스트림으로서 생성된다. 이하 상세히 설명되는 바와 같이, 본 발명은 출력 디지털 비디오 스트림의 완전한 자동 생성을 가능하게 한다. 예를 들어, 이러한 생성은 상기 출력 비디오 스트림; 출력 비디오 스트림의 비디오 화면 레이아웃; 시간에 따른 다양한 용도 또는 레이아웃 사이의 전환 패턴; 등에서 어느 정도까지 사용하기 위해 어떤 기본 비 디오 스트림(210, 301)으로부터 어떤 비디오 및/또는 오디오 정보를 선택할지를 포함할 수 있다. 이것은 상기 공통 시간 기준과 시간 동기화되어 출력 비디오 스트림의 생성 시 시간 동기화된 기본 비디오 스트림(210, 301)과 함께 사용될 수 있는 추가 디지털 비디오 정보 스트림과 같은, 시간 관련(공통 시간 기준과 관련) 디지털 비디오 정보 중 하나 또는 여러 개의 추가 부분을 보여주는 도 6f에 도시되어 있다. 예를 들어, 추가 스트림은 예를 들어 감지된 패턴에 동적으로 기초하여 사용할 임의의 비디오 및/또 는 오디오 특수 효과에 관한 정보; 비디오 통화를 위한 계획된 시간 일정; 등을 포함할 수 있다. 게시 기능에 의해 수행되는 후속 게시 단계에서, 생성된 출력 디지털 비디오 스트림은 전술한 바와 같이 공유 디지털 비디오 스트림의 소비자(110, 150)에게 지속적으로 제공된다. 후속 단계에서 방법은 종료된다. 그러나 먼저 이 방법은 연속적으로 제공되는 스트림으로서 출력 비디오 스트림 을 생성하기 위해 도 5에 도시된 바와 같이 임의의 횟수만큼 반복될 수 있다. 바람직하게, 출력 비디오 스 트림은 실시간 또는 거의 실시간으로 (모든 단계에서 추가되는 총 대기 시간을 고려하여), 및 지속적으로 (더 많은 정보가 제공되면 즉시 게시가 발생하지만 아래 설명된 의도적으로 추가된 대기 시간은 계산되지 않음) 소비되도록 생성된다. 이러한 방식으로, 출력 비디오 스트림은 대화형 방식으로 소비될 수 있으므로, 출력 비디오 스트림이 비디오 통신 서비스로 또는 닫힌 피드백 루프를 형성하기 위해 다시 수집 기능(13 1)에 공급되는 기본 비디오 스트림의 생성을 위한 기초를 형성하는 임의의 다른 컨텍스트로 피드백되거나; 출력 비디오 스트림이 다른(시스템 외부 또는 적어도 중앙 서버 외부) 컨텍스트로 소비될 수 있 지만 실시간 대화형 비디오 통신의 기초를 형성할 수 있다. 상술된 바와 같이, 일부 실시 예에서, 상기 기본 디지털 비디오 스트림(210, 301) 중 적어도 2개는 상기 비디오 통신 서비스에 의해 제공되는 것과 같은 공유 디지털 비디오 통신의 일부로 제공되고, 이 때 상기 비디오 통신은 문제의 기본 디지털 비디오 스트림을 제공하는 각각의 원격으로 연결된 참여 클라이언트를 포 함한다. 그런 경우에, 상기 수집 단계는 예를 들어 문제의 비디오 통신 서비스 내로부터 비디오 및/또는 오디오 스트림 데이터에 대한 액세스가 승인되는 자동 참여 클라이언트를 통해; 및/또는 비디오 통신 서비 스의 API를 통해, 공유 디지털 비디오 통신 서비스 자체로부터 상기 기본 디지털 비디오 스트림 중 적어도 하나를 수집하는 단계를 포함할 수 있다. 또한, 이 경우 및 그외 경우에, 수집 단계는 공유 디지털 비디오 통신 서비스 외부에 있는 정보 소스(30 0)로부터 수집된 각각의 외부 디지털 비디오 스트림으로서 상기 기본 디지털 비디오 스트림(210, 301) 중 적어도 하나를 수집하는 단계를 포함할 수 있다. 하나 또는 여러개의 외부 비디오 소스가 또한 중앙 서버 외부에 있을 수도 있다는 점에 유의한다. 일부 실시 예에서, 기본 비디오 스트림(210, 301)은 동일한 방식으로 포맷되지 않는다. 이러한 서로 다른 포맷 은 서로 다른 유형의 데이터 컨테이너(AVI 또는 MPEG 등)로 수집 기능에 전달되는 형태일 수 있지만, 바람 직한 실시 예에서 기본 비디오 스트림(210, 301) 중 적어도 하나는 이탈한 비디오 인코딩을 갖는 상기 이탈한 기본 디지털 비디오 스트림(210, 301); 이탈한 고정 또는 가변 프레임 속도; 이탈한 종횡비; 이탈한 비디오 해 상도; 및/또는 이탈한 오디오 샘플 속도의 관점에서, (상기 기본 비디오 스트림(210, 301) 중 적어도 하나와 비 교하여) 이탈 형식에 따라 포맷된다. 수집 기능은 수집된 모든 기본 비디오 스트림(210, 301)에서 발생하는 모든 인코딩 형식, 컨테이너 표준 등을 읽고 해석하도록 사전 구성되는 것이 바람직한다. 이는 본 명세서에 설명된 처리를 수행하는 것을 가능하 게 하며, 프로세스에서 상대적으로 늦은 시점까지(예를 들어 문제의 기본 스트림이 해당 버퍼에 배치될 때까지; 이벤트 감지 단계가 끝날 때까지; 또는 이벤트 감지 단계가 끝날 때까지) 어떤 디코딩도 요구하지 않는다. 그러 나 기본 비디오 피드(210, 301) 중 하나 또는 여러 개가 수집 기능이 디코딩 없이 해석할 수 없는 코덱을 사용하여 인코딩되는 드문 경우에, 수집 기능은 이러한 기본 비디오 스트림(210, 301)의 디코딩 및 분석을 수행한 후, 예를 들어 이벤트 감지 기능에 의해 처리될 수 있는 형식으로의 변환을 수행하도록 배열될 수 있다.이 경우에 이 단계에서는 어떠한 재인코딩도 수행하지 않는 것이 바람직하다는 점에 유의한다. 예를 들어, 비디오 통신 서비스에 의해 제공되는 것과 같은, 다자간 비디오 이벤트로부터 가져오는 기본 비디오 스트림은 일반적으로 낮은 대기 시간에 대한 요구 사항이 있으므로 일반적으로 참가자가 효과 적인 통신을 할 수 있도록 가변 프레임 속도 및 가변 픽셀 해상도와 연관된다. 즉, 낮은 대기 시간을 위해 필요 에 따라 전체 비디오 및 오디오 품질이 저하되게 된다. 반면, 외부 비디오 피드는 일반적으로 더 안정적인 프레임 속도, 더 높은 품질을 갖지만, 이에 따라 더 높 은 대기 시간을 가질 수 있다. 따라서, 비디오 통신 서비스는 매 순간 외부 비디오 소스와는 다른 인코딩 및/또는 컨테이너를 사용 할 수 있다. 따라서 본 명세서에서 설명된 분석 및 비디오 생성 프로세스는 서로 다른 형식의 스트림(210, 30 1)을 결합된 경험을 위한 새로운 스트림으로 결합해야 한다. 상술된 바와 같이, 수집 기능은 형식별 수집 기능(131a)의 세트를 포함할 수 있으며, 각각은 특정 유형의 형식의 기본 비디오 스트림(210, 301)을 처리하도록 구성된다. 예를 들어, 이러한 형식별 수집 기능(131a) 각각 은 Windows® Media® 또는 DivX®와 같은, 서로 다른 비디오 각각의 인코딩 방법/코덱을 사용하여 인코딩된 기 본 비디오 스트림(210, 301)을 처리하도록 배열될 수 있다. 그러나, 바람직한 실시 예에서, 수집 단계는 기본 디지털 비디오 스트림(210, 301) 중 적어도 2개 또는 모두를 공통 프로토콜로 변환하는 단계를 포함한다. 이 컨텍스트에서 사용되는 \"프로토콜\"이라는 용어는 디지털 비디오/오디오 스트림에 포함된 정보를 저장하는 방 법을 지정하는 정보 구조화 표준 또는 데이터 구조를 나타낸다. 그러나 공통 프로토콜은 바람직하게는 디지털 비디오 및/또는 오디오 정보(즉, 소리와 이미지 자체를 지시하는 인코딩/압축된 데이터)를 이진 레벨로 저장하 는 방법을 지정하지 않지만, 대신에 그러한 데이터를 저장하기 위해 미리 결정된 형식의 구조를 형성한다. 다시 말해서, 공통 프로토콜은 가능하게는 이진 형식 바이트 시퀀스를 연결 및/또는 분할하는 것 외에는 기존 이진 형식을 전혀 수정하지 않음으로써, 디지털 비디오 데이터를 저장과 관련하여 디지털 비디오 디코딩 또는 디지털 비디오 인코딩을 수행하지 않고 원시 이진 형식으로 저장하도록 규정한다. 대신에, 문제의 기본 비디오 스트림 (210, 301)의 원시(인코딩/압축된) 이진 데이터 콘텐츠는 프로토콜에 의해 정의된 데이터 구조에 이 원시 이진 데이터를 다시 압축하면서 유지된다. 일부 실시 예에서, 공통 프로토콜은 비디오 파일 컨테이너 형식을 정의한 다. 도 7은 일 예로서, 각각의 형식별 수집 기능(131a)에 의해 재구성되고 상기 공통 프로토콜을 사용하는, 도 6a에 도시된 기본 비디오 스트림(210, 301)을 도시한다. 따라서, 공통 프로토콜은 디지털 비디오 및/또는 오디오 데이터를 데이터 세트에 저장하는 것을 규정 하며, 바람직하게는 문제의 기본 비디오 스트림(210, 301)에 속하는 타임 라인을 따라 개별적이고 연속적인 데 이터 세트로 구분된다. 이러한 각 데이터 세트는 하나 또는 여러 개의 비디오 프레임과 관련 오디오 데이터를 포함할 수 있다. 공통 프로토콜은 또한 저장된 디지털 비디오 및/또는 오디오 데이터 세트와 관련하여 지정된 시점과 연관된 메타데이터를 저장하는 것을 규정할 수 있다. 메타데이터는 예를 들어, 원시 이진 데이터; 비디오 데이터의 해상도; 비디오 프레임 속도; 프레임 속도 가변성 플래그; 비디오 해상도; 비디오 종횡비; 오디오 압축 알고리즘; 또는 오디오 샘플링 속도를 생성하는 데 사용되는 디지털 비디오 인코딩 방법 또는 코덱과 관련하여, 문제의 기본 디지털 비디오 스트림의 원시 이 진 형식에 관한 정보를 포함할 수 있다. 메타데이터는 또한 문제의 기본 비디오 스트림(210, 301)의 시간 기준과 관련하여 저장된 데이터의 타임스탬프에 대한 정보를 포함할 수 있다. 상기 공통 프로토콜과 결합하여 상기 형식별 수집 기능(131a)을 사용하면 수신된 비디오/오디오 데이터를 디코딩/재인코딩하여 지연 시간을 추가하지 않고 기본 비디오 스트림(210, 301)의 정보 콘텐츠를 신속하게 수집 하는 것을 가능하게 한다. 따라서, 수집 단계는 문제의 기본 비디오 스트림(210, 301)을 구문 분석하고 관련 메타데이터와 함께 공통 프로 토콜을 사용하여 구문 분석된 원시 및 이진 데이터를 데이터 구조에 저장하기 위해서, 서로 다른 이진 비디오 및/또는 오디오 인코딩 형식을 사용하여 인코딩되는 기본 디지털 비디오 스트림(210, 301)을 수집하기 위해 상 기 형식별 수집 기능(131a) 중 서로 다른 기능을 사용하는 단계를 포함할 수 있다. 당연하게도, 어떤 형식별 수집 기능(131a)을 어떤 기본 비디오 스트림(210, 301)에 사용할 것인지에 대한 결정은 문제의 각 기본 비디오 스 트림(210, 301)의 사전 결정된 및/또는 동적으로 감지된 속성을 기반으로 하여 수집 기능에 의해 수행될 수 있다. 각각의 이렇게 수집된 기본 비디오 스트림(210, 301)은 중앙 서버의 RAM 메모리 버퍼와 같은, 자신의 별도 메모리 버퍼에 저장될 수 있다. 따라서, 각 형식별 수집 기능(131a)에 의해 수행되는 기본 비디오 스트림(210, 301)의 변환은 이렇게 변환된 각 각의 기본 디지털 비디오 스트림(210, 301)의 원시 이진 데이터를 상기 더 작은 데이터 세트의 정렬된 세 트로 분할하는 단계를 포함할 수 있다. 게다가, 변환은 또한 상기 작은 세트의 각각(또는 해당 기본 스트림(210, 301)의 각각의 시간 라인을 따라 규칙적으로 분포된 서브세트와 같은 서브세트)을 상기 공통 시간 기준의 각각의 시간과 연관시키는 것을 포함할 수 있다. 이러한 연관은 아래 설명된 기본 방식 중 하나 또는 다른 방식으로 원시 이진 비디오 및/또는 오디오 데이터를 분석하여 수행될 수 있으며, 기본 비디오 스트림(210, 301)의 후속 시간 동기화를 수행할 수 있도록 수행될 수 있다. 사용된 공통 시간 기준의 유형에 따라, 각 데이터 세트의 이러한 연관의 적 어도 일부는 또한 또는 대신 동기화 기능에 의해 수행될 수 있다. 후자의 경우, 수집 단계는 더 작은 세트 의 각각 또는 서브세트를 문제의 기본 스트림(210, 301)에 특정한 타임 라인의 각각의 시간과 연관시키는 단계를 포함할 수 있다. 일부 실시 예에서, 수집 단계는 또한 기본 비디오 스트림(210, 301)으로부터 수집된 원시 이진 비디오 및/또는 오디오 데이터를 균일한 품질 및/또는 업데이트 빈도로 변환하는 단계를 포함한다. 이는 필요에 따라 기본 디지 털 비디오 스트림(210, 301)의 원시 이진 디지털 비디오 및/또는 오디오 데이터를 공통 비디오 프레임 속도; 일 반적인 비디오 해상도; 또는 일반적인 오디오 샘플링 속도로 다운샘플링하거나 업샘플링하는 단계를 포함할 수 있다. 이러한 재샘플링은 문제의 형식별 수집 기능(131a)이 올바른 이진 인코딩 대상 형식에 따라 원시 이진 데 이터를 직접 처리할 수 있기 때문에, 전체 디코딩/재인코딩을 수행하지 않고도 수행될 수 있으며, 심지어는 어 떤 디코딩도 전혀 수행하지 않고도 수행될 수 있다는 것에 유의한다. 바람직하게, 상기 기본 디지털 비디오 스트림(210, 301) 각각은 개별 데이터 저장 버퍼에 상술된 바와 같 이 개별 프레임 또는 프레임의 시퀀스로 저장되고, 또한 각각은 상기 공통 시간 기준과 연관된 대응 타임 스탬프와 연관되어 있다. 설명을 위해 제공된 구체적인 예에서, 비디오 통신 서비스는 동시 참가자가 포함된 비디오 회의를 실 행하는 Microsoft® Teams®이다. 자동 참여 클라이언트는 Teems® 회의에서 회의 참가자로 등록된다. 다음에, 기본 비디오 입력 신호는 자동 참여 클라이언트를 통해 수집 기능에 이용 가능하고 이 에 의해 획득된다. 이는 H264 형식의 원시 신호이며 모든 비디오 프레임에 대한 타임스탬프 정보를 포함한다. 관련 형식별 수집 기능(131a)은 구성 가능한 사전 정의된 TCP 포트에서 IP(클라우드의 LAN 네트워크)를 통해 원 시 데이터를 선택한다. 모든 Teems® 회의 참가자와 관련 오디오 데이터는 별도의 포트와 연결된다. 그런 다음 수집 기능은 (50Hz인) 오디오 신호의 타임스탬프를 사용하고 비디오 스트림을 각각의 개별 버퍼(25 0)에 저장하기 전에 비디오 데이터를 25Hz의 고정 출력 신호로 다운샘플링한다. 상술된 바와 같이, 공통 프로토콜은 데이터를 원시 이진 형식으로 저장한다. 이는 매우 낮은 수준이 되어, 비디오/오디오 데이터의 원시 비트와 바이트를 처리하도록 설계될 수 있다. 바람직한 실시 예에서, 데이터는 단 순한 바이트 어레이 또는 대응하는 데이터 구조(슬라이스 등)로서 공통 프로토콜에 저장된다. 이것은 데이 터를 기존 비디오 컨테이너에 전혀 넣을 필요가 없는 것을 의미한다(이 컨텍스트에서 그러한 기존 컨테이너를 구성하지 않는 공통 프로토콜이 언급됨). 또한, 비디오 인코딩 및 디코딩은 계산량이 많아, 지연을 초래하 고 고가의 하드웨어가 필요하다. 게다가 이 문제는 참가자 수에 따라 확장된다. 공통 프로토콜을 사용하여, 각 Teams® 회의 참가자와 관련된 기본 비디오 스트림, 및 또한 외 부 비디오 소스에 대해 수집 기능에서 메모리를 예약한 다음에, 프로세스 중에 즉시 할당된 메모리 양을 변경하는 것이 가능해진다. 이러한 방식으로 입력 스트림 수를 변경하고, 결과적으로 각 버퍼를 효과적으 로 유지하는 것이 가능해진다. 예를 들어, 해상도, 프레임 속도 등과 같은 정보는 가변적일 수 있지만 공통 프 로토콜에 메타데이터로 저장되기 때문에, 이 정보는 필요에 따라 각 버퍼의 크기를 빠르게 조정하는 데 사 용될 수 있다.다음은 현재 유형의 공통 프로토콜 사양의 예이다. 바이트 예 설명 1바이트 1 0=비디오; 1=오디오 4바이트 1234567 버퍼 길이(정수) 8바이트 424234234 수신오디오/비디오 버퍼의 타임스탬프 틱 단위로 측정, 1틱=100ns(긴 정수) 1바이트 0 VideoColorFormat { NV12 = 0, Rgb24 = 1, Yuy2 = 2, H264 = 3 } 4바이트 720 비디오 프레임 픽셀 높이(정수) 4바이트 640 비디오 프레임 픽셀 너비(정수) 4바이트 25.0 비디오 프레임 속도 초당 프레임 수(부동) 1바이트 0 오디오 무음인가? 1 = 사실; 0 = 거짓 1바이트 0 AudioFormat { 0 = Pcm16K 1 = Pcm44KStereo } 1바이트 0 감지된 이벤트, 있는 경우 0 = 이벤트 없음 1,2,3 등=지정된 유형의 이벤트 감지 30바이트 향후 사용을 위해 예약 8바이트 1000000 바이트단위의 이진데이터 길이 (긴 정수) 변수 0x87A879… 이 프레임(들)의 원시 이진비디오/오디오 데이터 4바이트 1234567 주 스피커 포트 4바이트 1234567 활성 스피커 상기 \"있는 경우, 감지된 이벤트\" 데이터는 공통 프로토콜 260 사양의 일부로 포함된다. 그러나 일부 실시 예에 서, 이 정보(감지된 이벤트에 관한)는 대신 별도의 메모리 버퍼에 저장될 수 있다. 일부 실시 예에서, 오버레이 또는 효과일 수 있는 적어도 하나의 추가 디지털 비디오 정보는 또한, 공통 시간 기준과 연관된 해당 타임 스탬프와 각각 연관된 개별 프레임 또는 프레임 시퀀스로서 각각의 개별 버퍼에 저장된다. 위에서 예시한 바와 같이, 이벤트 감지 단계는 상기 공통 프로토콜을 사용하여 문제의 이벤트가 감지 된 기본 디지털 비디오 스트림(210, 301)과 연관된 감지된 이벤트를 설명하는 메타데이터를 저장하는 단계를 포함할 수 있다. 이벤트 감지는 다양한 방법으로 수행될 수 있다. 일부 실시 예에서, AI 구성요소(132a)에 의해 수행되는, 이벤 트 감지 단계는 임의의 이벤트를 자동으로 감지하기 위해서, 개별적으로 상기 기본 디지털 비디오 스트림 (210, 301) 중 적어도 하나, 예를 들어 여러 개 또는 전부를 분석하는 제1 훈련된 신경망 또는 기타 기계 학습 구성요소를 포함한다. 이는 관리되는 분류에서 기본 비디오 스트림(210, 301) 데이터를 사전 정의된 이벤트 세 트로 분류하고/하거나 관리되지 않는 분류에서 동적으로 결정된 이벤트 세트로 분류하는 AI 구성요소(132a)를 포함할 수 있다. 일부 실시 예에서, 감지된 이벤트는 문제의 기본 비디오 스트림(210, 301)이거나 이에 포함되는 프리젠테 이션의 프리젠테이션 슬라이드의 변경이다. 예를 들어, 프레젠테이션의 발표자가 그 시간에 청중에게 제공하고 있는 프레젠테이션의 슬라이드를 변경하기로 결정한다면, 이것은 특정 시청자에게는 흥미로운 것이 바뀔 수 있는 것을 의미한다. 새로 표시된 슬라이드는 소 위 \"버터플라이비\" 모드에서 잠깐 잘 볼 수 있는 하이 레벨의 화상일 수 있다(예를 들어, 출력 비디오 스트림 에는 슬라이드를 발표자의 비디오와 나란히 표시함). 대안적으로, 슬라이드는 많은 세부 정보, 작은 글꼴 크기의 텍스트 등을 포함할 수 있다. 후자의 경우, 슬라이드는 일반적인 경우 보다 다소 긴 시간 동안 전체 화 면으로 표시되어야 한다. 버터플라이 모드는 적절하지 않을 수 있는데, 이 경우 슬라이드는 발표자의 얼굴보다 프레젠테이션을 보는 사람에게 더 흥미로울 수 있기 때문이다. 실제로, 이벤트 감지 단계는 다음 중 적어도 하나를 포함할 수 있다: 첫째로, 이벤트는 감지된 슬라이드의 제1 이미지와 감지된 슬라이드의 후속하는 제2 이미지 간의 차이에 대한 이미지 분석을 기반으로 감지될 수 있다. 슬라이드를 보여주는 기본 비디오 스트림(220, 301)의 특성은 예 를 들어 OCR(광학 문자 인식)과 함께 동작 감지를 사용하여, 그 자체로 기존의 디지털 이미지 처리를 사용하여 자동으로 결정될 수 있다. 이것은 자동 컴퓨터 이미지 처리 기술을 사용하여 감지된 슬라이드가 실제로 슬라이드 변경으로 분류될 만큼 충 분히 크게 변경되었는지 확인하는 작업을 포함할 수 있다. 이는 RGB 색상 값과 관련하여 현재 슬라이드와 이전 슬라이드 사이의 델타를 확인하여 수행될 수 있다. 예를 들어, 문제의 슬라이드가 포함하는 화면 영역에서 RGB 값이 전체적으로 얼마나 변경되었는지 및 함께 속해 있고 함께 변화하는 픽셀 그룹을 찾는 것이 가능한지 여부 를 평가할 수 있다. 이러한 방식으로 관련 슬라이드 변경 사항을 감지하는 동시에 화면 전체에 표시된 컴퓨터 마우스 움직임과 같은 관련 없는 변경 사항을 필터링할 수 있다. 이 접근 방식을 사용하면 전체 구성도 가능하 고 - 예를 들어, 발표자가 컴퓨터 마우스를 사용하여 다른 항목을 가리키며 무언가를 자세히 발표하려는 경우, 컴퓨터 마우스 움직임을 캡처할 수 있기를 원할 때도 있다. 둘째, 이벤트는 상기 제2 이미지 자체의 정보적 복잡성에 대한 이미지 분석을 기반으로 감지되어 이벤트의 유형을 보다 구체적으로 결정할 수 있다. 이것은 예를 들어, 문제의 슬라이드에 있는 텍스트 정보의 총량과 관련 글꼴 크기를 평가하는 작업을 포함할 수 있다. 이는 딥러닝 기반 문자 인식 기술과 같은 기존 OCR 방법을 사용하여 수행할 수 있다. 평가된 비디오 스트림(210, 301)의 원시 이진 형식은 알려져 있기 때문에, 이것은 비디오 데이터를 먼저 디코딩 하거나 다시 인코딩하지 않고 이진 도메인에서 직접 수행될 수 있다는 것에 유의한다. 예를 들어, 이벤트 감지 기능은 이미지 해석 서비스를 위한 해당 형식별 수집 기능을 호출할 수 있거나, 이벤트 감지 기능은 다수의 다양한 지원되는 원시 이진 비디오 데이터 형식에 대해, 개별 픽셀 수준과 같은 이미지 정보를 평가하는 기능을 자체적으로 포함할 수 있다. 또 다른 예에서는, 감지된 이벤트는 참여 클라이언트와 디지털 비디오 통신 서비스의 통신 연결 이 끊긴 것이다. 그 다음, 감지 단계는 상기 참여 클라이언트가 문제의 참여 클라이언트에 대응하는 기본 디지털 비디오 스트림의 일련의 후속 비디오 프레임의 이미지 분석에 기초하여 통신 연결이 끊 긴 것을 감지하는 단계를 포함할 수 있다. 참여 클라이언트는 서로 다른 물리적 위치와 서로 다른 인터넷 연결과 연관되어 있으므로, 누군가가 비디 오 통신 서비스 또는 중앙 서버에 대한 연결이 끊기는 일이 발생할 수 있다. 이러한 상황에서, 생성 된 출력 비디오 스트림에서 검은 화면이나 빈 화면을 표시하는 것을 피하는 것이 바람직한다. 대신에, 이러한 연결 끊김은 예를 들어 사용된 2개의 클래스가 연결/연결되지 않은(데이터 없음) 2-클래스 분류 알고리즘을 적용하여, 이벤트 감지 기능에 의해 이벤트로 감지될 수 있다. 이 경우, '데이터 없음'은 발표 자가 의도적으로 검은 화면을 보내는 것과는 다른 것으로 이해된다. 1~2 프레임 정도의 짧은 검은 화면은 최종 생성 스트림에서는 눈에 띄지 않을 수 있으므로, 시계열을 생성하기 위해 시간이 지남에 따라 상기 2-클래 스 분류 알고리즘을 적용할 수 있다. 그런 다음 연결 중단의 최소 길이를 지정하는 임계값을 사용하여 연결이 끊어졌는지 여부를 결정할 수 있다. 다음에 설명되는 바와 같이, 이러한 예시적인 유형의 감지된 이벤트는 적합하고 원하는 대로 다양한 조치를 취 하기 위해 패턴 감지 기능에 의해 사용될 수 있다. 상술된 바와 같이, 개별 기본 비디오 스트림(210, 301)은 각각 공통 시간 기준과 관련되어 있으므로, 동기 화 기능이 서로에 대해 시간 동기화하는 것을 가능하게 한다. 일부 실시 예에서, 공통 시간 기준은 공통 오디오 신호에 기초하거나 이를 포함하고(도 1-3 참조), 공통 오디오 신호는 위에서 설명된 바와 같이 적어도 두 개의 원격으로 연결된 참여 클라이언트를 포 함하는 공유 디지털 비디오 통신 서비스에 공통이며, 각각은 상기 기본 디지털 비디오 스트림 중 하 나를 제공한다. 위에서 설명한 Microsoft® Teams®의 예에서, 공통 오디오 신호가 생성되고 자동 참여 클라이언트 및/또 는 API를 통해 중앙 서버에 의해 캡처될 수 있다. 이 예와 다른 예에서, 그러한 공통 오디오 신호는 이 하트비트 신호에 기초하여 각각의 기본 데이터 스트림을 특정 시점에 바인딩함으로써 개별 기본 비디오 스트 림을 시간 동기화하기 위한 하트비트 신호로 사용될 수 있다. 이러한 공통 오디오 신호는 (다른 기본 비디 오 스트림 각각과 관련하여) 별도의 신호로 제공될 수 있고, 이에 따라 다른 기본 비디오 스트림은 각각 문제의 다른 기본 비디오 스트림에 포함된 오디오에 기초하거나 심지어 거기에 포함된 이미지 정보에 기초하여(예를 들어, 자동 이미지 처리 기반 립싱크 기술 사용하여) 공통 오디오 신호와 개별적으로 시간 상관 될 수 있다. 즉, 개별 기본 비디오 스트림과 관련된 임의의 변수 및/또는 다른 대기 시간을 처리하기 위해, 그리고 결 합된 비디오 출력 스트림에 대한 시간 동기화를 달성하기 위해, 이러한 공통 오디오 신호는 중앙 서버 의 모든 기본 비디오 스트림(그러나 외부 기본 비디오 스트림은 아닐 수도 있음)에 대한 하트비 트로 사용된다. 즉, 다른 모든 신호는 이 공통 오디오 시간 하트비트에 매핑되어 모든 것이 시간 동기화되도록 한다. 다른 예에서, 시간 동기화는 출력 디지털 비디오 스트림에 도입된 시간 동기화 요소를 사용하여 달성 되며, 참여 클라이언트 중 하나 또는 여러 개별 클라이언트의 일부로 제공되는 각각의 로컬 시간 동기화 소프트웨어 기능에 의해 감지되고, 로컬 소프트웨어 기능은 출력 비디오 스트림에서 시간 동기 화 요소의 도착 시간을 감지하도록 배열된다. 이해되는 바와 같이, 이러한 실시 예에서 출력 비디오 스트 림은 비디오 통신 서비스로 피드백되거나 아니면 각 참여 클라이언트 및 문제의 로컬 소프트웨 어 기능이 이용 가능하게 된다. 예를 들어, 시간 동기화 요소는 예를 들어, 일정한 시간 간격으로 출력 비디오에 배치되거나 업데이 트되는 미리 결정된 순서 또는 방식의 픽셀 변경 생상; 출력 비디오에 업데이트되어 표시되는 시각적 시계; 출력 비디오 스트림의 오디오 형성 부분에 추가된 사운드 신호(예를 들어 충분히 낮은 진폭 및/또는 충분히 높은 주파수를 가짐으로써 참가자가 들을 수 없도록 설계될 수 있음)와 같은, 시각적 마커일 수 있 다. 로컬 소프트웨어 기능은 적절한 이미지 및/또는 오디오 처리를 사용하여 각 시간 동기화 요소 (들)의 각각의 도착 시간을 자동으로 감지하도록 구성된다. 그러면, 공통 시간 기준은 상기 감지된 도착 시간에 적어도 부분적으로 기반하여 결정될 수 있다. 예를 들 어, 각 로컬 소프트웨어 기능은 상기 감지된 도착 시간을 나타내는 각각의 정보를 중앙 서버에 전달 할 수 있다. 이러한 통신은 해당 참여 클라이언트와 중앙 서버 사이의 직접 통신 링크를 통해 이루어질 수 있다. 하지만, 통신은 문제의 참여 클라이언트와 관련된 기본 비디오 스트림을 통해 이루어질 수도 있다. 예를 들어, 참여 클라이언트는 중앙 서버에 의한 자동 감지를 위해 문제의 참여 클라이언트에의해 생성되어 공통 시간 기준을 결정하는 데 사용되는 기본 비디오 스트림에서, 상술된 유형과 같은 시각적 또는 청각적 코드를 도입할 수 있다. 추가적인 예에서는, 각 참여 클라이언트는 비디오 통신 서비스에 대해 모든 참여 클라이언트가 시청할 수 있는 공통 비디오 스트림에서 이미지 감지를 수행할 수 있고 이러한 이미지 감지 결과를 상술된 것과 대응하는 방식으로 중앙 서버에 전달하여, 그곳에서 시간이 지남에 따라 서로 관련하여 각 참여 클라이언 트의 개별 오프셋을 결정하기 위해 사용된다. 이러한 방식으로, 공통 시간 기준은 개별 상대 오프셋 의 세트로서 결정될 수 있다. 예를 들어, 일반적으로 사용 가능한 비디오 스트림의 선택된 참조 픽셀은 상기 로 컬 소프트웨어 기능과 같은 여러 또는 모든 참여 클라이언트에 의해 모니터링될 수 있고, 해당 픽셀 의 현재 색상이 중앙 서버로 전달될 수 있다. 중앙 서버는 다수의 (또는 전체) 참여 클라이언트 각각으로부터 연속적으로 수신된 이러한 색상 값을 기초로 각각의 시계열을 계산할 수 있으며, 서로 다른 참여 클라이언트에 걸쳐 상대적인 시간 오프셋의 추정된 세트를 초래하는 상호 상관을 수행할 수 있다. 실제로, 비디오 통신 서비스에 공급되는 출력 비디오 스트림은 문제의 비디오 통신의 모든 참여 클라 이언트의 공유 화면의 일부로서 포함될 수 있고, 따라서 참여 클라이언트와 연관된 그러한 시간 오프셋을 평가하는 데 사용될 수 있다. 특히, 비디오 통신 서비스에 공급되는 출력 비디오 스트림은 자동 참여 클라이언트 및/또는 API를 통해 중앙 서버에서 다시 이용 가능해질 수 있다. 일부 실시 예에서, 공통 시간 기준은 상기 기본 디지털 비디오 스트림(210, 301) 중 제1 스트림의 오디오 부분과 상기 제1 기본 디지털 비디오 스트림(210, 301)의 이미지 부분 사이의 감지된 불일치에 적어 도 부분적으로 기초하여 결정될 수 있다. 이러한 불일치는 예를 들어, 문제의 상기 제1 기본 디지털 비디오 스 트림(210, 301)에서 보이는 발언 참가자의 디지털 립싱크 비디오 이미지 분석에 기초할 수 있다. 이러한 립싱크 분석은 그 자체로 기존 방식이며, 예를 들어 훈련된 신경망을 사용할 수 있다. 분석은 이용 가능한 공통 오디오 정보와 관련하여 각 기본 비디오 스트림(210, 301)에 대해 동기화 기능에 의해 수행될 수 있으며, 개별 기본 비디오 스트림(210, 301)에 걸친 상대적인 오프셋은 이 정보에 기초하여 결정될 수 있다. 일부 실시 예에서, 동기화 단계는 의도적으로 최대 30초, 예를 들어 최대 5초, 최대 1초, 최대 0.5초 등 0초보 다 긴 대기 시간을 도입하는 것으로 구성되므로, 출력 디지털 비디오 스트림에는 적어도 상기 대기 시간이 제공된다. 여하튼, 의도적으로 도입된 대기 시간은 수집 단계에서 리샘플링 후에 저장된 프레임(또는 개별 이미 지) 수와 같이 적어도 3개, 심지어는 적어도 5개 또는 심지어 10개와 같은 적어도 여러 개의 비디오 프레임이다. 본 명세서에 사용된 바와 같이, \"의도적으로\"라는 용어는 동기화 문제 등을 기반으로 대기 시간을 도입해야 하는 필요성과 관계없이 대기 시간이 도입되는 것을 의미한다. 다시 말해서, 서로 시간을 동기화하기 위해서 기본 비디오 스트림(210, 301)의 동기화의 일부로 도입된 대기 시간에 추가로 의도적으로 도입된 대기 시간이 도입된다. 의도적으로 도입된 대기 시간은 공통 시간 기준과 관련하여 미리 결정되거나 고정되거나 가변적일 수 있다. 지연 시간은 기본 비디오 스트림(210, 301) 중 가장 적게 잠재된 스트림과 관련하여 측정될 수 있다. 따라서 상기 시간 동기화의 결과로 이들 스트림(210, 301) 중 더 많은 잠재 스트림은 상대적으로 더 작은 의도적으로 추가된 대기 시간과 연관된다. 일부 실시 예에서는 0.5초 이하와 같이 상대적으로 작은 대기 시간이 도입된다. 이러한 대기 시간은 출력 비디 오 스트림을 사용하는 비디오 통신 서비스에 대한 참가자가 거의 인지할 수 없을 것이다. 다른 실시 예에서, 예를 들어, 출력 비디오 스트림은 대화형 컨텍스트에서 사용되지 않고 대신 외부 소비자에 대해 단방향 통신으로 게시되는 경우, 더 큰 대기 시간이 도입될 수 있다. 의도적으로 도입된 대기 시간은 동기화 기능이 수집된 개별 기본 스트림(210, 301) 비디오 프레임을 올바 른 공통 시간 기준 타임스탬프에 매핑하는 데에 충분한 시간을 달성한다. 이는 또한 손실된 기본 스 트림(210, 301) 신호, 슬라이드 변경, 해상도 변경 등을 감지하기 위해 위에서 설명한 이벤트 감지를 수행하는 데 충분한 시간을 허용한다. 뿐만 아니라, 의도적으로 상기 대기 시간을 도입함으로써 이하에 설명되는 바와 같 이 개선된 패턴 감지 기능이 가능해진다. 상기 대기 시간의 도입은 문제의 버퍼링된 프레임을 사용하여 출력 비디오 스트림을 게시하기 전에, 수집되고 시간 동기화된 기본 비디오 스트림(210, 301) 각각을 버퍼링하는 단계를 포함한다는 것이 인식된 다. 다시 말해서, 기본 비디오 스트림(210, 301) 중 적어도 하나, 여러 개 또는 심지어 전부의 비디오 및/또는 오디오 데이터는 캐시와 마찬가지로 버퍼링된 방식으로 중앙 서버에 존재하지만 (기존 캐시 버퍼와 유사하 게) 다양한 대역폭 상황을 처리할 수 있는 의도로 사용되지는 않고 상기 이유로 특히 패턴 감지 기능에 의 해 사용된다.따라서 일부 실시 예에서, 상기 패턴 감지 단계는 기본 디지털 비디오 스트림(210, 301) 중 여러 개 또는 심지 어 전부와 같은 적어도 하나의 특정 정보를 고려하는 단계를 포함하고, 특정 정보는 아직 출력 디지털 비디오 스트림의 생성에 사용될 시간 동기화된 기본 디지털 비디오 스트림의 프레임보다 나중 프레임에 존재한다. 따라서 새로 추가된 프레임은 출력 비디오 스트림의 일부(또는 기초)를 형성하기 전에 특 정 대기 시간 동안 문제의 버퍼에 존재할 것이다. 이 기간 동안, 문제의 프레임에 있는 정보는 출력 비디오 스트림의 현재 프레임을 생성하기 위해 현재 사용되는 프레임과 관련된 \"미래\"의 정보를 구성할 것 이다. 출력 비디오 스트림 타임라인이 문제의 프레임에 도달하면, 이것은 출력 비디오 스트림의 해당 프레임의 생성에 사용될 것이며 그 후에 폐기될 수 있다. 다시 말해서, 패턴 감지 기능은 출력 비디오 스트림을 생성하는 데 아직 사용되지 않은 비디오/오디 오 프레임 세트를 처리할 수 있고, 이 데이터를 사용하여 상기 패턴을 감지한다. 패턴 감지는 다양한 방식으로 수행될 수 있다. AI 구성요소(134a)에 의해 수행되는 일부 실시 예에서, 패턴 감 지 단계는 상기 패턴을 자동으로 감지하기 위해 상기 기본 디지털 비디오 스트림(120, 301) 중 적어도 2개, 예를 들어 적어도 3개 또는 심지어 전부를 분석하는 제2 훈련된 신경망 또는 다른 기계 학습 구성요소를 포함한다. 일부 실시 예에서, 감지된 패턴은 공유 비디오 통신 서비스에 대해 각각의 참여 클라이언트와 각각 연관된 적어도 2명의 서로 다른 발언 참가자를 포함하는 말하기 패턴을 포함하고, 상기 발언 참가자 각각은 상기 기본 디지털 비디오 스트림(210, 301) 각각에서 시각적으로 보여진다. 생성 단계는 바람직하게는 출력 비디오 스트림의 현재 생성 상태를 결정하고, 추적하고, 업데이트하는 단 계를 포함한다. 예를 들어, 이러한 상태는 참가자가 출력 비디오 스트림에서 볼 수 있는 것이 무엇인 지, 그리고 화면의 어디에 있는지; 외부 비디오 스트림이 출력 비디오 스트림에 표시되는지, 그리고 화면의 어디에 있는지; 슬라이드나 공유 화면이 전체 화면 모드로 표시되거나 라이브 비디오 스트림과 함께 표 시되는지 여부 등등을 지시할 수 있다. 그러므로, 생성 기능는 생성된 출력 비디오 스트림에 관한 상 태 머신으로 볼 수 있다. 예를 들어 최종 소비자가 볼 수 있는 결합된 비디오 경험으로 출력 비디오 스트 림을 생성하려면, 개별 기본 비디오 스트림(210, 301)과 관련된 개별 이벤트를 단순히 감지하는 것보다 더 깊은 수준에서 무슨 일이 일어나는지 중앙 서버가 이해할 수 있다는 것이 유리한다. 제1 예에서, 발표 참여 클라이언트는 현재 보고 있는 슬라이드를 변경하고 있다. 이 슬라이드 변화는 전술 한 바와 같이 이벤트 감지 기능에 의해 감지되고, 발생한 슬라이드 변화를 나타내는 메타데이터가 문 제의 프레임에 추가된다. 이런 일이 여러 번 발생하는데, 이것은 발표 참여 클라이언트가 빠르게 연속해서 앞으로 여러 슬라이드를 건너뛴 것으로 밝혀졌기 때문이고, 결과적으로 짝수 감지 기능에 의해 감지되고 해당 기본 비디오 스트림에 대한 개별 버퍼에 해당 메타데이터와 함께 저장되는 일련의 \"슬라이 드 변경\" 이벤트가 발생한다. 실제로 이렇게 빠르게 앞으로 건너뛴 슬라이드는 단 몇 분의 1초 동안만 표시될 수 있다. 이러한 감지된 슬라이드 변화 중 여러 개에 걸쳐 있는 문제의 버퍼에 있는 정보를 보는, 패턴 감지 기능 은 다수의 또는 빠르게 수행된 슬라이드 변경이 아닌, 하나의 단일 슬라이드 변경(즉, 앞으로 건너뛰기의 마지막 슬라이드, 빠른 건너뛰기가 끝나면 다시 표시되는 슬라이드)에 해당하는 패턴을 감지하게 된다. 다시 말 해서, 패턴 감지 기능은 예를 들어 매우 짧은 시간 내에 10개의 슬라이드 변경이 있음을 알 수 있으며, 감 지된 패턴으로 처리되는지 이유는 하나의 단일 슬라이드 변경을 나타낸다. 패턴 감지 기능에 의해 감지된 패턴에 액세스하는 생성 기능은 몇 초 동안 출력 비디오 스트림에서 전체 화면 모드로 최종 슬라이드 를 표시하도록 선택할 수 있는데, 이는 이 슬라이드가 상기 상태 머신에서 잠재적으로 중요하다고 판단하기 때 문이다. 또한 출력 스트림에서 중간에 본 슬라이드를 전혀 표시하지 않도록 선택할 수도 있다. 여러 개의 빠르게 변경한 슬라이드의 패턴은 간단한 규칙 기반 알고리즘에 의해 감으로 감지될 수 있지만, 분류 에 따라 움직이는 이미지에서 이러한 패턴을 감지하도록 설계되고 훈련된 신경망을 사용하여 대안적으로 감지될 수 있다. 비디오 커뮤니케이션이 토크쇼, 패널 토론 또는 이와 유사한 경우에 유용할 수 있는 다른 예에서, 현 재 화자와 조용하고 부드러운 출력 비디오 스트림을 생성하고 게시함으로써 여전히 소비자에게 적절 한 시청 경험을 제공하는 것 사이에서 시각적 주의를 빠르게 전환하는 것이 바람직하다. 이 경우, 이벤트 감지 기능은 특정 기본 비디오 스트림(210, 301)에서 보고 있는 사람이 현재 말하고 있는지 여부를 항상 결정하 기 위해 각 기본 비디오 스트림(210, 301)을 지속적으로 분석할 수 있다. 이는 예를 들어, 본래 일반적인 이미 지 처리 도구를 사용하여 위에서 설명한 대로 수행될 수 있다. 그 다음, 패턴 감지 기능은 상기 기본 비디오 스트림(210, 301) 중 몇몇을 포함하는 특정 전체 패턴을 감지하도록 동작할 수 있으며, 상기 패턴은 원활한 출력 비디오 스트림을 생성하는 데 유용하다. 예를 들어, 패턴 감지 기능은 현재 화자 및/또는 여러 동시 화자와 관련된 패턴 사이에서 매우 빈번한 전환 패턴을 감지할 수 있다. 그러면, 생성 기능은 예를 들어 0.5초 동안만 말하고 다시 침묵하는 화자에게 시각적 초점을 자동으로 전 환하지 않거나, 두 사람이 번갈아 가거나 동시에 말하는 경우 일정 시간 동안 여러 명의 화자가 나란히 표시되 는 상태로 전환함으로써, 상기 생성 상태와 관련하여 자동화된 결정을 내릴 때 이러한 감지된 패턴을 고려할 수 있다. 이러한 상태 결정 프로세스는 시계열 패턴 인식 기술을 사용하거나, 훈련된 신경망을 사용하여 자체적으 로 수행될 수 있지만, 미리 결정된 규칙 세트에 적어도 부분적으로 기초할 수도 있다. 일부 실시 예에서, 병렬로 감지되어 생성 기능 상태 머신에 대한 입력을 형성하는 여러 패턴이 있을 수 있 다. 이러한 다중 패턴은 생성 기능에 의해 다양한 AI 구성 요소, 컴퓨터 비전 감지 알고리즘 등에 의해 사 용될 수 있다. 예를 들어, 일부 참여 클라이언트의 불안정한 연결을 동시에 감지하며서 영구적인 슬라이드 변경이 감지될 수 있는 반면, 다른 패턴은 현재 주 발언 참가자를 감지할 수 있다. 이러한 모든 사용 가능 한 패턴 데이터를 사용하여, 분류기 신경망이 훈련될 수 있으며, 및/또는 이러한 패턴 데이터의 시계열 분석을 위해 규칙 세트가 개발될 수 있다. 이러한 분류는 적어도 부분적으로, 예를 들어 완전히 감독되어 상기 생성에 사용될 결정된 원하는 상태 변경이 발생하도록 할 수 있다. 예를 들어, 이러한 미리 결정된 분류기가 생성될 수 있으며, 특히 다양하고 서로 다른 생성 스타일 및 요구 사항에 따라 출력 비디오 스트림을 자동으로 생성 하도록 배열될 수 있다. 훈련은 원하는 출력으로 알려진 생성 상태 변경 시퀀스와 훈련 데이터로 알려진 패턴 시계열 데이터를 기반으로 할 수 있다. 일부 실시 예에서, 베이지안(Bayesian) 모델은 이러한 분류기를 생성하 는 데 사용될 수 있다. 구체적인 예로, 경험이 풍부한 프로듀서로부터 선험적으로 정보가 수집될 수 있어, \"토 크쇼에서 나는 화자 A에서 화자 B로 직접 전환하지 않고, 다른 화자가 매우 지배적으로 큰 소리로 말하는 경우 를 제외하고는 항상 다른 화자에게 초점을 맞추기 전에 먼저 개요를 보여준다\"와 같은 입력을 제공할 수 있다. 이 생성 논리는 \"X가 참인 경우 |Y가 참이라는 사실을 고려해볼 때| Z를 수행한다\"라는 일반 형태에 대해 베이 지안 모델로 표현될 수 있다. (누군가 큰 소리로 말하고 있는지 등에 대한) 실제 감지는 분류자 또는 임계값 기 반 규칙을 사용하여 수행될 수 있다. (패턴 시계열 데이터의) 대규모 데이터 세트를 사용하면, 딥 러닝 방법을 사용하여 비디오 스트림의 자동화된 생성에 사용할 정확하고 매력적인 생성 형식을 개발할 수 있다."}
{"patent_id": "10-2024-7014195", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "요약하면, 개별 기본 비디오 스트림(210, 301)을 기반으로 하는 이벤트 감지; 의도적으로 도입된 대기 시간; 여 러 시간 동기화된 기본 비디오 스트림(210, 301) 및 감지된 이벤트에 기초한 패턴 감지; 및 감지된 패턴을 기반 으로 하는 생성 공정의 조합을 사용하게 되면 다양한 취향과 스타일 선택에 따라 출력 디지털 비디오 스트림 의 자동화된 생성을 달성하는 것을 가능하게 한다. 이 결과는 이벤트 감지 기능, 패턴 감지 기능 및 생성 기능에 의해 사용되는 광범위한 가능한 신경망 및/또는 규칙 기반 분석 기술에 걸쳐 유효하 다. 위에서 예시한 바와 같이, 생성 단계는 상기 출력 디지털 비디오 스트림에 있는 상기 기본 디지털 비디오 스트림(210, 301) 중 개별적인 가시성에 관한 사전 결정된 및/또는 동적으로 가변적인 매개변수 세트; 시각적 및/또는 청각적 비디오 콘텐츠 배열; 사용되는 시각 또는 청각 효과 ; 및/또는 출력 디지털 비디오 스트림(23 0)의 출력 모드에 기초하여 출력 디지털 비디오 스트림을 생성하는 단계를 포함할 수 있다. 이러한 매개변 수는 상기 생성 기능 상태 기계에 의해 자동으로 결정될 수 있고 및/또는 생성을 제어하는 조작자(반자동 으로 만듦)에 의해 설정될 수 있고 및/또는 특정한 선험적 구성 요구(예를 들어 출력 비디오 스트림 레이 아웃 변경 또는 위에서 예시된 유형의 상태 변경 간의 최단 시간)에 기초하여 미리 결정될 수 있다. 실제적인 예에서는, 상태 머신은 전체 화면 발표자 보기(현재 발언 참가자를 전체 화면으로 표시); 슬라이 드 보기(현재 공유된 프레젠테이션 슬라이드를 전체 화면으로 표시); 현재 발언 참가자를 현재 공유된 프 리젠테이션 슬라이드와 함께 나란히 표시하는 \"버터플라이 보기\"; 참가자의 전체 또는 선택된 하위 집합을 나란히 또는 매트릭스 레이아웃으로 보여주는 다중 화자 보기; 등과 같은, 출력 비디오 스트림에 적용될 수 있는 미리 결정된 표준 레이아웃 세트를 지원할 수 있다. 다양한 이용 가능한 생성 형식은 (상기 표준 레이 아웃 세트와 같은) 이용 가능한 상태 세트와 함께 (위에 예시된 바와 같이) 상태 머신 상태 변경 규칙 세트에 의해 정의될 수 있다. 예를 들어, 이러한 생성 형식 중 하나는 \"패널 토론\", 또 다른 \"프리젠테이션\" 등일 수 있다. GUI 또는 중앙 서버에 대한 다른 인터페이스를 통해 특정 생성 형식을 선택함으로써, 시스템의 운영자는 미리 정의된 생성 형식 세트 중 하나를 신속하게 선택한 다음에, 중앙 서버로 하여금 상술된 바와 같이 이용 가능한 정보에 기초하여 문제의 생성 형식에 따라 출력 비디오 스트림을 완전 자동으로 생성 하도록 할 수 있다. 뿐만 아니라, 생성 중에 각 회의 참여 클라이언트 또는 외부 비디오 소스에 대해, 상술된 바오 같이 각각의 인메모리 버퍼가 생성되고 유지된다. 이러한 버퍼는 즉시 쉽게 제거, 추가 및 변경할 수 있다. 그러면 중앙 서버는 추가/탈락된 참여 클라이언트 및 연설 예정된 참가자; 계획되거나 예상치 못한 프 레젠테이션 일시 중지/재개; 현재 사용되는 생성 형식에 대한 원하는 변경 사항 등에 관하여, 출력 비디오 스트 림을 생성하는 동안 정보를 수신하도록 배열될 수 있다. 이러한 정보는 예를 들어 전술한 바와 같이 운영 자 GUI 또는 인터페이스를 통해 중앙 서버에 공급될 수 있다. 위에 예시된 바와 같이, 일부 실시 예에서 기본 디지털 비디오 스트림(210, 301) 중 적어도 하나가 디지털 비디 오 통신 서비스에 제공되고, 게시 단계는 상기 출력 디지털 비디오 스트림을 동일한 통신 서비스 에 제공하는 단계를 포함할 수 있다. 예를 들어, 출력 비디오 스트림은 비디오 통신 서비스의 참여 클라이언트에 제공될 수 있거나, API를 통해 외부 비디오 스트림으로서 비디오 통신 서비스 에 제공될 수 있다. 이러한 방식으로, 출력 비디오 스트림은 현재 비디오 통신 서비스에 의해 달성되고 있는 비디오 통신 이벤트에 대한 일부 또는 모든 참가자에게 이용 가능하게 될 수 있다. 상술된 바와 같이, 추가적으로 또는 대안적으로 출력 비디오 스트림은 하나 또는 여러 외부 소비자에 게 제공될 수 있다. 일반적으로, 생성 단계는 중앙 서버에 의해 수행될 수 있으며, API를 통해 라이브 비디오 스트림으로 서 하나 이상의 동시 소비자에게 상기 출력 디지털 비디오 스트림을 제공할 수 있다. 본 발명은 또한 상술된 바에 따라 공유 디지털 비디오 스트림을 제공하기 위한 컴퓨터 소프트웨어 기능에 관한 것이다. 그런 다음 이러한 컴퓨터 소프트웨어 기능은 실행 시 상술된 수집, 이벤트 감지, 동기화, 패턴 감지, 생성 및 게시 단계를 수행하도록 구성된다. 컴퓨터 소프트웨어 기능은 전술한 바와 같이 중앙 서버의 물리 적 또는 가상 하드웨어에서 실행되도록 구성된다. 본 발명은 또한 공유 디지털 비디오 스트림을 제공하고 중앙 서버를 포함하는 시스템인 시스템에 관 한 것이기도 하다. 중앙 서버는 다음에 상기 수집, 이벤트 감지, 동기화, 패턴 감지, 생성 및 발간 단계를 수행하도록 구성된다. 예를 들어, 이들 단계는 상술된 바와 같이 상기 단계를 수행하기 위해 상기 컴퓨터 소프 트웨어 기능을 실행하는 중앙 서버에 의해 수행된다. 이상, 바람직한 실시 예가 설명되었다. 그러나, 당업자라면 본 발명의 기본 사상에서 벗어나지 않고 개시된 실 시 예에 많은 수정이 이루어질 수 있다는 것이 명백할 것이다. 예를 들어, 많은 추가 기능이 본 명세서에 기술된 시스템의 일부로서 제공될 수 있으며, 이는 본 명세서에 기술되지 않는다. 일반적으로, 현재 설명된 솔루션은 비디오 데이터 스트림이 통신에 사용되는 다양한 구체적인 애플리케이션을 충족하기 위해 세부적인 기능과 특징을 구축할 수 있는 프레임워크를 제공한다. 일 예로, 기본 비디오 스트림이 발표자의 모습, 공유된 디지털 슬라이드 기반 프리젠테이션, 시연 중인 제품의 라이브 비디오를 포함하는 시연 상황이 있다. 또 다른 예는 교육 상황으로, 이 때 기본 비디오 스트림은 교사의 보기, 교육 주제가 되는 물리적 개체의 라이 브 비디오, 교사와 질문을 하고 대화에 참여할 수 있는 여러 학생의 각각의 라이브 비디오가 포함된다. 이 두 가지 예 중 하나에서, 비디오 통신 서비스(시스템의 일부일 수도 있고 아닐 수도 있음)는 기본 비디오 스 트림 중 하나 또는 여러 개를 제공할 수 있고, 및/또는 기본 비디오 스트림 중 몇 개가 여기에 설명된 유형의 외부 비디오 소스로 제공될 수 있다. 일반적으로, 현재 방법과 관련하여 설명한 모든 내용은 현재 시스템 및 컴퓨터 소프트웨어 제품에 적용 가능하 며, 그 반대의 경우도 마찬가지이다. 따라서, 본 발명은 설명된 실시 예에 제한되지 않고, 첨부된 청구범위의 범위 내에서 변경될 수 있다. 도면 도면1 도면2 도면3 도면4 도면5 도면6a 도면6b 도면6c 도면6d 도면6e 도면6f 도면7"}
{"patent_id": "10-2024-7014195", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이하에서, 본 발명의 예시적인 실시 예 및 첨부된 도면을 참조하여 본 발명을 상세히 설명할 것이다: 도 1은 본 발명에 따른 제1 시스템을 도시한다; 도 2는 본 발명에 따른 제2 시스템을 도시한다; 도 3은 본 발명에 따른 제3 시스템을 도시한다; 도 4는 본 발명에 따른 중앙 서버를 도시한다; 도 5는 본 발명에 따른 시스템에서 사용하기 위한 중앙 서버를 도시한다; 도 6a-6f는 도 5에 도시된 방법의 다양한 방법 단계와 관련된 후속 상태를 도시한다; 및 도 7은 본 발명에 사용되는 공통 프로토콜을 개념적으로 도시한다."}
