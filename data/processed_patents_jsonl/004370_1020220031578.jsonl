{"patent_id": "10-2022-0031578", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0090963", "출원번호": "10-2022-0031578", "발명의 명칭": "분산 유닛 스케일링을 수행하는 네트워크 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "권준환"}}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "분산 유닛(DU)를 포함하는 무선 액세스 네트워크 장치로서, 적어도 하나 이상의 제1 리모트 유닛(RU)와 통신하는 제1 DU;제1 서버의 리소스 상태에 따라 스케일링 과정을 제어하는 스케일링 컨트롤러(scaling controller); 및 상기 제1 DU의 리소스 사용량 정보를 기반으로 상기 스케일링 컨트롤러에 의해 선정된 제2 DU를 포함하고, 상기 스케일링 컨트롤러는, 상기 제1 DU의 서비스를 처리중인 상기 제1 RU 중에서 상기 제2 DU로 이전(migration)할 제2 RU를 선택하고, 상기 제1 DU는, 상기 제2 DU에게 이전 대상이 되는 상기 제2 RU에 대한 정보를 송신하고, 상기 제1 RU 중 상기 제2 RU를 제외한 나머지 RU에서 상기 제1 DU의 서비스를 처리하는 것인 장치."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 스케일링 컨트롤러는 상기 제2 DU의 서비스를 실행할 용량이 있는 제2 서버를 선택하도록 구성되는 장치."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 선정된 제2 DU는 상기 제1 DU에 대한 리소스 사용량이 제1 서버의 가용 리소스와 연관된 조건을 만족함에기반하여, 상기 제1 DU의 서비스의 적어도 일부를 상기 제1 서버와 상이한 제2 서버를 이용하여 처리할 상기 제2 DU로 선정된 것인 장치."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 제2 RU에 대한 정보는 이전 대상이 되는 UE에 대한 SRB(signaling radio bearer)리스트 및 DRB(dataradio bearer)리스트를 포함하는 것인 장치."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 제2 RU에 대한 정보는 상기 제2 RU와 관련된 UE에 관한 정보, 채널 상태에 대한 정보, 무선 리소스 스케쥴링 정보(radio resource scheduling information) 및 시스템 정보(system information)중 적어도 하나 이상을포함하는 것인 장치."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,공개특허 10-2023-0090963-3-상기 제1 DU가 상기 제2 DU에게 이전 대상이 되는 제2 RU에 대한 정보를 동기화 하기 위한 통신 세션을 생성하도록 구성되는 장치."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 제2 DU는 상기 제2 RU에 연결된 UE 중에서 상기 제2 DU에서 처리할 UE를 선정하도록 구성되는 장치."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 제1 DU는 상기 제2 DU에게 이전 대상이 되는 UE에 대한 정보를 전송하도록 구성되고, 상기 이전 대상이 되는 UE는 상기 제2 DU에 대한 서비스를 처리하는 것인 장치."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 무선 엑세스 네트워크 장치는 상기 제1 DU 및 상기 제2 DU와 중앙 유닛(CU)을 연결하는 F1 splitter을 더포함하고, 상기 F1 splitter는 데이터 플로우를 상기 제1 DU에서 스위칭하여 상기 제2 DU로 송신하도록 구성되는 장치."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 무선 엑세스 네트워크 장치는, 분산 유닛(DU)과 중앙 유닛 (CU)를 연결하는 F1 splitter; 및상기 분산 유닛(DU)과 리모트 유닛(RU)를 연결하는 fronthaul(FH) splitter을 더 포함하며, 상기 스케일링 컨트롤러는 상기 제2 DU의 서비스에 대한 정보를 상기 F1 splitter 및 상기 FH splitter에 각각등록하도록 구성되는 장치."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "분산 유닛(DU)를 포함하는 무선 엑세스 네트워크 장치의 통신 방법으로서, 상기 방법은:스케일링 컨트롤러(scaling controller)에 의해 제1 서버를 통해 실행되는 제1 DU의 리소스 사용량에 대한 정보를 획득하는 과정;상기 스케일링 컨트롤러에 의해 상기 제1 DU의 리소스 사용량에 대한 상기 정보를 기반으로 제2 DU를 선정하는과정;상기 스케일링 컨트롤러에 의해 상기 제1 DU의 서비스를 처리중인 제1 리모드 유닛(RU) 중에서 상기 제2 DU로이전(migration) 할 제2 RU를 선택하는 과정; 및상기 제1 DU에 의해, 상기 제2 RU에 대한 정보를 상기 제2 DU에게 송신하는 과정을 포함하고,상기 제1 RU 중 상기 제2 RU를 제외한 나머지 RU에서 상기 제1 DU의 서비스를 처리하는 것인 방법."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2023-0090963-4-제 11 항에 있어서,상기 스케일링 컨트롤러에 의해, 상기 제2 DU의 서비스를 실행할 용량이 있는 제2 서버를 선택하는 과정을 더포함하는 방법."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11 항에 있어서,상기 제2 DU를 선정하는 과정은, 상기 제1 DU 에 대한 리소스 사용량이 제1 서버의 가용 리소스와 연관된 조건을 만족함에 기반하여, 상기 제1 DU의 서비스의 적어도 일부를 상기 제1 서버와 상이한 제2 서버를 이용하여 처리할 상기 제2 DU를 선정하는 것인 방법."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 11 항에 있어서,상기 제2 RU에 대한 정보는 이전 대상이 되는 UE에 대한 SRB(signaling radio bearer)리스트 및 DRB(dataradio bearer)리스트를 포함하는 것인 방법."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 11 항에 있어서,상기 제2 RU에 대한 정보는 상기 제2 RU와 관련된 UE에 관한 정보, 채널 상태에 대한 정보, 무선 리소스 스케쥴링 정보(radio resource scheduling information) 및 시스템 정보(system information)중 적어도 하나 이상을포함하는 것인 방법."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 11 항에 있어서,상기 스케일링 컨트롤러는 상기 제1 DU가 상기 제2 DU에게 이전 대상이 되는 제2 RU에 대한 정보를 동기화 하기위한 통신 세션을 생성하도록 지시하는 과정을 더 포함하는 방법."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 11 항에 있어서,상기 제2 DU는 상기 제2 RU에 연결된 UE 중에서 상기 제2 DU에서 처리할 UE를 선정하는 과정을 더 포함하는 것인 방법."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 11 항에 있어서,상기 제1 DU는 상기 제2 DU에게 이전 대상이 되는 UE에 대한 정보를 전송하는 과정을 더 포함하고, 상기 이전대상이 되는 UE는 상기 제2 DU에 대한 서비스를 처리하는 것인 방법."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "공개특허 10-2023-0090963-5-제 11 항에 있어서,상기 무선 엑세스 네트워크 장치는 상기 제1 DU 및 상기 제2 DU와 중앙 유닛(CU)을 연결하는 F1 splitter을 더포함하며, 상기 제1 DU는 상기 F1 splitter에게 데이터 플로우를 제1 DU에서 스위칭하여 제2 DU로 송신되도록요청하는 과정을 더 포함하는 방법."}
{"patent_id": "10-2022-0031578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 11 항에 있어서,상기 무선 엑세스 네트워크 장치는, 분산 유닛(DU)과 중앙 유닛 (CU)를 연결하는 F1 splitter; 및상기 분산 유닛(DU)과 리모트 유닛(RU)를 연결하는 fronthaul(FH) splitter을 더 포함하며, 상기 스케일링 컨트롤러에 의해, 상기 제2 DU의 서비스에 대한 정보를 상기 F1 splitter 및 상기 FH splitter에각각 등록하는 과정을 더 포함하는 방법."}
{"patent_id": "10-2022-0031578", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다양한 실시예에 따라서, 분산 유닛(DU)를 포함하는 무선 엑세스 네트워크 장치의 통신 방법으로서, 상기 방법은 스케일링 컨트롤러(scaling controller)에 의해 제1 서버를 통해 실행되는 제1 DU의 리소스 사용량에 대한 정보 를 획득하는 과정, 상기 스케일링 컨트롤러에 의해 상기 제1 DU의 리소스 사용량에 대한 상기 정보를 기반으로 제2 DU를 선정하는 과정, 상기 스케일링 컨트롤러에 의해 상기 제1 DU의 서비스를 처리중인 제1 리모드 유닛(RU) 중에서 상기 제2 DU로 이전(migration) 할 제2 RU를 선택하는 과정, 상기 제1 DU에 의해, 상기 제2 RU에 대한 정보를 상기 제2 DU에게 송신하는 과정을 포함하고, 상기 제1 RU 중 상기 제2 RU를 제외한 나머지 RU에서 상기 제1 DU의 서비스를 처리하는 것인 방법이며, 그 밖의 다양한 실시예가 가능하다."}
{"patent_id": "10-2022-0031578", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "다양한 실시예는, 무선 접속망의 분리된 기능인 분산 유닛의 스케일링 방법 및 무선 자원의 할당에 관한 것이다."}
{"patent_id": "10-2022-0031578", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기존의 기지국(base station)은 기지국의 데이터 처리부(distributed unit, DU)와 무선 송수신부(radio unit 또는 remote unit, RU)가 함께 셀 사이트에 설치되는 형태로 구현되었다. 하지만, 이러한 일체형 구현 형태는 물리적 제약을 가진다. 예를 들어, 서비스 가입자 또는 트래픽의 증가에 따라, 사업자는 새롭게 셀 사이트에 기지국을 구축하여야 한다. 이를 극복하고자, C-RAN(centralized RAN(radio access network) 또는 cloud RAN) 구조가 구현되었다. C-RAN은 DU를 하나의 물리적 장소에 배치하고, 실제 사용자 장치(user equipment, UE)와 무선 신호를 송수신하는 셀 사이트에는 RU를 배치하는 구조를 가질 수 있다. DU 및 RU는 광케이블 또는 동축 케이블로 연결될 수 있다. RU 및 DU가 분리되면서 이들간의 통신을 위한 인터페이스 규격이 필요하였으며, CPRI (Common Public Radio Interface) 등의 규격이 RU와 DU간에 사용되고 있다. 3GPP (3rd Generation Partnership Project)에서도 기지국 구조가 규격화되고 있으며, 5G 시스템에 적용될 수 있는 개방형 네트워크 표준인 O-RAN(Open Radio Access Network)에 대한 논의가 진행되고 있다. O-RAN은 기존의 3GPP NE인 RU, DU, CU-CP(central unit-control plane), CU-UP(central unit-user plane)를 각각 O-RU, O-DU, O-CU-CP, O-CU-UP라고 새로이 정의하고(이를 통합해서 O-RAN 기지국이라 칭할 수 있다), 그 외 추가로 RIC (RAN Intelligent Controller) 와 NRT-RIC(non-real-time RAN Intelligent Controller)를 제안 하였다. 차세대 통신 시스템에서 새로운 무선 접속 네트워크 (radio access network; RAN) 구조는 중앙 유닛 (centralized unit; CU)들, 분산 유닛(distributed unit; DU)들 및 리모트 유닛(remote unit; RU)들을 포함하 는 무선 접속 네트워크 구조가 고려되고 있다. 통신을 위한 무선 프로토콜 스택 또는 기능들은 다양한 방식으로 CU, DU, RU로 분할(split)될 수 있다. 규격에서는 이를 function split이라고 한다. RAN function을 분리함으 로써, 각 이동통신사의 환경에 따라서 다양한 형태의 운영이 가능하다. RU 장비만 cell site에 설치하고, CU 및 DU는 central office나 cloud data center에 배포하고, fronthaul로 연결하여 전체적인 운영비용을 감소할 수 있다. 하나의 CU 아래에 적어도 하나 이상의 DU가 있을 수 있다. 통신을 위한 무선 프로토콜 스택 또는 기능들 은 다양한 방식으로 CU와 DU 간에 분할될 수 있다. 예를 들어, PDCP 계층/기능들은 CU에 위치되고 RLC/MAC/PHY 기능들/계층들은 DU에 위치될 수 있다. 다른 옵션에서, PDCP/RLC 계층들/기능들이 CU에 위치되며 MAC/PHY 계층 들/기능들은 DU에 위치될 수 있다. 마찬가지로, CU, DU, RU간에 기능을 분리하는 다른 옵션이 있을 수 있다. 무 선 접속 네트워크 구조에서, 사용자 단말 (user equipment; UE) 이동성으로 인해, UE는 동일한 CU 내의 하나의 DU로부터 다른 DU로 이동할 수 있거나, UE는 상이한 CU에서 하나의 DU로부터 다른 DU로 이동할 수 있다. 또는,UE는 source DU 상에서 무선 링크 실패(radio link failure; RLF)를 검출할 수 있고, 그 다음에 동일한 CU 또 는 상이한 CU 내의 target DU로 전환할 수 있다. 기존의 H/W 기반의 CU 및 DU의 운영 방식에서, software로 구 현하고, 가상머신(virtual machine; VM) 또는 컨테이너(container)기술을 기반으로 하는 클라우드 환경에 CU 및 DU를 운영하는 방향으로 발전하고 있다."}
{"patent_id": "10-2022-0031578", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "클라우드 환경의 도입으로 어플리케이션을 개발하거나 서비스를 제공함에 있어서 내부 자원을 효율적으로 사용 할 수 있게 되었고, 수초 단위의 민첩한 어플리케이션의 배포 및 관리가 가능한 컨테이너 기반의 서비스가 출현 할 수 있었다. 다만, 컨테이너 기반의 마이크로 서비스는 폭증하는 사용자의 트래픽에 대응해야 하는 문제가 있 었다. 기존의 서비스는 컨테이너 플랫폼간 서비스 이동도 불가능하고, 자원의 유연한 확장이 어려운 점이 있다. 이에 따라, 클라우드 환경에서 컨테이너 내 자원을 균형적으로 사용하기 위한 스케일링 아웃/인 방법이 주목받 게 되었다. RU의 데이터를 처리할 수 있을 만큼만 DU에게 동적으로 서버리소스를 할당한다면, 필요로 하는 전체 서버 리소 스의 양을 줄일 수 있지만 현재 NR 규격에서는 UE의 통신단절 없이 DU에게 동적으로 리소스를 할당하는 방법에 대하여 제안하지 못하고 있다. RU의 평균적인 데이터 처리에 필요한 용량만큼 DU에게 서버 리소스를 할당하고, RU의 데이터 용량이 증가할 경 우, 추가적인 DU를 다른 서버에서 실행하고, 이전 DU가 담당하던 복수의 RU 중 일부를 신규로 배포된 DU에서 처 리하도록 traffic을 옮길 수 있다. DU에게 동적으로 서버 리소스를 할당하면 전체적이 리소스(CPU, Memory, 가 속기 등)사용량이 줄어들 수 있다. 기존(source) DU-RU-UE(단말) 간 데이터 플로우가 존재하고, 신규(target) DU-RU-UE로 데이터 플로우를 seamless하게 이전하는 방법이 필요하다. 다양한 실시예는 단말의 통신이 끊어지지 않은 상태로 DU를 스케일링하는 방법을 기술한다."}
{"patent_id": "10-2022-0031578", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "다양한 실시예에 따르면, 분산 유닛(DU)를 포함하는 무선 액세스 네트워크 장치로서, 적어도 하나 이상의 제1 리모트 유닛(RU)와 통신하는 제1 DU, 제1 서버의 리소스 상태에 따라 스케일링 과정을 제어하는 스케일링 컨트 롤러(scaling controller) 및 상기 제1 DU의 리소스 사용량 정보를 기반으로 상기 스케일링 컨트롤러에 의해 선 정된 제2 DU를 포함하고, 상기 스케일링 컨트롤러는, 상기 제1 DU의 서비스를 처리중인 상기 제1 RU 중에서 상 기 제2 DU로 이전(migration)할 제2 RU를 선택하고, 상기 제1 DU는, 상기 제2 DU에게 이전 대상이 되는 상기 제 2 RU에 대한 정보를 송신하고, 상기 제1 RU 중 상기 제2 RU를 제외한 나머지 RU에서 상기 제1 DU의 서비스를 처 리하는 것인 장치를 제안한다. 다양한 실시예에 따르면, 분산 유닛(DU)를 포함하는 무선 엑세스 네트워크 장치의 통신 방법으로서, 상기 방법 은 스케일링 컨트롤러(scaling controller)에 의해 제1 서버를 통해 실행되는 제1 DU의 리소스 사용량에 대한 정보를 획득하는 과정, 상기 스케일링 컨트롤러에 의해 상기 제1 DU의 리소스 사용량에 대한 상기 정보를 기반 으로 제2 DU를 선정하는 과정, 상기 스케일링 컨트롤러에 의해 상기 제1 DU의 서비스를 처리중인 제1 리모드 유 닛(RU) 중에서 상기 제2 DU로 이전(migration) 할 제2 RU를 선택하는 과정, 상기 제1 DU에 의해, 상기 제2 RU 에 대한 정보를 상기 제2 DU에게 송신하는 과정을 포함하고, 상기 제1 RU 중 상기 제2 RU를 제외한 나머지 RU에 서 상기 제1 DU의 서비스를 처리하는 것인 방법을 제안한다."}
{"patent_id": "10-2022-0031578", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "다양한 실시예에 따라서, 사용자 단말이 연결되어 통신할 수 있도록 지원하는 RAN에서 소프트웨어화 된 가상 DU 의 동적 스케일링이 가능하도록 하여 전체 DU가 필요로 하는 서버 리소스를 효율적으로 사용할 수 있다. 다양한 실시예에 따라서, RU에 전용 DU를 할당하는 대신 클라우드 플랫폼의 서버 리소스 pooling 효과을 활용하 여, RU의 트래픽 양에 따라서 필요한 양만큼 DU에게 서버 리소스가 할당하도록 하여 필요한 서버 리소스를 줄이 고, 서버 수 감소를 통해 소모 전력도 함께 줄일 수 있다. 다양한 실시예에 따라서, DU 내 무선 리소스 할당을 담당하는 스케쥴러가 단말(UE)에게 할당하는 리소스 source DU로부터 target DU로 무선 베어러를 seamless하게 제어할 수 있다."}
{"patent_id": "10-2022-0031578", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1a는 다양한 실시예에 따른 RAN 및 코어 네트워크(core network, CN)를 설명하기 위한 블록도를 도시한다. 다양한 실시예에 따라서, RAN은 적어도 하나의 DU(distributed unit), 적어도 하나의 CU-CP(central unit-control plane), 또는 적어도 하나의 CU-UP(central unit-user plane) 중 적어도 하나를 포함 할 수 있다. RAN은 적어도 하나의 RU(remote unit, 또는 radio unit)에 연결되는 것과 같이 도시되 어 있지만, 이는 예시적인 것으로 적어도 하나의 RU는, RAN에 연결되거나, 또는 RAN에 포함될 수 있다. RAN은, O-RAN일 수도 있으며, 이 경우에는, DU는 O-DU일 수 있으며, CU-CP는 O-CU- CP일 수 있으며, CU-UP는 O-CU-UP일 수 있으며, RU는 O-RU일 수 있다. 다양한 실시예에 따라서, RU는, 사용자 장치(user equipment, UE)와 통신을 수행할 수 있다. RU는, 하위 물리 계층(low-PHY) 기능 및 RF 프로세싱을 제공하는 논리적 노드일 수 있다. DU는 RLC, MAC, 상위 물리 계층(high-PHY)의 기능을 제공하는 논리적 노드일 수 있으며, 예를 들어 RU와 연결될 수 있다. CU(152,153)는 RRC(radio resource control), SDAP(service data adaptation protocol), PDCP(packet data convergence protocol) 프로토콜의 기능을 제공하는 논리적 노드일 수 있다. CU-CP는 RRC 및 PDCP의 제어 평면 부분의 기능을 제공하는 논리적 노드일 수 있다. CU-UP는 SDAP 및 PDCP의 사용 자 평면 부분의 기능을 제공하는 논리적 노드일 수 있다. 다양한 실시예에 따라서, 코어 네트워크(일 예로, 5GC 5th generation core)는, AMF(access and mobility management function) , UPF(User plane Function), 또는 SMF(Session Management Function) 중 적어도 하나를 포함할 수 있다. AMF는 UE 단위의 접속 및 이동성 관리를 위한 기능을 제공할 수 있다. SMF는 세션 관리 기능을 제공할 수 있다. UPF는 데이터 네트워크로부터 수신한 하향링크 데 이터를 UE에게 전달하거나, 또는 UE로부터 수신한 상향링크 데이터를 데이터 네트워크로 전달할 수 있다. 일 예로, CU-CP는 AMF와 N2 인터페이스(또는, NGAP 인터페이스)로 연결될 수 있다. AMF는 SMF와 N11 인터페이스로 연결될 수 있다. CU-UP는 UPF와 N3 인터페이스로 연결될 수 있다. 도 1b는, 다양한 실시예에 따른 네트워크 장치의 하드웨어적 구성을 설명하기 위한 블록도를 도시한다. 다양한 실시예에 따라서, RAN 장치는, 프로세서, 저장 장치, 또는 통신 모듈 중 적어도 하나를 포함할 수 있다. 다양한 실시예에 따라서, 프로세서는, 예를 들면, 소프트웨어(예: 프로그램)를 실행하여 프로세서에 연결된 RIC(또는, RIC의 기능을 수행하도록 구성된 전자 장치)의 적어도 하나의 다른 구성요소(예: 하드웨어 또는 소프트웨어 구성요소)를 제어할 수 있고, 다양한 데이터 처리 또는 연산을 수행할 수 있다. 소프트웨어는, 일 예로 xAPP을 포함할 수 있으나 제한은 없다. 일실시예에 따르면, 데이터 처리 또는 연산의 적 어도 일부로서, 프로세서는 다른 구성요소로부터 수신된 명령 또는 데이터를 저장 장치에 저장하고, 저장 장치에 저장된 명령 또는 데이터를 처리하고, 결과 데이터를 저장 장치에 저장할 수 있다. 일실 시예에 따르면, 프로세서는, 중앙 처리 장치, 어플리케이션 프로세서, 신경망 처리 장치(NPU: neural processing unit), 또는 커뮤니케이션 프로세서 중 적어도 일부를 포함할 수 있으나, 프로세서의 종류에는 제한이 없다. 신경망 처리 장치는 인공지능 모델의 처리에 특화된 하드웨어 구조를 포함할 수 있다. 인공지능 모델은 기계 학습(일 예로, 강화 학습, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 또는 준지도형 학습(semi-supervised learning)을 포함할 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 인공 신경망 레이어들을 포함할 수 있다. 인공 신경망은 심층 신경망(DNN: deep neural network), CNN(convolutional neural network), RNN(recurrent neural network), RBM(restricted boltzmann machine), DBN(deep belief network), BRDNN(bidirectional recurrent deep neural network), 심층 Q-네트워크(deep Q-networks) 또는 상기 중 둘 이상의 조합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은 하드웨어 구조 이외에, 추가적으로 또는 대체적으로, 소프트웨어 구조를 포함할 수 있 다. 저장 장치는, 디스크(일 예로, HDD)와 같은 데이터를 저장할 수 있는 장치라면 제한이 없음을 당업자 는 이해할 것이다. 다양한 실시예에 따라서, 저장 장치는, 프로세서 또는 통신 모듈에 의해 사용되는 다양한 데이 터를 저장할 수 있다. 데이터는, 일 예로, 소프트웨어 및, 이와 관련된 명령에 대한 입력 데이터 또는 출력 데 이터를 포함할 수 있다. 다양한 실시예에 따라서, 통신 모듈은, RAN 장치와 외부 전자 장치 간의 직접(예: 유선) 통신 채널 또는 무선 통신 채널의 수립, 및 수립된 통신 채널을 통한 통신 수행을 지원할 수 있다. 통신 모듈은, 일 예로 E2 인터페이스를 지원할 수 있다면, 그 타입에는 제한이 없다. 한편, RAN이 단일 장치로 구현되는 경우에 는, 통신 모듈은 양 엔티티를 위한 인터페이스를 의미할 수도 있다. 통신 시스템에서 새로운 무선 접속 네트워크 (radio access network; RAN) 구조는 중앙 유닛(centralized unit; CU)들, 분산 유닛(distributed unit; DU)들 및 리모트 유닛(remote unit; RU)들을 포함하는 무선 접속 네트워크 구조가 고려되고 있다. 통신을 위한 무선 프로토콜 스택 또는 기능들은 다양한 방식으로 CU와 DU간에 분할(split)될 수 있다. 규격에서는 이를 function split이라고 한다. RAN function을 분리함으로써, 각 이동 통신사의 환경에 따라서 다양한 형태의 운영이 가능하다. RU 장비만 cell site에 설치하고, CU 및 DU는 central office나 cloud data center에 배포하고, fronthaul로 연결하여 전체적인 운영비용을 감소할 수 있다. 하나의 CU 아래에 하나 또는 그 이상의 DU가 있을 수 있다. 통신을 위한 무선 프로토콜 스택 또는 기능들은 다양한 방 식으로 CU와 DU 간에 분할될 수 있다. 일 예로, 하나의 옵션에서 PDCP 계층/기능들은 CU에 위치되고 RLC/MAC/PHY 기능들/계층들은 DU에 위치될 수 있다. 다른 옵션에서, PDCP/RLC 계층들/기능들이 CU에 위치되며 MAC/PHY 계층들/기능들은 DU에 위치될 수 있다. 마찬가지로, CU와 DU간에 기능을 분리하는 다른 옵션이 있을 수 있다. 무선 접속 네트워크 구조에서, 사용자 단말 (user equipment; UE) 이동성으로 인해, UE는 동일한 CU 내의 하나의 DU로부터 다른 DU로 이동할 수 있거나, UE는 상이한 CU에서 하나의 DU로부터 다른 DU로 이동할 수 있다. 또는, UE는 서빙(serving) DU 상에서 무선 링크 실패(radio link failure; RLF)를 검출할 수 있고, 그 다음에 동일한 CU 또는 상이한 CU 내의 타겟 DU로 전환할 수 있다. 도 2a는 다양한 실시예에 따른, RAN 시스템 내의 cell site 와 central office를 도시한 것이다. 차세대 통신 시스템에서 RAN 기능을 분리함으로써, 각 이동통신사의 환경에 따라서 다양한 형태의 운영이 가능 하게 되었다. 일 예로, 적어도 하나의 RU 장비만이 cell site에 설치되고, CU(혹은 virtual CU) 및 적어도 하나의 DU(혹은 virtual DU)는 central office나 클라우드 환경(일 예로, 클라우드 데이터 센터)에 배포되고, fronthaul(FH)로 연결될 수 있어, 전체적인 운영비용이 감소될 수 있다. 하나의 CU에 적어도 하나 이상의 DU가 대응될 수(또는, 연결될 수) 있다. 기존의 H/W 기반의 CU 및 DU의 운 영 방식과는 대조적으로, CU 및/또는 DU가 software로 구현될 수 있다. 일 예로, 가상머신(virtual machine; VM) 또는 컨테이너(container)기술을 기반으로 하는 클라우드 환경에서 CU 및/또는 DU가 운영될 수 있다. 도 2b는 다양한 실시예에 따른, 클라우드 환경의 서버 및 리소스 풀을 도시한 것이다. 도 2b의 좌측에 도시된 실시예를 참조하면, 적어도 하나의 셀 사이트 각각에는, 적어도 하나의 DU가 각각 연결될 수 있다. 일 예로, 하나의 셀 사이트에는, 하나 이상의 RU가 대응(또는, 연결)될 수 있 다. 좌측에 도시된 실시예에 따르면, 일 예로 하나의 셀 사이트에 하나의 DU가 고정적(fixedly)으로대응(또는, 연결)될 수 있다. 이는, 셀 사이트(또는, 셀 사이트를 구성하는 엔티티(일 예로, 하나 이상의 RU)에 대한 전용(dedicated) DU가 설정될 수 있으며, 이에 따라 DU을 전용 DU로 예시적으로 명명할 수 있다. 하나의 셀 사이트에 대하여 전용 DU가 설정된다는 것의 의미는, 하나의 셀 사이트 를 구성하는 하나 이상의 RU에 대하여 전용 DU가 설정되는 것으로 이해될 수도 있다. 전용 DU 각각의 실 행을 위하여 네트워크 장치는, 전용 DU 각각을 위한 서버(일 예로, VM 또는 컨테이너)를 할당(또는, 실행)하여 야 하며, 서버의 실행을 위하여 지정된 크기 이상의 리소스가 할당되어야 한다. 지정된 크기 이상의 리소스는 미리 설정되거나, 가변적일 수도 있다. 한편, 도 2b의 좌측을 참조하면, 적어도 하나의 DU(320a, 320b) 각각에 는 바(bar) 형태의 인디케이터(231a)가 표시되어 있다. 각각의 인디케이터(231a)는, 적어도 하나의 DU에 서 가용 가능한 최대 리소스에 대한, 적어도 하나의 DU 각각에서 현재 사용 중인 리소스의 비율을 나타낼 수 있다. 가용 가능한 최대 리소스는, 일 예로 전용 DU를 실행하기 위한 서버(일 예로, VM 또는 컨테이너)에 할당된 가용 가능한 최대 리소스일 수도 있다. 도 2b의 좌측의 실시예를 참조한 바와 같이, 셀 사이트에 대하 여 전용 DU가 대응(또는, 연결)되는 경우에는, 하나의 DU(일 예로, DU)에서 가용 가능한 리소스 전체가 이 용되지 않을 수 있으며, 이에 따라 유휴 리소스가 발생할 수 있으며, 이는 네트워크 장치의 리소스 낭비를 야기 할 수 있다. 일 예로, 가용 가능한 리소스는, 하나 이상의 RU에 최대 개수의 UE가 연결된 경우를 상정하 여 결정될 수 있으며, 이에 따라 최대 개수보다 작은 UE가 RU에 연결되는 경우에는, 유휴 리소스가 발생할 수 있다. 하지만, 하나 이상의 RU에 대하여 고정적인 리소스가 할당됨에 따라, 유휴 리소스가 이용이 불 가능하다. 도 2b의 우측의 실시예를 참조하면, RU에 전용(dedicated) DU를 할당하는 대신 클라우드 환경에 서버 풀을 두어 리소스 풀링(pooling) 기능이 활용될 수 있다. 도 2b의 좌측의 실시예와는 대조적으로, 하나의 셀 사이트에 대한 전용 DU가 할당되기 보다는, 하나의 서버(일 예로, 서버(232b))는 복수 개의 셀 사이트들에 포함되는 RU들에 대응하는 기능을 수행할 수 있다. 일 예로, 서버(232b)는, 하나의 셀 사이트에 포함된 RU에 대응하는 기능을 수행하면서, 다른 셀 사이트에 포함된 RU에 대응하는 기능을 수행할 수도 있다. 네트워크 장 치는, RU 단위(또는, RU에 포함된 UE 단위)로, 대응하는 기능을 수행할 서버를 결정할 수 있다. 이에 따라, 도 2b의 우측의 실시예에서 도시된 바와 같이, 하나의 서버(일 예로, 서버(232a))는, 제 1 셀 사이트(210a)에 포함 된 RU에 대응하는 기능을 수행하기 위한 리소스(233a) 및 제 2 셀 사이트(210b)에 포함된 RU에 대응하는 기능을 수행하기 위한 리소스(233b)를 할당할 수 있다. 이에 따라, 서버(232a)는, 제 1 셀 사이트(210a)의 처리를 위 한 리소스(233a) 할당 이후 남은 유휴 리소스를, 제 2 셀 사이트(210b)에 포함된 적어도 하나의 RU의 처리를 위 한 리소스(233b)에 할당할 수 있어, 유휴 리소스가 최소화될 수 있다. 리소스가 할당되지 않은 서버(232c)는 사용되지 않을 수 있다. 도 2b를 참고하면 적어도 하나의 서버에서 일부 남은 부분(232b) 및 점선으로 표시된 서버(232c)는 DU의 기능 수행을 위하여 할당되지 않은 잉여 서버, 다시 말하면 할당되지 않은 서버의 리소스를 의미할 수 있으며, 네트 워크 장치는 잉여 서버는 구동시키지 않거나 리소스를 할당하지 않음으로써 리소스 낭비가 방지될 수 있다. 도 2b를 참고하면, 전용(dedicated) DU마다 하나의 셀 사이트를 구성하는 하나 이상의 RU들이 할당되었으나, 서버 풀을 활용하면 리소스 풀링에 따라 RU가 요구하는 트래픽 양만큼 서버 풀의 임의의 서버의 리소스가 할당될 수 있다. 이에 따라, central office에서는 서버 풀를 통해 DU의 기능을 수행하기 위하여 구동되는 서버의 개수가 감소될 수 있다. 도 3a는 다양한 실시예들에 따른, 네트워크 구성요소를 포함하는 블록도이다. 다양한 실시예에 따르면, 통신을 위한 무선 프로토콜 스택 또는 기능들은 다양한 방식으로 CU와 DU 간에 분할될 수 있다. 일 예로, PDCP(packet data convergence protocol)/RRC/SDAP 계층/기능 들은 CU에 위치되고 RLC/MAC/PHY 기능들/계층들은 DU 에 위치될 수 있다. 다른 옵션 에서, PDCP/RRC/SDAP 계층들/기능들이 CU에 위치되며 RLC/MAC 계층들/기능들은 DU 에 위치될 수 있다. 마찬가지로, CU와 DU간에 기능을 분리하는 다른 옵션이 있을 수 있다. 무선 접속 네트워크 구조에서, 사용자 단말 (user equipment; UE) 이동성으로 인해, UE는 동일한 DU(32 0)내의 RU(330a, 330b, 330c)사이를 이동할 수 있거나, 하나의 DU 이외의 DU에 연결된 RU로 이동할 수 있 다. 또는, UE는 동일한DU 상에서 무선 링크 실패(radio link failure; RLF)를 검출할 수 있고, 그 다음에 동일한 CU 또는 상이한 CU 내의 DU 이외의 DU 로 전환할 수 있다. 다양한 실시예에 따르면, RAN을 구성하는 CU, DU 및 RU 의 3단 구조는 다양한 5G 응용 (eMBB, URLLC, mMTC 등)에 유연하게 5G RAN을 구축하기 위한 5G 기지국 (gNB)을 구성할 수 있다. 도 3a를 참조하면, 기지국은 3단 구조로 나뉘어 RRC, SDAP 및 PDCP는 CU로 RLC, MAC 및 high PHY는 DU로, low PHY는 RU로 분류될 수 있다. 구체적으로, CU 와 DU 사이에는 Midhaul channels 가 위치하고, DU 와 RU 사이에는 Fronthaul channels가 위치할 수 있다. 기능의 분리 지점은 도면에 도시된 것에 제한되지 않는다. 도 3b는 다양한 실시예에 따른, 복수의 DU를 포함하는 네트워크의 블록도이다. 다양한 실시예에 따르면, 네트워크 장치는, CU, 적어도 하나 이상의 DU(일 예로, 도 3b의 source DU(320a), target DU(320b)), scaling controller, CU과 적어도 하나 이상의 DU(320a, 320b)를 디커 플링(decoupling)하는 F1 splitter, 스케일링 과정을 컨트롤하는 scaling controller, 적어도 하나 이상의 DU에 각각 포함된 F1 handler(321a, 321b), scale agent(322a, 322b). RLC(325a, 325b), MAC(327a, 327b), PHY-H(329a, 329b), scheduler(324a, 324b), fronthaul handler(323a, 323b), 적어도 하나 이상의 DU(320a, 320b)와 적어도 하나 이상의 RU(330a, 330b, 330c)를 디커플링(decoupling)하는 fronthaul splitter 및 적어도 하나 이상의 RU(330a, 330b, 330c) 각각에 대응되는 적어도 하나 이상의 UE를 포함하여 실행할 수 있다. 다양한 실시예에 따르면, CU는 U-plane에서의 UE의 데이터 플로우에 있어서 하향링크 데이터를 UE에 게 전달하거나, UE으로부터 수신한 상향링크 데이터를 네트워크로 전달할 수 있다. CU에 대한 설명은 도1a 내지 도3a의 설명을 준용할 수 있다. 다양한 실시예에 따르면, 3GPP F1 interface 규격을 참고하면, F1 splitter는 CU, DU(320a, 320b)간 decoupling 기능을 제공한다. CU 가 source DU(320a)와 target DU(320b)를 하나의 DU로 인식할 수 있는 기능을 제공할 수 있다. CU와 source DU(320a), target DU(320b)간 data flow 경로(IP address translation)를 제어할 수 있다. F1 splitter는 스탠드 얼론(standalone) 또는 CU에 포함된 구성일 수 있다. 다양한 실시예에 따르면, scaling controller는 스케일링 전반을 컨트롤 할 수 있다. 도 3b를 참조하면, scaling controller는 source DU(320a), target DU(320b), F1 splitter 및 fronthaul splitter과 통신할 수 있다. 다양한 실시예에 따르면, scaling controller는 source DU(320a)에서 scaling out이 필요한지 여부를 판단하기 위하여 source DU(320a)로부터 리소스 사용량에 대한 보고를 받을 수 있다. scaling controller는 scaling out이 필요하다고 판단되면, 새로운 target DU(320b)를 생성하도록 쿠버네티스와 같은 클라우드 플랫폼에 요청할 수 있다. scaling controller는 target DU(320b)를 F1 splitter 및 fronthaul splitter에 등록하도록 target DU(320b)에 대한 정보를 F1 splitter 및 fronthaul splitter에 송신할 수 있다. 또는 scaling controller는 target DU(320b)를 F1 splitter 및 fronthaul splitter에 등록하도록 target DU(320b)에 대한 정보를 F1 splitter 및 fronthaul splitter에 송신하도록 scale agent(322a, 322b)에게 지시할 수 있다. 다양한 실시예에 따르면, DU(320a, 320b)는 도1a 내지 도3a의 설명을 준용할 수 있다. 도 3b를 참조하면, source DU(320a)는 F1 handler(321a), scale agent(322a), fronthaul handler(323a), scheduler(324a), RLC(325a), MAC(327a), PHY-H(329a)를 포함할 수 있다. 다양한 실시예에 따르면, source DU(320a)는 정기적으 로 혹은 일정 조건에 따라 scale agent(322a)를 통해 scaling controller에게 리소스 사용량에 대하여 보 고할 수 있다. 다양한 실시예에 따르면, source DU(320a)로부터 트래픽(traffic) 처리를 이전(migration) 받는 target DU(320b)는 F1 handler(321b), scale agent(322b), fronthaul handler(323b), scheduler(324b), RLC(325b), MAC(327b), PHY-H(329b)를 포함할 수 있다. target DU(320b)의 scale agent(322b)는 source DU(320a)의 scale agent(322a)로부터 context 동기화를 위한 정보를 수신할 수 있다. 다양한 실시예에 따르면, F1 handler(321a, 321b)는 DU(320a, 320b)내에서 CU와 통신을 하는 구성으로 3GPP F1 interface 규격을 준수할 수 있다. 다양한 실시예에 따르면, fronthaul handler(323a, 323b)는 DU 내에서 RU와 통신하는 부분으로 ORAN Fronthaul 규격(7.2x)를 준수하거나 Small Cell Forum의 nFAPI를 준수할 수 있다. 다양한 실시예에 따르면, ORAN Fronthaul 규격에 의하면 fronthaul(FH) splitter는 DU(320a, 320b) 및 RU(330a, 330b, 330c)간 decoupling 기능을 제공할 수 있다. RU(330a, 330b, 330c)가 source DU(320a)와 target DU(320b)를 하나의 DU로 인식할 수 있는 기능을 제공할 수 있다. RU(330a, 330b, 330c)와 source DU(320a), target DU(320b)간 data flow 경로(MAC Address Translation)를 제어할 수 있다. 다양한 실시예에따르면, fronthaul splitter는 스탠드 얼론(standalone) 또는 RU에 포함된 구성일 수 있다. 다양한 실시예에 따르면, RU은 UE과 통신을 수행할 수 있다. RU은 하위 물리 계층(PHY-low) 기 능 및 RF 프로세싱을 제공하는 논리적 노드일 수 있다. RU은 RAN에 연결되거나 RAN에 포함될 수 있다. RU에 대한 설명은 도 1a내지 도3a의 설명을 준용할 수 있다. 도 3c 는 DU의 데이터 플로우 및 데이터 플로 우의 이전을 도시한 것이다. 다양한 실시예에 따르면, 사용자 단말 (user equipment; UE)은 무선 접속 네트워크 구조에서 UE의 이동성으로 인해, UE는 동일한 CU 내의 하나의 DU(예를 들어, 도 3b의 source DU(320a)) 로부터 다른 DU(예를 들어, 도 3b의 target DU(320b)) 로 이동할 수 있다. 또는, UE는 상이한 CU에서 하나의 DU(예를 들어, 도 3b의 source DU(320a)) 로부터 다른 DU(예를 들어, 도 3b의 target DU(320b)) 로 이동할 수 있다. 일 예로, UE는 하나의 DU(예를 들어, 도 3b의 source DU(320a)) 상에서 무선 링크 실패(radio link failure; RLF) 를 검출할 수 있고, 그 다음에 동일한 CU 또는 상이한 CU 내의 다른 DU(예를 들어, 도 3b의 target DU(320b))로 전환할 수 있다. 도 3c를 참조하면, target DU(320b)는 scaling out을 위하여 scaling controller에서 생성된 DU일 수 있거나, 또는 target DU(320b)의 생성 과정은 기존에 생성되었던 DU가 scaling out을 위하여 지정되는 것으 로 대체될 수도 있음을 당업자는 이해할 것이다. scaling controller는 target DU(320b)에 대한 정보를 F1 splitter에 전송하여 F1 splitter은 새로운 DU를 등록할 수 있다. 일 예로, 소스 DU(320 a)에서는 scaling out을 위한 적어도 하나의 이벤트가 검출될 수 있으며, 검출된 이벤트에 대응하여 scaling out을 위한 target DU(320b)가 생성(또는, 지정)될 수 있다. 여기에서, 이벤트는, 일 예로 소스 DU(320a)(또 는, 소스 DU(320a)를 구동하기 위한 서버)가 가용 가능한 전체 리소스에 대한 현재 이용중인 리소스의 크기의 비율이 임계 비율 이상인 것을 의미할 수 있으나 이는 예시적인 것으로, 소스 DU(320a)에서 이용중인 리소스가 상대적으로 과다하여 scaling out이 요구됨을 나타내는 조건이라면 제한이 없음을 당업자는 이해할 것이다. scaling controller는 새로운 DU에 대한 정보를 Fronthaul splitter에 송신하여 새로운 DU에 대한 정보를 등록하게 할 수 있다. 현재의 source DU(320a)는 target DU(320b)와 context를 동기화하기 위하여 context를 target DU(320b)로 송신할 수 있다. 일 예로, context는 system information (synchronization, system information block, random access, reference signal 을 포함할 수 있다), scheduling context (channel status, power management, HARQ, DRX 를 포함할 수 있다), control information (MAC-CE, paging 에 대한 정보를 포함할 수 있다.), frequency resource (carrier aggregation, BWP, SUL에 대한 정보를 포함할 수 있다.) spatial resource (beam management, MINO 에 대한 정보를 포함할 수 있다.) UE context (RNTI, SRB, DRB, RAT 에 대한 정보를 포함할 수 있다.) 또는 RU context 중 적어도 하 나를 포함할 수 있다. 여기에서, context는, source DU(320a)에 대응하는(또는, 연결된) 적어도 하나의 RU 중 이전(migration)이 요구되는 RU(또는, 해당 RU에 연결된 적어도 하나의 UE)와 연관될 수 있으나 제한은 없다. Target DU(320b)는, 상술한 context를 수신할 수 있으며, 이에 따라 이전(migration)될 RU(또는, 해당 RU에 연결된 적어도 하나의 UE)에 대한 정보를 확인할 수 있다. F1 splitter은 target DU(320b)에 대한 Downlink/Uplink 리소스 할당 정보에 맞추어 전송할 데이터 혹은 수신할 데이터를 준비할 수 있다. fronthaul splitter은 target DU(320b)에 대해 할당된 Downlink/ Uplink 리소스 정보에 맞추어 준비된 전 송 데이터를 수신하거나 target DU(320b)에게 송신할 수 있다. 앞서 언급하였던 도 3c의 301 내지 306 동 작에 대하여 target DU(320b)를 담당하는 RU(일 예로, 330c)와 데이터 라디오 베어러로 연결된 적어도 하나 이 상의 UE에 대하여 데이터 플로우가 target DU(320b)로 이전되도록 각각의 UE에 대하여 상기 동작들을 반복(30 7)하여 실행할 수 있다. 이에 따라, target DU(320b)에 scaling out될 RU(330c)에 연결된 적어도 하나의 UE에 대한 정보가 제공될 수 있으며, 적어도 하나의 UE와 연관된 다운링크 데이터 및/또는 업링크 데이터의 송신 및/ 또는 수신 절차가 관리될 수 있다. 도 4는 다양한 실시예에 따른, 스케일링 컨트롤러에 의한 동작을 도시한 것이다. 다양한 실시예에 따르면, 무선 엑세스 네트워크 장치에 있어서, 스케일링 컨트롤러(도 3b의 312)의 동작으로써 제1 서버를 통해 실행되는 제1 DU(source DU, 도 3b의 320a)의 리소스 사용량에 대한 정보를 제1 DU(320a)로부 터 획득할 수 있다. 스케일링 컨트롤러 도 3b의 312에 의해 제1 DU(320a)의 리소스 사용량에 대한 정보를 기반으로 제2 DU(target DU, 도 3b의 320b)를 선정할 수 있다. 스케일링 컨트롤러에 의해 제1 DU(320a)의 서비스를 처리중인 제1 RU(일 예로, 도 3b의 330a, 330b, 330c) 중에서 제2 DU(일 예로, 도 3b의 320b)로 이전할 제2 RU(일 예로, 도 3b의 330c)를 선택할 수 있다. 스케일링 컨트롤러에 의하여 제2 RU(일 예로, 도 3b의 330c)에 대한 정보가 제1 DU(320a) 에서 제2 DU(320b)로 송신되도록 제1 DU(320a)에게 통신 세션을 설립하도록 요청할 수 있다. 구체적인 스케일링 컨트롤러의 동작은 아래에 후술할 수 있다. 도 5a 및 도 5b는 DU의 리소스 사용량에 따라 클라우드 환경에서 scaling controller에 의한 scale out 및 scale in 의 프로세스를 도시한 것이다. 다양한 실시예에 따르면, 클라우드에서 실행중인 어플리케이션이나 워크로드가 메모리 부족 문제나 성능 저하를 일으키는 가상머신(VM) 또는 논리 파티션에서 실행중인 경우, 컨테이너 기반의 확장(scaling out) 또는 축소 (scaling in)를 할 수 있다. 도 5a를 참조하면, source DU(320a)는 scaling controller에게 리소스 현황을 보고할 수 있다. 상기 보고된 리소스 현황에 기반하여 scaling controller는 scaling out 여부를 판단할 수 있다. scaling controller는 scaling out 할 target DU(320b)를 생성할 수 있다. scaling controller는 F1 splitter, fronthaul splitter에 target DU(320b)에 대한 정보를 등록할 수 있다. scaling controller는 source DU(320a)의 서비스를 처리중인 RU(일 예로, 도 3b의 330a, 330b, 330c) 중에서 target DU(320b)로 이전(migration)할 이전 대상 RU(일 예로, 도 3b의 330c)를 선택할 수 있다. scaling controller는 scaling out 을 위한 서버(일 예로, 도 2b의 232b 또는 232c)를 선택할 수 있다. scaling controller 이전 대상이 되는 RU(일 예로, 도 3b의 330c)에 연결된 이전 대상이 되는 UE에 대하여 데이터 플로우를 source DU(320a)에서 target DU(320b)로 스위칭 할 수 있다. 직전의 스위칭 동작 을 이전 대상이 되는 RU(일 예로, 도 3b의 330c)에 연결된 모든 UE가 target DU(320b)로 이전될 때까지 각각의 UE에 대하여 반복수행 할 수 있다. 도 5b를 참조하면, target DU(320b)는 scaling controller에게 리소스 현황을 보고할 수 있다. 상기 보고된 리소스 현황에 기반하여 scaling controller는 scaling in 여부를 판단하고, scaling controller는 scaling in 할 target DU(320b)를 선정할 수 있다. scaling controller는 target DU(320b)의 서비스를 처리중인 RU(일 예로, 도 3b의 330a, 330b, 330c) 중에서 source DU(320a)로 이전 (migration)할 이전 대상 RU(일 예로, 도 3b의 330c)를 선택할 수 있다. scaling controller는 scaling in 을 위한 서버(일 예로, 도 2b의 232b)를 선택할 수 있다. scaling controller는 이전 대 상이 되는 RU(일 예로, 도 3b의 330c)에 연결된 이전 대상이 되는 UE에 대하여 데이터 플로우를 target DU(320b)에서 source DU(320a)로 스위칭 할 수 있다. 직전의 스위칭 동작을 이전 대상이 되는 RU(일 예로, 도 3b의 330c)에 연결된 모든 UE가 source DU(320a)로 이전될 때까지 각각의 UE에 대하여 반복수행 할 수 있다. 구체적인 프로세스는 다음과 같을 수 있다. 1) scaling out 프로세스 a) scaling agent는 DU 서버의 CPU 사용률, 메모리 사용률, 네트워크 스루풋(throughput), 소모 전 력, 가속기 사용량 (FPGA/GPU/Smart NIC 등) 등과 같은 리소스 현황을 주기적으로 scaling controller에 게 보고 할 수 있다. 다양한 실시예에 따르면, scaling agent는 주기적으로 보고하는 대신 scaling controller가 사전에 설정한 리소스 사용 조건을 만족할 때, 보고하는 방식도 가능하다. b) scaling controller는 DU의 리소스 사용량 정보를 기반으로 scaling out할 DU를 선정하고 (scaling decision) DU의 서비스가 처리 중인 RU 중(330a, 330b, 330c)에서 다른 서버로 옮겨서 처리할 RU를 선택할 수 있다. 다양한 실시예에 따르면, scaling 할 source DU(320a)의 선정은 다양한 정책에 의해 선정 가능하다. 예를 들면, source DU(320a)에 할당된 서버 리소스가 RU 당 피크 스루풋(throughput)의 30% 및 3개의 RU를 처리하도록 할당했다면, 전체 스루풋이 피크의 60%(30% x 2) 이상이 되었을 때, 해당 DU의 scaling out을 시작할 수 있다. 또는 인공지능/ 기계학습 기술을 통해서 scaling할 최적의 DU를 선정할 수도 있다. 다양 한 실시예에 따르면, scaling controller는 scaling out 할 새로운 DU인 target DU(320b)를 생성하고, target DU(320b)를 F1 splitter에 등록할 수 있다. scaling controller는 fronthaul splitter에 target DU(320b)를 등록할 수 있다. 다양한 실시예에 따르면, RU의 선택은 다양한 정책에 의해 선택 가능 하다. 일 예로, 현재 서버(일 예로, 도 2b의 232a)에서 source DU(320a)의 서비스를 처리하고 있는 RU 중 에서 스루풋(throughput)이 평균보다 작은 RU를 선택하여 다른 서버(일 예로, 도 2b의 232b)에 target DU(320b)의 서비스를 실행하고 target DU(320b)에 해당하는 RU가 처리하도록 옮길 수 있다. 또는 스루풋 (throughput)이 가장 큰 RU를 선택하여, 피크 rate를 처리할 수 있는 용량이 있는 서버에 target DU(320b)를 실행하고, target DU(320b)에 해당하는 RU를 처리하도록 할 수 있다. c) scaling controller는 신규 서비스에 대하여 target DU(320b)에서 처리 용량 여유가 있는 서버(일 예 로, 도 2b의 232b)를 선택(scale out server selection)하여 상기 서버에서 서비스를 실행할 수 있다. 다양한 실시예에 따르면, target DU(320b) 서비스를 실행하기 위한 서버의 선택은 다양한 정책에 의해 선택 가능하다. 일 예로, 하나의 RU에 대하여 최대의 데이터를 처리할 수 있는 서버를 선택하거나, 평균적으로 처리 가능 한 서버를 선택할 수 있다. scaling out을 위한 서버의 선택은 scaling out의 대상이 되는 RU를 선정하는 정책과 관련이 있다. scaling out 대상이 되는 RU 즉, target DU(320b) 서비스로 처리가 이관되는 RU가 peak rate를 처리해야 한다면, target DU(320b)의 서비스는 해당 traffic을 처리할 수 있는 리소스 용량이 있는 서버에 실행될 수 있다. target DU(320b) 서비스가 필요한 리소스를 가진 서버에 실행하도록 하는 것은 일반적 으로 Kubernetes와 같은 클라우드 플랫폼을 통해서 수행될 수 있다. scaling controller는 클라우드 플랫 폼이 DU의 서비스를 실행할 서버를 선택할 수 있도록 필요할 리소스 정보를 제공할 수 있다. d) scaling controller는 target DU(320b)의 서비스가 F1 splitter에 등록되도록 할 수 있다. 일 예 로, F1 splitter은 등록된 정보를 이용해서 source DU(320a)로 전달되는 데이터를 target DU(320b)로 전 송(switch)할 준비를 한다. F1 splitter은 필요시 target DU(320b)와 SCTP(stream control transmission protocol) 통신 session을 신규로 생성할 수 있다. (transport network layer 연결) e) scaling controller는 target DU(320b) 서비스가 FH splitter에 등록되도록 할 수 있다. (transport network layer 연결 포함) 일 예로, FH splitter은 등록된 정보를 이용해서 source DU(320a)로 전달되는 데이터를 target DU(320b) 로 전송(switch)할 준비를 할 수 있다. f) scaling controller는 source DU(320a)와 target DU(320b)에 있는 scale agent 간 context 동기 화(synchronize context)를 위해 통신 세션(communication session)의 생성을 지시할 수 있다. g) source DU(320a) 의 scale agent(322a)는 target DU(320b)의 scale agent(322b)에게 이전(migration) 대상 이 되는 RU에 대한 context 전송을 시작하고 context의 변경 부분은 계속해서 업데이트할 수 있다. 전송되 는 context는 UE context, channel state, radio resource scheduling information 및 system information에 대한 정보일 수 있다. h) scale agent(322a)는 이전(migration) 대상이 되는 RU에 연결되어 있는 UE 중에서 target DU(320b)에 서 처리할 UE를 선정할 수 있다. 다양한 실시예에 의하면, UE의 선정은 다양한 정책에 의해 가능하다. 일 예로, 비활성상태(inactive state)에 있는 UE 부터 이동하고, 연결상태(connected state)에 있는 UE 중 데이터 전송 이 작은 UE부터 많은 UE 순으로 순차적으로 선정할 수 있다. 반대 순서도 가능하다. 또는 UE의 DRB QoS 값을 비 교하여, 우선순위가 낮은 순서대로 선정할 수도 있다. i) source DU(320a)의 scale agent(322a)는 target DU(320b)의 scale agent(322b)에게 이전(migration) 대상 에 되는 UE에 대한 정보를 전송할 수 있다. 일 예로, 전송되는 UE에 대한 정보는 SRB(signaling radio bearer) list, DRB(Data Radio Bearer) List 등을 포함할 수 있다. j) source DU(320a)의 scale agent(322a)는 F1 splitter에게 이전(migration) 대상이 되는 UE로 향하는 데이터를 target DU(320b)로 보낼 것을 요청할 수 있다. 다양한 실시예에 의하면, F1 splitter는 이전 (migration) 대상이 되는 UE로 가는 모든 데이터를 target DU(320b)로 전송(source DU(320a)에서 target DU(320b)로 데이터 경로를 스위칭)할 수 있다. k) source DU(320a)의 scale agent(322a)는 source DU(320a)의 스케쥴러에게 이전(migration) 대상의 UE에 대 한 Uplink/Downlink 리소스 할당 중단을 요청할 수 있다. l) source DU(320a)의 scale agent(322a)는 target DU(320b)의 scale agent(322b)에게 현재 남아 있는 Uplink/downlink 데이터를 전송할 수 있다. m) target DU(320b)는 source DU(320a)와 F1 splitter로부터 받은 데이터로 버퍼(buffer)를 재설정 하고, UE에 대한 데이터 송수신을 준비할 수 있다. n) target DU(320b)의 scale agent(322b)는 source DU(320a)의 scale agent(322a)에게 UE에 대한 데이터 송수 신 준비 완료를 통보할 수 있다. o) source DU(320a)의 scale agent(322a)는 스케쥴러에게 이전(migration) 대상의 UE에 대한 Uplink/Downlink 리소스 할당을 다시 수행하도록 요청할 수 있다. p) source DU(320a)의 scale agent(322a)는 스케쥴러에게 이전(migration) 대상의 UE에 대한 Uplink/Downlink 리소스 할당 정보를 target DU(320b)의 scale agent(322b)에게 전달할 수 있다. 다양한 실시예에 의하면, RU의 이전(migration)이 완료될 때까지 스케쥴링 정보(scheduling information)를 계속 전달할 수 있다. q) source DU(320a)의 scale agent(322a)는 FH splitter에게 source DU address 및/또는 target DU address 정보를 전송할 수 있다. r) target DU는 Uplink/Downlink 리소스 할당 정보에 맞추어 전송 데이터를 준비하고 FH splitter에게 송 신하거나 FH splitter로부터 수신할 수 있다. s) FH splitter는 target DU(320b)로부터 C-Plane Message (ORAN Fronthaul 7.2x 규격)를 받으면 다음과 같이 처리할 수 있다. 다양한 실시예에 의하면, RU는 새로운 target DU(320b)를 알 수 없으므로 FH splitter는 source DU(320a)의 MAC 주소로 변경 후 RU로 전송할 수 있다. C-Plane Packet의 FrameID, SubframeID, SlotID, SymbolID 및 SectionID 중 적어도 하나 이상을 저장할 수 있다. 일 예로 uplink 의 경우, RU로부터 source DU(320a)의 MAC 주소를 Destination Address로 하는 Packet을 받으면, FrameID, SubframeID, SlotID, SymbolID 및 SectionID 중 적어도 하나 이상을 확인 후, 저장된 것과 일치하면 target DU(320b)의 MAC 주소로 목적지 주소를 변경할 수 있다. 일 예로 downlink의 경우, target DU(320b)로부 터 U-Plane packet를 받으면, RU는 변경된 target DU(320b)를 알 수 없으므로 source DU(320a)의 MAC 주 소로 변경 후 RU로 전송할 수 있다. t) 상기 h~s 과정에서 source DU(320a)의 control agent(322a)가 이전(migration)의 대상이 되는 RU에 연 결되어있는 UE중에서 target DU(320b)에서 처리할 UE를 선정하는 과정부터 FH splitter이 target DU로부 터 C-plane 메시지를 받고 이전 대상이 되는 RU에게 source DU(320a)의 MAC 주소를 송신하는 과정까지 일련의 과정들을 이전 대상이 되는 RU에 연결된 모든 UE가 target DU(320b)로 migration 될 때까지 반복하여 수행할 수 있다. u) source DU(320a)의 scale agent(322a)는 target DU(320b)의 scale agent(322b)에게 이전(migration) RU의 스케쥴링을 처리하도록 요청 할 수 있다. v) source DU(320a)의 scale agent(322a)는 scaling controller에게 이전(migration) RU로의 이전 (migration) 완료를 통보하고 이전(migration) 완료된 RU에 대한 정보를 제거할 수 있다. 다양한 실시예에 의하 면, source DU(320a)의 scale agent(322a)는 이전(migration) 완료된 RU에 대한 정보를 유지하고, target DU(320b)의 scale agent(322b)로부터 RU에 대한 정보를 받아 동기화를 진행할 수 있다. w) scaling controller는 F1 splitter, FH splitter에게 RU의 이전(migration) 완료를 통보 할 수 있다. 일 예로, F1 splitter는 이전이 완료된 RU로 가는 데이터 전환(switch)을 위해 IP 주소 기반 NAT(Network Address Translation)를 수행할 수 있다. FH splitter는 이전이 완료된 RU 에서 target DU(320b)로 가는 데이터 전환(switch)을 위해 MAC(Medium Access Control) 주소 기반 NAT(Network Address Translation)를 수행할 수 있다. 2) scaling in 프로세스 a) source DU(320a)의 scaling agent(322a) 는 DU 서버의 CPU 사용률, 메모리 사용률, 네트워크 스루풋 (throughput), 소모 전력, 가속기 사용량 (FPGA/GPU/Smart NIC 등) 등과 같은 리소스 현황을 주기적으로 scaling controller에게 보고할 수 있다. 다양한 실시예에 의하면, scaling agent(322a) 는 scaling controller에게 주기적으로 보고하는 대신 scaling controller가 사전에 설정한 리소스 사용 조건을 만족할 때, 보고하는 방식도 가능하다. b) scaling controller는 DU의 리소스 사용량 정보를 기반으로 scaling in을 할 DU(target DU)를 선 정하고(scaling decision) 제1 서버(일 예로, 도 2b의 232c)에서 target DU 서비스를 처리 중인 RU 중에 서 다른 서버(일 예로, 도2b의 232b)로 옮겨서 처리할 RU(일 예로, 330c)를 선택할 수 있다. 다양한 실시예에 의하면, scaling in 대상이 되는 DU (target DU(320b))의 선정은 다양한 정책으로 가능하다. 일 예로, target DU(320a)에 할당된 resource가 RU의 피크 스루풋(throughput)의 30%를 기준으로 3개의 RU(일 예로, 도 3b의 330a, 330b, 330c)를 처리할 수 있도록 할당되어 있고, 현재 1개의 RU(일 예로, 도 3b의 330a)가 연결되어 있어서, 처리할 수 있는 용량(총90%) 중에서 20%를 사용하고 있다면, scaling in을 시작할 수 있다. 또는 scaling controller는 인공지능/머신러닝 기술을 통해서 scaling할 최적의 DU를 선정할 수도 있다. scaling controller는 다양한 정책에 의해 RU를 선택 가능하다. 일 예로, 서버(일 예로, 도 2b의 232c)에서 target DU(320b)의 서비스를 처리하고 있는 RU(일 예로, 도 3b의 330a, 330b, 330c) 중에서 스루풋 (throughput)이 평균 보다 작은 RU(일 예로, 도 3b의 330c)를 선택하여 다른 서버(일 예로, 도 2b의 232b)에 target DU(320b) 서비스를 실행하고 해당 RU(330c)가 처리하도록 옮길 수 있다. 또는 scaling controller(31 2)는 스루풋(throughput)이 가장 큰 RU를 선택하여, 해당 용량을 처리할 수 있는 source DU(320a)로 이전 대상 이 되는 RU를 처리하도록 할 수 있다. c) scaling controller는 target DU(320b) 서비스를 처리 용량 여유가 있는 서버(일 예로, 도 2b의 232 b)를 선택(scaling in server selection)하여 해당 서버에서 실행할 수 있다. 다양한 실시예에 의하면, target DU(320b)의 서비스를 실행하기 위한 서버의 선택은 다양한 정책에 의해 선택 가능하다. 일 예로, scaling controller는 여러 RU 중 peak data rate를 처리할 수 있는 서버를 선택하거나, average rate를 처리 가 능한 서버를 선택할 수 있다. scaling in 대상이 되는 서버의 선택은 scaling in 대상이 되는 RU를 선정하는 정 책과 관련이 있을 수 있다. scaling controller는 scaling in 대상이 되는 RU(target DU 서비스로 처리가 이관되는 RU)가 스루풋(throughput)이 피크(peak)의 20%라면, target DU(320b) 중에서 scaling out 기준값 보 다 20% 이하의 리소스를 사용하고 있는 DU(일 예로, source DU(320a))로 해당 RU를 이동시킬 수 있다. 다양한 실시예에 따르면, DU(일 예로, target DU(320b)) 서비스가 사용하고 있는 리소스를 서버에서 회수하는 것은 일 반적으로 Kubernetes와 같은 클라우드 환경을 통해서 수행될 수 있다. 리소스가 회수된 서버(일 예로, 도 2b의 232c)는 클라우드 환경에서 제거될 수 있다. 또는 적은 리소스를 사용하고 있는 target DU(320b)를 source DU(320a)로 해당 RU를 이동시킴으로써 target DU(320b)를 제거할 수 있다. scaling controller는 클라우 드 환경에서 DU(일 예로, target DU(320b)) 서비스를 삭제할 수 있는 정보를 제공할 수 있다. d) scaling controller는 scaling in 되는 target DU(320b)가 F1 splitter에게 등록된 정보를 수정 (target DU(320b)가 source DU(320a)와 다른 서버로 scale in 하는 경우)하거나 삭제(target DU(320b)가 source DU(320a)와 동일 서버로 scale in 하는 경우)할 수 있다. e) scaling controller는 scaling in 되는 target DU(320b)가 fronthaul splitter에 등록된 정보를 수정(target DU(320b)가 source DU(320a)와 다른 서버로 scale in 하는 경우)하거나 삭제(target DU(320b)가 source DU(320a)와 동일 서버로 scale in 하는 경우)할 수 있다. f) scaling controller는 source DU(320a)와 target DU(320b)에 있는 scale agent(321a, 321b) 간 context 동기화를 위한 통신 세션(communication session)의 생성을 지시할 수 있다. g) target DU(320b)의 scale agent(322b)는 source DU(320a)의 scale agent(322a)에게 이전(migration) 대상 이 되는 RU(일 예로, 330c)에 대한 context 전송을 시작할 수 있고, context의 변경 부분은 계속해서 업데이트 할 수 있다. 다양한 실시예에 따르면, context는 UE Context, Channel State, Radio Resource Scheduling Information, 및 System Information 중 적어도 하나 이상을 포함할 수 있다. h) target DU(320b)의 scaling agent(322b)는 이전 대상이 되는 RU(일 예로, 도 3b의 330c)에 연결되어 있는 적어도 하나 이상의 UE 중에서 source DU(320a)에서 처리할 UE를 선정할 수 있다. 다양한 실시예에 따르면, scaling agent(322b)는 다양한 정책에 의해 이전 대상이 되는 RU(일 예로, 도 3b의 330c)를 선정할 수 있다. 일 예로, 비활성화 상태(inactive state)에 있는 UE 부터 이동하고, RRC 연결 상태(connected state)에 있는 UE 중 데이터 전송이 작은 UE부터 많은 UE 순으로 순차적으로 선정할 수 있다. 또는 UE의 DRB QoS 값을 비교하 여, 우선순위가 낮은 순서대로 선정할 수도 있다. i) target DU(320b)의 scale agent(322b)는 source DU(320a) 의 scale agent(322a)에게 이전 대상이 되는 UE에 대한 정보를 전송할 수 있다. 다양한 실시예에 따르면, target DU(320b)의 scale agent(322b)는 source DU(320a)의 scale agent(322a)에게 RU에 대한 정보를 UE에 대한 정보를 전송하기 전에 보낼 수 있다. 다양한 실 시예에 따르면, 상기 UE에 대한 정보는 SRB(Signaling Radio Bearer) List, DRB(Data Radio Bearer) List를 포 함할 수 있다. j) target DU(320b)의 scale agent(322b)는 F1 splitter에게 이전 대상이 되는 UE로 향하는 데이터를 source DU(320b)로 보낼 것을 요청할 수 있다. 다양한 실시예에 따르면, F1 splitter는 이전 대상이 되는 UE로 가는 모든 데이터를 source DU(320a)로 전송할 수 있다. 즉, 데이터 플로우를 target DU(320b)에서source DU(320a)로 스위칭 할 수 있다. k) target DU(320b)의 scale agent(322b)는 스케쥴러(324b)에게 이전 대상인 UE에 대한 uplink/downlink 리소 스의 할당 중단을 요청할 수 있다. l) target DU(320b)의 scale agent(322b)는 source DU(320a) 의 scale agent(322a)에게 현재 남아 있는 uplink/downlink 데이터를 전송할 수 있다. m) source DU(320a)는 target DU(320b)와 F1 splitter로부터 받은 데이터로 버퍼를 재설정 하고, UE 데이 터 송수신을 준비할 수 있다. n) source DU(320a)의 scale agent(322a)는 target DU(320b)의 scale agent(322b)에게 UE에 대한 데이터 송수 신 준비 완료를 통보할 수 있다. o) target DU(320b)의 scale agent(322b)는 스케쥴러(324b)에게 이전 대상이 되는 UE에 대한 uplink/downlink 리소스 할당을 다시 수행하도록 요청할 수 있다. p) target DU(320b)의 scale agent(322b)는 스케쥴러(324b)에게 이전 대상이 되는 UE에게 uplink/downlink 리 소스 할당 정보를 source DU(320a)의 scale agent(322a)에게 전달할 수 있다. 다양한 실시예에 따르면, target DU(320b)의 scale agent(322b)는 이전 대상이 되는 RU의 이전이 완료될 때까지 스케쥴링 정보(scheduling information)을 계속 전달할 수 있다. q) target DU(320b)의 scale agent(322b)는 FH Splitter에게 source DU Address 및 target DU Address 정보를 전송할 수 있다. r) source DU(320a)는 uplink/downlink 리소스 할당 정보에 맞추어 전송 데이터를 준비하고 fronthaul splitter에게 송신하거나 fronthaul splitter로부터 수신 할 수 있다. s) fronthaul splitter는 source DU(320a)로부터 C-Plane 메시지 (ORAN Fronthaul 7.2x 규격)를 받으면, target DU(320b)의 MAC 주소로 변경 후 RU로 전송하고, C-Plane 패킷의 FrameID, SubframeID, SlotID, SymbolID, 및 SectionID 중 적어도 하나 이상을 저장할 수 있다. 다양한 실시예에 따르면, 업링크 송신의 경우 에 fronthaul splitter는 RU로부터 target DU(320b)의 MAC 주소를 목적지 주소(destination address)로 하는 패킷을 받으면, FrameID, SubframeID, SlotID, SymbolID 및 SectionID 중 적어도 하나 이상을 확인 후, 저장된 것과 일치하면 source DU(320a)의 MAC 주소로 목적지 주소를 변경할 수 있다. 다양한 실시예에 따르면, 다운링크 송신의 경우에 fronthaul splitter가 target DU(320b)로부터 U-Plane 패킷을 받으면, source DU(320a)의 MAC 주소로 변경 후 변경된 주소를 RU로 전송할 수 있다. t) 상기 h 내지 s 과정을 이전 대상이 되는 RU에 연결된 모든 UE가 source DU(320a)로 이전될 때까지 각각의 UE 에 대하여 반복 수행할 수 있다. u) target DU(320b)의 scale agent(322b)는 source DU(320a)의 scale agent(322a)에게 이전 대상이 되는 RU(일 예로, 330c)의 스케쥴링을 처리하도록 요청할 수 있다. v) target DU(320b)의 scale agent(322b)는 scaling controller에게 이전 대상이 되는 RU(일 예로, 도 3b 의 330c)의 이전 완료를 통보하고 이전 완료된 RU(일 예로, 도 3b의 330c)에 대한 정보를 제거할 수 있다. w) scaling controller는 F1 splitter 및/또는 fronthaul splitter에게 RU(일 예로, 330c)의 이전 완료를 통보할 수 있다. x) scaling controller는 target DU(320b)가 처리하는 RU가 없는 경우 target DU(320b)의 인스턴스 를 삭제할 수 있다. 본 개시에 따른 다양한 실시예에 의하면, CU, DU, RU로 구성된 5G RAN 시스템에서 CU와 DU를 디커플링 (decoupling)하는 F1 splitter, DU와 RU를 decoupling하는 fronthaul splitter, 서버 리소스 상태에 따라 scaling 과정을 제어하는 스케일링 컨트롤러(scaling controller), 및 scaling controller와 통신하면서 DU 내 에서 스케일링에 필요한 데이터 플로우를 제어하고, DU 간 context 동기화를 처리하는 스케일링 에이전트 (scaling agent)로 구성된 소프트웨어 및 장치를 제안한다. 다양한 실시예에 의하면, DU내 리소스 할당을 담당하는 스케쥴러를 이용하여 단말에 할당하는 리소스를 source DU로부터 target DU로 옮기는 경우 라디오 베어러(radio bearer)을 심리스(seamless)하게 제어할 수 있다. 다양한 실시예에 의하면, source DU와 단말간 데이터 플로우에서 target DU와 단말 간 데이터 플로우로 전환(스 위칭)을 위해 Frame ID, Subframe ID, Slot ID, Symbol ID, Section ID 정보에 기반하여 RU와 target DU에 대 한 데이터 플로우로 변경할 수 있다. 다양한 실시예에 의하면, RU에 전용(dedicated) DU를 할당하는 대신 클라우드 플랫폼의 서버 리소스 풀링 을 통해 RU의 트래픽량에 따라 필요한 양만큼 DU에게 서버 리소스가 할당될 수 있다. 그 결과, 서버 리소 스가 확보되어 서버 수를 감소할 수 있고, 이를 통해 소모 전력도 함께 감소할 수 있다. 다양한 실시예에 의하면, 리소스 풀은 적어도 하나 이상의 서버나 스토리지 등의 자원을 확보하고 이를 사용자 의 요청에 따라 제공할 수 있는 상태를 의미할 수 있으며, 가상적인 공간에서 구현 될 수 있다. 클라우드 환경 에서는 미리 확보한 리소스 풀을 통해 즉각적 또는 최소한의 과정을 통해 사용자가 요청할 경우 리소스를 제공 할 수 있다. 본 문서에 개시된 다양한 실시예들에 따른 전자 장치는 다양한 형태의 장치가 될 수 있다. 전자 장치는, 예를 들면, 통신사 기지국 시스템, 사설망 장치(Private 5G 시스템)를 포함할 수 있다. 본 문서의 실시예에 따른 전 자 장치는 전술한 기기들에 한정되지 않는다. 본 문서의 다양한 실시예들 및 이에 사용된 용어들은 본 문서에 기재된 기술적 특징들을 특정한 실시예들로 한 정하려는 것이 아니며, 해당 실시예의 다양한 변경, 균등물, 또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 또는 관련된 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 아이템 에 대응하는 명사의 단수 형은 관련된 문맥상 명백하게 다르게 지시하지 않는 한, 상기 아이템 한 개 또는 복수 개를 포함할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. \"제 1\", \"제 2\", 또는 \"첫째\" 또는 \"둘째\"와 같은 용어들은 단순히 해당 구성요소를 다른 해당 구성요소와 구분하기 위 해 사용될 수 있으며, 해당 구성요소들을 다른 측면(예: 중요성 또는 순서)에서 한정하지 않는다. 어떤(예: 제 1) 구성요소가 다른(예: 제 2) 구성요소에, \"기능적으로\" 또는 \"통신적으로\"라는 용어와 함께 또는 이런 용어 없이, \"커플드\" 또는 \"커넥티드\"라고 언급된 경우, 그것은 상기 어떤 구성요소가 상기 다른 구성요소에 직접적 으로(예: 유선으로), 무선으로, 또는 제 3 구성요소를 통하여 연결될 수 있다는 것을 의미한다. 본 문서의 다양한 실시예들에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함 할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로와 같은 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부 가 될 수 있다. 예를 들면, 일실시예에 따르면, 모듈은 ASIC(application-specific integrated circuit)의 형 태로 구현될 수 있다. 본 문서의 다양한 실시예들은 기기(machine)(예: 전자 장치) 의해 읽을 수 있는 저장 매체(storage medium)(예: 내장 메모리 또는 외장 메모리)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨어 (예: 프로그램)로서 구현될 수 있다. 예를 들면, 기기(예: 전자 장치)의 프로세서(예: 프로세서 )는, 저장 매체로부터 저장된 하나 이상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행할 수 있다. 이것은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도록 운영되는 것 을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적(non-transitory) 저장 매체의 형 태로 제공될 수 있다. 여기서, ‘비일시적’은 저장 매체가 실재(tangible)하는 장치이고, 신호(signal)(예: 전 자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장 매체에 반영구적으로 저장되는 경 우와 임시적으로 저장되는 경우를 구분하지 않는다. 일실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory(CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 이동통신사업자의 배포 시스 템을 통해, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제 품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다.다양한 실시예들에 따르면, 상기 기술한 구성요소들의 각각의 구성요소(예: 모듈 또는 프로그램)는 단수 또는 복수의 개체를 포함할 수 있으며, 복수의 개체 중 일부는 다른 구성요소에 분리 배치될 수도 있다. 다양한 실시 예들에 따르면, 전술한 해당 구성요소들 중 하나 이상의 구성요소들 또는 동작들이 생략되거나, 또는 하나 이상 의 다른 구성요소들 또는 동작들이 추가될 수 있다. 대체적으로 또는 추가적으로, 복수의 구성요소들(예: 모듈 또는 프로그램)은 하나의 구성요소로 통합될 수 있다. 이런 경우, 통합된 구성요소는 상기 복수의 구성요소들 각각의 구성요소의 하나 이상의 기능들을 상기 통합 이전에 상기 복수의 구성요소들 중 해당 구성요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따르면, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적으로, 병렬적으로, 반복적으로, 또는 휴리스틱하게 실행되거나, 상기 동 작들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또는 하나 이상의 다른 동작들이 추가될 수 있다."}
{"patent_id": "10-2022-0031578", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 다양한 실시예에 따른 RAN 및 코어 네트워크(core network, CN)를 설명하기 위한 블록도를 도시한다. 도 1b는, 다양한 실시예에 따른 RAN 장치의 하드웨어적 구성을 설명하기 위한 블록도를 도시한다. 도 2a는, 다양한 실시예에 따른, RAN 시스템 내의 cell site 와 central office를 도시한 것이다. 도 2b는, 다양한 실시예에 따른, 클라우드 환경에서의 서버 및 리소스 풀을 도시한 것이다. 도 3a는 다양한 실시예에 따른, 네트워크 구성요소를 포함하는 블록도이다. 도 3b는 다양한 실시예에 따른, 복수의 DU를 포함하는 네트워크의 블록도이다. 도 3c 는 DU의 데이터 플로우 및 데이터 플로우의 이전을 도시한 것이다. 도 4는 다양한 실시예에 따른, 스케일링 컨트롤러에 의한 동작을 도시한 것이다. 도 5a는 DU의 리소스 사용량에 따라 클라우드 환경에서 scaling controller에 의한 scale out 의 프로세스를 도 시한 것이다. 도 5b는 DU의 리소스 사용량에 따라 클라우드 환경에서 scaling controller에 의한 scale in 의 프로세스를 도 시한 것이다."}
