{"patent_id": "10-2023-0055753", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0158704", "출원번호": "10-2023-0055753", "발명의 명칭": "교통사고 감지 방법 및 교통사고 감지 시스템", "출원인": "동국대학교 산학협력단", "발명자": "성연식"}}
{"patent_id": "10-2023-0055753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "객체 인식 알고리즘에 기초하여, CCTV(Closed-Circuit TeleVision)가 촬영한 복수 개의 프레임에 포함된 객체에바운딩 박스를 생성하는 단계;SORT (Simple Online and Realtime Tracking) 알고리즘에 기초하여, 상기 바운딩 박스에 포함된 객체의 궤도를추출하는 단계;상기 추출된 객체의 궤도에 기호, 라벨, 텍스트 또는 색상 중 적어도 하나를 포함하는 표기(notation)를 부가함으로써, 상기 객체의 궤도 간의 관계를 나타내는 영향도 맵(Influence Map)을 생성하는 단계;상기 영향도 맵을 CNN(Convolution Neural Network) 기반 알고리즘의 입력값으로 입력하고, 상기 CNN 기반 알고리즘의 출력값에 기초하여 상기 CCTV 프레임이 사고 영상인지 여부를 판단하는 단계;를 포함하는 교통사고 감지 방법."}
{"patent_id": "10-2023-0055753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 영향도 맵을 생성하는 단계는,제1 객체의 궤도 및 제2 객체의 궤도 간의 거리 비율에 기초하여 크기 및 색깔의 명도가 결정되는 복수 개의 제1 서클을 생성하는 단계;를 포함하는 교통사고 감지 방법."}
{"patent_id": "10-2023-0055753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 복수 개의 제1 서클을 생성하는 단계는,상기 객체의 위치에 기초하여 상기 복수 개의 제 1 서클의 위치가 결정되는 단계;를 더 포함하는 교통사고 감지방법."}
{"patent_id": "10-2023-0055753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,상기 영향도 맵을 생성하는 단계는,상기 객체의 궤도가 차지하는 위치에 기초하여 크기 및 색깔의 명도가 결정되는 제2 서클을 생성하는 단계;를더 포함하는 교통사고 감지 방법."}
{"patent_id": "10-2023-0055753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3항에 있어서,상기 영향도 맵을 생성하는 단계는,상기 복수 개의 제1 서클의 위치를 연결시킴으로써,상기 객체의 궤도를 나타내는 라인을 생성하는 단계;를 포함하는 교통사고 감지 방법."}
{"patent_id": "10-2023-0055753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,상기 객체 인식 알고리즘은, YOLO (You Only Look Once) 알고리즘을 포함하고,상기 SORT 알고리즘은, Deep SORT 알고리즘을 포함하는 교통사고 감지 방법.공개특허 10-2024-0158704-3-청구항 7 제 2항에 있어서,상기 제1 객체 및 상기 제2 객체 간의 거리 비율이 작아지면, 상기 생성되는 제1 서클의 반지름이 커지고, 상기제1 서클의 색깔이 진해지는 것을 특징으로 교통사고 감지 방법."}
{"patent_id": "10-2023-0055753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 4항에 있어서,상기 영향도 맵을 생성하는 단계는,상기 객체의 크기가 증가하면, 상기 제2 서클의 크기가 증가하고, 상기 제2 서클의 크기가 증가하는 것은 사고가능성이 커지는 는 것을 나타내는 교통사고 감지 방법."}
{"patent_id": "10-2023-0055753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "인공지능을 미리 학습시키는 프로세서 및 상기 학습된 인공지능, 데이터를 저장하는 메모리 및 CCTV 프레임을출력하는 디스플레이를 포함하고,상기 프로세서는,사용자로부터 입력되는 CCTV 프레임을 수신하고, 객체 인식 알고리즘에 기초하여 상기 CCTV 프레임에 포함된 객체에 바운딩 박스를 생성하는 바운딩 박스 생성기;SORT 알고리즘에 기초하여, 상기 바운딩 박스에 포함된 객체의 궤도를 추출하는 궤도 추출기;상기 추출된 객체의 궤도에 기호, 라벨, 텍스트 또는 색상 중 적어도 하나를 포함하는 표기를 부가함으로써, 상기 객체의 궤도 간의 관계를 나타내는 영향도 맵을 생성하는 영향도 맵 생성기; 및상기 영향도 맵을 CNN기반 알고리즘의 입력값으로 입력하고, 상기 CNN 기반 알고리즘의 출력값에 기초하여 상기CCTV 프레임이 사고 영상인지 여부를 판단하는 사고 판단기;를 포함하는 교통사고 감지 시스템."}
{"patent_id": "10-2023-0055753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,상기 영향도 맵 생성기는,제1 객체의 궤도 및 제2 객체의 궤도 간의 거리 비율에 기초하여 크기 및 색깔의 명도가 결정되는 복수 개의 제1 서클을 생성하는 교통사고 감지 시스템."}
{"patent_id": "10-2023-0055753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10항에 있어서,상기 영향도 맵 생성기는,상기 객체의 궤도가 차지하는 위치에 기초하여 사고를 구별하는 값을 생성하고, 상기 생성된 값에 기초하여 사고 발생의 지점을 나타내는 제2 서클을 생성하는 교통사고 감지 시스템."}
{"patent_id": "10-2023-0055753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 영향도 맵 생성기는,상기 제1 서클에 해당하는 궤도의 좌표로 각 객체의 궤도를 나타내는 라인을 생성하는 교통사고 감지 시스템."}
{"patent_id": "10-2023-0055753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 10항에 있어서,상기 영향도 맵 생성기는,공개특허 10-2024-0158704-4-상기 제1 객체 및 상기 제2 객체간의 거리 비율이 작아지면, 상기 생성되는 제1 서클의 반지름이 커지고, 상기제1 서클의 색깔이 진해지는 것을 특징으로 하는 교통사고 감지 시스템."}
{"patent_id": "10-2023-0055753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 11항에 있어서,상기 영향도 맵 생성기는,상기 객체의 크기가 증가하면, 상기 제2 서클의 크기가 증가하고, 상기 제2 서클의 크기가 증가하는 것은 사고가능성이 커지는 것을 특징으로 하는 교통사고 감지 시스템."}
{"patent_id": "10-2023-0055753", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "개시된 일 실시예에 따른 교통사고 감지 방법은 객체 인식 알고리즘에 기초하여, CCTV(Closed-Circuit TeleVision)가 촬영한 복수 개의 프레임에 포함된 객체에 바운딩 박스를 생성하는 단계; SORT (Simple Online and Realtime Tracking) 알고리즘에 기초하여, 상기 바운딩 박스에 포함된 객체의 궤도를 추출하는 단계; 상기 추출된 객체의 궤도에 기호, 라벨, 텍스트 또는 색상 중 적어도 하나를 포함하는 표기(notation)를 부가함으로써, 상기 객체의 궤도 간의 관계를 나타내는 영향도 맵(Influence Map)을 생성하는 단계; 상기 영향도 맵을 CNN(Convolution Neural Network) 기반 알고리즘의 입력값으로 입력하고, 상기 CNN 기반 알고리즘의 출력 값에 기초하여 상기 CCTV 프레임이 사고 영상인지 여부를 판단하는 단계;를 포함한다."}
{"patent_id": "10-2023-0055753", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 CCTV(Closed-Circuit TeleVision)에서 촬영한 복수 개의 프레임으로부터 궤적 감지(Trajectory Tracking) 및 영향도 맵(Influence Maps)을 이용하여 사고 여부를 탐지하는 교통사고 감지 방법 및 교통사고 감 지 시스템에 관련된 것이다."}
{"patent_id": "10-2023-0055753", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기계 학습(Machine Learning), 객체 탐지(Object Detection) 및 궤도 추척(Trajectory Tracking)와 같은 인공 지능 기술은 자율주행 및 교통사고탐지 분야에서 활발히 적용되고 있다. 예를 들어, 자율주행 차량은 도로를 주 행 중에 객체 탐지 또는 궤도 추적을 통해서 실시간으로 주행환경의 감지가 가능하며, RGB 카메라, 라이다 센서 가 수집하는 다양한 이미지 분석을 통해 실시간으로 교통사고를 탐지가 가능하다. 그러나 종래 활발히 연구되는 인공지능은, 주로 RGB 카메라 또는 라이다 센서를 통해 촬영한 이미지에 기초하여 교통사고 또는 주행환경을 분석하는 것이 대부분이며, CCTV에서 촬영한 이미지를 사용해 인공지능 분석을 진행 하는 연구는 활발히 진행되지 않는 상황이다. 왜냐하면, CCTV가 촬영하는 영상 또는 이미지는 단순히 교통에 관 한 상황 이외에 일상에서 일어나는 매우 다양한 상황까지도 촬영되며, 고정되어 설치되는 CCTV가 촬영하는 범위 가 매우 제한적이기 때문이다. 따라서 일반적으로 연구되는 이미지 분석의 인공지능은 CCTV에서 촬영한 이미지 로부터 교통사고를 탐지하는데 한계가 있었다. (특허문헌 1) KR 10-2022-0098677 A"}
{"patent_id": "10-2023-0055753", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시된 실시예는 CCTV가 촬영한 프레임에서 인식되는 객체의 궤적에 기초하여 거리 비율 및 바운딩 박스의 크기 에 따른 영향도 맵을 생성함으로써, 이를 통해 인공지능이 CCTV 프레임에서 사고가 발생했는지 여부를 판별하는 교통사고 감지 방법 및 교통사고 감지 시스템에 관한 것이다."}
{"patent_id": "10-2023-0055753", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시된 일 실시예에 따른 교통사고 감지 방법 및 교통사고 감지 시스템은 영상 프레임에서 인식되는 객체의 궤 적에 기초하여 거리 비율 및 바운딩 박스의 크기에 따른 영향도 맵을 생성함으로써, 이를 통해 인공지능이 영상 프레임에서 사고가 발생했는지 여부를 판별할 수 있다. 또한, 개시된 일 실시예에 따른 교통사고 감지 방법 및 교통사고 감지 시스템은 종래 일반적인 인공지능이 CCTV 프레임에서 구별하기 어려운 사고까지도 높은 정확도 및 적은 훈련량을 통해서 구별할 수 있다."}
{"patent_id": "10-2023-0055753", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면들을 참조하여 본 발명의 바람직한 실시 예를 상세히 설명할 것이다. 그러나 본 발명의 기술 적 사상은 여기서 설명되는 실시 예에 한정되지 않고 다른 형태로 구체화될 수도 있다. 오히려, 여기서 소개되 는 실시 예는 개시된 내용이 철저하고 완전해질 수 있도록 그리고 당업자에게 본 발명의 사상이 충분히 전달될 수 있도록 하기 위해 제공되는 것이다. 본 명세서에서, 어떤 구성요소가 다른 구성요소 상에 있다고 언급되는 경우에 그것은 다른 구성요소 상에 직접 형성될 수 있거나 또는 그들 사이에 제3의 구성요소가 개재될 수도 있다는 것을 의미한다. 또한, 도면들에 있어 서, 형상 및 크기는 기술적 내용의 효과적인 설명을 위해 과장된 것이다. 또한, 본 명세서의 다양한 실시 예 들에서 제1, 제2, 제3 등의 용어가 다양한 구성요소들을 기술하기 위해서 사 용되었지만, 이들 구성요소들이 이 같은 용어들에 의해서 한정되어서는 안 된다. 이들 용어들은 단지 어느 구성 요소를 다른 구성요소와 구별시키기 위해서 사용되었을 뿐이다. 따라서, 어느 한 실시 예에 제1 구성요소로 언 급된 것이다른 실시 예에서는 제2 구성요소로 언급될 수도 있다. 여기에 설명되고 예시되는 각 실시 예는 그것 의 상보적인 실시 예도 포함한다. 또한, 본 명세서에서 '및/또는'은 전후에 나열한 구성요소들 중 적어도 하나 를 포함하는 의미로 사용되었다. 명세서에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함한다. 또한, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 구성요소 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 구성요소 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 배제하는 것으로 이해되어서는 안 된다. 또한, 본 명세서에서 \"연결\"은 복수의 구성 요소를 간접적으로 연결하는 것, 및 직접적으로 연결 하는 것을 모두 포함하는 의미로 사용된다. 또한, 하기에서 본 발명을 설명함에 있어 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지 를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략할 것이다. 도 1 은 개시된 교통사고 감지 시스템의 하드웨어적 구성을 설명하기 위한 도면이고, 도 2는 교통사고 감지 시 스템의 각 구성에 대한 제어 블록도이다. 중복되는 설명을 피하기 위해서 이하 함께 설명한다. 도 1을 먼저 참조하면, 교통사고 감지 시스템은, 사용자 단말의 일 예로 구성될 수 있다. 교통사고 감지 시 스템은 외부로부터 인공지능 학습에 필요한 다양한 데이터를 습득할 수 있고, 학습 데이터를 통해 교통사고 감지에 필요한 다양한 인공지능을 학습한다. 특히 교통사고 감지 시스템은 CCTV가 촬영한 영상, 그 중에서 영상을 이루는 복수 개의 프레임에서 사고 발생 여부를 탐지한 결과를 사용자에게 출력할 수 있다. 교통사고 감지 시스템을 하드웨어적으로 구성하는 사용자 단말은, 네트워크를 통해 외부에 접속할 수 있는 컴퓨터나 휴대용 단말기로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱(laptop), 태블릿 PC, 슬레이트 PC 등을 포함하고, 휴대용 단말기는 예를들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), WiBro(Wireless Broadband Internet) 단 말, 스마트 폰(Smart Phone) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치와 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD) 등과 같은 웨어러블 장치를 포함할 수 있다. 만약 사용자 단말이 휴대용 단말로 사용되는 경우, 대용량의 데이터를 보관하거나 인공 지능의 학습 등은 외부 서버를 통해서 별도로 진행할 수 있다. 교통사고 감지 시스템은 후술하는 교통사고 감지 방법을 수행하는 알고리즘을 구현하는 프로세서, 프로 세서가 처리하는 알고리즘과 알고리즘 처리에 필요한 데이터를 저장하는 메모리 및 CCTV 프레임을 통해 CCTV 영상을 표시하고, CCTV프레임에 기초한 사고감지 여부를 표시하는 디스플레이를 포함한다. 구체적으로 프로세서는 교통사고 감지 시스템 내 구성요소들의 동작을 제어하기 위한 알고리즘뿐만 아니 라, CCTV 프레임에 포함된 객체를 인식하는 객체 인식 알고리즘, 객체로 인식된 바운딩 박스의 궤적을 추출하는 SORT (Simple Online and Realtime Tracking) 알고리즘, 궤적이 포함된 이미지(Object Trajectories)에서 영향 도 맵을 생성하는 이미지 전처리 알고리즘과 생성된 영향도 맵에서 사고 발생 여부를 구별하는 CNN(Convolution Neural Network) 기반 알고리즘을 구현한다. 메모리는 외부로부터 수신되는 CCTV 프레임 뿐만 아니라, 전술한 알고리즘의 학습에 필요한 대용량의 데이 터를 저장한다. 메모리는 프로세스의 동작에 필요한 다양한 데이터를 저장하고, 이하의 교통사고 감지 시스템이 필요로 하는 다양한 데이터를 수집할 수 있다. 메모리는 캐쉬, ROM(Read Only Memory), PROM(Programmable ROM), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM) 및 플래쉬 메모리(Flash memory)와 같은 비휘발성 메모리 소 자 또는 RAM(Random Access Memory)과 같은 휘발성 메모리 소자 또는 하드디스크 드라이브(HDD, Hard Disk Drive), CD-ROM과 같은 저장 매체 중 적어도 하나로 구현될 수 있으나 이에 한정되지는 않는다. 메모리는 전술한 프로세서와 별개의 칩으로 구현될 수 있으나, 도 1에서 도시된 바와 달리 프로세서와 단일 칩으 로 구현될 수도 있다. 디스플레이는 프로세스가 사고 여부를 탐지한 결과를 유저 인터페이스로 표시하면서, CCTV 프레임을 표 시하는 구성이다. 디스플레이는 디지털 광원 처리(Digital Light Processing: DLP) 패널, 플라즈마 디스플 레이 패널(Plasma Display Penal), 액정 디스플레이(Liquid Crystal Display: LCD) 패널, 전기 발광(Electro Luminescence: EL) 패널, 전기영동 디스플레이(Electrophoretic Display: EPD) 패널, 전기변색 디스플레이 (Electrochromic Display: ECD) 패널, 발광 다이오드(Light Emitting Diode: LED) 패널, 음극선관(Cathode Ray Tube: CRT), 또는 유기 발광 다이오드(Organic Light Emitting Diode: OLED) 패널 등으로 마련될 수 있으나, 이에 한정되지는 않는다. 한편, 교통사고 감지 시스템은 도 1에 도시되지 않은 다양한 구성을 더 포함할 수 있다. 일 예로, 교통사고 감지 시스템은 CCTV 프레임 또는 다양한 인공지능 알고리즘을 외부로부터 수신 받기 위한 클라우드 서버 등과 연계될 수도 있다. 다른 예로, 교통사고 감지 시스템은 사용자의 입력을 받는 입력부를 더 포함할 수 있다. 여기서 입력부는 유 저 입력을 위해 터치 패드(touch pad) 등과 같은 GUI(Graphical User interface), 즉 소프트웨어인 장치를 포 함할 수도 있으며, 터치 패드는 터치 스크린 패널(Touch Screen Panel: TSP)로 구현되어 디스플레이와 상호 레이어 구조를 이룰 수 있다. 도 2를 참조하면, 개시된 교통사고 감지 시스템은 CCTV 프레임에서 객체를 인식한 후, 바운딩 박스를 생성하 는 바운딩 박스 생성기(Bounding Box Generator 21), 생성된 바운딩 박스를 포함한 CCTV 프레임에서 각 객체의 궤적을 추출하는 궤도 추출기(Trajectory Extractor 22), 궤도 추출기에서 생성한 객체 추적도(2D Object Trajectories)을 기초로 영향도 맵을 생성하는 영향도 맵 생성기(Influence Map Generator, 31), 생성된 영향 도 맵에 기초하여 이미지 내에서 사고를 구별하는 사고 판단기(Detection Executor, 32)을 포함한다. 각 제어블록이 실행하는 교통사고 감지 방법은 바운딩 박스 생성기 및 궤도 추출기가 실행하는 추적 단 계(Tracking Phase)와 영향도 맵 생성기 및 사고 판단기가 실행하는 실행 단계(Execution Phase)로 구분될 수 있다. 추적 단계에서는 CCTV 프레임이 입력되면서, CCTV 프레임에 포함된 객체의 궤도가 표시된 이미지, 즉 객체 추적 도(2D Object Trajectories)가 출력된다. 실행 단계에서는 궤도가 표시된 이미지가 입력되면, 그 이미지에서 사 고가 발생했는지 여부를 판단한 결과가 출력된다. 구체적으로 바운딩 박스 생성기는 객체 인식 알고리즘에 기초하여, CCTV 프레임에 포함된 객체마다 바운딩 박스를 생성한다. 개시된 일 실시예에 따른 바운딩 박스 생성기는 YOLO(You Only Look Once) 알고리즘을 사 용할 수 있으며, 하나의 프레임에서 복수 개의 객체를 동시에 탐지할 수 있다. 바운딩 박스 생성기가 생성 한 바운딩 박스를 포함한 CCTV 프레임은 궤도 추출기로 입력된다. 바운딩 박스 생성기는 CCTV 프레임에서 도로 위의 동적 객체를 인식한다. 예를 들어 바운딩 박스 생성기 는 차량 뿐만 아니라 보행자를 구분할 수 있으며, 바운딩 박스 생성기는 CADP(Car Accident Detection and Prediction) 데이터 셋을 학습 데이터로 이용할 수 있다. 바운딩 박스 생성기가 학습한 데이터 등에 대 한 구체적인 설명은 도 8등을 통해 후술한다. 궤도 추출기는 SORT (Simple Online and Realtime Tracking) 알고리즘에 기초하여, 바운딩 박스에 포함된 객체의 궤도를 추출한다. 개시된 일 실시예에 따른 궤도 추출기는 Deep SORT (Deep Learning-based SORT) 알고리즘을 사용하여 객체 의 궤적을 추적할 수 있다. 여기서 Deep SORT 알고리즘은 딥러닝과 SORT 알고리즘을 결합한 추적 기술로, 딥러 닝 기술을 이용하여 객체의 위치와 특징을 추출한 후, 추출된 특징을 객체의 일련번호와 함께 저장된다. 객체가 다시 감지되면, 저장된 특징과 비교하여 해당 객체가 이전에 추적한 객체인지 여부를 확인한 후, 궤적을 추출한 다. 궤도 추출기는 바운딩 박스 생성기가 인식한 복수 개의 객체 각각의 궤적을 추출하며, 이렇게 궤도 추 출기가 추출한 객체 추적도(2D Object Trajectories)는 영향도 맵 생성기로 입력된다. 영향도 맵 생성기는 궤도 추출기가 추출한 객체의 궤도에 기호, 라벨, 텍스트 또는 색상 중 적어도 하 나를 포함하는 표기(Notation)를 부가하여, 각 객체에 대한 궤도 간의 관계를 정의하는 영향도 맵(Influence Map)를 생성한다. 구체적으로 영향도 맵 생성기는 시공간 정보를 표기로 부가함으로써, 객체 추적도(2D Object Trajectories)를 인코딩(Encoding)한다. 시공간의 정보를 포함한 영향도 맵은 사고 판단기로 입력되며, 사 고 판단기는 영향도 맵을 입력값으로 CCTV 프레임에 사고가 있었는지 여부를 판단(추론)한다. 여기서 영향도 맵은 게임 개발에서 NPC(Non-Player Character)의 이동 및 행동 패턴을 결정하는데 주로 사용되 는 기술로, 영향도 맵에서 서클(CirCle)은 일종의 지역(Region)을 나타낸다. 즉, 영향도 맵에서 서클은 해당 지 점을 중심으로 객체의 영향력의 정도를 나타내는 것으로, 서클의 크기가 클수록 객체의 영향력 범위가 넓어진다. 개시된 영향도 맵은 객체의 속도, 특정 지점에서의 위험도를 고려하여, 궤적에 따라 서클을 생성할 수 있다. 영향도 맵 생성기가 영향도 맵을 생성하는 구체적인 방법은 이하의 다른 도면을 통해서 후술한다. 사고 판단기는 영향도 맵을 입력값으로, CNN 기반의 알고리즘을 통해 CCTV 프레임이 사고 영상인지 여부를 판단한다. 사고 판단기가 사용하는 CNN 기반 알고리즘은, 영향도 맵을 구별하고, 중요한 가중치(Weights)를 부여하면서, 영향도 맵을 바이어스(Bias)한다. 개시된 일 실시예에 따른 사고 판단기는 5개의 컨벌루젼 레 이어(Convolution Layer)와 5개의 맥스 폴링 레이어(Max Pooling Layer) 및 3개의 Fully Connected Layer로 구 성된 CNN일 수 있다. 개시된 일 예에 따라, 사고 판단기에 입력되는 영향도 맵은 224x224 픽셀 사이즈의 RGB 3채널을 포함한 맵 일 수 있다. 영향도 맵이 입력되면, 컨벌루젼 레이어는 3 x 3 커널을 이용할 수 있으며, 2번째 및 5번째 컨벌루 젼 레이어는 64 및 512 채널을 가질 수 있다. 맥스 폴링 레이어는 2 x 2 커널을 이용하며, 영향도 맵으로부터 추출된 시공간 특징의 리텐션을 최대화하고, 컨벌루젼 레이어의 특징 맵(Feature Map)의 차원(dimensionality) 을 최소화할 수 있다. 또한, 이러한 실시예에서 컨벌루젼 레이어에 배치 표준화(Batch Normalization) 및 ReLU (Rectfied Linear Unit) 활성 함수가 추가되며, 배치 표준화는 영향도 맵의 사이즈에 의해서 ReLU의 불안정성을 막기 위해서 실행될 수 있다. Fully Connected Layer의 사이즈는 4096, 1024 및 2일 수 있으며, CNN 기반의 알 고리즘은 CCTV 프레임이 사고 여부를 포함하는지 또는 불포함하는지를 구별한다.사고 판단기를 통해 구별된 값은 디스플레이등을 통해 출력될 수 있다. 한편, 도 2에서 전술한 각 제어블록은 교통사고 감지 방법의 설명의 편의를 위해서 구분된 것이며, 하드웨어적 으론 하나의 프로세서에서 실행될 수 있다. 도 2에서 설명한 각각의 인공지능 알고리즘은 실시예에 불과하며, 다양한 번형례가 있을 수 있다. 일 예로, 바 운딩 박스 생성기가 반드시 YOLO만을 사용해야 하는 것은 아니며, 객체 인식이 가능한 다른 알고리즘을 사 용할 수도 있다. 궤도 추출기 또한, 반드시 Deep SORT 알고리즘에 한정되어서 궤도를 추출하는 것은 아니며, 마찬가지로 사고 판단기가 사용하는 CNN 또한, 반드시 도 2에서 설명한 스펙에 한정되는 것은 아니 고, 영향도 맵에서 사고를 판단할 수 있는 다양한 형태의 인공지능을 더 포함할 수 있다. 도 3은 개시된 교통사고 감지 방법을 설명하기 위한 순서도이고, 도 4는 도 3의 순서도를 설명하기 위한 도면이 다. 중복되는 설명을 피하기 위해서 이하 함께 설명한다. 교통사고 감지 시스템은 객체 인식 알고리즘을 통해 객체에 바운딩 박스를 생성한다. 개시된 일 실시예에서 복수 개의 CCTV 프레임이 입력되면, 바운딩 박스를 생성하는 객체 인식 알고리즘은 YOLO V5일 수 있다. 도 4에서 도시된 바와 같이, 객체 인식 알고리즘은 바운딩 박스 생성기는 각 객체마다 바운 딩 박스가 포함된 복수 개의 이미지(2D Object Bounding Boxes)를 출력할 수 있다. 교통사고 감지 시스템은 SORT 알고리즘에 기초하여 객체의 궤도를 추출한다. 개시된 일 실시예에서 궤도 추출기는 Deep SORT 알고리즘을 통해 객체 추적도(2D Object Trajectories)를 출력할 수 있다. 여기서 궤도가 표시된 이미지는 CCTV 프레임에 인식되는 여러 객체 중, 하나의 객체마다 궤적 을 추출하여 생성된 이미지이며, 도 4에서 도시된 바와 같이, 각 객체마다 복수 개의 궤도가 표시된 이미지가 생성될 수 있다. 교통사고 감지 시스템은 영향도 맵을 생성하는 이미지 전처리를 수행한다. 도 4에서 도시된 바와 같이, 개시된 일 실시예에 따른 영향도 맵은 각 궤적에서 객체의 시공간 정보를 나타내는 RGB 채널을 이용한 서클 형태로 생성될 수 있다. 영향도 맵은 각 객체의 궤도 간의 거리 비율에 기초하여 크기, 색깔의 명도가 결정되는 복수 개의 서클(이하 제1 서클)을 생성하고, 각 객체의 바운딩 박스의 위치에 기초하여 사고 발생 확률을 산출하고, 산출된 확률 값에 기초하여 또 다른 서클(이하 제2 서클)을 생성하고, 객체의 궤도 를 각 서클에 중첩시켜 최종적인 영향도 맵을 생성한다. 영향도 맵에 대한 구체적인 설명은 이하의 다른 도면을 통해 더욱 구체적으로 설명한다. 영향도 맵 생성기가 생성한 영향도 맵은 객체의 시공간의 정보를 포함하게 되고, CCTV 프레임에 대응된 영 향도 맵은 사고 판단기로 입력된다. 사고 판단기는 CNN 기반 알고리즘에 기초하여 사고여부를 판단한다. 개시된 일 실시예에 따른 사고 판단기는 기본적으로 입력된 영향도 맵이 교통사고를 포함하는지 아닌지 여 부를 0과 1로 판단한다. 사고 판단기는 영향도 맵에 대응되는 CCTV 프레임을 매칭시키고 있으므로, 입력된 영향도 맵이 사고여부를 포함하는 경우, 사용자에게 영향도 맵에 대응되는 프레임의 사고여부를 포함하는지도 함께 출력할 수 있다. 도 4에서 도시된 예시와 같이, 사고 판단기는 CCTV 프레임 중 승용차와 화물차, 2개 의 객체가 서로 충돌하는 영상은 사고를 포함하는 프레임으로 판단하고, 2개의 객체가 서로 충돌 전인 프레임은 사고를 포함하지 않는 프레임으로 판단할 수 있다. 한편, 사고 여부를 0 또는 1로 이분법적으로 판단하는 결과 이외에도 교통사고 감지 시스템은 디스플레이를 통해 사용자에게 사고여부를 포함하는 정보 이외에 각종 다양한 유저 인터페이스적 처리를 수행함으로써, 사용 자가 CCTV 프레임 내 사고 발생지점 또는 객체의 속도 등 다양한 정보를 함께 제공받을 수도 있다. 도 5는 개시된 일 실시예에 따른 영향도 맵 생성기의 동작을 구체적으로 설명하기 위한 순서도이다. 도 6은 생 성된 영향도 맵의 일 예의 이미지이다. 영향도 맵은 궤도 추출기에서 생성한 궤적을 표시한 이미지, 객체 추적도(2D Object Trajectories)에 기초 하여 생성된다. 종래 일반적인 궤적을 포함한 이미지를 그대로 CNN 기반의 TASP(Traffic Accident Severity Prediction)에 사용하면, 충돌에 의한 궤도 이탈 등으로, 감지 여부가 명확하지 않는 문제가 있었다. 따라서 개 시된 교통사고 감지 시스템은 시공간의 정보를 포함시킨 영향도 맵을 생성하고 이를 통해서 정확도 높은 사고 구별을 수행할 수 있다. 도 5를 참조하면, 영향도 맵 생성기는 객체 궤도간의 거리 비율에 기초하여 크기 및 색깔의 명도가 서로 다 른 복수 개의 서클(이하 제1 서클)을 생성한다. 여기서 영향도 맵의 표기(notation)으로 표시되는 제1 서클은 수학식 1에 의해서 정의된다. 수학식 1"}
{"patent_id": "10-2023-0055753", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 rc는 제1 서클의 반지름이고, rmin은 궤도가 표시된 이미지, 객체 추적도(2D Object Trajectories)의 가 로(wi) 또는 높이(hi) 중 큰 값이다. 제1 서클의 거리 비율은 객체끼리 중첩된 영역을 계산하기 위해서 객체 추적도(2D Object Trajectories)의 사이 즈에 기초하여 조정될 수 있다. 거리 비율이 크다는 것은 객체 사이의 중첩된 영역이 크다는 것을 나타내며, 제 1 서클의 색은 진해진다. 이와 반대로, 거리 비율이 낮다는 것은, 객체 사이의 중첩된 영역이 작다는 것을 의미 하며, 제1 서클의 색은 옅어진다. 거리 비율과 제1 서클의 색은 아래의 수학식 2 및 3을 통해서 결정될 수 있다. 수학식 2"}
{"patent_id": "10-2023-0055753", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 3"}
{"patent_id": "10-2023-0055753", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서 x는 거리 비율이며, dmin은 객체 사이의 거리가 가장 가까울 때의 거리이며, c는 색 변화 정도이며, Tmax 는 궤도 좌표가 존재하는 최대 시간이며, 현재 궤도 좌표가 위치하는 시간이다. 시간은 영상에서 프레임이 위치 하는 시간으로 산출될 수 있다. 전술한 수학식에서 알 수 있듯이, 제1 서클은 객체 추적도(2D Object Trajectories)에 표시된 객체의 궤도 간의 거리 비율에 기초하여 그 크기 및 색깔의 명도가 결정된다. 또한, 제1 서클은 객체 인식 알고리즘에 의해서 인 식된 객체의 위치에 기초하여 제1 서클의 위치가 결정되며. 각 객체 간의 거리 비율이 작아지면, 생성되는 제1 서클의 반지름이 커지고, 색깔이 진해진다. 제 1서클이 생성되면, 영향도 맵 생성기는 사고의 발생 확률을 고려한 표기(notation)을 나타내는 서클(이 하 제2 서클)을 생성한다. 제2 서클은 수학식 4를 통해서 생성될 수 있다. 수학식 4 여기서 y는 객체 인식에 사용된 바운딩 박스의 영역이며, wc와 hc는 바운딩 박스의 크기이다. 즉, 제2 서클은 바 운딩 박스의 영역과 크기에 기초하여 결정되며, 제2 서클의 영역은 사고 발생 가능성에 대한 확률을 나타낼 수 있다. 전술한 수학식에서 알 수 있듯이, 제2 서클은 객체의 궤도가 객체 추적도에서 차지하는 위치(좌표)에 기초하여 크기 및 색깔의 명도가 결정된다. 즉, 제2 서클은 객체의 크기가 증가할수록, 제2 서클의 크기가 증가한다. 또 한, 객체의 귀도가 차지하는 위치는 사고를 구별하는 값(Value)이므로, 사고 발생 지점을 나타내는 제2 서클의 크기가 증가하는 것은 사고 가능성이 커지는 것을 의미한다. 영향도 맵 생성기가 제2 서클까지 생성하면, 각각의 프레임으로부터 확인될 수 있는 각 객체의 궤도를 영향 도 맵 상에 생성한다. 즉, 도 5와 같이, 영향도 맵 생성기는 제1 서클 위치를 연결(제1 서클에 해당하는 궤 도의 좌표를 연결)해서 객체의 궤도를 나타내는 라인을 생성하여 최종적인 영향도 맵을 생성한다.도 6을 참조하 면, 일 예에 따라 생성된 영향도 맵은 서로 다른 RGB 표기를 통해 생성될 수 있다. 도 6에서 Y자 형태로 표시된 붉은 라인은 제1 차량 및 제2 차량의 궤적을 나타내며, 객체 사이의 거리가 가까워질수록 푸른색의 제1 서클은 진해지며 크기가 커질 수 있다. 사고 발생 가능성을 나타내는 제2 서클은 도 6의 녹색 영역이 진해질수록 높아 지며, 이는 바운딩 박스의 크기에 기초하여 결정된다. 도 7은 도 6의 실시예를 실제 CCTV 프레임과 비교하여 설명한 표이다. 도 7을 참조하면, 도 6의 영향도 맵은 CCTV 프레임별로 매칭되어 생성될 수 있다. 구체적으로 교통사고 감지 시 스템에 입력되는 프레임은 50개의 프레임이 입력될 수 있으며, 이는 시간 순서대로 입력된다. 교통사고 감지 시스템은 추적 단계에서 궤적이 표시된 이미지, 객체 추적도(2D Object Trajectories)를 각 프레임에 대응하여 도 7과 같이 생성할 수 있다. 교통사고 감지 시스템은 영향도 맵 생성기에서 도 7과 같이 CCTV 프레임에 대응한 영향도 맵을 생성할 수 있으며, 도 6의 영향도 맵은 객체 간의 거리 비율과 각 객체 의 바운딩 박스의 크기에 기초하여 각 서클 및 보정된 궤적이 표시된 영향도 맵이다. 즉 개시된 실시예에 따른 영향도 맵은 각 객체의 속도 정보 및 거리 정보에 기초하여 사고 발생 가능성이 포함된 정보를 포함하고 있으므 로, CNN 기반의 알고리즘이 훨씬 높은 정확도에 기초하여 CCTV 프레임이 사고 영상인지 아닌지 여부를 판단할 수 있으며, 도 7에서 볼 수 있듯이, 25번째 프레임을 기준으로 교통사고 감지 시스템은 이후의 프레임이 교 통사고를 포함하는 프레임으로 구별하게 된다. 도 8은 개시된 교통사고 감지 시스템에 포함된 알고리즘을 훈련시키는 매개변수를 설명하기 위한 표이다. 개시된 교통사고 감지 시스템은 도 8의 표와 같이 다양한 훈련 파라미터(매개변수, Hyperparameter)를 사용 하여 알고리즘을 학습시킨 후, 우수한 성능을 나타내었다. 구체적으로 성능 실험에 사용된 CCTV 프레임의 매개변수는 이미지 크기(Weight, Height)이며, 차원(Dimension, Dim)은 2이다. 객체 추적도(2D Object Trajectories)는 추적 단계(Tracking Phase)의 궤도 추출기에서 생 성되는 중간 결과물로써, CCTV 프레임과 같은 이미지 형식이다. 따라서 객체 추적도 또한, 매개변수로 이미지 크기(Weight, Height)를 조절하였으며, 차원(Dimension, Dim)은 2이다. 영향도 맵(Influence Map)은 영향도 맵 생성기의 결과물로써, 객체 추적도를 이미지 전처리한 결과이다. 영 향도 맵은 224x224픽셀로 균일하게 잘리도록(Cropped) 매개변수를 설정하였으며, 이 때 차원은 3이다. 개시된 실시예에 따른 교통사고 감지 시스템의 성능 평가에 사용되는 인공지능의 배치 사이즈(Batch Size)는 64이며, Learning Rate는 1x10-5이다. 개시된 실시예에 따른 교통사고 감지 시스템에 인공지능이 학습하는 전체 데이터 셋(Set)의 에포크(Epoch)는 15번으로 설정하고, Steps Per Epoch는 94로 성능 실험을 진행하였다. 교통사고 감지 시스템의 성능 평가에서 최적화 알고리즘((Optimizer)로 확률적 경사 하강법(Stochastic Gradient Descent, SGD)를 사용하였으며, 목적 함수(Objective Function)로, Softmax를 사용하였다. 도 9는 개시된 교통사고 감지 시스템의 데이터 셋의 스펙을 설명하기 위한 표이다. 도 8에서 언급한 성능 평가를 위해서 개시된 일 실시예에 따른 교통사고 감지 시스템은 CADP(Car Accident Detection and Prediction) 데이터 셋을 사용하였다. 본 실시예에서 사용한 CADP 데이터셋은 1416개의 CCTV segments로 구성되었고, 이 중 150개의 CCTV segments는 전처리를 수행하였고, CCTV segment별 프레임은 50개로 구성되었다. 즉, 개시된 교통사고 감지 시스템의 성능 평가에 입력되는 CCTV 프레임은 총 7500개이며, 7500개의 영향도 맵을 생성하였다. 생성된 7500개의 영향도 맵 중 6750개(90%)가 사고 판단기의 학습 데이 터로 사용되었으며, 이 중 750개(10%)의 영향도 맵이 유효한 데이터(Validation data)로 사용되었다. 도 9의 표에서 설명한 CADP 데이터 셋은 다양한 교통 상황에 대한 CCTV 프레임이 포함되어 있으며, 낮과 밤에 촬영된 CCTV 프레임, 눈 또는 비가 내리는 날씨에 대한 다양한 상황이 포함된 CCTV 프레임, 교통 체증이 있는 CCTV 프레임과 다양한 해상도를 가지는 CCTV 프레임 등 다양한 데이터를 포함하고 있다. 도 10 내지 도 11은 개시된 교통사고 감지 시스템의 성능 평가의 결과를 보여주기 위한 표이다. 도 10을 먼저 참조하면, 도 10의 그래프는 개시된 교통사고 감지 시스템의 훈련 손실(Training Loss) 및 유 효 결과 손실(Validation Loss)를 나타내며, X축은 에포크(Epoch), Y축은 손실(Loss)를 나타낸다. 구체적으로 개시된 교통사고 감지 시스템의 훈련 손실은 2.88의 초기 값(Initial Value)를 보이며, 4번의 에 포크 후 감소하는 것으로 전환되면서, 최종적으로 0.06의 훈련 손실을 기록하였다. 유효 결과 손실 또한, 3.41 의 초기 값을 보이다가, 4번의 에포크 후 감소하여 최종적으로 0.12를 기록하였다. 도 11을 참조하면, 도 11의 그래프는 개시된 교통사고 감지 시스템의 훈련 정확도(Training Accuracy) 및 유 효 결과 정확도(Validation Accuracy)를 나타내며, X축은 에코프(Epoch), Y축은 정확도(Accuracy)를 나타낸다. 구체적으로 개시된 교통사고 감지 시스템의 훈련 정확도는 55.63의 초기 값을 보이다가, 2번의 에포크 후 증 가되는 것으로 전환되면서, 최종적으로 97.13만큼 기록하였다. 유효 결과 정확도는 77.87을 초기값으로 시작하 여, 계속적인 훈련을 통해 95.87까지 증가한 것을 볼 수 있다. 도 10 및 도 11를 통해 개시된 교통사고 감지 방법은, 영향도 맵의 특징을 유효하게 추출하고, 교통사고 여부를 원할하게 수행하는 것을 확인할 수 있다. 도 12 및 도 13은 종래 일반적인 알고리즘과 개시된 교통사고 감지 시스템의 성능을 비교하기 위한 그래프이다. 구체적으로 도 12 및 도 13은 종래 일반적인 CNN 기반의 알고리즘(이하 종래 알고리즘)을 통해 CCTV 프레임에 대한 교통사고 감지 여부를 판단하는 비교 실험의 결과로, 도 10 및 도 11과 동일한 지표를 사용하였다. 도 12에서 볼 수 있듯이, 종래 알고리즘은 5번째 에포크 전에 훈련 손실이 6.43에서 0.86으로 급격하게 떨어진 후, 0.37까지 천천히 떨어지는 것을 확인할 수 있다. 또한, 유효 결과 손실도 훈련 손실과 유사하게, 훈련 초기 6.56을 나타내다가, 50에포크 후에 0.45로 전환된다. 도 13에서 볼 수 있듯이, 훈련 정확도 또한, 종래 알고리즘은 4 번의 에포크 전인 4.67에서 55.4까지 빠르게 증 가하다가, 95.2까지 천천히 증가하는 것을 확인할 수 있다. 유효 결과 정확도도 50 에포크 후에 0.75에서 94.38 까지 빠르게 증가하는 것을 확인할 수 있다. 도 12 및 도 13에서 확인할 수 있듯이, 개시된 교통사고 감지 시스템은, 종래 CNN 기반의 알고리즘에 비해서 낮 은 훈련 로스 및 빠른 유효 결과 데이터로의 전환을 확인할 수 있으며, 15 에포크 동안 훈련된 개시된 교통사고 감지 시스템이 50 에포크 동안 훈련된 종래 알고리즘이 비해 1.93정도 높은 정확도와 0.31의 낮은 전환율을 가진다. 이처럼 개시된 교통사고 감지 시스템은 CCTV 프레임에서 교통 사고를 판단하는 훈련 효율성 및 정확성이 종래 일반적인 CNN 기반의 알고리즘보다 우수하다. 도 14는 개시된 영향도 맵 이외에 다른 접근 방식을 통해 사고 여부를 판단하는 방법을 비교한 그래프이다. 개시된 교통사고 감지 시스템이 생성하는 영향도 맵 이외에 객체 바운딩 박스(Object Bounding Box), 객체 추적 데이터(Object Trajectory Data Type), 광학 흐름도(Optical Flow), 어텐션 맵(Attention Map)을 비교한 실험을 진행하였다. 도 14에서 볼 수 있듯이, 개시된 교통사고 감지 시스템은 97.3 및 95.9의 훈련 정확도 및 유효 결과 정확도 를 나타낸데 반해, 객체 바운딩 박스만을 사용한 경우 96.4 및 91.7의 정확도만을 나타내었으며, 객체 추적 데 이터를 사용한 경우, 93.8 및 93.0의 정확도를 나타내었다. 광학 흐름도를 사용하여 교통사고 여부를 판단한 경 우 67.0 및 65.9의 낮은 정확도를 기록하였으며, 어텐션 맵을 사용한 경우 86.6 및 84.3의 정확도를 기록하였다. 즉, 개시된 교통사고 감지 시스템은 영상 프레임에서 인식되는 객체의 궤적에 기초하여 거리 비율 및 바운딩 박스의 크기에 따른 영향도 맵을 생성함으로써, 종래 다른 알고리즘 및 다른 타입의 이미지 전처리를 수행한 것 보다, 높은 정확도 및 훈련 속도를 가지면서 영상 프레임에서 교통사고가 발생했는지 여부를 판별할 수 있다. 또한 교통사고 감지 시스템은 종래 일반적인 인공지능이 보여주었던 낮은 정확도 및 훈련 속도를 극복하고, CCTV 프레임에서 구별할 수 없었던 사고까지도 구별할 수 있다."}
{"patent_id": "10-2023-0055753", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 은 개시된 교통사고 감지 시스템의 하드웨어적 구성을 설명하기 위한 도면이다. 도 2는 교통사고 감지 시스템의 각 구성에 대한 제어 블록도이다. 도 3은 개시된 교통사고 감지 방법을 설명하기 위한 순서도이다. 도 4는 도 3의 순서도를 설명하기 위한 도면이다. 도 5는 개시된 일 실시예에 따른 영향도 맵 생성기의 동작을 구체적으로 설명하기 위한 순서도이다. 도 6은 생성된 영향도 맵의 일 예의 이미지이다. 도 7은 도 6의 실시예를 실제 CCTV 프레임과 비교하여 설명한 표이다. 도 8은 개시된 교통사고 감지 시스템에 포함된 알고리즘을 훈련시키는 매개변수를 설명하기 위한 표이다. 도 9는 개시된 교통사고 감지 시스템의 데이터 셋의 스펙을 설명하기 위한 표이다. 도 10 내지 도 11은 개시된 교통사고 감지 시스템의 성능 평가의 결과를 보여주기 위한 표이다. 도 12 및 도 13은 종래 일반적인 알고리즘과 개시된 교통사고 감지 시스템의 성능을 비교하기 위한 그래프이다. 도 14는 개시된 영향도 맵 이외에 다른 접근 방식을 통해 사고 여부를 판단하는 방법을 비교한 그래프이다."}
