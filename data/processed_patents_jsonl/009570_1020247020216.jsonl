{"patent_id": "10-2024-7020216", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0105464", "출원번호": "10-2024-7020216", "발명의 명칭": "사용자 장비 인공 지능-머신 러닝 능력 범주화 시스템, 방법, 디바이스 및 프로그램", "출원인": "라쿠텐 모바일 가부시키가이샤", "발명자": "무함마드 온"}}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "통신 네트워크에서 사용자 디바이스의 머신 러닝 능력을 분류하기 위한 방법으로서, 상기 방법은 프로세서에 의해 실행되며, 상기 방법은:상기 사용자 디바이스로부터 사용자 디바이스 능력 정보를 수신하는 단계;상기 사용자 디바이스 능력 정보에 기초하여, 상기 사용자 디바이스의 머신 러닝 능력의 분류를 결정하는 단계;및상기 사용자 디바이스의 머신 러닝 능력의 분류에 기초하여 머신 러닝 모델과 연관된 데이터를 상기 사용자 디바이스에 전송하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 사용자 디바이스 능력 정보는 상기 사용자 디바이스와 연관된 복수의 파라미터들을 포함하며, 각각의 파라미터는 범주형 변수로 표현되는, 방법."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 사용자 디바이스와 연관된 상기 복수의 파라미터들은, 상기 사용자 디바이스의 프로세서유형, 가용 메모리의 크기, 상기 사용자 디바이스의 배터리 전력, 상기 사용자 디바이스의 배터리 상태, 상기사용자 디바이스의 디바이스 유형, 또는 상기 사용자 디바이스의 라디오 주파수 하드웨어 능력 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 분류를 결정하는 단계는:상기 복수의 파라미터들로부터 상기 사용자 디바이스의 하나 이상의 파라미터를 평가하는 단계; 상기 하나 이상의 파라미터 각각에 대한 범주형 값을 결정하는 단계; 및 상기 하나 이상의 파라미터 각각에 대한 범주형 값을 미리 결정된 최소 범주형 값 세트와 비교하는 것에 기초하여, 상기 하나 이상의 파라미터 각각에 대한 범주형 값에 기반하여 상기 사용자 디바이스에 분류 번호를 할당하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 머신 러닝 모델과 연관된 데이터를 상기 사용자 디바이스 전송하는 단계는:상기 사용자 디바이스의 머신 러닝 능력의 분류에 기초하여,상기 사용자 디바이스에서의 전체 규모의 훈련을 위한 훈련 데이터 및 모델 파라미터들;상기 사용자 디바이스에서의 경량 훈련을 위한 가볍게 훈련된 모델, 상기 훈련 데이터의 서브세트, 및 상기 모델 파라미터들;일반 훈련된 모델, 훈련 데이터의 서브세트, 및 상기 사용자 디바이스에서의 상기 일반 훈련된 모델의 특정 사용 사례 기반 업데이트를 위한 상기 모델 파라미터들; 및상기 사용자 디바이스에서의 추론을 위한 훈련된 모델중 하나를 상기 사용자 디바이스에 전송하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 일반 훈련된 모델에 대한 상기 특정 사용 사례 기반 업데이트는 CSI(channel-state공개특허 10-2024-0105464-3-information) 피드백 향상, 빔 관리, 위치 결정 정확도, 수신 신호(RS) 오버헤드 감소, 로드 밸런싱, 이동성 최적화 또는 네트워크 에너지 절약 중에서의 사용 사례와 연관되는, 방법."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서, 상기 사용자 디바이스에서의 상기 경량 훈련은 허용 가능한 수준의 정확도를 달성하기 위해 제한된 횟수의 에포크 동안 상기 가볍게 훈련된 모델을 업데이트하는 것을 포함하는, 방법."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서, 상기 사용자 디바이스에서의 상기 전체 규모의 훈련은 상기 훈련 데이터 및 상기 모델 파라미터들을 사용하여 상기 머신 러닝 모델을 생성하는 것을 포함하며, 상기 생성하는 것은 높은 수준의 정확도를 달성하기 위해 다수의 에포크 동안 모델을 훈련시키는 것을 포함하는, 방법."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 사용자 디바이스의 머신 러닝 능력의 분류는 상기 사용자 디바이스의 인공 지능 모델 훈련 용량을 나타내는, 방법."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 사용자 디바이스의 머신 러닝 능력의 분류는 상기 사용자 디바이스의 인공 지능 모델 추론 용량을 나타내는, 방법."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 사용자 디바이스 능력 정보를 수신하는 것은 상기 사용자 디바이스로부터의 요청을 수신하는 것에 대한 응답인, 방법."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서, 상기 사용자 디바이스 능력 정보를 수신하는 것은 상기 통신 네트워크의 네트워크 요소로부터의 요청을 수신하는 것에 대한 응답인, 방법."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "장치로서,명령어들을 저장하도록 구성된 메모리; 및하나 이상의 프로세서를 포함하며, 상기 하나 이상의 프로세서는사용자 디바이스로부터 사용자 디바이스 능력 정보를 수신하고;상기 사용자 디바이스 능력 정보에 기초하여, 상기 사용자 디바이스의 머신 러닝 능력의 분류를 결정하며;상기 사용자 디바이스의 머신 러닝 능력의 분류에 기초하여 머신 러닝 모델과 연관된 데이터를 상기 사용자 디바이스에 전송하기 위해상기 명령어들을 실행하도록 구성되는, 장치."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서, 상기 사용자 디바이스 능력 정보는 상기 사용자 디바이스와 연관된 복수의 파라미터들을 포함하며, 각각의 파라미터는 범주형 변수로 표현되는, 장치."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 분류를 결정하는 것은:상기 복수의 파라미터들로부터 상기 사용자 디바이스의 하나 이상의 파라미터를 평가하는 것;상기 하나 이상의 파라미터 각각에 대한 범주형 값을 결정하는 것; 및공개특허 10-2024-0105464-4-상기 하나 이상의 파라미터 각각에 대한 범주형 값을 미리 결정된 최소 범주형 값 세트와 비교하는 것에 기초하여, 상기 하나 이상의 파라미터 각각에 대한 범주형 값에 기반하여 상기 사용자 디바이스에 분류 번호를 할당하는 것을 포함하는, 장치."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서, 머신 러닝 모델과 연관된 데이터를 상기 사용자 디바이스 전송하는 것은:상기 사용자 디바이스의 머신 러닝 능력의 분류에 기초하여,상기 사용자 디바이스에서의 전체 규모의 훈련을 위한 훈련 데이터 및 모델 파라미터들;상기 사용자 디바이스에서의 경량 훈련을 위한 가볍게 훈련된 모델, 상기 훈련 데이터의 서브세트, 및 상기 모델 파라미터들;일반 훈련된 모델, 훈련 데이터의 서브세트, 및 상기 사용자 디바이스에서의 상기 일반 훈련된 모델의 특정 사용 사례 기반 업데이트를 위한 상기 모델 파라미터들; 및상기 사용자 디바이스에서의 추론을 위한 훈련된 모델중 하나를 상기 사용자 디바이스에 전송하는 것을 포함하는, 장치."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 사용자 디바이스에서의 상기 경량 훈련은 허용 가능한 수준의 정확도를 달성하기 위해제한된 횟수의 에포크 동안 상기 가볍게 훈련된 모델을 업데이트하는 것을 포함하고, 상기 사용자 디바이스에서의 상기 전체 규모의 훈련은 상기 훈련 데이터 및 상기 모델 파라미터들을 사용하여 상기 머신 러닝 모델을 생성하는 것을 포함하며, 상기 생성하는 것은 높은 수준의 정확도를 달성하기 위해 다수의 에포크 동안 모델을 훈련시키는 것을 포함하는, 장치."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "명령어들을 저장한 비일시적 컴퓨터 판독 가능 매체로서, 상기 명령어들은, 하나 이상의 프로세서를 포함하는네트워크 요소에 의해 실행될 때, 상기 하나 이상의 프로세서로 하여금사용자 디바이스로부터 사용자 디바이스 능력 정보를 수신하게 하고;상기 사용자 디바이스 능력 정보에 기초하여, 상기 사용자 디바이스의 머신 러닝 능력의 분류를 결정하게 하며;상기 사용자 디바이스의 머신 러닝 능력의 분류에 기초하여 머신 러닝 모델과 연관된 데이터를 상기 사용자 디바이스에 전송하게 하는하나 이상의 명령어를 포함하는, 비일시적 컴퓨터 판독 가능 매체."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 사용자 디바이스 능력 정보는 상기 사용자 디바이스와 연관된 복수의 파라미터들을 포함하며; 상기 분류를 결정하는 것은:상기 복수의 파라미터들로부터 상기 사용자 디바이스의 하나 이상의 파라미터를 평가하는 것;상기 하나 이상의 파라미터 각각에 대한 범주형 값을 결정하는 것; 및상기 하나 이상의 파라미터 각각에 대한 범주형 값을 미리 결정된 최소 범주형 값 세트와 비교하는 것에 기초하여, 상기 하나 이상의 파라미터 각각에 대한 범주형 값에 기반하여 상기 사용자 디바이스에 분류 번호를 할당하는 것을 포함하는, 비일시적 컴퓨터 판독 가능 매체."}
{"patent_id": "10-2024-7020216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에 있어서, 머신 러닝 모델과 연관된 데이터를 상기 사용자 디바이스 전송하는 것은:상기 사용자 디바이스의 머신 러닝 능력의 분류에 기초하여, 공개특허 10-2024-0105464-5-상기 사용자 디바이스에서의 전체 규모의 훈련을 위한 훈련 데이터 및 모델 파라미터들; 상기 사용자 디바이스에서의 경량 훈련을 위한 가볍게 훈련된 모델, 상기 훈련 데이터의 서브세트, 및 상기 모델 파라미터들; 일반 훈련된 모델, 훈련 데이터의 서브세트, 및 상기 사용자 디바이스에서의 상기 일반 훈련된 모델의 특정 사용 사례 기반 업데이트를 위한 상기 모델 파라미터들; 및 상기 사용자 디바이스에서의 추론을 위한 훈련된 모델 중 하나를 상기 사용자 디바이스에 전송하는 것을 포함하는, 비일시적 컴퓨터 판독 가능 매체."}
{"patent_id": "10-2024-7020216", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "통신 네트워크에서 사용자 디바이스의 머신 러닝 능력을 분류하기 위한 방법, 시스템, 장치 및 비일시적 컴퓨터 판독 가능 매체가 제공될 수 있다. 이 방법은 하나 이상의 프로세서에 의해 수행될 수 있고, 사용자 디바이스로 부터 사용자 디바이스 능력 정보를 수신하는 단계; 사용자 디바이스 능력 정보에 기초하여, 사용자 디바이스의 머신 러닝 능력의 분류를 결정하는 단계; 및 사용자 디바이스의 머신 러닝 능력의 분류에 기초하여 머신 러닝 모 델과 연관된 데이터를, 사용자 디바이스로, 전송하는 단계를 포함할 수 있다."}
{"patent_id": "10-2024-7020216", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공 지능 및 머신 러닝(AI/ML)에 관련된 사용자 장비 또는 사용자 디바이스 능력을 범주화 또는 분 류하는 것에 관한 것이다. 특히, 본 개시는 AI/ML 모델의 훈련, 업데이트 및 추론에 관련된 통신 네트워크에 또는 그 일부에 연결된 사용자 장비 또는 사용자 디바이스의 능력을 분류하는 것에 관한 것이다."}
{"patent_id": "10-2024-7020216", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "통신 네트워크에서, 통신 네트워크의 컴포넌트들에 의해 수행되는 복수의 기능들이 AI/ML 모델링을 사용하여 최 적화될 수 있다. 그렇지만, 통신 네트워크에서 AI/ML을 사용하는 것에 관련된 기존 표준이나 논의조차도 없다. 통신 네트워크의 컴포넌트들에 의해 제공되는 서비스들을 개선시키기 위해 AI/ML을 적용하고 사용하는 것은 고 유한 과제들을 제시한다. 예를 들어, 통신 네트워크의 새로운 능력을 정의하는 관련 기술의 방법은 radio- frequency parameters(라디오-주파수 파라미터들), featureSetCombinations, 또는 featureSets 면에서 새로운 능력을 정의하는 것을 포함할 수 있다. 그렇지만, 이러한 방법들은 사용자 장비의 능력에 관련된 통합 및 검증 문제들로 인해 사용자 장비의 능력을 정의하는 데 충분하지 않을 수 있다. 따라서, AI/ML 사용을 효과적으로 활용하기 위해서는, 통신 네트워크의 컴포넌트들에 의해 수행되는 기능들 또 는 서비스들을 최적화하기 위해 사용자 장비 처리 능력을 범주화하는 것이 필요할 수 있다. 본 개시의 실시예들에 따르면, 통신 네트워크에서 사용자 디바이스의 머신 러닝 능력을 분류하기 위한 방법이 제공될 수 있다. 이 방법은 프로세서에 의해 실행될 수 있으며, 이 방법은: 사용자 디바이스로부터 사용자 디 바이스 능력 정보를 수신하는 단계; 사용자 디바이스 능력 정보에 기초하여, 사용자 디바이스의 머신 러닝 능력 의 분류를 결정하는 단계; 및 사용자 디바이스의 머신 러닝 능력의 분류에 기초하여 머신 러닝 모델과 연관된 데이터를 사용자 디바이스에 전송하는 단계를 포함할 수 있다. 본 개시의 실시예들에 따르면, 사용자 디바이스 능력 정보는 사용자 디바이스와 연관된 복수의 파라미터들을 포 함할 수 있으며, 여기서 각각의 파라미터는 범주형 변수(categorical variable)로 표현된다. 본 개시의 실시예들에 따르면, 사용자 디바이스와 연관된 복수의 파라미터들은 사용자 디바이스의 프로세서 유 형, 가용 메모리의 크기, 사용자 디바이스의 배터리 전력, 사용자 디바이스의 배터리 상태(battery health), 사 용자 디바이스의 디바이스 유형, 또는 사용자 디바이스의 라디오 주파수 하드웨어 능력 중 적어도 하나를 포함 할 수 있다. 본 개시의 실시예들에 따르면, 분류를 결정하는 단계는 복수의 파라미터들로부터 사용자 디바이스의 하나 이상 의 파라미터를 평가하는 단계; 하나 이상의 파라미터 각각에 대한 범주형 값(categorical value)을 결정하는 단 계; 및 하나 이상의 파라미터 각각에 대한 범주형 값을 미리 결정된 최소 범주형 값 세트와 비교하는 것에 기초 하여, 하나 이상의 파라미터 각각에 대한 범주형 값에 기반하여 사용자 디바이스에 분류 번호를 할당하는 단계 를 포함할 수 있다. 본 개시의 실시예들에 따르면, 머신 러닝 모델과 연관된 데이터를 사용자 디바이스 전송하는 단계는, 사용자 디 바이스의 머신 러닝 능력의 분류에 기초하여, 사용자 디바이스에서의 전체 규모의 훈련(full scale training)을 위한 훈련 데이터 및 모델 파라미터들; 사용자 디바이스에서의 경량 훈련(lightweight training)을 위한 가볍게훈련된 모델(lightly trained model), 훈련 데이터의 서브세트, 및 모델 파라미터들; 일반 훈련된 모델(general trained model), 훈련 데이터의 서브세트, 및 사용자 디바이스에서의 일반 훈련된 모델의 특정 사용 사례 기반 업데이트를 위한 모델 파라미터들; 및 사용자 디바이스에서의 추론을 위한 훈련된 모델 중 하나를 사용자 디바 이스에 전송하는 단계를 포함할 수 있다. 본 개시의 실시예들에 따르면, 일반 훈련된 모델에 대한 특정 사용 사례 기반 업데이트는 CSI(channel-state information) 피드백 향상, 빔 관리, 위치 결정 정확도, 수신 신호(received signal)(RS) 오버헤드 감소, 로드 밸런싱, 이동성 최적화 또는 네트워크 에너지 절약 중에서의 사용 사례와 연관된다. 본 개시의 실시예들에 따르면, 사용자 디바이스에서의 경량 훈련은 허용 가능한 수준의 정확도를 달성하기 위해 제한된 횟수의 에포크(epoch) 동안 가볍게 훈련된 모델을 업데이트하는 것을 포함한다. 본 개시의 실시예들에 따르면, 사용자 디바이스에서의 전체 규모의 훈련은 훈련 데이터 및 모델 파라미터들을 사용하여 머신 러닝 모델을 생성하는 것을 포함하며, 여기서 생성하는 것은 높은 수준의 정확도를 달성하기 위 해 다수의 에포크 동안 모델을 훈련시키는 것을 포함한다. 본 개시의 실시예들에 따르면, 사용자 디바이스의 머신 러닝 능력의 분류는 사용자 디바이스의 인공 지능 모델 훈련 용량(artificial intelligence model training capacity)을 나타낸다. 본 개시의 실시예들에 따르면, 사용자 디바이스의 머신 러닝 능력의 분류는 사용자 디바이스의 인공 지능 모델 추론 용량(artificial intelligence model inference capacity)을 나타낸다. 본 개시의 실시예들에 따르면, 사용자 디바이스 능력 정보를 수신하는 것은 사용자 디바이스로부터의 요청을 수 신하는 것에 대한 응답이다. 본 개시의 실시예들에 따르면, 사용자 디바이스 능력 정보를 수신하는 것은 통신 네트워크의 네트워크 요소로부 터의 요청을 수신하는 것에 대한 응답이다. 본 개시의 실시예들에 따르면, 명령어들을 저장하도록 구성된 메모리 및 명령어들을 실행하도록 구성된 하나 이 상의 프로세서를 포함하는 장치가 제공될 수 있다. 명령어들은 사용자 디바이스로부터 사용자 디바이스 능력 정보를 수신하고; 사용자 디바이스 능력 정보에 기초하여, 사용자 디바이스의 머신 러닝 능력의 분류를 결정하 며; 사용자 디바이스의 머신 러닝 능력의 분류에 기초하여 머신 러닝 모델과 연관된 데이터를 사용자 디바이스 에 전송하는 명령어들을 포함할 수 있다. 본 개시의 실시예들에 따르면, 명령어들을 저장한 비일시적 컴퓨터 판독 가능 매체가 제공될 수 있다. 명령어 들은, 하나 이상의 프로세서를 포함하는 네트워크 요소에 의해 실행될 때, 하나 이상의 프로세서로 하여금 사용 자 디바이스로부터 사용자 디바이스 능력 정보를 수신하게 하고; 사용자 디바이스 능력 정보에 기초하여, 사용 자 디바이스의 머신 러닝 능력의 분류를 결정하게 하며; 사용자 디바이스의 머신 러닝 능력의 분류에 기초하여 머신 러닝 모델과 연관된 데이터를 사용자 디바이스에 전송하게 할 수 있다."}
{"patent_id": "10-2024-7020216", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "예시적인 실시예들에 대한 이하의 상세한 설명은 첨부 도면을 참조한다. 상이한 도면들에서의 동일한 참조 번 호들은 동일하거나 유사한 요소들을 식별해 줄 수 있다. 전술한 개시는 예시 및 설명을 제공하지만, 총망라하거나 구현들을 개시된 정확한 형태로 제한하려는 의도는 아 니다. 위의 개시를 바탕으로 수정 및 변형이 가능하거나 구현들의 실시로부터 획득될 수 있다. 위에서 언급된 바와 같이, 통신 네트워크에서 AI/ML을 사용하는 것에 관련된 기존 표준이 없다. 통신 네트워크 의 컴포넌트들에 의해 수행되는 기능들 또는 서비스들을 최적화하기 위해서는 AI/ML 사용을 효과적으로 활용하 기 위해 사용자 장비(UE) 또는 사용자 디바이스 처리 능력의 범주화가 필요하다. 그렇지만, 통신 네트워크의 컴포넌트들에 의해 제공되는 서비스들을 개선시키기 위해 AI/ML을 적용하고 사용하는 것은 고유한 과제들을 제 시한다. 예를 들어, 통신 네트워크의 새로운 능력을 정의하는 관련 기술의 방법들은 radio-frequency parameters, featureSetCombinations, 또는 featureSets 면에서 새로운 능력을 정의하는 것을 포함할 수 있다. 그렇지만, 이러한 관련 기술의 방법들은 UE의 능력에 관련된 통합 및 검증 문제들로 인해 사용자 장비의 능력을 정의하는 데 충분하지 않을 수 있다. 추가적으로, 통신 네트워크의 최적 성능 또는 사용자 디바이스의 최적 성능을 위해서는, AI/ML 모델들의 조합이 필요할 수 있지만, 상이한 유형의 환경에 대해 모든 UE에서 모델들을 훈련시키는 것은 통신 네트워크 및 사용자 디바이스의 자원에 부담이 될 수 있다. 예로서, 네트워크 요소 또는 UE의 지리적 위치(예를 들면, 지역 유형, 실내 지역, 차폐 지역 등), UE 유형(스마트폰, 랩톱, 드론 등), UE 프로세서 속도, 네트워크 요소 대역폭, 작동 주파수 대역, 네트워크 요소 유형(예를 들면, 기지국 - 매크로 또는 마이크로), 다른 UE 하드웨어 및 소프트웨 어 능력 등은 사용될 수 있는 모델 및 모델이 훈련되거나, 업데이트되거나, 추론에 사용될 수 있는 위치에 영향 을 미칠 수 있다. 따라서, 통신 네트워크 또는 사용자 디바이스의 컴포넌트들에 의해 수행되는 기능들 또는 서비스들을 최적화하 기 위해서는 통신 네트워크에서 AI/ML 사용을 활용하기 위한 사용자 장비 처리 능력의 범주화가 필요할 수 있다. UE 처리 능력의 범주화 또는 분류의 장점들 중 하나는 일련의 능력을 갖는 통신 네트워크 내의 UE의 더 쉽고 더 간단한 통합 및 검증이다. 게다가, UE를 특정 AI/ML 능력으로 분류하는 것은 UE 공급업체와 네트워크 요소(예를 들면, gNode B(gNB)) 공급업체가 거대한 특징 조합 대신 특징 세트에 집중하는 것을 용이하게 할 수 있다. 마지막으로, UE의 범주 또는 분류를 결정하기 위해 UE의 특정 AI/ML 처리 능력에 집중하는 것은 교환되 는 정보량을 감소시켜, 통신 네트워크의 효율성을 증가시킬 수 있다. 본 개시의 실시예들은 사용자 디바이스의 처리 능력을 사용하여 통신 네트워크에 연결된 사용자 디바이스의 머 신 러닝 능력을 범주화 또는 분류하고, 이어서, 사용자 디바이스의 머신 러닝 능력의 분류에 기초하여, 통 신 네트워크의 기능 또는 목표를 최적화하기 위해 통신 네트워크의 사용자 디바이스에서 AI/ML 모델을 훈련시키 기 위한 데이터를 전송하는 것 또는 통신 네트워크의 기능 또는 목표를 최적화하기 위해 통신 네트워크의 사용자 디바이스로 부분적으로 또는 완전히 훈련된 AI/ML 모델을 전송하는 것에 관한 것이다. 사용자 디바이스 의 AI/ML 관련 처리 능력의 범주화 또는 분류를 사용하는 것은 모델 훈련, 모델 튜닝/업데이트, 및 모델 추론과 같은 AI/ML 모델의 다양한 스테이지들이 발생할 수 있는 위치를 결정하는 매우 자원 효율적이고 간결한 방법일 수 있다. 사용자 디바이스가 높은 처리 용량(processing capacity)을 가지고 있는 경우, 사용자 디바이스는 사 용자 디바이스로부터의 자원을 활용하여 AI/ML 모델의 전체 규모의 훈련을 수행하는 데 사용될 수 있다. 반면 에, 사용자 디바이스가 낮은 처리 용량을 가지고 있는 경우, 사용자 디바이스는 통신 네트워크로부터의 자원을 활용하여 네트워크 요소 또는 노드에서 훈련될 수 있는 AI/ML 모델을 기반으로 추론만을 수행하는 데 사용될 수 있다. 도 1은 본 개시에 설명된 시스템들 및/또는 방법들이 구현될 수 있는 네트워크 아키텍처의 단편(snippet)의 예 시적인 개략적 예시이다. 도 1에 도시된 바와 같이, 통신 네트워크의 네트워크 인프라스트럭처는 하나 이상의 사용자 디바이스 , 하나 이상의 네트워크 요소 및 하나 이상의 데이터 센터를 포함할 수 있다. 실시예들에 따르면, 사용자 디바이스는 통신 네트워크를 사용하여 통신하기 위해 최종 사용자에 의해 사용 되는 임의의 디바이스일 수 있다. 사용자 디바이스는 라디오 채널을 통해 네트워크 요소와 통신할 수 있다. 사용자 디바이스는 '단말', '사용자 장비(UE)', '이동국', '가입자국', 고객 구내 장비 (customer premises equipment)(CPE)', '원격 단말', '무선 단말', '사용자 디바이스', '디바이스', '랩톱', '컴퓨팅 디바이스' 또는 이와 동등한 기술적 의미를 갖는 다른 용어들로 대체될 수 있다. 본 개시의 실시예들 에 따르면, 사용자 디바이스 능력 정보에 따라, AI/ML 모델이 사용자 디바이스에서 훈련, 업데이트 및/또 는 배포될 수 있다. 사용자 디바이스 능력에 기초하여 분류를 결정하는 것은 통신 네트워크에서 AI/ML 모델들 이 사용될 수 있는 방법과 위치를 최적화하는 데 도움이 될 것이다. 추가적으로, 일단 계산되면, 여러 번 전송 하기 쉬울 수 있는 분류를 사용하는 것은 통신 네트워크의 오버헤드를 감소시킬 수 있다. 일부 실시예들에서, 사용자 디바이스는 기지국과 같은 네트워크 요소를 사용하여 통신 네트워크와 통 신할 수 있다. 기지국의 예는 gNodeB 또는 eNodeB일 수 있다. 네트워크 요소는 라디오 채널을 사용하여 사용자 디바이스와 통신 시스템 사이의 통신을 가능하게 하는 노드일 수 있다. 네트워크 요소는 사 용자 디바이스에 무선 연결을 제공할 수 있는 네트워크 인프라스트럭처 컴포넌트일 수 있다. 네트워크 요 소는 신호 전송 가능 거리에 기초하여 섹터라고도 알려진 특정 지리적 영역으로 정의된 커버리지를 가질 수 있다. 본 개시의 실시예들에 따르면, 사용자 디바이스 능력 정보에 따라, AI/ML 모델이 네트워크 요소에서 훈련, 업데이트 및/또는 배포될 수 있다. 사용자 디바이스 능력에 기초하여 분류를 결정하는 것은 통신 네트워크에서 AI/ML 모델들이 사용될 수 있는 방법과 위치를 최적화하는 데 도움이 될 것이다. 추가적으로, 일단 계산되면, 여러 번 전송하기 쉬울 수 있는 분류를 사용하는 것은 통신 네트워크의 오버헤드를 감소시킬 수 있다. 일부 실 시예들에서, 네트워크 요소는 또한 데이터 센터와 사용자 디바이스 사이에서 AI/ML 모델과 연관 된 데이터를 수신 및 전송할 수 있다. 일부 실시예들에 따르면, 네트워크 인프라스트럭처는 하나 이상의 데이터 센터를 포함할 수 있다. 데이터 센터는 AI/ML 모델의 훈련, 테스트 및 검증과 연관된 데이터를 저장할 수 있다. 데이터 센터는 데 이터를 네트워크 요소로 전송할 수 있고, 네트워크 요소는 데이터를 사용자 디바이스로 추가로 전송할 수 있다. 데이터 센터는 하나 이상의 중앙 데이터 센터, 하나 이상의 지역 데이터 센터 및 하나 이상의 에지 데이터 센터를 포함할 수 있다. 데이터 센터는 주로 콘텐츠 전달(content delivery)을 주도하는 일, 네트워크 기능을 제공하는 일, 네트워크 서비스, 모바일 서비스 및 클라우드 서비스를 제공하는 일을 담당할 수 있다. 예로서, 데이터 센터는 도시, 지구(district), 카운티(county) 또는 주와 같은 넓은 지리적 영역에서 통신 네트워 크 서비스를 주도하는 중앙 데이터 센터일 수 있다. 지역 데이터 센터는 지역 수준(regional level)에서 통신 네트워크 서비스를 주도할 수 있다. 중앙 데이터 센터는 복수의 지역 데이터 센터들을 포함할 수 있다. 에지 데이터 센터는 로컬 지역 수준(locality level)에서 통신 네트워크 서비스를 주도할 수 있다. 지역 데이터 센 터는 복수의 에지 데이터 센터들을 포함할 수 있다. 일부 실시예들에서, 각각의 에지 데이터 센터는 복수의 기 지국들, 노드들 또는 네트워크 요소들을 통해 통신 서비스들을 프로비저닝할 수 있다. 도 2는 본 개시의 실시예들에 따른, 통신 네트워크에서 사용자 디바이스의 머신 러닝 능력을 분류하기 위한 예 시적인 프로세스를 예시하는 예시적인 플로차트이다. 도 2에 도시된 바와 같이, 프로세스의 하나 이상의 프로세스 블록은 본 출원에서 논의된 도 1 및 도 6과 도 7의 컴포넌트들 중 임의의 것에 의해 수행될 수 있다. 도 4에서, 프로세스의 하나 이상의 프로세스 블 록은 셀, 기지국 또는 노드와 같은 네트워크 요소와 연관된 동작들에 대응할 수 있다. 동작에서, 사용자 디바이스의 AI/ML 능력에 대한 초기 요청이 요청되거나 전송될 수 있다. 일부 실시예들 에서, 네트워크 요소는 사용자 디바이스로부터 사용자 디바이스의 AI/ML 능력에 대한 요청을 수신할 수 있다. 일부 실시예들에서, 셀 또는 노드(예를 들면, gNodeB 또는 eNodeB)와 같은 네트워크 요소는 사용자 디바이스의 AI/ML 능력에 대한 요청을 개시하거나 사용자 디바이스에 전송할 수 있다. 예로서, 네트워크 요소는 사용 자 디바이스의 AI/ML 능력에 대한 초기 요청을 전송하거나 사용자 디바이스로부터 수신할 수 있다. 동작에서, 사용자 디바이스 능력 정보가 수신될 수 있다. 일부 실시예들에서, 사용자 디바이스 능력 정보 는 사용자 디바이스와 연관된 복수의 파라미터들을 포함할 수 있다. 사용자 디바이스와 연관된 복수의 파라미 터들은 사용자 디바이스의 프로세서 유형, 가용 메모리의 크기, 사용자 디바이스의 배터리 전력, 사용자 디바이 스의 배터리 상태, 사용자 디바이스의 디바이스 유형, 또는 사용자 디바이스의 라디오 주파수 하드웨어 능력 중하나 이상을 포함할 수 있다. 예로서, 사용자 디바이스의 프로세서 유형은 프로세서가 NPU(neural processing unit)인지 GPU(graphical processing unit)인지를 나타낼 수 있다. 다른 예로서, 사용자 디바이스의 배터리 전력은 사용자 디바이스의 배터리의 배터리 용량 또는 배터리 상태를 나타낼 수 있다. 사용자 디바이스의 디바 이스 유형은 스마트폰, 랩톱, 드론 또는 사물 인터넷 지원 디바이스(internet of things enabled device)인 사 용자 디바이스를 포함할 수 있지만 이에 제한되지는 않는다. 각각의 파라미터는 범주형 변수로 표현될 수 있다, 즉, 특정 값 또는 값 범위 대신, 각각의 파라미터가 범주로 표현될 수 있다. 예로서, 가용 메모리의 크기는 \"높음(high)\", \"중간(medium)\", 또는 \"낮음(low)\"으로 표현될 수 있으며, 여기서 높음, 중간, 또는 낮음에 포함될 수 있는 값 범위는 네트워크 운영자, 네트워크 요소에 의해 정의될 수 있거나, 과거 데이터에 기초하여 학습될 수 있다. 일부 실시예들에서, 사용자 디바이스 능력 정보는 네트워크 요소에 의해 사용자 디바이스에 전송되는 초기 요청 에 응답하여 수신될 수 있다. 다른 실시예들에서, 사용자 디바이스 능력 정보는 사용자 디바이스로부터 네트워 크 요소에 의해 수신되는 초기 요청에 응답하여 수신될 수 있다. 동작에서, 사용자 디바이스의 AI/ML 능력의 분류가 결정될 수 있다. 일부 실시예들에서, 사용자 디바이스 의 머신 러닝 능력의 분류는 사용자 디바이스의 인공 지능 모델 훈련 용량을 나타낼 수 있다. 예로서, 사용자 디바이스의 머신 러닝 능력의 분류는 사용자 디바이스에서 AI/ML 모델을 훈련시키는 것의 실현 가능성 (feasibility)을 나타낼 수 있다. 다른 예로서, 사용자 디바이스의 머신 러닝 능력의 분류는 사용자 디바이스 에서 AI/ML 모델을 훈련시키는 것의 실현 불가능성(infeasibility)을 나타낼 수 있지만 사용자 인터페이스에서 부분적으로 또는 완전히 훈련된 AI/ML 모델을 업데이트하는 것의 실현 가능성을 나타낼 수 있다. 사용자 디바이스의 머신 러닝 능력의 분류는 또한 사용자 디바이스의 인공 지능 모델 추론 용량을 나타낼 수 있 다. 일부 실시예들에서, 사용자 디바이스의 머신 러닝 능력의 분류는 사용자 디바이스에서 추론을 위해서만 완 전히 훈련된 AI/ML 모델을 사용하는 것이 가장 실현 가능할 수 있다는 것을 나타낼 수 있다. 일부 실시예들에서, 사용자 디바이스의 머신 러닝 능력의 분류는 숫자 또는 라벨을 사용하여 표현될 수 있다. 사용되는 숫자는 10진수, 2진수, 16진수 등과 같은 임의의 숫자 체계일 수 있다. 사용되는 숫자 또는 라벨은 미리 정의되거나 네트워크에 의해 정의될(network-defined) 수 있다. 일부 실시예들에서, 분류가 높을수록, 사 용자 디바이스가 더 우수한 성능(more capable)일 수 있다. 예로서, 분류 1은 사용자 디바이스가 모델 훈련이 아닌 모델 추론에만 실현 가능할 수 있다는 것을 나타낼 수 있다. 그 반대의 경우도 마찬가지일 수 있다. 분 류 1은 사용자 디바이스가 고성능(highly capable)이고 전체 규모의 AI/ML 모델을 훈련시키는 것이 사용자 디바 이스에서 실현 가능할 수 있음을 나타낼 수 있다. 사용자 디바이스의 머신 러닝 능력의 분류를 결정하는 것은 복수의 파라미터들로부터 사용자 디바이스의 하나 이상의 파라미터를 평가하는 것을 포함할 수 있다. 이어서, 사용자 디바이스의 하나 이상의 파라미터 각각에 대한 범주형 값이 결정될 수 있다. 하나 이상의 파라미터 각각에 대한 범주형 값을 미리 결정된 최소 범주형 값 세트와 비교하는 것에 기초하여, 분류 번호가 하나 이상의 파라미터 각각에 대한 범주형 값에 기반하여 사용 자 디바이스에 할당될 수 있다. 일부 실시예들에서, 복수의 파라미터들로부터 사용자 디바이스의 하나 이상의 파라미터를 평가하는 것은 머신 러닝 모델에 대한 사용 사례에 기초하여 복수의 파라미터들로부터 하나 이상의 파라미터를 선택하는 것을 포함 할 수 있다. 사용 사례의 예는 CSI(channel-state information) 피드백 향상, 빔 관리, 위치 결정 정확도, 수 신 신호(RS) 오버헤드 감소, 로드 밸런싱, 이동성 최적화 또는 네트워크 에너지 절약을 포함할 수 있지만 이에 제한되지 않을 수 있다. 사용자 디바이스의 하나 이상의 파라미터 각각에 대한 범주형 값을 결정하는 것은 사용자 디바이스로부터 수신 되는 사용자 디바이스 능력 정보를 파싱하는 것을 포함할 수 있다. 일부 실시예들에서, 사용자 디바이스의 하 나 이상의 파라미터 중 임의의 것에 대한 범주형 값을 결정하기 위해 사용자 디바이스가 별도로 폴링될 수 있다. 하나 이상의 파라미터 각각에 대한 범주형 값을 미리 결정된 최소 범주형 값 세트와 비교하는 것에 기초하여 분 류 번호가 하나 이상의 파라미터 각각에 대한 범주형 값에 기반하여 사용자 디바이스에 할당될 수 있다. 일부 실시예들에서, 미리 결정된 최소 범주형 값 세트는 머신 러닝 모델에 대한 사용 사례에 기초하여 복수의 파라미 터들로부터 선택되는 파라미터들에 대한 범주형 값 세트일 수 있다. 아래에는 파라미터들에 대한 예시적인 미 리 결정된 최소 범주형 값 세트를 제공하는 표가 있다. 이는 제한을 위한 것이 아니다. 선택된 파라미터들의많은 조합들은 물론 해당 파라미터들에 대한 최소 범주형 값 세트들이 있을 수 있다는 것이 이해될 수 있다. 네트워크 요소 또는 네트워크 운영자는 이러한 조합들 및 최소 범주형 값 세트들을 정의할 수 있다. 표 1"}
{"patent_id": "10-2024-7020216", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "위에서 알 수 있는 바와 같이, 표 1에서, 저용량 프로세서, 낮은 가용 메모리, 낮은 배터리 전력 및 낮은 RF 하 드웨어 능력을 갖는 사용자 디바이스의 경우, AI/ML 모델 추론을 사용자 디바이스에 전송하는 것만이 실현 가능 할 수 있다. 이는 또한 본 예에서 사용자 디바이스에서 전체 규모의 또는 부분 AI/ML 모델 훈련을 수행하는 것 이 실현 불가능할 수 있음을 나타낼 수 있다. 동작에서, 사용자 디바이스의 AI/ML 능력의 분류에 기초하여 머신 러닝 모델과 연관된 데이터가 전송될 수 있다. 생성, 훈련, 업데이트 또는 전송될 수 있는 머신 러닝 모델은 지도 학습, 비지도 학습, 준지도 학습, 강 화 학습, 딥 러닝, 전이 학습 및/또는 메타 학습을 포함하지만 이에 제한되지 않는 본 기술 분야에서 알려진 임 의의 유형의 AI/ML 기법에 기초할 수 있다. 전송될 수 있는 데이터는 사용자 디바이스의 머신 러닝 능력의 분류에 기초할 수 있다. 일부 실시예들에서, 사 용자 디바이스의 머신 러닝 능력의 분류에 기초하여 다음 중 하나가 사용자 디바이스에 전송될 수 있다. 일부 실시예들에서, 사용자 디바이스의 머신 러닝 능력의 분류가 고성능 사용자 디바이스를 나타내는 것에 기초하여 사용자 디바이스에서의 전체 규모의 훈련을 위한 훈련 데이터 및 모델 파라미터들이 전송될 수 있다. 사용자 디바이스에서의 전체 규모의 훈련은 훈련 데이터 및 모델 파라미터들을 사용하여 머신 러닝 모델을 생성하는 것 을 포함할 수 있으며, 여기서 생성하는 것은 높은 수준의 정확도를 달성하기 위해 다수의 에포크 동안 모델을 훈련시키는 것을 포함할 수 있다. 예로서, 사용자 디바이스가 높은 GPU 용량, 큰 가용 메모리, 높은 RF 하드웨 어 용량, 및 높은 배터리 전력을 갖는 랩톱이거나, 현재 충전 중인 경우, AI/ML 모델이 사용자 디바이스에서 완 전히 훈련될 수 있도록 훈련 데이터 및 모델 파라미터들이 전송될 수 있다. 일부 실시예들에서, 사용자 디바이스가 충분히 능력이 있는 것에 기초하여 가볍게 훈련된 모델, 훈련 데이터의 서브세트 및 모델 파라미터들이 사용자 디바이스에서의 경량 훈련을 위해 전송될 수 있다. 사용자 디바이스에 서의 경량 훈련은 허용 가능한 수준의 정확도를 달성하기 위해 제한된 횟수의 에포크 동안 가볍게 훈련된 모델 을 업데이트하는 것을 포함할 수 있다. 일부 실시예들에서, 사용자 디바이스가 충분히 능력이 있고/있거나 신경 네트워크가 존재하는 것에 기초하여 일 반 훈련된 모델, 훈련 데이터의 서브세트 및 모델 파라미터들이 사용자 디바이스에서의 일반 훈련된 모델의 특 정 사용 사례 기반 업데이트를 위해 사용자 디바이스에 전송될 수 있다. 예를 들어, 신경 네트워크가 사용되는 경우, 다른 작업에 대해 훈련된 일반 모델이 전이 학습을 사용하여 커스터마이즈하기 위해 사용자 디바이스에 전송될 수 있다. 일반 모델의 마지막 몇 개의 계층들은 재훈련될 수 있고 일반 모델은 특정 사용 사례에 맞게 업데이트될 수 있다. 일부 실시예들에서, 사용자 디바이스가 불충분한 자원을 갖는 것에 기초하여 완전히 훈련된 모델이 사용자 디바 이스에서의 추론을 위해 사용자 디바이스에 전송될 수 있다. 추론에 AI/ML 모델을 활용하는 것은 모델이 보지 못한 데이터에 대해 AI/ML 모델을 배포하는 것이다. 일부 실시예들에서, 모델 추론은 모델 훈련 동안 학습된 규칙들 및/또는 관계들을 실제 데이터(real world data)에 적용하는 것이다. 도 3은 본 개시의 실시예들에 따른, 통신 네트워크에서 사용자 디바이스의 머신 러닝 능력을 분류하기 위한 예 시적인 프로세스를 예시하는 예시적인 플로차트이다. 프로세스는 사용자 디바이스의 AI/ML 능력의 분류를 결정하는 것을 예시할 수 있다. 일부 실시예들에서, 사용자 디바이스의 머신 러닝 능력의 분류는 사용자 디바이스의 인공 지능 모델 훈련 용량을 나타낼 수 있다. 프로세스는 셀 또는 노드(예를 들면, gNodeB 및 eNodeB)와 같은 네트워크 요소에 의해 수행될 수 있다. 일부 실시예들에서, 사용자 디바이스의 머신 러닝 능력의 분류는 사용자 디바이스의 인공 지능 모델 훈련 용량 을 나타낼 수 있다. 사용자 디바이스의 머신 러닝 능력의 분류는 또한 사용자 디바이스의 인공 지능 모델 추론 용량을 나타낼 수 있다. 도 3에서 알 수 있는 바와 같이, 프로세스는 동작을 포함할 수 있다. 동작에서, 복수의 파라미 터들 중 하나 이상의 파라미터가 평가될 수 있다. 파라미터를 평가하는 것은 머신 러닝 모델에 대한 사용 사례 에 기초하여 복수의 파라미터들로부터 하나 이상의 파라미터를 선택하는 것을 포함할 수 있다. 사용 사례의 예 는 CSI(channel-state information) 피드백 향상, 빔 관리, 위치 결정 정확도, 수신 신호(RS) 오버헤드 감소, 로드 밸런싱, 이동성 최적화 또는 네트워크 에너지 절약을 포함할 수 있지만 이에 제한되지 않을 수 있다. 동작에서, 사용자 디바이스의 하나 이상의 파라미터 각각에 대한 범주형 값이 결정될 수 있다. 일부 실시 예들에서, 이 결정은 사용자 디바이스로부터 수신되는 사용자 디바이스 능력 정보를 파싱하는 것을 포함할 수 있다. 일부 실시예들에서, 사용자 디바이스의 하나 이상의 파라미터 중 임의의 것에 대한 범주형 값을 결정하 기 위해 사용자 디바이스가 별도로 폴링될 수 있다. 동작 내지 동작에서, 하나 이상의 파라미터 각각에 대한 범주형 값을 미리 결정된 최소 범주형 값 세 트와 비교하는 것에 기초하여 분류 번호가 하나 이상의 파라미터 각각에 대한 범주형 값에 기반하여 사용자 디 바이스에 할당될 수 있다. 일부 실시예들에서, 미리 결정된 최소 범주형 값 세트는 머신 러닝 모델에 대한 사 용 사례에 기초하여 복수의 파라미터들로부터 선택되는 파라미터들에 대한 범주형 값 세트일 수 있다. 도 4는 본 개시의 실시예들에 따른, 통신 네트워크에서 사용자 디바이스의 머신 러닝 능력을 분류하는 것에 기 초하여 머신 러닝 모델과 연관된 데이터를 전송하기 위한 예시적인 프로세스를 나타내는 예시적인 플로차 트이다. 프로세스는 사용자 디바이스의 AI/ML 능력의 분류의 결정에 따라 데이터 또는 머신 러닝 모델을 전송하는 것을 예시할 수 있다. 동작에서, 사용자 디바이스의 머신 러닝 능력의 분류가 결정될 수 있다. 일부 실시예들에서, 도 3에서의 프로세스의 일부로서 수행되는 동작 내지 동작은 동작에 포함될 수 있다. 동작(410A)에서, 사용자 디바이스의 머신 러닝 능력의 분류가 고성능 사용자 디바이스를 나타내는 것에 기초하 여 사용자 디바이스에서의 전체 규모의 훈련을 위한 훈련 데이터 및 모델 파라미터들이 전송될 수 있다. 사용 자 디바이스에서의 전체 규모의 훈련은 훈련 데이터 및 모델 파라미터들을 사용하여 머신 러닝 모델을 생성하는 것을 포함할 수 있으며, 여기서 생성하는 것은 높은 수준의 정확도를 달성하기 위해 다수의 에포크 동안 모델을 훈련시키는 것을 포함할 수 있다. 동작(410B)에서, 사용자 디바이스가 충분히 능력이 있는 것에 기초하여 가볍게 훈련된 모델, 훈련 데이터의 서 브세트 및 모델 파라미터들이 사용자 디바이스에서의 경량 훈련을 위해 전송될 수 있다. 사용자 디바이스에서 의 경량 훈련은 허용 가능한 수준의 정확도를 달성하기 위해 제한된 횟수의 에포크 동안 가볍게 훈련된 모델을 업데이트하는 것을 포함할 수 있다. 동작(410C)에서, 사용자 디바이스가 충분히 능력이 있고/있거나 신경 네트워크가 존재하는 것에 기초하여 일반 훈련된 모델, 훈련 데이터의 서브세트 및 모델 파라미터들이 사용자 디바이스에서의 일반 훈련된 모델의 특정 사용 사례 기반 업데이트를 위해 사용자 디바이스에 전송될 수 있다. 예를 들어, 신경 네트워크가 사용되는 경 우, 다른 작업에 대해 훈련된 일반 모델이 전이 학습을 사용하여 커스터마이즈하기 위해 사용자 디바이스에 전 송될 수 있다. 일반 모델의 마지막 몇 개의 계층들은 재훈련될 수 있고 일반 모델은 특정 사용 사례에 맞게 업 데이트될 수 있다. 동작(410D)에서, 사용자 디바이스가 불충분한 자원을 갖는 것에 기초하여 완전히 훈련된 모델이 사용자 디바이 스에서의 추론을 위해 사용자 디바이스에 전송될 수 있다. 추론에 AI/ML 모델을 활용하는 것은 모델이 보지 못 한 데이터에 대해 AI/ML 모델을 배포하는 것이다. 일부 실시예들에서, 모델 추론은 모델 훈련 동안 학습된 규칙들 및/또는 관계들을 실제 데이터에 적용하는 것이다. 도 5는 본 개시의 실시예들에 따른, 통신 네트워크에서 사용자 디바이스의 머신 러닝 능력을 분류하기 위한 예 시적인 개략적 예시이다. 도 5에서 알 수 있는 바와 같이, 사용자 디바이스 AI/ML 능력의 분류는 사용자 디바이스의 AI/ML 모델 훈련 용 량 및/또는 사용자 디바이스의 AI/ML 모델 추론 용량을 나타낼 수 있다. 사용자 디바이스가 적어도 어느 정도 의 AI/ML 모델 훈련 용량을 갖는 것에 기초하여, 사용자 디바이스에서의 전체 규모의 훈련을 위한 훈련 데이터 및 모델 파라미터들 또는 가볍게 훈련된 모델, 훈련 데이터의 서브세트 및 모델 파라미터들이 사용자 디바이스 에 전송될 수 있다. 사용자 디바이스가 어느 정도의 AI/ML 모델 업데이트 또는 추론 용량을 갖는 것에 기초하 여, 일반 훈련된 모델, 훈련 데이터의 서브세트, 및 사용자 디바이스에서의 일반 훈련된 모델의 특정 사용 사례 기반 업데이트를 위한 모델 파라미터들 또는 사용자 디바이스에서의 추론을 위한 완전히 훈련된 모델이 사용자 디바이스에 전송될 수 있다. 도 6은 본 개시의 실시예들에 따른, 도 1의 하나 이상의 디바이스의 예시적인 컴포넌트들의 다이어그램이다. 도 6에 도시된 바와 같이, 환경은 사용자 디바이스, 플랫폼 및 네트워크를 포함할 수 있다. 환경의 디바이스들은 유선 연결, 무선 연결, 또는 유선 연결과 무선 연결의 조합을 통해 상호 연결 될 수 있다. 실시예들에서, 네트워크 인프라스트럭처에 포함된 요소들의 기능들 중 임의의 기능은 도 6에 예시된 요소들의 임의의 조합에 의해 수행될 수 있다. 예를 들어, 실시예들에서, 사용자 디바이스는 개인 용 컴퓨팅 디바이스와 연관된 하나 이상의 기능을 수행할 수 있고, 플랫폼은 네트워크 요소들 중 임 의의 것과 연관된 하나 이상의 기능을 수행할 수 있다. 사용자 디바이스는 플랫폼과 연관된 정보를 수신, 생성, 저장, 처리 및/또는 제공할 수 있는 하나 이 상의 디바이스를 포함할 수 있다. 예를 들어, 사용자 디바이스는 컴퓨팅 디바이스(예를 들면, 데스크톱 컴퓨터, 랩톱 컴퓨터, 태블릿 컴퓨터, 핸드헬드 컴퓨터, 스마트 스피커, 서버 등), 모바일 폰(예를 들면, 스마 트폰, 라디오 전화(radiotelephone) 등), 웨어러블 디바이스(예를 들면, 스마트 안경 또는 스마트 워치), 또는 유사한 디바이스를 포함할 수 있다. 일부 구현들에서, 사용자 디바이스는 플랫폼으로부터 정보를 수 신하고/하거나 플랫폼으로 정보를 전송할 수 있다. 플랫폼은 정보를 수신, 생성, 저장, 처리 및/또는 제공할 수 있는 하나 이상의 디바이스를 포함할 수 있다. 일부 구현들에서, 플랫폼은 클라우드 서버 또는 클라우드 서버 그룹을 포함할 수 있다. 일부 구현 들에서, 플랫폼은 특정 소프트웨어 컴포넌트들이 특정 필요에 따라 스왑 인(swap in) 또는 스왑 아웃(swap out)될 수 있도록 모듈식으로 설계될 수 있다. 이에 따라, 플랫폼은 상이한 용도들에 맞게 쉽게 및/또는 신속하게 재구성될 수 있다. 일부 구현들에서, 도시된 바와 같이, 플랫폼은 클라우드 컴퓨팅 환경에서 호스팅될 수 있다. 특히, 본 명세서에 설명된 구현들은 플랫폼이 클라우드 컴퓨팅 환경에서 호스팅되는 것으로 설명하지만, 일 부 구현들에서, 플랫폼은 클라우드 기반이 아니거나(즉, 클라우드 컴퓨팅 환경 외부에서 구현될 수 있거나) 부분적으로 클라우드 기반일 수 있다. 클라우드 컴퓨팅 환경은 플랫폼을 호스팅하는 환경을 포함한다. 클라우드 컴퓨팅 환경은 최종 사용자(예를 들면, 사용자 디바이스)가 플랫폼을 호스팅하는 시스템(들) 및/또는 디바이스(들)의 물 리적 위치 및 구성에 대해 알 필요가 없는 계산, 소프트웨어, 데이터 액세스, 저장 등의 서비스들을 제공할 수 있다. 도시된 바와 같이, 클라우드 컴퓨팅 환경은 컴퓨팅 자원들의 그룹(집합적으로 \"컴퓨팅 자원들 \"이라고 지칭되고 개별적으로 \"컴퓨팅 자원\"이라고 지칭됨)을 포함할 수 있다. 컴퓨팅 자원은 하나 이상의 개인용 컴퓨터, 컴퓨팅 디바이스 클러스터, 워크스테이션 컴퓨터, 서버 디바이 스, 또는 다른 유형의 계산 및/또는 통신 디바이스를 포함한다. 일부 구현들에서, 컴퓨팅 자원은 플랫폼 을 호스팅할 수 있다. 클라우드 자원들은 컴퓨팅 자원에서 실행되는 컴퓨트 인스턴스(compute instance), 컴퓨팅 자원에서 제공되는 저장 디바이스, 컴퓨팅 자원에 의해 제공되는 데이터 전송 디 바이스 등을 포함할 수 있다. 일부 구현들에서, 컴퓨팅 자원은 유선 연결, 무선 연결 또는 유선 연결과 무선 연결의 조합을 통해 다른 컴퓨팅 자원들과 통신할 수 있다. 도 6에 추가로 도시된 바와 같이, 컴퓨팅 자원은 하나 이상의 애플리케이션(\"APP들\")(624-1), 하나 이상의 가상 머신(\"VM들\")(624-2), 가상화된 저장소(\"VS들\")(624-3), 하나 이상의 하이퍼바이저(\"HYP들\")(624-4) 등과같은 클라우드 자원 그룹을 포함한다. 애플리케이션(624-1)은 사용자 디바이스 또는 네트워크 요소에 제공되거나 이에 의해 액세스될 수 있 는 하나 이상의 소프트웨어 애플리케이션을 포함한다. 애플리케이션(624-1)은 사용자 디바이스 또는 네트 워크 요소에 소프트웨어 애플리케이션을 설치하고 실행할 필요가 없게 할 수 있다. 예를 들어, 애플리케 이션(624-1)은 플랫폼과 연관된 소프트웨어 및/또는 클라우드 컴퓨팅 환경을 통해 제공될 수 있는 임 의의 다른 소프트웨어를 포함할 수 있다. 일부 구현들에서, 하나의 애플리케이션(624-1)은 가상 머신(624-2)을 통해 하나 이상의 다른 애플리케이션(624-1)으로/으로부터 정보를 송신/수신할 수 있다. 가상 머신(624-2)은 물리적 머신과 같은 프로그램을 실행하는 머신(예를 들면, 컴퓨터)의 소프트웨어 구현을 포 함한다. 가상 머신(624-2)은, 용도 및 가상 머신(624-2)과 임의의 실제 머신의 대응 정도에 따라, 시스템 가상 머신 또는 프로세스 가상 머신일 수 있다. 시스템 가상 머신은 완전한 운영 체제(\"OS\")의 실행을 지원하는 완 전한 시스템 플랫폼을 제공할 수 있다. 프로세스 가상 머신은 단일 프로그램을 실행할 수 있고, 단일 프로세스 를 지원할 수 있다. 일부 구현들에서, 가상 머신(624-2)은 사용자(예를 들면, 사용자 디바이스)를 대신하 여 실행될 수 있고, 데이터 관리, 동기화 또는 장기간 데이터 전송과 같은 클라우드 컴퓨팅 환경의 인프라 스트럭처를 관리할 수 있다. 가상화된 저장소(624-3)는 컴퓨팅 자원의 저장 시스템들 또는 디바이스들 내에서 가상화 기법들을 사용하 는 하나 이상의 저장 시스템 및/또는 하나 이상의 디바이스를 포함한다. 일부 구현들에서, 저장 시스템의 맥락 내에서, 가상화 유형은 블록 가상화 및 파일 가상화를 포함할 수 있다. 블록 가상화란 물리적 저장소 또는 이 기종 구조에 상관없이 저장 시스템이 액세스될 수 있도록 물리적 저장소로부터 논리적 저장소를 추상화(또는 분 리)하는 것을 지칭할 수 있다. 분리는 저장 시스템의 관리자에게 관리자가 최종 사용자를 위해 저장소를 관리 하는 방법에서의 유연성을 부여할 수 있다. 파일 가상화는 파일 수준에서 액세스되는 데이터와 파일이 물리적 으로 저장되는 위치 간의 종속성을 제거할 수 있다. 이는 저장소 사용의 최적화, 서버 통합, 및/또는 무중단 파일 마이그레이션(non-disruptive file migration)의 수행을 가능하게 할 수 있다. 하이퍼바이저(624-4)는 다수의 운영 체제들(예를 들면, \"게스트 운영 체제들\")이 컴퓨팅 자원과 같은 호스 트 컴퓨터에서 동시에 실행될 수 있도록 하는 하드웨어 가상화 기법들을 제공할 수 있다. 하이퍼바이저(624- 4)는 게스트 운영 체제들에 가상 운영 플랫폼을 제공할 수 있고, 게스트 운영 체제들의 실행을 관리할 수 있다. 다양한 운영 체제들의 다수의 인스턴스들이 가상화된 하드웨어 자원들을 공유할 수 있다. 네트워크는 하나 이상의 유선 및/또는 무선 네트워크를 포함한다. 예를 들어, 네트워크는 셀룰러 네 트워크(예를 들면, 5G(fifth generation) 네트워크, LTE(long-term evolution) 네트워크, 3G(third generation) 네트워크, CDMA(code division multiple access) 네트워크 등), PLMN(public land mobile network), LAN(local area network), WAN(wide area network), MAN(metropolitan area network), 전화 네트워 크(예를 들면, PSTN(Public Switched Telephone Network)), 사설 네트워크, 애드혹(ad hoc) 네트워크, 인트라 넷, 인터넷, 광섬유 기반 네트워크 등, 및/또는 이들 또는 다른 유형의 네트워크들의 조합을 포함할 수 있다. 도 6에 도시된 디바이스들 및 네트워크들의 수 및 배열은 예로서 제공된다. 실제로, 도 6에 도시된 것보다 추 가적인 디바이스 및/또는 네트워크, 더 적은 수의 디바이스 및/또는 네트워크, 상이한 디바이스 및/또는 네트워 크, 또는 상이하게 배열된 디바이스 및/또는 네트워크가 있을 수 있다. 게다가, 도 6에 도시된 2개 이상의 디 바이스는 단일 디바이스 내에 구현될 수 있거나, 도 6에 도시된 단일 디바이스는 다수의 분산 디바이스들로서 구현될 수 있다. 추가적으로 또는 대안적으로, 환경의 디바이스 세트(예를 들면, 하나 이상의 디바이스) 는 환경의 다른 디바이스 세트에 의해 수행되는 것으로 설명된 하나 이상의 기능을 수행할 수 있다. 도 7은 본 개시의 실시예들에 따른, 도 1의 하나 이상의 디바이스의 예시적인 컴포넌트들의 다이어그램이다. 도 7은 사용자 디바이스의 예시적인 컴포넌트들의 다이어그램이다. 사용자 디바이스는 인가된 사용 자, 셀의 운영자 또는 RF 엔지니어와 연관된 디바이스에 대응할 수 있다. 사용자 디바이스는 네트워크 요 소를 통해 클라우드 플랫폼과 통신하는 데 사용될 수 있다. 도 7에 도시된 바와 같이, 사용자 디바 이스는 버스, 프로세서, 메모리, 저장 컴포넌트, 입력 컴포넌트, 출력 컴포넌트 및 통신 인터페이스를 포함할 수 있다. 버스는 사용자 디바이스의 컴포넌트들 간의 통신을 가능하게 하는 컴포넌트를 포함할 수 있다. 프로 세서는 하드웨어, 펌웨어, 또는 하드웨어와 소프트웨어의 조합으로 구현될 수 있다. 프로세서는 CPU(central processing unit), GPU(graphics processing unit), APU(accelerated processing unit), 마이크로프로세서, 마이크로컨트롤러, DSP(digital signal processor), FPGA(field-programmable gate array), ASIC(application-specific integrated circuit) 또는 다른 유형의 처리 컴포넌트일 수 있다. 일부 구현들에 서, 프로세서는 기능을 수행하도록 프로그래밍될 수 있는 하나 이상의 프로세서를 포함한다. 메모리(73 0)는 프로세서가 사용하기 위한 정보 및/또는 명령어들을 저장하는 RAM(random access memory), ROM(read only memory), 및/또는 다른 유형의 동적 또는 정적 저장 디바이스(예를 들면, 플래시 메모리, 자기 메모리 및/ 또는 광학 메모리)를 포함한다. 저장 컴포넌트는 사용자 디바이스의 작동 및 사용에 관련된 정보 및/또는 소프트웨어를 저장한다. 예를 들어, 저장 컴포넌트는 하드 디스크(예를 들면, 자기 디스크, 광학 디스크, 광자기 디스크 및/또는 솔리드 스테이트 디스크), CD(compact disc), DVD(digital versatile disc), 플로피 디스크, 카트리지, 자기 테이프 및/또는 다른 유형의 비일시적 컴퓨터 판독 가능 매체를, 대응하는 드라이브와 함께, 포함할 수 있다. 입력 컴포넌트는 사용자 디바이스가, 예컨대, 사용자 입력을 통해, 정보를 수신할 수 있게 하는 컴포 넌트(예를 들면, 터치 스크린 디스플레이, 키보드, 키패드, 마우스, 버튼, 스위치 및/또는 마이크로폰)를 포함 한다. 추가적으로 또는 대안적으로, 입력 컴포넌트는 정보를 감지하기 위한 센서(예를 들면, GPS(global positioning system) 컴포넌트, 가속도계, 자이로스코프 및/또는 액추에이터)를 포함할 수 있다. 출력 컴포넌 트는 사용자 디바이스로부터의 출력 정보를 제공하는 컴포넌트(예를 들면, 디스플레이, 스피커 및/또 는 하나 이상의 LED(light-emitting diode))를 포함한다. 통신 인터페이스는 사용자 디바이스가, 예컨대, 유선 연결, 무선 연결 또는 유선 연결과 무선 연결의 조합을 통해, 다른 디바이스들과 통신할 수 있게 하는 트랜시버 유사 컴포넌트(예를 들면, 트랜시버 및/또는 별 도의 수신기 및 송신기)를 포함한다. 통신 인터페이스는 사용자 디바이스가 다른 디바이스로부터 정 보를 수신하고/하거나 다른 디바이스에 정보를 제공할 수 있게 할 수 있다. 예를 들어, 통신 인터페이스 는 이더넷 인터페이스, 광학 인터페이스, 동축 인터페이스, 적외선 인터페이스, RF(radio frequency) 인터페이 스, USB(universal serial bus) 인터페이스, Wi-Fi 인터페이스, 셀룰러 네트워크 인터페이스 등을 포함할 수 있 다. 사용자 디바이스는 본 명세서에 설명된 하나 이상의 프로세스를 수행할 수 있다. 사용자 디바이스는 프로세서가 메모리 및/또는 저장 컴포넌트와 같은 비일시적 컴퓨터 판독 가능 매체에 저장된 소 프트웨어 명령어들을 실행하는 것에 응답하여 이러한 프로세스들을 수행할 수 있다. 컴퓨터 판독 가능 매체는 본 명세서에서 비일시적 메모리 디바이스로서 정의될 수 있다. 메모리 디바이스는 단일 물리적 저장 디바이스 내의 메모리 공간 또는 다수의 물리적 저장 디바이스들에 걸쳐 분산된 메모리 공간을 포함한다. 소프트웨어 명령어들은 다른 컴퓨터 판독 가능 매체로부터 또는 통신 인터페이스를 통해 다른 디바이스로 부터 메모리 및/또는 저장 컴포넌트 내로 판독될 수 있다. 실행될 때, 메모리 및/또는 저장 컴 포넌트에 저장된 소프트웨어 명령어들은 프로세서로 하여금 본 명세서에 설명된 하나 이상의 프로세 스를 수행하게 할 수 있다. 본 명세서에 설명된 시스템들 및/또는 방법들이 상이한 형태의 하드웨어, 펌웨어, 또는 하드웨어와 소프트웨어 의 조합으로 구현될 수 있다는 것이 명백할 것이다. 이러한 시스템들 및/또는 방법들을 구현하는 데 사용되는 실제 특수 제어 하드웨어 또는 소프트웨어 코드는 구현들을 제한하지 않는다. 따라서, 시스템들 및/또는 방법 들의 작동 및 거동은 특정 소프트웨어 코드를 참조하지 않고 본 명세서에 설명되었다 - 소프트웨어 및 하드웨어 가 본 명세서에서의 설명에 기초하여 시스템들 및/또는 방법들을 구현하도록 설계될 수 있다는 것이 이해된다 -. 해당 분야에서 전통적인 것처럼, 실시예들은 설명된 기능 또는 기능들을 수행하는 블록의 관점에서 설명되고 예 시될 수 있다. 본 명세서에서 유닛 또는 모듈 등으로 지칭될 수 있는 이러한 블록은 논리 게이트, 집적 회로, 마이크로프로세서, 마이크로컨트롤러, 메모리 회로, 수동 전자 컴포넌트, 능동 전자 컴포넌트, 광학 컴포넌트, 고정 배선 회로 등과 같은 아날로그 또는 디지털 회로에 의해 물리적으로 구현될 수 있으며 펌웨어 및 소프트웨 어에 의해 구동될 수 있다. 회로는, 예를 들어, 하나 이상의 반도체 칩에 구체화되거나 인쇄 회로 기판 등과 같은 기판 지지체 상에 구체화될 수 있다. 블록에 포함된 회로는 전용 하드웨어에 의해, 또는 프로세서(예를 들면, 하나 이상의 프로그래밍된 마이크로프로세서 및 연관된 회로)에 의해, 또는 블록의 일부 기능들을 수행하 는 전용 하드웨어와 블록의 다른 기능들을 수행하는 프로세서의 조합에 의해 구현될 수 있다. 실시예들의 각각 의 블록은 2개 이상의 상호 작용하는 개별 블록으로 물리적으로 분리될 수 있다. 마찬가지로, 실시예들의 블록 들은 더 복잡한 블록들로 물리적으로 결합될 수 있다.특징들의 특정 조합들이 청구항들에 기재되고/되거나 명세서에 개시되어 있더라도, 이러한 조합들은 가능한 구 현들의 개시를 제한하려는 의도가 아니다. 실제로, 이들 특징 중 다수는 청구항들에 구체적으로 기재되지 않고 /않거나 명세서에 구체적으로 개시되지 않은 방식으로 결합될 수 있다. 아래에 나열된 각각의 종속 청구항은 하나의 청구항에만 직접적으로 의존할 수 있지만, 가능한 구현들의 개시는 청구항 세트 내의 모든 다른 청구항 과 조합하여 각각의 종속 청구항을 포함한다. 본 명세서에 사용된 어떠한 요소, 행위 또는 지시도, 명시적으로 그러한 것으로 설명되지 않는 한, 중요하거나 필수적인 것으로 해석되어서는 안 된다. 또한, 본 명세서에서 사용되는 바와 같이, 관형사 \"한\"은 하나 이상의 항목을 포함하도록 의도되었으며, \"하나 이상\"과 상호 교환적으로 사용될 수 있다. 하나의 항목만이 의도된 경 우, \"하나\" 또는 유사한 표현(language)과 같은 용어가 사용된다. 또한, 본 명세서에서 사용되는 바와 같이, \"가지다\"(\"has,\" \"have\"), \"가지는(having)\", \"포함하다(include)\", \"포함하는(including)\" 등의 용어들은 개 방형 용어(open-ended term)인 것으로 의도된다. 게다가, \"~에 기초하여\"라는 문구는, 달리 명시적으로 언급되 지 않는 한, \"~에 적어도 부분적으로 기초하여\"를 의미하는 것으로 의도된다."}
{"patent_id": "10-2024-7020216", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 예시적인 실시예들의 특징, 장점 및 중요성은 유사한 부호가 유사한 요소를 나타내는 첨부 도면을 참 조하여 아래에서 설명될 것이다. 도 1은 본 개시에 설명된 시스템들 및/또는 방법들이 구현될 수 있는 네트워크 아키텍처의 예시적인 개략적 예 시이다. 도 2는 본 개시의 실시예들에 따른, 통신 네트워크에서 사용자 디바이스의 머신 러닝 능력을 분류하기 위한 예 시적인 프로세스를 예시하는 예시적인 플로차트이다. 도 3은 본 개시의 실시예들에 따른, 통신 네트워크에서 사용자 디바이스의 머신 러닝 능력을 분류하기 위한 예 시적인 프로세스를 예시하는 예시적인 플로차트이다. 도 4는 본 개시의 실시예들에 따른, 통신 네트워크에서 사용자 디바이스의 머신 러닝 능력을 분류하기 위한 예 시적인 프로세스를 예시하는 예시적인 플로차트이다. 도 5는 본 개시의 실시예들에 따른, 통신 네트워크에서 사용자 디바이스의 머신 러닝 능력을 분류하기 위한 예 시적인 개략적 예시이다.도 6은 본 개시의 실시예들에 따른, 도 1의 하나 이상의 디바이스의 예시적인 컴포넌트들의 다이어그램이다. 도 7은 본 개시의 실시예들에 따른, 도 1의 하나 이상의 디바이스의 예시적인 컴포넌트들의 다이어그램이다."}
