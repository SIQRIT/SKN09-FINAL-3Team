{"patent_id": "10-2009-0031934", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2010-0113382", "출원번호": "10-2009-0031934", "출원인": "한양대학교 산학협력단", "발명자": "서일홍"}}
{"patent_id": "10-2009-0031934", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "행동유발성(affordance) 확률모델의 학습방법에 있어서,로봇의 임무 수행에 필요한 행동유발성을 학습하기 위해, 상기 행동유발성별로 베이지안 네트워크를 이용하여로봇과 환경 사이의 연관성에 관한 구조를 구성하는 단계;상기 로봇으로부터 상기 행동유발성 각각의 학습데이터를 수집하는 단계; 및상기 학습데이터를 이용하여 상기 베이지안 네트워크에 기반한 상기 행동유발성에 관한 확률모델을 개별적으로학습하는 단계를 포함하는 것을 특징으로 하는 행동유발성 확률모델의 학습방법."}
{"patent_id": "10-2009-0031934", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 로봇과 환경 사이의 연관성에 관한 구조를 구성하는 단계는 상기 베이지안 네트워크의 구조를 형성하는 인지, 행동, 및 결과에 관련된 주요 변수들을 선택하는 단계를 포함하며,상기 학습데이터를 수집하는 단계는 선택된 상기 주요 변수들의 값을 수집하는 단계를 포함하며,상기 확률모델을 개별적으로 학습하는 단계는 상기 변수들의 값을 이용하여 상기 확률모델을 학습하는 단계를포함하는 것을 특징으로 하는 행동유발성 확률모델의 학습방법."}
{"patent_id": "10-2009-0031934", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "행동 유발성 확률 모델을 이용한 로봇의 행동 선택 방법에 있어서,상기 로봇으로부터 상기 행동유발성 각각의 학습데이터를 수집하는 단계; 상기 학습데이터를 이용하여 상기 베이지안 네트워크에 기반한 상기 행동유발성에 관한 확률모델을 개별적으로학습하는 단계; 및상기 행동유발성들 간의 순차적인 연결을 위한 소프트 행동-동기 스위치를 상기 행동유발성들 각각에 연결하여스킬들을 형성하는 단계를 포함하는 것을 특징으로 하는 행동 유발성 확률 모델을 이용한 로봇의 행동 선택 방법."}
{"patent_id": "10-2009-0031934", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 로봇의 행동 선택 방법은,임무 수행에 필요한 스킬을 선택하는 단계; 및상기 스킬 각각의 상기 소프트 행동-동기 스위치를 순차적으로 연결하여 소프트 행동-동기 네트워크를 형성하는단계를 더 포함하는 것을 특징으로 하는 행동 유발성 확률 모델을 이용한 로봇의 행동 선택 방법."}
{"patent_id": "10-2009-0031934", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 로봇의 행동 선택 방법은,아래 식들을 이용하여 현재 인지된 정보와 상기 행동유발성을 가지고, 상기 스킬의 행동을 평가하기 위한 2-튜플값을 산출하는 단계; 및공개특허 10-2010-0113382-3-(여기서, 여기서, zi는 인지에 연관된 변수들을 나타내고, A, ai는 행동에 연관된 변수들을 나타내며, ei는 결과에 연관된 변수를 나타내고, σ는 학습 데이터의 집합을 나타내며, π는 사전 지식(Preliminary Knowledge)을의미하며, vi는 ith 스킬의 jth 행동을 사용한 확률적 분포에 의한 최대값이고, ai*는 ith 스킬에서 값을 최대화하기 위한 jth 행동임, Ti는 2-튜플 값을 의미함)아래식을 이용하여 상기 2-튜플값에 기초하여 스킬을 선택하는 단계를 더 포함하는 것을 특징으로 하는 행동 유발성 확률 모델을 이용한 로봇의 행동 선택 방법:"}
{"patent_id": "10-2009-0031934", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 로봇의 행동 선택 방법은,아래식을 이용하여 상기 선택된 스킬에 기초하여 임무를 수행하기 위한 행동을 결정하는 단계를 더 포함하는 것을 특징으로 하는 행동 유발성 확률 모델을 이용한 로봇의 행동 선택 방법:(여기서, Ti는 2-튜플 값, 함수 Φ(·)는 선택한 2-튜플로부터 행동을 선택하는 함수임)."}
{"patent_id": "10-2009-0031934", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제3항 내지 제6항 중 어느 하나의 항에 있어서, 상기 로봇의 행동 선택 방법은,상기 베이지안 네트워크의 구조를 형성하는 인지, 행동, 및 결과에 관련된 주요 변수들을 선택하는 단계를 더포함하는 것을 특징으로 하는 행동 유발성 확률 모델을 이용한 로봇의 행동 선택 방법.명 세 서발명의 상세한 설명 기 술 분 야본 발명은 행동유발성 확률모델의 학습방법 및 이를 이용한 로봇의 행동 선택 방법에 관한 것이다. [0001] 배 경 기 술종래 인공지능은 상대적으로 잡음이나 불확실성이 배제된 비교적 간단한 환경과 미리 환경에 대한 정보를 갖고 [0002]작동하는 시스템을 고려해왔다. 그러나, 실제에 있어서는 변화하는 환경과, 불완전한 인식 및 확률적 행동 결과들로 인해, 로봇이 물체에 대해 항상 행동을 수행할 수 있는 상태에 놓여 있을 수 없다. 따라서, 로봇이 불확실공개특허 10-2010-0113382-4-한 조건 하에서 임무를 수행할 수 있는 것이 요구된다. 이를 위해서는 로봇이 합리적으로 스킬을 배우고 실행할수 있어야 하며, 또한 배운 스킬을 쉽게 재사용하고 수정할 수 있어야 한다. 그러나, 종래의 기술들은 사람이 직접 행동과 동기 간의 연관관계를 생성해야 하므로, 사람이 미리 예상하지 못 [0003]한 환경에 대해서 로봇은 적절히 대처하지 못하게 된다. 또한, 로봇에게 주어지는 임무의 대부분은 순차적인 행동을 통해 완수될 수 있는 것이 보통이다. 그러나 종래의 [0004]기술들은 이러한 순차적인 행동을 수행할 수 있는 방법을 제안하지 못하고 있다. 종래의 기술에서는 로봇에게순차적인 행동을 수행하게 하기 위해서는 순차적인 행동을 수행하기 위한 새로운 모델을 생성해야 한다. 발명의 내용 해결 하고자하는 과제따라서, 본 발명의 목적은 유사한 다양한 임무에도 재사용할 수 있고 또한 쉽게 수정 가능한 행동유발성을 생성 [0005]하는 것이다. 또한, 소프트 행동-동기 스위치를 이용하여 행동유발성을 순차적으로 배치 및 연결함으로써 별도의 모델을 생성하지 않고도 순차적인 행동을 요하는 임무를 수행하는 것이다. 과제 해결수단상기 목적은 본 발명에 따라, 행동유발성(affordance) 확률모델의 생성방법에 있어서, 로봇의 임무 수행에 필요 [0006]한 행동유발성을 학습하기 위해, 상기 행동유발성별로 베이지안 네트워크를 이용하여 로봇과 환경 사이의 연관성에 관한 구조를 구성하는 단계; 상기 로봇으로부터 상기 행동유발성 각각의 학습데이터를 수집하는 단계; 및상기 학습데이터를 이용하여 상기 베이지안 네트워크에 기반한 상기 행동유발성에 관한 확률모델을 개별적으로생성하는 단계를 포함하는 것을 특징으로 하는 행동유발성 확률모델의 학습방법에 의해 달성될 수 있다. 상기 로봇과 환경 사이의 연관성에 관한 구조를 구성하는 단계는 상기 베이지안 네트워크의 구조를 형성하는 인 [0007]지, 행동, 및 결과에 관련된 주요 변수들을 선택하는 단계를 포함하며, 상기 학습데이터를 수집하는 단계는 선택된 상기 주요 변수들의 값을 수집하는 단계를 포함하며, 상기 확률모델을 개별적으로 생성하는 단계는 상기변수들의 값을 이용하여 상기 확률모델을 학습하는 단계를 포함할 수 있다. 한편, 상기 목적은 본 발명에 따라, 행동 유발성 확률 모델을 이용한 로봇의 행동 선택 방법에 있어서, 상기 로 [0008]봇으로부터 상기 행동유발성 각각의 학습데이터를 수집하는 단계; 상기 학습데이터를 이용하여 상기 베이지안네트워크에 기반한 상기 행동유발성에 관한 확률모델을 개별적으로 생성하는 단계; 및 상기 행동유발성들 간의순차적인 연결을 위한 소프트 행동-동기 스위치를 상기 행동유발성들 각각에 연결하여 스킬들을 형성하는 단계를 더 포함하는 것을 특징으로 하는 행동 유발성 확률 모델을 이용한 로봇의 행동 선택 방법에 의해서도 달성될수 있다. 또한, 임무 수행에 필요한 스킬을 선택하는 단계; 상기 스킬 각각의 상기 소프트 행동-동기 스위치를 순차적으 [0009]로 연결하여 소프트 행동-동기 네트워크를 형성하는 단계를 더 포함할 수 있다. 아울러, 아래 식들을 이용하여 현재 인지된 정보와 상기 행동유발성을 가지고, 상기 스킬의 행동을 평가하기 위 [0010]한 2-튜플값을 산출하는 단계; 및[0011][0012](여기서, 여기서, zi는 인지에 연관된 변수들을 나타내고, A, ai는 행동에 연관된 변수들을 나타내며, ei는 결과 [0013]공개특허 10-2010-0113382-5-에 연관된 변수를 나타내고, σ는 학습 데이터의 집합을 나타내며, π는 사전 지식(Preliminary Knowledge)을의미하며, vi는 ith 스킬의 jth 행동을 사용한 확률적 분포에 의한 최대값이고, ai*는 ith 스킬에서 값을 최대화하기 위한 jth 행동임, Ti는 2-튜플 값을 의미함)아래식을 이용하여 상기 2-튜플값에 기초하여 스킬을 선택하는 단계를 더 포함할 수 있다: [0014][0015]또한, 아래식을 이용하여 상기 선택된 스킬에 기초하여 임무를 수행하기 위한 행동을 결정하는 단계를 더 포함 [0016]할 수 있다:[0017](여기서, Ti는 2-튜플 값, 함수 Φ(·)는 선택한 2-튜플로부터 행동을 선택하는 함수임) [0018]상기 베이지안 네트워크의 구조를 형성하는 인지, 행동, 및 결과에 관련된 주요 변수들을 선택하는 단계를 더 [0019]포함할 수 있다. 효 과이상 설명한 바와 같이, 본 발명에 따르면, 학습 데이터를 이용하여 확률 모델을 학습하고, 이를 이용해 임무를 [0020]수행할 수 있으며, 임무 수행을 위한 스킬 학습을 쉽게 할 수 있다. 또한, 유사한 다양한 임무에도 재사용할 수있고 또한 쉽게 수정 가능한 행동유발성을 생성할 수 있다. 또한, 사람이 직접 임무 수행을 위한 스킬을 프로그래밍할 수 있다. 또한, 불확실한 환경, 부정확한 인지, 불확실한 결과 하에서 행동을 선택하는 것이 가능하다.또한, 소프트 행동-동기 스위치를 이용하여 행동유발성을 순차적으로 배치 및 연결함으로써 별도의 모델을 생성하지 않고도 학습된 스킬의 다양한 조합을 통해 다양한 임무를 수행할 수 있다. 발명의 실시를 위한 구체적인 내용'스킬(skill)'이라는 용어는 어떤 일을 할 수 있는 능력, 특히 학습을 통해 얻어진 능력을 의미한다. 로봇이 임 [0021]무를 수행하기 위해서는 이러한 스킬을 학습해야 하며, 학습된 스킬들을 쉽게 재사용하거나 수정할 수 있어야한다. 이러한 '스킬'을 학습하기 위해, 본 발명에서는 베이지안 네트워크에 기반한 확률 모델을 학습하는 방법을 제안 [0022]한다.스킬에 대한 베이지안 네트워크는 행동유발성(affordance)으로 간주될 수 있으며, 여기서 행동유발성은 로봇의 [0023]행동 능력과 센싱 능력을 통하여 로봇 자신과 환경 사이에서 생성되는 연관성이라 말할 수 있다. 로봇은 이러한연관성을 바탕으로 행동을 수행하게 된다. 본 발명은 베이지안 네트워크를 이용하여 행동유발성을 모델링한다. 베이지안 네트워크를 이용한 모델링을 위해 [0024]서는 우선 구조 설계(즉, 변수들 간의 연관성)와 그 구조들 간의 확률 모델을 생성해야 한다.본 발명에서는 베이지안 네트워크의 구조를 인지-행동-결과로 정의하여 로봇과 환경 사이의 연관성을 생성하며, [0025]학습 데이터를 통해 각 연관성들의 확률 모델을 생성한다.베이지안 네트워크는 양적인 확률 정보에 의해 평가되는 각 노드의 방향성을 갖는 그래프이다. 도메인에서 직접 [0026]적인 영향을 받는 것을 결정하기가 일반적으로 쉽기 때문이다. 베이지안 네트워크의 토폴리지가 일단 생성되면,부모가 주어졌을 때 각 변수(Variable)에 대한 조건부 확률 분포를 표현할 수 있다. 토폴로지와 조건부 분포의조합은 모든 변수들의 완전 결합 분포(Full Joint Distribution)를 규정하는데 충분하다. 베이지안 네트워크는몇 개의 데이터가 없는 경우에도 쉽게 다룰 수 있다. 또한, 원인관계를 학습하는데 사용될 수도 있고, 불확실하공개특허 10-2010-0113382-6-거나 부정확한 지식에 기반한 문제를 풀 수도 있어, 매우 효율적이다. 본 발명에서는 베이지안 네트워크를 생성하기 위해, 우선 각 스킬에 연관된 주요 변수들을 선택한다. 이때, 변 [0027]수들은 인식, 행동, 결과로 구성된다. 본 발명에서는 각 스킬에 대해 개별적으로 베이지안 네트워크를 생성함으로써 베이지안 네트워크의 더 단순한 분포를 생성할 수 있다. 인공 지능 로봇은 무작위로 나열된 행동유발성을 가지고 임무를 수행하기 위해 상황적응적 행동을 선택할 수 있 [0028]을지도 모른다. 그러나, 대부분의 임무는 순차적인 행동을 요하며, 무작위로 나열된 행동유발성을 사용하여 임무를 수행하는 것은 현실적으로 어려움이 있다. 본 발명은 새로운 모델을 학습할 필요 없이도 주어진 임무를 수행하기 위해 행동유발성을 순차적으로 나열하는 [0029]방법으로서, 소프트 행동-동기 스위치(Soft Behavior Motivation Switch)를 제안한다. 행동유발성과 소프트 행동-동기 스위치를 결합한 것을 스킬이라고 정의하며, 이는 로봇의 행동을 합리적으로 제어하는데 사용될 수 있다. 이러한 스킬들의 소프트 행동-동기 스위치를 연결하여 구축된 것이 소프트 행동-동기 네트워크이며, 로봇의 임 [0030]무 수행에 사용된다. 소프트 행동-동기 네트워크는 전체적으로 연결된 유한상태기계(Finite State Machine)와같이 행동할 수 있다. 따라서, 본 발명에 따르면, 로봇은 불확실한 환경, 불완전한 인식, 및/또는 확률적 행동결과로 인한 불확실한 조건 하에서도 순차적인 행동을 요하는 다양한 임무들을 수행할 수 있다. 도 1은 전술한 본 발명의 베이지안 네트워크에 기반한 행동유발성과, 이를 이용한 로봇의 행동 선택 방법을 개 [0031]념적으로 도시한 것이다. 이하, 도면을 참조하여 본 발명의 구체적인 실시예들에 대해 설명하기로 한다. [0032] [0033]베이지안 행동 유발성 모델의 학습 [0034]전술한 바와 같이, 행동 유발성은 로봇의 행동 능력과 센싱 능력을 통하여 로봇 자신과 환경 사이에서 생성되는 [0035]연관성이라 말할 수 있다. 행동 유발성을 생성하기 위해, 본 발명에서는 인지, 행동, 및 결과의 변수들 간의 관계를 정의하는데 베이지안 네트워크의 확률 모델을 사용한다.이는 완전 결합 분포를 구하는 것이 현실적으로 어렵기 때문에, 더 단순한 형태의 곱으로 결합 분포를 표현하기 [0036]위해 베이지안 네트워크를 이용하는 것이다. 본 발명에 따른 베이지안 네트워크의 구조는 두 가지 가정에 기초한다. 첫째, 많은 양의 학습데이터로부터 이미 [0037]그 구조가 알려져 있다고 가정한다. 둘째, 인지, 행동, 결과의 모든 변수들은 조건부 독립적이라고 가정한다.즉, 결과에 연관된 ei는 인지에 연관된 zi와 행동에 연관된 변수 A에만 의존적이다. 도 2는 위와 같은 가정에 의해 완전 결합 분포를 구하기 위한 베이지안 네트워크의 구조의 일 예를 도시한 것이 [0038]다. 도 2에서 (a)는 완전 결합 분포에 대한 베이지안 네트워크이고, (b)는 행동 유발성에 대한 베이지안 네트워크를 나타낸다. 도 2에서, 완전 결합 분포는 다음과 같이 정의될 수 있다. [0039]수학식 1P(z1,..., zn,A,e1,...,en│σ,π) [0040]여기서, zi는 인지에 연관된 변수들을 나타내고, A는 행동에 연관된 변수들을 나타내며, ei는 결과에 연관된 변 [0041]수를 나타내고, σ는 학습 데이터의 집합을 나타내며, π는 사전 지식(Preliminary Knowledge)을 의미한다. 수학식 1의 완전 결합 분포식은 도 2의 (b)의 행동 유발성에 대한 베이지안 네트워크로서 다음과 같이 단순화될 [0042]수 있다. 수학식 2P(Z,A,E│σ,π) = P(Z│σ,π)ㆍP(A│Z,σ,π)ㆍP(E│A,Z,σ,π) [0043]공개특허 10-2010-0113382-7- = P(Z│σ,π)ㆍP(A│σ,π)ㆍP(E│A,Z,σ,π) [0044]여기서, Z={z1,..., zn) 이고, E={e1,...,en)으로 정의된다. 수학식 2를 가지고 완전 결합 분포를 산출하기 위해 [0045]서는 각 확률적 모델이 학습되어야 한다. 여기서, 각 스킬로 표현되는 베이지안 네트워크를 행동유발성이라 간주하고, 행동유발성은 유사한 임무에 재사 [0046]용할 수 있도록 한다. 이를 위해, 본 발명에서는 각 스킬의 학습 데이터를 개별적으로 수집하고, 수집한 학습데이터를 이용하여 각 스킬에 대한 행동유발성을 생성한다. 도 3은 불연속 변수와 연속 변수로 구성된 하이브리드 베이지안 네트워크의 일 예를 도시한 것이다. 도 3을 참 [0047]조하면, 행동에 연관된 변수 A는 불연속 변수로 정의되며, Z와 E의 일부는 불연속 변수이고, 일부는 연속 변수이다. 이러한 베이지안 네트워크의 확률 분포는 선형 분포를 이용하여 적절히 구성할 수 있다. 가장 일반적인 선형 분 [0048]포는 선형 가우시안 분포이며, 여기서 자식은 부모의 값에 따라 선형적으로 변화하는 평균 μ의 가우시안 분포를 가지며, 표준편차 σ는 다음과 같이 정의된다.수학식 3[0049]여기서, ei는 결과에 연관된 변수이고, zi는 인지에 연관된 변수이며, A는 행동에 연관된 변수이다. 불연속 부모 [0050]노드 A의 분포는 정확한 계산에 의해 다루어진다. 즉, 각 분포는 행동 변수의 모든 값 ai에 의해 P(ei│A =ai,zi,σ,π)로 정해진다. 이들 파라미터들은 다음과 같이 정의된다.수학식 4[0051]도 4는 위의 수학식 3 및 4에 기초하여 행동에 연관된 변수 A의 값 F1에 속하는 선형 가우시안 분포의 일 예를 [0052]도시한 것이다. 여기서, A=F1, a=1, b=10, σ=10인 것으로 설정하였다. 본 발명에 따른 행동 유발성은 사용자가 로봇의 베이지안 네트워크 구조인 주요 변수들을 선택하고, 로봇으로부 [0053]터 이에 관한 학습 데이터만 수집되면 스킬에 대한 행동 유발성을 생성할 수 있으므로, 스킬의 생성이 매우 편리하다. 또한, 주요 변수의 추가, 삭제, 변경 등을 통해 스킬을 수정하거나 새로운 스킬을 생성하는 것이 매우용이하다는 장점을 갖는다.소프트 행동-동기 스위치를 이용한 스킬 생성 [0054]로봇은 무작위로 나열된 행동유발성을 가지고 임무를 수행하기 위해서 상황-적응적 행동을 선택할 수 있을 것이 [0055]다. 그러나, 대부분의 임무는 순차적인 행동이 필요하다. 따라서, 무작위로 나열된 행동유발성을 이용하여 임무를 수행하는 것은 매우 어려운 일이다. 그러한 임무를 수행하기 위해서, 로봇은 순차적인 행동을 수행하기 위한모델을 학습해야한다. 본 발명에서는 추가적인 확률적 모델을 학습하지 않고도 임무를 수행하는 방법을 제안한다. 이를 위해, 임무를 수행하기 위한 행동 유발성을 나열하기 위해 소프트 행동-동기 스위치를 사용한다. 도 5는 소프트 행동-동기 스위치를 개념적으로 도시한 것이고, 도 6은 행동 유발성과 소프트 행동-동기 스위치 [0056]를 결합하여 만들어진 스킬을 개념적으로 도시한 것이며, 도 7은 로봇의 임무 수행을 위한 소프트 행동-동기 네트워크를 개념적으로 도시한 것이다. 행동유발성을 순차적으로 배열하기 위해, 본 발명에서는 도 6과 같이, 행동유발성과 소프트 행동-동기 스위치를 [0057]결합한다. 또한, 임무 수행을 위해 도 7에 도시된 바와 같이, 스킬의 소프트 행동-동기 스위치들을 연결하여 소공개특허 10-2010-0113382-8-프트 행동-동기 네트워크를 구축한다. 도 8은 완전히 결합된 유한상태기계의 일예로서, (a)는 완전히 연결된 유한상태기계의 상태 전이를 도시한 것 [0058]이고, (b)는 현존하는 상태와 추가되는 상태 사이의 관계를 형성하는 일 예를 도시한 것이다. 소프트 행동-동기 네트워크는 도 8의 (a)와 같이, 완전히 결합된 유한상태기계(Finite State Machine)와 같이 [0059]스킬들 간에 자유롭게 전이할 수 있다. 완전히 결합된 유한상태기계는 도 8의 (b)에 도시된 바와 같이, 상태가추가되는 경우 현존하는 상태와 추가되는 상태 사이에 모든 관계를 형성해야 한다. 그러나, 본 발명의 소프트행동-동기 네트워크를 이용하면, 추가적으로 새로운 상태와 기존 상태의 관계를 생성하지 않고도 완전히 연결된유한상태기계처럼 동작할 수 있다. 베이지안 행동 유발성 모델을 가진 행동-동기 기반 행동선택방법 [0060]로봇은 임무를 합리적으로 수행하기 위해 스킬을 학습하고 수행해야 한다. 이를 위해, 본 발명은 소프트 행동- [0061]동기 네트워크를 구성하는 방법을 제안한다. 로봇은 소프트 행동-동기 네트워크에 기초하여 현재 인지된 정보에 기초하여 각 스킬의 행동을 평가하기 위한 [0062]2-튜플(tuples)을 산출한다. 2-튜플은 다음과 같이 정의된다. [0063]수학식 5[0064]여기서, vi는 ith 스킬의 jth 행동을 사용한 확률적 분포에 의한 최대값이고, ai*는 ith 스킬에서 값을 최대화하기 [0065]위한 jth 행동이다. 수학식 5를 사용하여 스킬의 2-튜플을 산출하기 위해서는, 도 7에 도시된 행동 유발성 모델에 기반하여 현재 인지된 정보의 확률 분포를 산출해야 한다. 각 행동의 확률 값은 베이지안 추론에 의한 행동유발성에 속하는 완전 결합 분포를 사용하여 산출한다. 행동유발성을 이용한 각 행동의 확률 값은 다음과 같이산출된다.수학식 6[0066]여기서, 스킬의 값을 최대화하는 2-튜플을 얻을 수 있다. 이렇게 얻은 2-튜플은 조정기(arbiter)로 전송된다. [0067]조정기는 현재 인지된 정보하에서 가장 적합한 행동을 선택하기 위해 2-튜플의 vi값을 정규화하고, 아래와 같이정규화된 값을 이용하여 하나의 행동을 선택하게 된다. 수학식 7[0068]조정기는 선택된 viN에 대응하는 2-튜플 Ti를 선택할 수 있다. 행동은 다음 식과 같이 선택한 2-튜플 Ti를 이용 [0069]하여 선택된다.수학식 8[0070]공개특허 10-2010-0113382-9-여기서, 함수 Φ(·)는 선택한 2-튜플로부터 행동을 선택한다. 인공지능 로봇은 행동유발성과 소프트 행동-동기 [0071]스위치로 이루어진 스킬을 사용하여 임무를 수행할 행동을 선택한다. 더 나아가, 로봇은 현재 상황에 따라 지식을 논리적으로 재구성하거나 점진적으로 증가시킬 수 있어야 한다. 본 발명에서는 각 스킬의 베이지안 네트워크에 기초하여 독립적으로 행동 유발성을 구성한다. 따라서, 점진적인 [0072]학습 도중에 다른 스킬에 영향을 받거나 예상치 못한 일의 발생으로 인해 영향을 받지 않는다. 본 발명은 학습데이터를 수집하여 새로운 확률 모델을 생성하거나 기존의 확률 모델을 재구성함으로써 지식을 증가시킬 수 있다. 실험 결과 [0073]본 발명의 성능을 시험하기 위해, 4족 강아지 로봇인 제노보를 대상으로, '목표 물체 찾기(Search a target [0074]object)', '목표 물체에 접근하기(Approach a target object)', '목표 물체의 냄새맡기(Sniff a targetobject)', 및 '목표 물체 걷어차기(Knick a target object)\"의 스킬을 사용하여 두 가지 임무를 시험하였다.우선, 로봇은 '목표 물체 찾기', '목표 물체에 접근하기', 및 '목표 물체의 냄새맡기'의 스킬을 이용하여 목표 [0075]물체의 냄새를 맡는 임무를 수행하였다. 그리고, '목표 물체의 냄새맡기'의 스킬을 '목표 물체 걷어차기'로 변경함으로써 목표 물체를 걷어차는 임무를 수행하였다. 로봇은 이 임무를 수행하기 전에 먼저 각 행동유발성을 학습하였다. [0076]'목표 물체 찾기' 스킬은 목표 물체를 인지하지 전의 상황, 목표 물체를 찾기 위해 좌로 회전, 우로 회전, [0077]전진, 후진 등의 행동, 및 목표 물체를 인지한 후의 상황 간의 관계에 의해 형성된다. '목표 물체에 접근하기' 스킬은 목표 물체에 접근하기 전의 상황, 로봇이 목표 물체에 접근하기 위해 전지, 후 [0078]진 등의 행동, 및 목표 물체에 접근한 후의 상황 간의 관계에 의해 형성된다. '목표 물체의 냄새맡기' 스킬은 로봇이 목표 물체의 냄새를 맡기 전의 상황, 냄새를 맡는 행동, 및 냄새를 맡은 [0079]후의 상황 간의 관계에 의해 형성된다. '목표 물체 걷어차기' 스킬은 로봇의 목표 물체를 걷어차기 전의 상황, 목표 물체를 걷어차는 행동, 및 목표 물 [0080]체를 걷어찬 후의 상황 간의 관계에 의해 형성된다.도 9는 행동 유발성을 학습하기 위한 학습 데이터를 수집하는 실험의 일 예를 도시한 것으로서, (a)는 목표 물 [0081]체 찾기, (b)는 목표 물체에 다가가기 스킬의 그림을 나타낸다.본 실험에서는 도 9에 도시된 바와 같이, 조이스틱을 사용하여 각 스킬에 대한 실험 데이터를 수집하였다. 이와 [0082]같이, 조이스틱이나 리모콘 등을 사용하여 로봇의 행동을 제어할 수 있으므로, 사용자가 스킬 학습을 쉽게 할수 있다. 도 10은 \"목표 물체 찾기\" 스킬의 베이지안 네트워크의 구성의 일 예를 나타낸다. [0083]베이지안 네트워크의 각 변수는 다음과 같이 정의된다. [0084]수학식 9[0085]여기서, A는 li와 ri를 포함하는 행동의 집합, ri는 i 시간의 좌로 회전과 i 시간의 우로 회전, zs는 SIFT에 의 [0086]해 행동을 수행하기 전에 목표 물체와 그 레퍼런스 모델 사이에 매칭된 점의 정규화 값, zd 및 za는 각각 행동을수행하기 전에 로봇과 목표 물체 사이의 거리 및 각도, es는 SIFT에 의해 행동을 수행한 후 목표 물체와 그 레퍼런스 모델 사이의 매칭된 점의 정규화 값, ed 및 ea는 각각 행동 수행 후 로봇과 목표 물체 사이의 거리 및 각공개특허 10-2010-0113382-10-도를 의미한다. '목표 물체 찾기' 스킬의 완전 결합 분포는 도 10과 같은 베이지안 네트워크를 이용하여 산출된다. [0087]등식은 다음과 같이 정의된다. [0088]수학식 10[0089]행동 유발성의 확률 모델은 수집된 학습 데이터를 사용하여 산출된다. 이렇게 산출된 행동유발성 확률 모델은 [0090]소프트 행동-동기 스위치를 결합하여 스킬을 구성한다. 이외에 '목표 물체에 접근하기', '목표 물체의냄새맡기', 및 '목표 물체 걷어차기\"의 스킬도 전술한 방법을 이용하여 산출할 수 있다. 도 11은 '목표 물체 찾기', '목표 물체에 접근하기', '목표 물체의 냄새맡기'의 스킬을 이용하여 임무를 수행하 [0091]는 일 예를 도시한 것이다. 도 11을 참조하면, 임무를 수행하기 위해, 로봇은 스킬의 소프트 행동-동기 스위치들을 연결하여 소프트 행동-동기 네트워크를 형성한다. 도 12는 완전히 결합된 유한상태기계와 같이 동작하는 본 발명에 따른 로봇의 동작을 보여주는 그림이다. 도 12 [0092]를 참조하면, 목표 물체가 부분적으로 가려지거나 위치를 변경한 경우 등 동적으로 변화하는 실제 환경하에서도완전히 결합된 유한상태기계와 같이 동작하였으며, 그 임무 성공률이 95% 이상을 기록하였다. 도 13은 유사한 임무에 행동 유발성 모델을 사용하는 일 예를 나타내는 그림이다. 도 13의 (a)와 같이 \"딸기 [0093]차\" 박스를 이용하여 행동 유발성 모델을 생성하였으나, 도 13의 (b)와 같이, 다양한 물체(예컨대, 버터 와플박스 또는 컵 등)에 대해서도 임무를 수행할 수 있었다.결과적으로, 학습된 행동유발성을 동일한 역할을 수행하는 다양한 임무에 재사용할 수 있음을 확인할 수 [0094]있었다.도 14는 전술한 본 발명에 따른 행동유발성 확률 모델을 생성 방법 및 이를 이용한 로봇의 행동 선택 방법을 정 [0095]리한 흐름도이다.행동유발성 확률 모델을 학습하기 위해 우선, 베이지안 네트워크의 구조를 구성한다(S10). 베이지안 네트워크의 [0096]구조는 도 2에 도시된 바와 같이, 인지-행동-결과의 구조를 가지며, 인지-행동-결과의 주요변수들을 선택한다. 이렇게 주요 변수들이 선택되면, 도 9와 같이 로봇으로부터 이들 변수에 대한 학습데이터를 수집한다(S11). [0097]학습데이터가 수집되면, 이를 이용하여 행동유발성의 완전 결합 분포를 산출하기 위해 확률 모델을 학습한다 [0098](S12). 전술한 바와 같이, 완전 결합 분포를 산출하는 것이 어렵기 때문에 베이지안 네트워크에 기초한 확률 모델을 학습하여 완전 결합 분포를 산출하게 된다.유의할 점은 이러한 베이지안 네트워크 구조, 학습 데이터의 수집, 및 확률 모델 학습은 행동 유발성 별로 개별 [0099]적으로 이루어진다는 점이다. 학습 데이터의 수집이 많을수록, 확률 모델의 생성이 많을수록 로봇은 다양한 임무를 수행할 수 있는 능력이 커질 것이다. 이와 같이, 로봇을 학습시키는 사람의 능력에 따라 로봇의 능력이 달라질 수 있다. 이렇게 생성된 행동 유발성은 로봇의 임무 수행에 사용된다. 다만, 대부분의 임무는 순차적인 행동을 요하는 경 [0100]우가 많으므로, 본 발명에서는 이러한 임무를 수행하기 위해, 행동 유발성에 소프트 행동-동기 스위치를 결합시켜 하나의 스킬을 생성한다(S13). 생성한 행동 유발성이 많을수록 스킬의 수도 많아질 것이다. 로봇에게 임무에 필요한 행동 유발성을 순차적으로 나열하여 입력하면, 로봇은 소프트 행동-동기 스위치를 행동 [0101]유발성에 연결하여 스킬을 생성하고(도 6 참조), 각 스킬의 소프트 행동-동기 스위치를 연결하여 도 7과 같이소프트 행동-동기 네트워크를 형성한다(S14). 로봇은 수학식 5 및 6을 이용하여 현재 인지된 정보와 행동 유발성을 가지고 각 스킬의 2-튜플 값을 산출한다 [0102](S15).이렇게 산출된 2-튜플 값에 기초하여 수학식 7을 이용하여 스킬을 선택한다(S16). [0103]이렇게 선택된 스킬에 기반하여 임무를 수행하기 위해 수학식 8을 이용하여 가장 적합한 행동을 선택한다(S17). [0104]그리고, 선택한 행동을 함으로써 임무를 수행하게 된다. 즉, 이러한 스킬 및 행동 선택에 따라 순차적인 행동을 [0105]공개특허 10-2010-0113382-11-통해 임무를 수행할 수 있게 된다. 로봇은 사용자가 원하는 임무를 학습된 스킬의 다양한 조합을 통해 수행할 수 있으며, 스킬의 조합을 통해 생성 [0106]된 새로운 임무는 유사한 임무에 사용될 수 있을 것이다. 이와 같이, 본 발명은 소프트 행동-동기 스위치를 이용하여 간단한 방법으로 로봇이 완전히 결합된 유한상태기 [0107]계와 동일한 역할을 수행할 수 있도록 하였으며, 불확실하고 변화하는 동적인 환경에서 강인한 성능을 가질 수있다. 또한, 전술한 행동유발성 확률 모델의 생성방법 또는 학습방법과 이를 이용하여 로봇의 행동을 선택하는 방법은 [0108]소프트웨어 프로그램으로 구현 가능하며, 본 발명은 다양한 컴퓨터로 구현되는 동작을 수행하기 위한 프로그램명령을 포함하는 컴퓨터 판독 가능 매체를 포함한다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다.컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magneticmedia), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 비록 본 발명의 몇몇 실시예들이 도시되고 설명되었지만, 본 발명이 속하는 기술분야의 통상의 지식을 가진 당 [0109]업자라면 본 발명의 원칙이나 정신에서 벗어나지 않으면서 본 실시예를 변형할 수 있음을 알 수 있을 것이다.발명의 범위는 첨부된 청구항과 그 균등물에 의해 정해질 것이다.도면의 간단한 설명도 1은 본 발명의 베이지안 네트워크에 기반한 행동유발성과, 이를 이용한 로봇의 행동 선택 방법을 개념적으로 [0110]도시한 것이다. 도 2는 본 발명의 일 실시예에 따라 완전 결합 분포를 구하기 위한 베이지안 네트워크의 구조의 일 예를 도시한 [0111]것이다.도 3은 본 발명의 일 실시예에 따라 불연속 변수와 연속 변수로 구성된 하이브리드 베이지안 네트워크의 일 예 [0112]를 도시한 것이다. 도 4는 수학식 3 및 4에 기초하여 행동에 연관된 변수 A의 값 F1에 속하는 선형 가우시안 분포의 일 예를 도시 [0113]한 것이다. 도 5는 본 발명의 일 실시예에 따른 소프트 행동-동기 스위치를 개념적으로 도시한 것이고, 도 6은 행동 유발성 [0114]과 소프트 행동-동기 스위치를 결합하여 만들어진 스킬을 개념적으로 도시한 것이다.도 7은 본 발명의 일 실시예에 따른 로봇의 임무 수행을 위한 소프트 행동-동기 네트워크를 개념적으로 도시한 [0115]것이다. 도 8은 본 발명의 일 실시예에 따른 완전히 결합된 유한상태기계의 일예로서, (a)는 완전히 연결된 유한상태기 [0116]계의 상태 전이를 도시한 것이고, (b)는 현존하는 상태와 추가되는 상태 사이의 관계를 형성하는 일 예를 도시한 것이다. 도 9는 본 발명의 일 실시예에 따라 행동 유발성을 학습하기 위한 학습 데이터를 수집하는 실험의 일 예를 도시 [0117]한 것으로서, (a)는 '목표 물체 찾기', (b)는 '목표 물체에 다가가기' 스킬의 그림을 나타낸다.도 10은 '목표 물체 찾기' 스킬의 베이지안 네트워크의 구성의 일 예를 나타낸다. [0118]도 11은 '목표 물체 찾기', '목표 물체에 접근하기', '목표 물체의 냄새맡기'의 스킬을 이용하여 임무를 수행하 [0119]는 일 예를 도시한 것이다. 도 12는 완전히 결합된 유한상태기계와 같이 동작하는 본 발명에 따른 로봇의 동작을 보여주는 그림이다. [0120]도 13은 본 발명에 따른 행동 유발성 모델을 유사한 임무에 사용하는 일 예를 나타내는 그림이다. [0121]공개특허 10-2010-0113382-12-도 14는 본 발명에 따른 행동 유발성 모델 학습 방법 및 이를 이용한 로봇의 행동 선택 방법의 일 실시예를 정 [0122]리한 흐름도이다.도면 도면1 도면2공개특허 10-2010-0113382-13- 도면3 도면4 도면5공개특허 10-2010-0113382-14- 도면6공개특허 10-2010-0113382-15- 도면7공개특허 10-2010-0113382-16- 도면8 도면9공개특허 10-2010-0113382-17- 도면10공개특허 10-2010-0113382-18- 도면11공개특허 10-2010-0113382-19- 도면12 도면13공개특허 10-2010-0113382-20- 도면14공개특허 10-2010-0113382-21-"}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 행동유발성 확률모델의 학습방법 및 이를 이용한 로봇의 행동 선택 방법에 관한 것이다. 본 발명에 따 른 행동유발성(affordance) 확률모델의 생성방법은 로봇의 임무 수행에 필요한 행동유발성을 학습하기 위해, 상 기 행동유발성별로 베이지안 네트워크를 이용하여 로봇과 환경 사이의 연관성에 관한 구조를 구성하는 단계; 상 기 로봇으로부터 상기 행동유발성 각각의 학습데이터를 수집하는 단계; 및 상기 학습데이터를 이용하여 상기 베 이지안 네트워크에 기반한 상기 행동유발성에 관한 확률모델을 개별적으로 생성하는 단계를 포함한다. 그리하여, 유사한 다양한 임무에도 재사용할 수 있고 또한 쉽게 수정 가능한 행동유발성을 생성할 수 있다. 또한, 소프트 행동-동기 스위치를 이용하여 행동유발성을 순차적으로 배치 및 연결함으로써 별도의 모델을 생성 하지 않고도 순차적인 행동을 요하는 임무를 수행할 수 있다."}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 행동유발성 확률모델의 학습방법 및 이를 이용한 로봇의 행동 선택 방법에 관한 것이다."}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래 인공지능은 상대적으로 잡음이나 불확실성이 배제된 비교적 간단한 환경과 미리 환경에 대한 정보를 갖고 작동하는 시스템을 고려해왔다. 그러나, 실제에 있어서는 변화하는 환경과, 불완전한 인식 및 확률적 행동 결과 들로 인해, 로봇이 물체에 대해 항상 행동을 수행할 수 있는 상태에 놓여 있을 수 없다. 따라서, 로봇이 불확실한 조건 하에서 임무를 수행할 수 있는 것이 요구된다. 이를 위해서는 로봇이 합리적으로 스킬을 배우고 실행할 수 있어야 하며, 또한 배운 스킬을 쉽게 재사용하고 수정할 수 있어야 한다. 그러나, 종래의 기술들은 사람이 직접 행동과 동기 간의 연관관계를 생성해야 하므로, 사람이 미리 예상하지 못 한 환경에 대해서 로봇은 적절히 대처하지 못하게 된다. 또한, 로봇에게 주어지는 임무의 대부분은 순차적인 행동을 통해 완수될 수 있는 것이 보통이다. 그러나 종래의 기술들은 이러한 순차적인 행동을 수행할 수 있는 방법을 제안하지 못하고 있다. 종래의 기술에서는 로봇에게 순차적인 행동을 수행하게 하기 위해서는 순차적인 행동을 수행하기 위한 새로운 모델을 생성해야 한다."}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용 해결 하고자하는 과제 따라서, 본 발명의 목적은 유사한 다양한 임무에도 재사용할 수 있고 또한 쉽게 수정 가능한 행동유발성을 생성 하는 것이다. 또한, 소프트 행동-동기 스위치를 이용하여 행동유발성을 순차적으로 배치 및 연결함으로써 별도 의 모델을 생성하지 않고도 순차적인 행동을 요하는 임무를 수행하는 것이다. 과제 해결수단 상기 목적은 본 발명에 따라, 행동유발성(affordance) 확률모델의 생성방법에 있어서, 로봇의 임무 수행에 필요 한 행동유발성을 학습하기 위해, 상기 행동유발성별로 베이지안 네트워크를 이용하여 로봇과 환경 사이의 연관 성에 관한 구조를 구성하는 단계; 상기 로봇으로부터 상기 행동유발성 각각의 학습데이터를 수집하는 단계; 및 상기 학습데이터를 이용하여 상기 베이지안 네트워크에 기반한 상기 행동유발성에 관한 확률모델을 개별적으로 생성하는 단계를 포함하는 것을 특징으로 하는 행동유발성 확률모델의 학습방법에 의해 달성될 수 있다. 상기 로봇과 환경 사이의 연관성에 관한 구조를 구성하는 단계는 상기 베이지안 네트워크의 구조를 형성하는 인 지, 행동, 및 결과에 관련된 주요 변수들을 선택하는 단계를 포함하며, 상기 학습데이터를 수집하는 단계는 선 택된 상기 주요 변수들의 값을 수집하는 단계를 포함하며, 상기 확률모델을 개별적으로 생성하는 단계는 상기 변수들의 값을 이용하여 상기 확률모델을 학습하는 단계를 포함할 수 있다. 한편, 상기 목적은 본 발명에 따라, 행동 유발성 확률 모델을 이용한 로봇의 행동 선택 방법에 있어서, 상기 로 봇으로부터 상기 행동유발성 각각의 학습데이터를 수집하는 단계; 상기 학습데이터를 이용하여 상기 베이지안 네트워크에 기반한 상기 행동유발성에 관한 확률모델을 개별적으로 생성하는 단계; 및 상기 행동유발성들 간의 순차적인 연결을 위한 소프트 행동-동기 스위치를 상기 행동유발성들 각각에 연결하여 스킬들을 형성하는 단계 를 더 포함하는 것을 특징으로 하는 행동 유발성 확률 모델을 이용한 로봇의 행동 선택 방법에 의해서도 달성될 수 있다. 또한, 임무 수행에 필요한 스킬을 선택하는 단계; 상기 스킬 각각의 상기 소프트 행동-동기 스위치를 순차적으 로 연결하여 소프트 행동-동기 네트워크를 형성하는 단계를 더 포함할 수 있다. 아울러, 아래 식들을 이용하여 현재 인지된 정보와 상기 행동유발성을 가지고, 상기 스킬의 행동을 평가하기 위 한 2-튜플값을 산출하는 단계; 및"}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 3, "content": "(여기서, 여기서, zi는 인지에 연관된 변수들을 나타내고, A, ai는 행동에 연관된 변수들을 나타내며, ei는 결과 에 연관된 변수를 나타내고, σ는 학습 데이터의 집합을 나타내며, π는 사전 지식(Preliminary Knowledge)을 의미하며, vi는 ith 스킬의 jth 행동을 사용한 확률적 분포에 의한 최대값이고, ai*는 ith 스킬에서 값을 최대화하 기 위한 jth 행동임, Ti는 2-튜플 값을 의미함) 아래식을 이용하여 상기 2-튜플값에 기초하여 스킬을 선택하는 단계를 더 포함할 수 있다:"}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 4, "content": "또한, 아래식을 이용하여 상기 선택된 스킬에 기초하여 임무를 수행하기 위한 행동을 결정하는 단계를 더 포함 할 수 있다:"}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 5, "content": "(여기서, Ti는 2-튜플 값, 함수 Φ(·)는 선택한 2-튜플로부터 행동을 선택하는 함수임) 상기 베이지안 네트워크의 구조를 형성하는 인지, 행동, 및 결과에 관련된 주요 변수들을 선택하는 단계를 더 포함할 수 있다. 효 과 이상 설명한 바와 같이, 본 발명에 따르면, 학습 데이터를 이용하여 확률 모델을 학습하고, 이를 이용해 임무를 수행할 수 있으며, 임무 수행을 위한 스킬 학습을 쉽게 할 수 있다. 또한, 유사한 다양한 임무에도 재사용할 수 있고 또한 쉽게 수정 가능한 행동유발성을 생성할 수 있다. 또한, 사람이 직접 임무 수행을 위한 스킬을 프로그 래밍할 수 있다. 또한, 불확실한 환경, 부정확한 인지, 불확실한 결과 하에서 행동을 선택하는 것이 가능하다. 또한, 소프트 행동-동기 스위치를 이용하여 행동유발성을 순차적으로 배치 및 연결함으로써 별도의 모델을 생성 하지 않고도 학습된 스킬의 다양한 조합을 통해 다양한 임무를 수행할 수 있다. 발명의 실시를 위한 구체적인 내용 '스킬(skill)'이라는 용어는 어떤 일을 할 수 있는 능력, 특히 학습을 통해 얻어진 능력을 의미한다. 로봇이 임 무를 수행하기 위해서는 이러한 스킬을 학습해야 하며, 학습된 스킬들을 쉽게 재사용하거나 수정할 수 있어야 한다. 이러한 '스킬'을 학습하기 위해, 본 발명에서는 베이지안 네트워크에 기반한 확률 모델을 학습하는 방법을 제안 한다. 스킬에 대한 베이지안 네트워크는 행동유발성(affordance)으로 간주될 수 있으며, 여기서 행동유발성은 로봇의 행동 능력과 센싱 능력을 통하여 로봇 자신과 환경 사이에서 생성되는 연관성이라 말할 수 있다. 로봇은 이러한 연관성을 바탕으로 행동을 수행하게 된다. 본 발명은 베이지안 네트워크를 이용하여 행동유발성을 모델링한다. 베이지안 네트워크를 이용한 모델링을 위해 서는 우선 구조 설계(즉, 변수들 간의 연관성)와 그 구조들 간의 확률 모델을 생성해야 한다. 본 발명에서는 베이지안 네트워크의 구조를 인지-행동-결과로 정의하여 로봇과 환경 사이의 연관성을 생성하며, 학습 데이터를 통해 각 연관성들의 확률 모델을 생성한다. 베이지안 네트워크는 양적인 확률 정보에 의해 평가되는 각 노드의 방향성을 갖는 그래프이다. 도메인에서 직접 적인 영향을 받는 것을 결정하기가 일반적으로 쉽기 때문이다. 베이지안 네트워크의 토폴리지가 일단 생성되면, 부모가 주어졌을 때 각 변수(Variable)에 대한 조건부 확률 분포를 표현할 수 있다. 토폴로지와 조건부 분포의 조합은 모든 변수들의 완전 결합 분포(Full Joint Distribution)를 규정하는데 충분하다. 베이지안 네트워크는 몇 개의 데이터가 없는 경우에도 쉽게 다룰 수 있다. 또한, 원인관계를 학습하는데 사용될 수도 있고, 불확실하거나 부정확한 지식에 기반한 문제를 풀 수도 있어, 매우 효율적이다. 본 발명에서는 베이지안 네트워크를 생성하기 위해, 우선 각 스킬에 연관된 주요 변수들을 선택한다. 이때, 변 수들은 인식, 행동, 결과로 구성된다. 본 발명에서는 각 스킬에 대해 개별적으로 베이지안 네트워크를 생성함으 로써 베이지안 네트워크의 더 단순한 분포를 생성할 수 있다. 인공 지능 로봇은 무작위로 나열된 행동유발성을 가지고 임무를 수행하기 위해 상황적응적 행동을 선택할 수 있 을지도 모른다. 그러나, 대부분의 임무는 순차적인 행동을 요하며, 무작위로 나열된 행동유발성을 사용하여 임 무를 수행하는 것은 현실적으로 어려움이 있다. 본 발명은 새로운 모델을 학습할 필요 없이도 주어진 임무를 수행하기 위해 행동유발성을 순차적으로 나열하는 방법으로서, 소프트 행동-동기 스위치(Soft Behavior Motivation Switch)를 제안한다. 행동유발성과 소프트 행 동-동기 스위치를 결합한 것을 스킬이라고 정의하며, 이는 로봇의 행동을 합리적으로 제어하는데 사용될 수 있 다. 이러한 스킬들의 소프트 행동-동기 스위치를 연결하여 구축된 것이 소프트 행동-동기 네트워크이며, 로봇의 임 무 수행에 사용된다. 소프트 행동-동기 네트워크는 전체적으로 연결된 유한상태기계(Finite State Machine)와 같이 행동할 수 있다. 따라서, 본 발명에 따르면, 로봇은 불확실한 환경, 불완전한 인식, 및/또는 확률적 행동 결과로 인한 불확실한 조건 하에서도 순차적인 행동을 요하는 다양한 임무들을 수행할 수 있다. 도 1은 전술한 본 발명의 베이지안 네트워크에 기반한 행동유발성과, 이를 이용한 로봇의 행동 선택 방법을 개 념적으로 도시한 것이다. 이하, 도면을 참조하여 본 발명의 구체적인 실시예들에 대해 설명하기로 한다."}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 6, "content": "베이지안 행동 유발성 모델의 학습 전술한 바와 같이, 행동 유발성은 로봇의 행동 능력과 센싱 능력을 통하여 로봇 자신과 환경 사이에서 생성되는 연관성이라 말할 수 있다. 행동 유발성을 생성하기 위해, 본 발명에서는 인지, 행동, 및 결과의 변수들 간의 관 계를 정의하는데 베이지안 네트워크의 확률 모델을 사용한다. 이는 완전 결합 분포를 구하는 것이 현실적으로 어렵기 때문에, 더 단순한 형태의 곱으로 결합 분포를 표현하기 위해 베이지안 네트워크를 이용하는 것이다. 본 발명에 따른 베이지안 네트워크의 구조는 두 가지 가정에 기초한다. 첫째, 많은 양의 학습데이터로부터 이미 그 구조가 알려져 있다고 가정한다. 둘째, 인지, 행동, 결과의 모든 변수들은 조건부 독립적이라고 가정한다. 즉, 결과에 연관된 ei는 인지에 연관된 zi와 행동에 연관된 변수 A에만 의존적이다. 도 2는 위와 같은 가정에 의해 완전 결합 분포를 구하기 위한 베이지안 네트워크의 구조의 일 예를 도시한 것이다. 도 2에서 (a)는 완전 결합 분포에 대한 베이지안 네트워크이고, (b)는 행동 유발성에 대한 베이지안 네트워 크를 나타낸다. 도 2에서, 완전 결합 분포는 다음과 같이 정의될 수 있다. 수학식 1 P(z1,..., zn,A,e1,...,en│σ,π) 여기서, zi는 인지에 연관된 변수들을 나타내고, A는 행동에 연관된 변수들을 나타내며, ei는 결과에 연관된 변 수를 나타내고, σ는 학습 데이터의 집합을 나타내며, π는 사전 지식(Preliminary Knowledge)을 의미한다. 수학식 1의 완전 결합 분포식은 도 2의 (b)의 행동 유발성에 대한 베이지안 네트워크로서 다음과 같이 단순화될 수 있다. 수학식 2 P(Z,A,E│σ,π) = P(Z│σ,π)ㆍP(A│Z,σ,π)ㆍP(E│A,Z,σ,π) = P(Z│σ,π)ㆍP(A│σ,π)ㆍP(E│A,Z,σ,π) 여기서, Z={z1,..., zn) 이고, E={e1,...,en)으로 정의된다. 수학식 2를 가지고 완전 결합 분포를 산출하기 위해 서는 각 확률적 모델이 학습되어야 한다. 여기서, 각 스킬로 표현되는 베이지안 네트워크를 행동유발성이라 간주하고, 행동유발성은 유사한 임무에 재사 용할 수 있도록 한다. 이를 위해, 본 발명에서는 각 스킬의 학습 데이터를 개별적으로 수집하고, 수집한 학습데 이터를 이용하여 각 스킬에 대한 행동유발성을 생성한다. 도 3은 불연속 변수와 연속 변수로 구성된 하이브리드 베이지안 네트워크의 일 예를 도시한 것이다. 도 3을 참 조하면, 행동에 연관된 변수 A는 불연속 변수로 정의되며, Z와 E의 일부는 불연속 변수이고, 일부는 연속 변수 이다. 이러한 베이지안 네트워크의 확률 분포는 선형 분포를 이용하여 적절히 구성할 수 있다. 가장 일반적인 선형 분 포는 선형 가우시안 분포이며, 여기서 자식은 부모의 값에 따라 선형적으로 변화하는 평균 μ의 가우시안 분포 를 가지며, 표준편차 σ는 다음과 같이 정의된다. 수학식 3"}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 7, "content": "여기서, ei는 결과에 연관된 변수이고, zi는 인지에 연관된 변수이며, A는 행동에 연관된 변수이다. 불연속 부모 노드 A의 분포는 정확한 계산에 의해 다루어진다. 즉, 각 분포는 행동 변수의 모든 값 ai에 의해 P(ei│A = ai,zi,σ,π)로 정해진다. 이들 파라미터들은 다음과 같이 정의된다. 수학식 4"}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "배경기술", "item": 8, "content": "도 4는 위의 수학식 3 및 4에 기초하여 행동에 연관된 변수 A의 값 F1에 속하는 선형 가우시안 분포의 일 예를 도시한 것이다. 여기서, A=F1, a=1, b=10, σ=10인 것으로 설정하였다. 본 발명에 따른 행동 유발성은 사용자가 로봇의 베이지안 네트워크 구조인 주요 변수들을 선택하고, 로봇으로부 터 이에 관한 학습 데이터만 수집되면 스킬에 대한 행동 유발성을 생성할 수 있으므로, 스킬의 생성이 매우 편 리하다. 또한, 주요 변수의 추가, 삭제, 변경 등을 통해 스킬을 수정하거나 새로운 스킬을 생성하는 것이 매우 용이하다는 장점을 갖는다. 소프트 행동-동기 스위치를 이용한 스킬 생성 로봇은 무작위로 나열된 행동유발성을 가지고 임무를 수행하기 위해서 상황-적응적 행동을 선택할 수 있을 것이다. 그러나, 대부분의 임무는 순차적인 행동이 필요하다. 따라서, 무작위로 나열된 행동유발성을 이용하여 임무 를 수행하는 것은 매우 어려운 일이다. 그러한 임무를 수행하기 위해서, 로봇은 순차적인 행동을 수행하기 위한 모델을 학습해야한다. 본 발명에서는 추가적인 확률적 모델을 학습하지 않고도 임무를 수행하는 방법을 제안한 다. 이를 위해, 임무를 수행하기 위한 행동 유발성을 나열하기 위해 소프트 행동-동기 스위치를 사용한다. 도 5는 소프트 행동-동기 스위치를 개념적으로 도시한 것이고, 도 6은 행동 유발성과 소프트 행동-동기 스위치 를 결합하여 만들어진 스킬을 개념적으로 도시한 것이며, 도 7은 로봇의 임무 수행을 위한 소프트 행동-동기 네 트워크를 개념적으로 도시한 것이다. 행동유발성을 순차적으로 배열하기 위해, 본 발명에서는 도 6과 같이, 행동유발성과 소프트 행동-동기 스위치를 결합한다. 또한, 임무 수행을 위해 도 7에 도시된 바와 같이, 스킬의 소프트 행동-동기 스위치들을 연결하여 소프트 행동-동기 네트워크를 구축한다. 도 8은 완전히 결합된 유한상태기계의 일예로서, (a)는 완전히 연결된 유한상태기계의 상태 전이를 도시한 것 이고, (b)는 현존하는 상태와 추가되는 상태 사이의 관계를 형성하는 일 예를 도시한 것이다. 소프트 행동-동기 네트워크는 도 8의 (a)와 같이, 완전히 결합된 유한상태기계(Finite State Machine)와 같이 스킬들 간에 자유롭게 전이할 수 있다. 완전히 결합된 유한상태기계는 도 8의 (b)에 도시된 바와 같이, 상태가 추가되는 경우 현존하는 상태와 추가되는 상태 사이에 모든 관계를 형성해야 한다. 그러나, 본 발명의 소프트 행동-동기 네트워크를 이용하면, 추가적으로 새로운 상태와 기존 상태의 관계를 생성하지 않고도 완전히 연결된 유한상태기계처럼 동작할 수 있다. 베이지안 행동 유발성 모델을 가진 행동-동기 기반 행동선택방법 로봇은 임무를 합리적으로 수행하기 위해 스킬을 학습하고 수행해야 한다. 이를 위해, 본 발명은 소프트 행동- 동기 네트워크를 구성하는 방법을 제안한다. 로봇은 소프트 행동-동기 네트워크에 기초하여 현재 인지된 정보에 기초하여 각 스킬의 행동을 평가하기 위한 2-튜플(tuples)을 산출한다. 2-튜플은 다음과 같이 정의된다. 수학식 5"}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 9, "content": "여기서, vi는 ith 스킬의 jth 행동을 사용한 확률적 분포에 의한 최대값이고, ai*는 ith 스킬에서 값을 최대화하기 위한 jth 행동이다. 수학식 5를 사용하여 스킬의 2-튜플을 산출하기 위해서는, 도 7에 도시된 행동 유발성 모델 에 기반하여 현재 인지된 정보의 확률 분포를 산출해야 한다. 각 행동의 확률 값은 베이지안 추론에 의한 행동 유발성에 속하는 완전 결합 분포를 사용하여 산출한다. 행동유발성을 이용한 각 행동의 확률 값은 다음과 같이 산출된다. 수학식 6"}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 10, "content": "여기서, 스킬의 값을 최대화하는 2-튜플을 얻을 수 있다. 이렇게 얻은 2-튜플은 조정기(arbiter)로 전송된다. 조정기는 현재 인지된 정보하에서 가장 적합한 행동을 선택하기 위해 2-튜플의 vi값을 정규화하고, 아래와 같이 정규화된 값을 이용하여 하나의 행동을 선택하게 된다. 수학식 7"}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 11, "content": "조정기는 선택된 viN에 대응하는 2-튜플 Ti를 선택할 수 있다. 행동은 다음 식과 같이 선택한 2-튜플 Ti를 이용 하여 선택된다. 수학식 8 여기서, 함수 Φ(·)는 선택한 2-튜플로부터 행동을 선택한다. 인공지능 로봇은 행동유발성과 소프트 행동-동기 스위치로 이루어진 스킬을 사용하여 임무를 수행할 행동을 선택한다. 더 나아가, 로봇은 현재 상황에 따라 지식 을 논리적으로 재구성하거나 점진적으로 증가시킬 수 있어야 한다. 본 발명에서는 각 스킬의 베이지안 네트워크에 기초하여 독립적으로 행동 유발성을 구성한다. 따라서, 점진적인 학습 도중에 다른 스킬에 영향을 받거나 예상치 못한 일의 발생으로 인해 영향을 받지 않는다. 본 발명은 학습 데이터를 수집하여 새로운 확률 모델을 생성하거나 기존의 확률 모델을 재구성함으로써 지식을 증가시킬 수 있 다. 실험 결과 본 발명의 성능을 시험하기 위해, 4족 강아지 로봇인 제노보를 대상으로, '목표 물체 찾기(Search a target object)', '목표 물체에 접근하기(Approach a target object)', '목표 물체의 냄새맡기(Sniff a target object)', 및 '목표 물체 걷어차기(Knick a target object)\"의 스킬을 사용하여 두 가지 임무를 시험하였다. 우선, 로봇은 '목표 물체 찾기', '목표 물체에 접근하기', 및 '목표 물체의 냄새맡기'의 스킬을 이용하여 목표 물체의 냄새를 맡는 임무를 수행하였다. 그리고, '목표 물체의 냄새맡기'의 스킬을 '목표 물체 걷어차기'로 변 경함으로써 목표 물체를 걷어차는 임무를 수행하였다. 로봇은 이 임무를 수행하기 전에 먼저 각 행동유발성을 학습하였다. '목표 물체 찾기' 스킬은 목표 물체를 인지하지 전의 상황, 목표 물체를 찾기 위해 좌로 회전, 우로 회전, 전진, 후진 등의 행동, 및 목표 물체를 인지한 후의 상황 간의 관계에 의해 형성된다. '목표 물체에 접근하기' 스킬은 목표 물체에 접근하기 전의 상황, 로봇이 목표 물체에 접근하기 위해 전지, 후 진 등의 행동, 및 목표 물체에 접근한 후의 상황 간의 관계에 의해 형성된다. '목표 물체의 냄새맡기' 스킬은 로봇이 목표 물체의 냄새를 맡기 전의 상황, 냄새를 맡는 행동, 및 냄새를 맡은 후의 상황 간의 관계에 의해 형성된다. '목표 물체 걷어차기' 스킬은 로봇의 목표 물체를 걷어차기 전의 상황, 목표 물체를 걷어차는 행동, 및 목표 물 체를 걷어찬 후의 상황 간의 관계에 의해 형성된다. 도 9는 행동 유발성을 학습하기 위한 학습 데이터를 수집하는 실험의 일 예를 도시한 것으로서, (a)는 목표 물 체 찾기, (b)는 목표 물체에 다가가기 스킬의 그림을 나타낸다. 본 실험에서는 도 9에 도시된 바와 같이, 조이스틱을 사용하여 각 스킬에 대한 실험 데이터를 수집하였다. 이와 같이, 조이스틱이나 리모콘 등을 사용하여 로봇의 행동을 제어할 수 있으므로, 사용자가 스킬 학습을 쉽게 할 수 있다. 도 10은 \"목표 물체 찾기\" 스킬의 베이지안 네트워크의 구성의 일 예를 나타낸다. 베이지안 네트워크의 각 변수는 다음과 같이 정의된다. 수학식 9"}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 12, "content": "여기서, A는 li와 ri를 포함하는 행동의 집합, ri는 i 시간의 좌로 회전과 i 시간의 우로 회전, zs는 SIFT에 의 해 행동을 수행하기 전에 목표 물체와 그 레퍼런스 모델 사이에 매칭된 점의 정규화 값, zd 및 za는 각각 행동을 수행하기 전에 로봇과 목표 물체 사이의 거리 및 각도, es는 SIFT에 의해 행동을 수행한 후 목표 물체와 그 레 퍼런스 모델 사이의 매칭된 점의 정규화 값, ed 및 ea는 각각 행동 수행 후 로봇과 목표 물체 사이의 거리 및 각도를 의미한다. '목표 물체 찾기' 스킬의 완전 결합 분포는 도 10과 같은 베이지안 네트워크를 이용하여 산출된다. 등식은 다음과 같이 정의된다. 수학식 10"}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 13, "content": "행동 유발성의 확률 모델은 수집된 학습 데이터를 사용하여 산출된다. 이렇게 산출된 행동유발성 확률 모델은 소프트 행동-동기 스위치를 결합하여 스킬을 구성한다. 이외에 '목표 물체에 접근하기', '목표 물체의 냄새맡기', 및 '목표 물체 걷어차기\"의 스킬도 전술한 방법을 이용하여 산출할 수 있다. 도 11은 '목표 물체 찾기', '목표 물체에 접근하기', '목표 물체의 냄새맡기'의 스킬을 이용하여 임무를 수행하 는 일 예를 도시한 것이다. 도 11을 참조하면, 임무를 수행하기 위해, 로봇은 스킬의 소프트 행동-동기 스위치 들을 연결하여 소프트 행동-동기 네트워크를 형성한다. 도 12는 완전히 결합된 유한상태기계와 같이 동작하는 본 발명에 따른 로봇의 동작을 보여주는 그림이다. 도 12 를 참조하면, 목표 물체가 부분적으로 가려지거나 위치를 변경한 경우 등 동적으로 변화하는 실제 환경하에서도 완전히 결합된 유한상태기계와 같이 동작하였으며, 그 임무 성공률이 95% 이상을 기록하였다. 도 13은 유사한 임무에 행동 유발성 모델을 사용하는 일 예를 나타내는 그림이다. 도 13의 (a)와 같이 \"딸기 차\" 박스를 이용하여 행동 유발성 모델을 생성하였으나, 도 13의 (b)와 같이, 다양한 물체(예컨대, 버터 와플 박스 또는 컵 등)에 대해서도 임무를 수행할 수 있었다. 결과적으로, 학습된 행동유발성을 동일한 역할을 수행하는 다양한 임무에 재사용할 수 있음을 확인할 수 있었다. 도 14는 전술한 본 발명에 따른 행동유발성 확률 모델을 생성 방법 및 이를 이용한 로봇의 행동 선택 방법을 정 리한 흐름도이다. 행동유발성 확률 모델을 학습하기 위해 우선, 베이지안 네트워크의 구조를 구성한다(S10). 베이지안 네트워크의 구조는 도 2에 도시된 바와 같이, 인지-행동-결과의 구조를 가지며, 인지-행동-결과의 주요변수들을 선택한다. 이렇게 주요 변수들이 선택되면, 도 9와 같이 로봇으로부터 이들 변수에 대한 학습데이터를 수집한다(S11). 학습데이터가 수집되면, 이를 이용하여 행동유발성의 완전 결합 분포를 산출하기 위해 확률 모델을 학습한다 (S12). 전술한 바와 같이, 완전 결합 분포를 산출하는 것이 어렵기 때문에 베이지안 네트워크에 기초한 확률 모 델을 학습하여 완전 결합 분포를 산출하게 된다. 유의할 점은 이러한 베이지안 네트워크 구조, 학습 데이터의 수집, 및 확률 모델 학습은 행동 유발성 별로 개별 적으로 이루어진다는 점이다. 학습 데이터의 수집이 많을수록, 확률 모델의 생성이 많을수록 로봇은 다양한 임 무를 수행할 수 있는 능력이 커질 것이다. 이와 같이, 로봇을 학습시키는 사람의 능력에 따라 로봇의 능력이 달 라질 수 있다. 이렇게 생성된 행동 유발성은 로봇의 임무 수행에 사용된다. 다만, 대부분의 임무는 순차적인 행동을 요하는 경 우가 많으므로, 본 발명에서는 이러한 임무를 수행하기 위해, 행동 유발성에 소프트 행동-동기 스위치를 결합시 켜 하나의 스킬을 생성한다(S13). 생성한 행동 유발성이 많을수록 스킬의 수도 많아질 것이다. 로봇에게 임무에 필요한 행동 유발성을 순차적으로 나열하여 입력하면, 로봇은 소프트 행동-동기 스위치를 행동 유발성에 연결하여 스킬을 생성하고(도 6 참조), 각 스킬의 소프트 행동-동기 스위치를 연결하여 도 7과 같이 소프트 행동-동기 네트워크를 형성한다(S14). 로봇은 수학식 5 및 6을 이용하여 현재 인지된 정보와 행동 유발성을 가지고 각 스킬의 2-튜플 값을 산출한다 (S15). 이렇게 산출된 2-튜플 값에 기초하여 수학식 7을 이용하여 스킬을 선택한다(S16). 이렇게 선택된 스킬에 기반하여 임무를 수행하기 위해 수학식 8을 이용하여 가장 적합한 행동을 선택한다(S17). 그리고, 선택한 행동을 함으로써 임무를 수행하게 된다. 즉, 이러한 스킬 및 행동 선택에 따라 순차적인 행동을 통해 임무를 수행할 수 있게 된다. 로봇은 사용자가 원하는 임무를 학습된 스킬의 다양한 조합을 통해 수행할 수 있으며, 스킬의 조합을 통해 생성 된 새로운 임무는 유사한 임무에 사용될 수 있을 것이다. 이와 같이, 본 발명은 소프트 행동-동기 스위치를 이용하여 간단한 방법으로 로봇이 완전히 결합된 유한상태기 계와 동일한 역할을 수행할 수 있도록 하였으며, 불확실하고 변화하는 동적인 환경에서 강인한 성능을 가질 수 있다. 또한, 전술한 행동유발성 확률 모델의 생성방법 또는 학습방법과 이를 이용하여 로봇의 행동을 선택하는 방법은 소프트웨어 프로그램으로 구현 가능하며, 본 발명은 다양한 컴퓨터로 구현되는 동작을 수행하기 위한 프로그램 명령을 포함하는 컴퓨터 판독 가능 매체를 포함한다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파 일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체는 프로그램 명령은 본 발명을 위하 여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행 하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포 함한다."}
{"patent_id": "10-2009-0031934", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 14, "content": "비록 본 발명의 몇몇 실시예들이 도시되고 설명되었지만, 본 발명이 속하는 기술분야의 통상의 지식을 가진 당 업자라면 본 발명의 원칙이나 정신에서 벗어나지 않으면서 본 실시예를 변형할 수 있음을 알 수 있을 것이다. 발명의 범위는 첨부된 청구항과 그 균등물에 의해 정해질 것이다."}
