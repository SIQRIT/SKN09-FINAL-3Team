{"patent_id": "10-2020-0118500", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0036210", "출원번호": "10-2020-0118500", "발명의 명칭": "영상의 음질을 향상시키는 디바이스 및 방법", "출원인": "삼성전자주식회사", "발명자": "카주크 제이쿱"}}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디바이스가 영상의 음질을 향상시키는 방법에 있어서,영상을 획득하는 단계;상기 획득한 영상으로부터 음향(sound) 및 이미지(image)를 획득하는 단계;상기 획득한 이미지로부터 적어도 하나의 음원(sound source)을 나타내는 음원 이미지를 획득하는 단계;상기 획득한 음향으로부터, 상기 적어도 하나의 음원에 대응하는 적어도 하나의 유닛 음향 데이터를 획득하는단계;기 설정된 음향-이미지 매칭 모델을 적용하여, 상기 적어도 하나의 음원 이미지 및 상기 적어도 하나의 유닛 음향 데이터를 각각 매칭하는 단계;상기 음원 이미지로부터 상기 적어도 하나의 음원의 움직임을 추적하는 단계; 및상기 추적된 음원의 움직임에 따라 상기 유닛 음향 데이터의 음량(loudness)을 개별적으로 조정하는 단계;를 포함하고,상기 음향-이미지 매칭 모델은 특정 음원의 이미지와 상기 특정 음원이 발생시키는 음향 간의 매칭 정보를 포함하는, 방법."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 영상을 획득하는 단계는,상기 디바이스에 포함된 입력부를 통해 영상을 획득하는 것을 포함하고,상기 입력부는 음향(sound)을 획득하는 마이크 및 이미지(image)를 획득하는 카메라를 포함하는, 방법."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 영상을 획득하는 단계는,상기 디바이스에 포함된 입력부 및 상기 디바이스 외부의 보조 입력부를 통해 영상을 획득하는 것을 포함하고,상기 입력부는 음향(sound)을 획득하는 마이크 및 이미지(image)를 획득하는 카메라를 포함하고,상기 보조 입력부는 추가적인 음향을 획득하는 보조 마이크를 포함하는, 방법."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 획득한 음향으로부터, 상기 적어도 하나의 음원에 대응하는 적어도 하나의 유닛 음향 데이터를 획득하는단계는,상기 음향을 진폭, 주파수, 위상, 파형 및 스펙트럼에 따라 적어도 하나 의 유닛 음향 데이터로 분리하는 것을포함하고,상기 진폭, 주파수, 위상, 파형 및 스펙트럼이 동일한 두 개 이상의 유닛 음향 데이터들이 존재하는 경우, 상기음원 이미지를 이용하여 상기 두 개 이상의 유닛 음향 데이터를 각각의 유닛 음향 데이터로 분리하는 것을 포함하는, 방법.공개특허 10-2022-0036210-3-청구항 5 제1항에 있어서,상기 기 설정된 음향-이미지 매칭 모델을 적용하여, 상기 적어도 하나 의 음원 이미지 및 상기 적어도 하나의유닛 음향 데이터를 각각 매칭하는 단계는,상기 음원 이미지에서 획득한 정보를 추가로 이용하여 상기 적어도 하나 의 음원 이미지 및 상기 적어도 하나의유닛 음향 데이터를 각각 매칭하는 것을 포함하는, 방법."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 음원 이미지로부터 상기 적어도 하나의 음원의 움직임을 추적하는 단계는, 상기 음원 이미지의 상태 변화를 통해 해당 음원의 움직임을 추적하는 것을 포함하는, 방법."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 음원 이미지로부터 상기 적어도 하나의 음원의 움직임을 추적하는 단계는, 가속도계(accelerometer), 자이로스코프(gyroscope) 및 지자기계(magnetometer)를 포함하는 모션 센서로부터 획득된 디바이스의 움직임 정보를이용하여, 상기 음원 이미지의 상태 변화를 통해 해당 음원의 움직임을 추적하는 것을 포함하는, 방법."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 추적된 음원의 움직임에 따라 상기 유닛 음향 데이터의 음량을 개별적으로 조정하는 단계는,각각의 유닛 음향 데이터의 전체 실행 시간의 음량 곡선을 획득하는 단계;상기 각각의 유닛 음향 데이터에 대해 수행할 조정 정보를 포함하는 음량 보정 곡선을 획득하는 단계; 및상기 음량 보정 곡선을 기반으로 상기 각각의 유닛 음향 데이터의 음량을 개별적으로 조정하는 단계를포함하는, 방법."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 음량이 개별적으로 조정된 유닛 음향 데이터로부터 출력 음향을 획득하는 단계; 및상기 출력 음향 및 상기 이미지로부터 출력 영상을 획득하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 음량이 개별적으로 조정된 유닛 음향 데이터로부터 출력 음향을 획득하는 단계는,상기 유닛 음향 데이터를 두 개 이상의 채널로 분류하여 렌더링하고, 멀티 채널을 갖는 출력 음향을 획득하는것을 포함하는, 방법."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "영상의 음질을 향상시키는 디바이스에 있어서,영상을 획득하는 입력부;출력 영상을 출력하는 출력부;공개특허 10-2022-0036210-4-하나 이상의 명령어들(instructions)을 포함하는 프로그램을 저장하는 메모리; 및상기 메모리에 저장된 하나 이상의 명령어들을 실행하는 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는,상기 입력부를 제어함으로써, 영상을 획득하고,상기 획득한 영상으로부터 음향(sound) 및 이미지(image)를 획득하고,상기 획득한 이미지로부터 적어도 하나의 음원(sound source)을 나타내는 음원 이미지를 획득하고,상기 획득한 음향으로부터, 상기 적어도 하나의 음원에 대응하는 적어도 하나의 유닛 음향 데이터를 획득하고,기 설정된 음향-이미지 매칭 모델을 적용하여, 상기 적어도 하나 의 음원 이미지 및 상기 적어도 하나의 유닛음향 데이터를 각각 매칭하고,상기 음원 이미지로부터 상기 적어도 하나의 음원의 움직임을 추적하고,상기 추적된 음원의 움직임에 따라 상기 유닛 음향 데이터의 음량(loudness)을 개별적으로 조정하고,상기 음향-이미지 매칭 모델은 특정 음원의 이미지와 상기 특정 음원이 발생시키는 음향 간의 매칭 정보를 포함하는, 디바이스."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 입력부는, 음향(sound)을 획득하는 마이크 및 이미지(image)를 획득하는 카메라를 포함하는, 디바이스."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 프로세서는 상기 하나 이상의 명령어들을 실행하여,상기 디바이스 외부의 보조 마이크를 통해 추가적인 음향을 획득하는, 디바이스."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 프로세서는 상기 하나 이상의 명령어들을 실행하여,상기 음향을 진폭, 주파수, 위상, 파형 및 스펙트럼에 따라 적어도 하나 의 유닛 음향 데이터로 분리하고,상기 진폭, 주파수, 위상, 파형 및 스펙트럼이 전부 동일한 두 개 이상의 유닛 음향 데이터들이 존재하는 경우,상기 음원 이미지를 이용하여 상기 두 개 이상의 유닛 음향 데이터를 각각의 유닛 음향 데이터로 분리함으로써,상기 획득한 음향으로부터, 상기 적어도 하나의 음원에 대응하는 적어도 하나의 유닛 음향 데이터를 획득하는,디바이스."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 프로세서는 상기 하나 이상의 명령어들을 실행하여,상기 음원 이미지에서 획득한 정보를 추가로 이용하여 상기 적어도 하나 의 음원 이미지 및 상기 적어도 하나의유닛 음향 데이터를 각각 매칭함으로써,상기 기 설정된 음향-이미지 매칭 모델을 적용하여, 상기 적어도 하나 의 음원 이미지 및 상기 적어도 하나의유닛 음향 데이터를 각각 매칭하는, 디바이스."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "공개특허 10-2022-0036210-5-제11항에 있어서,상기 프로세서는 상기 하나 이상의 명령어들을 실행하여,상기 음원 이미지의 상태 변화를 통해 해당 음원의 움직임을 추적하는, 디바이스."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,상기 프로세서는 상기 하나 이상의 명령어들을 실행하여,가속도계(accelerometer), 자이로스코프(gyroscope) 및 지자기계(magnetometer)를 포함하는 모션 센서로부터획득된 디바이스의 움직임 정보를 이용하여, 상기 음원 이미지의 상태 변화를 통해 해당 음원의 움직임을 추적하는, 디바이스."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서,상기 프로세서는 상기 하나 이상의 명령어들을 실행하여,각각의 유닛 음향 데이터의 전체 실행 시간의 음량 곡선을 획득하고,상기 각각의 유닛 음향 데이터에 대해 수행할 조정 정보를 포함하는 음량 보정 곡선을 획득하고,상기 음량 보정 곡선을 기반으로 상기 각각의 유닛 음향 데이터의 음량을 개별적으로 조정함으로써,상기 추적된 음원의 움직임에 따라 상기 유닛 음향 데이터의 음량을 개별적으로 조정하는, 디바이스."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 프로세서는 상기 하나 이상의 명령어들을 실행하여,상기 음량이 개별적으로 조정된 유닛 음향 데이터로부터 출력 음향을 획득하고,상기 출력 음향 및 상기 이미지로부터 출력 영상을 획득하는 것을 더 포함하는, 디바이스."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 프로세서는 상기 하나 이상의 명령어들을 실행하여,상기 유닛 음향 데이터를 두 개 이상의 채널로 분류하여 렌더링하고, 멀티 채널을 갖는 출력 음향을 획득하는,디바이스."}
{"patent_id": "10-2020-0118500", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2020-0118500", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "영상의 음질을 향상시키는 디바이스 및 방법이 제공된다. 디바이스가 영상의 음질을 향상시키는 방법은, 영상을 획득하는 단계; 상기 획득한 영상으로부터 음향(sound) 및 이미지(image)를 획득하는 단계; 상기 획득한 이미지 로부터 적어도 하나의 음원(sound source)을 나타내는 음원 이미지를 획득하는 단계; 상기 획득한 음향으로부터, 상기 적어도 하나의 음원에 대응하는 적어도 하나의 유닛 음향 데이터를 획득하는 단계; 기 설정된 음향-이미지 매칭 모델을 적용하여, 상기 적어도 하나의 음원 이미지 및 상기 적어도 하나의 유닛 음향 데이터를 각각 매칭하 는 단계; 상기 음원 이미지로부터 상기 적어도 하나의 음원의 움직임을 추적하는 단계; 및 상기 추적된 음원의 움직임에 따라 상기 유닛 음향 데이터의 음량(loudness)을 개별적으로 조정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2020-0118500", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 영상의 음질을 향상시키는 디바이스 및 방법에 대한 것으로서, 보다 상세하게는, 음향을 음원 별로 분리하고, 분리된 유닛 음향 데이터의 음량을 개별적으로 조절함으로써 전체적인 영상의 음질을 향상시키는 디 바이스 및 방법에 관한 것이다."}
{"patent_id": "10-2020-0118500", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상 촬영은 주변 세계를 포착하는 동작이다. 카메라가 장착된 모든 최신 모바일 디바이스에는 영상 촬영 기능 이 있다. 스마트 폰 등의 모바일 디바이스가 널리 보급됨에 따라, 개개인이 영상을 촬영하고 감상하는 경우가 늘고 있다. 오랜 시간에 걸쳐 모바일 디바이스를 통한 영상 기록의 품질이 개선되었으나, 대부분은 녹화된 시각 적 이미지의 품질 향상 또는 시각적인 사용자 경험의 개선에 중점을 두고 있다. 이에 반해, 음향의 품질 개선에 대해서는 거의 다루지 않고 있다. 또한, 모바일 디바이스의 보급으로, 자택 안에서 티비(TV)를 통해 모두가 함께 동일한 영상을 시청하는 것보다, 대중 교통 안에서 이동중일 때, 사무실에서, 또는 화장실에서 개개인의 시청자가 서로 다른 영상을 각자의 모바 일 디바이스로 시청하는 경우가 많다. 개인 모바일 디바이스를 이용해 영상을 시청할 경우, 주변에 방해가 되지 않도록 하고, 영상에 집중하기 위해 헤드셋(headset) 또는 이어폰(earphone)을 일반적으로 사용한다. 헤드셋 및 이어폰은 좌측과 우측에서 재생되는 음향이 서로 다른 스테레오(stereo) 형식의 음향을 지원한다. 따라서, 단일 한 마이크를 통해 모노 오디오로 녹음된 음향의 경우에도, 음질 개선을 위해 스테레오 형식 또는 다른 멀티 채 널 형식으로 변환하는 것이 필요하다. 일반적인 모바일 디바이스에서는, 영상의 음질 개선을 위해 내장된 마이크 이외에 샷건(shotgun) 마이크, 라펠 (lapel) 마이크 등의 별도의 마이크를 사용하거나, 촬영을 마친 후 영상을 컴퓨터 등의 기기로 옮겨 비디오 압 축, 노이즈 제거 등의 별도의 수동 후처리 동작을 통한다. 별도의 전문적인 마이크 장비는 고가이며, 촬영 시마 다 지참해야 하는 불편함이 있다. 음질 개선을 위한 별도의 후처리 공정은 영상 편집 프로그램 및 프로그램을 다룰 수 있는 전문적인 지식이 필요하고, 화면이 작은 스마트 폰 등의 모바일 디바이스에서 직접 영상을 편집하 기 힘들다. 따라서, 스마트 폰으로 영상을 촬영하고 배포하려는 일반적인 사용자가 영상의 음질을 개선시키기는 용이하지 않다. 이에 따라, 별도의 음향 장비가 요구되지 않고, 별도의 후처리 동작이 필요하지 않으면서도, 스마트 폰 등의 모 바일 디바이스에 포함된 카메라 및 마이크를 통해 촬영한 영상의 음질을 모바일 디바이스 내에서 자동으로 개선 할 수 있는 기술이 요구된다."}
{"patent_id": "10-2020-0118500", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일 실시예는, 영상의 이미지로부터 적어도 하나의 음원(sound source)을 나타내는 음원 이미지를 획 득하고, 영상의 음향을 동일한 음원에서의 발생 여부에 따라 유닛 음향 데이터로 분리하고, 음원 이미지와 유닛 음향 데이터를 각각 매칭시키고, 유닛 음향 데이터 각각의 음량(loudness)을 조정함으로써, 입력 음향의 채널 개수와 관계 없이 출력 음향의 채널 개수를 조절할 수 있고, 출력 영상의 음질을 향상시킬 수 있는 디바이스 및 방법을 제공할 수 있다. 또한, 본 개시의 일 실시예는, 모바일 디바이스에 포함된 입력부를 통해 영상을 촬영하고, 모바일 디바이스에 포함된 프로세서가 자동으로 촬영된 영상의 음향 처리를 수행함으로써, 음질의 향상을 위해 별도의 음향 장비가 요구되지 않고, 사용자가 수동으로 후처리 동작을 수행하지 않을 수 있는 디바이스 및 방법을 제공할 수 있다."}
{"patent_id": "10-2020-0118500", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 개시된, 디바이스가 영상의 음질을 향상시키는 방법은, 영상을 획득하는 단계; 상기 획득한 영상으로부터 음향(sound) 및 이미지(image)를 획득하는 단계; 상기 획득한 이미지로부터 적어도 하나의 음원(sound source)을 나타내는 음원 이미지를 획득하는 단계; 상기 획득한 음향으 로부터, 상기 적어도 하나의 음원에 대응하는 적어도 하나의 유닛 음향 데이터를 획득하는 단계; 기 설정된 음 향-이미지 매칭 모델을 적용하여, 상기 적어도 하나의 음원 이미지 및 상기 적어도 하나의 유닛 음향 데이터를 각각 매칭하는 단계; 상기 음원 이미지로부터 상기 적어도 하나의 음원의 움직임을 추적하는 단계; 및 상기 추 적된 음원의 움직임에 따라 상기 유닛 음향 데이터의 음량(loudness)을 개별적으로 조정하는 단계를 포함할 수 있다. 상기 음향-이미지 매칭 모델은 특정 음원의 이미지와 상기 특정 음원이 발생시키는 음향 간의 매칭 정보 를 포함할 수 있다. 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 개시된, 디바이스는, 영상을 획득하는 입력부; 출력 영 상을 출력하는 출력부; 하나 이상의 명령어들(instructions)을 포함하는 프로그램을 저장하는 메모리; 및 상기 메모리에 저장된 하나 이상의 명령어들을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하 나의 프로세서는, 상기 입력부를 제어함으로써, 영상을 획득하고, 상기 획득한 영상으로부터 음향(sound) 및 이 미지(image)를 획득하고, 상기 획득한 이미지로부터 적어도 하나의 음원(sound source)을 나타내는 음원 이미지를 획득하고, 상기 획득한 음향으로부터, 상기 적어도 하나의 음원에 대응하는 적어도 하나의 유닛 음향 데이터 를 획득하고, 기 설정된 음향-이미지 매칭 모델을 적용하여, 상기 적어도 하나의 음원 이미지 및 상기 적어도 하나의 유닛 음향 데이터를 각각 매칭하고, 상기 음원 이미지로부터 상기 적어도 하나의 음원의 움직임을 추적 하고, 상기 추적된 음원의 움직임에 따라 상기 유닛 음향 데이터의 음량(loudness)을 개별적으로 조정할 수 있 다. 상기 음향-이미지 매칭 모델은 특정 음원의 이미지와 상기 특정 음원이 발생시키는 음향 간의 매칭 정보를 포함할 수 있다. 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 컴퓨터로 읽을 수 있는 기록매체는, 개시된 방법의 실 시예들 중에서 적어도 하나를 컴퓨터에서 실행시키기 위한 프로그램이 저장된 것일 수 있다."}
{"patent_id": "10-2020-0118500", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시의 실시예들에서 사용되는 용어는 본 개시의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용 어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라 질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 실시예의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시 전체에서 어떤 부분이 어떤 구성요소를 “포함”한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 본 명세서에 기 재된 “...부”, “...모듈” 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하 드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 사용된 표현 “~하도록 구성된(또는 설정된)(configured to)”은 상황에 따라, 예를 들면, “~에 적합한(suitable for)”, “~하는 능력을 가지는(having the capacity to)”, “~하도록 설계된(designed to) ”, “~하도록 변경된(adapted to)”, “~하도록 만들어진(made to)”, 또는 “~를 할 수 있는(capable of)” 과 바꾸어 사용될 수 있다. 용어 “~하도록 구성된(또는 설정된)”은 하드웨어적으로 “특별히 설계된 (specifically designed to)” 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, “~하도록 구성 된 시스템”이라는 표현은, 그 시스템이 다른 장치 또는 부품들과 함께 “~할 수 있는” 것을 의미할 수 있다. 예를 들면, 문구 “A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서”는 해당 동작을 수행하기 위한 전 용 프로세서(예: 임베디드 프로세서), 또는 메모리에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로 써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 본 개시에서 ‘영상(video)’은 청각적 소리 및 시각적 화면을 포함하는 시청각 자료를 의미한다. 영상의 시각 적 구성은 ‘이미지(image)’, ‘시각 데이터(visual data)’ 또는 ‘그림(picture)’으로 기술될 수 있고, 영 상의 청각적 구성은 ‘오디오(audio)’, ‘음향(sound)’, ‘어쿠스틱(acoustic)’ 또는 ‘음향 데이터(sound data)’로 기술될 수 있다. 본 개시에서 ‘음질(sound quality)’은 소리의 품질을 의미한다. 음질은 다양한 음향적 요소에 따라 달라질 수 있다. 예를 들어, 노이즈의 많고 적음이 음질의 기준이 될 수도 있고, 소리의 주파수 평탄 정도, 음량의 평탄 정도에 따라 음질이 달라질 수 있다. 본 개시에서 ‘음원(sound source)’은 소리가 발생하는 소리의 근원을 의미한다. 예를 들어, 사람, 동물, 각종 악기(musical instruments) 또는 어떠한 물체도 그로부터 소리가 발생한다면 음원이 될 수 있다. 본 개시에서 ‘특정 음원에 대응하는 음향’은 해당 특정 음원으로부터 발생한 음향을 의미한다. 예를 들어, 특 정 사람에 대응하는 음향이란 해당 사람이 낸 목소리를 의미하고, 특정 동물에 대응하는 음향은 해당 동물의 울 음소리를 의미할 수 있다. 본 개시에서 ‘화면 범위(screen area)’는 영상의 시각적 화면이 표시(디스플레이)되는 스크린 상의 영역을 의 미한다. 예를 들어, 화면 범위는 특정 시점에 영상에서 캡쳐된 이미지의 테두리로 정의되는 영역일 수 있다. 본 개시에서 ‘모노(monaural, monophonic: mono)’ 오디오는, 1개의 채널로 구성된 오디오를 의미한다. 모노 오디오는 하나의 마이크를 통한 녹음이며, 하나의 스피커를 통해서 듣는 소리가 이에 해당할 수 있다. 여러 개 의 스피커를 통해 녹음 또는 재생되는 음향이더라도, 1개의 채널로만 음향이 연결되어 있다면 모노 오디오가 될 수 있다. 모노 오디오에서는 연결된 모든 스피커에서 동일한 음향이 재생된다. 본 개시에서 ‘멀티 채널(multi-channel)’ 오디오는 2개 이상의 채널로 구성된 오디오를 의미한다. 예를 들어, 멀티 채널 오디오의 일종인 스테레오(stereo) 오디오는 하나의 스피커를 통해 듣는 경우, 2개의 채널의 신호가 합성되어 하나로 재생되지만, 두 개의 스피커(예를 들어 헤드셋(headset), 이어폰(earphone) 등)를 통해 재생할 경우, 양쪽의 스피커에서 서로 다른 음향이 재생되며, 모노 오디오에 비해 공간감 있고 풍부한 소리를 재생할 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 본 개시의 일 실시예에 따른 디바이스가 영상의 음질을 향상시키는 방법의 개요도이다. 도 1을 참조하면, 디바이스에 입력된 영상은 이미지 및 음향 을 포함할 수 있다. 일 실시예에 서, 이미지는 카메라 등의 입력 장치를 통해 녹화될 수 있고, 음향은 마이크 등의 입력 장치를 통해 녹음될 수 있다. 디바이스는 녹화된 이미지로부터 개별 음원으로 분리된 음원 이미지(SS1, SS2, SS3)들을 획득할 수 있다. 일 실시예에서, 음원 이미지는 화자(사람)(SS1, SS2) 및 배경(예를 들어, 대화자가 아닌 사람, 책상, 의자, 종이 및 배경 이미지를 포함)(SS3)으로 나뉘어질 수 있다. 디바이스는 음향을 각각의 음원에서 발생되는 소리로 나눈 유닛 음향 데이터 세트를 획득할 수 있다. 일 실시예에서, 디바이스는 분리된 유닛 음향 데이터 세트를 사람의 목소리(UA1, UA2) 또는 배경음(노이즈)(UA3)으로 분류할 수 있다. 디바이스는 기 설정된 음향-이미지 매칭 모델을 적용하여, 분류된 유닛 음향 데이터 세트를 분리된 음원 이미지(SS1, SS2, SS3)에 각각 매칭할 수 있다. 예를 들어, 사람의 목소리로 분류된 유닛 음향 데이터 (UA1, UA2)를 사람으로 판단된 음원 이미지(SS1, SS2)에 매칭시킬 수 있으며, 그 밖의 소리들(UA3)은 배경 이미 지(SS3)에 매칭시킬 수 있다. 둘 이상의 사람이 대화하고 있는 경우, 디바이스는 음향-이미지 매칭 모델 에 포함된 ‘사람의 얼굴 및 해당 얼굴에 대응되는 목소리’ 정보를 통해, 분리된 유닛 음향 데이터(UA1, UA2) 를 각각의 음원 이미지(SS1, SS2)에 매칭시킬 수 있다. 디바이스는, 분리된 유닛 음향 데이터(UA1, UA2, UA3) 각각의 음량을 개별적으로 조정할 수 있다. 예를 들어, 노이즈에 해당하는 유닛 음향 데이터 UA3의 경우 음량을 줄일 수 있고, 화자의 대화에 해당하는 유닛 음 향 데이터(UA1, UA2)의 음량은 입력 신호에 대응하는 레벨 또는 기 설정된 레벨로 조정할 수 있다. 디바이스는, 조정된 각각의 유닛 음향 데이터로부터 출력 음향을 재합성할 수 있다. 일 실시예에서, 출력 음향은 헤드폰 등의 출력 장치로의 출력을 위해 멀티 채널(multi-channel) 음향의 일종인 스테레오 (stereo) 형식으로 합성될 수 있다. 예를 들어, 출력 음향은 좌측 스피커(LC)로 출력되는 제1 채널 및 우측 스피커(RC)로 출력되는 제2 채널을 포함할 수 있다. 디바이스는, 음원 이미지(SS1, SS2)의 화면 범위 내의 상대적인 위치에 따라, 각각의 음원 이미지(SS1, SS2)에 대응되는 유닛 음향 데이터(UA1, UA2)의 렌더링 채널을 결정할 수 있다. 예를 들어, 제1 음원 이미지 (SS1)는 화면 범위 내의 좌측에 위치하므로 제1 음원 이미지(SS1)와 대응되는 제1 유닛 음향 데이터(UA1)는 좌 측 스피커(LC)로 출력되는 제1 채널에 렌더링할 수 있다. 또한, 화면 범위 내의 우측에 위치하는 제2 음원 이미지(SS2)에 대응되는 제2 유닛 음향 데이터(UA2)는 우측 스피커(RC)로 출력되는 제2 채널에 렌더링할 수 있다. 일 실시예에서, 디바이스는 입력 음향의 채널 개수와 관계없이 출력 음향의 채널 개 수를 조절할 수 있고, 공간감 있고 풍부한 소리의 출력이 가능하도록 영상의 음질을 개선할 수 있다. 도 2는 본 개시의 일 실시예에 따른 디바이스의 블록도이다. 도 2를 참조하면, 디바이스는 입력부, 프로세서, 메모리, 출력부 및 모션 센서 를 포함할 수 있다. 도 2에 도시된 구성 요소 모두가 디바이스의 필수 구성 요소인 것은 아니다. 도 2에 도시된 구성 요소보다 많은 구성 요소들에 의해 디바이스가 구현될 수도 있고, 도 2에 도시된 구 성 요소보다 적은 구성 요소에 의해 디바이스가 구현될 수도 있다. 입력부는 외부로부터 영상을 획득할 수 있다. 일 실시예에서, 입력부는 시각적 이미지를 획득하는 녹화부 및 청각적 음향을 획득하는 녹음부를 포함할 수 있다. 예를 들어, 녹화부는 카메라(Camera)를 포함할 수 있고, 녹음부는 마이크로폰(Microphone, mic)을 포함할 수 있다. 일 실시예에서, 입력부는 녹화부 및 녹 음부로 물리적으로 분리되지 않는 단일한 구성일 수도 있다. 출력부는 출력 영상을 외부로 출력할 수 있다. 출력부는 디스플레이 및 오디오 출력부(172 0)를 포함할 수 있다.디스플레이는 시각적 이미지를 외부로 표시하여 출력할 수 있다. 일 실시예에서, 디스플레이는 패 널(panel)을 포함할 수 있다. 디스플레이는 예를 들어, 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 유기 발광 다이오드(organic light-emitting diode), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전기영동 디 스플레이(electrophoretic display) 중에서 적어도 하나로 구성될 수 있다. 오디오 출력부는 청각적 음향을 외부로 재생하여 출력할 수 있다. 일 실시예에서, 오디오 출력부는 스피커(speaker)를 포함할 수 있다. 오디오 출력부는 예를 들어, 단일한 스피커, 두 개 이상의 복수의 스 피커, 모노 스피커(mono speaker), 스테레오 스피커(stereo speaker), 서라운드 스피커(surround speaker), 헤 드셋(headset), 이어폰(earphone) 중에서 적어도 하나로 구성될 수 있다. 일 실시예에서, 출력부의 디스플레이 및 오디오 출력부는 물리적으로 분리되지 않는 단일한 구성일 수도 있다. 메모리는 디바이스의 동작을 제어하기 위해 후술할 프로세서에 의해 실행될 프로그램을 저장 할 수 있다. 메모리는 디바이스의 동작을 제어하기 위한 적어도 하나의 명령어들(instructions)을 포함하는 프로그램을 저장할 수 있다. 메모리에는 프로세서가 판독할 수 있는 명령어들 및 프로그 램 코드(program code)가 저장될 수 있다. 일 실시예에서, 프로세서는 메모리에 저장된 프로그램의 명령어들 또는 코드들을 실행하도록 구현될 수 있다. 메모리는 디바이스로 입력되거나 디바이스 로부터 출력되는 데이터를 저장할 수 있다. 메모리는 예를 들어, 플래시 메모리(flash memory), 하드디스크(hard disk), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어, SD 또는 XD 메모리 등), 램(RAM, Random Access Memory), SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장 매체를 포함할 수 있다. 메모리에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있다. 예를 들어, 메모리 는, 음향 이미지 분리 모듈, 음원 이미지 획득 모듈, 유닛 음향 데이터 획득 모듈, 매 칭 모듈, 음원 움직임 추적 모듈 및 음량 조정 모듈을 포함할 수 있다. 또한, 메모리 는 음향-이미지 매칭 모델, DNN(심층 신경망) 및 데이터베이스를 포함할 수 있다. 프로세서는, 디바이스의 전반적인 동작을 제어할 수 있다. 예를 들어, 프로세서는 메모리 에 저장된 프로그램들을 실행함으로써, 입력부, 디스플레이 및 오디오 출력부를 포함 하는 출력부, 모션 센서 및 메모리 등을 전반적으로 제어할 수 있다. 프로세서는 산술, 로직 및 입출력 연산과 시그널 프로세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서 (microprocessor), 그래픽 프로세서(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), 및 FPGAs(Field Programmable Gate Arrays) 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 프로세서는, 메모리에 저장된 적어도 하나의 명령어들을 실행함으로써, 입력부를 통해 영상 을 획득할 수 있다. 영상은 시각적 데이터인 이미지 및 청각적 데이터인 음향을 포함할 수 있다. 프로세서는, 메모리에 저장된 프로그램들 중 음향 이미지 분리 모듈을 구성하는 적어도 하나 의 명령어들을 실행함으로써, 획득한 영상으로부터 음향(sound) 및 이미지(image)를 획득할 수 있다. 일 실시예 에서, 단일한 모노(mono) 파일로 구성된 영상을, 청각적 데이터인 음향 파일 및 시각적 데이터인 이미지 파일로 분리할 수 있다. 프로세서는, 메모리에 저장된 프로그램들 중 음원 이미지 획득 모듈을 구성하는 적어도 하나 의 명령어들을 실행함으로써, 획득한 이미지로부터 적어도 하나의 음원(sound source)을 나타내는 음원 이미지 를 획득할 수 있다. 이미지는 구분되지 않은 하나의 연속적인 화면으로 구성될 수 있다. 이러한 연속적인 화면 에서 사람, 동물, 물건 등의 각각의 오브젝트(object)를 분리할 수 있다. 분리된 각각의 오브젝트는 소리를 발 생시키는 음원이 될 수 있다. 일 실시예에서, 심층 신경망(Deep Neural Network, DNN) 또는 이미지 파일들이 축적된 데이터베이스를 이용해 이미지로부터 적어도 하나의 음원 이미지를 획득할 수 있다. 프로세서는, 메모리에 저장된 프로그램들 중 유닛 음향 데이터 획득 모듈을 구성하는 적어도 하나의 명령어들을 실행함으로써, 획득한 음향으로부터 동일한 음원에서의 발생 여부에 따라 결정된 적어도 하 나의 유닛 음향 데이터를 획득할 수 있다. 유닛 음향 데이터 획득 모듈은 하나의 채널로 구성된 입력 음 향을 서로 다른 음원에서 발생하는 유닛 음향 데이터의 복수의 채널로 분리할 수 있다. 일 실시예에서, 유닛 음 향 데이터 획득 모듈은 심층 신경망(Deep Neural Network, DNN) 또는 오디오 정보들이 축적된 데이터베이 스를 이용하여 음향을 유닛 음향 데이터로 분리할 수 있다. 분리된 유닛 음향 데이터의 정보는 메모리에 저장된 데이터베이스로 전달되어 저장되고, 데이터베이스를 업데이트할 수 있다. 일 실시예에서, 음향 데이터를 분리하기 위한 모델은 기 설정되어 데이터베이스에 저장되어 있을 수 있다. 프로세서는, 메모리에 저장된 프로그램들 중 매칭 모듈을 구성하는 적어도 하나의 명령어들 을 실행함으로써, 기 설정된 음향-이미지 매칭 모델을 적용하여, 적어도 하나의 음원 이미지 및 적어도 하나의 유닛 음향 데이터를 각각 매칭할 수 있다. 음향-이미지 매칭 모델에는 특정 음원의 이미지와 해당 특정 음원이 발생시키는 음향 간의 매칭 정보가 포함될 수 있다. 음향과 이미지의 매칭 정보에는, 음원 이미지의 정보에 따른 음향의 정보(예를 들어, 강아지 이미지에 대응되는 짖음 소리, 나무 이미지에 대응되는 바스락 소리, 또는 둘 이상의 사람이 대화하고 있는 경 우 특정 사람의 얼굴 이미지에 따른 목소리 정보 등 특정 이미지에 따른 음향의 특징) 및 특정 음향에 따른 음 원 이미지의 정보(예를 들어, 특정 소리가 발생할 때의 이미지의 입모양)가 포함될 수 있다. 일 실시예에서, 음향-이미지 매칭 모델은 심층 신경망(Deep Neural Network, DNN) 또는 이미지 파일 및 오디오 정보들이 축적된 데이터베이스를 이용해 설정될 수 있다. 일 실시예에서, 이미지로부터 분리된 개별 음원 이미지들과 음향으로부터 분리된 개별 유닛 음향 데이터들은 각 각 음향-이미지 매칭 모델에 포함된 음향과 이미지의 대응관계 정보에 기반하여 매칭될 수 있다. 기 설정 된 음향-이미지 매칭 모델에 따라 매칭된 각각의 음원 이미지 및 유닛 음향 데이터의 정보는, 메모리 에 저장된 음향-이미지 매칭 모델에 다시 전달되어 저장되고 음향-이미지 매칭 모델을 업데 이트 하거나, 데이터베이스로 전달되어 저장되고 데이터베이스를 업데이트 할 수 있다. 프로세서는, 메모리에 저장된 프로그램들 중 음원 움직임 추적 모듈을 구성하는 적어도 하나 의 명령어들을 실행함으로써, 음원 이미지로부터 적어도 하나의 음원의 움직임을 추적할 수 있다. 움직이는 이 미지를 포함하는 영상에서는 특정 음원 이미지의 상태 또는 위치가 시간의 경과에 따라 변화할 수 있다. 일 실 시예에서, 음원 움직임 추적 모듈은 이미지(화면)를 분석하여, 특정 음원의 움직이는 방향, 속도, 음원 이미지의 모양의 변화 등을 분석하고 특정 음원에 대한 움직임 프로파일(profile)을 획득할 수 있다. 일 실시예 에서, 획득한 움직임 프로파일은 후속 단계에서 각각의 유닛 음향 데이터의 음량을 개별적으로 조정하는 것에 이용될 수 있다. 프로세서는, 메모리에 저장된 프로그램들 중 음량 조절 모듈을 구성하는 적어도 하나의 명령 어들을 실행함으로써, 추적된 음원의 움직임에 따라 유닛 음향 데이터의 음량(loudness)을 개별적으로 조정할 수 있다. 일 실시예에서, 전체 영상에서 출력 음향이 일정한 음량을 유지하도록 유닛 음향 데이터의 음량을 조 정할 수 있다. 예를 들어, 사람이 말하는 것을 녹음하는 경우, 음원(말하고 있는 사람)이 녹음 중 이동하여 디 바이스로부터 상대적으로 멀어짐에 따라, 입력 유닛 음향 데이터의 음량은 감소한다. 이러한 경우, 음원 이 디바이스에 가까울 때의 음량을 기준으로, 유닛 음향 데이터가 전체 영상에서 일정한 음량을 가질 수 있도록 음량을 조정할 수 있다. 이와 같이, 앞서 음원 움직임 추적 모듈에서 획득된 음원의 움직임 프로 파일을 기반으로, 해당 음원에 대응하는 유닛 음향 데이터의 음량을 개별적으로 조정할 수 있다. 일 실시예에서, 프로세서는 메모리에 저장된 프로그램들 중 음량 조절 모듈을 구성하는 적어 도 하나의 명령어들을 실행함으로써, 음원의 종류에 따라 유닛 음향 데이터의 음량을 개별적으로 조정할 수도 있다. 예를 들어, 특정 유닛 음향 데이터가 노이즈(noise)로 분류된 경우, 해당 유닛 음향 데이터의 음량을 작 게 조정할 수 있다. 일 실시예에서, 특정한 종류의 음향만의 출력이 요구되는 경우, 유닛 음향 데이터들 중 출 력하고자 하는 특정 종류의 음향 만을 필터링(filtering)하며 다른 종류의 유닛 음향 데이터는 노이즈와 같이 음량을 작게 조정할 수도 있다. 메모리에 저장된 심층 신경망(Deep Neural Network, DNN)은 인공 신경망의 한 종류로서, 입력층과 출력층 상이에 여러 개의 은닉층(hidden layer)들로 이루어지는 특징을 가질 수 있다. DNN(심층 신경망)은 일반적인 인공 신경망과 마찬가지로 복잡한 비선형 관계들을 모델링할 수 있다. 예를 들어, 사물 식별 모델 을 위한 심층 신경망 구조에서는 각 객체가 이미지 기본 요소들의 계층적 구성으로 표현될 수 있다. 이때, 추가 계층들은 점진적으로 모인 하위 계층들의 특징을 규합 시킬 수 있다. DNN(심층 신경망)의 이러한 특징은, 더 적은 수의 유닛들만으로도 복잡한 데이터를 모델링할 수 있게 한다. DNN(심층 신경망)은 이미지 인식 이나 음성 인식 분야에 적용될 수 있고, 본 개시와 같이 이미지를 분리하고 분리된 이미지를 각각의 음성 정보 와 매칭시키는 처리에 이용될 수 있다. 메모리에 저장된 데이터베이스는 방대한 양의 데이터의 집합으로 구성될 수 있다. 일 실시예에서, 데이터베이스는 특정 음원 이미지에 대응되는 음향 정보 및 특정 음향에 대응되는 이미지 정보를 포함할 수 있다. 일 실시예에서 데이터베이스는 음향과 이미지의 대응관계를 나타내는 매칭 정보를 획득하여 음 향-이미지 매칭 모델을 설정하는데 이용될 수 있다. 또한, 데이터베이스는, 유닛 음향 데이터와 음 원 이미지를 매칭 시키거나, 각각의 유닛 음향 데이터의 음량을 조절하는데 이용될 수 있다. 프로세서는, 메모리에 저장된 적어도 하나의 명령어들을 실행함으로써, 음량이 개별적으로 조정된 유닛 음향 데이터로부터 출력 음향을 획득하고, 출력 음향 및 이미지로부터 출력 영상을 획득할 수 있다. 일 실 시예에서, 음량이 개별적으로 조정된 유닛 음향 데이터들을 재합성하여 최종 출력 음향 데이터를 획득할 수 있 다. 일 실시예에서, 프로세서는, 스테레오(stereo) 형식 등의 멀티 채널(multi-channel)을 가지는 출력 음향을 획득하기 위해, 두 개 이상의 채널로 유닛 음향 데이터들을 분류하여 렌더링할 수 있다. 예를 들어, 디 스플레이 화면 상 왼쪽에 배치된 음원 이미지들에 대응하는 유닛 음향 데이터들은 제1 채널로, 디스플레이 화면 상 오른쪽에 배치된 음원 이미지들에 대응하는 유닛 음향 데이터들은 제2 채널로 렌더링할 수 있다. 이후, 왼쪽 스피커에서는 제1 채널을 재생하고, 오른쪽 스피커에서는 제2 채널을 재생하는 출력 음향을 획득할 수 있다. 일 실시예에서, 출력 음향은 스테레오 형식뿐만 아니라, 서라운드(Surround) 형식, 앰비소닉(Ambisonic) 형식 또는 그 밖의 멀티채널(Multi-channel) 형식일 수도 있다. 일 실시예에서, 디바이스는 모션 센서를 더 포함할 수 있다. 모션 센서는, 가속도계 (accelerometer), 자이로스코프(gyroscope) 및 지자기계(magnetometer)를 포함할 수 있다. 모션 센서는 디바이스의 움직임을 검출할 수 있다. 영상을 획득하는 입력부가 포함된 디바이 스 자체의 움직임이 있는 경우, 실제 오브젝트(object)의 움직임이 없더라도, 획득된 영상에서는 음원 이 미지의 움직임이 있는 것으로 인식될 수 있다. 일 실시예에서, 모션 센서로부터 획득된 디바이스의 움직임 정보를 기반으로, 음원 이미지의 화면 상에서의 상대적인 변화를 통해 음원의 움직임 프로파일을 추가로 획득할 수 있다. 획득된 추가적인 음원 움직임 프로파일은 해당 음원 이미지에 매칭된 유닛 음향 데이터의 음량 을 조정하는데 이용될 수 있다. 종래에는 양질의 음향을 포함하는 영상을 획득하기 위하여, 전문적인 음향 녹음 장비를 사용하거나, 일반적인 음향 장비로 녹음한 후 영상 후처리 과정을 거쳐야했다. 인터넷 및 소셜 네트워크의 발전으로 개인적으로 영상 을 촬영, 편집 및 배포하는 크리에이터가 늘어나고 있다. 이 같은 개인 크리에이터들은 전문적인 장비를 이용하 기 보다는, 스마트 폰과 같은 모바일 디바이스에 기본적으로 포함된 카메라 및 마이크를 이용해 영상을 촬영하 는 경우가 많다. 모바일 디바이스에 의한 영상 촬영은 시각적 데이터인 이미지의 처리 영역에서는 많은 개선이 있었으나, 청각적 데이터인 음향의 처리 영역에서는 크게 개선되지 않았다. 음질의 개선은 보다 실감나는 영상 의 시청에 있어서 중요하다. 본 개시의 일 실시예에 따른 디바이스는, 프로세서가 메모리에 저장된 하나 이상의 명령어들 을 실행함으로써, 디바이스에 포함된 입력부에서 획득한 영상을 시각적 데이터인 이미지 및 청각적 데이터인 음향으로 분리하고, 영상의 이미지로부터 적어도 하나의 음원(sound source)을 나타내는 음원 이미지 를 획득하고, 영상의 음향을 동일한 음원에서의 발생 여부에 따라 유닛 음향 데이터로 분리하고, 음원 이미지와 유닛 음향 데이터를 각각 매칭시키고, 유닛 음향 데이터 각각의 음량(loudness)을 조정함으로써, 출력 영상의 음질을 향상시킬 수 있다. 따라서, 스마트 폰 등의 모바일 디바이스에 기본적으로 포함된 마이크 등의 입력부를 이용해 녹음하는 경 우에도, 촬영된 영상이 디바이스에 포함된 프로세서를 통해 디바이스 내부에서 즉각적으로 후처리 될 수 있다. 이러한 경우, 촬영된 영상의 음질의 향상을 위한 별도의 음향 장비가 요구되지 않고, 사용 자가 전문적인 영상 후처리 기술이 없어도 모바일 디바이스가 자동으로 음향의 후처리를 수행함으로써, 양질의 음향을 포함하는 영상을 획득할 수 있다. 또한, 본 개시의 일 실시예에 따른 디바이스는, 프로세서가 메모리에 저장된 하나 이상의 명 령어들을 실행함으로써, 분리된 개별 유닛 음향 데이터를, 두 개 이상의 서로 다른 채널로 렌더링 할 수 있다. 따라서, 단일한 마이크를 통해 모노 오디오로 녹음된 경우에도, 출력 영상은 멀티 채널을 가지는 스테레오 형식 음향, 서라운드 형식 음향 또는 앰비소닉 형식의 음향을 가질 수 있다. 이와 같이, 입력 음향의 채널 개수와 관 계 없이 출력 음향의 채널 개수를 조절할 수 있고, 보다 실감나는 영상을 위한 양질의 음향을 획득할 수 있다. 도 3은 본 개시의 일 실시예에 따른 영상의 음질을 향상시키는 방법의 흐름도이다. 단계 S300에서, 영상을 획득할 수 있다. 영상은 2차원 평면 위에 그려진 시청각적 표현물을 의미할 수 있다. 영 상은 움직이는 동영상을 의미할 수 있다. 일 실시예에서, 영상은 음향(sound)을 획득하는 마이크 및 이미지 (image)를 획득하는 카메라를 포함하는 입력부를 통해 획득할 수 있다. 단계 S310에서, 영상으로부터 음향(sound)을 획득할 수 있다. 예를 들어, 음향은 사람의 목소리, 동물의 소리, 사물로부터 발생하는 소리, 노이즈 등을 포함할 수 있다. 일 실시예에서, 음향은 단일한 마이크로부터 녹음된 단일 채널의 모노 오디오일 수도 있고, 복수의 마이크들로부터 녹음된 멀티 채널의 오디오일 수도 있다. 단계 S320에서, 영상으로부터 이미지(image)를 획득할 수 있다. 예를 들어, 이미지는 카메라로부터 녹음된 시각 적 데이터일 수 있다. 일 실시예에서 이미지는 다양한 음원들의 음원 이미지를 포함할 수 있다. 단계 S330에서, 음향으로부터 적어도 하나의 음원에 대응하는 적어도 하나의 유닛 음향 데이터를 획득할 수 있 다. 예를 들어, 동일한 음원에서의 발생 여부에 따라 결정된 적어도 하나의 유닛 음향 데이터를 획득할 수 있 다. 일 실시예에서, 단일 채널의 모노 오디오로 구성된 음향을 서로 다른 음원에서 발생하는 복수의 유닛 음향 데이터들로 분리할 수 있다. 일 실시예에서, 음향을 복수의 유닛 음향 데이터들로 분리할 때, 이미지를 이용할 수도 있다. 단계 S340에서, 이미지로부터 적어도 하나의 음원(sound source)을 나타내는 음원 이미지를 획득할 수 있다. 예 를 들어, 연속적인 시각적 데이터로 구성된 이미지로부터, 사람, 동물, 물건, 배경 등 각각이 음향을 발생시키 는 음원이 될 수 있는 오브젝트(object)들을 분리할 수 있다. 단계 S350에서, 기 설정된 음향-이미지 매칭 모델을 적용하여, 적어도 하나 의 음원 이미지 및 적어도 하나의 유닛 음향 데이터를 각각 매칭할 수 있다. 일 실시예에서, 음향-이미지 매칭 모델은 특정 음원의 이미지와 특정 음원이 발생시키는 음향 간의 매칭 정보를 포함할 수 있다. 일 실시예에서, 음향-이미지 매칭 모델은 심층 신경 망(Deep Neural Network, DNN)을 통해 기 설정될 수 있다. 음향과 이미지의 매칭 정보에는 음원 이미지의 정보 에 따른 음향의 정보 및 특정 음향에 따른 음원 이미지의 정보가 포함될 수 있다. 일 실시예에서, 이미지로부터 분리된 음원 이미지들과 음향으로부터 분리된 유닛 음향 데이터들은 각각 음향-이 미지 매칭 모델에 기반하여 일대일, 다대일, 또는 다대다 매칭될 수 있다. 일 실시예에서, 유닛 음향 데이터와 음원 이미지를 매칭 시킬 때, 음원 이미지의 움직임 및 음원 이미지의 변화가 고려될 수도 있다. 단계 S360에서, 음원 이미지로부터 적어도 하나의 음원의 움직임을 추적할 수 있다. 움직임은 각각의 음원 이미 지 별로 추적될 수 있다. 음원의 움직임 프로파일은 후속 단계에서 각각의 유닛 음향 데이터의 음량을 개별적으 로 조정하는 것에 이용될 수 있다. 일 실시예에서, 음원의 움직임은, 음원 이미지의 화면 상에서의 변화를 통해 계산되고 추적될 수 있다. 일 실시예에서, 음원의 움직임은, 가속도계(accelerometer), 자이로스코프 (gyroscope) 및 지자기계(magnetometer)를 포함하는 모션 센서로부터 획득된 디바이스의 움직임 정보를 이용하 여 음원 이미지의 화면 상에서의 상대적인 변화를 통해 계산되고 추적될 수도 있다. 단계 S370에서, 추적된 음원의 움직임에 따라 유닛 음향 데이터의 음량(loudness)을 개별적으로 조정할 수 있다. 일 실시예에서, 음향으로부터 분리된 각각의 유닛 음향 데이터의 음량을 줄이거나, 늘리거나, 전체 영상 에서 일정한 음량을 가질 수 있도록 조정할 수 있다. 각각의 유닛 음향 데이터들의 음량을 개별적으로 조정함으 로써, 전체적인 음향의 최적화 및 튜닝이 가능하다. 단계 S380에서, 음량이 개별적으로 조정된 유닛 음향 데이터로부터 출력 음향을 획득할 수 있다. 일 실시예에서, 음량이 개별적으로 조정된 유닛 음향 데이터들을 재합성하여 최종 출력 음향 데이터를 획득할 수 있다. 일 실시예에서, 유닛 음향 데이터를 두 개 이상의 채널로 분류하여 렌더링하고, 스테레오(stereo) 형식 등의 멀티 채널(multi-channel)을 가지는 출력 음향을 획득할 수도 있다. 예를 들어, 출력 음향은 노이즈에 해 당하는 유닛 음향 데이터의 음량이 작게 조정되어 재합성 되거나, 풍부한 음향을 위해 멀티 채널을 가지도록 재 합성될 수 있고, 따라서, 최종 출력 음향은 초기 입력된 음향에 비해 음질이 개선될 수 있다. 단계 S390에서, 출력 음향 및 이미지로부터 출력 영상을 획득할 수 있다. 출력 영상은 입력 영상과 비교할 때, 이미지(화면)는 일치하나 조정된 유닛 음향 데이터를 포함하므로 음향의 음질은 개선될 수 있다. 도 4는 본 개시의 일 실시예에 따른 영상의 음질을 향상시키는 방법의 흐름도이다. 단계 S400에서, 음향(sound) 및 이미지(image)를 포함하는 영상을 획득할 수 있고, 단계 S410 및 단계 S420에서 영상으로부터 음향 및 이미지를 분리하여 획득할 수 있다. 단계 S430에서, 이미지로부터 적어도 하나의 음원(sound source)을 나타내는 음원 이미지를 획득할 수 있다. 예 를 들어, 연속적인 시각적 데이터로 구성된 이미지로부터, 사람, 동물, 물건, 배경 등 각각이 음향을 발생시키 는 음원이 될 수 있는 오브젝트(object)들을 분리할 수 있다. 단계 S440에서, 기 설정된 음향-이미지 매칭 모델을 적용하여, 적어도 하나 의 음원 이미지 및 음향의 일부를 매칭할 수 있다. 일 실시예에서, 음향-이미지 매칭 모델은 특정 음원의 이미지와 특정 음원이 발생시키는 음향 간의 매칭 정보를 포함할 수 있다. 단계 S450에서, 음향 및 분리된 음원 이미지로부터 적어도 하나의 음원에 대응하는 적어도 하나의 유닛 음향 데 이터를 획득할 수 있다. 예를 들어, 동일한 음원에서의 발생 여부에 따라 결정된 적어도 하나의 유닛 음향 데 이터를 획득할 수 있다. 일 실시예에서, 단일 채널의 모노 오디오로 구성된 음향을 서로 다른 음원에서 발생하 는 복수의 유닛 음향 데이터들로 분리할 때, 음원 이미지를 이용할 수 있다. 예를 들어, 음향을 각각의 유닛 음 향 데이터로 분리할 때, 앞서 분리된 음원 이미지를 참조하여, 어떠한 음원이 존재하는지를 미리 판단하고, 해 당 음원에 의한 음향을 우선적으로 분리할 수 있다. 예를 들어, 각각의 음원 이미지에 매칭된 음향의 일부를 각 각의 유닛 음향 데이터로 분리할 수 있다. 이미지로부터 음원 이미지를 우선적으로 분리하고, 매칭된 음원 이미지를 이용하여 음향으로부터 유닛 음향 데 이터를 분리하는 동작은, 영상의 이미지에 나타나지 않는 음원이 존재하는 경우에 유용할 수 있다. 예를 들어, 각각의 분리된 음원 이미지에 대응하는 음향들을 각각의 유닛 음향 데이터로 분리한 후, 남은 음향 데이터로부 터 영상의 이미지에 나타나지 않는 음원에 대응되는 유닛 음향 데이터를 획득할 수 있다. 단계 S460에서, 음원의 음원 이미지로부터 적어도 하나의 음원의 움직임을 추적할 수 있다. 음원의 움직임은 각 각의 음원 이미지 별로 추적될 수 있다. 음원의 움직임 프로파일은 후속 단계에서 각각의 유닛 음향 데이터의 음량을 개별적으로 조정하는 것에 이용될 수 있다. 이후, 전술한 실시예에서와 유사하게, 단계 S470에서 추적된 음원의 움직임에 따라 유닛 음향 데이터의 음량 (loudness)을 개별적으로 조정할 수 있고, 단계 S480에서 음량이 개별적으로 조정된 유닛 음향 데이터로부터 출 력 음향을 획득할 수 있다. 출력 음향은 초기 입력된 음향에 비해 음질이 개선될 수 있다. 도 5는 본 개시의 일 실시예에 따른 디바이스가 보조 입력부를 통해 추가적인 음향을 획득하는 동 작을 설명하기 위한 도면이다. 본 개시의 일 실시예에 따른 디바이스는 음향을 획득하는 마이크 및 이미지를 획득하는 카메라를 포함하 는 입력부를 자체적으로 포함할 수 있다. 일 실시예에서, 디바이스는 디바이스 외부의 보조 입력부를 통해 추가적인 음향을 획득할 수 도 있다. 예를 들어, 보조 입력부는 라펠(lapel) 마이크 등의 보조 마이크를 포함할 수 있다. 디바이스 가 직접 획득한 음향 및 보조 입력부를 통해 획득한 음향은 동일한 음원(SS)에서 발생한 음향일 수 도 있고, 일 실시예에서, 디바이스가 직접 획득한 음향 및 보조 입력부를 통해 획득한 음향은 서로 다른 음원에서 발생한 음향으로서 멀티 채널 음향을 구성할 수도 있다. 디바이스가 직접 획득한 음향 및 보조 입력부를 통해 획득한 음향이 동일한 음원(SS)에서 발생한 음향인 경우, 디바이스에서 직접 획득한 음향과 보조 입력부를 통해 획득한 음향은 음량 또는 신호 대 잡음비의 차이만을 가질 수 있다. 이러한 경우, 보조 입력부를 통해 입력된 음향은, 디바이스로 전송되어, 디바이스가 획득한 음향과 함께 영상의 후처리에 이용될 수 있다. 예를 들어, 보조 입력부 를 통해 입력된 음향이 더 나은 신호 대 잡음비를 가지는 경우, 보조 입력부를 통해 입력된 음향은 디바이스가 획득한 영상의 음향 노이즈 제거에 이용될 수 있다. 보조 입력부를 통해 획득한 음향은 디바이스가 자체적으로 획득한 음향을 보조할 수 있고, 디바이스가 획득한 음향을 완전히 대체하는 것은 아니다. 디바이스가 직접 획득한 음향 및 보조 입력부를 통해 획득한 음향이 서로 다른 채널의 음향으로서 멀티 채널 음향을 구성하는 경우, 각각의 음향은 함께 또는 독립적으로 후처리 되어, 새로운 모노 채널 형식 또 는 멀티 채널 형식의 출력 음향을 획득할 수 있다. 도 6은 본 개시의 일 실시예에 따른 디바이스가 이미지로부터 적어도 하나의 음원 이미지를 획득하 는 동작을 설명하기 위한 도면이다. 디바이스는 이미지로부터 적어도 하나의 음원(sound source)을 나타내는 음원 이미지를 획득할 수 있다. 도 6을 참조하면, 획득한 영상의 이미지는 연속적인 시각적 데이터로 구성될 수 있다. 연속적인 시각적 데 이터 이미지로부터, 사람, 동물, 물건, 배경 등 각각이 음향을 발생시키는 음원이 될 수 있는 오브젝트(objec t)들을 분리할 수 있다. 일 실시예에서, 이미지 분석은, 심층 신경망(DNN) 기술인 딥러닝(Deep Learning) 또는 인공지능을 통해 분석될 수 있으며, 이 경우 높은 정확도와 다양한 사물 인식이 가능하다. 인공지능(Artificial Intelligence, AI)의 이미지 인식 기술은, 이미지를 여러 패턴으로 분류하고, 패턴형 데이 터를 학습하여 새로운 이미지가 주어질 때 이미지가 무엇인지 판단할 수 있다. 일 실시예에서, 디바이스 는, 심층 신경망(DNN) 또는 인공지능(AI)을 통해, 이미지에서 사람 이미지(H1, H2, H3, H4, H5, H6) 및 개 이미지(D1, D2)들을 분리할 수 있다. 분리된 사람 이미지(H1, H2, H3, H4, H5, H6) 및 개 이미지(D1, D2)들 은 각각 음원 이미지가 될 수 있다. 이와 같이, 디바이스는 이미지로부터 적어도 하나의 음원 이미 지를 분리하고 획득할 수 있다. 도 7은 본 개시의 일 실시예에 따른 디바이스가 음향으로부터 적어도 하나의 유닛 음향 데이터 세트 를 획득하는 동작을 설명하기 위한 도면이다. 유닛 음향 데이터는 동일한 음원에서의 발생 여부에 따라 결정될 수 있다. 소리는 세기, 음색 및 높이의 3 요소를 가진다. 이 세 가지 요소는 각각 소리 파동의 진폭, 파형 및 진동수에 해당한다. 파동의 진폭이 클수록 소리의 세기는 크고, 파동의 진동수가 높을수록 소리의 높이가 높다. 소리의 음색은 파형에 의해 결정되는데, 같은 음이라도 피아노, 사람, 바이올린 등의 소리가 다른 이유는 소리의 파형이 다르기 때문이다. 또한, 소리를 구별할 때 엔벨로프(envelope)가 고려될 수 있다. 엔벨로프란 시간에 따른 소리의 변화이며, 음이 최고점까지 도달하는 시간, 음이 안정되기까지의 시간, 음이 지속되는 시간 및 음이 사라질 때까지의 시간을 의 미한다. 엔벨로프는 음원이 소리를 발생하는 방법에 따라 달라질 수 있다. 일 실시예에서, 동일한 음원에서 발 생한 소리인지 여부는 소리의 3요소 및 엔벨로프에에 따라 결정될 수 있다. 일 실시예에서, 음향으로부터 유닛 음향 데이터 세트를 분리하고 획득하는 동작은, 음향을 진폭, 주파수, 위상, 파형 및 스펙트럼에 따라 적어도 하나의 유닛 음향 데이터(761, 762, 763, 764)들로 분리 하는 동작을 포함할 수 있다. 예를 들어, 네 개의 악기의 소리가 합성된 음향으로부터, 진폭, 주파수, 위 상, 파형, 스펙트럼 등에 의존하는 소리의 3요소 및 엔벨로프에 따라, 각각의 악기에 의한 소리로 분리된 4개의 유닛 음향 데이터(761, 762, 763, 764)들을 획득할 수 있다. 일 실시예에서, 두 개 이상의 유닛 음향 데이터들의 진폭, 주파수, 위상, 파형 및 스펙트럼이 전부 동일한 경우, 음원 이미지를 이용하여 각각의 유닛 음향 데이터로 분리할 수 있다. 예를 들어, 이미지가 분할 화면을 포함하고, 동일한 사람이 각각의 분할 화면 상에서 동시에 말하고 있는 경우, 각각의 분할 화면 상의 사람의 입 모양을 참조하여 각각의 분할 화면에 대응하는 유닛 음향 데이터를 분리할 수 있다. 예를 들어, 동일한 종류의 악기가 두 개 이상 존재하는 경우, 악기를 연주하는 사람의 손 모양 등을 참조하여 각각의 악기 별로 유닛 음향 데이터를 분리할 수 있다. 이와 같이, 음향의 특징으로는 음원 별로 유닛 음향 데이터를 분리하기 어려운 경우, 이미지 데이터를 추가로 이용할 수 있다. 도 8은 본 개시의 일 실시예에 따른 디바이스가 음원 이미지(821, 822)에 따라 음향을 분리하고, 분 리된 유닛 음향 데이터(861, 862)를 각각의 음원 이미지(821, 822)에 매칭하는 동작을 설명하기 위한 도면이다. 도 8을 참조하면, 영상은 개별 음원으로 분리된 음원 이미지(821, 822)를 포함하는 이미지 및 음향을 포함할 수 있다. 음향은 각각의 음원 이미지(821, 822)로부터 발생된 소리(A1, A2)의 합성을 포함할 수 있 다. 일 실시예에서, 음향은, 각각의 음원 이미지(821, 822)에 대응되는 목소리 정보를 포함하는 음향-이미 지 매칭 모델을 적용하여, 유닛 음향 데이터(861, 862)로 분리될 수 있다. 분리된 유닛 음향 데이터(861, 862) 는 목소리 정보에 따라 각각의 음원 이미지(821, 822)와 매칭될 수 있다. 일 실시예에서, 음원 이미지 및 유닛 음향 데이터를 각각 매칭하는 동작은, 음원 이미지에서 획득한 정보를 추 가로 이용할 수도 있다. 예를 들어, 동일한 사람이 분할 화면 상에서 동시에 말하고 있는 경우, 각각의 분할 화 면 상의 사람의 입 모양을 참조하여 분할 화면에 유닛 음향 데이터를 매칭할 수 있다. 예를 들어, 동일한 종류 의 악기가 두 개 이상 존재하는 경우, 악기를 연주하는 사람의 손 모양 등을 참조하여 각각의 악기 별로 유닛 음향 데이터를 매칭할 수 있다. 일 실시예에서, 특정한 음향만의 출력이 요구되는 경우, 유닛 음향 데이터(861, 862)들 중 출력하고자 하는 특 정 종류의 음향 만을 필터링(filtering)하며, 다른 종류의 유닛 음향 데이터의 음량을 작게 조정할 수도 있다. 예를 들어, 도 8을 참조하면, 음원 이미지 821 에 대응하는 유닛 음향 데이터만을 출력하고자 할 경우, 음 원 이미지 822 에 대응하는 유닛 음향 데이터를 음소거 처리할 수 있다. 또한, 음원 이미지 822 에 대응 하는 유닛 음향 데이터만을 출력하고자 할 경우, 음원 이미지 821 에 대응하는 유닛 음향 데이터를 음소거 처리할 수 있다. 도 9는 본 개시의 일 실시예에 따른 디바이스가 추적된 음원의 움직임에 따라 유닛 음향 데이터의 음량을 개별적으로 조정하는 동작(S370)의 구체적인 실시예를 설명하기 위한 도면이다. 단계 S910에서, 각각의 유닛 음향 데이터의 전체 실행 시간의 음량 곡선을 획득할 수 있다. 예를 들어, 각각의 유닛 음향 데이터에 대해 감지된 음량의 레벨(level)을 시간에 따라 계산할 수 있다. 단계 S920에서, 각각의 유닛 음향 데이터에 대해 수행할 조정 정보를 포함하는 음량 보정 곡선을 획득할 수 있 다. 일 실시예에서, 음량 보정 곡선은 영상의 전체 실행 시간 내에서 특정 시간에 유닛 음향 데이터의 음량을 줄일지 키울지에 대한 정보를 포함할 수 있다. 예를 들어, 영상의 전체 실행 시간 내에서 음향의 음량을 일정하 게 유지하고자 하는 경우, 음량 보정 곡선은, 음량 곡선과 기 설정된 출력 음량의 값 사이의 차이로 계산될 수 있다. 단계 S930에서, 음량 보정 곡선을 기반으로 각각의 유닛 음향 데이터의 음량을 시간에 따라 개별적으로 조정할 수 있다. 도 10a, 10b 및 10c는 본 개시의 일 실시예에 따른 디바이스가 멀티 채널을 갖는 출력 음향을 획득하는 예시를 나타내는 도면이다. 도 10a를 참조하면, 일 실시예에서, 디바이스는 두 개의 음원(SS101, SS102)을 포함하는 영상을 촬영할 수 있다. 도 10b를 참조하면, 녹음된 입력 음향은 모노 오디오로서 그 상태로 후처리 없이 재생 시, 두 개의 음원에서 발 생한 입력 음향(IA101, IA102)이 각각의 좌채널(LC) 및 우채널(RC)에서 동시에 재생될 수 있다. 이 경우, 두 개 의 음원(SS101, SS102)은 같은 장소에 있는 것으로 인식될 수 있다. 이와 같이, 단일한 채널을 갖는 모노 오디 오에서, 사용자는 두 개의 음원(SS101, SS102)의 방향을 인식할 수 없다. 도 10c를 참조하면, 녹음된 입력 음향(IA101, IA102)에 본 개시의 일 실시예에 따른 영상의 음질을 향상시키는 방법이 적용될 경우, 디바이스는 음향을 각각의 음원(SS101, SS102)에 따라 유닛 음향 데이터로 분리할 수 있고, 분리된 유닛 음향 데이터를 각각의 음원 이미지의 화면 상의 위치에 따라 좌채널(LC) 또는 우채널(R C)로 렌더링할 수 있다. 예를 들어, 화면 상 좌측에 위치하는 음원 SS101에 대응되는 유닛 음향 데이터는 좌채 널(LC)로, 화면 상 우측에 위치하는 음원 SS102에 대응되는 유닛 음향 데이터는 우채널(RC)로 출력 음향을 렌더 링할 수 있다. 따라서, 출력 음향은, 두 개의 채널(LC, RC)을 가지는 멀티 채널 오디오로 구현될 수 있다. 도 11은 본 개시의 일 실시예에 따른 디바이스가 유닛 음향 데이터의 음량을 개별적으로 조정하는 예시를 나타내는 도면이다. 일 실시예에서, 디바이스를 소지하고 촬영하는 사람이 직접 음향을 발생시키는 음원 SS111이 될 수 있다. 디바이스를 소지하고 촬영하는 사람은 화면 상에 나타나는 경우도 있으나, 나타나지 않는 경우도 있을 수 있다. 음향을 유닛 음향 데이터로 분리하는 동작에 있어서, 음원 SS111의 음원 이미지가 화면 상에 존재하는 경우, 음 향-이미지 매칭 모델을 이용할 수 있다. 음원 SS111이 화면 상에 나타나지 않아 음원 이미지가 존재하지 않는 경우, 화면 상에 나타난 다른 음원 SS112에 대응하는 유닛 음향 데이터 A2를 분리하고 남은 음향 데이터를 음원 SS111에 대응하는 유닛 음향 데이터 A1으로 결정할 수 있다. 도 11의 (a)를 참조하면, 입력 음향에 있에서, 디바이스로부터 가까운 곳에 위치한 음원 SS111이 발생시 킨 유닛 음향 데이터 A1은 디바이스에서 먼 곳에 위치한 음원 SS112가 발생시킨 유닛 음향 데이터 A2에 비해 음량이 클 수 있다. 도 11의 (b)를 참조하면, 디바이스는 영상의 음질을 향상시키기 위해, 유닛 음향 데이터 A1의 음량을 줄 이고, 유닛 음향 데이터 A2의 음량을 키워 A1과 A2의 음량을 같은 레벨로 조정할 수 있다. 유닛 음향 데이터 A1 및 A2의 음량이 동일한 레벨로 조정되면, 영상의 전체적인 음향의 음량이 일정하게 유지될 수 있으므로, 영상의 음질이 향상될 수 있다. 도 12는 본 개시의 일 실시예에 따른 디바이스가 추적된 음원의 움직임에 따라 유닛 음향 데이터의 음량 을 개별적으로 조정하는 예시를 나타내는 도면이다. 일 실시예에서, 디바이스가 촬영 중인 피사체(음원)(SS120)는 음향을 발생시키면서 이동중일 수 있다. 예 를 들어, 피사체는 초기 위치(SS120i) 및 최종 위치(SS120f)를 가질 수 있다. 일 실시예에서, 피사체는 디바이 스에서 멀어지는 방향으로 이동할 수 있다. 이 때, 피사체의 초기 위치(SS120i)는 디바이스에서 상 대적으로 가깝고, 피사체의 최종 위치(SS120f)는 디바이스에서 상대적으로 멀 수 있다. 도 12의 (a)를 참조하면, 피사체의 초기 위치(SS120i)에서 발생한 초기 입력 음향(Ai)의 음량은 크고, 음원이 디바이스에서 멀어질수록 음량이 작아질 수 있다. 피사체의 최종 위치(SS120f)에서 발생한 최종 입력 음 향(Af)의 음량은 상대적으로 작을 수 있다. 도 12의 (b)를 참조하면, 일 실시예에서, 디바이스는 영상의 음질을 향상시키기 위해, 초기 입력 음향 (Ai)의 음량을 줄이고, 최종 입력 음향(Af)의 음량을 키우는 등, 시간에 따른 음량의 조정 정보를 포함하는 음 량 보정 곡선을 획득할 수 있다. 디바이스는 획득한 음량 보정 곡선을 이용하여 음향의 음량을 조정할 수 있고, 영상의 전체 실행 시간 내에 출력 음향의 음량이 동일한 레벨로 유지되도록 할 수 있다. 도 13은 본 개시의 일 실시예에 따른 디바이스가 추적된 음원의 움직임에 따라 유닛 음향 데이터의 음량 을 조정하고, 조정된 유닛 음향 데이터로부터 멀티 채널을 갖는 출력 음향을 획득하는 예시를 나타내는 도면이 다. 일 실시예에서, 디바이스가 촬영 중인 피사체(음원)(SS130)는 음향을 발생시키면서, 디바이스에 대 해 상대적으로 이동할 수 있다. 초기 시간(Ti)에서, 피사체는 디바이스의 먼 우측에 위치하였다가, 최종 시간(Tf)로 갈수록 디바이스에 가까운 좌측으로 이동할 수 있다. 이 때, 피사체의 초기 위치(SS130i)는 디바이스에서 상대적으로 멀고, 피사체의 최종 위치(SS130f)는 디바이스에서 상대적으로 가까울 수 있다. 도 13의 (a)를 참조하면, 초기 시간(Ti)에서, 초기 위치(SS130i)로부터 발생한 초기 입력 음향(Ai)의 음량은 작 을 수 있다. 음원(SS130)이 디바이스에 가까워질수록 음량이 커지며, 도 13의 (c)를 참조하면, 최종 시간 (Tf)에서, 최종 위치(SS130f)로부터 발생한 최종 입력 음향(Af)의 음량은 상대적으로 클 수 있다. 일 실시예에서, 디바이스는 영상의 음질을 향상시키기 위해, 초기 입력 음향(Ai)의 음량을 키우고, 최종 입력 음향(Af)의 음량을 줄이는 등, 시간에 따른 음량의 조정 정보를 포함하는 음량 보정 곡선을 획득할 수 있 다. 디바이스는 획득한 음량 보정 곡선을 이용하여 음향의 음량을 조정할 수 있고, 영상의 전체 실행 시 간 내에 출력 음향의 음량이 동일한 레벨로 유지되도록 할 수 있다. 더욱 실감나는 음질을 획득하기 위해, 디바이스는 음원의 위치에 따라 출력 음향을 멀티 채널 오디오로 렌더링할 수 있다. 예를 들어, 음원(SS130i)이 화면 상 우측에 위치하는 초기 시간(Ti) 부근에서는 우채널(RC i)의 음량을 키워 렌더링할 수 있다. 도 13의 (b)를 참조하면, 초기 시간(Ti)에서, 출력 음향은 우채널(RCi)의 음량은 크고, 좌채널(LCi)의 음량은 작게 조정될 수 있다. 도 13의 (d)를 참조하면, 음원(SS130f)이 화면 상 좌측에 위치하는 최종 시간(Tf) 부근에서는 좌채널(LCf)의 음 향이 우채널(RCf)의 음향보다 잘 들리도록 우채널(RCf)의 음량을 줄여 렌더링할 수 있다. 예를 들어, 최종 시간 (Tf)에서, 출력 음향은 우채널(RCf)의 음량은 작고, 좌채널(LCf)의 음량은 크게 조정될 수 있다. 도 14는 본 개시의 일 실시예에 따른 디바이스가 보조 입력부를 통해 추가적인 음향을 획득하고, 멀티 채널을 갖는 출력 음향을 획득하는 예시를 나타내는 도면이다. 일 실시예에서, 디바이스는 입력부를 통해 직접 획득한 음향 A1 및 디바이스 외부의 보조 입력부 를 통해 획득한 음향 A2를 포함하는 음향을 획득할 수 있다. 보조 입력부는 예를 들어, 마이크를포함하는 웨어러블 디바이스(wearable device)일 수 있다. 도 14의 (a)를 참조하면, 음원(SS140)이 디바이스로부터 먼 곳에 위치하는 경우, 디바이스의 입력 부에서 직접 획득한 음향(A1)은 음량이 작고, 신호 대 잡음비가 낮을 수 있다. 한편, 보조 입력부는 항상 음원(SS140)으로부터 가까운 곳에 위치하므로, 보조 입력부를 통해 획득한 음향(A2)은 음량이 크고 선명 하며, 신호 대 잡음비가 높다. 신호 대 잡음비(Signal-to-Noise Ratio, SNR)는 신호의 세기와 노이즈의 세기의 비율이다. 일 실시예에서, 신호 대 잡음비에 있어서 신호는 유효한 음향 데이터를 의미할 수 있다. 신호 대 잡음비가 높을수록 노이즈가 적음을 의미한다. 일 실시예에서, 디바이스는, 영상의 음질을 향상시키기 위해, 보조 입력부에서 획득한 음향(A2)을 이용하여 음향의 노이즈를 줄이고, 출력 음향의 음량을 기 설정된 레벨로 조정할 수 있다. 더욱 실감나는 음질을 획득하기 위해, 디바이스는 음원(SS140)의 위치에 따라 출력 음향을 멀티 채널 오 디오로 렌더링할 수 있다. 예를 들어, 도 14를 참조하면 음원(SS140)이 화면 상 우측에 위치할 수 있다. 도 14 의 (b)를 참조하면, 이 경우, 좌측 채널(LC)의 음량은 작고, 우측 채널(RC)의 음량은 크게 조정하여 출력 음향 을 렌더링할 수 있다. 본 개시의 일 실시예는, 영상의 이미지로부터 적어도 하나의 음원(sound source)을 나타내는 음원 이미지를 분 리하고, 영상의 음향을 동일한 음원에서의 발생 여부에 따라 유닛 음향 데이터로 분리함으로써, 입력 음향의 채 널 개수와 관계 없이 음향을 처리할 수 있다. 또한, 분리된 유닛 음향 데이터를 단일한 채널 또는 멀티 채널로 렌더링함으로써, 입력 음향의 채널과 무관하게 출력 음향의 채널 개수를 조절할 수 있다. 본 개시의 일 실시예 는, 분리된 음원 이미지와 유닛 음향 데이터를 각각 매칭시키고, 유닛 음향 데이터 각각의 음량(loudness)을 조 정함으로써, 출력 영상의 음질을 향상시킬 수 있다. 뿐만 아니라, 본 개시의 일 실시예는, 모바일 디바이스에 포함된 입력부를 통해 영상을 촬영하고, 모바일 디바 이스에 포함된 프로세서가 자동으로 촬영된 영상의 음향 처리를 수행함으로써, 음질의 향상을 위해 별도의 음향 장비가 요구되지 않고, 사용자가 수동으로 후처리 동작을 수행하지 않을 수 있다. 본 개시의 일 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어를 포 함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의 의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령 어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독가능 명령 어, 데이터 구조, 또는 프로그램 모듈과 같은 변조된 데이터 신호의 기타 데이터를 포함할 수 있다. 또한, 컴퓨터에 의해 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다 는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경 우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 본 명세서에서, “부”는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로 세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN(Convolutional Neural Network), DNN(Deep Neural Network), RNN(Recurrent Neural Network), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크(Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은 학습을 통해 만들어 질 수 있다. 여기서, 학습을 통해 만들어진다는 것은, 기본 인공지능 모델 이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하 도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경망 연산을 수행한다."}
{"patent_id": "10-2020-0118500", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10a 도면10b 도면10c 도면11 도면12 도면13 도면14"}
{"patent_id": "10-2020-0118500", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 디바이스가 영상의 음질을 향상시키는 방법의 개요도이다. 도 2는 본 개시의 일 실시예에 따른 디바이스의 블록도이다. 도 3은 본 개시의 일 실시예에 따른 영상의 음질을 향상시키는 방법의 흐름도이다. 도 4는 본 개시의 일 실시예에 따른 영상의 음질을 향상시키는 방법의 흐름도이다. 도 5는 본 개시의 일 실시예에 따른 디바이스가 보조 입력부를 통해 추가적인 음향을 획득하는 동작을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시예에 따른 디바이스가 이미지로부터 적어도 하나의 음원 이미지를 획득하는 동작을 설 명하기 위한 도면이다. 도 7은 본 개시의 일 실시예에 따른 디바이스가 음향으로부터 적어도 하나의 유닛 음향 데이터를 획득하는 동작 을 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시예에 따른 디바이스가 음원 이미지에 따라 음향을 분리하고, 분리된 유닛 음향 데이터 를 각각의 음원 이미지에 매칭하는 동작을 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시예에 따른 디바이스가 추적된 음원의 움직임에 따라 유닛 음향 데이터의 음량을 개별 적으로 조정하는 동작의 구체적인 실시예를 설명하기 위한 도면이다. 도 10a는 본 개시의 일 실시예에 따른 디바이스가 멀티 채널을 갖는 출력 음향을 획득하는 예시를 나타내는 도 면이다. 도 10b는 본 개시의 일 실시예에 따른 디바이스가 멀티 채널을 갖는 출력 음향을 획득하는 예시를 나타내는 도 면이다. 도 10c는 본 개시의 일 실시예에 따른 디바이스가 멀티 채널을 갖는 출력 음향을 획득하는 예시를 나타내는 도 면이다. 도 11은 본 개시의 일 실시예에 따른 디바이스가 유닛 음향 데이터의 음량을 개별적으로 조정하는 예시를 나타 내는 도면이다. 도 12는 본 개시의 일 실시예에 따른 디바이스가 추적된 음원의 움직임에 따라 유닛 음향 데이터의 음량을 개별 적으로 조정하는 예시를 나타내는 도면이다. 도 13은 본 개시의 일 실시예에 따른 디바이스가 추적된 음원의 움직임에 따라 유닛 음향 데이터의 음량을 조정 하고, 조정된 유닛 음향 데이터로부터 멀티 채널을 갖는 출력 음향을 획득하는 예시를 나타내는 도면이다. 도 14는 본 개시의 일 실시예에 따른 디바이스가 보조 입력부를 통해 추가적인 음향을 획득하고, 멀티 채널을 갖는 출력 음향을 획득하는 예시를 나타내는 도면이다."}
