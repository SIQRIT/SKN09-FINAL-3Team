{"patent_id": "10-2020-0051815", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0133083", "출원번호": "10-2020-0051815", "발명의 명칭": "카메라를 이용하여 공간의 깊이를 획득하는 디바이스 및 방법", "출원인": "삼성전자주식회사", "발명자": "유병욱"}}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디바이스가 카메라 모듈을 이용하여 특징 영역의 깊이를 획득하는 방법에 있어서,카메라 모듈을 기설정된 각도로 순차적으로 회전시키면서 상기 카메라의 주변을 복수회 촬영함으로써 복수의 이미지들을 획득하는 단계;상기 복수의 이미지들 중 제1 이미지 및 제n 이미지 사이의 서로 인접한 이미지들을 비교함으로써, 상기 제1 이미지 내의 제1 특징 영역 및 상기 제n 이미지 내의 상기 제1 특징 영역과 동일한 제n 특징 영역을 식별하는 단계;상기 제1 이미지를 촬영할 때의 상기 카메라 모듈의 배치 및 상기 n번째 이미지를 촬영할 때의 상기 카메라 모듈의 배치에 기초하여, 상기 제1 이미지 및 상기 제n 이미지에 대한 베이스 라인(base line) 값을 획득하는 단계;상기 제1 이미지 내의 상기 제1 특징 영역의 위치 및 상기 제n 이미지 내의 상기 제n 특징 영역의 위치에 기초하여, 상기 제1 특징 영역 및 상기 제n 특징 영역 간의 디스패리티(disparity) 값을 획득하는 단계; 및상기 베이스 라인 값 및 상기 디스패리티 값에 기초하여, 상기 제1 특징 영역 또는 상기 제n 특징 영역의 깊이를 산출하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 복수의 이미지들을 획득하는 단계는,상기 카메라 모듈을 소정의 촬영 각도 범위 내에서 소정의 각도 간격으로 패닝시키면서 상기 카메라의 주변을순차적으로 촬영하는 것인, 방법."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 제1 특징 영역 및 상기 제n 특징 영역을 식별하는 단계는,상기 복수의 이미지 내의 상기 제1 이미지 내지 상기 제n 이미지 중에서, 서로 인접한 이미지들을 순차적으로비교함으로써, 상기 제1 이미지 내지 상기 제n 이미지 내의 특징 영역들 중에서, 상기 제1 특징 영역과 동일한특징 영역들을 식별하는 단계;를 포함하는 것인, 방법."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 카메라 모듈이 기설정된 각도로 순차적으로 회전됨으로써, 상기 카메라 모듈의 촬영 각도가 변경되며,상기 제1 이미지 및 상기 제n 이미지에 대한 상기 베이스 라인 값은, 상기 제1 이미지를 획득할 때의 상기 카메라 모듈의 카메라 렌즈의 위치와 상기 제1 이미지를 획득할 때의 상기 카메라 모듈의 카메라 렌즈의 위치 사이공개특허 10-2021-0133083-3-의 거리 값에 기초하여 결정되는 것인, 방법."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 디스패리티 값을 획득하는 단계는,상기 제1 이미지를 촬영할 때의 상기 카메라 모듈의 촬영 방향 및 상기 제n 이미지를 촬영할 때의 상기 카메라모듈의 촬영 방향이 서로 평행해지도록, 상기 제1 이미지를 촬영할 때의 상기 카메라 모듈 및 상기 제n 이미지를 촬영할 때의 상기 카메라 모듈을 가상으로 배치하는 단계;상기 배치된 카메라 모듈들의 촬영 방향에 기초하여 상기 제1 이미지 및 상기 제n 이미지를 배열하는 단계; 및상기 배열된 제1 이미지 내의 상기 제1 특징 영역 및 상기 배열된 상기 제n 이미지 내의 상기 제n 특징 영역 사이의 거리 값을 획득하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 배치하는 단계는, 상기 제1 이미지 및 상기 제n 이미지에 대한 상기 베이스 라인 값을 유지하면서, 상기제1 이미지를 촬영할 때의 상기 카메라 모듈 및 상기 제n 이미지를 촬영할 때의 상기 카메라 모듈을 가상으로배치하는 것인, 방법."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 깊이를 산출하는 단계는, 상기 베이스 라인 값, 상기 디스패리티 값 및 상기 제1 이미지 및 상기 제n 이미지를 촬영할 때의 상기 카메라 모듈의 초점 거리에 기초하여 상기 깊이를 산출하는 것인, 방법."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서,상기 카메라 모듈의 촬영 모드를 결정하는 단계; 및상기 촬영 모드에 따라 미리 설정된 촬영 각도 범위를 식별하는 단계;를 더 포함하며,상기 복수의 이미지들을 획득하는 단계는, 상기 식별된 촬영 각도 범위 내에서 상기 기설정된 각도로 상기 카메라 모듈을 순차적으로 회전시키면서 상기 복수의 이미지들을 획득하는 것인, 방법."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 촬영 모드는, 상기 카메라 모듈 주변의 사용자의 제스처를 식별하기 위한 제스처 인식 모드 및 상기 카메라 모듈 주변의 공간을 인식하기 위한 공간 인식 모드를 포함하는 것인, 방법.공개특허 10-2021-0133083-4-청구항 10 제1 항에 있어서,상기 복수의 이미지들을 획득하는 단계는,상기 카메라 모듈의 초점 거리를 결정하는 단계;를 더 포함하며,상기 결정된 초점 거리에 따라, 상기 카메라의 주변이 촬영되는 것인, 방법."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "카메라 모듈을 이용하여 특징 영역의 깊이를 획득하는 디바이스에 있어서,카메라 모듈;상기 카메라 모듈을 소정 각도로 회전시키는 촬영 방향 제어 유닛;디스플레이;하나 이상의 인스트럭션을 저장하는 메모리; 및상기 하나 이상의 인스터럭션을 실행하는 프로세서;를 포함하며,상기 프로세서는,상기 촬영 방향 제어 유닛 및 상기 카메라 모듈을 제어함으로써, 상기 카메라 모듈을 기설정된 각도로 순차적으로 회전시키면서 상기 카메라의 주변을 복수회 촬영하여 복수의 이미지들을 획득하고,상기 복수의 이미지들 중 제1 이미지 및 제n 이미지 사이의 서로 인접한 이미지들을 비교함으로써, 상기 제1 이미지 내의 제1 특징 영역 및 상기 제n 이미지 내의 상기 제1 특징 영역과 동일한 제n 특징 영역을 식별하고,상기 제1 이미지를 촬영할 때의 상기 카메라 모듈의 배치 및 상기 n번째 이미지를 촬영할 때의 상기 카메라 모듈의 배치에 기초하여, 상기 제1 이미지 및 상기 제n 이미지에 대한 베이스 라인(base line) 값을 획득하고,상기 제1 이미지 내의 상기 제1 특징 영역의 위치 및 상기 제n 이미지 내의 상기 제n 특징 영역의 위치에 기초하여, 상기 제1 특징 영역 및 상기 제n 특징 영역 간의 디스패리티(disparity) 값을 획득하고,상기 베이스 라인 값 및 상기 디스패리티 값에 기초하여, 상기 제1 특징 영역 또는 상기 제n 특징 영역의 깊이를 산출하는, 디바이스."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 카메라 모듈을 소정의 촬영 각도 범위 내에서 소정의 각도 간격으로 패닝시키면서 상기 카메라의 주변을 순차적으로 촬영하는 것인, 디바이스."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11 항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행하여,상기 복수의 이미지 내의 상기 제1 이미지 내지 상기 제n 이미지 중에서, 서로 인접한 이미지들을 순차적으로비교함으로써, 상기 제1 이미지 내지 상기 제n 이미지 내의 특징 영역들 중에서, 상기 제1 특징 영역과 동일한공개특허 10-2021-0133083-5-특징 영역들을 식별하는 것인, 디바이스."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11 항에 있어서,상기 카메라 모듈이 기설정된 각도로 순차적으로 회전됨으로써, 상기 카메라 모듈의 촬영 각도가 변경되며,상기 제1 이미지 및 상기 제n 이미지에 대한 상기 베이스 라인 값은, 상기 제1 이미지를 획득할 때의 상기 카메라 모듈의 카메라 렌즈의 위치과 상기 제1 이미지를 획득할 때의 상기 카메라 모듈의 카메라 렌즈의 위치 사이의 거리 값에 기초하여 결정되는 것인, 디바이스."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11 항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 제1 이미지를 촬영할 때의 상기 카메라 모듈의 촬영 방향 및 상기 제n 이미지를 촬영할 때의 상기 카메라모듈의 촬영 방향이 서로 평행해지도록, 상기 제1 이미지를 촬영할 때의 상기 카메라 모듈 및 상기 제n 이미지를 촬영할 때의 상기 카메라 모듈을 가상으로 배치하고,상기 배치된 카메라 모듈들의 촬영 방향에 기초하여 상기 제1 이미지 및 상기 제n 이미지를 배열하고,상기 배열된 제1 이미지 내의 상기 제1 특징 영역 및 상기 배열된 상기 제n 이미지 내의 상기 제n 특징 영역 사이의 거리 값을 획득하는, 디바이스."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 제1 이미지 및 상기 제n 이미지에 대한 상기 베이스 라인 값을 유지하면서, 상기 제1 이미지를 촬영할 때의 상기 카메라 모듈 및 상기 제n 이미지를 촬영할 때의 상기 카메라 모듈을 가상으로 배치하는 것인,디바이스."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11 항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 베이스 라인 값, 상기 디스패리티 값 및 상기 제1 이미지 및 상기 제n 이미지를 촬영할 때의 상기 카메라모듈의 초점 거리에 기초하여 상기 깊이를 산출하는 것인, 디바이스."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11 항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 카메라 모듈의 촬영 모드를 결정하고,상기 촬영 모드에 따라 미리 설정된 촬영 각도 범위를 식별하며,공개특허 10-2021-0133083-6-상기 식별된 촬영 각도 범위 내에서 상기 기설정된 각도로 상기 카메라 모듈을 순차적으로 회전시키면서 상기복수의 이미지들을 획득하는 것인, 디바이스."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18 항에 있어서,상기 촬영 모드는, 상기 카메라 모듈 주변의 사용자의 제스처를 식별하기 위한 제스처 인식 모드 및 상기 카메라 모듈 주변의 공간을 인식하기 위한 공간 인식 모드를 포함하는 것인, 디바이스."}
{"patent_id": "10-2020-0051815", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2020-0051815", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "카메라를 이용하여 공간의 깊이를 획득하는 디바이스 및 방법이 제공된다. 디바이스가 카메라 모듈을 이용하여 특징 영역의 깊이를 획득하는 방법은, 카메라 모듈을 기설정된 각도로 순차적으로 회전시키면서 상기 카메라의 주변을 복수회 촬영함으로써 복수의 이미지들을 획득하는 단계; 상기 복수의 이미지들 중 제1 이미지 및 제n 이 미지 사이의 서로 인접한 이미지들을 비교함으로써, 상기 제1 이미지 내의 제1 특징 영역 및 상기 제n 이미지 내 의 상기 제1 특징 영역과 동일한 제n 특징 영역을 식별하는 단계; 상기 제1 이미지 및 상기 제n 이미지에 대한 베이스 라인(base line) 값을 획득하는 단계; 상기 제1 특징 영역 및 상기 제n 특징 영역 간의 디스패리티 (disparity) 값을 획득하는 단계; 및 상기 베이스 라인 값 및 상기 디스패리티 값에 기초하여, 상기 제1 특징 영 역 또는 상기 제n 특징 영역의 깊이를 산출하는 단계;를 포함한다."}
{"patent_id": "10-2020-0051815", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 카메라를 이용하여 공간의 깊이를 획득하는 디바이스 및 방법에 관한 것으로서, 회전하는 카메라를 이용하여 주변 공간의 깊이 값을 산출하는 디바이스 및 방법에 관한 것이다."}
{"patent_id": "10-2020-0051815", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "증강 현실(Augmented Reality)은 현실 세계의 물리적 환경 공간이나 현실 객체(real world object) 상에 가상 이미지를 투영시켜 하나의 이미지로 보여주는 기술이다. 증강 현실 장치는 사용자의 안면부나 두부에 착용된 상태에서 사용자의 눈앞에 배치되는, 시스루(see-through) 형태의 디스플레이 모듈을 통해 현실 장면과 가상 이미지를 함께 볼 수 있게 한다. 이러한 증강 현실 장치에 대 한 연구가 활발히 진행됨에 따라 다양한 형태의 착용형 장치들이 출시되거나 출시가 예고 되고 있다. 예를 들어, 안경형 디스플레이 장치(wearable glasses)나 헤드마운트 디스플레이 장치(Head Mounted Display)가 현 재 출시되거나 출시가 예고되고 있는 착용형 디스플레이 장치이다. 이러한 증강 현실 장치는 사용자의 제스처를 인식하거나 가상 객체를 실제 객체와 자연스럽게 연동하여 표시하 기 위해 실제 객체의 깊이를 측정할 필요가 있다. 그런데, 기존의 증강 현실 장치는 주변 공간 내의 객체들을 인식하기 위하여 복수의 카메라 또는 TOF(Time of Flight) 카메라를 이용하여 주변 공간의 깊이를 측정하였으며, 이로 인하여 카메라의 무게 또는 개수가 증가하는 문제가 있었다. 또한, 이로 인하여 증강 현실 장치의 부피, 무게 및 배터리 소모량이 증가하는 등과 같은 문제가 발생하였다. 이에 따라, 증강 현실 장치가 사용자에 의해 장시간 착용되거나 자주 착용되는 경우에도, 사용자가 불편함을 느 끼지 않도록, 증강 현실 장치를 경량화하고 소형화하는 것이 중요하다."}
{"patent_id": "10-2020-0051815", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일 실시예는, 하나의 카메라 모듈을 기설정된 각도로 순차적으로 회전시키면서 상기 카메라의 주변을 복수회 촬영함으로써 획득되는 이미지들을 비교함으로써, 디바이스를 경량화하면서도 특정 영역의 깊이를 효과 적으로 산출할 수 있는 디바이스 및 방법을 제공할 수 있다. 또한, 본 개시의 일 실시예는, 순차적으로 촬영된 복수의 이미지들 중 서로 인접한 이미지들을 비교하여 이미지 들 내의 동일한 특정 영역을 효율적으로 식별하고, 식별된 특정 영역들의 위치에 기초하여 특정 영역들의 깊이 값을 산출할 수 있는 디바이스 및 방법을 제공할 수 있다. 또한, 본 개시의 일 실시예는, 촬영 모드에 따라 카메라 모듈을 통한 촬영 각도 범위를 설정할 수 있는 디바이 스 및 방법을 제공할 수 있다."}
{"patent_id": "10-2020-0051815", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 카메라 모듈을 기설정된 각도 로 순차적으로 회전시키면서 상기 카메라의 주변을 복수회 촬영함으로써 복수의 이미지들을 획득하는 단계; 상 기 복수의 이미지들 중 제1 이미지 및 제n 이미지 사이의 서로 인접한 이미지들을 비교함으로써, 상기 제1 이미 지 내의 제1 특징 영역 및 상기 제n 이미지 내의 상기 제1 특징 영역과 동일한 제n 특징 영역을 식별하는 단계; 상기 제1 이미지를 촬영할 때의 상기 카메라 모듈의 배치 및 상기 n번째 이미지를 촬영할 때의 상기 카메라 모 듈의 배치에 기초하여, 상기 제1 이미지 및 상기 제n 이미지에 대한 베이스 라인(base line) 값을 획득하는 단 계; 상기 제1 이미지 내의 상기 제1 특징 영역의 위치 및 상기 제n 이미지 내의 상기 제n 특징 영역의 위치에 기초하여, 상기 제1 특징 영역 및 상기 제n 특징 영역 간의 디스패리티(disparity) 값을 획득하는 단계; 및 상 기 베이스 라인 값 및 상기 디스패리티 값에 기초하여, 상기 제1 특징 영역 또는 상기 제n 특징 영역의 깊이를 산출하는 단계;를 포함하는, 디바이스가 카메라 모듈을 이용하여 특징 영역의 깊이를 획득하는 방법을 제공할 수 있다. 또한, 본 개시의 제2 측면은, 카메라 모듈; 상기 카메라 모듈을 소정 각도로 회전시키는 촬영 방향 제어 유닛; 디스플레이; 하나 이상의 인스트럭션을 저장하는 메모리; 및 상기 하나 이상의 인스터럭션을 실행하는 프로세서;를 포함하며, 상기 프로세서는, 상기 촬영 방향 제어 유닛 및 상기 카메라 모듈을 제어함으로써, 상기 카메라 모듈을 기설정된 각도로 순차적으로 회전시키면서 상기 카메라의 주변을 복수회 촬영하여 복수의 이미지 들을 획득하고, 상기 복수의 이미지들 중 제1 이미지 및 제n 이미지 사이의 서로 인접한 이미지들을 비교함으로 써, 상기 제1 이미지 내의 제1 특징 영역 및 상기 제n 이미지 내의 상기 제1 특징 영역과 동일한 제n 특징 영역 을 식별하고, 상기 제1 이미지를 촬영할 때의 상기 카메라 모듈의 배치 및 상기 n번째 이미지를 촬영할 때의 상 기 카메라 모듈의 배치에 기초하여, 상기 제1 이미지 및 상기 제n 이미지에 대한 베이스 라인(base line) 값을 획득하고, 상기 제1 이미지 내의 상기 제1 특징 영역의 위치 및 상기 제n 이미지 내의 상기 제n 특징 영역의 위 치에 기초하여, 상기 제1 특징 영역 및 상기 제n 특징 영역 간의 디스패리티(disparity) 값을 획득하고, 상기 베이스 라인 값 및 상기 디스패리티 값에 기초하여, 상기 제1 특징 영역 또는 상기 제n 특징 영역의 깊이를 산 출하는, 카메라 모듈을 이용하여 특징 영역의 깊이를 획득하는 디바이스를 제공할 수 있다. 또한, 본 개시의 제3 측면은, 제1 측면의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체를 제공할 수 있다."}
{"patent_id": "10-2020-0051815", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 개시에서, '증강 현실(AR: Augmented Reality)'은 현실 세계의 물리적 환경 공간 내에 가상 이미지를 함께 보여주거나 현실 객체와 가상 이미지를 함께 보여주는 것을 의미한다. 아울러, '증강 현실 장치(Augmented Reality Device)'라 함은 '증강 현실(Augmented Reality)'을 표현할 수 있 는 장치로서, 일반적으로 사용자가 안면부(顔面部)에 착용하는 안경 형상의 증강 현실 안경 장치(Augmented Reality Glasses) 뿐만 아니라, 두부(頭部)에 착용하는 헤드 마운트 디스플레이 장치 (HMD : Head Mounted Display Apparatus)나, 증강 현실 헬멧(Augmented Reality Helmet) 등을 포괄한다. 한편, '현실 장면(real scene)'이란 사용자가 증강 현실 장치를 통해서 보는 현실 세계의 장면으로서, 현실 객 체(real world object)를 포함할 수 있다. 또한, '가상 이미지(virtual image)'는 광학 엔진을 통해 생성되는 이미지로 정적 이미지와 동적 이미지를 모두 포함할 수 있다. 이러한 가상 이미지는 현실 장면과 함께 관측되며, 현실 장면 속의 현실 객체에 대한 정보 또는 증강 현실 장치의 동작에 대한 정보나 제어 메뉴 등을 나타내는 이미지일 수 있다. 따라서, 일반적인 증강 현실 장치는 광원에서 생성된 광으로 구성되는 가상 이미지를 생성하기 위한 광학 엔진 과 광학 엔진에서 생성된 가상 이미지를 사용자의 눈까지 안내하고 현실 세계의 장면도 함께 볼 수 있도록 투명 한 재질로 형성된 도광판(Wave guide)을 구비한다. 전술한 바와 같이, 증강 현실 장치는 현실 세계의 장면도 함 께 관측할 수 있어야 하므로 광학 엔진에서 생성된 광을 도광판을 통해 사용자의 눈까지 안내하기 위해서는 기 본적으로 직진성을 가지는 광의 경로를 변경하기 위한 광학 소자(Optical element)가 필요하다. 이 때, 미러 등 에 의한 반사를 이용하여 광 경로를 변경할 수도 있고, DOE(Diffractive optical element), HOE(Holographic optical element) 등과 같은 회절 소자에 의한 회절을 통해 광 경로를 변경할 수도 있으나 이에 한정되는 것은 아니다. 또한, 본 개시에서, 제스처 인식 모드는 소정 임계치보다 작은 촬영 각도 범위에서 근거리에 위치한 사용자의 신체에 의한 제스처를 촬영하기 위한 촬영 모드이며, 공간 인식 모드는 소정 임계치보다 큰 촬영 각도 범위에서 디바이스 주변의 공간을 촬영하기 위한 촬영 모드일 수 있다. 또한, 본 개시에서, 두 이미지에 대한 디스패리티 값은, 촬영된 두 이미지 중에서 한 이미지 내의 어떤 특징 영 역이 다른 이미지에서 얼마나 쉬프트되었는 지를 나타내는 값일 수 있다.또한, 본 개시에서, 베이스 라인 값은 한 이미지를 촬영할 때의 카메라 모듈의 촬영 중심 및 다른 이미지를 촬 영할 때의 카메라 모듈의 촬영 중심 간의 거리를 나타내는 값일 수 있다. 카메라 모듈의 촬영 중심은, 예를 들 어, 카메라 모듈의 렌즈의 중심점일 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 본 개시의 일 실시예에 따른 디바이스가 주변 영역의 깊이를 획득하는 방법의 개요도이다. 도 1을 참조하면, 디바이스는 카메라 모듈을 기설정된 각도로 회전시키면서, 회전되는 카메라 모듈 을 통하여 디바이스의 주변을 순차적으로 촬영하고, 디바이스의 주변이 촬영된 복수의 이미 지들을 획득할 수 있다. 디바이스는 제1 이미지 내지 제n 이미지를 포함하는 복수의 이미지들을 획득하고, 복수의 이미지들 중 인접한 이미지들을 비교함으로써, 복수의 이미지들 내의 동일한 특징 영역들을 식별할 수 있다. 또한, 이를 통하여, 디바이스는 제1 이미지 및 제n 이미지 내의 동일한 특징 영역들 간 의 디스패리티 값을 획득하고, 특징 영역에 대한 깊이 값을 산출할 수 있다. 디바이스는 증강 현실(Augmented Reality)을 표현할 수 있는 증강 현실 장치일 수 있다. 디바이스 는, 예를 들어, 사용자가 안면부(顔面部)에 착용하는 안경 형상의 증강 현실 안경 장치(Augmented Reality Glasses), 및 두부(頭部)에 착용하는 헤드 마운트 디스플레이 장치 (HMD : Head Mounted Display Apparatus)나, 증강 현실 헬멧(Augmented Reality Helmet) 등을 포함할 수 있다. 또한, 디바이스는 스마트폰, 태블릿 PC, PC, 스마트 TV, 휴대폰, PDA(personal digital assistant), 랩 톱, 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단 말기, 네비게이션, 키오스크, MP3 플레이어, 디지털 카메라, 가전기기 및 기타 모바일 또는 비모바일 컴퓨팅 장 치일 수도 있다. 그러나, 이에 제한되지 않으며, 디바이스는 카메라 모듈을 제어하여 획득되는 이미지를 처리할 수 있는 모든 종류의 기기를 포함할 수 있다. 도 2는 본 개시의 일 실시예에 따른 디바이스의 블록도이다. 도 2를 참조하면, 본 개시의 일 실시예에 따른 디바이스는 사용자 입력부, 마이크, 디스플레 이부, 카메라 모듈, 촬영 방향 제어 유닛, 통신 인터페이스, 저장부 및 프로세 서를 포함할 수 있다. 사용자 입력부는, 사용자가 디바이스를 제어하기 위한 데이터를 입력하는 수단을 의미한다. 예를 들어, 사용자 입력부는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠 또는 조그 스위치 중 적어도 하나를 포함할 수 있으나 이에 한정되는 것은 아니다. 사용자 입력부는 후술할 카메라 모듈을 이용하여 디바이스의 주변을 촬영하고 촬영된 이미지 를 기반으로 디바이스 또는 서버(미도시)로부터의 서비스를 제공받기 위한 사용자 입력을 수신할 수 있다. 마이크는, 외부의 음향 신호를 입력 받아 전기적인 음성 데이터로 처리한다. 예를 들어, 마이크은 외부 디바이스 또는 화자로부터의 음향 신호를 수신할 수 있다. 마이크는 외부의 음향 신호를 입력 받는 과정에서 발생 되는 잡음(noise)를 제거하기 위한 다양한 잡음 제거 알고리즘을 이용할 수 있다. 마이크 는 디바이스를 제어하기 위한 사용자의 음성 입력을 수신할 수 있다. 디스플레이부는 디바이스에서 처리되는 정보를 출력한다. 예를 들어, 디스플레이부는, 디바 이스의 주변을 촬영하기 위한 사용자 인터페이스, 디바이스 주변의 촬영된 이미지를 기반으로 제공 되는 서비스에 관련된 정보를 디스플레이할 수 있다. 디바이스는, 일 실시 예에 의하면, 디스플레이 는 AR(Augmented Reality) 영상을 제공할 수 있다. 일 실시 예에 따른 디스플레이는 웨이브 가이 드(미도시)와 디스플레이 모듈(미도시)을 포함할 수 있다. 웨이브 가이드(미도시)는 사용자가 디바이스를 착용할 때, 배면의 일부 영역이 보이는 투명한 소재로 구성될 수 있다. 웨이브 가이드(미도시)는 광이 내부에서 반사되면서 전파될 수 있는 투명 재질의 단층 혹은 다층 구조의 평판으로 구성될 수 있다. 웨이브 가이드(미도 시)는 디스플레이 모듈의 출사면에 마주하여 투사된 가상 이미지의 광을 입력 받을 수 있다. 여기서, 투명 재질 이라 함은, 광이 통과될 수 있는 재질이라는 의미이며, 투명도가 100%가 아닐 수 있으며, 소정의 색상을 지닐 수도 있다. 일 실시 예에서, 웨이브 가이드(미도시)는 투명 재질로 형성됨에 따라, 사용자는 디스플레이(130 0)를 통해 가상 이미지의 가상 객체를 볼 수 있을 뿐만 아니라, 외부 실제 장면(scene)을 볼 수도 있으므로, 웨이브 가이드(미도시)는 시스루 디스플레이(see through display)로 지칭될 수 있다. 디스플레이는 웨이브 가이드를 통해 가상 이미지의 가상 객체를 출력함으로써, 증강 현실(argumented reality) 영상을 제공할 수 있 다. 카메라 모듈은 디바이스의 주변을 촬영할 수 있다. 카메라 모듈은 촬영 기능을 요구하는 애플리케 이션이 실행되는 경우에 이미지 센서를 통해 정지 영상 또는 동영상 등의 화상 프레임을 얻을 수 있다. 이미지 센서를 통해 캡쳐된 이미지는 후술할 프로세서 또는 별도의 이미지 처리부(미도시)를 통해 처리될 수 있 다. 촬영 방향 제어 유닛은 카메라 모듈의 촬영 방향을 변경할 수 있다. 촬영 방향 제어 유닛은 카메라 모듈을 패닝시킴으로써 카메라 모듈의 촬영 방향을 변경할 수 있는 하드웨어 구조를 포함할 수 있다. 촬영 방향 제어 유닛을 통해 카메라 모듈은 소정의 축을 기준으로 시계 또는 반시계 방향 으로 회전될 수 있으며, 카메라 모듈은 소정 각도로 회전하면서 디바이스 주변을 순차적으로 촬영 할 수 있다. 촬영 방향 제어 유닛은, 예를 들어, 카메라 모듈의 근처에 위치한 전자석을 포함하며, 전자석에 전기를 인가함으로써 발생되는 자력을 이용하여 카메라 모듈의 촬영 방향을 제어할 수 있다. 또 는, 촬영 방향 제어 유닛은, 예를 들어, 카메라 모듈에 물리적으로 연결되는 모터를 포함하며, 모 터를 이용하여 카메라 모듈의 촬영 방향을 제어할 수 있다. 하지만, 촬영 방향 제어 유닛이 카메라 모듈의 촬영 방향을 제어하는 방법은 이에 제한되지 않으며, 다양한 방법을 통해 카메라 모듈을 회 전시킴으로써 카메라 모듈의 촬영 방향을 제어할 수 있다. 통신 인터페이스는 디바이스 주변을 촬영하여 획득되는 이미지를 기반으로 서비스를 받기 위한 데 이터를 외부 디바이스(미도시) 및 서버(미도시)와 송수신할 수 있다. 저장부는 후술할 프로세서에 의해 실행될 프로그램을 저장할 수 있고, 디바이스로 입력되거 나 디바이스로부터 출력되는 데이터를 저장할 수 있다. 저장부는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 저장부에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있는데, 예를 들어, 촬영 모드 식별 모듈, 촬영 각도 결정 모듈, 촬영 모듈, 이미지 비교 모듈, 이미지 배열 모 듈, 깊이 산출 모듈, 제스처 인식 모듈 및 공간 인식 모듈을 포함할 수 있다. 프로세서는 디바이스의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 저장부에 저장된 프로그램들을 실행함으로써, 사용자 입력부, 마이크, 디스플레이부, 카메라 모듈 , 촬영 방향 제어 유닛, 통신 인터페이스 및 저장부 등을 전반적으로 제어할 수 있다. 프로세서는 저장부에 저장된 촬영 모드 식별 모듈을 실행함으로써, 카메라 모듈의 촬 영 모드를 식별할 수 있다. 카메라 모듈의 촬영 모드는, 예를 들어, 사용자의 제스처를 인식하기 위한 제 스처 인식 모드 및 디바이스 주변의 공간을 인식하기 위한 공간 인식 모드를 포함할 수 있다. 제스처 인 식 모드는 소정 임계치보다 작은 촬영 각도 범위에서 근거리에 위치한 사용자의 신체에 의한 제스처를 촬영하기 위한 촬영 모드이며, 공간 인식 모드는 소정 임계치보다 큰 촬영 각도 범위에서 디바이스 주변의 공간을 촬영하기 위한 촬영 모드일 수 있다. 프로세서는 기설정된 기준에 따라 카메라 모듈의 촬영 모드를 식별할 수 있다. 예를 들어, 디바이 스의 전원이 켜지거나 디바이스가 비활성화 상태에서 활성화되면, 프로세서는 사용자의 제스 처 입력을 수신하기 위하여 카메라 모듈의 촬영 모드를 제스처 인식 모드로 식별할 수 있다. 또한, 프로 세서는 제스처 인식 모드에서 사용자의 제스처를 인식하고 인식된 제스처에 따라 카메라 모듈의 촬 영 모드를 변경할 수 있다. 프로세서는 제스처에 대응되는 애플리케이션을 실행하고, 실행된 애플리케이 션이 요구하는 촬영 모드에 따라 카메라 모듈의 촬영 모드를 변경할 수 있다. 또한, 예를 들어, 프로세서 는 카메라 모듈을 통한 촬영을 필요로 하지 않는 애플리케이션이 실행되면, 카메라 모듈을 비활성화할 수 있다. 또는, 예를 들어, 디바이스의 전원이 켜지거나 디바이스가 비활성화 상태에서 활성화되면 디바이스 는 카메라 모듈의 촬영 모드를 공간 인식 모드로 식별할 수 있다. 또한, 프로세서는 공간 인 식 모드에서 디바이스의 주변을 촬영함으로써 디바이스의 주변 공간을 인식할 수 있다. 또한, 예를 들어, 프로세서는 디바이스에 대한 기설정된 사용자 입력이 수신되면, 카메라 모듈 의 촬영 모드를 제스처 모드로 또는 공간 인식 모드로 식별할 수 있다. 프로세서는 저장부에 저장된 촬영 각도 결정 모듈을 실행함으로써, 카메라 모듈의 촬 영 각도의 범위를 결정할 수 있다. 프로세서는 식별된 촬영 모드에 따라 촬영 각도의 범위를 결정할 수 있다. 이 경우, 촬영 모드에 따른 촬영 각도의 범위가 미리 설정될 수 있다. 예를 들어, 카메라 모듈의 촬영 모드가 제스처 모드인 경우에 -15도 ~ 15도의 촬영 각도 범위에서 카메라 모듈이 디바이스의 주변을 촬영하도록 설정될 수 있다. 예를 들어, 카메라 모듈이 정면을 향 하고 있을 때의 각도를 0도라고 하면, 카메라 모듈의 촬영 각도 범위가 -15도 ~ 15도인 경우에, 카메라 모듈은 정면을 기준으로 하여 좌측으로 -15도까지 회전하고 우측으로 15도까지 회전할 수 있다. 예를 들어, 카메라 모듈의 촬영 모드가 공간 인식 모드인 경우에 -60도 ~ 60도의 촬영 각도 범위에서 카 메라 모듈이 디바이스의 주변을 촬영하도록 설정될 수 있다. 예를 들어, 카메라 모듈이 정면 을 향하고 있을 때의 각도를 0도라고 하면, 카메라 모듈의 촬영 각도 범위가 -60도 ~ 60도인 경우에, 카 메라 모듈은 정면을 기준으로 하여 좌측으로 -60도까지 회전하고 우측으로 60도까지 회전할 수 있다. 프로세서는 저장부에 저장된 촬영 각도 결정 모듈을 실행함으로써, 카메라 모듈의 촬 영 간격을 결정할 수 있다. 프로세서는 촬영 각도 범위 내에서 얼마만큼의 각도 간격으로 디바이스(100 0)의 주변을 촬영할 지를 결정할 수 있다. 예를 들어, 프로세서는 촬영 각도 범위 내에서 5도 간격으로 디바이스의 주변을 촬영하도록 촬영 간격을 결정할 수 있다. 또한, 카메라 모듈의 촬영 간격은, 예 를 들어, 촬영 모드 및 촬영 환경에 따라 상이하게 설정될 수 있다. 촬영 환경은, 디바이스 주변의 밝기, 피사체의 개수 및 피사체의 움직임 등을 포함할 수 있으나, 이에 제한되지 않는다. 프로세서는 저장부에 저장된 촬영 모듈을 실행함으로써, 카메라 모듈을 통해 디바이스 의 주변을 촬영할 수 있다. 프로세서는 카메라 모듈 및 촬영 방향 제어 유닛을 제어함 으로써, 식별된 촬영 각도의 범위 내에서 결정된 촬영 간격에 따라 디바이스의 주변을 순차적으로 촬영함 으로써 복수의 이미지를 획득할 수 있다. 카메라 모듈은 촬영 각도 범위 내에서 회전하면서 촬영 간격에 따라 디바이스 주변을 복수회 촬영할 수 있다. 카메라 모듈에 의해 촬영된 이미지들 중 인접한 이 미지들의 일부는 서로 중첩될 수 있다. 또는, 프로세서는 카메라 모듈 및 촬영 방향 제어 유닛을 제어함으로써, 촬영 각도 범위 내 에서 카메라 모듈을 회전시키면서 동영상을 촬영할 수 있다. 이 경우, 프로세서는 촬영된 동영상 내의 프레임들 중에서 복수의 프레임을 촬영 간격에 따라 추출할 수 있다. 추출된 프레임들의 이미지들 중 인접 한 이미지들의 일부는 서로 중첩될 수 있다. 프로세서는 저장부에 저장된 촬영 모듈을 실행함으로써, 카메라 모듈의 초점 거리를 변경할 수 있다. 카메라 모듈이 소정 임계치보다 가까운 거리에 위치한 피사체들을 촬영하는 경우에, 프 로세서는 카메라 모듈의 초점 거리를 변경하지 않을 수 있다. 카메라 모듈이 활성화되는 경 우에 카메라 모듈의 초점 거리는 가까운 거리에 위치한 피사체를 측정할 수 있도록 설정되어 있을 수 있 으며, 이로 인하여, 가까운 거리의 피사체를 촬영하기 위하여 프로세서는 카메라 모듈의 초점 거리 를 변경하지 않을 수 있다. 또한, 소정 거리 값 부근의 가까운 거리의 피사체들을 촬영하기 위한 초점 거리는 실질적으로 거의 동일하기 때문에, 프로세서는 카메라 모듈의 초점 거리를 변경하지 않을 수 있다. 또한, 카메라 모듈이 소정 임계치보다 먼 거리에 위치한 피사체들을 촬영하는 경우에, 프로세서는 초점 거리를 피사체에 따라 변경하면서 카메라 모듈이 변경된 초점 거리에 따라 디바이스의 주변을 촬영을 하도록 카메라 모듈을 제어할 수 있다. 프로세서는 저장부에 저장된 이미지 비교 모듈을 실행함으로써, 카메라 모듈을 통해 획득된 복수의 이미지들 중 인접한 이미지들을 비교할 수 있다. 프로세서는 인접한 이미지들을 서로 비교 함으로써, 인접한 이미지들 내의 동일한 특징 영역들을 식별할 수 있다. 예를 들어, 카메라 모듈로부터 5개의 이미지가 획득된 경우에 프로세서는 제1 이미지와 제2 이미지 를 비교하고, 제2 이미지와 제3 이미지를 비교하고, 제3 이미지와 제4 이미지를 비교하고, 제4 이미지와 제5 이 미지를 비교할 수 있다. 또한, 프로세서는 제1 이미지 내의 제1 특징 영역이 제2 이미지 내의 제2 특징영역과 동일함을 식별하고, 제2 이미지 내의 제2 특징 영역이 제3 이미지 내의 제3 특징 영역과 동일함을 식별 하고, 제3 이미지 내의 제3 특징 영역이 제4 이미지 내의 제4 특징 영역과 동일함을 식별하고, 제4 이미지 내의 제4 특징 영역이 제5 이미지 내의 제5 특징 영역과 동일함을 식별할 수 있다. 이에 따라, 프로세서는 제1 이미지 내의 제1 특징 영역과 제5 이미지 내의 제5 특징 영역이 동일함을 보다 효과적으로 식별할 수 있다. 또 한, 예를 들어, 이미지 내의 특징 영역은 소정의 특징점(feature point)일 수 있다. 프로세서는 저장부에 저장된 이미지 배열 모듈을 실행함으로써, 복수의 이미지들 중 선택된 두 이미지를 배열할 수 있다. 프로세서는, 특징 영역의 깊이를 산출하기 위하여, 복수의 이미지들 중에서 소정 임계치 이상으로 촬영 각도가 상이한 두 이미지를 선택할 수 있다. 예를 들어, 프로세서는 복수의 이미지들 중에서 촬영 각도의 차이가 가장 크지만 동일한 특징 영역을 포함하고 있는 두 이미지를 선택함으로써, 특징 영역의 깊이가 보다 정확하게 산출되도록 할 수 있다. 예를 들어, 카메라 모듈로부터 5개의 이미지가 획득된 경우에 프로세서는 획득된 5개의 이미지들 중에서, 소정 수치 이상으로 상이한 제 1 이미지 및 제5 이미지를 선택할 수 있다. 또한, 프로세서는 선택된 두 이미지에 대한 디스패리티 값을 획득하기 위하여 두 이미지를 가상으로 배열 할 수 있다. 두 이미지에 대한 디스패리티 값은, 촬영된 두 이미지 중에서 한 이미지 내의 어떤 특징 영역이 다 른 이미지에서 얼마나 쉬프트되었는 지를 나타내는 값일 수 있다. 프로세서는 카메라 모듈의 촬영 방향이 서로 평행해지도록 카메라 모듈을 가상으로 배치할 수 있다. 예를 들어, 제1 이미지를 촬영할 때의 카메라 모듈과 제5 이미지를 촬영할 때의 카메라 모듈 간의 베이스 라인 값을 유지하면서, 제1 이미지를 촬영할 때의 카메라 모듈의 촬영 방향 및 제5 이미지를 촬영할 때의 카메라 모듈의 촬영 방향이 평행해지도록, 제1 이미지를 촬영할 때의 카메라 모듈 과 제5 이미지를 촬영할 때의 카메라 모듈을 가상으로 배치할 수 있다. 베이스 라인 값은 한 이미 지를 촬영할 때의 카메라 모듈의 촬영 중심 및 다른 이미지를 촬영할 때의 카메라 모듈의 촬영 중 심 간의 거리를 나타내는 값일 수 있다. 카메라 모듈의 촬영 중심은, 예를 들어, 카메라 모듈의 렌 즈의 중심점일 수 있다. 카메라 모듈을 가상으로 배열하는 방법에 대하여는 후술하기로 한다. 프로세서는 가상으로 배치된 카메라 모듈의 위치를 기준으로 하여 이미지들을 배열할 수 있다. 예 를 들어, 제1 이미지를 촬영할 때의 카메라 모듈의 배치된 위치 및 제5 이미지를 촬영할 때의 카메라 모 듈의 배치된 위치를 기준으로, 제1 이미지 및 제5 이미지가 가상으로 배열될 수 있다. 이 경우, 프로세서(180 0)는 가상으로 배열된 제1 이미지 내의 제1 특징 영역의 위치 및 가상으로 배열된 제5 이미지 내의 제5 특징 영 역의 위치에 기초하여, 제1 이미지 내의 제1 특징 영역 및 제5 이미지 내의 제5 특징 영역 간의 디스패리티 값 을 획득할 수 있다. 예를 들어, 디스패리티 값은 가상으로 배열된 이미지들 내의 동일한 특징 영역들 간의 거리 에 기초하여 산출될 수 있다. 프로세서는 저장부에 저장된 깊이 산출 모듈을 실행함으로써, 특징 영역의 깊이를 산출할 수 있다. 프로세서는 두 이미지 내의 동일한 특징 영역들에 대한 디스패리티 값, 카메라 모듈의 베이 스 라인 값 및 카메라 모듈의 초점 거리를 이용하여, 두 이미지 내의 동일한 특징 영역에 대한 깊이를 산 출할 수 있다. 프로세서는 베이스 라인 값과 초점 거리 간의 비율이 디스패리티 값과 깊이 간의 비율과 동일함을 이용하여, 특징 영역의 깊이를 산출할 수 있다. 프로세서는 이미지 내의 특징 영역들의 깊이를 산출함으로써, 디바이스 주변 공간에 대한 깊이 맵 (depth map)을 생성할 수 있다. 깊이 맵은 이미지 내에 존재하는 객체들 또는 공간들의 3차원 거리 정보를 나타 내는 이미지로서, 이미지 내의 각 화소값은 해당 화소의 깊이 정보를 나타낼 수 있다. 깊이 정보는, 시점(view point)로부터 특정 화소에 대응되는 공간까지의 거리를 나타내는 값일 수 있다. 깊이 맵은 시점으로부터 먼 부 분과 가까운 부분을 구별되게 나타낼 수 있다. 예를 들어, 깊이 맵에서, 사용자의 시점에서 먼 부분으로부터 가 까운 부분까지가 흰색에서 검정색으로 점점 어두워지도록 그라데이션 방식으로 표시될 수 있다. 이에 따라, 디 바이스의 주변 공간 내의 객체들의 형상 및 깊이가 깊이 맵에서 구별되게 표현될 수 있다. 프로세서는 소정 단위의 이미지 세트들로부터 디바이스 주변 공간의 일부들에 대한 복수의 깊이 맵 을 생성하고, 생성된 복수의 깊이 맵을 연결함으로써 디바이스 주변 공간에 대한 깊이 맵을 완성할 수 있 다. 예를 들어, 카메라 모듈이 회전하면서 디바이스의 주변을 촬영하여 20개의 이미지들을 획득한 경우에, 프로세서는 첫번째 내지 10번째 이미지를 포함하는 제1 이미지 세트로부터 제1 부분 깊이 맵을 생성하고, 6번째 내지 15번째 이미지를 포함하는 제2 이미지 세트로부터 제2 부분 깊이 맵을 생성하고, 11번째 내지 20번째 이미지를 포함하는 제3 이미지 세트로부터 제3 부분 깊이 맵을 생성할 수 있다. 또한, 프로세서는 제1 부분 깊이 맵, 제2 부분 깊이 맵 및 제3 부분 깊이 맵을 이용하여, 전체 깊이 맵을 생성할 수 있 다. 한편, 프로세서는 인공지능 모델을 이용하여 특징 영역의 깊이를 식별할 수 있다. 이 경우, 프로세서 는 이미지들로부터 특징 영역의 깊이를 산출하도록 훈련된 인공지능 모델에 카메라 모듈로부터 촬 영된 이미지들을 입력함으로써 특징 영역의 깊이에 관한 정보를 획득할 수 있다. 인공지능 모델로부터 획득되는 특징 영역의 깊이 정보는 깊이 산출 모듈에 의해 산출된 깊이 정보를 검증하는데 이용될 수 있으나, 이에 제한되지 않는다. 또한, 카메라 모듈을 통해 촬영된 이미지들 및 깊이 산출 모듈에 의해 산출된 깊 이 정보는, 깊이 산출을 위한 인공지능 모델을 업데이트하는데 이용될 수 있다. 또한, 프로세서는 인공지능 모델을 이용하여 깊이 맵을 획득할 수 있다. 이 경우, 프로세서는 이미 지들로부터 깊이 맵을 생성하도록 훈련된 인공지능 모델에 카메라 모듈로부터 촬영된 이미지들을 입력함 으로써, 디바이스 주변 공간에 대한 깊이 맵을 획득할 수 있다. 인공지능 모델로부터 획득되는 깊이 맵은 깊이 산출 모듈에 의해 생성된 깊이 맵을 검증하는데 이용될 수 있으나, 이에 제한되지 않는다. 또한, 카 메라 모듈을 통해 촬영된 이미지들 및 깊이 산출 모듈에 의해 생성된 깊이 맵은, 깊이 맵 생성을 위한 인공지능 모델을 업데이트하는데 이용될 수 있다. 프로세서는 저장부에 저장된 제스처 인식 모듈을 실행함으로써, 사용자의 제스처를 인식할 수 있다. 프로세서는 촬영 각도 범위 내에서 복수회 반복하여 회전하면서 이미지들을 획득할 수 있다. 예 를 들어, 프로세서는 촬영 각도 범위 내에서 첫번째로 회전하면서 n 개의 제1 제스처 이미지 세트를 획득 하고, 촬영 각도 범위 내에서 두번째로 회전하면서 n 개의 제2 제스처 이미지 세트를 획득하고, 촬영 각도 범위 내에서 세번째로 회전하면서 n 개의 제3 제스처 이미지 세트를 획득할 수 있다. 또한, 예를 들어, 프로세서 는 제1 제스처 이미지 세트 내의 이미지들로부터 사용자의 손의 깊이를 산출하여 사용자의 손의 제1 모양 및 제1 위치를 식별할 수 있다. 예를 들어, 프로세서는 제2 제스처 이미지 세트 내의 이미지들로부터 사 용자의 손의 깊이를 산출하여 사용자의 손의 제2 모양 및 제2 위치를 식별할 수 있다. 예를 들어, 프로세서 는 제3 제스처 이미지 세트 내의 이미지들로부터 사용자의 손의 깊이를 산출하여 사용자의 손의 제3 모양 및 제3 위치를 식별할 수 있다. 또한, 프로세서는 사용자의 손의 제1 모양, 제2 모양 및 제3 모양에 기초 하여 사용자의 손의 모양 변화를 식별하고, 식별된 손의 모양 변화에 따른 제스처를 인식할 수 있다. 또한, 프 로세서는 사용자의 손의 제1 위치, 제2 위치 및 제3 위치에 기초하여 손의 위치 변화를 식별하고, 식별된 손의 위치 변화에 따른 제스처를 인식할 수 있다. 프로세서는 사용자의 손의 모양 변화 및 위치 변화를 함께 고려하여 제스처를 인식할 수도 있다. 상기에서는, 사용자의 손에 따른 제스처에 대하여 설명되었지만, 제 스처를 인식하기 위하여 사용자의 손이 아닌 다른 신체 부위가 인식될 수도 있다. 프로세서는 인공지능 모델을 이용하여 제스처를 식별할 수 있다. 이 경우, 프로세서는 이미지들로 부터 사용자의 제스처를 식별하도록 훈련된 인공지능 모델에 카메라 모듈로부터 촬영된 이미지들을 입력 함으로써, 사용자의 제스처를 식별할 수 있다. 인공지능 모델로부터 식별되는 제스처는 제스처 인식 모델에 의 해 인식된 제스처를 검증하는데 이용될 수 있으나, 이에 제한되지 않는다. 또한, 카메라 모듈을 통해 촬 영된 이미지들 및 제스처 인식 모듈에 의해 인식된 제스처는, 제스처 인식을 위한 인공지능 모델을 업데 이트하는데 이용될 수 있다. 프로세서는 저장부에 저장된 공간 인식 모듈을 실행함으로써, 디바이스 주변의 공간을 인식할 수 있다. 프로세서는 디바이스의 주변에 대하여 생성된 깊이 맵으로부터 디바이스 주 변의 특징 영역들이 무엇인지를 식별할 수 있다. 예를 들어, 프로세서는 디바이스 주변의 특징 영 역에 대응되는 객체가 무엇인지에 대한 식별 정보, 디바이스에 대한 특징 영역의 상대적인 위치를 나타내 는 좌표 정보, 디바이스와 특징 영역 간의 거리를 나타내는 깊이 정보 등을 생성할 수 있다. 또한, 프로세서는 디바이스 주변 공간 중에서 인식되지 않은 공간을 식별하고, 인식되지 않은 공간 이 촬영되는 경우에 인식되지 않은 공간에 대한 깊이 맵을 생성하여 전체 깊이 맵에 추가할 수 있다. 이 경우, 프로세서는 카메라 모듈이 디바이스 주변의 어떤 영역을 촬영하였는 지에 관한 이력을 저장 할 수 있으며, 저장된 이력에 기초하여 카메라 모듈이 촬영되지 않은 공간을 향하는 경우에 공간 인식 모 드를 활성화할 수 있다. 프로세서는 인공지능 모델을 이용하여 공간을 인식할 수 있다. 이 경우, 프로세서는 이미지들로부 터 공간 내의 특징 영역을 식별하도록 훈련된 인공지능 모델에 카메라 모듈로부터 촬영된 이미지들 또는 깊이 맵을 입력함으로써, 디바이스의 주변 공간을 인식할 수 있다. 인공지능 모델로부터 인식되는 공간정보는 공간 인식 모델에 의해 인식된 공간을 검증하는데 이용될 수 있으나, 이에 제한되지 않는다. 또한, 카메 라 모듈을 통해 촬영된 이미지들 또는 깊이 맵, 및 공간 인식 모듈에 의해 인식된 공간 정보는, 공 간 인식을 위한 인공지능 모델을 업데이트하는데 이용될 수 있다. 도 3은 본 개시의 일 실시예에 따른 디바이스 내의 카메라 모듈이 회전하는 예시를 나타내는 도면이다. 도 3을 참조하면, 촬영 방향 제어 유닛은 회전 중심을 기준으로 카메라 모듈 시계 또는 반시계 방향으로 회전할 수 있다. 이에 따라, 카메라 모듈은 소정 각도로 회전하면서 디바이스의 주변 을 순차적으로 촬영할 수 있게 된다. 또한, 카메라 모듈은 회전 중심을 중심으로 소정 각도로 패닝 (panning) 또는 틸팅(tilting)되면서 디바이스의 주변을 촬영할 수 있다. 도 4a는 본 개시의 일 실시예에 따른 디바이스 내의 카메라 모듈이 회전하면서 복수의 이미지를 획득하는 예시 를 나타내는 도면이다. 도 4a를 참조하면, 디바이스 내의 카메라 모듈은 소정의 촬영 각도 범위 내에서 시계 또는 반 시계 방향으로 소정 각도씩 회전하면서 디바이스의 주변을 순차적으로 촬영할 수 있다. 예를 들어, 디바 이스는 카메라 모듈을 시계 방향으로 5도씩 회전시키면서 디바이스의 주변을 순차적으로 촬 영할 수 있다. 카메라 모듈의 촬영 각도 범위는 디바이스의 촬영 모드에 따라 상이하게 설정될 수 있다. 예를 들어, 디바이스의 촬영 모드가 제스처 인식 모드인 경우에 촬영 각도 범위는 기준축 을 기준으로 -15도 ~ +15도의 범위로 설정될 수 있다. 또한, 예를 들어, 디바이스의 촬영 모드가 공 간 인식 모드인 경우에 촬영 각도 범위는 기준축을 기준으로 -30도 ~ +30도의 범위일 수 있다. 기준축 은 카메라 모듈이 디바이스의 정면을 향하고 있는 경우의 카메라 모듈의 촬영 방향에 의 해 결정될 수 있다. 디바이스는 카메라 모듈을 통하여 디바이스의 주변을 촬영함으로써, 제1 내지 제n 이미지를 획득할 수 있다. 이 경우, 제1 내지 제n 이미지들 중 인접한 이미지들은 일정 부분이 서로 중첩될 수 있다. 도 4b는 본 개시의 일 실시예에 따른 인접한 이미지들 내의 동일한 특징 영역이 순차적으로 식별되는 예시를 나 타내는 도면이다. 도 4b를 참조하면, 디바이스는 스테레오 매칭(stereo matching) 기법을 통하여 이미지들 내의 동일한 특 징 영역들을 식별할 수 있다. 디바이스는 제1 이미지 내의 제1 특징 영역이 제2 이미지 내의 제2 특징 영 역과 동일함을 식별할 수 있다. 또한, 디바이스는 제2 이미지 내의 제2 특징 영역이 제3 이미지 내의 제3 특징 영역과 동일함을 식별할 수 있다. 이와 같이, 디바이스는 인접한 2개의 이미지들을 순차적으로 비교 함으로써, 제n-1 이미지 내의 제 n-1 특징 영역이 제n 이미지 내의 제n 특징 영역과 동일함을 식별할 수 있다. 도 4c는 본 개시의 일 실시예에 따른 디바이스가 가장 큰 각도 차이가 나는 이미지들 내의 동일한 식별 영역들 을 식별하는 예시를 나타내는 도면이다. 도 4c를 참조하면, 디바이스는 도 4b에서의 식별 결과에 기초하여, 제1 이미지 내의 제1 특징 영역이 제n 이미지 내의 제n 특징 영역과 동일함을 식별할 수 있다. 이에 따라, 디바이스는 제1 내지 제n 이미지들 중에서 촬영 각도 차이가 가장 큰 두 개의 이미지에서 동일한 특징 영역을 식별할 수 있으며, 디바이스는 후술할 특징 영역의 깊이를 보다 정확하게 산출할 수 있게 된다. 인접한 이미지들은 많은 부분이 서로 중첩되며, 인접한 이미지들 내의 동일한 특정 영역들은 인접한 이미지들 내에서 서로 비슷한 위치에 표시되므로, 디바이스는 인접한 이미지들을 비교함으로써 보다 효과적으로 동 일한 특정 영역들을 식별할 수 있게 된다. 예를 들어, 제1 이미지는 다른 이미지들보다 제2 이미지와 더 많은 부분이 중첩되며, 제1 이미지 내에서의 제1 특징 영역의 위치는 제2 이미지 내의 제2 특징 영역의 위치와 차이 가 적기 때문에, 디바이스는 제1 이미지 및 제2 이미지의 보다 적은 부분을 서로 비교하더라도, 디바이스 는 제1 특징 영역 및 제2 특징 영역이 동일함을 효과적으로 정확하게 식별할 수 있게 된다. 또한, 디바이 스는 인접한 이미지들을 순차적으로 비교하고, 순차적으로 비교된 결과들을 이용함으로써 제1 이미지의 제1 특징 영역 및 제n 이미지의 제n 특징 영역이 동일함을 보다 정확하게 식별할 수 있게 된다. 도 4a 내지 도 4c에서는 디바이스가 촬영된 이미지 모두를 이용하여 이미지들 내의 동일한 특징 영역들을 식별하는 것으로 설명하였지만, 이에 제한되지 않는다. 디바이스는 촬영된 이미지들 중 일부인 복수의 이 미지들을 선택하고, 선택된 복수의 이미지들을 비교함으로써 선택된 복수의 이미지들 내의 동일한 특징 영역들 을 식별할 수도 있다. 예를 들어, 제1 내지 제n 이미지들 중에서 제3 내지 제n-3 이미지를 선택하고, 제3 내지제n-3 이미지들 중 인접한 이미지들을 비교함으로써, 제3 이미지 내의 제3 특징 영역 및 제n-3 이미지 내의 제 n-3 특징 영역이 동일함을 식별할 수도 있다. 도 4a 내지 도 4c에서는, 디바이스가 촬영 각도 범위 내에서 가장 작은 촬영 각도에서 촬영된 제1 이미지 및 가장 큰 촬영 각도에서 촬영된 제n 이미지로부터 동일한 특징 영역들을 식별하는 것으로 설명되었지만, 이에 제한되지 않는다. 디바이스는 소정 임계치 이상의 촬영 각도 차이를 가지는 두 이미지들로부터 동일한 특 징 영역들을 식별하고, 식별된 특징 영역들을 이용하여 특징 영역들의 깊이를 산출할 수도 있다. 예를 들어, 디 바이스는 제1 내지 제n 이미지들 중에서 촬영 각도의 차이가 소정 임계치 이상인 제1 이미지 및 제n-3 이 미지를 선택하고, 선택된 제1 이미지 및 제n-3 이미지로부터 동일한 특징 영역들을 식별할 수 있다. 도 5a 내지 도 5c는 본 개시의 일 실시예에 따른 디바이스가 촬영된 이미지를 배열하고 특징 영역의 디스패리티 값을 획득하는 예시를 설명하기 위한 도면이다. 도 5a는 본 개시의 일 실시예에 따른 디바이스가 디바이스의 주변을 촬영하는 예시를 도시한 도면이다. 도 5a를 참조하면, 디바이스는 촬영 각도 범위 내에서 소정 촬영 각도 간격으로 디바이스의 주변을 순차적으로 촬영할 수 있다. 또한, 촬영 각도 범위 내에서 차이가 가장 큰 두 이미지인 제1 이미지를 촬영할 때 의 카메라 모듈(1400-1)의 촬영 중심 및 제n 이미지를 촬영할 때의 카메라 모듈(1400-n)의 촬영 중심에 의해, 제1 이미지 및 제n 이미지에 대한 베이스라인 값(b)이 결정될 수 있다. 예를 들어, 제1 이미지를 촬영할 때의 카메라 모듈(1400-1)의 렌즈 중심 및 제n 이미지를 촬영할 때의 카메라 모듈(1400-n)의 렌즈 중심 간의 거리가 베이스 라인 값(b)일 수 있다. 도 5b는 본 개시의 일 실시예에 따른 디바이스가 카메라 모듈을 가상으로 배치하는 예시를 나타내는 도면이다. 도 5b를 참조하면, 디바이스는 제1 이미지를 촬영할 때의 카메라 모듈(1400-1)과 제n 이미지를 촬영할 때 의 카메라 모듈(1400-n) 간의 베이스 라인 값(b)을 유지하면서, 제1 이미지를 촬영할 때의 카메라 모듈(1400- 1)의 촬영 방향 및 제n 이미지를 촬영할 때의 카메라 모듈(1400-n)의 촬영 방향이 서로 평행해지도록, 제1 이미지를 촬영할 때의 카메라 모듈(1400-1)과 제n 이미지를 촬영할 때의 카메라 모듈(1400-n)을 가상으로 배치할 수 있다. 도 5c는 본 개시의 일 실시예에 따른 디바이스가 디스패리티 값을 산출하는 예시를 나타내는 도면이다. 도 5c를 참조하면, 디바이스는 제1 이미지 및 제n 이미지에서 동일한 특징 영역들의 디스패리티 값(d)을 산출하기 위하여, 제1 이미지 및 제n 이미지를 배열할 수 있다. 예를 들어, 디바이스는 제1 이미지 및 제 n 이미지를 세로축 및 세로축을 따라 배열할 수 있다. 또한, 예를 들어, 제1 이미지 및 제n 이미지의 세로변들이 세로축 및 세로축에 일치하지 않을 수 있다. 이 경우 디바이스는 제1 이미지 및 제n 이미지의 세로변들이 세로축 및 세로축에 일치하도록 제1 이미지 및 제n 이미지를 소정 알고리즘에 따 라 수정(rectification)할 수 있다. 또한, 디바이스는 배열된 제1 이미지 내의 제1 특징 영역의 위치 및 배열된 제 n 이미지 내의 제n 특징 영역의 위치에 기초하여, 제1 특징 영역 및 제n 특징 영역 간의 디스패리티 값(d)를 산출할 수 있다. 예를 들어, 제1 특징 영역 및 제n 특징 영역 간의 디스패리티 값(d)은 제1 특징 영역을 가로지르는 세로선 및 제 n 특징 영역을 가로지르는 세로선 간의 거리에 의해 결정될 수 있다. 도 6은 본 개시의 일 실시예에 따른 디바이스가 특징 영역의 깊이를 산출하는 예시를 나타내는 도면이다. 도 6을 참조하면, 두 이미지 내의 동일한 특징 영역들에 대한 디스패리티 값, 카메라 모듈의 베이스 라 인 값 및 카메라 모듈의 초점 거리를 이용하여, 두 이미지 내의 동일한 특징 영역에 대한 깊이가 산출될 수 있다. 예를 들어, 특징 영역의 깊이(z) 및 카메라 모듈의 초점 거리(f)간의 비율이 디스패리티 값(d) 및 베이스라인 값(b)의 비율과 동일함에 기초하여, 아래의 수학식 1과 같이, 특징 영역의 깊이(z)가 산출될 수 있다. <수학식 1> 특징 영역의 깊이(z) = {디스패리티 값(d) x 초점거리(f)}/베이스라인값(b) 예를 들어, 수학식 1에서, 특징 영역의 깊이(z)는 이미지 내의 동일한 특징 영역들인 제1 특징 영역 및 제n 특 징 영역의 깊이이며, 디스패리티 값(d)은 이미지 내의 제1 특징 영역 및 제n 특징 영역에 대한 디스패리티 값이 며, 베이스 라인 값(b)은 제1 특징 영역을 촬영할 때의 카메라 모듈의 렌즈 중심과 제n 특징 영역을 촬영할 때의 카메라 모듈의 렌즈 중심 간의 거리하며, 초점 거리(f)는 제1 특징 영역 및 제n 특징 영역을 촬 영할 때의 카메라 렌즈의 초점 거리일 수 있다. 도 7은 본 개시의 일 실시예에 따른 디바이스가 이미지 내의 특징 영역의 깊이를 산출하는 방법의 흐름도이다. 동작 S700에서 디바이스는 카메라 모듈을 회전시키면서 디바이스의 주변을 연속하여 촬영할 수 있다. 디바이스는 카메라 모듈 및 촬영 방향 제어 유닛을 제어함으로써, 식별된 촬영 각 도의 범위 내에서 결정된 촬영 간격에 따라 디바이스의 주변을 순차적으로 촬영함으로써 복수의 이미지를 획득할 수 있다. 카메라 모듈은 촬영 각도 범위 내에서 회전하면서 촬영 간격에 따라 디바이스 주 변을 복수회 촬영할 수 있다. 카메라 모듈에 의해 촬영된 이미지들 중 인접한 이미지들의 일부는 서로 중 첩될 수 있다. S710에서 디바이스는 촬영된 복수의 이미지들 중에서 서로 인접한 이미지들을 비교함으로써, 이미지들 내 의 동일한 특징 영역들을 식별할 수 있다. 디바이스는 제1 이미지 내의 제1 특징 영역이 제2 이미지 내의 제2 특징 영역과 동일함을 식별할 수 있다. 또한, 디바이스는 제2 이미지 내의 제2 특징 영역이 제3 이미 지 내의 제3 특징 영역과 동일함을 식별할 수 있다. 이와 같이, 디바이스는 인접한 2개의 이미지들을 순 차적으로 비교함으로써, 제n-1 이미지 내의 제 n-1 특징 영역이 제n 이미지 내의 제n 특징 영역과 동일함을 식 별할 수 있다. 동작 S720에서 디바이스는 복수의 이미지들 중에서 촬영 각도가 소정 값 이상이 제1 이미지 및 제n 이미 지를 선택할 수 있다. 예를 들어, n 개의 이미지가 촬영된 경우에, 촬영 각도 범위 내에서 가장 작은 촬영 각도 에서 촬영된 제1 이미지 및 가장 큰 촬영 각도에서 촬영된 제n 이미지를 선택할 수 있으나, 이에 제한되지 않는 다. 디바이스는 소정 임계치 이상의 촬영 각도 차이를 가지는 두 이미지들로부터 동일한 특징 영역들을 식별하고, 식별된 특징 영역들을 이용하여 특징 영역들의 깊이를 산출할 수도 있다. 예를 들어, 디바이스(100 0)는 제1 내지 제n 이미지들 중에서 촬영 각도의 차이가 소정 임계치 이상인 제1 이미지 및 제n-3 이미지를 선 택하고, 선택된 제1 이미지 및 제n-3 이미지로부터 동일한 특징 영역들을 식별할 수도 있다. 동작 S730에서 디바이스는 제1 이미지를 촬영할 때의 카메라 모듈의 촬영 중심 및 제2 이미지를 촬 영할 때의 카메라 모듈의 촬영 중심에 기초하여 베이스라인 값을 획득할 수 있다. 베이스 라인 값은 한 이미지를 촬영할 때의 카메라 모듈의 촬영 중심 및 다른 이미지를 촬영할 때의 카메라 모듈의 촬영 중심 간의 거리를 나타내는 값일 수 있다. 카메라 모듈의 촬영 중심은, 예를 들어, 카메라 모듈의 렌즈의 중심점일 수 있다. 동작 S740에서 디바이스는 제1 이미지 내의 제1 특징 영역 및 제n 이미지 내의 제n 특징 영역 간의 디스 패리티 값을 산출할 수 있다. 디바이스는 베이스라인 값을 유지하면서 제1 이미지를 촬영할 때의 카메라 모듈과 제n 이미지를 촬영할 때의 카메라 모듈을 가상으로 배치하고, 제1 이미지 및 제2 이미지를 소정 기준에 따라 배열할 수 있다. 또한, 디바이스는 배열된 제1 이미지 내의 제1 특징 영역의 위치 및 배열된 제n 이 미지 내의 제n 특징 영역의 위치에 기초하여, 제1 특징 영역 및 제2 특징 영역 간의 디스패리티 값을 산출할 수 있다. 동작 S750에서 디바이스는 디스패리티 값, 베이스라인 값 및 카메라 모듈의 초점 거리에 기초하여, 특징 영역의 깊이를 산출할 수 있다. 디바이스는 두 이미지 내의 동일한 특징 영역들에 대한 디스패리티 값, 카메라 모듈의 베이스 라인 값 및 카메라 모듈의 초점 거리를 이용하여, 두 이미지 내의 동일한 특 징 영역에 대한 깊이를 산출할 수 있다. 디바이스는 베이스 라인 값과 초점 거리 간의 비율이 디스패리티 값과 깊이 간의 비율과 동일함을 이용하여, 특징 영역의 깊이를 산출할 수 있다. 도 8은 본 개시의 일 실시예에 따른 디바이스가 디스패리티 값을 산출하는 예시를 나타내는 도면이다. S800에서 디바이스는 베이스라인 값을 유지하면서, 제1 이미지를 촬영할 때의 카메라 모듈(1400-1)과 제n 이미지를 촬영할 때의 카메라 모듈(1400-n)을 가상으로 배치할 수 있다. 디바이스는 제1 이미지를 촬영할 때의 카메라 모듈(1400-1)의 촬영 방향 및 제n 이미지를 촬영할 때의 카메라 모듈(1400-n)의 촬영 방향이 서로 평행해지도록 제1 이미지를 촬영할 때의 카메라 모듈(1400-1)과 제n 이미지를 촬영할 때의 카메라 모듈(1400- n)을 가상으로 배치할 수 있다. S810에서 디바이스는 제1 이미지 및 제n 이미지를 배열할 수 있다. 디바이스는 제1 이미지 및 제n 이미지를 세로축 및 세로축을 따라 배열할 수 있다. 제1 이미지 및 제n 이미지의 세로변들이 세로축 및 세로축에 일치하지 않는 경우에, 디바이스는 제1 이미지 및 제n 이미지의 세로변들이 세로축 및 세로축에 일치하도록 제1 이미지 및 제n 이미지를 소정 알고리즘에 따라 수정(rectification)할 수 있다. 동작 S820에서 디바이스는 제1 이미지 내의 제1 특징 영역 및 제n 이미지 내의 제n 특징 영역 간의 거리 를 산출할 수 있다. 디바이스는 동작 S820에서 배열된 제1 이미지 내의 제1 특징 영역의 위치 및 동작 S820에서 배열된 제2 이미지 내의 제2 특징 영역의 위치에 기초하여, 제1 특징 영역 및 제n 특징 영역 간의 거 리를 산출할 수 있다. 도 9는 본 개시의 일 실시예에 따른 디바이스가 촬영 모드에 따라 디바이스의 주변을 인식하는 방법의 흐름도이 다. 동작 S900에서 디바이스는 촬영 모드를 식별할 수 있다. 예를 들어, 디바이스의 전원이 켜지거나 디바이스가 비활성화 상태에서 활성화되면, 디바이스는 사용자의 제스처 입력을 수신하기 위하여 카메라 모듈의 촬영 모드를 제스처 인식 모드로 식별할 수 있다. 또한, 디바이스는 제스처 인식 모 드에서 사용자의 제스처를 인식하고 인식된 제스처에 따라 카메라 모듈의 촬영 모드를 변경할 수 있다. 디바이스는 제스처에 대응되는 애플리케이션을 실행하고, 실행된 애플리케이션이 요구하는 촬영 모드에 따라 카메라 모듈의 촬영 모드를 변경할 수 있다. 또한, 예를 들어, 디바이스는 카메라 모듈(140 0)을 통한 촬영을 필요로 하지 않는 애플리케이션이 실행되면, 카메라 모듈을 비활성화할 수 있다. 또는, 예를 들어, 디바이스의 전원이 켜지거나 디바이스가 비활성화 상태에서 활성화되면 디바이스 는 카메라 모듈의 촬영 모드를 공간 인식 모드로 식별할 수 있다. 또한, 예를 들어, 프로세서는 디바이스에 대한 기설정된 사용자 입력이 수신되면, 카메라 모듈 의 촬영 모드를 제스처 모드로 또는 공간 인식 모드로 식별할 수 있다. 동작 S900에서의 식별 결과, 촬영 모드가 제스처 모드라고 식별되면, 동작 S905에서 디바이스는 제스처 모드에 대응되는 제1 촬영 각도 범위를 식별할 수 있다. 예를 들어, 카메라 모듈의 촬영 모드가 제스처 모드인 경우에 -15도 ~ 15도의 촬영 각도 범위에서 카메라 모듈이 디바이스의 주변을 촬영하도록 설정될 수 있다. 예를 들어, 카메라 모듈이 정면을 향하고 있을 때의 각도를 0도라고 하면, 카메라 모듈 의 촬영 각도 범위가 -15도 ~ 15도인 경우에, 카메라 모듈은 정면을 기준으로 하여 좌측으로 -15도 까지 회전하고 우측으로 15도까지 회전할 수 있다. 동작 S910에서 디바이스는 제1 촬영 각도 범위 내에서 디바이스의 주변을 촬영할 수 있다. 디바이 스는 카메라 모듈 및 촬영 방향 제어 유닛을 제어함으로써, 제1 촬영 각도의 범위 내에서 소 정의 촬영 간격에 따라 디바이스의 주변을 순차적으로 촬영함으로써 복수의 이미지를 획득할 수 있다. 이 경우, 디바이스는 카메라 모듈의 촬영 간격을 결정할 수 있다. 동작 S915에서 디바이스는 촬영된 이미지들로부터 제스처에 관련된 객체를 식별할 수 있다. 디바이스 는 촬영된 이미지들 내의 여러 객체들에 관련된 특징 영역들의 깊이 값들을 산출하고 산출된 깊이 값들을 비교할 수 있다. 디바이스는 산출된 깊이 값들을 비교함으로써, 사용자의 제스처에 관련된 객체를 식별할 수 있다. 또한, 디바이스는 식별된 객체의 모양 및 위치를 식별할 수 있다. 동작 S920에서 디바이스는 객체의 모양 및 위치에 기초하여 제스처를 식별할 수 있다. 디바이스는 객체의 모양 변화 및 객체의 위치 변화에 기초하여, 사용자의 제스처를 식별할 수 있다. 동작 S900에서의 식별 결과, 촬영 모드가 공간 인식 모드라고 식별되면, 동작 S950에서 디바이스는 공간 인식 모드에 대응되는 제2 촬영 각도 범위를 식별할 수 있다. 예를 들어, 카메라 모듈의 촬영 모드가 공 간 인식 모드인 경우에 -60도 ~ 60도의 촬영 각도 범위에서 카메라 모듈이 디바이스의 주변을 촬영 하도록 설정될 수 있다. 예를 들어, 카메라 모듈이 정면을 향하고 있을 때의 각도를 0도라고 하면, 카메 라 모듈의 촬영 각도 범위가 -60도 ~ 60도인 경우에, 카메라 모듈은 정면을 기준으로 하여 좌측으 로 -60도까지 회전하고 우측으로 60도까지 회전할 수 있다. 동작 S955에서 디바이스는 제2 촬영 각도 범위 내에서 디바이스의 주변을 촬영할 수 있다. 디바이 스는 카메라 모듈 및 촬영 방향 제어 유닛을 제어함으로써, 제2 촬영 각도의 범위 내에서 소 정의 촬영 간격에 따라 디바이스의 주변을 순차적으로 촬영함으로써 복수의 이미지를 획득할 수 있다. 이 경우, 디바이스는 카메라 모듈의 촬영 간격을 결정할 수 있다. 동작 S960에서 디바이스는 촬영된 이미지들로부터 주변 객체들을 식별할 수 있다. 디바이스는 디바 이스는 촬영된 이미지들 내의 여러 객체들에 관련된 특징 영역들의 깊이 값들을 산출하고 산출된 깊이 값 들을 비교할 수 있다. 디바이스는 산출된 깊이 값들을 비교함으로써, 디바이스 주변의 객체들을 식 별함으로써 디바이스의 주변 공간을 인식할 수 있다. 일 실시예에 따르면, 디바이스는 사용자가 응시하는 물체를 식별할 수 있다. 사용자의 눈동자가 소정 시 간이상 고정되면, 디바이스는 카메라 모듈을 소정 촬영 각도 범위 내에서 회전시키면서 사용자가 바라보는 방향 주변을 순차적으로 촬영할 수 있다. 또한, 디바이스는 사용자가 바라보는 방향 주변의 깊 이 맵을 생성하고, 사용자가 응시한 물체를 식별할 수 있다. 또한, 디바이스는 식별된 물체에 관한 부가 정보를 디스플레이할 수 있다. 부가 정보는, 예를 들어, 물체의 식별 값, 물체의 깊이 값을 포함할 수 있으나, 이에 제한되지 않는다. 디바이스는 식별된 물체에 관한 부가 정보를 사용자에게 제공하기 위한 GUI를 디 스플레이할 수도 있다. 도 10a은 본 개시의 일 실시예에 따른 디바이스가 제스처 모드에서 사용자의 손 동작을 촬영하는 예시를 나타내 는 도면이다. 도 10a을 참조하면, 사용자는 손가락을 구부리는 제스처를 행할 수 있으며, 제스처 모드에서 디바이스 는 구부려지는 손가락을 복수회 순차적으로 촬영할 수 있다. 예를 들어, 디바이스는 제스처 모드에 대응되는 제1 촬영 각도 범위 내에서 카메라 모듈을 소정 촬영 간격으로 복수회 회전시키면서 손 가락을 순차적으로 촬영할 수 있다. 이에 따라, 디바이스는 n개의 이미지들을 포함하는 복수의 이미 지 세트들을 획득할 수 있다. 예를 들어, 디바이스는 손가락이 펴진 상태에서 촬영된 제1 이미지 세 트, 및 손가락이 구부려진 상태에서 촬영된 제2 이미지 세트를 획득할 수 있다. 도 10b는 본 개시의 일 실시예에 따른 디바이스가 이미지 세트들로부터 제스처를 인식하는 예시를 나타내 는 도면이다. 도 10b를 참조하면, 디바이스는 손가락이 펴진 상태에서 촬영된 제1 이미지 세트로부터 제1 깊 이 맵을 생성하고, 손가락이 구부려진 상태에서 촬영된 제2 이미지 세트로부터 제2 깊이 맵 를 생성할 수 있다. 또한, 디바이스는 제1 깊이 맵으로부터 펴진 손가락을 식별하고, 제2 깊이 맵으로부터 구 부려진 손가락을 식별할 수 있다. 이후, 디바이스는 펴진 손가락의 모양 및 구부려진 손가락 의 모양을 분석하여, 사용자의 제스처가 ‘클릭’ 동작임을 식별할 수 있다. 도 11a 내지 도 11c는 본 개시의 일 실시예에 따른 디바이스가 디바이스 주변의 공간을 분석하는 예시를 나타내 는 도면이다. 도 11a는 본 개시의 일 실시예에 따른 디바이스가 디바이스 주변을 촬영하여 획득된 복수의 이미지들을 복수의 이미지 세트로 그룹핑하는 예시를 나타내는 도면이다. 도 11a를 참조하면, 디바이스는 공간 인식 모드에 대응되는 제2 촬영 각도 범위 내에서 카메라 모듈 을 소정 촬영 간격으로 복수회 회전시키면서 디바이스의 주변을 순차적으로 촬영할 수 있다. 또한, 디바이스는 복수의 이미지들 중 인접한 이미지들을 그룹핑함으로써 복수의 이미지 세트를 획득할 수 있다. 복수의 이미지 세트들은 연속되는 이미지들로 구성될 수 있다. 이미지 세트 내의 연속되는 이미지들 중 일부는, 인접한 이미지 세트 내의 연속되는 이미지들 중 일부와 중복될 수 있다. 도 11b는 본 개시의 일 실시예에 따른 디바이스에 의해 그룹핑된 복수의 이미지 세트들의 예시를 나타내는 도면 이다. 도 11b를 참조하면, 디바이스는 디바이스 주변을 촬영된 복수의 이미지들로부터 제1 이미지 세트 , 제2 이미지 세트 및 제3 이미지 세트를 획득할 수 있다. 제1 이미지 세트는 이미지, 이미지 , 이미지 및 이미지 를 포함할 수 있으며, 제2 이미지 세트는 이미지, 이미지 , 이미지 및 이미지 를 포함할 수 있으며, 제3 이미지 세트는 이미지, 이미지 , 이미지 및 이미지 를 포함할 수 있다. 또한, 특징 영역은 이미지에서는 사라지지만 제1 이미지 세트 내의 이미지들 내에는 존재하므로, 디 바이스는 이미지 세트로부터 특징 영역의 깊이 값을 산출할 수 있다. 도 11c는 본 개시의 일 실시예에 따른 디바이스가 복수의 이미지 세트로부터 생성된 깊이 맵으로부터 디바이스 주변 공간을 나타내는 깊이 맵을 생성하고 분석하는 예시를 나타내는 도면이다. 또한, 디바이스는 제1 이미지 세트로부터 제1 부분 깊이 맵을 생성하고, 제2 이미지 세트(11 5)로부터 제2 부분 깊이 맵을 생성하고, 제3 이미지 세트로부터 제3 부분 깊이 맵을 생성할 수 있다. 또한, 디바이스는 제1 부분 깊이 맵, 제2 부분 깊이 맵 및 제3 부분 깊이 맵을 이 용하여, 전체 깊이 맵을 생성하고 분석할 수 있다. 본 개시의 일 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포 함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의 의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령 어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독가능 명령 어, 데이터 구조, 또는 프로그램 모듈과 같은 변조된 데이터 신호의 기타 데이터를 포함할 수 있다. 또한, 컴퓨터에 의해 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다 는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경 우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치들(예: 스 마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 본 명세서에서, “부”는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로 세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다. 또한, 본 명세서에서, “a, b 또는 c 중 적어도 하나를 포함한다”는 “a만 포함하거나, b만 포함하거나, c만 포함하거나, a 및 b를 포함하거나, b 및 c를 포함하거나, a 및 c를 포함하거나, a, b 및 c를 모두 포함하는 것 을 의미할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost)값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 개시에 따른 인공지능 모델은 이미지 데이터를 인공지능 모델의 입력 데이터로 이용하여 이미지 또는 이미지 내 특징 영역을 인식한 출력 데이터를 출력할 수 있다. 인공지능 모델은 학습을 통해 만들어 질 수 있다. 여기 서, 학습을 통해 만들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이 용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델 이 만들어짐을 의미한다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경망 연산을 수행한다. 시각적 이해는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 특징 영역 인식(Object Recognition), 특 징 영역 추적(Object Tracking), 영상 검색(Image Retrieval), 사람 인식(Human Reconnition), 장면 이해 (Scene Recognition), 공간 이해(3D Reconstruction/Localization), 영상 개선(Image Enhancement) 등을 포함 한다."}
{"patent_id": "10-2020-0051815", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3 도면4a 도면4b 도면4c 도면5a 도면5b 도면5c 도면6 도면7 도면8 도면9 도면10a 도면10b 도면11a 도면11b 도면11c"}
{"patent_id": "10-2020-0051815", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 디바이스가 주변 영역의 깊이를 획득하는 방법의 개요도이다. 도 2는 본 개시의 일 실시예에 따른 디바이스의 블록도이다. 도 3은 본 개시의 일 실시예에 따른 디바이스 내의 카메라 모듈이 회전하는 예시를 나타내는 도면이다. 도 4a는 본 개시의 일 실시예에 따른 디바이스 내의 카메라 모듈이 회전하면서 복수의 이미지를 획득하는 예시 를 나타내는 도면이다. 도 4b는 본 개시의 일 실시예에 따른 인접한 이미지들 내의 동일한 특징 영역이 순차적으로 식별되는 예시를 나 타내는 도면이다. 도 4c는 본 개시의 일 실시예에 따른 디바이스가 가장 큰 각도 차이가 나는 이미지들 내의 동일한 식별 영역들 을 식별하는 예시를 나타내는 도면이다. 도 5a는 본 개시의 일 실시예에 따른 디바이스가 디바이스의 주변을 촬영하는 예시를 도시한 도면이다. 도 5b는 본 개시의 일 실시예에 따른 디바이스가 카메라 모듈을 가상으로 배치하는 예시를 나타내는 도면이다. 도 5c는 본 개시의 일 실시예에 따른 디바이스가 디스패리티 값을 산출하는 예시를 나타내는 도면이다. 도 6은 본 개시의 일 실시예에 따른 디바이스가 특징 영역의 깊이를 산출하는 예시를 나타내는 도면이다. 도 7은 본 개시의 일 실시예에 따른 디바이스가 이미지 내의 특징 영역의 깊이를 산출하는 방법의 흐름도이다. 도 8은 본 개시의 일 실시예에 따른 디바이스가 디스패리티 값을 산출하는 예시를 나타내는 도면이다. 도 9는 본 개시의 일 실시예에 따른 디바이스가 촬영 모드에 따라 디바이스의 주변을 인식하는 방법의 흐름도이다. 도 10a은 본 개시의 일 실시예에 따른 디바이스가 제스처 모드에서 사용자의 손 동작을 촬영하는 예시를 나타내 는 도면이다. 도 10b는 본 개시의 일 실시예에 따른 디바이스가 이미지 세트들로부터 제스처를 인식하는 예시를 나타내 는 도면이다. 도 11a는 본 개시의 일 실시예에 따른 디바이스가 디바이스 주변을 촬영하여 획득된 복수의 이미지들을 복수의 이미지 세트로 그룹핑하는 예시를 나타내는 도면이다. 도 11b는 본 개시의 일 실시예에 따른 디바이스에 의해 그룹핑된 복수의 이미지 세트들의 예시를 나타내는 도면 이다. 도 11c는 본 개시의 일 실시예에 따른 디바이스가 복수의 이미지 세트로부터 생성된 깊이 맵으로부터 디바이스 주변 공간을 나타내는 깊이 맵을 생성하고 분석하는 예시를 나타내는 도면이다."}
