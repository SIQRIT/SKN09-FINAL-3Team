{"patent_id": "10-2023-0141408", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0057507", "출원번호": "10-2023-0141408", "발명의 명칭": "전자 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "허재명"}}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치(100)에 있어서, 투사 모듈(162);하나 이상의 공간 감지 센서(140A);통신 모듈(120);하나 이상의 인스트럭션을 저장하는 메모리(130); 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서(110)를 포함하고, 상기 적어도 하나의 프로세서(110)는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 하나 이상의 공간 감지 센서(140A)를 이용하여, 검출 영역으로부터 타겟 디바이스를 검출하고(510), 상기 통신 모듈(120)을 통해 상기 타겟 디바이스에 관한 정보를 획득하고(520),상기 타겟 디바이스에 관한 정보에 기반하여 그래픽 이미지를 결정하고(530),상기 그래픽 이미지를 투사면에 투사하도록 상기 투사 모듈(162)을 제어하는(540), 전자 장치."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항의 전자 장치에 있어서, 상기 적어도 하나의 프로세서(110)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 그래픽 이미지를 상기 타겟 디바이스의 외부 영역에 투사하도록 상기 투사 모듈을 제어하는, 전자 장치."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항 또는 제2 항의 전자 장치에 있어서, 상기 적어도 하나의 프로세서(110)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 공간 감지 센서를 통해 상기 검출 영역에 관한 정보를 획득하고,상기 검출 영역에 관한 정보를, 기 수집된 디바이스 데이터 베이스 또는 상기 획득된 타겟 디바이스에 관한 정보 중 적어도 하나와 비교함으로써, 상기 타겟 디바이스를 검출하는, 전자 장치."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항 내지 제3 항 중 어느 한 항의 전자 장치에 있어서, 상기 적어도 하나의 프로세서(110)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 검출된 타겟 디바이스와 사용자와의 상호작용없이 자동으로 연동(link)하는, 전자 장치."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항 내지 제4 항 중 어느 한 항의 전자 장치에 있어서, 상기 검출 영역에 관한 정보는, 상기 검출 영역 내 상기 투사면의 형상에 관련된 정보;상기 검출 영역 내 객체들의 배치에 관련된 정보;상기 검출 영역 내 객체의 형상에 관련된 정보; 또는상기 검출 영역 내 객체의 3D 모델링 정보; 공개특허 10-2025-0057507-3-중 적어도 하나를 포함하는, 전자 장치."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항 내지 제5 항 중 어느 한 항의 전자 장치에 있어서, 상기 타겟 디바이스에 관한 정보는, 디바이스의 모델명;디바이스 ID (identifier);디바이스의 형상에 관련된 정보;디바이스의 3D 모델링 정보;디바이스의 실시간 동작 상태 관련 정보;디바이스에 내장된 데이터; 네트워크 관련 정보;벤더(Vendor) 관련 정보; 또는사용자 계정 관련 정보; 중 적어도 하나를 포함하는, 전자 장치."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항 내지 제6 항 중 어느 한 항의 전자 장치에 있어서, 상기 적어도 하나의 프로세서(110)는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 통신 모듈을 통해 상기 타겟 디바이스 외 다른 주변 디바이스에 관한 정보를 획득하고,상기 타겟 디바이스 외 다른 주변 디바이스에 관한 정보에 기반하여 그래픽 이미지를 결정하고,상기 그래픽 이미지를 상기 타겟 디바이스가 포함된 상기 투사면에 투사하도록 상기 투사 모듈을 제어하는, 전자 장치."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항 내지 제7 항 중 어느 한 항의 전자 장치에 있어서, 상기 적어도 하나의 프로세서(110)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 하나 이상의 공간 감지 센서를 이용하여, 상기 전자 장치 주위의 모든 방향을 둘러싼 360도 영역을 상기검출 영역으로 하는, 전자 장치."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항 내지 제8 항 중 어느 한 항의 전자 장치에 있어서, 상기 전자 장치(100)는 자율 주행 수단을 더 포함하고, 상기 적어도 하나의 프로세서(110)는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 전자 장치(100)가 상기 자율 주행 수단을 이용하여 이동하는 동안, 실시간으로 상기 검출 영역에 관한 정보를 업데이트하고, 실시간으로 타겟 디바이스에 관한 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항 내지 제9 항 중 어느 한 항의 전자 장치에 있어서, 상기 적어도 하나의 프로세서(110)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 그래픽 이미지와 연관된 디바이스를 제어하기 위한 사용자의 입력을 수신하고,상기 수신된 사용자의 입력에 따라, 상기 그래픽 이미지와 연관된 디바이스를 제어하고, 상기 제어 결과를 투사하도록 상기 투사 모듈을 제어하는, 전자 장치.공개특허 10-2025-0057507-4-청구항 11 제1 항 내지 제10 항 중 어느 한 항의 전자 장치에 있어서, 상기 적어도 하나의 프로세서(110)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 타겟 디바이스로부터 상기 그래픽 이미지와 연관된 디바이스를 제어한 결과를 지시하는 입력을 수신하고, 상기 타겟 디바이스로부터 수신된 입력에 기초하여, 상기 지시된 제어 결과를 투사하도록 상기 투사 모듈을 제어하는, 전자 장치."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "전자 장치(100)의 동작 방법에 있어서, 하나 이상의 공간 감지 센서를 이용하여, 검출 영역으로부터 타겟 디바이스를 검출하는 단계 (510);통신 모듈을 통해 상기 타겟 디바이스에 관한 정보를 획득하는 단계 (520);상기 타겟 디바이스에 관한 정보에 기반하여 그래픽 이미지를 결정하는 단계 (530); 및상기 그래픽 이미지를 투사면에 투사하도록 투사 모듈을 제어하는 단계 (540)를 포함하는, 방법."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서, 상기 투사 모듈을 제어하는 단계는,상기 그래픽 이미지를 상기 타겟 디바이스의 외부 영역에 투사하도록 상기 투사 모듈을 제어하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12 항 또는 제13 항에 있어서, 상기 타겟 디바이스를 검출하는 단계는,상기 공간 감지 센서를 통해 상기 검출 영역에 관한 정보를 획득하는 단계; 및상기 검출 영역에 관한 정보를, 기 수집된 디바이스 데이터 베이스 또는 상기 획득된 타겟 디바이스에 관한 정보 중 적어도 하나와 비교함으로써, 상기 타겟 디바이스를 검출하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12 항 내지 제14 항 중 어느 한 항에 있어서, 상기 방법은,상기 검출된 타겟 디바이스와 사용자와의 상호작용없이 자동으로 연동(link)하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12 항 내지 제15 항 중 어느 한 항에 있어서, 상기 방법은,상기 통신 모듈을 통해 상기 타겟 디바이스 외 다른 주변 디바이스에 관한 정보를 획득하는 단계;상기 타겟 디바이스 외 다른 주변 디바이스에 관한 정보에 기반하여 그래픽 이미지를 결정하는 단계; 및상기 그래픽 이미지를 상기 타겟 디바이스가 포함된 상기 투사면에 투사하도록 상기 투사 모듈을 제어하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12 항 내지 제16 항 중 어느 한 항에 있어서, 상기 방법은,상기 하나 이상의 공간 감지 센서를 이용하여, 상기 전자 장치 주위의 모든 방향을 둘러싼 360도 영역을 상기검출 영역으로 하는, 방법."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12 항 내지 제17 항 중 어느 한 항에 있어서, 상기 방법은,공개특허 10-2025-0057507-5-상기 전자 장치(100)가 자율 주행 수단을 이용하여 이동하는 동안, 실시간으로 상기 검출 영역에 관한 정보를업데이트하고, 실시간으로 상기 타겟 디바이스에 관한 정보를 획득 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12 항 내지 제18 항 중 어느 한 항에 있어서, 상기 방법은,상기 그래픽 이미지와 연관된 디바이스를 제어하기 위한 사용자의 입력을 수신하는 단계; 및상기 수신된 사용자의 입력에 따라, 상기 그래픽 이미지와 연관된 디바이스를 제어하고, 상기 제어 결과를 투사하도록 상기 투사 모듈을 제어하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0141408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제12 항 내지 제19 항 중 어느 한 항에 있어서, 상기 방법은,상기 타겟 디바이스로부터 상기 그래픽 이미지와 연관된 디바이스를 제어한 결과를 지시하는 입력을 수신하는단계; 및상기 타겟 디바이스로부터 수신된 입력에 기초하여, 상기 지시된 제어 결과를 투사하도록 상기 투사 모듈을 제어하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0141408", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "투사 모듈을 구비한 전자 장치 및 그 동작 방법이 제공된다. 전자 장치는 투사 모듈, 하나 이상의 공간 감지 센 서, 통신 모듈, 하나 이상의 인스트럭션을 저장하는 메모리 및 메모리에 저장된 하나 이상의 인스트럭션을 실행 하는 적어도 하나의 프로세서를 포함한다. 프로세서는, 하나 이상의 공간 감지 센서를 이용하여, 검출 영역으로 부터 타겟 디바이스를 검출한다. 프로세서는, 통신 모듈을 통해 타겟 디바이스에 관한 정보를 획득한다. 프로세 서는, 타겟 디바이스에 관한 정보에 기반하여 그래픽 이미지를 결정한다. 프로세서는, 그래픽 이미지를 투사면에 투사하도록 투사 모듈을 제어한다."}
{"patent_id": "10-2023-0141408", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 그 동작 방법에 관한 것으로, 구체적으로는, 투사 모듈을 구비한 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2023-0141408", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "프로젝터 또는 프로젝션 시스템등은, 디스플레이 패널을 내장하지 않고, 컴퓨터, 노트북, DVD 플레이어, 스마트 폰 등으로부터 입력받은 영상신호 또는 이미지 신호를 광원에서 방출되는 빛을 이용하여 스크린(투사면)에 투사 하여 화상을 보여주는 디스플레이 장치이다. 이러한 프로젝터는 디스플레이 장치로써 교육 엔터테인먼트, 비즈 니스 프레젠테이션 등 다양한 분야에서 활용되며, 영상 또는 이미지를 효과적으로 전달하거나 시청자들에게 인 상적인 경험을 제공한다. 한편, 최근 인터넷과 네트워크 기술의 발달로, IoT(Internet of Things) 및 초연결성(ultra-connectivity)을 활용한 기술이 활발히 연구되고 있다. IoT 환경에서는 다양한 유형의 기기나 사물이 인터넷에 연결되어 데이터 를 수집, 교환, 분석하고, 사용자 또는 다른 기기들과 초연결을 이루어 서로 상호 작용할 수 있다. 이에 따라, 프로젝터 또한 단순한 디스플레이 장비로써 역할을 넘어서, 주변 기기들과의 연결을 통해 데이터를 수집 및 분석하여, 기존 시청 환경에서 주변 기기들이 제공하지 않았던 정보를 표시해주는 UI/UX를 제공함으로 써 사용자들에게 새로운 디스플레이 경험을 제공할 필요가 있다."}
{"patent_id": "10-2023-0141408", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따른 전자 장치는 투사 모듈, 하나 이상의 공간 감지 센서, 통신 모듈, 하나 이상의 인 스트럭션을 저장하는 메모리 및 메모리에 저장된 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서를 포함한다. 프로세서는, 하나 이상의 공간 감지 센서를 이용하여, 검출 영역으로부터 타겟 디바이스를 검출한다. 프로세서는, 통신 모듈을 통해 타겟 디바이스에 관한 정보를 획득한다. 프로세서는, 타겟 디바이스에 관한 정보 에 기반하여 그래픽 이미지를 결정한다. 프로세서는, 그래픽 이미지를 투사면에 투사하도록 투사 모듈을 제어한 다. 본 개시의 일 실시예에 따른 전자 장치의 동작 방법은 하나 이상의 공간 감지 센서를 이용하여, 검출 영역으로 부터 타겟 디바이스를 검출하는 단계를 포함한다. 전자 장치의 동작 방법은, 통신 모듈을 통해 타겟 디바이스에 관한 정보를 획득하는 단계를 포함한다. 전자 장치의 동작 방법은, 타겟 디바이스에 관한 정보에 기반하여 그래픽 이미지를 결정하는 단계를 포함한다. 전자 장치의 동작 방법은, 그래픽 이미지를 투사면에 투사하도록 투사 모듈을 제어하는 단계를 포함한다. 본 개시의 일 실시예는 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 개시된 방법의 실시예들 중 적 어도 하나를 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체를 제공할 수 있다."}
{"patent_id": "10-2023-0141408", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "다른 기술적 특징들은 다음의 도면들, 설명들 및 청구항들로부터 본 기술분야의 통상의 기술자에게 용이하게 이 해될 수 있을 것이다."}
{"patent_id": "10-2023-0141408", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에서 사용되는 용어는, 본 개시에서 언급되는 기능을 고려하여 현재 사용되는 일반적인 용어로 기재되었 으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 다양한 다른 용어를 의미할 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 실시예의 설명 부분에서 상세히 그 의미를 기재할 것이다 따라서 본 개시에서 사용되는 용어는 용어의 명칭만으로 해석되어서 는 안되며, 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 해석되어야 한다. 또한, 본 개시에서 사용된 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것이며, 본 개시를 한정하려는 의도로 사용되는 것이 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 명세서에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 본 명세서에 기재된 \"...부\", \"...모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 이하에서 설명할 구성요소 각각은 자신이 담당하는 주기능 이외에도 다른 구성요소가 담당하는 기능 중 일부 또는 전부의 기능을 추가적으로 수행할 수도 있으며, 구성요소 각각이 담당하는 주기능 중 일부 기능이 다 른 구성요소에 의해 전담되어 수행될 수도 있다. 본 명세서에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적 합한(suitable for)\", \"~하는 능력을 가지는(having the capacity to)\", \"~하도록 설계된(designed to)\", \"~하 도록 변경된(adapted to)\", \"~하도록 만들어진(made to)\", 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용 될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반 드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 시스템\"이라는 표현은, 그 시스템이 다 른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 본 명세서에서 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구 성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존재 하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것이다. 본 명세서에서 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아 니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 본 명세서, 특히, 특허 청구 범위에서 사용된 “상기” 및 이와 유사한 지시어는 단수 및 복수 모두를 지시하는 것일 수 있다. 또한, 본 개시에 따른 방법을 설명하는 단계들의 순서를 명백하게 지정하는 기재가 없다면, 기재 된 단계들은 적당한 순서로 행해질 수 있다. 기재된 단계들의 기재 순서에 따라 본 개시가 한정되는 것은 아니 다. 본 명세서에서 다양한 곳에 등장하는 \"일부 실시 예에서\" 또는 \"일 실시 예에서\" 등의 어구는 반드시 모두 동일 한 실시 예를 가리키는 것은 아니다. 본 개시의 일부 실시 예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술 을 채용할 수 있다. 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유 사한 부분에 대해서는 유사한 도면 부호를 붙였다. 또한, 각각의 도면에서 사용된 도면 부호는 각각의 도면을 설명하기 위한 것일 뿐, 상이한 도면들 각각에서 사용된 상이한 도면 부호가 상이한 요소를 나타내기 위한 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또 는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 실시예를 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있 다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 명세서에서, \"a, b 또는 c 중 적어도 하나\" 표현은 \" a\", \" b\", \" c\", \"a 및 b\", \"a 및 c\", \"b 및 c\", \"a, b 및 c 모두\", 혹은 그 변형들을 지칭할 수 있다. 명세서 의 설명 과정에서 이용되는 숫자(예를 들어, 제1, 제2, 제3 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별기호에 불과하다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시에서 '사용자'는 전자 장치를 사용하는 사람을 의미하며, 소비자, 평가자, 시청자, 관리자 또는 설치 기 사를 포함할 수 있다. '사용자'는 전자 장치 외 주변 디바이스들을 이용하는 사람을 의미할 수 있다. 본 개시에서, '공간 감지 센서(Space Detection Sensor)'는 주변 공간에서 물체의 존재, 물체의 위치, 크기, 모 양 또는 물체의 움직임을 정확하게 감지하고 측정하는 기능을 수행하는 모든 센서를 의미할 수 있다. 3D 공간 감지 센서는, 주변 환경을 3차원 공간으로 인식 할 수 있으며, 예를 들어, 적외선, 초음파, 레이저 스캐너, 스 테레오 카메라, TOF(Time-of-Flight), 레이다(Radar) 등 다양한 원리를 기반으로 구현될 수 있다. 본 개시에서, 전자 장치가 디바이스를 '검출한다'는 것은, 전자 장치가 공간 감지 센서를 이용하여 공간을 감지 /측정하고, 디바이스의 존재를 탐지/감지/발견/인식하고, 어떤 디바이스인지를 특정/식별하고, 해당 디바이스 또는 검출 영역에 관한 정보/데이터를 수집/수신하는 것을 의미할 수 있다. 본 개시에서 '검출 영역'은 센서가 디바이스를 검출하는 동작을 수행하는 영역을 의미할 수 있으며, 검출 영역은 3D 영역일 수 있다. 본 개시에서 '네트워크(network)'는 디지털 기기 간 데이터, 파일, 그래픽 이미지 등 기타 형태의 정보를 공유 하고 통신하기 위한 상호 연결된 구조 또는 시스템을 의미할 수 있다. 네트워크는 RF(Radio Frequency) 통신을 포함할 수 있다. RF 통신은 무선 주파수 대역을 사용하여 정보를 전송하고 수신하는 무선 통신 기술이며, 예를 들어, 와이파이(wi-fi), 블루투스(Bluetooth), BLE(Bluetooth Low Energy), WFD(WiFi direct), UWB(Ultra wide band), NFC(near field communication) 및 Zigbee 등 포함할 수 있다. 본 개시에서, 디바이스 간 서로 '연동한다' 또는 '페어링한다'는 것은 복수의 디바이스들이 네트워크를 통해 서 로 연결되는 과정을 의미할 수 있다. 구체적으로, 복수의 디바이스들이 네트워크를 통해 데이터 또는 정보를 공 유하고, 작업을 협력적으로 수행하는 것을 의미할 수 있다. 복수의 디바이스들은 네트워크를 통해, 직접적으로 또는 서버를 공유함으로써 서로 연동 또는 페어링할 수 있다. 복수의 디바이스들이 서버를 공유함으로써 연동 또는 페어링한다는 것은, 복수의 디바이스들 각각이 서버와 연동하여, 서버에 저장된 각 디바이스들의 정보 또 는 데이터를 서로 공유할 수 있는 상태에 있는 것을 의미할 수 있다. 복수의 디바이스들이 서로 연동 또는 페어 링하면, 서로를 인식하고 식별할 수 있도록 설정되며, 서로 데이터를 주고 받을 수 있고, 한 디바이스에서 다른 디바이스를 제어하거나 조작할 수 있다. 본 개시에서, '그래픽 이미지'는 시각적 정보를 나타내기 위해 컴퓨터 그래픽스나 디지털 매체에서 생성된 이미 지를 의미할 수 있다. 그래픽 이미지의 일 예로, 비트맵 이미지, 벡터 이미지, 애니메이션 이미지, 3D 그래픽 이미지 등이 있다. 본 개시에서 그래픽 이미지는 UI(user interface)를 포함할 수 있다. 본 개시에서, 전자 장치가 그래픽 이미지를 '투사한다'는 것은, 전자 장치가 빛을 사용하여 그래픽 이미지를 스 크린, 벽 또는 다른 표면에 투영/표시하는 것을 의미할 수 있다. 전자 장치가 그래픽 이미지를 투영/표시하는 표면을 '투사면'이라고 할 수 있다. 투사면은 일정한 3D 공간 내 '천장', '바닥' 또는 '벽면'을 포함할 수 있으 며, 전자 장치를 포함한 다른 주변 디바이스들의 표면일 수 있다. 본 개시에서, 전자 장치가 디바이스를 '제어한다'고 하는 것은, 전자 장치가 디바이스에서 사용자에게 서비스를 제공하도록 조작하거나 지시하는 것을 의미할 수 있다. 서비스는 디바이스에서 수행되는 모든 기능이나 동작을 의미할 수 있다. 서비스의 종류와 유형은 디바이스에 따라서 다양하게 존재할 수 있다. 예를 들어, 디바이스가 홈 어플라이언스(Home appliance)인 경우, 서비스는 홈 어플라이언스를 온(on)/오프(off)하거나 특정 동작을 수 행하도록 제어하는 기능일 수 있다. 본 개시는, 전자 장치가 공간 감지 센서 및 무선 통신 모듈을 활용하여, 기존 시청 환경에서는 제공되지 않았던 주변 디바이스들에 관한 정보를 표시하기 위한 그래픽 이미지를 생성 및 투사하는 방법을 제공함으로써, 사용자 에게 새로운 디스플레이 경험을 제공하는 것을 목적으로 한다. 다만, 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급하지 않은 또 다른 효과 들은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다. 도 1은 일 실시예에 따른 전자 장치 100의 개념을 설명하기 위한 참고도이다. 도 1을 참조하면, 일 실시예에 따른 전자 장치 100는, 공간 감지 센서를 이용하여 검출 영역으로부터 타겟 디바 이스 102를 검출할 수 있다. 타겟 디바이스 102는 다양한 전자 장치를 포함할 수 있으며, 예를 들어 도 1에서는 TV 가 도시되어 있다. 예를 들어, 전자 장치 100 는 공간 감지 센서를 이용하여 투사면의 형상에 관련된 정보, 검출 영역 내 디바이스 들의 배치에 관련된 정보, 타겟 디바이스 102의 형상에 관련된 정보, 타겟 디바이스 102의 3D 모델링 정보 등을 획득하여, 타겟 디바이스 102를 검출 할 수 있다. 전자 장치 100는, 통신 모듈을 이용하여 네트워크 400를 통해 타겟 디바이스 102와 연동할 수 있다. 예를 들어, 전자 장치 100는 통신 모듈을 이용하여 네트워크 400를 통해, 타겟 디바이스 102와 직접 연동하거나 또는 서버 300를 공유함으로써 타겟 디바이스 102와 연동할 수 있다. 전자 장치 100는, 통신 모듈을 이용하여 네트워크 400를 통해 타겟 디바이스 102에 관한 정보를 획득할 수 있다. 일 실시예에 따라, 전자 장치 100는, 타겟 디바이스 102로부터 직접 네트워크 400를 통해 타겟 디바이스 102에 관한 정보를 획득할 수 있다. 일 실시예에 따라, 전자 장치 100는 서버 300로부터 네트워크 400를 통해 타겟 디바이스 102에 관한 정보를 획득할 수 있다. 예를 들어, 도 1의 예에서, 전자 장치 100는, 네트워크 400를 통해 타겟 디바이스 102의 일 예인 TV와 연동하고, TV에 관한 정보로서, TV의 실시간 동작 상태 또는 TV에 내장되어 있는 애플리케이션 등의 데이터를 획득할 수 있다. 전자 장치 100는, TV에 내장된 허브(Hub)로부터 직접 TV에 관한 정보를 획득하거나 또는 TV에 연동된 외부 허브(Hub)로부터 기 저장되어 있는 TV에 관한 정보를 획득할 수 있다. 전자 장치 100는, 획득한 타겟 디바이스 102에 관한 정보에 기반하여, 그래픽 이미지 101를 결정할 수 있다. 그 래픽 이미지 101는 타겟 디바이스 102와 연관된 그래픽 이미지일 수 있다. 그래픽 이미지 101는 전자 장치 100 가 타겟 디바이스 102에 관한 정보에 의해 생성할 수 있는 모든 그래픽 이미지를 포함할 수 있다. 예를 들어, 도 1의 예에서, 전자 장치 100는, 타겟 디바이스 102의 일 예인 TV의 실시간 동작 상태 또는 TV에 내장되어 있는 애플리케이션 등의 데이터 등에 기반하여, TV와 연관된 그래픽 이미지를 결정 할 수 있다. 예를 들어, TV와 연관된 그래픽 이미지는, 도 1에 도시한 바와 같이, 컨텐츠 제공 OTT(Over The Top)를 선택하 기 위한 매뉴얼을 표시하는 UI일 수 있다. 다른 예로, TV와 연관된 그래픽 이미지는, 현재 재생하고 있는 컨텐 츠 영상의 비율에 따라 잘리는 부분을 표시하는 그래픽 이미지일 수 있다. 다른 예로, TV와 연관된 그래픽 이미 지는, 현재 재생하고 있는 컨텐츠와 관련된 시각 특수 효과를 표시하는 그래픽 이미지일 수 있다. 다른 예로, 타겟 디바이스가 에어컨일 경우, 그래픽 이미지 101는, 현재 동작 모드(ex, 제습 또는 냉방 모드), 현재 습도, 및 현재 온도 등을 표시하는 그래픽 이미지일 수 있다. 다른 예로, 타겟 디바이스가 스마트 스피커 일 경우, 그래픽 이미지 101는, 현재 재생중인 노래에 관한 정보(ex, 제목, 가수, 발행 년도, 가사 등) 음량, 및 EQ (equalizer) 등을 표시하는 그래픽 이미지일 수 있다. 다른 예로, 타겟 디바이스가 로봇청소기일 경우, 그래픽 이미지 101는, 현재 청소 진행 정도 및 배터리 잔량 등을 표시하는 그래픽 이미지일 수 있다. 전자 장치 100는 결정된 그래픽 이미지 101를 투사면에 투사하도록 투사 모듈을 제어할 수 있다. 일 실시예에 따른 전자 장치 100는 그래픽 이미지 101를 타겟 디바이스 102의 표면과 중첩하게 투사하도록 투사 모듈을 제어 할 수 있다. 일 실시예에 따른 전자 장치 100는 그래픽 이미지 101를 사용자의 시청 환경을 방해하지 않도록 타 겟 디바이스 102의 외부 영역에 투사하도록 투사 모듈을 제어할 수 있다. 예를 들어, 도 1의 예에서, 전자 장치 100는 TV를 시청하고 있는 사용자의 시청 환경을 방해하지 않도록 그래픽 이미지를 TV의 외부 영역에 투사하도록 투사 모듈을 제어할 수 있다. 전자 장치 100는 그래픽 이미지 101를 통해 타겟 디바이스 102를 제어할 수 있다. 이 경우는 전자 장치 100가 주체가 되어 타겟 디바이스 102를 제어하는 경우에 해당할 수 있다. 예를 들어, 도 1의 예에서, 사용자는 전자 장치 100에 대응하는 리모트 컨트롤 장치로 그래픽 이미지 101를 통 해 컨텐츠 제공 OTT를 선택하기 위한 메뉴얼을 조작하여 TV 102를 제어할 수 있다. 전자 장치 100는 타겟 디바이스 102 제어와 관련된 동작을 수행할 수 있다. 이 경우는 타겟 디바이스 102가 주 체가 되어 스스로를 제어하는 경우에 해당할 수 있다. 전자 장치 100는 타겟 디바이스 102로부터 제어 결과를 지시하는 입력을 수신하여, 제어 결과를 투사하도록 투사 모듈을 제어할 수 있다. 예를 들어, 도 1의 예에서, 사용자는 TV에 대응하는 리모트 컨트롤 장치로 그래픽 이미지 101를 통해 컨텐츠 제 공 OTT를 선택하기 위한 매뉴얼을 조작하여 TV를 제어할 수 있다. 본 개시의 일 실시예에 따라 전자 장치 100는 공감 감지 센서, 통신 모듈, 및 투사 모듈을 이용하여 주변 디바 이스를 인식하고, 주변 디바이스에 관한 정보와 연관된 그래픽 이미지를 제공함으로써 사용자로 하여금 새로운 디스플레이 기능 및 새로운 연결 사용성을 경험하도록 할 수 있다. 또한, 본 개시의 일 실시예에 따라 전자 장치 100는 디스플레이를 내장하지 않은 디바이스들의 제어 관련 정보 를 사용자가 시각적으로 보고, 제어할 수 있도록 그래픽 이미지를 투사함으로써, 사용자로 하여금 새로운 디스 플레이 기능 및 새로운 연결 사용성을 경험하도록 할 수 있다.도 2는 일 실시예에 따른 시스템의 블록도이다. 도 2를 참조하면, 일 실시예에 따른 시스템은 전자 장치 100, 주변 디바이스들 200, 서버 300 및 네트워크 400 를 포함할 수 있다. 일 실시예에 따른 시스템은 서버 300를 포함하지 않을 수 있다. 전자 장치 100는 공간 감지 센서를 이용하여 주변 디바이스들 200을 검출할 수 있다. 전자 장치 100는 통신 모 듈을 이용하여 주변 디바이스들 200 또는 서버 300와 연동할 수 있다. 전자 장치 100는 투사 모듈을 이용하여 그래픽 이미지를 투사면에 투사할 수 있다. 주변 디바이스들 200은, 다양한 목적으로 설계된, 특정 기능을 수행하는 하드웨어 또는 전자 제품들을 의미할 수 있다. 본 개시에서 주변 디바이스들 200은 전자 장치 100의 주변에 위치하는 디바이스들을 의미할 수 있고, 전자 장치 100가 검출하는 타겟 디바이스는 주변 디바이스들 200 중 하나일 수 있다. 주변 디바이스들 200은 다양한 형태와 크기로 존재할 수 있다. 예를 들어, 주변 디바이스들 200은 TV 201, 에어 컨 202, 세탁기 203, 건조기, 로봇 청소기 204, 스피커 205, 스마트 스탠드 206, 스마트폰, 노트북, 데스크탑 컴퓨터, 태플릿, 청소기, 공기청정기, 냉장고, 스타일러, 스마트 홈 디바이스(예를 들어, 스마트 스피커, 스마 트 서큘레이터 팬, 스마트 보안 카메라 등), 웨어러블 디바이스(예를 들어, 스마트 시계, 스마트 안경 등)을 포 함할 수 있으나, 이에 한정되는 것은 아니다. 서버 300는 클라이언트 디바이스에 대한 서비스를 제공하거나 요청에 응답하는 컴퓨터 또는 소프트웨어를 의미 할 수 있다. 서버 300는 클라이언트 디바이스에서 요청하는 데이터, 파일, 애플리케이션, 웹 페이지 등을 제공 하고, 데이터베이스와 같은 정보 저장소를 관리하며, 네트워크 상에서 다양한 기능을 수행할 수 있다. 서버 300 는 \"허브(Hub)\" 또는 \"중앙 제어 장치\"로 언급될 수 있다. 본 개시에서 서버 300는 전자 장치 100 및 타겟 디바 이스의 외부 서버를 의미한다. 일 실시예에 따라, 서버 300는 전자 장치 100 및 주변 디바이스들 200과 네트워크 400를 통해 연동할 수 있다. 서버 300는 전자 장치 100의 요청에 대한 응답으로, 네트워크 400를 통해 전자 장치 100에게, 서버 300에 기 수 집된 데이터 베이스 또는 주변 디바이스들로부터 수신한 각 디바이스들에 관한 정보를 제공할 수 있다. 네트워크 400는, 디바이스들 간에 데이터, 정보 또는 리소스를 교환하기 위한 인프라와 프로토콜의 집합을 의미 할 수 있다. 전자 장치 100는 네트워크 400를 통해 주변 디바이스들 200과 직접적으로 또는 서버 300를 공유함으로써 연동할 수 있다. 프로토콜 protocol은, 네트워크 400에서 디지털 기기 간 통신 및 정보 교환을 위한 규칙 및 표준의 집합을 의미 할 수 있다. 일 실시예에 따라, 프로토콜(protocol)은, HTTP(Hyper Text Transfer Protocol), HTTPS(Hyper Text Transfer Protocol Secure), FTP(File Transfer Protocol), SFTP(Secure File Transfer Protocol), Telnet(TErminaL NETwork), POP3(Post Office Protocol version 3), SMTP(Simple Mail Transfer Protocol), SSH(Secure Shell), SSL(Secure Socket Layer), SOAP(Simple Object Access Protocol) 및 ARP(Adress Resolution Protocol) 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에 따라, 네트워크 400는 RF 통신을 포함할 수 있다. 예를 들어, RF 통신은 와이파이(wi-fi), 블루투 스(Bluetooth), BLE(Bluetooth Low Energy), WFD(WiFi direct), UWB, NFC(near field communication) 및 Zigbee 을 포함할 수 있으나, 이에 한정되는 것은 아니다. 도 3은 일 실시예에 따른 전자 장치 100의 블록도이다. 도 3을 참조하면, 일 실시예에 따른 전자 장치 100는, 하나 이상의 공간 감지 센서 140A, 통신 모듈 120, 투사 모듈 162, 메모리 130 및 적어도 하나의 프로세서 110를 포함할 수 있다. 그러나, 전자 장치 100은, 도시된 구 성요소보다 많은 구성요소에 의해 구현될 수 있으며, 전술한 예에 한정되지 않는다. 이하 상기 구성요소들에 대 해 차례로 살펴본다. 하나 이상의 공간 감지 센서 140A는 프로세서 110의 제어에 의해 검출 영역으로부터 타겟 디바이스를 검출 할 수 있다. 공간 감지 센서 140A는 적외선 센서 (Infrared sensor), 초음파 센서 (Ultrasonic sensor), 레이저 센서 (Laser sensor), TOF 센서(Time-of-Flight sensor), 카메라 센서(camera sensor), 열 이미징 센서 (Thermal Imaging Sensors), 라이다 센서 (LiDAR Sensors), 자기 감지 센서 (Magnetic Sensors), 울트라 와이드밴드(Ultra-Wideband, UWB) 센서, GPS (Global Positioning System) 중 적어도 하나를 포함할 수 있으며, 이에 한 정 되는 것은 아니다. 일 실시예에 따라, 공간 감지 센서 140A는, 3D 센서로서, 전자 장치 100 주변의 3D 공간에서 객체의 형태와 위 치를 측정할 수 있으며, TOF(Time-of-Flight) 방식, 스테레오 비전(Stereo Vision) 방식 또는 구조광 (Structured Light Sensor) 방식 중 적어도 하나로 동작할 수 있다. 하나 이상의 공간 감지 센서 140A는 프로세서 110의 제어에 의해 검출 영역에 관한 정보를 획득할 수 있다. 하 나 이상의 공간 감지 센서 140A는, 검출 영역에 관한 정보로서, 검출 영역 내 투사면의 형상에 관련된 정보; 검 출 영역 내 객체들의 배치에 관련된 정보; 검출 영역 내 객체의 형상에 관련된 정보; 검출 영역 내 객체의 3D 모델링 정보 등을 획득할 수 있다. 그러나, 전술한 예에 한정되지 않는다. 통신 모듈 120은 프로세서 110의 제어에 의해 주변 디바이스들 200 또는 서버 300와 연동할 수 있다. 통신 모듈 120은 타겟 디바이스에 관한 정보를 획득하기 위해 타겟 디바이스 또는 서버 300와 네트워크 400을 통해서 통신 할 수 있다. 통신 모듈 120은, 타겟 디바이스에 관한 정보로서, 디바이스의 모델명; 디바이스의 형상에 관련된 정보; 디바이 스의 3D 모델링 정보; 디바이스의 실시간 동작 상태 관련 정보; 디바이스에 내장된 데이터; 네트워크 관련 정보; 벤더(Vendor) 관련 정보; 및 사용자 계정 관련 정보; 등을 획득할 수 있다. 그러나, 전술한 예에 한정되 지 않는다. 투사 모듈 162은 프로세서 110 의 제어에 의해 그래픽 이미지를 투사면에 투사할 수 있다. 투사 모듈 162은 광 학 모듈로 언급될 수도 있다. 메모리 130는 적어도 하나의 프로세서 130의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 전자 장치 100로 입력되거나 전자 장치 100로부터 출력되는 데이터를 저장할 수 있다. 메모리 130는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마 이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 일 실시예에 따른 메모리 130는 본 개시에서 개시된 타겟 디바이스와 연관된 그래픽 이미지를 투사하는 기능을 수행하는 하나 이상의 인스트럭션을 포함할 수 있다. 적어도 하나의 프로세서 110는 전자 장치 100의 전반적인 동작을 제어한다. 예를 들어, 적어도 하나의 프로세서 110는, 메모리 130에 저장된 하나 이상의 인스트럭션을 실행함으로써, 공간 감지 센서 140A, 통신 모듈 120 및 투사 모듈 162을 제어할 수 있으며, 도 1 내지 도 12에 기재된 전자 장치의 기능을 수행할 수 있다. 프로세서 110는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 예를 들어, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구 조로 설계될 수 있다. 일 실시예에 따라, 적어도 하나의 프로세서 110는 하나 이상의 공간 감지 센서 140A를 이용하여, 검출 영역으로 부터 타겟 디바이스를 검출할 수 있다. 적어도 하나의 프로세서 110는 통신 모듈 120을 통해 타겟 디바이스에 관한 정보를 획득할 수 있다. 적어도 하나의 프로세서 110는 타겟 디바이스에 관한 정보에 기반하여 그래픽 이 미지를 결정할 수 있다. 적어도 하나의 프로세서 110는 결정된 그래픽 이미지를 투사면에 투사하도록 투사 모듈 162을 제어할 수 있다. 일 실시예에 따라, 적어도 하나의 프로세서 110는 그래픽 이미지를 타겟 디바이스의 외부 영역에 투사하도록 투 사 모듈을 제어할 수 있다. 일 실시예에 따라, 적어도 하나의 프로세서 110는 공간 감지 센서 140A를 통해 검출 영역에 관한 정보를 획득할 수 있다. 적어도 하나의 프로세서 110는 검출 영역에 관한 정보를, 기 수집된 디바이스 데이터 베이스 또는 획 득된 타겟 디바이스에 관한 정보 중 적어도 하나와 비교함으로써, 타겟 디바이스를 검출할 수 있다.일 실시예에 따라, 적어도 하나의 프로세서 110는 검출된 타겟 디바이스와 사용자와의 상호작용없이 자동으로 연동할 수 있다. 일 실시예에 따라, 검출 영역에 관한 정보는, 검출 영역 내 투사면의 형상에 관련된 정보; 검출 영역 내 객체들 의 배치에 관련된 정보; 검출 영역 내 객체의 형상에 관련된 정보; 검출 영역 내 객체의 3D 모델링 정보; 중 적 어도 하나를 포함할 수 있다. 일 실시예에 따라, 타겟 디바이스에 관한 정보는, 디바이스의 모델명; 디바이스 ID (identifier); 디바이스의 형상에 관련된 정보; 디바이스의 3D 모델링 정보; 디바이스의 실시간 동작 상태 관련 정보; 디바이스에 내장된 데이터; 네트워크 관련 정보; 벤더(Vendor) 관련 정보; 및 사용자 계정 관련 정보; 중 적어도 하나를 포함할 수 있다. 일 실시예에 따라, 적어도 하나의 프로세서 110는 통신 모듈 120을 통해 타겟 디바이스 외 다른 주변 디바이스 에 관한 정보를 획득할 수 있다. 적어도 하나의 프로세서 110는 타겟 디바이스 외 다른 주변 디바이스에 관한 정보에 기반하여 그래픽 이미지를 결정하고, 결정된 그래픽 이미지를 타겟 디바이스가 포함된 투사면에 투사하 도록 투사 모듈 162을 제어할 수 있다. 일 실시예에 따라, 적어도 하나의 프로세서 110는 하나 이상의 공간 감지 센서 140A를 이용하여, 전자 장치 100 주위의 모든 방향을 둘러싼 360도 영역을 검출 영역으로 할 수 있다. 일 실시예에 따라, 전자 장치 100는 자율 주행 수단을 더 포함할 수 있다. 적어도 하나의 프로세서 110는 전자 장치 100가 자율 주행 수단을 이용하여 이동하는 동안, 실시간으로 검출 영역에 관한 정보를 업데이트하고, 실 시간으로 타겟 디바이스에 관한 정보를 획득할 수 있다. 일 실시예에 따라, 적어도 하나의 프로세서 110는 그래픽 이미지와 연관된 디바이스를 제어하기 위한 사용자의 입력을 수신할 수 있다. 적어도 하나의 프로세서 110는 수신된 사용자의 입력에 따라, 그래픽 이미지와 연관된 디바이스를 제어하고, 제어 결과를 투사하도록 투사 모듈 162을 제어할 수 있다. 일 실시예에 따라, 적어도 하나의 프로세서 110는 타겟 디바이스로부터 그래픽 이미지와 연관된 디바이스를 제 어한 결과를 지시하는 입력을 수신할 수 있다. 적어도 하나의 프로세서 110는 타겟 디바이스로부터 수신된 입력 에 기초하여, 지시된 제어 결과를 투사하도록 투사 모듈 162을 제어할 수 있다. 본 개시의 일 실시예에 따라 전자 장치 100는 공간 감지 센서 및 통신 모듈을 활용하여, 주변 디바이스를 인식 하고, 주변 디바이스에 관한 정보와 연관된 그래픽 이미지를 제공함으로써, 사용자로 하여금 새로운 디스플레이 기능 및 새로운 연결 사용성을 경험하도록 할 수 있다. 다만, 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급하지 않은 또 다른 효과 들은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다. 도 4는 일 실시예에 따른 전자 장치 100의 구체적인 블록도이다. 도 4를 참조하면, 전자 장치100는, 예를 들면, 도 3에 도시된 전자 장치 100의 전체 또는 일부를 구성할 수 있 다. 전자 장치 100는 적어도 하나의 프로세서 110, 통신 모듈 120, 메모리 130, 센서 모듈 140, 입력 장치 150, 광학 모듈 160, 인터페이스 170, 오디오 모듈 180, 카메라 모듈 191, 인디케이터 192, 모터 193, 전력관리 모듈 194, 배터리 195, 무선 충전 모듈 196를 포함할 수 있다. 적어도 하나의 프로세서 110는 운영체제 또는 응용 프로그램을 구동하여 프로세서 110에 연결된 다수의 하드웨 어 또는 소프트웨어 구성요소들을 제어할 수 있고, 멀티미디어 데이터를 포함한 각종 데이터 처리 및 연산을 수 행할 수 있다. 프로세서 110는, 예를 들면, SoC(system on chip) 로 구현될 수 있다. 프로세서 110는 GPU(graphic processi`ng unit, 미도시)를 더 포함할 수 있다. 통신 모듈 120은 전자 장치 100와 네트워크 400를 통해 연결된 다른 전자 장치들, 예를 들어, 주변 디바이스들 200나 서버 300 간의 통신에서 데이터 송수신을 수행할 수 있다. 일 실시예에 따르면, 통신 모듈 120은 Wifi 모 듈 121, BT 모듈 122 및 RF(radio frequency) 모듈 123을 포함할 수 있다. 와이파이(Wifi) 모듈 121 및 BT 모듈 122은, 예를 들면, 해당하는 모듈을 통해서 송수신되는 데이터를 처리하는 프로세서를 포함할 수 있다. 도 4에서는 Wifi 모듈 121 및 BT 모듈 122 이 각각 별개의 블록으로 도시되었으나, 일 실시예에 따르면, Wifi 모듈 121 또는 BT 모듈 122중 적어도 일부는 하나의 integrated chip(IC) 또는 IC패키지 내에 포함될 수 있다. 예를 들면, Wifi 모듈 121 및 BT 모듈 122 각각에 대응하는 프로세서들 중 적어도 일부는 하나의 SoC로 구현될 수 있다. RF 모듈 123은 데이터의 송수신, 예를 들면, RF 신호의 송수신을 할 수 있다. RF 모듈 123은, 도시하지 않았으 나, 예를 들면, 트랜시버(transceiver), PAM(power amp module), 주파수 필터(frequency filter) 또는 LNA(low noise amplifier) 등을 포함할 수 있다. 또한, RF 모듈 123은 무선 통신에서 자유 공간상의 전자파를 송수신하 는 부품, 예를 들면, 도체 또는 도선 등을 더 포함할 수 있다. 도 4에서는 Wifi 모듈 121 및 BT 모듈 122이 하 나의 RF 모듈 123을 서로 공유하는 것으로 도시되어 있으나, 일 실시예에 따르면, Wifi 모듈 121 및 BT 모듈 122 적어도 하나는 별개의 RF 모듈을 통하여 RF 신호의 송수신을 수행할 수 있다. 메모리 130는 내장 메모리 131 를 포함할 수 있다. 내장 메모리 131는, 예를 들면, 휘발성 메모리(예를 들면, DRAM(dynamic RAM), SRAM(static RAM), SDRAM(synchronous dynamic RAM) 등) 또는 비휘발성 메모리(non- volatile Memory, 예를 들면, OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, NAND flash memory, NOR flash memory 등) 중 적어도 하나를 포함할 수 있다. 메모리 130는 프로세서 110의 제어에 의해 전자 장치 100를 구동하고 제어하는 다양한 데이터, 프로그램 또는 어플리케이션을 저장할 수 있다. 메모리 130는 적어도 하나의 프로세서 110, 통신 모듈 120, 센서 모듈 140, 입 력 장치 150, 광학 모듈 160, 인터페이스 170, 오디오 모듈 180, 카메라 모듈 191, 인디케이터 192, 모터 193, 전력관리 모듈 194, 배터리 195, 무선충전모듈 196의 구동에 대응되는 입력/출력되는 신호 또는 데이터를 저장 할 수 있다 센서 모듈 140은 물리량을 계측하거나 전자 장치 100의 작동 상태를 감지하여, 계측 또는 감지된 정보를 전기 신호로 변환할 수 있다. 센서 모듈 140은, 예를 들면, 공간 감지 센서 140A, 자이로 센서 140B, 가속도 센서 140C, 초음파 센서 140D, 적외선 센서 140E, 홀 센서 140F, 근접 센서 140G, 조도 센서 140H 중 적어도 하나를 포함할 수 있다. 추가적으로 또는 대체적으로, 센서 모듈 140은, 예를 들면, 도시하지 않았으나, 제스처 센서 (gesture sensor), 후각 센서(E-nose sensor), EMG 센서(electromyography sensor), EEG 센서 (electroencephalogram sensor), ECG 센서(electrocardiogram sensor), 홍채 센서 또는 지문 센서, 압력 센서 등을 포함할 수 있다. 센서 모듈 140은 그 안에 속한 적어도 하나 이상의 센서들을 제어하는 제어 회로를 더 포 함할 수 있다. 입력 장치 150은 키(key) 151 를 포함할 수 있다. 키 151는 예를 들면, 물리적인 버튼, 광학식 키 또는 키패드 를 포함할 수 있다. 일 실시예에 따르면, 상기 전자 장치 100는 통신 모듈 120를 이용하여 이와 연결된 외부 장 치(예: 주변 디바이스들 200 또는 서버300)로부터 사용자 입력을 수신할 수도 있다. 광학 모듈 160은 조명 모듈 161와 투사 모듈 162를 포함할 수 있다. 투사 모듈 163은 스크린에 빛을 투사하여 영상을 표시할 수 있다. 일 실시예에 따라 광학 모듈 160은 전자 장치 100이 투사면으로부터 소정 거리 이내에 접근한 경우에는 컨텐츠 를 투사할 수 있다. 투사 모듈 162이 빛을 투사하는 방식으로는, DLP, LCOS, 3LCD, LCD, 레이저 방식 등이 있다. DLP은 화면 표시 소자(Display Element)의 하나인 디지털 마이크로미러 디스플레이(DMD)를 사용한 프로젝션 디 스플레이 방식이다. LCOS(Liquid Crystal on Silicon)방식은 다수 개의 스캔라인과 데이터라인에 의해 픽셀을 정의하고, 소정의 분자배열을 갖는 액정을 구비하고, 상기 액정에 의해 외부로부터 입력되는 빛을 투과 및 반사 하여 디스플레이하는 LCOS 패널을 이용해서 투사할 수도 있다. 3LCD방식은 프로젝터의 램프 광원이 투과되는 액 정 표시장치(LCD)가 3개로 나누어져 있으며, 3LCD는 램프에서 나온 빛을 LCD 패널을 통해 렌즈에서 확대하기 전 에 색깔별로 나뉜 빨강, 파랑, 초록의 3LCD를 사용한다. 상기와 같은 3LCD방식으로 프로젝터를 구현할 수도 있 다. 또한 LCD와 같이 하나의 LCD패널을 이용한 프로젝터를 구비할 수도 있다. Laser방식은 적색, 녹색 및 청색 레이저 발광소자로 이루어지는 광원, 광원에서 출사된 레이저 광이 입사되는 광터널, 및 광터널을 통해 입사된 레이저 광을 이용하여 스크린상에 영상을 투사하는 디스플레이 소자를 포함한다. 광터널의 내부에는, 광원으로 부터 출사된 레이저 광의 일부 색을 투과 또는 반사하여 합성하는 합성모듈과, 합성모듈을 통해 합성된 레이저 광의 위상을 불규칙적으로 변환하여 스펙클을 제거하는 스펙클 제거부가 형성된 구조를 투사 모듈로 구비할 수 도 있다. 인터페이스 170는, 예를 들면, HDMI(high-definition multimedia interface) 171, USB(universal serial bus) 172를 포함할 수 있다. 인터페이스 170는, 예를 들면, 통신 모듈 120에 포함될 수 있다. 추가적으로 또는 대체 적으로, 인터페이스 170는, 예를 들면, MHL(mobile high-definition link) 인터페이스, SD(secure Digital) 카 드/MMC(multi-media card) 인터페이스 또는 IrDA(infrared data association) 규격 인터페이스를 포함할 수 있 다. 오디오 모듈 180은 소리(sound)와 전기신호를 쌍방향으로 변환시킬 수 있다. 상기 오디오 모듈 180은, 예를 들 면, 스피커 181, 또는 마이크 182182 등을 통해 입력 또는 출력되는 소리 정보를 처리할 수 있다. 일 실시예에 따라 전자 장치100는 오디오 모듈 180을 구비하지 않고, 통신 모듈 120에 포함된 BT 모듈 122을 이용해서 오디 오를 외부 장치에 전송할 수도 있다. 카메라 모듈 191은 정지 영상 및 동영상을 촬영할 수 있는 장치로서, 한 실시예에 따르면, 하나 이상의 이미지 센서(예: 전면 센서 또는 후면 센서), 렌즈(미도시), ISP(image signal processor, 미도시) 또는 플래쉬 (flash, 미도시)(예: LED 또는 xenon lamp)를 포함할 수 있다. 카메라 모듈 191은 카메라 인식 범위에서 제스처를 포함하는 사용자의 모션에 대응되는 영상(예를 들어, 연속되 는 프레임)을 수신한다. 예를 들어, 카메라 모듈 191은 인식 범위는 카메라 모듈 191에서부터 사용자까지 0.1 ~ 5 m 이내 거리가 될 수 있다. 사용자 모션은 예를 들어, 사용자의 얼굴, 표정, 손, 주먹, 손가락과 같은 사용자 의 신체 일부분 또는 사용자 일부분의 모션 등을 포함할 수 있다. 인디케이터 192는 전자 장치 100 혹은 그 일부(예: 프로세서 110)의 특정 상태, 예를 들면, 부팅 상태, 메시지 상태 또는 충전 상태 등을 표시할 수 있다. 모터 193는 전기적 신호를 기계적 진동으로 변환할 수 있다. 전자 장치 100는, 도시하지 않았으나, 모바일 TV 지원을 할 수 있는 처리 장치(예: GPU)를 포함할 수 있다. 모바일 TV지원을 할 수 있는 처리 장치는, 예를 들면, DMB(digital multimedia broadcasting), DVB(digital video broadcasting) 또는 미디어플로우(media flow) 등의 규격에 따른 미디어 데이터를 처리할 수 있다. 전력 관리 모듈 194는 전자 장치 100의 전력을 관리할 수 있다. 전력 관리 모듈 194는, 도시하지 않았으나, 예 를 들면, PMIC(power management integrated circuit), 충전 IC(charger integrated circuit) 또는 배터리 또 는 연료 게이지(battery or fuel gauge)를 포함할 수 있다. 일 실시예에 따라 전력관리 모듈 194는 전자 장치 100가 투사면에 위치하거나 또는 투사면으로부터 소정 거리 이내에 접근한 경우에는 광학모듈 160으로 전원을 인가하여 광학모듈 160이 동작하게 할 수 있다. 일 실시예에 따라 전력관리 모듈 194는 전자 장치 100이 투사면으로부터 소정 거리 이내에 접근하지 않은 경우 에는 광학 모듈 160으로의 전원을 차단하여 광학 모듈 160이 동작하지 않도록 할 수 있다. PMIC는, 예를 들면, 집적회로 또는 SoC 반도체 내에 탑재될 수 있다. 충전 방식은 유선과 무선으로 구분될 수 있다. 충전 IC는 배터리를 충전시킬 수 있으며, 충전기로부터의 과전압 또는 과전류 유입을 방지할 수 있다. 일 실시예에 따르면, 충전 IC는 유선 충전 방식 또는 무선 충전 방식 중 적어도 하나를 할 수 있는 충전 IC를 포함 할 수 있다. 무선 충전 모듈 196은 무선 충전을 할 수 있는 회로, 예를 들면, 코일 루프, 공진 회로 또는 정류기 등의 회로 를 포함할 수 있으며, 무선 충전 방식으로는, 예를 들면, 자기공명 방식, 자기유도 방식 또는 전자기파 방식 등 이 있다. 배터리 게이지는, 예를 들면, 배터리 195의 잔량, 충전 중 전압, 전류 또는 온도를 측정할 수 있다. 배터리 195 는 전기를 저장 또는 생성할 수 있고, 그 저장 또는 생성된 전기를 이용하여 전자 장치 100에 전원을 공급할 수 있다. 배터리 195는, 예를 들면, 충전식 전지(rechargeable battery) 또는 태양 전지(solar battery)를 포함할 수 있다. 본 개시의 일 실시예에 따른 전자 장치 100의 전술한 구성요소들 각각은 하나 또는 그 이상의 부품(component) 으로 구성될 수 있으며, 해당 구성 요소의 명칭은 전자 장치의 종류에 따라서 달라질 수 있다. 본 개시의 일 실 시예에 따른 전자 장치 100는 전술한 구성요소 중 적어도 하나를 포함하여 구성될 수 있으며, 일부 구성요소가 생략되거나 또는 추가적인 다른 구성요소를 더 포함할 수 있다. 또한, 본 개시의 일 실시예에 따른 전자 장치 100의 구성 요소들 중 일부가 결합되어 하나의 개체(entity)로 구성됨으로써, 결합되기 이전의 해당 구성 요소 들의 기능을 동일하게 수행할 수 있다.도 5는 일 실시예에 따른 전자 장치 100의 동작 방법 500을 설명하기 위한 흐름도이다. 도 5를 참조하면, 단계 510에서, 일 실시예에 따른 전자 장치 100는, 하나 이상의 공간 감지 센서를 이용하여, 검출 영역으로부터 타겟 디바이스를 검출할 수 있다. 전자 장치 100는 하나 이상의 공간 감지 센서를 이용하여, 전자 장치 100 주변의 3D 공간(e.g. 검출 영역)에 존재하는 다양한 객체의 형태와 위치를 측정할 수 있으며, TOF(Time-of-Flight) 방식, 스테레오 비전(Stereo Vision) 방식 또는 구조광(Structured Light Sensor) 방식 중 적어도 하나로 동작할 수 있다. 전자 장치 100는, 하나 이상의 공간 감지 센서를 이용하여, 검출 영역에 관한 정보를 획득할 수 있다. 검출 영 역에 관한 정보는, 검출 영역 내 투사면의 형상에 관련된 정보; 검출 영역 내 객체들의 배치에 관련된 정보; 검 출 영역 내 객체의 형상에 관련된 정보; 검출 영역 내 객체의 3D 모델링 정보; 중 적어도 하나를 포함할 수 있 다. 검출 영역 내 객체들은, 전자 장치 100의 주변에 존재하는 형태를 가진 다양한 객체들을 의미할 수 있으며, 벽 면, 천장 면, 바닥 면, 디바이스, 물체, 사람, 동물 등을 모두 포함할 수 있다. 전자 장치 100는, 상기 검출 영역에 관한 정보를 기 수집된 디바이스 데이터 베이스와 비교하여 타겟 디바이스 를 검출 할 수 있다. 디바이스 데이터 베이스는, 전자 장치 100가 기 수집한 주변 디바이스들에 관한 정보의 리 스트이거나, 또는 전자 장치 100와 연동된 서버가 기 수집한 서버와 연동된 주변 디바이스들에 관한 정보의 리 스트일 수 있다. 일 실시예에 따라, 전자 장치 100는, 검출 영역에 관한 정보와 디바이스 데이터 베이스에 포함된 정보와 비교하 고, 매칭되는 정보에 해당하는 디바이스를 타겟 디바이스로 특정하여, 타겟 디바이스를 검출할 수 있다. 일 실시예에 따라, 전자 장치 100는, 공간 감지 센서를 이용하여 검출한 타겟 디바이스가 복수 개인 경우, 하나 의 타겟 디바이스를 특정하기 위해, 검출 영역에 관한 정보를, 단계 520에서, 통신 모듈을 이용하여 획득한 타 겟 디바이스에 관한 제1 정보와 추가로 비교하여 하나의 타겟 디바이스를 검출할 수 있다. 일 실시예에 따라, 전자 장치 100는 미리 정의된 우선순위에 따라, 검출된 복수의 디바이스들 중 하나의 타겟 디바이스를 특정하여, 타겟 디바이스를 검출할 수 있다. 예를 들어, 전자 장치 100는 검출 영역에 관한 정보와 가장 가깝게 매칭되는 정보에 대응하는 디바이스를 우선 적으로 타겟 다바이스로 특정하여 검출할 수 있다. 다른 예로, 전자 장치 100는 검출된 복수의 디바이스들 중 디스플레이를 내장하는 디바이스를 디스플레이를 내장하지 않는 디바이스들 보다 우선적으로 타겟 디바이스로 특정하여 검출할 수 있다. 또는, 반대로, 전자 장치 100는 검출된 복수의 디바이스들 중 디스플레이를 내장하지 않는 디바이스를 디스플레이를 내장하는 디바이스들 보다 우선적으로 타겟 디바이스로 특정하여 검출할 수 있다. 다른 예로, 전자 장치 100는, 단계 520에서, 통신 모듈을 이용하여 획득한 타겟 디바이스에 관한 제1 정 보 중 네트워크 관련 정보인, 디바이스의 RSSI(Received Signal Strength Indicator) 값이 가장 큰 값을 가지 는 디바이스를 우선적으로 타겟 디바이스로 특정하여 검출 할 수 있다. 일 실시예에 따라, 전자 장치 100는, 사용자와의 상호작용없이 검출된 타겟 디바이스와 자동으로 연동할 수 있 다. 전자 장치 100는, 타겟 디바이스를 검출한 후, 타겟 디바이스가 서버 300와 연동되지 않거나 또는 전자 장 치 100와 연동되지 않은 경우, 사용자와의 상호작용없이 자동으로, 타겟 디바이스를 서버 300 또는 전자 장치 100와 연동시킬 수 있다. 종래에는, 디바이스의 서버 또는 다른 디바이스와의 연동을 위해서, 디바이스에서 브 로드캐스팅 또는 서치 시도 후 사용자가 컨펌하는 일련의 동작에 따라 사용자와의 상호작용이 필수적이었다. 일 실시예에 따라, 전자 장치 100는 사용자와의 상호작용없이 자동으로 타겟 디바이스를 서버 300 또는 전자 장치 100와 연동시킴으로써, 사용자의 편의를 향상시킬 수 있다. 단계 520에서, 일 실시예에 따른 전자 장치 100는, 통신 모듈을 이용하여 타겟 디바이스에 관한 정보를 획득할 수 있다. 전자 장치 100는 통신 모듈을 이용하여 네트워크를 통해, 타겟 디바이스로부터 직접 또는 서버로부터, 타겟 디바이스에 관한 정보를 획득 할 수 있다. 전자 장치 100가 타겟 디바이스를 검출하기 위해 사용하는 타겟 디바이스에 관한 정보는 타겟 디바이스에 관한 제1 정보로 언급될 수 있다. 전자 장치 100가 그래픽 이미지를 결정하기 위해 사용하는 타겟 디바이스에 관한 정보는 타겟 디바이스에 관한 제2 정보를 언급될 수 있다. 일 실시예에 따라, 전자 장치 100는 통신 모듈을 이용하여 네트워크를 통해 타겟 디바이스에 관한 제1 정보를 획득할 수 있다. 예를 들어, 전자 장치 100는, 타겟 디바이스와 연동하기 전에 타겟 디바이스에 관한 제1 정보를 획득할 수 있다. 전자 장치 100는, 타겟 디바이스와 연동하고 나서도 타겟 디바이스에 관한 제1 정보를 획득 할 수 있음은 물론이다. 타겟 디바이스에 관한 제1 정보는, 디바이스의 모델명; 디바이스 ID (identifier); 디바이스의 형상에 관련된 정보; 디바이스의 3D 모델링 정보; 네트워크 관련 정보; 또는 벤더(Vendor) 관련 정보 중 적어도 하나를 포함할 수 있다. 타겟 디바이스에 관한 제1 정보 중 네트워크 관련 정보는, 디바이스의 RSSI(Received Signal Strength Indicator) 값을 포함할 수 있다. 디바이스의 RSSI 값은 RF 신호의 강도를 나타내는 측정 값으로, dBm(데시벨 밀리와트) 단위로 표현될 수 있으며, 기본적으로 음수로 표현되며 0에 가까울수록 신호의 세기가 강하고, 신호 의 범위는 대부분 0 ~ -100 dBm까지 사용한다. 일 실시예에 따라, 전자 장치 100은 타겟 디바이스에 관한 제1 정보를 타겟 디바이스를 검출하는 데 사용할 수 있다. 전자 장치 100는, 단계 510에서 공간 감지 센서를 이용하여 검출한 타겟 디바이스가 복수 개인 경우, 하나의 타 겟 디바이스를 특정하기 위해, 단계 510에서 공간 감지 센서를 이용하여 획득한 검출 영역에 관한 정보를, 통신 모듈을 이용하여 획득한 타겟 디바이스에 관한 제1 정보와 추가로 비교하여 하나의 타겟 디바이스를 검출할 수 있다. 일 실시예에 따라, 전자 장치 100는 통신 모듈을 이용하여 네트워크를 통해 타겟 디바이스에 관한 제2 정보를 획득할 수 있다. 예를 들어, 전자 장치 100는 타겟 디바이스와 연동한 후에 타겟 디바이스에 관한 제2 정보를 획득할 수 있다. 타겟 디바이스에 관한 제2 정보는, 디바이스의 실시간 동작 상태 관련 정보; 디바이스에 내장된 데이터; 또는 사용자 계정 관련 정보; 중 적어도 하나를 포함할 수 있다. 전자 장치 100는 타겟 디바이스에 관한 제2 정보 중 일부를 사용자의 동의 하에 획득할 수 있다. 일 실시예에 따라, 전자 장치 100는 타겟 디바이스에 관한 제2 정보를 그래픽 이미지를 결정하는데 사용할 수 있다. 단계 530에서, 일 실시예에 따른 전자 장치 100는, 타겟 디바이스에 관한 정보에 기반하여, 그래픽 이미지를 결 정할 수 있다. 그래픽 이미지는 타겟 디바이스에 관한 정보를 사용자에게 디스플레이하기 위한 것이다. 일 실시예에 따라, 전자 장치 100는 획득한 타겟 디바이스에 관한 정보, (예를 들어, 디바이스의 실시간 동작 상태 관련 정보, 디바이스에 내장된 데이터 등) 중 사용자에게 필요한 정보를 선택하여 그 정보와 연관된 그래 픽 이미지를 결정할 수 있다. 일 실시예에 따라, 전자 장치 100는 미리 정의된 우선순위에 따라 획득한 타겟 디바이스에 관한 정보 중 사용자 에게 필요한 정보를 선택할 수 있다. 예를 들어, 전자 장치 100는 타겟 디바이스에 관한 제2 정보를 타겟 디바이스에 관한 제1 정보 보다 우선적으로 선택할 수 있다. 다른 예로, 전자 장치 100는 타겟 디바이스에 관한 정보 중 현재 타겟 디바이스의 동작 상태와 관련된 정보를 최우선적으로 선택할 수 있다. 일 실시예에 따라, 전자 장치 100는 획득한 타겟 디바이스에 관한 정보 중 사용자에게 필요한 정보를 추출하여, 사용자에게 디스플레이를 원하는 정보를 선택하도록 할 수 있다. 전자 장치 100는 디스플레이를 원하는 정보를 선택하는 사용자의 입력에 따라, 사용자에게 필요한 정보를 선택할 수 있다. 단계 540에서, 일 실시예에 따른 전자 장치 100는, 결정된 그래픽 이미지를 투사면에 투사하도록 투사 모듈을 제어할 수 있다. 사용자는 전자 장치 100에 의해 투사된 그래픽 이미지를 이용하여 타겟 디바이스를 제어할 수 있다. 전자 장치 100는 결정된 그래픽 이미지를 타겟 디바이스의 외부 영역에 투사하도록 투사 모듈을 제어할 수 있다. 이에 따라, 사용자는 사용 환경을 방해 받지 않고 투사된 그래픽 이미지를 이용해 타겟 디바이스를 제어 할 수 있다. 본 개시의 일 실시예에 따라 전자 장치 100는 공간 감지 센서 및 통신 모듈을 활용하여, 주변 디바이스를 인식 하고, 주변 디바이스에 관한 정보와 연관된 그래픽 이미지를 제공함으로써, 사용자로 하여금 새로운 디스플레이기능 및 새로운 연결 사용성을 경험하도록 할 수 있다. 다만, 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급하지 않은 또 다른 효과 들은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다. 도 6은 일 실시예에 따른 전자 장치 100가 하나 이상의 공간 감지 센서 140A를 통해 타겟 디바이스를 검출하기 위해 검출 영역에 관한 정보를 획득하는 과정의 일 예시를 설명하기 위한 도면이다. 도 6을 참조하면, 일 실시예에 따른 전자 장치 100는, 하나 이상의 공간 감지 센서 140A를 이용하여, 검출 영역 으로부터 타겟 디바이스 601을 검출할 수 있다. 일 실시예에 따라, 공간 감지 센서 140A는, 3D 센서일 수 있으며, 검출 영역은 3D 공간일 수 있다. 전자 장치 100는 하나 이상의 공간 감지 센서 140A를 이용하여, 전자 장치 100 주변의 3D 공간(e.g. 검출 영역)에 존재하 는 다양한 객체의 형태와 위치를 측정할 수 있다. 하나 이상의 공간 감지 센서 140A는, 3D 센서로서, TOF(Time- of-Flight) 방식, 스테레오 비전(Stereo Vision) 방식 또는 구조광(Structured Light Sensor) 방식 중 적어도 하나로 동작할 수 있다. 3D TOF 방식의 공간 감지 센서는, 빛을 방출하고 해당 빛이 객체에 도달하고 돌아오는 데 걸리는 시간을 측정하 여, 빛의 속도를 이용해 거리를 계산할 수 있으며, 레이저 빔 또는 LED 빛을 사용하여 구현될 수 있다. 3D TOF 방식의 공간 감지 센서를 활용함으로써, 전자 장치 100는 주변 3D 공간에서 각 객체와의 정밀한 거리 측정이 가 능하며, 빠른 응답 속도를 가지고, 어두운 환경에서도 잘 동작 할 수 있다. 3D 스테레오 비전 방식의 공간 감지 센서는, 두 개의 카메라 렌즈를 사용하여 객체를 다른 시각에서 볼 때 생기 는 시차를 측정하여 거리를 계산할 수 있다. 3D 스테레오 비전 방식의 공간 감지 센서를 활용함으로써, 전자 장 치 100는 비교적 저렴한 하드웨어를 사용하여 비용을 절감할 수 있으며, 3D 검출 영역에 관한 정밀한 3D 재구성 이 가능하다. 3D 구조광 방식의 공간 감지 센서는, 객체 표면에 패턴을 투사하고, 카메라를 사용하여 그 패턴이 변형되는 것 을 관찰하고, 패턴의 왜곡 정도를 분석하여 객체의 3D 형태를 재구성할 수 있다. 3D 구조광 방식의 공간 감지 센서를 활용함으로써, 전자 장치 100는, 조명 조건에 상관없이 다양한 객체를 검출할 수 있고, 3D 검출 영역에 관한 정밀한 3D 재구성이 가능하다. 이하에서는, 일 실시예에 따라, 전자 장치 100가 3D TOF 방식의 공간 감지 센서를 활용하여, 타겟 디바이스를 검출하는 과정의 일 예시를 설명한다. 일 실시예에 따라, 전자 장치 100는, 하나 이상의 3D TOF 방식의 공간 감지 센서 140A를 이용하여, 검출 영역 내 다양한 객체 601, 602, 603, 604를 구성하는 픽셀들을 향해 복수의 광신호 (e,g 레이저 빔 또는 LED 빛)를 방출할 수 있다. 전자 장치 100는 검출 영역 내 다양한 객체 601, 602, 603, 604를 구성하는 픽셀들 각각의 신 뢰도(Confidence Level)를 파악하여, 신뢰도가 높은 픽셀들에 복수의 광신호를 방출할 수 있다. 검출 영역 내 객체들은, 전자 장치 100의 주변에 존재하는 형태를 가진 다양한 객체들을 의미할 수 있으며, 벽면 604, 천장 면, 바닥 면, 디바이스 601-603, 물체, 사람, 동물 등을 모두 포함할 수 있다. 전자 장치 100는 방출한 복수의 광신호의 복수의 반사 신호를 감지할 수 있다. 복수의 반사 신호는 방출된 복수 의 광신호가 검출 영역 내 다양한 객체 601, 602, 603, 604를 구성하는 픽셀들에서 반사되어 전자 장치 100로 돌아오는 신호이다. 전자 장치 100는 복수의 반사 신호에 기반하여, 방출한 복수의 광신호 각각에 대한 TOF 시 간을 측정할 수 있다. TOF 시간은, 각 광신호가 방출된 시점부터 반사되어 되돌아오는 시점까지 걸리는 시간을 의미한다. 전자 장치 100는 복수의 광신호 각각에 대한 TOF 시간에 기반하여, 수학식 1에 따라, 검출 영역 내 존재하는 다 양한 객체들 601, 602, 603, 604까지의 거리를 계산할 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0141408", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서, 은 전자 장치 100로부터 검출 영역 내 존재하는 다양한 객체들을 구성하는 각각의 픽셀들까 지의 거리이다. 은 각각의 픽셀들에 방출한 복수의 광신호들 각각의 TOF 시간이다. c는 빛의 속도로, 3 x 10^8 m/s 이다. 전자 장치 100는 계산된 검출 영역 내 존재하는 다양한 객체들 601, 602, 603, 604까지의 거리에 기반하여, 검 출 영역에 관한 정보를 획득할 수 있다. 검출 영역에 관한 정보는, 검출 영역 내 투사면 604의 형상에 관련된 정보; 검출 영역 내 객체들 601, 602, 603, 604의 배치에 관련된 정보; 검출 영역 내 객체 601, 602, 603, 604 의 형상에 관련된 정보; 검출 영역 내 객체 601, 602, 603, 604의 3D 모델링 정보; 중 적어도 하나를 포함할 수 있다. 도 6에서는, 전자 장치 100의 공간 감지 센서 140A가 전자 장치 100를 기준으로 상단 영역을 검출영역으로 하지 만, 일 실시예에 따라, 전자 장치 100는 전자 장치 100를 기준으로 하단 영역을 검출영역으로 할 수 있다. 또한, 일 실시예에 따라, 전자 장치 100는 하나 이상의 3D TOF 방식의 공간 감지 센서를 이용하여, 전자 장치 주위의 모든 방향을 둘러싼 360도 영역을 검출 영역으로 할 수 있다. 도 7은 일 실시예에 따른 전자 장치 100가 검출 영역에 관한 정보에 기반하여 타겟 디바이스 701를 검출하는 과 정의 일 예시를 설명하기 위한 도면이다. 도 7을 참조하면, 일 실시예에 따른 전자 장치 100는, 공간 감지 센서 140A를 이용하여 검출 영역에 관한 정보 710을 획득할 수 있다. 예를 들어, 검출 영역에 관한 정보 710는, 검출 영역 내 투사면 708의 형상에 관련된 정 보; 검출 영역 내 객체들 701, 702, 703, 708, 709의 배치에 관련된 정보; 검출 영역 내 객체들 701, 702, 703, 708, 709의 형상에 관련된 정보; 검출 영역 내 객체들 701, 702, 703, 708, 709의 3D 모델링 정보; 중 적 어도 하나를 포함할 수 있다. 일 실시예에 따라, 전자 장치 100는, 검출 영역에 관한 정보 710를 기 수집된 디바이스 데이터 베이스 720와 비 교함으로써 매칭되는 정보에 해당하는 디바이스를 타겟 디바이스 701로 검출할 수 있다. 디바이스 데이터 베이스 720은, 전자 장치 100가 기 수집한 주변 디바이스들 701-707 중 적어도 하나에 관한 정 보의 리스트이거나, 또는 전자 장치 100와 연동된 서버 300가 기 수집한 서버 300와 연동된 주변 디바이스들 701-707 중 적어도 하나에 관한 정보의 리스트일 수 있다. 예를 들어, 전자 장치 100는, 검출 영역에 관한 정보 710 중 TV 701의 형상에 관련된 정보 및 TV 701의 3D모델 링 정보가 디바이스 데이터 베이스 720와 가장 가깝게 매칭된다고 판단할 수 있다. 이 경우, 전자 장치 100는 TV 701을 타겟 디바이스로 검출할 수 있다. 예를 들어, 전자 장치 100는, 검출 영역에 관한 정보 710 중 TV 701의 형상에 관련된 정보, TV 701의 3D모델링 정보, 세탁기 702의 형상에 관련된 정보 및 세탁기 702의 3D모델링 정보가 디바이스 데이터 베이스 720와 매칭 된다고 판단할 수 있다. 이 경우, 전자 장치 100는 TV 701 및 세탁기 702를 타겟 디바이스의 후보군으로 검출할 수 있다. 전자 장치 100는, TV 701 및 세탁기 702 중에서, 통신 모듈을 통해 획득한 타겟 디바이스에 관한 정보 730와 비교하여 매칭되는 TV 701를 타겟 디바이스로 검출할 수 있다. 예를 들어, 전자 장치 100는, 검출 영역에 관한 정보 710 및 미리 정의된 우선순위에 기반하여, 디스플레이를 내장한 디바이스인 TV 701를 우선적으로 타겟 디바이스로 검출 할 수 있다. 일 실시예에 따라, 전자 장치 100는, 검출 영역에 관한 정보 710를 통신 모듈을 통해 획득한 타겟 디바이스에 관한 정보 730와 비교함으로써 타겟 디바이스 701를 검출할 수 있다. 예를 들어, 전자 장치 100가 검출 영역에 관한 정보 710과 디바이스 데이터 베이스 720과 비교하여 복수개의 디 바이스 701, 702를 타겟 디바이스 후보군으로 검출한 경우, 전자 장치 100는, 검출 영역에 관한 정보 710를 통 신 모듈을 통해 획득한 타겟 디바이스에 관한 정보 730와 비교함으로써, 매칭되는 TV 701를 타겟 디바이스로 검 출할 수 있다. 예를 들어, 전자 장치 100는 통신 모듈을 통해 획득한 타겟 디바이스에 관한 정보 730 및 미리 정의된 우선순위 에 기반하여, RSSI 값이 가장 큰 TV 701를 우선적으로 타겟 디바이스로 검출할 수 있다. 일 실시예에 따라, 전자 장치 100는 타겟 디바이스 701의 일부분만 검출한 경우에도, 타겟 디바이스 701의 일부 분의 형상에 관련된 정보 또는 타겟 디바이스 701의 일부분의 3D 모델링 정보를 획득하고, 기 수집된 디바이스 데이터 베이스 720 또는 통신 모듈을 통해 획득한 타겟 디바이스 701에 관한 정보 730중 적어도 하나와 비교함으로써, 타겟 디바이스 701을 검출할 수 있다. 도 8는 일 실시예에 따라 검출 영역에 변화가 있는 경우 전자 장치 100의 동작 방법의 일 예시를 설명하기 위한 도면이다. 도 8을 참조하면, 일 실시예에 따라, 전자 장치 100는 도 6에서 설명한 방법에 따라 획득한 검출 영역에 관한 정보를 저장할 수 있다. 전자 장치 100는 검출 영역에 변화가 있는 경우, 도 6에서 설명한 과정을 반복하여 기 저장된 검출 영역에 관한 정보를 업데이트할 수 있다. 도 6에서 설명한 내용과 중복되는 내용은 도 6을 참고하 고, 여기에서는 설명을 생략하기로 한다. 검출 영역에 변화가 있는 경우는, 예를 들어, 사용자가 전자 장치 100의 위치를 이동시킴에 따라 전자 장치 100 의 위치가 달라지거나, 또는 검출 영역에 새로운 디바이스가 추가되는 경우를 포함할 수 있다. 그러나, 이에 한 정되는 것은 아니고, 전자 장치 100가 이전에 획득한 검출 영역에 관한 정보에 변화가 생기는 경우를 모두 포함 할 수 있다. 일 실시예에 따라 전자 장치 100는, 가속도 센서 140C를 이용하여, 전자 장치 100의 운동(movement)을 감지하고, 운동의 길이나 충격량을 측정하여, 전자 장치 100의 위치에 변화가 있는지 여부 또는 단순 충격인지 여부를 판단할 수 있다. 단순 충격이라고 판단한 경우, 전자 장치 100는 기 저장된 검출 영역에 관한 정보를 유 지할 수 있다. 전자 장치 100의 위치에 변화가 있다고 판단한 경우, 전자 장치 100는 기 저장된 검출 영역에 관 한 정보를 업데이트할 수 있다. 일 실시예에 따라 전자 장치 100는, 전자 장치 100의 운동이 감지되지 않더라도, 공간 감지 센서 140A를 이용하 여 검출 영역에 새로운 디바이스(ex, 도 8의 810)가 추가됨을 감지하는 경우, 기 저장된 검출 영역에 관한 정보 를 업데이트할 수 있다. 예를 들어, 전자 장치 100는, 공간 감지 센서 140A를 이용하여 일정한 주기로 검출 영 역을 스캔하여 검출 영역에 새로운 디바이스(ex, 도 8의 810)가 추가되었음을 감지할 수 있다. 일 실시예에 따라 전자 장치 100는, 업데이트된 검출 영역에 관한 정보에 기반하여 도 7에 설명한 바와 같이 타 겟 디바이스를 검출 할 수 있다. 도 7에서 설명한 내용과 중복되는 내용은 도 7을 참고하고, 여기에서는 설명을 생략하기로 한다. 일 실시예에 따라 전자 장치 100는, 업데이트된 검출 영역에 관한 정보에 기반하여 검출한 타겟 디바이스가 서 버 300와 연동되지 않거나 또는 전자 장치 100와 연동되지 않은 경우, 사용자와의 상호작용없이 자동으로, 타겟 디바이스를 서버 300 또는 전자 장치 100와 연동시킬 수 있다. 일 실시예에 따라 전자 장치 100는, 도 5의 단계 520 내지 단계 540에서 설명한 것과 같이, 통신 모듈을 통해, 업데이트된 검출 영역에 관한 정보에 기반하여 검출한 타겟 디바이스에 관한 정보를 획득하고, 그래픽 이미지를 결정하고, 그래픽 이미지를 투사하도록 투사 모듈을 제어할 수 있다. 도 5에서 설명한 내용과 중복되는 내용은 도 5을 참고하고, 여기에서는 설명을 생략하기로 한다. 본 개시의 일 실시예에 따라 전자 장치 100는 가속도 센서 및 공간 감지 센서를 활용하여 검출 영역에 관한 정 보를 업데이트함으로써, 동적으로 사용자에게 주변 디바이스에 관한 정보와 연관된 그래픽 이미지를 제공함으로 써 사용자로 하여금 새로운 디스플레이 기능 및 새로운 연결 사용성을 경험하도록 할 수 있다. 도 9는 일 실시예에 따른 전자 장치 100가 타겟 디바이스 외 다른 주변 디바이스에 관한 정보에 기반하여 그래 픽 이미지를 결정하는 과정의 일 예시를 설명하기 위한 도면이다. 도 9를 참조하면, 일 실시예 따른 전자 장치 100는, 통신 모듈을 통해 타겟 디바이스 910 외 다른 주변 디바이 스 920에 관한 정보를 획득할 수 있다. 예를 들어, 전자 장치 100는 타겟 디바이스 TV 910를 검출한 후, TV 외 주변 디바이스 세탁기 또는 건조기 920 에 관한 정보를 획득할 수 있다. 전자 장치 100와 세탁기 또는 건조기 920는 직접적으로 연동되어 있지 않고, 서버를 공유함으로써 연동될 수 있다. 이 경우, 세탁기 또는 건조기 920가 전자 장치 100의 검출 영역에 없더라 도, 전자 장치 100는 통신 모듈을 이용하여 서버 300를 통해 세탁기 또는 건조기 920에 관한 정보를 획득할 수 있다. 전자 장치 100는, 타겟 디바이스 910 외 다른 주변 디바이스 920에 관한 정보에 기반하여 그래픽 이미지 930를 결정할 수 있다. 전자 장치 100는, 그래픽 이미지 930를 타겟 디바이스 910가 포함된 투사면에 투사하도록 투사 모듈을 제어할 수 있다. 예를 들어, 전자 장치 100는 세탁기 또는 건조기 920에 관한 정보로써, 세탁기 및 건조기 920의 현재 동작 상태 (ex. 세탁 완료, 건조 완료까지 남은 시간 등) 정보를 획득하고, 세탁기 및 건조기 920의 현재 동작 상태 정보 와 연관된 그래픽 이미지 930를 결정하고, 그래픽 이미지 930를 검출한 타겟 디바이스 TV 910가 포함된 투사면 에 투사하도록 투사 모듈을 제어할 수 있다. 전자 장치 100는 사용자의 시청 환경을 방해하지 않도록 세탁기 또는 건조기 920의 현재 동작 상태 정보에 연관 된 그래픽 이미지 930를 타겟 디바이스 TV 910의 외부 영역에 투사하도록 투사 모듈을 제어할 수 있다. 본 개시의 일 실시예에 따라 전자 장치 100는 통신 모듈을 이용하여 검출 영역에 존재하지 않는 물리적으로 떨 어진 주변 디바이스에 관한 정보와 연관된 그래픽 이미지를 타겟 디바이스의 주변에 투사함으로써, 사용자로 하 여금 새로운 디스플레이 기능 및 새로운 연결 사용성을 경험하도록 할 수 있다. 도 10은 일 실시예에 따른 전자 장치 100가 자율 주행 수단을 이용하여 이동하는 경우 전자 장치 100의 동작 방 법의 일 예시를 설명하기 위한 도면이다. 도 10을 참조하면, 일 실시예에 따른 전자 장치 100는 자율 주행 수단 1010을 포함할 수 있다. 자율 수행 수단 은, 전자 장치 100가 자율적으로 이동하기 위한 모든 수단을 의미할 수 있으며, 도 10은 바퀴 형태의 자율 주행 수단 1010을 도시하나, 이에 한정되지 않으며, 날개 형태 또는 다리 형태의 자율 주행 수단도 포함할 수 있다. 일 실시예에 따라, 자율 주행 수단은, 자율 주행 기술과 결합하여 자율 주행 로봇과 같은 자동화된 시스템을 포 함할 수 있고, 인공 지능(AI) 및 머신 러닝을 활용하여 주행 판단 및 의사 결정을 수행할 수 있으며, 학습 알고 리즘을 통해 주행 시나리오를 개선하고 새로운 상황에 대처할 수 있다. 일 실시예에 따른 전자 장치 100는, 전자 장치 100가 자율 주행 수단 1010을 이용하여 이동하는 동안, 실시간으 로 검출 영역에 관한 정보를 업데이트하고, 실시간으로 타겟 디바이스에 관한 정보를 획득할 수 있다. 예를 들어, 전자 장치 100는 자율 주행 수단 1010을 이용하여 (A)위치에서 (B)위치로, (B)위치에서 (C)위치로 자율적으로 이동할 수 있다. 전자 장치 100는, (A)위치에서 (B)위치로, (B)위치에서 (C)위치로 이동하는 동안, 계속해서 실시간으로 변화하는 검출 영역에 관한 정보를 업데이트할 수 있고, 실시간으로 타겟 디바이스에 관한 정보를 획득할 수 있다. 일 실시예에 따라 전자 장치 100는, 이동하는 동안 실시간으로 업데이트되는 검출 영역에 관한 정보에 기반하여 검출한, 타겟 디바이스가 서버 300와 연동되지 않거나 또는 전자 장치 100와 연동되지 않은 경우, 사용자와의 상호작용없이 자동으로, 타겟 디바이스를 서버 300 또는 전자 장치 100와 연동시킬 수 있다. 일 실시예에 따라 전자 장치 100는, 타겟 디바이스가 자율 주행 수단으로 이동하는 디바이스(ex, 도 10의 102 0)인 경우, 실시간으로 업데이트되는 검출 영역에 관한 정보에 기반하여 해당 타겟 디바이스(ex, 도 10의 102 0)의 위치를 추적(tracking)하고, 실시간으로 획득한 해당 타겟 디바이스(ex, 도 10의 1020)의 현재 동작 상태 정보와 연관된 그래픽 이미지를 결정하고, 해당 타겟 디바이스(ex, 도 10의 1020)의 현재 동작 상태 정보와 연 관된 그래픽 이미지를 해당 타겟 디바이스(ex, 도 10의 1020)의 외부 영역에 투사하도록 투사 모듈을 제어할 수 있다. 일 실시예에 따라 전자 장치 100는, 통신 모듈을 통해 실시간으로 획득한 타겟 디바이스 또는 주변 디바이스들 에 관한 정보에 변화가 발생한 경우(예를 들어, 동작 상태 정보가 완료 상태로 변화한 경우 등), 자율 주행 수 단 1010을 이용하여 사용자의 주변으로 이동해, 변화가 발생한 정보와 연관된 그래픽 이미지를 사용자 주변의 투사면에 투사하도록 투사 모듈을 제어할 수 있다. 일 실시예에 따라 전자 장치 100는, 통신 모듈을 통해 실시간으로 획득한 타겟 디바이스 또는 주변 디바이스들 에 관한 정보에 변화가 발생한 경우(예를 들어, 동작 상태 정보가 완료 상태로 변화한 경우 등), 자율 주행 수 단 1010을 이용하여 상태 변화가 발생한 해당 디바이스의 주변으로 이동해, 변화가 발생한 정보와 연관된 그래 픽 이미지를 해당 디바이스 외부 영역에 투사하도록 투사 모듈을 제어할 수 있다. 본 개시의 일 실시예에 따라 전자 장치 100는 자율 주행 수단을 이용하여 이동하면서 실시간으로 검출 영역에 관한 정보를 업데이트하고, 실시간으로 타겟 디바이스에 관한 정보를 획득함으로써, 공간적 제약없이, 사용자로 하여금 새로운 디스플레이 기능 및 새로운 연결 사용성을 경험하도록 할 수 있다. 도 11은 일 실시예에 따른 전자 장치 100가 그래픽 이미지를 통해 타겟 디바이스 제어와 관련된 동작을 수행하 는 과정의 일 예시를 설명하기 위한 도면이다.도 11을 참조하면, 일 실시예에 따른 전자 장치 100는, 그래픽 이미지 1120 와 연관된 디바이스 1110를 제어하 기 위한 사용자의 입력 1130을 수신할 수 있다. 전자 장치 100는 수신된 사용자의 입력 1130에 따라, 그래픽 이 미지 1120와 연관된 디바이스 11110를 제어하고, 제어 결과를 투사하도록 투사 모듈을 제어할 수 있다. 예를 들어, 사용자가 전자 장치 100에 대응하는 리모트 컨트롤 장치 1100를 사용하여 특정 버튼을 누르는 경우, 전자 장치 100는 공간 감지 센서를 이용하여 타겟 디바이스로 에어컨 1110를 검출하고, 통신 모듈을 통해 에어 컨 1110에 관한 정보로써, 에어컨 1110의 현재 동작 상태 정보(ex. 냉방 모드, 온도 18도, 예약 시간 1시간 등)를 획득할 수 있다. 전자 장치 100는, 획득한 에어컨 1110에 관한 정보에 기반하여 그래픽 이미지 1120를 결 정하고, 그래픽 이미지 1120을 투사하도록 투사 모듈을 제어할 수 있다. 이후, 사용자가 그래픽 이미지 1120에서 표시하는 UI를 이용해서 에어컨 1110을 제어하기 위해, 전자 장치 100 에 대응하는 리모트 컨트롤 장치 1100를 사용하여 방향키를 누르는 경우 1130, 전자 장치 100는 에어컨 111을 제어하기 위한 사용자의 입력 1130을 수신할 수 있다. 예를 들어, 도 11에서 사용자 입력 1130을 리모트 컨트롤 장치 1100 입력으로 도시하지만, 이에 한정되는 것은 아니고, 음성 입력 또는 터치 입력을 포함할 수 있다. 전자 장치 100는 수신된 사용자 입력 1130에 기초하여, 사용자가 리모트 컨트롤 장치 1100를 사용하여 방향키로 지시한 에어컨 1110의 제어 결과를 투사하도록 투사 모듈을 제어할 수 있다. 본 개시의 일 실시예에 따라 전자 장치 100는, 사용자의 입력을 수신하여 투사된 그래픽 이미지를 통해 타겟 디 바이스를 제어하고, 제어 결과를 타겟 디바이스의 주변에 투사함으로써, 사용자로 하여금 새로운 디스플레이 기 능 및 새로운 연결 사용성을 경험하도록 할 수 있다. 도 12는 일 실시예에 따른 전자 장치 100가 그래픽 이미지를 통해 타겟 디바이스 제어와 관련된 동작을 수행하 는 과정의 일 예시를 설명하기 위한 도면이다. 도 12를 참조하면, 일 실시예에 따른 전자 장치 100는, 타겟 디바이스 1210로부터 그래픽 이미지 1220와 연관된 디바이스(도 12에서는, 타겟 디바이스 1210)를 제어한 결과를 지시하는 입력 1240을 수신할 수 있다. 전자 장치 100는, 타겟 디바이스 1210로부터 수신된 입력 1240에 기초하여, 지시된 제어 결과를 투사하도록 투사 모듈을 제어할 수 있다. 예를 들어, 사용자가 TV 1210에 대응하는 리모트 컨트롤 장치 1200를 사용하여 특정 버튼을 누르는 경우, 전자 장치 100는 공간 감지 센서를 이용하여 타겟 디바이스로 TV 1210를 검출하고, 통신 모듈을 통해 TV 1210에 관한 정보로써, TV 1210에서 사용하는 YouTube, Netflix, Disney+ 또는 HDMI에 연결된 OTT, Set-top Box 등의 아이 콘과 해당하는 데이터를 획득할 수 있다. 전자 장치 100는, 획득한 TV 1210에 관한 정보에 기반하여 그래픽 이 미지 1220를 결정하고, 그래픽 이미지 1220을 투사하도록 투사 모듈을 제어할 수 있다. 이후, 사용자가 그래픽 이미지 1220에서 표시하는 UI를 이용해서 TV 1210를 제어하기 위해, TV 1210에 대응하는 리모트 컨트롤 장치 1200를 사용하여 방향키를 누르는 경우 1230, 전자 장치 100는 TV 1210로부터 TV 1210를 제 어한 결과를 지시하는 입력 1240을 수신할 수 있다. 예를 들어, 도 12에서 사용자 입력 1230을 리모트 컨트롤 장치 1200 입력으로 도시하지만, 이에 한정되는 것은 아니고, 음성 입력 또는 터치 입력을 포함할 수 있다. 전자 장치 100는 TV 1210로부터 수신된 입력 1240에 기초하여, 사용자가 리모트 컨트롤 장치 1200를 사용하여 방향키로 지시한 TV 1210의 제어 결과를 투사하도록 투사 모듈을 제어할 수 있다. 본 개시의 일 실시예에 따라 전자 장치 100는, 타겟 디바이스로부터, 투사된 그래픽 이미지를 통해 타겟 디바이 스를 제어하는 결과를 수신하고, 제어 결과를 타겟 디바이스의 주변에 투사함으로써, 사용자로 하여금 새로운 디스플레이 기능 및 새로운 연결 사용성을 경험하도록 할 수 있다. 본 개시에 따른 실시 예를 설명하기 위한 구체적인 예시는 각 기준, 방법, 세부 방법, 동작의 하나의 조합일 뿐 이며, 서술한 다양한 기법들 중 적어도 두 개 이상의 기법들의 조합을 통해 전자 장치 100는 공감 감지 센서, 통신 모듈, 및 투사 모듈을 이용하여 주변 디바이스와 연관된 그래픽 이미지를 제공함으로써 사용자로 하여금 새로운 디스플레이 기능 및 새로운 연결 사용성을 경험하도록 할 수 있다. 또한, 이 때, 전술한 기법들 중 하나 또는 적어도 두 개 이상의 조합을 통해 결정된 방식에 따라 수행될 수 있다. 예를 들어, 일 실시예의 동작의 일 부를 다른 실시예의 동작의 일부와 조합하여 수행하는 것이 가능할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일 시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 본 개시의 일 실시예에 따라 전자 장치는 공감 감지 센서, 통신 모듈, 및 투사 모듈을 이용하여 주변 디바이스 와 연관된 그래픽 이미지를 제공함으로써 사용자로 하여금 새로운 디스플레이 기능 및 새로운 연결 사용성을 경 험하도록 할 수 있다. 다만, 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급 하지 않은 또 다른 효과들은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명 확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0141408", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 전자 장치의 개념을 설명하기 위한 참고도이다. 도 2는 일 실시예에 따른 시스템의 블록도이다. 도 3은 일 실시예에 따른 전자 장치의 블록도이다. 도 4는 일 실시예에 따른 전자 장치의 구체적인 블록도이다. 도 5는 일 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도 이다. 도 6은 일 실시예에 따른 전자 장치가 하나 이상의 공간 감지 센서를 통해 타겟 디바이스를 검출하기 위해 검출 영역에 관한 정보를 획득하는 과정의 일 예시를 설명하기 위한 도면이다. 도 7은 일 실시예에 따른 전자 장치가 검출 영역에 관한 정보에 기반하여 타겟 디바이스를 검출하는 과정의 일 예시를 설명하기 위한 도면이다. 도 8는 일 실시예에 따라 검출 영역에 변화가 있는 경우 전자 장치의 동작 방법의 일 예시를 설명하기 위한 도 면이다. 도 9은 일 실시예에 따른 전자 장치가 타겟 디바이스 외 다른 주변 디바이스에 관한 정보에 기반하여 그래픽 이 미지를 결정하는 과정의 일 예시를 설명하기 위한 도면이다. 도 10은 일 실시예에 따른 전자 장치가 자율 주행 수단을 이용하여 이동하는 경우, 전자 장치의 동작 방법의 일 예시를 설명하기 위한 도면이다. 도 11은 일 실시예에 따른 전자 장치가 그래픽 이미지를 통해 타겟 디바이스 제어와 관련된 동작을 수행하는 과 정의 일 예시를 설명하기 위한 도면이다. 도 12은 일 실시예에 따른 전자 장치가 그래픽 이미지를 통해 타겟 디바이스 제어와 관련된 동작을 수행하는 과 정의 일 예시를 설명하기 위한 도면이다."}
