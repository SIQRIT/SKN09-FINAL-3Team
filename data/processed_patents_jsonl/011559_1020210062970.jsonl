{"patent_id": "10-2021-0062970", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0131124", "출원번호": "10-2021-0062970", "발명의 명칭": "인공 신경망에서 학습을 통한 로드 밸런싱 방법 및 시스템", "출원인": "리벨리온 주식회사", "발명자": "오진욱"}}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "프로세싱 유닛은 인공 신경망의 가중치들에 대해 가지치기(pruning) 마스크들을 적용하는 단계; 상기 프로세싱 유닛은 상기 인공 신경망을 통해 훈련 데이터(training data)로부터 활성화 데이터를 프로파게이팅(propagating)하는 단계; 상기 프로세싱 유닛은 상기 활성화 데이터와 목표 데이터에 기초하여 손실 함수(loss function)의 값을 계산하는 단계; 상기 프로세싱 유닛은 상기 인공 신경망의 가중치들과 관련된 상기 손실 함수(loss function)의 기울기(gradient)와, 상기 가지치기 마스크들의 문턱값들(Threshold)과 관련된 상기 손실 함수의 기울기를 계산하기위해 상기 손실 함수의 값을 백프로파게이팅(backpropagating)하는 단계; 및 상기 프로세싱 유닛은 상기 인공 신경망의 가중치들과 관련된 상기 손실 함수의 기울기와, 상기 가지치기 마스크들의 문턱값들과 관련된 상기 손실 함수의 기울기에 기초하여 상기 인공 신경망의 가중치들과, 상기 가지치기마스크의 문턱값들을 업데이트하는 단계를 포함하는 인공 신경망에서 학습을 통한 로드 밸런싱 방법."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 프로세싱 유닛은 인공 신경망의 가중치들에 대해 가지치기(pruning) 마스크들을 적용하는단계는, 상기 프로세싱 유닛은 상기 가중치들을 가중치 그룹들로 그룹화하는 단계; 상기 프로세싱 유닛은 상기 가중치 그룹들 각각과 상기 가지치기 마스크들의 문턱값들 각각을 비교하는 단계;및상기 프로세싱 유닛은 상기 비교에 따라 상기 가중치 그룹들 중 특정 그룹에 속한 가중치들을 모두 0으로 설정하는 단계를 포함하는 인공 신경망에서 학습을 통한 로드 밸런싱 방법."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 프로세싱 유닛은 상기 가중치 그룹들 각각과 상기 가지치기 마스크들의 문턱값들 각각을비교하는 단계는,상기 프로세싱 유닛은 상기 가중치 그룹들에서 대표 가중치들을 추출하는 단계; 및상기 프로세싱 유닛은 상기 대표 가중치들 각각을 상기 가지치기 마스크들의 문턱값들 각각과 비교하는 단계를포함하는 인공 신경망에서 학습을 통한 로드 밸런싱 방법."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 프로세싱 유닛은 상기 비교에 따라 상기 가중치 그룹들 중 특정 그룹에 속한 가중치들을모두 0으로 설정하는 단계는,상기 대표 가중치들 중 어느 하나가 대응하는 문턱값보다 작을 때, 상기 프로세싱 유닛은 상기 대표 가중치들중 어느 하나에 대응하는 가중치 그룹에 속한 가중치들 모두를 0으로 설정하는 단계; 및상기 대표 가중치들 중 다른 하나가 대응하는 문턱값보다 클 때, 상기 프로세싱 유닛은 상기 대표 가중치들 중다른 하나에 대응하는 가중치 그룹에 속한 가중치들을 모두 유지하는 단계를 포함하는 인공 신경망에서 학습을통한 로드 밸런싱 방법."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 프로세싱 유닛은 상기 손실 함수의 기울기와, 상기 가지치기 마스크들의 문턱값들과 관련공개특허 10-2022-0131124-3-된 상기 손실 함수의 기울기에 기초하여 상기 인공 신경망의 가중치들과, 상기 가지치기 마스크의 문턱값들을업데이트하는 단계는, 상기 프로세싱 유닛은 가속기의 프로세싱 엘리먼트들의 가중치 레지스터들에서 상기 가지치기 마스크들이 적용된 가중치들의 배열을 분석하는 단계; 상기 프로세싱 유닛은 상기 배열의 분석에 따라 임의의 에포크들(epoch) 동안 상기 가중치 레지스터들 중 특정가중치 레지스터에 배열된 가중치들을 업데이트하지 않기 위해 상기 특정 가중치 레지스터에 배열된 가중치들에대응하는 가지치기 마스크의 문턱값들을 유지하는 단계; 및상기 프로세싱 유닛은 상기 특정 가중치 레지스터에 배열된 가중치들을 제외한 나머지 가중치 레지스터들에 배열된 가중치들을 업데이트하기 위해 상기 나머지 가중치 레지스터들에 배열된 가중치들에 대응하는 가지치기 마스크들의 문턱값들을 조정하는 단계를 포함하는 인공 신경망에서 학습을 통한 로드 밸런싱 방법."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 프로세싱 유닛은 가속기의 프로세싱 엘리먼트들의 가중치 레지스터들에서 상기 가지치기마스크들이 적용된 가중치들의 배열을 분석하는 단계는, 상기 프로세싱 유닛은 상기 가중치 레지스터들 각각에서 각 열에 배열된 가중치들이 모두 0인 제로 가중치 그룹들의 개수를 카운팅하는 단계를 포함하는 인공 신경망에서 학습을 통한 로드 밸런싱 방법."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 가중치 레지스터들 중 상기 특정 가중치 레지스터의 상기 제로 가중치 그룹들의 개수가다른 가중치 레지스터의 상기 제로 가중치 그룹들의 개수와 임의의 값의 합보다 클 때, 상기 프로세싱 유닛은상기 특정 가중치 레지스터에 배열된 가중치들에 대응하는 가지치기 마스크의 문턱값들을 유지하는 인공 신경망에서 학습을 통한 로드 밸런싱 방법."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서, 상기 나머지 가중치 레지스터들에 배열된 가중치들에 대응하는 가지치기 마스크들의 문턱값들은, 가지치기를 더 많이 수행하도록 조정되는 인공 신경망에서 학습을 통한 로드 밸런싱 방법."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 가지치기 마스크들 각각은, 희소 행렬(sparse matrix)인 인공 신경망에서 학습을 통한 로드 밸런싱 방법."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 프로세싱 유닛은, CPU(Central Processing Unit), 또는 GPU(Graphic Processing Unit)인 인공 신경망에서 학습을 통한 로드 밸런싱 방법."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "명령들을 저장하는 메모리; 및 상기 명령들을 실행하는 프로세싱 유닛을 포함하며, 상기 명령들은, 인공 신경망의 가중치들에 대해 가지치기 마스크들을 적용하며, 상기 인공 신경망을 통해 훈련 데이터로부터 활성화 데이터를 프로파게이팅(propagating)하며,상기 활성화 데이터와 목표 데이터에 기초하여 손실 함수의 값을 계산하며,상기 인공 신경망의 가중치들과 관련된 상기 손실 함수의 기울기와, 상기 가지치기 마스크들의 문턱값들과 관련공개특허 10-2022-0131124-4-된 상기 손실 함수의 기울기를 계산하기 위해 상기 손실 함수의 값을 백프로파게이팅(backpropagating)하며, 상기 인공 신경망의 가중치들과 관련된 상기 손실 함수의 기울기와, 상기 가지치기 마스크들의 문턱값들과 관련된 상기 손실 함수의 기울기에 기초하여 상기 인공 신경망의 가중치들과, 상기 가지치기 마스크의 문턱값들을업데이트하도록 구현되는 인공 신경망에서 학습을 통한 로드 밸런싱 시스템."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 인공 신경망의 가중치들에 대해 가지치기 마스크들을 적용하는 명령은, 상기 가중치들을 가중치 그룹들로 그룹화하며, 상기 가중치 그룹들 각각과 상기 가지치기 마스크들의 문턱값들 각각을 비교하며, 상기 비교에 따라 상기 가중치 그룹들 중 특정 그룹에 속한 가중치들을 모두 0으로 설정하도록 구현되는 인공신경망에서 학습을 통한 로드 밸런싱 시스템."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 가중치 그룹들 각각과 상기 가지치기 마스크들의 문턱값들 각각을 비교하는 명령은, 상기 가중치 그룹들에서 대표 가중치들을 추출하며, 상기 대표 가중치들 각각을 상기 가지치기 마스크들의 문턱값들 각각과 비교하도록 구현되는 인공 신경망에서학습을 통한 로드 밸런싱 시스템."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 비교에 따라 상기 가중치 그룹들 중 특정 그룹에 속한 가중치들을 모두 0으로 설정하는명령은,상기 대표 가중치들 중 어느 하나가 대응하는 문턱값보다 작을 때, 상기 대표 가중치들 중 어느 하나에 대응하는 가중치 그룹에 속한 가중치들 모두를 0으로 설정하며, 상기 대표 가중치들 중 다른 하나가 대응하는 문턱값보다 클 때, 상기 대표 가중치들 중 다른 하나에 대응하는가중치 그룹에 속한 가중치들을 모두 유지하도록 구현되는 인공 신경망에서 학습을 통한 로드 밸런싱 시스템."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서, 상기 손실 함수의 기울기와, 상기 가지치기 마스크들의 문턱값들과 관련된 상기 손실 함수의기울기에 기초하여 상기 인공 신경망의 가중치들과, 상기 가지치기 마스크의 문턱값들을 업데이트하는 명령은, 가속기의 프로세싱 엘리먼트의 가중치 레지스터에서 상기 가지치기 마스크들이 적용된 가중치들의 배열을 분석하며, 상기 배열의 분석에 따라 임의의 에포크들 동안 상기 가중치 레지스터들 중 특정 가중치 레지스터에 배열된 가중치들을 업데이트하지 않기 위해 상기 특정 가중치 레지스터에 배열된 가중치들에 대응하는 가지치기 마스크의문턱값들을 유지하며, 상기 특정 가중치 레지스터에 배열된 가중치들을 제외한 나머지 가중치 레지스터들에 배열된 가중치들을 업데이트하기 위해 상기 나머지 가중치 레지스터들에 배열된 가중치들에 대응하는 가지치기 마스크들의 문턱값들을 조정하도록 구현되는 인공 신경망에서 학습을 통한 로드 밸런싱 시스템."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 가속기의 프로세싱 엘리먼트들의 가중치 레지스터들에서 상기 가지치기 마스크들이 적용된 가중치들의 배열을 분석하는 명령은, 상기 가중치 레지스터들 각각에서 각 열에 배열된 가중치들이 모두 0인 제로 가중치 그룹들의 개수를 카운팅하도록 구현되는 인공 신경망에서 학습을 통한 로드 밸런싱 시스템."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "공개특허 10-2022-0131124-5-제16항에 있어서, 상기 가중치 레지스터들 상기 특정 가중치 레지스터의 상기 제로 가중치 그룹들의 개수가 다른 가중치 레지스터의 상기 제로 가중치 그룹들의 개수와 임의의 값의 합보다 클 때, 상기 명령들은 상기 특정가중치 레지스터에 배열된 가중치들에 대응하는 가지치기 마스크의 문턱값들을 유지하도록 구현되는 인공 신경망에서 학습을 통한 로드 밸런싱 시스템."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서, 상기 나머지 가중치 레지스터들에 배열된 가중치들에 대응하는 가지치기 마스크들의 문턱값들은, 가지치기를 더 많이 수행하도록 조정되는 인공 신경망에서 학습을 통한 로드 밸런싱 시스템."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서, 상기 가지치기 마스크들 각각은, 희소 행렬(sparse matrix)인 인공 신경망에서 학습을 통한 로드 밸런싱 시스템."}
{"patent_id": "10-2021-0062970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서, 상기 프로세싱 유닛은, CPU(Central Processing Unit), 또는 GPU(Graphic Processing Unit)인 인공 신경망에서 학습을 통한 로드 밸런싱 시스템."}
{"patent_id": "10-2021-0062970", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 신경망에서 학습을 통한 로드 밸런싱 방법이 개시된다. 상기 인공 신경망에서 학습을 통한 로드 밸런싱 방 법은 프로세싱 유닛은 인공 신경망의 가중치들에 대해 가지치기(pruning) 마스크들을 적용하는 단계, 상기 프로 세싱 유닛은 상기 인공 신경망을 통해 훈련 데이터(training data)로부터 활성화 데이터를 프로파게이팅 (뒷면에 계속)"}
{"patent_id": "10-2021-0062970", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공 신경망에서 학습을 통한 로드 밸런싱 방법 및 시스템에 관한 것으로, 상세하게는 가속기에서 연 산 속도 향상과 에너지 소비 감소를 위한 인공 신경망에서 학습을 통한 로드 밸런싱 방법 및 시스템에 관한 것 이다."}
{"patent_id": "10-2021-0062970", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 신경망(artificial neural network)은 컴퓨터 비전(computer vision), 자연어 처리, 및 음성 인식과 같은 다양한 인공 지능 어플리케이션들에서 사용된다. 인공 신경망은 훈련 단계와 추론 단계로 나뉠 수 있다. 훈련 단계에서 훈련 데이터를 이용하여 인공 신경망의 파라미터들이 학습된다. 추론 단계에서 새로운 입력 데이터를 훈련된 인공 신경망에 적용하여 인공 신경망의 예측 결과가 출력된다. 훈련 동작은 CPU, 또는 GPU에서 수행된다. 추론 동작은 인공 지능 어플리케이션들을 가속시키기 위해 특별히 고 안된 하드웨어인 AI 가속기에서 수행된다. 인공 신경망의 파라미터들이 많아질수록 인공 신경망의 정확도는 향상될 수 있다. 하지만, 인공 신경망이 복잡 해짐에 따라 더 많은 에너지 소비와 연산이 요구된다. 이러한 에너지 소비와 연산을 줄이기 위해 가중치 가지치 기(weight pruning) 방법이 소개되어 왔다. 가중치 가지치기란 인공 신경망에서 불필요한 가중치들을 제거하는 것을 의미한다. 가중치들을 0으로 설정함으로써 불필요한 가중치들이 제거될 수 있다. AI 가속기는 복수의 프로세싱 엘리먼트들을 포함한다. AI 가속기의 프로세싱 엘리먼트는 0으로 설정된 가중치들 에 대해서는 연산을 스킵(skip)할 수 있다. 따라서 연산 속도가 향상될 수 있다. 하지만 특정 프로세싱 엘리먼 트에 가중치들이 0인 제로 그룹들이 집중될 때, 프로세싱 엘리먼트의 동작은 비효율적일 수 있다. 왜냐하면 프 로세싱 엘리먼트들은 모든 프로세싱 엘리먼트들의 곱셈 연산이 끝나야 다음 가중치들에 대해 새로운 연산을 수 행하기 때문이다. 예컨대, 임의의 프로세싱 엘리먼트의 곱셈 연산이 먼저 끝났다고 하더라도 상기 프로세싱 엘 리먼트는 다음 곱셈 연산을 먼저 수행할 수 없다. 즉, 상기 프로세싱 엘리먼트는 나머지 프로세싱 엘리먼트의 곱셈 연산이 끝날 때까지 기다려야 한다. 선행기술문헌특허문헌 (특허문헌 0001) 한국 공개특허공보 제10-2020-0093404호(2020.08.05.)"}
{"patent_id": "10-2021-0062970", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적인 과제는 상기와 같은 종래의 문제점을 해결하기 위한 것으로, 인공 신경망의 훈련 단계에서 AI 가속기에서 특정 프로세싱 엘리먼트에 구현된 가중치 레지스터에 0으로 설정된 가중치들이 집 중되는 것을 방지하기 위한 인공 신경망에서 학습을 통한 로드 밸런싱 방법 및 시스템을 제공하는 것이다."}
{"patent_id": "10-2021-0062970", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공 신경망에서 학습을 통한 로드 밸런싱 방법은 프로세싱 유닛은 인공 신경망의 가 중치들에 대해 가지치기(pruning) 마스크들을 적용하는 단계, 상기 프로세싱 유닛은 상기 인공 신경망을 통해 훈련 데이터(training data)로부터 활성화 데이터를 프로파게이팅(propagating)하는 단계, 상기 프로세싱 유닛 은 상기 활성화 데이터와 목표 데이터에 기초하여 손실 함수(loss function)의 값을 계산하는 단계, 상기 프로 세싱 유닛은 상기 인공 신경망의 가중치들과 관련된 상기 손실 함수(loss function)의 기울기(gradient)와, 상 기 가지치기 마스크들의 문턱값들(Threshold)과 관련된 상기 손실 함수의 기울기를 계산하기 위해 상기 손실 함 수의 값을 백프로파게이팅(backpropagating)하는 단계, 및 상기 프로세싱 유닛은 상기 인공 신경망의 가중치들 과 관련된 상기 손실 함수의 기울기와, 상기 가지치기 마스크들의 문턱값들과 관련된 상기 손실 함수의 기울기 에 기초하여 상기 인공 신경망의 가중치들과, 상기 가지치기 마스크의 문턱값들을 업데이트하는 단계를 포함한 다. 상기 프로세싱 유닛은 인공 신경망의 가중치들에 대해 가지치기(pruning) 마스크들을 적용하는 단계는 상기 프 로세싱 유닛은 상기 가중치들을 가중치 그룹들로 그룹화하는 단계, 상기 프로세싱 유닛은 상기 가중치 그룹들 각각과 상기 가지치기 마스크들의 문턱값들 각각을 비교하는 단계, 및 상기 프로세싱 유닛은 상기 비교에 따라 상기 가중치 그룹들 중 특정 그룹에 속한 가중치들을 모두 0으로 설정하는 단계를 포함한다. 상기 프로세싱 유닛은 상기 가중치 그룹들 각각과 상기 가지치기 마스크들의 문턱값들 각각을 비교하는 단계는 상기 프로세싱 유닛은 상기 가중치 그룹들에서 대표 가중치들을 추출하는 단계, 및 상기 프로세싱 유닛은 상기 대표 가중치들 각각을 상기 가지치기 마스크들의 문턱값들 각각과 비교하는 단계를 포함한다. 상기 프로세싱 유닛은 상기 비교에 따라 상기 가중치 그룹들 중 특정 그룹에 속한 가중치들을 모두 0으로 설정 하는 단계는 상기 대표 가중치들 중 어느 하나가 대응하는 문턱값보다 작을 때, 상기 프로세싱 유닛은 상기 대 표 가중치들 중 어느 하나에 대응하는 가중치 그룹에 속한 가중치들 모두를 0으로 설정하는 단계, 및 상기 대표 가중치들 중 다른 하나가 대응하는 문턱값보다 클 때, 상기 프로세싱 유닛은 상기 대표 가중치들 중 다른 하나 에 대응하는 가중치 그룹에 속한 가중치들을 모두 유지하는 단계를 포함한다. 상기 프로세싱 유닛은 상기 손실 함수의 기울기와, 상기 가지치기 마스크들의 문턱값들과 관련된 상기 손실 함 수의 기울기에 기초하여 상기 인공 신경망의 가중치들과, 상기 가지치기 마스크의 문턱값들을 업데이트하는 단 계는 상기 프로세싱 유닛은 가속기의 프로세싱 엘리먼트들의 가중치 레지스터들에서 상기 가지치기 마스크들이 적용된 가중치들의 배열을 분석하는 단계, 상기 프로세싱 유닛은 상기 배열의 분석에 따라 임의의 에포크들 (epoch) 동안 상기 가중치 레지스터들 중 특정 가중치 레지스터에 배열된 가중치들을 업데이트하지 않기 위해 상기 특정 가중치 레지스터에 배열된 가중치들에 대응하는 가지치기 마스크의 문턱값들을 유지하는 단계, 및 상 기 프로세싱 유닛은 상기 특정 가중치 레지스터에 배열된 가중치들을 제외한 나머지 가중치 레지스터들에 배열 된 가중치들을 업데이트하기 위해 상기 나머지 가중치 레지스터들에 배열된 가중치들에 대응하는 가지치기 마스 크들의 문턱값들을 조정하는 단계를 포함한다. 상기 프로세싱 유닛은 가속기의 프로세싱 엘리먼트들의 가중치 레지스터들에서 상기 가지치기 마스크들이 적용 된 가중치들의 배열을 분석하는 단계는 상기 프로세싱 유닛은 상기 가중치 레지스터들 각각에서 각 열에 배열된 가중치들이 모두 0인 제로 가중치 그룹들의 개수를 카운팅하는 단계를 포함한다. 상기 가중치 레지스터들 중 상기 특정 가중치 레지스터의 상기 제로 가중치 그룹들의 개수가 다른 가중치 레지 스터의 상기 제로 가중치 그룹들의 개수와 임의의 값의 합보다 클 때, 상기 프로세싱 유닛은 상기 특정 가중치 레지스터에 배열된 가중치들에 대응하는 가지치기 마스크의 문턱값들을 유지한다. 상기 나머지 가중치 레지스터들에 배열된 가중치들에 대응하는 가지치기 마스크들의 문턱값들은 가지치기를 더 많이 수행하도록 조정된다. 상기 가지치기 마스크들 각각은 희소 행렬(sparse matrix)이다. 상기 프로세싱 유닛은 CPU(Central Processing Unit), 또는 GPU(Graphic Processing Unit)일 수 있다. 본 발명의 실시 예에 따른 인공 신경망에서 학습을 통한 로드 밸런싱 시스템은 명령들을 저장하는 메모리, 및 상기 명령들을 실행하는 프로세싱 유닛을 포함한다. 상기 명령들은 인공 신경망의 가중치들에 대해 가지치기 마스크들을 적용하며, 상기 인공 신경망을 통해 훈련 데이터로부터 활성화 데이터를 프로파게이팅(propagating)하며, 상기 활성화 데이터와 목표 데이터에 기초하여 손실 함수의 값을 계산하며, 상기 인공 신경망의 가중치들과 관련된 상기 손실 함수의 기울기와, 상기 가지치기 마스크들의 문턱값들과 관련된 상기 손실 함수의 기울기를 계산하기 위해 상기 손실 함수의 값을 백프로파게이 팅(backpropagating)하며, 상기 인공 신경망의 가중치들과 관련된 상기 손실 함수의 기울기와, 상기 가지치기 마스크들의 문턱값들과 관련된 상기 손실 함수의 기울기에 기초하여 상기 인공 신경망의 가중치들과, 상기 가지 치기 마스크의 문턱값들을 업데이트하도록 구현된다. 상기 인공 신경망의 가중치들에 대해 가지치기 마스크들을 적용하는 명령은 상기 가중치들을 가중치 그룹들로 그룹화하며, 상기 가중치 그룹들 각각과 상기 가지치기 마스크들의 문턱값들 각각을 비교하며, 상기 비교에 따 라 상기 가중치 그룹들 중 특정 그룹에 속한 가중치들을 모두 0으로 설정하도록 구현된다. 상기 가중치 그룹들 각각과 상기 가지치기 마스크들의 문턱값들 각각을 비교하는 명령은 상기 가중치 그룹들에 서 대표 가중치들을 추출하며, 상기 대표 가중치들 각각을 상기 가지치기 마스크들의 문턱값들 각각과 비교하도 록 구현된다. 상기 손실 함수의 기울기와, 상기 가지치기 마스크들의 문턱값들과 관련된 상기 손실 함수의 기울기에 기초하여 상기 인공 신경망의 가중치들과, 상기 가지치기 마스크의 문턱값들을 업데이트하는 명령은 가속기의 프로세싱 엘리먼트의 가중치 레지스터에서 상기 가지치기 마스크들이 적용된 가중치들의 배열을 분석하며, 상기 배열의 분석에 따라 임의의 에포크들 동안 상기 가중치 레지스터들 중 특정 가중치 레지스터에 배열된 가중치들을 업데 이트하지 않기 위해 상기 특정 가중치 레지스터에 배열된 가중치들에 대응하는 가지치기 마스크의 문턱값들을 유지하며, 상기 특정 가중치 레지스터에 배열된 가중치들을 제외한 나머지 가중치 레지스터들에 배열된 가중치 들을 업데이트하기 위해 상기 나머지 가중치 레지스터들에 배열된 가중치들에 대응하는 가지치기 마스크들의 문 턱값들을 조정하도록 구현된다. 상기 가속기의 프로세싱 엘리먼트들의 가중치 레지스터들에서 상기 가지치기 마스크들이 적용된 가중치들의 배 열을 분석하는 명령은 상기 가중치 레지스터들 각각에서 각 열에 배열된 가중치들이 모두 0인 제로 가중치 그룹 들의 개수를 카운팅하도록 구현된다. 상기 가중치 레지스터들 상기 특정 가중치 레지스터의 상기 제로 가중치 그룹들의 개수가 다른 가중치 레지스터 의 상기 제로 가중치 그룹들의 개수와 임의의 값의 합보다 클 때, 상기 명령들은 상기 특정 가중치 레지스터에 배열된 가중치들에 대응하는 가지치기 마스크의 문턱값들을 유지하도록 구현된다. 상기 나머지 가중치 레지스터들에 배열된 가중치들에 대응하는 가지치기 마스크들의 문턱값들은 가지치기를 더 많이 수행하도록 조정된다. 상기 가지치기 마스크들 각각은 희소 행렬(sparse matrix)이다. 상기 프로세싱 유닛은 CPU(Central Processing Unit), 또는 GPU(Graphic Processing Unit)일 수 있다."}
{"patent_id": "10-2021-0062970", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공 신경망에서 학습을 통한 로드 밸런싱 방법 및 시스템은 가지치기(pruning) 마스 크의 문턱값들을 업데이트함으로써 가속기에서 연산 속도 향상과 에너지 소비 감소가 가능하다는 효과가 있다. 또한, 본 발명의 실시 예에 따른 인공 신경망에서 학습을 통한 로드 밸런싱 방법 및 시스템은 가속기의 프로세 싱 엘리먼트들의 가중치 레지스터들에서 가중치들의 배열을 분석하여 가지치기(pruning)함으로써 가속기에서 연산 속도 향상과 에너지 소비 감소가 가능하다는 효과가 있다."}
{"patent_id": "10-2021-0062970", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 개시되어 있는 본 발명의 개념에 따른 실시 예들에 대해서 특정한 구조적 또는 기능적 설명들은 단 지 본 발명의 개념에 따른 실시 예들을 설명하기 위한 목적으로 예시된 것으로서, 본 발명의 개념에 따른 실시 예들은 다양한 형태들로 실시될 수 있으며 본 명세서에 설명된 실시 예들에 한정되지 않는다. 본 발명의 개념에 따른 실시 예들은 다양한 변경들을 가할 수 있고 여러 가지 형태들을 가질 수 있으므로 실시 예들을 도면에 예시하고 본 명세서에 상세하게 설명하고자 한다. 그러나, 이는 본 발명의 개념에 따른 실시 예 들을 특정한 개시 형태들에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물, 또는 대체물을 포함한다. 제1 또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용어 들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로 만, 예컨대 본 발명의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1구성요소는 제2구성요소로 명명될 수 있고, 유사하게 제2구성요소는 제1구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관 계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 본 명세서에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 설시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 나타낸다. 일반 적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 이하, 첨부한 도면을 참조하여 본 발명의 바람직한 실시 예를 설명함으로써, 본 발명을 상세히 설명한다. 도 1은 본 발명의 실시 예에 따른 인공 신경망에서 학습을 통한 로드 밸런싱 시스템의 블록도를 나타낸다. 도 2 는 도 1에 도시된 프로세싱 유닛의 동작을 설명하기 위한 인공 신경망의 블록도를 나타낸다. 도 1과 도 2를 참고하면, 인공 신경망에서 로드 밸런싱 시스템은 인공 신경망의 훈련 단계에서 AI 가속기의 특정 프로세싱 엘리먼트에서 연산이 집중되는 것을 방지하기 위한 시스템이다. 인공 신경망에서 로드 밸런싱 시스템은 연산 속도 향상과 에너지 소비 감소가 가능한 스마트 폰, 노트북, 태블릿 PC, PC, 또는 서버와 같은 전자 장치이다. 시스템은 CPU(Central Processing Unit; 10), GPU(Graphics Processing Unit; 20), 메모리, 및 가속기를 포함한다. 도 1에 도시된 시스템은 본 발명을 설명 하기 위한 일 실시 예를 나타낸다. 실시 예에 따라 시스템은 다양하게 구현될 수 있다. 예컨대, 시스템 은 입력 장치(미도시), 또는 송수신기(transceiver; 미도시)를 더 포함할 수 있다. CPU, GPU, 메 모리, 및 가속기는 버스에 접속된다. CPU, GPU, 메모리, 및 가속기는 버스 를 통해 명령들과 데이터를 주고 받는다. CPU는 인공 신경망의 가중치들(weights)과 편향 벡터들(bias vectors)인 파라미터들을 훈련시키기 위 한 명령들을 실행한다. 실시 예에 따라 인공 신경망의 훈련은 GPU에서 수행될 수 있다. 메모리는 CPU, 또는 GPU에서 실행되는 명령들을 저장한다. 본 발명에서 프로세싱 유닛은 CPU, 또는 GPU를 의미한다. 가속기는 인공 신경망의 훈련이 끝난 뒤인 인공 신경망의 추론이 수행된다. 실시 예에 따라 가 속기는 AI 가속기로 호칭될 수 있다. 또한, 실시 예에 따라 가속기는 가속 하드웨어로 호칭될 수 있 다. 도 2를 참고하면, 인공 신경망은 입력 레이어(input layer; 105), 은닉 레이어(hidden layer; 107), 및 출력 레이어(output layer; 109)를 포함한다. 입력 레이어는 각 값(each value)을 수신한다. 입력 레이어는 각 값을 복제(duplicate)하고, 복제된 각 값을 은닉층으로 전송한다. 상기 각 값은 입력 활성화(input activations)라고 호칭될 수 있다. 메모리 는 각 값을 저장한다. 은닉 레이어는 각 값과 가중치들을 곱하고, 가중치 합(weighted sum)을 출력한다. 상기 가중치 합은 출력 활성화(output activations)라고 호칭될 수 있다. 메모리는 가중치들과 가중치 합을 저장한다. 실시 예에 따라 은닉 레이어는 가중치 합을 활성화 함수에 적용할 수 있다. 인공 신경망의 훈련 단계 에서 각 값과 가중치들의 곱은 CPU, 또는 GPU에서 수행된다. 인경 신경망의 추론 단계에서 각 값 과 가중치들의 곱은 가속기에서 수행된다. 출력 레이어는 은닉 레이어로부터 수신된 가중치 합을 활성화 함수(activation function)에 적용하여 출력 값을 생성한다. 입력 레이어, 은닉 레이어, 및 출력 레이어 각각은 노드들을 포함한다. 실시 예에 따라 입력 레 이어, 은닉 레이어, 및 출력 레이어의 노드들의 수와, 은닉 레이어의 레이어 수는 다양할 수 있다. 입력 레이어, 은닉 레이어, 및 출력 레이어의 노드들의 수와, 은닉 레이어의 레 이어 수의 증가함에 따라 인공 신경망의 사이즈는 증가한다. 인공 신경망의 사이즈의 증가는 에너지 소비 증가와 병목 현상을 유발한다. 따라서 인공 신경망의 훈련 단계에서 에너지 효율성과 연산 속도 증가 를 위해 인공 신경망를 감소시킬 필요가 있다. 또한, 인공 신경망의 각 값과 가중치들의 수가 증가함 에 따라 메모리에서 필요한 저장 공간은 증가한다. 따라서 인공 신경망의 훈련 단계에서 메모리의 저장 공간의 절약이 필요하다. CPU, 또는 GPU와 같은 프로세싱 유닛은 인공 신경망의 가중치들에 대해 가지치기(prunining) 마스 크들을 적용한다. 가지치기 마스크들 각각은 희소 행렬(sparse matrix)이다. 희소 행렬은 많은 0의 값들을 포함 하는 행렬이다. 가지치기 마스크들을 적용하는 것은 가중치 행렬과 희소 행렬의 곱셈을 의미한다. 인공 신경망 의 가중치들에 대해 가지치기 마스크들을 적용하는 구체적인 동작은 다음과 같다. 상기 프로세싱 유닛은 상기 가중치들을 가중치 그룹들로 그룹화한다. 구체적으로, 상기 프로세싱 유닛은 상기 가중치들을 채널들, 또는 필터들을 고려하여 가중치 그룹들로 나눌 수 있다. 예컨대, 상기 프로세싱 유닛은 상 기 가중치들을 입력 채널에 배열된 가중치들, 또는 출력 채널에 배열된 가중치들을 고려하여 가중치 그룹들로 나눌 수 있다. 또한, 상기 프로세싱 유닛은 SIMD(Single Instruction Multiple Data) 폭에 따라 가중치들을 가중치 그룹들로 그룹화할 수 있다. 예컨대, SIMD 폭이 2일 때, 상기 프로세싱 유닛은 2개의 가중치들이 하나의 가중치 그룹을 형성하도록 가중치들을 가중치 그룹들로 나눌 수 있다. SIMD 폭이 4일 때, 상기 프로세싱 유닛은 4개의 가중치 들이 하나의 가중치 그룹을 형성하도록 가중치들을 가중치 그룹들로 나눌 수 있다. SIMD 폭이 8일 때, 상기 프로세싱 유닛은 8개의 가중치들이 하나의 가중치 그룹을 형성하도록 가중치들을 가중치 그룹들로 나눌 수 있다. 상기 프로세싱 유닛은 상기 가중치 그룹들 각각과 상기 가지치기 마스크들의 문턱값들 각각을 비교한다. 상기 가지치기 마스크들은 대응하는 문턱값들을 포함한다. 구체적으로, 상기 프로세싱 유닛은 상기 가중치 그룹들에 서 대표 가중치들을 추출한다. 상기 대표 가중치들은 상기 가중치 그룹들에서 임의로 추출될 수 있다. 예컨대, 가중치 그룹들 중 어느 하나의 가중치 그룹이 8개의 가중치들(W1~W8)을 포함할 때, 임의로 제1가중치(W1)가 대 표 가중치로서 추출될 수 있다. 또한, 실시 예에 따라 가중치 그룹이 8개의 가중치들(W1~W8)을 포함할 때, 8개 의 가중치들의 RMS(Root Means Square)를 계산하고, RMS 값이 대표 가중치로서 추출될 수 있다. 또한, 실시 예 에 따라 가중치 그룹이 8개의 가중치들(W1~W8)을 포함할 때, 8개의 가중치들 중 최소 값, 또는 최대 값이 대표 가중치로서 추출될 수 있다. 상기 프로세싱 유닛은 가중치 그룹들 각각에서 추출된 대표 가중치들 각각을 상기 가지치기 마스크들의 문턱값 들 각각과 비교한다. 상기 문턱값들 각각은 임의로 설정될 수 있다. 또한, 상기 문턱값들은 서로 다르게 설정될 수 있다. 상기 대표 가중치들 중 어느 하나가 대응하는 문턱값보다 작을 때, 상기 프로세싱 유닛은 상기 대표 가중치들 중 어느 하나에 대응하는 가중치 그룹에 속한 가중치들 모두를 0으로 설정한다. 예컨대, 하나의 가중치 그룹인 8개의 가중치들(W1~W8) 중 대표 가중치가 대응하는 문턱값보다 작을 때, 상기 프로세싱 유닛은 상기 대표 가중 치에 대응하는 가중치 그룹에 속한 가중치들(W1~W8)을 모두 0으로 설정한다. 상기 0으로 설정은 가중치 행렬과 희소 행렬의 곱으로 설정될 수 있다. 반대로, 상기 대표 가중치들 중 다른 하나가 대응하는 문턱값보다 클 때, 상기 프로세싱 유닛은 상기 대표 가중 치들 중 다른 하나에 대응하는 가중치 그룹에 속한 가중치들을 모두 유지한다. 유지한다함은 상기 가중치 그룹 에 속한 가중치들(W1~W8)을 모두 변경하지 않는다 것을 의미한다. 즉, 가중치 행렬과 희소 행렬의 곱셈 동작은 수행되지 않는다. 인공 신경망의 가중치들에 대해 가지치기 마스크들을 적용한 후, 상기 프로세싱 유닛은 인공 신경망 을 통해 훈련 데이터로부터 활성화 데이터를 프로파게팅(propagating)한다. 즉, 상기 프로세싱 유닛은 인공 신 경망의 입력 레이어에 훈련 데이터를 입력하고, 은닉 레이어와 출력 레이어를 통해 활성화 데이터를 출력한다. 상기 프로세싱 유닛은 상기 활성화 데이터와 목표 데이터에 기초하여 손실 함수(loss function)의 값을 계산한 다. 상기 손실 함수의 값은 상기 활성화 데이터와 목표 데이터 사이의 MSE(Means Squared Error), 또는 크로스- 엔트로피(cross-entropy)를 이용하여 계산될 수 있다. 상기 프로세싱 유닛은 인공 신경망의 가중치들과 관련된 손실 함수의 기울기와, 상기 가지치기 마스크들의 문턱값들과 관련된 상기 손실 함수의 기울기를 계산하기 위해 상기 손실 함수의 값을 백프로파게이팅 (backpropagating)한다. 백프로파게이션 동작은 인공 신경망의 가중치들과 관련된 상기 손실 함수(loss function)의 기울기(gradient)와, 문턱값들(Threshold)과 관련된 상기 손실 함수의 기울기를 계산하는 동작을 포함한다. 상기 백프로파게이션은 상기 가중치들과 문턱값들을 조절하여 상기 손실 함수의 값을 최소화를 목표 로 한다. 인공 신경망의 가중치들에 따라 손실 함수의 값이 변한다. 따라서 상기 프로세싱 유닛은 가중치들에 따른 손실 함수의 변화 값을 이용하여 가중치들과 관련된 손실 함수의 기울기를 계산한다. 가지치기 마스크들의 문턱값들에 따라 손실 함수의 값도 변한다. 상기 문턱값들에 따라 가중치들이 0으로 설정 될 수 있기 때문이다. 따라서 상기 프로세싱 유닛은 가지치기 마스크들의 문턱값들에 따른 손실 함수의 변화 값 을 이용하여 상기 가지치기 마스크들의 문턱값들과 관련된 손실 함수의 기울기를 계산한다. 상기 프로세싱 유닛은 인공 신경망의 오버피팅(overfitting)을 피하기 위해 인공 신경망에 대해 구조 화된 희소 정규화(structured sparisty regularization)를 수행한다. 구조화된 희소 정규화란 가중치 그룹들을 고려하여 정규화 동작을 수행함을 의미한다. 상기 프로세싱 유닛은 인공 신경망의 가중치들과 관련된 상기 손실 함수의 기울기와, 상기 가지치기 마스 크들의 문턱값들과 관련된 상기 손실 함수의 기울기에 기초하여 인공 신경망의 가중치들과, 상기 가지치기 마스크의 문턱값들을 업데이트한다. 상기 문턱값들의 업데이트에 따라 특정 가중치 그룹들이 모두 0으로 재설정 되거나, 0으로의 설정이 취소될 수 있다. 상기 문턱값들의 업데이트 동작은 구조화된 회소 정규화를 수행하는과정에서 수행된다. 상기 구조화된 희소 정규화의 최적화 목표(optimization target)는 다음의 수학식과 같이 표현될 수 있다. [수학식 1]"}
{"patent_id": "10-2021-0062970", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상기 는 최적화 목표를, 상기 는 문턱값을, 상기 는 가중치들을, 상기 는 분류 손 실(classification loss)을, 상기 는 어느 하나의 그룹에 속한 가중치들을 얼마나 패널티를 주기 위해 (penalize) 결정하는 페널티 텀(penalty term), 혹은 정규화 파라미터(regularization parameter)를, 상기 는 구조화된 희소 정규화 텀(structured sparisty regularization term을 의미한다. 상기 N 은 콘볼루션 층들(convolution layers)의 수를 의미하며, 상기 n은 가중치 텐서의 순서를 의미한다. 구체적으로 는 L1 규범(norm) 또는 L2 규범(norm)일 수 있다. 상기 분류 손실( )은 최종 손실(overall loss)을 최소화하기 위해 업데이트된다. 상기 구조화된 희 소 정규화 텀( )은 손실을 최소화하는 방향으로 학습된다. 상기 문턱값( )은 희소화 (sparsity)를 증가시키는 방향으로 업데이트된다. 도 3은 도 1에 도시된 가속기의 블록도를 나타낸다. 도 1과 도 3을 참고하면, 가속기는 컨트롤러, 입력 활성화 버퍼, 가중치 버퍼, 출력 버퍼 , 제1레지스터, 제2레지스터, 복수의 프로세싱 엘리먼트들(processing elements; 270), 및 누 산기(accumulator; 280)를 포함한다. 컨트롤러는 CPU, 또는 GPU로부터 가속기의 동작을 실행시키기 위한 명령들을 수신한다. 예컨 대, 상기 명령들은 로드(load) 명령, 곱셈 명령, 합산 명령, 및 저장 명령을 포함할 수 있다. 컨트롤러가 상기 로드 명령을 수신할 때, 컨트롤러는 제1레지스터에 저장된 입력 활성화들, 또는 제2레지스터 에 저장된 가중치들을 복수의 프로세싱 엘리먼트들에 로드(load)하기 위해 제1레지스터, 또는 제2레지스터를 제어한다. 컨트롤러는 CPU, 또는 GPU로부터 수신된 명령들에 따라 가속기 의 각 구성요소들(220, 230, 240, 250, 260, 270, 및 280)의 동작들을 제어한다. 입력 활성화 버퍼는 메모리로부터 입력 활성화들을 수신하여 저장한다. 가중치 버퍼는 메모리 로부터 가중치들을 수신하여 저장한다. 출력 버퍼는 누산기로부터 출력되는 결과 값을 저장하고, 결과 값을 CPU, GPU, 또는 메모리 로 전송한다. 제1레지스터는 입력 활성화 버퍼로부터 입력 활성화들을 수신하고 저장한다. 제2레지스터는 가 중치 버퍼로부터 가중치들을 수신하고 저장한다. 제1레지스터와 제2레지스터는 FIFO(First In First Out) 레지스터일 수 있다. 복수의 프로세싱 엘리먼트들 각각은 제1레지스터로부터 수신된 입력 활성화들과 제2레지스터로 부터 수신된 가중치들을 곱하는 곱셈 연산을 수행하고, 부분 합(partial sum)을 생성한다. 복수의 프로세싱 엘 리먼트들은 프로세싱 엘리먼트 어레이로 호칭될 수 있다. 누산기는 복수의 프로세싱 엘리먼트들로부터 출력되는 부분 합들을 저장하고, 부분 합들을 더하여 곱 셈 가중치 합(weighted sum)을 업데이트한다. 실시 예에 따라 가속기의 구조는 다양하게 구현될 수 있다. 도 4는 도 3에 도시된 프로세싱 엘리먼트(processing element)의 내부 블록도를 나타낸다. 도 1 내지 도 4를 참고하면, 복수의 프로세싱 엘리먼트들은 모두 같은 구조를 가진다. 도 4에 대표적으로 복수의 프로세싱 엘리먼트들 중 어느 하나의 프로세싱 엘리먼트가 도시된다. 프로세싱 엘리먼트는 가중치 레지스터, 입력 활성화 레지스터, 복수의 곱셈기들, 및 가산 기를 포함한다. 가중치 레지스터는 제2레지스터로부터 가중치들(예컨대, W11~W44)을 전송받는다. 가중치 레지스터 는 가중치들을 저장하기 위한 행렬(MX)로 구현된다. 도 4에서 4개의 가중치들(W11~W14, W21~W24, W31~W34, 또 는 W41~W44)이 하나의 가중치 그룹(G1, G2, G3, 또는 G4)을 형성한다. 각 가중치 그룹들(G1~G4)은 행렬(MX)에서 각 행에 배열된다. 프로세싱 유닛은 가중치 그룹들(G1~G4)에서 대표 가중치들을 추출한다. 상기 프로세싱 유닛은 대표 가중치들 각 각을 가지치기 마스크들의 문턱값들 각각과 비교한다. 상기 프로세싱 유닛은 상기 비교에 따라 가중치 그룹들 (G1~G4) 중 특정 그룹(예컨대, G2, 또는 G3)에 속한 가중치들(W21~W24, 또는 W31~W34)을 모두 0으로 설정할 수 있 다. 입력 활성화 레지스터는 제1레지스터로부터 입력 활성화들(예컨대, a11~a41)을 전송받는다. 입력 활성 화들(a11~a41)은 행렬로 구현된다. 복수의 곱셈기들 각각은 가중치 레지스터로부터 출력되는 가중치들과 입력 활성화 레지스터로부 터 출력되는 입력 활성화들을 곱한다. 예컨대, 첫 번째 사이클에서 곱셈기는 가중치 레지스터에서 제 1가중치 그룹(G1)에 포함된 가중치들(W11~W14)과 입력 활성화 레지스터에서 제1열(CL1)에 포함된 입력 활성 화들(a11~a14)을 곱한다. 곱셈기는 가중치(W11)와 입력 활성화(a11)를 곱한다. 곱셈기는 가중치(W12)와 입력 활성화(a12)를 곱한다. 가산기는 부분 합(partial sum)을 생성한다. 두 번째 사이클에서 곱셈기는 가중치 레지스터에서 제2가중치 그룹(G2)에 포함된 가중치들(W21~W24)과 입력 활성화 레지스터에서 제2열(CL2)에 포함된 입력 활성화들(a21~a24)을 곱한다. 가산기는 부분 합 을 생성한다. 세 번째 사이클에서 곱셈기는 가중치 레지스터에서 제3가중치 그룹(G3)에 포함된 가중치들(W31~W34)과 입력 활성화 레지스터에서 제3열(CL3)에 포함된 입력 활성화들(a31~a34)을 곱한다. 가산기는 부분 합 을 생성한다. 네 번째 사이클에서 곱셈기는 가중치 레지스터에서 제4가중치 그룹(G4)에 포함된 가중치들(W41~W44)과 입력 활성화 레지스터에서 제4열(CL4)에 포함된 입력 활성화들(a41~a44)을 곱한다. 가산기는 부분 합 을 생성한다. 만약, 가중치 레지스터에서 가중치 그룹들(G1~G4) 중 특정 가중치 그룹(G2, 또는 G3)이 0으로 설정된 제로 그룹이라 가정할 때, 가중치들(W21~W24)과 입력 활성화들(a21~a24)의 곱의 연산, 또는 가중치들(W31~W34)과 입력 활 성화들(a31~a34)의 곱의 연산은 스킵(skip)될 수 있다. 이는 가속기의 연산 속도 향상으로 이어진다. 도 5는 도 3에 도시된 복수의 프로세싱 엘리먼트들의 내부 블록도를 나타낸다. 도 5에서는 설명의 편의를 위해 프로세싱 엘리먼트들 중 일부 프로세싱 엘리먼트들만이 도시된다. 또한, 도 5에서는 설명의 편의를 위해 프로세 싱 엘리먼트에서 가중치 레지스터만이 도시된다. 도 5(a)는 로드 밸런싱 동작이 적용되기 전의 복수의 프로세싱 엘리먼트들의 내부 블록도를 나타낸다. 도 5(b)는 로드 밸런싱 동작 적용 후의 복수의 프로세싱 엘리먼트들의 내부 블록도를 나타낸다. 도 1 내지 도 5(a)를 참고하면, 프로세싱 엘리먼트들(270-1~270-3)은 가중치 레지스터들(271-1~271-3)을 포함한 다. 가중치 레지스터들(271-1~271-3)에서 해시(hash) 블록은 제로(zero) 그룹을 의미한다. 즉, 제로 그룹에 포 함된 가중치들은 모두 0이다. 가중치 레지스터들(271-1~271-3)에서 빈(blank) 블록은 제로가 아닌 그룹을 의미 한다. 실시 예에 따라 하나의 그룹을 형성하는 가중치들의 수는 다양할 수 있다. 예컨대, 4개의 가중치들이 하나의 가중치 그룹을 형성할 수 있다. 컨트롤러의 제어 하에 프로세싱 엘리먼트들은 곱셈 명령을 수행한다. 제1프로세싱 엘리먼트(270-1)는 상기 곱셈 명령에 따라 제1가중치 그룹(G1)에 속한 가중치들과 입력 활성화들을 곱한다. 다만, 제1가중치 그룹 (G1)은 제로 그룹이므로, 제1가중치 그룹(G1)에 속한 가중치들과 입력 활성화들을 곱하는 곱셈 동작은 스킵된다. 동시에 제2프로세싱 엘리먼트(270-2)는 상기 곱셈 명령에 따라 제1가중치 그룹(G1)에 속한 가중치들 과 입력 활성화들을 곱한다. 그리고, 제2프로세싱 엘리먼트(270-2)는 부분 합을 생성한다. 또한, 제3프로세싱 엘리먼트(270-3)도 상기 곱셈 명령에 따라 제1가중치 그룹(G1)에 속한 가중치들과 입력 활성화들을 곱한다. 그 리고, 제3프로세싱 엘리먼트(270-3)는 부분 합을 생성한다. 제1가중치 그룹(G1)에 대한 곱셈 동작이 끝난 후, 프로세싱 엘리먼트들(270-1~270-3)은 나머지 가중치 그룹들 (G2~G8)에 대해서도 순차적으로 곱셈 명령을 수행한다. 제1프로세싱 엘리먼트(270-1)의 가중치 레지스터(271-1)에서 제1가중치 그룹(G1), 제3가중치 그룹(G3), 제5가중 치 그룹(G5), 및 제6가중치 그룹(G6)이 제로 그룹들이라 가정한다. 가중치 레지스터(271-1)에서 제로 그룹들이 많을수록 가속기의 연산 속도가 향상될 수 있다. 왜냐하면 제로 그룹에서 가중치들과 입력 활성화들의 곱 의 연산이 스킵될 수 있기 때문이다. 제2프로세싱 엘리먼트(270-2)의 가중치 레지스터(271-2)에서 제3가중치 그룹(G3)과 제5가중치 그룹(G5)이 제로 그룹들이라 가정한다. 제3프로세싱 엘리먼트(270-3)의 가중치 레지스터(271-3)에서 제6가중치 그룹(G6)이 제로 그룹이라 가정한다. 제1프로세싱 엘리먼트(270-1)는 다른 프로세싱 엘리먼트들(270-2과 270-3)보다 더 많은 제로 그룹들을 포함하고 있다. 따라서 제1프로세싱 엘리먼트(270-1)는 다른 프로세싱 엘리먼트들(270-2과 270-3)보다 더 빨리 곱셈 명령 들을 수행할 수 있다. 제3프로세싱 엘리먼트(270-3)는 가장 적은 제로 그룹을 포함하고 있어서 프로세싱 엘리먼 트들(270-1~270-3) 중 연산 속도가 가장 느리다. 하지만, 제1프로세싱 엘리먼트(270-1)는 제3프로세싱 엘리먼트 (270-3)의 곱셈들이 완전히 끝나기 전까지 대기하여야한다. 즉, 가속기의 연산 속도는 가장 적은 제로 그 룹을 포함하는 프로세싱 엘리먼트(270-3)에 따라 결정된다. 따라서 이러한 레이턴스(latency)를 감소시키기 위 해 로드 밸런싱(load balancing)이 요구된다. 추론 단계에서 가속기의 연산 속도 향상을 위해 훈련 단계에서 로드 밸런싱이 수행된다. 도 1 내지 도 5(b)를 참고하면, 상기 프로세싱 유닛은 가속기의 프로세싱 엘리먼트들(270-1, 270-2, 및 270-3)의 가중치 레지스터들(271-1, 271-2, 및 271-3) 각각에서 상기 가지치기 마스크들이 적용된 가중치들의 배열을 분석한다. 즉, 상기 프로세싱 유닛은 가중치 레지스터들(271-1, 271-2, 및 271-3) 각각에서 각 열에 배 열된 가중치들이 모두 0인 제로 가중치 그룹들의 개수를 카운팅한다. 상기 제로 가중치 그룹들은 제로 그룹들을 의미한다. 예컨대, 상기 프로세싱 유닛은 제1프로세싱 엘리먼트(270-1)의 가중치 레지스터(271-1)에서 제로 가중치 그룹들 (G1, G3, G5, 및 G6)의 개수(4개)를 카운팅한다. 상기 프로세싱 유닛은 제2프로세싱 엘리먼트(270-2)의 가중치 레지스터(271-2)에서 제로 가중치 그룹들(G3과 G5)의 개수(2개)를 카운팅한다. 상기 프로세싱 유닛은 제3프로세 싱 엘리먼트(270-3)의 가중치 레지스터(271-3)에서 제로 가중치 그룹(G6)의 개수(1개)를 카운팅한다. 상기 프로세싱 유닛은 상기 배열의 분석에 따라 임의의 에포크들(epoch) 동안 가중치 레지스터들(271-1, 271-2, 및 271-1) 중 특정 가중치 레지스터(예컨대, 271-1)에 배열된 가중치들을 업데이트하지 않기 위해 상기 특정 가 중치 레지스터(예컨대, 271-1)에 배열된 가중치들에 대응하는 가지치기 마스크의 문턱값들을 유지한다. 하나의 에포크는 인공 신경망을 통해 한 번의 데이터가 프로파게이팅되고, 백프로파게이팅되는 것을 의미한다. 상기 프로세싱 유닛은 프로세싱 엘리먼트들(270-1, 270-2, 및 270-3)의 가중치 레지스터들(271-1, 271-2, 및 271-3) 중 제로 가중치 그룹들의 개수가 가장 많은 프로세싱 엘리먼트(예컨대, 270-1)의 가중치 레지스터(예컨 대, 271-1)를 판단한다. 상기 배열의 분석 결과, 상기 프로세싱 유닛은 제1프로세싱 엘리먼트(270-1)의 가중치 레지스터(271-1)에서 제로 가중치 그룹들이 가장 많다고 판단한다. 따라서 상기 프로세싱 유닛은 제1프로세싱 엘리먼트(270-1)의 가중치 레지스터(271-1)에 배열된 가중치들을 업데이트하지 않기 위해 임의의 에포크들 동안 제1가중치 레지스터(271-1)에 배열된 가중치들에 대응하는 가지치기 마스크의 문턱값들을 유지한다. 그러므로 임의의 에포크들 동안 제1가중치 레지스터(271-1)에서 제1가중치 그룹(G1), 제3가중치 그룹(G3), 제5가중치 그 룹(G5), 및 제6가중치 그룹(G6)은 제로 그룹을 유지하고, 제1가중치 레지스터(271-1)에서 나머지 가중치 그룹들(G2, G4, G7, 및 G8)은 논 제로 그룹(non-zero) 그룹을 유지한다. 실시 예에 따라 프로세싱 엘리먼트들(270-1, 270-2, 및 270-3)의 가중치 레지스터들(271-1, 271-2, 및 271-3) 중 특정 가중치 레지스터의 제로 가중치 그룹들의 개수가 다른 가중치 레지스터의 제로 가중치 그룹들의 개수와 임의의 값의 합보다 큰 지를 판단한다. 프로세싱 엘리먼트들(270-1, 270-2, 및 270-3)의 가중치 레지스터들 (271-1, 271-2, 및 271-3) 중 특정 가중치 레지스터(예컨대, 271-1)의 가중치 그룹들의 개수(예컨대, 4개)가 다 른 프로세싱 엘리먼트(예컨대, 270-3)의 가중치 레지스터(271-3)의 제로 가중치 그룹들의 개수(예컨대, 1개)와 임의의 값(예컨대, 1)의 합보다 큰 때, 상기 프로세싱 유닛은 임의의 에포크들 동안 상기 특정 가중치 레지스터 (예컨대, 271-1)에 배열된 가중치들에 대응하는 가지치기 마스크들의 문턱값들을 유지한다. 제1가중치 레지스터(271-1)에 배열된 가중치들을 업데이트하지 않는 동안, 상기 프로세싱 유닛은 나머지 가중치 레지스터들(271-2과 271-3)에 배열된 가중치들에 대해 더 많이 가지치기를 수행하도록 상기 나머지 가중치 레지 스터들(271-2과 271-3)에 배열된 가중치들에 대응하는 가지치기 마스크들의 문턱값들을 조정한다. 구체적으로 상기 프로세싱 유닛은 상기 나머지 가중치 레지스터들(271-2과 271-3)에 배열된 가중치들에 대응하는 가지치기 마스크들의 문턱값들을 작게 재설정하여 더 많은 제로 그룹들이 생성되도록 한다. 가중치 레지스터들(271-1, 271-2, 및 271-3)에서 상기 가지치기 마스크들이 적용된 가중치들의 배열을 분석하여 선택적으로 가중치들을 업데이트하는 동작은 다음의 수학식과 같이 표현될 수 있다. [수학식 2]"}
{"patent_id": "10-2021-0062970", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기 는 최적화 목표를, 상기 는 문턱값을, 상기 는 가중치들을, 상기 는 분류 손 실(classification loss)을, 상기 는 어느 하나의 그룹에 속한 가중치들을 얼마나 패널티를 주기 위해 (penalize) 결정하는 페널티 텀(penalty term), 혹은 정규화 파라미터(regularization parameter)를, 상기 는 구조화된 희소 정규화 텀(structured sparisty regularization term을 의미한다. 상기 N 은 콘볼루션 층들(convolution layers)의 수를 의미하며, 상기 n은 가중치 텐서의 순서를 의미한다. 구체적으로 는 L1 규범(norm) 또는 L2 규범(norm)일 수 있다. 상기 는 어느 하나의 가중치 레지스 터(271-1, 271-2, 또는 271-3)의 열(column)에 속한 가중치들을 얼마나 패널티를 주기 위해 결정하는 패널티 텀, 혹은 정규화 파라미터를, 상기 는 어느 하나의 가중치 레지스터(271-1, 271-2, 또는 27-3)의 열(column)에 속한 가중치들의 정규화 텀(term)을 의미한다. 상기 C은 가중치 레지스터(271-1, 271-2, 또는 271-3)의 열들(columns)의 수를, 상기 c는 열의 순서를 의미한다. 는 L1 규범(norm) 또는 L2 규범(norm)일 수 있다. 상기 분류 손실( )은 최종 손실(overall loss)을 최소화하기 위해 업데이트된다. 상기 구조화된 희 소 정규화 텀( )은 손실을 최소화하는 방향으로 학습된다. 상기 문턱값( )은 희소화 (sparsity)를 증가시키는 방향으로 업데이트된다. 상기 정규화 텀( )은 손실을 최소화하는 방향으로 학습된다. 상기 문턱값( )은 가중치 레지스터(271-1, 271-2, 또는 271-3)의 열(column)당 제로 그룹(zeo-group)의 개수 차이를 최소화하는 방향으로 업데이트된다.도 5(b)는 로드 밸런싱 동작 적용 후의 복수의 프로세싱 엘리먼트들의 내부 블록도를 나타낸다. 도 5(b)를 참고하면, 제1가중치 레지스터(271-1)에 배열된 가중치들은 업데이트되지 않는다. 제1가중치 레지스 터(271-1)의 제로 그룹들과 넌 제로(non-zero) 그룹들은 변하지 않는다. 하지만, 제2가중치 레지스터(271-2)와 제3가중치 레지스터(271-3)에 배열된 가중치들은 변한다. 가중치 레지스 터들(271-2과 271-3)에 배열된 가중치들에 대응하는 가지치기 마스크들의 문턱값들이 조정되고, 제2가중치 레지 스터(271-2)와 제3가중치 레지스터(271-3)에 포함된 가중치 그룹들이 변한다. 제2가중치 레지스터(271-2)의 제7 가중치 그룹(G7)과 제8가중치 그룹(G8)이 넌 제로 그룹들에서 제로 그룹들로 변한다. 제3가중치 레지스터(271- 3)의 제2가중치 그룹(G2), 제3가중치 그룹(G3), 및 제8가중치 그룹(G8)이 넌 제로 그룹들에서 제로 그룹들로 변 한다. 로드 밸런싱 후에 가중치 레지스터들(271-1, 271-2, 및 271-3)은 모두 동일한 개수의 제로 그룹들을 포함하게 된다. 따라서 가속기의 레이턴스가 감소될 수 있다. 실시 예에 따라 가중치 레지스터들(271-1, 271-2, 및 271-3)에 포함된 제로 그룹들의 수는 같지 않을 수 있다. 예컨대, 제1가중치 레지스터들(271-1)의 제로 그룹들의 수가 4개라 할 때, 제2가중치 레지스터들(271-2)과 제3 가중치 레지스터들(271-3)의 제로 그룹들의 수는 5개일 수 있다. 가중치 레지스터들(271-1, 271-2, 및 271-3)에 포함된 제로 그룹들의 수는 같지 않은 경우라도 가속기의 레이턴스는 처음보다 감소될 수 있다. 도 6은 도 1에 도시된 시스템의 동작 방법을 설명하기 위한 흐름도를 나타낸다. 도 1 내지 도 6을 참고하면, 프로세싱 유닛은 인공 신경망의 가중치들에 대해 가지치기(pruning) 마스크들 을 적용한다(S10). 구체적으로, 상기 프로세싱 유닛은 상기 가중치들을 가중치 그룹들로 그룹화한다. 상기 프로 세싱 유닛은 상기 가중치 그룹들 각각과 상기 가지치기 마스크들의 문턱값들 각각을 비교한다. 상기 프로세싱 유닛은 상기 비교에 따라 상기 가중치 그룹들 중 특정 그룹에 속한 가중치들을 모두 0으로 설정한다. 상기 프로세싱 유닛은 인공 신경망을 통해 훈련 데이터(training data)로부터 활성화 데이터를 프로파게이 팅(propagating)한다(S20). 상기 프로세싱 유닛은 상기 활성화 데이터와 목표 데이터에 기초하여 손실 함수(loss function)의 값을 계산한 다(S30). 상기 프로세싱 유닛은 인공 신경망의 가중치들과 관련된 상기 손실 함수(loss function)의 기울기 (gradient)와, 상기 가지치기 마스크들의 문턱값들(Threshold)과 관련된 상기 손실 함수의 기울기를 계산하기 위해 상기 손실 함수의 값을 백프로파게이팅(backpropagating)한다(S40). 상기 프로세싱 유닛은 인공 신경망의 가중치들과 관련된 상기 손실 함수의 기울기와, 상기 가지치기 마스 크들의 문턱값들과 관련된 상기 손실 함수의 기울기에 기초하여 인공 신경망의 가중치들과, 상기 가지치기 마스크의 문턱값들을 업데이트한다(S50). 상기 프로세싱 유닛은 가속기의 프로세싱 엘리먼트들의 가 중치 레지스터들에서 상기 가지치기 마스크들이 적용된 가중치들의 배열을 분석한다. 상기 프로세싱 유닛 은 상기 배열의 분석에 따라 임의의 에포크들(epoch) 동안 상기 가중치 레지스터들 중 특정 가중치 레지스터에 배열된 가중치들을 업데이트하지 않기 위해 상기 특정 가중치 레지스터에 배열된 가중치들에 대응하는 가지치기 마스크의 문턱값들을 유지한다. 상기 프로세싱 유닛은 상기 특정 가중치 레지스터에 배열된 가중치들을 제외한 나머지 가중치 레지스터들에 배 열된 가중치들을 업데이트하기 위해 상기 나머지 가중치들에 대응하는 가지치기 마스크들의 문턱값들을 조정한 다. 상기 프로세싱 유닛은 조정된 문턱값들에 따라 인공 신경망을 훈련시킨다. 본 발명에서는 가속기의 프로세싱 엘리먼트들의 가중치 레지스터들에 배열된 제로 가중치 그룹 들을 고려하여 가지치기함으로써 가속기에서의 레이턴시를 감소될 수 있다. 본 발명은 도면에 도시된 일 실시 예를 참고로 설명되었으나 이는 예시적인 것에 불과하며, 본 기술 분야의 통 상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시 예가 가능하다는 점을 이해할 것이다. 따라 서 본 발명의 진정한 기술적 보호 범위는 첨부된 등록청구범위의 기술적 사상에 의해 정해져야 할 것이다. 부호의 설명100: 시스템; 10: CPU; 20: GPU; 30: 메모리; 101: 버스; 200: 가속기;"}
{"patent_id": "10-2021-0062970", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 상세한 설명에서 인용되는 도면을 보다 충분히 이해하기 위하여 각 도면의 상세한 설명이 제공된다. 도 1은 본 발명의 실시 예에 따른 인공 신경망에서 학습을 통한 로드 밸런싱 시스템의 블록도를 나타낸다. 도 2는 도 1에 도시된 프로세싱 유닛의 동작을 설명하기 위한 인공 신경망의 블록도를 나타낸다. 도 3은 도 1에 도시된 가속기의 블록도를 나타낸다. 도 4는 도 3에 도시된 프로세싱 엘리먼트(processing element)의 내부 블록도를 나타낸다. 도 5는 도 3에 도시된 복수의 프로세싱 엘리먼트들의 내부 블록도를 나타낸다. 도 6은 도 1에 도시된 시스템의 동작 방법을 설명하기 위한 흐름도를 나타낸다."}
