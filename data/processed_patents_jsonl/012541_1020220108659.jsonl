{"patent_id": "10-2022-0108659", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0156242", "출원번호": "10-2022-0108659", "발명의 명칭": "시맨틱 분석을 통한 의미 검색 서비스 제공 방법", "출원인": "한국데이터플랫폼 주식회사", "발명자": "김영호"}}
{"patent_id": "10-2022-0108659", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "문장 형태의 텍스트 정보를 입력받는 문장 획득부;문장 획득부로부터 입력받은 문장을 의미를 가지는 최소 단위의 단어인 형태소로 분리하는 형태소 추출부;입력 단어(형태소)에 대응하는 대체어, 유의어, 추론어, 해당 단어의 감정에 관련된 감정 형태소의 의미 연관어를 벡터화하여 저장하는 연관어 데이터베이스부와, 상기 입력 단어에 매칭되는 하나 이상의 주제어를 벡터화하여 저장하는 주제어 데이터베이스부 및 단어와 단어로 이루어진 문장의 의미를 분석하여 의미별로 분류된 의미분석 문장을 벡터화하여 저장하는 의미 분석 데이터베이스부로 이루어진 데이터 저장부;상기 형태소 추출부로부터 추출된 단어를 단어 벡터 변환을 처리하는 단어 임베딩 처리부;상기 단어 임베딩 처리부에서 처리된 단어 벡터를 기초로 단어들의 문맥(단어 의미의 앞뒤 연결)을 고려한 기설정된 문맥 연결 기준에 부합하는 문장에 대하여 문장 벡터 변환을 처리하는 문장 임베딩 처리부;상기 문장 벡터 변환을 처리한 문장을 상기 의미 분석 데이터베이스부에서 비교, 분석하여 상기 문장에 대응되는 의미별로 분류된 의미 분석 문장을 벡터화 처리하고, 상기 주제어 데이터베이스부에서 상기 벡터화된 의미분석 문장을 기초로 하나 이상의 주제어를 추출하는 제어부;책, 논문, 잡지, 출판물의 복수의 텍스트 데이터를 문장 단위로 벡터화하여 저장하고 있는 대상 문서 데이터베이스부; 및상기 추출한 주제어를 나타내는 벡터 집합과, 상기 대상 문서 데이터베이스부의 텍스트 데이터의 벡터 집합을이용하여 문장 간의 유사도를 계산하는 문장 유사도 계산부로 이루어진 시맨틱 분석 서버를 포함하며, 상기 제어부는 상기 문장 유사도 계산부에서 판단한 동일하거나 유사한 문장들을 상기 텍스트 데이터에서 유사 문장으로 카운트하고, 유사 문장 개수가 많은 순서로 기설정된 상위 순번의 텍스트 데이터를 추출하고, 상기 추출한상위 순번의 텍스트 데이터마다 상기 동일하거나 유사한 문장들의 페이지 번호의 몇 번째 문단인지 페이지 알림정보를 생성하고,상기 문장 유사도 계산부는 문장 임베딩 기법에서 하기의 수학식 1에 의해 두 문장 p와 q 간의 유사도를 나타내는 유클리디안 거리(Euclidean Distance)를 계산하고, 상기 계산한 유클리디안 거리가 기설정된 제1 임계값 이상인 경우, 동일하거나 유사한 제1 문장으로 판단하는 제1 문장 유사도 계산부; 및문장 임베딩 기법에서 하기의 수학식 2에 의해 코사인 유사도(Cosine Similarity)를 계산하고, 상기 계산한 코사인 유사도가 기설정된 제2 임계값 이상인 경우, 동일하거나 유사한 제2 문장으로 판단하는 제2 문장 유사도계산부를 포함하고,[수학식 1]상기 문장 p는 문장 획득부에 입력된 문장을 나타내고, 상기 문장 q는 대상 문서 데이터베이스부에 저장된 복수의 텍스트 데이터를 나타내고, 주제어로 이루어진 문장 p의 doc2vec가 이고, 문장 q의doc2vec가 임.공개특허 10-2023-0156242-3-[수학식 2]상기 a는 문장 획득부에 입력된 문장을 나타내고, 상기 b는 대상 문서 데이터베이스부에 저장된 복수의 텍스트데이터이고,상기 제어부는 상기 제1 문장 유사도 계산부에서 동일하거나 유사한 문장으로 판단한 하나 이상의 제1 문장과,상기 제2 문장 유사도 계산부에서 동일하거나 유사한 문장으로 판단한 하나 이상의 제2 문장을 비교하고, 상기제1 문장, 상기 제1 문장과 중복되지 않은 제2 문장(제1 문장들의 여집합)을 상기 대상 문서 데이터베이스부의텍스트 데이터에서 검색하고, 상기 대상 문서 데이터베이스부에서 복수의 제1 문장과, 제1 문장과 중복되지 않은 제2 문장들(제1 문장들의 여집합)을 유사 문장 개수로 검색하여 카운트하며, 상기 카운트된 유사 문장 개수가 많은 순서로 상기 기설정된 상위 순번의 텍스트 데이터를 추출하고,상기 대상 문서 데이터베이스부는 입력되는 텍스트 데이터인 PDF 파일을 텍스트 파일(TXT 파일)로 변환하는 텍스트 변환부; 및상기 텍스트 변환부에서 텍스트 파일이 변환할 때마다 페이지 번호를 생성하고, 텍스트 파일의 첫 번째 페이지의 시작 위치에 식별용 태그를 삽입하며, 문단마다 식별용 태그를 순번대로 삽입하여 페이지를 식별하고, 식별용 태그와 페이지 번호로 이루어진 페이지 정보를 삽입한 텍스트 파일을 저장부에 저장하는 페이지 번호 식별부를 더 포함하고,상기 시맨틱 분석 서버는 단어와 단어로 이루어진 문장 벡터과, 벡터화된 의미 분석 문장과, 이에 대응하는 텍스트 데이터의 주제어를 수신하여 저장하는 데이터 수집부를 더 포함하며, 상기 문장 벡터와, 상기 벡터화된 의미 분석 문장을 인공 신경 처리망에 입력하고, 상기 인공 신경 처리망의 응답으로 의미 분석 문장에 대응하는텍스트 데이터의 하나 이상의 주제어를 출력하는 문장 의미를 분석하여 찾아주는 시맨틱 분석 제공 시스템."}
{"patent_id": "10-2022-0108659", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예는 시맨틱 분석을 통한 의미 검색 서비스 제공 방법에 관한 것으로, 문장 형태의 질의문에 대하여 의미 분석하고, 텍스트 문서에서 질의문과 동일하거나 유사한 문장을 찾아주어 페이지 정보와 함께 시맨 트 분석 서비스를 제공할 수 있다."}
{"patent_id": "10-2022-0108659", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 시맨틱 분석을 통한 의미 검색 서비스 제공 방법에 관한 것이다."}
{"patent_id": "10-2022-0108659", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "시맨틱(Semantic) 검색은 질의 분석을 통해서 검색 의도를 파악하고, 검색 의도에 부합하는 검색 결과를 제공한 다. 현재 포털 사이트나 검색 사이트는 단어를 입력하는 경우, 검색 엔진에서 입력된 단어와 일치되는 문서를 추출 하는 기능을 수행하고 있다. 그러나 예를 들어, 사람이 책을 읽고 나서 어떤 내용을 물어보면, 문장 형태를 시 맨틱 분석하여 찾아주는 기능이 아직까지 구현되지 못하고 있다. 텍스트 자료에서는 문장 질의문에 대응하는 문장을 자연어 처리하여 추출하는 것이 매우 어려우며, 문장 질의문 에 맞는 문장을 추출하는 효율이나 성능이 높지 않은 문제점이 있다. 현재에도 문장 형태로 질의하는 경우, 문장의 의미 분석을 통해 유사한 의미의 문장을 포함한 책, 논문, 기타 자료를 찾아주는 시맨틱 분석 제공 서비스가 활성화되어 있지 않으며, 여전히 연구해야 할 대상으로 남아 있다. 선행기술문헌 특허문헌"}
{"patent_id": "10-2022-0108659", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "(특허문헌 0001) 한국 등록특허번호 제10-2285232호 발명의 내용"}
{"patent_id": "10-2022-0108659", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이와 같은 문제점을 해결하기 위하여, 본 발명은 문장 형태의 질의문에 대하여 의미 분석하고, 텍스트 문서에서 질의문과 동일하거나 유사한 문장을 찾아주어 페이지 정보와 함께 시맨트 분석 서비스로 제공하는 문장 의미를 분석하여 찾아주는 시맨틱 분석 제공 시스템을 제공하는데 그 목적이 있다."}
{"patent_id": "10-2022-0108659", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 특징에 따른 문장 의미를 분석하여 찾아주는 시맨틱 분석 제공 시스템은, 문장 형태의 텍스트 정보를 입력받는 문장 획득부; 문장 획득부로부터 입력받은 문장을 의미를 가지는 최소 단위의 단어인 형태소로 분리하는 형태소 추출부; 입력 단어(형태소)에 대응하는 대체어, 유의어, 추론어, 해당 단어의 감정에 관련된 감정 형태소의 의미 연관어 를 벡터화하여 저장하는 연관어 데이터베이스부와, 상기 입력 단어에 매칭되는 하나 이상의 주제어를 벡터화하 여 저장하는 주제어 데이터베이스부 및 단어와 단어로 이루어진 문장의 의미를 분석하여 의미별로 분류된 의미 분석 문장을 벡터화하여 저장하는 의미 분석 데이터베이스부로 이루어진 데이터 저장부; 상기 형태소 추출부로부터 추출된 단어를 단어 벡터 변환을 처리하는 단어 임베딩 처리부; 상기 단어 임베딩 처리부에서 처리된 단어 벡터를 기초로 단어들의 문맥(단어 의미의 앞뒤 연결)을 고려한 기설 정된 문맥 연결 기준에 부합하는 문장에 대하여 문장 벡터 변환을 처리하는 문장 임베딩 처리부; 상기 문장 벡터 변환을 처리한 문장을 상기 의미 분석 데이터베이스부에서 비교, 분석하여 상기 문장에 대응되 는 의미별로 분류된 의미 분석 문장을 벡터화 처리하고, 상기 주제어 데이터베이스부에서 상기 벡터화된 의미 분석 문장을 기초로 하나 이상의 주제어를 추출하는 제어부; 책, 논문, 잡지, 출판물의 복수의 텍스트 데이터를 문장 단위로 벡터화하여 저장하고 있는 대상 문서 데이터베 이스부; 및 상기 추출한 주제어를 나타내는 벡터 집합과, 상기 대상 문서 데이터베이스부의 텍스트 데이터의 벡터 집합을 이용하여 문장 간의 유사도를 계산하는 문장 유사도 계산부로 이루어진 시맨틱 분석 서버를 포함하며, 상기 제 어부는 상기 문장 유사도 계산부에서 판단한 동일하거나 유사한 문장들을 상기 텍스트 데이터에서 유사 문장으 로 카운트하고, 유사 문장 개수가 많은 순서로 기설정된 상위 순번의 텍스트 데이터를 추출하고, 상기 추출한 상위 순번의 텍스트 데이터마다 상기 동일하거나 유사한 문장들의 페이지 번호의 몇 번째 문단인지 페이지 알림 정보를 생성한다. 또한, 문장 유사도 계산부는 문장 임베딩 기법에서 하기의 수학식 1에 의해 두 문장 p와 q 간의 유사도를 나타 내는 유클리디안 거리(Euclidean Distance)를 계산하고, 상기 계산한 유클리디안 거리가 기설정된 제1 임계값 이상인 경우, 동일하거나 유사한 제1 문장으로 판단하는 제1 문장 유사도 계산부; 및 문장 임베딩 기법에서 하기의 수학식 2에 의해 코사인 유사도(Cosine Similarity)를 계산하고, 상기 계산한 코 사인 유사도가 기설정된 제2 임계값 이상인 경우, 동일하거나 유사한 제2 문장으로 판단하는 제2 문장 유사도 계산부를 포함하는 문장 의미를 분석하여 찾아주는 시맨틱 분석 제공 시스템. [수학식 1]"}
{"patent_id": "10-2022-0108659", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "여기서, 문장 p는 문장 획득부에 입력된 문장을 나타내고, 문장 q는 대상 문서 데이터베이스부에 저장된 복수의 텍스트 데이터를 나타내고, 주제어로 이루어진 문장 p의 doc2vec가 이고, 문장 q의doc2vec가 임. [수학식 2]"}
{"patent_id": "10-2022-0108659", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "여기서, a는 문장 획득부에 입력된 문장을 나타내고, b는 대상 문서 데이터베이스부에 저장된 복수의 텍스트 데 이터임. 또한, 제어부는 상기 제1 문장 유사도 계산부에서 동일하거나 유사한 문장으로 판단한 하나 이상의 제1 문장과, 상기 제2 문장 유사도 계산부에서 동일하거나 유사한 문장으로 판단한 하나 이상의 제2 문장을 비교하고, 상기 제1 문장, 상기 제1 문장과 중복되지 않은 제2 문장(제1 문장들의 여집합)을 상기 대상 문서 데이터베이스부의 텍스트 데이터에서 검색하고, 상기 대상 문서 데이터베이스부에서 복수의 제1 문장과, 제1 문장과 중복되지 않 은 제2 문장들(제1 문장들의 여집합)을 유사 문장 개수로 검색하여 카운트하며, 상기 카운트된 유사 문장 개수 가 많은 순서로 상기 기설정된 상위 순번의 텍스트 데이터를 추출한다."}
{"patent_id": "10-2022-0108659", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 구성에 의하여, 본 발명은 문장의 의미 분석을 통해 유사한 의미의 문장을 포함한 책, 논문, 기타 자료 를 찾아주는 시맨틱 분석 제공 서비스를 제공하는 효과가 있다. 본 발명은 문장의 의미를 단어의 동일어, 대체어, 유의어, 추론어, 해당 단어의 감정에 관련된 감정 형태소 등 의 의미 연관어를 모두 포괄하여 검색할 수 있어 문장 검색의 효율과 성능이 향상되는 효과가 있다."}
{"patent_id": "10-2022-0108659", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어 야 한다. 각 도면을 설명하면서 유사한 참조부호를 유사한 구성요소에 대해 사용하였다. 제1, 제2, A, B 등의 용어는 다양한 구성요소들을 설명하는 데 사용될 수 있지만, 상기 구성요소들은 상기 용어 들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있 고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. \"및/또는\"이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 본 발명을 설 명함에 있어 전체적인 이해를 용이하게 하기 위하여 도면상의 동일한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 도 1은 본 발명의 실시예에 따른 문장 의미를 분석하여 찾아주는 시맨틱 분석 제공 시스템의 구성을 나타낸 블 록도이다. 본 발명의 실시예에 따른 문장 의미를 분석하여 찾아주는 시맨틱 분석 제공 시스템은 사용자 단말인 하나 이상의 전자 기기, 통신망 및 시맨틱 분석 서버를 포함한다. 복수의 전자 기기들은 컴퓨터 장치로 구현되는 고정형 단말이거나 이동형 단말일 수 있다. 복수의 전자 기기들는 예를 들면, 스마트폰(smart phone), 휴대폰, 내비게이션, 컴퓨터, 노트북, 디지털방 송용 단말, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 태블릿 PC 등이 있다. 일례 로 전자 기기는 무선 또는 유선 통신 방식을 이용하여 통신망를 통해 시맨틱 분석 서버와 통신 할 수 있다. 통신망은 통신 방식은 제한되지 않으며, 일례로, 이동통신망, 유선 인터넷, 무선 인터넷, 방송망)을 활용 하는 통신 방식뿐만 아니라 기기들간의 근거리 무선 통신 역시 포함될 수 있다. 예를 들어, 통신망은 PAN(personal area network), LAN(local area network), CAN(campus area network), MAN(metropolitan area network), WAN(wide area network), BBN(broadband network), 인터넷 등의 네트워크 중 하나 이상의 임의의 네 트워크를 포함할 수 있다. 또한, 통신망은 버스 네트워크, 스타 네트워크, 링 네트워크, 메쉬 네트워크, 스타-버스 네트워크, 트리 또는 계층적(hierarchical) 네트워크 등을 포함하는 네트워크 토폴로지 중 임의의 하 나 이상을 포함할 수 있으나, 이에 제한되지 않는다. 시맨틱 분석 서버는 복수의 전자 기기들과 통신망을 통해 통신하여 명령, 코드, 파일, 컨텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구현될 수 있다. 시맨틱 분석 서버는 통신망를 통해 접속한 전자 기기로 어플리케이션의 설치를 위한 파일을 제 공할 수 있다. 이 경우 전자 기기는 시맨틱 분석 서버로부터 제공된 파일을 이용하여 어플리케이션을 설치할 수 있다. 또한, 전자 기기가 포함하는 운영체제(Operating System, OS) 및 적어도 하나의 프로그램(일례로 브라우저 나 상기 설치된 어플리케이션)의 제어에 따라 시맨틱 분석 서버에 접속하여 시맨틱 분석 서버가 제공 하는 서비스나 컨텐츠를 제공받을 수 있다. 예를 들어, 전자 기기가 어플리케이션의 제어에 따라 통신망 를 통해 서비스 요청 메시지를 시맨틱 분석 서버로 전송하면, 시맨틱 분석 서버는 서비스 요청 메시지에 대응하는 코드를 전자 기기로 전송할 수 있고, 전자 기기는 어플리케이션의 제어에 따라 코 드에 따른 화면을 구성하여 표시함으로써 사용자에게 컨텐츠를 제공할 수 있다. 전자 기기는 사용자로부터 단어로 이루어진 문장을 입력받고, 시맨틱 분석 서버로부터 입력받은 문장 의 의미를 시맨틱 분석하여 책, 논문, 잡지, 출판물의 텍스트 데이터에서 검색하여 유사한 문장을 찾아주는 시 맨틱 분석 서비스를 제공받는다. 시맨틱 분석 서버는 전자 기기로부터 하나 이상의 단어로 이루어진 문장 형태의 정보를 입력받고, 입 력받은 문장의 의미를 분석하여 책, 논문, 잡지, 출판물의 텍스트 데이터에서 유사한 문장을 찾는 시맨틱 분석 을 수행한다.도 2는 본 발명의 실시예에 따른 시맨틱 분석 서버의 내부 구성을 나타낸 블록도이다. 본 발명의 실시예에 따른 시맨틱 분석 서버는 문장 획득부, 형태소 추출부, 데이터 저장부 , 제어부, 단어 임베딩 처리부, 문장 임베딩 처리부, 대상 문서 데이터베이스부, 문 장 유사도 계산부 및 통신부를 포함한다. 문장 획득부는 전자 기기로부터 하나 이상의 단어로 이루어진 문장 형태의 정보를 수신한다. 예를 들 어, \"오늘 우울한데 어떤 책을 읽을까?\", \"19세기 인도 철학을 알고 싶습니다\" 등 문장 형태의 정보를 나타낸다. 형태소 추출부는 문장 획득부로부터 입력받은 문장을 의미를 가지는 최소 단위의 단어인 형태소로 분 리한다. 이때, 형태소 추출부는 문장의 분별력 향상을 위해 불필요한 단어 즉, 불용어에 대한 필터링을 수행한다. 불용어는 대다수의 문장에서 높은 빈도로 포함된 단어로 조사, 어미, 접두사 또는 접미사 중에 어느 하나로 구 성될 수 있으며, 사용자 설정에 따라 지정된 단어를 포함할 수 있다. 데이터 저장부는 입력 단어(형태소)에 대응하는 대체어, 유의어, 추론어, 해당 단어의 감정에 관련된 감정 형태소 등의 의미 연관어를 word2vec 또는 doc2vec를 통해 벡터화하여 저장하는 연관어 데이터베이스부(133a)와, 입력 단어에 매칭되는 하나 이상의 주제어를 word2vec 또는 doc2vec를 통해 벡터화하 여 저장하는 주제어 데이터베이스부(133b)와, 단어들의 문맥(단어 의미의 앞뒤 연결)을 고려한 기설정된 문맥 연결 기준에 부합하고, 단어와 단어로 이루어진 문장의 의미를 분석하여 의미별로 분류된 의미 분석 문장을 벡 터화하여 저장하는 의미 분석 데이터베이스부(133c)를 포함한다. 예를 들어, 입력 문장이 19세기 인도 철학인 경우, 19세기+인도+철학의 형태소로 분리하고, 문장의 의미를 분석 하여 의미 분석 데이터베이스부(133c)에 저장된다. 대상 문서 데이터베이스부는 책, 논문, 잡지, 출판물 등의 복수의 텍스트 데이터를 문장 단위로 벡터화하 여 저장하고 있다. 대상 문서 데이터베이스부는 텍스트 변환부(135a), 페이지 번호 식별부(135b) 및 저장부(135c)를 포함한다. 텍스트 변환부(135a)는 입력되는 텍스트 데이터인 PDF 파일을 텍스트 파일(TXT 파일)로 변환한다. 페이지 번호 식별부(135b)는 텍스트 변환부(135a)에서 텍스트 파일이 변환할 때마다 페이지 번호를 생성하고, 텍스트 파일의 첫 번째 페이지의 시작 위치에 식별용 태그를 삽입하며, 문단마다 식별용 태그를 순번대로 삽입 하여 페이지를 식별할 수 있다. 페이지 번호 식별부(135b)는 식별용 태그와 페이지 번호로 이루어진 페이지 정보를 삽입한 텍스트 파일을 저장 부(135c)에 저장한다. 단어 임베딩 처리부는 형태소 추출부로부터 추출된 단어를 단어 벡터 변환을 처리한다. 문장 임베딩 처리부는 단어 임베딩 처리부에서 처리된 단어 벡터를 기초로 단어들의 문맥(단어 의미 의 앞뒤 연결)을 고려한 기설정된 문맥 연결 기준에 부합하는 문장에 대하여 문장 벡터 변환을 처리한다. 단어 임베딩 처리부와 문장 임베딩 처리부는 단어와 문장을 신경망 기반의 임베딩 알고리즘을 이용하 여 벡터화한다. 여기서, 임베딩 알고리즘은 doc2vec, word2vec, sense2vec 등 기공지된 임베딩 기술을 활용할 수 있다. 제어부는 문장 벡터 변환을 처리한 문장을 의미 분석 데이터베이스부(133c)에서 비교, 분석하여 문장에 대 응되는 의미별로 분류된 의미 분석 문장을 벡터화 처리하고, 주제어 데이터베이스부(133b)에서 벡터화된 의미 분석 문장을 기초로 하나 이상의 주제어를 추출한다. 여기서, 주제어는 어떤 글이나 문학 작품에서 중심이 되는 사상을 나타내는 단어나 구를 나타낸다. 제어부는 입력 문장이 \"19세기 인도 철학을 알고 싶습니다\"인 경우, 의미 분석 데이터베이스부(133c)에서 19세기+인도+철학을 의미별로 분류하여 의미 분석 문장을 추출하고, 주제어 데이터베이스부(133b)에서 추출한 의미 분석 문장을 이용하여 의미 분석 문장과 관련된 상키야 철학, 힌두교 철학 등을 주제어로 추출한다.제어부는 입력 문장이 \"오늘 우울한데 어떤 책을 읽을까요?\"인 경우, 의미 분석 데이터베이스부(133c)에서 우울+책+읽다를 의미별로 분류하여 의미 분석 문장을 추출하고, 주제어 데이터베이스부(133b)에서 추출한 의미 분석 문장을 이용하여 의미 분석 문장과 관련하여 낙심, 불행, 슬픈, 비참, 외롭, 자포자기, 후회 등을 주제어 로 추출한다. 문장 유사도 계산부는 추출한 주제어를 나타내는 벡터 집합과, 대상 문서 데이터베이스부의 텍스트 데이터의 벡터 집합을 이용하여 문장 간의 유사도를 계산하고 제1 문장 유사도 계산부(138a)와 제2 문장 유사도 계산부(138b)를 포함한다. 제1, 2 문장 유사도 계산부(138a, 138b)는 주제어들을 나타내는 벡터 집합을 이용하여 문장 간의 유사성 점수를 산출할 수 있다. 제1 문장 유사도 계산부(138a)는 주제어로 이루어진 문장 p의 doc2vec가 이고, 문장 q의 doc2vec가 라 할 때, 두 문장 p와 q 간의 제1 유사도를 나타내는 유클리디안 거리는 하 기의 수학식 2와 같이 정의될 수 있다. 문장 p는 문장 획득부에 입력된 문장을 나타내고, 문장 q는 대상 문서 데이터베이스부에 저장된 복수 의 텍스트 데이터를 나타낸다. 제1 문장 유사도 계산부(138a)는 문장 임베딩 기법에서 다음의 수학식 1에 의해 두 문장 p와 q 간의 유사도를 나타내는 유클리디안 거리(Euclidean Distance)를 계산하고, 계산한 유클리디안 거리가 기설정된 제1 임계값 이 상인 경우, 동일하거나 유사한 제1 문장으로 판단한다. 수학식 1"}
{"patent_id": "10-2022-0108659", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "제2 문장 유사도 계산부(138b)는 문장 임베딩 기법에서 다음의 수학식 2에 의해 코사인 유사도(Cosine Similarity)를 계산하고, 계산한 코사인 유사도가 기설정된 제2 임계값 이상인 경우, 동일하거나 유사한 제2 문 장으로 판단한다. 수학식 2"}
{"patent_id": "10-2022-0108659", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, a는 문장 획득부에 입력된 문장을 나타내고, b는 대상 문서 데이터베이스부에 저장된 복수의 텍스트 데이터를 나타낸다. 제어부는 문장 유사도 계산부에서 판단한 동일하거나 유사한 문장들을 텍스트 데이터에서 유사 문장 으로 카운트하고, 유사 문장 개수가 많은 순서로 기설정된 상위 순번의 텍스트 데이터를 추출하고, 추출한 상위 순번의 텍스트 데이터마다 동일하거나 유사한 문장들의 페이지 번호의 몇 번째 문단인지 페이지 알림 정보를 생 성한다. 제어부는 제1 문장 유사도 계산부(138a)에서 동일하거나 유사한 문장으로 판단한 하나 이상의 제1 문장과, 제2 문장 유사도 계산부(138b)에서 동일하거나 유사한 문장으로 판단한 하나 이상의 제2 문장을 비교하고, 제1문장, 제1 문장과 중복되지 않은 제2 문장(제1 문장들의 여집합)을 대상 문서 데이터베이스부의 텍스트 데 이터에서 검색한다. 제어부는 대상 문서 데이터베이스부에서 복수의 제1 문장과, 제1 문장과 중복되지 않은 제2 문장들 (제1 문장들의 여집합)을 유사 문장 개수로 검색하여 카운트한다. 제어부는 카운트된 유사 문장 개수가 많은 순서로 기설정된 상위 순번의 텍스트 데이터를 추출한다. 여기 서, 텍스트 데이터는 대상 문서 데이터베이스부에 저장된 책, 논문, 잡지, 출판물 등 자연어 처리가 가능 한 문서를 의미한다. 예를 들어, 카운트된 유사 문장 개수가 많은 상위 5개의 텍스트 데이터를 추출하고, 각각의 텍스트 데이터마다 유사 문장들을 색깔로 표시한다. 제어부는 추출한 각각의 텍스트 데이터에 동일하거나 유사한 문장으로 판단한 제1 문장과 제2 문장을 블록 화된 화면 영역을 색깔로 표시하고, 표시된 문장마다 페이지 정보를 이용하여 페이지 번호의 몇 번째 문단인지 페이지 알림 정보를 생성한다. 제어부는 페이지 알림 정보와 텍스트 데이터의 종류를 포함한 결과 정보를 생성하여 통신부를 통해 전자 기기로 전송한다. 다른 실시예로서, 제어부는 수학식 1에 의해 계산된 유클리디안 거리(Euclidean Distance)와, 수학식 2에 의해 계산된 코사인 유사도(Cosine Similarity)를 하기의 수학식 3에 대입하여 문장 검색 지수를 계산한다. 문 장 검색 지수는 입력 문장에 유사한 정도를 나타내는 유사도 값을 나타낸다. 제어부는 전술한 제1 문장과 제2 문장마다 문장 검색 지수를 계산하고, 계산한 문장 검색 지수를 기설정된 검색 범위에 따라 색상을 다르게 하여 블록화된 화면 영역으로 표시한다. 예를 들어, 문장 검색 지수의 범위는 제1 값 내지 제2 값인 경우, 녹색, 제2 값 내지 제3 값인 경우, 파란색, 제3 값 내지 제4 값인 경우, 노란색, 제4 값 내지 제5 값인 경우, 빨간색으로 문장의 색깔을 다르게 표시할 수 있다. 수학식 3"}
{"patent_id": "10-2022-0108659", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, W1는 문장 유사도 검색 시 유클리디안 거리와 관련된 기설정된 가중치이고, W2는 문장 유사도 검색 시 코사인 유사도와 관련된 기설정돤 가중치이고, ED는 유클리디안 거리(Euclidean Distance)이며, CS는 코사인 유 사도(Cosine Similarity)이다. 입력 문장의 분리된 형태소를 기초로 주제어 데이터 저장부에서 형태소에 대응하는 하나 이상의 주제어를 추출하는 방법을 아래와 같이 설명한다. 제어부는 하기의 수학식 4와 같이, 입력 단어의 검색 빈도수와 입력 단어(형태소)에 대응하는 의미 연관어 의 개수에 따라 텍스트 데이터에 포함된 단어의 중요도 인덱스를 계산한다. 제어부는 계산한 중요도 인덱스가 기설정된 제3 임계값 이상인 경우, 해당 텍스트 데이터에 포함된 단어가 입력 문장의 단어에 매칭되는 주제어에 해당된다고 판단하여 주제어 데이터베이스부(133b)에 저장한다. 수학식 4"}
{"patent_id": "10-2022-0108659", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "중요도 인덱스는 주제어 데이터 저장부에 저장된 주제어를 선정하는데 필요한 지표이다. 여기서, W3는 입력 문장의 단어에 대응하는 주제어를 텍스트 데이터에서 추출하는 경우, 검색 빈도수 (Frequency)와 관련된 가중치이고, W4는 입력 문장의 단어에 대응하는 주제어를 텍스트 데이터에서 추출하는 경 우, 의미 연관도(Semantic Relevance)와 관련된 가중치이고, FR은 검색 빈도수(Frequency)의 개수이며, SR은 의미 연관어의 개수를 나타내는 의미 연관도(Semantic Relevance)이다. 중요도 인덱스는 입력 문장의 단어가 텍스트 데이터에서 검색되는 빈도수가 많을수록 인덱스 값이 높고, 텍스트 데이터에서 입력 문장의 단어와 연관된 의미 연관어의 개수가 많을수록 인덱스 값이 높아진다. 제어부는 대상 문서 데이터베이스부와 연동하여 카운트한 유사 문장 개수가 가장 많은 텍스트 데이터 를 선택하고, 선택한 텍스트 데이터의 종류, 페이지 알림 정보를 포함한 결과 정보를 생성하여 통신부를 통해 전자 기기로 전송한다. 제어부는 각각의 텍스트 데이터에서 제1 문장들, 제1 문장과 중복되지 않은 제2 문장들(제1 문장들의 여집 합)의 문장 검색 지수를 전술한 수학식 3에 의해 계산하고, 문장 검색 지수가 기설정된 기준치 이상인지 판단하 고, 기준치 이상인 문장 검색 지수의 개수를 카운트한다. 제어부는 카운트한 문장 검색 지수가 가장 많은 텍스트 데이터를 선택하고, 선택한 텍스트 데이터의 종류, 페이지 알림 정보를 포함한 결과 정보를 생성하여 통신부를 통해 전자 기기로 전송한다. 문장이 입력되면, 인공지능을 이용하여 입력 문장과 연관된 주제어를 생성하는 방법과, 단어와 단어로 이루어진 문장 벡터와 이에 대응하는 벡터화된 의미 분석 문장을 생성하는 방법을 하기의 도 3을 참조하여 상세하게 설명 한다. 도 3은 본 발명의 실시예에 따른 시맨틱 분석 서버의 학습 모델과 인공 신경 처리망의 구성을 나타낸 도면이다. 본 발명의 실시예에 따른 시맨틱 분석 서버는 제어부, 데이터 수집부, 디스플레이부, 학습 모델부 및 인공 신경 처리망을 포함한다. 데이터 수집부는 단어와 단어로 이루어진 문장 벡터과, 벡터화된 의미 분석 문장과, 이에 대응하는 텍스트 데이터의 주제어를 수신하여 저장하고 있다. 시맨틱 분석 서버는 문장 벡터와, 벡터화된 의미 분석 문장을 인공 신경 처리망에 입력하고, 인공 신 경 처리망의 응답으로 의미 분석 문장에 대응하는 텍스트 데이터의 하나 이상의 주제어를 출력한다. 데이터 수집부에 저장된 데이터 세트는 훈련 세트와 테스트 세트로 더 나뉜다. 훈련 세트는 머신 러닝 또 는 딥 러닝 모델에 제공된다. 학습 모델부는 데이터 처리부, 학습부 및 분류부를 포함한다. 인공 신경 처리망은 입력층, 컨볼루션 레이어부, 풀링 레이어부 및 풀리 커넥티드 레이어 부로 이루어진 은닉층, 출력층을 포함한다. 데이터 처리부는 데이터 수집부로부터 데이터 세트에서 문장 벡터와 이에 대응하는 벡터화된 의미 분 석 문장으로 이루어진 훈련 세트(Train Set)를 수신하여 인공 신경 처리망로 전송한다. 훈련 세트는 학습 데이터를 나타낸다. 데이터 처리부는 데이터 수집부로부터 데이터 세트에서 문장 벡터와 이에 대응하는 벡터화된 의미 분 석 문장으로 이루어진 훈련 세트(Train Set)를 수신하여 인공 신경 처리망로 전송한다. 데이터 처리부는 데이터 수집부로부터 데이터 세트에서 문장 벡터와 이에 대응하는 벡터화된 의미 분 석 문장으로 이루어진 테스트 세트(Test Set)를 수신하여 분류부로 전송한다. 데이터 처리부는 분산 병렬 처리가 가능한 데이터베이스부로 형성될 수 있다. 인공 신경 처리망은 문장 벡터와 이에 대응하는 벡터화된 의미 분석 문장으로 이루어진 훈련 세트(Train Set)를 인공 신경 처리망에 입력하여 적용시켜 오류를 수정하고, 수정된 오류를 이용하여 텍스트 데이터의 주제어 생성의 예측 결과 여부를 출력한다. 인공 신경 처리망은 문장 벡터와 이에 대응하는 벡터화된 의미 분석 문장으로 이루어진 훈련 세트(Train Set)를 인공 신경 처리망에 입력하여 적용시켜 오류를 수정하고, 수정된 오류를 이용하여 의미 분석 문장에 대응하는 텍스트 데이터의 주제어 생성 결과를 출력한다. 이때, 인공 신경 처리망은 심층 컨볼루션 신경망(Deep Convolutional Neural Neworks, CNNs)을 이용하고, 입력층, 은닉층, 출력층을 포함할 수 있다. 인공 신경 처리망은 예측 분석을 위해 신경망 기반 모델을 사용한다. 인공 신경 처리망은 입력층 x, 출력층 y 및 4개의 뉴런을 포함하는 임의의 양의 은닉층을 포함한다. 각 레이어는 출력층을 제외하고 밴드 W로 표시되는 편향 및 가중치 세트로 구성된다. 각 은닉층의 활성화 함수로 시그모이드 함수를 사용한다. 모델의 예측 점수를 향상시키기 위해 입력 데이터의 편향 및 가중치 미세 조정이 수행된다. 훈련 과정에서 각 반복에는 다음 단계가 포함된다. 예측된 출력층 y의 계산을 포함하는 피드포워드(Feed-forward)와, 가중치와 편향을 업데이트하는 역전파 (Back-propagation)의 두 단계로 구성된 신경망 모델의 훈련 과정을 수행한다. 인공 신경 처리망은 예측 손실의 오차를 측정하기 위해 역전파가 수행하고, 예측 오차(손실)를 측정한다. 편향과 가중치에 대한 손실 함수의 미분은 가중치와 편향을 조정하기 위해 사용된다. 입력층은 데이터 처리부에 저장된 학습 데이터를 획득하고, 획득한 학습 데이터를 특징맵을 가지는 레이어로 저장한다. 여기서, 특징맵은 다수의 노드들이 2차원으로 배열된 구조를 가짐으로써 후술되는 은닉층 과의 연결을 용이하게 할 수 있다. 은닉층은 상위 계층에 위치한 레이어의 특징맵을 획득하고, 획득한 특징맵으로부터 점차 높은 수준의 특징 을 추출한다. 은닉층은 하나 또는 그 이상으로 형성될 수 있으며 컨볼루션 레이어부, 풀링 레이어부 및 풀리 커넥티드 레이어부를 포함한다. 컨볼루션 레이어부는 학습 데이터로부터 컨볼루션 연산을 수행하는 구성으로서, 복수의 입력 특징맵과 연 결되는 특징맵을 포함한다. 풀링 레이어부는 컨볼루션 레이어부의 출력을 입력으로 받아 컨볼루션 연산, 즉 서브 샘플링 연산을 수행하는 구성이고, 은닉층의 하위 계층에 위치한 컨볼루션 레이어부가 가지는 입력 특징맵의 수와 동일한 수의 특징맵을 포함하며, 각각의 특징맵은 입력 특징맵과 일대일로 연결된다. 풀리 커넥티드 레이어부는 컨볼루션 레이어부의 출력을 입력으로 받아 출력층에서 출력되는 각 카테고리별 출력에 맞게 학습하는 구성이고, 학습된 국소적 정보, 즉 특징들을 종합하여 추상적인 내용을 학습 한다. 이때, 은닉층이 풀링 레이어부를 구비할 경우, 폴링 커넥티드 레이어부는 폴링 레이어부와 연결되며, 폴링 레이어부의 출력으로부터 특징들을 종합하여 추상적인 내용을 학습한다. 출력층은 소프트 맥스(soft-max) 등의 함수를 이용하여 분류하고자 원하는 각 카테고리별 출력을 확률값으 로 매핑한다. 이때, 출력층에서 출력된 결과는 학습부 또는 분류부로 전달되어 오류역전파를 수 행하거나 응답 데이터로 출력될 수도 있다. 학습부는 지도 학습을 수행하는 것으로, 지도 학습은 학습 데이터에 기계학습 알고리즘을 적용하여 함수를 추론하고, 그 추론된 함수를 통해 해답을 찾는다. 학습부는 지도 학습을 통해서 학습 데이터를 대표하는 선형 모델을 생성하고, 그 선형 모델을 통해 미래의 사건을 예측할 수 있다. 학습부는 이전까지 학습된 데이터를 근거로 새로운 데이터가 기존에 학습된 데이터에 어떻게 분류되는지 판단한다. 학습부는 데이터 처리부로부터 데이터 세트에서 문장 벡터와 이에 대응하는 벡터화된 의미 분석 문장 으로 이루어진 훈련 세트(Train Set)를 인공 신경 처리망의 학습을 수행하고, 유형별 딥러닝 특징값을 이 용하여 의미 분석 문장에 대응하는 텍스트 데이터의 주제어 생성 여부를 학습한다. 학습부는 유형별 딥러닝 특징값을 이용하여 의미 분석 문장에 대응하는 텍스트 데이터의 주제어 생성 여부 를 인공 신경 처리망에서 학습한다.본 발명의 일실시예에서 인공 신경 처리망의 학습은 지도 학습(supervised-learning)으로 이루어진다. 지도 학습은 학습 데이터와 그에 대응하는 출력 데이터를 함께 인공 신경 처리망에 입력하고, 학습 데이터 에 대응하는 출력 데이터가 출력되도록 연결된 간선들의 가중치를 업데이트 하는 방법이다. 일예로, 본 발명의 인공 신경 처리망은 델타 규칙 및 오류역전파 학습 등을 이용하여 인공뉴런들 사이의 연결 가중치를 업데 이트 할 수 있다. 오류역전파(Error-back-propagation) 학습은 주어진 학습 데이터에 대해 전방계산(Feed-Forward)으로 오류를 추정한 후, 출력 레이어에서 시작하여 은닉층과 입력층 방향인 역방향으로 추정한 오류를 전파하고, 오류를 줄이는 방향으로 인공 뉴런들 사이의 연결 가중치를 업데이트한다. 인공 신경 처리망은 입력층 - 은닉층 - 폴링 커넥티드 레이어부 - 출력층을 통해 획 득된 결과로부터 오차를 계산하고, 계산된 오차를 보정하기 위해 다시 출력층 - 폴링 커넥티드 레이어부 - 은닉층 - 입력층의 순서로 오류를 전파하여 연결 가중치를 업데이트할 수 있다. 학습부는 문장 벡터와 이에 대응하는 벡터화된 의미 분석 문장으로 이루어진 훈련 세트(Train Set)를 입력 벡터가 되며, 입력층, 은닉층, 출력층을 통과하면, 의미 분석 문장에 대응하는 텍스트 데이터의 주제어 생성 여부를 출력 벡터로 생성하도록 지도 학습을 통해 학습된다. 학습부는 인공 신경 처리망을 이용하여 입력되는 문장 벡터와 이에 대응하는 벡터화된 의미 분석 문 장의 특징값들이 입력 벡터가 되며, 입력층, 은닉층, 출력층을 통과하면, 의미 분석 문장에 대 응하는 텍스트 데이터의 주제어 생성 결과를 출력 벡터로 생성하도록 지도 학습을 통해 학습된다. 학습부는 의미 분석 문장에 대응하는 텍스트 데이터의 주제어 생성 결과를 학습 데이터로 하여 인공 신경 처리망과 연동하여 인공지능에 학습한다. 인공 신경 처리망은 입력값(문장 벡터와 이에 대응하는 벡터화된 의미 분석 문장)이 입력되면, 출력값(의 미 분석 문장에 대응하는 텍스트 데이터의 주제어 생성 결과)이 나와야 하는지 미리 알고 있다. 분류부는 학습부에서의 오류역전파를 통해 업데이트된 연결 가중치를 가지는 인공 신경 처리망 의 출력 데이터를 응답 데이터로 출력할 수 있다. 분류부는 업데이트된 연결 가중치를 가지는 인공 신경 처리망에 학습 데이터, 테스트 데이터 또는 학 습에 사용되지 않은 새 데이터가 입력되면, 입력층 - 은닉층 - 폴링 커넥티드 레이어부 - 출력 층을 통해 출력된 결과를 획득하여 응답 데이터로 출력할 수 있다. 인공 신경 처리망은 입력된 문장 벡터와 이에 대응하는 벡터화된 의미 분석 문장에 대응하는 텍스트 데이 터의 주제어 생성 결과 여부를 기반으로 최적화를 통해 딥러닝 기반 분류기 모델을 생성한다. 학습부는 문장 벡터와 이에 대응하는 벡터화된 의미 분석 문장에 따라 인공 신경 처리망 내 레이어들 및 레이어들 간의 연결 강도에 관한 개별 요소 가중치를 다르게 적용할 수 있다. 학습부는 텍스트 데이터의 주제어 생성 결과를 출력 벡터로 생성하도록 지도 학습을 통해 학습되고, 입력 층에서 출력층으로 방향으로 계산하고, 반대로 출력층에서 입력층 방향으로 계산하는 작업 을 반복하면서 가중치를 수정하여 오차를 최소화한다. 분류부는 테스트 데이터인 입력된 문장 벡터와 이에 대응하는 벡터화된 의미 분석 문장을 인공 신경 처리 망의 딥러닝 기반 분류기 모델을 이용하여 응답 데이터의 결과값(텍스트 데이터의 주제어 생성 결과)으로 출력한다. 분류부는 벡터화된 의미 분석 문장에 대응하여 텍스트 데이터의 주제어 생성 결과의 여부를 판단한다. 분류부는 테스트 데이터인 입력된 문장 벡터와 이에 대응하는 벡터화된 의미 분석 문장을 인공 신경 처리 망의 딥러닝 기반 분류기 모델을 이용하여 텍스트 데이터의 주제어 생성 결과의 여부를 판단한다. 출력부는 분류부로부터 수신된 의미 분석 문장에 대응하는 텍스트 데이터의 주제어 생성 결과 여부를 디스플레이부에 표시한다. 주제어 데이터베이스부(133b)는 입력 문장, 의미 분석 문장과 이에 대응하는 텍스트 데이터의 하나 이상의 주제 어를 저장하고 있다.사서, 평론가 등 전문가들이 책, 논문, 잡지, 출판물과 같은 텍스트 데이터를 읽고, 주제어를 복수개 추출한다. 데이터 수집부는 전문가들이 각각의 텍스트 데이터에서 추출한 복수의 주제어를 전자 기기를 통해 수 신하여 저장한다. 제어부는 인공 신경 처리망의 응답으로 의미 분석 문장에 대응하는 텍스트 데이터의 하나 이상의 제1 주제어를 출력하면, 출력된 제1 주제어와 데이터 수집부에 저장된 전문가들이 추출한 제2 주제어를 비교, 분석한다. 제어부는 제1 주제어와 제2 주제어가 다른 경우, 다른 제2 주제어를 주제어 데이터베이스부(133b)의 텍스 트 데이터의 주제어로 추가하여 업데이트한다. 본 명세서의 실시예에 따른 동작은 컴퓨터로 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 프로그램 또는 코 드로서 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의해 읽혀질 수 있는 데이 터가 저장되는 모든 종류의 기록장치를 포함한다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어 분산 방식으로 컴퓨터로 읽을 수 있는 프로그램 또는 코드가 저장되고 실행될 수 있 다. 실시예가 소프트웨어로 구현될 때, 상술한 기법은 상술한 기능을 수행하는 모듈(과정, 기능 등)로 구현될 수 있 다. 모듈은 메모리에 저장되고, 프로세서에 의해 실행될 수 있다. 메모리는 프로세서 내부 또는 외부에 있을 수 있고, 잘 알려진 다양한 수단으로 프로세서와 연결될 수 있다. 또한, 컴퓨터가 읽을 수 있는 기록매체는 롬(rom), 램(ram), 플래시 메모리(flash memory) 등과 같이 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 프로그램 명령은 컴파일러 (compiler)에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터(interpreter) 등을 사용해서 컴퓨 터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 본 발명의 일부 측면들은 장치의 문맥에서 설명되었으나, 그것은 상응하는 방법에 따른 설명 또한 나타낼 수 있 고, 여기서 블록 또는 장치는 방법 단계 또는 방법 단계의 특징에 상응한다. 유사하게, 방법의 문맥에서 설명된 측면들은 또한 상응하는 블록 또는 아이템 또는 상응하는 장치의 특징으로 나타낼 수 있다. 방법 단계들의 몇몇 또는 전부는 예를 들어, 마이크로프로세서, 프로그램 가능한 컴퓨터 또는 전자 회로와 같은 하드웨어 장치에 의 해(또는 이용하여) 수행될 수 있다. 몇몇의 실시예에서, 가장 중요한 방법 단계들의 하나 이상은 이와 같은 장 치에 의해 수행될 수 있다. 실시예들에서, 프로그램 가능한 로직 장치(예를 들어, 필드 프로그래머블 게이트 어레이)가 여기서 설명된 방법 들의 기능의 일부 또는 전부를 수행하기 위해 사용될 수 있다. 실시예들에서, 필드 프로그래머블 게이트 어레이 는 여기서 설명된 방법들 중 하나를 수행하기 위한 마이크로프로세서와 함께 작동할 수 있다. 일반적으로, 방법 들은 어떤 하드웨어 장치에 의해 수행되는 것이 바람직하다. 상기에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특 허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2022-0108659", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 문장 의미를 분석하여 찾아주는 시맨틱 분석 제공 시스템의 구성을 나타낸 블 록도이다. 도 2는 본 발명의 실시예에 따른 시맨틱 분석 서버의 내부 구성을 나타낸 블록도이다. 도 3은 본 발명의 실시예에 따른 시맨틱 분석 서버의 학습 모델과 인공 신경 처리망의 구성을 나타낸 도면이다."}
