{"patent_id": "10-2023-0057609", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0160822", "출원번호": "10-2023-0057609", "발명의 명칭": "인공지능을 이용한 음향 사건 검출을 위한 방법 및 그 장치", "출원인": "한양대학교 산학협력단", "발명자": "장준혁"}}
{"patent_id": "10-2023-0057609", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서,음성 데이터를 수신하는 단계;상기 음성 데이터를 샘플링 레이트(rate) 및 윈도우 크기 중 적어도 하나를 기반으로 복수의 해상도를 나타내는복수의 제1 데이터들을 결정하는 단계; 및상기 복수의 제1 데이터들을 입력 정보로 하여 기 학습된 제1 인공지능 네트워크에서 제2 데이터를 출력하는 단계를 포함하고,상기 기 학습된 제1 인공지능 네트워크는 상기 복수의 제1 데이터들, 제2 인공지능 네트워크에서 출력된 제3 데이터를 기반으로 학습되는 방법."}
{"patent_id": "10-2023-0057609", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제2 데이터 및 상기 제3 데이터간의 손실을 결정하는 단계; 및상기 손실을 최소화하는 파라미터를 결정하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2023-0057609", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 음성 데이터가 레이블(label)을 포함하는 경우,상기 제1 인공지능 네트워크는 상기 레이블과 상기 제2 데이터간의 손실을 결정하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2023-0057609", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 음성 데이터가 레이블을 포함하지 않는 경우,상기 음성 데이터를 샘플링 레이트를 기반으로 복수의 해상도를 나타내는 복수의 제4 데이터들을 결정하는단계,상기 복수의 제4 데이터들을 입력으로 하여 제3 인공지능 네트워크에서 출력된 제5 데이터 및 상기 제2 데이터간의 손실을 결정하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2023-0057609", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 음성 데이터를 샘플링 레이트 및 윈도우 크기 중 적어도 하나를 기반으로 복수의 해상도를 나타내는 복수의 제1 데이터들을 결정하는 단계는:상기 샘플링 레이트 및 윈도우 크기 중 적어도 하나를 로그-가우시안 분포를 기반으로 추출하는 단계; 및,공개특허 10-2024-0160822-3-상기 추출된 샘플링 레이트 및 윈도우 크기 중 적어도 하나를 상기 음성 데이터에 적용하여 상기 복수의 제1 데이터들을 결정하는 단계를 포함하는 방법."}
{"patent_id": "10-2023-0057609", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제2 데이터를 기반으로 상기 음성 데이터에서 특정한 음성 데이터를 검출하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2023-0057609", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 제1 인공지능 네트워크는 상기 제2 인공지능 네트워크로부터 지식 증류 프로세스를 통하여 학습되고,상기 제1 인공지능 네트워크는 학생(student) 네트워크이고, 및상기 제2 인공지능 네트워크는 교사(teacher) 네트워크인 방법."}
{"patent_id": "10-2023-0057609", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "전자 장치에 있어서,메모리;모뎀; 및상기 모뎀 및 상기 메모리에 연결되는 프로세서를 포함하고,상기 프로세서는:음성 데이터를 수신하고, 상기 음성 데이터를 샘플링 레이트(rate) 및 윈도우 크기 중 적어도 하나를 기반으로복수의 해상도를 나타내는 복수의 제1 데이터들을 결정하고, 그리고상기 복수의 제1 데이터들을 입력 정보로 하여 기 학습된 제1 인공지능 네트워크에서 제2 데이터를 출력하도록구성되고,상기 기 학습된 제1 인공지능 네트워크는 상기 복수의 제1 데이터들, 제2 인공지능 네트워크에서 출력된 제3 데이터를 기반으로 학습되는 전자 장치."}
{"patent_id": "10-2023-0057609", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 프로세서는:상기 제2 데이터 및 상기 제3 데이터간의 손실을 결정하고, 및상기 손실을 최소화하는 파라미터를 결정하도록 더 구성되는 전자 장치."}
{"patent_id": "10-2023-0057609", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 상기 프로세서는:상기 음성 데이터가 레이블(label)을 포함하는 경우,상기 제1 인공지능 네트워크는 상기 레이블과 상기 제2 데이터간의 손실을 결정하도록 더 구성되는 전자 장치.공개특허 10-2024-0160822-4-청구항 11 제8항에 있어서, 상기 프로세서는:상기 음성 데이터가 레이블을 포함하지 않는 경우,상기 음성 데이터를 샘플링 레이트를 기반으로 복수의 해상도를 나타내는 복수의 제4 데이터들을 결정하고, 상기 복수의 제4 데이터들을 입력으로 하여 제3 인공지능 네트워크에서 출력된 제5 데이터 및 상기 제2 데이터 간의 손실을 결정하도록 더 구성되는 방법."}
{"patent_id": "10-2023-0057609", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서, 상기 프로세서는:상기 샘플링 레이트 및 윈도우 크기 중 적어도 하나를 로그-가우시안 분포를 기반으로 추출하고, 상기 추출된 샘플링 레이트 및 윈도우 크기 중 적어도 하나를 상기 음성 데이터에 적용하여 상기 복수의 제1 데이터들을 결정하도록 구성되는 전자 장치."}
{"patent_id": "10-2023-0057609", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서, 상기 프로세서는:상기 제2 데이터를 기반으로 상기 음성 데이터에서 특정한 음성 데이터를 검출하도록 더 구성되는 전자 장치."}
{"patent_id": "10-2023-0057609", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서,상기 제1 인공지능 네트워크는 상기 제2 인공지능 네트워크로부터 지식 증류 프로세스를 통하여 학습되고,상기 제1 인공지능 네트워크는 학생(student) 네트워크이고, 및상기 제2 인공지능 네트워크는 교사(teacher) 네트워크인 전자 장치."}
{"patent_id": "10-2023-0057609", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "프로세서(processor)에 의해 실행 가능한 인공지능 알고리즘을 통해 방향 추정 방법을 수행하기 위한 매체에 저장된 프로그램으로서,음성 데이터를 수신하는 단계;상기 음성 데이터를 샘플링 레이트 및 윈도우 크기 중 적어도 하나를 기반으로 복수의 해상도를 나타내는 복수의 제1 데이터들을 결정하는 단계; 및상기 복수의 제1 데이터들을 입력 정보로 하여 기 학습된 제1 인공지능 네트워크에서 제2 데이터를 출력하는 단계를 수행하고,상기 기 학습된 제1 인공지능 네트워크는 상기 복수의 제1 데이터들, 제2 인공지능 네트워크에서 출력된 제3 데이터를 기반으로 학습되는 프로그램."}
{"patent_id": "10-2023-0057609", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서, 음성 데이터를 수신 하는 단계; 상기 음성 데이터를 샘플링 레이트 및 윈도우 크기 중 적어도 하나를 기반으로 복수의 해상도를 나타 내는 복수의 제1 데이터들을 결정하는 단계; 및 상기 복수의 제1 데이터들을 입력 정보로 하여 기 학습된 제1 인 공지능 네트워크에서 제2 데이터를 출력하는 단계를 포함하고, 상기 기 학습된 제1 인공지능 네트워크는 상기 복 수의 제1 데이터들, 제2 인공지능 네트워크에서 출력된 제3 데이터를 기반으로 학습될 수 있다."}
{"patent_id": "10-2023-0057609", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공지능을 이용하여 음향 사건(또는 이벤트)을 검출하기 위한 방법 및 그 장치 나타낸다. 구체적으 로, 인공지능을 학습시켜 음성 사건 검출 기술을 활용하여 특정 음원이 발생한 지점을 검출하는 방법을 나타낸다."}
{"patent_id": "10-2023-0057609", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 개시는 음성 신호에 대하여 특정한 음원(또는 음향 사건)에 대하여 검출하는 장치 및 방법에 관한 것이다. 음향 사건 감지 기술은 매시간에 대하여 특정한 소리(예를 들어, 벨소리, 강아지 소리)를 감지하기 위한 기술이 다. 특히, 실생활에서 발생하는 다양한 소리들 중에서 사용자의 선택에 따라 특정한 소리만을 감지하여 활용할 수 있다는 장점이 있다. 인공지능을 이용한 음향 사건 검출 기술에서는 일반적인 음향 데이터에 대하여 전처리 를 수행하고, 전처리된 음향 데이터에서 음향 사건들 각각의 특징을 추출하고, 해당 특징들을 알고리즘 모델에 학습시키는 방식으로 수행된다. 다만, 인공지능 기반의 음향 사건 검출 기술에서 시스템을 구축하기 위해서는 매시간마다 정답이 라벨링 (labelling) 되어있는 음향 데이터가 요구된다. 학습에 사용되는 음향 데이터 라벨링을 수행하기 위하여는 학습 을 시키는 사람이 직접 음향 각각에 대하여 라벨링을 해야하는데 소요되는 시간 및 비용이 크다는 단점이 있다. 따라서, 라벨링 정보가 없는 상황 또는 부족한 상황에서도 효과적으로 데이터를 학습할 수 있는 방법이 요구되 고 있다. 특히, 음향 사건 검출 기술에서는 반지도학습 방식이 주도적으로 사용되었다. 반지도학습(semi-supervised learning) 방식은 이미지 데이터에서 주로 사용되는 학습 방식으로 mean teacher, FixMatch 방식 등이 사용되고 있다. 반지도학습은 데이터 증강기법을 기반으로 제안된 것으로 이미지에 약간의 변형 또는 교란을 주더라도 신 경망의 학습 결과 값이 원본 이미지의 결과 값과 동일하게 나오도록 학습하는 방식을 사용한다. 다만, 이미지 데이터의 경우 x, y축이 각각 위치로 정의되는 반면에 오디오 스펙트로그램에서는 x, y축이 각각 시간 및 주파 수로 정의된다. 이러한 차이점으로 인하여 문제점이 발생하는데 x축과 y축의 의미가 다르다는 것, 데이터의 시 간 축에 대하여 교란을 발생시켰을 때 이에 대응하는 정답 값이 바뀐다는 점이다. 즉, 이미지 데이터에서 사용 하는 학습 방식을 오디오 데이터에 적용할 때, 시간 영역에서 교란을 발생시키는 경우 정답 값이 바뀔 수 있기 때문에 일관성을 유지하도록 하는 방법이 필요하다. 따라서, 반지도학습 방식에서 데이터 증강 기법을 활용한 일관성 학습법을 사용할 수 있으며, 이하에서는 해상도를 기반으로 일관성 학습법을 사용하는 방법에 대하여 제 안한다."}
{"patent_id": "10-2023-0057609", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에서는 데이터 전처리 방식을 통해 다양한 해상도를 도출하여 음향 사건 검출 기능을 향상시키는 방법 및 그 장치를 제공하고자 한다. 본 개시에서는 라벨링되지 않은 데이터에 대하여 증강 정도를 다르게 설정하여음향 사건 검출 기능을 향상시키 는 방법을 제공하고자 한다."}
{"patent_id": "10-2023-0057609", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서, 음성 데이터를 수신 하는 단계; 상기 음성 데이터를 샘플링 레이트 및 윈도우 크기 중 적어도 하나를 기반으로 복수의 해상도를 나 타내는 복수의 제1 데이터들을 결정하는 단계; 및 상기 복수의 제1 데이터들을 입력 정보로 하여 기 학습된 제1 인공지능 네트워크에서 제2 데이터를 출력하는 단계를 포함하고, 상기 기 학습된 제1 인공지능 네트워크는 상기 복수의 제1 데이터들, 제2 인공지능 네트워크에서 출력된 제3 데이터를 기반으로 학습될 수 있다. 일 실시예에서, 상기 제2 데이터 및 상기 제3 데이터간의 손실을 결정하는 단계; 및 상기 손실을 최소화하는 파 라미터를 결정하는 단계를 더 포함할 수 있다. 일 실시예에서, 상기 음성 데이터가 레이블(label)을 포함하는 경우, 상기 제1 인공지능 네트워크는 상기 레이 블과 상기 제2 데이터간의 손실을 결정하는 단계를 더 포함할 수 있다. 일 실시예에서, 상기 음성 데이터가 레이블을 포함하지 않는 경우, 상기 음성 데이터를 샘플링 레이트를 기반으 로 복수의 해상도를 나타내는 복수의 제4 데이터들을 결정하는 단계, 상기 복수의 제4 데이터들을 입력으로 하 여 제3 인공지능 네트워크에서 출력된 제5 데이터 및 상기 제2 데이터 간의 손실을 결정하는 단계를 더 포함할 수 있다. 일 실시예에서, 상기 음성 데이터를 샘플링 레이트 및 윈도우 크기 중 적어도 하나를 기반으로 복수의 해상도를 나타내는 복수의 제1 데이터들을 결정하는 단계는: 상기 샘플링 레이트 및 윈도우 크기 중 적어도 하나를 로그- 가우시안 분포를 기반으로 추출하는 단계; 및, 상기 추출된 샘플링 레이트 및 윈도우 크기 중 적어도 하나를 상 기 음성 데이터에 적용하여 상기 복수의 제1 데이터들을 결정하는 단계를 포함할 수 있다. 일 실시예에서, 상기 제2 데이터를 기반으로 상기 음성 데이터에서 특정한 음성 데이터를 검출하는 단계를 더 포함할 수 있다. 일 실시예에서, 상기 제1 인공지능 네트워크는 상기 제2 인공지능 네트워크로부터 지식 증류 프로세스를 통하여 학습되고, 상기 제1 인공지능 네트워크는 학생(student) 네트워크이고, 및 상기 제2 인공지능 네트워크는 교사 (teacher) 네트워크일 수 있다. 본 발명의 실시 예에 따른 전자 장치에 있어서, 메모리; 모뎀; 및 상기 모뎀 및 상기 메모리에 연결되는 프로세 서를 포함하고, 상기 프로세서는: 음성 데이터를 수신하고, 상기 음성 데이터를 샘플링 레이트 및 윈도우 크기 중 적어도 하나를 기반으로 복수의 해상도를 나타내는 복수의 제1 데이터들을 결정하고, 그리고 상기 복수의 제 1 데이터들을 입력 정보로 하여 기 학습된 제1 인공지능 네트워크에서 제2 데이터를 출력하도록 구성되고, 상기 기 학습된 제1 인공지능 네트워크는 상기 복수의 제1 데이터들, 제2 인공지능 네트워크에서 출력된 제3 데이터 를 기반으로 학습될 수 있다. 본 발명의 실시 예에 따른 프로세서(processor)에 의해 실행 가능한 인공지능 알고리즘을 통해 방향 추정 방법 을 수행하기 위한 매체에 저장된 프로그램으로서, 음성 데이터를 수신하는 단계; 상기 음성 데이터를 샘플링 레 이트 및 윈도우 크기 중 적어도 하나를 기반으로 복수의 해상도를 나타내는 복수의 제1 데이터들을 결정하는 단 계; 및 상기 복수의 제1 데이터들을 입력 정보로 하여 기 학습된 제1 인공지능 네트워크에서 제2 데이터를 출력 하는 단계를 수행하고, 상기 기 학습된 제1 인공지능 네트워크는 상기 복수의 제1 데이터들, 제2 인공지능 네트 워크에서 출력된 제3 데이터를 기반으로 학습될 수 있다."}
{"patent_id": "10-2023-0057609", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, 데이터 전처리 방식을 통해 다양한 해상도를 도출하여 과적합 문제를 완화하고 음향 사건 검출 기능을 향상시킬 수 있다."}
{"patent_id": "10-2023-0057609", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 기술적 사상은 다양한 변경을 가할 수 있고 여러 가지 실시 예를 가질 수 있는 바, 특정 실시 예들을 도면에 예시하고 이를 상세한 설명을 통해 상세히 설명하고자 한다. 그러나, 이는 본 발명의 기술적 사상을 특 정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 기술적 사상의 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 발명의 기술적 사상을 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 본 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제1, 제2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별기호에 불과하다. 또한, 본 명세서에서, 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것이다. 또한, 본 명세서에 기재된 \"~부\", \"~기\", \"~자\", \"~모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 프로세서(Processor), 마이크로 프로세서(Micro Processer), 마이크로 컨트롤러(Micro Controller), CPU(Central Processing Unit), GPU(Graphics Processing Unit), APU(Accelerate Processor Unit), DSP(Drive Signal Processor), ASIC(Application Specific Integrated Circuit), FPGA(Field Programmable Gate Array) 등과 같은 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있으며, 적어도 하나의 기능이나 동작의 처리에 필요한 데이터를 저장하는 메모리(memory)와 결합되는 형태 로 구현될 수도 있다. 그리고 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기능 별로 구분한 것에 불과함을 명확 히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이하에서 설명할 구성부 각각은 자 신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전부의 기능을 추가적으로 수행할 수도 있으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의해 전담되어 수행될 수도 있음은 물론이다. 본 개시의 실시예들을 설명함에 있어서 관련된 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필 요하게 흐릴 수 있다고 판단된 경우 그 상세한 설명은 생략한다. 그리고 후술되는 용어들은 본 개시에서의 기능 을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 마찬가지 이유로 첨부 도면에 있어서 일부 구성요소는 과장되거나 생략되거나 개략적으로 도시될 수 있다. 또한, 각 구성요소의 크기는 실제 크기를 전적으로 반영하는 것이 아니다. 각 도면에서 동일한 또는 대응하는 구성요소에는 동일한 참조 번호를 부여하였다. 본 개시의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 실시예들은 본 개시의 설명이 완전하도록 하고, 본 개시의 실시예"}
{"patent_id": "10-2023-0057609", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "들이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 개시의 청구하고자 하는 범위는 청구항의 범주에 의해 정의될 뿐이다. 이때, 처리 흐름도를 보이는 도면들의 각 블록과 처리 흐름도 도면들의 조합들은 컴퓨터 프로그램 인스트럭션들 에 의해 수행될 수 있음을 이해할 수 있을 것이다. 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서를 통해 수행되는 그 인스트럭션들이 흐름도 블록(들)에서 설 명된 기능들을 수행하는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구 현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능하므로, 그 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저장된 인스트럭션들은 흐름도 블록(들)에서 설명된 기능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생 산하는 것도 가능하다. 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장 비 상에 탑재되는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에서 일련의 동 작 단계들이 수행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능한 데이터 프로 세싱 장비를 수행하는 인스트럭션들은 흐름도 블록(들)에서 설명된 기능들을 실행하기 위한 단계들을 제공하는 것도 가능하다. 또한, 각 블록은 특정된 논리적 기능(들)을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또, 몇 가지 대체 실행 예들에서는 블록들에서 언급된 기 능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들 은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들이 때때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다. 본 개시에서 사용되는 '~부(unit or part)'라는 용어는 소프트웨어 또는 FPGA(field-Programmable Gate Array) 또는 ASIC(Application Specific Integrated Circuit)과 같은 하드웨어 구성요소를 의미하며, '~부'는 특정한 역할들을 수행하도록 구성될 수 있다. 그렇지만 '~부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '~부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 실행시키 도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브 루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들, 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수 의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구 성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 CPU들을 재생시키도록 구 현될 수도 있다. 또한 실시예에서 '~부'는 하나 이상의 프로세서 및/또는 장치를 포함할 수 있다. 이하, 본 발명의 기술적 사상에 따른 실시 예들을 차례로 상세히 설명한다. 도 1은 본 개시의 일 실시 예에 따른 인공지능 구조의 기본적인 원리를 나타낸 개념도이다. 도 1을 참조하면, 인공지능 구조에서 학습이 수행되는 기본적인 원리를 나타낸다. 인공지능 기술은 학습, 문제 해결, 인식 등과 같이 주로 인간 지능과 연결된 인지 문제를 해결하기 위한 기술을 나타낸다. 인공지능은 Machine learning(ML)이라고 불리는 기계 학습 방식과 Deep learning(DL)이라고 불리는 딥 러닝 방식을 통해 학습될 수 있다. 머신 러닝은 패턴 인식 및 학습에 사용되는 기법에 주로 사용되며 기록된 데이터를 학습하여 이를 기반으로 이후의 데이터를 예측하는 알고리즘을 나타낸다. 사전에 정의된 규칙이나 패 턴을 기반으로 하지 않고 데이터로부터 스스로 학습하는 기술을 나타낸다. 반면에 딥 러닝은 머신 러닝의 한 분 야로 인공 신경망(Artificial Neural Network: ANN)을 기반으로 하여 데이터를 처리하는 차이점이 있다. 딥 러 닝은 인공 신경망을 이용하기 때문에 머신 러닝보다 더욱 복잡하고 정교한 연산을 처리할 수 있다. 딥 러닝을 위한 알고리즘 종류로는 합성곱 신경망(Convolution neural network: CNN), DNN(deep neural network), 인공 신경망(ANN), 순환 신경망(Recurrent Neural Network: RNN)등을 포함할 수 있다. 도 1을 참고하면, 인공지능 구조는 인공지능 모듈로 나타낼 수 있다. 인공지능 모듈은 소정의 입력 데이터를 수신하여 모듈에서 미리 정해진 방식을 통해 학습을 수행하고, 학습 결과에 대한 출력 데이터 를 출력하게 된다. 일 실시예에 따르면, 입력 데이터에는 소정의 데이터(ex 그림, 소리 등), 음성 신 호, 입력 시퀀스를 포함할 수 있다. 출력 데이터에는 출력 시퀀스, 향상된 음성 신호, 음성 사건 정보(예 를 들어, 특정한 음성) 등이 포함될 수 있다. 도 2는 본 개시의 일 실시예에 따른 인공지능 네트워크의 구조를 나타낸 도면이다. 도 2에서 사용되는 인공지능 알고리즘은 도 1의 인공지능 모듈의 종류 중 하나일 수 있다. 도 2는 입력되 는 음성 데이터가 레이블(label)을 포함하는 경우의 인공지능 알고리즘을 나타내는 도면일 수 있다. 도 2를 참조하면, 인공지능 시스템의 구조는 음성 데이터와 인공지능 알고리즘 구조를 포함할 수 있다. 일 실시예에 따르면, 음성 데이터는 레이블을 포함하는 음성 데이터 또는 레이블을 포함하지 않는 음성 데이터 를 지칭할 수 있다. 일 실시예에 따르면, 인공지능 알고리즘 구조는 데이터 전처리, 인공지능 학습, 출력 데이터 확인으로 단계가 나눠어질 수 있다. 본 개시에서의 데이터 전처리는 데이터 증강(augment)기법을 사용할 수 있다. 데이터 증강 기법은 오디오 신호의 샘플링 레이트(rate)와 단시간 푸리에 변환의 조작 변수인 윈도우(window) 크기를 다르게 함으로써 데이터를 증강하는 방법이다. 데이터 증강 기법은 강한 증강 기법(strong augment), 약한 증강 기법 (weak augment)을 포함할 수 있다. 강한 증강 기법은 샘플링 레이트와 윈도우 크기를 로그-가우시안 분포에서 랜덤하게 추출하여 적용할 수 있다. 예를 들어, 로그-가우시안 분포의 평균은 기준 스펙트로그램(즉, 증강하지 않은 스펙트로그램)의 샘플링 레이트와 윈도우 크기값이 되며, 표준편차는 1.25로 설정할 수 있다. 로그-가우시 안 분포에서 랜덤하게 추출되는 값은 왜곡이 너무 심하게 적용되지 않도록 1/2배, 2배로 제한하여 사용할 수 있 다. 약한 증강 기법은 윈도우 크기는 기준 스펙트로그램과 동일하게 사용하되 샘플링 레이트만 강한 증강 기법 과 동일한 방식으로 추출하여 사용하는 방식을 의미한다. 예를 들어, 기준 스펙트로그램에서는 샘플링 레이트로 16kHz를 사용하고, 윈도우 크기는 128ms를 사용한다. 여기서, 스펙트로그램은 오디오 신호를 분석하는 데 사용되는 것으로 주파수 성분을 시각적으로 나타낸 2차원 그래프이다. 특히, 로그-멜 스펙트로그램은 시간-주파수 영역에서 스펙트로그램을 멜 스케일로 변환하여 로그처 리한 것이다. 도 2의 인공지능 시스템은 학생(student) 네트워크와 매 학습 단계마다 갱신되는 학생 네트워크 파라미터 의 지수 이동 평균(Exponential Moving Average: EMA)으로 이루어진 교사(teacher) 네트워크로 구성될 수 있다. 여기서 사용되는 기법은 지식 증류(knowledge Distillation) 기법으로, 딥러닝에서 일반적으로 크고 복잡 한 모델인 교사 네트워크가 작고 단순한 모델인 학생 네트워크로 정보를 전달하는 형식이다. 지식 증류의 목표 는 학생 모델에서 교사 네트워크의 성능을 최대한으로 유지하되 모델의 크기와 계산 복잡성을 낮추기 위한 것이다. 지식 증류 기법에서는 교사 네트워크를 먼저 학습하고, 교사 네트워크에서의 결과 데이터를 기반으로 학생 네트워크를 학습하여 그 성능을 비교한다. 도 2를 참조하면, 레이블을 포함하는 음성 데이터에는 강한 증강 기법이 적용될 수 있다. 강한 증강 기법에 따라서 샘플링 레이트 및 윈도우 크기 중 적어도 하나를 변경하여 다양한 해상도를 가지는 데이터 들을 추출할 수 있다. 강한 증강 기법을 기반으로 증강된 데이터는 학생 네트워크와 교사 네트워크로 각각 입력정보로 활용되고, 학생 네트워크에 따른 결과 데이터와 교사 네트워크에 따른 결과 데이터 간에 일관성 손실 (consistency loss) 을 계산할 수 있다. 계산된 일관성 손실은 다시 학생 네트워크를 최적화하 는데 사용될 수 있다. 일관성 손실은 평균 제곱 오차로 계산될 수 있다. 또한, 레이블을 포함하는 음성 데이터에서 레이블과 학생 네트워크에서 획득한 결과 데이 터간에 지도학습 기반의 손실(supervised loss)를 계산할 수 있다. 계산된 supervised loss도 일관 성 손실과 함께 학생 네트워크를 최적화하는데 사용될 수 있다. Supervised loss는 이진 교차 엔트로 피로 계산될 수 있다. 본 개시의 실시예에 따라, 학생 네트워크는 가벼운 모델로 교사 네트워크와 유사한 성능을 가지는 인 공지능 네트워크로 학습될 수 있다. 본 개시에 따른 인공지능 알고리즘을 통해 음성 데이터에서 특정한 음성 데 이터(또는 음성 사건(event))를 검출할 수 있다. 도 3은 본 개시의 다른 실시예에 따른 인공지능 네트워크의 구조를 나타낸 도면이다. 도 3에서 사용되는 인공지능 알고리즘은 도 1의 인공지능 모듈의 종류 중 하나일 수 있다. 도 3은 입력되 는 음성 데이터가 레이블(label)을 포함하지 않는 경우의 인공지능 알고리즘을 나타내는 도면일 수 있다. 도 3을 참조하면, 인공지능 시스템의 구조는 음성 데이터와 인공지능 알고리즘 구조를 포함할 수 있다. 일 실시예에 따르면, 음성 데이터는 레이블을 포함하는 음성 데이터 또는 레이블을 포함하지 않는 음성 데이터 를 지칭할 수 있다. 도 3의 인공지능 시스템은 학생(student) 네트워크와 매 학습 단계마다 갱신되는 학생 네트워크 파라미터 의 지수 이동 평균(Exponential Moving Average: EMA)으로 이루어진 교사(teacher) 네트워크로 구성될 수 있다. 도 3을 참조하면, 레이블을 포함하지 않는 음성 데이터에는 강한 증강 기법이 적용될 수 있다. 강한 증강 기법을 기반으로 증강된 데이터는 학생 네트워크와 교사 네트워크로 각각 입력정보로 활용되고, 학생 네트워크에 따른 결과 데이터와 교사 네트워크에 따른 결과 데이터 간에 일관성 손실 (consistency loss) 을 계산할 수 있다. 계산된 일관성 손실은 다시 학생 네트워크를 최적화하 는데 사용될 수 있다. 또한, 레이블을 포함하지 않은 음성 데이터에서 학생 네트워크 값을 이용하여 레이블과 같은 역할을 수행할 수 있다. 학생 네트워크에서의 값을 결정하여 fixed 학생 네트워크를 설정하고, 음성 데이터 에 약한 증강 기법을 통해 증강시킨 데이터를 입력정보로 하여 출력 데이터를 추출할 수 있다. 약한 증강 기법에 따라서 윈도우 크기는 고정하고 샘플링 레이트를 변경하여 다양한 해상도를 가지는 데이터들을 추 출할 수 있다. 여기서, fixed 네트워크의 의미는 입력된 증강 데이터에 대하여 기울기를 계산하지 않는 방식의 네트워크를 나타낸다. Fixed 학생 네트워크의 출력 데이터와 학생 네트워크에서 획득한 결과 데이터간에 지도학습 기반의 손실(supervised loss)을 계산할 수 있다. 계산된 supervised loss도 일관성 손실과 함께 학생 네트워크를 최적화하는데 사용될 수 있다. 본 개시의 실시예에 따라, 학생 네트워크는 가벼운 모델로 교사 네트워크와 유사한 성능을 가지는 인 공지능 네트워크로 학습될 수 있다. 도 4는 본 개시의 일 실시예에 따른 데이터 증강 방식에 따라 생성된 스펙트로그램을 나타낸 것이다. 도 4는 도 2 및 도 3의 데이터 증강 방식에 따라 증강된 데이터의 일 예를 나타낸 것일 수 있다. 도 4를 참조하면, 윈도우 크기가 같을 때 샘플링 레이트를 변경하여 로그-멜 스펙트로그램의 해상도를 조정한 경우, 샘플링 레이트를 고정하고 윈도우 크기만을 변경하여 로그-멜 스펙트로그램의 해상도를 조정한 경우 를 나타낸다. 윈도우 크기가 같을 때 샘플링 레이트를 변경하여 로그-멜 스펙트로그램의 해상도를 조정한 경우에 윈도우 크기는 64ms로 고정한 뒤, 기준 로그-멜 스펙트로그램(410b)을 16kHz로 설정하여 다운샘플링(410a) 및 업샘플링 (410c)을 진행한 것이다. 샘플링 레이트에 따라 최대 주파수 제한에 차이가 있음을 확인할 수 있다. 샘플링 레이트를 고정하고 윈도우 크기만을 변경하여 로그-멜 스펙트로그램의 해상도를 조정한 경우에 샘 플링 레이트는 16kHz로 고정한 뒤, 기준 로그-멜 스펙트로그램(420b)을 64ms로 설정하여 다운샘플링(420a) 및 업샘플링(420c)을 진행한 것이다. 윈도우 크기에 따라 주파수 해상도 또는 시간 해상도에 차이가 발생하였다. 도 5는 본 개시의 일 실시예에 따른 윈도우 크기에 따른 스펙트럼 분석을 나타낸 것이다. 도 5를 참조하면, 본 개시의 일 실시예에 따라 데이터에 대하여 윈도우 크기를 다르게 하여 증강시켰을 때, 출 력된 스펙트럼에 대한 분석을 나타낸 것이다. 기준 케이스를 중심으로 윈도우 크기의 변동폭을 줄인 경우 , 윈도우 크기의 변동 폭을 늘린 경우의 스펙트럼 결과를 나타낸 것이다. 윈도우 사이즈에 r값을 나 눈 경우 및 곱한 경우에 대하여 어떤 지점에서 스펙트럼들간의 차이가 심해지는지를 통하여 소리 발생 지점 (onset)이 어디인지를 확인할 수 있다. 윈도우 크기의 변동폭을 줄인 경우는 r값을 1.25로 설정한 결과 하 나의 프레임에서 스펙트럼들간의 차이가 심해져 해당 부분에서 소리가 발생한 것으로 인식할 수 있다. 기준 케 이스의 경우 r값을 1.5로 설정하였으며, 두개의 프레임에서 차이가 심해져 두 개의 프레임 동안 소리가 발 생한 것을 인식할 수 있다. 윈도우 크기의 변동 폭을 늘린 경우엔 r값을 2로 설정하여 차이가 심해지는 프 레임이 3개의 프레임으로 나타나고, 소리가 언제 발생했는지 3개의 프레임동안 확인할 수 있다. 결과를 볼 때 본 개시의 실시예를 통하여 음원의 발생 지점(onset)과 끝 지점(offset)을 정확히 감지할 수 있다. 음원이 발생하는 지점에서 스펙트럼들간의 패턴이 다른 패턴을 나타내고, 음원이 발생하는 지점 외의 구 간에서는 유사한 패턴을 보인다. 즉, 데이터 증강 기법에 따라 음원의 발생 지점과 끝 지점에서 교란을 일으켜 onset과 offset을 검출하는데 효과가 있음을 확인할 수 있다.도 6은 본 개시의 일 실시예에 따른 데이터 증강에 사용가능한 확률분포를 나타낸 것이다. 도 6을 참조하면, 샘플링 레이트 및 윈도우 크기를 추출하기 위하여 다양한 확률분포가 사용될 수 있다. 확률분 포의 종류로는 로그-유니폼 분포, 로그-가우시안 분포, 로그-베타 분포가 있다. 로그-유니폼 분 포는 샘플링 레이트 및 윈도우 크기의 변화와 상관없이 동일한 확률을 가지는 것을 나타내고, 로그-가우시 안 분포는 기준 스펙트로그램인 16kHz, 128ms인 경우 가장 높은 확률을 가지고 끝으로 갈수록 점점 확률이 낮아지는 경향을 가진다. 로그-베타 분포는 로그-가우시안 분포와 반대로 기준 스펙트로그램인 16kHz, 128ms인 경우 가장 낮은 확률을 가지고 끝으로 갈수록 점점 확률이 높아지는 경향을 가진다. 도 7은 본 발명의 일 실시예에 따른 인공 신경망의 구조를 나타낸 도면이다. 도 7의 인공 신경망의 구조는 도 2 내지 도 5의 학생 네트워크, 교사 네트워크의 구조와 동일한 것일 수 있다. 도 7을 참고하면, 본 개시에서의 일 실시예에 따른 데이터 증강 기법을 사용하여 증강된 데이터는 CNN으로 입력될 수 있다. 예를 들어, CNN은 ResNet으로 block 수 = {3, 3, 3, 1}, 스택 = {2, 2, 2, 2}, CNN 채널 = {8, 16, 32, 64}), BCResNet (초기 채널 수 = 50), FUSE (초기 채널 수 = 32, block 수 = 3)일 수 있다. CNN은 EfficientNetv2로 대체하여 사용될 수 있다. CNN에서 출력된 데이터는 RNN으로 입력될 수 있다. 예를 들어, RNN은 one-sided gated recurrent units (GRU, layer 수 = 2, hidden size = 10)일 수 있다. 도 8은 본 개시의 다양한 실시예들에 따른, 알고리즘의 종류에 따른 검증 손실을 나타낸 도면이다. 도 8에서는 총 6가지의 인공지능 알고리즘 방식을 사용하여 에포크(epoch)의 시행수에 따른 검증 손실의 변화를 나타낸다. 도 8에서 x축은 에포크의 시행횟수를 나타내고, y축은 검증 손실(loss)을 나타낸다. 도 8을 참조하면, 반지도학습에서 자주 사용되는 FixMatch 방식 및 Unsupervised Data Augmentation(UDA)가 에포크의 증가에 따라 손실이 꾸준히 감소하는 추세를 보이는 것이 아닌 50횟수까지 는 감소하다가 다시 점차 증가하는 양상을 보이는 것을 확인할 수 있다. 다음으로, ICT 및 SCT은 손실의 상승세가 FixMatch나 UDA보다는 작게 상승하나 여전히 에 포크의 증가에 따라 감소하다가 다시 상승하는 양상을 보이는 것을 확인할 수 있다. 다음으로는, 반지도학습 방식 중 하나인 MT는 일정 에포크까지 손실이 감소한 뒤, 상대적으로 상승이 적게 유지되고 있음을 확인할 수 있다. 마지막으로, 본 개시에서 제안하는 방식 중 하나인 RCT(Resolution Consistency Training) 방식의 경우, 에포크가 증가함에 따라 일정 구간까지 손실이 꾸준히 감소한 뒤, 다시 상승하지 않고, 손실이 유지되고 있음을 확인할 수 있어, 손실의 폭이 매우 작은 양상을 보인다. 따라서, FixMatch에서 RCT 방식으로 갈수록 학습이 가장 잘되고, 성능이 상대적으로 뛰어남을 확인할 수 있다. 도 9는 본 개시의 일 실시예에 따른, 데이터 셋의 구조를 나타낸 표이다. 도 10은 본 개시의 다양한 실시예에 따른 다양한 알고리즘 방식에 따른 성능을 나타낸 표이다. 도 9는 본 개시의 일 실시예에 따른 모델들의 학습 및 실험에 사용된 데이터 셋에 대한 것이다. 모델 구축에 사 용된 데이터 셋은 음향 사건 검출 실험에서 자주 사용되는 DESED 데이터 베이스를 사용한 것이다. DESED 데이터 베이스는 10초 길이의 오디오 클립으로 이루어지며, 44.1kHz 또는 16kHz로 이루어질 수 있다. 도 9를 참조하면, 오디오 데이터는 3가지 유형으로 구분될 수 있다. 매시간 단위로 레이블이 존재하는 데이터 (frame-level 또는 strongly labeled data), 클립 단위로 레이블이 존재하는 데이터(clip-level 또는 weaky labeled data), 그리고 레이블이 존재하지 않는 데이터(unlabeled)로 이루어져 있다. 또한, 실제 녹음된 데이터와 음원을 배경음에 합성한 데이터로 이루어져 있을 수 있다.도 9를 참조하면, frame-level데이터는 실제 녹음된 소리로 train 영역 3,470개 Eval. 영역 1,168개가 있 고 이론상의 소리로 10,000개가 포함될 수 있다. Clip-level의 경우 실제 녹음된 소리로 train 영역에서 1,578개가 포함될 수 있다. Unlabeled는 실제 녹음된 소리로 train 영역에서 14,412개가 포함될 수 있다. 도 10은 본 개시의 다양한 실시예에 따라 음성 사건 검출의 성능을 확인하기 위한 실험에 대한 결과값을 나타낼 수 있다. 도 8에서 나타냈던 6가지 알고리즘 방식에 대하여 성능 평가 방식으로 event-f1방식, intersection- f1 방식, PSDS1 방식, PSDS2 방식을 각각 평가한 것이다. 여기서 event-f1 방식과 PSDS1 방식은 onset과 offset을 검출하는 성능을 테스트하는데 주로 사용되며, intersection-f1 및 PSDS2 방식은 사운드의 유, 무를 검출하는 성능을 테스트하는데 주로 사용된다. 도 10을 참조하면, MT는 PSDS2에서 가장 뛰어난 성능을 보였으나, EVENT-F1이나 PSDS1에서는 효과적이지 않은 것을 확인할 수 있다. PSDS2를 제외한 모든 방식의 테스트에서 RCT 방식이 가장 효과적인 성능을 보이는 것을 확인할 수 있다. 특히 onset 및 offset을 검출하는 음성 사건 검출 성능을 나타내는 지표인 event-f1과 PSDS1에서 다른 알고리즘 방식보다 월등한 성능을 나타냄을 확인할 수 있다. 도 11은 본 개시의 일 실시예에 따른, 음성 사건 검출을 위한 전자 장치에 대한 블록 구성도이다. 도 11을 참조하면, 전자 장치는 모뎀(MODEM, 1120), 메모리(MEMORY, 1140) 및 프로세서(PROCESSOR, 1130)를 포함할 수 있다. 모뎀은 다른 전자 장치들과 전기적으로 연결되어 상호 통신이 이뤄지도록 하는 통신 모뎀일 수 있다. 특 히 모뎀은 데이터 입력을 수신하여 프로세서로 전송할 수 있고, 프로세서는 입력된 데이터 값 을 메모리에 저장할 수 있다. 또한, 시스템에서 학습된 인공지능 알고리즘에 의해 출력된 데이터 값을 다 른 전자 장치로 전송할 수 있다. 메모리는 전자 장치의 동작을 위한 각종 정보 및 프로그램 명령어들이 저장되는 구성으로서, 하드 디스크(Hard Disk), SSD(Solid State Drive) 등과 같은 기억장치일 수 있다. 특히, 메모리는 프로세서 의 제어에 의해 모뎀에서 입력되는 하나 이상의 데이터 입력 값을 저장할 수 있다. 또한, 메모리 는 프로세서에 의해 실행 가능한 방향 추정을 위한 인공지능 알고리즘과 같은 프로그램 명령어들을 저장할 수 있다. 또한, 메모리는 본 개시에서 설명한 커리큘럼 학습 방식, 딥 슈퍼비젼 방식, deeply supervised curriculum learning을 통해 학습된 인공지능 알고리즘과 같은 프로그램 (또는 프로그램 명령어)를 저장할 수 있다. 프로세서는 적어도 하나의 프로세서로 구성되며, 메모리에 저장된 데이터 및 프로그램 명령어들을 이용하여 음성 사건 검출과 관련된 인공지능 알고리즘을 학습하고 이를 활용하여 데이터를 계산할 수 있다. 프 로세서는 도 1 내지 도 7에서 설명한 모든 인공지능 알고리즘을 제어하고 계산할 수 있다. 프로세서 는 이후 도 12에서 설명하는 방법에 대한 동작을 수행할 수 있다. 도 12는 본 발명의 일 실시예에 따른 음성 사건 검출 방법을 설명하기 위한 순서도이다. 이하 도 12을 참조하여, 도 1 내지 도 11을 참조하여 설명한 전자 장치의 인공지능 알고리즘의 학습 동작 및 음 성 사건 검출 방법에 대해 정리하여 설명한다. 각 동작들은 일련의 과정에서 필수적으로 포함되어야 하는 동작 들은 아니며 상황에 따라 일부만이 구성되어 동작할 수 있다. 단계 S1210에서, 인공지능을 통한 음성 사건을 추정하기 위하여 음성 데이터를 수신할 수 있다. 음성 데이터는 입력 정보로 활용되어 인공지능을 학습시키는데 사용될 수 있다. 음성데이터는 인공지능 학습에서 정답이라고 해석될 수 있는 레이블을 포함할 수 있다. 레이블을 포함하는 경우와 레이블을 포함하지 않는 경우 각각 다른 방식으로 인공지능이 학습될 수 있다. 단계 S1220에서, 수신된 음성 데이터를 샘플링 레이트 및 윈도우 크기 중 적어도 하나를 기반으로 복수의 해상 도를 나타내는 복수의 제1 데이터들을 결정할 수 있다. 데이터 증강 기법 중 강한 증강 기법이 적용되는 경우 샘플링 레이트 및 윈도우 크기 모두 변경하여 데이터를 증강할 수 있으며, 약한 증강 기법이 적용되는 경우 샘플링 레이트 및 윈도우 크기 중 적어도 하나를 기반으로 데이터 증강을 수행할 수 있다. 샘플링 레이트 및 윈도 우 크기는 로그-가우시안 분포를 기반으로 추출될 수 있다. 단계 S1230에서, 복수의 제1 데이터들을 입력 정보로 하여 기 학습된 제1 인공지능 네트워크에서 제2 데이터를 출력할 수 있다. 제2 데이터는 onset 및 offset에 대한 정보를 포함할 수 있다. 상기 제2 데이터를 기반으로 수 신된 음성 데이터에서 특정한 음성 데이터를 검출해 낼 수 있다. 단계 S1240에서, 기 학습된 제1 인공지능 네트워크는 상기 복수의 제1 데이터들, 제2 인공지능 네트워크에서 출 력된 제3 데이터를 기반으로 학습할 수 있다. 제1 인공지능 네트워크는 상기 방식으로만 학습되는 것은 아니며, 도 2 내지 도 3에서 설명한 다양한 방식을 통해 학습될 수 있음은 당연하다. 여기서 제1 인공지능 네트워크는 지식 증류 기법에서 사용되는 학생 네트워크이고, 제2 인공지능 네트워크는 교사 네트워크일 수 있다. 이상, 본 발명의 기술적 사상을 다양한 실시 예들을 들어 상세하게 설명하였으나, 본 발명의 기술적 사상은 상 기 실시 예들에 한정되지 않고, 본 발명의 기술적 사상의 범위 내에서 당 분야에서 통상의 지식을 가진 자에 의 하여 여러가지 변형 및 변경이 가능하다."}
{"patent_id": "10-2023-0057609", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 상세한 설명에서 인용되는 도면을 보다 충분히 이해하기 위하여 각 도면의 간단한 설명이 제공된다. 도 1은 본 개시의 일 실시 예에 따른 인공지능 구조의 기본적인 원리를 나타낸 개념도이다. 도 2는 본 개시의 일 실시예에 따른 인공지능 네트워크의 구조를 나타낸 도면이다. 도 3은 본 개시의 다른 실시예에 따른 인공지능 네트워크의 구조를 나타낸 도면이다. 도 4는 본 개시의 일 실시예에 따른 데이터 증강 방식에 따라 생성된 스펙트로그램을 나타낸 것이다. 도 5는 본 개시의 일 실시예에 따른 윈도우 크기에 따른 스펙트럼 분석을 나타낸 것이다. 도 6은 본 개시의 일 실시예에 따른 데이터 증강에 사용가능한 확률분포를 나타낸 것이다. 도 7은 본 발명의 일 실시예에 따른 인공 신경망의 구조를 나타낸 도면이다. 도 8은 본 개시의 다양한 실시예들에 따른, 알고리즘의 종류에 따른 검증 손실을 나타낸 도면이다. 도 9는 본 개시의 일 실시예에 따른, 데이터 셋의 구조를 나타낸 표이다. 도 10은 본 개시의 다양한 실시예에 따른 다양한 알고리즘 방식에 따른 성능을 나타낸 표이다.도 11은 본 개시의 일 실시예에 따른, 음성 사건 검출을 위한 전자 장치에 대한 블록 구성도이다. 도 12는 본 발명의 일 실시예에 따른 음성 사건 검출 방법을 설명하기 위한 순서도이다."}
