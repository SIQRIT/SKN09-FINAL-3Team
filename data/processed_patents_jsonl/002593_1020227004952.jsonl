{"patent_id": "10-2022-7004952", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0036956", "출원번호": "10-2022-7004952", "발명의 명칭": "생성적 및 검색-기반 애플리케이션들을 위한 효과적인 음악적 특징들을 학습하는 방법", "출원인": "삼성전자주식회사", "발명자": "브레탄, 피터 엠."}}
{"patent_id": "10-2022-7004952", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "입력 음악 콘텐트(input musical content)와 연관된 비언어적 입력을 수신하는 단계;상이한 음악 콘텐트 및 상기 상이한 음악 콘텐트 간의 관계들을 설명하는 복수의 음악적 특징들(musicalfeatures)을 잠재 공간(latent space)에 임베딩하는 모델을 이용하여, 상기 입력 음악 콘텐트에 기초하여 하나이상의 임베딩들(embeddings)을 식별하는 단계;(i) 상기 하나 이상의 식별된 임베딩들에 기초하여 저장된(stored) 음악 콘텐트를 식별하는 단계 또는 (ii) 상기 하나 이상의 식별된 임베딩들에 기초하여 도출된(derived) 음악 콘텐트를 생성하는 단계 중 적어도 하나; 및상기 저장된 음악 콘텐트 또는 상기 도출된 음악 콘텐트 중 적어도 하나를 제시하는(presenting) 단계를 포함하고,상기 모델은, 상기 잠재 공간 내 상기 음악적 특징들의 임베딩들이 미리-정의된 분포(predefined distribution)를 가지도록 하나 이상의 제1 신경망 구성요소들 및 하나 이상의 제2 신경망 구성요소들을 포함하는 기계 학습 시스템을 트레이닝함으로써, 생성되는, 방법."}
{"patent_id": "10-2022-7004952", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 음악 콘텐트 식별(identification), 음악 콘텐트 순위화(ranking), 음악 콘텐트 검색(retrieval), 및 음악 콘텐트 생성(generation) 중 적어도 2개를 수행하기 위해 상기 모델을 이용하는 단계를더 포함하는, 방법."}
{"patent_id": "10-2022-7004952", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서, 상기 비언어적 입력은 사용자에 의한 음악 연주(musical performance)를 포함하고;상기 도출된 음악 콘텐트는 상기 사용자에 의한 상기 음악 연주를 반주하도록(accompany) 제시되는, 방법."}
{"patent_id": "10-2022-7004952", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서, 상기 비언어적 입력은 상기 잠재 공간 내 기존 음악의 임베딩 또는 사용자에 의해 제공되는음악 콘텐트를 포함하고;상기 도출된 음악 콘텐트는 제시되며(presented), 상기 기존 음악 또는 상기 사용자에 의해 제공되는 상기 음악콘텐트에 기초하여 생성되는 구성 음악 콘텐트(composed musical content)를 포함하는, 방법."}
{"patent_id": "10-2022-7004952", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서, 상기 비언어적 입력은 비언어적 사운드들(sounds)을 포함하고;상기 저장된 음악 콘텐트는 제시되며, 상기 비언어적 사운드들에 기초하여 식별된 기존 음악을 포함하는, 방법."}
{"patent_id": "10-2022-7004952", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서, 상기 기계 학습 시스템을 위한 트레이닝 프로세스가 수행되고:상기 하나 이상의 제1 신경망 구성요소들은 참조(reference) 음악 콘텐트, 상기 참조 음악 콘텐트와 유사한 긍정(positive) 음악 콘텐트, 및 상기 참조 음악 콘텐트와 유사하지 않은 부정(negative) 음악 콘텐트를수신하고, 특정된 손실 함수(loss function)를 최소화하는 상기 잠재 공간 내 임베딩들을 생성하도록 트레이닝되며;상기 하나 이상의 제2 신경망 구성요소들은, 상기 미리-정의된 분포를 갖는 상기 잠재 공간 내 상기 임베딩들을생성하도록, 상기 하나 이상의 제1 신경망 구성요소들을 적대적으로(adversarially) 트레이닝하도록, 상기 트레이닝 프로세스가 수행되는, 방법.공개특허 10-2022-0036956-3-청구항 7 제1 항에 있어서, 상기 기계 학습 시스템을 위한 트레이닝 프로세스가 수행되고:인접성 판별기(adjacency discriminator)를 포함하는 분류기(classifier)는 상기 하나 이상의 제1 신경망 구성요소들에 의해 생성된 참조 음악 콘텐트의 임베딩들을 (i) 상기 하나 이상의 제1 신경망 구성요소들에 의해 생성되며 상기 참조 음악 콘텐트와 유사한 긍정 음악 콘텐트의 임베딩들과 관련되고 또한 (ii) 상기 하나 이상의제1 신경망 구성요소들에 의해 생성되며 상기 참조 음악 콘텐트와 유사하지 않은 부정 음악 콘텐트의 임베딩들과 관련 없는 것으로 분류하도록 트레이닝되고;상기 하나 이상의 제2 신경망 구성요소들은, 상기 미리-정의된 분포를 갖는 상기 잠재 공간 내 상기 임베딩들을생성하도록, 상기 하나 이상의 제1 신경망 구성요소들을 적대적으로 트레이닝하도록, 상기 트레이닝 프로세스가수행되는, 방법."}
{"patent_id": "10-2022-7004952", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "적어도 하나의 메모리;적어도 하나의 스피커; 및상기 적어도 하나의 메모리 및 상기 적어도 하나의 스피커와 작동 가능하게 결합되고, 입력 음악 콘텐트와 연관된 비언어적 입력을 수신하고; 상이한 음악 콘텐트 및 상기 상이한 음악 콘텐트 간의 관계들을 설명하는 복수의 음악적 특징들을 잠재 공간에 임베딩하는 모델을 이용하여, 상기 입력 음악 콘텐트에 기초하여 하나 이상의 임베딩들을 식별하며; (i) 상기 하나 이상의 식별된 임베딩들에 기초하여 저장된 음악 콘텐트를 식별하거나 또는 (ii) 상기 하나 이상의 식별된 임베딩들에 기초하여 도출된 음악 콘텐트를 생성하는 것 중 적어도 하나를 수행하고; 상기 적어도 하나의 스피커를 통해, 상기 저장된 음악 콘텐트 또는 상기 도출된 음악 콘텐트 중 적어도 하나를 제시하도록 구성된, 적어도 하나의 프로세서를 포함하고,상기 모델은, 상기 잠재 공간 내 상기 음악적 특징들의 임베딩들이 미리-정의된 분포를 가지도록 하나 이상의제1 신경망 구성요소들 및 하나 이상의 제2 신경망 구성요소들을 포함하는 기계 학습 시스템을 트레이닝함으로써, 생성되는, 전자 디바이스."}
{"patent_id": "10-2022-7004952", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서, 상기 적어도 하나의 프로세서는 음악 콘텐트 식별, 음악 콘텐트 순위화, 음악 콘텐트 검색,및 음악 콘텐트 생성 중 적어도 2개를 수행하기 위해 상기 모델을 이용하도록 더 구성되는, 전자 디바이스."}
{"patent_id": "10-2022-7004952", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8 항에 있어서, 상기 비언어적 입력은 사용자에 의한 음악 연주(musical performance)를 포함하고;상기 적어도 하나의 프로세서는 상기 사용자에 의한 상기 음악 연주를 반주하여(accompany) 상기 도출된 음악콘텐트를 제시하도록 구성되는, 전자 디바이스."}
{"patent_id": "10-2022-7004952", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8 항에 있어서, 상기 비언어적 입력은 상기 잠재 공간 내 기존 음악의 임베딩 또는 사용자에 의해 제공되는음악 콘텐트를 포함하고;상기 적어도 하나의 프로세서는, 상기 기존 음악 또는 상기 사용자에 의해 제공되는 상기 음악 콘텐트에 기초하여 생성된 구성 음악 콘텐트(composed musical content)를 포함하는, 상기 도출된 음악 콘텐트를 제시하도록 구성되는, 전자 디바이스."}
{"patent_id": "10-2022-7004952", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8 항에 있어서, 상기 비언어적 입력은 비언어적 사운드들을 포함하고;공개특허 10-2022-0036956-4-상기 적어도 하나의 프로세서는, 상기 비언어적 사운드들에 기초하여 식별된 기존 음악을 포함하는, 상기 저장된 음악 콘텐트를 제시하도록 구성되는, 전자 디바이스."}
{"patent_id": "10-2022-7004952", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8 항에 있어서, 상기 기계 학습 시스템을 위한 트레이닝 프로세스가 수행되고:상기 하나 이상의 제1 신경망 구성요소들은 참조 음악 콘텐트, 상기 참조 음악 콘텐트와 유사한 긍정 음악 콘텐트, 및 상기 참조 음악 콘텐트와 유사하지 않은 부정 음악 콘텐트를 수신하고, 특정된 손실 함수를 최소화하는상기 잠재 공간 내 임베딩들을 생성하도록 트레이닝되며;상기 하나 이상의 제2 신경망 구성요소들은, 상기 미리-정의된 분포를 갖는 상기 잠재 공간 내 상기 임베딩들을생성하도록, 상기 하나 이상의 제1 신경망 구성요소들을 적대적으로 트레이닝하도록, 상기 트레이닝 프로세스가수행되는, 전자 디바이스."}
{"patent_id": "10-2022-7004952", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8 항에 있어서, 상기 기계 학습 시스템을 위한 트레이닝 프로세스가 수행되고:인접성 판별기를 포함하는 분류기는 상기 하나 이상의 제1 신경망 구성요소들에 의해 생성된 참조 음악 콘텐트의 임베딩들을 (i) 상기 하나 이상의 제1 신경망 구성요소들에 의해 생성되며 상기 참조 음악 콘텐트와 유사한긍정 음악 콘텐트의 임베딩들과 관련되고 또한 (ii) 상기 하나 이상의 제1 신경망 구성요소들에 의해 생성되며상기 참조 음악 콘텐트와 유사하지 않은 부정 음악 콘텐트의 임베딩들과 관련 없는 것으로 분류하도록 트레이닝되고;상기 하나 이상의 제2 신경망 구성요소들은, 상기 미리-정의된 분포를 갖는 상기 잠재 공간 내 상기 임베딩들을생성하도록, 상기 하나 이상의 제1 신경망 구성요소들을 적대적으로 트레이닝하도록, 상기 트레이닝 프로세스가수행되는, 전자 디바이스."}
{"patent_id": "10-2022-7004952", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "실행되는 경우, 전자 디바이스의 적어도 하나의 프로세서로 하여금 제1 항 내지 제7 항 중 어느 한 항의 방법을수행하도록 하는 명령어들(instructions)을 포함하는, 기계-판독가능 매체(machine-readable medium)."}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "방법은 입력 음악 콘텐트와 연관된 비언어적 입력을 수신하는 단계를 포함한다. 상기 방법은 또한, 상이한 음악 콘텐트 및 상기 상이한 음악 콘텐트 간의 관계들을 설명하는 복수의 음악적 특징들을 잠재 공간(latent space)에 임베딩하는 모델을 이용하여, 상기 입력 음악 콘텐트에 기초하여 하나 이상의 임베딩들(embeddings)을 식별하는 (뒷면에 계속)"}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 일반적으로 기계 학습 시스템들에 관한 것이다. 보다 구체적으로, 본 개시는 생성적 및 검색-기반 애 플리케이션들(generative and retrieval-based applications)을 위한 효과적인 음악적 특징들(musical features)을 학습하는 방법에 관한 것이다."}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음악은 본질적으로 복잡하며, 음악의 단일 주제(motif) 또는 스타일은 종종 다양한 차원(dimension)에서 설명될 수 있다. 일부 차원들은 넓은 의미에서 음악을 설명하며, 음악의 보다 종합적 표현을 제공하는 특성들을 캡처할 수 있다. 이러한 차원들은, 조성(tonality), 음 밀도(note density), 복잡성(complexity), 및 기악 편성법 (instrumentation)과 같은, 음악적 특징들을 포함할 수 있다. 다른 차원들은 음악의 순차적 성질 및 시간적 측 면을 고려하여 음악을 설명할 수 있다. 그러한 차원들은, 싱코페이션(syncopation), 화성 진행(harmonic progression), 피치 곡선(pitch contour), 및 반복(repetition)과 같은, 음악적 특징들을 포함할 수 있다."}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "최근, 이러한 유형의 음악적 특징들을 요약하는(encapsulate) 저차원적 잠재(latent) \"음악 공간(musical space)\"을 학습하는 데 신경망들(neural networks)이 이용되어 왔다. 상이한 음악 소절들(musical passages)이, 상기 공간 내 상이한 벡터들과 같은, 상기 공간 내 상이한 임베딩들(embeddings)과 연관되거나 또 는 이들로 표현될 수 있다. 상기 공간 내 2개의 임베딩들 간의 거리는 2개의 음악 소절들 간의 유사도 (similarity)의 척도(measure)로서 이용될 수 있다. 서로 더 유사한 음악 소절들은 더 작은 거리만큼 분리된 임"}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 3, "content": "베딩들로 표현될 수 있다. 서로 덜 유사한 음악 소절들은 더 큰 거리만큼 분리된 임베딩들로 표현될 수 있다.발명의 내용"}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시는 생성적 및 검색-기반 애플리케이션들을 위한 효과적인 음악적 특징들을 학습하는 방법을 제공한다. 제1 실시예에서, 방법은 입력 음악 콘텐트(input musical content)와 연관된 비언어적 입력(non-linguistic input)을 수신하는 단계를 포함한다. 상기 방법은 또한, 상이한 음악 콘텐트 및 상기 상이한 음악 콘텐트 간의 관계들(relationships)을 설명하는 복수의 음악적 특징들을 잠재 공간(latent space)에 임베딩하는 모델을 이용 하여, 상기 입력 음악 콘텐트에 기초하여 하나 이상의 임베딩들(embeddings)을 식별하는 단계를 포함한다. 상기 방법은 (i) 상기 하나 이상의 식별된 임베딩들에 기초하여 저장된(stored) 음악 콘텐트를 식별하는 단계 또는 (ii) 상기 하나 이상의 식별된 임베딩들에 기초하여 도출된(derived) 음악 콘텐트를 생성하는 단계 중 적어도 하나를 더 포함한다. 또한, 상기 방법은 상기 저장된 음악 콘텐트 또는 상기 도출된 음악 콘텐트 중 적어도 하 나를 제시하는(presenting) 단계를 포함한다. 상기 모델은, 상기 잠재 공간에서의 상기 음악적 특징들의 임베딩 들이 미리-정의된 분포(predefined distribution)를 가지도록 하나 이상의 제1 신경망 구성요소들 및 하나 이상 의 제2 신경망 구성요소들을 갖는 기계 학습 시스템(machine learning system)을 트레이닝함으로써, 생성된다. 제2 실시예에서, 전자 디바이스는 적어도 하나의 메모리, 적어도 하나의 스피커, 및 상기 적어도 하나의 메모리 및 상기 적어도 하나의 스피커와 작동 가능하게(operatively) 결합된 적어도 하나의 프로세서를 포함한다. 상기 적어도 하나의 프로세서는 입력 음악 콘텐트와 연관된 비언어적 입력을 수신하도록 구성된다. 상기 적어도 하나 의 프로세서는 또한, 상이한 음악 콘텐트 및 상기 상이한 음악 콘텐트 간의 관계들을 설명하는 복수의 음악적 특징들을 잠재 공간에 임베딩하는 모델을 이용하여, 상기 입력 음악 콘텐트에 기초하여 하나 이상의 임베딩들을 식별하도록 구성된다. 상기 적어도 하나의 프로세서는 (i) 상기 하나 이상의 식별된 임베딩들에 기초하여 저장 된 음악 콘텐트를 식별하거나 또는 (ii) 상기 하나 이상의 식별된 임베딩들에 기초하여 도출된 음악 콘텐트를 생성하는 것 중 적어도 하나를 수행하도록 더 구성된다. 또한, 상기 적어도 하나의 프로세서는, 상기 적어도 하 나의 스피커를 통해, 상기 저장된 음악 콘텐트 또는 상기 도출된 음악 콘텐트 중 적어도 하나를 제시하도록 구 성된다. 상기 모델은, 상기 잠재 공간에서의 상기 음악적 특징들의 임베딩들이 미리-정의된 분포를 가지도록 하 나 이상의 제1 신경망 구성요소들 및 하나 이상의 제2 신경망 구성요소들을 갖는 기계 학습 시스템을 트레이닝 함으로써, 생성된다. 제3 실시예에서, 비일시적 기계-판독가능 매체(non-transitory machine-readable medium)는, 실행되는 경우, 전자 디바이스의 적어도 하나의 프로세서로 하여금 입력 음악 콘텐트와 연관된 비언어적 입력을 수신하도록 하 는, 명령어들(instructions)을 포함한다. 상기 매체는 또한, 실행되는 경우, 상기 적어도 하나의 프로세서로 하 여금, 상이한 음악 콘텐트 및 상기 상이한 음악 콘텐트 간의 관계들을 설명하는 복수의 음악적 특징들을 잠재 공간에 임베딩하는 모델을 이용하여, 상기 입력된 음악 콘텐트에 기초하여 하나 이상의 임베딩들을 식별하도록 하는, 명령어들을 포함한다. 상기 매체는, 실행되는 경우, 상기 적어도 하나의 프로세서로 하여금 (i) 상기 하 나 이상의 식별된 임베딩들에 기초하여 저장된 음악 콘텐트를 식별하거나 또는 (ii) 상기 하나 이상의 식별된 임베딩들에 기초하여 도출된 음악 콘텐트를 생성하는 것 중 적어도 하나를 수행하도록 하는, 명령어들을 더 포 함한다. 또한, 상기 매체는, 실행되는 경우, 상기 적어도 하나의 프로세서로 하여금 상기 저장된 음악 콘텐트 또는 상기 도출된 음악 콘텐트 중 적어도 하나를 제시하도록 하는, 명령어들을 포함한다. 상기 모델은, 상기 잠 재 공간에서의 상기 음악적 특징들의 임베딩들이 미리-정의된 분포를 가지도록 하나 이상의 제1 신경망 구성요 소들 및 하나 이상의 제2 신경망 구성요소들을 갖는 기계 학습 시스템을 트레이닝함으로써, 생성된다. 제4 실시예에서, 방법은 참조 음악 콘텐트(reference musical content), 상기 참조 음악 콘텐트와 유사한 긍정 (positive) 음악 콘텐트, 및 상기 참조 음악 콘텐트와 유사하지 않은 부정(negative) 음악 콘텐트를 수신하는 단계를 포함한다. 상기 방법은 또한, 상기 참조 음악 콘텐트, 상기 긍정 음악 콘텐트, 및 상기 부정 음악 콘텐 트, 및 상기 참조 음악 콘텐트, 상기 긍정 음악 콘텐트, 및 상기 부정 음악 콘텐트 간의 관계들을 설명하는 복 수의 음악적 특징들을 잠재 공간에 임베딩하는, 모델을 생성하는 단계를 포함한다. 상기 모델을 생성하는 단계 는 상기 잠재 공간에서의 상기 음악적 특징들의 임베딩들이 미리-정의된 분포를 가지도록 하나 이상의 제1 신경 망 구성요소들 및 하나 이상의 제2 신경망 구성요소들을 갖는 기계 학습 시스템을 트레이닝하는 단계를 포함한다. 다른 실시예에서, 상기 기계 학습 시스템을 트레이닝하는 단계는: 상기 하나 이상의 제1 신경망 구성요소들은 상기 참조 음악 콘텐트, 상기 긍정 음악 콘텐트, 및 상기 부정 음악 콘텐트를 수신하고, 특정된 손실 함수(loss function)를 최소화하는, 상기 잠재 공간 내의 임베딩들을 생성하도록 트레이닝되며; 상기 하나 이상의 제2 신 경망 구성요소들은 상기 미리-정의된 분포를 갖는 상기 잠재 공간 내의 상기 임베딩들을 생성하도록 상기 하나 이상의 제1 신경망 구성요소들을 적대적으로(adversarially) 트레이닝하도록, 수행된다. 다른 실시예에서, 상기 기계 학습 시스템은 2개의 반복 스테이지들(repeating stages)로 트레이닝되고; 상기 반 복 스테이지들 중 제1 스테이지는 상기 하나 이상의 제1 신경망 구성요소들을 트레이닝하며; 상기 반복 스테이 지들 중 제2 스테이지는 상기 제2 신경망 구성요소들을 이용하여 상기 제1 신경망 구성요소들을 적대적으로 트 레이닝한다. 다른 실시예에서, 상기 미리-정의된 분포는 가우시안(Gaussian)이며 연속적이다. 다른 실시예에서, 상기 기계 학습 시스템을 트레이닝하는 단계가 수행되고: 인접성 판별기(adjacency discriminator)를 포함하는 분류기(classifier)는 상기 하나 이상의 제1 신경망 구성요소들에 의해 생성된 상기 참조 음악 콘텐트의 임베딩들을 (i) 상기 하나 이상의 제1 신경망 구성요소들에 의해 생성된 상기 긍정 음악 콘 텐트의 임베딩들과 관련되고 또한 (ii) 상기 하나 이상의 제1 신경망 구성요소들에 의해 생성된 상기 부정 음악 콘텐트의 임베딩들과 관련되지 않는 것으로 분류하도록 트레이닝되고; 상기 하나 이상의 제2 신경망 구성요소들 은 상기 미리-정의된 분포를 갖는 상기 잠재 공간 내의 상기 임베딩들을 생성하도록 상기 하나 이상의 제1 신경 망 구성요소들을 적대적으로 트레이닝하도록, 상기 트레이닝 단계가 수행된다. 다른 실시예에서, 상기 분류기는 음악 구성(musical composition)에서 2개의 음악 콘텐트들이 인접해 있는지 여 부를 결정하도록 트레이닝된다. 다른 실시예에서, 상기 기계 학습 시스템은 2개의 반복 스테이지들로 트레이닝되고; 상기 반복 스테이지들 중 제1 스테이지는 관련된 음악 콘텐트를 관련 없는 음악 콘텐트와 구별하도록 상기 분류기를 트레이닝하되, 상기 하나 이상의 제1 신경망 구성요소들 및 상기 인접성 판별기 모두가 업데이트되며; 상기 반복 스테이지들 중 제2 스테이지는 상기 하나 이상의 제2 신경망 구성요소들을 이용하여 상기 하나 이상의 제1 신경망 구성요소들을 적 대적으로 트레이닝한다. 다른 실시예에서, 상기 트레이닝 동안: 상기 분류기는 제1 결합된 임베딩들(combined embeddings)을 생성하도록 상기 참조 음악 콘텐트의 상기 임베딩들 및 상기 긍정 음악 콘텐트의 상기 임베딩들을 연결하고(concatenate); 상기 분류기는 제2 결합된 임베딩들을 생성하도록 상기 참조 음악 콘텐트의 상기 임베딩들 및 상기 부정 음악 콘텐트의 상기 임베딩들을 연결하며; 상기 분류기는 상기 제1 및 제2 결합된 임베딩들을 이용하여 관련된 음악 콘텐트 및 관련 없는 음악 콘텐트를 분류하도록 트레이닝된다. 다른 실시예에서, 상기 하나 이상의 제1 신경망 구성요소들은 컨볼루션 신경망(convolutional neural network) 을 포함하고; 상기 하나 이상의 제2 신경망 구성요소들은 적대적 판별기(adversarial discriminator)를 포함한 다."}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "기타 기술적 특징들은 이하의 도면, 설명, 및 청구범위로부터 본 개시가 속하는 기술분야의 통상의 지식을 가진 자에게 쉽게 이해될 수 있다. 하기 상세한 설명에 착수하기 전에, 본 특허 문서 전체에 걸쳐 사용되는 특정 단어들 및 문구들의 정의를 설명 하는 것이 유리할 수 있다. \"전송하다(transmit)\", \"수신하다(receive)\", 및 \"통신하다(communicate)\"라는 용 어들뿐 아니라 그 파생어들은 직접 및 간접 통신 모두를 포괄한다. \"포함하다(include)\" 및 \"구비하다 (comprise)\"라는 용어들 및 그 파생어들은 제한 없는 포함을 의미한다. \"또는(or)\"이라는 용어는 \"및/또는 (and/or)\"을 의미하는 포괄적인 용어이다. \"~와 연관된(associated with)\"이라는 문구 및 그 파생문구들은 포함 하다(include), ~내에 포함되다(be included within), ~와 상호연결되다(interconnect with), 함유하다 (contain), ~내에 함유되다(be contained within), ~에 또는 ~와 연결하다(connect to or with), ~에 또는 ~와 결합하다(couple to or with), ~와 통신가능하다(be communicable with), ~와 협력하다(cooperate with), 인터 리빙하다(interleave), 병치하다(juxtapose), ~에 근접하다(be proximate to), ~에 또는 ~와 결속되다(be bound to or with), 가지다(have), ~의 특성을 가지다(have a property of), ~에 또는 ~와 관계성을 가지다 (have a relationship to or with) 등을 의미한다.또한, 하기 설명되는 다양한 기능들(functions)은 하나 이상의 컴퓨터 프로그램들에 의해 구현되거나 또는 지원 될 수 있으며, 상기 하나 이상의 컴퓨터 프로그램들 각각은 컴퓨터 판독가능 프로그램 코드(computer readable program code)로 구성되고 컴퓨터 판독가능 매체(computer readable medium)에서 구현된다. \"애플리케이션 (application)\" 및 \"프로그램(program)\"이라는 용어들은 하나 이상의 컴퓨터 프로그램들, 소프트웨어 구성요소 들, 명령어들(instructions)의 세트들, 절차들(procedures), 기능들(functions), 객체들(objects), 클래스들 (classes), 인스턴스들(instances), 관련 데이터, 또는 적절한 컴퓨터 판독가능 프로그램 코드의 구현에 적합한 이들의 일부를 의미한다. \"컴퓨터 판독가능 프로그램 코드\"라는 문구는, 소스 코드(source code), 객체 코드 (object code), 및 실행가능 코드(executable code)를 포함하는 모든 유형의 컴퓨터 코드를 포함한다. \"컴퓨터 판독가능 매체\"라는 문구는, 읽기 전용 메모리(read only memory: ROM), 랜덤 액세스 메모리(random access memory: RAM), 하드 디스크 드라이브, 컴팩트 디스크(compact disc: CD), 디지털 비디오 디스크(digital video disc: DVD), 또는 다른 어떤 유형의 메모리와 같이, 컴퓨터에 의해 액세스될 수 있는 어떠한 유형의 매체라도 포함한다. \"비일시적(non-transitory)\" 컴퓨터 판독가능 매체는 일시적인 전기적 또는 기타 신호들을 전송하는 유선, 무선, 광학적, 또는 기타 통신 링크들을 제외한다. 비일시적 컴퓨터 판독가능 매체는 데이터가 영구적으 로 저장될 수 있는 매체들 및, 다시쓰기가능(rewritable) 광디스크 또는 소거가능(erasable) 메모리 디바이스와 같이, 데이터가 저장되고 추후에 덮어 쓰일(overwritten) 수 있는 매체들을 포함한다. 본 명세서에서, 특징(feature)(예를 들면, 수(number), 기능(function), 동작(operation), 또는 부품(part)과 같은 구성요소(component))를 \"가지다(have)\", \"가질 수 있다(may have)\", \"포함하다(include)\", 또는 \"포함할 수 있다\"와 같은, 용어들 및 문구들은 상기 특징의 존재를 나타내며 다른 특징들의 존재를 배제하지 않는다. 또 한, 본 명세서에서, \"A 또는 B(A or B)\", \"A 및/또는 B 중 적어도 하나(at least one of A and/or B)\", 또는 \"A 및/또는 B 중 하나 이상(one or more of A and/or B)\"이라는 문구들은 A 및 B의 모든 가능한 조합들을 포함 할 수 있다. 예를 들면, \"A 또는 B\", \"A 및 B 중 적어도 하나\", 및 \"A 또는 B 중 적어도 하나\"는 적어도 하 나의 A(at least one A)를 포함하는 것, 적어도 하나의 B(at least one B)를 포함하는 것, 또는 적어 도 하나의 A 및 적어도 하나의 B를 포함하는 것을 모두 나타낼 수 있다. 또한, 본 명세서에서, \"제1(first)\" 및 \"제2(second)\"라는 용어들은 중요도와 상관 없이 다양한 구성요소들을 수식할 수 있으며 상기 구성요소들을 제 한하지 않는다. 이러한 용어들은 단지 하나의 구성요소를 다른 것과 구별하기 위해 사용된다. 예를 들면, 제1 사용자 디바이스 및 제2 사용자 디바이스는, 상기 디바이스들의 순서 또는 중요도와 상관 없이, 서로 다른 사용 자 디바이스들을 나타낼 수 있다. 본 개시의 범위를 벗어나지 않고, 제1 구성요소가 제2 구성요소로 표기될 수 있고 그 반대의 경우도 마찬가지이다. 어떤 구성요소(예를 들면, 제1 구성요소)가 다른 구성요소(예를 들면, 제2 구성요소)와 (작동 가능하게 (operatively) 또는 통신 가능하게(communicatively)) \"결합(coupled with/to)\" 또는 \"연결(connected with/to)\"된다고 언급될 때, 상기 구성요소는 상기 다른 구성요소와 직접 또는 제3 구성요소를 통해 결합 또는 연결될 수 있음을 이해할 수 있을 것이다. 반면에, 어떤 구성요소(예를 들면, 제1 구성요소)가 다른 구성요소 (예를 들면, 제2 구성요소)와 \"직접 결합(directly coupled with/to)\" 또는 \"직접 연결(directly connected with/to)\"된다고 언급될 때, 상기 구성요소와 상기 다른 구성요소 사이에 다른 구성요소(예를 들면, 제3 구성요 소)가 개재되지 않음을 이해할 수 있을 것이다. 본 명세서에서, \"~하도록 구성된(또는 설정된)(configured(or set) to)\"이라는 문구는, 상황에 따라, \"~에 적합 한(suitable for)\", \"~할 능력이 있는(having the capacity to)\", \"~하도록 설계된(designed to)\", \"~하도록 적응된(adapted to)\", \"~하도록 만들어진(made to)\", 또는 \"~할 수 있는(capable of)\"이라는 문구들과 상호교 환적으로 사용될 수 있다. \"~하도록 구성된(또는 설정된)\"이라는 문구가 본질적으로 \"~하도록 하드웨어적으로 특별히 설계된(specifically designed in hardware to)\"이라는 의미를 나타내는 것은 아니다. 오히려, \"~하도 록 구성된\"이라는 문구는 디바이스가 다른 디바이스 또는 부품들과 함께 동작(operation)을 수행할 수 있음을 의미할 수 있다. 예를 들면, \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"라는 문구는 메모리 디바 이스에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써 상기 동작들을 수행할 수 있는 범용 (generic-purpose) 프로세서(예를 들면, CPU 또는 애플리케이션 프로세서), 또는 상기 동작들을 수행하기 위한 전용(dedicated) 프로세서(예를 들면, 내장형(embedded) 프로세서)를 의미할 수 있다. 본 명세서에서 사용된 용어들 및 문구들은 단지 본 개시의 일부 실시예들을 설명하기 위해 제공되는 것이지 본 개시의 다른 실시예들의 범위를 제한하고자 제공되는 것이 아니다. 문맥상 명확히 달리 언급되지 않는 한 \"a\", \"an\", 및 \"the\"라는 단수 형태들은 복수 형태의 언급을 포함한다는 것을 이해해야 할 것이다. 본 명세서에서 사"}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "용되는, 기술적 및 과학적 용어들 및 문구들을 포함하는, 모든 용어들 및 문구들은 본 개시의 실시예들이 속하는 기술분야의 통상의 지식을 가진 자에 의해 통상적으로 이해되는 바와 동일한 의미들을 가진다. 통상적으로"}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 4, "content": "사용되는 사전들에서 정의된 바와 같은, 용어들 및 문구들은 관련 기술분야의 맥락에서 그 의미와 일치하는 의 미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명시적으로 정의되지 않는 한 이상적이거나 지나치게 형식적 인 의미로 해석되어서는 안 된다는 것을 또한 이해할 것이다. 경우에 따라서, 본 명세서에서 정의된 용어들 및 문구들은 본 개시의 실시예들을 배제하는 것으로 해석될 수 있다. 본 개시의 실시예들에 따른 \"전자 디바이스\"의 예들은 스마트폰, 태블릿 개인용 컴퓨터(personal computer: PC), 휴대 전화(mobile phone), 비디오폰, 전자책 단말기(e-book reader), 데스크탑(desktop) PC, 랩탑 (laptop) 컴퓨터, 노트북 컴퓨터, 워크스테이션, 개인 휴대 정보 단말기(personal digital assistant: PDA), 휴대용 멀티미디어 플레이어(portable multimedia player: PMP), MP3 플레이어, 모바일 의료 디바이스, 카메라, 또는 웨어러블 디바이스(예를 들면, 스마트 안경, 머리 착용형 디바이스(head-mounted device: HMD), 전자 의류(electronic clothes), 전자 팔찌, 전자 목걸이, 전자 액세서리, 전자 문신, 스마트 거울, 또는 스마 트 워치(smart watch)) 중 적어도 하나를 포함할 수 있다. 전자 디바이스의 다른 예들은 스마트 가전제품(smart home appliance)를 포함한다. 상기 스마트 가전제품의 예들은 텔레비전, 디지털 비디오 디스크(digital video disc: DVD) 플레이어, 오디오 플레이어, 냉장고, 에어컨, 청소기, 오븐, 전자레인지, 세탁기, 드라이기, 공기 청정기, 셋탑 박스(set-top box), 가정 자동화 제어 패널(home automation control panel), 보안 제어 패널, TV 박스(예를 들면, 삼성 홈싱크(SAMSUNG HOMESYNC), 애플TV(APPLETV), 또는 구글 TV(GOOGLE TV)), 통합 디지 털 비서(integrated digital assistant)를 갖춘 스마트 스피커 또는 스피커(예를 들면, 삼성 갤럭시 홈 (SAMSUNG GALAXY HOME), 애플 홈팟(APPLE HOMEPOD), 또는 아마존 에코(AMAZON ECHO)), 게임 콘솔(예를 들면, 엑스박스(XBOX), 플레이스테이션(PLAYSTATION), 또는 닌텐도(NINTENDO)), 전자 사전, 전자 키(key), 캠코더 (camcorder), 또는 전자 액자 중 적어도 하나를 포함할 수 있다. 전자 디바이스의 또 다른 예들은 다양한 의료 디바이스들(예를 들면, 다양한 휴대용 의료 측정 디바이스들(예를 들면, 혈당 측정 디바이스, 심박 측정 디바이 스, 또는 체온 측정 디바이스), 자기자원 혈관조영(magnetic resource angiography: MRA) 디바이스, 자기자원 영상(magnetic resource imaging: MRI) 디바이스, 컴퓨터 단층촬영(computed tomography: CT) 디바이스, 영상 화 디바이스, 또는 초음파 디바이스), 네비게이션 디바이스, 범지구 위치확인 시스템(global positioning system: GPS) 수신기, 사고 데이터 기록장치(event data recorder: EDR), 비행 데이터 기록장치(flight data recorder: FDR), 자동차 인포테인먼트(infotainment) 디바이스, 항해(sailing) 전자 디바이스(예를 들면, 항해 네비게이션 디바이스 또는 자이로컴퍼스(gyro compass)), 항공전자기기(avionics), 보안 디바이스들, 차량용 헤 드 유닛들(vehicular head units), 산업용 또는 가정용 로봇들, 자동 현금 입출금기들(automatic teller machines: ATMs), 판매시점 관리(point of sales: POS) 디바이스들, 또는 사물인터넷(Internet of Things: IoT) 디바이스들(예를 들면, 전구, 다양한 센서들, 전기 또는 가스 계량기, 스프링클러(sprinkler), 화재 경보 기(fire alarm), 온도 조절장치(thermostat), 가로등, 토스터(toaster), 피트니스 장비, 온수 탱크, 히터 (heater), 또는 보일러) 중 적어도 하나를 포함한다. 전자 디바이스의 다른 예들은 가구 또는 건물(building)/ 구조물(structure)의 적어도 일부, 전자 보드(electronic board), 전자 서명(electronic signature) 수신 디바 이스, 프로젝터(projector), 또는 다양한 측정 디바이스들(예를 들면, 물, 전기, 가스, 또는 전자파 측정 디바 이스들)을 포함한다. 본 개시의 다양한 실시예들에 따르면, 전자 디바이스는 상기 열거된 디바이스들 중 하나 또는 이들의 조합일 수 있음을 유의하라. 본 개시의 일부 실시예들에 따르면, 상기 전자 디바이스는 플렉서블 (flexible) 전자 디바이스일 수 있다. 본 명세서에 개시된 상기 전자 디바이스는 상기 열거된 디바이스들에 제 한되지 않으며 기술 발전에 따라 새로운 전자 디바이스들을 포함할 수 있다. 하기 설명에서, 전자 디바이스들은, 본 개시의 다양한 실시예들에 따라, 첨부된 도면을 참조하여 설명된다. 본 명세서에서, \"사용자(user)\"라는 용어는 상기 전자 디바이스를 사용하는 인간 또는 다른 디바이스(예를 들면, 인공지능(artificial intelligent) 전자 디바이스)를 나타낼 수 있다. 기타 특정 단어들 및 문구들에 대한 정의들은 본 특허 문서 전체에 걸쳐 제공될 수 있다. 본 개시가 속하는 기 술분야의 통상의 지식을 가진 자는, 대부분은 아닐지라도 많은 경우, 그러한 정의들이 그와 같이 정의된 단어들 및 문구들의 선행(prior) 사용뿐만 아니라 향후(future) 사용에도 적용됨을 이해해야 할 것이다. 본 출원에서의 어떤 설명도 어떤 특정 요소(elememt), 단계(step), 또는 기능(function)이 청구 범위(claim scope)에 포함되어야 하는 필수 요소임을 암시하는 것으로 해석되어서는 안 된다. 특허 대상(patented subject matter)의 범위는 오직 청구항들에 의해서만 정의된다. 청구항 내에서, 제한 없이 \"메커니즘(mechanism)\", \"모 듈(module)\", \"디바이스(device)\", \"유닛(unit)\", \"구성요소(component)\", \"요소(element)\", \"부재(member)\","}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 5, "content": "\"장치(apparatus)\", \"기계(machine)\", \"시스템(system)\", \"프로세서(processor)\", 또는 \"컨트롤러(controller)\"를 포함하는, 다른 어떤 용어의 사용은 관련 기술분야의 통상의 지식을 가진 자에게 알려진 구조 들을 지칭하는 것으로 본 출원인에 의해 이해된다."}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서 논의되는 도 1 내지 도 13, 및 본 개시의 다양한 실시예들은 첨부 도면을 참조하여 설명된다. 그러나, 본 개시는 이러한 실시예들에 제한되지 않으며, 이들에 대한 모든 변경들 및/또는 균등물들(equivalents) 또는 대체물들(replacements)도 또한 본 개시의 범위에 속함을 이해해야 할 것이다. 명세서 및 도면들에 전체에 걸쳐 동일 또는 유사한 요소들을 지칭하기 위해 동일 또는 유사한 참조 표시들(reference denotations)이 이용될 수 있다. 상술된 바와 같이, 음악은 본질적으로 복잡하며 종종 복수의 차원들에서 설명될 수 있다. 일부 차원들은 넓은 의미에서 음악을 설명하며, 조성(tonality), 음 밀도(note density), 복잡성(complexity), 및 기악 편성법 (instrumentation)과 같은, 음악의 보다 종합적 표현을 제공하는 특성들을 캡처할 수 있다. 다른 차원들은, 싱 코페이션(syncopation), 화성 진행(harmonic progression), 피치 곡선(pitch contour), 및 반복(repetition)과"}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "같은, 음악의 순차적 성질 및 시간적 측면을 고려하여 음악을 설명할 수 있다. 그러한 음악적 특징들을 요약하 는(encapsulate) 저차원적 잠재(latent) \"음악 공간(musical space)\"을 학습하는 데 신경망들(neural networks)이 이용되어 왔으며, 여기서 상이한 음악 소절들(musical passages)은 상기 공간 내 상이한 벡터들 또 는 기타 임베딩들(embeddings)과 연관되거나 또는 이들로 표현될 수 있다. 상기 공간 내 2개의 임베딩들 간의 거리는 2개의 음악 소절들 간의 유사도의 척도(measure)로서 이용될 수 있다. 이는, 상위 레벨에서, 유사한 음 악 콘텐트의 임베딩들은 상기 잠재 공간에서 비유사한 음악 콘텐트보다 기하학적으로 더 가까워야 함을 의미한 다. 특정 태스크들(tasks)에 대하여, 이러한 잠재 공간을 효과적으로 학습하는 것은, 음악이 인간의 기대에 부합하 는 방식으로 식별되거나, 선택되거나, 생성되거나, 또는 달리 사용되도록 돕기 위해, 중요할 수 있다. 이는 특 히 기계의 응답이 전형적으로 인간 수행자(human performer)를 조건으로 하는 대화형 애플리케이션들 (interactive applications)에 있어서 사실일 수 있다. 따라서, 음악적 특징들의 효과적인 임베딩이 인간의 지 각(human perceptions)과 상호 연관되는 방식으로 음악을 해석하는 데 이용될 수 있다. 이러한 유형의 임베딩은 다운스트림(downstream) 태스크들에 유용한 특징들을 캡처하며 샘플링 및 의미 있는 보간(interpolation)에 적 합한 분포를 따른다. 불행하게도, 유용한 음악적 특징들의 학습은 종종 학습된 음악적 특징들로부터 효과적으로 생성 또는 디코딩할 수 있는 능력을 희생하면서 이루어진다(또한 그 반대도 마찬가지이다). 본 개시는 생성적 및 검색-기반 애플리케이션들을 위한 효과적인 음악적 특징들을 학습하는 방법을 제공한다. 이러한 방법들은 의미 있는 음악적 특징들을 학습하고 잠재 음악 공간(latent musical space)에 임베딩된 그러 한 음악적 특징들의 유용한 분포를 따를 수 있다. 이러한 방법들은 컨텍스트(context)를 레버리징하고 (leverage) 동시에, 적대적 구성요소(adversarial component)를 이용하여, 예를 들면, 역전파 (backpropagation)를 통해, 상기 잠재 공간 내 상기 특징들의 상기 분포에 형태(shape)를 부과한다. 이는 컨텍 스트를 레버리징하고(이는 특징들을 향상시킴) 상기 잠재 공간 내 상기 분포를 제한함으로써(이는 생성적 샘플 링(generative sampling)을 가능하게 함) 원하는 특성들에 대해 공동으로 최적화할 수 있도록 한다. 명시적으로 라벨링된 데이터(labeled data) 대신에, 신경망 구성요소들 또는 기타 기계 학습 알고리즘들이, 음악 콘텐트의 2개의 인접한 단위들(units)(예를 들면, 동일한 음악 구성에서 2개의 인접한 소절들(passages) 또는 섹션들 (sections))이 관련되어 있다는 가정 하에서, 트레이닝될 수 있다. 다시 말하면, 상기 잠재 공간 내 동일한 음 악 콘텐트의 2개의 인접한 단위들의 임베딩들 간의 거리는 상기 잠재 공간 내 음악 콘텐트의 2개의 랜덤한 관련 없는 단위들의 임베딩들보다 더 작아야 한다. 무엇보다, 음악 콘텐트가 분석될 수 있고, 그 특징들은, 연속적 저차원 공간(continuous low-dimensional space) 내에서 원하는 분포를 유지하면서, 인간 청취자(human listener)와 관련 있는 상기 연속적 저차원 공간 으로 투사될 수 있다. 따라서, 이러한 방법들은 수많은 관련된 음악적 특징들을 상기 공간으로 임베딩함으로써 상기 특징 공간을 효과적으로 학습하는 데 이용될 수 있다. 또한, 이러한 접근법들은 단일 기계 학습 모델이 트 레이닝되어 다양한 다운스트림 태스크들에 이용될 수 있도록 한다. 종종, 다수의 태스크들에 대해 단일 모델을 트레이닝 할 때 전형적으로 태스크들에 걸쳐 성능이 저하되기 때문에, 각각의 특정 태스크에 대해 하나의 고유 한 모델이 트레이닝된다. 본 개시에서 설명되는 방법들을 이용하여 트레이닝된 각 모델은, 가청의(audible) 비 언어적 입력에 기초하여 특정 음악 콘텐트를 탐색하는 것, 가청의 비언어적 입력과 가장 유사한 음악 콘텐트의 순위화(ranking), 가청의 비언어적 입력에 기초하여 재생을 위한 특정 음악 콘텐트를 선택하는 것, 및 가청의 비언어적 입력에 기초하여 음악을 자율적으로(autonomously) 생성하는 것과 같은, 다양한 기능들(functions)을 수행하는 데 이용될 수 있다. 또한, 상기 설명된 방법들은 컨텍스트의 임베딩, 자체 재구성(self- reconstruction), 및 분포의 제한을 위해 다수의 손실 함수들을 공동으로 최적화할 수 있다(예를 들면, 역전파 (backpropagation)를 이용하여). 복수의 태스크들에 대해 단일 모델이 이용될 수 있기 때문에, 복수의 손실 함 수들이 동시에 최적화될 수 있으며, 상기 잠재 공간 내 특징들의 분포는 상기 분포가 특정 부분공간(subspace) 을 따르도록 제한될 수 있다. 이 분포는 컨텍스트를 이용하는 추가적 손실 함수들을 이용하여 효과적인 특징들 이 학습될 수 있도록 한다. 또한, 하나 이상의 다운스트림 태스크들에 있어서 개선된 성능을 달성하기 위해 트 레이닝된 기계 학습 모델이 이용될 수 있다. 도 1은, 본 개시에 따른, 전자 디바이스를 포함하는 예시적인 네트워크 구성을 도시한다. 도 1에 도시된 네트워크 구성의 실시예는 단지 예시를 위한 것이다. 본 개시의 범위를 벗어나지 않고 네트워크 구성(10 0)의 다른 실시예들이 이용될 수 있다. 본 개시의 실시예들에 따르면, 전자 디바이스는 네트워크 구성에 포함된다. 전자 디바이스는 버 스, 프로세서, 메모리, 입출력(input/output: I/O) 인터페이스, 디스플레이, 통신 인터페이스, 센서, 또는 스피커 중 적어도 하나를 포함할 수 있다. 일부 실시예들에서, 전자 디 바이스는 이러한 구성요소들 중 적어도 하나를 제외할 수 있거나 또는 적어도 하나의 다른 구성요소를 추 가할 수 있다. 버스는 구성요소들(120-190)을 서로 연결하고 상기 구성요소들 간에 통신들(예를 들면, 제 어 메시지들 및/또는 데이터)을 전달하기 위한 회로를 포함한다. 프로세서는 중앙 처리 장치(central processing unit: CPU), 애플리케이션 프로세서(application processor: AP), 또는 통신 프로세서(communication processor: CP) 중 하나 이상을 포함한다. 프로세서 는 전자 디바이스의 다른 구성요소들 중 적어도 하나에 대해 제어를 수행하고 및/또는 통신과 관련된 동작 (operation) 또는 데이터 처리(data processing)를 수행할 수 있다. 예를 들면, 프로세서는, 예를 들면, 다량의 상이한 음악 콘텐트를 잠재 공간 내에 원하는 분포로 임베딩함으로써, 효과적인 음악적 특징들을 학습하 기 위한 트레이닝에 이용될 수 있다. 프로세서는 또한 또는 대안적으로, 음악 콘텐트의 탐색(searching), 순위화(ranking), 재생(playing), 또는 생성(generating)과 같은, 하나 이상의 생성적 및 검색-기반 애플리케이 션들(generative and retrieval-based applications)을 위해 트레이닝된 기계 학습 모델을 이용할 수 있다. 메모리는 휘발성 및/또는 비휘발성 메모리를 포함할 수 있다. 예를 들면, 메모리는 전자 디바이스 의 적어도 하나의 다른 구성요소와 관련된 명령들(commands) 또는 데이터를 저장할 수 있다. 본 개시의 실 시예들에 따르면, 메모리는 소프트웨어 및/또는 프로그램을 저장할 수 있다. 프로그램은, 예를 들면, 커널(kernal), 미들웨어(middleware), 애플리케이션 프로그래밍 인터페이스(applicationprogramming interface: API), 및/또는 애플리케이션 프로그램(또는 \"애플리케이션\")을 포함한다. 커널, 미들웨어, 또는 API의 적어도 일부는 운영 체제(operating system: OS)로 표시될 수 있 다. 커널은 다른 프로그램들(예를 들면, 미들웨어, API, 또는 애플리케이션)에서 구현되는 동 작들(operations) 또는 기능들(functions)을 수행하는 데 이용되는 시스템 자원들(예를 들면, 버스, 프로 세서, 또는 메모리)를 제어 또는 관리할 수 있다. 커널은, 미들웨어, API, 또는 애 플리케이션이 상기 시스템 자원들을 제어 또는 관리하기 위해 전자 디바이스의 개별 구성요소들을 액 세스할 수 있도록 하는, 인터페이스를 제공한다. 애플리케이션은, 이하에서 논의되는 바와 같이, 기계 학 습 및/또는 트레이닝된 기계 학습 모델 용도의 하나 이상의 애플리케이션들을 포함할 수 있다. 이러한 기능들 (functions)은 단일 애플리케이션에 의해 또는, 각각이 이러한 기능들 중 하나 이상의 기능들을 수행하는, 복수 의 애플리케이션들에 의해 수행될 수 있다. 미들웨어는, 예를 들면, API 또는 애플리케이션이 커널과 데이터를 통신할 수 있도록 하는, 릴레이(relay)로서 기능할 수 있다. 복수의 애플리케이션들(14 7)이 제공될 수 있다. 미들웨어는, 예를 들면, 전자 디바이스의 상기 시스템 자원들(예를 들면, 버스 , 프로세서, 또는 메모리)를 이용하는 우선순위를 상기 복수의 애플리케이션들 중 적어도 하나에 할당함으로써, 애플리케이션들로부터 수신되는 작업 요청들(work requests)을 제어할 수 있다. API는, 애플리케이션이 커널 또는 미들웨어로부터 제공되는 기능들(functions)을 제어할 수 있도록 하는, 인터페이스이다. 예를 들면, API는 파일링 제어(filing control), 윈도우 제어, 이미지 처리, 또는 텍스트 제어를 위한 적어도 하나의 인터페이스 또는 기능(예를 들면, 명령(command))을 포함한다. I/O 인터페이스는, 예를 들면, 사용자 또는 다른 외부 디바이스들로부터 입력된 명령들 또는 데이터를 전 자 디바이스의 다른 구성요소(들)로 전달할 수 있는, 인터페이스로서의 역할을 한다. I/O 인터페이스(15 0)는 또한 전자 디바이스의 다른 구성요소(들)로부터 수신된 명령들 또는 데이터를 상기 사용자 또는 상기 다른 외부 디바이스로 출력할 수 있다. 디스플레이는, 예를 들면, 액정 디스플레이(liquid crystal display: LCD), 발광 다이오드(light emitting diode: LED) 디스플레이, 유기 발광 다이오드(organic light emitting diode: OLED) 디스플레이, 퀀 텀닷 발광 다이오드(quantum-dot light emitting diode: QLED) 디스플레이, 미세전자기계 시스템 (microelectromechanical systems: MEMS) 디스플레이, 또는 전자 종이 디스플레이를 포함한다. 디스플레이 는 또한, 다중-초점 디스플레이와 같은, 깊이-인식(depth-aware) 디스플레이일 수 있다. 디스플레이 는, 예를 들면, 다양한 콘텐트들(예를 들면, 텍스트, 이미지들, 비디오들, 아이콘들(icons), 또는 기호들 (symbols))을 상기 사용자에게 표시할 수 있다. 디스플레이는 터치스크린을 포함할 수 있고, 예를 들면, 전자 펜 또는 상기 사용자의 신체 일부를 이용한 터치, 제스처(gesture), 근접(proximity), 또는 호버링 (hovering) 입력을 수신할 수 있다. 통신 인터페이스는, 예를 들면, 전자 디바이스와 외부 전자 디바이스(예를 들면, 제1 전자 디바이스 , 제2 전자 디바이스, 또는 서버) 간에 통신을 설정할 수 있다. 예를 들면, 통신 인터페이스 는, 상기 외부 전자 디바이스와 통신하기 위해, 무선 또는 유선 통신을 통해 네트워크(162 또는 164)와 연 결될 수 있다. 통신 인터페이스는 유선 또는 무선 송수신기(transceiver)이거나 또는 신호를 송신 및 수신 하는 다른 어떤 구성요소일 수 있다. 전자 디바이스는, 물리량을 계측하거나 전자 디바이스의 활성화 상태를 검출하고 게측된 또는 검출된 정보를 전기 신호로 변환할 수 있는, 하나 이상의 센서들을 더 포함한다. 예를 들면, 하나 이상의 센서들 은, 하나 이상의 사용자들로부터의 비언어적 가청(audible) 입력을 캡처하는 데 이용될 수 있는, 하나 이 상의 마이크들(microphones)을 포함할 수 있다. 센서(들)는 또한 하나 이상의 터치 입력용 버튼들, 하나 이상의 카메라들, 제스처 센서, 자이로스코프(gyroscope) 또는 자이로 센서(gyro sensor), 기압(air pressure) 센서, 자기 센서 또는 자력계(magnetometer), 가속도 센서 또는 가속도계(accelerometer), 그립(grip) 센서, 근접(proximity) 센서, 컬러(color) 센서(예를 들면, 적녹청(red green blue: RGB) 센서), 생체물리(bio- physical) 센서, 온도 센서, 습도 센서, 조도(illumination) 센서, 자외선(ultraviolet: UV) 센서, 근전도 (electromyography: EMG) 센서, 뇌파(electroencephalogram: EEG) 센서, 심전도(electrocardiogram: ECG) 센서, 적외선(infrared: IR) 센서, 초음파 센서, 홍채(iris) 센서, 또는 지문 센서를 포함할 수 있다. 센서 (들)는, 하나 이상의 가속도계들, 자이로스코프들, 및 기타 구성요소들을 포함할 수 있는, 관성 측정 장치 (inertial measurement unit)를 더 포함할 수 있다. 또한, 센서(들)는 여기에 포함된 상기 센서들 중 적 어도 하나를 제어하기 위한 제어 회로를 포함할 수 있다. 이러한 센서(들) 중 어떤 것이라도 전자 디바이스 내에 위치할 수 있다. 또한, 전자 디바이스는 전기 신호들을 가청 사운드들(audible sounds)로 변환할 수 있는 하나 이상의 스피 커들을 포함한다. 이하에서 설명되는 바와 같이, 하나 이상의 스피커들은 적어도 하나의 사용자에게 음악 콘텐트를 재생하는 데 이용될 수 있다. 하나 이상의 스피커들을 통해 재생되는 상기 음악 콘텐트는 상기 사용자(들)에 의한 음악 연주(musical performance)에 반주하는(accompany) 음악 콘텐트, 상기 사용자(들)에 의해 제공되는 입력과 관련된 음악 콘텐트, 또는 상기 사용자(들)에 의해 제공되는 입력에 기초하 여 생성된 음악 콘텐트를 포함할 수 있다. 제1 외부 전자 디바이스 또는 제2 외부 전자 디바이스는 웨어러블 디바이스이거나 또는 전자 디바이 스에 장착 가능한 웨어러블 디바이스(예를 들면, HMD)일 수 있다. 전자 디바이스가 전자 디바이스(예 를 들면, HMD)에 장착되는 경우, 전자 디바이스는 통신 인터페이스를 통해 전자 디바이스와 통 신할 수 있다. 전자 디바이스는 별도의 네트워크와 관련 없이 전자 디바이스와 통신하기 위해 전자 디바이스와 직접 연결될 수 있다. 전자 디바이스는 또한, 하나 이상의 카메라들을 포함하는, 안경과 같은, 증강 현실(augmented reality) 웨어러블 디바이스일 수 있다. 상기 무선 통신은, 셀룰러 통신 프로토콜(cellular communication protocol)로서, 예를 들면, 롱텀 에벌루션 (long term evolution: LTE), 롱텀 에벌루션-어드밴스드(long term evolution-advanced: LTE-A), 5세대 무선 시스템(5th generation wireless system: 5G), 밀리미터파 또는 60 GHz 무선 통신, 무선 USB, 코드 분할 다중 접속(code division multiple access: CDMA), 광대역 코드 분할 다중 접속(wideband code division multiple access: WCDMA), 범용 이동 통신 시스템(universal mobile telecommunication system: UMTS), 무선 광대역 (wireless broadband: WiBro), 또는 세계 이동 통신 시스템(global system for mobile communication: GSM) 중 적어도 하나를 이용할 수 있다. 상기 유선 연결은, 예를 들면, 범용 직렬 버스(universal serial bus: USB), 고 선명 멀티미디어 인터페이스(high definition multimedia interface: HDMI), 권장 표준 232(recommended standard 232: RS-232), 또는 재래식 전화 서비스(plain old telephone service: POTS) 중 적어도 하나를 포함 할 수 있다. 네트워크(162 또는 164)는, 컴퓨터 네트워크(예를 들면, 로컬 영역 네트워크(local area network: LAN) 또는 광역 네트워크(wide area network: WAN)), 인터넷, 또는 전화 네트워크와 같은, 적어도 하나의 통신 네트워크를 포함한다. 제1 및 제2 외부 전자 디바이스들(102 및 104) 및 서버는 각각 전자 디바이스와 동일 또는 상이한 유 형의 디바이스일 수 있다. 본 개시의 특정 실시예들에 따르면, 서버는 하나 이상의 서버들의 그룹을 포함 한다. 또한, 본 개시의 특정 실시예들에 따르면, 전자 디바이스 상에서 실행되는 동작들(operations) 전부 또는 일부는 다른 전자 디바이스 또는 다수의 다른 전자 디바이스들(예를 들면, 전자 디바이스들(102 및 104) 또는 서버) 상에서 실행될 수 있다. 나아가, 본 개시의 특정 실시예들에 따르면, 전자 디바이스가 어 떤 기능 또는 서비스를 자동적으로 또는 요청에 따라 수행해야 하는 경우, 전자 디바이스는, 상기 기능 또 는 서비스를 자체적으로 또는 추가적으로 실행하지 않고, 다른 디바이스(예를 들면, 전자 디바이스들(102 및 104) 또는 서버)에 대해 이들과 연관된 적어도 일부 기능들을 수행하도록 요청할 수 있다. 상기 다른 전자 디바이스(예를 들면, 전자 디바이스들(102 및 104) 또는 서버)는 상기 요청된 기능들 또는 추가적 기능들 을 실행하고 실행 결과를 전자 디바이스에 전달할 수 있다. 전자 디바이스는 수신된 결과를 그대로 또는 추가적으로 처리함으로써 요청된 기능 또는 서비스를 제공할 수 있다. 이를 위해, 예를 들면, 클라우드 컴 퓨팅(cloud computing), 분산 컴퓨팅(distributed com), 또는 클라이언트-서버 컴퓨팅(client-server computing) 기법이 이용될 수 있다. 도 1은 전자 디바이스가 네트워크(162 또는 164)를 통해 외부 전자 디 바이스 또는 서버와 통신하기 위해 통신 인터페이스를 포함하는 것을 도시하고 있지만, 본 개시 의 실시예들에 따르면, 전자 디바이스는 별도의 통신 기능 없이 독립적으로 동작될 수 있다. 서버는 전자 디바이스 상에 구현된 동작들(또는 기능들) 중 적어도 하나를 수행 또는 지원함으로써 전자 디바이스를 선택적으로(optionally) 지원할 수 있다. 예를 들면, 서버는, 전자 디바이스에 구현된 프로세서를 지원할 수 있는, 처리 모듈(processing module) 또는 프로세서를 포함할 수 있다. 도 1은 전자 디바이스를 포함하는 네트워크 구성의 일 예를 도시하고 있지만, 도 1에 대해 다양한 변 경이 이루어질 수 있다. 예를 들면, 네트워크 구성은 각 구성요소를 어떤 개수로 어떤 적절한 배치로도 포 함할 수 있다. 일반적으로, 컴퓨팅 및 통신 시스템들은 매우 다양한 구성으로 구현되며, 도 1은 본 개시의 범위 를 어떤 특정한 구성으로 제한하지 않는다. 또한, 도 1은 본 특허 문서에 개시된 다양한 특징들이 이용될 수 있 는 하나의 동작 환경(operational environment)을 도시하고 있지만, 이러한 특징들은 다른 어떤 적절한 시스템에서도 이용될 수 있다. 도 2는, 본 개시에 따른, 효과적인 음악적 특징들을 식별하기 위한 기계 학습용 제1 예시적 시스템을 도시 한다. 특히, 도 2에 도시된 시스템은, 관련된 음악적 특징들을 잠재 음악 공간(latent musical space)에 임베딩함으로써 상기 잠재 음악 공간을 학습하도록 트레이닝될 수 있는, 하나의 기계 학습 모델을 나타낼 수 있 다. 도 2에 도시된 시스템은, 예를 들면, 도 2의 시스템이 도 1의 네트워크 구성에서의 서버 를 이용하여 구현되거나 또는 서버에 의해 수행되는 경우, 도 1의 네트워크 구성에서 이용될 수 있다. 그러나, 시스템은 다른 어떤 적절한 디바이스(들)를 이용하여 다른 어떤 적절한 환경(들)에서도 구 현될 수 있음을 유의하라. 도 2의 예시적 실시예에서, 시스템은 심층 구조화된 시맨틱 모델(Deep Structured Semantic Model: DSS M)의 수정된 형태(modified form)를 이용하여 구현된다. 보다 구체적으로, 적대적(adversarial) DSSM이 시스템 을 구현하는 데 이용된다. 도 2에 도시된 바와 같이, 시스템은 임베딩 생성기(embedding generator)를 포함한다. 도 2는 임베딩 생성기 및 2개의 임베딩 생성기들(202' 및 202\")을 식별하고 있지만, 임베딩 생성기들(202' 및 202\")은 단순히 상이한 정보를 처리하는 데 이용되는 동일한 임베딩 생성기 를 나타낼 수 있음을 유의하라. 물론, 여기서 하나 초과의 임베딩 생성기도 또한 이용될 수 있다. 본 특정 예에서의 임베딩 생성기는 다수의 동작 계층들(operational layers)을 포함한다. 임베딩 생성기 내의 동작 계층들은 일반적으로, 비언어적 가청 입력 데이터(210a-210c)를 출력 임베딩들(212a-212c)로 각 각 변환하기 위해, 다양한 동작들을 수행하도록 동작한다. 각각의 출력 임베딩(212a-212c)은 상기 잠재 음악 공 간에서 연관된 비언어적 가청 입력 데이터(210a-210c)의 음악적 특징들을 나타낸다. 임베딩 생성기 내의 동작 계층들은, 비언어적 가청 입력 데이터(210a-210c)에 기초하여 출력 임베딩 (212a-212c)을 생성하기 위해, 어떤 적절한 동작들이라도 수행할 수 있다. 일부 실시예들에서, 임베딩 생성기 는, 하나 이상의 풀링(pooling) 계층들, 하나 이상의 정규화(normalization) 계층들, 하나 이상의 연결된 (connected) 계층들, 및/또는 하나 이상의 컨볼루션(convolution) 계층들과 같은, 동작 계층들을 포함하는, 컨볼루션 신경망(convolutional neural network)을 나타낸다. 각각의 풀링 계층은, 다음(next) 계층 에 대한 입력을 위해, 이전(prior) 계층으로부터의 출력들을 선택 또는 결합할(combine) 수 있다. 예를 들면, 최대 풀링을 이용하는 풀링 계층은 다음 계층에 대한 입력을 위해 이전 계층에서의 클러스터들(clusters)로부터 의 최대 출력들을 식별하며, 평균 풀링을 이용하는 풀링 계층은 다음 계층에 대한 입력을 위해 이전 계층에서의 클러스터들로부터의 출력들의 평균들을 식별한다. 각각의 정규화 계층은 다음 계층에 대한 입력을 위해 이전 계 층으로부터의 출력들을 정규화할 수 있다. 각각의 연결된 계층은 계층들 간에 정보를 라우팅하기(routing) 위한 연결들(connections)을 구성할 수 있다. 각각의 컨볼루션 계층은, 다음 계층으로 출력되는 결과를 생성하기 위 해, 컨볼루션 연산(convolution operation)을 입력에 적용할 수 있다. 여기서 라인들은 비인접(non- adjacent) 동작 계층들 간의 선택적 연결들(optional connections)을 나타내는 데 이용될 수 있으며, 이 는 하나의 계층에 의해 생성된 잔차들(residuals) 또는 기타 데이터가 비인접 계층에 제공될 수 있음 을 의미한다. 특정 실시예들에서, 임베딩 생성기는 완전 연결된(fully-connected) 컨볼루션 신경망을 나타 낼 수 있다. 그러나, 특정 유형의 기계 학습 알고리즘 및 여기서 임베딩 생성기에 이용되는 상기 계층들 간의 연결들은 필요에 따라 또는 원하는 바에 따라 달라질 수 있으며, 다른 유형의 기계 학습 알고리즘들이 잠 재 공간에 음악 콘텐트의 임베딩들을 생성할 수 있는 한, 상기 다른 유형의 기계 학습 알고리즘들이 여기에서 이용될 수 있음을 유의하라. 여기서 임베딩 생성기는 상이한 참조(reference) 입력 데이터(210a)를 처리하여 상이한 임베딩들(212a)을 생성하고, 상이한 긍정(positive) 입력 데이터(210b)를 처리하여 상이한 임베딩들(212b)을 생성하며, 부정 (negative) 입력 데이터(210c)를 처리하여 상이한 임베딩들(212c)을 생성하는 데 이용된다. 긍정 입력 데이터 (210b)는 참조 입력 데이터(210a)와 유사하다고 알려진 것이다(적어도 상기 임베딩들에 의해 표현되는 상기 음 악적 특징들에 관하여). 경우에 따라, 참조 입력 데이터(210a) 및 긍정 입력 데이터(210b)는 동일한 음악 구성 에서 인접한 소절들(passages) 또는 섹션들(sections)을 나타낼 수 있으며, 상기 둘 간의 유사성을 보장하는 데 도움이 된다. 부정 입력 데이터(210c)는 참조 입력 데이터(210a)와 비유사하다고 알려진 것이다(적어도 상기 임 베딩들에 의해 표현되는 상기 음악적 특징들에 관하여). 경우에 따라, 참조 입력 데이터(210a) 및 부정 입력 데 이터(210c)는 상이한 음악 구성들(예를 들면, 상이한 장르들(genres))에서 상이한 소절들 또는 섹션들을 나타낼 수 있으며, 상기 둘 간의 비유사성을 보장하는 데 도움이 된다. DSSM을 이용하여, q(z)가 x ∈ X에 대한 DSSM 함수 f(x)에 의해 생성된 길이 d의 모든 임베딩들의 집성된 사후 분포(aggregated posterior distribution)를 나타내는 경우, 상기 DSSM을 트레이닝하는 한 가지 목표는q(z)를, zi ~ Nd(μ, σ2)로 정의될 수 있는, 미리-정의된 원하는 분포(predefined desired distribution) p(z)와 매칭하는 것이며, 여기서 μ = 0이고 σ2 = 1이다. 이는 적대적 판별기를 임베딩 생성기의 마 지막 계층(last layer)에 연결함으로써 달성될 수 있다. 도 2는 적대적 판별기 및 2개의 적대적 판별기들 (216' 및 216\")을 식별하고 있지만, 적대적 판별기들(216' 및 216\")은 단순히 상이한 정보를 처리하는 데 이용 되는 동일한 적대적 판별기를 나타낼 수 있음을 유의하라. 물론, 본 명세서에서 하나 초과의 적대적 판별 기도 또한 이용될 수 있다. 적대적 판별기는 임베딩 생성기(이는 자체가 DSSM임)와 연합하여 적대적 으로 트레이닝된다. 적대적 판별기는, 일반적으로, 생성된 임베딩들(212a-212c)을 q(z)로부터 샘플링된 벡 터들과 구별하도록 동작한다. 이에 의해, 적대적 판별기는 임베딩 생성기로부터의 임베딩들(212a- 212c)의 집성된 사후 분포가 미리-정의된 분포를 따르는 것을 보장하는 데 도움이 된다. 일부 실시예들에서, 상 기 미리-정의된 분포는 가우시안(Gaussian)이며 연속적일 수 있지만, 다른 미리-정의된 분포들(예를 들면, 균일 (uniform) 분포)이 이용될 수 있다. 도 2에서 알 수 있는 바와 같이, 적대적 판별기는, 적대적 판별기를 지원하기 위해 원하는 기능들 (functions)을 수행하는 데 이용될 수 있는, 몇 개의 동작 계층들을 포함한다. 실제 판별(actual discrimination)을 수행하는 데 오직 몇 개의 계층들만을 이용함으로써, 음악 콘텐트의 분류를 위한 대부 분의 양호한 특징들(good features)이 임베딩 생성기에 의해 학습되어야 할 것이다. 이는 시스템으로 하여금, 입력 데이터(210a-210c) 자체를 효율적으로 인코딩할 뿐 아니라 입력 데이터(210a-210c) 자체를 관련 없는 입력들과 효과적으로 구별할 수 있는 방식으로, 입력 데이터(210a-210c)를 임베딩하도록 한다. 여기에서는 3개의 동작 계층들이 도시되어 있지만, 적대적 판별기는 어떤 적절한 수의 동작 계층들이라도 포함할 수 있다. 손실 함수는 시스템의 트레이닝 시 임베딩 생성기를 구성하는 신경망(들) 또는 기타 기계 학습 알고리즘(들)에 대한 적절한(proper) 파라미터들을 설정하는 것을 돕는 데 이용된다. 예를 들면, 손실 함수 는 확률적 경사 하강법(stochastic gradient descent)과 같은 접근법들을 이용한 트레이닝 시 최소화될 수 있다. 표준 DSSM 트레이닝은, 관련 없는 아이템들을 더 멀리 밀어내면서 관련된 아이템들에 대해 서로 더 가까운(거리 메트릭(distance metric)에 따라) 임베딩들을 생성하기 위해, DSSM의 파마리터들을 명시적으로 트레이닝하기 때 문에, 표준 DSSM 트레이닝은 메트릭 학습(metric learning)에 적합하다. 그러나, 부정 예들(negative examples)의 수 및 쉬운 예 대 어려운 예의 비(ratio of easy-to-hard examples)는 보통 쉬운 쪽으로 크게 치 우쳐 있다. 이는 종종 불량한 성능을 초래하는데, 왜냐하면 많은 예들이 역전파(backpropagation) 시 실제 의미 있는 업데이트를 제공하지 않는 매우 작은 손실로 제약 조건(constraint)을 충족할 수 있기 때문이다. 이는 전 형적으로 높은 클래스 간 분산(inter-class variance) 및 낮은 클래스 내 분산(intra-class variance)을 초래 하여, 세분화된 카테고리화 또는 의미 있는 유사도 측정(음악에 중요함)을 어렵거나 불가능하게 만든다. 이 문 제를 해결하기 위해, 과거에는, 특히 어려운 예들이 데이터세트로부터 수동으로 마이닝되어(mined) 상이한 트레 이닝 스테이지들(stages)에서 이용되는, 부트스트랩(bootstrapping) 방법이 이용되었다. 불행하게도, 이는 트레 이닝 프로세스에서 수동 개입을 필요로 한다. 일부 실시예들에서, 적대적 판별기의 사용은 본질적으로, 임베딩 생성기에 의해 생성된 임베딩들에 미리-정의된 분포를 강제함으로써(enforcing), 이 문제를 완화하는 데 도움이 된다. 트레이닝 시, 대부분의 예 들이 유사도 제약 조건(similarity constraint)을 쉽게 충족하는 학습된 공간을 허용하지 않는 미리-정의된 분 포를 고수하면서, 원하는 유사도 메트릭을 달성하는 방법을 찾기 위해, 임베딩 생성기의 파라미터들이 수 정될 수 있다. 일부 실시예들에서, 도 2에 도시된 시스템은 2개의 스테이지들(stages)로 트레이닝될 수 있다. 제1 스테이 지에서, 표준 또는 기타 적합한 DSSM 트레이닝 방법이 임베딩 생성기를 트레이닝하는 데 이용될 수 있으며, 손실(예를 들면, 소프트맥스 손실(softmax loss))은 이 스테이지 동안 부정 예들(negative examples) 을 이용하여 계산될 수 있다. 제2 스테이지에서, 임베딩 생성기 및 적대적 판별기는, 적대적 판별기 가 임베딩 생성기로 하여금 미리-정의된 분포 p(z)로부터 샘플링된 것처럼 보이는 임베딩들을 생성하 도록, 트레이닝된다. 따라서, 시스템의 파라미터들은 2개의 상이한 손실들에 따라 최적화되는데, 하나의 손실은 유사도 메트릭을 학습하며 다른 하나의 손실은 상기 임베딩들의 집성된 사후 분포가 미리-정의된 분포 (이는 일부 실시예들에서 가우시안이며 연속적일 수 있음)를 충족하도록 데이터를 설명하는 것을 학습한다. 상기 트레이닝의 제1 스테이지에 대하여, 임베딩 생성기는 일부 실시예들에서 유클리드 유사도(Euclidean similarity)를 이용하여 트레이닝될 수 있다. 2개의 임베딩들 간의 유클리드 유사도는 다음과 같이 표현될 수 있다:"}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 및 는 상기 2개의 임베딩들을 나타내고, sim( , )는 상기 2개의 임베딩들 간의 유클리드 유사도 를 나타내며, D( , )는 잠재 특징 공간(latent feature space)에서 상기 2개의 임베딩들 간의 유클리드 거리 메트릭(Euclidean distance metric)을 나타낸다. 본 예에서, 거리 메트릭이 유클리드 거리의 관점에서 표현되어 있지만, 다른 거리 관점들(예를 들면, 코사인 거리(cosine distance))이 거리 메트릭으로 이용될 수 있다. 일부 실시예들에서 P( | )를 계산하기 위해 부정 예들이 소프트맥스 함수에 포함될 수 있으며, 여기서 은 재구성된 벡터(reconstructed vector) 또는 다른 임베딩(other embedding)을 나타내고 는 입력 벡터 또는 다른 임베딩 을 나타낸다. 이는 다음과 같이 표현될 수 있다:"}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "시스템은 일부 실시예들에서, 예를 들면, 확률적 경사 하강법을 이용하여, 손실 함수를 최소화함으로 써 시스템의 파라미터들을 학습하도록 임베딩 생성기를 트레이닝한다. 이는 다음과 같이 표현될 수 있다:"}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "상기 트레이닝의 제2 스테이지에 대하여, 임베딩 생성기 및 적대적 판별기를 트레이닝하기 위해 일부 실시예들에서 생성적 적대 네트워크(generative adversarial network: GAN) 트레이닝 절차가 이용될 수 있다. GAN 트레이닝 절차에서, 먼저 적대적 판별기가 생성된 임베딩들(212a-212c)을 q(z)로부터 샘플링된 벡터들 또는 다른 임베딩들과 구별하도록 트레이닝된다. 다음으로, 임베딩 생성기가 연관된 적대적 판별기를 기만하도록 트레이닝된다. 일부 실시예들은 상기 GAN 트레이닝 절차의 결정적 버전(deterministic version)을 이용하며, 여기서 확률성(stochasticity)은 오직 데이터 분포로부터 비롯되고, 추가적인 랜덤성(randomness)이 포함될 필요가 없다. 트레이닝은, 식 이 수렴할 때까지, DSSM 절차를 이용하는 상기 제1 스테이지와 GAN 절차를 이용하는 상기 제 2 스테이지 사이를 교번한다. DSSM 손실들에 비해 상기 GAN 절차에 대한(특히 임베딩 생성기를 업데이트하 기 위한) 보다 높은 학습 속도(learning rate)가 원하는 결과를 얻는 데 도움이 될 수 있다. 그렇지 않은 경우, GAN-기반의 업데이트들은 거의 효과가 없거나 또는 전혀 효과가 없을 수 있고, 이에 따라 결과적으로 어떠한 적 대적 구성요소들도 없이 표준 DSSM과 매우 유사한 거동을 하는 모델이 초래될 수 있다. 도 3은, 본 개시에 따른, 효과적인 음악적 특징들을 식별하기 위한 기계 학습용 제2 예시적 시스템을 도시 한다. 특히, 도 3에 도시된 시스템은, 관련된 음악적 특징들을 잠재 음악 공간에 임베딩함으로써 상기 잠 재 음악 공간을 학습하도록 트레이닝될 수 있는, 다른 기계 학습 모델을 나타낼 수 있다. 도 3에 도시된 시스템 은, 예를 들면, 도 3의 시스템이 도 1의 네트워크 구성에서의 서버를 이용하여 구현되거나 또는 서버에 의해 수행되는 경우, 도 1의 네트워크 구성에서 이용될 수 있다. 그러나, 시스템은 다른 어떤 적절한 디바이스(들)를 이용하여 다른 어떤 적절한 환경(들)에서 구현될 수 있음을 유의하라. 도 3의 예시적 실시예에서, 시스템은, 일종의 샴 네트워크 패러다임(Siamese network paradigm)을 나타낸 다고 말할 수 있는, 적대적 인접 모델(adversarial adjacency model)을 이용하여 구현된다. 도 3에 도시된 바와 같이, 시스템은 임베딩 생성기를 포함한다. 도 3은 임베딩 생성기 및 임베딩 생성기(302')를 식 별하고 있지만, 임베딩 생성기(302')는 단순히 상이한 정보를 처리하는 데 이용되는 동일한 임베딩 생성기(30 2)를 나타낼 수 있음을 유의하라. 물론, 여기서 하나 초과의 임베딩 생성기도 또한 이용될 수 있다. 본 특정한 예에서의 임베딩 생성기는 다수의 동작 계층들을 포함하며, 이들은 일반적으로 비언어적 가청 입력 데이터(310a-310b)를 출력 임베딩들(312a-312b)로 각각 변환하기 위한 다양한 동작들을 수행하도록 동작한다. 각각의 출력 임베딩(312a-312b)은 정의된 잠재 음악 공간에서 연관된 비언어적 가청 입력 데이터(310a-310b)의 음악적 특징들을 나타낸다. 임베딩 생성기 내의 동작 계층들은 비언어적 가청 입력 데이터(310a-310b)에 기초하여 출력 임베딩 (312a-312b)을 생성하기 위한 어떤 적절한 동작들이라도 수행할 수 있다. 일부 실시예들에서, 임베딩 생성기 는, 하나 이상의 풀링 계층들, 하나 이상의 정규화 계층들, 하나 이상의 연결된 계층들, 및/또는 하나 이 상의 컨볼루션 계층들과 같은, 동작 계층들을 포함하는, 컨볼루션 신경망을 나타낸다. 라인들은 비인 접 동작 계층들 간의 선택적 연결들(optional connections)을 나타내는 데 이용될 수 있으며, 이는 하나의 계층에 의해 생성된 잔차들(residuals) 또는 기타 데이터가 비인접 계층에 제공될 수 있음을 의미한 다. 특정 실시예들에서, 임베딩 생성기는 완전 연결된(fully-connected) 컨볼루션 신경망을 나타낼 수 있 다. 그러나, 특정 유형의 기계 학습 알고리즘 및 여기서 임베딩 생성기에 이용되는 상기 계층들 간의 연결 들은 필요에 따라 또는 원하는 바에 따라 달라질 수 있으며, 다른 유형의 기계 학습 알고리즘들이 잠재 공간에 서 음악 콘텐트의 임베딩들을 생성할 수 있는 한, 상기 다른 유형의 기계 학습 알고리즘들이 여기에서 이용될 수 있음을 유의하라. 여기서 임베딩 생성기는 상이한 참조 입력 데이터(310a)를 처리하여 상이한 임베딩들(312a)을 생성하고, 상이한 긍정 또는 부정 입력 데이터(310b)를 처리하여 상이한 임베딩들(312b)을 생성하는 데 이용된다. 긍정 입 력 데이터(310b)는 참조 입력 데이터(310a)와 유사하다고 알려진 것이고 부정 입력 데이터(310b)는 참조 입력 데이터(310a)와 비유사하다고 알려진 것이다(적어도 상기 임베딩들에 의해 표현되는 상기 음악적 특징들에 관하 여). 경우에 따라, 참조 입력 데이터(310a) 및 긍정 입력 데이터(310b)는 동일한 음악 구성에서 인접한 소절들 (passages) 또는 섹션들(sections)을 나타낼 수 있으며, 이는 상기 둘 간의 유사성을 보장하는 데 도움이 된다. 경우에 따라, 참조 입력 데이터(310a) 및 부정 입력 데이터(310c)는 상이한 음악 구성들(예를 들면, 상이한 장 르들)에서 상이한 소절들 또는 섹션들을 나타낼 수 있으며, 이는 상기 둘 간의 비유사성을 보장하는 데 도움이 된다. 도 2에서 DSSM들을 이용하는 것과 달리, 도 3에서의 임베딩들(312a-312b)은 원하는 메트릭에 대해 직접 최적화 되지 않는다. 대신에, 인접성 판별기(adjacency discriminator)를 이용하여 구현될 수 있는, 분류기가 2개 의 입력 단위들(임베딩(312a) 및 임베딩(312b))이 관련되어 있는지 여부를 결정하도록 트레이닝된다. 인접성은 수동으로 설계된 유사도 라벨들(manually-designed similarity labels) 대신에 자기-지도 대리인(self- supervising surrogate)으로서 이용되기 때문에, 여기서 분류기는 2개의 임베딩들(312a 및 312b)이 음악 구성에서 인접해 있는 음악 콘텐트를 나타내는지 여부를 결정하도록 트레이닝될 수 있다. 일부 실시예들에서, 분류기의 하나의 버전은 결합된 임베딩들을 생성하되, 각각의 결합된 임베딩은 단일 분류기 입력을 구성하도록 하나의 임베딩(312a)을 하나의 임베딩(312b)과 연결함으로써(concatenating) 형성된 다. 따라서, 상기 결합된 임베딩들은 연결된(concatenated) 벡터들을 나타낼 수 있다. 상기 결합된 임베딩들은 각각의 결합된 임베딩으로부터 이진 분류(binary classification)를 생성하도록 분류기를 트레이닝하는 데 이용된다. 상기 이진 분류는 임베딩(312b)과 연결된 임베딩(312a)이 관련되어 있음(임베딩(312b)이 긍정 입력 데이터(310b)를 위한 것인 경우) 또는 관련이 없음(임베딩(312b)이 부정 입력 데이터(310b)를 위한 것인 경우) 을 식별할 수 있다. 그러나, 여기서 하나의 목표는 단일 단위(단일 임베딩(312a 또는 312b))를 임베딩할 수 있 는 능력을 포함할 수 있다. 그러므로, 시스템의 일부 실시예들은, 임베딩 생성기의 하위 계층들이 동 일하고, 임베딩들은 몇 개의 계층들이 상기 네트워크로 깊이 들어갈 때까지 연결되지 않는, 묶인 가중치들(tied weights)을 이용한다. 다시 말하면, 2개의 입력들(입력 데이터(310a) 및 입력 데이터(310b))가 독립적으로 임베 딩되지만, 상기 임베딩들을 수행하는 데 동일한 파라미터들이 이용된다. 분류기는 연결된 임베딩들(312a-312b)을 이용하여 관련된 입력과 관련 없는 입력을 구별하도록 구성된다. 거듭 말하면, 분류기에서 실제 구별을 수행하는 데 오직 몇 개의 계층들만을 이용함으로써, 음악 콘텐트의 분류를 위한 대부분의 양호한 특징들이 임베딩 생성기에 의해 학습되어야 할 것이다. 이는 시스템으 로 하여금, 입력 데이터(310a-310b) 자체를 효율적으로 인코딩할 뿐 아니라 입력 데이터(310a-310b) 자체를 관 련 없는 입력들과 효과적으로 구별할 수 있는 방식으로, 입력 데이터(310a-310b)를 임베딩하도록 한다. 시스템 은 서로 더 가까운 관련된 단위들을 임베딩함으로써 이를 달성할 수 있다. 비교의 편의를 위해, 시스템 의 아키텍처의 일부는 도 2에 도시된 동일한 DSSM-유형의 네트워크들을 이용할 수 있음을 유의하라. 거듭 말하면, 적대적 판별기는 임베딩 생성기의 마지막 계층에 연결될 수 있다. 도 3은 적대적 판별 기 및 적대적 판별기(316')를 식별하고 있지만, 적대적 판별기(316')는 단순히 상이한 정보를 처리하는 데 이용되는 동일한 적대적 판별기를 나타낼 수 있음을 유의하라. 물론, 여기서 하나 초과의 적대적 판별기도 또한 이용될 수 있다. 적대적 판별기는 적대적 판별기와 동일 또는 유사한 방식으로 동작할 수 있다. 거듭 말하면, 여기서 하나의 목표는 임베딩 생성기로부터의 임베딩들(312a-312b)의 집성된 사후 분포가 미 리-정의된 분포를 따르는 것이다. 일부 실시예들에서, 상기 미리-정의된 분포는 가우시안(Gaussian)이고 연속적일 수 있지만, 다른 미리-정의된 분포들(예를 들면, 균일 분포)이 이용될 수 있다. 일부 실시예들에서, 도 3에 도시된 시스템은 2개의 스테이지들로 트레이닝될 수 있다. 제1 스테이지에서, 분류기는 관련된 입력과 관련 없는 입력을 구별하도록 트레이닝된다. 제2 스테이지에서, 임베딩 생성기 및 적대적 판별기는, 적대적 판별기가 임베딩 생성기로 하여금 미리-정의된 분포 p(z)로 부터 샘플링된 것처럼 보이는 임베딩들을 생성하게 하도록, 트레이닝된다. 따라서, 상기 모델의 임베딩 부분은 상기 트레이닝 프로세스의 2개의 스테이지들 동안 업데이트될 수 있다. 상기 트레이닝의 제1 스테이지 동안, 일부 실시예들에서 분류기는 2개의 클래스들(관련됨(related) 및 관 련 없음(non-related))이 있는 교차 엔트로피(cross entropy)를 이용하여 트레이닝될 수 있다. 이는 다음과 같 이 표현될 수 있다:"}
{"patent_id": "10-2022-7004952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서 M은 클래스 수(본 예에서는 2)를 나타내고, y'는 예측된 확률을 나타내며, y는 그라운드 트루스(ground truth)를 나타낸다. 상기 트레이닝의 제2 스테이지 동안, 상술된 GAN 트레이닝 절차가 이용될 수 있다. 구현에 따라, 도 3에 도시된 접근법은, 도 2에 도시된 접근법과 비교하여, 본질적으로 더 안정적이고 2개의 손실들 간 에 학습 속도들의 튜닝(tuning)이 더 적을 수 있다. 여기서 도 2 및 도 3에 도시된 2개의 접근법들은 수많은 음악 소절들을 잠재 음악 공간에 임베딩함으로써 상기 잠재 음악 공간을 학습하는 데 이용될 수 있으며, 어느 접근법에서도 결과적인 모델은 다양한 기능들 (functions)을 수행하는 데 이용될 수 있음을 유의해야 한다. 예를 들면, 사용자 입력은, 상기 사용자 입력에 가장 가까운 임베딩(들)을 식별하기 위해, 상기 잠재 공간으로 투사될 수 있다. 다음으로, 상기 가장 가까운 임 베딩(들)은 상기 사용자를 위한 음악 콘텐트를 식별, 순위화(rank), 재생(play), 또는 생성하는 데 이용될 수 있다. 여기서 이러한 접근법들의 실행 또는 이용은 입력-불가지론적(input-agnostic)일 수 있음도 또한 유의해 야 한다. 즉, 도 2 및 도 3에 도시된 접근법들은 음악 콘텐트 및 기타 비언어적 가청 데이터가 어떻게 표현되는 지에 상관 없이 성공적으로 동작할 수 있다. 따라서, 음악-기반 모델의 성능이 데이터의 입력 표현(input representation)에 의해 결정될 수 있는 다른 접근법들과 달리, 본 명세서에서의 접근법들은 음악의 어떤 적절 한 표현이라도 이용하여 기계 학습 모델을 트레이닝할 수 있다. 이러한 표현들은 음악의 기호적 표현들 (symbolic representations) 및, 멜-주파수 켑스트럼 계수(mel-frequency cepstral coefficient: MFCC) 시퀀스 들, 스펙트로그램들(spectrograms), 진폭 스펙트럼들(amplitude spectrums), 또는 크로마그램들(chromagrams) 과 같은, 음악의 원시 오디오 표현들(raw audio representations)을 포함할 수 있다. 도 2 및 도 3은 효과적인 음악 특징들을 식별하기 위한 기계 학습용 시스템들(200 및 300)의 두 가지 예들을 도 시하고 있지만, 도 2 및 도 3에 대해 다양한 변경이 이루어질 수 있다. 예를 들면, 도 2 및 도 3에서 임베딩들 을 생성하는 데 이용되는 상기 임베딩 생성기들을 구현하는 특정 기계 학습 알고리즘들은 상술된 것들과는 달라 질 수 있다. 또한, 상기 다양한 임베딩 생성기들, 적대적 판별기들, 및 분류기들에 도시된 동작 계층의 개수들 은 필요에 따라 또는 원하는 바에 따라 달라질 수 있다. 도 4 및 도 5는, 본 개시에 따른, 효과적인 음악 특징들을 식별하도록 트레이닝된 기계 학습용 제1 예시적 애플 리케이션을 도시한다. 특히, 도 4 및 도 5는, 기계 학습 모델(상술된 바와 같이 트레이닝될 수 있음)이 특 정한 최종-사용자(end-user) 애플리케이션을 수행하는 데 이용될 수 있는, 제1 예시적 방법을 도시한다. 도 4 및 도 5에 도시된 애플리케이션은, 예를 들면, 애플리케이션이 도 1의 네트워크 구성에서의 적 어도 하나의 서버 및 적어도 하나의 전자 디바이스(101, 102, 104)를 이용하여 수행되는 경우, 도 1의 네 트워크 구성에서 이용될 수 있다. 그러나, 애플리케이션은 다른 어떤 적절한 디바이스(들)를 이용하 여 다른 어떤 적절한 환경(들)에서도 수행될 수 있음을 유의하라. 도 4 및 도 5에 도시된 바와 같이, 본 예에서 음악 콘텐트가 적어도 하나의 사용자에 의한 음악 연주에 반주하 도록 생성되게 해 달라는 요청을 나타내는, 입력 발화(input utterance)가 수신된다. 일부 실시예들에서, 입력 발화는 사용자의 전자 디바이스(101, 102, 104)에서 수신되고 전자 디바이스(101, 102, 104)의 적어 도 하나의 센서(예를 들면, 마이크)에 의해 감지될 수 있다. 여기서 입력 발화는 디지털화되어 전자 디바이스(101, 102, 104)로부터, 하나의 서버 또는 다수의 서버들을 이용하여 구현될 수 있는, 클라 우드-기반 플랫폼(cloud-based platform)으로 전달된다. 상기 클라우드-기반 플랫폼의 자동 음성 인식(automatic speech recognition: ASR) 및 유형 분류기(type classifier) 기능은, 입력 발화를 이해하고 입력 발화에 응답하여 발생할 액션(action)의 유형을 식별하기 위해, 입력 발화의 상기 디지털화된 버전을 분석한다. 예를 들면, ASR 및 유형 분류기 기능은 입력 발화의 의미(meaning)를 도출하기 위해 자연어 이해(natural language understanding: NLU)를 수행 할 수 있다. ASR 및 유형 분류기 기능은, 정적 기능(static function) 또는 연속적 기능(continuous function)이 입력 발화에 대한 응답을 생성하는 데 이용되어야 하는지 여부를 결정하기 위해, 입력 발화의 상기 도출된 의미를 이용할 수 있다. ASR 및 유형 분류기 기능은 음성 인식을 수행하고 제공 될 응답의 유형을 선택하기 위한 어떤 적절한 논리(logic)라도 지원한다. 선택된 경우, 정적 기능은 입력 발화 및 이것의 도출된 의미를 분석하고 표준 응답(standard response)을 생성할 수 있다. 표준 응답은 상기 적어도 하나의 사용자에게 제시하기 위해 전자 디바 이스(101, 102, 104)에 제공될 수 있다. 정적 기능은 종종 일단 표준 응답이 제공되면 입력 발화 의 처리가 완료될 수 있다는 사실에 의해 특징지어진다. 반대로, 연속적 기능은 입력 발화 또는 이것의 도출된 의미를 분석하고, 상기 사용자 요청에 대한 보다 연속적인 응답을 제공하기 위해 전자 디바이스 (101, 102, 104)와 상호작용할 수 있다. 본 예에서, 상기 요청은 음악 콘텐트가 음악 연주에 반주하도록 생성되 게 해 달라는 것이기 때문에, 연속적 기능은 전자 디바이스(101, 102, 104)로 하여금 상기 음악 연주에 반 주하는 음악 콘텐트를 생성 및 재생하도록 할 수 있다. 여기서 상기 사용자 요청을 충족하기 위해, 비언어적 사용자 입력이 적어도 하나의 사용자로부터 제공되고 전자 디바이스(101, 102, 104)의 하나 이상의 분석 기능들에 의해 처리된다. 여기서 비언어적 사용자 입력 은 상기 적어도 하나의 사용자에 의한 상기 음악 연주를 나타낸다. 예를 들면, 비언어적 사용자 입력(41 2)은 하나 이상의 악기들을 연주하는 하나 이상의 사용자들에 의해 생성될 수 있다. 사용자 입력은, 예를 들면, 전자 디바이스(101, 102, 104)의 마이크를 이용하여, 전자 디바이스(101, 102, 104)에 의해 캡처될 수 있 다. 분석 기능의 아날로그-디지털 기능은 캡처된 사용자 입력을 상응하는 디지털 데이터로 변환 하는 데 이용될 수 있으며, 상기 디지털 데이터는 트레이닝된 기계 학습 모델(예를 들면, 도 2의 시스템 또는 도 3의 시스템)을 위한 입력 데이터의 하나 이상의 세트들을 생성하기 위해 분석 기능에 의해 이용된다. 상기 트레이닝된 학습 모델은 입력 데이터의 상기 하나 이상의 세트들을 이용하여, 상기 학습된 잠재 공간에 투사된 사용자 입력을 나타내는, 하나 이상의 임베딩들을 생성한다. 여기에 도시 되진 않았지만, 하나 이상의 임베딩들의 생성 전에, 디지털화된 사용자 입력에 대해 다양한 전처리 동작들(pre-processing operations)이 수행될 수 있다. 여기서, 피치 검출(pitch detection)과 같은, 어떤 적 절한 전처리 동작들이라도 수행될 수 있다. 하나 이상의 임베딩들은, 본 예에서 상기 음악 연주에 반주하는 음악 콘텐트를 재생하는 것(예를 들면, 전 자 디바이스(101, 102, 104)의 스피커를 통해)을 포함하는, 하나 이상의 보조 액션들(assistant actions)을 결정하는 데 이용된다. 예를 들면, 하나 이상의 임베딩들은 하나 이상의 수정된 임베딩들 을 생성하도록 교란될(perturbed) 수 있다. 하나 이상의 임베딩들의 교란은, 예를 들면, 일부 특정된 기준들(specified criteria)에 따라 하나 이상의 임베딩들에 포함된 값들을 수정하는 것과 같이, 어떤 적 절한 방식으로도 발생할 수 있다. 하나 이상의 임베딩들 및/또는 하나 이상의 수정된 임베딩들은 상기 사용자(들)에게 재생될 음악 콘 텐트를 선택 또는 생성하는 데 이용될 수 있다. 예를 들면, 하나 이상의 임베딩들 및/또는 하나 이상의 수 정된 임베딩들은 검색 동작(retrieval operation)의 일부로 상기 잠재 공간에서 하나 이상의 유사한 임베딩들을 식별하는 데 이용될 수 있다. 여기서, 상기 잠재 공간 내 상기 하나 이상의 유사한 임베딩들은 상기 음악 연주와 유사한 음악 콘텐트와 연관되며, 이에 따라 전자 디바이스(101, 102, 104)는 상기 하나 이상의 유 사한 임베딩들과 연관된 상기 음악 콘텐트를 검색하고 이를 상기 사용자(들)에 대해 재생할 수 있다. 다른 예로, 하나 이상의 수정된 임베딩들은 디코딩되어 생성 동작의 일부에서 도출된 음악 콘텐트를 생성 하는 데 이용될 수 있으며, 전자 디바이스(101, 102, 104)는 상기 도출된 음악 콘텐트를 상기 사용자(들)에 대 해 재생할 수 있다. 더 많은 비언어적 사용자 입력이 수신되고 추가적인 음악 콘텐트(검색된 것이든 또는 생성된 것이든 상관 없음)가 상기 사용자(들)에 대해 재생됨에 따라, 이 프로세스는 반복될 수 있다. 여기서 단일 전자 디바이스(101, 102, 104)가 적어도 하나의 사용자에 의해 이용되는 것으로 설명되어 있지만, 도 4 및 도 5에 도시된 애플리케이션은 다수의 전자 디바이스들(101, 102, 104)을 이용하여 수행될 수 있 음을 유의하라. 예를 들면, 입력 발화는 제1 전자 디바이스(101, 102, 104)를 통해 수신될 수 있고, 음악 콘텐트는 제2 전자 디바이스(101, 102, 104)를 통해 재생될 수 있다. 제2 전자 디바이스(101, 102, 104)는, 예 를 들면, 이전 구성에 기초하여 또는 입력 발화에 기초하여 식별되는 것과 같이, 어떤 적절한 방식으로도식별될 수 있다. 도 6 및 도 7은, 본 개시에 따른, 효과적인 음악적 특징들을 식별하도록 트레이닝된 기계 학습용 제2 예시적 애 플리케이션을 도시한다. 특히, 도 6 및 도 7은, 기계 학습 모델(상술된 바와 같이 트레이닝될 수 있음)이 특정한 최종-사용자 애플리케이션을 수행하는 데 이용될 수 있는, 제2 예시적 방법을 도시한다. 도 6 및 도 7에 도시된 애플리케이션은, 예를 들면, 애플리케이션이 도 1의 네트워크 구성에서의 적어도 하나의 서버 및 적어도 하나의 전자 디바이스(101, 102, 104)를 이용하여 수행되는 경우, 도 1의 네트워크 구성 에서 이용될 수 있다. 그러나, 애플리케이션은 다른 어떤 적절한 디바이스(들)를 이용하여 다른 어떤 적절한 환경(들)에서도 수행될 수 있음을 유의하라. 도 6에 도시된 바와 같이, 본 예에서 음악 콘텐트가 구성되도록(composed) 해 달라는 요청을 나타내는, 사용자 입력이 수신된다. 여기서, 사용자 입력은 다양한 형태들을 만들 수 있으며, 상기 형태들의 몇 가지 예들이 도 6에 도시되어 있다. 예를 들면, 사용자 입력은 기존 음악 콘텐트와 유사한 음악 콘텐트의 구성 (composition)을 요청할 수 있거나, 또는 사용자 입력은 사용자에 의해(예를 들면, 허밍(humming) 또는 악 기 연주에 의해) 제공되는 비언어적 입력과 유사한 음악 콘텐트의 구성을 요청할 수 있다. 여기서, 상기 사용자 에 의해 제공되는 어떤 비언어적 입력은, 예를 들면, 약 3초 내지 약 10초와 같이, 지속시간이 상대적으로 짧을 수 있다. 여기에 도시되진 않았지만, 사용자 입력은 도 4의 입력 발화와 유사한 경로를 따를 수 있다. 즉, 사용자 입력은 클라우드-기반 플랫폼에 제공되며, 사용자 입력에 대한 응답을 생성하는 데 연속적 기능이 이용되어야 함을 결정할 수 있는, ASR 및 유형 분류기 기능에 의해 처리될 수 있다. 생성 기능은 어떤 특정된 음악 콘텐트를 시작 시드(starting seed)로 이용하고, 제시 기능(presentation function)을 통해 상기 사용자에게 재생하기 위한 도출된 음악 콘텐트를 생성한다. 예를 들면, 상기 사용 자가 기존 음악 콘텐트와 유사한 음악의 구성을 요청하는 경우, 사용자의 전자 디바이스(101, 102, 104)는 상기 잠재 공간에서 상기 기존 음악 콘텐트의 하나 이상의 임베딩들을 식별(또는 생성)할 수 있고, 상기 하나 이상의 임베딩들을 이용하여 상기 도출된 음악 콘텐트를 생성할 수 있다. 상기 사용자가 상기 사용자에 의해 제공되는 음악 입력과 유사한 음악의 구성을 요청하는 경우, 사용자의 전자 디바이스(101, 102, 104)는 상기 잠재 공간에 서 상기 사용자의 음악 입력의 하나 이상의 임베딩들을 생성할 수 있고, 상기 하나 이상의 임베딩들을 이용하여 상기 도출된 음악 콘텐트를 생성할 수 있다. 특정한 예로, 상기 사용자로부터의 상기 음악 입력의 상기 하나 이 상의 임베딩들은, 임베딩(들)이 상기 사용자로부터의 상기 음악 입력의 상기 임베딩들과 유사한, 기존 음악 구 성(preexisting musical composition)을 선택하는 데 이용될 수 있으며, 상기 기존 음악 구성은 시드(seed)로 서 이용될 수 있다. 생성 기능의 하나의 예시적 구현이 도 7에 도시되어 있으며, 도 7은 입력 데이터(702a-702n)의 복수의 세 트들을 수신하는 생성 기능을 도시하고 있다. 여기서, 입력 데이터(702a-702n)는 상기 도출된 음악 콘텐트 를 생성하는 데 이용될 상기 시드를 나타낸다. 일부 실시예들에서, 입력 데이터(702a-702n)는 기존 음악 구성의 상이한 부분들(예를 들면, 5초 내지 10초 섹션들)을 나타낼 수 있다. 상기 기존 음악 구성은 상기 사용자에 의 해 구체적으로 식별된 상기 기존 음악 콘텐트를 나타낼 수 있거나, 또는 상기 기존 음악 구성은 상기 사용자의 음악 입력에 기초하여 선택된 기존 음악 콘텐트를 나타낼 수 있다. 입력 데이터(702a-702n)는, 트레이닝된 기계 학습 모델(예를 들면, 도 2의 시스템 또는 도 3의 시스템)을 이용하여, 상이한 임베딩들로 변환 된다. 임베딩들은, 도출된 임베딩들을 생성하도록 임베딩들을 처리하는, 적어도 하나의 순환 신 경망(recurrent neural network: RNN)에 제공된다. 도출된 임베딩들은, 입력 데이터(702a-702n)로 표현된 상기 음악 시드에 기초하여 생성되는, 상기 잠재 공간 내 임베딩들을 나타낸다. 다음으로, 도출된 임베 딩들은 디코딩되어(상술된 생성 동작과 유사함), 하나 이상의 사용자들에게 재생될 수 있는, 상기 도 출된 음악 콘텐트를 생성할 수 있다. 여기에 도시된 바와 같이, 적어도 하나의 입력 데이터 세트에 대해 적어도 하나의 순환 신경망에 의해 생 성된 상기 출력은 추가적인 입력 데이터 세트들의 처리에 이용하기 위해 피드포워드(feed-forward) 방식으로 제 공될 수 있다. 이는 적어도 하나의 순환 신경망이, 일반적으로 서로 일치하는(현저히 상이한 것이 아니 라), 상기 도출된 음악 콘텐트의 상이한 부분들을 생성하는 데 도움이 될 수 있다. 효과적으로, 입력 데이터 (702a-702n)로부터 생성된 임베딩들은 적어도 하나의 순환 신경망을 트레이닝하는 데 이용될 수 있다. 여기서 적어도 하나의 순환 신경망이 이용되는 것으로 도시되어 있지만, 다른 어떤 적절한 생성적 기계 학습 모델이라도 이용될 수 있음을 유의해야 한다. 거듭 말하면, 여기서 단일 전자 디바이스(101, 102, 104)가 적어도 하나의 사용자에 의해 이용되는 것으로 설명 되어 있지만, 도 6 및 도 7에 도시된 애플리케이션은 다수의 전자 디바이스들(101, 102, 104)을 이용하여 수행될 수 있음을 유의하라. 예를 들면, 사용자 입력은 제1 전자 디바이스(101, 102, 104)를 통해 수신될 수 있고, 음악 콘텐트는 제2 전자 디바이스(101, 102, 104)를 통해 재생될 수 있다. 제2 전자 디바이스(101, 102, 104)는, 예를 들면, 이전 구성(configuration)에 기초하여 또는 사용자 입력에 기초하여 식별되는 것 과 같이, 어떤 적절한 방식으로도 식별될 수 있다. 도 8, 도 9, 및 도 10은, 본 개시에 따른, 효과적인 음악적 특징들을 식별하도록 트레이닝된, 기계 학습용 제3 예시적 애플리케이션을 도시한다. 특히, 도 8, 도 9, 및 도 10은, 기계 학습 모델(상술된 바와 같이 트레 이닝될 수 있음)이 특정한 최종-사용자 애플리케이션을 수행하는 데 이용될 수 있는, 제3 예시적 방법을 도시한 다. 도 8, 도 9, 및 도 10에 도시된 애플리케이션은, 예를 들면, 애플리케이션이 도 1의 네트워크 구 성에서의 적어도 하나의 서버 및 적어도 하나의 전자 디바이스(101, 102, 104)를 이용하여 수행되는 경우, 도 1의 네트워크 구성에서 이용될 수 있다. 그러나, 애플리케이션은 다른 어떤 적절한 디바이 스(들)를 이용하여 다른 어떤 적절한 환경(들)에서도 수행될 수 있음을 유의하라. 도 8에 도시된 바와 같이, 사용자는, 본 예에서 특정 유형의 음악(예를 들면, 클래식 음악)의 재생을 요청하는, 초기 사용자 발화를 제공할 수 있다. 입력 발화는 클라우드-기반 플랫폼에 제공되고, 입력 발화(80 2)에 대한 응답을 생성하는 데 정적 기능이 이용되어야 함을 결정할 수 있는 ASR 및 유형 분류기 기능 에 의해 처리된다. 이는 결과적으로, 어떤 형태의 클래식 음악 또는 기타 요청된 음악 콘텐트의 재생과 같 은, 표준 응답을 초래한다. 도 9에 도시된 바와 같이, 상기 사용자는 표준 응답에 불만족할 수 있으며, 본 예에서 상기 사용자에 의해 제공될 가청(audible) 데이터에 기초하여 음악 콘텐트의 재생을 요청하는, 후속 입력 발화를 제공할 수 있 다. 입력 발화는 상기 클라우드-기반 플랫폼에 제공되고, 입력 발화에 대한 응답을 생성하는 데 연속 적 기능이 이용되어야 함을 결정할 수 있는, ASR 및 유형 분류기 기능에 의해 처리된다. 비언어적 사용자 입력이, 예를 들면, 음악 연주 또는 기타 비언어적 입력 사운드들(input sounds)의 형태 로, 사용자의 전자 디바이스(101, 102, 104)에 제공된다. 여기서 비언어적 사용자 입력은 특정한 기존 노 래를 나타낼 필요는 없으며 대신에 상기 사용자가 듣고 싶어하는 특정 스타일(style)로 즉흥적으로 이루어질 수 있다. 전자 디바이스(101, 102, 104)의 하나 이상의 분석 기능들은, 예를 들면, 도 5에 도시되고 상술된 바와 동일 또는 유사한 방식으로, 비언어적 사용자 입력을 하나 이상의 임베딩들로 변환할 수 있다. 상기 하나 이상의 임베딩들은, 본 예에서 사용자 입력과 유사한 클래식 음악 또는 기타 관련된 음악 콘텐트의 연주(예를 들면, 전자 디바이스(101, 102, 104)의 스피커를 통한)를 포함하는, 하나 이상의 보조 액션들 을 결정하는 데 이용된다. 예를 들면, 사용자 입력의 상기 하나 이상의 임베딩들은, 사용자 입력 의 상기 임베딩(들)과 거리가 가장 가까운, 잠재 특징 공간 내 하나 이상의 임베딩들을 식별하는 데 이용 될 수 있으며, 상기 잠재 특징 공간 내의 상기 하나 이상의 식별된 임베딩들과 연관된 상기 음악 콘텐트가 식별 되어 상기 사용자에게 재생될 수 있다. 도 10은 분석 기능들 및 보조 액션들이 발생할 수 있는 방법의 일 예를 도시한다. 도 10에 도시된 바 와 같이, 사용자 입력이, 도 2의 시스템 또는 도 3의 시스템을 나타낼 수 있는, 트레이닝된 기 계 학습 모델에 제공된다. 트레이닝된 기계 학습 모델은 사용자 입력을 이용하여, 상술된 방 식으로 발생할 수 있는, 적어도 하나의 임베딩을 생성한다. 적어도 하나의 임베딩은, 다른 음악 콘 텐트에 대한 임베딩들을 포함하는, 학습된(learned) 잠재 공간을 탐색하는(search) 데 이용된다. 여기서 상기 탐색은, 예를 들면, 임베딩(들)로부터 가장 가까운 이웃들(유클리드 거리, 코사인 거리, 또 는 기타 거리의 관점에서)인 하나 이상의 임베딩들(1008')을 찾아 볼 수 있다. 하나 이상의 식별된 임베딩들 (1008')은, 제시 기능을 통해 상기 사용자에게 재생되는, 음악 콘텐트를 검색 또는 생성하는 데 이 용될 수 있다. 이런 식으로, 사용자 입력과 유사한(지각적으로(perceptually) 관련된 음악적 특징들에 기 초하여) 음악 콘텐트가 식별될 수 있고, 이에 따라 상기 사용자에게 재생되는 상기 음악 콘텐트가 사용자 입력 에 기초하며 사용자 입력과 유사하도록 할 수 있다. 거듭 말하면, 여기서 단일 전자 디바이스(101, 102, 104)가 적어도 하나의 사용자에 의해 이용되는 것으로 설명 되어 있지만, 도 8, 도 9, 및 도 10에 도시된 애플리케이션은 복수의 전자 디바이스들(101, 102, 104)을 이용하여 수행될 수 있음을 유의하라. 예를 들면, 입력 발화들(802, 902)은 제1 전자 디바이스(101, 102, 104) 를 통해 수신될 수 있고, 음악 콘텐트는 제2 전자 디바이스(101, 102, 104)를 통해 재생될 수 있다. 제2 전자 디바이스(101, 102, 104)는, 예를 들면, 이전 구성(configuration)에 기초하여 또는 입력 발화(802, 902)에 기초하여 식별되는 것과 같이, 어떤 적절한 방식으로도 식별될 수 있다. 도 4, 도 5, 도 6, 도 7, 도 8, 도 9, 및 도 10은 효과적인 음악적 특징들을 식별하도록 트레이닝된 기계 학습 용 애플리케이션들의 예들을 도시하고 있지만, 이 도면들에 대해 다양한 변경이 이루어질 수 있다. 예를 들면, 효과적인 음악적 특징들을 식별하도록 트레이닝된 기계 학습은 본 개시의 범위를 벗어나지 않고 다른 어떤 적절 한 방식으로도 이용될 수 있다. 본 개시는 이 도면들에서 제시된 상기 특정한 최종-사용자 애플리케이션들로 제 한되지 않는다. 도 11 및 도 12는, 본 개시에 따른, 효과적인 음악적 특징들을 식별하기 위한 예시적인 기계 학습 방법들(1100 및 1200)을 도시한다. 특히, 도 11은 도 2에 도시된 기계 학습 모델을 트레이닝하는 예시적 방법을 도시 하고, 도 12는 도 3에 도시된 기계 학습 모델을 트레이닝하는 예시적 방법을 도시한다. 도 11 및 도 12에 도시된 방법들(1100 및 1200) 각각은, 예를 들면, 방법들(1100 및 1200)이 도 1의 네트워크 구성에서의 서 버에 의해 수행되는 경우, 도 1의 네트워크 구성에서 수행될 수 있다. 그러나, 방법들(1100 및 1200) 각각은 다른 어떤 적절한 디바이스(들)를 이용하여 다른 어떤 적절한 환경(들)에서도 수행될 수 있다. 도 11에 도시된 바와 같이, 기계 학습 모델의 트레이닝은 복수의 스테이지들(1102 및 1104)로 발생한다. 제1 스 테이지에서, 단계(step)에서, 임베딩 생성기가 음악 콘텐트에 대한 유사도 메트릭(similarity metric)에 기초하여 트레이닝된다. 이는, 예를 들면, 서버의 프로세서가 표준 또는 기타 적절한 DSSM 트레이닝 방법을 이용하여 임베딩 생성기를 트레이닝하는 것을 포함할 수 있다. 이 스테이지 동안, 임베딩 생성기는 유클리드 거리, 코사인 거리, 또는 기타 거리 메트릭에 기초하여 트레이닝될 수 있다. 또 한, 여기서 부정 예들(negative examples)이 소프트맥스 함수에 포함될 수 있다. 전반적으로, 이 스테이지 동안, 임베딩 생성기는 손실 함수를 최소화함으로써 임베딩 생성기의 파라미터들을 학습 하도록 트레이닝될 수 있다. 제2 스테이지에서, 생성된 임베딩을 샘플링된 임베딩과 구별하도록 적대적 판별기를 단계에서 트레 이닝하고 상기 적대적 판별기를 기만하는 시도를 하도록 상기 임베딩 생성기를 단계에서 트레이닝함으로 써, 상기 기계 학습 모델이 적대적으로 트레이닝된다. 이는, 예를 들면, 서버의 프로세서가 GAN 트레 이닝 절차를 이용하는 단계를 포함할 수 있다. 여기서, 적대적 판별기는 임베딩 생성기로부터 생성된 임베딩들(212a-212c)을 q(z)로부터 샘플링된 임베딩들과 구별하도록 트레이닝된다. 또한, 임베딩 생성기는 적대적 판별기를 기만하도록 트레이닝된다. 결과적으로, 단계에서, 상기 적대적 판별기는 상기 임베 딩 생성기에 의해 생성된 상기 임베딩들로 하여금 미리-정의된 분포를 가지도록 하는 데 이용된다. 이는, 예를 들면, 적대적 판별기가 임베딩 생성기로 하여금 상기 미리-정의된 분포 p(z)로부터 샘플링된 것처럼 보이는 임베딩들을 생성하게 하도록, 임베딩 생성기 및 적대적 판별기가 트레이닝되는 단계를 포함할 수 있다. 단계에서, 상기 트레이닝 스테이지들을 반복할지 여부에 대해 결정이 이루어진다. 이는, 예를 들면, 서버 의 프로세서가 식 의 손실이 수렴되었는지 여부를 결정하는 단계를 포함할 수 있다. 특정한 예로, 이는 서버의 프로세서가 상기 식 의 손실의 계산된 값들이 스테이지들(1102 및 1104)을 통한 한 번 이상의 반복들(iterations) 동안 서로의 임계값(threshold amount) 또는 임계 백분율(threshold percentage) 내에서 유지되었는지 여부를 결정하는 단계를 포함할 수 있다. 유지되지 않은 경우, 상기 프로세스 는 제1 트레이닝 스테이지로 돌아간다. 유지된 경우, 트레이닝된 기계 학습 모델이 생성 완료되어 단계 에서 출력된다. 이 시점에서, 예를 들면, 음악 콘텐트 식별, 음악 콘텐트 순위화, 음악 콘텐트 검색, 및/ 또는 음악 콘텐트 생성과 같이 하나 이상의 최종-사용자 애플리케이션들을 위해, 상기 트레이닝된 기계 학습 모 델이 이용될 수 있다. 도 12에 도시된 바와 같이, 기계 학습 모델의 트레이닝은 복수의 스테이지들(1202 및 1204)로 발생한다. 제1 스 테이지에서, 단계에서, 인접성 판별기를 포함하는 분류기가 관련된 콘텐트를 관련 없는 콘텐트와 구별하도록 트레이닝된다. 이는, 예를 들면, 서버의 프로세서가 임베딩들(312a-312b)이 관련되어 있 음(임베딩들(312b)이 긍정 입력 데이터(310b)를 위한 것인 경우) 또는 관련 없음(임베딩들(312b)이 부정 입력 데이터(310b)를 위한 것인 경우)을 인식하도록 분류기를 트레이닝하는 단계를 포함할 수 있다. 상술된 바 와 같이, 분류기의 상기 인접성 판별기는, 예를 들면, 각각의 결합된 임베딩이 임베딩(312a) 및 연결된 (concatenated) 임베딩(312b)을 나타내는 경우, 상기 결합된 임베딩들을 처리할 수 있다. 특정한 예로, 일부 실 시예들에서 분류기는 2개의 클래스들을 갖는 교차 엔트로피를 이용하여 트레이닝될 수 있다. 제2 스테이지에서, 생성된 임베딩들을 샘플링된 임베딩들과 구별하도록 적대적 판별기를 단계에서 트레이닝하고 상기 적대적 판별기를 기만하는 시도를 하도록 임베딩 생성기를 단계에서 트레이닝함으로써, 상기 기계 학습 모델이 적대적으로 트레이닝된다. 이는, 예를 들면, 서버의 프로세서 가 GAN 트레이닝 절차를 이용하는 단계를 포함할 수 있다. 여기서, 적대적 판별기는 임베딩 생성기 로부터 생성된 임베딩들(312a-312b)을 q(z)로부터 샘플링된 임베딩들과 구별하도록 트레이닝된다. 또한, 임베딩 생성기는 적대적 판별기를 기만하도록 트레이닝된다. 결과적으로, 단계에서, 상기 적대 적 판별기는 상기 임베딩 생성기에 의해 생성된 상기 임베딩들로 하여금 미리-정의된 분포를 가지도록 하는 데 이용된다. 이는, 예를 들면, 적대적 판별기가 임베딩 생성기로 하여금 상기 미리-정의된 분포 p(z)로 부터 샘플링된 것처럼 보이는 임베딩들을 생성하게 하도록, 임베딩 생성기 및 적대적 판별기가 트레 이닝되는 단계를 포함할 수 있다. 단계에서, 상기 트레이닝 스테이지들을 반복할지 여부에 대해 결정이 이루어진다. 반복하도록 결정되는 경우, 상기 프로세스는 제1 트레이닝 스테이지로 돌아간다. 그렇지 않은 경우, 트레이닝된 기계 학습 모 델이 생성 완료되어 단계에서 출력된다. 이 시점에서, 예를 들면, 음악 콘텐트 식별, 음악 콘텐트 순위화, 음악 콘텐트 검색, 및/또는 음악 콘텐트 생성과 같이 하나 이상의 최종-사용자 애플리케이션들을 위해, 상기 트레이닝된 기계 학습 모델이 이용될 수 있다. 도 11 및 도 12는 효과적인 음악적 특징들을 식별하기 위한 기계 학습 방법들(1100 및 1200)의 예들을 도시하고 있지만, 도 11 및 도 12에 대해 다양한 변경이 이루어질 수 있다. 예를 들면, 일련의 단계들(steps)로 도시되어 있지만, 각 도면에서의 다양한 단계들은 중첩되거나, 병렬적으로 발생하거나, 상이한 순서로 발생하거나, 또는 몇 번이라도 발생할 수 있다. 또한, 본 개시의 가르침(teachings)에 따라 설계된 기계 학습 모델을 트레이닝하 는 데 다른 어떤 적절한 방법들이라도 이용될 수 있다. 도 13은, 본 개시에 따른, 효과적인 음악적 특징들을 식별하도록 트레이닝된 기계 학습을 이용하는 예시적 방법 을 도시한다. 특히, 도 13은 적어도 하나의 최종-사용자 애플리케이션을 지원하기 위해 기계 학습 모델 (상술된 바와 같이 트레이닝될 수 있음)을 이용하는 예시적 방법을 도시한다. 여기에서 이용되는 상기 기 계 학습 모델은, 잠재 공간 내 음악적 특징들의 복수의 임베딩들이 미리-정의된 분포를 가지도록 하나 이상의 신경망들 및 하나 이상의 적대적 판별기들을 갖는 기계 학습 시스템을 트레이닝함으로써, 생성되었을 수 있다. 도 13에 도시된 방법은 예를 들면, 방법이 도 1의 네트워크 구성에서의 적어도 하나의 전자 디바이스(101, 102, 104)에 의해(아마도 적어도 하나의 서버와 함께) 수행되는 경우, 도 1의 네트워크 구 성에서 수행될 수 있다. 그러나, 방법은 다른 어떤 적절한 디바이스(들)를 이용하여 다른 어떤 적절 한 환경(들)에서도 수행될 수 있다. 도 13에 도시된 바와 같이, 단계에서, 입력 음악 콘텐트와 연관된 비언어적 입력이 획득된다. 이는, 예를 들면, 전자 디바이스(101, 102, 104)의 프로세서가 마이크를 통해 적어도 하나의 사용자로부터 비언어적 입력을 수신하는 단계를 포함할 수 있다. 이러한 경우, 상기 비언어적 입력은 음악을 식별, 반주(accompany), 구성(compose), 또는 재생해 달라는 사용자의 요청과 연관된 음악 연주 또는 사운드들을 나타낼 수 있다. 이는 또한 또는 대안적으로 전자 디바이스(101, 102, 104)의 프로세서가 기존 음악 콘텐트와 유사한 음악을 구 성해(compose) 달라는 요청을 수신하는 단계를 포함할 수 있다. 그러한 경우, 상기 비언어적 입력은 상기 기존 음악 콘텐트의 하나 이상의 임베딩들을 나타낼 수 있다. 필요한 경우, 단계에서, 상기 비언어적 입력의 하나 이상의 임베딩들은 트레이닝된 기계 학습 모델을 이용하여 생성된다. 이는, 예를 들면, 전자 디바이스 (101, 102, 104)의 프로세서가 상기 트레이닝된 기계 학습 모델을 이용하여 상기 비언어적 입력의 디지털 화된 버전을 잠재 음악 공간으로 투사하는 단계를 포함할 수 있다. 단계에서, 상기 입력 음악 콘텐트와 연관된 상기 임베딩(들)과 관련된 하나 이상의 임베딩들이 식별된다. 이는, 예를 들면, 전자 디바이스(101, 102, 104)의 프로세서가, 예를 들면, 트레이닝된 임베딩 생성기(202 또는 302)를 이용하여, 상기 입력 음악 콘텐트와 연관된 상기 임베딩(들)에 가장 가까운 이웃(들)을 나타내는, 하나 이상의 임베딩들을 식별하는 단계를 포함할 수 있다. 상술된 바와 같이, 임베딩들 간의 거리들은, 유클리 드 거리, 코사인 거리, 또는 기타 거리 메트릭들과 같은, 다양한 메트릭들을 이용하여 결정될 수 있다. 입력 음악 콘텐트의 상기 하나 이상의 임베딩들 및/또는 상기 하나 이상의 식별된 임베딩들은 원하는 사용자 기 능을 수행하는 데 이용된다. 본 예에서, 이는, 단계에서, 상기 하나 이상의 식별된 임베딩들과 연관된 저 장된 음악 콘텐트를 식별하는 단계 및/또는 도출된 음악 콘텐트를 생성하는 단계를 포함한다. 이는, 예를 들면, 전자 디바이스(101, 102, 104)의 프로세서가 상기 하나 이상의 식별된 임베딩들과 연관된 기존 음악 콘텐 트를 식별하거나 또는 상기 하나 이상의 식별된 임베딩들에 기초하여 음악 콘텐트를 구성하는(composing) 단계를 포함할 수 있다. 단계에서, 상기 저장된 및/또는 도출된 음악 콘텐트가 제시된다. 이는, 예를 들면, 전자 디바이스(101, 102, 104)의 프로세서가 적어도 하나의 스피커를 통해 상기 저장된 및/또는 도출 된 음악 콘텐트를 재생하는 단계를 포함할 수 있다. 도 13은 효과적인 음악적 특징들을 식별하도록 트레이닝된 기계 학습을 이용하는 방법의 일 예를 도시하 고 있지만, 도 13에 대해 다양한 변경이 이루어질 수 있다. 예를 들면, 일련의 단계들로 도시되어 있지만, 도 13에서의 다양한 단계들은 중첩되거나, 병렬적으로 발생하거나, 상이한 순서로 발생하거나, 또는 몇 번이라도 발생할 수 있다. 또한, 본 개시의 가르침에 따라 설계된 기계 학습 모델은 다른 어떤 적절한 방식으로도 이용될 수 있다. 상술된 바와 같이, 예를 들면, 상기 모델은 음악 콘텐트 식별, 음악 콘텐트 순위화, 음악 콘텐트 검색, 및/또는 음악 콘텐트 생성에 이용될 수 있다. 경우에 따라, 동일 모델이 이러한 기능들 중 적어도 2개에 이용될 수 있다. 본 개시가 다양한 예시적 실시예들을 참조하여 설명되었지만, 다양한 변경들 및 변형들이 본 개시가 속하는 기 술분야의 통상의 지식을 가진 자에게 시사될 수 있다. 본 개시는 그러한 변경들 및 변형들을 첨부된 청구항들의 범위 내에 속하는 것으로 포괄하고자 한 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13"}
{"patent_id": "10-2022-7004952", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시 및 그 이점의 보다 완전한 이해를 위해, 첨부된 도면과 함께 이하의 설명이 이루어지며, 여기서 동일한 참조 번호는 동일한 부분을 나타낸다. 도 1은, 본 개시에 따른, 전자 디바이스를 포함하는 예시적인 네트워크 구성을 도시한다. 도 2는, 본 개시에 따른, 효과적인 음악적 특징들을 식별하기 위한 기계 학습용 제1 예시적 시스템을 도시한다. 도 3은, 본 개시에 따른, 효과적인 음악적 특징들을 식별하기 위한 기계 학습용 제2 예시적 시스템을 도시한다. 도 4 및 도 5는, 본 개시에 따른, 효과적인 음악적 특징들을 식별하도록 트레이닝된 기계 학습용 제1 예시적 애 플리케이션을 도시한다. 도 6 및 도 7은, 본 개시에 따른, 효과적인 음악적 특징들을 식별하도록 트레이닝된 기계 학습용 제2 예시적 애 플리케이션을 도시한다. 도 8, 도 9, 및 도 10은, 본 개시에 따른, 효과적인 음악적 특징들을 식별하도록 트레이닝된 기계 학습용 제3 예시적 애플리케이션을 도시한다. 도 11 및 도 12는, 본 개시에 따른, 효과적인 음악적 특징들을 식별하기 위한 예시적인 기계 학습 방법들을 도 시한다. 도 13은, 본 개시에 따른, 효과적인 음악적 특징들을 식별하도록 트레이닝된 기계 학습을 이용하는 예시적 방법 을 도시한다."}
