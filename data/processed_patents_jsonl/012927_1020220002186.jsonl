{"patent_id": "10-2022-0002186", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0106370", "출원번호": "10-2022-0002186", "발명의 명칭": "분류 네트워크를 학습하는 전자 장치 및 그의 동작 방법 및 분류 네트워크를 이용하는 전자", "출원인": "에스케이하이닉스 주식회사", "발명자": "김동익"}}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 특징 추출 레이어들을 포함하는 분류 네트워크를 저장하는 메모리; 및객체를 포함하는 학습 이미지를 상기 분류 네트워크에 입력하여, 상기 분류 네트워크로부터 출력된, 상기 객체에 대응되는 클래스 스코어를 획득하고, 상기 복수의 특징 추출 레이어들 각각으로부터 출력된 복수의 활성화맵들, 및 상기 클래스 스코어를 기초로 최종 손실값을 획득하고, 상기 최종 손실값을 기초로 상기 분류 네트워크를 제어하는 프로세서;를 포함하는 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 복수의 특징 추출 레이어들은,상기 활성화맵들 중에서 상기 학습 이미지에 대한 제1 활성화맵을 출력하는 제1 특징 추출 레이어, 및 상기 제1활성화맵에 대한 제2 활성화맵을 출력하는 제2 특징 추출 레이어를 포함하는 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는, 상기 제1 활성화맵을 기초로 상기 학습 이미지의 사이즈와 같은 사이즈를 갖는 제1 스케일된 활성화맵을 획득하고, 상기 제2 활성화맵을 기초로 상기 학습 이미지의 사이즈와 같은 사이즈를 갖는 제2 스케일된 활성화맵을 획득하는 스케일링부;를 포함하는 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프로세서는,손실 함수에 상기 제1 스케일된 활성화맵 및 상기 학습 이미지에 대응되는 이진화 이미지를 입력함으로써 제1세그먼테이션 값을 획득하고, 상기 손실 함수에 상기 제2 스케일된 활성화맵 및 상기 이진화 이미지를 입력함으로써 제2 세그먼테이션 값을 획득하는 손실값 연산부;를 포함하는 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 손실값 연산부는,상기 제1 세그먼테이션 값 및 상기 제2 세그먼테이션 값을 이용한 연산을 수행한 결과 값을 활성화맵 손실값으로 획득하고,공개특허 10-2023-0106370-3-상기 연산은, 합 연산, 가중치 연산 및 평균 연산 중에서 하나인 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 손실값 연산부는, 상기 활성화맵 손실값 및 상기 클래스 스코어의 오차를 나타내는 소프트맥스 손실값을 이용한 가중치 연산을 수행한 결과 값을 최종 손실값으로 획득하는 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 프로세서는,상기 최종 손실값을 상기 분류 네트워크의 출력단에 입력하여 상기 제1 특징 추출 레이어 및 상기 제2 특징 추출 레이어 중 적어도 하나를 학습하는 데이터 연산부;를 포함하는 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 분류 네트워크는, 상기 복수의 특징 추출 레이어들 중 마지막 순서의 특징 추출 레이어와 직렬 연결된 풀리 커넥티드 레이어 및상기 풀리 커넥티드 레이어와 직렬 연결된 소프트맥스 레이어를 포함하고, 상기 손실값 연산부는, 상기 손실 함수에 상기 클래스 스코어 및 상기 객체에 대응되는 기준 스코어를 입력함으로써 상기 소프트맥스손실값을 획득하는 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제4항에 있어서, 상기 학습 이미지는, 제1 색상 채널의 픽셀값들, 제2 색상 채널의 픽셀값들 및 제3 색상 채널의 픽셀값들을 포함하고,상기 프로세서는, 상기 제1 색상 채널의 픽셀값들, 상기 제2 색상 채널의 픽셀값들 및 상기 제3 색상 채널의 픽셀값들 중에서, 서로 같은 위치를 나타내는 상기 제1 색상 채널의 픽셀값, 상기 제2 색상 채널의 픽셀값 및 상기 제3 색상 채널의픽셀값의 평균값을 획득하고,상기 평균값이 임계값 미만이면, 상기 위치에 대응되는 픽셀값을 제1 값으로 처리하고, 상기 평균값이 상기 임계값 이상이면, 상기 위치에 대응되는 픽셀값을 제2 값으로 처리한 상기 이진화 이미지를 획득하는 이진화 처리부;를 포함하는 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제2항에 있어서, 공개특허 10-2023-0106370-4-상기 제1 특징 추출 레이어는, 직렬로 연결된 제1 컨볼루션 레이어 및 제1 활성화 함수 레이어를 포함하고,상기 제2 특징 추출 레이어는, 직렬로 연결된 풀링 함수 레이어, 제2 컨볼루션 레이어 및 제2 활성화 함수 레이어를 포함하는 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "복수의 특징 추출 레이어들을 포함하고, 이미지에 포함된 객체를 분류하도록 학습된 분류 네트워크를 저장하는메모리; 및수신된 입력 이미지를 상기 분류 네트워크에 입력함으로써, 상기 입력 이미지에 포함된 객체가 복수의 클래스각각에 매칭되는 스코어를 나타내는 클래스 스코어를 획득하는 프로세서;를 포함하고,상기 학습된 분류 네트워크는,상기 분류 네트워크에 입력된 학습 이미지에 대응되는 소프트맥스 손실값, 및 상기 복수의 특징 추출 레이어들각각으로부터 출력된 활성화맵들을 이용해 획득된 활성화맵 손실값의 가중치 연산을 기초로 학습된 신경망 네트워크인 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 복수의 특징 추출 레이어들 각각은, 직렬로 연결된 컨볼루션 레이어 및 활성화 함수 레이어를 포함하고,상기 컨볼루션 레이어는, 복수의 가중치 파라미터들을 포함하고, 상기 복수의 가중치 파라미터들 중 적어도 하나는, 상기 가중치 연산의 결과로 획득된 손실값을 상기 분류 네트워크의 출력단에 입력하여 업데이트된 것인 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 활성화맵 손실값은, 상기 학습 이미지의 사이즈와 같은 사이즈를 갖도록 사이즈가 조정된 상기 활성화맵들 각각 및 상기 학습 이미지에 대응되는 이진화 이미지에 손실 함수를 적용함으로써 획득된 세그먼트 값들의 합인 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 학습된 분류 네트워크는,상기 복수의 특징 추출 레이어들 중 마지막 순서의 특징 추출 레이어와 직렬 연결된 풀리 커넥티드 레이어 및상기 풀리 커넥티드 레이어와 직렬 연결된 소프트맥스 레이어를 포함하는 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 입력 이미지 및 상기 학습 이미지는, 공개특허 10-2023-0106370-5-제1 색상 채널의 픽셀값들, 제2 색상 채널의 픽셀값들 및 제3 색상 채널의 픽셀값들을 포함하는 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 객체를 포함하는 상기 입력 이미지를 획득하는 이미지 센서; 및정보를 표시하는 디스플레이;를 더 포함하고,상기 프로세서는, 상기 입력 이미지에 포함된 상기 객체를 상기 클래스 스코어에 포함된 스코어들 중 가장 높은 스코어에 대응되는 클래스로 분류한 결과를 표시하도록 상기 디스플레이를 제어하는 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,외부 장치로부터 상기 입력 이미지를 수신하는 통신부;를 포함하고,상기 프로세서는, 상기 입력 이미지에 포함된 상기 객체를 상기 클래스 스코어에 포함된 스코어들 중 가장 높은 스코어에 대응되는 클래스로 분류한 결과를 상기 외부 장치로 전송하도록 상기 통신부를 제어하는 전자 장치."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "복수의 특징 추출 레이어들을 포함하는 분류 네트워크에 객체를 포함하는 학습 이미지를 입력하는 단계; 상기 분류 네트워크로부터 출력된, 상기 객체에 대응되는 클래스 스코어를 획득하는 단계; 상기 학습 이미지에 대응되는 이진화 이미지, 상기 복수의 특징 추출 레이어들 각각으로부터 출력된 복수의 활성화맵들, 및 상기 클래스 스코어를 기초로 최종 손실값을 획득하는 단계; 및상기 최종 손실값을 기초로 상기 분류 네트워크를 제어하는 단계;를 포함하는 전자 장치의 동작 방법."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 학습 이미지의 사이즈와 같아지도록 상기 활성화맵들 각각의 사이즈를 스케일링함으로써 스케일된 활성화맵들을 획득하는 단계; 상기 스케일된 활성화맵들 각각 및 상기 학습 이미지에 대응되는 이진화 이미지를 손실 함수에 입력함으로써 세그먼테이션 값들을 획득하는 단계; 및상기 세그먼테이션 값들을 이용한 연산을 수행한 결과 값을 활성화맵 손실값으로 획득하는 단계;를 더포함하고,상기 연산은, 합 연산, 가중치 연산 및 평균 연산 중에서 하나인 전자 장치의 동작 방법."}
{"patent_id": "10-2022-0002186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,공개특허 10-2023-0106370-6-상기 최종 손실값을 획득하는 단계는,상기 활성화맵 손실값, 및 상기 클래스 스코어의 오차를 나타내는 소프트맥스 손실값을 이용한 가중치 연산을수행한 결과 값을 상기 최종 손실값으로 획득하고, 상기 분류 네트워크를 제어하는 단계는, 상기 최종 손실값을 상기 분류 네트워크의 출력단에 입력하여, 상기 복수의 특징 추출 레이어들 각각에 포함된복수의 가중치 파라미터들 중 적어도 하나를 업데이트하는 전자 장치의 동작 방법."}
{"patent_id": "10-2022-0002186", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 기술에 따른 전자 장치는 복수의 특징 추출 레이어들을 포함하는 분류 네트워크를 저장하는 메모리, 및 객체 를 포함하는 학습 이미지를 분류 네트워크에 입력하여, 분류 네트워크로부터 출력된 객체에 대응되는 클래스 스 코어를 획득하고, 복수의 특징 추출 레이어들 각각으로부터 출력된 복수의 활성화맵들, 및 클래스 스코어를 기초 로 최종 손실값을 획득하고, 최종 손실값을 기초로 분류 네트워크를 제어하는 프로세서를 포함한다."}
{"patent_id": "10-2022-0002186", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 분류 네트워크에 관한 것으로, 보다 구체적으로는 분류 네트워크를 학습하는 전자 장치 및 그의 동작 방법 및 학습된 분류 네트워크를 이용하는 전자 장치에 관한 것이다."}
{"patent_id": "10-2022-0002186", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 반도체 기술 및 통신 기술의 발전으로 인해, 대규모의 데이터를 기반으로 하는 인공 신경망(Artificial Neural Network, ANN) 기술을 활용할 수 있게 되었다. 인공 신경망은 생물학적 구조를 모방한 기계학습 모델이 다. 인공 신경망은 다중 레이어로 구성되며, 한 레이어에 포함된 인공 뉴런(노드)이 다음 레이어에 포함된 인공 뉴런과 특정한 강도(가중치 파라미터)로 연결되는 네트워크 구조를 갖는다. 인공 신경망은 학습을 통해 가중치 파라미터가 변경될 수 있다. 인공 신경망의 한 종류인 컨볼루션 신경망(Convolution Neural Network, CNN) 모델은 이미지 분석, 이미지 분류 등에 활용되고 있다. 특히, 컨볼루션 신경망을 활용한 분류 네트워크의 경우, 입력된 이미지에 포함된 객체를 특정한 클래스로 분류할 수 있다. 일반적으로, 분류 네트워크의 학습에는 클래스에 대한 정보만을 이용하기 때 문에, 잘못된 위치를 학습하게 될 경우에는 분류 네크워크의 분류 결과가 오버피팅 되는 등 분류 네크워크의 분 류 성능이 저하되는 문제가 발생할 수 있다."}
{"patent_id": "10-2022-0002186", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 실시 예는 향상된 분류 정확도를 갖는 분류 네크워크를 학습하는 전자 장치 및 그의 동작 방법을 제 공한다."}
{"patent_id": "10-2022-0002186", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 전자 장치는 복수의 특징 추출 레이어들을 포함하는 분류 네트워크를 저장하는 메 모리, 및 객체를 포함하는 학습 이미지를 분류 네트워크에 입력하여, 분류 네트워크로부터 출력된 객체에 대응 되는 클래스 스코어를 획득하고, 복수의 특징 추출 레이어들 각각으로부터 출력된 복수의 활성화맵들, 및 클래 스 스코어를 기초로 최종 손실값을 획득하고, 최종 손실값을 기초로 분류 네트워크를 제어하는 프로세서를 포함 할 수 있다. 본 개시의 일 실시 예에 따른 전자 장치는 복수의 특징 추출 레이어들을 포함하고, 이미지에 포함된 객체를 분 류하도록 학습된 분류 네트워크를 저장하는 메모리, 및 수신된 입력 이미지를 분류 네트워크에 입력함으로써, 입력 이미지에 포함된 객체가 복수의 클래스 각각에 매칭되는 스코어를 나타내는 클래스 스코어를 획득하는 프 로세서를 포함할 수 있다. 여기에서, 학습된 분류 네트워크는, 분류 네트워크에 입력된 학습 이미지에 대응되는 소프트맥스 손실값, 및 복수의 특징 추출 레이어들 각각으로부터 출력된 활성화맵들을 이용해 획득된 활성화맵 손실값의 가중치 연산을 기초로 학습된 신경망 네트워크일 수 있다. 본 개시의 일 실시 예에 따른 전자 장치의 동작 방법은, 복수의 특징 추출 레이어들을 포함하는 분류 네트워크 에 학습 이미지를 입력하는 단계, 분류 네트워크로부터 출력된, 객체에 대응되는 클래스 스코어를 획득하는 단 계, 학습 이미지에 대응되는 이진화 이미지, 복수의 특징 추출 레이어들 각각으로부터 출력된 복수의 활성화맵 들, 및 클래스 스코어를 기초로 최종 손실값을 획득하는 단계, 및 최종 손실값을 기초로 분류 네트워크를 제어하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0002186", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시 예에 따르면, 향상된 분류 정확도를 갖는 분류 네크워크를 학습하는 전자 장치 및 그의 동작 방 법을 제공할 수 있다. 본 개시의 실시 예에 따르면, 향상된 분류 정확도를 갖는 분류 네크워크를 이용하는 전자 장치를 제공할 수 있다."}
{"patent_id": "10-2022-0002186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서 또는 출원에 개시되어 있는 본 발명의 개념에 따른 실시 예들에 대해서 특정한 구조적 내지 기능적 설명들은 단지 본 발명의 개념에 따른 실시 예를 설명하기 위한 목적으로 예시된 것으로, 본 발명의 개념에 따 른 실시 예들은 다양한 형태로 실시될 수 있으며 본 명세서 또는 출원에 설명된 실시 예들에 한정되는 것으로 해석되어서는 아니 된다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치를 설명하기 위한 도면이다. 도 1을 참조하면, 본 개시의 일 실시 예에 따른 제1 전자 장치는 데이터 학습부, 분류 네트워크 및 데이터 처리부를 포함할 수 있다. 본 개시의 일 실시 예에 따른 제1 전자 장치는 서버, 데이터 센터, 클라우드 서버, 워크스테이션, 모바일 장치, 스마트폰(smart phone), PC(Personal Computer), 태블릿 PC(tablet personal computer), 노트북 (notebook), PDA(personal digital assistant), EDA(enterprise digital assistant), PMP(portable multimedia player), 웨어러블 디바이스(wearable device), 블랙박스, 로봇, 드론, 자율주행 차량, 셋톱 박스, 스마트 스피커, 인공지능 스피커, 게임 콘솔, 텔레비전, 냉장고, 에어컨, 세탁기, 공기 청정기, 스마트 미러,스마트 윈도우, 전자 액자 등일 수 있다. 여기서, 웨어러블 디바이스는 스마트 워치, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 헤드 마운티드 장치(head-mounted-device; HMD), 스킨 패드, 문신, 또는 생체 이식 형 회로 등일 수 있다. 데이터 학습부는 분류 네트워크를 학습할 수 있다. 데이터 학습부는 학습 이미지를 통해 분류 네트워크를 학습할 수 있다. 구체적으로, 데이터 학습부는 학습 이미지를 분류 네트워크에 입력 하고, 분류 네트워크로부터 출력된 클래스 스코어 및 분류 네트워크로부터 출력된 활성화맵에 기초하 여 분류 네트워크를 학습할 수 있다. 분류 네트워크는 복수의 레이어들을 포함할 수 있다. 복수의 레이어들은 순서에 따라 직렬로 연결된 구조 일 수 있다. 예를 들어, 제1 레이어의 출력이 다음 순서인 제2 레이어의 입력으로 처리되도록 연결된 구조일 수 있다. 일 실시 예에서, 분류 네트워크는 컨볼루션 신경망 모델일 수 있다. 예를 들어, 각 레이어는 컨볼루 션 레이어, 활성화 함수 레이어, 풀링 레이어, 풀리 커넥티드 레이어, 및 소프트맥스 레이어 중 하나일 수 있다. 분류 네트워크는 이미지가 입력되면, 클래스 스코어를 출력할 수 있다. 구체적으로, 분류 네트워크는 객체를 포함하는 이미지가 입력되면 객체가 복수의 클래스 각각에 매칭되는 스코어를 나타내는 클래스 스코어를 출력할 수 있다. 여기서, 이미지는 학습 이미지 또는 입력 이미지일 수 있다. 학습 이미지는 학습 이미지에 포함된 객체를 분류 하도록 분류 네트워크를 학습하기 위한 데이터이고, 입력 이미지는 학습된 분류 네트워크를 이용해 입력 이미지에 포함된 객체를 분류하기 위한 데이터를 나타낼 수 있다. 즉, 학습 이미지는 분류 네트워크 를 학습하는 과정에서 분류 네트워크에 입력되는 이미지이고, 입력 이미지는 분류 네트워크가 학습된 이후에 분류 네트워크에 입력되는 이미지이다. 클래스 스코어는 클래스 별 스코어를 포함할 수 있다. 예를 들어, 클래스 스코어는 제1 클래스의 스코어 및 제2 클래스의 스코어를 포함할 수 있다. 즉, 클래스 스코어는 복수의 스코어들을 포함할 수 있다. 스코어는 객체가 해당 클래스에 매칭되는 정도 또는 객체가 해당 클래스로 분류되거나 해당 클래스에 속할 확률을 나타낼 수 있다. 클래스에는 라벨이 미리 설정될 수 있다. 예를 들어, 제1 클래스는 '고양이'라는 라벨이 설정되고, 제2 클래스는 '개'라는 라벨이 미리 설정될 수 있다. 클래스에 설 정된 라벨 및 클래스의 개수는 다양하게 변형되어 실시될 수 있다. 분류 네트워크를 학습한다는 것은, 분 류 네트워크에 포함된 레이어들 내 가중치 파라미터, 서로 인접한 레이어들 간의 바이어스, 또는 레이어들 내에서 서로 연결된 노드들 간의 바이어스를 결정하거나 업데이트하는 것을 의미할 수 있다. 데이터 처리부는 분류 네트워크를 이용해 이미지에 포함된 객체를 특정한 클래스로 분류할 수 있다. 예를 들어, 제1 클래스가 고양이이고, 제2 클래스가 개로 미리 설정된 경우를 가정하도록 한다. 여기서, 데이터 처리부는 분류 네트워크에 이미지를 입력하고, 분류 네트워크으로부터 출력된 값에 따라 이미지 에 포함된 객체를 제1 클래스 및 제2 클래스 중 하나로 분류할 수 있다. 데이터 처리부는 객체가 제1 클래 스로 분류되면, 객체가 제1 클래스에 설정된 고양이인 것으로 식별할 수 있다. 한편, 도 1에서는 데이터 학습부, 분류 네트워크 및 데이터 처리부가 모두 제1 전자 장치(100 0)에 포함되는 것으로 설명하였으나, 이는 일 실시 예일 뿐이며 데이터 학습부, 분류 네트워크 및 데 이터 처리부 중 적어도 하나는 별개의 장치에 탑재되는 등 다양한 형태로 실시될 수 있다. 일 실시 예에서, 제2 전자 장치(1100, 도 2a 참조)는 데이터 학습부 및 분류 네트워크을 포함할 수 있다. 일 실시 예에서, 제3 전자 장치(1200, 도 12a 참조)는 분류 네트워크 및 데이터 처리부를 포함할 수 있 다. 이하에서는 본 개시의 다양한 실시 예에 대해 첨부된 도면을 참고하여 구체적으로 설명하도록 한다. 도 2a는 본 개시의 일 실시 예에 따른 분류 네트워크를 학습하는 전자 장치를 설명하기 위한 도면이다. 도 2a를 참조하면, 본 개시의 일 실시 예에 따른 제2 전자 장치는 프로세서 및 메모리를 포 함할 수 있다. 프로세서는 메모리에 저장된 분류 네트워크에 포함된 복수의 레이어들 각각으로 입력되는 데 이터를 각 레이어에서 정의하는 규칙 또는 연산을 이용해 처리할 수 있다. 프로세서는 복수의 레이어들 중에서 일부 레이어에 포함된 가중치 파라미터들을 학습을 통해 업데이트시킬 수 있다. 이를 위해, 프로세서는 CPU(Central Processing Unit), APU(Application Processor Unit) 등과 같은 범용 프로세서, GPU(Graphic Processing Unit) 등과 같은 그래픽 전용 프로세서, NPU(Neural Processing Unit)와 같은 인공지 능 전용 프로세서 등으로 구현될 수 있다. 프로세서는 하나 또는 복수의 프로세서 유닛으로 구성될 수 있 다. 메모리는 데이터, 정보 또는 인스트럭션 등의 다양한 정보를 전기 또는 자기 형태로 저장할 수 있다. 이 를 위해, 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(Flash Memory), 하드디스크 드라이브 (HDD) 또는 솔리드 스테이트 드라이브(SSD), RAM, ROM 등 중에서 적어도 하나의 하드웨어로 구현될 수 있다. 메모리는 분류 네트워크를 저장할 수 있다. 메모리는 분류 네트워크가 학습될 때마다, 학습에 따라 업데이트된 가중치 파라미터들을 저장할 수 있다. 데이터베이스는 다량의 학습 이미지들을 저장할 수 있다. 데이터베이스는 다량의 학습 이미지들을 프로세서로 제공할 수 있다. 일 실시 예에서, 데이터베이스는 제2 전자 장치의 외부에 별도 로 존재하거나, 제2 전자 장치의 내부에 포함되는 등 다양하게 변형될 수 있다. 각 학습 이미지는 객체를 포함할 수 있다. 학습 이미지는 객체를 촬영함으로써 획득된 이미지이거나 또는 그래픽 소프트웨어를 이용해 생 성된 이미지일 수 있다. 예를 들어, 객체는 고양이, 개, 사람, 나무 등과 같은 생물 또는 의자, 책상, 바위, 창 문, 가로등 등과 같은 사물 등 일 수 있다. 학습 이미지는 행과 열 방향으로 배열되는 복수의 픽셀값들을 포함 할 수 있다. 학습 이미지는 제1 색상 채널의 픽셀값들, 제2 색상 채널의 픽셀값들, 제3 색상 채널의 픽셀값들을 포함할 수 있다. 예를 들어, 제1 색상 채널은 레드 채널, 제2 색상 채널은 그린 채널, 제3 색상 채널은 블루 채 널일 수 있다. 즉, 학습 이미지는 RGB 이미지일 수 있다. 이때, 제1 색상 채널의 픽셀값들, 제2 색상 채널의 픽 셀값들, 제3 색상 채널의 픽셀값들의 사이즈는 모두 같을 수 있다. 여기서 사이즈는 행과 열 방향으로 배열되는 픽셀값들의 개수를 나타낼 수 있다. 학습 이미지에 포함된 픽셀값들 각각은 0 내지 255의 범위에 포함되는 값을 가질 수 있다. 다만, 이는 일 실시 예일 뿐이며 픽셀값들 각각은 0 내지 1023의 범위에 포함되는 값 등과 같이 다양하게 변형되어 실시될 수 있다. 일 실시 예에서, 데이터베이스는 각각의 학습 이미지에 대응되는 이진화 이미지를 더 저장할 수 있다. 이 진화 이미지는 1개의 색상 채널을 갖는 픽셀값들을 포함할 수 있다. 예를 들어, 이진화 이미지에 포함된 픽셀값 들 각각은 0 또는 1의 값일 수 있다. 다른 예를 들어, 이진화 이미지에 포함된 픽셀값들 각각은 0 또는 255의 값일 수 있다. 이진화 이미지는 객체의 위치를 나타내는 이미지일 수 있다. 이진화 이미지는 분류 네트워크 에 입력된 이미지에 포함된 객체의 위치를 정확히 식별하도록 분류 네트워크를 학습하는데 사용될 수 있다. 이 경우, 데이터베이스는 학습 이미지와 함께, 학습 이미지에 대응되는 이진화 이미지를 프로세서 로 제공할 수 있다. 일 실시 예에서, 프로세서는 데이터베이스로부터 수신된 학습 이미지들 각각을 이용하여 분류 네트 워크를 학습할 수 있다. 프로세서는 학습 이미지를 분류 네트워크에 입력하여, 분류 네트워크로부터 출력된 클래스 스 코어를 획득할 수 있다. 학습 이미지는 객체를 포함할 수 있다. 클래스 스코어는 객체에 대응될 수 있다. 여기 서, 분류 네트워크는 복수의 특징 추출 레이어들을 포함할 수 있다. 프로세서는 복수의 특징 추출 레이어들 각각으로부터 출력된 복수의 활성화맵들, 및 클래스 스코어를 기 초로 최종 손실값을 획득할 수 있다. 복수의 활성화맵들은 복수의 특징 추출 레이어들 중 첫번째 레이어에 학습 이미지가 입력되면, 복수의 특징 추출 레이어들 각각으로부터 출력된 것일 수 있다. 최종 손실값은 활성화맵 손 실값, 및 소프트맥스 손실값을 기초로 획득될 수 있다. 활성화맵 손실값은 복수의 활성화맵들 각각 및 이진화 이미지를 기초로 획득될 수 있다. 소프트맥스 손실값은 클래스 스코어 및 기준 스코어를 기초로 획득될 수 있다. 소프트맥스 손실값은 클래스 스코어의 오차를 나타낼 수 있다. 프로세서는 최종 손실값을 분류 네트워크를 제어할 수 있다. 여기서, 분류 네트워크를 제어한 다는 것은 분류 네트워크를 학습한다는 의미일 수 있다. 분류 네트워크를 학습한다는 것은 복수의 특 징 추출 레이어들 각각에 포함된 복수의 가중치 파라미터들 중 적어도 하나를 업데이트한다는 의미일 수 있다. 일 실시 예에서, 프로세서는 데이터 학습부를 포함할 수 있다. 프로세서의 동작들 중 적어도 일부는 데이터 학습부에 의해 수행될 수 있다. 보다 구체적인 내용은 도 2b를 참조하여 설명하도록 한다. 도 2b는 본 개시의 일 실시 예에 따른 분류 네트워크를 학습하는 방법을 설명하기 위한 도면이다. 도 2b를 참조하면, 데이터 학습부는 학습 이미지(data_TR)를 분류 네트워크에 입력할 수 있다. 학습 이미지(data_TR)는 객체를 포함할 수 있다. 도 2b에서 도시하는 데이터의 입출력 처리는 데이터 학습부에 의해 수행되는 것일 수 있다. 여기서, 분류 네트워크는 추출 모델 및 분류 모델을 포함할 수 있다. 추출 모델 및 분류 모델은 직렬로 연결된 구조일 수 있다. 예를 들어, 추출 모델의 출력 데이터가 분류 모델의 입 력 데이터로 처리되도록 연결된 구조일 수 있다. 추출 모델은 입력된 데이터의 특징을 추출하기 위한 모델일 수 있다. 구체적으로, 추출 모델은 복수 의 특징 추출 레이어들(210-1~210-N)을 포함할 수 있다. 복수의 특징 추출 레이어들(210-1~210-N)은 직렬로 연 결된 구조일 수 있다. 복수의 특징 추출 레이어들(210-1~210-N) 각각은 데이터가 입력되면 활성화맵을 출력할 수 있다. 각 특징 추출 레이어에서 출력된 활성화맵은 각 특징 추출 레이어로 입력된 데이터에서 고유한 특징을 부각시킨 데이터일 수 있다. 예를 들어, 활성화맵은 특징 추출 레이어에 입력된 이미지를 처리한 이미지일 수 있다. 한편, 활성화맵에 포함된 값들의 개수는 입력된 데이터에 포함된 값들의 개수 보다 감소된 것일 수 있다. 일 실시 예에 있어서, 복수의 특징 추출 레이어들(210-1~210-N)은 직렬로 연결된 제1 특징 추출 레이어(210-1) 및 제2 특징 추출 레이어(210-2)를 포함할 수 있다. 여기서, 제1 특징 추출 레이어(210-1)는 학습 이미지 (data_TR)에 대한 제1 활성화맵(AM_1)을 출력할 수 있다. 즉, 제1 특징 추출 레이어(210-1)는 학습 이미지 (data_TR)가 입력되면, 제1 활성화맵(AM_1)을 출력할 수 있다. 제2 특징 추출 레이어(210-2)는 제1 활성화맵 (AM_1)에 대한 제2 활성화맵(AM_2)을 출력할 수 있다. 즉, 제2 특징 추출 레이어(210-2)는 제1 활성화맵(AM_1) 이 입력되면, 제2 활성화맵(AM_2)을 출력할 수 있다. 이와 같이, 제1 특징 추출 레이어(210-1)의 출력 데이터는 제2 특징 추출 레이어(210-2)의 입력 데이터로 처리될 수 있다. 일 실시 예에서, 특징 추출 레이어들(210- 1~210-N)의 개수는 1개이거나 또는 3개 이상인 것과 같이 다양하게 변형되어 실시될 수 있다. 분류 모델은 입력된 데이터의 특징으로부터 클래스를 분류하기 위한 모델일 수 있다. 분류 모델은 활 성화맵이 입력되면, 클래스 스코어(score_class)를 출력할 수 있다. 데이터 학습부는 분류 모델로부터 출력된 클래스 스코어(score_class) 및 복수의 특징 추출 레이어들 (210-1~210-N)로부터 각각 출력된 복수의 활성화맵들(AM_1~AM_N)을 기초로 분류 네트워크를 학습할 수 있 다. 보다 구체적인 내용은 도 3을 참조하여 설명하도록 한다. 도 3은 본 개시의 일 실시 예에 따른 분류 네트워크를 학습하는 방법을 설명하기 위한 도면이다. 도 3을 참조하면, 본 개시의 일 실시 예에 따른 데이터 학습부는 데이터 연산부, 스케일링부 및 손실값 연산부 중에서 적어도 하나를 포함할 수 있다. 데이터 연산부는 추출 모델 및 분류 모델 중 적어도 하나에 입력되는 데이터를 처리할 수 있다. 예를 들어, 추출 모델은 제1 특징 추출 레이어(210-1) 내지 제N 특징 추출 레이어들(210-N)를 포함하는 것 을 가정하도록 한다. 이 경우, 데이터 연산부는 복수의 특징 추출 레이어들(210-1~210-N) 중에서 첫번째 순서로 배열된 제1 특 징 추출 레이어(210-1)에 학습 이미지(data_TR)를 입력할 수 있다. 데이터 연산부는 제1 특징 추출 레이어 (210-1)에 포함된 레이어 별로 학습 이미지(data_TR)를 처리하여, 제1 활성화맵(AM_1)을 제1 특징 추출 레이어 (210-1)의 출력 데이터로서 획득할 수 있다. 그리고, 데이터 연산부는 복수의 특징 추출 레이어들(210- 1~210-N) 중에서 두번째 순서로 배열된 제2 특징 추출 레이어(210-2)에 제1 활성화맵(AM_1)을 입력할 수 있다. 데이터 연산부는 제2 특징 추출 레이어(210-2)에 포함된 레이어 별로 제1 활성화맵(AM_1)을 처리하여, 제2 활성화맵(AM_2)을 제2 특징 추출 레이어(210-2)의 출력 데이터로서 획득할 수 있다. 데이터 연산부는 이와 같은 동작을 반복하여, 복수의 특징 추출 레이어들(210-1~210-N) 중에서 N-1번째 순서로 배열된 제N-1 특징 추 출 레이어의 출력 데이터로서, 제N-1 활성화맵을 획득하고, 제N-1 활성화맵을 제N 활성화맵(AM_N)에 입력할 수 있다. 그리고, 데이터 연산부는 복수의 특징 추출 레이어들(210-1~210-N) 중에서 마지막 순서인 N번째로 배열된 제N 특징 추출 레이어(210-N)에 포함된 레이어 별로 제N-1 활성화맵을 처리하여, 제N 활성화맵(AM_N)을제N 특징 추출 레이어(210-N)의 출력 데이터로서 획득할 수 있다. 그리고, 데이터 연산부는 제N 활성화맵(AM_N)을 분류 모델에 입력할 수 있다. 여기서, 분류 모델 은 풀리 커넥티드 레이어 및 소프트맥스 레이어를 포함할 수 있다. 풀리 커넥티드 레이어는 복수의 특징 추출 레이어들(210-1~210-N) 중 마지막 순서에 위치한 제N 특징 추출 레이어(210-N)와 직렬 연결될 수 있다. 여기서, 제N 특징 추출 레이어(210-N)의 출력 데이터는 풀리 커넥티드 레이어의 입력 데이터로 처리될 수 있다. 즉, 데이터 연산부는 제N 특징 추출 레이어(210-N)으로부터 출력된 제N 활성화맵(AM_N)을 풀리 커넥티드 레이어에 입력할 수 있다. 소프트맥스 레이어는 풀리 커넥티드 레이어와 직렬 연결될 수 있다. 즉, 풀리 커넥티드 레이어 의 출력 데이터는 소프트맥스 레이어의 입력 데이터로 처리될 수 있다. 데이터 연산부는 풀리 커넥티드 레이어로부터 출력된 값들 각각을 소프트맥스 레이어에 입력할 수 있다. 데이터 연산부는 소프트맥스 레이어에 포함된 소프트맥스 함수를 적용해 연산한 스코어들의 집합을 클래스 스코어(score_class)로서 획득할 수 있다. 소프트맥스 함수는 정규화를 통해 출력 값을 확률 값 으로 변환하는 함수일 수 있다. 스케일링부는 복수의 특징 추출 레이어들(210-1~210-N)로부터 출력된 활성화맵들(AM_1~AM_N) 각각의 사이 즈를 조정할 수 있다. 그리고, 스케일링부는 활성화맵들(AM_1~AM_N) 각각의 사이즈가 조정된 스케일된 활 성화맵들을 획득할 수 있다. 이때, 조정된 사이즈는 학습 이미지(data_TR)의 사이즈와 같은 것일 수 있다. 여기 서 사이즈는 가로 방향 및 세로 방향(또는 행과 열 방향)으로 배열된 데이터 또는 픽셀값들의 개수를 나타낼 수 있다. 일 실시 예에서, 스케일링부는 제1 활성화맵(AM_1)을 기초로 학습 이미지(data_TR)의 사이즈와 같은 사이 즈를 갖는 제1 스케일된 활성화맵을 획득할 수 있다. 스케일링부는 제2 활성화맵(AM_2)을 기초로 학습 이 미지(data_TR)의 사이즈와 같은 사이즈를 갖는 제2 스케일된 활성화맵을 획득할 수 있다. 이와 같은 동작을 반 복하여, 스케일링부는 제N 활성화맵(AM_N)을 기초로 학습 이미지(data_TR)의 사이즈와 같은 사이즈를 갖는 제N 스케일된 활성화맵을 획득할 수 있다. 입력 데이터에 비해 컨볼루션 등의 연산 결과에 따라 출력되는 활성 화맵들(AM_1~AM_N)은 사이즈가 점차 감소하는 형태가 되어, 손실 함수에 입력하기 전에 활성화맵들(AM_1~AM_N) 각각의 사이즈를 조정하는 것이 필요할 수 있기 때문이다. 스케일링부는 디컨볼루션, 바이큐빅, Lanczos, SRCNN(Super Resolution CNN), SRGAN(Super Resolution Generative Adversarial Network) 등의 다양한 알고리즘을 이용하여 활성화맵들(AM_1~AM_N) 각각의 사이즈를 조정할 수 있다. 손실값 연산부는 손실 함수를 이용한 연산을 수행할 수 있다. 손실 함수는 목표 값과 추정 값 사이의 에러 를 구하는 함수일 수 있다. 예를 들어, 손실 함수는 L1 손실 함수, L2 손실 함수, SSIM(Structure Similarity Index), VGG loss 등의 다양한 함수 중 하나일 수 있다. 일 실시 예에서 있어서, 손실값 연산부는 손실 함수에 클래스 스코어(score_class) 및 객체에 대응되는 기 준 스코어(score_t)를 입력함으로써 소프트맥스 손실값(loss_softmax)을 획득할 수 있다. 여기서, 기준 스코어 (score_t)는 객체의 클래스 또는 라벨을 나타내는 데이터일 수 있다. 예를 들어, 객체가 제1 내지 제4 클래스 중에서 제2 클래스에 해당할 경우, 기준 스코어(score_t)는 [0, 1, 0, 0]T일 수 있다. 일 실시 예에서, 손실값 연산부는 손실 함수에 제1 스케일된 활성화맵 및 이진화 이미지(data_TRB)를 입력 함으로써 제1 세그먼테이션 값(loss_seg1)을 획득할 수 있다. 손실값 연산부는 손실 함수에 제2 스케일된 활성화맵 및 이진화 이미지(data_TRB)를 입력함으로써 제2 세그먼테이션 값(loss_seg2)을 획득할 수 있다. 손실 값 연산부는 이와 같은 동작을 반복하여 수행하여, 손실값 연산부는 손실 함수에 제N 스케일된 활성 화맵 및 이진화 이미지(data_TRB)를 입력함으로써 제N 세그먼테이션 값(loss_segN)을 획득할 수 있다. 일 실시 예에 있어서, 손실값 연산부는 복수의 세그먼테이션 값들(loss_seg1~loss_segN)을 기초로 활성화 맵 손실값을 획득할 수 있다. 구체적인 예를 들어, 복수의 세그먼테이션 값들(loss_seg1~loss_segN)이 제1 세그 먼테이션 값(loss_seg1) 및 제2 세그먼테이션 값(loss_seg2)을 포함할 경우를 가정하면, 손실값 연산부는 제1 세그먼테이션 값(loss_seg1) 및 제2 세그먼테이션 값(loss_seg2)를 기초로 활성화맵 손실값을 획득할 수 있 다. 이 경우, 손실값 연산부는 제1 세그먼테이션 값(loss_seg1) 및 제2 세그먼테이션 값(loss_seg2)을 이 용한 연산을 수행한 결과 값을 활성화맵 손실값으로 획득할 수 있다. 여기에서, 연산은 합 연산, 가중치 연산및 평균 연산 중에서 하나일 수 있다. 일 실시 예에 있어서, 손실값 연산부는 활성화맵 손실값 및 소프트맥스 손실값을 이용한 가중치 연산을 수 행한 결과 값을 최종 손실값으로 획득할 수 있다. 가중치 연산은 활성화맵 손실값 및 소프트맥스 손실값 각각에 서로 다른 가중치를 곱한 후, 이들을 합하는 연산일 수 있다. 여기서, 각각의 가중치는 미리 설정된 값일 수 있 다. 일 실시 예에서, 서로 다른 가중치들의 합은 1일 수 있다. 일 실시 예에 있어서, 데이터 연산부는 최종 손실값을 분류 네트워크에 역전파(back-propagtion)함으 로써 복수의 특징 추출 레이어들(210-1~210-N) 중에서 적어도 하나를 학습할 수 있다. 일 실시 예에서, 최종 손 실값(loss_f)은 분류 모델의 출력단에 입력될 수 있다. 이때, 상술한 추출 모델 및 분류 모델의 데이터의 입출력 방향과는 반대 방향으로 연산이 수행될 수 있다. 일 실시 예에서, 데이터 연산부는 최종 손실값이 낮아지도록 학습을 반복 수행할 수 있다. 일 실시 예에서, 데이터 연산부는 최종 손실값이 임계 값 이하가 될 때까지, 학습을 반복 수행할 수 있다. 이에 따 라, 최종 손실값의 크기가 감소하는 방향으로, 특징 추출 레이어들(210-1~210-N) 각각에 포함된 컨볼루션 레이 어에 포함된 복수의 가중치 파라미터들 중 적어도 하나가 업데이트될 수 있다. 일 실시 예에 있어서, 학습 이미지(data_TR)는 제1 색상 채널의 픽셀값들, 제2 색상 채널의 픽셀값들 및 제3 색 상 채널의 픽셀값들을 포함할 수 있다. 예를 들어, 학습 이미지(data_TR)는 레드 채널의 픽셀값들, 그린 채널의 픽셀값들 및 블루 채널의 픽셀값들을 포함할 수 있다. 일 실시 예에서, 프로세서는 이진화 처리부를 더 포함할 수 있다. 이진화 처리부는 학습 이미지(data_T R)에 대응되는 이진화 이미지(data_TRB)를 생성할 수 있다. 구체적으로, 이진화 처리부는 학습 이미지(data_TR)에 포함된 제1 색상 채널의 픽셀값들, 제2 색상 채널의 픽셀 값들 및 제3 색상 채널의 픽셀값들 중에서, 서로 같은 위치를 나타내는 제1 색상 채널의 픽셀값, 제2 색상 채널 의 픽셀값 및 제3 색상 채널의 픽셀값의 평균값을 획득할 수 있다. 여기에서, 이진화 처리부는 평균값이 임계값 미만이면, 같은 위치에 대응되는 픽셀값을 미리 설정된 제1 값으로 처리할 수 있다. 한편, 이진화 처리부는 평균값이 임계값 이상이면, 같은 위치에 대응되는 픽셀값을 미리 설정 된 제2 값으로 처리할 수 있다. 예를 들어, 픽셀값이 0~255와 같이 8비트의 값을 갖는 경우, 임계값은 127이고, 제1 값은 0이고, 제2 값은 255으로 설정될 수 있다. 다만, 이는 일 실시 예일 뿐 임계값, 제1 값 및 제2 값 각 각은 다양한 값으로 변형되어 실시될 수 있다. (1, 1) 위치를 예로 들면, 이진화 처리부는 (1, 1)에 위치한 제1 색상 채널의 픽셀값, (1, 1)에 위치한 제2 색 상 채널의 픽셀값, (1, 1)에 위치한 제3 색상 채널의 픽셀값의 평균값을 획득할 수 있다. 그리고, 이진화 처리 부는 (1, 1)에 대한 평균값이 임계값 미만이면, 이진화 이미지(data_TRB)의 (1, 1)에 위치한 픽셀값을 제1 값으 로 처리할 수 있다. 이와 달리, 이진화 처리부는 (1, 1)에 대한 평균값이 임계값 이상이면, 이진화 이미지 (data_TRB)의 (1, 1)에 위치한 픽셀값을 제2 값으로 처리할 수 있다. 이와 같은 동작을 반복하여 수행함으로써, 이진화 처리부는 제1 값 또는 제2 값을 갖는 픽셀값들을 포함하는 이진화 이미지(data_TRB)를 획득할 수 있다. 일 실시 예에서, 복수의 특징 추출 레이어들(210-1~210-N) 각각은 컨볼루션 레이어를 포함할 수 있다. 컨볼루션 레이어는 적어도 하나의 필터를 포함할 수 있다. 필터는 복수의 가중치 파라미터들을 포함할 수 있다. 여기서, 복수의 가중치 파라미터들 중 적어도 하나는 학습에 의해 업데이트될 수 있다. 일 실시 예에서, 복수의 특징 추출 레이어들(210-1~210-N) 각각은 풀링 레이어 및 활성화 함수 레이어 중에서 적어도 하나를 더 포함할 수 있다. 여기에서, 활성화 함수 레이어는 컨볼루션 레이어의 출력을 입력으로 처리하도록 컨볼루션 레이어에 직렬 연결 될 수 있다. 활성화 함수 레이어는 활성화 함수를 이용한 연산을 수행할 수 있다. 한편, 풀링 레이어는 이전 순 서의 특징 추출 레이어로부터 출력된 활성화맵을 입력으로 수신할 수 있다. 풀링 레이어는 이전 순서의 특징 추 출 레이어로부터 출력된 활성화맵에 포함된 값들의 개수를 감소시키는 연산을 수행할 수 있다. 풀링 레이어는 풀링 레이어의 출력을 컨볼루션 레이어의 입력으로 처리하도록 컨볼루션 레이어에 직렬 연결될 수 있다. 한편, 이하에서는 설명의 편의를 위해, 복수의 특징 추출 레이어들(210-1~210-N)은 서로 직렬로 연결된 제1 특 징 추출 레이어(210-1) 및 제2 특징 추출 레이어(210-2)를 포함하는 것으로 가정하여 설명하도록 한다. 도 4는 본 개시의 일 실시 예에 따른 제1 특징 추출 레이어를 설명하기 위한 도면이다. 도 4를 참조하면, 제1 특징 추출 레이어(210-1)는 학습 이미지(data_TR)에 대한 제1 활성화맵(AM_1)을 출력할 수 있다. 즉, 제1 특징 추출 레이어(210-1)는 학습 이미지(data_TR)가 입력되면, 제1 활성화맵(AM_1)을 출력할 수 있다. 예를 들어, 데이터 연산부는 제1 특징 추출 레이어(210-1)에 학습 이미지(data_TR) 또는 입력 이 미지를 입력하고, 제1 특징 추출 레이어(210-1)의 출력 데이터인 제1 활성화맵(AM_1)을 획득할 수 있다. 일 실시 예에서, 제1 특징 추출 레이어(210-1)는 제1 컨볼루션 레이어(213-1)를 포함할 수 있다. 제1 컨볼루션 레이어(213-1)는 적어도 하나의 필터를 포함할 수 있다. 제1 컨볼루션 레이어(213-1)는 입력된 데이터에 대해 필터를 이용한 컨볼루션 연산을 수행할 수 있다. 예를 들어, 제1 컨볼루션 레이어(213-1)는 학습 이미지 (data_TR)가 입력되면, 학습 이미지(data_TR)에 대해 필터를 이용한 컨볼루션 연산을 수행할 수 있다. 제1 컨볼 루션 레이어(213-1)는 컨볼루션 연산을 수행한 결과를 출력 데이터로 출력할 수 있다. 여기서, 필터는 행과 열 방향으로 배열된 가중치 파라미터들을 포함할 수 있다. 예를 들어, 필터는 2 x 2, 3 x 3 등과 같이 배열된 가중 치 파라미터들을 포함할 수 있다. 일 실시 예에서, 제1 특징 추출 레이어(210-1)는 제1 활성화 함수 레이어(215-1)를 더 포함할 수 있다. 제1 활 성화 함수 레이어(215-1)는 제1 컨볼루션 레이어(213-1)에 직렬로 연결될 수 있다. 제1 컨볼루션 레이어(213- 1)의 출력 데이터가 제1 활성화 함수 레이어(215-1)의 입력 데이터로 처리되는 구조로 연결될 수 있다. 한편, 제1 활성화 함수 레이어(215-1)가 생략된 경우, 제1 활성화맵(AM_1)은 제1 컨볼루션 레이어(213-1)의 출 력 데이터일 수 있다. 여기서, 각 컨볼루션 레이어의 출력 데이터는 컨볼루션맵이라 지칭하도록 한다. 즉, 이 경우, 제1 활성화맵(AM_1)은 제1 컨볼루션맵일 수 있다. 이와 달리, 제1 활성화 함수 레이어(215-1)가 존재할 경우, 제1 활성화맵(AM_1)은 제1 활성화 함수 레이어(215-1)의 출력 데이터일 수 있다. 도 5a 내지 도 5e는 본 개시의 일 실시 예에 따른 컨볼루션 연산을 설명하기 위한 도면이다. 도 5a 내지 도 5e를 참조하면, 본 개시의 일 실시 예에 따른 컨볼루션 레이어는 필터를 포함할 수 있다. 필터는 가중치 파라미터들(w1~w4)를 포함할 수 있다. 데이터 연산부는 컨볼루션 레이어에 입력 데이 터가 입력되면, 입력 데이터에 필터를 적용한 컨볼루션 연산을 수행하여 컨볼루션 레이어의 출력 데이터를 획득할 수 있다.일 실시 예에서, 데이터 연산부는 컨볼루션 레이어에 이미지가 입력되면, 이미지 에 필터를 적용하여 컨볼루션 연산을 수행할 수 있다. 데이터 연산부는 컨볼루션 레이어의 출력 데이터인 컨볼루션맵을 획득할 수 있다. 일 실시 예에서, 이미지는 픽셀값들(x1~x9)을 포함할 수 있다. 한편, 도 5a 내지 도 5e에 도시된 이미지 는 설명의 편의를 위해 학습 이미지(data_TR) 또는 입력 이미지의 일부만을 나타낸 것이다. 여기서, 이미 지는 1개 채널의 이미지일 수 있다. 도 5a를 참조하면, 데이터 연산부는 이미지의 제1 영역과 오버랩되도록 필터를 위치시킬 수 있다. 이 경우, 데이터 연산부는 제1 영역에 포함된 픽셀값들(x1, x2, x4, x5) 및 가중치 파라미 터들(w1, w2, w3, w4) 중에서 서로 같은 위치에 대응되는 픽셀값과 가중치 파라미터를 곱한 값들을 합한 값(y 1)을 제1 영역에 대한 제1 컨볼루션 값으로 획득할 수 있다. 도 5b를 참조하면, 데이터 연산부는 이미지의 제2 영역으로 필터를 이동시킬 수 있다. 데 이터 연산부는 제2 영역에 포함된 픽셀값들(x2, x3, x5, x6) 및 가중치 파라미터들(w1, w2, w3, w4) 중에서 서로 같은 위치에 대응되는 픽셀값과 가중치 파라미터를 곱한 값들을 합한 값(y2)을 제2 영역에 대 한 제2 컨볼루션 값으로 획득할 수 있다. 도 5c를 참조하면, 데이터 연산부는 이미지의 제3 영역으로 필터를 이동시킬 수 있다. 데 이터 연산부는 제3 영역에 포함된 픽셀값들(x1, x2, x4, x5) 및 가중치 파라미터들(w1, w2, w3, w4) 중에서 서로 같은 위치에 대응되는 픽셀값과 가중치 파라미터를 곱한 값들을 합한 값(y3)을 제3 영역에 대 한 제3 컨볼루션 값으로 획득할 수 있다. 도 5d를 참조하면, 데이터 연산부는 이미지의 제4 영역으로 필터를 이동시킬 수 있다. 데 이터 연산부는 제4 영역에 포함된 픽셀값들(x1, x2, x4, x5) 및 가중치 파라미터들(w1, w2, w3, w4) 중에서 서로 같은 위치에 대응되는 픽셀값과 가중치 파라미터를 곱한 값들을 합한 값(y4)을 제4 영역에 대한 제4 컨볼루션 값으로 획득할 수 있다. 이와 같이, 데이터 연산부는 컨볼루션 레이어에 포함된 필터를 이용해 컨볼루션 레이어로 입력된 이 미지에 대한 컨볼루션맵을 획득할 수 있다. 즉, 데이터 연산부는 필터를 포함하는 컨볼루 션 레이어의 입력 데이터로서 이미지가 입력되면, 컨볼루션 레이어의 출력 데이터로서 컨볼루션맵을 획득할 수 있다. 여기서, 컨볼루션맵은 제1 내지 제4 컨볼루션 값(541~544)을 포함할 수 있다. 한편, 상술한 설명에서 필터는 픽셀값 1개만큼 행 또는 열 방향으로 이동하였으나, 이는 일 실시 예일 뿐 이며, 필터가 이동하는 값은 다양하게 변형되어 실시될 수 있다. 한편, 컨볼루션 레이어가 복수의 필터를 포함할 경우, 필터의 개수와 동일한 개수의 컨볼루션맵(55 0)이 출력될 수 있다. 한편, 도 5a 내지 도 5d의 컨볼루션 연산은 도 5e와 같은 인공 신경망 구조로 나타낼 수 있다. 일 실시 예에서, 도 5e를 참조하면, 각각의 출력 노드는 중 적어도 하나의 입력 노드와 연결될 수 있다. 각각의 입력 노드에는 컨볼루션 레이어의 입력 데이터에 포함된 값들 중 하나가 입력될 수 있다. 예를 들어, 입력 데이터가 이미지 인 경우, 이미지에 포함된 픽셀값들(x1~x9) 각각이 입력 노드에 입력될 수 있다. 출력 노드의 컨볼루션 값(y1~y4)은 출력 노드에 입력된 값들이 합산된 값일 수 있다. 출력 노드에 입력된 값은 입력 노드의 값을 가중치 파라미터(w1~w4)에 곱한 값일 수 있다. 출력 노드들의 컨볼루션 값들(y1~y4)은 컨볼루 션 레이어의 출력 데이터에 포함될 수 있다. 예를 들어, 출력 노드들의 컨볼루션 값들(y1~y4)은 컨볼루션맵 에 포함될 수 있다. 구체적으로, 출력 노드의 컨볼루션 값(y1~y4)은 해당 출력 노드와 연결된 입력 노드, 및 필터에 포함된 가 중치 파라미터(w1~w4)를 이용한 컨볼루션 연산을 통해 획득될 수 있다. 제1 출력 노드의 제1 컨볼루션 값(y1)을 대표적인 예로 들면, 제1 컨볼루션 값(y1)은 제1 출력 노드와 연결된 제1 입력 노드의 제1 픽셀값(x1)을 제1 가 중치 파라미터(w1)에 곱한 값, 제1 출력 노드와 연결된 제2 입력 노드의 제2 픽셀값(x2)을 제2 가중치 파라미터 (w2)에 곱한 값, 제1 출력 노드와 연결된 제4 입력 노드의 제4 픽셀값(x4)을 제3 가중치 파라미터(w3)에 곱한 값, 및 제1 출력 노드와 연결된 제5 입력 노드의 제5 픽셀값(x5)을 제4 가중치 파라미터(w4)에 곱한 값을 합산 한 값일 수 있다. 도 6a 및 도 6b는 본 개시의 일 실시 예에 따른 컨볼루션 연산을 설명하기 위한 도면이다. 도 6a 및 도 6b를 참조하면, 본 개시의 일 실시 예에 따른 컨볼루션 레이어는 다채널의 이미지가 입력될 수 있다. 여기서, 컨볼루션 레이어는 다채널의 필터를 포함할 수 있다. 컨볼루션 레이어는 이미지 및 필터 중에서 같은 채널의 이미지 및 필터를 이용하여 컨볼루션 연산을 수행할 수 있다. 컨볼루션 레이어는 컨볼루션 연산의 수행 결과로 획득된 최종 컨볼루션맵을 출력할 수 있다. 구체적인 예를 들어, 이미지는 레드 채널의 제1 이미지(610R), 그린 채널의 제2 이미지(610G), 블루 채널 의 제3 이미지(610B)를 포함할 수 있다. 여기서, 제1 이미지(610R)는 레드 채널의 픽셀값들을 포함할 수 있다. 제2 이미지(610G)는 그린 채널의 픽셀값들을 포함할 수 있다. 제3 이미지(610B)는 블루 채널의 픽셀값들을 포함 할 수 있다. 필터는 레드 채널의 제1 필터(620R), 그린 채널의 제2 필터(620G), 블루 채널의 제3 필터(620B)를 포함할 수 있다. 여기서, 제1 필터(620R), 제2 필터(620G) 및 제3 필터(620B) 각각은 서로 독립적인 복수의 가중치 파 라미터들을 포함할 수 있다. 이 경우, 컨볼루션 레이어는 제1 이미지(610R) 및 제1 필터(620R)에 대한 컨볼루션 연산을 수행하여 제1 컨볼루 션맵(650R)을 획득할 수 있다. 컨볼루션 레이어는 제2 이미지(610G) 및 제2 필터(620G)에 대한 컨볼루션 연산을 수행하여 제2 컨볼루션맵(650G)을 획득할 수 있다. 컨볼루션 레이어는 제3 이미지(610B) 및 제3 필터(620B)에 대한 컨볼루션 연산을 수행하여 제3 컨볼루션맵(650B)을 획득할 수 있다. 여기서, 컨볼루션 연산은 도 5a 내지 도 5e에서 전술한 내용과 중복되는 점에서 생략하도록 한다. 그리고, 컨볼루션 레이어는 제1 컨볼루션맵(650R), 제2 컨볼루션맵(650G) 및 제3 컨볼루션맵(650B)를 합산하여 최종 컨볼루션맵을 획득할 수 있다.도 7a 및 도 7b는 본 개시의 일 실시 예에 따른 활성화 함수 레이어를 설명하기 위한 도면이다. 도 7a 및 도 7b를 참조하면, 활성화 함수 레이어는 컨볼루션맵이 입력되면, 활성화맵을 출력할 수 있다. 활성화맵은 컨볼루션맵에 포함된 값들 각각에 활성화 함수를 적용해 계산한 값들을 포함할 수 있다. 예를 들어, 데이터 연산부는 활성화 함수 레이어에 컨볼루션맵를 입력하고, 활성화 함 수 레이어의 출력 데이터인 활성화맵을 획득할 수 있다. 일 실시 예에 따른 활성화 함수는 출력 값을 비선형으로 만드는 함수일 수 있다. 일 실시 예에서, 활성화 함수 는 도 7b의 함수 테이블에 포함된 함수들 중 하나일 수 있다. 예를 들어, 활성화 함수는 Sigmoid 함수, tanh 함수, ReLU(Rectified Linear Unit) 함수, Leaky ReLU 함수, ELU(Exponential Linear Unit) 함수, maxout 함수 중 하나일 수 있다. 도 8은 본 개시의 일 실시 예에 따른 제2 특징 추출 레이어를 설명하기 위한 도면이다. 도 8을 참조하면, 제2 특징 추출 레이어(210-2)는 제1 활성화맵(AM_1)에 대한 제2 활성화맵(AM_2)을 출력할 수 있다. 즉, 제2 특징 추출 레이어(210-2)는 제1 활성화맵(AM_1)이 입력되면, 제2 활성화맵(AM_2)을 출력할 수 있 다. 예를 들어, 데이터 연산부는 제2 특징 추출 레이어(210-2)에 제1 활성화맵(AM_1)을 입력하고, 제2 특 징 추출 레이어(210-2)의 출력 데이터인 제2 활성화맵(AM_2)을 획득할 수 있다. 제2 특징 추출 레이어(210-2)는 제2 컨볼루션 레이어(213-2)를 포함할 수 있다. 제2 컨볼루션 레이어(213-2)는 적어도 하나의 필터를 포함할 수 있다. 하나의 필터는 복수의 가중치 파라미터들을 포함할 수 있다. 제2 컨볼루 션 레이어(213-2)는 제2 컨볼루션 레이어(213-2)에 포함된 필터를 이용해 입력 데이터에 대한 컨볼루션 연산을 수행할 수 있다. 컨볼루션 연산에 관련된 내용은 도 5a 내지 도 6b에서 전술한 내용과 중복되는 점에서 생략하 도록 한다. 일 실시 예에 따른 제2 특징 추출 레이어(210-2)는 제1 풀링 레이어(211-2) 및 제2 활성화 함수 레이어(215-2) 중에서 적어도 하나를 더 포함할 수 있다. 제1 풀링 레이어(211-2)는 제2 컨볼루션 레이어(213-2)와 직렬로 연결될 수 있다. 즉, 제1 풀링 레이어(211-2) 및 제2 컨볼루션 레이어(213-2)는 제1 풀링 레이어(211-2)의 출력 데이터가 제2 컨볼루션 레이어(213-2)의 입력 데이터로 처리되도록 연결될 수 있다. 제1 풀링 레이어(211-2)는 입력 데이터에 포함된 값들의 개수를 감소시키는 연산을 수행할 수 있다. 여기서, 제 1 풀링 레이어(211-2)의 입력 데이터는 제1 활성화맵(AM_1)일 수 있다. 구체적인 내용은 도 9a 및 도 9b를 참조 하여 설명하도록 한다. 제2 활성화 함수 레이어(215-2)는 제2 컨볼루션 레이어(213-2)와 직렬로 연결될 수 있다. 즉, 제2 활성화 함수 레이어(215-2) 및 제2 컨볼루션 레이어(213-2)는 제2 컨볼루션 레이어(213-2)의 출력 데이터가 제2 활성화 함수 레이어(215-2)의 입력 데이터로 처리되도록 연결될 수 있다. 도 9a 및 도 9b는 본 개시의 일 실시 예에 따른 풀링 레이어를 설명하기 위한 도면이다. 도 9a 및 도 9b를 참조하면, 풀링 레이어는 활성화맵이 입력되면, 풀링 데이터를 출력할 수 있 다. 예를 들어, 데이터 연산부는 활성화맵을 풀링 레이어에 입력하고, 풀링 레이어의 출력 데이터인 풀링 데이터를 획득할 수 있다. 일 실시 예에서, 풀링 레이어는 활성화맵이 입력되면, 활성화맵에 포함된 값들(z1~z16)을 단위 영역마다 하나의 그룹으로 묶고, 각 단위 영역에 대응되는 풀링 함수를 계산하여 풀링 데이터를 획득할 수 있다. 풀링 데이터는 제1 그룹(Z1)에 대한 제1 풀링 값(g(Z1)), 제2 그룹(Z2)에 대한 제2 풀링 값 (g(Z2)), 제3 그룹(Z3)에 대한 제3 풀링 값(g(Z3)) 및 제4 그룹(Z4)에 대한 제4 풀링 값(g(Z4))을 포함할 수 있다. 여기에서, 단위 영역의 사이즈는 2 x 2인 것을 가정하였으나, 이는 다양하게 변형되어 실시될 수 있다. 여기에서, 풀링 함수는 활성화맵에 포함된 값의 개수를 감소시키는 함수일 수 있다. 즉, 풀링 함수는 다운 샘플링을 통해 활성화맵의 사이즈를 줄이는 함수일 수 있다. 일 실시 예에서, 풀링 함수는 도 9b의 함수 테이블에 포함된 함수들 중 하나일 수 있다. 예를 들어, 풀링 함수는 max 함수, min 함수, average 함수중 하나일 수 있다. 이에 따라, 풀링 데이터에 포함된 값의 개수는 활성화맵에 포함된 값의 개수보다 적을 수 있다. 한편, 풀링 레이어의 출력 데이터인 풀링 데이터는 풀링 레이어와 직렬 연결된 컨볼루션 레이어 의 입력 데이터로 처리될 수 있다. 도 10a는 본 개시의 일 실시 예에 따른 풀리 커넥티드 레이어를 설명하기 위한 도면이다. 도 10a를 참조하면, 풀리 커넥티드 레이어는 서로 직렬로 연결되는 입력 레이어, 히든 레이어 및 출력 레이어를 포함할 수 있다. 데이터 연산부는 입력 레이어에 입력된 데이터를 1차원 데이터로 인코딩할 수 있다. 입력된 데이터 는 가로 x 세로 x 채널과 같은 3차원 데이터일 수 있다. 입력 레이어는 복수의 입력 노드들을 포함할 수 있다. 하나의 입력 노드에는 1차원 데이터 값들(x1~x3) 중 하나가 입력될 수 있다. 히든 레이어는 복수의 히든 노드들을 포함할 수 있다. 복수의 히든 노드들 각각은 복수의 입력 노드들 각 각에 연결되는 구조일 수 있다. 서로 연결된 입력 노드 및 출력 노드 간에는 가중치 파라미터가 설정될 수 있다. 또한, 가중치 파라미터는 학습을 통해 업데이트될 수 있다. 데이터 연산부는 하나의 히든 노드에 연 결된 입력 노드들에 대응되는 입력 값들(x1~x3)에 대한 가중치 연산을 수행하고, 가중치 연산의 결과로 하나의 히든 노드에 대응되는 각 히든 값(h1~h4)을 획득할 수 있다. 일 실시 예에 따른 히든 레이어는 생략될 수 있다. 이와 다른 일 실시 예에 따른 히든 레이어는 복 수의 레이어로 구성될 수 있다. 출력 레이어는 복수의 출력 노드들을 포함할 수 있다. 복수의 출력 노드들 각각은 복수의 히든 노드들 각 각에 연결되는 구조일 수 있다. 서로 연결된 히든 노드 및 출력 노드 간에는 가중치 파라미터가 설정될 수 있다. 가중치 파라미터는 학습을 통해 업데이트될 수 있다. 데이터 연산부는 하나의 출력 노드에 연결된 히든 노드들에 대응되는 히든 값들(h1~h4)에 대한 가중치 연산을 수행하고, 가중치 연산의 결과로 하나의 출력 노드에 대응되는 각 출력 값(z1, z2)을 획득할 수 있다. 여기서, 출력 값(z1, z2)의 개수는 출력 노드의 개수와 같을 수 있다. 도 10b는 본 개시의 일 실시 예에 따른 소프트맥스 레이어를 설명하기 위한 도면이다. 도 10b를 참조하면, 소프트맥스 레이어는 출력 레이어의 출력 값들(z1, z2) 각각에 소프트맥스 함 수를 적용한 연산을 수행할 수 있다. 예를 들어, 데이터 연산부는 소프트맥스 레이어에 풀리 커넥티 드 레이어의 출력 값들(z1, z2)을 입력하고, 소프트맥스 레이어의 출력 데이터인 클래스 스코어 (score_class)를 획득할 수 있다. 클래스 스코어(score_class)는 복수의 스코어들(s1, s2)을 포함할 수 있다. 여기에서, 소프트맥스 함수는 정규화를 통해 출력 값(z1, z2)을 확률을 나타내는 스코어(s1, s2)로 변환하는 함 수일 수 있다. 일 실시 예에 따른 소프트맥스 함수는 도 10b에 도시된 Softmax(zk)와 같은 함수일 수 있다. 각 스코어(z1, z2)는 하나의 클래스에 대응될 수 있다. 예를 들어, 제1 스코어(s1)은 이미지에 포함된 객체가 제1 클래스에 매칭되는 정도를 나타낼 수 있다. 제2 스코어(s2)은 이미지에 포함된 객체가 제2 클래스에 매칭되 는 정도를 나타낼 수 있다. 여기서, 제1 스코어(s1)의 값이 제2 스코어(s2)의 값보다 높다는 것은, 이미지에 포 함된 객체가 제1 클래스로 분류될 확률이 높다는 것을 의미할 수 있다. 도 10c는 본 개시의 일 실시 예에 따른 소프트맥스 손실값을 설명하기 위한 도면이다. 도 10c를 참조하면, 손실값 연산부는 소프트맥스 레이어로부터 출력된 클래스 스코어(s1, s2) 및 기 준 스코어를 손실 함수에 입력하고, 손실 함수를 계산한 결과로 소프트맥스 손실값(loss_softmax)를 획득 할 수 있다. 여기에서, 소프트맥스 손실값(loss_softmax)은 1개의 값일 수 있다. 일 실시 예에 따르면, 손실값 연산부는 클래스 스코어(s1, s2)에 포함된 스코어들(s1, s2) 중에서 제1 클 래스에 대응되는 제1 스코어(s1)와 기준 스코어에 포함된 기준 값들(t1, t2) 중에서 제1 클래스에 대응되 는 제1 기준 값(t1)의 차이를 제1 오차(e1)로서 획득할 수 있다. 그리고, 손실값 연산부는 제2 클래스에대응되는 제2 스코어(s2)와 제2 기준 값(t2)의 차이를 제2 오차(e2)로서 획득할 수 있다. 일 실시 예에서, 손실 값 연산부는 제1 오차(e1) 및 제2 오차(e2)를 합산한 값을 소프트맥스 손실값(loss_softmax)으로 획득할 수 있다. 일 실시 예에서, 손실값 연산부는 제1 오차(e1)의 제곱 값 및 제2 오차(e2)의 제곱 값을 합산한 값을 소프트맥스 손실값(loss_softmax)으로 획득할 수 있다. 다만, 이는 일 실시 예일 뿐이며, 손실값 연산부는 L1 손실 함수, L2 손실 함수, SSIM(Structure Similarity Index), VGG loss 등의 다양한 손실 함수 중 하나를 이용하여 소프트맥스 손실값(loss_softmax)를 획득할 수 있다. 도 11a는 본 개시의 일 실시 예에 따른 세그먼테이션 값을 설명하기 위한 도면이다. 도 11a를 참조하면, 손실값 연산부는 손실 함수에 제N 스케일된 활성화맵 및 이진화 이미지 를 입력하고, 제1 손실 함수를 계산한 결과로 제N 세그먼테이션 값(loss_segN)을 획득할 수 있다. 여기에 서, 제N 스케일된 활성화맵은 복수의 값들(m1~m9)을 포함할 수 있다. 이진화 이미지는 복수의 값들 (c1~c9)을 포함할 수 있다. 예를 들어, 제N 스케일된 활성화맵 및 이진화 이미지은 같은 개수의 값들 을 포함할 수 있다. 제N 세그먼테이션 값(loss_segN)은 1개의 값일 수 있다. 일 실시 예에 따르면, 손실값 연산부는 제N 스케일된 활성화맵에 포함된 값들(m1~m9) 중에서 (1, 1) 위치의 제1 값(m1)을 선택하고, 이진화 이미지에 포함된 값들(c1~c9) 중에서 (1, 1) 위치의 제1 값(c1)을 선택할 수 있다. 손실값 연산부는 서로 같은 (1, 1) 위치의 제1 값들(m1, c1)의 차이를 제1 오차로 획득할 수 있다. 그리고, 손실값 연산부는 (2, 1) 위치의 제2 값들(m2, c2)을 선택하고, 서로 같은 (2, 1) 위치의 제2 값들(m2, c2)의 차이를 제2 오차로 획득할 수 있다. 이와 유사한 방식으로 손실값 연산부는 (3, 3) 위 치의 제9 값들(m9, c9)의 차이를 제9 오차로 획득할 수 있다. 일 실시 예에서, 손실값 연산부는 제1 오차 내지 제9 오차를 합산한 값을 제N 세그먼테이션 값(loss_segN)으로 획득할 수 있다. 일 실시 예에서, 손실값 연 산부는 제1 오차의 제곱 값 내지 제9 오차의 제곱 값을 합산한 값을 제N 세그먼테이션 값(loss_segN)으로 획득할 수 있다. 다만, 이는 일 실시 예일 뿐이며, 손실값 연산부는 L1 손실 함수, L2 손실 함수, SSIM(Structure Similarity Index), VGG loss 등의 다양한 손실 함수 중 하나를 이용하여 제N 세그먼테이션 값 (loss_segN)를 획득할 수 있다. 이와 같은 방식을 통해 손실값 연산부는 제1 세그먼테이션 값(loss_seg1) 내지 제N 세그먼테이션 값(loss_segN)을 획득할 수 있다. 도 11b는 본 개시의 일 실시 예에 따른 최종 손실값을 설명하기 위한 도면이다. 도 11b의 의 수식을 참조하면, 일 실시 예에 있어서, 손실값 연산부는 복수의 세그먼테이션 값들 (loss_seg1~loss_segN)을 이용한 합 연산을 수행한 결과 값을 활성화맵 손실값(loss_AM)으로 획득할 수 있다. 다만 이는 일 실시 예일 뿐이며, 합 연산은 가중치 연산 및 평균 연산 중에서 하나로 변경되어 실시될 수 있다. 도 11b의 의 수식을 참조하면, 일 실시 예에 있어서, 손실값 연산부는 활성화맵 손실값(loss_AM) 및 소 프트맥스 손실값(loss_sofrmax)을 이용한 가중치 연산을 수행한 결과 값을 최종 손실값(loss_f)으로 획득할 수 있다. 가중치 연산은 활성화맵 손실값(loss_AM) 및 소프트맥스 손실값(loss_sofrmax) 각각에 서로 다른 가중치 (α, 1-α)를 곱한 후, 이들을 합하는 연산일 수 있다. 여기서, 각각의 가중치(α, 1-α)는 미리 설정된 값일 수 있다. 일 실시 예에서, 서로 다른 가중치들(α, 1-α)의 합은 1일 수 있다. 도 11c는 본 개시의 일 실시 예에 따른 분류 네트워크의 학습을 설명하기 위한 도면이다. 도 11c를 참조하면, 데이터 학습부는 학습 이미지(data_TR)를 분류 네트워크에 입력할 수 있다. 이 경우, 데이터 학습부는 분류 네트워크으로부터 출력된 클래스 스코어(score_class)를 획득할 수 있다. 데이터 학습부는 클래스 스코어(score_class) 및 기준 스코어(score_t)를 적용한 손실 함수로부터 출력된 소프트맥스 손실값(loss_softmax)을 획득할 수 있다. 한편, 데이터 학습부는 분류 네트워크에 포함된 복수의 특징 추출 레이어들(210-1~210-N) 각각으로부 터 출력된 활성화맵들(AM_1~AM_N)을 스케일링하여, 스케일된 활성화맵들을 획득할 수 있다. 데이터 학습부(10 0)는 학습 이미지(data_TR)에 대응되는 이진화 이미지(data_TRB) 및 스케일된 활성화맵들 각각을 적용한 손실 함수를 계산하여, 활성화맵 손실값(loss_AM)을 획득할 수 있다. 이 경우, 데이터 학습부는 소프트맥스 손실값(loss_softmax) 및 활성화맵 손실값(loss_AM)에 대한 가중치 연산을 통해 최종 손실값(loss_f)를 획득할 수 있다. 데이터 학습부는 최종 손실값(loss_f)을 분류 네트워 크에 역전파(back-propagtion)함으로써 복수의 특징 추출 레이어들(210-1~210-N) 중에서 적어도 하나를 학 습할 수 있다. 일 실시 예에서, 최종 손실값(loss_f)은 분류 네트워크 또는 분류 모델의 출력 노드에 입력되어, 각각의 노드와 연결된 엣지들을 고려해 역순으로 계산하는 방식일 수 있다. 이에 따라, 복수의 특징 추출 레이어들(210-1~210-N) 각각에 포함된 컨볼루션 레이어의 가중치 파라미터들 중 적어도 하나가 업데이트될 수 있다. 도 12a 및 도 12b는 본 개시의 일 실시 예에 따른 학습된 분류 네트워크를 이용하는 전자 장치를 설명하기 위한 도면이다. 도 12a 및 도 12b를 참조하면, 본 개시의 일 실시 예에 따른 제3 전자 장치는 프로세서 및 메모리 를 포함할 수 있다. 프로세서는 CPU(Central Processing Unit), APU(Application Processor Unit) 등과 같은 범용 프로세서, GPU(Graphic Processing Unit) 등과 같은 그래픽 전용 프로세서, NPU(Neural Processing Unit)와 같은 인공지 능 전용 프로세서 등으로 구현될 수 있다. 프로세서는 하나 또는 복수의 프로세서 유닛으로 구성될 수 있 다. 메모리는 데이터, 정보 또는 인스트럭션 등의 다양한 정보를 전기 또는 자기 형태로 저장할 수 있다. 이 를 위해, 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(Flash Memory), 하드디스크 드라이브 (HDD) 또는 솔리드 스테이트 드라이브(SSD), RAM, ROM 등 중에서 적어도 하나의 하드웨어로 구현될 수 있다. 메모리는 학습된 분류 네트워크를 저장할 수 있다. 학습된 분류 네트워크는 이미지에 포함된 객체를 분류하도록 학습된 것일 수 있다. 구체적으로, 학습된 분류 네트워크는 분류 네트워크에 입력 된 학습 이미지(data_TR)에 대응되는 클래스 스코어(score_class)를 이용해 획득된 소프트맥스 손실값 (loss_softmax), 및 분류 네트워크에 포함된 복수의 특징 추출 레이어들 각각으로부터 출력된 활성화맵들 을 이용해 획득된 활성화맵 손실값(loss_AM)의 가중치 연산을 기초로 학습된 신경망 네트워크일 수 있다. 분류 네트워크는 추출 모델 및 분류 모델을 포함할 수 있다. 추출 모델은 복수의 특징 추 출 레이어들(210-1~210-N)을 포함할 수 있다. 분류 모델은 풀리 커넥티드 레이어 및 소프트맥스 레이 어를 포함할 수 있다. 풀리 커넥티드 레이어는 복수의 특징 추출 레이어들 중 마지막 순서의 특징 추 출 레이어와 직렬 연결된 것일 수 있다. 소프트맥스 레이어는 풀리 커넥티드 레이어와 직렬 연결된 것일 수 있다. 일 실시 예에 있어서, 복수의 특징 추출 레이어들(210-1~210-N) 각각은 직렬로 연결된 컨볼루션 레이어 및 활성 화 함수 레이어를 포함할 수 있다. 여기서, 컨볼루션 레이어는 복수의 가중치 파라미터들을 포함할 수 있다. 복 수의 가중치 파라미터들 중 적어도 하나는, 가중치 연산의 결과로 획득된 손실값을 분류 네트워크에 역전 파함으로써 업데이트된 것일 수 있다. 일 실시 예에 있어서, 활성화맵 손실값(loss_AM)은 학습 이미지(data_TR)의 사이즈와 같은 사이즈를 갖도록 사 이즈가 조정된 활성화맵들 각각 및 학습 이미지(data_TR)에 대응되는 이진화 이미지(data_TRB)에 손실 함수를 적용함으로써 획득된 세그먼트 값들의 합일 수 있다. 일 실시 예에 있어서, 입력 이미지(data_input) 및 학습 이미지(data_TR)는 제1 색상 채널의 픽셀값들, 제2 색 상 채널의 픽셀값들 및 제3 색상 채널의 픽셀값들을 포함할 수 있다. 일 실시 예에 따른 프로세서는 데이터 처리부를 포함할 수 있다. 데이터 처리부는 수신된 입력 이미지(data_input)를 분류 네트워크에 입력할 수 있다. 데이터 처리부는 분류 네트워크를 통해 입력 이미지(data_input)에 포함된 객체가 복수의 클래스 각각에 매칭되는 스코어를 나타내는 클래스 스코어 (score_class)를 획득할 수 있다. 일 실시 예에서, 데이터 처리부는 분류 네트워크에 포함된 복수의 특징 추출 레이어들(210-1~210-N) 중에서 제1 특징 추출 레이어(210-1)에 입력 이미지(data_input)를 입력할 수 있다. 데이터 처리부는 제1 특징 추출 레이어(210-1)으로부터 출력된 제1 활성화맵을 제2 특징 추출 레이어(210-2)로 입력할 수 있다. 이와 같은 방식으로, 데이터 처리부는 제N-1 특징 추출 레이어으로부터 출력된 제N-1 활성화맵을 제N 특징 추출레이어(210-N)로 입력할 수 있다. 그리고, 데이터 처리부는 제N 특징 추출 레이어(210-N)로부터 출력된 제 N 활성화맵(AM_N)을 분류 모델에 입력할 수 있다. 데이터 처리부는 분류 모델로부터 출력된 클 래스 스코어(score_class)를 획득할 수 있다. 이 경우, 데이터 처리부는 클래스 스코어(score_class)에 포 함된 복수의 스코어들 중에서 가장 높은 스코어에 대응되는 클래스로 객체를 분류할 수 있다. 한편, 입력 이미지(data_input)는 이미지 센서를 통해 수신될 수 있다. 이미지 센서는 제3 전자 장 치의 내부에 포함되거나, 또는 제3 전자 장치의 외부에 별도로 존재할 수 있다. 이미지 센서는 광 신호를 센싱하여 이미지를 획득할 수 있다. 이를 위해, 이미지 센서는 CCD(Charge Coupled Device) 센서 또는 CMOS(Complementary Metal Oxide Semiconductor) 센서 등으로 구현될 수 있다. 도 13a 및 도 13b는 본 개시의 일 실시 예에 따른 학습된 분류 네트워크를 이용하는 방법을 설명하기 위한 도면 이다. 도 13a를 참조하면, 일 실시 예에 있어서, 제3 전자 장치는 이미지 센서 및 디스플레이를 더 포함할 수 있다. 이미지 센서는 객체를 촬영함으로써 객체를 포함하는 입력 이미지(data_input)를 획득할 수 있다. 디스플레이는 정보를 표시할 수 있다. 이를 위해, 디스플레이는 별도의 백라이트 유닛(예: LED(light emitting diode) 등)을 광원으로 이용하고 액정(Liquid Crystal)의 분자 배열을 제어함으로써 백라 이트 유닛에서 방출된 빛이 액정을 통해 투과되는 정도(빛의 밝기 또는 빛의 세기)를 조절하는 LCD(Liquid Crystal Display), 별도의 백라이트 유닛 또는 액정 없이 자발광 소자(예: 크기가 100-200μm인 mini LED, 크 기가 100μm이하인 micro LED, OLED(Organic LED), QLED(Quantum dot LED) 등)를 광원으로 이용하는 디스플레 이 등과 같은 다양한 형태의 디스플레이로 구현될 수 있다. 이 경우, 디스플레이는 출력 이미지에 대응되 는 레드, 그린, 블루 색상의 빛을 외부로 방출시킬 수 있다. 이 경우, 프로세서는 이미지 센서를 통해 입력 이미지(data_input)가 수신되면, 입력 이미지 (data_input)를 분류 네트워크에 입력할 수 있다. 그리고, 프로세서는 분류 네트워크로부터 출 력된 클래스 스코어(score_class)에 포함된 스코어들 중 가장 높은 스코어에 대응되는 클래스로 객체를 분류한 결과를 표시하도록 디스플레이를 제어할 수 있다. 일 실시 예에 따르면, 제3 전자 장치는 통신부를 더 포함할 수 있다. 통신부는 제2 전자 장 치와 다양한 방식에 따른 데이터 통신을 수행할 수 있다. 이를 위해, 제2 전자 장치는 통신부 를 포함할 수 있다. 여기서, 통신부(1150, 1250)는 TCP/IP(Transmission Control Protocol/Internet Protocol), UDP(User Datagram Protocol), HTTP(Hyper Text Transfer Protocol), HTTPS(Secure Hyper Text Transfer Protocol), FTP(File Transfer Protocol), SFTP(Secure File Transfer Protocol), MQTT(Message Queuing Telemetry Transport) 등의 통신 규약(프로토콜)을 이용하여 다양한 정보를 송수신할 수 있다. 이를 위해, 통신부(1150, 1250)는 유선 통신 또는 무선 통신을 통해 네트워크로 연결될 수 있다. 이때, 네트워 크는 영역 또는 규모에 따라 개인 통신망(PAN; Personal Area Network), 근거리 통신망(LAN; Local Area Network), 광역 통신망(WAN; Wide Area Network) 등일 수 있으며, 네트워크의 개방성에 따라 인트라넷 (Intranet), 엑스트라넷(Extranet), 또는 인터넷(Internet) 등일 수 있다. 여기에서, 무선 통신은 LTE(long-term evolution), LTE-A(LTE Advance), 5G(5th Generation) 이동통신, CDMA(code division multiple access), WCDMA(wideband CDMA), UMTS(universal mobile telecommunications system), WiBro(Wireless Broadband), GSM(Global System for Mobile Communications), DMA(Time Division Multiple Access), WiFi(Wi-Fi), WiFi Direct, Bluetooth, NFC(near field communication), Zigbee 등의 통신 방식 중 적어도 하나를 포함할 수 있다. 유선 통신은 이더넷(Ethernet), 광 네트워크(optical network), USB(Universal Serial Bus), 선더볼트(ThunderBolt) 등의 통신 방식 중 적어도 하나를 포함할 수 있다. 제3 전자 장치는 제2 전자 장치로부터 학습된 분류 네트워크를 수신할 수 있다. 수신된 분류 네트워크는 제3 전자 장치의 메모리에 저장될 수 있다. 여기에서, 제2 전자 장치 및 제3 전자 장치 각각은 서버, 데이터 센터, 클라우드 서버, 워크스테이 션, 모바일 장치, 스마트폰(smart phone), PC(Personal Computer), 태블릿 PC(tablet personal computer), 노 트북(notebook), PDA(personal digital assistant), EDA(enterprise digital assistant), PMP(portable multimedia player), 웨어러블 디바이스(wearable device), 블랙박스, 로봇, 드론, 자율주행 차량, 셋톱 박스, 스마트 스피커, 인공지능 스피커, 게임 콘솔, 텔레비전, 냉장고, 에어컨, 세탁기, 공기 청정기, 스마트 미러, 스마트 윈도우, 전자 액자 등일 수 있다. 여기서, 웨어러블 디바이스는 스마트 워치, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 헤드 마운티드 장치(head-mounted-device; HMD), 스킨 패드, 문신, 또는 생체 이식 형 회로 등일 수 있다. 도 13b를 참조하면, 일 실시 예에 있어서, 제3 전자 장치는 통신부를 포함할 수 있다. 여기에서, 통신부는 외부 장치로부터 입력 이미지(data_input)를 수신할 수 있다. 외부 장치는 프로세서, 메모리, 이미지 센서, 디스플레이, 및 통신부를 포함할 수 있다. 여기에서, 상술한 프로세서(1110, 1210), 메모리(1120, 1220), 이미지 센서, 디스플레이 , 통신부(1150, 1250) 각각에 대한 설명은 외부 장치의 프로세서, 메모리, 이미지 센 서, 디스플레이, 및 통신부에 적용될 수 있다. 외부 장치는 이미지 센서를 통해 입력 이미지(data_input)를 획득하면, 통신부를 통해 입력 이미지(data_input)를 제3 전자 장치로 전송할 수 있다. 이 경우, 프로세서는 통신부를 통해 입력 이미지(data_input)가 수신되면, 입력 이미지 (data_input)를 분류 네트워크에 입력할 수 있다. 그리고, 프로세서는 분류 네트워크로부터 출 력된 클래스 스코어(score_class)에 포함된 스코어들 중 가장 높은 스코어에 대응되는 클래스로 객체를 분류한 분류 결과를 외부 장치로 전송하도록 통신부를 제어할 수 있다. 이 경우, 외부 장치는 통신부를 통해 분류 결과가 수신되면, 분류 결과를 디스플레이에 표시 할 수 있다. 여기서, 외부 장치는 모바일 장치, 스마트폰, PC 등일 수 있으나, 이에 한정되지 아니하고 상술한 제2 전자 장치 및 제3 전자 장치의 예시들 중 하나일 수 있다. 여기서, 제3 전자 장치 는 서버일 수 있으나, 이에 한정되지 아니하고 다양한 실시 예들로 변형될 수 있다. 도 14는 본 개시의 일 실시 예에 따른 전자 장치의 동작 방법을 설명하기 위한 도면이다. 도 14를 참조하여, 본 개시의 일 실시 예에 따른 전자 장치의 동작 방법은 복수의 특징 추출 레이어들(210- 1~210-N)을 포함하는 분류 네트워크에 학습 이미지(data_TR)를 입력하는 단계(S1410), 및 분류 네트워크 로부터 출력된 클래스 스코어(score_class)를 획득하는 단계(S1420), 복수의 특징 추출 레이어들(210- 1~210-N) 각각으로부터 출력된 복수의 활성화맵들(AM_1~AM_N), 및 클래스 스코어(score_class)를 기초로 최종 손실값(loss_f)을 획득하는 단계(S1430), 및 최종 손실값(loss_f)을 기초로 분류 네트워크를 제어하는 단계 (S1440)를 포함할 수 있다. 구체적으로, 분류 네트워크에 학습 이미지(data_TR)를 입력할 수 있다(S1410). 그리고, 분류 네트워크 로부터 출력된 클래스 스코어(score_class)를 획득할 수 있다(S1420). 여기서, 분류 네트워크는 객체 를 포함하는 이미지가 입력되면, 객체에 대응되는 클래스 스코어(score_class)를 출력하도록 구성될 수 있다. 예를 들어, 분류 네트워크는 추출 모델 및 분류 모델을 포함할 수 있다. 추출 모델은 복수 의 특징 추출 레이어들(210-1~210-N)을 포함할 수 있다. 분류 모델은 풀리 커넥티드 레이어 및 소프 트맥스 레이어를 포함할 수 있다. 그리고, 복수의 활성화맵들(AM_1~AM_N), 및 클래스 스코어(score_class)를 기초로 최종 손실값(loss_f)을 획득 할 수 있다(S1430). 일 실시 예에서, 복수의 활성화맵들(AM_1~AM_N)을 기초로 활성화맵 손실값(loss_AM)을 획득할 수 있다. 구체적인 일 실시 예에 있어서, 복수의 활성화맵들(AM_1~AM_N) 각각의 사이즈를 스케일링함으로써 스케일된 활 성화맵들을 획득할 수 있다. 이 경우, 스케일된 활성화맵들 각각은 학습 이미지의 사이즈와 같은 사이즈를 가질 수 있다. 그리고, 스케일된 활성화맵들 각각 및 학습 이미지(data_TR)에 대응되는 이진화 이미지(data_TRB)를손실 함수에 입력함으로써 세그먼테이션 값들(loss_seg1~loss_segN)을 획득할 수 있다. 예를 들어, 스케일된 활 성화맵들 중, 제1 스케일된 활성화맵 및 이진화 이미지(data_TRB)를 적용한 손실 함수에 계산하여 제1 세그먼테 이션 값(loss_seg1)을 획득하고, 제2 스케일된 활성화맵 및 이진화 이미지(data_TRB)를 적용한 손실 함수에 계 산하여 제2 세그먼테이션 값(loss_seg2)을 획득하는 것과 같이 스케일된 활성화맵들 각각에 대한 세그먼테이션 값들(loss_seg1~loss_segN)을 획득할 수 있다. 그리고, 세그먼테이션 값들(loss_seg1~loss_segN)을 이용한 연 산을 수행한 결과 값을 활성화맵 손실값(loss_AM)으로 획득할 수 있다. 여기에서, 연산은 합 연산, 가중치 연산 및 평균 연산 중에서 하나일 수 있다. 일 실시 예에서, 클래스 스코어(score_class)를 기초로 소프트맥스 손실값(loss_softmax)을 획득할 수 있다. 여 기서, 클래스 스코어(score_class)는 소프트맥스 레이어의 출력 데이터일 수 있다. 소프트맥스 손실값 (loss_softmax)는 클래스 스코어(score_class)의 오차를 나타낼 수 있다. 구체적인 일 실시 예에 있어서, 클래스 스코어(score_class) 및 객체에 대응되는 기준 스코어(score_t)를 손실 함수에 입력함으로써 소프트맥스 손실값(loss_softmax)을 획득할 수 있다. 예를 들어, 클래스 스코어 (score_class) 및 기준 스코어(score_t)를 적용한 손실 함수를 계산하여 소프트맥스 손실값(loss_softmax)을 획득할 수 있다. 기준 스코어(score_t)는 학습 이미지(data_TR)에 포함된 객체에 대해 미리 결정된 것일 수 있 다. 일 실시 예에서, 활성화맵 손실값(loss_AM) 및 소프트맥스 손실값(loss_softmax)을 기초로 최종 손실값(loss_ f)을 획득할 수 있다. 구체적인 일 실시 예에서, 활성화맵 손실값(loss_AM) 및 소프트맥스 손실값(loss_sofrmax)을 이용한 가중치 연 산을 수행한 결과 값을 최종 손실값(loss_f)으로 획득할 수 있다. 가중치 연산은 활성화맵 손실값(loss_AM) 및 소프트맥스 손실값(loss_sofrmax) 각각에 서로 다른 가중치(α, 1-α)를 곱한 후, 이들을 합하는 연산일 수 있 다. 여기서, α는 0 이상이고 1 이하인 값일 수 있다. 그리고, 최종 손실값(loss_f)을 기초로 분류 네트워크를 제어할 수 있다(S1440). 여기서, 제어는 분류 네 트워크를 학습하는 것을 의미할 수 있다. 일 실시 예에 있어서, 분류 네트워크를 제어하는 단계는, 최종 손실값(loss_f)을 분류 네트워크의 출 력단에 입력하여, 복수의 특징 추출 레이어들(210-1~210-N) 각각에 포함된 복수의 가중치 파라미터들 중 적어도 하나를 업데이트할 수 있다. 즉, 최종 손실값(loss_f)을 분류 네트워크에 역전파할 수 있다. 이상과 같은 본 개시의 일 실시 예에 따르면, 향상된 분류 정확도를 갖는 분류 네크워크를 학습하는 전자 장치 및 그의 동작 방법을 제공할 수 있다. 본 개시의 실시 예에 따르면, 향상된 분류 정확도를 갖는 분류 네크워크 를 이용하는 전자 장치를 제공할 수 있다."}
{"patent_id": "10-2022-0002186", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 전자 장치를 설명하기 위한 도면이다. 도 2a는 본 개시의 일 실시 예에 따른 분류 네트워크를 학습하는 전자 장치를 설명하기 위한 도면이다. 도 2b는 본 개시의 일 실시 예에 따른 분류 네트워크를 학습하는 방법을 설명하기 위한 도면이다. 도 3은 본 개시의 일 실시 예에 따른 분류 네트워크를 학습하는 방법을 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시 예에 따른 제1 특징 추출 레이어를 설명하기 위한 도면이다. 도 5a 내지 도 6b는 본 개시의 일 실시 예에 따른 컨볼루션 연산을 설명하기 위한 도면이다. 도 7a 및 도 7b는 본 개시의 일 실시 예에 따른 활성화 함수 레이어를 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시 예에 따른 제2 특징 추출 레이어를 설명하기 위한 도면이다. 도 9a 및 도 9b는 본 개시의 일 실시 예에 따른 풀링 레이어를 설명하기 위한 도면이다. 도 10a는 본 개시의 일 실시 예에 따른 풀리 커넥티드 레이어를 설명하기 위한 도면이다. 도 10b는 본 개시의 일 실시 예에 따른 소프트맥스 레이어를 설명하기 위한 도면이다. 도 10c는 본 개시의 일 실시 예에 따른 소프트맥스 손실값을 설명하기 위한 도면이다. 도 11a는 본 개시의 일 실시 예에 따른 세그먼테이션 값을 설명하기 위한 도면이다. 도 11b는 본 개시의 일 실시 예에 따른 최종 손실값을 설명하기 위한 도면이다. 도 11c는 본 개시의 일 실시 예에 따른 분류 네트워크의 학습을 설명하기 위한 도면이다. 도 12a 및 도 12b는 본 개시의 일 실시 예에 따른 학습된 분류 네트워크를 이용하는 전자 장치를 설명하기 위한 도면이다. 도 13a 및 도 13b는 본 개시의 일 실시 예에 따른 학습된 분류 네트워크를 이용하는 방법을 설명하기 위한 도면 이다. 도 14는 본 개시의 일 실시 예에 따른 전자 장치의 동작 방법을 설명하기 위한 도면이다."}
